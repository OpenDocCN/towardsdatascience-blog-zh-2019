<html>
<head>
<title>Modeling Lunar Cycles in Tweets and Financial Markets using Facebook Prophet</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用脸书预言家为推特和金融市场中的月亮周期建模</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/modeling-lunar-cycles-in-tweets-and-financial-markets-using-facebook-prophet-d6ec0e9e20f?source=collection_archive---------26-----------------------#2019-10-11">https://towardsdatascience.com/modeling-lunar-cycles-in-tweets-and-financial-markets-using-facebook-prophet-d6ec0e9e20f?source=collection_archive---------26-----------------------#2019-10-11</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><p id="417c" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">我最近读了一篇文章，认为满月时犯罪率会上升。出于对这种效应的好奇，我做了一点研究，似乎月亮周期是否影响人类行为的问题已经在学术界激烈争论了几十年(见<a class="ae ko" href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC1444800/" rel="noopener ugc nofollow" target="_blank">塔库尔和夏尔马，1984 </a>和<a class="ae ko" href="https://www.researchgate.net/publication/19277222_Much_Ado_About_the_Full_Moon_A_Meta-Analysis_of_Lunar-Lunacy_Research" rel="noopener ugc nofollow" target="_blank">罗顿和凯利，1985 </a>反对观点的例子；这场争论的双方都有很多学者)。不满意，我决定通过检查一年的推文和财务数据来进行调查。</p><h1 id="9020" class="kp kq it bd kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm bi translated">概观</h1><p id="7c7b" class="pw-post-body-paragraph jq jr it js b jt ln jv jw jx lo jz ka kb lp kd ke kf lq kh ki kj lr kl km kn im bi translated">这个项目的完整 Python 代码可以在这个<a class="ae ko" href="https://github.com/magnawhale/capstone_project" rel="noopener ugc nofollow" target="_blank"> GitHub 库</a>中找到。如果你想玩玩我的发现，我还做了一个<a class="ae ko" href="https://human-lunar-cycles.herokuapp.com/" rel="noopener ugc nofollow" target="_blank">交互式仪表盘</a>。</p><p id="8a20" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">为了这个项目，我使用各种关键词搜索短语在 2018 年的每一天收集了大约 1000 条推文。这一过程产生了每个搜索短语超过 365，000 条推文的数据集。然后，对产生的数据集进行情绪处理，并按日期汇总，以检查情绪随时间的趋势。此外，2018 年各种股票、货币和市场指数的每日金融数据都是从互联网上收集的。</p><p id="f7a4" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">然后，Twitter 和金融数据都使用脸书预言家进行建模，以确定与月亮可见阶段相关的任何季节性的程度(或缺失)。事实证明，月亮周期和人类行为之间确实存在关联，尽管影响的大小并不明显。</p><h1 id="3a32" class="kp kq it bd kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm bi translated">获取数据并探索它</h1><p id="4276" class="pw-post-body-paragraph jq jr it js b jt ln jv jw jx lo jz ka kb lp kd ke kf lq kh ki kj lr kl km kn im bi translated">当使用<a class="ae ko" href="https://github.com/taspinar/twitterscraper" rel="noopener ugc nofollow" target="_blank"> twitterscraper </a>库时，抓取 Tweets 是一个相当简单的过程(警告，这可能需要几个小时才能完全执行):</p><pre class="ls lt lu lv gt lw lx ly lz aw ma bi"><span id="f8d4" class="mb kq it lx b gy mc md l me mf"><strong class="lx iu">import</strong> pandas <strong class="lx iu">as</strong> pd<strong class="lx iu"><br/>import</strong> json<strong class="lx iu"><br/>from</strong> twitterscraper <strong class="lx iu">import</strong> query_tweets<br/><strong class="lx iu">import</strong> twitterscraper<br/></span><span id="ca90" class="mb kq it lx b gy mg md l me mf">def scrape_tweets(query, year=2018, num_tweets=1000):<br/>    <em class="mh">"""scrapes X Tweets per day for a year.</em><br/><em class="mh">    Scraping works backwards from midnight.</em><br/><em class="mh">    'query' must be a string.</em><br/><em class="mh">    ------------------------------------</em><br/><em class="mh">    Generates a JSON file for each day scraped.</em><br/><em class="mh">    """</em><br/>    dates_year = [str(date)[:10] for date in pd.date_range(start=f'1/1/{year}', end=f'12/31/{year}')]<br/>    for i in range(len(dates_year)):<br/>        begin_date = dates_year[i]<br/>        if i == len(dates_year)-1:<br/>            end_date = f'{year+1}-01-01'<br/>        else:<br/>            end_date = dates_year[i+1]<br/>        day = dates_year[i]<br/>        cmd = 'twitterscraper "{}" -l {} -o t{}.json -bd {} -ed {} --lang en'.format(query, num_tweets, day, begin_date, end_date)<br/>        subprocess.run(cmd)<br/>        if (i+1)%5 == 0:<br/>            print(f"finished scraping {i+1} days of {year}")<br/>    print("SCRAPING PROCESS COMPLETE!")<br/>    pass</span></pre><p id="1330" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">使用 alphavantage.co 的 API 搜集财务数据也相当容易，尽管这些数据需要一些额外的条件使其更有用。</p><pre class="ls lt lu lv gt lw lx ly lz aw ma bi"><span id="c5e1" class="mb kq it lx b gy mc md l me mf"><strong class="lx iu">import</strong> requests<br/><strong class="lx iu">import</strong> matplotlib.pyplot <strong class="lx iu">as</strong> plt<br/>plt.style.use('ggplot')<br/>%matplotlib inline</span><span id="d2d3" class="mb kq it lx b gy mg md l me mf">def get_financial_data(symbol, stocks_apikey, column="close_24", year=2018, verbose=True):<br/>    <em class="mh">"""Inputs:</em><br/><em class="mh">    symbol         (string) Stock or Currency symbol</em><br/><em class="mh">    stocks_apikey  (string) your API key for </em><br/><em class="mh">                      https://www.alphavantage.co<br/>    column         (string) column of output to use for plotting<br/>    year           (int) the year you wish to examine</em><br/><em class="mh">    =========================================</em><br/><em class="mh">    Returns a DataFrame of daily financial information containing</em><br/><em class="mh">    at least opening, closing, high, and low values.</em><br/><em class="mh">    """</em><br/>    valid_types = ['stock','index','currency','cryptocurrency']<br/>    credentials = {'function':'TIME_SERIES_DAILY',<br/>                       'symbol':symbol,<br/>                       'outputsize':'full',<br/>                       'apikey':stocks_apikey}<br/>    r = requests.get('https://www.alphavantage.co/query', params=credentials)<br/>    df = pd.DataFrame(r.json()["Time Series (Daily)"])<br/>    df = df.T.reset_index()<br/>    df.columns = ['date','open','high','low','close','volume']<br/>    df.date = pd.to_datetime(df.date)<br/>    df[['open','high','low','close','volume']] = df[['open',<br/>            'high','low','close','volume']].astype(float)</span><span id="6e48" class="mb kq it lx b gy mg md l me mf"><em class="mh">    # create a new column to account for after-hours trading</em><br/>    <em class="mh"># uses the next day's open value as the prior day's close value</em><br/>    cl24 = [df.loc[0].close]<br/>    for val in df.open.values:<br/>        cl24.append(val)<br/>    cl24 = pd.DataFrame(cl24[:-1], columns=['close_24'])<br/>    df = df.join(cl24)<br/>   <em class="mh"># now account for after-hours trading exceeding high/low values</em><br/>    df['high_24'] = df[['high', 'close_24']].values.max(1)<br/>    df['low_24'] = df[['low', 'close_24']].values.min(1)<br/>    df['range'] = df['high'] - df['low']<br/>    df['range_24'] = df['high_24'] - df['low_24']<br/>    df['change_24'] = df['close_24'] - df['open']<br/>    df.set_index('date', inplace=True)<br/>    year_df = df[f'{year}':f'{year}']    <em class="mh"># getting 1 year's data</em></span><span id="4b7e" class="mb kq it lx b gy mg md l me mf"><em class="mh">    # plotting the results<br/>    </em>plt.figure(figsize=(15,5))<br/>    plt.plot(df[column], label=column)<br/>    plt.title(f"{symbol} Daily Performance for {year}", fontsize=16)<br/>    plt.ylabel("Price (in USD)", fontsize=14)<br/>    plt.legend(loc='best', borderpad=1, fontsize=14);<br/>    return df</span></pre><p id="1b7f" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">有了数据集，下一步是确定我们收集的所有推文的总体情绪。为此，<a class="ae ko" href="https://textblob.readthedocs.io/en/dev/" rel="noopener ugc nofollow" target="_blank"> TextBlob </a>库非常有用。TextBlob 可以快速解析文本以确定文本本质上通常是正面的还是负面的。我选择扩展“中性”极性值，以包含从-0.1 到 0.1 的所有极性分数，从而消除+/-类别中的一些噪声。</p><pre class="ls lt lu lv gt lw lx ly lz aw ma bi"><span id="cb2e" class="mb kq it lx b gy mc md l me mf"><strong class="lx iu">from</strong> <strong class="lx iu">textblob</strong> <strong class="lx iu">import</strong> <strong class="lx iu">TextBlob</strong></span><span id="4dc7" class="mb kq it lx b gy mg md l me mf">def get_tweet_sentiment(tweet): <br/>    analysis = TextBlob(tweet)<br/>    polarity = analysis.sentiment.polarity<br/>    subjectivity = analysis.sentiment.subjectivity<br/>    if analysis.sentiment.polarity &gt; 0.1: <br/>        sentiment = 'positive'<br/>    elif analysis.sentiment.polarity &lt; -0.1: <br/>        sentiment = 'negative'<br/>    else: <br/>        sentiment = 'neutral'<br/>    return sentiment, polarity, subjectivity</span></pre><p id="75eb" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">在所有这些处理之后，我最终可以使用 statmodels 的<code class="fe mi mj mk lx b"><a class="ae ko" href="https://www.statsmodels.org/stable/generated/statsmodels.tsa.seasonal.seasonal_decompose.html" rel="noopener ugc nofollow" target="_blank">seasonal_decompose</a></code>方法来确定收集到的 Twitter 数据中是否存在任何季节性。你瞧，事实证明<strong class="js iu"> <em class="mh">是</em></strong>7.4 和 29.5 天的季节性，这与月亮周期完全吻合。</p><figure class="ls lt lu lv gt mm gh gi paragraph-image"><div role="button" tabindex="0" class="mn mo di mp bf mq"><div class="gh gi ml"><img src="../Images/49b35c6e147e3bcefb43675709370d7e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*FPcRJwWx_0UrB5-DTXs-IA.jpeg"/></div></div><figcaption class="mt mu gj gh gi mv mw bd b be z dk">Seasonal Decomposition of scraped tweets</figcaption></figure><h1 id="59d2" class="kp kq it bd kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm bi translated">和脸书先知一起做模特</h1><p id="f87c" class="pw-post-body-paragraph jq jr it js b jt ln jv jw jx lo jz ka kb lp kd ke kf lq kh ki kj lr kl km kn im bi translated"><a class="ae ko" href="https://facebook.github.io/prophet/" rel="noopener ugc nofollow" target="_blank">脸书预言家</a>，虽然很新，却是一个非常强大的适应性建模工具。幸运的是，<code class="fe mi mj mk lx b">Prophet()</code>包含一个名为<code class="fe mi mj mk lx b">holidays=</code>的参数，它允许用户输入一个格式正确的数据帧，FBProphet 会特别注意这个数据帧。其中，该功能模拟了<code class="fe mi mj mk lx b">holidays</code>对所研究的时间序列的季节性影响。在下图中，满月发生在 1 月 2-3 日，2 月 1 日，3 月 1-2 日，等等。</p><pre class="ls lt lu lv gt lw lx ly lz aw ma bi"><span id="6636" class="mb kq it lx b gy mc md l me mf"><strong class="lx iu"># `phases` was a pre-generated DataFrame of lunar phase dates</strong></span><span id="9696" class="mb kq it lx b gy mg md l me mf"><strong class="lx iu">from</strong> fbprophet <strong class="lx iu">import</strong> Prophet<br/><strong class="lx iu">from</strong> fbprophet.plot <strong class="lx iu">import</strong> plot_plotly, plot_cross_validation_metric<br/><strong class="lx iu">from</strong> fbprophet.diagnostics <strong class="lx iu">import</strong> cross_validation, performance_metrics</span><span id="1ca4" class="mb kq it lx b gy mg md l me mf"><em class="mh">#to maintain pd.plotting functionality<br/></em>pd.plotting.register_matplotlib_converters()</span><span id="29f5" class="mb kq it lx b gy mg md l me mf">def tweet_fbprophet(filename=''):<br/>    tweets_df = pd.read_csv(filename)<br/>    tweets_df.timestamp = pd.to_datetime(tw_df.timestamp, format='%Y%m%d')<br/>    grouped = pd.DataFrame(tweets_df.groupby(['timestamp', 'sentiment'])['tally'].sum()).reset_index()<br/><br/>    <em class="mh">#prepare grouped sentiment data for FBProphet processing</em><br/>    <em class="mh">#here, positive sentiment only</em><br/>    grp_pos = grouped[grouped.sentiment == 'positive'].drop('sentiment', axis=1).reset_index(drop=True)<br/>    grp_pos.columns = ['ds','y']<br/><br/>    m = Prophet(holidays=phases)<br/>    m.fit(grp_pos)<br/>    future = m.make_future_dataframe(periods=60, freq='D')<br/>    forecast = m.predict(future)<br/>    forecast[(forecast['fullmoon'] + forecast['lastquarter'] + <br/>             forecast['newmoon'] + forecast['firstquarter']).abs() &gt; <br/>             0][['ds', 'fullmoon', 'lastquarter', 'newmoon', 'firstquarter']][:10]<br/>    fig1 = m.plot(forecast);<br/>    fig1.set_size_inches(15, 5)<br/>    plt.show();<br/>    fig2 = m.plot_components(forecast)<br/>    fig2.set_size_inches(15, 10)<br/>    plt.show();<br/>    return m</span></pre><figure class="ls lt lu lv gt mm gh gi paragraph-image"><div role="button" tabindex="0" class="mn mo di mp bf mq"><div class="gh gi mx"><img src="../Images/c3079440073580267244efa63bdb5739.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*vIGwyJjpWI-rdMdl0fo4bQ.png"/></div></div><figcaption class="mt mu gj gh gi mv mw bd b be z dk">Example of seasonality effect of lunar cycles found in tweets using FBProphet</figcaption></figure><p id="ad3c" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">FBProphet 的另一个好处是种类繁多的<code class="fe mi mj mk lx b">performance_metrics</code>，很容易访问。我选择研究 RMSE(均方根误差),因为它很容易用原始数据集的单位来解释。实际上，在所有情况下，(推特和金融数据)RMSE 平均比月球周期的季节性影响高出 50%。虽然从纯预测的角度来看这并不太好，但需要注意的是，该项目的目标是确定是否存在相关性，而不是创建一个可以准确预测 twitter 情绪或股票价格的模型...这需要太多的额外变量。下面是性能指标的示例表和不同时间跨度的 RMSE 图。</p><figure class="ls lt lu lv gt mm gh gi paragraph-image"><div role="button" tabindex="0" class="mn mo di mp bf mq"><div class="gh gi my"><img src="../Images/6174333af83f56ac7452debdf65da747.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*12MOY_5Qt7umNJK68OYNBg.png"/></div></div><figcaption class="mt mu gj gh gi mv mw bd b be z dk">RMSE plot from FBProphet cross-validation method</figcaption></figure><p id="b9c1" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">随着 Twitter 阴历季节性的确立，我对财务数据运行了同样的 FBProphet 程序。该数据还显示了与月亮周期相关的明显的季节性。然而，对于每个金融对象，相关性并不相同。一些股票/货币在满月时上涨，而另一些在满月时下跌。此外，似乎许多月相都有一个初始峰值，然后在第二天出现相应的修正(甚至过度修正)。例如，比较下面为比特币和微软生成的农历季节性图表。</p><figure class="ls lt lu lv gt mm gh gi paragraph-image"><div role="button" tabindex="0" class="mn mo di mp bf mq"><div class="gh gi mz"><img src="../Images/c84c4538b6df7ab6bf0d6601457415f2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*tM9fZQagSrjlNJvfF1zjIQ.png"/></div></div><figcaption class="mt mu gj gh gi mv mw bd b be z dk">Lunar seasonality comparison of BTC and MSFT (Microsoft does not trade on weekends, hence the gaps)</figcaption></figure><h1 id="dbc6" class="kp kq it bd kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm bi translated">寻找信息的视觉化</h1><p id="31aa" class="pw-post-body-paragraph jq jr it js b jt ln jv jw jx lo jz ka kb lp kd ke kf lq kh ki kj lr kl km kn im bi translated">最初，我认为生成单词云可能是从我的数据中提取更多信息的一种好方法。毕竟，单词云可以在视觉上提供大量信息，而其他图形则不能(因为它们缺乏单词云的莫邪)。不幸的是，由于我正在处理的语料库的规模(每个关键词搜索大约 5-6，000，000 个单词)，使用极其简单的<a class="ae ko" href="http://amueller.github.io/word_cloud/" rel="noopener ugc nofollow" target="_blank"> wordcloud </a>库被证明是不切实际的，因为执行时间延长到 10 多个小时。然而，这是我一次运行这个过程的代码和图表。</p><pre class="ls lt lu lv gt lw lx ly lz aw ma bi"><span id="eb4f" class="mb kq it lx b gy mc md l me mf"><strong class="lx iu">from </strong>wordcloud <strong class="lx iu">import</strong> WordCloud<br/><strong class="lx iu">from </strong>sklearn.feature_extraction.stop_words<strong class="lx iu"> import</strong> ENGLISH_STOP_WORDS</span><span id="bd63" class="mb kq it lx b gy mg md l me mf">df = pd.read_csv('tweets.csv')<br/>df.timestamp = pd.to_datetime(df.timestamp, format='%Y%m%d')  <br/>comment_words = ' '<br/>stopwords = set(ENGLISH_STOP_WORDS)<br/>stopwords.update(['com','ve','ll','just','don','really','00'])</span><span id="a15f" class="mb kq it lx b gy mg md l me mf"><em class="mh"># </em><strong class="lx iu"><em class="mh">this for loop took hours to run</em></strong><em class="mh"> </em><br/>it = 0<br/>for val in df.text: <br/>    val = str(val)          <em class="mh"># typecaste each val to string</em> <br/>    tokens = val.split()    <em class="mh"># split the value </em><br/>    for i in range(len(tokens)): <br/>        tokens[i] = tokens[i].lower() <em class="mh"># Convert tokens to lowercase</em><br/>    for words in tokens: <br/>        comment_words = comment_words + words + ' '<br/>    it += 1<br/>    if (it)%10 == 0:<br/>        print(f"Completed {i} of {len(df.text)} loops")<br/>   <br/><em class="mh"># generate the word cloud</em><br/>wordcloud = WordCloud(width = 1200, height = 1200, <br/>                background_color ='white', <br/>                stopwords = stopwords, <br/>                min_font_size = 10).generate(comment_words)</span><span id="f27c" class="mb kq it lx b gy mg md l me mf"><em class="mh"># plot &amp; save the WordCloud image  </em>                      <br/>plt.figure(figsize = (20, 20), facecolor = None) <br/>plt.imshow(wordcloud) <br/>plt.axis("off") <br/>plt.tight_layout(pad = 0) <br/>plt.savefig('images/tweets_wordcloud.png')</span></pre><figure class="ls lt lu lv gt mm gh gi paragraph-image"><div role="button" tabindex="0" class="mn mo di mp bf mq"><div class="gh gi na"><img src="../Images/760bf376f579635037199efb9e0ff974.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Lk6eV5rAkJMIVpLh8FsPfw.png"/></div></div><figcaption class="mt mu gj gh gi mv mw bd b be z dk">Word cloud for the search “love OR hate OR peace OR war”</figcaption></figure><p id="facd" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">通过在一个查询语料库中比较正面/负面/中性，或者将一个语料库与另一个语料库进行比较，可以进行快速和简单的可视化来绘制每个搜索短语的情绪的每日变化。</p><figure class="ls lt lu lv gt mm gh gi paragraph-image"><div role="button" tabindex="0" class="mn mo di mp bf mq"><div class="gh gi nb"><img src="../Images/2d96e77a69dc4529f465d1d299e5a55f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*jA81hHELIyekRPJprwZRog.png"/></div></div><figcaption class="mt mu gj gh gi mv mw bd b be z dk">Unsurprisingly, tweeters had the least positive things to say regarding politics.</figcaption></figure><figure class="ls lt lu lv gt mm gh gi paragraph-image"><div role="button" tabindex="0" class="mn mo di mp bf mq"><div class="gh gi nc"><img src="../Images/70f0b341b6394dbcb679f84720dc9697.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*fXeru2TBDoko3lYRPQqdWg.png"/></div></div><figcaption class="mt mu gj gh gi mv mw bd b be z dk">Daily sentiment of Tweets with no search phrase given</figcaption></figure><p id="521b" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">一个更简单的方法是创建一个单词包，只过滤出现次数最多的第 n 个 T2，然后绘制一个直方图。这种简单的方法，当与日期过滤器结合使用来区分月相日期和非月相日期时，会为每个搜索短语产生一些有趣的结果(见下面的例子)。虽然没有出现什么过分令人担忧的情况，但有趣的是看到词频的顺序是如何根据月相变化的。</p><figure class="ls lt lu lv gt mm gh gi paragraph-image"><div role="button" tabindex="0" class="mn mo di mp bf mq"><div class="gh gi nd"><img src="../Images/0c1a268d010ef53ff526431bc226c4cc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ssNM9zxuFO0uBdRkMcfHdA.png"/></div></div><figcaption class="mt mu gj gh gi mv mw bd b be z dk">Comparison of most common words when no search phrase was entered</figcaption></figure><p id="552a" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">最后，也可能是我最喜欢的，是利用<a class="ae ko" href="https://github.com/JasonKessler/scattertext" rel="noopener ugc nofollow" target="_blank">散点图</a>库来制作一个漂亮的、交互式的、可搜索的 Twitter 数据图表。这个库实际上生成一个 HTML 文件来显示图表，对于像我这样大的语料库，每个 HTML 文件平均 30MB，这导致 web 浏览器的加载时间大约为 5-10 分钟。该库是为中小型数据集设计的，不是我的怪物，但结果仍然值得等待。可视化是交互式的(鼠标悬停在每个数据点上，会出现一个信息提示),并且是可关键字搜索的。最重要的是，选择一个关键字还会在图表下方显示该词的大量分类(肯定/否定)出现，以了解它在每个场景中的常用情况。我可以立即看到，这个图书馆有很大的潜力，有利于学术研究人员，特别是在文学，历史，政治学等领域。这里有一个<a class="ae ko" href="https://nbviewer.jupyter.org/github/magnawhale/capstone_project/blob/master/Scattertext_nowords_example.html" rel="noopener ugc nofollow" target="_blank">精简后的例子</a>，应该可以快速加载，还有一个下面功能的. gif 文件。</p><figure class="ls lt lu lv gt mm gh gi paragraph-image"><div role="button" tabindex="0" class="mn mo di mp bf mq"><div class="gh gi ne"><img src="../Images/f48e2405a336732777a0451c9739b15f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/1*XEBuZdxx3_2MTVayrCL4Bw.gif"/></div></div></figure><p id="c715" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">以下是我用于散文本的代码。</p><pre class="ls lt lu lv gt lw lx ly lz aw ma bi"><span id="9cd8" class="mb kq it lx b gy mc md l me mf"><em class="mh">!pip install scattertext<br/>!pip install spacy<br/>!python -m spacy download en_core_web_sm<br/></em><strong class="lx iu">import</strong> scattertext <strong class="lx iu">as</strong> st<br/><strong class="lx iu">import</strong> pandas <strong class="lx iu">as</strong> pd<br/><strong class="lx iu">import</strong> numpy <strong class="lx iu">as</strong> np<strong class="lx iu"><br/>import</strong> spacy<br/><strong class="lx iu">import</strong> en_core_web_sm</span><span id="9fa5" class="mb kq it lx b gy mg md l me mf">df = pd.read_csv('tweets.csv')<br/>df.timestamp = pd.to_datetime(df.timestamp, format='%Y%m%d')  <br/>df = df[df['sentiment'].isin(['positive','negative'])]</span><span id="c460" class="mb kq it lx b gy mg md l me mf"><em class="mh"># Turn DataFrame into a Scattertext Corpus</em><br/>nlp = en_core_web_sm.load()<br/>corpus = st.CorpusFromPandas(data_frame=df,<br/>                             category_col='sentiment',<br/>                             text_col='text',<br/>                             nlp=nlp).build()</span><span id="2bb5" class="mb kq it lx b gy mg md l me mf"><em class="mh"># Create an HTML page for the interactive visualization</em><br/>html = st.produce_scattertext_explorer(corpus,<br/>    category='positive',<br/>    category_name='Positive',<br/>    not_category_name='Negative',<br/>    minimum_term_frequency=25,   <em class="mh">### high values reduce load time</em><br/>    minimum_not_category_term_frequency=25,  <em class="mh">### high values reduce load time</em><br/>    max_terms=5000,   <em class="mh">### aim for at least 1000 for a pretty graph</em><br/>    max_snippets=50,<br/>    show_characteristic=True,<br/>    width_in_pixels=1000)</span><span id="d4f8" class="mb kq it lx b gy mg md l me mf">open("tweet_scattertext".html", 'wb').write(html.encode('utf-8'))</span></pre><h1 id="1348" class="kp kq it bd kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm bi translated">最终想法和建议</h1><p id="514b" class="pw-post-body-paragraph jq jr it js b jt ln jv jw jx lo jz ka kb lp kd ke kf lq kh ki kj lr kl km kn im bi translated">基于我的分析，似乎相当清楚的是，事实上人类行为和月相之间存在关联。然而，这必须留给未来的研究人员来确定这种相关性的本质和原因。这种影响相对较小，但仍然存在。就推文中的整体情绪而言，满月和上弦月似乎与积极情绪的增加相关，而新月和上弦月与消极情绪的增加相关。</p><p id="52e2" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">金融市场也表现出月球季节性，包括股票、市场指数、货币和加密货币。然而，这种相关性并不是全面一致的；一些股票与满月正相关，其他的负相关。此外，大多数股票/货币在月相数据中表现出在一个方向上飙升的强烈趋势，然后在第二天立即在相反方向上修正(或过度修正)。任何试图使用这一信息的人都必须在个案的基础上检查季节性。尽管相关性很小(季节性占价格变化的大约 1%)，我怀疑从事算法交易的新兴实践的投资者将能够从将月球季节性纳入他们的投资算法中获利。</p></div></div>    
</body>
</html>