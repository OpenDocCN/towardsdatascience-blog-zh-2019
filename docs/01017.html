<html>
<head>
<title>Handwritten Digit Recognition Using PyTorch — Intro To Neural Networks</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用 PyTorch 的手写数字识别——神经网络介绍</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/handwritten-digit-mnist-pytorch-977b5338e627?source=collection_archive---------1-----------------------#2019-02-17">https://towardsdatascience.com/handwritten-digit-mnist-pytorch-977b5338e627?source=collection_archive---------1-----------------------#2019-02-17</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><figure class="gl gn jo jp jq jr gh gi paragraph-image"><div class="gh gi jn"><img src="../Images/b52c25bf3920afad2c3f3effb5f0f239.png" data-original-src="https://miro.medium.com/v2/resize:fit:282/format:webp/1*xpszL7jJrV5UTV7Xa-fgWQ.png"/></div></figure><p id="b567" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi ks translated">对吗？——弄清楚上面的图片代表数字<strong class="jw ir">四</strong>，对你来说没什么。你甚至没有为图像的分辨率差而烦恼，多神奇啊。我们都应该花点时间感谢我们的<em class="lb">大脑</em>！我想知道我们的大脑对图像进行处理、分类和反馈是多么自然。我们是天才！</p><p id="f5f3" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">模仿人脑会有多难？深度学习，<em class="lb">简单来说，</em>是机器学习研究的领域，它允许计算机学习执行大脑自然的任务，如手写数字识别。从技术上来说，它涉及更多的<em class="lb">层</em>(我们后面会讲到)和更多的<em class="lb">数据</em>。</p><p id="6328" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">在本文中，我们将讨论神经网络，并从头开始开发一个手写数字分类器。我们将使用<strong class="jw ir"> <em class="lb"> PyTorch </em> </strong>因为它<em class="lb">很酷</em>！</p><figure class="ld le lf lg gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="lh li di lj bf lk"><div class="gh gi lc"><img src="../Images/c8be38bc46d6930cdef9be2027729051.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*jlxdirCP5Qre1pcoNC-7JQ.png"/></div></div></figure><p id="f8cd" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">本文的唯一先决条件是 Python 语法的基础知识。坐下来，喝杯咖啡，跟着我走。</p><figure class="ld le lf lg gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="lh li di lj bf lk"><div class="gh gi ll"><img src="../Images/316dcd3124e39577f7bfce2b88aeed19.png" data-original-src="https://miro.medium.com/v2/resize:fit:852/1*CEz3o545anOnLGXaOIO3SQ.gif"/></div></div><figcaption class="lm ln gj gh gi lo lp bd b be z dk">Only Good Coffee Please!</figcaption></figure><h2 id="7507" class="lq lr iq bd ls lt lu dn lv lw lx dp ly kf lz ma mb kj mc md me kn mf mg mh mi bi translated">步骤 1 —了解数据集</h2><p id="8a7c" class="pw-post-body-paragraph ju jv iq jw b jx mj jz ka kb mk kd ke kf ml kh ki kj mm kl km kn mn kp kq kr ij bi translated">作为数据科学家，最重要的任务是收集完美的数据集，并彻底理解它。相信我，剩下的就简单多了。对于这个项目，我们将使用流行的<a class="ae mo" href="https://en.wikipedia.org/wiki/MNIST_database" rel="noopener ugc nofollow" target="_blank"> MNIST 数据库</a>。它是 70000 个手写数字的集合，分为分别由 60000 个和 10000 个图像组成的训练集和测试集。</p><figure class="ld le lf lg gt jr gh gi paragraph-image"><div class="gh gi mp"><img src="../Images/e7620493a3de60425cfd89c7d99be1f0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1188/format:webp/1*Ft2rLuO82eItlvJn5HOi9A.png"/></div><figcaption class="lm ln gj gh gi lo lp bd b be z dk">Source: Wikimedia</figcaption></figure><p id="8ec2" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">该数据集最初可在 Yann Lecun 的网站上获得。清理数据是最大的任务之一。别忘了— <strong class="jw ir"> <em class="lb">“垃圾进，垃圾出！”</em> </strong>。幸运的是，对我们来说，PyTorch 提供了一个简单的实现，使用几行代码就可以下载干净的和已经准备好的数据。在开始之前，我们需要做所有必要的进口。</p><pre class="ld le lf lg gt mq mr ms mt aw mu bi"><span id="49d6" class="lq lr iq mr b gy mv mw l mx my">import numpy as np<br/>import torch<br/>import torchvision<br/>import matplotlib.pyplot as plt<br/>from time import time<br/>from torchvision import datasets, transforms<br/>from torch import nn, optim</span></pre><p id="f2ce" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">在下载数据之前，让我们定义在将数据输入管道之前，我们希望对数据执行哪些转换。换句话说，您可以将它视为对图像执行的某种自定义编辑，以便所有图像都具有相同的尺寸和属性。我们使用<strong class="jw ir"> torchvision.transforms </strong>来实现。</p><pre class="ld le lf lg gt mq mr ms mt aw mu bi"><span id="b787" class="lq lr iq mr b gy mv mw l mx my">transform = transforms.Compose([transforms.ToTensor(),<br/>                              transforms.Normalize((0.5,), (0.5,)),<br/>                              ])</span></pre><ol class=""><li id="5769" class="mz na iq jw b jx jy kb kc kf nb kj nc kn nd kr ne nf ng nh bi translated"><strong class="jw ir"> <em class="lb">摇身一变。ToTensor() </em> </strong> —将图像转换成系统可理解的数字。它将图像分成三个颜色通道(单独的图像):<em class="lb">红色、绿色&amp;蓝色</em>。然后，它将每个图像的像素转换为其颜色在 0 到 255 之间的亮度。然后将这些值缩小到 0 到 1 之间的范围。图像现在是一个<a class="ae mo" href="https://pytorch.org/docs/stable/tensors.html" rel="noopener ugc nofollow" target="_blank">火炬张量</a>。</li><li id="3392" class="mz na iq jw b jx ni kb nj kf nk kj nl kn nm kr ne nf ng nh bi translated"><strong class="jw ir"> <em class="lb">变换变换。Normalize() </em></strong></li></ol><p id="2fdc" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">现在，我们终于下载了数据集，对它们进行了洗牌和转换。我们下载数据集并将它们加载到<em class="lb"> DataLoader </em>，它将数据集和采样器结合在一起，并在数据集上提供单进程或多进程迭代器。</p><pre class="ld le lf lg gt mq mr ms mt aw mu bi"><span id="14bb" class="lq lr iq mr b gy mv mw l mx my">trainset = datasets.MNIST('PATH_TO_STORE_TRAINSET', download=<strong class="mr ir">True</strong>, train=<strong class="mr ir">True</strong>, transform=transform)</span><span id="dd85" class="lq lr iq mr b gy nn mw l mx my">valset = datasets.MNIST('PATH_TO_STORE_TESTSET', download=<strong class="mr ir">True</strong>, train=<strong class="mr ir">False</strong>, transform=transform)</span><span id="f0d9" class="lq lr iq mr b gy nn mw l mx my">trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=<strong class="mr ir">True</strong>)</span><span id="3d62" class="lq lr iq mr b gy nn mw l mx my">valloader = torch.utils.data.DataLoader(valset, batch_size=64, shuffle=<strong class="mr ir">True</strong>)</span></pre><p id="3e5e" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">在一行中，<em class="lb">批量大小</em>是我们想要一次读取的图像数量。</p><h2 id="e41b" class="lq lr iq bd ls lt lu dn lv lw lx dp ly kf lz ma mb kj mc md me kn mf mg mh mi bi translated">步骤 2-更好地了解数据集</h2><p id="6f91" class="pw-post-body-paragraph ju jv iq jw b jx mj jz ka kb mk kd ke kf ml kh ki kj mm kl km kn mn kp kq kr ij bi translated">在这个阶段，我们将对我们的图像和张量进行一些探索性的数据分析。让我们检查一下图像和标签的形状。</p><pre class="ld le lf lg gt mq mr ms mt aw mu bi"><span id="1ccc" class="lq lr iq mr b gy mv mw l mx my">dataiter = iter(trainloader)<br/>images, labels = dataiter.next()<br/><br/>print(images.shape)<br/>print(labels.shape)</span></pre><p id="6001" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">您将发现图像的形状是，<code class="fe no np nq mr b">torch.Size([64,1,28,28])</code>，这表明每批中有 64 个图像，每个图像的尺寸为 28 x 28 像素。类似地，标签的形状为<code class="fe no np nq mr b">torch.Size([64])</code>。猜猜为什么？—是的，你说得对！64 张图片应该分别有 64 个标签。就是这样。轻松点。</p><figure class="ld le lf lg gt jr gh gi paragraph-image"><div class="gh gi nr"><img src="../Images/9cb431bf437dd0092708a0f24ea1ff57.png" data-original-src="https://miro.medium.com/v2/resize:fit:800/1*GqGSw_G4bzRSlU1SlPfpKg.gif"/></div></figure><p id="7ae9" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">让我们显示训练集中的一幅图像，例如第一幅。</p><pre class="ld le lf lg gt mq mr ms mt aw mu bi"><span id="369f" class="lq lr iq mr b gy mv mw l mx my">plt.imshow(images[0].numpy().squeeze(), cmap='gray_r');</span></pre><p id="2e5e" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">酷吧！让我们展示更多的图像，这将让我们感受一下数据集的样子。</p><pre class="ld le lf lg gt mq mr ms mt aw mu bi"><span id="79c5" class="lq lr iq mr b gy mv mw l mx my">figure = plt.figure()<br/>num_of_images = 60<br/><strong class="mr ir">for</strong> index <strong class="mr ir">in</strong> range(1, num_of_images + 1):<br/>    plt.subplot(6, 10, index)<br/>    plt.axis('off')<br/>    plt.imshow(images[index].numpy().squeeze(), cmap='gray_r')</span></pre><p id="5248" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">这将生成一个随机排列的图像网格。现在，是时候开始定义我们将要使用的神经网络了。</p><h2 id="ca4e" class="lq lr iq bd ls lt lu dn lv lw lx dp ly kf lz ma mb kj mc md me kn mf mg mh mi bi translated">步骤 3——建立神经网络</h2><p id="ea07" class="pw-post-body-paragraph ju jv iq jw b jx mj jz ka kb mk kd ke kf ml kh ki kj mm kl km kn mn kp kq kr ij bi translated">我们将构建下面的网络，正如你所看到的，它包含一个输入层(第一层)，一个由十个<em class="lb">神经元</em>(或单元，圆圈)组成的输出层，以及中间的两个隐藏层。</p><figure class="ld le lf lg gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="lh li di lj bf lk"><div class="gh gi ns"><img src="../Images/04cd3c8c6424a8cb8cf065a0c5a5812c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*HWhBextdDSkxYvz0kEMTVg.png"/></div></div></figure><p id="8c68" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">PyTorch 的<code class="fe no np nq mr b">torch.nn</code>模块允许我们非常简单地构建上述网络。这也非常容易理解。看看下面的代码。</p><pre class="ld le lf lg gt mq mr ms mt aw mu bi"><span id="1b97" class="lq lr iq mr b gy mv mw l mx my">input_size = 784<br/>hidden_sizes = [128, 64]<br/>output_size = 10<br/><br/>model = nn.Sequential(nn.Linear(input_size, hidden_sizes[0]),<br/>                      nn.ReLU(),<br/>                      nn.Linear(hidden_sizes[0], hidden_sizes[1]),<br/>                      nn.ReLU(),<br/>                      nn.Linear(hidden_sizes[1], output_size),<br/>                      nn.LogSoftmax(dim=1))<br/>print(model)</span></pre><p id="48b6" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated"><code class="fe no np nq mr b">nn.Sequential</code>包裹网络中的层。有三个带<strong class="jw ir"> ReLU 激活</strong>的<strong class="jw ir">线性层</strong>(一个允许正值通过的简单函数，而负值被修改为零)。输出图层是激活了<a class="ae mo" href="https://pytorch.org/docs/stable/nn.html#logsoftmax" rel="noopener ugc nofollow" target="_blank"> <strong class="jw ir"> LogSoftmax </strong> </a>的线性图层，因为这是一个分类问题。</p><p id="1f2e" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">从技术上来说，一个 LogSoftmax 函数是一个<strong class="jw ir"> Softmax </strong>函数的对数，顾名思义，它看起来像这样，如下所示。</p><figure class="ld le lf lg gt jr gh gi paragraph-image"><div class="gh gi nt"><img src="../Images/705b8ba471b43ad9a867339cb10df9f1.png" data-original-src="https://miro.medium.com/v2/resize:fit:666/format:webp/1*b3-oeEsJvbosyuZbo1FP8Q.png"/></div></figure><p id="5e77" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">接下来，我们定义<a class="ae mo" href="https://pytorch.org/docs/stable/nn.html#nllloss" rel="noopener ugc nofollow" target="_blank"> <strong class="jw ir">负对数似然损失</strong> </a>。用 C 类训练一个分类问题很有用。<strong class="jw ir"> LogSoftmax() </strong>和<strong class="jw ir"> NLLLoss() </strong>一起充当交叉熵损失，如上面的网络架构图所示。</p><p id="f2b5" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">另外，你一定想知道为什么我们在第一层有 784 个单元。很好！这是因为我们在将每幅图像发送到神经网络之前将其展平。<em class="lb"> (28 x 28 = 784) </em></p><pre class="ld le lf lg gt mq mr ms mt aw mu bi"><span id="ff0c" class="lq lr iq mr b gy mv mw l mx my">criterion = nn.NLLLoss()<br/>images, labels = next(iter(trainloader))<br/>images = images.view(images.shape[0], -1)<br/><br/>logps = model(images) #log probabilities<br/>loss = criterion(logps, labels) #calculate the NLL loss</span></pre><p id="5feb" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">我们将在以后的文章中讨论更多的神经网络，激活函数，优化算法等。</p><p id="6e25" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated"><strong class="jw ir">步骤 4 —调整重量</strong></p><p id="8520" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">神经网络<em class="lb">通过对可用数据进行多次迭代来学习</em>。<strong class="jw ir"> <em class="lb">学习</em> </strong>是指调整网络的权值，使损耗最小。让我们想象一下它是如何工作的。</p><pre class="ld le lf lg gt mq mr ms mt aw mu bi"><span id="28ca" class="lq lr iq mr b gy mv mw l mx my">print('Before backward pass: <strong class="mr ir">\n</strong>', model[0].weight.grad)<br/>loss.backward()<br/>print('After backward pass: <strong class="mr ir">\n</strong>', model[0].weight.grad)</span></pre><p id="844e" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">在向后传递之前，模型权重被设置为默认的<strong class="jw ir">无</strong>值。一次，我们调用<strong class="jw ir"> backward() </strong>函数来更新权重。</p><pre class="ld le lf lg gt mq mr ms mt aw mu bi"><span id="ac25" class="lq lr iq mr b gy mv mw l mx my">Before backward pass: <br/> None<br/>After backward pass: <br/> tensor([[-0.0003, -0.0003, -0.0003,  ..., -0.0003, -0.0003, -0.0003],<br/>        [ 0.0008,  0.0008,  0.0008,  ...,  0.0008,  0.0008,  0.0008],<br/>        [-0.0037, -0.0037, -0.0037,  ..., -0.0037, -0.0037, -0.0037],<br/>        ...,<br/>        [-0.0005, -0.0005, -0.0005,  ..., -0.0005, -0.0005, -0.0005],<br/>        [ 0.0043,  0.0043,  0.0043,  ...,  0.0043,  0.0043,  0.0043],<br/>        [-0.0006, -0.0006, -0.0006,  ..., -0.0006, -0.0006, -0.0006]])</span></pre><h2 id="684f" class="lq lr iq bd ls lt lu dn lv lw lx dp ly kf lz ma mb kj mc md me kn mf mg mh mi bi translated">步骤 5 —核心培训流程</h2><p id="8890" class="pw-post-body-paragraph ju jv iq jw b jx mj jz ka kb mk kd ke kf ml kh ki kj mm kl km kn mn kp kq kr ij bi translated">这是真正的奇迹发生的地方。您的神经网络迭代训练集并更新权重。我们使用 PyTorch 提供的模块<code class="fe no np nq mr b">torch.optim</code>来优化模型，执行梯度下降，并通过反向传播来更新权重。因此，在每个<strong class="jw ir">时期</strong>(我们迭代训练集的次数)，我们将看到训练损失逐渐减少。</p><pre class="ld le lf lg gt mq mr ms mt aw mu bi"><span id="2f9d" class="lq lr iq mr b gy mv mw l mx my">optimizer = optim.SGD(model.parameters(), lr=0.003, momentum=0.9)<br/>time0 = time()<br/>epochs = 15<br/><strong class="mr ir">for</strong> e <strong class="mr ir">in</strong> range(epochs):<br/>    running_loss = 0<br/>    <strong class="mr ir">for</strong> images, labels <strong class="mr ir">in</strong> trainloader:<br/>        <em class="lb"># Flatten MNIST images into a 784 long vector</em><br/>        images = images.view(images.shape[0], -1)<br/>    <br/>        <em class="lb"># Training pass</em><br/>        optimizer.zero_grad()<br/>        <br/>        output = model(images)<br/>        loss = criterion(output, labels)<br/>        <br/>        <em class="lb">#This is where the model learns by backpropagating</em><br/>        loss.backward()<br/>        <br/>        <em class="lb">#And optimizes its weights here</em><br/>        optimizer.step()<br/>        <br/>        running_loss += loss.item()<br/>    <strong class="mr ir">else</strong>:<br/>        print("Epoch <strong class="mr ir">{}</strong> - Training loss: <strong class="mr ir">{}</strong>".format(e, running_loss/len(trainloader)))</span><span id="4dab" class="lq lr iq mr b gy nn mw l mx my">print("<strong class="mr ir">\n</strong>Training Time (in minutes) =",(time()-time0)/60)</span></pre><p id="d41b" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">这可能需要一些时间来执行，并且会因系统而异。我在云笔记本上花了 2.5 分钟。</p><h2 id="1588" class="lq lr iq bd ls lt lu dn lv lw lx dp ly kf lz ma mb kj mc md me kn mf mg mh mi bi translated">步骤 6 —测试和评估</h2><p id="eab1" class="pw-post-body-paragraph ju jv iq jw b jx mj jz ka kb mk kd ke kf ml kh ki kj mm kl km kn mn kp kq kr ij bi translated">我们的工作快完成了。模型做好了，但我们要先评估一下。我创建了一个实用函数<strong class="jw ir"> view_classify() </strong>来显示预测的图像和类别概率。代码可以在 GitHub 上找到。(下面参考资料部分的链接)。</p><p id="b0ac" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">我将我们之前创建的验证集中的一个图像传递给训练好的模型，以查看模型是如何工作的。</p><pre class="ld le lf lg gt mq mr ms mt aw mu bi"><span id="a9b8" class="lq lr iq mr b gy mv mw l mx my">images, labels = next(iter(valloader))<br/><br/>img = images[0].view(1, 784)</span><span id="7bfd" class="lq lr iq mr b gy nn mw l mx my"><strong class="mr ir">with</strong> torch.no_grad():<br/>    logps = model(img)<br/><br/>ps = torch.exp(logps)<br/>probab = list(ps.numpy()[0])<br/>print("Predicted Digit =", probab.index(max(probab)))<br/><strong class="mr ir">view_classify</strong>(img.view(1, 28, 28), ps)</span></pre><figure class="ld le lf lg gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="lh li di lj bf lk"><div class="gh gi nu"><img src="../Images/8f6f78b60f13d0da3c8c203322c7303a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*eZifJcHLHfzsy1Bo9udi0g.png"/></div></div><figcaption class="lm ln gj gh gi lo lp bd b be z dk">Prediction Result. Perfect Prediction!</figcaption></figure><p id="2046" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">现在，我们使用 for 循环遍历验证集，并计算正确预测的总数。这是我们计算精确度的方法。</p><pre class="ld le lf lg gt mq mr ms mt aw mu bi"><span id="65f3" class="lq lr iq mr b gy mv mw l mx my">correct_count, all_count = 0, 0<br/><strong class="mr ir">for</strong> images,labels <strong class="mr ir">in</strong> valloader:<br/>  <strong class="mr ir">for</strong> i <strong class="mr ir">in</strong> range(len(labels)):<br/>    img = images[i].view(1, 784)<br/>    <strong class="mr ir">with</strong> torch.no_grad():<br/>        logps = model(img)<br/><br/>    <br/>    ps = torch.exp(logps)<br/>    probab = list(ps.numpy()[0])<br/>    pred_label = probab.index(max(probab))<br/>    true_label = labels.numpy()[i]<br/>    <strong class="mr ir">if</strong>(true_label == pred_label):<br/>      correct_count += 1<br/>    all_count += 1<br/><br/>print("Number Of Images Tested =", all_count)<br/>print("<strong class="mr ir">\n</strong>Model Accuracy =", (correct_count/all_count))</span></pre><p id="6eb7" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">现在来看看结果。这是最有趣的部分！</p><pre class="ld le lf lg gt mq mr ms mt aw mu bi"><span id="3140" class="lq lr iq mr b gy mv mw l mx my">Number Of Images Tested = 10000<br/>Model Accuracy = 0.9751</span></pre><p id="a376" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">哇！我们有超过 97.5%的准确率。这是值得庆祝的事情。我们获得如此高精度的原因是，我们的数据集是干净的，有各种各样经过良好洗牌的图像，而且数量很大。这使得我们的模型能够很好地识别大量看不见的数字。</p><h2 id="63c2" class="lq lr iq bd ls lt lu dn lv lw lx dp ly kf lz ma mb kj mc md me kn mf mg mh mi bi translated">步骤 7 —保存模型</h2><p id="1f2a" class="pw-post-body-paragraph ju jv iq jw b jx mj jz ka kb mk kd ke kf ml kh ki kj mm kl km kn mn kp kq kr ij bi translated">现在我们已经完成了所有的工作，我们不想失去训练好的模型。我们不想每次用的时候都训练它。为此，我们将保存模型。以后需要的时候，可以直接加载使用，不需要进一步的训练。</p><pre class="ld le lf lg gt mq mr ms mt aw mu bi"><span id="79a8" class="lq lr iq mr b gy mv mw l mx my">torch<strong class="mr ir">.save</strong>(model, './my_mnist_model.pt') </span></pre><p id="4592" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">第一个参数是模型对象，第二个参数是路径。PyTorch 型号一般用<code class="fe no np nq mr b">.pt</code>或<code class="fe no np nq mr b">.pth</code>扩展名保存。<a class="ae mo" href="https://pytorch.org/tutorials/beginner/saving_loading_models.html#save-load-entire-model" rel="noopener ugc nofollow" target="_blank">查阅文件</a>。</p></div><div class="ab cl nv nw hu nx" role="separator"><span class="ny bw bk nz oa ob"/><span class="ny bw bk nz oa ob"/><span class="ny bw bk nz oa"/></div><div class="ij ik il im in"><h2 id="af81" class="lq lr iq bd ls lt lu dn lv lw lx dp ly kf lz ma mb kj mc md me kn mf mg mh mi bi translated">结论</h2><p id="f5cb" class="pw-post-body-paragraph ju jv iq jw b jx mj jz ka kb mk kd ke kf ml kh ki kj mm kl km kn mn kp kq kr ij bi translated">我希望你喜欢建立一个神经网络，训练它，测试它，最后保存它的过程。在构建一个很酷的项目的同时，你肯定已经掌握了一些概念，学到了一些新东西。我很想知道它是如何为你工作的。<strong class="jw ir"> <em class="lb">并且，如果你喜欢请鼓掌，这对我是一种鼓励。</em> </strong> :) <em class="lb">更多炫酷文章一字排开。即将推出！</em></p><p id="a1b2" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">如果你有心情请我喝啤酒🤩&gt; &gt;<a class="ae mo" href="https://www.buymeacoffee.com/amitrajit" rel="noopener ugc nofollow" target="_blank">https://www.buymeacoffee.com/amitrajit</a></p><p id="0138" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">哦！并且，<a class="ae mo" href="https://github.com/amitrajitbose/handwritten-digit-recognition" rel="noopener ugc nofollow" target="_blank"> <em class="lb">整个笔记本在这里</em> </a>都有。笔记本电脑的 GPU 版本不同于 CPU 版本。你可以根据你的需要参考。</p><h2 id="2319" class="lq lr iq bd ls lt lu dn lv lw lx dp ly kf lz ma mb kj mc md me kn mf mg mh mi bi translated">参考文献</h2><p id="bbdf" class="pw-post-body-paragraph ju jv iq jw b jx mj jz ka kb mk kd ke kf ml kh ki kj mm kl km kn mn kp kq kr ij bi translated">[1] <a class="ae mo" href="https://pytorch.org/docs/stable/index.html" rel="noopener ugc nofollow" target="_blank"> <em class="lb"> PyTorch 官方 Doc</em></a><em class="lb">s<br/></em>【2】<a class="ae mo" href="https://en.wikipedia.org/wiki/MNIST_database" rel="noopener ugc nofollow" target="_blank"><em class="lb">MNIST 维基百科</em></a><em class="lb"><br/></em>【3】<em class="lb">Cool GIFs 来自</em><a class="ae mo" href="https://giphy.com" rel="noopener ugc nofollow" target="_blank"><em class="lb">GIPHY</em></a><br/>【4】<a class="ae mo" href="https://github.com/amitrajitbose/handwritten-digit-recognition" rel="noopener ugc nofollow" target="_blank"><em class="lb">GitHub 上的全部代码</em> </a></p><h2 id="00e8" class="lq lr iq bd ls lt lu dn lv lw lx dp ly kf lz ma mb kj mc md me kn mf mg mh mi bi translated">承认</h2><p id="c102" class="pw-post-body-paragraph ju jv iq jw b jx mj jz ka kb mk kd ke kf ml kh ki kj mm kl km kn mn kp kq kr ij bi translated"><em class="lb">感谢</em><a class="ae mo" href="https://zykrr.com/" rel="noopener ugc nofollow" target="_blank"><em class="lb">Zykrr</em></a><em class="lb">工程给予的灵感。在，</em><a class="ae mo" href="https://www.linkedin.com/company/zykrr/" rel="noopener ugc nofollow" target="_blank"><em class="lb">Zykrr</em></a><em class="lb">我们与</em> <a class="ae mo" href="https://medium.com/zykrrtech" rel="noopener"> <em class="lb">客户体验和反馈分析</em> </a> <em class="lb">领域的尖端技术合作。</em></p></div></div>    
</body>
</html>