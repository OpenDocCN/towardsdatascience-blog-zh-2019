<html>
<head>
<title>Principal Component Analysis — Math and Intuition (Post 2)</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">主成分分析—数学和直觉(后 2)</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/principal-component-analysis-math-and-intuition-post-2-1849090e6b7a?source=collection_archive---------7-----------------------#2019-04-04">https://towardsdatascience.com/principal-component-analysis-math-and-intuition-post-2-1849090e6b7a?source=collection_archive---------7-----------------------#2019-04-04</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><figure class="gl gn jr js jt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi jq"><img src="../Images/2077b1b815c98f080656ebbb6a369eb8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*c-ZYbjLfhsSHaiup-vhbpQ.jpeg"/></div></div></figure><p id="3dce" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">这是关于<strong class="kd iu">主成分分析——数学和直觉</strong>的三部分系列的第二部分。如果你想通过真实世界的例子阅读 PCA 的直观解释，请前往<a class="ae kz" rel="noopener" target="_blank" href="/principal-component-analysis-math-and-intuition-post-1-d44bf32844f3">帖子 1 </a>。PCA 的数学涉及到中级的线性代数概念，我们将在这里讨论。</p><p id="5cea" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated"><strong class="kd iu">线性代数</strong></p><p id="dbbc" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">线性代数是数学的一个分支，研究数字之间的线性关系。考虑下面的等式，</p><p id="5673" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">2x + 3y = 13</p><p id="11e4" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">5x + 2y = 16</p><p id="32fb" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">虽然你可能会尝试手动解决它们，这可能不会超过 30 秒；想象一个场景，你有 10 个变量和 10 个方程。这就是向量和矩阵符号出现的地方。上面的等式可以表示为，</p><figure class="lb lc ld le gt ju gh gi paragraph-image"><div class="gh gi la"><img src="../Images/264d227af796c2b512cb869069ac6f07.png" data-original-src="https://miro.medium.com/v2/resize:fit:600/format:webp/1*D23pJYAdlc8os57LqAO_6A.png"/></div></figure><p id="8264" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">向量和矩阵是简洁表示线性方程的方便符号。如果向量是一个列表，矩阵就是一个列表的列表。一个<strong class="kd iu"> m </strong> x <strong class="kd iu"> n </strong>矩阵是一个由 m<strong class="kd iu">行和 n<strong class="kd iu">列组成的矩形数组。向量也是矩阵，但只有一行或一列。有一些方法可以求解上面的表达式，并确定 x 和 y 的值，我们在这里就不深究了。在上面的例子中要理解的概念是，等式左边的向量被矩阵变换，以给出等式右边的向量。</strong></strong></p><p id="c41b" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated"><strong class="kd iu">特殊矩阵</strong></p><p id="2db4" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">我们已经看到，矩阵是对向量或其他矩阵执行运算的 2D 数列。线性代数中定义了各种具有特殊性质的矩阵，这有助于简化这些运算。当你在机器学习应用中一次又一次地遇到这些特殊矩阵时，你就会意识到它们的重要性。让我们介绍几个与 PCA 相关的应用程序(以及其他几个机器学习应用程序)。</p><p id="3182" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated"><strong class="kd iu"> <em class="lf">方阵</em> </strong></p><p id="f960" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">当行数等于列数时，矩阵是正方形的。简单？</p><figure class="lb lc ld le gt ju gh gi paragraph-image"><div class="gh gi la"><img src="../Images/5bfb3694aec6f64627d968fff18aa2f5.png" data-original-src="https://miro.medium.com/v2/resize:fit:600/format:webp/1*2XaLM1GlAbXd1BZ8lS2qyw.png"/></div><figcaption class="lg lh gj gh gi li lj bd b be z dk">Square matrices</figcaption></figure><p id="94df" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated"><strong class="kd iu"> <em class="lf">对角矩阵</em> </strong></p><p id="510d" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">矩阵的主对角线是从左上到右下的。如果一个矩阵的所有非对角元素都为 0，则该矩阵是对角矩阵。非零条目只出现在主对角线上。主对角线可以有也可以没有零。</p><figure class="lb lc ld le gt ju gh gi paragraph-image"><div class="gh gi la"><img src="../Images/d1ded73f063947a314b6954378da3185.png" data-original-src="https://miro.medium.com/v2/resize:fit:600/format:webp/1*4aVFE3asonFWq6igUd_Gxw.png"/></div><figcaption class="lg lh gj gh gi li lj bd b be z dk">Diagonal matrix</figcaption></figure><p id="e0dc" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated"><strong class="kd iu"> <em class="lf">单位矩阵</em> </strong></p><p id="410b" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">单位矩阵是一种特殊的方阵。当单位矩阵与向量相乘时，它对向量没有任何作用。这相当于将一个标量数乘以 1(例如，5 x 1 = 5)。类似地，将向量乘以单位矩阵没有任何作用。听起来很蹩脚，但它让一些操作变得简单多了。单位矩阵通常表示为 I。</p><figure class="lb lc ld le gt ju gh gi paragraph-image"><div class="gh gi la"><img src="../Images/517813cb7ff1f9388ee31657a83ffe94.png" data-original-src="https://miro.medium.com/v2/resize:fit:600/format:webp/1*qcsgckpLZ9yUheDzCEvUfA.png"/></div><figcaption class="lg lh gj gh gi li lj bd b be z dk">Identity matrix</figcaption></figure><p id="05f7" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated"><strong class="kd iu"> <em class="lf">逆矩阵</em> </strong></p><p id="62ac" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">标量数 5 的倒数是 1/5 或 5^-1.逆矩阵是应用于矩阵的相同概念。将矩阵 a 与其逆矩阵 A^-1 相乘得到单位矩阵(对于矩阵来说类似于 1)，这是线性代数运算中广泛使用的概念。</p><figure class="lb lc ld le gt ju gh gi paragraph-image"><div class="gh gi la"><img src="../Images/a24f4aa3f52307da92b04a9f2889e86f.png" data-original-src="https://miro.medium.com/v2/resize:fit:600/format:webp/1*aPNAAr5DDVdQsV7faApSKg.png"/></div><figcaption class="lg lh gj gh gi li lj bd b be z dk">Inverse Matrix operation</figcaption></figure><p id="236e" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated"><strong class="kd iu"> <em class="lf">转置操作</em> </strong></p><p id="25ee" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">对矩阵应用转置操作就是将矩阵的所有行都变成列，反之亦然。矩阵 a 的转置由 A^T.表示</p><figure class="lb lc ld le gt ju gh gi paragraph-image"><div class="gh gi la"><img src="../Images/cfed6464551cbb8cf0595609b9ac029d.png" data-original-src="https://miro.medium.com/v2/resize:fit:600/format:webp/1*QKRk_1F9Fg5vj77eOgbupA.png"/></div><figcaption class="lg lh gj gh gi li lj bd b be z dk">Matrix Transpose</figcaption></figure><p id="0276" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated"><strong class="kd iu"> <em class="lf">正交和标准正交矩阵</em> </strong></p><p id="0642" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">正交矩阵是一种方阵，其列和行是正交单位向量，即垂直且大小为 1。定理 1: <strong class="kd iu"> <em class="lf">若</em> </strong> <strong class="kd iu"> <em class="lf"> A 是正交矩阵，其逆矩阵等于转置矩阵即 A^T = A^-1 </em> </strong></p><p id="d15f" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated"><strong class="kd iu"> <em class="lf">对称矩阵</em> </strong></p><p id="f71e" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">对称矩阵是特殊的方阵。矩阵 a 是对称的，如果它等于它的转置 A^T.。对称轴总是对称矩阵的主对角线。定理 2: <strong class="kd iu"> <em class="lf">若 a 是任意矩阵，则(A^T)A 和 A(A^T)是对称的。</em> </strong></p><figure class="lb lc ld le gt ju gh gi paragraph-image"><div class="gh gi la"><img src="../Images/42a24e2c016471129c2b2dfd9c8165fe.png" data-original-src="https://miro.medium.com/v2/resize:fit:600/format:webp/1*ZXPtC46Fukh-alYYfRv8Iw.png"/></div><figcaption class="lg lh gj gh gi li lj bd b be z dk">Symmetric matrix</figcaption></figure><p id="4bfb" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">你可能不需要记住不同的矩阵类型或定理。最好将此保存为备忘单，因为您会经常遇到它们。</p><p id="1445" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated"><strong class="kd iu">基础变更</strong></p><p id="ff99" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">考虑二维空间 R 中的向量<strong class="kd iu"> <em class="lf"> r </em> </strong>。空间 R 可以由任意一组正交的单位长度向量 e1 和 e2 来定义。</p><figure class="lb lc ld le gt ju gh gi paragraph-image"><div class="gh gi la"><img src="../Images/a3d90fd71e3897f370c4e2c6af721d3c.png" data-original-src="https://miro.medium.com/v2/resize:fit:600/format:webp/1*1Mg3lTvGwZK9p5cjWhKEbw.png"/></div><figcaption class="lg lh gj gh gi li lj bd b be z dk">Vector <strong class="bd lk"><em class="ll">r</em></strong> in R² space</figcaption></figure><p id="b857" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">现在来看相对于坐标 e1 和 e2 的矢量<strong class="kd iu"> <em class="lf"> r </em> </strong>，可以表示如下:</p><figure class="lb lc ld le gt ju gh gi paragraph-image"><div class="gh gi la"><img src="../Images/093908a46920d0c463149043be54b352.png" data-original-src="https://miro.medium.com/v2/resize:fit:600/format:webp/1*twyF8x3ctJXBvC1p4ZUDUw.png"/></div><figcaption class="lg lh gj gh gi li lj bd b be z dk">Vector <strong class="bd lk"><em class="ll">r</em></strong> defined with basis e</figcaption></figure><p id="c371" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">我们最初将矢量 e1 和 e2 表示为一组“任意的”矢量。按照惯例，e1 和 e2 形成标准坐标集，因为它们具有单位长度并且彼此正交。当向量<strong class="kd iu"> <em class="lf"> r </em> </strong>相对于一组向量 e 或<em class="lf">基</em> e 来描述时，可以表示为<strong class="kd iu"> <em class="lf"> r </em> </strong> e(用基 e 读向量 r)。然而，相同的向量<strong class="kd iu"> <em class="lf"> r </em> </strong>仍然可以相对于另一组坐标来描述，例如 b1 和 b2。在这个新的坐标系中，向量<strong class="kd iu"> <em class="lf"> r </em> </strong> b(以 b 为基读取向量 r)的编号会不同；在下图中用[x，y]表示。图中的矢量 b1 和 b2 是相对于标准坐标或<em class="lf">基</em> e 来描述的。注意，矢量 b1 和 b2 不必彼此正交(在该特定示例中，它们是正交的)。</p><figure class="lb lc ld le gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi la"><img src="../Images/ba7436e3469bc7d5fd63a23331fcab85.png" data-original-src="https://miro.medium.com/v2/resize:fit:600/format:webp/1*R7YeDTHlWazyVgPMkwi6qg.png"/></div></div><figcaption class="lg lh gj gh gi li lj bd b be z dk">Vector <strong class="bd lk"><em class="ll">r</em></strong> with basis e and basis b</figcaption></figure><p id="ef24" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">我们如何确定<strong class="kd iu"> <em class="lf"> r </em> </strong> b 中的数字？</p><p id="2acb" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">因为我们知道了新坐标集合 b 相对于基 e 的向量，我们就有了将任意向量从基 b 变换到基 e 的变换矩阵，让我们称这个变换矩阵为 b。</p><figure class="lb lc ld le gt ju gh gi paragraph-image"><div class="gh gi la"><img src="../Images/f3575584514a9dbf4810f1a60e3f7af6.png" data-original-src="https://miro.medium.com/v2/resize:fit:600/format:webp/1*0AnBttL_5lKO__h2uehiwg.png"/></div></figure><p id="6be1" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">因此，要确定基 B 中向量<strong class="kd iu"> <em class="lf"> r </em> </strong>的个数，我们现在要做的就是将矩阵 B 的逆乘以基 e 中的向量<strong class="kd iu"> <em class="lf"> r </em> </strong></p><figure class="lb lc ld le gt ju gh gi paragraph-image"><div class="gh gi la"><img src="../Images/1ffaa82a8d92e2bcad7c598dad5c41bc.png" data-original-src="https://miro.medium.com/v2/resize:fit:600/format:webp/1*DkSVBa0C1TTdsnhvLtx68Q.png"/></div></figure><p id="e45a" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">我没有进入计算的细节，因为它是微不足道的。</p><p id="ac88" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">这里我们需要注意的是，向量并不依赖于最初用来描述它的坐标轴。我们可以用一组新的坐标轴或基向量来重新描述它。这是线性代数中的一个重要概念。它允许我们移动向量或数据项的基础，从而移动向量中的数字。</p><p id="c742" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">让我们更进一步。你想在向量<strong class="kd iu"> <em class="lf"> r </em> </strong> b 上应用一个用基 e 描述的变换矩阵 R(向量 R 用基 b)。由于我们不知道基 b 中的变换矩阵 R，我们将首先将其应用于向量<strong class="kd iu"> <em class="lf"> r </em> </strong> e，然后将其变换回基 b</p><p id="fe77" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">第一步:将矢量<strong class="kd iu"> <em class="lf"> r </em> </strong> b 的基改为<strong class="kd iu"> <em class="lf"> r </em> </strong> e</p><figure class="lb lc ld le gt ju gh gi paragraph-image"><div class="gh gi la"><img src="../Images/d45e8d8d665bce10f9ea657657ac8a7e.png" data-original-src="https://miro.medium.com/v2/resize:fit:600/format:webp/1*6ayGNUMRkF2WZQqbf-RrOg.png"/></div></figure><p id="3198" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">步骤 2:应用变换矩阵 R</p><figure class="lb lc ld le gt ju gh gi paragraph-image"><div class="gh gi la"><img src="../Images/71271c3fa43b27280e6466ccb56eb6f3.png" data-original-src="https://miro.medium.com/v2/resize:fit:600/format:webp/1*7CnTBVge-3iX6GTcA8CAuQ.png"/></div></figure><p id="749d" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">步骤 3:转换回基础 b</p><figure class="lb lc ld le gt ju gh gi paragraph-image"><div class="gh gi la"><img src="../Images/0f7329d36e85be1c69e5ec76ce878e8d.png" data-original-src="https://miro.medium.com/v2/resize:fit:600/format:webp/1*W6sBbByMgiJXuSkWcpwVGQ.png"/></div></figure><p id="8039" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">综上所述，如果你想把一组坐标中描述的变换矩阵(e 基中的矩阵 R)应用到另一组坐标中描述的向量(b 基中的向量<strong class="kd iu"> <em class="lf"> r </em> </strong>)上，这是线性代数中你会遇到相当多的情况；可以用 B(逆)和 B 把 R 包起来。</p><p id="23e3" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">这可能有点难以理解，但它是线性代数中非常重要的概念，值得投入精力。</p><p id="165f" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated"><strong class="kd iu">特征向量和特征值</strong></p><p id="3828" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">“eigen”这个词来源于德语，意思是“特有的”。它帮助我们识别某样东西的特性。到目前为止，我们一直在研究一个向量在应用变换矩阵时是如何变化的。现在让我们试着想象一个变换矩阵是如何影响整个向量空间的。考虑由正方形突出显示的 R 的示例向量子空间。为了便于理解，我在这个空间中突出了三个向量(红色、绿色和蓝色)。</p><figure class="lb lc ld le gt ju gh gi paragraph-image"><div class="gh gi la"><img src="../Images/a4380e43dc25e28521de3e663c555b5d.png" data-original-src="https://miro.medium.com/v2/resize:fit:600/format:webp/1*6e-dIR3nTzp-hQhNzRbkJA.png"/></div></figure><p id="03b8" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">让我们应用变换矩阵 T，将这个正方形子空间放大到矩形。</p><figure class="lb lc ld le gt ju gh gi paragraph-image"><div class="gh gi la"><img src="../Images/efc9cf71d6a2a7c0c91be375def7feea.png" data-original-src="https://miro.medium.com/v2/resize:fit:600/format:webp/1*9J2wjr3qnbvSGp8DArPFQA.png"/></div></figure><p id="94f8" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">注意一些向量在其跨度内保持不变，而另一些则不然。红色的水平向量指向相同的方向，大小不变。垂直的绿色向量指向相同的方向，但是其大小增加了 2 倍。对角线上的蓝色向量指向其他方向，其大小也有所增加。事实上，除了水平和垂直向量之外。我们子空间中的所有向量都通过应用这种垂直缩放的变换而改变了。</p><p id="bcc0" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">因此，水平和垂直向量是特殊的，并且是该特定变换矩阵 T 的“特征”,并且被称为变换矩阵 T 的“特征向量”。此外，水平向量的幅度保持不变，这意味着它具有 1 的相应“特征值”。垂直向量的特征值是 2，因为它在变换后大小加倍。注意，虽然在这个特定的例子中不适用，但是在变换时方向翻转的向量；但是保持在相同跨度中的向量也称为特征向量。您只需将负号(-)应用到相关的特征值上。</p><p id="051d" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">我们通过几何表示看到的特征向量和特征值的概念可以用代数表示如下，</p><figure class="lb lc ld le gt ju gh gi paragraph-image"><div class="gh gi la"><img src="../Images/44de227b2791164c194c8107f014ba32.png" data-original-src="https://miro.medium.com/v2/resize:fit:600/format:webp/1*uIuBIgyGMLXi9QI_ba9aLg.png"/></div></figure><p id="9691" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">其中，向量<strong class="kd iu"> <em class="lf"> v </em> </strong>是与变换矩阵 t 相关联的特征向量。它改变标量λ，该标量λ是与向量<strong class="kd iu"> <em class="lf"> v </em> </strong>相关联的特征值。</p><p id="a393" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">所以，我们已经知道，特征向量是在变换后不会改变太多的向量。它们可能被缩放或压缩，指向相同的方向或被颠倒；但是它们总是保持在相同的跨度内。特征向量是特定变换矩阵的特征，它们之所以重要，是因为它们是有趣的基向量或坐标，我们很快就会看到。</p><p id="1aef" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated"><strong class="kd iu">改变到特征基</strong></p><p id="769e" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">考虑这样一个场景，你必须将一个 3×3 的变换矩阵 T 应用到一个向量 x 上，然后反复应用 n 次，其中 n = 1 百万。</p><figure class="lb lc ld le gt ju gh gi paragraph-image"><div class="gh gi la"><img src="../Images/97b1f6e38b8c111c42a001c4fc543030.png" data-original-src="https://miro.medium.com/v2/resize:fit:600/format:webp/1*L9n4d1GVUhZH6vtleQzVDA.png"/></div></figure><p id="2f66" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">在一些实际应用中，您可能需要执行更大规模的矩阵乘法，这使得这些任务的计算量非常大。然而，这个问题有一个明显的例外，那就是当 T 是一个对角矩阵时。对角矩阵是只在从左上到右下的对角线上有非零元素的矩阵。将一个对角矩阵乘以 n 次等于将对角元素提升 n 倍！</p><figure class="lb lc ld le gt ju gh gi paragraph-image"><div class="gh gi la"><img src="../Images/a4a4bc5a50f85d74055a552a697ddbb3.png" data-original-src="https://miro.medium.com/v2/resize:fit:600/format:webp/1*L41i13tdhHzakMjsw6OpIw.png"/></div><figcaption class="lg lh gj gh gi li lj bd b be z dk">Raising a Diagonal matrix to a power of n</figcaption></figure><p id="7e31" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">如果矩阵 T 不是对角的呢？这就是我们到目前为止所学的变化基和特征向量的概念可以应用到现实世界场景中的地方。让我们在这里重温一下我们的问题。我们想对一个向量应用一个变换矩阵 T n 次，这需要将 T 乘以自身 n 次或者将 T 提升到 n 次幂，我们这个问题的一个简单而优雅的解决方案是将基改为特征基；使用特征转换矩阵。如果矩阵 C 的列是矩阵 T 的线性无关特征向量，我们可以应用矩阵 C(逆)化为特征基。这将我们带到一个世界，其中矩阵 T 由对角矩阵表示，让我们称之为 D。矩阵 D 中的对角线由与相应的特征向量相关联的特征值组成。现在，应用该变换 n 次只是纯粹的缩放，或者有效地将主对角线上的特征值提升到 n 次幂，从而使计算过程更加高效。我们现在要做的就是把基础变回原来的坐标，瞧！我们有矩阵 T 的 n 次方。</p><figure class="lb lc ld le gt ju gh gi paragraph-image"><div class="gh gi la"><img src="../Images/f136852ccc3253dc735a23508013be45.png" data-original-src="https://miro.medium.com/v2/resize:fit:600/format:webp/1*JHhHZ59DPuuCgTqPuew55w.png"/></div><figcaption class="lg lh gj gh gi li lj bd b be z dk">Diagonalization of a matrix</figcaption></figure><figure class="lb lc ld le gt ju gh gi paragraph-image"><div class="gh gi la"><img src="../Images/ccab0c537582370e36b9e2d742f55e61.png" data-original-src="https://miro.medium.com/v2/resize:fit:600/format:webp/1*jKKxkf1c7LTkLjKZ7K2CGw.png"/></div></figure><p id="781e" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">这里的关键信息是，如果一个矩阵可以通过基到特征基的变换而对角化，那么它就是可对角化的矩阵。</p><p id="e8b5" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated"><strong class="kd iu">谱定理</strong></p><p id="d952" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">到目前为止，我们所学的一切都带我们到了谱定理。</p><p id="00ca" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">设 a 是实数的 m×n 矩阵，A^T 是它的转置矩阵。</p><p id="7768" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated"><strong class="kd iu">定理 3 </strong>:若 a 对称(意为 A^T = A)，则 a 正交可对角化，且只有实特征值。换句话说，存在实数λ1，λ2。。。λn(特征值)和正交的非零实向量<strong class="kd iu"> <em class="lf"> v </em> </strong> 1，<strong class="kd iu"> <em class="lf"> v </em> </strong> 2，…<strong class="kd iu"> <em class="lf"> v </em> </strong> n(特征向量)使得对于每个 i = 1，2，…，n:</p><figure class="lb lc ld le gt ju gh gi paragraph-image"><div class="gh gi la"><img src="../Images/d9023728625d233f258245ad8d420a1b.png" data-original-src="https://miro.medium.com/v2/resize:fit:600/format:webp/1*RKyVL3jgtAjngoPfgq9Kqg.png"/></div></figure><p id="c35b" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">这就是谱定理，线性代数中最重要最有力的定理之一。你可能已经注意到了，它受到一个事实的限制，即它只适用于对称矩阵。</p><p id="208b" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">但是，如果你回忆一下定理 2(在对称矩阵一节下陈述):<strong class="kd iu"> <em class="lf">如果 a 是任意矩阵，那么(A^T)A 和 A(A^T)是对称的。</em> </strong>这暗示着谱定理可以应用于矩阵(A^T)A 和 A(A^T).谱定理是主成分分析的核心；这可能是它最重要的应用之一。</p><p id="43c8" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">就是这样！你已经在线性代数方面打下了坚实的基础，并且知道足够的数学知识来理解 PCA 的数学。恐怕这是一个令人精疲力尽的帖子，但是你在这里学到的概念不仅会帮助你解开 PCA 但是数据科学中的其他一些应用。</p><p id="2290" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">做得好，请继续关注本系列的<a class="ae kz" rel="noopener" target="_blank" href="/principal-component-analysis-math-and-intution-post-3-35ea8d2301b3"> post3 </a>，在这里我们将应用到目前为止学到的所有概念，并了解 PCA 是如何工作的。</p><p id="02d4" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">参考</p><ol class=""><li id="55cc" class="lm ln it kd b ke kf ki kj km lo kq lp ku lq ky lr ls lt lu bi translated"><a class="ae kz" href="https://www.coursera.org/learn/linear-algebra-machine-learning" rel="noopener ugc nofollow" target="_blank">机器学习数学——线性代数</a></li><li id="2902" class="lm ln it kd b ke lv ki lw km lx kq ly ku lz ky lr ls lt lu bi translated"><a class="ae kz" href="https://www.khanacademy.org/math/linear-algebra" rel="noopener ugc nofollow" target="_blank">线性代数</a></li><li id="1eb6" class="lm ln it kd b ke lv ki lw km lx kq ly ku lz ky lr ls lt lu bi translated"><a class="ae kz" href="http://www.math.union.edu/~jaureguj/PCA.pdf" rel="noopener ugc nofollow" target="_blank">线性代数主成分分析</a></li></ol></div></div>    
</body>
</html>