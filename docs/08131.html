<html>
<head>
<title>Neural Networks: Basics</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">神经网络:基础</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/neural-networks-basics-29cc093b82be?source=collection_archive---------8-----------------------#2019-11-07">https://towardsdatascience.com/neural-networks-basics-29cc093b82be?source=collection_archive---------8-----------------------#2019-11-07</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><figure class="gl gn jo jp jq jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi jn"><img src="../Images/bd09ab1d82712f8c523570a340f9444a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*0JESytw4ZERB0Xef"/></div></div></figure><figure class="jy jz ka kb gt jr"><div class="bz fp l di"><div class="kc kd l"/></div><figcaption class="ke kf gj gh gi kg kh bd b be z dk">Auditory learner? Listen to this article in podcast form instead!</figcaption></figure><p id="1875" class="pw-post-body-paragraph ki kj iq kk b kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf ij bi translated">人工神经网络(ann)是机器学习领域的热门话题。因此，大量的研究正在进行。计算机视觉对噪音数据的容忍度、自动驾驶汽车对道路路线的预测，以及自然语言处理(NLP)的进步，使你可以与你的语音助手交流，这些都归功于人工神经网络。了解神经网络的基础知识将有助于你参与到围绕这个话题的对话中。</p><p id="ea21" class="pw-post-body-paragraph ki kj iq kk b kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf ij bi translated">让我们从定义开始:人工神经网络是一种数学结构，当给定输入时，它可以映射到期望的输出。这样，十几个问题就会浮现在你的脑海里。让我们继续回答一些常见问题，以了解神经网络的基础知识。</p><h1 id="4be8" class="lg lh iq bd li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md bi translated">谁发明了神经网络？</h1><p id="c422" class="pw-post-body-paragraph ki kj iq kk b kl me kn ko kp mf kr ks kt mg kv kw kx mh kz la lb mi ld le lf ij bi translated">这个答案会因你问的人而异。有些人相信沃伦麦卡洛克和沃尔特皮茨的第一个理论。他们被认为描述了一个神经元如何有一个数学表示。然而，在这篇文章中，我们说的是一位名叫弗兰克·罗森布拉特的心理学家。</p><h1 id="15d9" class="lg lh iq bd li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md bi translated">罗森布拉特</h1><p id="5901" class="pw-post-body-paragraph ki kj iq kk b kl me kn ko kp mf kr ks kt mg kv kw kx mh kz la lb mi ld le lf ij bi translated">罗森布拉特在 1957 年发表了一篇名为<a class="ae mj" href="https://blogs.umass.edu/brain-wars/files/2016/03/rosenblatt-1957.pdf" rel="noopener ugc nofollow" target="_blank">“感知机:感知和识别自动化”</a>的论文。该出版物描述了神经网络的构建模块，感知器。他描述了这些人工神经元如何从数据中学习。他被认为创造了监督学习，允许神经元根据其准确性改变自己的权重。</p><h1 id="8c47" class="lg lh iq bd li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md bi translated">麦卡洛克和皮茨</h1><p id="1e25" class="pw-post-body-paragraph ki kj iq kk b kl me kn ko kp mf kr ks kt mg kv kw kx mh kz la lb mi ld le lf ij bi translated">麦卡洛克和皮茨在 1943 年发表了一篇名为“<a class="ae mj" href="https://www.cs.cmu.edu/~./epxing/Class/10715/reading/McCulloch.and.Pitts.pdf" rel="noopener ugc nofollow" target="_blank">神经活动中固有观念的逻辑演算”的论文。他们极大地影响了罗森布拉特的研究。在那篇论文中，他们描述了人类神经元如何在生物神经网络的“全有或全无”特征中进行数学表示。</a></p><p id="7209" class="pw-post-body-paragraph ki kj iq kk b kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf ij bi translated">当神经元接收到一个信号时，它不会自动开始向下游传递信号。它会保持信号，直到达到阈值，然后它沿着轴突发送信息，被邻近的细胞接收。</p><h1 id="6320" class="lg lh iq bd li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md bi translated">Hebb</h1><p id="ab9a" class="pw-post-body-paragraph ki kj iq kk b kl me kn ko kp mf kr ks kt mg kv kw kx mh kz la lb mi ld le lf ij bi translated">神经心理学的心理学家先驱唐纳德·赫布(Donald Hebb)在 1949 年发表了一篇名为<a class="ae mj" href="http://s-f-walker.org.uk/pubsebooks/pdfs/The_Organization_of_Behavior-Donald_O._Hebb.pdf" rel="noopener ugc nofollow" target="_blank">“行为的组织:一种神经心理学理论”</a>的论文。这篇开创性的论文产生了心理学中一个全新的规则，叫做赫布规则。该规则描述了一个神经元如何刺激另一个神经元，在重复激活后，细胞 A 变得有效地激活细胞 b。用 Hebb 的话说，“一起放电的神经元连接在一起”。</p><blockquote class="mk ml mm"><p id="0b66" class="ki kj mn kk b kl km kn ko kp kq kr ks mo ku kv kw mp ky kz la mq lc ld le lf ij bi translated"><em class="iq">“当 A 细胞的轴突足够接近以激活 B 细胞，并重复和持续地参与其激活时，在一个或两个细胞中发生某种类型的生长过程或代谢变化，从而增加 A 细胞激活 B 细胞的效率”</em></p><p id="9a78" class="ki kj mn kk b kl km kn ko kp kq kr ks mo ku kv kw mp ky kz la mq lc ld le lf ij bi translated"><em class="iq">赫布规则定义</em></p></blockquote><h1 id="066b" class="lg lh iq bd li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md bi translated">什么是感知器，它是如何组成神经网络的？</h1><p id="747b" class="pw-post-body-paragraph ki kj iq kk b kl me kn ko kp mf kr ks kt mg kv kw kx mh kz la lb mi ld le lf ij bi translated">感知器是神经网络的构建模块，类似于核酸、脂类、碳水化合物和蛋白质的<a class="ae mj" href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2892900/" rel="noopener ugc nofollow" target="_blank">生物构建模块</a>。四个部分也构成了这些:</p><ol class=""><li id="8575" class="mr ms iq kk b kl km kp kq kt mt kx mu lb mv lf mw mx my mz bi translated">输入值</li><li id="bb7b" class="mr ms iq kk b kl na kp nb kt nc kx nd lb ne lf mw mx my mz bi translated">权重和偏差</li><li id="0119" class="mr ms iq kk b kl na kp nb kt nc kx nd lb ne lf mw mx my mz bi translated">求和函数</li><li id="6c0f" class="mr ms iq kk b kl na kp nb kt nc kx nd lb ne lf mw mx my mz bi translated">激活功能</li></ol><figure class="jy jz ka kb gt jr gh gi paragraph-image"><div class="gh gi nf"><img src="../Images/dd5552510c4962f21e6f3a3f5fef256c.png" data-original-src="https://miro.medium.com/v2/resize:fit:672/format:webp/0*DXb7u_fftQ-Fe2aj.png"/></div></figure><p id="cc08" class="pw-post-body-paragraph ki kj iq kk b kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf ij bi translated">输入值受到预定权重值的影响，然后在求和函数中相加在一起。在求和函数之后，该值在激活函数中被压缩在-1 和 1 之间或 0 和 1 之间。这将决定感知器是否会被激活。值越负，越接近最小值(-1 或 0)，值越正，越接近最大值(1)。如果它被激活，那么输出将沿着它的路径发送。</p><h1 id="2144" class="lg lh iq bd li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md bi translated">单一感知器</h1><p id="04be" class="pw-post-body-paragraph ki kj iq kk b kl me kn ko kp mf kr ks kt mg kv kw kx mh kz la lb mi ld le lf ij bi translated">如果感知器是单一形式的，那么第一个也是唯一的输出将是 yes 或 no 格式。单感知器非常适合线性可分性数据集，即可以使用具有恒定斜率的单条线来分离的组。</p><figure class="jy jz ka kb gt jr gh gi paragraph-image"><div class="gh gi ng"><img src="../Images/5fc675243ced34f32238b276b6b1eb2e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/0*j3gnyadEvTb9YDcx.png"/></div></figure><p id="f810" class="pw-post-body-paragraph ki kj iq kk b kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf ij bi translated">感知器对于“与”、“或”、“异或”逻辑门来说非常优秀。让我们来分解一下:</p><p id="bad3" class="pw-post-body-paragraph ki kj iq kk b kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf ij bi translated">如果两个输入都为真，那么结果逻辑将为真。</p><figure class="jy jz ka kb gt jr gh gi paragraph-image"><div class="gh gi nh"><img src="../Images/b54899d64174c3ea7260f8a66de0c1fa.png" data-original-src="https://miro.medium.com/v2/resize:fit:478/format:webp/0*3IeLFp0X8KDWGQlM.png"/></div></figure><p id="2af5" class="pw-post-body-paragraph ki kj iq kk b kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf ij bi translated">或者，如果一个或两个输入为真，则推理结果为真。</p><figure class="jy jz ka kb gt jr gh gi paragraph-image"><div class="gh gi ni"><img src="../Images/ec8b61241c96fdcf3ac296b10391f3bb.png" data-original-src="https://miro.medium.com/v2/resize:fit:494/format:webp/0*k6iylmE6OO0L0qch.png"/></div></figure><p id="1d3c" class="pw-post-body-paragraph ki kj iq kk b kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf ij bi translated">XOR '，exclusive 'OR '，如果信息中的一个(但不是两个)为真，则命题将得出 true。</p><figure class="jy jz ka kb gt jr gh gi paragraph-image"><div class="gh gi nj"><img src="../Images/289623891d5cba99fca50257629a7f75.png" data-original-src="https://miro.medium.com/v2/resize:fit:462/format:webp/0*FTguAH_lYaYpjQAQ.png"/></div></figure><h1 id="9400" class="lg lh iq bd li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md bi translated">神经网络</h1><p id="d52f" class="pw-post-body-paragraph ki kj iq kk b kl me kn ko kp mf kr ks kt mg kv kw kx mh kz la lb mi ld le lf ij bi translated">然而，如果有一个以上的感知器存在并以分层的方式连接，我们就产生了一个神经网络。第一层的输出成为第二层的输入，依此类推，直到输出层对总激活进行求和。总激活度是网络最终决策的置信度。</p><figure class="jy jz ka kb gt jr gh gi paragraph-image"><div class="gh gi nk"><img src="../Images/700cdf1442f380f7c34e34eaf1575b71.png" data-original-src="https://miro.medium.com/v2/resize:fit:852/format:webp/0*AS4xRWgYT3PTMncQ.png"/></div></figure><h1 id="5978" class="lg lh iq bd li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md bi translated">神经网络有哪些层？</h1><p id="699f" class="pw-post-body-paragraph ki kj iq kk b kl me kn ko kp mf kr ks kt mg kv kw kx mh kz la lb mi ld le lf ij bi translated">神经网络有 3 层:</p><ol class=""><li id="5780" class="mr ms iq kk b kl km kp kq kt mt kx mu lb mv lf mw mx my mz bi translated">输入层</li><li id="c559" class="mr ms iq kk b kl na kp nb kt nc kx nd lb ne lf mw mx my mz bi translated">隐蔽层</li><li id="5a67" class="mr ms iq kk b kl na kp nb kt nc kx nd lb ne lf mw mx my mz bi translated">输出层</li></ol><figure class="jy jz ka kb gt jr gh gi paragraph-image"><div class="gh gi nl"><img src="../Images/0f4698190b8514e1ec99f3a185af7768.png" data-original-src="https://miro.medium.com/v2/resize:fit:872/format:webp/0*zscXecgQYgEQa74Z.png"/></div></figure><p id="397b" class="pw-post-body-paragraph ki kj iq kk b kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf ij bi translated">输入层是网络的起点。这是将用于预测的值引入的图层。隐藏层是网络发挥其“魔力”的地方。在整个区域计算输入值的激活量。隐藏层可以小到 1 层，也可以大到项目所需的数量。最后，输出层是每个最终节点的激活用于选择解决方案的地方。</p><p id="a395" class="pw-post-body-paragraph ki kj iq kk b kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf ij bi translated">如您所见，每个单元都连接到后续层的每个单元。这使得附近的感知器可以相互通信，并创建最适合其使用的权重。</p><p id="e31a" class="pw-post-body-paragraph ki kj iq kk b kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf ij bi translated">只要记住，第一层是输入，最后一层是输出。中间的任何东西都是隐藏层。</p><h1 id="1df1" class="lg lh iq bd li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md bi translated">计算机如何“看见”神经网络？</h1><p id="88d6" class="pw-post-body-paragraph ki kj iq kk b kl me kn ko kp mf kr ks kt mg kv kw kx mh kz la lb mi ld le lf ij bi translated">经常用于表示神经网络的图表(如上图所示)是人类友好的版本。计算机如何处理和观察它们是以矩阵的形式出现的。</p><figure class="jy jz ka kb gt jr gh gi paragraph-image"><div class="gh gi nm"><img src="../Images/54c9a2def03d6b556c72fcce0b803873.png" data-original-src="https://miro.medium.com/v2/resize:fit:642/format:webp/0*O1tD7-zMtOthQcko.png"/></div></figure><p id="36ba" class="pw-post-body-paragraph ki kj iq kk b kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf ij bi translated">我们将首先讨论前馈或训练部分。这是使用矩阵乘法完成的。</p><h1 id="d560" class="lg lh iq bd li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md bi translated">矩阵乘法</h1><p id="cd1b" class="pw-post-body-paragraph ki kj iq kk b kl me kn ko kp mf kr ks kt mg kv kw kx mh kz la lb mi ld le lf ij bi translated">让我们分解一个具有 2 个输入值的神经网络，1 个隐藏层包含 3 个节点，我们以 2 个输出层节点结束。</p><figure class="jy jz ka kb gt jr gh gi paragraph-image"><div class="gh gi nf"><img src="../Images/9f43d9190e40c98487a6f596a441a525.png" data-original-src="https://miro.medium.com/v2/resize:fit:672/format:webp/0*uE1mO0jtCq1TVxKe.png"/></div></figure><p id="21c6" class="pw-post-body-paragraph ki kj iq kk b kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf ij bi translated">我们将通过对每个元素使用唯一的字母来保持这一点，以便您可以在我们进行的过程中引用它。</p><h2 id="5ab7" class="nn lh iq bd li no np dn lm nq nr dp lq kt ns nt lu kx nu nv ly lb nw nx mc ny bi translated">权重 x 输入层</h2><p id="6354" class="pw-post-body-paragraph ki kj iq kk b kl me kn ko kp mf kr ks kt mg kv kw kx mh kz la lb mi ld le lf ij bi translated">矩阵乘法是通过取第一矩阵的行并将每个元素与第二矩阵中的相应元素相乘来完成的。该操作的主要规则是第一个矩阵中的列数必须与第二个矩阵中的行数相匹配。让我们看一下将用于该网络的第一组矩阵。</p><figure class="jy jz ka kb gt jr gh gi paragraph-image"><div class="gh gi nz"><img src="../Images/4bf7cc6bdafd676f34310cb6cb50e2ec.png" data-original-src="https://miro.medium.com/v2/resize:fit:828/format:webp/0*cU1SN3W4ko3c4Nhj.png"/></div></figure><p id="022a" class="pw-post-body-paragraph ki kj iq kk b kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf ij bi translated">正如我们所看到的，如果输入值的矩阵是第一个，我们将得到一个未定义的结果，因为上面的规则不被遵守。然而，如果我们翻转矩阵，我们将能够执行乘法。结果/输入矩阵作为第二个或右矩阵，权重矩阵作为第一个或左矩阵。</p><p id="23b9" class="pw-post-body-paragraph ki kj iq kk b kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf ij bi translated">让我们在这个网络中执行第一次乘法。</p><figure class="jy jz ka kb gt jr gh gi paragraph-image"><div class="gh gi ng"><img src="../Images/09248dbf4b0787738466403d5199a78e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/0*ke8NxbN8_b-GFdbs.png"/></div></figure><p id="481f" class="pw-post-body-paragraph ki kj iq kk b kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf ij bi translated">我们得到的矩阵包含 3 行，分别对应于隐藏层中的 3 个节点:</p><h2 id="17c7" class="nn lh iq bd li no np dn lm nq nr dp lq kt ns nt lu kx nu nv ly lb nw nx mc ny bi translated">权重 x 隐藏层</h2><p id="b181" class="pw-post-body-paragraph ki kj iq kk b kl me kn ko kp mf kr ks kt mg kv kw kx mh kz la lb mi ld le lf ij bi translated">让我们做最后的乘法。</p><figure class="jy jz ka kb gt jr gh gi paragraph-image"><div class="gh gi ng"><img src="../Images/a8a8e8a191222f58bebc18c7f8a11de2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/0*U4fLkiB-AhOSp5N6.png"/></div></figure><p id="3b6d" class="pw-post-body-paragraph ki kj iq kk b kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf ij bi translated">输出矩阵具有最终结果，它包含与输出层的 2 个节点相关的 2 行:</p><p id="5cc6" class="pw-post-body-paragraph ki kj iq kk b kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf ij bi translated">上述等式的结果将是每个神经元的激活水平。如果 O 0 高于 O 1，那么与 O 0 相关的预测将作为解给出。</p><h1 id="820d" class="lg lh iq bd li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md bi translated">神经网络是如何“学习”的？</h1><p id="2bde" class="pw-post-body-paragraph ki kj iq kk b kl me kn ko kp mf kr ks kt mg kv kw kx mh kz la lb mi ld le lf ij bi translated">神经网络分两步学习，前馈(我们刚刚讲过)和反向传播。反向传播本身可以分为两步，计算成本，然后最小化成本。</p><p id="b465" class="pw-post-body-paragraph ki kj iq kk b kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf ij bi translated">成本是网络的预测值和数据集的期望值之间的差值。成本越大，误差越大。目标是尽可能降低成本。为了实现这一目标，通过改变权重和偏好来最小化成本是游戏的名称。简单来说，它的前馈是反向的。你正在做矩阵乘法来改变权重，以便根据某些神经元将接收到的内容来给予它们更多的强调。</p><p id="33aa" class="pw-post-body-paragraph ki kj iq kk b kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf ij bi translated">最小化成本函数的一种常见方法是通过梯度下降。</p><h1 id="01a2" class="lg lh iq bd li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md bi translated">梯度下降</h1><p id="d405" class="pw-post-body-paragraph ki kj iq kk b kl me kn ko kp mf kr ks kt mg kv kw kx mh kz la lb mi ld le lf ij bi translated">目标是通过合计实际和预期输出之间的所有差异，然后将其乘以学习率，找到函数的全局成本最小值。最常见的成本函数是均方误差。</p><figure class="jy jz ka kb gt jr gh gi paragraph-image"><div class="gh gi oa"><img src="../Images/078d4557d57d82716f8428507c47f34d.png" data-original-src="https://miro.medium.com/v2/resize:fit:434/format:webp/0*_JqtvmAfZpv5gxzV.png"/></div></figure><p id="2248" class="pw-post-body-paragraph ki kj iq kk b kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf ij bi translated">J(θ)由梯度下降函数调用。</p><figure class="jy jz ka kb gt jr gh gi paragraph-image"><div class="gh gi ob"><img src="../Images/56abb1662338b32ffd091dce7c3765dc.png" data-original-src="https://miro.medium.com/v2/resize:fit:308/format:webp/0*B1s-ThwXHsu1JF_Z.png"/></div></figure><p id="2f4a" class="pw-post-body-paragraph ki kj iq kk b kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf ij bi translated">学习率α基本上是收敛的一大步(换句话说就是找到全局最小值)。为了给你一个视觉效果，想象你站在山顶上，下面是一个美丽的山谷。你开始沿着山坡往下走。对抗听从你内心孩子的冲动，快速滚下山(可能错过你的目标)，你从容不迫，轻松地走下来，避开路上的任何石头和树木。</p><p id="b590" class="pw-post-body-paragraph ki kj iq kk b kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf ij bi translated">学习率类似于你要走多大步或方法才能到达山谷。如果学习率太大，你可能会继续滚向另一边，并且由于你滚的冲力而完全错过山谷。如果学习率太小，那么在你到达山谷(最佳目标)之前，天就已经黑了。为您的模型找到合适的学习速率对于创建有效且高效的神经网络至关重要。</p><figure class="jy jz ka kb gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi oc"><img src="../Images/59acf36cedc0cf96e32d4846899c0354.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*uJrA_ukNlM8GUBxB"/></div></div></figure><p id="88e3" class="pw-post-body-paragraph ki kj iq kk b kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf ij bi translated">如果你想知道从哪里开始机器学习的自学，请查看<a class="ae mj" href="https://medium.com/analytics-vidhya/5-easy-steps-to-master-machine-learning-18621ac795d7" rel="noopener">学习机器学习的 5 个简单步骤</a>。这篇文章将帮助你有效地学习这个广泛的主题。</p><p id="865c" class="pw-post-body-paragraph ki kj iq kk b kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf ij bi translated">在我们重新学习之前，</p><figure class="jy jz ka kb gt jr gh gi paragraph-image"><div class="gh gi od"><img src="../Images/5cc252fa202d08cce8d892b3607e92f8.png" data-original-src="https://miro.medium.com/v2/resize:fit:320/format:webp/0*3wqAJekdamHbNsD5.png"/></div></figure></div></div>    
</body>
</html>