<html>
<head>
<title>Deep Multi-Input Models Transfer Learning for Image and Word Tag Recognition</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">用于图像和单词标签识别的深度多输入模型迁移学习</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/deep-multi-input-models-transfer-learning-for-image-and-word-tag-recognition-7ae0462253dc?source=collection_archive---------6-----------------------#2019-11-21">https://towardsdatascience.com/deep-multi-input-models-transfer-learning-for-image-and-word-tag-recognition-7ae0462253dc?source=collection_archive---------6-----------------------#2019-11-21</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="4c03" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">一种用于图像和文本理解的多模型深度学习方法</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/b6fd455bdadbb0d2ca8cf580c9d25714.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*1ZnavSAzpdOYQDXsngs0MQ.jpeg"/></div></div></figure><p id="2603" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">随着<a class="ae lq" href="https://en.wikipedia.org/wiki/Deep_learning" rel="noopener ugc nofollow" target="_blank">深度学习</a>如<a class="ae lq" href="https://en.wikipedia.org/wiki/Convolutional_neural_network" rel="noopener ugc nofollow" target="_blank">卷积神经网络</a>(即<a class="ae lq" href="https://neurohive.io/en/popular-networks/vgg16/" rel="noopener ugc nofollow" target="_blank">conv net</a>)【1】，<a class="ae lq" href="https://en.wikipedia.org/wiki/Computer_vision" rel="noopener ugc nofollow" target="_blank">计算机视觉</a>再次成为热门科研课题。现在计算机视觉的一个主要目标是使用机器学习(尤其是深度学习)来训练计算机从数字图像、文本或视频中获得人类级别的理解。</p><p id="8e2c" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">随着它的广泛使用，ConvNet 成为图像识别的事实模型。如[1]所述，一般来说，有两种方法可以将 ConvNet 用于计算机视觉:</p><ul class=""><li id="9b48" class="lr ls it kw b kx ky la lb ld lt lh lu ll lv lp lw lx ly lz bi translated"><strong class="kw iu">从头开始培训新的 ConvNet 模型</strong></li><li id="f50f" class="lr ls it kw b kx ma la mb ld mc lh md ll me lp lw lx ly lz bi translated"><strong class="kw iu">使用</strong> <a class="ae lq" href="https://en.wikipedia.org/wiki/Transfer_learning" rel="noopener ugc nofollow" target="_blank"> <strong class="kw iu">转移学习</strong> </a> <strong class="kw iu">，即使用预先训练好的 ConvNet 模型</strong></li></ul><p id="9e1c" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">如下图所示，一个 ConvNet 模型由两部分组成:一个<em class="mf">卷积基</em>和一个全连通<em class="mf">分类器</em>。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi mg"><img src="../Images/ec4dc2c949f5300c3421e880f166ebff.png" data-original-src="https://miro.medium.com/v2/resize:fit:360/format:webp/1*2waFrR-dSTK9rzBEtGLAUA.png"/></div></figure><p id="a3b0" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated"><strong class="kw iu">图 1:</strong>conv net 迁移学习的典型场景。</p><p id="8ebd" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">ConvNet 迁移学习可以进一步细分为三种方法:</p><ul class=""><li id="12cc" class="lr ls it kw b kx ky la lb ld lt lh lu ll lv lp lw lx ly lz bi translated"><strong class="kw iu">方法一:无需图像论证的特征提取</strong>【1】<br/>这种方法首先使用预先训练的卷积基将新图像转换为数组，例如 Numpy 数组(如果需要，可以将其保存到文件中)，然后使用内存中图像的那些数组表示，使用随机初始化的权重训练单独的新分类模型。</li><li id="6f5c" class="lr ls it kw b kx ma la mb ld mc lh md ll me lp lw lx ly lz bi translated"><strong class="kw iu">方法二:带图像论证的特征提取</strong>【1】<br/>该方法以预先训练好的卷积基为输入层建立新的模型，冻结卷积基的权值，最后加入一个新的随机初始化权值的输出分类器。</li><li id="92ce" class="lr ls it kw b kx ma la mb ld mc lh md ll me lp lw lx ly lz bi translated"><strong class="kw iu">方法三:微调</strong>【1】<br/>这种方法不使用整个冻结的预训练卷积基。它允许解冻冻结的预训练卷积基的一些顶层，使得那些解冻的顶层可以与新的完全连接的分类器联合训练。</li></ul><p id="7a87" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">方法 2 在本文中用于多输入模型迁移学习。</p><p id="faee" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">迁移学习背后的主要思想不仅可以用于有监督的 ConvNet，还可以用于其他深度学习算法，例如用于自然语言处理的无监督<a class="ae lq" href="https://en.wikipedia.org/wiki/Word_embedding" rel="noopener ugc nofollow" target="_blank">单词嵌入</a>模型(<a class="ae lq" href="https://en.wikipedia.org/wiki/Natural_language_processing" rel="noopener ugc nofollow" target="_blank">NLP</a>)【4】。</p><p id="250d" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">目前流行的预训练单词嵌入模型有两种:<a class="ae lq" href="https://code.google.com/archive/p/word2vec/" rel="noopener ugc nofollow" target="_blank"> word2vec </a>和<a class="ae lq" href="https://nlp.stanford.edu/projects/glove/" rel="noopener ugc nofollow" target="_blank">GloVe</a>【3】。像[4]中使用的<a class="ae lq" href="https://pypi.org/project/word2vec-keras/" rel="noopener ugc nofollow" target="_blank"> word2vec-keras </a>模型，这些预训练的单词嵌入模型通常与其他有监督的深度学习算法相结合，如文本分类等<a class="ae lq" href="https://en.wikipedia.org/wiki/Recurrent_neural_network" rel="noopener ugc nofollow" target="_blank">递归神经网络</a>(RNN)<a class="ae lq" href="https://keras.io/examples/lstm_stateful/" rel="noopener ugc nofollow" target="_blank">LSTM</a><a class="ae lq" href="https://en.wikipedia.org/wiki/Natural_language_processing" rel="noopener ugc nofollow" target="_blank">NLP</a>【4】。</p><p id="7cb4" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">ConvNet 模型或 NLP 模型(例如，单词嵌入与 LSTM 的组合)可以单独用于解决计算机视觉和 NLP 中的许多有趣问题。正如本文所示，这些不同类型的模型还可以以各种方式组合起来[1]形成更强大的模型，以解决更具挑战性的问题，如<a class="ae lq" href="https://nanonets.com/blog/ai-in-insurance/" rel="noopener ugc nofollow" target="_blank">保险索赔流程自动化</a>不仅需要图像识别能力，还需要自然语言(如文本)理解能力。</p><p id="ac1a" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">本文使用 Kaggle 中一个有趣但具有挑战性的数据集，<a class="ae lq" href="https://www.kaggle.com/c/challenges-in-representation-learning-multi-modal-learning/data" rel="noopener ugc nofollow" target="_blank">表征学习中的挑战:多模态学习</a> [2]，提出了一个新的多输入迁移学习模型，该模型将两个输入模型与一个完全连接的分类层相结合，同时用于图像识别和单词标签识别(见图 2)。</p><p id="57e7" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">新的多输入模型背后的主要思想是将图像和单词标签识别的问题转化为机器学习分类问题，即确定给定的图像是否与给定的一组单词标签匹配(0-否，1-是)。</p><h1 id="39da" class="mh mi it bd mj mk ml mm mn mo mp mq mr jz ms ka mt kc mu kd mv kf mw kg mx my bi translated">1.数据准备</h1><p id="a0e1" class="pw-post-body-paragraph ku kv it kw b kx mz ju kz la na jx lc ld nb lf lg lh nc lj lk ll nd ln lo lp im bi translated">在将图像文件和单词标签文件的 Kaggle 数据集[2]下载到本地机器之后，可以使用下面的代码来构建和打乱图像文件名和相关单词标签文件名的列表。在用于训练目的的数据集中有 100，000 个图像文件和 100，000 个相应的单词标签文件。</p><pre class="kj kk kl km gt ne nf ng nh aw ni bi"><span id="195b" class="nj mi it nf b gy nk nl l nm nn">original_dataset_dir = './multi_task_learning/data/ESPGame100k'<br/>base_dataset_dir = './multi_task_learning/data/ESPGame100k_small'</span><span id="7f78" class="nj mi it nf b gy no nl l nm nn">original_label_path = original_dataset_dir + '/labels'<br/>original_label_files = [f for f in listdir(original_label_path) if isfile(join(original_label_path, f))]</span><span id="98c5" class="nj mi it nf b gy no nl l nm nn">original_image_path = original_dataset_dir + '/thumbnails'<br/>original_image_files = [f for f in listdir(original_image_path) if isfile(join(original_image_path, f))]</span><span id="247c" class="nj mi it nf b gy no nl l nm nn">original_image_files = np.array(original_image_files)<br/>original_label_files = np.array(original_label_files)</span><span id="76fc" class="nj mi it nf b gy no nl l nm nn">dataset_size = original_label_files.shape[0]<br/>perm = np.arange(dataset_size)<br/>np.random.shuffle(perm)<br/>original_image_files = original_image_files[perm]<br/>original_label_files = original_label_files[perm]</span></pre><p id="479c" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">为了在合理的时间内(几个小时)在笔记本电脑上训练新的多输入模型，我随机选择了 2，000 张图像和相应的 2，000 个 word 标记文件用于本文的模型训练:</p><pre class="kj kk kl km gt ne nf ng nh aw ni bi"><span id="e729" class="nj mi it nf b gy nk nl l nm nn">if not os.path.isdir(base_dataset_dir):<br/>    os.mkdir(base_dataset_dir)<br/>    <br/>small_label_path = os.path.join(base_dataset_dir, 'labels')<br/>small_image_path = os.path.join(base_dataset_dir, 'thumbnails')<br/>if not os.path.isdir(small_label_path):<br/>    os.mkdir(small_label_path)<br/>if not os.path.isdir(small_image_path):<br/>    os.mkdir(small_image_path)</span><span id="a3eb" class="nj mi it nf b gy no nl l nm nn">for fname in original_label_files[:2000]:<br/>    src = os.path.join(original_label_path, fname)<br/>    dst = os.path.join(small_label_path, fname)<br/>    shutil.copyfile(src, dst)</span><span id="2267" class="nj mi it nf b gy no nl l nm nn">for fname in original_label_files[:2000]:<br/>    img_fname = fname[:-5]<br/>    src = os.path.join(original_image_path, img_fname)<br/>    dst = os.path.join(small_image_path, img_fname)<br/>    shutil.copyfile(src, dst)</span></pre><p id="72c7" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">下面的代码将 2，000 个图像标签文件名和相应的 2，000 个单词标签加载到 Pandas DataFrame 中:</p><pre class="kj kk kl km gt ne nf ng nh aw ni bi"><span id="a6dd" class="nj mi it nf b gy nk nl l nm nn">label_map = {'label_file' : [], 'word_tags' : []}<br/>for fname in listdir(small_label_path): <br/>    f = join(small_label_path, fname)<br/>    if isfile(f):<br/>        f = open(f)<br/>        label_map['label_file'].append(fname)<br/>        line = f.read().splitlines()<br/>        label_map['word_tags'].append(line)<br/>label_df = pd.DataFrame(label_map)<br/>label_df.head()</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi np"><img src="../Images/6d920bf26763084ce651282b53b71734.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*etb6Gr0Leyte0-OumofqBQ.png"/></div></div></figure><p id="b739" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">与[4]类似，Jupyter notebook [5]中包含一个文本数据预处理程序，用于执行最少的数据预处理，如删除停用词和数字，以防产生重大差异:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nq"><img src="../Images/ba1ce425b187cb58ecfa4dad4600fdec.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*8zFGvJoG7TXDKKbmOKGvvA.png"/></div></div></figure><p id="c3c9" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">如[4]中所述，文本数据预处理的影响是不显著的，因此在本文中，未经预处理的原始单词标签用于模型训练。</p><h1 id="511d" class="mh mi it bd mj mk ml mm mn mo mp mq mr jz ms ka mt kc mu kd mv kf mw kg mx my bi translated">2.多输入模型迁移学习体系结构</h1><p id="88a2" class="pw-post-body-paragraph ku kv it kw b kx mz ju kz la na jx lc ld nb lf lg lh nc lj lk ll nd ln lo lp im bi translated">如下图所示，新的多输入迁移学习模型使用预训练的 ConvNet 模型<a class="ae lq" href="https://neurohive.io/en/popular-networks/vgg16/" rel="noopener ugc nofollow" target="_blank"> VGG16 </a>来接收和处理图像，并使用新的 NLP 模型(预训练的单词嵌入模型 GloVe 和 Keras LSTM 的组合)来接收和处理单词标签。这两个输入模型首先被合并在一起，然后与完全连接的输出分类模型组合，该完全连接的输出分类模型使用图像识别模型输出和 NLP 模型输出来确定图像和一组单词标签的输入对是否匹配(0-否，1-是)。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nr"><img src="../Images/635c0d8231f1f565e81a3dba15bfb476.png" data-original-src="https://miro.medium.com/v2/resize:fit:900/format:webp/1*eG7PpVYyc8giXfOju_cxsQ.png"/></div></figure><p id="a203" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated"><strong class="kw iu">图 2: </strong>多输入模型迁移学习的新深度学习模型的架构。</p><h1 id="0a50" class="mh mi it bd mj mk ml mm mn mo mp mq mr jz ms ka mt kc mu kd mv kf mw kg mx my bi translated">3.图像识别中的迁移学习</h1><p id="4a64" class="pw-post-body-paragraph ku kv it kw b kx mz ju kz la na jx lc ld nb lf lg lh nc lj lk ll nd ln lo lp im bi translated">如图 2 所示，新的多输入迁移学习模型使用预训练的 ConvNet 模型 VGG16 进行图像识别。VGG16 型号已经包含在 Keras 库中。来自[1]的以下代码用于将 VGG16 卷积基与新的全连接分类器相结合，以形成新的图像识别输入模型:</p><pre class="kj kk kl km gt ne nf ng nh aw ni bi"><span id="0e4b" class="nj mi it nf b gy nk nl l nm nn">from keras.applications import VGG16<br/><br/>image_input = Input(shape=(150, 150, 3), name='image')<br/>vgg16 = VGG16(weights='imagenet',<br/>                  include_top=False,<br/>                  input_shape=(150, 150, 3))(image_input)<br/>x = layers.Flatten()(vgg16) <br/>x = layers.Dense(256, activation='relu')(x)</span></pre><h1 id="c99c" class="mh mi it bd mj mk ml mm mn mo mp mq mr jz ms ka mt kc mu kd mv kf mw kg mx my bi translated">4.面向文本分类的迁移学习</h1><p id="a799" class="pw-post-body-paragraph ku kv it kw b kx mz ju kz la na jx lc ld nb lf lg lh nc lj lk ll nd ln lo lp im bi translated">如图 2 所示，新的多输入迁移学习模型使用预训练的单词嵌入模型 GloVe [3]将单词标签转换为紧凑向量。一旦手套数据集[3]被下载到本地机器，来自[1]的以下代码可用于将单词嵌入模型加载到存储器中:</p><pre class="kj kk kl km gt ne nf ng nh aw ni bi"><span id="5ebf" class="nj mi it nf b gy nk nl l nm nn">glove_dir = './multi_task_learning/data/'</span><span id="6909" class="nj mi it nf b gy no nl l nm nn">embeddings_index = {}<br/>f = open(os.path.join(glove_dir, 'glove.6B.100d.txt'))<br/>for line in f:<br/>    values = line.split()<br/>    word = values[0]<br/>    coefs = np.asarray(values[1:], dtype='float32')<br/>    embeddings_index[word] = coefs<br/>f.close()</span></pre><p id="952e" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">如图 2 所示，GloVe 单词嵌入与 Keras LSTM 相结合，形成了一个新的预测/识别单词标签的 NLP 输入模型:</p><pre class="kj kk kl km gt ne nf ng nh aw ni bi"><span id="65cb" class="nj mi it nf b gy nk nl l nm nn">tag_input = Input(shape=(None,), dtype='int32', name='tag')<br/>embedded_tag = layers.Embedding(max_words, embedding_dim)(tag_input)<br/>encoded_tag = layers.LSTM(512)(embedded_tag)</span></pre><h1 id="3514" class="mh mi it bd mj mk ml mm mn mo mp mq mr jz ms ka mt kc mu kd mv kf mw kg mx my bi translated">5.多输入模型与全连接分类器的结合</h1><p id="ef17" class="pw-post-body-paragraph ku kv it kw b kx mz ju kz la na jx lc ld nb lf lg lh nc lj lk ll nd ln lo lp im bi translated">一旦创建了新的图像识别输入模型和新的 NLP 输入模型，以下代码可以将它们与新的输出分类器组合成一个多输入迁移学习模型:</p><pre class="kj kk kl km gt ne nf ng nh aw ni bi"><span id="11d2" class="nj mi it nf b gy nk nl l nm nn">concatenated = layers.concatenate([x, encoded_tag], axis=-1)<br/>output = layers.Dense(1, activation='sigmoid')(concatenated)model = Model([image_input, tag_input], output)<br/>model.summary()</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ns"><img src="../Images/fdfb3f9564db9053e4f479ac714376e9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Ghb-BII1G55CqqAlgI_zOw.png"/></div></div></figure><p id="59f1" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">如[1]中所述，预训练的 VGG16 卷积基和手套字嵌入层都必须被冻结，使得这些模型的预训练权重在新的多输入模型训练期间不会被修改:</p><pre class="kj kk kl km gt ne nf ng nh aw ni bi"><span id="ef13" class="nj mi it nf b gy nk nl l nm nn"># model.layers[1].trainable = False # freeze VGG16<br/>model.layers[4].set_weights([embedding_matrix])<br/>model.layers[4].trainable = False # freeze GloVe word embedding</span></pre><p id="7f1d" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">然而，关于 VGG16 卷积基，有趣的是，我尝试了两种方法(冻结或不冻结)，但在模型训练时间或模型预测结果方面没有看到显著差异。</p><h1 id="cd0c" class="mh mi it bd mj mk ml mm mn mo mp mq mr jz ms ka mt kc mu kd mv kf mw kg mx my bi translated">6.多输入模型训练</h1><p id="2b94" class="pw-post-body-paragraph ku kv it kw b kx mz ju kz la na jx lc ld nb lf lg lh nc lj lk ll nd ln lo lp im bi translated">原始 Kaggle 训练数据集仅包括正确的图像对和相应的单词标签。在本文中，每一个这样的正确对都被标记为 1(匹配)(另请参见下面的代码)。为了创建一个平衡的数据集，除了现有的 2，000 对正确的图像和单词标记之外，下面的代码还创建了 2，000 对不正确的图像和单词标记。为简单起见，这是通过将所选择的 2000 幅图像中的每一幅(比如图像 I)与下一个图像文件的单词标签(即图像 i+1 的单词标签)配对来实现的。</p><pre class="kj kk kl km gt ne nf ng nh aw ni bi"><span id="8114" class="nj mi it nf b gy nk nl l nm nn">import cv2</span><span id="76a3" class="nj mi it nf b gy no nl l nm nn">dim = (150, 150)<br/>X_image_train = []<br/>X_tag_train = tag_data<br/>y_train = []<br/>    <br/>for fname in listdir(small_image_path):<br/>    fpath = os.path.join(small_image_path, fname)<br/>    im = cv2.imread(fpath)<br/>    im_resized = cv2.resize(im, dim, interpolation = cv2.INTER_AREA)<br/>    X_image_train.append(im_resized)<br/>    y_train.append(1)<br/>    <br/># add incorrect image and tag pairs<br/>num_negative_samples = len(y_train)<br/>for i in range(num_negative_samples):<br/>    image = X_image_train[i]<br/>    X_image_train.append(image)<br/>    j = (i + 1) % num_negative_samples # get a different tag<br/>    tag = X_tag_train[j]<br/>    X_tag_train = np.append(X_tag_train, tag) <br/>    y_train.append(0)</span></pre><p id="39ca" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">总共有 4000 对图片和文字标签，2000 对正确，2000 对错误。</p><p id="7bc3" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">每个图像单词标签需要被编码为整数，并且在单词标签可以被单词嵌入模型消费之前，单词标签的每个列表/序列需要被转换为整数值序列。这是通过使用和修改[1]中的代码来实现的:</p><pre class="kj kk kl km gt ne nf ng nh aw ni bi"><span id="5a02" class="nj mi it nf b gy nk nl l nm nn">from keras.preprocessing.text import Tokenizer<br/>from keras.preprocessing.sequence import pad_sequences</span><span id="4b1b" class="nj mi it nf b gy no nl l nm nn">maxlen = 100<br/>training_samples = num_of_samples<br/>tag_vocabulary_size = 10000<br/>max_words = tag_vocabulary_size<br/>num_of_samples = label_df.shape[0]</span><span id="d7f0" class="nj mi it nf b gy no nl l nm nn">tokenizer = Tokenizer(num_words=max_words)<br/>texts = []<br/>for tag_list in label_df_clean['word_tags']:<br/>    texts.append(' '.join(tag_list))<br/>tokenizer.fit_on_texts(texts)<br/>sequences = tokenizer.texts_to_sequences(texts)<br/>word_index = tokenizer.word_index<br/>print('Found {} unique tokens'.format(len(word_index)))<br/>tag_data = pad_sequences(sequences, maxlen=maxlen)</span></pre><p id="ee9f" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">得到的图像和单词标签训练数据集被转换成 Numpy 数组并被混洗用于模型训练:</p><pre class="kj kk kl km gt ne nf ng nh aw ni bi"><span id="385e" class="nj mi it nf b gy nk nl l nm nn">X_image_train = np.array(X_image_train)<br/>X_tag_train   = np.array(X_tag_train)<br/>y_train       = np.array(y_train)<br/>perm = np.arange(y_train.shape[0])<br/>np.random.shuffle(perm)<br/>X_image_train = X_image_train[perm]<br/>X_tag_train   = X_tag_train[perm]<br/>y_train       = y_train[perm]</span></pre><p id="4b7e" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">新的多输入模型被编译和训练如下，仅具有 30 个时期和 4，000 对平衡的图像和单词标签:</p><pre class="kj kk kl km gt ne nf ng nh aw ni bi"><span id="d37a" class="nj mi it nf b gy nk nl l nm nn">model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc'])<br/>model.fit([X_image_train, X_tag_train], y_train, epochs=30, batch_size=64)</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nt"><img src="../Images/4cd57e0d5af8e566c0454e211496ef24.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*5I_lnJBsEkncXwpSDSZ8tA.png"/></div></div></figure><h1 id="bdf7" class="mh mi it bd mj mk ml mm mn mo mp mq mr jz ms ka mt kc mu kd mv kf mw kg mx my bi translated">7.模型预测法</h1><p id="ff7f" class="pw-post-body-paragraph ku kv it kw b kx mz ju kz la na jx lc ld nb lf lg lh nc lj lk ll nd ln lo lp im bi translated">如下所示,[2]中的私有测试数据集包括 500 个图像，每个图像与两组单词标签相关联:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nu"><img src="../Images/abf33b17cb5284d46a46be63bdc3e859.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*N-EkTXWaTDQy-nh74tgaWg.png"/></div></div></figure><p id="be3d" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">给定测试数据集中的图像，新的多输入迁移学习模型需要能够预测给定的两组单词标签中的哪一组与图像匹配。</p><p id="574a" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">以下代码用于将测试图像加载到内存中:</p><pre class="kj kk kl km gt ne nf ng nh aw ni bi"><span id="3b5c" class="nj mi it nf b gy nk nl l nm nn">dim = (150, 150)<br/>X_image_test = []</span><span id="883a" class="nj mi it nf b gy no nl l nm nn">for fname in listdir(test_image_dir):<br/>    fpath = os.path.join(test_image_dir, fname)<br/>    im = cv2.imread(fpath)<br/>    im_resized = cv2.resize(im, dim, interpolation = cv2.INTER_AREA)<br/>    X_image_test.append(im_resized)</span></pre><p id="2e8c" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">测试字标签被转换成如下编码的整数值序列:</p><pre class="kj kk kl km gt ne nf ng nh aw ni bi"><span id="59cf" class="nj mi it nf b gy nk nl l nm nn">tokenizer_test = Tokenizer(num_words=max_words)<br/>texts_1 = []<br/>texts_2 = []<br/>texts_all = []<br/>for tag_list in test_image_label_df['word_tags_1']:<br/>    texts_1.append(' '.join(tag_list))<br/>for tag_list in test_image_label_df['word_tags_2']:<br/>    texts_2.append(' '.join(tag_list))<br/>texts_all.extend(texts_1)<br/>texts_all.extend(texts_2)<br/>tokenizer_test.fit_on_texts(texts_all)<br/>sequences_1 = tokenizer_test.texts_to_sequences(texts_1)<br/>sequences_2 = tokenizer_test.texts_to_sequences(texts_2)</span><span id="465c" class="nj mi it nf b gy no nl l nm nn">word_index_test = tokenizer_test.word_index<br/>print('Found {} unique tokens in test'.format(len(word_index_test)))<br/>tag_data_test_1 = pad_sequences(sequences_1, maxlen=maxlen)<br/>tag_data_test_2 = pad_sequences(sequences_2, maxlen=maxlen)</span></pre><p id="7287" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">然后，生成的图像和单词标签的 Python 数组被转换为 Numpy 数组，并适合训练好的预测模型:</p><pre class="kj kk kl km gt ne nf ng nh aw ni bi"><span id="2e2d" class="nj mi it nf b gy nk nl l nm nn">X_image_test = np.array(X_image_test)<br/>X_tag_test_1 = np.array(tag_data_test_1)<br/>X_tag_test_2 = np.array(tag_data_test_2)<br/>y_predict_1 = loaded_model.predict([X_image_test, X_tag_test_1])<br/>y_predict_2 = loaded_model.predict([X_image_test, X_tag_test_2])</span></pre><p id="0e93" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">下表显示了前 20 个预测结果:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nv"><img src="../Images/d8f4a570dc94b70540c5fb2f4e128fb6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*cc8hu2u9aY6ZGW-pNdxF6g.png"/></div></div></figure><p id="4355" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">下图是测试数据集中的影像 201.png:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nw"><img src="../Images/6968914e0711e6ccaef2b895f56e4cc8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1304/format:webp/1*fdZx95vIeyw5brSp5r-yJA.png"/></div></figure><p id="09c6" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">两个相关的单词标签集如下:</p><pre class="kj kk kl km gt ne nf ng nh aw ni bi"><span id="4156" class="nj mi it nf b gy nk nl l nm nn">word-tag-set-0: ['bloom', 'glow', 'overexposed', 'bright', 'white', 'face', 'woman', 'blonde']<br/>word-tag-set-1: ['iron', 'nuggets', 'samples', 'metal', 'ore', 'shadow', 'white', 'grey', 'gray', 'rust', 'shiny']</span></pre><p id="5a0a" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">该模型预测:</p><pre class="kj kk kl km gt ne nf ng nh aw ni bi"><span id="ca0e" class="nj mi it nf b gy nk nl l nm nn">word-tag-set-0: probability of 0.797<br/>word-tag-set-1: probability of 0.999</span></pre><p id="6a92" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">概率较高的 0.999 的答案是:</p><p id="7381" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated"><strong class="kw iu"> <em class="mf"> ['铁'，'金块'，'样本'，'金属'，'矿石'，'阴影'，'白色'，'灰色'，'铁锈'，'闪亮'] </em> </strong></p><p id="ae13" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">作为另一个正面例子，下面是测试数据集中的影像 76.png:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nx"><img src="../Images/0d29c947c0ced3013849794f96c75e92.png" data-original-src="https://miro.medium.com/v2/resize:fit:1252/format:webp/1*7ULB9ao-viQ2h9jXDWHv2A.png"/></div></figure><p id="59d3" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">以下是相关的两组单词标签:</p><pre class="kj kk kl km gt ne nf ng nh aw ni bi"><span id="b842" class="nj mi it nf b gy nk nl l nm nn">word-tag-set-0: ['person', 'man', 'shirt', 'pinstripe', 'smile', 'balding', 'grey', 'gray']<br/>word-tag-set-1: ['country', 'music', 'man', 'instrument', 'guitar', 'musician', 'person', 'playing', 'watch', 'striped', 'shirt', 'red', 'glasses']</span></pre><p id="f793" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">该模型预测:</p><pre class="kj kk kl km gt ne nf ng nh aw ni bi"><span id="1420" class="nj mi it nf b gy nk nl l nm nn">word-tag-set-0: probability of 0.997<br/>word-tag-set-1: probability of 0.530</span></pre><p id="7689" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">概率较高的 0.997 的答案是:</p><p id="ce80" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated"><strong class="kw iu"> <em class="mf"> ['人'，'男人'，'衬衫'，'细条纹'，'微笑'，'谢顶'，'灰色'] </em> </strong></p><p id="8de3" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">作为一个假阳性示例，以下是测试数据集中的图像 189.png:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ny"><img src="../Images/2a4795e627fe91ca121847971d5adf9c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1276/format:webp/1*M2GiSnf3BOw7Yuo2NknWKw.png"/></div></figure><p id="a778" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">以下是相关的两组单词标签:</p><pre class="kj kk kl km gt ne nf ng nh aw ni bi"><span id="766d" class="nj mi it nf b gy nk nl l nm nn">word-tag-set-0: ['necklace', 'woman', 'earring', 'jewelry', 'mouth', 'chin', 'closeup']<br/>word-tag-set-1: ['circle', 'lines', 'round', 'window', 'porthole', 'man', 'face', 'beard', 'person', 'dark', 'shadow']</span></pre><p id="e7b5" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">该模型预测:</p><pre class="kj kk kl km gt ne nf ng nh aw ni bi"><span id="387a" class="nj mi it nf b gy nk nl l nm nn">word-tag-set-0: probability of 0.016<br/>word-tag-set-1: probability of 0.999</span></pre><p id="a973" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">概率较高的 0.999 的误报答案是:</p><p id="057e" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated"><em class="mf"> ['圆'，'线'，'圆'，'窗'，'舷窗'，'人'，'脸'，'胡子'，'人'，'黑暗'，'影子'] </em></p><p id="1205" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">上面的测试结果表明，即使新的多输入迁移学习模型仅用 4000 对图像和单词标签以及 30 个时期来训练，该模型也能够在准确性方面获得相当合理的结果。</p><p id="2d49" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">然而，由于模型过度拟合，该模型也产生了相当多的假阳性。</p><h1 id="35e7" class="mh mi it bd mj mk ml mm mn mo mp mq mr jz ms ka mt kc mu kd mv kf mw kg mx my bi translated">摘要</h1><p id="b492" class="pw-post-body-paragraph ku kv it kw b kx mz ju kz la na jx lc ld nb lf lg lh nc lj lk ll nd ln lo lp im bi translated">本文提出了一种新的多输入深度迁移学习模型，该模型将两个预训练的输入模型(VGG16 和 GloVe &amp; LSTM)与一个新的全连接分类层相结合，用于同时识别图像和单词标签。</p><p id="f42e" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">新的多输入深度学习方法的关键点是将图像和单词标签识别的问题转化为分类问题，即确定给定的图像是否与给定的一组单词标签匹配(0-否，1-是)。</p><p id="b9e1" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">Kaggle 中具有挑战性的公共数据集<a class="ae lq" href="https://www.kaggle.com/c/challenges-in-representation-learning-multi-modal-learning/data" rel="noopener ugc nofollow" target="_blank">表征学习中的挑战:多模态学习</a>【2】，用于训练和评估新模型。</p><p id="14eb" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">模型预测结果表明，新模型在用于演示目的的有限模型训练(只有 30 个时期和 4，000 对图像和单词标签)下表现得相当好。然而，毫不奇怪，由于模型过度拟合，该模型也产生了相当多的假阳性。这个问题可以通过用更多时期和/或更多对图像和单词标签来训练模型来解决。</p><p id="c08d" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">显然，随机选择的 2000 幅训练图像不足以代表总共 100000 幅可用的训练图像。通过将训练图像的数量从 2，000 个增加到更大的尺寸，如 10，000 个，模型性能将得到显著提高。</p><p id="bc5d" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">Github [5]中提供了一个包含所有源代码的 Jupyter 笔记本。</p><h1 id="a39f" class="mh mi it bd mj mk ml mm mn mo mp mq mr jz ms ka mt kc mu kd mv kf mw kg mx my bi translated">参考</h1><p id="5c6d" class="pw-post-body-paragraph ku kv it kw b kx mz ju kz la na jx lc ld nb lf lg lh nc lj lk ll nd ln lo lp im bi translated">[1] F. Chollet，用 Python 进行深度学习，曼宁出版公司，2018</p><p id="902f" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">[2] <a class="ae lq" href="https://www.kaggle.com/c/challenges-in-representation-learning-multi-modal-learning/data" rel="noopener ugc nofollow" target="_blank">表征学习的挑战:多模态学习</a></p><p id="c58a" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">[3] J. Pennington，R. Socher，C.D. Manning，<a class="ae lq" href="https://nlp.stanford.edu/projects/glove/" rel="noopener ugc nofollow" target="_blank"> GloVe:单词表示的全局向量</a></p><p id="5328" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">[4] Y. Zhang，<a class="ae lq" rel="noopener" target="_blank" href="/deep-learning-for-natural-language-processing-using-word2vec-keras-d9a240c7bb9d">利用 word2vec-keras 进行自然语言处理的深度学习</a></p><p id="4d38" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">[5] Y. Zhang，<a class="ae lq" href="https://github.com/yzzhang/machine-learning/tree/master/deep_learning/multi_input_transfer_learning" rel="noopener ugc nofollow" target="_blank"> Github 中的 Jupyter 笔记本</a></p></div><div class="ab cl nz oa hx ob" role="separator"><span class="oc bw bk od oe of"/><span class="oc bw bk od oe of"/><span class="oc bw bk od oe"/></div><div class="im in io ip iq"><p id="4f7a" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">披露声明:2019 首创一。观点是作者个人的观点。除非本帖中另有说明，否则 Capital One 不隶属于所提及的任何公司，也不被这些公司认可。使用或展示的所有商标和其他知识产权是其各自所有者的财产。</p></div></div>    
</body>
</html>