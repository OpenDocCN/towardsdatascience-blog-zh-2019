<html>
<head>
<title>The Jungle of Koalas, Pandas, Optimus and Spark</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">树袋熊、熊猫、擎天柱和火花的丛林</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/the-jungle-of-koalas-pandas-optimus-and-spark-dd486f873aa4?source=collection_archive---------4-----------------------#2019-04-25">https://towardsdatascience.com/the-jungle-of-koalas-pandas-optimus-and-spark-dd486f873aa4?source=collection_archive---------4-----------------------#2019-04-25</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="2eb5" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">从 Databricks(考拉)、Optimus framework 和 Apache Spark 3.x 的最新库可以期待什么</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/deb09f1ae9b1161b556fd08ae67bf8f9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*n5SXQBLr7YJRZJLf9FD4pg.png"/></div></div></figure><p id="f979" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">如果你和我一样对数据科学感到兴奋，你大概知道 Spark+AI 最新峰会昨天(2019 年 4 月 24 日)开始了。而且有很棒的事情可以聊。但我会用衍生产品来做。</p><p id="0ba4" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">如果你一直在关注我，你会发现我参与创建了一个叫做 Optimus 的框架。如果您想了解更多信息，请查看以下文章:</p><div class="ln lo gp gr lp lq"><a rel="noopener follow" target="_blank" href="/data-science-with-optimus-part-1-intro-1f3e2392b02a"><div class="lr ab fo"><div class="ls ab lt cl cj lu"><h2 class="bd ir gy z fp lv fr fs lw fu fw ip bi translated">擎天柱的数据科学。第 1 部分:简介。</h2><div class="lx l"><h3 class="bd b gy z fp lv fr fs lw fu fw dk translated">用 Python、Spark 和 Optimus 分解数据科学。</h3></div><div class="ly l"><p class="bd b dl z fp lv fr fs lw fu fw dk translated">towardsdatascience.com</p></div></div><div class="lz l"><div class="ma l mb mc md lz me kp lq"/></div></div></a></div><div class="ln lo gp gr lp lq"><a rel="noopener follow" target="_blank" href="/data-science-with-optimus-part-2-setting-your-dataops-environment-248b0bd3bce3"><div class="lr ab fo"><div class="ls ab lt cl cj lu"><h2 class="bd ir gy z fp lv fr fs lw fu fw ip bi translated">擎天柱的数据科学。第 2 部分:设置您的数据操作环境。</h2><div class="lx l"><h3 class="bd b gy z fp lv fr fs lw fu fw dk translated">用 Python、Spark 和 Optimus 分解数据科学。今天:数据科学的数据操作。..*第 1 部分在此…</h3></div><div class="ly l"><p class="bd b dl z fp lv fr fs lw fu fw dk translated">towardsdatascience.com</p></div></div><div class="lz l"><div class="mf l mb mc md lz me kp lq"/></div></div></a></div><p id="c882" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">我在这里用 Optimus 和其他开源工具解释了整个数据科学环境。这可能是第 3 部分，但我更感兴趣的是向您展示其他内容。</p><h1 id="bcc9" class="mg mh iq bd mi mj mk ml mm mn mo mp mq jw mr jx ms jz mt ka mu kc mv kd mw mx bi translated">擎天柱蜜蜂</h1><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi my"><img src="../Images/f8fde6cb2c058be5a861de81cd089a66.png" data-original-src="https://miro.medium.com/v2/resize:fit:1200/format:webp/0*I01SfsEKx_JwppFn.png"/></div><figcaption class="mz na gj gh gi nb nc bd b be z dk"><a class="ae nd" href="https://github.com/ironmussa/Optimus" rel="noopener ugc nofollow" target="_blank">https://github.com/ironmussa/Optimus</a></figcaption></figure><p id="85d0" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">起初，Optimus 是作为一个清理大数据的项目开始的，但突然我们意识到这个框架有更多的机会。现在，我们已经创造了许多有趣的东西，如果你是一个使用熊猫或 spark 的数据科学家，你应该去看看。</p><p id="e149" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">现在我们有这些 API:</p><ul class=""><li id="01d5" class="ne nf iq kt b ku kv kx ky la ng le nh li ni lm nj nk nl nm bi translated">Spark 数据帧的改进版本(更适合清理和管理数据)。</li><li id="43e3" class="ne nf iq kt b ku nn kx no la np le nq li nr lm nj nk nl nm bi translated">使用 Spark 简化机器学习。</li><li id="2fa9" class="ne nf iq kt b ku nn kx no la np le nq li nr lm nj nk nl nm bi translated">使用 Spark 和 Spark 深度学习更轻松地进行深度学习。</li><li id="0d4b" class="ne nf iq kt b ku nn kx no la np le nq li nr lm nj nk nl nm bi translated">直接从火花数据帧绘图。</li><li id="f396" class="ne nf iq kt b ku nn kx no la np le nq li nr lm nj nk nl nm bi translated">描绘火花数据帧。</li><li id="ae34" class="ne nf iq kt b ku nn kx no la np le nq li nr lm nj nk nl nm bi translated">数据库连接(像亚马逊红移)更容易。</li><li id="e385" class="ne nf iq kt b ku nn kx no la np le nq li nr lm nj nk nl nm bi translated">丰富与外部 API 连接的数据。</li></ul><p id="07ee" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">还有更多。你甚至可以直接从网上读取数据到 Spark。</p><p id="23a3" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">因此，您可以看到，我们一直在努力改善数据科学家的世界。我们关心的事情之一是创建一个简单和可用的 API，我们并不喜欢 Pandas API 或 Spark API 本身，但它们的组合加上一点点令人惊叹的东西，创建了你今天可以称为我们的框架。</p><h1 id="4682" class="mg mh iq bd mi mj mk ml mm mn mo mp mq jw mr jx ms jz mt ka mu kc mv kd mw mx bi translated">考拉 vs 擎天柱 vs 火花 vs 熊猫</h1><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi ns"><img src="../Images/e1d235490c09f7f417d673bb2b200a26.png" data-original-src="https://miro.medium.com/v2/resize:fit:1024/format:webp/1*J8hxMIDA7E7NkmdfkWfD8Q.png"/></div><figcaption class="mz na gj gh gi nb nc bd b be z dk"><a class="ae nd" href="https://www.freepik.com/" rel="noopener ugc nofollow" target="_blank">https://www.freepik.com/</a></figcaption></figure><p id="f882" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">今天，Databricks 宣布，通过增强 Apache Spark 的 Python DataFrame API 以兼容熊猫，Koala 项目是与大数据交互时更有效的方式。</p><p id="c824" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">如果你想试试这个<a class="ae nd" href="https://matrixds.com/" rel="noopener ugc nofollow" target="_blank"> MatrixDS </a>项目:</p><div class="ln lo gp gr lp lq"><a href="https://community.platform.matrixds.com/community/project/5cc0de62b8f4a97f2912aabf" rel="noopener  ugc nofollow" target="_blank"><div class="lr ab fo"><div class="ls ab lt cl cj lu"><h2 class="bd ir gy z fp lv fr fs lw fu fw ip bi translated">MatrixDS |数据项目工作台</h2><div class="lx l"><h3 class="bd b gy z fp lv fr fs lw fu fw dk translated">MatrixDS 是一个构建、共享和管理任何规模的数据项目的地方。</h3></div><div class="ly l"><p class="bd b dl z fp lv fr fs lw fu fw dk translated">community.platform.matrixds.com</p></div></div></div></a></div><p id="5fbf" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">还有这个 GitHub 回购:</p><div class="ln lo gp gr lp lq"><a href="https://github.com/FavioVazquez/koalas_optimus_spark" rel="noopener  ugc nofollow" target="_blank"><div class="lr ab fo"><div class="ls ab lt cl cj lu"><h2 class="bd ir gy z fp lv fr fs lw fu fw ip bi translated">FavioVazquez/考拉 _ 擎天柱 _ 火花</h2><div class="lx l"><h3 class="bd b gy z fp lv fr fs lw fu fw dk translated">与火花和朋友一起震撼世界。。为 FavioVazquez/koalas _ Optimus _ spark 开发做出贡献，创建一个…</h3></div><div class="ly l"><p class="bd b dl z fp lv fr fs lw fu fw dk translated">github.com</p></div></div><div class="lz l"><div class="nt l mb mc md lz me kp lq"/></div></div></a></div><p id="3896" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">因此，我没有用复制粘贴树袋熊的文档来烦你，而是创建了一个树袋熊、Optimus 和 Spark 之间联系的简单示例。</p><p id="3ecb" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">你需要安装擎天柱</p><pre class="kg kh ki kj gt nu nv nw nx aw ny bi"><span id="13c2" class="nz mh iq nv b gy oa ob l oc od">pip install --user optimuspyspark</span></pre><p id="8bcc" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">还有考拉</p><pre class="kg kh ki kj gt nu nv nw nx aw ny bi"><span id="c394" class="nz mh iq nv b gy oa ob l oc od">pip install --user koalas</span></pre><p id="94f1" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">我将使用这个数据集进行测试:</p><p id="1052" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated"><a class="ae nd" href="https://raw.githubusercontent.com/databricks/koalas/master/data/sample_stocks.csv" rel="noopener ugc nofollow" target="_blank">https://raw . githubusercontent . com/databricks/考拉/master/data/sample _ stocks . CSV</a></p><p id="bc32" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">让我们首先用 Spark vanilla 读取数据:</p><pre class="kg kh ki kj gt nu nv nw nx aw ny bi"><span id="b9a1" class="nz mh iq nv b gy oa ob l oc od">from pyspark.sql import SparkSession<br/>spark = SparkSession.builder.getOrCreate()</span><span id="55e3" class="nz mh iq nv b gy oe ob l oc od">df = spark.read.csv("sample_stocks.csv", header=True)</span></pre><p id="6134" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">为此，我之前需要上传数据集。让我们看看擎天柱:</p><pre class="kg kh ki kj gt nu nv nw nx aw ny bi"><span id="1dec" class="nz mh iq nv b gy oa ob l oc od">from optimus import Optimus<br/>op = Optimus()<br/>df = op.load.url("<a class="ae nd" href="https://raw.githubusercontent.com/databricks/koalas/master/data/sample_stocks.csv" rel="noopener ugc nofollow" target="_blank">https://raw.githubusercontent.com/databricks/koalas/master/data/sample_stocks.csv</a>")</span></pre><p id="3c90" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">这简单了一步，因为有了 Optimus，你可以直接从网上读取数据。</p><p id="9917" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">考拉呢？</p><pre class="kg kh ki kj gt nu nv nw nx aw ny bi"><span id="e50f" class="nz mh iq nv b gy oa ob l oc od">import databricks.koalas as ks</span><span id="90fd" class="nz mh iq nv b gy oe ob l oc od">df = ks.read_csv("<a class="ae nd" href="https://raw.githubusercontent.com/databricks/koalas/master/data/sample_stocks.csv" rel="noopener ugc nofollow" target="_blank">https://raw.githubusercontent.com/databricks/koalas/master/data/sample_stocks.csv</a>")</span></pre><p id="29ca" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">这段代码会失败，那会发生在熊猫身上吗？</p><pre class="kg kh ki kj gt nu nv nw nx aw ny bi"><span id="6b93" class="nz mh iq nv b gy oa ob l oc od">import pandas as pd</span><span id="0ca3" class="nz mh iq nv b gy oe ob l oc od">df = pd.read_csv("<a class="ae nd" href="https://raw.githubusercontent.com/databricks/koalas/master/data/sample_stocks.csv" rel="noopener ugc nofollow" target="_blank">https://raw.githubusercontent.com/databricks/koalas/master/data/sample_stocks.csv</a>")</span></pre><p id="f857" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">不，那会有用的。那是因为你可以直接从网上读取熊猫的数据。好吧，让我们让考拉代码工作:</p><pre class="kg kh ki kj gt nu nv nw nx aw ny bi"><span id="88e5" class="nz mh iq nv b gy oa ob l oc od">import databricks.koalas as ks</span><span id="a7b3" class="nz mh iq nv b gy oe ob l oc od">df_ks = ks.read_csv("sample_stocks.csv")</span></pre><p id="1753" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">这看起来很简单。顺便说一下，如果你想用 Optimus 从本地存储器中读取数据，几乎是一样的:</p><pre class="kg kh ki kj gt nu nv nw nx aw ny bi"><span id="33e3" class="nz mh iq nv b gy oa ob l oc od">from optimus import Optimus<br/>op = Optimus()<br/>df_op_local = op.load.csv("sample_stocks.csv")</span></pre><p id="552a" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">但是，让我们看看接下来会发生什么。这种数据帧有哪些类型？</p><pre class="kg kh ki kj gt nu nv nw nx aw ny bi"><span id="a96e" class="nz mh iq nv b gy oa ob l oc od">print(type(df_sp))<br/>print(type(df_op))<br/>print(type(df_pd))<br/>print(type(df_ks))</span></pre><p id="c5b1" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">结果是:</p><pre class="kg kh ki kj gt nu nv nw nx aw ny bi"><span id="7015" class="nz mh iq nv b gy oa ob l oc od">&lt;class 'pyspark.sql.dataframe.DataFrame'&gt;<br/>&lt;class 'pyspark.sql.dataframe.DataFrame'&gt;<br/>&lt;class 'pandas.core.frame.DataFrame'&gt;<br/>&lt;class 'databricks.koalas.frame.DataFrame'&gt;</span></pre><p id="579b" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">所以除了 Spark 本身，唯一能创造 Spark DF 的框架就是 Optimus。这是什么意思？</p><p id="d47f" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">让我们看看当我们想要显示数据时会发生什么。为了在 Spark 中显示数据，我们通常使用<em class="of">。秀()</em>法，而对于熊猫则为<em class="of">。</em>头()【法。</p><pre class="kg kh ki kj gt nu nv nw nx aw ny bi"><span id="06c9" class="nz mh iq nv b gy oa ob l oc od">df_sp.show(1)</span></pre><p id="2a25" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">会按预期工作。</p><pre class="kg kh ki kj gt nu nv nw nx aw ny bi"><span id="61a3" class="nz mh iq nv b gy oa ob l oc od">df_op.show(1)</span></pre><p id="677e" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">也会起作用。</p><pre class="kg kh ki kj gt nu nv nw nx aw ny bi"><span id="7e2b" class="nz mh iq nv b gy oa ob l oc od">df_pd.head(1)</span></pre><p id="9b8a" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">也会起作用。但是我们的考拉 DF 呢？你需要使用 pandas API，因为这是这个库的目标之一，让从 pandas 的过渡更容易。所以:</p><pre class="kg kh ki kj gt nu nv nw nx aw ny bi"><span id="c853" class="nz mh iq nv b gy oa ob l oc od">df_ks.show(1)</span></pre><p id="7685" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">会失败，但是</p><pre class="kg kh ki kj gt nu nv nw nx aw ny bi"><span id="f0f8" class="nz mh iq nv b gy oa ob l oc od">df_ks.head(1)</span></pre><p id="84c3" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">会管用的。</p><p id="69be" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">如果你和我一起运行这段代码，如果你点击 spark 的<em class="of"> show </em>，你会看到:</p><pre class="kg kh ki kj gt nu nv nw nx aw ny bi"><span id="43dc" class="nz mh iq nv b gy oa ob l oc od">+----------+------+------+------+------+----------+----------+----------+-------+-------+------+--------+----------+------+<br/>|      Date|  Open|  High|   Low| Close|    Volume|ExDividend|SplitRatio|AdjOpen|AdjHigh|AdjLow|AdjClose| AdjVolume|Symbol|<br/>+----------+------+------+------+------+----------+----------+----------+-------+-------+------+--------+----------+------+<br/>|2018-03-27|173.68|175.15|166.92|168.34|38962839.0|       0.0|       1.0| 173.68| 175.15|166.92|  168.34|38962839.0|  AAPL|<br/>+----------+------+------+------+------+----------+----------+----------+-------+-------+------+--------+----------+------+<br/>only showing top 1 row</span></pre><p id="131e" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">这有点糟糕。每个人都喜欢那些漂亮的 HTML 大纲表来查看他们的数据，熊猫也有，所以考拉从熊猫那里继承了它们。但是记住，这不是火花 DF。如果你真的想看到一个更漂亮的带有 Optimus 的 Spark DF 版本，你可以使用<em class="of">。表()</em>方法<em class="of">。</em></p><pre class="kg kh ki kj gt nu nv nw nx aw ny bi"><span id="98a0" class="nz mh iq nv b gy oa ob l oc od">df_op.table(1)</span></pre><p id="4287" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">你会看到:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi og"><img src="../Images/62e3c03e146dea4a2ba1f8a9168c36ec.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*XCcx6BJf-Kn8eUc1rpPTyQ.png"/></div></div></figure><p id="d151" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">它更好地向您显示了数据以及相关信息，如列的类型、DF 中的行数、列数和分区数。</p><h1 id="9c81" class="mg mh iq bd mi mj mk ml mm mn mo mp mq jw mr jx ms jz mt ka mu kc mv kd mw mx bi translated">选择数据</h1><p id="65db" class="pw-post-body-paragraph kr ks iq kt b ku oh jr kw kx oi ju kz la oj lc ld le ok lg lh li ol lk ll lm ij bi translated">让我们用我们的数据做更多的事情。比如切片。</p><p id="0256" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">我将选择日期、开盘价、盘高、盘低和交易量。可能有更多的选择数据的方法，我只是使用常见的。</p><p id="9e42" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated"><strong class="kt ir">带火花:</strong></p><pre class="kg kh ki kj gt nu nv nw nx aw ny bi"><span id="4394" class="nz mh iq nv b gy oa ob l oc od"># With Spark<br/>df_sp["Date","Open","High","Volume"].show(1)</span><span id="4fc3" class="nz mh iq nv b gy oe ob l oc od"># or<br/>df_sp.select("Date","Open","High","Volume").show(1)</span></pre><p id="839f" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated"><strong class="kt ir">带擎天柱:</strong></p><pre class="kg kh ki kj gt nu nv nw nx aw ny bi"><span id="37fe" class="nz mh iq nv b gy oa ob l oc od">df_op["Date","Open","High","Volume"].table(1)</span><span id="31b9" class="nz mh iq nv b gy oe ob l oc od"># or<br/>df_op.select("Date","Open","High","Volume").table(1)</span><span id="4c79" class="nz mh iq nv b gy oe ob l oc od"># or with indices :)</span><span id="6953" class="nz mh iq nv b gy oe ob l oc od">df_op.cols.select([0,1,2,5]).table(1)</span></pre><p id="af9f" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated"><strong class="kt ir">与熊猫:</strong></p><pre class="kg kh ki kj gt nu nv nw nx aw ny bi"><span id="4344" class="nz mh iq nv b gy oa ob l oc od">df_pd[["Date","Open","High","Volume"]].head(1)</span><span id="fd29" class="nz mh iq nv b gy oe ob l oc od">#or </span><span id="6b62" class="nz mh iq nv b gy oe ob l oc od">df_pd.iloc[:, [0,1,2,4]].head(1)</span></pre><p id="fa9c" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated"><strong class="kt ir">带考拉:</strong></p><pre class="kg kh ki kj gt nu nv nw nx aw ny bi"><span id="1309" class="nz mh iq nv b gy oa ob l oc od">df_ks[["Date","Open","High","Volume"]].head(1) # will work</span><span id="ae6f" class="nz mh iq nv b gy oe ob l oc od">df_ks.iloc[:, [0,1,2,4]].head(1) # will fail</span><span id="410e" class="nz mh iq nv b gy oe ob l oc od">df_ks.select("Date","Open","High","Volume") # will fail</span></pre><p id="c5f4" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">所以正如你现在看到的，我们用 Optimus 很好地支持了不同的东西，如果你喜欢熊猫的[[]]风格，你也可以用它来处理考拉，但是你不能通过索引来选择，至少现在还不能。</p><p id="6bb0" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">与考拉和擎天柱不同的是，你在底层运行 Spark 代码，所以你不必担心性能。至少现在不是。</p><h1 id="1d13" class="mg mh iq bd mi mj mk ml mm mn mo mp mq jw mr jx ms jz mt ka mu kc mv kd mw mx bi translated">更多高级内容:</h1><p id="3e6d" class="pw-post-body-paragraph kr ks iq kt b ku oh jr kw kx oi ju kz la oj lc ld le ok lg lh li ol lk ll lm ij bi translated">让我们得到一列的频率:</p><p id="5adf" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">熊猫:</p><pre class="kg kh ki kj gt nu nv nw nx aw ny bi"><span id="7962" class="nz mh iq nv b gy oa ob l oc od">df_pd["Symbol"].value_counts()</span></pre><p id="d432" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated"><strong class="kt ir">考拉:</strong></p><pre class="kg kh ki kj gt nu nv nw nx aw ny bi"><span id="0c7e" class="nz mh iq nv b gy oa ob l oc od">df_ks["Symbol"].value_counts()</span></pre><p id="d653" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">他们是一样的，这很酷。</p><p id="01a2" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated"><strong class="kt ir">火花(一些坏零件):</strong></p><pre class="kg kh ki kj gt nu nv nw nx aw ny bi"><span id="3edd" class="nz mh iq nv b gy oa ob l oc od">df_sp.groupBy('Symbol').count().show()</span></pre><p id="f885" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated"><strong class="kt ir">擎天柱(你可以像在 Spark 里那样做):</strong></p><pre class="kg kh ki kj gt nu nv nw nx aw ny bi"><span id="cb4b" class="nz mh iq nv b gy oa ob l oc od">df_op.groupBy('Symbol').count().show()</span></pre><p id="353a" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">或者你可以使用<em class="of">。cols </em>属性获得更多功能:</p><pre class="kg kh ki kj gt nu nv nw nx aw ny bi"><span id="cf74" class="nz mh iq nv b gy oa ob l oc od">df_op.cols.frequency("Symbol")</span></pre><p id="8fe1" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">让我们用 One-Hot-encoding 来转变我们的数据:</p><p id="444f" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated"><strong class="kt ir">熊猫:</strong></p><pre class="kg kh ki kj gt nu nv nw nx aw ny bi"><span id="a467" class="nz mh iq nv b gy oa ob l oc od"># This is crazy easy<br/>pd.get_dummies(data=df_pd, columns=["Symbol"]).head(1)</span></pre><p id="8e74" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated"><strong class="kt ir">考拉:</strong></p><pre class="kg kh ki kj gt nu nv nw nx aw ny bi"><span id="804b" class="nz mh iq nv b gy oa ob l oc od"># This is crazy easy too<br/>ks.get_dummies(data=df_ks, columns=["Symbol"]).head(1)</span></pre><p id="07f6" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated"><strong class="kt ir">火花(足够相似的结果，但做起来很恐怖):</strong></p><pre class="kg kh ki kj gt nu nv nw nx aw ny bi"><span id="374a" class="nz mh iq nv b gy oa ob l oc od"># I hate this<br/>from pyspark.ml.feature import StringIndexer,OneHotEncoderEstimator</span><span id="d2af" class="nz mh iq nv b gy oe ob l oc od">indexer = StringIndexer(inputCol="Symbol", outputCol="SymbolIndex")<br/>df_sp_indexed = indexer.fit(df_sp).transform(df_sp)</span><span id="78d8" class="nz mh iq nv b gy oe ob l oc od">encoder = OneHotEncoderEstimator(inputCols=["SymbolIndex"],<br/>                                 outputCols=["SymbolVec"])</span><span id="6f2b" class="nz mh iq nv b gy oe ob l oc od">model = encoder.fit(df_sp_indexed)<br/>df_sp_encoded = model.transform(df_sp_indexed)<br/>df_sp_encoded.show(1)</span></pre><p id="1660" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated"><strong class="kt ir">擎天柱(好一点但我还是更喜欢考拉这个):</strong></p><pre class="kg kh ki kj gt nu nv nw nx aw ny bi"><span id="49d8" class="nz mh iq nv b gy oa ob l oc od">from optimus.ml.feature import string_to_index, one_hot_encoder</span><span id="1e75" class="nz mh iq nv b gy oe ob l oc od">df_sp_indexed = string_to_index(df_sp, "Symbol")<br/>df_sp_encoded = one_hot_encoder(df_sp_indexed, "Symbol_index")<br/>df_sp_encoded.show()</span></pre><p id="b141" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">在这种情况下，更简单的方法来自熊猫，幸运的是它在考拉身上实现了，这种类型的功能在未来会增加，但现在这几乎是我们所有的功能，正如你在这里看到的:</p><div class="ln lo gp gr lp lq"><a href="https://koalas.readthedocs.io/en/latest/reference/general_functions.html" rel="noopener  ugc nofollow" target="_blank"><div class="lr ab fo"><div class="ls ab lt cl cj lu"><h2 class="bd ir gy z fp lv fr fs lw fu fw ip bi translated">一般功能-考拉 0.1.0 文档</h2><div class="lx l"><h3 class="bd b gy z fp lv fr fs lw fu fw dk translated">编辑描述</h3></div><div class="ly l"><p class="bd b dl z fp lv fr fs lw fu fw dk translated">考拉. readthedocs.io</p></div></div></div></a></div><p id="89fc" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">但是他们在火花中运行，所以它摇滚。</p><h2 id="148b" class="nz mh iq bd mi om on dn mm oo op dp mq la oq or ms le os ot mu li ou ov mw ow bi translated">情节:</h2><p id="94d6" class="pw-post-body-paragraph kr ks iq kt b ku oh jr kw kx oi ju kz la oj lc ld le ok lg lh li ol lk ll lm ij bi translated">绘图是数据分析的重要部分。对于熊猫，我们习惯于非常容易地绘制我们想要的任何东西，但是对于 Spark 来说，就没有那么容易了。我们很高兴地宣布，在最新版本的 Optimus (2.2.2)中，我们已经创建了一种直接从 Spark 数据帧创建绘图的方法，不需要子集化。</p><p id="f5ac" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">熊猫:</p><pre class="kg kh ki kj gt nu nv nw nx aw ny bi"><span id="8df0" class="nz mh iq nv b gy oa ob l oc od">df_pd.plot.scatter("Open","Volume")</span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ox"><img src="../Images/d0fc9df9a0dd061cfe1f01fdb7b2eb70.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*gCkTaSue7nf72L5BX3vxCg.png"/></div></div></figure><pre class="kg kh ki kj gt nu nv nw nx aw ny bi"><span id="c10a" class="nz mh iq nv b gy oa ob l oc od">df_pd.boxplot("High")</span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi oy"><img src="../Images/57acd964873eb123aa6d7751c1f3bf66.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*I_KY3YiStwSfU50JlK6JRA.png"/></div></div></figure><pre class="kg kh ki kj gt nu nv nw nx aw ny bi"><span id="ae7f" class="nz mh iq nv b gy oa ob l oc od">df_pd.hist("Low")</span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi oz"><img src="../Images/9277c477a88d578a14e9306f2d48d832.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*meMZ5oL4hh-4gnjCewGRlA.png"/></div></div></figure><p id="aa8d" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated"><strong class="kt ir">考拉:</strong></p><pre class="kg kh ki kj gt nu nv nw nx aw ny bi"><span id="16fb" class="nz mh iq nv b gy oa ob l oc od">df_ks.hist("Low")</span></pre><p id="f063" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">这样不行。</p><p id="4092" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated"><strong class="kt ir">火花:</strong></p><p id="a3f6" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">没有。</p><p id="362f" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated"><strong class="kt ir">擎天柱:</strong></p><pre class="kg kh ki kj gt nu nv nw nx aw ny bi"><span id="fa92" class="nz mh iq nv b gy oa ob l oc od">df_op.plot.boxplot(“High”)</span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi pa"><img src="../Images/d1020c2599a807a470ce9e3c8a1257cf.png" data-original-src="https://miro.medium.com/v2/resize:fit:812/format:webp/1*lcNPxquuSSFzVzemuRLpvw.png"/></div></figure><pre class="kg kh ki kj gt nu nv nw nx aw ny bi"><span id="ae2f" class="nz mh iq nv b gy oa ob l oc od">df_op.plot.hist(“Low”)</span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi pb"><img src="../Images/43465ba2613e901aedbd7961af313da9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*KqtY2Ux54M58qqX7uYxyMg.png"/></div></div></figure><pre class="kg kh ki kj gt nu nv nw nx aw ny bi"><span id="be63" class="nz mh iq nv b gy oa ob l oc od">df_op.plot.scatterplot(["Open","Volume"])</span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi pc"><img src="../Images/fe8578a8e0cf1273c569af94739a25e8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*KEoBaLSxHJFHstj8F132Vw.png"/></div></div></figure><h1 id="d7f4" class="mg mh iq bd mi mj mk ml mm mn mo mp mq jw mr jx ms jz mt ka mu kc mv kd mw mx bi translated">Apache Spark 3.x:</h1><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi pd"><img src="../Images/777217d76eef6e680c59d0cb1dd8f4ec.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*emVz9ocLE2-LqFHfeeBVFw.png"/></div></div><figcaption class="mz na gj gh gi nb nc bd b be z dk">databricks.com</figcaption></figure><p id="4b78" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">以下是对 Spark 3.x 的一些期望:</p><ul class=""><li id="efa9" class="ne nf iq kt b ku kv kx ky la ng le nh li ni lm nj nk nl nm bi translated">Scala 2.12 支持(列出两次)</li><li id="4068" class="ne nf iq kt b ku nn kx no la np le nq li nr lm nj nk nl nm bi translated">非实验性连续加工</li><li id="c7ed" class="ne nf iq kt b ku nn kx no la np le nq li nr lm nj nk nl nm bi translated">Kubernetes 支持非实验性</li><li id="2e70" class="ne nf iq kt b ku nn kx no la np le nq li nr lm nj nk nl nm bi translated">数据源 API v2 的更新版本</li><li id="fdda" class="ne nf iq kt b ku nn kx no la np le nq li nr lm nj nk nl nm bi translated">Hadoop 3.0 支持</li><li id="59ae" class="ne nf iq kt b ku nn kx no la np le nq li nr lm nj nk nl nm bi translated">提高 Spark 深度学习管道的可用性</li></ul><p id="1404" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">还有更多！</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi pe"><img src="../Images/74a198b206b0da589053a6c6f41acd55.png" data-original-src="https://miro.medium.com/v2/resize:fit:1104/format:webp/1*hGh2F1FOjyWV2nd-wzgQ9Q.png"/></div><figcaption class="mz na gj gh gi nb nc bd b be z dk">databricks.com</figcaption></figure><h1 id="761d" class="mg mh iq bd mi mj mk ml mm mn mo mp mq jw mr jx ms jz mt ka mu kc mv kd mw mx bi translated">结论</h1><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="pf pg l"/></div></figure><p id="3588" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">Spark 它正呈指数级增长，如果你现在没有使用它，你肯定应该使用它。通常你会来自熊猫或类似的地方，所以利用像考拉和擎天柱这样的伟大的库来改善你在数据科学世界中的生活。</p></div><div class="ab cl ph pi hu pj" role="separator"><span class="pk bw bk pl pm pn"/><span class="pk bw bk pl pm pn"/><span class="pk bw bk pl pm"/></div><div class="ij ik il im in"><p id="5822" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">如果您有任何问题，请在此写信给我:</p><div class="ln lo gp gr lp lq"><a href="https://www.linkedin.com/in/faviovazquez/" rel="noopener  ugc nofollow" target="_blank"><div class="lr ab fo"><div class="ls ab lt cl cj lu"><h2 class="bd ir gy z fp lv fr fs lw fu fw ip bi translated">法维奥·瓦兹奎——science y Datos | LinkedIn 创始人/首席数据科学家</h2><div class="lx l"><h3 class="bd b gy z fp lv fr fs lw fu fw dk translated">加入 LinkedIn ‼️‼️重要提示:由于 LinkedIn 技术限制，我现在只能接受连接请求…</h3></div><div class="ly l"><p class="bd b dl z fp lv fr fs lw fu fw dk translated">www.linkedin.com</p></div></div><div class="lz l"><div class="po l mb mc md lz me kp lq"/></div></div></a></div><p id="edf0" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">在推特上关注我:</p><div class="ln lo gp gr lp lq"><a href="https://twitter.com/faviovaz" rel="noopener  ugc nofollow" target="_blank"><div class="lr ab fo"><div class="ls ab lt cl cj lu"><h2 class="bd ir gy z fp lv fr fs lw fu fw ip bi translated">法维奥·巴斯克斯(@法维奥·巴斯克斯)|推特</h2><div class="lx l"><h3 class="bd b gy z fp lv fr fs lw fu fw dk translated">Favio Vázquez 的最新推文(@FavioVaz)。数据科学家。物理学家和计算工程师。我有一个…</h3></div><div class="ly l"><p class="bd b dl z fp lv fr fs lw fu fw dk translated">twitter.com</p></div></div><div class="lz l"><div class="pp l mb mc md lz me kp lq"/></div></div></a></div><p id="102b" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">祝学习愉快:)</p></div></div>    
</body>
</html>