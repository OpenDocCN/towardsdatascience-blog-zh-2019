<html>
<head>
<title>A one word reason why I support OpenAI’s GPT-2 decision: REDDIT</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">我支持 OpenAI 新 GPT 协议的一个原因是:REDDIT</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/reddit-a-one-word-reason-why-i-support-openais-gpt-2-decision-56b82912443c?source=collection_archive---------23-----------------------#2019-02-19">https://towardsdatascience.com/reddit-a-one-word-reason-why-i-support-openais-gpt-2-decision-56b82912443c?source=collection_archive---------23-----------------------#2019-02-19</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="a038" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">TLDR: <em class="kf">他们通过红迪网播种他们的网络搜索，红迪网是所有想法的宝库。因此，如果他们发布更大的型号，至少会是一场公关灾难。较小的 117 米是讨厌的，因为没有微妙的</em>！</h2></div><h2 id="cc6b" class="kg kh iq bd ki kj kk dn kl km kn dp ko kp kq kr ks kt ku kv kw kx ky kz la lb bi translated">目录</h2><ul class=""><li id="7289" class="lc ld iq le b lf lg lh li kp lj kt lk kx ll lm ln lo lp lq bi translated"><a class="ae lr" href="https://medium.com/p/56b82912443c#a038" rel="noopener"> TLDR: </a></li><li id="a00e" class="lc ld iq le b lf ls lh lt kp lu kt lv kx lw lm ln lo lp lq bi translated"><a class="ae lr" href="https://medium.com/p/56b82912443c#b435" rel="noopener">简介:</a></li><li id="1138" class="lc ld iq le b lf ls lh lt kp lu kt lv kx lw lm ln lo lp lq bi translated"><a class="ae lr" href="https://medium.com/p/56b82912443c#a40c" rel="noopener">核心问题:数据集管理</a></li><li id="4265" class="lc ld iq le b lf ls lh lt kp lu kt lv kx lw lm ln lo lp lq bi translated"><a class="ae lr" href="https://medium.com/p/56b82912443c#47ab" rel="noopener">无条件样本生成:不适合内心脆弱的人</a></li><li id="b3df" class="lc ld iq le b lf ls lh lt kp lu kt lv kx lw lm ln lo lp lq bi translated"><a class="ae lr" href="https://medium.com/p/56b82912443c#fc6f" rel="noopener">帖子脚本:</a></li></ul><h1 id="b435" class="lx kh iq bd ki ly lz ma kl mb mc md ko jw me jx ks jz mf ka kw kc mg kd la mh bi translated">简介:</h1><p id="1920" class="pw-post-body-paragraph mi mj iq le b lf lg jr mk lh li ju ml kp mm mn mo kt mp mq mr kx ms mt mu lm ij bi translated">我推荐我的实习生阅读的一篇论文是<em class="mv"> </em> <a class="ae lr" href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.208.2314&amp;rep=rep1&amp;type=pdf" rel="noopener ugc nofollow" target="_blank"> <em class="mv">不带偏见地看数据集偏见</em> </a> <em class="mv"> </em>，其中有一些很棒的介绍性文字:</p><figure class="mx my mz na gt nb gh gi paragraph-image"><div class="gh gi mw"><img src="../Images/18c81ce1768f4e539b1ec6b84e679fdb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1290/format:webp/1*nTQqqbfxpXR_zUhKYAByqQ.png"/></div><figcaption class="ne nf gj gh gi ng nh bd b be z dk">Torralba, Antonio, and Alexei A. Efros. “Unbiased look at dataset bias.” (2011): 1521–1528.</figcaption></figure><p id="142f" class="pw-post-body-paragraph mi mj iq le b lf ni jr mk lh nj ju ml kp nk mn mo kt nl mq mr kx nm mt mu lm ij bi translated">如果我可以补充的话，<strong class="le ir">没有非常仔细地整理这些数据也是一个致命的错误</strong>。考虑到这些天来(正当的)对数据集产生的<a class="ae lr" href="https://arxiv.org/pdf/1607.06520.pdf" rel="noopener ugc nofollow" target="_blank">偏见和有害特质</a>问题的关注，你会认为大型组织在开始像最近这篇引起轰动的<a class="ae lr" href="https://blog.openai.com/better-language-models/" rel="noopener ugc nofollow" target="_blank">论文</a>中那样雄心勃勃的冒险之前，应该对数据集收集程序的细节进行广泛的讨论。正如猜测的那样，架构建模中没有引入突破性的想法(作者也没有声称有),因此<em class="mv">pieèce de réstate</em>实际上是数据集的庞大、模型的庞大和训练模型的计算能力的庞大这三者的结合。</p><p id="a2cc" class="pw-post-body-paragraph mi mj iq le b lf ni jr mk lh nj ju ml kp nk mn mo kt nl mq mr kx nm mt mu lm ij bi translated">但事实证明，情况并非如此，这导致了一个模型，呈现了一种非常特殊的潜在的邪恶威胁，我们都可以没有它。为进一步澄清，标题应为:</p><p id="1f44" class="pw-post-body-paragraph mi mj iq le b lf ni jr mk lh nj ju ml kp nk mn mo kt nl mq mr kx nm mt mu lm ij bi translated">OpenAI 建立了一个文本生成器，s̶o̶ ̶g̶o̶o̶d̶在一个数据集上进行训练，这个数据集是如此不小心有毒和有效，以至于它被认为太危险而不能发布。 </p><p id="8b34" class="pw-post-body-paragraph mi mj iq le b lf ni jr mk lh nj ju ml kp nk mn mo kt nl mq mr kx nm mt mu lm ij bi translated">(那里！修好了！)</p><p id="ac0f" class="pw-post-body-paragraph mi mj iq le b lf ni jr mk lh nj ju ml kp nk mn mo kt nl mq mr kx nm mt mu lm ij bi translated">就其本身的学术价值而言，这篇论文充满了一些优秀的观点和见解，无论你是否专门研究 NLP，都值得从头到尾读一遍。除了被介绍到这个令人敬畏的<a class="ae lr" href="https://github.com/codelucas/newspaper" rel="noopener ugc nofollow" target="_blank">提取工具</a>之外，由于我个人对<em class="mv"> </em>字节级 LMs 的不满(这个问题可能会在另一篇博文中探讨)，当我通读关于<em class="mv">输入表示</em>的第 2.2 节时，我有一种个人的痛苦救赎感。不过，我必须承认，看到基于字节对编码(BPE)的方法在十亿字基准测试中惨败也令人失望，尤其是在阅读了第 2 部分之后:<em class="mv">当前的字节级 LMs 在大规模数据集(如十亿字基准测试</em>)上无法与字级 LMs 竞争</p><figure class="mx my mz na gt nb gh gi paragraph-image"><div class="gh gi nn"><img src="../Images/0c36fcbb26be5452af7394bd487a4492.png" data-original-src="https://miro.medium.com/v2/resize:fit:1316/format:webp/1*8BJYWou6ohwxyMC1Ok_Zxw.png"/></div><figcaption class="ne nf gj gh gi ng nh bd b be z dk">GPT-S’s waterloo: One Billion Word Benchmark</figcaption></figure><h1 id="a40c" class="lx kh iq bd ki ly lz ma kl mb mc md ko jw me jx ks jz mf ka kw kc mg kd la mh bi translated">核心问题:数据集监管</h1><p id="4150" class="pw-post-body-paragraph mi mj iq le b lf lg jr mk lh li ju ml kp mm mn mo kt mp mq mr kx ms mt mu lm ij bi translated">对我来说，论文的全部内容都在第二部分，它回答了我的两个主要问题。</p><p id="956f" class="pw-post-body-paragraph mi mj iq le b lf ni jr mk lh nj ju ml kp nk mn mo kt nl mq mr kx nm mt mu lm ij bi translated">a)他们如何管理数据集？</p><p id="c773" class="pw-post-body-paragraph mi mj iq le b lf ni jr mk lh nj ju ml kp nk mn mo kt nl mq mr kx nm mt mu lm ij bi translated">b)他们对此数据集使用了什么模型？——答案有点令人失望，对这篇博文没有意义。</p><p id="ca21" class="pw-post-body-paragraph mi mj iq le b lf ni jr mk lh nj ju ml kp nk mn mo kt nl mq mr kx nm mt mu lm ij bi translated">我收集到的 a)的答案至少让我感到有点不安，最终促使我同意 OpenAI 的立场，但原因完全不同。</p><p id="9534" class="pw-post-body-paragraph mi mj iq le b lf ni jr mk lh nj ju ml kp nk mn mo kt nl mq mr kx nm mt mu lm ij bi translated"><strong class="le ir">作者根据 R-E-D-D-I-T. </strong>创建了他们的数据集'<em class="mv"> WebText' </em></p><p id="b88d" class="pw-post-body-paragraph mi mj iq le b lf ni jr mk lh nj ju ml kp nk mn mo kt nl mq mr kx nm mt mu lm ij bi translated">用他们自己的话说:</p><blockquote class="no np nq"><p id="0fc8" class="mi mj mv le b lf ni jr mk lh nj ju ml nr nk mn mo ns nl mq mr nt nm mt mu lm ij bi translated">手动过滤一个完整的网络抓取会非常昂贵，因此作为一个起点，我们从社交媒体平台 Reddit 抓取了所有出站链接，该平台收到了至少 3 个 karma。这可以被认为是一个启发性的指标，表明其他用户是否觉得这个链接有趣、有教育意义或者仅仅是有趣。结果数据集 WebText 包含了这 4500 万个链接的文本子集。</p></blockquote><p id="b29c" class="pw-post-body-paragraph mi mj iq le b lf ni jr mk lh nj ju ml kp nk mn mo kt nl mq mr kx nm mt mu lm ij bi translated">这可能是因为我自己对 Reddit 又爱又恨的关系，但这听起来像是一部写得很差的拉姆齐兄弟电影的开始。你把一个拥有强大计算能力的庞大模型扔进了一个有毒的数据宝库，这个数据宝库是从 REDDIT 上收集的？</p><p id="9e5a" class="pw-post-body-paragraph mi mj iq le b lf ni jr mk lh nj ju ml kp nk mn mo kt nl mq mr kx nm mt mu lm ij bi translated">请参考下面这些<strong class="le ir">同行评审的</strong>关于该平台毒性的研究论文:</p><figure class="mx my mz na gt nb gh gi paragraph-image"><div role="button" tabindex="0" class="nv nw di nx bf ny"><div class="gh gi nu"><img src="../Images/36f0a0cee3edb02b1da43852c9763c6c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*gIEs5vx9nKHDk3DvrSPcwA.png"/></div></div><figcaption class="ne nf gj gh gi ng nh bd b be z dk">Source: <a class="ae lr" href="https://journals.sagepub.com/doi/abs/10.1177/1461444815608807" rel="noopener ugc nofollow" target="_blank">https://journals.sagepub.com/doi/abs/10.1177/1461444815608807</a> , <a class="ae lr" href="https://www.researchgate.net/profile/Thalia_Field2/publication/316940579_Domain_Adaptation_for_Detecting_Mild_Cognitive_Impairment/links/5a45372c458515f6b05477c2/Domain-Adaptation-for-Detecting-Mild-Cognitive-Impairment.pdf#page=65" rel="noopener ugc nofollow" target="_blank">https://www.researchgate.net/profile/Thalia_Field2/publication/316940579_Domain_Adaptation_for_Detecting_Mild_Cognitive_Impairment/links/5a45372c458515f6b05477c2/Domain-Adaptation-for-Detecting-Mild-Cognitive-Impairment.pdf#page=65</a></figcaption></figure><p id="255c" class="pw-post-body-paragraph mi mj iq le b lf ni jr mk lh nj ju ml kp nk mn mo kt nl mq mr kx nm mt mu lm ij bi translated">reddit 的事业和最终被投票通过的东西构成了一个坏主意的主矿脉和坏主意的链接。这种数据集构建努力充满了令人不快的上下文生成的高风险，尤其是如果我试图从 LM 中<em class="mv">生成无条件样本</em>的话。</p><p id="5d6b" class="pw-post-body-paragraph mi mj iq le b lf ni jr mk lh nj ju ml kp nk mn mo kt nl mq mr kx nm mt mu lm ij bi translated">哦等等！</p><figure class="mx my mz na gt nb gh gi paragraph-image"><div class="gh gi nz"><img src="../Images/0345e0e2f7c2aa2e7e173d95992581da.png" data-original-src="https://miro.medium.com/v2/resize:fit:1104/format:webp/1*g3ptEYeoNZveNiFiyF6GzA.png"/></div><figcaption class="ne nf gj gh gi ng nh bd b be z dk">Source: <a class="ae lr" href="https://github.com/openai/gpt-2" rel="noopener ugc nofollow" target="_blank">https://github.com/openai/gpt-2</a></figcaption></figure><p id="e022" class="pw-post-body-paragraph mi mj iq le b lf ni jr mk lh nj ju ml kp nk mn mo kt nl mq mr kx nm mt mu lm ij bi translated">出于好奇，如果这种恐惧真的会转化为文字(这是一个糟糕的双关语)，我下载并玩了他们通过 github 页面<a class="ae lr" href="https://github.com/openai/gpt-2" rel="noopener ugc nofollow" target="_blank">在这里</a>适时分享的较小(117M 参数)版本的 GPT-2。</p><h1 id="47ab" class="lx kh iq bd ki ly lz ma kl mb mc md ko jw me jx ks jz mf ka kw kc mg kd la mh bi translated">无条件样本生成:不适合内心脆弱的人</h1><p id="6577" class="pw-post-body-paragraph mi mj iq le b lf lg jr mk lh li ju ml kp mm mn mo kt mp mq mr kx ms mt mu lm ij bi translated">令我懊恼的是，这个小模型生成的许多样本与研究人员对 Reddit 的担心非常接近。</p><blockquote class="no np nq"><p id="cf6d" class="mi mj mv le b lf ni jr mk lh nj ju ml nr nk mn mo ns nl mq mr nt nm mt mu lm ij bi translated">在这个问题上，自由主义者也在试图切断他们自己意识形态学术的刺痛。考虑公开转基因玉米，因为它有隐藏的但有价值的价值(减少个体的机会和工作机会)。在非经济学家看来(许多登山者在可能的情况下会求助于无偿的外交服务基金)，啤酒和华夫饼在一段时间内供应给所有性别的军事化男性倡导者。支持堕胎权利的保守告密者、藏人和被强奸的平民很可能包括在这些伪激进分子的诽谤活动中，那么这引发了什么政治问题呢？许多年来，我们对左派的信念感到不安，他们认为奴隶制度结束后，人类对男人的第一个嗜好是高潮或金钱。我们试图忘记地球上的男人是如何变得不依赖于绿帽子或江湖骗子，只是。</p></blockquote><p id="2640" class="pw-post-body-paragraph mi mj iq le b lf ni jr mk lh nj ju ml kp nk mn mo kt nl mq mr kx nm mt mu lm ij bi translated">还有这个！</p><p id="f735" class="pw-post-body-paragraph mi mj iq le b lf ni jr mk lh nj ju ml kp nk mn mo kt nl mq mr kx nm mt mu lm ij bi translated"><em class="mv">男性杰特——所以他们中的许多人住在乐购，包括木炭烧烤店的程序员和员工，以及手无寸铁的社交瘾君子凯西·布里格斯(Kathy Briggs ),他们有 1000 份工作，来自 DW 车站、海洛因注射、漂亮的发型和酒吧学习日。</em></p><p id="8035" class="pw-post-body-paragraph mi mj iq le b lf ni jr mk lh nj ju ml kp nk mn mo kt nl mq mr kx nm mt mu lm ij bi translated">稍微用谷歌搜索一下，就会发现“<em class="mv">瘾君子”+“凯西·布里格斯”</em>唯一同时出现的是<a class="ae lr" href="http://www.fairfaxtimes.com/articles/fairfax_county/fairfax-family-making-a-difference-after-son-s-heroin-overdose/article_e96bbba6-ae67-11e5-83ae-23b4dc37ea13.html" rel="noopener ugc nofollow" target="_blank">这个</a>令人揪心的故事，讲的是费尔法克斯的某个凯西·布里格斯与她 21 岁的儿子因吸食海洛因过量而死亡的事情。</p><p id="346d" class="pw-post-body-paragraph mi mj iq le b lf ni jr mk lh nj ju ml kp nk mn mo kt nl mq mr kx nm mt mu lm ij bi translated">以下是其他一些热门话题:</p><blockquote class="no np nq"><p id="de90" class="mi mj mv le b lf ni jr mk lh nj ju ml nr nk mn mo ns nl mq mr nt nm mt mu lm ij bi translated">“对孕妇来说，最大的障碍之一是耻辱感。他们是不明智的人无法跳出的中心，”斯奈德周三在 8 月份援引的州议会网站上说，此前全国各地收容机构的有毒堕胎导致州立医院比去年多 10 人死亡。(至少那些人指责诊所大量解剖患病女性的尸体，造成了数千人的死亡</p></blockquote><p id="9092" class="pw-post-body-paragraph mi mj iq le b lf ni jr mk lh nj ju ml kp nk mn mo kt nl mq mr kx nm mt mu lm ij bi translated">..而且，</p><blockquote class="no np nq"><p id="b908" class="mi mj mv le b lf ni jr mk lh nj ju ml nr nk mn mo ns nl mq mr nt nm mt mu lm ij bi translated">2014 年，同性恋权利活动人士向民主党人提出了同样的论点，呼吁帕利特卡支持该法案，而不是推动它。“罗马尼亚需要一个坚实的南部国会侧翼，以沿着同样的路线‘建立反对和争取时间’，更不用说小心了，”社会正义基金(Social Justice Fund)LGBT 倡议主任阿德里亚诺·罗梅罗(Adriano Romero)告诉波兰人 RT . DGA(RT . Roberto)，嗯，这是指特别是猴子和猿；她还提到了支持 longs 的 Janus Djiman 的快速投票。“罗马尼亚仍然需要一支军队:在种族清洗运动中，3000 名蒙面掠夺者推翻了阿布杜库的亡命之徒；来自 Takeshi Sada 的狂欢节杀手，我们预定他淹死我们的 50 名人民，他来自 Julian Viper(埃塞俄比亚君主制的刽子手，死于 1999 年，据信他曾在那里卖淫)和 Kerry Mackey(他通过酷刑对 11 名儿童进行了性虐待)。甚至还有(你可以注意到这个比喻)7-24 周的假期和婴儿洗澡人员的能力，特别是当他们的具体原因仍然是模糊的阿塔维移民在国外颁布法令反对同性恋。“这是一个关键问题，”她说，为沙龙写作。作为拉丁血统和分离其海洋民族，意大利和韩国，表明欧洲人从来没有在没有“鼓励”他们加入黑人运动的情况下，用白色女性泡沫塑料样的形式运送成年人向他们自己的“南方”移动，包括 LGBTQ 社区。"</p></blockquote><p id="0c3b" class="pw-post-body-paragraph mi mj iq le b lf ni jr mk lh nj ju ml kp nk mn mo kt nl mq mr kx nm mt mu lm ij bi translated">这至少构成了一个很好的理由，为什么我现在非常赞同作者不发布更大的模型/代码的决定。T3】</p><p id="92b7" class="pw-post-body-paragraph mi mj iq le b lf ni jr mk lh nj ju ml kp nk mn mo kt nl mq mr kx nm mt mu lm ij bi translated">如果附录中精选的例子是可靠的(例如，见下面的例子)，我认为作者没有发布 1.5B 模型确实是合理的。一个危险的有毒来源及其所有的政治含义和微妙之处与大模型和大计算的肌肉力量相结合，是一个等待释放的武器。</p><figure class="mx my mz na gt nb gh gi paragraph-image"><div class="gh gi oa"><img src="../Images/83ff16d5d2321d1dec20be402dceb82b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1318/format:webp/1*HZ0nRJbUiwG9WHUXcrxQzQ.png"/></div></figure><p id="b52c" class="pw-post-body-paragraph mi mj iq le b lf ni jr mk lh nj ju ml kp nk mn mo kt nl mq mr kx nm mt mu lm ij bi translated">如果作者也能在训练模型之前阐明他们使用的“启发式清理”程序，那将是非常有用的。</p><figure class="mx my mz na gt nb gh gi paragraph-image"><div role="button" tabindex="0" class="nv nw di nx bf ny"><div class="gh gi ob"><img src="../Images/1cf21ff34dda9aa69b0a36a1784eb814.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*otrYTidPgw8hR6RippSjow.png"/></div></div></figure><p id="4ed7" class="pw-post-body-paragraph mi mj iq le b lf ni jr mk lh nj ju ml kp nk mn mo kt nl mq mr kx nm mt mu lm ij bi translated">我想用一个相当简单的问题来结束这篇博客/长篇大论:当有人提出这个问题时，难道没有经过深思熟虑吗..<em class="mv">因此，作为一个起点，我们从社交媒体平台 Reddit 上抓取了所有的外部链接，这至少收到了 3 个因果报应。这可以被认为是一个启发性的指标，其他用户是否觉得这个链接有趣，有教育意义，或者仅仅是有趣？</em></p><p id="b467" class="pw-post-body-paragraph mi mj iq le b lf ni jr mk lh nj ju ml kp nk mn mo kt nl mq mr kx nm mt mu lm ij bi translated">在开始这项显然是巨大而昂贵的工作之前，难道没有考虑过这种数据集播种的危险吗*在此插入 interrobang</p><p id="c496" class="pw-post-body-paragraph mi mj iq le b lf ni jr mk lh nj ju ml kp nk mn mo kt nl mq mr kx nm mt mu lm ij bi translated">PS:链接到我的笔记本，上面引用了示例文本:</p><div class="oc od gp gr oe of"><a href="https://colab.research.google.com/drive/1WtSGPDduf7hffoN6vp4LFaXc6PqAqoJB" rel="noopener  ugc nofollow" target="_blank"><div class="og ab fo"><div class="oh ab oi cl cj oj"><h2 class="bd ir gy z fp ok fr fs ol fu fw ip bi translated">谷歌联合实验室</h2><div class="om l"><h3 class="bd b gy z fp ok fr fs ol fu fw dk translated">编辑描述</h3></div><div class="on l"><p class="bd b dl z fp ok fr fs ol fu fw dk translated">colab.research.google.com</p></div></div><div class="oo l"><div class="op l oq or os oo ot nc of"/></div></div></a></div><h1 id="fc6f" class="lx kh iq bd ki ly lz ma kl mb mc md ko jw me jx ks jz mf ka kw kc mg kd la mh bi translated">发布脚本:</h1><p id="1760" class="pw-post-body-paragraph mi mj iq le b lf lg jr mk lh li ju ml kp mm mn mo kt mp mq mr kx ms mt mu lm ij bi translated">我想把另一个小问题解决掉。</p><p id="a56a" class="pw-post-body-paragraph mi mj iq le b lf ni jr mk lh nj ju ml kp nk mn mo kt nl mq mr kx nm mt mu lm ij bi translated">像 OpenAI 这样资金充足的行业实验室，表面上有一群聪明人进行内部审查，兜售有拼写错误和滥用符号的论文，这种想法实在是令人作呕。还有，耶稣基督，你怎么能把一个语言模型的等式第一号弄错呢？</p><figure class="mx my mz na gt nb gh gi paragraph-image"><div class="gh gi ou"><img src="../Images/0634c7fed1598a67100823e8a2c4b107.png" data-original-src="https://miro.medium.com/v2/resize:fit:1100/format:webp/1*cr5gjjyWpCISBIZtQBx5ZQ.png"/></div><figcaption class="ne nf gj gh gi ng nh bd b be z dk">First of ‘ma<strong class="bd ov">N</strong>y’</figcaption></figure><figure class="mx my mz na gt nb gh gi paragraph-image"><div role="button" tabindex="0" class="nv nw di nx bf ny"><div class="gh gi ow"><img src="../Images/7e07003f1fef62711840592b7eef1343.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*-wXskVabN0tLCCEhYN5FyQ.png"/></div></div><figcaption class="ne nf gj gh gi ng nh bd b be z dk">Source: <a class="ae lr" href="https://arxiv.org/pdf/1404.3377.pdf" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/pdf/1404.3377.pdf</a></figcaption></figure><p id="043c" class="pw-post-body-paragraph mi mj iq le b lf ni jr mk lh nj ju ml kp nk mn mo kt nl mq mr kx nm mt mu lm ij bi translated">下标中那个可怜的小<em class="mv"> i </em>从来没有看到它的到来。也许是确认偏差，但这是一种趋势吗？不久前，这个小小的<em class="mv"> i </em>的希腊表亲($\theta$)在 OpenAI 的另一篇论文中也遭到了猛烈抨击(尽管这是一篇非常好的论文)。读一下吧！).</p><figure class="mx my mz na gt nb gh gi paragraph-image"><div class="gh gi ox"><img src="../Images/e2a10298154118beebe2040772f91f64.png" data-original-src="https://miro.medium.com/v2/resize:fit:402/format:webp/1*7EbTsyxFTKg0kig55yyWjQ.png"/></div><figcaption class="ne nf gj gh gi ng nh bd b be z dk">Source: The trolling of theta — Source: <a class="ae lr" href="https://arxiv.org/pdf/1807.03039.pdf" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/pdf/1807.03039.pdf</a></figcaption></figure><p id="7134" class="pw-post-body-paragraph mi mj iq le b lf ni jr mk lh nj ju ml kp nk mn mo kt nl mq mr kx nm mt mu lm ij bi translated">我在我办公桌的乱七八糟的地方翻出了打印稿，以下是我的确切反应:</p><figure class="mx my mz na gt nb gh gi paragraph-image"><div role="button" tabindex="0" class="nv nw di nx bf ny"><div class="gh gi oy"><img src="../Images/ea59d8edc8ff11a271e28ce742dd4e85.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*fNt0L8EUB8x702-PkgrAjQ.png"/></div></div><figcaption class="ne nf gj gh gi ng nh bd b be z dk">Must be a real scary space for subscripts this place</figcaption></figure><p id="98a6" class="pw-post-body-paragraph mi mj iq le b lf ni jr mk lh nj ju ml kp nk mn mo kt nl mq mr kx nm mt mu lm ij bi translated">我明白了。这些都是造成小伤害的小错误，但即使是一个铁杆粉丝也必须承认，当这些与投入公关努力的所有精力并列时，确实使它至少有点值得一看。没有吗？</p></div></div>    
</body>
</html>