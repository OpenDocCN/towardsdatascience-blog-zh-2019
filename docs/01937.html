<html>
<head>
<title>Building efficient data pipelines using TensorFlow</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用 TensorFlow 构建高效的数据管道</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/building-efficient-data-pipelines-using-tensorflow-8f647f03b4ce?source=collection_archive---------2-----------------------#2019-03-31">https://towardsdatascience.com/building-efficient-data-pipelines-using-tensorflow-8f647f03b4ce?source=collection_archive---------2-----------------------#2019-03-31</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><p id="41ae" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">拥有高效的数据管道对于任何机器学习模型都是至关重要的。在这篇博客中，我们将学习如何使用 TensorFlow 的数据集模块<code class="fe kl km kn ko b">tf.data</code>来构建高效的数据管道。</p><figure class="kq kr ks kt gt ku gh gi paragraph-image"><div class="gh gi kp"><img src="../Images/af90bfa37a0fab0135cdf4f1c0b0cf57.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*3pf3BewrY0L_8gECmKKqlw.png"/></div><figcaption class="kx ky gj gh gi kz la bd b be z dk"><a class="ae lb" href="https://www.tensorflow.org/guide/performance/datasets" rel="noopener ugc nofollow" target="_blank">https://www.tensorflow.org/guide/performance/datasets</a></figcaption></figure><h2 id="4d0a" class="lc ld iq bd le lf lg dn lh li lj dp lk jy ll lm ln kc lo lp lq kg lr ls lt lu bi translated">动机</h2><p id="5f25" class="pw-post-body-paragraph jn jo iq jp b jq lv js jt ju lw jw jx jy lx ka kb kc ly ke kf kg lz ki kj kk ij bi translated">大多数关于 TensorFlow 的介绍性文章都会向您介绍将数据输入模型的<code class="fe kl km kn ko b">feed_dict</code>方法。<code class="fe kl km kn ko b">feed_dict</code>在单线程中处理输入数据，当数据在 CPU 上加载和处理时，GPU 保持空闲，当 GPU 正在训练一批数据时，CPU 保持空闲状态。TensorFlow 的开发者建议不要在相同数据集的训练或重复验证过程中使用这种方法。</p><figure class="kq kr ks kt gt ku gh gi paragraph-image"><div role="button" tabindex="0" class="mb mc di md bf me"><div class="gh gi ma"><img src="../Images/fc4a2be3d8cc4185cf691907e78d33ed.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*xJBrmPZm0LPDkQXt8WBXuQ.png"/></div></div></figure><p id="86c4" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><code class="fe kl km kn ko b">tf_data</code>通过异步预取下一批数据来提高性能，使 GPU 无需等待数据。您还可以并行处理数据集的预处理和加载过程。</p><figure class="kq kr ks kt gt ku gh gi paragraph-image"><div role="button" tabindex="0" class="mb mc di md bf me"><div class="gh gi mf"><img src="../Images/330b2e959d160ba5bac13222dfd07840.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*o6QsRtkDZKj8E5W6rJe3Bw.png"/></div></div></figure><p id="ea14" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">在这篇博文中，我们将介绍<code class="fe kl km kn ko b">Datasets</code>和<code class="fe kl km kn ko b">Iterators</code>。我们将学习如何从源数据创建数据集，将转换应用到数据集，然后使用迭代器消费数据。</p><h1 id="569c" class="mg ld iq bd le mh mi mj lh mk ml mm lk mn mo mp ln mq mr ms lq mt mu mv lt mw bi translated">如何创建数据集？</h1><p id="b3a4" class="pw-post-body-paragraph jn jo iq jp b jq lv js jt ju lw jw jx jy lx ka kb kc ly ke kf kg lz ki kj kk ij bi translated">Tensorflow 提供了各种方法来从 numpy 数组、文本文件、CSV 文件、张量等创建数据集。让我们看看下面的几种方法</p><ul class=""><li id="b55b" class="mx my iq jp b jq jr ju jv jy mz kc na kg nb kk nc nd ne nf bi translated"><strong class="jp ir"> from_tensor_slices: </strong>它接受单个或多个 numpy 数组或张量。使用此方法创建的数据集一次只会发出一个数据。</li></ul><pre class="kq kr ks kt gt ng ko nh ni aw nj bi"><span id="2cd2" class="lc ld iq ko b gy nk nl l nm nn"># source data - numpy array<br/>data = np.arange(10)</span><span id="ee46" class="lc ld iq ko b gy no nl l nm nn"># create a dataset from numpy array<br/>dataset = tf.data.Dataset.from_tensor_slices(data)</span></pre><p id="4203" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">对象<code class="fe kl km kn ko b">dataset</code>是一个 tensorflow 数据集对象。</p><ul class=""><li id="1c62" class="mx my iq jp b jq jr ju jv jy mz kc na kg nb kk nc nd ne nf bi translated"><strong class="jp ir"> from_tensors: </strong>它也接受单个或多个 numpy 数组或 tensor。使用此方法创建的数据集将一次发出所有数据。</li></ul><pre class="kq kr ks kt gt ng ko nh ni aw nj bi"><span id="1820" class="lc ld iq ko b gy nk nl l nm nn">data = tf.arange(10)<br/>dataset = tf.data.Dataset.from_tensors(data)</span></pre><p id="51b5" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">3.<strong class="jp ir"> from_generator: </strong>创建一个数据集，其元素由函数生成。</p><pre class="kq kr ks kt gt ng ko nh ni aw nj bi"><span id="fdd4" class="lc ld iq ko b gy nk nl l nm nn">def generator():<br/>  for i in range(10):<br/>    yield 2*i<br/>    <br/>dataset = tf.data.Dataset.from_generator(generator, (tf.int32))</span></pre><h1 id="b4b8" class="mg ld iq bd le mh mi mj lh mk ml mm lk mn mo mp ln mq mr ms lq mt mu mv lt mw bi translated">数据集上的操作</h1><ul class=""><li id="44ea" class="mx my iq jp b jq lv ju lw jy np kc nq kg nr kk nc nd ne nf bi translated"><strong class="jp ir">批处理:</strong>将数据集的连续元素合并成一个批处理。当您想要训练较小批次的数据以避免内存不足错误时，这很有用。</li></ul><pre class="kq kr ks kt gt ng ko nh ni aw nj bi"><span id="f020" class="lc ld iq ko b gy nk nl l nm nn">data = np.arange(10,40)</span><span id="05f5" class="lc ld iq ko b gy no nl l nm nn"># create batches of 10<br/>dataset = tf.data.Dataset.from_tensor_slices(data).batch(10)</span><span id="192c" class="lc ld iq ko b gy no nl l nm nn"># creates the iterator to consume the data <br/>iterator = dataset.make_one_shot_iterator()<br/>next_ele = iterator.get_next()</span><span id="201b" class="lc ld iq ko b gy no nl l nm nn">with tf.Session() as sess:<br/>  try:<br/>    while True:<br/>      val = sess.run(next_ele)<br/>      print(val)<br/>  except tf.errors.OutOfRangeError:<br/>    pass</span></pre><p id="fe0e" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">您可以跳过创建迭代器并打印数据集元素的代码。我们将在本博客的后面部分详细了解迭代器。输出是:</p><pre class="kq kr ks kt gt ng ko nh ni aw nj bi"><span id="61e0" class="lc ld iq ko b gy nk nl l nm nn">[10 11 12 13 14 15 16 17 18 19] <br/>[20 21 22 23 24 25 26 27 28 29] <br/>[30 31 32 33 34 35 36 37 38 39]</span></pre><ul class=""><li id="9368" class="mx my iq jp b jq jr ju jv jy mz kc na kg nb kk nc nd ne nf bi translated"><strong class="jp ir"> Zip: </strong>通过压缩数据集来创建数据集。在具有要素和标注并且需要提供要素和标注对来训练模型的情况下非常有用。</li></ul><pre class="kq kr ks kt gt ng ko nh ni aw nj bi"><span id="0137" class="lc ld iq ko b gy nk nl l nm nn">datax = np.arange(10,20)<br/>datay = np.arange(11,21)</span><span id="198a" class="lc ld iq ko b gy no nl l nm nn">datasetx = tf.data.Dataset.from_tensor_slices(datax)<br/>datasety = tf.data.Dataset.from_tensor_slices(datay)</span><span id="0106" class="lc ld iq ko b gy no nl l nm nn">dcombined = tf.data.Dataset.zip((datasetx, datasety)).batch(2)<br/>iterator = dcombined.make_one_shot_iterator()<br/>next_ele = iterator.get_next()</span><span id="a6b4" class="lc ld iq ko b gy no nl l nm nn">with tf.Session() as sess:<br/>  try:<br/>    while True:<br/>      val = sess.run(next_ele)<br/>      print(val)<br/>  except tf.errors.OutOfRangeError:<br/>    pass</span></pre><p id="05c5" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">输出是</p><pre class="kq kr ks kt gt ng ko nh ni aw nj bi"><span id="4098" class="lc ld iq ko b gy nk nl l nm nn">(array([10, 11]), array([11, 12])) <br/>(array([12, 13]), array([13, 14])) <br/>(array([14, 15]), array([15, 16])) <br/>(array([16, 17]), array([17, 18])) <br/>(array([18, 19]), array([19, 20]))</span></pre><ul class=""><li id="ea92" class="mx my iq jp b jq jr ju jv jy mz kc na kg nb kk nc nd ne nf bi translated"><strong class="jp ir">重复:</strong>用于重复数据集。</li></ul><pre class="kq kr ks kt gt ng ko nh ni aw nj bi"><span id="1056" class="lc ld iq ko b gy nk nl l nm nn">dataset = tf.data.Dataset.from_tensor_slices(tf.range(10))<br/>dataset = dataset.repeat(count=2)<br/>iterator = dataset.make_one_shot_iterator()<br/>next_ele = iterator.get_next()</span><span id="608c" class="lc ld iq ko b gy no nl l nm nn">with tf.Session() as sess:<br/>  try:<br/>    while True:<br/>      val = sess.run(next_ele)<br/>      print(val)<br/>  except tf.errors.OutOfRangeError:<br/>    pass</span></pre><p id="a2fd" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">输出是</p><pre class="kq kr ks kt gt ng ko nh ni aw nj bi"><span id="035f" class="lc ld iq ko b gy nk nl l nm nn">0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9</span></pre><ul class=""><li id="d47c" class="mx my iq jp b jq jr ju jv jy mz kc na kg nb kk nc nd ne nf bi translated"><strong class="jp ir"> Map: </strong>用于变换数据集的元素。如果您希望在将原始数据输入到模型中之前对其进行转换，这将非常有用。</li></ul><pre class="kq kr ks kt gt ng ko nh ni aw nj bi"><span id="11e5" class="lc ld iq ko b gy nk nl l nm nn">def map_fnc(x):<br/>  return x*2;</span><span id="6257" class="lc ld iq ko b gy no nl l nm nn">data = np.arange(10)<br/>dataset = tf.data.Dataset.from_tensor_slices(data)<br/>dataset = dataset.map(map_fnc)</span><span id="3fe4" class="lc ld iq ko b gy no nl l nm nn">iterator = dataset.make_one_shot_iterator()<br/>next_ele = iterator.get_next()</span><span id="7d28" class="lc ld iq ko b gy no nl l nm nn">with tf.Session() as sess:<br/>  try:<br/>    while True:<br/>      val = sess.run(next_ele)<br/>      print(val)<br/>  except tf.errors.OutOfRangeError:<br/>    pass</span></pre><p id="4d4e" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">输出是</p><pre class="kq kr ks kt gt ng ko nh ni aw nj bi"><span id="1fa9" class="lc ld iq ko b gy nk nl l nm nn">0 2 4 6 8 10 12 14 16 18</span></pre><h1 id="67fc" class="mg ld iq bd le mh mi mj lh mk ml mm lk mn mo mp ln mq mr ms lq mt mu mv lt mw bi translated">创建迭代器</h1><p id="55f7" class="pw-post-body-paragraph jn jo iq jp b jq lv js jt ju lw jw jx jy lx ka kb kc ly ke kf kg lz ki kj kk ij bi translated">我们已经学习了创建数据集和应用各种转换的各种方法，但是我们如何消费数据呢？Tensorflow 提供了<code class="fe kl km kn ko b">Iterators</code>来做到这一点。</p><p id="ada7" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">迭代器不知道数据集中存在的元素数量。它有一个<code class="fe kl km kn ko b">get_next</code>函数，用于在 tensorflow 图中创建一个操作，当在一个会话上运行时，它将从迭代器返回值。一旦数据集用尽，就会抛出一个<code class="fe kl km kn ko b">tf.errors.OutOfRangeError</code>异常。</p><p id="4414" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我们来看看 TensorFlow 提供的各种<code class="fe kl km kn ko b">Iterators</code>。</p><ul class=""><li id="ac27" class="mx my iq jp b jq jr ju jv jy mz kc na kg nb kk nc nd ne nf bi translated"><strong class="jp ir">一次性迭代器:</strong>这是迭代器最基本的形式。它不需要显式初始化，只对数据迭代一次，一旦用完，就无法重新初始化。</li></ul><pre class="kq kr ks kt gt ng ko nh ni aw nj bi"><span id="a06e" class="lc ld iq ko b gy nk nl l nm nn">data = np.arange(10,15)</span><span id="1683" class="lc ld iq ko b gy no nl l nm nn">#create the dataset<br/>dataset = tf.data.Dataset.from_tensor_slices(data)</span><span id="1593" class="lc ld iq ko b gy no nl l nm nn">#create the iterator<br/>iterator = dataset.make_one_shot_iterator()<br/>next_element = iterator.get_next()<br/>with tf.Session() as sess:<br/>  val = sess.run(next_element)<br/>  print(val)</span></pre><ul class=""><li id="e8a9" class="mx my iq jp b jq jr ju jv jy mz kc na kg nb kk nc nd ne nf bi translated"><strong class="jp ir">可初始化迭代器:</strong>这个迭代器要求你通过运行<code class="fe kl km kn ko b">iterator.initialize.</code>显式初始化迭代器。你可以定义一个<code class="fe kl km kn ko b">tf.placeholder</code>，并在每次调用初始化操作时动态地传递数据给它。</li></ul><pre class="kq kr ks kt gt ng ko nh ni aw nj bi"><span id="6001" class="lc ld iq ko b gy nk nl l nm nn"># define two placeholders to accept min and max value<br/>min_val = tf.placeholder(tf.int32, shape=[])<br/>max_val = tf.placeholder(tf.int32, shape=[])</span><span id="2e44" class="lc ld iq ko b gy no nl l nm nn">data = tf.range(min_val, max_val)</span><span id="c218" class="lc ld iq ko b gy no nl l nm nn">dataset = tf.data.Dataset.from_tensor_slices(data)</span><span id="84ac" class="lc ld iq ko b gy no nl l nm nn">iterator = dataset.make_initializable_iterator()<br/>next_ele = iterator.get_next()<br/>with tf.Session() as sess:<br/>  <br/>  <strong class="ko ir"># initialize an iterator with range of values from 10 to 15</strong><br/>  sess.run(iterator.initializer, feed_dict={min_val:10, max_val:15})<br/>  try:<br/>    while True:<br/>      val = sess.run(next_ele)<br/>      print(val)<br/>  except tf.errors.OutOfRangeError:<br/>    pass<br/>      <br/>  <strong class="ko ir"># initialize an iterator with range of values from 1 to 10</strong><br/>  sess.run(iterator.initializer, feed_dict={min_val:1, max_val:10})<br/>  try:<br/>    while True:<br/>      val = sess.run(next_ele)<br/>      print(val)<br/>  except tf.errors.OutOfRangeError:<br/>    pass</span></pre><ul class=""><li id="d928" class="mx my iq jp b jq jr ju jv jy mz kc na kg nb kk nc nd ne nf bi translated"><strong class="jp ir">可重新初始化的迭代器:</strong>这个迭代器可以从结构相同的不同 Dataset 对象初始化。每个数据集都可以通过自己的转换管道。</li></ul><pre class="kq kr ks kt gt ng ko nh ni aw nj bi"><span id="7c50" class="lc ld iq ko b gy nk nl l nm nn">def map_fnc(ele):<br/>  return ele*2</span><span id="532c" class="lc ld iq ko b gy no nl l nm nn">min_val = tf.placeholder(tf.int32, shape=[])<br/>max_val = tf.placeholder(tf.int32, shape=[])<br/>data = tf.range(min_val, max_val)</span><span id="0a1b" class="lc ld iq ko b gy no nl l nm nn">#Define separate datasets for training and validation<br/>train_dataset =  tf.data.Dataset.from_tensor_slices(data)<br/>val_dataset = tf.data.Dataset.from_tensor_slices(data).map(map_fnc)</span><span id="0460" class="lc ld iq ko b gy no nl l nm nn">#create an iterator <br/>iterator=tf.data.Iterator.from_structure(train_dataset.output_types    ,train_dataset.output_shapes)</span><span id="3741" class="lc ld iq ko b gy no nl l nm nn">train_initializer = iterator.make_initializer(train_dataset)<br/>val_initializer = iterator.make_initializer(val_dataset)</span><span id="51d1" class="lc ld iq ko b gy no nl l nm nn">next_ele = iterator.get_next()<br/>with tf.Session() as sess:<br/>  <br/>  # initialize an iterator with range of values from 10 to 15<br/>  sess.run(train_initializer, feed_dict={min_val:10, max_val:15})<br/>  try:<br/>    while True:<br/>      val = sess.run(next_ele)<br/>      print(val)<br/>  except tf.errors.OutOfRangeError:<br/>    pass<br/>      <br/>  # initialize an iterator with range of values from 1 to 10<br/>  sess.run(val_initializer, feed_dict={min_val:1, max_val:10})<br/>  try:<br/>    while True:<br/>      val = sess.run(next_ele)<br/>      print(val)<br/>  except tf.errors.OutOfRangeError:<br/>    pass</span></pre><ul class=""><li id="d677" class="mx my iq jp b jq jr ju jv jy mz kc na kg nb kk nc nd ne nf bi translated"><strong class="jp ir"> Feedable 迭代器:</strong>可以用来在不同数据集的迭代器之间切换。当您有不同的数据集，并且您想要对数据集使用哪个迭代器有更多的控制时，这很有用。</li></ul><pre class="kq kr ks kt gt ng ko nh ni aw nj bi"><span id="9208" class="lc ld iq ko b gy nk nl l nm nn">def map_fnc(ele):<br/>  return ele*2</span><span id="0753" class="lc ld iq ko b gy no nl l nm nn">min_val = tf.placeholder(tf.int32, shape=[])<br/>max_val = tf.placeholder(tf.int32, shape=[])</span><span id="4e63" class="lc ld iq ko b gy no nl l nm nn">data = tf.range(min_val, max_val)<br/>train_dataset = tf.data.Dataset.from_tensor_slices(data)<br/>val_dataset = tf.data.Dataset.from_tensor_slices(data).map(map_fnc)</span><span id="d5cf" class="lc ld iq ko b gy no nl l nm nn">train_val_iterator = tf.data.Iterator.from_structure(train_dataset.output_types , train_dataset.output_shapes)<br/>train_initializer = train_val_iterator.make_initializer(train_dataset)<br/>val_initializer = train_val_iterator.make_initializer(val_dataset)</span><span id="13f6" class="lc ld iq ko b gy no nl l nm nn">test_dataset = tf.data.Dataset.from_tensor_slices(tf.range(10,15))<br/>test_iterator = test_dataset.make_one_shot_iterator()</span><span id="ba1d" class="lc ld iq ko b gy no nl l nm nn">handle = tf.placeholder(tf.string, shape=[])<br/>iterator = tf.data.Iterator.from_string_handle(handle, train_dataset.output_types, train_dataset.output_shapes)<br/>next_ele = iterator.get_next()</span><span id="91ff" class="lc ld iq ko b gy no nl l nm nn">with tf.Session() as sess:<br/>  <br/>  train_val_handle = sess.run(train_val_iterator.string_handle())<br/>  test_handle = sess.run(test_iterator.string_handle())<br/>  <br/>  # training<br/>  sess.run(train_initializer, feed_dict={min_val:10, max_val:15})<br/>  try:<br/>    while True:<br/>      val = sess.run(next_ele, feed_dict={handle:train_val_handle})<br/>      print(val)<br/>  except tf.errors.OutOfRangeError:<br/>    pass<br/>      <br/>  #validation<br/>  sess.run(val_initializer, feed_dict={min_val:1, max_val:10})<br/>  try:<br/>    while True:<br/>      val = sess.run(next_ele, feed_dict={handle:train_val_handle})<br/>      print(val)<br/>  except tf.errors.OutOfRangeError:<br/>    pass<br/>  <br/>  #testing<br/>  try:<br/>    while True:<br/>      val = sess.run(next_ele, feed_dict={handle:test_handle})<br/>      print(val)<br/>  except tf.errors.OutOfRangeError:<br/>    pass</span></pre><p id="0bf8" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我们已经学习了各种迭代器。让我们将这些知识应用于一个实际的数据集。我们将使用 LeNet-5 模型训练著名的 MNIST 数据集。本教程不会深入讨论实现 LeNet-5 模型的细节，因为这超出了本文的范围。</p><h1 id="804f" class="mg ld iq bd le mh mi mj lh mk ml mm lk mn mo mp ln mq mr ms lq mt mu mv lt mw bi translated">LeNet-5 模型</h1><p id="24d7" class="pw-post-body-paragraph jn jo iq jp b jq lv js jt ju lw jw jx jy lx ka kb kc ly ke kf kg lz ki kj kk ij bi translated">让我们从 tensorflow 库中导入 MNIST 数据。MNIST 数据库包含 60，000 幅训练图像和 10，000 幅测试图像。每个图像的大小为 28*28*1。对于 LeNet-5 型号，我们需要将其大小调整为 32*32*1。</p><pre class="kq kr ks kt gt ng ko nh ni aw nj bi"><span id="c87c" class="lc ld iq ko b gy nk nl l nm nn">from tensorflow.examples.tutorials.mnist import input_data<br/>mnist = input_data.read_data_sets("MNIST_data/", reshape=False, one_hot = True)</span><span id="a2bd" class="lc ld iq ko b gy no nl l nm nn">X_train, y_train = mnist.train.images, mnist.train.labels<br/>X_val, y_val = mnist.validation.images, mnist.validation.labels<br/>X_test, y_test = mnist.test.images, mnist.test.labels</span><span id="0909" class="lc ld iq ko b gy no nl l nm nn">X_train = np.pad(X_train, ((0,0), (2,2), (2,2), (0,0)), 'constant')<br/>X_val =   np.pad(X_val, ((0,0), (2,2), (2,2), (0,0)), 'constant')<br/>X_test =  np.pad(X_test, ((0,0), (2,2), (2,2), (0,0)), 'constant')</span></pre><figure class="kq kr ks kt gt ku gh gi paragraph-image"><div role="button" tabindex="0" class="mb mc di md bf me"><div class="gh gi ns"><img src="../Images/6d75795837315121134c3c052f53d69f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*zfzWutrDAuC53ooAtR3Qwg.png"/></div></div><figcaption class="kx ky gj gh gi kz la bd b be z dk">Ref: <a class="ae lb" href="https://www.researchgate.net/figure/Structure-of-LeNet-5_fig1_312170477" rel="noopener ugc nofollow" target="_blank">https://www.researchgate.net/figure/Structure-of-LeNet-5_fig1_312170477</a></figcaption></figure><p id="a857" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">让我们定义模型的正向传播。</p><pre class="kq kr ks kt gt ng ko nh ni aw nj bi"><span id="1645" class="lc ld iq ko b gy nk nl l nm nn">def forward_pass(X):<br/>    W1 = tf.get_variable("W1", [5,5,1,6], initializer = tf.contrib.layers.xavier_initializer(seed=0))<br/>    # for conv layer2</span><span id="d1d3" class="lc ld iq ko b gy no nl l nm nn">    W2 = tf.get_variable("W2", [5,5,6,16], initializer = tf.contrib.layers.xavier_initializer(seed=0))</span><span id="8d35" class="lc ld iq ko b gy no nl l nm nn">    Z1 = tf.nn.conv2d(X, W1, strides = [1,1,1,1], padding='VALID')<br/>    A1 = tf.nn.relu(Z1)<br/>    P1 = tf.nn.max_pool(A1, ksize = [1,2,2,1], strides = [1,2,2,1], padding='VALID')</span><span id="4100" class="lc ld iq ko b gy no nl l nm nn">    Z2 = tf.nn.conv2d(P1, W2, strides = [1,1,1,1], padding='VALID')<br/>    A2= tf.nn.relu(Z2)<br/>    P2= tf.nn.max_pool(A2, ksize = [1,2,2,1], strides=[1,2,2,1], padding='VALID')</span><span id="1cd6" class="lc ld iq ko b gy no nl l nm nn">    P2 = tf.contrib.layers.flatten(P2)<br/>   <br/>    Z3 = tf.contrib.layers.fully_connected(P2, 120)<br/>    Z4 = tf.contrib.layers.fully_connected(Z3, 84)<br/>    Z5 = tf.contrib.layers.fully_connected(Z4,10, activation_fn= None)</span><span id="7dcd" class="lc ld iq ko b gy no nl l nm nn">    return Z5</span></pre><p id="cc23" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">让我们定义模型操作</p><pre class="kq kr ks kt gt ng ko nh ni aw nj bi"><span id="5a9a" class="lc ld iq ko b gy nk nl l nm nn">def model(X,Y):<br/>    <br/>    logits = forward_pass(X)<br/>    cost = tf.reduce_mean( tf.nn.softmax_cross_entropy_with_logits_v2(logits=logits, labels=Y))</span><span id="079f" class="lc ld iq ko b gy no nl l nm nn">    optimizer = tf.train.AdamOptimizer(learning_rate=0.0009)<br/>    learner = optimizer.minimize(cost)</span><span id="9a3c" class="lc ld iq ko b gy no nl l nm nn">    correct_predictions = tf.equal(tf.argmax(logits,1),   tf.argmax(Y,1))</span><span id="193f" class="lc ld iq ko b gy no nl l nm nn">    accuracy = tf.reduce_mean(tf.cast(correct_predictions, tf.float32))<br/>    <br/>    return (learner, accuracy)</span></pre><p id="4a4a" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我们现在已经创建了模型。在决定为我们的模型使用迭代器之前，让我们看看机器学习模型的典型要求是什么。</p><ol class=""><li id="cbb4" class="mx my iq jp b jq jr ju jv jy mz kc na kg nb kk nt nd ne nf bi translated"><strong class="jp ir">批量训练数据:</strong>数据集可能非常庞大。为了防止出现内存不足的错误，我们需要小批量地训练数据集。</li><li id="610e" class="mx my iq jp b jq nu ju nv jy nw kc nx kg ny kk nt nd ne nf bi translated"><strong class="jp ir">在数据集的 n 次传递中训练模型:</strong>通常，您希望在数据集的多次传递中运行训练模型。</li><li id="19e6" class="mx my iq jp b jq nu ju nv jy nw kc nx kg ny kk nt nd ne nf bi translated"><strong class="jp ir">在每个时期验证模型:</strong>您需要在每个时期验证您的模型，以检查您的模型的性能。</li><li id="76c5" class="mx my iq jp b jq nu ju nv jy nw kc nx kg ny kk nt nd ne nf bi translated"><strong class="jp ir">最后，在看不见的数据上测试你的模型:</strong>在模型被训练之后，你想要在看不见的数据上测试你的模型。</li></ol><p id="71a4" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">让我们看看每个迭代器的优缺点。</p><ul class=""><li id="e40d" class="mx my iq jp b jq jr ju jv jy mz kc na kg nb kk nc nd ne nf bi translated"><strong class="jp ir">一次性迭代器:</strong>数据集一旦用完就无法重新初始化。为了训练更多的历元，您需要在输入迭代器之前重复数据集。如果数据量很大，这将需要巨大的内存。它也没有提供任何验证模型的选项。</li></ul><pre class="kq kr ks kt gt ng ko nh ni aw nj bi"><span id="23d0" class="lc ld iq ko b gy nk nl l nm nn">epochs = 10 <br/>batch_size = 64 <br/>iterations = len(y_train) * epochs</span><span id="e071" class="lc ld iq ko b gy no nl l nm nn">tf.reset_default_graph()<br/>dataset = tf.data.Dataset.from_tensor_slices((X_train, y_train))</span><span id="8818" class="lc ld iq ko b gy no nl l nm nn"># need to repeat the dataset for epoch number of times, as all the data needs<br/># to be fed to the dataset at once<br/>dataset = dataset.repeat(epochs).batch(batch_size)<br/>iterator = dataset.make_one_shot_iterator()</span><span id="c823" class="lc ld iq ko b gy no nl l nm nn">X_batch , Y_batch = iterator.get_next()</span><span id="643c" class="lc ld iq ko b gy no nl l nm nn">(learner, accuracy) = model(X_batch, Y_batch)</span><span id="7305" class="lc ld iq ko b gy no nl l nm nn">with tf.Session() as sess:<br/>  sess.run(tf.global_variables_initializer())<br/>  <br/>  total_accuracy = 0<br/>  try:<br/>    while True:<br/>      temp_accuracy, _ = sess.run([accuracy, learner])<br/>      total_accuracy += temp_accuracy<br/>      <br/>  except tf.errors.OutOfRangeError:<br/>    pass<br/>  <br/>  <br/>print('Avg training accuracy is {}'.format((total_accuracy * batch_size) / iterations ))</span></pre><ul class=""><li id="c4aa" class="mx my iq jp b jq jr ju jv jy mz kc na kg nb kk nc nd ne nf bi translated"><strong class="jp ir">可初始化的迭代器:</strong>可以在训练数据集和验证数据集之间动态改变数据集。然而，在这种情况下，两个数据集需要通过相同的转换管道。</li></ul><pre class="kq kr ks kt gt ng ko nh ni aw nj bi"><span id="5b72" class="lc ld iq ko b gy nk nl l nm nn">epochs = 10 <br/>batch_size = 64</span><span id="b8fc" class="lc ld iq ko b gy no nl l nm nn">tf.reset_default_graph()</span><span id="dfab" class="lc ld iq ko b gy no nl l nm nn">X_data = tf.placeholder(tf.float32, [None, 32,32,1])<br/>Y_data = tf.placeholder(tf.float32, [None, 10])</span><span id="6376" class="lc ld iq ko b gy no nl l nm nn">dataset = tf.data.Dataset.from_tensor_slices((X_data, Y_data))<br/>dataset = dataset.batch(batch_size)<br/>iterator = dataset.make_initializable_iterator()</span><span id="3eeb" class="lc ld iq ko b gy no nl l nm nn">X_batch , Y_batch = iterator.get_next()</span><span id="9c7e" class="lc ld iq ko b gy no nl l nm nn">(learner, accuracy) = model(X_batch, Y_batch)</span><span id="6908" class="lc ld iq ko b gy no nl l nm nn">with tf.Session() as sess:<br/>  sess.run(tf.global_variables_initializer())<br/>  for epoch in range(epochs):<br/>    <br/>    # train the model<br/>    sess.run(iterator.initializer, feed_dict={X_data:X_train, Y_data:y_train})<br/>    total_train_accuracy = 0<br/>    no_train_examples = len(y_train)<br/>    try:<br/>      while True:<br/>        temp_train_accuracy, _ = sess.run([accuracy, learner])<br/>        total_train_accuracy += temp_train_accuracy*batch_size<br/>    except tf.errors.OutOfRangeError:<br/>      pass<br/>    <br/>    # validate the model<br/>    sess.run(iterator.initializer, feed_dict={X_data:X_val, Y_data:y_val})<br/>    total_val_accuracy = 0<br/>    no_val_examples = len(y_val)<br/>    try:<br/>      while True:<br/>        temp_val_accuracy = sess.run(accuracy)<br/>        total_val_accuracy += temp_val_accuracy*batch_size<br/>    except tf.errors.OutOfRangeError:<br/>      pass<br/>    <br/>    print('Epoch {}'.format(str(epoch+1)))<br/>    print("---------------------------")<br/>    print('Training accuracy is {}'.format(total_train_accuracy/no_train_examples))<br/>    print('Validation accuracy is {}'.format(total_val_accuracy/no_val_examples))</span></pre><ul class=""><li id="8c4a" class="mx my iq jp b jq jr ju jv jy mz kc na kg nb kk nc nd ne nf bi translated"><strong class="jp ir">可重新初始化的迭代器:</strong>这个迭代器通过使用两个独立的数据集克服了可初始化迭代器的问题。每个数据集都可以通过自己的预处理管道。迭代器可以使用<code class="fe kl km kn ko b">tf.Iterator.from_structure</code>方法创建。</li></ul><pre class="kq kr ks kt gt ng ko nh ni aw nj bi"><span id="afab" class="lc ld iq ko b gy nk nl l nm nn">def map_fnc(X, Y):<br/>     return X, Y</span><span id="307d" class="lc ld iq ko b gy no nl l nm nn">epochs = 10 <br/>batch_size = 64</span><span id="e0fe" class="lc ld iq ko b gy no nl l nm nn">tf.reset_default_graph()</span><span id="fb70" class="lc ld iq ko b gy no nl l nm nn">X_data = tf.placeholder(tf.float32, [None, 32,32,1])<br/>Y_data = tf.placeholder(tf.float32, [None, 10])</span><span id="d8ea" class="lc ld iq ko b gy no nl l nm nn">train_dataset = tf.data.Dataset.from_tensor_slices((X_data, Y_data)).batch(batch_size).map(map_fnc)</span><span id="e35c" class="lc ld iq ko b gy no nl l nm nn">val_dataset =  tf.data.Dataset.from_tensor_slices((X_data, Y_data)).batch(batch_size)</span><span id="3181" class="lc ld iq ko b gy no nl l nm nn">iterator = tf.data.Iterator.from_structure(train_dataset.output_types, train_dataset.output_shapes)</span><span id="b842" class="lc ld iq ko b gy no nl l nm nn">X_batch , Y_batch = iterator.get_next()<br/>(learner, accuracy) = model(X_batch, Y_batch)</span><span id="a4a5" class="lc ld iq ko b gy no nl l nm nn">train_initializer = iterator.make_initializer(train_dataset)<br/>val_initializer =  iterator.make_initializer(val_dataset)</span><span id="ef8d" class="lc ld iq ko b gy no nl l nm nn">with tf.Session() as sess:<br/>  sess.run(tf.global_variables_initializer())<br/>  for epoch in range(epochs):<br/>    <br/>    # train the model<br/>    sess.run(train_initializer, feed_dict={X_data:X_train, Y_data:y_train})<br/>    total_train_accuracy = 0<br/>    no_train_examples = len(y_train)<br/>    try:<br/>      while True:<br/>        temp_train_accuracy, _ = sess.run([accuracy, learner])<br/>        total_train_accuracy += temp_train_accuracy*batch_size<br/>    except tf.errors.OutOfRangeError:<br/>      pass<br/>    <br/>    # validate the model<br/>    sess.run(val_initializer, feed_dict={X_data:X_val, Y_data:y_val})<br/>    total_val_accuracy = 0<br/>    no_val_examples = len(y_val)<br/>    try:<br/>      while True:<br/>        temp_val_accuracy = sess.run(accuracy)<br/>        total_val_accuracy += temp_val_accuracy*batch_size<br/>    except tf.errors.OutOfRangeError:<br/>      pass<br/>    <br/>    print('Epoch {}'.format(str(epoch+1)))<br/>    print("---------------------------")<br/>    print('Training accuracy is {}'.format(total_train_accuracy/no_train_examples))<br/>    print('Validation accuracy is {}'.format(total_val_accuracy/no_val_examples))</span></pre><ul class=""><li id="df08" class="mx my iq jp b jq jr ju jv jy mz kc na kg nb kk nc nd ne nf bi translated"><strong class="jp ir"> Feedable 迭代器:</strong>这个迭代器提供了在各种迭代器之间切换的选项。您可以创建一个可重新初始化的迭代器，用于训练和验证。对于需要一遍数据集的推断/测试，可以使用一次性迭代器。</li></ul><pre class="kq kr ks kt gt ng ko nh ni aw nj bi"><span id="2c77" class="lc ld iq ko b gy nk nl l nm nn">epochs = 10 <br/>batch_size = 64</span><span id="9c16" class="lc ld iq ko b gy no nl l nm nn">tf.reset_default_graph()</span><span id="d324" class="lc ld iq ko b gy no nl l nm nn">X_data = tf.placeholder(tf.float32, [None, 32,32,1])<br/>Y_data = tf.placeholder(tf.float32, [None, 10])</span><span id="a5d2" class="lc ld iq ko b gy no nl l nm nn">train_dataset = tf.data.Dataset.from_tensor_slices((X_data, Y_data)).batch(batch_size)<br/>val_dataset =  tf.data.Dataset.from_tensor_slices((X_data, Y_data)).batch(batch_size)</span><span id="950d" class="lc ld iq ko b gy no nl l nm nn">test_dataset =  tf.data.Dataset.from_tensor_slices((X_test, y_test.astype(np.float32)).batch(batch_size)</span><span id="c533" class="lc ld iq ko b gy no nl l nm nn">handle = tf.placeholder(tf.string, shape=[])<br/>iterator = tf.data.Iterator.from_string_handle(handle, train_dataset.output_types, train_dataset.output_shapes)<br/>X_batch , Y_batch = iterator.get_next()<br/>(learner, accuracy) = model(X_batch, Y_batch)</span><span id="cf01" class="lc ld iq ko b gy no nl l nm nn">train_val_iterator = tf.data.Iterator.from_structure(train_dataset.output_types, train_dataset.output_shapes)<br/>train_iterator = train_val_iterator.make_initializer(train_dataset)<br/>val_iterator = train_val_iterator.make_initializer(val_dataset)<br/>test_iterator = test_dataset.make_one_shot_iterator()</span><span id="6a4f" class="lc ld iq ko b gy no nl l nm nn">with tf.Session() as sess:<br/>  sess.run(tf.global_variables_initializer())<br/>  train_val_string_handle = sess.run(train_val_iterator.string_handle())<br/>  test_string_handle = sess.run(test_iterator.string_handle())<br/>  <br/>  for epoch in range(epochs):<br/>    <br/>    # train the model<br/>    sess.run(train_iterator, feed_dict={X_data:X_train, Y_data:y_train})<br/>    total_train_accuracy = 0<br/>    no_train_examples = len(y_train)<br/>    try:<br/>      while True:<br/>        temp_train_accuracy, _ = sess.run([accuracy, learner], feed_dict={handle:train_val_string_handle})<br/>        total_train_accuracy += temp_train_accuracy*batch_size<br/>    except tf.errors.OutOfRangeError:<br/>      pass<br/>    <br/>    # validate the model<br/>    sess.run(val_iterator, feed_dict={X_data:X_val, Y_data:y_val})<br/>    total_val_accuracy = 0<br/>    no_val_examples = len(y_val)<br/>    try:<br/>      while True:<br/>        temp_val_accuracy, _ = sess.run([accuracy, learner], feed_dict={handle:train_val_string_handle})<br/>        total_val_accuracy += temp_val_accuracy*batch_size<br/>    except tf.errors.OutOfRangeError:<br/>      pass<br/>    <br/>    print('Epoch {}'.format(str(epoch+1)))<br/>    print("---------------------------")<br/>    print('Training accuracy is {}'.format(total_train_accuracy/no_train_examples))<br/>    print('Validation accuracy is {}'.format(total_val_accuracy/no_val_examples))<br/>  <br/>  <br/>  print("Testing the model --------")<br/> <br/>  total_test_accuracy = 0<br/>  no_test_examples = len(y_test)<br/>  try:<br/>    while True:<br/>        temp_test_accuracy, _ = sess.run([accuracy, learner], feed_dict={handle:test_string_handle})<br/>        total_test_accuracy += temp_test_accuracy*batch_size<br/>  except tf.errors.OutOfRangeError:<br/>    pass<br/>    <br/>  print('Testing accuracy is {}'.format(total_test_accuracy/no_test_examples))</span></pre><p id="2c85" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">感谢阅读博客。本博客中使用的代码示例可以在这个<a class="ae lb" href="https://github.com/animesh-agarwal/Datasets-and-Iterators/blob/master/DataSet_and_Iterators.ipynb" rel="noopener ugc nofollow" target="_blank"> jupyter 笔记本</a>中找到。</p><p id="1acf" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">如果你有任何问题或者你有任何改进这个博客的建议，请在下面留下你的评论。</p><h2 id="7bd0" class="lc ld iq bd le lf lg dn lh li lj dp lk jy ll lm ln kc lo lp lq kg lr ls lt lu bi translated">参考</h2><ul class=""><li id="6b44" class="mx my iq jp b jq lv ju lw jy np kc nq kg nr kk nc nd ne nf bi translated"><a class="ae lb" href="https://www.tensorflow.org/api_docs/python/tf/data/Iterator#from_string_handle" rel="noopener ugc nofollow" target="_blank">https://www . tensor flow . org/API _ docs/python/TF/data/Iterator # from _ string _ handle</a></li><li id="2d25" class="mx my iq jp b jq nu ju nv jy nw kc nx kg ny kk nc nd ne nf bi translated"><a class="ae lb" href="https://www.tensorflow.org/guide/datasets" rel="noopener ugc nofollow" target="_blank">https://www.tensorflow.org/guide/datasets</a></li><li id="2604" class="mx my iq jp b jq nu ju nv jy nw kc nx kg ny kk nc nd ne nf bi translated"><a class="ae lb" href="https://docs.google.com/presentation/d/16kHNtQslt-yuJ3w8GIx-eEH6t_AvFeQOchqGRFpAD7U/edit#slide=id.g254d08e080_0_141" rel="noopener ugc nofollow" target="_blank">https://docs . Google . com/presentation/d/16 khntqslt-yuj 3 w8 gix-eEH6t _ avfeqochqgrfpad 7 u/edit # slide = id . g 254d 08 e 080 _ 0 _ 141</a></li><li id="3a20" class="mx my iq jp b jq nu ju nv jy nw kc nx kg ny kk nc nd ne nf bi translated"><a class="ae lb" href="https://github.com/tensorflow/tensorflow/issues/2919" rel="noopener ugc nofollow" target="_blank">https://github.com/tensorflow/tensorflow/issues/2919</a></li></ul></div></div>    
</body>
</html>