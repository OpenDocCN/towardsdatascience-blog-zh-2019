<html>
<head>
<title>Class Model Visualization for CNNs</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">面向 CNNs 的类模型可视化</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/class-model-visualization-for-cnns-e49be906680d?source=collection_archive---------22-----------------------#2019-07-13">https://towardsdatascience.com/class-model-visualization-for-cnns-e49be906680d?source=collection_archive---------22-----------------------#2019-07-13</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><figure class="gl gn jr js jt ju gh gi paragraph-image"><div class="gh gi jq"><img src="../Images/47b88c3bf4217dfe14dce0ad9c79719d.png" data-original-src="https://miro.medium.com/v2/resize:fit:976/format:webp/1*2IB62tK2rSNiKdV1__EaXw.png"/></div></figure><p id="0040" class="pw-post-body-paragraph jx jy it jz b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku im bi translated">本文将涉及类模型可视化，这在本文<a class="ae kv" href="https://arxiv.org/abs/1312.6034" rel="noopener ugc nofollow" target="_blank"/>的第 2 节中有描述。类模型可视化是一种用于使用训练分类 CNN 来创建表示该 CNN 的特定类的图像的技术。“鸟”的类模型最大程度地激活对应于“鸟”类的 CNN 输出神经元。</p><p id="1e7f" class="pw-post-body-paragraph jx jy it jz b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku im bi translated">下面是本文中的图 1，显示了 12 个不同类的示例类模型:</p><figure class="kx ky kz la gt ju gh gi paragraph-image"><div class="gh gi kw"><img src="../Images/63b7f6047e9f2f84cf11892b9b11da63.png" data-original-src="https://miro.medium.com/v2/resize:fit:1232/0*xGY19E82GCu5ZGMX"/></div></figure><figure class="kx ky kz la gt ju gh gi paragraph-image"><div class="gh gi kw"><img src="../Images/ee5d067612abf257bb1c50a81ddb38f2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1232/0*1B1LR2KkXyPbCm1q"/></div></figure><figure class="kx ky kz la gt ju gh gi paragraph-image"><div class="gh gi kw"><img src="../Images/3c3d1a0575ad9c90c7bdda8e82499016.png" data-original-src="https://miro.medium.com/v2/resize:fit:1232/0*YphZzEEOi_BK_Eun"/></div></figure><figure class="kx ky kz la gt ju gh gi paragraph-image"><div class="gh gi kw"><img src="../Images/96f9b0c968758a5938f6b6c669b9c32f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1232/0*a4YmIFEGeZQeT45g"/></div></figure><figure class="kx ky kz la gt ju gh gi paragraph-image"><div class="gh gi kw"><img src="../Images/43bedd6c7702b91101ad7e1240bb8f89.png" data-original-src="https://miro.medium.com/v2/resize:fit:1232/0*TD41-MCmg2rphAYr"/></div></figure><h2 id="8a00" class="lb lc it bd ld le lf dn lg lh li dp lj ki lk ll lm km ln lo lp kq lq lr ls lt bi translated"><strong class="ak">注</strong></h2><p id="a809" class="pw-post-body-paragraph jx jy it jz b ka lu kc kd ke lv kg kh ki lw kk kl km lx ko kp kq ly ks kt ku im bi translated">Simonyan 等人介绍类模型的论文还介绍了用于创建显著性图的反向传播。显著性图将在<a class="ae kv" href="https://glassboxmedicine.com/2019/06/21/cnn-heat-maps-saliency-backpropagation/" rel="noopener ugc nofollow" target="_blank">本帖</a>中单独讨论。</p><h1 id="2088" class="lz lc it bd ld ma mb mc lg md me mf lj mg mh mi lm mj mk ml lp mm mn mo ls mp bi translated"><strong class="ak">类模型的表达</strong></h1><p id="dc80" class="pw-post-body-paragraph jx jy it jz b ka lu kc kd ke lv kg kh ki lw kk kl km lx ko kp kq ly ks kt ku im bi translated">一个阶级模式是一个形象<em class="mq"> I </em>产生一个高分<em class="mq"> Sc(I) </em>当馈入一个已经训练有素的 CNN。类模型<em class="mq"> I </em>由以下表达式总结:</p><figure class="kx ky kz la gt ju gh gi paragraph-image"><div class="gh gi mr"><img src="../Images/fa0d3bd0c2dcac98cc1abcab03068197.png" data-original-src="https://miro.medium.com/v2/resize:fit:410/0*2EQBP8WScUIvPtho"/></div></figure><p id="49ad" class="pw-post-body-paragraph jx jy it jz b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku im bi translated">在这里，我们对图像<em class="mq"> I </em>进行<a class="ae kv" href="https://en.wikipedia.org/wiki/Arg_max" rel="noopener ugc nofollow" target="_blank"> arg max </a>，这意味着我们试图找到特定的图像<em class="mq"> I </em>(类模型)，使得表达式的第二段，</p><figure class="kx ky kz la gt ju gh gi paragraph-image"><div class="gh gi ms"><img src="../Images/c74eb65f67a16763a3d25d70596cbff5.png" data-original-src="https://miro.medium.com/v2/resize:fit:274/0*kXvr9CrD02P8wtYm"/></div></figure><p id="0807" class="pw-post-body-paragraph jx jy it jz b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku im bi translated">最大化。</p><p id="8c6b" class="pw-post-body-paragraph jx jy it jz b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku im bi translated">表达式的第二部分就是 CNN 对该图像的原始类评分<em class="mq"> Sc(I) </em>，后面是一个 L2 正则化项【这里的正则化回顾】。</p><p id="e8dd" class="pw-post-body-paragraph jx jy it jz b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku im bi translated">换句话说，这个表达是另一种说法，即类模型是使类得分最大化的图像<em class="mq"> I </em>。</p><p id="f8f6" class="pw-post-body-paragraph jx jy it jz b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku im bi translated"><strong class="jz iu">为什么包括 L2 正则化项？</strong></p><p id="7976" class="pw-post-body-paragraph jx jy it jz b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku im bi translated">L2 正则化项鼓励所学习的图像不包含极值。回想一下<a class="ae kv" href="https://glassboxmedicine.com/2019/06/08/regularization-for-neural-networks-with-framingham-case-study/" rel="noopener ugc nofollow" target="_blank"> L2 正则化试图使所有值的大小都较小(但不一定为零)，而 L1 正则化试图使尽可能多的值为零</a>。可以使用不同类型的正则化创建类模型。</p><p id="99ea" class="pw-post-body-paragraph jx jy it jz b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku im bi translated">存储库<a class="ae kv" href="https://github.com/utkuozbulak/pytorch-cnn-visualizations" rel="noopener ugc nofollow" target="_blank">pytorch-CNN-visualizations</a>提供了以下正则化对类模型外观的影响示例:</p><p id="5fec" class="pw-post-body-paragraph jx jy it jz b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku im bi translated">首先，这里有一个 gif 展示了在没有任何正则化的情况下学习“flamingo”类的类模型的过程:</p><figure class="kx ky kz la gt ju gh gi paragraph-image"><div class="gh gi mt"><img src="../Images/22022bae87d062635627b277aa146a19.png" data-original-src="https://miro.medium.com/v2/resize:fit:448/0*vpHVRb4fKOCZE1Dp"/></div></figure><p id="a1c6" class="pw-post-body-paragraph jx jy it jz b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku im bi translated">我们可以看到结果图像包括许多明亮的颜色(高值)。</p><p id="34b3" class="pw-post-body-paragraph jx jy it jz b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku im bi translated">接下来，这里有一个 gif 展示了学习 L2 正则化的“火烈鸟”类模型的过程:</p><figure class="kx ky kz la gt ju gh gi paragraph-image"><div class="gh gi mt"><img src="../Images/4cf020cd92e982830ee079c84970183f.png" data-original-src="https://miro.medium.com/v2/resize:fit:448/0*_IQ5w2lANmkdwV59"/></div></figure><p id="6e20" class="pw-post-body-paragraph jx jy it jz b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku im bi translated">这一个包括更多的灰色值，和更少的高值，正如我们应用 L2 正则化所期望的。</p><p id="a48d" class="pw-post-body-paragraph jx jy it jz b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku im bi translated">最后，这里有一个 gif，展示了用 L1 正则化学习“flamingo”类模型的过程:</p><figure class="kx ky kz la gt ju gh gi paragraph-image"><div class="gh gi mt"><img src="../Images/65fed2e075607721dd15bb5f801378e6.png" data-original-src="https://miro.medium.com/v2/resize:fit:448/0*xMDZOuewQw609klY"/></div></figure><p id="4676" class="pw-post-body-paragraph jx jy it jz b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku im bi translated">我们可以看到，这个类模型包括许多黑色(零)值，正如我们在应用 L1 正则化时所期望的那样。</p><p id="19f5" class="pw-post-body-paragraph jx jy it jz b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku im bi translated">没有“唯一正确的方法”来规范班级模型。类模型的全部意义在于向好奇的人提供 CNN 对类的理解。L2 正规化是一个很好的选择，但你也可以探索其他形式的正规化。</p><p id="893a" class="pw-post-body-paragraph jx jy it jz b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku im bi translated"><strong class="jz iu">为什么最大化分数而不是概率？</strong></p><p id="653b" class="pw-post-body-paragraph jx jy it jz b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku im bi translated">回想一下，美国有线电视新闻网(CNN)的分类产生原始的类别分数<em class="mq"> Sc </em>，然后使用 softmax 层将这些分数<a class="ae kv" href="https://glassboxmedicine.com/2019/05/26/classification-sigmoid-vs-softmax/" rel="noopener ugc nofollow" target="_blank">转换成概率<em class="mq"> Pc </em>:</a></p><figure class="kx ky kz la gt ju gh gi paragraph-image"><div class="gh gi mu"><img src="../Images/b0b80e91039f4afc17958ed2f619317e.png" data-original-src="https://miro.medium.com/v2/resize:fit:272/0*COAHyTU0INCl42ib"/></div></figure><p id="540a" class="pw-post-body-paragraph jx jy it jz b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku im bi translated">在类模型方法中，我们试图最大化未标准化的类分数<em class="mq"> Sc </em>，而不是类概率<em class="mq"> Pc </em>。这是因为有两种方法可以最大化类别概率<em class="mq"> Pc </em>:</p><ol class=""><li id="5976" class="mv mw it jz b ka kb ke kf ki mx km my kq mz ku na nb nc nd bi translated">我们可以最大化感兴趣的类的原始分数</li><li id="b1ed" class="mv mw it jz b ka ne ke nf ki ng km nh kq ni ku na nb nc nd bi translated">我们可以最小化其他课程的原始分数</li></ol><p id="7fe0" class="pw-post-body-paragraph jx jy it jz b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku im bi translated">我们不想以做(2)结束，因为如果我们做(2)将不会清楚如何解释产生的图像。因此，我们忽略 softmax 层，直接最大化感兴趣类别的原始分数<em class="mq"> Sc </em>。</p><p id="1f6c" class="pw-post-body-paragraph jx jy it jz b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku im bi translated"><strong class="jz iu">创建班级模型的步骤</strong></p><p id="4dde" class="pw-post-body-paragraph jx jy it jz b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku im bi translated">我们可以通过以下步骤学习图像<em class="mq"> I </em>来为类别“bird”产生高分:</p><ol class=""><li id="181b" class="mv mw it jz b ka kb ke kf ki mx km my kq mz ku na nb nc nd bi translated">训练一个分类 CNN。</li><li id="d950" class="mv mw it jz b ka ne ke nf ki ng km nh kq ni ku na nb nc nd bi translated">创建随机的以零为中心的图像(假设分类 CNN 是在以零为中心的图像数据上训练的。)</li><li id="f6bb" class="mv mw it jz b ka ne ke nf ki ng km nh kq ni ku na nb nc nd bi translated">重复以下步骤:(a)在图像上做一个<a class="ae kv" href="https://glassboxmedicine.com/2019/01/17/introduction-to-neural-networks/" rel="noopener ugc nofollow" target="_blank">正向传递</a>，计算当前类别分数；(b)使用<a class="ae kv" href="https://glassboxmedicine.com/2019/01/17/introduction-to-neural-networks/" rel="noopener ugc nofollow" target="_blank">反向传播算法</a>找到“鸟”神经元输出(分数)相对于图像像素的梯度；(c)对图像进行小的更新，以便在下一次向前传递时产生更高的“鸟”分数。</li></ol><p id="5987" class="pw-post-body-paragraph jx jy it jz b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku im bi translated">这是梯度上升，其中我们对图像进行更新以最大化得分(与梯度下降相反，在梯度下降中，我们试图进行更新以最小化得分。)</p><p id="f1db" class="pw-post-body-paragraph jx jy it jz b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku im bi translated">我们可以为 CNN 接受训练的每个班级制作班级模型可视化。我们训练 CNN 一次，然后对每一个可能的类别选择重复步骤(2)和(3)。</p><p id="0743" class="pw-post-body-paragraph jx jy it jz b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku im bi translated"><strong class="jz iu">代号</strong></p><p id="f000" class="pw-post-body-paragraph jx jy it jz b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku im bi translated">下面是类模型的 Pytorch 实现:<a class="ae kv" href="https://github.com/utkuozbulak/pytorch-cnn-visualizations/blob/master/src/generate_class_specific_samples.py" rel="noopener ugc nofollow" target="_blank">py torch-CNN-visualizations/src/generate _ class _ specific _ samples . py</a>。下面的 gif 来自存储库，显示了从随机初始化的图像开始学习目标类“Spider”的类模型的过程:</p><figure class="kx ky kz la gt ju gh gi paragraph-image"><div class="gh gi mt"><img src="../Images/a8c2369e52392d1620fa64ef420d94f8.png" data-original-src="https://miro.medium.com/v2/resize:fit:448/0*E5M8rY5xC9Jpfh2l"/></div></figure><p id="60c2" class="pw-post-body-paragraph jx jy it jz b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku im bi translated"><strong class="jz iu">结论</strong></p><p id="3cec" class="pw-post-body-paragraph jx jy it jz b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku im bi translated">班级模型可以帮助我们理解 CNN 认为某个班级“看起来像什么”它们是深入了解我们训练有素的 CNN 从每堂课中学到了什么的有用工具。</p><p id="f6ae" class="pw-post-body-paragraph jx jy it jz b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku im bi translated"><strong class="jz iu">附加参考文献</strong></p><ul class=""><li id="e8fd" class="mv mw it jz b ka kb ke kf ki mx km my kq mz ku nj nb nc nd bi translated">原始研究论文:<a class="ae kv" href="https://arxiv.org/abs/1312.6034" rel="noopener ugc nofollow" target="_blank"> Simonyan K，Vedaldi A，Zisserman A .深入卷积网络内部:可视化图像分类模型和显著图。arXiv 预印本 arXiv:1312.6034。2013 年 12 月 20 日。</a> <em class="mq">被 1479</em>引用</li><li id="c023" class="mv mw it jz b ka ne ke nf ki ng km nh kq ni ku nj nb nc nd bi translated"><a class="ae kv" href="http://cs231n.stanford.edu/slides/2017/cs231n_2017_lecture12.pdf" rel="noopener ugc nofollow" target="_blank">费-，，杨威。斯坦福 CS 231n 讲座 12:可视化和理解</a>(幻灯片 21–24)</li></ul><p id="873e" class="pw-post-body-paragraph jx jy it jz b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku im bi translated"><strong class="jz iu">特色图片</strong></p><p id="064a" class="pw-post-body-paragraph jx jy it jz b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku im bi translated">特色图像显示了 VGG16 CNN 的“鸵鸟”类的鸵鸟和类模型图像，并根据以下 GitHub 库中的图像进行了修改:<a class="ae kv" href="https://github.com/saketd403/Visualising-Image-Classification-Models-and-Saliency-Maps" rel="noopener ugc nofollow" target="_blank">saketd 403/visualizing-Image-Classification-Models-and-studential-Maps</a></p></div><div class="ab cl nk nl hx nm" role="separator"><span class="nn bw bk no np nq"/><span class="nn bw bk no np nq"/><span class="nn bw bk no np"/></div><div class="im in io ip iq"><p id="2939" class="pw-post-body-paragraph jx jy it jz b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku im bi translated"><em class="mq">原载于 2019 年 7 月 13 日 http://glassboxmedicine.com</em><em class="mq">的</em> <a class="ae kv" href="https://glassboxmedicine.com/2019/07/13/class-model-visualization-for-cnns/" rel="noopener ugc nofollow" target="_blank"> <em class="mq">。</em></a></p></div></div>    
</body>
</html>