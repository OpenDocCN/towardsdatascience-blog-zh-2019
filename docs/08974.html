<html>
<head>
<title>SSD : Single Shot Detector for object detection using MultiBox</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">SSD:使用多盒进行物体检测的单次检测器</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/ssd-single-shot-detector-for-object-detection-using-multibox-1818603644ca?source=collection_archive---------2-----------------------#2019-11-30">https://towardsdatascience.com/ssd-single-shot-detector-for-object-detection-using-multibox-1818603644ca?source=collection_archive---------2-----------------------#2019-11-30</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><p id="53cc" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu"> <em class="ko">在这篇短文中，我们将了解什么是固态硬盘、它的架构以及它如何被训练和用于物体检测</em> </strong></p><h1 id="777f" class="kp kq it bd kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm bi translated">单发探测器</h1><p id="fbf4" class="pw-post-body-paragraph jq jr it js b jt ln jv jw jx lo jz ka kb lp kd ke kf lq kh ki kj lr kl km kn im bi translated">像 YOLO <strong class="js iu">这样的单镜头探测器只需一次拍摄，就可以使用多框探测图像中的多个物体。</strong></p><p id="a106" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">它在速度上明显快于高精度的目标检测算法。在 VOC2007 上快速比较不同对象检测模型的速度和准确性</p><ul class=""><li id="f8d9" class="ls lt it js b jt ju jx jy kb lu kf lv kj lw kn lx ly lz ma bi translated"><strong class="js iu"> SDD300 </strong> : 59 FPS，贴图 74.3%</li><li id="2c4f" class="ls lt it js b jt mb jx mc kb md kf me kj mf kn lx ly lz ma bi translated"><strong class="js iu">SSD 500:</strong>22 帧/秒，平均映射为 76.9%</li><li id="eeb7" class="ls lt it js b jt mb jx mc kb md kf me kj mf kn lx ly lz ma bi translated"><strong class="js iu">更快的 R-CNN </strong> : 7 FPS，mAP 73.2%</li><li id="b82e" class="ls lt it js b jt mb jx mc kb md kf me kj mf kn lx ly lz ma bi translated"><strong class="js iu"> YOLO </strong> : 45 FPS，贴图 63.4%</li></ul><p id="ca97" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">使用相对低分辨率图像的 SSD 的高速度和准确性归因于以下原因</p><ul class=""><li id="4a66" class="ls lt it js b jt ju jx jy kb lu kf lv kj lw kn lx ly lz ma bi translated">消除了像 RCNN 中使用的包围盒建议</li><li id="28f3" class="ls lt it js b jt mb jx mc kb md kf me kj mf kn lx ly lz ma bi translated">包括用于预测物体类别和边界框位置偏移的递减卷积滤波器。</li></ul><p id="67a3" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">SSD 中的高检测精度是通过使用具有不同大小和纵横比的多个盒子或过滤器来进行对象检测而实现的。它还将这些过滤器应用于网络后期的多个要素地图。这有助于在多个尺度上进行检测。</p><h1 id="26cf" class="kp kq it bd kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm bi translated">单触发探测器的体系结构</h1><p id="5f6c" class="pw-post-body-paragraph jq jr it js b jt ln jv jw jx lo jz ka kb lp kd ke kf lq kh ki kj lr kl km kn im bi translated"><strong class="js iu">固态硬盘有一个基本的 VGG-16 网络，后跟多个 conv 层</strong></p><p id="14be" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu">基本神经网络:提取特征</strong></p><p id="d8a8" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">SDD 的 VGG-16 基础网络是用于高质量图像分类的标准 CNN 架构，但是没有最终分类层。VGG-16 用于特征提取。</p><p id="c18a" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu">附加 Conv 层:检测物体</strong></p><p id="0b81" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">对于基本的 VGG 网络，我们增加了额外的卷积层用于检测。基本网络末端的卷积层大小逐渐减小。这有助于在多个尺度上检测物体。用于检测的卷积模型对于每个特征层是不同的。</p><p id="5229" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu">对图像中不同对象的包围盒和置信度的预测不是由一个而是由代表多个尺度的不同大小的多个特征图来完成</strong></p><figure class="mh mi mj mk gt ml gh gi paragraph-image"><div role="button" tabindex="0" class="mm mn di mo bf mp"><div class="gh gi mg"><img src="../Images/7853dc32d913a2e8a52c788e6d5d7bab.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*hdSE1UCV7gA7jzfQ03EnWw.png"/></div></div></figure><p id="5be7" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">逐渐减少的卷积层会减小特征图的大小并增加深度。深层覆盖更大的感受野，并构建更抽象的表达。这有助于探测更大的物体。初始 conv 层覆盖较小的感受野，有助于检测图像中存在的较小物体。</p><h1 id="9dd9" class="kp kq it bd kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm bi translated">SSD 的培训</h1><p id="6759" class="pw-post-body-paragraph jq jr it js b jt ln jv jw jx lo jz ka kb lp kd ke kf lq kh ki kj lr kl km kn im bi translated">SSD 的输入是一个输入图像，图像中的每个对象都有地面真实边界框，如下所示</p><p id="4298" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">VGG-16 是执行特征提取的基础网络。Conv 图层在不同比例的多个要素地图中的每个位置评估不同纵横比的盒子，如下所示。</p><p id="4230" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">多盒子就像快速 R-CNN 的主播。我们有多个不同大小的默认框，如下图所示。SSD 用 8732 盒。这有助于找到与包含对象的地面真实边界框重叠最多的默认框。</p><figure class="mh mi mj mk gt ml gh gi paragraph-image"><div class="gh gi ms"><img src="../Images/9a8e1daeb977c2e09c2ff60a62350b14.png" data-original-src="https://miro.medium.com/v2/resize:fit:838/format:webp/1*StrJBibOgAlBea3bJ2umEg.png"/></div></figure><h1 id="25fc" class="kp kq it bd kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm bi translated">匹配策略</h1><p id="e0cf" class="pw-post-body-paragraph jq jr it js b jt ln jv jw jx lo jz ka kb lp kd ke kf lq kh ki kj lr kl km kn im bi translated">在训练期间，默认框在纵横比、位置和比例上与地面真实框相匹配。我们选择与地面真实边界框具有最高重叠的框。预测框和地面实况之间的 IoU(交集/并集)应大于 0.5。我们最终选择了与真实情况有最大重叠的预测框。</p><figure class="mh mi mj mk gt ml gh gi paragraph-image"><div role="button" tabindex="0" class="mm mn di mo bf mp"><div class="gh gi mt"><img src="../Images/f868fefe022f09a88507acad07b02714.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*rqDKaNwxd8lSxBwSMxRCwA.png"/></div></div></figure><p id="03c4" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">在上图中，我们匹配了两个默认的框。一个带着猫，一个带着狗。它们被视为正边界框，其余的被视为负边界框。</p><p id="1d68" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">每个预测包括</p><ul class=""><li id="6a25" class="ls lt it js b jt ju jx jy kb lu kf lv kj lw kn lx ly lz ma bi translated">具有形状偏移的边界框。∈<em class="ko">c</em>x，∈<em class="ko">c</em>y，<em class="ko"> h </em>和 w <em class="ko">，</em>代表从默认框中心的偏移量及其高度和宽度</li><li id="82c3" class="ls lt it js b jt mb jx mc kb md kf me kj mf kn lx ly lz ma bi translated">所有对象类别或所有类的置信度。类 0 被保留以指示对象的不存在</li></ul><figure class="mh mi mj mk gt ml gh gi paragraph-image"><div role="button" tabindex="0" class="mm mn di mo bf mp"><div class="gh gi mu"><img src="../Images/212179e8b65df3764c9e3fec10454a3a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ZpY74E1Njx8BS65DT8YpaA.png"/></div></div></figure><p id="ecae" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">SSD 中使用的损失函数是多盒损失，它由两项组成:置信度损失和定位损失。</p><h1 id="f358" class="kp kq it bd kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm bi translated"><strong class="ak">数据扩充:</strong></h1><p id="f57d" class="pw-post-body-paragraph jq jr it js b jt ln jv jw jx lo jz ka kb lp kd ke kf lq kh ki kj lr kl km kn im bi translated">数据扩充技术用于处理对象大小和形状的变化，使用剪切、放大、缩小、翻转、裁剪等。数据扩充的应用使得该模型对于各种输入对象尺寸和形状更加稳健。这有助于提高模型的准确性。</p><p id="7ca1" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">每个训练图像由以下选项之一随机采样</p><ul class=""><li id="550c" class="ls lt it js b jt ju jx jy kb lu kf lv kj lw kn lx ly lz ma bi translated">使用整个原始输入图像</li><li id="da8d" class="ls lt it js b jt mb jx mc kb md kf me kj mf kn lx ly lz ma bi translated">对对象的面片进行采样，使与对象的最小重叠为 0.1、0.3、0.5、0.7 或 0.9</li><li id="98ea" class="ls lt it js b jt mb jx mc kb md kf me kj mf kn lx ly lz ma bi translated">随机抽取补丁样本</li></ul><h1 id="384c" class="kp kq it bd kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm bi translated">使用 SSD 进行推断</h1><p id="2405" class="pw-post-body-paragraph jq jr it js b jt ln jv jw jx lo jz ka kb lp kd ke kf lq kh ki kj lr kl km kn im bi translated">SSD 在不同的输出层上使用不同比例、形状和纵横比的默认框。</p><p id="6104" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">它使用 8732 个盒子来更好地覆盖位置、比例和长宽比。大多数预测将不包含任何对象。SSD 会丢弃置信度得分低于 0.01 的预测。然后，我们应用每类 0.45 的非最大抑制(NMS)重叠，并保留每幅图像的前 200 个检测。</p><p id="d186" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">固态硬盘需要记住的要点</p><ul class=""><li id="0398" class="ls lt it js b jt ju jx jy kb lu kf lv kj lw kn lx ly lz ma bi translated">而 Yolo 具有固定的网格单元纵横比。固态硬盘使用不同的宽高比和多个盒子，以获得更高的精确度</li><li id="3b67" class="ls lt it js b jt mb jx mc kb md kf me kj mf kn lx ly lz ma bi translated">固态硬盘在基本 VGG-16 的末端有额外的 conv 层，用于物体检测。卷积层具有不同尺度的多种特征，因此能够更好地检测多尺度下的目标</li></ul><h1 id="cdfe" class="kp kq it bd kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm bi translated">参考资料:</h1><p id="f650" class="pw-post-body-paragraph jq jr it js b jt ln jv jw jx lo jz ka kb lp kd ke kf lq kh ki kj lr kl km kn im bi translated"><a class="ae mv" href="https://arxiv.org/pdf/1512.02325.pdf" rel="noopener ugc nofollow" target="_blank">单发探测器(C. Szegedy 等人)</a></p><p id="0563" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">https://github.com/amdegroot/ssd.pytorch#demos<a class="ae mv" href="https://github.com/amdegroot/ssd.pytorch#demos" rel="noopener ugc nofollow" target="_blank"/></p></div></div>    
</body>
</html>