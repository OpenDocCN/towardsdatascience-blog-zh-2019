<html>
<head>
<title>A different way to deploy a Python model over Spark</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">在 Spark 上部署 Python 模型的不同方式</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/a-different-way-to-deploy-a-python-model-over-spark-2da4d625f73e?source=collection_archive---------15-----------------------#2019-05-06">https://towardsdatascience.com/a-different-way-to-deploy-a-python-model-over-spark-2da4d625f73e?source=collection_archive---------15-----------------------#2019-05-06</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="174e" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">将预测方法与 Python 类的其余部分分开，然后在 Scala 中实现</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/8c882a5c83ddf87d8728c03497900185.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*EXzYpzDRDw1jX7M7m6D0vQ.jpeg"/></div></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk">Instead of using the whole thing, just take the pieces you need.</figcaption></figure><p id="58a5" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">前阵子，我写了一篇关于<a class="ae lr" rel="noopener" target="_blank" href="/deploy-a-python-model-more-efficiently-over-spark-497fc03e0a8d">如何在 Spark </a>上部署 Python 模型的帖子。方法大致如下:</p><ol class=""><li id="180f" class="ls lt iq kx b ky kz lb lc le lu li lv lm lw lq lx ly lz ma bi translated">根据全部数据的样本在 Python 中训练模型。</li><li id="bc4d" class="ls lt iq kx b ky mb lb mc le md li me lm mf lq lx ly lz ma bi translated">将测试数据收集到任意大小的组中——大约 500，000 条记录对我来说似乎很好。</li><li id="76df" class="ls lt iq kx b ky mb lb mc le md li me lm mf lq lx ly lz ma bi translated">广播训练好的模型，然后使用用户定义的函数对每组记录整体调用模型的<code class="fe mg mh mi mj b">predict</code>方法，而不是对每条单独的记录(如果对未分组的数据帧调用 UDF，Spark 就会这样做)。</li></ol><p id="6b21" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">该方法利用了支持 scikit-learn 的支持 numpy 的优化，并减少了您必须经历序列化和反序列化模型对象的昂贵过程的次数。</p><p id="d0c6" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">我最近采用了一种不同的方式在 Spark 上部署 Python 模型，不需要对大量数据进行分组和分解。我仍然在 Python 中对全部数据的样本进行模型训练，但是我将调用 predict 方法所需的一切存储在一个 JSON 文件中，然后该文件可以被调用到一个可以实现 predict 方法的 Scala 函数中。</p><p id="fb82" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">例如，以 sci kit-learn<a class="ae lr" href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html" rel="noopener ugc nofollow" target="_blank">RandomForestRegressor</a>为例。<code class="fe mg mh mi mj b">predict</code>方法是一堆个体决策树的<code class="fe mg mh mi mj b">predict</code>方法结果的平均值，但是方法本身的实现根本不使用树结构。它将所有内容编码成一系列列表。</p><p id="a46a" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">以下代码创建了一个纯 Python 函数，该函数将精确再现经过训练的 RandomForestRegressor 的预测:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mk ml l"/></div></figure><p id="1215" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">看一下<code class="fe mg mh mi mj b">tree_template</code>字符串。我们从五个列表开始——每个列表都有树中的节点。<code class="fe mg mh mi mj b">features</code>列表中的唯一值与模型训练所依据的特征一样多。我们从列表的第一个值开始—索引 0。如果索引 0 处的值是，比如说，3，那么我们取出模型被训练所基于的第三个特征的值。然后我们从<code class="fe mg mh mi mj b">thresholds</code>列表中取出索引零值。如果所选特征的值小于或等于相应阈值的值，那么我们查看<code class="fe mg mh mi mj b">children_left</code>列表的零索引值。否则，我们查看<code class="fe mg mh mi mj b">children_right</code>列表的零索引值。不管怎样，这个值就是我们的新索引，然后我们重新开始这个过程。我们一直这样做，直到子列表中的值成为“您已经到达了树的末尾”的占位符。在 scikit-learn 中，这个占位符的默认值是-2。此时，无论您当前在哪个索引上，您都可以从<code class="fe mg mh mi mj b">values</code>列表中查找该索引的值。那是你的预测。</p><p id="2ccd" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">所以，是的，这是一个很大的数据量——拥有几十个特征的决策树回归器通常有大约 100，000 个节点。但是导航树以获得预测的逻辑非常简单。因此，您所要做的就是创建一个包含每棵树的列表的函数，以及从一个索引跳到另一个索引的逻辑。然后取一组特征，从每棵树上得到预测值，并取平均值。那是你的随机森林。</p><p id="e778" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">很容易将所有这些信息转储到 JSON。下面的函数就是这样做的。它只需要一个经过训练的 RandomForestRegressor 对象、按照训练中使用的顺序排列的特性列表，以及一个将 JSON 文件转储到的文件路径。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mk ml l"/></div></figure><p id="1cd3" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">单棵树的输出如下所示:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mk ml l"/></div></figure><p id="a612" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">下一段代码来自我的同事 Sam Hendley，他已经忘记了比我所知道的更多的 Scala 知识。它从 JSON 文件中读入树信息，实现每棵树的预测逻辑，然后对整个森林进行平均。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mk ml l"/></div></figure><p id="c4a3" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">在 Scala 中实现预测避免了对函数的 Python 表示进行序列化和反序列化的过程——一切都可以直接在 JVM 上完成。随机森林是这里最复杂的用例之一。在任何产生系数的模型中，将预测函数转换成 JSON 和 Scala 甚至更容易。</p></div></div>    
</body>
</html>