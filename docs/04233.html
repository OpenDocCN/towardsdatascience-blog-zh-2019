<html>
<head>
<title>Making an Autoencoder</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">制作自动编码器</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/how-to-make-an-autoencoder-2f2d99cd5103?source=collection_archive---------10-----------------------#2019-07-02">https://towardsdatascience.com/how-to-make-an-autoencoder-2f2d99cd5103?source=collection_archive---------10-----------------------#2019-07-02</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="9c7a" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">使用 Keras 和 MNIST 培训</h2></div><h1 id="92d6" class="kf kg iq bd kh ki kj kk kl km kn ko kp jw kq jx kr jz ks ka kt kc ku kd kv kw bi translated">了解自动编码器:</h1><figure class="ky kz la lb gt lc gh gi paragraph-image"><div role="button" tabindex="0" class="ld le di lf bf lg"><div class="gh gi kx"><img src="../Images/a661f4c73f2f40fc3f94e897bca929f2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*E7PuQJU9HNpwDOVi8kPrrw.png"/></div></div><figcaption class="lj lk gj gh gi ll lm bd b be z dk">Image of Autoencoder Architecture created by Arvin Singh Kushwaha</figcaption></figure><p id="814b" class="pw-post-body-paragraph ln lo iq lp b lq lr jr ls lt lu ju lv lw lx ly lz ma mb mc md me mf mg mh mi ij bi translated">自动编码器是一类无监督网络，由两个主要网络组成:编码器和解码器。</p><p id="2295" class="pw-post-body-paragraph ln lo iq lp b lq lr jr ls lt lu ju lv lw lx ly lz ma mb mc md me mf mg mh mi ij bi translated">无监督网络是在没有任何训练标签的情况下从数据中学习模式的网络。网络在没有被告知模式应该是什么的情况下在数据中找到它的模式。</p><p id="3903" class="pw-post-body-paragraph ln lo iq lp b lq lr jr ls lt lu ju lv lw lx ly lz ma mb mc md me mf mg mh mi ij bi translated">相反，有监督网络，其中当给定特定输入时，网络被训练以返回特定输出。</p><p id="d3f8" class="pw-post-body-paragraph ln lo iq lp b lq lr jr ls lt lu ju lv lw lx ly lz ma mb mc md me mf mg mh mi ij bi translated">编码器通常使用一系列密集和/或卷积层将图像编码成以紧凑形式表示图像的固定长度向量，而解码器使用密集和/或卷积层将潜在表示向量转换回相同的图像或另一个修改的图像。</p><p id="74a3" class="pw-post-body-paragraph ln lo iq lp b lq lr jr ls lt lu ju lv lw lx ly lz ma mb mc md me mf mg mh mi ij bi translated">上图显示了一个简单的自动编码器的例子。在这个自动编码器中，您可以看到大小为 X 的输入被压缩成大小为 Z 的潜在向量，然后被解压缩成大小为 X 的相同图像。</p><p id="9c6f" class="pw-post-body-paragraph ln lo iq lp b lq lr jr ls lt lu ju lv lw lx ly lz ma mb mc md me mf mg mh mi ij bi translated">为了生成图像，给解码器网络一个随机输入向量。解码器网络将把输入向量转换成完整的图像。</p></div><div class="ab cl mj mk hu ml" role="separator"><span class="mm bw bk mn mo mp"/><span class="mm bw bk mn mo mp"/><span class="mm bw bk mn mo"/></div><div class="ij ik il im in"><h1 id="e31e" class="kf kg iq bd kh ki mq kk kl km mr ko kp jw ms jx kr jz mt ka kt kc mu kd kv kw bi translated">创建自动编码器:</h1><p id="da08" class="pw-post-body-paragraph ln lo iq lp b lq mv jr ls lt mw ju lv lw mx ly lz ma my mc md me mz mg mh mi ij bi translated">我推荐使用 Google Colab 来运行和训练 Autoencoder 模型。</p><h2 id="d3c0" class="na kg iq bd kh nb nc dn kl nd ne dp kp lw nf ng kr ma nh ni kt me nj nk kv nl bi translated">安装 Tensorflow 2.0</h2><pre class="ky kz la lb gt nm nn no np aw nq bi"><span id="7542" class="na kg iq nn b gy nr ns l nt nu">#If you have a GPU that supports CUDA<br/>$ pip3 install tensorflow-gpu==2.0.0b1</span><span id="878c" class="na kg iq nn b gy nv ns l nt nu">#Otherwise<br/>$ pip3 install tensorflow==2.0.0b1</span></pre><p id="f710" class="pw-post-body-paragraph ln lo iq lp b lq lr jr ls lt lu ju lv lw lx ly lz ma mb mc md me mf mg mh mi ij bi translated">Tensorflow 2.0 内置了 Keras 作为其高级 API。Keras 可通过此导入进行访问:</p><pre class="ky kz la lb gt nm nn no np aw nq bi"><span id="7427" class="na kg iq nn b gy nr ns l nt nu">import tensorflow.keras as keras</span></pre><h2 id="578a" class="na kg iq bd kh nb nc dn kl nd ne dp kp lw nf ng kr ma nh ni kt me nj nk kv nl bi translated">导入必要的模块/包</h2><pre class="ky kz la lb gt nm nn no np aw nq bi"><span id="7a43" class="na kg iq nn b gy nr ns l nt nu">from tensorflow.keras.datasets import mnist<br/>from tensorflow.keras.layers import Dense, Input, Flatten,\<br/>                                    Reshape, LeakyReLU as LR,\<br/>                                    Activation, Dropout<br/>from tensorflow.keras.models import Model, Sequential<br/>from matplotlib import pyplot as plt<br/>from IPython import display # If using IPython, Colab or Jupyter<br/>import numpy as np</span></pre><h2 id="99e6" class="na kg iq bd kh nb nc dn kl nd ne dp kp lw nf ng kr ma nh ni kt me nj nk kv nl bi translated">正在加载 MNIST 数据</h2><pre class="ky kz la lb gt nm nn no np aw nq bi"><span id="aad1" class="na kg iq nn b gy nr ns l nt nu">(x_train, y_train), (x_test, y_test) = mnist.load_data()<br/>x_train = x_train/255.0<br/>x_test = x_test/255.0</span></pre><p id="be11" class="pw-post-body-paragraph ln lo iq lp b lq lr jr ls lt lu ju lv lw lx ly lz ma mb mc md me mf mg mh mi ij bi translated">MNIST 数据集由 70000 个 28 像素乘 28 像素的手写数字图像和 70000 个包含每个数字是哪个数字的信息的向量组成。</p><p id="3393" class="pw-post-body-paragraph ln lo iq lp b lq lr jr ls lt lu ju lv lw lx ly lz ma mb mc md me mf mg mh mi ij bi translated">图像训练数据从[0，255]缩放到[0，1]，以允许使用 sigmoid 激活函数。</p><figure class="ky kz la lb gt lc gh gi paragraph-image"><div class="gh gi nw"><img src="../Images/995b8c4a89319a59ecb77e807f4a93d6.png" data-original-src="https://miro.medium.com/v2/resize:fit:510/format:webp/1*U3_-_P362397tX9Ss3bLNA.png"/></div><figcaption class="lj lk gj gh gi ll lm bd b be z dk">Data from x_train[0]</figcaption></figure><p id="ab0e" class="pw-post-body-paragraph ln lo iq lp b lq lr jr ls lt lu ju lv lw lx ly lz ma mb mc md me mf mg mh mi ij bi translated">为了检查我们的数据，我们将绘制训练数据集中的第一幅图像。</p><pre class="ky kz la lb gt nm nn no np aw nq bi"><span id="970a" class="na kg iq nn b gy nr ns l nt nu"># Plot image data from x_train<br/>plt.imshow(x_train[0], cmap = "gray")<br/>plt.show()</span></pre><h2 id="6026" class="na kg iq bd kh nb nc dn kl nd ne dp kp lw nf ng kr ma nh ni kt me nj nk kv nl bi translated">决定潜在规模</h2><p id="76a9" class="pw-post-body-paragraph ln lo iq lp b lq mv jr ls lt mw ju lv lw mx ly lz ma my mc md me mz mg mh mi ij bi translated">潜在大小是潜在空间的大小:压缩后保存信息的向量。该值是一个至关重要的超参数。如果该值太小，将没有足够的数据用于重建，如果该值太大，可能会发生过度拟合。</p><p id="e70b" class="pw-post-body-paragraph ln lo iq lp b lq lr jr ls lt lu ju lv lw lx ly lz ma mb mc md me mf mg mh mi ij bi translated">我发现一个好的、成功的潜在大小是 32 个值长。</p><pre class="ky kz la lb gt nm nn no np aw nq bi"><span id="2c8b" class="na kg iq nn b gy nr ns l nt nu">LATENT_SIZE = 32</span></pre><h2 id="5f9d" class="na kg iq bd kh nb nc dn kl nd ne dp kp lw nf ng kr ma nh ni kt me nj nk kv nl bi translated">创建编码器</h2><pre class="ky kz la lb gt nm nn no np aw nq bi"><span id="94e0" class="na kg iq nn b gy nr ns l nt nu">encoder = Sequential([<br/>    Flatten(input_shape = (28, 28)),<br/>    Dense(512),<br/>    LR(),<br/>    Dropout(0.5),<br/>    Dense(256),<br/>    LR(),<br/>    Dropout(0.5),<br/>    Dense(128),<br/>    LR(),<br/>    Dropout(0.5),<br/>    Dense(64),<br/>    LR(),<br/>    Dropout(0.5),<br/>    Dense(LATENT_SIZE),<br/>    LR()<br/>])</span></pre><p id="ee22" class="pw-post-body-paragraph ln lo iq lp b lq lr jr ls lt lu ju lv lw lx ly lz ma mb mc md me mf mg mh mi ij bi translated">编码器由一系列致密层和间隙漏失层和泄漏层组成。密集层允许将 28×28 的输入张量压缩到大小为 32 的潜在向量。下降层有助于防止过拟合和泄漏。作为激活层，下降层会在混合中引入非线性。<code class="fe nx ny nz nn b">Dense(LATENT_SIZE)</code>创建大小为 32 的最终矢量。</p><h2 id="99af" class="na kg iq bd kh nb nc dn kl nd ne dp kp lw nf ng kr ma nh ni kt me nj nk kv nl bi translated">创建解码器</h2><pre class="ky kz la lb gt nm nn no np aw nq bi"><span id="d4e2" class="na kg iq nn b gy nr ns l nt nu">decoder = Sequential([<br/>    Dense(64, input_shape = (LATENT_SIZE,)),<br/>    LR(),<br/>    Dropout(0.5),<br/>    Dense(128),<br/>    LR(),<br/>    Dropout(0.5),<br/>    Dense(256),<br/>    LR(),<br/>    Dropout(0.5),<br/>    Dense(512),<br/>    LR(),<br/>    Dropout(0.5),<br/>    Dense(784),<br/>    Activation("sigmoid"),<br/>    Reshape((28, 28))<br/>])</span></pre><p id="4845" class="pw-post-body-paragraph ln lo iq lp b lq lr jr ls lt lu ju lv lw lx ly lz ma mb mc md me mf mg mh mi ij bi translated">解码器本质上与编码器相同，但方向相反。然而，最终的激活层是 s 形的。sigmoid 激活函数输出范围为[0，1]的值，这与我们的缩放图像数据完全吻合。</p><figure class="ky kz la lb gt lc gh gi paragraph-image"><div role="button" tabindex="0" class="ld le di lf bf lg"><div class="gh gi kx"><img src="../Images/2bf790e2c60d80a5912853e4fb26af1b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*L4BcYIyPMD-LX_Nd.png"/></div></div><figcaption class="lj lk gj gh gi ll lm bd b be z dk">Sigmoid Function</figcaption></figure><h2 id="bcd3" class="na kg iq bd kh nb nc dn kl nd ne dp kp lw nf ng kr ma nh ni kt me nj nk kv nl bi translated">创建完整的模型</h2><p id="ea1b" class="pw-post-body-paragraph ln lo iq lp b lq mv jr ls lt mw ju lv lw mx ly lz ma my mc md me mz mg mh mi ij bi translated">要创建完整的模型，必须使用 Keras 功能 API。函数式 API 允许我们将多个模型串在一起。</p><pre class="ky kz la lb gt nm nn no np aw nq bi"><span id="7d5a" class="na kg iq nn b gy nr ns l nt nu">img = Input(shape = (28, 28))</span></pre><p id="b002" class="pw-post-body-paragraph ln lo iq lp b lq lr jr ls lt lu ju lv lw lx ly lz ma mb mc md me mf mg mh mi ij bi translated">这将创建一个占位张量，我们可以将它输入到每个网络中，以获得整个模型的输出。</p><pre class="ky kz la lb gt nm nn no np aw nq bi"><span id="3284" class="na kg iq nn b gy nr ns l nt nu">latent_vector = encoder(img)<br/>output = decoder(latent_vector)</span></pre><p id="8f9f" class="pw-post-body-paragraph ln lo iq lp b lq lr jr ls lt lu ju lv lw lx ly lz ma mb mc md me mf mg mh mi ij bi translated">Keras Functional API 最好的部分是它的可读性。Keras Functional API 允许您将模型直接调用到张量上，并从该张量获得输出。通过将<code class="fe nx ny nz nn b">encoder</code>模型调用到<code class="fe nx ny nz nn b">img</code>张量上，我得到了<code class="fe nx ny nz nn b">latent_vector</code>。同样的事情也可以在<code class="fe nx ny nz nn b">latent_vector</code>上用<code class="fe nx ny nz nn b">decoder</code>模型来完成，这给了我们输出。</p><pre class="ky kz la lb gt nm nn no np aw nq bi"><span id="d61c" class="na kg iq nn b gy nr ns l nt nu">model = Model(inputs = img, outputs = output)<br/>model.compile("nadam", loss = "binary_crossentropy")</span></pre><p id="db09" class="pw-post-body-paragraph ln lo iq lp b lq lr jr ls lt lu ju lv lw lx ly lz ma mb mc md me mf mg mh mi ij bi translated">要创建模型本身，可以使用 model 类并定义模型的输入和输出。</p><p id="31ce" class="pw-post-body-paragraph ln lo iq lp b lq lr jr ls lt lu ju lv lw lx ly lz ma mb mc md me mf mg mh mi ij bi translated">要训练一个模型，你必须编译它。为了编译一个模型，你必须选择一个优化器和一个损失函数。对于优化器，我选择了 Nadam，这是应用于自适应矩估计的内斯特罗夫加速梯度。这是一个改进的 Adam 优化器。对于损失，我选择了二元交叉熵。二进制交叉熵通常用于自动编码器。然而，通常二元交叉熵与二元分类器一起使用。此外，二进制交叉熵只能在[0，1]范围内的输出值之间使用。</p><h2 id="1cae" class="na kg iq bd kh nb nc dn kl nd ne dp kp lw nf ng kr ma nh ni kt me nj nk kv nl bi translated">训练模型</h2><pre class="ky kz la lb gt nm nn no np aw nq bi"><span id="05fa" class="na kg iq nn b gy nr ns l nt nu">EPOCHS = 60</span></pre><p id="6d65" class="pw-post-body-paragraph ln lo iq lp b lq lr jr ls lt lu ju lv lw lx ly lz ma mb mc md me mf mg mh mi ij bi translated">值<code class="fe nx ny nz nn b">EPOCHS</code>是一个设置为 60 的超参数。一般来说，时期越多越好，至少在模型稳定下来之前是这样。</p><pre class="ky kz la lb gt nm nn no np aw nq bi"><span id="1b09" class="na kg iq nn b gy nr ns l nt nu">#Only do plotting if you have IPython, Jupyter, or using Colab</span></pre><p id="a379" class="pw-post-body-paragraph ln lo iq lp b lq lr jr ls lt lu ju lv lw lx ly lz ma mb mc md me mf mg mh mi ij bi translated">只有在使用 IPython、Jupyter 或 Colab 时，才建议重复绘图，以便 matplotlib 绘图是内联的，而不是重复创建单个绘图。</p><pre class="ky kz la lb gt nm nn no np aw nq bi"><span id="4e3a" class="na kg iq nn b gy nr ns l nt nu">for epoch in range(EPOCHS):<br/>    fig, axs = plt.subplots(4, 4)<br/>    rand = x_test[np.random.randint(0, 10000, 16)].reshape((4, 4, 1, 28, 28))<br/>    <br/>    display.clear_output() # If you imported display from IPython<br/>    <br/>    for i in range(4):<br/>        for j in range(4):<br/>            axs[i, j].imshow(model.predict(rand[i, j])[0], cmap = "gray")<br/>            axs[i, j].axis("off")<br/>    <br/>    plt.subplots_adjust(wspace = 0, hspace = 0)<br/>    plt.show()<br/>    print("-----------", "EPOCH", epoch, "-----------")<br/>    model.fit(x_train, x_train)</span></pre><p id="ac5d" class="pw-post-body-paragraph ln lo iq lp b lq lr jr ls lt lu ju lv lw lx ly lz ma mb mc md me mf mg mh mi ij bi translated">首先，我们创建具有 4 行 4 列子曲线的曲线，并选择 16 个随机测试数据图像来检查网络的性能。</p><p id="a7b5" class="pw-post-body-paragraph ln lo iq lp b lq lr jr ls lt lu ju lv lw lx ly lz ma mb mc md me mf mg mh mi ij bi translated">接下来，我们清空屏幕(仅适用于 IPython、Jupyter 和 Colab ),并在随机测试图像上绘制模型预测。</p><p id="e600" class="pw-post-body-paragraph ln lo iq lp b lq lr jr ls lt lu ju lv lw lx ly lz ma mb mc md me mf mg mh mi ij bi translated">最后，我们训练模型。为了训练模型，我们简单地在训练图像数据上调用<code class="fe nx ny nz nn b">model.fit</code>。还记得 autoencoder 的目标是如何获取输入数据，压缩它，解压缩它，然后输出输入数据的副本吗？这意味着输入和目标输出都是训练图像数据。</p><p id="5934" class="pw-post-body-paragraph ln lo iq lp b lq lr jr ls lt lu ju lv lw lx ly lz ma mb mc md me mf mg mh mi ij bi translated">如你所见，这些生成的图像非常好。然而，这些图像最大的问题是模糊不清。这些问题中的许多可以用其他类型的生成网络或者甚至其他类型的自动编码器来修复。</p><h2 id="67fb" class="na kg iq bd kh nb nc dn kl nd ne dp kp lw nf ng kr ma nh ni kt me nj nk kv nl bi translated">完整代码</h2><pre class="ky kz la lb gt nm nn no np aw nq bi"><span id="89ae" class="na kg iq nn b gy nr ns l nt nu">from tensorflow.keras.datasets import mnist<br/>from tensorflow.keras.layers import Dense, Input, Flatten,\<br/>                                    Reshape, LeakyReLU as LR,\<br/>                                    Activation, Dropout<br/>from tensorflow.keras.models import Model, Sequential<br/>from matplotlib import pyplot as plt<br/>from IPython import display # If using IPython, Colab or Jupyter<br/>import numpy as np</span><span id="2a55" class="na kg iq nn b gy nv ns l nt nu">(x_train, y_train), (x_test, y_test) = mnist.load_data()<br/>x_train = x_train/255.0<br/>x_test = x_test/255.0</span><span id="6dd0" class="na kg iq nn b gy nv ns l nt nu"># Plot image data from x_train<br/>plt.imshow(x_train[0], cmap = "gray")<br/>plt.show()</span><span id="a05a" class="na kg iq nn b gy nv ns l nt nu">LATENT_SIZE = 32</span><span id="0bb9" class="na kg iq nn b gy nv ns l nt nu">encoder = Sequential([<br/>    Flatten(input_shape = (28, 28)),<br/>    Dense(512),<br/>    LR(),<br/>    Dropout(0.5),<br/>    Dense(256),<br/>    LR(),<br/>    Dropout(0.5),<br/>    Dense(128),<br/>    LR(),<br/>    Dropout(0.5),<br/>    Dense(64),<br/>    LR(),<br/>    Dropout(0.5),<br/>    Dense(LATENT_SIZE),<br/>    LR()<br/>])</span><span id="8727" class="na kg iq nn b gy nv ns l nt nu">decoder = Sequential([<br/>    Dense(64, input_shape = (LATENT_SIZE,)),<br/>    LR(),<br/>    Dropout(0.5),<br/>    Dense(128),<br/>    LR(),<br/>    Dropout(0.5),<br/>    Dense(256),<br/>    LR(),<br/>    Dropout(0.5),<br/>    Dense(512),<br/>    LR(),<br/>    Dropout(0.5),<br/>    Dense(784),<br/>    Activation("sigmoid"),<br/>    Reshape((28, 28))<br/>])</span><span id="dcfe" class="na kg iq nn b gy nv ns l nt nu">img = Input(shape = (28, 28))<br/>latent_vector = encoder(img)<br/>output = decoder(latent_vector)</span><span id="ae73" class="na kg iq nn b gy nv ns l nt nu">model = Model(inputs = img, outputs = output)<br/>model.compile("nadam", loss = "binary_crossentropy")</span><span id="2bcd" class="na kg iq nn b gy nv ns l nt nu">EPOCHS = 60</span><span id="4ee1" class="na kg iq nn b gy nv ns l nt nu">#Only do plotting if you have IPython, Jupyter, or using Colab</span><span id="3a6a" class="na kg iq nn b gy nv ns l nt nu">for epoch in range(EPOCHS):<br/>    fig, axs = plt.subplots(4, 4)<br/>    rand = x_test[np.random.randint(0, 10000, 16)].reshape((4, 4, 1, 28, 28))<br/>    <br/>    display.clear_output() # If you imported display from IPython<br/>    <br/>    for i in range(4):<br/>        for j in range(4):<br/>            axs[i, j].imshow(model.predict(rand[i, j])[0], cmap = "gray")<br/>            axs[i, j].axis("off")<br/>    <br/>    plt.subplots_adjust(wspace = 0, hspace = 0)<br/>    plt.show()<br/>    print("-----------", "EPOCH", epoch, "-----------")<br/>    model.fit(x_train, x_train)</span></pre><p id="d9da" class="pw-post-body-paragraph ln lo iq lp b lq lr jr ls lt lu ju lv lw lx ly lz ma mb mc md me mf mg mh mi ij bi translated">这段代码的 Google Colab 可以在<a class="ae oa" href="https://colab.research.google.com/drive/19BBIU0A7c4ExRD0cly-mMs7LqZkO44K_" rel="noopener ugc nofollow" target="_blank">这里</a>找到。</p><p id="b8ba" class="pw-post-body-paragraph ln lo iq lp b lq lr jr ls lt lu ju lv lw lx ly lz ma mb mc md me mf mg mh mi ij bi translated">经过 60 个纪元的训练，我得到了这个图像:</p><figure class="ky kz la lb gt lc gh gi paragraph-image"><div class="gh gi ob"><img src="../Images/c9e211fd5bbffc04f62556b516bd57af.png" data-original-src="https://miro.medium.com/v2/resize:fit:514/format:webp/1*5Ix9ocbRpopK22XNI7VJUg.png"/></div><figcaption class="lj lk gj gh gi ll lm bd b be z dk">Generated Image after 60 epochs</figcaption></figure><p id="45c5" class="pw-post-body-paragraph ln lo iq lp b lq lr jr ls lt lu ju lv lw lx ly lz ma mb mc md me mf mg mh mi ij bi translated">如你所见，结果相当不错。自动编码器成功地编码和解码了潜在的空间矢量，质量相当好。这种自动编码器是“普通的”类型，但是其他类型的自动编码器，如变型自动编码器，有更好的图像质量。此外，通过增加历元的数量，可以进一步改善结果。</p><h1 id="6854" class="kf kg iq bd kh ki kj kk kl km kn ko kp jw kq jx kr jz ks ka kt kc ku kd kv kw bi translated">自动编码器的用途</h1><p id="9406" class="pw-post-body-paragraph ln lo iq lp b lq mv jr ls lt mw ju lv lw mx ly lz ma my mc md me mz mg mh mi ij bi translated">简单地说，自动编码器学习如何在没有监督的情况下有效地压缩和解压缩数据。这意味着自动编码器可以用于降维。自动编码器的解码器部分也可以用于从噪声矢量生成图像。</p><p id="bae8" class="pw-post-body-paragraph ln lo iq lp b lq lr jr ls lt lu ju lv lw lx ly lz ma mb mc md me mf mg mh mi ij bi translated">自动编码器网络的实际应用包括:</p><ul class=""><li id="c594" class="oc od iq lp b lq lr lt lu lw oe ma of me og mi oh oi oj ok bi translated">去噪</li><li id="df16" class="oc od iq lp b lq ol lt om lw on ma oo me op mi oh oi oj ok bi translated">图像重建</li><li id="994a" class="oc od iq lp b lq ol lt om lw on ma oo me op mi oh oi oj ok bi translated">图象生成</li><li id="255a" class="oc od iq lp b lq ol lt om lw on ma oo me op mi oh oi oj ok bi translated">数据压缩和解压缩</li></ul></div></div>    
</body>
</html>