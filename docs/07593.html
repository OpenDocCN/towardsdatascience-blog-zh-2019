<html>
<head>
<title>Implicit-Decoder part 1 - 3D reconstruction</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">隐式解码器部分 1 - 3D 重建</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/implicit-decoder-3d-reconstruction-838193f9b760?source=collection_archive---------31-----------------------#2019-10-22">https://towardsdatascience.com/implicit-decoder-3d-reconstruction-838193f9b760?source=collection_archive---------31-----------------------#2019-10-22</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><h2 id="8010" class="ir is it bd b dl iu iv iw ix iy iz dk ja translated" aria-label="kicker paragraph">内部人工智能</h2><div class=""/><div class=""><h2 id="a5bd" class="pw-subtitle-paragraph jz jc it bd b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq dk translated"><strong class="ak">使用深度学习从单幅图像进行 3D 重建</strong></h2></div><p id="5c5d" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">一种编码-解码类型的神经网络，用于对 2D 图像中形状的 3D 结构进行编码，然后对该结构进行解码并重建 3D 形状。这是我见过的最高质量的 3D 图像重建。</p><h2 id="e9ad" class="ln lo it bd lp lq lr dn ls lt lu dp lv la lw lx ly le lz ma mb li mc md me iz bi translated">一些细节</h2><ul class=""><li id="2cf7" class="mf mg it kt b ku mh kx mi la mj le mk li ml lm mm mn mo mp bi translated">输入图像:128X128 像素</li><li id="4af9" class="mf mg it kt b ku mq kx mr la ms le mt li mu lm mm mn mo mp bi translated">透明图像背景</li><li id="49fd" class="mf mg it kt b ku mq kx mr la ms le mt li mu lm mm mn mo mp bi translated">训练和生成是基于相似对象的类别来完成的</li><li id="6ae9" class="mf mg it kt b ku mq kx mr la ms le mt li mu lm mm mn mo mp bi translated">输出体素:基本分辨率为 64X64X64 体素。但是，可以产生任何所需分辨率的输出(！)而无需重新训练神经网络</li></ul><h2 id="ee81" class="ln lo it bd lp lq lr dn ls lt lu dp lv la lw lx ly le lz ma mb li mc md me iz bi translated">神经网络结构:</h2><ul class=""><li id="b052" class="mf mg it kt b ku mh kx mi la mj le mk li ml lm mm mn mo mp bi translated">2D 编码器—基于 ResNet18。从输入图像生成大小为 128 的编码向量(z 向量)</li><li id="db03" class="mf mg it kt b ku mq kx mr la ms le mt li mu lm mm mn mo mp bi translated">解码器——简单的 6 个全连接层，带 1 个分类输出神经元。接收空间中的 z 向量和- <strong class="kt jd"> 1 </strong> - 3D 坐标作为输入，并分类该坐标是否属于物体的质量。</li></ul><figure class="mw mx my mz gt na gh gi paragraph-image"><div role="button" tabindex="0" class="nb nc di nd bf ne"><div class="gh gi mv"><img src="../Images/38be0a4f0a2c80f725d26a7bbc71d843.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*OWOzBdzqT214bETaRIxPSw.png"/></div></div><figcaption class="nh ni gj gh gi nj nk bd b be z dk">Neural Network Structure</figcaption></figure><h2 id="5db8" class="ln lo it bd lp lq lr dn ls lt lu dp lv la lw lx ly le lz ma mb li mc md me iz bi translated">重建是如何从这个网络发生的？</h2><p id="880d" class="pw-post-body-paragraph kr ks it kt b ku mh kd kw kx mi kg kz la nl lc ld le nm lg lh li nn lk ll lm im bi translated">为了重建物体的整个结构，空间中的所有 3D 坐标被发送到解码器(在该论文的情况下，每个物体有 64X64X64 坐标)，以及来自图像的单个 z 向量。解码器对每个坐标进行分类，并创建 3D 结构的表示。这创建了 3D 对象的体素表示。然后，使用<a class="ae no" href="https://en.wikipedia.org/wiki/Marching_cubes" rel="noopener ugc nofollow" target="_blank">行进立方体</a>算法来创建网格表示。</p><h1 id="0546" class="np lo it bd lp nq nr ns ls nt nu nv lv ki nw kj ly kl nx km mb ko ny kp me nz bi translated">汽车类别重建示例</h1><figure class="mw mx my mz gt na gh gi paragraph-image"><div class="gh gi oa"><img src="../Images/4d71b43c4bc5d0760f9c88fba6fb2f0b.png" data-original-src="https://miro.medium.com/v2/resize:fit:994/format:webp/0*KeN3ahvXL5Fr2FxJ.jpg"/></div></figure><p id="90e8" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">第一列是输入图像，第二列是 AI 3D 重建，最后一列是汽车的原始 3D 对象(或者，用技术语言来说，是地面真相)。这个图像案例中的神经网络是在汽车模型上训练的。在论文中有在椅子、飞机等上面训练的结果。请注意，本文中的输入输出图像和体素分辨率是特定的，但可以根据任何所需的实现进行相应的更改。</p><h2 id="d550" class="ln lo it bd lp lq lr dn ls lt lu dp lv la lw lx ly le lz ma mb li mc md me iz bi translated">等等！最后一辆车是怎么改造的？</h2><p id="6101" class="pw-post-body-paragraph kr ks it kt b ku mh kd kw kx mi kg kz la nl lc ld le nm lg lh li nn lk ll lm im bi translated">软件甚至没有看到图像中的车头。这就是 DL 培训的力量所在。由于我们通过许多以前的汽车例子来训练网络，它知道如何推断它从未见过的新车的形状。外推是可能的，因为网络是在来自相似类别的对象上训练的，所以网络有效地重建它之前被训练的相似结构，该结构匹配它在图像中看到的结构。</p><h1 id="c41f" class="np lo it bd lp nq nr ns ls nt nu nv lv ki nw kj ly kl nx km mb ko ny kp me nz bi translated">现有的三维重建软件</h1><p id="9e8a" class="pw-post-body-paragraph kr ks it kt b ku mh kd kw kx mi kg kz la nl lc ld le nm lg lh li nn lk ll lm im bi translated">现在有很多工具可以从图像中进行三维重建。这些工具使用经典的<a class="ae no" href="https://en.wikipedia.org/wiki/Photogrammetry" rel="noopener ugc nofollow" target="_blank">摄影测量</a>技术，从同一物体的多个图像中重建 3D 模型。两个例子:</p><ul class=""><li id="d7cb" class="mf mg it kt b ku kv kx ky la ob le oc li od lm mm mn mo mp bi translated"><a class="ae no" href="https://agisoft.com" rel="noopener ugc nofollow" target="_blank"> Agisoft </a></li><li id="c33e" class="mf mg it kt b ku mq kx mr la ms le mt li mu lm mm mn mo mp bi translated"><a class="ae no" href="https://www.autodesk.com/products/recap/overview" rel="noopener ugc nofollow" target="_blank">欧特克公司——重述</a></li></ul><p id="24c2" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">这种类型的软件可以从当前的 AI 研究中受益。简单平面的重建，即使它们在图像中不完全可见，处理图像中的光反射或像差，更好的比例估计等等。所有这些都可以使用类似的神经网络解决方案来改进。</p><h1 id="ddbc" class="np lo it bd lp nq nr ns ls nt nu nv lv ki nw kj ly kl nx km mb ko ny kp me nz bi translated">类似的研究</h1><p id="163e" class="pw-post-body-paragraph kr ks it kt b ku mh kd kw kx mi kg kz la nl lc ld le nm lg lh li nn lk ll lm im bi translated">由于编码-解码架构和 GANs，单图像 3D 重建目前正在发展。这种研究的一个很好的例子是:<a class="ae no" href="https://2d3d.ai/index.php/2019/10/09/3d-scene-reconstruction-from-single-image/" rel="noopener ugc nofollow" target="_blank">单幅图像的 3D 场景重建</a> —用于场景重建。单个物体重建的质量看起来不是很好，但令人印象深刻的是，他们是从自然场景图像中实现的。</p><h1 id="1b73" class="np lo it bd lp nq nr ns ls nt nu nv lv ki nw kj ly kl nx km mb ko ny kp me nz bi translated">ShapeNet</h1><p id="9dba" class="pw-post-body-paragraph kr ks it kt b ku mh kd kw kx mi kg kz la nl lc ld le nm lg lh li nn lk ll lm im bi translated">与 ImageNet 的图像类似，ShapeNet 是一个大型的带注释的 3D 模型数据集，以及围绕 3D 主题进行 ML 研究的竞赛和人群。大多数(如果不是全部的话)3D ML 研究使用该数据集进行训练和基准测试，包括隐式解码器研究。有两个主要的 Shapenet 数据集，最新的是 ShapeNetCore.v2:</p><ul class=""><li id="1c2e" class="mf mg it kt b ku kv kx ky la ob le oc li od lm mm mn mo mp bi translated">55 个常见对象类别</li><li id="1899" class="mf mg it kt b ku mq kx mr la ms le mt li mu lm mm mn mo mp bi translated">大约 51，300 个独特的 3D 模型</li><li id="4828" class="mf mg it kt b ku mq kx mr la ms le mt li mu lm mm mn mo mp bi translated">验证每个 3D 模型的类别和对齐(位置和方向)。</li></ul><h1 id="b487" class="np lo it bd lp nq nr ns ls nt nu nv lv ki nw kj ly kl nx km mb ko ny kp me nz bi translated">参考</h1><ul class=""><li id="8410" class="mf mg it kt b ku mh kx mi la mj le mk li ml lm mm mn mo mp bi translated">博文原文:<a class="ae no" href="https://2d3d.ai/index.php/2019/10/11/implicit-decoder-part-1-3d-reconstruction/" rel="noopener ugc nofollow" target="_blank">https://2d3d . ai/index . PHP/2019/10/11/implicit-decoder-part-1-3d-re construction/</a></li><li id="0a92" class="mf mg it kt b ku mq kx mr la ms le mt li mu lm mm mn mo mp bi translated">研究:[1]陈、、。"学习生成式形状建模的隐式场."<em class="oe">IEEE 计算机视觉和模式识别会议论文集</em>。2019.</li><li id="a4c9" class="mf mg it kt b ku mq kx mr la ms le mt li mu lm mm mn mo mp bi translated">shape net:<a class="ae no" href="https://www.shapenet.org/" rel="noopener ugc nofollow" target="_blank">https://www.shapenet.org/</a></li></ul><p id="81c4" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated"><a class="ae no" rel="noopener" target="_blank" href="/implicit-decoder-part-2-3d-generation-80dbcad8a563">隐式解码器第 2 部分— 3D 生成</a></p></div></div>    
</body>
</html>