<html>
<head>
<title>Multivariate Differential Calculus and Optimization-Part 2</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">多元微分学和最优化-第二部分</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/multivariate-differential-calculus-and-optimization-part-2-d157af25d82d?source=collection_archive---------22-----------------------#2019-09-01">https://towardsdatascience.com/multivariate-differential-calculus-and-optimization-part-2-d157af25d82d?source=collection_archive---------22-----------------------#2019-09-01</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><figure class="is it gp gr iu iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi ir"><img src="../Images/60eb260b142c057b7eb63c3f8ce4db20.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*IgprHQQ9Av-pnOUL"/></div></div></figure><div class=""/><p id="f549" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">在我之前的<a class="ae kz" href="https://medium.com/@valentinaalto/multivariate-differential-calculus-and-optimization-part-1-5c6b84831b27" rel="noopener">文章</a>中，我介绍了一些概念，如果我们想在多元环境中设置一个优化问题，这些概念是必要的。</p><p id="193b" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">在这里，我们将首先讨论如何检查曲面的平滑度(这是部署优化任务的主要假设)，然后我们将了解如何在多元环境中寻找局部/全局最大值/最小值。</p><h1 id="f8bb" class="la lb je bd lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx bi translated">光滑性和可微性</h1><p id="7ba5" class="pw-post-body-paragraph kb kc je kd b ke ly kg kh ki lz kk kl km ma ko kp kq mb ks kt ku mc kw kx ky im bi translated">用一种非常直观的方式，我们可以说一个曲面是光滑的，如果它既没有洞，也没有角，也没有跳跃。这与一维空间中连续性的概念相同，但扩展到了多元环境中。</p><p id="d210" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">更具体地说，指出一个曲面在一个点<strong class="kd jf"> p0 </strong>上可微意味着我们可以以任何我们想要的方式到达那个点，而不仅仅是通过偏导数。这意味着存在一个与<strong class="kd jf"> p0 </strong>相切的平面，该平面可以逼近<strong class="kd jf"> p0 </strong>的一个邻域(最好:<em class="md">任何一个</em>邻域)中的曲面。</p><p id="0780" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">让我们用下面的表面来形象化这个概念:</p><figure class="mf mg mh mi gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi me"><img src="../Images/ee868ff869dbba15d11e8228c55aace6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*7aU_CbKcP4itdDUT"/></div></div></figure><p id="2092" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">根据定义，曲面上和切面上的点<strong class="kd jf"> p0 </strong>的值是相同的。另一方面，挑一个接近<strong class="kd jf"> p0 </strong>的点，姑且说<strong class="kd jf"> p </strong>吧，我们可以看到<strong class="kd jf"> p </strong>在表面上的值和在平面上的值是不一样的:我们将这种差异称为<em class="md">误差</em>。因此，我们可以将曲面在一般点<strong class="kd jf"> p </strong>上的近似表示如下:</p><figure class="mf mg mh mi gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi mj"><img src="../Images/4f6be3cfe7dc191cdf9162ec99437ed5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*PSozr6YFMERFIz01"/></div></div></figure><p id="a82b" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">其思想是，如果相对于<strong class="kd jf"> p0 </strong>和<strong class="kd jf"> p </strong>之间的距离，误差可以忽略不计，则该平面是该表面的良好近似。换句话说，我们希望误差是距离的一个小的<em class="md"> o </em>，因此:</p><figure class="mf mg mh mi gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi mk"><img src="../Images/eab111d70a85a9c8734f9bd59a5a9896.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*dieNiqEfkkjhUgkZ"/></div></div></figure><figure class="mf mg mh mi gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi ml"><img src="../Images/3cb9b35aa00f3b85abd766666c340788.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*wOLh67NzVoiMk0KB"/></div></div></figure><p id="09d1" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">很好，现在我们可以开始优化程序了。</p><h1 id="e5cd" class="la lb je bd lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx bi translated">最佳化</h1><p id="0e88" class="pw-post-body-paragraph kb kc je kd b ke ly kg kh ki lz kk kl km ma ko kp kq mb ks kt ku mc kw kx ky im bi translated">正如预期的那样，从现在起我们将考虑给定的可微性:这将是我们强有力的假设。话虽如此，让我们首先想象一下我们想要解决的问题:</p><figure class="mf mg mh mi gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi mk"><img src="../Images/a061a13148907a0d29f1ffa29c3c82ac.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*G2mctaAvy72xsUej"/></div></div></figure><p id="5c46" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">这个想法是找到我们表面的最大值和最小值，我们可以从一个基本定理开始，费马定理:</p><p id="65e9" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated"><em class="md">“若 f(x，y)在其自然域上可微，则每个最优点都有一个水平切面”。</em></p><p id="91cd" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">所以如果我们看看切面的方程:</p><figure class="mf mg mh mi gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi mm"><img src="../Images/87874c63cffc0c0116b943f8ec11d8ef.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*7igP5Io7ME1fv8XN"/></div></div></figure><p id="4fda" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">这意味着红色部分必须等于零，这样平面才是水平的。这意味着函数的梯度(其分量是偏导数)必须等于 0 向量:</p><figure class="mf mg mh mi gt iv gh gi paragraph-image"><div class="gh gi mn"><img src="../Images/7f71eace506841e07bfb8d7cf619e663.png" data-original-src="https://miro.medium.com/v2/resize:fit:816/0*_xjBnd0PzmTM6OFA"/></div></figure><p id="4070" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">因此，通过设置梯度等于零，我们挑选了所有的候选最佳点。然而，我们该如何对它们进行分类呢？为此，我们需要二阶泰勒多项式，然后研究红色量的符号:</p><figure class="mf mg mh mi gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi mk"><img src="../Images/0dca551f689cd578d72dfe9092aa932c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*QRZVl8pVGLtGhyJk"/></div></div></figure><p id="9792" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">如果它是正的，这意味着曲面的函数在其周围各处取大于<strong class="kd jf"> p0 </strong>的值，因此<strong class="kd jf"> p0 </strong>是局部最小值。另一方面，如果数量是负的，这意味着该函数在其周围各处取比<strong class="kd jf"> p0 </strong>低的值，因此<strong class="kd jf"> p0 </strong>是局部最大值。</p><p id="c957" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">我们可以很容易地研究该量的符号，因为它是具有代表性矩阵的二次型:</p><figure class="mf mg mh mi gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi mo"><img src="../Images/f9a97d626dfc0351d79bcb1d7ac97ef1.png" data-original-src="https://miro.medium.com/v2/resize:fit:742/0*3l9NScCfPK4NrXis"/></div></div></figure><p id="e137" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">这就是所谓的海森矩阵。因此，我们可以说，如果在<strong class="kd jf"> p0 </strong>处评估的 H 是正定的，<strong class="kd jf"> p0 </strong>是局部最小值；如果 H 是负定的，<strong class="kd jf"> p0 </strong>是局部最大值；如果是不定的，<strong class="kd jf"> p0 </strong>不是一个最优点。只要 H 是非奇异矩阵(因此它的行列式必须不等于 0)，一切都成立。</p><figure class="mf mg mh mi gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi mk"><img src="../Images/7b0a9e3d5fb7a5eafb84c4aeeb83b23a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*Tw2dzxDKV-BaQs3Z"/></div></div></figure><p id="dbae" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">优化是数据科学中的一个基本概念，可以采用许多不同的技术。然而，背后的想法总是相同的:选择一个目标函数(在机器学习算法的情况下，它由损失函数表示，因此优化意味着最小化)并将问题设置为多元环境。</p><p id="f911" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">当然，预建的算法会为你做所有的计算，然而重要的是要放弃直觉，因为即使是自我学习的算法也需要调整(或者至少初始化)。</p></div><div class="ab cl mp mq hx mr" role="separator"><span class="ms bw bk mt mu mv"/><span class="ms bw bk mt mu mv"/><span class="ms bw bk mt mu"/></div><div class="im in io ip iq"><p id="ec22" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated"><em class="md">原载于 2019 年 9 月 1 日</em><a class="ae kz" href="https://datasciencechalktalk.com/2019/09/01/multivariate-differential-calculus-and-optimization-part-2/" rel="noopener ugc nofollow" target="_blank"><em class="md">http://datasciencechalktalk.com</em></a>T22。</p></div></div>    
</body>
</html>