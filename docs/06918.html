<html>
<head>
<title>Neural Networks for Option Pricing</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">期权定价的神经网络</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/neural-networks-for-option-pricing-danielcotto-c24569ad0bb?source=collection_archive---------10-----------------------#2019-10-01">https://towardsdatascience.com/neural-networks-for-option-pricing-danielcotto-c24569ad0bb?source=collection_archive---------10-----------------------#2019-10-01</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><h2 id="cfab" class="ir is it bd b dl iu iv iw ix iy iz dk ja translated" aria-label="kicker paragraph">金融中的人工神经网络</h2><div class=""/><div class=""><h2 id="5bb2" class="pw-subtitle-paragraph jz jc it bd b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq dk translated">使用 R 在布莱克&amp;斯科尔斯世界中学习</h2></div><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi kr"><img src="../Images/3bdcda839c739350e1a3f6e6308d88d7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*5aJ91WurWd7ouEdU"/></div></div><figcaption class="ld le gj gh gi lf lg bd b be z dk">Photo by <a class="ae lh" href="https://unsplash.com/@alinnnaaaa?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Alina Grubnyak</a> on <a class="ae lh" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><p id="a785" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">本文只是将深度学习应用于期权定价的一种尝试。特别是，主要目标是展示人工神经网络从数据集“学习”模型的能力。</p></div><div class="ab cl me mf hx mg" role="separator"><span class="mh bw bk mi mj mk"/><span class="mh bw bk mi mj mk"/><span class="mh bw bk mi mj"/></div><div class="im in io ip iq"><p id="c36e" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">具有多个隐藏层的人工神经网络(ann)已经成为从大数据集检测模式的成功方法。人工神经网络实现通常可以分解为两个独立的阶段:训练部分和测试部分。在训练阶段，人工神经网络从数据集“学习”模型，而在测试阶段，经过训练的人工神经网络可用于预测结果</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi ml"><img src="../Images/1420a9cf55c43da54c2e987fbc74766d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*FsklYIOQvp-FfJyu0yQTqA.jpeg"/></div></div></figure><p id="fc37" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">该架构是由定义数量的神经元组成的不同层的组合。将前一层的神经元与后一层的神经元连接起来，可以使用来自前一步的输出信号作为下一层的输入信号。</p><p id="ebf7" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">激活函数ψ()增加了系统的非线性。虽然有许多函数，但为了本节的目的，我将只使用 ReLu 函数，定义如下:</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi mm"><img src="../Images/171a0924e0c6b67084e4d2ed8108917e.png" data-original-src="https://miro.medium.com/v2/resize:fit:596/format:webp/1*jG1a_lWlugwQVd8GMYG-3Q.png"/></div></figure><p id="36fd" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">为了评估性能，均方误差(MSE)</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi mn"><img src="../Images/699d995371c072576802494f567c5fec.png" data-original-src="https://miro.medium.com/v2/resize:fit:792/format:webp/1*VqdlrwSe7xTybT92Dlcb4Q.png"/></div></figure><p id="1ef2" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">训练过程试图学习最小化损失函数的最优权重和偏差</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi mo"><img src="../Images/3dc146ce79d806c85134ffdca6b51f23.png" data-original-src="https://miro.medium.com/v2/resize:fit:672/format:webp/1*RzkBgOgw-QGpNbS1HfLarQ.png"/></div></figure><p id="7096" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">由于期权价格的历史数据相当昂贵，我决定模拟它们。</p><p id="7d0c" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">已经假设股票价格遵循 gBM 以获得足够数量的股票价格。因此，模拟价值必须有足够的执行价格、到期日、利率和波动性。</p><p id="2fab" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">根据这些参数，通过布莱克-斯科尔斯公式计算出了欧式看涨期权的价格。因此，假设它处于布莱克-斯科尔斯世界，即模型的所有假设都得到满足。</p><pre class="ks kt ku kv gt mp mq mr ms aw mt bi"><span id="ca8b" class="mu mv it mq b gy mw mx l my mz">#BS_closed formula: </span><span id="704d" class="mu mv it mq b gy na mx l my mz">EU_call_bs = function(S, K, r, sigma,t=0, T){<br/>  d1 = (log(S/K)+(r+((sigma)^2)/2)*(T-t))/(sigma*sqrt(T-t))<br/>  d2 = d1-(sigma*sqrt(T-t))<br/>  return((S*pnorm(d1))-(K*exp(-r*(T-t))*pnorm(d2)))<br/>}</span><span id="f520" class="mu mv it mq b gy na mx l my mz">#Generate Dataset<br/>sample&lt;-sde::GBM(x=100,N=1000000,r = r,sigma = 0.8,T = 1)</span><span id="7d84" class="mu mv it mq b gy na mx l my mz">mydata &lt;- NULL<br/>mydata$Stock &lt;- sample<br/>mydata$Strike &lt;- sample*runif(length(sample),min = 0.4,max=1)<br/>mydata$Time &lt;- runif(n=length(sample))<br/>mydata$sigma &lt;- runif(n=length(sample), min = 0.1, max = 0.8)<br/>mydata$r &lt;-runif(n=length(sample),min = 0.01, max=0.05)<br/>mydata$BS &lt;-  EU_call_bs(S = mydata$Stock, t = 0, T = mydata$Time, <br/>r = mydata$r, K = mydata$Strike, sigma = as.numeric(mydata$sigma));</span></pre><p id="49a2" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">一旦数据集建立起来，它就被分成两个子集:训练集和测试集。人工神经网络已经在训练集上进行了训练，然后在测试数据集上进行了评估。</p><pre class="ks kt ku kv gt mp mq mr ms aw mt bi"><span id="91a0" class="mu mv it mq b gy mw mx l my mz">#Split dataset</span><span id="4c63" class="mu mv it mq b gy na mx l my mz">split &lt;- rsample::initial_split(mydata, prop = .7, strata='BS' )</span><span id="bb91" class="mu mv it mq b gy na mx l my mz">train &lt;- rsample::training(split)<br/>test  &lt;- rsample::testing(split)</span><span id="0608" class="mu mv it mq b gy na mx l my mz"># Create &amp; standardize feature sets<br/># training features<br/>train_x &lt;- train %&gt;% dplyr::select(-BS)<br/>mean    &lt;- colMeans(train_x)<br/>std     &lt;- apply(train_x, 2, sd)<br/>train_x &lt;- scale(train_x, center = mean, scale = std)</span><span id="c77e" class="mu mv it mq b gy na mx l my mz"># testing features<br/>test_x &lt;- test %&gt;% dplyr::select(-BS)<br/>test_x &lt;- scale(test_x, center = mean, scale = std)</span><span id="40be" class="mu mv it mq b gy na mx l my mz"># Create &amp; transform response sets<br/>train_y &lt;- log(train$BS)<br/>test_y  &lt;- log(test$BS)</span></pre><p id="fb4c" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">下图显示了用于人工神经网络的超参数。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi nb"><img src="../Images/9b5a82477e4f90d8219e6eda2f05e3f3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*2OM4rOpyLGWtQ7qHEmKO9w.png"/></div></div></figure><pre class="ks kt ku kv gt mp mq mr ms aw mt bi"><span id="f496" class="mu mv it mq b gy mw mx l my mz">#MODEL 1<br/>model_1 &lt;- keras_model_sequential() %&gt;%<br/>  layer_dense(units =  200,activation = "relu", input_shape = ncol(train_x)) %&gt;%<br/>  layer_dense(units = 130,activation = "relu") %&gt;%<br/>  layer_dense(units = 50,activation = "relu") %&gt;%<br/>  layer_dense(units = 1)  %&gt;%<br/>  <br/>  # backpropagation<br/>  compile(<br/>    optimizer = "rmsprop",<br/>    loss = "mse",<br/>    metrics = c("mae")<br/>  )</span><span id="5e19" class="mu mv it mq b gy na mx l my mz">learn_1 &lt;- model_1 %&gt;% fit(<br/>  x = train_x,<br/>  y = train_y,<br/>  epochs = 45,<br/>  batch_size = 256,<br/>  validation_split = .2,<br/>  verbose = TRUE,<br/>)</span><span id="cd1e" class="mu mv it mq b gy na mx l my mz">#MODEL 2</span><span id="9b24" class="mu mv it mq b gy na mx l my mz">model_2 &lt;- keras_model_sequential() %&gt;%<br/>  layer_dense(units =  200,activation = "relu", input_shape = ncol(train_x),kernel_regularizer = regularizer_l2(0.001)) %&gt;%<br/>  layer_batch_normalization() %&gt;%<br/>  layer_dropout(rate = 0.2) %&gt;%<br/>  layer_dense(units = 130,activation = "relu",kernel_regularizer = regularizer_l2(0.001)) %&gt;%<br/>  layer_batch_normalization() %&gt;%<br/>  layer_dropout(rate = 0.2) %&gt;%<br/>  layer_dense(units = 50,activation = "relu",kernel_regularizer = regularizer_l2(0.001)) %&gt;%<br/>  layer_batch_normalization() %&gt;%<br/>  layer_dropout(rate = 0.2) %&gt;%<br/>  layer_dense(units = 1)  %&gt;%<br/>  <br/>  compile(<br/>    optimizer = "rmsprop", #optimizer_adam(lr = 0.01) <br/>    loss = "mse",<br/>    metrics = c("mae")<br/>  )<br/>learn_2 &lt;- model_2 %&gt;% fit(<br/>  x = train_x,<br/>  y = train_y,<br/>  epochs = 45,<br/>  batch_size = 256,<br/>  validation_split = .2,<br/>  verbose = TRUE,<br/>  callbacks = list(<br/>    #callback_early_stopping(patience = 10),<br/>    callback_reduce_lr_on_plateau(patience = 5))<br/>)</span></pre><p id="a43e" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">在预测阶段，结果与在训练阶段得到的结果差别不大。</p><pre class="ks kt ku kv gt mp mq mr ms aw mt bi"><span id="4563" class="mu mv it mq b gy mw mx l my mz">#Storing Prediction</span><span id="80ad" class="mu mv it mq b gy na mx l my mz">risultati &lt;- NULL</span><span id="06e2" class="mu mv it mq b gy na mx l my mz">risultati$predcted_values_model_1&lt;- model_1 %&gt;% predict(test_x)<br/>risultati$true_value &lt;- test_y</span><span id="0a21" class="mu mv it mq b gy na mx l my mz">risultati$predcted_values_model_2&lt;- model_2 %&gt;% predict(test_x)</span><span id="b0ad" class="mu mv it mq b gy na mx l my mz">risultati$pred_value_model_1_converted &lt;- exp(risultati$predcted_values_model_1)</span><span id="6cf9" class="mu mv it mq b gy na mx l my mz">risultati$true_converted &lt;- exp(risultati$true_value)</span><span id="2a4e" class="mu mv it mq b gy na mx l my mz">risultati$pred_value_model_2_converted &lt;- exp(risultati$predcted_values_model_2)</span><span id="a241" class="mu mv it mq b gy na mx l my mz">risultati$S_K &lt;- test[,1] / test[,2]</span><span id="3edb" class="mu mv it mq b gy na mx l my mz">risultati$Err_model_1 &lt;- abs(risultati$true_converted - risultati$pred_value_model_1_converted )</span><span id="c140" class="mu mv it mq b gy na mx l my mz">risultati$Err_model_2 &lt;- abs(risultati$true_converted - risultati$pred_value_model_2_converted )</span></pre><p id="32b4" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">测试集前三行的预测结果是:</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi nc"><img src="../Images/efeb0a038a80e8b5c18eadaccf1c3518.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*VED_lRBEHDhmvs5-ZBRk5A.png"/></div></div></figure><p id="d95d" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">下面的图是两个模型的每个选项的实际价格与预测价格，产生了一条偏差很小的窄线。</p><pre class="ks kt ku kv gt mp mq mr ms aw mt bi"><span id="580d" class="mu mv it mq b gy mw mx l my mz">plot(x=risultati$true_converted, y=risultati$pred_value_model_1_converted , cex= 0.001, xlab='Actual', ylab='Predicted Model 1')</span><span id="6fff" class="mu mv it mq b gy na mx l my mz">plot(x=risultati$true_converted, y=risultati$pred_value_model_2_converted , cex= 0.001, xlab='Actual', ylab='Predicted Model 2')</span></pre><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi nd"><img src="../Images/be3cb4445beddfab678ec63e25efdcd1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*9_TdOh5Enn5bHt43qZzbmg.png"/></div></div></figure><p id="81f6" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">为了更好地查看结果，模型产生的绝对误差如下图所示。有趣的是，随着 S/K 的增加，两个模型有不同的行为。</p><pre class="ks kt ku kv gt mp mq mr ms aw mt bi"><span id="c1cb" class="mu mv it mq b gy mw mx l my mz">plot(x=risultati$S_K, risultati$Err_model_1, xlab='S / K', ylab='|BS Price - Predicted model 1|',cex=0.01)</span><span id="0a4e" class="mu mv it mq b gy na mx l my mz">plot(x=risultati$S_K, risultati$Err_model_2, xlab='S / K', ylab='|BS Price - Predicted model 2|',cex=0.01)</span></pre><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi ne"><img src="../Images/39f70455c0bb96156092dbe989b31d08.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*SdQQm9oKd-9Uek8eHMuh4g.png"/></div></div></figure><p id="74bc" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">对模型进行更深入的分析并对参数进行微调肯定会改善结果。总的来说，在 Black &amp; Scholes 世界中，人工神经网络提供了一种计算欧式衍生产品的好方法。</p><blockquote class="nf"><p id="5530" class="ng nh it bd ni nj nk nl nm nn no md dk translated">所有的模型都是错误的，但有些是有用的。</p><p id="e1bb" class="ng nh it bd ni nj nk nl nm nn no md dk translated">乔治·博克斯，1978 年</p></blockquote></div><div class="ab cl me mf hx mg" role="separator"><span class="mh bw bk mi mj mk"/><span class="mh bw bk mi mj mk"/><span class="mh bw bk mi mj"/></div><div class="im in io ip iq"><p id="092e" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">[1] R.Kristiansson，<a class="ae lh" href="https://www.math.kth.se/matstat/seminarier/reports/M-exjobb18/180525c.pdf" rel="noopener ugc nofollow" target="_blank">奇异衍生品与深度学习</a> (2019)，KTH 皇家理工学院工程科学学院</p><p id="d7f1" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">[2]刘帅强，Cornelis W. Oosterlee，Sander M.Bohte，<a class="ae lh" href="https://arxiv.org/abs/1901.08943" rel="noopener ugc nofollow" target="_blank"/>(2018)</p><p id="5f1c" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">[3] Robert Culkin，Sanjiv R. Das，<a class="ae lh" href="https://www.joim.com/article/machine-learning-in-finance-the-case-of-deep-learning-for-option-pricing/" rel="noopener ugc nofollow" target="_blank">金融中的机器学习:期权定价的深度学习案例</a> (2017)</p><p id="7ef8" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">[4]雅各布·迈克尔逊·孔林德、约翰·哈里斯和凯罗尔·普日拜特科夫斯基，<a class="ae lh" href="http://cs229.stanford.edu/proj2009/KolindHarrisPrzybytkowski.pdf" rel="noopener ugc nofollow" target="_blank">使用机器学习对期权进行套期保值和定价</a> (2009)</p><p id="9b0b" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">[5] D.Stafford，<a class="ae lh" href="http://jultika.oulu.fi/files/nbnfioulu-201901091016.pdf" rel="noopener ugc nofollow" target="_blank">期权定价中的机器学习</a> (2018)，奥卢大学</p></div></div>    
</body>
</html>