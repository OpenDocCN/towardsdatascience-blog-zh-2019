<html>
<head>
<title>Vessel Segmentation With Python and Keras</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">基于 Python 和 Keras 的血管分割</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/vessel-segmentation-with-python-and-keras-722f9fb71b21?source=collection_archive---------3-----------------------#2019-03-19">https://towardsdatascience.com/vessel-segmentation-with-python-and-keras-722f9fb71b21?source=collection_archive---------3-----------------------#2019-03-19</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><figure class="gl gn jo jp jq jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi jn"><img src="../Images/1177211fb4ea869ae66b0582384042a8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ARG_VyRl8ZODP7D0dxhCeQ.jpeg"/></div></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk">Photo by <a class="ae kc" href="https://unsplash.com/photos/_FoHMYYlatI?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank">Erica Leong</a> on <a class="ae kc" href="https://unsplash.com/search/photos/eyes?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><h1 id="d641" class="kd ke iq bd kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la bi translated">动机:</h1><p id="10d2" class="pw-post-body-paragraph lb lc iq ld b le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly ij bi translated">医学图像的自动分割是提取有用信息帮助医生做出诊断的重要步骤。例如，它可以用于分割视网膜血管，以便我们可以表示它们的结构并测量它们的宽度，这反过来可以帮助诊断视网膜疾病。</p><p id="91b9" class="pw-post-body-paragraph lb lc iq ld b le lz lg lh li ma lk ll lm mb lo lp lq mc ls lt lu md lw lx ly ij bi translated">在这篇文章中，我们将实现一个神经基线，对视网膜血管图像进行图像分割。</p><h1 id="c49e" class="kd ke iq bd kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la bi translated">数据集:</h1><figure class="mf mg mh mi gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi me"><img src="../Images/1f1574f842e17898fa11e41364377e7b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*xqk-tXMd_ucnobOWTY-EzQ.png"/></div></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk"><a class="ae kc" href="http://www.isi.uu.nl/Research/Databases/DRIVE/browser.php" rel="noopener ugc nofollow" target="_blank">http://www.isi.uu.nl/Research/Databases/DRIVE/browser.php</a></figcaption></figure><p id="21dc" class="pw-post-body-paragraph lb lc iq ld b le lz lg lh li ma lk ll lm mb lo lp lq mc ls lt lu md lw lx ly ij bi translated">我们使用<a class="ae kc" href="http://www.isi.uu.nl/Research/Databases/DRIVE/" rel="noopener ugc nofollow" target="_blank"> DRIVE(用于血管提取的数字视网膜图像)</a>数据集进行所有实验。它是 40 个视网膜图像(20 个用于训练，20 个用于测试)的数据集，其中在像素级(参见上面的例子)对血管进行注释，以在图像的每个像素(I，j)处标记血管的存在(1)或不存在(0)。</p><h1 id="57a3" class="kd ke iq bd kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la bi translated">问题设置:</h1><p id="7174" class="pw-post-body-paragraph lb lc iq ld b le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly ij bi translated"><strong class="ld ir">问题</strong>:我们想给每个像素分配一个“1”标签，如果它是图像中血管的一部分，否则为“0”。<br/> <strong class="ld ir">直觉</strong> / <strong class="ld ir">假设</strong>:相邻像素值对于对每个像素(I，j)进行预测很重要，所以我们应该考虑上下文。预测不依赖于图像上的特定位置，因此分类器应该具有某种平移不变性。<br/> <strong class="ld ir">解决方案</strong>:用 CNN！我们将使用<a class="ae kc" href="https://duckduckgo.com/?q=U-net&amp;t=canonical&amp;atb=v134-5__&amp;ia=web" rel="noopener ugc nofollow" target="_blank"> U-net </a>架构来进行血管分割。它是一种广泛用于语义分割任务的架构，尤其是在医学领域。</p><h1 id="a112" class="kd ke iq bd kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la bi translated">型号:</h1><figure class="mf mg mh mi gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi mj"><img src="../Images/c24db20bb526effec7da44da83d25c17.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*jqoAmEyQmxKpGcAkbPGNMQ.png"/></div></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk">U-net</figcaption></figure><p id="1738" class="pw-post-body-paragraph lb lc iq ld b le lz lg lh li ma lk ll lm mb lo lp lq mc ls lt lu md lw lx ly ij bi translated">U-net 架构是一个编码器-解码器，在编码器和解码器之间有一些跳跃连接。这种架构的主要优点是在对像素进行预测时能够考虑更广泛的背景。这得益于上采样操作中使用的大量通道。</p><h2 id="4df2" class="mk ke iq bd kf ml mm dn kj mn mo dp kn lm mp mq kr lq mr ms kv lu mt mu kz mv bi translated"><strong class="ak">输入图像处理:</strong></h2><p id="6373" class="pw-post-body-paragraph lb lc iq ld b le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly ij bi translated">我们在把它传送给 CNN 之前应用了这一系列的处理步骤。</p><ul class=""><li id="d996" class="mw mx iq ld b le lz li ma lm my lq mz lu na ly nb nc nd ne bi translated">标准化:我们将像素强度除以 255，因此它们在 0-1 的范围内。</li><li id="c604" class="mw mx iq ld b le nf li ng lm nh lq ni lu nj ly nb nc nd ne bi translated">裁剪:由于汇集操作，网络希望输入图像的每个维度都能被 2⁴整除，因此我们从每个图像中随机裁剪 64*64。</li><li id="1409" class="mw mx iq ld b le nf li ng lm nh lq ni lu nj ly nb nc nd ne bi translated">数据扩充:随机翻转(水平或垂直或两者)、随机剪切、随机平移(水平或垂直或两者)、随机缩放。仅在培训期间执行。</li></ul><p id="3b8c" class="pw-post-body-paragraph lb lc iq ld b le lz lg lh li ma lk ll lm mb lo lp lq mc ls lt lu md lw lx ly ij bi translated">我们训练模型的三个变体:</p><ul class=""><li id="74ef" class="mw mx iq ld b le lz li ma lm my lq mz lu na ly nb nc nd ne bi translated">预先接受过 ImageNet VGG 编码器+数据增强的培训。</li><li id="b817" class="mw mx iq ld b le nf li ng lm nh lq ni lu nj ly nb nc nd ne bi translated">从零开始训练+数据扩充。</li><li id="a259" class="mw mx iq ld b le nf li ng lm nh lq ni lu nj ly nb nc nd ne bi translated">在没有数据扩充的情况下从头开始训练。</li></ul><p id="f8df" class="pw-post-body-paragraph lb lc iq ld b le lz lg lh li ma lk ll lm mb lo lp lq mc ls lt lu md lw lx ly ij bi translated">我们将使用 AUC ROC 指标来比较这三个模型，并且我们将在评估中仅考虑视网膜掩膜内的像素(这意味着图像圆圈周围的黑边将不计算在内)。</p><h2 id="0892" class="mk ke iq bd kf ml mm dn kj mn mo dp kn lm mp mq kr lq mr ms kv lu mt mu kz mv bi translated">结果:</h2><ul class=""><li id="19e7" class="mw mx iq ld b le lf li lj lm nk lq nl lu nm ly nb nc nd ne bi translated">从零开始训练+数据增强 AUC ROC : <strong class="ld ir"> 0.9820 </strong></li><li id="7108" class="mw mx iq ld b le nf li ng lm nh lq ni lu nj ly nb nc nd ne bi translated">从零开始训练，没有增加 AUC ROC : 0.9806</li><li id="1cd5" class="mw mx iq ld b le nf li ng lm nh lq ni lu nj ly nb nc nd ne bi translated">预训练编码器+数据增强 AUC ROC : <em class="nn"> 0.9811 </em></li></ul><p id="1dd6" class="pw-post-body-paragraph lb lc iq ld b le lz lg lh li ma lk ll lm mb lo lp lq mc ls lt lu md lw lx ly ij bi translated">这三种变体的性能很接近，但在这种情况下，预训练似乎没有帮助，而数据扩充有一点帮助。</p><figure class="mf mg mh mi gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi no"><img src="../Images/9126d4215188a65ce1812740d0e29a81.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*cwkutNmvGr7G3-KPNDSGcg.png"/></div></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk">Best model predictions</figcaption></figure><p id="f29d" class="pw-post-body-paragraph lb lc iq ld b le lz lg lh li ma lk ll lm mb lo lp lq mc ls lt lu md lw lx ly ij bi translated">上图中的预测看起来相当酷！😄</p><figure class="mf mg mh mi gt jr gh gi paragraph-image"><div class="gh gi np"><img src="../Images/b0f5fc8a998fefaa12c8912ec8e7864d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1130/format:webp/1*p7i0beLshYjgxXLKvXdfLw.jpeg"/></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk">Predictions on top of ground Truth</figcaption></figure><p id="2616" class="pw-post-body-paragraph lb lc iq ld b le lz lg lh li ma lk ll lm mb lo lp lq mc ls lt lu md lw lx ly ij bi translated">我们还画出了预测和实际情况之间的差异:蓝色为假阴性，红色为假阳性。我们可以看到，该模型在预测只有一两个像素宽的精细血管时存在一些困难。</p><h1 id="20fe" class="kd ke iq bd kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la bi translated">结论:</h1><p id="ffcd" class="pw-post-body-paragraph lb lc iq ld b le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly ij bi translated">在这篇文章中，我们实现了一个神经网络来进行图像分割，应用于视网膜图像中的血管检测。我们获得的 AUC ROC 值为<strong class="ld ir"> 0.9820 </strong>，非常接近最先进水平(<a class="ae kc" href="https://paperswithcode.com/search?q=vessel" rel="noopener ugc nofollow" target="_blank">https://paperswithcode.com/search?q=vessel</a>)。关于实验结果，我发现最有趣的是，对于像这样的一些任务，我们可以在少至 20 张图像上训练一个深度神经网络，并仍然获得良好的性能和非常酷的结果。</p><p id="5fe2" class="pw-post-body-paragraph lb lc iq ld b le lz lg lh li ma lk ll lm mb lo lp lq mc ls lt lu md lw lx ly ij bi translated">重现结果的代码可从这里获得:<a class="ae kc" href="https://github.com/CVxTz/medical_image_segmentation" rel="noopener ugc nofollow" target="_blank">https://github.com/CVxTz/medical_image_segmentation</a></p><p id="ffdc" class="pw-post-body-paragraph lb lc iq ld b le lz lg lh li ma lk ll lm mb lo lp lq mc ls lt lu md lw lx ly ij bi translated">如果你有任何建议，请不要犹豫发表意见😸</p></div></div>    
</body>
</html>