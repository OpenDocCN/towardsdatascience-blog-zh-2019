# ä½¿ç”¨ç©ºé—´çš„è‡ªå®šä¹‰å‘½åå®ä½“è¯†åˆ«

> åŸæ–‡ï¼š<https://towardsdatascience.com/custom-named-entity-recognition-using-spacy-7140ebbb3718?source=collection_archive---------0----------------------->

![](img/a3ee50418fc6cd06fea40cfd88b930b4.png)

Figure 1: [Source](https://www.google.com/url?sa=i&source=images&cd=&cad=rja&uact=8&ved=2ahUKEwiKo-uSzffgAhXJknAKHXH4CwYQjRx6BAgBEAU&url=%2Furl%3Fsa%3Di%26source%3Dimages%26cd%3D%26ved%3D%26url%3Dhttps%253A%252F%252Fspacy.io%252Fusage%252Flinguistic-features%26psig%3DAOvVaw3H52fKKxtUkhEj4jVFkQxO%26ust%3D1552308120763958&psig=AOvVaw3H52fKKxtUkhEj4jVFkQxO&ust=1552308120763958)

# ä»€ä¹ˆæ˜¯å‘½åå®ä½“è¯†åˆ«(NER)ï¼Ÿ

å‘½åå®ä½“è¯†åˆ«(NER)æ˜¯ä¿¡æ¯æå–(IE)çš„ä¸€ä¸ªå­ä»»åŠ¡ï¼Œåœ¨ä¸€ä¸ªæˆ–å¤šä¸ªæ–‡æœ¬ä¸»ä½“ä¸­æ‰¾å‡ºæŒ‡å®šçš„[å®ä½“](https://en.wikipedia.org/wiki/Named_entity)å¹¶å¯¹å…¶è¿›è¡Œåˆ†ç±»ã€‚NER ä¹Ÿç®€ç§°ä¸ºå®ä½“è¯†åˆ«ã€å®ä½“åˆ†å—å’Œå®ä½“æå–ã€‚NER è¢«ç”¨äºäººå·¥æ™ºèƒ½çš„è®¸å¤šé¢†åŸŸ( [AI](https://en.wikipedia.org/wiki/Artificial_intelligence) )ï¼ŒåŒ…æ‹¬è‡ªç„¶è¯­è¨€å¤„ç†( [NLP](https://en.wikipedia.org/wiki/Natural_language_processing) )å’Œ[æœºå™¨å­¦ä¹ ](https://en.wikipedia.org/wiki/Machine_learning)ã€‚

# NER çš„ç©ºé—´

SpaCy æ˜¯ Python ä¸­é«˜çº§è‡ªç„¶è¯­è¨€å¤„ç†çš„å¼€æºåº“ã€‚å®ƒæ˜¯ä¸“é—¨ä¸ºç”Ÿäº§ä½¿ç”¨è€Œè®¾è®¡çš„ï¼Œæœ‰åŠ©äºæ„å»ºå¤„ç†å’Œâ€œç†è§£â€å¤§é‡æ–‡æœ¬çš„åº”ç”¨ç¨‹åºã€‚å®ƒå¯ä»¥ç”¨äºæ„å»ºä¿¡æ¯æå–æˆ–è‡ªç„¶è¯­è¨€ç†è§£ç³»ç»Ÿï¼Œæˆ–è€…ç”¨äºæ·±åº¦å­¦ä¹ çš„æ–‡æœ¬é¢„å¤„ç†ã€‚spaCy æä¾›çš„ä¸€äº›åŠŸèƒ½åŒ…æ‹¬æ ‡è®°åŒ–ã€è¯æ€§(PoS)æ ‡è®°ã€æ–‡æœ¬åˆ†ç±»å’Œå‘½åå®ä½“è¯†åˆ«ã€‚

SpaCy ä¸º python ä¸­çš„ NER æä¾›äº†ä¸€ä¸ªéå¸¸æœ‰æ•ˆçš„ç»Ÿè®¡ç³»ç»Ÿï¼Œå®ƒå¯ä»¥å°†æ ‡ç­¾åˆ†é…ç»™è¿ç»­çš„æ ‡è®°ç»„ã€‚å®ƒæä¾›äº†ä¸€ä¸ªé»˜è®¤æ¨¡å‹ï¼Œå¯ä»¥è¯†åˆ«å¹¿æ³›çš„å‘½åæˆ–æ•°å­—å®ä½“ï¼ŒåŒ…æ‹¬*ä¸ªäººã€ç»„ç»‡ã€è¯­è¨€ã€äº‹ä»¶ç­‰ã€‚*é™¤äº†è¿™äº›é»˜è®¤å®ä½“ä¹‹å¤–ï¼ŒspaCy è¿˜å…è®¸æˆ‘ä»¬è‡ªç”±åœ°å‘ NER æ¨¡å‹æ·»åŠ ä»»æ„ç±»åˆ«ï¼Œæ–¹æ³•æ˜¯è®­ç»ƒè¯¥æ¨¡å‹ï¼Œä»¥ä¾¿ç”¨æ›´æ–°çš„è®­ç»ƒæ ·æœ¬å¯¹å…¶è¿›è¡Œæ›´æ–°ã€‚

# å…¥é—¨æŒ‡å—

## è£…ç½®

SpaCy å¯ä»¥é€šè¿‡ç®€å•çš„`pip`å®‰è£…æ¥å®‰è£…ã€‚æ‚¨è¿˜éœ€è¦ä¸‹è½½æ‚¨å¸Œæœ›ä½¿ç”¨ spaCy çš„è¯­è¨€çš„è¯­è¨€æ¨¡å‹ã€‚

```
pip install -U spacy 
python -m spacy download en
```

# æˆ‘ä»¬å¼€å§‹å§ï¼

## *æ•°æ®é›†*

æˆ‘ä»¬å°†è¦å¤„ç†çš„æ•°æ®é›†å¯ä»¥ä»[è¿™é‡Œ](https://www.kaggle.com/abhinavwalia95/entity-annotated-corpus)ä¸‹è½½ã€‚æˆ‘ä»¬å°†ä½¿ç”¨`ner_dataset.csv`æ–‡ä»¶ï¼Œåªè®­ç»ƒ 260 ä¸ªå¥å­ã€‚

![](img/a9c9f9babecb958f32d4085818c44369.png)

Figure 2: NER Dataset

æ•°æ®é›†ç”±ä»¥ä¸‹æ ‡ç­¾ç»„æˆ-

*   åœ°ç†=åœ°ç†å®ä½“
*   org =ç»„ç»‡
*   per =äºº
*   åœ°ç¼˜æ”¿æ²»å®ä½“
*   tim =æ—¶é—´æŒ‡ç¤ºå™¨
*   è‰ºæœ¯=è‰ºæœ¯å“
*   eve =äº‹ä»¶
*   è‡ªç„¶ç°è±¡

æ•°æ®é›†éµå¾ª[ç”Ÿç‰©](https://natural-language-understanding.fandom.com/wiki/Named_entity_recognition)ç±»å‹æ ‡è®°ã€‚

## æ•°æ®é¢„å¤„ç†

SpaCy è¦æ±‚è®­ç»ƒæ•°æ®é‡‡ç”¨ä»¥ä¸‹æ ¼å¼-

![](img/ed11bbe8750b526beb24811c43c37fdd.png)

Figure 3: spaCy Format Training Data ([Source](https://spacy.io/usage/training#ner))

æ‰€ä»¥æˆ‘ä»¬å¿…é¡»æŠŠæˆ‘ä»¬çš„æ•°æ®ä»`.csv`æ ¼å¼è½¬æ¢æˆä¸Šé¢çš„æ ¼å¼ã€‚*(spaCy ä¹Ÿæ¥å—å…¶ä»–å½¢å¼çš„è®­ç»ƒæ•°æ®ã€‚æ›´å¤šç»†èŠ‚è¯·å‚è€ƒ* [*æ–‡æ¡£*](https://spacy.io/api/annotation#named-entities) *ã€‚)*æˆ‘ä»¬é¦–å…ˆåˆ é™¤åˆ—`Sentence #`å’Œ`POS`ï¼Œå› ä¸ºæˆ‘ä»¬ä¸éœ€è¦å®ƒä»¬ï¼Œç„¶åå°†`.csv`æ–‡ä»¶è½¬æ¢ä¸º`.tsv`æ–‡ä»¶ã€‚æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬å¿…é¡»è¿è¡Œä¸‹é¢çš„è„šæœ¬æ¥è·å–`.json`æ ¼å¼çš„è®­ç»ƒæ•°æ®ã€‚

ç°åœ¨æ•°æ®åº”è¯¥æ˜¯è¿™æ ·çš„ï¼Œ

![](img/c95f605e41368b74ea2b2c2a54cf43c9.png)

Figure 4: Training Data in Json Format

ä¸‹ä¸€æ­¥æ˜¯å°†ä¸Šè¿°æ•°æ®è½¬æ¢æˆ spaCy éœ€è¦çš„æ ¼å¼ã€‚å¯ä»¥ä½¿ç”¨ä»¥ä¸‹è„šæœ¬æ¥å®Œæˆ-

ç°åœ¨æˆ‘ä»¬å·²ç»ä¸ºè®­ç»ƒå‡†å¤‡å¥½äº†æ•°æ®ï¼è®©æˆ‘ä»¬é€šè¿‡æ·»åŠ è‡ªå®šä¹‰å®ä½“æ¥è®­ç»ƒä¸€ä¸ª NER æ¨¡å‹ã€‚

## ä½¿ç”¨è‡ªå®šä¹‰å®ä½“åŸ¹è®­ç©ºé—´ NER

SpaCy NER å·²ç»æ”¯æŒåƒ- `PERSON`äººè¿™æ ·çš„å®ä½“ç±»å‹ï¼ŒåŒ…æ‹¬è™šæ„çš„ã€‚æ°‘æ—ã€å®—æ•™æˆ–æ”¿æ²»å›¢ä½“ã€‚`FAC`å»ºç­‘ã€æœºåœºã€å…¬è·¯ã€æ¡¥æ¢ç­‰ã€‚`ORG`å…¬å¸ã€æœºå…³ã€æœºæ„ç­‰ã€‚`GPE`å›½å®¶ã€åŸå¸‚ã€å·ç­‰ã€‚

æˆ‘ä»¬çš„ç›®æ ‡æ˜¯è¿›ä¸€æ­¥è®­ç»ƒè¿™ä¸ªæ¨¡å‹ï¼Œä½¿å…¶åŒ…å«æˆ‘ä»¬æ•°æ®é›†ä¸­çš„è‡ªå®šä¹‰å®ä½“ã€‚è¦åšåˆ°è¿™ä¸€ç‚¹ï¼Œæˆ‘ä»¬å¿…é¡»ç»å†ä»¥ä¸‹æ­¥éª¤-

1.  **åŠ è½½æ¨¡å‹**ï¼Œæˆ–ä½¿ç”¨å¸¦æœ‰æ‰€éœ€è¯­è¨€ ID çš„`[spacy.blank](https://spacy.io/api/top-level#spacy.blank)`åˆ›å»ºä¸€ä¸ª**ç©ºæ¨¡å‹**ã€‚å¦‚æœæ­£åœ¨ä½¿ç”¨ç©ºç™½æ¨¡å‹ï¼Œæˆ‘ä»¬å¿…é¡»å°†å®ä½“è¯†åˆ«å™¨æ·»åŠ åˆ°[ç®¡é“](https://spacy.io/usage/processing-pipelines)ä¸­ã€‚å¦‚æœä½¿ç”¨ç°æœ‰æ¨¡å‹ï¼Œæˆ‘ä»¬å¿…é¡»åœ¨è®­ç»ƒæœŸé—´ä½¿ç”¨`[nlp.disable_pipes](https://spacy.io/api/language#disable_pipes)`ç¦ç”¨æ‰€æœ‰å…¶ä»–ç®¡é“ç»„ä»¶ã€‚è¿™æ ·ï¼Œåªæœ‰å®ä½“è¯†åˆ«å™¨å¾—åˆ°è®­ç»ƒã€‚

```
# Setting up the pipeline and entity recognizer.if model is not None:
    nlp = spacy.load(model)  # load existing spacy model
    print("Loaded model '%s'" % model)
else:
    nlp = spacy.blank('en')  # create blank Language class
    print("Created blank 'en' model")if 'ner' not in nlp.pipe_names:
    ner = nlp.create_pipe('ner')
    nlp.add_pipe(ner)
else:
    ner = nlp.get_pipe('ner')
```

2.**ä½¿ç”¨`[add_label](https://spacy.io/api/entityrecognizer#add_label)`æ–¹æ³•å°†æ–°çš„å®ä½“æ ‡ç­¾**æ·»åŠ åˆ°å®ä½“è¯†åˆ«å™¨ä¸­ã€‚

```
# Add new entity labels to entity recognizerfor i in LABEL:
    ner.add_label(i)# Inititalizing optimizerif model is None:
    optimizer = nlp.begin_training()
else:
    optimizer = nlp.entity.create_optimizer()
```

3.**å¾ªç¯éå†**ç¤ºä¾‹ï¼Œå¹¶è°ƒç”¨`[nlp.update](https://spacy.io/api/language#update)`ï¼Œé€æ­¥éå†è¾“å…¥çš„å•è¯ã€‚åœ¨æ¯ä¸€ä¸ªå•è¯ä¸Šï¼Œå®ƒéƒ½ä¼šåšå‡ºä¸€ä¸ª**é¢„æµ‹**ã€‚ç„¶åï¼Œå®ƒæŸ¥é˜…æ³¨é‡Šï¼Œçœ‹çœ‹å®ƒæ˜¯å¦æ­£ç¡®ã€‚å¦‚æœå®ƒé”™äº†ï¼Œå®ƒä¼šè°ƒæ•´å®ƒçš„æƒé‡ï¼Œè¿™æ ·ä¸‹æ¬¡æ­£ç¡®çš„åŠ¨ä½œä¼šå¾—åˆ°æ›´é«˜çš„åˆ†æ•°ã€‚

```
# Get names of other pipes to disable them during training to train # only NER and update the weightsother_pipes = [pipe for pipe in nlp.pipe_names if pipe != 'ner']
with nlp.disable_pipes(*other_pipes):  # only train NER
    for itn in range(n_iter):
        random.shuffle(TRAIN_DATA)
        losses = {}
        batches = minibatch(TRAIN_DATA, 
                            size=compounding(4., 32., 1.001))
        for batch in batches:
            texts, annotations = zip(*batch) 
            # Updating the weights
            nlp.update(texts, annotations, sgd=optimizer, 
                       drop=0.35, losses=losses)
        print('Losses', losses) nlp.update(texts, annotations, sgd=optimizer, 
                       drop=0.35, losses=losses)
        print('Losses', losses)
```

4.**ä½¿ç”¨`[nlp.to_disk](https://spacy.io/api/language#to_disk)`ä¿å­˜**è®­ç»ƒå¥½çš„æ¨¡å‹ã€‚

```
# Save model 
if output_dir is not None:
    output_dir = Path(output_dir)
    if not output_dir.exists():
        output_dir.mkdir()
    nlp.meta['name'] = new_model_name  # rename model
    nlp.to_disk(output_dir)
    print("Saved model to", output_dir)
```

5.**æµ‹è¯•**æ¨¡å‹ï¼Œç¡®ä¿æ–°å®ä½“è¢«æ­£ç¡®è¯†åˆ«ã€‚

```
# Test the saved model
print("Loading from", output_dir)
nlp2 = spacy.load(output_dir)
doc2 = nlp2(test_text)
for ent in doc2.ents:
    print(ent.label_, ent.text)
```

ä½¿ç”¨æ­¤è„šæœ¬æ¥è®­ç»ƒå’Œæµ‹è¯•æ¨¡å‹-

æ‰§è¡ŒæŒ‡ä»¤-

```
python spacy_ner_custom_entities.py \
-m=en \ 
-o=path/to/output/directory \
-n=1000
```

## ç»“æœ

å½“å¯¹æŸ¥è¯¢- `['John Lee is the chief of CBSE', 'Americans suffered from H5N1']`è¿›è¡Œæµ‹è¯•æ—¶ï¼Œæ¨¡å‹è¯†åˆ«å‡ºä»¥ä¸‹å®ä½“-

```
John Lee is the chief of CBSE.B-per JohnI-per LeeB-org CBSE Americans suffered from H5N1 virus in 2002.B-gpe AmericansB-nat H5N1B-tim 2002
```

# ç»“è®º

æˆ‘å¸Œæœ›ä½ ç°åœ¨å·²ç»æ˜ç™½äº†å¦‚ä½•åœ¨æ–¯å¸•è¥¿ NER æ¨¡å‹çš„åŸºç¡€ä¸Šè®­ç»ƒä½ è‡ªå·±çš„ NER æ¨¡å‹ã€‚æ„Ÿè°¢é˜…è¯»ï¼ğŸ˜Š