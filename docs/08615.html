<html>
<head>
<title>Clearing Programming Interview Assignment: RSS Feed Parser in Python</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">清除编程面试任务:Python 中的 RSS 提要解析器</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/rss-feed-parser-in-python-553b1857055c?source=collection_archive---------17-----------------------#2019-11-20">https://towardsdatascience.com/rss-feed-parser-in-python-553b1857055c?source=collection_archive---------17-----------------------#2019-11-20</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="95da" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated"><em class="kf">如何使用 Python 完成数据科学和数据工程面试编程任务</em></h2></div><p id="8746" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated">最近一直在面试数据科学家的职位。其中一家公司给了我一个任务，用 python 创建一个 RSS 提要解析器。它以增量方式获取提要条目，并将它们存储在数据库中。<br/>完整代码可以在<a class="ae lc" href="https://github.com/vintageplayer/RSS-Parser" rel="noopener ugc nofollow" target="_blank"><strong class="ki ir"><em class="ld">github</em></strong></a><strong class="ki ir"><em class="ld">上找到。</em>T12】</strong></p></div><div class="ab cl le lf hu lg" role="separator"><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj"/></div><div class="ij ik il im in"><h1 id="9b45" class="ll lm iq bd ln lo lp lq lr ls lt lu lv jw lw jx lx jz ly ka lz kc ma kd mb mc bi translated"><strong class="ak">问题阐述</strong></h1><p id="2662" class="pw-post-body-paragraph kg kh iq ki b kj md jr kl km me ju ko kp mf kr ks kt mg kv kw kx mh kz la lb ij bi translated">因此，与其深入技术细节，我想回顾一下问题的背景。<br/>对于那些不知道的人来说，RSS 是一种基于网络的内容(或提要)共享格式。(<a class="ae lc" href="https://en.wikipedia.org/wiki/RSS" rel="noopener ugc nofollow" target="_blank">https://en.wikipedia.org/wiki/RSS</a>)。以下是手头问题的细节:</p><ol class=""><li id="9f87" class="mi mj iq ki b kj kk km kn kp mk kt ml kx mm lb mn mo mp mq bi translated">要解析的 RSS 提要是<a class="ae lc" href="https://audioboom.com/channels/4930693.rss" rel="noopener ugc nofollow" target="_blank"> <strong class="ki ir">印</strong></a><strong class="ki ir">(</strong><a class="ae lc" href="https://audioboom.com/channels/4930693.rss" rel="noopener ugc nofollow" target="_blank">https://audioboom.com/channels/4930693.rss</a>)</li><li id="1d63" class="mi mj iq ki b kj mr km ms kp mt kt mu kx mv lb mn mo mp mq bi translated">需要设计一个合适的数据模型来表示每个帖子</li><li id="223e" class="mi mj iq ki b kj mr km ms kp mt kt mu kx mv lb mn mo mp mq bi translated">任何支持 python 连接的关系数据库都可以用来存储 post 数据</li><li id="5c66" class="mi mj iq ki b kj mr km ms kp mt kt mu kx mv lb mn mo mp mq bi translated">禁止使用能够进行 RSS 解析的库(如 feedparser)</li><li id="17f8" class="mi mj iq ki b kj mr km ms kp mt kt mu kx mv lb mn mo mp mq bi translated">负载应该是递增的，即只有先前没有处理的记录应该被处理</li><li id="f519" class="mi mj iq ki b kj mr km ms kp mt kt mu kx mv lb mn mo mp mq bi translated">应该安排脚本每天运行一次以获取更新</li></ol></div><div class="ab cl le lf hu lg" role="separator"><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj"/></div><div class="ij ik il im in"><h1 id="0232" class="ll lm iq bd ln lo lp lq lr ls lt lu lv jw lw jx lx jz ly ka lz kc ma kd mb mc bi translated">方法和系统设计</h1><p id="6bba" class="pw-post-body-paragraph kg kh iq ki b kj md jr kl km me ju ko kp mf kr ks kt mg kv kw kx mh kz la lb ij bi translated">显然我决定用<strong class="ki ir"> <em class="ld"> python 3.7 </em> </strong>，用生命终结支持来换<strong class="ki ir"> <em class="ld"> python 2.7 </em> </strong>。以上基本上意味着我必须自己实现 RSS 解析器。考虑到 1 天的时间限制，所有其他决定都非常简单，为这项工作留出 3-4 个小时(假设每天工作 8-9 个小时)。下面是我最终使用的方法:</p><blockquote class="mw mx my"><p id="ed9e" class="kg kh ld ki b kj kk jr kl km kn ju ko mz kq kr ks na ku kv kw nb ky kz la lb ij bi translated"><strong class="ki ir"> 1。</strong>RSS 解析器库的限制，基本上指望我自己写解析器。由于它最终是基于 xml 的内容，我决定使用一直可靠的<a class="ae lc" href="https://www.crummy.com/software/BeautifulSoup/bs4/doc/" rel="noopener ugc nofollow" target="_blank"> <strong class="ki ir"> BeautifulSoup 库</strong></a><strong class="ki ir">(</strong><a class="ae lc" href="https://www.crummy.com/software/BeautifulSoup/bs4/doc/" rel="noopener ugc nofollow" target="_blank">【https://www.crummy.com/software/BeautifulSoup/bs4/doc/】</a>)<strong class="ki ir"><br/>2。</strong>我选择的关系数据库是<a class="ae lc" href="https://www.postgresql.org/" rel="noopener ugc nofollow" target="_blank"><strong class="ki ir"><em class="iq">postgres</em></strong></a><strong class="ki ir"><em class="iq">(</em></strong><a class="ae lc" href="https://www.postgresql.org/" rel="noopener ugc nofollow" target="_blank">https://www.postgresql.org/</a><strong class="ki ir"><em class="iq">)</em></strong>。没有特别的原因，除了易用性和熟悉度，显然还有疯狂流行的开源支持。<br/> <strong class="ki ir"> 3。</strong>库<a class="ae lc" href="https://apscheduler.readthedocs.io/en/latest/index.html" rel="noopener ugc nofollow" target="_blank"> <strong class="ki ir"> <em class="iq">自动调度器</em></strong></a><strong class="ki ir"><em class="iq">(</em></strong>【https://apscheduler.readthedocs.io/en/latest/index.html】<strong class="ki ir"><em class="iq">)</em></strong>每天调度一次任务(简单的库开始，<a class="ae lc" href="https://airflow.apache.org/" rel="noopener ugc nofollow" target="_blank"> <strong class="ki ir"> <em class="iq">气流</em></strong></a><strong class="ki ir"><em class="iq">(</em></strong><a class="ae lc" href="https://airflow.apache.org/" rel="noopener ugc nofollow" target="_blank">【https://airflow.apache.org/】</a><strong class="ki ir"/>库<a class="ae lc" href="https://pypi.org/project/psycopg2/" rel="noopener ugc nofollow" target="_blank">此外，由于没有给出环境规范，我决定使用两个</a><a class="ae lc" href="https://www.docker.com/" rel="noopener ugc nofollow" target="_blank"><strong class="ki ir"><em class="iq">docker</em></strong></a><strong class="ki ir"><em class="iq">(</em></strong><a class="ae lc" href="https://www.docker.com/" rel="noopener ugc nofollow" target="_blank">https://www.docker.com/</a><strong class="ki ir"><em class="iq">)</em></strong>容器来构建所有这些，一个用于<strong class="ki ir"><em class="iq"/></strong>，一个用于<strong class="ki ir"/></p></blockquote><p id="f658" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated">有了上面分享的方法，让我们开始实施吧！</p></div><div class="ab cl le lf hu lg" role="separator"><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj"/></div><div class="ij ik il im in"><h1 id="9a0d" class="ll lm iq bd ln lo lp lq lr ls lt lu lv jw lw jx lx jz ly ka lz kc ma kd mb mc bi translated"><strong class="ak">设置事物</strong></h1><p id="6707" class="pw-post-body-paragraph kg kh iq ki b kj md jr kl km me ju ko kp mf kr ks kt mg kv kw kx mh kz la lb ij bi translated">首先设置 docker 环境和容器:</p><p id="bda2" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated">1.为容器创建一个单独的网络进行交互:</p><pre class="nc nd ne nf gt ng nh ni nj aw nk bi"><span id="3b7e" class="nl lm iq nh b gy nm nn l no np">docker network create rss</span></pre><p id="5e67" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated">2.使用数据库名称、密码的环境变量创建 postgres 容器。公开端口，设置绑定挂载和工作目录:</p><pre class="nc nd ne nf gt ng nh ni nj aw nk bi"><span id="fcf7" class="nl lm iq nh b gy nm nn l no np">docker run -d --name rss-postgres \<br/> --net=rss \<br/> -e POSTGRES_DB=audioboom \<br/> -e POSTGRES_PASSWORD=parserssfeed \<br/> -p 5432:5432 \<br/> -v $(PWD):/home \<br/> -w /home  \<br/> postgres</span></pre><p id="3e1c" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated">3.创建 python 容器，绑定挂载，设置工作目录并运行它:</p><pre class="nc nd ne nf gt ng nh ni nj aw nk bi"><span id="c633" class="nl lm iq nh b gy nm nn l no np">docker run -dt --name rss-python \<br/> --net=rss \<br/> -v $(PWD)/src:/home/src \<br/> -w /home/src  \<br/> conda/miniconda3-centos6 bash</span></pre><p id="cb72" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated">4.为 python 安装必要的库:</p><pre class="nc nd ne nf gt ng nh ni nj aw nk bi"><span id="0670" class="nl lm iq nh b gy nm nn l no np">docker exec rss-python conda update -c base -c defaults conda<br/>docker exec rss-python conda install beautifulsoup4 lxml psycopg2<br/>docker exec rss-python conda install -c conda-forge apscheduler</span></pre><p id="2903" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated">让我们现在开始构建我们的数据模型…</p></div><div class="ab cl le lf hu lg" role="separator"><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj"/></div><div class="ij ik il im in"><h1 id="8c6b" class="ll lm iq bd ln lo lp lq lr ls lt lu lv jw lw jx lx jz ly ka lz kc ma kd mb mc bi translated">创建数据模型</h1><p id="fcbd" class="pw-post-body-paragraph kg kh iq ki b kj md jr kl km me ju ko kp mf kr ks kt mg kv kw kx mh kz la lb ij bi translated">看了一些帖子后，我意识到需要三个实体:</p><blockquote class="mw mx my"><p id="53f2" class="kg kh ld ki b kj kk jr kl km kn ju ko mz kq kr ks na ku kv kw nb ky kz la lb ij bi translated"><strong class="ki ir"> 1。</strong> <strong class="ki ir">帖子:</strong>保存 feed 上发布的每个帖子的条目<br/> <strong class="ki ir"> 2。itunes_data: </strong>一篇文章可以有选择地包含它的 itunes 列表的链接。媒体:一篇文章可以呈现 0 个或多个媒体对象</p></blockquote><p id="32bc" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated">跟踪这三个实体几乎包含了整篇文章。<br/>请使用此<a class="ae lc" href="https://github.com/vintageplayer/RSS-Parser/blob/master/create_db.sql" rel="noopener ugc nofollow" target="_blank"> <strong class="ki ir"> <em class="ld"> github 链接</em> </strong> </a>进行精确的创建表查询(因为它们非常简单)<br/>可以通过运行以下命令一次性创建表:</p><pre class="nc nd ne nf gt ng nh ni nj aw nk bi"><span id="e9d6" class="nl lm iq nh b gy nm nn l no np">docker exec -it rss-postgres psql -U postgres -d audioboom -f create_db.sql</span></pre></div><div class="ab cl le lf hu lg" role="separator"><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj"/></div><div class="ij ik il im in"><h1 id="8b8e" class="ll lm iq bd ln lo lp lq lr ls lt lu lv jw lw jx lx jz ly ka lz kc ma kd mb mc bi translated">编码开始…</h1><p id="674d" class="pw-post-body-paragraph kg kh iq ki b kj md jr kl km me ju ko kp mf kr ks kt mg kv kw kx mh kz la lb ij bi translated"><strong class="ki ir">助手模块<br/> </strong>除了主脚本之外，还创建了三个脚本来抽象一些带有函数调用的底层功能:</p><blockquote class="mw mx my"><p id="44a7" class="kg kh ld ki b kj kk jr kl km kn ju ko mz kq kr ks na ku kv kw nb ky kz la lb ij bi translated"><strong class="ki ir"> 1。</strong><a class="ae lc" href="https://github.com/vintageplayer/RSS-Parser/blob/master/src/content_fetcher.py" rel="noopener ugc nofollow" target="_blank"><strong class="ki ir">content _ fetcher . py</strong></a><strong class="ki ir">:</strong>用于半健壮地处理网页请求，并返回其内容<br/> <strong class="ki ir"> 2。</strong><a class="ae lc" href="https://github.com/vintageplayer/RSS-Parser/blob/master/src/data_parser.py" rel="noopener ugc nofollow" target="_blank"><strong class="ki ir">data _ parser . py</strong></a><strong class="ki ir">:</strong>将网页内容转换为 BeautifulSoup 对象进行解析，解析 feed 中给定的 RSS post 记录，并返回相同的字典。<br/> <strong class="ki ir"> 3。</strong><a class="ae lc" href="https://github.com/vintageplayer/RSS-Parser/blob/master/src/db_connect.py" rel="noopener ugc nofollow" target="_blank"><strong class="ki ir">DB _ connect . py</strong></a><strong class="ki ir">:</strong>包含 DB helper 函数，用于获取连接、获取已有记录的计数(用于增量加载)以及执行给定的查询。</p></blockquote></div><div class="ab cl le lf hu lg" role="separator"><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj"/></div><div class="ij ik il im in"><h1 id="8d6a" class="ll lm iq bd ln lo lp lq lr ls lt lu lv jw lw jx lx jz ly ka lz kc ma kd mb mc bi translated">Main.py！！！</h1><p id="35fc" class="pw-post-body-paragraph kg kh iq ki b kj md jr kl km me ju ko kp mf kr ks kt mg kv kw kx mh kz la lb ij bi translated">最后，让我们构建将所有部分连接在一起的脚本… <br/> <strong class="ki ir"> 1。</strong> <strong class="ki ir">导入:</strong>下面几行将导入所需的模块和对象</p><pre class="nc nd ne nf gt ng nh ni nj aw nk bi"><span id="26e5" class="nl lm iq nh b gy nm nn l no np">from data_parser import get_soup, parse_record, store_tags<br/>from db_connect import get_connection, get_max_records,execute_query<br/>from apscheduler.schedulers.blocking import BlockingScheduler</span></pre><p id="01c4" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated"><strong class="ki ir"> 2。</strong>我们还将定义一些全局变量(我知道这不是一个推荐的做法，但考虑到时间限制，这是我们都必须采取的一个折衷方案)</p><pre class="nc nd ne nf gt ng nh ni nj aw nk bi"><span id="491c" class="nl lm iq nh b gy nm nn l no np"># Query to find the max record processed so far<br/>get_max_query = 'SELECT COALESCE(max(itunes_episode),0) FROM tasteofindia.posts;'</span><span id="0c3b" class="nl lm iq nh b gy nq nn l no np"># Query template to insert values in any table<br/>query_string = 'INSERT INTO tasteofindia.{0} ({1}) VALUES ({2}{3});'</span><span id="afaf" class="nl lm iq nh b gy nq nn l no np"># List of columns present in the table<br/>col_list  = {<br/> 'posts'  : [&lt;check the github script for the actual names&gt;]<br/> ,'itunes_data' : [&lt;check the github script for the actual names&gt;]<br/> ,'media'  : ['itunes_episode','url','type','duration','lang','medium']<br/>}</span><span id="442a" class="nl lm iq nh b gy nq nn l no np"># Creating insert queries for all the tables from template<br/>query_strings = {k: query_string.format(k , ','.join(col_list[k]),('%s,'*(len(col_list[k])-1) ),'%s' ) for k in col_list}</span></pre><blockquote class="mw mx my"><p id="ddc5" class="kg kh ld ki b kj kk jr kl km kn ju ko mz kq kr ks na ku kv kw nb ky kz la lb ij bi translated">未显示<strong class="ki ir"> <em class="iq">帖子&amp; itunes_data </em> </strong>的列列表。同样请参考<a class="ae lc" href="https://github.com/vintageplayer/RSS-Parser/blob/master/src/main.py" rel="noopener ugc nofollow" target="_blank"> <strong class="ki ir"> <em class="iq"> github 链接</em> </strong> </a>。放给<strong class="ki ir"><em class="iq">itunes _ episode</em></strong>看，了解一下大意。</p></blockquote><p id="b37b" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated"><strong class="ki ir"> 3。begin(</strong><em class="ld">feed _ URL</em><strong class="ki ir">，</strong><em class="ld">db _ credential _ file</em><strong class="ki ir">)</strong>:获取凭据文件上的的连接，并开始解析来自 feed url 的 feed:</p><pre class="nc nd ne nf gt ng nh ni nj aw nk bi"><span id="79ab" class="nl lm iq nh b gy nm nn l no np">def begin(feed_url,db_credential_file):<br/> try:<br/>  connection = get_connection(db_credential_file)<br/>  update_feed_data(feed_url,connection)<br/> except Exception as e:<br/>  print('Error Received...')<br/>  print(e)<br/> finally:<br/>  print('Closing connection')<br/>  connection.close()</span></pre><p id="2312" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated">一个简单的功能，开始所有的骚动，让事情动起来。<br/> <strong class="ki ir"> 4。update _ feed _ data(</strong><em class="ld">feed</em><strong class="ki ir">，</strong> <em class="ld"> conn </em> <strong class="ki ir"> ): </strong>请求给定 url 的 BeautifulSoup 对象并尝试处理其中的任何记录:</p><pre class="nc nd ne nf gt ng nh ni nj aw nk bi"><span id="658a" class="nl lm iq nh b gy nm nn l no np">def update_feed_data(feed,conn):<br/> content   = get_soup(feed)<br/> print(f"Processing Records for : {feed}")<br/> records   = content.find_all('item')<br/> process_records(records,conn)<br/> return</span></pre><p id="04c9" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated">同样，按照函数范式，它通过检索 BeautifulSoup 对象来完成工作，并传递内容以供进一步处理。</p><p id="d208" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated"><strong class="ki ir"> 5。process_records( </strong></p><pre class="nc nd ne nf gt ng nh ni nj aw nk bi"><span id="84e4" class="nl lm iq nh b gy nm nn l no np">def process_records(content,conn):<br/>  record_count = len(content)<br/>  current_max  = get_max_records(conn,get_max_query)<br/>  print('Current Max : ',current_max)<br/>  records = {}</span><span id="14d2" class="nl lm iq nh b gy nq nn l no np">  if record_count == current_max:<br/>    print("No new records found!!")<br/>    return records</span><span id="5411" class="nl lm iq nh b gy nq nn l no np">  print(f"Total Records Found: {record_count}. Currently present: {current_max}")</span><span id="abc8" class="nl lm iq nh b gy nq nn l no np">  # List comprehension on the result of map operation on records<br/>  [persist_taste_of_india_record(conn,record) for record in map(parse_record, content[record_count-current_max-1::-1])]</span><span id="a51e" class="nl lm iq nh b gy nq nn l no np">  return records</span></pre><p id="8efc" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated">这是最大的功能。它检查是否找到新记录。如果是，它首先为每个记录调用<strong class="ki ir"><em class="ld">parse _ record()</em></strong>，然后继续保存记录。</p><p id="e4cc" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated"><strong class="ki ir"> 6。persist _ tastse _ of _ India _ record(</strong><em class="ld">conn</em><strong class="ki ir">，</strong> <em class="ld"> data </em> <strong class="ki ir"> ): </strong>它尝试分别持久化帖子的每个组成部分(基于定义的实体)</p><pre class="nc nd ne nf gt ng nh ni nj aw nk bi"><span id="d20e" class="nl lm iq nh b gy nm nn l no np">def persist_taste_of_india_record(conn,data):<br/>  persist_record(conn,data,'posts')<br/>  persist_record(conn,data['itunes'],'itunes_data')<br/>  for media in data['media']:<br/>    persist_record(conn,media,'media')<br/>  conn.commit()<br/> return True</span></pre><p id="2d14" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated">conn.commit() 是必需的，否则数据库中的更改不是永久的，并且会在会话过期后丢失。</p><p id="e356" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated"><strong class="ki ir"> 7。persist _ record(</strong><em class="ld">conn</em><strong class="ki ir">，</strong> <em class="ld"> data </em> <strong class="ki ir">，</strong><em class="ld">TB _ name</em><strong class="ki ir">):</strong>根据对象类型执行插入查询:</p><pre class="nc nd ne nf gt ng nh ni nj aw nk bi"><span id="f12e" class="nl lm iq nh b gy nm nn l no np">def persist_record(conn,data,tb_name):<br/> query_param  = tuple(<br/>                list(map(lambda k : data[k],col_list[tb_name])))</span><span id="bab1" class="nl lm iq nh b gy nq nn l no np"> execute_query(conn,query_strings[tb_name],query_param)<br/> return</span></pre><p id="caff" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated"><strong class="ki ir"> <em class="ld"> query_param </em> </strong>只是将列顺序中的值存储在一个元组中。<br/><strong class="ki ir"><em class="ld">execute _ query()</em></strong>最后将数据插入数据库</p><p id="96b5" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated">8.<strong class="ki ir">执行并调度它:</strong>脚本通过调用 begin 函数并调度它每天执行一次来完成，如下所示:</p><pre class="nc nd ne nf gt ng nh ni nj aw nk bi"><span id="8a66" class="nl lm iq nh b gy nm nn l no np">if __name__ == '__main__':<br/>  feed_url  = 'https://audioboom.com/channels/4930693.rss'<br/>  db_credentials = 'connection.json'</span><span id="9bc3" class="nl lm iq nh b gy nq nn l no np">  print('Main Script Running...')<br/>  begin(feed_url,db_credentials)<br/>  scheduler = BlockingScheduler()<br/>  scheduler.add_job(begin, 'interval',[feed_url,db_credentials], hours=24)</span><span id="bd77" class="nl lm iq nh b gy nq nn l no np">  try:<br/>    scheduler.start()<br/>  except Exception as e:<br/>    print('Stopping Schedule!!')</span><span id="fdfe" class="nl lm iq nh b gy nq nn l no np">  print('Main Script Exiting!!')</span></pre><p id="670a" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated">我在这里使用了阻塞调度程序，因此 python 线程总是活跃的。如果您想要停止执行，那么<strong class="ki ir"> try…catch </strong>块将干净地退出。现在，您只需使用以下命令执行主脚本，立即运行一次，并安排在每天同一时间运行一次:</p><pre class="nc nd ne nf gt ng nh ni nj aw nk bi"><span id="227c" class="nl lm iq nh b gy nm nn l no np">docker exec -d rss-python python main.py</span></pre><h1 id="348f" class="ll lm iq bd ln lo nr lq lr ls ns lu lv jw nt jx lx jz nu ka lz kc nv kd mb mc bi translated">瞧啊。</h1><p id="f00e" class="pw-post-body-paragraph kg kh iq ki b kj md jr kl km me ju ko kp mf kr ks kt mg kv kw kx mh kz la lb ij bi translated">就是这样。您已经准备好一个 RSS 解析器，每天运行并更新数据库。</p><h1 id="d7bc" class="ll lm iq bd ln lo nr lq lr ls ns lu lv jw nt jx lx jz nu ka lz kc nv kd mb mc bi translated">提高</h1><p id="84bc" class="pw-post-body-paragraph kg kh iq ki b kj md jr kl km me ju ko kp mf kr ks kt mg kv kw kx mh kz la lb ij bi translated">显然，许多升级和增强是可能。许多最佳实践没有被遵循。坚实的原则，后台调度程序，使用 docker 编写文件等可能是第一步。在构建这个系统的时候，我首先关注的是得到一个功能性的系统，并在重构和设计上花费最少的精力。<br/>尽管如此，请留下您的评论，并随时通过 github 联系我。</p></div></div>    
</body>
</html>