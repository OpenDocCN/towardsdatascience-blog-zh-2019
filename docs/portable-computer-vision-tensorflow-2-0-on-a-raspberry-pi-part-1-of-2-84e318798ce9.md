# ä¾¿æºå¼è®¡ç®—æœºè§†è§‰:æ ‘è“ Pi ä¸Šçš„ TensorFlow 2.0

> åŸæ–‡ï¼š<https://towardsdatascience.com/portable-computer-vision-tensorflow-2-0-on-a-raspberry-pi-part-1-of-2-84e318798ce9?source=collection_archive---------0----------------------->

![](img/ae9693f1f1b48d074beeece6401a5b76.png)

## å¾®å°ã€ä½æˆæœ¬çš„ç‰©ä½“æ£€æµ‹å’Œåˆ†ç±»ã€‚

# ç¬¬ 1 éƒ¨åˆ†â€”ç®€ä»‹

åªéœ€å¤§çº¦ 100 ç¾å…ƒï¼Œä½ å°±å¯ä»¥å°†æ·±åº¦å­¦ä¹ æ·»åŠ åˆ°åµŒå…¥å¼ç³»ç»Ÿæˆ–ä½ çš„ä¸‹ä¸€ä¸ªç‰©è”ç½‘é¡¹ç›®ä¸­ã€‚

ä½ æ˜¯åˆšå…¥é—¨æœºå™¨/æ·±åº¦å­¦ä¹ ï¼ŒTensorFlowï¼Œè¿˜æ˜¯ Raspberry Piï¼Ÿå®Œç¾ï¼Œè¿™ä¸ªåšå®¢ç³»åˆ—æ˜¯ç»™ä½ çš„ï¼

åœ¨è¿™ä¸ªç³»åˆ—ä¸­ï¼Œæˆ‘å°†å‘æ‚¨å±•ç¤ºå¦‚ä½•:

1.  ä½¿ç”¨ **TensorFlow 2.0** å’Œ **Keras éƒ¨ç½²é¢„è®­ç»ƒçš„å›¾åƒåˆ†ç±»æ¨¡å‹( **MobileNetV2** )ã€‚**
2.  å°†æ¨¡å‹è½¬æ¢ä¸º **TensorFlow Liteï¼Œ**ä¸€ç§é’ˆå¯¹åµŒå…¥å¼å’Œç§»åŠ¨è®¾å¤‡ä¼˜åŒ–çš„æ¨¡å‹æ ¼å¼ã€‚
3.  ä½¿ç”¨ Coral çš„ **USB Edge TPU åŠ é€Ÿå™¨**å’Œ **Edge TPU ç¼–è¯‘å™¨ï¼ŒåŠ é€Ÿä»»ä½• **TensorFlow Lite** æ¨¡å‹çš„æ¨ç†ã€‚**
4.  ä½¿ç”¨**è½¬ç§»å­¦ä¹ **ç”¨**è‡ªå®šä¹‰å›¾åƒåˆ†ç±»å™¨é‡æ–°è®­ç»ƒ MobileNetV2ã€‚**

æœ¬ç³»åˆ—**ç¬¬ä¸€ç¯‡**(ä½ ç°åœ¨æ­£åœ¨çœ‹ï¼)å°†å¸¦æ‚¨å®Œæˆæ„å»ºææ–™ã€å®‰è£…ä»¥åŠå°† MobileNetV2 éƒ¨ç½²åˆ°æ‚¨ Raspberry Piã€‚

# æœ¯è¯­å’Œå‚è€ƒğŸ“š

[**æ ‘è“æ´¾**](https://www.raspberrypi.org/)â€”â€”ä¸€æ¬¾å—æ•™è‚²è€…ã€ç¡¬ä»¶çˆ±å¥½è€…å’Œæœºå™¨äººä¸“å®¶æ¬¢è¿çš„å°å‹å»‰ä»·ç”µè„‘ã€‚ğŸ¤–

[**TensorFlow**](https://www.tensorflow.org/) â€”æœºå™¨å­¦ä¹ çš„å¼€æºå¹³å°ã€‚

[**tensor flow Lite**](https://www.tensorflow.org/lite)â€”ç”¨äºåœ¨ç§»åŠ¨å’ŒåµŒå…¥å¼è®¾å¤‡ä¸Šéƒ¨ç½² **TensorFlow** æ¨¡å‹çš„è½»é‡çº§åº“ã€‚

**å·ç§¯ç¥ç»ç½‘ç»œ**â€”â€”ä¸€ç§æ·±åº¦å­¦ä¹ æ¨¡å‹ï¼Œéå¸¸é€‚åˆå›¾åƒåˆ†ç±»å’Œå¯¹è±¡æ£€æµ‹åº”ç”¨ã€‚

[**MobileNetV2**](https://ai.googleblog.com/2018/04/mobilenetv2-next-generation-of-on.html)**â€”**ä¸€ç§å…ˆè¿›çš„å›¾åƒè¯†åˆ«æ¨¡å‹ï¼Œé’ˆå¯¹æ™®é€šæ‰‹æœºå¤„ç†å™¨çš„æ€§èƒ½è¿›è¡Œäº†ä¼˜åŒ–ã€‚

![](img/32001cfa8d79abb17ee79459b58ccc5e.png)

Comparison of general-purpose computer vision neural networks. Image Credit: [MobileNetV2: The Next Generation of On-Device Computer Vision Networks](https://ai.googleblog.com/2018/04/mobilenetv2-next-generation-of-on.html)

[**è¾¹ç¼˜ TPU**](https://cloud.google.com/edge-tpu/) â€”å¼ é‡å¤„ç†å•å…ƒ(TPU)æ˜¯ä¸€ä¸ªé›†æˆç”µè·¯ï¼Œç”¨äºåŠ é€Ÿ **TensorFlow æ‰§è¡Œçš„è®¡ç®—ã€‚****è¾¹ç¼˜ TPU** æ˜¯ä¸ºâ€œåœ¨è¾¹ç¼˜â€çš„ç§»åŠ¨å’ŒåµŒå…¥å¼è®¾å¤‡å¼€å‘çš„ï¼Œå åœ°é¢ç§¯å°

![](img/2b47c18580f665108f041cd229f63d09.png)![](img/d5397b2102de4819b38915c3a0f2933e.png)![](img/62a6a774990ddaa2fa92f9b07199e571.png)

TPUv1, TPUv2 (left, middle) at Cloud Next â€˜18\. Edge TPUs on a United States penny (right). Image credit: [Google](https://cloud.google.com/edge-tpu/))

# ç¬¬ 2 éƒ¨åˆ†â€”âœ…æ„å»ºåˆ—è¡¨

## å¯åŠ¨å·¥å…·åŒ…

å¦‚æœä½ åˆšåˆšå…¥é—¨æ ‘è“ Piï¼Œæˆ‘æ¨è Arrow çš„ [Pi ç›¸æœºå¥—è£…](https://www.arrow.com/en/products/3275/adafruit-industries)(90 ç¾å…ƒ)ã€‚å®ƒåŒ…æ‹¬æ‚¨éœ€è¦çš„ä¸€åˆ‡ï¼Œç«‹å³å¼€å§‹:

*   5V 2.4A MicroUSB ç”µæº
*   320x240 2.8 è‹±å¯¸ TFT å‹å· PiTFT ç”µé˜»å¼è§¦æ‘¸å±
*   æ ‘è“ Pi 3 å‹å· B
*   Raspberry Pi æ‘„åƒæœº v2
*   å¡‘æ–™ç›’
*   é¢„è£…äº† NOOBS å®‰è£…ç®¡ç†å™¨çš„ 8GB MicroSD å¡

## Coral USB Edge TPU åŠ é€Ÿå™¨(å¯é€‰)

æ‚¨å¯ä»¥ç¼–è¯‘ **TensorFlow Lite** æ¨¡å‹ï¼Œåœ¨ Coral çš„ USB åŠ é€Ÿå™¨( [Link](https://coral.withgoogle.com/products/accelerator/) )ä¸Šè¿è¡Œï¼Œä»¥ä¾¿æ›´å¿«åœ°è¿›è¡Œæ¨¡å‹é¢„æµ‹ã€‚

å®æ—¶åº”ç”¨ç¨‹åºä»è¿™ç§åŠ é€Ÿä¸­å—ç›ŠåŒªæµ…ã€‚è‡ªåŠ¨é©¾é©¶æœºå™¨äººçš„å†³ç­–æ¨¡å—å°±æ˜¯ä¸€ä¸ªä¾‹å­ã€‚

ä¸€äº›åº”ç”¨ç¨‹åºå¯ä»¥å®¹å¿æ›´é«˜çš„é¢„æµ‹é€Ÿåº¦ï¼Œå¯èƒ½ä¸éœ€è¦ TPU åŠ é€Ÿã€‚ä¾‹å¦‚ï¼Œä½ ä¸éœ€è¦ TPU åŠ é€Ÿæ¥å»ºç«‹ä¸€ä¸ªæ™ºèƒ½ç‹—é—¨ï¼Œä¸ºä½ çš„ç‹—å¼€é—¨(ä½†ä¸è®©æµ£ç†Šè¿›æ¥)ã€‚

å¦‚æœä½ åˆšåˆšå¼€å§‹ï¼Œè·³è¿‡è´­ä¹°è¿™ä¸ªç»„ä»¶ã€‚

ä½ ä¸ç¡®å®šä½ æ˜¯å¦éœ€è¦ USB åŠ é€Ÿå™¨ï¼Ÿä¸‹é¢çš„ MobileNet åŸºå‡†å¯ä»¥å¸®åŠ©æ‚¨åšå‡ºå†³å®šã€‚ä¸‹é¢çš„æµ‹é‡æè¿°äº†æ¨ç†é€Ÿåº¦(å•ä½ä¸ºæ¯«ç§’)â€”â€”é€Ÿåº¦è¶Šä½è¶Šå¥½ï¼

![](img/dffacc8575d108a2e3ab8d20a76ed892.png)

Image Credit: [Alasdair Allan](https://blog.hackster.io/@aallan), [Benchmarking TensorFlow and TensorFlow Lite on the Raspberry Pi](https://blog.hackster.io/benchmarking-tensorflow-and-tensorflow-lite-on-the-raspberry-pi-43f51b796796)

## å®šåˆ¶æ„å»º

å¦‚æœæ‚¨å·²ç»æœ‰äº†ä¸€ä¸ª Raspberry Pi æˆ–ä¸€äº›ç»„ä»¶ï¼Œåˆå­¦è€…å·¥å…·åŒ…å¯èƒ½ä¼šåŒ…å«æ‚¨ä¸éœ€è¦çš„é¡¹ç›®ã€‚

ä»¥ä¸‹æ˜¯æˆ‘è‡ªå·±åˆ¶ä½œçš„é›¶ä»¶(å¤§çº¦ 250 ç¾å…ƒ/å°)ã€‚

*   æ ‘è“ Pi å‹å· 3 b+(35 ç¾å…ƒ)
*   æ ‘è“ Pi ç›¸æœº v2(30 ç¾å…ƒ)
*   Coral USB Edge TPU åŠ é€Ÿå™¨â€”â€”åŠ é€Ÿæ¨¡å‹æ¨ç†(75 ç¾å…ƒï¼Œ[é“¾æ¥](https://coral.withgoogle.com/products/accelerator)
*   Pi Foundation æ˜¾ç¤ºå±â€” 7 è‹±å¯¸è§¦æ‘¸å±æ˜¾ç¤ºå±(80 ç¾å…ƒï¼Œ[é“¾æ¥](https://www.adafruit.com/product/2718)
*   SmartiPi è§¦æ‘¸æ”¯æ¶(25 ç¾å…ƒï¼Œ[é“¾æ¥](http://www.adafruit.com/product/3187)
*   å¯è°ƒ Pi æ‘„åƒæœºæ”¯æ¶(5 ç¾å…ƒï¼Œ[è¿æ†](https://www.adafruit.com/product/1434)
*   RPi æ‘„åƒæœº 24 è‹±å¯¸çš„æŸ”æ€§ç”µç¼†(ï¼„3ï¼Œ[é“¾æ¥](https://www.adafruit.com/product/1731))

æˆ‘å¾ˆæƒ³å¬å¬ä½ è‡ªå·±çš„æ„å»ºåˆ—è¡¨ï¼â¤ï¸ç»™æˆ‘å‘æ¨ç‰¹ [@grepLeigh](https://twitter.com/grepLeigh) æˆ–è€…åœ¨ä¸‹é¢è¯„è®ºã€‚

# ç¬¬ 3 éƒ¨åˆ†â€” Raspberry Pi è®¾ç½®ğŸ°

å¦‚æœä½ è´­ä¹°äº†ä¸€ä¸ªé¢„è£… NOOBS çš„ SD å¡ï¼Œæˆ‘å»ºè®®ä½ å…ˆæµè§ˆä¸€ä¸‹è¿™ä¸ªæ¦‚è¿°:[è®¾ç½®ä½ çš„æ ‘è“æ´¾](https://projects.raspberrypi.org/en/projects/raspberry-pi-setting-up/2)

**åœ¨è¿›è¡Œ**ä¹‹å‰ï¼Œæ‚¨éœ€è¦:

*   å°†æ‚¨çš„ Pi è¿æ¥åˆ°äº’è”ç½‘( [doc](https://projects.raspberrypi.org/en/projects/raspberry-pi-using/4) )
*   SSH åˆ°ä½ çš„æ ‘è“ Pi ( [doc](https://www.raspberrypi.org/documentation/remote-access/ssh/) )

# ç¬¬ 4 éƒ¨åˆ†â€”ä¸»è¦è®¡ç®—æœº:ä¸‹è½½å’Œå®‰è£…ä¾èµ–é¡¹

`rpi-vision`æ˜¯ä¸€å¥—å·¥å…·ï¼Œå¯è®©æ‚¨æ›´è½»æ¾åœ°:

*   åœ¨ä½ çš„ Raspberry Pi ä¸Šå®‰è£…å¾ˆå¤šä¾èµ–é¡¹(TensorFlow Liteï¼ŒTFT è§¦æ‘¸å±é©±åŠ¨ç¨‹åºï¼Œå°† PiCamera å¸§ç¼“å†²åŒºå¤åˆ¶åˆ° TFT è§¦æ‘¸å±çš„å·¥å…·)ã€‚
*   å°†æ¨¡å‹éƒ¨ç½²åˆ° Raspberry Piã€‚
*   åœ¨ä½ çš„ç”µè„‘æˆ–è°·æ­Œäº‘çš„äººå·¥æ™ºèƒ½å¹³å°ä¸Šè®­ç»ƒæ–°æ¨¡å‹ã€‚
*   ä¸ºè¾¹ç¼˜ TPU ç¼–è¯‘ 8 ä½é‡åŒ–æ¨¡å‹ã€‚

1.  åœ¨æ‚¨çš„**ä¸»è®¡ç®—æœº**ä¸Šå…‹éš†`rpi-vision` repo(ä¸æ˜¯æ‚¨çš„ Raspberry Pi)

```
$ git clone git@github.com:leigh-johnson/rpi-vision.git && cd rpi-vision
```

2.åœ¨æ‚¨çš„**ä¸»è®¡ç®—æœº**ä¸Šï¼Œåˆ›å»ºä¸€ä¸ªæ–°çš„è™šæ‹Ÿç¯å¢ƒï¼Œç„¶åå®‰è£…`rpi-vision`åŒ…ã€‚

```
$ pip install virtualenv; virtualenv -p $(which python3) .venv && source .venv/bin/activate && pip install -e .
```

3.åœ¨ç»§ç»­ä¹‹å‰ï¼ŒéªŒè¯ä½ å¯ä»¥å¯¹ä½ çš„æ ‘è“ Pi è¿›è¡Œ SSHã€‚

å¦‚æœæ‚¨ä½¿ç”¨é»˜è®¤çš„ Raspbian æ˜ åƒï¼Œæ‚¨çš„ Pi çš„ä¸»æœºåå°†æ˜¯`raspberrypi.local`

```
$ ssh pi@raspberry.local
```

# ç¬¬ 5 éƒ¨åˆ†â€”ä¸»è¦è®¡ç®—æœº:åˆ›å»ºé…ç½®æ–‡ä»¶

`rpi-vision`ä½¿ç”¨ **Ansible** æ¥ç®¡ç†ä½ çš„ Raspberry Pi ä¸Šçš„éƒ¨ç½²å’Œä»»åŠ¡ã€‚Ansible æ˜¯ä¸€ä¸ªè‡ªåŠ¨åŒ–è®¡ç®—æœºé…ç½®çš„æ¡†æ¶ã€‚

åˆ›å»º Ansible æ‰€éœ€çš„ 2 ä¸ªé…ç½®æ–‡ä»¶:

## **ã€‚env/my-inventory.ini**

å¦‚æœæ‚¨å¯¹ Pi ä½¿ç”¨è‡ªå®šä¹‰ä¸»æœºåï¼Œè¯·æ›¿æ¢`raspberrypi.local.`

```
tee -a .env/my-inventory.ini <<EOF
[rpi_vision]
raspberrypi.local[rpi_vision:vars]
ansible_connection=ssh
ansible_user=pi
ansible_python=/usr/bin/python3
EOF
```

## ã€‚env/my-vars.json

å¦‚æœæ‚¨å¯¹ Pi ä½¿ç”¨è‡ªå®šä¹‰ä¸»æœºåï¼Œè¯·æ›¿æ¢`raspberrypi.local.`

```
tee -a .env/my-vars.ini <<EOF
{ 
  *"RPI_HOSTNAME"*: "raspberrypi.local",
  *"VERSION"*: "release-v1.0.0"
}
EOF
```

# ç¬¬ 6 éƒ¨åˆ†â€” Raspberry Pi:å®‰è£…ä¾èµ–é¡¹

```
$ make rpi-install
```

æ‚¨å°†çœ‹åˆ°ä¸€ä¸ª**å¯è¡Œå‰§æœ¬**çš„è¾“å‡ºã€‚ [**Ansible**](https://docs.ansible.com/) æ˜¯ä¸€ä¸ªè‡ªåŠ¨åŒ–é…ç½®è®¡ç®—æœºçš„æ¡†æ¶ã€‚

æ‚¨çš„ Pi ä¸Šå®‰è£…äº†ä»€ä¹ˆçš„å¿«é€Ÿæ‘˜è¦:

*   `rpi-vision`å›è´­
*   `rpi-fbcp`(ä» PiCamera å¤åˆ¶ framebuffer åˆ° TFT è§¦æ‘¸å±æ˜¾ç¤ºå™¨çš„å·¥å…·)
*   TFT è§¦æ‘¸å±é©±åŠ¨å™¨å’Œ X11 é…ç½®

æ‚¨å¯ä»¥é€šè¿‡æ‰“å¼€`playbooks/bootstrap-rpi.yml`æ¥æ£€æŸ¥åœ¨æ‚¨çš„ Raspberry Pi ä¸Šè¿è¡Œçš„ä»»åŠ¡

åœ¨å®‰è£…è¿è¡Œæ—¶ï¼Œé€šè¯»ä¸‹ä¸€éƒ¨åˆ†ï¼Œäº†è§£ ***å¦‚ä½•***CNN**å·¥ä½œä»¥åŠ ***ä¸ºä»€ä¹ˆ*** å®ƒä»¬å¯¹**è®¡ç®—æœºè§†è§‰**ä»»åŠ¡æœ‰ç”¨ã€‚**

# **ç¬¬ 7 éƒ¨åˆ† CNNs(å·ç§¯ç¥ç»ç½‘ç»œ)ç®€ä»‹**

**CNN æ˜¯é©±åŠ¨è‡ªåŠ¨é©¾é©¶æ±½è½¦å’Œå›¾åƒæœç´¢å¼•æ“çš„å…³é”®æŠ€æœ¯ã€‚è¯¥æŠ€æœ¯å¯¹äºè®¡ç®—æœºè§†è§‰æ¥è¯´æ˜¯å¸¸è§çš„ï¼Œä½†ä¹Ÿå¯ä»¥åº”ç”¨äºæ•°æ®ä¸­å…·æœ‰**å±‚æ¬¡æ¨¡å¼çš„ä»»ä½•é—®é¢˜ï¼Œå…¶ä¸­**å¤æ‚æ¨¡å¼**å¯ä»¥ç”±ç®€å•æ¨¡å¼**ç»„è£…è€Œæˆ**ã€‚****

## **è§†è§‰çš®å±‚å»ºæ¨¡**

**åœ¨ 20 ä¸–çºª 50 å¹´ä»£æœ«å’Œ 60 å¹´ä»£ï¼Œå¤§å«Â·HÂ·å“ˆè´å°”å’Œæ‰˜é¡¿Â·å¨å°”æ£®åœ¨çŒ«å’ŒçŒ´å­èº«ä¸Šåšäº†å®éªŒï¼Œä»¥æ›´å¥½åœ°äº†è§£è§†è§‰çš®å±‚ã€‚**

**![](img/07c001cfd01fc53026c7f010537bca42.png)**

**Diagram of the implant installed in the skulls of cats with a trephine. Image Credit: [SINGLE UNIT ACTIVITY IN STRIATE CORTEX OF UNRESTRAINED CATS](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC1357023/pdf/jphysiol01301-0020.pdf)**

**ä»–ä»¬è¯æ˜äº†çº¹çŠ¶çš®å±‚ä¸­çš„ç¥ç»å…ƒå¯¹æœ‰é™è§†é‡ä¸­çš„åˆºæ¿€åšå‡ºååº”ï¼Œä»–ä»¬ç§°ä¹‹ä¸ºæ„Ÿå—é‡ã€‚**

**ä»–ä»¬æ³¨æ„åˆ°äº†åŒå¿ƒé‡å ååº”ï¼Œå…¶ä¸­å¤æ‚çš„æ¨¡å¼æ˜¯ä½æ°´å¹³æ¨¡å¼çš„ç»„åˆã€‚**

**ä»–ä»¬çš„å‘ç°è¿˜æ­ç¤ºäº†**ç‰¹æ®ŠåŒ–**ï¼Œå…¶ä¸­ä¸€äº›ç¥ç»å…ƒå°†**åªå¯¹**ç‰¹å®šå½¢çŠ¶**æˆ–æ¨¡å¼**åšå‡ºååº”ã€‚**

**åœ¨ 20 ä¸–çºª 80 å¹´ä»£ï¼Œå— Hubel å’Œ Wielson çš„å¯å‘ï¼ŒKunihiko Fukushima åœ¨**neocogniton**ã€**ã€**ä¸Šå‘è¡¨äº†ä¸€ç§èƒ½å¤Ÿå­¦ä¹ å…·æœ‰å‡ ä½•ç›¸ä¼¼æ€§çš„æ¨¡å¼çš„ç¥ç»ç½‘ç»œã€‚**

**![](img/c458ce629007f0d2d3c48581a8184079.png)**

**Diagram of a Neocogitron, the foundation for modern CNNS. Image Credit: [Neocognitron: A Self-organizing Neural Network Model for a Mechanism of Pattern Recognition Unaffected by Shift in Position](https://www.cs.princeton.edu/courses/archive/spr08/cos598B/Readings/Fukushima1980.pdf)**

**æ–°å›æ—‹åŠ é€Ÿå™¨æœ‰ä¸¤ä¸ªå…³é”®ç‰¹æ€§:**

*   *****å­¦ä¹ åˆ°çš„æ¨¡å¼æ˜¯æœ‰å±‚æ¬¡çš„ã€‚*** è¶Šæ¥è¶Šå¤æ‚çš„å›¾æ¡ˆæ˜¯ç”±è¶Šæ¥è¶Šç®€å•çš„å›¾æ¡ˆç»„æˆçš„ã€‚**
*   *****å­¦ä¹ åˆ°çš„æ¨¡å¼æ˜¯ä½ç½®ä¸å˜å’Œå¹³ç§»ä¸å˜çš„*ã€‚**ç½‘ç»œå­¦ä¹ åˆ°ä¸€ä¸ªæ¨¡å¼åï¼Œå¯ä»¥åœ¨ä¸åŒçš„ä½ç½®è¯†åˆ«è¿™ä¸ªæ¨¡å¼ã€‚åœ¨**å­¦ä¹ å¦‚ä½•å¯¹ç‹—**è¿›è¡Œåˆ†ç±»ä¹‹åï¼Œç½‘ç»œå¯ä»¥å‡†ç¡®åœ°å¯¹å€’ç«‹çš„ç‹—**è¿›è¡Œåˆ†ç±»ï¼Œè€Œæ— éœ€å­¦ä¹ å…¨æ–°çš„æ¨¡å¼ã€‚****

**neocogitron æ¨¡å‹æ˜¯ç°ä»£å·ç§¯ç¥ç»ç½‘ç»œçš„çµæ„Ÿæ¥æºã€‚**

## **å¯è§†åŒ–å·ç§¯è¿ç®—:2D**

**![](img/39bd4a300e52ac38b3d02f2480532423.png)**

**(Left) 2D 4x4 Input matrix. (Middle) 2D 2x2 kernel. (Right) 2D 2x2 output feature map.**

****è¾“å…¥å±‚**è¢«é€å…¥**å·ç§¯å±‚**ï¼Œå·ç§¯å±‚ä½¿ç”¨**æ»¤æ³¢å™¨è½¬æ¢è¾“å…¥çš„**åŒºåŸŸ**ã€‚****

****è¿‡æ»¤å™¨**ä¹Ÿè¢«ç§°ä¸º**å†…æ ¸ã€‚****

**![](img/780f22cc93a46f888ba3a49b8170dd31.png)**

**The filter â€œslidesâ€ to each possible position, and the result is added to the feature map.**

**å¯¹äºè¾“å…¥çŸ©é˜µä¸­çš„æ¯ä¸ªä½ç½®ï¼Œ**å·ç§¯è¿ç®—**å¯¹æ¯ä¸ªå…ƒç´ æ‰§è¡ŒçŸ©é˜µä¹˜æ³•ã€‚**

**äº§ç”Ÿçš„çŸ©é˜µè¢«æ±‚å’Œå¹¶å­˜å‚¨åœ¨**ç‰¹å¾å›¾ä¸­ã€‚****

**å¯¹è¾“å…¥çŸ©é˜µä¸­çš„æ¯ä¸ªä½ç½®é‡å¤è¯¥æ“ä½œã€‚**

## **å¯è§†åŒ–å·ç§¯è¿ç®—:3D**

**![](img/298497d2f3123508f5d6ac03fce582a2.png)**

**Image Credit: [Applied Deep Learning â€” Part 4: Convolutional Neural Networks](/applied-deep-learning-part-4-convolutional-neural-networks-584bc134c1e2)**

**CNN çš„**è¾“å…¥å±‚**é€šå¸¸æ˜¯ä¸€ä¸ª 3D æ•°æ®ç»“æ„ï¼Œå…·æœ‰ ***é«˜åº¦*** ã€ ***å®½åº¦*** ã€ ***é€šé“*** (RGB æˆ–ç°åº¦å€¼)ã€‚**

**æˆ‘ä»¬åœ¨ç‰¹å¾åœ°å›¾æ ˆä¸­è¶Šæ·±å…¥ï¼Œæ¯ä¸ªåœ°å›¾å±‚å°±å˜å¾—è¶Šç¨€ç–ã€‚è¿™æ„å‘³ç€è¿‡æ»¤å™¨æ£€æµ‹åˆ°çš„ç‰¹å¾æ›´å°‘ã€‚**

**ç‰¹å¾åœ°å›¾å †æ ˆ**çš„**å‰å‡ å±‚**æ£€æµ‹ç®€å•çš„è¾¹ç¼˜å’Œå½¢çŠ¶**ï¼Œçœ‹èµ·æ¥ä¸è¾“å…¥å›¾åƒç›¸ä¼¼ã€‚éšç€æˆ‘ä»¬è¿›å…¥ç‰¹å¾åœ°å›¾å †æ ˆè¶Šæ¥è¶Šæ·±ï¼Œå¯¹äºäººçœ¼æ¥è¯´ï¼Œç‰¹å¾å˜å¾—è¶Šæ¥è¶ŠæŠ½è±¡ã€‚æ›´æ·±çš„ç‰¹å¾å±‚**ç¼–ç åˆ†ç±»æ•°æ®ï¼Œ**åƒâ€œçŒ«è„¸â€æˆ–â€œçŒ«è€³â€ã€‚**

**![](img/0a7f86b502e1f2eba61edfc0b89561f9.png)**

**Comparison of feature maps from the first convolution layer (block1_conv1) with later layers (block5_conv1). Image Credit: [Applied Deep Learning â€” Part 4: Convolutional Neural Networks](/applied-deep-learning-part-4-convolutional-neural-networks-584bc134c1e2)**

## **ä½ æƒ³äº†è§£æ›´å¤šå…³äº CNN çš„ä¿¡æ¯å—ï¼Ÿ**

**æ‚¨çš„ä¾èµ–é¡¹å®‰è£…ç°åœ¨å¯èƒ½å·²ç»å®Œæˆäº†ã€‚è¦å‘å‰è¿ˆè¿›ï¼Œè¯·è·³åˆ°**ç¬¬ 8 éƒ¨åˆ†â€”â€”éƒ¨ç½²é¢„åŸ¹è®­æ¨¡å‹ MobileNetV2ã€‚****

**å¦‚æœæ‚¨è®¡åˆ’è®­ç»ƒä¸€ä¸ªè‡ªå®šä¹‰åˆ†ç±»å™¨ï¼Œæˆ–è€…æƒ³äº†è§£æ›´å¤šå…³äºå·ç§¯ç¥ç»ç½‘ç»œçš„ä¿¡æ¯ï¼Œè¯·ä»è¿™é‡Œå¼€å§‹:**

*   **[åº”ç”¨æ·±åº¦å­¦ä¹ â€”ç¬¬ 4 éƒ¨åˆ†:å·ç§¯ç¥ç»ç½‘ç»œ](/applied-deep-learning-part-4-convolutional-neural-networks-584bc134c1e2)**
*   **[ä½¿ç”¨ Scikit-learn å’Œ TensorFlow è¿›è¡Œæœºå™¨å­¦ä¹ ](https://www.amazon.com/Hands-Machine-Learning-Scikit-Learn-TensorFlow/dp/1491962291)ï¼Œ*ç¬¬ 13 ç« ï¼Œå·ç§¯ç¥ç»ç½‘ç»œ*ï¼Œä½œè€… AurÃ©lien GÃ©ron**
*   **[ç”¨ Python è¿›è¡Œæ·±åº¦å­¦ä¹ ](https://www.amazon.com/Deep-Learning-Python-Francois-Chollet/dp/1617294438/)ï¼Œ*ç¬¬äº”ç« è®¡ç®—æœºè§†è§‰çš„æ·±åº¦å­¦ä¹ ï¼Œ*Francois Chollet**

# **ç¬¬ 8 éƒ¨åˆ†â€”éƒ¨ç½²é¢„è®­ç»ƒæ¨¡å‹(MobileNetV2)**

## **ç°åœºæ¼”ç¤º(ä½¿ç”¨ TensorFlow 2.0)**

**I used this code to sanity-check the TensorFlow 2.0-beta0 wheel that I cross-compiled for my Raspberry Pi 3.**

1.  **å˜˜åˆ°ä½ çš„æ ‘è“çš®**

```
$ ssh raspberrypi.local
```

**2.å¯åŠ¨æ–°çš„ tmux ä¼šè¯**

```
pi@raspberryi:~ $ tmux new-session -s mobilenetv2
```

**3.é€šè¿‡æŒ‰ control+b å‚ç›´æ‹†åˆ† tmux ä¼šè¯ï¼Œç„¶å"**

**4.å¯åŠ¨ä¸€ä¸ª`fbcp`è¿›ç¨‹ï¼Œé€šè¿‡ SPI æ¥å£å°†å¸§ç¼“å†²åŒºä» PiCamera å¤åˆ¶åˆ° TFT æ˜¾ç¤ºå™¨ã€‚è®©è¿™ä¸ªè¿‡ç¨‹ç»§ç»­è¿è¡Œã€‚**

```
pi@raspberryi:~ $ fbcp
```

**5.é€šè¿‡æŒ‰ä¸‹ control+bï¼Œç„¶åæŒ‰ä¸‹ o æ¥åˆ‡æ¢ tmux é¢æ¿ã€‚**

**6.æ¿€æ´»å‰é¢ç¬¬ 6 éƒ¨åˆ†ä¸­å®‰è£…çš„è™šæ‹Ÿç¯å¢ƒã€‚**

```
pi@raspberryi:~ $ cd ~/rpi-vision && . .venv/bin/activate
```

**7.å¯åŠ¨ mobilenetv2 ä»£ç†è¿›ç¨‹ã€‚ä»£ç†åˆå§‹åŒ–å¤§çº¦éœ€è¦ 60 ç§’ã€‚**

```
pi@raspberryi:~/rpi-vision $ python rpi_vision/agent/mobilenet_v2.py
```

**æ‚¨å°†çœ‹åˆ°æ¨¡å‹åŸºç¡€çš„æ‘˜è¦ï¼Œç„¶åä»£ç†å°†æ‰“å°æ¨ç†ï¼Œç›´åˆ°åœæ­¢ã€‚[ç‚¹å‡»æŸ¥çœ‹æ‚¨åº”è¯¥çœ‹åˆ°çš„è¦ç‚¹](https://gist.github.com/leigh-johnson/14541749afbd8e4471b85699ddd0c9f5)ã€‚**

**è¿™ä¸ªæ¼”ç¤ºä½¿ç”¨äº† **ImageNet** åˆ†ç±»å™¨çš„æƒé‡ï¼Œä½ å¯ä»¥åœ¨ã€image-net.orgã€‘çš„[ä¸­æŸ¥æ‰¾ã€‚](http://image-net.org/explore)**

# **æ„Ÿè°¢æ‚¨çš„é˜…è¯»ï¼**

**æ­å–œæ‚¨ï¼Œæ‚¨åˆšåˆšä¸ºæ‚¨çš„ Raspberry Pi éƒ¨ç½²äº†ä¸€ä¸ªå›¾åƒåˆ†ç±»æ¨¡å‹ï¼âœ¨**

**å¯»æ‰¾æ›´å¤šé’ˆå¯¹ Raspberry Pi å’Œå…¶ä»–å°å‹è®¾å¤‡çš„æœºå™¨å­¦ä¹ å®è·µç¤ºä¾‹ï¼Ÿ[æ³¨å†Œæˆ‘çš„ç®€è®¯](https://www.bitsy.ai/)ï¼**

**æˆ‘å‘å¸ƒäº†ç°å®ä¸–ç•Œä¸­ ML åº”ç”¨ç¨‹åºçš„ä¾‹å­(æœ‰å®Œæ•´çš„æºä»£ç )å’Œæ¼‚äº®çš„æŠ€å·§ï¼Œå¦‚[è‡ªåŠ¨æ¶ˆé™¤è¾¹æ¡†æ³¨é‡Šçš„ç—›è‹¦](https://www.bitsy.ai/automate-bounding-box-annotation-with-tensorflow-and-automl/)ã€‚**