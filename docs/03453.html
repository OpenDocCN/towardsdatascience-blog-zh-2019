<html>
<head>
<title>Text Classification — RNN’s or CNN’s?</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">文本分类——RNN 的还是 CNN 的？</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/text-classification-rnns-or-cnn-s-98c86a0dd361?source=collection_archive---------5-----------------------#2019-06-02">https://towardsdatascience.com/text-classification-rnns-or-cnn-s-98c86a0dd361?source=collection_archive---------5-----------------------#2019-06-02</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><p id="a1bb" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><a class="ae ko" href="https://en.wikipedia.org/wiki/Recurrent_neural_network" rel="noopener ugc nofollow" target="_blank"><strong class="js iu"/></a>是一类人工神经网络，其中节点之间的连接沿着序列形成有向图。它基本上是一系列神经网络块，像链条一样相互链接。每一个都在向下一个传递信息。如果你想深入内部机制，我强烈推荐科拉的<a class="ae ko" href="http://colah.github.io/posts/2015-08-Understanding-LSTMs/" rel="noopener ugc nofollow" target="_blank">博客</a>。这种架构允许 RNN 展示时间行为并捕获顺序数据，这使它在处理文本数据时成为一种更“自然”的方法，因为文本天生就是顺序的。</p><p id="f60e" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><a class="ae ko" href="https://en.wikipedia.org/wiki/Convolutional_neural_network" rel="noopener ugc nofollow" target="_blank"> <strong class="js iu"> CNN </strong> </a>是一类深度前馈人工神经网络，其中节点之间的连接不形成循环。CNN 通常用在计算机视觉中，然而当应用于各种 NLP 任务时，它们也显示出有希望的结果。再次深入细节，Colah 的博客是一个很好的起点。</p><p id="b581" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">RNN 人被训练识别跨时间的模式，而 CNN 学习识别跨空间的模式。</p><p id="1634" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">哪种 DNN 类型在处理文本数据时表现得更好取决于理解全局/远程语义的频率。对于文本长度很重要的任务，使用 RNN 变体是有意义的。这些类型的任务包括:问答、翻译等。</p><p id="e862" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">事实证明，应用于某些 NLP 问题的 CNN 表现相当好。让我们简单看看当我们在文本数据上使用 CNN 时会发生什么。</p><p id="a067" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">当检测到特殊模式时，将触发每个卷积的结果。通过改变内核的大小并连接它们的输出，您允许自己检测多个大小的模式(2、3 或 5 个相邻的单词)。模式可以是表达式(单词 ngrams？)像“我讨厌”、“非常好”，因此 CNN 可以在句子中识别它们，而不管它们的位置。基于上述解释，最适合 CNN 的似乎是分类任务，如情感分析、垃圾邮件检测或主题分类。卷积和汇集操作丢失了关于单词的本地顺序的信息，因此像在词性标注或实体提取中那样的序列标注有点难以适应纯 CNN 架构(尽管并非不可能，但您可以向输入添加位置特征)。汇集也减少了输出维度，但(希望)保留了最突出的信息。你可以把每个过滤器想象成检测一个特定的特征，比如检测句子是否包含否定，比如“不惊人”。如果这个短语出现在句子中的某个地方，那么对该区域应用过滤器的结果将产生一个大值，而在其他区域产生一个小值。通过执行 max 操作，您保留了关于该特征是否出现在句子中的信息，但是您丢失了关于它出现的确切位置的信息。</p><p id="2f6a" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">当当前步骤与前面的步骤有某种关系时，rnn 被设计成利用顺序数据。这使得它们非常适合具有时间成分(音频、时序数据)和自然语言处理的应用。对于顺序信息显然很重要的应用程序，RNN 的表现非常好，因为如果不使用顺序信息，意思可能会被误解或者语法可能不正确。应用包括图像字幕，语言建模和机器翻译。</p><p id="220d" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">CNN 擅长提取局部的和位置不变的特征，而当分类是由长范围的语义依赖而不是一些局部的关键短语来确定时，RNN 更好。对于文本中的特征检测更重要的任务，例如，搜索愤怒的术语、悲伤、辱骂、命名实体等。CNN 做得很好，而对于顺序建模更重要的任务，RNN 做得更好。基于上述特征，选择 CNN 用于分类任务(如情感分类)是有意义的，因为情感通常由一些关键短语确定，而选择 RNNs 用于序列建模任务(如语言建模或机器翻译或图像字幕)是有意义的，因为它需要对上下文依赖性进行灵活的建模。rnn 通常擅长预测序列中的下一步，而 CNN 可以学习对句子或段落进行分类。</p><p id="f116" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">CNN 的一个重要理由是他们速度快。非常快。基于计算时间，CNN 似乎比 RNN 快得多(~ 5 倍)。卷积是计算机图形的核心部分，在 GPU 的硬件层面上实现。像文本分类或情感分析这样的应用实际上并不需要使用存储在数据序列中的信息。比如一个假设的餐厅点评:<em class="kp">我对这家餐厅非常失望。服务慢得令人难以置信，食物也很一般。我不会回来了。</em>虽然数据中有顺序信息，但如果你试图预测情绪是好是坏，CNN 模型可能就足够了，甚至在计算方面更好。做出预测所需的重要信息存在于短语“非常失望”、“慢得令人难以置信”和“平庸”中如果你只使用 2-gram，一个 RNN 可能能够额外捕捉到是<em class="kp">服务</em>慢得令人难以置信，相比之下，其他东西可能对慢有好处(也许是音乐？).但是，通常情况下，这是不必要的，与简单的模型相比，更复杂的 RNN 可能会溢出。</p><h2 id="4c6d" class="kq kr it bd ks kt ku dn kv kw kx dp ky kb kz la lb kf lc ld le kj lf lg lh li bi translated">参考</h2><figure class="lj lk ll lm gt ln"><div class="bz fp l di"><div class="lo lp l"/></div></figure><div class="lq lr gp gr ls lt"><a href="http://www.wildml.com/2015/11/understanding-convolutional-neural-networks-for-nlp/" rel="noopener  ugc nofollow" target="_blank"><div class="lu ab fo"><div class="lv ab lw cl cj lx"><h2 class="bd iu gy z fp ly fr fs lz fu fw is bi translated">理解用于 NLP 的卷积神经网络</h2><div class="ma l"><h3 class="bd b gy z fp ly fr fs lz fu fw dk translated">当我们听到卷积神经网络(CNN)时，我们通常会想到计算机视觉。CNN 对此负有责任…</h3></div><div class="mb l"><p class="bd b dl z fp ly fr fs lz fu fw dk translated">www.wildml.com</p></div></div><div class="mc l"><div class="md l me mf mg mc mh mi lt"/></div></div></a></div></div></div>    
</body>
</html>