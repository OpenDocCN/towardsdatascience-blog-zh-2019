# 使用 SnowNLP 进行简体中文情感分析的初学者指南

> 原文：<https://towardsdatascience.com/beginners-guide-to-sentiment-analysis-for-simplified-chinese-using-snownlp-ce88a8407efb?source=collection_archive---------5----------------------->

![](img/6c8be1a885b9b3f84e9fd8f0d8a5f63c.png)

Image made by a colleague from Yoozoo Games

通过阅读本文，您将接触到一种分析任何简体中文文本情感的技术。本教程将基于简体中文，但它也可以用于繁体中文，因为 SnowNLP 能够将繁体中文转换为简体中文。

本教程将分为 4 个部分:

1.  设置和安装
2.  用法和 API 调用
3.  培训模式
4.  结论

# [第 1 节]设置和安装

在本教程中，我将通过 pip 在 Windows 操作系统上安装所需的模块。让我们从一个名为 SnowNLP 的开源模块获取文件，它是一个简体中文文本处理模块。虽然这个模块已经很久没有更新了，但是对于大多数用例来说，结果已经足够好了。

## 开源代码库

进入下面的[链接](https://github.com/isnowfy/snownlp)，下载需要的文件。完成后，将压缩文件解压缩到您喜欢的目录中。你应该有一个 **snownlp-master** 文件夹，里面包含所有必要的文件。

## 计算机编程语言

SnowNLP 支持 Python 3，如官方 Github 链接中所述。在本教程中，我将在虚拟环境中使用 Python 3.7.1。

## SnowNLP 模块

您可以通过以下命令轻松安装该模块:

```
pip install snownlp
```

一旦完成，您将能够看到指示版本号的输出。如果您错过了它，可以通过下面的命令检查它:

```
pip list
```

本教程我使用的是 0.12.3 版本。完成后，继续下一部分。

# [第 2 节]用法和 API 调用

让我们更深入地研究一下可用于预处理输入文本的基本 API 调用。

## 初始化

您必须导入它并通过 SnowNLP 类进行初始化，如下所示:

用输入文本作为参数初始化它。建议以一个 **u** 作为前缀，表明这是一个 **Unicode 字符串**。这种语法从 Python 2.0 开始使用，但后来在 3.0 到 3.2 版本中被删除。从 3.3 开始， **u 前缀**是 **Unicode 字符串**的有效语法。

## 单词(标记化)

汉语是一种独特的语言，从某种意义上说，不像世界上的大多数语言，单词之间没有空格。这使得很难确定一个句子中的单词数，因为一个单词可以是一个或多个汉字的组合。因此，当执行任何自然语言处理时，您需要将整个文本块分割成单词，这个过程被称为**标记化**。您可以很容易地使用以下命令来进行令牌化:

您应该得到以下结果作为输出:

```
['我', '喜欢', '看', '电影', '。']
```

## 词性标注

很多时候，我们会对词性标签更感兴趣，词性标签是指与句子中相邻和相关的词之间的关系。如果你理解这个有困难，可以把它想象成用一个标签来标识一个单词是名词、副词、动词、形容词还是其他。使用以下代码获取每个单词的标签:

函数 tags 返回一个 zip 对象，可以使用 list 函数对其进行解压缩。您应该会得到以下结果:

```
[('我', 'r'), ('喜欢', 'v'), ('看', 'v'), ('电影', 'n'), ('。', 'w')]
```

每个单词将与各自的标签配对。请参考下面的列表以了解更多关于某些标签的含义(这不是一个完整的列表，因为我在官方网站上找不到任何关于它的文档):

*   **r** :指代词，在句子中代替名词的词。
*   **v** :指动词，一个用来描述动作、状态或事件的词。
*   **n** :指名词，一个用来标识一类人、一类地方或一类事物的词。
*   **w** :指标点符号，书写时用来分隔句子及其成分并阐明意思的符号

## 拼音

还有一个函数可以得到每个字的拼音。但是，声调不包括在拼音中。获取拼音的示例如下:

您应该得到以下输出:

```
['wo', 'xi', 'huan', 'kan', 'dian', 'ying', '。']
```

## 繁体中文到简体中文

正如我前面提到的，这个模块是为简体中文设计的。如果您想处理繁体中文，请使用以下代码将文本转换为简体中文:

您应该得到以下输出"

```
'这家伙是坏人。'
```

## 分成句子

到目前为止，输入文本只包含一个句子。如果你使用一个段落作为输入，你应该在运行任何 API 调用之前把它分成句子块。为此，请键入以下命令:

检查是否得到以下输出:

```
['在茂密的大森林里',
 '一只饥饿的老虎逮住了一只狐狸',
 '老虎张开大嘴就要把狐狸吃掉',
 '“慢着”',
 '狐狸虽然很害怕但还是装出一副很神气的样子说',
 '“你知道我是谁吗',
 '我可是玉皇大帝派来管理百兽的兽王',
 '你要是吃了我',
 '玉皇大帝是决不会放过你的”']
```

## 关键词

还有一个从句子中识别关键词的选项。您可以传递一个整数参数，指示要从输入中获取的关键字的数量。我亲自测试了它，提取 5 个关键词，它对新闻文章和短篇故事非常有效。键入以下命令:

提取的关键词如下:

```
['狐狸', '大', '老虎', '大帝', '皇']
```

## 摘要

如果关键词不是你要找的，你可以试着用摘要从中提取*梗概*(重要句子)。该模块将把文本分成句子，并提取它认为是最重要的句子。与关键字类似，它接受一个整数作为参数来确定摘要的数量。如果你的文本中的句子少于输入，它将输出整个文本作为摘要。使用以下命令:

您应该得到以下输出:

```
['老虎张开大嘴就要把狐狸吃掉',
 '我可是玉皇大帝派来管理百兽的兽王',
 '玉皇大帝是决不会放过你的”',
 '一只饥饿的老虎逮住了一只狐狸',
 '你要是吃了我']
```

## 情感分析

本教程的重点是情感分析。然而，大多数时候，你需要做文本预处理，以减少输入文本的准确性。因此，您可以使用上面提到的其他 API 调用。让我们用一些示例文本来测试它:

检查是否得到以下结果(注释不是输出的一部分，它们是为了更容易查看而添加的):

```
0.7853504415636449 #这个产品很好用
0.5098208142944668 #这个产品不好用
0.13082804652201174 #这个产品是垃圾
0.5 #这个也太贵了吧
0.0954842128485538 #超级垃圾
0.04125325276132508 #是个垃圾中的垃圾
```

值输出范围从 0 到 1，其中 0 表示负面情绪，而 1 表示正面情绪。正如你所看到的，结果并不坏，考虑到大多数结果都是正确的，除了 0.5 这个应该是负面情绪的值。请注意，情绪是根据购买产品时的评论培养出来的。如果你在其他领域测试它，结果会非常糟糕。您可以查看以下文件，了解有关所用培训数据的更多信息:

1.  snownlp-master/snownlp/情操/neg.txt
2.  snownlp-master/snownlp/情操/pos.txt

You will notice that the word 贵 appeared about 600+ times in both *neg.txt* and *pos.txt*. This is the reason why the module output a neutral 0.5 value for the sentiment. In contrast, the word 垃圾 appeared 200+ times in *neg.txt* and only 35 times in *pos.txt*. To solve this issue, we can train our own model using custom text dataset. It will be explained in the next section.

# [第三节]培训模式

## 正在准备数据集

通过在两个文本文件夹中收集积极和消极的例句来准备你自己的数据集。我在 **snownlp-master** 文件夹中创建了它们，并将它们命名为 *custom_pos.txt* 和 *custom_neg.txt* 。每个例句用换行符隔开如下:

```
今天明明是周六，我就不想工作，
你看他，好意思吗？一直在偷懒
...
```

## 训练您的模型

准备好数据集后，让运行以下代码(相应地更改名称):

您应该会在 **snownlp-master** 文件夹中获得一个名为*custom _ invision . marshal . 3*的输出文件。不要对文件末尾的 **.3** 扩展名感到惊讶。要使用输出模型，您可以执行以下操作之一:

1.  修改 snownlp-master/snownlp/impression/_ _ init _ _ . py 中的代码，将数据路径改为新输出的 *marshal.3* 文件的目录。
2.  转到**snownlp-master/snownlp/sensation**文件夹。创建一个名为 backup 的新文件夹，将*perspective . marshal*和*perspective . marshal . 3*放入备份文件夹。从 snownlp-master 文件夹中复制*custom _ sensition . marshal . 3*放入**snownlp-master/snownlp/sensition**文件夹。改名为*情操.元帅. 3* 。

就个人而言，我更喜欢第二种方法，因为修改代码有时会有风险。请注意，您只需要 *.3* 文件。您可以通过重新初始化 SnowNLP 模块并运行以下代码来测试结果(用类似于您的训练数据的内容替换文本):

根据您的训练数据，输出结果会有一些差异。

## 分段和标签培训

除了情感，你还可以训练分段和标签。参考以下代码进行分段训练:

我们将对标签使用以下代码:

# [第四节]结论

本文演示了一种简单有效的方法，使用名为 SnowNLP 的 Python 模块对简体中文进行情感分析。在撰写本文时，官方文档在解释某些功能方面仍然缺乏质量。请随意阅读代码并探索它，以便更好地理解开发人员使用的技术。自然语言处理还有很多其他的模块，每一个都有自己的优缺点。请根据您的用例对它们进行评估，并在您的项目中使用它们。谢谢，祝你有美好的一天！

# 参考

1.  [https://github.com/isnowfy/snownlp](https://github.com/isnowfy/snownlp)