<html>
<head>
<title>Useful Plots to Diagnose your Neural Network</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">诊断神经网络的有用图表</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/useful-plots-to-diagnose-your-neural-network-521907fa2f45?source=collection_archive---------2-----------------------#2019-10-02">https://towardsdatascience.com/useful-plots-to-diagnose-your-neural-network-521907fa2f45?source=collection_archive---------2-----------------------#2019-10-02</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><p id="a249" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">训练神经网络不是一项容易的任务，有时会产生比预期好得多的结果，或者表现得差得多，产生的只是噪音。</p><figure class="km kn ko kp gt kq gh gi paragraph-image"><div role="button" tabindex="0" class="kr ks di kt bf ku"><div class="gh gi kl"><img src="../Images/776c733e4aa5f07dfd6447fd95408e9a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*QL_G2NiLuVtB5MkH"/></div></div><figcaption class="kx ky gj gh gi kz la bd b be z dk">Photo by <a class="ae lb" href="https://unsplash.com/@ninaz?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Nina Ž.</a> on <a class="ae lb" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><p id="2b78" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">让我们面对它…训练一个神经网络很难，如果你认为它很容易，那么很有可能你还没有完全理解深度学习。典型的深度学习模型由数百万个可学习的参数组成。分析他们中的每一个人在训练中如何变化，以及一个人如何影响其他人，是一项不可能完成的任务。</p><p id="88ed" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">幸运的是，我们有一定的数量可以观察训练的进展。这些措施让我们得以一窥黑箱，了解它们是如何变化的。</p></div><div class="ab cl lc ld hu le" role="separator"><span class="lf bw bk lg lh li"/><span class="lf bw bk lg lh li"/><span class="lf bw bk lg lh"/></div><div class="ij ik il im in"><p id="855e" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">随着每一次网络培训的开始，让我们从数据开始。</p><h2 id="44d2" class="lj lk iq bd ll lm ln dn lo lp lq dp lr jy ls lt lu kc lv lw lx kg ly lz ma mb bi translated">数据</h2><p id="d5c8" class="pw-post-body-paragraph jn jo iq jp b jq mc js jt ju md jw jx jy me ka kb kc mf ke kf kg mg ki kj kk ij bi translated">对于每一个机器学习模型，数据的重要性高于所有其他因素。我不能强调这一点…看看你的数据！！！。数据可能会解释为什么你在训练时会有问题。您的数据可能会让您了解为什么您的模型没有像预期的那样运行。让我解释一下。</p><p id="be5e" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">在训练分类模型之后，可能存在模型的输出完全或大部分属于一个类别的情况，即模型有偏差的情况。这主要是由于不平衡的数据集。</p><figure class="km kn ko kp gt kq"><div class="bz fp l di"><div class="mh mi l"/></div></figure><p id="7e44" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">人们可能面临的另一个问题是没有足够的数据来支持问题陈述。为了说明这一点，我来分享一个经历。几个月前(在我发表这篇文章的时候)，我的一个朋友请我帮个忙。他让我用很少的数据点重新生成一个图形，即训练一个神经网络作为函数逼近器。</p><p id="c9b9" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">光是看原图照片，就知道是指数曲线。但这还不够，因为他需要对情节进行推理。他需要精确的曲线。他设法给了我一些从图表中手动提取的数据点。当我训练网络并预测一个小域的值时，我得到的只是一条略微弯曲的线。我没想到会是这样的曲线。无论我做什么，图表都保持不变。</p><p id="09d3" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">当我将数据可视化时，我发现数据是不够的。网络仅仅理解它是一条指数曲线是不够的。</p><figure class="km kn ko kp gt kq"><div class="bz fp l di"><div class="mh mi l"/></div></figure><p id="15b5" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">这种情况在数据收集期间是一个严重的问题。我们可能认为我们得到了一切，但我们可能只收集了所需数据的一个子集。这可能不足以解决问题。想想吧…</p><h2 id="fee7" class="lj lk iq bd ll lm ln dn lo lp lq dp lr jy ls lt lu kc lv lw lx kg ly lz ma mb bi translated">损失曲线</h2><p id="a58f" class="pw-post-body-paragraph jn jo iq jp b jq mc js jt ju md jw jx jy me ka kb kc mf ke kf kg mg ki kj kk ij bi translated">调试神经网络最常用的图之一是训练期间的损失曲线。它为我们提供了训练过程和网络学习方向的快照。斯坦福大学的安德烈·卡帕西在这个<a class="ae lb" href="http://cs231n.github.io/neural-networks-3/" rel="noopener ugc nofollow" target="_blank">链接</a>上给出了一个令人惊叹的解释。这一节深受它的启发。</p><figure class="km kn ko kp gt kq gh gi paragraph-image"><div class="gh gi ml"><img src="../Images/eea61a134411bef819607fd4963c01b9.png" data-original-src="https://miro.medium.com/v2/resize:fit:918/format:webp/1*nM0iXoX5cWIROpbgWi4PQA.jpeg"/></div><figcaption class="kx ky gj gh gi kz la bd b be z dk">Effect of Learning rate on Loss (Source: <a class="ae lb" href="http://cs231n.github.io/assets/nn3/learningrates.jpeg" rel="noopener ugc nofollow" target="_blank">CS231n Convolutional Neural Networks for Visual Recognition</a>)</figcaption></figure><p id="99e3" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">这个图像很容易理解。您可以在两个时间段内记录您的损失:</p><ul class=""><li id="979a" class="mm mn iq jp b jq jr ju jv jy mo kc mp kg mq kk mr ms mt mu bi translated">在每个时代之后</li><li id="b8c3" class="mm mn iq jp b jq mv ju mw jy mx kc my kg mz kk mr ms mt mu bi translated">每次迭代后</li></ul><blockquote class="na nb nc"><p id="8111" class="jn jo nd jp b jq jr js jt ju jv jw jx ne jz ka kb nf kd ke kf ng kh ki kj kk ij bi translated">据说绘制跨时期的损失比迭代更理想。</p></blockquote><p id="7965" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">在一个历元期间，跨每个数据项计算损失函数，并且保证在给定的历元给出定量的损失度量。但是跨迭代绘制曲线仅给出整个数据集的子集的损失。</p><p id="95b9" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">通过绘制验证损失和训练损失图，可以获得更多的信息。</p><h2 id="2fb5" class="lj lk iq bd ll lm ln dn lo lp lq dp lr jy ls lt lu kc lv lw lx kg ly lz ma mb bi translated">精确度曲线</h2><p id="47d8" class="pw-post-body-paragraph jn jo iq jp b jq mc js jt ju md jw jx jy me ka kb kc mf ke kf kg mg ki kj kk ij bi translated">另一个最常用于理解神经网络进展的曲线是精度曲线。对于任何在深度学习方面有一些经验的人来说，使用准确度和损失曲线是显而易见的。</p><p id="0765" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">更重要的曲线是同时具有训练和验证准确性的曲线。</p><figure class="km kn ko kp gt kq gh gi paragraph-image"><div class="gh gi nh"><img src="../Images/9e8201421fd06137ba66c1ad9f05809d.png" data-original-src="https://miro.medium.com/v2/resize:fit:944/format:webp/1*0lDcZ7E872CDwrWCYkj9EQ.jpeg"/></div><figcaption class="kx ky gj gh gi kz la bd b be z dk">Accuracy Plot (Source: <a class="ae lb" href="http://cs231n.github.io/assets/nn3/accuracies.jpeg" rel="noopener ugc nofollow" target="_blank">CS231n Convolutional Neural Networks for Visual Recognition</a>)</figcaption></figure><blockquote class="na nb nc"><p id="0f91" class="jn jo nd jp b jq jr js jt ju jv jw jx ne jz ka kb nf kd ke kf ng kh ki kj kk ij bi translated">训练和验证准确性之间的差距是过度拟合的明显标志。间隙越大，过度拟合程度越高。</p></blockquote></div><div class="ab cl lc ld hu le" role="separator"><span class="lf bw bk lg lh li"/><span class="lf bw bk lg lh li"/><span class="lf bw bk lg lh"/></div><div class="ij ik il im in"><h2 id="4d2b" class="lj lk iq bd ll lm ln dn lo lp lq dp lr jy ls lt lu kc lv lw lx kg ly lz ma mb bi translated">不确定</h2><p id="b68d" class="pw-post-body-paragraph jn jo iq jp b jq mc js jt ju md jw jx jy me ka kb kc mf ke kf kg mg ki kj kk ij bi translated">另一个可能被削弱的量是<a class="ae lb" href="http://mlg.eng.cam.ac.uk/yarin/thesis/thesis.pdf" rel="noopener ugc nofollow" target="_blank">不确定性</a>。不确定性是一个有点高深的话题，但我建议每个人都应该理解这个概念。它更像是一个定量的衡量，而不是一个情节。不确定性有两种类型:</p><ul class=""><li id="a592" class="mm mn iq jp b jq jr ju jv jy mo kc mp kg mq kk mr ms mt mu bi translated">随机不确定性/数据不确定性</li><li id="0d52" class="mm mn iq jp b jq mv ju mw jy mx kc my kg mz kk mr ms mt mu bi translated">认知不确定性/模型不确定性</li></ul><p id="0d49" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">在本节中，我们将重点关注模型的不确定性。</p><p id="b5ba" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">模型不确定性是关于模型参数和模型结构的不确定性。两种神经网络架构可以具有不同的不确定性值。因此，我们得到了一个量化的方法来比较这些体系结构，并找到更好的一个。</p><p id="4e9f" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">在我个人看来，完全偏向准确性不是一个好的方法。</p><p id="aa33" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">在下面的例子中，我绘制了一个建筑的不确定性，这个建筑是在<a class="ae lb" href="https://www.kaggle.com/shanekonaung/boston-housing-price-dataset-with-keras" rel="noopener ugc nofollow" target="_blank">波士顿房价数据集</a>上训练出来的。模型的不确定性被记录在整个训练时期。</p><figure class="km kn ko kp gt kq"><div class="bz fp l di"><div class="mh mi l"/></div></figure><p id="e42f" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">模型的不确定性随着训练而降低……这是有道理的。我已经训练了 250 个时期的模型，只是为了向你们展示不确定性是如何变化的。</p></div><div class="ab cl lc ld hu le" role="separator"><span class="lf bw bk lg lh li"/><span class="lf bw bk lg lh li"/><span class="lf bw bk lg lh"/></div><div class="ij ik il im in"><h2 id="6a88" class="lj lk iq bd ll lm ln dn lo lp lq dp lr jy ls lt lu kc lv lw lx kg ly lz ma mb bi translated">结论</h2><p id="8ae0" class="pw-post-body-paragraph jn jo iq jp b jq mc js jt ju md jw jx jy me ka kb kc mf ke kf kg mg ki kj kk ij bi translated">当一个模型没有给出想要的结果时，试着去理解发生了什么。这些措施可以让我们一窥神经网络的训练。此外，可视化隐藏层输出(尤其是在卷积网络中)在很大程度上有所帮助。</p><p id="b12d" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">谢谢大家！！😁</p></div></div>    
</body>
</html>