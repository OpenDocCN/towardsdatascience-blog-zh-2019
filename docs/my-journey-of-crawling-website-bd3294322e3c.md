# 爬网站时我旅途中最好和最糟糕的时刻

> 原文：<https://towardsdatascience.com/my-journey-of-crawling-website-bd3294322e3c?source=collection_archive---------10----------------------->

## 一个成为数据科学家的个人分享

![](img/c91f2c233623c2cc4b411ff36a2cac19.png)

## 如何看待抓取或抓取网站？

许多人可能会将这项技能视为一种自动化工具，或者仅仅是一项通常被人们视为低端技能的技能。

对我来说，你可以把它看作一场战争，只是这场战争发生在互联网上。特别是当你在一个特定的网站上进行例行的网络爬行时，也许最初几次你能够获胜，你会庆祝*地狱耶这个网站很容易刮*，但你还没有意识到另一方面，也有人可以跟踪你的机器人的可疑活动，然后试图阻止你的机器人爬上网站。

很多时候，人们可能会忽略检索良好数据源的重要性，而是更加重视如何建立一个更准确的机器学习模型。有一个构建机器学习模型的首字母缩略词，叫 GIGO，是**“垃圾进，垃圾出”的缩写。**因此，重要的是要认识到，如果您能够检索到良好的数据源，再加上您已经具备出色的 EDA 和建模技能，您将能够构建更好的机器学习模型。

回到正题，我要和大家分享一下，我从抓取到抓取网站的历程。给你们一些我的背景，我毕业于新加坡南洋理工大学，拥有数学和经济学学位，不是来自技术背景，学习技术技能通常更难，但如果你努力工作，最终你会擅长它。

![](img/535938f74923b5413980de40c90f46f1.png)

**自动化刮削初体验**

它始于我在南洋理工大学统计研究所的一份兼职工作，当我还在大学学习时，我必须去每个网站，复制并粘贴每个页面到 excel 文件。基本上，我被要求从这个[网站](https://www.usnews.com/education/best-global-universities/rankings)获取所有与世界排名和各大学分数相关的信息。

兼职之后，眼睛总是感觉很累。这就是我开始刮网站的原因。没什么特别的，我只是用 Python 库 **Request** 抓取网站，用 **BeautifulSoup** 解析 HTML 内容。

结果很好，我对此非常感激。刮刀不仅可以保护我疲劳的眼睛，还可以提高我的工作效率。第一次做抓取，我发现用这两个 Python 包来抓取网站真的很容易。

如果你对这个刮刀感兴趣，可以访问我的 [github repo](https://github.com/M140042/web_crawler_usnews) 了解更多信息。

**数据科学项目的抓取经验**

![](img/56a61ae897cb425d94e370610e33de5c.png)

机器学习是我的兴趣。自从我在电通宙斯盾网络全球数据创新中心第一次实习以来，它就激发了我的兴趣。如果有机会见证数字营销中涉及机器学习的项目，我真的对它的力量印象深刻。所以，未来要成为一名数据科学家，我告诉自己要多做一些涉及机器学习的项目。

我决定做一个基于某些因素的租金价格预测的项目，例如，捷运和出租单元之间的距离，房间的大小，单元中浴室的数量等等。所以，我决定爬上[房地产](https://www.propertyguru.com.sg)大师网站，这是在新加坡寻找出租单位的最受欢迎的网站之一。

这个网站是一个动态网站，需要我建立一个互动的机器人，因此我选择 Python 包 Selenium 和 BeautifulSoup 来抓取网站。起初，我认为我似乎能够建立一个刮刀，并很容易地检索数据，但该网站实现了**完全自动化的公共图灵测试，以区分计算机和人类(验证码)。**

![](img/712e27e30b1a1e621b6fcbc63a04e1dd.png)

我意识到爬行并不容易。它涉及到对特定网站的深入了解，以便您能够检索数据。在花了很大的努力去理解被网站屏蔽的可能原因后，我想出了一个模仿人类行为的方法，最终它非常有效。

长话短说，然后我能够应用机器学习模型进行预测，在应用 EDA 创建多个功能后，结果似乎很好。如果我不能为我的机器学习模型获得准确和干净的数据，这将是不可能的。

**工作中爬行的经验**

毕业后，我在 Shopee 开始了我的第一份工作，担任商业智能职位。我负责每天搜集大约 12 万件商品，用于竞争对手的分析。这是我爬行技能真正大幅提高的地方。我的机器人又一次被**验证码**屏蔽了，这就是为什么我学习了一个新的 Python 爬行包，Scrapy。这绝对是一个伟大的爬行包。关于 Scrapy 和 Selenium 包的比较详情，请随时访问本网站:[https://hackernoon.com/scrapy-or-selenium-c3efa9df2c06](https://hackernoon.com/scrapy-or-selenium-c3efa9df2c06)

是的，我设法解决了这个问题，但这次我认为我学到了更多的东西，列举如下:

1.  维护过去数据的数据库，以便用于分析。
2.  建立一个仪表板来监控几个爬虫的性能，这样当问题发生时我就能尽快修改代码。
3.  关于如何绕过反抓取措施，或者创建更高效的爬虫的技巧，更多信息可以访问本网站:[https://towards data science . com/https-towards data science-com-5-tips-to-create-a-more-reliable-we B- crawler-3 efb 6878 F8 db](/https-towardsdatascience-com-5-tips-to-create-a-more-reliable-web-crawler-3efb6878f8db)
4.  检索敏感数据的技术，这可能需要您使用 POST 方法。

# 最终想法

我目前是一名数据科学家，我可以通知你的是，爬行仍然非常重要。我真的希望这篇文章能帮助和启发你解决一些在网页抓取中遇到困难的问题。

感谢你阅读这篇文章。欢迎在下面留下你感兴趣的话题的评论。我将在未来发布更多关于我的经历和项目的帖子。

# **关于作者**

[低伟鸿](https://www.linkedin.com/in/lowweihong/)是 Shopee 的数据科学家。他的经验更多地涉及抓取网站，创建数据管道，以及实施机器学习模型来解决业务问题。

他提供爬行服务，能够为你提供你所需要的准确和干净的数据。你可以访问 [**这个网站**](https://www.thedataknight.com/) 查看他的作品集，也可以联系他获取抓取服务。

你可以在 [LinkedIn](https://www.linkedin.com/in/lowweihong/) 和 [Medium](https://medium.com/@lowweihong) 上和他联系。