# ML 中的危险反馈循环

> 原文：<https://towardsdatascience.com/dangerous-feedback-loops-in-ml-e9394f2e8f43?source=collection_archive---------8----------------------->

## 机器学习模型如何改变社会行为

![](img/0df144d1e5a477a1e43afcd44f11b9ca.png)

Trefoil Knot, is an impossible knot with no known origin

昨天，一位刚刚加入我团队的数据科学家问了我一个问题。他的问题与我们公司的一个非常具体的问题有关，但答案的含义远不止于此。他问道:

> 生产中的当前模型决定了我们是否会根据一组给定的功能给销售线索回电。如果之前的模型确定某些特征表明我们不应该给销售线索打电话，那么这些特征现在与结果高度相关，因为我们只给那些销售线索回电。如果我想开发一个新的模型，这些特征会不会成为泄露的数据？

换句话说:如果我们用一组给定的特征训练一个模型，并且我们展示基于这些特征的行为，那么这些特征现在与结果相关，并且所有后续的模型将继续使用它们。

## 这里有一个简单的例子来说明这是如何工作的:

管道:

*   给定一组输入要素，返回销售线索转换的概率。
*   考虑到潜在客户转化的可能性，给客户回电。
*   如果我们有大量的销售线索，但只有少量的回电，我们该如何优化呢？

假设我们的模型有来自脸书、谷歌和必应的线索。如果我们的第一个模型决定来自这些给定来源的转换概率为 3%、5%和 1%，并且我们可以进行有限数量的回调，我们将只回调 5%的概率。现在快进两个月。第二个模型发现这些概率现在是:0.5%，8.5%，和 0%。发生了什么事？

因为我们开始只给谷歌潜在客户回电，我们增加了转化这些潜在客户的机会，同样，因为我们不再给脸书和必应潜在客户回电，**这些潜在客户从未转化过，因为我们从未给它们打过电话**。这是一个真实世界反馈循环的例子。

**这种反馈循环对一家公司来说很危险，但对一个社会来说可能更危险。**

在上面的例子中，反馈循环意味着我们因为历史转换率而放弃了脸书和必应的领先优势。这些潜在利率可能会改变，这意味着这些线索实际上可能会及时变得更好(例如，如果脸书在引导线索到正确的地方方面做得更好)。因为我们有一个强系数的模型，把权重往下拉，我们可能永远不会调用这些线索，即使给出一个变化，我们也会对它们有偏见。

在这种情况下，该模型不再基于来自源头的销售线索转化的实际潜在分布，而是基于来自源头的销售线索转化的*行为结果*(即召回来源)。

# 从更广泛的角度理解这一含义

这个反馈循环的著名案例是累犯模型。如果我们训练一个模型，根据一些特征(包括位置、性别、家庭成员入狱的概率和所犯罪行)预测一名囚犯最终是否会回到监狱，我们可能会发现我们的模型对某个种族和性别特别有偏见。这是为什么呢？

如果巴尔的摩的黑人男性更有可能因为肤色和性别而入狱，那么这个模型就会发现这一点。但是为什么他们更容易进监狱呢？是因为他们犯罪的潜在分布高于西雅图的白人女性，还是因为历史上(和目前)司法系统对这个群体更有偏见，并以更高的比率对他们采取行动？

对于大多数读者来说，这可能不会特别深刻，不是因为你不关心正义，而是因为你可能不会控制累犯模型。我要强调的另一个例子是雇佣模特。

假设我们在招聘模型中加入了性别因素。这里的招聘模型是预测一个雇员是否是公司的成功候选人的模型。假设我们正在为谷歌的软件开发人员建立一个招聘模型。我们发现绝大多数“成功”的软件开发人员恰好是男性。那么给定 1k 个候选人，难道不应该只挑男候选人吗？

这种模式可能会因为几个原因而有所偏差，例如，“成功”是由一些固有的更以男性为中心的指标选择的，女性在男性主导的世界中更难“成功”，或者许多其他原因。尽管如此，公司可以根据这种性别划分采取行动，并进一步创造这种划分。

也许今天，大多数公司都意识到了种族和性别不平等，并积极反对它。但也许隐藏在几层深处，它在银行贷款模型、保险价格模型和其他支配我们世界的模型中被遗漏了。