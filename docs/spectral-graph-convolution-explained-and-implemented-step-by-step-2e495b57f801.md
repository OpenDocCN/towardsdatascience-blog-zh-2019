# é€æ­¥è§£é‡Šå’Œå®ç°å…‰è°±å›¾å·ç§¯

> åŸæ–‡ï¼š<https://towardsdatascience.com/spectral-graph-convolution-explained-and-implemented-step-by-step-2e495b57f801?source=collection_archive---------2----------------------->

## ä½œä¸ºâ€œè®¡ç®—æœºè§†è§‰å›¾å½¢ç¥ç»ç½‘ç»œæ•™ç¨‹â€çš„ä¸€éƒ¨åˆ†

![](img/720f32881d9a92dfa56d14848d9d6701.png)

The Fourier basis (DFT matrix) on the left, in which each column or row is a basis vector, reshaped to 28Ã—28 (on the right), i.e. 20 basis vectors are shown on the right. The Fourier basis is used to compute spectral convolution is signal processing. In graphs, the Laplacian basis is used described in this post.

é¦–å…ˆï¼Œè®©æˆ‘ä»¬å›å¿†ä¸€ä¸‹ä»€ä¹ˆæ˜¯å›¾ã€‚å›¾ *G* æ˜¯ç”±æœ‰å‘/æ— å‘**è¾¹**è¿æ¥çš„ä¸€ç»„**èŠ‚ç‚¹**(é¡¶ç‚¹)ã€‚åœ¨è¿™ç¯‡æ–‡ç« ä¸­ï¼Œæˆ‘å°†å‡è®¾ä¸€ä¸ªæ— å‘å›¾ *G* æœ‰ *N* ä¸ªèŠ‚ç‚¹ã€‚è¯¥å›¾ä¸­çš„æ¯ä¸ª**èŠ‚ç‚¹**éƒ½æœ‰ä¸€ä¸ª *C* ç»´ç‰¹å¾å‘é‡ï¼Œæ‰€æœ‰èŠ‚ç‚¹çš„ç‰¹å¾éƒ½è¡¨ç¤ºä¸ºä¸€ä¸ª *N* Ã— *C* ç»´çŸ©é˜µ *Xâ½Ë¡â¾.å›¾çš„* **è¾¹**è¡¨ç¤ºä¸ºä¸€ä¸ª *N* Ã— *N* çŸ©é˜µ aï¼Œå…¶ä¸­æ¡ç›® A *áµ¢â±¼* è¡¨ç¤ºèŠ‚ç‚¹ *i* æ˜¯å¦è¿æ¥(T30 é‚»æ¥)åˆ°èŠ‚ç‚¹ *j* ã€‚è¿™ä¸ªçŸ©é˜µè¢«ç§°ä¸º*é‚»æ¥çŸ©é˜µ*ã€‚

![](img/9c7d132e1e5e715f1364be7afbb96d5e.png)

Two undirected graphs with N=5 and N=6 nodes. The order of nodes is arbitrary.

å›¾çš„è°±åˆ†æ(å‚è§è¯¾å ‚è®²ç¨¿[è¿™é‡Œ](http://www.cs.yale.edu/homes/spielman/561/)å’Œæ—©æœŸçš„å·¥ä½œ[è¿™é‡Œ](https://papers.nips.cc/paper/1961-laplacian-eigenmaps-and-spectral-techniques-for-embedding-and-clustering))å·²ç»å¯¹å›¾èšç±»ã€ç¤¾åŒºå‘ç°å’Œå…¶ä»–*ä¸»è¦æ˜¯æ— ç›‘ç£çš„*å­¦ä¹ ä»»åŠ¡æœ‰ç”¨ã€‚åœ¨è¿™ç¯‡æ–‡ç« ä¸­ï¼Œæˆ‘ä¸»è¦æè¿°äº†[å¸ƒé²çº³ç­‰äººï¼Œ2014ï¼ŒICLR 2014](https://arxiv.org/abs/1312.6203) çš„å·¥ä½œï¼Œä»–ä»¬å°†è°±åˆ†æä¸å·ç§¯ç¥ç»ç½‘ç»œ(ConvNets)ç›¸ç»“åˆï¼Œäº§ç”Ÿäº†è°±**å›¾å·ç§¯ç½‘ç»œ**ï¼Œå®ƒå¯ä»¥ä»¥*ç›‘ç£*çš„æ–¹å¼è¿›è¡Œè®­ç»ƒï¼Œä¾‹å¦‚ç”¨äºå›¾åˆ†ç±»ä»»åŠ¡ã€‚

å°½ç®¡*å…‰è°±*å›¾å½¢å·ç§¯ç›®å‰ä¸*ç©ºé—´*å›¾å½¢å·ç§¯æ–¹æ³•ç›¸æ¯”ä½¿ç”¨è¾ƒå°‘ï¼Œä½†äº†è§£å…‰è°±å·ç§¯çš„å·¥ä½œåŸç†ä»ç„¶æœ‰åŠ©äºç†è§£å’Œé¿å…å…¶ä»–æ–¹æ³•çš„æ½œåœ¨é—®é¢˜ã€‚æ­¤å¤–ï¼Œåœ¨ç»“è®ºä¸­ï¼Œæˆ‘æåˆ°äº†ä¸€äº›æœ€è¿‘ä»¤äººå…´å¥‹çš„å·¥ä½œï¼Œä½¿è°±å›¾å·ç§¯æ›´å…·ç«äº‰åŠ›ã€‚

# 1.æ‹‰æ™®æ‹‰æ–¯å›¾å’Œä¸€ç‚¹ç‰©ç†çŸ¥è¯†

è™½ç„¶â€œé¢‘è°±â€å¬èµ·æ¥å¯èƒ½å¾ˆå¤æ‚ï¼Œä½†å¯¹äºæˆ‘ä»¬çš„ç›®çš„æ¥è¯´ï¼Œç†è§£å®ƒä»…ä»…æ„å‘³ç€*å°†ä¿¡å·/éŸ³é¢‘/å›¾åƒ/å›¾å½¢åˆ†è§£ä¸ºç®€å•å…ƒç´ (å°æ³¢ã€graphlets)çš„ç»„åˆ(é€šå¸¸æ˜¯æ€»å’Œ)å°±è¶³å¤Ÿäº†ã€‚ä¸ºäº†ä½¿è¿™ç§*åˆ†è§£*å…·æœ‰ä¸€äº›å¥½çš„ç‰¹æ€§ï¼Œè¿™äº›ç®€å•å…ƒç´ é€šå¸¸æ˜¯*æ­£äº¤*ï¼Œå³ç›¸äº’çº¿æ€§ç‹¬ç«‹ï¼Œå› æ­¤å½¢æˆäº†*åŸº*ã€‚*

å½“æˆ‘ä»¬è°ˆè®ºä¿¡å·/å›¾åƒå¤„ç†ä¸­çš„â€œé¢‘è°±â€æ—¶ï¼Œæˆ‘ä»¬æŒ‡çš„æ˜¯[å‚…ç«‹å¶å˜æ¢](https://en.wikipedia.org/wiki/Discrete_Fourier_transform)ï¼Œå®ƒä¸ºæˆ‘ä»¬æä¾›äº†ä¸åŒé¢‘ç‡çš„åŸºæœ¬æ­£å¼¦å’Œä½™å¼¦æ³¢çš„ç‰¹å®š*åŸº* ( [DFT çŸ©é˜µ](https://en.wikipedia.org/wiki/DFT_matrix)ï¼Œä¾‹å¦‚ Python ä¸­çš„`scipy.linalg.dft`)ï¼Œå› æ­¤æˆ‘ä»¬å¯ä»¥å°†ä¿¡å·/å›¾åƒè¡¨ç¤ºä¸ºè¿™äº›æ³¢çš„æ€»å’Œã€‚ä½†æ˜¯å½“æˆ‘ä»¬è°ˆè®ºå›¾å’Œå›¾ç¥ç»ç½‘ç»œ(GNNs)æ—¶ï¼Œâ€œè°±â€æ„å‘³ç€å›¾æ‹‰æ™®æ‹‰æ–¯ [**çš„*æœ¬å¾åˆ†è§£***](https://en.wikipedia.org/wiki/Laplacian_matrix)***L .*ä½ å¯ä»¥æŠŠå›¾æ‹‰æ™®æ‹‰æ–¯ *L* æƒ³è±¡æˆä¸€ä¸ªä»¥ç‰¹æ®Šæ–¹å¼å½’ä¸€åŒ–çš„é‚»æ¥çŸ©é˜µ *A* ï¼Œè€Œ*æœ¬å¾åˆ†è§£*æ˜¯ä¸€ç§å¯»æ‰¾é‚£äº›åŸºæœ¬æ­£äº¤åˆ†é‡çš„æ–¹æ³•**

**ç›´è§‚åœ°è¯´ï¼Œæ‹‰æ™®æ‹‰æ–¯å›¾æ˜¾ç¤ºäº†å¦‚æœæˆ‘ä»¬åœ¨èŠ‚ç‚¹ *i* ä¸­æ”¾ç½®ä¸€äº›â€œåŠ¿â€,*å¦‚ä½•å¹³æ»‘åœ°*â€œèƒ½é‡â€å°†åœ¨å›¾ä¸­æ‰©æ•£ã€‚æ‹‰æ™®æ‹‰æ–¯åœ¨æ•°å­¦å’Œç‰©ç†ä¸­çš„ä¸€ä¸ªå…¸å‹ç”¨ä¾‹æ˜¯è§£å†³ä¿¡å·(æ³¢)å¦‚ä½•åœ¨åŠ¨æ€ç³»ç»Ÿä¸­ä¼ æ’­ã€‚å½“é‚»å±…ä¹‹é—´çš„å€¼æ²¡æœ‰çªç„¶å˜åŒ–æ—¶ï¼Œæ‰©æ•£æ˜¯å¹³æ»‘çš„ï¼Œå¦‚ä¸‹å›¾æ‰€ç¤ºã€‚**

**![](img/a4ce6366deb8298797206bdf72be89fe.png)**

**Diffusion of some signal (for example, it can be heat) in a regular grid graph computed based on the graph Laplacian ([source](https://en.wikipedia.org/wiki/Laplacian_matrix)). Basically, the only things required to compute these dynamics are the Laplacian and initial values in nodes (pixels), i.e. red and yellow pixels corresponding to high intensity (of heat).**

**åœ¨è¿™ç¯‡æ–‡ç« çš„å…¶ä½™éƒ¨åˆ†ï¼Œæˆ‘å°†å‡è®¾â€œ*å¯¹ç§°å½’ä¸€åŒ–æ‹‰æ™®æ‹‰æ–¯ç®—å­*â€ï¼Œå®ƒç»å¸¸ç”¨äºå›¾å½¢ç¥ç»ç½‘ç»œï¼Œå› ä¸ºå®ƒæ˜¯å½’ä¸€åŒ–çš„ï¼Œä»¥ä¾¿å½“ä½ å †å è®¸å¤šå›¾å½¢å±‚æ—¶ï¼ŒèŠ‚ç‚¹ç‰¹å¾ä»¥æ›´å¹³æ»‘çš„æ–¹å¼ä¼ æ’­ï¼Œè€Œä¸ä¼šå‡ºç°ç‰¹å¾å€¼æˆ–æ¢¯åº¦çš„çˆ†ç‚¸æˆ–æ¶ˆå¤±ã€‚å®ƒä»…åŸºäºå›¾çš„é‚»æ¥çŸ©é˜µ*å’Œ*çš„*è¿›è¡Œè®¡ç®—ï¼Œè¿™å¯ä»¥ç”¨å‡ è¡Œ Python ä»£ç å®Œæˆï¼Œå¦‚ä¸‹æ‰€ç¤º:***

```
**# Computing the graph Laplacian
# A is an adjacency matrix of some graph *G*** import numpy as npN = A.shape[0] **# number of nodes in a graph**
D = np.sum(A, 0) **# node degrees**
D_hat = np.diag((D + 1e-5)**(-0.5)) **# normalized node degrees**
L = np.identity(N) â€” np.dot(D_hat, A).dot(D_hat) **# Laplacian**
```

**è¿™é‡Œï¼Œæˆ‘ä»¬å‡è®¾ *A* æ˜¯å¯¹ç§°çš„ï¼Œå³ *A* = *A* áµ€ï¼Œå¹¶ä¸”æˆ‘ä»¬çš„å›¾æ˜¯æ— å‘å›¾ï¼Œå¦åˆ™èŠ‚ç‚¹åº¦ä¸æ˜¯æ˜ç¡®å®šä¹‰çš„ï¼Œå¹¶ä¸”å¿…é¡»åšå‡ºä¸€äº›å‡è®¾æ¥è®¡ç®—æ‹‰æ™®æ‹‰æ–¯ç®—å­ã€‚é‚»æ¥çŸ©é˜µ *A* çš„ä¸€ä¸ªæœ‰è¶£çš„æ€§è´¨æ˜¯ *Aâ¿* (çŸ©é˜µä¹˜ç§¯å– *n* æ¬¡)å…¬å¼€äº†èŠ‚ç‚¹ä¹‹é—´çš„ *n* è·³è¿æ¥(æ›´å¤šç»†èŠ‚è§[æ­¤å¤„](https://en.wikipedia.org/wiki/Adjacency_matrix#Matrix_powers))ã€‚**

**è®©æˆ‘ä»¬ç”Ÿæˆä¸‰ä¸ªå›¾ï¼Œå¹¶å¯è§†åŒ–å®ƒä»¬çš„é‚»æ¥çŸ©é˜µå’Œæ‹‰æ™®æ‹‰æ–¯ç®—å­ä»¥åŠå®ƒä»¬çš„èƒ½åŠ›ã€‚**

**![](img/660729a47c67add3ceec0192976f5d78.png)**

**Adjacency matrices, Laplacians and their powers for a random graph (left), â€œstar graphâ€ (middle) and â€œpath graphâ€ (right). I normalize AÂ² such that the sum in each row equals 1 to have a probabilistic interpretation of 2-hop connections. Notice that Laplacians and their powers are symmetric matrices, which makes eigen-decomposition easier as well as facilitates feature propagation in a deep graph network.**

**ä¾‹å¦‚ï¼Œæƒ³è±¡ä¸­é—´ä¸Šæ–¹çš„æ˜Ÿå›¾æ˜¯ç”±é‡‘å±åˆ¶æˆçš„ï¼Œè¿™æ ·å®ƒå¯ä»¥å¾ˆå¥½åœ°ä¼ çƒ­ã€‚ç„¶åï¼Œå¦‚æœæˆ‘ä»¬å¼€å§‹åŠ çƒ­èŠ‚ç‚¹ 0(æ·±è“è‰²)ï¼Œè¿™ç§çƒ­é‡å°†ä»¥æ‹‰æ™®æ‹‰æ–¯å®šä¹‰çš„æ–¹å¼ä¼ æ’­åˆ°å…¶ä»–èŠ‚ç‚¹ã€‚åœ¨æ‰€æœ‰è¾¹éƒ½ç›¸ç­‰çš„æ˜Ÿå½¢å›¾çš„ç‰¹æ®Šæƒ…å†µä¸‹ï¼Œçƒ­é‡å°†å‡åŒ€åœ°ä¼ æ’­åˆ°æ‰€æœ‰å…¶ä»–èŠ‚ç‚¹ï¼Œè¿™å¯¹äºå…¶ä»–å›¾æ¥è¯´æ˜¯ä¸æ­£ç¡®çš„ï¼Œå› ä¸ºå®ƒä»¬çš„ç»“æ„ã€‚**

**åœ¨è®¡ç®—æœºè§†è§‰å’Œæœºå™¨å­¦ä¹ çš„èƒŒæ™¯ä¸‹ï¼Œå›¾å½¢æ‹‰æ™®æ‹‰æ–¯å®šä¹‰äº†å¦‚æœæˆ‘ä»¬å †å å‡ ä¸ªå›¾å½¢ç¥ç»å±‚ï¼ŒèŠ‚ç‚¹ç‰¹å¾å°†å¦‚ä½•æ›´æ–°ã€‚ä¸æˆ‘çš„æ•™ç¨‹ çš„ç¬¬ä¸€éƒ¨åˆ† [*ç±»ä¼¼ï¼Œä¸ºäº†ä»è®¡ç®—æœºè§†è§‰çš„è§’åº¦ç†è§£å…‰è°±å›¾å·ç§¯ï¼Œæˆ‘å°†ä½¿ç”¨ MNIST æ•°æ®é›†ï¼Œå®ƒåœ¨ 28Ã—28 çš„è§„åˆ™ç½‘æ ¼å›¾ä¸Šå®šä¹‰å›¾åƒã€‚*](https://medium.com/p/3d9fada3b80d)**

**![](img/71a4ac2c82438a4a4793329058b2f455.png)**

**MNIST image defining features X (left), adjacency matrix A (middle) and the Laplacian (right) of a regular 28Ã—28 grid. The reason that the graph Laplacian looks like an identity matrix is that the graph has a relatively large number of nodes (784), so that after normalization values outside the diagonal become much smaller than 1.**

# **2.ç›˜æ—‹**

**åœ¨ä¿¡å·å¤„ç†ä¸­ï¼Œå¯ä»¥è¯æ˜ç©ºé—´åŸŸä¸­çš„å·ç§¯æ˜¯é¢‘åŸŸä¸­çš„ä¹˜æ³•(åˆç§°ä¸º[å·ç§¯å®šç†](https://en.wikipedia.org/wiki/Convolution_theorem))ã€‚åŒæ ·çš„å®šç†ä¹Ÿé€‚ç”¨äºå›¾å½¢ã€‚åœ¨ä¿¡å·å¤„ç†ä¸­ï¼Œä¸ºäº†å°†ä¿¡å·å˜æ¢åˆ°é¢‘åŸŸï¼Œæˆ‘ä»¬ä½¿ç”¨ç¦»æ•£å‚…é‡Œå¶å˜æ¢ï¼Œå®ƒåŸºæœ¬ä¸Šæ˜¯ä¿¡å·ä¸ç‰¹æ®ŠçŸ©é˜µ(åŸºï¼ŒDFT çŸ©é˜µ)çš„çŸ©é˜µä¹˜æ³•ã€‚è¿™ä¸ªåŸºç¡€å‡è®¾äº†ä¸€ä¸ª*è§„åˆ™çš„*ç½‘æ ¼ï¼Œæ‰€ä»¥æˆ‘ä»¬ä¸èƒ½æŠŠå®ƒç”¨äº*ä¸è§„åˆ™çš„*å›¾å½¢ï¼Œè¿™æ˜¯ä¸€ä¸ªå…¸å‹çš„æƒ…å†µã€‚è€Œæ˜¯ç”¨ä¸€ä¸ªæ›´ä¸€èˆ¬çš„åŸºï¼Œå°±æ˜¯å›¾æ‹‰æ™®æ‹‰æ–¯ *L* çš„ç‰¹å¾å‘é‡ *V* ï¼Œå¯ä»¥é€šè¿‡ç‰¹å¾åˆ†è§£æ‰¾åˆ°:*l*=*vÎ»váµ€*ï¼Œå…¶ä¸­*Î»*æ˜¯ *L.* çš„ç‰¹å¾å€¼**

****ä¸»æˆåˆ†åˆ†æ vs æ‹‰æ™®æ‹‰æ–¯å›¾çš„ç‰¹å¾åˆ†è§£ã€‚**åœ¨å®é™…è®¡ç®—è°±å›¾å·ç§¯æ—¶ï¼Œåªéœ€ä½¿ç”¨ä¸*æœ€å°*ç‰¹å¾å€¼å¯¹åº”çš„å‡ ä¸ªç‰¹å¾å‘é‡å°±è¶³å¤Ÿäº†ã€‚ä¹ä¸€çœ‹ï¼Œä¸è®¡ç®—æœºè§†è§‰ä¸­ç»å¸¸ä½¿ç”¨çš„[ä¸»æˆåˆ†åˆ†æ(PCA)](https://en.wikipedia.org/wiki/Principal_component_analysis) ç›¸æ¯”ï¼Œè¿™ä¼¼ä¹æ˜¯ä¸€ç§ç›¸åçš„ç­–ç•¥ï¼Œå…¶ä¸­æˆ‘ä»¬å¯¹*æœ€å¤§*ç‰¹å¾å€¼å¯¹åº”çš„ç‰¹å¾å‘é‡æ›´æ„Ÿå…´è¶£ã€‚ç„¶è€Œï¼Œè¿™ç§å·®å¼‚ä»…ä»…æ˜¯ç”±äºä¸Šé¢ç”¨äºè®¡ç®—æ‹‰æ™®æ‹‰æ–¯ç®—å­çš„*å¦å®š*ï¼Œå› æ­¤ä½¿ç”¨ PCA è®¡ç®—çš„ç‰¹å¾å€¼ä¸å›¾æ‹‰æ™®æ‹‰æ–¯ç®—å­çš„ç‰¹å¾å€¼*æˆåæ¯”*(å½¢å¼åˆ†æè§[æœ¬æ–‡](http://outobox.cs.umn.edu/PCA_on_a_Graph.pdf))ã€‚è¿˜è¦æ³¨æ„çš„æ˜¯ï¼ŒPCA åº”ç”¨äºæ•°æ®é›†çš„åæ–¹å·®çŸ©é˜µï¼Œç›®çš„æ˜¯æå–æœ€å¤§çš„å˜åŒ–å› ç´ ï¼Œå³æ•°æ®å˜åŒ–æœ€å¤§çš„ç»´åº¦ï¼Œå¦‚[ç‰¹å¾é¢](https://en.wikipedia.org/wiki/Eigenface)ã€‚è¿™ç§å˜åŒ–é€šè¿‡ç‰¹å¾å€¼æ¥æµ‹é‡ï¼Œå› æ­¤æœ€å°çš„ç‰¹å¾å€¼åŸºæœ¬ä¸Šå¯¹åº”äºå™ªå£°æˆ–â€œä¼ªâ€ç‰¹å¾ï¼Œè¿™äº›ç‰¹å¾åœ¨å®è·µä¸­è¢«è®¤ä¸ºæ˜¯æ— ç”¨çš„ç”šè‡³æ˜¯æœ‰å®³çš„ã€‚**

**![](img/b69fd997c5082cd38117afc6769534c8.png)**

**Eigenvalues (in a descending order) and corresponding eigenvectors for the MNIST dataset.**

**æ‹‰æ™®æ‹‰æ–¯å›¾çš„ç‰¹å¾åˆ†è§£åº”ç”¨äºå•ä¸ªå›¾ï¼Œç›®çš„æ˜¯æå–èŠ‚ç‚¹çš„å­å›¾æˆ–é›†ç¾¤(ç¤¾åŒº)ï¼Œå¹¶ä¸”[ç‰¹å¾å€¼å‘Šè¯‰æˆ‘ä»¬è®¸å¤šå…³äºå›¾è¿é€šæ€§çš„ä¿¡æ¯](http://blog.shriphani.com/2015/04/06/the-smallest-eigenvalues-of-a-graph-laplacian/)ã€‚æˆ‘å°†åœ¨ä¸‹é¢çš„ä¾‹å­ä¸­ä½¿ç”¨å¯¹åº”äº 20 ä¸ªæœ€å°ç‰¹å¾å€¼çš„ç‰¹å¾å‘é‡ï¼Œå‡è®¾ 20 è¿œå°äºèŠ‚ç‚¹æ•° *N(åœ¨ MNIST *)* çš„æƒ…å†µä¸‹ N* =784)ã€‚ä¸ºäº†æ‰¾åˆ°ä¸‹é¢å·¦è¾¹çš„ç‰¹å¾å€¼å’Œç‰¹å¾å‘é‡ï¼Œæˆ‘ä½¿ç”¨äº†ä¸€ä¸ª 28Ã—28 çš„è§„åˆ™å›¾ï¼Œè€Œåœ¨å³è¾¹ï¼Œæˆ‘éµå¾ª[å¸ƒé²çº³ç­‰äºº](https://arxiv.org/abs/1312.6203)çš„å®éªŒï¼Œé€šè¿‡åœ¨ 28Ã—28 çš„è§„åˆ™ç½‘æ ¼ä¸Šé‡‡æ · 400 ä¸ªéšæœºä½ç½®æ¥æ„å»ºä¸€ä¸ªä¸è§„åˆ™å›¾(æœ‰å…³è¯¥å®éªŒçš„æ›´å¤šç»†èŠ‚ï¼Œè¯·å‚è§ä»–ä»¬çš„è®ºæ–‡)ã€‚**

**![](img/33dbee17f8d768c2c94d1aa62f8ac9c0.png)**

**Eigenvalues *Î› (****bottom****) and e*igenvectors V (**top**) of the graph Laplacian L for a regular 28*Ã—*28 grid (**left**) and non-uniformly subsampled grid with 400 points according to experiments in [Bruna et al., 2014, ICLR 2014](https://arxiv.org/abs/1312.6203) (**right**). Eigenvectors corresponding to the 20 **smallest** **eigenvalues** are shown. Eigenvectors are 784 dimensional on the left and 400 dimensional on the right, so V is 784*Ã—20 and 400Ã—20 respectively.* Each of the 20 eigenvectors on the left was reshaped to 28*Ã—*28, whereas on the right to reshape a 400 dimensional eigenvector to 28*Ã—28, white pixels for missing nodes were added. So, e*ach pixel in each eigenvector corresponds to a node or a missing node (in white on the right). These eigenvectors can be viewed as a basis in which we decompose our graph.**

**æ‰€ä»¥ï¼Œç»™å®šå›¾çš„æ‹‰æ™®æ‹‰æ–¯ *L* ï¼ŒèŠ‚ç‚¹ç‰¹å¾ *X* å’Œæ»¤æ³¢å™¨ *W* _spectralï¼Œåœ¨ Python **å›¾ä¸Šè¿›è¡Œè°±å·ç§¯**çœ‹èµ·æ¥éå¸¸ç®€å•:**

```
**# Spectral convolution on graphs
# X is an *NÃ—1 matrix of 1-dimensional node features*** **# L** **is an** ***N******Ã—N* graph Laplacian computed above
# W_spectral are** ***N******Ã—******F weights (filters) that we want to train*** from scipy.sparse.linalg import eigsh **# assumes *L* to be symmetric***Î›**,V* = eigsh(L,k=20,which=â€™SMâ€™) **#** **eigen-decomposition (i.e. find *Î›******,V)***
X_hat = V.T.dot(X) **# *20*****Ã—*****1* node features in the "spectral" domain**
W_hat = V.T.dot(W_spectral)  **# 20Ã—*F* filters in the** **"spectral" domain**
Y = V.dot(X_hat * W_hat)  **# *N******Ã—******F* result of convolution**
```

**å½¢å¼ä¸Š:**

**![](img/d84facfea1cd1a9c42cd1a0dbf5a468b.png)**

**Spectral graph convolution, where âŠ™ means element-wise multiplication.**

**å…¶ä¸­ï¼Œæˆ‘ä»¬å‡è®¾æˆ‘ä»¬çš„èŠ‚ç‚¹ç‰¹å¾ *Xâ½Ë¡â¾* æ˜¯ä¸€ç»´çš„ï¼Œä¾‹å¦‚ m åƒç´ ï¼Œä½†æ˜¯å®ƒå¯ä»¥æ‰©å±•åˆ° *C* ç»´çš„æƒ…å†µ:æˆ‘ä»¬å°†åªéœ€è¦å¯¹æ¯ä¸ª*é€šé“*é‡å¤è¿™ä¸ªå·ç§¯ï¼Œç„¶ååƒåœ¨ä¿¡å·/å›¾åƒå·ç§¯ä¸­ä¸€æ ·å¯¹ *C* æ±‚å’Œã€‚**

**å…¬å¼(3)æœ¬è´¨ä¸Šä¸ä½¿ç”¨å‚…ç«‹å¶å˜æ¢çš„è§„åˆ™ç½‘æ ¼ä¸Šçš„[ä¿¡å·çš„é¢‘è°±å·ç§¯](https://en.wikipedia.org/wiki/Convolution_theorem)ç›¸åŒï¼Œå› æ­¤ä¸ºæœºå™¨å­¦ä¹ äº§ç”Ÿäº†ä¸€äº›é—®é¢˜:**

*   **å¯è®­ç»ƒæƒé‡(æ»¤æ³¢å™¨) *W_* è°±çš„ç»´æ•°å–å†³äºå›¾ä¸­èŠ‚ç‚¹ *N* çš„æ•°é‡ï¼›**
*   ***W_* è°±ä¹Ÿå–å†³äºå›¾ç»“æ„ä¸­ç¼–ç çš„ç‰¹å¾å‘é‡ *V.***

**è¿™äº›é—®é¢˜é˜»ç¢äº†æ‰©å±•åˆ°å…·æœ‰å¯å˜ç»“æ„çš„å¤§å‹å›¾å½¢çš„æ•°æ®é›†ã€‚ä¸‹æ–‡æ¦‚è¿°çš„è¿›ä¸€æ­¥åŠªåŠ›ä¾§é‡äºè§£å†³è¿™äº›å’Œå…¶ä»–é—®é¢˜ã€‚**

# ****3ã€‚è°±åŸŸä¸­çš„â€œå¹³æ»‘â€****

**![](img/ef1eb6ee0fdbca4b76e966f746d7657e.png)**

**Strawberry and banana smoothie (source: [joyfoodsunshine.com](https://joyfoodsunshine.com/strawberry-banana-smoothie/)). Smoothing in the spectral domain is a little bit different ğŸ˜ƒ.**

**[å¸ƒé²çº³ç­‰äºº](https://arxiv.org/abs/1312.6203)æ˜¯æœ€æ—©å°†è°±å›¾åˆ†æåº”ç”¨åˆ°*å­¦ä¹ å·ç§¯æ»¤æ³¢å™¨*æ¥è§£å†³å›¾åˆ†ç±»é—®é¢˜çš„äººä¹‹ä¸€ã€‚ä½¿ç”¨ä¸Šè¿°å…¬å¼(3)å­¦ä¹ çš„æ»¤æ³¢å™¨ä½œç”¨äº*æ•´ä¸ªå›¾*ï¼Œå³å®ƒä»¬å…·æœ‰*å…¨å±€æ”¯æŒ*ã€‚åœ¨è®¡ç®—æœºè§†è§‰ç¯å¢ƒä¸­ï¼Œè¿™å°†ä¸åœ¨ MNIST ä¸Šè®­ç»ƒ 28Ã—28 åƒç´ å¤§å°çš„å·ç§¯æ»¤æ³¢å™¨ç›¸åŒï¼Œå³æ»¤æ³¢å™¨å…·æœ‰ä¸è¾“å…¥ç›¸åŒçš„å¤§å°(æ³¨æ„ï¼Œæˆ‘ä»¬ä»å°†æ»‘åŠ¨æ»¤æ³¢å™¨ï¼Œä½†åœ¨é›¶å¡«å……å›¾åƒä¸Š)ã€‚è™½ç„¶å¯¹äº MNISTï¼Œæˆ‘ä»¬å®é™…ä¸Šå¯ä»¥è®­ç»ƒè¿™æ ·çš„è¿‡æ»¤å™¨ï¼Œä½†å¸¸è¯†å»ºè®®é¿å…è¿™æ ·åšï¼Œå› ä¸ºè¿™ä¼šä½¿è®­ç»ƒå˜å¾—æ›´åŠ å›°éš¾ï¼Œå› ä¸ºå‚æ•°æ•°é‡å¯èƒ½ä¼šæ¿€å¢ï¼Œå¹¶ä¸”éš¾ä»¥è®­ç»ƒå¯ä»¥æ•æ‰ä¸åŒå›¾åƒä¹‹é—´å…±äº«çš„æœ‰ç”¨ç‰¹å¾çš„å¤§å‹è¿‡æ»¤å™¨ã€‚**

**å®é™…ä¸Šï¼Œæˆ‘ä½¿ç”¨ PyTorch å’Œæ¥è‡ª GitHub çš„ä»£ç æˆåŠŸåœ°è®­ç»ƒäº†è¿™æ ·ä¸€ä¸ªæ¨¡å‹ã€‚æ‚¨åº”è¯¥ä½¿ç”¨`mnist_fc.py --model conv`æ¥è¿è¡Œå®ƒã€‚ç»è¿‡ 100 ä¸ªæ—¶æœŸçš„è®­ç»ƒåï¼Œè¿‡æ»¤å™¨çœ‹èµ·æ¥åƒæ•°å­—çš„æ··åˆç‰©:**

**![](img/35da0cbd0f3b3a69f5d8e26bc3189cb2.png)**

**Examples of filters with **global support** typically used in spectral convolution. In this case, these are 28Ã—28 filters learned using a ConvNet with a single convolutional layer followed by ReLU, 7Ã—7 MaxPooling and a fully-connected classification layer. To make it clear, the output of the convolutional layer is still 28Ã—28 due to zero-padding. Surprisingly, this net achieves 96.7% on MNIST. This can be explained by the simplicity of the dataset.**

**é‡ç”³ä¸€ä¸‹ï¼Œæˆ‘ä»¬é€šå¸¸å¸Œæœ›è®©è¿‡æ»¤å™¨æ›´å°ï¼Œæ›´å±€éƒ¨(è¿™å’Œæˆ‘ä¸‹é¢è¦æåˆ°çš„ä¸å®Œå…¨ä¸€æ ·)ã€‚**

**ä¸ºäº†æ›´å¥½åœ°å®ç°è¿™ä¸€ç‚¹ï¼Œä»–ä»¬å»ºè®®åœ¨å…‰è°±åŸŸä¸­å¹³æ»‘æ»¤å…‰å™¨ï¼Œæ ¹æ®å…‰è°±ç†è®ºï¼Œè¿™ä½¿å¾—æ»¤å…‰å™¨åœ¨ç©ºé—´åŸŸä¸­æ›´æ¥è¿‘ T2ã€‚å…¶æ€æƒ³æ˜¯ï¼Œæ‚¨å¯ä»¥å°†å…¬å¼(3)ä¸­çš„æ»¤æ³¢å™¨ *W_* é¢‘è°±è¡¨ç¤ºä¸ºğ¾é¢„å®šä¹‰å‡½æ•°(å¦‚æ ·æ¡å‡½æ•°)çš„å’Œï¼Œå¹¶ä¸”æˆ‘ä»¬å­¦ä¹ è¿™ä¸ªå’Œçš„ *K* ç³»æ•° *Î±* ï¼Œè€Œä¸æ˜¯å­¦ä¹  *W* çš„ *N* å€¼:**

**![](img/e4bc0d9cd74eadddfdd33be6cd0db3c0.png)**

**We can approximate our N dimensional filter*W_*spectral as a finite sum of *K* functions f, such as splines shown below. So, instead of learning N values of *W_*spectral, we can learn K coefficients (alpha) of those functions; it becomes efficient when K << N.**

**è™½ç„¶ *fk* çš„ç»´æ•°ç¡®å®å–å†³äºèŠ‚ç‚¹ *N* çš„æ•°é‡ï¼Œä½†æ˜¯è¿™äº›å‡½æ•°æ˜¯å›ºå®šçš„ï¼Œæ‰€ä»¥æˆ‘ä»¬ä¸å­¦ä¹ å®ƒä»¬ã€‚æˆ‘ä»¬å”¯ä¸€çŸ¥é“çš„æ˜¯ç³»æ•° *Î±* ï¼Œå› æ­¤ *W_* å…‰è°±ä¸å†ä¾èµ–äº *N* ã€‚æ•´æ´ï¼Œå¯¹ä¸å¯¹ï¼Ÿ**

**![](img/763b1810c52e0c662b90d0d4b8960b34.png)**

**The spline basis used to smooth filters in the frequency domain, thereby making them more local. Splines and other polynomial functions are useful, because we can represent filters as their sums.**

**ä¸ºäº†ä½¿æˆ‘ä»¬åœ¨å…¬å¼(4)ä¸­çš„è¿‘ä¼¼åˆç†ï¼Œæˆ‘ä»¬å¸Œæœ› *K* < < *N* å°†å¯è®­ç»ƒå‚æ•°çš„æ•°é‡ä» *N* å‡å°‘åˆ° *K* ï¼Œæ›´é‡è¦çš„æ˜¯ï¼Œä½¿å…¶ç‹¬ç«‹äº *N* ï¼Œè¿™æ ·æˆ‘ä»¬çš„ GNN å¯ä»¥æ¶ˆåŒ–ä»»ä½•å¤§å°çš„å›¾ã€‚æˆ‘ä»¬å¯ä»¥ä½¿ç”¨ä¸åŒçš„ç¢±åŸºæ¥è¿›è¡Œè¿™ç§â€œæ‰©å±•â€ï¼Œè¿™å–å†³äºæˆ‘ä»¬éœ€è¦å“ªäº›æ€§è´¨ã€‚ä¾‹å¦‚ï¼Œä¸Šé¢æ˜¾ç¤ºçš„ä¸‰æ¬¡æ ·æ¡å‡½æ•°è¢«è®¤ä¸ºæ˜¯éå¸¸å¹³æ»‘çš„å‡½æ•°(ä¹Ÿå°±æ˜¯è¯´ï¼Œä½ çœ‹ä¸åˆ°èŠ‚ç‚¹ï¼Œä¹Ÿå°±æ˜¯åˆ†æ®µæ ·æ¡å¤šé¡¹å¼çš„å„ä¸ªéƒ¨åˆ†ç›¸é‡çš„åœ°æ–¹)ã€‚æˆ‘åœ¨[çš„å¦ä¸€ç¯‡æ–‡ç« ](https://medium.com/@BorisAKnyazev/tutorial-on-graph-neural-networks-for-computer-vision-and-beyond-part-2-be6d71d70f49)ä¸­è®¨è®ºçš„åˆ‡æ¯”é›ªå¤«å¤šé¡¹å¼å…·æœ‰é€¼è¿‘å‡½æ•°ä¹‹é—´çš„æœ€å°ğ‘™âˆè·ç¦»ã€‚å‚…ç«‹å¶åŸºæ˜¯åœ¨å˜æ¢åä¿ç•™å¤§éƒ¨åˆ†ä¿¡å·èƒ½é‡çš„åŸºã€‚å¤§å¤šæ•°ç¢±åŸºæ˜¯æ­£äº¤çš„ï¼Œå› ä¸ºæœ‰å¯ä»¥ç›¸äº’è¡¨è¾¾çš„é¡¹æ˜¯å¤šä½™çš„ã€‚**

**æ³¨æ„ï¼Œæ»¤æ³¢å™¨ *W_* å…‰è°±ä»ç„¶ä¸è¾“å…¥ä¸€æ ·å¤§ï¼Œä½†æ˜¯å®ƒä»¬çš„*æœ‰æ•ˆå®½åº¦*å¾ˆå°ã€‚åœ¨ MNIST å›¾åƒçš„æƒ…å†µä¸‹ï¼Œæˆ‘ä»¬å°†æœ‰ 28Ã—28 ä¸ªæ»¤æ³¢å™¨ï¼Œå…¶ä¸­åªæœ‰ä¸€å°éƒ¨åˆ†å€¼çš„ç»å¯¹é‡å€¼å¤§äº 0ï¼Œå¹¶ä¸”æ‰€æœ‰è¿™äº›å€¼åº”è¯¥å½¼æ­¤é è¿‘ï¼Œå³æ»¤æ³¢å™¨å°†æ˜¯å±€éƒ¨çš„å¹¶ä¸”å®é™…ä¸Šå¾ˆå°ï¼Œå¦‚ä¸‹æ‰€ç¤º(å·¦èµ·ç¬¬äºŒä¸ª):**

**![](img/6683bec24e75ddda45bbf050b62d9308.png)**

**From left to right: (first) Input image. (second) Local filter with small effective width. Most values are very close to 0\. (third) The result of spectral graph convolution of the MNIST image of digit 7 and the filter. (fourth) The result of spectral convolution using the Fourier transform. These results indicate that spectral graph convolution is quite limited if applied to images, perhaps, due to the weak spatial structure of the Laplacian basis compared to the Fourier basis.**

**![](img/9c0e01ba4835f57dd52db150fdc87197.png)**

**Reconstruction of the MNIST image using the Fourier and graph Laplacian bases using only M components of V: Xâ€™=V V*áµ€X*. We can see that the bases compress different patterns in images (orientated edges in the Fourier case and global patterns in the Laplacian case). This makes results of convolutions illustrated above very different.**

**æ€»è€Œè¨€ä¹‹ï¼Œé¢‘è°±åŸŸä¸­çš„å¹³æ»‘å…è®¸[å¸ƒé²çº³ç­‰äºº](https://arxiv.org/abs/1312.6203)å­¦ä¹ æ›´å¤šçš„å±€éƒ¨æ»¤æ³¢å™¨ã€‚å…·æœ‰è¿™ç§è¿‡æ»¤å™¨çš„æ¨¡å‹å¯ä»¥å®ç°ä¸æ²¡æœ‰å¹³æ»‘çš„æ¨¡å‹(å³ï¼Œä½¿ç”¨æˆ‘ä»¬çš„å…¬å¼(3))ç±»ä¼¼çš„ç»“æœï¼Œä½†æ˜¯å…·æœ‰å°‘å¾—å¤šçš„å¯è®­ç»ƒå‚æ•°ï¼Œå› ä¸ºè¿‡æ»¤å™¨å¤§å°ç‹¬ç«‹äºè¾“å…¥å›¾è¡¨å¤§å°ï¼Œè¿™å¯¹äºå°†æ¨¡å‹ç¼©æ”¾åˆ°å…·æœ‰è¾ƒå¤§å›¾è¡¨çš„æ•°æ®é›†æ˜¯é‡è¦çš„ã€‚ç„¶è€Œï¼Œå­¦ä¹ æ»¤æ³¢å™¨ *W* _spectral ä»ç„¶ä¾èµ–äºç‰¹å¾å‘é‡ *V* ï¼Œè¿™ä½¿å¾—å°†è¯¥æ¨¡å‹åº”ç”¨äºå…·æœ‰å¯å˜å›¾ç»“æ„çš„æ•°æ®é›†å…·æœ‰æŒ‘æˆ˜æ€§ã€‚**

# **ç»“è®º**

**å°½ç®¡æœ€åˆçš„å…‰è°±å›¾å·ç§¯æ–¹æ³•å­˜åœ¨ç¼ºç‚¹ï¼Œä½†å®ƒå·²ç»å¾—åˆ°äº†å¾ˆå¤šå‘å±•ï¼Œå¹¶åœ¨ä¸€äº›åº”ç”¨ä¸­ä¿æŒäº†ç›¸å½“æœ‰ç«äº‰åŠ›çš„æ–¹æ³•ï¼Œå› ä¸ºå…‰è°±æ»¤æ³¢å™¨å¯ä»¥æ›´å¥½åœ°æ•æ‰å›¾ä¸­çš„å…¨å±€å¤æ‚æ¨¡å¼ï¼Œè€Œåƒ GCN ( [Kipf & Wellingï¼ŒICLRï¼Œ2017](https://arxiv.org/abs/1609.02907) )è¿™æ ·çš„å±€éƒ¨æ–¹æ³•é™¤éå †å åœ¨æ·±åº¦ç½‘ç»œä¸­ï¼Œå¦åˆ™æ— æ³•å®ç°ã€‚ä¾‹å¦‚ï¼Œ2019 å¹´çš„ä¸¤ç¯‡è®ºæ–‡ï¼Œåˆ†åˆ«æ˜¯[å»–ç­‰äºº](https://arxiv.org/abs/1901.01484)å…³äºâ€œLanczosNetâ€å’Œ[å¾ç­‰äºº](https://arxiv.org/abs/1904.07785)å…³äºâ€œå›¾å°æ³¢ç¥ç»ç½‘ç»œâ€ï¼Œè§£å†³äº†è°±å›¾å·ç§¯çš„ä¸€äº›ç¼ºç‚¹ï¼Œå¹¶åœ¨é¢„æµ‹åˆ†å­æ€§è´¨å’ŒèŠ‚ç‚¹åˆ†ç±»æ–¹é¢æ˜¾ç¤ºå‡ºå¾ˆå¥½çš„ç»“æœã€‚ [Levie ç­‰äººçš„å¦ä¸€é¡¹æœ‰è¶£çš„å·¥ä½œï¼Œ2018](https://arxiv.org/abs/1705.07664) å…³äºâ€œCayleyNetsâ€åœ¨èŠ‚ç‚¹åˆ†ç±»ã€çŸ©é˜µå®Œæˆ(æ¨èç³»ç»Ÿ)å’Œç¤¾åŒºæ£€æµ‹æ–¹é¢è¡¨ç°å¼ºåŠ²ã€‚å› æ­¤ï¼Œæ ¹æ®æ‚¨çš„åº”ç”¨å’ŒåŸºç¡€è®¾æ–½ï¼Œè°±å›¾å·ç§¯å¯èƒ½æ˜¯ä¸€ä¸ªä¸é”™çš„é€‰æ‹©ã€‚**

**åœ¨æˆ‘å…³äºè®¡ç®—æœºè§†è§‰å›¾å½¢ç¥ç»ç½‘ç»œçš„[æ•™ç¨‹çš„å¦ä¸€éƒ¨åˆ†](https://medium.com/@BorisAKnyazev/tutorial-on-graph-neural-networks-for-computer-vision-and-beyond-part-2-be6d71d70f49)ä¸­ï¼Œæˆ‘è§£é‡Šäº†ç”± [Defferrard ç­‰äºº](https://arxiv.org/abs/1606.09375)åœ¨ 2016 å¹´å¼•å…¥çš„åˆ‡æ¯”é›ªå¤«è°±å›¾å·ç§¯ï¼Œå®ƒä»ç„¶æ˜¯ä¸€ä¸ªéå¸¸å¼ºå¤§çš„åŸºçº¿ï¼Œå…·æœ‰ä¸€äº›å¾ˆå¥½çš„å±æ€§ï¼Œå¹¶ä¸”æ˜“äºå®ç°ï¼Œæ­£å¦‚æˆ‘ä½¿ç”¨ PyTorch æ¼”ç¤ºçš„é‚£æ ·ã€‚**

***é¸£è°¢:æœ¬æ•™ç¨‹çš„å¾ˆå¤§ä¸€éƒ¨åˆ†æ˜¯æˆ‘åœ¨ SRI International å®ä¹ æœŸé—´åœ¨* [*ç©†ç½•é»˜å¾·Â·é˜¿æ¢…å°”*](https://medium.com/u/6cf41cb2c546?source=post_page-----2e495b57f801--------------------------------) *(* [*ä¸»é¡µ*](https://mohamedramer.com/) *)å’Œæˆ‘çš„åšå£«å¯¼å¸ˆæ ¼æ‹‰æ±‰å§†Â·æ³°å‹’(* [*ä¸»é¡µ*](https://www.gwtaylor.ca/) *)çš„æŒ‡å¯¼ä¸‹ç¼–å†™çš„ã€‚æˆ‘ä¹Ÿæ„Ÿè°¢* [*å¡æ´›ç³Â·å¥¥å¤æ–¯å¡”*](https://www.linkedin.com/in/carolynaugusta/) *çš„æœ‰ç”¨åé¦ˆã€‚***

**åœ¨ [Github](https://github.com/bknyaz/) ã€ [LinkedIn](https://www.linkedin.com/in/boris-knyazev-39690948/) å’Œ [Twitter](https://twitter.com/BorisAKnyazev) ä¸Šæ‰¾æˆ‘ã€‚[æˆ‘çš„ä¸»é¡µ](https://bknyaz.github.io/)ã€‚**

**å¦‚æœä½ æƒ³åœ¨ä½ çš„è®ºæ–‡ä¸­å¼•ç”¨è¿™ç¯‡åšæ–‡ï¼Œè¯·ä½¿ç”¨:
[*@ misc*](http://twitter.com/misc)*{ Knyazev 2019 Tutorialï¼Œ
title = {ç”¨äºè®¡ç®—æœºè§†è§‰åŠè¶…è¶Šçš„å›¾å½¢ç¥ç»ç½‘ç»œæ•™ç¨‹}ï¼Œ
author={Knyazevï¼ŒBoris and Taylorï¼ŒGraham W and Amerï¼ŒMohamed R}ï¼Œ
year={2019}
}***