<html>
<head>
<title>Capitalism: the Enemy of Friendly AI</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">资本主义:友好人工智能的敌人</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/capitalism-the-enemy-of-friendly-ai-e6b3f40dbe08?source=collection_archive---------25-----------------------#2019-10-12">https://towardsdatascience.com/capitalism-the-enemy-of-friendly-ai-e6b3f40dbe08?source=collection_archive---------25-----------------------#2019-10-12</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="20d6" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">先发优势如何导致人类灭绝</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/b8793a007151d2f8c58878240aaf233e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*qY3SjWBHIMJwaoG70wc76Q.jpeg"/></div></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk">Photo by <a class="ae ky" href="https://unsplash.com/@sharonmccutcheon?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank">Sharon McCutcheon</a> on <a class="ae ky" href="https://unsplash.com/s/photos/money?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><p id="188e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们需要谈论我们的未来；具体来说，我们的未来受到高级人工智能(AI)的影响。在不久的将来，许多专家预计人类将创造出第一个人工通用智能(AGI):一个大致和人类一样聪明的人工智能。相对不久之后，一种人工超级智能(ASI:一种比任何人都聪明得多的人工智能)将很有可能出现。注意，人类统治这个星球是因为他们的智力超群；一个人工智能很可能接管，因为它的智能比我们的智能更高。一个人工智能并不默认我们的道德价值观，许多思想家，如已故的物理学家斯蒂芬·霍金，警告说创造一个人工智能可能会导致人类的灭绝。</p><h2 id="8bad" class="lv lw it bd lx ly lz dn ma mb mc dp md li me mf mg lm mh mi mj lq mk ml mm mn bi translated">什么是友军 AI？</h2><p id="a92e" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">让我们从定义友好的 AI 开始。人工智能研究者 Eliezer Yudkowsky 创造的一个术语，它指的是对人类有益而不是有害的人工智能。就像我们在引言中讨论的，一个 ASI 默认不分享我们的道德；友好的人工智能就是这样。友好的人工智能的重要性怎么强调都不为过，可以用一个名为回形针最大化器的思维实验来说明，这个实验首先由<a class="ae ky" href="https://en.wikipedia.org/wiki/Nick_Bostrom" rel="noopener ugc nofollow" target="_blank">尼克·博斯特罗姆</a>描述。这个思维实验描述了一个 AGI，它被赋予了一个看似天真的目标，即最大化其收藏中回形针的数量。</p><blockquote class="mt"><p id="701a" class="mu mv it bd mw mx my mz na nb nc lu dk translated">ASI 是如此的成功，以至于它最终把地球变成了纸夹制造工厂。</p></blockquote><p id="192e" class="pw-post-body-paragraph kz la it lb b lc nd ju le lf ne jx lh li nf lk ll lm ng lo lp lq nh ls lt lu im bi translated">为了更成功地优化回形针的数量，AGI 提高了自己的智能，以成为一个 ASI。然后，ASI 发明了制造越来越多回形针的新方法；它是如此的成功，以至于最终将地球变成了纸夹制造工厂。当然，作为副作用，人类灭绝了。这并不是说 ASI 讨厌我们；只是我们是由它可以为自己所用的材料制成的。</p><p id="f180" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">请注意，人类灭绝可能是 ASI 的许多目标的副作用，而不仅仅是最大化回形针的数量。人类灭绝甚至可能有助于 ASI 的目标。假设你给一个 ASI 设定了一个目标，那就是最大限度地减少你收件箱里的垃圾邮件数量。为了实现这一点，ASI 可以简单地消灭人类，因为这将保证你再也不会收到垃圾邮件。</p><h2 id="6236" class="lv lw it bd lx ly lz dn ma mb mc dp md li me mf mg lm mh mi mj lq mk ml mm mn bi translated">资本主义和这有什么关系？</h2><p id="343c" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">我希望回形针 maximizer 思想实验已经表明“友好”不是 ASI 的默认属性。这正是问题所在:构建一个人工智能是一个(巨大的)挑战，但是让它变得友好(一个友好的人工智能)<em class="ni">需要在</em>之上的一些挑战。关键在于，资本主义会奖励那些更快上市的公司:公司会赶在竞争对手推出产品之前将产品投放市场，因为它们明白第一是至关重要的。</p><blockquote class="mt"><p id="7c30" class="mu mv it bd mw mx my mz na nb nc lu dk translated">作为第一家创立 ASI 的公司，金钱回报将是难以置信的。</p></blockquote><p id="e13d" class="pw-post-body-paragraph kz la it lb b lc nd ju le lf ne jx lh li nf lk ll lm ng lo lp lq nh ls lt lu im bi translated">ASI 也将如此:公司已经在向 AI 投资数十亿美元，但在未来，总投资只会增长，特别是当创建 ASI 的可能性变得更加可行时。作为第一家创立 ASI 的公司，金钱回报将是难以置信的。一个人工智能可以比任何人做得更好、更快、更有价值的工作，其先发优势是难以形容的。现在记住我们讨论过的:友好的人工智能需要在人工智能之上的额外挑战。为了成为第一个创造 ASI 的公司，公司很可能不会考虑太多友好性，这就是灾难的开始。</p><h2 id="e187" class="lv lw it bd lx ly lz dn ma mb mc dp md li me mf mg lm mh mi mj lq mk ml mm mn bi translated">如何解决这个问题？</h2><p id="081d" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">关心友好人工智能的公司可能很容易被不关心的公司超越。但是如果我们拥有的第一个人工智能是友好的，那么我们在人类这一方拥有更高的智慧。这种友好的人工智能可能会帮助我们保护自己免受未来可能的 ASIs。因此，我们不应该把第一个 ASI 的创建留给公司。第一个 ASI 应该建在一个非盈利的研究中心，那里没有盈利的压力。这个研究中心必须足够大，才能真正赢得大公司的第一次 ASI 竞赛，所以它可能应该是由许多不同政府资助的跨国努力。让它成为一个多国的努力也将有助于美国航天局造福于全人类，而不仅仅是一个国家牺牲其他国家。你怎么想呢?</p></div></div>    
</body>
</html>