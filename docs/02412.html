<html>
<head>
<title>Data Augmentation library for text</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">文本数据扩充库</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/data-augmentation-library-for-text-9661736b13ff?source=collection_archive---------8-----------------------#2019-04-20">https://towardsdatascience.com/data-augmentation-library-for-text-9661736b13ff?source=collection_archive---------8-----------------------#2019-04-20</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><figure class="gl gn jo jp jq jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi jn"><img src="../Images/ac9504c49cec84c68d12dc7b9d112f17.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*bB6Grog7PMawSL5_"/></div></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk">Photo by <a class="ae kc" href="https://unsplash.com/@makcedward?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Edward Ma</a> on <a class="ae kc" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><p id="b7cc" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在前面的<a class="ae kc" rel="noopener" target="_blank" href="/data-augmentation-in-nlp-2801a34dfc28">故事</a>中，您了解了为 NLP 任务模型生成更多训练数据的不同方法。在这个故事中，我们将学习如何只用几行代码就能做到这一点。</p><blockquote class="lb lc ld"><p id="7478" class="kd ke le kf b kg kh ki kj kk kl km kn lf kp kq kr lg kt ku kv lh kx ky kz la ij bi translated">在自然语言处理领域，由于语言的高度复杂性，对文本进行扩充是非常困难的。不是每一个词我们都可以用其他词来代替，比如 a，an，the。另外，不是每个单词都有同义词。即使改变一个单词，上下文也会完全不同。另一方面，在计算机视觉领域生成增强图像相对容易。即使引入噪声或裁剪掉图像的一部分，模型仍然可以对图像进行分类。</p></blockquote><h1 id="e2ab" class="li lj iq bd lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf bi translated">nlpaug 简介</h1><p id="f9e3" class="pw-post-body-paragraph kd ke iq kf b kg mg ki kj kk mh km kn ko mi kq kr ks mj ku kv kw mk ky kz la ij bi translated">在计算机视觉项目中使用 imgaug 后，我在想我们是否可以有一个类似的库来生成合成数据。因此，我通过使用现有的库和预先训练的模型来重新实现那些研究论文。nlpaug 的基本要素包括:</p><ul class=""><li id="f0fe" class="ml mm iq kf b kg kh kk kl ko mn ks mo kw mp la mq mr ms mt bi translated">OCR 增强器、QWERTY 增强器和随机字符增强器</li><li id="c5a8" class="ml mm iq kf b kg my kk mz ko na ks nb kw nc la mq mr ms mt bi translated"><code class="fe mu mv mw mx b">Word</code> : WordNet 增强器、word2vec 增强器、GloVe 增强器、fasttext 增强器、BERT 增强器、随机单词字符</li><li id="7d61" class="ml mm iq kf b kg my kk mz ko na ks nb kw nc la mq mr ms mt bi translated"><code class="fe mu mv mw mx b">Flow</code>:序列增强器，有时是增强器</li></ul><p id="ee87" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">直观来看，<code class="fe mu mv mw mx b">Character Augmenters</code>和<code class="fe mu mv mw mx b">Word Augmenters</code>分别专注于字符级和单词级的操控。<code class="fe mu mv mw mx b">Flow</code>像管弦乐队一样控制增强流。您可以访问<a class="ae kc" href="https://github.com/makcedward/nlpaug" rel="noopener ugc nofollow" target="_blank"> github </a>获取库。</p><h1 id="14ff" class="li lj iq bd lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf bi translated">性格；角色；字母</h1><p id="302d" class="pw-post-body-paragraph kd ke iq kf b kg mg ki kj kk mh km kn ko mi kq kr ks mj ku kv kw mk ky kz la ij bi translated">在字符级别扩充数据。可能的场景包括图像到文本和聊天机器人。在从图像中识别文本的过程中，我们需要光学字符识别(OCR)模型来实现，但是 OCR 会引入一些错误，如识别“0”和“0”。在聊天机器人中，我们仍然会有打字错误，尽管大多数应用程序都有单词纠正功能。为了克服这个问题，你可以让你的模型在在线预测之前“看到”那些可能的结果。</p><h2 id="a76e" class="nd lj iq bd lk ne nf dn lo ng nh dp ls ko ni nj lw ks nk nl ma kw nm nn me no bi translated">光学字符识别</h2><p id="e4d8" class="pw-post-body-paragraph kd ke iq kf b kg mg ki kj kk mh km kn ko mi kq kr ks mj ku kv kw mk ky kz la ij bi translated">当处理 NLP 问题时，OCR 结果可能是您的 NLP 问题的输入之一。例如，“0”可能被识别为“O”或“O”。如果你正在使用<a class="ae kc" rel="noopener" target="_blank" href="/3-basic-approaches-in-bag-of-words-which-are-better-than-word-embeddings-c2cbc7398016">单词袋</a>或经典<a class="ae kc" rel="noopener" target="_blank" href="/3-silver-bullets-of-word-embedding-in-nlp-10fa8f50cc5a">单词嵌入</a>作为一个特征，你将会遇到麻烦，因为你周围的词汇(OOV)现在和将来都是如此。如果你使用最先进的模型，比如伯特<a class="ae kc" rel="noopener" target="_blank" href="/how-bert-leverage-attention-mechanism-and-transformer-to-learn-word-contextual-relations-5bbee1b6dbdb">和 GPT</a>和<a class="ae kc" rel="noopener" target="_blank" href="/combining-supervised-learning-and-unsupervised-learning-to-improve-word-vectors-d4dea84ec36b">的话，OOV 问题似乎就解决了，因为 word 将被拆分成子 word。然而，一些信息丢失了。</a></p><p id="5b77" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><code class="fe mu mv mw mx b">OCRAug</code>旨在模拟 OCR 错误。它会用预定义的映射表替换目标字符。</p><figure class="nq nr ns nt gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi np"><img src="../Images/b709b001072bcda2afdc1fbc26b00a13.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*AtOdNjJfnqHhQalPDDCSug.png"/></div></div></figure><p id="ea8d" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">增强的例子</p><pre class="nq nr ns nt gt nu mx nv nw aw nx bi"><span id="c342" class="nd lj iq mx b gy ny nz l oa ob">Original:<br/>The quick brown fox jumps over the lazy dog<br/>Augmented Text:<br/>The quick brown fox jumps over the lazy <strong class="mx ir">d0g</strong></span></pre><h2 id="c6d4" class="nd lj iq bd lk ne nf dn lo ng nh dp ls ko ni nj lw ks nk nl ma kw nm nn me no bi translated">QWERTY 键盘</h2><p id="5096" class="pw-post-body-paragraph kd ke iq kf b kg mg ki kj kk mh km kn ko mi kq kr ks mj ku kv kw mk ky kz la ij bi translated">你可能参与的另一个项目是聊天机器人或其他信息渠道，如电子邮件。虽然拼写检查将被执行，但一些拼写错误仍然存在。可能会伤害到你之前提到的 NLP 模型。</p><p id="2ddb" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><code class="fe mu mv mw mx b">QWERTYAug</code>旨在模拟关键字距离误差。它会将目标字符替换为 1 个关键字距离。您可以配置是否包括数字或特殊字符。</p><figure class="nq nr ns nt gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi oc"><img src="../Images/898b14315c7fd7275538fcc5e34285d3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*d1wuTwI5lv4p1Q-MRHUVHg.png"/></div></div></figure><p id="ffba" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">增强的例子</p><pre class="nq nr ns nt gt nu mx nv nw aw nx bi"><span id="5492" class="nd lj iq mx b gy ny nz l oa ob">Original:<br/>The quick brown fox jumps over the lazy dog<br/>Augmented Text:<br/><strong class="mx ir">Tne 2uick hrown Gox jumpQ ovdr tNe &lt;azy d8g</strong></span></pre><h2 id="916c" class="nd lj iq bd lk ne nf dn lo ng nh dp ls ko ni nj lw ks nk nl ma kw nm nn me no bi translated">随机字符</h2><p id="9bed" class="pw-post-body-paragraph kd ke iq kf b kg mg ki kj kk mh km kn ko mi kq kr ks mj ku kv kw mk ky kz la ij bi translated">根据不同的研究，噪声注入有时可能有助于推广您的 NLP 模型。我们可能会在您的单词中添加一些干扰，例如从您的单词中添加或删除一个字符。</p><p id="16ba" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><code class="fe mu mv mw mx b">RandomCharAug</code>旨在给你的数据注入噪音。与<code class="fe mu mv mw mx b">OCRAug</code>和<code class="fe mu mv mw mx b">QWERTYAug</code>不同，它支持插入、替换和插入。</p><p id="a50a" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">插入增强的例子</p><pre class="nq nr ns nt gt nu mx nv nw aw nx bi"><span id="b54c" class="nd lj iq mx b gy ny nz l oa ob">Original:<br/>The quick brown fox jumps over the lazy dog<br/>Augmented Text:<br/><strong class="mx ir">T(he quicdk browTn Ffox jumpvs 7over kthe clazy 9dog</strong></span></pre><h1 id="7ef6" class="li lj iq bd lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf bi translated">单词</h1><p id="75ae" class="pw-post-body-paragraph kd ke iq kf b kg mg ki kj kk mh km kn ko mi kq kr ks mj ku kv kw mk ky kz la ij bi translated">除了字符增强，单词水平也很重要。我们利用 word2vec (Mikolov 等人，2013)、GloVe (Pennington 等人，2014)、fasttext (Joulin 等人，2016)、BERT(Devlin 等人，2018)和 wordnet 来插入和替换相似的单词。<code class="fe mu mv mw mx b">Word2vecAug</code>、<code class="fe mu mv mw mx b">GloVeAug</code>和<code class="fe mu mv mw mx b">FasttextAug</code>使用单词嵌入来寻找最相似的一组单词来替换原来的单词。另一方面，<code class="fe mu mv mw mx b">BertAug</code>利用语言模型预测可能的目标词。<code class="fe mu mv mw mx b">WordNetAug</code>用统计的方式找到一组相似的单词。</p><h2 id="d3ac" class="nd lj iq bd lk ne nf dn lo ng nh dp ls ko ni nj lw ks nk nl ma kw nm nn me no bi translated">单词嵌入(word2vec、GloVe、fasttext)</h2><p id="c917" class="pw-post-body-paragraph kd ke iq kf b kg mg ki kj kk mh km kn ko mi kq kr ks mj ku kv kw mk ky kz la ij bi translated">经典的嵌入使用静态向量来表示单词。理想情况下，如果向量彼此靠近，这个词的意思是相似的。其实要看训练数据。比如<a class="ae kc" rel="noopener" target="_blank" href="/3-silver-bullets-of-word-embedding-in-nlp-10fa8f50cc5a"> word2vec </a>中的“兔子”类似于“狐狸”，而<a class="ae kc" rel="noopener" target="_blank" href="/3-silver-bullets-of-word-embedding-in-nlp-10fa8f50cc5a"> GloVe </a>中的“nbc”类似于“狐狸”。</p><figure class="nq nr ns nt gt jr gh gi paragraph-image"><div class="gh gi od"><img src="../Images/e2f20ac4a5343d5761fbec6f47933586.png" data-original-src="https://miro.medium.com/v2/resize:fit:1048/format:webp/1*eatzgOd9njd6mv8pwXZ9LA.png"/></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk">Most similar words of “fox” among classical word embeddings models</figcaption></figure><p id="06c6" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">有时，您希望用相似的单词替换单词，以便 NLP 模型不依赖于单个单词。<code class="fe mu mv mw mx b">Word2vecAug</code>、<code class="fe mu mv mw mx b">GloVeAug</code>和<code class="fe mu mv mw mx b">FasttextAug</code>被设计成基于预先训练的向量来提供“相似”的单词。</p><p id="44e6" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">除了替换之外，插入还有助于在数据中加入噪声。它从词汇中随机挑选单词。</p><p id="13f5" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">插入增强的例子</p><pre class="nq nr ns nt gt nu mx nv nw aw nx bi"><span id="a6d6" class="nd lj iq mx b gy ny nz l oa ob">Original:<br/>The quick brown fox jumps over the lazy dog<br/>Augmented Text:<br/>The quick <strong class="mx ir">Bergen-Belsen</strong> brown fox jumps over <strong class="mx ir">Tiko</strong> the lazy dog</span></pre><p id="a2cc" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">替代增强示例</p><pre class="nq nr ns nt gt nu mx nv nw aw nx bi"><span id="c61a" class="nd lj iq mx b gy ny nz l oa ob">Original:<br/>The quick brown fox jumps over the lazy dog<br/>Augmented Text:<br/>The quick <strong class="mx ir">gray</strong> fox jumps over to lazy dog</span></pre><h2 id="bb46" class="nd lj iq bd lk ne nf dn lo ng nh dp ls ko ni nj lw ks nk nl ma kw nm nn me no bi translated">语境化的单词嵌入</h2><p id="f5a5" class="pw-post-body-paragraph kd ke iq kf b kg mg ki kj kk mh km kn ko mi kq kr ks mj ku kv kw mk ky kz la ij bi translated">因为经典的单词嵌入使用静态向量来表示同一个单词。它可能不适合某些场景。因为“福克斯”可以代表动物和广播公司。为了解决这个问题，引入了上下文化单词嵌入来考虑周围的单词，以生成不同上下文下的向量。</p><p id="12d5" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><code class="fe mu mv mw mx b">BertAug</code>旨在提供此功能来执行插入和替换。与以前的单词嵌入不同，插入是由<a class="ae kc" rel="noopener" target="_blank" href="/how-bert-leverage-attention-mechanism-and-transformer-to-learn-word-contextual-relations-5bbee1b6dbdb"> BERT </a>语言模型预测的，而不是随机选取一个单词。替换使用周围的单词作为特征来预测目标单词。</p><p id="adf4" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">插入增强的例子</p><pre class="nq nr ns nt gt nu mx nv nw aw nx bi"><span id="efe3" class="nd lj iq mx b gy ny nz l oa ob">Original:<br/>The quick brown fox jumps over the lazy dog<br/>Augmented Text:<br/>the <strong class="mx ir">lazy</strong> quick brown fox <strong class="mx ir">always</strong> jumps over the lazy dog</span></pre><p id="a11c" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">替代增强示例</p><pre class="nq nr ns nt gt nu mx nv nw aw nx bi"><span id="94e3" class="nd lj iq mx b gy ny nz l oa ob">Original:<br/>The quick brown fox jumps over the lazy dog<br/>Augmented Text:<br/>the quick <strong class="mx ir">thinking</strong> fox jumps over the lazy dog</span></pre><h1 id="4584" class="li lj iq bd lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf bi translated">同义词</h1><p id="5ebc" class="pw-post-body-paragraph kd ke iq kf b kg mg ki kj kk mh km kn ko mi kq kr ks mj ku kv kw mk ky kz la ij bi translated">除了神经网络方法之外，同义词库也可以达到类似的目的。同义词的局限性在于有些词可能没有相似的词。来自一个很棒的 NLTK 库的 WordNet 帮助找到同义词。</p><p id="6483" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><code class="fe mu mv mw mx b">WordNetAug</code>提供了替换功能来替换目标单词。不是纯粹地寻找同义词，一些初步的检查确保目标单词可以被替换。这些规则是:</p><ul class=""><li id="633e" class="ml mm iq kf b kg kh kk kl ko mn ks mo kw mp la mq mr ms mt bi translated">不要选择限定词(例如，a、an、the)</li><li id="7b18" class="ml mm iq kf b kg my kk mz ko na ks nb kw nc la mq mr ms mt bi translated">不要选择没有同义词的词。</li></ul><p id="6880" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">增强的例子</p><pre class="nq nr ns nt gt nu mx nv nw aw nx bi"><span id="01a7" class="nd lj iq mx b gy ny nz l oa ob">Original:<br/>The quick brown fox jumps over the lazy dog<br/>Augmented Text:<br/>The quick brown fox parachute over the lazy blackguard</span></pre><h2 id="c06b" class="nd lj iq bd lk ne nf dn lo ng nh dp ls ko ni nj lw ks nk nl ma kw nm nn me no bi translated">随机词</h2><p id="01dd" class="pw-post-body-paragraph kd ke iq kf b kg mg ki kj kk mh km kn ko mi kq kr ks mj ku kv kw mk ky kz la ij bi translated">到目前为止，我们没有在单词级引入删除。<code class="fe mu mv mw mx b">RandomWordAug</code>可以帮助随机删除一个单词。</p><p id="084e" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">增强的例子</p><pre class="nq nr ns nt gt nu mx nv nw aw nx bi"><span id="a7e2" class="nd lj iq mx b gy ny nz l oa ob">Original:<br/>The quick brown fox jumps over the lazy dog<br/>Augmented Text:<br/>The fox jumps over the lazy dog</span></pre><h1 id="63a5" class="li lj iq bd lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf bi translated">流动</h1><p id="7a0d" class="pw-post-body-paragraph kd ke iq kf b kg mg ki kj kk mh km kn ko mi kq kr ks mj ku kv kw mk ky kz la ij bi translated">到此为止，上述增强器都可以单独调用。如果你想把多个增强器组合在一起呢？为了使用多个增强器，有时会引入<strong class="kf ir"><em class="le"/></strong><strong class="kf ir"><em class="le">管道来连接增强器。一个文本可以通过不同的增强器产生不同的数据。</em></strong></p><h2 id="140d" class="nd lj iq bd lk ne nf dn lo ng nh dp ls ko ni nj lw ks nk nl ma kw nm nn me no bi translated"><strong class="ak"> <em class="oe">时序</em> </strong></h2><p id="2ab3" class="pw-post-body-paragraph kd ke iq kf b kg mg ki kj kk mh km kn ko mi kq kr ks mj ku kv kw mk ky kz la ij bi translated">您可以向该流程添加任意数量的增强器，然后<code class="fe mu mv mw mx b">Sequential</code>逐个执行它们。例如，你可以将<code class="fe mu mv mw mx b">RandomCharAug</code>和<code class="fe mu mv mw mx b">RandomWordAug</code>组合在一起。</p><figure class="nq nr ns nt gt jr"><div class="bz fp l di"><div class="of og l"/></div></figure><h2 id="319d" class="nd lj iq bd lk ne nf dn lo ng nh dp ls ko ni nj lw ks nk nl ma kw nm nn me no bi translated"><strong class="ak"> <em class="oe">有时</em> </strong></h2><p id="7625" class="pw-post-body-paragraph kd ke iq kf b kg mg ki kj kk mh km kn ko mi kq kr ks mj ku kv kw mk ky kz la ij bi translated">如果您不想一直执行同一组增强器，<code class="fe mu mv mw mx b">sometimes</code>每次都会选择一些增强器。</p><figure class="nq nr ns nt gt jr"><div class="bz fp l di"><div class="of og l"/></div></figure><h1 id="2266" class="li lj iq bd lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf bi translated">建议</h1><p id="74e7" class="pw-post-body-paragraph kd ke iq kf b kg mg ki kj kk mh km kn ko mi kq kr ks mj ku kv kw mk ky kz la ij bi translated">上述方法旨在解决作者在他们的问题中所面临的问题。如果你了解你的数据，你应该量身定做增强方法。请记住，数据科学的黄金法则是垃圾进垃圾出。</p><p id="857b" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">一般来说，您可以在不完全理解数据的情况下尝试同义词库方法。由于上述同义词库方法的限制，它可能不会提高很多。</p><h1 id="b204" class="li lj iq bd lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf bi translated">关于我</h1><p id="49f6" class="pw-post-body-paragraph kd ke iq kf b kg mg ki kj kk mh km kn ko mi kq kr ks mj ku kv kw mk ky kz la ij bi translated">我是湾区的数据科学家。专注于数据科学、人工智能，尤其是 NLP 和平台相关领域的最新发展。欢迎在<a class="ae kc" href="https://www.linkedin.com/in/edwardma1026" rel="noopener ugc nofollow" target="_blank"> LinkedIn </a>上与<a class="ae kc" href="https://makcedward.github.io/" rel="noopener ugc nofollow" target="_blank"> me </a>联系，或者在<a class="ae kc" href="http://medium.com/@makcedward/" rel="noopener"> Medium </a>或<a class="ae kc" href="https://github.com/makcedward" rel="noopener ugc nofollow" target="_blank"> Github </a>上关注我。</p><h1 id="be7f" class="li lj iq bd lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf bi translated">延伸阅读</h1><ul class=""><li id="8a14" class="ml mm iq kf b kg mg kk mh ko oh ks oi kw oj la mq mr ms mt bi translated">图像增强库(<a class="ae kc" href="https://github.com/aleju/imgaug" rel="noopener ugc nofollow" target="_blank"> imgaug </a>)</li><li id="73d5" class="ml mm iq kf b kg my kk mz ko na ks nb kw nc la mq mr ms mt bi translated">文本增强库(<a class="ae kc" href="https://github.com/makcedward/nlpaug" rel="noopener ugc nofollow" target="_blank"> nlpaug </a>)</li><li id="b7df" class="ml mm iq kf b kg my kk mz ko na ks nb kw nc la mq mr ms mt bi translated"><a class="ae kc" rel="noopener" target="_blank" href="/data-augmentation-in-nlp-2801a34dfc28">NLP 中的数据扩充</a></li><li id="4780" class="ml mm iq kf b kg my kk mz ko na ks nb kw nc la mq mr ms mt bi translated"><a class="ae kc" rel="noopener" target="_blank" href="/data-augmentation-for-audio-76912b01fdf6">音频数据增强</a></li><li id="d042" class="ml mm iq kf b kg my kk mz ko na ks nb kw nc la mq mr ms mt bi translated"><a class="ae kc" rel="noopener" target="_blank" href="/data-augmentation-for-speech-recognition-e7c607482e78">声谱图数据增强</a></li><li id="f871" class="ml mm iq kf b kg my kk mz ko na ks nb kw nc la mq mr ms mt bi translated">你的自然语言处理模型能够防止恶意攻击吗？</li><li id="375c" class="ml mm iq kf b kg my kk mz ko na ks nb kw nc la mq mr ms mt bi translated"><a class="ae kc" href="https://neptune.ai/blog/data-augmentation-nlp" rel="noopener ugc nofollow" target="_blank">NLP 中的数据扩充:来自 Kaggle Master 的最佳实践</a></li></ul><h1 id="191e" class="li lj iq bd lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf bi translated">参考</h1><ul class=""><li id="b4b3" class="ml mm iq kf b kg mg kk mh ko oh ks oi kw oj la mq mr ms mt bi translated">X.张、赵军、李乐存。<a class="ae kc" href="https://arxiv.org/pdf/1509.01626.pdf" rel="noopener ugc nofollow" target="_blank">用于文本分类的字符级卷积网络</a>。2015</li><li id="fef8" class="ml mm iq kf b kg my kk mz ko na ks nb kw nc la mq mr ms mt bi translated">W.王燕和杨丹。<a class="ae kc" href="https://aclweb.org/anthology/D15-1306" rel="noopener ugc nofollow" target="_blank">真讨厌！！！:基于词汇和框架语义嵌入的数据增强方法，使用#petpeeve Tweets </a>对恼人的行为进行自动分类。2015</li><li id="003e" class="ml mm iq kf b kg my kk mz ko na ks nb kw nc la mq mr ms mt bi translated">南小林。<a class="ae kc" href="https://arxiv.org/pdf/1805.06201.pdf" rel="noopener ugc nofollow" target="_blank">语境扩充:通过具有聚合关系的词语进行数据扩充</a>。2018</li><li id="a1c8" class="ml mm iq kf b kg my kk mz ko na ks nb kw nc la mq mr ms mt bi translated">C.库伦贝。<a class="ae kc" href="https://arxiv.org/ftp/arxiv/papers/1812/1812.04718.pdf" rel="noopener ugc nofollow" target="_blank">利用 NLP 云 API 简化文本数据扩充</a>。2018</li></ul></div></div>    
</body>
</html>