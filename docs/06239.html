<html>
<head>
<title>Attribute Relevance Analysis in Python — IV and WoE</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">Python-IV 和 WoE 中的属性相关性分析</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/attribute-relevance-analysis-in-python-iv-and-woe-b5651443fc04?source=collection_archive---------6-----------------------#2019-09-09">https://towardsdatascience.com/attribute-relevance-analysis-in-python-iv-and-woe-b5651443fc04?source=collection_archive---------6-----------------------#2019-09-09</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><p id="4746" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">最近我写了关于<a class="ae ko" rel="noopener" target="_blank" href="/feature-selection-in-python-recursive-feature-elimination-19f1c39b8d15">递归特征消除</a>——我最常用的许多特征选择技术之一。今天我要讲的是另一个——<strong class="js iu">属性相关性分析</strong>。与<strong class="js iu"> RFE </strong>不同，它更深入地挖掘个人属性，并试图告诉你变量的哪个部分与目标变量有最强的联系。</p><figure class="kq kr ks kt gt ku gh gi paragraph-image"><div role="button" tabindex="0" class="kv kw di kx bf ky"><div class="gh gi kp"><img src="../Images/6140c7d3c5b567eb65a770dfa6feb605.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*RcO8rGpq36Eqo2LwxZKRNw.jpeg"/></div></div><figcaption class="lb lc gj gh gi ld le bd b be z dk">Photo by <a class="ae ko" href="https://unsplash.com/@garri?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank">Vladislav Babienko</a> on <a class="ae ko" href="https://unsplash.com/search/photos/decision?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><p id="45d8" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">在我攻读数据科学硕士学位的第一个学期，我遇到了一位“古怪”的教授。他真的是个老古董——乍一看，你可以看出他是这个行业的老手。他的课叫做“<em class="lf">数据科学简介</em>”，根据这个名字，你会期望对数据科学领域、基本术语的基本介绍，以及对数据科学库的介绍。</p><p id="dbb1" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">不是这样的。</p><p id="2250" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">开始的时候，我对这门课不是很满意，主要是因为它有严重的偏见。他谈论的都是客户流失模型和一些我一无所知的神秘术语— <strong class="js iu">属性相关性分析</strong>。</p><p id="f507" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">我现在在业内工作，现在才真正体会到他的话。对于一个新人来说，听客户流失建模并不是最有趣的事情——你可能更愿意学习用超复杂的神经网络对狗和猫进行分类。</p><p id="0aee" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">但是残酷的现实是——这不是你在日常工作中要做的事情！</p><p id="2f8f" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">大多数“数据科学”工作，至少在我居住的这个不发达的第三世界国家，包括与数据库和数据仓库打交道，而每天写 R/Python 代码不是很多人做的事情。</p><p id="d5ff" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">突然听到关于流失建模变得更有趣了！</p><h1 id="2727" class="lg lh it bd li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md bi translated">但是什么是属性相关性分析呢？</h1><p id="9626" class="pw-post-body-paragraph jq jr it js b jt me jv jw jx mf jz ka kb mg kd ke kf mh kh ki kj mi kl km kn im bi translated">好问题。我引用一下官方课书里的一段话:</p><blockquote class="mj mk ml"><p id="d900" class="jq jr lf js b jt ju jv jw jx jy jz ka mm kc kd ke mn kg kh ki mo kk kl km kn im bi translated">属性相关性分析阶段的任务是识别对客户流失影响最大的属性(特征)。通过属性相关性分析，显示出与流失(流失=“是”或“否”)相关的最大分离能力的属性将被选为建立预测流失模型的最佳候选。[1]</p></blockquote><p id="54d0" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">出于某种原因，这本书里的英语很糟糕。我不是说我的是完美的，但作为有声读物听这个是一个痛苦的过程。</p><p id="2576" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">尽管如此，我还是希望你能领会它的要点。</p><p id="d275" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">属性相关性分析绝不仅仅用于预测性流失模型开发，您可以将其用于所有分类任务。它基于两个术语:<strong class="js iu">信息值</strong>和<strong class="js iu">证据权重</strong>。</p><h1 id="af08" class="lg lh it bd li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md bi translated">信息价值和证据权重</h1><p id="c0d6" class="pw-post-body-paragraph jq jr it js b jt me jv jw jx mf jz ka kb mg kd ke kf mh kh ki kj mi kl km kn im bi translated">好吧，我保证我会简短的讲讲这个理论。根据<a class="ae ko" href="http://www.listendata.com" rel="noopener ugc nofollow" target="_blank">www.listendata.com</a>的证据权重解释如下:</p><blockquote class="mj mk ml"><p id="6acf" class="jq jr lf js b jt ju jv jw jx jy jz ka mm kc kd ke mn kg kh ki mo kk kl km kn im bi translated">证据的权重表明了自变量相对于因变量的预测能力。由于它是从信用评分世界演变而来的，它通常被描述为区分好客户和坏客户的一种方法。<strong class="js iu">【不良客户】</strong>指拖欠贷款的客户。<strong class="js iu">【好客户】</strong>指还贷客户。[2]</p></blockquote><p id="251b" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">从同一来源，信息价值的解释如下:</p><blockquote class="mj mk ml"><p id="b96e" class="jq jr lf js b jt ju jv jw jx jy jz ka mm kc kd ke mn kg kh ki mo kk kl km kn im bi translated">信息值是选择预测模型中重要变量的最有用的技术之一。这有助于根据变量的重要性对其进行排序。[3]</p></blockquote><p id="90d8" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">两者都很容易计算。下面是公式:</p><figure class="kq kr ks kt gt ku gh gi paragraph-image"><div role="button" tabindex="0" class="kv kw di kx bf ky"><div class="gh gi mp"><img src="../Images/a5d42e65613c096b6de4066993000828.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*lJ5SY7dunVLh6s5tuE2R4w.png"/></div></div><figcaption class="lb lc gj gh gi ld le bd b be z dk">WoE and IV formulas</figcaption></figure><p id="6d05" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">如果我们在讨论客户流失建模，那么<em class="lf">商品</em>将是没有流失的客户，而<em class="lf">商品</em>将是流失的客户。仅仅从这一点，就可以看出公式背后的简单。</p><p id="8d9f" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">然而，计算这两者将是你最后要做的事情之一——一些<strong class="js iu">先决条件</strong>需要事先满足。</p><h1 id="2199" class="lg lh it bd li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md bi translated">WoE 和 IV 先决条件</h1><p id="903d" class="pw-post-body-paragraph jq jr it js b jt me jv jw jx mf jz ka kb mg kd ke kf mh kh ki kj mi kl km kn im bi translated">为了突出先决条件，我将把它们放在一个有序列表中。</p><ol class=""><li id="48a4" class="mq mr it js b jt ju jx jy kb ms kf mt kj mu kn mv mw mx my bi translated"><strong class="js iu">数据集必须干净</strong>。您可以用单词'<em class="lf"> MISSING </em>'逐字填充缺失的值，我建议您这样做，看看缺失的值是如何与目标变量联系起来的。</li><li id="8037" class="mq mr it js b jt mz jx na kb nb kf nc kj nd kn mv mw mx my bi translated"><strong class="js iu">不应该有任何连续属性</strong>。根据你的喜好，代表年龄或任何连续事物的属性应该被分成 5-10 个格。只要确保每个箱至少有 5%的观察值。</li></ol><p id="33e3" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">一旦您的数据集处于这种形式，您就可以继续进行 WoE 和 IV 计算过程。</p><h1 id="1c3e" class="lg lh it bd li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md bi translated">流失建模示例</h1><p id="48de" class="pw-post-body-paragraph jq jr it js b jt me jv jw jx mf jz ka kb mg kd ke kf mh kh ki kj mi kl km kn im bi translated">为了制作这个例子，我使用了来自<a class="ae ko" href="https://www.kaggle.com" rel="noopener ugc nofollow" target="_blank"> Kaggle </a>的<a class="ae ko" href="https://www.kaggle.com/aakash50897/churn-modellingcsv" rel="noopener ugc nofollow" target="_blank">客户流失建模</a>数据集。装入熊猫时，看起来是这样的:</p><figure class="kq kr ks kt gt ku gh gi paragraph-image"><div role="button" tabindex="0" class="kv kw di kx bf ky"><div class="gh gi ne"><img src="../Images/e675dfe6a92d9d25e4d3c6273a217b5e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*wrVpieQS4EaaEojlUaclWA.png"/></div></div><figcaption class="lb lc gj gh gi ld le bd b be z dk">Head of Churn_Modeling.csv</figcaption></figure><p id="bf50" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">流失建模示例的属性相关性分析分为 6 个步骤:</p><ol class=""><li id="998a" class="mq mr it js b jt ju jx jy kb ms kf mt kj mu kn mv mw mx my bi translated"><strong class="js iu">数据清理和准备</strong></li><li id="9953" class="mq mr it js b jt mz jx na kb nb kf nc kj nd kn mv mw mx my bi translated"><strong class="js iu">计算 IV 和 WoE </strong></li><li id="49e2" class="mq mr it js b jt mz jx na kb nb kf nc kj nd kn mv mw mx my bi translated"><strong class="js iu">识别搅拌器轮廓</strong></li><li id="0f9e" class="mq mr it js b jt mz jx na kb nb kf nc kj nd kn mv mw mx my bi translated"><strong class="js iu">粗分类</strong></li><li id="727f" class="mq mr it js b jt mz jx na kb nb kf nc kj nd kn mv mw mx my bi translated"><strong class="js iu">虚拟变量创建</strong></li><li id="8119" class="mq mr it js b jt mz jx na kb nb kf nc kj nd kn mv mw mx my bi translated"><strong class="js iu">虚拟变量之间的相关性</strong></li></ol><p id="d8f1" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">所以，事不宜迟，我们开始吧！</p><h2 id="c327" class="nf lh it bd li ng nh dn lm ni nj dp lq kb nk nl lu kf nm nn ly kj no np mc nq bi translated">第一步。数据清理和准备</h2><p id="b810" class="pw-post-body-paragraph jq jr it js b jt me jv jw jx mf jz ka kb mg kd ke kf mh kh ki kj mi kl km kn im bi translated">数据集不包含缺失值，因此满足先决条件 1/2！</p><p id="4a2e" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">有 10，000 个观察值和 14 列。从这里开始，我开始清理数据。以下是我采取的步骤:</p><ol class=""><li id="02db" class="mq mr it js b jt ju jx jy kb ms kf mt kj mu kn mv mw mx my bi translated">删除<strong class="js iu"><em class="lf"/></strong><strong class="js iu"><em class="lf">CustomerId</em></strong><strong class="js iu"><em class="lf">姓氏</em></strong>——任意，不能用。</li><li id="7d57" class="mq mr it js b jt mz jx na kb nb kf nc kj nd kn mv mw mx my bi translated">将<strong class="js iu"> <em class="lf">信用分数</em> </strong>、<strong class="js iu"> <em class="lf">年龄</em> </strong>、<strong class="js iu"> <em class="lf">余额</em> </strong>和<strong class="js iu"> <em class="lf">估计销售额</em> </strong>分组到 5 个箱中</li><li id="5e56" class="mq mr it js b jt mz jx na kb nb kf nc kj nd kn mv mw mx my bi translated">删除<strong class="js iu"><em class="lf"/></strong><strong class="js iu"><em class="lf">年龄</em></strong><strong class="js iu"><em class="lf">余额</em> </strong>和<strong class="js iu"> <em class="lf">估计销售额</em> </strong>，因为不再需要它们</li></ol><p id="2e9f" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">下面是实现这些步骤的代码片段:</p><figure class="kq kr ks kt gt ku"><div class="bz fp l di"><div class="nr ns l"/></div><figcaption class="lb lc gj gh gi ld le bd b be z dk">Data Cleaning — <a class="ae ko" href="https://gist.github.com/dradecic/10f4b1a909a8ad42539e7b8aee4da74b" rel="noopener ugc nofollow" target="_blank">https://gist.github.com/dradecic/10f4b1a909a8ad42539e7b8aee4da74b</a></figcaption></figure><p id="103a" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">数据集现在是干净的，不包含连续变量。2 的先决条件 2 已满足！</p><p id="45f5" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">新的、清理后的数据集如下所示:</p><figure class="kq kr ks kt gt ku gh gi paragraph-image"><div role="button" tabindex="0" class="kv kw di kx bf ky"><div class="gh gi nt"><img src="../Images/e69029a34189e914d2bb8f0057635322.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ZS6B7TeJmiXua-AtNEc2FQ.png"/></div></div><figcaption class="lb lc gj gh gi ld le bd b be z dk">Head of the Cleaned version of Churn_Modeling.csv</figcaption></figure><h2 id="ae43" class="nf lh it bd li ng nh dn lm ni nj dp lq kb nk nl lu kf nm nn ly kj no np mc nq bi translated">第二步。计算 IV 和 WoE</h2><p id="c223" class="pw-post-body-paragraph jq jr it js b jt me jv jw jx mf jz ka kb mg kd ke kf mh kh ki kj mi kl km kn im bi translated">现在我可以开始计算 IV 和 WoE 了。出于某种原因，我无法找到这样做的 Python 包，至少我没有找到有良好文档记录的包，所以我必须自己编写代码——没问题！</p><p id="8248" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">下面是计算证据权重和信息值的函数。给定 Pandas 数据帧、属性名和目标变量名，它将进行计算。<br/>该函数将返回熊猫数据帧和 IV 分数。代码乍一看可能有点复杂，但如果逐行阅读，就不会复杂。</p><figure class="kq kr ks kt gt ku"><div class="bz fp l di"><div class="nr ns l"/></div><figcaption class="lb lc gj gh gi ld le bd b be z dk">IV and WoE function — <a class="ae ko" href="https://gist.github.com/dradecic/52d8b2b2213dd3d46f4b75f85c1183f2" rel="noopener ugc nofollow" target="_blank">https://gist.github.com/dradecic/52d8b2b2213dd3d46f4b75f85c1183f2</a></figcaption></figure><p id="306b" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">为了避免在内存中创建许多不必要的数据帧，一个简单的循环将为您打印出所有内容:</p><figure class="kq kr ks kt gt ku"><div class="bz fp l di"><div class="nr ns l"/></div><figcaption class="lb lc gj gh gi ld le bd b be z dk">Printing Loop — <a class="ae ko" href="https://gist.github.com/dradecic/9bd774d84c3ad9f193646fb7dccbd326" rel="noopener ugc nofollow" target="_blank">https://gist.github.com/dradecic/9bd774d84c3ad9f193646fb7dccbd326</a></figcaption></figure><p id="eca4" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">这里注意<strong class="js iu"> <em class="lf"> Exited </em> </strong>是目标变量的名字，由于逻辑原因，你不会为它做计算。当执行这个代码单元时，您将在笔记本中获得大量输出:</p><figure class="kq kr ks kt gt ku gh gi paragraph-image"><div role="button" tabindex="0" class="kv kw di kx bf ky"><div class="gh gi nu"><img src="../Images/caa406ec2478cce75e5fd61babaa84d5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*pCTUGe-KKiCzld_806r8SA.png"/></div></div><figcaption class="lb lc gj gh gi ld le bd b be z dk">Excerpt of IV and WoE output</figcaption></figure><p id="890c" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">如果这是你第一次计算 IV 和 WoE，你可能会想:<strong class="js iu">这到底是怎么回事？！</strong></p><p id="dea2" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">有一个简单的解释。</p><p id="d2fe" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">现在，你应该只关心 IV 分数那一行。更准确地说，<strong class="js iu">把你的想法放在 IV 分数最高的变量上</strong>。下面是 IV 解释表:</p><figure class="kq kr ks kt gt ku gh gi paragraph-image"><div class="gh gi nv"><img src="../Images/ad920c967a1258c88a6303090309cb0a.png" data-original-src="https://miro.medium.com/v2/resize:fit:986/format:webp/1*rSR3ThQsO9YYvOp7WPL_GQ.png"/></div><figcaption class="lb lc gj gh gi ld le bd b be z dk">IV Interpretation table</figcaption></figure><p id="1c91" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">现在你应该能看到更清晰的画面了。您应该只保留那些具有良好预测能力的属性！在当前数据集中，它们是:</p><ul class=""><li id="706d" class="mq mr it js b jt ju jx jy kb ms kf mt kj mu kn nw mw mx my bi translated"><strong class="js iu"><em class="lf">NumOfProducts</em></strong>(0.80)</li><li id="ef01" class="mq mr it js b jt mz jx na kb nb kf nc kj nd kn nw mw mx my bi translated"><strong class="js iu"> <em class="lf">年龄 _ 仓位</em> </strong> (0.74)</li><li id="143c" class="mq mr it js b jt mz jx na kb nb kf nc kj nd kn nw mw mx my bi translated"><strong class="js iu"> <em class="lf">地理</em> </strong> (0.17)</li><li id="8163" class="mq mr it js b jt mz jx na kb nb kf nc kj nd kn nw mw mx my bi translated"><strong class="js iu"><em class="lf">is active member</em></strong>(0.15)</li></ul><h2 id="afa7" class="nf lh it bd li ng nh dn lm ni nj dp lq kb nk nl lu kf nm nn ly kj no np mc nq bi translated">第三步。识别搅拌器轮廓</h2><p id="3a1a" class="pw-post-body-paragraph jq jr it js b jt me jv jw jx mf jz ka kb mg kd ke kf mh kh ki kj mi kl km kn im bi translated">这实际上并不是必需的步骤，但是这样做是非常有益的。</p><p id="d730" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">作为一家公司，你可能想知道典型的厨师是什么样子的。我的意思是，你不关心他/她的外表，但你想知道那个人住在哪里，他/她的年龄，等等…</p><p id="411d" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">为了找出答案，您需要仔细查看那些预测能力最强的变量的返回数据帧。更准确地说，看看<strong class="js iu"> WoE </strong>一栏。理想情况下，你会发现<strong class="js iu">负的 WoE 分数</strong>——这是大多数搅拌者拥有的数值。</p><p id="348a" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">在我们的示例中，这是典型的搅拌器配置文件:</p><ul class=""><li id="bc69" class="mq mr it js b jt ju jx jy kb ms kf mt kj mu kn nw mw mx my bi translated">生活在德国(权重系数 0.63)</li><li id="a966" class="mq mr it js b jt mz jx na kb nb kf nc kj nd kn nw mw mx my bi translated">使用 3 种产品/服务(WoE -2.92)</li><li id="51c5" class="mq mr it js b jt mz jx na kb nb kf nc kj nd kn nw mw mx my bi translated">不是活跃成员(WoE -0.36)</li><li id="52f8" class="mq mr it js b jt mz jx na kb nb kf nc kj nd kn nw mw mx my bi translated">已超过 46 年(WoE -1.20)</li></ul><p id="b6f0" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">有了这些信息，作为一家公司，您可以采取行动，解决这个关键的客户群。</p><h2 id="f49c" class="nf lh it bd li ng nh dn lm ni nj dp lq kb nk nl lu kf nm nn ly kj no np mc nq bi translated">第四部分。粗分类</h2><p id="13ed" class="pw-post-body-paragraph jq jr it js b jt me jv jw jx mf jz ka kb mg kd ke kf mh kh ki kj mi kl km kn im bi translated">粗分类是另一个我在攻读硕士学位之前没有听说过的术语。解释其背后的想法非常简单，<strong class="js iu">你基本上是想把有相似遭遇的实例放在一起，因为它们提供了相同的信息。</strong></p><p id="3901" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">我再次需要自己编写代码来完成这项工作。</p><p id="dc26" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">对于这个数据集，应该对<strong class="js iu"> <em class="lf">地理</em> </strong>属性中的<em class="lf">西班牙</em>和<em class="lf">法国</em>进行粗分类(0.24 和 0.28)。</p><figure class="kq kr ks kt gt ku gh gi paragraph-image"><div role="button" tabindex="0" class="kv kw di kx bf ky"><div class="gh gi nx"><img src="../Images/41f1e8ede6de3621bb92cebc3e51c5d7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*usCBpDWjDRq8NsAh-FlO7g.png"/></div></div><figcaption class="lb lc gj gh gi ld le bd b be z dk">IV and WoE for Geography attribute</figcaption></figure><p id="f4dc" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">下面是用于粗略分类的函数，以及函数调用。要调用该函数，您必须事先知道您想要粗化的两行的索引位置。代码非常简单明了，请看一下:</p><figure class="kq kr ks kt gt ku"><div class="bz fp l di"><div class="nr ns l"/></div><figcaption class="lb lc gj gh gi ld le bd b be z dk">Coarse Classing function — <a class="ae ko" href="https://gist.github.com/dradecic/564c3a9de955ef972b74575f2b700920" rel="noopener ugc nofollow" target="_blank">https://gist.github.com/dradecic/564c3a9de955ef972b74575f2b700920</a></figcaption></figure><p id="b4d2" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">以下是粗分类过程后数据集的样子:</p><figure class="kq kr ks kt gt ku gh gi paragraph-image"><div role="button" tabindex="0" class="kv kw di kx bf ky"><div class="gh gi ny"><img src="../Images/22180b20f110649f5899aab0f4e4fed7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*tVOmom_tRXSZ6kOZAOVT5Q.png"/></div></div><figcaption class="lb lc gj gh gi ld le bd b be z dk">IV and WoE for Geography after coarse classing</figcaption></figure><p id="9c01" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">您可以注意到，对于新创建的行，<em class="lf">值</em>为<em class="lf"> NaN </em>。这没什么好担心的，你可以简单地重新映射原始数据集，用新的东西替换<em class="lf">西班牙</em>和<em class="lf">法国</em>，例如<em class="lf">西班牙 _ 和 _ 法国</em>。</p><figure class="kq kr ks kt gt ku"><div class="bz fp l di"><div class="nr ns l"/></div><figcaption class="lb lc gj gh gi ld le bd b be z dk">Geography remapping — <a class="ae ko" href="https://gist.github.com/dradecic/f1a72679206cdc5285983f40fbe3a679" rel="noopener ugc nofollow" target="_blank">https://gist.github.com/dradecic/f1a72679206cdc5285983f40fbe3a679</a></figcaption></figure><p id="1132" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">相关属性中的所有唯一值现在都有非常不同的 WoE——这意味着您可以继续下一步——创建虚拟变量。</p><h2 id="bb28" class="nf lh it bd li ng nh dn lm ni nj dp lq kb nk nl lu kf nm nn ly kj no np mc nq bi translated">第五步。虚拟变量创建</h2><p id="ed3d" class="pw-post-body-paragraph jq jr it js b jt me jv jw jx mf jz ka kb mg kd ke kf mh kh ki kj mi kl km kn im bi translated">我们就要到达终点了。差不多了。</p><p id="c28b" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">如您所知，当只有二元属性时，分类模型表现最好。这就是虚拟变量出现的原因。</p><p id="1e0c" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">根据维基百科:</p><blockquote class="mj mk ml"><p id="e1ed" class="jq jr lf js b jt ju jv jw jx jy jz ka mm kc kd ke mn kg kh ki mo kk kl km kn im bi translated">虚拟变量是一个取值为 0 或 1 的变量，用来表示可能会改变结果的某种分类效应的存在与否。[4]</p></blockquote><p id="e408" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">简而言之，如果属性有<em class="lf"> n </em>个唯一值，您将需要创建<em class="lf"> n — 1 </em>个虚拟变量。当一个变量是另一个变量的完美预测变量时，可以少创建一个虚拟变量以避免共线性问题。</p><p id="197e" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">以下属性将需要虚拟变量:</p><ul class=""><li id="097b" class="mq mr it js b jt ju jx jy kb ms kf mt kj mu kn nw mw mx my bi translated"><strong class="js iu"> <em class="lf">地理</em> </strong></li><li id="e237" class="mq mr it js b jt mz jx na kb nb kf nc kj nd kn nw mw mx my bi translated"><strong class="js iu"><em class="lf">NumOfProducts</em></strong></li><li id="b660" class="mq mr it js b jt mz jx na kb nb kf nc kj nd kn nw mw mx my bi translated"><strong class="js iu"> <em class="lf">年龄 _ 仓位</em> </strong></li></ul><p id="f255" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">下面的代码将创建它们，然后将它们与<strong class="js iu"> <em class="lf"> IsActiveMember </em> </strong>属性和目标变量<strong class="js iu"> <em class="lf"> Exited </em> </strong>连接成一个新的数据帧:</p><figure class="kq kr ks kt gt ku"><div class="bz fp l di"><div class="nr ns l"/></div><figcaption class="lb lc gj gh gi ld le bd b be z dk">Dummy Variables — <a class="ae ko" href="https://gist.github.com/dradecic/e6eaafed7ed5cd6599abb12dc8a40f60" rel="noopener ugc nofollow" target="_blank">https://gist.github.com/dradecic/e6eaafed7ed5cd6599abb12dc8a40f60</a></figcaption></figure><p id="5826" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">如果您现在看一下新创建的数据帧的头部:</p><figure class="kq kr ks kt gt ku gh gi paragraph-image"><div role="button" tabindex="0" class="kv kw di kx bf ky"><div class="gh gi nz"><img src="../Images/aa511cbd80aedfe68269b3982adbf931.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ICS--XvBOBXTxH5Jt5GKYA.png"/></div></div><figcaption class="lb lc gj gh gi ld le bd b be z dk">DF with Dummy Variables — Head</figcaption></figure><p id="b825" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">现在所有的属性都是二进制格式——只剩下最后一步了！</p><h2 id="268c" class="nf lh it bd li ng nh dn lm ni nj dp lq kb nk nl lu kf nm nn ly kj no np mc nq bi translated">第六步。虚拟变量之间的相关性</h2><p id="c2dc" class="pw-post-body-paragraph jq jr it js b jt me jv jw jx mf jz ka kb mg kd ke kf mh kh ki kj mi kl km kn im bi translated">你已经坚持到最后了。该过程的最后一步是计算虚拟变量之间的相关性，并排除相关性高的变量。</p><p id="107e" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">什么被认为是高相关系数还有待讨论，但是我建议你<strong class="js iu">去掉任何相关度超过 0.7 </strong>(绝对值)的东西。</p><p id="4dab" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">如果您想知道在这两个变量中要删除哪个虚拟变量，<strong class="js iu">删除证据权重较低的那个</strong>，因为它与目标变量的联系较弱。</p><p id="9359" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">我决定绘制一个相关性矩阵，以获得相关性的直观表示:</p><figure class="kq kr ks kt gt ku gh gi paragraph-image"><div role="button" tabindex="0" class="kv kw di kx bf ky"><div class="gh gi oa"><img src="../Images/d8fc980d298e208af081698fd708e848.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*N65BBIN8ahQk2VLltRIrAw.png"/></div></div><figcaption class="lb lc gj gh gi ld le bd b be z dk">Correlation Matrix</figcaption></figure><p id="8c86" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">这里可以看到，虚拟变量之间不存在相关性，因此，它们都必须保留。</p><h1 id="568f" class="lg lh it bd li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md bi translated">结论</h1><p id="975d" class="pw-post-body-paragraph jq jr it js b jt me jv jw jx mf jz ka kb mg kd ke kf mh kh ki kj mi kl km kn im bi translated">我将在这里结束这一部分。下一部分将在几天内完成，最多一周，将涵盖基于虚拟变量的预测模型的开发和优化。</p><p id="ec31" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">我希望你能看到属性相关性分析的威力，不仅在特征选择领域，而且在客户特征分析领域。这篇文章只涉及了整个过程的一小部分，所有的事情都被简化了。为了全面了解情况，我强烈建议你阅读整本书——这本书可以在亚马逊上买到。这不是最便宜的，当然也不是没有错别字，但嘿，如果你能在 YouTube 上观看印度教程，你将能够理解一些刺耳的斯拉夫英语。大概吧。</p><p id="b052" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">一旦文章上线，第二部分的链接将附在这里。<br/>在那之前，敬请期待！</p><p id="2e2f" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">感谢阅读。</p></div><div class="ab cl ob oc hx od" role="separator"><span class="oe bw bk of og oh"/><span class="oe bw bk of og oh"/><span class="oe bw bk of og"/></div><div class="im in io ip iq"><p id="7cc2" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><em class="lf">喜欢这篇文章吗？成为</em> <a class="ae ko" href="https://medium.com/@radecicdario/membership" rel="noopener"> <em class="lf">中等会员</em> </a> <em class="lf">继续无限制的学习。如果你使用下面的链接，我会收到你的一部分会员费，不需要你额外付费。</em></p><div class="oi oj gp gr ok ol"><a href="https://medium.com/@radecicdario/membership" rel="noopener follow" target="_blank"><div class="om ab fo"><div class="on ab oo cl cj op"><h2 class="bd iu gy z fp oq fr fs or fu fw is bi translated">通过我的推荐链接加入 Medium-Dario rade ci</h2><div class="os l"><h3 class="bd b gy z fp oq fr fs or fu fw dk translated">作为一个媒体会员，你的会员费的一部分会给你阅读的作家，你可以完全接触到每一个故事…</h3></div><div class="ot l"><p class="bd b dl z fp oq fr fs or fu fw dk translated">medium.com</p></div></div><div class="ou l"><div class="ov l ow ox oy ou oz kz ol"/></div></div></a></div></div><div class="ab cl ob oc hx od" role="separator"><span class="oe bw bk of og oh"/><span class="oe bw bk of og oh"/><span class="oe bw bk of og"/></div><div class="im in io ip iq"><h1 id="183b" class="lg lh it bd li lj pa ll lm ln pb lp lq lr pc lt lu lv pd lx ly lz pe mb mc md bi translated">参考</h1><p id="8f69" class="pw-post-body-paragraph jq jr it js b jt me jv jw jx mf jz ka kb mg kd ke kf mh kh ki kj mi kl km kn im bi translated">[1] Klepac，g .，Kopal，r .，MRI，L. (2014 年)。使用数据挖掘技术和社会网络分析开发流失模型。美国:IGI-全球</p><p id="b00e" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">[2]<a class="ae ko" href="https://www.listendata.com/2015/03/weight-of-evidence-woe-and-information.html#What-is-Weight-of-Evidence-WOE-" rel="noopener ugc nofollow" target="_blank">https://www . listen data . com/2015/03/Weight-of-Evidence-WOE-and-information . html # What-is-Weight-of-Evidence-WOE-</a></p><p id="ac49" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">[3]<a class="ae ko" href="https://www.listendata.com/2015/03/weight-of-evidence-woe-and-information.html#Information-Value-IV-" rel="noopener ugc nofollow" target="_blank">https://www . listen data . com/2015/03/weight-of-evidence-woe-and-Information . html # Information-Value-IV-</a></p><p id="cf50" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">[4]<a class="ae ko" href="https://en.wikipedia.org/wiki/Dummy_variable_(statistics)" rel="noopener ugc nofollow" target="_blank">https://en . Wikipedia . org/wiki/Dummy _ variable _(statistics)</a></p></div></div>    
</body>
</html>