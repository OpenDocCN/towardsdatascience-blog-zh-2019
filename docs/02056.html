<html>
<head>
<title>A guide to Face Detection in Python (With Code)</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">Python 人脸检测指南(附代码)</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/a-guide-to-face-detection-in-python-3eab0f6b9fc1?source=collection_archive---------1-----------------------#2019-04-05">https://towardsdatascience.com/a-guide-to-face-detection-in-python-3eab0f6b9fc1?source=collection_archive---------1-----------------------#2019-04-05</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><figure class="gl gn jr js jt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi jq"><img src="../Images/d0d39e2f2bc56d621f133b88efb61527.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Mb_CsdWdSHwvKwCz1uR2hg.jpeg"/></div></div><figcaption class="kb kc gj gh gi kd ke bd b be z dk">Greenland</figcaption></figure><p id="43ba" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">在本教程中，我们将看到如何使用 OpenCV 和 Dlib 在 Python 中创建和启动人脸检测算法。我们还将添加一些功能来同时检测多张脸上的眼睛和嘴巴。本文将介绍人脸检测的最基本实现，包括级联分类器、HOG 窗口和深度学习 CNN。</p><p id="b851" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">我们将使用以下内容来介绍人脸检测:</p><ul class=""><li id="f65b" class="ld le it kh b ki kj km kn kq lf ku lg ky lh lc li lj lk ll bi translated">基于 OpenCV 的 Haar 级联分类器</li><li id="3cbb" class="ld le it kh b ki lm km ln kq lo ku lp ky lq lc li lj lk ll bi translated">使用 Dlib 的方向梯度直方图</li><li id="bacb" class="ld le it kh b ki lm km ln kq lo ku lp ky lq lc li lj lk ll bi translated">使用 Dlib 的卷积神经网络</li></ul><p id="6f85" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">本文原载于我的个人博客:<a class="ae lr" href="https://maelfabien.github.io/tutorials/face-detection/#" rel="noopener ugc nofollow" target="_blank">https://maelfabien.github.io/tutorials/face-detection/#</a></p><p id="d7db" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">本文的 Github 库(以及我博客中的所有其他内容)可以在这里找到:</p><div class="ls lt gp gr lu lv"><a href="https://github.com/maelfabien/Machine_Learning_Tutorials" rel="noopener  ugc nofollow" target="_blank"><div class="lw ab fo"><div class="lx ab ly cl cj lz"><h2 class="bd iu gy z fp ma fr fs mb fu fw is bi translated">mael fabien/机器学习教程</h2><div class="mc l"><h3 class="bd b gy z fp ma fr fs mb fu fw dk translated">本报告包含练习、代码、教程和我的个人博客文章</h3></div><div class="md l"><p class="bd b dl z fp ma fr fs mb fu fw dk translated">github.com</p></div></div><div class="me l"><div class="mf l mg mh mi me mj jz lv"/></div></div></a></div><h1 id="0305" class="mk ml it bd mm mn mo mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne nf ng nh bi translated">介绍</h1><p id="9521" class="pw-post-body-paragraph kf kg it kh b ki ni kk kl km nj ko kp kq nk ks kt ku nl kw kx ky nm la lb lc im bi translated">我们将使用 OpenCV，这是一个用于计算机视觉的开源库，用 C/C++编写，有 C++、Python 和 Java 的接口。它支持 Windows、Linux、MacOS、iOS 和 Android。我们的一些工作还需要使用 Dlib，这是一个现代 C++工具包，包含机器学习算法和用于创建复杂软件的工具。</p><h1 id="8ec4" class="mk ml it bd mm mn mo mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne nf ng nh bi translated">要求</h1><p id="c182" class="pw-post-body-paragraph kf kg it kh b ki ni kk kl km nj ko kp kq nk ks kt ku nl kw kx ky nm la lb lc im bi translated">第一步是安装 OpenCV，和 Dlib。运行以下命令:</p><pre class="nn no np nq gt nr ns nt nu aw nv bi"><span id="2d88" class="nw ml it ns b gy nx ny l nz oa">pip install opencv-python</span><span id="0e62" class="nw ml it ns b gy ob ny l nz oa">pip install dlib</span></pre><p id="dbac" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">根据您的版本，文件将安装在以下位置:</p><pre class="nn no np nq gt nr ns nt nu aw nv bi"><span id="371d" class="nw ml it ns b gy nx ny l nz oa">/usr/local/lib/python3.7/site-packages/cv2</span></pre><p id="1a9c" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">如果你遇到 Dlib 的一些问题，请查看<a class="ae lr" href="https://www.pyimagesearch.com/2018/01/22/install-dlib-easy-complete-guide/" rel="noopener ugc nofollow" target="_blank">这篇文章</a>。</p><h1 id="e96a" class="mk ml it bd mm mn mo mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne nf ng nh bi translated">导入和模型路径</h1><p id="6562" class="pw-post-body-paragraph kf kg it kh b ki ni kk kl km nj ko kp kq nk ks kt ku nl kw kx ky nm la lb lc im bi translated">我们将创建一个新的 Jupyter 笔记本/ python 文件，并从以下内容开始:</p><pre class="nn no np nq gt nr ns nt nu aw nv bi"><span id="48e6" class="nw ml it ns b gy nx ny l nz oa">import cv2<br/>import matplotlib.pyplot as plt<br/>import dlib<br/>from imutils import face_utils</span><span id="3aa0" class="nw ml it ns b gy ob ny l nz oa">font = cv2.FONT_HERSHEY_SIMPLEX</span></pre><h1 id="8dd8" class="mk ml it bd mm mn mo mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne nf ng nh bi translated">一.级联分类器</h1><p id="2b4f" class="pw-post-body-paragraph kf kg it kh b ki ni kk kl km nj ko kp kq nk ks kt ku nl kw kx ky nm la lb lc im bi translated">我们将首先探索级联分类器。</p><h1 id="aff0" class="mk ml it bd mm mn mo mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne nf ng nh bi translated">一. 1 .理论</h1><p id="bb95" class="pw-post-body-paragraph kf kg it kh b ki ni kk kl km nj ko kp kq nk ks kt ku nl kw kx ky nm la lb lc im bi translated">级联分类器，即使用 haar-like 特征的级联提升分类器，是集成学习的一个特例，称为 boosting。它通常依赖于<a class="ae lr" href="https://maelfabien.github.io/machinelearning/adaboost" rel="noopener ugc nofollow" target="_blank"> Adaboost </a>分类器(以及其他模型，如 Real Adaboost、Gentle Adaboost 或 Logitboost)。</p><p id="2540" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">级联分类器在包含我们想要检测的对象的图像的几百个样本图像上以及不包含那些图像的其他图像上被训练。</p><p id="3e56" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">我们如何检测一张脸是否存在？有一种算法，称为 Viola–Jones 对象检测框架，它包括实时人脸检测所需的所有步骤:</p><ul class=""><li id="c56f" class="ld le it kh b ki kj km kn kq lf ku lg ky lh lc li lj lk ll bi translated">哈尔特征选择，从哈尔小波导出的特征</li><li id="fa42" class="ld le it kh b ki lm km ln kq lo ku lp ky lq lc li lj lk ll bi translated">创建整体图像</li><li id="dc7a" class="ld le it kh b ki lm km ln kq lo ku lp ky lq lc li lj lk ll bi translated">Adaboost 训练</li><li id="de03" class="ld le it kh b ki lm km ln kq lo ku lp ky lq lc li lj lk ll bi translated">级联分类器</li></ul><p id="fb2c" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">最初的<a class="ae lr" href="https://www.cs.cmu.edu/~efros/courses/LBMV07/Papers/viola-cvpr-01.pdf" rel="noopener ugc nofollow" target="_blank">论文</a>发表于 2001 年。</p><h1 id="ccf4" class="mk ml it bd mm mn mo mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne nf ng nh bi translated">I.1.a .哈尔特征选择</h1><p id="a248" class="pw-post-body-paragraph kf kg it kh b ki ni kk kl km nj ko kp kq nk ks kt ku nl kw kx ky nm la lb lc im bi translated">我们在大多数普通人的脸上发现了一些共同的特征:</p><ul class=""><li id="86d8" class="ld le it kh b ki kj km kn kq lf ku lg ky lh lc li lj lk ll bi translated">与脸颊上部相比，眼部区域较暗</li><li id="816a" class="ld le it kh b ki lm km ln kq lo ku lp ky lq lc li lj lk ll bi translated">与眼睛相比明亮的鼻梁区域</li><li id="a4cf" class="ld le it kh b ki lm km ln kq lo ku lp ky lq lc li lj lk ll bi translated">眼睛、嘴巴、鼻子的一些特定位置…</li></ul><p id="d9d6" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">这些特征称为哈尔特征。特征提取过程将如下所示:</p><figure class="nn no np nq gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi oc"><img src="../Images/f9c5286eab326290aea11b033a0c4620.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*gl4JHntNPHQt1G7txpiRMA.png"/></div></div><figcaption class="kb kc gj gh gi kd ke bd b be z dk">Haar Features</figcaption></figure><p id="9270" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">在这个例子中，第一特征测量眼睛区域和上脸颊区域之间的亮度差异。特征值简单地通过将黑色区域中的像素相加并减去白色区域中的像素来计算。</p><figure class="nn no np nq gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi od"><img src="../Images/41d22cb6a6c5fa8850c8407a6d8b616e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*N-R2Is-gMvtW4ZMkXHi0QA.png"/></div></div></figure><p id="0e5c" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">然后，我们应用这个矩形作为卷积核，覆盖整个图像。为了做到面面俱到，我们应该应用每个内核所有可能的维度和位置。简单的 24*24 图像通常会产生超过 160，000 个特征，每个特征由像素值的和/减组成。对于活体面部检测来说，在计算上是不可能的。那么，我们如何加快这个过程呢？</p><ul class=""><li id="5e31" class="ld le it kh b ki kj km kn kq lf ku lg ky lh lc li lj lk ll bi translated">一旦好的区域被矩形识别，在图像的完全不同的区域上运行窗口是没有用的。这可以通过 Adaboost 来实现。</li><li id="b0d2" class="ld le it kh b ki lm km ln kq lo ku lp ky lq lc li lj lk ll bi translated">使用积分图像原理计算矩形特征，这样更快。我们将在下一节讨论这个问题。</li></ul><figure class="nn no np nq gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi oe"><img src="../Images/eebb74706126e8f2d61edf5751000e31.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*QBPQOgbIzfHlmXBq7jao2w.png"/></div></div></figure><p id="8ef3" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">有几种类型的矩形可以应用于 Haar 特征提取。根据原始论文:</p><ul class=""><li id="957b" class="ld le it kh b ki kj km kn kq lf ku lg ky lh lc li lj lk ll bi translated">双矩形特征是两个矩形区域内的像素之和的差，主要用于检测边缘(a，b)</li><li id="ad03" class="ld le it kh b ki lm km ln kq lo ku lp ky lq lc li lj lk ll bi translated">三矩形功能计算两个外部矩形的总和，从中心矩形的总和中减去，主要用于检测线(c，d)</li><li id="88a7" class="ld le it kh b ki lm km ln kq lo ku lp ky lq lc li lj lk ll bi translated">四矩形特征计算矩形(e)的对角线对之间的差</li></ul><figure class="nn no np nq gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi of"><img src="../Images/efed57dedda47053fb99513cb8fdc505.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*74hqvuGl_8UZ-ups1uRsig.png"/></div></div><figcaption class="kb kc gj gh gi kd ke bd b be z dk">Haar Rectangles</figcaption></figure><p id="08b9" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">既然已经选择了特征，我们使用 Adaboost 分类将它们应用于训练图像集，Adaboost 分类结合一组弱分类器来创建准确的集成模型。有了 200 个特征(而不是最初的 160，000 个)，准确率达到了 95%。论文作者选择了 6000 个特征。</p><h1 id="0331" class="mk ml it bd mm mn mo mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne nf ng nh bi translated">I.1.b .整体形象</h1><p id="6977" class="pw-post-body-paragraph kf kg it kh b ki ni kk kl km nj ko kp kq nk ks kt ku nl kw kx ky nm la lb lc im bi translated">在卷积核样式中计算矩形特征可能会很长，非常长。出于这个原因，作者 Viola 和 Jones 提出了图像的中间表示:积分图像。积分图像的作用是允许仅使用四个值简单地计算任何矩形和。我们来看看效果如何！</p><p id="72c3" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">假设我们想要确定坐标为(x，y)的给定像素处的矩形特征。然后，在给定像素的上面和左边的像素的总和中的像素的积分图像。</p><figure class="nn no np nq gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi og"><img src="../Images/3af09c340962ce86ca4a737ba75a2082.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ORwLhG7fMhXMeW4891AAuA.png"/></div></div></figure><p id="0645" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">其中 ii(x，y)是积分图像，i(x，y)是原始图像。</p><p id="0433" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">当你计算整个积分图像时，有一种形式的递归，只需要在原始图像上遍历一次。事实上，我们可以定义以下一对递归:</p><figure class="nn no np nq gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi oh"><img src="../Images/bf55d6c8a99dd2265ddcf13abadbd171.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ChCeoE4wZ5FMxKw5lPyHFg.png"/></div></div></figure><p id="b937" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">其中 s(x，y)为累计行和，s(x1)= 0，ii(1，y)=0。</p><p id="665e" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">这有什么用？好吧，考虑一个区域 D，我们想估计它的像素总数。我们已经定义了 3 个其他区域:A、B 和 c。</p><ul class=""><li id="d774" class="ld le it kh b ki kj km kn kq lf ku lg ky lh lc li lj lk ll bi translated">点 1 处的积分图像的值是矩形 a 中像素的总和。</li><li id="21e2" class="ld le it kh b ki lm km ln kq lo ku lp ky lq lc li lj lk ll bi translated">点 2 的值是 A + B</li><li id="4de9" class="ld le it kh b ki lm km ln kq lo ku lp ky lq lc li lj lk ll bi translated">点 3 的值是 A + C</li><li id="cdd6" class="ld le it kh b ki lm km ln kq lo ku lp ky lq lc li lj lk ll bi translated">点 4 的值是 A + B + C + D。</li></ul><p id="0e3d" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">因此，区域 D 的像素之和可以简单地计算为:4+1(2+3)。</p><p id="0c5e" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">在一次传递中，我们仅使用 4 个数组引用计算了矩形内部的值。</p><figure class="nn no np nq gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi oi"><img src="../Images/b5b50eae0dae8be5d8fb87b254fe3b32.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*PIuGskVCejQS5kgionNf5A.png"/></div></div></figure><p id="ed58" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">人们应该简单地意识到矩形在实践中是非常简单的特征，但是对于人脸检测来说已经足够了。当涉及复杂问题时，方向可调滤波器往往更加灵活。</p><figure class="nn no np nq gt ju gh gi paragraph-image"><div class="gh gi oj"><img src="../Images/72eb90813556a71ca40b7eef38344101.png" data-original-src="https://miro.medium.com/v2/resize:fit:654/format:webp/1*8K4OvCit8fvOkt5zEaqBaA.png"/></div><figcaption class="kb kc gj gh gi kd ke bd b be z dk">Steerable Filters</figcaption></figure><h1 id="d25c" class="mk ml it bd mm mn mo mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne nf ng nh bi translated">I.1c .用 Adaboost 学习分类函数</h1><p id="9b5d" class="pw-post-body-paragraph kf kg it kh b ki ni kk kl km nj ko kp kq nk ks kt ku nl kw kx ky nm la lb lc im bi translated">给定一组标记的训练图像(正的或负的)，Adaboost 用于:</p><ul class=""><li id="6753" class="ld le it kh b ki kj km kn kq lf ku lg ky lh lc li lj lk ll bi translated">选择一小组特征</li><li id="54fd" class="ld le it kh b ki lm km ln kq lo ku lp ky lq lc li lj lk ll bi translated">并训练分类器</li></ul><p id="d471" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">由于 160，000 个特征中的大多数特征被认为是完全不相关的，因此我们围绕其构建增强模型的弱学习算法被设计成选择分割最佳负样本和正样本的单个矩形特征。</p><h1 id="52a0" class="mk ml it bd mm mn mo mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne nf ng nh bi translated">级联分类器</h1><p id="ca17" class="pw-post-body-paragraph kf kg it kh b ki ni kk kl km nj ko kp kq nk ks kt ku nl kw kx ky nm la lb lc im bi translated">尽管上述过程非常有效，但仍存在一个主要问题。在一幅图像中，图像的大部分是非人脸区域。赋予图像的每个区域同等的重要性是没有意义的，因为我们应该主要关注最有可能包含图片的区域。Viola 和 Jones 使用级联分类器提高了检测率，同时减少了计算时间。</p><p id="4eb4" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">关键思想是拒绝不包含人脸的子窗口，同时识别包含人脸的区域。由于任务是正确地识别人脸，我们希望最小化假阴性率，即包含人脸并且没有被识别为人脸的子窗口。</p><p id="71ea" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">一系列分类器被应用于每个子窗口。这些分类器是简单的决策树:</p><ul class=""><li id="e608" class="ld le it kh b ki kj km kn kq lf ku lg ky lh lc li lj lk ll bi translated">如果第一个分类器是肯定的，我们继续第二个</li><li id="ee97" class="ld le it kh b ki lm km ln kq lo ku lp ky lq lc li lj lk ll bi translated">如果第二个分类器是肯定的，我们继续第三个</li><li id="3173" class="ld le it kh b ki lm km ln kq lo ku lp ky lq lc li lj lk ll bi">…</li></ul><p id="4bb4" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">在某一点上的任何否定结果都导致拒绝该子窗口，因为该子窗口可能包含人脸。初始分类器以较低的计算成本消除了大多数负样本，随后的分类器消除了额外的负样本，但需要更多的计算工作。</p><figure class="nn no np nq gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi ok"><img src="../Images/7ce8eeed236f23add29eb18a5edb9112.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*AeviEHYbpmffW37LRjQ-KA.png"/></div></div></figure><p id="610d" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">使用 Adaboost 训练分类器，并调整阈值以最小化错误率。当训练这样的模型时，变量如下:</p><ul class=""><li id="259c" class="ld le it kh b ki kj km kn kq lf ku lg ky lh lc li lj lk ll bi translated">分类器级数</li><li id="e3ec" class="ld le it kh b ki lm km ln kq lo ku lp ky lq lc li lj lk ll bi translated">每个阶段的特征数量</li><li id="bcd6" class="ld le it kh b ki lm km ln kq lo ku lp ky lq lc li lj lk ll bi translated">每个阶段的门槛</li></ul><p id="ed39" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">幸运的是，在 OpenCV 中，整个模型已经为人脸检测进行了预训练。</p><p id="8038" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">如果你想了解更多关于增强技术的知识，我邀请你查看我关于 Adaboost 的文章。</p><h1 id="eddb" class="mk ml it bd mm mn mo mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne nf ng nh bi translated">一. 2 .进口</h1><p id="74ff" class="pw-post-body-paragraph kf kg it kh b ki ni kk kl km nj ko kp kq nk ks kt ku nl kw kx ky nm la lb lc im bi translated">下一步就是找到预先训练好的权重。我们将使用默认的预训练模型来检测面部，眼睛和嘴巴。根据您的 Python 版本，这些文件应该位于以下位置:</p><pre class="nn no np nq gt nr ns nt nu aw nv bi"><span id="15ce" class="nw ml it ns b gy nx ny l nz oa">/usr/local/lib/python3.7/site-packages/cv2/data</span></pre><p id="bdde" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">一旦确定，我们将这样声明级联分类器:</p><pre class="nn no np nq gt nr ns nt nu aw nv bi"><span id="0e12" class="nw ml it ns b gy nx ny l nz oa">cascPath = "/usr/local/lib/python3.7/site-packages/cv2/data/haarcascade_frontalface_default.xml"<br/>eyePath = "/usr/local/lib/python3.7/site-packages/cv2/data/haarcascade_eye.xml"<br/>smilePath = "/usr/local/lib/python3.7/site-packages/cv2/data/haarcascade_smile.xml"</span><span id="907d" class="nw ml it ns b gy ob ny l nz oa">faceCascade = cv2.CascadeClassifier(cascPath)<br/>eyeCascade = cv2.CascadeClassifier(eyePath)<br/>smileCascade = cv2.CascadeClassifier(smilePath)</span></pre><h1 id="1b00" class="mk ml it bd mm mn mo mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne nf ng nh bi translated">I.3 .检测图像上的人脸</h1><p id="3b0e" class="pw-post-body-paragraph kf kg it kh b ki ni kk kl km nj ko kp kq nk ks kt ku nl kw kx ky nm la lb lc im bi translated">在实现实时人脸检测算法之前，让我们在一幅图像上尝试一个简单的版本。我们可以从加载测试图像开始:</p><pre class="nn no np nq gt nr ns nt nu aw nv bi"><span id="66b1" class="nw ml it ns b gy nx ny l nz oa"># Load the image<br/>gray = cv2.imread('face_detect_test.jpeg', 0)</span><span id="fbe7" class="nw ml it ns b gy ob ny l nz oa">plt.figure(figsize=(12,8))<br/>plt.imshow(gray, cmap='gray')<br/>plt.show()</span></pre><figure class="nn no np nq gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi ol"><img src="../Images/1de53596668a93f24475280936cfb155.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*uqpBwvG3JsdJdVQidv0ulw.png"/></div></div><figcaption class="kb kc gj gh gi kd ke bd b be z dk">Test image</figcaption></figure><p id="1a31" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">然后，我们检测面部，并在其周围添加一个矩形:</p><pre class="nn no np nq gt nr ns nt nu aw nv bi"><span id="64fd" class="nw ml it ns b gy nx ny l nz oa"># Detect faces<br/>faces = faceCascade.detectMultiScale(<br/>gray,<br/>scaleFactor=1.1,<br/>minNeighbors=5,<br/>flags=cv2.CASCADE_SCALE_IMAGE<br/>)</span><span id="e417" class="nw ml it ns b gy ob ny l nz oa"># For each face<br/>for (x, y, w, h) in faces: <br/>    # Draw rectangle around the face<br/>    cv2.rectangle(gray, (x, y), (x+w, y+h), (255, 255, 255), 3)</span></pre><p id="190e" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">以下是<code class="fe om on oo ns b">detectMultiScale</code>功能最常见的参数列表:</p><ul class=""><li id="b99e" class="ld le it kh b ki kj km kn kq lf ku lg ky lh lc li lj lk ll bi translated">scaleFactor:指定图像在每个图像比例下缩小多少的参数。</li><li id="688b" class="ld le it kh b ki lm km ln kq lo ku lp ky lq lc li lj lk ll bi translated">minNeighbors:指定每个候选矩形应该有多少个邻居来保留它的参数。</li><li id="b201" class="ld le it kh b ki lm km ln kq lo ku lp ky lq lc li lj lk ll bi translated">最小尺寸:可能的最小物体尺寸。小于该值的对象将被忽略。</li><li id="7828" class="ld le it kh b ki lm km ln kq lo ku lp ky lq lc li lj lk ll bi translated">maxSize:可能的最大对象大小。大于该值的对象将被忽略。</li></ul><p id="0baf" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">最后，显示结果:</p><pre class="nn no np nq gt nr ns nt nu aw nv bi"><span id="bffc" class="nw ml it ns b gy nx ny l nz oa">plt.figure(figsize=(12,8))<br/>plt.imshow(gray, cmap='gray')<br/>plt.show()</span></pre><figure class="nn no np nq gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi op"><img src="../Images/36bb110002973c70bd84fb8d9c044f16.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*sKvr9CAWcmBlZI5AXrTIHg.png"/></div></div></figure><p id="b974" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">人脸检测在我们的测试图像上运行良好。现在让我们进入实时时间！</p><h1 id="87d5" class="mk ml it bd mm mn mo mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne nf ng nh bi translated">I.4 .实时人脸检测</h1><p id="8947" class="pw-post-body-paragraph kf kg it kh b ki ni kk kl km nj ko kp kq nk ks kt ku nl kw kx ky nm la lb lc im bi translated">让我们继续讨论实时面部检测的 Python 实现。第一步是启动相机，捕捉视频。然后，我们将图像转换成灰度图像。这用于减少输入图像的尺寸。事实上，我们应用简单的线性变换，而不是每像素 3 个点来描述红、绿、蓝:</p><figure class="nn no np nq gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi oq"><img src="../Images/f9c8594d2d87b658896289ab87f184d0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*l6gyRjrBdnqyjirHzVzecw.png"/></div></div></figure><p id="1139" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">这在 OpenCV 中是默认实现的。</p><pre class="nn no np nq gt nr ns nt nu aw nv bi"><span id="d66b" class="nw ml it ns b gy nx ny l nz oa">video_capture = cv2.VideoCapture(0)</span><span id="7c1b" class="nw ml it ns b gy ob ny l nz oa">while True:<br/>    # Capture frame-by-frame<br/>    ret, frame = video_capture.read()<br/>    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)</span></pre><p id="65ff" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">现在，我们将使用上面定义的<code class="fe om on oo ns b">faceCascade</code>变量，它包含一个预先训练的算法，并将其应用于灰度图像。</p><pre class="nn no np nq gt nr ns nt nu aw nv bi"><span id="5022" class="nw ml it ns b gy nx ny l nz oa">faces = faceCascade.detectMultiScale(<br/>        gray,<br/>        scaleFactor=1.1,<br/>        minNeighbors=5,<br/>        minSize=(30, 30),<br/>        flags=cv2.CASCADE_SCALE_IMAGE<br/>        )</span></pre><p id="ae42" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">对于每个检测到的人脸，我们将在人脸周围画一个矩形:</p><pre class="nn no np nq gt nr ns nt nu aw nv bi"><span id="506c" class="nw ml it ns b gy nx ny l nz oa">for (x, y, w, h) in faces:<br/>        if w &gt; 250 :<br/>            cv2.rectangle(frame, (x, y), (x+w, y+h), (255, 0, 0), 3)<br/>            roi_gray = gray[y:y+h, x:x+w]<br/>            roi_color = frame[y:y+h, x:x+w]</span></pre><p id="b694" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">对于检测到的每个嘴部，在其周围画一个矩形:</p><pre class="nn no np nq gt nr ns nt nu aw nv bi"><span id="4ee4" class="nw ml it ns b gy nx ny l nz oa">smile = smileCascade.detectMultiScale(<br/>        roi_gray,<br/>        scaleFactor= 1.16,<br/>        minNeighbors=35,<br/>        minSize=(25, 25),<br/>        flags=cv2.CASCADE_SCALE_IMAGE<br/>    )<br/>    for (sx, sy, sw, sh) in smile:<br/>        cv2.rectangle(roi_color, (sh, sy), (sx+sw, sy+sh), (255, 0, 0), 2)<br/>        cv2.putText(frame,'Smile',(x + sx,y + sy), 1, 1, (0, 255, 0), 1)</span></pre><p id="0813" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">对于检测到的每只眼睛，在其周围画一个矩形:</p><pre class="nn no np nq gt nr ns nt nu aw nv bi"><span id="0a9d" class="nw ml it ns b gy nx ny l nz oa">eyes = eyeCascade.detectMultiScale(roi_gray)<br/>    for (ex,ey,ew,eh) in eyes:<br/>        cv2.rectangle(roi_color,(ex,ey),(ex+ew,ey+eh),(0,255,0),2)<br/>        cv2.putText(frame,'Eye',(x + ex,y + ey), 1, 1, (0, 255, 0), 1)</span></pre><p id="79a8" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">然后，计算面部总数，并显示整体图像:</p><pre class="nn no np nq gt nr ns nt nu aw nv bi"><span id="1b6e" class="nw ml it ns b gy nx ny l nz oa">cv2.putText(frame,'Number of Faces : ' + str(len(faces)),(40, 40), font, 1,(255,0,0),2)      <br/>    # Display the resulting frame<br/>    cv2.imshow('Video', frame)</span></pre><p id="f748" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">当我们想要按下<code class="fe om on oo ns b">q</code>停止拍摄时，执行退出选项:</p><pre class="nn no np nq gt nr ns nt nu aw nv bi"><span id="d877" class="nw ml it ns b gy nx ny l nz oa">if cv2.waitKey(1) &amp; 0xFF == ord('q'):<br/>        break</span></pre><p id="1cd9" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">最后，当一切完成后，释放捕获并销毁所有窗口。在 Mac 上杀死 windows 有一些问题，这可能需要稍后从活动管理器中杀死 Python。</p><pre class="nn no np nq gt nr ns nt nu aw nv bi"><span id="b157" class="nw ml it ns b gy nx ny l nz oa">video_capture.release()<br/>cv2.destroyAllWindows()</span></pre><h1 id="be6a" class="mk ml it bd mm mn mo mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne nf ng nh bi translated">I.5 .包装</h1><figure class="nn no np nq gt ju"><div class="bz fp l di"><div class="or os l"/></div></figure><h1 id="0fa8" class="mk ml it bd mm mn mo mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne nf ng nh bi translated">一. 6 .结果</h1><p id="33a6" class="pw-post-body-paragraph kf kg it kh b ki ni kk kl km nj ko kp kq nk ks kt ku nl kw kx ky nm la lb lc im bi translated">我在 YouTube 上做了一个脸部检测算法的快速演示。</p><figure class="nn no np nq gt ju"><div class="bz fp l di"><div class="ot os l"/></div></figure><h1 id="b8df" class="mk ml it bd mm mn mo mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne nf ng nh bi translated">二。Dlib 中的方向梯度直方图(HOG)</h1><p id="dd00" class="pw-post-body-paragraph kf kg it kh b ki ni kk kl km nj ko kp kq nk ks kt ku nl kw kx ky nm la lb lc im bi translated">第二个最流行的人脸检测工具是由 Dlib 提供的，它使用了一个叫做梯度方向直方图(HOG)的概念。这是 Dalal 和 Triggs 最初<a class="ae lr" href="https://lear.inrialpes.fr/people/triggs/pubs/Dalal-cvpr05.pdf" rel="noopener ugc nofollow" target="_blank">论文的实现。</a></p><h1 id="48e9" class="mk ml it bd mm mn mo mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne nf ng nh bi translated">二. 1 .理论</h1><p id="9bd3" class="pw-post-body-paragraph kf kg it kh b ki ni kk kl km nj ko kp kq nk ks kt ku nl kw kx ky nm la lb lc im bi translated">HOG 背后的想法是将特征提取到一个向量中，并将其输入到一个分类算法中，例如支持向量机，该算法将评估一张脸(或任何你训练它实际识别的对象)是否存在于一个区域中。</p><p id="a1f2" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">提取的特征是图像梯度方向(定向梯度)的分布(直方图)。边缘和角落周围的梯度通常较大，这使我们能够检测到这些区域。</p><p id="6adb" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">在原始论文中，该过程被实现用于人体检测，并且检测链如下:</p><figure class="nn no np nq gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi ou"><img src="../Images/02eba31d1b6c7f3ec23a6193c364bb6c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*sS_WZM4GLS88XlnDLKcZ-g.png"/></div></div></figure><h1 id="568d" class="mk ml it bd mm mn mo mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne nf ng nh bi translated">二. 1.a .预处理</h1><p id="b372" class="pw-post-body-paragraph kf kg it kh b ki ni kk kl km nj ko kp kq nk ks kt ku nl kw kx ky nm la lb lc im bi translated">首先，输入图像必须大小相同(裁剪和重缩放图像)。我们将应用的补丁需要 1:2 的纵横比，因此输入图像的尺寸可能是<code class="fe om on oo ns b">64x128</code>或<code class="fe om on oo ns b">100x200</code>。</p><h1 id="d25e" class="mk ml it bd mm mn mo mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne nf ng nh bi translated">计算梯度图像</h1><p id="2b88" class="pw-post-body-paragraph kf kg it kh b ki ni kk kl km nj ko kp kq nk ks kt ku nl kw kx ky nm la lb lc im bi translated">第一步是通过应用以下内核来计算图像的水平和垂直梯度:</p><figure class="nn no np nq gt ju gh gi paragraph-image"><div class="gh gi ov"><img src="../Images/3dd0cbd1c18443d4f04496241e2124e8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1180/format:webp/1*Wwbo9wTuUw7F5xrL0A4yLg.jpeg"/></div><figcaption class="kb kc gj gh gi kd ke bd b be z dk">Kernels to compute the gradients</figcaption></figure><p id="ec3a" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">图像的梯度通常会移除不重要的信息。</p><p id="a66d" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">我们上面考虑的图像的渐变可以在 Python 中以这种方式找到:</p><pre class="nn no np nq gt nr ns nt nu aw nv bi"><span id="ab5d" class="nw ml it ns b gy nx ny l nz oa">gray = cv2.imread('images/face_detect_test.jpeg', 0)</span><span id="637d" class="nw ml it ns b gy ob ny l nz oa">im = np.float32(gray) / 255.0</span><span id="ab52" class="nw ml it ns b gy ob ny l nz oa"># Calculate gradient <br/>gx = cv2.Sobel(im, cv2.CV_32F, 1, 0, ksize=1)<br/>gy = cv2.Sobel(im, cv2.CV_32F, 0, 1, ksize=1)<br/>mag, angle = cv2.cartToPolar(gx, gy, angleInDegrees=True)</span></pre><p id="a95a" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">画出这幅图:</p><pre class="nn no np nq gt nr ns nt nu aw nv bi"><span id="22d8" class="nw ml it ns b gy nx ny l nz oa">plt.figure(figsize=(12,8))<br/>plt.imshow(mag)<br/>plt.show()</span></pre><figure class="nn no np nq gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi ol"><img src="../Images/8b1bf208e6d7d610e55a8d3acb3a8db3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Agyd4SZpP4Q5g9Ei0tTqLg.png"/></div></div></figure><p id="bfa0" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">但是我们之前没有对图像进行预处理。</p><h1 id="91c2" class="mk ml it bd mm mn mo mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne nf ng nh bi translated">II.1.c 计算猪</h1><p id="c363" class="pw-post-body-paragraph kf kg it kh b ki ni kk kl km nj ko kp kq nk ks kt ku nl kw kx ky nm la lb lc im bi translated">然后，图像被分成 8×8 的单元，以提供紧凑的表示，并使我们的 HOG 对噪声更加鲁棒。然后，我们计算每个单元格的 HOG。</p><p id="54e1" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">为了估计区域内的梯度方向，我们简单地在每个区域内的梯度方向的 64 个值(8×8)和它们的量值(另外 64 个值)之间建立直方图。直方图的类别对应于渐变的角度，从 0°到 180°。总共有 9 类:0，20，40 … 160。</p><p id="34f9" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">上面的代码给了我们两个信息:</p><ul class=""><li id="af76" class="ld le it kh b ki kj km kn kq lf ku lg ky lh lc li lj lk ll bi translated">渐变的方向</li><li id="4d4d" class="ld le it kh b ki lm km ln kq lo ku lp ky lq lc li lj lk ll bi translated">和梯度的大小</li></ul><p id="4197" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">当我们制造 HOG 时，有 3 种情况:</p><ul class=""><li id="13d4" class="ld le it kh b ki kj km kn kq lf ku lg ky lh lc li lj lk ll bi translated">角度小于 160°且不在两个类别的中间。在这种情况下，角度将被添加到猪的正确类别中</li><li id="31ce" class="ld le it kh b ki lm km ln kq lo ku lp ky lq lc li lj lk ll bi translated">角度小于 160°，正好在 2 级之间。在这种情况下，我们考虑对两个最近的类的相等贡献，并且将大小分成两部分</li></ul><figure class="nn no np nq gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi ow"><img src="../Images/0f072277700895199927307f4fd5eaed.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*m2yR2OcMQsDGm7Bv02f1Vg.png"/></div></div></figure><ul class=""><li id="4fb4" class="ld le it kh b ki kj km kn kq lf ku lg ky lh lc li lj lk ll bi translated">角度大于 160°。在这种情况下，我们认为像素成比例地贡献给 160 和 0。</li></ul><figure class="nn no np nq gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi ow"><img src="../Images/e1463788c29f7c4c4611a0b2906fb0ca.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*yTcQHm1n8noWRY-u-proqg.png"/></div></div></figure><p id="c092" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">对于每个 8×8 单元，猪看起来像这样:</p><figure class="nn no np nq gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi ox"><img src="../Images/7d46c5125c06d0866336919a37683ecf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*xsnjvrkXXebqemTIq4u0NA.png"/></div></div><figcaption class="kb kc gj gh gi kd ke bd b be z dk">HoG</figcaption></figure><h1 id="95d8" class="mk ml it bd mm mn mo mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne nf ng nh bi translated">II.1.d .块标准化</h1><p id="bea5" class="pw-post-body-paragraph kf kg it kh b ki ni kk kl km nj ko kp kq nk ks kt ku nl kw kx ky nm la lb lc im bi translated">最后，可以应用 16×16 的块，以便归一化图像并使其对于例如光照不变。这可以简单地通过将大小为 8×8 的 HOG 的每个值除以包含它的 16×16 块的 HOG 的 L2 范数来实现，这实际上是长度为<code class="fe om on oo ns b">9*4 = 36</code>的简单向量。</p><h1 id="afb8" class="mk ml it bd mm mn mo mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne nf ng nh bi translated">II.1.e .块标准化</h1><p id="140b" class="pw-post-body-paragraph kf kg it kh b ki ni kk kl km nj ko kp kq nk ks kt ku nl kw kx ky nm la lb lc im bi translated">最后，所有的 36×1 向量被连接成一个大向量。我们完了。我们有我们的特征向量，在其上我们可以训练一个软 SVM 分类器(C=0.01)。</p><h1 id="9cbe" class="mk ml it bd mm mn mo mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne nf ng nh bi translated">II.2 .检测图像上的人脸</h1><p id="ed83" class="pw-post-body-paragraph kf kg it kh b ki ni kk kl km nj ko kp kq nk ks kt ku nl kw kx ky nm la lb lc im bi translated">实现非常简单:</p><pre class="nn no np nq gt nr ns nt nu aw nv bi"><span id="e4a5" class="nw ml it ns b gy nx ny l nz oa">face_detect = dlib.get_frontal_face_detector()</span><span id="e209" class="nw ml it ns b gy ob ny l nz oa">rects = face_detect(gray, 1)</span><span id="e353" class="nw ml it ns b gy ob ny l nz oa">for (i, rect) in enumerate(rects):<br/>(x, y, w, h) = face_utils.rect_to_bb(rect)<br/>    cv2.rectangle(gray, (x, y), (x + w, y + h), (255, 255, 255), 3)<br/>    <br/>plt.figure(figsize=(12,8))<br/>plt.imshow(gray, cmap='gray')<br/>plt.show()</span></pre><figure class="nn no np nq gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi oy"><img src="../Images/3aef26e7fd35b671f28c04c806cc197b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*9rXTPe70SUbGUGJvfMLGqA.png"/></div></div></figure><h1 id="7ae9" class="mk ml it bd mm mn mo mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne nf ng nh bi translated">II.3 .实时人脸检测</h1><p id="602b" class="pw-post-body-paragraph kf kg it kh b ki ni kk kl km nj ko kp kq nk ks kt ku nl kw kx ky nm la lb lc im bi translated">如前所述，该算法很容易实现。我们还通过只检测面部来实现一个更轻的版本。Dlib 也使得检测面部关键点变得非常容易，但这是另一个话题了。</p><figure class="nn no np nq gt ju"><div class="bz fp l di"><div class="or os l"/></div></figure><h1 id="c2e7" class="mk ml it bd mm mn mo mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne nf ng nh bi translated">三。Dlib 中的卷积神经网络</h1><p id="7d7e" class="pw-post-body-paragraph kf kg it kh b ki ni kk kl km nj ko kp kq nk ks kt ku nl kw kx ky nm la lb lc im bi translated">最后一种方法基于卷积神经网络(CNN)。它还实现了一个关于最大边际对象检测(MMOD)的<a class="ae lr" href="https://arxiv.org/pdf/1502.00046.pdf" rel="noopener ugc nofollow" target="_blank">文件</a>，以增强结果。</p><h1 id="7768" class="mk ml it bd mm mn mo mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne nf ng nh bi translated">III.1 .一点理论</h1><p id="7e1d" class="pw-post-body-paragraph kf kg it kh b ki ni kk kl km nj ko kp kq nk ks kt ku nl kw kx ky nm la lb lc im bi translated">卷积神经网络(CNN)是主要用于计算机视觉前馈神经网络。它们提供了自动化的图像预处理以及密集的神经网络部分。CNN 是一种特殊类型的神经网络，用于处理具有网格状拓扑结构的数据。CNN 的建筑灵感来自动物的视觉皮层。</p><p id="60a5" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">在以前的方法中，很大一部分工作是选择滤波器以创建特征，从而从图像中提取尽可能多的信息。随着深度学习和更大计算能力的兴起，这项工作现在可以自动化。CNN 的名字来源于我们用一组滤波器卷积初始图像输入的事实。要选择的参数仍然是要应用的过滤器数量和过滤器的尺寸。过滤器的尺寸被称为内核尺寸。步长是我们移动该过滤器的像素数。步幅的典型值介于 2 和 5 之间。</p><figure class="nn no np nq gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi oz"><img src="../Images/f95a987e610a768985dbcf265fdd99a0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*FMLmO7x6zQOl73BImKnG4A.png"/></div></div></figure><p id="dccf" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">在这种特定情况下，CNN 的输出是二进制分类，如果有人脸，则取值 1，否则取值 0。</p><h1 id="7da0" class="mk ml it bd mm mn mo mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne nf ng nh bi translated">III.2 .检测图像上的人脸</h1><p id="4dab" class="pw-post-body-paragraph kf kg it kh b ki ni kk kl km nj ko kp kq nk ks kt ku nl kw kx ky nm la lb lc im bi translated">某些元素在实现中会发生变化。</p><p id="575d" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">第一步是在这里下载预先训练好的模型<a class="ae lr" href="https://github.com/davisking/dlib-models/blob/master/mmod_human_face_detector.dat.bz2" rel="noopener ugc nofollow" target="_blank">。将权重移动到您的文件夹，并定义<code class="fe om on oo ns b">dnnDaceDetector</code>:</a></p><pre class="nn no np nq gt nr ns nt nu aw nv bi"><span id="1342" class="nw ml it ns b gy nx ny l nz oa">dnnFaceDetector = dlib.cnn_face_detection_model_v1("mmod_human_face_detector.dat")</span></pre><p id="4acb" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">然后，非常类似于我们到目前为止所做的:</p><pre class="nn no np nq gt nr ns nt nu aw nv bi"><span id="58dc" class="nw ml it ns b gy nx ny l nz oa">rects = dnnFaceDetector(gray, 1)</span><span id="4ec8" class="nw ml it ns b gy ob ny l nz oa">for (i, rect) in enumerate(rects):</span><span id="a6e3" class="nw ml it ns b gy ob ny l nz oa">    x1 = rect.rect.left()<br/>    y1 = rect.rect.top()<br/>    x2 = rect.rect.right()<br/>    y2 = rect.rect.bottom()</span><span id="68de" class="nw ml it ns b gy ob ny l nz oa">    # Rectangle around the face<br/>    cv2.rectangle(gray, (x1, y1), (x2, y2), (255, 255, 255), 3)</span><span id="0fa2" class="nw ml it ns b gy ob ny l nz oa">plt.figure(figsize=(12,8))<br/>plt.imshow(gray, cmap='gray')<br/>plt.show()</span></pre><figure class="nn no np nq gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi pa"><img src="../Images/ef5af777df37b750774de46acf7ce5f9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*VmG9dVH1uVNsNUsk96HNjA.png"/></div></div></figure><h1 id="8dbb" class="mk ml it bd mm mn mo mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne nf ng nh bi translated">III.3 .实时人脸检测</h1><p id="4377" class="pw-post-body-paragraph kf kg it kh b ki ni kk kl km nj ko kp kq nk ks kt ku nl kw kx ky nm la lb lc im bi translated">最后，我们将实现 CNN 人脸检测的实时版本:</p><figure class="nn no np nq gt ju"><div class="bz fp l di"><div class="or os l"/></div></figure><h1 id="ea91" class="mk ml it bd mm mn mo mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne nf ng nh bi translated">四。选哪个？</h1><p id="21ae" class="pw-post-body-paragraph kf kg it kh b ki ni kk kl km nj ko kp kq nk ks kt ku nl kw kx ky nm la lb lc im bi translated">这是一个棘手的问题，但我们将只讨论两个重要的指标:</p><ul class=""><li id="3e8c" class="ld le it kh b ki kj km kn kq lf ku lg ky lh lc li lj lk ll bi translated">计算时间</li><li id="0970" class="ld le it kh b ki lm km ln kq lo ku lp ky lq lc li lj lk ll bi translated">准确性</li></ul><p id="f1d0" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">在速度上，HoG 似乎是最快的算法，其次是 Haar 级联分类器和 CNN。</p><p id="4eee" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">然而，Dlib 中的 CNN 往往是最精确的算法。HoG 表现很好，但是在识别小脸方面有一些问题。总体而言，HaarCascade 分类器的性能与 HoG 差不多。</p><p id="c474" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">我个人在我的个人项目中主要使用 HoG，因为它在实时人脸检测方面速度很快。</p><p id="d65f" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated"><strong class="kh iu"> <em class="pb">结论</em> </strong> <em class="pb">:希望你喜欢这个关于 OpenCV 和 Dlib 人脸检测的快速教程。如果您有任何问题/评论，请不要犹豫，发表评论。</em></p><h1 id="8a00" class="mk ml it bd mm mn mo mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne nf ng nh bi translated">动词 （verb 的缩写）来源:</h1><ul class=""><li id="51b7" class="ld le it kh b ki ni km nj kq pc ku pd ky pe lc li lj lk ll bi translated"><a class="ae lr" href="https://www.learnopencv.com/histogram-of-oriented-gradients/" rel="noopener ugc nofollow" target="_blank">猪</a></li><li id="88e1" class="ld le it kh b ki lm km ln kq lo ku lp ky lq lc li lj lk ll bi translated"><a class="ae lr" href="https://www.pyimagesearch.com/2018/01/22/install-dlib-easy-complete-guide/" rel="noopener ugc nofollow" target="_blank"> DLIB </a></li><li id="80f6" class="ld le it kh b ki lm km ln kq lo ku lp ky lq lc li lj lk ll bi translated"><a class="ae lr" href="https://www.cs.cmu.edu/~efros/courses/LBMV07/Papers/viola-cvpr-01.pdf" rel="noopener ugc nofollow" target="_blank">维奥拉-琼斯论文</a></li><li id="5224" class="ld le it kh b ki lm km ln kq lo ku lp ky lq lc li lj lk ll bi translated"><a class="ae lr" href="https://www.pyimagesearch.com/2018/02/26/face-detection-with-opencv-and-deep-learning/" rel="noopener ugc nofollow" target="_blank">人脸检测 1 </a></li><li id="1703" class="ld le it kh b ki lm km ln kq lo ku lp ky lq lc li lj lk ll bi translated"><a class="ae lr" href="https://www.learnopencv.com/face-detection-opencv-dlib-and-deep-learning-c-python/" rel="noopener ugc nofollow" target="_blank">人脸检测 2 </a></li><li id="a6e9" class="ld le it kh b ki lm km ln kq lo ku lp ky lq lc li lj lk ll bi translated"><a class="ae lr" href="https://docs.opencv.org/3.4.3/d7/d8b/tutorial_py_face_detection.html" rel="noopener ugc nofollow" target="_blank">人脸检测 3 </a></li><li id="12b7" class="ld le it kh b ki lm km ln kq lo ku lp ky lq lc li lj lk ll bi translated"><a class="ae lr" href="https://docs.opencv.org/2.4/modules/objdetect/doc/cascade_classification.html" rel="noopener ugc nofollow" target="_blank">探测多尺度</a></li><li id="f189" class="ld le it kh b ki lm km ln kq lo ku lp ky lq lc li lj lk ll bi translated">维奥拉-琼斯</li></ul></div></div>    
</body>
</html>