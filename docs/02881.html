<html>
<head>
<title>How WaveNet Works</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">WaveNet 如何工作</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/how-wavenet-works-12e2420ef386?source=collection_archive---------1-----------------------#2019-05-10">https://towardsdatascience.com/how-wavenet-works-12e2420ef386?source=collection_archive---------1-----------------------#2019-05-10</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="fd7b" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">是关于时序深度学习进化的！</h2></div><p id="87c1" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">WaveNet 是一种强大的新预测技术，它使用来自计算机视觉(CV)和音频信号处理模型的多种深度学习策略，并将它们应用于纵向时间序列数据。它是由伦敦人工智能公司<a class="ae le" href="https://deepmind.com/" rel="noopener ugc nofollow" target="_blank"> DeepMind </a>的研究人员创造的，目前为<a class="ae le" href="https://assistant.google.com/" rel="noopener ugc nofollow" target="_blank">谷歌助手语音</a>提供动力。</p><figure class="lg lh li lj gt lk gh gi paragraph-image"><div role="button" tabindex="0" class="ll lm di ln bf lo"><div class="gh gi lf"><img src="../Images/b28b231fe7454fdbb03e7ab50960c709.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*0TbaaX8l86ghbGEhuSjPzw.jpeg"/></div></div><figcaption class="lr ls gj gh gi lt lu bd b be z dk">The building blocks of the WaveNet Deep Learning Model</figcaption></figure><p id="56dd" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">这篇博客文章伴随着我最近在西雅图<a class="ae le" href="http://www.globalbigdataconference.com/seattle/global-artificial-intelligence-conference/event-103.html" rel="noopener ugc nofollow" target="_blank">全球人工智能大会(2019 年 4 月 23 日至 25 日)</a>上的一次演讲。它也是我用来讲课和实验的 Jupyter 笔记本的精华，<a class="ae le" href="https://github.com/ultimatist/WaveNet" rel="noopener ugc nofollow" target="_blank">可以在我的 GitHub 上找到，还有支持数据和资源</a>。</p><p id="5b36" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我们将主要探索 WaveNet 及其工作原理，但首先让我们深入研究数据准备、当前的高性能模型(作为基线，脸书预言家)，然后比较结果！</p><p id="9797" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我们正在分析雅虎财经 2000 年 1 月至 2019 年 5 月的 AAPL、MSFT、S&amp;P500、纳斯达克指数数据；这些都在回购的数据文件夹里。</p></div><div class="ab cl lv lw hx lx" role="separator"><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma"/></div><div class="im in io ip iq"><h1 id="8cb6" class="mc md it bd me mf mg mh mi mj mk ml mm jz mn ka mo kc mp kd mq kf mr kg ms mt bi translated">背景</h1><p id="cd0e" class="pw-post-body-paragraph ki kj it kk b kl mu ju kn ko mv jx kq kr mw kt ku kv mx kx ky kz my lb lc ld im bi translated">在我们转向笔记本和我们的结果之前，我们必须了解 WaveNet 是如何形成的。DeepMind 正在研究音频排序问题，特别是与学习和模仿人类语言有关的问题。解决这个问题对于突破我们多年来一直使用的机器人声音至关重要，而且<a class="ae le" href="https://cloud.google.com/text-to-speech/docs/wavenet" rel="noopener ugc nofollow" target="_blank">让数字助理听起来更像人类</a>。</p><p id="a447" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">DeepMind 寻找灵感的一个领域是计算机视觉和卷积网络架构。有趣的是，<a class="ae le" href="https://stackoverflow.com/questions/22471072/convolutional-neural-network-cnn-for-audio" rel="noopener ugc nofollow" target="_blank">滤波和卷积这两个概念不仅适用于图像和视频，<em class="mz">也适用于音频应用</em> </a>。简而言之，DeepMind 对这种被标记为“WaveNet”的架构的实验开始启用<a class="ae le" href="http://https" rel="noopener ugc nofollow" target="_blank">谷歌复杂的助手语音</a>。</p><p id="9fd1" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">随着深度网络的跨功能应用如此成功，研究人员想知道 WaveNet 是否还有其他应用，如序列或时间序列数据。嗯…你猜怎么着？它运行得非常好，但是<em class="mz">需要一些调整</em>。让我们深入研究这些调整，以及我们需要为顺序数据优化的架构。</p></div><div class="ab cl lv lw hx lx" role="separator"><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma"/></div><div class="im in io ip iq"><h1 id="5c18" class="mc md it bd me mf mg mh mi mj mk ml mm jz mn ka mo kc mp kd mq kf mr kg ms mt bi translated">WaveNet 架构</h1><figure class="lg lh li lj gt lk gh gi paragraph-image"><div role="button" tabindex="0" class="ll lm di ln bf lo"><div class="gh gi na"><img src="../Images/53cade3fd4414d34b57de9db7091b3d1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*8jAy-2OtCvOcmiXzh0Ix4Q.png"/></div></div><figcaption class="lr ls gj gh gi lt lu bd b be z dk">Gated Activations and Skip Connections</figcaption></figure><p id="2002" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我们上面看到的是一个<strong class="kk iu">门控激活</strong>。与 LSTM 或格鲁什的门类似，<em class="mz">双曲正切分支</em>是一个激活滤波器，或者说是下面发生的扩张卷积的修改器。这就是我们之前在 CNN 上看到的“挤压功能”。<em class="mz">s 形分支</em>本质上充当了一个二进制门，能够消除之前的一切；它知道哪些数据是重要的，可以追溯到过去任意数量的时期。</p><p id="5e0c" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">还要注意指向右侧的灰色箭头:这些是<strong class="kk iu">跳过连接</strong>。它们允许完全绕过卷积层，并使原始数据能够影响未来任意多个时期的预测公式。这些是可以在数据切片上验证的超参数；最佳值取决于您想要学习的序列的结构和复杂性。</p><p id="8e12" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">请记住，在全连接神经网络中，一个神经元接收来自前一层所有神经元的输入:早期层通过中间计算的层次结构影响后期层。这允许神经网络建立原始输入/信号的复杂交互。</p><p id="5066" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">但是…如果早期的原始输入对预测直接有用，并且我们希望它们直接影响输出，那该怎么办？具体来说，跳过连接允许任何层的输出绕过多个未来层，并且<em class="mz">跳过影响稀释！</em> Keras 允许我们使用<code class="fe nb nc nd ne b">skips.append()</code>存储每个卷积块的张量输出——除了通过进一步的层传递之外。请注意，对于上面堆栈中的每个块，门控激活的输出如何加入跳过连接的集合。</p></div><div class="ab cl lv lw hx lx" role="separator"><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma"/></div><div class="im in io ip iq"><figure class="lg lh li lj gt lk gh gi paragraph-image"><div class="gh gi nf"><img src="../Images/66229eec5e966ce799cbb79c8efac019.png" data-original-src="https://miro.medium.com/v2/resize:fit:1280/format:webp/1*bbfqSNKFkpkf9Y5_mOgdSA.png"/></div><figcaption class="lr ls gj gh gi lt lu bd b be z dk">Residual Connections</figcaption></figure><p id="1243" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="kk iu">剩余连接</strong>类似于跳过连接:把它们想象成持续可用的短层跳过！我们将为我们的模型使用一层跳跃，但它也是一个超参数。他们为什么帮助是神秘的，但它最有可能是由于在反向传播中帮助<a class="ae le" href="https://medium.com/learn-love-ai/the-curious-case-of-the-vanishing-exploding-gradient-bf58ec6822eb" rel="noopener">消失或爆炸梯度</a>障碍。对于较大的模型来说，这变得更加重要，但是出于教育目的，我将向您展示一个较小设置中的实现。</p><figure class="lg lh li lj gt lk gh gi paragraph-image"><div class="gh gi ng"><img src="../Images/09f4f1d4c78f7348439ad0b67c262527.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*ca9rmhIygpu_YxjyCret3g.png"/></div></figure></div><div class="ab cl lv lw hx lx" role="separator"><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma"/></div><div class="im in io ip iq"><h1 id="f542" class="mc md it bd me mf mg mh mi mj mk ml mm jz mn ka mo kc mp kd mq kf mr kg ms mt bi translated">我的结果</h1><p id="a2fb" class="pw-post-body-paragraph ki kj it kk b kl mu ju kn ko mv jx kq kr mw kt ku kv mx kx ky kz my lb lc ld im bi translated">正如您在<a class="ae le" href="https://github.com/ultimatist/WaveNet" rel="noopener ugc nofollow" target="_blank">笔记本</a>中看到的，与脸书先知相比，我的结果非常好:</p><ul class=""><li id="2b0c" class="nh ni it kk b kl km ko kp kr nj kv nk kz nl ld nm nn no np bi translated">预言者平均绝对误差:8.04</li><li id="4edc" class="nh ni it kk b kl nq ko nr kr ns kv nt kz nu ld nm nn no np bi translated">验证集上的 wave net MAE:~ 1.5</li></ul><figure class="lg lh li lj gt lk gh gi paragraph-image"><div role="button" tabindex="0" class="ll lm di ln bf lo"><div class="gh gi nv"><img src="../Images/0493cdc6446730cf0fd7c464684e545b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*O9v-XSY1NmHPAslqKTFtCw.png"/></div></div><figcaption class="lr ls gj gh gi lt lu bd b be z dk">MSFT Volume Prediction</figcaption></figure><p id="cae9" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">然而，当谈到股票预测时，有一些棘手的趋势，没有简单的答案:</p><figure class="lg lh li lj gt lk gh gi paragraph-image"><div role="button" tabindex="0" class="ll lm di ln bf lo"><div class="gh gi nw"><img src="../Images/518ce39c8d1596024dc8376416f3da83.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*33cLGTs4SgETpGHmIPoc6w.png"/></div></div><figcaption class="lr ls gj gh gi lt lu bd b be z dk">MSFT Adjusted Close Prediction</figcaption></figure><p id="59a1" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">整体趋势愚弄了 WaveNet 进入一个强大的回归，而不是跟随局部势头。唉，市场上没有容易赚到的钱！！</p><p id="d67a" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">然而，我只对我的模型进行了轻微的超参数调整，我的训练集非常有限。我们能做得更好吗？请在下面的评论中告诉我你得到了什么结果，以及你是如何部署 WaveNet 的！</p></div></div>    
</body>
</html>