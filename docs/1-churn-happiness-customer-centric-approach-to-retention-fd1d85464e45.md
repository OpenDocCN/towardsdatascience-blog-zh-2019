# 1 —流失=快乐:以客户为中心的保持直觉

> 原文：<https://towardsdatascience.com/1-churn-happiness-customer-centric-approach-to-retention-fd1d85464e45?source=collection_archive---------22----------------------->

## [异种客户血统](https://towardsdatascience.com/tagged/hetero-customer-geneous)

## 使用 Google BigQuery 和 Apache Spark 的 KKBOX Music 的流失预测用例

![](img/eb2cc8e8e4137c2f4aaba5a68ca0264f.png)

[Photo by Pixabay on Pexels](https://www.pexels.com/photo/alternative-career-challenge-chance-277021/)

> “只有一个老板。顾客。他可以解雇公司里从董事长开始的所有人，只要把钱花在别的地方。”
> 
> —萨姆·沃尔顿

客户流失无疑是企业主最害怕的词汇之一，因为这意味着他们已经永远失去了一个客户。尽管这是做生意不可避免的一部分，但如果公司实施适时的营销和销售方法，许多流失的客户都可以被保留下来。

如果你问任何一个数据科学家，流失预测模型的目的是什么，他们很可能会说“预测流失…废话。”这个回答当然是正确的；然而，它只是部分地解决了实际问题。

除了预测，客户的获得和保留不可避免地归结为理解 ***客户价值*** 和 ***我们愿意支付*** 的价格来保持这一价值。它是关于“[庆祝客户的异质性](https://www.amazon.com/Customer-Centricity-Playbook-Implement-Strategy/dp/1613630905/ref=pd_sbs_14_t_0/136-7241085-8546265?_encoding=UTF8&pd_rd_i=1613630905&pd_rd_r=203ddc72-0e0a-45e1-86ef-cf14eccea428&pd_rd_w=PLWuH&pd_rd_wg=fSUpn&pf_rd_p=5cfcfe89-300f-47d2-b1ad-a4e27203a02a&pf_rd_r=HXVVT628T7SNBM0VTPQT&psc=1&refRID=HXVVT628T7SNBM0VTPQT#customerReviews)”知道所有客户并非生来平等，从而使公司产品和服务的开发和交付与其最高价值客户的当前和未来需求保持一致。要正确执行此操作，我们需要回答以下问题:

**1)哪些客户很快就有翻盘的概率最高？**如前所述，可以训练预测模型来识别最有可能离开的客户。

**2)我们每个客户的终身价值是什么？**在确定哪些客户有离开的风险后，我们会遇到这样的问题:“我们提供什么激励措施让他们重新考虑？”(这种优惠通常被称为治疗)。通过了解客户对我们企业长期成功的价值(即客户终身价值)，我们可以开始以*合适的*价格用*合适的*待遇接近他们。

**3) *什么样的挽留优惠最适合每位客户？*** 根据顾客的终身价值，商家可以制定多种治疗方案。将它们分发给所有高风险客户后，可以创建一个模型来了解哪些治疗方法是最有效的。

我将使用现有企业的数据作为例子来探讨这些问题。在本文中，我们将遵循 CRISP-DM 方法，并在下一篇文章中的建模和评估基础上进行构建:

*   ***业务理解:*** 这个阶段从业务的角度考虑我们想要完成什么
*   ***数据理解:*** 此阶段涉及收集、描述和探索数据
*   ***数据准备:*** 此阶段涉及数据的清理、构建和集成
*   ***建模:*** 这一阶段包括建立和评估模型
*   ***评估:*** 在这里，我们评估模型满足我们的业务目标的程度，并试图找到该模型有缺陷的业务原因
*   ***部署:*** 在这个阶段，我们确定一个部署结果的策略，监控部署的性能，维护部署。*这一部分不包括在内。*

最后，这篇文章是作为[我的回购](https://github.com/dangoML/Thinkful-Course-Module-Excercises/tree/master/Capstones/KKBox%20Customer%20Churn)的“后续”而写的。在这里，我将涵盖我在这个项目过程中遇到的主要想法、结果和推论。所以，让我们从问题 1 开始:

> 哪些客户很快翻盘的概率最高？

# 1.商业理解:进入 KKBOX 音乐

![](img/97de2851d875635c1a2373052304f967.png)

KKBOX 是亚洲领先的音乐流媒体服务，拥有世界上最全面的亚洲流行音乐库，拥有超过 3000 万首歌曲。他们向数百万人提供无限制版本的服务，由广告和付费订阅支持。然而，这种微妙的商业模式依赖于准确预测付费用户的流失，这正是我希望实现的。

# 2.数据理解

本次练习的数据[可在 Kaggle](https://www.kaggle.com/c/kkbox-churn-prediction-challenge/data) 公开获取。这是由第 11 届 ACM 网络搜索和数据挖掘国际会议(WSDM 2018)主办的比赛的一部分。数据包含了~ 230 万会员从 2015 年 1 月到 2017 年 3 月的音乐收听和交易习惯。

# — 2.1 数据集描述—

我们将在这个项目中使用的数据集分为两个版本: ***v1*** 和 ***v2*** 。这里，我们将只使用 ***v1*** 文件，因为它们包含近 3 年的数据，而 ***v2*** 只包含一个月。

*   **train_v1:** 包含唯一的用户 id，以及自***2017***2/28 日起是否被篡改。 *~800K 记录@ 45.56 MB*
*   **交易 _v1:** 截至***2017***2/28 的用户交易。它包含与计划定价、交易日期和会员到期日相关的功能。*~ 2200 万条记录@ 1.68 GB*
*   **user_logs_v1:** 截至***2017***2/28 日的日订阅用户活跃度。这包含与播放的独特歌曲数量、每天收听的总秒数以及部分收听的歌曲数量相关的特征。 *~4 亿条记录@ 29.78 GB*
*   **会员:**所有用户信息数据。它包含与性别、注册方法、城市和年龄相关的特征。*~ 500 万条记录@ 417.89 MB*

**总计:31.92 GB** 包含所有文件的 22 个原始数据点，包括 4 个日期字段

以下是我用于高效数据准备和模型构建的数据架构:

*   **原始表( *RAW_* )** —所有表的原始未触及版本，将用作干净备份。
*   **工作表( *WRK_* )** —所有表格的清洁和正确格式化版本。这些将作为我们的派生表的源。
*   **衍生表( *DRV_* )** —专为我们的用例创建的表。所有的特征工程都将在这里进行。

# — 2.2 注释和观察—

鉴于如此庞大的数据集，我决定使用 Google BigQuery *作为持久化的*存储解决方案。对于建模，我使用了 Apache Spark(通过 Google Dataproc)。

*免责声明:我意识到 Google BigQuery 并不打算用作 DBMS，Postgre 和 MySQL 服务器之类的东西更适合这个用例，但是……他们提出让我免费使用它！*

![](img/3d7a48449a45ff74b1f7759a1c3a2373.png)

# 3.数据准备

*请参考* ***创建派生表*** ***及特性*** *章节中的* [*KKBox 搅动—第 1 部分— ETL 笔记本*](https://github.com/dangoML/Project-Portfolio/blob/master/KKBox%20Part%201%20-%20Customer%20Churn%20Prediction/KKBox%20Churn%20-%20Part%201%20-%20ETL.ipynb)

# — 3.1 派生表构造—

我们将从构建每月派生表开始，其中包含在每个月内具有*成员资格到期日*的所有成员。我们还将包括表中所有特定于成员的信息，以及一些简单派生的特性。最后，我们根据 KKBOX 的定义计算 *is_churn* 。结果是:

![](img/7dc2106edbfe6e4f5d244949f90239d4.png)

我们将分别使用 2016 年 1 月和 2016 年 2 月作为训练集和验证集。

# — 3.2 特征工程—

对于这个项目，我最终创建了大约 230 个特性，每个特性都有两种形式；汇总和追溯数据。

***聚集特征*** 是成员数据的一般聚集，主要是绝对总和和平均值。这些集合特征的例子:

*   **Total _ spend:**会员一生中花费的总金额。
*   **spent_per_num_unq** :总花费/独特歌曲数量总和

***回顾性特征*** 采取三种主要形式:

成员资格到期后 7、15、30、60 和 120 天的时间间隔内的聚合数据(AVG、标准差、总和)。示例:

*   **total_secs_last_15_AVG** :过期 15 天内平均收听的音乐秒数
*   **over_50perc_last_30** :过期 30 天内收听率超过 50%的歌曲数量

两周一次的活动街区。示例:

*   **SUM_unq_songs_0_15** :对过期后 0 到 15 天内的唯一歌曲进行求和
*   **AVG _ 歌曲 _15_30** : AVG #到期后 15 到 30 天内的歌曲

双周活动板块比较。创建这些功能是为了捕捉导致成员到期日期的趋势行为。示例:

*   **dif SUM _ unq _ Songs _ 0 _ 15 _ 15 _ 30**:过期后 0-15 天与 15-30 天区间内唯一歌曲总和的差值
*   **dif avg _ Songs _ 15 _ 30 _ 30 _ 45**:到期后 15-30 天与 30-45 天内每天播放的 AVG 歌曲数量的差异

# — 3.3 EDA 和客户细分分析—

*本节参考以下笔记本:*

*   [*KKBox 搅动—第二部— EDA 笔记本*](https://github.com/dangoML/Project-Portfolio/blob/master/KKBox%20Part%201%20-%20Customer%20Churn%20Prediction/KKBox%20Churn%20-%20Part%202%20-%20EDA.ipynb)
*   [*KKBox 细分—第二部分—客户细分分析*](https://github.com/dangoML/Project-Portfolio/blob/master/KKBox%20Part%202%20-%20Customer%20Segmentation%20Analysis/KKBox%20Segmentation%20-%20Part%202%20-%20Segmentation%20Analysis.ipynb)

由于本文更多地关注于项目的建模方面，我强烈建议您访问本节的相应笔记本。正如您将在第一个笔记本中看到的，我喜欢使用统计方法来指导 EDA 过程，尤其是在处理如此多的功能时。除此之外，还通过 K-Means 将用户划分为集群组，以进一步了解现有的客户群及其各自的行为。

我将这些细分市场定义如下:

***电力用户***

人数不多但忠诚，这部分用户是所有指标中最活跃的。由于这些用户往往比其他人拥有更长的会员时间，他们的流失率低于 1%。这个群体也拥有最高的每用户平均收入。

***集群 2，二级电力用户***

就活跃度而言，这些用户仅次于我们的超级用户，约占总观察收入的 16%。像我们的集群 0 用户一样，他们的流失率略高于 1%。

***集群 0，主动多数***

排在第三位的是活跃分子，我们称之为“活跃多数”。这些用户占我们观察人口的近 43%，是收入的最大贡献者，占总收入的近一半。尽管集群 2 的用户更活跃，但在流失率%和每用户平均收入方面，他们之间几乎没有区别。

***集群 1、*** 非活跃少数

与所有其他群体相比，客户流失率最高，我们观察到这部分客户的活跃程度明显低于其他群体。然而，有趣的是，这些用户最有可能在他们的订阅上获得折扣，然而他们中的许多人最终都搅动了 ***(集群 1 中所有用户中 34.5%的人目前低于他们的计划价格，搅动了。这让我对这些人中的许多人是否值得花费资源产生了疑问，并强调了为什么在决定谁值得追求时，客户终身价值如此重要。***

# — 3.4 处理阶级不平衡—

![](img/e87cbd571bf6adb6b93e8862be6ba409.png)

正如我们在探索性数据分析中所讨论的，我们正在处理我们的目标变量(流失)中的一个显著的类别不平衡，非流失与流失的比例为 97:3。为了避免我们的非流失数据占主导地位，我们将从基于 50:50 平衡集(通过对主导类进行欠采样)的建模开始，并在必要时调整这种平衡。

# 4.建模

请参考本节的*跟踪笔记本:*

*   [*KKBox 搅动—第三部分— Spark RFC 建模*笔记本](https://github.com/dangoML/Project-Portfolio/blob/master/KKBox%20Part%201%20-%20Customer%20Churn%20Prediction/KKBox%20Churn%20-%20Part%203%20-%20Spark%20RFC%20Modeling.ipynb)
*   [*KKBox 搅动—第三部分—火花 GBT 建模*笔记本](https://github.com/dangoML/Project-Portfolio/blob/master/KKBox%20Part%201%20-%20Customer%20Churn%20Prediction/KKBox%20Churn%20-%20Part%203%20-%20Spark%20GBT%20Modeling.ipynb)

我们最终在 Apache Spark 上使用了两个分类评估器:***【GBT】***和 ***随机森林分类器(RFC)*** 。为这个项目构建了各种模型，这些迭代产生了许多特性。在这里，我将介绍导致我们最终的 GBT 模型(最佳性能)的一般演变。该部分按如下方式进行:

1.  最初的 GBT 和 RFC 模型建立在一个 ***1 对 1*** 样本上
2.  GBT 模型基于各种 ***x 比 1*** 采样比例，以减少过拟合和整体精度
3.  基于各种 ***x 比 1*** 采样比例和不同特征重要性阈值构建的 GBT 模型，以进一步降低过拟合和整体精度

我们会参考流失值如下: ***流失= 0:*** 正类，客户没流失。 ***流失= 1:*** 负类，客户确实流失了

# 模型#1:一对一流失与非流失比例分割

![](img/90d76ef7d64e2d47468a00ee5c2568aa.png)

## 观察

值得注意的是，我们的模型特征目前仅包括聚合特征和随时间间隔聚合数据特征。查看这些分数，我们可以看到我们的模型稍微有些过度拟合。然而，最令人担忧的是，与召回率相比，我们的准确率较低。查看我们的验证模型的混淆矩阵，我们可以看到这些分数的影响。

![](img/21fbdf69ab291a3605081e0c2d28dbe9.png)

这里我们看到，与我们的假阳性相比，我们模型的假阴性太高了。考虑到我们目前的使用案例，如果 KKBox 使用这种模式，他们在治疗成本上的损失可能会比实际客户流失更多。就验证分数而言，GBT 和 RFC 之间没有实质性差异，然而，RFC 似乎概括得更好。

## 下一次迭代的注释

我们需要解决的第一个问题是两个模型中的大量假阴性。由于我们的模型目前对做出**客户流失=1** 预测更加敏感，我相信通过引入更多非客户流失数据来创造轻微的不平衡，我们可能能够降低这种敏感性。

# 模型#2:具有趋势特征的多个比率子集分割

在这里，我们总共创建了 7 个子集，在每个奇数时间间隔上从 1 比 1 到 13 比 1(非流失到流失)，因为我们希望改善假阳性和假阴性之间的平衡。我们还增加了更多关注趋势的功能。

![](img/0f9bf9dcefb7fa772cd3858262aa30b6.png)![](img/11782bceadfb34c64e84a4c83366d8d2.png)![](img/08bf341eb411cd9038687801c1ec12d9.png)

## 观察

我们现在有大约 230 个功能，包括我们的*双周活动板块*和*双周活动板块功能对比*。看上面的结果，我们可以看到我们对 AUC 做了一些改进。我们还可以看到，在比率子集上，回忆显著增加。这意味着子集似乎已经解决了大量假阴性的问题，但代价是产生了更多的假阳性。

我们的模型仍然过度拟合，高比率模型(9:1、11:1 等)表现最差。然而，在高比率模型上，我们的召回分数更好，在模型误差上也有所改善，精确度略有下降。

## 下一次迭代的注释

由于归纳缺乏一致性，我们将通过基于重要性减少特征的数量来解决模型的复杂性。为此，我们将首先得出所有模型的所有特征重要性分数的平均值。然后，我们将生成该组的 5 个数字的汇总，以生成以下特征组:高于平均值的特征、高于 75%的特征、高于 50%的特征和高于 25%的特征。

# 模型#3:多个比率子集分裂@调整阈值—最佳性能模型

![](img/6a5f804f0798ff858461460000ccc5b7.png)![](img/652f7528635e373623587e0f1e7fc013.png)

## 观察

为了简化我们的分析，我们只包括了每个比率子集的模型，这些模型都是一般化的最佳模型(最佳 1:1 模型、最佳 3:1 模型等)。基于目前的结果，我们增加了模型的总体概括。

![](img/91278fa22f7097470013cde5f2cd2a36.png)

我希望在泛化、假阳性和假阴性方面有更好的结果。[我们可以通过许多方式继续构建和改进这些模型](https://github.com/dangoML/Project-Portfolio/blob/master/KKBox%20Part%201%20-%20Customer%20Churn%20Prediction/KKBox%20Churn%20-%20Future%20Improvements.ipynb)，但我们将结束项目的这一阶段，继续我们目前的成果。

# 5.估价

## — 5.1 模型评估—

在这个项目开始的时候，我们就着手回答这个问题: ***哪些客户很快就有翻腾的概率最高？*** 和虽然我们创建了几个可以轻松回答这个问题的模型，但我们仍然没有足够的信息来为我们的业务选择最佳模型。

由于我们目前不知道每个客户的价值，因此我们不能正确地确定什么样的待遇会说服他们留在我们这里。这种治疗的成本是最终决定使用哪种模型的因素，因为 ***这些模型根据我们选择的策略让我们清楚地了解风险和回报。*** 让我进一步解释一下:

***例#1:太多的假阴性***

![](img/72acc73e24eb26eee83c5345edd41a51.png)

通过查看 ***预测，流失=1*** 列，我们可以看到我们的模型归类为高流失风险的总人数。仅根据这一模型，我们将为 93，367 名成员提供治疗，希望保留其中的 17，305 人，同时冒着 2，618 人的风险。这并不意味着这种模式不好。据我们所知，这些成员的治疗费用可以忽略不计，这意味着对所有 93，367 名成员进行治疗是可以承受的。但是如果总的治疗费用不可忽略呢？在这种情况下，这种模式可能过于昂贵，因为总治疗成本可能超过没有流失的用户的总价值。

***例二:误报太多***

![](img/4727e53b6e0ec8e7d7e1458ffa0867ed.png)

与之前的模型相比，现在我们只有一小部分的假阴性，但是我们也有大约 4.5 倍的假阳性。查看 ***预测，流失=1*** 列，我们看到 15，559 个成员被标记为高风险。我们冒着失去 11，670 名会员的风险，却可能获得说服 8，253 名会员留下的回报。因此，这种模式可能更适合于总治疗费用高而我们的资源有限的情况。

## — 5.2 结论—

这两个模型仅仅是我们在寻找如何识别和接近不开心的顾客的完美平衡时追求的两个极端。它们还展示了正确理解客户价值对我们业务长期成功的重要性，以及留住客户的相关成本。流失预测项目通常不会产生一个单一的、完美的模型，但是它们会提供有价值的信息，这些信息可以用于更有效的决策和实践。

如果你喜欢这个话题，你可能会喜欢我写的下面这篇文章。[通过计算终身价值庆祝“客户异质性”](https://medium.com/@dangoml/1-churn-happiness-a-customer-centric-approach-to-retention-540d1f4a7037)。