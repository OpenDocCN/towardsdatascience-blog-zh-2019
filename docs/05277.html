<html>
<head>
<title>Teaching AI how to do Quantum Mechanics</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">教人工智能如何做量子力学</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/teaching-ai-how-to-do-quantum-mechanics-8ea693b2fa8a?source=collection_archive---------22-----------------------#2019-08-06">https://towardsdatascience.com/teaching-ai-how-to-do-quantum-mechanics-8ea693b2fa8a?source=collection_archive---------22-----------------------#2019-08-06</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><figure class="is it gp gr iu iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi ir"><img src="../Images/25220fceba1b64ca74bdac956953a90c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*A9Ob5FZ0yNROguF3Ku4_7w.png"/></div></div><figcaption class="jc jd gj gh gi je jf bd b be z dk">Pictured top left: Schrodinger, Einstein and Pople. Pictured bottom middle: Hinton and Bengio</figcaption></figure><div class=""/><div class=""><h2 id="a95a" class="pw-subtitle-paragraph kf jh ji bd b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw dk translated">使用传统的先进方法，精确计算化合物的量子力学性质，如原子化能，可能需要几个小时到几周的时间。这篇文章探索了使用<em class="kx">深度神经网络在几秒钟内计算上述属性，准确率达到 99.8%</em>。</h2></div><figure class="kz la lb lc gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi ky"><img src="../Images/f2b7554ec91de215c1df096af1ba3cfa.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*VwXi3784fMCmOugMVr9_zA.png"/></div></div><figcaption class="jc jd gj gh gi je jf bd b be z dk">Training a DNN to predict atomization energy based on a Coulomb matrix input. The average error is 3 kcal/mol, equating to a mind-boggling 99.8% accuracy</figcaption></figure><p id="bfd1" class="pw-post-body-paragraph ld le ji lf b lg lh kj li lj lk km ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi lz translated"><span class="l ma mb mc bm md me mf mg mh di">答</span>在 20 世纪 20 年代发现<em class="mi">量子力学</em>之后，科学家们很快意识到从该理论中产生的基本方程只能在最简单的系统中求解(比如氢原子……)。用诺贝尔奖获得者保罗·狄拉克自己的话说:</p><blockquote class="mj"><p id="1e52" class="mk ml ji bd mm mn mo mp mq mr ms ly dk translated">“潜在的物理定律必要的数学理论的大部分物理和整个化学<a class="ae mt" href="https://en.wikiquote.org/wiki/Chemistry" rel="noopener ugc nofollow" target="_blank">因此完全知道，困难只是这些定律的精确应用导致方程太复杂而无法解决。因此，发展应用</a><a class="ae mt" href="https://en.wikiquote.org/wiki/Quantum_mechanics" rel="noopener ugc nofollow" target="_blank">量子力学</a>的近似实用方法变得很有必要，这可以导致对复杂原子系统的主要特征的解释，而不需要太多的计算”——保罗·狄拉克，1929</p></blockquote><p id="4b73" class="pw-post-body-paragraph ld le ji lf b lg mu kj li lj mv km ll lm mw lo lp lq mx ls lt lu my lw lx ly im bi translated">接下来的快速发展是寻找新的近似方法来处理这个复杂的问题。由此产生了两种最先进的方法:<a class="ae mt" href="https://medium.com/analytics-vidhya/practical-introduction-to-hartree-fock-448fc64c107b" rel="noopener"> <strong class="lf jj">哈特里-福克理论</strong></a><strong class="lf jj">(HF)</strong><a class="ae mt" href="https://en.wikipedia.org/wiki/Density_functional_theory" rel="noopener ugc nofollow" target="_blank"><strong class="lf jj">密度泛函理论</strong> </a> <strong class="lf jj"> (DFT)。</strong></p><p id="04e1" class="pw-post-body-paragraph ld le ji lf b lg lh kj li lj lk km ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">特别是，在 20 世纪 90 年代，DFT 取得了突破性进展，至今仍保持着领先水平。</p><p id="b075" class="pw-post-body-paragraph ld le ji lf b lg lh kj li lj lk km ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">今天，DFT 是计算化学和材料科学的基石。例如，它可用于精确模拟大分子的电子密度表面，如<a class="ae mt" href="https://en.wikipedia.org/wiki/Buckminsterfullerene" rel="noopener ugc nofollow" target="_blank">巴克敏斯特富勒烯</a>:</p><figure class="kz la lb lc gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi mz"><img src="../Images/467b9fd372c2f2e229041dc5a3943a1b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*yIZAeAFfesJu3Uycz9BskQ.png"/></div></div><figcaption class="jc jd gj gh gi je jf bd b be z dk">Electron density map of Buckminsterfullerene (C60)</figcaption></figure><p id="8f4a" class="pw-post-body-paragraph ld le ji lf b lg lh kj li lj lk km ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">DFT 和 HF 的问题是，要得到准确的结果，还是需要很长的时间:<strong class="lf jj">小时，天甚至几周</strong>。</p><p id="e489" class="pw-post-body-paragraph ld le ji lf b lg lh kj li lj lk km ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">我们将使用深度神经网络的预测能力将这个时间缩短到几秒钟。</p><p id="d4c1" class="pw-post-body-paragraph ld le ji lf b lg lh kj li lj lk km ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">这篇文章附带了一个 Google Colab 笔记本,可以用来阅读和深入研究这里提到的一些过程。</p><p id="7698" class="pw-post-body-paragraph ld le ji lf b lg lh kj li lj lk km ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">最后，对最初出版这部作品的<a class="ae mt" href="https://pdfs.semanticscholar.org/5761/d22bb67798167a832879a473e0ece867df04.pdf" rel="noopener ugc nofollow" target="_blank"> G .蒙塔冯等人</a>给予应有的感谢。确实是一个伟大的发现，他们正在继续做一些有趣的事情。</p></div><div class="ab cl na nb hx nc" role="separator"><span class="nd bw bk ne nf ng"/><span class="nd bw bk ne nf ng"/><span class="nd bw bk ne nf"/></div><div class="im in io ip iq"><h1 id="cb48" class="nh ni ji bd nj nk nl nm nn no np nq nr ko ns kp nt kr nu ks nv ku nw kv nx ny bi translated">1.什么是库仑矩阵，为什么它很重要？</h1><p id="e734" class="pw-post-body-paragraph ld le ji lf b lg nz kj li lj oa km ll lm ob lo lp lq oc ls lt lu od lw lx ly im bi translated">库仑矩阵是一种装置，本质上<em class="mi">存储不同原子相互作用的所有信息</em>。</p><p id="e1bd" class="pw-post-body-paragraph ld le ji lf b lg lh kj li lj lk km ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">准确地说，它储存了分子中所有原子对的成对静电势能。</p><p id="fb59" class="pw-post-body-paragraph ld le ji lf b lg lh kj li lj lk km ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">分子的每个原子都有一个与之相关的<strong class="lf jj"> <em class="mi">电荷</em> </strong> <em class="mi"> </em>。此外，每个原子都有一组表示其在空间中的<strong class="lf jj">位置的 3D 坐标。因此，对于每一对原子，我们记下两个原子的距离。那么<strong class="lf jj">库仑矩阵</strong>就是:</strong></p><figure class="kz la lb lc gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi oe"><img src="../Images/0dff3b8598afa5b09be6ee093c434fe4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*6iCHEp_dcNWUOwCmRiBe4w.png"/></div></div><figcaption class="jc jd gj gh gi je jf bd b be z dk">Definition of the Coulomb Matrix</figcaption></figure><p id="cb23" class="pw-post-body-paragraph ld le ji lf b lg lh kj li lj lk km ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">我们希望使用库仑矩阵作为我们的数据输入，因为它具有<strong class="lf jj">预测能力</strong>。</p><p id="4497" class="pw-post-body-paragraph ld le ji lf b lg lh kj li lj lk km ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">事实上，给定库仑矩阵，我们可以进行 DFT 或 HF 计算，以精确计算复杂的量子力学性质(库仑矩阵直接进入薛定谔方程——参考前面的图像)。</p><blockquote class="of og oh"><p id="332e" class="ld le mi lf b lg lh kj li lj lk km ll oi ln lo lp oj lr ls lt ok lv lw lx ly im bi translated"><em class="ji">我们本质上是使用库仑矩阵来</em>隐含地教导机器学习模型关于量子力学的规则。</p></blockquote></div><div class="ab cl na nb hx nc" role="separator"><span class="nd bw bk ne nf ng"/><span class="nd bw bk ne nf ng"/><span class="nd bw bk ne nf"/></div><div class="im in io ip iq"><h1 id="e0b6" class="nh ni ji bd nj nk nl nm nn no np nq nr ko ns kp nt kr nu ks nv ku nw kv nx ny bi translated">2.库仑矩阵有什么问题？</h1><p id="937e" class="pw-post-body-paragraph ld le ji lf b lg nz kj li lj oa km ll lm ob lo lp lq oc ls lt lu od lw lx ly im bi translated">事实上有三个问题。幸运的是，这些都可以解决，仍然可以产生一个非常有用的模型。</p><h2 id="be58" class="ol ni ji bd nj om on dn nn oo op dp nr lm oq or nt lq os ot nv lu ou ov nx ow bi translated">2.1 不同大小的分子有不同大小的库仑矩阵。这与机器学习不兼容。</h2><p id="88da" class="pw-post-body-paragraph ld le ji lf b lg nz kj li lj oa km ll lm ob lo lp lq oc ls lt lu od lw lx ly im bi translated">这个问题的解决方案是填充较小分子的库仑矩阵的边缘，就像这样:</p><figure class="kz la lb lc gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi oe"><img src="../Images/40c7f7a2bb50a29fe44d6bf1e5888b56.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*6RXt6IzbH3zegepoRmT78g.png"/></div></div></figure><p id="91e7" class="pw-post-body-paragraph ld le ji lf b lg lh kj li lj lk km ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">幸运的是，我们使用的数据中已经生成了填充库仑矩阵。我们暂时不需要担心这个问题。</p><h2 id="894e" class="ol ni ji bd nj om on dn nn oo op dp nr lm oq or nt lq os ot nv lu ou ov nx ow bi translated">2.2 存在几个(N！准确地说)标记你的分子的方法——每种标记方案都会产生不同的库仑矩阵。</h2><figure class="kz la lb lc gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi oe"><img src="../Images/21c8993d444b200e781cb2103cbe72e1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*oDqEee7mPDSVrldA2GAtKA.png"/></div></div><figcaption class="jc jd gj gh gi je jf bd b be z dk">Different atom labeling leads to different Coulomb matrices of the same molecule</figcaption></figure><p id="4320" class="pw-post-body-paragraph ld le ji lf b lg lh kj li lj lk km ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">解决这个问题的方法是简单地按照最大原子的顺序对矩阵进行排序。</p><p id="08bb" class="pw-post-body-paragraph ld le ji lf b lg lh kj li lj lk km ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">但是有一个问题——在排序时，我们实际上给矩阵添加了一点噪声，所以每次排序都略有不同。这使神经网络暴露于同一库仑矩阵的几个微小变化，使其更加鲁棒，并防止过拟合。</p><h2 id="3509" class="ol ni ji bd nj om on dn nn oo op dp nr lm oq or nt lq os ot nv lu ou ov nx ow bi translated">2.3 订单中包含大量与标签相关的信息</h2><p id="8375" class="pw-post-body-paragraph ld le ji lf b lg nz kj li lj oa km ll lm ob lo lp lq oc ls lt lu od lw lx ly im bi translated">这个问题可以通过将库仑矩阵通过激活函数转换成二进制输入(0 和 1)来解决。这方面的细节并不重要，要了解更多细节，以及这篇文章中提到的许多其他细节，请阅读以下内容:<a class="ae mt" href="https://pdfs.semanticscholar.org/5761/d22bb67798167a832879a473e0ece867df04.pdf" rel="noopener ugc nofollow" target="_blank">学习原子化能量预测的分子不变表示</a></p><figure class="kz la lb lc gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi ox"><img src="../Images/1e0b8703c89b863598bd96d35504720d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*A_0ZwskLMvAxx9cSdTeayA.png"/></div></div><figcaption class="jc jd gj gh gi je jf bd b be z dk">Converting the Coulomb Matrix into a Binary input</figcaption></figure><p id="2025" class="pw-post-body-paragraph ld le ji lf b lg lh kj li lj lk km ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">对于以上两个问题，这些输入输出类会整理一下。你可以通过代码工作，或者你不能这样做，只是信任它；)</p><figure class="kz la lb lc gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi oy"><img src="../Images/a3cd1e69c07ceb324b9f3df1295c44a6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*m_zNd9Z4iPctjEUMklvLLA.png"/></div></div><figcaption class="jc jd gj gh gi je jf bd b be z dk">Stochastic augmentation and input processing functions</figcaption></figure></div><div class="ab cl na nb hx nc" role="separator"><span class="nd bw bk ne nf ng"/><span class="nd bw bk ne nf ng"/><span class="nd bw bk ne nf"/></div><div class="im in io ip iq"><h1 id="4526" class="nh ni ji bd nj nk nl nm nn no np nq nr ko ns kp nt kr nu ks nv ku nw kv nx ny bi translated">3.我们的数据是什么？</h1><p id="8cd8" class="pw-post-body-paragraph ld le ji lf b lg nz kj li lj oa km ll lm ob lo lp lq oc ls lt lu od lw lx ly im bi translated">我们使用了大约 7000 个分子的数据，这些分子具有几个不同的官能团。</p><p id="2afa" class="pw-post-body-paragraph ld le ji lf b lg lh kj li lj lk km ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">对于每个分子，库仑矩阵已经计算出来(这在代码中很容易做到；每个分子的原子坐标都使用 MM94 力场进行了优化——都相当标准。</p><p id="bfea" class="pw-post-body-paragraph ld le ji lf b lg lh kj li lj lk km ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">对于每个分子，我们还使用 DFT 实现计算其<em class="mi">原子化能量</em>，这是一种量子力学属性。这是我们试图预测的数据，我们将使用计算值来训练我们的神经网络。</p><figure class="kz la lb lc gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi oe"><img src="../Images/42c6d85cb4e267ac6e1de62145649121.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*hwKjzpJC6Lq9DBvUae-XEg.png"/></div></div><figcaption class="jc jd gj gh gi je jf bd b be z dk">The flow of data from molecule to quantum energy prediction</figcaption></figure></div><div class="ab cl na nb hx nc" role="separator"><span class="nd bw bk ne nf ng"/><span class="nd bw bk ne nf ng"/><span class="nd bw bk ne nf"/></div><div class="im in io ip iq"><h1 id="4697" class="nh ni ji bd nj nk nl nm nn no np nq nr ko ns kp nt kr nu ks nv ku nw kv nx ny bi translated">4.我们的深度神经网络是什么架构？</h1><p id="a1af" class="pw-post-body-paragraph ld le ji lf b lg nz kj li lj oa km ll lm ob lo lp lq oc ls lt lu od lw lx ly im bi translated">我们使用一个非常简单的架构:2 个完全连接的隐藏层，每层分别有 400 和 100 个神经元。</p><p id="2ce4" class="pw-post-body-paragraph ld le ji lf b lg lh kj li lj lk km ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">使用<a class="ae mt" href="http://proceedings.mlr.press/v9/glorot10a/glorot10a.pdf" rel="noopener ugc nofollow" target="_blank"> Xavier 初始化</a>对重量进行初始化。</p><p id="bc20" class="pw-post-body-paragraph ld le ji lf b lg lh kj li lj lk km ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">更复杂的架构有很大的发展空间(请随意尝试，如果发现更好的，请告诉我)，但这个简单的结构适用于这个问题。</p><figure class="kz la lb lc gt iv gh gi paragraph-image"><div class="gh gi oz"><img src="../Images/9082a7df5260ff37148a37406af06a64.png" data-original-src="https://miro.medium.com/v2/resize:fit:1380/format:webp/1*dnvGC-PORSoCo7VXT3PV_A.png"/></div><figcaption class="jc jd gj gh gi je jf bd b be z dk">We used something somewhere in between these two…</figcaption></figure><p id="62b6" class="pw-post-body-paragraph ld le ji lf b lg lh kj li lj lk km ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">我们使用<a class="ae mt" href="https://machinelearningmastery.com/adam-optimization-algorithm-for-deep-learning/" rel="noopener ugc nofollow" target="_blank"> Adam 优化器</a>来最小化我们的 MSE(均方误差)损失函数。</p><p id="280a" class="pw-post-body-paragraph ld le ji lf b lg lh kj li lj lk km ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">神经网络在 Google 的<a class="ae mt" href="https://www.infoworld.com/article/3278008/what-is-tensorflow-the-machine-learning-library-explained.html" rel="noopener ugc nofollow" target="_blank"> Tensorflow </a>库中实现，代码在<a class="ae mt" href="https://github.com/aced125/Coulomb_matrix_Medium_blogpost/blob/master/Notebook_accompanying_blogpost.ipynb" rel="noopener ugc nofollow" target="_blank"> Colab 笔记本</a>中。</p></div><div class="ab cl na nb hx nc" role="separator"><span class="nd bw bk ne nf ng"/><span class="nd bw bk ne nf ng"/><span class="nd bw bk ne nf"/></div><div class="im in io ip iq"><h1 id="5c2a" class="nh ni ji bd nj nk nl nm nn no np nq nr ko ns kp nt kr nu ks nv ku nw kv nx ny bi translated">5.结果</h1><p id="d860" class="pw-post-body-paragraph ld le ji lf b lg nz kj li lj oa km ll lm ob lo lp lq oc ls lt lu od lw lx ly im bi translated">如果你想深入了解更多细节，请点击这里查看 Google Colab 笔记本<a class="ae mt" href="https://github.com/aced125/Coulomb_matrix_Medium_blogpost/blob/master/Notebook_accompanying_blogpost.ipynb" rel="noopener ugc nofollow" target="_blank"/>。</p><p id="2c6a" class="pw-post-body-paragraph ld le ji lf b lg lh kj li lj lk km ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">您应该能够毫无问题地运行它，并且神经网络应该训练得非常快(大喊免费 GPU 的 Google Colab)。</p><p id="3746" class="pw-post-body-paragraph ld le ji lf b lg lh kj li lj lk km ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">回归的结果如下所示。很好，如你所见…</p><figure class="kz la lb lc gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi ky"><img src="../Images/f2b7554ec91de215c1df096af1ba3cfa.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*VwXi3784fMCmOugMVr9_zA.png"/></div></div><figcaption class="jc jd gj gh gi je jf bd b be z dk">The straight line represents a perfect prediction while the scattered points represent predictions made by the DNN</figcaption></figure></div><div class="ab cl na nb hx nc" role="separator"><span class="nd bw bk ne nf ng"/><span class="nd bw bk ne nf ng"/><span class="nd bw bk ne nf"/></div><div class="im in io ip iq"><h1 id="3a61" class="nh ni ji bd nj nk nl nm nn no np nq nr ko ns kp nt kr nu ks nv ku nw kv nx ny bi translated">6.后续步骤</h1><p id="3344" class="pw-post-body-paragraph ld le ji lf b lg nz kj li lj oa km ll lm ob lo lp lq oc ls lt lu od lw lx ly im bi translated">要深入探究这篇博客文章中的更多概念，请继续阅读发表这项研究的<a class="ae mt" href="https://pdfs.semanticscholar.org/5761/d22bb67798167a832879a473e0ece867df04.pdf" rel="noopener ugc nofollow" target="_blank">原始论文</a>。</p><p id="337b" class="pw-post-body-paragraph ld le ji lf b lg lh kj li lj lk km ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">这个研究小组发布了更多关于这个想法的论文，所以一定要去看看。</p><p id="7d99" class="pw-post-body-paragraph ld le ji lf b lg lh kj li lj lk km ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">如果你喜欢这个，给这个帖子鼓掌，在<a class="ae mt" href="https://www.linkedin.com/in/laksh-aithani-7b0451148/" rel="noopener ugc nofollow" target="_blank"> LinkedIn </a>上和我联系，告诉我你喜欢什么。下次见！</p></div></div>    
</body>
</html>