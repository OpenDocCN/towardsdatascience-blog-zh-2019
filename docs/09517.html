<html>
<head>
<title>Guide how to learn and master computer vision in 2020</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">2020 年指导如何学习和掌握计算机视觉</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/guide-to-learn-computer-vision-in-2020-36f19d92c934?source=collection_archive---------5-----------------------#2019-12-15">https://towardsdatascience.com/guide-to-learn-computer-vision-in-2020-36f19d92c934?source=collection_archive---------5-----------------------#2019-12-15</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="b85a" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">这篇文章将关注资源，我相信这将最大程度地提高你在计算机视觉方面的知识，并且主要基于我自己的经验。</h2></div><p id="476c" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在开始学习计算机视觉之前，了解机器学习和 python 的基础知识将会很有帮助。</p><blockquote class="le lf lg"><p id="1be0" class="ki kj lh kk b kl km ju kn ko kp jx kq li ks kt ku lj kw kx ky lk la lb lc ld im bi translated">看看我的机器和深度学习博客<a class="ae ll" href="https://diyago.github.io/" rel="noopener ugc nofollow" target="_blank">https://diyago.github.io/</a></p></blockquote><h1 id="1efb" class="lm ln it bd lo lp lq lr ls lt lu lv lw jz lx ka ly kc lz kd ma kf mb kg mc md bi translated">结构</h1><figure class="mf mg mh mi gt mj gh gi paragraph-image"><div class="gh gi me"><img src="../Images/340ca94fffdf62ba40be638968dd336d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1396/format:webp/1*1-aDlv_vQJobrZSWxsAW3w.png"/></div><figcaption class="mm mn gj gh gi mo mp bd b be z dk">Star Wars: Luke Skywalker &amp; Darth Vader</figcaption></figure><p id="9869" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">你不必一开始就选择它，但应用新获得的知识是必要的。</p><p id="dd5d" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">没有太多可选项:<a class="ae ll" href="https://pytorch.org/tutorials/" rel="noopener ugc nofollow" target="_blank"> <strong class="kk iu"> pytorch </strong> </a>或者<a class="ae ll" href="https://www.tensorflow.org/guide/keras" rel="noopener ugc nofollow" target="_blank"><strong class="kk iu">keras</strong></a>(tensor flow)。Pytorch 可能需要编写更多的代码，但是它提供了很大的灵活性，所以请使用它。除此之外，大部分深度学习的研究者开始使用 pytoch。</p><p id="a943" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="kk iu">albumination</strong>(图像增强)和<strong class="kk iu"> catalyst </strong>(框架，pytorch 上面的高级 API)可能也有用，用它们吧，尤其是第一个。</p><h1 id="6ce5" class="lm ln it bd lo lp lq lr ls lt lu lv lw jz lx ka ly kc lz kd ma kf mb kg mc md bi translated">五金器具</h1><ul class=""><li id="807c" class="mq mr it kk b kl ms ko mt kr mu kv mv kz mw ld mx my mz na bi translated">Nvidia GPU 10xx+会绰绰有余(300 美元以上)</li><li id="6e54" class="mq mr it kk b kl nb ko nc kr nd kv ne kz nf ld mx my mz na bi translated"><a class="ae ll" href="https://www.kaggle.com/kernels" rel="noopener ugc nofollow" target="_blank"> Kaggle 内核</a> —每周仅 30 小时(免费)</li><li id="2372" class="mq mr it kk b kl nb ko nc kr nd kv ne kz nf ld mx my mz na bi translated"><a class="ae ll" href="https://colab.research.google.com/" rel="noopener ugc nofollow" target="_blank"> Google Colab </a> — 12 小时会话限制，未知周限制(免费)</li></ul><h1 id="caf0" class="lm ln it bd lo lp lq lr ls lt lu lv lw jz lx ka ly kc lz kd ma kf mb kg mc md bi translated"><strong class="ak">理论&amp;实践</strong></h1><h2 id="0702" class="ng ln it bd lo nh ni dn ls nj nk dp lw kr nl nm ly kv nn no ma kz np nq mc nr bi translated">在线课程</h2><ul class=""><li id="041f" class="mq mr it kk b kl ms ko mt kr mu kv mv kz mw ld mx my mz na bi translated"><a class="ae ll" href="http://cs231n.stanford.edu/" rel="noopener ugc nofollow" target="_blank"> CS231n </a>是顶级在线，涵盖了计算机视觉中所有必要的基础知识。Youtube 在线视频。他们甚至有练习，但我不能建议解决它们。(免费)</li><li id="e7cd" class="mq mr it kk b kl nb ko nc kr nd kv ne kz nf ld mx my mz na bi translated">Fast.ai 是你应该注意的下一道菜。还有，fast.ai 是 pytorch 上面的高层框架，但是他们改变自己的 API 太频繁，文档的缺乏让它用起来不靠谱。然而，理论和有用的技巧只是花时间观看本课程的幻想。(免费)</li></ul><p id="9285" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在学习这些课程的时候，我鼓励你将理论付诸实践，将它应用到一个框架中。</p><h2 id="301b" class="ng ln it bd lo nh ni dn ls nj nk dp lw kr nl nm ly kv nn no ma kz np nq mc nr bi translated"><strong class="ak">商品和编码</strong></h2><ul class=""><li id="841f" class="mq mr it kk b kl ms ko mt kr mu kv mv kz mw ld mx my mz na bi translated">ArXiv.org——所有最近的信息都会在这里。(免费)</li><li id="7b17" class="mq mr it kk b kl nb ko nc kr nd kv ne kz nf ld mx my mz na bi translated"><a class="ae ll" href="https://paperswithcode.com/sota" rel="noopener ugc nofollow" target="_blank">https://paperswithcode.com/sota</a>——最常见的深度学习任务的最新水平，不仅仅是计算机视觉。(免费)</li><li id="d341" class="mq mr it kk b kl nb ko nc kr nd kv ne kz nf ld mx my mz na bi translated">Github  —如果有什么东西被实现了，你可以在这里找到它。(免费)</li></ul><h2 id="9bbc" class="ng ln it bd lo nh ni dn ls nj nk dp lw kr nl nm ly kv nn no ma kz np nq mc nr bi translated">书</h2><p id="c990" class="pw-post-body-paragraph ki kj it kk b kl ms ju kn ko mt jx kq kr ns kt ku kv nt kx ky kz nu lb lc ld im bi translated">没什么可读的，但我相信这两本书会有用，不管你选择用 pytorch 还是 keras</p><ul class=""><li id="aae8" class="mq mr it kk b kl km ko kp kr nv kv nw kz nx ld mx my mz na bi translated"><a class="ae ll" href="https://www.amazon.com/Deep-Learning-Python-Francois-Chollet/dp/1617294438" rel="noopener ugc nofollow" target="_blank">用 Python 进行深度学习</a>Keras 创造者、谷歌人工智能研究员弗朗索瓦·乔莱(Franç ois Chollet)。易于使用，并可能获得一些你以前不知道的洞察力。(不免费)</li><li id="7e15" class="mq mr it kk b kl nb ko nc kr nd kv ne kz nf ld mx my mz na bi translated"><a class="ae ll" href="https://pytorch.org/deep-learning-with-pytorch-thank-you" rel="noopener ugc nofollow" target="_blank">py torch 深度学习</a>py torch 团队 Eli Stevens &amp; Luca Antiga(免费)</li></ul><h2 id="7d12" class="ng ln it bd lo nh ni dn ls nj nk dp lw kr nl nm ly kv nn no ma kz np nq mc nr bi translated">卡格尔</h2><p id="db62" class="pw-post-body-paragraph ki kj it kk b kl ms ju kn ko mt jx kq kr ns kt ku kv nt kx ky kz nu lb lc ld im bi translated"><a class="ae ll" href="https://www.kaggle.com/competitions" rel="noopener ugc nofollow" target="_blank">竞赛</a> — kaggle 是一个知名的在线平台，提供各种机器学习竞赛，其中许多都是关于计算机视觉的。您甚至可以在没有完成课程的情况下开始参与，因为从比赛开始，将会有许多开放的内核(端到端代码)，您可以直接从浏览器运行这些内核。(免费)</p><h1 id="0336" class="lm ln it bd lo lp lq lr ls lt lu lv lw jz lx ka ly kc lz kd ma kf mb kg mc md bi translated">强硬(绝地)方式</h1><figure class="mf mg mh mi gt mj gh gi paragraph-image"><div class="gh gi ny"><img src="../Images/25e9f9539d94cd47509f34d9de2d8831.png" data-original-src="https://miro.medium.com/v2/resize:fit:444/format:webp/1*N7OR1VrYihP8lqI5dT-VFQ.png"/></div><figcaption class="mm mn gj gh gi mo mp bd b be z dk">Star Wars`s Jedi: Yoda</figcaption></figure><p id="bc91" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">另一条路可能会很艰难，但你将获得所需的知识，不仅可以进行拟合预测，还可以进行自己的研究。谢尔盖·别洛乌索夫又名贝斯。</p><p id="790a" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="kk iu">你只需要阅读并实现下面所有的文章(免费)。光是阅读它们也会很棒。</strong></p><h2 id="36e2" class="ng ln it bd lo nh ni dn ls nj nk dp lw kr nl nm ly kv nn no ma kz np nq mc nr bi translated">结构</h2><p id="ee2c" class="pw-post-body-paragraph ki kj it kk b kl ms ju kn ko mt jx kq kr ns kt ku kv nt kx ky kz nu lb lc ld im bi translated">* Alex net:<a class="ae ll" href="https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks" rel="noopener ugc nofollow" target="_blank">https://papers . nips . cc/paper/4824-imagenet-class ification-with-deep-convolutional-neural-networks</a><br/>* ZF net:<a class="ae ll" href="https://arxiv.org/abs/1311.2901" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/abs/1311.2901</a><br/>* vgg 16:<a class="ae ll" href="https://arxiv.org/abs/1505.06798" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/abs/1505.06798</a><br/>* ResNet:<a class="ae ll" href="https://arxiv.org/abs/1704.06904" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/abs/1704.06904</a><br/>* Google net:<a class="ae ll" href="https://arxiv.org/abs/1409.4842" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/abs/1409.4842</a><br/>* Inception:<a class="ae ll" href="https://arxiv.org/abs/1512.00567" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/abs/1512.00567</a></p><h2 id="d06f" class="ng ln it bd lo nh ni dn ls nj nk dp lw kr nl nm ly kv nn no ma kz np nq mc nr bi translated">语义分割</h2><p id="7bde" class="pw-post-body-paragraph ki kj it kk b kl ms ju kn ko mt jx kq kr ns kt ku kv nt kx ky kz nu lb lc ld im bi translated">* FCN: <a class="ae ll" href="https://arxiv.org/abs/1411.4038" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/abs/1411.4038 </a> <br/> * SegNet: <a class="ae ll" href="https://arxiv.org/abs/1511.00561" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/abs/1511.00561 </a> <br/> * UNET: <a class="ae ll" href="https://arxiv.org/abs/1505.04597" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/abs/1505.04597 </a> <br/> * PSPNet: <a class="ae ll" href="https://arxiv.org/abs/1612.01105" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/abs/1612.01105 </a> <br/> * DeepLab: <a class="ae ll" href="https://arxiv.org/abs/1606.00915" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/abs/1606.00915 </a> <br/> * ICNet: <a class="ae ll" href="https://arxiv.org/abs/1704.08545" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/abs/1704.08545 </a> * ENT: <a class="ae ll" href="https://arxiv.org/abs/1606.02147" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/abs/1</a></p><h2 id="88fa" class="ng ln it bd lo nh ni dn ls nj nk dp lw kr nl nm ly kv nn no ma kz np nq mc nr bi translated">生成对抗网络 Generative adversarial Networks</h2><p id="34fe" class="pw-post-body-paragraph ki kj it kk b kl ms ju kn ko mt jx kq kr ns kt ku kv nt kx ky kz nu lb lc ld im bi translated">* GAN: <a class="ae ll" href="https://arxiv.org/abs/1406.2661" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/abs/1406.2661 </a> <br/> * DCGAN: <a class="ae ll" href="https://arxiv.org/abs/1511.06434" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/abs/1511.06434 </a> <br/> * WGAN: <a class="ae ll" href="https://arxiv.org/abs/1701.07875" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/abs/1701.07875 </a> <br/> * Pix2Pix: <a class="ae ll" href="https://arxiv.org/abs/1611.07004" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/abs/1611.07004 </a> <br/> * CycleGAN: <a class="ae ll" href="https://arxiv.org/abs/1703.10593" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/abs/1703.10593 </a></p><h2 id="ba8d" class="ng ln it bd lo nh ni dn ls nj nk dp lw kr nl nm ly kv nn no ma kz np nq mc nr bi translated">对象检测 Object Detection</h2><p id="2729" class="pw-post-body-paragraph ki kj it kk b kl ms ju kn ko mt jx kq kr ns kt ku kv nt kx ky kz nu lb lc ld im bi translated">* RCNN: <a class="ae ll" href="https://arxiv.org/abs/1311.2524" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/abs/1311.2524 </a> <br/> * Fast-RCNN: <a class="ae ll" href="https://arxiv.org/abs/1504.08083" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/abs/1504.08083 </a> <br/> * Faster-RCNN: <a class="ae ll" href="https://arxiv.org/abs/1506.01497" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/abs/1506.01497 </a> <br/> * SSD: <a class="ae ll" href="https://arxiv.org/abs/1512.02325" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/abs/1512.02325 </a> <br/> * YOLO: <a class="ae ll" href="https://arxiv.org/abs/1506.02640" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/abs/1506.02640 </a> * YOLO9000: <a class="ae ll" href="https://arxiv.org/abs/1612.08242" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/abs/1612.08242 </a></p><h2 id="0096" class="ng ln it bd lo nh ni dn ls nj nk dp lw kr nl nm ly kv nn no ma kz np nq mc nr bi translated">实例 Segmentation</h2><p id="8f4a" class="pw-post-body-paragraph ki kj it kk b kl ms ju kn ko mt jx kq kr ns kt ku kv nt kx ky kz nu lb lc ld im bi translated">* Mask-RCNN: <a class="ae ll" href="https://arxiv.org/abs/1703.06870" rel="noopener ugc nofollow" target="_blank"> https://arxiv.org/abs/1703.06870 </a> <br/> * YOLACT: <a class="ae ll" href="https://arxiv.org/abs/1904.02689" rel="noopener ugc nofollow" target="_blank"> https://arxiv.org/abs/1904.02689 </a></p><h2 id="62f6" class="ng ln it bd lo nh ni dn ls nj nk dp lw kr nl nm ly kv nn no ma kz np nq mc nr bi translated">姿势估计</h2><p id="5526" class="pw-post-body-paragraph ki kj it kk b kl ms ju kn ko mt jx kq kr ns kt ku kv nt kx ky kz nu lb lc ld im bi translated">* PoseNet: <a class="ae ll" href="https://arxiv.org/abs/1505.07427" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/abs/1505.07427</a><br/>*DensePose:<a class="ae ll" href="https://arxiv.org/abs/1802.00434" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/abs/1802.00434</a></p></div></div>    
</body>
</html>