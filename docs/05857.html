<html>
<head>
<title>Bayesian Inference for AR(p) Models</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">AR(p)模型的贝叶斯推断</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/bayesian-inference-for-ar-models-73ff916101c9?source=collection_archive---------18-----------------------#2019-08-26">https://towardsdatascience.com/bayesian-inference-for-ar-models-73ff916101c9?source=collection_archive---------18-----------------------#2019-08-26</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="a251" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">以“贝叶斯”方式实现 AR 模型。用 Julia 写的代码，可以在这里找到<a class="ae ki" href="https://github.com/saumyagshah/JupyterNBTuringExamples/blob/master/time_series_AR_shampoo.ipynb" rel="noopener ugc nofollow" target="_blank"/>(Jupyter 笔记本上的图和输出)或者在这里找到<a class="ae ki" href="https://github.com/TuringLang/TuringExamples/blob/master/time_series_AR.jl" rel="noopener ugc nofollow" target="_blank"/>(。jl 文件)。</h2></div><figure class="kk kl km kn gt ko gh gi paragraph-image"><div role="button" tabindex="0" class="kp kq di kr bf ks"><div class="gh gi kj"><img src="../Images/b362848b33ec11753832a659c7456f6b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*M4B3CcJgiysvBKca"/></div></div><figcaption class="kv kw gj gh gi kx ky bd b be z dk">Example of Time Series Data; Photo by <a class="ae ki" href="https://unsplash.com/@isaacmsmith?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Isaac Smith</a> on <a class="ae ki" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><p id="4c92" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">你好！</p><p id="49fb" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi lv translated"><span class="l lw lx ly bm lz ma mb mc md di"/>单变量时间序列大致是指在每个等距有序的时间间隔上有一个值(某个期望量)的序列。对于多变量情况，在每个时刻都有一个以上的值(不同的期望量)。这篇文章主要集中在单变量时间序列，现在将被称为只是时间序列。</p><p id="da0a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">时间序列数据的例子包括过去几年中特定地区的月降雨量和特定城市的日最高温度。从这两个例子可以明显看出，获得给定时间序列的准确预测是非常有用的。这些预测让我们得以一窥未来，帮助拯救无数生命。</p><p id="1899" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">AR 模型可用于获得时间序列的预测。本文描述了使用贝叶斯推理对此类模型进行参数估计的过程。对于那些不熟悉这种技术的人，我将提供一个简短的描述。用户提供数据以及待估计参数的先验分布。顾名思义，这些先验分布是基于用户对被估计参数的先验信念。基于这些输入，给定数据，模型输出参数<em class="me">的分布。这种分布称为后验分布，然后可以用于获得对未知数据的预测，在我们的情况下，这是指我们的时间序列的未来值。</em></p><p id="6226" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这是对贝叶斯推理的一个极其简短的描述，它并不完全符合其广泛而令人兴奋的应用。然而，这对于本文的目的来说已经足够了，尽管我强烈建议您进一步阅读这个主题。如果你现在感到困惑，不要担心。事情会越来越明朗:)。</p><p id="b9a2" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我目前正在 Julia Season of Contributions(JSoC)2019 下向 Turing.jl 投稿，这篇文章描述了我作为 JSoC 的一部分实现的其中一个模型。图灵是一种用 Julia 编写的概率编程语言(PPL ),它使得在纸上定义模型成为一个无缝的过程。此外，它有助于从成分分布中轻松取样。</p><h1 id="3304" class="mf mg it bd mh mi mj mk ml mm mn mo mp jz mq ka mr kc ms kd mt kf mu kg mv mw bi translated">从 AR(p)模型开始</h1><p id="4e09" class="pw-post-body-paragraph kz la it lb b lc mx ju le lf my jx lh li mz lk ll lm na lo lp lq nb ls lt lu im bi lv translated">AR(p)模型是指具有<em class="me"> p 滞后项</em>的自回归模型。自回归意味着变量相对于他自己过去的值线性回归。滞后参数<em class="me"> p </em>决定了在每个时刻使用多少过去的值。对于给定的由<em class="me"> x </em>表示的时间序列，我们得到 AR(p)模型的以下预测方程:</p><figure class="kk kl km kn gt ko gh gi paragraph-image"><div class="gh gi nc"><img src="../Images/4343b1adb0e521009207f0807d9fa292.png" data-original-src="https://miro.medium.com/v2/resize:fit:952/format:webp/1*bUaJLcEfwqaM4iNu9TxHzQ.png"/></div></figure><p id="85dd" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">其中，ε表示白噪声。现在，有了这些基本信息，让我们来看看代码。</p><h2 id="e53e" class="nd mg it bd mh ne nf dn ml ng nh dp mp li ni nj mr lm nk nl mt lq nm nn mv no bi translated">导入库</h2><p id="fc1e" class="pw-post-body-paragraph kz la it lb b lc mx ju le lf my jx lh li mz lk ll lm na lo lp lq nb ls lt lu im bi translated">我们从导入所需的库开始。我们将使用<a class="ae ki" href="https://turing.ml/dev/" rel="noopener ugc nofollow" target="_blank"> Turing.jl </a>，一种 Julia 中的概率编程语言。从定义模型到从后验分布中获取样本，会让整个过程变得流畅，毫不费力。</p><figure class="kk kl km kn gt ko"><div class="bz fp l di"><div class="np nq l"/></div></figure><h2 id="7181" class="nd mg it bd mh ne nf dn ml ng nh dp mp li ni nj mr lm nk nl mt lq nm nn mv no bi translated">加载和可视化数据集</h2><p id="f4bc" class="pw-post-body-paragraph kz la it lb b lc mx ju le lf my jx lh li mz lk ll lm na lo lp lq nb ls lt lu im bi translated">让我们首先加载数据集。我们将使用洗发水销售数据集，可以从<a class="ae ki" href="https://machinelearningmastery.com/time-series-datasets-for-machine-learning/" rel="noopener ugc nofollow" target="_blank">这里</a>下载。原始数据集归功于 Makridakis、Wheelwright 和 Hyndman (1998 年)。它包含了一种洗发水在 3 年内的月销售额。该部分的代码和绘制该数据集时获得的图形如下:</p><figure class="kk kl km kn gt ko"><div class="bz fp l di"><div class="np nq l"/></div></figure><figure class="kk kl km kn gt ko gh gi paragraph-image"><div class="gh gi nr"><img src="../Images/418bbda290343a47ce528c7465f2c59b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1200/format:webp/1*rfMSehc9g5-MMQzowd2LwA.png"/></div><figcaption class="kv kw gj gh gi kx ky bd b be z dk">Plot of the Complete Time Series</figcaption></figure><h2 id="12bf" class="nd mg it bd mh ne nf dn ml ng nh dp mp li ni nj mr lm nk nl mt lq nm nn mv no bi translated">分成训练和测试数据</h2><p id="3da9" class="pw-post-body-paragraph kz la it lb b lc mx ju le lf my jx lh li mz lk ll lm na lo lp lq nb ls lt lu im bi translated">我们使用 90:10 的训练测试分割。由于总共有 36 个观察值(3 年数据，每月一次)，我们将使用过去 32 天的数据(训练集)预测最后 4 天(测试集)。</p><figure class="kk kl km kn gt ko"><div class="bz fp l di"><div class="np nq l"/></div></figure><figure class="kk kl km kn gt ko gh gi paragraph-image"><div class="gh gi nr"><img src="../Images/14f957f5d43c504886514ce8d1d08c09.png" data-original-src="https://miro.medium.com/v2/resize:fit:1200/format:webp/1*N3lCNQCjvRXtcWu_uN8m4g.png"/></div><figcaption class="kv kw gj gh gi kx ky bd b be z dk">Plot of the Training Set</figcaption></figure><h2 id="62d5" class="nd mg it bd mh ne nf dn ml ng nh dp mp li ni nj mr lm nk nl mt lq nm nn mv no bi translated">分析 ACF 和 PACF 图</h2><p id="d9b8" class="pw-post-body-paragraph kz la it lb b lc mx ju le lf my jx lh li mz lk ll lm na lo lp lq nb ls lt lu im bi translated">相关性是两个量(比如 A 和 B)之间的统计度量，它决定了它们的值相对于彼此的增加或减少。如果 A 随着 B 的增加而增加(反之亦然)，那么就说它们具有正相关性。例如，给定质量的物体所受的力越大，其加速度就越大。如果 A 随着 B 的减少而增加(反之亦然)，也就是说，如果两个量的变化方向相反，那么就说它们具有负相关性。</p><p id="41ba" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">显示时间序列与其过去值的相关性的图称为自相关函数(ACF)。<em class="me"> Auto </em>来源于这样一个事实:我们正在计算一个序列与该序列的值的相关性。</p><p id="f249" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">xₜ(时间索引<em class="me"> t </em>的时间序列中的元素)与其滞后 xₜ ₋ ₚ之间的偏相关是在去除 xₜ和 xₜ ₋ ₚ与 xₜ ₋ ₁、xₜ ₋ ₂、…、xₜ ₋ ₍ₚ ₋ ₁₎中的每一个相关的影响后，即滞后短于<em class="me"> p </em>的这两个量之间的相关。显示时间序列与其过去值的偏相关的图称为偏相关函数(PACF)。</p><p id="2956" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">下面显示的是我们训练数据的 ACF 和 PACF 图:</p><figure class="kk kl km kn gt ko gh gi paragraph-image"><div class="gh gi nr"><img src="../Images/e8ab76d03c96e396fbde5b28fa1bd625.png" data-original-src="https://miro.medium.com/v2/resize:fit:1200/format:webp/1*ntp6mnjYT6Ig-VCvpqSaEg.png"/></div><figcaption class="kv kw gj gh gi kx ky bd b be z dk">ACF and PACF plots</figcaption></figure><p id="1708" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">自回归模型以 ACF 和 PACF 图中的以下观察结果为标志:</p><ul class=""><li id="73ea" class="ns nt it lb b lc ld lf lg li nu lm nv lq nw lu nx ny nz oa bi translated">滞后 1 时的正自相关</li><li id="5fd3" class="ns nt it lb b lc ob lf oc li od lm oe lq of lu nx ny nz oa bi translated">PACF 在某个滞后 k 处突然截止。这个 k 值等于我们应该在 AR(p)模型中使用的 p 值。</li><li id="4095" class="ns nt it lb b lc ob lf oc li od lm oe lq of lu nx ny nz oa bi translated">ACF 图逐渐减少到 0</li></ul><p id="8e17" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们可以看到，我们的 ACF 和 PACF 图满足上述三点的条件。此外，我们为 AR(p)模型获得的 p 值是<em class="me"> p = 2 </em>，因为 PACF 曲线在第二个滞后截止。我们继续定义 AR(2)模型。</p><h2 id="5627" class="nd mg it bd mh ne nf dn ml ng nh dp mp li ni nj mr lm nk nl mt lq nm nn mv no bi translated">模型定义</h2><p id="3997" class="pw-post-body-paragraph kz la it lb b lc mx ju le lf my jx lh li mz lk ll lm na lo lp lq nb ls lt lu im bi translated">我们现在使用前面讨论的预测方程来定义 AR(p)模型。我们取<em class="me"> p = 2 </em>，这是借助于 ACF 和 PACF 图得到的。我们可以用图灵的直观界面很容易地定义模型:</p><figure class="kk kl km kn gt ko"><div class="bz fp l di"><div class="np nq l"/></div></figure><p id="c34c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这里，我们假设β系数具有一致的(-1，1)先验，α系数具有正态的(0，1)先验。现在，有了模型定义，是时候对我们的后验进行采样了！</p><h2 id="b9ee" class="nd mg it bd mh ne nf dn ml ng nh dp mp li ni nj mr lm nk nl mt lq nm nn mv no bi translated">抽样</h2><p id="e769" class="pw-post-body-paragraph kz la it lb b lc mx ju le lf my jx lh li mz lk ll lm na lo lp lq nb ls lt lu im bi translated">我们使用不掉头采样器(NUTS)采样器采样，重复 5000 次(抽取 5000 个样本)。如果您不熟悉马尔可夫链蒙特卡罗抽样，您可以将其视为一个黑盒，当提供模型定义和相关参数作为输入时，它会给出后验概率。关于在图灵中使用这个采样器和参数定义的更多信息，你可以在这里参考文档<a class="ae ki" href="https://turing.ml/dev/docs/library/#Turing.Inference.NUTS" rel="noopener ugc nofollow" target="_blank">。</a></p><figure class="kk kl km kn gt ko"><div class="bz fp l di"><div class="np nq l"/></div></figure><h2 id="869f" class="nd mg it bd mh ne nf dn ml ng nh dp mp li ni nj mr lm nk nl mt lq nm nn mv no bi translated">分析采样参数</h2><p id="88fa" class="pw-post-body-paragraph kz la it lb b lc mx ju le lf my jx lh li mz lk ll lm na lo lp lq nb ls lt lu im bi translated">运行上述代码将产生一个输出，提供关于链的基本信息和估计参数的汇总统计信息，如下所示:</p><figure class="kk kl km kn gt ko gh gi paragraph-image"><div role="button" tabindex="0" class="kp kq di kr bf ks"><div class="gh gi og"><img src="../Images/a90798153b852e2ee37bfe3b6563d60c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*RembNseG5VjMAt2Tw8NOvg.png"/></div></div></figure><figure class="kk kl km kn gt ko"><div class="bz fp l di"><div class="np nq l"/></div></figure><figure class="kk kl km kn gt ko"><div class="bz fp l di"><div class="np nq l"/></div></figure><p id="37c0" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">只需一行代码，我们就可以得到采样参数的分布，以及它们在所有迭代中的值。</p><p id="e191" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们还可以用另一行代码查看这些采样参数的角图。</p><div class="kk kl km kn gt ab cb"><figure class="oh ko oi oj ok ol om paragraph-image"><div role="button" tabindex="0" class="kp kq di kr bf ks"><img src="../Images/f1e4c9236231dec05193270235cb608a.png" data-original-src="https://miro.medium.com/v2/resize:fit:858/format:webp/1*M_-pnZzRQkIvV4DW0ZORKg.png"/></div></figure><figure class="oh ko on oj ok ol om paragraph-image"><div role="button" tabindex="0" class="kp kq di kr bf ks"><img src="../Images/44be7f5d842515a4b18f9f1266a22f90.png" data-original-src="https://miro.medium.com/v2/resize:fit:1144/format:webp/1*agXgrtZ8VyIF1echmX08YQ.png"/></div><figcaption class="kv kw gj gh gi kx ky bd b be z dk oo di op oq">Output of: L: corner(chain), R: plot(chain)</figcaption></figure></div><p id="e736" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们现在拥有了我们之前讨论过的窥视未来所需的所有工具。我们将首先从采样链中移除预热样本。这些样本是在最初几次迭代期间在链中最初采样的，并且在我们已经获得所需的后验分布之后不再需要。然后，我们将所有采样参数的平均值作为该参数值的点估计值。</p><figure class="kk kl km kn gt ko"><div class="bz fp l di"><div class="np nq l"/></div></figure><p id="7228" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">正是这些点估计值，我们将把它们代入预测方程以得到预测值。注意，为了预测前几个元素，我们将不得不使用来自训练集末尾的元素(确切地说，必须对多少个元素进行预测取决于 p 的值)。这是因为我们需要时间序列先前的滞后值来预测当前值。例如，在我们使用的 AR(2)模型中，前两个预测将使用来自训练集的值。因此，我们可以计算预测的时间序列<em class="me"> s_pred </em>，如下面的代码所示:</p><figure class="kk kl km kn gt ko"><div class="bz fp l di"><div class="np nq l"/></div></figure><p id="31a0" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">绘制预测和测试集(原始数据):</p><figure class="kk kl km kn gt ko gh gi paragraph-image"><div class="gh gi nr"><img src="../Images/e393fdea596af63f7b90c289f8334d36.png" data-original-src="https://miro.medium.com/v2/resize:fit:1200/format:webp/1*KQ0pu4xwzKBlbtHVGGTEsg.png"/></div></figure><p id="0777" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们可以看到，在要预测的四个值中，只有一个接近，而其他三个非常不准确。一个原因可能是这个时间序列不是协方差平稳的。我们可以通过使用更复杂的 ARIMA 模型来改进这一缺点，这些模型使用差分来首先使序列平稳，然后使用自回归和移动平均项对差分序列进行建模。</p></div><div class="ab cl or os hx ot" role="separator"><span class="ou bw bk ov ow ox"/><span class="ou bw bk ov ow ox"/><span class="ou bw bk ov ow"/></div><div class="im in io ip iq"><p id="382a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这就是我关于 AR(p)模型的贝叶斯推断的文章的结论。我要感谢<a class="ae ki" href="http://cameron.pfiffer.org/" rel="noopener ugc nofollow" target="_blank"> Cameron Pfiffer </a>在实施过程中以及在过去的几个月里提供的巨大帮助和指导。如果你对这篇文章有任何问题或疑问，请随时通过<a class="ae ki" href="https://saumyagshah.github.io/" rel="noopener ugc nofollow" target="_blank"> s </a> shah@iitk.ac.in 联系我，或者你可以在 Julia slack 上用@Saumya Shah 给我加标签。感谢阅读！:).</p><h1 id="da08" class="mf mg it bd mh mi mj mk ml mm mn mo mp jz mq ka mr kc ms kd mt kf mu kg mv mw bi translated">参考</h1><p id="305c" class="pw-post-body-paragraph kz la it lb b lc mx ju le lf my jx lh li mz lk ll lm na lo lp lq nb ls lt lu im bi translated">[1] Jason Brownlee，<em class="me">机器学习的 7 个时间序列数据集</em>，机器学习掌握，可从<a class="ae ki" href="https://machinelearningmastery.com/time-series-datasets-for-machine-learning/" rel="noopener ugc nofollow" target="_blank">https://machinelingmastery . com/Time-Series-Datasets-for-Machine-Learning/</a><a class="ae ki" href="https://machinelearningmastery.com/machine-learning-with-python/," rel="noopener ugc nofollow" target="_blank">，</a>2019 年 8 月 26 日访问。</p><p id="9a42" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">[2]资料来源:时间序列数据库(引用:Makridakis、Wheelwright 和 Hyndman (1998 年))</p><figure class="kk kl km kn gt ko"><div class="bz fp l di"><div class="np nq l"/></div></figure></div></div>    
</body>
</html>