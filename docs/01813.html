<html>
<head>
<title>Data science productionization: scale</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">数据科学生产化:规模</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/data-science-productionization-scale-1884ca4e969e?source=collection_archive---------26-----------------------#2019-03-25">https://towardsdatascience.com/data-science-productionization-scale-1884ca4e969e?source=collection_archive---------26-----------------------#2019-03-25</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><h2 id="e0ae" class="io ip iq bd b dl ir is it iu iv iw dk ix translated" aria-label="kicker paragraph"><a class="ae ep" href="https://towardsdatascience.com/tagged/ds-productionization" rel="noopener" target="_blank"> DS 生产化</a></h2><div class=""/><div class=""><h2 id="eec1" class="pw-subtitle-paragraph jw iz iq bd b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn dk translated">你可以等到你对意外感到惊讶，或者你可以建立系统来限制意外对你的伤害程度。</h2></div><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi ko"><img src="../Images/556abe3ecbc5ca23c662918021daca37.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*mtIGioOv3WWY1s8fHz69jg.jpeg"/></div></div></figure><p id="b345" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">这是关于数据科学生产的五部分系列的第四部分:</p><ol class=""><li id="40f6" class="lw lx iq lc b ld le lg lh lj ly ln lz lr ma lv mb mc md me bi translated"><a class="ae mf" rel="noopener" target="_blank" href="/what-does-it-mean-to-productionize-data-science-82e2e78f044c">数据科学的“生产化”意味着什么？</a></li><li id="183c" class="lw lx iq lc b ld mg lg mh lj mi ln mj lr mk lv mb mc md me bi translated"><a class="ae mf" rel="noopener" target="_blank" href="/data-science-productionization-portability-f5d1a1f2f45b">便携性</a></li><li id="380f" class="lw lx iq lc b ld mg lg mh lj mi ln mj lr mk lv mb mc md me bi translated"><a class="ae mf" rel="noopener" target="_blank" href="/data-science-productionization-maintenance-af59ce6c958">维护</a></li><li id="855c" class="lw lx iq lc b ld mg lg mh lj mi ln mj lr mk lv mb mc md me bi translated"><a class="ae mf" rel="noopener" target="_blank" href="/data-science-productionization-scale-1884ca4e969e">刻度</a></li><li id="7810" class="lw lx iq lc b ld mg lg mh lj mi ln mj lr mk lv mb mc md me bi translated"><a class="ae mf" rel="noopener" target="_blank" href="/data-science-productionization-trust-b37f10b8f426">信任</a></li></ol></div><div class="ab cl ml mm hu mn" role="separator"><span class="mo bw bk mp mq mr"/><span class="mo bw bk mp mq mr"/><span class="mo bw bk mp mq"/></div><div class="ij ik il im in"><p id="5561" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">让我们再看一遍单词规范化代码(来自我的前两篇文章)。</p><figure class="kp kq kr ks gt kt"><div class="bz fp l di"><div class="ms mt l"/></div></figure><p id="1340" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">我们之前写的代码对于一个单词来说很好。它甚至可以很好地处理几千个单词。但是如果我们需要规范化数百万或数十亿个单词，这将花费比我们可能想花费的更多的时间。这就是可伸缩性的问题:您必须处理的数据量通常与处理数据所需的时间有直接关系。企业是有期限的——如果你不能在你需要的时间框架内得到结果，那么这些结果对你没有任何好处。</p><figure class="kp kq kr ks gt kt"><div class="bz fp l di"><div class="ms mt l"/></div></figure><p id="d112" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">在示例中，我们通过并行化来扩展代码。有很多方法可以做到这一点——我使用 Spark 是因为它是目前大规模处理数据最流行的方法之一。我首先创建一个 DataFrame，它或多或少是 Python 版本的电子表格。它有两列——id 和 words——每一列都有三个值。然后，我将数据帧转换为 Spark 数据帧，这样就可以分别并行处理每条记录。然后，我将我们的“normalize_word”函数转换为 Spark“用户定义函数”(UDF)，这允许将函数分配给不同的虚拟机来处理数据。出于同样的原因，我将我们的停靠点列表转换成一个 Spark 数组。</p><p id="4f52" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">一旦我将所有不可伸缩的代码转换成可伸缩的代码，我就可以使用 UDF 处理数据帧了。这将数据帧的每一行输出给一个“执行程序”,执行程序使用提供的函数处理记录，并给出结果:</p><pre class="kp kq kr ks gt mu mv mw mx aw my bi"><span id="46f9" class="mz na iq mv b gy nb nc l nd ne"><strong class="mv ja">+---+--------+<br/>|ids|   norms|<br/>+---+--------+<br/>|  1|      rr|<br/>|  2|houspous|<br/>|  3|    shzm|<br/>+---+--------+</strong></span></pre><p id="ef36" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">Spark 允许我调整发送给每个执行程序的记录数量，以及我想要(或负担得起)多少个执行程序。我可以决定我希望每个执行者拥有多少内存(对于上面的例子，我需要很少的内存，但是如果我分发整个机器学习模型，有时我需要很多)。</p><p id="96d9" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">当我们从思考代码转移到思考代码系统时，我认为可伸缩性归结为三个主要部分:资源管理、集成和实现创造力。</p><h2 id="5e16" class="mz na iq bd nf ng nh dn ni nj nk dp nl lj nm nn no ln np nq nr lr ns nt nu iw bi translated"><strong class="ak">资源管理</strong></h2><p id="0755" class="pw-post-body-paragraph la lb iq lc b ld nv ka lf lg nw kd li lj nx ll lm ln ny lp lq lr nz lt lu lv ij bi translated">我发现从内存、计算能力和磁盘空间的角度来考虑资源是很有用的。我不认为这些事情有任何类比不会因为过于简单而给我带来麻烦，但我要冒险一试:如果你试图从一个州向另一个州运送大量货物，你的卡车的数量和大小将是你的内存，你的卡车的速度和马力将是你的计算能力，你的仓库的大小和数量将是你的磁盘空间。每个部分都制约着其他部分。如果货物到达目的地后没有地方存放，那么你有多少辆卡车或者这些卡车开得多快都没有用。如果你的货物装不下你的卡车，你的仓库再大也没用。如果卡车没有燃料，你的仓库和卡车的大小都不重要。你明白了。</p><p id="5382" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">尽管我们实际上只管理三种基本的资源，但是管理每一种资源的方法有很多很多。想想一辆卡车可能发生故障的所有方式。有很多方法可以打乱你的内存使用。对于 spark 作业，我通常必须使用以下参数:</p><ul class=""><li id="cd8b" class="lw lx iq lc b ld le lg lh lj ly ln lz lr ma lv oa mc md me bi translated">我希望可用于运行作业的执行者总数</li><li id="ce0a" class="lw lx iq lc b ld mg lg mh lj mi ln mj lr mk lv oa mc md me bi translated">每个执行器上的内核数量(这允许额外的并行化)</li><li id="599b" class="lw lx iq lc b ld mg lg mh lj mi ln mj lr mk lv oa mc md me bi translated">每个执行器上的内存量</li><li id="c954" class="lw lx iq lc b ld mg lg mh lj mi ln mj lr mk lv oa mc md me bi translated">为了在执行器上移动数据，我愿意承担的内存开销</li><li id="fa4b" class="lw lx iq lc b ld mg lg mh lj mi ln mj lr mk lv oa mc md me bi translated">我愿意移入和移出执行者的最大数据量</li><li id="399b" class="lw lx iq lc b ld mg lg mh lj mi ln mj lr mk lv oa mc md me bi translated">当将数据集连接在一起或聚合时，我希望将数据拆分成的“无序”分区的数量</li></ul><p id="bb7d" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">还有 10-20 个我更喜欢的默认参数，它们几乎适用于任何工作。还有几十个其他参数我甚至不知道，因为我从来没有必要去弄乱它们。可伸缩性与获得更多资源关系不大。主要是学习如何明智地分配可用资源。</p><h2 id="1a8d" class="mz na iq bd nf ng nh dn ni nj nk dp nl lj nm nn no ln np nq nr lr ns nt nu iw bi translated"><strong class="ak">集成</strong></h2><p id="1dc3" class="pw-post-body-paragraph la lb iq lc b ld nv ka lf lg nw kd li lj nx ll lm ln ny lp lq lr nz lt lu lv ij bi translated">有时，流程中的瓶颈并不是技术资源分配的结果。换句话说，有时候人类会把你的东西弄乱。我见过的一些最常见的方式是:</p><ul class=""><li id="ddd4" class="lw lx iq lc b ld le lg lh lj ly ln lz lr ma lv oa mc md me bi translated"><strong class="lc ja">需求的意外增长。</strong>你习惯于在被要求时给出结果。一开始你每周都会收到一些请求。现在你每小时都会收到一些请求。</li><li id="3a12" class="lw lx iq lc b ld mg lg mh lj mi ln mj lr mk lv oa mc md me bi translated"><strong class="lc ja">供应商延误。直到公司的另一个部门给你他们最新的数据，你才能运行你的流程。他们忘记发送邮件(或者他们降低了工作优先级，或者通常发送邮件的人生病了，等等。)你被阻止，直到他们给你他们的拼图。</strong></li><li id="82d0" class="lw lx iq lc b ld mg lg mh lj mi ln mj lr mk lv oa mc md me bi translated"><strong class="lc ja">随时间自然降解。</strong>你训练一个模型，每个人对结果都很满意。随着时间的推移，人们开始变得不那么快乐。你把旧的模型拿出来重新评估，发现它的性能远不如投入使用时那么好。所以几个月(或几年)以来，你一直在糟糕的预测基础上运作。</li></ul><p id="c207" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">所有这些问题的解决方案是，首先要问一个人是否真的需要参与进来。每次请求报告时，单个分析师是否需要手动滚动每个报告？财务部门的一个人真的需要把来自几个系统的数据汇编成 Excel 报表，然后通过电子邮件发给你吗？你真的需要在你的日程表上安排一个老型号的重新评估吗？所有这些事情都可以部分或全部自动化。有几种常见的方法可以做到这一点:</p><ul class=""><li id="35fd" class="lw lx iq lc b ld le lg lh lj ly ln lz lr ma lv oa mc md me bi translated"><strong class="lc ja">数据仓库</strong>。厌倦了不得不向别人要你的数据？将所有数据存储在同一个地方。</li><li id="697f" class="lw lx iq lc b ld mg lg mh lj mi ln mj lr mk lv oa mc md me bi translated"><strong class="lc ja">原料药</strong>。无法在一个地方获取数据？教一台计算机去要求它(并教其他计算机去递送它)，这样递送就可以按照设定的时间表进行。</li><li id="ddcd" class="lw lx iq lc b ld mg lg mh lj mi ln mj lr mk lv oa mc md me bi translated"><strong class="lc ja">仪表盘。厌倦了回应数据请求？把它挂在网站上，自动更新，让它成为自助服务。</strong></li></ul><p id="c739" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">集成允许您更明确、更有效地管理不受您直接控制的资源。它们还允许您获得警报和报告的好处。</p><h2 id="3f20" class="mz na iq bd nf ng nh dn ni nj nk dp nl lj nm nn no ln np nq nr lr ns nt nu iw bi translated"><strong class="ak">实现创意</strong></h2><p id="7bec" class="pw-post-body-paragraph la lb iq lc b ld nv ka lf lg nw kd li lj nx ll lm ln ny lp lq lr nz lt lu lv ij bi translated">通常，可伸缩性更多地与您如何考虑问题有关，而不是与您如何管理技术资源和合作关系有关。让我参考我自己工作中的一个例子来解释我的意思(我已经在这里<a class="ae mf" rel="noopener" target="_blank" href="/deploy-a-python-model-more-efficiently-over-spark-497fc03e0a8d">更详细地描述了这个例子</a>)。在我目前的工作中，我们查看位置数据的一种方式是将手机定位信号与地块叠加。宗地来自市或县估价员办公室，用于划分建筑红线。它们通常看起来像这样:</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi ob"><img src="../Images/76bb5f6cf7c5adc2aeffe5ec60f2148d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*3qvGEDFEXHv3iVY5jr40Lw.png"/></div></div></figure><p id="6b9a" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">当我们看到位置信号位于住宅区或宜家缴税的地块内时，这对我们非常有用。这有助于我们理解为什么那些信号会在它们所在的地方。并不是所有的包裹都有很好的标签，所以我们需要为没有标签的包裹推断标签。特别是，我们希望区分住宅和非住宅地块。为居住性建模的方法非常简单:我们有数千万个被标注的地块，我们有许多与这些地块相关联的元数据，我们可以根据这些元数据训练模型来识别正确的标签。</p><p id="e51b" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">当我们想要实际生成标签时，困难就来了。我们有大约 1.4 亿个包裹需要决定。我们已经使用 Python 的 scikit-learn 库训练了这个模型。然而，通过 PySpark 用户定义函数调用 scikit-learn ' predict '方法会产生一些问题。首先，它导致了序列化模型对象以传输到执行器，然后反序列化该对象以在执行器上实际使用的开销。它必须为作业中使用的每个执行者都这样做。第二，它未能利用 scikit-learn 的优化，这主要是因为它依赖于另一个包 numpy，以便一次对整个数据数组快速执行计算，而不是遍历单个记录。</p><p id="60d3" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">使用 spark 逐行应用模型的开销如此之大，以至于我们甚至无法完成这个过程。我们最终发现，解决方案是创造性地思考如何应用经过训练的模型:</p><figure class="kp kq kr ks gt kt"><div class="bz fp l di"><div class="ms mt l"/></div></figure><p id="b99b" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">上面的代码做了几件事:</p><ul class=""><li id="accf" class="lw lx iq lc b ld le lg lh lj ly ln lz lr ma lv oa mc md me bi translated">将唯一的宗地 id 映射到模型进行预测所需的要素列表。</li><li id="7d4f" class="lw lx iq lc b ld mg lg mh lj mi ln mj lr mk lv oa mc md me bi translated">将这些映射的项目分组到合理大小的组中。我们发现大约 50，000 人的小组运作良好。</li><li id="c16a" class="lw lx iq lc b ld mg lg mh lj mi ln mj lr mk lv oa mc md me bi translated">重写用户定义的函数，使其按组而不是按记录应用。所以不需要移动和应用模型 1.4 亿次，只需要发生(1.4 亿/ 5 万)= 2800 次。</li></ul><p id="bc27" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">正如我所说的，即使运行了 48 小时，最初的实现也没有完成。新的实施在 30 分钟内完成。教训:谈到可伸缩性，有时我们需要新奇的新技术；有时候我们只需要五分钟的散步，这样我们就能获得一个新的视角。有时候我们两者都需要。</p><p id="3296" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">可伸缩性是为了让您的工作面向未来。你真的无法预测有多少人最终会想要你所构建的东西，或者他们想要它的时间框架。您可以等到需求意外增长时再做决定，也可以构建自己的系统来限制需求变化对工作的瓶颈影响。</p></div></div>    
</body>
</html>