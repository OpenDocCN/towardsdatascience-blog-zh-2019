<html>
<head>
<title>The Bias-Variance Tradeoff</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">偏差-方差权衡</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/the-bias-variance-tradeoff-8818f41e39e9?source=collection_archive---------3-----------------------#2019-11-08">https://towardsdatascience.com/the-bias-variance-tradeoff-8818f41e39e9?source=collection_archive---------3-----------------------#2019-11-08</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><p id="70d2" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">在这篇文章中，我们将解释偏差-方差权衡，这是机器学习中的一个基本概念，并展示它在实践中的意义。我们将表明，一个看不见的(测试)点的均方误差是两种竞争力量(偏差/方差)和问题本身固有噪声的结果。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi ko"><img src="../Images/53903da2e28fef66fdccec6a020b5a3b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*2ON11sx51DXpT31Rc7SfLw.png"/></div></div></figure><h1 id="5f84" class="la lb it bd lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx bi translated">动机</h1><p id="7829" class="pw-post-body-paragraph jq jr it js b jt ly jv jw jx lz jz ka kb ma kd ke kf mb kh ki kj mc kl km kn im bi translated">我们经常在机器学习教科书中看到下图描述了泛化(测试)错误及其与模型复杂性的联系。泛化(测试)误差，即看不见的数据中的误差，可以分解为<em class="md">偏倚误差</em>(错误的模型假设产生的误差)、方差(对训练数据小波动的敏感性产生的误差)和不可约误差(问题本身固有的噪声)。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi me"><img src="../Images/8d78a2d25513e8b9ed1a33563f19bd25.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*oO0KYF7Z84nePqfsJ9E0WQ.png"/></div></div></figure><p id="b21e" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">高偏差通常源于过于简化的模型假设，而高方差则源于过于复杂的假设。顾名思义，不可约误差与底层模型无关，而是与问题中的固有噪声有关。这种噪声可以表示来自数据质量的噪声(例如，数据收集或报告中的不准确性)、来自描述现实问题的真实函数的仅近似知识的噪声、来自潜在现象的非确定性行为的噪声，并且一般来说，是不能容易地定义的任何类型的噪声。当我们的模型遭受高偏差时，模型的平均响应远离真实值，我们称之为<em class="md">欠拟合</em>。当我们的模型遭受高方差时，这通常是因为它无法在训练数据之外进行推广，我们称之为<em class="md">过度拟合</em>。我们的目标是建立一个模型，实现偏差和方差之间的平衡，使这两种竞争力量的综合误差最小*。这是上图中的中间区域！</p><p id="7965" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">*通常，随着模型复杂性的增加，传统的机器算法(如回归算法、梯度提升树、支持向量机等)会遇到偏差-方差权衡的问题。然而，深度学习的最新进展质疑了只要有大量训练数据，模型复杂度就会增加的既定概念。</p><h1 id="5ca9" class="la lb it bd lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx bi translated">问题定义</h1><p id="e6d0" class="pw-post-body-paragraph jq jr it js b jt ly jv jw jx lz jz ka kb ma kd ke kf mb kh ki kj mc kl km kn im bi translated">让我们从定义一些关键概念开始。我们假设自变量<em class="md"> x </em>通过确定性或非确定性关系影响因变量<em class="md"> y </em>的值。我们说<em class="md">非确定性</em>是因为<em class="md"> y </em>的值也会受到无法明确建模的噪声的影响。让我们通过函数<em class="md"> f </em>来表示<em class="md"> y </em>对<em class="md"> x </em>的依赖关系，这实质上代表了<em class="md"> x </em>和<em class="md"> y </em>之间真实的底层关系。在真实情况下，当然很难——如果不是不可能的话——知道这种关系，但是我们将假设<em class="md"> f </em>是固定的，即使它是未知的。在这种情况下，<em class="md"> y </em>是<em class="md"> x </em>和随机噪声的结果，由公式给出:</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi mf"><img src="../Images/bef90701195b9467b4607df0b5c389d0.png" data-original-src="https://miro.medium.com/v2/resize:fit:236/format:webp/1*2HwR8f0b-vz35kT5v4evRA.png"/></div></figure><p id="32e4" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">噪声由具有零均值和方差σϵ的随机变量ϵ建模。方差的大小代表了潜在现象的不确定性水平。我们的不确定性越大，σϵ的价值就越大。在数学上，ϵ具有以下特性:</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi mg"><img src="../Images/951d8b355d99fc1db6e793f14fe1e39a.png" data-original-src="https://miro.medium.com/v2/resize:fit:524/format:webp/1*KiiBLJ0fZ4fLMQ41Vv6w7A.png"/></div></figure><p id="13ea" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">现在，当我们试图对潜在的现实生活问题建模时，这实际上意味着我们试图找到一个函数<em class="md"> f̂ </em>，使得它尽可能接近真实的(但我们未知的)函数<em class="md"> f </em>。函数<em class="md"> f̂ </em>在回归情况下可以采用系数的形式，在支持向量机(SVMs)的情况下可以采用支持向量和对偶系数的形式，并且它是从训练数据中学习的。生成训练数据的基础分布越接近生成测试(看不见的)数据的基础分布，由函数<em class="md"> f̂ </em>表示的模型将越好地推广到看不见的数据。函数<em class="md"> f̂ </em>通过最小化损失函数来学习，其目标是使训练数据的预测尽可能接近它们的观察值:<em class="md"> y ≈ f̂(x) </em>。</p><p id="2386" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">M <em class="md"> ean 平方误差</em>(简称 MSE)是一个预测<em class="md"> f̂(x) </em>与其真值<em class="md"> y </em>的均方差。它被定义为:</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi mh"><img src="../Images/e6d16bbf6e0292bb9bf6425d4f79bc45.png" data-original-src="https://miro.medium.com/v2/resize:fit:412/format:webp/1*19oSApfSwSfC-N9xney9kA.png"/></div></figure><p id="47e7" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><em class="md">偏差</em>被定义为对于给定的不可见(测试)点<em class="md"> x </em>的预测平均值(<em class="md">在训练数据</em>的不同实现上)与真实底层函数<em class="md"> f(x) </em>的差异。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi mi"><img src="../Images/082e816973f599e7c2ef94a4b9b6c3d3.png" data-original-src="https://miro.medium.com/v2/resize:fit:508/format:webp/1*q4F69fvs4NTBkqOqN7dyYQ.png"/></div></figure><p id="ad2c" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">让我们花一些时间来解释一下我们所说的“<em class="md">训练数据的不同实现”</em>是什么意思。假设我们想要监控某个社区的家庭收入水平和房屋销售价格之间的关系。如果我们能够获得每家每户的数据，我们就能够训练出一个非常精确的模型。但是，由于获取数据可能成本高昂、耗时，或者受到隐私问题的影响，大多数时候我们无法获得底层人群的所有数据。一个<em class="md">实现</em>意味着我们只能访问一部分底层数据作为我们的<em class="md">训练数据</em>。这种认识可能不代表潜在人口(例如，如果我们只调查某个家庭有一定教育水平的房屋)或具有代表性(如果没有种族、教育、年龄或其他类型的偏见)。因此，当我们说期望𝔼[<em class="md">【f̂(x】</em><em class="md"/>是针对训练数据的不同实现时，这可以被认为是我们有机会从基础总体中投票选出一个样本，在这个样本上训练我们的模型<em class="md"> f̂ </em>，计算<em class="md"> f̂(x) </em>并重复多次(每次使用不同的训练样本)。预测的平均值将代表𝔼[<em class="md">【f̂(x】</em><em class="md">。</em>在这里，<em class="md"> f̂(x) </em>即使<em class="md"> x </em>是<em class="md">固定</em>也是变化的，仅仅是因为<em class="md"> f̂依赖于训练数据。</em> <strong class="js iu">所以，<em class="md"> f̂ </em>对于训练数据的不同实现会有所不同。</strong>用更数学的术语来说，<em class="md"> f̂ </em>是一个随机变量，受我们获取训练数据的随机性影响。</p><p id="2bf1" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><em class="md">方差</em>定义为<em class="md"> f̂(x) </em>与其期望值𝔼[<em class="md">f̂(x)</em><em class="md"/>在训练数据的不同实现上的均方偏差。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi mj"><img src="../Images/40fd144480f1990f3e33e909b8706cd3.png" data-original-src="https://miro.medium.com/v2/resize:fit:608/format:webp/1*lsu13hMQE9Gt5cJTvfkF0A.png"/></div></figure><p id="04b1" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">将测试 MSE 与偏差、方差和不可约误差联系起来的公式为:</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi mk"><img src="../Images/f25946ce4c83cce4ebe158a07b7289b8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1008/format:webp/1*uq-w_Q67nKjIP81q2pXboQ.png"/></div></figure><p id="23c3" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">术语𝔼[𝔼[(<em class="md">y</em>—<em class="md">f̂(x</em>)]]中的第一个期望是未知(测试)点的分布<em class="md"> x </em>，而第二个期望是训练数据和随机变量ϵ.的分布因为<em class="md"> f̂ </em>依赖于训练数据，我们也可以说第二次期望已经超过了<em class="md"> f̂、</em> ϵ.<em class="md"> </em>如果我们把上面的公式写得更明确一点，那就是:</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi ml"><img src="../Images/abafdec783dd15a15fd21e0893513472.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*IGnLMHp9H1nmGOPChFGstQ.png"/></div></div></figure><p id="6e61" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">但是为了简单起见，我们将跳过期望标识符。右边的三项都是非负的，不可约误差不受模型选择的影响。这意味着测试 MSE 不能低于σϵ。我们现在将推导出给定测试点 x 的公式。因为它适用于给定的测试点 x，所以它适用于任何看不见的测试点的分布。</p><h1 id="b396" class="la lb it bd lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx bi translated">偏差-方差分解的证明</h1><p id="e831" class="pw-post-body-paragraph jq jr it js b jt ly jv jw jx lz jz ka kb ma kd ke kf mb kh ki kj mc kl km kn im bi translated">提醒一下，<em class="md"> </em>我们假设<em class="md"> x </em>是一个看不见的(测试)点，<em class="md"> f </em>是潜在的真函数(规定了<em class="md"> x </em>和<em class="md"> y </em>之间的关系)，它是未知但固定的，ϵ代表问题中的固有噪声。测试 MSE，𝔼[(<em class="md">y</em>—<em class="md">f̂(x)</em>]<em class="md"/>是对训练数据和随机变量ϵ <em class="md"> : </em>的不同实现</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi mm"><img src="../Images/e60dd0c3f80f92f00407ecd325a9f7ac.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*GemIb3_v3-Akhz4ap_Qtyg.png"/></div></div></figure><p id="1935" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">(1)是因为<em class="md"> y = f(x) </em> + ϵ，(2)是因为平方展开、期望的线性性质和随机变量ϵ的独立性<em class="md"> f̂ </em>。记住，当两个随机变量独立时，它们乘积的期望等于它们期望的乘积。在 Eq 中。(3)我们看到测试 MSE 如何分解成不可约误差σϵ和𝔼[(<em class="md">f(x)</em>—<em class="md">f̂(x)</em>】。现在让我们看看如何进一步分析后一项。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi mn"><img src="../Images/69f03971c8167f89cc55efc333248d4d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ByQ5MgtKTSU8MBxZ2s8MOw.png"/></div></div></figure><p id="fb8e" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">在 Eq 中。(4)我们通过𝔼[<em class="md">【f̂(x】</em><em class="md"/>和等式中的加减。(5)我们展开正方形内的项。偏置𝔼[<em class="md">f̂(x)</em>-<em class="md">f(x)</em>只是一个常数，因为我们从𝔼[ <em class="md"> f̂(x) </em>中减去<em class="md"> f(x) </em>(一个常数)，后者也是一个常数。因此，将期望应用于平方偏差，(𝔼[<em class="md">f̂(x)</em><em class="md">f(x)</em>)没有任何效果。换句话说，𝔼[(𝔼[<em class="md">f̂(x)</em>—<em class="md">f(x)</em>)=(𝔼[<em class="md">f̂(x)</em>—<em class="md">f(x)</em>)。在 Eq 中。(6)我们能够把<em class="md"> f(x) </em> −𝔼[ <em class="md"> f̂(x) </em>拉出预期，因为正如我们提到的它只是一个常数。最后，由于期望的线性，(7)成立。因此，我们在(8)中看到，𝔼[(<em class="md">f(x)</em>—<em class="md">f̂(x)</em>]是偏差和方差的平方和。当我们结合等式。(3)和(8)，我们最后得到:</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi mo"><img src="../Images/97e5899b91af7746607e73e4be04c0d7.png" data-original-src="https://miro.medium.com/v2/resize:fit:848/format:webp/1*-iiFXsYeS3U9GKgQGP3Q1w.png"/></div></figure><p id="4736" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">这是针对给定的测试点<em class="md"> x </em>的，但是我们通常有一组测试点，这可以转换成我们在上一节中给出的公式。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi mk"><img src="../Images/f25946ce4c83cce4ebe158a07b7289b8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1008/format:webp/1*uq-w_Q67nKjIP81q2pXboQ.png"/></div></figure><p id="064c" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">(期望𝔼在右手边是测试数据的分布。)</p><h1 id="c6c4" class="la lb it bd lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx bi translated">在实践中显示偏差-方差权衡</h1><p id="8730" class="pw-post-body-paragraph jq jr it js b jt ly jv jw jx lz jz ka kb ma kd ke kf mb kh ki kj mc kl km kn im bi translated">在我们推导出偏差-方差分解公式之后，我们将展示它在实践中的意义。假设，规定<em class="md"> x </em>和<em class="md"> y </em>之间关系的基础真函数<em class="md"> f </em>为:</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi mp"><img src="../Images/014bc976d2d902aff3ecadeeb880bcc6.png" data-original-src="https://miro.medium.com/v2/resize:fit:676/format:webp/1*q3OGXXALZ0mkAD3Jon9PMw.png"/></div></div></figure><p id="6142" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">并且噪声由具有零均值和标准偏差 1 的高斯模型(ϵ ~𝒩(0，1)来建模。提醒一下，<em class="md"> y = f(x) </em> + ϵ.如果我们从这个过程中随机产生 1000 个点，我们会得到下面的图。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi mq"><img src="../Images/b1c1f548527a69b93c35c6b5de54001f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*GU0tWmlizo9j-Vb2QZKCTg.png"/></div></div></figure><p id="d48f" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">蓝点代表(<em class="md"> x </em>、<em class="md"> y </em>)对，红线是底层真函数<em class="md"> f(x) </em>。红点是我们要预测的看不见的(测试)点。我们看到<em class="md"> f </em>遵循非线性模式，因为在函数定义中增加了平方根和余弦。出于我们的目的，这 1，000 个点代表了整个潜在人群。下面是重现这个情节的代码。</p><figure class="kp kq kr ks gt kt"><div class="bz fp l di"><div class="mr ms l"/></div></figure><p id="890c" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">我们将用不同复杂程度的多项式回归来模拟这个问题。提醒一下，在多项式回归中，我们试图拟合<em class="md"> x </em>和<em class="md"> y </em>之间的非线性关系。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi mt"><img src="../Images/376260a2da9183313b87d19480bfdc33.png" data-original-src="https://miro.medium.com/v2/resize:fit:880/format:webp/1*sgpiE4yi0g7VW7aTYwlKdg.png"/></div></figure><p id="3bc2" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">换句话说，我们试图用<em class="md"> f̂(x) </em>来近似<em class="md"> y </em>，如等式所示。(9).我们将不详细讨论如何学习模型参数 w₀、w₁、…、wd，因为这超出了本文的范围，但是让我们假设它们是通过最小化损失函数来评估的，该函数试图使<em class="md">f̂(x</em>尽可能接近<em class="md">y</em><em class="md">。</em></p><p id="cb6b" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">现在，假设我们只能使用 20 个点(1000 个点中的 20 个)来训练我们的多项式回归模型，我们考虑四个不同的回归模型，一个具有度<em class="md"> d </em> =1(简单直线)，一个具有<em class="md"> d </em> =2、<em class="md"> d </em> =3 和<em class="md"> d </em> =5。如果我们从潜在人群中随机抽取 20 个点，并重复这个实验 6 次，这就是我们可能得到的结果。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi mu"><img src="../Images/b6eba9221c5a069e37e7552696c84dbc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*03EtD22_GVR0ncxgED5h_A.png"/></div></div></figure><p id="fb03" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">蓝点代表特定实现(实验)的 20 个训练数据点。红线是潜在的(我们未知的)真实函数<em class="md"> f </em>，其他线代表四种不同模型对训练数据的不同实现<em class="md">的拟合。绿色、紫色、青色、橙色点代表每个模型下测试(未显示)点<em class="md"> x </em>的预测<em class="md">f̂(x】</em>。正如我们所看到的，复杂度较低的代码行差异较小。以<em class="md"> d </em> =1(简单直线)为例。在不同的实验中，直线的斜率没有太大的变化。另一方面，更复杂的模型(<em class="md"> d </em> =5)对训练数据</em>中的<em class="md">小波动更敏感。例如，看实验 1 和实验 6 之间的橙色线(<em class="md"> d </em> =5)的差异，以及这如何影响预测<em class="md"> f̂(x).</em>这就是我们前面提到的<em class="md">方差</em>问题。一个简单的模型对训练数据的变化非常稳健，但一个更复杂的模型则不然。另一方面，平均而言，<em class="md"> f̂(x) </em>与<em class="md"> f(x) </em>的偏差<em class="md">偏差</em>对于更简单的模型来说更大，因为我们的假设不能代表潜在的真实关系<em class="md"> f </em>。以下是上述情节的代码。</em></p><figure class="kp kq kr ks gt kt"><div class="bz fp l di"><div class="mr ms l"/></div></figure><p id="6f91" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">现在，假设我们<em class="md">模拟</em> 10，000 个不同的实验，每次从底层人群中随机抽取 20 个点作为我们的训练数据。在每次实验中，我们都会学到与实验训练数据相关的不同的 f̂。如果对于一个给定的看不见的测试点 x，我们为每个实验评估<em class="md"> f̂(x) </em>，我们将为<em class="md"> f̂(x).收集 10，000 个值</em>对于线性(<em class="md"> d </em> =1)和二次(<em class="md"> d </em> =2)回归模型，我们这样做。如果我们记录这 10，000 个值，我们会得到下面的图。<em class="md"> ( </em>注意，在代码和图中，测试点用<em class="md"> x_ </em>表示，训练数据用<em class="md"> x </em> _train 表示。换句话说，尽管我们在本文中用<em class="md"> x </em>来表示测试点，但是在代码中，为了避免混淆，我们用变量<em class="md">x _</em>test)<em class="md">来表示。</em></p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi mv"><img src="../Images/9120a95f547ca01c22e10e3e7e7be9fb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*xHYSK-YP9fxEbFSko8MHJw.png"/></div></div></figure><p id="7ade" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">正如我们看到的，黑线代表的<em class="md"> f̂(x、</em> 𝔼[ <em class="md"> f̂(x) </em>的均值，对于线性回归模型来说比二次回归模型(紫色 hist)更远离真实<em class="md"> f(x) </em>(红线)。这就是<em class="md">偏差</em>，换句话说，当我们的模型假设过于简单时，与真实模型的偏差。另一方面，<em class="md"> f̂(x、</em> var( <em class="md"> f̂(x) </em>)的方差在二次模型上比线性模型上更大，正如我们从底部(紫色)直方图的更大分布中看到的。这就是<em class="md">方差</em>问题，换句话说，<em class="md"> f̂(x) </em>对训练数据的小波动的依赖性较大。下面是再现直方图的代码。</p><figure class="kp kq kr ks gt kt"><div class="bz fp l di"><div class="mr ms l"/></div></figure><p id="dd04" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">现在让我们考虑 1000 个测试点，并计算平均测试 MSE(在这些点上)。我们还计算平均平方偏差(在这 1000 个测试点上)和平均方差。如果我们对五个模型这样做，从度数<em class="md"> d </em> =0(水平线)一直到度数<em class="md"> d </em> =4，我们得到下面的图。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi mw"><img src="../Images/88aeaa151fdbafca67422f9cb83223d6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*UGHWHBDw0mVKnAIYAW2xDg.png"/></div></div></figure><p id="01c7" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">如果我们把黄色(偏差的平方)、蓝色(方差)和红色(不可约误差)的线加在一起，我们得到绿色的线(测试误差)。这是我们熟悉的偏差-方差公式！</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi mx"><img src="../Images/b537e2aad37c4973d97454b65aaab595.png" data-original-src="https://miro.medium.com/v2/resize:fit:944/format:webp/1*81OGG9hw-iCqNoU4Y1otyQ.png"/></div></figure><p id="b696" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">黑线代表训练 MSE，它随着模型复杂性而降低，因为更复杂的模型往往更适合训练数据。在这个特定的例子中，我们看到潜在问题的最佳模型是二次模型(<em class="md"> d </em> =2)，因为它实现了最小的测试误差。上述情节的代码发布在下面。</p><figure class="kp kq kr ks gt kt"><div class="bz fp l di"><div class="mr ms l"/></div></figure><p id="b451" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">如果你有兴趣了解更多关于偏差-方差的问题，这里有一个非常有用的吴恩达的教程。</p><figure class="kp kq kr ks gt kt"><div class="bz fp l di"><div class="my ms l"/></div></figure><h1 id="4483" class="la lb it bd lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx bi translated">结论</h1><p id="924b" class="pw-post-body-paragraph jq jr it js b jt ly jv jw jx lz jz ka kb ma kd ke kf mb kh ki kj mc kl km kn im bi translated">在本文中，我们提出了偏差-方差问题。我们继续进行数学推导，并举例说明偏差方差在实践中的真正含义。我们证明了模型选择必须与两种竞争力量作战:偏差和方差。一个好的模型应该在这两者之间取得平衡，但是由于不可约误差的存在，我们永远不可能达到零测试误差。我们的模型不应该过于简单，但也不应该过于复杂，这样它就可以很好地推广到以前看不到的数据。</p></div></div>    
</body>
</html>