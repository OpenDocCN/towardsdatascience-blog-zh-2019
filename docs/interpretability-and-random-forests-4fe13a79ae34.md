# 可解释性和随机森林

> 原文：<https://towardsdatascience.com/interpretability-and-random-forests-4fe13a79ae34?source=collection_archive---------8----------------------->

![](img/374dd63949a3c41cc723badcc72c7bbb.png)

## 我们如何以及为什么可以从随机森林分类器中获得特征重要性？

机器学习的出现是因为人类不能总是很好地解释我们自己，尤其是对机器。在很长一段时间里，机器只能执行精确的逐步指令，而简单的人工任务对我们来说太自然了，以至于我们无法明确地将它们作为算法写下来。以识别某物是猫为例——我无法向你或计算机解释我是如何确切地知道某物是猫的。事实上，从来没有人真正向我解释过:我只是遇到了一群猫，最终，作为一个优秀的小神经网络，我明白了要点。

![](img/7b527bcaf0db7fc67a54906e6f7d4602.png)

You’ve got a lot to learn, kid.

我知道猫通常有两只耳朵，四条腿，圆圆的脸型，还有那双独特的猫眼，但这只是解开了第一层解释。在此基础上，我必须用算法解释上一句中每个形容词和名词的意思:二，耳朵，圆，等等。，以及详述诸如猫眼到底是什么样子之类的细节。理论上，我也许可以继续一项一项地解开这个问题——只是这可能会花费我大量的时间。

我们人类相当聪明地决定，对学习过程进行数学建模可能比用算法分解每个决策过程更容易，这就是我们如何开始机器学习的。然而，我们使用的学习模型并不总是符合任何一种“自然”的学习方法，建模学习并不能解决我们与计算机的基本交流问题。机器学习没有摆脱*解释数据中*关系的困难，这导致在建立和分析学习模型时可解释性和准确性之间的冲突。

## 可解释性和准确性之间的冲突

当谈到机器学习模型的使用时，数据科学几乎只有两个目标:

1.  应用程序，通过它我们使用训练好的模型来执行任务，理想情况下尽可能准确有效。
2.  解释，通过学习特征和响应变量之间的关系，我们使用训练好的模型来获得对数据的洞察力。

正如我们刚刚讨论的，我们人类几乎不知道我们实际上是如何识别事物的，但是我们真的很擅长。换句话说，我们大脑的内部逻辑是准确的，非常适合应用，但它不是很好解释。那么，通常最准确的机器学习方法是最不可解释的，这就不应该令人惊讶了。

![](img/462c7c833e8da7c1f1a88ebd35a22a40.png)

RoboCat: First Contact

所谓的黑盒模型，如神经网络，给我们很少关于他们的决策过程的信息；他们学习的函数的代数复杂性倾向于失去关于原始特征变量集的任何意义。另一方面，线性回归和决策树等有助于解释的模型往往在准确性方面有所欠缺，因为它们往往无法捕捉数据集中任何细微或复杂的关系。我们可以将这种关系概括如下:

> 对于足够复杂的数据，在决策算法的可解释性和应用的准确性之间存在自然的权衡。

就像计算机没有理解猫的腿、眼睛和耳朵的天然亲和力一样，人类也没有对高阶数字关系的内在理解。我们无法有意义地解释神经网络的复杂决策边界，我们无法向计算机解释猫是什么，这是一个硬币的两面。在两个方向的转换中，有些东西会丢失。

## 找到平衡

我们史前穴居人的大脑似乎非常喜欢解释线性关系/决策边界。线性回归是一个高度可解释的算法，这是毫无疑问的:如果 *x* 增加 *1* ，y 增加 *m，*，我们就都可以回家了*。*然而，线是简单的和高度偏向的，因此它们通常不适合伟大的学习算法*。当然，我们可以调整我们对线性的定义，并扩展我们的基础，以包括多项式、指数和其他任何术语，但在某些时候债务必须偿还，我们失去了参数的自然意义。*

![](img/b365e1d702378c1c9785abdcebc77817.png)

Barney and Fred, excited about Linear Regression.

另一个简单易懂但本质上很弱的分类器是决策树:通过贪婪地将特征空间分割成矩形，我们最终得到了一个描述决策过程背后逻辑的漂亮图表——以及一个除了最基本的关系之外几乎毫无用处的模型。但是，回想一下，树模型非常适合集成方法，随机森林是一种特别强大的方法，可以将大量单独较弱的树聚合到一个强预测模型中。

# 随机森林和特征重要性

得知随机森林能够无视这种可解释性-准确性的权衡，或者至少将它推到极限，这似乎令人惊讶。毕竟，随机森林的决策过程存在固有的随机因素，而且有这么多树，任何固有的意义都可能在森林中迷失。然而，就像树一起工作来减少预测误差一样，它们一起工作来准确地表示特征的重要性。为了理解它们是如何做到这一点的，首先有必要了解一种解释单个树中的特性重要性的自然方法。

## 单一树中的特征重要性

回想一下，单个树旨在以局部最优的方式减少误差，因为它分割特征空间。分类树使用杂质的度量来对当前的类别分离进行评分，而回归树使用残差平方误差。我们将使用分类树的概念来使我们的可视化效果更好，但是在交换掉误差函数之后，回归情况是一样的…

减少杂质(或熵)是迭代分裂区域以减少决策树的分类错误的最快和最稳定的方法。衡量某个特性在决策过程中的影响的一种自然方法是查看该特性从系统中移除的熵值，即仅根据该特性的值所做决策获得的信息量或准确度。下面的可视化演示了我们分割特征空间和构建决策树的过程。我们从一个初始熵值( *D* )开始，我们计算每个子区域中的减少，然后对整个树中每个特征变量的熵的归因变化求和。

![](img/b5c4e1ba9c9ddc4c88fb93f6ba4430b8.png)

We start with D=1.31 and split feature space until we reach zero entropy. 1.011 of the reduction is due to decisions made on y, while x is only responsible for 0.299 of the reduction.

我以前说过，现在再说一遍:决策树是弱分类器。训练数据中的微小变化可能意味着我们最终会得到一个完全不同的树，从而对我们的特征重要性有不同的估计。在我们的观想中，考虑原始数据的这一微小变化:

![](img/02ce454c029613e3a501a5d43e6e093d.png)

Now the reduction in entropy due to x is 1.011 while the reduction due to y is 0.299\. The variable importances have switched!

## 减少与许多树的差异

如果这种计算特征重要性的方法如此不稳定，对我们来说就没有多大用处了。问题是测量的方差太高，这就是随机森林的作用所在:回想一下，随机森林最终的工作方式是，首先通过从本质上消除个体树对局部最优策略的偏好并随机分割要素，然后通过聚合树来减少模型的整体方差。

这种方差的减少稳定了模型，减少了其对训练数据选择的偏差，并导致更少的变量和更准确的预测。如果像我们预测的那样，通过对每个特征变量的熵或准确度的变化取平均值，我们对随机森林中的树木的特征重要性的度量进行汇总，我们会获得完全相同的效果。

直观地说，对随机特征的分割使模型中的每个特征都有机会在树的所有可能点上显示其决策能力，而聚合减少了最终结果的可变性。本质上，与随机森林提高最终预测的准确性一样，它也提高了这种特征重要性度量的准确性。如果你不相信我，这里有一点证据:

![](img/ff4bc714df037df8ee3a5b6fd076e1c3.png)

A, B, C are all i.i.d

当用连续变量对抗分类变量时，这种方法有一些明确的问题；连续变量有更多的“空间”来分割，所以可以比分类变量多一点，但不一定更重要。这种方法*也没有真正*违反可解释性-准确性权衡的思想，因为它只真正告诉我们变量如何相互叠加，也就是说，它没有告诉我们如果我们增加或减少特征值(就像以前的线性回归一样)，我们的决策会发生什么。但是，嘿，这很有用*我从没说过随机森林是完美的*。

不管怎样，现在你知道 scikit-learn `RandomForestClassifier`上的`feature_importances_`属性的力量了…但是你仍然不能解释猫对计算机来说是什么。哦好吧。

![](img/70f53740eaef3d66aa7c0211dde729b5.png)

Later!

另外，这个博客很乱，也很粗糙，但是我想发表一些东西。我会花一天左右的时间来整理它。请给我发电子邮件，询问我在 thomasggrigg@gmail.com 需要澄清或反馈的任何问题

正在撰写的博文:内核技巧--偏差-方差权衡--深入探究随机森林的工作原理(我在这里稍微提到了一点)。