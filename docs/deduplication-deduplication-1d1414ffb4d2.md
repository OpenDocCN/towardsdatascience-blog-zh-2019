# é‡å¤æ•°æ®åˆ é™¤

> åŸæ–‡ï¼š<https://towardsdatascience.com/deduplication-deduplication-1d1414ffb4d2?source=collection_archive---------13----------------------->

## æ˜¯çš„ï¼Œè¿™å°±æ˜¯æˆ‘æƒ³å¸®ä½ è§£å†³çš„é—®é¢˜ã€‚åˆ é™¤é‚£äº›é€ æˆä¼¤å®³ã€é˜»ç¢æŸäº›ä»»åŠ¡çš„æ•ˆç‡ç”šè‡³æ±¡æŸ“æˆ‘ä»¬ç³»ç»Ÿçš„è‚®è„çš„å°å‰¯æœ¬ã€‚

> **é‡å¤æ•°æ®åˆ é™¤**
> /diËËŒdjuËplÉªËˆkeÉªÊƒ(É™)n/
> 
> ***åè¯***æ¶ˆé™¤é‡å¤æˆ–å¤šä½™çš„ä¿¡æ¯ï¼Œå°¤å…¶æ˜¯è®¡ç®—æœºæ•°æ®ã€‚
> 
> â€œé‡å¤æ•°æ®åˆ é™¤åœ¨å­˜å‚¨ä¹‹å‰åˆ é™¤é‡å¤ä¿¡æ¯â€

æ­£å¦‚å®šä¹‰æ‰€è¯´ï¼Œæˆ‘ä»¬è¦åšçš„ä»»åŠ¡æ˜¯åˆ é™¤é‡å¤çš„æ–‡æœ¬/å¥å­ç­‰ç­‰ã€‚è¿™åªä¸è¿‡æ˜¯æ£€æŸ¥æ–‡æœ¬å½¼æ­¤æœ‰å¤šç›¸ä¼¼çš„è¡Œä¸ºã€‚ä»–ä»¬å¯ä»¥ä¸€æ¨¡ä¸€æ ·çš„åƒ:
**æ·±åº¦å­¦ä¹ ç‰›é€¼ï¼**å’Œ**æ·±åº¦å­¦ä¹ ç‰›é€¼ï¼**ã€‚æˆ–è€…ï¼Œå°±å¥å­è¯•å›¾ä¼ è¾¾çš„å†…å®¹è€Œè¨€ï¼Œå®ƒä»¬å¯èƒ½éå¸¸ç›¸ä¼¼ï¼Œæ¯”å¦‚:
**æ·±åº¦å­¦ä¹ å¤ªæ£’äº†ï¼**å’Œ**æ·±åº¦å­¦ä¹ å¤ªé…·äº†ã€‚** æˆ‘ä»¬çŸ¥é“è¿™ä¸¤å¥è¯ä¼ è¾¾çš„æ˜¯åŒä¸€ä¸ªä¸œè¥¿ï¼Œè¿™ä¹Ÿæ˜¯æˆ‘ä»¬å¸Œæœ›æˆ‘ä»¬çš„æœºå™¨æ•æ‰åˆ°çš„ä¸œè¥¿ã€‚

![](img/4b88068bb7fbf26da1e8acbe696b5cbd.png)

è¿™æ ·çš„ä»»åŠ¡åœ¨æ–‡çŒ®ä¸­è¢«ç§°ä¸º**è¯­ä¹‰æ–‡æœ¬ç›¸ä¼¼æ€§(STS)ã€‚**å®ƒå¤„ç†ç¡®å®šä¸¤æ®µ**æ–‡æœ¬**æœ‰å¤šç›¸ä¼¼ã€‚è¿™å°†ä¸ä»…åŒ…æ‹¬**å¥æ³•ç›¸ä¼¼åº¦**ï¼Œå³ä¸¤ä¸ªå¥å­ä¸­ä½¿ç”¨çš„å•è¯æœ‰å¤šç›¸ä¼¼æˆ–ç›¸åŒï¼Œè¿˜åŒ…æ‹¬**è¯­ä¹‰ç›¸ä¼¼åº¦**ï¼Œå®ƒæ•æ‰äº†ä½¿ç”¨ä¸¤ä¸ªå¥å­æ‰€ä¼ è¾¾çš„å†…å®¹çš„ç›¸ä¼¼åº¦ï¼Œå³æ–‡æœ¬çš„å«ä¹‰åœ¨ç¡®å®šç›¸ä¼¼å’Œä¸ç›¸ä¼¼æ–¹é¢èµ·ç€é‡è¦ä½œç”¨ã€‚

# **é—®é¢˜**

é—®é¢˜ã€‚æ˜¯çš„ï¼Œè¿™æ˜¯æˆ‘ä»¬çš„ä¸»è¦ç›®æ ‡ã€‚æ¥è§£å†³é—®é¢˜ã€‚æˆ‘ç»™ä½ ä¸¾ä¸ªä¾‹å­ã€‚æ¯”æ–¹è¯´ï¼Œä½ å¿…é¡»é€šè¿‡ç”µå­é‚®ä»¶å‘ä¸€ç¾¤äººå‘é€éå¸¸æœ‰è¶£çš„ç¬‘è¯(ä½ çš„ç¬‘è¯å¯ä»¥æ˜¯ä¸€å¥è¯æˆ–ä¸€ä¸²è¯)ã€‚ä½ çš„è€æ¿è¦æ±‚ä½ ç¡®ä¿äººä»¬ä¸ä¼šæ”¶åˆ°åŒæ ·çš„ç¬‘è¯ã€‚æ‰€ä»¥ä½ å¿…é¡»ç¡®ä¿ä½ æ‰€æœ‰çš„ç¬‘è¯éƒ½æ˜¯ç‹¬ä¸€æ— äºŒçš„ï¼Œäººä»¬ä¸ä¼šå¯¹å…¶å†…å®¹æ„Ÿåˆ°åŒçƒ¦ã€‚
*ä»€ä¹ˆå·¥ä½œï¼Œè®¤çœŸï¼Ÿ*

ä½œä¸ºä¸€åå‡ºè‰²çš„ç¨‹åºå‘˜ï¼Œä½ å†³å®šè‡ªåŠ¨å®Œæˆè¿™é¡¹ä»»åŠ¡ã€‚ä½ æœ‰è¿™ä¸ªç¥å¥‡çš„ APIï¼Œå¯ä»¥å…è´¹ç»™ä½ å¾ˆå¤šç¬‘è¯ï¼Œä½ å†™ä¸€ä¸ªè„šæœ¬ï¼ŒæŠŠè¿™äº›ç¬‘è¯å‘ç»™ä½ è€æ¿å–œæ¬¢çš„é‚£ç¾¤äººã€‚ä½†æ˜¯ï¼Œæˆ‘ä»¬ä¸èƒ½çœŸçš„ç›¸ä¿¡è¿™ä¸ªç¥å¥‡çš„ APIï¼Œä¸æ˜¯å—ï¼Ÿç®€ç›´*ç¥å¥‡ã€‚*API ç»™ä½ å¼€ç±»ä¼¼çš„ç©ç¬‘æ€ä¹ˆåŠï¼Ÿä½ ä¸èƒ½å†’é™©æƒ¹æ¼ä½ çš„è€æ¿ã€‚
è¿™æ˜¯ä½ å¯ä»¥ä½¿ç”¨ ***é‡å¤æ•°æ®åˆ é™¤å¼•æ“*** çš„åœ°æ–¹ï¼Œç¡®ä¿å‘é€çš„ç¬‘è¯ä¸ä¼šä¸è¿‡å»å‘é€çš„ç¬‘è¯ç›¸ä¼¼ã€‚

æˆ‘åœ¨è¿™é‡Œçš„ä¸»è¦ç›®çš„ä¸æ˜¯è°ˆè®ºè¿™äº›æ¨¡å‹ã€‚è€Œæ˜¯ä¸ºäº†å¸®åŠ©æ‚¨åœ¨å®é™…å·¥ä½œä¸­ä½¿ç”¨å®ƒä»¬ï¼Œå°±åƒä¸Šé¢æåˆ°çš„é‚£æ ·ã€‚æˆ‘æ‰¿è®¤ï¼Œä¸ºäº†ç»™ä½ çš„è€æ¿ç•™ä¸‹æ·±åˆ»å°è±¡è€Œå‘åˆ«äººå‘é€ç¬‘è¯å¹¶ä¸å®é™…ã€‚

# åœ¨ STS çš„ç©ºé—´é‡Œâ€¦

è®©æˆ‘ä»¬è¯•ç€æŠŠå®ƒåˆ†è§£æˆè¿™ç§ç›¸ä¼¼æ€§åº¦é‡æ˜¯å¦‚ä½•å®šä¹‰çš„ï¼Œä»¥åŠæˆ‘ä»¬è¯•å›¾æ‰¾å‡ºå“ªä¸¤ä¸ªå®ä½“ä¹‹é—´çš„ç›¸ä¼¼æ€§(å­—é¢ä¸Šæ˜¯æ–‡æœ¬æœ¬èº«ï¼Œè¿˜æ˜¯åˆ«çš„ä»€ä¹ˆï¼Ÿ).

**é¦–å…ˆæ˜¯**ï¼Œè¯´åˆ°ç›¸ä¼¼æ€§åº¦é‡ï¼Œå¯ä»¥ä½¿ç”¨çš„æœ‰ä¸å°‘ã€‚åªæ˜¯ä¸ºäº†å®Œæ•´èµ·è§ï¼Œåˆ—ä¸¾å‡ ä¸ª:
1ã€‚ [**Jaccard ç›¸ä¼¼åº¦**](https://en.wikipedia.org/wiki/Jaccard_index)2ã€‚[**ä½™å¼¦ç›¸ä¼¼åº¦**](https://en.wikipedia.org/wiki/Cosine_similarity)3ã€‚[**æ¨åœŸæœºè·ç¦»**](https://en.wikipedia.org/wiki/Earth_mover%27s_distance)4ã€‚[**è©¹æ£®-é¦™å†œè·ç¦»**](https://en.wikipedia.org/wiki/Jensen%E2%80%93Shannon_divergence)

![](img/f5e5147322b575a2bfd8796a12600525.png)

ä½†æ˜¯ä¸ºäº†åˆ‡å…¥æ­£é¢˜ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨**ä½™å¼¦ç›¸ä¼¼åº¦ã€‚**æ•°å­¦ä¸Šï¼Œ**ä½™å¼¦ç›¸ä¼¼åº¦**æ˜¯[å†…ç§¯ç©ºé—´](https://en.wikipedia.org/wiki/Inner_product_space)çš„ä¸¤ä¸ªå‘é‡(éé›¶)ä¹‹é—´ç›¸ä¼¼åº¦[çš„åº¦é‡ï¼Œåº¦é‡å®ƒä»¬ä¹‹é—´è§’åº¦çš„](https://en.wikipedia.org/wiki/Measure_of_similarity)[ä½™å¼¦](https://en.wikipedia.org/wiki/Cosine)ã€‚

å¦‚æœä¸¤ä¸ªæ–‡æ¡£ç›¸ä¼¼ï¼Œå¹¶ä¸”åœ¨æ¬§å‡ é‡Œå¾—ç©ºé—´ä¸­ç›¸è·å¾ˆè¿œï¼Œå®ƒä»¬ä»ç„¶å¯ä»¥å½¼æ­¤éå¸¸æ¥è¿‘ã€‚è¿™æ˜¯ç”±ä½™å¼¦è·ç¦»æ•è·çš„ï¼Œå› æ­¤æ˜¯æœ‰åˆ©çš„ã€‚

**å…¶æ¬¡ï¼Œ**è¿™ä¸ªä½™å¼¦è·ç¦»æˆ‘ä»¬ç”¨åœ¨å“ªé‡Œï¼Ÿæˆå¯¹çš„å¥å­ä¸²ä¹‹é—´ï¼Ÿæ²¡æœ‰ã€‚è¿™å°±æ˜¯æˆ‘ä»¬åˆ©ç”¨*è‡ªç„¶è¯­è¨€å¤„ç†*å’Œ*æ·±åº¦å­¦ä¹ *çš„åŠ›é‡ã€‚æˆ‘ä»¬ä½¿ç”¨*å‘é‡*ã€‚

***ä¸€ä¸ªå•è¯/å¥å­å‘é‡æ˜¯ä¸€è¡Œå®æ•°å€¼*** (ä¸è™šæ‹Ÿæ•°å­—ç›¸å)ï¼Œå…¶ä¸­ ***æ¯ä¸ªç‚¹æ•æ‰å•è¯/å¥å­çš„ä¸€ä¸ªç»´åº¦çš„å«ä¹‰*** å’Œ ***ï¼Œå…¶ä¸­è¯­ä¹‰ç›¸ä¼¼çš„å•è¯/å¥å­å…·æœ‰ç›¸ä¼¼çš„å‘é‡ã€‚***

åŒæ ·ï¼Œæœ‰å¾ˆå¤šæ–¹æ³•å¯ä»¥å¾—åˆ°è¿™äº›å‘é‡ã€‚ä¸¾å‡ ä¸ª:
**å•è¯åµŒå…¥** : word2vecã€GloVeã€BERT å•è¯åµŒå…¥ã€ELMo ç­‰ç­‰ã€‚
**è¯­å¥åµŒå…¥** : BERT è¯­å¥åµŒå…¥ï¼Œé€šç”¨è¯­å¥ç¼–ç å™¨ç­‰ã€‚

æˆ‘å°†ç›´æ¥è¿›å…¥æˆ‘äº²è‡ªè¯•éªŒè¿‡çš„æ–¹æ³•ï¼Œè¿™äº›æ–¹æ³•å¯¹æˆ‘éå¸¸æœ‰æ•ˆã€‚

```
 [word2vec](https://github.com/mmihaltz/word2vec-GoogleNews-vectors) + [Universal Sentence Encoder](https://tfhub.dev/google/universal-sentence-encoder-large/3)
```

ä¸ºäº†é¿å…è¿™ç¯‡æ–‡ç« æˆä¸ºä¸€ç¯‡çº¯ç²¹çš„é¢å‘å®ç°çš„æ–‡ç« (è¿™æ­£æ˜¯æˆ‘ä»¬æƒ³è¦çš„)ï¼Œæˆ‘å°†è¯•ç€ç®€å•åœ°è§£é‡Šä¸€ä¸‹è¿™äº›æ¨¡å‹æ˜¯ä»€ä¹ˆã€‚

# word2vec

word2vec æœ‰ä¸¤ç§å˜ä½“: **Skip-Gram** å’Œ**è¿ç»­å•è¯åŒ…æ¨¡å‹(CBOW)ã€‚**å¦‚æœä½ æƒ³å¯»æ‰¾è¯¦ç»†çš„è§£é‡Šï¼Œå…³äºè¿™ä¸¤ç§å˜ä½“æœ‰å¤§é‡çš„ææ–™ã€‚æˆ‘ä¼šå¾ˆå¹²è„†çš„ã€‚skip-gram æ¨¡å‹é€Ÿåº¦ç¨æ…¢ï¼Œä½†é€šå¸¸åœ¨å¤„ç†ä¸å¸¸ç”¨çš„å•è¯æ—¶æ•ˆæœæ›´å¥½ã€‚å› æ­¤ï¼Œè¿™æ˜¯ç»å¸¸ä½¿ç”¨çš„ã€‚è¿™ä¸ªæˆ‘ä»¬ç®€å•è¯´ä¸€ä¸‹ã€‚

ä½ ä¼šåœ¨å‡ ä¹æ‰€æœ‰çš„ word2vec (Skip-Gram model)åšå®¢å’Œæ•™ç¨‹ä¸­æ‰¾åˆ°è¿™ä¸ªå›¾è¡¨ã€‚åœ¨è¿™ç§æ¶æ„ä¸­ï¼Œæ¨¡å‹ä½¿ç”¨å½“å‰å•è¯æ¥é¢„æµ‹ä¸Šä¸‹æ–‡å•è¯çš„å‘¨å›´çª—å£ã€‚å®ƒå¯¹é™„è¿‘çš„ä¸Šä¸‹æ–‡å•è¯çš„åŠ æƒæ¯”å¯¹è¿œå¤„çš„ä¸Šä¸‹æ–‡å•è¯çš„åŠ æƒæ›´é‡ã€‚

![](img/17b0b81fd5decc91a968f3aa3cace4b6.png)

è¿™é‡Œï¼Œæˆ‘ä»¬çœ‹ä¸€ä¸ªä¸Šä¸‹æ–‡å•è¯çš„çª—å£(åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œæ¯è¾¹ 2 ä¸ªå•è¯),å¹¶å°è¯•é¢„æµ‹ä¸­å¿ƒå•è¯ã€‚

![](img/893ff2c92c107117790124b98074f439.png)

The Skip-gram model architecture ([https://arxiv.org/pdf/1301.3781.pdf](https://arxiv.org/pdf/1301.3781.pdf))

è€ƒè™‘ *w(t)* æ˜¯è¾“å…¥å­—ï¼Œé€šå¸¸æƒé‡çŸ©é˜µå’Œè¾“å…¥å‘é‡ *w(t)* ä¹‹é—´çš„ç‚¹ç§¯æ˜¯ç”±å•éšå±‚å®Œæˆçš„ã€‚æˆ‘ä»¬å°† *softmax* å‡½æ•°åº”ç”¨äºéšè—å±‚çš„è¾“å‡ºå‘é‡å’Œæƒé‡çŸ©é˜µä¹‹é—´çš„ç‚¹ç§¯ã€‚è¿™ç»™å‡ºäº†å•è¯åœ¨å½“å‰å•è¯ä½ç½®å‡ºç°åœ¨ *w(t)* çš„ä¸Šä¸‹æ–‡ä¸­çš„æ¦‚ç‡ã€‚

éšè—å±‚ä¸­çš„çŸ¢é‡æˆä¸ºäº†è¿™ä¸ªå•è¯çš„çŸ¢é‡è¡¨ç¤ºã€‚ä½†æ˜¯è¿™äº›éƒ½æ˜¯'*å­—'åµŒå…¥ï¼Œ*å’Œæˆ‘ä»¬è¦æ‰¾çš„ç›¸ä¼¼çš„'å¥å­'ã€‚é‚£ä¹ˆï¼Œ*æˆ‘ä»¬å¦‚ä½•å¾—åˆ°å¥å­çš„å‘é‡è¡¨ç¤ºè€Œä¸ä»…ä»…æ˜¯å•è¯åµŒå…¥å‘¢ï¼Ÿ*

ä¸€ç§ç®€å•è€Œçç¢çš„æ–¹æ³•(æˆ‘ä»Šå¤©å°†å±•ç¤ºçš„æ–¹æ³•)æ˜¯ç®€å•åœ°å¯¹è¯¥å¥å­çš„æ‰€æœ‰å•è¯çš„å•è¯åµŒå…¥è¿›è¡Œå¹³å‡ã€‚å¾ˆç®€å•ï¼Œä¸æ˜¯å—ï¼Ÿ

ç°åœ¨å¯¹äºä¸»è¦éƒ¨åˆ†ï¼Œè®©æˆ‘ä»¬æŠŠå®ƒç¼–ç è¿›å»ã€‚

```
w2vmodel = **gensim.models.KeyedVectors.load_word2vec_format**(
'models/GoogleNews-vectors-negative300.bin.gz'), binary=True) **def** sent2vec**(s)**:                               
'''
Finding word2vec vector representation of sentences                               @param s  : sentence                                
'''                               
    words = **str**(s).**lower**()                               
    words = **word_tokenize**(words)                               
    words = [w **for** w **in** words **if** **not** w **in** stop_words]
    words = [w **for** w **in** words **if** w.**isalpha**()]

    featureVec = **np.zeros**((300,), dtype="float32")
    nwords = 0

    **for** w **in** words:                                   
        **try**:                                       
            nwords = nwords + 1                                       
            featureVec = **np.add**(featureVec, w2vmodel[w])
        **except**:                                       
            **continue**                               
        # averaging                               
        **if** nwords > 0:                                   
            featureVec = **np.divide**(featureVec, nwords)
    **return** featureVec **def** get_w2v_vectors**(list_text1, list_text2)**: 
â€˜â€™â€™
Computing the word2vec vector representation of list of sentences
@param list_text1 : first list of sentences
@param list_text2 : second list of sentences 
â€˜â€™â€™ 
    **print**(â€œComputing first vectorsâ€¦â€) text1_vectors = **np.zeros**((len(list_text1), 300))
    **for** i, q **in** tqdm(enumerate(list_text1)):
        text1_vectors[i, :] = sent2vec(q) text2_vectors = **np.zeros**((len(list_text2), 300))
    **for** i, q **in** tqdm(enumerate(list_text2)):
        text2_vectors[i, :] = sent2vec(q) **return** text1_vectors, text2_vectors
```

å°±æ˜¯è¿™æ ·ï¼ğŸ¤·â€â™‚ä½ æœ‰ä½ çš„å¥å­åµŒå…¥ä½¿ç”¨ **word2vec** ã€‚

# é€šç”¨å¥å­ç¼–ç å™¨

è°·æ­Œå±•ç¤ºäº†ä¸€ç³»åˆ—ç”¨äºå°†å¥å­ç¼–ç æˆå‘é‡çš„æ¨¡å‹ã€‚ä½œè€…ç‰¹åˆ«é’ˆå¯¹ä¸‹æ¸¸ä»»åŠ¡ï¼Œå³è¿ç§»å­¦ä¹ ä»»åŠ¡ã€‚STS å°±æ˜¯è¿™æ ·ä¸€ä¸ªä»»åŠ¡ã€‚

å®ƒæœ‰ä¸¤ç§å˜ä½“:
1ã€‚ä¸€ä¸ªå¸¦æœ‰ [**å˜å‹å™¨**](http://jalammar.github.io/illustrated-transformer/) ç¼–ç å™¨
2ã€‚ä¸€ç”¨ä¸€ [**æ·±åº¦å¹³å‡ç½‘ç»œ**](http://mlexplained.com/2018/05/11/paper-dissected-deep-unordered-composition-rivals-syntactic-methods-for-text-classification-explained/)

ä»–ä»¬æ¯ä¸ªäººéƒ½æœ‰ä¸åŒçš„è®¾è®¡ç›®æ ‡:
1ã€‚ä»¥æ›´å¤§çš„æ¨¡å‹å¤æ‚æ€§å’Œèµ„æºæ¶ˆè€—ä¸ºä»£ä»·æ¥å®ç°é«˜ç²¾åº¦ã€‚
2ã€‚ç›®æ ‡æ˜¯ä»¥ç¨å¾®é™ä½çš„å‡†ç¡®åº¦è¿›è¡Œæœ‰æ•ˆçš„æ¨ç†ã€‚

æˆ‘å·²ç»ç”¨æˆ‘æœ€å–œæ¬¢çš„åšå®¢å°†è¿™ä¸¤ç§æ¶æ„éƒ½åšäº†è¶…é“¾æ¥ï¼Œè¿™äº›åšå®¢å¯¹å®ƒä»¬éƒ½åšäº†å¾ˆå¥½çš„è§£é‡Šã€‚è®©æˆ‘ä»¬æ›´å…³æ³¨å¦‚ä½•å®ç°å®ƒä»¬ã€‚

```
usemodel = **hub.Module**('models/sentence_encoder')**def** get_use_vectors**(list_text1, list_text2)**:
'''
Computing the USE vector representation of list of sentences
@param  list_text1  :   first list of sentences
@param  list_text2  :   second list of sentences 
'''
    **print**("Computing second vectors...")
    messages1 = list_text1
    messages2 = list_text2 num_batches = **math.ceil**(len(messages1) / BATCH_SIZE) # Reduce logging output.
    **tf.logging.set_verbosity**(tf.logging.ERROR) message_embeddings1 = []
    message_embeddings2 = [] **with** tf.Session() **as** session:
        session.**run**([tf.global_variables_initializer(),
             tf.tables_initializer()]) **for** batch **in** range(num_batches):
        **print**(batch * BATCH_SIZE, batch *
              BATCH_SIZE + BATCH_SIZE)
        batch_msgs1 = messages1[batch * BATCH_SIZE: batch *
                    BATCH_SIZE + BATCH_SIZE]
        batch_msgs2 = messages2[batch * BATCH_SIZE: batch *
                    BATCH_SIZE + BATCH_SIZE] message_embeddings1_temp, message_embeddings2_temp =  session.**run**([usemodel(batch_msgs1), usemodel(batch_msgs2)])

        message_embeddings1.**append**(message_embeddings1_temp)
        message_embeddings2.**append**(message_embeddings2_temp) all_embedding1 = **np**.**concatenate**(**tuple**(message_embeddings1))
    all_embedding2 = **np**.**concatenate**(**tuple**(message_embeddings2)) **return** all_embedding1, all_embedding2
```

å†è¯´ä¸€éï¼Œå°±æ˜¯è¿™æ ·ï¼ğŸ¤·â€â™‚

ç°åœ¨æˆ‘ä»¬æœ‰äº†æ¥è‡ªä¸¤ä¸ªä¸åŒæ¨¡å‹çš„ç¬‘è¯çš„å¥å­åµŒå…¥ã€‚

ç°åœ¨æˆ‘ä»¬éœ€è¦ä½™å¼¦ç›¸ä¼¼åº¦ï¼

```
**def** cosine_similarity**(list_vec1, list_vec2)**:
'''
Computing the cosine similarity between two vector representation
[@param](http://twitter.com/param)  list_text1  :   first list of sentences
[@param](http://twitter.com/param)  list_text2  :   second list of sentences 
'''
    cosine_dist = [cosine(x, y) **for** (x, y) **in** **zip**(np.nan_to_num(list_vec1), np.nan_to_num(list_vec2))] cosine_sim = [(1 - dist) **for** dist **in** cosine_dist] **return** cosine_sim
```

å½“æˆ‘åœ¨ä½ ä¹‹å‰åšè¿™ä»½å·¥ä½œæ—¶ï¼Œæˆ‘æœ‰ä¸€å †ä¸é‡å¤çš„ç¬‘è¯ï¼Œå¾ˆå°‘æœ‰é‡å¤çš„ã€‚å…·ä½“æ¥è¯´ï¼Œæˆ‘æœ‰ **385K** éé‡å¤å¯¹å’Œ **10K** é‡å¤å¯¹ã€‚æˆ‘ä»…ä½¿ç”¨ **word2vec** æ¨¡å‹ç»˜åˆ¶äº†è¿™é¡¹ä»»åŠ¡çš„ *AUC-ROC* ã€‚

![](img/6f4e844dbeb7e5050fbaaf34f3dbd3d9.png)

AUC-ROC

ä¸é”™ï¼æ›²çº¿çœ‹èµ·æ¥å¾ˆæ¼‚äº®ã€‚(æˆ‘æ•…æ„çœç•¥äº†æ··æ·†çŸ©é˜µ)ã€‚

**TPR/å¬å›ç‡/æ•æ„Ÿåº¦**:77%
**FPR**:2.2%

è®©æˆ‘ä»¬çœ‹çœ‹**é€šç”¨å¥å­ç¼–ç å™¨**çš„è¡¨ç°å¦‚ä½•ã€‚

![](img/f01115f381a15fac428ebba808e4edad.png)

AUC-ROC

æ›²çº¿ä¸‹çš„åŒºåŸŸç¨å¾®å¥½ä¸€ç‚¹ï¼Œä¸æ˜¯å—ï¼Ÿ

**TPR/å¬å›/æ•æ„Ÿåº¦**:77%
**FPR**:2.2%

è®©æˆ‘ä»¬çœ‹çœ‹å½“æˆ‘ä»¬æŠŠå®ƒä»¬ç»“åˆåœ¨ä¸€èµ·æ—¶ä¼šå‘ç”Ÿä»€ä¹ˆã€‚é€šè¿‡ç»„åˆï¼Œæˆ‘çš„æ„æ€æ˜¯å¹³å‡æ¥è‡ªä¸¤ç§æ–¹æ³•çš„ä½™å¼¦ç›¸ä¼¼æ€§ï¼Œå¹¶æ£€æŸ¥åº¦é‡ã€‚â€œä¸€ä¸ªå¹³å‡çš„**é›†åˆ**çš„æ¨¡å‹â€ã€‚

![](img/eee18d01b14476abd6d47f811d76be0d.png)

è¿„ä»Šä¸ºæ­¢æœ€å¥½çš„ä¸€ä¸ªï¼

**TPR/å¬å›/æ•æ„Ÿåº¦**:78.2%
**FPR**:1.5%

å–”å–”å–”ï¼ğŸ‰ğŸ‰æˆ‘ä»¬æœ‰ä¸€ä¸ªæ˜ç¡®çš„èµ¢å®¶ï¼

è¿™æ˜¯ä¸€ç§å¿«é€ŸæŸ¥æ‰¾é‡å¤é¡¹çš„æ–¹æ³•ã€‚æ— éœ€åŸ¹è®­ï¼Œåªéœ€ä¸‹è½½ç°æœ‰çš„ä¼˜ç§€æ¨¡å‹å¹¶å°†å…¶ç”¨äºæ‚¨çš„ STS ä»»åŠ¡ï¼

æœ‰äº†è¿™ä¸€å—ï¼Œæ‚¨å¯ä»¥è½»æ¾æ„å»ºæ‚¨çš„**é‡å¤æ•°æ®åˆ é™¤å¼•æ“ã€‚åªéœ€å­˜å‚¨ä½ ç¬¬ä¸€å¤©å‘é€åˆ°è€æ¿å°ç»„çš„æ‰€æœ‰ç¬‘è¯ï¼Œç„¶åå¯¹äºæ¯ä¸ªæ–°æ¥çš„ç¬‘è¯ï¼Œå°†å®ƒä»¬ä¸ä¹‹å‰çœ‹åˆ°çš„æ‰€æœ‰ç¬‘è¯é…å¯¹ï¼Œå¹¶ä½¿ç”¨è¿™ä¸ªé›†åˆæ¨¡å‹æ¥ç¡®å®šå®ƒä»¬æ˜¯å¦é‡å¤ã€‚å¦‚æœæ˜¯ï¼Œå°±æ‰”æ‰ã€‚**

é€šè¿‡è¿™ç§æ–¹å¼ï¼Œè®©ä½ è€æ¿çš„æœ‹å‹å¼€å¿ƒï¼Œè€æ¿å¼€å¿ƒï¼Œå¾—åˆ°ä¸€ä»½ä¸é”™çš„è–ªæ°´ï¼Œè®©ä½ è‡ªå·±å¼€å¿ƒ:)