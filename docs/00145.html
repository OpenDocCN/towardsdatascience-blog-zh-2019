<html>
<head>
<title>From raw images to real-time predictions with Deep Learning</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">从原始图像到深度学习的实时预测</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/from-raw-images-to-real-time-predictions-with-deep-learning-ddbbda1be0e4?source=collection_archive---------6-----------------------#2019-01-07">https://towardsdatascience.com/from-raw-images-to-real-time-predictions-with-deep-learning-ddbbda1be0e4?source=collection_archive---------6-----------------------#2019-01-07</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="f66b" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated"><strong class="ak">使用 Keras、Flask 和 OpenCV 的人脸表情识别</strong></h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/1481755b95f421c39d5085e4bb3f3472.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*3a5inP5C1-yrLM5W"/></div></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk">Photo by <a class="ae kv" href="https://unsplash.com/@plloyd?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Peter Lloyd</a> on <a class="ae kv" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><p id="334e" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在我看来，人工智能最令人兴奋的领域之一是计算机视觉。我发现非常有趣的是，我们现在如何从复杂的原始数据结构(如图像)中自动提取知识。</p><p id="8587" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">本文的目标是探索一个计算机视觉应用的完整例子:构建一个具有深度学习的人脸表情识别系统。我们将了解如何:</p><ul class=""><li id="6773" class="ls lt iq ky b kz la lc ld lf lu lj lv ln lw lr lx ly lz ma bi translated">设计一个卷积神经网络</li><li id="4cce" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr lx ly lz ma bi translated">通过输入一批图像来训练它</li><li id="f336" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr lx ly lz ma bi translated">将其导出，以便与实时图像数据一起重新使用</li></ul><h1 id="fc4f" class="mg mh iq bd mi mj mk ml mm mn mo mp mq jw mr jx ms jz mt ka mu kc mv kd mw mx bi translated">工具</h1><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi my"><img src="../Images/4665b852a73e47af10c4ef4181334541.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*_q3DELiGBUI-uGdP.png"/></div></div></figure><p id="9edd" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">Keras 是一种高级神经网络 API，用 Python 编写，能够在 TensorFlow、CNTK 或 Theano 之上运行。我们将用它来建立、训练和输出神经网络。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi my"><img src="../Images/392498e7909284a0f1fae484d44cfb42.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*DkiKNIYkf61kY0V9.png"/></div></div></figure><p id="b182" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">Flask 是一个用 Python 编写的微型 web 框架，它允许我们将模型直接提供给 web 界面。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi mz"><img src="../Images/ed86098161f412cb0a204cad2b64ce90.png" data-original-src="https://miro.medium.com/v2/resize:fit:440/format:webp/0*mkSP9o3cdOIX1obu.png"/></div></figure><p id="ddb0" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">OpenCV 是一个计算机视觉库，有 C++、Python 和 Java 接口。我们将使用这个库来自动检测图像中的人脸。</p><h1 id="2946" class="mg mh iq bd mi mj mk ml mm mn mo mp mq jw mr jx ms jz mt ka mu kc mv kd mw mx bi translated">数据源</h1><p id="c9ad" class="pw-post-body-paragraph kw kx iq ky b kz na jr lb lc nb ju le lf nc lh li lj nd ll lm ln ne lp lq lr ij bi translated">数据来源于往届 Kaggle 竞赛《表征学习中的挑战:面部表情识别挑战》:</p><p id="20b5" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><a class="ae kv" href="https://www.kaggle.com/c/challenges-in-representation-learning-facial-expression-recognition-challenge" rel="noopener ugc nofollow" target="_blank">https://www . ka ggle . com/c/challenges-in-re presentation-learning-face-expression-recognition-challenge</a></p><p id="1fb0" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">该数据由 48x48 像素的面部灰度图像组成。面部已经被自动注册，使得面部或多或少地居中，并且在每个图像中占据大约相同的空间。每张图片对应七种表情中的一种(0 =生气，1 =厌恶，2 =恐惧，3 =快乐，4 =悲伤，5 =惊讶，6 =中性)。数据集包含大约 36K 幅图像。</p><p id="9110" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">原始数据包含在数组中，每个像素有一个灰度值。我们将这些数据转换成原始图像，并将其拆分到多个文件夹中:</p><pre class="kg kh ki kj gt nf ng nh ni aw nj bi"><span id="6865" class="nk mh iq ng b gy nl nm l nn no">images/<br/>    train/<br/>        angry/<br/>        disgust/<br/>        fear/<br/>        happy/<br/>        neutral/<br/>        sad/<br/>        surprise/<br/>    validation/<br/>        angry/<br/>        disgust/<br/>        fear/<br/>        happy/<br/>        neutral/<br/>        sad/<br/>        surprise/</span></pre><p id="457c" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我们 80%的图像包含在 train 文件夹中，最后 20%在 validation 文件夹中。</p><h1 id="c9ce" class="mg mh iq bd mi mj mk ml mm mn mo mp mq jw mr jx ms jz mt ka mu kc mv kd mw mx bi translated">快速数据可视化</h1><p id="d76c" class="pw-post-body-paragraph kw kx iq ky b kz na jr lb lc nb ju le lf nc lh li lj nd ll lm ln ne lp lq lr ij bi translated">首先让我们看看我们的图像是什么样子的:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="np nq l"/></div></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nr"><img src="../Images/1db54e6be4fd38d50e94d72f83c7903c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*DFPFIwRQh4cPsuJ0FzPHQA.png"/></div></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk">Sample of the training images</figcaption></figure><p id="eece" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">你能猜出这些图像与哪些表情有关吗？</p><p id="9748" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这项任务对人来说很容易，但对预测算法来说可能有点挑战，因为:</p><ul class=""><li id="122b" class="ls lt iq ky b kz la lc ld lf lu lj lv ln lw lr lx ly lz ma bi translated">这些图像的分辨率很低</li><li id="be9a" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr lx ly lz ma bi translated">这些面不在同一位置</li><li id="d8f8" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr lx ly lz ma bi translated">一些图像上写有文字</li><li id="1788" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr lx ly lz ma bi translated">有些人用手遮住部分脸</li></ul><p id="15bc" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">然而，所有这些图像的多样性将有助于建立一个更通用的模型。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="np nq l"/></div></figure><pre class="kg kh ki kj gt nf ng nh ni aw nj bi"><span id="b28e" class="nk mh iq ng b gy nl nm l nn no">4103 fear images<br/>436 disgust images<br/>4982 neutral images<br/>7164 happy images<br/>3993 angry images<br/>3205 surprise images<br/>4938 sad images</span></pre><p id="ecc1" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">除了“厌恶”类别，我们训练数据集中的面部表情相当平衡。</p><h1 id="8821" class="mg mh iq bd mi mj mk ml mm mn mo mp mq jw mr jx ms jz mt ka mu kc mv kd mw mx bi translated">设置数据生成器</h1><p id="80dd" class="pw-post-body-paragraph kw kx iq ky b kz na jr lb lc nb ju le lf nc lh li lj nd ll lm ln ne lp lq lr ij bi translated">深度学习模型通过输入批量数据来训练。Keras 有一个非常有用的类可以自动从目录中获取数据:ImageDataGenerator。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="np nq l"/></div></figure><pre class="kg kh ki kj gt nf ng nh ni aw nj bi"><span id="8fe4" class="nk mh iq ng b gy nl nm l nn no">Found 28821 images belonging to 7 classes.<br/>Found 7066 images belonging to 7 classes.</span></pre><p id="fe2b" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">它还可以在获取图像的同时执行数据扩充(随机旋转图像、缩放等。).当数据集很小时，这种方法通常被用作人工获取更多数据的方法。</p><p id="49af" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">函数 flow_from_directory()指定生成器应该如何导入图像(路径、图像大小、颜色等)。).</p><h1 id="97bf" class="mg mh iq bd mi mj mk ml mm mn mo mp mq jw mr jx ms jz mt ka mu kc mv kd mw mx bi translated">设置我们的卷积神经网络(CNN)</h1><p id="2723" class="pw-post-body-paragraph kw kx iq ky b kz na jr lb lc nb ju le lf nc lh li lj nd ll lm ln ne lp lq lr ij bi translated">我们选择使用卷积神经网络来解决这个人脸识别问题。事实上，这种类型的神经网络(NN)对于提取图像的特征是很好的，并且被广泛用于图像分析主题，如图像分类。</p><p id="d42a" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir">快速提醒什么是 NN:</strong></p><p id="ce1d" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">神经网络是由多层人工神经元(节点)组成的学习框架。每个节点获得加权的输入数据，将其传递给激活函数，并输出该函数的结果:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi ns"><img src="../Images/26f1a0603588fbf12362259ef11d8dfb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1310/format:webp/1*_tUtD8EvW7WZiLT-l-A_sA.png"/></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk">A node</figcaption></figure><p id="973d" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">神经网络由几层节点组成:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nt"><img src="../Images/16a0ff94ceb148da046cc6eb91cc41ee.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*JSkKLofovVEBHiApmdyOTw.png"/></div></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk">A classic NN architecture</figcaption></figure><ul class=""><li id="f55e" class="ls lt iq ky b kz la lc ld lf lu lj lv ln lw lr lx ly lz ma bi translated">将获取数据的输入图层。输入图层的大小取决于输入数据的形状。</li><li id="c003" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr lx ly lz ma bi translated">一些隐藏层将允许神经网络学习数据中复杂的相互作用。具有许多隐藏层的神经网络被称为深度神经网络。</li><li id="53fb" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr lx ly lz ma bi translated">给出最终结果的输出层，例如类别预测。这一层的大小取决于我们想要产生的输出类型(例如，我们想要预测多少个类？)</li></ul><p id="9bd6" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">经典神经网络通常由几个完全连接的层组成。这意味着一层的每个节点都连接到下一层的所有节点。</p><p id="2675" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">卷积神经网络也具有卷积层，该卷积层将滑动函数应用于彼此相邻的像素组。因此，这些结构对我们可以在图像中观察到的模式有更好的理解。我们将在后面对此进行更详细的解释。</p><p id="d28b" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">现在让我们来定义 CNN 的架构:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="np nq l"/></div></figure><p id="0a15" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我们用以下全球架构定义我们的 CNN:</p><ul class=""><li id="d324" class="ls lt iq ky b kz la lc ld lf lu lj lv ln lw lr lx ly lz ma bi translated">4 个卷积层</li><li id="1efa" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr lx ly lz ma bi translated">2 个完全连接的层</li></ul><p id="f93f" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">卷积层将从图像中提取相关特征，完全连接的层将专注于使用这些特征来很好地分类我们的图像。这个建筑的灵感来自于以下关于这个主题的工作:【https://github.com/jrishabh96/Facial-Expression-Recognition T2】</p><p id="15f3" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">现在让我们来关注这些卷积层是如何工作的。其中每个都包含以下操作:</p><ul class=""><li id="dac3" class="ls lt iq ky b kz la lc ld lf lu lj lv ln lw lr lx ly lz ma bi translated">卷积运算符:使用滑动矩阵从输入图像中提取特征，以保持像素之间的空间关系。下图总结了它的工作原理:</li></ul><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi nu"><img src="../Images/0e7de8a67e0c197106c87d417e45b499.png" data-original-src="https://miro.medium.com/v2/resize:fit:1052/1*ZCjPUFrB6eHPRi4eyP6aaA.gif"/></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk">A convolution operator</figcaption></figure><p id="4cdb" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">绿色矩阵对应于原始图像值。橙色滑动矩阵被称为“过滤器”或“内核”。此滤镜在图像上滑动，每步滑动一个像素。在每一步中，我们将滤波器与基础矩阵的相应元素相乘，并将结果相加。有不同类型的过滤器，每一种都能够检索不同的图像特征:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi nv"><img src="../Images/4802d49944ce67338d18d2d9568d7f82.png" data-original-src="https://miro.medium.com/v2/resize:fit:684/format:webp/1*dhQEgKQB0H8i2nSnaOPrQw.png"/></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk">Different filter results</figcaption></figure><ul class=""><li id="1833" class="ls lt iq ky b kz la lc ld lf lu lj lv ln lw lr lx ly lz ma bi translated">我们应用 ReLU 函数在 CNN 中引入非线性。也可以使用其他函数，如 tanh 或 sigmoid，但 ReLU 在大多数情况下表现更好。</li><li id="cbd5" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr lx ly lz ma bi translated">池用于减少每个特征的维数，同时保留最重要的信息。像卷积步骤一样，我们对数据应用滑动函数。可以应用不同的函数:max、sum、mean…max 函数通常执行得更好。</li></ul><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nw"><img src="../Images/43c9d1def28f9c877534635172a57cd8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*GksqN5XY8HPpIddm5wzm7A.jpeg"/></div></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk">Max pooling operation</figcaption></figure><p id="4349" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我们还为每一层使用一些通用技术:</p><ul class=""><li id="e0a7" class="ls lt iq ky b kz la lc ld lf lu lj lv ln lw lr lx ly lz ma bi translated">批量标准化:通过提供零均值和单位方差的输入，提高 NNs 的性能和稳定性。</li><li id="4ef0" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr lx ly lz ma bi translated">Dropout:通过随机不更新某些节点的权重来减少过度拟合。这有助于防止神经网络过分依赖层中的一个节点。</li></ul><p id="efa3" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我们选择 softmax 作为最后的激活函数，因为它通常用于多标签分类。</p><p id="4d06" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">现在我们的 CNN 已经定义好了，我们可以用更多的参数来编译它。我们选择 Adam 优化器，因为它是计算效率最高的优化器之一。我们选择分类交叉熵作为我们的损失函数，因为它与分类任务非常相关。我们的衡量标准将是准确性，这对于平衡数据集上的分类任务也非常有用。</p><p id="e746" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在这里，我们从头开始定义和训练我们的 CNN，但您可能希望对需要更多计算资源的问题应用迁移学习方法。Keras 有几个预先训练好的模型可供使用:</p><div class="nx ny gp gr nz oa"><a href="https://keras.io/applications/" rel="noopener  ugc nofollow" target="_blank"><div class="ob ab fo"><div class="oc ab od cl cj oe"><h2 class="bd ir gy z fp of fr fs og fu fw ip bi translated">应用程序— Keras 文档</h2><div class="oh l"><h3 class="bd b gy z fp of fr fs og fu fw dk translated">Keras 应用程序是深度学习模型，可与预训练的权重一起使用。这些型号可以是…</h3></div><div class="oi l"><p class="bd b dl z fp of fr fs og fu fw dk translated">keras.io</p></div></div><div class="oj l"><div class="ok l ol om on oj oo kp oa"/></div></div></a></div><h1 id="b42e" class="mg mh iq bd mi mj mk ml mm mn mo mp mq jw mr jx ms jz mt ka mu kc mv kd mw mx bi translated">训练模型</h1><p id="002c" class="pw-post-body-paragraph kw kx iq ky b kz na jr lb lc nb ju le lf nc lh li lj nd ll lm ln ne lp lq lr ij bi translated">一切都准备好了，现在开始训练我们的模型吧！</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="np nq l"/></div></figure><pre class="kg kh ki kj gt nf ng nh ni aw nj bi"><span id="0f6b" class="nk mh iq ng b gy nl nm l nn no">Epoch 1/50<br/>225/225 [==============================] - 36s 161ms/step - loss: 2.0174 - acc: 0.2333 - val_loss: 1.7391 - val_acc: 0.2966<br/><br/>Epoch 00001: val_acc improved from -inf to 0.29659, saving model to model_weights.h5</span><span id="040d" class="nk mh iq ng b gy op nm l nn no">Epoch 2/50<br/>225/225 [==============================] - 31s 138ms/step - loss: 1.8401 - acc: 0.2873 - val_loss: 1.7091 - val_acc: 0.3311<br/><br/>Epoch 00002: val_acc improved from 0.29659 to 0.33108, saving model to model_weights.h5</span><span id="c739" class="nk mh iq ng b gy op nm l nn no">...</span><span id="ed42" class="nk mh iq ng b gy op nm l nn no">Epoch 50/50<br/>225/225 [==============================] - 30s 132ms/step - loss: 0.6723 - acc: 0.7499 - val_loss: 1.1159 - val_acc: 0.6384<br/><br/>Epoch 00050: val_acc did not improve from 0.65221</span></pre><p id="8998" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我们的最佳模型设法获得了大约 65%的验证准确率，这已经很不错了，因为我们的目标类有 7 个可能的值！</p><p id="b386" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在每个时期，Keras 检查我们的模型是否比前一时期的模型表现得更好。如果是这种情况，新的最佳模型权重被保存到文件中。这将允许我们直接加载模型的权重，而不必在其他情况下使用它时重新训练它。</p><p id="8b1a" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我们还必须保存我们的 CNN 的结构(层等)。)到一个文件中:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="np nq l"/></div></figure><h1 id="f62d" class="mg mh iq bd mi mj mk ml mm mn mo mp mq jw mr jx ms jz mt ka mu kc mv kd mw mx bi translated">分析结果</h1><p id="cfdb" class="pw-post-body-paragraph kw kx iq ky b kz na jr lb lc nb ju le lf nc lh li lj nd ll lm ln ne lp lq lr ij bi translated">我们在训练阶段的每一步都有产出。所有这些输出都保存在“历史”变量中。我们可以使用它在训练和验证数据集上绘制损失和准确性的演变:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="np nq l"/></div></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi oq"><img src="../Images/365eb8355e0d2e0322ca2633502dc29f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*zdW4628tRwnY7DLaXtaBbA.png"/></div></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk">Evolution of loss and accuracy with the number of training epochs</figcaption></figure><p id="dbb2" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在 50 个周期结束时，验证准确度开始稳定在 60%和 65%之间。</p><p id="17a2" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">训练损失略高于第一个时期的验证损失，这可能令人惊讶。事实上，我们习惯于看到机器学习中验证损失比训练损失更高。在这里，这仅仅是由于辍学的存在，它只适用于培训阶段，而不是在验证阶段。</p><p id="9e9a" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我们可以看到，在第 20 次迭代之后，训练损失变得比验证损失小得多。这意味着我们的模型在太多的时期后开始过度适应我们的训练数据集。这就是为什么验证损失在之后没有减少很多的原因。一种解决方案是提前停止模型的训练。</p><p id="ebdc" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我们也可以使用一些不同的丢弃值并执行数据扩充。这些方法在这个数据集上进行了测试，但是尽管它们减少了过拟合效应，但是它们并没有显著增加验证的准确性。使用它们稍微增加了模型的训练持续时间。</p><p id="7ea3" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">最后，我们可以绘制混淆矩阵，以了解我们的模型如何对图像进行分类:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="np nq l"/></div></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi or"><img src="../Images/0abb6609e389bad06a3b6458d60b8de6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1348/format:webp/1*vq3P8waRENRLkEozhB4shQ.png"/></div></figure><p id="75ce" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我们的模型非常适合预测快乐和惊讶的面孔。然而，它预测的是非常糟糕的恐惧面孔，因为它把它们和悲伤的面孔混淆了。</p><p id="74f9" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">随着更多的研究和更多的资源，这个模型肯定会得到改善，但这项研究的目标主要是集中在获得一个相当好的模型相比，在这个领域已经做了什么。</p><p id="15cf" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">现在是时候在真实情况下尝试我们的模型了！我们将使用 flask 来服务于我们的模型，以便通过网络摄像头输入来执行实时预测。</p><h1 id="09fa" class="mg mh iq bd mi mj mk ml mm mn mo mp mq jw mr jx ms jz mt ka mu kc mv kd mw mx bi translated">实时预测</h1><p id="abbf" class="pw-post-body-paragraph kw kx iq ky b kz na jr lb lc nb ju le lf nc lh li lj nd ll lm ln ne lp lq lr ij bi translated">对于这一部分，我重用了来自以下存储库的一些代码:</p><ul class=""><li id="56e1" class="ls lt iq ky b kz la lc ld lf lu lj lv ln lw lr lx ly lz ma bi translated"><a class="ae kv" href="https://github.com/log0/video_streaming_with_flask_example" rel="noopener ugc nofollow" target="_blank">https://github.com/log0/video_streaming_with_flask_example</a></li><li id="f17e" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr lx ly lz ma bi translated"><a class="ae kv" href="https://github.com/piyush2896/Facial-Expression-Recognition-Challenge" rel="noopener ugc nofollow" target="_blank">https://github . com/piyush 2896/面部表情识别挑战</a></li></ul><p id="6034" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">首先，让我们创建一个类，它将为我们提供之前训练的模型的预测:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="np nq l"/></div></figure><p id="6aaa" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">接下来，我们实现一个 camera 类，它将执行以下操作:</p><ul class=""><li id="bc98" class="ls lt iq ky b kz la lc ld lf lu lj lv ln lw lr lx ly lz ma bi translated">从我们的网络摄像头获取图像流</li><li id="6380" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr lx ly lz ma bi translated">使用 OpenCV 检测人脸并添加边界框</li><li id="fc19" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr lx ly lz ma bi translated">将人脸转换成灰度，重新缩放，然后发送给我们预先训练好的神经网络</li><li id="2560" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr lx ly lz ma bi translated">从我们的神经网络中获取预测，并将标签添加到网络摄像头图像中</li><li id="9879" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr lx ly lz ma bi translated">返回最终的图像流</li></ul><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="np nq l"/></div></figure><p id="0f09" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">最后，我们的主脚本将创建一个 Flask 应用程序，将我们的图像预测渲染到一个网页中。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="np nq l"/></div></figure><p id="691e" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这是结果！</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi os"><img src="../Images/6b6940b24d549b684a5f4aab55a4eefd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1200/1*FEmCiEnI-lsKIWqvmg6Hbw.gif"/></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk">Our face expression recognition app</figcaption></figure><p id="5008" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">有用！我们的应用程序能够检测面部位置并预测正确的表情。</p><p id="9096" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">然而，该模型似乎在恶劣的条件下工作不佳(低光，人没有面对相机，人移动…)，但仍然是一个好的开始！</p><p id="fccd" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">感谢阅读这篇文章，我希望你喜欢它！</p><p id="8dce" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">你可以在这里找到完整的代码:</p><div class="nx ny gp gr nz oa"><a href="https://github.com/jonathanoheix/Real-Time-Face-Expression-Recognition" rel="noopener  ugc nofollow" target="_blank"><div class="ob ab fo"><div class="oc ab od cl cj oe"><h2 class="bd ir gy z fp of fr fs og fu fw ip bi translated">jonathanoheix/实时人脸表情识别</h2><div class="oh l"><h3 class="bd b gy z fp of fr fs og fu fw dk translated">带有 Keras、Flask 和 OpenCV-jonathanoheix/实时面部表情识别的面部表情识别应用程序</h3></div><div class="oi l"><p class="bd b dl z fp of fr fs og fu fw dk translated">github.com</p></div></div><div class="oj l"><div class="ot l ol om on oj oo kp oa"/></div></div></a></div><p id="d8b9" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在 LinkedIn 上找到我:</p><div class="nx ny gp gr nz oa"><a href="https://www.linkedin.com/in/jonathanoheix/" rel="noopener  ugc nofollow" target="_blank"><div class="ob ab fo"><div class="oc ab od cl cj oe"><h2 class="bd ir gy z fp of fr fs og fu fw ip bi translated">Jonathan Oheix -数据科学家- Influans | LinkedIn</h2><div class="oh l"><h3 class="bd b gy z fp of fr fs og fu fw dk translated">查看 Jonathan Oheix 在全球最大的职业社区 LinkedIn 上的个人资料。乔纳森列出了 8 份工作…</h3></div><div class="oi l"><p class="bd b dl z fp of fr fs og fu fw dk translated">www.linkedin.com</p></div></div><div class="oj l"><div class="ou l ol om on oj oo kp oa"/></div></div></a></div></div></div>    
</body>
</html>