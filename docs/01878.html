<html>
<head>
<title>Link Prediction with Neo4j Part 2: Predicting co-authors using scikit-learn</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用 Neo4j 进行链接预测第 2 部分:使用 scikit-learn 预测合著者</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/link-prediction-with-neo4j-part-2-predicting-co-authors-using-scikit-learn-78b42356b44c?source=collection_archive---------5-----------------------#2019-03-28">https://towardsdatascience.com/link-prediction-with-neo4j-part-2-predicting-co-authors-using-scikit-learn-78b42356b44c?source=collection_archive---------5-----------------------#2019-03-28</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="fe14" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">这是最近添加到<a class="ae kf" href="https://neo4j.com/docs/graph-algorithms/current/" rel="noopener ugc nofollow" target="_blank"> Neo4j 图形算法库</a>的链接预测函数系列文章的第二篇。</h2></div><figure class="kh ki kj kk gt kl gh gi paragraph-image"><div role="button" tabindex="0" class="km kn di ko bf kp"><div class="gh gi kg"><img src="../Images/f062df7277fd409e6a5aa4d5d12f3f28.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*DDCMYs0XeppGqyl0MAwKkg.png"/></div></div><figcaption class="ks kt gj gh gi ku kv bd b be z dk">Link Predictions in the Neo4j Graph Algorithms Library</figcaption></figure><p id="f7d5" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在第一篇<a class="ae kf" href="https://medium.com/neo4j/link-prediction-with-neo4j-part-1-an-introduction-713aa779fd9" rel="noopener">帖子</a>中，我们学习了链接预测度量，如何在 Neo4j 中应用它们，以及如何在机器学习分类器中用作特征。我们还了解了在处理图形时拆分训练和测试数据集的挑战。</p><p id="eabf" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在本帖中，我们将应用我们在引用数据集中学到的东西。我们将<strong class="ky ir">使用 scikit-learn 和链接预测算法来预测未来的合作关系</strong>。</p><p id="bfa5" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">Amy Hodler 和我在上周的 Neo4j 在线会议上展示了如何应用本文中描述的方法，所以你也可以观看视频。</p><figure class="kh ki kj kk gt kl"><div class="bz fp l di"><div class="ls lt l"/></div><figcaption class="ks kt gj gh gi ku kv bd b be z dk">Link Prediction Online Meetup</figcaption></figure><p id="6902" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">如果你还在等待书面版本，那就让我们开始吧！</p><h1 id="e976" class="lu lv iq bd lw lx ly lz ma mb mc md me jw mf jx mg jz mh ka mi kc mj kd mk ml bi translated">导入引用数据集</h1><p id="d445" class="pw-post-body-paragraph kw kx iq ky b kz mm jr lb lc mn ju le lf mo lh li lj mp ll lm ln mq lp lq lr ij bi translated">我们将使用来自<a class="ae kf" href="https://aminer.org/citation" rel="noopener ugc nofollow" target="_blank"> DBLP 引文网络</a>的数据，其中包括来自各种学术来源的引文数据。我写了一篇博文解释了如何导入完整的数据集，但是在这篇博文中，我们将关注来自一些软件开发会议的数据。</p><figure class="kh ki kj kk gt kl gh gi paragraph-image"><div class="gh gi mr"><img src="../Images/87f1c372b34be4aeed07a9dea5853d24.png" data-original-src="https://miro.medium.com/v2/resize:fit:1256/format:webp/1*Mp1iSeuCOAafUPGD6IMKiA.png"/></div><figcaption class="ks kt gj gh gi ku kv bd b be z dk">Citation Networks</figcaption></figure><p id="2dd6" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我们可以通过运行以下 Cypher 语句来导入该数据子集。只要在 Neo4j 浏览器中启用了多语句编辑器，就可以一次性运行所有语句:</p><figure class="kh ki kj kk gt kl gh gi paragraph-image"><div class="gh gi ms"><img src="../Images/aee94d4a11c9eeacacb87f064d0ce778.png" data-original-src="https://miro.medium.com/v2/resize:fit:586/format:webp/1*x01aEN66cD6p858eq2aR_Q.png"/></div></figure><pre class="kh ki kj kk gt mt mu mv mw aw mx bi"><span id="1cef" class="my lv iq mu b gy mz na l nb nc">// Create constraints<br/>CREATE CONSTRAINT ON (a:Article) ASSERT a.index IS UNIQUE;<br/>CREATE CONSTRAINT ON (a:Author) ASSERT a.name IS UNIQUE;<br/>CREATE CONSTRAINT ON (v:Venue) ASSERT v.name IS UNIQUE;</span><span id="197e" class="my lv iq mu b gy nd na l nb nc">// Import data from JSON files using the APOC library<br/>CALL apoc.periodic.iterate(<br/>  'UNWIND ["dblp-ref-0.json", "dblp-ref-1.json", "dblp-ref-2.json", "dblp-ref-3.json"] AS file<br/>   CALL apoc.load.json("<a class="ae kf" href="https://github.com/mneedham/link-prediction/raw/master/data/" rel="noopener ugc nofollow" target="_blank">https://github.com/mneedham/link-prediction/raw/master/data/</a>" + file)<br/>   YIELD value WITH value<br/>   RETURN value',<br/>  'MERGE (a:Article {index:value.id})<br/>   SET a += apoc.map.clean(value,["id","authors","references", "venue"],[0])<br/>   WITH a, value.authors as authors, value.references AS citations, value.venue AS venue<br/>   MERGE (v:Venue {name: venue})<br/>   MERGE (a)-[:VENUE]-&gt;(v)<br/>   FOREACH(author in authors | <br/>     MERGE (b:Author{name:author})<br/>     MERGE (a)-[:AUTHOR]-&gt;(b))<br/>   FOREACH(citation in citations | <br/>     MERGE (cited:Article {index:citation})<br/>     MERGE (a)-[:CITED]-&gt;(cited))', <br/>   {batchSize: 1000, iterateList: true});</span></pre><p id="0cda" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">下图显示了数据导入 Neo4j 后的样子:</p><figure class="kh ki kj kk gt kl gh gi paragraph-image"><div role="button" tabindex="0" class="km kn di ko bf kp"><div class="gh gi ne"><img src="../Images/8250a9231a84947f9a4da8162604c872.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*WWr5hwkP6P7AyJ3jVxnMKw.png"/></div></div><figcaption class="ks kt gj gh gi ku kv bd b be z dk">Diagram showing Citation Network in Neo4j</figcaption></figure><h1 id="0732" class="lu lv iq bd lw lx ly lz ma mb mc md me jw mf jx mg jz mh ka mi kc mj kd mk ml bi translated">构建合著者图表</h1><p id="f00f" class="pw-post-body-paragraph kw kx iq ky b kz mm jr lb lc mn ju le lf mo lh li lj mp ll lm ln mq lp lq lr ij bi translated">数据集不包含描述他们合作的作者之间的关系，但我们可以根据找到的多人撰写的文章来推断它们。</p><p id="4b72" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">下面的 Cypher 语句在至少合作过一篇文章的作者之间创建了一个<code class="fe nf ng nh mu b">CO_AUTHOR</code>关系:</p><pre class="kh ki kj kk gt mt mu mv mw aw mx bi"><span id="e055" class="my lv iq mu b gy mz na l nb nc">MATCH (a1)&lt;-[:AUTHOR]-(paper)-[:AUTHOR]-&gt;(a2:Author)<br/>WITH a1, a2, paper<br/>ORDER BY a1, paper.year<br/>WITH a1, a2, collect(paper)[0].year AS year, <br/>     count(*) AS collaborations<br/>MERGE (a1)-[coauthor:CO_AUTHOR {year: year}]-(a2)<br/>SET coauthor.collaborations = collaborations;</span></pre><p id="1281" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我们在已经合作的作者之间只创建一个<strong class="ky ir">关系，即使他们已经合作了多篇文章。我们在这些关系上创建了几个属性:</strong></p><ul class=""><li id="93fa" class="ni nj iq ky b kz la lc ld lf nk lj nl ln nm lr nn no np nq bi translated">一个<code class="fe nf ng nh mu b">year</code>属性，表示作者合作的第一篇文章的出版年份</li><li id="fc32" class="ni nj iq ky b kz nr lc ns lf nt lj nu ln nv lr nn no np nq bi translated">一个<code class="fe nf ng nh mu b">collaborations</code>属性，指示作者合作了多少篇文章</li></ul><figure class="kh ki kj kk gt kl gh gi paragraph-image"><div role="button" tabindex="0" class="km kn di ko bf kp"><div class="gh gi nw"><img src="../Images/7d838204354a484d0997393bd5e2733a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*YreIC_-Qnprjl7c2UaxKnA.png"/></div></div><figcaption class="ks kt gj gh gi ku kv bd b be z dk">Diagram showing co-authorsin Neo4j</figcaption></figure><p id="6bd5" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">现在我们已经有了合著者图表，我们需要弄清楚如何预测作者之间未来的合作。</p><p id="ea26" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">为此，我们将构建一个二元分类器，因此我们的下一步是创建训练和测试图。</p><h1 id="7be2" class="lu lv iq bd lw lx ly lz ma mb mc md me jw mf jx mg jz mh ka mi kc mj kd mk ml bi translated">训练和测试数据集</h1><p id="d647" class="pw-post-body-paragraph kw kx iq ky b kz mm jr lb lc mn ju le lf mo lh li lj mp ll lm ln mq lp lq lr ij bi translated">正如在第一篇文章中提到的，我们不能随意将数据分成训练和测试数据集，因为这可能导致数据泄漏。</p><p id="ede1" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">当您的训练数据之外的数据被无意中用于创建您的模型时，可能会发生数据泄漏。这在处理图形时很容易发生，因为我们的训练集中的节点对可能连接到测试集中的节点对。</p><p id="fbf2" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">相反，我们需要将我们的图分成训练和测试子图，幸运的是，我们的引用图包含我们可以分割的时间信息。我们将通过拆分特定年份的数据来创建训练和测试图。</p><p id="1ae0" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">但是我们应该在哪一年分手呢？我们来看看合著者合作的第一年的分布情况:</p><figure class="kh ki kj kk gt kl gh gi paragraph-image"><div role="button" tabindex="0" class="km kn di ko bf kp"><div class="gh gi nx"><img src="../Images/d8e7139a957015c691d48f3eb5da8894.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*JRCV3cyFHwQ8DdUS1Baf3g.png"/></div></div><figcaption class="ks kt gj gh gi ku kv bd b be z dk">Chart showing distribution of year of collaboration</figcaption></figure><p id="9a2a" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">看起来 2006 年是拆分数据的好年份，因为它将为我们的每个子图提供合理数量的数据。我们将把 2005 年及更早的所有合作者作为我们的训练图，而从 2006 年开始的所有合作者作为测试图。</p><p id="e2aa" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">让我们基于该年在图表中创建明确的<code class="fe nf ng nh mu b">CO_AUTHOR_EARLY</code>和<code class="fe nf ng nh mu b">CO_AUTHOR_LATE</code>关系。以下代码将为我们创建这些关系:</p><p id="d601" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><em class="ny">列车子图</em></p><pre class="kh ki kj kk gt mt mu mv mw aw mx bi"><span id="024e" class="my lv iq mu b gy mz na l nb nc">MATCH (a)-[r:CO_AUTHOR]-&gt;(b) <br/>WHERE r.year &lt; 2006<br/>MERGE (a)-[:CO_AUTHOR_EARLY {year: r.year}]-(b);</span></pre><p id="1be9" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><em class="ny">测试子图</em></p><pre class="kh ki kj kk gt mt mu mv mw aw mx bi"><span id="dcf1" class="my lv iq mu b gy mz na l nb nc">MATCH (a)-[r:CO_AUTHOR]-&gt;(b) <br/>WHERE r.year &gt;= 2006<br/>MERGE (a)-[:CO_AUTHOR_LATE {year: r.year}]-(b);</span></pre><p id="da42" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这种分裂在早期图表中留给我们 81，096 个关系，在后期图表中留给我们 74，128 个关系。这是 52 比 48 的比例。这比我们通常在测试图中看到的数值百分比要高，但是应该没问题。</p><p id="a205" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这些子图中的关系将作为我们训练和测试集中的<strong class="ky ir">正例</strong>，但是我们也需要一些<strong class="ky ir">反例</strong>。需要反面的例子，这样我们的模型就可以学习区分应该有链接的节点和不应该有链接的节点。</p><p id="bc43" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">正如在链接预测问题中经常出现的情况一样，负面例子比正面例子多得多。反例的最大数量等于:</p><pre class="kh ki kj kk gt mt mu mv mw aw mx bi"><span id="af06" class="my lv iq mu b gy mz na l nb nc"># negative examples = (# nodes)² - (# relationships) - (# nodes)</span></pre><p id="ec5b" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">即节点数的平方，减去图中的关系，减去自身关系。</p><p id="0316" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我们不是使用几乎所有可能的节点对，而是使用彼此相距 2 到 3 跳<strong class="ky ir">的节点对。这将为我们提供更多可管理的数据。</strong></p><p id="21e1" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我们可以通过运行以下查询来生成这些对:</p><pre class="kh ki kj kk gt mt mu mv mw aw mx bi"><span id="19f1" class="my lv iq mu b gy mz na l nb nc">MATCH (author:Author)<br/>WHERE (author)-[:CO_AUTHOR_EARLY]-()<br/>MATCH (author)-[:CO_AUTHOR_EARLY*2..3]-(other)<br/>WHERE not((author)-[:CO_AUTHOR_EARLY]-(other))<br/>RETURN id(author) AS node1, id(other) AS node2</span></pre><p id="6fbd" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这个查询返回了 4389478 个负面例子，而 81096 个正面例子，这意味着我们有<strong class="ky ir"> 54 倍于</strong>的负面例子。</p><figure class="kh ki kj kk gt kl gh gi paragraph-image"><div class="gh gi nz"><img src="../Images/c5f6c53ee45bcb4287cf3101f752d96c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1200/format:webp/1*hDIcPQtZVJ8sORWfpLFmhg.jpeg"/></div><figcaption class="ks kt gj gh gi ku kv bd b be z dk">Imbalanced data</figcaption></figure><p id="e089" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">因此，我们仍然有很大的类别不平衡，<strong class="ky ir">这意味着预测每对节点都不会有链接的模型将非常准确。</strong></p><p id="c1fc" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">为了解决这个问题，我们可以对正样本进行上采样，或者对负样本进行下采样。我们将采用下采样方法。</p><h2 id="424b" class="my lv iq bd lw oa ob dn ma oc od dp me lf oe of mg lj og oh mi ln oi oj mk ok bi translated">py2neo，熊猫，scikit-学习</h2><p id="4620" class="pw-post-body-paragraph kw kx iq ky b kz mm jr lb lc mn ju le lf mo lh li lj mp ll lm ln mq lp lq lr ij bi translated">在这篇文章的剩余部分，我们将用 Python 处理<a class="ae kf" href="https://py2neo.org/v4/" rel="noopener ugc nofollow" target="_blank"> py2neo </a>、<a class="ae kf" href="https://pandas.pydata.org/" rel="noopener ugc nofollow" target="_blank"> pandas </a>和<a class="ae kf" href="https://scikit-learn.org/stable/" rel="noopener ugc nofollow" target="_blank"> scikit-learn </a>库。</p><p id="53d1" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><a class="ae kf" href="https://py2neo.org/v4/" rel="noopener ugc nofollow" target="_blank"> py2neo </a>驱动程序使数据科学家能够<strong class="ky ir">轻松地将 Neo4j 与 Python 数据科学生态系统中的工具集成</strong>。我们将使用这个库对 Neo4j 执行 Cypher 查询。</p><p id="2a08" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir"> pandas </strong>是一个开源的、BSD 许可的库，为 Python 编程语言提供了高性能、易于使用的数据结构和数据分析工具</p><p id="bc89" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir"> scikit-learn </strong>是一个流行的机器学习库。我们将使用这个库来构建我们的机器学习模型。</p><p id="5cf3" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我们可以从 PyPi 安装这些库:</p><pre class="kh ki kj kk gt mt mu mv mw aw mx bi"><span id="48bc" class="my lv iq mu b gy mz na l nb nc">pip install py2neo==4.1.3 pandas sklearn</span></pre><p id="b4f0" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">一旦我们安装了这些库，我们将导入所需的包，并创建一个数据库连接:</p><pre class="kh ki kj kk gt mt mu mv mw aw mx bi"><span id="6bab" class="my lv iq mu b gy mz na l nb nc">from py2neo import Graph<br/>import pandas as pd</span><span id="2baf" class="my lv iq mu b gy nd na l nb nc">graph = Graph("bolt://localhost", auth=("neo4j", "neo4jPassword"))</span></pre><h2 id="8527" class="my lv iq bd lw oa ob dn ma oc od dp me lf oe of mg lj og oh mi ln oi oj mk ok bi translated"><strong class="ak">构建我们的训练和测试集</strong></h2><p id="7023" class="pw-post-body-paragraph kw kx iq ky b kz mm jr lb lc mn ju le lf mo lh li lj mp ll lm ln mq lp lq lr ij bi translated">我们现在可以编写以下代码来创建一个包含基于<strong class="ky ir">早期图</strong>的正面和反面例子的测试数据帧:</p><pre class="kh ki kj kk gt mt mu mv mw aw mx bi"><span id="8f50" class="my lv iq mu b gy mz na l nb nc"># Find positive examples<br/>train_existing_links = graph.run("""<br/>MATCH (author:Author)-[:CO_AUTHOR_EARLY]-&gt;(other:Author)<br/>RETURN id(author) AS node1, id(other) AS node2, 1 AS label<br/>""").to_data_frame()</span><span id="ad07" class="my lv iq mu b gy nd na l nb nc"># Find negative examples<br/>train_missing_links = graph.run("""<br/>MATCH (author:Author)<br/>WHERE (author)-[:CO_AUTHOR_EARLY]-()<br/>MATCH (author)-[:CO_AUTHOR_EARLY*2..3]-(other)<br/>WHERE not((author)-[:CO_AUTHOR_EARLY]-(other))<br/>RETURN id(author) AS node1, id(other) AS node2, 0 AS label<br/>""").to_data_frame()</span><span id="78fc" class="my lv iq mu b gy nd na l nb nc"># Remove duplicates<br/>train_missing_links = train_missing_links.drop_duplicates()</span><span id="d7ab" class="my lv iq mu b gy nd na l nb nc"># Down sample negative examples<br/>train_missing_links = train_missing_links.sample(<br/>    n=len(train_existing_links))</span><span id="06db" class="my lv iq mu b gy nd na l nb nc"># Create DataFrame from positive and negative examples<br/>training_df = train_missing_links.append(<br/>    train_existing_links, ignore_index=True)<br/>training_df['label'] = training_df['label'].astype('category')</span></pre><figure class="kh ki kj kk gt kl gh gi paragraph-image"><div role="button" tabindex="0" class="km kn di ko bf kp"><div class="gh gi ol"><img src="../Images/01c60e4ecab78d651715e6de2b7ac2d7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*gK-pYiE_Y3_lglp8khw8vQ.png"/></div></div><figcaption class="ks kt gj gh gi ku kv bd b be z dk">Sample of the training DataFrame</figcaption></figure><p id="bf4a" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">现在我们将做同样的事情来创建一个测试数据帧，但是这次我们只考虑<strong class="ky ir">后期图</strong>中的关系:</p><pre class="kh ki kj kk gt mt mu mv mw aw mx bi"><span id="03ca" class="my lv iq mu b gy mz na l nb nc"># Find positive examples<br/>test_existing_links = graph.run("""<br/>MATCH (author:Author)-[:CO_AUTHOR_LATE]-&gt;(other:Author)<br/>RETURN id(author) AS node1, id(other) AS node2, 1 AS label<br/>""").to_data_frame()</span><span id="f804" class="my lv iq mu b gy nd na l nb nc"># Find negative examples<br/>test_missing_links = graph.run("""<br/>MATCH (author:Author)<br/>WHERE (author)-[:CO_AUTHOR_LATE]-()<br/>MATCH (author)-[:CO_AUTHOR_LATE*2..3]-(other)<br/>WHERE not((author)-[:CO_AUTHOR_LATE]-(other))<br/>RETURN id(author) AS node1, id(other) AS node2, 0 AS label<br/>""").to_data_frame()</span><span id="c2e4" class="my lv iq mu b gy nd na l nb nc"># Remove duplicates <br/>test_missing_links = test_missing_links.drop_duplicates()</span><span id="a3c3" class="my lv iq mu b gy nd na l nb nc"># Down sample negative examples<br/>test_missing_links = test_missing_links.sample(n=len(test_existing_links))</span><span id="859e" class="my lv iq mu b gy nd na l nb nc"># Create DataFrame from positive and negative examples<br/>test_df = test_missing_links.append(<br/>    test_existing_links, ignore_index=True)<br/>test_df['label'] = test_df['label'].astype('category')</span></pre><p id="e2cf" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">现在是时候创建我们的机器学习模型了。</p><h1 id="025a" class="lu lv iq bd lw lx ly lz ma mb mc md me jw mf jx mg jz mh ka mi kc mj kd mk ml bi translated">选择机器学习算法</h1><p id="d14a" class="pw-post-body-paragraph kw kx iq ky b kz mm jr lb lc mn ju le lf mo lh li lj mp ll lm ln mq lp lq lr ij bi translated">我们将创建一个随机森林分类器。这种方法非常适合，因为我们的数据集将由强特征和弱特征混合组成。虽然弱特征有时会有所帮助，但随机森林方法将确保我们不会创建过度适合我们的训练数据的模型。</p><p id="1d04" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我们可以用下面的代码创建这个模型:</p><pre class="kh ki kj kk gt mt mu mv mw aw mx bi"><span id="feb5" class="my lv iq mu b gy mz na l nb nc">from sklearn.ensemble import RandomForestClassifier</span><span id="ee7c" class="my lv iq mu b gy nd na l nb nc">classifier = RandomForestClassifier(n_estimators=30, max_depth=10, <br/>                                    random_state=0)</span></pre><p id="f783" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">现在是时候<strong class="ky ir">设计一些特征</strong>来训练我们的模型了。</p><p id="2f23" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">特征提取是一种从大量数据和属性中提取出一组有代表性的数值，即特征的方法。然后将其用作输入数据，这样我们就可以区分学习任务的类别/值。</p><blockquote class="om on oo"><p id="d49a" class="kw kx ny ky b kz la jr lb lc ld ju le op lg lh li oq lk ll lm or lo lp lq lr ij bi translated">请记住，如果您想在这篇文章的下一部分试用代码示例，您需要确保您已经按照本系列文章的第<a class="ae kf" href="https://medium.com/neo4j/link-prediction-with-neo4j-part-1-an-introduction-713aa779fd9" rel="noopener">篇文章中所述设置了 Neo4j 开发环境。</a></p></blockquote><h1 id="b1bb" class="lu lv iq bd lw lx ly lz ma mb mc md me jw mf jx mg jz mh ka mi kc mj kd mk ml bi translated">生成链接预测要素</h1><p id="9652" class="pw-post-body-paragraph kw kx iq ky b kz mm jr lb lc mn ju le lf mo lh li lj mp ll lm ln mq lp lq lr ij bi translated">我们将首先使用链接预测函数创建一些要素</p><pre class="kh ki kj kk gt mt mu mv mw aw mx bi"><span id="64a4" class="my lv iq mu b gy mz na l nb nc">def apply_graphy_features(data, rel_type):<br/>    query = """<br/>    UNWIND $pairs AS pair<br/>    MATCH (p1) WHERE id(p1) = pair.node1<br/>    MATCH (p2) WHERE id(p2) = pair.node2<br/>    RETURN pair.node1 AS node1,<br/>           pair.node2 AS node2,<br/>           algo.linkprediction.commonNeighbors(<br/>               p1, p2, {relationshipQuery: $relType}) AS cn,<br/>           algo.linkprediction.preferentialAttachment(<br/>               p1, p2, {relationshipQuery: $relType}) AS pa,<br/>           algo.linkprediction.totalNeighbors(<br/>               p1, p2, {relationshipQuery: $relType}) AS tn<br/>    """<br/>    pairs = [{"node1": pair[0], "node2": pair[1]}  <br/>             for pair in data[["node1", "node2"]].values.tolist()]<br/>    params = {"pairs": pairs, "relType": rel_type}<br/>    <br/>    features = graph.run(query, params).to_data_frame()<br/>    return pd.merge(data, features, on = ["node1", "node2"])</span></pre><p id="377f" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">此函数执行一个查询，该查询从提供的数据帧中提取每对节点，并计算:</p><ul class=""><li id="906d" class="ni nj iq ky b kz la lc ld lf nk lj nl ln nm lr nn no np nq bi translated">共同邻居(cn)</li><li id="5232" class="ni nj iq ky b kz nr lc ns lf nt lj nu ln nv lr nn no np nq bi translated">优先附件(pa)，以及</li><li id="4926" class="ni nj iq ky b kz nr lc ns lf nt lj nu ln nv lr nn no np nq bi translated">邻居总数(tn)</li></ul><p id="4d76" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">对于每一对。这些措施在第一篇文章中被定义为<a class="ae kf" href="https://medium.com/neo4j/link-prediction-with-neo4j-part-1-an-introduction-713aa779fd9" rel="noopener">。</a></p><p id="1cc8" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我们可以将它应用到我们的训练和测试数据帧中，如下所示:</p><pre class="kh ki kj kk gt mt mu mv mw aw mx bi"><span id="c80d" class="my lv iq mu b gy mz na l nb nc">training_df = apply_graphy_features(training_df, "CO_AUTHOR_EARLY")<br/>test_df = apply_graphy_features(test_df, "CO_AUTHOR")</span></pre><p id="cea1" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">对于训练数据帧，我们仅基于早期的图表计算这些指标，而对于测试数据帧，我们将跨整个图表计算它们。</p><p id="b9ab" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我们仍然可以使用整个图表来计算这些特征，因为图表的演变取决于它在整个时间内的样子，而不仅仅是基于 2006 年及以后发生的事情。</p><figure class="kh ki kj kk gt kl gh gi paragraph-image"><div role="button" tabindex="0" class="km kn di ko bf kp"><div class="gh gi os"><img src="../Images/b03af66a80f4631f87eb6ef18268a7de.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*-D0rx4Uuv7EZcaw03fdXEA.png"/></div></div><figcaption class="ks kt gj gh gi ku kv bd b be z dk">Sample of the training DataFrame</figcaption></figure><p id="81af" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">现在我们准备训练我们的模型。我们可以用下面的代码做到这一点:</p><pre class="kh ki kj kk gt mt mu mv mw aw mx bi"><span id="3280" class="my lv iq mu b gy mz na l nb nc">columns = ["cn", "pa", "tn"]</span><span id="b7df" class="my lv iq mu b gy nd na l nb nc">X = training_df[columns]<br/>y = training_df["label"]<br/>classifier.fit(X, y)</span></pre><p id="00b9" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我们的模型现在已经训练好了，但是我们需要评估它。</p><h1 id="2b5c" class="lu lv iq bd lw lx ly lz ma mb mc md me jw mf jx mg jz mh ka mi kc mj kd mk ml bi translated">评估我们的模型</h1><p id="315a" class="pw-post-body-paragraph kw kx iq ky b kz mm jr lb lc mn ju le lf mo lh li lj mp ll lm ln mq lp lq lr ij bi translated">我们要计算它的准确度、精确度和召回率。下图摘自<a class="ae kf" href="https://www.oreilly.com/library/view/graph-algorithms/9781492047674/" rel="noopener ugc nofollow" target="_blank">奥莱利图算法书</a>，解释了这些指标是如何计算的。</p><figure class="kh ki kj kk gt kl gh gi paragraph-image"><div role="button" tabindex="0" class="km kn di ko bf kp"><div class="gh gi ot"><img src="../Images/c97902cd3001872dbdd8c8fdaa9e7441.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*itbkirpjJRU71ckb7EO3Aw.png"/></div></div><figcaption class="ks kt gj gh gi ku kv bd b be z dk">Accuracy measures</figcaption></figure><p id="9868" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">scikit-learn 内置了我们可以用于此的函数。我们还可以返回模型中使用的每个特性的重要性。</p><p id="c7b2" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">以下函数将对此有所帮助:</p><pre class="kh ki kj kk gt mt mu mv mw aw mx bi"><span id="295d" class="my lv iq mu b gy mz na l nb nc">from sklearn.metrics import recall_score<br/>from sklearn.metrics import precision_score<br/>from sklearn.metrics import accuracy_score</span><span id="26a3" class="my lv iq mu b gy nd na l nb nc">def evaluate_model(predictions, actual):<br/>    accuracy = accuracy_score(actual, predictions)<br/>    precision = precision_score(actual, predictions)<br/>    recall = recall_score(actual, predictions)<br/>    <br/>    metrics = ["accuracy", "precision", "recall"]<br/>    values = [accuracy, precision, recall]    <br/>    return pd.DataFrame(data={'metric': metrics, 'value': values})</span><span id="0236" class="my lv iq mu b gy nd na l nb nc">def feature_importance(columns, classifier):        <br/>    features = list(zip(columns, classifier.feature_importances_))<br/>    sorted_features = sorted(features, key = lambda x: x[1]*-1)<br/>    <br/>    keys = [value[0] for value in sorted_features]<br/>    values = [value[1] for value in sorted_features]<br/>    return pd.DataFrame(data={'feature': keys, 'value': values})</span></pre><p id="7438" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我们可以通过运行以下代码来评估我们的模型:</p><pre class="kh ki kj kk gt mt mu mv mw aw mx bi"><span id="d4e0" class="my lv iq mu b gy mz na l nb nc">predictions = classifier.predict(test_df[columns])<br/>y_test = test_df["label"]</span><span id="289e" class="my lv iq mu b gy nd na l nb nc">evaluate_model(predictions, y_test)</span></pre><figure class="kh ki kj kk gt kl gh gi paragraph-image"><div class="gh gi ou"><img src="../Images/f47fe8d3e935d66a5f10c7ab859b52d1.png" data-original-src="https://miro.medium.com/v2/resize:fit:600/format:webp/1*UmhMqYuMMhHu98siiZF1WA.png"/></div><figcaption class="ks kt gj gh gi ku kv bd b be z dk">Accuracy, Precision, Recall</figcaption></figure><p id="c2af" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我们在各方面都有很高的分数。现在，我们可以运行以下代码来查看哪个功能发挥了最重要的作用:</p><pre class="kh ki kj kk gt mt mu mv mw aw mx bi"><span id="6692" class="my lv iq mu b gy mz na l nb nc">feature_importance(columns, classifier)</span></pre><figure class="kh ki kj kk gt kl gh gi paragraph-image"><div class="gh gi ov"><img src="../Images/a819ebc33247b62314ad5dbd69e9ab94.png" data-original-src="https://miro.medium.com/v2/resize:fit:516/format:webp/1*RDFpZJDnjW2694jAKb8qOQ.png"/></div><figcaption class="ks kt gj gh gi ku kv bd b be z dk">Feature Importance</figcaption></figure><p id="a491" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我们可以在上面看到，公共邻居(cn)是我们模型中的主要特征。Common neighbors 向我们返回了一个作者拥有的未闭合合著三角形的数量，因此这可能并不令人惊讶。</p><p id="9ef9" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">现在，我们将添加一些由图形算法生成的新功能。</p><h1 id="6607" class="lu lv iq bd lw lx ly lz ma mb mc md me jw mf jx mg jz mh ka mi kc mj kd mk ml bi translated">三角形和聚集系数</h1><p id="42b7" class="pw-post-body-paragraph kw kx iq ky b kz mm jr lb lc mn ju le lf mo lh li lj mp ll lm ln mq lp lq lr ij bi translated">我们将从在测试和训练子图上运行<a class="ae kf" href="https://neo4j.com/docs/graph-algorithms/current/algorithms/triangle-counting-clustering-coefficient/" rel="noopener ugc nofollow" target="_blank">三角形计数</a>算法开始。该算法返回每个节点形成的三角形数量，以及每个节点的聚类系数。节点的聚类系数表示其邻居也是相连的可能性。</p><p id="142d" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我们可以在 Neo4j 浏览器中运行以下 Cypher 查询，以在我们的列车图上运行该算法:</p><pre class="kh ki kj kk gt mt mu mv mw aw mx bi"><span id="139a" class="my lv iq mu b gy mz na l nb nc">CALL algo.triangleCount('Author', 'CO_AUTHOR_EARLY', { <br/>  write:true,<br/>  writeProperty:'trianglesTrain', <br/>  clusteringCoefficientProperty:'coefficientTrain'});</span></pre><p id="8376" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">和下面的 Cypher 查询来在测试图上运行它:</p><pre class="kh ki kj kk gt mt mu mv mw aw mx bi"><span id="b568" class="my lv iq mu b gy mz na l nb nc">CALL algo.triangleCount('Author', 'CO_AUTHOR', { <br/>  write:true,<br/>  writeProperty:'trianglesTest', <br/>  clusteringCoefficientProperty:'coefficientTest'});</span></pre><p id="0db8" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我们现在在节点上有 4 个新属性:<em class="ny"> trianglesTrain </em>、<em class="ny">系数 Train </em>、<em class="ny"> trianglesTest </em>和<em class="ny">系数 Test </em>。现在，让我们在以下函数的帮助下，将这些添加到我们的训练和测试数据帧中:</p><pre class="kh ki kj kk gt mt mu mv mw aw mx bi"><span id="798f" class="my lv iq mu b gy mz na l nb nc">def apply_triangles_features(data,triangles_prop,coefficient_prop):<br/>    query = """<br/>    UNWIND $pairs AS pair<br/>    MATCH (p1) WHERE id(p1) = pair.node1<br/>    MATCH (p2) WHERE id(p2) = pair.node2<br/>    RETURN pair.node1 AS node1,<br/>    pair.node2 AS node2,<br/>    apoc.coll.min([p1[$triangles], p2[$triangles]]) AS minTriangles,<br/>    apoc.coll.max([p1[$triangles], p2[$triangles]]) AS maxTriangles,<br/>    apoc.coll.min([p1[$coefficient], p2[$coefficient]]) AS minCoeff,<br/>    apoc.coll.max([p1[$coefficient], p2[$coefficient]]) AS maxCoeff<br/>    """<br/>    <br/>    pairs = [{"node1": pair[0], "node2": pair[1]}  <br/>          for pair in data[["node1", "node2"]].values.tolist()]</span><span id="426a" class="my lv iq mu b gy nd na l nb nc">    params = {"pairs": pairs,<br/>              "triangles": triangles_prop,<br/>              "coefficient": coefficient_prop}<br/>    <br/>    features = graph.run(query, params).to_data_frame()<br/>    return pd.merge(data, features, on = ["node1", "node2"])</span></pre><p id="94ce" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这些度量与我们迄今为止使用的不同，因为它们不是基于节点对计算的，而是特定于节点的度量。</p><p id="3322" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我们不能简单地将这些值作为<em class="ny"> node1Triangles </em>或<em class="ny"> node1Coeff </em>添加到我们的数据帧中，因为我们不能保证节点对中节点的顺序。我们需要想出一个不可知论的方法</p><p id="155b" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我们可以通过取值的平均值、值的乘积，或者通过计算最小值和最大值来实现这一点，就像我们在这里所做的那样。</p><p id="9ab2" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我们可以将该函数应用于数据帧，如下所示:</p><pre class="kh ki kj kk gt mt mu mv mw aw mx bi"><span id="93cb" class="my lv iq mu b gy mz na l nb nc">training_df = apply_triangles_features(training_df, <br/>  "trianglesTrain", "coefficientTrain")<br/>test_df = apply_triangles_features(test_df, <br/>  "trianglesTest", "coefficientTest")</span></pre><p id="93e9" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">现在我们可以训练和评估:</p><pre class="kh ki kj kk gt mt mu mv mw aw mx bi"><span id="ff92" class="my lv iq mu b gy mz na l nb nc">columns = [<br/>    "cn", "pa", "tn", <br/>    "minTriangles", "maxTriangles", "minCoeff", "maxCoeff"<br/>]</span><span id="1287" class="my lv iq mu b gy nd na l nb nc">X = training_df[columns]<br/>y = training_df["label"]<br/>classifier.fit(X, y)</span><span id="b21e" class="my lv iq mu b gy nd na l nb nc">predictions = classifier.predict(test_df[columns])<br/>y_test = test_df["label"]</span><span id="5fce" class="my lv iq mu b gy nd na l nb nc">display(evaluate_model(predictions, y_test))</span></pre><figure class="kh ki kj kk gt kl gh gi paragraph-image"><div class="gh gi ow"><img src="../Images/5cfa48a71825ed3970ac49547902babc.png" data-original-src="https://miro.medium.com/v2/resize:fit:460/format:webp/1*3j0icuCmyXNrtxw9s_i-2Q.png"/></div><figcaption class="ks kt gj gh gi ku kv bd b be z dk">Accuracy, Precision, Recall</figcaption></figure><p id="254a" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这些功能非常有用！我们的每项指标都比最初的模型提高了大约 4%。哪些功能最重要？</p><pre class="kh ki kj kk gt mt mu mv mw aw mx bi"><span id="6a4b" class="my lv iq mu b gy mz na l nb nc">display(feature_importance(columns, classifier))</span></pre><figure class="kh ki kj kk gt kl gh gi paragraph-image"><div class="gh gi ox"><img src="../Images/11a112e5959046ec8f7c35aea2f2c5e5.png" data-original-src="https://miro.medium.com/v2/resize:fit:530/format:webp/1*sCBU7cWHeRL80r2r9Y4RrA.png"/></div><figcaption class="ks kt gj gh gi ku kv bd b be z dk">Feature Importance</figcaption></figure><p id="b0c5" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">公共邻域仍然是最有影响力的，但三角形功能也增加了一些价值。</p><h1 id="8038" class="lu lv iq bd lw lx ly lz ma mb mc md me jw mf jx mg jz mh ka mi kc mj kd mk ml bi translated">概括起来</h1><p id="9906" class="pw-post-body-paragraph kw kx iq ky b kz mm jr lb lc mn ju le lf mo lh li lj mp ll lm ln mq lp lq lr ij bi translated">这篇文章已经比我预期的时间长了很多，所以我们就到此为止，但是肯定还有一些练习留给读者。</p><h2 id="89e6" class="my lv iq bd lw oa ob dn ma oc od dp me lf oe of mg lj og oh mi ln oi oj mk ok bi translated">工程更多功能</h2><p id="eb3f" class="pw-post-body-paragraph kw kx iq ky b kz mm jr lb lc mn ju le lf mo lh li lj mp ll lm ln mq lp lq lr ij bi translated">你能想到我们可以添加的任何其他功能来帮助我们创建一个更高精度的模型吗？也许其他社区检测，甚至中心算法可能会有所帮助？</p><h2 id="53d4" class="my lv iq bd lw oa ob dn ma oc od dp me lf oe of mg lj og oh mi ln oi oj mk ok bi translated">扩展对链接预测的支持</h2><p id="18a2" class="pw-post-body-paragraph kw kx iq ky b kz mm jr lb lc mn ju le lf mo lh li lj mp ll lm ln mq lp lq lr ij bi translated">目前，图算法库中的链接预测算法仅适用于单部图。单部图是指两个节点的标号相同的图。这些算法基于节点的拓扑结构，如果我们试图将它们应用于具有不同标签的节点，这些节点将可能具有不同的拓扑结构，这意味着这些算法不会工作得很好。</p><p id="fb5a" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我们正在考虑添加适用于其他图形的链接预测算法版本。如果你有什么特别想看的，请在<a class="ae kf" href="https://github.com/neo4j-contrib/neo4j-graph-algorithms/issues" rel="noopener ugc nofollow" target="_blank"> GitHub 问题</a>上告诉我们。</p><h1 id="e954" class="lu lv iq bd lw lx ly lz ma mb mc md me jw mf jx mg jz mh ka mi kc mj kd mk ml bi translated">接下来呢？</h1><figure class="kh ki kj kk gt kl gh gi paragraph-image"><div class="gh gi oy"><img src="../Images/e3d126816d4b16acd10188b7738f900b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*95R362FZTZxMma61NS8qxg.png"/></div></figure><p id="cf4c" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">如果你觉得这篇博文很有趣，你可能会喜欢我和艾米·霍德勒在过去 9 个月里写的《奥莱利图算法》一书。我们正处于最后的审查阶段，它应该在未来几周内可用。</p><p id="7afe" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">您可以注册从 Neo4j 网站获得免费的电子版，网址:<a class="ae kf" href="https://neo4j.com/graph-algorithms-book/" rel="noopener ugc nofollow" target="_blank"><strong class="ky ir">neo4j.com/graph-algorithms-book</strong></a></p><p id="2f5a" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">威尔·里昂和我还在与 Neo4j 一起开发一个新的关于<strong class="ky ir">数据科学的在线培训课程，请关注<a class="ae kf" href="https://neo4j.com/graphacademy/online-training/" rel="noopener ugc nofollow" target="_blank">在线培训</a>页面，了解详细信息。</strong></p></div></div>    
</body>
</html>