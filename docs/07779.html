<html>
<head>
<title>Demystifying Model Training &amp; Tuning</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">揭开模型训练和调整的神秘面纱</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/demystifying-model-training-tuning-f4e6b46e7307?source=collection_archive---------10-----------------------#2019-10-28">https://towardsdatascience.com/demystifying-model-training-tuning-f4e6b46e7307?source=collection_archive---------10-----------------------#2019-10-28</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><figure class="gl gn jr js jt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi jq"><img src="../Images/3818717af779e1b6ff948f76e768f0d2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*4sLRRKZZYj38E5fy"/></div></div></figure><p id="9648" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">不同的机器学习算法在寻找不同的趋势和模式。因此，一种算法不是所有数据集或所有用例的最佳算法。为了找到最佳解决方案，我们进行了大量的实验，评估不同的机器学习算法，并调整它们的超参数。这篇文章介绍了各种重要的话题:</p><ul class=""><li id="58f0" class="kz la it kd b ke kf ki kj km lb kq lc ku ld ky le lf lg lh bi translated">培训、测试和验证数据</li><li id="d0d5" class="kz la it kd b ke li ki lj km lk kq ll ku lm ky le lf lg lh bi translated">算法探索</li><li id="d0c6" class="kz la it kd b ke li ki lj km lk kq ll ku lm ky le lf lg lh bi translated">超参数优化</li><li id="4454" class="kz la it kd b ke li ki lj km lk kq ll ku lm ky le lf lg lh bi translated">合奏</li></ul><h1 id="2e8a" class="ln lo it bd lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk bi translated">术语</h1><h2 id="7f24" class="ml lo it bd lp mm mn dn lt mo mp dp lx km mq mr mb kq ms mt mf ku mu mv mj mw bi translated">偏见</h2><p id="08db" class="pw-post-body-paragraph kb kc it kd b ke mx kg kh ki my kk kl km mz ko kp kq na ks kt ku nb kw kx ky im bi translated">偏差是完全符合您的数据的模型参数与您的算法已经学习到的参数之间的预期差异。与高偏差算法相比，低偏差算法(决策树、K-最近邻和支持向量机)倾向于找到更复杂的模式。</p><h2 id="d99a" class="ml lo it bd lp mm mn dn lt mo mp dp lx km mq mr mb kq ms mt mf ku mu mv mj mw bi translated">差异</h2><p id="7910" class="pw-post-body-paragraph kb kc it kd b ke mx kg kh ki my kk kl km mz ko kp kq na ks kt ku nb kw kx ky im bi translated">这是算法受训练数据影响的程度；参数随着新的训练数据改变多少。低方差算法(如线性回归、逻辑回归和朴素贝叶斯)往往比高方差算法找到的模式更简单。</p><h2 id="a3b0" class="ml lo it bd lp mm mn dn lt mo mp dp lx km mq mr mb kq ms mt mf ku mu mv mj mw bi translated">欠拟合</h2><p id="5f9a" class="pw-post-body-paragraph kb kc it kd b ke mx kg kh ki my kk kl km mz ko kp kq na ks kt ku nb kw kx ky im bi translated">模型过于简单，无法捕捉数据中的模式；这将在它已经被训练的数据以及看不见的数据上表现不佳。高偏差，低方差。高训练误差和高测试误差。</p><h2 id="7dd5" class="ml lo it bd lp mm mn dn lt mo mp dp lx km mq mr mb kq ms mt mf ku mu mv mj mw bi translated">过度拟合</h2><p id="40eb" class="pw-post-body-paragraph kb kc it kd b ke mx kg kh ki my kk kl km mz ko kp kq na ks kt ku nb kw kx ky im bi translated">模型太复杂或太具体，捕捉的趋势不能概括；它将准确预测它已经训练过的数据，但不会预测看不见的数据。低偏差，高方差。训练误差低，测试误差高。</p><figure class="nd ne nf ng gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi nc"><img src="../Images/dbf11283f3735f8bfbeb148c7d712129.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*v7CCpKBfPjug7K1Pos048w.png"/></div></div></figure><h2 id="a501" class="ml lo it bd lp mm mn dn lt mo mp dp lx km mq mr mb kq ms mt mf ku mu mv mj mw bi translated">偏差-方差权衡</h2><p id="0b76" class="pw-post-body-paragraph kb kc it kd b ke mx kg kh ki my kk kl km mz ko kp kq na ks kt ku nb kw kx ky im bi translated">偏差-方差权衡是指找到一个具有适当复杂性的模型，使训练和测试误差最小化。</p><p id="f48b" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">延伸阅读:<a class="ae nh" href="https://elitedatascience.com/bias-variance-tradeoff" rel="noopener ugc nofollow" target="_blank">偏差-方差权衡信息图</a></p><h1 id="4fc3" class="ln lo it bd lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk bi translated">培训、验证和测试数据</h1><p id="08c7" class="pw-post-body-paragraph kb kc it kd b ke mx kg kh ki my kk kl km mz ko kp kq na ks kt ku nb kw kx ky im bi translated">机器学习算法从例子中学习，如果你有好的数据，你提供的例子越多，它就越容易在数据中找到模式。然而，你必须小心过度拟合；过度拟合是指模型可以准确地预测它已经训练过的数据，但不能推广到以前没有见过的数据。</p><p id="20f2" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">这就是为什么我们将数据分为训练数据、验证数据和测试数据。验证数据和测试数据通常是可互换的，然而，它们在下面被描述为具有不同的目的。</p><h2 id="825f" class="ml lo it bd lp mm mn dn lt mo mp dp lx km mq mr mb kq ms mt mf ku mu mv mj mw bi translated">培训用数据</h2><p id="05d0" class="pw-post-body-paragraph kb kc it kd b ke mx kg kh ki my kk kl km mz ko kp kq na ks kt ku nb kw kx ky im bi translated">这是用于训练模型以拟合模型参数的数据。它将占最大比例的数据，因为你希望模型看到尽可能多的例子。</p><h2 id="2d94" class="ml lo it bd lp mm mn dn lt mo mp dp lx km mq mr mb kq ms mt mf ku mu mv mj mw bi translated">验证数据</h2><p id="9fa1" class="pw-post-body-paragraph kb kc it kd b ke mx kg kh ki my kk kl km mz ko kp kq na ks kt ku nb kw kx ky im bi translated">这是用于拟合超参数和特征选择的数据。虽然模型在训练过程中从未看到这些数据，但通过基于这些数据选择特定的特征或超参数，您会引入偏差并再次面临过度拟合的风险。</p><h2 id="2bef" class="ml lo it bd lp mm mn dn lt mo mp dp lx km mq mr mb kq ms mt mf ku mu mv mj mw bi translated">测试数据</h2><p id="74eb" class="pw-post-body-paragraph kb kc it kd b ke mx kg kh ki my kk kl km mz ko kp kq na ks kt ku nb kw kx ky im bi translated">这是用于评估和比较您的优化模型的数据。由于在训练或调整过程中没有看到这些数据，因此它可以让您深入了解您的模型是否能很好地推广到看不见的数据。</p><h2 id="4553" class="ml lo it bd lp mm mn dn lt mo mp dp lx km mq mr mb kq ms mt mf ku mu mv mj mw bi translated">交叉验证</h2><p id="fbdd" class="pw-post-body-paragraph kb kc it kd b ke mx kg kh ki my kk kl km mz ko kp kq na ks kt ku nb kw kx ky im bi translated">交叉验证的目的是评估特定算法是否适合您的数据和用例。它还用于超参数调整和功能选择。</p><p id="1c14" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">数据被分成训练集和验证集(尽管您也应该将一些测试数据放在一边)，并用每个数据片段构建一个模型。算法的最终评估是每个模型的平均性能。</p><p id="ebce" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated"><strong class="kd iu">保持方法</strong></p><p id="88fb" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">交叉验证的最简单版本是保留法，在这种方法中，我们将数据随机分成两组，一组是训练集，另一组是验证集。这是最快的方法，因为它只需要构建一次模型。但是，如果只有一个验证数据集，就有可能包含特别容易或特别难预测的观察值。因此，我们可能会发现我们过度适应这个验证数据，并且在测试集上表现不佳。</p><p id="cf66" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated"><strong class="kd iu"> K 倍交叉验证</strong></p><p id="778c" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">k 倍交叉验证方法包括将数据分成 k 个子集。然后对模型进行 k 次训练，每次都使用 k 个子集之一作为验证数据。训练数据将是不在验证集中的所有其他观察值。你的最终评估是所有 k 倍的平均值。</p><p id="13c7" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated"><strong class="kd iu">留一交叉验证</strong></p><p id="5627" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">这是 K-fold 交叉验证的最极端版本，其中 K 是 N(数据集中的观察次数)。您可以使用除一次观察之外的所有数据对模型进行 N 次单独的定型，然后使用该观察的预测来验证其准确性。尽管您正在全面评估这种算法在数据集上的表现，但这种方法非常昂贵，因为它需要您构建 N 个模型。</p><p id="7fa7" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated"><strong class="kd iu">分层交叉验证</strong></p><p id="4647" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">分层交叉验证强制要求 k-fold 集合在分类特征或标签中对每个类别具有相似的观察比例。</p><h1 id="c81e" class="ln lo it bd lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk bi translated">算法探索</h1><p id="f4fa" class="pw-post-body-paragraph kb kc it kd b ke mx kg kh ki my kk kl km mz ko kp kq na ks kt ku nb kw kx ky im bi translated">你探索的算法应该由你的用例驱动。通过首先确定你想要达到的目标，你可以缩小寻找解决方案的范围。尽管不是可能方法的完整列表，下面是介绍回归、分类、聚类、建议和异常检测算法的链接。我和一位同事还创建了这个工具来帮助指导算法选择(<a class="ae nh" href="https://samrose3.github.io/algorithm-explorer/" rel="noopener ugc nofollow" target="_blank">单击此处访问算法浏览器</a>)。</p><h2 id="47e9" class="ml lo it bd lp mm mn dn lt mo mp dp lx km mq mr mb kq ms mt mf ku mu mv mj mw bi translated">回归</h2><p id="204f" class="pw-post-body-paragraph kb kc it kd b ke mx kg kh ki my kk kl km mz ko kp kq na ks kt ku nb kw kx ky im bi translated">回归算法是预测连续数值的机器学习技术。它们是监督学习任务，这意味着它们需要带标签的训练样本。</p><p id="6e7b" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">延伸阅读:<a class="ae nh" href="https://medium.com/@srnghn/machine-learning-trying-to-predict-a-numerical-value-8aafb9ad4d36" rel="noopener">机器学习:试图预测一个数值</a></p><h2 id="f569" class="ml lo it bd lp mm mn dn lt mo mp dp lx km mq mr mb kq ms mt mf ku mu mv mj mw bi translated">分类</h2><p id="924e" class="pw-post-body-paragraph kb kc it kd b ke mx kg kh ki my kk kl km mz ko kp kq na ks kt ku nb kw kx ky im bi translated">分类算法是机器学习技术，用于预测输入数据属于哪个类别。它们是监督学习任务，这意味着它们需要带标签的训练样本。</p><p id="5e33" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">延伸阅读:<a class="ae nh" href="https://medium.com/@srnghn/machine-learning-trying-to-predict-a-categorical-outcome-6ba542b854f5" rel="noopener">机器学习:试图对你的数据进行分类预测</a></p><h2 id="4c50" class="ml lo it bd lp mm mn dn lt mo mp dp lx km mq mr mb kq ms mt mf ku mu mv mj mw bi translated">使聚集</h2><p id="10a7" class="pw-post-body-paragraph kb kc it kd b ke mx kg kh ki my kk kl km mz ko kp kq na ks kt ku nb kw kx ky im bi translated">聚类算法是一种机器学习技术，用于将数据分成许多组，其中组中的点具有相似的特征。它们是无监督的学习任务，因此不需要带标签的训练样本。</p><p id="7b1c" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">延伸阅读:<a class="ae nh" href="https://medium.com/@srnghn/machine-learning-trying-to-discover-structure-in-your-data-2fbbc4f819ae" rel="noopener">机器学习:试图在你的数据中发现结构</a></p><h2 id="ba7b" class="ml lo it bd lp mm mn dn lt mo mp dp lx km mq mr mb kq ms mt mf ku mu mv mj mw bi translated">推荐引擎</h2><p id="9e51" class="pw-post-body-paragraph kb kc it kd b ke mx kg kh ki my kk kl km mz ko kp kq na ks kt ku nb kw kx ky im bi translated">推荐引擎被创建来预测指示用户对项目/产品的兴趣的偏好或评级。用于创建该系统的算法在用户、物品或两者之间找到相似之处。</p><p id="dcfa" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">延伸阅读:<a class="ae nh" href="https://medium.com/@srnghn/machine-learning-trying-to-make-recommendations-ea2912cf468" rel="noopener">机器学习:尝试做推荐</a></p><h2 id="0321" class="ml lo it bd lp mm mn dn lt mo mp dp lx km mq mr mb kq ms mt mf ku mu mv mj mw bi translated">异常检测</h2><p id="8b5b" class="pw-post-body-paragraph kb kc it kd b ke mx kg kh ki my kk kl km mz ko kp kq na ks kt ku nb kw kx ky im bi translated">异常检测是一种用于识别不符合预期行为的异常事件或模式的技术。那些被识别的通常被称为异常或异常值。</p><p id="1bb7" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">延伸阅读:<a class="ae nh" href="https://medium.com/@srnghn/machine-learning-trying-to-detect-outliers-or-unusual-behavior-2d9f364334f9" rel="noopener">机器学习:试图检测异常值或异常行为</a></p><h1 id="0747" class="ln lo it bd lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk bi translated">超参数优化</h1><p id="e93b" class="pw-post-body-paragraph kb kc it kd b ke mx kg kh ki my kk kl km mz ko kp kq na ks kt ku nb kw kx ky im bi translated">尽管术语参数和超参数偶尔会互换使用，但我们还是要区分这两者。</p><p id="caf6" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated"><strong class="kd iu">参数</strong>是算法在训练期间学习的属性。</p><p id="6e86" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated"><em class="ni">对于线性回归，这些是权重和偏差；而对于随机森林，这些是每个节点的变量和阈值。</em></p><p id="35c7" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated"><strong class="kd iu">另一方面，超参数</strong>是必须在训练前设置的属性。</p><p id="bc37" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated"><em class="ni">对于 k-means 聚类，必须定义 k 的值；而对于神经网络，一个例子是学习速率。</em></p><p id="467b" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated"><strong class="kd iu">超参数优化</strong>是为这些超参数找到最佳可能值的过程，以优化您的性能指标(例如，最高精度、最低 RMSE 等)。).为此，我们为不同的值组合训练一个模型，并评估哪个找到最佳解决方案。用于搜索最佳组合的三种方法是网格搜索、随机搜索和贝叶斯优化。</p><h2 id="f6af" class="ml lo it bd lp mm mn dn lt mo mp dp lx km mq mr mb kq ms mt mf ku mu mv mj mw bi translated">网格搜索</h2><p id="89fd" class="pw-post-body-paragraph kb kc it kd b ke mx kg kh ki my kk kl km mz ko kp kq na ks kt ku nb kw kx ky im bi translated">您为每个超参数指定值，这些值的所有组合将被评估。</p><p id="2e7f" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated"><em class="ni">例如，如果您希望评估随机森林的超参数，您可以指定为树的数量超参数提供三个选项(10、20 和 50)，并为每棵树的最大深度提供三个选项(无限制，10 和 20)。这将导致为 9 种可能组合中的每一种构建随机森林模型:(10，无限制)，(10，10)，(10，20)，(20，无限制)，(20，10)，(20，20)，(50，无限制)，(50，10)和(50，20)。提供最佳性能的组合将是您用于最终模型的组合。</em></p><p id="cc97" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated"><strong class="kd iu">优点</strong>:使用简单。你会找到你所提供的价值的最佳组合。您可以并行运行每个实验。</p><p id="e3e6" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">缺点:计算成本很高，因为有太多的模型正在建造中。如果一个特定的超参数不重要，你就不必要地探索不同的可能性。</p><h2 id="e7fa" class="ml lo it bd lp mm mn dn lt mo mp dp lx km mq mr mb kq ms mt mf ku mu mv mj mw bi translated">随机搜索</h2><p id="018c" class="pw-post-body-paragraph kb kc it kd b ke mx kg kh ki my kk kl km mz ko kp kq na ks kt ku nb kw kx ky im bi translated">为每个超参数指定范围或选项，并选择每个超参数的随机值。</p><p id="c74a" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated"><em class="ni">继续以随机森林为例，您可以提供介于 10 和 50 之间的树的数量范围，max_depth 可以是无限制，10 或 20。这一次，不是它计算所有排列，而是您可以指定您希望运行的迭代次数。假设我们只想要五个，那么我们可能会测试类似于(19，20)，(32 无限制)，(40，无限制)，(10，20)，(27，10)的东西。</em></p><p id="6137" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated"><strong class="kd iu">优点</strong>:使用简单。效率更高，当只有几个超参数影响整体性能时，性能优于网格搜索。您可以并行运行每个实验。</p><p id="122b" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated"><strong class="kd iu">缺点</strong>:它涉及随机抽样，所以只有在搜索空间时才会找到最佳组合。</p><h2 id="b459" class="ml lo it bd lp mm mn dn lt mo mp dp lx km mq mr mb kq ms mt mf ku mu mv mj mw bi translated">由粗到细</h2><p id="0ff9" class="pw-post-body-paragraph kb kc it kd b ke mx kg kh ki my kk kl km mz ko kp kq na ks kt ku nb kw kx ky im bi translated">对于网格搜索和随机搜索，您也可以使用由粗到细的技术。这包括探索更大范围的变量和更宽的区间或所有可能的选项。一旦你从最初的搜索中得到了结果，你就可以探索这些结果，看看是否有任何模式或特定区域看起来有希望。如果是这样，你可以重复这个过程，但要改进你的搜索。</p><p id="a3e0" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated"><em class="ni">对于上面的随机森林示例，我们可能会注意到，当最大深度没有限制并且树的数量超参数为 10 或 20 时，结果是有希望的。重复搜索过程，但保持最大深度超参数不变，并增加树选项数量的粒度，测试值 12、14、16、18，看看我们是否能找到更好的结果。</em></p><p id="d225" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated"><strong class="kd iu"> Pro </strong>:可以找到更优化的超参数，提高性能指标。</p><p id="0a9b" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated"><strong class="kd iu">缺点</strong>:评估结果以找到最佳探索区域可能很麻烦。</p><h2 id="9a58" class="ml lo it bd lp mm mn dn lt mo mp dp lx km mq mr mb kq ms mt mf ku mu mv mj mw bi translated">贝叶斯优化</h2><p id="30de" class="pw-post-body-paragraph kb kc it kd b ke mx kg kh ki my kk kl km mz ko kp kq na ks kt ku nb kw kx ky im bi translated">贝叶斯优化使用超参数组合成功的先验知识来选择下一个最佳方案。</p><p id="d473" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">该技术使用机器学习方法，建立一个模型，其中超参数是特征，性能是目标变量。每次实验后，都会添加一个新的数据点，并建立一个新的模型。</p><p id="7599" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">它假设相似的组合将有相似的结果，并优先探索已经看到有希望的结果的区域。然而，它也考虑到不确定性作为大收益的可能性；如果有尚未勘探的大面积区域，它也会优先考虑这些区域。</p><p id="7a45" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">仅取一个超参数，即树的数量，该算法可能首先尝试 10，并获得相当好的性能。然后，它尝试 32 次，性能明显提高。贝叶斯优化基于前两个数据点建立模型来预测性能。该模型可能仅具有两个数据点的线性，因此选择的下一个值是 40，预期性能将随着树数量的增加而继续提高。事实并非如此。现在，它建立了另一个模型，表明在 32 附近可能会有改进，这是迄今为止它看到的最好结果，但是，在 10 和 32 之间仍然有很大的差距没有被探索，由于很大的不确定性，它选择 21。再次用这个新数据和选择的另一个值调整模型… </p><p id="9595" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated"><strong class="kd iu">优点</strong>:可以找到更优化的超参数，提高性能指标。当参数数量很大并且每个实验的计算量很大时，它可以减少搜索最优解所花费的时间。</p><p id="3e3e" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated"><strong class="kd iu">缺点</strong>:您不能并行运行每个实验，因为超参数值的下一个组合由之前的运行决定。它还需要调整—为每个超参数选择一个比例和一个合适的内核。</p><h1 id="b63b" class="ln lo it bd lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk bi translated">集成学习</h1><p id="8016" class="pw-post-body-paragraph kb kc it kd b ke mx kg kh ki my kk kl km mz ko kp kq na ks kt ku nb kw kx ky im bi translated">集成结合了几个机器学习模型，每个模型在数据中找到不同的模式，以提供更准确的解决方案。这些技术既可以提高性能，因为它们捕捉更多的趋势，也可以减少过度拟合，因为最终预测是许多模型的共识。</p><h2 id="b990" class="ml lo it bd lp mm mn dn lt mo mp dp lx km mq mr mb kq ms mt mf ku mu mv mj mw bi translated">制袋材料</h2><p id="1907" class="pw-post-body-paragraph kb kc it kd b ke mx kg kh ki my kk kl km mz ko kp kq na ks kt ku nb kw kx ky im bi translated">Bagging (bootstrap aggregations)是一种并行构建多个模型并对其预测进行平均作为最终预测的方法。这些模型可以使用相同的算法构建(即随机森林算法构建许多决策树)，或者您可以构建不同类型的模型(如线性回归模型和 SVM 模型)。</p><h2 id="6415" class="ml lo it bd lp mm mn dn lt mo mp dp lx km mq mr mb kq ms mt mf ku mu mv mj mw bi translated">助推</h2><p id="c5c4" class="pw-post-body-paragraph kb kc it kd b ke mx kg kh ki my kk kl km mz ko kp kq na ks kt ku nb kw kx ky im bi translated">Boosting 构建模型，依次评估早期模型的成功性；下一个模型优先考虑学习趋势，以预测当前模型表现不佳的例子。有三种常见的技术:AdaBoost、梯度增强和 XGBoosted。</p><h2 id="66db" class="ml lo it bd lp mm mn dn lt mo mp dp lx km mq mr mb kq ms mt mf ku mu mv mj mw bi translated">堆垛</h2><p id="2811" class="pw-post-body-paragraph kb kc it kd b ke mx kg kh ki my kk kl km mz ko kp kq na ks kt ku nb kw kx ky im bi translated">堆叠包括构建多个模型，并将其输出作为最终模型的特征。例如，您的目标是创建一个分类器，您构建了一个 KNN 模型和一个朴素贝叶斯模型。您可以将他们的两个预测传递到最终的逻辑回归模型中，而不是在两者之间进行选择。这个最终模型可能比两个中间模型产生更好的结果。</p></div></div>    
</body>
</html>