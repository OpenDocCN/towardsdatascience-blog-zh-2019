# 数据科学最难的部分？数据。

> 原文：<https://towardsdatascience.com/the-hardest-part-of-data-science-data-1877a5cd30d7?source=collection_archive---------25----------------------->

![](img/f7233e403b8e7065bc372eb2b503a7aa.png)

Photo by [Tim Gouw](https://unsplash.com/@punttim?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText) on [Unsplash](https://unsplash.com/?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)

## 数据科学不是，也从来不是关于模型的。

在过去的十年中，数据科学突破了所有的噪音，成为现代技术的支柱之一。现在，基于历史数据进行预测的能力推动了几乎所有新产品、商业计划和处于行业前沿的组织。

这些功能是随着预测模型(能够“拟合”(学习)历史数据的算法)的采用而引入的。因此，毫不奇怪，在选择和训练模型的过程的自动化、精简化和民主化方面已经投入了大量的工作。

从商业机器学习工具到开源库(像 Sklearn、Auto-Sklearn、TPOT 等。)，前几年投入的工作使我们能够清楚地表明:

**模特开始商品化**。

每个知道如何编写 Python 脚本的新手现在都可以训练一个模型。现在，每个拥有合适 Excel 插件的业务分析师都可以根据他们的财务数据训练一个回归模型。我，我自己，在学习 Python 的两个月内就能训练出一个成功的模型。

训练模型，尤其是复杂的模型(例如梯度增强树)，在十年前可能是一个挑战，但自那以后发生了很多事情:

*   **成熟、高效且易于使用的开源建模库获得了巨大的吸引力(如 Sklearn、XGBoost、CatBoost 等)。)**
*   可用的计算能力显著提高
*   像 Python 这样易于编写的语言开始占据主导地位
*   大数据和云基础设施取得了进步
*   围绕数据科学和机器学习的开放和可访问的知识和学习材料变得可用

**训练一个复杂的模型现在只需要几行代码和很短的计算时间。**

*在我们继续之前，快速声明:在本文中，我将重点关注涉及表格和/或半结构化数据的经典数据科学问题。我的观点不适用于计算机视觉/音频用例。*

# 数据科学的核心挑战

**这与算法无关，而是要给它们提供正确的数据。**

今天，当将数据科学应用于商业问题时，几乎没有人发明新的算法(同样，不一定适用于计算机视觉/音频和 NLP 用例)。十多年来，我们一直在使用相同的模型。梯度推进树(XGBoost)在上个世纪被引入，支持向量机在 20 世纪 60 年代被引入，线性回归……可能在公元前 1000 年左右。

数据科学与任何其他从新技术中产生并影响社会的职业没有什么不同。它继续发展，为复杂的问题和挑战打开了无尽的大门，一个比一个更令人兴奋。然而我们继续使用同样的模型。Kaggle 竞赛的获胜者通过使用 30 岁的模特来登上排行榜的榜首来证明这一点。如果 30 岁的模特正在赢得比赛，按理说这些模特不是“X 因素”的来源。

事实是，数据科学一直专注于试图从最新的算法中产生商业价值，以至于我们错过了最重要的部分:**数据科学不是，也从来不是关于模型的。**

假设大部分建模都是商品化和自动化的，那么构建一个强大而准确的预测系统的下一个挑战是什么？究竟是什么让一个模型成功？

# 将“数据”纳入数据科学

我们都听说过“垃圾进，垃圾出”这句话如果我试图训练一个模型，根据一个人名字中的字符数来预测信用违约，我可能会成功地让模型工作(训练和预测)，但模型基本上是随机猜测的。

为了决定一个数据科学项目是否会成功，我们需要问的主要问题是并且永远是:**我们是否有正确的数据来训练一个模型来解决我们试图解决的问题？**

“正确的数据”可以分解为多个子问题:

1.  我们是否有正确的数据属性，以便我们的模型可以推断出现实的模式和规则？
2.  我们有足够的样本来训练模型吗？
3.  在将数据输入算法之前，我们是否以正确的方式设计(整合、聚集、转换)了数据？

说到工程……斯坦福大学教授吴恩达准确地说:

> “…应用机器学习基本上是特征工程。”

吴教授所说的“特征工程”是什么意思

由于该领域的争论，围绕不同术语的含义出现了一些混乱。我建议我们将特征工程分解成两个部分:

*   **特征生成**:初始阶段，我们搜索数据以生成特征。我们汇总、应用业务逻辑，并将多个来源纳入每个样本的一个数字属性矩阵。
*   **特征标准化**:归一化、缩放、插补和编码。我们对特征集进行转换，使其对模型更具“吸引力”。这些通常与模型相关。例如，虽然决策树可以很好地处理原始的、未缩放的数字特征，但线性模型通常需要正确的插补和缩放(例如，单位方差和零均值)。

我认为功能标准化正在走一条与模型相似的道路。与模型商品化的方式相同，功能标准化也可以商品化。就像 autoML 技术一样，您可以使用不同的标准化技术遍历不同的模型，直到您找到性能最佳的组合。与要生成的可能特征的搜索空间不同，标准化技术和不同模型的不同组合没有我们想象的那么大。

为了说明我的观点，下面是我用特征标准化技术自动选择模型的伪算法:

*给出一系列可能的特征标准化方法，如缩放和插补方法(均值插补、单位方差缩放、PCA 等)*

*并给出了可能的模型列表(线性回归、SVM、有 100 棵决策树的 XGBoost、有 1000 棵决策树的 XGBoost……)*

*用随机预处理器和随机模型生成实验。*

经过几次迭代后，选择最佳实验。

很明显，这并不像我提出的那么简单。参数空间大，组合数量应该有限——但这不是火箭科学。有很多工具在这方面做得很好(比如 Auto-Sklearn 或 TPOT)。随着计算能力变得越来越便宜和可用，这只会变得更容易。

**然而，特征生成并不在同一个地方。**

# 特征生成的艺术

今天，主流数据科学更多地采用艺术方法而不是科学方法来生成特征。它相信人类数据科学家会为功能想到正确的想法，找到正确的数据源，了解如何将它们集成在一起，了解聚合和转换数据的正确方法，并在最终的功能之间生成交互。

因此，我将有点粗鲁地把吴教授的说法改为:

> “…应用机器学习基本上是特征生成。”

生成特征时没有通用准则可循的原因很明显:潜在相关数据源(组织内部和外部)的数量太大。你可以想出无限多的方法来生成特征。

如今，所有试图“[自动化数据科学](https://www.explorium.ai/blog/why-automating-data-science-will-kill-the-bi-industry/)”的工具都将生成高价值特征和信号以馈入模型(和标准化技术)的任务留给了我们人类。鉴于我们不像机器那样擅长探索搜索空间，我们错过了很多东西。

有无数的数据可能与我们试图解决的每一个用例以及我们试图建立的模型都相关，但最大限度地发掘其潜力是不可行的。

当一家银行只根据一个人的历史交易记录建立信用违约模型时，他们做得好吗？如果那个人刚读完一个大概率找到高薪工作的学位怎么办？

当零售商根据历史销售和促销活动计划促销日历时，他们做得好吗？如果假期过后人们不介意支付更高的价格呢？

冒着在本文中使用太多术语的风险，重要的是要记住数据实际上是新的石油。然而，当我们审视数据科学工具和技术的当前状态时，我们经常会发现算法工具是从数据工具中分离出来的。我们在与模型相关的任务方面取得了很多进步，但仍有数量呈指数增长的数据在很大程度上被忽略。

# 自动化特征生成和数据发现

我相信，解决模型构建过程中的数据部分将为我们周围的企业和产品带来无尽的价值。如今，这是所有类型组织的主要瓶颈。

如果一家具有前瞻性思维的大型公司试图将数据科学扩展到不同的功能和用例，它很快就会发现，没有足够多的数据科学家能够通过不同的功能和数据源进行编码。如果一家公司希望获得相关的数据源来改进现有的模型，它可能会为测试一个新的数据源(假设、匹配和集成、聚合和生成特征)而不得不做的大量人工工作而感到头疼，这只是为了确定它是否确实改进了一个预测模型。如果一家公司没有无限量的数据，他们将需要越来越努力地寻找更好的数据，并产生高价值的功能。

所有这些障碍都可以通过在构建模型的上下文中自动执行探索数据源和生成要素的过程来解决。

现在，随着越来越多的自动化进入数据科学，我们都在问这个问题:这将取代数据科学家吗？号码

将业务问题转化为“数据问题”总是需要数据科学家，以了解什么是正确的预测，定义问题的搜索空间，防止数据泄漏，并测试结果以确保它们有意义并可用于生产以影响业务。

是时候开始关注数据科学的数据部分了。我们的模型需要它。