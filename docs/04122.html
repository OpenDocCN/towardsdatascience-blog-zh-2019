<html>
<head>
<title>How to Participate in a Kaggle Competition with Zero Code</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">零代码如何参加 Kaggle 比赛</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/how-to-participate-in-a-kaggle-competition-with-zero-code-f017918d2f08?source=collection_archive---------13-----------------------#2019-06-28">https://towardsdatascience.com/how-to-participate-in-a-kaggle-competition-with-zero-code-f017918d2f08?source=collection_archive---------13-----------------------#2019-06-28</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><p id="7b63" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">如果没有以前的经验和对至少一个标准深度学习框架(如 TensorFlow 或 PyTorch)的深入了解，Kaggle 竞赛的入门可能会非常复杂。在本教程中，我们将探索零代码参与 Kaggle 竞赛的机会。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi ko"><img src="../Images/f26741b87becf64ec981b3aeb892bbf4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*vALdz4yKCoun2AK6sFhZFg.jpeg"/></div></div></figure><h1 id="958b" class="la lb it bd lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx bi translated">Freesound 音频标记 2019</h1><p id="d43a" class="pw-post-body-paragraph jq jr it js b jt ly jv jw jx lz jz ka kb ma kd ke kf mb kh ki kj mc kl km kn im bi translated">我们将参加<a class="ae md" href="https://www.kaggle.com/c/freesound-audio-tagging-2019" rel="noopener ugc nofollow" target="_blank"> Freesound 音频标记 2019 </a> Kaggle 比赛。本次比赛是<strong class="js iu"> DCASE2019 挑战赛</strong> 中的<a class="ae md" href="http://dcase.community/challenge2019/task-audio-tagging" rel="noopener ugc nofollow" target="_blank"> <strong class="js iu">任务 2 </strong>。如果你想使用与比赛相关的数据集，我们鼓励你在 Kaggle 上注册，通读比赛规则并接受它们。</a></p><p id="e300" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">Freesound Audio Tagging 2019 是前几年由<a class="ae md" href="https://freesound.org/" rel="noopener ugc nofollow" target="_blank">free sound</a>(<a class="ae md" href="https://www.upf.edu/web/mtg" rel="noopener ugc nofollow" target="_blank">MTG-庞贝大学</a>)和<a class="ae md" href="https://research.google.com/audioset////////about.html" rel="noopener ugc nofollow" target="_blank">谷歌的机器感知</a>举办的音频标签比赛的更新。2019 版本是多标签音频标签，音频类别数量是原来的两倍。<strong class="js iu"> FSDKaggle2019 </strong>数据集中的注释是通过<a class="ae md" href="https://annotator.freesound.org/" rel="noopener ugc nofollow" target="_blank"> Freesound 注释器</a>收集的。</p><p id="9139" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">竞赛基于<a class="ae md" href="http://www.eduardofonseca.net/" rel="noopener ugc nofollow" target="_blank"> Eduardo Fonseca </a>等人的论文:</p><ul class=""><li id="8058" class="me mf it js b jt ju jx jy kb mg kf mh kj mi kn mj mk ml mm bi translated"><a class="ae md" href="https://arxiv.org/abs/1906.02975" rel="noopener ugc nofollow" target="_blank">带有嘈杂标签和最少监督的音频标签</a></li><li id="132e" class="me mf it js b jt mn jx mo kb mp kf mq kj mr kn mj mk ml mm bi translated"><a class="ae md" href="https://ismir2017.smcnus.org/wp-content/uploads/2017/10/161_Paper.pdf" rel="noopener ugc nofollow" target="_blank"> Freesound Datasets:一个创建开放音频数据集的平台</a></li></ul><h1 id="4042" class="la lb it bd lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx bi translated">注册 Peltarion 平台</h1><p id="0a59" class="pw-post-body-paragraph jq jr it js b jt ly jv jw jx lz jz ka kb ma kd ke kf mb kh ki kj mc kl km kn im bi translated">Peltarion 平台是一个用于深度学习的可视化开发环境。该平台从构建到培训再到部署你的深度学习模型，一行代码都不需要。</p><ol class=""><li id="2841" class="me mf it js b jt ju jx jy kb mg kf mh kj mi kn ms mk ml mm bi translated"><a class="ae md" href="https://peltarion.com/signup" rel="noopener ugc nofollow" target="_blank">到平台报名</a>。</li><li id="588e" class="me mf it js b jt mn jx mo kb mp kf mq kj mr kn ms mk ml mm bi translated">确认你的电子邮件。</li><li id="928a" class="me mf it js b jt mn jx mo kb mp kf mq kj mr kn ms mk ml mm bi translated">等待激活邮件。可能需要几分钟。</li><li id="fcb4" class="me mf it js b jt mn jx mo kb mp kf mq kj mr kn ms mk ml mm bi translated">设置您的密码。</li><li id="3c60" class="me mf it js b jt mn jx mo kb mp kf mq kj mr kn ms mk ml mm bi translated">该平台已准备就绪，可免费使用 50 个 GPU 小时。</li></ol><figure class="kp kq kr ks gt kt"><div class="bz fp l di"><div class="mt mu l"/></div><figcaption class="mv mw gj gh gi mx my bd b be z dk">Peltarion Platform</figcaption></figure><h1 id="7cf4" class="la lb it bd lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx bi translated">下载 FSDKaggle2019 数据集</h1><p id="130c" class="pw-post-body-paragraph jq jr it js b jt ly jv jw jx lz jz ka kb ma kd ke kf mb kh ki kj mc kl km kn im bi translated">下载<a class="ae md" href="https://www.kaggle.com/carlthome/preprocess-freesound-data-to-train-with-peltarion/output" rel="noopener ugc nofollow" target="_blank"> <strong class="js iu"> FSDKaggle2019 </strong>数据集</a>。</p><p id="4cc8" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu"> FSDKaggle2019 </strong>数据集已经针对 Peltarion 平台进行了预处理。这意味着音频文件已被转换为<a class="ae md" href="https://en.wikipedia.org/wiki/Spectrogram" rel="noopener ugc nofollow" target="_blank">频谱图</a>并与包含每个文件对应类别的<strong class="js iu"> index.csv </strong>文件一起保存为 NumPy 文件。</p><p id="79d9" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">可下载数据集已经过预处理，可以上传到平台。点击<strong class="js iu"> dataset.zip </strong>下载。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi mz"><img src="../Images/8ef9ea5aa558940bb0c6716f343af2c6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*dH043qSNJhtPW5SJF_1aLg.png"/></div></div><figcaption class="mv mw gj gh gi mx my bd b be z dk">Click on the dataset.zip</figcaption></figure><h1 id="e193" class="la lb it bd lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx bi translated">创建新项目</h1><p id="f9fa" class="pw-post-body-paragraph jq jr it js b jt ly jv jw jx lz jz ka kb ma kd ke kf mb kh ki kj mc kl km kn im bi translated">在左侧的 Peltarion 主视图中，点击<strong class="js iu">新建项目</strong>按钮。现在，您可以在弹出模式中添加项目名称和可选描述。我们将该项目称为项目 v1 。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi na"><img src="../Images/539a5626170b84d4b11a23ba88cd4c8e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*bNWdg_WZ5K0-coU1wZbk3Q.png"/></div></div><figcaption class="mv mw gj gh gi mx my bd b be z dk">Home view.</figcaption></figure><p id="9df6" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu">项目 v1 </strong>出现在<strong class="js iu">新建项目</strong>按钮下方的左侧。点击展开项目，然后点击<strong class="js iu">打开</strong>。</p><h1 id="2a65" class="la lb it bd lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx bi translated">上传数据集</h1><p id="fce2" class="pw-post-body-paragraph jq jr it js b jt ly jv jw jx lz jz ka kb ma kd ke kf mb kh ki kj mc kl km kn im bi translated">点击<strong class="js iu">转到项目</strong>后，您将进入项目的<strong class="js iu">数据集</strong>视图。在<strong class="js iu">数据集</strong>视图上，点击<strong class="js iu">新建数据集</strong>。在<strong class="js iu">上传文件</strong>选项卡上，点击<strong class="js iu">选择文件</strong>上传<strong class="js iu"> dataset.zip </strong>，等待其上传，点击<strong class="js iu">下一步</strong>。命名数据集。我们准备把它命名为<strong class="js iu">音频</strong>。默认情况下，数据集分为 80%的数据用于定型，剩下的 20%用于验证。我们将使用这种拆分。</p><p id="0fd5" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">我们需要通过点击顶部的<strong class="js iu">新特性集</strong>来捆绑类别特性。选择除<strong class="js iu"> fname </strong>之外的所有特征(共 80 个)，并将 F <strong class="js iu">特征集名称</strong>设置为<strong class="js iu">标签</strong>，然后点击<strong class="js iu">创建</strong>。</p><p id="5795" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">在右上角，点击<strong class="js iu">保存版本</strong>，你就可以进入<strong class="js iu">建模</strong>阶段了。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi nb"><img src="../Images/d7b817f9e888505910577352a8238cd2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*BVp6MJm41rHMiM8Vn-diDA.png"/></div></div><figcaption class="mv mw gj gh gi mx my bd b be z dk">Datasets view.</figcaption></figure><h1 id="9e76" class="la lb it bd lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx bi translated">创建一个深度学习实验</h1><p id="7cbe" class="pw-post-body-paragraph jq jr it js b jt ly jv jw jx lz jz ka kb ma kd ke kf mb kh ki kj mc kl km kn im bi translated">从顶部的选项卡转到<strong class="js iu">建模</strong>视图。点击左边的<strong class="js iu">新实验</strong>。我们将把我们的实验命名为<strong class="js iu">实验 v1 </strong>。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi nc"><img src="../Images/ced4d5cfb5f81e8a81a2f5b514092519.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*3t0uWzAVgWRSDZBbQhOEbQ.png"/></div></div></figure><h1 id="00db" class="la lb it bd lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx bi translated">建模</h1><p id="04ae" class="pw-post-body-paragraph jq jr it js b jt ly jv jw jx lz jz ka kb ma kd ke kf mb kh ki kj mc kl km kn im bi translated">在<strong class="js iu">建模</strong>视图的右侧，可以看到<strong class="js iu">构建</strong>和<strong class="js iu">设置</strong>选项卡。这些是我们将在构建深度学习模型时使用的工具。在本教程中，我们将把音频文件视为称为光谱图的图片，并执行图像分类。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi nd"><img src="../Images/90bea6e7a1e4219f3704492bf70c2f21.png" data-original-src="https://miro.medium.com/v2/resize:fit:798/format:webp/1*hxJPKrVqvV23QmZ-WbxP9Q.png"/></div><figcaption class="mv mw gj gh gi mx my bd b be z dk">Audio as a picture.</figcaption></figure><p id="b6fe" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">由于我们正在对被视为图片的声音数据进行分类，因此我们可以使用性能良好的卷积神经网络。在这种情况下，我们将使用<strong class="js iu"> ResNetv2 large 50 </strong>。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi ne"><img src="../Images/4e74b532aabed2dede7e0dd73d08c9b6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*iaa6B6a8SXE-XXu59C4HKg.png"/></div></div><figcaption class="mv mw gj gh gi mx my bd b be z dk">Ready model in modeling view.</figcaption></figure><p id="01fb" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">我们现在将在<strong class="js iu">建模</strong>视图中创建模型:</p><ol class=""><li id="bd2c" class="me mf it js b jt ju jx jy kb mg kf mh kj mi kn ms mk ml mm bi translated">从<strong class="js iu">块</strong>中添加<strong class="js iu">输入</strong>块，并将<strong class="js iu"> fname </strong>指定为右上角的<strong class="js iu">特征</strong>。</li><li id="4e60" class="me mf it js b jt mn jx mo kb mp kf mq kj mr kn ms mk ml mm bi translated">添加<strong class="js iu">批量标准化</strong>块并保持可训练状态。批次正常化是为了加快训练速度。</li><li id="4419" class="me mf it js b jt mn jx mo kb mp kf mq kj mr kn ms mk ml mm bi translated">从<strong class="js iu">块</strong>添加<strong class="js iu">整形</strong>块，并将<strong class="js iu">目标形状</strong>设置为(256，256，1)。<strong class="js iu"> ResNetv2 large 50 </strong>需要一个额外的通道轴。</li><li id="91d5" class="me mf it js b jt mn jx mo kb mp kf mq kj mr kn ms mk ml mm bi translated">从<strong class="js iu">片段</strong>中添加<strong class="js iu"> ResNetv2 large 50 </strong>。</li><li id="5dd4" class="me mf it js b jt mn jx mo kb mp kf mq kj mr kn ms mk ml mm bi translated">点击<strong class="js iu"> ResNetv2 large 50 </strong>上方的<strong class="js iu">输入</strong>块，按 backspace 删除。</li><li id="365b" class="me mf it js b jt mn jx mo kb mp kf mq kj mr kn ms mk ml mm bi translated">将<strong class="js iu">批量正常化</strong>模块的点连接到<strong class="js iu"> ResNetv2 大 50 </strong>模块。</li><li id="c1f8" class="me mf it js b jt mn jx mo kb mp kf mq kj mr kn ms mk ml mm bi translated">将<strong class="js iu"> ResNetv2 大 50 </strong>后的<strong class="js iu">密集</strong>块中的<strong class="js iu">激活</strong>改为<strong class="js iu"> ReLU </strong>。<strong class="js iu"> ReLU </strong>在大多数情况下是优秀的激活功能。</li><li id="44b8" class="me mf it js b jt mn jx mo kb mp kf mq kj mr kn ms mk ml mm bi translated">在<strong class="js iu">目标</strong>块之前添加另一个<strong class="js iu">密集</strong>块，将其<strong class="js iu">节点</strong>设置为 80，<strong class="js iu">激活</strong>为<strong class="js iu">s 形</strong>。</li><li id="3d95" class="me mf it js b jt mn jx mo kb mp kf mq kj mr kn ms mk ml mm bi translated">将<strong class="js iu">目标</strong>块的<strong class="js iu">特征</strong>更改为<strong class="js iu">标签</strong>并将<strong class="js iu">损失</strong>更改为<strong class="js iu">二元交叉熵</strong>。</li><li id="433d" class="me mf it js b jt mn jx mo kb mp kf mq kj mr kn ms mk ml mm bi translated">转到右侧的<strong class="js iu">设置</strong>选项卡，将<strong class="js iu">批量</strong>设置为<strong class="js iu"> 28 </strong>，<strong class="js iu">周期</strong>到<strong class="js iu"> 30 </strong>和<strong class="js iu">优化</strong> r 到<strong class="js iu"> Adam </strong>。<strong class="js iu">批量</strong> 28 将适合 GPU 内存，30 个<strong class="js iu">历元</strong>应该足够模型收敛，<strong class="js iu"> Adam </strong>是一个很好的标准<strong class="js iu">优化器</strong>。</li><li id="f03b" class="me mf it js b jt mn jx mo kb mp kf mq kj mr kn ms mk ml mm bi translated">点击视图右上角的<strong class="js iu"> Run </strong>。</li></ol><h1 id="e314" class="la lb it bd lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx bi translated">评价</h1><p id="7dc6" class="pw-post-body-paragraph jq jr it js b jt ly jv jw jx lz jz ka kb ma kd ke kf mb kh ki kj mc kl km kn im bi translated">从顶部的选项卡进入<strong class="js iu">评估</strong>视图。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi nf"><img src="../Images/d780a6c503a5ffd2bfe37d8c901e5b5c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ormQXtFJj_wq0wEKRnWNqg.png"/></div></div></figure><p id="6be5" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">在<strong class="js iu">评估</strong>视图中，您可以跟踪您的模型的训练，并获得实验的实时训练指标。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi ng"><img src="../Images/395c35c779a6954c78aeaf71aaff5174.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*KXa6ECCk9RghDwZ7purjOg.png"/></div></div><figcaption class="mv mw gj gh gi mx my bd b be z dk">Evaluation view.</figcaption></figure><p id="ddb7" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">你应该感兴趣的指标是<strong class="js iu">精度</strong>和<strong class="js iu">召回</strong>。如果你想了解更多，有一篇很棒的<a class="ae md" rel="noopener" target="_blank" href="/precision-vs-recall-386cf9f89488">媒体文章</a>。</p><p id="3c49" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">我们的模型现在已经训练好了，可以下载了。您可以点击<strong class="js iu">实验 1 </strong>概述中左侧的三点下拉菜单下载模型。在下拉菜单中，点击下载，它打开一个模态，点击<strong class="js iu">确定</strong>。将模型下载为 H5 文件会有一点延迟。如果您训练了多个模型，请下载具有最佳验证精度的模型。</p><p id="64b1" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">模型现在可以发货了！</p><h1 id="dee0" class="la lb it bd lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx bi translated">Kaggle 帐户入门</h1><p id="4d38" class="pw-post-body-paragraph jq jr it js b jt ly jv jw jx lz jz ka kb ma kd ke kf mb kh ki kj mc kl km kn im bi translated">如果您还没有 Kaggle 帐户，您可以在这里创建一个<a class="ae md" href="https://www.kaggle.com/account/login" rel="noopener ugc nofollow" target="_blank">。请按照说明操作。</a></p><p id="fced" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">一旦您的帐户准备就绪，请加入<a class="ae md" href="https://www.kaggle.com/c/freesound-audio-tagging-2019" rel="noopener ugc nofollow" target="_blank">音频标记 2019 </a>。<strong class="js iu">迟交</strong>按钮在右上角。如果这是你第一次参加 Kaggle 比赛，你需要在参加比赛前用你的手机验证你的帐户。</p><h1 id="fbfa" class="la lb it bd lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx bi translated">提交预测</h1><p id="e0dc" class="pw-post-body-paragraph jq jr it js b jt ly jv jw jx lz jz ka kb ma kd ke kf mb kh ki kj mc kl km kn im bi translated">点击<strong class="js iu">新内核</strong>，选择<strong class="js iu">笔记本。</strong></p><p id="c974" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">您需要将下载的模型 H5 文件添加为数据集。为了找到 H5 文件的正确路径，将下面的代码添加到 Kaggle notebook 并运行它(记住保存路径以备将来使用)。</p><figure class="kp kq kr ks gt kt"><div class="bz fp l di"><div class="nh mu l"/></div></figure><p id="e042" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">有一些代码。你必须将下面的代码复制粘贴到 Kaggle 笔记本中。</p><figure class="kp kq kr ks gt kt"><div class="bz fp l di"><div class="nh mu l"/></div></figure><p id="b7e4" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">将模型变量路径更改为之前保存的路径，并点击右上角的<strong class="js iu">提交</strong>。</p><p id="92f7" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">点击<strong class="js iu">提交后，</strong>ka ggle 内核检查错误并开始用你的模型进行预测，并将<strong class="js iu"> submission.csv </strong>发送给竞赛。</p><h1 id="0c34" class="la lb it bd lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx bi translated">进一步工作—迁移学习</h1><p id="c7d2" class="pw-post-body-paragraph jq jr it js b jt ly jv jw jx lz jz ka kb ma kd ke kf mb kh ki kj mc kl km kn im bi translated">即使比赛不允许迁移学习，在平台上测试迁移学习的能力也是有用的。迁移学习利用从 ImageNet 或 CIFAR-100 等大规模数据集学习的图像属性，然后针对特定的图像识别问题微调神经网络。在我们的例子中，我们会用音频文件的图像对它进行微调。</p><p id="6055" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">该平台支持 VGG16、VGG19 和 ResNetv2，权重在 ImageNet 上训练。</p><p id="ba32" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">使用迁移学习时，您可以尝试使用较小的数据集获得更好的结果。迁移学习通常收敛得更快，即使预训练数据集与您正在使用的数据集非常不同。</p><h1 id="644e" class="la lb it bd lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx bi translated">特别感谢</h1><p id="c800" class="pw-post-body-paragraph jq jr it js b jt ly jv jw jx lz jz ka kb ma kd ke kf mb kh ki kj mc kl km kn im bi translated">特别感谢<strong class="js iu">free sound Audio Tagging 2019</strong>的组织者在整个过程中给予的帮助。</p><h1 id="a612" class="la lb it bd lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx bi translated">参考</h1><p id="7790" class="pw-post-body-paragraph jq jr it js b jt ly jv jw jx lz jz ka kb ma kd ke kf mb kh ki kj mc kl km kn im bi translated">Eduardo Fonseca、Manoj Plakal、Frederic Font、Daniel P. W. Ellis 和 Xavier Serra。“带有嘈杂标签和最小监督的音频标签”。已提交至 DCASE2019 Workshop，2019。网址:【https://arxiv.org/abs/1906.02975 T2】</p><p id="018f" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">爱德华多·丰塞卡、若尔迪·庞斯、哈维尔·法沃里、弗雷德里克·方特、德米特里·波格丹诺夫、安德烈斯·费拉罗、塞尔吉奥·奥拉马斯、阿拉斯泰尔·波特和哈维尔·塞拉。<a class="ae md" href="https://ismir2017.smcnus.org/wp-content/uploads/2017/10/161_Paper.pdf" rel="noopener ugc nofollow" target="_blank"> Freesound datasets:一个创建开放音频数据集的平台</a>。《第 18 届国际音乐信息检索学会会议论文集》(ISMIR 2017)，第 486–493 页。中国苏州，2017。</p></div></div>    
</body>
</html>