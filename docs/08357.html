<html>
<head>
<title>Automatic Machine Learning in Fraud Detection Using H2O AutoML</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用 H2O AutoML 的欺诈检测中的自动机器学习</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/automatic-machine-learning-in-fraud-detection-using-h2o-automl-6ba5cbf5c79b?source=collection_archive---------22-----------------------#2019-11-13">https://towardsdatascience.com/automatic-machine-learning-in-fraud-detection-using-h2o-automl-6ba5cbf5c79b?source=collection_archive---------22-----------------------#2019-11-13</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="7285" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">金融中的机器学习自动化</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/10eaf3fd94e6b68058ddc2ff7b7131f5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*lMVP1-oS4rU4WrwftsPE5A.jpeg"/></div></div></figure><p id="5914" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">机器学习在金融领域有许多应用，如安全、流程自动化、贷款/保险承保、信用评分、交易等。[1][2].金融欺诈是金融安全的主要问题之一[1][2]。为了对抗日益增加的金融欺诈风险，机器学习已被积极应用于欺诈检测[3][4]。</p><p id="9fe8" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">将机器学习应用于欺诈检测存在许多技术挑战。一个主要的困难是数据集在正负类方面倾向于高度倾斜和不平衡[3][4]。如[3]所示，为了在这种情况下获得血统欺诈检测/预测结果，通常需要领域专业知识和大量人工工作来进行数据探索、数据预处理、特征工程、模型选择、训练、评估等。</p><p id="b1fd" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">为了应对这些挑战，H2O [6]提供了一个用户友好的自动机器学习模块，称为 AutoML [7]，非专家也可以使用。</p><p id="b082" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">在本文中，与[3]类似，我使用 Kaggle [5]中相同的高度偏斜和不平衡的合成金融数据集来演示如何使用 AutoML [7]来简化机器学习以进行欺诈预测，与[3]中的机器学习方法相比。</p><h1 id="fd52" class="lq lr it bd ls lt lu lv lw lx ly lz ma jz mb ka mc kc md kd me kf mf kg mg mh bi translated">1.没有自动化的机器学习</h1><p id="2ded" class="pw-post-body-paragraph ku kv it kw b kx mi ju kz la mj jx lc ld mk lf lg lh ml lj lk ll mm ln lo lp im bi translated">本节总结了[3]中无自动化的机器学习方法的要点，以建立与第 2 节中的 H2O 自动机器学习方法进行比较的基线。</p><h2 id="12d2" class="mn lr it bd ls mo mp dn lw mq mr dp ma ld ms mt mc lh mu mv me ll mw mx mg my bi translated">1.1 数据探索</h2><p id="f727" class="pw-post-body-paragraph ku kv it kw b kx mi ju kz la mj jx lc ld mk lf lg lh ml lj lk ll mm ln lo lp im bi translated">在[3]中，进行了广泛的数据探索和分析工作，以了解哪些数据记录和特征是必需的，以及哪些数据记录和特征可以被丢弃而不会对机器学习建模和欺诈预测产生重大影响。这类工作往往需要领域专业知识，如[3]所示。[3]中的主要结果可以总结如下:</p><ul class=""><li id="1c14" class="mz na it kw b kx ky la lb ld nb lh nc ll nd lp ne nf ng nh bi translated"><strong class="kw iu">特征<em class="ni">类型</em>T3】</strong></li></ul><p id="544d" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">响应类<em class="ni">is fraud</em>(0-否，1-是)仅在值的特征<em class="ni">类型</em>为 CASH_OUT 或 TRANSFER 时设置。因此，唯一相关的数据记录是那些具有值 CASH_OUT 或 TRANSFER [3]的<em class="ni">类型</em>的记录。</p><ul class=""><li id="2648" class="mz na it kw b kx ky la lb ld nb lh nc ll nd lp ne nf ng nh bi translated"><strong class="kw iu">特征<em class="ni">isFlaggedFraud</em>T13】</strong></li></ul><p id="a4a0" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">特征<em class="ni"> isFlaggedFraud </em>仅在总共数百万条数据记录中的 16 条数据记录/样本[3]中设置，因此我们可以在不对建模和欺诈预测的结果产生重大影响的情况下删除该特征。</p><ul class=""><li id="f58a" class="mz na it kw b kx ky la lb ld nb lh nc ll nd lp ne nf ng nh bi translated"><strong class="kw iu">特性<em class="ni">命名来源</em>和<em class="ni">命名最早</em>T21】</strong></li></ul><p id="4719" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">如[3]中所指出的，特性<em class="ni">命名来源</em>和<em class="ni">命名目的</em>没有意义，因为它们没有以预期的方式对商户账户进行编码，因此可以删除。</p><h2 id="9525" class="mn lr it bd ls mo mp dn lw mq mr dp ma ld ms mt mc lh mu mv me ll mw mx mg my bi translated">1.2 数据预处理</h2><p id="0594" class="pw-post-body-paragraph ku kv it kw b kx mi ju kz la mj jx lc ld mk lf lg lh ml lj lk ll mm ln lo lp im bi translated">根据数据探索的结果，数据集在[3]中进行如下预处理。</p><ul class=""><li id="462f" class="mz na it kw b kx ky la lb ld nb lh nc ll nd lp ne nf ng nh bi translated"><strong class="kw iu">提取<em class="ni">类</em>转账或提现</strong>的数据记录</li></ul><p id="87c4" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">根据数据探索的结果，只有当数据类型为 TRANSFER 或 CASH_OUT 时，才会发生欺诈。因此，只有那些数据记录从原始数据集中提取出来，用于模型训练和欺诈预测[3]。此外，不太有用的功能<em class="ni">命名为 Orig </em>、<em class="ni">命名为 Dest </em>和<em class="ni">为 FlaggedFraud </em>被删除:</p><pre class="kj kk kl km gt nj nk nl nm aw nn bi"><span id="0617" class="mn lr it nk b gy no np l nq nr">X = df.loc[(df.type == ‘TRANSFER’) | (df.type == ‘CASH_OUT’)]<br/>X = X.drop([‘nameOrig’, ‘nameDest’, ‘isFlaggedFraud’], axis = 1)</span></pre><ul class=""><li id="66f9" class="mz na it kw b kx ky la lb ld nb lh nc ll nd lp ne nf ng nh bi translated"><strong class="kw iu">输入缺失值</strong></li></ul><p id="b1f7" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">如[3]中所述，目的地账户余额为零是欺诈的明显迹象。因此，帐户余额不应该用统计值或随后对交易金额进行调整的分布值来估算。这是因为这样做会使欺诈交易看起来像真的。为了避免这个问题，在[3]中，值为 0 的目标帐户余额被替换为-1，以使其更适合用于欺诈检测的机器学习算法:</p><pre class="kj kk kl km gt nj nk nl nm aw nn bi"><span id="c088" class="mn lr it nk b gy no np l nq nr">X.loc[(X.oldBalanceDest == 0) &amp; (X.newBalanceDest == 0) &amp; (X.amount != 0), [‘oldBalanceDest’, ‘newBalanceDest’]] = -1</span></pre><p id="1ae8" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">此外，如[3]中所指出的，在非零金额交易之前和之后，数据还具有发起账户的零余额的若干交易。在这种情况下，与真实交易的比例(47%)相比，欺诈交易的比例(0.3%)要小得多[3]。类似于目的地账户余额为零的处理，起始账户余额 0 被替换为空值<em class="ni">而不是输入一个数值来区分欺诈交易和[3]中的真实交易。</em></p><pre class="kj kk kl km gt nj nk nl nm aw nn bi"><span id="e22f" class="mn lr it nk b gy no np l nq nr">X.loc[(X.oldBalanceOrig == 0) &amp; (X.newBalanceOrig == 0) &amp; (X.amount != 0), ['oldBalanceOrig', 'newBalanceOrig']] = np.nan</span></pre><h2 id="a9fa" class="mn lr it bd ls mo mp dn lw mq mr dp ma ld ms mt mc lh mu mv me ll mw mx mg my bi translated">1.3 特征工程</h2><p id="790f" class="pw-post-body-paragraph ku kv it kw b kx mi ju kz la mj jx lc ld mk lf lg lh ml lj lk ll mm ln lo lp im bi translated">如[3]所述，目的账户或发起账户的零余额有助于区分欺诈交易和真实交易。这促使作者创建了以下两个新功能来记录每笔交易的起始帐户和目的帐户中的错误[3]。这些新特性对于获得[3]中采用的机器学习算法的最佳性能非常重要。</p><pre class="kj kk kl km gt nj nk nl nm aw nn bi"><span id="c056" class="mn lr it nk b gy no np l nq nr">X[‘errorBalanceOrig’] = X.newBalanceOrig + X.amount - X.oldBalanceOrig</span><span id="d0e7" class="mn lr it nk b gy ns np l nq nr">X[‘errorBalanceDest’] = X.oldBalanceDest + X.amount — X.newBalanceDest</span></pre><h2 id="f751" class="mn lr it bd ls mo mp dn lw mq mr dp ma ld ms mt mc lh mu mv me ll mw mx mg my bi translated">1.4 型号选择</h2><p id="4143" class="pw-post-body-paragraph ku kv it kw b kx mi ju kz la mj jx lc ld mk lf lg lh ml lj lk ll mm ln lo lp im bi translated">[3]中考虑的用于模型选择的第一种方法是在应用机器学习算法之前，通过对多数类进行欠采样来平衡不平衡数据。欠采样的缺点是，以这种方式训练的模型在现实世界中看不到的不平衡数据上可能表现不好，因为在模型训练期间几乎所有的不平衡信息都被丢弃了。</p><p id="c935" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">[3]中考虑的第二种方法是<a class="ae nt" href="https://en.wikipedia.org/wiki/Oversampling" rel="noopener ugc nofollow" target="_blank">过采样</a>少数类。作者尝试了各种类型的异常检测和监督学习方法。</p><p id="9b56" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">如[3]所述，经过多次实验，作者最终得出结论:采用<a class="ae nt" href="https://xgboost.readthedocs.io/en/latest/python/python_intro.html" rel="noopener ugc nofollow" target="_blank">xboost</a>机器学习算法在原始数据集上获得了最好的结果。</p><h2 id="3731" class="mn lr it bd ls mo mp dn lw mq mr dp ma ld ms mt mc lh mu mv me ll mw mx mg my bi translated">1.5 模型培训与评估</h2><p id="cae6" class="pw-post-body-paragraph ku kv it kw b kx mi ju kz la mj jx lc ld mk lf lg lh ml lj lk ll mm ln lo lp im bi translated">数据集分为两部分，如下文[3]所示，80%用于模型训练，20%用于模型测试:</p><pre class="kj kk kl km gt nj nk nl nm aw nn bi"><span id="5043" class="mn lr it nk b gy no np l nq nr">trainX, testX, trainY, testY = train_test_split(X, Y, test_size = 0.2, random_state = randomState)</span></pre><p id="0017" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">所选<em class="ni">XB classifier</em>模型的超参数设置为特定值:</p><pre class="kj kk kl km gt nj nk nl nm aw nn bi"><span id="a150" class="mn lr it nk b gy no np l nq nr">weights = (Y == 0).sum() / (1.0 * (Y == 1).sum())</span><span id="1064" class="mn lr it nk b gy ns np l nq nr">clf = XGBClassifier(max_depth = 3, scale_pos_weight = weights, n_jobs = 4)</span></pre><p id="eec6" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">模型训练和测试按以下[3]进行:</p><pre class="kj kk kl km gt nj nk nl nm aw nn bi"><span id="88ef" class="mn lr it nk b gy no np l nq nr">probabilities = clf.fit(trainX, trainY).predict_proba(testX)</span></pre><p id="32dc" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">使用<em class="ni"> AUPRC </em> ( <a class="ae nt" href="http://pages.cs.wisc.edu/~boyd/aucpr_final.pdf" rel="noopener ugc nofollow" target="_blank">精确-再调用曲线下的区域</a>)而非正常的<a class="ae nt" href="https://en.wikipedia.org/wiki/Receiver_operating_characteristic#Area_under_the_curve" rel="noopener ugc nofollow" target="_blank"> <em class="ni"> AUC </em> </a>的值来评估模型性能:</p><pre class="kj kk kl km gt nj nk nl nm aw nn bi"><span id="6216" class="mn lr it nk b gy no np l nq nr">print(‘AUPRC = {}’.format(average_precision_score(testY, probabilities[:, 1])))</span></pre><h1 id="f1b7" class="lq lr it bd ls lt lu lv lw lx ly lz ma jz mb ka mc kc md kd me kf mf kg mg mh bi translated">2.自动机器学习</h1><p id="9088" class="pw-post-body-paragraph ku kv it kw b kx mi ju kz la mj jx lc ld mk lf lg lh ml lj lk ll mm ln lo lp im bi translated">如前一节和[3]所述，为了从高度倾斜和不平衡的数据中获得血统欺诈预测结果，数据探索、数据预处理、特征工程、模型选择、训练、评估等都需要大量的领域知识和手工工作。</p><p id="08b0" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">本节将演示如何使用 H2O AutoML [7]通过自动机器学习来减少手动工作量，包括但不限于以下内容:</p><ul class=""><li id="7ad9" class="mz na it kw b kx ky la lb ld nb lh nc ll nd lp ne nf ng nh bi translated">自动数据预处理(例如，处理丢失的数据)</li><li id="1d67" class="mz na it kw b kx nu la nv ld nw lh nx ll ny lp ne nf ng nh bi translated">自动特征工程</li><li id="52cf" class="mz na it kw b kx nu la nv ld nw lh nx ll ny lp ne nf ng nh bi translated">自动选型</li><li id="47cc" class="mz na it kw b kx nu la nv ld nw lh nx ll ny lp ne nf ng nh bi translated">自动模型训练</li><li id="bd79" class="mz na it kw b kx nu la nv ld nw lh nx ll ny lp ne nf ng nh bi translated">自动模型评估</li></ul><p id="eabb" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">H2O [6]是基于客户机和服务器的集群架构。在开始任何其他活动之前，H2O 服务器需要启动:</p><pre class="kj kk kl km gt nj nk nl nm aw nn bi"><span id="3286" class="mn lr it nk b gy no np l nq nr">import h2o<br/>from h2o.automl import H2OAutoML<br/>h2o.init()</span></pre><p id="1d71" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">如果 H2O 服务器在本地计算机上成功启动，将显示以下内容:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nz"><img src="../Images/7899b84ca07ae41e37996c4233c6a94b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*rPc0Vg0AESm5t8UYrBXAwQ.png"/></div></div></figure><h2 id="24ad" class="mn lr it bd ls mo mp dn lw mq mr dp ma ld ms mt mc lh mu mv me ll mw mx mg my bi translated">2.1 数据加载</h2><p id="5db0" class="pw-post-body-paragraph ku kv it kw b kx mi ju kz la mj jx lc ld mk lf lg lh ml lj lk ll mm ln lo lp im bi translated">一旦将 Kaggle [5]中的合成金融数据集下载到 H2O 服务器机器上，就可以按如下方式将该数据集加载到 H2O 服务器上:</p><pre class="kj kk kl km gt nj nk nl nm aw nn bi"><span id="7f5b" class="mn lr it nk b gy no np l nq nr">df = h2o.import_file(‘./data/PS_20174392719_1491204439457_log.csv’)<br/>df.head(10)</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oa"><img src="../Images/5f527a0302dbfba169bd2cc870c94f17.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*96Zbg-7M7UX2RKE7tyvweQ.png"/></div></div></figure><p id="ac2e" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">数据集的摘要描述可通过以下方式获得:</p><pre class="kj kk kl km gt nj nk nl nm aw nn bi"><span id="d63f" class="mn lr it nk b gy no np l nq nr">df.describe()</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ob"><img src="../Images/7065c29a2df4cc29474295fdfd09d3dd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*0jRHP_C20STv2SItVQ7log.png"/></div></div></figure><p id="4904" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">响应类<em class="ni">的数据类型为 raud </em>设置为分类(即因子)，因为它是二进制的(0-否，1-是):</p><pre class="kj kk kl km gt nj nk nl nm aw nn bi"><span id="a9f8" class="mn lr it nk b gy no np l nq nr">factorslist = [‘isFraud’]<br/>df[factorslist] = df[factorslist].asfactor()</span></pre><h2 id="14d7" class="mn lr it bd ls mo mp dn lw mq mr dp ma ld ms mt mc lh mu mv me ll mw mx mg my bi translated">2.2 数据预处理</h2><p id="87e0" class="pw-post-body-paragraph ku kv it kw b kx mi ju kz la mj jx lc ld mk lf lg lh ml lj lk ll mm ln lo lp im bi translated">为与[3]中的方法相比较，与[3]类似，仅从原始数据集中提取 TRANSFER 或 CASH_OUT 类型的数据记录进行模型训练和欺诈预测，去掉不重要的特征<em class="ni"> nameOrig </em>、<em class="ni"> nameDest </em>、<em class="ni">is lagged 欺诈</em>。</p><pre class="kj kk kl km gt nj nk nl nm aw nn bi"><span id="8c0e" class="mn lr it nk b gy no np l nq nr">df1 = df[df[‘type’] == ‘TRANSFER’ or df[‘type’] == ‘CASH_OUT’]<br/>y = “isFraud”<br/>x = df.columns<br/>x.remove(y)<br/>x.remove(“nameOrig”)<br/>x.remove(“nameDest”)<br/>x.remove(“isFlaggedFraud”)</span></pre><h2 id="5764" class="mn lr it bd ls mo mp dn lw mq mr dp ma ld ms mt mc lh mu mv me ll mw mx mg my bi translated">2.3 选型及培训</h2><p id="7a8e" class="pw-post-body-paragraph ku kv it kw b kx mi ju kz la mj jx lc ld mk lf lg lh ml lj lk ll mm ln lo lp im bi translated">为了与[3]中的方法相比较，提取的数据集被分成如下两部分，80%用于模型训练，20%用于模型测试:</p><pre class="kj kk kl km gt nj nk nl nm aw nn bi"><span id="7b11" class="mn lr it nk b gy no np l nq nr">train, test = df1.split_frame([0.8])</span></pre><p id="d8cf" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">选择了超参数<em class="ni"> max_models </em>值为 10 的<em class="ni"> H2O 汽车</em>模型:</p><pre class="kj kk kl km gt nj nk nl nm aw nn bi"><span id="36f8" class="mn lr it nk b gy no np l nq nr">aml = H2OAutoML(max_models = 10, seed = 1)</span></pre><p id="ff11" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">使用默认设置训练选定的模型，如下所示:</p><pre class="kj kk kl km gt nj nk nl nm aw nn bi"><span id="8c3d" class="mn lr it nk b gy no np l nq nr">aml.train(x = x, y = y, training_frame = train)</span></pre><h2 id="c856" class="mn lr it bd ls mo mp dn lw mq mr dp ma ld ms mt mc lh mu mv me ll mw mx mg my bi translated">2.4 模型评估</h2><ul class=""><li id="4d1f" class="mz na it kw b kx mi la mj ld oc lh od ll oe lp ne nf ng nh bi translated"><strong class="kw iu">查看训练模型列表</strong></li></ul><p id="5320" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">一旦 H2O AutoML 模型被训练，相应的<em class="ni">排行榜</em>方法可用于显示训练模型列表，按<em class="ni"> AUC </em>(非<em class="ni"> AUPRC </em>)降序排列:</p><pre class="kj kk kl km gt nj nk nl nm aw nn bi"><span id="0ccf" class="mn lr it nk b gy no np l nq nr">lb = aml.leaderboard<br/>lb.head(rows=lb.nrows)</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi of"><img src="../Images/95e0088a0b892f3b2b33071c869df3c1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*P_OywEiQq2pAdp0Xf9RXYg.png"/></div></div></figure><p id="63d0" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">从上表中我们可以看到，H2O AutoML 自动选择并训练了 12 个不同的模型，包括堆叠系综模型。主导车型为<em class="ni">XGBoost _ 3 _ AutoML _ 2019 11 13 _ 110031</em>。</p><ul class=""><li id="625f" class="mz na it kw b kx ky la lb ld nb lh nc ll nd lp ne nf ng nh bi translated"><strong class="kw iu">获取并评估主导模型</strong></li></ul><p id="e1fa" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">位于训练模型列表顶部的模型可以如下获得:</p><pre class="kj kk kl km gt nj nk nl nm aw nn bi"><span id="76a4" class="mn lr it nk b gy no np l nq nr">leader_model = aml.leader</span></pre><p id="d63a" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">注意，这个领先的模型在模型训练<em class="ni"> AUC </em>(不是<em class="ni"> AUPRC </em>)分数方面是最好的。</p><p id="68c9" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">主要模型测试性能的综合总结如下:</p><pre class="kj kk kl km gt nj nk nl nm aw nn bi"><span id="a34b" class="mn lr it nk b gy no np l nq nr">leader_model.model_performance(test)</span></pre><p id="b7cb" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">如下图所示，领先车型的测试<em class="ni"> AUPRC </em>(即<em class="ni"> pr_auc </em>)得分为 0.988。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi og"><img src="../Images/547fcddd20df5149cd0220670f87a0d0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*5dWQwXOuyuZgQCc3VZiXxg.png"/></div></div></figure><p id="1636" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">下面的代码将获取主导模型的特征重要性:</p><pre class="kj kk kl km gt nj nk nl nm aw nn bi"><span id="fb16" class="mn lr it nk b gy no np l nq nr">leader_model.varimp_plot()</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oh"><img src="../Images/9f671cecf661eeefeb6a2bb07bb96f05.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_qmeAu-iuiIxP6CpYro4IA.png"/></div></div></figure><ul class=""><li id="a009" class="mz na it kw b kx ky la lb ld nb lh nc ll nd lp ne nf ng nh bi translated"><strong class="kw iu">获得并评估具有最佳训练的模型 AUPRC </strong></li></ul><p id="a1b5" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">然而，模型测试<em class="ni"> AUPRC </em>而非<em class="ni"> AUC </em>在【3】中用于模型性能评估。为了进行公平的比较，我们需要用最好的测试<em class="ni"> AUPRC </em>来获取和评估训练好的模型。为此，我们可以首先获得并评估具有最佳训练 AUPRC 的模型，然后将其测试 AUPRC 性能与领先模型进行比较，以确定应该选择哪个模型。</p><p id="b8c7" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">如前所述，H2O AutoML 的<em class="ni">排行榜</em>方法按照训练<em class="ni"> AUC </em>而非<em class="ni"> AUPRC </em>的降序显示已训练车型列表。为了找到具有最佳训练<em class="ni"> AUPRC </em>的模型，可以使用以下代码以训练<em class="ni"> AUPRC </em>的降序显示训练过的模型:</p><pre class="kj kk kl km gt nj nk nl nm aw nn bi"><span id="590d" class="mn lr it nk b gy no np l nq nr">import pandas as pd</span><span id="b8e6" class="mn lr it nk b gy ns np l nq nr">model_ids = list(aml.leaderboard['model_id'].as_data_frame().iloc[:,0])</span><span id="8e64" class="mn lr it nk b gy ns np l nq nr">model_auprc_map = {'Model Id' : [], 'AUPRC' : []}<br/>for mid in model_ids:<br/>    model = h2o.get_model(mid)<br/>    model_prauc_map['Model Id'].append(mid)<br/>    model_prauc_map['<em class="ni">AUPRC</em>'].append(model.pr_auc(train))<br/>model_auprc_df = pd.DataFrame(model_auprc_map)<br/>model_auprc_df.sort_values(['<em class="ni">AUPRC</em>'], ascending=0, inplace=True)<br/>model_auprc_df.head(20)</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oi"><img src="../Images/c0c0900e0dc74829c43f6e16749ae049.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*VxDrg473ThzUOUU8jsfNCA.png"/></div></div></figure><p id="9398" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">可以看到最佳训练<em class="ni"> AUPRC </em>为 0.937 的模型 id 为 XGBoost _ 2 _ AutoML _ 2019 11 13 _ 110031。</p><p id="97dc" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">列表顶部的模型可以通过以下方式获得:</p><pre class="kj kk kl km gt nj nk nl nm aw nn bi"><span id="fe0c" class="mn lr it nk b gy no np l nq nr">best_auprc_model_id = model_auprc_df.iloc[0, 0]<br/>best_auprc_model = h2o.get_model(best_auprc_model_id)</span></pre><p id="39ba" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">然后，可以获得模型测试性能的全面总结:</p><pre class="kj kk kl km gt nj nk nl nm aw nn bi"><span id="538c" class="mn lr it nk b gy no np l nq nr">best_auprc_model.model_performance(test)</span></pre><p id="abd7" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">如下图所示，最佳训练<em class="ni"> AUPRC </em>(即<em class="ni"> pr_auc </em>)的车型取得了 0.975 的测试<em class="ni"> AUPRC </em>分数。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oj"><img src="../Images/5152580cf4ea6797292b3344de43638a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*nej-qO-vD2jx7-adM4YLPg.png"/></div></div></figure><p id="7026" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">以下代码用于获取具有最佳训练<em class="ni"> AUPRC </em>分数的模型的特征重要性:</p><pre class="kj kk kl km gt nj nk nl nm aw nn bi"><span id="865f" class="mn lr it nk b gy no np l nq nr">best_prauc_model.varimp_plot()</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ok"><img src="../Images/e58e2f284bb8fb83eb21d793e97a5636.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*gBvoaBqBDBkMnUstfZBtfQ.png"/></div></div></figure><p id="9925" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">测试结果表明，在测试 AUPRC 分数方面，领先模型优于具有最佳训练 AUPRC 分数的模型。因此，应该选择领先的模型。</p><h2 id="650b" class="mn lr it bd ls mo mp dn lw mq mr dp ma ld ms mt mc lh mu mv me ll mw mx mg my bi translated">2.5 与没有自动化的机器学习的比较</h2><p id="923c" class="pw-post-body-paragraph ku kv it kw b kx mi ju kz la mj jx lc ld mk lf lg lh ml lj lk ll mm ln lo lp im bi translated">下表比较了 H2O AutoML [7]和[3]中无自动化的机器学习方法之间的主要机器学习活动。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oh"><img src="../Images/9426f9e9d21f0b3f7cd11ae73a31cc4e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*GvFqfHilyF_W6KgdvXyuRg.png"/></div></div></figure><p id="15d2" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">如第 1 节和[3]中所述，在处理缺失数据、特征工程、模型选择、培训、评估等方面，需要领域专业知识和大量手工工作。所有这些类型的工作都是在 AutoML [7]中自动完成的，无需人工干预。另外，AutoML [7]中的模型超参数设置比[3]中的机器学习方法简单得多。</p><p id="5fc6" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">然而，关于模型测试方面的模型测试性能<em class="ni"> AUPRC </em>，与 AutoML 的 0.988 分相比，[3]中的机器学习方法获得了更高的 0.997 分。</p><p id="7e52" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">AutoML 的主要优势在于，非专家可以使用它从复杂的数据集(如本文中使用的高度偏斜和不平衡的数据集)中获得相当下降的欺诈检测/预测结果。</p><h1 id="dce8" class="lq lr it bd ls lt lu lv lw lx ly lz ma jz mb ka mc kc md kd me kf mf kg mg mh bi translated">摘要</h1><p id="fc26" class="pw-post-body-paragraph ku kv it kw b kx mi ju kz la mj jx lc ld mk lf lg lh ml lj lk ll mm ln lo lp im bi translated">在本文中，正如在[3]中一样，我在 Kaggle [5]中使用了相同的高度偏斜和不平衡的合成金融数据集来展示 H2O 汽车公司[7]在使非专家能够将机器学习应用于金融欺诈检测方面的能力。这是通过数据预处理、特征工程、模型选择、模型训练和模型评估的自动化实现的。体面的模型测试<em class="ni"> AUPRC </em>得分为 0.988。</p><p id="2167" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">如第 2.5 节所述，通过手工制作数据预处理、特征工程、模型选择、训练等方法，在[3]中获得了更高的模型测试<em class="ni"> AUPRC </em>分数 0.997。在这种情况下，根据业务需求，可能有理由支持用户定义的机器学习方法而不是 AutoML。我注意到 H2O 提供了一个更强大的端到端自动机器学习工具集，叫做，<a class="ae nt" href="https://www.h2o.ai/products/h2o-driverless-ai/?utm_source=google&amp;utm_medium=test&amp;utm_campaign=aiforbiz&amp;utm_content=get-it-now&amp;gclid=CjwKCAiA8K7uBRBBEiwACOm4d0zU8kzChZsufVOOI3LYYlypv_33jWqxj4CK9t7YzTvfHM65CzbarBoCeNAQAvD_BwE" rel="noopener ugc nofollow" target="_blank"> H2O 无人驾驶 AI </a> [8]。该工具集具有<a class="ae nt" href="https://www.h2o.ai/products-h2o-driverless-ai-recipes/" rel="noopener ugc nofollow" target="_blank">自带方法</a>的功能，使用户能够即插即用自己的方法进行数据预处理、特征工程、建模等。</p><p id="5ef5" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">Github [9]中有一个 Jupyter 笔记本，上面有本文中的所有源代码。</p><h1 id="c6e1" class="lq lr it bd ls lt lu lv lw lx ly lz ma jz mb ka mc kc md kd me kf mf kg mg mh bi translated">参考</h1><p id="f85f" class="pw-post-body-paragraph ku kv it kw b kx mi ju kz la mj jx lc ld mk lf lg lh ml lj lk ll mm ln lo lp im bi translated">[1].K. Didur，<a class="ae nt" rel="noopener" target="_blank" href="/machine-learning-in-finance-why-what-how-d524a2357b56">金融中的机器学习:为什么，什么&amp;如何</a></p><p id="1be5" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">[2].D. Faggella，<a class="ae nt" href="https://emerj.com/ai-sector-overviews/machine-learning-in-finance/" rel="noopener ugc nofollow" target="_blank">金融中的机器学习——现在和未来的应用</a></p><p id="af32" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">[3].a .约书亚，<a class="ae nt" href="https://www.kaggle.com/arjunjoshua/predicting-fraud-in-financial-payment-services" rel="noopener ugc nofollow" target="_blank">预测金融支付服务中的欺诈</a></p><p id="c128" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">[4].R. Pierre，<a class="ae nt" rel="noopener" target="_blank" href="/detecting-financial-fraud-using-machine-learning-three-ways-of-winning-the-war-against-imbalanced-a03f8815cce9">使用机器学习检测金融欺诈:赢得对不平衡数据的战争</a></p><p id="b6d1" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">[5].<a class="ae nt" href="https://www.kaggle.com/ntnu-testimon/paysim1" rel="noopener ugc nofollow" target="_blank">用于欺诈检测的合成金融数据集</a></p><p id="cc06" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">[6].<a class="ae nt" href="http://docs.h2o.ai/h2o/latest-stable/h2o-docs/index.html" rel="noopener ugc nofollow" target="_blank"> H2O.ai </a></p><p id="0624" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">[7].<a class="ae nt" href="http://docs.h2o.ai/h2o/latest-stable/h2o-docs/automl.html" rel="noopener ugc nofollow" target="_blank"> H2O 汽车</a></p><p id="fcf8" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">【8】<a class="ae nt" href="https://www.h2o.ai/products/h2o-driverless-ai/?utm_source=google&amp;utm_medium=test&amp;utm_campaign=aiforbiz&amp;utm_content=get-it-now&amp;gclid=CjwKCAiA8K7uBRBBEiwACOm4d0zU8kzChZsufVOOI3LYYlypv_33jWqxj4CK9t7YzTvfHM65CzbarBoCeNAQAvD_BwE" rel="noopener ugc nofollow" target="_blank">H2O 无人驾驶 AI </a></p><p id="b205" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">[9].Github 中的 Jupyter 笔记本</p></div><div class="ab cl ol om hx on" role="separator"><span class="oo bw bk op oq or"/><span class="oo bw bk op oq or"/><span class="oo bw bk op oq"/></div><div class="im in io ip iq"><p id="4046" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">披露声明:2019 首创一。观点是作者个人的观点。除非本帖中另有说明，否则 Capital One 不隶属于所提及的任何公司，也不被这些公司认可。使用或展示的所有商标和其他知识产权是其各自所有者的财产。</p></div></div>    
</body>
</html>