<html>
<head>
<title>A Brief Primer on Optimization for Disillusionment</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">幻灭优化的简单入门</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/a-brief-primer-on-optimization-to-unlock-the-universe-7d5c72af59e1?source=collection_archive---------25-----------------------#2019-10-02">https://towardsdatascience.com/a-brief-primer-on-optimization-to-unlock-the-universe-7d5c72af59e1?source=collection_archive---------25-----------------------#2019-10-02</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><figure class="is it gp gr iu iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi ir"><img src="../Images/d17d3bc8c3959d859915fc0c22a21e0e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*_xwi7-VUPXfOTzYn"/></div></div><figcaption class="jc jd gj gh gi je jf bd b be z dk">Photo by <a class="ae jg" href="https://unsplash.com/@lucabravo?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Luca Bravo</a> on <a class="ae jg" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><div class=""/><div class=""><h2 id="5848" class="pw-subtitle-paragraph kg ji jj bd b kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx dk translated">人工智能、机器学习和运筹学之间有什么共同点？优化，优化，优化…</h2></div><p id="07fc" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">你有没有想过所有这些疯狂的深度学习算法和机器学习论文的背后是什么？核心是优化，即拟合参数以最小化或最大化某个目标函数。在这篇文章中，我将给出一个关于优化和各种子类别的简要概述。在进一步阅读之前只要记住一件事，<strong class="la jk">针对人工智能和机器学习爱好者</strong>:</p><figure class="lv lw lx ly gt iv gh gi paragraph-image"><div class="gh gi lu"><img src="../Images/d7169073f78cc2f8efd38c2efceab849.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/0*njWXQG7MtA57oNRt.jpg"/></div></figure><p id="bffd" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">实际上，我还要写一份免责声明:</p><blockquote class="lz"><p id="1d7e" class="ma mb jj bd mc md me mf mg mh mi lt dk translated">这里没有高等数学，只有纯粹的直觉。</p></blockquote><p id="17a3" class="pw-post-body-paragraph ky kz jj la b lb mj kk ld le mk kn lg lh ml lj lk ll mm ln lo lp mn lr ls lt im bi translated">首先，让我们明确一件重要的事情，什么是优化。大多数情况下，我们需要学习某种参数θ，以便最小化目标函数。具体来说，我们写如下:</p><figure class="lv lw lx ly gt iv gh gi paragraph-image"><div class="gh gi mo"><img src="../Images/60dc0ba9e5f76724d6b4cb6151f2197d.png" data-original-src="https://miro.medium.com/v2/resize:fit:488/0*JxssUQEEF7oHXRww"/></div></figure><p id="7d10" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">所以有某种函数，<strong class="la jk"> L </strong>我们称之为目标函数。我们想把它最小化。现在，我们不会对如何实际最小化它感兴趣，但是我们将在优化类型之间进行高层次的区分。</p><ol class=""><li id="da2f" class="mp mq jj la b lb lc le lf lh mr ll ms lp mt lt mu mv mw mx bi translated">我们有<strong class="la jk">无约束最优化。</strong>这基本上意味着我们可以最小化/最大化目标函数，而不用考虑其他任何事情，这使得问题变得简单了一些。</li><li id="4741" class="mp mq jj la b lb my le mz lh na ll nb lp nc lt mu mv mw mx bi translated">另一方面，有<strong class="la jk">约束优化</strong>在这种情况下，我们有一组特定的约束。这些规则规定了我们可以使用什么样的参数<strong class="la jk"> θ </strong>进行最小化。</li></ol><p id="f8b0" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">现在我们知道了什么是约束优化，什么是无约束优化。让我们转向最低限度的问题。显然，各种优化都与寻找某种最大值的最小值有关。正确的措辞应该是<strong class="la jk">极端</strong>。关键在于搜索是局部极值还是全局极值。</p><ol class=""><li id="f97d" class="mp mq jj la b lb lc le lf lh mr ll ms lp mt lt mu mv mw mx bi translated"><strong class="la jk">局部极值</strong>更容易找到，我们可以只看一下一阶和二阶条件来检查某个东西是否是局部最小值或最大值。一阶意味着检查目标函数的一阶导数是否等于 0，并检查我们是否具有正曲率或负曲率(二阶导数)。</li><li id="fb1e" class="mp mq jj la b lb my le mz lh na ll nb lp nc lt mu mv mw mx bi translated"><strong class="la jk">全局极值，</strong>则有点奸计。找到全局最小值或最大值并确认它们是全局的真的很难！然而，在某些情况下，函数有很好的性质，比如凸性，我们可以说我们的算法肯定会收敛到全局最小值。虽然很吸引人，但实际上这种情况很少发生，我们无法保证全局最小值/最大值。</li></ol><figure class="lv lw lx ly gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi nd"><img src="../Images/425cf4c91033e624a1a9812e5db5fe8e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ofMieq66tyAJCqAW6zYmnw.jpeg"/></div></div></figure><p id="4e2e" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">在这个超级简单的 2D 例子中，我们看到了一个全局最小值和一个局部最小值。如果我们进行基于梯度的优化，我们通常会对参数进行如下更新:</p><figure class="lv lw lx ly gt iv gh gi paragraph-image"><div class="gh gi ne"><img src="../Images/e5d08342a91276670ac032b2fbaaed68.png" data-original-src="https://miro.medium.com/v2/resize:fit:358/0*H_Tcp813ECfa3cjX"/></div></figure><p id="c1ee" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">所以我们在时间步<strong class="la jk"> t </strong>有一些参数，它们在时间步<strong class="la jk"> t+1 </strong>结束。更新是神秘的<strong class="la jk"> η </strong>乘以向量<strong class="la jk">p</strong>的简单加法。这些方法中的整个研究基本上关注于为更新方向(向量<strong class="la jk"> p </strong>)和步长参数<strong class="la jk"> η定义良好的值。</strong></p><p id="5bee" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">你可以想象一下，如果算法的步长和方向都不够好的话，想要走到全局最小值是相当困难的。一开始就有好的方向是什么意思？嗯，这意味着我们的参数更新的方向向量<strong class="la jk"> p </strong>与梯度向量形成一个小于或等于 90 度的角度<strong class="la jk"> α </strong>(对正在优化的函数性质的一些细节取模)，如下图所示:</p><figure class="lv lw lx ly gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi nd"><img src="../Images/f4f832450dae7e61f557c3727139e356.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*QmQsQMgF7FlrUB5Q_-sKHQ.jpeg"/></div></div></figure><p id="5159" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">实际上是一个不好的方向，显然与我之前说的相反。当角度大于 90 度时。也许这对你来说听起来不太直观，但是想象一下下面的情况:</p><figure class="lv lw lx ly gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi nd"><img src="../Images/517f91c4b2df75b1a93b76889f6ed15f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*bY4-BPhB6WVzQDiEesgjDw.jpeg"/></div></div></figure><p id="1428" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">将它直接放在函数的上下文中，您可以查看下图并了解其效果:</p><figure class="lv lw lx ly gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi nd"><img src="../Images/a8bc66f9ac7601d58395546933ea8994.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*2AJklVn5kKucZcu5SkRiwQ.jpeg"/></div></div></figure><p id="9ed7" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">你走反了方向！显然你不会达到当地的最低值。但是方向不是唯一要担心的…</p><figure class="lv lw lx ly gt iv gh gi paragraph-image"><div class="gh gi nf"><img src="../Images/75b53d31e0cd0b76a495e100e289df4a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1284/format:webp/0*lPq5p1czNohLY02R.jpg"/></div></figure><p id="18d0" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">是的……步长非常重要，选择时也很重要。为了说明这一点，请看下图:</p><figure class="lv lw lx ly gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi nd"><img src="../Images/60d561ae3276624dffefc5671c6c3185.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*FmdgDW-xjwixfC6qTv0bxw.jpeg"/></div></div><figcaption class="jc jd gj gh gi je jf bd b be z dk">Big step in the wrong direction = missing the minimum.</figcaption></figure><p id="fd71" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">我们在优化中迈出了太大的一步，因此我们错过了函数的实际最小值。为了进一步说明这一点，请看下图:</p><figure class="lv lw lx ly gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi nd"><img src="../Images/3b226bcbb6cab256a673ba828e680744.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*JmdzYESn-Ig6qMXliUg1ag.jpeg"/></div></div></figure><p id="e154" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">如果在我们用向量<strong class="la jk"> p </strong>进行更新的点处，步长是相同的，那么我们将被卡住。因此，所有这些学习率的调整，适应性时刻等等——都是为了避免这种情况。</p></div><div class="ab cl ng nh hx ni" role="separator"><span class="nj bw bk nk nl nm"/><span class="nj bw bk nk nl nm"/><span class="nj bw bk nk nl"/></div><div class="im in io ip iq"><p id="4273" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">区分不同优化方法的另一个因素是目标函数的性质。你可能已经假设目标函数只是一个简单的连续函数。但事实未必如此，如果是随机的呢？</p><ol class=""><li id="004c" class="mp mq jj la b lb lc le lf lh mr ll ms lp mt lt mu mv mw mx bi translated"><strong class="la jk">确定性优化</strong>关注相对“正常”的函数。它们是正常的，因为它们不会在随机过程中发生变化。</li><li id="a8f1" class="mp mq jj la b lb my le mz lh na ll nb lp nc lt mu mv mw mx bi translated">在<strong class="la jk">随机(随机)</strong>的情况下，基础函数可能会在未来发生变化，因此我们只能处理期望值并最小化我们估计的不确定性。</li></ol><p id="f6c8" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">约束优化是一个有点高级的话题，所以让我们来谈谈无约束优化和不同的可能方法。显然，一篇博客文章不足以涵盖所有的优化方法。但是我们可以有把握地说，大多数约束优化方法本质上是基于无约束方法的。无约束方法可以分为以下几大类:</p><ol class=""><li id="80cb" class="mp mq jj la b lb lc le lf lh mr ll ms lp mt lt mu mv mw mx bi translated"><strong class="la jk">线搜索法</strong>是更常用的方法。这是你古老的梯度下降法。本质上，这些方法试图确定方向和步长，以基于关于目标函数的信息来更新参数。</li><li id="32fa" class="mp mq jj la b lb my le mz lh na ll nb lp nc lt mu mv mw mx bi translated"><strong class="la jk">信赖域方法</strong>只不过是线搜索方法，但它们在某一点周围对与原始函数相似的模型函数进行线搜索，并根据模型函数与原始目标函数相比的良好程度来限制参数的移动。</li></ol><p id="3ce3" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">优化文献很广泛，但我可以理解每个人都想跳入机器学习和人工智能。就我个人而言，我发现深入挖掘所有这些方法来理解所有这些方法的基本原理是非常有用的，这些方法被反复使用。</p><p id="ba00" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">我希望这篇文章有助于揭示这些优化器在更高层次上实际做了什么。一旦你摆脱了那些让整个事情看起来过于“复杂”的丑陋等式，这些概念就相对容易掌握了。实际上，一些关于梯度优化器的同样复杂的论文在他们的证明中有著名的错误，但是直觉上这些方法是相当简单的。(不会指名道姓，可能会在后面的文章中涉及:)。</p><p id="e141" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">感谢您的关注！</p><figure class="lv lw lx ly gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi nn"><img src="../Images/12c330c07c3868ffd854d2d055a716d4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*SoQV0viBcInSbJjgWBh-zA.jpeg"/></div></div></figure></div></div>    
</body>
</html>