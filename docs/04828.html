<html>
<head>
<title>Computer Vision — A journey from CNN to Mask R-CNN and YOLO -Part 1</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">计算机视觉——从 CNN 到面具 R-CNN 和 YOLO 之旅——第一部分</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/computer-vision-a-journey-from-cnn-to-mask-r-cnn-and-yolo-1d141eba6e04?source=collection_archive---------3-----------------------#2019-07-22">https://towardsdatascience.com/computer-vision-a-journey-from-cnn-to-mask-r-cnn-and-yolo-1d141eba6e04?source=collection_archive---------3-----------------------#2019-07-22</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><p id="b987" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><em class="ko">在本文中，我们将探索和了解不同计算机视觉算法 CNN 的架构和工作方式，基于区域的 CNN(R-CNN)，快速 R-CNN，更快 R-CNN。在下一篇文章中，我们将探索面具 R-CNN 和 YOLO(你只看一次)</em></p><figure class="kq kr ks kt gt ku gh gi paragraph-image"><div class="gh gi kp"><img src="../Images/034a6bd25123cdc47f126e0e5866ce3b.png" data-original-src="https://miro.medium.com/v2/resize:fit:484/format:webp/1*WBiez5pko3g2iaPVXI1KDw.png"/></div></figure><p id="a27d" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu"> <em class="ko">计算机视觉的目的是什么？</em> </strong></p><p id="ec2f" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">计算机视觉是人工智能的一个分支。它用于使计算机能够像人类视觉一样理解、识别和生成对数字图像的智能理解。</p><p id="66e0" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu"> <em class="ko">计算机视觉是干什么的？</em>T9】</strong></p><p id="c450" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">利用计算机视觉，我们可以识别</p><ul class=""><li id="5ffd" class="kx ky it js b jt ju jx jy kb kz kf la kj lb kn lc ld le lf bi translated"><strong class="js iu">图像中存在的特征</strong>如边缘检测。</li></ul><figure class="kq kr ks kt gt ku gh gi paragraph-image"><div class="gh gi lg"><img src="../Images/204b6291a969c88e0a044673d6addb96.png" data-original-src="https://miro.medium.com/v2/resize:fit:486/format:webp/1*Gu8C2a5sdKjB1z9cqgsrNA.png"/></div><figcaption class="lh li gj gh gi lj lk bd b be z dk"><strong class="bd ll">Edge detection</strong></figcaption></figure><ul class=""><li id="3732" class="kx ky it js b jt ju jx jy kb kz kf la kj lb kn lc ld le lf bi translated"><strong class="js iu">对图像中存在的物体进行分类</strong>。给图像分配标签，就像识别图像中的猫和狗或对数字进行分类</li></ul><figure class="kq kr ks kt gt ku gh gi paragraph-image"><div class="gh gi lm"><img src="../Images/124d1ece1ec29f0b2c0e71e9ca69adab.png" data-original-src="https://miro.medium.com/v2/resize:fit:1160/format:webp/1*vJ9j-FYH0L6Q-dEG_Vfgdg.png"/></div><figcaption class="lh li gj gh gi lj lk bd b be z dk"><strong class="bd ll">Image classification of digits</strong></figcaption></figure><ul class=""><li id="5817" class="kx ky it js b jt ju jx jy kb kz kf la kj lb kn lc ld le lf bi translated"><strong class="js iu">图像分类和定位</strong>。这包括对图像进行分类，以及识别物体在边界框中的位置。</li></ul><figure class="kq kr ks kt gt ku gh gi paragraph-image"><div class="gh gi ln"><img src="../Images/56b26b2bfc66e2a9bc25267bf8135e8c.png" data-original-src="https://miro.medium.com/v2/resize:fit:444/format:webp/1*XxYYa8IuLOGDD7njgNgvgw.png"/></div></figure><ul class=""><li id="aa2f" class="kx ky it js b jt ju jx jy kb kz kf la kj lb kn lc ld le lf bi translated"><strong class="js iu">对象检测</strong>识别图像中出现的所有不同对象及其位置。围绕图像中出现的所有对象绘制一个边界框。检测是识别图像中存在的内容。定位是指物体在图像中的位置</li></ul><figure class="kq kr ks kt gt ku gh gi paragraph-image"><div role="button" tabindex="0" class="lp lq di lr bf ls"><div class="gh gi lo"><img src="../Images/b69d1b3cf9fe5edd439c13a5f6719a01.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*rCzSaFvP7n3zyB7LCknpNQ.png"/></div></div><figcaption class="lh li gj gh gi lj lk bd b be z dk">Source: <a class="ae lt" href="http://www.robots.ox.ac.uk/~tvg/publications/talks/fast-rcnn-slides.pdf" rel="noopener ugc nofollow" target="_blank">http://www.robots.ox.ac.uk/~tvg/publications/talks/fast-rcnn-slides.pdf</a></figcaption></figure><ul class=""><li id="332d" class="kx ky it js b jt ju jx jy kb kz kf la kj lb kn lc ld le lf bi translated"><strong class="js iu">对象分割或语义分割</strong>在像素级检测图像中存在的所有对象。输出具有不同类别或对象的区域</li></ul><figure class="kq kr ks kt gt ku gh gi paragraph-image"><div class="gh gi lu"><img src="../Images/980da3105101b91ff4257dc44acbce4a.png" data-original-src="https://miro.medium.com/v2/resize:fit:672/format:webp/1*tt6hZzpoX6Xf0s0qjdvWGA.png"/></div><figcaption class="lh li gj gh gi lj lk bd b be z dk"><strong class="bd ll">Semantic Segmentation of two people riding a bike in front of a building</strong></figcaption></figure><ul class=""><li id="7e46" class="kx ky it js b jt ju jx jy kb kz kf la kj lb kn lc ld le lf bi translated"><strong class="js iu">神经风格转移</strong>我们通过学习一幅图像的风格并将其应用于另一幅图像来生成一幅新图像</li></ul><figure class="kq kr ks kt gt ku gh gi paragraph-image"><div role="button" tabindex="0" class="lp lq di lr bf ls"><div class="gh gi lv"><img src="../Images/043076f1ab615a6fd75f65651d78e568.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*sl7jruT0nM6o_FNaxfEdkQ.png"/></div></div><figcaption class="lh li gj gh gi lj lk bd b be z dk"><strong class="bd ll">Neural Style Transfer</strong></figcaption></figure><h1 id="c8de" class="lw lx it bd ly lz ma mb mc md me mf mg mh mi mj mk ml mm mn mo mp mq mr ms mt bi translated"><strong class="ak"> <em class="mu">利用卷积神经网络(CNN)进行图像分类是如何工作的？</em>T25】</strong></h1><p id="ea15" class="pw-post-body-paragraph jq jr it js b jt mv jv jw jx mw jz ka kb mx kd ke kf my kh ki kj mz kl km kn im bi translated">当我们观看图像时，我们扫描图像。我们可以从左到右或从上到下查看图像，以了解图像的不同特征。我们的大脑结合我们扫描的不同局部特征来对图像进行分类。这正是 CNN 的工作方式。</p><p id="27b6" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">CNN 将输入作为图像“x”，这是一个具有不同颜色通道(红色、绿色和蓝色-RGB)的二维像素阵列。</p><p id="cade" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">我们对输入图像应用不同的<strong class="js iu">滤波器或特征检测器</strong>来输出<strong class="js iu">特征图。</strong>与输入图像相比，过滤器或特征检测器在空间上很小。这些滤波器贯穿输入图像的整个深度。</p><p id="acfb" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">通过对卷积层应用非线性函数 ReLU，并行执行多次卷积。</p><p id="42eb" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">多特征检测器识别不同的东西，如边缘检测，不同的形状，弯曲或不同的颜色等。</p><figure class="kq kr ks kt gt ku gh gi paragraph-image"><div role="button" tabindex="0" class="lp lq di lr bf ls"><div class="gh gi na"><img src="../Images/05dda4756c42e00894471bcfc403a107.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*T_OMmR-w0zIi8O9b0JOb6w.png"/></div></div></figure><p id="baa9" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">我们将池应用于卷积层。我们可以应用最小池、最大池或平均池。与最小或平均池相比，最大池功能提供了更好的性能。</p><p id="26c7" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">汇集有助于<strong class="js iu">平移不变性。</strong>平移不变性意味着当我们少量改变输入时，汇集的输出不会改变。</p><p id="b5e5" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">图像的不变性意味着，即使当图像被旋转、调整不同大小或在不同照明下观看时，一个对象也将被识别为相同的对象。</p><p id="685c" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">在下一步中，我们将合并层展平，以将其输入到全连接(FC)神经网络。</p><p id="57ad" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">我们在全连接层的最终输出层中使用<strong class="js iu"> softmax </strong>激活函数进行多类分类。</p><p id="36f3" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">对于二元分类，我们在全连接层的最终输出层中使用<strong class="js iu"> sigmoid </strong>激活函数。</p><p id="f40e" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu">CNN 的实力</strong></p><p id="7cb6" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">CNN 用于</p><ul class=""><li id="76cd" class="kx ky it js b jt ju jx jy kb kz kf la kj lb kn lc ld le lf bi translated">图像分类</li><li id="f928" class="kx ky it js b jt nb jx nc kb nd kf ne kj nf kn lc ld le lf bi translated">使用包围盒的目标检测</li></ul><p id="6aa7" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu">CNN 的局限性</strong></p><ul class=""><li id="e0ee" class="kx ky it js b jt ju jx jy kb kz kf la kj lb kn lc ld le lf bi translated">使用边界框进行对象检测，但一次只能检测一个对象</li><li id="6bf2" class="kx ky it js b jt nb jx nc kb nd kf ne kj nf kn lc ld le lf bi translated">由于干扰，当多个物体在视野中时，效果不好。</li></ul><p id="d528" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu"> <em class="ko">那么我们如何识别一幅图像中存在的多个对象，并在所有不同的对象周围绘制边界框呢？</em>T13】</strong></p><p id="1675" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">我们现在探索基于区域的 CNN，这将有助于解决图像中存在多个对象的问题，并在所有不同的对象周围绘制边界框。</p><h1 id="4ea2" class="lw lx it bd ly lz ma mb mc md me mf mg mh mi mj mk ml mm mn mo mp mq mr ms mt bi translated">基于区域的 CNN- R-CNN</h1><p id="381b" class="pw-post-body-paragraph jq jr it js b jt mv jv jw jx mw jz ka kb mx kd ke kf my kh ki kj mz kl km kn im bi translated">R-CNN 用于分类，以及利用图像中存在的多个对象的边界框进行对象检测</p><p id="7be5" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu"><em class="ko">R-CNN 是如何工作的？</em> </strong></p><p id="900a" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">R-CNN 工作的前提是，在给定的区域中，只有单个感兴趣的对象将占主导地位。</p><p id="4b26" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">R-CNN 使用选择性搜索算法进行目标检测，以生成区域建议。</p><p id="6a9e" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu"> <em class="ko">那么是什么在一幅图像中形成了一个区域呢？</em>T25】</strong></p><p id="b0ab" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">图像中的区域可以通过以下方式识别</p><ul class=""><li id="5868" class="kx ky it js b jt ju jx jy kb kz kf la kj lb kn lc ld le lf bi translated">变化的颜色</li><li id="de20" class="kx ky it js b jt nb jx nc kb nd kf ne kj nf kn lc ld le lf bi translated">不同的尺度</li><li id="ecf4" class="kx ky it js b jt nb jx nc kb nd kf ne kj nf kn lc ld le lf bi translated">不同的纹理</li><li id="f051" class="kx ky it js b jt nb jx nc kb nd kf ne kj nf kn lc ld le lf bi translated">不同外壳</li></ul><figure class="kq kr ks kt gt ku gh gi paragraph-image"><div role="button" tabindex="0" class="lp lq di lr bf ls"><div class="gh gi ng"><img src="../Images/491b2bb5d36f29f2cd10f8b0718b35d5.png" data-original-src="https://miro.medium.com/v2/resize:fit:906/format:webp/1*nWLIQ2hY7yy5b--LcaBdaw.png"/></div></div><figcaption class="lh li gj gh gi lj lk bd b be z dk">Identifying different objection based on regions</figcaption></figure><p id="1a16" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">图(a)，勺子，碗都是不同比例的。图(b)，小猫是基于颜色而不是纹理来区分的。图(c ),变色龙可以通过纹理来区分，但不能通过颜色来区分。图(d)，车轮是汽车的一部分，但颜色或纹理不相似。它们是外壳的一部分。</p><p id="1ecd" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu"> <em class="ko">什么是选择性搜索，我们将如何使用它来识别图像中的多个对象？</em>T29】</strong></p><h2 id="720d" class="nh lx it bd ly ni nj dn mc nk nl dp mg kb nm nn mk kf no np mo kj nq nr ms ns bi translated">选择性搜索</h2><ul class=""><li id="5bf9" class="kx ky it js b jt mv jx mw kb nt kf nu kj nv kn lc ld le lf bi translated">使用自下而上的图像区域分组来生成从小到大的区域层次结构</li><li id="462f" class="kx ky it js b jt nb jx nc kb nd kf ne kj nf kn lc ld le lf bi translated">目标是生成一小组高质量的对象位置</li><li id="2860" class="kx ky it js b jt nb jx nc kb nd kf ne kj nf kn lc ld le lf bi translated">结合了细分和穷举搜索的最佳直觉。</li><li id="8aba" class="kx ky it js b jt nb jx nc kb nd kf ne kj nf kn lc ld le lf bi translated">图像分割利用图像的结构来生成对象位置</li><li id="614c" class="kx ky it js b jt nb jx nc kb nd kf ne kj nf kn lc ld le lf bi translated">穷举搜索旨在捕捉所有可能的对象位置</li></ul><h2 id="50a5" class="nh lx it bd ly ni nj dn mc nk nl dp mg kb nm nn mk kf no np mo kj nq nr ms ns bi translated"><strong class="ak">选择性搜索与穷举搜索逐步工作</strong></h2><p id="aee1" class="pw-post-body-paragraph jq jr it js b jt mv jv jw jx mw jz ka kb mx kd ke kf my kh ki kj mz kl km kn im bi translated">步骤 1: <strong class="js iu">生成初始子分割</strong>。我们生成尽可能多的区域，每个区域最多属于一个对象。</p><p id="dbd3" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">第二步:<strong class="js iu">递归地将相似的区域合并成更大的区域。</strong>这里我们使用贪婪算法。</p><ul class=""><li id="0488" class="kx ky it js b jt ju jx jy kb kz kf la kj lb kn lc ld le lf bi translated">从该组区域中，选择两个最相似的区域。</li><li id="08f9" class="kx ky it js b jt nb jx nc kb nd kf ne kj nf kn lc ld le lf bi translated">将它们合并成一个更大的区域。</li><li id="17d6" class="kx ky it js b jt nb jx nc kb nd kf ne kj nf kn lc ld le lf bi translated">重复直到只剩下一个区域。</li></ul><p id="709a" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">这就产生了一个依次增大的区域层次结构，正如我们所希望的那样</p><figure class="kq kr ks kt gt ku gh gi paragraph-image"><div role="button" tabindex="0" class="lp lq di lr bf ls"><div class="gh gi nw"><img src="../Images/6d3b84adbf9521195ba68b4cf8911e42.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Od54nnlU6YlrglUe_YNkUQ.png"/></div></div><figcaption class="lh li gj gh gi lj lk bd b be z dk">Selective search Algorithm to generate regions for object locations</figcaption></figure><p id="dc8a" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">步骤 3: <strong class="js iu">使用生成的区域产生候选对象位置</strong>。</p><p id="fda8" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">现在我们知道了选择性搜索是如何工作的，让我们进入 R-CNN 的细节</p><p id="b59e" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu"> R-CNN 将地区提案与 CNN 相结合。</strong></p><h2 id="a62b" class="nh lx it bd ly ni nj dn mc nk nl dp mg kb nm nn mk kf no np mo kj nq nr ms ns bi translated">什么是区域提案？</h2><p id="98d4" class="pw-post-body-paragraph jq jr it js b jt mv jv jw jx mw jz ka kb mx kd ke kf my kh ki kj mz kl km kn im bi translated">区域建议是检测器可用的候选检测的集合。CNN 在整个图像上运行滑动窗口，但是 R-CNN 只选择几个窗口。R-CNN 对一幅图像使用 2000 个区域。</p><p id="a8b4" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">区域建议运行一种称为分段算法的算法，该算法使用选择性搜索。</p><p id="9e33" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu"> <em class="ko">但是 R-CNN 中的物体检测是如何工作的呢？</em>T13】</strong></p><ol class=""><li id="489d" class="kx ky it js b jt ju jx jy kb kz kf la kj lb kn nx ld le lf bi translated"><strong class="js iu">使用选择性搜索提取大约 2000 个区域提案，生成独立于类别的区域提案。扭曲每一个提议。</strong></li><li id="c3f5" class="kx ky it js b jt nb jx nc kb nd kf ne kj nf kn nx ld le lf bi translated"><strong class="js iu">扭曲区域建议被馈送到大型卷积神经</strong> <strong class="js iu">网络。</strong> CNN 作为特征提取器，从每个区域提取固定长度的特征向量。在通过 CNN 之后，R-CNN 为每个区域提议提取 4096 维特征向量</li><li id="a506" class="kx ky it js b jt nb jx nc kb nd kf ne kj nf kn nx ld le lf bi translated"><strong class="js iu">将 SVM(支持向量机)应用于从 CNN 提取的特征。SVM 有助于对该区域中物体的存在进行分类。回归变量用于预测包围盒的四个值</strong></li></ol><p id="d1fe" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu">对图像中的所有得分区域应用贪婪非最大抑制</strong>。</p><p id="8900" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">如果一个区域的交集(IoU)与大于学习阈值的较高得分选定区域重叠，则非最大抑制会拒绝该区域。</p><figure class="kq kr ks kt gt ku gh gi paragraph-image"><div role="button" tabindex="0" class="lp lq di lr bf ls"><div class="gh gi ny"><img src="../Images/fe12d141bca49bcacb66daa7b3e75abf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*WJ2ZSMSHWKDrHHAVXvQ4tg.png"/></div></div></figure><h2 id="7f40" class="nh lx it bd ly ni nj dn mc nk nl dp mg kb nm nn mk kf no np mo kj nq nr ms ns bi translated"><strong class="ak"> <em class="mu">什么是贪婪非 Max 压制，我们为什么要用它？</em> </strong></h2><p id="3681" class="pw-post-body-paragraph jq jr it js b jt mv jv jw jx mw jz ka kb mx kd ke kf my kh ki kj mz kl km kn im bi translated">我们的目标是用一个包围盒检测一个物体一次。但是，使用对象检测，我们可能会发现对相同对象的多次检测。<strong class="js iu">非最大抑制确保只检测一次物体</strong></p><p id="2c50" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">要了解非最大抑制，我们需要了解 IoU。</p><h2 id="d4a8" class="nh lx it bd ly ni nj dn mc nk nl dp mg kb nm nn mk kf no np mo kj nq nr ms ns bi translated">并集上的交集— IoU</h2><p id="e0e6" class="pw-post-body-paragraph jq jr it js b jt mv jv jw jx mw jz ka kb mx kd ke kf my kh ki kj mz kl km kn im bi translated">IoU 通过算法计算两个边界框的并集上的交集，即地面真实的边界框和预测框的边界框</p><figure class="kq kr ks kt gt ku gh gi paragraph-image"><div class="gh gi nz"><img src="../Images/ceaf1f291131d42c69e2a4034e987b72.png" data-original-src="https://miro.medium.com/v2/resize:fit:1132/format:webp/1*i6x_DA6nUA-q9ZoECfOp9A.png"/></div></figure><figure class="kq kr ks kt gt ku gh gi paragraph-image"><div class="gh gi oa"><img src="../Images/139488ad4d680518c9a8a2ce37410399.png" data-original-src="https://miro.medium.com/v2/resize:fit:1318/format:webp/1*wYsyMHYGUgdKoFkp8D4uVA.png"/></div></figure><p id="c26a" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">当 IoU 为 1 时，这意味着预测的和真实的边界框完全重叠。</p><p id="c940" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">为了在图像中检测一次对象，<strong class="js iu">非最大抑制会考虑 IoU &gt;为 0.5 </strong>的所有边界框</p><p id="d9d0" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu"> <em class="ko">如果我有多个 IoU 大于 0.5 的包围盒怎么办？</em> </strong></p><h2 id="a258" class="nh lx it bd ly ni nj dn mc nk nl dp mg kb nm nn mk kf no np mo kj nq nr ms ns bi translated">非最大抑制</h2><ul class=""><li id="6129" class="kx ky it js b jt mv jx mw kb nt kf nu kj nv kn lc ld le lf bi translated">非最大抑制将移除 IoU 小于或等于 0.5 的所有边界框</li><li id="4ba3" class="kx ky it js b jt nb jx nc kb nd kf ne kj nf kn lc ld le lf bi translated">选取 IoU 值最高的边界框，并抑制其他边界框以识别同一对象</li></ul><p id="6b25" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">例如，如果我们有三个分别为 0.6、0.7 和 0.9 的矩形。为了让 IoU 识别下图中的车辆，非最大抑制将保留 IoU 为 0.9 的边界框，并将抑制剩余的 IoU 为 0.6 和 0.7 的边界框。</p><p id="b94f" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">对于下图中的汽车，非最大抑制将保持 IoU 为 0.8，抑制或移除 IoU 边界框为 0.7</p><figure class="kq kr ks kt gt ku gh gi paragraph-image"><div class="gh gi ob"><img src="../Images/b23b503f411291863a2f09f8bddd93fc.png" data-original-src="https://miro.medium.com/v2/resize:fit:754/format:webp/1*B3VLNr77E6XiWiOJZD1fWw.png"/></div></figure><blockquote class="oc"><p id="25cc" class="od oe it bd of og oh oi oj ok ol kn dk translated">R-CNN 面临的最大挑战是<strong class="ak">培训缓慢且昂贵</strong></p></blockquote><h2 id="d0c5" class="nh lx it bd ly ni om dn mc nk on dp mg kb oo nn mk kf op np mo kj oq nr ms ns bi translated">R-CNN 的体系结构</h2><figure class="kq kr ks kt gt ku gh gi paragraph-image"><div role="button" tabindex="0" class="lp lq di lr bf ls"><div class="gh gi or"><img src="../Images/9bca6234d331f0d77d97a180edc7c93d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*qH7-znEbjWw9B-s36QFbkw.png"/></div></div></figure><p id="48b9" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu"> <em class="ko">是什么让 R-CNN 的训练又慢又贵？</em>T13】</strong></p><ul class=""><li id="35ab" class="kx ky it js b jt ju jx jy kb kz kf la kj lb kn lc ld le lf bi translated">我们基于选择性搜索为每幅图像提取 2000 个区域。</li><li id="e13f" class="kx ky it js b jt nb jx nc kb nd kf ne kj nf kn lc ld le lf bi translated">使用 CNN 提取每个图像区域的特征。对于 N 个图像，我们将有 N*2000 个 CNN 特征。</li><li id="f7c2" class="kx ky it js b jt nb jx nc kb nd kf ne kj nf kn lc ld le lf bi translated">R-CNN 的对象检测使用三种模型:</li></ul><blockquote class="os ot ou"><p id="e990" class="jq jr ko js b jt ju jv jw jx jy jz ka ov kc kd ke ow kg kh ki ox kk kl km kn im bi translated">CNN 用于特征提取</p><p id="ffe5" class="jq jr ko js b jt ju jv jw jx jy jz ka ov kc kd ke ow kg kh ki ox kk kl km kn im bi translated">用于识别物体的线性 SVM 分类器</p><p id="9bcf" class="jq jr ko js b jt ju jv jw jx jy jz ka ov kc kd ke ow kg kh ki ox kk kl km kn im bi translated">收紧边界框的回归模型</p></blockquote><p id="9939" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu"> <em class="ko">那么我们如何让算法更加高效快速呢？</em> </strong></p><p id="e1a5" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">R-CNN 需要改进的地方很少</p><ul class=""><li id="1ea7" class="kx ky it js b jt ju jx jy kb kz kf la kj lb kn lc ld le lf bi translated"><strong class="js iu">使用一个 ConvNet 处理图像一次，而不是对图像的每个区域使用 2000 个 con vnet</strong>。</li><li id="4843" class="kx ky it js b jt nb jx nc kb nd kf ne kj nf kn lc ld le lf bi translated"><strong class="js iu">使用单一模型提取特征、分类和生成边界框，不像 R-CNN 使用三种不同的模型</strong></li></ul><p id="6905" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">这一切都是在快速 R-CNN 中完成的。</p><h1 id="c4ca" class="lw lx it bd ly lz ma mb mc md me mf mg mh mi mj mk ml mm mn mo mp mq mr ms mt bi translated">快速 R-CNN</h1><p id="f6e3" class="pw-post-body-paragraph jq jr it js b jt mv jv jw jx mw jz ka kb mx kd ke kf my kh ki kj mz kl km kn im bi translated"><strong class="js iu">快速 R-CNN 是一个快速框架，用于对象分类和具有深度网络的对象检测</strong></p><h2 id="9d61" class="nh lx it bd ly ni nj dn mc nk nl dp mg kb nm nn mk kf no np mo kj nq nr ms ns bi translated">快速 R-CNN 的结构和工作原理</h2><figure class="kq kr ks kt gt ku gh gi paragraph-image"><div role="button" tabindex="0" class="lp lq di lr bf ls"><div class="gh gi oy"><img src="../Images/a4db21caca62cc3124709fdbbcd4d039.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*B5NzTB8eKrulfLjrRsyvmQ.png"/></div></div></figure><p id="c2c8" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">快速 R-CNN 网络将图像和一组对象提议作为输入。</p><p id="5958" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">与 R-CNN 不同，<strong class="js iu">快速 R-CNN 使用单个深度 ConvNet 一次提取整个图像的特征。</strong></p><p id="fb01" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">我们还使用选择性搜索为图像创建一组<strong class="js iu"> ROI(感兴趣区域)</strong>。<strong class="js iu">感兴趣区域(RoI)层从特征图中提取一个固定长度的特征向量，用于对象检测</strong>。RoI 图层是只有一个金字塔等级的空间金字塔池图层的特例</p><p id="1c3b" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu">全连接层(FC)需要固定大小的输入。因此，我们使用 ROI Pooling 层将用于对象检测的特征图的补丁扭曲到固定大小</strong>。</p><p id="a7fb" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu"> ROI pooling </strong>层然后被送入 FC 进行<strong class="js iu">分类</strong>以及<strong class="js iu">定位。</strong> RoI 池层使用最大池。它将任何感兴趣的有效区域内的要素转换成一个小的要素地图。</p><p id="32df" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu">全连接层分支成两个同级输出层</strong></p><ul class=""><li id="eae6" class="kx ky it js b jt ju jx jy kb kz kf la kj lb kn lc ld le lf bi translated">一个具有对 K 个对象类的 softmax 概率估计，加上一个包罗万象的“背景”类</li><li id="bd4a" class="kx ky it js b jt nb jx nc kb nd kf ne kj nf kn lc ld le lf bi translated">另一层带有一个<strong class="js iu">回归器，为 K 个对象类</strong>中的每一个输出精确边界框位置的四个实数值。</li></ul><h2 id="6e5b" class="nh lx it bd ly ni nj dn mc nk nl dp mg kb nm nn mk kf no np mo kj nq nr ms ns bi translated">R-CNN 和快速 R-CNN 的主要区别</h2><ul class=""><li id="9e98" class="kx ky it js b jt mv jx mw kb nt kf nu kj nv kn lc ld le lf bi translated"><strong class="js iu">快速 R-CNN 使用单一深度 ConvNet 进行特征提取。</strong>与 R-CNN 对图像的每个区域使用 2000 个 ConvNet 不同，单个深度 conv net 大大加快了图像处理的速度。</li><li id="5b8b" class="kx ky it js b jt nb jx nc kb nd kf ne kj nf kn lc ld le lf bi translated"><strong class="js iu">快速 R-CNN 使用 softmax 进行对象分类，而不是 R-CNN </strong>中使用的 SVM。在异议分类方面，Softmax 略胜 SVM</li><li id="dfd8" class="kx ky it js b jt nb jx nc kb nd kf ne kj nf kn lc ld le lf bi translated"><strong class="js iu">快速 R-CNN 使用多任务丢失实现深度神经网络的端到端训练，提高了检测精度。</strong></li></ul><figure class="kq kr ks kt gt ku gh gi paragraph-image"><div role="button" tabindex="0" class="lp lq di lr bf ls"><div class="gh gi oz"><img src="../Images/f8dc5262fc7fb289d79092ae6d1e752d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Rg-_WjjiH4GP57SYhhhFiw.png"/></div></div></figure><blockquote class="oc"><p id="2ec7" class="od oe it bd of og oh oi oj ok ol kn dk translated">快速 R-CNN 使用选择性搜索作为发现感兴趣区域的建议方法，这是一个缓慢且耗时的过程。不适合大型真实数据集</p></blockquote><h1 id="ac58" class="lw lx it bd ly lz ma mb mc md me mf mg mh pa mj mk ml pb mn mo mp pc mr ms mt bi translated">更快的 R-CNN</h1><p id="bf6b" class="pw-post-body-paragraph jq jr it js b jt mv jv jw jx mw jz ka kb mx kd ke kf my kh ki kj mz kl km kn im bi translated">更快的 R-CNN 不使用昂贵的选择性搜索而是使用区域建议网络。</p><p id="a8ee" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">这是一个单一、统一的目标检测网络</p><p id="d180" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu">更快的 R-CNN 由两个阶段组成</strong></p><ul class=""><li id="b7e6" class="kx ky it js b jt ju jx jy kb kz kf la kj lb kn lc ld le lf bi translated"><strong class="js iu">第一阶段是提议区域的深度全卷积网络，称为区域提议网络(RPN)。RPN 模块作为统一网络的关注点</strong></li><li id="233b" class="kx ky it js b jt nb jx nc kb nd kf ne kj nf kn lc ld le lf bi translated"><strong class="js iu">第二阶段是快速 R-CNN 检测器，使用 RoIPool 从每个候选框中提取特征，并执行分类和包围盒回归</strong></li></ul><figure class="kq kr ks kt gt ku gh gi paragraph-image"><div role="button" tabindex="0" class="lp lq di lr bf ls"><div class="gh gi pd"><img src="../Images/d2687bbf85dbaff004fa356a13e2a478.png" data-original-src="https://miro.medium.com/v2/resize:fit:1068/format:webp/1*F72K8wjiIXux7deAUrha-g.png"/></div></div><figcaption class="lh li gj gh gi lj lk bd b be z dk">Faster R-CNN</figcaption></figure><h2 id="ef8e" class="nh lx it bd ly ni nj dn mc nk nl dp mg kb nm nn mk kf no np mo kj nq nr ms ns bi translated">区域提案网络</h2><p id="6603" class="pw-post-body-paragraph jq jr it js b jt mv jv jw jx mw jz ka kb mx kd ke kf my kh ki kj mz kl km kn im bi translated">区域提议网络将任意大小的图像作为输入，并输出一组矩形对象提议，每个提议都有一个客观分数。这是通过在卷积层生成的特征图上滑动一个小网络来实现的</p><p id="5a4f" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">RPN 与快速 R-CNN 对象检测网络共享计算。</p><p id="72f1" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">从 RPN 生成的要素被提供给两个完全连接的同级图层-用于边界框的框回归图层和用于对象分类的框分类图层。</p><p id="d44c" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">RPN 是高效的，每幅图像处理 10 ms 以生成 ROI。</p><figure class="kq kr ks kt gt ku gh gi paragraph-image"><div class="gh gi pe"><img src="../Images/d9e6c460ef2672128fe8415d43f7cc68.png" data-original-src="https://miro.medium.com/v2/resize:fit:1108/format:webp/1*cBiml1WjBV0VnkZuEZaoog.png"/></div><figcaption class="lh li gj gh gi lj lk bd b be z dk">Region Proposal Network</figcaption></figure><h2 id="32e0" class="nh lx it bd ly ni nj dn mc nk nl dp mg kb nm nn mk kf no np mo kj nq nr ms ns bi translated">锚</h2><p id="e5e1" class="pw-post-body-paragraph jq jr it js b jt mv jv jw jx mw jz ka kb mx kd ke kf my kh ki kj mz kl km kn im bi translated">锚点位于所讨论的滑动窗口的中心，并与比例和纵横比相关联。更快的 R-CNN 使用 3 个比例和 3 个纵横比，在每个滑动窗口产生 9 个锚。</p><p id="0cca" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">锚点有助于平移不变性。</p><p id="9645" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">在每个滑动窗口位置，我们同时预测多个区域建议。每个位置的最大可能建议数表示为 k</p><p id="06d8" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">Reg 层有 4k 个输出，对 k 个框的坐标进行编码，cls 层输出 2k 个分数，估计每个提议的反对或不反对的概率</p><h2 id="ec65" class="nh lx it bd ly ni nj dn mc nk nl dp mg kb nm nn mk kf no np mo kj nq nr ms ns bi translated">快速 R-CNN 的结构和工作原理</h2><figure class="kq kr ks kt gt ku gh gi paragraph-image"><div role="button" tabindex="0" class="lp lq di lr bf ls"><div class="gh gi pf"><img src="../Images/1f81339eb4da63efee8af2f9fdbf5792.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*4jKv5oDaEWWtrsYcPhiv1Q.png"/></div></div></figure><p id="00ca" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">快速 R-CNN 由 3 个不同的神经网络组成</p><ol class=""><li id="6b9b" class="kx ky it js b jt ju jx jy kb kz kf la kj lb kn nx ld le lf bi translated">使用深度卷积层从输入图像生成特征地图的特征网络</li><li id="9148" class="kx ky it js b jt nb jx nc kb nd kf ne kj nf kn nx ld le lf bi translated">区域提议网络(RPN)用于识别不同的区域，其对于每个滑动窗口使用 9 个锚。这有助于平移不变性。RPN 生成许多被称为感兴趣区域(ROI)的边界框，这些边界框对于对象的存在具有高概率</li><li id="0d1d" class="kx ky it js b jt nb jx nc kb nd kf ne kj nf kn nx ld le lf bi translated">检测网络是 R-CNN，它以来自卷积层和 RPN 网络的输入作为特征映射。这将生成对象的边界框和类</li></ol><p id="b2f6" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">更快的 R-CNN 以图像作为输入，通过特征网络生成特征图。</p><p id="076e" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">RPN 使用来自特征网络的特征地图作为输入来生成对象提议的矩形框和对象性分数。</p><p id="ecaa" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">来自 RPN 的预测区域提议随后使用 RoI 池层进行整形。扭曲成固定的向量大小。</p><p id="d65e" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">然后，扭曲的固定大小向量被馈送到两个完全连接的兄弟层，一个回归层用于预测边界框的偏移值，一个分类层用于对象分类</p><h2 id="d989" class="nh lx it bd ly ni nj dn mc nk nl dp mg kb nm nn mk kf no np mo kj nq nr ms ns bi translated">使用更快的 R-CNN</h2><ul class=""><li id="2bbb" class="kx ky it js b jt mv jx mw kb nt kf nu kj nv kn lc ld le lf bi translated">三维物体检测</li><li id="2f08" class="kx ky it js b jt nb jx nc kb nd kf ne kj nf kn lc ld le lf bi translated">基于部件的检测</li><li id="dc67" class="kx ky it js b jt nb jx nc kb nd kf ne kj nf kn lc ld le lf bi translated">实例分割</li><li id="e163" class="kx ky it js b jt nb jx nc kb nd kf ne kj nf kn lc ld le lf bi translated">图像字幕</li></ul><h2 id="11a5" class="nh lx it bd ly ni nj dn mc nk nl dp mg kb nm nn mk kf no np mo kj nq nr ms ns bi translated">摘要</h2><p id="ee70" class="pw-post-body-paragraph jq jr it js b jt mv jv jw jx mw jz ka kb mx kd ke kf my kh ki kj mz kl km kn im bi translated">我们从一个简单的 CNN 开始，它用于图像分类和图像中单个物体的物体检测。</p><p id="1189" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">R-CNN 用于图像分类以及图像中多个对象的定位。</p><p id="42c0" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">R-CNN 又慢又贵，所以快速 R-CNN 被开发成一种更快更有效的算法。R-CNN 和 Fast R-CNN 都使用选择性搜索来搜索图像中的区域。</p><p id="d9f0" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">快速 R-CNN 将 RPN(区域建议网络)与快速 R-CNN 一起用于多图像分类、检测和分割。</p><p id="5b03" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">在下一篇文章中，我们将探索 YOLO 和面具 R-CNN。</p><p id="242e" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu">参考文献:</strong></p><p id="aa98" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><a class="ae lt" href="http://vision.stanford.edu/teaching/cs231b_spring1415/slides/ssearch_schuyler.pdf" rel="noopener ugc nofollow" target="_blank">http://vision . Stanford . edu/teaching/cs 231 b _ spring 1415/slides/ssearch _ schuyler . pdf</a></p><p id="41c0" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">【https://arxiv.org/pdf/1406.4729.pdf T4】</p><p id="257d" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><a class="ae lt" href="https://arxiv.org/pdf/1506.01497.pdf" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/pdf/1506.01497.pdf</a></p><p id="6e2f" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">【https://arxiv.org/pdf/1311.2524.pdf T2】号</p><p id="ddfe" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><a class="ae lt" href="http://www.cs.toronto.edu/~tingwuwang/semantic_segmentation.pdf" rel="noopener ugc nofollow" target="_blank">http://www . cs . Toronto . edu/~ ting Wu Wang/semantic _ segmentation . pdf</a></p><p id="11da" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><a class="ae lt" href="http://www.cs.toronto.edu/~tingwuwang/semantic_segmentation.pdf" rel="noopener ugc nofollow" target="_blank">http://www . cs . Toronto . edu/~ ting Wu Wang/semantic _ segmentation . pdf</a></p><p id="b085" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><a class="ae lt" href="https://ivi.fnwi.uva.nl/isis/publications/2013/UijlingsIJCV2013/UijlingsIJCV2013.pdf" rel="noopener ugc nofollow" target="_blank">https://IVI . fnwi . UVA . nl/ISIS/publications/2013/uijlingsijcv 2013/uijlingsijcv 2013 . pdf</a></p><p id="e906" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><a class="ae lt" href="http://www.robots.ox.ac.uk/~tvg/publications/talks/fast-rcnn-slides.pdf" rel="noopener ugc nofollow" target="_blank">http://www . robots . ox . AC . uk/~ tvg/publications/talks/fast-rcnn-slides . pdf</a></p></div></div>    
</body>
</html>