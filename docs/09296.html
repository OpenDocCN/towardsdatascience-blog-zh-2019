<html>
<head>
<title>The Complete Hands-On Machine Learning Crash Course</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">完整的动手机器学习速成班</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/the-complete-hands-on-machine-learning-crash-course-59e43c8cee52?source=collection_archive---------7-----------------------#2019-12-09">https://towardsdatascience.com/the-complete-hands-on-machine-learning-crash-course-59e43c8cee52?source=collection_archive---------7-----------------------#2019-12-09</a></blockquote><div><div class="fc ij ik il im in"/><div class="io ip iq ir is"><div class=""/><div class=""><h2 id="514a" class="pw-subtitle-paragraph js iu iv bd b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj dk translated">从线性回归到无监督学习，本指南涵盖了你开始学习机器所需要知道的一切。每个主题都包括理论和实践练习！</h2></div><figure class="kl km kn ko gt kp gh gi paragraph-image"><div class="gh gi kk"><img src="../Images/18ff71837669f38fda3210cb9bc2518b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*rQOlOjXwSfsm5P_WJ1kQog.jpeg"/></div></figure><h1 id="5336" class="ks kt iv bd ku kv kw kx ky kz la lb lc kb ld kc le ke lf kf lg kh lh ki li lj bi translated">目录</h1><ol class=""><li id="4ae3" class="lk ll iv lm b ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb bi translated"><a class="ae mc" rel="noopener" target="_blank" href="/the-complete-hands-on-machine-learning-crash-course-59e43c8cee52#b035">线性回归—理论</a></li><li id="613c" class="lk ll iv lm b ln md lp me lr mf lt mg lv mh lx ly lz ma mb bi translated"><a class="ae mc" href="#429c" rel="noopener ugc nofollow">线性回归—练习</a></li><li id="d16b" class="lk ll iv lm b ln md lp me lr mf lt mg lv mh lx ly lz ma mb bi translated"><a class="ae mc" href="#b95e" rel="noopener ugc nofollow">逻辑回归—理论</a></li><li id="9b44" class="lk ll iv lm b ln md lp me lr mf lt mg lv mh lx ly lz ma mb bi translated"><a class="ae mc" href="#a78c" rel="noopener ugc nofollow">线性判别分析(LDA) —理论</a></li><li id="5427" class="lk ll iv lm b ln md lp me lr mf lt mg lv mh lx ly lz ma mb bi translated"><a class="ae mc" href="#7fe0" rel="noopener ugc nofollow">二次判别分析(QDA)—理论</a></li><li id="65af" class="lk ll iv lm b ln md lp me lr mf lt mg lv mh lx ly lz ma mb bi translated"><a class="ae mc" href="#ef44" rel="noopener ugc nofollow">逻辑回归、LDA 和 QDA —实践</a></li><li id="5986" class="lk ll iv lm b ln md lp me lr mf lt mg lv mh lx ly lz ma mb bi translated"><a class="ae mc" href="#f87f" rel="noopener ugc nofollow">重采样—理论</a></li><li id="faff" class="lk ll iv lm b ln md lp me lr mf lt mg lv mh lx ly lz ma mb bi translated"><a class="ae mc" href="#ed7b" rel="noopener ugc nofollow">正则化理论</a></li><li id="dbe2" class="lk ll iv lm b ln md lp me lr mf lt mg lv mh lx ly lz ma mb bi translated"><a class="ae mc" href="#43b4" rel="noopener ugc nofollow">重采样和正则化—练习</a></li><li id="7d0f" class="lk ll iv lm b ln md lp me lr mf lt mg lv mh lx ly lz ma mb bi translated"><a class="ae mc" href="#4ab3" rel="noopener ugc nofollow">决策树—理论</a></li><li id="87ac" class="lk ll iv lm b ln md lp me lr mf lt mg lv mh lx ly lz ma mb bi translated"><a class="ae mc" href="#d1e8" rel="noopener ugc nofollow">决策树—实践</a></li><li id="b73c" class="lk ll iv lm b ln md lp me lr mf lt mg lv mh lx ly lz ma mb bi translated"><a class="ae mc" href="#270d" rel="noopener ugc nofollow">支持向量机(SVM)—理论</a></li><li id="21bd" class="lk ll iv lm b ln md lp me lr mf lt mg lv mh lx ly lz ma mb bi translated"><a class="ae mc" href="#d4e4" rel="noopener ugc nofollow">支持向量机(SVM) —实践</a></li><li id="c52f" class="lk ll iv lm b ln md lp me lr mf lt mg lv mh lx ly lz ma mb bi translated"><a class="ae mc" href="#3f0c" rel="noopener ugc nofollow">无监督学习——理论</a></li><li id="8ca2" class="lk ll iv lm b ln md lp me lr mf lt mg lv mh lx ly lz ma mb bi translated"><a class="ae mc" href="#0cc5" rel="noopener ugc nofollow">无监督学习—实践</a></li><li id="2f97" class="lk ll iv lm b ln md lp me lr mf lt mg lv mh lx ly lz ma mb bi translated"><a class="ae mc" href="#7acb" rel="noopener ugc nofollow">时间序列分析—理论</a></li><li id="b6d5" class="lk ll iv lm b ln md lp me lr mf lt mg lv mh lx ly lz ma mb bi translated"><a class="ae mc" href="#dab5" rel="noopener ugc nofollow">时间序列分析—练习</a></li><li id="6f25" class="lk ll iv lm b ln md lp me lr mf lt mg lv mh lx ly lz ma mb bi translated"><a class="ae mc" href="#cefd" rel="noopener ugc nofollow">来源</a></li></ol><blockquote class="mi"><p id="8090" class="mj mk iv bd ml mm mn mo mp mq mr lx dk translated">关于机器学习、深度学习和人工智能的实践视频教程，请查看我的<a class="ae mc" href="https://www.youtube.com/channel/UC-0lpiwlftqwC7znCcF83qg?view_as=subscriber" rel="noopener ugc nofollow" target="_blank"> YouTube 频道</a>。</p></blockquote><h1 id="b035" class="ks kt iv bd ku kv kw kx ky kz la lb lc kb ms kc le ke mt kf lg kh mu ki li lj bi translated">线性回归理论</h1><p id="4a83" class="pw-post-body-paragraph mv mw iv lm b ln lo jw mx lp lq jz my lr mz na nb lt nc nd ne lv nf ng nh lx io bi translated">线性回归可能是统计学习最简单的方法。对于更高级的方法来说，这是一个很好的起点，事实上，许多新奇的统计学习技术可以被视为线性回归的扩展。因此，在进入更复杂的方法之前，理解这个简单的模型将建立一个良好的基础。</p><p id="3f17" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">线性回归很好地回答了以下问题:</p><ul class=""><li id="0ee1" class="lk ll iv lm b ln ni lp nj lr nn lt no lv np lx nq lz ma mb bi translated">两个变量之间有关系吗？</li><li id="22c8" class="lk ll iv lm b ln md lp me lr mf lt mg lv mh lx nq lz ma mb bi translated">关系有多牢固？</li><li id="44d1" class="lk ll iv lm b ln md lp me lr mf lt mg lv mh lx nq lz ma mb bi translated">哪个变量的贡献最大？</li><li id="4c21" class="lk ll iv lm b ln md lp me lr mf lt mg lv mh lx nq lz ma mb bi translated">我们能多精确地估计每个变量的影响？</li><li id="f33f" class="lk ll iv lm b ln md lp me lr mf lt mg lv mh lx nq lz ma mb bi translated">我们能多精确地预测目标？</li><li id="459d" class="lk ll iv lm b ln md lp me lr mf lt mg lv mh lx nq lz ma mb bi translated">关系是线性的吗？(咄)</li><li id="70af" class="lk ll iv lm b ln md lp me lr mf lt mg lv mh lx nq lz ma mb bi translated">有交互作用吗？</li></ul><h2 id="1a28" class="nr kt iv bd ku ns nt dn ky nu nv dp lc lr nw nx le lt ny nz lg lv oa ob li oc bi translated">估计系数</h2><p id="c880" class="pw-post-body-paragraph mv mw iv lm b ln lo jw mx lp lq jz my lr mz na nb lt nc nd ne lv nf ng nh lx io bi translated">假设我们只有一个变量和一个目标。然后，线性回归表示为:</p><figure class="kl km kn ko gt kp gh gi paragraph-image"><div role="button" tabindex="0" class="oe of di og bf oh"><div class="gh gi od"><img src="../Images/916269ef445f81ce2cafbe42b8d3bc95.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*6ShYjDy-LBv3wQ26sZF8sQ.png"/></div></div><figcaption class="oi oj gj gh gi ok ol bd b be z dk">Equation for a linear model with 1 variable and 1 target</figcaption></figure><p id="a5a2" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">在上式中，<em class="om">β</em>是系数。这些系数是我们用模型进行预测所需要的。</p><p id="edfc" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">那么我们如何找到这些参数呢？</p><p id="29fc" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">为了找到参数，我们需要最小化<strong class="lm iw">最小平方</strong>或<strong class="lm iw">误差平方和</strong>。当然，线性模型并不完美，它不会准确预测所有数据，这意味着实际值和预测值之间存在差异。误差很容易通过下式计算:</p><figure class="kl km kn ko gt kp gh gi paragraph-image"><div class="gh gi on"><img src="../Images/9050767b66daef9531a1d8f9298d54c3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1322/format:webp/1*hYt2F9dXepXYwqE0koXX_A.png"/></div><figcaption class="oi oj gj gh gi ok ol bd b be z dk">Subtract the prediction from the true value</figcaption></figure><p id="083c" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">但是为什么误差是平方的呢？</p><p id="80e8" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">我们平方误差，因为预测可以高于或低于真实值，分别导致负的或正的差异。如果我们不对误差进行平方，误差的总和可能会因为负差异而减少，而不是因为模型非常适合。</p><p id="676b" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">此外，平方误差不利于较大的差异，因此最小化平方误差“保证”更好的模型。</p><p id="d0e2" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">让我们来看一个图表，以便更好地理解。</p><figure class="kl km kn ko gt kp gh gi paragraph-image"><div role="button" tabindex="0" class="oe of di og bf oh"><div class="gh gi oo"><img src="../Images/eb35aad427279c1c787653cad8de43fd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ZC9jOzQPCsio3xqtK4aM2Q.png"/></div></div><figcaption class="oi oj gj gh gi ok ol bd b be z dk">Linear fit to a data set</figcaption></figure><p id="ac85" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">在上图中，红点是真实数据，蓝线是线性模型。灰色线条表示预测值和真实值之间的误差。因此，蓝线是使灰线的平方长度之和最小的线。</p><p id="8474" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">经过一些对本文来说过于繁琐的数学计算后，您最终可以用下面的等式来估计系数:</p><figure class="kl km kn ko gt kp gh gi paragraph-image"><div class="gh gi op"><img src="../Images/52f035125856f44b3d24e519760587c9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1116/format:webp/1*oVnFCTLwxmlOGCtjMNYQqQ.png"/></div></figure><figure class="kl km kn ko gt kp gh gi paragraph-image"><div class="gh gi oq"><img src="../Images/7f2ce1c70fad9dfd4cca748674c8f471.png" data-original-src="https://miro.medium.com/v2/resize:fit:616/format:webp/1*n48CcucPaBBIzza1ZFVQHw.png"/></div></figure><p id="d29a" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">其中<em class="om"> x 条</em>和<em class="om"> y 条</em>代表平均值。</p><h2 id="ef69" class="nr kt iv bd ku ns nt dn ky nu nv dp lc lr nw nx le lt ny nz lg lv oa ob li oc bi translated">估计系数的相关性</h2><p id="e0c9" class="pw-post-body-paragraph mv mw iv lm b ln lo jw mx lp lq jz my lr mz na nb lt nc nd ne lv nf ng nh lx io bi translated">现在你有了系数，你如何知道它们是否与预测你的目标相关？</p><p id="054b" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">最好的方法是找到<em class="om"> p 值。</em><em class="om">p 值</em>用于量化统计显著性；它允许判断是否要拒绝零假设。</p><p id="7d48" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">无效假设？</p><p id="e07a" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">对于任何建模任务，假设在特征和目标之间存在某种相关性。因此，零假设是相反的:<strong class="lm iw">在特征和目标之间没有相关性</strong>。</p><p id="b895" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">因此，找到每个系数的<em class="om"> p 值</em>将会知道该变量对于预测目标是否具有统计显著性。根据一般经验，如果<em class="om"> p 值</em>小于<strong class="lm iw">0.05</strong>:变量和目标之间有很强的关系。</p><h2 id="50ea" class="nr kt iv bd ku ns nt dn ky nu nv dp lc lr nw nx le lt ny nz lg lv oa ob li oc bi translated">评估模型的准确性</h2><p id="aa77" class="pw-post-body-paragraph mv mw iv lm b ln lo jw mx lp lq jz my lr mz na nb lt nc nd ne lv nf ng nh lx io bi translated">通过找到变量的<em class="om"> p 值</em>，您发现您的变量具有统计显著性。太好了！</p><p id="bddb" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">现在，你怎么知道你的线性模型是好的呢？</p><p id="df68" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">为了进行评估，我们通常使用 RSE(剩余标准误差)和 R 统计量。</p><figure class="kl km kn ko gt kp gh gi paragraph-image"><div role="button" tabindex="0" class="oe of di og bf oh"><div class="gh gi or"><img src="../Images/efee456589bdf52a726a41b5a877e684.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*F9g6XenPJN2AffG8yIzq8Q.png"/></div></div><figcaption class="oi oj gj gh gi ok ol bd b be z dk">RSE formula</figcaption></figure><figure class="kl km kn ko gt kp gh gi paragraph-image"><div role="button" tabindex="0" class="oe of di og bf oh"><div class="gh gi os"><img src="../Images/118de819cd726b763b447c9ce1830928.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*nJ2zMf6Qxb3XfWa6n2Heag.png"/></div></div><figcaption class="oi oj gj gh gi ok ol bd b be z dk">R² formula</figcaption></figure><p id="257f" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">第一个误差指标很容易理解:残差越低，模型就越符合数据(在这种情况下，数据越接近线性关系)。</p><p id="8ed6" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">至于 R 度量，它测量目标中可以用特征 X 解释的<strong class="lm iw">可变性比例。所以假设线性关系，如果特征 X 能解释(预测)目标，那么比例高，R 值会接近 1。如果相反，R 值则更接近于 0。</strong></p><h2 id="1e73" class="nr kt iv bd ku ns nt dn ky nu nv dp lc lr nw nx le lt ny nz lg lv oa ob li oc bi translated">多元线性回归理论</h2><p id="74c5" class="pw-post-body-paragraph mv mw iv lm b ln lo jw mx lp lq jz my lr mz na nb lt nc nd ne lv nf ng nh lx io bi translated">在现实生活中，永远不会有单一的特征来预测目标。那么，我们一次对一个特征进行线性回归吗？当然不是。我们简单地执行多元线性回归。</p><p id="3387" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">该方程非常类似于简单的线性回归；简单地将预测值的数量和它们相应的系数相加:</p><figure class="kl km kn ko gt kp gh gi paragraph-image"><div class="gh gi ot"><img src="../Images/8cc0e780f0d5ab3c443c177b70e1a30f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1362/format:webp/1*CbYHku07Tjd50a50jttu2A.png"/></div><figcaption class="oi oj gj gh gi ok ol bd b be z dk">Multiple linear regression equation. <strong class="bd ou">p</strong> is the number of predictors</figcaption></figure><h2 id="6cf4" class="nr kt iv bd ku ns nt dn ky nu nv dp lc lr nw nx le lt ny nz lg lv oa ob li oc bi translated">评估预测值的相关性</h2><p id="af10" class="pw-post-body-paragraph mv mw iv lm b ln lo jw mx lp lq jz my lr mz na nb lt nc nd ne lv nf ng nh lx io bi translated">以前，在简单的线性回归中，我们通过寻找特征的<em class="om"> p 值</em>来评估特征的相关性。</p><p id="1103" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">在多元线性回归的情况下，我们使用另一个指标:F 统计量。</p><figure class="kl km kn ko gt kp gh gi paragraph-image"><div role="button" tabindex="0" class="oe of di og bf oh"><div class="gh gi ov"><img src="../Images/8305a7e95b0fbc3b4da6344f377012fb.png" data-original-src="https://miro.medium.com/v2/resize:fit:732/format:webp/1*W37Z8hscDevXdgvI3grGQw.png"/></div></div><figcaption class="oi oj gj gh gi ok ol bd b be z dk">F-statistic formula. <strong class="bd ou">n</strong> is the number of data points and <strong class="bd ou">p</strong> is the number of predictors</figcaption></figure><p id="754d" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">在这里，F 统计量是为整个模型计算的，而<em class="om"> p 值</em>是特定于每个预测值的。如果有强关系，那么 F 会远大于 1。否则，它将近似等于 1。</p><p id="a1a3" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">如何使<em class="om">大于</em> <em class="om">比 1 </em>足够大？</p><p id="e155" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">这个很难回答。通常，如果有大量的数据点，F 可能略大于 1，表明有很强的关系。对于小数据集，F 值必须远大于 1，以表明强相关关系。</p><p id="370f" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">为什么我们不能在这种情况下使用<em class="om"> p 值</em>？</p><p id="b83b" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">由于我们正在拟合许多预测值，因此我们需要考虑有许多特征的情况(<em class="om"> p </em>很大)。对于非常大量的预测值，总会有大约 5%的预测值偶然具有非常小的<em class="om"> p 值</em> <strong class="lm iw"> <em class="om">甚至</em> </strong> <em class="om"> </em> <strong class="lm iw"> <em class="om">，尽管它们在统计上不显著。因此，我们使用 F 统计量来避免将不重要的预测因子视为重要的预测因子。</em></strong></p><h2 id="0229" class="nr kt iv bd ku ns nt dn ky nu nv dp lc lr nw nx le lt ny nz lg lv oa ob li oc bi translated">评估模型的准确性</h2><p id="a286" class="pw-post-body-paragraph mv mw iv lm b ln lo jw mx lp lq jz my lr mz na nb lt nc nd ne lv nf ng nh lx io bi translated">就像简单的线性回归一样，R 可以用于多元线性回归。但是，要知道添加更多的预测值总是会增加 R 值，因为模型必然会更好地拟合训练数据。</p><p id="f7b5" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">然而，这并不意味着它将在测试数据上表现良好(对未知数据点进行预测)。</p><h2 id="41bb" class="nr kt iv bd ku ns nt dn ky nu nv dp lc lr nw nx le lt ny nz lg lv oa ob li oc bi translated">添加交互</h2><p id="e3cd" class="pw-post-body-paragraph mv mw iv lm b ln lo jw mx lp lq jz my lr mz na nb lt nc nd ne lv nf ng nh lx io bi translated">一个线性模型中有多个预测因子意味着一些预测因子可能会对其他预测因子产生影响。</p><p id="9e19" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">例如，你想预测一个人的工资，知道她的年龄和上学的年数。当然，一个人越老，他在学校度过的时间就越多。那么我们如何对这种互动效应建模呢？</p><p id="6de1" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">考虑这个非常简单的例子，有两个预测值:</p><figure class="kl km kn ko gt kp gh gi paragraph-image"><div role="button" tabindex="0" class="oe of di og bf oh"><div class="gh gi ow"><img src="../Images/249e1184ccd6965101fa0536ab9e8949.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*enACSDDH4l3sK2YrYJjgVA.png"/></div></div><figcaption class="oi oj gj gh gi ok ol bd b be z dk">Interaction effect in multiple linear regression</figcaption></figure><p id="c1df" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">如你所见，我们简单地将两个预测因子相乘，并关联一个新的系数。简化公式，我们现在看到系数受另一个特征的值的影响。</p><p id="4fa4" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">一般来说，如果我们包括交互模型，我们应该包括特征的个体效应，即使它的<em class="om"> p 值</em>不显著。这就是所谓的<strong class="lm iw">等级原则</strong>。这背后的基本原理是，如果两个预测者相互作用，那么包括他们各自的贡献将对模型产生很小的影响。</p><h1 id="429c" class="ks kt iv bd ku kv kw kx ky kz la lb lc kb ld kc le ke lf kf lg kh lh ki li lj bi translated">线性回归—实践</h1><p id="c04b" class="pw-post-body-paragraph mv mw iv lm b ln lo jw mx lp lq jz my lr mz na nb lt nc nd ne lv nf ng nh lx io bi translated">好吧！现在我们知道了它是如何工作的，让我们让它工作吧！我们将通过 Python 中的简单和多元线性回归来工作，我将展示如何在这两种情况下评估参数和整体模型的质量。</p><p id="43c5" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">你可以在这里获取代码和数据。</p><p id="0ffb" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">我强烈建议您在自己的 Jupyter 笔记本中遵循并重新创建这些步骤，以充分利用本教程。</p><p id="8ef9" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">数据集包含关于花费在广告上的钱及其产生的销售额的信息。钱花在了电视、广播和报纸广告上。</p><p id="da05" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated"><strong class="lm iw">目标是使用线性回归来了解广告支出如何影响销售。</strong></p><h2 id="96a9" class="nr kt iv bd ku ns nt dn ky nu nv dp lc lr nw nx le lt ny nz lg lv oa ob li oc bi translated">导入库</h2><p id="d77a" class="pw-post-body-paragraph mv mw iv lm b ln lo jw mx lp lq jz my lr mz na nb lt nc nd ne lv nf ng nh lx io bi translated">使用 Python 的优势在于，我们可以访问许多库，这些库允许我们快速读取数据、绘制数据并执行线性回归。</p><p id="1e2e" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">我喜欢在笔记本顶部导入所有必要的库，以保持一切井然有序。导入以下内容:</p><pre class="kl km kn ko gt ox oy oz pa aw pb bi"><span id="8206" class="nr kt iv oy b gy pc pd l pe pf">import pandas as pd<br/>import numpy as npimport matplotlib.pyplot as pltfrom sklearn.linear_model import LinearRegression<br/>from sklearn.metrics import r2_scoreimport statsmodels.api as sm</span></pre><h2 id="def0" class="nr kt iv bd ku ns nt dn ky nu nv dp lc lr nw nx le lt ny nz lg lv oa ob li oc bi translated">读取数据</h2><p id="7b8d" class="pw-post-body-paragraph mv mw iv lm b ln lo jw mx lp lq jz my lr mz na nb lt nc nd ne lv nf ng nh lx io bi translated">假设您下载了数据集，将它放在项目文件夹内的一个<code class="fe pg ph pi oy b">data</code>目录中。然后，像这样读取数据:</p><pre class="kl km kn ko gt ox oy oz pa aw pb bi"><span id="b780" class="nr kt iv oy b gy pc pd l pe pf">data = pd.read_csv("data/Advertising.csv")</span></pre><p id="de03" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">为了查看数据的样子，我们执行以下操作:</p><pre class="kl km kn ko gt ox oy oz pa aw pb bi"><span id="1551" class="nr kt iv oy b gy pc pd l pe pf">data.head()</span></pre><p id="2c78" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">你应该看看这个:</p><figure class="kl km kn ko gt kp gh gi paragraph-image"><div class="gh gi pj"><img src="../Images/c81885c3b0a05438e439c34a31c44914.png" data-original-src="https://miro.medium.com/v2/resize:fit:1326/format:webp/1*FNfhnv-r5ZzHd56XBTpp6A.png"/></div></figure><p id="327a" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">如您所见，列<code class="fe pg ph pi oy b">Unnamed: 0</code>是多余的。因此，我们删除它。</p><pre class="kl km kn ko gt ox oy oz pa aw pb bi"><span id="08be" class="nr kt iv oy b gy pc pd l pe pf">data.drop(['Unnamed: 0'], axis=1)</span></pre><p id="0b0e" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">好了，我们的数据是干净的，可以进行线性回归了！</p><h2 id="0d70" class="nr kt iv bd ku ns nt dn ky nu nv dp lc lr nw nx le lt ny nz lg lv oa ob li oc bi translated">简单线性回归</h2><p id="ec10" class="pw-post-body-paragraph mv mw iv lm b ln lo jw mx lp lq jz my lr mz na nb lt nc nd ne lv nf ng nh lx io bi translated">对于<strong class="lm iw">简单线性回归</strong>，我们只考虑电视广告对销售的影响。在开始建模之前，让我们看一下数据是什么样子的。</p><p id="dd87" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">我们使用<code class="fe pg ph pi oy b">matplotlib</code>，一个流行的 Python 绘图库来制作散点图。</p><pre class="kl km kn ko gt ox oy oz pa aw pb bi"><span id="f060" class="nr kt iv oy b gy pc pd l pe pf">plt.figure(figsize=(16, 8))<br/>plt.scatter(<br/>    data['TV'],<br/>    data['sales'],<br/>    c='black'<br/>)<br/>plt.xlabel("Money spent on TV ads ($)")<br/>plt.ylabel("Sales ($)")<br/>plt.show()</span></pre><p id="5c00" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">运行这个代码单元，您应该会看到这个图形:</p><figure class="kl km kn ko gt kp gh gi paragraph-image"><div role="button" tabindex="0" class="oe of di og bf oh"><div class="gh gi pk"><img src="../Images/b9e1a535082285acd85ec5098a9b6145.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*adZn_xDeZ9nGKy309G6laQ.png"/></div></div><figcaption class="oi oj gj gh gi ok ol bd b be z dk">Scatter plot of money spent on TV ads and sales</figcaption></figure><p id="7e3d" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">正如你所看到的，在电视广告上的花费和销售额之间有着明显的关系。</p><p id="c1fe" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">让我们看看如何生成该数据的线性近似值。</p><pre class="kl km kn ko gt ox oy oz pa aw pb bi"><span id="d8f7" class="nr kt iv oy b gy pc pd l pe pf">X = data['TV'].values.reshape(-1,1)<br/>y = data['sales'].values.reshape(-1,1)reg = LinearRegression()<br/>reg.fit(X, y)print("The linear model is: Y = {:.5} + {:.5}X".format(reg.intercept_[0], reg.coef_[0][0]))</span></pre><p id="c77c" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">就这样？</p><p id="2106" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">是啊！对数据集拟合一条直线并查看方程的参数就是这么简单。在这种情况下，我们有</p><figure class="kl km kn ko gt kp gh gi paragraph-image"><div class="gh gi pl"><img src="../Images/43c1d4950cf042385168a05ff2e632d4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1386/format:webp/1*AEtxZoIxzs5S3WKqtjpjiw.png"/></div><figcaption class="oi oj gj gh gi ok ol bd b be z dk">Simple linear regression equation</figcaption></figure><p id="1729" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">让我们想象一下这条线是如何拟合数据的。</p><pre class="kl km kn ko gt ox oy oz pa aw pb bi"><span id="bc3b" class="nr kt iv oy b gy pc pd l pe pf">predictions = reg.predict(X)plt.figure(figsize=(16, 8))<br/>plt.scatter(<br/>    data['TV'],<br/>    data['sales'],<br/>    c='black'<br/>)<br/>plt.plot(<br/>    data['TV'],<br/>    predictions,<br/>    c='blue',<br/>    linewidth=2<br/>)<br/>plt.xlabel("Money spent on TV ads ($)")<br/>plt.ylabel("Sales ($)")<br/>plt.show()</span></pre><p id="4575" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">现在，你看:</p><figure class="kl km kn ko gt kp gh gi paragraph-image"><div role="button" tabindex="0" class="oe of di og bf oh"><div class="gh gi pk"><img src="../Images/5b2bfbcff843acad376b61410f0e1d71.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*GUFp-JY-VInBPEEtTpOmDA.png"/></div></div><figcaption class="oi oj gj gh gi ok ol bd b be z dk">Linear fit</figcaption></figure><p id="5519" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">从上图来看，似乎一个简单的线性回归可以解释电视广告支出和销售额的总体影响。</p><h2 id="afcf" class="nr kt iv bd ku ns nt dn ky nu nv dp lc lr nw nx le lt ny nz lg lv oa ob li oc bi translated">评估模型的相关性</h2><p id="9398" class="pw-post-body-paragraph mv mw iv lm b ln lo jw mx lp lq jz my lr mz na nb lt nc nd ne lv nf ng nh lx io bi translated">现在，如果你还记得这篇<a class="ae mc" rel="noopener" target="_blank" href="/linear-regression-understanding-the-theory-7e53ac2831b5">文章</a>，为了看看这个模型是否好，我们需要看看每个系数的 R 值和<em class="om"> p 值</em>。</p><p id="eea3" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">我们是这样做的:</p><pre class="kl km kn ko gt ox oy oz pa aw pb bi"><span id="5364" class="nr kt iv oy b gy pc pd l pe pf">X = data['TV']<br/>y = data['sales']X2 = sm.add_constant(X)<br/>est = sm.OLS(y, X2)<br/>est2 = est.fit()<br/>print(est2.summary())</span></pre><p id="85ff" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">这给了你这个可爱的输出:</p><figure class="kl km kn ko gt kp gh gi paragraph-image"><div role="button" tabindex="0" class="oe of di og bf oh"><div class="gh gi pm"><img src="../Images/7d334c04669dc64dbc31e9f8952c872a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*rt3Bs49UnXPcQlBHSYGE_Q.png"/></div></div><figcaption class="oi oj gj gh gi ok ol bd b be z dk">R² and p-value</figcaption></figure><p id="cfd2" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">查看这两个系数，我们有一个非常低的<em class="om"> p 值</em>(尽管它可能不完全是 0)。这意味着这些系数和目标(销售额)之间有很强的相关性。</p><p id="b095" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">然后，看 R 值，我们有 0.612。因此，<strong class="lm iw">大约 60%的销售变化可以用花在电视广告上的金额来解释</strong>。这没问题，但肯定不是我们能准确预测销售的最好方法。当然，在报纸和广播广告上的花费肯定会对销售产生一定的影响。</p><p id="0d07" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">让我们看看多元线性回归是否会表现得更好。</p><h2 id="ce91" class="nr kt iv bd ku ns nt dn ky nu nv dp lc lr nw nx le lt ny nz lg lv oa ob li oc bi translated">多元线性回归</h2><p id="bb8b" class="pw-post-body-paragraph mv mw iv lm b ln lo jw mx lp lq jz my lr mz na nb lt nc nd ne lv nf ng nh lx io bi translated">就像简单的线性回归一样，我们将定义我们的特性和目标变量，并使用<em class="om"> scikit-learn </em>库来执行线性回归。</p><pre class="kl km kn ko gt ox oy oz pa aw pb bi"><span id="45d9" class="nr kt iv oy b gy pc pd l pe pf">Xs = data.drop(['sales', 'Unnamed: 0'], axis=1)<br/>y = data['sales'].reshape(-1,1)reg = LinearRegression()<br/>reg.fit(Xs, y)print("The linear model is: Y = {:.5} + {:.5}*TV + {:.5}*radio + {:.5}*newspaper".format(reg.intercept_[0], reg.coef_[0][0], reg.coef_[0][1], reg.coef_[0][2]))</span></pre><p id="9a4a" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">仅此而已！从这个代码单元，我们得到下面的等式:</p><figure class="kl km kn ko gt kp gh gi paragraph-image"><div role="button" tabindex="0" class="oe of di og bf oh"><div class="gh gi pk"><img src="../Images/88d2a9d2f41964151d11748a7351f306.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*HtaOtinBig3X_UZQZmE-SQ.png"/></div></div><figcaption class="oi oj gj gh gi ok ol bd b be z dk">Multiple linear regression equation</figcaption></figure><p id="b1bf" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">当然，我们无法想象所有三种媒体对销售的影响，因为它总共有四个维度。</p><p id="0621" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">请注意，报纸的系数是负的，但也相当小。与我们的模型相关吗？让我们通过计算每个系数的 F 统计量、R 值和<em class="om"> p 值</em>来看看。</p><h2 id="fb2c" class="nr kt iv bd ku ns nt dn ky nu nv dp lc lr nw nx le lt ny nz lg lv oa ob li oc bi translated">评估模型的相关性</h2><p id="a99e" class="pw-post-body-paragraph mv mw iv lm b ln lo jw mx lp lq jz my lr mz na nb lt nc nd ne lv nf ng nh lx io bi translated">正如您所料，这里的过程与我们在简单线性回归中所做的非常相似。</p><pre class="kl km kn ko gt ox oy oz pa aw pb bi"><span id="0185" class="nr kt iv oy b gy pc pd l pe pf">X = np.column_stack((data['TV'], data['radio'], data['newspaper']))<br/>y = data['sales']X2 = sm.add_constant(X)<br/>est = sm.OLS(y, X2)<br/>est2 = est.fit()<br/>print(est2.summary())</span></pre><p id="e071" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">您会得到以下结果:</p><figure class="kl km kn ko gt kp gh gi paragraph-image"><div role="button" tabindex="0" class="oe of di og bf oh"><div class="gh gi pn"><img src="../Images/d7fbfa516bbb01464bac24ce86c90e7e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*E2B-td65Q1s2tVGGr1imsg.png"/></div></div><figcaption class="oi oj gj gh gi ok ol bd b be z dk">R², p-value and F-statistic</figcaption></figure><p id="9420" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">可以看到，R 远高于简单线性回归的 R，其值为<strong class="lm iw"> 0.897 </strong>！</p><p id="c71d" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">此外，F 统计值为<strong class="lm iw"> 570.3 </strong>。这比 1 大得多，而且由于我们的数据集相当小(只有 200 个数据点)，它<strong class="lm iw">表明广告支出和销售</strong>之间有很强的关系。</p><p id="f1a6" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">最后，因为我们只有三个预测值，所以我们可以考虑它们的<em class="om"> p 值</em>来确定它们是否与模型相关。当然，你会注意到第三个系数(报纸的系数)有一个很大的 p 值。因此，报纸上的广告支出<strong class="lm iw">在统计上并不显著</strong>。移除那个预测因子会稍微降低 R 值，但我们可能会做出更好的预测。</p><h1 id="b95e" class="ks kt iv bd ku kv kw kx ky kz la lb lc kb ld kc le ke lf kf lg kh lh ki li lj bi translated">逻辑回归理论</h1><h2 id="f617" class="nr kt iv bd ku ns nt dn ky nu nv dp lc lr nw nx le lt ny nz lg lv oa ob li oc bi translated">回归与分类问题</h2><p id="0cd2" class="pw-post-body-paragraph mv mw iv lm b ln lo jw mx lp lq jz my lr mz na nb lt nc nd ne lv nf ng nh lx io bi translated">之前，我们看到<a class="ae mc" rel="noopener" target="_blank" href="/the-complete-guide-to-linear-regression-in-python-3d3f8f06bf8">线性回归</a>假设响应变量是定量的。然而，在许多情况下，反应实际上是定性的，就像眼睛的颜色。这种类型的反应被称为<strong class="lm iw">绝对的。</strong></p><p id="a403" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">分类是预测定性反应的过程。用于分类的方法通常预测定性变量的每个类别的概率，作为进行分类的基础。在某种程度上，它们的行为类似于回归方法。</p><p id="f9f9" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">通过分类，我们可以回答如下问题:</p><ul class=""><li id="2510" class="lk ll iv lm b ln ni lp nj lr nn lt no lv np lx nq lz ma mb bi translated">一个人有一系列症状，这些症状可以归因于三种医学状况中的一种。哪一个？</li><li id="45ec" class="lk ll iv lm b ln md lp me lr mf lt mg lv mh lx nq lz ma mb bi translated">一笔交易是不是欺诈？</li></ul><p id="e963" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">分类回答通常用词来表达。当然，我们不能用文字作为传统统计方法的输入数据。当我们实现算法的时候，我们会看到如何处理这个问题。</p><p id="1901" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">现在，让我们看看逻辑回归是如何工作的。</p><h2 id="e0ff" class="nr kt iv bd ku ns nt dn ky nu nv dp lc lr nw nx le lt ny nz lg lv oa ob li oc bi translated">逻辑回归</h2><p id="3c92" class="pw-post-body-paragraph mv mw iv lm b ln lo jw mx lp lq jz my lr mz na nb lt nc nd ne lv nf ng nh lx io bi translated">当涉及到分类时，我们要确定一个观察值是否属于某一类的概率。因此，我们希望用 0 到 1 之间的值来表示概率。</p><p id="d136" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">接近 1 的概率意味着观测结果<strong class="lm iw">很可能</strong>属于那一类。</p><p id="a829" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">为了生成介于 0 和 1 之间的值，我们使用以下等式来表示概率:</p><figure class="kl km kn ko gt kp gh gi paragraph-image"><div class="gh gi po"><img src="../Images/2b92f7b52ada4b2f97d12182e9b2000e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1138/format:webp/1*16pvfuKHKmt444j3A0JMaQ.png"/></div><figcaption class="oi oj gj gh gi ok ol bd b be z dk">Sigmoid function</figcaption></figure><p id="91aa" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">上面的等式被定义为<strong class="lm iw"> sigmoid 函数。</strong></p><p id="cb92" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">画出这个方程，你会发现这个方程总是产生一个介于 0 和 1 之间的 S 形曲线。</p><figure class="kl km kn ko gt kp gh gi paragraph-image"><div role="button" tabindex="0" class="oe of di og bf oh"><div class="gh gi pp"><img src="../Images/4e6f08f12007fb3aa1d3aaf852c9e765.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*d82VwmBN3YGn3rzMUTluJg.png"/></div></div><figcaption class="oi oj gj gh gi ok ol bd b be z dk">Logistic regression curve</figcaption></figure><p id="fe18" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">对上面的等式进行一些操作后，您会发现:</p><figure class="kl km kn ko gt kp gh gi paragraph-image"><div class="gh gi pq"><img src="../Images/6c4d4ac4127958c37d66cd80235d62ba.png" data-original-src="https://miro.medium.com/v2/resize:fit:1136/format:webp/1*UHGn0QlV5Ifybot8RirOaA.png"/></div></figure><p id="5298" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">在两侧取<em class="om">圆木</em>；</p><figure class="kl km kn ko gt kp gh gi paragraph-image"><div class="gh gi pr"><img src="../Images/da59415e20f8acdccfdfc796aa0fc3bc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1168/format:webp/1*6pnEwGy2Z5z73NasEmC9MQ.png"/></div></figure><p id="48d0" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">上面的等式被称为<em class="om"> logit </em>。可以看到，在<em class="om"> X </em>中是线性的。这里，如果系数是正的，那么<em class="om"> X </em>的增加将导致更高的概率。</p><h2 id="a1d7" class="nr kt iv bd ku ns nt dn ky nu nv dp lc lr nw nx le lt ny nz lg lv oa ob li oc bi translated">估计系数</h2><p id="cc08" class="pw-post-body-paragraph mv mw iv lm b ln lo jw mx lp lq jz my lr mz na nb lt nc nd ne lv nf ng nh lx io bi translated">与线性回归一样，我们需要一种方法来估计系数。为此，我们<strong class="lm iw">最大化</strong>的<em class="om">似然函数</em>:</p><figure class="kl km kn ko gt kp gh gi paragraph-image"><div class="gh gi ps"><img src="../Images/fe9b7da0c6c9ef17607f78d6b3ff2dbb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1236/format:webp/1*IDgIv1rCstBxoAD2E5SWIA.png"/></div><figcaption class="oi oj gj gh gi ok ol bd b be z dk">Likelihood function</figcaption></figure><p id="73a8" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">这里的直觉是，我们希望系数使得预测的概率(在上面的等式中用撇号表示)尽可能接近观察到的状态。</p><p id="d674" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">与线性回归类似，我们使用<em class="om"> p 值</em>来确定是否拒绝零假设。</p><p id="c06d" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">Z 统计数据<em class="om">也被广泛使用。大的绝对 Z 统计量意味着零假设被拒绝。</em></p><p id="1f73" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">请记住，零假设声明:特征和目标之间没有相关性。</p><h2 id="3dc4" class="nr kt iv bd ku ns nt dn ky nu nv dp lc lr nw nx le lt ny nz lg lv oa ob li oc bi translated">多元逻辑回归</h2><p id="a978" class="pw-post-body-paragraph mv mw iv lm b ln lo jw mx lp lq jz my lr mz na nb lt nc nd ne lv nf ng nh lx io bi translated">当然，逻辑回归可以很容易地扩展到容纳一个以上的预测因子:</p><figure class="kl km kn ko gt kp gh gi paragraph-image"><div class="gh gi pt"><img src="../Images/e29a7fec4a5aab3c90857900e998ae2d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1216/format:webp/1*WswbXWnjjzP2pglpBp0PnQ.png"/></div><figcaption class="oi oj gj gh gi ok ol bd b be z dk">Multiple logistic regression</figcaption></figure><p id="fbbb" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">请注意，使用多元逻辑回归可能会给出更好的结果，因为它可以考虑预测因素之间的相关性，这种现象被称为<em class="om">混杂</em>。此外，很少仅有一个预测器就足以建立准确的预测模型。</p><h1 id="a78c" class="ks kt iv bd ku kv kw kx ky kz la lb lc kb ld kc le ke lf kf lg kh lh ki li lj bi translated">线性判别分析(LDA) —理论</h1><p id="537c" class="pw-post-body-paragraph mv mw iv lm b ln lo jw mx lp lq jz my lr mz na nb lt nc nd ne lv nf ng nh lx io bi translated">现在，我们明白了逻辑回归是如何工作的，但是像任何模型一样，它也存在一些缺陷:</p><ul class=""><li id="120b" class="lk ll iv lm b ln ni lp nj lr nn lt no lv np lx nq lz ma mb bi translated">当类被很好地分开时，从逻辑回归估计的参数往往是不稳定的</li><li id="75f2" class="lk ll iv lm b ln md lp me lr mf lt mg lv mh lx nq lz ma mb bi translated">当数据集很小时，逻辑回归也是不稳定的</li><li id="9cf5" class="lk ll iv lm b ln md lp me lr mf lt mg lv mh lx nq lz ma mb bi translated">最好不要预测两个以上的类</li></ul><p id="561b" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">这就是线性判别分析(LDA)派上用场的地方。它比逻辑回归更稳定，广泛用于预测两个以上的类别。</p><p id="6f65" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">LDA 的特殊性在于，它分别对每个响应类别中预测值的分布进行建模，然后使用贝叶斯定理来估计概率。</p><p id="8c36" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">好吧，这有点难以理解。我们来分解一下。</p><h2 id="4bc6" class="nr kt iv bd ku ns nt dn ky nu nv dp lc lr nw nx le lt ny nz lg lv oa ob li oc bi translated">贝叶斯分类定理</h2><p id="0141" class="pw-post-body-paragraph mv mw iv lm b ln lo jw mx lp lq jz my lr mz na nb lt nc nd ne lv nf ng nh lx io bi translated"><em class="om">(抱歉，Medium 不支持数学方程。我尽了最大努力，尽可能的明确)。</em></p><p id="9e57" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">假设我们想要将一个观察结果分类到<em class="om"> K </em>类中的一个，其中<em class="om"> K </em>大于或等于 2。然后，让<em class="om"> pi-k </em>成为一个观察值关联到第<em class="om">个</em>类的总概率。然后，让<em class="om"> f_k(X) </em>表示<em class="om"> X </em>的密度函数，用于来自<em class="om">第 k 个</em>类的观察。这意味着如果来自<em class="om">第 k 个</em>类的观测值具有 X = x 的概率，那么<em class="om"> f_k(X) </em>是大的。然后，贝叶斯定理陈述:</p><figure class="kl km kn ko gt kp gh gi paragraph-image"><div role="button" tabindex="0" class="oe of di og bf oh"><div class="gh gi pu"><img src="../Images/8d926810b82bace2969c746be224514a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*NcxRpOttYmE7_xNaYPJY3A.png"/></div></div><figcaption class="oi oj gj gh gi ok ol bd b be z dk">Bayes’ theorem for classification</figcaption></figure><p id="9749" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">上面的等式可以简单地缩写为:</p><figure class="kl km kn ko gt kp gh gi paragraph-image"><div class="gh gi on"><img src="../Images/99fe7de58b205720d8604b771e9e5a74.png" data-original-src="https://miro.medium.com/v2/resize:fit:1322/format:webp/1*CG0Qv2fGlfxMJdJ4-6fJZg.png"/></div><figcaption class="oi oj gj gh gi ok ol bd b be z dk">Abbreviated Bayes’ theorem for classification</figcaption></figure><p id="6788" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">希望这有一定的意义！</p><p id="192c" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">这里的挑战是估计密度函数。理论上，贝叶斯的分类错误率最低。因此，我们的分类器需要估计密度函数，以逼近贝叶斯分类器。</p><h2 id="e1f4" class="nr kt iv bd ku ns nt dn ky nu nv dp lc lr nw nx le lt ny nz lg lv oa ob li oc bi translated">一个预测器的 LDA</h2><p id="9f49" class="pw-post-body-paragraph mv mw iv lm b ln lo jw mx lp lq jz my lr mz na nb lt nc nd ne lv nf ng nh lx io bi translated">假设我们只有一个预测值，并且密度函数是正态的。然后，您可以将密度函数表示为:</p><figure class="kl km kn ko gt kp gh gi paragraph-image"><div role="button" tabindex="0" class="oe of di og bf oh"><div class="gh gi pv"><img src="../Images/83627df82ffdd989eaea46c114edf28e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*MMP0tIKRK-jtKK0eH3Nt0g.png"/></div></div><figcaption class="oi oj gj gh gi ok ol bd b be z dk">Normal distribution function</figcaption></figure><p id="a620" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">现在，我们要指定一个观察值<em class="om"> X = x </em>，对于该观察值<em class="om"> P_k(X) </em>最大。如果你在<em class="om"> P_k(X) </em>中插入密度函数，取<em class="om">对数</em>，你会发现你希望最大化:</p><figure class="kl km kn ko gt kp gh gi paragraph-image"><div role="button" tabindex="0" class="oe of di og bf oh"><div class="gh gi pw"><img src="../Images/4bb3f76ad375a92a4729065196e48091.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ZTlK7kePOQIQPJQ9fEQz5A.png"/></div></div><figcaption class="oi oj gj gh gi ok ol bd b be z dk">Discriminant equation</figcaption></figure><p id="8e16" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">上面的等式称为<strong class="lm iw">判别式。</strong>如你所见，这是一个线性方程。因此得名:<strong class="lm iw">线性判别分析</strong>！</p><p id="65b7" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">现在，假设只有两个具有相等分布的类，您会发现:</p><figure class="kl km kn ko gt kp gh gi paragraph-image"><div role="button" tabindex="0" class="oe of di og bf oh"><div class="gh gi px"><img src="../Images/2a6bfda7e458a505807aabc59f320463.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*KFffe_Sbr40PwYLvwfO2PA.png"/></div></div><figcaption class="oi oj gj gh gi ok ol bd b be z dk">Boundary equation</figcaption></figure><p id="08b9" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">这是边界方程。下图显示了图示。</p><figure class="kl km kn ko gt kp gh gi paragraph-image"><div class="gh gi py"><img src="../Images/ffe69e5db11a49d70659bfe4942a65ff.png" data-original-src="https://miro.medium.com/v2/resize:fit:1356/format:webp/1*CDviUGNenbTAF4CK4HLdyg.png"/></div><figcaption class="oi oj gj gh gi ok ol bd b be z dk">Boundary line to separate 2 classes using LDA</figcaption></figure><p id="af30" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">当然，这代表了一种理想的解决方案。事实上，我们无法精确计算边界线。</p><p id="6d75" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">因此，LDA 利用以下近似:</p><ul class=""><li id="7d82" class="lk ll iv lm b ln ni lp nj lr nn lt no lv np lx nq lz ma mb bi translated">对于所有训练观察的平均值</li></ul><figure class="kl km kn ko gt kp gh gi paragraph-image"><div class="gh gi pz"><img src="../Images/e72c60e61ce4dca18c8226f64cbb4c64.png" data-original-src="https://miro.medium.com/v2/resize:fit:1038/format:webp/1*sXg0dhjsM8rnWKOvjitNDA.png"/></div><figcaption class="oi oj gj gh gi ok ol bd b be z dk">Average of all training observations</figcaption></figure><ul class=""><li id="8cca" class="lk ll iv lm b ln ni lp nj lr nn lt no lv np lx nq lz ma mb bi translated">对于每类样本方差的加权平均值</li></ul><figure class="kl km kn ko gt kp gh gi paragraph-image"><div role="button" tabindex="0" class="oe of di og bf oh"><div class="gh gi qa"><img src="../Images/368090a325b230584b871ae1a68dc8ca.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*si02aMPhNrabyr06mq4_kA.png"/></div></div><figcaption class="oi oj gj gh gi ok ol bd b be z dk">Weighted average of sample variances for each class</figcaption></figure><p id="c42b" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">其中<em class="om"> n </em>是观察次数。</p><p id="2d9a" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">重要的是要知道，LDA 为每个类别假设了一个<strong class="lm iw">正态分布</strong>，一个<strong class="lm iw">特定类别均值</strong>，以及一个<strong class="lm iw">共同方差</strong>。</p><h2 id="2ac2" class="nr kt iv bd ku ns nt dn ky nu nv dp lc lr nw nx le lt ny nz lg lv oa ob li oc bi translated">多个预测值的 LDA</h2><p id="776e" class="pw-post-body-paragraph mv mw iv lm b ln lo jw mx lp lq jz my lr mz na nb lt nc nd ne lv nf ng nh lx io bi translated">现在扩展到多个预测值，我们必须假设<em class="om"> X </em>来自<strong class="lm iw">多元高斯分布</strong>，具有特定类别的均值向量和公共协方差矩阵。</p><p id="d954" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">相关和不相关高斯分布的示例如下所示。</p><figure class="kl km kn ko gt kp gh gi paragraph-image"><div role="button" tabindex="0" class="oe of di og bf oh"><div class="gh gi pk"><img src="../Images/08dc756c5e3a44c38ff49c63266ead04.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*GrPryIQQntXoZ0UIWPh4LA.png"/></div></div><figcaption class="oi oj gj gh gi ok ol bd b be z dk">Left: Uncorrelated normal distribution. Right: correlated normal distribution</figcaption></figure><p id="33e6" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">现在，用向量符号表示判别方程，我们得到:</p><figure class="kl km kn ko gt kp gh gi paragraph-image"><div role="button" tabindex="0" class="oe of di og bf oh"><div class="gh gi qb"><img src="../Images/cbcab3a712d6404dd44f7d7c6712ec4e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*4JBGR-vPiJpu2so9LYr3PA.png"/></div></div><figcaption class="oi oj gj gh gi ok ol bd b be z dk">Discriminant equation with matrix notation</figcaption></figure><p id="9e55" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">如你所见，等式保持不变。只是这一次，我们使用向量符号来容纳许多预测值。</p><h2 id="55b5" class="nr kt iv bd ku ns nt dn ky nu nv dp lc lr nw nx le lt ny nz lg lv oa ob li oc bi translated">如何评估模型的性能</h2><p id="8cd2" class="pw-post-body-paragraph mv mw iv lm b ln lo jw mx lp lq jz my lr mz na nb lt nc nd ne lv nf ng nh lx io bi translated">对于分类，有时使用准确性来评估模型的性能是不相关的。</p><p id="95b7" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">考虑分析一个高度不平衡的数据集。例如，您试图确定一项交易是否是欺诈性的，但您的数据集只有 0.5%包含欺诈性交易。然后，您可以预测没有任何交易是欺诈性的，并有 99.5%的准确率得分！当然，这是一种非常幼稚的方法，无助于检测欺诈交易。</p><p id="3631" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">那么我们用什么呢？</p><p id="927e" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">通常，我们用<strong class="lm iw">灵敏度</strong>和<strong class="lm iw">特异性</strong>。</p><p id="1a4d" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated"><strong class="lm iw">灵敏度</strong>是真正的阳性率:被正确识别的实际阳性的比例。</p><p id="7499" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated"><strong class="lm iw">特异性</strong>是真阴性率:实际阴性被正确识别的比例。</p><p id="1484" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">让我们给出一些背景来更好地理解。使用欺诈检测问题，<strong class="lm iw">敏感度</strong>是被识别为欺诈的欺诈交易的比例。<strong class="lm iw">特异性</strong>是被识别为非欺诈的非欺诈交易的比例。</p><p id="d52c" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">因此，在理想情况下，我们需要高灵敏度和高特异性，尽管这可能会因环境而异。例如，银行可能希望优先考虑较高的敏感性而不是特异性，以确保识别欺诈性交易。</p><p id="52b6" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated"><strong class="lm iw"> ROC 曲线</strong>(接收器工作特性)可以很好地显示上述两种误差指标。分类器的总体性能由 ROC 曲线下的面积给出(<strong class="lm iw"> AUC </strong>)。理想情况下，它应该紧挨着图形的左上角，并且面积接近 1。</p><figure class="kl km kn ko gt kp gh gi paragraph-image"><div role="button" tabindex="0" class="oe of di og bf oh"><div class="gh gi qc"><img src="../Images/70a6ba90afd16cf93ba43751747c9107.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*s40QXq6Ia3xP7iBju4NyoA.png"/></div></div><figcaption class="oi oj gj gh gi ok ol bd b be z dk">Example of a ROC curve. The straight line is a base model</figcaption></figure><h1 id="7fe0" class="ks kt iv bd ku kv kw kx ky kz la lb lc kb ld kc le ke lf kf lg kh lh ki li lj bi translated">二次判别分析(QDA)——理论</h1><p id="f8d4" class="pw-post-body-paragraph mv mw iv lm b ln lo jw mx lp lq jz my lr mz na nb lt nc nd ne lv nf ng nh lx io bi translated">这里，我们保持与 LDA 相同的假设，但是现在，来自第<em class="om">个</em>类的每个观察值都有自己的协方差矩阵。</p><p id="53b4" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">对于 QDA，判别式表示为:</p><figure class="kl km kn ko gt kp gh gi paragraph-image"><div role="button" tabindex="0" class="oe of di og bf oh"><div class="gh gi qd"><img src="../Images/ae6647a2eb116829c38300c5e2bbeb4c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*hM7ZhQC8jSa4EK1aXTcpbg.png"/></div></div><figcaption class="oi oj gj gh gi ok ol bd b be z dk">Discriminant equation for QDA</figcaption></figure><p id="5045" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">毫无疑问，你会注意到这个方程现在是二次方程了。</p><p id="9bd5" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">但是，为什么选择 QDA 而不是 LDA？</p><p id="4ab1" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">对于大型数据集，QDA 是更好的选择，因为它倾向于具有更低的偏差和更高的方差。</p><p id="d9d2" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">另一方面，LDA 更适合于较小的数据集，它有较高的偏倚和较低的方差。</p><h1 id="ef44" class="ks kt iv bd ku kv kw kx ky kz la lb lc kb ld kc le ke lf kf lg kh lh ki li lj bi translated">逻辑回归、线性判别分析和 QDA——实践</h1><p id="b697" class="pw-post-body-paragraph mv mw iv lm b ln lo jw mx lp lq jz my lr mz na nb lt nc nd ne lv nf ng nh lx io bi translated">太好了！既然我们已经深刻理解了逻辑回归、LDA 和 QDA 的工作原理，让我们应用每种算法来解决一个分类问题。</p><h2 id="e603" class="nr kt iv bd ku ns nt dn ky nu nv dp lc lr nw nx le lt ny nz lg lv oa ob li oc bi translated">动机</h2><p id="738a" class="pw-post-body-paragraph mv mw iv lm b ln lo jw mx lp lq jz my lr mz na nb lt nc nd ne lv nf ng nh lx io bi translated">蘑菇味道好极了！但是，仅在北美就有超过 10 000 种蘑菇，我们怎么知道哪些是可以食用的呢？</p><p id="4f63" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">这是这个项目的目标。我们将构建一个分类器来确定某种蘑菇是可食用的还是有毒的。</p><p id="4b3a" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">我建议你拿起<a class="ae mc" href="https://www.kaggle.com/uciml/mushroom-classification" rel="noopener ugc nofollow" target="_blank">数据集</a>跟着做。如果你被卡住了，请随时查阅<a class="ae mc" href="https://github.com/marcopeix/ISL-classification" rel="noopener ugc nofollow" target="_blank">完整笔记本</a>。</p><p id="25af" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">我们开始吧！</p><h2 id="4145" class="nr kt iv bd ku ns nt dn ky nu nv dp lc lr nw nx le lt ny nz lg lv oa ob li oc bi translated">探索性数据分析</h2><p id="6282" class="pw-post-body-paragraph mv mw iv lm b ln lo jw mx lp lq jz my lr mz na nb lt nc nd ne lv nf ng nh lx io bi translated">我们将使用的<a class="ae mc" href="https://www.kaggle.com/uciml/mushroom-classification" rel="noopener ugc nofollow" target="_blank">数据集</a>包含 8124 个蘑菇实例，有 22 个特征。其中，我们发现了蘑菇的帽形、帽色、鳃色、面纱类型等。当然，它也告诉我们蘑菇是可食用的还是有毒的。</p><p id="e158" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">让我们导入一些库，它们将帮助我们导入数据并操作它。在您的笔记本中，运行以下代码:</p><figure class="kl km kn ko gt kp gh gi paragraph-image"><div role="button" tabindex="0" class="oe of di og bf oh"><div class="gh gi pk"><img src="../Images/58b73f27068f2a6c75fdf1c3ae0eaeda.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*7iApqwtcYt4FyyPGGy5t1A.png"/></div></div></figure><p id="9bcb" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">数据科学项目通常的第一步是执行<strong class="lm iw">探索性数据分析</strong> (EDA)。这一步通常包括了解更多关于您正在处理的数据的信息。您可能想知道数据集的<strong class="lm iw">形状</strong>(有多少行和列)、空值的数量，并可视化部分数据以更好地理解特征和目标之间的相关性。</p><p id="5236" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">导入数据并查看前五列，代码如下:</p><figure class="kl km kn ko gt kp gh gi paragraph-image"><div role="button" tabindex="0" class="oe of di og bf oh"><div class="gh gi pk"><img src="../Images/b4c2225b692422914a31fff461c3f043.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*RVBTRa_oRtG4wZ8LCjiv6Q.png"/></div></div></figure><p id="d07d" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">将数据集放在项目目录下的<em class="om">数据</em>文件夹中总是好的。此外，我们将文件路径存储在一个变量中，这样，如果路径发生变化，我们只需更改变量赋值。</p><p id="a975" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">运行此代码单元后，您应该会看到前五行。您会注意到每个特性都是分类的，并且用一个字母来定义某个值。当然，分类器不能接受字母作为输入，所以我们最终必须改变它。</p><p id="2421" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">现在，让我们看看我们的数据集是否不平衡。一个不平衡的数据集是指<strong class="lm iw">一个类比另一个类出现得多</strong>。理想情况下，在分类的上下文中，我们希望每个类的实例数量相等。否则，我们将需要实现先进的采样方法，如<strong class="lm iw">少数过采样。</strong></p><p id="e164" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">在我们的例子中，我们想看看数据集中有毒和可食用蘑菇的数量是否相等。我们可以像这样画出每一类的频率:</p><figure class="kl km kn ko gt kp gh gi paragraph-image"><div role="button" tabindex="0" class="oe of di og bf oh"><div class="gh gi pk"><img src="../Images/af932d5a7202b139d8681162a311ce01.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*5HNVJPMo9eL_NOmUc4_fPg.png"/></div></div></figure><p id="b029" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">你会得到下面的图表:</p><figure class="kl km kn ko gt kp gh gi paragraph-image"><div class="gh gi qe"><img src="../Images/35b55f4073edd33af850ca408d6dacbe.png" data-original-src="https://miro.medium.com/v2/resize:fit:1394/format:webp/1*OI4IpjZlwcBogDgCWEVx_Q.png"/></div></figure><p id="2b2f" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">厉害！这看起来像是一个相当平衡的数据集，有毒和可食用蘑菇的数量几乎相等。</p><p id="6b7f" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">现在，我想看看每个特征如何影响目标。为了做到这一点，对于每个特性，我绘制了一个由蘑菇类分隔的所有可能值的条形图。为所有 22 个特性手动执行没有意义，因此我们构建了这个帮助器函数:</p><figure class="kl km kn ko gt kp gh gi paragraph-image"><div role="button" tabindex="0" class="oe of di og bf oh"><div class="gh gi pk"><img src="../Images/32027fc3c16706836c88d14749924b0b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*p8ZBPwVLlPOAfcpX1QYDrA.png"/></div></div></figure><p id="639f" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated"><em class="om">色调</em>会给有毒和可食用类一个颜色代码。<em class="om">数据</em>参数将包含除蘑菇类之外的所有特征。运行下面的单元代码:</p><figure class="kl km kn ko gt kp gh gi paragraph-image"><div role="button" tabindex="0" class="oe of di og bf oh"><div class="gh gi pk"><img src="../Images/224bd64fe7274d0d409f860c8e2565f3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*P4Pj5Wh3oHPc2wpjQfo5ZQ.png"/></div></div></figure><p id="6b8e" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">您应该会得到一个包含 22 个地块的列表。下面是一个输出示例:</p><figure class="kl km kn ko gt kp gh gi paragraph-image"><div role="button" tabindex="0" class="oe of di og bf oh"><div class="gh gi qf"><img src="../Images/db322ecb75d6e14c81b6ff7121a1025b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*qfXbUC9EihVKV-azuuqvbQ.png"/></div></div></figure><p id="a4e6" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">花些时间浏览所有的情节。</p><p id="da19" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">现在，让我们看看是否有丢失的值。运行这段代码:</p><figure class="kl km kn ko gt kp gh gi paragraph-image"><div role="button" tabindex="0" class="oe of di og bf oh"><div class="gh gi pk"><img src="../Images/bfc790df49b54660af67c1fcc54e07d4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*gbEg3L5UthuTPpUcIvMyPQ.png"/></div></div></figure><p id="e5a4" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">您应该看到每一列都有缺失值的数量。幸运的是，我们有一个没有缺失值的数据集。这很不常见，但我们不会抱怨。</p><h2 id="0b64" class="nr kt iv bd ku ns nt dn ky nu nv dp lc lr nw nx le lt ny nz lg lv oa ob li oc bi translated">为建模做准备</h2><p id="2537" class="pw-post-body-paragraph mv mw iv lm b ln lo jw mx lp lq jz my lr mz na nb lt nc nd ne lv nf ng nh lx io bi translated">现在我们已经熟悉了数据，是时候为建模做准备了。如前所述，特性用字母来表示不同的可能值，但是我们需要将它们转换成数字。</p><p id="e274" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">为此，我们将使用<strong class="lm iw">标签编码</strong>和<strong class="lm iw">一键编码。</strong></p><p id="dd7d" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">让我们首先在目标列上使用标签编码。运行以下代码:</p><figure class="kl km kn ko gt kp gh gi paragraph-image"><div role="button" tabindex="0" class="oe of di og bf oh"><div class="gh gi pk"><img src="../Images/28111d83217791c3380d5f73e12eefdc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*BKiNIcQFWRAEeP2_Tk3jkA.png"/></div></div></figure><p id="9901" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">您会注意到现在该列包含 1 和 0。</p><figure class="kl km kn ko gt kp gh gi paragraph-image"><div role="button" tabindex="0" class="oe of di og bf oh"><div class="gh gi qg"><img src="../Images/7f583d51dd75dede4dc793299b3f0c11.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*tX5a8e64PmaeQ1z4lwjkgg.png"/></div></div><figcaption class="oi oj gj gh gi ok ol bd b be z dk">Result of label encoding the ‘class’ column</figcaption></figure><p id="492a" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">现在，有毒的用 1 表示，可食用的用 0 表示。现在，我们可以把我们的分类器想成“有毒与否”。毒蘑菇得 1(真)，食用菌得 0(假)。</p><p id="f3ab" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">因此，<strong class="lm iw">标签编码</strong>会将分类特征转化为数字特征。但是，当有两个以上的可能值时，不建议使用标签编码。</p><p id="952f" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">为什么？</p><p id="9bda" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">因为它会将每个值赋给 0、1 或 2。这是一个问题，因为“2”可能被认为是更重要的<em class="om"/>，并且可能由此得出错误的相关性。</p><p id="29e5" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">为了避免这个问题，我们在其他特性上使用<strong class="lm iw">一键编码</strong>。为了理解它的作用，让我们考虑一下第一个入口点的帽形。你可以看到它的值为“x ”,代表凸帽形状。然而，在数据集中总共记录了六种不同的帽形状。如果我们对特征进行一次性编码，我们应该得到:</p><figure class="kl km kn ko gt kp gh gi paragraph-image"><div role="button" tabindex="0" class="oe of di og bf oh"><div class="gh gi pk"><img src="../Images/e8f0cf1ef58ca8d63603fd5b70f40248.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*lX3IblxDBB1hsQa_kYjTrA.png"/></div></div><figcaption class="oi oj gj gh gi ok ol bd b be z dk">One-hot encoding the “cap-shape” feature</figcaption></figure><p id="f825" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">如您所见，帽子形状现在是一个矢量。1 表示数据集中条目的实际帽形状值，其余部分用 0 填充。同样，你可以认为 1 代表<em class="om">真</em>，0 代表<em class="om">假。</em></p><p id="0656" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">一键编码的缺点是它向数据集引入了更多的列。在帽形的情况下，我们从一列到六列。对于非常大的数据集，这可能是一个问题，但是在我们的例子中，额外的列应该是可以管理的。</p><p id="fffa" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">让我们继续对其余的功能进行一次性编码:</p><figure class="kl km kn ko gt kp gh gi paragraph-image"><div role="button" tabindex="0" class="oe of di og bf oh"><div class="gh gi pk"><img src="../Images/33136b55890783c901265993df28540d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*5f1xtLJ21ujGk3rpxYwh8g.png"/></div></div></figure><p id="d084" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">现在您应该可以看到:</p><figure class="kl km kn ko gt kp gh gi paragraph-image"><div role="button" tabindex="0" class="oe of di og bf oh"><div class="gh gi pk"><img src="../Images/b309089bb8d4bf68854492beb79f9c9a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*7mYzIOow8qrFYFpKrCTJWQ.png"/></div></div><figcaption class="oi oj gj gh gi ok ol bd b be z dk">One-hot encoded data set</figcaption></figure><p id="6521" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">你注意到我们从 23 列增加到 118 列。这是五倍的增长，但这个数字还不足以导致计算机内存问题。</p><p id="e454" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">既然我们的数据集只包含数字数据，我们就可以开始建模和预测了！</p><h2 id="d968" class="nr kt iv bd ku ns nt dn ky nu nv dp lc lr nw nx le lt ny nz lg lv oa ob li oc bi translated">训练/测试分割</h2><p id="e677" class="pw-post-body-paragraph mv mw iv lm b ln lo jw mx lp lq jz my lr mz na nb lt nc nd ne lv nf ng nh lx io bi translated">在深入建模和进行预测之前，我们需要将数据集分成训练集和测试集。这样，我们可以在训练集上训练算法，并在测试集上进行预测。这种方式的误差度量将更加相关，因为该算法将对以前没有见过的数据进行预测。</p><p id="24a3" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">我们可以像这样轻松地分割数据集:</p><figure class="kl km kn ko gt kp gh gi paragraph-image"><div role="button" tabindex="0" class="oe of di og bf oh"><div class="gh gi pk"><img src="../Images/1fa736ccf4b2df7c537573ebeba60a5e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*vWbPMR9YO6-Q1rlFF5evnA.png"/></div></div></figure><p id="81b4" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">在这里，<em class="om"> y </em>仅仅是目标(有毒或可食用)。那么，<em class="om"> X </em>就是简单的数据集的所有特征。最后，我们使用<em class="om"> train_test_split </em>函数。<em class="om"> test_size </em>参数对应于将用于测试的数据集部分。通常，我们使用 20%。然后，<em class="om"> random_state </em>参数用于再现性。它可以设置为任何数字，但它将确保每次代码运行时，数据集将被相同地分割。如果没有提供<em class="om"> random_state </em>，那么训练集和测试集将会不同，因为函数会随机分割它。</p><p id="56b2" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">好了，我们正式准备好开始建模和预测了！</p><h2 id="966b" class="nr kt iv bd ku ns nt dn ky nu nv dp lc lr nw nx le lt ny nz lg lv oa ob li oc bi translated">逻辑回归</h2><p id="3952" class="pw-post-body-paragraph mv mw iv lm b ln lo jw mx lp lq jz my lr mz na nb lt nc nd ne lv nf ng nh lx io bi translated">我们将首先使用逻辑回归。在接下来的步骤中，我们将使用 ROC 曲线下的面积和混淆矩阵作为误差度量。</p><p id="0b9c" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">让我们先导入我们需要的所有内容:</p><figure class="kl km kn ko gt kp gh gi paragraph-image"><div role="button" tabindex="0" class="oe of di og bf oh"><div class="gh gi pk"><img src="../Images/cc103937c5a58660475c4b6e8c11da77.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*avepTkKd3CV1n26Uu3ADcA.png"/></div></div></figure><p id="9574" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">然后，我们创建一个<em class="om"> LogisticRegression </em>对象的实例，并使模型适合训练集:</p><figure class="kl km kn ko gt kp gh gi paragraph-image"><div role="button" tabindex="0" class="oe of di og bf oh"><div class="gh gi pk"><img src="../Images/c27537585f7f6c6519053650d8b7c372.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*SXct7ynPPN8u40Yy5oKQ_Q.png"/></div></div></figure><p id="6e2b" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">然后，我们预测蘑菇有毒的概率。记住，我们认为蘑菇有毒或无毒。</p><p id="31ee" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">此外，必须提醒您，逻辑回归会返回一个概率。现在，让我们将阈值设置为 0.5，这样，如果概率大于 0.5，蘑菇将被分类为有毒。当然，如果概率小于阈值，蘑菇被分类为可食用。</p><p id="6279" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">这正是下面代码单元格中发生的情况:</p><figure class="kl km kn ko gt kp gh gi paragraph-image"><div role="button" tabindex="0" class="oe of di og bf oh"><div class="gh gi pk"><img src="../Images/db46fc90a53c38d8e9a1b58473a096f1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*VG3-6Mv1ZcdJHGYj4gaY-Q.png"/></div></div></figure><p id="af12" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">注意，我们是在测试集上计算概率的。</p><p id="ffcd" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">现在，让我们看看<strong class="lm iw">混淆矩阵。</strong>这将显示真实阳性率、真实阴性率、假阳性率和假阴性率。</p><figure class="kl km kn ko gt kp gh gi paragraph-image"><div class="gh gi qh"><img src="../Images/011ee3d97d11b162641d9c4fdd960c7f.png" data-original-src="https://miro.medium.com/v2/resize:fit:576/format:webp/1*iGCc-GJHfpkyHQxNjK3_GA.png"/></div><figcaption class="oi oj gj gh gi ok ol bd b be z dk">Example of a confusion matrix</figcaption></figure><p id="3319" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">我们像这样输出我们的混淆矩阵:</p><figure class="kl km kn ko gt kp gh gi paragraph-image"><div role="button" tabindex="0" class="oe of di og bf oh"><div class="gh gi pk"><img src="../Images/e22b33ecab4d9bdb66bb96d453f940ad.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*6Va4Ot2hEH6GsXa5b7MQsA.png"/></div></div></figure><p id="0161" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">您应该得到:</p><figure class="kl km kn ko gt kp gh gi paragraph-image"><div role="button" tabindex="0" class="oe of di og bf oh"><div class="gh gi qi"><img src="../Images/c2a1c65429ba9c79ad1b8eedf2006693.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*IwqU8DDJ-knFnaGsCATbug.png"/></div></div></figure><p id="376d" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">太神奇了！我们的分类器是完美的！从上面的混淆矩阵中，你可以看到我们的假阳性和假阴性率是 0，这意味着所有的蘑菇都被正确地分类为有毒或可食用！</p><p id="09f4" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">让我们打印 ROC 曲线下的面积。如你所知，对于一个完美的分类器，它应该等于 1。</p><figure class="kl km kn ko gt kp gh gi paragraph-image"><div role="button" tabindex="0" class="oe of di og bf oh"><div class="gh gi pk"><img src="../Images/87313a6de5b0155cbc32fd2a3b219ff0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Tfs3mA7zmDQfRHQpn7iuxg.png"/></div></div></figure><p id="33ef" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">的确，上面的代码块输出 1！我们可以制作自己的函数来可视化 ROC 曲线:</p><figure class="kl km kn ko gt kp gh gi paragraph-image"><div role="button" tabindex="0" class="oe of di og bf oh"><div class="gh gi pk"><img src="../Images/10bc72c0515784d2592d19bf9686454d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*la_dM76Dzar2sN7czfrRuA.png"/></div></div></figure><p id="6b80" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">您应该会看到:</p><figure class="kl km kn ko gt kp gh gi paragraph-image"><div role="button" tabindex="0" class="oe of di og bf oh"><div class="gh gi pm"><img src="../Images/a354c11e01f3d90479525c96fad4fa1d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Bg9emKDvbv5JdqX_vc74qw.png"/></div></div><figcaption class="oi oj gj gh gi ok ol bd b be z dk">ROC curve</figcaption></figure><p id="2148" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">恭喜你！你用一个基本的逻辑回归模型建立了一个完美的分类器。</p><p id="c0c4" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">然而，为了获得更多的经验，让我们使用 ld a 和 QDA 建立一个分类器，看看我们是否得到类似的结果。</p><h2 id="f315" class="nr kt iv bd ku ns nt dn ky nu nv dp lc lr nw nx le lt ny nz lg lv oa ob li oc bi translated">LDA 分类器</h2><p id="9f2b" class="pw-post-body-paragraph mv mw iv lm b ln lo jw mx lp lq jz my lr mz na nb lt nc nd ne lv nf ng nh lx io bi translated">遵循逻辑回归概述的相同步骤:</p><figure class="kl km kn ko gt kp gh gi paragraph-image"><div role="button" tabindex="0" class="oe of di og bf oh"><div class="gh gi pk"><img src="../Images/383fa6631bb2aa7bb5ec333150655823.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*YRmL993WZFRE-CVxUHzvfQ.png"/></div></div></figure><p id="44b9" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">如果您运行上面的代码，您应该看到我们再次获得了一个完美的分类器，其结果与使用逻辑回归的分类器相同。</p><h2 id="d2db" class="nr kt iv bd ku ns nt dn ky nu nv dp lc lr nw nx le lt ny nz lg lv oa ob li oc bi translated">QDA 分类器</h2><p id="1ffd" class="pw-post-body-paragraph mv mw iv lm b ln lo jw mx lp lq jz my lr mz na nb lt nc nd ne lv nf ng nh lx io bi translated">现在，我们重复这个过程，但是使用 QDA:</p><figure class="kl km kn ko gt kp gh gi paragraph-image"><div role="button" tabindex="0" class="oe of di og bf oh"><div class="gh gi pk"><img src="../Images/547ac66fc01f5c926ae3e22a910c1f18.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*qEJKwnRXCXsJ6yTZi3WScQ.png"/></div></div></figure><p id="1196" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">同样，结果是一样的！</p><h1 id="f87f" class="ks kt iv bd ku kv kw kx ky kz la lb lc kb ld kc le ke lf kf lg kh lh ki li lj bi translated">重采样—理论</h1><p id="4424" class="pw-post-body-paragraph mv mw iv lm b ln lo jw mx lp lq jz my lr mz na nb lt nc nd ne lv nf ng nh lx io bi translated">重采样和正则化是两个重要的步骤，可以显著提高模型的性能和对模型的信心。</p><p id="0b24" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">在本文中，交叉验证将被广泛讨论，因为它是最流行的重采样方法。然后，将介绍岭回归和 lasso 作为线性模型的正则化方法。之后，将在项目设置中应用重采样和正则化。</p><p id="905c" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">我希望这篇文章能作为你未来某个项目的参考，并能成为你的书签。</p><p id="b19b" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">我们开始吧！</p><h2 id="ef23" class="nr kt iv bd ku ns nt dn ky nu nv dp lc lr nw nx le lt ny nz lg lv oa ob li oc bi translated">重采样的重要性</h2><p id="9685" class="pw-post-body-paragraph mv mw iv lm b ln lo jw mx lp lq jz my lr mz na nb lt nc nd ne lv nf ng nh lx io bi translated">重采样方法是现代统计学中不可缺少的工具。它们涉及重复地从训练集中抽取样本，并在每个样本上重新拟合感兴趣的模型，以便获得关于拟合模型的附加信息。这使我们能够获得更多的信息，而这些信息是仅拟合一次模型所无法获得的。</p><p id="388e" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">通常，数据科学项目的目标是使用训练数据创建模型，并让它对新数据进行预测。因此，重采样方法允许我们在不收集新数据的情况下，观察模型在未经训练的数据上的表现。</p><h2 id="6cae" class="nr kt iv bd ku ns nt dn ky nu nv dp lc lr nw nx le lt ny nz lg lv oa ob li oc bi translated">交叉验证</h2><p id="3dac" class="pw-post-body-paragraph mv mw iv lm b ln lo jw mx lp lq jz my lr mz na nb lt nc nd ne lv nf ng nh lx io bi translated">交叉验证(<strong class="lm iw"> CV </strong>)用于估计与模型相关的测试误差，以评估其性能或选择适当的灵活性水平。评估一个模型的性能通常被定义为<strong class="lm iw">模型评估</strong>，而<strong class="lm iw">模型选择</strong>用于选择灵活性的级别。这个术语广泛用于数据科学领域。</p><p id="c65f" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">现在，有不同的方法来执行交叉验证。让我们逐一探索。</p><h2 id="d19b" class="nr kt iv bd ku ns nt dn ky nu nv dp lc lr nw nx le lt ny nz lg lv oa ob li oc bi translated">验证集方法</h2><p id="496b" class="pw-post-body-paragraph mv mw iv lm b ln lo jw mx lp lq jz my lr mz na nb lt nc nd ne lv nf ng nh lx io bi translated">这是最基本的方法。它只是简单地将数据集随机分成两部分:一个<strong class="lm iw">训练集</strong>和<strong class="lm iw"> </strong>一个<strong class="lm iw">验证集</strong>或<strong class="lm iw">保留集</strong>。该模型适合训练集，并且该适合的模型用于对验证集进行预测。</p><figure class="kl km kn ko gt kp gh gi paragraph-image"><div role="button" tabindex="0" class="oe of di og bf oh"><div class="gh gi pk"><img src="../Images/fe1f82b70b6be5466d4c81481a459bf1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*DeRE43o18hnz0dNb.png"/></div></div><figcaption class="oi oj gj gh gi ok ol bd b be z dk">Validation set schematic</figcaption></figure><p id="4b29" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">上面是验证集方法的示意图。在一个数据集中有 n 个观察值，它被随机分成两部分。蓝色一侧代表训练集，橙色一侧是验证集。数字只是代表行数。</p><p id="9ac5" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">当然，这种简单的方法也有一些缺点。</p><p id="35a7" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">首先，验证测试错误率是高度可变的，这取决于训练和验证集中的观察值。</p><p id="6609" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">第二，只有一小部分观察值用于拟合模型。然而，我们知道统计方法在数据较少的情况下往往表现较差。</p><figure class="kl km kn ko gt kp gh gi paragraph-image"><div role="button" tabindex="0" class="oe of di og bf oh"><div class="gh gi pk"><img src="../Images/dba7a9d498ce02df3578a6ac248957bb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*MmYFVf94NVyU52Wu.png"/></div></div><figcaption class="oi oj gj gh gi ok ol bd b be z dk">MSE for the validation set approach</figcaption></figure><p id="3967" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">在上面的左侧，您可以看到验证集方法仅应用一次时的 MSE。在右边，这个过程重复了 10 次。如你所见，MSE 变化很大。</p><p id="c748" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">这显示了使用验证集方法时 MSE 的显著可变性。</p><p id="e3f7" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">当然，有一些方法可以解决这些缺点。</p><h2 id="34a8" class="nr kt iv bd ku ns nt dn ky nu nv dp lc lr nw nx le lt ny nz lg lv oa ob li oc bi translated">留一交叉验证</h2><p id="1833" class="pw-post-body-paragraph mv mw iv lm b ln lo jw mx lp lq jz my lr mz na nb lt nc nd ne lv nf ng nh lx io bi translated">留一交叉验证(<strong class="lm iw"> LOOCV </strong>)是比验证集方法更好的选择。不是将数据集分成两个子集，而是只使用一个观察值进行验证，其余的用于拟合模型。</p><figure class="kl km kn ko gt kp gh gi paragraph-image"><div role="button" tabindex="0" class="oe of di og bf oh"><div class="gh gi pk"><img src="../Images/a3d2aeddceac2d6863ae877030eaf061.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*piy_yGrvpwv4pR_2.png"/></div></div><figcaption class="oi oj gj gh gi ok ol bd b be z dk">LOOCV schematic</figcaption></figure><p id="1d97" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">以上是 LOOCV 的示意图。如您所见，只有一个观察用于验证，其余的用于训练。然后，该过程重复多次。</p><p id="5f1a" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">多次运行后，误差估计为:</p><figure class="kl km kn ko gt kp gh gi paragraph-image"><div role="button" tabindex="0" class="oe of di og bf oh"><div class="gh gi qj"><img src="../Images/cd9bbadfe45d83436bf1f917b99aa50c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*xWZvxMihp8P__qZq.png"/></div></div><figcaption class="oi oj gj gh gi ok ol bd b be z dk">LOOCV estimated error</figcaption></figure><p id="33d1" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">这仅仅是每次运行的误差的平均值。</p><p id="5144" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">这种方法要好得多，因为它的偏差要小得多，因为更多的观察数据被用来拟合模型。在训练/验证集分割中没有随机性。因此，我们降低了 MSE 的可变性，如下所示。</p><figure class="kl km kn ko gt kp gh gi paragraph-image"><div role="button" tabindex="0" class="oe of di og bf oh"><div class="gh gi pk"><img src="../Images/2adcbfca6e6aa7371d7d92fecb6c11f6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*JjLAPupIqqnM-SiR.png"/></div></div><figcaption class="oi oj gj gh gi ok ol bd b be z dk">MSE of LOOCV</figcaption></figure><h2 id="b66f" class="nr kt iv bd ku ns nt dn ky nu nv dp lc lr nw nx le lt ny nz lg lv oa ob li oc bi translated">k 倍交叉验证</h2><p id="b574" class="pw-post-body-paragraph mv mw iv lm b ln lo jw mx lp lq jz my lr mz na nb lt nc nd ne lv nf ng nh lx io bi translated">这种方法包括将一组观察值随机分成大约相等大小的<em class="om"> k </em>组或<strong class="lm iw">折叠</strong>。第一个折叠被视为验证集，模型适合其余的折叠。然后重复该过程<em class="om"> k </em>次，其中不同的组被视为验证集。</p><figure class="kl km kn ko gt kp gh gi paragraph-image"><div role="button" tabindex="0" class="oe of di og bf oh"><div class="gh gi pk"><img src="../Images/93fbd4f6db4441bd74267b7b8e4d6a53.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*_kcP-lsu9KS2z1e9.png"/></div></div><figcaption class="oi oj gj gh gi ok ol bd b be z dk">k-fold cross-validation schematic</figcaption></figure><p id="989a" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">因此，你意识到 LOOCV 是一个特殊的 k 重交叉验证案例，其中 k 等于观察总数 n(T21)。但是，通常将<em class="om"> k </em>设置为等于 5 或 10。</p><p id="0cc3" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">尽管 LOOCV 对于大型数据集来说是计算密集型的，但是 k-fold 更通用，可以用于任何模型。此外，它通常比 LOOCV 给出更准确的测试误差估计。因此，要评估和验证您的模型，k 倍交叉验证方法是最佳选择。</p><p id="313d" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">既然我们知道了交叉验证是如何工作的，以及它如何提高我们对模型性能的信心，那么让我们看看如何通过正则化来改进模型本身。</p><h1 id="ed7b" class="ks kt iv bd ku kv kw kx ky kz la lb lc kb ld kc le ke lf kf lg kh lh ki li lj bi translated">正则化理论</h1><p id="906c" class="pw-post-body-paragraph mv mw iv lm b ln lo jw mx lp lq jz my lr mz na nb lt nc nd ne lv nf ng nh lx io bi translated">正则化方法有效地防止了过度拟合。当模型在训练集上表现良好，但在验证集上表现不佳时，就会发生过度拟合。</p><p id="3a3f" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">我们已经看到，线性模型，如<a class="ae mc" rel="noopener" target="_blank" href="/the-complete-guide-to-linear-regression-in-python-3d3f8f06bf8">线性回归</a>和推而广之的<a class="ae mc" rel="noopener" target="_blank" href="/the-complete-guide-to-classification-in-python-b0e34c92e455">逻辑回归</a>，使用最小二乘法来估计参数。</p><p id="6a0a" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">现在，我们探索如何通过用其他拟合过程代替最小二乘拟合来改进线性模型。这些方法将产生更好的预测精度和模型可解释性。</p><p id="8eae" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">但是为什么呢？为什么要用其他拟合方式？</p><p id="757c" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">最小二乘拟合在大多数情况下是可行的，但也有失败的情况。</p><p id="b742" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">例如，如果您的观察值数量<em class="om"> n </em>大于预测值数量<em class="om"> p </em>，那么最小二乘估计将具有较低的方差，并且表现良好。另一方面，当<em class="om"> p </em>大于<em class="om"> n </em>(预测值多于观测值)时，方差为无穷大，该方法无法使用！</p><p id="4ad7" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">此外，多元线性回归往往会增加与响应实际不相关的变量。这给模型增加了不必要的复杂性。如果有一种方法可以自动执行特征选择，比如只包含最相关的变量，那就太好了。</p><p id="36d3" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">为了实现这一点，我们引入了<strong class="lm iw">岭回归</strong>和<strong class="lm iw">套索</strong>。这是两种常见的正则化方法，也称为<strong class="lm iw">收缩方法</strong>。</p><h2 id="0e17" class="nr kt iv bd ku ns nt dn ky nu nv dp lc lr nw nx le lt ny nz lg lv oa ob li oc bi translated">收缩方法</h2><p id="c91d" class="pw-post-body-paragraph mv mw iv lm b ln lo jw mx lp lq jz my lr mz na nb lt nc nd ne lv nf ng nh lx io bi translated">将估计的系数向 0 收缩可以显著提高拟合度并减少系数的方差。在这里，我们探讨<strong class="lm iw">岭回归</strong>和<strong class="lm iw">套索</strong>。</p><h2 id="8a2a" class="nr kt iv bd ku ns nt dn ky nu nv dp lc lr nw nx le lt ny nz lg lv oa ob li oc bi translated">里脊回归</h2><p id="9229" class="pw-post-body-paragraph mv mw iv lm b ln lo jw mx lp lq jz my lr mz na nb lt nc nd ne lv nf ng nh lx io bi translated">传统的线性拟合涉及最小化 RSS(残差平方和)。在岭回归中，添加了一个新参数，现在参数将最小化:</p><figure class="kl km kn ko gt kp gh gi paragraph-image"><div role="button" tabindex="0" class="oe of di og bf oh"><div class="gh gi qk"><img src="../Images/668650449d1d768ef5c20f528846a6eb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*VGAONEphX5ezauXe.png"/></div></div></figure><p id="056e" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">其中<em class="om">λ</em>为<strong class="lm iw">调谐参数</strong>。使用交叉验证找到该参数，因为它必须最小化测试误差。因此，<em class="om">λ</em>的范围用于拟合模型，并且使测试误差最小化的<em class="om">λ</em>是最佳值。</p><p id="0ec3" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">这里，岭回归将包括模型中所有的<em class="om"> p </em>预测值。因此，这是一种提高模型拟合度的好方法，但它不会执行变量选择。</p><h2 id="4fb6" class="nr kt iv bd ku ns nt dn ky nu nv dp lc lr nw nx le lt ny nz lg lv oa ob li oc bi translated">套索</h2><p id="5c96" class="pw-post-body-paragraph mv mw iv lm b ln lo jw mx lp lq jz my lr mz na nb lt nc nd ne lv nf ng nh lx io bi translated">与岭回归类似，套索将最小化:</p><figure class="kl km kn ko gt kp gh gi paragraph-image"><div role="button" tabindex="0" class="oe of di og bf oh"><div class="gh gi ql"><img src="../Images/49c8159d6e1374e56536c480d46cb999.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*_84LxzXHVjtKy0VJ.png"/></div></div></figure><p id="070d" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">注意，我们使用参数<em class="om">β</em>的绝对值，而不是它的平方值。此外，还存在相同的调谐参数。</p><p id="12b9" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">然而，如果<em class="om">λ</em>足够大，一些系数将有效地为 0！因此，lasso 还可以执行变量选择，使模型更容易解释。</p><h1 id="43b4" class="ks kt iv bd ku kv kw kx ky kz la lb lc kb ld kc le ke lf kf lg kh lh ki li lj bi translated">重采样和正则化-实践</h1><p id="e0dc" class="pw-post-body-paragraph mv mw iv lm b ln lo jw mx lp lq jz my lr mz na nb lt nc nd ne lv nf ng nh lx io bi translated">我们知道正则化和重采样是如何工作的。现在，让我们在项目设置中应用这些技术。</p><p id="ec64" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">打开 Jupyter 笔记本，获取数据集。如果你遇到困难，也可以使用<a class="ae mc" href="https://github.com/marcopeix/ISL-Ridge-Lasso" rel="noopener ugc nofollow" target="_blank">解决方案笔记本</a>。</p><h2 id="9396" class="nr kt iv bd ku ns nt dn ky nu nv dp lc lr nw nx le lt ny nz lg lv oa ob li oc bi translated">导入库</h2><p id="67ff" class="pw-post-body-paragraph mv mw iv lm b ln lo jw mx lp lq jz my lr mz na nb lt nc nd ne lv nf ng nh lx io bi translated">像任何项目一样，我们导入常用的库来帮助我们执行基本的数据操作和绘图。</p><figure class="kl km kn ko gt kp gh gi paragraph-image"><div role="button" tabindex="0" class="oe of di og bf oh"><div class="gh gi pk"><img src="../Images/57cc7c617bbae142dc55b35b78543902.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*OAqt3PajhLffjtjW.png"/></div></div></figure><p id="7599" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">现在，我们可以开始探索性的数据分析了。</p><h2 id="433b" class="nr kt iv bd ku ns nt dn ky nu nv dp lc lr nw nx le lt ny nz lg lv oa ob li oc bi translated">探索性数据分析</h2><p id="cece" class="pw-post-body-paragraph mv mw iv lm b ln lo jw mx lp lq jz my lr mz na nb lt nc nd ne lv nf ng nh lx io bi translated">我们从导入数据集开始，查看前五行:</p><figure class="kl km kn ko gt kp gh gi paragraph-image"><div role="button" tabindex="0" class="oe of di og bf oh"><div class="gh gi pk"><img src="../Images/c53bcef5668c5c07adb42406c0403011.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*mWco4zD-mCTvXpuz.png"/></div></div></figure><p id="a8b3" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">您应该看到:</p><figure class="kl km kn ko gt kp gh gi paragraph-image"><div role="button" tabindex="0" class="oe of di og bf oh"><div class="gh gi qm"><img src="../Images/d56534b63741ab5039b4cc690279e69a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*Y7vehpFyzbnRAkRQ.png"/></div></div></figure><p id="79f2" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">注意<em class="om">未命名:0 </em>列是无用的。让我们把它拿出来。</p><figure class="kl km kn ko gt kp gh gi paragraph-image"><div role="button" tabindex="0" class="oe of di og bf oh"><div class="gh gi pk"><img src="../Images/fca8acdf98f0754505bec813eb7959c4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*fVGu2M-RDH5iZDET.png"/></div></div></figure><p id="852a" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">现在，我们的数据集看起来像这样:</p><figure class="kl km kn ko gt kp gh gi paragraph-image"><div class="gh gi qn"><img src="../Images/629a58c3bd4fd6f85fedffa5dffed63b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1276/format:webp/0*c5l4TKyQtJJ1iK8R.png"/></div></figure><p id="f788" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">如你所见，我们只有三种广告媒体，而<em class="om">销售额</em>是我们的目标变量。</p><p id="cb20" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">让我们通过绘制散点图来看看每个变量是如何影响销售的。首先，我们构建一个辅助函数来绘制散点图:</p><figure class="kl km kn ko gt kp gh gi paragraph-image"><div role="button" tabindex="0" class="oe of di og bf oh"><div class="gh gi pk"><img src="../Images/61bb3c423e9fa676b1ed294842e16df2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*iENzKnbT2Y172QcQ.png"/></div></div></figure><p id="6280" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">现在，我们可以为每个特征生成三个不同的图。</p><figure class="kl km kn ko gt kp gh gi paragraph-image"><div role="button" tabindex="0" class="oe of di og bf oh"><div class="gh gi pk"><img src="../Images/3c560fe9c90525205881b8511a4ef232.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*LKPokucuDQo07WYI.png"/></div></div></figure><p id="d6c3" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">您会得到以下结果:</p><figure class="kl km kn ko gt kp gh gi paragraph-image"><div role="button" tabindex="0" class="oe of di og bf oh"><div class="gh gi pk"><img src="../Images/052c095aa9d5cf674e0684e0e9779f34.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*mU0CQ_LGIGn5dsDj.png"/></div></div><figcaption class="oi oj gj gh gi ok ol bd b be z dk">Sales with respect to money spend on TV ads</figcaption></figure><figure class="kl km kn ko gt kp gh gi paragraph-image"><div role="button" tabindex="0" class="oe of di og bf oh"><div class="gh gi pk"><img src="../Images/6cfc42f94dfaa6623f35e0336d280402.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*V4MzLF6TPWGWCCRC.png"/></div></div><figcaption class="oi oj gj gh gi ok ol bd b be z dk">Sales with respect to money spent on radio ads</figcaption></figure><figure class="kl km kn ko gt kp gh gi paragraph-image"><div role="button" tabindex="0" class="oe of di og bf oh"><div class="gh gi pk"><img src="../Images/0bf1d3a77fce9a6c753b62b694bdc6cc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*zVcQQVgCTKqNuAQU.png"/></div></div><figcaption class="oi oj gj gh gi ok ol bd b be z dk">Sales with respect to money spent on newspaper ads</figcaption></figure><p id="68a7" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">正如你所看到的，电视和广播广告似乎是销售的良好预测工具，而销售和报纸广告之间似乎没有相关性。</p><p id="6aed" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">幸运的是，我们的数据集不需要进一步处理，所以我们准备好马上开始建模了！</p><h2 id="324e" class="nr kt iv bd ku ns nt dn ky nu nv dp lc lr nw nx le lt ny nz lg lv oa ob li oc bi translated">多元线性回归—最小二乘拟合</h2><p id="e1e2" class="pw-post-body-paragraph mv mw iv lm b ln lo jw mx lp lq jz my lr mz na nb lt nc nd ne lv nf ng nh lx io bi translated">在浏览之前，让我们先看看代码是什么样子的。</p><figure class="kl km kn ko gt kp gh gi paragraph-image"><div role="button" tabindex="0" class="oe of di og bf oh"><div class="gh gi pk"><img src="../Images/e8042b755bc1448c9d2c86dd56204494.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*zveEHVctuAjxiDe_.png"/></div></div></figure><p id="7573" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">首先，我们导入<em class="om"> LinearRegression </em>和<em class="om"> cross_val_score </em>对象。第一个对象将允许我们拟合一个线性模型，而第二个对象将执行 k-fold 交叉验证。</p><p id="2ed3" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">然后，我们定义我们的特征和目标变量。</p><p id="25c3" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated"><em class="om"> cross_val_score </em>将为每个交叉验证步骤返回一个 MSE 数组。在我们的例子中，我们有五个。所以我们取 MSE 的平均值，打印出来。您应该得到-3.0729 的负 MSE。</p><p id="12ae" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">现在，我们来看看岭回归和套索哪个会更好。</p><h2 id="56a5" class="nr kt iv bd ku ns nt dn ky nu nv dp lc lr nw nx le lt ny nz lg lv oa ob li oc bi translated">里脊回归</h2><p id="a6fe" class="pw-post-body-paragraph mv mw iv lm b ln lo jw mx lp lq jz my lr mz na nb lt nc nd ne lv nf ng nh lx io bi translated">对于岭回归，我们引入<em class="om"> GridSearchCV </em>。这将允许我们使用一系列不同的正则化参数自动执行 5 重交叉验证，以便找到<em class="om">α</em>的最佳值。</p><p id="76ae" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">代码如下所示:</p><figure class="kl km kn ko gt kp gh gi paragraph-image"><div role="button" tabindex="0" class="oe of di og bf oh"><div class="gh gi pk"><img src="../Images/28da438c73f11549046771fd9c31a98e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*mTZvabmcSrG2N28d.png"/></div></div></figure><p id="8288" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">然后，我们可以通过以下公式找到最佳参数和最佳 MSE:</p><figure class="kl km kn ko gt kp gh gi paragraph-image"><div role="button" tabindex="0" class="oe of di og bf oh"><div class="gh gi pk"><img src="../Images/672004d91790b7af60177ca74cba4c5e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*HtgfxuGVKkM44M2y.png"/></div></div></figure><p id="5843" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">您应该看到<em class="om"> alpha </em>的最佳值是 20，MSE 为负-3.07267。这是对基本多元线性回归的一点改进。</p><h2 id="935a" class="nr kt iv bd ku ns nt dn ky nu nv dp lc lr nw nx le lt ny nz lg lv oa ob li oc bi translated">套索</h2><p id="ff96" class="pw-post-body-paragraph mv mw iv lm b ln lo jw mx lp lq jz my lr mz na nb lt nc nd ne lv nf ng nh lx io bi translated">对于 lasso，我们遵循与岭回归非常相似的过程:</p><figure class="kl km kn ko gt kp gh gi paragraph-image"><div role="button" tabindex="0" class="oe of di og bf oh"><div class="gh gi pk"><img src="../Images/f5f12e61f86e6eaa9aef738563f71203.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*I0MYCmmB2Miu0EMl.png"/></div></div></figure><p id="bb67" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">在这种情况下，<em class="om"> alpha </em>的最优值为 1，负的 MSE 为-3.0414，这是三个模型的最好成绩！</p><h1 id="4ab3" class="ks kt iv bd ku kv kw kx ky kz la lb lc kb ld kc le ke lf kf lg kh lh ki li lj bi translated">决策树——理论</h1><p id="a66b" class="pw-post-body-paragraph mv mw iv lm b ln lo jw mx lp lq jz my lr mz na nb lt nc nd ne lv nf ng nh lx io bi translated">基于树的方法可用于回归或分类。它们包括将预测空间分割成许多简单的区域。分割规则集可以总结为一棵树，因此被命名为<strong class="lm iw">决策树</strong>方法。</p><p id="648a" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">单个决策树往往不如<a class="ae mc" rel="noopener" target="_blank" href="/linear-regression-understanding-the-theory-7e53ac2831b5">线性回归</a>、<a class="ae mc" href="https://becominghuman.ai/classification-part-1-intro-to-logistic-regression-f6258791d309" rel="noopener ugc nofollow" target="_blank">逻辑回归</a>、<a class="ae mc" rel="noopener" target="_blank" href="/classification-part-2-linear-discriminant-analysis-ea60c45b9ee5"> LDA </a>等性能好。但是，通过引入 bagging、随机森林和 boosting，它可以显著提高预测的准确性，但会损失一些解释能力。</p><h2 id="171b" class="nr kt iv bd ku ns nt dn ky nu nv dp lc lr nw nx le lt ny nz lg lv oa ob li oc bi translated">回归树</h2><p id="ebaa" class="pw-post-body-paragraph mv mw iv lm b ln lo jw mx lp lq jz my lr mz na nb lt nc nd ne lv nf ng nh lx io bi translated">在进入理论之前，我们需要一些基本的术语。</p><p id="4f52" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">树是倒着画的。最后的区域被称为<em class="om">叶。</em>树内发生分裂的点是<em class="om">区间节点</em>。最后，连接节点的线段是<em class="om">分支</em>。</p><figure class="kl km kn ko gt kp gh gi paragraph-image"><div role="button" tabindex="0" class="oe of di og bf oh"><div class="gh gi qo"><img src="../Images/c0c71c4fa59786e5ba1e70565dce10d6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*LdIxINNr9KPGwcl0.png"/></div></div><figcaption class="oi oj gj gh gi ok ol bd b be z dk">Decision tree schematic</figcaption></figure><p id="1684" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">要创建回归树，请执行以下操作:</p><ol class=""><li id="6a65" class="lk ll iv lm b ln ni lp nj lr nn lt no lv np lx ly lz ma mb bi translated">将预测空间划分为<em class="om"> J </em>个不同且不重叠的区域</li><li id="0bb3" class="lk ll iv lm b ln md lp me lr mf lt mg lv mh lx ly lz ma mb bi translated">对于落在一个区域中的每个观察值，预测该区域中响应值的平均值</li></ol><p id="b681" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">每个区域被分割以最小化 RSS。为此，需要一种<strong class="lm iw">自顶向下的贪婪方法</strong>，也称为<em class="om">递归二进制分裂</em>。</p><p id="ef7e" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">为什么自上而下？</p><p id="c284" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">因为在第一次分裂之前，所有观测值都在单个区域中。</p><p id="2dc9" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">为什么是贪婪的方法？</p><p id="2e38" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">因为最佳分割发生在特定步骤，而不是向前看并进行分割，这将导致对未来步骤的更好预测。</p><p id="64bc" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">数学上，我们将这对半平面定义为:</p><figure class="kl km kn ko gt kp gh gi paragraph-image"><div role="button" tabindex="0" class="oe of di og bf oh"><div class="gh gi qp"><img src="../Images/f69bd7b6a4d5bced3713639523e98ffb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*9I8gVigKrPzNJV4D.png"/></div></div></figure><p id="b649" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">并且我们寻求<em class="om"> j </em>和<em class="om"> s </em>最小化:</p><figure class="kl km kn ko gt kp gh gi paragraph-image"><div role="button" tabindex="0" class="oe of di og bf oh"><div class="gh gi qp"><img src="../Images/2f066aeca0f186482a171426f19e179e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*pZDOQ8HXfY6N_ayk.png"/></div></div></figure><p id="388a" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">但是，这可能会导致过度拟合。修剪树将产生一个更小的子树，我们可以用交叉验证来验证它。</p><figure class="kl km kn ko gt kp gh gi paragraph-image"><div role="button" tabindex="0" class="oe of di og bf oh"><div class="gh gi qq"><img src="../Images/a53bd79216480180ed1a73138862a673.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*2uP-k_8tATkW2Wn2.png"/></div></div><figcaption class="oi oj gj gh gi ok ol bd b be z dk">Schematic of an unpruned tree</figcaption></figure><h2 id="e550" class="nr kt iv bd ku ns nt dn ky nu nv dp lc lr nw nx le lt ny nz lg lv oa ob li oc bi translated">分类树</h2><p id="bee4" class="pw-post-body-paragraph mv mw iv lm b ln lo jw mx lp lq jz my lr mz na nb lt nc nd ne lv nf ng nh lx io bi translated">分类树与回归树非常相似。但是，我们不能使用响应的平均值，所以我们现在预测一个区域中最常出现的类。当然，RSS 不能作为评判标准。相反，每次分割都是为了最小化<strong class="lm iw">分类错误率</strong>。</p><p id="1acc" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">分类错误率只是不属于最常见类别的区域中训练观察值的分数。</p><figure class="kl km kn ko gt kp gh gi paragraph-image"><div role="button" tabindex="0" class="oe of di og bf oh"><div class="gh gi qp"><img src="../Images/de9072d92dca885f0ea05f9cb487efe3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*2V0Yy1mJlGvg7ZYS.png"/></div></div><figcaption class="oi oj gj gh gi ok ol bd b be z dk">Classification error rate</figcaption></figure><p id="d13a" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">不幸的是，这对于植树来说不够灵敏。在实践中，还使用了另外两种方法。</p><p id="c118" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">还有<strong class="lm iw">基尼指数</strong>:</p><figure class="kl km kn ko gt kp gh gi paragraph-image"><div role="button" tabindex="0" class="oe of di og bf oh"><div class="gh gi qp"><img src="../Images/3684648290afc3251724b23935ba7e06.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*1-GZzISRcbU7rFeH.png"/></div></div><figcaption class="oi oj gj gh gi ok ol bd b be z dk">Gini index</figcaption></figure><p id="3f3f" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">这是对所有类别的总方差的度量。如你所见，如果比例接近 0 或 1，基尼指数会很小，所以它是一个很好的衡量<strong class="lm iw">节点纯度</strong>的指标。</p><p id="2b51" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">类似的基本原理适用于另一种称为<strong class="lm iw">交叉熵</strong>的方法:</p><figure class="kl km kn ko gt kp gh gi paragraph-image"><div role="button" tabindex="0" class="oe of di og bf oh"><div class="gh gi qp"><img src="../Images/f276ac9ae72afe75a58fdc80f2fca16a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*4Fdi7XM3oG5wgBzV.png"/></div></div><figcaption class="oi oj gj gh gi ok ol bd b be z dk">Cross-entropy</figcaption></figure><p id="12a4" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">既然我们已经看到了基本决策树是如何工作的，那么让我们来看看如何提高它的性能！</p><h2 id="5d44" class="nr kt iv bd ku ns nt dn ky nu nv dp lc lr nw nx le lt ny nz lg lv oa ob li oc bi translated">制袋材料</h2><p id="58c8" class="pw-post-body-paragraph mv mw iv lm b ln lo jw mx lp lq jz my lr mz na nb lt nc nd ne lv nf ng nh lx io bi translated">我们知道 bootstrap 可以计算任何感兴趣的量的标准差。对于决策树来说，方差非常大。因此，通过 bootstrap 聚合或<strong class="lm iw"> bagging </strong>，我们可以减少方差并提高决策树的性能。</p><p id="8ebb" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">装袋包括从数据集中重复提取样本。这产生了<em class="om"> B </em>不同的引导训练集。然后，我们对所有自举训练集进行训练，以获得每个集的预测，并对这些预测进行平均。</p><p id="a675" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">数学上，平均预测是:</p><figure class="kl km kn ko gt kp gh gi paragraph-image"><div role="button" tabindex="0" class="oe of di og bf oh"><div class="gh gi qp"><img src="../Images/d7e6006a8b2b7c68d25485bc7559b1cc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*i2JAouQzPxTbPs6N.png"/></div></div></figure><p id="2e92" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">将此应用于决策树，这意味着我们可以构建大量具有高方差和低偏差的树。然后，我们可以对他们的预测进行平均，以减少方差，从而提高决策树的性能。</p><h2 id="dd95" class="nr kt iv bd ku ns nt dn ky nu nv dp lc lr nw nx le lt ny nz lg lv oa ob li oc bi translated">随机森林</h2><p id="57e7" class="pw-post-body-paragraph mv mw iv lm b ln lo jw mx lp lq jz my lr mz na nb lt nc nd ne lv nf ng nh lx io bi translated">随机森林通过一个小调整提供了对袋装树的改进，这个小调整解除了树木之间的关联。</p><p id="7618" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">像装袋一样，建立多个决策树。然而，在每次分割时，从所有的<em class="om"> p </em>预测值中选择一个随机样本<em class="om"> m </em>预测值。分割只允许使用一个<em class="om"> m </em>预测器，通常:</p><figure class="kl km kn ko gt kp gh gi paragraph-image"><div class="gh gi qr"><img src="../Images/e03c2e4193a8bda4b6c4f910943f239c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1080/format:webp/0*wRSoX8NHYV_rhrnv.png"/></div></figure><p id="084d" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">换句话说，在每次分割时，不允许算法考虑大多数可用的预测值！</p><p id="f4c0" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">为什么？</p><p id="9bb5" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">假设数据集中有一个非常强的预测因子，以及其他中等强度的预测因子。然后在套袋树的采集中，他们都会在顶裂中使用这个强预测器。因此，所有装袋的树将非常相似，平均它们的预测不会减少方差，因为预测将高度相关。</p><p id="5dfa" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">随机森林通过强制每次分割只考虑有效地<em class="om">去相关</em>树的预测子集合来克服这个问题。</p><p id="0876" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">当然，如果<em class="om"> m </em>等于<em class="om"> p </em>，那么就跟装袋一样。通常情况下，<em class="om"> p </em>的平方根给出的结果最好，如下图所示。</p><figure class="kl km kn ko gt kp gh gi paragraph-image"><div role="button" tabindex="0" class="oe of di og bf oh"><div class="gh gi qs"><img src="../Images/6085e27470410513d8c4fa568486a181.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*FzUsprlOJN6M-E6g.png"/></div></div><figcaption class="oi oj gj gh gi ok ol bd b be z dk">Classification error as a function of the number of trees. Each line represents the number of predictors available at each split.</figcaption></figure><h2 id="9ce5" class="nr kt iv bd ku ns nt dn ky nu nv dp lc lr nw nx le lt ny nz lg lv oa ob li oc bi translated">助推</h2><p id="4bbd" class="pw-post-body-paragraph mv mw iv lm b ln lo jw mx lp lq jz my lr mz na nb lt nc nd ne lv nf ng nh lx io bi translated">Boosting 的工作方式与 bagging 类似，但树是按顺序生长的:每棵树都使用来自先前生长的树的信息。</p><p id="be8e" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">这意味着算法慢慢地学习<em class="om"/>。每棵树都适合模型的残差，而不是目标变量。因此，每棵树都很小，在表现不好的地方会慢慢改善预测。</p><p id="e1e3" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">升压有三个调整参数:</p><p id="9ff2" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">1.树的数量(<strong class="lm iw"> <em class="om"> B </em> </strong>):与套袋和随机森林不同，如果<em class="om"> B </em>太大，boosting 可能会溢出。使用交叉验证来选择正确的树的数量。</p><p id="8b68" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">2.收缩参数(<strong class="lm iw"> <em class="om"> alpha </em> </strong>):控制 boosting 学习速率的小正数。它通常设置为 0.01 或 0.001。</p><p id="49b4" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">3.每棵树的分裂数(<strong class="lm iw"> <em class="om"> d </em> </strong>):它控制增强整体的复杂度。通常，单个拆分(<em class="om"> d </em> = 1)效果很好。它也被称为<strong class="lm iw"><em class="om"/></strong><em class="om">。</em></p><figure class="kl km kn ko gt kp gh gi paragraph-image"><div role="button" tabindex="0" class="oe of di og bf oh"><div class="gh gi qt"><img src="../Images/d5c0174602b6b15af440d2c0926f23a5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*M075e1IBc3GbZAuY.png"/></div></div><figcaption class="oi oj gj gh gi ok ol bd b be z dk">Classification error as a function of the number of trees. Each line represents a different interaction depth.</figcaption></figure><p id="d5cf" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">正如你在上面看到的，交互深度为 1 似乎给出了最好的结果。</p><h1 id="d1e8" class="ks kt iv bd ku kv kw kx ky kz la lb lc kb ld kc le ke lf kf lg kh lh ki li lj bi translated">决策树—实践</h1><p id="2f11" class="pw-post-body-paragraph mv mw iv lm b ln lo jw mx lp lq jz my lr mz na nb lt nc nd ne lv nf ng nh lx io bi translated">现在，让我们应用我们所学的知识来预测乳腺癌。许多关于乳腺癌的数据集包含关于肿瘤的信息。然而，我很幸运地找到了一个数据集，其中包含了乳腺癌患者和非乳腺癌患者的常规血液检查信息。潜在地，如果我们能够准确地预测一个病人是否患有癌症，那么这个病人可以接受非常早期的治疗，甚至在肿瘤被发现之前！</p><p id="db22" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">当然，数据集和完整的笔记本都可以在这里<a class="ae mc" href="https://github.com/marcopeix/ISL-Decision-Trees" rel="noopener ugc nofollow" target="_blank">获得</a>，我强烈建议你也一起编码。</p><h2 id="ba9d" class="nr kt iv bd ku ns nt dn ky nu nv dp lc lr nw nx le lt ny nz lg lv oa ob li oc bi translated">探索性数据分析</h2><p id="7022" class="pw-post-body-paragraph mv mw iv lm b ln lo jw mx lp lq jz my lr mz na nb lt nc nd ne lv nf ng nh lx io bi translated">在开始 Jupyter 的工作之前，我们可以在这里获得关于数据集<a class="ae mc" href="https://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Coimbra" rel="noopener ugc nofollow" target="_blank">的信息。</a></p><p id="9c1d" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">首先，您会注意到数据集非常小，只有 116 个实例。这带来了几个挑战，因为决策树可能会过度拟合数据，或者由于缺乏其他观察，我们的预测模型可能不是最好的。然而，这是一个很好的概念验证，可能证明通过简单的血液测试预测乳腺癌的真正潜力。</p><p id="2374" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">数据集仅包含以下十个属性:</p><p id="4eec" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">1.年龄:患者的年龄(岁)</p><p id="45e4" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">2.身体质量指数:体重指数(千克/米)</p><p id="91e6" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">3.葡萄糖:血液中的葡萄糖浓度(毫克/分升)</p><p id="c86e" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">4.胰岛素:血液中的胰岛素浓度(微单位/毫升)</p><p id="17d7" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">5.HOMA:胰岛素抵抗的稳态模型评估(<em class="om">葡萄糖</em>乘以<em class="om">胰岛素</em></p><p id="d761" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">6.瘦素:能量消耗激素瘦素的浓度(ng/mL)</p><p id="54ea" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">7.脂联素:脂联素的浓度——一种调节葡萄糖水平的蛋白质(微克/毫升)</p><p id="ea99" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">8.抵抗素:抵抗素的浓度——脂肪组织分泌的一种蛋白质(ng/mL)</p><p id="dd8f" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">9.MCP . 1:MCP-1 的浓度——一种由于组织损伤或炎症而将单核细胞募集到炎症部位的蛋白质(pg/dL)</p><p id="589a" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">10.分类:健康对照(1)或患者(2)</p><p id="2423" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">现在我们知道了我们将使用什么，我们可以从导入我们常用的库开始:</p><figure class="kl km kn ko gt kp gh gi paragraph-image"><div role="button" tabindex="0" class="oe of di og bf oh"><div class="gh gi qp"><img src="../Images/d173c69bde718b213ab301a182ce1a46.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*WNIyXR7ExHTmK3s9.png"/></div></div></figure><p id="1182" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">然后，定义数据集的路径，让我们预览一下:</p><figure class="kl km kn ko gt kp gh gi paragraph-image"><div role="button" tabindex="0" class="oe of di og bf oh"><div class="gh gi qp"><img src="../Images/7fdedf8c0dfd5881b7a0961c2f0399c8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*pQMUMZUhWZ4c2Xnw.png"/></div></div></figure><p id="3867" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">太好了！现在，因为这是一个分类问题，所以让我们看看这些类别是否平衡:</p><figure class="kl km kn ko gt kp gh gi paragraph-image"><div role="button" tabindex="0" class="oe of di og bf oh"><div class="gh gi qp"><img src="../Images/d0661d292dc5eb45476fa1e4ab0ef361.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*QbkkmZBh-ZecO5i6.png"/></div></div></figure><p id="b7ea" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">结果应该是:</p><figure class="kl km kn ko gt kp gh gi paragraph-image"><div role="button" tabindex="0" class="oe of di og bf oh"><div class="gh gi qu"><img src="../Images/9fc753ed1070cf89bb544fae6e4da26e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*y7lcBKjTbyNj0b9B.png"/></div></div></figure><p id="d7fe" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">如你所见，病人和健康对照的数量几乎相同。</p><p id="a05b" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">现在，看看健康人和病人的每个特征的分布和密度会很有趣。为此，一个<strong class="lm iw">小提琴情节</strong>是理想的。它显示了单一地块中要素的密度和分布。让我们有九个小提琴情节:每个特征一个:</p><figure class="kl km kn ko gt kp gh gi paragraph-image"><div role="button" tabindex="0" class="oe of di og bf oh"><div class="gh gi qp"><img src="../Images/5f0a7d4055d047e4e794260e7ac9cd9e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*CbhoK6EMl53Bqp3T.png"/></div></div></figure><p id="c9d9" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">花点时间回顾一下所有的图，试着找出健康对照和患者之间的一些差异。</p><p id="2690" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">最后，让我们检查一下是否有丢失的值:</p><figure class="kl km kn ko gt kp gh gi paragraph-image"><div role="button" tabindex="0" class="oe of di og bf oh"><div class="gh gi qp"><img src="../Images/3d42006fc83b7ecaddf5b2faa4295bb9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*JEfyZZmkgIEqyliY.png"/></div></div></figure><p id="dd05" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">您应该看到没有一列缺少值！我们现在准备开始建模！</p><h1 id="ed19" class="ks kt iv bd ku kv kw kx ky kz la lb lc kb ld kc le ke lf kf lg kh lh ki li lj bi translated">系统模型化</h1><p id="f0e3" class="pw-post-body-paragraph mv mw iv lm b ln lo jw mx lp lq jz my lr mz na nb lt nc nd ne lv nf ng nh lx io bi translated">首先，我们需要将类编码为 0 和 1:</p><figure class="kl km kn ko gt kp gh gi paragraph-image"><div role="button" tabindex="0" class="oe of di og bf oh"><div class="gh gi qp"><img src="../Images/8eda354d6849b3ed95b4fead5474a65a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*uo7xChf3250AeCCu.png"/></div></div></figure><p id="4e79" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">现在，0 代表健康对照，1 代表病人。</p><p id="51f7" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">然后，我们将数据集分为训练集和测试集:</p><figure class="kl km kn ko gt kp gh gi paragraph-image"><div role="button" tabindex="0" class="oe of di og bf oh"><div class="gh gi qp"><img src="../Images/147ba4355fe00df482d7d93f5d43ce11.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*T2FOl4YS7OVVrSEH.png"/></div></div></figure><p id="f259" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">在编写模型之前，我们需要定义适当的误差度量。在这种情况下，由于这是一个分类问题，我们可以使用<strong class="lm iw">混淆矩阵</strong>并使用分类误差。让我们编写一个帮助函数来绘制混淆矩阵:</p><figure class="kl km kn ko gt kp gh gi paragraph-image"><div role="button" tabindex="0" class="oe of di og bf oh"><div class="gh gi qp"><img src="../Images/ce6676ed4a37d96b818d2513829b38f8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*lRsjOkT5t-sqDSip.png"/></div></div></figure><p id="ca17" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">厉害！现在，让我们实现一个决策树。</p><h2 id="db27" class="nr kt iv bd ku ns nt dn ky nu nv dp lc lr nw nx le lt ny nz lg lv oa ob li oc bi translated">决策图表</h2><p id="fc3b" class="pw-post-body-paragraph mv mw iv lm b ln lo jw mx lp lq jz my lr mz na nb lt nc nd ne lv nf ng nh lx io bi translated">使用<em class="om"> scikit-learn </em>，决策树很容易实现:</p><figure class="kl km kn ko gt kp gh gi paragraph-image"><div role="button" tabindex="0" class="oe of di og bf oh"><div class="gh gi qp"><img src="../Images/f47dbc8086c10d90a91fa338638fdb89.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*af3q9VbOwtDAK0Ku.png"/></div></div></figure><p id="d1eb" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">您应该得到以下混淆矩阵:</p><figure class="kl km kn ko gt kp gh gi paragraph-image"><div class="gh gi qv"><img src="../Images/4fdc3d25264da64c7d59c5789a7cefd5.png" data-original-src="https://miro.medium.com/v2/resize:fit:60/0*tuVn0D_Ab9qKcPyN"/></div></figure><figure class="kl km kn ko gt kp gh gi paragraph-image"><div role="button" tabindex="0" class="oe of di og bf oh"><div class="gh gi qw"><img src="../Images/825dbc72ef8467c1642b9672e5493487.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*06GkFRt8ZXtzoWrO.png"/></div></div></figure><p id="c664" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">如您所见，它错误地分类了三个实例。因此，我们来看看套袋、助推或随机森林是否能提高树的性能。</p><h2 id="8e7b" class="nr kt iv bd ku ns nt dn ky nu nv dp lc lr nw nx le lt ny nz lg lv oa ob li oc bi translated">制袋材料</h2><p id="47a5" class="pw-post-body-paragraph mv mw iv lm b ln lo jw mx lp lq jz my lr mz na nb lt nc nd ne lv nf ng nh lx io bi translated">为了实现带有 bagging 的决策树，我们编写以下代码:</p><figure class="kl km kn ko gt kp gh gi paragraph-image"><div role="button" tabindex="0" class="oe of di og bf oh"><div class="gh gi qp"><img src="../Images/8d27e844c3c7dc0e4f6d0d1bf6012f3c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*Yh2rjn5MdE43Zoc2.png"/></div></div></figure><p id="077c" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">你会得到下面的混淆矩阵:</p><figure class="kl km kn ko gt kp gh gi paragraph-image"><div role="button" tabindex="0" class="oe of di og bf oh"><div class="gh gi qx"><img src="../Images/69b1b29cae1e85dca3ca0d789b8b9057.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*0x7A0y0JB_7Fr_qf.png"/></div></div></figure><p id="2e9a" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">太神奇了！该模型对测试集中的所有实例进行了正确分类！为了得到更多的练习，让我们也实现一个随机森林分类器并使用 boosting。</p><h2 id="8b61" class="nr kt iv bd ku ns nt dn ky nu nv dp lc lr nw nx le lt ny nz lg lv oa ob li oc bi translated">随机森林分类器</h2><p id="3182" class="pw-post-body-paragraph mv mw iv lm b ln lo jw mx lp lq jz my lr mz na nb lt nc nd ne lv nf ng nh lx io bi translated">这里，对于随机森林分类器，我们指定我们想要的树的数量。让我们用 100:</p><figure class="kl km kn ko gt kp gh gi paragraph-image"><div class="gh gi qv"><img src="../Images/2c31af6cdc9144666d1118ae4dfd2099.png" data-original-src="https://miro.medium.com/v2/resize:fit:60/0*eH6I5raMUAy9_ev1"/></div></figure><figure class="kl km kn ko gt kp gh gi paragraph-image"><div role="button" tabindex="0" class="oe of di og bf oh"><div class="gh gi qp"><img src="../Images/67c9aaf3b01a4bc53b686869085cf423.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*GNRGdYY-4N7sDkCJ.png"/></div></div></figure><p id="f55e" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">你会得到这个混乱矩阵:</p><figure class="kl km kn ko gt kp gh gi paragraph-image"><div role="button" tabindex="0" class="oe of di og bf oh"><div class="gh gi qy"><img src="../Images/cc49790e34bd5cc714a803ceb97619f6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*m_Nwya1nDXLtYhSh.png"/></div></div></figure><p id="8432" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">在这里，虽然只有一个实例被错误分类，但是模型实际上说一个病人是健康的，而实际上这个人患有癌症！这是非常不理想的情况。</p><h2 id="15f6" class="nr kt iv bd ku ns nt dn ky nu nv dp lc lr nw nx le lt ny nz lg lv oa ob li oc bi translated">助推</h2><p id="c709" class="pw-post-body-paragraph mv mw iv lm b ln lo jw mx lp lq jz my lr mz na nb lt nc nd ne lv nf ng nh lx io bi translated">最后，对于升压:</p><figure class="kl km kn ko gt kp gh gi paragraph-image"><div role="button" tabindex="0" class="oe of di og bf oh"><div class="gh gi qp"><img src="../Images/380fceec4ad130f62c1eaea2159afcfe.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*NZxmltgPESfTWbBb.png"/></div></div></figure><p id="4f81" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">我们得到了以下结果:</p><figure class="kl km kn ko gt kp gh gi paragraph-image"><div role="button" tabindex="0" class="oe of di og bf oh"><div class="gh gi qz"><img src="../Images/98c7ba6daf904a96ad649e6fbcec78b8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*2ywit4JTAGkTyYSV.png"/></div></div></figure><p id="c57d" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">同样，只有一个实例被错误分类。</p><h1 id="270d" class="ks kt iv bd ku kv kw kx ky kz la lb lc kb ld kc le ke lf kf lg kh lh ki li lj bi translated">支持向量机(SVM)——理论</h1><p id="933b" class="pw-post-body-paragraph mv mw iv lm b ln lo jw mx lp lq jz my lr mz na nb lt nc nd ne lv nf ng nh lx io bi translated">我们已经看到了如何使用<a class="ae mc" rel="noopener" target="_blank" href="/the-complete-guide-to-classification-in-python-b0e34c92e455">逻辑回归、LDA </a>和<a class="ae mc" rel="noopener" target="_blank" href="/the-complete-guide-to-decision-trees-17a874301448">决策树</a>处理分类问题。现在，又引入了另一个分类工具:<strong class="lm iw">支持向量机</strong>。</p><p id="f652" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">支持向量机是一种称为<strong class="lm iw">最大间隔分类器</strong>的分类器的推广。最大间隔分类器很简单，但它不能应用于大多数数据集，因为类必须由线性边界分隔。</p><p id="b23f" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">这就是为什么<strong class="lm iw">支持向量分类器</strong>被引入作为最大间隔分类器的扩展，其可以应用于更广泛的情况。</p><p id="94fe" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">最后，<strong class="lm iw">支持向量机</strong>只是支持向量分类器的进一步扩展，以适应非线性类边界。</p><p id="4aba" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">它可用于二元或多元分类。</p><p id="c8aa" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">解释支持向量机的理论非常专业。希望这篇文章能让你更容易理解支持向量机是如何工作的。</p><h2 id="5b27" class="nr kt iv bd ku ns nt dn ky nu nv dp lc lr nw nx le lt ny nz lg lv oa ob li oc bi translated">最大间隔分类器</h2><p id="63b3" class="pw-post-body-paragraph mv mw iv lm b ln lo jw mx lp lq jz my lr mz na nb lt nc nd ne lv nf ng nh lx io bi translated">这种方法依赖于使用超平面来分离类。</p><p id="ba90" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">什么是超平面？</p><p id="d28c" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">在<em class="om"> p </em>维空间中，超平面是维数为<em class="om"> p-1 </em>的平坦仿射子空间。视觉上，在 2D 空间中，超平面将是一条线，而在 3D 空间中，它将是一个平面。</p><p id="ab03" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">数学上，超平面简单地说就是:</p><figure class="kl km kn ko gt kp gh gi paragraph-image"><div class="gh gi ra"><img src="../Images/dbc14ed950161a3be9dba414c1ff9293.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*t3whKMPgUO5uGe3G.png"/></div><figcaption class="oi oj gj gh gi ok ol bd b be z dk">General hyperplane equation</figcaption></figure><p id="1585" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">如果<em class="om"> X </em>满足上式，则该点位于平面上。否则，它必须在平面的一侧，如下图所示。</p><figure class="kl km kn ko gt kp gh gi paragraph-image"><div class="gh gi ra"><img src="../Images/49a3963427e05c098766158a070419be.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*TTzx4tTIVewZO431.png"/></div><figcaption class="oi oj gj gh gi ok ol bd b be z dk">The line represents a hyperplane in a 2D space. Points that satisfy the equation above will lie on the line, while others are on one side of the plane.</figcaption></figure><p id="d1e5" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">一般来说，如果可以使用超平面完美地分离数据，那么就有无限数量的超平面，因为它们可以向上或向下移动，或者稍微旋转，而不会接触到观察结果。</p><p id="2baf" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">这就是为什么我们使用<strong class="lm iw">最大间隔超平面</strong>或<em class="om">最佳分离超平面</em>的原因，最佳分离超平面是离观察值最远的分离超平面。我们从给定超平面的每个训练观察计算垂直距离。这就是所谓的<strong class="lm iw">余量</strong>。因此，最优分离超平面是具有最大余量的超平面。</p><figure class="kl km kn ko gt kp gh gi paragraph-image"><div class="gh gi ra"><img src="../Images/084c082986d999be33444dbbfe3e7c25.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*JRvfsB33_IgRoak4.png"/></div><figcaption class="oi oj gj gh gi ok ol bd b be z dk">Example of a maximal margin hyperplane</figcaption></figure><p id="cbc3" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">正如你在上面看到的，有三个点与超平面等距。这些观察结果被称为<strong class="lm iw">支持向量</strong>，因为如果它们的位置移动，超平面也会移动。有趣的是，这意味着超平面仅依赖于支持向量，而不依赖于任何其他观察。</p><p id="3a02" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">如果不存在分离平面呢？</p><figure class="kl km kn ko gt kp gh gi paragraph-image"><div class="gh gi ra"><img src="../Images/e11a998c4bab15ba7738d7cb737b820d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*9BFsS-jU_AoM1_WN.png"/></div><figcaption class="oi oj gj gh gi ok ol bd b be z dk">Overlapping classes where no separating hyperplane exists</figcaption></figure><p id="9ddb" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">在这种情况下，没有最大间隔分类器。我们使用一个支持向量分类器，该分类器使用一个被称为<strong class="lm iw">支持向量分类器的<em class="om">软余量</em>来<em class="om">几乎</em>分离类别。</strong>然而，进一步讨论这种方法变得非常技术性，因为它不是最理想的方法，我们现在将跳过这个主题。</p><h2 id="0904" class="nr kt iv bd ku ns nt dn ky nu nv dp lc lr nw nx le lt ny nz lg lv oa ob li oc bi translated">支持向量机(SVM)</h2><p id="0205" class="pw-post-body-paragraph mv mw iv lm b ln lo jw mx lp lq jz my lr mz na nb lt nc nd ne lv nf ng nh lx io bi translated">支持向量机是支持向量分类器的扩展，通过使用<strong class="lm iw">内核</strong>来扩大特征空间。核方法只是一种有效的计算方法，用于适应类之间的非线性边界。</p><p id="e771" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">在不涉及技术细节的情况下，核是量化两个观察的相似性的函数。内核可以是任何程度的。使用度大于 1 的核导致更灵活的决策边界，如下所示。</p><figure class="kl km kn ko gt kp gh gi paragraph-image"><div class="gh gi ra"><img src="../Images/80d754b0335f90b988f8d379503dc718.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*hpelHCf3FhFvzuVe.png"/></div><figcaption class="oi oj gj gh gi ok ol bd b be z dk">Example of classification with SVM</figcaption></figure><p id="24eb" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">为了更好地理解内核的选择如何影响 SVM 算法，让我们在四个不同的场景中实现它。</p><h1 id="d4e4" class="ks kt iv bd ku kv kw kx ky kz la lb lc kb ld kc le ke lf kf lg kh lh ki li lj bi translated">支持向量机(SVM)-实践</h1><p id="9424" class="pw-post-body-paragraph mv mw iv lm b ln lo jw mx lp lq jz my lr mz na nb lt nc nd ne lv nf ng nh lx io bi translated">这个项目分为四个小项目。</p><p id="c737" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">第一部分将展示如何使用线性核执行分类，以及正则化参数<em class="om"> C </em>如何影响得到的<strong class="lm iw">超平面</strong>。</p><p id="1eb6" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">然后，第二部分将展示如何使用<strong class="lm iw">高斯核</strong>生成一个非线性超平面。</p><p id="c731" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">第三部分模拟重叠类，我们将使用<strong class="lm iw">交叉验证</strong>来找到 SVM 的最佳参数。</p><p id="da6f" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">最后，我们使用 SVM 执行了一个非常简单的垃圾邮件分类器。</p><blockquote class="rb rc rd"><p id="b043" class="mv mw om lm b ln ni jw mx lp nj jz my re nk na nb rf nl nd ne rg nm ng nh lx io bi translated">以上练习摘自吴恩达在 Coursera 上的免费课程。我简单用 Python 解决，导师不推荐。尽管如此，我还是向所有初学者强烈推荐这门课程。</p></blockquote><p id="2386" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">一如既往，笔记本和资料在这里<a class="ae mc" href="https://github.com/marcopeix/ISL-SVM?source=post_page---------------------------" rel="noopener ugc nofollow" target="_blank">可用</a>。</p><h2 id="b9b7" class="nr kt iv bd ku ns nt dn ky nu nv dp lc lr nw nx le lt ny nz lg lv oa ob li oc bi translated">迷你项目 1——线性核 SVM</h2><p id="c2fe" class="pw-post-body-paragraph mv mw iv lm b ln lo jw mx lp lq jz my lr mz na nb lt nc nd ne lv nf ng nh lx io bi translated">在我们开始之前，让我们导入一些有用的库:</p><figure class="kl km kn ko gt kp gh gi paragraph-image"><div class="gh gi ra"><img src="../Images/632fee737e10eeb45cb501e44067c662.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*pMpsjwSXiNIkQqRR.png"/></div></figure><p id="cf14" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">注意，我们在这里导入了<em class="om"> loadmat </em>，因为我们的数据是矩阵形式的。</p><p id="33a3" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">然后，我们将数据集的路径存储在不同的变量中:</p><figure class="kl km kn ko gt kp gh gi paragraph-image"><div class="gh gi ra"><img src="../Images/c2a26d5378c538e4e5b2b5c253eb75ec.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*uFEXCEiwEMw1Lxck.png"/></div></figure><p id="cd86" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">最后，我们将构建一个函数来帮助我们快速绘制每个数据集:</p><figure class="kl km kn ko gt kp gh gi paragraph-image"><div class="gh gi ra"><img src="../Images/69e71a7027b84de3dc56fc89ef8d8486.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*767xNFH8eMif01d0.png"/></div></figure><p id="be07" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">完美！</p><p id="d9b1" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">现在，在这一部分，我们将使用线性核实现一个支持向量机，我们将看到正则化参数如何影响超平面。</p><p id="f172" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">首先，让我们加载并可视化数据:</p><figure class="kl km kn ko gt kp gh gi paragraph-image"><div class="gh gi ra"><img src="../Images/f8aaff9fefb72dd99aee105e6e6cfd97.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*eBTs9v1Qf4CSh7bZ.png"/></div></figure><p id="3256" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">您应该会看到:</p><figure class="kl km kn ko gt kp gh gi paragraph-image"><div class="gh gi ra"><img src="../Images/203882e3f3fcd5cd7a216fc97de8c8c6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*KPGZSH3YxxhIObYa.png"/></div></figure><p id="576c" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated"><strong class="lm iw">注意上图左侧的异常值</strong>。让我们看看正则化参数在存在异常值时将如何影响超平面。</p><figure class="kl km kn ko gt kp gh gi paragraph-image"><div class="gh gi ra"><img src="../Images/e9053b18a78180b8aa514a8aa05cc6df.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*lTpZ5N3-68ZUJVPz.png"/></div></figure><p id="a911" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">上面的代码块简单地将 SVM 拟合到数据中，我们使用预测来绘制超平面。注意，我们使用正则化参数 1。结果应该如下所示:</p><figure class="kl km kn ko gt kp gh gi paragraph-image"><div class="gh gi ra"><img src="../Images/8080c44bd58e65b06f3108e875859aec.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*uYcPNs9ABL6rrovZ.png"/></div><figcaption class="oi oj gj gh gi ok ol bd b be z dk">Hyperplane with C=1</figcaption></figure><p id="f6ca" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">如你所见，超平面忽略了异常值。因此，较低正则化参数将被<strong class="lm iw">更好地概括</strong>。测试误差通常会高于交叉验证误差。</p><p id="c56c" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">现在，让我们增加正则化参数:</p><figure class="kl km kn ko gt kp gh gi paragraph-image"><div role="button" tabindex="0" class="oe of di og bf oh"><div class="gh gi ra"><img src="../Images/a8634a88d3182bbf12e77e480060a56d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*ucUbRhQBkAm5O8cO.png"/></div></div></figure><p id="d6bb" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">你会得到:</p><figure class="kl km kn ko gt kp gh gi paragraph-image"><div class="gh gi ra"><img src="../Images/713a3ba14e902944bf3866403c2e132a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*EpHEwA7KYASjqIOQ.png"/></div><figcaption class="oi oj gj gh gi ok ol bd b be z dk">Hyperplane with C=100</figcaption></figure><p id="f7dd" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">现在，异常值在超平面的右侧，但这也意味着我们过度拟合了。最终，这个边界在未观察到的数据上表现不好。</p><h2 id="6cd2" class="nr kt iv bd ku ns nt dn ky nu nv dp lc lr nw nx le lt ny nz lg lv oa ob li oc bi translated">迷你项目 2——高斯核 SVM</h2><p id="2230" class="pw-post-body-paragraph mv mw iv lm b ln lo jw mx lp lq jz my lr mz na nb lt nc nd ne lv nf ng nh lx io bi translated">现在，我们知道为了适应非线性边界，我们需要改变核函数。在这个练习中，我们将使用一个高斯内核。</p><p id="badf" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">首先，让我们绘制我们的数据:</p><figure class="kl km kn ko gt kp gh gi paragraph-image"><div class="gh gi ra"><img src="../Images/81378a0680669a5380fbad3a9a1e7065.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*nCUd_mIlB6p9xhGL.png"/></div></figure><p id="164a" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">您应该会看到:</p><figure class="kl km kn ko gt kp gh gi paragraph-image"><div class="gh gi ra"><img src="../Images/dd13ed3c92d7ae377dee495f3cba92e5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*sXhgwHIC6ffxYYy6.png"/></div></figure><p id="27f3" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">在实现 SVM 之前，您应该知道高斯核表示为:</p><figure class="kl km kn ko gt kp gh gi paragraph-image"><div class="gh gi ra"><img src="../Images/c5445d79945ffe07455873dee6d81ce4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*LA6d3dndsv8kZa0i.png"/></div><figcaption class="oi oj gj gh gi ok ol bd b be z dk">Gaussian kernel function</figcaption></figure><p id="3277" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">注意，有一个参数<em class="om"> sigma </em>决定了当它们相距较远时，相似性度量多快变为零。</p><p id="f9e0" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">因此，我们用以下代码实现它:</p><figure class="kl km kn ko gt kp gh gi paragraph-image"><div class="gh gi ra"><img src="../Images/59e575514fdb431eb24e7b50372467ec.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*D5NGM4-2fsqVNDJ-.png"/></div></figure><p id="a3b0" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">你应该得到下面的超平面:</p><figure class="kl km kn ko gt kp gh gi paragraph-image"><div role="button" tabindex="0" class="oe of di og bf oh"><div class="gh gi ra"><img src="../Images/76d90697215309e58c786ce98aac8932.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*ZgA6THxRz6Bma7lj.png"/></div></div><figcaption class="oi oj gj gh gi ok ol bd b be z dk">Non-linear hyperplane with a Gaussian kernel</figcaption></figure><p id="68b6" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">太神奇了！超平面不是一个完美的边界，但它在分类大多数数据方面做得很好。我建议你尝试不同的<em class="om"> sigma </em>值，看看它是如何影响超平面的。</p><h2 id="65c6" class="nr kt iv bd ku ns nt dn ky nu nv dp lc lr nw nx le lt ny nz lg lv oa ob li oc bi translated">迷你项目 3——交叉验证的 SVM</h2><p id="a617" class="pw-post-body-paragraph mv mw iv lm b ln lo jw mx lp lq jz my lr mz na nb lt nc nd ne lv nf ng nh lx io bi translated"><a class="ae mc" rel="noopener" target="_blank" href="/the-complete-guide-to-resampling-methods-and-regularization-in-python-5037f4f8ae23">交叉验证</a>对于从我们的模型中选择最佳性能的最佳调整参数至关重要。让我们看看如何将它应用到支持向量机中。</p><p id="fa18" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">当然，让我们看看这个练习的数据是什么样的:</p><figure class="kl km kn ko gt kp gh gi paragraph-image"><div class="gh gi ra"><img src="../Images/2720ffd3c65288c1e6f725552f71f98a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*D4BNX5IZR1F_KtPp.png"/></div></figure><p id="0d38" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">你会得到:</p><figure class="kl km kn ko gt kp gh gi paragraph-image"><div class="gh gi ra"><img src="../Images/1129108e85abb3d9626472e502df7f2a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*vELjeA0lbNx1nwIm.png"/></div></figure><p id="d272" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">注意我们有重叠的类。当然，我们的超平面不会尽善尽美，但我们将使用交叉验证来确保它是我们能得到的最好结果:</p><figure class="kl km kn ko gt kp gh gi paragraph-image"><div class="gh gi ra"><img src="../Images/242ebdcf66471eca4c230f0762147981.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*csFU3Ul4zUZx-b5g.png"/></div></figure><p id="6bb4" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">从上面的代码单元中，您应该得到最佳正则化参数是 1，并且<em class="om"> sigma </em>应该是 0.1。使用这些值，我们可以生成超平面:</p><figure class="kl km kn ko gt kp gh gi paragraph-image"><div class="gh gi ra"><img src="../Images/fd5f0e6c918f9a8e61a10e7db0f7ca8d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*xavJ1yT6RbVIQrUW.png"/></div></figure><p id="b512" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">并获得:</p><figure class="kl km kn ko gt kp gh gi paragraph-image"><div class="gh gi ra"><img src="../Images/844f4e8d201c6a6dc647efd89217b994.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*rKRAY1Yt9tbisGMq.png"/></div><figcaption class="oi oj gj gh gi ok ol bd b be z dk">Hyperplane with C=1 and sigma=0.1</figcaption></figure><h2 id="bd33" class="nr kt iv bd ku ns nt dn ky nu nv dp lc lr nw nx le lt ny nz lg lv oa ob li oc bi translated">迷你项目 4—SVM 垃圾邮件分类</h2><p id="d93b" class="pw-post-body-paragraph mv mw iv lm b ln lo jw mx lp lq jz my lr mz na nb lt nc nd ne lv nf ng nh lx io bi translated">最后，我们用 SVM 训练了一个垃圾邮件分类器。在这种情况下，我们将使用线性核。此外，我们有单独的数据集用于训练和测试，这将使我们的分析更容易一些。</p><figure class="kl km kn ko gt kp gh gi paragraph-image"><div class="gh gi ra"><img src="../Images/90b1bc9f7b5b28fee0c4d1421746ca41.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*T6jmbY_Uh_x15W4v.png"/></div></figure><p id="39e8" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">你可以看到，我们得到的<strong class="lm iw">训练</strong>准确率为 99.825%，而<strong class="lm iw">测试</strong>准确率为 98.9%！</p><h1 id="3f0c" class="ks kt iv bd ku kv kw kx ky kz la lb lc kb ld kc le ke lf kf lg kh lh ki li lj bi translated">无监督学习——理论</h1><p id="a946" class="pw-post-body-paragraph mv mw iv lm b ln lo jw mx lp lq jz my lr mz na nb lt nc nd ne lv nf ng nh lx io bi translated">无监督学习是一组统计工具，用于只有一组特征而没有目标的场景。因此，我们无法做出预测，因为对每个观察结果都没有相关的反应。相反，我们感兴趣的是找到一种有趣的方式来可视化数据，或者发现类似观察的子群。</p><p id="d646" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">无监督学习往往更具挑战性，因为分析没有明确的目标，而且往往是主观的。此外，很难评估获得的结果是否良好，因为没有公认的机制来执行交叉验证或验证独立数据集上的结果，因为我们不知道真实的答案。</p><p id="d5d1" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">本指南将重点介绍两种技术:<strong class="lm iw">主成分分析</strong>和<strong class="lm iw">聚类</strong>。</p><h2 id="a8d2" class="nr kt iv bd ku ns nt dn ky nu nv dp lc lr nw nx le lt ny nz lg lv oa ob li oc bi translated">主成分分析</h2><p id="c263" class="pw-post-body-paragraph mv mw iv lm b ln lo jw mx lp lq jz my lr mz na nb lt nc nd ne lv nf ng nh lx io bi translated">PCA 是指计算主成分并用于更好地理解数据的过程。PCA 也可以用于可视化。</p><p id="d7a2" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">什么是主成分？</p><p id="85f3" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">假设您想要可视化一组<em class="om"> p </em>特征上的<em class="om"> n </em>观测值，作为探索性数据分析的一部分。我们可以一次检查两个特征的 2D 散点图，但如果有很多预测因素，就会很快失控。</p><p id="06d5" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">使用 PCA，我们可以找到包含尽可能多的变化的数据集的低维表示。因此，我们只获得最感兴趣的<em class="om">特征，因为它们是方差的主要来源。</em></p><p id="d91b" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">主成分是怎么找到的？</p><p id="5a6c" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">第一个主成分是具有最大方差的特征的归一化线性组合:</p><figure class="kl km kn ko gt kp gh gi paragraph-image"><div role="button" tabindex="0" class="oe of di og bf oh"><div class="gh gi qp"><img src="../Images/9d71d94cf116cbc85d98583973251d7e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*ILuD9r8eyMATmT5P.png"/></div></div><figcaption class="oi oj gj gh gi ok ol bd b be z dk">First principal component equation</figcaption></figure><p id="ddf0" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">符号<em class="om">φ</em>被称为<strong class="lm iw">载荷</strong>。负载必须最大化:</p><figure class="kl km kn ko gt kp gh gi paragraph-image"><div class="gh gi pr"><img src="../Images/407e6b64cbefae42da14e6136f260070.png" data-original-src="https://miro.medium.com/v2/resize:fit:1168/format:webp/0*SPWSqnsNiJWGpYk7.png"/></div></figure><p id="a62d" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">这就是全部了！</p><h2 id="3580" class="nr kt iv bd ku ns nt dn ky nu nv dp lc lr nw nx le lt ny nz lg lv oa ob li oc bi translated">聚类方法</h2><p id="a801" class="pw-post-body-paragraph mv mw iv lm b ln lo jw mx lp lq jz my lr mz na nb lt nc nd ne lv nf ng nh lx io bi translated">聚类是指在数据集中查找子组或聚类的一系列技术。这有助于我们将观察结果划分为不同的组，以便每个组包含彼此相似的观察结果。例如，在乳腺癌的情况下，组可以代表肿瘤等级。它在市场细分的营销中也非常有用，以便确定更容易接受某种产品的人群。</p><p id="67f5" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">聚类方法有很多，但我们将重点介绍<strong class="lm iw"> k-means 聚类</strong>和<strong class="lm iw">层次聚类</strong>。在 K 均值聚类中，我们希望将数据划分成预先指定数量的<em class="om"> K </em>个聚类。另一方面，对于层次聚类，我们不知道我们需要多少个聚类。相反，我们想要一个树状图，它允许我们查看每个可能的聚类数所获得的所有聚类。</p><h2 id="f7aa" class="nr kt iv bd ku ns nt dn ky nu nv dp lc lr nw nx le lt ny nz lg lv oa ob li oc bi translated">k 均值聚类</h2><p id="c631" class="pw-post-body-paragraph mv mw iv lm b ln lo jw mx lp lq jz my lr mz na nb lt nc nd ne lv nf ng nh lx io bi translated">这种方法简单地将观察结果分成<em class="om"> K </em>个集群。它假设:</p><p id="4d1b" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">1.每个观察值属于 K 个聚类中的至少一个</p><p id="cda9" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">2.集群不重叠</p><p id="02df" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">此外，每个集群内的变化被最小化。</p><figure class="kl km kn ko gt kp gh gi paragraph-image"><div role="button" tabindex="0" class="oe of di og bf oh"><div class="gh gi qp"><img src="../Images/e455c5c4132ae5a91eecfaf2d38890cd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*rNz81_atGf2DNYl4.png"/></div></div><figcaption class="oi oj gj gh gi ok ol bd b be z dk">How observations were clustered depending on the number of specified clusters</figcaption></figure><p id="efb9" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">这是通过最小化一个聚类内每个观察值之间的平方欧几里德距离之和来实现的:</p><figure class="kl km kn ko gt kp gh gi paragraph-image"><div role="button" tabindex="0" class="oe of di og bf oh"><div class="gh gi qp"><img src="../Images/25ff472a7282bbec4f86f89c191ee295.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*4fUMCNk4fruTUJpq.png"/></div></div><figcaption class="oi oj gj gh gi ok ol bd b be z dk">Optimization function for k-mean clustering</figcaption></figure><p id="18ea" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">为了最小化，我们遵循以下算法:</p><p id="d2e7" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">1.从 1 到<em class="om"> K </em>之间随机分配一个数字给每个观察值。这些用作观测的初始聚类分配。</p><p id="bbee" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">2.迭代直到集群分配停止变化:</p><p id="af4f" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">2.a .对于每个<em class="om"> K </em>簇，计算簇<strong class="lm iw">质心</strong>。第<em class="om">个</em>簇质心是第<em class="om">个</em>簇中观测值的<em class="om"> p </em>特征均值的向量</p><p id="1666" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">2.b .将每个观察值分配给质心最近(最短欧几里得距离)的聚类</p><p id="ef25" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">请注意，上面的算法将找到一个局部最小值。因此，所获得的结果将取决于初始随机聚类分配。因此，多次运行该算法非常重要。</p><h2 id="2ab5" class="nr kt iv bd ku ns nt dn ky nu nv dp lc lr nw nx le lt ny nz lg lv oa ob li oc bi translated">分层聚类</h2><p id="543a" class="pw-post-body-paragraph mv mw iv lm b ln lo jw mx lp lq jz my lr mz na nb lt nc nd ne lv nf ng nh lx io bi translated">k-means 聚类的一个潜在缺点是它需要人工输入来指定聚类的数量。<strong class="lm iw">另一方面，层次聚类</strong>不需要聚类的初始数量。</p><p id="3d2d" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">最常见的层次聚类类型是<em class="om">自底向上</em>或<em class="om">聚集</em>聚类。这指的是这样一个事实，即从叶子开始生成一个<strong class="lm iw">树状图</strong>,并将簇组合到树干。</p><figure class="kl km kn ko gt kp gh gi paragraph-image"><div role="button" tabindex="0" class="oe of di og bf oh"><div class="gh gi qp"><img src="../Images/6a33728ac4e44e34f326b14932064eb2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*l9pG-xGRhC6LMumP.png"/></div></div><figcaption class="oi oj gj gh gi ok ol bd b be z dk">Examples of dendrograms</figcaption></figure><p id="088d" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">算法其实很简单。它从定义每对观察值之间的不相似性度量开始，比如欧几里德距离。然后，首先假设每个观察值属于它自己的集群。然后将两个最相似的聚类融合，这样就有了<em class="om"> n-1 </em>个聚类。之后，融合另外两个相似的簇，产生<em class="om"> n-2 </em>簇。该过程反复重复，直到所有的观察结果都是单个聚类的一部分。</p><p id="856b" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">虽然简单，但有些事情没有解决。如何定义聚类之间的相异度？这是通过<strong class="lm iw">联动</strong>的概念实现的。下表总结了四种最常见的链接类型:</p><figure class="kl km kn ko gt kp gh gi paragraph-image"><div role="button" tabindex="0" class="oe of di og bf oh"><div class="gh gi rh"><img src="../Images/21e50396492f02af3ef63c0136fb195c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*GpKG31u8v9d-siXp.png"/></div></div><figcaption class="oi oj gj gh gi ok ol bd b be z dk">The four most common types of linkage</figcaption></figure><p id="ed4e" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">完全连锁、平均连锁和质心连锁是最常见的连锁类型，因为单个连锁往往会产生不平衡的树状图。注意，生成的树状图很大程度上取决于所用的连锁类型。</p><figure class="kl km kn ko gt kp gh gi paragraph-image"><div class="gh gi qv"><img src="../Images/6ae5467315df7abac0c06d0fb7416100.png" data-original-src="https://miro.medium.com/v2/resize:fit:60/0*Z7zE-094LEfuTeGP"/></div></figure><figure class="kl km kn ko gt kp gh gi paragraph-image"><div role="button" tabindex="0" class="oe of di og bf oh"><div class="gh gi qp"><img src="../Images/bda261871318d25795b6fc0879754102.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*PMTGIe8CIDwN8oLg.png"/></div></div><figcaption class="oi oj gj gh gi ok ol bd b be z dk">Effect of linkage on the final dendrogram</figcaption></figure><p id="026c" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">此外，选择合适的相异度也很关键。欧几里德距离被广泛讨论，但也有基于相关性的距离<em class="om"/>。如果两个特征高度相关，则认为它们是相似的，这意味着它们具有相似的轮廓。</p><figure class="kl km kn ko gt kp gh gi paragraph-image"><div role="button" tabindex="0" class="oe of di og bf oh"><div class="gh gi qp"><img src="../Images/dfe1b0ebd10b69610961bf6ea3567b77.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*-SyYQLb0pjYjsJsr.png"/></div></div><figcaption class="oi oj gj gh gi ok ol bd b be z dk">Observation 1 and 2 are highly correlated, since they have similar profiles</figcaption></figure><p id="cba5" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">例如，假设一家在线零售商对基于购物者过去的购物历史对他们进行聚类感兴趣。目标是识别相似购物者的子群，这样他们就可以看到可能引起他们兴趣的广告。使用欧几里德距离，那么总体上很少购买商品的购物者将被聚集在一起，这可能不是理想的。另一方面，使用基于相关性的距离，具有类似<em class="om">偏好</em>(他们购买了商品 A 和 B，但没有购买商品 C 和 D)的购物者将被聚集在一起，即使他们购买了不同数量的商品。</p><p id="fc21" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">然而，在所有情况下，一旦层次聚类完成，我们仍然需要人工输入来确定要使用的最终聚类数。</p><p id="a826" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">现在您已经了解了 PCA 和聚类方法的工作原理，让我们在一个小型项目环境中实现它们。</p><h1 id="0cc5" class="ks kt iv bd ku kv kw kx ky kz la lb lc kb ld kc le ke lf kf lg kh lh ki li lj bi translated">无监督学习—实践</h1><p id="70f4" class="pw-post-body-paragraph mv mw iv lm b ln lo jw mx lp lq jz my lr mz na nb lt nc nd ne lv nf ng nh lx io bi translated">这部分将分为两个迷你项目。在第一个例子中，我们将使用 k-means 聚类对图像执行<strong class="lm iw">颜色量化</strong>。</p><p id="0ee0" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">然后，在第二个迷你项目中，我们将使用主成分分析来降低数据集的维度，允许我们用 2D 图来可视化它。</p><p id="1aca" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">在这里<a class="ae mc" href="https://github.com/marcopeix/ISL-Unsupervised?source=post_page---------------------------" rel="noopener ugc nofollow" target="_blank">你可以得到你需要的一切。</a></p><p id="60e4" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">旋转你的 Jupyter 笔记本，我们走吧！</p><h2 id="3a4a" class="nr kt iv bd ku ns nt dn ky nu nv dp lc lr nw nx le lt ny nz lg lv oa ob li oc bi translated">初始设置</h2><p id="9873" class="pw-post-body-paragraph mv mw iv lm b ln lo jw mx lp lq jz my lr mz na nb lt nc nd ne lv nf ng nh lx io bi translated">在开始任何实现之前，我们将导入一些在以后会变得方便的库:</p><figure class="kl km kn ko gt kp gh gi paragraph-image"><div role="button" tabindex="0" class="oe of di og bf oh"><div class="gh gi qp"><img src="../Images/0ccfa4bc65ca02d3635b0221a0312414.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*N60txYejTNKYR9Ca.png"/></div></div></figure><p id="39b6" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">与之前的教程不同，我们不会导入数据集。相反，我们将使用由<em class="om"> scikit-learn </em>库提供的数据。</p><h2 id="07f3" class="nr kt iv bd ku ns nt dn ky nu nv dp lc lr nw nx le lt ny nz lg lv oa ob li oc bi translated">迷你项目 1 —使用 k 均值聚类的颜色量化</h2><p id="8248" class="pw-post-body-paragraph mv mw iv lm b ln lo jw mx lp lq jz my lr mz na nb lt nc nd ne lv nf ng nh lx io bi translated">快速，颜色量化是一种技术，以减少在图像中使用的不同颜色的数量。这对于在保持图像完整性的同时压缩图像尤其有用。</p><p id="3c2e" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">首先，我们导入以下库:</p><figure class="kl km kn ko gt kp gh gi paragraph-image"><div role="button" tabindex="0" class="oe of di og bf oh"><div class="gh gi qp"><img src="../Images/a97e38c9301ab92f6e653d0e916cd5b2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*1vFoEXBFb81CCdIJ.png"/></div></div></figure><p id="6bb3" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">注意，我们导入了一个名为<em class="om"> load_sample_image </em>的样本数据集。这仅仅包含两个图像。我们将使用其中一个来执行颜色量化。</p><p id="352f" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">因此，让我们展示一下我们将在本练习中使用的图像:</p><figure class="kl km kn ko gt kp gh gi paragraph-image"><div role="button" tabindex="0" class="oe of di og bf oh"><div class="gh gi qp"><img src="../Images/e8cd1ad5ae5d95976468487f080ebe49.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*E-LWpIAbeVO6lrEP.png"/></div></div></figure><p id="29a6" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">您应该会看到:</p><figure class="kl km kn ko gt kp gh gi paragraph-image"><div role="button" tabindex="0" class="oe of di og bf oh"><div class="gh gi ri"><img src="../Images/d677e60a7a7d9bc46ed43bf08f0358ed.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*yoX8qeDv0ZCQE11L.png"/></div></div><figcaption class="oi oj gj gh gi ok ol bd b be z dk">Original image</figcaption></figure><p id="c193" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">现在，对于颜色量化，必须遵循不同的步骤。</p><p id="584b" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">首先，我们需要将图像转换成 2D 矩阵进行处理:</p><figure class="kl km kn ko gt kp gh gi paragraph-image"><div role="button" tabindex="0" class="oe of di og bf oh"><div class="gh gi qp"><img src="../Images/ca98235215ebfa9e743cee2482405808.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*TnzEKfUxPdKrxl8s.png"/></div></div></figure><p id="19dd" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">然后，我们训练我们的模型来聚合颜色，以便在图像中有 64 种不同的颜色:</p><figure class="kl km kn ko gt kp gh gi paragraph-image"><div role="button" tabindex="0" class="oe of di og bf oh"><div class="gh gi qp"><img src="../Images/ed6d230a3d67bc39d7dc77cda6508833.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*UbEzYJWkwmyDchlJ.png"/></div></div></figure><p id="a39c" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">然后，我们构建一个辅助函数来帮助我们用指定颜色的数量重建图像:</p><figure class="kl km kn ko gt kp gh gi paragraph-image"><div role="button" tabindex="0" class="oe of di og bf oh"><div class="gh gi qp"><img src="../Images/03867d1078963d46b70bc487360837f4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*7sVfEPR-FjRJN2qw.png"/></div></div></figure><p id="aec9" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">最后，我们现在可以看到只有 64 种颜色的图像，以及它与原始图像的对比:</p><figure class="kl km kn ko gt kp gh gi paragraph-image"><div role="button" tabindex="0" class="oe of di og bf oh"><div class="gh gi rj"><img src="../Images/94872814acb43d8bd492c78c1e8dddd4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*NOa77wcej3zMnJVj.png"/></div></div><figcaption class="oi oj gj gh gi ok ol bd b be z dk">Original image with 96 615 colors</figcaption></figure><figure class="kl km kn ko gt kp gh gi paragraph-image"><div role="button" tabindex="0" class="oe of di og bf oh"><div class="gh gi rk"><img src="../Images/1238e9cdfc236df0bd951d763b42ff6b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*5pcEU5qykr-P3qfm.png"/></div></div><figcaption class="oi oj gj gh gi ok ol bd b be z dk">Reconstructed image with 64 colors</figcaption></figure><p id="2117" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">当然，我们可以看到一些差异，但总体而言，图像的完整性是守恒的！一定要探索不同数量的集群！例如，如果指定 10 种颜色，将会得到以下结果:</p><figure class="kl km kn ko gt kp gh gi paragraph-image"><div class="gh gi rl"><img src="../Images/2ece0f86be84496e9fd3d1cbd0824784.png" data-original-src="https://miro.medium.com/v2/resize:fit:1364/format:webp/0*eRydOkCJ9SeAGD9a.png"/></div><figcaption class="oi oj gj gh gi ok ol bd b be z dk">Reconstructed image with 10 colors</figcaption></figure><h2 id="7a55" class="nr kt iv bd ku ns nt dn ky nu nv dp lc lr nw nx le lt ny nz lg lv oa ob li oc bi translated">迷你项目 2 —使用主成分分析进行降维</h2><p id="9ee6" class="pw-post-body-paragraph mv mw iv lm b ln lo jw mx lp lq jz my lr mz na nb lt nc nd ne lv nf ng nh lx io bi translated">在本练习中，我们将使用主成分分析来降低数据集的维度，以便我们可以轻松地将其可视化。</p><p id="b1b0" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">因此，让我们从<em class="om"> scikit-learn </em>导入虹膜数据集:</p><figure class="kl km kn ko gt kp gh gi paragraph-image"><div role="button" tabindex="0" class="oe of di og bf oh"><div class="gh gi qp"><img src="../Images/4308432d5b64fa085b0aa7a9b46af025.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*G8tKaEccP5ASM_Pr.png"/></div></div></figure><p id="ba27" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">现在，我们将计算前两个主成分，并查看每个主成分可以解释的方差比例:</p><figure class="kl km kn ko gt kp gh gi paragraph-image"><div role="button" tabindex="0" class="oe of di og bf oh"><div class="gh gi qp"><img src="../Images/a9440bd28d87b21ef9979b2e6a0984ea.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*TArPS-oCvWtkzDQR.png"/></div></div></figure><p id="e910" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">从上面的代码块中，您应该看到第一个主成分包含 92%的方差，而第二个主成分占 5%的方差。因此，这意味着仅两个特征就足以解释数据集中 97%的方差！</p><p id="a4f1" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">现在，我们可以利用它轻松绘制二维数据:</p><figure class="kl km kn ko gt kp gh gi paragraph-image"><div role="button" tabindex="0" class="oe of di og bf oh"><div class="gh gi qp"><img src="../Images/815007f25eb941870f88efcd02ec0694.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*vG7m6aO_UKobaF-y.png"/></div></div></figure><p id="5ed8" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">你会得到:</p><figure class="kl km kn ko gt kp gh gi paragraph-image"><div role="button" tabindex="0" class="oe of di og bf oh"><div class="gh gi rm"><img src="../Images/3fdbbab42decf9e4b3a3f7bda6284aac.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*GJP7BUHeTuBNcfTd.png"/></div></div></figure><p id="a31c" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">正如你所看到的，主成分分析有助于减少数据集的维数，允许我们绘制它，并可视化每个类别是如何分开的。</p><h1 id="7acb" class="ks kt iv bd ku kv kw kx ky kz la lb lc kb ld kc le ke lf kf lg kh lh ki li lj bi translated">时间序列分析—理论</h1><p id="3c8a" class="pw-post-body-paragraph mv mw iv lm b ln lo jw mx lp lq jz my lr mz na nb lt nc nd ne lv nf ng nh lx io bi translated">无论我们希望预测金融市场或电力消费的趋势，时间都是我们的模型中必须考虑的重要因素。例如，预测在一天中的什么时间将会出现用电高峰是令人感兴趣的，例如调整电力的价格或产量。</p><p id="10f3" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">进入<strong class="lm iw">时间序列</strong>。时间序列就是按时间顺序排列的一系列数据点。在时间序列中，时间通常是独立变量，目标通常是对未来做出预测。</p><p id="1b67" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">然而，在处理时间序列时，还有其他方面的因素在起作用。</p><p id="7684" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">是<strong class="lm iw">静止的</strong>吗？</p><p id="c1cb" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">有没有<strong class="lm iw">季节性</strong>？</p><p id="0cf8" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">目标变量<strong class="lm iw">是否与</strong>自相关？</p><h2 id="2e85" class="nr kt iv bd ku ns nt dn ky nu nv dp lc lr nw nx le lt ny nz lg lv oa ob li oc bi translated">自相关</h2><p id="340f" class="pw-post-body-paragraph mv mw iv lm b ln lo jw mx lp lq jz my lr mz na nb lt nc nd ne lv nf ng nh lx io bi translated">非正式地说，<strong class="lm iw">自相关</strong>是观测值之间的相似性，是它们之间的时滞的函数。</p><figure class="kl km kn ko gt kp gh gi paragraph-image"><div role="button" tabindex="0" class="oe of di og bf oh"><div class="gh gi qp"><img src="../Images/7edd2de14775eb18bb9c8ba636a49728.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*jdKY_6aoWV16rsov.png"/></div></div><figcaption class="oi oj gj gh gi ok ol bd b be z dk">Example of an autocorrelation plot</figcaption></figure><p id="c18b" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">上面是一个自相关图的例子。仔细观察，您会发现第一个值和第 24 个值具有很高的自相关性。同样，第 12 次和第 36 次观察高度相关。这意味着我们会在每 24 个时间单位找到一个非常相似的值。</p><p id="9c07" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">注意这个图看起来像正弦函数。这是对<strong class="lm iw">季节性、</strong>的暗示，你可以通过在上面的图中找到时间段来找到它的值，这将给出 24 小时。</p><h2 id="d799" class="nr kt iv bd ku ns nt dn ky nu nv dp lc lr nw nx le lt ny nz lg lv oa ob li oc bi translated">季节性</h2><p id="4ea6" class="pw-post-body-paragraph mv mw iv lm b ln lo jw mx lp lq jz my lr mz na nb lt nc nd ne lv nf ng nh lx io bi translated"><strong class="lm iw">季节性</strong>指周期性波动。例如，用电量白天高，晚上低，或者圣诞节期间在线销售增加，然后再次放缓。</p><figure class="kl km kn ko gt kp gh gi paragraph-image"><div role="button" tabindex="0" class="oe of di og bf oh"><div class="gh gi qp"><img src="../Images/b11ab09eee09f31d62d137db6cedeba3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*bud3uPUxZS_8z9G5.png"/></div></div><figcaption class="oi oj gj gh gi ok ol bd b be z dk">Example of seasonality</figcaption></figure><p id="73b5" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">从上面可以看出，有明显的日季节性。每一天，你都会在傍晚看到一个高峰，而最低点则是每天的开始和结束。</p><p id="5515" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">请记住，如果自相关图呈正弦曲线形状，季节性也可以从自相关图中得出。简单地看周期，它给出了季节的长度。</p><h2 id="3397" class="nr kt iv bd ku ns nt dn ky nu nv dp lc lr nw nx le lt ny nz lg lv oa ob li oc bi translated">平稳性</h2><p id="4dd5" class="pw-post-body-paragraph mv mw iv lm b ln lo jw mx lp lq jz my lr mz na nb lt nc nd ne lv nf ng nh lx io bi translated"><strong class="lm iw">平稳性</strong>是时间序列的重要特征。如果一个时间序列的统计特性不随时间变化，则称该时间序列是平稳的。换句话说，它有<strong class="lm iw">常数均值和方差</strong>，协方差与时间无关。</p><figure class="kl km kn ko gt kp gh gi paragraph-image"><div role="button" tabindex="0" class="oe of di og bf oh"><div class="gh gi qp"><img src="../Images/b8380d669033da3855f34537a94b8891.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*wTX-Bj0BAHt05L94.png"/></div></div><figcaption class="oi oj gj gh gi ok ol bd b be z dk">Example of a stationary process</figcaption></figure><p id="e21b" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">再看同样的图，我们看到上面的过程是静止的。平均值和方差不随时间变化。</p><p id="4469" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">通常，股票价格不是一个稳定的过程，因为我们可能会看到一个增长的趋势，或者它的波动性可能会随着时间的推移而增加(意味着方差在变化)。</p><p id="8cc0" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">理想情况下，我们希望有一个平稳的时间序列来建模。当然，并不是所有的都是静止的，但是我们可以做不同的变换使它们静止。</p><h2 id="e301" class="nr kt iv bd ku ns nt dn ky nu nv dp lc lr nw nx le lt ny nz lg lv oa ob li oc bi translated">如何测试一个过程是否是稳定的</h2><p id="4518" class="pw-post-body-paragraph mv mw iv lm b ln lo jw mx lp lq jz my lr mz na nb lt nc nd ne lv nf ng nh lx io bi translated">你可能已经注意到了上面这个图的标题。这是我们用来确定时间序列是否平稳的统计测试。</p><p id="a77d" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">在不深入 Dickey-Fuller 检验的技术细节的情况下，它检验了单位根存在的零假设。</p><p id="0224" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">如果是，那么<em class="om">p&gt;T9】0，过程不是静止的。</em></p><p id="07ed" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">否则，<em class="om"> p = </em> 0，零假设被拒绝，过程被认为是平稳的。</p><p id="8d85" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">例如，下面的过程不是静止的。请注意，平均值在整个时间内并不恒定。</p><figure class="kl km kn ko gt kp gh gi paragraph-image"><div role="button" tabindex="0" class="oe of di og bf oh"><div class="gh gi rn"><img src="../Images/255f7107c96eb97a6649abe60d2ba0ae.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*f7DHcRJ8SjA3N1SX.png"/></div></div><figcaption class="oi oj gj gh gi ok ol bd b be z dk">Example of a non-stationary process</figcaption></figure><h2 id="e86a" class="nr kt iv bd ku ns nt dn ky nu nv dp lc lr nw nx le lt ny nz lg lv oa ob li oc bi translated">建模时间序列</h2><p id="792a" class="pw-post-body-paragraph mv mw iv lm b ln lo jw mx lp lq jz my lr mz na nb lt nc nd ne lv nf ng nh lx io bi translated">为了进行预测，有许多方法可以对时间序列进行建模。在这里，我将介绍:</p><ul class=""><li id="bfe1" class="lk ll iv lm b ln ni lp nj lr nn lt no lv np lx nq lz ma mb bi translated">移动平均数</li><li id="ead0" class="lk ll iv lm b ln md lp me lr mf lt mg lv mh lx nq lz ma mb bi translated">指数平滑法</li><li id="a363" class="lk ll iv lm b ln md lp me lr mf lt mg lv mh lx nq lz ma mb bi translated">ARIMA</li></ul><h2 id="7e54" class="nr kt iv bd ku ns nt dn ky nu nv dp lc lr nw nx le lt ny nz lg lv oa ob li oc bi translated">移动平均数</h2><p id="5e0a" class="pw-post-body-paragraph mv mw iv lm b ln lo jw mx lp lq jz my lr mz na nb lt nc nd ne lv nf ng nh lx io bi translated">移动平均模型可能是时间序列建模中最简单的方法。该模型简单地说明了下一个观察值是所有过去观察值的平均值。</p><p id="4bcf" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">虽然简单，但这个模型可能会出奇的好，它代表了一个好的起点。</p><p id="cd59" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">否则，移动平均线可用于识别数据中有趣的趋势。我们可以定义一个<em class="om">窗口</em>来应用移动平均模型<em class="om">平滑</em>时间序列，并突出显示不同的趋势。</p><figure class="kl km kn ko gt kp gh gi paragraph-image"><div role="button" tabindex="0" class="oe of di og bf oh"><div class="gh gi qp"><img src="../Images/fde466b525d8561c85ce2182ebf726c3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*sP6SlrAgLEoDFu3i.png"/></div></div><figcaption class="oi oj gj gh gi ok ol bd b be z dk">Example of a moving average on a 24h window</figcaption></figure><p id="7875" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">在上图中，我们将移动平均模型应用于 24 小时窗口。绿线<em class="om">平滑了时间序列</em>，我们可以看到 24 小时内有两个峰值。</p><p id="6de5" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">当然，窗口越长，趋势就越平稳。下面是一个小窗口的移动平均线的例子。</p><figure class="kl km kn ko gt kp gh gi paragraph-image"><div role="button" tabindex="0" class="oe of di og bf oh"><div class="gh gi qp"><img src="../Images/ff1f5108cf193a6c71a390899203d8e8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*_aqws5qD9RFW7-XD.png"/></div></div><figcaption class="oi oj gj gh gi ok ol bd b be z dk">Example of a moving average on a 12h window</figcaption></figure><h2 id="7f09" class="nr kt iv bd ku ns nt dn ky nu nv dp lc lr nw nx le lt ny nz lg lv oa ob li oc bi translated">指数平滑法</h2><p id="190c" class="pw-post-body-paragraph mv mw iv lm b ln lo jw mx lp lq jz my lr mz na nb lt nc nd ne lv nf ng nh lx io bi translated">指数平滑使用与移动平均类似的逻辑，但是这一次，不同的<em class="om">递减权重</em>被分配给每个观察值。换句话说，<em class="om">随着我们离现在越来越远，观察的重要性</em>就越来越小。</p><p id="376f" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">数学上，指数平滑表示为:</p><figure class="kl km kn ko gt kp gh gi paragraph-image"><div role="button" tabindex="0" class="oe of di og bf oh"><div class="gh gi qp"><img src="../Images/830cc3a2f044953975fba6b541332b92.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*thAjiJyRkXW-8l7h.png"/></div></div><figcaption class="oi oj gj gh gi ok ol bd b be z dk">Exponential smoothing expression</figcaption></figure><p id="9400" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">这里，<em class="om">α</em>是取值在 0 和 1 之间的<strong class="lm iw">平滑因子</strong>。它决定了先前观察到的重量减少的速度。</p><figure class="kl km kn ko gt kp gh gi paragraph-image"><div role="button" tabindex="0" class="oe of di og bf oh"><div class="gh gi qp"><img src="../Images/73f3f31efc315f0332a093e95674a308.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*3ufxlf5WBxm1HHxD.png"/></div></div><figcaption class="oi oj gj gh gi ok ol bd b be z dk">Example of exponential smoothing</figcaption></figure><p id="9755" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">从上面的图中，深蓝色线表示使用平滑因子 0.3 对时间序列进行指数平滑，而橙色线使用平滑因子 0.05。</p><p id="2a1d" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">可以看到，平滑因子越小，时间序列就越平滑。这是有意义的，因为当平滑因子接近 0 时，我们就接近移动平均模型。</p><h2 id="cec2" class="nr kt iv bd ku ns nt dn ky nu nv dp lc lr nw nx le lt ny nz lg lv oa ob li oc bi translated">双指数平滑</h2><p id="ef9a" class="pw-post-body-paragraph mv mw iv lm b ln lo jw mx lp lq jz my lr mz na nb lt nc nd ne lv nf ng nh lx io bi translated">当时间序列中存在趋势时，使用双指数平滑。在这种情况下，我们使用这种技术，它只是指数平滑的两次递归使用。</p><p id="d8e1" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">数学上:</p><figure class="kl km kn ko gt kp gh gi paragraph-image"><div role="button" tabindex="0" class="oe of di og bf oh"><div class="gh gi qp"><img src="../Images/a7a0fe89e577462da50b2cad761f8dc3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*H4G-4FMYNiRzeiIf.png"/></div></div><figcaption class="oi oj gj gh gi ok ol bd b be z dk">Double exponential smoothing expression</figcaption></figure><p id="ed21" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">这里，<em class="om"> beta </em>是<strong class="lm iw">趋势平滑因子</strong>，取 0 到 1 之间的值。</p><p id="1a86" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">下面，您可以看到<em class="om"> alpha </em>和<em class="om"> beta </em>的不同值如何影响时间序列的形状。</p><figure class="kl km kn ko gt kp gh gi paragraph-image"><div role="button" tabindex="0" class="oe of di og bf oh"><div class="gh gi qp"><img src="../Images/38b54fdc5605e995a0c391d93d312fa0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*8Hxd4aX5rBkiXMmB.png"/></div></div><figcaption class="oi oj gj gh gi ok ol bd b be z dk">Example of double exponential smoothing</figcaption></figure><h2 id="6e45" class="nr kt iv bd ku ns nt dn ky nu nv dp lc lr nw nx le lt ny nz lg lv oa ob li oc bi translated">三指数平滑</h2><p id="0f15" class="pw-post-body-paragraph mv mw iv lm b ln lo jw mx lp lq jz my lr mz na nb lt nc nd ne lv nf ng nh lx io bi translated">该方法通过添加<strong class="lm iw">季节性平滑因子</strong>扩展了双指数平滑。当然，如果您注意到时间序列中的季节性，这是很有用的。</p><p id="68d0" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">数学上，三重指数平滑表示为:</p><figure class="kl km kn ko gt kp gh gi paragraph-image"><div role="button" tabindex="0" class="oe of di og bf oh"><div class="gh gi qp"><img src="../Images/503b788d7fd49e102369bb535972e169.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*745knvIXsrzgrm-L.png"/></div></div><figcaption class="oi oj gj gh gi ok ol bd b be z dk">Triple exponential smoothing expression</figcaption></figure><p id="c192" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">其中<em class="om">伽玛</em>是季节平滑因子，而<em class="om"> L </em>是季节的长度。</p><h2 id="80b9" class="nr kt iv bd ku ns nt dn ky nu nv dp lc lr nw nx le lt ny nz lg lv oa ob li oc bi translated">季节性自回归积分移动平均模型</h2><p id="dc6e" class="pw-post-body-paragraph mv mw iv lm b ln lo jw mx lp lq jz my lr mz na nb lt nc nd ne lv nf ng nh lx io bi translated">SARIMA 实际上是简单模型的组合，以形成一个复杂的模型，该模型可以模拟具有非平稳属性和季节性的时间序列。</p><p id="99b2" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">首先，我们有<strong class="lm iw">自回归模型 AR(p) </strong>。这基本上是时间序列自身的回归。这里，我们假设当前值依赖于它以前的值，有一些滞后。它采用一个代表最大滞后的参数<strong class="lm iw"> p </strong>。为了找到它，我们查看部分自相关图，并确定大多数滞后不显著之后的滞后。</p><p id="bab0" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">在下面的例子中，<strong class="lm iw"> p </strong>应该是 4。</p><figure class="kl km kn ko gt kp gh gi paragraph-image"><div class="gh gi ro"><img src="../Images/08a4219afa8c3282fc898d56a236143b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1390/format:webp/0*iaz2ILWnbi4_V2vq.png"/></div><figcaption class="oi oj gj gh gi ok ol bd b be z dk">Example of a partial autocorrelation plot</figcaption></figure><p id="a7e8" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">然后，我们添加<strong class="lm iw">移动平均线模型 MA(q) </strong>。这需要一个参数<strong class="lm iw"> q </strong>，该参数代表最大滞后，在该最大滞后之后，其他滞后在自相关图上不显著。</p><p id="3164" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">下面，<strong class="lm iw"> q </strong>会是 4。</p><figure class="kl km kn ko gt kp gh gi paragraph-image"><div class="gh gi rp"><img src="../Images/5bd2212bb1f20511437229b8f6e667b8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1382/format:webp/0*PSeDCtFSmPJbQtsB.png"/></div><figcaption class="oi oj gj gh gi ok ol bd b be z dk">Example of an autocorrelation plot</figcaption></figure><p id="c05e" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">之后，我们加上<strong class="lm iw">的积分顺序</strong> <strong class="lm iw"> I(d) </strong>。参数<strong class="lm iw"> d </strong>代表使序列稳定所需的差值数量。</p><p id="269f" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">最后，我们添加最后一个组件:<strong class="lm iw">季节性 S(P，D，Q，s) </strong>，其中<strong class="lm iw"> s </strong>就是季节的长度。此外，该组件需要参数<strong class="lm iw"> P </strong>和<strong class="lm iw"> Q </strong>，它们与<strong class="lm iw"> p </strong>和<strong class="lm iw"> q </strong>相同，但针对季节性组件。最后，<strong class="lm iw"> D </strong>是季节积分的顺序，代表从序列中去除季节性所需的差异数。</p><p id="64cb" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">综合所有这些，我们得到了<strong class="lm iw">萨里玛(P，D，q)(P，D，Q，s) </strong>模型。</p><p id="437a" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">主要要点是:在使用 SARIMA 建模之前，我们必须对时间序列进行转换，以消除季节性和任何非平稳行为。</p><h1 id="dab5" class="ks kt iv bd ku kv kw kx ky kz la lb lc kb ld kc le ke lf kf lg kh lh ki li lj bi translated">时间序列分析—实践</h1><p id="8351" class="pw-post-body-paragraph mv mw iv lm b ln lo jw mx lp lq jz my lr mz na nb lt nc nd ne lv nf ng nh lx io bi translated">我们会试着预测一家特定公司的股价。现在，预测股票价格几乎是不可能的。然而，这仍然是一个有趣的练习，也是练习我们所学知识的好方法。</p><p id="a3c7" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">我们将使用新德国基金(GF)的历史股价来尝试预测未来五个交易日的收盘价。</p><p id="6619" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">你可以在这里抓取数据集和笔记本<a class="ae mc" href="https://github.com/marcopeix/stock-prediction" rel="noopener ugc nofollow" target="_blank">。</a></p><p id="29f7" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">和往常一样，我强烈推荐你跟着编码！启动你的笔记本，我们走吧！</p><h2 id="333c" class="nr kt iv bd ku ns nt dn ky nu nv dp lc lr nw nx le lt ny nz lg lv oa ob li oc bi translated">导入数据</h2><figure class="kl km kn ko gt kp"><div class="bz fp l di"><div class="rq rr l"/></div></figure><p id="d4fc" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">首先，我们导入一些对我们的分析有帮助的库。此外，我们定义了<strong class="lm iw">平均百分比误差(MAPE) </strong>，因为这将是我们的误差度量。</p><p id="5038" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">首先，我们导入一些对我们的分析有帮助的库。此外，我们定义了<strong class="lm iw">平均百分比误差(MAPE) </strong>，因为这将是我们的误差度量。</p><p id="7dc9" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">然后，我们导入数据集，对前十个条目进行排序，您应该会得到</p><figure class="kl km kn ko gt kp gh gi paragraph-image"><div role="button" tabindex="0" class="oe of di og bf oh"><div class="gh gi qp"><img src="../Images/da5bcc0a478e162cfd22204a116d1b3b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*cR5BVWoURYPcOrXV.png"/></div></div><figcaption class="oi oj gj gh gi ok ol bd b be z dk">First 10 entries of the dataset</figcaption></figure><p id="61b9" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">正如你所看到的，我们有几个条目是关于一只不同于新德国基金的股票。此外，我们有一个关于当天信息的条目，但我们只想要当天结束时(EOD)的信息。</p><h2 id="64ef" class="nr kt iv bd ku ns nt dn ky nu nv dp lc lr nw nx le lt ny nz lg lv oa ob li oc bi translated">清理数据</h2><figure class="kl km kn ko gt kp"><div class="bz fp l di"><div class="rq rr l"/></div></figure><p id="499d" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">首先，我们删除不需要的条目。</p><p id="6559" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">然后，我们删除不需要的列，因为我们只想关注股票的收盘价。</p><p id="54f3" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">如果预览数据集，您应该会看到:</p><figure class="kl km kn ko gt kp gh gi paragraph-image"><div role="button" tabindex="0" class="oe of di og bf oh"><div class="gh gi rs"><img src="../Images/015b497f1b387ed65c3259b5bd4ac730.png" data-original-src="https://miro.medium.com/v2/resize:fit:1114/format:webp/0*FGycg7BWJnJxBnu-.png"/></div></div><figcaption class="oi oj gj gh gi ok ol bd b be z dk">Clean dataset</figcaption></figure><p id="b7e7" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">厉害！我们准备好进行探索性数据分析了！</p><h2 id="dfe4" class="nr kt iv bd ku ns nt dn ky nu nv dp lc lr nw nx le lt ny nz lg lv oa ob li oc bi translated">探索性数据分析</h2><figure class="kl km kn ko gt kp"><div class="bz fp l di"><div class="rq rr l"/></div></figure><p id="d03b" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">我们绘制了数据集整个时间段的收盘价。</p><p id="1fb4" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">您应该得到:</p><figure class="kl km kn ko gt kp gh gi paragraph-image"><div role="button" tabindex="0" class="oe of di og bf oh"><div class="gh gi qp"><img src="../Images/07d499beb7240cbc2605b89d45bc23bc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*PxSIizrenVHKWTWl.png"/></div></div><figcaption class="oi oj gj gh gi ok ol bd b be z dk">Closing price of the New Germany Fund (GF)</figcaption></figure><p id="b091" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">显然，你看到这不是一个<strong class="lm iw">平稳的</strong>过程，很难判断是否存在某种<strong class="lm iw">季节性</strong>。</p><h2 id="ce32" class="nr kt iv bd ku ns nt dn ky nu nv dp lc lr nw nx le lt ny nz lg lv oa ob li oc bi translated">移动平均数</h2><p id="f648" class="pw-post-body-paragraph mv mw iv lm b ln lo jw mx lp lq jz my lr mz na nb lt nc nd ne lv nf ng nh lx io bi translated">让我们使用<strong class="lm iw">移动平均</strong>模型来平滑我们的时间序列。为此，我们将使用一个助手函数，该函数将在指定的时间窗口运行移动平均模型，并绘制出平滑的结果曲线:</p><figure class="kl km kn ko gt kp"><div class="bz fp l di"><div class="rq rr l"/></div></figure><p id="ff2e" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">使用 5 天的时间窗，我们得到:</p><figure class="kl km kn ko gt kp gh gi paragraph-image"><div role="button" tabindex="0" class="oe of di og bf oh"><div class="gh gi qp"><img src="../Images/d9c5cf48c4b4902a62585281cd72047f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*dCQXtwiMrprWeJ14.png"/></div></div><figcaption class="oi oj gj gh gi ok ol bd b be z dk">Smoothed curve by the previous trading week</figcaption></figure><p id="5320" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">如你所见，我们几乎看不到趋势，因为它太接近实际曲线了。让我们看看上个月和上个季度的平滑结果。</p><figure class="kl km kn ko gt kp gh gi paragraph-image"><div role="button" tabindex="0" class="oe of di og bf oh"><div class="gh gi qp"><img src="../Images/fe9d8f97287513c8ee9931b90c9c6c0f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*A6B--USx8MBt8Gav.png"/></div></div><figcaption class="oi oj gj gh gi ok ol bd b be z dk">Smoothed by the previous month (30 days)</figcaption></figure><figure class="kl km kn ko gt kp gh gi paragraph-image"><div role="button" tabindex="0" class="oe of di og bf oh"><div class="gh gi qp"><img src="../Images/219dcec6c0ea9510991015af5984fba3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*B6nJRB6dQmu7FQlL.png"/></div></div><figcaption class="oi oj gj gh gi ok ol bd b be z dk">Smoothed by the previous quarter (90 days)</figcaption></figure><p id="07e9" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">现在趋势更容易发现了。注意 30 天和 90 天的趋势是如何在最后显示出下降曲线的。这可能意味着股票可能会在接下来的几天下跌。</p><h2 id="c609" class="nr kt iv bd ku ns nt dn ky nu nv dp lc lr nw nx le lt ny nz lg lv oa ob li oc bi translated">指数平滑法</h2><p id="7e7b" class="pw-post-body-paragraph mv mw iv lm b ln lo jw mx lp lq jz my lr mz na nb lt nc nd ne lv nf ng nh lx io bi translated">现在，让我们使用<strong class="lm iw">指数平滑</strong>来看看它是否能获得更好的趋势。</p><figure class="kl km kn ko gt kp"><div class="bz fp l di"><div class="rq rr l"/></div></figure><p id="f880" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">这里，我们使用 0.05 和 0.3 作为<strong class="lm iw">平滑因子</strong>的值。随意尝试其他值，看看结果如何。</p><figure class="kl km kn ko gt kp gh gi paragraph-image"><div role="button" tabindex="0" class="oe of di og bf oh"><div class="gh gi qp"><img src="../Images/9f4033b4b762eaf25ef90452dd546e6d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*ZSZpQmg6EOc0v4bb.png"/></div></div><figcaption class="oi oj gj gh gi ok ol bd b be z dk">Exponential smoothing</figcaption></figure><p id="6488" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">正如你所看到的，0.05 的<em class="om"> alpha </em>值平滑了曲线，同时拾取了大部分向上和向下的趋势。</p><p id="d82b" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">现在，让我们使用<strong class="lm iw">双指数平滑。</strong></p><h2 id="4e83" class="nr kt iv bd ku ns nt dn ky nu nv dp lc lr nw nx le lt ny nz lg lv oa ob li oc bi translated">双指数平滑</h2><figure class="kl km kn ko gt kp"><div class="bz fp l di"><div class="rq rr l"/></div></figure><p id="4d41" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">你会得到:</p><figure class="kl km kn ko gt kp gh gi paragraph-image"><div role="button" tabindex="0" class="oe of di og bf oh"><div class="gh gi qp"><img src="../Images/202ee29389341176fa982150891f5d41.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*0toApSV_lRt9--zq.png"/></div></div><figcaption class="oi oj gj gh gi ok ol bd b be z dk">Double exponential smoothing</figcaption></figure><p id="f88b" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">同样，尝试不同的<em class="om"> alpha </em>和<em class="om"> beta </em>组合来获得更好看的曲线。</p><h2 id="28f0" class="nr kt iv bd ku ns nt dn ky nu nv dp lc lr nw nx le lt ny nz lg lv oa ob li oc bi translated">系统模型化</h2><p id="3709" class="pw-post-body-paragraph mv mw iv lm b ln lo jw mx lp lq jz my lr mz na nb lt nc nd ne lv nf ng nh lx io bi translated">如前所述，我们必须把我们的系列变成一个平稳的过程，以便对它建模。因此，让我们应用 Dickey-Fuller 检验来看看它是否是一个平稳过程:</p><figure class="kl km kn ko gt kp"><div class="bz fp l di"><div class="rq rr l"/></div></figure><p id="75b5" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">您应该看到:</p><figure class="kl km kn ko gt kp gh gi paragraph-image"><div role="button" tabindex="0" class="oe of di og bf oh"><div class="gh gi qp"><img src="../Images/08c96700f15df83ab30ed5294a4de4be.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*n7iOouRpMEBPhn-0.png"/></div></div></figure><p id="2539" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">通过 Dickey-Fuller 检验，时间序列无疑是非平稳的。还有，看自相关图，看到很高，似乎没有明显的季节性。</p><p id="4278" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">因此，为了去掉高自相关性，并使过程平稳，我们取第一个差(代码块中的第 23 行)。我们简单地从滞后一天的时间序列中减去时间序列，我们得到:</p><figure class="kl km kn ko gt kp gh gi paragraph-image"><div role="button" tabindex="0" class="oe of di og bf oh"><div class="gh gi qp"><img src="../Images/c83f4ed100014819cb7a122b2fc1bd67.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*lurHFcpxRGC_Y5P0.png"/></div></div></figure><p id="5aa1" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">厉害！我们的系列现在是固定的，我们可以开始建模！</p><h2 id="ece6" class="nr kt iv bd ku ns nt dn ky nu nv dp lc lr nw nx le lt ny nz lg lv oa ob li oc bi translated">萨里玛</h2><figure class="kl km kn ko gt kp"><div class="bz fp l di"><div class="rq rr l"/></div></figure><p id="df47" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">现在，对于 SARIMA，我们首先定义一些参数和其他参数的值范围，以生成 P，Q，D，P，Q，D，s 的所有可能组合的列表。</p><p id="8513" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">现在，在上面的代码单元中，我们有 625 种不同的组合！我们将尝试每种组合，并用每种组合来训练 SARIMA，以找到最佳表现模式。这可能需要一段时间，具体取决于您计算机的处理能力。</p><p id="7bef" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">完成后，我们会打印出最佳模型的摘要，您应该会看到:</p><figure class="kl km kn ko gt kp gh gi paragraph-image"><div role="button" tabindex="0" class="oe of di og bf oh"><div class="gh gi qp"><img src="../Images/422f16e790eb76c554eb0f6a4717b3e9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*VPwKFGqce24NYFKp.png"/></div></div></figure><p id="74f7" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">厉害！我们最终预测未来五个交易日的收盘价，并评估模型的 MAPE。</p><p id="b9b5" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">在这种情况下，我们有 0.79%的 MAPE，这非常好！</p><h2 id="0946" class="nr kt iv bd ku ns nt dn ky nu nv dp lc lr nw nx le lt ny nz lg lv oa ob li oc bi translated">将预测价格与实际数据进行比较</h2><figure class="kl km kn ko gt kp"><div class="bz fp l di"><div class="rq rr l"/></div></figure><p id="8e11" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">现在，为了将我们的预测与实际数据进行比较，我们从<a class="ae mc" href="https://ca.finance.yahoo.com/" rel="noopener ugc nofollow" target="_blank">雅虎财经</a>获取财务数据，并创建一个数据框架。</p><p id="cbf2" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">然后，我们画一个图，看看我们离实际收盘价有多远:</p><figure class="kl km kn ko gt kp gh gi paragraph-image"><div role="button" tabindex="0" class="oe of di og bf oh"><div class="gh gi qp"><img src="../Images/d824cb08ede9f2c2539c237221786c18.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*ZYH-6NvI0J05i0CC.png"/></div></div><figcaption class="oi oj gj gh gi ok ol bd b be z dk">Comparison of predicted and actual closing prices</figcaption></figure><p id="5885" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">看来我们的预测有点偏差。事实上，预测价格基本持平，这意味着我们的模型可能表现不佳。</p><p id="a04f" class="pw-post-body-paragraph mv mw iv lm b ln ni jw mx lp nj jz my lr nk na nb lt nl nd ne lv nm ng nh lx io bi translated">同样，这不是因为我们的程序，而是因为预测股票价格基本上是不可能的</p><h1 id="cefd" class="ks kt iv bd ku kv kw kx ky kz la lb lc kb ld kc le ke lf kf lg kh lh ki li lj bi translated">来源</h1><ol class=""><li id="ef7b" class="lk ll iv lm b ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb bi translated"><a class="ae mc" href="http://faculty.marshall.usc.edu/gareth-james/" rel="noopener ugc nofollow" target="_blank">统计学习介绍</a> —加雷斯·詹姆士<em class="om">等</em>。</li><li id="b118" class="lk ll iv lm b ln md lp me lr mf lt mg lv mh lx ly lz ma mb bi translated"><a class="ae mc" href="https://www.coursera.org/learn/machine-learning" rel="noopener ugc nofollow" target="_blank">机器学习</a> —吴恩达</li><li id="990b" class="lk ll iv lm b ln md lp me lr mf lt mg lv mh lx ly lz ma mb bi translated"><a class="ae mc" href="https://medium.com/open-machine-learning-course/open-machine-learning-course-topic-9-time-series-analysis-in-python-a270cb05e0b3" rel="noopener">开放机器学习课程:时间序列</a> —德米特里·谢尔盖耶夫</li></ol></div></div>    
</body>
</html>