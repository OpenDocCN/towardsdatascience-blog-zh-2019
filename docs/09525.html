<html>
<head>
<title>How to Build a Content-Based Movie Recommender System</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">如何构建基于内容的电影推荐系统</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/how-to-build-a-content-based-movie-recommender-system-92352f5db7c6?source=collection_archive---------13-----------------------#2019-12-15">https://towardsdatascience.com/how-to-build-a-content-based-movie-recommender-system-92352f5db7c6?source=collection_archive---------13-----------------------#2019-12-15</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="a574" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">创建基于内容的电影推荐系统</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/46e57878769e650bfd5f99096f79e823.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ID8CZKUq5-5we9n2W1-HeA.jpeg"/></div></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk">Designed by rawpixel.com / Freepik</figcaption></figure><p id="51e9" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">在这篇文章中，我将尝试解释我们如何在没有用户数据的情况下创建一个推荐系统。我还将分享一个我用 Python 做的例子，并一步步告诉你它是如何工作的。</p><p id="a476" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">我不打算单独解释推荐系统的类型，因为它在互联网上很容易找到。所以，我们先来说说基于内容的推荐系统吧！</p><h1 id="d15a" class="lu lv it bd lw lx ly lz ma mb mc md me jz mf ka mg kc mh kd mi kf mj kg mk ml bi translated">什么是基于内容的推荐系统？</h1><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi mm"><img src="../Images/3a16450a0af0d83fa3af431d62d4cd01.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*GKeESn8RruAbAUEm4k3_EQ.png"/></div></div></figure><p id="793e" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">基于内容的推荐系统不包括从除你之外的用户那里检索的数据。它只是通过识别与你喜欢的产品相似的产品来帮助你。</p><p id="911f" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">例如，您有一个在线销售商品的网站，但您还没有注册用户，但您仍然想向网站的访问者推荐产品。在这种情况下，基于内容的推荐系统将是您的理想选择。</p><p id="3a61" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">然而，基于内容的推荐系统是有限的，因为它们不包含其他用户数据。它也不能帮助用户发现他们潜在的品味。</p><p id="4912" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">举个例子，假设用户 A 和用户 B 喜欢剧情电影。用户 A 也喜欢喜剧电影，但是既然你没有那方面的知识，你就继续提供剧情电影。最终，你排除了用户 B 可能喜欢的其他选项。</p><p id="7ff4" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">反正！在创建这个系统之前，我们先来讨论几个术语。先说<a class="ae mn" href="https://en.wikipedia.org/wiki/Kernel_density_estimation" rel="noopener ugc nofollow" target="_blank">核密度估计</a>！</p><h1 id="8537" class="lu lv it bd lw lx ly lz ma mb mc md me jz mf ka mg kc mh kd mi kf mj kg mk ml bi translated">核密度估计</h1><blockquote class="mo mp mq"><p id="d7f2" class="ky kz mr la b lb lc ju ld le lf jx lg ms li lj lk mt lm ln lo mu lq lr ls lt im bi translated">核密度估计是一个非常有用的统计工具，有一个吓人的名字。通常简称为<strong class="la iu"> KDE </strong>，这是一种让你在给定一组数据的情况下创建平滑曲线的技术。</p></blockquote><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi mv"><img src="../Images/aa34c884cec53c7afa783a7fb83e4e65.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ABix8Fk6HTCEIB10BX6MPw.png"/></div></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk">KDE plot example from seaborn</figcaption></figure><p id="1d57" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">KDE 是一种帮助确定数据分布密度的方法。它提供了许多点位于何处和不在何处的信息。因此，在一维数组中，它通过将最低密度点(局部最小值)与最高密度点(局部最大值)分开来帮助您进行聚类。只要遵循这些步骤，</p><ol class=""><li id="fdd4" class="mw mx it la b lb lc le lf lh my ll mz lp na lt nb nc nd ne bi translated">计算密度</li><li id="e930" class="mw mx it la b lb nf le ng lh nh ll ni lp nj lt nb nc nd ne bi translated">寻找局部最小值和局部最大值</li><li id="8795" class="mw mx it la b lb nf le ng lh nh ll ni lp nj lt nb nc nd ne bi translated">创建集群</li></ol><h1 id="4b97" class="lu lv it bd lw lx ly lz ma mb mc md me jz mf ka mg kc mh kd mi kf mj kg mk ml bi translated">余弦相似性</h1><p id="f439" class="pw-post-body-paragraph ky kz it la b lb nk ju ld le nl jx lg lh nm lj lk ll nn ln lo lp no lr ls lt im bi translated"><a class="ae mn" href="https://en.wikipedia.org/wiki/Cosine_similarity" rel="noopener ugc nofollow" target="_blank">余弦相似度</a>是一种度量向量之间相似度的方法。数学上，它计算两个向量之间角度的余弦值。如果两个向量之间的角度为零，则相似性被计算为 1，因为零的余弦为 1。所以这两个向量是相同的。任何角度的余弦值从 0 到 1 不等。因此，相似率将从 0 变化到 1。该公式表示如下:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi np"><img src="../Images/2f1f759bac9584ed0d979d2099478386.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*FCpDu6yvkAcP-OMRsOrajQ.png"/></div></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk">Cosine similarity formula</figcaption></figure><p id="74bd" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">现在够了！我们来编码吧！</p><h1 id="5fd6" class="lu lv it bd lw lx ly lz ma mb mc md me jz mf ka mg kc mh kd mi kf mj kg mk ml bi translated">特征重要性</h1><p id="1ca2" class="pw-post-body-paragraph ky kz it la b lb nk ju ld le nl jx lg lh nm lj lk ll nn ln lo lp no lr ls lt im bi translated">我想为每部电影或连续剧设定一个分数，并且我需要为每个特征设定一个系数，所以我将查看特征的重要性。</p><p id="a7ff" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">数据集如下:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nq"><img src="../Images/c24b3bf5b97dcbc98e0b1d662cf686e6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*x7XkvVmBMGbTWz_Bec6asA.png"/></div></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk">Sample data</figcaption></figure><p id="f940" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">通过合并在<a class="ae mn" href="https://datasets.imdbws.com" rel="noopener ugc nofollow" target="_blank">https://datasets.imdbws.com</a>共享的文件，你可以很容易地获得这个数据集。我通过将 title.basics.tsv.gz 的<strong class="la iu"><em class="mr"/></strong>与 title.ratings.tsv.gz 的<strong class="la iu"><em class="mr"/></strong><em class="mr"/>合并得到这个数据，之后，我删除了一些特征。例如，<em class="mr"> end_year </em>字段包含了太多的空值，所以我删除了它。更多详细信息，请查看我的知识库。在本文最后分享。</p><p id="d779" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">我还得多说一个细节，我已经通过使用<em class="mr">标签编码器</em>将<em class="mr">种类</em>字段转换为<em class="mr">整数</em>字段。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nr ns l"/></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk">Feature importances</figcaption></figure><p id="b8df" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">正如你在上面看到的，我已经尝试了三种不同的方法。首先是由<strong class="la iu"> <em class="mr">随机森林</em> </strong>模型直接提供的特性的重要性。</p><p id="20d3" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">另一个是<strong class="la iu"> <em class="mr">排列重要性</em> </strong>。这种方法通过对每个预测值使用随机重排技术来直接测量磁场对模型的影响。它保持了变量的分布，因为它使用了随机重排技术。</p><p id="38af" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">最后是<strong class="la iu"> <em class="mr">降列特征重要度</em> </strong>。这种方法是完全直观的，每次它删除一个特征，并将其与使用所有列的模型进行比较。它通常要安全得多，但处理时间可能会很长。处理时间对我们的数据集来说并不重要。</p><p id="7bc2" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">结果是这样的:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nt"><img src="../Images/af6b72a6103f70399800b560d8ad133d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_ZbjpC2vz5tK8xCaJzgIXA.png"/></div></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk">Feature importance results</figcaption></figure><p id="8f55" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">我们在这些方法中选择了<strong class="la iu">删除列特征重要性</strong>方法。正如我们之前指出的，它更加可靠，当我们看一眼结果时，它们对计算分数更有意义。</p><pre class="kj kk kl km gt nu nv nw nx aw ny bi"><span id="0da3" class="nz lv it nv b gy oa ob l oc od">dataset['score'] = (<br/>    0.4576 * dataset['num_votes'] + <br/>    0.3271 * dataset['runtime'] + <br/>    0.3517 * dataset['start_year'] + <br/>    0.0493 * dataset['kind']<br/>)</span></pre><h1 id="1972" class="lu lv it bd lw lx ly lz ma mb mc md me jz mf ka mg kc mh kd mi kf mj kg mk ml bi translated">使聚集</h1><p id="cead" class="pw-post-body-paragraph ky kz it la b lb nk ju ld le nl jx lg lh nm lj lk ll nn ln lo lp no lr ls lt im bi translated">我将使用分数来创建聚类。所以我可以推荐平均分数相同的电影。</p><p id="79b8" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">我有一个分数的一维数组，我可以用 KDE 聚类。我用这个代码来看分数的分布:</p><pre class="kj kk kl km gt nu nv nw nx aw ny bi"><span id="818d" class="nz lv it nv b gy oa ob l oc od">import matplotlib.pyplot as plt<br/>import seaborn as sns</span><span id="df66" class="nz lv it nv b gy oe ob l oc od">plt.figure(figsize=(9, 6))<br/>sns.distplot(dataset['score'])<br/>plt.axvline(18000, color='r');</span></pre><p id="c09c" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">我得到了这样一张图表，</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi of"><img src="../Images/7ea40d79133f751db00139ae775d617b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*guQO677Y_Kg8qL6gCO-yMQ.png"/></div></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk">Score distribution</figcaption></figure><p id="2127" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">我加了一条竖线 18000，因为密度在 650 到 18000 之间。如果我在应用 KDE 时给你大于 18，000 的点，它会将所有小于 18，000 的点收集在一个聚类中，这不是我们想要的，因为这会降低多样性。</p><p id="ee7f" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">正如我在文章开头提到的，我应用了 3 个阶段对 KDE 进行聚类。</p><ol class=""><li id="9c67" class="mw mx it la b lb lc le lf lh my ll mz lp na lt nb nc nd ne bi translated">计算密度</li></ol><pre class="kj kk kl km gt nu nv nw nx aw ny bi"><span id="eb5b" class="nz lv it nv b gy oa ob l oc od">from sklearn.neighbors.kde import KernelDensity</span><span id="b15b" class="nz lv it nv b gy oe ob l oc od">vals = dataset['score'].values.reshape(-1, 1)<br/>kde = KernelDensity(kernel='gaussian', bandwidth=3).fit(vals)<br/><br/>s = np.linspace(650, 18000)<br/>e = kde.score_samples(s.reshape(-1, 1))</span></pre><p id="c9d0" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">2.寻找局部最小值和局部最大值</p><pre class="kj kk kl km gt nu nv nw nx aw ny bi"><span id="5e0b" class="nz lv it nv b gy oa ob l oc od">from scipy.signal import argrelextrema</span><span id="2f65" class="nz lv it nv b gy oe ob l oc od">mi = argrelextrema(e, np.less)[0]<br/>ma = argrelextrema(e, np.greater)[0]</span><span id="a9d5" class="nz lv it nv b gy oe ob l oc od">points = np.concatenate((s[mi], s[ma]), axis=0)<br/>buckets = []<br/><br/>for point in points:<br/>    buckets.append(point)</span><span id="6025" class="nz lv it nv b gy oe ob l oc od">buckets = np.array(buckets)<br/>buckets.sort()</span></pre><p id="3f96" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">3.创建集群</p><pre class="kj kk kl km gt nu nv nw nx aw ny bi"><span id="70a2" class="nz lv it nv b gy oa ob l oc od">dataset['cluster'] = buckets.searchsorted(dataset.score)</span></pre><h1 id="557a" class="lu lv it bd lw lx ly lz ma mb mc md me jz mf ka mg kc mh kd mi kf mj kg mk ml bi translated">文本相似度</h1><p id="ce3c" class="pw-post-body-paragraph ky kz it la b lb nk ju ld le nl jx lg lh nm lj lk ll nn ln lo lp no lr ls lt im bi translated">最后，我计算了类型之间的相似性，以便能够尽可能准确地推荐同一类型的电影。为此我使用了 TF-IDF 和线性内核。因此，在背景中使用余弦相似性来寻找相似性。</p><pre class="kj kk kl km gt nu nv nw nx aw ny bi"><span id="38b2" class="nz lv it nv b gy oa ob l oc od">from sklearn.feature_extraction.text import TfidfVectorizer<br/>from sklearn.metrics.pairwise import linear_kernel</span><span id="f4d6" class="nz lv it nv b gy oe ob l oc od">tfidf_vectorizer = TfidfVectorizer()<br/>matrix = tfidf_vectorizer.fit_transform(dataset['genres'])</span><span id="f21d" class="nz lv it nv b gy oe ob l oc od">kernel = linear_kernel(matrix, matrix)</span></pre><p id="d7f4" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">现在就来看看推荐吧！</p><pre class="kj kk kl km gt nu nv nw nx aw ny bi"><span id="9087" class="nz lv it nv b gy oa ob l oc od">def get_recommendations2(movie_index):<br/>    print(dataset.iloc[movie_index])<br/>    print('**' * 40)<br/>    sim_ = list(enumerate(kernel[movie_index]))<br/>    <br/>    sim = sorted(sim_, key=lambda x: x[1], reverse=True)<br/>    index = [i[0] for i in sim if i[0] != movie_index and i[1] &gt; .5]<br/>    <br/>    cond1 = dataset.index.isin(index)<br/>    cond2 = dataset.cluster == dataset.iloc[movie_index]['cluster']</span><span id="b6c3" class="nz lv it nv b gy oe ob l oc od">    selected = dataset.loc[cond1 &amp; cond2] \<br/>        .sort_values(by='score', ascending=False).head(20)</span><span id="322a" class="nz lv it nv b gy oe ob l oc od">    print(selected[['title', 'cluster', 'genres']])</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi og"><img src="../Images/2f39861021aa5061e5331b20009eda97.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*EFgjlv2xX0WGrthEEh46WA.png"/></div></div></figure><p id="3f0d" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">这对我来说似乎很有用！如果你想看更详细的代码，用<strong class="la iu"> <em class="mr">烧瓶</em> </strong>上菜，用<strong class="la iu"> <em class="mr">橡皮筋搜索</em> </strong>索引电影，用<strong class="la iu"> <em class="mr"> docker </em> </strong>，你可以看看我的资源库:</p><div class="oh oi gp gr oj ok"><a href="https://github.com/egemenzeytinci/recommovie" rel="noopener  ugc nofollow" target="_blank"><div class="ol ab fo"><div class="om ab on cl cj oo"><h2 class="bd iu gy z fp op fr fs oq fu fw is bi translated">egemenzeytinci/recommovie</h2><div class="or l"><h3 class="bd b gy z fp op fr fs oq fu fw dk translated">对于所有选项，克隆存储库，$ git 克隆 https://github.com/egemenzeytinci/recommovie.git 构建并运行…</h3></div><div class="os l"><p class="bd b dl z fp op fr fs oq fu fw dk translated">github.com</p></div></div><div class="ot l"><div class="ou l ov ow ox ot oy ks ok"/></div></div></a></div><p id="bd98" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">感谢您的阅读！</p><h1 id="dad8" class="lu lv it bd lw lx ly lz ma mb mc md me jz mf ka mg kc mh kd mi kf mj kg mk ml bi translated">参考</h1><ul class=""><li id="e323" class="mw mx it la b lb nk le nl lh oz ll pa lp pb lt pc nc nd ne bi translated">Eryk Lewinson，<a class="ae mn" rel="noopener" target="_blank" href="/explaining-feature-importance-by-example-of-a-random-forest-d9166011959e">以随机森林为例解释特征重要性</a> (2019)</li><li id="55f0" class="mw mx it la b lb nf le ng lh nh ll ni lp nj lt pc nc nd ne bi translated">马修·康伦<strong class="la iu">，</strong>，<a class="ae mn" href="https://mathisonian.github.io/kde/" rel="noopener ugc nofollow" target="_blank">核密度估计</a></li><li id="df57" class="mw mx it la b lb nf le ng lh nh ll ni lp nj lt pc nc nd ne bi translated">马修·奥弗比，<a class="ae mn" href="https://blog.mattoverby.net/2017/05/1d-clustering-with-kde.html" rel="noopener ugc nofollow" target="_blank"> 1D 与 KDE </a> (2017)</li><li id="de42" class="mw mx it la b lb nf le ng lh nh ll ni lp nj lt pc nc nd ne bi translated"><a class="ae mn" href="https://www.kaggle.com/adamschroeder/countvectorizer-tfidfvectorizer-predict-comments" rel="noopener ugc nofollow" target="_blank">计数矢量器，tfidf 矢量器，预测评论</a> (2018)</li></ul></div></div>    
</body>
</html>