# 关于人工智能，记者需要知道什么

> 原文：<https://towardsdatascience.com/what-journalists-need-to-know-about-artificial-intelligence-ebc8f08b1b78?source=collection_archive---------16----------------------->

## 专业人员指南

![](img/15b602aa21e9dd321b53a4269079f3af.png)

Photo by [Andrew Neel](https://unsplash.com/@andrewtneel?utm_source=medium&utm_medium=referral) on [Unsplash](https://unsplash.com?utm_source=medium&utm_medium=referral)

# 为什么是这篇文章？

一名记者最近让我评论一个涉及脸书人工智能算法的阴谋论的可行性。他想知道脸书是否有可能使用其现有的自杀视频检测算法来筛选和审查保守的媒体来源。为了有意义地回答这个问题，我发现我需要花一个小时来教育这位记者关于人工智能的一般知识，只是为了给他足够的背景信息来理解我对阴谋论的评估。在这样做的过程中，我让他有能力处理未来与人工智能相关的调查，随着人工智能扩大与我们日常生活的互动，他和他的同事在未来肯定会越来越频繁地遇到这些调查。

从上面描述的遭遇中，我意识到记者们将很快面临越来越多的解释和评论与人工智能相关的各种社会问题的需求。我的结论是，目前大多数记者都不具备完成这项任务的条件。为了补救这种情况，我撰写了这本初级读本，以帮助记者获得足够的相关知识，帮助他们做他们最擅长的事情:引导公众讨论当天的相关问题。

我不是唯一一个说记者需要人工智能技术状态以及它如何与日常生活互动的信息的人；著名的人工智能先驱费最近向《连线》杂志提供了以下引文:

> *“我也非常希望人工智能扫盲更加普遍——从* **记者** *开始，但也包括政策制定者、教师和公民社会。这不是一个教授想要每个人都知道如何编码；而是让更多的人参与到 AI 的引导中”[1](强调我的)。*

事实是，作为公民和全球北方的经济参与者，我们现在每天都在消耗人工智能算法的产出。虽然(非人工智能)算法和计算机调节的体验已经存在了相当长一段时间，但人工智能在今天规模上的实际商业应用是非常新的——只是在最近七八年才出现。为了控制由此产生的社会后果，我们需要足够了解人工智能的外行人来做出明智的决定。记者们发现自己处在一个就这些问题接触普通人的位置上，我希望这篇文章能帮助他们完成这项任务。

# 关键要点

以下是这篇文章中需要记住的关键事项，每一个都在下面的文本中有更详细的描述:

*   我们进入全面的人工智能革命只有大约十年，人工智能的广泛使用使商业和政府决策影响了大量的个人。因此，我们需要伟大的记者来引导我们完成这一转变！
*   AI 的使用导致了不良的社会后果，包括死亡和不适当的长期监禁。
*   人工智能和机器学习技术努力模仿智能，无论是人类智能还是一种与人类非常不同的智能。
*   一个人工智能过程只是创建一个它试图做出决策的真实世界问题域的近似模型。因此，近似值的限制削弱了它的准确性。
*   一个人工智能解决方案可能在一个非常具体的问题上表现良好——它被训练来解决的问题。然而，它不会有效地推广到其他任务。
*   用于训练人工智能算法的数据集的偏差导致其输出的偏差。
*   人工智能算法被证明很难审计。
*   我们不知道人工智能的使用可能给社会带来的后果，例如，可能的技术失业。

# 人工智能失败比比皆是

对记者来说，眼前的问题是人工智能的应用有时会产生实质性的问题，记者会向公众传播这些故事，并发表社论。几个例子:

*   当基于人工智能的面部识别技术被用于控制犯罪时，错误的身份会导致逮捕和/或公开羞辱无辜者[18，19]。
*   最近，一辆优步无人驾驶汽车撞死了一名行人。
*   最近人工智能驱动的亚马逊员工招聘算法产生了可测量的性别偏见[18，21]。

当然，一个人也可能犯这样的错误，但是大多数社会已经建立了处理人为错误的协议。我们没有为人工智能相关的错误建立这样的协议——关于这个问题需要一个全球性的对话。事实将证明，记者对这场对话至关重要。

# 什么是人工智能和机器学习？

人工智能(AI)泛指让计算机模仿智能的研究和工程实践。在这里，我给“智力”下了一个松散的定义；它可以意味着模仿人类的信息和决策能力[2]，也可以指与人类思维高度不同的智力发展[3]。但是这些定义都是基于计算机本身并不智能的假设。我的意思是，要使它们有用，它们必须被“编程”，即由人类以某种方式指导。

深入挖掘指令的问题:在计算历史的大部分时间里，人类编写“程序”来指导计算机的数据处理和决策。软件工程师应用 C++或 Python 等编程语言来详述运行给定程序的计算机会做出的每一个动作。这些详细的指令被证明是非常明确的(例如，如果用户键入“Hello”然后按回车键，那么打印“Hello back to you！”在屏幕上)。

然而，这种活动没有很好地扩展。编写明确的指令来解释每一个可能的输入和每一个可能的决策是困难的，即使对于最好的软件工程团队也是如此。因此，人工智能研究人员设计了两个基本框架作为回应:“专家系统”和“机器学习”(ML)。两者几乎同时出现在学术界，但后者只是在最近几年才开始商业化。本文将主要关注机器学习，但在这里，我将简要解释专家系统作为起点:

专家系统试图解决这样一个挑战，即从给定的程序输入中显式地编写每个决策的脚本。它们在 20 世纪 80 年代激增[5],但现在大部分已经半途而废。一个“知识工程师”会在采访一个专家，比如一个高度专业化的医生之后，将数据输入到专家系统中。大量事实将被手动收集——因此考虑每个可能的输入的问题仍然存在——然后“推理引擎”(本身是一种算法)将处理这些事实以得出结论，而不需要对每个数据影响的特定推理步骤进行编码。以这种方式，他们被认为是模仿专家的智力。专家系统仍在使用——仅在去年一年，我就创建了两个，一个用于医疗推理，一个用于时尚推荐——但人工智能的研究和实践在很大程度上已经转向第二个框架:机器学习。

机器学习试图解决每个可能的输入或输入组合的问题，这样软件工程师就不必再这样做了。本质上，工程师“训练”一种算法，以从大量已知输入中产生所需输出，其中已知输出通常伴随着每个提供的已知输入，以帮助训练。例如，旨在检测视频中滑板存在的 ML 算法将显示数万到数十万个视频，有些有滑板，有些没有。在最常见的情况下，这些视频中的每一个都将被“标记”为要么有滑板，要么没有滑板。ML 训练程序将处理这些输入，并“学习”如何在未来看不见的视频中检测滑板。在这种情况下，工程师变得更像“老师”，而不是显式规则的设计者(稍后将详细介绍)。

委婉地说，机器学习已经迅速席卷了全世界。ML 算法驱动着谷歌的搜索结果[10]、网飞的电影推荐[9]和脸书的过滤器[8]。大公司使用 ML 来过滤简历和监控员工[11]。一些司法管辖区在刑事判决程序中使用 ML[7]。中国应用基于最大似然的面部识别来压迫维吾尔少数民族[6]。就我而言，我已经将 ML 用于分子设计[12]，货币交易[13]，政治偏见检测[14]，并向音乐家提供关于观众热情的实时反馈[15]。

本文的其余部分将特别关注机器学习，并与人工智能互换使用该术语，这是当今的常见做法。

# 什么是“模型”？

AI 从业者经常把自己创造的算法称为“模型”。原因如下:

模型是对真实世界对象的近似，用于帮助对该对象的研究或决策。建模的对象可以是物理的，例如在风洞中测试的模型飞机，过程，例如供应链的动态图，或者甚至是想法，例如在商务午餐期间在餐巾纸上绘制的商业模型的“信封背面”。模型也可以是数学的，如一组一个或多个方程。比如“E = mc”就是描述能量和质量之间物理关系的数学模型。

更重要的是，机器学习算法是数学模型——一个方程(或一组方程),近似于算法训练所依据的输入和输出之间的真实世界关系。训练过程“发现”这些关系，并将它们编码到方程的参数中。然后，在新的输入上运行经过训练的 ML 模型，辅助甚至取代人类在现实世界中的决策。

# 这里我们遇到了第一个问题…

我在最后一段故意用了“近似”这个词。模型只是它们所反映的对象的近似值，而不是真实的东西。因此，丢失了一些细节，基于模型得出的结论可能不能充分反映现实。例如，风洞中的模型飞机可能没有真实飞机的每一个铆钉和接缝。因此，这些未建模的铆钉和接缝的微流体效应(在现实生活中可能会增加明显的阻力)仍未被发现。

同样，我的货币兑换市场 ML 模型没有考虑到影响价格波动的每一个可能的因素。举例来说，我(还)没有包括央行声明的影响。我也不能包括政治事件；在最近美国和中国之间的贸易战中，我的模型损失了钱。预测的结果是，当现实转向另一个方向时，算法有时会预测一个价格方向。

好吧，我损失了一些钱。没什么大不了的。但是考虑到类似的模型决定了社会重要的事情，比如一个给定的罪犯的刑期有多长。或者你(以及一整群人——在某些方面与你相似，你可能知道也可能不知道)是否得到了一份你胜任的工作。或者评估你母亲的癌症状况。使用这些“近似”模型可以做出严肃的决策。

接下来，记者、政策制定者和哲学家面临的一个关于人工智能使用的迫切问题是“多长时间犯一次错误是可以接受的？”。当然，这取决于应用:如果我的货币预测只有 60%的正确率，我仍然在大量交易中赚钱。但是，对于自动驾驶汽车的行人检测算法来说，社会可以容忍的准确度是多少呢？99.9%?99.99999%?在基于人工智能的癌症诊断中，你可以获得第二种意见。但是自动驾驶汽车可能会撞死人！

即使自动驾驶汽车偶尔会碾过行人，人们也必须评估它们在避免行人方面的表现与人类驾驶员相比如何，着眼于决定人类驾驶员还是人工驾驶员总体上更好。诸如此类的问题及其政策后果需要社会讨论。记者在这些讨论中发挥着重要作用。

# 假阳性和假阴性

更正式地说，在两种可能性(例如，有罪与无罪、感染与未感染、视频中存在滑板与视频中不存在滑板)之间进行选择的任何类型的程序(无论是法庭案件、医学测试还是机器学习算法)被称为“分类器”。从技术上讲，分类器可以涉及两个以上的结果，但是为了定义以下关键术语，我们将把对话限制在双向分类器上:

当一个分类器说一个情况是真的(有罪、被感染、滑板存在)，而那个情况实际上是假的，我们就把这个结论叫做“假阳性”。类似地，被声明为假的真实情况被表示为“假阴性”。基于人工智能的分类算法的设计者寻求减少这些假阳性和假阴性的数量，就像刑事司法系统寻求减少不准确判决的数量一样。但是，如上所述，不准确的结论仍然存在，我们作为一个社会必须决定对于给定的应用，我们可以接受什么样的错误结论率。

为了说明在现实世界中的社会后果，2015 年谷歌图像分类器设计用于识别照片中的大猩猩，产生了误报，宣布图像中的黑人是大猩猩[4]。在另一个众所周知的情况下[5]，人工智能在一些司法管辖区被用来预测一个被定罪的罪犯是否会再次犯罪。这种算法产生的假阳性可能会导致更长的刑期。在我介绍这篇文章的案例中，为了回应一个阴谋论，即脸书正在使用其自杀视频检测算法审查右翼视频，我得出的结论是，最有可能的情况是，自杀视频检测算法对特定的审查右翼视频产生了误报，从而催生了阴谋。

# 人工智能很“脆弱”

继续讨论脸书的自杀视频检测算法；

AI 的能力远不如公众普遍认为的那样。最令人困惑的是人工智能的可归纳性。换句话说，人们倾向于认为被训练来执行任务的人工智能算法可以很容易地适应执行相关的任务。事实并非如此，因此我们称人工智能算法为“脆弱的”，意思是它们不能适应不断变化的条件。(提高人工智能的可推广性是一个积极研究的领域)。

关于脸书的自杀视频检测算法，由于该技术缺乏可推广性，它根本无法准确判断视频是否显示极右翼极端主义内容。如果脸书想要这样的算法，他们很可能已经有了，他们必须使用一套完全不同的训练视频从头开始训练它。然后，这种算法一旦被训练，就不能用于检测 ISIS 的宣传——他们需要再次从头开始。

# 你只能根据你之前看到的来预测

当我第一次申请学分时，远在现代人工智能出现之前，我只是因为事先没有任何学分而被拒绝。发卡方的算法——可能基于传统的统计方法——只知道如何处理以前有信用记录的申请人，因为这很可能是程序员在创建它时考虑的。

同样的问题仍然存在于今天更加有效的机器学习技术中:它们只能根据在训练过程中看到的输入来近似数据和结果之间的关系。当给定的输入数据场景位于训练域之外足够远时，该算法是无助的。易碎。

# 这里我们遇到了第二个主要问题:训练偏差

当讨论机器学习模型仅在它们被训练的数据范围内是好的这一事实时(例如，我上面描述的信用模型不知道如何处理零信用历史的申请人)，我们意识到在选择所使用的数据时可能存在偏差。例如，对于错误地将黑人归类为大猩猩的谷歌算法，很可能在训练过程中很少使用黑人(相对于白人)的照片作为输入。由此产生的影响让我想起了“所有黑人看起来都一样”的态度，这种态度仍然让许多无辜的人被送进监狱，只是在潜在的不准确性上更加“精确”。

上面我把 ML 算法的训练者称为“老师”。所有的老师都会把他们的偏见传递给学生，不管他们喜不喜欢。甚至已经证明，软件工程师在他们所谓的中性代码中传播他们的社会偏见[17]。

# 不透明盒子

大多数机器学习技术中涉及的数学通常是高维的，这意味着一个训练好的模型可能有成千上万个与之相关的数字。因此，对于一个人来说，审核模型是很困难的；来确定 it 中的哪些关系驱动了哪些行为。这在自动驾驶汽车等情况下是一个问题，假设这样一辆汽车撞到了行人，我们会希望当局以调查飞机失事的同样方式调查碰撞的原因。然而，飞机中的机械关系虽然复杂，但在大多数情况下可以清晰地追溯到一连串的因果关系。然而，由于大多数 ML 模型的不透明性质，在自动驾驶汽车的行人检测算法的情况下，这种评估将被证明是不可实现的。

提高机器学习技术的可问责性和可审计性仍然是一个活跃的学术研究领域。

# 社会必须尽快解决的未知问题

两个与人工智能相关的大未知数即将出现:技术失业和 ML 算法“串扰”的影响。随着这些情况成为焦点，记者们会发现自己在描述这种情况。

自工业革命以来，技术失业的幽灵，即由于自动化而大规模快速解雇人类工人(及其社会后果)，一直困扰着西方。然而，今天工业社会发展的每一个转折点都创造了足够多的新工作来取代那些失去的工作。这种趋势是否会在人工智能驱动的自动化中保持，还有待观察。在过去，自动化取代了需要很少人类脑力来执行的简单任务，让人类执行更复杂的推理和创造性活动。现在，需要更多训练和智力的职业面临风险；假设受过高等教育的中产阶级，而不仅仅是无产阶级，发现自己大量失业？在这种情况下，我们的政治、经济和社会稳定会发生什么变化？

第二个未知可能被认为是“人工智能生态”[16]。随着成千上万的 ML 算法调整我们的日常经验，算法之间的串扰必然会发生，并且以不可能预测的方式发生。举个简单的例子，当我从历史价格数据中训练我的货币交易算法时，我间接地包括了所有其他 ML 算法对历史价格数据的净影响(其他交易者拥有的算法)。当我的算法执行交易时，他们的算法会响应我的信号。这种影响可能是缓和的，也可能滚雪球般变成灾难性的事情。我们根本不知道。

因此，我将整个生产 AI 操作空间视为一个生态:算法以类似于生态概念的方式直接并通过我们相互交互。真正的力量不在于谁能做出“最好”或“正确”的算法(尽管这很有帮助)，而在于谁能更好地将这个复杂的交互生态“偏向”他们的目标。

# 这场革命仅仅进行了十年

我们(社会)在这场革命中只有大约十年的时间；在那之前，人工智能所需的计算需求超过了现成的硅片所能推动的，因此人工智能仍停留在实验室中。现在我们生活在这样一个世界里，人工智能可以被新手工程师经济地部署到生产环境中，以产生显著的商业收益。其结果可能会像互联网的引入一样，被证明是一场彻底的社会变革。

伟大的记者才能带领我们度过这场剧变。

![](img/e07667eeb192d061ae0dc0d5af4825b6.png)

Photo by [Andrew Neel](https://unsplash.com/@andrewtneel?utm_source=medium&utm_medium=referral) on [Unsplash](https://unsplash.com?utm_source=medium&utm_medium=referral)

# 参考

1.  [https://www . wired . com/story/飞飞-李-艾-关心-更多-关于-人类/](https://www.wired.com/story/fei-fei-li-ai-care-more-about-humans/)
2.  [https://www . Forbes . com/sites/Bernard marr/2018/02/14/the-key-definitions-of-artificial-intelligence-ai-that-explain-its-importance/# 4e1a 52774 f5d](https://www.forbes.com/sites/bernardmarr/2018/02/14/the-key-definitions-of-artificial-intelligence-ai-that-explain-its-importance/#4e1a52774f5d)
3.  [https://www . fast company . com/40459339/Google-perspective-fighting-hate-and-trolls-a-mind-ai](https://www.fastcompany.com/40459339/google-perspective-fighting-hate-and-trolls-with-a-mindless-ai)
4.  [https://www . USA today . com/story/tech/2015/07/01/Google-道歉-拍照后-识别-黑人-大猩猩/29567465/](https://www.usatoday.com/story/tech/2015/07/01/google-apologizes-after-photos-identify-black-people-as-gorillas/29567465/)
5.  [https://en.wikipedia.org/wiki/Expert_system](https://en.wikipedia.org/wiki/Expert_system)
6.  [https://www . the guardian . com/news/2019/apr/11/China-high-tech-war-on-Muslim-minority-新疆-维吾尔-监控-人脸识别](https://www.theguardian.com/news/2019/apr/11/china-hi-tech-war-on-muslim-minority-xinjiang-uighurs-surveillance-face-recognition)
7.  [https://www . technology review . com/s/612775/algorithms-criminal-justice-ai/](https://www.technologyreview.com/s/612775/algorithms-criminal-justice-ai/)
8.  [https://edition . CNN . com/2019/05/01/tech/Facebook-ai-F8/index . html](https://edition.cnn.com/2019/05/01/tech/facebook-ai-f8/index.html)
9.  [https://becoming human . ai/how-网飞-uses-ai-and-machine-learning-a 087614630 Fe](https://becominghuman.ai/how-netflix-uses-ai-and-machine-learning-a087614630fe)
10.  [https://www . wired . com/2016/02/ai-is-changing-the-technology-behind-Google-searches/](https://www.wired.com/2016/02/ai-is-changing-the-technology-behind-google-searches/)
11.  [https://www . HR technologist . com/articles/digital-transformation/the-初学者指南-ai-in-hr/](https://www.hrtechnologist.com/articles/digital-transformation/the-beginners-guide-to-ai-in-hr/)
12.  [https://badassdatasscience . com/2018/01/07/rapid-identifying-potential-crispr cas 9-off-target-sites-part-one/](https://badassdatascience.com/2018/01/07/rapidly-identifying-potential-crisprcas9-off-target-sites-part-one/)
13.  [https://badassdatasscience . com/2017/08/16/pseudo-harmonic-forex-prediction-with-machine-learning-part-one/](https://badassdatascience.com/2017/08/16/pseudo-harmonic-forex-prediction-with-machine-learning-part-one/)
14.  罗伯特·爱泼斯坦和艾米丽·威廉姆斯。2019.*2018 年美国中期选举前 10 天在线搜索结果中系统性政治偏见的证据。*西方心理学协会第 99 届年会，加利福尼亚州帕萨迪纳，2019 年 4 月 26 日。
15.  [https://badassdatasscience . com/2018/05/12/using-ai-to-measure-fan-sizes-at-music-festivals-and-discoques/](https://badassdatascience.com/2018/05/12/using-ai-to-measure-fan-enthusiasm-at-music-festivals-and-discotheques/)
16.  [https://badassdatasscience . com/2012/03/10/ai _ and _ algorithm-ecologists/](https://badassdatascience.com/2012/03/10/ai_and_algorithm-ecologists/)
17.  [https://blogs . scientific American . com/root-of-unity/even-kids-can-understand-that-algorithms-can-be-biased/](https://blogs.scientificamerican.com/roots-of-unity/even-kids-can-understand-that-algorithms-can-be-biased/)
18.  [https://medium . com/synced review/2018-in-review-10-ai-failures-C18 faadf 5983](https://medium.com/syncedreview/2018-in-review-10-ai-failures-c18faadf5983)
19.  [https://www . telegraph . co . uk/technology/2018/11/25/Chinese-business woman-被告-乱穿马路-ai-camera-spots-face/](https://www.telegraph.co.uk/technology/2018/11/25/chinese-businesswoman-accused-jaywalking-ai-camera-spots-face/)
20.  [https://www . nytimes . com/2018/03/19/technology/Uber-driver less-deadline . html](https://www.nytimes.com/2018/03/19/technology/uber-driverless-fatality.html)
21.  [https://www . Reuters . com/article/us-Amazon-com-jobs-automation-insight/Amazon-scraps-secret-ai-recruiting-tool-show-bias-against-women-iduskcn 1 MK 08g](https://www.reuters.com/article/us-amazon-com-jobs-automation-insight/amazon-scraps-secret-ai-recruiting-tool-that-showed-bias-against-women-idUSKCN1MK08G)