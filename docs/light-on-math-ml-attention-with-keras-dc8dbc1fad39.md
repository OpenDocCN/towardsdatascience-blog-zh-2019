# Keras æ·±å±‚ç½‘ç»œä¸­çš„æ³¨æ„åŠ›

> åŸæ–‡ï¼š<https://towardsdatascience.com/light-on-math-ml-attention-with-keras-dc8dbc1fad39?source=collection_archive---------0----------------------->

## [ç‚¹äº®æ•°å­¦æœºå™¨å­¦ä¹ ](https://towardsdatascience.com/tagged/light-on-math)

## å°†æ‰€æœ‰é”™ç»¼å¤æ‚çš„æ³¨æ„åŠ›è½¬ç§»åˆ°å–€æ‹‰æ–¯çš„ä¸€æ¡ä¼˜é›…çš„çº¿ä¸Š

![](img/1b88455455109f0215537cf0f5961368.png)

Courtesy of Pixabay

è¿™ä¸ªæ•…äº‹å‘æ‚¨ä»‹ç»äº†ä¸€ä¸ª Github å­˜å‚¨åº“ï¼Œå…¶ä¸­åŒ…å«ä¸€ä¸ªä½¿ç”¨ Keras åç«¯æ“ä½œå®ç°çš„åŸå­æœ€æ–°å…³æ³¨å±‚ã€‚å¯åœ¨ [**å…³æ³¨ _keras**](https://github.com/thushv89/attention_keras) **è·å¾—ã€‚**

è¦è®¿é—®æœ¬ç³»åˆ—ä¸­æˆ‘ä»¥å‰çš„æ–‡ç« ï¼Œè¯·ä½¿ç”¨ä»¥ä¸‹ä¿¡ä»¶ã€‚

[**A**](/light-on-math-ml-attention-with-keras-dc8dbc1fad39)**B**[**C**](http://www.thushv.com/computer_vision/light-on-math-machine-learning-intuitive-guide-to-convolution-neural-networks/)**[**D**](/light-on-math-machine-learning-intuitive-guide-to-understanding-decision-trees-adb2165ccab7)*** E F G H I J**[**K**](http://www.thushv.com/machine-learning/light-on-math-machine-learning-intuitive-guide-to-understanding-kl-divergence/)**[**L*******](/light-on-math-machine-learning-intuitive-guide-to-latent-dirichlet-allocation-437c81220158)[**M**](https://medium.com/p/bee5af0c01aa)****

******[** ğŸ”ˆğŸ”¥**æœ€æ–°æ–‡ç« **ğŸ”¥ğŸ”ˆ**:[Mâ€”çŸ©é˜µåˆ†è§£](https://medium.com/p/bee5af0c01aa)******

# ******ä¸ºä»€ä¹ˆæ˜¯ Kerasï¼Ÿ******

******éšç€ TensorFlow 2.0 çš„æ¨å‡ºï¼Œå¾ˆéš¾å¿½è§†å¼•äººæ³¨ç›®çš„å…³æ³¨(æ²¡æœ‰åŒå…³è¯­ï¼)é€ç»™ Kerasã€‚æœ‰æ›´å¤šçš„é‡ç‚¹æ˜¯å€¡å¯¼ Keras å®æ–½æ·±åº¦ç½‘ç»œã€‚TensorFlow 2.0 ä¸­çš„ Keras å°†æä¾›ä¸‰ä¸ªå¼ºå¤§çš„ API æ¥å®ç°æ·±åº¦ç½‘ç»œã€‚******

*   ******é¡ºåº APIâ€”â€”è¿™æ˜¯æœ€ç®€å•çš„ APIï¼Œé¦–å…ˆè°ƒç”¨`model = Sequential()`å¹¶ä¸æ–­æ·»åŠ å±‚ï¼Œä¾‹å¦‚`model.add(Dense(...))`ã€‚******
*   ******åŠŸèƒ½ API â€”é«˜çº§ APIï¼Œæ‚¨å¯ä»¥åœ¨å…¶ä¸­åˆ›å»ºå…·æœ‰ä»»æ„è¾“å…¥/è¾“å‡ºçš„è‡ªå®šä¹‰æ¨¡å‹ã€‚å®šä¹‰ä¸€ä¸ªæ¨¡å‹éœ€è¦éå¸¸å°å¿ƒï¼Œå› ä¸ºåœ¨ç”¨æˆ·ç«¯æœ‰å¾ˆå¤šäº‹æƒ…è¦åšã€‚å¯ä»¥ä½¿ç”¨`model = Model(inputs=[...], outputs=[...])`å®šä¹‰æ¨¡å‹ã€‚******
*   ******å­ç±»åŒ– APIâ€”â€”å¦ä¸€ä¸ªé«˜çº§ APIï¼Œå¯ä»¥å°†æ¨¡å‹å®šä¹‰ä¸º Python ç±»ã€‚åœ¨è¿™é‡Œï¼Œæ‚¨å¯ä»¥åœ¨ç±»ä¸­å®šä¹‰æ¨¡å‹çš„å‘å‰ä¼ é€’ï¼ŒKeras ä¼šè‡ªåŠ¨è®¡ç®—å‘åä¼ é€’ã€‚é‚£ä¹ˆè¿™ä¸ªæ¨¡å‹å¯ä»¥åƒä½¿ç”¨ä»»ä½• Keras æ¨¡å‹ä¸€æ ·æ­£å¸¸ä½¿ç”¨ã€‚******

******æ›´å¤šä¿¡æ¯ï¼Œ[ä» TensorFlow å›¢é˜Ÿè·å¾—ç¬¬ä¸€æ‰‹ä¿¡æ¯](https://www.tensorflow.org/guide/keras)ã€‚ç„¶è€Œï¼Œè¯·è®°ä½ï¼Œè™½ç„¶é€‰æ‹©é«˜çº§ API ä¸ºå®ç°å¤æ‚æ¨¡å‹æä¾›äº†æ›´å¤šçš„â€œå›æ—‹ç©ºé—´â€ï¼Œä½†å®ƒä»¬ä¹Ÿå¢åŠ äº†å‡ºç°é”™è¯¯å’Œå„ç§å…”å­æ´çš„æœºä¼šã€‚******

# ******ä¸ºä»€ä¹ˆå‘è¿™ä¸ªå¸–å­ï¼Ÿ******

******æœ€è¿‘ï¼Œæˆ‘æ­£åœ¨ä¸ºæˆ‘æ­£åœ¨åšçš„ä¸€ä¸ªé¡¹ç›®å¯»æ‰¾ä¸€ä¸ªåŸºäº Keras çš„æ³¨æ„åŠ›å±‚å®ç°æˆ–åº“ã€‚æˆ‘å¤„ç†äº†å‡ ä¸ªå·²ç»å¼•èµ·å…³æ³¨çš„å›å¤ã€‚ç„¶è€Œï¼Œæˆ‘çš„åŠªåŠ›æ˜¯å¾’åŠ³çš„ï¼Œè¯•å›¾è®©ä»–ä»¬ä¸ä»¥åçš„ TF ç‰ˆæœ¬ã€‚ç”±äºå‡ ä¸ªåŸå› :******

*   ******å®ç°æ³¨æ„åŠ›çš„æ–¹å¼ç¼ºä¹æ¨¡å—åŒ–(å¯¹æ•´ä¸ªè§£ç å™¨è€Œä¸æ˜¯è§£ç å™¨çš„å„ä¸ªå±•å¼€æ­¥éª¤å®ç°æ³¨æ„åŠ›******
*   ******ä½¿ç”¨æ—©æœŸ TF ç‰ˆæœ¬ä¸­ä¸æ¨èä½¿ç”¨çš„å‡½æ•°******

******ä»–ä»¬åšå‡ºäº†å·¨å¤§çš„åŠªåŠ›ï¼Œæˆ‘å°Šé‡æ‰€æœ‰åšå‡ºè´¡çŒ®çš„äººã€‚ä½†æ˜¯æˆ‘æƒ³æˆ‘ä¼šä»‹å…¥å¹¶å®ç°ä¸€ä¸ª **AttentionLayer** ï¼Œå®ƒé€‚ç”¨äºæ›´å¤šçš„åŸå­çº§åˆ«ï¼Œå¹¶éšç€æ–°çš„ TF ç‰ˆæœ¬è€Œæ›´æ–°ã€‚è¿™ä¸ªåº“åœ¨[è¿™é‡Œ](https://github.com/thushv89/attention_keras)å¯ç”¨ã€‚******

******æ³¨**:è¿™æ˜¯æ•°å­¦æœºå™¨å­¦ä¹  A-Z ä¸Š ***å…‰ç³»åˆ—çš„ä¸€ç¯‡æ–‡ç« ã€‚ä½ å¯ä»¥åœ¨ä¸‹é¢çš„ä¿¡ä¸­æ‰¾åˆ°ä»¥å‰çš„åšå®¢æ–‡ç« ã€‚*******

******A B**[**C**](http://www.thushv.com/computer_vision/light-on-math-machine-learning-intuitive-guide-to-convolution-neural-networks/)**[**D**](/light-on-math-machine-learning-intuitive-guide-to-understanding-decision-trees-adb2165ccab7)*** E F G H I J**[**K**](http://www.thushv.com/machine-learning/light-on-math-machine-learning-intuitive-guide-to-understanding-kl-divergence/)**[**L**](/light-on-math-machine-learning-intuitive-guide-to-latent-dirichlet-allocation-437c81220158)*** M**[**N**](/light-on-math-machine-learning-intuitive-guide-to-neural-style-transfer-ef88e46697ee)**O P Q R S T U V**********

# ****ä»‹ç»****

****åœ¨è¿™ç¯‡æ–‡ç« ä¸­ï¼Œé¦–å…ˆä½ ä¼šæ¢ç©¶ä»€ä¹ˆæ˜¯åºåˆ—å¯¹åºåˆ—æ¨¡å‹ï¼Œç„¶åæ˜¯ä¸ºä»€ä¹ˆæ³¨æ„åŠ›å¯¹åºåˆ—æ¨¡å‹å¾ˆé‡è¦ï¼Ÿæ¥ä¸‹æ¥ï¼Œä½ å°†å­¦ä¹ æ³¨æ„åŠ›æœºåˆ¶çš„æœ¬è´¨ã€‚è¿™ç¯‡åšæ–‡å°†ä»¥è§£é‡Šå¦‚ä½•ä½¿ç”¨æ³¨æ„åŠ›å±‚æ¥ç»“æŸã€‚****

# ****åºåˆ—åˆ°åºåˆ—æ¨¡å‹****

****Sequence to sequence æ˜¯ä¸€ä¸ªå¼ºå¤§çš„æ·±åº¦å­¦ä¹ æ¨¡å‹å®¶æ—ï¼Œæ—¨åœ¨è§£å†³ ML é¢†åŸŸä¸­æœ€ç–¯ç‹‚çš„é—®é¢˜ã€‚ä¸¾ä¸ªä¾‹å­ï¼Œ****

*   ****æœºå™¨ç¿»è¯‘****
*   ****èŠå¤©æœºå™¨äºº****
*   ****æ–‡æœ¬æ‘˜è¦****

****æœ‰ç€éå¸¸ç‹¬ç‰¹å’Œç‹¬ç‰¹çš„æŒ‘æˆ˜ã€‚æ¯”å¦‚æœºå™¨ç¿»è¯‘è¦å¤„ç†ä¸åŒçš„[è¯­åºæ‹“æ‰‘](https://en.wikipedia.org/wiki/Word_order)(å³ä¸»è¯­-åŠ¨è¯-å®¾è¯­é¡ºåº)ã€‚å› æ­¤å®ƒä»¬æ˜¯è§£å†³å¤æ‚ NLP é—®é¢˜çš„å¿…å¤‡æ­¦å™¨ã€‚****

****è®©æˆ‘ä»¬çœ‹çœ‹å¦‚ä½•å°†åºåˆ—å¯¹åºåˆ—æ¨¡å‹ç”¨äºè‹±æ³•æœºå™¨ç¿»è¯‘ä»»åŠ¡ã€‚****

****åºåˆ—å¯¹åºåˆ—æ¨¡å‹æœ‰ä¸¤ä¸ªç»„ä»¶ï¼Œä¸€ä¸ª**ç¼–ç å™¨**å’Œä¸€ä¸ª**è§£ç å™¨**ã€‚ç¼–ç å™¨å°†æºå¥å­ç¼–ç æˆä¸€ä¸ªç®€æ´çš„å‘é‡(ç§°ä¸º**ä¸Šä¸‹æ–‡å‘é‡**)ï¼Œè§£ç å™¨å°†ä¸Šä¸‹æ–‡å‘é‡ä½œä¸ºè¾“å…¥ï¼Œå¹¶ä½¿ç”¨ç¼–ç çš„è¡¨ç¤ºæ¥è®¡ç®—ç¿»è¯‘ã€‚****

****![](img/9ef7ddbbf4852f7b7404e43af109e39d.png)****

****Sequence to sequence model****

# ****è¿™ç§æ–¹æ³•æœ‰é—®é¢˜å—ï¼Ÿ****

****è¿™ç§æ–¹æ³•æœ‰ä¸€ä¸ªå·¨å¤§çš„ç“¶é¢ˆã€‚ä¸Šä¸‹æ–‡å‘é‡è´Ÿè´£å°†ç»™å®šæºå¥å­ä¸­çš„æ‰€æœ‰ä¿¡æ¯ç¼–ç æˆä¸€ä¸ªåŒ…å«å‡ ç™¾ä¸ªå…ƒç´ çš„å‘é‡ã€‚ç°åœ¨ç»™å‡ºä¸€ç‚¹èƒŒæ™¯ï¼Œè¿™ä¸ªå‘é‡éœ€è¦ä¿æŒ:****

*   ****å…³äºä¸»è¯­ã€å®¾è¯­å’ŒåŠ¨è¯çš„ä¿¡æ¯****
*   ****è¿™äº›å®ä½“ä¹‹é—´çš„ç›¸äº’ä½œç”¨****

****è¿™å¯èƒ½æ˜¯ç›¸å½“ä»¤äººç”Ÿç•çš„ï¼Œå°¤å…¶æ˜¯å¯¹äºé•¿å¥ã€‚å› æ­¤ï¼Œéœ€è¦ä¸€ç§æ›´å¥½çš„è§£å†³æ–¹æ¡ˆæ¥çªç ´æé™ã€‚****

# ****è¾“å…¥å…³æ³¨ï¼****

****å¦‚æœè§£ç å™¨èƒ½å¤Ÿè®¿é—®ç¼–ç å™¨çš„æ‰€æœ‰è¿‡å»çŠ¶æ€ï¼Œè€Œä¸æ˜¯ä»…ä»…ä¾èµ–äºä¸Šä¸‹æ–‡å‘é‡ï¼Œä¼šæ€ä¹ˆæ ·ï¼Ÿè¿™æ­£æ˜¯æ³¨æ„åŠ›åœ¨åšçš„äº‹æƒ…ã€‚åœ¨æ¯ä¸ªè§£ç æ­¥éª¤ä¸­ï¼Œè§£ç å™¨éƒ½ä¼šæŸ¥çœ‹ç¼–ç å™¨çš„ä»»ä½•ç‰¹å®šçŠ¶æ€ã€‚è¿™é‡Œæˆ‘ä»¬å°†è®¨è®º [Bahdanau æ³¨æ„åŠ›](https://arxiv.org/pdf/1409.0473.pdf)ã€‚ä¸‹å›¾æç»˜äº†æ³¨æ„åŠ›çš„å†…éƒ¨è¿ä½œã€‚****

****![](img/67b72586bcb8e59b83196ff1f2518c65.png)****

****Sequence to sequence with attention****

****å› æ­¤ï¼Œå¦‚å›¾æ‰€ç¤ºï¼Œä¸Šä¸‹æ–‡å‘é‡å·²ç»æˆä¸ºæ‰€æœ‰è¿‡å»ç¼–ç å™¨çŠ¶æ€çš„**åŠ æƒå’Œã€‚******

# ****ä»‹ç» attention_keras****

****ç”±äºæˆ‘å‰é¢è§£é‡Šçš„åŸå› ï¼Œè®©ä¸€äº›æ³¨æ„åŠ›å±‚åœ¨é‚£é‡Œå·¥ä½œå¯èƒ½ä¼šå¾ˆéº»çƒ¦ã€‚****

# ****ä½¿ç”¨æ³¨æ„åŠ›å±‚****

****æ‚¨å¯ä»¥å°†å®ƒç”¨ä½œä»»ä½•å…¶ä»–å±‚ã€‚ä¸¾ä¸ªä¾‹å­ï¼Œ****

```
**attn_layer = AttentionLayer(name='attention_layer')([encoder_out, decoder_out])**
```

****æˆ‘è¿˜æä¾›äº†ä¸€ä¸ªç©å…·ç¥ç»æœºå™¨ç¿»è¯‘å™¨(NMT)çš„ä¾‹å­ï¼Œå±•ç¤ºäº†å¦‚ä½•åœ¨ NMT ( [nmt/train.py](https://github.com/thushv89/attention_keras/blob/master/examples/nmt/train.py) )ä¸­ä½¿ç”¨æ³¨æ„åŠ›å±‚ã€‚ä½†æ˜¯è®©æˆ‘å¸¦ä½ äº†è§£ä¸€äº›ç»†èŠ‚ã€‚****

# ****ç”¨å¿ƒå®æ–½ NMT****

****åœ¨è¿™é‡Œï¼Œæˆ‘å°†ç®€è¦ä»‹ç»ä¸€ä¸‹å®ç° NMT çš„æ­¥éª¤ã€‚****

****é¦–å…ˆå®šä¹‰ç¼–ç å™¨å’Œè§£ç å™¨è¾“å…¥(æº/ç›®æ ‡å­—)ã€‚ä¸¤è€…éƒ½æ˜¯å½¢çŠ¶(batch_sizeï¼Œtimestepsï¼Œvocabulary_size)ã€‚****

```
**encoder_inputs = Input(batch_shape=(batch_size, en_timesteps, en_vsize), name='encoder_inputs')
decoder_inputs = Input(batch_shape=(batch_size, fr_timesteps - 1, fr_vsize), name='decoder_inputs')**
```

****å®šä¹‰ç¼–ç å™¨(æ³¨æ„`return_sequences=True`)****

```
**encoder_gru = GRU(hidden_size, return_sequences=True, return_state=True, name='encoder_gru')
encoder_out, encoder_state = encoder_gru(encoder_inputs)**
```

****å®šä¹‰è§£ç å™¨(æ³¨æ„`return_sequences=True`****

```
**decoder_gru = GRU(hidden_size, return_sequences=True, return_state=True, name='decoder_gru')
decoder_out, decoder_state = decoder_gru(decoder_inputs, initial_state=encoder_state)**
```

****å®šä¹‰å…³æ³¨å±‚ã€‚æ³¨æ„å±‚çš„è¾“å…¥æ˜¯`encoder_out`(ç¼–ç å™¨è¾“å‡ºåºåˆ—)å’Œ`decoder_out`(è§£ç å™¨è¾“å‡ºåºåˆ—)****

```
**attn_layer = AttentionLayer(name='attention_layer')
attn_out, attn_states = attn_layer([encoder_out, decoder_out])**
```

****è¿æ¥`attn_out`å’Œ`decoder_out`ä½œä¸º softmax å±‚çš„è¾“å…¥ã€‚****

```
**decoder_concat_input = Concatenate(axis=-1, name='concat_layer')([decoder_out, attn_out])**
```

****å®šä¹‰`TimeDistributed` Softmax å±‚å¹¶æä¾›`decoder_concat_input`ä½œä¸ºè¾“å…¥ã€‚****

```
**dense = Dense(fr_vsize, activation='softmax', name='softmax_layer')
dense_time = TimeDistributed(dense, name='time_distributed_layer')
decoder_pred = dense_time(decoder_concat_input)**
```

****å®šä¹‰å®Œæ•´æ¨¡å‹ã€‚****

```
**full_model = Model(inputs=[encoder_inputs, decoder_inputs], outputs=decoder_pred)
full_model.compile(optimizer='adam', loss='categorical_crossentropy')**
```

****å°±æ˜¯è¿™æ ·ï¼****

# ****ç”šè‡³æ”¯æŒæ³¨æ„åŠ›å¯è§†åŒ–â€¦****

****è¿™ä¸ä»…å®ç°äº†æ³¨æ„åŠ›ï¼Œä¹Ÿç»™äº†ä½ ä¸€ä¸ªå¾ˆå®¹æ˜“çª¥è§†æ³¨æ„åŠ›æœºåˆ¶çš„æ–¹æ³•ã€‚è¿™æ˜¯å¯èƒ½çš„ï¼Œå› ä¸ºè¿™ä¸€å±‚è¿”å›ä¸¤è€…ï¼Œ****

*   ****æ³¨æ„ä¸Šä¸‹æ–‡å‘é‡(ç”¨ä½œè§£ç å™¨çš„ Softmax å±‚çš„é¢å¤–è¾“å…¥)****
*   ****æ³¨æ„èƒ½é‡å€¼(æ³¨æ„æœºåˆ¶çš„ Softmax è¾“å‡º)****

****å¯¹äºæ¯ä¸ªè§£ç æ­¥éª¤ã€‚å› æ­¤ï¼Œé€šè¿‡å¯è§†åŒ–æ³¨æ„åŠ›èƒ½é‡å€¼ï¼Œä½ å¯ä»¥å®Œå…¨äº†è§£æ³¨æ„åŠ›åœ¨è®­ç»ƒ/æ¨ç†è¿‡ç¨‹ä¸­åœ¨åšä»€ä¹ˆã€‚ä¸‹é¢ï¼Œæˆ‘æ¥è¯´è¯´è¿™ä¸ªè¿‡ç¨‹çš„ä¸€äº›ç»†èŠ‚ã€‚****

# ****ä» NMT æ¨æ–­å¹¶è·å¾—å…³æ³¨æƒé‡****

****ä» NMT æ¨æ–­æ˜¯ç¹ççš„ï¼å› ä¸ºä½ å¿…é¡»è¿™ä¹ˆåšï¼Œ****

*   ****è·å–ç¼–ç å™¨è¾“å‡º****
*   ****å®šä¹‰ä¸€ä¸ªæ‰§è¡Œè§£ç å™¨çš„å•ä¸ªæ­¥éª¤çš„è§£ç å™¨(å› ä¸ºæˆ‘ä»¬éœ€è¦æä¾›è¯¥æ­¥éª¤çš„é¢„æµ‹ä½œä¸ºä¸‹ä¸€æ­¥çš„è¾“å…¥)****
*   ****ä½¿ç”¨ç¼–ç å™¨è¾“å‡ºä½œä¸ºè§£ç å™¨çš„åˆå§‹çŠ¶æ€****
*   ****æ‰§è¡Œè§£ç ï¼Œç›´åˆ°æˆ‘ä»¬å¾—åˆ°ä¸€ä¸ªæ— æ•ˆå­—/ <eos>ä½œä¸ºè¾“å‡º/æˆ–å›ºå®šæ­¥æ•°</eos>****

****æˆ‘ä¸æ‰“ç®—è®¨è®ºæ¨¡å‹å®šä¹‰ã€‚è¯¦æƒ…è¯·å‚è€ƒ`examples/nmt/train.py`ã€‚è®©æˆ‘ä»¬æ¥çœ‹çœ‹å¦‚ä½•åˆ©ç”¨è¿™ä¸€ç‚¹æ¥è·å¾—å…³æ³¨æƒé‡ã€‚****

```
**for i in range(20):

    dec_out, attention, dec_state = decoder_model.predict([enc_outs, dec_state, test_fr_onehot_seq])
    dec_ind = np.argmax(dec_out, axis=-1)[0, 0]

    ...

    attention_weights.append((dec_ind, attention))** 
```

****å¦‚ä½ æ‰€è§ï¼Œæˆ‘ä»¬æ­£åœ¨ä¸ºæ¯ä¸ªè§£ç æ­¥éª¤æ”¶é›†æ³¨æ„åŠ›æƒé‡ã€‚****

****ç„¶åï¼Œæ‚¨åªéœ€å°†è¿™ä¸ªæ³¨æ„åŠ›æƒé‡åˆ—è¡¨ä¼ é€’ç»™`plot_attention_weights` ( [nmt/train.py](https://github.com/thushv89/attention_keras/blob/master/examples/nmt/train.py) )ï¼Œä»¥ä¾¿è·å¾—å¸¦æœ‰å…¶ä»–å‚æ•°çš„æ³¨æ„åŠ›çƒ­å›¾ã€‚ç»˜å›¾åçš„è¾“å‡ºå¯èƒ½å¦‚ä¸‹æ‰€ç¤ºã€‚****

****![](img/aa769458d19069ddcfbfec0cd9fbc54a.png)****

# ****2022 å¹´ 6 æœˆæ›´æ–°****

****æœ€è¿‘æœ‰ä¸€ä¸ªå…³äº AttentionLayer [åœ¨ TensorFlow 2.4+ç‰ˆæœ¬](https://github.com/thushv89/attention_keras/issues/59)ä¸Šä¸å·¥ä½œçš„ bug æŠ¥å‘Šã€‚è¿™å¯¼è‡´äº†å¦‚ä¸‹çš„ç¥ç§˜é”™è¯¯ï¼Œ****

```
**TypeError: Exception encountered when calling layer "tf.keras.backend.rnn" (type TFOpLambda).

You are passing KerasTensor(type_spec=TensorSpec(shape=(None, 101), dtype=tf.float32, name=None), name='tf.compat.v1.nn.softmax_1/Softmax:0', description="created by layer 'tf.compat.v1.nn.softmax_1'"), an intermediate Keras symbolic input/output, to a TF API that does not allow registering custom dispatchers, such as `tf.cond`, `tf.function`, gradient tapes, or `tf.map_fn`. Keras Functional model construction only supports TF API calls that *do* support dispatching, such as `tf.math.add` or `tf.reshape`. Other APIs cannot be called directly on symbolic Kerasinputs/outputs. You can work around this limitation by putting the operation in a custom Keras layer `call` and calling that layer on this symbolic input/output.

Call arguments received:
  â€¢ step_function=<function AttentionLayer.call.<locals>.energy_step at 0x7f1d5ff279e0>
  â€¢ inputs=tf.Tensor(shape=(None, None, 256), dtype=float32)
  â€¢ initial_states=['tf.Tensor(shape=(None, 101), dtype=float32)']
  â€¢ go_backwards=False
  â€¢ mask=None
  â€¢ constants=None
  â€¢ unroll=False
  â€¢ input_length=None
  â€¢ time_major=False
  â€¢ zero_output_for_mask=False**
```

****è¯¥é”™è¯¯æ˜¯ç”±äºåŸºäºå›¾å½¢çš„`KerasTensor`å¯¹è±¡å’Œæ¸´æœ›çš„`tf.Tensor`å¯¹è±¡ä¹‹é—´çš„æ··æ·†é€ æˆçš„ã€‚å³å°†åˆå¹¶çš„ https://github.com/thushv89/attention_keras/tree/tf2-fix åˆ†å…¬å¸æ­£åœ¨è¿›è¡Œè°ƒæ•´ã€‚****

# ****ç»“è®º****

****åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘å‘æ‚¨ä»‹ç»äº† AttentionLayer çš„ä¸€ä¸ªå®ç°ã€‚æ³¨æ„åŠ›å¯¹äºåºåˆ—æ¨¡å‹ç”šè‡³å…¶ä»–ç±»å‹çš„æ¨¡å‹éƒ½æ˜¯éå¸¸é‡è¦çš„ã€‚ç„¶è€Œï¼Œå½“å‰çš„å®ç°è¦ä¹ˆä¸æ˜¯æœ€æ–°çš„ï¼Œè¦ä¹ˆä¸æ˜¯éå¸¸æ¨¡å—åŒ–ã€‚æ‰€ä»¥æˆ‘ç¨å¾®æŒ–äº†ä¸€ä¸‹ï¼Œç”¨ Keras åç«¯æ“ä½œå®ç°äº†ä¸€ä¸ªæ³¨æ„åŠ›å±‚ã€‚æ‰€ä»¥æˆ‘å¸Œæœ›ä½ èƒ½åœ¨è¿™ä¸€å±‚åšå¾—å¾ˆå¥½ã€‚å¦‚æœæ‚¨æœ‰ä»»ä½•é—®é¢˜/å‘ç°ä»»ä½• bugï¼Œè¯·éšæ—¶åœ¨ Github ä¸Šæäº¤é—®é¢˜ã€‚****

# ****æ¬¢è¿è´¡çŒ®è€…****

****æˆ‘å°†éå¸¸æ„Ÿè°¢æœ‰è´¡çŒ®è€…ï¼Œä¿®å¤ä»»ä½•é”™è¯¯/å®æ–½æ–°çš„æ³¨æ„æœºåˆ¶ã€‚æ‰€ä»¥æ¬¢è¿æŠ•ç¨¿ï¼****

****å¦‚æœä½ å–œæ¬¢æˆ‘åˆ†äº«çš„å…³äºæ•°æ®ç§‘å­¦å’Œæœºå™¨å­¦ä¹ çš„æ•…äº‹ï¼Œè€ƒè™‘æˆä¸ºä¼šå‘˜å§ï¼****

****[](https://thushv89.medium.com/membership) [## é€šè¿‡æˆ‘çš„æ¨èé“¾æ¥åŠ å…¥åª’ä½“

### ä½œä¸ºä¸€ä¸ªåª’ä½“ä¼šå‘˜ï¼Œä½ çš„ä¼šå‘˜è´¹çš„ä¸€éƒ¨åˆ†ä¼šç»™ä½ é˜…è¯»çš„ä½œå®¶ï¼Œä½ å¯ä»¥å®Œå…¨æ¥è§¦åˆ°æ¯ä¸€ä¸ªæ•…äº‹â€¦

thushv89.medium.com](https://thushv89.medium.com/membership)**** 

# ****æƒ³åœ¨æ·±åº¦ç½‘ç»œå’Œ TensorFlow ä¸Šåšå¾—æ›´å¥½ï¼Ÿ****

****æ£€æŸ¥æˆ‘åœ¨è¿™ä¸ªè¯¾é¢˜ä¸Šçš„å·¥ä½œã€‚****

****![](img/c902b07566ddcbe9ec0bc8a9c98954cb.png)****

****[1] [(ä¹¦)TensorFlow 2 åœ¨è¡ŒåŠ¨â€”â€”æ›¼å®](https://www.manning.com/books/tensorflow-in-action)****

****[2] [(è§†é¢‘è¯¾ç¨‹)Python ä¸­çš„æœºå™¨ç¿»è¯‘](https://www.datacamp.com/courses/machine-translation-in-python) â€” DataCamp****

****[3] [(ä¹¦)TensorFlow ä¸­çš„è‡ªç„¶è¯­è¨€å¤„ç† 1](https://www.amazon.com.au/Natural-Language-Processing-TensorFlow-Ganegedara/dp/1788478312/ref=sr_1_25?dchild=1&keywords=nlp+with+tensorflow&qid=1603009947&sr=8-25) â€” Packt****

# ****æ–°çš„ï¼åŠ å…¥æˆ‘çš„æ–° YouTube é¢‘é“****

****[![](img/9aa6e53203c7a7784377ba29519f211f.png)](https://www.youtube.com/channel/UC1HkxV8PtmWRyQ39MfzmtGA/)****

****å¦‚æœä½ æ¸´æœ›çœ‹åˆ°æˆ‘å…³äºå„ç§æœºå™¨å­¦ä¹ /æ·±åº¦å­¦ä¹ ä¸»é¢˜çš„è§†é¢‘ï¼Œè¯·ç¡®ä¿åŠ å…¥ [DeepLearningHero](https://www.youtube.com/channel/UC1HkxV8PtmWRyQ39MfzmtGA/) ã€‚****