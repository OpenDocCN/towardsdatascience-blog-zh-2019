# ä½¿ç”¨ PyTorch çš„è‡ªé€‚åº”å’Œå¾ªç¯å­¦ä¹ ç‡

> åŸæ–‡ï¼š<https://towardsdatascience.com/adaptive-and-cyclical-learning-rates-using-pytorch-2bf904d18dee?source=collection_archive---------7----------------------->

![](img/fd378827193a1346c176dffff448f18e.png)

Photo by [Sirma Krusteva](https://unsplash.com/@forevercarrieon?utm_source=medium&utm_medium=referral) on [Unsplash](https://unsplash.com?utm_source=medium&utm_medium=referral)

å­¦ä¹ ç‡(LR)æ˜¯è°ƒæ•´ç¥ç»ç½‘ç»œçš„å…³é”®å‚æ•°ä¹‹ä¸€ã€‚å…·æœ‰è‡ªé€‚åº”å­¦ä¹ ç‡çš„ SGD ä¼˜åŒ–å™¨å·²ç»æµè¡Œäº†ä¸€æ®µæ—¶é—´:Adamã€Adamax å’Œå®ƒçš„è€å…„å¼Ÿä»¬é€šå¸¸æ˜¯äº‹å®ä¸Šçš„æ ‡å‡†ã€‚å®ƒä»¬æ¶ˆé™¤äº†æ‰‹åŠ¨æœç´¢å’Œå®‰æ’ä½ çš„å­¦ä¹ é€Ÿåº¦(å¦‚è¡°å‡ç‡)çš„ç—›è‹¦ã€‚

![](img/98a0975b88fcf01d6a7840ec4a8be046.png)

Source: Jeremy Jordanâ€™s blogpost

è¿™ç¯‡æ–‡ç« å°†ç»™å‡ºä¸€ä¸ªç®€çŸ­çš„ä¾‹å­ï¼Œæ¦‚è¿°å’Œæ¯”è¾ƒæœ€æµè¡Œçš„è‡ªé€‚åº”å­¦ä¹ ç‡ä¼˜åŒ–ã€‚æˆ‘ä»¬å°†ä½¿ç”¨ PyTorchï¼Œæ—¶é«¦çš„ç¥ç»ç½‘ç»œåº“çš„é€‰æ‹©ï¼

![](img/cda1e97f5b9df9a14b6b2ea2bc2cb859.png)

é™¤æ­¤ä¹‹å¤–ï¼Œfast.ai è¿˜å®£æ‰¬äº†å¾ªç¯å­¦ä¹ ç‡(CLR)çš„æ¦‚å¿µï¼Œæåˆ°äº†è±æ–¯åˆ©Â·å²å¯†æ–¯çš„ä¼Ÿå¤§è®ºæ–‡([é“¾æ¥](https://arxiv.org/abs/1506.01186))ã€‚æˆ‘ä»¬å°†çœ‹çœ‹ SGD å¦‚ä½•ä¸å…¶ä»–ä¼˜åŒ–ç¨‹åºç›¸æŠ—è¡¡ã€‚

ä¸ºäº†æ¼”ç¤ºï¼Œæˆ‘ä»¬å°†æ‰¿æ‹…ä¸¤é¡¹åˆ†ç±»ä»»åŠ¡:

*   åŸºäºæ™®é€š CNN æ¶æ„çš„å›¾åƒåˆ†ç±»
*   ä½¿ç”¨é¢„è®­ç»ƒ(åœ¨ ImageNet ä¸Š)çš„ ResNet34 ç½‘ç»œè¿›è¡Œå›¾åƒåˆ†ç±»

è¯¥èŒä½çš„æ‰€æœ‰ä»£ç å’ŒåŸ¹è®­æ—¥å¿—å¯ä»¥åœ¨ [GitHub](https://github.com/TDehaene/blogposts/tree/master/learning_rates) ä¸Šæ‰¾åˆ°ã€‚

# æ•°æ®

åœ¨è¿™ç¯‡æ–‡ç« ä¸­ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨ Kaggle çš„â€œé²œèŠ±è¯†åˆ«â€æ•°æ®é›†([é“¾æ¥](https://www.kaggle.com/alxmamaev/flowers-recognition))ã€‚è¿™æ˜¯ä¸€ä¸ªå¾ˆå¥½çš„æµ‹è¯•å›¾åƒåˆ†ç±»ç½‘ç»œçš„åŸºæœ¬çœŸå®æ•°æ®é›†ã€‚

![](img/0f63e34bf61a1f1a64e80baedb20a0ac.png)

example image of the class â€˜dandelionâ€™

ä½¿ç”¨ 20%è¿›è¡ŒéªŒè¯çš„æ•°æ®è¢«å¹³å‡åˆ†é…åˆ° 5 ä¸ªç±»åˆ«ä¸­è¿›è¡Œé¢„æµ‹:

# è‡ªé€‚åº”ä¼˜åŒ–å™¨

åœ¨ä¸æ·±å…¥ç ”ç©¶æ¯ä¸€ä¸ªä¼˜åŒ–å™¨çš„æ•°å­¦åŸç†çš„æƒ…å†µä¸‹ï¼Œè¿™é‡Œæœ‰ä¸€ä¸ªç®€çŸ­(æœ‰ç‚¹è¿‡äºç®€å•)çš„æ¦‚è¿°ï¼Œä»‹ç»ä¸€ä¸‹æˆ‘ä»¬å°†è¦ä¸ä¹‹å¯¹æŠ—çš„ä¼˜åŒ–å™¨:

*   **Adagrad** :è¿™å°†æ ¹æ®æ¢¯åº¦çš„è¿‡å»å†å²ï¼Œç¼©æ”¾æ¯ä¸ªå‚æ•°çš„å­¦ä¹ ç‡ã€‚æœ¬è´¨ä¸Š:å¤§æ¢¯åº¦= >å°Î±ï¼Œåä¹‹äº¦ç„¶ã€‚ç„¶è€Œä¸åˆ©çš„ä¸€é¢æ˜¯å­¦ä¹ ç‡ä¼šå¾ˆå¿«ä¸‹é™ã€‚
*   **Adadelta** :åœ¨ Adagrad ä¸Šç»§ç»­ï¼Œä½†æ˜¯æœ‰äº†æ–°çš„èŠ±æ ·:åªå­˜å‚¨è¿‡å»çš„ w æ¸å˜è€Œä¸æ˜¯æ•´ä¸ªå†å²ï¼Œ(ç°åœ¨æœ‰é™çš„)å†å²å­˜å‚¨ä¸ºè¡°å‡çš„å¹³å‡å€¼ã€‚
*   RMSProp :æœ‰ç‚¹ç±»ä¼¼(è¯·ä¸è¦å‘æˆ‘å¼€æªï¼Œè¾›é¡¿å…ˆç”Ÿï¼Œå…ˆç”Ÿ)ï¼Œä½†æ˜¯ RMSProp å°† LR é™¤ä»¥æ¢¯åº¦å¹³æ–¹çš„æŒ‡æ•°è¡°å‡å¹³å‡å€¼ã€‚
*   **Adam** :é™¤äº†å­˜å‚¨å†å²æ¢¯åº¦å¹³æ–¹å’Œï¼Œå®ƒè¿˜è®¡ç®—è¿‡å»æ¢¯åº¦çš„æŒ‡æ•°è¡°å‡å¹³å‡å€¼(ç±»ä¼¼äºåŠ¨é‡)ã€‚
*   **Adamax** :è¿™é‡Œï¼Œå¦ä¸€ä¸ªæŠ€å·§åº”ç”¨äºå¹³æ–¹æ¢¯åº¦ v(t)çš„ç§»åŠ¨å¹³å‡å€¼ï¼Œä½œè€…åº”ç”¨æ— ç©·èŒƒæ•°â„“âˆæ¥è·å¾—æ–°çš„èŒƒæ•°çº¦æŸå‘é‡ v(t)ï¼Œå°†å…¶æ’å…¥ Adamï¼Œä»è€Œè·å¾—ä»¤äººæƒŠè®¶çš„ç¨³å®šç®—æ³•ã€‚

![](img/198ed6b5d85b582d286e388413f3357a.png)

ğŸ‘‰æç¤º:å¦‚æœä½ æ­£åœ¨å¯»æ‰¾ä¼˜åŒ–è€…çš„æ›´æ·±å…¥çš„æ•°å­¦æ¯”è¾ƒï¼Œçœ‹çœ‹ Sebastian Ruder çš„[è¿™ç¯‡ç²¾å½©çš„åšå®¢æ–‡ç« ](http://ruder.io/optimizing-gradient-descent/index.html#momentum)ï¼Œå®ƒå¯¹æˆ‘å†™è¿™ç¯‡æ–‡ç« æœ‰å¾ˆå¤§å¸®åŠ©ã€‚

# å¾ªç¯å­¦ä¹ ç‡

CLR çš„è®ºæ–‡æå‡ºäº†ä¸¤ä¸ªéå¸¸æœ‰è¶£çš„è§‚ç‚¹:

1.  å®ƒä¸ºæˆ‘ä»¬æä¾›äº†ä¸€ç§åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­æœ‰æ•ˆå®‰æ’å­¦ä¹ é€Ÿç‡çš„æ–¹æ³•ï¼Œå³ä»¥ä¸‰è§’å½¢çš„æ–¹å¼åœ¨ä¸Šé™å’Œä¸‹é™ä¹‹é—´å˜åŒ–ã€‚
2.  è¿™ç»™äº†æˆ‘ä»¬ä¸€ä¸ªéå¸¸åˆç†çš„ä¼°è®¡ï¼Œå“ªä¸ªå­¦ä¹ ç‡èŒƒå›´æœ€é€‚åˆä½ çš„ç‰¹å®šç½‘ç»œã€‚

![](img/8f17c863b43f7327283840f2f7055c3f.png)

è¿™é‡Œæœ‰è®¸å¤šå‚æ•°å¯ä¾›é€‰æ‹©:

*   **æ­¥é•¿**:LR ä»ä¸‹é™ä¸Šå‡åˆ°ä¸Šé™éœ€è¦å¤šå°‘ä¸ªå†å…ƒã€‚
*   **max_lr** :è°ƒåº¦ä¸­æœ€é«˜çš„ lrã€‚
*   **base_lr** :è¿›åº¦è¡¨ä¸­æœ€ä½çš„ lrï¼Œå®é™…ä¸Š:æœ¬æ–‡ä½œè€…å»ºè®®å°†æ­¤å–æ¯” **max_lr** å°ä¸€ä¸ªå› å­ Rã€‚æˆ‘ä»¬çš„åˆ©ç”¨ç³»æ•°æ˜¯ 6ã€‚

å½“ç„¶ï¼Œå¾ˆéš¾åˆ†æå‡ºè¿™ç§æ–¹æ³•è¡Œå¾—é€šçš„ç¡®åˆ‡åŸå› ã€‚LR çš„å‘å±•å¯èƒ½ä¼šå¯¼è‡´ç½‘ç»œåœ¨çŸ­æœŸå†…å‡ºç°æ›´é«˜çš„æŸè€—ï¼Œä½†è¿™ç§çŸ­æœŸçš„ç¼ºç‚¹åœ¨é•¿æœŸå†…è¯æ˜æ˜¯æœ‰åˆ©çš„ã€‚å¦‚æœå½“å‰çš„ç½‘ç»œä¸å¤ªç¨³å®šï¼Œå®ƒå¯ä»¥è®©ç½‘ç»œè·³åˆ°å¦ä¸€ä¸ªå±€éƒ¨æœ€å°å€¼ã€‚

![](img/1c6e344306475c62bce59012adcbb349.png)

Source: Snapsshot Ensembles ([https://arxiv.org/abs/1704.00109](https://arxiv.org/abs/1704.00109))

CLR ä¼˜äºä¸Šè¿°è‡ªé€‚åº”æ–¹æ³•çš„å¦ä¸€ä¸ªä¼˜ç‚¹æ˜¯è®¡ç®—é‡è¾ƒå°ã€‚

åœ¨è®ºæ–‡ä¸­ï¼Œè¿˜æåˆ°ä½ å¯ä»¥éšç€æ—¶é—´çº¿æ€§æˆ–æŒ‡æ•°é€’å‡ä¸Šç•Œï¼Œä½†è¿™åœ¨è¿™ç¯‡åšæ–‡ä¸­æ²¡æœ‰å®ç°ã€‚

é‚£ä¹ˆè¿™åœ¨ä»£ç ä¸­æ˜¯å¦‚ä½•å·¥ä½œçš„å‘¢ï¼Ÿâ€¦

## ç¬¬ä¸€æ­¥:æ‰¾åˆ°ä¸Šé¢çš„ LR

ä»¥ä¸€ä¸ªæ™®é€šçš„ CNN ä¸ºä¾‹:ç¬¬ä¸€æ­¥æ˜¯ä¸ºä½ çš„æ¨¡å‹è®¡ç®—å­¦ä¹ ç‡çš„ä¸Šé™ã€‚åšåˆ°è¿™ä¸€ç‚¹çš„æ–¹æ³•æ˜¯:

*   å®šä¹‰ä¸€ä¸ªåˆå§‹å­¦ä¹ ç‡ï¼Œå³æ‚¨æƒ³è¦æµ‹è¯•çš„èŒƒå›´çš„ä¸‹é™(å‡è®¾ä¸º 1e-7)
*   å®šä¹‰èŒƒå›´çš„ä¸Šé™(å‡è®¾ä¸º 0.1)
*   å®šä¹‰ä¸€ä¸ªæŒ‡æ•°æ–¹æ¡ˆæ¥é€æ­¥å®Œæˆè¿™ä¸ªè¿‡ç¨‹:

![](img/8355eb4f46ef7e12ea13c9fc11b610b5.png)

Used formula for the LR finder scheduling (N = number of images, BS = Batch Size, lr = learning rate)

å¹¸è¿çš„æ˜¯ï¼ŒPyTorch æœ‰ä¸€ä¸ª LambdaLR å¯¹è±¡ï¼Œå®ƒå…è®¸æˆ‘ä»¬åœ¨ lambda å‡½æ•°ä¸­å®šä¹‰ä¸Šè¿°å†…å®¹:

*   æ¥ä¸‹æ¥ï¼Œåœ¨ä½ çš„ç½‘ç»œä¸­è¿è¡Œ(æˆ‘ç”¨äº†ä¸¤ä¸ªçºªå…ƒ)ã€‚åœ¨æ¯ä¸ªæ­¥éª¤(æ¯ä¸ªæ‰¹é‡):è·å– LRã€è·å–æŸå¤±å¹¶ä¼˜åŒ–æ¢¯åº¦:

ğŸ‘‰æ³¨æ„:æˆ‘ä»¬ä¸æ˜¯åœ¨æ¯ä¸€æ­¥å–â€œåŸå§‹â€æŸå¤±ï¼Œè€Œæ˜¯å¹³æ»‘æŸå¤±ï¼Œå³:æŸå¤±= Î±ã€‚æŸè€—+ (1- Î±)ã€‚ä»¥å‰çš„æŸå¤±

åœ¨æ­¤ä¹‹åï¼Œæˆ‘ä»¬å¯ä»¥æ¸…æ¥šåœ°çœ‹åˆ° LR éµå¾ªä¸€ä¸ªå¾ˆå¥½çš„æŒ‡æ•°è§„å¾‹:

åŸºæœ¬ç½‘ç»œçš„æŸè€—-lr æ›²çº¿(è§ä¸‹æ–‡)å¦‚ä¸‹æ‰€ç¤º:

æˆ‘ä»¬å¯ä»¥æ¸…æ¥šåœ°çœ‹åˆ°ï¼Œè¿‡é«˜çš„ LR ä¼šå¯¼è‡´ç½‘ç»œæŸè€—å‘æ•£ï¼Œè¿‡ä½çš„ LR æ ¹æœ¬ä¸ä¼šå¯¼è‡´ç½‘ç»œå­¦ä¹ å¤ªå¤šâ€¦

åœ¨ä»–çš„ fast.ai è¯¾ç¨‹ä¸­ï¼Œæ°ç‘ç±³Â·éœåå¾·æåˆ°ä¸€ä¸ªå¥½çš„ä¸Šé™å¹¶ä¸åœ¨æœ€ä½ç‚¹ï¼Œè€Œæ˜¯å‘å·¦ 10 å€ã€‚

è€ƒè™‘åˆ°è¿™ä¸€ç‚¹ï¼Œæˆ‘ä»¬å¯ä»¥è¯´å­¦ä¹ ç‡çš„ä¸€ä¸ªå¥½çš„ä¸Šé™æ˜¯:3e-3ã€‚

æ ¹æ®è¿™ç¯‡è®ºæ–‡å’Œå…¶ä»–èµ„æ–™ï¼Œä¸€ä¸ªå¥½çš„ä¸‹é™æ˜¯ä¸Šé™é™¤ä»¥å› å­ 6ã€‚

## æ­¥éª¤ 2: CLR è°ƒåº¦ç¨‹åº

ç¬¬äºŒæ­¥æ˜¯åˆ›å»ºä¸€ä¸ªå¾ªç¯å­¦ä¹ æ—¶é—´è¡¨ï¼Œå®ƒåœ¨ä¸‹é™å’Œä¸Šé™ä¹‹é—´æ”¹å˜å­¦ä¹ é€Ÿç‡ã€‚

è¿™å¯ä»¥é€šè¿‡å¤šç§æ–¹å¼å®ç°:

![](img/8059cb660309d64be15e85980e2129ce.png)

Various possibilites for the CLR shape (source: [jeremy jordanâ€™s blog](https://www.jeremyjordan.me/nn-learning-rate/))

æˆ‘ä»¬è¦ç”¨ç®€å•çš„ä¸‰è§’ CLR æ—¶é—´è¡¨ã€‚

ä»¥ç¼–ç¨‹æ–¹å¼ï¼Œæˆ‘ä»¬åªéœ€è¦åˆ›å»ºä¸€ä¸ªè‡ªå®šä¹‰å‡½æ•°:

## ç¬¬ä¸‰æ­¥:åŒ…è£…

åœ¨æ­¥éª¤ 3 ä¸­ï¼Œè¿™å¯ä»¥è¢«åŒ…è£…åœ¨ PyTorch ä¸­çš„ LambdaLR å¯¹è±¡ä¸­:

## è®­ç»ƒ

åœ¨ä¸€ä¸ªæ—¶æœŸå†…ï¼Œæˆ‘ä»¬éœ€è¦ä½¿ç”¨'æ›´æ–° LRã€‚scheduler å¯¹è±¡çš„â€œstep()â€æ–¹æ³•:

# å¯¹æ¯” 1:é¦™è‰ CNN

é¦–å…ˆæ˜¯ä½¿ç”¨æ™®é€šçš„(éé¢„è®­ç»ƒçš„)CNN è¿›è¡Œåˆ†ç±»ã€‚æˆ‘ä½¿ç”¨äº†ä»¥ä¸‹ç½‘ç»œæ¶æ„:

ä¸ºäº†é˜²æ­¢æ¨¡å‹è¿‡åº¦é€‚åº”(ç›¸å¯¹è¾ƒå°çš„)æ•°æ®é›†ï¼Œæˆ‘ä»¬ä½¿ç”¨ä»¥ä¸‹æŠ€æœ¯:

*   çº¿æ€§å›¾å±‚ä¸­çš„ä¸¢å¤±
*   CNN å—ä¸­çš„ Batchnorm å±‚
*   æ•°æ®æ‰©å……:

ğŸ‘‰æç¤º:ä½ éœ€è¦æå‰è®¡ç®—é€šé“æ ‡å‡†åŒ–çš„å‡å€¼å’Œæ ‡å‡†å·®ï¼ŒæŸ¥çœ‹å®Œæ•´çš„ç¬”è®°æœ¬ï¼Œçœ‹çœ‹å¦‚ä½•è§£å†³è¿™ä¸ªé—®é¢˜ã€‚

æˆ‘ä»¬ä¸º 6 ä¸ªä¼˜åŒ–å™¨ä¸­çš„æ¯ä¸€ä¸ªè®­ç»ƒäº† 150 ä¸ªæ—¶æœŸçš„ç½‘ç»œã€‚ä¸ºäº†æ¶ˆé™¤ä¸€äº›å¯å˜æ€§ï¼Œæˆ‘ä»¬ä¸ºæ¯ä¸ªä¼˜åŒ–å™¨è¿è¡Œäº† 3 æ¬¡ã€‚

è®­ç»ƒå’ŒéªŒè¯å‡†ç¡®æ€§çœ‹èµ·æ¥åƒè¿™æ ·:

Training accuracy

Validation accuracy

å¥½äº†ï¼Œå­©å­ä»¬ï¼Œæˆ‘ä»¬åœ¨è¿™é‡Œèƒ½çœ‹åˆ°ä»€ä¹ˆ:

ğŸ‘‰é˜¿è¾¾æ ¼æ‹‰å¾·:å¹³åº¸çš„è¡¨ç°ï¼Œæ­£å¦‚æ‰€æ–™

ğŸ‘‰é˜¿è¾¾å¾·å°”å¡”:åœ¨ acc è®­ç»ƒä¸­ä¸æ˜¯çœŸæ­£çš„å† å†›ï¼Œä½†åœ¨éªŒè¯ä¸­è¡¨ç°éå¸¸å‡ºè‰²

ğŸ‘‰RMSProp:é™¤éæˆ‘åœ¨è¿™é‡Œåšé”™äº†ä»€ä¹ˆï¼Œå¦åˆ™æˆ‘å¯¹ç³Ÿç³•çš„è¡¨ç°æ„Ÿåˆ°æœ‰ç‚¹æƒŠè®¶

ğŸ‘‰äºšå½“:ä¸€ç›´å¾ˆå¥½

ğŸ‘‰Adamax:æœ‰å¸Œæœ›çš„è®­ç»ƒç²¾åº¦å‘å±•ï¼Œä½†æ²¡æœ‰å®Œç¾åœ°åæ˜ åœ¨éªŒè¯ç²¾åº¦ä¸Š

ğŸ‘‰å¸¦ CLR çš„ SGD:è®­ç»ƒç²¾åº¦æ”¶æ•›å¿«å¾—å¤šï¼ŒéªŒè¯ç²¾åº¦æ”¶æ•›å¿«ï¼Œä¸ç®—å¤ªå·®â€¦

æœ€ç»ˆï¼ŒSGD+CLRã€Adam å’Œ Adadelta ä¼¼ä¹éƒ½ä»¥å¤§çº¦ 83%çš„æœ€ç»ˆéªŒè¯å‡†ç¡®ç‡ç»“æŸã€‚

# å¯¹æ¯”äºŒ:Resnet34 è¿ç§»å­¦ä¹ 

å¦‚æœä½ è¯´:â€œå°æ•°æ®é›†ä¸Šçš„å›¾åƒåˆ†ç±»â€ï¼Œä½ éœ€è¦è€ƒè™‘è¿ç§»å­¦ä¹ ã€‚

æ‰€ä»¥æˆ‘ä»¬å°±è¿™ä¹ˆåšäº†ï¼Œä½¿ç”¨ Resnet34ï¼Œåœ¨ ImageNet ä¸Šè¿›è¡Œé¢„è®­ç»ƒã€‚æˆ‘ç›¸ä¿¡æ•°æ®é›†ç›¸å½“æ¥è¿‘ Imagenet å›¾ç‰‡ï¼Œæ‰€ä»¥æˆ‘åªè§£å†»äº† 5 ä¸ªå·ç§¯å—çš„æœ€åä¸€ä¸ªå—ï¼Œå¹¶ç”¨æ–°çš„çº¿æ€§å±‚æ›¿æ¢äº†æœ€åä¸€ä¸ªçº¿æ€§å±‚:

å¯¹äº 6 ä¸ªä¼˜åŒ–å™¨ä¸­çš„æ¯ä¸€ä¸ªï¼Œç½‘ç»œè¢«è®­ç»ƒ 100 ä¸ªæ—¶æœŸ(ç”±äºæ›´å¿«çš„æ”¶æ•›):

Training accuracy

Validation accuracy

æ­¤å¤„æœ‰é‡è¦æç¤º:

ğŸ‘‰æ€»çš„æ¥è¯´:ä¼˜åŒ–å™¨ä¹‹é—´çš„å·®å¼‚è¦å°å¾—å¤šï¼Œå°¤å…¶æ˜¯åœ¨è§‚å¯ŸéªŒè¯å‡†ç¡®æ€§æ—¶

ğŸ‘‰RMSProp:ä»ç„¶æœ‰ç‚¹è¡¨ç°ä¸ä½³

ğŸ‘‰SGD+CLR åœ¨è®­ç»ƒå‡†ç¡®æ€§æ–¹é¢å†æ¬¡è¡¨ç°è‰¯å¥½ï¼Œä½†è¿™å¹¶æ²¡æœ‰ç«‹å³åæ˜ åœ¨éªŒè¯å‡†ç¡®æ€§ä¸Šã€‚

å¯¹äºè¿ç§»å­¦ä¹ æ¥è¯´ï¼Œè°ƒæ•´å­¦ä¹ é€Ÿåº¦å’Œä»”ç»†é€‰æ‹©ä¼˜åŒ–å™¨çš„ç»å¯¹å›æŠ¥ä¼¼ä¹ä¸å¤ªå¤§ã€‚

è¿™å¯èƒ½æ˜¯ç”±äºä¸¤ä¸ªä¸»è¦å½±å“:

*   ç½‘ç»œæƒé‡å·²ç»å¤§å¤§ä¼˜åŒ–
*   ä¼˜åŒ–å™¨é€šå¸¸åªèƒ½ä¼˜åŒ–æ•´ä¸ªç½‘ç»œæƒé‡çš„ä¸€å°éƒ¨åˆ†ï¼Œå› ä¸ºå¤§éƒ¨åˆ†æƒé‡ä¿æŒå†»ç»“

# ç»“è®º

è¿™ç¯‡åšæ–‡çš„ä¸»è¦è§‚ç‚¹æ˜¯:

> ä¸è¦åªæ˜¯é‡‡ç”¨ä»»ä½•æ—§çš„ç°æˆçš„ä¼˜åŒ–ç¨‹åºã€‚å­¦ä¹ ç‡æ˜¯æœ€é‡è¦çš„è¶…å‚æ•°ä¹‹ä¸€ï¼Œå› æ­¤ä»”ç»†ç ”ç©¶å®ƒæ˜¯å€¼å¾—çš„ã€‚å¦‚æœä½ æƒ³æ¯”è¾ƒï¼Œçœ‹çœ‹ SGD çš„ CLR æ—¶é—´è¡¨ã€‚

å†æ¬¡å£°æ˜:æ‰€æœ‰ä»£ç éƒ½å¯ä»¥åœ¨è¿™é‡Œæ‰¾åˆ°[ï¼Œå¯ä»¥éšæ„æŸ¥çœ‹ï¼](https://github.com/TDehaene/blogposts/tree/master/learning_rates)

èµ„æ–™æ¥æºå’Œè¿›ä¸€æ­¥é˜…è¯»

*   https://arxiv.org/abs/1506.01186
*   [https://www . data camp . com/community/tutorials/cyclic-learning-neural-nets](https://www.datacamp.com/community/tutorials/cyclical-learning-neural-nets)
*   [https://medium . com/@ Li Peng 2/cyclic-learning-rates-for-training-neural-networks-4de 755927 d46](https://medium.com/@lipeng2/cyclical-learning-rates-for-training-neural-networks-4de755927d46)
*   [http://ruder . io/optimizing-gradient-descent/index . html # momentum](http://ruder.io/optimizing-gradient-descent/index.html#momentum)
*   [http://teleported.in/posts/cyclic-learning-rate/](http://teleported.in/posts/cyclic-learning-rate/)