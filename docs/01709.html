<html>
<head>
<title>Sync AWS RDS Postgres to Redshift using AWS DMS</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用 AWS DMS 将 AWS RDS Postgres 同步到红移</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/synching-your-rds-postgresql-database-and-your-redshift-warehouse-using-dms-or-really-any-ea8907aa53ca?source=collection_archive---------9-----------------------#2019-03-20">https://towardsdatascience.com/synching-your-rds-postgresql-database-and-your-redshift-warehouse-using-dms-or-really-any-ea8907aa53ca?source=collection_archive---------9-----------------------#2019-03-20</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="747e" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">实时仓库更新指南</h2></div><p id="efee" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">免责声明:这篇文章假设你对编程有所了解。</p><figure class="lf lg lh li gt lj gh gi paragraph-image"><div role="button" tabindex="0" class="lk ll di lm bf ln"><div class="gh gi le"><img src="../Images/b0ac57b19c16c312dc7faba9c9537ce9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*evn5GWAcqRfMRT-J"/></div></div><figcaption class="lq lr gj gh gi ls lt bd b be z dk">Photo by <a class="ae lu" href="https://unsplash.com/@hishahadat?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Shahadat Rahman</a> on <a class="ae lu" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><h1 id="fe58" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">问题是</h1><p id="b0c2" class="pw-post-body-paragraph ki kj it kk b kl mn ju kn ko mo jx kq kr mp kt ku kv mq kx ky kz mr lb lc ld im bi translated">当我们第一次开始了解 AWS 红移时，我们爱上了<a class="ae lu" href="https://aws.amazon.com/es/blogs/big-data/performance-matters-amazon-redshift-is-now-up-to-3-5x-faster-for-real-world-workloads/" rel="noopener ugc nofollow" target="_blank">快速聚合查询处理</a>。这种强大的优势意味着<strong class="kk iu">在执行统计研究或简单的数据提取时，我们的生产力和速度</strong>突飞猛进。所以，当然，我们把它变成了我们管理的所有数据源(Adwords、Salesforce、FBAds、Zendesk 等)的主数据仓库。)—所有这些，使用<a class="ae lu" href="https://www.stitchdata.com" rel="noopener ugc nofollow" target="_blank">缝合</a>作为我们主要的 ETL 工具。</p><figure class="lf lg lh li gt lj gh gi paragraph-image"><div class="gh gi ms"><img src="../Images/83ae6e3a2e3db0e5c49cb4a3563a1bd9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1106/format:webp/0*DCgft3hucN9kbhUW.png"/></div><figcaption class="lq lr gj gh gi ls lt bd b be z dk">RDS Postgres instance vs Redshift on the company’s everyday aggregated query performance time.</figcaption></figure><p id="b4dc" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">Stitch 有一个不错的 100 美元的<a class="ae lu" href="https://www.stitchdata.com/pricing/" rel="noopener ugc nofollow" target="_blank">订阅计划</a>，为 500 万行提供处理能力，每增加 100 万行收费 20 美元。缝合日志和账单发票告诉我们，在一个非常繁忙的月份，使用上面提到的所有数据源，我们勉强达到了 180 美元。这些月份中的大部分只是普通的 100 美元(没有使用额外的百万行)。</p><p id="d7f6" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我们公司开发、维护和销售其核心 SaaS 产品<a class="ae lu" href="https://increasecard.com/" rel="noopener ugc nofollow" target="_blank">增卡</a>。我们的生产数据库托管在 AWS 云中，驻留在 AWS RDS 中，<strong class="kk iu">每月存储 1000 万到 2000 万行新数据</strong>，并且还在大幅增长。<br/>因此，通常情况下，对于一家第三世界的初创公司来说，使用 Stitch 将我们的生产数据库同步到红移仓库会被证明是<strong class="kk iu">极其昂贵的</strong>。另外考虑到我们国家的货币<a class="ae lu" href="https://en.wikipedia.org/wiki/Historical_exchange_rates_of_Argentine_currency" rel="noopener ugc nofollow" target="_blank">最近对美元贬值了很多。</a></p><figure class="lf lg lh li gt lj gh gi paragraph-image"><div role="button" tabindex="0" class="lk ll di lm bf ln"><div class="gh gi mt"><img src="../Images/ea4b23dcc616c889739a375009b1678e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*g8oP_cHFKLIe_vk2"/></div></div><figcaption class="lq lr gj gh gi ls lt bd b be z dk">Argentina’s Congress — Photo by <a class="ae lu" href="https://unsplash.com/@sandercrombach?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Sander Crombach</a> on <a class="ae lu" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><p id="9e04" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我们还有另一个限制。该公司正在开发其第二个主要产品<a class="ae lu" href="https://increasecard.com/conciliacion/" rel="noopener ugc nofollow" target="_blank"><em class="mu">increacenconcicion</em></a>。这一个使用 NoSQL <a class="ae lu" href="http://cassandra.apache.org/" rel="noopener ugc nofollow" target="_blank"> Apache Cassandra 数据库</a>来存储和处理其庞大的数据。问题是，两个产品必须同步，以便<em class="mu">会议</em>使用<em class="mu">卡</em>提取的交易。换句话说，我们必须<strong class="kk iu">建立一个可供任何服务消费的数据湖，以按需执行同步操作。</strong></p><p id="9e42" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">很多事情要考虑，对吧？</p><h1 id="4358" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">测试解决方案</h1><p id="aea4" class="pw-post-body-paragraph ki kj it kk b kl mn ju kn ko mo jx kq kr mp kt ku kv mq kx ky kz mr lb lc ld im bi translated">作为一个 2 人的小团队，强大的“数据团队”，我们很容易尝试和测试新事物，尤其是<strong class="kk iu">架构</strong>。</p><p id="51c5" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我们从使用 AWS 数据管道开始，这是一种基于 UI 的服务，用于在一堆数据源之间构建 ETL。尽管构建 ETL 的<strong class="kk iu">过程相当简单</strong>，但是为了使它有效，我们必须采取一系列的变通方法——记住我们必须更新每一个变化，不管是插入、删除还是更新。由于这里不能使用代码，很快就变成了<strong class="kk iu">不可维护</strong>。此外，对于这项服务，IMO 没有太多详细的文档或清晰的示例。</p><p id="7335" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我们尝试设置一个 Lambda，每 15 分钟消耗一次 Postgres 数据库的复制槽的日志，并将其发送到 Kinesis Firehose 数据流。在一个生产过程更新了比通常预期更多的行之前，它看起来似乎是安全可靠的。我们发现，在这些情况下，记录来自逻辑解码的方式是充满所涉及的表的大块更改的巨大行，导致<strong class="kk iu">函数每次试图加载它时都会因内存不足而死亡</strong>。我们通过将<code class="fe mv mw mx my b">true</code>设置为逻辑解码插件的属性<code class="fe mv mw mx my b">write_in_chunks</code>来解决这个问题，我们使用(<a class="ae lu" href="https://github.com/eulerto/wal2json" rel="noopener ugc nofollow" target="_blank"><em class="mu">wa</em>l<em class="mu">2json</em></a><em class="mu">)</em>，使我们能够对传入的 json 日志进行分区。长话短说，由于没有足够的时间来处理巨额交易，该功能仍可能<strong class="kk iu">终止不成功。不好的消息。</strong></p><h1 id="05f1" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">你来这里做什么</h1><p id="c071" class="pw-post-body-paragraph ki kj it kk b kl mn ju kn ko mo jx kq kr mp kt ku kv mq kx ky kz mr lb lc ld im bi translated">好吧，让我们开始吧。</p><figure class="lf lg lh li gt lj gh gi paragraph-image"><div role="button" tabindex="0" class="lk ll di lm bf ln"><div class="gh gi mz"><img src="../Images/232612dcb5a41068866691d1770ead72.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*WnyGtsDGRzN21mvRUpg42Q.png"/></div></div><figcaption class="lq lr gj gh gi ls lt bd b be z dk">Architecture diagram — Made with <a class="ae lu" href="http://lucidchart.com/" rel="noopener ugc nofollow" target="_blank">Lucidchart</a></figcaption></figure><p id="aba1" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我们当前的架构包括以下内容:</p><ul class=""><li id="03dc" class="na nb it kk b kl km ko kp kr nc kv nd kz ne ld nf ng nh ni bi translated">DMS(数据库迁移服务)实例复制对红移和 S3 的持续更改。</li><li id="1218" class="na nb it kk b kl nj ko nk kr nl kv nm kz nn ld nf ng nh ni bi translated">红移源端点。</li><li id="9b5d" class="na nb it kk b kl nj ko nk kr nl kv nm kz nn ld nf ng nh ni bi translated">DMS 使用 S3 桶作为<em class="mu">目标端点</em>。</li><li id="a710" class="na nb it kk b kl nj ko nk kr nl kv nm kz nn ld nf ng nh ni bi translated">每次在上述 S3 桶中创建对象时触发的 Lambda。</li><li id="c5f9" class="na nb it kk b kl nj ko nk kr nl kv nm kz nn ld nf ng nh ni bi translated">(可选)订阅同一对象创建事件的 SNS 主题。这使您能够订阅该主题的任何内容，例如，多个 lambdas。更多信息，请点击此<a class="ae lu" href="https://docs.aws.amazon.com/AmazonS3/latest/dev/ways-to-add-notification-config-to-bucket.html?shortFooter=true" rel="noopener ugc nofollow" target="_blank">链接</a>。</li></ul><p id="475d" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">为了让这篇文章更“民主”，我会把它分成两部分。第一个是将变化直接复制到红移的步骤。第二，建立 S3 数据湖供其他服务使用。你可以随意阅读其中一个，或者更好的是，两个都读😄。</p><h2 id="0aa0" class="no lw it bd lx np nq dn mb nr ns dp mf kr nt nu mh kv nv nw mj kz nx ny ml nz bi translated">首先，启用逻辑解码</h2><p id="a449" class="pw-post-body-paragraph ki kj it kk b kl mn ju kn ko mo jx kq kr mp kt ku kv mq kx ky kz mr lb lc ld im bi translated">由于我不认为自己比编写 AWS 文档的人聪明，我将复制粘贴他们的一些说明如下🤷‍♂.</p><p id="315b" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">找到您的 RDS 实例，查找该实例应用的参数组。使用以下命令直接复制或修改参数组。</p><blockquote class="oa ob oc"><p id="c4e0" class="ki kj mu kk b kl km ju kn ko kp jx kq od ks kt ku oe kw kx ky of la lb lc ld im bi translated">1.-将<code class="fe mv mw mx my b"><em class="it">rds.logical_replication</em></code>静态参数设置为 1。作为应用该参数的一部分，我们还设置了参数<code class="fe mv mw mx my b"><em class="it">wal_level</em></code>、<code class="fe mv mw mx my b"><em class="it">max_wal_senders</em></code>、<code class="fe mv mw mx my b"><em class="it">max_replication_slots</em></code>和<code class="fe mv mw mx my b"><em class="it">max_connections</em></code>。这些参数更改会增加 WAL 生成，因此您应该只在使用逻辑插槽时设置<code class="fe mv mw mx my b"><em class="it">rds.logical_replication</em></code>参数。</p><p id="2aea" class="ki kj mu kk b kl km ju kn ko kp jx kq od ks kt ku oe kw kx ky of la lb lc ld im bi translated">2.-重新启动 DB 实例以使静态<code class="fe mv mw mx my b"><em class="it">rds.logical_replication</em></code>参数生效。</p></blockquote><p id="1bc9" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">重启后，我们应该准备好了。测试一切是否正常的一个好方法是在数据库控制台上运行下面一行。</p><pre class="lf lg lh li gt og my oh oi aw oj bi"><span id="ca6c" class="no lw it my b gy ok ol l om on">increasecard=&gt; show wal_level;<br/> wal_level<br/>-----------<br/> logical<br/>(1 row)</span></pre><h1 id="32fb" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">将变化直接复制到红移</h1><p id="96f6" class="pw-post-body-paragraph ki kj it kk b kl mn ju kn ko mo jx kq kr mp kt ku kv mq kx ky kz mr lb lc ld im bi translated">首先，我们必须创建任务将要使用的资源。创建端点(源和目标)和复制实例(基本上是负责所有脏工作的 EC2 实例)。</p><p id="9310" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">创建复制实例的过程非常简单，所以我不赘述，只需确保使用能够访问您打算使用的源和目标的 VPC。</p><p id="80f0" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">对于源端点，勾选类似“<em class="mu">选择一个 RDS 实例”</em>的选项，并有效地选择您的源数据库并填充凭证字段。</p><p id="4b2c" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">对于目标端点，选择<em class="mu">红移</em>并在所有文本框中填入主机、端口和凭证。</p><p id="2bac" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">太好了，现在我们已经有了我们需要的一切，让我们创建一个任务来迁移和复制<em class="mu">的东西</em>。</p><p id="2b2f" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在 DMS 中，按下 C<em class="mu">create Task</em>按钮，给它起一个有趣的名字，并开始选择我们之前创建的所有资源。对于<em class="mu">迁移类型</em>选择<em class="mu">迁移现有数据并复制正在进行的更改</em>，这将首先执行完全迁移，然后开始复制目标数据库上正在进行的<em class="mu"> CRUD </em>操作。</p><p id="e40e" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在选择部分，选择您想要使用的任何模式/表，在我的例子中，我将只复制一个模式中的每个更改——此外，检查表是否有主键，如果它们没有主键，DMS 可能会出错。使用<em class="mu"> % </em>字符作为通配符(即<em class="mu">“所有包含单词‘foo’的表格都将是</em> <code class="fe mv mw mx my b"><em class="mu">table = %foo%</em></code>)。</p><p id="389d" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">该任务还可以有<em class="mu">转换</em>规则，它使您能够，例如，在目标目的地上更改模式或表名。</p><p id="ddaa" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">准备好让<em class="mu">给</em>松绑了吗？点击<em class="mu">创建任务</em>按钮并等待它开始——或者如果您选择在创建时不<em class="mu">开始，则启动它。现在的任务是将表完全加载到目的地，然后开始复制更改。当完成迁移时，您应该看到<em class="mu">加载完成，复制正在进行</em>作为其状态。</em></p><p id="1710" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><em class="mu">aaaaaaand…</em></p><figure class="lf lg lh li gt lj gh gi paragraph-image"><div role="button" tabindex="0" class="lk ll di lm bf ln"><div class="gh gi oo"><img src="../Images/e04c4f7b507b4a3057ffc0268866ef76.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*5yGRdNNJ4n4aK7Uxcv2mzw.jpeg"/></div></div><figcaption class="lq lr gj gh gi ls lt bd b be z dk">Image by <a class="ae lu" href="https://pixabay.com/es/users/pasja1000-6355831/?utm_source=link-attribution&amp;utm_medium=referral&amp;utm_campaign=image&amp;utm_content=4369865" rel="noopener ugc nofollow" target="_blank">pasja1000</a> on <a class="ae lu" href="https://pixabay.com/es/?utm_source=link-attribution&amp;utm_medium=referral&amp;utm_campaign=image&amp;utm_content=4369865" rel="noopener ugc nofollow" target="_blank">Pixabay</a></figcaption></figure><p id="a8cf" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><em class="mu">瞧，</em>搞定！。你的红移仓库现在被你的生产 RDS 数据丰富了，干得好！。此时，如果出现任何问题，您可以随时启用 DMS 任务的日志记录功能来查看发生了什么😄，只要考虑到 Cloudwatch <a class="ae lu" href="https://aws.amazon.com/cloudwatch/pricing/" rel="noopener ugc nofollow" target="_blank">计费</a>。</p><p id="bff0" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">您还可以查看 DMS 任务提供给我们的一些有用的图表。</p><figure class="lf lg lh li gt lj gh gi paragraph-image"><div role="button" tabindex="0" class="lk ll di lm bf ln"><div class="gh gi op"><img src="../Images/d31ccc482a7258e3b570424f90618f9e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*rKOc9sFVPWurqqK2W7mWVw.png"/></div></div><figcaption class="lq lr gj gh gi ls lt bd b be z dk">Screenshot of dashboard of migrating task metrics — AWS DMS</figcaption></figure><p id="f0cb" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">下一节将讨论为其他服务创建 S3 数据湖，以消耗数据库更改。如果你现在要离开，感谢你的阅读，我希望这篇文章对你有用。</p></div><div class="ab cl oq or hx os" role="separator"><span class="ot bw bk ou ov ow"/><span class="ot bw bk ou ov ow"/><span class="ot bw bk ou ov"/></div><div class="im in io ip iq"><h1 id="28f3" class="lv lw it bd lx ly ox ma mb mc oy me mf jz oz ka mh kc pa kd mj kf pb kg ml mm bi translated">构建你的 S3 数据湖</h1><h2 id="1913" class="no lw it bd lx np nq dn mb nr ns dp mf kr nt nu mh kv nv nw mj kz nx ny ml nz bi translated">创建和测试 DMS 任务以创建我们的 S3 数据湖</h2><p id="884c" class="pw-post-body-paragraph ki kj it kk b kl mn ju kn ko mo jx kq kr mp kt ku kv mq kx ky kz mr lb lc ld im bi translated">和以前一样，创建一个任务，它不是作为目标目的地的<em class="mu">红移</em>，而是一个 S3 桶。</p><p id="fda0" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">对于目标端点，预先创建一个 S3 存储桶，只需输入存储桶的名称和相应的角色就可以访问它。考虑到服务角色应该有以下策略。</p><pre class="lf lg lh li gt og my oh oi aw oj bi"><span id="bfeb" class="no lw it my b gy ok ol l om on">{<br/>    "Version": "2012-10-17",<br/>    "Statement": [<br/>       {<br/>            "Effect": "Allow",<br/>            "Action": [<br/>                "s3:PutObject",<br/>                "s3:DeleteObject"<br/>            ],<br/>            "Resource": [<br/>                "arn:aws:s3:::&lt;name-of-bucket&gt;"<br/>            ]<br/>        },<br/>        {<br/>            "Effect": "Allow",<br/>            "Action": [<br/>                "s3:ListBucket"<br/>            ],<br/>            "Resource": [<br/>                "arn:aws:s3:::&lt;name-of-bucket&gt;"<br/>            ]<br/>        }<br/>    ]<br/>}</span></pre><p id="9ba9" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在<em class="mu">附加参数</em>部分，输入以下<code class="fe mv mw mx my b">addColumnName=true;</code>，包括之前的参数或您可能想要使用的其他参数。</p><p id="5333" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在这种情况下，选择<em class="mu">仅复制数据更改</em>作为迁移类型，我们不想让以前的数据充斥我们的 S3 存储桶。</p><figure class="lf lg lh li gt lj gh gi paragraph-image"><div role="button" tabindex="0" class="lk ll di lm bf ln"><div class="gh gi pc"><img src="../Images/32185c8cc6c0c57c66a37f0b0f498de5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*fcjeT-G5SLKCnQor.png"/></div></div><figcaption class="lq lr gj gh gi ls lt bd b be z dk">Screenshot of AWS DMS task creation</figcaption></figure><p id="ce7b" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">有关使用 S3 作为 DMS 目标的更多信息，请单击此处的<a class="ae lu" href="https://docs.aws.amazon.com/dms/latest/userguide/CHAP_Target.S3.html" rel="noopener ugc nofollow" target="_blank"/>。</p><figure class="lf lg lh li gt lj gh gi paragraph-image"><div role="button" tabindex="0" class="lk ll di lm bf ln"><div class="gh gi oo"><img src="../Images/8fe665c79b52513ffecba7e17bbcbc79.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*kt2gfvD1LFnb-R7W0dvUvQ.jpeg"/></div></div><figcaption class="lq lr gj gh gi ls lt bd b be z dk">Image by <a class="ae lu" href="https://pixabay.com/es/users/maraisea-2989330/?utm_source=link-attribution&amp;utm_medium=referral&amp;utm_campaign=image&amp;utm_content=1648250" rel="noopener ugc nofollow" target="_blank">Etienne Marais</a> on <a class="ae lu" href="https://pixabay.com/es/?utm_source=link-attribution&amp;utm_medium=referral&amp;utm_campaign=image&amp;utm_content=1648250" rel="noopener ugc nofollow" target="_blank">Pixabay</a></figcaption></figure><p id="20e4" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">好了，<strong class="kk iu">真相时刻</strong>，运行你的小<em class="mu">弗兰肯斯坦</em>宝贝。</p><p id="8ece" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">任务的状态应该是<em class="mu">正在复制</em>。否则，检查与复制实例相关的日志，查看 Cloudwatch 服务中的错误。</p><p id="cf03" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">从现在开始，如果您正在使用一个临时数据库实例(我希望您是这样)，那么创建、更新和删除一些行，以便任务能够复制更改。这将有望以您在目的地端点中指定的 S3 存储桶中的<em class="mu"> csv </em>文件结束。</p><p id="de03" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">该文件应该类似于:</p><pre class="lf lg lh li gt og my oh oi aw oj bi"><span id="2a3c" class="no lw it my b gy ok ol l om on">Op, id, field..fields<br/>I, 1, ...<br/>D, 2<br/>U, 3, ...</span></pre><p id="1a2a" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">如果你不是，这里我们称之为<em class="mu"> salame，</em>你会意识到<em class="mu"> I </em>代表插入，<em class="mu"> D </em>代表删除，<em class="mu"> U </em>代表更新。</p><h2 id="8913" class="no lw it bd lx np nq dn mb nr ns dp mf kr nt nu mh kv nv nw mj kz nx ny ml nz bi translated">构建 Lambda 函数</h2><p id="3338" class="pw-post-body-paragraph ki kj it kk b kl mn ju kn ko mo jx kq kr mp kt ku kv mq kx ky kz mr lb lc ld im bi translated">你期待已久的时刻。这是我们编写函数的地方，该函数将解析在我们的 bucket 上创建的<em class="mu"> CSV </em>文档。</p><p id="5270" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">对于这一部分，我建议您使用<a class="ae lu" href="https://serverless.com/" rel="noopener ugc nofollow" target="_blank">无服务器</a>，这是一个很好的工具，可以使用您的 AWS CLI 凭证轻松部署 Lambda 函数。就像写一个<code class="fe mv mw mx my b">.yml</code>文件，点击<code class="fe mv mw mx my b">serverless deploy</code>和<em class="mu">瞧</em>那么简单。</p><p id="d93c" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">现在，让我们创建我们的 Lambda 函数，然后添加 S3 桶事件，以便在每次创建对象时触发该函数。另外，如果你已经指定了文件将被创建在一个特定的文件夹中，你可能想要添加一个前缀，只要把<code class="fe mv mw mx my b">folder/</code>放在前缀文本框中，你就可以开始了。</p><figure class="lf lg lh li gt lj gh gi paragraph-image"><div role="button" tabindex="0" class="lk ll di lm bf ln"><div class="gh gi pd"><img src="../Images/71b5f77c71380eec13f94709c4af9df3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*FaoO8MNOrVglhzriaBwS7g.png"/></div></div><figcaption class="lq lr gj gh gi ls lt bd b be z dk">Screenshot of AWS Lambda</figcaption></figure><p id="46cd" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">让我们编写一部分函数，它将从 bucket 中上传的文件中接收和提取数据。</p><p id="d52e" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">所以，我们首先要做的是构建我们的<em class="mu">处理程序</em>函数，你知道，通常的<code class="fe mv mw mx my b">main()</code>但是<em class="mu">委婉地说</em>。</p><p id="38af" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">这个主函数将接收 Cloudwatch 处理的 JSON 事件作为参数，基本上是说"<em class="mu">哟，桶中创建了一个新文件，这是访问它的键。"</em></p><p id="88c8" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">这是 AWS 给我们的示例事件。</p><figure class="lf lg lh li gt lj"><div class="bz fp l di"><div class="pe pf l"/></div></figure><p id="cee8" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">下面我粘贴了 Python 代码，用来获得在 S3 创建的文件的最终内容。</p><figure class="lf lg lh li gt lj"><div class="bz fp l di"><div class="pe pf l"/></div></figure><p id="c061" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">现在在<code class="fe mv mw mx my b">file_content</code>变量中有了<em class="mu"> CSV </em>的数据。如果你有使用解析器的经验，这应该是小菜一碟，如果你没有，我推荐你查看这个<a class="ae lu" href="https://realpython.com/python-csv/#parsing-csv-files-with-pythons-built-in-csv-library" rel="noopener ugc nofollow" target="_blank">链接</a>。</p><p id="2fb1" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">从现在开始，就看你的了。使用 python 驱动程序来处理<em class="mu"> CRUD </em>操作，处理<em class="mu"> CSV </em>中影响红移变化的每一行。在这种情况下，我建议使用像<code class="fe mv mw mx my b">execute_values()</code> (psycopg2)这样的函数来最小化执行时间，如这里的<a class="ae lu" href="https://billyfung.com/blog/2017/06/psycopg2-multiple-insert/" rel="noopener ugc nofollow" target="_blank">所解释的</a>。使用 Lambda 环境变量来处理函数要使用的凭证机密，记住硬编码它们不是一个好主意。</p><h1 id="e283" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">一般性结论</h1><p id="df41" class="pw-post-body-paragraph ki kj it kk b kl mn ju kn ko mo jx kq kr mp kt ku kv mq kx ky kz mr lb lc ld im bi translated">我呈现给你的，只是实现数据库同步目标的千万种可能中的一种。如果你不介意花几百块💸在为你处理 ETL 过程的服务上，去做吧。不，真的，去吧。</p><p id="4756" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">这个架构给我们带来了两个积极的副作用。首先，拥有关于生产数据库变化的<em class="mu">跟踪信息</em>，这是绝对不必要的。如今有了像<a class="ae lu" href="https://aws.amazon.com/es/athena/" rel="noopener ugc nofollow" target="_blank"> AWS Athena 和 Glue </a>这样的服务，你可以直接通过控制台查询数据。第二个是通过 S3 桶<em class="mu">对象创建</em>事件连接/触发任何过程的能力——在我们的例子中，<em class="mu">increase cilica ción</em>团队复制他们自己的<em class="mu"> Cassandra </em>数据库中的变更。</p></div><div class="ab cl oq or hx os" role="separator"><span class="ot bw bk ou ov ow"/><span class="ot bw bk ou ov ow"/><span class="ot bw bk ou ov"/></div><div class="im in io ip iq"><p id="3ded" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我们已经结束了，希望你喜欢我的第一篇文章😄</p></div></div>    
</body>
</html>