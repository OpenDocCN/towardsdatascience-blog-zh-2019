<html>
<head>
<title>Synthesizing Audio with Generative Adversarial Networks</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">用生成性对抗网络合成音频</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/synthesizing-audio-with-generative-adversarial-networks-8e0308184edd?source=collection_archive---------12-----------------------#2019-08-06">https://towardsdatascience.com/synthesizing-audio-with-generative-adversarial-networks-8e0308184edd?source=collection_archive---------12-----------------------#2019-08-06</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="af1b" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">毕竟，音频和图像并没有太大的不同</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/5dfd68ba41c946e4f620921d5079f440.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*EYygXa45vcnuvndf"/></div></div></figure><h1 id="a398" class="ku kv it bd kw kx ky kz la lb lc ld le jz lf ka lg kc lh kd li kf lj kg lk ll bi translated">介绍</h1><p id="eda1" class="pw-post-body-paragraph lm ln it lo b lp lq ju lr ls lt jx lu lv lw lx ly lz ma mb mc md me mf mg mh im bi translated">在过去的几年里，生成对抗网络(GANs)在计算机视觉领域取得了巨大的成功。由于最近的进步，如 Nvidia 的 StyleGAN 和 Google 的 BigGAN，我们现在能够生成高清晰度的高度逼真的图像；通常生成的或“伪造的”图像与真实的图像完全无法区分，这决定了 GAN 的实际发展程度。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi mi"><img src="../Images/d1bafdb78b6c262a58be3e9f6c3fb2ee.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ap0GITM96OWp_AN5bZVAnQ.png"/></div></div><figcaption class="mj mk gj gh gi ml mm bd b be z dk">Faces generated by StyleGAN</figcaption></figure><p id="78e0" class="pw-post-body-paragraph lm ln it lo b lp mn ju lr ls mo jx lu lv mp lx ly lz mq mb mc md mr mf mg mh im bi translated">但是图像并不是 GANs 能够吃的唯一食物:音频是这种网络的另一个可能的应用，不知何故这个领域仍然是广泛未被探索的。</p><p id="1292" class="pw-post-body-paragraph lm ln it lo b lp mn ju lr ls mo jx lu lv mp lx ly lz mq mb mc md mr mf mg mh im bi translated">在本文中，我们将解释如何将 GANs 应用于音频信号，最后我们将尝试生成一些音频剪辑。</p><h1 id="6728" class="ku kv it bd kw kx ky kz la lb lc ld le jz lf ka lg kc lh kd li kf lj kg lk ll bi translated">音频信号</h1><p id="6b17" class="pw-post-body-paragraph lm ln it lo b lp lq ju lr ls lt jx lu lv lw lx ly lz ma mb mc md me mf mg mh im bi translated">音频和图像有什么区别？嗯，它们比你想象的更相似。</p><p id="e6aa" class="pw-post-body-paragraph lm ln it lo b lp mn ju lr ls mo jx lu lv mp lx ly lz mq mb mc md mr mf mg mh im bi translated">在处理数据科学和机器学习的时候，我们必须把一切都想成数字、向量和张量；您可能已经知道，黑白图像可以被视为一个简单的 2D 矩阵，其中每个数字代表一个像素，并表示该像素在特定位置的“白”程度。然而，对于 RGB 图像，我们必须有 3 个矩阵或通道，每种原色一个。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ms"><img src="../Images/0d707ed13281a1d57e6096231fd313c1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*h1ymqblIpie7VE4DixE4Ow.png"/></div></div><figcaption class="mj mk gj gh gi ml mm bd b be z dk">Color Image as 3 matrices (Tensor)</figcaption></figure><p id="bd1d" class="pw-post-body-paragraph lm ln it lo b lp mn ju lr ls mo jx lu lv mp lx ly lz mq mb mc md mr mf mg mh im bi translated">现在我们来看音频信号。听音乐时，你实际上听到的是不同时间的不同声音:这就是为什么我们可以将音频信号视为时间序列。</p><p id="7e16" class="pw-post-body-paragraph lm ln it lo b lp mn ju lr ls mo jx lu lv mp lx ly lz mq mb mc md mr mf mg mh im bi translated">在每一个时间点上,“声音”可以用一个单一的值来表示；因此，我们可以认为声音(或“振幅”<em class="mt"> a </em>)是时间的简单函数(<em class="mt"> t </em>)，因此<em class="mt"> a=f(t) </em>。函数<em class="mt"> f </em>是连续的(本质上),所以要将信号转换成一组有限的数字，我们需要选择一个采样率。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi mu"><img src="../Images/f0f476a7627845ee078950454bd3a763.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*3u93W3YpvecKL6A5FYRZAQ.png"/></div></div><figcaption class="mj mk gj gh gi ml mm bd b be z dk">Plot of Audio Signal: Amplitude over Time</figcaption></figure><p id="f3ce" class="pw-post-body-paragraph lm ln it lo b lp mn ju lr ls mo jx lu lv mp lx ly lz mq mb mc md mr mf mg mh im bi translated">如果采样率是 16000 Hz，这意味着我们将以 1/16000 秒的间隔记下幅度值，因此 2 秒的音频剪辑将产生 32000 个数字的单个向量(如果音频是立体声，我们将有 2 个长度相同的向量，每个音频通道一个)。</p><p id="176e" class="pw-post-body-paragraph lm ln it lo b lp mn ju lr ls mo jx lu lv mp lx ly lz mq mb mc md mr mf mg mh im bi translated">总之，虽然图像可以被视为矩阵(或张量)，但音频信号可以被视为简单的向量。</p><p id="71e4" class="pw-post-body-paragraph lm ln it lo b lp mn ju lr ls mo jx lu lv mp lx ly lz mq mb mc md mr mf mg mh im bi translated">关于音频信号还有很多有趣的理论，对音频进行编码的方式也很多(例如作为图像)，但这对于我们在本文中将要讨论的内容来说已经足够了。</p><h1 id="be42" class="ku kv it bd kw kx ky kz la lb lc ld le jz lf ka lg kc lh kd li kf lj kg lk ll bi translated">韦弗根</h1><p id="0cff" class="pw-post-body-paragraph lm ln it lo b lp lq ju lr ls lt jx lu lv lw lx ly lz ma mb mc md me mf mg mh im bi translated">2018 年的一篇论文介绍了<a class="ae mv" href="https://arxiv.org/abs/1802.04208" rel="noopener ugc nofollow" target="_blank"> WaveGAN </a>，一种能够合成音频的生成式对抗性网络架构。网络结构与一种名为<a class="ae mv" href="https://arxiv.org/abs/1511.06434" rel="noopener ugc nofollow" target="_blank"> DCGAN </a>的网络结构极其相似，在生成器和鉴别器中都使用了卷积层:如果你熟悉用于生成图像的传统卷积 GAN 架构，WaveGAN 将非常容易理解。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi mw"><img src="../Images/d1284eef70039a614cae449fe1a3eace.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Ha-KDefLwg82rIkvk63frw.png"/></div></div><figcaption class="mj mk gj gh gi ml mm bd b be z dk">DCGAN architecture</figcaption></figure><p id="bdf1" class="pw-post-body-paragraph lm ln it lo b lp mn ju lr ls mo jx lu lv mp lx ly lz mq mb mc md mr mf mg mh im bi translated">假设我们有一个发生器，它必须从一个噪声矢量输出 1 秒的音频(如果采样速率为 16 kHz，这将是一个 16000 长的矢量，不考虑它必须是 4 的幂这一事实，我们将在后面解释)。</p><p id="4199" class="pw-post-body-paragraph lm ln it lo b lp mn ju lr ls mo jx lu lv mp lx ly lz mq mb mc md mr mf mg mh im bi translated">首先，由于我们不再处理 2D 图像，传统卷积层中使用的 2D 滤波器现在已经没有用了。请记住，音频信号可以被视为简单的向量:因此，我们必须将滤波器更改为一维:DCGAN 中的 5×5 2D 滤波器现在变成了 WaveGAN 中的 25 长 1D 滤波器。</p><p id="95c1" class="pw-post-body-paragraph lm ln it lo b lp mn ju lr ls mo jx lu lv mp lx ly lz mq mb mc md mr mf mg mh im bi translated">使用转置卷积将音频从噪声放大到 16000 长的矢量会影响合成的音频，因为它们在图像中会产生棋盘状伪影，在音频信号中也会产生类似的伪影。仅仅基于这种人为因素，鉴别者可以很容易地学会识别假音频，从而恶化整个训练过程。该论文提出了一种称为相位混洗的智能解决方案，但我们将避免转置卷积，而是使用上采样层(最近的邻居)后跟正常卷积。</p><p id="f03d" class="pw-post-body-paragraph lm ln it lo b lp mn ju lr ls mo jx lu lv mp lx ly lz mq mb mc md mr mf mg mh im bi translated">在 DCGAN 中，我们在每一层将“图像”放大 2 倍(例如 32x32 到 64x64)，而在一维中，向量每次放大 4 倍(例如 1024 到 4096)。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi mx"><img src="../Images/4e1b47d8f045e6070645589a8ad1183b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1036/format:webp/1*AhhDA_lleVcJ82wyHp7fqw.jpeg"/></div><figcaption class="mj mk gj gh gi ml mm bd b be z dk">From 2D (DCGAN) to 1D (WaveGAN)</figcaption></figure><p id="479f" class="pw-post-body-paragraph lm ln it lo b lp mn ju lr ls mo jx lu lv mp lx ly lz mq mb mc md mr mf mg mh im bi translated">这一点很重要，因为我们需要记住，对于 1 秒钟的音频，考虑到采样速率为 16 kHz，相应的向量长度为 16000，选择每次以 2 倍的因子进行上采样将需要很多层。</p><p id="427f" class="pw-post-body-paragraph lm ln it lo b lp mn ju lr ls mo jx lu lv mp lx ly lz mq mb mc md mr mf mg mh im bi translated">这也是为什么生成的向量的长度是 4 的幂(如果我们想要以 16 kHz 采样约 1 秒的合成音频，则长度为 16384)。</p><p id="989f" class="pw-post-body-paragraph lm ln it lo b lp mn ju lr ls mo jx lu lv mp lx ly lz mq mb mc md mr mf mg mh im bi translated">因此，一切也适用于鉴别器:在这种情况下，我们将使用步长为 4 的 1D 卷积，这相当于在每一层以因子 4 进行下采样。</p><p id="7d58" class="pw-post-body-paragraph lm ln it lo b lp mn ju lr ls mo jx lu lv mp lx ly lz mq mb mc md mr mf mg mh im bi translated">这绝对是你需要知道的使图像的传统 GAN 与音频信号一起工作的一切:改变滤波器为 1 维，放大和缩小 4 倍。这两个网络的训练方式和损失函数是相同的，所以没有什么新的东西。</p><p id="c4fb" class="pw-post-body-paragraph lm ln it lo b lp mn ju lr ls mo jx lu lv mp lx ly lz mq mb mc md mr mf mg mh im bi translated">很简单，对吧？</p><h1 id="2c22" class="ku kv it bd kw kx ky kz la lb lc ld le jz lf ka lg kc lh kd li kf lj kg lk ll bi translated">成果和障碍</h1><p id="fa5e" class="pw-post-body-paragraph lm ln it lo b lp lq ju lr ls lt jx lu lv lw lx ly lz ma mb mc md me mf mg mh im bi translated">最初的 WaveGAN 论文作者在官方网页<a class="ae mv" href="https://chrisdonahue.com/wavegan_examples/" rel="noopener ugc nofollow" target="_blank">这里</a>展示了他们的成果。他们试图生成各种各样的音频领域，如人类语音、鸟鸣、鼓和音乐，并获得了令人信服的结果。我真的推荐你<a class="ae mv" href="https://chrisdonahue.com/wavegan_examples/" rel="noopener ugc nofollow" target="_blank">亲自去看看</a>。</p><p id="6683" class="pw-post-body-paragraph lm ln it lo b lp mn ju lr ls mo jx lu lv mp lx ly lz mq mb mc md mr mf mg mh im bi translated">最难合成的领域之一当然是人类的语音:虽然我们不知道真实的鸟声应该是什么样的，但我们对如何解读人类的声音以及如何辨别真假有着非常深刻的理解。</p><p id="9acc" class="pw-post-body-paragraph lm ln it lo b lp mn ju lr ls mo jx lu lv mp lx ly lz mq mb mc md mr mf mg mh im bi translated">我们可以说，人类的声音对于音频来说就像人脸对于图像来说一样:对于一台机器来说，学习如何生成这些域同时保持它们与真实域无法区分确实很难。这就是为什么在这种特殊情况下，WaveGAN 的后代对我们的耳朵来说显然是假的:我们必须记住，GAN 对单词、短语组成和语调毫无概念，所有概念都难以学习，在合成样本中对我们来说代表着直接的危险信号。</p><p id="f527" class="pw-post-body-paragraph lm ln it lo b lp mn ju lr ls mo jx lu lv mp lx ly lz mq mb mc md mr mf mg mh im bi translated">我们需要在这项技术的发展中采取更多的步骤，以便能够从原始语音数据中创建真实的样本，但我认为我们离这一成就不远了。</p><p id="ea98" class="pw-post-body-paragraph lm ln it lo b lp mn ju lr ls mo jx lu lv mp lx ly lz mq mb mc md mr mf mg mh im bi translated">我自己曾试图从巴拉克·奥巴马演讲的原始音频中提取一些样本，不出所料，没有任何令人信服的结果。以下是一些例子:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="my mz l"/></div></figure><h1 id="7afc" class="ku kv it bd kw kx ky kz la lb lc ld le jz lf ka lg kc lh kd li kf lj kg lk ll bi translated">结论</h1><p id="4760" class="pw-post-body-paragraph lm ln it lo b lp lq ju lr ls lt jx lu lv lw lx ly lz ma mb mc md me mf mg mh im bi translated">使用 GANs 进行音频生成有很大的潜力，既有积极的一面，也有消极的一面:一些研究人员已经探索了人类语音领域翻译的想法(想象一下将奥巴马的语音转换为特朗普的语音，就像语音的 Deepfakes)，使用一些众所周知的 GANs 架构，如 CycleGAN，以达到他们的目标。</p><p id="330c" class="pw-post-body-paragraph lm ln it lo b lp mn ju lr ls mo jx lu lv mp lx ly lz mq mb mc md mr mf mg mh im bi translated">正如我们所见，虽然这项技术产生的结果与现实相差甚远，但我们需要考虑这样一个事实，即它为滥用提供了可能性，就像 Deepfakes 所发生的那样。在我看来，这不应该吓退我们探索合成音频生成的世界，而是应该邀请我们拥抱它，并发现它的潜力和弱点。</p><p id="ea43" class="pw-post-body-paragraph lm ln it lo b lp mn ju lr ls mo jx lu lv mp lx ly lz mq mb mc md mr mf mg mh im bi translated">我想真诚地感谢你阅读这篇文章，我真的很感激，希望你能学到一些新的东西。</p><p id="c7cc" class="pw-post-body-paragraph lm ln it lo b lp mn ju lr ls mo jx lu lv mp lx ly lz mq mb mc md mr mf mg mh im bi translated">玩得开心！</p></div></div>    
</body>
</html>