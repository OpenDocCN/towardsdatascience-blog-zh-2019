<html>
<head>
<title>Finding Nemo with Azure</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">天蓝色的海底总动员</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/finding-nemo-with-azure-476ed516090?source=collection_archive---------19-----------------------#2019-06-02">https://towardsdatascience.com/finding-nemo-with-azure-476ed516090?source=collection_archive---------19-----------------------#2019-06-02</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="9296" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">使用 Azure 自定义视觉服务探索对象识别</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/a5dd01d1fc85ae7ec2e3736a9dd00e30.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*WOGngatmD4aDSASTU82xOg.png"/></div></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk">Marlin and Dory are on a search for Nemo — Marlin’s only son, who was taken by a fishing trawler. I just figured out a way to utilize the power of Azure cloud to help them find Nemo in the vast sea.</figcaption></figure><p id="bd70" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi lu translated">我正在浏览我童年时收藏的珍贵电影，这时我发现了《海底总动员》。小时候，我一直想帮助尼莫回到他爸爸身边。我只是不知道怎么做。</p><p id="4da4" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">现在我在技术的陪伴下成长，我想我终于找到了出路。</p><p id="1a3d" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">我们可以用 Azure 帮助马林找到尼莫。这是我们需要的:</p><ol class=""><li id="51c5" class="md me it la b lb lc le lf lh mf ll mg lp mh lt mi mj mk ml bi translated">Azure 订阅—查看如何为学生激活<a class="ae mm" href="https://medium.com/@sukhmanjawa/100-credits-with-azure-for-students-without-credit-card-94a09986e0b4?source=friends_link&amp;sk=0371582c7928635714fb10d0561d1432" rel="noopener">Azure</a></li><li id="aacf" class="md me it la b lb mn le mo lh mp ll mq lp mr lt mi mj mk ml bi translated">Azure 自定义视觉帐户</li><li id="73c9" class="md me it la b lb mn le mo lh mp ll mq lp mr lt mi mj mk ml bi translated"><a class="ae mm" href="https://stdntpartners-my.sharepoint.com/:f:/g/personal/sukhmanpreetsingh_jawa_studentpartner_com/Eji3j8POR6BOiHOeZReas5MBIrOp2mKm9HvBkUm3r_PkrQ?e=YyakFL" rel="noopener ugc nofollow" target="_blank">尼莫的照片</a></li></ol><h1 id="5ebe" class="ms mt it bd mu mv mw mx my mz na nb nc jz nd ka ne kc nf kd ng kf nh kg ni nj bi translated">什么是 Azure 自定义视觉？</h1><p id="c41f" class="pw-post-body-paragraph ky kz it la b lb nk ju ld le nl jx lg lh nm lj lk ll nn ln lo lp no lr ls lt im bi translated">Azure Custom Vision 是一项认知服务，让我们可以构建、部署和改进我们自己的图像分类器和对象检测器。图像分类器是一种人工智能服务，它根据图像的视觉特征将标签应用于图像，而对象检测器是一种人工智能服务，它在图像中找到特定的对象，在我们的情况下，就是 Nemo。</p><p id="82e5" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">自定义视觉服务使用机器学习算法将标签应用于图像。图像在提交时会被贴上标签。然后，该算法根据这些数据进行训练，并通过在这些相同的图像上测试自己来计算自己的准确性。一旦算法经过训练，我们就可以测试、重新训练，并最终根据我们应用程序的需求使用它来对新图像进行分类。</p><h2 id="08ea" class="np mt it bd mu nq nr dn my ns nt dp nc lh nu nv ne ll nw nx ng lp ny nz ni oa bi translated">创建 Azure 自定义 Vision 帐户</h2><p id="1f77" class="pw-post-body-paragraph ky kz it la b lb nk ju ld le nl jx lg lh nm lj lk ll nn ln lo lp no lr ls lt im bi translated">要开始构建我们的人工智能解决方案，首先我们需要获得一个 Azure 自定义视觉帐户。让我们开始吧:</p><ol class=""><li id="c151" class="md me it la b lb lc le lf lh mf ll mg lp mh lt mi mj mk ml bi translated">打开<a class="ae mm" href="https://www.customvision.ai" rel="noopener ugc nofollow" target="_blank"> customvision.ai </a></li></ol><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ob"><img src="../Images/1b0c495400b7a1ec01c43d55036a7315.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*fTNrrkwB8FVl0rDsyGXhVA.png"/></div></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk">Azure Custom Vision Portal</figcaption></figure><p id="38be" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">2.登录与 Azure 订阅关联的 Microsoft 帐户，并接受服务条款</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oc"><img src="../Images/6c6c2a06eab51446c44823a6bcbbed3b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*XVPCmLZFNFYy_FaRvndSZg.png"/></div></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk">Terms of Service</figcaption></figure><h1 id="66ed" class="ms mt it bd mu mv mw mx my mz na nb nc jz nd ka ne kc nf kd ng kf nh kg ni nj bi translated">建立一个识别尼莫的模型</h1><p id="927d" class="pw-post-body-paragraph ky kz it la b lb nk ju ld le nl jx lg lh nm lj lk ll nn ln lo lp no lr ls lt im bi translated">现在，我们都准备建立一个机器学习模型，它将能够识别尼莫，并告诉他在哪里。要使用自定义视觉服务，我们需要在 Azure 门户网站<a class="ae mm" href="https://portal.azure.com/?microsoft_azure_marketplace_ItemHideKey=microsoft_azure_cognitiveservices_customvision#create/Microsoft.CognitiveServicesCustomVision" rel="noopener ugc nofollow" target="_blank">中创建自定义视觉训练和预测资源。这将创建训练和预测资源。</a></p><h2 id="4bed" class="np mt it bd mu nq nr dn my ns nt dp nc lh nu nv ne ll nw nx ng lp ny nz ni oa bi translated">创建新项目</h2><ol class=""><li id="e6df" class="md me it la b lb nk le nl lh od ll oe lp of lt mi mj mk ml bi translated">要创建您的第一个项目，选择<strong class="la iu">新建项目</strong>。将出现<strong class="la iu">创建新项目</strong>对话框。</li></ol><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi og"><img src="../Images/213eab942c249c17888c3979b070aa14.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*tX4uOJL2RkFi0MnCitMqpg.png"/></div></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk">Azure Custom Vision projects</figcaption></figure><p id="5413" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">2.输入项目的名称和描述。然后选择一个资源组。如果您的登录帐户与 Azure 帐户相关联，资源组下拉列表将显示您的所有 Azure 资源组，其中包括自定义 Vision 服务资源。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oc"><img src="../Images/7b30979dc5d15e27ad0bef53575e0872.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*tIdOuVOJAc2dVGCm0yphxw.png"/></div></div></figure><p id="de03" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">3.从项目类型中选择对象检测，并从域中选择常规(精简)。紧凑域针对移动设备上的实时对象检测的约束进行了优化。紧凑域生成的模型可以导出到本地运行。</p><p id="7e22" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><strong class="la iu">分类和对象检测:</strong>自定义视觉功能可分为两个特征。图像分类将一个或多个标签应用于图像。对象检测与此类似，但它也返回图像中可以找到应用标签的坐标。从而使我们能够在图像中找到物体的位置。</p><p id="1355" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">4.最后，选择<strong class="la iu">创建项目</strong>。</p><h2 id="09cf" class="np mt it bd mu nq nr dn my ns nt dp nc lh nu nv ne ll nw nx ng lp ny nz ni oa bi translated">选择训练图像</h2><p id="140c" class="pw-post-body-paragraph ky kz it la b lb nk ju ld le nl jx lg lh nm lj lk ll nn ln lo lp no lr ls lt im bi translated">作为最低要求，Azure Custom Vision service 要求每个标签至少有 15 张图像，以便在初始训练集中进行对象识别。我们还需要一些额外的图像来测试模型一旦训练。</p><p id="9600" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">为了有效地训练模型，我们将使用具有视觉多样性的图像，即尼莫的不同图像。</p><p id="05ca" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">此外，所有训练图像必须满足以下标准:</p><ul class=""><li id="f39d" class="md me it la b lb lc le lf lh mf ll mg lp mh lt oh mj mk ml bi translated">。jpg，。png，或者。bmp 格式</li><li id="a332" class="md me it la b lb mn le mo lh mp ll mq lp mr lt oh mj mk ml bi translated">大小不超过 6MB(预测图像为 4MB)</li><li id="4acd" class="md me it la b lb mn le mo lh mp ll mq lp mr lt oh mj mk ml bi translated">最短边不少于 256 像素；任何短于此长度的图像将被自定义视觉服务自动放大</li></ul><h2 id="7e53" class="np mt it bd mu nq nr dn my ns nt dp nc lh nu nv ne ll nw nx ng lp ny nz ni oa bi translated">上传和标记图像</h2><p id="ff2d" class="pw-post-body-paragraph ky kz it la b lb nk ju ld le nl jx lg lh nm lj lk ll nn ln lo lp no lr ls lt im bi translated">在本节中，我们将上传并手动标记图像，以帮助训练对象检测器。</p><ol class=""><li id="f065" class="md me it la b lb lc le lf lh mf ll mg lp mh lt mi mj mk ml bi translated">要添加图像，请单击添加图像按钮，然后选择浏览本地文件。选择打开以上传图像。</li></ol><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oi"><img src="../Images/660633a3507fb901984d5fa91886cd61.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*B15YYY733X-l31PGWNqNkw.png"/></div></div></figure><p id="354c" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">2.与分类器不同，在使用 Nemo 选择图像区域后，必须手动标记单个图像。单击上传的图像以打开标记窗口。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oj"><img src="../Images/c39fa874885a81f4e00b581fed2cc510.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*qGmfKjQRcqCM3olHCRPYmQ.png"/></div></div></figure><h2 id="7347" class="np mt it bd mu nq nr dn my ns nt dp nc lh nu nv ne ll nw nx ng lp ny nz ni oa bi translated">训练模型</h2><p id="a10c" class="pw-post-body-paragraph ky kz it la b lb nk ju ld le nl jx lg lh nm lj lk ll nn ln lo lp no lr ls lt im bi translated">一旦所有的图像都被标记，我们需要训练模型使用它。开始训练</p><ol class=""><li id="1041" class="md me it la b lb lc le lf lh mf ll mg lp mh lt mi mj mk ml bi translated">选择训练按钮。对象识别服务使用所有当前图像来创建识别 Nemo 的视觉质量的模型。</li></ol><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ok"><img src="../Images/c154d47e0ef0f6b0799eb56c97b912aa.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*q0ROrtIjX63EY-U0PCGDBg.png"/></div></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk">Training the model</figcaption></figure><p id="a996" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">2.选择 1 小时培训预算的高级培训，点击<strong class="la iu">培训</strong>。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ol"><img src="../Images/0a808d7dbd7224278c254dbdca916f5f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*J6iFWQpGHszvOycZhbaHZw.png"/></div></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk">Selecting Training Type</figcaption></figure><p id="b474" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">训练过程应该只需要几分钟。在此期间，有关培训过程的信息显示在 Performance 选项卡中。</p><h2 id="cde0" class="np mt it bd mu nq nr dn my ns nt dp nc lh nu nv ne ll nw nx ng lp ny nz ni oa bi translated">评估模型</h2><p id="fbaa" class="pw-post-body-paragraph ky kz it la b lb nk ju ld le nl jx lg lh nm lj lk ll nn ln lo lp no lr ls lt im bi translated">训练完成后，评估并显示模型的性能。定制视觉服务使用我们提交的用于训练的图像来计算精确度和召回率，使用一种称为<a class="ae mm" href="https://en.wikipedia.org/wiki/Cross-validation_(statistics)" rel="noopener ugc nofollow" target="_blank"> k-fold 交叉验证</a>的过程。精确度和召回率是模型有效性的两种不同的度量:</p><ul class=""><li id="7487" class="md me it la b lb lc le lf lh mf ll mg lp mh lt oh mj mk ml bi translated">精度表示正确的已识别图像的比例。例如，如果模型将 100 幅图像识别为 Nemo，并且其中 99 幅图像实际上是 Nemo，那么精度将是 99%。</li><li id="4f74" class="md me it la b lb mn le mo lh mp ll mq lp mr lt oh mj mk ml bi translated">回忆表示被正确识别的实际图像的比例。例如，如果实际上有 100 个尼莫的图像，并且模型识别出 80 个是尼莫，则召回率将是 80%。</li></ul><p id="4aba" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><strong class="la iu">平均精度(mAP): </strong> mAP 告知海底总动员处物体探测器的整体精度。</p><p id="017b" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><strong class="la iu"> <em class="om">注</em> </strong>:紧凑域比一般域精度低，无法构建可在计算资源有限的智能手机上本地运行的模型。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi on"><img src="../Images/4f2856c2103d6f5e6ddab40e0d130aa2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*bhq_FlxyDytLD5ipqM9-pg.png"/></div></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk">Evaluating the model</figcaption></figure><h2 id="b7c0" class="np mt it bd mu nq nr dn my ns nt dp nc lh nu nv ne ll nw nx ng lp ny nz ni oa bi translated">概率阈值</h2><p id="279e" class="pw-post-body-paragraph ky kz it la b lb nk ju ld le nl jx lg lh nm lj lk ll nn ln lo lp no lr ls lt im bi translated">这是在计算精度和召回率时被认为是正确的预测概率的阈值。</p><p id="4d4e" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">用高概率阈值解释预测调用倾向于以回忆为代价返回高精度的结果，这意味着发现的检测是正确的，但是许多甚至没有被模型发现；低概率阈值则相反，即模型检测到大多数实例，但在该集合中存在假阳性。考虑到这一点，我们应该设置概率阈值，这样才能找到尼莫。</p><h2 id="d327" class="np mt it bd mu nq nr dn my ns nt dp nc lh nu nv ne ll nw nx ng lp ny nz ni oa bi translated">测试我们的模型</h2><ol class=""><li id="1719" class="md me it la b lb nk le nl lh od ll oe lp of lt mi mj mk ml bi translated">选择顶部菜单栏右侧的快速测试。此操作会打开一个标记为快速测试的窗口。</li></ol><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi on"><img src="../Images/7dcf1f6db8680837e90b106ff48e7bbf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*KvGLB--PVLsbxmh9SzEhFA.png"/></div></div></figure><p id="9c40" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">2.在<strong class="la iu">快速测试</strong>窗口中，我们点击<strong class="la iu">提交图像</strong>字段，并输入要测试的图像的 URL。要使用本地存储的图像，我们点击<strong class="la iu">浏览本地文件</strong>按钮并选择一个本地图像文件。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oo"><img src="../Images/4b4d00ef5342d57a0ee4b24c26ab2c2f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*hrkCw7CcOhNsnJYmke7ONA.png"/></div></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk">Quick Test window</figcaption></figure><p id="9c4d" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">所选图像出现在页面中间。然后结果以两列表格的形式出现在图像下方，分别标记为<strong class="la iu">标签</strong>和<strong class="la iu">置信度</strong>。查看结果后，我们可以关闭<strong class="la iu">快速测试</strong>窗口。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oo"><img src="../Images/16cf10c885330011d86688e4cebdc328.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*am426b8R8k34zEWb8lhKbA.png"/></div></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk">Results in a Quick Test window</figcaption></figure><h2 id="3d5f" class="np mt it bd mu nq nr dn my ns nt dp nc lh nu nv ne ll nw nx ng lp ny nz ni oa bi translated">使用预测图像进行训练</h2><p id="fa28" class="pw-post-body-paragraph ky kz it la b lb nk ju ld le nl jx lg lh nm lj lk ll nn ln lo lp no lr ls lt im bi translated">我们可以使用之前提交的图像进行培训，具体步骤如下:</p><ol class=""><li id="9e73" class="md me it la b lb lc le lf lh mf ll mg lp mh lt mi mj mk ml bi translated">打开<a class="ae mm" href="https://customvision.ai/" rel="noopener ugc nofollow" target="_blank">自定义视觉网页</a>并选择预测选项卡查看提交给物体检测器的图像。</li></ol><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi op"><img src="../Images/4aa346b8d3a3e86009b18011cacf1ac4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*HuMjsodb_5-RiDqLJXWcqQ.png"/></div></div></figure><p id="a97c" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">2.将鼠标悬停在图像上以查看模型预测的标签。要将图像添加到训练数据，选择图像，选择图像中正确的标记区域，然后选择窗口右上角的<strong class="la iu"> X </strong>按钮。图像从<strong class="la iu">预测</strong>中移除并添加到训练图像中。可以通过选择<strong class="la iu">训练图像</strong>选项卡进行查看。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oj"><img src="../Images/4e64f93dfc19a666e8c13ca5fcdd661a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*kBOEG6spWf5apjJoMzb8xg.png"/></div></div></figure><p id="13b0" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">我们现在可以用更新的训练数据重新训练模型，它将被保存为一个新的迭代。</p><p id="ba9a" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">最后，我们已经使用 Azure 自定义视觉服务构建、训练和测试了一个对象检测模型，现在可以帮助 Marlin 寻找 Nemo。</p></div><div class="ab cl oq or hx os" role="separator"><span class="ot bw bk ou ov ow"/><span class="ot bw bk ou ov ow"/><span class="ot bw bk ou ov"/></div><div class="im in io ip iq"><h1 id="ee09" class="ms mt it bd mu mv ox mx my mz oy nb nc jz oz ka ne kc pa kd ng kf pb kg ni nj bi translated">下一步是什么？</h1><p id="a3a1" class="pw-post-body-paragraph ky kz it la b lb nk ju ld le nl jx lg lh nm lj lk ll nn ln lo lp no lr ls lt im bi translated">我们将导出训练好的模型，使用 CoreML 在 iPhone 上的应用程序上本地运行</p><p id="8496" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">感谢阅读。如果你喜欢它，有什么要分享的或者有什么问题，请在评论中告诉我。</p></div></div>    
</body>
</html>