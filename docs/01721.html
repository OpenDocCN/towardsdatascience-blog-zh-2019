<html>
<head>
<title>Image aesthetics quantification with a convolutional neural network (CNN)</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">基于卷积神经网络的图像美学量化</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/image-aesthetics-quantification-with-a-convolutional-neural-network-cnn-7b39b3cc8189?source=collection_archive---------21-----------------------#2019-03-20">https://towardsdatascience.com/image-aesthetics-quantification-with-a-convolutional-neural-network-cnn-7b39b3cc8189?source=collection_archive---------21-----------------------#2019-03-20</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="cf98" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">基于 MobileNetV1 的卷积神经网络(CNN)训练项目报告，仅使用 14，000 幅图像进行迁移学习</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/62b2a06cef530a7eed13c4a5e61d99d5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*a_fbOaZXdIsHxoiF.jpg"/></div></div></figure><p id="9a99" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated"><em class="ln">雅各布·欧文斯在 Unsplash 上的照片</em></p><h1 id="f642" class="lo lp iq bd lq lr ls lt lu lv lw lx ly jw lz jx ma jz mb ka mc kc md kd me mf bi translated">一.定义</h1><h1 id="2c6d" class="lo lp iq bd lq lr ls lt lu lv lw lx ly jw lz jx ma jz mb ka mc kc md kd me mf bi translated">项目概述</h1><p id="511a" class="pw-post-body-paragraph kr ks iq kt b ku mg jr kw kx mh ju kz la mi lc ld le mj lg lh li mk lk ll lm ij bi translated">“一幅画胜过千言万语”强调了图像在现代世界中的重要性。例如，图像的质量会影响我们在不同领域的决策。尤其是在电子商务领域，我们不能碰的东西是必不可少的。因此，他们对我们的产品购买决策有着重大影响。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ml"><img src="../Images/3ef9337e3bbe6eaf8e7d09c1357298b0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*PsgGBUYxasoQedsW.png"/></div></div></figure><p id="9d58" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated"><em class="ln">订哪个房间？</em></p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi mm"><img src="../Images/207b80070b4ebf0b364434c5b037eed8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*VRITb0N4F1NTh6To3fLrQw.png"/></div></div></figure><p id="a254" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated"><em class="ln">和哪个家伙约会？</em></p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/a028a3e31047fc33b6e41c28ea540f15.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*xU0CjG-_Cer1_-f1.png"/></div></div></figure><p id="30ae" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">点什么菜？</p><p id="f64e" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">这个项目的目标是创建一个可以量化图像美学的模型。</p><h1 id="ac3b" class="lo lp iq bd lq lr ls lt lu lv lw lx ly jw lz jx ma jz mb ka mc kc md kd me mf bi translated">问题陈述</h1><p id="86d5" class="pw-post-body-paragraph kr ks iq kt b ku mg jr kw kx mh ju kz la mi lc ld le mj lg lh li mk lk ll lm ij bi translated">图像质量的量化是计算机视觉中的一个老问题。有客观和主观的方法来评估图像质量。使用客观方法，不同的算法量化图像中的失真和退化。主观方法基于人的感知。这些方法往往互不相关。客观方法涉及传统的基于规则的编程，主观方法不能以这种方式解决。</p><p id="3939" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">这个项目的目标是开发一种主观的图像质量评估方法。如前所述，这个问题不能用经典编程来解决。然而，有监督的机器学习似乎是解决该问题的完美候选，因为这种方法从示例中学习，并且是一种量化不可言喻的方式。具有图像质量注释的数据集是从样本学习的要求。</p><p id="69a5" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">在机器学习生态系统中，卷积神经网络(CNN)是一类神经网络，已被证明在图像识别和分类等领域非常有效。它们受到生物过程的启发，因为神经元之间的连接模式类似于人类视觉皮层的组织。</p><p id="fb0f" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">主观质量模型是用卷积神经网络实现的，因为它似乎非常适合解决这个问题。</p><p id="39d7" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">这些步骤是必要的:</p><ol class=""><li id="f17c" class="mn mo iq kt b ku kv kx ky la mp le mq li mr lm ms mt mu mv bi translated">查找带有高质量注释的图像数据集</li><li id="ff23" class="mn mo iq kt b ku mw kx mx la my le mz li na lm ms mt mu mv bi translated">对数据集进行探索性数据分析(EDA ),以评估问题空间的特征和适用性</li><li id="9b3c" class="mn mo iq kt b ku mw kx mx la my le mz li na lm ms mt mu mv bi translated">数据集的清理和预处理</li><li id="4fab" class="mn mo iq kt b ku mw kx mx la my le mz li na lm ms mt mu mv bi translated">CNN 架构设计</li><li id="99bd" class="mn mo iq kt b ku mw kx mx la my le mz li na lm ms mt mu mv bi translated">CNN 的培训</li><li id="c826" class="mn mo iq kt b ku mw kx mx la my le mz li na lm ms mt mu mv bi translated">对照基准测试模型</li><li id="368c" class="mn mo iq kt b ku mw kx mx la my le mz li na lm ms mt mu mv bi translated">结果分析</li></ol><p id="90af" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">步骤 4 有几次迭代。-7.</p><h1 id="1f22" class="lo lp iq bd lq lr ls lt lu lv lw lx ly jw lz jx ma jz mb ka mc kc md kd me mf bi translated">韵律学</h1><p id="fa42" class="pw-post-body-paragraph kr ks iq kt b ku mg jr kw kx mh ju kz la mi lc ld le mj lg lh li mk lk ll lm ij bi translated">项目中预测了用户评分的分布。从那里你可以预测一个定量的平均评级，也可以预测一个定性的评级桶。为了捕捉这两个指标，使用了。</p><h2 id="f37c" class="nb lp iq bd lq nc nd dn lu ne nf dp ly la ng nh ma le ni nj mc li nk nl me nm bi translated">推土机距离(EMD)</h2><p id="deb5" class="pw-post-body-paragraph kr ks iq kt b ku mg jr kw kx mh ju kz la mi lc ld le mj lg lh li mk lk ll lm ij bi translated"><strong class="kt ir">推土机距离(EMD) </strong>是一种评价某个特征空间中两个多维分布之间不相似性的方法，其中给出了单个特征之间的距离度量，我们称之为地面距离。EMD 将这个距离从单个特征“提升”到完全分布。假设表现良好的 CNN 应该预测类别分布，使得更接近地面真实类别的类别应该比更远的类别具有更高的预测概率。对于图像质量评级，分数 4、5 和 6 比 1、5 和 10 更相关，即目标是如果实际分数是 10，那么当实际分数是 5 时，惩罚预测 4。EMD 定义为将一个分布(直方图)的质量转移到另一个分布的最小成本。(侯、于和萨马拉斯，2016 年)(鲁布纳、托马西和吉巴斯，2000 年)和米兰法尔，2018 年)</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi nn"><img src="../Images/caee14aa17c68103a34e31b0c961326c.png" data-original-src="https://miro.medium.com/v2/resize:fit:570/format:webp/0*SUilD6zBW2twALrX.png"/></div></figure><h2 id="0d32" class="nb lp iq bd lq nc nd dn lu ne nf dp ly la ng nh ma le ni nj mc li nk nl me nm bi translated">准确(性)</h2><p id="b45b" class="pw-post-body-paragraph kr ks iq kt b ku mg jr kw kx mh ju kz la mi lc ld le mj lg lh li mk lk ll lm ij bi translated">为了比较定性结果，使用了<strong class="kt ir">精度</strong>。准确度是正确预测的比率。在这种情况下，在“官方”测试集上使用阈值 5 的地面实况和预测平均值，因为这是 AVA 数据集的标准做法。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi no"><img src="../Images/4055abec3b8311192c779c80f5d5cc8d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*qS3i9KNLfvwJX5Bi.png"/></div></div></figure><h1 id="94bc" class="lo lp iq bd lq lr ls lt lu lv lw lx ly jw lz jx ma jz mb ka mc kc md kd me mf bi translated">数据探索</h1><p id="afed" class="pw-post-body-paragraph kr ks iq kt b ku mg jr kw kx mh ju kz la mi lc ld le mj lg lh li mk lk ll lm ij bi translated">由(Murray、Marchesotti 和 Perronnin 2012a)，(Murray、Marchesotti 和 Perronnin 2012b)介绍的 AVA(美学视觉分析)图像数据集是各种图像美学的参考数据集。该数据集包含 255508 幅图像，以及各种美学、语义和摄影风格的注释。这些图片是从 www.dpchallenge.com 的<a class="ae np" href="http://www.dpchallenge.com." rel="noopener ugc nofollow" target="_blank">收集的。</a></p><h2 id="ea9c" class="nb lp iq bd lq nc nd dn lu ne nf dp ly la ng nh ma le ni nj mc li nk nl me nm bi translated">样本行</h2><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nq"><img src="../Images/d6d1058f108ef6b4339402e6ac44e515.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*PqwEMLhPpbCbXf91.png"/></div></div></figure><h2 id="ab76" class="nb lp iq bd lq nc nd dn lu ne nf dp ly la ng nh ma le ni nj mc li nk nl me nm bi translated">样本图像</h2><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi nr"><img src="../Images/7d46d61b58256bc071253a2458d08ded.png" data-original-src="https://miro.medium.com/v2/resize:fit:1152/format:webp/0*EsuISCNdEANujaAe.png"/></div></figure><p id="c61b" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated"><em class="ln">最佳评价图片</em></p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi nr"><img src="../Images/aa5ac6a1adb4c9c051c99fd15cde0a15.png" data-original-src="https://miro.medium.com/v2/resize:fit:1152/format:webp/0*2GBD5lMaJ9Myy5FB.png"/></div></figure><p id="ea9a" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated"><em class="ln">评价最差的图片</em></p><h2 id="92e8" class="nb lp iq bd lq nc nd dn lu ne nf dp ly la ng nh ma le ni nj mc li nk nl me nm bi translated">评级数量的描述性统计</h2><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi ns"><img src="../Images/6c1e7df03782c69bdf2221788a83f1a5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1204/format:webp/0*9nfoZzq8Q0-06iTX.png"/></div></figure><h2 id="dcfb" class="nb lp iq bd lq nc nd dn lu ne nf dp ly la ng nh ma le ni nj mc li nk nl me nm bi translated">评分均值的描述性统计</h2><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi nt"><img src="../Images/183f58db8e4df343bc4f84ee37fe659a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1122/format:webp/0*YhWigsaRKA8eSP6Q.png"/></div></figure><h1 id="1b6b" class="lo lp iq bd lq lr ls lt lu lv lw lx ly jw lz jx ma jz mb ka mc kc md kd me mf bi translated">探索性可视化</h1><h2 id="17db" class="nb lp iq bd lq nc nd dn lu ne nf dp ly la ng nh ma le ni nj mc li nk nl me nm bi translated">评级数量的分布</h2><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi nu"><img src="../Images/3cb2dcc4b73709286a7bbc6442e59834.png" data-original-src="https://miro.medium.com/v2/resize:fit:1344/format:webp/0*KDgHPga_HrTxxLkW.png"/></div></figure><p id="4088" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated"><em class="ln">每张图片的评分数量:大多数由超过 100 名评分者进行评分</em></p><p id="667c" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">这些图片的评分从 78 到 549 不等，平均分为 210 分，从 1 到 10 分不等。</p><p id="4d94" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">可以看出，所有的图像都被大量的评价者进行了评价。这是非常重要的，因为通过图像的美学来评价图像是非常主观的。要消除异常值评级，需要大量的评级人。</p><h2 id="97e9" class="nb lp iq bd lq nc nd dn lu ne nf dp ly la ng nh ma le ni nj mc li nk nl me nm bi translated">平均评级的分布</h2><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi nr"><img src="../Images/11f335999a0f3af291256e633a411b71.png" data-original-src="https://miro.medium.com/v2/resize:fit:1152/format:webp/0*U6euvOk56MP82pjM.png"/></div></figure><p id="73ab" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated"><em class="ln">评分均值分布</em></p><p id="efbc" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">从分布和描述性统计可以看出，50%的图像具有在 4.9 和 5.9 之间的评级均值，并且大约 85%的图像在 3.9 和 6.8 之间。从箱线图中可以看出，高于 7.2 和低于 3.5 的评级均值是异常值，因为这些值很少。</p><p id="844b" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">这是有问题的，因为模型性能不适用于质量优秀和糟糕的图像。</p><h1 id="fe6e" class="lo lp iq bd lq lr ls lt lu lv lw lx ly jw lz jx ma jz mb ka mc kc md kd me mf bi translated">算法和技术</h1><h2 id="6efb" class="nb lp iq bd lq nc nd dn lu ne nf dp ly la ng nh ma le ni nj mc li nk nl me nm bi translated">卷积神经网络(CNN)</h2><p id="dc2e" class="pw-post-body-paragraph kr ks iq kt b ku mg jr kw kx mh ju kz la mi lc ld le mj lg lh li mk lk ll lm ij bi translated">卷积神经网络(CNN)将用于解决图像美学评估的问题。它们是受生物过程启发的深度神经网络，最常用于分析视觉图像。</p><p id="b7d0" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">CNN 由一个输入层、一个输出层和几个隐藏层组成。隐藏层通常是卷积层，后面是汇集层。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nv"><img src="../Images/a108f053c1e29197be663ed5ab5baed8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*GSxFd5lXDzVwm-rV.png"/></div></div></figure><p id="46bc" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated"><em class="ln">用于图像分类的典型 CNN 的结构。网络的每个卷积层都有多个过滤内核，用于提取特征。二次抽样或汇集层用于减少信息。(来源维基百科)</em></p><p id="b7ca" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated"><em class="ln">卷积层</em></p><p id="2833" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">卷积层的目的是从输入图像中提取特征。它们通过使用输入数据的小方块学习图像特征来保持像素之间的空间关系。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nw"><img src="../Images/cfc2d02f93cdcd644848132c7ea1d12d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*gYWHa2_8U5uMwYfr.png"/></div></div></figure><p id="fde0" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated"><em class="ln">卷积运算提取特征</em></p><p id="f2ca" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated"><em class="ln">汇集层</em></p><p id="4955" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">卷积网络可以包括汇集层。这些层将一层的神经元簇的输出组合成下一层的单个神经元。这样做的原因如下:</p><ul class=""><li id="6d5f" class="mn mo iq kt b ku kv kx ky la mp le mq li mr lm nx mt mu mv bi translated">内存的减少和执行速度的提高</li><li id="9edc" class="mn mo iq kt b ku mw kx mx la my le mz li na lm nx mt mu mv bi translated">过度拟合的减少</li></ul><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi ny"><img src="../Images/e6816aa2b1da7aedd4da5c67608ea860.png" data-original-src="https://miro.medium.com/v2/resize:fit:1140/format:webp/0*AXBevh79jtyujiQT.png"/></div></figure><p id="3601" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated"><em class="ln"> MaxPooling 层，提取一个区域中的最大值来减少信息。(来源维基百科)</em></p><p id="790b" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated"><em class="ln">全连接层</em></p><p id="c800" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">经过多层卷积层和汇集层，一个全连接层完成了网络。全连接层是负责分类任务的传统多层感知器。</p><h2 id="b017" class="nb lp iq bd lq nc nd dn lu ne nf dp ly la ng nh ma le ni nj mc li nk nl me nm bi translated">迁移学习</h2><p id="2757" class="pw-post-body-paragraph kr ks iq kt b ku mg jr kw kx mh ju kz la mi lc ld le mj lg lh li mk lk ll lm ij bi translated">迁移学习是计算机视觉中一种流行的方法，因为它允许我们以省时的方式建立精确的模型(Rawat 和 Wang 2017)。使用迁移学习，你不是从零开始学习过程，而是从解决一个不同的问题时已经学到的模式开始。这样你可以利用以前的经验，避免从头开始。</p><p id="6ddf" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">在计算机视觉中，迁移学习通常通过使用预先训练的模型来表达。预训练模型是在大型基准数据集上训练的模型，用于解决与我们想要解决的问题类似的问题。因此，由于训练这种模型的计算成本，通常的做法是从公开的文献(例如，VGG、Inception、MobileNet)中导入和使用模型。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi nz"><img src="../Images/a2b09fd04ed4be24fd197bc84a92dd3c.png" data-original-src="https://miro.medium.com/v2/resize:fit:892/format:webp/0*_Y1i5I5UtlXHLJ7V.png"/></div></figure><p id="6cca" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated"><em class="ln">迁移学习</em></p><p id="5994" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">一些最先进的图像分类应用程序基于迁移学习解决方案(何等人，2016 年)，(Szegedy 等人，2016 年)谷歌在其(神经图像评估)论文中报告了基于迁移学习的模型的最高准确性(塔莱比和米兰法尔，2018 年)</p><p id="2500" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">该项目的目标是将 MobileNet 架构与 ImageNet 权重结合使用，并将 MobileNet 中的最后一个密集层替换为输出到 10 个类别(得分 1 至 10)的密集层，这些类别与(塔莱比和米兰法尔 2018 年)建议的评级分布一起形成</p><h1 id="0405" class="lo lp iq bd lq lr ls lt lu lv lw lx ly jw lz jx ma jz mb ka mc kc md kd me mf bi translated">基准</h1><p id="5be3" class="pw-post-body-paragraph kr ks iq kt b ku mg jr kw kx mh ju kz la mi lc ld le mj lg lh li mk lk ll lm ij bi translated">在不同的论文中报道了不同模型在 AVA 数据集上的精度。这些精确度被用来作为在这个项目中创建的模型的基准。这些基准基于“官方的”AVA 测试集。目标是达到至少 68%的准确度，这高于图像美学相关论文的下限。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi oa"><img src="../Images/5eae51f6b793b85817e72d980cd5813c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*tE4jxTDO-UIOhNwu.png"/></div></div></figure><h1 id="8c5f" class="lo lp iq bd lq lr ls lt lu lv lw lx ly jw lz jx ma jz mb ka mc kc md kd me mf bi translated">三。方法学</h1><h1 id="e8be" class="lo lp iq bd lq lr ls lt lu lv lw lx ly jw lz jx ma jz mb ka mc kc md kd me mf bi translated">数据预处理</h1><p id="2b71" class="pw-post-body-paragraph kr ks iq kt b ku mg jr kw kx mh ju kz la mi lc ld le mj lg lh li mk lk ll lm ij bi translated">数据预处理可以分为两部分:第一部分是在探索性数据分析过程中完成的。在该步骤中，执行了以下检查和清洁:</p><ol class=""><li id="89f5" class="mn mo iq kt b ku kv kx ky la mp le mq li mr lm ms mt mu mv bi translated">移除图像:</li></ol><ul class=""><li id="9250" class="mn mo iq kt b ku kv kx ky la mp le mq li mr lm nx mt mu mv bi translated">一些图像必须从元数据中删除，因为它们不存在。</li><li id="506e" class="mn mo iq kt b ku mw kx mx la my le mz li na lm nx mt mu mv bi translated">用脚本识别了几个损坏的图像。损坏的图像已从元数据中删除。</li></ul><p id="c91f" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">2.设计了技术图像属性来检查图像异常</p><p id="11d5" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">几个技术图像属性(文件大小、分辨率、长宽比)被设计并检查异常。没有异常图像可以在这里确定这些属性。</p><p id="e13a" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">第二个预处理步骤在训练期间执行:</p><ol class=""><li id="dc37" class="mn mo iq kt b ku kv kx ky la mp le mq li mr lm ms mt mu mv bi translated">将数据拆分为训练集和验证集</li></ol><p id="e768" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">训练集的 10%的图像用于验证。</p><p id="e9d0" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">2.执行了基础模型特定预处理</p><p id="a708" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">Keras 提供的每个基础模型都提供了一个预处理函数，并为该模型提供了特定的预处理步骤。这个预处理步骤被应用于图像生成器，该图像生成器加载用于训练和模型评估的图像。</p><p id="ce40" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">3.分布的标准化</p><p id="e2b9" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">评级分布是标准化的，因为每张图片由不同数量的人进行评级。</p><p id="d24e" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">4.图像大小调整和随机裁剪</p><p id="efba" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">训练图像被重新缩放到 256×256 像素，然后，提取 224×224 像素的随机执行的裁剪。据报道，这可以减少过度拟合问题。(塔莱比和米兰法尔 2018)</p><p id="0922" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">5.数据的欠采样</p><p id="af9a" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">对于更早的训练期，通过在 10 个分级箱中切割数据并取每个箱的前 n 个样本来减少图像的数量。这样做有两个原因:由于计算能力有限，使用的图像较少，这减少了训练模型的时间。另一个原因是数据不平衡。只有很少的几张图片有很低和很高的评分。预计欠采样会降低最常见等级周围的图像过拟合的影响。</p><h1 id="d5e0" class="lo lp iq bd lq lr ls lt lu lv lw lx ly jw lz jx ma jz mb ka mc kc md kd me mf bi translated">履行</h1><p id="82b4" class="pw-post-body-paragraph kr ks iq kt b ku mg jr kw kx mh ju kz la mi lc ld le mj lg lh li mk lk ll lm ij bi translated">目标是创建一个清晰的训练脚本，可以从外部参数化，用于触发不同的训练课程。为了减少这个培训脚本的代码行，它用一个管道脚本来编排培训的构建块。</p><ol class=""><li id="c6b4" class="mn mo iq kt b ku kv kx ky la mp le mq li mr lm ms mt mu mv bi translated">所有需要的库都被确定并放入 requirements.txt 中</li><li id="68cf" class="mn mo iq kt b ku mw kx mx la my le mz li na lm ms mt mu mv bi translated">实现了用于下载 AVA 图像和元数据的内部库。</li><li id="2fe2" class="mn mo iq kt b ku mw kx mx la my le mz li na lm ms mt mu mv bi translated">使用用于训练的构建块创建了训练脚本(加载数据、准备数据、训练、评估)</li><li id="847c" class="mn mo iq kt b ku mw kx mx la my le mz li na lm ms mt mu mv bi translated">培训脚本的构建块被移动到管道脚本中。这些脚本保存了不同的人工制品:模型架构、模型权重、训练历史、训练时间、训练可视化</li><li id="1389" class="mn mo iq kt b ku mw kx mx la my le mz li na lm ms mt mu mv bi translated">创建了一个模型类，它封装了基础模型和顶层模型，并提供了帮助器函数来动态更改优化器和冻结层</li><li id="0e20" class="mn mo iq kt b ku mw kx mx la my le mz li na lm ms mt mu mv bi translated">创建了 EMD 损失函数</li><li id="49e2" class="mn mo iq kt b ku mw kx mx la my le mz li na lm ms mt mu mv bi translated">创建图像生成器是为了加载图像并执行图像的预处理</li><li id="a0fb" class="mn mo iq kt b ku mw kx mx la my le mz li na lm ms mt mu mv bi translated">实现了几个用于模型评估的辅助函数</li></ol><p id="0f96" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">实际训练分两步进行:</p><ol class=""><li id="337b" class="mn mo iq kt b ku kv kx ky la mp le mq li mr lm ms mt mu mv bi translated">基本模型的权重被冻结，只有顶部模型以较高的学习率被训练</li><li id="0e78" class="mn mo iq kt b ku mw kx mx la my le mz li na lm ms mt mu mv bi translated">基本模型权重被解冻，整个网络以较低的学习速率进行训练</li></ol><h2 id="dba8" class="nb lp iq bd lq nc nd dn lu ne nf dp ly la ng nh ma le ni nj mc li nk nl me nm bi translated">CNN 的模型设计</h2><p id="0939" class="pw-post-body-paragraph kr ks iq kt b ku mg jr kw kx mh ju kz la mi lc ld le mj lg lh li mk lk ll lm ij bi translated">如前所述，该模型由两部分组成。除了移除的第一层之外，基本模型保持不变。用 ImageNet 权重初始化模型。ImageNet 项目是一个广泛的视觉数据库，设计用于视觉对象识别软件研究。由于影像与 AVA 数据集中的影像相似，因此使用该数据集的权重。对于基本模型，使用 MobileNet 架构，因为该网络比其他网络小，适合计算能力不足的基于移动和嵌入式的视觉应用。(霍华德等人 2017 年)</p><p id="2633" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">顶层模型由两层组成。第一层是一个下降层，以减少过度拟合，随后是一个密集层，输出大小为 10，激活 softmax 以预测评级分布。具有不同学习速率和学习速率衰减的 Adam 优化器用于训练。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi ob"><img src="../Images/5692c05fdfa16dae0b9852cee43d1990.png" data-original-src="https://miro.medium.com/v2/resize:fit:582/format:webp/0*ZXZG1OC9SaEHaf77.png"/></div></figure><p id="8072" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated"><em class="ln">顶层模型的设计:避免过拟合的脱落层，10 个输出类的密集层</em></p><h1 id="efed" class="lo lp iq bd lq lr ls lt lu lv lw lx ly jw lz jx ma jz mb ka mc kc md kd me mf bi translated">精炼</h1><p id="e4ab" class="pw-post-body-paragraph kr ks iq kt b ku mg jr kw kx mh ju kz la mi lc ld le mj lg lh li mk lk ll lm ij bi translated">模型优化使用了几个参数:</p><ul class=""><li id="3cfc" class="mn mo iq kt b ku kv kx ky la mp le mq li mr lm nx mt mu mv bi translated">密集层和所有层的学习率</li><li id="aa91" class="mn mo iq kt b ku mw kx mx la my le mz li na lm nx mt mu mv bi translated">密集层和所有层的学习率衰减</li><li id="8cb0" class="mn mo iq kt b ku mw kx mx la my le mz li na lm nx mt mu mv bi translated">密集层和所有层的历元数</li><li id="bc89" class="mn mo iq kt b ku mw kx mx la my le mz li na lm nx mt mu mv bi translated">用于训练的每个分级箱的图像数量</li><li id="f3de" class="mn mo iq kt b ku mw kx mx la my le mz li na lm nx mt mu mv bi translated">顶层模型中漏失层的漏失率</li></ul><p id="c530" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">训练是迭代完成的:首先，用非常少的样本和上述参数的默认值训练模型。然后用更多的样本对模型进行训练，对参数进行微调。在模型被训练之后，为测试集计算损失值和准确度。然后将准确度与论文中的准确度分数进行比较(参见“基准”一节),直到达到足够的模型准确度。</p><p id="2069" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">训练过程由训练和验证集的损失图来监督，以检查一切是否正常，并优化学习过程。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/55db11965775b544e7aa0bb6948dedc1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*KJhcmQ3CvdZYCH5X.png"/></div></div></figure><p id="9997" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated"><em class="ln">训练历史图用于寻找两个学习阶段的最佳时期数。在第 1 阶段，验证损失在第 5 时段(图中为 4)变平，在第 2 阶段，val 损失在第 8 时段(图中为 12)变平</em></p><h1 id="32d1" class="lo lp iq bd lq lr ls lt lu lv lw lx ly jw lz jx ma jz mb ka mc kc md kd me mf bi translated">四。结果</h1><h1 id="c26d" class="lo lp iq bd lq lr ls lt lu lv lw lx ly jw lz jx ma jz mb ka mc kc md kd me mf bi translated">模型评估和验证</h1><p id="4708" class="pw-post-body-paragraph kr ks iq kt b ku mg jr kw kx mh ju kz la mi lc ld le mj lg lh li mk lk ll lm ij bi translated">在不同的模型中，选择了模型 8，因为它的 EMD 损失值最低，并且在测试集的所有模型中，它的精度最高。结果是可信的，因为测试集是 AVA 的“官方”测试集，模型在训练或验证期间从未“看到”这些图像。一个有趣的事实是，这个模型的表现略好于模型 9，模型 9 是用两倍数量的训练图像训练的。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi oc"><img src="../Images/a32c93158dc199567c4db58ad4496324.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*7knCzvkTUH7rIjgD.png"/></div></div></figure><p id="563f" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">最佳模型基于 MobileNet 架构，并使用以下参数。所有这些参数似乎都是合理的:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi od"><img src="../Images/460d430f71874710534704161e60792f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*wr4IWH3521w6_jje.png"/></div></div></figure><p id="ba93" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">从下图中可以看出，最佳模型的实际平均评级和预测平均评级的分布非常相似。该模型适用于 3.5 到 7.5 之间的平均评分。低于或高于这些界限的评级没有被模型很好地覆盖。这是因为事实上，没有多少图像具有很高和很低的评级。因此，由于缺乏实例，该模型无法正确评估这些极端异常值。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi oe"><img src="../Images/d42234ebb5c1b957f678cb8ed8386cb2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*--6ODSlenWOCqXaN.png"/></div></div></figure><p id="8cad" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated"><em class="ln">大图:测试集上有蒂平均评分和真实评分的分布。小数字:分布在测试集的下端和上端。</em></p><h1 id="34a6" class="lo lp iq bd lq lr ls lt lu lv lw lx ly jw lz jx ma jz mb ka mc kc md kd me mf bi translated">正当理由；辩解</h1><p id="b47a" class="pw-post-body-paragraph kr ks iq kt b ku mg jr kw kx mh ju kz la mi lc ld le mj lg lh li mk lk ll lm ij bi translated">与基准测试相比，该模型在 AVA 的参考测试集上显示了中等的准确性，该测试集在论文的所有模型中使用。</p><p id="6e01" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">结果相当令人印象深刻，因为该模型仅用 13，914 张图像进行了训练。论文中的模型使用完整的训练集(250，000 幅图像)进行训练。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi of"><img src="../Images/483aaf75bd82e1d4d93daf60d114e070.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*fyHbcqSeQx99Misc.png"/></div></div></figure><h1 id="b710" class="lo lp iq bd lq lr ls lt lu lv lw lx ly jw lz jx ma jz mb ka mc kc md kd me mf bi translated">动词 （verb 的缩写）结论</h1><h1 id="f19e" class="lo lp iq bd lq lr ls lt lu lv lw lx ly jw lz jx ma jz mb ka mc kc md kd me mf bi translated">自由形式可视化</h1><p id="9c36" class="pw-post-body-paragraph kr ks iq kt b ku mg jr kw kx mh ju kz la mi lc ld le mj lg lh li mk lk ll lm ij bi translated">对于最后的快速和肮脏的测试，从“项目概述”部分的图像与模型评级。影像不是 AVA 数据集的一部分。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ml"><img src="../Images/a9119183a99f7da2a8736a85c562e23d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*-DcbRPLrU_qu_6Qj.png"/></div></div></figure><p id="81d0" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated"><em class="ln">左图:4.23 右图:3.91 </em></p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi mm"><img src="../Images/a41895053f88a52b9de66f34f71a6cff.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*0AKAyuSC5mWb-9TV.png"/></div></div></figure><p id="2418" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated"><em class="ln">左图:3.27 右图:4.00 </em></p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/fdf3d009f1a045665363b33bcb4174f0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*bkAJmmnk1rkVz94d.png"/></div></div></figure><p id="9a9e" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated"><em class="ln">左图像:3.98 右图像:4.67 </em></p><p id="4afa" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">可以看出，虽然食物图像的质量几乎相同，但是我们作为人类会评价得更好的图像也被模型评价得更好。</p><h1 id="d268" class="lo lp iq bd lq lr ls lt lu lv lw lx ly jw lz jx ma jz mb ka mc kc md kd me mf bi translated">反射</h1><p id="e2e8" class="pw-post-body-paragraph kr ks iq kt b ku mg jr kw kx mh ju kz la mi lc ld le mj lg lh li mk lk ll lm ij bi translated">本项目所用的流程可概括为以下步骤</p><ol class=""><li id="839c" class="mn mo iq kt b ku kv kx ky la mp le mq li mr lm ms mt mu mv bi translated">发现一个相关问题</li><li id="6a3e" class="mn mo iq kt b ku mw kx mx la my le mz li na lm ms mt mu mv bi translated">对相关论文进行了研究</li><li id="046b" class="mn mo iq kt b ku mw kx mx la my le mz li na lm ms mt mu mv bi translated">对该问题的数据集进行了研究和分析，并选择了最合适的数据集</li><li id="91d0" class="mn mo iq kt b ku mw kx mx la my le mz li na lm ms mt mu mv bi translated">数据集已被清理</li><li id="41c9" class="mn mo iq kt b ku mw kx mx la my le mz li na lm ms mt mu mv bi translated">模型基准是从论文中摘录的</li><li id="94e1" class="mn mo iq kt b ku mw kx mx la my le mz li na lm ms mt mu mv bi translated">项目的技术基础设施已经建立</li><li id="04e0" class="mn mo iq kt b ku mw kx mx la my le mz li na lm ms mt mu mv bi translated">模型被训练、微调，并对照基准进行检查，直到找到一个足够好的模型，解决问题</li></ol><p id="2b3c" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">由于缺乏计算能力和数据集非常大，该项目非常具有挑战性。直到最后，我都无法在完整的训练集上训练模型，因为总是会出现内存不足、Keras 和 Tensorflow 特有的问题。我在某个时候卡住了，因为模型表现不佳。在做了一轮额外的研究后，我找到了谷歌的 Nima 论文，这是一篇全新的论文，以至于当我 7 月份开始这个项目时，它还没有发表。论文中的见解是一个突破，特别是对推土机 Loss 的使用和对基本模型的 MobileNet 架构的使用。我感到非常自豪的是，我可以在相关论文的范围内获得准确性，并掌握了一个目前非常热门的话题，主要是因为我在论文中使用的图像比研究人员少。</p><h1 id="6a10" class="lo lp iq bd lq lr ls lt lu lv lw lx ly jw lz jx ma jz mb ka mc kc md kd me mf bi translated">改进</h1><p id="3568" class="pw-post-body-paragraph kr ks iq kt b ku mg jr kw kx mh ju kz la mi lc ld le mj lg lh li mk lk ll lm ij bi translated">令人兴奋的是，我确实用欠采样策略达到了一定的精度，这一半是出于需要。即使在对数据进行欠采样之后，评级的分布也是不平衡的。</p><p id="52b4" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">更好地执行的策略是对未被充分表示的评级图像进行图像增强。这并不容易，因为不是每种图像增强都可以使用，例如，使图像变暗可能会影响图像的美观。另一个有趣的方法是用 GANs(生成-对抗-网络)生成具有非常高和非常低评级的图像。</p><p id="8d2e" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">该项目的另一个改进是用 Docker 和 Docker NVIDIA 将整个过程集装箱化。目标是有一个 docker 映像，它自动下载数据，对数据进行预处理，进行训练，并在训练后停止容器。在这个项目中，这是通过 anaconda 环境完成的，在我看来这并不理想。我不得不总是从我的本地环境切换到 AWS 云实例，这浪费了时间，因为环境不一样。Docker 环境也可以通过其他深度学习项目的可重用元素进行优化。</p><h1 id="1803" class="lo lp iq bd lq lr ls lt lu lv lw lx ly jw lz jx ma jz mb ka mc kc md kd me mf bi translated">不及物动词参考</h1><p id="091e" class="pw-post-body-paragraph kr ks iq kt b ku mg jr kw kx mh ju kz la mi lc ld le mj lg lh li mk lk ll lm ij bi translated">何、、、任、。2016."图像识别的深度剩余学习."Ieee 计算机视觉和模式识别会议论文集，770–78。</p><p id="4e0b" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">侯、乐、陈-、迪米特里斯-萨马拉斯。2016."平方推土机的距离为基础的损失训练深度神经网络."<em class="ln"> arXiv 预印本 arXiv:1611.05916 </em>。</p><p id="60b0" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">Howard，Andrew G，Menglong Zhu，，Dmitry Kalenichenko，，Tobias Weyand，Marco Andreetto 和 Hartwig Adam。2017." Mobilenets:用于移动视觉应用的高效卷积神经网络."<em class="ln"> arXiv 预印本 arXiv:1704.04861 </em>。</p><p id="22dc" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">孔、舒、沈晓辉、哲林、拉多米尔·梅克和查尔斯·福尔克斯。"照片美学排名网络与属性和内容适应."在欧洲计算机视觉会议上，662–79 页。斯普林格。</p><p id="c85c" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">陆，辛，林哲，金海林，杨建超，王。2014." Rapid:使用深度学习评价绘画美学."在<em class="ln">第 22 届 Acm 多媒体国际会议论文集</em>，457–66。ACM。</p><p id="d096" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">陆、辛哲林、沈晓辉、拉多米尔·梅奇和詹姆斯·Z·王。2015."深层多补丁聚合网络，用于图像风格、美学和质量评估."在<em class="ln">Ieee 计算机视觉国际会议论文集</em>，990–98。</p><p id="02fb" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">默里，奈拉，卢卡·马尔凯索蒂和弗洛伦特·佩罗宁。2012 年 a。" AVA:美学视觉分析的大规模数据库."<a class="ae np" href="https://github.com/mtobeiyf/ava_downloader" rel="noopener ugc nofollow" target="_blank">https://github.com/mtobeiyf/ava_downloader</a>。</p><p id="5b33" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">— — — .2012 年 b。" AVA:美学视觉分析的大规模数据库."在<em class="ln">计算机视觉和模式识别(Cvpr)，2012 Ieee 会议上</em>，2408–15。IEEE。</p><p id="0621" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">拉瓦特、瓦西姆和王增辉。2017."用于图像分类的深度卷积神经网络:综述."<em class="ln">神经计算</em> 29 (9)。麻省理工学院出版社:2352–2449。</p><p id="4881" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">Rubner，Yossi，Carlo Tomasi 和 Leonidas J Guibas。2000."推土机的距离作为图像检索的度量."<em class="ln">国际计算机视觉杂志</em> 40 卷 2 期。斯普林格:99–121。</p><p id="2581" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">施瓦兹、卡塔琳娜、帕特里克·维肖莱克和亨德里克·帕·伦施。2018.“人们会喜欢你的形象吗？学审美空间。”在<em class="ln">计算机视觉的应用(Wacv)，2018 Ieee 冬季会议于</em>，2048–57。IEEE。</p><p id="504c" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">塞格迪，克里斯蒂安，文森特·万霍克，谢尔盖·约菲，乔恩·施伦斯和兹比格涅夫·沃伊纳。2016."重新思考计算机视觉的初始架构."Ieee 计算机视觉和模式识别会议论文集<em class="ln">，2818–26。</em></p><p id="772f" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">塔莱比、侯赛因和佩曼·米兰法尔。2018."尼玛:神经影像评估."<em class="ln"> IEEE 图像处理汇刊</em> 27 (8)。IEEE:3998–4011。</p><p id="647d" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">2019 年 3 月 20 日由延斯·劳弗撰写</p><p id="f18c" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">随意分享！</p></div><div class="ab cl og oh hu oi" role="separator"><span class="oj bw bk ok ol om"/><span class="oj bw bk ok ol om"/><span class="oj bw bk ok ol"/></div><div class="ij ik il im in"><p id="7211" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated"><em class="ln">原载于 2019 年 3 月 20 日 jenslaufer.com</em><em class="ln">的</em> <a class="ae np" href="http://jenslaufer.com/machine/learning/image-aesthetics-quantification-with-a-convolutional-neural-network.html" rel="noopener ugc nofollow" target="_blank"> <em class="ln">。</em></a></p></div></div>    
</body>
</html>