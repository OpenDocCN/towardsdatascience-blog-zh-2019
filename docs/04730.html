<html>
<head>
<title>How to Adjust DetectNet</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">如何调整检测网</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/how-to-adjust-detectnet-a9ad0452d27f?source=collection_archive---------25-----------------------#2019-07-18">https://towardsdatascience.com/how-to-adjust-detectnet-a9ad0452d27f?source=collection_archive---------25-----------------------#2019-07-18</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="158e" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">一种由 NVIDIA 创建的对象检测架构</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/caffd187e5deca8c482b04fa36b6d138.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*XxG0cjIowWrChNNQ"/></div></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk">Photo by <a class="ae kv" href="https://unsplash.com/@christianw?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Christian Wiediger</a> on <a class="ae kv" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><p id="ba0e" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">DetectNet 是由 NVIDIA 创建的对象检测架构。它可以从 NVIDIA 的 Deep Learning 图形用户界面 DIGITS 运行，通过该界面，您可以快速设置和开始训练分类、物体检测、分割和其他类型的模型。</p><p id="e56c" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">NVIDIA 提供了两个基本的 DetectNet prototxt 文件:</p><ol class=""><li id="3c82" class="ls lt iq ky b kz la lc ld lf lu lj lv ln lw lr lx ly lz ma bi translated">单个类一个(为原件)，可在<a class="ae kv" href="https://github.com/NVIDIA/caffe/blob/v0.15.9/examples/kitti/detectnet_network.prototxt" rel="noopener ugc nofollow" target="_blank">这里</a>找到，并且</li><li id="0535" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr lx ly lz ma bi translated">两个等级中的一个可以在这里<a class="ae kv" href="https://github.com/NVIDIA/caffe/blob/caffe-0.15/examples/kitti/detectnet_network-2classes.prototxt" rel="noopener ugc nofollow" target="_blank"/>找到。</li></ol><p id="d322" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">DetectNet 最初的架构是用 Caffe 编写的。除了在<a class="ae kv" href="https://devblogs.nvidia.com/" rel="noopener ugc nofollow" target="_blank">英伟达网站</a>上发表的两篇博客文章和一些(主要)重申博客内容的教程之外，我没有找到太多关于该架构的文档。我确实发现，在 NVIDIA/DIGITS 存储库中，有一个特定的 GitHub 问题<a class="ae kv" href="https://github.com/NVIDIA/DIGITS/issues/980" rel="noopener ugc nofollow" target="_blank">问题#980 </a>已经积累了大量信息。</p><p id="bf79" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">以下是我从 GitHub 问题中收集的重点:</p><ul class=""><li id="46bb" class="ls lt iq ky b kz la lc ld lf lu lj lv ln lw lr mg ly lz ma bi translated">训练集中的图像大小不应该不同。如果是，您应该填充它们或调整它们的大小，使其大小相等。调整大小或填充可以在数字数据集创建步骤中完成。</li><li id="0f77" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr mg ly lz ma bi translated">DetectNet 对大小在 50x50 像素到 400x400 像素之间的边界框很敏感。它很难识别超出这个范围的边界框。</li><li id="efb1" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr mg ly lz ma bi translated">如果您想检测比检测网敏感的尺寸小的对象，您可以调整图像的大小，使大部分边界框适合检测网的首选范围，或者您可以将模型的步距更改得更小。</li><li id="6d26" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr mg ly lz ma bi translated">图像尺寸必须可被步幅整除。例如，1248 和 384(检测网的默认图像大小)可以被 16 整除。</li><li id="5a4f" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr mg ly lz ma bi translated">如果您正在使用不同于原始架构的图像分辨率来训练模型(原始架构期望图像的宽度为 1248，高度为 384)，您需要在架构内的行<a class="ae kv" href="https://github.com/NVIDIA/caffe/blob/94c600c56e726deed2aebe954f9ec390a8e4f9f3/examples/kitti/detectnet_network.prototxt#L57" rel="noopener ugc nofollow" target="_blank"> 57 </a>、<a class="ae kv" href="https://github.com/NVIDIA/caffe/blob/94c600c56e726deed2aebe954f9ec390a8e4f9f3/examples/kitti/detectnet_network.prototxt#L58" rel="noopener ugc nofollow" target="_blank"> 58 </a>、<a class="ae kv" href="https://github.com/NVIDIA/caffe/blob/94c600c56e726deed2aebe954f9ec390a8e4f9f3/examples/kitti/detectnet_network.prototxt#L79" rel="noopener ugc nofollow" target="_blank"> 79 </a>、<a class="ae kv" href="https://github.com/NVIDIA/caffe/blob/94c600c56e726deed2aebe954f9ec390a8e4f9f3/examples/kitti/detectnet_network.prototxt#L80" rel="noopener ugc nofollow" target="_blank"> 80 </a>、<a class="ae kv" href="https://github.com/NVIDIA/caffe/blob/94c600c56e726deed2aebe954f9ec390a8e4f9f3/examples/kitti/detectnet_network.prototxt#L118" rel="noopener ugc nofollow" target="_blank"> 118 </a>、<a class="ae kv" href="https://github.com/NVIDIA/caffe/blob/94c600c56e726deed2aebe954f9ec390a8e4f9f3/examples/kitti/detectnet_network.prototxt#L119" rel="noopener ugc nofollow" target="_blank"> 119 </a>、<a class="ae kv" href="https://github.com/NVIDIA/caffe/blob/94c600c56e726deed2aebe954f9ec390a8e4f9f3/examples/kitti/detectnet_network.prototxt#L2504" rel="noopener ugc nofollow" target="_blank"> 2504 </a>、<a class="ae kv" href="https://github.com/NVIDIA/caffe/blob/94c600c56e726deed2aebe954f9ec390a8e4f9f3/examples/kitti/detectnet_network.prototxt#L2519" rel="noopener ugc nofollow" target="_blank"> 2519 上更改指定的图像尺寸</a></li><li id="3b17" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr mg ly lz ma bi translated">要更改模型步幅，您必须在行<a class="ae kv" href="https://github.com/NVIDIA/caffe/blob/94c600c56e726deed2aebe954f9ec390a8e4f9f3/examples/kitti/detectnet_network.prototxt#L73" rel="noopener ugc nofollow" target="_blank"> 73 </a>、<a class="ae kv" href="https://github.com/NVIDIA/caffe/blob/94c600c56e726deed2aebe954f9ec390a8e4f9f3/examples/kitti/detectnet_network.prototxt#L112" rel="noopener ugc nofollow" target="_blank"> 112 </a>、<a class="ae kv" href="https://github.com/NVIDIA/caffe/blob/94c600c56e726deed2aebe954f9ec390a8e4f9f3/examples/kitti/detectnet_network.prototxt#L2504" rel="noopener ugc nofollow" target="_blank"> 2504 </a>、<a class="ae kv" href="https://github.com/NVIDIA/caffe/blob/94c600c56e726deed2aebe954f9ec390a8e4f9f3/examples/kitti/detectnet_network.prototxt#L2519" rel="noopener ugc nofollow" target="_blank"> 2519 </a>和<a class="ae kv" href="https://github.com/NVIDIA/caffe/blob/94c600c56e726deed2aebe954f9ec390a8e4f9f3/examples/kitti/detectnet_network.prototxt#L2545" rel="noopener ugc nofollow" target="_blank"> 2545 </a>中将默认步幅值(16)更改为您想要的值(这些行指的是单个类 DetectNet prototxt)。</li><li id="625a" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr mg ly lz ma bi translated">如果指定一个较小的步幅，则需要减少网络中的层数来调整维度。降低维数的一种方法是将 pool3/3x3_s2 层的内核和步幅参数更改为 1。该层存在于从<a class="ae kv" href="https://github.com/NVIDIA/caffe/blob/94c600c56e726deed2aebe954f9ec390a8e4f9f3/examples/kitti/detectnet_network.prototxt#L826-L836" rel="noopener ugc nofollow" target="_blank">行 826 到 836 </a>(这些行指的是单个类 DetectNet prototxt)。</li></ul><p id="1748" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">对于<strong class="ky ir">多类</strong>目标检测，其中您想要检测两个以上的类，您可以更改 2 类检测网络协议[ <a class="ae kv" href="https://www.coria.com/insights/blog/computer-vision/training-a-custom-mutliclass-object-detection-model" rel="noopener ugc nofollow" target="_blank"> 5 </a> ]。取决于类别数量的行有:</p><ul class=""><li id="7ff8" class="ls lt iq ky b kz la lc ld lf lu lj lv ln lw lr mg ly lz ma bi translated"><a class="ae kv" href="https://github.com/NVIDIA/caffe/blob/caffe-0.15/examples/kitti/detectnet_network-2classes.prototxt#L82-%23L83" rel="noopener ugc nofollow" target="_blank">第 82 行到第 83 行</a>:为每个额外的类添加一行，递增地或基于数据集标签文本文件中的类值更改“src”和“dst”。</li><li id="894b" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr mg ly lz ma bi translated"><a class="ae kv" href="https://github.com/NVIDIA/caffe/blob/caffe-0.15/examples/kitti/detectnet_network-2classes.prototxt#L2388" rel="noopener ugc nofollow" target="_blank">第 2388 行</a>:更改你的模型将识别的类别数量。</li><li id="8636" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr mg ly lz ma bi translated">第 2502 至 2503 行:每增加一个等级增加一行</li><li id="a58f" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr mg ly lz ma bi translated"><a class="ae kv" href="https://github.com/NVIDIA/caffe/blob/caffe-0.15/examples/kitti/detectnet_network-2classes.prototxt#L2507" rel="noopener ugc nofollow" target="_blank">第 2507 行</a>:将最后一个数字更改为您的模型将识别的类的数量。</li><li id="d286" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr mg ly lz ma bi translated"><a class="ae kv" href="https://github.com/NVIDIA/caffe/blob/caffe-0.15/examples/kitti/detectnet_network-2classes.prototxt#L2518-#L2519" rel="noopener ugc nofollow" target="_blank">2518-2519</a>行:每增加一节课就增加一行。</li><li id="0e8f" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr mg ly lz ma bi translated"><a class="ae kv" href="https://github.com/NVIDIA/caffe/blob/caffe-0.15/examples/kitti/detectnet_network-2classes.prototxt#L2523" rel="noopener ugc nofollow" target="_blank">2523</a>行:将最后一个数字更改为您的模型将识别的类的数量。</li><li id="94e8" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr mg ly lz ma bi translated"><a class="ae kv" href="https://github.com/NVIDIA/caffe/blob/caffe-0.15/examples/kitti/detectnet_network-2classes.prototxt#L2527-L2579" rel="noopener ugc nofollow" target="_blank">2527-2579 行</a>:这里有 4 层，每层 2 层。每个类别有一个对应于分数的层(该层对指定类别的检测进行评分)和一个对应于 mAP 的层(该层计算指定类别的 mAP)。为每一个额外的类别添加一个分数和类别图层，并确保在图层的顶部和底部 blobs 中指定正确的类别号。</li></ul></div><div class="ab cl mh mi hu mj" role="separator"><span class="mk bw bk ml mm mn"/><span class="mk bw bk ml mm mn"/><span class="mk bw bk ml mm"/></div><div class="ij ik il im in"><p id="c4d7" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">综上所述:(I)确保数据集中的所有图像大小相同(如果不相同，请调整大小或填充它们)；(ii)如果使用的是自定义大小的数据集，则必须修改 DetectNet prototxt 文件中的多行内容；(iii)确保数据中的大部分边界框的大小在 50x50 和 400x400 像素之间；(iv)如果要将跨步更改为较小的值， 您必须减少网络中的层，并且(v)您可以调整 DetectNet 体系结构，通过将一些数字更改为您要识别的类的数目，并在 prototxt 文件中添加额外的行和层来进行多类对象检测。</p><p id="17a8" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我建议您阅读下面提到的所有参考资料，以便更好地了解 DetectNet 以及如何针对您的问题对其进行修改。</p></div><div class="ab cl mh mi hu mj" role="separator"><span class="mk bw bk ml mm mn"/><span class="mk bw bk ml mm mn"/><span class="mk bw bk ml mm"/></div><div class="ij ik il im in"><p id="f904" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">参考文献:</p><ol class=""><li id="7bac" class="ls lt iq ky b kz la lc ld lf lu lj lv ln lw lr lx ly lz ma bi translated"><a class="ae kv" href="https://devblogs.nvidia.com/detectnet-deep-neural-network-object-detection-digits/" rel="noopener ugc nofollow" target="_blank">检测网:数字量物体检测的深层神经网络</a></li><li id="fa9c" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr lx ly lz ma bi translated"><a class="ae kv" href="https://github.com/NVIDIA/caffe/blob/v0.15.9/examples/kitti/detectnet_network.prototxt" rel="noopener ugc nofollow" target="_blank"> 1 级检测网网络原型</a></li><li id="08ca" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr lx ly lz ma bi translated"><a class="ae kv" href="https://github.com/NVIDIA/caffe/blob/caffe-0.15/examples/kitti/detectnet_network-2classes.prototxt" rel="noopener ugc nofollow" target="_blank"> 2 级检测网网络原型</a></li><li id="ad68" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr lx ly lz ma bi translated"><a class="ae kv" href="https://github.com/NVIDIA/DIGITS/issues/980" rel="noopener ugc nofollow" target="_blank"> GitHub NVIDIA/DIGITS 问题#980:如何使用 DetectNet 获取自定义大小的数据？</a></li><li id="5374" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr lx ly lz ma bi translated"><a class="ae kv" href="https://groups.google.com/forum/m/#!topic/digits-users/zx_UYu3jlt8" rel="noopener ugc nofollow" target="_blank">数字用户:将初始步幅从 16 改为 8 </a></li><li id="4774" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr lx ly lz ma bi translated"><a class="ae kv" href="https://www.coria.com/insights/blog/computer-vision/training-a-custom-mutliclass-object-detection-model" rel="noopener ugc nofollow" target="_blank">使用 Nvidia 数字训练自定义多类对象检测模型</a></li></ol></div></div>    
</body>
</html>