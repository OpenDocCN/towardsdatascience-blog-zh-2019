<html>
<head>
<title>An Intuitive Understanding to Neural Style Transfer</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">对神经类型转移的直观理解</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/an-intuitive-understanding-to-neural-style-transfer-e85fd80394be?source=collection_archive---------15-----------------------#2019-05-08">https://towardsdatascience.com/an-intuitive-understanding-to-neural-style-transfer-e85fd80394be?source=collection_archive---------15-----------------------#2019-05-08</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><p id="3300" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">神经风格转移是一种机器学习技术，它将一幅图像的“内容”与另一幅图像的“风格”融合在一起</p><div class="ko kp gp gr kq kr"><a href="https://arxiv.org/abs/1508.06576" rel="noopener  ugc nofollow" target="_blank"><div class="ks ab fo"><div class="kt ab ku cl cj kv"><h2 class="bd iu gy z fp kw fr fs kx fu fw is bi translated">艺术风格的神经算法</h2><div class="ky l"><h3 class="bd b gy z fp kw fr fs kx fu fw dk translated">在美术中，尤其是绘画，人类已经掌握了通过构图创造独特视觉体验的技巧</h3></div><div class="kz l"><p class="bd b dl z fp kw fr fs kx fu fw dk translated">arxiv.org</p></div></div></div></a></div><figure class="lb lc ld le gt lf gh gi paragraph-image"><div role="button" tabindex="0" class="lg lh di li bf lj"><div class="gh gi la"><img src="../Images/b2d10847f4a77bea5b3b315c9ec45d49.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*9fmqtmtM3k9Utnr_pSqVOA.png"/></div></div><figcaption class="lm ln gj gh gi lo lp bd b be z dk">Creating a rainbow, mosaic hummingbird with neural style transfer</figcaption></figure><ul class=""><li id="c193" class="lq lr it js b jt ju jx jy kb ls kf lt kj lu kn lv lw lx ly bi translated"><strong class="js iu">内容:</strong>描述图像中物体及其排列的高级特征。<em class="lz">内容的例子是人、动物和形状</em></li><li id="1ee2" class="lq lr it js b jt ma jx mb kb mc kf md kj me kn lv lw lx ly bi translated"><strong class="js iu">风格:</strong>图像的质感。<em class="lz">风格的例子有粗糙度、颜色和锐度</em></li></ul><figure class="lb lc ld le gt lf gh gi paragraph-image"><div class="gh gi mf"><img src="../Images/66f61d239387ea325a4d6b0d3fc000ce.png" data-original-src="https://miro.medium.com/v2/resize:fit:512/format:webp/1*sriWDYtd7SFEvc5Q2aBqBg.png"/></div><figcaption class="lm ln gj gh gi lo lp bd b be z dk">Start by guessing with a white noise image</figcaption></figure><p id="b598" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">给定你的内容图像和风格图像，我们想要创建第三个图像，它是前两个图像的混合。让我们从一个简单的白噪声图像开始。为了优化效率，我们可以从内容图像或样式图像开始，但现在先不要担心这个。</p><p id="9eb7" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">现在假设我们有两个损失函数，<strong class="js iu">内容损失</strong>和<strong class="js iu">风格损失</strong>。这些函数都接受我们生成的图像，并返回一个损失值，该值表示我们生成的图像的内容和样式分别与给定的内容图像和样式图像的内容和样式有多么不同。</p><blockquote class="mg"><p id="b87d" class="mh mi it bd mj mk ml mm mn mo mp kn dk translated">目标是最小化我们生成的图像的内容和风格损失的加权和</p></blockquote><p id="be11" class="pw-post-body-paragraph jq jr it js b jt mq jv jw jx mr jz ka kb ms kd ke kf mt kh ki kj mu kl km kn im bi translated">就像任何其他神经网络模型一样，我们使用优化算法，如随机梯度下降法<em class="lz">，但不是优化神经网络模型的参数，而是优化我们图像的像素值</em>。</p><figure class="lb lc ld le gt lf gh gi paragraph-image"><div role="button" tabindex="0" class="lg lh di li bf lj"><div class="gh gi mv"><img src="../Images/fb1dfcecd98d17e40800d9454326e818.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*MRC8PNNX76KioFTIjs5jdw.png"/></div></div><figcaption class="lm ln gj gh gi lo lp bd b be z dk">Minimizing a weighted sum of style loss and content loss over the generated image. This is a progression of optimization across 600 steps</figcaption></figure><blockquote class="mw mx my"><p id="2b25" class="jq jr lz js b jt ju jv jw jx jy jz ka mz kc kd ke na kg kh ki nb kk kl km kn im bi translated">虽然风格和内容并不是完全相互独立的，但神经风格转移表明，在大多数情况下，我们可以很好地区分这两者。为了解决样式和内容之间的任何冲突，可以调整样式和内容损失的权重，以在生成的图像中显示更多的样式或内容。</p></blockquote><p id="f20d" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">这就结束了我们对神经类型转移的高级解释。</p><h1 id="ff09" class="nc nd it bd ne nf ng nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny nz bi translated">获取内容和风格损失函数</h1><blockquote class="mw mx my"><p id="0f2d" class="jq jr lz js b jt ju jv jw jx jy jz ka mz kc kd ke na kg kh ki nb kk kl km kn im bi translated">本节假设机器学习和卷积神经网络的基础知识。</p></blockquote><p id="da51" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">我们使用经过训练的卷积神经网络(CNN)模型，例如 VGG19，来获取内容和风格损失函数。</p><h2 id="0e36" class="oa nd it bd ne ob oc dn ni od oe dp nm kb of og nq kf oh oi nu kj oj ok ny ol bi translated">内容</h2><p id="9a07" class="pw-post-body-paragraph jq jr it js b jt om jv jw jx on jz ka kb oo kd ke kf op kh ki kj oq kl km kn im bi translated">回想一下，内容是描述对象及其在图像中的排列的高级特征。图像分类模型需要在内容上训练有素，以便准确地将图像标记为“狗”或“汽车”。卷积神经网络(CNN)被设计成过滤掉图像的高级特征。CNN 本质上是从一个图像到另一个图像的顺序映射。每个连续的映射过滤掉更多的高级特征。因此，我们对 CNN 中的图像映射更感兴趣，因为它们捕捉了更多的内容。</p><p id="67af" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">关于 CNN 如何捕捉高级特征的更多详细信息，我推荐谷歌的这篇<a class="ae or" href="https://distill.pub/2017/feature-visualization/" rel="noopener ugc nofollow" target="_blank">文章。它有很多很棒的视觉效果</a></p><figure class="lb lc ld le gt lf gh gi paragraph-image"><div role="button" tabindex="0" class="lg lh di li bf lj"><div class="gh gi os"><img src="../Images/7c28de10b24c33d5f3fde6e515af0c11.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Qa30MNsvrkSZZdiYM9beXg.png"/></div></div><figcaption class="lm ln gj gh gi lo lp bd b be z dk">VGG19 is a traditional CNN model, which sequentially maps images to images via convolutional filters (blue). The red blocks are pooling functions that simply shrink the images to reduce the number of parameters in training. Licensed under CC BY 4.0 — <a class="ae or" href="https://www.researchgate.net/figure/The-figure-maps-of-VGG19-in-our-approach-Blue-ones-are-got-from-convolutional-layer-and_fig4_321232691" rel="noopener ugc nofollow" target="_blank">https://www.researchgate.net/figure/The-figure-maps-of-VGG19-in-our-approach-Blue-ones-are-got-from-convolutional-layer-and_fig4_321232691</a></figcaption></figure><p id="c420" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">我们将图像的<strong class="js iu">内容表示</strong>定义为相对更深入 CNN 模型的图像映射。</p><figure class="lb lc ld le gt lf gh gi paragraph-image"><div role="button" tabindex="0" class="lg lh di li bf lj"><div class="gh gi ot"><img src="../Images/cf44d117f75cc376eaa2b44213026253.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*P5Qsxpt-edRxrLP3HE4WKQ.jpeg"/></div></div><figcaption class="lm ln gj gh gi lo lp bd b be z dk">We chose the fifth image mapping as our content representation. In more technical terms, we would say that our content representation is the feature response of the fifth convolutional layer.</figcaption></figure><p id="d00e" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">我们可以通过仅使用内容表示来重建图像来可视化内容表示。我们首先天真地猜测一个白噪声图像，并迭代优化它，直到图像的内容表示收敛到原始图像的内容表示。这种技术被称为<em class="lz">内容重建</em></p><figure class="lb lc ld le gt lf gh gi paragraph-image"><div role="button" tabindex="0" class="lg lh di li bf lj"><div class="gh gi ou"><img src="../Images/95bdc67c8f2a87fefbb3578a5c1d868d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*2KUSXqqLxgg-0hFv2vNnng.png"/></div></div><figcaption class="lm ln gj gh gi lo lp bd b be z dk">Content reconstructions: The first image uses the content representation from the first image mapping, the second image uses the fifth image mapping and the third image uses the ninth mapping. With each successive image, there is more noise, but the high level structure of the bird is still retained. This indicates that the higher level features are being filtered out</figcaption></figure><h2 id="4234" class="oa nd it bd ne ob oc dn ni od oe dp nm kb of og nq kf oh oi nu kj oj ok ny ol bi translated">风格</h2><p id="7f3a" class="pw-post-body-paragraph jq jr it js b jt om jv jw jx on jz ka kb oo kd ke kf op kh ki kj oq kl km kn im bi translated">对于风格损失，我们希望捕捉图像的纹理信息，而不是结构信息。回想一下，一个图像包含多个通道，在 CNN 模型中，我们通常将图像映射到具有更多通道的图像，以便我们可以捕捉更多的特征。</p><p id="d17c" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">让我们用单词<em class="lz"> layer </em>来描述一个特定通道的图像切片。我们将<strong class="js iu">样式表示</strong>定义为图像映射中各层之间的<em class="lz">相关性</em>。</p><p id="04d3" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">更具体地说，它是图像映射中所有层对的逐元素矩阵乘法的总和。格拉米矩阵经常被用来表达风格。对于给定的图像映射，格拉米矩阵的第 I 行和第 j 列的元素将包含展平的第 I 层和第 j 层之间的点积。</p><figure class="lb lc ld le gt lf gh gi paragraph-image"><div role="button" tabindex="0" class="lg lh di li bf lj"><div class="gh gi ov"><img src="../Images/4cdd1cb93ecea9bb28bdab783b034eac.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*WzxbHR7hIXByvzG4cWxxbw.jpeg"/></div></div><figcaption class="lm ln gj gh gi lo lp bd b be z dk">We chose the first image mapping as our style representation. Style representation is the correlation between all layers in an image. While we only used one image mapping here, we usually use multiple image mappings for style representation (e.g. the first 5 image mappings)</figcaption></figure><p id="09ee" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">就像在内容重建中一样，我们可以通过仅使用样式表示来重建图像，从而可视化样式表示。我们开始天真地猜测一个白噪声图像，并迭代优化它，直到图像的风格表示收敛到原始图像。这种技术被称为<em class="lz">风格重建</em></p><figure class="lb lc ld le gt lf gh gi paragraph-image"><div role="button" tabindex="0" class="lg lh di li bf lj"><div class="gh gi ow"><img src="../Images/3588fbfb134a622b194828152264b4c0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*9j8KGVopN3X-kg_m9b5xOA.png"/></div></div><figcaption class="lm ln gj gh gi lo lp bd b be z dk">Style reconstructions: The first image uses the the style representation from the first image mapping, the second image uses the style representations from the first two image mappings… etc. With each successive image mapping, the textures we obtain become more high level.</figcaption></figure><p id="5045" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">现在我们可以定义内容损失和样式损失函数。</p><blockquote class="mg"><p id="1d13" class="mh mi it bd mj mk ml mm mn mo mp kn dk translated">内容损失是输出图像和内容图像的内容表示之间的平方误差</p><p id="f52a" class="mh mi it bd mj mk ml mm mn mo mp kn dk translated">样式损失是输出图像和样式图像的样式表示之间的平方误差</p></blockquote><h1 id="8e3f" class="nc nd it bd ne nf ng nh ni nj nk nl nm nn ox np nq nr oy nt nu nv oz nx ny nz bi translated">神经类型转移的高级过程</h1><ol class=""><li id="d8b8" class="lq lr it js b jt om jx on kb pa kf pb kj pc kn pd lw lx ly bi translated">决定 CNN 模型的哪些图像映射用于内容表示和样式表示，然后从内容图像计算内容表示，从样式图像计算样式表示。<em class="lz">对于所有这些图像，我将第五个图像映射用于内容表示，将前五个图像映射用于样式表示</em></li><li id="1682" class="lq lr it js b jt ma jx mb kb mc kf md kj me kn pd lw lx ly bi translated">初始化您的输出图像(可以是白噪音图像、样式图像或内容图像的副本，并不重要)</li><li id="c022" class="lq lr it js b jt ma jx mb kb mc kf md kj me kn pd lw lx ly bi translated">根据相同 CNN 模型的<em class="lz">相同图像映射</em>计算输出图像的内容表示和样式表示</li><li id="b854" class="lq lr it js b jt ma jx mb kb mc kf md kj me kn pd lw lx ly bi translated">计算内容损失和风格损失</li><li id="6dc0" class="lq lr it js b jt ma jx mb kb mc kf md kj me kn pd lw lx ly bi translated">在内容损失和样式损失的加权和上优化您的输出图像。<em class="lz">这通常通过随机梯度下降来实现</em></li><li id="7016" class="lq lr it js b jt ma jx mb kb mc kf md kj me kn pd lw lx ly bi translated">重复步骤 2–5，直到您对结果满意为止</li></ol><h1 id="269b" class="nc nd it bd ne nf ng nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny nz bi translated">更多神经类型转移的例子</h1><p id="bf35" class="pw-post-body-paragraph jq jr it js b jt om jv jw jx on jz ka kb oo kd ke kf op kh ki kj oq kl km kn im bi translated">神经风格转移是一种惊人的机器学习技术，可以被艺术家广泛使用。这里还有一些神经类型转移的例子。所有图片都在<a class="ae or" href="https://pixabay.com" rel="noopener ugc nofollow" target="_blank"> Pixabay </a>下授权</p><figure class="lb lc ld le gt lf gh gi paragraph-image"><div role="button" tabindex="0" class="lg lh di li bf lj"><div class="gh gi pe"><img src="../Images/1948a1cf1b1c0b36a8961a5213f972c0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*3cYK9XmfsVkI8NrlkrVwpw.png"/></div></div></figure><figure class="lb lc ld le gt lf gh gi paragraph-image"><div role="button" tabindex="0" class="lg lh di li bf lj"><div class="gh gi pf"><img src="../Images/9eb335054a8a25ec1ac05db66191856e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*K7syMQganRPqNwvrDgfi2g.png"/></div></div></figure><h1 id="23f1" class="nc nd it bd ne nf ng nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny nz bi translated">履行</h1><p id="a414" class="pw-post-body-paragraph jq jr it js b jt om jv jw jx on jz ka kb oo kd ke kf op kh ki kj oq kl km kn im bi translated">有大量的神经类型转换的代码基础。我推荐看看 PyTorch 的教程系列中的<a class="ae or" href="https://pytorch.org/tutorials/advanced/neural_style_tutorial.html" rel="noopener ugc nofollow" target="_blank">。</a></p></div></div>    
</body>
</html>