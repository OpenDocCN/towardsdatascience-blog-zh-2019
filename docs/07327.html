<html>
<head>
<title>Beating the S&amp;P500 Using Machine Learning</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">用机器学习打败 S&amp;P500</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/beating-the-s-p500-using-machine-learning-c5d2f5a19211?source=collection_archive---------6-----------------------#2019-10-15">https://towardsdatascience.com/beating-the-s-p500-using-machine-learning-c5d2f5a19211?source=collection_archive---------6-----------------------#2019-10-15</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="955e" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">使用随机森林回归在 15 年内产生 1400%的回报</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/c731ab530aa3e514554823ed555015dc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*2WQzSu9zNAA3FM_ELShUxg.jpeg"/></div></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk"><em class="ky">The “Fearless Girl” statue on Wall Street. </em>Photo by <a class="ae kz" href="https://unsplash.com/@robertbye?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank">Robert Bye</a> on <a class="ae kz" href="https://unsplash.com/s/photos/wall-street?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank">Unsplash</a>.</figcaption></figure><p id="4d6c" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi lw translated">标准普尔 500 指数是最受关注的市场指数之一，通常被用作整个美国股票市场的基准。虽然人们可以考虑投资一只复制标准普尔 500 指数的被动型基金，但许多人会转向基金经理，更喜欢投资主动型基金。不幸的是，越来越多的研究和数据表明，“跑赢市场”(跑赢基准)非常困难。你可以去<a class="ae kz" href="https://www.cnbc.com/2017/02/27/active-fund-managers-rarely-beat-their-benchmarks-year-after-year.html" rel="noopener ugc nofollow" target="_blank">这里</a>和<a class="ae kz" href="https://www.aei.org/carpe-diem/more-evidence-that-its-very-hard-to-beat-the-market-over-time-95-of-financial-professionals-cant-do-it/" rel="noopener ugc nofollow" target="_blank">这里</a>阅读更多关于这个主题的内容，伯顿·g·马尔基尔的这本优秀的书也值得推荐。<strong class="lc iu">这些研究的结论之一是，在截至 2018 年 12 月的 15 年期间，美国积极管理的股票基金中有 91.62 % </strong>  <strong class="lc iu">跑输了标准普尔 500 指数。</strong></p><p id="15dc" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">在这篇文章中，提出了一种基于机器学习的系统方法，它能够大大超过同期的标准普尔 500。</p></div><div class="ab cl mf mg hx mh" role="separator"><span class="mi bw bk mj mk ml"/><span class="mi bw bk mj mk ml"/><span class="mi bw bk mj mk"/></div><div class="im in io ip iq"><p id="e057" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated"><strong class="lc iu"> <em class="mm">来自《走向数据科学》编辑的提示:</em> </strong> <em class="mm">虽然我们允许独立作者根据我们的</em> <a class="ae kz" rel="noopener" target="_blank" href="/questions-96667b06af5"> <em class="mm">规则和指导方针</em> </a> <em class="mm">发表文章，但我们并不认可每个作者的贡献。你不应该在没有寻求专业建议的情况下依赖一个作者的作品。详见我们的</em> <a class="ae kz" rel="noopener" target="_blank" href="/readers-terms-b5d780a700a4"> <em class="mm">读者术语</em> </a> <em class="mm">。</em></p></div><div class="ab cl mf mg hx mh" role="separator"><span class="mi bw bk mj mk ml"/><span class="mi bw bk mj mk ml"/><span class="mi bw bk mj mk"/></div><div class="im in io ip iq"><h2 id="30a5" class="mn mo it bd mp mq mr dn ms mt mu dp mv lj mw mx my ln mz na nb lr nc nd ne nf bi translated">目标和方法</h2><p id="7a7e" class="pw-post-body-paragraph la lb it lc b ld ng ju lf lg nh jx li lj ni ll lm ln nj lp lq lr nk lt lu lv im bi translated">用 Python 编写的机器学习算法旨在预测 S&amp;P 1500 指数中哪些公司的月度表现可能优于标准普尔 500 指数。为此，实施了基于随机森林回归的算法，将 S&amp;P 1500 指数所有成分的财务比率作为输入。本项目中使用了以下工作流程:</p><ol class=""><li id="c3d1" class="nl nm it lc b ld le lg lh lj nn ln no lr np lv nq nr ns nt bi translated">数据采集和准备</li><li id="3ea4" class="nl nm it lc b ld nu lg nv lj nw ln nx lr ny lv nq nr ns nt bi translated">数据清理</li><li id="26cf" class="nl nm it lc b ld nu lg nv lj nw ln nx lr ny lv nq nr ns nt bi translated">特征选择</li><li id="70fb" class="nl nm it lc b ld nu lg nv lj nw ln nx lr ny lv nq nr ns nt bi translated">训练和回溯测试随机森林回归器</li></ol><blockquote class="nz oa ob"><p id="e693" class="la lb mm lc b ld le ju lf lg lh jx li oc lk ll lm od lo lp lq oe ls lt lu lv im bi translated">*请注意，本项目中使用的数据集来自专有来源(标准普尔和彭博)，因此无法公布。因此，我们将跳过本文中的步骤 1。那些通过所需订阅访问数据集的人可以参考托管在以下 Github 项目上的完整笔记本:<a class="ae kz" href="https://github.com/ThomasRochefortB/SP1500stockPicker" rel="noopener ugc nofollow" target="_blank"> SP1500StockPicker </a>。</p></blockquote><h2 id="bad0" class="mn mo it bd mp mq mr dn ms mt mu dp mv lj mw mx my ln mz na nb lr nc nd ne nf bi translated">随机森林集成学习方法</h2><p id="28e2" class="pw-post-body-paragraph la lb it lc b ld ng ju lf lg nh jx li lj ni ll lm ln nj lp lq lr nk lt lu lv im bi translated"><a class="ae kz" href="https://en.wikipedia.org/wiki/Random_forest" rel="noopener ugc nofollow" target="_blank">随机森林方法</a>基于多个决策树。单个决策树是通过自顶向下的方法构建的，其中数据集遵循基于变量值的一系列布尔分裂，这些布尔分裂在每个节点产生最精确的分离。每个唯一的决策树都是在带有替换的训练集的不同样本上训练的(意味着样本被替换到更大的数据集中)。随机森林回归将多个决策树平均在一起以发出预测。这篇文章不会太深入这个技术的细节，但是在这些由<a class="ae kz" rel="noopener" target="_blank" href="/decision-trees-in-machine-learning-641b9c4e8052">普拉尚特古普塔</a>和<a class="ae kz" rel="noopener" target="_blank" href="/a-guide-to-decision-trees-for-machine-learning-and-data-science-fe2607241956">乔治赛夫</a>撰写的优秀文章中可以找到更多关于随机森林方法的信息。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi of"><img src="../Images/691664797c4aa1360fa1f6980372a009.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*B1XXhoIgOWpWxejMsm4Hdg.png"/></div></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk">An example of a tree with 3 different splits.</figcaption></figure><h2 id="f222" class="mn mo it bd mp mq mr dn ms mt mu dp mv lj mw mx my ln mz na nb lr nc nd ne nf bi translated">工作台</h2><p id="570d" class="pw-post-body-paragraph la lb it lc b ld ng ju lf lg nh jx li lj ni ll lm ln nj lp lq lr nk lt lu lv im bi translated">以下代码是在 Jupyter 笔记本上用 Python 写的。JupyterHub 环境用于在计算服务器上托管代码。大多数数据操作都是使用<a class="ae kz" href="https://pandas.pydata.org/" rel="noopener ugc nofollow" target="_blank"> Pandas </a>和<a class="ae kz" href="https://numpy.org/" rel="noopener ugc nofollow" target="_blank"> NumPy </a>库完成的。机器学习算法基于广泛的<a class="ae kz" href="https://scikit-learn.org/stable/" rel="noopener ugc nofollow" target="_blank"> Scikit-learn </a>库。对于代码某些部分的并行化，使用了 Python 的<a class="ae kz" href="https://docs.python.org/3/library/multiprocessing.html" rel="noopener ugc nofollow" target="_blank">多重处理</a>包。最后，特征选择过程基于<a class="ae kz" href="https://github.com/WillKoehrsen/feature-selector" rel="noopener ugc nofollow" target="_blank">特征选择器</a>包。</p><p id="2084" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">Python 的优点之一是大量的包和库是开源的，任何人都可以使用。利用现有工具的能力来创建创新的解决方案，可以快速高效地解决问题。</p><h2 id="c7af" class="mn mo it bd mp mq mr dn ms mt mu dp mv lj mw mx my ln mz na nb lr nc nd ne nf bi translated">数据清理</h2><p id="e4dd" class="pw-post-body-paragraph la lb it lc b ld ng ju lf lg nh jx li lj ni ll lm ln nj lp lq lr nk lt lu lv im bi translated">起始数据集由 86 个变量组成。下图简要介绍了前 5 个条目:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi og"><img src="../Images/804c58c51d2711d08e1920ad38601388.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*tSAW5OI-9VydoztAJ-oU-g.png"/></div></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk">Head of the database.</figcaption></figure><p id="493f" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">下表显示了一些最重要的变量。其他变量都在<a class="ae kz" href="https://github.com/ThomasRochefortB/SP1500stockPicker/blob/master/variables.txt" rel="noopener ugc nofollow" target="_blank"> Github repo </a>的“variables.txt”文件中定义。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="oh oi l"/></div></figure><p id="548d" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">使用下面的<em class="mm"> pandas </em>命令，我们可以看到每个变量有多少个缺失条目:</p><pre class="kj kk kl km gt oj ok ol om aw on bi"><span id="e4c3" class="mn mo it ok b gy oo op l oq or">dataset.isna().sum()<br/><br/>trt1m                5141<br/>exchg                   0<br/>tpci                    0<br/>adate                 441<br/>qdate                   0<br/>public_date             0<br/>CAPEI                2332<br/>bm                   4764<br/>evm                  1942<br/>pe_op_basic          9984<br/>pe_op_dil           74009<br/>pe_exi              10594<br/>pe_inc              10261<br/>ps                    475<br/><br/>roe                  5294<br/>roce                 3336<br/>                    ...  <br/>dltt_be              5698<br/>debt_assets           532<br/>debt_capital         5328<br/>de_ratio              535<br/>intcov              63530<br/>intcov_ratio        63542<br/>cash_ratio          56652<br/>quick_ratio         56634<br/>curr_ratio          56635<br/><br/>sprtrn                  0<br/>win                     0<br/>decision_date           0<br/>SP1500                  0<br/>Length: 86, dtype: int64</span></pre><p id="cc20" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">我们可以看到一些变量有大量的缺失条目，知道数据帧的总长度是 413 012 个条目。为了解决这个问题，采取了以下步骤来清理数据:</p><ol class=""><li id="12a3" class="nl nm it lc b ld le lg lh lj nn ln no lr np lv nq nr ns nt bi translated">遗漏股票月度回报的行被删除，因为我们不能交易遗漏的回报。</li><li id="d9a5" class="nl nm it lc b ld nu lg nv lj nw ln nx lr ny lv nq nr ns nt bi translated">超过 50%的行为空的变量被删除。</li><li id="5e50" class="nl nm it lc b ld nu lg nv lj nw ln nx lr ny lv nq nr ns nt bi translated">对于缺失的财务比率，我们使用来自<em class="mm"> Scikit-learn </em>的 SimpleImputer 包，用整个数据库的变量平均值替换缺失值。这种方法非常懒惰，会给数据增加建模错误。更合适的方法是使用每种特定股票 n 个月的平均值。尽管如此，还是使用了惰性方法，下面的代码总结了这里列举的 3 个步骤。</li></ol><pre class="kj kk kl km gt oj ok ol om aw on bi"><span id="d781" class="mn mo it ok b gy oo op l oq or">#Dropping rows with now "trt1m" values:</span><span id="ca9a" class="mn mo it ok b gy os op l oq or">database = database[np.isfinite(database['trt1m'])]</span><span id="8be7" class="mn mo it ok b gy os op l oq or"># Dropping columns with more than 50% of the rows missing:</span><span id="40d8" class="mn mo it ok b gy os op l oq or">database = database.loc[:, database.isnull().mean() &lt; .5]</span><span id="ca81" class="mn mo it ok b gy os op l oq or">#Looping through the variables to replace NaNs with the average:</span><span id="53ce" class="mn mo it ok b gy os op l oq or">imp=SimpleImputer(missing_values=np.nan, strategy="mean" )<br/>impute_columns=database.columns[database.isna().any()].tolist()</span><span id="cf47" class="mn mo it ok b gy os op l oq or">for i in impute_columns:<br/>    database[i] = imp.fit_transform(database[[i]])</span></pre><p id="ad34" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">采取了辅助步骤来完成清理过程，可以在本文结尾插入的完整笔记本中查找，或者在我的 Github 上托管。</p><h2 id="a807" class="mn mo it bd mp mq mr dn ms mt mu dp mv lj mw mx my ln mz na nb lr nc nd ne nf bi translated">特征选择</h2><p id="eba4" class="pw-post-body-paragraph la lb it lc b ld ng ju lf lg nh jx li lj ni ll lm ln nj lp lq lr nk lt lu lv im bi translated">使用了来自<a class="ae kz" href="https://github.com/WillKoehrsen/feature-selector" rel="noopener ugc nofollow" target="_blank"> WillKoehrsen </a>的包特征选择器。你可以在这里阅读他的文章<a class="ae kz" rel="noopener" target="_blank" href="/a-feature-selection-tool-for-machine-learning-in-python-b64dd23710f0">，全面了解它的功能。</a></p><p id="c29d" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">基本上，特征选择算法将有助于识别无意义的(低重要性)和共线的特征，以便从不必要的数据变量中修剪起始数据集。移除那些共线变量将减少来自没有贡献的条目的数据集，从而加快整体机器学习过程。当试图识别变量之间的非线性关系时，这种特征选择也将有助于提高算法的泛化能力。</p><p id="7b31" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">使用 feature_selector 包识别高度相关的要素并打印出相关矩阵非常简单:</p><pre class="kj kk kl km gt oj ok ol om aw on bi"><span id="fcad" class="mn mo it ok b gy oo op l oq or">fs.identify_collinear(correlation_threshold=0.975)<br/>fs.plot_collinear(plot_all=True)</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ot"><img src="../Images/9775c24ba5c02c22ef3f68161ee72a7d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1222/format:webp/1*BOlDdQV6T-FpEa3iuLGe6g.png"/></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk">Correlation matrix for the different variables.</figcaption></figure><p id="78dd" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">从上面的图中，我们可以看到一些特征具有高相关性(更红),并且通过该函数识别了相关性高于 0.975 的 5 个特征。</p><p id="afa0" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">接下来，我们想要识别重要性为零的特征。这些特征将不用于分割决策树的任何节点，因此可以被移除以减少训练时间。feature_selector 包从<a class="ae kz" href="https://lightgbm.readthedocs.io/en/latest/" rel="noopener ugc nofollow" target="_blank"> LightGBM </a>库中实现了一个渐变增强机器。该函数将对 10 次训练运行的特征重要性进行平均，以减少方差。</p><pre class="kj kk kl km gt oj ok ol om aw on bi"><span id="159e" class="mn mo it ok b gy oo op l oq or">fs.identify_zero_importance (task = 'regression', eval_metric = 'auc', n_iterations = 10, early_stopping = True)</span><span id="96e5" class="mn mo it ok b gy os op l oq or">1 features with zero importance after one-hot encoding.</span></pre><p id="8bff" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">低重要性特征也可以用 feature_selector 包来标识。该方法使用来自零重要性特征选择的结果来识别不需要获得 99%的总重要性的特征。</p><pre class="kj kk kl km gt oj ok ol om aw on bi"><span id="5152" class="mn mo it ok b gy oo op l oq or">fs.identify_low_importance(cumulative_importance = 0.99)</span><span id="a67a" class="mn mo it ok b gy os op l oq or">69 features required for cumulative importance of 0.99 after one hot encoding.<br/>5 features do not contribute to cumulative importance of 0.99.</span></pre><p id="353e" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">现在，我们可以从上述 3 个步骤中移除所有选定的特征，以获得最终的数据框:</p><pre class="kj kk kl km gt oj ok ol om aw on bi"><span id="c9dc" class="mn mo it ok b gy oo op l oq or">all_to_remove = fs.check_removal()<br/>database = database.drop(columns = all_to_remove)</span><span id="2283" class="mn mo it ok b gy os op l oq or">Total of 9 features identified for removal:<br/>['ptpm', 'tpci', 'debt_invcap', 'debt_ebitda', 'opmad', 'aftret_equity', 'dltt_be', 'cfm', 'capital_ratio']</span></pre><h2 id="72e7" class="mn mo it bd mp mq mr dn ms mt mu dp mv lj mw mx my ln mz na nb lr nc nd ne nf bi translated">机器学习算法</h2><p id="ed6d" class="pw-post-body-paragraph la lb it lc b ld ng ju lf lg nh jx li lj ni ll lm ln nj lp lq lr nk lt lu lv im bi translated">本节介绍的机器学习算法将预测整个月最有可能跑赢 S&amp;P500 的股票。预测将在指定月份的第一天进行。我们还希望能够在不同时期对算法进行回溯测试，以验证模型的性能。我们将定义一个名为“rfstockpicker_backtest”的函数，它将包含以下条目:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="oh oi l"/></div></figure><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="oh oi l"/></div></figure><p id="9915" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">该函数的第一部分获取决策日期并标识前一个月。然后，它会创建一个范围从上个月到 7 年前的训练集。选择这个持续时间是因为我们知道过去 33 个经济周期的平均持续时间是 56 个月。目前的扩张周期已经持续了 10 年。7 年的时间让我们可以为我们的每个训练集获得大约一个完整的经济周期。测试集将是我们希望发出预测的月份。我们将使用一个基本的迭代，一个月接一个月地回溯，以便进行几个月的回溯测试。在每次迭代中实例化我们的变量可以确保没有信息及时传播回来(详细信息请参见完整代码)。</p><p id="2830" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">在删除用于训练和测试的非必要数据后，该函数从<a class="ae kz" href="https://scikit-learn.org/stable/" rel="noopener ugc nofollow" target="_blank"> <em class="mm"> sklearn </em> </a> <em class="mm"> </em>库中实例化 aRandomForestRegressor 对象，并使用作为输入参数提供的树的数量(n_estimators)和可用进程(n_jobs)对其进行初始化。然后，该函数在训练集上训练算法，并在测试月对 SP1500 的每只股票发出预测。</p><p id="cc49" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">函数的最后一部分返回各种要素的重要性，以供进一步分析。</p><p id="80d3" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">例如，可以测试 2018 年 12 月的函数:</p><pre class="kj kk kl km gt oj ok ol om aw on bi"><span id="2cd8" class="mn mo it ok b gy oo op l oq or">results,feature_imp,importances,train_feature_list=rfstockpicker_backtest(database,("2018-12-01"),7,1,100,24)</span></pre><p id="baf1" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">对“rfstockpicker_backtest”函数的调用将返回以下信息:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="oh oi l"/></div></figure><p id="2f6a" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">例如，假设每个月，决定买入跑赢指数几率最高的前 10 只股票。可以使用以下命令显示这些内容:</p><pre class="kj kk kl km gt oj ok ol om aw on bi"><span id="f468" class="mn mo it ok b gy oo op l oq or">portfolio=results[0].nlargest(10, 'predictions')<br/>portfolio</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ou"><img src="../Images/199a3f20fb220206afc0e217f11d489a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ryK8giBHn7NtLLOG1EfWGQ.png"/></div></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk">The 10 stocks with the highest probability of beating the SP500 for December 2018.</figcaption></figure><p id="4cbe" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">用相等的权重对这些回报率进行平均(算术平均)得出 2018 年 12 月的回报率为<strong class="lc iu"> 2.09% </strong>，相比之下，同期的 SP500 回报率为<strong class="lc iu">1.79%</strong>。</p><p id="5dc9" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">可以通过查看特征重要性来改进该模型:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ov"><img src="../Images/50f50ae5ac958248f39daa3cdc078ee1.png" data-original-src="https://miro.medium.com/v2/resize:fit:788/format:webp/1*ZYl01yuZfqXvW6ybjcGnOA.png"/></div></figure><p id="6cd7" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">虽然在该图中，许多特征被压缩在 x 轴上，但是仍然可以看出其中一些特征具有非常低的重要性。重要性低于 0.02 的要素可以使用以下命令移除:</p><pre class="kj kk kl km gt oj ok ol om aw on bi"><span id="6189" class="mn mo it ok b gy oo op l oq or">df_importance = pd.DataFrame(feature_imp, columns = ['Feature', 'Importance']) <br/>feature_to_drop=df_importance.Feature[df_importance['Importance']&lt;0.02]<br/>new_db=database.drop(columns=feature_to_drop)</span></pre><p id="95a5" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">这个新数据库允许我们增加 2018 年 12 月的月度回报率，回报率为<strong class="lc iu"> 3.57%，</strong>提高了<strong class="lc iu"> +1.48%。</strong></p><p id="7405" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">现在让我们从 2003 年 12 月到 2018 年 12 月，对我们的模型进行 15 年的回溯测试:</p><pre class="kj kk kl km gt oj ok ol om aw on bi"><span id="4eb9" class="mn mo it ok b gy oo op l oq or">results,feature_imp,importances,train_feature_list=rfstockpicker_backtest(new_db,("2018-12-01"),7,(12*15),100,24)</span></pre><p id="87af" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">主迭代循环将于 2018 年 12 月开始，并在 12*15 或 180 个月的时间内回溯 1 个月，以覆盖整个回溯测试期。在 180 个月的测试期内，我们的模型获得了<strong class="lc iu">+1421%</strong><strong class="lc iu"/>的复合回报，相比之下，实际 SP500 指数的复合回报为<strong class="lc iu"> +261 % </strong>。<strong class="lc iu">因此，该模型在 15 年期间产生了+1160%的超额回报。</strong></p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ow"><img src="../Images/da6e8e243056804bbf0049e4514cf796.png" data-original-src="https://miro.medium.com/v2/resize:fit:840/format:webp/1*-77IUhROX-0lATGuChkNiQ.png"/></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk">Growth of 1$ over the 15 year period.</figcaption></figure><h2 id="54cd" class="mn mo it bd mp mq mr dn ms mt mu dp mv lj mw mx my ln mz na nb lr nc nd ne nf bi translated">结束语</h2><p id="378f" class="pw-post-body-paragraph la lb it lc b ld ng ju lf lg nh jx li lj ni ll lm ln nj lp lq lr nk lt lu lv im bi translated">为了简化项目，提出了三个主要假设:</p><ol class=""><li id="ed3e" class="nl nm it lc b ld le lg lh lj nn ln no lr np lv nq nr ns nt bi translated">前一个月买入的每只股票都被卖出，每个月测试 10 只新股票。因此，有可能一只股票在月末被卖出，然后第二天又被买入。</li><li id="2f3d" class="nl nm it lc b ld nu lg nv lj nw ln nx lr ny lv nq nr ns nt bi translated">没有考虑交易成本，这将影响模型的复合回报。在测试的每个月中，有 10 只股票被买入，10 只股票被卖出。</li><li id="b52d" class="nl nm it lc b ld nu lg nv lj nw ln nx lr ny lv nq nr ns nt bi translated">没有考虑股息，这也将影响模型的复合回报。</li></ol><p id="2c53" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">代码中还可以实现许多改进。其他机器学习技术和神经网络将在以后的文章中探讨。敬请期待！</p><p id="4745" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">如果你有任何意见或问题，欢迎写在下面！我会尽我所能回答他们。这篇文章的代码可以从项目的<a class="ae kz" href="https://github.com/ThomasRochefortB/SP1500stockPicker" rel="noopener ugc nofollow" target="_blank"> Github Repo 的 Jupyter 笔记本中获得。</a></p><p id="b777" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">感谢您的宝贵时间！</p></div></div>    
</body>
</html>