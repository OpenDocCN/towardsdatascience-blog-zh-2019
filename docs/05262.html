<html>
<head>
<title>Probability Learning I : Bayes’ Theorem</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">概率学习 I:贝叶斯定理</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/probability-learning-i-bayes-theorem-708a4c02909a?source=collection_archive---------7-----------------------#2019-08-06">https://towardsdatascience.com/probability-learning-i-bayes-theorem-708a4c02909a?source=collection_archive---------7-----------------------#2019-08-06</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="d644" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">通过一个简单的日常例子来了解概率的基本定理之一。</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/4ad4bd052316d75c7010457dd53f3a2a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*sTToCe0vcpxgxVfsNWgZ3A.jpeg"/></div></div></figure><p id="5272" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">这篇文章假设你有一些概率和统计的基础知识。如果你不知道，不要害怕，我已经在<strong class="kw iu">收集了我能找到的向你介绍这些主题的最佳资源</strong>，这样你就可以阅读这篇文章，理解它，并且<strong class="kw iu">充分享受它</strong>。</p><p id="12b6" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">在这本书中，我们将讨论概率论中最著名和最常用的定理之一:<strong class="kw iu">贝叶斯定理</strong>。没听说过？那么你将会享受到一顿大餐！已经知道是什么了？然后继续读下去，用一个简单的日常例子巩固你的知识，这样你也可以用简单的语言向他人解释。</p><p id="9c3c" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">在接下来的<strong class="kw iu">帖子</strong>中，我们将了解一些<strong class="kw iu">更实用的贝叶斯定理</strong>的简化，以及<strong class="kw iu">其他机器学习的概率方法</strong>，如<strong class="kw iu"> <em class="lq">隐马尔可夫模型</em> </strong>。</p><p id="9c09" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated"><em class="lq">最后，在我们开始之前，这里有一些额外的资源可以让你的机器学习生涯突飞猛进:</em></p><pre class="kj kk kl km gt lr ls lt lu aw lv bi"><span id="a899" class="lw lx it ls b gy ly lz l ma mb"><em class="lq">Awesome Machine Learning Resources:</em></span><span id="5cc1" class="lw lx it ls b gy mc lz l ma mb"><em class="lq">- For </em><strong class="ls iu"><em class="lq">learning resources</em></strong><em class="lq"> go to </em><a class="ae md" href="https://howtolearnmachinelearning.com/books/machine-learning-books/" rel="noopener ugc nofollow" target="_blank"><strong class="ls iu"><em class="lq">How to Learn Machine Learning</em></strong></a><em class="lq">! <br/>- For </em><strong class="ls iu"><em class="lq">professional</em></strong><em class="lq"> </em><strong class="ls iu"><em class="lq">resources</em></strong><em class="lq"> (jobs, events, skill tests) go to </em><a class="ae md" href="https://aigents.co/" rel="noopener ugc nofollow" target="_blank"><strong class="ls iu"><em class="lq">AIgents.co — A career community for Data Scientists &amp; Machine Learning Engineers</em></strong></a><strong class="ls iu"><em class="lq">.</em></strong></span></pre><p id="09b8" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">我们走吧！</p><h1 id="91e7" class="me lx it bd mf mg mh mi mj mk ml mm mn jz mo ka mp kc mq kd mr kf ms kg mt mu bi translated">概率介绍:</h1><p id="3aff" class="pw-post-body-paragraph ku kv it kw b kx mv ju kz la mw jx lc ld mx lf lg lh my lj lk ll mz ln lo lp im bi translated">在本节中，我列出了三个非常好的和简明的<strong class="kw iu">来源(主要是前两个，第三个更广泛一点)来学习概率的基础知识</strong>，这是你理解这篇文章所需要的。不要害怕，这些概念非常简单，只要快速阅读，你就一定能理解它们。</p><p id="ee4d" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">如果你已经掌握了基本概率，可以跳过这一节。</p><ul class=""><li id="8702" class="na nb it kw b kx ky la lb ld nc lh nd ll ne lp nf ng nh ni bi translated"><a class="ae md" href="https://medium.com/@laumannfelix/statistics-probability-fundamentals-1-1325ef72f3f" rel="noopener"/></li><li id="9ad4" class="na nb it kw b kx nj la nk ld nl lh nm ll nn lp nf ng nh ni bi translated"><a class="ae md" href="http://www.mbmlbook.com/MurderMystery.html" rel="noopener ugc nofollow" target="_blank"> <strong class="kw iu">有趣的小概率介绍在<em class="lq">机器学习</em> </strong> </a> <em class="lq"> </em>中，主要用一个神秘但简单的例子来介绍概率的每个主要术语。</li><li id="a1a8" class="na nb it kw b kx nj la nk ld nl lh nm ll nn lp nf ng nh ni bi translated"><a class="ae md" href="https://projects.iq.harvard.edu/stat110/home" rel="noopener ugc nofollow" target="_blank"> <strong class="kw iu">哈佛的统计学 110 课程</strong>。</a>这是一个更大的资源，以防你不仅想学习基础知识，还想更深入地了解统计的奇妙世界:</li></ul><p id="238e" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">好了，现在你已经准备好继续这篇文章的其余部分了，坐下来，放松，享受吧。</p><h1 id="d075" class="me lx it bd mf mg mh mi mj mk ml mm mn jz mo ka mp kc mq kd mr kf ms kg mt mu bi translated">贝叶斯定理:</h1><h2 id="4511" class="lw lx it bd mf no np dn mj nq nr dp mn ld ns nt mp lh nu nv mr ll nw nx mt ny bi translated">贝叶斯是谁？</h2><p id="630a" class="pw-post-body-paragraph ku kv it kw b kx mv ju kz la mw jx lc ld mx lf lg lh my lj lk ll mz ln lo lp im bi translated"><strong class="kw iu">托马斯·贝叶斯</strong> (1701 — 1761)是<strong class="kw iu">的英国神学家和数学家</strong>，隶属于<strong class="kw iu">皇家学会</strong>(世界上最古老的国家科学学会，也是促进英国科学研究的主要国家组织)，其他知名人士都曾在此注册，如牛顿、达尔文或法拉第。他发展了一个最重要的概率定理，这个定理创造了他的名字:<strong class="kw iu">贝叶斯定理，或条件概率定理。</strong></p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nz"><img src="../Images/e747106ddefbd4d50e2e387316d6c84e.png" data-original-src="https://miro.medium.com/v2/resize:fit:884/1*WtyVnX1UFixKHOAcR74dpw.gif"/></div><figcaption class="oa ob gj gh gi oc od bd b be z dk">Portrait of the Reverend Thomas Bayes, father of Bayes’ Theorem</figcaption></figure><h2 id="06ad" class="lw lx it bd mf no np dn mj nq nr dp mn ld ns nt mp lh nu nv mr ll nw nx mt ny bi translated">定理:条件概率</h2><p id="267c" class="pw-post-body-paragraph ku kv it kw b kx mv ju kz la mw jx lc ld mx lf lg lh my lj lk ll mz ln lo lp im bi translated">为了解释这个定理，我们将使用一个非常简单的例子。假设你被诊断出患有一种非常罕见的疾病，这种疾病只影响 0.1%的人。也就是说，每 1000 人中有 1 人。</p><p id="a743" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated"><strong class="kw iu">您进行的疾病检查</strong>测试<strong class="kw iu">对 99%的患病者进行了正确分类</strong>，而对健康人的错误分类只有 1%的几率。</p><blockquote class="oe of og"><p id="7733" class="ku kv lq kw b kx ky ju kz la lb jx lc oh le lf lg oi li lj lk oj lm ln lo lp im bi translated">我完了！这种病致命吗医生？</p></blockquote><p id="6dc3" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">大多数人都会这么说。然而，在这次测试之后，我们真的患病的可能性有多大？</p><blockquote class="oe of og"><p id="14d5" class="ku kv lq kw b kx ky ju kz la lb jx lc oh le lf lg oi li lj lk oj lm ln lo lp im bi translated">99%肯定！我最好把我的东西整理好。</p></blockquote><p id="3887" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">基于这种想法，贝叶斯的想法应该会占上风，因为它实际上与现实相差甚远。让我们用贝叶斯定理来获得一些观点。</p><p id="04cc" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated"><strong class="kw iu">贝叶斯定理</strong>，或者我之前称之为条件概率定理<strong class="kw iu">，用于计算假设(H)为真的<strong class="kw iu">概率</strong>(即。患有疾病)<strong class="kw iu">鉴于某一事件(E)已经发生</strong>(在测试中被诊断为该疾病阳性)。使用以下公式描述该计算:</strong></p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ok"><img src="../Images/994e43bf6b98f0dad7485a1b7a2cd57f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*4_dSOG3F5qmjOFTGzA829Q.png"/></div></div><figcaption class="oa ob gj gh gi oc od bd b be z dk">Bayes’ formula for conditional probability</figcaption></figure><p id="35af" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">等号 P(H |E ) 左边的<strong class="kw iu">项是<strong class="kw iu">假设我们在这种疾病的测试中被诊断为阳性(E) </strong>，那么我们实际上想要计算的是患这种疾病的概率(H)。概率项中的<strong class="kw iu">竖线(|) </strong>表示条件概率(即给定 B 的概率将是<strong class="kw iu"> <em class="lq"> P(A|B) </em> </strong>)。</strong></p><p id="9108" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">右边<strong class="kw iu"> <em class="lq"> P(E|H) </em> </strong>的分子左边一项是假设为真的情况下，事件发生的概率。在我们的例子中，这将是在测试中被诊断为阳性的<strong class="kw iu">概率，假设我们患有疾病</strong>。</p><p id="e961" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">它旁边的术语；<strong class="kw iu"><em class="lq">【P(H)</em></strong>是假设在任何事件发生之前的<strong class="kw iu">先验概率。在这种情况下，这将是在进行任何测试之前患病的可能性。</strong></p><p id="6b9a" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">最后，分母上的项；<strong class="kw iu"> <em class="lq"> P(E) </em> </strong>是事件发生的概率，即被诊断为该疾病阳性的概率。<strong class="kw iu">这个术语可以进一步分解</strong>为两个更小术语的总和:患病且检测呈阳性加上未患病且检测也呈阳性。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ol"><img src="../Images/4c9bd228a3350500deeb68e43a64940a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*uh-9cBH-qsU9z9WS6eK2kw.png"/></div></div><figcaption class="oa ob gj gh gi oc od bd b be z dk">Deconstruction of the probability of testing positive on the test</figcaption></figure><p id="ed3d" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">在这个公式中<strong class="kw iu"> <em class="lq"> P(~H) </em> </strong>表示没有患病的<strong class="kw iu">先验概率，</strong>其中<strong class="kw iu"> <em class="lq"> ~ </em> </strong>表示否定或不否定。下图描述了条件概率整体计算中涉及的每个术语:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi om"><img src="../Images/8d654e1aaecdefd42f7971c2f6b30dac.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*QOvV5TOJyYu1jFYzMHru6w.png"/></div></div><figcaption class="oa ob gj gh gi oc od bd b be z dk">Description of each of the terms involved on the formulation of by Bayes’ Theorem</figcaption></figure><p id="d682" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">记住，对我们来说,<strong class="kw iu">假设或假设 H 患有</strong>疾病，而<strong class="kw iu">事件或证据 E </strong>在这种疾病的测试中被<strong class="kw iu">诊断为阳性</strong>。</p><p id="c56e" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">如果我们使用我们看到的<strong class="kw iu">第一个公式</strong>(计算患有疾病并被诊断为阳性的条件概率的完整公式)<strong class="kw iu">分解分母，并插入数字</strong>，我们得到以下计算结果:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi on"><img src="../Images/e13dbdd81311d2f7ebd05edbb51bb2b7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*wG9EG9D2Vr-gnpbcL-BJ2Q.png"/></div></div><figcaption class="oa ob gj gh gi oc od bd b be z dk">Calculation of the conditional probability</figcaption></figure><p id="a034" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">0.99 来自 99%的被诊断为阳性的概率，0.001 来自 1000 分之一的患病概率，0.999 来自没有患病的概率，最后的 0.01 来自即使我们没有患病也能被诊断为阳性的概率。这种计算的最终结果是:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oo"><img src="../Images/4311ac10a40739d2217cac20e9c62b9a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*5uBWtHV1hXrE5oF_J3zw7Q.png"/></div></div><figcaption class="oa ob gj gh gi oc od bd b be z dk">Result of the calculation</figcaption></figure><p id="34b6" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated"><strong class="kw iu"> 9%！我们患这种疾病的可能性只有 9%!</strong><em class="lq">怎么会这样？”</em>你大概在问自己。<strong class="kw iu">魔法？</strong>不，我的朋友们，这不是魔术，这是<strong class="kw iu">只是概率</strong>:应用于数学的常识。就像丹尼尔·卡内曼在《思考，快与慢》一书中描述的那样，人类的大脑非常不擅长估计和计算概率，就像前面的例子所显示的那样，所以我们应该总是抑制我们的直觉，后退一步，使用我们所能使用的所有概率工具。</p><p id="a9f1" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">现在想象一下，在第一次测试被诊断为阳性后，我们决定<strong class="kw iu">在不同的诊所以相同的条件进行另一次测试</strong>以复查结果，不幸的是，我们再次得到阳性诊断，这表明第二次测试也表明我们患有该疾病。</p><p id="a24c" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">现在得这种病的实际概率是多少？好的，我们可以使用和之前完全一样的公式，但是<strong class="kw iu">用上一次</strong>得到的后验概率(一次检测阳性后 9%的概率)代替最初的先验概率 (0.1%患病几率)<strong class="kw iu">，以及它们的补充项。</strong></p><p id="d7e5" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">如果我们处理这些数字，我们会得到:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi on"><img src="../Images/bcf112c080120495ce0a63ef097e457b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*4zQ4vn-ykDurOcOKmOgT1w.png"/></div></div><figcaption class="oa ob gj gh gi oc od bd b be z dk">Calculation of the conditional probability after the second positive</figcaption></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi op"><img src="../Images/9c52690adabad539e3474974f57cc90b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Y2DLeJ26BUpVnrhZoOxgwQ.png"/></div></div><figcaption class="oa ob gj gh gi oc od bd b be z dk">Results after the second positive</figcaption></figure><p id="da34" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">现在，我们有更高的几率真的患上这种疾病。尽管看起来很糟糕，但在两次阳性测试后，仍然不能完全确定我们患有这种疾病。确定性似乎逃离了概率的世界。</p><h2 id="6ca4" class="lw lx it bd mf no np dn mj nq nr dp mn ld ns nt mp lh nu nv mr ll nw nx mt ny bi translated">定理背后的直觉</h2><p id="713e" class="pw-post-body-paragraph ku kv it kw b kx mv ju kz la mw jx lc ld mx lf lg lh my lj lk ll mz ln lo lp im bi translated">这个著名定理背后的直觉是，我们永远无法完全确定这个世界，因为它是一个不断变化的存在，变化是现实的本质。然而，我们可以做的事情，这是这个定理背后的基本原则，是随着我们获得越来越多的数据或证据，更新和改善我们对现实的知识。</p><p id="34cd" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated"><strong class="kw iu">这可以用一个非常简单的例子来说明。</strong>想象以下情景:你在边上方形的花园里，坐在椅子上，看着花园外面。在对面，躺着一个仆人，他把一个蓝色的球扔进了正方形。在那之后，他继续在方块内投掷其他黄色球，并告诉你它们相对于最初的蓝色球落在哪里。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi oq"><img src="../Images/715ca6813e690ef5e85e58b991e9b895.png" data-original-src="https://miro.medium.com/v2/resize:fit:1200/1*M83W1qqTkKWvuop5cac_4Q.gif"/></div><figcaption class="oa ob gj gh gi oc od bd b be z dk">Video of this mental experiment with our good old Bayes sitting on the edge of his garden with his back towards a servant that is throwing the balls.</figcaption></figure><p id="4fe5" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">随着越来越多的黄球落地，你得到了它们相对于第一个蓝球落地的位置的信息，你逐渐增加了关于蓝球可能在哪里的知识，忽略了花园的某些部分:<strong class="kw iu">随着我们获得更多的证据(更多的黄球)，我们更新了我们的知识(蓝球的位置)。</strong></p><p id="c752" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">在上面的例子中，<strong class="kw iu">只扔了 3 个黄色的球</strong>，我们已经可以开始建立一个确定的想法，蓝色的球位于花园左上角的某个地方。</p><p id="aa75" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">当贝氏第一次公式化这个定理时，<strong class="kw iu">他起初没有发表，认为这没什么了不起，</strong>而公式化这个定理的论文是在他死后才被发现的。</p><p id="2b20" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">今天，贝叶斯定理不仅是现代概率的基础之一，而且是许多智能系统中高度使用的工具，如垃圾邮件过滤器和许多其他文本和非文本相关的问题解决程序。</p><p id="0626" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">在接下来的文章中，我们将看到<strong class="kw iu">这些应用是什么</strong>，以及贝叶斯定理及其变体如何应用于许多现实世界的用例。来看看<a class="ae md" href="https://medium.com/@jaimezornoza" rel="noopener"> <strong class="kw iu">跟我上媒</strong> </a>，敬请期待！</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi or"><img src="../Images/30fd77b071e5df6dced55e395e40585e.png" data-original-src="https://miro.medium.com/v2/resize:fit:806/format:webp/1*5-rteZSOFol3RgVi2t66wg.png"/></div></figure><p id="775d" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">想了解更多关于概率和统计的资料，请点击下面的<a class="ae md" href="https://howtolearnmachinelearning.com/online-courses/statistics-and-probability-courses/" rel="noopener ugc nofollow" target="_blank">最佳在线课程</a>来了解这个精彩的话题！</p><p id="95fb" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">就这些，我希望你喜欢这个帖子。请随时在<a class="ae md" href="https://www.linkedin.com/in/jaime-zornoza/" rel="noopener ugc nofollow" target="_blank"> LinkedIn </a>上与我联系，或者在<strong class="kw iu"> @jaimezorno </strong>的 Twitter 上关注我。还有，你可以看看我其他关于数据科学和机器学习的帖子<strong class="kw iu"> </strong> <a class="ae md" href="https://medium.com/@jaimezornoza" rel="noopener"> <strong class="kw iu">这里</strong> </a>。好好读！</p></div></div>    
</body>
</html>