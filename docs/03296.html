<html>
<head>
<title>Dracarys!— Use Docker Machine, PyTorch &amp; Gigantum for Portable &amp; Reproducible GPU Workflows</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">德卡里斯。—使用 Docker Machine、PyTorch 和 Gigantum 实现可移植和可再现的 GPU 工作流</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/dracarys-use-docker-machine-pytorch-gigantum-for-portable-reproducible-gpu-workflows-481ca2632bbb?source=collection_archive---------15-----------------------#2019-05-26">https://towardsdatascience.com/dracarys-use-docker-machine-pytorch-gigantum-for-portable-reproducible-gpu-workflows-481ca2632bbb?source=collection_archive---------15-----------------------#2019-05-26</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><figure class="gl gn jo jp jq jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi jn"><img src="../Images/4c960b2811ec505c1e680b00415ca5e5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*yzN3LzTZwa7uUn1TOnX5bA.jpeg"/></div></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk"><a class="ae kc" href="https://commons.wikimedia.org/w/index.php?curid=4632541" rel="noopener ugc nofollow" target="_blank">CC image By I, Luc Viatour, CC BY-SA 3.0</a></figcaption></figure><h1 id="3745" class="kd ke iq bd kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la bi translated">TL；速度三角形定位法(dead reckoning)</h1><ol class=""><li id="27ad" class="lb lc iq ld b le lf lg lh li lj lk ll lm ln lo lp lq lr ls bi translated">手动创建可移植和可再现的 GPU 工作流是脆弱的、技能密集型的和费力的，即使使用容器也是如此。</li><li id="5f1a" class="lb lc iq ld b le lt lg lu li lv lk lw lm lx lo lp lq lr ls bi translated">幸运的是，你可以使用 Docker Machine、PyTorch &amp; Gigantum 或多或少地实现自动化。</li><li id="a086" class="lb lc iq ld b le lt lg lu li lv lk lw lm lx lo lp lq lr ls bi translated">我们用这三样东西来展示一个强大的系统，以创建在笔记本电脑和云、CPU 和 GPU 之间无缝移动的工作流。</li></ol><h2 id="112c" class="ly ke iq bd kf lz ma dn kj mb mc dp kn li md me kr lk mf mg kv lm mh mi kz mj bi translated"><strong class="ak">假设</strong> —你应该有:</h2><ol class=""><li id="e49b" class="lb lc iq ld b le lf lg lh li lj lk ll lm ln lo lp lq lr ls bi translated">使用 Bash(在 Linux/macOS 上)或 PowerShell(在 Windows 上)的经验。</li><li id="94be" class="lb lc iq ld b le lt lg lu li lv lk lw lm lx lo lp lq lr ls bi translated">Docker CE 安装在本地。</li><li id="ec44" class="lb lc iq ld b le lt lg lu li lv lk lw lm lx lo lp lq lr ls bi translated">AWS 凭证&amp; EC2 GPU 实例的足够权限。</li></ol><p id="238f" class="pw-post-body-paragraph mk ml iq ld b le mm mn mo lg mp mq mr li ms mt mu lk mv mw mx lm my mz na lo ij bi translated">如果达不到这些要求，也不要绝望。你可以通过一些背景阅读和一些剪切粘贴来快速阅读这篇文章。</p><p id="5546" class="pw-post-body-paragraph mk ml iq ld b le mm mn mo lg mp mq mr li ms mt mu lk mv mw mx lm my mz na lo ij bi translated"><strong class="ld ir"> <em class="nb">剧透预警</em></strong>——完成这篇帖子所用的时间将远远少于《GoT》第五集丹妮莉丝·坦格利安烧毁君临所需的时间。</p><h1 id="fd2f" class="kd ke iq bd kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la bi translated">介绍</h1><p id="f9a9" class="pw-post-body-paragraph mk ml iq ld b le lf mn mo lg lh mq mr li nc mt mu lk nd mw mx lm ne mz na lo ij bi translated">用于并行处理的 GPU 为一些计算提供了令人难以置信的速度提升——最著名的是深度学习。好的图形处理器可以在 CPU 上完成复杂的计算。</p><p id="8551" class="pw-post-body-paragraph mk ml iq ld b le mm mn mo lg mp mq mr li ms mt mu lk mv mw mx lm my mz na lo ij bi translated">不幸的是，安装和配置必要的软件环境需要技能和时间。对于大多数用户来说，访问 GPU 的唯一方式是通过不断增长的平台之一，这些平台提供了进入托管云环境的浏览器界面。这些平台的基本问题是，它们要么是免费的&amp;在计算上毫无价值，要么是功能性的，但似乎是为企业预算量身定制的。</p><p id="d90b" class="pw-post-body-paragraph mk ml iq ld b le mm mn mo lg mp mq mr li ms mt mu lk mv mw mx lm my mz na lo ij bi translated">获得更广泛访问的一个途径是通过最大限度地减少设置所需的技能和时间，让人们能够自己做事情。另一种方法是使 GPU 工作流<em class="nb">可移植</em>，即自包含&amp;易于跨各种资源运行。例如，促进 CPU &amp; GPU 机器之间的移动使得能够在更便宜的 CPU 上测试&amp;调试，从而节省昂贵的 GPU 用于实际计算。在这篇文章中，我们将做这两件事。</p><p id="6b8b" class="pw-post-body-paragraph mk ml iq ld b le mm mn mo lg mp mq mr li ms mt mu lk mv mw mx lm my mz na lo ij bi translated">基本上，当谈到轻松复制和便携式 GPU 笔记本电脑时，我们会给你自己的龙。</p><p id="fd38" class="pw-post-body-paragraph mk ml iq ld b le mm mn mo lg mp mq mr li ms mt mu lk mv mw mx lm my mz na lo ij bi translated"><strong class="ld ir">我们使用的工具</strong></p><p id="6017" class="pw-post-body-paragraph mk ml iq ld b le mm mn mo lg mp mq mr li ms mt mu lk mv mw mx lm my mz na lo ij bi translated"><a class="ae kc" href="https://docs.docker.com/machine/get-started-cloud/" rel="noopener ugc nofollow" target="_blank"><em class="nb">Docker Machine</em></a>是一个简单的 Apache 许可命令行工具，用于供应、配置&amp;管理远程虚拟环境。</p><p id="bebb" class="pw-post-body-paragraph mk ml iq ld b le mm mn mo lg mp mq mr li ms mt mu lk mv mw mx lm my mz na lo ij bi translated"><a class="ae kc" href="https://pytorch.org/" rel="noopener ugc nofollow" target="_blank"> <em class="nb"> PyTorch </em> </a>是一个 BSD 授权的深度学习框架，可以轻松在 CPU 和 GPU 之间切换进行计算。</p><p id="c691" class="pw-post-body-paragraph mk ml iq ld b le mm mn mo lg mp mq mr li ms mt mu lk mv mw mx lm my mz na lo ij bi translated"><a class="ae kc" href="https://gigantum.com" rel="noopener ugc nofollow" target="_blank"> <em class="nb"> Gigantum </em> </a>是一个<a class="ae kc" href="https://github.com/gigantum/gigantum-client" rel="noopener ugc nofollow" target="_blank">麻省理工学院许可的</a>本地应用程序，它与云服务配对，以创建任何人都可以轻松使用的可复制工作流<em class="nb">。</em></p><p id="8abb" class="pw-post-body-paragraph mk ml iq ld b le mm mn mo lg mp mq mr li ms mt mu lk mv mw mx lm my mz na lo ij bi translated">我们的存在性证明有三个部分:</p><ol class=""><li id="8ec0" class="lb lc iq ld b le mm lg mp li nf lk ng lm nh lo lp lq lr ls bi translated">用 Docker Machine 创建 EC2 GPU 实例的简单过程:</li><li id="ddf3" class="lb lc iq ld b le lt lg lu li lv lk lw lm lx lo lp lq lr ls bi translated">从 Bash 提示符配置实例；</li><li id="e786" class="lb lc iq ld b le lt lg lu li lv lk lw lm lx lo lp lq lr ls bi translated">只需点击几下鼠标，即可导入和运行 PyTorch 迁移学习笔记本。</li></ol><p id="f5ab" class="pw-post-body-paragraph mk ml iq ld b le mm mn mo lg mp mq mr li ms mt mu lk mv mw mx lm my mz na lo ij bi translated"><strong class="ld ir">在我们开始</strong>之前——为了使这篇文章对不同的用户都是可靠的，我们在过程的确定性方面犯了错误&amp;工具的简单性。</p><h1 id="558c" class="kd ke iq bd kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la bi translated">第 1 部分—创建一个 EC2 p2.xlarge 实例</h1><p id="2282" class="pw-post-body-paragraph mk ml iq ld b le lf mn mo lg lh mq mr li nc mt mu lk nd mw mx lm ne mz na lo ij bi translated">我们开始吧。</p><p id="2fa9" class="pw-post-body-paragraph mk ml iq ld b le mm mn mo lg mp mq mr li ms mt mu lk mv mw mx lm my mz na lo ij bi translated">第 1 步到第 3 步是一次性步骤，但是第 4 步中的 Docker Machine 命令是您随时可以用来创建新遥控器的命令。</p><p id="be22" class="pw-post-body-paragraph mk ml iq ld b le mm mn mo lg mp mq mr li ms mt mu lk mv mw mx lm my mz na lo ij bi translated">如果您以前没有使用过，Docker Machine 是一个简单的工具，可以在远程主机上轻松安装、管理和连接 Docker。方便的是，它可以自动发送和简单的端口转发。可以了解一下<a class="ae kc" href="https://docs.docker.com/machine/overview/" rel="noopener ugc nofollow" target="_blank">这里</a> &amp; <a class="ae kc" href="https://dev.to/zac_siegel/using-docker-machine-to-provision-a-remote-docker-host-1267" rel="noopener ugc nofollow" target="_blank">这里</a>。</p><p id="85cc" class="pw-post-body-paragraph mk ml iq ld b le mm mn mo lg mp mq mr li ms mt mu lk mv mw mx lm my mz na lo ij bi translated"><strong class="ld ir">第 1 步— </strong> <em class="nb">验证 Docker CE &amp;是否正在运行</em>。</p><p id="db7a" class="pw-post-body-paragraph mk ml iq ld b le mm mn mo lg mp mq mr li ms mt mu lk mv mw mx lm my mz na lo ij bi translated">在终端(Bash 或 PowerShell)中，运行:</p><pre class="ni nj nk nl gt nm nn no np aw nq bi"><span id="2c74" class="ly ke iq nn b gy nr ns l nt nu">docker version</span></pre><p id="fa51" class="pw-post-body-paragraph mk ml iq ld b le mm mn mo lg mp mq mr li ms mt mu lk mv mw mx lm my mz na lo ij bi translated">您必须在本地运行 Docker CE。如果你没有一个相当<a class="ae kc" href="https://docs.docker.com/engine/release-notes/" rel="noopener ugc nofollow" target="_blank">最近的版本</a>，你可能想要更新它。<em class="nb">注意:你不能使用 Docker 工具箱</em>。</p><p id="6774" class="pw-post-body-paragraph mk ml iq ld b le mm mn mo lg mp mq mr li ms mt mu lk mv mw mx lm my mz na lo ij bi translated"><strong class="ld ir">第二步(仅限 Linux 用户)——</strong><em class="nb">没有 Docker 机器就安装</em>。</p><p id="73eb" class="pw-post-body-paragraph mk ml iq ld b le mm mn mo lg mp mq mr li ms mt mu lk mv mw mx lm my mz na lo ij bi translated">Docker for Linux 的发行版通常不包含 Docker Machine(但 macOS &amp; Windows 包含)。要解决这个问题，请在 Bash 终端中运行以下命令:</p><pre class="ni nj nk nl gt nm nn no np aw nq bi"><span id="6192" class="ly ke iq nn b gy nr ns l nt nu">base=<!-- -->https://github.com/docker/machine/releases/download/v0.16.0 </span><span id="cbe2" class="ly ke iq nn b gy nv ns l nt nu">curl -L $base/docker-machine-$(uname -s)-$(uname -m) &gt; /tmp/docker-machine</span><span id="bbd3" class="ly ke iq nn b gy nv ns l nt nu">sudo install /tmp/docker-machine /usr/local/bin/docker-machine</span></pre><blockquote class="nw nx ny"><p id="ca50" class="mk ml nb ld b le mm mn mo lg mp mq mr nz ms mt mu oa mv mw mx ob my mz na lo ij bi translated">然后，注销&amp;登录——确保 docker-machine 在您的路径上。</p></blockquote><p id="08c2" class="pw-post-body-paragraph mk ml iq ld b le mm mn mo lg mp mq mr li ms mt mu lk mv mw mx lm my mz na lo ij bi translated"><strong class="ld ir">步骤 3 — </strong> <em class="nb">为 CLI </em>配置 AWS API 凭证。</p><p id="ee95" class="pw-post-body-paragraph mk ml iq ld b le mm mn mo lg mp mq mr li ms mt mu lk mv mw mx lm my mz na lo ij bi translated">如果您没有凭证，请访问<a class="ae kc" href="https://console.aws.amazon.com/iam/home" rel="noopener ugc nofollow" target="_blank">控制台</a>进行设置。您需要:</p><ol class=""><li id="7f4f" class="lb lc iq ld b le mm lg mp li nf lk ng lm nh lo lp lq lr ls bi translated">您的访问密钥 ID，<em class="nb"> youraccesskey。</em></li><li id="8a2d" class="lb lc iq ld b le lt lg lu li lv lk lw lm lx lo lp lq lr ls bi translated">您的秘密访问密钥:<em class="nb"> yoursecretkey </em>。</li></ol><p id="7a99" class="pw-post-body-paragraph mk ml iq ld b le mm mn mo lg mp mq mr li ms mt mu lk mv mw mx lm my mz na lo ij bi translated">确保将您的 AWS CLI 配置为自动调用凭证供<a class="ae kc" href="https://docs.aws.amazon.com/cli/latest/userguide/cli-chap-configure.html" rel="noopener ugc nofollow" target="_blank">命令行</a>使用，否则您需要将它们添加到下面的 Docker 机器命令中。</p><p id="9791" class="pw-post-body-paragraph mk ml iq ld b le mm mn mo lg mp mq mr li ms mt mu lk mv mw mx lm my mz na lo ij bi translated">在终端中，运行:</p><pre class="ni nj nk nl gt nm nn no np aw nq bi"><span id="3826" class="ly ke iq nn b gy nr ns l nt nu">aws configure<br/>AWS Access Key ID [None]: <strong class="nn ir"><em class="nb">youraccesskey</em></strong> <br/>AWS Secret Access Key [None]: <strong class="nn ir"><em class="nb">yoursecretkey</em></strong> <br/>Default region name [None]: <br/>Default output format [None]: </span></pre><p id="a232" class="pw-post-body-paragraph mk ml iq ld b le mm mn mo lg mp mq mr li ms mt mu lk mv mw mx lm my mz na lo ij bi translated"><strong class="ld ir">步骤 4 </strong> — <em class="nb">使用 Docker Machine </em>创建实例。</p><p id="5905" class="pw-post-body-paragraph mk ml iq ld b le mm mn mo lg mp mq mr li ms mt mu lk mv mw mx lm my mz na lo ij bi translated">现在可以使用一个 Docker Machine 命令(带有多个参数)来设置 p2.xlarge 实例。</p><p id="4578" class="pw-post-body-paragraph mk ml iq ld b le mm mn mo lg mp mq mr li ms mt mu lk mv mw mx lm my mz na lo ij bi translated"><em class="nb">(在 Linux 或 Mac 上)</em>在 Bash 终端中输入以下命令</p><pre class="ni nj nk nl gt nm nn no np aw nq bi"><span id="21a6" class="ly ke iq nn b gy nr ns l nt nu">docker-machine create --driver amazonec2\<br/>--amazonec2-ami<strong class="nn ir"> </strong>ami-0a313d6098716f372 \<br/>--amazonec2-instance-type p2.xlarge \<br/>--amazonec2-region us-east-1 \<br/>--amazonec2-root-size 64 \<br/>gigantum-gpu</span></pre><p id="4ffd" class="pw-post-body-paragraph mk ml iq ld b le mm mn mo lg mp mq mr li ms mt mu lk mv mw mx lm my mz na lo ij bi translated"><em class="nb">(在 Windows 上)</em>在 PowerShell 终端中输入以下命令</p><pre class="ni nj nk nl gt nm nn no np aw nq bi"><span id="9210" class="ly ke iq nn b gy nr ns l nt nu">docker-machine create --driver amazonec2 `<br/> --amazonec2-ami<strong class="nn ir"> </strong>ami-0a313d6098716f372 `<br/> --amazonec2-instance-type p2.xlarge `<br/> --amazonec2-region us-east-1 `<br/> --amazonec2-root-size 64 `<br/> gigantum-gpu</span></pre><figure class="ni nj nk nl gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi oc"><img src="../Images/b387f42f934b00d073487a8a12d2e733.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/1*tG3_E4KIZC7w-xDD_WuWQw.gif"/></div></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk">Pasting and executing the commands for Windows PowerShell is pretty simple.</figcaption></figure><p id="9575" class="pw-post-body-paragraph mk ml iq ld b le mm mn mo lg mp mq mr li ms mt mu lk mv mw mx lm my mz na lo ij bi translated"><strong class="ld ir">如果这次成功了</strong> —恭喜！您已经设置了实例。</p><p id="2eec" class="pw-post-body-paragraph mk ml iq ld b le mm mn mo lg mp mq mr li ms mt mu lk mv mw mx lm my mz na lo ij bi translated">如果没有成功——原因可能很简单。</p><ul class=""><li id="7c09" class="lb lc iq ld b le mm lg mp li nf lk ng lm nh lo od lq lr ls bi translated">你的一把钥匙错了。纠正一下。</li><li id="b63e" class="lb lc iq ld b le lt lg lu li lv lk lw lm lx lo od lq lr ls bi translated">您没有足够的权限创建实例。纠正这一点，并确保从亚马逊请求访问一个<code class="fe oe of og nn b">p2.xlarge</code>。</li><li id="4202" class="lb lc iq ld b le lt lg lu li lv lk lw lm lx lo od lq lr ls bi translated">(Windows)Docker 有问题。重新启动 Docker，然后再次尝试 Docker Machine 命令。</li></ul><h2 id="59b4" class="ly ke iq bd kf lz ma dn kj mb mc dp kn li md me kr lk mf mg kv lm mh mi kz mj bi translated">用 Docker 机器管理遥控器</h2><ul class=""><li id="56f6" class="lb lc iq ld b le lf lg lh li lj lk ll lm ln lo od lq lr ls bi translated">用<code class="fe oe of og nn b">docker-machine ls</code>检查正在运行什么。</li><li id="f425" class="lb lc iq ld b le lt lg lu li lv lk lw lm lx lo od lq lr ls bi translated">用<code class="fe oe of og nn b">docker-machine start gigantum-gpu</code>开始实例。</li><li id="aae4" class="lb lc iq ld b le lt lg lu li lv lk lw lm lx lo od lq lr ls bi translated">用<code class="fe oe of og nn b">docker-machine restart gigantum-gpu</code>重启实例。</li><li id="d43e" class="lb lc iq ld b le lt lg lu li lv lk lw lm lx lo od lq lr ls bi translated">用<code class="fe oe of og nn b">docker-machine stop gigantum-gpu</code>停止实例。</li><li id="33b4" class="lb lc iq ld b le lt lg lu li lv lk lw lm lx lo od lq lr ls bi translated">用<code class="fe oe of og nn b">docker-machine ssh gigantum-gpu</code>SSH 进入实例。</li></ul><h2 id="b350" class="ly ke iq bd kf lz ma dn kj mb mc dp kn li md me kr lk mf mg kv lm mh mi kz mj bi translated"><strong class="ak">不是受益人</strong></h2><p id="1cf3" class="pw-post-body-paragraph mk ml iq ld b le lf mn mo lg lh mq mr li nc mt mu lk nd mw mx lm ne mz na lo ij bi translated">删除实例时要小心。这个命令很简单，<code class="fe oe of og nn b">docker-machine rm gigantum-gpu</code>，但是有两个潜在的问题。</p><p id="411f" class="pw-post-body-paragraph mk ml iq ld b le mm mn mo lg mp mq mr li ms mt mu lk mv mw mx lm my mz na lo ij bi translated"><em class="nb">第一个</em>——是永久的。你将会失去一切。</p><p id="d278" class="pw-post-body-paragraph mk ml iq ld b le mm mn mo lg mp mq mr li ms mt mu lk mv mw mx lm my mz na lo ij bi translated"><em class="nb">第二个</em>——在停止实例之前删除实例<em class="nb">可能不会实际关闭实例</em>。它可能仍在运行&amp;你不会知道，直到你去控制台。</p><blockquote class="oh"><p id="1405" class="oi oj iq bd ok ol om on oo op oq lo dk translated">有意识、有目的地删除实例。在删除实例之前，请始终停止该实例。</p></blockquote><h1 id="372f" class="kd ke iq bd kf kg kh ki kj kk kl km kn ko or kq kr ks os ku kv kw ot ky kz la bi translated"><strong class="ak">第 2 部分—在 GPU 实例上安装软件</strong></h1><p id="3fda" class="pw-post-body-paragraph mk ml iq ld b le lf mn mo lg lh mq mr li nc mt mu lk nd mw mx lm ne mz na lo ij bi translated">好的。现在结束了，让我们再走 5 步。你只需要做一次。</p><p id="8688" class="pw-post-body-paragraph mk ml iq ld b le mm mn mo lg mp mq mr li ms mt mu lk mv mw mx lm my mz na lo ij bi translated">准备好了吗？</p><p id="6993" class="pw-post-body-paragraph mk ml iq ld b le mm mn mo lg mp mq mr li ms mt mu lk mv mw mx lm my mz na lo ij bi translated"><strong class="ld ir">第一步</strong> — <em class="nb">登录遥控器</em>。</p><pre class="ni nj nk nl gt nm nn no np aw nq bi"><span id="d850" class="ly ke iq nn b gy nr ns l nt nu">docker-machine ssh gigantum-gpu</span></pre><figure class="ni nj nk nl gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi ou"><img src="../Images/d11c59c362deaf14f390b581e8bee2a2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*yFBxibphL52M8T_yTmRTqw.png"/></div></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk">Docker Machine completely automates the SSH process. No more secrets. No more putty.</figcaption></figure><p id="489b" class="pw-post-body-paragraph mk ml iq ld b le mm mn mo lg mp mq mr li ms mt mu lk mv mw mx lm my mz na lo ij bi translated">除非我们另外告诉你，否则你是在远程的 Bash 终端中。</p><p id="d2b4" class="pw-post-body-paragraph mk ml iq ld b le mm mn mo lg mp mq mr li ms mt mu lk mv mw mx lm my mz na lo ij bi translated"><strong class="ld ir">第二步</strong> — <em class="nb">将你的用户添加到 docker 组，添加显卡驱动 ppa，&amp;安装 Nvidia GPU 驱动</em>。</p><pre class="ni nj nk nl gt nm nn no np aw nq bi"><span id="23ae" class="ly ke iq nn b gy nr ns l nt nu">sudo usermod -aG docker $USER<br/>sudo add-apt-repository -y ppa:graphics-drivers/ppa</span></pre><p id="6fbc" class="pw-post-body-paragraph mk ml iq ld b le mm mn mo lg mp mq mr li ms mt mu lk mv mw mx lm my mz na lo ij bi translated">然后</p><p id="610d" class="pw-post-body-paragraph mk ml iq ld b le mm mn mo lg mp mq mr li ms mt mu lk mv mw mx lm my mz na lo ij bi translated"><code class="fe oe of og nn b">sudo apt-get install -y linux-aws nvidia-headless-430 nvidia-utils-430</code></p><p id="396f" class="pw-post-body-paragraph mk ml iq ld b le mm mn mo lg mp mq mr li ms mt mu lk mv mw mx lm my mz na lo ij bi translated">将出现一个菜单。默认设置是保留当前的本地版本。不要。</p><p id="2a34" class="pw-post-body-paragraph mk ml iq ld b le mm mn mo lg mp mq mr li ms mt mu lk mv mw mx lm my mz na lo ij bi translated">选择<code class="fe oe of og nn b">Install the package maintainer's version</code>并点击回车。</p><figure class="ni nj nk nl gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi ov"><img src="../Images/cba6ed383f2a49a94a9fde8115fa53ed.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*NC1Lg02eC7SUODNapMkS5g.png"/></div></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk">You will see this menu. Install the package maintainer’s version, although it doesn’t matter much how you answer.</figcaption></figure><p id="b22b" class="pw-post-body-paragraph mk ml iq ld b le mm mn mo lg mp mq mr li ms mt mu lk mv mw mx lm my mz na lo ij bi translated"><strong class="ld ir">步骤 3 </strong> — <em class="nb">安装 Nvidia Docker 驱动，然后注销并重启实例</em>。</p><pre class="ni nj nk nl gt nm nn no np aw nq bi"><span id="f7d2" class="ly ke iq nn b gy nr ns l nt nu">curl -s -L https://nvidia.github.io/nvidia-docker/gpgkey | \<br/> sudo apt-key add -<br/>distribution=$(. /etc/os-release;echo $ID$VERSION_ID)<br/>curl -s -L https://nvidia.github.io/nvidia-docker/$distribution/nvidia-docker.list | \<br/> sudo tee /etc/apt/sources.list.d/nvidia-docker.list</span></pre><p id="4de8" class="pw-post-body-paragraph mk ml iq ld b le mm mn mo lg mp mq mr li ms mt mu lk mv mw mx lm my mz na lo ij bi translated">然后</p><pre class="ni nj nk nl gt nm nn no np aw nq bi"><span id="89fe" class="ly ke iq nn b gy nr ns l nt nu">sudo apt-get update<br/>sudo apt-get install -y nvidia-docker2</span></pre><p id="9ee5" class="pw-post-body-paragraph mk ml iq ld b le mm mn mo lg mp mq mr li ms mt mu lk mv mw mx lm my mz na lo ij bi translated">通过从<strong class="ld ir">本地</strong>终端输入<code class="fe oe of og nn b">ctrl+d</code>、&amp;来注销，并使用</p><pre class="ni nj nk nl gt nm nn no np aw nq bi"><span id="4053" class="ly ke iq nn b gy nr ns l nt nu">docker-machine restart gigantum-gpu</span></pre><p id="bb66" class="pw-post-body-paragraph mk ml iq ld b le mm mn mo lg mp mq mr li ms mt mu lk mv mw mx lm my mz na lo ij bi translated"><strong class="ld ir">第四步</strong> — <em class="nb">登录，安装 Gigantum，注销&amp;然后停止实例</em>。</p><p id="ba82" class="pw-post-body-paragraph mk ml iq ld b le mm mn mo lg mp mq mr li ms mt mu lk mv mw mx lm my mz na lo ij bi translated">通过在<strong class="ld ir">本地</strong>终端输入以下内容登录:</p><pre class="ni nj nk nl gt nm nn no np aw nq bi"><span id="038d" class="ly ke iq nn b gy nr ns l nt nu">docker-machine ssh gigantum-gpu</span></pre><p id="4a6c" class="pw-post-body-paragraph mk ml iq ld b le mm mn mo lg mp mq mr li ms mt mu lk mv mw mx lm my mz na lo ij bi translated">然后，在远程运行的 Bash 提示符下:</p><pre class="ni nj nk nl gt nm nn no np aw nq bi"><span id="533f" class="ly ke iq nn b gy nr ns l nt nu">sudo apt-get install -y python3-pip<br/>pip3 install --user gigantum</span></pre><p id="530a" class="pw-post-body-paragraph mk ml iq ld b le mm mn mo lg mp mq mr li ms mt mu lk mv mw mx lm my mz na lo ij bi translated">现在，通过输入<code class="fe oe of og nn b">ctrl+d</code> &amp;退出，然后使用以下命令从<strong class="ld ir">本地</strong>终端重新登录:</p><pre class="ni nj nk nl gt nm nn no np aw nq bi"><span id="0968" class="ly ke iq nn b gy nr ns l nt nu">docker-machine ssh gigantum-gpu</span></pre><p id="0431" class="pw-post-body-paragraph mk ml iq ld b le mm mn mo lg mp mq mr li ms mt mu lk mv mw mx lm my mz na lo ij bi translated">然后</p><pre class="ni nj nk nl gt nm nn no np aw nq bi"><span id="5aa0" class="ly ke iq nn b gy nr ns l nt nu">gigantum install</span></pre><p id="8251" class="pw-post-body-paragraph mk ml iq ld b le mm mn mo lg mp mq mr li ms mt mu lk mv mw mx lm my mz na lo ij bi translated">最后，用<code class="fe oe of og nn b">ctrl+d</code> &amp;退出，然后从<strong class="ld ir">本地</strong>终端用以下命令停止:</p><pre class="ni nj nk nl gt nm nn no np aw nq bi"><span id="b2fb" class="ly ke iq nn b gy nr ns l nt nu">docker-machine stop gigantum-gpu</span></pre><p id="ccab" class="pw-post-body-paragraph mk ml iq ld b le mm mn mo lg mp mq mr li ms mt mu lk mv mw mx lm my mz na lo ij bi translated"><strong class="ld ir">第五步</strong> — T <em class="nb">休息一下，伸伸腿，稍微反思一下</em>。</p><p id="960a" class="pw-post-body-paragraph mk ml iq ld b le mm mn mo lg mp mq mr li ms mt mu lk mv mw mx lm my mz na lo ij bi translated">当你休息的时候，回想一下刚刚发生的事情。你的努力换来了什么？</p><ol class=""><li id="9f54" class="lb lc iq ld b le mm lg mp li nf lk ng lm nh lo lp lq lr ls bi translated">在很短的时间内&amp;使用相对较少的命令，您就可以设置最便宜的 EC2 GPU 实例并为容器化的 GPU 工作流安装软件。</li><li id="232f" class="lb lc iq ld b le lt lg lu li lv lk lw lm lx lo lp lq lr ls bi translated">您可以通过启动实例并使用 Docker Machine 登录来随时访问它。以上是一次性设置！</li></ol><blockquote class="oh"><p id="a43d" class="oi oj iq bd ok ol ow ox oy oz pa lo dk translated">最后，请记住，如果您不停止实例，Amazon 将向您收取计算时间费用。此外，它还连接了 64 GB 的 EBS 存储。如果你不删除它，即使它被停止，你也会产生(相对较小的)费用。</p></blockquote><h1 id="9bae" class="kd ke iq bd kf kg kh ki kj kk kl km kn ko or kq kr ks os ku kv kw ot ky kz la bi translated"><strong class="ak">第 4 部分—运行 PyTorch GPU 工作流</strong></h1><p id="3244" class="pw-post-body-paragraph mk ml iq ld b le lf mn mo lg lh mq mr li nc mt mu lk nd mw mx lm ne mz na lo ij bi translated">好的。让我们开始讨论最后 20 分钟的要点。</p><p id="34ca" class="pw-post-body-paragraph mk ml iq ld b le mm mn mo lg mp mq mr li ms mt mu lk mv mw mx lm my mz na lo ij bi translated">我们将<em class="nb">轻松地</em>在 GPU 实例上运行 CPU/GPU 不可知的&amp;可再现 PyTorch 笔记本。笔记本改编自<a class="ae kc" href="https://pytorch.org/tutorials/beginner/transfer_learning_tutorial.html" rel="noopener ugc nofollow" target="_blank">Sasank Chilamkurthy</a>的转学教程。举例说明了 CPU/GPU 便携笔记本的最佳实践和两种迁移学习思路:<em class="nb">微调</em> &amp; <em class="nb">特征提取</em>。</p><h2 id="4194" class="ly ke iq bd kf lz ma dn kj mb mc dp kn li md me kr lk mf mg kv lm mh mi kz mj bi translated">导入和检查 PyTorch 项目</h2><p id="312c" class="pw-post-body-paragraph mk ml iq ld b le lf mn mo lg lh mq mr li nc mt mu lk nd mw mx lm ne mz na lo ij bi translated">对于下一部分，只有三个命令。其余的在浏览器中。</p><ol class=""><li id="9869" class="lb lc iq ld b le mm lg mp li nf lk ng lm nh lo lp lq lr ls bi translated"><code class="fe oe of og nn b">docker-machine start gigantum-gpu</code></li><li id="4368" class="lb lc iq ld b le lt lg lu li lv lk lw lm lx lo lp lq lr ls bi translated"><code class="fe oe of og nn b">docker-machine ssh gigantum-gpu -L 10000:localhost:10000</code></li><li id="6363" class="lb lc iq ld b le lt lg lu li lv lk lw lm lx lo lp lq lr ls bi translated"><code class="fe oe of og nn b">gigantum start --wait 60</code></li></ol><p id="fc7d" class="pw-post-body-paragraph mk ml iq ld b le mm mn mo lg mp mq mr li ms mt mu lk mv mw mx lm my mz na lo ij bi translated">对于 Gigantum 和 Jupyter 的工作，我们不会列出另一个步骤序列，我们将只显示一个过程的视频(加速)。</p><p id="2b88" class="pw-post-body-paragraph mk ml iq ld b le mm mn mo lg mp mq mr li ms mt mu lk mv mw mx lm my mz na lo ij bi translated">可以使用以下 URL 导入迁移学习项目:</p><blockquote class="nw nx ny"><p id="9781" class="mk ml nb ld b le mm mn mo lg mp mq mr nz ms mt mu oa mv mw mx ob my mz na lo ij bi translated"><code class="fe oe of og nn b"><a class="ae kc" href="https://gigantum.com/tinydav/pytorch-transfer-learning" rel="noopener ugc nofollow" target="_blank"><em class="iq">https://gigantum.com/tinydav/simple-pytorch-transfer-learning</em></a></code></p></blockquote><figure class="ni nj nk nl gt jr"><div class="bz fp l di"><div class="pb pc l"/></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk">From start to finish, this takes a total of 7 minutes in real time.</figcaption></figure><p id="2af6" class="pw-post-body-paragraph mk ml iq ld b le mm mn mo lg mp mq mr li ms mt mu lk mv mw mx lm my mz na lo ij bi translated">该视频应该是不言自明的，但我们可以解开它一点。</p><ol class=""><li id="ea11" class="lb lc iq ld b le mm lg mp li nf lk ng lm nh lo lp lq lr ls bi translated">登录应用程序后，运行 PyTorch 笔记本所需的一切都作为代码、数据和环境的存储库导入。</li><li id="e7e6" class="lb lc iq ld b le lt lg lu li lv lk lw lm lx lo lp lq lr ls bi translated">自动构建一个包含运行笔记本的环境的容器。</li><li id="05af" class="lb lc iq ld b le lt lg lu li lv lk lw lm lx lo lp lq lr ls bi translated">在构建容器时，我们查看活动和环境的信息。</li><li id="77b9" class="lb lc iq ld b le lt lg lu li lv lk lw lm lx lo lp lq lr ls bi translated">构建完成后，单击 Code 选项卡中的文件名会在另一个选项卡中启动 JupyterLab。如果没有，你可能已经安装了弹出窗口拦截器。</li><li id="b5ae" class="lb lc iq ld b le lt lg lu li lv lk lw lm lx lo lp lq lr ls bi translated">笔记本运行在 GPU 上。</li></ol><p id="2c0a" class="pw-post-body-paragraph mk ml iq ld b le mm mn mo lg mp mq mr li ms mt mu lk mv mw mx lm my mz na lo ij bi translated">非常简单，在 p2.xlarge 上每小时只需 0.90 美元，而不是在 SageMaker 上每小时 1.20 美元。</p><p id="7e48" class="pw-post-body-paragraph mk ml iq ld b le mm mn mo lg mp mq mr li ms mt mu lk mv mw mx lm my mz na lo ij bi translated"><strong class="ld ir">有一点需要注意</strong>——你并不局限于在基于这个实例的 CUDA 10.0 上运行。如果你查看另一个项目<code class="fe oe of og nn b">my-first-project</code>的环境选项卡，你会注意到它<em class="nb">没有</em>的 CUDA 10.0，它有<em class="nb">一套完全不同的包</em>。</p><blockquote class="oh"><p id="7f58" class="oi oj iq bd ok ol om on oo op oq lo dk translated">完成后，请确保执行以下操作:</p></blockquote><ol class=""><li id="2a8d" class="lb lc iq ld b le pd lg pe li pf lk pg lm ph lo lp lq lr ls bi translated">在终端运行<code class="fe oe of og nn b">gigantum stop</code>。</li><li id="bba8" class="lb lc iq ld b le lt lg lu li lv lk lw lm lx lo lp lq lr ls bi translated">用<code class="fe oe of og nn b">ctrl+d</code>退出实例。</li><li id="0f55" class="lb lc iq ld b le lt lg lu li lv lk lw lm lx lo lp lq lr ls bi translated">用<code class="fe oe of og nn b">docker-machine stop gigantum-gpu</code>停止实例。</li></ol><h1 id="6f7c" class="kd ke iq bd kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la bi translated">现在，给读者一个练习</h1><p id="7030" class="pw-post-body-paragraph mk ml iq ld b le lf mn mo lg lh mq mr li nc mt mu lk nd mw mx lm ne mz na lo ij bi translated">您可能还记得，我们说过您可以使用相同的设置在 CPU 上运行笔记本电脑。我们将此作为一个练习留给读者，但我们给出了一个简短的草图，以使它进行得更顺利一些。</p><p id="959b" class="pw-post-body-paragraph mk ml iq ld b le mm mn mo lg mp mq mr li ms mt mu lk mv mw mx lm my mz na lo ij bi translated">按照上面的说明，你可以自己设置一个 CPU 实例，然后运行这个笔记本。如果你有 Docker CE，你可以通过<a class="ae kc" href="https://gigantum.com/download" rel="noopener ugc nofollow" target="_blank">安装 Gigantum </a>在本地完成，或者你可以通过修改上述过程在远程完成。</p><p id="38f3" class="pw-post-body-paragraph mk ml iq ld b le mm mn mo lg mp mq mr li ms mt mu lk mv mw mx lm my mz na lo ij bi translated">这次你不需要安装任何与 Nvidia 相关的软件。事实上，你甚至不需要在 AWS 上这样做，因为 Docker Machine 为其他提供商工作，比如<a class="ae kc" href="https://www.digitalocean.com/community/tutorials/how-to-provision-and-manage-remote-docker-hosts-with-docker-machine-on-ubuntu-16-04" rel="noopener ugc nofollow" target="_blank">数字海洋</a>。你甚至可以用你自己的遥控器来做</p><p id="eba7" class="pw-post-body-paragraph mk ml iq ld b le mm mn mo lg mp mq mr li ms mt mu lk mv mw mx lm my mz na lo ij bi translated">在 CPU EC2 实例上运行该笔记本的基本步骤是:</p><ol class=""><li id="9326" class="lb lc iq ld b le mm lg mp li nf lk ng lm nh lo lp lq lr ls bi translated">使用 Docker Machine 创建一个 t2.xlarge EC2 实例，使用我们为<code class="fe oe of og nn b">gigantum-cpu</code>创建的 AMI。</li><li id="48dd" class="lb lc iq ld b le lt lg lu li lv lk lw lm lx lo lp lq lr ls bi translated">将您的用户添加到 docker 组，安装 pip3，然后安装 Gigantum。</li><li id="27f4" class="lb lc iq ld b le lt lg lu li lv lk lw lm lx lo lp lq lr ls bi translated">请注意，在运行<code class="fe oe of og nn b">gigantum install</code>之前，您需要注销然后重新登录。</li><li id="d264" class="lb lc iq ld b le lt lg lu li lv lk lw lm lx lo lp lq lr ls bi translated">SSH 进入<code class="fe oe of og nn b">gigantum-cpu</code>，做同样的端口转发，启动 Gigantum &amp;然后导入运行笔记本。</li></ol><p id="6b36" class="pw-post-body-paragraph mk ml iq ld b le mm mn mo lg mp mq mr li ms mt mu lk mv mw mx lm my mz na lo ij bi translated">完成后，确保停止<code class="fe oe of og nn b">gigantum-cpu</code>实例。</p><h1 id="da4b" class="kd ke iq bd kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la bi translated">最后 TensorFlow 对 LSTM 笔记本的调侃</h1><p id="3890" class="pw-post-body-paragraph mk ml iq ld b le lf mn mo lg lh mq mr li nc mt mu lk nd mw mx lm ne mz na lo ij bi translated">如果您完成了上面的练习，那么您现在已经有了一个使用 PyTorch 非常容易地运行 CPU/GPU 不可知工作流的系统。其中重要的一点是 PyTorch 可以无缝地为您管理交换机。</p><p id="2b0b" class="pw-post-body-paragraph mk ml iq ld b le mm mn mo lg mp mq mr li ms mt mu lk mv mw mx lm my mz na lo ij bi translated">但是 TensorFlow 呢？它不能以这样一种无缝的方式处理这种切换，但事实证明，您可以使用不同的方法在 CPU 或 GPU 上创建工作流，同样是在 Gigantum 中。</p><p id="3102" class="pw-post-body-paragraph mk ml iq ld b le mm mn mo lg mp mq mr li ms mt mu lk mv mw mx lm my mz na lo ij bi translated">在下一篇文章中，我们将讨论如何使用 Docker Machine、Gigantum &amp; TensorFlow 实现这一点。</p><p id="614e" class="pw-post-body-paragraph mk ml iq ld b le mm mn mo lg mp mq mr li ms mt mu lk mv mw mx lm my mz na lo ij bi translated">但是，如果您愿意，您现在可以使用刚刚配置的 p2.xlarge 自己完成这项工作。<strong class="ld ir">你不需要改变什么</strong>。</p><p id="6974" class="pw-post-body-paragraph mk ml iq ld b le mm mn mo lg mp mq mr li ms mt mu lk mv mw mx lm my mz na lo ij bi translated">你可以使用 https://gigantum.com/dmk/trump-speech-generation 的 LSTM 笔记本<a class="ae kc" href="https://gigantum.com/dmk/trump-speech-generation" rel="noopener ugc nofollow" target="_blank">开始使用。</a></p><figure class="ni nj nk nl gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi pi"><img src="../Images/b2389e541b1e3d8b3305ccb602acccdd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*GnAbbd4eYlmez8t_k9tcMw.png"/></div></div></figure><h2 id="9b33" class="ly ke iq bd kf lz ma dn kj mb mc dp kn li md me kr lk mf mg kv lm mh mi kz mj bi translated">由<a class="ae kc" href="https://twitter.com/davclark" rel="noopener ugc nofollow" target="_blank">Dav Clark</a>(HDS)&amp;<a class="ae kc" href="https://www.linkedin.com/in/tyler-whitehouse-96761127/" rel="noopener ugc nofollow" target="_blank">Tyler white house</a>(Gigantum 的 CEO)撰写。</h2><h2 id="cc37" class="ly ke iq bd kf lz ma dn kj mb mc dp kn li md me kr lk mf mg kv lm mh mi kz mj bi translated">在<a class="ae kc" href="https://twitter.com/gigantumscience" rel="noopener ugc nofollow" target="_blank"> Twitter </a>上关注我们，或者在<a class="ae kc" href="https://spectrum.chat/gigantum" rel="noopener ugc nofollow" target="_blank"> Spectrum </a>上向我们问好！</h2><figure class="ni nj nk nl gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi pi"><img src="../Images/2a9127dcd1cbf6482c03a679bdfa0126.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*SjBxP4fD5Ek3dT-wc19Z4g.png"/></div></div></figure></div></div>    
</body>
</html>