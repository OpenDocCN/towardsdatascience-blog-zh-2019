<html>
<head>
<title>Deep Clustering for Financial Market Segmentation</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">金融市场细分的深度聚类</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/deep-clustering-for-financial-market-segmentation-2a41573618cf?source=collection_archive---------5-----------------------#2019-11-23">https://towardsdatascience.com/deep-clustering-for-financial-market-segmentation-2a41573618cf?source=collection_archive---------5-----------------------#2019-11-23</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="c1e9" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">一种无监督的信用卡客户聚类深度学习方法</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/3a1761354466043ce67e50cff2b762e5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*UsfWKsZJEAVfJyVuSayKAg.jpeg"/></div></div></figure><p id="0910" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated"><a class="ae lq" href="https://en.wikipedia.org/wiki/Unsupervised_learning" rel="noopener ugc nofollow" target="_blank">无监督学习</a>、<a class="ae lq" href="https://en.wikipedia.org/wiki/Supervised_learning" rel="noopener ugc nofollow" target="_blank">监督学习</a>和<a class="ae lq" href="https://en.wikipedia.org/wiki/Reinforcement_learning" rel="noopener ugc nofollow" target="_blank">强化学习</a>是机器学习方法的三大类。无监督学习有许多应用，如聚类、降维等。机器学习算法<a class="ae lq" href="https://en.wikipedia.org/wiki/K-means_clustering" rel="noopener ugc nofollow" target="_blank"> K-means </a>和<a class="ae lq" href="https://en.wikipedia.org/wiki/Principal_component_analysis" rel="noopener ugc nofollow" target="_blank">主成分分析</a> (PCA)分别广泛用于聚类和降维。与 PCA 类似，<a class="ae lq" href="https://en.wikipedia.org/wiki/T-distributed_stochastic_neighbor_embedding" rel="noopener ugc nofollow" target="_blank">T-分布式随机邻居嵌入</a> (t-SNE)是另一种用于维数约简的无监督机器学习算法。t-SNE 通常用于在二维或三维空间中嵌入高维数据以进行数据可视化。</p><p id="3885" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">随着无监督深度学习的发展，<a class="ae lq" href="https://en.wikipedia.org/wiki/Autoencoder" rel="noopener ugc nofollow" target="_blank">自动编码器</a>神经网络现在经常用于高维度(例如，具有数千或更多特征的数据集)的约简。Autoencoder 也可以与监督学习(如随机森林)相结合，形成<a class="ae lq" href="https://en.wikipedia.org/wiki/Semi-supervised_learning" rel="noopener ugc nofollow" target="_blank">半监督学习</a>方法(见<a class="ae lq" href="https://www.nature.com/articles/srep26094" rel="noopener ugc nofollow" target="_blank">深度病人</a>举例)。</p><p id="2e75" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">最近发表了一个<a class="ae lq" href="https://arxiv.org/pdf/1511.06335.pdf" rel="noopener ugc nofollow" target="_blank">深度嵌入聚类</a> (DEC)方法【1】。它将 autoencoder 与 K-means 和其他机器学习技术相结合，用于聚类而不是降维。DEC 的<a class="ae lq" href="https://github.com/piiswrong/dec" rel="noopener ugc nofollow" target="_blank">原实现基于</a><a class="ae lq" href="https://caffe.berkeleyvision.org/" rel="noopener ugc nofollow" target="_blank"> Caffe </a>。在【2】中可以找到<a class="ae lq" href="https://en.wikipedia.org/wiki/MNIST_database" rel="noopener ugc nofollow" target="_blank"> MNIST </a>数据集的<a class="ae lq" href="https://keras.io/" rel="noopener ugc nofollow" target="_blank"> Keras </a>中 DEC 的实现。</p><p id="c855" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">在本文中，与[2]类似，我在 Keras 中实现了 DEC 算法，并使用公共数据集<a class="ae lq" href="https://www.kaggle.com/arjunbhasin2013/ccdata" rel="noopener ugc nofollow" target="_blank"> Kaggle 信用卡数据集进行聚类</a> [3]来展示如何使用新实现的 DEC 模型对信用卡数据集进行聚类以进行客户细分。本文其余部分安排如下:</p><ul class=""><li id="141a" class="lr ls it kw b kx ky la lb ld lt lh lu ll lv lp lw lx ly lz bi translated">数据准备</li><li id="9a27" class="lr ls it kw b kx ma la mb ld mc lh md ll me lp lw lx ly lz bi translated">在 Keras 中实现 DEC 方法</li><li id="9363" class="lr ls it kw b kx ma la mb ld mc lh md ll me lp lw lx ly lz bi translated">摘要</li></ul><h1 id="8e88" class="mf mg it bd mh mi mj mk ml mm mn mo mp jz mq ka mr kc ms kd mt kf mu kg mv mw bi translated">1.数据准备</h1><p id="b4e5" class="pw-post-body-paragraph ku kv it kw b kx mx ju kz la my jx lc ld mz lf lg lh na lj lk ll nb ln lo lp im bi translated">本节描述聚类所需的常见数据预处理步骤。</p><h2 id="614a" class="nc mg it bd mh nd ne dn ml nf ng dp mp ld nh ni mr lh nj nk mt ll nl nm mv nn bi translated">1.1 加载数据</h2><p id="e7ce" class="pw-post-body-paragraph ku kv it kw b kx mx ju kz la my jx lc ld mz lf lg lh na lj lk ll nb ln lo lp im bi translated">将 Kaggle 信用卡数据集[3]下载到本地机器后，可以将其加载到 Pandas 数据框架中，如下所示:</p><pre class="kj kk kl km gt no np nq nr aw ns bi"><span id="bed0" class="nc mg it np b gy nt nu l nv nw">import Pandas as pd<br/>data = pd.read_csv('./data/CC_GENRAL.csv')<br/>data.head()</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nx"><img src="../Images/99547f89b854ab42215a3c0d479f1af8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*pNv3cd3OR4vchwdgs9ncsw.png"/></div></div></figure><h2 id="7fab" class="nc mg it bd mh nd ne dn ml nf ng dp mp ld nh ni mr lh nj nk mt ll nl nm mv nn bi translated">1.2 选择功能</h2><p id="968a" class="pw-post-body-paragraph ku kv it kw b kx mx ju kz la my jx lc ld mz lf lg lh na lj lk ll nb ln lo lp im bi translated">从上面的数据帧可以看出，CUST ID 字段对于每个客户数据记录都是唯一的。具有唯一值的该字段对聚类没有用，因此可以删除:</p><pre class="kj kk kl km gt no np nq nr aw ns bi"><span id="35c9" class="nc mg it np b gy nt nu l nv nw">data_x = data.drop(['CUST_ID'], axis=1)</span></pre><h2 id="6c9a" class="nc mg it bd mh nd ne dn ml nf ng dp mp ld nh ni mr lh nj nk mt ll nl nm mv nn bi translated">1.3 重缩放特征</h2><p id="c816" class="pw-post-body-paragraph ku kv it kw b kx mx ju kz la my jx lc ld mz lf lg lh na lj lk ll nb ln lo lp im bi translated">从数据帧中还可以看出，对于不同的字段/特征，值的范围是非常不同的。众所周知，K-means 对特征值的尺度很敏感，因为它使用欧氏距离作为相似性度量。为了避免这个问题，所有要素的值都被重新调整到[0，1]的范围内:</p><pre class="kj kk kl km gt no np nq nr aw ns bi"><span id="095c" class="nc mg it np b gy nt nu l nv nw">from sklearn.preprocessing import MinMaxScaler<br/>numeric_columns = data_x.columns.values.tolist()<br/>scaler = MinMaxScaler() <br/>data_x[numeric_columns] = scaler.fit_transform(data_x[numeric_columns])<br/>data_x.head()</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ny"><img src="../Images/0a285850ce21971e6b1e3b3f58d33ccb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*zt93WSRFxIddEX5YJ8uspg.png"/></div></div></figure><h2 id="c479" class="nc mg it bd mh nd ne dn ml nf ng dp mp ld nh ni mr lh nj nk mt ll nl nm mv nn bi translated">1.4 处理缺失数据</h2><p id="2a7d" class="pw-post-body-paragraph ku kv it kw b kx mx ju kz la my jx lc ld mz lf lg lh na lj lk ll nb ln lo lp im bi translated">以下代码用于检查数据集中是否存在任何缺失的数据:</p><pre class="kj kk kl km gt no np nq nr aw ns bi"><span id="20f6" class="nc mg it np b gy nt nu l nv nw">data_x.isnull().sum()</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nz"><img src="../Images/a466dc99f21d6fd31a680a06a549b17d.png" data-original-src="https://miro.medium.com/v2/resize:fit:864/format:webp/1*tFau-rQJwcuZVna5nuH9-w.png"/></div></figure><p id="80c2" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">上表显示有一个缺失的信用限额记录和 313 个缺失的最低付款额。在这种情况下，用零填充缺失的数据是有意义的:</p><pre class="kj kk kl km gt no np nq nr aw ns bi"><span id="a595" class="nc mg it np b gy nt nu l nv nw">data_x.fillna(0, inplace=True)</span></pre><h1 id="900b" class="mf mg it bd mh mi mj mk ml mm mn mo mp jz mq ka mr kc ms kd mt kf mu kg mv mw bi translated">2.在 Keras 中实现 DEC 方法</h1><p id="645c" class="pw-post-body-paragraph ku kv it kw b kx mx ju kz la my jx lc ld mz lf lg lh na lj lk ll nb ln lo lp im bi translated">与[2]类似，[1]中的 DEC 算法在本文中用 Keras 实现如下:</p><ul class=""><li id="40fe" class="lr ls it kw b kx ky la lb ld lt lh lu ll lv lp lw lx ly lz bi translated">步骤 1:估计聚类数</li><li id="b403" class="lr ls it kw b kx ma la mb ld mc lh md ll me lp lw lx ly lz bi translated">步骤 2:创建和训练 K 均值模型</li><li id="1ab7" class="lr ls it kw b kx ma la mb ld mc lh md ll me lp lw lx ly lz bi translated">步骤 3:创建和训练自动编码器</li><li id="bcef" class="lr ls it kw b kx ma la mb ld mc lh md ll me lp lw lx ly lz bi translated">步骤 4:实施 DEC 软标签</li><li id="2295" class="lr ls it kw b kx ma la mb ld mc lh md ll me lp lw lx ly lz bi translated">步骤 5:创建一个新的 DEC 模型</li><li id="895d" class="lr ls it kw b kx ma la mb ld mc lh md ll me lp lw lx ly lz bi translated">步骤 6:训练新的 DEC 模型</li><li id="c91c" class="lr ls it kw b kx ma la mb ld mc lh md ll me lp lw lx ly lz bi translated">步骤 7:使用训练好的 DEC 模型预测聚类类</li><li id="8b60" class="lr ls it kw b kx ma la mb ld mc lh md ll me lp lw lx ly lz bi translated">第八步:共同细化 DEC 模型</li><li id="ef0f" class="lr ls it kw b kx ma la mb ld mc lh md ll me lp lw lx ly lz bi translated">步骤 9:使用改进的 DEC 模型预测聚类类</li><li id="ce57" class="lr ls it kw b kx ma la mb ld mc lh md ll me lp lw lx ly lz bi translated">步骤 10:与 K 均值比较</li></ul><h2 id="868b" class="nc mg it bd mh nd ne dn ml nf ng dp mp ld nh ni mr lh nj nk mt ll nl nm mv nn bi translated">2.1 估计聚类数</h2><p id="6609" class="pw-post-body-paragraph ku kv it kw b kx mx ju kz la my jx lc ld mz lf lg lh na lj lk ll nb ln lo lp im bi translated">如前所述，DEC 方法将 Autoencoder 与 K-means 和其他机器学习技术相结合。为了训练 K-均值模型，需要估计的聚类数。本文通过研究不同 K-means 模型执行的<a class="ae lq" href="https://en.wikipedia.org/wiki/Silhouette_(clustering)" rel="noopener ugc nofollow" target="_blank">剪影</a>值来估计聚类的数量:</p><pre class="kj kk kl km gt no np nq nr aw ns bi"><span id="f6fc" class="nc mg it np b gy nt nu l nv nw">for num_clusters in range(2,10):<br/>    clusterer = KMeans(n_clusters=num_clusters, n_jobs=4)<br/>    preds = clusterer.fit_predict(x)<br/>    # centers = clusterer.cluster_centers_<br/>    score = silhouette_score (x, preds, metric='euclidean')<br/>    print ("For n_clusters = {}, Kmeans silhouette score is {})".format(num_clusters, score))</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oa"><img src="../Images/f285947ff882753854a86cda6db18065.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*oUT9YpRDwI0xc_f7glrj5g.png"/></div></div></figure><p id="b108" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">轮廓值衡量数据记录与其自己的分类(内聚力)相比与其他分类的相似程度。轮廓值的范围从 1 到+1，其中高值表示数据记录与其自己的分类匹配良好，而与其相邻的分类匹配较差。</p><p id="c32f" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">上面的轮廓值表明聚类数的前两个选择是 2 和 3。本文选择了 3 个簇的数目。</p><h2 id="789b" class="nc mg it bd mh nd ne dn ml nf ng dp mp ld nh ni mr lh nj nk mt ll nl nm mv nn bi translated">2.2 创建和训练 K 均值模型</h2><p id="3eef" class="pw-post-body-paragraph ku kv it kw b kx mx ju kz la my jx lc ld mz lf lg lh na lj lk ll nb ln lo lp im bi translated">一旦确定了聚类的数量，就可以创建 K 均值模型:</p><pre class="kj kk kl km gt no np nq nr aw ns bi"><span id="1df5" class="nc mg it np b gy nt nu l nv nw">n_clusters = 3<br/>kmeans = KMeans(n_clusters=n_clusters, n_jobs=4)<br/>y_pred_kmeans = kmeans.fit_predict(x)</span></pre><h2 id="99c7" class="nc mg it bd mh nd ne dn ml nf ng dp mp ld nh ni mr lh nj nk mt ll nl nm mv nn bi translated">2.3 创建和培训自动编码器</h2><p id="3096" class="pw-post-body-paragraph ku kv it kw b kx mx ju kz la my jx lc ld mz lf lg lh na lj lk ll nb ln lo lp im bi translated">除了 K-means，DEC 算法中还需要一个自动编码器[1]。以下函数用于创建自动编码器:</p><pre class="kj kk kl km gt no np nq nr aw ns bi"><span id="1fde" class="nc mg it np b gy nt nu l nv nw">def autoencoder(dims, act='relu', init='glorot_uniform'):<br/>    n_stacks = len(dims) - 1<br/>    <br/>    input_data = Input(shape=(dims[0],), name='input')<br/>    x = input_data<br/>    <br/>    # internal layers of encoder<br/>    for i in range(n_stacks-1):<br/>        x = Dense(dims[i + 1], activation=act,  kernel_initializer=init, name='encoder_%d' % i)(x)</span><span id="e54f" class="nc mg it np b gy ob nu l nv nw">    # latent hidden layer<br/>    encoded = Dense(dims[-1], kernel_initializer=init, name='encoder_%d' % (n_stacks - 1))(x)</span><span id="f014" class="nc mg it np b gy ob nu l nv nw">    x = encoded<br/>    # internal layers of decoder<br/>    for i in range(n_stacks-1, 0, -1):<br/>        x = Dense(dims[i], activation=act, kernel_initializer=init, name='decoder_%d' % i)(x)</span><span id="afe6" class="nc mg it np b gy ob nu l nv nw">    # decoder output<br/>    x = Dense(dims[0], kernel_initializer=init, name='decoder_0')(x)<br/>    <br/>    decoded = x<br/>    <br/>    autoencoder_model = Model(inputs=input_data, outputs=decoded, name='autoencoder')<br/>    encoder_model     = Model(inputs=input_data, outputs=encoded, name='encoder')<br/>    <br/>    return autoencoder_model, encoder_model</span></pre><p id="95ca" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">自动编码器模型创建如下:</p><pre class="kj kk kl km gt no np nq nr aw ns bi"><span id="6524" class="nc mg it np b gy nt nu l nv nw">n_epochs   = 100<br/>batch_size = 128<br/>dims = [x.shape[-1], 500, 500, 2000, 10] <br/>init = VarianceScaling(scale=1. / 3., mode='fan_in',<br/>                           distribution='uniform')<br/>pretrain_optimizer = SGD(lr=1, momentum=0.9)<br/>pretrain_epochs = n_epochs<br/>batch_size = batch_size<br/>save_dir = './results'</span><span id="df76" class="nc mg it np b gy ob nu l nv nw">autoencoder, encoder = autoencoder(dims, init=init)</span></pre><p id="0c7d" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">如[1]中所述，层的大小[500，500，2000，10]被选择作为用于任何数据集的自动编码器神经网络的一般配置。</p><p id="a69c" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">生成的编码器模型的图表可以创建如下:</p><pre class="kj kk kl km gt no np nq nr aw ns bi"><span id="59ad" class="nc mg it np b gy nt nu l nv nw">from keras.utils import plot_model<br/>plot_model(encoder, to_file='encoder.png', show_shapes=True)<br/>from IPython.display import Image<br/>Image(filename='encoder.png')</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi oc"><img src="../Images/c7f134663e976e99571e3e851b120db0.png" data-original-src="https://miro.medium.com/v2/resize:fit:922/format:webp/1*fTPivgBIw4Kjng9DXUiwNA.png"/></div></figure><p id="4ba2" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">自动编码器的训练如下:</p><pre class="kj kk kl km gt no np nq nr aw ns bi"><span id="8126" class="nc mg it np b gy nt nu l nv nw">autoencoder.compile(optimizer=pretrain_optimizer, loss='mse')<br/>autoencoder.fit(x, x, batch_size=batch_size, epochs=pretrain_epochs)<br/>autoencoder.save_weights(save_dir + '/ae_weights.h5')</span></pre><p id="cefa" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">被训练的自动编码器的权重被保存以备后用:</p><pre class="kj kk kl km gt no np nq nr aw ns bi"><span id="6641" class="nc mg it np b gy nt nu l nv nw">autoencoder.save_weights(save_dir + '/ae_weights.h5')<br/>autoencoder.load_weights(save_dir + '/ae_weights.h5')</span></pre><h2 id="9152" class="nc mg it bd mh nd ne dn ml nf ng dp mp ld nh ni mr lh nj nk mt ll nl nm mv nn bi translated">2.4 实施 DEC 软标签</h2><p id="3270" class="pw-post-body-paragraph ku kv it kw b kx mx ju kz la my jx lc ld mz lf lg lh na lj lk ll nb ln lo lp im bi translated">DEC 方法[1]中的一个关键组成部分是软标记，也就是说，为每个数据样本分配一个估计类，以使其可以迭代地改进。为此，与[2]类似，定义了一个新的<em class="od"> ClusteringLayer </em>类:</p><pre class="kj kk kl km gt no np nq nr aw ns bi"><span id="d6ba" class="nc mg it np b gy nt nu l nv nw">class ClusteringLayer(Layer):</span><span id="d5d2" class="nc mg it np b gy ob nu l nv nw">    def __init__(self, n_clusters, weights=None, alpha=1.0, **kwargs):<br/>        if 'input_shape' not in kwargs and 'input_dim' in kwargs:<br/>            kwargs['input_shape'] = (kwargs.pop('input_dim'),)<br/>        super(ClusteringLayer, self).__init__(**kwargs)<br/>        self.n_clusters = n_clusters<br/>        self.alpha = alpha<br/>        self.initial_weights = weights<br/>        self.input_spec = InputSpec(ndim=2)</span><span id="fca1" class="nc mg it np b gy ob nu l nv nw">    def build(self, input_shape):<br/>        assert len(input_shape) == 2<br/>        input_dim = input_shape[1]<br/>        self.input_spec = InputSpec(dtype=K.floatx(), shape=(None, input_dim))<br/>        self.clusters = self.add_weight(name='clusters', shape=(self.n_clusters, input_dim), initializer='glorot_uniform') <br/>        <br/>        if self.initial_weights is not None:<br/>            self.set_weights(self.initial_weights)<br/>            del self.initial_weights<br/>        self.built = True</span><span id="b417" class="nc mg it np b gy ob nu l nv nw">    def call(self, inputs, **kwargs):<br/>        q = 1.0 / (1.0 + (K.sum(K.square(K.expand_dims(inputs, axis=1) - self.clusters), axis=2) / self.alpha))<br/>        q **= (self.alpha + 1.0) / 2.0<br/>        q = K.transpose(K.transpose(q) / K.sum(q, axis=1)) <br/>        <br/>        return q</span><span id="05cf" class="nc mg it np b gy ob nu l nv nw">    def compute_output_shape(self, input_shape):<br/>        assert input_shape and len(input_shape) == 2<br/>        return input_shape[0], self.n_clusters</span><span id="d91d" class="nc mg it np b gy ob nu l nv nw">    def get_config(self):<br/>        config = {'n_clusters': self.n_clusters}<br/>        base_config = super(ClusteringLayer, self).get_config()<br/>        return dict(list(base_config.items()) + list(config.items()))</span></pre><h2 id="430c" class="nc mg it bd mh nd ne dn ml nf ng dp mp ld nh ni mr lh nj nk mt ll nl nm mv nn bi translated">2.5 创建新的 DEC 模型</h2><p id="868f" class="pw-post-body-paragraph ku kv it kw b kx mx ju kz la my jx lc ld mz lf lg lh na lj lk ll nb ln lo lp im bi translated">一旦定义了软标注图层，就可以使用它来形成 DEC 模型，如下所示:</p><pre class="kj kk kl km gt no np nq nr aw ns bi"><span id="f174" class="nc mg it np b gy nt nu l nv nw">clustering_layer = ClusteringLayer(n_clusters, name='clustering')(encoder.output)<br/>model = Model(inputs=encoder.input, outputs=clustering_layer)</span></pre><p id="cb74" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">可以创建新 DEC 模型的图表，如下所示:</p><pre class="kj kk kl km gt no np nq nr aw ns bi"><span id="afe1" class="nc mg it np b gy nt nu l nv nw">from keras.utils import plot_model<br/>plot_model(model, to_file='model.png', show_shapes=True)<br/>from IPython.display import Image<br/>Image(filename='model.png')</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nz"><img src="../Images/f58a59ab423954536ea92316c558f7af.png" data-original-src="https://miro.medium.com/v2/resize:fit:864/format:webp/1*iWLXdfDdcY8kdbtRR6gu0Q.png"/></div></figure><p id="65c7" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">新的 DEC 模型可以编译如下:</p><pre class="kj kk kl km gt no np nq nr aw ns bi"><span id="5f70" class="nc mg it np b gy nt nu l nv nw">model.compile(optimizer=SGD(0.01, 0.9), loss='kld')<br/>model.get_layer(name='clustering').set_weights([kmeans.cluster_centers_])</span></pre><h2 id="88c8" class="nc mg it bd mh nd ne dn ml nf ng dp mp ld nh ni mr lh nj nk mt ll nl nm mv nn bi translated">2.6 培训新的 DEC 模型</h2><p id="f67f" class="pw-post-body-paragraph ku kv it kw b kx mx ju kz la my jx lc ld mz lf lg lh na lj lk ll nb ln lo lp im bi translated">迭代训练新的 DEC 模型:</p><pre class="kj kk kl km gt no np nq nr aw ns bi"><span id="fb6f" class="nc mg it np b gy nt nu l nv nw"># computing an auxiliary target distribution<br/>def target_distribution(q):<br/>    weight = q ** 2 / q.sum(0)<br/>    return (weight.T / weight.sum(1)).T</span><span id="85b3" class="nc mg it np b gy ob nu l nv nw">loss = 0<br/>index = 0<br/>maxiter = 1000 <br/>update_interval = 100 <br/>tol = 0.001 # tolerance threshold to stop training</span><span id="dc5e" class="nc mg it np b gy ob nu l nv nw">index_array = np.arange(x.shape[0])<br/><br/>for ite in range(int(maxiter)):<br/>    if ite % update_interval == 0:<br/>        q = model.predict(x, verbose=0)<br/>        p = target_distribution(q)  </span><span id="33f9" class="nc mg it np b gy ob nu l nv nw">idx = index_array[index * batch_size: min((index+1) * batch_size, x.shape[0])]<br/>    loss = model.train_on_batch(x=x[idx], y=p[idx])<br/>    index = index + 1 if (index + 1) * batch_size &lt;= x.shape[0] else 0</span></pre><p id="cbd9" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">如[1]中所述，上述训练过程通过在辅助目标分布函数<em class="od"> target_distribution </em>)的帮助下从高置信度分配中学习来迭代地改进聚类。具体而言，通过将软分配与目标分布相匹配来训练 DEC 模型。为此，在 DEC 模型中，目标/损失函数被定义为软分配和辅助分布之间的<a class="ae lq" href="https://en.wikipedia.org/wiki/Kullback%E2%80%93Leibler_divergence" rel="noopener ugc nofollow" target="_blank"> Kullback-Leibler </a> (KL)发散损失。</p><p id="7eb9" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">已训练模型的模型权重被保存以备后用:</p><pre class="kj kk kl km gt no np nq nr aw ns bi"><span id="a88d" class="nc mg it np b gy nt nu l nv nw">model.save_weights(save_dir + '/DEC_model_final.h5')<br/>model.load_weights(save_dir + '/DEC_model_final.h5')</span></pre><h2 id="2e71" class="nc mg it bd mh nd ne dn ml nf ng dp mp ld nh ni mr lh nj nk mt ll nl nm mv nn bi translated">2.7 使用训练的 DEC 模型来预测聚类类别</h2><p id="fa4f" class="pw-post-body-paragraph ku kv it kw b kx mx ju kz la my jx lc ld mz lf lg lh na lj lk ll nb ln lo lp im bi translated">一旦 DEC 模型被定型，它就可以用于预测聚类类，如下所示:</p><pre class="kj kk kl km gt no np nq nr aw ns bi"><span id="d824" class="nc mg it np b gy nt nu l nv nw">q = model.predict(x, verbose=0)<br/>p = target_distribution(q) <br/>y_pred = q.argmax(1)</span></pre><p id="cd11" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">如下获得 0.291 的轮廓分数:</p><pre class="kj kk kl km gt no np nq nr aw ns bi"><span id="df49" class="nc mg it np b gy nt nu l nv nw">from sklearn.metrics import silhouette_score<br/>score = silhouette_score(x, y_pred, metric='euclidean')</span></pre><p id="f291" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">以下代码可用于使用 t-SNE 将数据集嵌入二维空间，然后使用预测聚类标签的颜色编码来可视化预测聚类结果:</p><pre class="kj kk kl km gt no np nq nr aw ns bi"><span id="b731" class="nc mg it np b gy nt nu l nv nw">import numpy as np<br/>from sklearn.manifold import TSNE</span><span id="1202" class="nc mg it np b gy ob nu l nv nw">x_embedded = TSNE(n_components=2).fit_transform(x)</span><span id="2aea" class="nc mg it np b gy ob nu l nv nw">vis_x = x_embedded[:, 0]<br/>vis_y = x_embedded[:, 1]<br/>plt.scatter(vis_x, vis_y, c=y_pred, cmap=plt.cm.get_cmap("jet", 256))<br/>plt.colorbar(ticks=range(256))<br/>plt.clim(-0.5, 9.5)<br/>plt.show()</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oe"><img src="../Images/d37c1bcab61e07aa86731e792d89b721.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*9GG2eDlLSDr9sny791F0qg.png"/></div></div></figure><p id="dea7" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated"><strong class="kw iu">图 1: </strong>剪影得分为 0.291 的新 DEC 模型的聚类。</p><h2 id="40ce" class="nc mg it bd mh nd ne dn ml nf ng dp mp ld nh ni mr lh nj nk mt ll nl nm mv nn bi translated">2.8 联合提炼 DEC 模型</h2><p id="b291" class="pw-post-body-paragraph ku kv it kw b kx mx ju kz la my jx lc ld mz lf lg lh na lj lk ll nb ln lo lp im bi translated">DEC 方法[1]背后的主要思想是使用深度神经网络同时学习特征表示和聚类分配。为此，以下代码使用预训练的 autoencoder 和 K-means 模型来定义一个新模型，该模型将预处理的信用卡数据集作为输入，并输出预测的聚类分析类和解码的输入数据记录。</p><pre class="kj kk kl km gt no np nq nr aw ns bi"><span id="d373" class="nc mg it np b gy nt nu l nv nw">autoencoder, encoder = autoencoder(dims, init=init)<br/>autoencoder.load_weights(save_dir + '/ae_weights.h5')<br/>clustering_layer = ClusteringLayer(n_clusters, name='clustering')(encoder.output)<br/>model = Model(inputs=encoder.input, outputs=[clustering_layer, autoencoder.output])</span></pre><p id="f8a6" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">可以按如下方式创建连接模型的图表:</p><pre class="kj kk kl km gt no np nq nr aw ns bi"><span id="efac" class="nc mg it np b gy nt nu l nv nw">from keras.utils import plot_model<br/>plot_model(model, to_file='model.png', show_shapes=True)<br/>from IPython.display import Image<br/>Image(filename='model.png')</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi of"><img src="../Images/26ced38c05c19a804a27d36fcd924dc8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*LMq5JdUy6VN1E6XN5p1piw.png"/></div></div></figure><p id="d53c" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">DEC 模型的优化执行如下:</p><pre class="kj kk kl km gt no np nq nr aw ns bi"><span id="7038" class="nc mg it np b gy nt nu l nv nw">kmeans = KMeans(n_clusters=n_clusters, n_init=20)<br/>y_pred = kmeans.fit_predict(encoder.predict(x))<br/>model.get_layer(name='clustering').set_weights([kmeans.cluster_centers_])<br/>y_pred_last = np.copy(y_pred)</span><span id="f037" class="nc mg it np b gy ob nu l nv nw">model.compile(loss=['kld', 'mse'], loss_weights=[0.1, 1], optimizer=pretrain_optimizer)</span><span id="2e0b" class="nc mg it np b gy ob nu l nv nw">for ite in range(int(maxiter)):<br/>    if ite % update_interval == 0:<br/>        q, _  = model.predict(x, verbose=0)<br/>        p = target_distribution(q)  <br/>        y_pred = q.argmax(1)</span><span id="6a0a" class="nc mg it np b gy ob nu l nv nw">        # check stop criterion<br/>        delta_label = np.sum(y_pred != y_pred_last).astype(np.float32) / y_pred.shape[0]<br/>        y_pred_last = np.copy(y_pred)<br/>        if ite &gt; 0 and delta_label &lt; tol:<br/>            print('delta_label ', delta_label, '&lt; tol ', tol)<br/>            print('Reached tolerance threshold. Stopping training.')<br/>            break<br/>    idx = index_array[index * batch_size: min((index+1) * batch_size, x.shape[0])]<br/>    loss = model.train_on_batch(x=x[idx], y=[p[idx], x[idx]])<br/>    index = index + 1 if (index + 1) * batch_size &lt;= x.shape[0] else 0</span></pre><p id="1f17" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">保存联合细化的模型权重:</p><pre class="kj kk kl km gt no np nq nr aw ns bi"><span id="260a" class="nc mg it np b gy nt nu l nv nw">model.save_weights(save_dir + '/b_DEC_model_final.h5')<br/>model.load_weights(save_dir + '/b_DEC_model_final.h5')</span></pre><h2 id="4c99" class="nc mg it bd mh nd ne dn ml nf ng dp mp ld nh ni mr lh nj nk mt ll nl nm mv nn bi translated">2.9 使用改进的 DEC 模型预测聚类类别</h2><p id="d3d3" class="pw-post-body-paragraph ku kv it kw b kx mx ju kz la my jx lc ld mz lf lg lh na lj lk ll nb ln lo lp im bi translated">以下代码将使用改进的 DEC 模型来预测聚类分析类:</p><pre class="kj kk kl km gt no np nq nr aw ns bi"><span id="0477" class="nc mg it np b gy nt nu l nv nw">q, _ = model.predict(x, verbose=0)<br/>p = target_distribution(q)  <br/>y_pred = q.argmax(1)</span></pre><p id="12df" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">下面的代码可用于重用 t-SNE 嵌入的二维空间(<em class="od"> vis_x </em>，<em class="od"> vis_y </em>)，并使用新的预测聚类标签的颜色编码来可视化新的预测聚类结果:</p><pre class="kj kk kl km gt no np nq nr aw ns bi"><span id="a489" class="nc mg it np b gy nt nu l nv nw">plt.scatter(vis_x, vis_y, c=y_pred, cmap=plt.cm.get_cmap("jet", 256))<br/>plt.colorbar(ticks=range(256))<br/>plt.clim(-0.5, 9.5)<br/>plt.show()</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi og"><img src="../Images/fc8511e159099e981cff7c26beff58f6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*qj8cbr4r9xebbZGe4TXoqQ.png"/></div></div></figure><p id="ec8e" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated"><strong class="kw iu">图 2: </strong>轮廓得分为 0.318 的细化 DEC 模型的聚类。</p><h2 id="f6a5" class="nc mg it bd mh nd ne dn ml nf ng dp mp ld nh ni mr lh nj nk mt ll nl nm mv nn bi translated">2.10 与 K 均值比较</h2><p id="e494" class="pw-post-body-paragraph ku kv it kw b kx mx ju kz la my jx lc ld mz lf lg lh na lj lk ll nb ln lo lp im bi translated">图 3 显示了 K-means 的聚类结果。通过比较图 3 和图 2，我们可以看到 K-means 取得了相对较高的轮廓得分。然而，可以看出，改进的 DEC 模型预测了具有更清晰可分边界的聚类。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oe"><img src="../Images/3f351add2b39fe43685819a49b7a4563.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*fLe7QvSY7Q00UO7Mx62Tmg.png"/></div></div></figure><p id="30c3" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">图 3:轮廓得分为 0.372 的 K 均值模型的聚类。</p><h1 id="5a4f" class="mf mg it bd mh mi mj mk ml mm mn mo mp jz mq ka mr kc ms kd mt kf mu kg mv mw bi translated">摘要</h1><p id="cfd7" class="pw-post-body-paragraph ku kv it kw b kx mx ju kz la my jx lc ld mz lf lg lh na lj lk ll nb ln lo lp im bi translated">在本文中，与[2]类似，我基于[1]中的原始 DEC 算法在 Keras 中实现了一个新的 DEC 模型，然后将新模型应用于公共数据集<a class="ae lq" href="https://www.kaggle.com/arjunbhasin2013/ccdata" rel="noopener ugc nofollow" target="_blank"> Kaggle 信用卡数据集进行聚类</a>【3】。</p><p id="138c" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">模型评估结果表明，与 K-means 方法相比，新的改进的 DEC 模型更清楚地预测了信用卡数据集的可分离聚类。这种新的 DEC 模型具有用于信用卡客户细分、其他金融市场细分等的潜力。</p><p id="a6c7" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">Github [4]中提供了一个 Jupyter 笔记本，其中包含了本文中使用的所有源代码。</p><h1 id="fa1d" class="mf mg it bd mh mi mj mk ml mm mn mo mp jz mq ka mr kc ms kd mt kf mu kg mv mw bi translated">参考</h1><p id="e88f" class="pw-post-body-paragraph ku kv it kw b kx mx ju kz la my jx lc ld mz lf lg lh na lj lk ll nb ln lo lp im bi translated">[1] J .谢，r .吉希克，a .，<a class="ae lq" href="https://arxiv.org/pdf/1511.06335.pdf" rel="noopener ugc nofollow" target="_blank">聚类分析的无监督深度嵌入</a>，2016 年 5 月 24 日</p><p id="4c63" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">[2]程维，<a class="ae lq" href="https://www.dlology.com/blog/how-to-do-unsupervised-clustering-with-keras/" rel="noopener ugc nofollow" target="_blank">如何用 Keras 做无监督聚类</a></p><p id="44c2" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">[3] Kaggle <a class="ae lq" href="https://www.kaggle.com/arjunbhasin2013/ccdata" rel="noopener ugc nofollow" target="_blank">用于聚类的信用卡数据集</a></p><p id="60fa" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">[4] Y. Zhang，<a class="ae lq" href="https://github.com/yzzhang/machine-learning/tree/master/deep_learning/unsupervised_learning/dec_keras_clustering" rel="noopener ugc nofollow" target="_blank"> Github </a>中的 Jupyter 笔记本</p></div><div class="ab cl oh oi hx oj" role="separator"><span class="ok bw bk ol om on"/><span class="ok bw bk ol om on"/><span class="ok bw bk ol om"/></div><div class="im in io ip iq"><p id="eab8" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">披露声明:2019 首创一。观点是作者个人的观点。除非本帖中另有说明，否则 Capital One 不隶属于所提及的任何公司，也不被这些公司认可。使用或展示的所有商标和其他知识产权是其各自所有者的财产。</p></div></div>    
</body>
</html>