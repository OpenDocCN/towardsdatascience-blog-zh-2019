<html>
<head>
<title>Metrics For Evaluating Machine Learning Classification Models</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">用于评估机器学习分类模型的度量</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/metrics-for-evaluating-machine-learning-classification-models-python-example-59b905e079a5?source=collection_archive---------7-----------------------#2019-06-07">https://towardsdatascience.com/metrics-for-evaluating-machine-learning-classification-models-python-example-59b905e079a5?source=collection_archive---------7-----------------------#2019-06-07</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><figure class="ip iq gp gr ir is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi io"><img src="../Images/7f2848df0ec3b2d0192e139a5ef914ce.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*-Urm9crsD_L7IwcT"/></div></div><figcaption class="iz ja gj gh gi jb jc bd b be z dk">Photo by <a class="ae jd" href="https://unsplash.com/@chrisliverani?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Chris Liverani</a> on <a class="ae jd" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><div class=""/><p id="973f" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在机器学习领域，有三种主要的问题:回归、分类和聚类。根据您正在处理的问题的类型，您将希望使用一组特定的指标来衡量您的模型的性能。这可以用一个例子来很好地说明。假设一家公司声称已经开发出面部检测算法，可以以 99.9%的准确率识别恐怖分子。抛开道德影响不谈，这应该会立即引发一个危险信号。恐怖分子只占人口的很小一部分(我找不到实际的统计数据，但我们假设是 0.001%)。因此，通过假设没有人是恐怖分子(即编写一个始终返回 false 的程序)，我们可以达到 99.9%以上的准确率。因此，准确性不是评估模型性能的好指标，因为它错误地将每个恐怖分子分类，但仍然获得了很高的分数。</p><h2 id="c172" class="lb lc jg bd ld le lf dn lg lh li dp lj ko lk ll lm ks ln lo lp kw lq lr ls lt bi translated">混淆矩阵</h2><p id="80bc" class="pw-post-body-paragraph kd ke jg kf b kg lu ki kj kk lv km kn ko lw kq kr ks lx ku kv kw ly ky kz la ij bi translated">另一方面，混淆矩阵将区分被正确分类为非恐怖分子的样本数量和被正确分类为恐怖分子的样本数量。混淆矩阵被分成 4 个象限。</p><figure class="ma mb mc md gt is gh gi paragraph-image"><div class="gh gi lz"><img src="../Images/1a3b71a6e2a3d9943b8cda9b52887097.png" data-original-src="https://miro.medium.com/v2/resize:fit:514/0*8BVXH3sScA9Un0B6"/></div><figcaption class="iz ja gj gh gi jb jc bd b be z dk"><a class="ae jd" href="https://commons.wikimedia.org/wiki/File:Binary_confusion_matrix.jpg" rel="noopener ugc nofollow" target="_blank">https://commons.wikimedia.org/wiki/File:Binary_confusion_matrix.jpg</a></figcaption></figure><p id="5553" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kf jh">真阳性:</strong></p><p id="023d" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">解读:你预测的是正的，这是真的。</p><p id="58de" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">你预测那个人是恐怖分子，他们确实是。</p><p id="838c" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kf jh">真阴性:</strong></p><p id="5acc" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">解读:你预测的是负数，这是真的。</p><p id="493e" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">你预测那个人不是恐怖分子，而他们实际上不是。</p><p id="9b0e" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kf jh">假阳性:(1 型错误)</strong></p><p id="c467" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">解读:你预测的是正的，是假的。</p><p id="eef7" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">你预测那个人是恐怖分子，但他们实际上不是。</p><p id="1f87" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kf jh">假阴性:(2 型错误)</strong></p><p id="cf43" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">解读:你预测的是负数，这是假的。</p><p id="adf8" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">你预测那个人不是恐怖分子，但他们确实是。</p><h2 id="d4aa" class="lb lc jg bd ld le lf dn lg lh li dp lj ko lk ll lm ks ln lo lp kw lq lr ls lt bi translated">精确度/召回率</h2><p id="a106" class="pw-post-body-paragraph kd ke jg kf b kg lu ki kj kk lv km kn ko lw kq kr ks lx ku kv kw ly ky kz la ij bi translated">有时，使用数字来评估模型的性能比依赖库来可视化混乱矩阵更容易。</p><figure class="ma mb mc md gt is gh gi paragraph-image"><div class="ab gu cl me"><img src="../Images/b288f5335c04e1412b551d52192ba639.png" data-original-src="https://miro.medium.com/v2/format:webp/1*7J08ekAwupLBegeUI8muHA.png"/></div></figure><p id="dbce" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在现实世界中，你会遇到分类问题，分界线迫使你在高精度和高召回率之间做出选择。在某些情况下，精度越高越好。例如，诊断中出现一些假阳性可能会更好，而不是让任何真正患有疾病的人从裂缝中溜走，逃避治疗。其他时候，最好有更高的召回率，就像垃圾邮件过滤器一样。在用户的收件箱里放几封垃圾邮件比把重要的邮件归类为垃圾邮件更容易被接受。为了形成更好的判断，我们可以用图形来表示精确度和召回率之间的权衡。</p><figure class="ma mb mc md gt is gh gi paragraph-image"><div class="gh gi mf"><img src="../Images/f0e34ddc285ce8a3aee1203b2c6668ac.png" data-original-src="https://miro.medium.com/v2/resize:fit:1104/format:webp/0*4P3MbyyU4VgNkzb1.png"/></div><figcaption class="iz ja gj gh gi jb jc bd b be z dk"><a class="ae jd" href="https://commons.wikimedia.org/wiki/File:ROCCurve.png" rel="noopener ugc nofollow" target="_blank">https://commons.wikimedia.org/wiki/File:ROCCurve.png</a></figcaption></figure><p id="ed3e" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">如果我们可以使用一个单一的分数，而不是每次都测量召回率和精确度，这将会更容易。首先，我们可以试着取两个结果的平均值。例如，假设一个垃圾邮件检测器的准确率为 80%，召回率为 37%，那么平均准确率为 58.5%。现在，假设我们构建了垃圾邮件检测器，它不会将任何电子邮件视为垃圾邮件(类似于恐怖分子的例子)。如果非垃圾邮件明显多于垃圾邮件，我们的模型将被解释为性能良好。具体来说，如果 300，000 封电子邮件是垃圾邮件(不是垃圾邮件), 500 封是垃圾邮件，那么将所有电子邮件分类为垃圾邮件的模型将获得 100%的精确度，因为它正确地分类了所有垃圾邮件，并且召回率为 0%,因为它错误地分类了所有垃圾邮件。如果我们取平均值，我们仍然会得到 50%,这有点误导，因为垃圾邮件检测器的整个目的是检测垃圾邮件。</p><p id="5b81" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">正是由于上述原因，我们使用调和平均值而不是算术平均值来计算平均值。调和平均值总是更接近较小的数，而不是较大的数。</p><figure class="ma mb mc md gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi mg"><img src="../Images/95d0c1bc0f6e982e42735abcfea0c444.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*j0psaPqcNhMC-rpT5Pb8wg.png"/></div></div></figure><p id="420a" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">回到我们的垃圾邮件检测器的例子。如果精度等于 100%，召回率等于 0%，则调和平均值等于 0%。我们把这个值叫做<strong class="kf jh"> F1 分数</strong>。</p><figure class="ma mb mc md gt is gh gi paragraph-image"><div class="ab gu cl me"><img src="../Images/815bfac570b3963d188f677fbeedd557.png" data-original-src="https://miro.medium.com/v2/format:webp/1*UJxVqLnbSj42eRhasKeLOA.png"/></div></figure><h2 id="0b4e" class="lb lc jg bd ld le lf dn lg lh li dp lj ko lk ll lm ks ln lo lp kw lq lr ls lt bi translated">ROC / AUC</h2><p id="cfe3" class="pw-post-body-paragraph kd ke jg kf b kg lu ki kj kk lv km kn ko lw kq kr ks lx ku kv kw ly ky kz la ij bi translated">类似于精确度/召回率曲线，接收器操作者特征(ROC)图提供了一种优雅的方式来呈现在不同阈值下产生的多个混淆矩阵。ROC 绘制了真阳性率和假阳性率之间的关系。</p><ul class=""><li id="a5a6" class="mh mi jg kf b kg kh kk kl ko mj ks mk kw ml la mm mn mo mp bi translated">真阳性率=召回率=灵敏度=真阳性/(真阳性+假阴性)</li><li id="25a4" class="mh mi jg kf b kg mq kk mr ko ms ks mt kw mu la mm mn mo mp bi translated">假阳性率= 1–特异性=假阳性/(假阳性+真阴性)</li></ul><figure class="ma mb mc md gt is gh gi paragraph-image"><div class="gh gi mv"><img src="../Images/a99cd6af25ba91c2d3e3b3035ab23adc.png" data-original-src="https://miro.medium.com/v2/resize:fit:870/format:webp/0*L3edUiUrhqm54IdO.png"/></div><figcaption class="iz ja gj gh gi jb jc bd b be z dk"><a class="ae jd" href="https://en.wikipedia.org/wiki/File:Basic_AUC_annotated.png" rel="noopener ugc nofollow" target="_blank">https://en.wikipedia.org/wiki/File:Basic_AUC_annotated.png</a></figcaption></figure><p id="ee97" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">值得注意的是，假阳性率是 1 减去特异性，这意味着假阳性率越接近 0，特异性就越高(回忆)。因此，为了获得特异性和敏感性的最佳值，我们需要选择左上角的一个点。</p><p id="ac2a" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">另一方面，曲线下面积(AUC)使得将一条 ROC 曲线与另一条进行比较变得容易。例如，红色 ROC 曲线的 AUC 大于蓝色 ROC 曲线的 AUC。因此，对于相同量的特异性，与红色曲线相关的模型实现了更高的灵敏度。</p><figure class="ma mb mc md gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi mw"><img src="../Images/72f63670fa3f59af9879345c8e38aa2b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*wLYTgW2znz0bgH4T.png"/></div></div><figcaption class="iz ja gj gh gi jb jc bd b be z dk"><a class="ae jd" href="https://commons.wikimedia.org/wiki/File:ROC_curve.svg" rel="noopener ugc nofollow" target="_blank">https://commons.wikimedia.org/wiki/File:ROC_curve.svg</a></figcaption></figure><h1 id="45f8" class="mx lc jg bd ld my mz na lg nb nc nd lj ne nf ng lm nh ni nj lp nk nl nm ls nn bi translated">密码</h1><p id="00ab" class="pw-post-body-paragraph kd ke jg kf b kg lu ki kj kk lv km kn ko lw kq kr ks lx ku kv kw ly ky kz la ij bi translated">在前面的例子中，我们将看一下前面所有正在运行的指标。</p><pre class="ma mb mc md gt no np nq nr aw ns bi"><span id="bac0" class="lb lc jg np b gy nt nu l nv nw">import pandas as pd<br/>from matplotlib import pyplot as plt<br/>plt.style.use('dark_background')<br/>from sklearn.datasets import load_breast_cancer<br/>from sklearn.ensemble import RandomForestClassifier<br/>from sklearn.model_selection import train_test_split<br/>from sklearn.preprocessing import LabelEncoder<br/>from sklearn.metrics import roc_curve<br/>from sklearn.metrics import auc<br/>from sklearn.metrics import precision_recall_curve<br/>from sklearn.metrics import precision_score<br/>from sklearn.metrics import recall_score<br/>from sklearn.metrics import f1_score<br/>from sklearn.metrics import average_precision_score<br/>from inspect import signature</span></pre><p id="8881" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">为简单起见，我们将使用 sklearn 提供的一个数据集。</p><pre class="ma mb mc md gt no np nq nr aw ns bi"><span id="969f" class="lb lc jg np b gy nt nu l nv nw">breast_cancer = load_breast_cancer()</span><span id="1ea4" class="lb lc jg np b gy nx nu l nv nw">X = pd.DataFrame(breast_cancer.data, columns=breast_cancer.feature_names)</span><span id="a3b3" class="lb lc jg np b gy nx nu l nv nw">y = pd.Categorical.from_codes(breast_cancer.target, breast_cancer.target_names)</span><span id="f8c4" class="lb lc jg np b gy nx nu l nv nw">encoder = LabelEncoder()</span><span id="5079" class="lb lc jg np b gy nx nu l nv nw">y = pd.Series(encoder.fit_transform(y))</span></pre><p id="4765" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这些指标将用于衡量我们的模型做出的预测与测试集中包含的样本之间的差异。</p><pre class="ma mb mc md gt no np nq nr aw ns bi"><span id="effe" class="lb lc jg np b gy nt nu l nv nw">X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)</span></pre><p id="2801" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们将使用随机森林分类器，但任何分类算法都可以。</p><pre class="ma mb mc md gt no np nq nr aw ns bi"><span id="6f22" class="lb lc jg np b gy nt nu l nv nw">rf = RandomForestClassifier()</span><span id="c890" class="lb lc jg np b gy nx nu l nv nw">rf.fit(X_train, y_train)</span></pre><p id="e0da" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们称<em class="ny"> predict_proba 方法 r </em>而不是<em class="ny"> predict </em>以获得一个概率列表，该列表表示样本属于给定类别的可能性。这类似于深度学习中常用的 softmax 激活函数。</p><pre class="ma mb mc md gt no np nq nr aw ns bi"><span id="85e4" class="lb lc jg np b gy nt nu l nv nw">probs = rf.predict_proba(X_test)</span></pre><figure class="ma mb mc md gt is gh gi paragraph-image"><div class="gh gi nz"><img src="../Images/9b135e50a7183d7332c10a31d676bc0f.png" data-original-src="https://miro.medium.com/v2/resize:fit:364/format:webp/1*aCXvsXAv7VfP_P0Je5nG2Q.png"/></div></figure><p id="b1b9" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><code class="fe oa ob oc np b">roc_curve</code>方法需要一个单一的特征。因此，我们采用肿瘤是恶性的预测概率。</p><pre class="ma mb mc md gt no np nq nr aw ns bi"><span id="f7c2" class="lb lc jg np b gy nt nu l nv nw">malignant_probs = probs[:,1]</span><span id="9d91" class="lb lc jg np b gy nx nu l nv nw">fpr, tpr, thresholds = roc_curve(y_test, malignant_probs)</span><span id="c6e4" class="lb lc jg np b gy nx nu l nv nw">roc_auc = auc(fpr, tpr)</span></pre><p id="c16e" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在这个例子中很难看到，但我们通常会选择左上角的一个点，它将产生最佳的灵敏度和特异性。AUC 为 0.98 意味着在特异性和敏感性之间几乎没有权衡。</p><pre class="ma mb mc md gt no np nq nr aw ns bi"><span id="dbbe" class="lb lc jg np b gy nt nu l nv nw">plt.title('Receiver Operating Characteristic')<br/>plt.plot(fpr, tpr, 'y', label = 'AUC = %0.2f' % roc_auc)<br/>plt.legend(loc = 'lower right')<br/>plt.plot([0, 1], [0, 1],'r--')<br/>plt.xlim([0, 1])<br/>plt.ylim([0, 1])<br/>plt.ylabel('True Positive Rate')<br/>plt.xlabel('False Positive Rate')<br/>plt.show()</span></pre><figure class="ma mb mc md gt is gh gi paragraph-image"><div class="gh gi od"><img src="../Images/91df7c6c684650c55eb404ffb5e23bc2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1066/format:webp/1*ZUzArzY4P8oKxYdZX5AooQ.png"/></div></figure><p id="13c7" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">接下来，让我们看看其他一些指标来评估我们模型的性能。首先，我们使用我们的模型根据上一步的概率对数据进行分类。</p><pre class="ma mb mc md gt no np nq nr aw ns bi"><span id="cadd" class="lb lc jg np b gy nt nu l nv nw">y_pred = rf.predict(X_test)</span></pre><p id="3ca8" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">快速提醒一下，precision 测量的是真阳性，而不是真阳性加上假阳性。</p><pre class="ma mb mc md gt no np nq nr aw ns bi"><span id="03db" class="lb lc jg np b gy nt nu l nv nw">precision_score(y_test, y_pred)</span></pre><figure class="ma mb mc md gt is gh gi paragraph-image"><div class="gh gi oe"><img src="../Images/c20b7e24fcc2f18e8166cbdcf1c7a15a.png" data-original-src="https://miro.medium.com/v2/resize:fit:404/format:webp/1*cLLG4ut9tmc-Zbih0tuDHw.png"/></div></figure><p id="eaf6" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">召回衡量的是真阳性与真阳性和假阴性之比。</p><pre class="ma mb mc md gt no np nq nr aw ns bi"><span id="4224" class="lb lc jg np b gy nt nu l nv nw">recall_score(y_test, y_pred)</span></pre><figure class="ma mb mc md gt is gh gi paragraph-image"><div class="gh gi oe"><img src="../Images/9a10b3a2e2138f8fa12fcd59c82bcb8a.png" data-original-src="https://miro.medium.com/v2/resize:fit:404/format:webp/1*ib7ylWIa1MrCira_eMLDWw.png"/></div></figure><p id="ec52" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">F1 分数使用调和平均值结合了精确度和召回率。</p><pre class="ma mb mc md gt no np nq nr aw ns bi"><span id="2fa6" class="lb lc jg np b gy nt nu l nv nw">f1_score(y_test, y_pred)</span></pre><figure class="ma mb mc md gt is gh gi paragraph-image"><div class="gh gi of"><img src="../Images/c88376851476eacb5bf85e488d0482eb.png" data-original-src="https://miro.medium.com/v2/resize:fit:430/format:webp/1*klJSp6GftDuCBVqVN1CJbw.png"/></div></figure><p id="1781" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">选择对应于右上角的阈值数量将导致精确度和召回率的最佳组合。</p><pre class="ma mb mc md gt no np nq nr aw ns bi"><span id="1dcc" class="lb lc jg np b gy nt nu l nv nw">precision, recall, threshold = precision_recall_curve(y_test, y_pred)<br/>average_precision = average_precision_score(y_test, y_pred)</span><span id="ea1a" class="lb lc jg np b gy nx nu l nv nw">step_kwargs = ({'step': 'post'} if 'step' in signature(plt.fill_between).parameters else {})<br/>plt.step(recall, precision, color='r', alpha=0.2, where='post')<br/>plt.fill_between(recall, precision, alpha=0.2, color='r', **step_kwargs)<br/>plt.xlabel('Recall')<br/>plt.ylabel('Precision')<br/>plt.ylim([0.0, 1.0])<br/>plt.xlim([0.0, 1.0])<br/>plt.title('2-class Precision-Recall curve: AP={0:0.2f}'.format(average_precision))</span></pre><figure class="ma mb mc md gt is gh gi paragraph-image"><div class="gh gi og"><img src="../Images/9d13377d81076b7c0a79ee0c29707e98.png" data-original-src="https://miro.medium.com/v2/resize:fit:1124/format:webp/1*849048OBT6RZswwFrlNB3w.png"/></div></figure><h1 id="092c" class="mx lc jg bd ld my mz na lg nb nc nd lj ne nf ng lm nh ni nj lp nk nl nm ls nn bi translated">最后的想法</h1><p id="c9d7" class="pw-post-body-paragraph kd ke jg kf b kg lu ki kj kk lv km kn ko lw kq kr ks lx ku kv kw ly ky kz la ij bi translated">我们用来评估模型性能的度量标准的选择取决于问题的性质。对于分类模型，我们可以使用精度、召回率、f1 得分或 ROC 曲线来衡量性能。</p></div></div>    
</body>
</html>