<html>
<head>
<title>How to measure the goodness of a regression model</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">如何衡量一个回归模型的好坏</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/how-to-measure-the-goodness-of-a-regression-model-60c7f87614ce?source=collection_archive---------8-----------------------#2019-04-16">https://towardsdatascience.com/how-to-measure-the-goodness-of-a-regression-model-60c7f87614ce?source=collection_archive---------8-----------------------#2019-04-16</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="145a" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">浅谈如何检验回归模型的统计优度？</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/048c8da7f5c505374b3df0a5d7ef4ea2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*s_6m3X8IQCdCVH-i"/></div></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk">Photo by <a class="ae ky" href="https://unsplash.com/@antoine1003?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Antoine Dautry</a> on <a class="ae ky" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><p id="8d07" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">回归模型</strong>非常有用，广泛应用于机器学习。然而，当测量一个训练好的模型的<strong class="lb iu">优度</strong>时，它们可能会显示出一些问题。而分类模型有一些<strong class="lb iu">标准工具</strong>可用于评估其性能(即 ROC 曲线下面积、混淆矩阵、F-1 评分等)。)，回归模型的性能可以用许多不同的方法来衡量。在本文中，我将向您展示我在作为数据科学家的经历中使用的一些技术。</p></div><div class="ab cl lv lw hx lx" role="separator"><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma"/></div><div class="im in io ip iq"><h1 id="6248" class="mc md it bd me mf mg mh mi mj mk ml mm jz mn ka mo kc mp kd mq kf mr kg ms mt bi translated">R 中的示例</h1><p id="4241" class="pw-post-body-paragraph kz la it lb b lc mu ju le lf mv jx lh li mw lk ll lm mx lo lp lq my ls lt lu im bi translated">在这个例子中，我将向你展示如何使用著名的<strong class="lb iu">虹膜数据集</strong>来衡量一个训练好的模型的好坏。我将使用<strong class="lb iu">线性回归模型</strong>来预测作为其他变量函数的萼片长度值。</p><p id="89b3" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">首先，我们将加载 iris 数据集，并将其分为定型和维持。</p><pre class="kj kk kl km gt mz na nb nc aw nd bi"><span id="c50d" class="ne md it na b gy nf ng l nh ni">data(iris)<br/>set.seed(1)</span><span id="2a70" class="ne md it na b gy nj ng l nh ni">training_idx = sample(1:nrow(iris),nrow(iris)*0.8,replace=FALSE)<br/>holdout_idx = setdiff(1:nrow(iris),training_idx)</span><span id="4a6f" class="ne md it na b gy nj ng l nh ni">training = iris[training_idx,]<br/>holdout = iris[holdout_idx,]</span></pre><p id="14a0" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">然后我们可以执行一个简单的<strong class="lb iu">线性回归</strong>来描述变量<strong class="lb iu"> Sepal。长度</strong>为其他长度的线性函数。这就是我们想要检验其优良性的模型。</p><pre class="kj kk kl km gt mz na nb nc aw nd bi"><span id="03b6" class="ne md it na b gy nf ng l nh ni">m = lm(Sepal.Length ~ .,training)</span></pre><p id="aeb0" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们现在需要做的就是将训练集中的<strong class="lb iu">残差</strong>与维持中的残差进行比较。记住残差是真实值和预测值之间的<strong class="lb iu">差</strong>。</p><pre class="kj kk kl km gt mz na nb nc aw nd bi"><span id="2b33" class="ne md it na b gy nf ng l nh ni">training_res = training$Sepal.Length - predict(m,training)<br/>holdout_res = holdout$Sepal.Length - predict(m,holdout)</span></pre><p id="f80c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">如果我们的训练程序已经产生了<strong class="lb iu">过拟合</strong>，那么与保持中的残差相比，训练集中的残差将<strong class="lb iu">非常小</strong>。这是一个消极的信号，应该促使我们<strong class="lb iu">简化</strong>模型或者<strong class="lb iu">去除</strong>一些变量。</p><p id="ddff" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">现在让我们执行一些统计检查。</p><h2 id="e326" class="ne md it bd me nk nl dn mi nm nn dp mm li no np mo lm nq nr mq lq ns nt ms nu bi translated">t 检验</h2><p id="802b" class="pw-post-body-paragraph kz la it lb b lc mu ju le lf mv jx lh li mw lk ll lm mx lo lp lq my ls lt lu im bi translated">我们首先要检查的是残差是否有偏差。我们从基本统计中知道，残差的平均值是零，所以我们可以开始用学生的 t 检验来检验这个样本是否正确。</p><pre class="kj kk kl km gt mz na nb nc aw nd bi"><span id="7b64" class="ne md it na b gy nf ng l nh ni">t.test(holdout_res,mu=0)</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nv"><img src="../Images/b59f779dbd57f5aa4903878a5e2adc37.png" data-original-src="https://miro.medium.com/v2/resize:fit:938/format:webp/1*0Gso5jlY6IlCJTtPtZ1fuQ.png"/></div></figure><p id="b196" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">正如我们所见，p 值大于 5%，因此我们<strong class="lb iu">无法拒绝</strong>零假设，可以说维持残差的平均值在统计上与 0 相似。</p><p id="4bb1" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">然后，我们可以测试保持残差是否具有与训练残差相同的平均值。这叫做<strong class="lb iu">韦尔奇的 t 检验</strong>。</p><pre class="kj kk kl km gt mz na nb nc aw nd bi"><span id="5718" class="ne md it na b gy nf ng l nh ni">t.test(training_res,holdout_res)</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nw"><img src="../Images/be1f9cc1f0643ce8d64a3115a0df9ee5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1212/format:webp/1*zATHQwG2YvpapXdUtzytSg.png"/></div></figure><p id="a8be" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">同样，高于 5%的 p 值可以让我们知道<strong class="lb iu">没有足够的理由</strong>假设平均值是不同的。</p><h2 id="1eff" class="ne md it bd me nk nl dn mi nm nn dp mm li no np mo lm nq nr mq lq ns nt ms nu bi translated">f 检验</h2><p id="1409" class="pw-post-body-paragraph kz la it lb b lc mu ju le lf mv jx lh li mw lk ll lm mx lo lp lq my ls lt lu im bi translated">在我们检查了平均值之后，就有了<strong class="lb iu">方差</strong>。我们显然希望维持残差显示一个与训练残差没有太大不同的行为<strong class="lb iu"/>，因此我们可以<strong class="lb iu">比较两个集合的方差</strong>，并检查维持方差是否高于训练方差。</p><p id="ac5e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">检验方差是否大于另一个方差的一个好测试是<strong class="lb iu"> F 检验</strong>，但是它只对<strong class="lb iu">正态分布残差</strong>有效。如果分布不正常，测试可能会给出错误的结果。</p><p id="54d3" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">所以，如果我们真的想使用这个测试，我们必须使用(例如)夏皮罗-维尔克测试来检查残差的正态性。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nx"><img src="../Images/3de668814a512b4c3cc32fcef7b602fa.png" data-original-src="https://miro.medium.com/v2/resize:fit:664/format:webp/1*weqN15sgUVWOkgILhgZuZQ.png"/></div></figure><p id="ce32" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">两个 p 值都高于 5%，因此我们可以说两个集合<strong class="lb iu">都显示正态分布残差</strong>。我们可以放心地继续进行 f 检验。</p><pre class="kj kk kl km gt mz na nb nc aw nd bi"><span id="8959" class="ne md it na b gy nf ng l nh ni">var.test(training_res,holdout_res)</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ny"><img src="../Images/5142fe4fd63b17765f027aaf5421597e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1194/format:webp/1*9U7V6m7OZP3fU_0uyxy0Mg.png"/></div></figure><p id="0978" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">p 值为 72%,大于 5%,可以说这两个集合具有相同的方差。</p><h2 id="9351" class="ne md it bd me nk nl dn mi nm nn dp mm li no np mo lm nq nr mq lq ns nt ms nu bi translated">科尔莫戈罗夫-斯米尔诺夫试验</h2><p id="84a1" class="pw-post-body-paragraph kz la it lb b lc mu ju le lf mv jx lh li mw lk ll lm mx lo lp lq my ls lt lu im bi translated">KS 测试非常通用，在许多情况下都很有用。一般来说，我们期望，如果我们的模型工作良好，保持残差的<strong class="lb iu">概率分布</strong>与训练残差的概率分布<strong class="lb iu">相似。创建 KS 检验是为了比较概率分布，因此它可用于此目的。然而，它带有一些近似值，对我们的分析可能是危险的。概率分布之间的显著差异可能隐藏在测试的一般考虑中。最后，KS 分布只有在某种近似下才是已知的，因此 p 值也是已知的；所以我建议谨慎使用这个测试。</strong></p><pre class="kj kk kl km gt mz na nb nc aw nd bi"><span id="4e11" class="ne md it na b gy nf ng l nh ni">ks.test(training_res,holdout_res)</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nz"><img src="../Images/4aef9b8ffbdf0ed071b97edd0cfa41e9.png" data-original-src="https://miro.medium.com/v2/resize:fit:794/format:webp/1*N6n6Z3uVthNORi95RWcDmw.png"/></div></figure><p id="73d0" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">同样，大的 p 值可以让我们知道这两个分布是相同的。</p><h2 id="2cfc" class="ne md it bd me nk nl dn mi nm nn dp mm li no np mo lm nq nr mq lq ns nt ms nu bi translated">情节</h2><p id="9c6d" class="pw-post-body-paragraph kz la it lb b lc mu ju le lf mv jx lh li mw lk ll lm mx lo lp lq my ls lt lu im bi translated">我在大学的一位教授通常说:“你必须用你的眼睛来看数据”。在机器学习中，肯定是这样的。</p><p id="b24c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">查看回归数据的最佳方式是通过<strong class="lb iu">绘制</strong>预测值与维持集中的真实值。在理想状态下，我们期望这些点位于穿过原点的<strong class="lb iu"> 45 度线</strong>上(公式为<em class="oa"> y = x </em>)。这些点离这条线越近，回归越好。如果我们的数据在笛卡儿平面上形成了一个不成形的斑点，那肯定有问题。</p><pre class="kj kk kl km gt mz na nb nc aw nd bi"><span id="68d1" class="ne md it na b gy nf ng l nh ni">plot(holdout$Sepal.Length,predict(m,holdout))<br/>abline(0,1)</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ob"><img src="../Images/cb9a79c6a41dc72fa48879b8351279a7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*jYnaEfRNl7pmxy_w4NlaQg.png"/></div></div></figure><p id="dbcc" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">嗯，本来可以更好的，但也不是完全错了。点近似位于直线上。</p><h2 id="ab97" class="ne md it bd me nk nl dn mi nm nn dp mm li no np mo lm nq nr mq lq ns nt ms nu bi translated">图的 t 检验</h2><p id="c1ec" class="pw-post-body-paragraph kz la it lb b lc mu ju le lf mv jx lh li mw lk ll lm mx lo lp lq my ls lt lu im bi translated">最后，我们可以根据前面的图计算一条线性回归线，并检查其截距在统计上是否不等于零，其斜率在统计上是否不等于 1。为了进行这些检查，我们可以使用一个简单的线性模型和学生 t 检验背后的统计理论。</p><p id="121f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">记住具有 n-1 个自由度的<em class="oa"> t </em>变量的定义:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi oc"><img src="../Images/498382b3c2a343d5b28571cd3d79af45.png" data-original-src="https://miro.medium.com/v2/resize:fit:300/format:webp/0*92yF9LZ7LHbyfree.png"/></div></figure><p id="e6cf" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">当我们在线性模型上使用 R 的<em class="oa">总结</em>函数时，它给出了参数的估计及其标准误差(即<em class="oa"> t </em>定义的完整分母)。</p><p id="db59" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">对于截距，我们有<em class="oa"> mu = 0 </em>，而斜率有<em class="oa"> mu = 1 </em>。</p><pre class="kj kk kl km gt mz na nb nc aw nd bi"><span id="e418" class="ne md it na b gy nf ng l nh ni">test_model = lm(real ~ predicted, data.frame(real=holdout$Sepal.Length,predicted=predict(m,holdout)))<br/>s = summary(test_model)</span><span id="21b2" class="ne md it na b gy nj ng l nh ni">intercept =  s$coefficients["(Intercept)","Estimate"]<br/>intercept_error = s$coefficients["(Intercept)","Std. Error"]<br/>slope = s$coefficients["predicted","Estimate"]<br/>slope_error = s$coefficients["predicted","Std. Error"]</span><span id="684c" class="ne md it na b gy nj ng l nh ni">t_intercept = intercept/intercept_error</span><span id="ec85" class="ne md it na b gy nj ng l nh ni">t_slope = (slope-1)/slope_error</span></pre><p id="e14a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">现在我们有了<em class="oa"> t </em>值，因此我们可以执行双边 t 检验来计算 p 值。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi od"><img src="../Images/4bf83d47c97a7d7c9ef90fec5f284833.png" data-original-src="https://miro.medium.com/v2/resize:fit:776/format:webp/1*wy076s-nK13R3-S3IjRb0A.png"/></div></figure><p id="3c9a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">它们大于 5%，但绝对值不太高。</p><h1 id="940b" class="mc md it bd me mf oe mh mi mj of ml mm jz og ka mo kc oh kd mq kf oi kg ms mt bi translated">哪种方法是最好的？</h1><p id="8321" class="pw-post-body-paragraph kz la it lb b lc mu ju le lf mv jx lh li mw lk ll lm mx lo lp lq my ls lt lu im bi translated">照例要看问题。如果残差是<strong class="lb iu">正态分布</strong>，t 检验和 f 检验就足够了。如果不是，也许在使用 Kolmogorov-Smirnov 测试之前，第一个图可以帮助我们发现宏观偏差。</p><p id="c272" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">然而，非正态分布的残差应该总是<strong class="lb iu">在我们的头脑中拉响警报</strong>，让我们寻找一些我们还没有考虑到的<strong class="lb iu">隐藏现象</strong>。</p><h1 id="6c09" class="mc md it bd me mf oe mh mi mj of ml mm jz og ka mo kc oh kd mq kf oi kg ms mt bi translated">结论</h1><p id="840c" class="pw-post-body-paragraph kz la it lb b lc mu ju le lf mv jx lh li mw lk ll lm mx lo lp lq my ls lt lu im bi translated">在这篇短文中，我向您展示了一些计算回归模型的良好程度的方法。虽然有许多可能的方法来衡量它，但这些简单的技术在许多情况下非常有用，并且很容易向非技术观众解释。</p></div></div>    
</body>
</html>