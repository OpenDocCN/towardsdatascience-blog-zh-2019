<html>
<head>
<title>Understanding CNN (Convolutional Neural Network)</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">了解 CNN(卷积神经网络)</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/understanding-cnn-convolutional-neural-network-69fd626ee7d4?source=collection_archive---------3-----------------------#2019-12-23">https://towardsdatascience.com/understanding-cnn-convolutional-neural-network-69fd626ee7d4?source=collection_archive---------3-----------------------#2019-12-23</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><h2 id="05df" class="ir is it bd b dl iu iv iw ix iy iz dk ja translated" aria-label="kicker paragraph">数据科学家的技术说明</h2><div class=""/><div class=""><h2 id="906a" class="pw-subtitle-paragraph jz jc it bd b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq dk translated">你学习图像分类深度学习的第一步</h2></div><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi kr"><img src="../Images/6244e78c81e4f04af3bd06e46db1db06.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*8PLiK23Z3ZjoiGsy"/></div></div><figcaption class="ld le gj gh gi lf lg bd b be z dk">Source <a class="ae lh" href="https://unsplash.com/photos/fYnyfx3UBxk" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><blockquote class="li lj lk"><p id="15d0" class="ll lm ln lo b lp lq kd lr ls lt kg lu lv lw lx ly lz ma mb mc md me mf mg mh im bi translated">想象一下 Google 相册:对于你所有的图片，你是如何用物体来标记的？要不要一个一个贴标签？可以搜索一下你最新的马里兰鸡快照吗？进入 CNN！</p></blockquote><h1 id="4df1" class="mi mj it bd mk ml mm mn mo mp mq mr ms ki mt kj mu kl mv km mw ko mx kp my mz bi translated">理解图像分类</h1><blockquote class="li lj lk"><p id="f444" class="ll lm ln lo b lp lq kd lr ls lt kg lu lv lw lx ly lz ma mb mc md me mf mg mh im bi translated">图像分类定义图像对象，并从标记的例子中标记这些图像。</p></blockquote><p id="3a7e" class="pw-post-body-paragraph ll lm it lo b lp lq kd lr ls lt kg lu na lw lx ly nb ma mb mc nc me mf mg mh im bi translated">我们的大脑是快速判断物体的大师。当你进入一家杂货店时，你可以把香蕉和鞋子等其他商品分开。我 2 岁的侄女知道如何区分猫和狗。</p><p id="4d23" class="pw-post-body-paragraph ll lm it lo b lp lq kd lr ls lt kg lu na lw lx ly nb ma mb mc nc me mf mg mh im bi translated">然而，用计算机来教这些分类是非常困难的。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi nd"><img src="../Images/94c28c5fc8da303eba3f71f958df7086.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*PiqtkepRtZC02_0j3GNw3g.png"/></div></div><figcaption class="ld le gj gh gi lf lg bd b be z dk">My search for the word “cat”</figcaption></figure><p id="45a7" class="pw-post-body-paragraph ll lm it lo b lp lq kd lr ls lt kg lu na lw lx ly nb ma mb mc nc me mf mg mh im bi translated">看看这些图片。在几个惊鸿一瞥之内，你应该已经意识到，在猫的形象中间，有几个来自音乐剧《猫》的女演员。也有一些是猫涂鸦的图片，但不是猫。那么我们如何教会我们的计算机理解这些图像呢？</p><h1 id="848e" class="mi mj it bd mk ml mm mn mo mp mq mr ms ki mt kj mu kl mv km mw ko mx kp my mz bi translated">经典图像分类</h1><p id="a99e" class="pw-post-body-paragraph ll lm it lo b lp ne kd lr ls nf kg lu na ng lx ly nb nh mb mc nc ni mf mg mh im bi translated">过去，图像分类模型使用原始像素对图像进行分类。您可以通过颜色直方图和边缘检测对猫进行分类，边缘检测允许您通过颜色和耳朵形状对猫进行分类。这种方法是成功的，但是直到该方法遇到更复杂的变体。</p><div class="ks kt ku kv gt ab cb"><figure class="nj kw nk nl nm nn no paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><img src="../Images/f9e3ea726be7c28209633599ace6f2f9.png" data-original-src="https://miro.medium.com/v2/resize:fit:858/0*W8wIkmPcC0p_dPNz"/></div></figure><figure class="nj kw np nl nm nn no paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><img src="../Images/6ff98cfd15e5bc3596d1b25021a3b78a.png" data-original-src="https://miro.medium.com/v2/resize:fit:572/format:webp/0*qvb71TVJ9bRgOwo5.jpg"/></div></figure><figure class="nj kw np nl nm nn no paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><img src="../Images/b797b02ec48e93c55de2a094ee343c74.png" data-original-src="https://miro.medium.com/v2/resize:fit:572/format:webp/0*gd57eyZom8oknC5S.jpg"/></div><figcaption class="ld le gj gh gi lf lg bd b be z dk nq di nr ns">Imagine if our classifiers only specify cats by their black color and ear shape. Are all of these pictures cats?</figcaption></figure></div><p id="1c0b" class="pw-post-body-paragraph ll lm it lo b lp lq kd lr ls lt kg lu na lw lx ly nb ma mb mc nc me mf mg mh im bi translated">这就是经典图像识别失败的地方，因为模型没有考虑其他特征。但是这些<em class="ln">的其他特征</em>是什么呢？需要一个一个讲型号吗？你会发现这即使不是不可能，也是一件非常麻烦的事。</p><h1 id="9054" class="mi mj it bd mk ml mm mn mo mp mq mr ms ki mt kj mu kl mv km mw ko mx kp my mz bi translated">介绍卷积神经网络(CNN)</h1><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi nt"><img src="../Images/d73f2d64598dd1eeecb5c9856589a86f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*78--J5vGoBls_Hbc.jpeg"/></div></div><figcaption class="ld le gj gh gi lf lg bd b be z dk">CNN Architecture</figcaption></figure><p id="7f35" class="pw-post-body-paragraph ll lm it lo b lp lq kd lr ls lt kg lu na lw lx ly nb ma mb mc nc me mf mg mh im bi translated">CNN 是一种神经网络模型，它允许我们提取图像内容的更高表示。与传统的图像识别不同，在传统的图像识别中，您需要自己定义图像特征，CNN 获取图像的原始像素数据，训练模型，然后自动提取特征以进行更好的分类。</p><p id="557e" class="pw-post-body-paragraph ll lm it lo b lp lq kd lr ls lt kg lu na lw lx ly nb ma mb mc nc me mf mg mh im bi translated">让我们来看看下面的视错觉，了解 CNN 是如何工作的。</p><h2 id="7fe4" class="nu mj it bd mk nv nw dn mo nx ny dp ms na nz oa mu nb ob oc mw nc od oe my iz bi translated">CNN 的直觉——想象一个视错觉</h2><div class="ks kt ku kv gt ab cb"><figure class="nj kw of nl nm nn no paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><img src="../Images/42db9b20d9b95392d2a62ae60f305dc0.png" data-original-src="https://miro.medium.com/v2/resize:fit:988/format:webp/0*ubFYiqbo4fJLbvcg.jpg"/></div></figure><figure class="nj kw og nl nm nn no paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><img src="../Images/ddf6ffa51f2f72d544393064f5da1db9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1014/format:webp/1*ZD2k1GKX42xIXFnoIXSmNw.png"/></div><figcaption class="ld le gj gh gi lf lg bd b be z dk oh di oi ns">Psychologist Edwin Boring introduced the painting of “My Wife and My Mother-in-Law” where the figure seems to morph from young lady to old woman, to the public in 1930. (Source)</figcaption></figure></div><p id="759c" class="pw-post-body-paragraph ll lm it lo b lp lq kd lr ls lt kg lu na lw lx ly nb ma mb mc nc me mf mg mh im bi translated">考虑这个图像。你看到一位年轻女士还是一位老奶奶？如果你把焦点放在图像中间的一个点上，你会看到一位年轻的女士。然而，如果你把焦点放在图像中下方的黑色条纹上，你会看到一位老太太。请看图片上的红色方框。</p><p id="f0ac" class="pw-post-body-paragraph ll lm it lo b lp lq kd lr ls lt kg lu na lw lx ly nb ma mb mc nc me mf mg mh im bi translated">这张图片提供了人类如何识别图像的见解。因为人类的大脑被设计用来捕捉模式以对物体进行分类，所以改变你观察的焦点也会改变你对整体图像的理解。</p><p id="3cbd" class="pw-post-body-paragraph ll lm it lo b lp lq kd lr ls lt kg lu na lw lx ly nb ma mb mc nc me mf mg mh im bi translated">与人类大脑的工作方式类似，CNN 区分图像中有意义的特征，以便对图像进行整体分类。</p><h1 id="7ecb" class="mi mj it bd mk ml mm mn mo mp mq mr ms ki mt kj mu kl mv km mw ko mx kp my mz bi translated">CNN 原理</h1><h2 id="ed45" class="nu mj it bd mk nv nw dn mo nx ny dp ms na nz oa mu nb ob oc mw nc od oe my iz bi translated">盘旋</h2><p id="7a92" class="pw-post-body-paragraph ll lm it lo b lp ne kd lr ls nf kg lu na ng lx ly nb nh mb mc nc ni mf mg mh im bi translated">卷积通过图像扫描窗口，然后计算其输入和过滤点积像素值。这允许卷积强调相关特征。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi oj"><img src="../Images/110fda9be32c6b831d4fbb141163b34e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*VxQvrbcOaduumKYzoGLjOQ.png"/></div></div><figcaption class="ld le gj gh gi lf lg bd b be z dk">1D Convolution Operation with features(filter)</figcaption></figure><p id="b749" class="pw-post-body-paragraph ll lm it lo b lp lq kd lr ls lt kg lu na lw lx ly nb ma mb mc nc me mf mg mh im bi translated">看看这个输入。我们将用一个小窗口包住窗口元素，用点乘它与过滤器元素，并保存输出。我们将重复每个操作以导出 5 个输出元素作为[0，0，0，1，0]。从这个输出中，我们可以知道序列 4 中的特征变化(1 变成 0)。过滤器很好地识别了输入值。同样，这也发生在 2D 卷积。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi ok"><img src="../Images/e29bd5dba88efc22fa2fa3fbf246cf4a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*Lxtbs0P1NdWwdUxb"/></div></div><figcaption class="ld le gj gh gi lf lg bd b be z dk">2D Convolution Operation with features(filter) — <a class="ae lh" href="https://github.com/PetarV-/TikZ/tree/master/2D%20Convolution" rel="noopener ugc nofollow" target="_blank">Source</a></figcaption></figure><p id="c508" class="pw-post-body-paragraph ll lm it lo b lp lq kd lr ls lt kg lu na lw lx ly nb ma mb mc nc me mf mg mh im bi translated">通过这种计算，您可以从输入图像中检测出特定的特征，并生成强调重要特征的<strong class="lo jd">特征图</strong>(卷积特征)。这些卷积特征将总是根据受梯度下降影响的滤波器值而变化，以最小化预测损失。</p><p id="671f" class="pw-post-body-paragraph ll lm it lo b lp lq kd lr ls lt kg lu na lw lx ly nb ma mb mc nc me mf mg mh im bi translated">此外，部署的过滤器越多，CNN 提取的特征就越多。这允许发现更多的特征，但是代价是更多的训练时间。有一个甜蜜点的层数，通常，我会把 150 x 150 大小的图像 6。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi ol"><img src="../Images/e6cd90bcf61fb0ab0128274a6a0ef9a6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1370/0*iADec-3T1pLI9P_9"/></div><figcaption class="ld le gj gh gi lf lg bd b be z dk">Feature map in each layer of CNN (<a class="ae lh" href="https://stackoverflow.com/questions/52741291/creating-a-cnn-model-in-keras-with-feature-maps-from-each-of-the-previous-filter" rel="noopener ugc nofollow" target="_blank">source</a>)</figcaption></figure><p id="a13e" class="pw-post-body-paragraph ll lm it lo b lp lq kd lr ls lt kg lu na lw lx ly nb ma mb mc nc me mf mg mh im bi translated">然而，边角值呢。它们没有足够的相邻块来适合过滤器。我们应该移除它们吗？</p><p id="77a1" class="pw-post-body-paragraph ll lm it lo b lp lq kd lr ls lt kg lu na lw lx ly nb ma mb mc nc me mf mg mh im bi translated">不，因为你会丢失重要信息。因此，你要做的反而是<strong class="lo jd">填充；</strong>用 0 填充相邻的特征图输出。通过将 0 插入其相邻像素，您不再需要排除这些像素。</p><p id="535d" class="pw-post-body-paragraph ll lm it lo b lp lq kd lr ls lt kg lu na lw lx ly nb ma mb mc nc me mf mg mh im bi translated">本质上，这些卷积层促进了<strong class="lo jd">权重共享</strong>来检查内核中的像素，并开发视觉上下文来对图像进行分类。与权重独立的神经网络(NN)不同，CNN 的权重被附加到相邻像素，以提取图像每个部分的特征。</p><h2 id="70e4" class="nu mj it bd mk nv nw dn mo nx ny dp ms na nz oa mu nb ob oc mw nc od oe my iz bi translated">最大池化</h2><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi om"><img src="../Images/8af4f869b7d1fbea883d1a296d1439bf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*0sIbLSH-rU8v40sB.jpeg"/></div></div><figcaption class="ld le gj gh gi lf lg bd b be z dk">We take the maximum max pooling slices of each 2x2 filtered areas (<a class="ae lh" href="http://cs231n.github.io/convolutional-networks/" rel="noopener ugc nofollow" target="_blank">source</a>)</figcaption></figure><p id="01ce" class="pw-post-body-paragraph ll lm it lo b lp lq kd lr ls lt kg lu na lw lx ly nb ma mb mc nc me mf mg mh im bi translated">CNN 使用<strong class="lo jd"> max pooling </strong>用 max summary 替换输出，以减少数据大小和处理时间。这使您可以确定产生最大影响的特征，并降低过度拟合的风险。</p><p id="a996" class="pw-post-body-paragraph ll lm it lo b lp lq kd lr ls lt kg lu na lw lx ly nb ma mb mc nc me mf mg mh im bi translated">最大池有两个<strong class="lo jd">超参数</strong>:步幅和大小。步幅将决定价值池的跳跃，而大小将决定每次跳跃中价值池的大小。</p><h2 id="8faa" class="nu mj it bd mk nv nw dn mo nx ny dp ms na nz oa mu nb ob oc mw nc od oe my iz bi translated">激活函数(ReLU 和 Sigmoid)</h2><p id="70cc" class="pw-post-body-paragraph ll lm it lo b lp ne kd lr ls nf kg lu na ng lx ly nb nh mb mc nc ni mf mg mh im bi translated">在每个卷积和最大池操作之后，我们可以应用校正线性单元(ReLU)。ReLU 函数模拟我们的神经元在“足够大的刺激”下的激活，从而为值 x&gt;0 引入非线性，如果不满足条件，则返回 0。这种方法对于解决梯度递减是有效的。在 ReLU 激活功能后，非常小的权重将保持为 0。</p><h1 id="c155" class="mi mj it bd mk ml mm mn mo mp mq mr ms ki mt kj mu kl mv km mw ko mx kp my mz bi translated">CNN 大图+全连接层</h1><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi on"><img src="../Images/83df01e2e8a3d6fd7197638038fe44c9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*EJ08nVFu6LD1h2mZ"/></div></div><figcaption class="ld le gj gh gi lf lg bd b be z dk">CNN architectures with convolutions, pooling (subsampling), and fully connected layers for softmax activation function</figcaption></figure><p id="a3c5" class="pw-post-body-paragraph ll lm it lo b lp lq kd lr ls lt kg lu na lw lx ly nb ma mb mc nc me mf mg mh im bi translated">最后，我们将使用全连接图层(FCL)提供卷积和最大池要素地图输出。我们将特征输出展平为列向量，并将其前馈到 FCL。我们用<strong class="lo jd"> softmax </strong>激活函数包装我们的特征，该函数为每个可能的标签分配十进制概率，其总和为 1.0。前一层中的每个节点都连接到最后一层，并表示要输出哪个不同的标签。</p><p id="f72e" class="pw-post-body-paragraph ll lm it lo b lp lq kd lr ls lt kg lu na lw lx ly nb ma mb mc nc me mf mg mh im bi translated"><strong class="lo jd">最终结果如何？</strong>你将能够对狗和猫的图片进行如下分类。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi oo"><img src="../Images/f346b6c572e0104764257f55e29dc93a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*loet1nSd4EwCIYcR"/></div></div><figcaption class="ld le gj gh gi lf lg bd b be z dk">Finding the perfect image classification with softmax (<a class="ae lh" href="https://colab.sandbox.google.com/drive/1v0VWuWnmP1Ns-PAUCiksxbzpy3AopXjc" rel="noopener ugc nofollow" target="_blank">Source</a>)</figcaption></figure><h1 id="193e" class="mi mj it bd mk ml mm mn mo mp mq mr ms ki mt kj mu kl mv km mw ko mx kp my mz bi translated">CNN 中的清洗和防止过拟合</h1><p id="6677" class="pw-post-body-paragraph ll lm it lo b lp ne kd lr ls nf kg lu na ng lx ly nb nh mb mc nc ni mf mg mh im bi translated">不幸的是，CNN 也不能幸免于过度拟合。如果没有适当的监控，模型可能会被训练得太多，以至于不能概括看不见的数据。通过我的经验，我犯了许多初学者过度拟合的错误，我是如何解决它们的如下:</p><h2 id="ed31" class="nu mj it bd mk nv nw dn mo nx ny dp ms na nz oa mu nb ob oc mw nc od oe my iz bi translated">使用测试集作为验证集来测试模型</h2><p id="b4d7" class="pw-post-body-paragraph ll lm it lo b lp ne kd lr ls nf kg lu na ng lx ly nb nh mb mc nc ni mf mg mh im bi translated">即使我们不使用测试集来训练模型，模型也可以用测试集来调整损失函数。这将使训练基于测试数据集，并且是过度拟合的常见原因。因此，在训练过程中，我们需要使用<strong class="lo jd">验证集</strong>，然后用看不见的测试集最终测试完成的模型。</p><h2 id="51ab" class="nu mj it bd mk nv nw dn mo nx ny dp ms na nz oa mu nb ob oc mw nc od oe my iz bi translated">数据集相对较小</h2><p id="ad14" class="pw-post-body-paragraph ll lm it lo b lp ne kd lr ls nf kg lu na ng lx ly nb nh mb mc nc ni mf mg mh im bi translated">当数据集很小时，很容易专注于几组规则而忘记概括。例如，如果您的模型只将靴子视为鞋子，那么下次您展示高跟鞋时，它不会将其识别为鞋子。</p><p id="f5fe" class="pw-post-body-paragraph ll lm it lo b lp lq kd lr ls lt kg lu na lw lx ly nb ma mb mc nc me mf mg mh im bi translated">因此，在训练数据集很小的情况下，你需要人为地提振训练样本的多样性和数量。这样做的一个方法是添加<strong class="lo jd">图像增强</strong>并创建新的变体。这些包括转换图像和创建尺寸变化，如缩放、裁剪、翻转等。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi op"><img src="../Images/a1125da27e9087e1e252b0e2a86148b7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1200/0*m9G3r4C99KbneQsE"/></div><figcaption class="ld le gj gh gi lf lg bd b be z dk">Image augmentation <a class="ae lh" href="https://www.javatpoint.com/pytorch-data-augmentation-process" rel="noopener ugc nofollow" target="_blank">Source</a></figcaption></figure><h2 id="5386" class="nu mj it bd mk nv nw dn mo nx ny dp ms na nz oa mu nb ob oc mw nc od oe my iz bi translated">过度记忆</h2><p id="91bf" class="pw-post-body-paragraph ll lm it lo b lp ne kd lr ls nf kg lu na ng lx ly nb nh mb mc nc ni mf mg mh im bi translated">过多的神经元、层和训练时期会促进记忆并抑制概括。你训练你的模型越多，它就越有可能变得过于专业化。为了解决这个问题，你可以通过去除一些隐藏层和每层的神经元来降低复杂度。</p><p id="d839" class="pw-post-body-paragraph ll lm it lo b lp lq kd lr ls lt kg lu na lw lx ly nb ma mb mc nc me mf mg mh im bi translated">或者，您也可以使用正则化技术，如<strong class="lo jd"> Dropout </strong>来移除每个梯度步长训练中的激活单元。每个历元训练去激活不同的神经元。</p><p id="0c7f" class="pw-post-body-paragraph ll lm it lo b lp lq kd lr ls lt kg lu na lw lx ly nb ma mb mc nc me mf mg mh im bi translated">因为梯度步骤的数量通常很高，所以所有神经元将平均具有相同的丢失发生率。直觉上，你退出的越多，你的模型记忆的可能性就越小。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi oq"><img src="../Images/4ba335f5abcabfacbd3b7aa66aebbae2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*qElVyiza3Bs-z-k6"/></div></div><figcaption class="ld le gj gh gi lf lg bd b be z dk">Drop out images</figcaption></figure><h2 id="f8ee" class="nu mj it bd mk nv nw dn mo nx ny dp ms na nz oa mu nb ob oc mw nc od oe my iz bi translated">处理彩色图像</h2><p id="1e0c" class="pw-post-body-paragraph ll lm it lo b lp ne kd lr ls nf kg lu na ng lx ly nb nh mb mc nc ni mf mg mh im bi translated">您还可以轻松地包含具有 3 层颜色通道的图像:红绿蓝(RGB)。在卷积过程中，您为每个颜色通道使用 3 个单独的卷积，并训练 3 级过滤器堆栈。这允许您检索 3D 要素地图。</p><h1 id="4a6e" class="mi mj it bd mk ml mm mn mo mp mq mr ms ki mt kj mu kl mv km mw ko mx kp my mz bi translated">我们如何做得更好？—迁移学习</h1><p id="af51" class="pw-post-body-paragraph ll lm it lo b lp ne kd lr ls nf kg lu na ng lx ly nb nh mb mc nc ni mf mg mh im bi translated">随着用例变得复杂，模型的复杂性也需要提高。有了几层 CNN，你可以确定简单的特征来分类狗和猫。然而，在深度学习阶段，你可能希望从图像中分类更复杂的对象，并使用更多的数据。因此，<strong class="lo jd">迁移学习</strong>允许你利用现有的模型快速分类，而不是自己训练它们。</p><p id="f02a" class="pw-post-body-paragraph ll lm it lo b lp lq kd lr ls lt kg lu na lw lx ly nb ma mb mc nc me mf mg mh im bi translated"><strong class="lo jd">迁移学习</strong>是一种将现有模型重新用于当前模型的技术。你可以在现有模型的基础上制作，这些模型是由专家精心设计的，并用数百万张图片进行了训练。</p><p id="763f" class="pw-post-body-paragraph ll lm it lo b lp lq kd lr ls lt kg lu na lw lx ly nb ma mb mc nc me mf mg mh im bi translated">然而，你需要遵循一些注意事项。首先，您需要修改最终层以匹配可能的类的数量。第二，您需要冻结参数，并将训练好的模型变量设置为不可变的。这阻止了模型的显著变化。</p><p id="464c" class="pw-post-body-paragraph ll lm it lo b lp lq kd lr ls lt kg lu na lw lx ly nb ma mb mc nc me mf mg mh im bi translated">你可以使用的一个著名的迁移学习工具是 MobileNet。它是为内存和计算资源较少的移动设备创建的。你可以在<a class="ae lh" href="https://www.tensorflow.org/hub" rel="noopener ugc nofollow" target="_blank"> Tensorflow Hub </a>找到 MobileNet，里面聚集了很多预训练的模型。你可以简单地在这些模型上添加你自己的 FCL 层。</p><h1 id="7378" class="mi mj it bd mk ml mm mn mo mp mq mr ms ki mt kj mu kl mv km mw ko mx kp my mz bi translated">结论:CNN 感知我们的视觉世界</h1><p id="bf11" class="pw-post-body-paragraph ll lm it lo b lp ne kd lr ls nf kg lu na ng lx ly nb nh mb mc nc ni mf mg mh im bi translated">CNN 是一门很难的课程，但却是一门值得学习的技术。它教会我们如何感知图像，并学习对图像和视频进行分类的有用应用。在学习了 CNN 之后，我意识到我可以在谷歌的项目中使用这个来检测网络钓鱼攻击。</p><p id="d9ca" class="pw-post-body-paragraph ll lm it lo b lp lq kd lr ls lt kg lu na lw lx ly nb ma mb mc nc me mf mg mh im bi translated">我也意识到对 CNN 的了解很深。多年来，CNN 变体有许多改进，包括最新的 ResNet，它甚至在 ImageNet 分类中击败了人类评论者。</p><ol class=""><li id="bd2c" class="or os it lo b lp lq ls lt na ot nb ou nc ov mh ow ox oy oz bi translated">乐网(杨乐村，1998 年)</li><li id="6a88" class="or os it lo b lp pa ls pb na pc nb pd nc pe mh ow ox oy oz bi translated">亚历克斯·奈特(2012 年)</li><li id="7d4e" class="or os it lo b lp pa ls pb na pc nb pd nc pe mh ow ox oy oz bi translated">VGGNet (2014) —深度神经网络</li><li id="5d52" class="or os it lo b lp pa ls pb na pc nb pd nc pe mh ow ox oy oz bi translated">初始模块 Google Net (2014) —堆栈模块层</li><li id="9dad" class="or os it lo b lp pa ls pb na pc nb pd nc pe mh ow ox oy oz bi translated">ResNet (2015) —首个超过人类图像网络的网络</li></ol><p id="134d" class="pw-post-body-paragraph ll lm it lo b lp lq kd lr ls lt kg lu na lw lx ly nb ma mb mc nc me mf mg mh im bi translated">对我来说，我写这篇文章是为了我在谷歌工作的一个项目探索我对 CNN 的基本理解。因此，如果我在写作中犯了任何错误或知识空白，请随时给我反馈。索利·迪奥·格洛丽亚。</p><h1 id="2cb8" class="mi mj it bd mk ml mm mn mo mp mq mr ms ki mt kj mu kl mv km mw ko mx kp my mz bi translated">参考</h1><p id="69d9" class="pw-post-body-paragraph ll lm it lo b lp ne kd lr ls nf kg lu na ng lx ly nb nh mb mc nc ni mf mg mh im bi translated">我真诚地希望这能激起你更深入了解 CNN 的兴趣。如果你有，这里有一些你可能会觉得非常有用的资源:</p><ol class=""><li id="e690" class="or os it lo b lp lq ls lt na ot nb ou nc ov mh ow ox oy oz bi translated"><a class="ae lh" href="http://yann.lecun.com/exdb/publis/pdf/lecun-99.pdf" rel="noopener ugc nofollow" target="_blank">CNN 的 Yann LeCun 论文</a></li><li id="20bf" class="or os it lo b lp pa ls pb na pc nb pd nc pe mh ow ox oy oz bi translated"><a class="ae lh" href="http://cs231n.github.io/convolutional-networks/" rel="noopener ugc nofollow" target="_blank"> CS 231 斯坦福</a></li><li id="bccf" class="or os it lo b lp pa ls pb na pc nb pd nc pe mh ow ox oy oz bi translated"><a class="ae lh" href="https://developers.google.com/machine-learning/practica/image-classification/convolutional-neural-networks" rel="noopener ugc nofollow" target="_blank">谷歌 ML CNN </a></li><li id="0ab3" class="or os it lo b lp pa ls pb na pc nb pd nc pe mh ow ox oy oz bi translated">和许多其他人</li></ol><h1 id="9545" class="mi mj it bd mk ml mm mn mo mp mq mr ms ki mt kj mu kl mv km mw ko mx kp my mz bi translated">最后…</h1><p id="1f0c" class="pw-post-body-paragraph ll lm it lo b lp ne kd lr ls nf kg lu na ng lx ly nb nh mb mc nc ni mf mg mh im bi translated">我真的希望这是一本很棒的读物，是你发展和创新的灵感来源。</p><p id="8f37" class="pw-post-body-paragraph ll lm it lo b lp lq kd lr ls lt kg lu na lw lx ly nb ma mb mc nc me mf mg mh im bi translated">请在下面<strong class="lo jd">评论</strong>以获得建议和反馈。就像你一样，我也在学习如何成为一名更好的数据科学家和工程师。请帮助我改进，以便我可以在后续的文章发布中更好地帮助您。</p><p id="a453" class="pw-post-body-paragraph ll lm it lo b lp lq kd lr ls lt kg lu na lw lx ly nb ma mb mc nc me mf mg mh im bi translated">谢谢大家，编码快乐:)</p><h1 id="ee24" class="mi mj it bd mk ml mm mn mo mp mq mr ms ki mt kj mu kl mv km mw ko mx kp my mz bi translated">关于作者</h1><p id="59a1" class="pw-post-body-paragraph ll lm it lo b lp ne kd lr ls nf kg lu na ng lx ly nb nh mb mc nc ni mf mg mh im bi translated">Vincent Tatan 是一名数据和技术爱好者，拥有在 Google LLC、Visa Inc .和 Lazada 实施微服务架构、商业智能和分析管道项目<a class="ae lh" href="https://bit.ly/2I8jkWV.?source=post_page---------------------------" rel="noopener ugc nofollow" target="_blank">的相关工作经验。</a></p><p id="46f4" class="pw-post-body-paragraph ll lm it lo b lp lq kd lr ls lt kg lu na lw lx ly nb ma mb mc nc me mf mg mh im bi translated">Vincent 是土生土长的印度尼西亚人，在解决问题方面成绩斐然，擅长全栈开发、数据分析和战略规划。</p><p id="548b" class="pw-post-body-paragraph ll lm it lo b lp lq kd lr ls lt kg lu na lw lx ly nb ma mb mc nc me mf mg mh im bi translated">他一直积极咨询 SMU BI &amp; Analytics Club，指导来自不同背景的有抱负的数据科学家和工程师，并为企业开发他们的产品开放他的专业知识。</p><p id="82c4" class="pw-post-body-paragraph ll lm it lo b lp lq kd lr ls lt kg lu na lw lx ly nb ma mb mc nc me mf mg mh im bi translated">文森特还在 10 日至 8 日开放了他的一对一导师服务，指导你如何在谷歌、Visa 或其他大型科技公司获得你梦想中的数据科学家/工程师工作。</p><ol class=""><li id="28cb" class="or os it lo b lp lq ls lt na ot nb ou nc ov mh ow ox oy oz bi translated"><a class="ae lh" href="https://forms.gle/iyo4oJtqKpQ1MgWy5" rel="noopener ugc nofollow" target="_blank"> <strong class="lo jd">如果你需要转介到谷歌，请通知他。谷歌在招人！</strong> </a></li><li id="c46c" class="or os it lo b lp pa ls pb na pc nb pd nc pe mh ow ox oy oz bi translated">如果你正在寻找良师益友，请在这里预约你和他的约会。</li></ol><p id="fef8" class="pw-post-body-paragraph ll lm it lo b lp lq kd lr ls lt kg lu na lw lx ly nb ma mb mc nc me mf mg mh im bi translated">最后，请通过<a class="ae lh" href="http://www.linkedin.com/in/vincenttatan/?source=post_page---------------------------" rel="noopener ugc nofollow" target="_blank"><strong class="lo jd">LinkedIn</strong></a><strong class="lo jd">，</strong><a class="ae lh" href="https://medium.com/@vincentkernn?source=post_page---------------------------" rel="noopener"><strong class="lo jd">Medium</strong></a><strong class="lo jd">或</strong> <a class="ae lh" href="https://www.youtube.com/user/vincelance1/videos?source=post_page---------------------------" rel="noopener ugc nofollow" target="_blank"> <strong class="lo jd"> Youtube 频道</strong> </a>联系文森特</p></div></div>    
</body>
</html>