<html>
<head>
<title>Markov Chains and HMMs</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">马尔可夫链和 hmm</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/markov-chains-and-hmms-ceaf2c854788?source=collection_archive---------5-----------------------#2019-05-05">https://towardsdatascience.com/markov-chains-and-hmms-ceaf2c854788?source=collection_archive---------5-----------------------#2019-05-05</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><h2 id="c35d" class="ir is it bd b dl iu iv iw ix iy iz dk ja translated" aria-label="kicker paragraph"><a class="ae ep" href="https://medium.com/towards-data-science/inside-ai/home" rel="noopener">内部 AI </a></h2><div class=""/><div class=""><h2 id="dda3" class="pw-subtitle-paragraph jz jc it bd b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq dk translated">主要概念、属性和应用</h2></div><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi kr"><img src="../Images/a37566f1fbd8d608e1497da474937405.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*sbX_jJghgjVCtIST2RBuUA.png"/></div></div><figcaption class="ld le gj gh gi lf lg bd b be z dk">Hidden Markov</figcaption></figure><p id="1b6f" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">在本文中，我们将关注马尔可夫模型，何时何地应该使用它们，以及隐马尔可夫模型。本文将着重于理论部分。在第二篇文章中，我将展示这些主题的 Python 实现。</p><p id="21f3" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">马尔可夫模型，尤其是隐马尔可夫模型(HMM)用于:</p><ul class=""><li id="a0d2" class="md me it lj b lk ll ln lo lq mf lu mg ly mh mc mi mj mk ml bi translated">语音识别</li><li id="61a6" class="md me it lj b lk mm ln mn lq mo lu mp ly mq mc mi mj mk ml bi translated">书写识别</li><li id="6bbb" class="md me it lj b lk mm ln mn lq mo lu mp ly mq mc mi mj mk ml bi translated">物体或人脸检测</li><li id="da77" class="md me it lj b lk mm ln mn lq mo lu mp ly mq mc mi mj mk ml bi translated">经济情景生成和特定财务任务</li><li id="2982" class="md me it lj b lk mm ln mn lq mo lu mp ly mq mc mi mj mk ml bi translated">和几个 NLP 任务…</li></ul><p id="e199" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">本文原载于我的个人博客:【https://maelfabien.github.io/machinelearning/HMM_1/#<a class="ae mr" href="https://maelfabien.github.io/machinelearning/HMM_1/#" rel="noopener ugc nofollow" target="_blank"/></p><p id="d7db" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">我在这个资源库上发布我所有的文章和相应的代码:</p><div class="ms mt gp gr mu mv"><a href="https://github.com/maelfabien/Machine_Learning_Tutorials" rel="noopener  ugc nofollow" target="_blank"><div class="mw ab fo"><div class="mx ab my cl cj mz"><h2 class="bd jd gy z fp na fr fs nb fu fw jc bi translated">mael fabien/机器学习教程</h2><div class="nc l"><h3 class="bd b gy z fp na fr fs nb fu fw dk translated">本报告包含练习、代码、教程和我的个人博客文章</h3></div><div class="nd l"><p class="bd b dl z fp na fr fs nb fu fw dk translated">github.com</p></div></div><div class="ne l"><div class="nf l ng nh ni ne nj lb mv"/></div></div></a></div><p id="085b" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">不要犹豫开始回购:)</p></div><div class="ab cl nk nl hx nm" role="separator"><span class="nn bw bk no np nq"/><span class="nn bw bk no np nq"/><span class="nn bw bk no np"/></div><div class="im in io ip iq"><h1 id="d2df" class="nr ns it bd nt nu nv nw nx ny nz oa ob ki oc kj od kl oe km of ko og kp oh oi bi translated">一.随机模型</h1><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi oj"><img src="../Images/7b571e4d1bc4fe5e57eb4b6bfa9dd613.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*j07ERLp2eH3tZOmSDUu26w.png"/></div></div><figcaption class="ld le gj gh gi lf lg bd b be z dk">Discrete-Time Stochastic Process</figcaption></figure><p id="6004" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">让我们从定义什么是随机模型开始。它本质上是一个离散时间过程，在时间 1，2，…取值，称为“<strong class="lj jd">状态</strong>，观察到:q1，q2，…”。状态简单地对应于过程的实际值，通常由有限空间定义:S=1，…Q。</p><p id="2d15" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">该过程从初始状态<strong class="lj jd">开始</strong> q1。然后，根据<strong class="lj jd">转移概率</strong>，我们在状态之间移动。我们可以使用<strong class="lj jd">贝叶斯法则</strong>计算状态序列的概率:</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi ok"><img src="../Images/d76732a21baea3fc2e2a4f7e39425318.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*mOCwj9zW2klnHNDbZS2gvA.png"/></div></div></figure><p id="db0d" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">为了描述模型的特征，我们需要:</p><ul class=""><li id="c0f5" class="md me it lj b lk ll ln lo lq mf lu mg ly mh mc mi mj mk ml bi translated">初始概率 P(q1)</li><li id="0786" class="md me it lj b lk mm ln mn lq mo lu mp ly mq mc mi mj mk ml bi translated">所有的转移概率</li></ul><p id="6370" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">正如你可能猜到的，这很难实现，因为我们需要知道很多参数。</p><h1 id="4c66" class="nr ns it bd nt nu ol nw nx ny om oa ob ki on kj od kl oo km of ko op kp oh oi bi translated">二。离散时间马尔可夫链模型(DTMC)</h1><h2 id="72d0" class="oq ns it bd nt or os dn nx ot ou dp ob lq ov ow od lu ox oy of ly oz pa oh iz bi translated">1.什么是马尔可夫链？</h2><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi pb"><img src="../Images/68ef5b972e7327c6039a9b88aacf2f45.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*2kFuQGVtyg2lfFq13ZOkjg.png"/></div></div><figcaption class="ld le gj gh gi lf lg bd b be z dk">DTMC</figcaption></figure><p id="c499" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">离散时间马尔可夫链(DTMC)是<em class="pc">时间和事件的离散随机过程</em>。马尔可夫链依赖于马尔可夫特性，即在过程中有一个<strong class="lj jd">有限的相关性</strong>:</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi pd"><img src="../Images/d58e64f0622ce68d34d32d21bf57c630.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*1tuIE_ZZX3dS-Y4qAxrFEA.png"/></div></div></figure><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi pe"><img src="../Images/3a43b8252129479cf709181220ef7df0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*-PYKJqHV5P7ztye3QcXq1Q.png"/></div></div></figure><p id="f39e" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">让我们来说明这一点:考虑一个简单的迷宫，其中有一只老鼠被困。我们将把<em class="pc"> qt 表示在<em class="pc"> t 步之后老鼠所处的迷宫的位置</em>。我们假设老鼠对它在迷宫中走过的路程没有记忆(T21)。它只是按照写在每一步棋旁边的概率，随机地走到那个位置。</em></p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi pf"><img src="../Images/5f9df3f4fd9d8b28ad5f9ecaa56ddb6e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*NrSeOyJbXoeNU2TPp-SXNQ.png"/></div></div><figcaption class="ld le gj gh gi lf lg bd b be z dk">DTMC Illustration</figcaption></figure><p id="6e00" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">这里的状态可以代表很多东西，包括在 NLP 中。例如，我们可以:</p><ul class=""><li id="adb4" class="md me it lj b lk ll ln lo lq mf lu mg ly mh mc mi mj mk ml bi translated">1 =名词，</li><li id="9c33" class="md me it lj b lk mm ln mn lq mo lu mp ly mq mc mi mj mk ml bi translated">2 =动词，</li><li id="d0ee" class="md me it lj b lk mm ln mn lq mo lu mp ly mq mc mi mj mk ml bi translated">3 =形容词…</li></ul><p id="0f25" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">例如，我们会对名词后有动词的概率感兴趣。</p><h2 id="e60f" class="oq ns it bd nt or os dn nx ot ou dp ob lq ov ow od lu ox oy of ly oz pa oh iz bi translated">2.转移概率</h2><p id="44cf" class="pw-post-body-paragraph lh li it lj b lk pg kd lm ln ph kg lp lq pi ls lt lu pj lw lx ly pk ma mb mc im bi translated">如果离散时间马尔可夫链的转移概率不依赖于时间 t，则称其为<strong class="lj jd">齐次</strong>:</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi pl"><img src="../Images/7315edd4aeb24797f10b2dbf576a1f46.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Cxi5Ic_Jc5EM0Gfu8ijP0g.png"/></div></div></figure><p id="ad4e" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">我们可以将该过程概括为一个<strong class="lj jd">转移矩阵</strong>，表示为 A =【AIJ】，i ∈ 1…Q，j ∈ 1…Q。如果:</p><ul class=""><li id="e6a1" class="md me it lj b lk ll ln lo lq mf lu mg ly mh mc mi mj mk ml bi translated">所有条目都是非负的</li><li id="1fb6" class="md me it lj b lk mm ln mn lq mo lu mp ly mq mc mi mj mk ml bi translated">每行总计为 1</li></ul><p id="9b3c" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">在我们的例子中，转移矩阵是:</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi pm"><img src="../Images/bd4a6746f542fda016e2b62ff5b02010.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*AXRd_-qQ2RievukN2rtX8Q.png"/></div></div><figcaption class="ld le gj gh gi lf lg bd b be z dk">Transition matrix</figcaption></figure><p id="8010" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">注意，如果 a 是随机的，那么 A^n 也是随机的。</p><h2 id="2afa" class="oq ns it bd nt or os dn nx ot ou dp ob lq ov ow od lu ox oy of ly oz pa oh iz bi translated">3.州</h2><p id="0b43" class="pw-post-body-paragraph lh li it lj b lk pg kd lm ln ph kg lp lq pi ls lt lu pj lw lx ly pk ma mb mc im bi translated">描述一个状态有几种方式。设 pii 为离开 I 后回到状态 I 的概率:</p><ul class=""><li id="17a6" class="md me it lj b lk ll ln lo lq mf lu mg ly mh mc mi mj mk ml bi translated">如果 pii &lt;为 1，则状态 I 为<strong class="lj jd">瞬态</strong></li><li id="64de" class="md me it lj b lk mm ln mn lq mo lu mp ly mq mc mi mj mk ml bi translated">如果 pii=1，状态 I 是<strong class="lj jd">循环的</strong></li><li id="5246" class="md me it lj b lk mm ln mn lq mo lu mp ly mq mc mi mj mk ml bi translated">如果 aii=1，则状态 I 正在<strong class="lj jd">吸收</strong></li></ul><p id="9576" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">因此，如果返回到表示为 Tii 的相同状态之前的平均时间是有限的，则状态是正循环的。</p><p id="b429" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">如果一个状态 j 可以从任何其它状态 I 经过有限步到达，则 DTMC 是不可约的。不可约的 DTMC 实际上是一个强连通的图。</p><p id="56a5" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">如果离散时间马尔可夫链只能在大于 1 的某个整数的倍数处返回状态，那么该链中的状态就是周期性的。</p><p id="07a8" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">例如:</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi pn"><img src="../Images/38a8b6cbdd5234a34761dfb73f2a3b5e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*CahMjgPubeMnxQ0lAmzs6Q.png"/></div></div><figcaption class="ld le gj gh gi lf lg bd b be z dk">Periodic Markov Chain</figcaption></figure><p id="103d" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">否则称为<strong class="lj jd">非周期性</strong>。具有自循环的状态总是非周期性的。</p><h2 id="aa79" class="oq ns it bd nt or os dn nx ot ou dp ob lq ov ow od lu ox oy of ly oz pa oh iz bi translated">4.逗留时间</h2><p id="56b4" class="pw-post-body-paragraph lh li it lj b lk pg kd lm ln ph kg lp lq pi ls lt lu pj lw lx ly pk ma mb mc im bi translated">设 Ti 是跳到其他状态之前在状态 I 花费的时间。</p><p id="e7c6" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">然后，Ti，即<strong class="lj jd">逗留时间</strong>，遵循<strong class="lj jd">几何分布</strong>:</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi po"><img src="../Images/796a750b5ba568abe63f16148e1984a1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*qEXDpRQRptWQ82RWNcBzhQ.png"/></div></div></figure><p id="34dd" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">预期花费的平均时间是 E(T)=1 / aii</p><h2 id="bb0b" class="oq ns it bd nt or os dn nx ot ou dp ob lq ov ow od lu ox oy of ly oz pa oh iz bi translated">5.m 步转换</h2><p id="afca" class="pw-post-body-paragraph lh li it lj b lk pg kd lm ln ph kg lp lq pi ls lt lu pj lw lx ly pk ma mb mc im bi translated">在 m 个步骤中从 I 到 j 的概率表示为:</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi pp"><img src="../Images/43c51b3f686d7732a7fe29d311ecab1d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*GbSBnwQmrkafHrv8QONlSw.png"/></div></div><figcaption class="ld le gj gh gi lf lg bd b be z dk">M-step transition</figcaption></figure><p id="9de5" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">我们可以将 a22(4)视为时间 t=4 时鼠标位于位置 2 的概率。因此，从 I 到 j 正好 n 步的概率由 fij(n)给出，其中:</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi pq"><img src="../Images/256f9b13daca91aaffdc87bdc647fd2d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*lOS35q5TRl46AbG2hHH8gw.png"/></div></div></figure><h2 id="7f76" class="oq ns it bd nt or os dn nx ot ou dp ob lq ov ow od lu ox oy of ly oz pa oh iz bi translated">6.状态的概率分布</h2><p id="37c5" class="pw-post-body-paragraph lh li it lj b lk pg kd lm ln ph kg lp lq pi ls lt lu pj lw lx ly pk ma mb mc im bi translated">设πi(n)是在时间 n 处于状态 I 的<strong class="lj jd">概率</strong>:πI(n)= P(Xn = I)</p><p id="53e1" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">那么，π(n)=[π1(n)，π2(n)，…]是概率分布的向量，它取决于:</p><ul class=""><li id="d011" class="md me it lj b lk ll ln lo lq mf lu mg ly mh mc mi mj mk ml bi translated">初始转移矩阵 A</li><li id="e41a" class="md me it lj b lk mm ln mn lq mo lu mp ly mq mc mi mj mk ml bi translated">初始分布π(0)</li></ul><p id="b04c" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">注意π(n+1) = π(n)A，递归地:</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi pr"><img src="../Images/3647f6561279ccd426d0fc2248328d53.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*z2qyM4235InJhNwv0PnyqQ.png"/></div></div></figure><p id="8cc9" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">对于不可约/非周期 DTMC，分布π(n)收敛到一个极限向量π，它与π(0)无关，是π = πP 的唯一解</p><p id="9093" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">并且∑i πi = 1</p><p id="af1a" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">πi 也叫<strong class="lj jd">定态概率，稳态或均衡分布。</strong></p><h2 id="6d18" class="oq ns it bd nt or os dn nx ot ou dp ob lq ov ow od lu ox oy of ly oz pa oh iz bi translated">7.生成序列</h2><p id="dc2f" class="pw-post-body-paragraph lh li it lj b lk pg kd lm ln ph kg lp lq pi ls lt lu pj lw lx ly pk ma mb mc im bi translated">为了模拟老鼠在迷宫中的路径，我们可能希望<strong class="lj jd">生成序列</strong>。</p><p id="803f" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">当我们想产生一个序列时，我们从一个初始状态 q1=1 开始。总的想法是:</p><ul class=""><li id="bf46" class="md me it lj b lk ll ln lo lq mf lu mg ly mh mc mi mj mk ml bi translated">我们选择一个随机数来知道我们应该从哪个状态开始</li><li id="0f89" class="md me it lj b lk mm ln mn lq mo lu mp ly mq mc mi mj mk ml bi translated">然后，选择一个随机数来知道我们移动到哪个状态</li></ul><p id="a488" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">假设我们有以下简单的模型:</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi ps"><img src="../Images/4f9fbcbb367711d329572b0e0d8e9d4b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*N1jB7j9JK3Nouj3TjNxHPw.png"/></div></div></figure><p id="34b5" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">这对应于下面的矩阵 A 和初始概率向量π:</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi pt"><img src="../Images/426b7ebc9e975bbc6a850d88f16fd841.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*VNEplI8y-7Yk8pW6gQh3zA.png"/></div></div></figure><p id="6566" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">生成器的工作方式如下，通过连续抽取随机数来识别哪个过渡是指。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi pu"><img src="../Images/05022c5e1e1cd8bf123dc79365e68feb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*hXLEPnda0iOk0zeIVtP52A.png"/></div></div><figcaption class="ld le gj gh gi lf lg bd b be z dk">Sequence Generation, Step-by-step</figcaption></figure><p id="5467" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">第一步，我们选择一个随机数，看看它在初始概率向量中的位置。这给了我们第一个状态。</p><p id="b79f" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">然后，我们选择下面的数字，它对应于状态 q1 的转移概率(矩阵 A 的第一行)。如果值小于 0.3，我们停留在 q1。否则，我们移到 q2。诸如此类…</p><h2 id="3490" class="oq ns it bd nt or os dn nx ot ou dp ob lq ov ow od lu ox oy of ly oz pa oh iz bi translated">8.解码序列</h2><p id="28e7" class="pw-post-body-paragraph lh li it lj b lk pg kd lm ln ph kg lp lq pi ls lt lu pj lw lx ly pk ma mb mc im bi translated">解码一个序列的目的是识别通向当前状态的最可能的路径。例如，如果鼠标处于状态 3，并经过 5 步到达那里，您需要确定最可能的路径。</p><h2 id="1eb4" class="oq ns it bd nt or os dn nx ot ou dp ob lq ov ow od lu ox oy of ly oz pa oh iz bi translated">9.用例</h2><p id="9b3b" class="pw-post-body-paragraph lh li it lj b lk pg kd lm ln ph kg lp lq pi ls lt lu pj lw lx ly pk ma mb mc im bi translated">可以使用马尔可夫链:</p><ul class=""><li id="49c2" class="md me it lj b lk ll ln lo lq mf lu mg ly mh mc mi mj mk ml bi translated">通过解码字符序列并识别最可能的语言来识别句子的语言。</li><li id="5474" class="md me it lj b lk mm ln mn lq mo lu mp ly mq mc mi mj mk ml bi translated">预测宏观经济形势，如市场崩溃和衰退与扩张之间的周期。</li><li id="5765" class="md me it lj b lk mm ln mn lq mo lu mp ly mq mc mi mj mk ml bi translated">预测资产和期权价格，并计算信用风险。</li><li id="0b78" class="md me it lj b lk mm ln mn lq mo lu mp ly mq mc mi mj mk ml bi">…</li></ul><h1 id="3624" class="nr ns it bd nt nu ol nw nx ny om oa ob ki on kj od kl oo km of ko op kp oh oi bi translated">三。隐马尔可夫模型</h1><p id="9f63" class="pw-post-body-paragraph lh li it lj b lk pg kd lm ln ph kg lp lq pi ls lt lu pj lw lx ly pk ma mb mc im bi translated">隐马尔可夫模型(HMM)广泛用于:</p><ul class=""><li id="c15a" class="md me it lj b lk ll ln lo lq mf lu mg ly mh mc mi mj mk ml bi translated">语音识别</li><li id="2f30" class="md me it lj b lk mm ln mn lq mo lu mp ly mq mc mi mj mk ml bi translated">书写识别</li><li id="fc22" class="md me it lj b lk mm ln mn lq mo lu mp ly mq mc mi mj mk ml bi translated">物体或人脸检测</li><li id="10b1" class="md me it lj b lk mm ln mn lq mo lu mp ly mq mc mi mj mk ml bi translated">词性标注和其他自然语言处理任务…</li></ul><p id="5aa2" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">我推荐看看 Luis Serrano 在 HMM 上做的介绍。</p><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="pv pw l"/></div></figure><p id="1a96" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">我们将把重点放在词性标注上。词性标注是一个过程，通过这个过程，我们能够将一个给定的单词标注为名词、代词、动词、副词…</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi px"><img src="../Images/3dca7c1efd2929e18465bb0ec4a5f189.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*9wZbAVDyeTPEvp4Gk8P4wg.png"/></div></div></figure><p id="cdaf" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">例如，PoS 可以用于文本到语音的转换或词义消歧。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi py"><img src="../Images/a253838c628b97b4b124bfb8a151525e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*JXCN1LKZw_Zp3LAzZFSwgA.png"/></div></div></figure><p id="9716" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">在这个具体情况下，同一个单词<code class="fe pz qa qb qc b">bear</code>有完全不同的意思，对应的 PoS 也因此不同。</p><p id="682f" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">让我们考虑下面的场景。在你的办公室里，有两个同事经常聊天。你知道他们要么谈论工作<strong class="lj jd"/>要么谈论假期<strong class="lj jd"/>。因为他们看起来很酷，你想加入他们。但是你离理解整个对话太远了，你只能听到句子中的一些单词</p><p id="23b9" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">在加入对话之前，为了不显得太怪异，你想猜猜他说的是<strong class="lj jd">工作</strong>还是<strong class="lj jd">假期</strong>。例如，你的朋友可能会说这样的句子:</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi qd"><img src="../Images/63dfcf6afb5484b063438ab464e99652.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*73lRyo2_hWXk2dSm2CFT7Q.png"/></div></div></figure><h2 id="223c" class="oq ns it bd nt or os dn nx ot ou dp ob lq ov ow od lu ox oy of ly oz pa oh iz bi translated">1.排放概率</h2><p id="4fce" class="pw-post-body-paragraph lh li it lj b lk pg kd lm ln ph kg lp lq pi ls lt lu pj lw lx ly pk ma mb mc im bi translated">你只听清楚<strong class="lj jd"> python </strong>或<strong class="lj jd"> bear </strong>这几个字，并试着猜测句子的上下文。由于你的朋友都是 Python 开发人员，所以当他们谈论工作时，他们 80%的时间都在谈论 Python。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi qe"><img src="../Images/f411eb1a37adb380aa4314cff25f0718.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*M3BPYdWP0jI29YgCIhWSpQ.png"/></div></div></figure><p id="dc59" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">这些概率被称为<strong class="lj jd">排放概率</strong>。</p><h2 id="a3f5" class="oq ns it bd nt or os dn nx ot ou dp ob lq ov ow od lu ox oy of ly oz pa oh iz bi translated">2.转移概率</h2><p id="b856" class="pw-post-body-paragraph lh li it lj b lk pg kd lm ln ph kg lp lq pi ls lt lu pj lw lx ly pk ma mb mc im bi translated">你听着他们的对话，每分钟都在试图理解这个话题。你朋友的谈话有某种连贯性。事实上，如果一个小时他们谈论工作，下一分钟他们谈论假期的可能性更低。</p><p id="f898" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">我们可以为这种情况定义我们称之为<strong class="lj jd">的隐马尔可夫模型</strong>:</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi qf"><img src="../Images/2f6e3dcd7f2862a2b4b3adc35205f8bf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Sc5eKgjGrEjdI9_QuEgmwQ.png"/></div></div></figure><p id="7c5a" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">改变或不改变话题的概率被称为<strong class="lj jd">转移概率</strong>。</p><ul class=""><li id="650f" class="md me it lj b lk ll ln lo lq mf lu mg ly mh mc mi mj mk ml bi translated">你理解的词语被称为<strong class="lj jd">观察</strong>，因为你观察它们。</li><li id="6986" class="md me it lj b lk mm ln mn lq mo lu mp ly mq mc mi mj mk ml bi translated">他们谈论的主题被称为<strong class="lj jd">隐藏状态</strong>，因为你无法观察到它。</li></ul><h2 id="3832" class="oq ns it bd nt or os dn nx ot ou dp ob lq ov ow od lu ox oy of ly oz pa oh iz bi translated">3.离散时间隐马尔可夫模型</h2><p id="6673" class="pw-post-body-paragraph lh li it lj b lk pg kd lm ln ph kg lp lq pi ls lt lu pj lw lx ly pk ma mb mc im bi translated">HMM λ是由两个随机过程组合而成的序列:</p><ul class=""><li id="8fd8" class="md me it lj b lk ll ln lo lq mf lu mg ly mh mc mi mj mk ml bi translated">一个<strong class="lj jd">观察到</strong>一个:O=o1，o2，…，oT，这里的话</li><li id="9de1" class="md me it lj b lk mm ln mn lq mo lu mp ly mq mc mi mj mk ml bi translated">一个<strong class="lj jd">隐藏的</strong>一:q=q1，q2，…qT，这里是谈话的话题。这被称为过程的状态。</li></ul><p id="9c3c" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">HMM 模型由下式定义:</p><ul class=""><li id="79c6" class="md me it lj b lk ll ln lo lq mf lu mg ly mh mc mi mj mk ml bi translated"><strong class="lj jd">初始概率的向量</strong> π=[π1，…πq]，其中πi=P(q1=i)</li><li id="b7f5" class="md me it lj b lk mm ln mn lq mo lu mp ly mq mc mi mj mk ml bi translated"><strong class="lj jd">未观察到的</strong>序列 a 的<strong class="lj jd">转移矩阵</strong>:a =[AIJ]= p(Qt = j∣qt1 = j)</li><li id="a381" class="md me it lj b lk mm ln mn lq mo lu mp ly mq mc mi mj mk ml bi translated"><strong class="lj jd">观察值的<strong class="lj jd">概率</strong>矩阵</strong>b =【bki】= p(ot = sk∣Qt = I)</li></ul><p id="38a1" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">HMMs 背后的<strong class="lj jd">主要假设</strong>有哪些？</p><ul class=""><li id="a37e" class="md me it lj b lk ll ln lo lq mf lu mg ly mh mc mi mj mk ml bi translated"><strong class="lj jd">观测值对隐藏态的条件独立性</strong>:p(O1，…，ot，…，oT ∣ q1，…，qt，…，qT，λ) = ∏i P(ot ∣ qt，λ)</li><li id="b1fa" class="md me it lj b lk mm ln mn lq mo lu mp ly mq mc mi mj mk ml bi translated"><strong class="lj jd">平稳马尔可夫链</strong> : P(q1，q2，…，Qt)= p(q1)p(q2∣q1)p(q3∣q2)…p(qt∣qt−1)</li><li id="a2b9" class="md me it lj b lk mm ln mn lq mo lu mp ly mq mc mi mj mk ml bi translated"><strong class="lj jd">观测值和状态序列的联合概率</strong>:p(O1，o2，…oT，q1，…，qT ∣ λ) = P(o1，…，oT ∣ q1，…，qT，λ) P(q1，…，qT)</li></ul><p id="ee5e" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">HMM 是<em class="pc">贝叶斯网络</em>的一个子案例。</p><h2 id="9f23" class="oq ns it bd nt or os dn nx ot ou dp ob lq ov ow od lu ox oy of ly oz pa oh iz bi translated">4.求转移概率</h2><p id="eef0" class="pw-post-body-paragraph lh li it lj b lk pg kd lm ln ph kg lp lq pi ls lt lu pj lw lx ly pk ma mb mc im bi translated">跃迁概率是基于我们所做的观察。我们可以假设，在仔细听完之后，每一分钟，我们都能理解他们谈论的话题。不过，这并没有给我们提供他们目前正在谈论的话题的全部信息。</p><p id="943b" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">在过去的 15 分钟里，你有 15 次观察，<strong class="lj jd"> W </strong>表示工作，<strong class="lj jd"> H </strong>表示假期。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi qg"><img src="../Images/01b5ebb80913c11a0c0ce2fff1119a23.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*lzQ0NiunrnAgwLNeGlvI2w.png"/></div></div></figure><p id="a18c" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">我们注意到，在五分之二的情况下，话题工作导致话题假期，这解释了上图中的转移概率。</p><h2 id="935e" class="oq ns it bd nt or os dn nx ot ou dp ob lq ov ow od lu ox oy of ly oz pa oh iz bi translated">5.找出排放概率</h2><p id="a8e6" class="pw-post-body-paragraph lh li it lj b lk pg kd lm ln ph kg lp lq pi ls lt lu pj lw lx ly pk ma mb mc im bi translated">因为我们对他们讨论的话题有观察，并且我们观察了讨论中使用的词语，我们可以定义<em class="pc">排放概率的估计值</em>:</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi qh"><img src="../Images/164c00bde39926f82fed1cf42300e2a1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*F7Tf0K3OTiVWlN4Cqq_j9w.png"/></div></div></figure><h2 id="5ea1" class="oq ns it bd nt or os dn nx ot ou dp ob lq ov ow od lu ox oy of ly oz pa oh iz bi translated">6.随机时间内某个主题的概率</h2><p id="eaa2" class="pw-post-body-paragraph lh li it lj b lk pg kd lm ln ph kg lp lq pi ls lt lu pj lw lx ly pk ma mb mc im bi translated">假设你要去喝咖啡，当你回来的时候，他们还在说话。你根本不知道他们在说什么！在那个随机时刻，他们谈论工作或假期的概率是多少？</p><p id="5c7e" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">我们可以从之前的观察中数出:10 次他们谈论假期，5 次谈论工作。因此，它表明我们有 1/3 的机会让他们谈论工作，2/3 的机会让他们谈论假期。</p><h2 id="ccf8" class="oq ns it bd nt or os dn nx ot ou dp ob lq ov ow od lu ox oy of ly oz pa oh iz bi translated">7.如果听到“Python”这个词，每个题目的概率是多少？</h2><p id="21e2" class="pw-post-body-paragraph lh li it lj b lk pg kd lm ln ph kg lp lq pi ls lt lu pj lw lx ly pk ma mb mc im bi translated">如果你听到“Python”这个词，那么这个话题是工作还是假期的概率就是用贝叶斯定理定义的！</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi qi"><img src="../Images/ebe45de3a0b12ab23fed403c3f5143d2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*JYeugFznmtose03WeLOgaA.png"/></div></div></figure><p id="1649" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">接近 57%。</p><h2 id="e6ee" class="oq ns it bd nt or os dn nx ot ou dp ob lq ov ow od lu ox oy of ly oz pa oh iz bi translated">8.如果你听到一个单词序列，每个题目的概率是多少？</h2><p id="9073" class="pw-post-body-paragraph lh li it lj b lk pg kd lm ln ph kg lp lq pi ls lt lu pj lw lx ly pk ma mb mc im bi translated">让我们从连续两次观察开始。假设我们连续听到“Python”和“Bear”这两个词。有哪些可能的组合？</p><ul class=""><li id="f7dd" class="md me it lj b lk ll ln lo lq mf lu mg ly mh mc mi mj mk ml bi translated">巨蟒和工作联系在一起，熊和工作联系在一起</li><li id="abbd" class="md me it lj b lk mm ln mn lq mo lu mp ly mq mc mi mj mk ml bi translated">蟒蛇和假期联系在一起，熊和工作联系在一起</li><li id="e2fd" class="md me it lj b lk mm ln mn lq mo lu mp ly mq mc mi mj mk ml bi translated">蟒蛇和假期联系在一起，熊和假期联系在一起</li><li id="a245" class="md me it lj b lk mm ln mn lq mo lu mp ly mq mc mi mj mk ml bi translated">蟒蛇和工作联系在一起，熊和假期联系在一起</li></ul><p id="93a9" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">这些场景可以这样总结:</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi qj"><img src="../Images/b1c9bc3bf532ad80b20d138c3d777499.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*svekxbAz0Zw-x4nSvjc0wQ.png"/></div></div></figure><p id="d6e8" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">所以最有可能隐藏的状态就是节假日和假期。如果你听到两个以上的单词呢？假设是 50？计算所有可能的路径变得非常具有挑战性！这就是为什么<strong class="lj jd">维特比算法</strong>被引入，以克服这个问题。</p><h2 id="2fea" class="oq ns it bd nt or os dn nx ot ou dp ob lq ov ow od lu ox oy of ly oz pa oh iz bi translated">9.维特比算法解码</h2><p id="8b2a" class="pw-post-body-paragraph lh li it lj b lk pg kd lm ln ph kg lp lq pi ls lt lu pj lw lx ly pk ma mb mc im bi translated"><strong class="lj jd">维特比算法</strong>背后的主要思想是，当我们计算最优<em class="pc">解码</em>序列时，我们并不保留所有的潜在路径，而是<em class="pc">只保留最大似然对应的路径。</em></p><p id="0b61" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">它是这样工作的。我们从一系列观察到的事件开始，比如说<code class="fe pz qa qb qc b">Python, Python, Python, Bear, Bear, Python</code>。这个序列简单地对应于一个观察序列:P(o1，o2，…，oT ∣ λm)</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi qk"><img src="../Images/86bda58a303d10f375edd751846f51f6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*RA92MCl_T0aWCGye-oIq-Q.png"/></div></div></figure><p id="c531" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">对于第一个观察，假设我们观察 Python，主题是 Work 的概率是它是 Work 的概率乘以假设它是 Work，它是 Python 的概率。</p><p id="7deb" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">最可能的状态序列简单地对应于:</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi ql"><img src="../Images/1049d27052eabfe18e54239e0a61a8d7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ezrx-7GaANMvlJqd4pik2w.png"/></div></div></figure><p id="edbb" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">然后我们可以继续下一个观察。接下来会发生什么:</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi po"><img src="../Images/a69433ca2fde92e44a7e982198f3934a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*jmcGOR00-rFUuGnwyzqAyQ.png"/></div></div></figure><p id="3771" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">对于每个位置，我们使用前一个主题是工作或假期的事实来计算概率，对于每个情况，我们只保留最大值，因为我们的目标是找到最大可能性。因此，下一步是对假日主题进行同样的估计，并保持两条路径之间的最大值。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi oj"><img src="../Images/17efe0d38b8d0be2602291fc28fb8ed9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*8xjJQhuHtTa9x8BhY-Li5A.png"/></div></div></figure><p id="dea6" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">如果您解码整个序列，您应该会得到与此类似的东西(我已经对每一步的值进行了舍入，所以您可能会得到稍微不同的结果):</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi oj"><img src="../Images/c07b93c8547341c1b012c4ef8cccc372.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*qE99xEZQy0nIqYjtyC9f0g.png"/></div></div></figure><p id="6da1" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">因此，当我们观察<code class="fe pz qa qb qc b">Python, Python, Python, Bear, Bear, Python</code>时，最有可能的序列是<code class="fe pz qa qb qc b">Work, Work, Work, Holidays, Holidays, Holidays</code>。</p><p id="4908" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">如果在这么长时间的跟踪之后，你终于去和你的同事聊天，你应该期待他们谈论假期:)</p><p id="f28c" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">在时间 T 结束于状态 I 并且对应于观测 o1，…，oT 的潜在状态的最佳序列的<strong class="lj jd">联合概率</strong>由δT(i)表示。这是上述可能的途径之一。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi oj"><img src="../Images/b5fcd198804d6acd9542a41673cbba79.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*V-qBu3Fbw39tBVmO28eg0A.png"/></div></div></figure><p id="2b9a" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">通过递归，可以表明:</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi qm"><img src="../Images/e44d2f01ca9192f18055bc554779e1d0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*V_gTpdrIJ0bE0BVVPmrLHg.png"/></div></div></figure><p id="5804" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">其中 bj 表示观察矩阵 B 的概率，aij 表示未观察序列的转移矩阵的值。这些参数是从一系列观察值和可用状态中估计出来的。δ就是我们在前进的每一步中取的最大值。</p><p id="3d97" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">我不会在这里详细讨论。你应该简单地记住有两种方法来解决维特比，<em class="pc">向前</em>(正如我们已经看到的)和<em class="pc">向后</em>。</p><p id="3e4c" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">当我们只观察到部分序列并且面对不完整的数据时，使用 EM 算法。</p><h2 id="d4c3" class="oq ns it bd nt or os dn nx ot ou dp ob lq ov ow od lu ox oy of ly oz pa oh iz bi translated">10.生成序列</h2><p id="2acb" class="pw-post-body-paragraph lh li it lj b lk pg kd lm ln ph kg lp lq pi ls lt lu pj lw lx ly pk ma mb mc im bi translated">正如我们在马尔可夫链中看到的，我们可以用 hmm 生成序列。为此，我们需要:</p><ul class=""><li id="31cd" class="md me it lj b lk ll ln lo lq mf lu mg ly mh mc mi mj mk ml bi translated">首先产生隐藏状态 q1</li><li id="0f6c" class="md me it lj b lk mm ln mn lq mo lu mp ly mq mc mi mj mk ml bi translated">从 q1 开始，生成 o1，例如 Work then Python</li><li id="3083" class="md me it lj b lk mm ln mn lq mo lu mp ly mq mc mi mj mk ml bi translated">然后产生 q1 到 q2 的转换</li><li id="81c9" class="md me it lj b lk mm ln mn lq mo lu mp ly mq mc mi mj mk ml bi translated">从 q2 生成 o2</li><li id="71cc" class="md me it lj b lk mm ln mn lq mo lu mp ly mq mc mi mj mk ml bi">…</li></ul><p id="8219" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">流程是如何运作的？如上所述，这是一个两步过程，我们首先生成状态，然后进行观察。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi qn"><img src="../Images/533a01572bd46a0e94f86d1f969bd9a5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*QoiIaUq9PbI0CMhQj4V-_Q.png"/></div></div><figcaption class="ld le gj gh gi lf lg bd b be z dk">Sequence Generation</figcaption></figure><h1 id="b285" class="nr ns it bd nt nu ol nw nx ny om oa ob ki on kj od kl oo km of ko op kp oh oi bi translated">结论:</h1><p id="228d" class="pw-post-body-paragraph lh li it lj b lk pg kd lm ln ph kg lp lq pi ls lt lu pj lw lx ly pk ma mb mc im bi">👏👏👏</p><p id="fa72" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">在本文中，我们介绍了马尔可夫链和 hmm 的基本理论，包括术语、假设、性质、序列生成和解码。</p><p id="046e" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">我希望这篇关于马尔可夫链和隐马尔可夫模型的介绍是有帮助的。我在下面的部分列出了我的消息来源。</p><p id="87a1" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">在下一篇文章中，我将尝试用 Python 来说明这些概念。</p><h1 id="ea20" class="nr ns it bd nt nu ol nw nx ny om oa ob ki on kj od kl oo km of ko op kp oh oi bi translated">来源:</h1><ul class=""><li id="dafe" class="md me it lj b lk pg ln ph lq qo lu qp ly qq mc mi mj mk ml bi translated">国家高级矿业学院:<a class="ae mr" href="https://www.emse.fr/~xie/SJTU/Ch4DMC.ppt" rel="noopener ugc nofollow" target="_blank">https://www.emse.fr/~xie/SJTU/Ch4DMC.ppt</a></li><li id="c3a6" class="md me it lj b lk mm ln mn lq mo lu mp ly mq mc mi mj mk ml bi translated">MVE220 财务风险:<a class="ae mr" href="http://www.math.chalmers.se/Stat/Grundutb/CTH/mve220/1617/redingprojects16-17/IntroMarkovChainsandApplications.pdf" rel="noopener ugc nofollow" target="_blank">http://www . math . chalmers . se/Stat/grund ub/CTH/mve 220/1617/reding projects 16-17/intromarkovchainsandapplications . pdf</a></li><li id="2e6a" class="md me it lj b lk mm ln mn lq mo lu mp ly mq mc mi mj mk ml bi translated">Udacity 的 HMMs:<a class="ae mr" href="https://www.youtube.com/watch?v=kqSzLo9fenk" rel="noopener ugc nofollow" target="_blank">https://www.youtube.com/watch?v=kqSzLo9fenk</a></li><li id="0aee" class="md me it lj b lk mm ln mn lq mo lu mp ly mq mc mi mj mk ml bi translated">个人博客主持人:<a class="ae mr" href="https://maelfabien.github.io/machinelearning/HMM_1/#" rel="noopener ugc nofollow" target="_blank">https://maelfabien.github.io/machinelearning/HMM_1/#</a></li><li id="b479" class="md me it lj b lk mm ln mn lq mo lu mp ly mq mc mi mj mk ml bi translated">个人博客嗯:<a class="ae mr" href="https://maelfabien.github.io/machinelearning/HMM_2/#" rel="noopener ugc nofollow" target="_blank">https://maelfabien.github.io/machinelearning/HMM_2/#</a></li></ul></div></div>    
</body>
</html>