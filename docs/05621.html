<html>
<head>
<title>5 Tips To Create A More Reliable Web Crawler</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">创建更可靠的网络爬虫的 5 个技巧</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/https-towardsdatascience-com-5-tips-to-create-a-more-reliable-web-crawler-3efb6878f8db?source=collection_archive---------6-----------------------#2019-08-18">https://towardsdatascience.com/https-towardsdatascience-com-5-tips-to-create-a-more-reliable-web-crawler-3efb6878f8db?source=collection_archive---------6-----------------------#2019-08-18</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="f3f9" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">提高你的网络爬虫的效率！</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/4b0649ef398aec2e622cf8f418281944.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*6Kcs2Xk8xtc-ncAPUaueUQ.jpeg"/></div></div></figure><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="ku kv l"/></div></figure><p id="ada4" class="pw-post-body-paragraph kw kx it ky b kz la ju lb lc ld jx le lf lg lh li lj lk ll lm ln lo lp lq lr im bi ls translated"><span class="l lt lu lv bm lw lx ly lz ma di"> W </span>当我在抓取网站时，网络爬虫被网站屏蔽可以说是最讨厌的情况。要成为真正的网络爬虫高手，你不仅要能够快速编写 XPath 或 CSS 选择器，而且你如何设计你的爬虫也很重要，尤其是从长远来看。</p><p id="e410" class="pw-post-body-paragraph kw kx it ky b kz la ju lb lc ld jx le lf lg lh li lj lk ll lm ln lo lp lq lr im bi translated">在我网络爬行旅程的第一年，我总是专注于如何抓取一个网站。能够搜集数据，清理和组织它，这个成就已经可以让我的一天。在爬越来越多的网站后，我发现有<strong class="ky iu">4</strong>T5】重要元素是建立一个伟大的网络爬虫最重要的。</p><p id="b40b" class="pw-post-body-paragraph kw kx it ky b kz la ju lb lc ld jx le lf lg lh li lj lk ll lm ln lo lp lq lr im bi translated">如何确定一个伟大的网络爬虫？您可能需要考虑以下几点:</p><h2 id="f5e8" class="mb mc it bd md me mf dn mg mh mi dp mj lf mk ml mm lj mn mo mp ln mq mr ms mt bi translated">爬虫的速度</h2><p id="296d" class="pw-post-body-paragraph kw kx it ky b kz mu ju lb lc mv jx le lf mw lh li lj mx ll lm ln my lp lq lr im bi translated">你能在有限的时间内收集数据吗？</p><h2 id="6f57" class="mb mc it bd md me mf dn mg mh mi dp mj lf mk ml mm lj mn mo mp ln mq mr ms mt bi translated">收集的数据的完整性</h2><p id="6050" class="pw-post-body-paragraph kw kx it ky b kz mu ju lb lc mv jx le lf mw lh li lj mx ll lm ln my lp lq lr im bi translated">你能收集到所有你感兴趣的数据吗？</p><h2 id="17ff" class="mb mc it bd md me mf dn mg mh mi dp mj lf mk ml mm lj mn mo mp ln mq mr ms mt bi translated">收集的数据的准确性</h2><p id="cff4" class="pw-post-body-paragraph kw kx it ky b kz mu ju lb lc mv jx le lf mw lh li lj mx ll lm ln my lp lq lr im bi translated">你如何确保你搜集的数据是准确的？</p><h2 id="154a" class="mb mc it bd md me mf dn mg mh mi dp mj lf mk ml mm lj mn mo mp ln mq mr ms mt bi translated">网络爬虫的可扩展性</h2><p id="2a09" class="pw-post-body-paragraph kw kx it ky b kz mu ju lb lc mv jx le lf mw lh li lj mx ll lm ln my lp lq lr im bi translated">当网站数量增加时，你能调整网络爬虫吗？</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi mz"><img src="../Images/2f5adbdf5b6f80a20d4878020dbf0e97.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*w_uvBqpNU3eH23FRF_yVrA.jpeg"/></div></div></figure><p id="eb4c" class="pw-post-body-paragraph kw kx it ky b kz la ju lb lc ld jx le lf lg lh li lj lk ll lm ln lo lp lq lr im bi translated">为了回答以上所有的问题，我将分享一些可以帮助你建立一个伟大的网络爬虫的技巧。</p></div><div class="ab cl na nb hx nc" role="separator"><span class="nd bw bk ne nf ng"/><span class="nd bw bk ne nf ng"/><span class="nd bw bk ne nf"/></div><div class="im in io ip iq"><h2 id="60e4" class="mb mc it bd md me mf dn mg mh mi dp mj lf mk ml mm lj mn mo mp ln mq mr ms mt bi translated">提示#1 减少你需要请求网页的次数。</h2><p id="e8e7" class="pw-post-body-paragraph kw kx it ky b kz mu ju lb lc mv jx le lf mw lh li lj mx ll lm ln my lp lq lr im bi translated">使用一个 web 抓取框架:<a class="ae nh" href="https://selenium-python.readthedocs.io/" rel="noopener ugc nofollow" target="_blank"> Selenium </a>为例。如果我们要刮这个网站:<a class="ae nh" href="https://www.yellowpages.com.sg/category/cleaning-services" rel="noopener ugc nofollow" target="_blank">https://www.yellowpages.com.sg/category/cleaning-services</a></p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ni"><img src="../Images/67cf8fb4c18175488f80fbaece7b3212.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Y1r_a9iAQdObfjzE5d8vQg.png"/></div></div></figure><p id="d66f" class="pw-post-body-paragraph kw kx it ky b kz la ju lb lc ld jx le lf lg lh li lj lk ll lm ln lo lp lq lr im bi translated">比方说，我们想要获得公司地址和描述的数据。所以，对于 Selenium，我们可能会使用<code class="fe nj nk nl nm b"><strong class="ky iu">driver.findElement</strong></code> <strong class="ky iu"> </strong>两次<strong class="ky iu"> </strong>到<strong class="ky iu"> </strong>分别检索<strong class="ky iu">地址</strong>和<strong class="ky iu">描述</strong>。更好的方法是使用驱动程序<strong class="ky iu">下载页面源</strong>并使用 BeautifulSoup 提取你需要的数据。总之，点击网站一次，而不是两次，这样不容易被发现！</p><p id="f559" class="pw-post-body-paragraph kw kx it ky b kz la ju lb lc ld jx le lf lg lh li lj lk ll lm ln lo lp lq lr im bi translated">另一种情况是，当我们在使用<code class="fe nj nk nl nm b"><strong class="ky iu">WebDriverWait</strong></code> ( <em class="nn">驱动</em>、<em class="nn">超时</em>、<em class="nn"> poll_frequency=0.5 </em>、<em class="nn"> ignored_exceptions=None </em>)等待页面满载时，记得将<code class="fe nj nk nl nm b"><strong class="ky iu">poll_frequency</strong></code>(调用之间的睡眠间隔)设置为一个较高的值，以最大限度地减少向网页发出请求的频率。更多详情可以通过这个<a class="ae nh" href="https://selenium-python.readthedocs.io/api.html" rel="noopener ugc nofollow" target="_blank">官方文档</a>阅读！</p></div><div class="ab cl na nb hx nc" role="separator"><span class="nd bw bk ne nf ng"/><span class="nd bw bk ne nf ng"/><span class="nd bw bk ne nf"/></div><div class="im in io ip iq"><h2 id="cec6" class="mb mc it bd md me mf dn mg mh mi dp mj lf mk ml mm lj mn mo mp ln mq mr ms mt bi translated">技巧#2 一旦擦除一条记录，就将数据写入 CSV</h2><p id="5f6e" class="pw-post-body-paragraph kw kx it ky b kz mu ju lb lc mv jx le lf mw lh li lj mx ll lm ln my lp lq lr im bi translated">以前当我抓取网站时，我将只输出一次记录——当所有记录都被抓取时。然而，这种方法可能不是完成任务的最聪明的方式。</p><p id="49ca" class="pw-post-body-paragraph kw kx it ky b kz la ju lb lc ld jx le lf lg lh li lj lk ll lm ln lo lp lq lr im bi translated">取而代之的一种方法是，在你抓取了一个记录之后，你需要写入这个文件，这样当问题发生时(例如你的计算机停止运行，或者你的程序因为发生错误而停止运行)，你可以从发生问题的网站开始，重新启动你的爬虫/抓取器:)</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi no"><img src="../Images/022cefed4e48c1e28b686d73cdaa1d03.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*t9pQvj1UAqt8CAeMpsmjmw.jpeg"/></div></div></figure><p id="93e7" class="pw-post-body-paragraph kw kx it ky b kz la ju lb lc ld jx le lf lg lh li lj lk ll lm ln lo lp lq lr im bi translated">对于我来说，我通常使用 python <a class="ae nh" href="https://docs.python.org/3/library/csv.html" rel="noopener ugc nofollow" target="_blank"> writerow 函数</a>将记录写入输出文件，这样我就可以从网站开始，如果我的 scraper 停止，我就不需要重新抓取所有以前废弃的数据。</p></div><div class="ab cl na nb hx nc" role="separator"><span class="nd bw bk ne nf ng"/><span class="nd bw bk ne nf ng"/><span class="nd bw bk ne nf"/></div><div class="im in io ip iq"><h2 id="39e2" class="mb mc it bd md me mf dn mg mh mi dp mj lf mk ml mm lj mn mo mp ln mq mr ms mt bi translated">技巧 3:减少被网站屏蔽的次数</h2><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi np"><img src="../Images/66046759d25737416328251ae632dd02.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*1jWbfeeONPcsUoRnwVmvCw.jpeg"/></div></div></figure><p id="7320" class="pw-post-body-paragraph kw kx it ky b kz la ju lb lc ld jx le lf lg lh li lj lk ll lm ln lo lp lq lr im bi translated">有相当多的方法来实现这些东西，这样爬行器或抓取器就不会被阻塞，但是一个好的爬行框架会减少你实现它们的工作量。</p><p id="912f" class="pw-post-body-paragraph kw kx it ky b kz la ju lb lc ld jx le lf lg lh li lj lk ll lm ln lo lp lq lr im bi translated">我使用的主要库是 Request、Scrapy 或 Selenium。Scrapy 和 Selenium 的对比可以参考这个<a class="ae nh" href="https://hackernoon.com/scrapy-or-selenium-c3efa9df2c06" rel="noopener ugc nofollow" target="_blank">链接</a>。我更喜欢<a class="ae nh" href="https://scrapy.org/" rel="noopener ugc nofollow" target="_blank"> Scrapy </a>，因为它已经实现了一些减少被网站屏蔽次数的方法。</p><ol class=""><li id="7f4f" class="nq nr it ky b kz la lc ld lf ns lj nt ln nu lr nv nw nx ny bi translated">服从 robots.txt，在刮网站之前一定要检查文件。</li><li id="dc6d" class="nq nr it ky b kz nz lc oa lf ob lj oc ln od lr nv nw nx ny bi translated">使用下载延迟或自动节流机制，已经存在于 Scrapy 框架，使您的刮刀/爬虫较慢。</li><li id="8f92" class="nq nr it ky b kz nz lc oa lf ob lj oc ln od lr nv nw nx ny bi translated">最好的方法是轮换一些 IP 和用户代理来伪装你的请求。如果你正在寻找任何代理服务，你可以看看这个服务<a class="ae nh" href="http://bit.ly/2PGh1AI" rel="noopener ugc nofollow" target="_blank">因为他们提供了大量的代理供你轮换。</a></li><li id="46bc" class="nq nr it ky b kz nz lc oa lf ob lj oc ln od lr nv nw nx ny bi translated">如果你使用 scrapy-splash 或 selenium，随机点击和滚动确实有助于模仿人类行为。</li></ol><p id="6fdc" class="pw-post-body-paragraph kw kx it ky b kz la ju lb lc ld jx le lf lg lh li lj lk ll lm ln lo lp lq lr im bi translated">有关更多信息，请参考以下链接</p><ol class=""><li id="949a" class="nq nr it ky b kz la lc ld lf ns lj nt ln nu lr nv nw nx ny bi translated"><a class="ae nh" href="https://www.scrapehero.com/how-to-prevent-getting-blacklisted-while-scraping/" rel="noopener ugc nofollow" target="_blank">https://www . scrape hero . com/how-to-prevent-getting-black-while-scraping/</a></li></ol></div><div class="ab cl na nb hx nc" role="separator"><span class="nd bw bk ne nf ng"/><span class="nd bw bk ne nf ng"/><span class="nd bw bk ne nf"/></div><div class="im in io ip iq"><p id="6308" class="pw-post-body-paragraph kw kx it ky b kz la ju lb lc ld jx le lf lg lh li lj lk ll lm ln lo lp lq lr im bi translated"><strong class="ky iu">提示 4 通过 API 检索数据</strong></p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi oe"><img src="../Images/957386aaca7a7c7a783ba63662393166.png" data-original-src="https://miro.medium.com/v2/resize:fit:1300/format:webp/1*TLVxi3WhHgssGjQ4TFCyMQ.jpeg"/></div></figure><p id="6d64" class="pw-post-body-paragraph kw kx it ky b kz la ju lb lc ld jx le lf lg lh li lj lk ll lm ln lo lp lq lr im bi translated">比如 twitter。你可以抓取网站或者使用<a class="ae nh" href="https://developer.twitter.com/en/docs/developer-utilities/twitter-libraries.html" rel="noopener ugc nofollow" target="_blank">他们的 API </a>。通过 API 访问他们的数据肯定会让您的生活变得更加轻松，而不是经历重重障碍！</p></div><div class="ab cl na nb hx nc" role="separator"><span class="nd bw bk ne nf ng"/><span class="nd bw bk ne nf ng"/><span class="nd bw bk ne nf"/></div><div class="im in io ip iq"><p id="25d8" class="pw-post-body-paragraph kw kx it ky b kz la ju lb lc ld jx le lf lg lh li lj lk ll lm ln lo lp lq lr im bi translated"><strong class="ky iu">技巧 5 抓取谷歌缓存的网站，而不是原来的网站</strong></p><p id="0d14" class="pw-post-body-paragraph kw kx it ky b kz la ju lb lc ld jx le lf lg lh li lj lk ll lm ln lo lp lq lr im bi translated">以<a class="ae nh" href="https://www.investing.com/" rel="noopener ugc nofollow" target="_blank">https://www.investing.com/</a>为例:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi of"><img src="../Images/23562d5baf6e69284d2d8c5c5675a426.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*U1cp_oapk9aPI7S8FAy4Uw.png"/></div></div></figure><p id="9463" class="pw-post-body-paragraph kw kx it ky b kz la ju lb lc ld jx le lf lg lh li lj lk ll lm ln lo lp lq lr im bi translated">您可以访问缓存版本，如下所示:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi og"><img src="../Images/24f307ef1cb79cf71683cbe18a8b35c9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*P6bTwHz63s9OaH7L-o_dZw.png"/></div></div></figure><p id="3c15" class="pw-post-body-paragraph kw kx it ky b kz la ju lb lc ld jx le lf lg lh li lj lk ll lm ln lo lp lq lr im bi translated">您将无法通过抓取缓存的网站而不是网站来获取最新数据。然而，如果网站的数据只在几周甚至几个月内发生变化，抓取谷歌缓存网站将是一个明智得多的选择。</p><p id="a56a" class="pw-post-body-paragraph kw kx it ky b kz la ju lb lc ld jx le lf lg lh li lj lk ll lm ln lo lp lq lr im bi translated">有关 google cache 的更多信息，您可以查看以下网站:</p><ol class=""><li id="54a8" class="nq nr it ky b kz la lc ld lf ns lj nt ln nu lr nv nw nx ny bi translated"><a class="ae nh" href="https://blog.hubspot.com/marketing/google-cache" rel="noopener ugc nofollow" target="_blank">https://blog.hubspot.com/marketing/google-cache</a></li></ol><h1 id="22d9" class="oh mc it bd md oi oj ok mg ol om on mj jz oo ka mm kc op kd mp kf oq kg ms or bi translated">关于作者</h1><p id="ae4c" class="pw-post-body-paragraph kw kx it ky b kz mu ju lb lc mv jx le lf mw lh li lj mx ll lm ln my lp lq lr im bi translated"><a class="ae nh" href="https://www.linkedin.com/in/lowweihong/?source=post_page---------------------------" rel="noopener ugc nofollow" target="_blank">低卫红</a>是 Shopee 的数据科学家。他的经验更多地涉及抓取网站，创建数据管道，以及实施机器学习模型来解决业务问题。</p><p id="c733" class="pw-post-body-paragraph kw kx it ky b kz la ju lb lc ld jx le lf lg lh li lj lk ll lm ln lo lp lq lr im bi translated">他提供爬行服务，能够为你提供你所需要的准确和干净的数据。你可以访问<a class="ae nh" href="https://www.thedataknight.com/" rel="noopener ugc nofollow" target="_blank"> <strong class="ky iu">这个网站</strong> </a>查看他的作品集，也可以联系他获取抓取服务。</p><p id="ed19" class="pw-post-body-paragraph kw kx it ky b kz la ju lb lc ld jx le lf lg lh li lj lk ll lm ln lo lp lq lr im bi translated">你可以在<a class="ae nh" href="https://www.linkedin.com/in/lowweihong/?source=post_page---------------------------" rel="noopener ugc nofollow" target="_blank"> LinkedIn </a>和<a class="ae nh" href="https://medium.com/@lowweihong?source=post_page---------------------------" rel="noopener"> Medium </a>上和他联系。</p><div class="os ot gp gr ou ov"><a href="https://medium.com/@lowweihong?source=post_page-----e85d1753fb4b----------------------" rel="noopener follow" target="_blank"><div class="ow ab fo"><div class="ox ab oy cl cj oz"><h2 class="bd iu gy z fp pa fr fs pb fu fw is bi translated">●伟鸿-中等</h2><div class="pc l"><h3 class="bd b gy z fp pa fr fs pb fu fw dk translated">在媒体上阅读低纬鸿的作品。数据科学家|网络搜集服务:http://datainfinite.mystrikingly.com/…</h3></div><div class="pd l"><p class="bd b dl z fp pa fr fs pb fu fw dk translated">medium.com</p></div></div><div class="pe l"><div class="pf l pg ph pi pe pj ks ov"/></div></div></a></div></div></div>    
</body>
</html>