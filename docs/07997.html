<html>
<head>
<title>How to get 4x speedup and better generalization using the right batch size</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">如何使用合适的批量获得 4 倍的加速和更好的泛化能力</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/implementing-a-batch-size-finder-in-fastai-how-to-get-a-4x-speedup-with-better-generalization-813d686f6bdf?source=collection_archive---------7-----------------------#2019-11-04">https://towardsdatascience.com/implementing-a-batch-size-finder-in-fastai-how-to-get-a-4x-speedup-with-better-generalization-813d686f6bdf?source=collection_archive---------7-----------------------#2019-11-04</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><p id="7658" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">有一次在推特上，我看到了杰瑞米·霍华德引用 Yann LeCun 关于批量的对话:</p><figure class="km kn ko kp gt kq gh gi paragraph-image"><div role="button" tabindex="0" class="kr ks di kt bf ku"><div class="gh gi kl"><img src="../Images/2fa147e9d734d57369d0fc6f44fffd9e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*vQUf3TyGx88q4wmXcygd2A.png"/></div></div><figcaption class="kx ky gj gh gi kz la bd b be z dk">Batch size discussion on Twitter</figcaption></figure><p id="acb7" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">自从我遇到 Fastai 的非常好的<strong class="jp ir">学习率查找器</strong>以来，这个主题一直在我脑海中的某个部分，我一直想知道是否有一个有用的<strong class="jp ir">批量大小查找器</strong>，人们可以使用它快速开始训练他们的模型具有良好的批量大小。</p><p id="0713" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">作为一个提醒，Fastai 中使用的学习率查找器通过测试不同的学习率来找到正确的学习率，以找到哪一个能最大程度地减少损失。更详细的解释可以在这里找到:<a class="ae lb" href="https://sgugger.github.io/how-do-you-find-a-good-learning-rate.html" rel="noopener ugc nofollow" target="_blank">https://sgu gger . github . io/how-do-you-find-a-good-learning-rate . html</a></p><p id="2124" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">拥有一个批量查找器的想法在我脑海中已经存在了很长时间，在从 Jeremy 那里获得了动力之后，我已经决定开始实现用于训练神经网络的批量查找器的旅程。</p><p id="d7a4" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">今天我想分享实现一篇论文的旅程和目的地，因为它们在我看来都很有趣，也许会激励你去尝试更多的东西！</p></div><div class="ab cl lc ld hu le" role="separator"><span class="lf bw bk lg lh li"/><span class="lf bw bk lg lh li"/><span class="lf bw bk lg lh"/></div><div class="ij ik il im in"><p id="65d0" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">一、大小故事</strong></p><figure class="km kn ko kp gt kq gh gi paragraph-image"><div role="button" tabindex="0" class="kr ks di kt bf ku"><div class="gh gi lj"><img src="../Images/e3e8272efa59a68a39d8ce8edd97e401.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*jig1e2BDLN7KPmgOcirflQ.jpeg"/></div></div><figcaption class="kx ky gj gh gi kz la bd b be z dk">OC meme about batch size</figcaption></figure><p id="b274" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">一个普遍的看法是，您不应该使用大批量，因为这只会导致模型过拟合，并且您可能会耗尽内存。虽然后者显然是正确的，但前者比后者更复杂，为了回答这个问题，我们将稍微深入一点 OpenAI 论文<a class="ae lb" href="https://arxiv.org/pdf/1812.06162.pdf" rel="noopener ugc nofollow" target="_blank">“大批量训练的经验模型”</a>。</p><p id="1ca1" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">这篇我推荐阅读的文章解释了许多简单的想法，值得记忆。</p><p id="8c33" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">首先，我们的目标是通过随机梯度下降法来最小化损失，并且有一个真正的基础景观，在此基础上我们将最小化损失。尽管如此，我们无法获得整个数据集的真实梯度(或者更准确地说，是整个分布的梯度)，<strong class="jp ir">因此，我们必须用有限的批量来近似梯度。</strong></p><p id="0953" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">因为我们对一批进行平均，如果我们的批量很小，就会有很多噪声，我们可能只训练噪声模型。尽管如此，应用几个连续的更新将朝着正确的方向推进，但我们还不如直接使用更大的批处理大小，这在计算上更有效，并直接平均掉噪声。尽管如此，在达到一定规模后，<strong class="jp ir">如果您的梯度已经很精确，那么再增加批量规模就没有意义了</strong>，因为这只是一种计算上的浪费，精度上的收益很小。</p><p id="4c62" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">此外，通过使用更大的批量(达到 GPU 允许的合理数量)，我们可以加快训练速度，因为这相当于迈出几大步，而不是迈出许多小步。因此，对于更大的批量，对于相同数量的历元，<strong class="jp ir">我们有时可以获得 2 倍的计算时间！</strong></p><p id="7be9" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">第二，有一个统计称为“<strong class="jp ir">简单噪声标度</strong>，它帮助我们确定什么是好的批量，它被定义为:</p><figure class="km kn ko kp gt kq gh gi paragraph-image"><div class="gh gi lk"><img src="../Images/35aed16206c281fc3bb0fe12453f7b9c.png" data-original-src="https://miro.medium.com/v2/resize:fit:930/1*04Idh-O-8DSyzpFaXa-MPA.gif"/></div><figcaption class="kx ky gj gh gi kz la bd b be z dk">Simple Noise Scale equation</figcaption></figure><p id="cb13" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">其中<strong class="jp ir"> <em class="ll"> G </em> </strong>是在 n 个参数上我们损失<strong class="jp ir"> <em class="ll"> L </em> </strong>的真实梯度。</p><p id="bf82" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">在不深入研究这篇论文的详细内容的情况下，我们的想法是，如果我们使用小于简单噪声标度的批量大小，我们可以通过增加批量大小来加快训练速度，相反，如果我们使用大于简单噪声标度的过大批量大小，我们只会浪费计算能力。</p><p id="8ee5" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">为了更好地理解这一统计数据的含义，让我们来研究一下每个术语:</p><ul class=""><li id="a090" class="lm ln iq jp b jq jr ju jv jy lo kc lp kg lq kk lr ls lt lu bi translated">分子是梯度中每个变量的方差之和。这是对梯度中存在的<strong class="jp ir">噪声</strong>的测量。</li><li id="7b1c" class="lm ln iq jp b jq lv ju lw jy lx kc ly kg lz kk lr ls lt lu bi translated">分母是梯度的平方范数，我们称之为<strong class="jp ir">标度</strong>，给出了梯度接近于零的局部最小值的接近程度的度量。</li></ul><p id="7b43" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">因此，梯度越大，我们想要的批量就越大，这很自然，因为我们想要在正确的方向上采取梯度步骤。相反，如果梯度没有噪声，我们将从较小的步长中受益更多，因为我们不需要平均大量的观察值并分别使用它们。</p><p id="9edf" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">另一方面，我们越接近最小值，批量越大，因为我们越接近局部最小值，我们希望采取更谨慎的步骤，因为我们不希望超过它而错过正确的方向。</p><p id="136e" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">最后，简单的噪声标度为我们提供了一个工具来回答“较大的批量会使我们过度适应，而较小的批量有助于调整”这个问题:</p><p id="2439" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">不一定！如果您的任务已经很复杂，并且近似梯度会有噪声，那么您可能会有兴趣使用更大的批量，以确保您的模型不会在太多的噪声上进行训练。<strong class="jp ir">不是说较大的批量会使你过度拟合，而是较小的批量会通过噪声注入增加更多的正则化</strong>，但是如果你连拟合都不合适，你还要增加正则化吗？</p></div><div class="ab cl lc ld hu le" role="separator"><span class="lf bw bk lg lh li"/><span class="lf bw bk lg lh li"/><span class="lf bw bk lg lh"/></div><div class="ij ik il im in"><p id="755c" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">二。实施文件</strong></p><figure class="km kn ko kp gt kq gh gi paragraph-image"><div role="button" tabindex="0" class="kr ks di kt bf ku"><div class="gh gi ma"><img src="../Images/842248baaee31fff336dcb51e70bf502.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*SelUlojqKN_McSSVv7aFcQ.png"/></div></div><figcaption class="kx ky gj gh gi kz la bd b be z dk">OC meme of my journey</figcaption></figure><p id="0cf2" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">现在，我们已经了解了为什么选择正确的批量大小很重要，以及我们如何通过简单的噪声比例统计找到合适的批量大小，现在是时候实施了！好吃！</p><p id="41ef" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">记住，简单的噪声比例公式是:</p><figure class="km kn ko kp gt kq gh gi paragraph-image"><div class="gh gi lk"><img src="../Images/35aed16206c281fc3bb0fe12453f7b9c.png" data-original-src="https://miro.medium.com/v2/resize:fit:930/1*04Idh-O-8DSyzpFaXa-MPA.gif"/></div><figcaption class="kx ky gj gh gi kz la bd b be z dk">Simple Noise Scale equation</figcaption></figure><p id="9595" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">问题是，我们不仅需要知道真实的梯度，还需要知道这个梯度的方差，这就更加困难了。为了解决这个问题，作者提出了两种不同的统计方法来逼近简单噪声标度的分子和分母。</p><figure class="km kn ko kp gt kq gh gi paragraph-image"><div class="gh gi mb"><img src="../Images/784606ebf79d84d602524096570efaa3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1190/1*HA26yc6d8cN_Z-ytVvsOBw.gif"/></div><figcaption class="kx ky gj gh gi kz la bd b be z dk">Estimator for the scale</figcaption></figure><figure class="km kn ko kp gt kq gh gi paragraph-image"><div class="gh gi mc"><img src="../Images/8e491c89350982cdc42a21a46aa1addc.png" data-original-src="https://miro.medium.com/v2/resize:fit:932/1*_90EHgOTfs-KYCsT1ZIVvg.gif"/></div><figcaption class="kx ky gj gh gi kz la bd b be z dk">Estimator for the noise</figcaption></figure><p id="1e00" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">这里，我们使用两个不同的批量大小，<strong class="jp ir"> <em class="ll"> B 大和 B 小</em> </strong>，使用以下公式计算实际梯度的两个不同估计值:</p><figure class="km kn ko kp gt kq gh gi paragraph-image"><div class="gh gi md"><img src="../Images/db82c25b7a273b91649d36ab05e03d07.png" data-original-src="https://miro.medium.com/v2/resize:fit:484/1*JQtXvUKZntRLS9m3cbJWbg.gif"/></div><figcaption class="kx ky gj gh gi kz la bd b be z dk">Approximate gradient for a given batch size</figcaption></figure><p id="e5f3" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">一旦有了这两个近似值，我们就可以用下面的公式来计算简单的噪声比例:</p><figure class="km kn ko kp gt kq gh gi paragraph-image"><div class="gh gi me"><img src="../Images/178fff3c978a0a5905bda52db4a0077f.png" data-original-src="https://miro.medium.com/v2/resize:fit:434/1*0VAW9y4BI1HXhT6KIZqs1w.gif"/></div><figcaption class="kx ky gj gh gi kz la bd b be z dk">Approximation of the Simple Noise Scale</figcaption></figure><p id="f53f" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">为了确保该估计量具有低方差，作者在整个训练过程中计算了几个简单的噪声尺度估计量，并对其进行了平均。</p><p id="3ea7" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">正如论文中所解释的，一种自然的方法是利用几个 GPU 来计算每个 GPU 的局部梯度，这将是小梯度，然后将其与不同 GPU 之间的平均梯度进行比较，这将是大梯度。尽管如此，这种方法假设我们有一个多 GPU，但对我们大多数人来说并不是这样。</p><p id="7d91" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">因此，必须找到一种有效的方法来为单个 GPU 实现这一点，而这在原始论文中没有描述。这就是我开始的地方，现在我将与你分享我如何解决这个问题的理由！</p><p id="9ebb" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">文章其余部分使用的代码可以在这里找到:<a class="ae lb" href="https://colab.research.google.com/drive/15lTG_r03yqSwShZ0JO4XaoWixLMXMEmv" rel="noopener ugc nofollow" target="_blank">https://colab . research . Google . com/drive/15 ltg _ r 03 yqswshz 0 jo 4xaowixlmxmemv</a></p><p id="5c60" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">在第一行代码中，我设置了一个 Fastai 环境来在 MNIST 上运行一个模型，因为这个数据集已经在论文中进行了测试，他们得到了平均 900 的简单噪声标度。</p><p id="cfc6" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我不会详细解释代码，因为我要花一整篇文章来解释 Fastai 如何将所有东西与他们的 API 放在一起，但是代码应该是一个好的开始。如果你想进一步了解代码，请在评论中告诉我，我可以解释它，甚至可以写一篇关于编码部分的文章。</p><p id="0724" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir"> A .使用指数移动平均线的第一种方法</strong></p><p id="1093" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">由于我没有多 GPU 设置，所以我发现论文中提出的统计数据并没有真正的帮助，我想我可以跳过它，通过进行近似，直接计算方差的总和:</p><figure class="km kn ko kp gt kq gh gi paragraph-image"><div class="gh gi mf"><img src="../Images/c43682e4cf873ddea67d9e7a20ae2442.png" data-original-src="https://miro.medium.com/v2/resize:fit:184/1*2NfsmdeLmBmP1QUmgJ2vDg.gif"/></div></figure><figure class="km kn ko kp gt kq gh gi paragraph-image"><div role="button" tabindex="0" class="kr ks di kt bf ku"><div class="gh gi mg"><img src="../Images/18c1fc76c1b1587259fed8c2431157cb.png" data-original-src="https://miro.medium.com/v2/resize:fit:778/1*BxCTztCkhvaGy0aW2vG1VQ.gif"/></div></div></figure><p id="1fdc" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">首先，我用给定批次的估计梯度来近似真实梯度。</p><p id="f44d" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">然后，由于协方差矩阵的计算可以被视为两个平均值，我试图用指数移动平均值来近似它，因为我不想在训练中存储许多梯度。</p><figure class="km kn ko kp gt kq gh gi paragraph-image"><div class="gh gi mh"><img src="../Images/15f64771449488531f4fef1dc5899f9f.png" data-original-src="https://miro.medium.com/v2/resize:fit:740/format:webp/1*x1fd0Xu87wvbDvfNQS9Swg.png"/></div><figcaption class="kx ky gj gh gi kz la bd b be z dk">Running average of noise, scale, and Simple Noise Scale over batches computed</figcaption></figure><p id="c9a1" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">正如您在这里看到的，结果很奇怪，简单噪声标度太不稳定，噪声比噪声大得多，这给出了一个非常负的简单噪声标度，没有意义。</p><p id="cc85" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir"> B .存储梯度</strong></p><p id="aa80" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我们看到，使用指数移动平均并不是逼近协方差矩阵的好主意。</p><p id="ce20" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">解决这个问题的另一种方法是简单地预先设置若干个<strong class="jp ir"><em class="ll">【N】</em></strong>梯度来保持，然后我们将简单地计算<strong class="jp ir"> <em class="ll"> N </em> </strong>不同的梯度，并使用那些<strong class="jp ir"> <em class="ll"> N </em> </strong>梯度来近似协方差矩阵。</p><figure class="km kn ko kp gt kq gh gi paragraph-image"><div class="gh gi mi"><img src="../Images/95c077cd9d85884d75ef8b08eafdc1af.png" data-original-src="https://miro.medium.com/v2/resize:fit:768/format:webp/1*7vi1EQIiKdQujyMxsUNiTg.png"/></div></figure><p id="d5ac" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">它开始显示结果，但是它的计算方式很复杂:x 轴是我存储的批次数量，以这种方式计算简单的噪声范围。虽然它似乎提供了某种结果，但实际上并不可用，因为我已经存储了数百个渐变！</p><p id="1fb3" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir"> C .进行两次培训</strong></p><p id="d742" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">又一次失败后，我决定按照论文的思路，计算他们的两个统计量。尽管如此，当我只有一个 GPU 时，我需要有一种方法在训练期间获得两个不同大小的批次。</p><p id="a720" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">然后我想，当我可以用两种不同的批量大小运行两个训练时期，然后再计算它时，为什么要运行一个训练时期呢？</p><p id="b4a9" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">于是我带着这个想法去做了，用<strong class="jp ir"> B 大</strong> = <strong class="jp ir"> <em class="ll"> 2 * B 小</em> </strong>，这将允许我计算它们各自的梯度，并使用它们来计算<strong class="jp ir"> <em class="ll"> G </em> </strong>和<strong class="jp ir"> <em class="ll"> S </em> </strong>如文中所述以指数移动平均的方式。</p><figure class="km kn ko kp gt kq gh gi paragraph-image"><div class="gh gi mj"><img src="../Images/8522a984a812ff4d944210e4cc120b3c.png" data-original-src="https://miro.medium.com/v2/resize:fit:780/format:webp/1*ywiCJTeVJy8NetE_Xmljkw.png"/></div></figure><p id="4981" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">哎哟！与第一种方法一样，它产生了奇怪的结果！此外，当我想到这一点时，我得到的批次可能在两次运行之间并不相同，因为没有什么会强制将小批次包含在大批次中。此外，我需要运行两个训练时期来计算这一点，所以它不是很好。</p><p id="5de2" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir"> D .连续批次</strong></p><p id="a3c0" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">最后，我意识到最好的方法似乎是第二种，但有些东西必须修改，因为我不想保留大量的梯度来计算统计数据。</p><p id="0b19" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">然后，一个非常简单但有效的想法出现在脑海中:如果我不是像论文中那样以平行的方式对几个批次进行平均，而是以连续的方式对连续的批次进行平均，会怎么样？</p><p id="f26c" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">这仅仅意味着我只需要设置一个参数，我调用<strong class="jp ir"><em class="ll">【n _ batch】</em></strong>这是在计算大梯度和小梯度之前我必须存储的批次号，然后我将能够以连续的方式计算论文的统计数据！</p><p id="1786" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">以这种方式实现后，我得到了以下结果:</p><figure class="km kn ko kp gt kq gh gi paragraph-image"><div class="gh gi mk"><img src="../Images/4d4a111cb2b89513cda286425f72efa1.png" data-original-src="https://miro.medium.com/v2/resize:fit:750/format:webp/1*jAFjFWB4yiiSXBE2nOyZWA.png"/></div></figure><p id="c267" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">她真是个美人！在论文中，他们描述了增长趋势是可以预期的，因为噪声更可能保持不变，而梯度的规模将随着我们越来越接近最小值而减小，这将导致简单噪声规模的增长。</p><p id="ddde" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">因为我们很可能没有相同的设置，我也没有访问他们的代码，所以我们的结果略有不同，但在论文中，作者提到了一个简单的噪声标度，从大约 50 开始，到 900，这才是重要的。考虑到理论和实践中的许多近似值，结果可能会有所不同，但正如论文中所解释的那样，差异不应超过一个数量级。</p><p id="4eaa" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">因此，在这个漫长的旅程之后，似乎有一个实现正在工作，尽管本文对此没有提供什么帮助，最好的部分是，要在实践中使用它，您只需要一行代码！</p><figure class="km kn ko kp gt kq"><div class="bz fp l di"><div class="ml mm l"/></div></figure><p id="67bf" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">这里的参数对应于:</p><ul class=""><li id="e570" class="lm ln iq jp b jq jr ju jv jy lo kc lp kg lq kk lr ls lt lu bi translated">学习:快速学习者。</li><li id="24c0" class="lm ln iq jp b jq lv ju lw jy lx kc ly kg lz kk lr ls lt lu bi translated">lr:完成一个训练循环的学习率，可以使用 lr_find()找到</li><li id="1687" class="lm ln iq jp b jq lv ju lw jy lx kc ly kg lz kk lr ls lt lu bi translated">num_it:您想要处理的批次数量，可以设置为<strong class="jp ir"> <em class="ll">【无】</em> </strong>，它会在一个时期内自动训练。</li><li id="054f" class="lm ln iq jp b jq lv ju lw jy lx kc ly kg lz kk lr ls lt lu bi translated">n_batch:在计算简单噪声标度之前要存储的批次数量。20 似乎可以很好地完成不同的任务。</li><li id="f48f" class="lm ln iq jp b jq lv ju lw jy lx kc ly kg lz kk lr ls lt lu bi translated">beta:指数移动平均的 beta 参数，用于计算方差和以及渐变的比例。如果绘图太不规则，如果需要，尝试增加到 0.999 或更大，或者增加 n_batch 参数。</li></ul><p id="d901" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">三世。在不同任务上测试批量查找器</strong></p><figure class="km kn ko kp gt kq gh gi paragraph-image"><div role="button" tabindex="0" class="kr ks di kt bf ku"><div class="gh gi mn"><img src="../Images/c80a12f2b0a7ecbfdf3d25602c503527.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*XWARmZiRjehuq3e3o6zueQ.jpeg"/></div></div><figcaption class="kx ky gj gh gi kz la bd b be z dk">Time to take big steps !</figcaption></figure><p id="fe92" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">现在我们有了一个工作的实现，看看它在实践中如何帮助找到一个好的批量大小会很有意思。</p><p id="9279" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">首先，我们将研究罗斯曼数据集。这个数据集已经在 Fastai courses v3 中进行了探索，您可以在这里找到:<a class="ae lb" href="https://github.com/fastai/course-v3/blob/master/nbs/dl1/lesson6-rossmann.ipynb" rel="noopener ugc nofollow" target="_blank">https://github . com/Fastai/course-v3/blob/master/nbs/dl1/lesson 6-rossmann . ipynb</a></p><p id="4d13" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">在这里，我将简单地运行我的批量大小查找器，并进行与原来完全相同的训练，但是批量大小考虑了简单的噪声标度。</p><figure class="km kn ko kp gt kq"><div class="bz fp l di"><div class="ml mm l"/></div></figure><figure class="km kn ko kp gt kq gh gi paragraph-image"><div class="gh gi mk"><img src="../Images/74abd6d5727c2769d14a4c27d0b9967e.png" data-original-src="https://miro.medium.com/v2/resize:fit:750/format:webp/1*lIJWY6auGZ8mzm35UWFT7w.png"/></div></figure><p id="bc58" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">现在如何解读这一点？这意味着，对于给定的学习速率，训练似乎收敛到大约 500 的简单噪声标度，即噪声和标度在训练的后期稳定。因此，计算时间和效率之间的最佳权衡似乎是批处理大小为 512。</p><p id="2a56" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">在使用批量大小 512 和 64 运行相同的训练后，我们可以观察到一些情况。</p><figure class="km kn ko kp gt kq gh gi paragraph-image"><div class="gh gi mo"><img src="../Images/de69fbc52247152580a0be13fb0086ba.png" data-original-src="https://miro.medium.com/v2/resize:fit:998/format:webp/1*OnkQ_bAMp58x9U0LCDZB-Q.png"/></div><figcaption class="kx ky gj gh gi kz la bd b be z dk">First one-cycle training with batch size 512</figcaption></figure><figure class="km kn ko kp gt kq gh gi paragraph-image"><div class="gh gi mp"><img src="../Images/a2eee66bed4b253954ac8638553f410e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1006/format:webp/1*1CVfmYygdCJA0v6nW-foTQ.png"/></div><figcaption class="kx ky gj gh gi kz la bd b be z dk">First one-cycle training with batch size 64</figcaption></figure><p id="a907" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">批量大小为 512 时，<strong class="jp ir">培训速度比批量大小为 64 时快近 4 倍</strong>！此外，即使批量大小 512 采取更少的步骤，最终它具有更好的训练损失和稍差的验证损失。</p><p id="5ab6" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">然后，如果我们查看每个批量的第二个训练周期损失:</p><figure class="km kn ko kp gt kq gh gi paragraph-image"><div class="gh gi mq"><img src="../Images/f4f23a9d512f0362cd5b77224998baa3.png" data-original-src="https://miro.medium.com/v2/resize:fit:804/format:webp/1*jCShCBWDwjpJn3AQRBLfug.png"/></div><figcaption class="kx ky gj gh gi kz la bd b be z dk">Second one-cycle training losses with batch size 512</figcaption></figure><figure class="km kn ko kp gt kq gh gi paragraph-image"><div class="gh gi mr"><img src="../Images/1668935e8e1ba68482c204183f724535.png" data-original-src="https://miro.medium.com/v2/resize:fit:796/format:webp/1*feGLBassjgokl8GYRp_kzQ.png"/></div><figcaption class="kx ky gj gh gi kz la bd b be z dk">Second one-cycle training losses with batch size 64</figcaption></figure><p id="6006" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我们可以看到，与批量大小为 512 的情况相比，批量大小为 64 的情况下，训练更加不稳定，因为验证损失继续减少。</p><p id="f2a4" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">最后，我们可以观察到最后一个培训周期的以下结果:</p><figure class="km kn ko kp gt kq gh gi paragraph-image"><div class="gh gi ms"><img src="../Images/55ab9463be493cf0251f62803a8308b9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1004/format:webp/1*l_3O6dASnGPk-fc61il3PA.png"/></div><figcaption class="kx ky gj gh gi kz la bd b be z dk">Last one-cycle training losses with batch size 512</figcaption></figure><figure class="km kn ko kp gt kq gh gi paragraph-image"><div class="gh gi mt"><img src="../Images/9fb744a9eeb4f47fa78aa26b2a524c23.png" data-original-src="https://miro.medium.com/v2/resize:fit:992/format:webp/1*jc1fNDWfG1cxOPuMK84xwg.png"/></div><figcaption class="kx ky gj gh gi kz la bd b be z dk">Last one-cycle training losses with batch size 64</figcaption></figure><p id="59ab" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">所以最后，如果我们总结 Rossmann 的结果，使用 512 而不是 64 的批量</p><ul class=""><li id="fe85" class="lm ln iq jp b jq jr ju jv jy lo kc lp kg lq kk lr ls lt lu bi translated">减少 4 的训练时间</li><li id="4fa4" class="lm ln iq jp b jq lv ju lw jy lx kc ly kg lz kk lr ls lt lu bi translated">提供了更好的训练和验证损失，以及感兴趣的度量，这里是 exp_rmse</li></ul><p id="6dce" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我研究过文本和图像数据，但考虑到它们要重得多，尤其是具有巨大身体的预训练模型，当我尝试以批量大小运行训练时，我遇到了 CUDA 内存不足，所以我不会在这里显示结果，但你可以在 Colab 笔记本上看看。</p><p id="12fe" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">结论</strong></p><p id="e113" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">贯穿这篇文章我们看到了很多东西！我希望你喜欢这次旅行，如果有什么事情你必须记住的话，那就是:</p><ul class=""><li id="ef82" class="lm ln iq jp b jq jr ju jv jy lo kc lp kg lq kk lr ls lt lu bi translated">没有神奇的批量大小数字，例如 32，它取决于您的数据的复杂性，以及您的 GPU 约束。我们看到，小批量可以通过噪声注入帮助调整，但如果你想学习的任务很难，这可能是有害的。而且，跑很多小步会花更多的时间。相反，大批量确实可以加快你的训练，甚至有更好的泛化性能。</li><li id="3d5e" class="lm ln iq jp b jq lv ju lw jy lx kc ly kg lz kk lr ls lt lu bi translated">一个很好的方法是使用<a class="ae lb" href="https://arxiv.org/pdf/1812.06162.pdf" rel="noopener ugc nofollow" target="_blank">“大批量培训的经验模型”</a>中介绍的简单噪音等级度量。我在这里提供了第一个快速的实现:【https://github.com/DanyWind/fastai_bs_finder】<a class="ae lb" href="https://github.com/DanyWind/fastai_bs_finder" rel="noopener ugc nofollow" target="_blank"/>。您可以在自己的数据集上尝试它，特别是在推荐系统或表格模型上，在那里您不太可能遇到 CUDA 内存不足的问题。</li><li id="08e6" class="lm ln iq jp b jq lv ju lw jy lx kc ly kg lz kk lr ls lt lu bi translated">不要犹豫去尝试一些事情，一个小小的推动有时可以推动你做好事！我大概在 6 个月前看到了这篇论文，但我并没有真正注意到它，直到我真正尝试(并且失败了很多次)去实现它。但是现在，我不仅可以与大型社区分享这些结果，它还帮助我更好地理解批量大小是如何工作的，以及它的常见概念可能是错误的。所以不要犹豫，现在就实施酷的东西，即使它不直接工作也没关系，旅程比目的地更有价值！</li></ul><p id="eaca" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">所以，我希望你喜欢读这篇文章，如果能得到你的反馈，那就太好了，我会在未来试着发布更多的文章。</p><p id="a7e2" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">如果您有任何问题，请不要犹豫，通过<a class="ae lb" href="https://www.linkedin.com/in/dhuynh95/" rel="noopener ugc nofollow" target="_blank"> Linkedin </a>联系我，您也可以通过<a class="ae lb" href="https://twitter.com/dhuynh95" rel="noopener ugc nofollow" target="_blank"> Twitter 找到我！</a></p></div></div>    
</body>
</html>