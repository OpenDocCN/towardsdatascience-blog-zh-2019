<html>
<head>
<title>9 Tips For Training Lightning-Fast Neural Networks In Pytorch</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">在 Pytorch 中训练快如闪电的神经网络的 9 个技巧</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/9-tips-for-training-lightning-fast-neural-networks-in-pytorch-8e63a502f565?source=collection_archive---------4-----------------------#2019-07-21">https://towardsdatascience.com/9-tips-for-training-lightning-fast-neural-networks-in-pytorch-8e63a502f565?source=collection_archive---------4-----------------------#2019-07-21</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><figure class="gl gn jr js jt ju gh gi paragraph-image"><div class="gh gi jq"><img src="../Images/5b2edd83cd768f0253a2abc8822270a9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/1*0nIzdYowxwJXFW2OCVg_pA.gif"/></div><figcaption class="jx jy gj gh gi jz ka bd b be z dk">Don’t let this be your Neural Network (Image credit: Monsters U)</figcaption></figure><p id="18ee" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">面对现实吧，你的模型很可能还停留在石器时代。我敢打赌，你仍然在使用 32 位精度或* <em class="kz"> GASP* </em>甚至可能只在单个 GPU 上训练<strong class="kd iu"/>。</p><p id="58c3" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi">😱.</p><p id="1310" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">我明白了，虽然有 99 个加速指南，但清单不是 1？(是的，那刚刚发生了)。好吧，把这看作是<strong class="kd iu">终极</strong>，一步一步的指导，确保你挤压所有的(GP-Use)😂你的模型之外。</p><p id="ed17" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">这份指南从最简单到最大的 PITA 修改，你可以做出最大限度地利用你的网络。我将展示 Pytorch 代码的例子和相关的标志，你可以在<a class="ae la" href="https://williamfalcon.github.io/pytorch-lightning/Trainer/" rel="noopener ugc nofollow" target="_blank"> Pytorch-Lightning Trainer </a>中使用，以防你不想自己编写这些代码！</p><p id="6ff3" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">这本指南是给谁的？任何在 Pytorch 中从事非平凡深度学习模型工作的人，如工业研究人员、博士生、学者等。我们在这里讨论的模型可能需要你花多天时间来训练，甚至几周或几个月。</p><p id="559e" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">我们将涵盖(从最简单到最皮塔饼)</p><ol class=""><li id="f794" class="lb lc it kd b ke kf ki kj km ld kq le ku lf ky lg lh li lj bi translated">使用数据加载器。</li><li id="cadf" class="lb lc it kd b ke lk ki ll km lm kq ln ku lo ky lg lh li lj bi translated">数据加载器中的工作线程数。</li><li id="5f9b" class="lb lc it kd b ke lk ki ll km lm kq ln ku lo ky lg lh li lj bi translated">批量大小。</li><li id="ba7b" class="lb lc it kd b ke lk ki ll km lm kq ln ku lo ky lg lh li lj bi translated">累积的梯度。</li><li id="e954" class="lb lc it kd b ke lk ki ll km lm kq ln ku lo ky lg lh li lj bi translated">保留图形。</li><li id="d511" class="lb lc it kd b ke lk ki ll km lm kq ln ku lo ky lg lh li lj bi translated">转移到单个 GPU。</li><li id="72d1" class="lb lc it kd b ke lk ki ll km lm kq ln ku lo ky lg lh li lj bi translated">16 位混合精度训练。</li><li id="ddf3" class="lb lc it kd b ke lk ki ll km lm kq ln ku lo ky lg lh li lj bi translated">移动到多个 GPU(模型复制)。</li><li id="b235" class="lb lc it kd b ke lk ki ll km lm kq ln ku lo ky lg lh li lj bi translated">移动到多个 GPU 节点(8 个以上的 GPU)。</li><li id="722d" class="lb lc it kd b ke lk ki ll km lm kq ln ku lo ky lg lh li lj bi translated">我的思考模型加速的技巧</li></ol></div><div class="ab cl lp lq hx lr" role="separator"><span class="ls bw bk lt lu lv"/><span class="ls bw bk lt lu lv"/><span class="ls bw bk lt lu"/></div><div class="im in io ip iq"><h1 id="6e10" class="lw lx it bd ly lz ma mb mc md me mf mg mh mi mj mk ml mm mn mo mp mq mr ms mt bi translated">py torch-闪电</h1><figure class="mv mw mx my gt ju gh gi paragraph-image"><div class="gh gi mu"><img src="../Images/231a543c2045cf59e24d1a6f474374a8.png" data-original-src="https://miro.medium.com/v2/resize:fit:800/1*oS5csUDs-RhQW4sbm8Hapw.gif"/></div></figure><p id="725e" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">你可以在 Pytorch 库<a class="ae la" href="https://github.com/williamFalcon/pytorch-lightning" rel="noopener ugc nofollow" target="_blank"> Pytorch-Lightning </a>中找到我在这里讨论的所有优化。Lightning 是 Pytorch 上的一个轻型包装器，它可以自动对研究人员进行培训，同时让他们完全控制关键的模型部件。查看<a class="ae la" href="https://github.com/williamFalcon/pytorch-lightning/blob/master/pytorch_lightning/examples/new_project_templates/single_gpu_node_template.py" rel="noopener ugc nofollow" target="_blank">本教程，获取更强大的示例</a>。</p><p id="17ab" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">Lightning 采用了最新的最佳实践，最大限度地减少了可能出错的地方。</p><p id="eea6" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">我们将在这里为 MNIST <a class="ae la" href="https://pytorch-lightning.readthedocs.io/en/latest/lightning-module.html#module-pytorch_lightning.core" rel="noopener ugc nofollow" target="_blank">定义我们的照明模型，并使用训练器进行拟合。</a></p><figure class="mv mw mx my gt ju"><div class="bz fp l di"><div class="mz na l"/></div></figure></div><div class="ab cl lp lq hx lr" role="separator"><span class="ls bw bk lt lu lv"/><span class="ls bw bk lt lu lv"/><span class="ls bw bk lt lu"/></div><div class="im in io ip iq"><h1 id="5278" class="lw lx it bd ly lz ma mb mc md me mf mg mh mi mj mk ml mm mn mo mp mq mr ms mt bi translated">1.数据加载器</h1><figure class="mv mw mx my gt ju gh gi paragraph-image"><div class="gh gi nb"><img src="../Images/03ae7660c1c2ad62d9e8f14d494662e4.png" data-original-src="https://miro.medium.com/v2/resize:fit:440/1*MbEyoYlOi4nBKzJfnViU4w.gif"/></div></figure><p id="6fb2" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">这可能是最容易获得一些速度增益的地方。保存 h5py 或 numpy 文件来加速数据加载的日子已经一去不复返了(等等…你们不会这么做吧？？).使用<a class="ae la" href="https://pytorch.org/tutorials/beginner/data_loading_tutorial.html" rel="noopener ugc nofollow" target="_blank"> Pytorch dataloader </a>加载图像数据很简单(对于 NLP 数据，查看<a class="ae la" href="https://torchtext.readthedocs.io/en/latest/datasets.html" rel="noopener ugc nofollow" target="_blank"> TorchText </a></p><figure class="mv mw mx my gt ju"><div class="bz fp l di"><div class="mz na l"/></div></figure><p id="61a8" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">在 lightning 中，你不需要指定训练循环，只需要定义数据加载器，训练器会在需要的时候<a class="ae la" href="https://williamfalcon.github.io/pytorch-lightning/LightningModule/RequiredTrainerInterface/#tng_dataloader" rel="noopener ugc nofollow" target="_blank">调用它们</a>。</p><h1 id="15b1" class="lw lx it bd ly lz nc mb mc md nd mf mg mh ne mj mk ml nf mn mo mp ng mr ms mt bi translated">2.数据加载器中的工作人员数量</h1><figure class="mv mw mx my gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="ni nj di nk bf nl"><div class="gh gi nh"><img src="../Images/fe16038300d5c837b7fa4d998644a715.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/1*juxFlJcvyEyp7JKW36q-Ng.gif"/></div></div></figure><p id="f44f" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">加速的另一个神奇之处来自于允许批量并行加载。因此，您可以一次加载 nb_workers 批处理，而不是一次加载一个批处理。</p><figure class="mv mw mx my gt ju"><div class="bz fp l di"><div class="mz na l"/></div></figure></div><div class="ab cl lp lq hx lr" role="separator"><span class="ls bw bk lt lu lv"/><span class="ls bw bk lt lu lv"/><span class="ls bw bk lt lu"/></div><div class="im in io ip iq"><h1 id="0305" class="lw lx it bd ly lz ma mb mc md me mf mg mh mi mj mk ml mm mn mo mp mq mr ms mt bi translated">3.批量</h1><figure class="mv mw mx my gt ju gh gi paragraph-image"><div class="gh gi nm"><img src="../Images/179c59fa77b6c0fb7e96dab6525e95d3.png" data-original-src="https://miro.medium.com/v2/resize:fit:560/1*jTwjkn9AH7ep7MU8IfIkdg.gif"/></div></figure><p id="67cd" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">在开始下一个优化步骤之前，将批处理大小提高到 CPU-RAM 或 GPU-RAM 允许的最大值。</p><p id="a83f" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">下一节将重点关注如何帮助减少内存占用，以便您可以继续增加批处理大小。</p><p id="be43" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">记住，你可能需要再次更新你的学习率。一个很好的经验法则是，如果你的批量加倍，学习速度也会加倍。</p><h1 id="7a59" class="lw lx it bd ly lz nc mb mc md nd mf mg mh ne mj mk ml nf mn mo mp ng mr ms mt bi translated">4.累积梯度</h1><figure class="mv mw mx my gt ju gh gi paragraph-image"><div class="gh gi jq"><img src="../Images/688cbd4ed75d67f6fc517a8ccc88e4f6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/1*NPrLSjVsT0l-DGKEIukHTw.gif"/></div></figure><p id="ef76" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">如果您的计算资源已经达到极限，并且您的批处理大小仍然太低(比如说 8)，那么我们需要模拟一个更大的批处理大小用于梯度下降，以提供一个好的估计。</p><p id="b44c" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">假设我们想要达到 128 的批量。然后，在执行单个优化器步骤之前，我们将执行 16 次向前和向后传递，批处理大小为 8。</p><figure class="mv mw mx my gt ju"><div class="bz fp l di"><div class="mz na l"/></div></figure><p id="fe27" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">在 lightning 中，这一切都是为你而做的。只需设置<a class="ae la" href="https://pytorch-lightning.readthedocs.io/en/latest/trainer.html#pytorch_lightning.trainer.Trainer" rel="noopener ugc nofollow" target="_blank">accumulate _ grad _ batches = 1</a>。</p><figure class="mv mw mx my gt ju"><div class="bz fp l di"><div class="mz na l"/></div></figure><h1 id="43ab" class="lw lx it bd ly lz nc mb mc md nd mf mg mh ne mj mk ml nf mn mo mp ng mr ms mt bi translated">5.保留图形</h1><figure class="mv mw mx my gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="ni nj di nk bf nl"><div class="gh gi nn"><img src="../Images/19fea1ca6ad7542289bacf093680b7c2.png" data-original-src="https://miro.medium.com/v2/resize:fit:700/1*NjtRZj_2DgxA_o5eRiALBg.gif"/></div></div></figure><p id="f08c" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">炸毁 RAM 的一个简单方法是不要释放指向计算图的指针，比如说……为了日志记录的目的存储您的损失</p><pre class="mv mw mx my gt no np nq nr aw ns bi"><span id="7362" class="nt lx it np b gy nu nv l nw nx">losses = []</span><span id="d3bf" class="nt lx it np b gy ny nv l nw nx">...<br/>losses.append(loss)</span><span id="87d0" class="nt lx it np b gy ny nv l nw nx">print(f'current loss: {torch.mean(losses)'})</span></pre><p id="c714" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">上面的问题是<strong class="kd iu">损失</strong>还有图的副本。在这种情况下，调用。项()来释放它。</p><pre class="mv mw mx my gt no np nq nr aw ns bi"><span id="bd0f" class="nt lx it np b gy nu nv l nw nx"># bad<br/>losses.append(loss)</span><span id="f54f" class="nt lx it np b gy ny nv l nw nx"># good<br/>losses.append(loss.item())</span></pre><p id="7b10" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">Lightning 特别注意确保它永远不会保留图形的副本。</p></div><div class="ab cl lp lq hx lr" role="separator"><span class="ls bw bk lt lu lv"/><span class="ls bw bk lt lu lv"/><span class="ls bw bk lt lu"/></div><div class="im in io ip iq"><h1 id="1a45" class="lw lx it bd ly lz ma mb mc md me mf mg mh mi mj mk ml mm mn mo mp mq mr ms mt bi translated">6.单 GPU 训练</h1><figure class="mv mw mx my gt ju gh gi paragraph-image"><div class="gh gi nb"><img src="../Images/dcb13bf7c7ee31995e5c88a31a24bb5a.png" data-original-src="https://miro.medium.com/v2/resize:fit:440/1*CER3v8cok2UOBNsmnBrzPQ.gif"/></div></figure><p id="372d" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">一旦你完成了前面的步骤，就该进入 GPU 培训了。GPU 上的培训将在许多 GPU 核心上并行化数学计算。您获得的加速取决于您使用的 GPU 类型。我推荐个人用的 2080Ti 和公司用的 V100。</p><p id="a33c" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">乍一看，这似乎令人不知所措，但你真的只需要做两件事:1)将你的模型移动到 GPU，2)每当你通过它运行数据时，将数据放在 GPU 上。</p><figure class="mv mw mx my gt ju"><div class="bz fp l di"><div class="mz na l"/></div></figure><p id="0dd9" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">如果你使用 Lightning，你不需要对你的代码做任何事情。只需设置<a class="ae la" href="https://pytorch-lightning.readthedocs.io/en/latest/trainer.html#pytorch_lightning.trainer.Trainer" rel="noopener ugc nofollow" target="_blank">训练器(GPU = 1)</a>。</p><figure class="mv mw mx my gt ju"><div class="bz fp l di"><div class="mz na l"/></div></figure><p id="eb82" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">在 GPU 上进行训练时，需要注意的主要问题是限制 CPU 和 GPU 之间的传输次数。</p><pre class="mv mw mx my gt no np nq nr aw ns bi"><span id="0d1b" class="nt lx it np b gy nu nv l nw nx"># <strong class="np iu">expensive</strong><br/>x = x.cuda(0)</span><span id="2955" class="nt lx it np b gy ny nv l nw nx"># <strong class="np iu">very</strong> expensive<br/>x = x.cpu()<br/>x = x.cuda(0)</span></pre><p id="3ee5" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">例如，如果内存不足，不要将数据移回 CPU 以节省内存。在采取这种方法之前，尝试用其他方法优化您的代码，或者在 GPU 之间进行分配。</p><p id="f6ce" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">另一件要注意的事情是调用强制 GPU 同步的操作。一个例子就是清除内存缓存。</p><pre class="mv mw mx my gt no np nq nr aw ns bi"><span id="0225" class="nt lx it np b gy nu nv l nw nx"># really bad idea. Stops all the GPUs until they all catch up<br/>torch.cuda.empty_cache()</span></pre><p id="45a6" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">但是，如果您使用 Lightning，唯一可能出现问题的地方是当您定义 Lightning 模块时。闪电特别注意不要犯这种错误。</p><h1 id="c624" class="lw lx it bd ly lz nc mb mc md nd mf mg mh ne mj mk ml nf mn mo mp ng mr ms mt bi translated">7.16 位精度</h1><p id="9580" class="pw-post-body-paragraph kb kc it kd b ke nz kg kh ki oa kk kl km ob ko kp kq oc ks kt ku od kw kx ky im bi translated">16 位精度是一个惊人的技巧，可以将内存占用减半。大多数模型都是使用 32 位精度数字进行训练的。然而，最近的研究发现，16 位的模型也能很好地工作。混合精度意味着对某些事情使用 16 位，但对权重等事情保持 32 位。</p><p id="23bd" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">要在 Pytorch 中使用 16 位精度，请安装英伟达的<a class="ae la" href="https://github.com/NVIDIA/apex" rel="noopener ugc nofollow" target="_blank"> apex 库</a>，并对您的模型进行这些更改。</p><figure class="mv mw mx my gt ju"><div class="bz fp l di"><div class="mz na l"/></div></figure><p id="1d4f" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated"><em class="kz"> amp </em>套餐会帮你搞定大部分事情。如果梯度爆炸或变为零，它甚至会缩放损失。</p><p id="765f" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">在 lightning 中，启用 16 位很简单，不需要修改模型中的任何内容，也不需要做我上面写的事情。设置<a class="ae la" href="https://pytorch-lightning.readthedocs.io/en/latest/trainer.html#pytorch_lightning.trainer.Trainer" rel="noopener ugc nofollow" target="_blank">训练器(精度=16) </a>。</p><figure class="mv mw mx my gt ju"><div class="bz fp l di"><div class="mz na l"/></div></figure><h1 id="a5c3" class="lw lx it bd ly lz nc mb mc md nd mf mg mh ne mj mk ml nf mn mo mp ng mr ms mt bi translated">8.移动到多个 GPU</h1><p id="eea4" class="pw-post-body-paragraph kb kc it kd b ke nz kg kh ki oa kk kl km ob ko kp kq oc ks kt ku od kw kx ky im bi translated">现在，事情变得非常有趣了。有 3 个(可能更多？)多 GPU 训练的方法。</p><p id="768d" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated"><strong class="kd iu">分批训练</strong></p><figure class="mv mw mx my gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="ni nj di nk bf nl"><div class="gh gi oe"><img src="../Images/cfe15cc17820896f2080fe8967c5960a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*YXv5kc5giwjc66mwn6AH1w.png"/></div></div><figcaption class="jx jy gj gh gi jz ka bd b be z dk">A) Copy model on each GPU. B) Give each GPU a portion of the batch.</figcaption></figure><p id="f05b" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">第一种方式应该叫做<em class="kz">分批</em>培训。这种策略将模型复制到每个 GPU 上，每个 GPU 获得一部分批次。</p><figure class="mv mw mx my gt ju"><div class="bz fp l di"><div class="mz na l"/></div></figure><p id="d008" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">在 lightning 中，你可以增加你告诉教练的 GPU 数量，而不必做上述任何事情。</p><figure class="mv mw mx my gt ju"><div class="bz fp l di"><div class="mz na l"/></div></figure><p id="2af0" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated"><strong class="kd iu">分割模型训练</strong></p><figure class="mv mw mx my gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="ni nj di nk bf nl"><div class="gh gi of"><img src="../Images/96c7fed4ac12e22cb893913f044454aa.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*NFa4IpnK9ogXMEGpBY6MxA.png"/></div></div><figcaption class="jx jy gj gh gi jz ka bd b be z dk">Put different parts of the model on different GPUs. Batch moves sequentially</figcaption></figure><p id="b4d6" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">有时你的模型可能太大而不适合内存。例如，带有编码器和解码器的序列到序列模型在生成输出时可能会占用 20 GB 的 RAM。在这种情况下，我们希望将编码器和解码器放在不同的 GPU 上。</p><figure class="mv mw mx my gt ju"><div class="bz fp l di"><div class="mz na l"/></div></figure><p id="a252" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">对于这种类型的训练，不要给闪电训练师任何 GPU。相反，把你自己的模块放到正确的 GPU 上的 LightningModule 中</p><figure class="mv mw mx my gt ju"><div class="bz fp l di"><div class="mz na l"/></div></figure><p id="ed3e" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated"><strong class="kd iu">混合两者</strong></p><p id="3dbf" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">在上述情况下，编码器和解码器仍然可以从并行化每个 操作<strong class="kd iu"> <em class="kz">中受益。我们现在可以变得更有创造力。</em></strong></p><figure class="mv mw mx my gt ju"><div class="bz fp l di"><div class="mz na l"/></div></figure><p id="8549" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">使用多个 GPU 时需要考虑的注意事项</p><ul class=""><li id="d05c" class="lb lc it kd b ke kf ki kj km ld kq le ku lf ky og lh li lj bi translated">model.cuda()不会做任何事情，如果它已经在那个设备上的话。</li><li id="533c" class="lb lc it kd b ke lk ki ll km lm kq ln ku lo ky og lh li lj bi translated">始终将输入放在设备列表中的第一个设备上。</li><li id="9f20" class="lb lc it kd b ke lk ki ll km lm kq ln ku lo ky og lh li lj bi translated">跨设备传输数据非常昂贵，请将此作为最后手段。</li><li id="17e2" class="lb lc it kd b ke lk ki ll km lm kq ln ku lo ky og lh li lj bi translated">优化器和渐变将存储在 GPU 0 上。因此，GPU 0 上使用的内存可能会比其他内存大得多。</li></ul><h1 id="3ad3" class="lw lx it bd ly lz nc mb mc md nd mf mg mh ne mj mk ml nf mn mo mp ng mr ms mt bi translated">9.多节点 GPU 培训</h1><figure class="mv mw mx my gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="ni nj di nk bf nl"><div class="gh gi oh"><img src="../Images/77414f062d8902fd70123196aa574fc1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*BnpnXNzYnlDoiIe50CwuyA.png"/></div></div><figcaption class="jx jy gj gh gi jz ka bd b be z dk">Every GPU on every machine gets a copy of the model. Each machine gets a portion of the data and trains only on that portion. Each machine syncs gradients with the other.</figcaption></figure><p id="dda8" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">如果你已经做到了这一步，你现在已经进入了训练 Imagenet 的领域！这没有您想象的那么难，但是可能需要更多关于您的计算集群的知识。这些说明假设您正在集群上使用 SLURM。</p><p id="d835" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">Pytorch 通过跨每个节点复制每个 GPU 上的模型并同步梯度，允许多节点训练。因此，每个模型在每个 GPU 上独立初始化，本质上在数据分区上独立训练，只是它们都从所有模型接收梯度更新。</p><p id="a2bd" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">在高层次上:</p><ol class=""><li id="df9a" class="lb lc it kd b ke kf ki kj km ld kq le ku lf ky lg lh li lj bi translated">在每个 GPU 上初始化一个模型的副本(确保设置种子，使每个模型初始化为相同的<strong class="kd iu">权重，否则会失败)。</strong></li><li id="aae0" class="lb lc it kd b ke lk ki ll km lm kq ln ku lo ky lg lh li lj bi translated">将数据集切割成子集(使用分布式采样器)。每个 GPU 只在自己的小子集上训练<strong class="kd iu">。</strong></li><li id="7453" class="lb lc it kd b ke lk ki ll km lm kq ln ku lo ky lg lh li lj bi translated">开着。backward()所有副本接收<strong class="kd iu">所有</strong>模型的渐变副本。这是模型之间唯一的一次交流。</li></ol><p id="e876" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">Pytorch 有一个很好的抽象，叫做 DistributedDataParallel，可以帮你做到这一点。要使用 DDP，您需要做以下事情:</p><figure class="mv mw mx my gt ju"><div class="bz fp l di"><div class="mz na l"/></div></figure><p id="f7b0" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">Pytorch 团队有一个<a class="ae la" href="https://github.com/pytorch/examples/blob/master/imagenet/main.py" rel="noopener ugc nofollow" target="_blank">不错的教程</a>来看这个的全部细节。</p><p id="4e67" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">然而，在 Lightning 中，这是为您提供的。只需设置节点数标志，剩下的事情就交给你了。</p><figure class="mv mw mx my gt ju"><div class="bz fp l di"><div class="mz na l"/></div></figure><p id="d48a" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">Lightning 还附带了一个 SlurmCluster 管理器，可以轻松地帮助您提交 SLURM 作业的正确细节(<a class="ae la" href="https://github.com/williamFalcon/pytorch-lightning/blob/master/examples/new_project_templates/multi_node_cluster_template.py#L103-L134" rel="noopener ugc nofollow" target="_blank">示例</a>)。</p><h1 id="9657" class="lw lx it bd ly lz nc mb mc md nd mf mg mh ne mj mk ml nf mn mo mp ng mr ms mt bi translated">10.奖金！在单个节点上进行更快的多 GPU 训练</h1><p id="4cf8" class="pw-post-body-paragraph kb kc it kd b ke nz kg kh ki oa kk kl km ob ko kp kq oc ks kt ku od kw kx ky im bi translated">事实证明，分布式数据并行比数据并行快得多，因为它执行的唯一通信是梯度同步。因此，一个好的方法是用它代替 DataParallel，即使是在单台机器上训练时</p><p id="b71f" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">在 Lightning 中，这很容易通过将 distributed_backend 设置为<strong class="kd iu"> ddp </strong>并设置 GPU 的数量来实现。</p><figure class="mv mw mx my gt ju"><div class="bz fp l di"><div class="mz na l"/></div></figure></div><div class="ab cl lp lq hx lr" role="separator"><span class="ls bw bk lt lu lv"/><span class="ls bw bk lt lu lv"/><span class="ls bw bk lt lu"/></div><div class="im in io ip iq"><h1 id="989e" class="lw lx it bd ly lz ma mb mc md me mf mg mh mi mj mk ml mm mn mo mp mq mr ms mt bi translated">通过模型加速进行思考</h1><p id="5bb0" class="pw-post-body-paragraph kb kc it kd b ke nz kg kh ki oa kk kl km ob ko kp kq oc ks kt ku od kw kx ky im bi translated">虽然这个指南会给你一个提高网络速度的技巧列表，但是我会解释我是如何通过寻找瓶颈来思考的。</p><p id="6d4a" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">我将模型分成几个部分:</p><p id="5fcd" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">首先，我确保我的数据加载没有瓶颈。为此，我使用我描述的现有数据加载解决方案，但是如果没有一个适合您的需要，那么考虑离线处理并缓存到高性能数据存储中，比如 h5py。</p><p id="8ca3" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">接下来看看你在训练步骤中做了什么。确保你的向前传递是快速的，避免过多的计算，并尽量减少 CPU 和 GPU 之间的数据传输。最后，避免做降低 GPU 速度的事情(在本指南中讨论)</p><p id="e67d" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">接下来，我尝试最大化我的批处理大小，这通常会受到 GPU 内存量的限制。这是一个关于跨 GPU 分布的游戏，同时最大限度地减少延迟，以有效地使用大批量(例如，在 Imagenet 上，我可能会尝试跨许多 GPU 获得 8，000+的有效批量。)</p><p id="4871" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">但是，您需要小心大批量。针对您的具体问题查阅文献，看看人们是如何解决的！</p><p id="c9f7" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated"><strong class="kd iu">致谢</strong></p><p id="465f" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">感谢<a class="ae la" href="https://research.fb.com/people/johnson-jeff/" rel="noopener ugc nofollow" target="_blank"> Jeff Johnson </a>带来的令人惊叹的 CUDA 洞察，感谢 Pytorch 团队帮助 DDP 工作(更不用说他们令人惊叹的框架和文档)。感谢我实验室成员的测试帮助(特别是<a class="ae la" href="https://deepai.org/machine-learning/researcher/cinjon-resnick" rel="noopener ugc nofollow" target="_blank">辛乔恩·雷斯尼克</a>)。</p></div></div>    
</body>
</html>