<html>
<head>
<title>Train a lines segmentation model using Pytorch</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用 Pytorch 训练线条分割模型</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/train-a-lines-segmentation-model-using-pytorch-34d4adab8296?source=collection_archive---------9-----------------------#2019-09-14">https://towardsdatascience.com/train-a-lines-segmentation-model-using-pytorch-34d4adab8296?source=collection_archive---------9-----------------------#2019-09-14</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><p id="c21c" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">让我们从确定<a class="ae kl" href="https://github.com/full-stack-deep-learning/fsdl-text-recognizer-project/blob/5574813a0ee48cccd067092e5bd024953c264f67/lab6_sln/readme.md#lab-6-line-detection" rel="noopener ugc nofollow" target="_blank">我们想要解决的问题</a>开始，这个问题是由<a class="ae kl" href="https://github.com/full-stack-deep-learning/fsdl-text-recognizer-project" rel="noopener ugc nofollow" target="_blank">这个项目</a>激发的。</p><blockquote class="km kn ko"><p id="2d5f" class="jn jo kp jp b jq jr js jt ju jv jw jx kq jz ka kb kr kd ke kf ks kh ki kj kk ij bi translated">给定包含文本行的图像，返回该图像的像素标签，每个像素属于背景或手写行。</p></blockquote></div><div class="ab cl kt ku hu kv" role="separator"><span class="kw bw bk kx ky kz"/><span class="kw bw bk kx ky kz"/><span class="kw bw bk kx ky"/></div><div class="ij ik il im in"><h1 id="2286" class="la lb iq bd lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx bi translated"><a class="ae kl" href="https://github.com/MostafaGazar/lines-segmentation-pytorch" rel="noopener ugc nofollow" target="_blank">项目</a>结构</h1><p id="4d29" class="pw-post-body-paragraph jn jo iq jp b jq ly js jt ju lz jw jx jy ma ka kb kc mb ke kf kg mc ki kj kk ij bi translated">它由 5 个主要部分组成，一个用于笔记本，一个用于共享 python 代码、数据集、Google Cloud 脚本，一个用于保存模型权重。</p><figure class="me mf mg mh gt mi gh gi paragraph-image"><div role="button" tabindex="0" class="mj mk di ml bf mm"><div class="gh gi md"><img src="../Images/b0b5435333c604327ec7dfbcf8dd3e59.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*lqTSR9LNNwOJpSHAfMZy1w.png"/></div></div></figure><p id="0f96" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">在一个生产项目中，您可能会有更多像<code class="fe mp mq mr ms b">web</code>和<code class="fe mp mq mr ms b">api</code>这样的目录。</p><p id="3817" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我还选择使用<code class="fe mp mq mr ms b">pipenv</code>而不是<code class="fe mp mq mr ms b">conda</code>和<code class="fe mp mq mr ms b">virtualenv</code>来管理我的 python 环境。我最近才从<code class="fe mp mq mr ms b">conda</code>切换到<code class="fe mp mq mr ms b">pipenv</code>，我发现它在任何地方都能一如既往地正常工作。</p><p id="f5de" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">对于 GPU 培训，我使用了一个谷歌云实例和一个 T4 英伟达 GPU。Bash 脚本管理实例的生命周期，从最初创建到启动、连接和停止。</p><h2 id="6413" class="mt lb iq bd lc mu mv dn lg mw mx dp lk jy my mz lo kc na nb ls kg nc nd lw ne bi translated">数据</h2><p id="93df" class="pw-post-body-paragraph jn jo iq jp b jq ly js jt ju lz jw jx jy ma ka kb kc mb ke kf kg mc ki kj kk ij bi translated">数据集在<code class="fe mp mq mr ms b">raw</code>目录中的<code class="fe mp mq mr ms b"><a class="ae kl" href="https://en.wikipedia.org/wiki/TOML" rel="noopener ugc nofollow" target="_blank">toml</a></code>文件中描述，一个<code class="fe mp mq mr ms b">toml</code>文件基本上由键、值对组成。git 忽略了<code class="fe mp mq mr ms b">data</code>下的其他目录，因为它们将包含实际的完整数据集下载。</p><h2 id="daf1" class="mt lb iq bd lc mu mv dn lg mw mx dp lk jy my mz lo kc na nb ls kg nc nd lw ne bi translated">笔记本电脑</h2><p id="01d6" class="pw-post-body-paragraph jn jo iq jp b jq ly js jt ju lz jw jx jy ma ka kb kc mb ke kf kg mc ki kj kk ij bi translated">我使用笔记本进行探索，并将其作为构建、清理数据集和构建培训基本管道所需代码的高级容器。</p><h2 id="f76c" class="mt lb iq bd lc mu mv dn lg mw mx dp lk jy my mz lo kc na nb ls kg nc nd lw ne bi translated">Python 文件</h2><p id="487b" class="pw-post-body-paragraph jn jo iq jp b jq ly js jt ju lz jw jx jy ma ka kb kc mb ke kf kg mc ki kj kk ij bi translated">在<code class="fe mp mq mr ms b">src</code>目录下，我保存了可以在不同笔记本之间共享和重用的代码。遵循良好的软件工程实践是快速正确完成工作的关键，在 ML 代码中发现和识别 bug 是非常困难的。这就是为什么你要从小处着手，并经常重申。</p><h2 id="f5eb" class="mt lb iq bd lc mu mv dn lg mw mx dp lk jy my mz lo kc na nb ls kg nc nd lw ne bi translated">python 环境</h2><p id="d9ce" class="pw-post-body-paragraph jn jo iq jp b jq ly js jt ju lz jw jx jy ma ka kb kc mb ke kf kg mc ki kj kk ij bi translated">您可以使用以下命令使用<a class="ae kl" href="https://docs.brew.sh/Homebrew-on-Linux" rel="noopener ugc nofollow" target="_blank"> linuxbrew </a>或<a class="ae kl" href="https://brew.sh" rel="noopener ugc nofollow" target="_blank"> macbrew </a>在 Linux 或 mac 上安装<code class="fe mp mq mr ms b">pipenv</code>:</p><pre class="me mf mg mh gt nf ms ng nh aw ni bi"><span id="5d1d" class="mt lb iq ms b gy nj nk l nl nm">brew install pipenv</span></pre><p id="c454" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">然后您可以使用<code class="fe mp mq mr ms b">pipenv install SOMETHING</code>从您的项目目录中下载您的依赖项。</p></div><div class="ab cl kt ku hu kv" role="separator"><span class="kw bw bk kx ky kz"/><span class="kw bw bk kx ky kz"/><span class="kw bw bk kx ky"/></div><div class="ij ik il im in"><h1 id="d9f8" class="la lb iq bd lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx bi translated">数据集</h1><p id="3643" class="pw-post-body-paragraph jn jo iq jp b jq ly js jt ju lz jw jx jy ma ka kb kc mb ke kf kg mc ki kj kk ij bi translated">我将使用这个<a class="ae kl" href="http://www.fki.inf.unibe.ch/databases/iam-handwriting-database" rel="noopener ugc nofollow" target="_blank">旧的学术数据集</a>作为基础来构建线条分割数据集，以训练一个<a class="ae kl" href="https://arxiv.org/pdf/1505.04597.pdf" rel="noopener ugc nofollow" target="_blank"> UNet </a>小型网络来检测手写线条。</p><p id="576c" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">数据集中的原始图像如下所示，它们还带有定义边界框的 XML 文件。</p><figure class="me mf mg mh gt mi gh gi paragraph-image"><div role="button" tabindex="0" class="mj mk di ml bf mm"><div class="gh gi nn"><img src="../Images/d12cd0800c2f32c4b141b55054490140.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*CCwBzqVXFR-RYlnQ_NOsnQ.jpeg"/></div></div></figure><p id="4209" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">在<code class="fe mp mq mr ms b">notebooks/01-explore-iam-dataset.ipynb</code>我下载了数据集，解压后用 XML 文件中的数据叠加了一些随机图像。</p><figure class="me mf mg mh gt mi gh gi paragraph-image"><div class="gh gi no"><img src="../Images/b879b8976f72213775e9ac38cfe35176.png" data-original-src="https://miro.medium.com/v2/resize:fit:854/format:webp/1*snRvGlt3Z-1Ts6jOyY8fFw.jpeg"/></div></figure><p id="52ff" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">接下来，我裁剪图像并生成遮罩图像来匹配新的尺寸。遮罩图像是我们将用于训练最终模型的地面真实图像。</p><figure class="me mf mg mh gt mi gh gi paragraph-image"><div class="gh gi np"><img src="../Images/9b4c5ffd7520da222cd0cfdb3f2797f8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1080/format:webp/1*_5iaw8K0XgZolJufOr5Ieg.jpeg"/></div></figure><p id="9615" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">最后，我将数据分为训练、有效和测试</p><figure class="me mf mg mh gt mi gh gi paragraph-image"><div role="button" tabindex="0" class="mj mk di ml bf mm"><div class="gh gi nq"><img src="../Images/870bcc4fa514452ab5ce240fbf002f38.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*VIlYaS196ZzXydZ8JTHSEg.png"/></div></div></figure></div><div class="ab cl kt ku hu kv" role="separator"><span class="kw bw bk kx ky kz"/><span class="kw bw bk kx ky kz"/><span class="kw bw bk kx ky"/></div><div class="ij ik il im in"><h1 id="093d" class="la lb iq bd lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx bi translated">网络</h1><p id="4940" class="pw-post-body-paragraph jn jo iq jp b jq ly js jt ju lz jw jx jy ma ka kb kc mb ke kf kg mc ki kj kk ij bi translated">因为我们没有很多数据可用于训练，所以我使用了一个基于 Keras 实现的迷你版本的 UNet 架构。</p><figure class="me mf mg mh gt mi"><div class="bz fp l di"><div class="nr ns l"/></div></figure><p id="f8e9" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">使用这个巨大的库，我可以通过一个特定输入大小的前馈来可视化网络。</p><figure class="me mf mg mh gt mi gh gi paragraph-image"><div role="button" tabindex="0" class="mj mk di ml bf mm"><div class="gh gi nt"><img src="../Images/7c020677d3c56484483342fb8a5c6c53.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*lyKarxl613ppkwho7mwJMQ.png"/></div></div></figure></div><div class="ab cl kt ku hu kv" role="separator"><span class="kw bw bk kx ky kz"/><span class="kw bw bk kx ky kz"/><span class="kw bw bk kx ky"/></div><div class="ij ik il im in"><h1 id="fdb3" class="la lb iq bd lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx bi translated">培训渠道</h1><p id="b71a" class="pw-post-body-paragraph jn jo iq jp b jq ly js jt ju lz jw jx jy ma ka kb kc mb ke kf kg mc ki kj kk ij bi translated">既然我们已经准备好了数据，并且定义了我们想要训练的网络，那么是时候建立一个基本的训练管道了。</p><p id="f27d" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">首先是定义一个火炬<code class="fe mp mq mr ms b">dataset</code>，并使用<code class="fe mp mq mr ms b">DataLoader</code>遍历它</p><pre class="me mf mg mh gt nf ms ng nh aw ni bi"><span id="5cd4" class="mt lb iq ms b gy nj nk l nl nm">from torch.utils.data import Dataset, DataLoader<br/>from torchvision import transforms, utils<br/></span><span id="d9c3" class="mt lb iq ms b gy nu nk l nl nm">class FormsDataset(Dataset):</span><span id="eb4c" class="mt lb iq ms b gy nu nk l nl nm">    def __init__(self, images, masks, num_classes: int, transforms=None):<br/>        self.images = images<br/>        self.masks = masks<br/>        self.num_classes = num_classes<br/>        self.transforms = transforms<br/>    <br/>    def __getitem__(self, idx):<br/>        image = self.images[idx]<br/>        image = image.astype(np.float32)<br/>        image = np.expand_dims(image, -1)<br/>        image = image / 255<br/>        if self.transforms:<br/>            image = self.transforms(image)<br/>            <br/>        mask = self.masks[idx]<br/>        mask = mask.astype(np.float32)<br/>        mask = mask / 255<br/>        mask[mask &gt; .7] = 1<br/>        mask[mask &lt;= .7] = 0<br/>        if self.transforms:<br/>            mask = self.transforms(mask)<br/>    <br/>        return image, mask<br/>    <br/>    def __len__(self):<br/>        return len(self.images)</span><span id="e40d" class="mt lb iq ms b gy nu nk l nl nm">train_dataset = FormsDataset(train_images, train_masks, number_of_classes, get_transformations(True))<br/>train_data_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)<br/>print(f'Train dataset has {len(train_data_loader)} batches of size {batch_size}')</span></pre><p id="2a81" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">接下来，我定义训练循环</p><pre class="me mf mg mh gt nf ms ng nh aw ni bi"><span id="3d15" class="mt lb iq ms b gy nj nk l nl nm"># Use gpu for training if available else use cpu<br/>device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')</span><span id="c3c1" class="mt lb iq ms b gy nu nk l nl nm"># Here is the loss and optimizer definition<br/>criterion = torch.nn.NLLLoss()<br/>optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)</span><span id="2f24" class="mt lb iq ms b gy nu nk l nl nm"># The training loop<br/>total_steps = len(train_data_loader)<br/>print(f"{epochs} epochs, {total_steps} total_steps per epoch")</span><span id="4ab0" class="mt lb iq ms b gy nu nk l nl nm">for epoch in range(epochs):<br/>    for i, (images, masks) in enumerate(train_data_loader, 1):<br/>        images = images.to(device)<br/>        masks = masks.type(torch.LongTensor)<br/>        masks = masks.reshape(masks.shape[0], masks.shape[2], masks.shape[3])<br/>        masks = masks.to(device)<br/>        <br/>        # Forward pass<br/>        outputs = model(images)<br/>        softmax = F.log_softmax(outputs, dim=1)<br/>        loss = criterion(softmax, masks)<br/>        <br/>        # Backward and optimize<br/>        optimizer.zero_grad()<br/>        loss.backward()<br/>        optimizer.step()<br/>        <br/>        if (i) % 100 == 0:<br/>            print (f"Epoch [{epoch + 1}/{epochs}], Step [{i}/{total_steps}], Loss: {loss.item():4f}")</span></pre><p id="eaf2" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">以下是最终的预测</p><figure class="me mf mg mh gt mi gh gi paragraph-image"><div class="gh gi np"><img src="../Images/7d40aaccc1925cbf7ce7393de89ae1d3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1080/format:webp/1*1lbUzDk_pH2hXlLHW1SyFA.jpeg"/></div></figure></div><div class="ab cl kt ku hu kv" role="separator"><span class="kw bw bk kx ky kz"/><span class="kw bw bk kx ky kz"/><span class="kw bw bk kx ky"/></div><div class="ij ik il im in"><p id="6ff9" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">你可以点击查看 TF2 支持的 Keras 项目。</p></div><div class="ab cl kt ku hu kv" role="separator"><span class="kw bw bk kx ky kz"/><span class="kw bw bk kx ky kz"/><span class="kw bw bk kx ky"/></div><div class="ij ik il im in"><p id="8cc4" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">谢谢你能走到这一步。我想说的最后一点是，不幸的是，大多数可用的在线材料要么提供了糟糕的建议，要么非常基本，它们实际上没有提供多少价值，有些是完全错误的。有一些很棒的资源，比如他们的 60 分钟闪电战系列(T1)和很棒的 T2 API 文档(T3)。还有这个<a class="ae kl" href="https://pytorch.org/tutorials/beginner/ptcheat.html?highlight=loss" rel="noopener ugc nofollow" target="_blank">小抄</a>和这个<a class="ae kl" href="https://github.com/yunjey/pytorch-tutorial" rel="noopener ugc nofollow" target="_blank">伟大的 GitHub 回购</a>。</p></div><div class="ab cl kt ku hu kv" role="separator"><span class="kw bw bk kx ky kz"/><span class="kw bw bk kx ky kz"/><span class="kw bw bk kx ky"/></div><div class="ij ik il im in"><p id="9c20" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">如果你喜欢阅读这篇文章，或者觉得它有帮助，我很乐意收到你的来信，给我留言或者在 Twitter 上关注我，当我发布新内容时，你会得到通知。</p></div></div>    
</body>
</html>