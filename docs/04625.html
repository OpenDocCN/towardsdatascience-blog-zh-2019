<html>
<head>
<title>Multi GPU, multi process with Tensorflow</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">采用 Tensorflow 的多 GPU、多进程</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/multi-gpu-multi-process-with-tensorflow-ba4cc2fe3ab7?source=collection_archive---------13-----------------------#2019-07-15">https://towardsdatascience.com/multi-gpu-multi-process-with-tensorflow-ba4cc2fe3ab7?source=collection_archive---------13-----------------------#2019-07-15</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="7402" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">如何加快你学习算法的速度</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/805d4193af727beb076eab9fea2b1a43.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*6AMxjSk-rutpOumTVzpLzA.jpeg"/></div></div></figure><p id="18ca" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">Tensorflow 是一个实验深度学习算法的巨大工具。但是，要利用深度学习的力量，你需要利用它的计算能力和良好的工程技术。您最终将需要使用多个 GPU，甚至可能是多个进程来达到您的目标。推荐你先看看 TensorFlow 关于 GPU 的<a class="ae lq" href="https://www.tensorflow.org/guide/using_gpu" rel="noopener ugc nofollow" target="_blank">官方教程</a>。</p><h1 id="4254" class="lr ls it bd lt lu lv lw lx ly lz ma mb jz mc ka md kc me kd mf kf mg kg mh mi bi translated">一个进程，多个 GPU</h1><p id="a6b7" class="pw-post-body-paragraph ku kv it kw b kx mj ju kz la mk jx lc ld ml lf lg lh mm lj lk ll mn ln lo lp im bi translated">这是最常见的情况，因为大多数深度学习社区正在进行监督学习，有一个大数据集(图像、文本、声音……)和许多参数。这也是最困难的一点:您需要在多个计算单元上并行化反向传播。</p><p id="12d3" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">Jonathan Hui 在 2017 年就此贴了一篇<a class="ae lq" href="https://jhui.github.io/2017/03/07/TensorFlow-GPU/" rel="noopener ugc nofollow" target="_blank">的优秀文章</a>，大家可以直接看。这不是本文的重点。</p><h1 id="d0aa" class="lr ls it bd lt lu lv lw lx ly lz ma mb jz mc ka md kc me kd mf kf mg kg mh mi bi translated">多个进程，多个 GPU</h1><p id="2a9b" class="pw-post-body-paragraph ku kv it kw b kx mj ju kz la mk jx lc ld ml lf lg lh mm lj lk ll mn ln lo lp im bi translated">这才是本文真正的看点。如果你正在进行强化学习，或者“奇特”类型的学习，比如遗传算法或水库计算，你可能会注意到拥有多个过程是必不可少的。</p><h2 id="4203" class="mo ls it bd lt mp mq dn lx mr ms dp mb ld mt mu md lh mv mw mf ll mx my mh mz bi translated">实验</h2><p id="2f6b" class="pw-post-body-paragraph ku kv it kw b kx mj ju kz la mk jx lc ld ml lf lg lh mm lj lk ll mn ln lo lp im bi translated">我们将尝试以解决贪吃蛇游戏为例。蛇是一串方块，目标是吃格子上的水果。吃一个水果，蛇长增长一，格子上随机出现一个新的水果。蛇(不小心)吃了自己的尾巴就输了。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi na"><img src="../Images/27ab1a38c353f153a02dbf47b217c503.png" data-original-src="https://miro.medium.com/v2/resize:fit:1200/format:webp/1*qZYqpnN23bAao_5pqBnBig.png"/></div><figcaption class="nb nc gj gh gi nd ne bd b be z dk">Snake game, the red dot is the fruit</figcaption></figure><p id="12d5" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">我们将让多个代理同时进行游戏，以加速学习过程。</p><h2 id="7a77" class="mo ls it bd lt mp mq dn lx mr ms dp mb ld mt mu md lh mv mw mf ll mx my mh mz bi translated">代理人</h2><p id="72fc" class="pw-post-body-paragraph ku kv it kw b kx mj ju kz la mk jx lc ld ml lf lg lh mm lj lk ll mn ln lo lp im bi translated">我们将使用一个简单的卷积神经网络，但您可以使用任何您想要的模型。例如，我们也可以使用密集神经网络或决策树。</p><p id="10a8" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">这个博弈不是“动态的”:代理人需要采取的策略只取决于最后一帧。因此，网络被输入最后一帧，在我开发的 python 版本中是一个 10x10 的图像。我使用 100 个 4x4 过滤器，然后是 200 个 3x3 过滤器。我最后展平卷积，添加一个 200 的密集层，最后输出层的长度为 4，用于 4 个可能的动作(上，右，左，下)。</p><h2 id="16ed" class="mo ls it bd lt mp mq dn lx mr ms dp mb ld mt mu md lh mv mw mf ll mx my mh mz bi translated">学习</h2><p id="13b2" class="pw-post-body-paragraph ku kv it kw b kx mj ju kz la mk jx lc ld ml lf lg lh mm lj lk ll mn ln lo lp im bi translated">我们就不赘述了，因为这不是这里的重点。例如，您可以使用<strong class="kw iu">策略梯度</strong>，其中输出层包含每个动作的概率，算法的思想是根据动作导致的分数“提升”动作。推荐你看<a class="ae lq" href="https://medium.com/@jonathan_hui/rl-policy-gradients-explained-9b13b688b146" rel="noopener">这篇文章</a>。</p><p id="0bc7" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">也可以使用<strong class="kw iu"> Q-learning，</strong>其中输出层包含指定状态(输入帧)下每个动作的平均分数，取这些分数的 argmax 来选择一个动作。我推荐你阅读<a class="ae lq" rel="noopener" target="_blank" href="/how-to-teach-an-ai-to-play-games-deep-reinforcement-learning-28f9b920440a">这篇文章</a>。</p><p id="d717" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">最后，你还可以使用一种<strong class="kw iu">遗传算法</strong>，这种算法的思想是在参数(这里是网络的权重)中加入噪声，只保留最好的代理。推荐你看<a class="ae lq" href="https://blog.coast.ai/lets-evolve-a-neural-network-with-a-genetic-algorithm-code-included-8809bece164" rel="noopener ugc nofollow" target="_blank">这篇文章</a>。</p><h2 id="201a" class="mo ls it bd lt mp mq dn lx mr ms dp mb ld mt mu md lh mv mw mf ll mx my mh mz bi translated"><strong class="ak">让我们多重处理它</strong></h2><p id="5ef5" class="pw-post-body-paragraph ku kv it kw b kx mj ju kz la mk jx lc ld ml lf lg lh mm lj lk ll mn ln lo lp im bi translated">好了，现在我们可以(终于！)说说多重处理。总的来说，这不是一项容易的任务。这里我不谈论多线程，它更简单，但功能也更弱。</p><p id="7538" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">多重处理意味着多核。您需要与您想要启动的进程一样多的内核(有时内核可以处理多个“线程”，所以这是您最终关心的数字)。</p><p id="6c8d" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">我们将使用来自 AWS 的实例 p3.8xlarge，提供 32 个 vCores 和 4 个 V100 显卡。AWS 以大约 12 美元/小时的价格租赁它，而这台设备的投资大约为 4.5 万美元，加上运行它所需的能源成本。</p><p id="bfb6" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">因此，我们可以同时运行 32 个不同的代理，每个代理在一个单独的进程中运行。我们将使用 python 中的“多重处理”包。这个包允许我们启动进程并创建与它们通信的管道。这是我们架构的拓扑结构:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nf"><img src="../Images/382cbcdd7903449b86d9d75c177f9416.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*e4SwXWnhyi-sHJXJ39DgVg.png"/></div></div><figcaption class="nb nc gj gh gi nd ne bd b be z dk">Graph of multiprocessing</figcaption></figure><p id="df21" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">我们有 32 个工作进程和 1 个主进程。工作进程只是玩游戏来收集数据并将其发送给主进程，主进程将根据这些数据进行训练，并将新网络保存在一个文件中。然后，工作人员收到消息以加载新网络，加载它，并再次玩 N 个游戏。因此，我们需要从主流程启动 32 个流程，并在主流程和每个流程之间创建一个管道(即 32 个管道)。我们还需要在主进程中创建线程来异步监听管道。下面是它的代码:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="ng nh l"/></div></figure><p id="4395" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">如您所见，我们在开始时创建了流程和管道，然后初始化字典来存储最后的分数和数据批次(键是流程 id)。然后我们创建线程来监听代理并启动它们。通信协议非常简单，只有一个词的消息，像“保存”或“train_with_batchs”。进程间的通信并不容易，因为你只需要传递可序列化的对象，所以基本上是容易解析的数据。例如，您不能直接传递 Tensorflow 会话。最后，我们玩游戏，同时将分数的移动平均值存储在一个文件中。</p><p id="57cd" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">现在我们来看看 AgentProcess 类，它非常简单:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="ng nh l"/></div></figure><p id="383a" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">代理正在创建它的人工智能模型，并使用它来玩游戏。评分方法不是我在这里的重点，但你可以检查它，并调整自己，以获得更好的表现。“数据”是一个三元组(状态、动作、奖励)。相当简单，对吧？</p><h2 id="313f" class="mo ls it bd lt mp mq dn lx mr ms dp mb ld mt mu md lh mv mw mf ll mx my mh mz bi translated">GPU 分配和内存</h2><p id="3c46" class="pw-post-body-paragraph ku kv it kw b kx mj ju kz la mk jx lc ld ml lf lg lh mm lj lk ll mn ln lo lp im bi translated">默认情况下，Tensorflow 会为您的模型选择第一个可用的 GPU，并在设备上为您的进程分配全部内存。我们两个都不要！我们希望我们的工作进程共享一个模型，但分配他们自己的 GPU 集部分供他们自己使用。</p><p id="aa02" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">共享模型非常困难，因为 Tensorflow 不允许在多个进程之间轻松共享图形或会话。我目前正在深入 Tensorflow，看看有没有可能，提高性能。目前，我得到的唯一解决方案是在每个进程中实例化一个新的 Tensorflow 核心，也就是说在 AgentProcess 类中调用“import tensorflow”。每个流程都有自己的图形和会话。</p><p id="4de3" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">对于 GPU 分配，我们有 32 个进程，4 个 GPU，每个 16GB 内存。<strong class="kw iu">增加每个进程的内存会提高运行模型的进程的速度</strong>。但是内存是有限的，所以我们必须手动进行非常严格的优化…训练是由主进程完成的，需要大量内存，所以我为它分配了几乎一整个 GPU。</p><p id="9c2f" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">最终分配是[3，10，10，10](每个 GPU 的进程数，其中第一个也包含主处理器)。要限制内存，您可以使用 per _ process _ GPU _ memory _ fraction 或 gpu_options.allow_growth 手动限制每个进程的比例，这将为您管理内存(不在初始化时分配所有内存，仅在需要时增加内存)。我用的是后者。代码如下:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="ng nh l"/></div></figure><p id="f0da" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">为了强制进程使用特定的 GPU，我使用了环境变量 CUDA_VISIBLE_DEVICES，它独立于派生工作进程的主进程。</p><p id="f917" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">很明显，增加流程的数量可以提高性能，这仅仅是因为处理了更多的批次。</p><h1 id="6b77" class="lr ls it bd lt lu lv lw lx ly lz ma mb jz mc ka md kc me kd mf kf mg kg mh mi bi translated">结论</h1><p id="fbe7" class="pw-post-body-paragraph ku kv it kw b kx mj ju kz la mk jx lc ld ml lf lg lh mm lj lk ll mn ln lo lp im bi translated">可以使用 Tensorflow 在“相当”强大的机器上进行多重处理和真正的强化学习。记住，机器学习不是如何想象一个算法，主要是如何高效地构建它。</p><p id="b217" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">这里是整个<a class="ae lq" href="https://github.com/fazega/snake-rl" rel="noopener ugc nofollow" target="_blank"> github 回购</a>。</p></div></div>    
</body>
</html>