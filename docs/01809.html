<html>
<head>
<title>Localization and Object Detection with Deep Learning</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">具有深度学习的定位和物体检测</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/localization-and-object-detection-with-deep-learning-67b5aca67f22?source=collection_archive---------22-----------------------#2019-03-25">https://towardsdatascience.com/localization-and-object-detection-with-deep-learning-67b5aca67f22?source=collection_archive---------22-----------------------#2019-03-25</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><p id="9c81" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">定位和目标检测是计算机视觉中的两个核心任务，因为它们被应用于许多现实世界的应用中，例如自主车辆和机器人。所以，如果你想在这些行业工作，成为一名计算机视觉专家，或者你想开发一个相关的产品，你最好能很好地掌握它们。但是它们是什么呢？物体检测和定位意味着什么？为什么我们把它们归为一类？</p><p id="36ab" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">重要的事情先来。让我们快速回顾一下最常用的术语及其含义，以避免误解:</p><ul class=""><li id="2aba" class="ko kp it js b jt ju jx jy kb kq kf kr kj ks kn kt ku kv kw bi translated"><strong class="js iu">分类/识别</strong>:给定一幅带有物体的图像，找出那个物体是什么。换句话说，从一组预定义的类别中将其分类。</li><li id="e3c8" class="ko kp it js b jt kx jx ky kb kz kf la kj lb kn kt ku kv kw bi translated"><strong class="js iu">定位:</strong>找到物体所在的位置，并在它周围画一个边界框</li><li id="4ab7" class="ko kp it js b jt kx jx ky kb kz kf la kj lb kn kt ku kv kw bi translated"><strong class="js iu">物体检测</strong>:对图像中的所有物体进行分类检测。给每个对象分配一个类，并围绕它画一个边界框。</li><li id="6048" class="ko kp it js b jt kx jx ky kb kz kf la kj lb kn kt ku kv kw bi translated"><strong class="js iu">语义分割</strong>:将图像中的每一个像素按照其上下文分类，这样每一个像素都被分配到一个对象</li><li id="5078" class="ko kp it js b jt kx jx ky kb kz kf la kj lb kn kt ku kv kw bi translated"><strong class="js iu">实例分割</strong>:将图像中的每一个像素归为一类，这样每一个像素都被分配给一个对象的不同实例</li></ul><p id="42c8" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">但是，请记住，这些术语在科学界没有明确的定义，因此您可能会遇到其中一个具有不同含义的术语。在我的理解中，这些是正确的解释。</p><p id="276a" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">当我们了解基本术语后，是时候做一些定位和物体检测了。我们怎么做呢？这些年来有许多方法，但自从深度学习到来后，卷积神经网络成为了行业标准。记住<strong class="js iu">我们的目标是对物体进行分类和定位</strong>。但是我们确定只有一个物体吗？有没有可能有两个或者三个或者十五个物体？事实上，大多数时候是这样的。</p><p id="7d9c" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">这就是为什么我们可以把我们的问题分成两个不同的问题。在第一种情况下，我们知道对象的数量(我们将该问题称为分类+定位)，而在第二种情况下，我们不知道(对象检测)。我将从第一个开始，因为它是最简单的。</p><figure class="ld le lf lg gt lh gh gi paragraph-image"><div class="gh gi lc"><img src="../Images/7d3a50a9a7a25ea38aac4db068f7d202.png" data-original-src="https://miro.medium.com/v2/resize:fit:1280/format:webp/0*hr9j47NyUZG3AtUo.jpg"/></div></figure><blockquote class="lk ll lm"><p id="f723" class="jq jr ln js b jt ju jv jw jx jy jz ka lo kc kd ke lp kg kh ki lq kk kl km kn im bi translated"><a class="ae lr" href="https://www.youtube.com/channel/UCdKG2JnvPu6mY1NDXYFfN0g" rel="noopener ugc nofollow" target="_blank"> <em class="it">斯坦福大学工程学院</em> </a></p></blockquote><h1 id="6c1f" class="ls lt it bd lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk ml mm mn mo mp bi translated">分类+本地化</h1><p id="882d" class="pw-post-body-paragraph jq jr it js b jt mq jv jw jx mr jz ka kb ms kd ke kf mt kh ki kj mu kl km kn im bi translated">如果我们只有一个对象或者我们知道对象的数量，这实际上是微不足道的。我们可以使用一个卷积神经网络，并训练它<strong class="js iu">不仅对图像进行分类，而且为边界框</strong>输出 4 个坐标。<strong class="js iu">这样，我们将本地化视为简单的回归问题</strong>。</p><p id="e09d" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">例如，我们可以借用一个经过充分研究的模型，如 ResNet 或 Alexnet，它由一堆卷积、池化和其他层组成，并重新调整全连接层的用途，以产生与类别无关的边界框。它如此简单，以至于我们怀疑它是否会有结果。实际上它在实践中运行得很好。当然，您可以使用它并修改架构以服务于特定的问题或增强其准确性，但主要思想仍然存在。</p><p id="7661" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">请务必注意，为了使用这个模型，我们应该有一个训练集，其中包含为类和边界框注释的图像。而且做这样的标注也不是最好玩的。</p><p id="a1bc" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">但是如果我们事先不知道物体的数量呢？然后我们需要进入兔子洞，谈论一些核心的东西。你准备好了吗？之前要不要休息一下？当然，我明白，但是我警告你不要离开。这就是乐趣的开始。</p><h1 id="8f07" class="ls lt it bd lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk ml mm mn mo mp bi translated">目标检测</h1><p id="bc74" class="pw-post-body-paragraph jq jr it js b jt mq jv jw jx mr jz ka kb ms kd ke kf mt kh ki kj mu kl km kn im bi translated">我开玩笑的。关于将要讨论的架构没有什么核心的东西。所有的是一些聪明的想法，使系统不能容忍输出的数量，并减少其计算成本。因此，我们不知道图像中对象的确切数量，我们希望对所有对象进行分类，并在它们周围绘制一个边界框。这意味着模型应该输出的坐标数量不是常数。如果图像有两个物体，我们需要 8 个坐标。如果它有 4 个对象，我们需要 16 个。那么我们如何建立这样一个模型呢？</p><p id="0099" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">传统计算机视觉的一个关键思想是区域提议。我们使用经典 CV 算法(如边缘和形状检测)生成一组可能包含对象的窗口，并且我们仅将这些窗口(或感兴趣的区域)应用于 CNN。要了解更多关于如何提议区域的信息，请务必查看此处的<a class="ae lr" href="https://www.learnopencv.com/selective-search-for-object-detection-cpp-python/" rel="noopener ugc nofollow" target="_blank"/>。</p><p id="80ad" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">这是一篇基础的<a class="ae lr" href="https://arxiv.org/abs/1311.2524" rel="noopener ugc nofollow" target="_blank">论文</a>的基础，该论文介绍了一种叫做 RCNN 的新架构。</p><figure class="ld le lf lg gt lh gh gi paragraph-image"><div role="button" tabindex="0" class="mw mx di my bf mz"><div class="gh gi mv"><img src="../Images/6837ec6a0b18a51e3cdcc4235e942ea7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*1ytl-8Rbpgz56Hf4.jpg"/></div></div></figure><h1 id="6910" class="ls lt it bd lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk ml mm mn mo mp bi translated">R-CNN</h1><p id="14e3" class="pw-post-body-paragraph jq jr it js b jt mq jv jw jx mr jz ka kb ms kd ke kf mt kh ki kj mu kl km kn im bi translated">给定具有多个对象的图像，我们使用提议方法(在 RCNN 的情况下，这种方法称为选择性搜索)生成一些感兴趣的区域，并将这些区域弯曲成固定的大小。我们将每个区域转发到卷积神经网络(如 AlexNet)，它将使用 SVM 为每个区域做出分类决定，并预测每个边界框的回归。该预测是对所提议的区域的校正，该区域可能处于正确的位置，但不是精确的大小和方向。</p><figure class="ld le lf lg gt lh gh gi paragraph-image"><div role="button" tabindex="0" class="mw mx di my bf mz"><div class="gh gi na"><img src="../Images/72c796885281f301f920f19a10e7fa75.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*JpaSXTHQb7e5DLCt.jpg"/></div></div></figure><p id="68b4" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">虽然这个模型产生了很好的结果，但是它有一个主要的问题。这是非常缓慢和计算昂贵的。想象一下，在一般情况下，我们产生 2000 个区域，我们需要将它们存储在磁盘中，我们将它们中的每一个都转发到 CNN 中多次传递，直到它被训练好。为了解决其中的一些问题，该模型的一个改进被称为“快速 RCNN”</p><h1 id="bc57" class="ls lt it bd lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk ml mm mn mo mp bi translated">快速 RCNN</h1><p id="349d" class="pw-post-body-paragraph jq jr it js b jt mq jv jw jx mr jz ka kb ms kd ke kf mt kh ki kj mu kl km kn im bi translated">这个想法很简单。我们将整个图像传递一次，并产生一个特征图，而不是将所有区域逐一传递到卷积层。然后，我们像以前一样(使用一些外部方法)将区域建议投影到特征图上。现在，我们在特征图中有了区域，而不是原始图像，我们可以在一些完全连接的层中转发它们，以输出分类决策和边界框校正。</p><figure class="ld le lf lg gt lh gh gi paragraph-image"><div role="button" tabindex="0" class="mw mx di my bf mz"><div class="gh gi nb"><img src="../Images/ac58ff4d68c553643e9d6df75965aa85.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*NRYpiM1_Og4gm4-S.jpg"/></div></div></figure><p id="ca45" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">请注意，区域投影建议是使用特殊层(ROI 层)实现的，它本质上是一种最大池，池大小取决于输入，因此输出总是具有相同的大小。有关 ROI 层的更多详细信息，请查看这篇伟大的<a class="ae lr" href="https://deepsense.ai/region-of-interest-pooling-explained/" rel="noopener ugc nofollow" target="_blank">文章</a>。</p><h1 id="05a8" class="ls lt it bd lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk ml mm mn mo mp bi translated">更快的 RCNN</h1><p id="0d4c" class="pw-post-body-paragraph jq jr it js b jt mq jv jw jx mr jz ka kb ms kd ke kf mt kh ki kj mu kl km kn im bi translated">我们可以更进一步。使用从卷积层产生的特征图，我们使用区域提议网络而不是依赖于外部系统来推断区域提议。一旦我们有了这些建议，剩下的过程与 Fast-RCNN 相同(前进到 ROI 层，使用 SVM 分类并预测边界框)。棘手的部分是如何训练整个模型，因为我们有多个任务需要处理:</p><ol class=""><li id="da6c" class="ko kp it js b jt ju jx jy kb kq kf kr kj ks kn nc ku kv kw bi translated">区域提议网络应该为每个区域决定它是否包含对象</li><li id="53e8" class="ko kp it js b jt kx jx ky kb kz kf la kj lb kn nc ku kv kw bi translated">并且它需要产生边界框坐标</li><li id="c5db" class="ko kp it js b jt kx jx ky kb kz kf la kj lb kn nc ku kv kw bi translated">整个模型应该对对象进行分类</li><li id="5cbf" class="ko kp it js b jt kx jx ky kb kz kf la kj lb kn nc ku kv kw bi translated">并且再次预测边界框偏移</li></ol><p id="266e" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">如果你想了解更多关于训练部分的内容，你应该检查一下最初的<a class="ae lr" href="https://arxiv.org/abs/1506.01497" rel="noopener ugc nofollow" target="_blank">论文</a>，但是为了给你一个概述，我们需要利用一个多任务损失来包括所有 4 个任务，并将这个损失反向传播到网络。</p><figure class="ld le lf lg gt lh gh gi paragraph-image"><div role="button" tabindex="0" class="mw mx di my bf mz"><div class="gh gi nd"><img src="../Images/2be3ee161b668ebc57b76ffb32dcd7df.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*qfV4jAAhM8Jf-acl.jpg"/></div></div></figure><p id="fac5" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">顾名思义，FasterRCNN 比以前的模型快得多，是大多数现实应用程序的首选。</p><p id="4e55" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">定位和目标检测是一个非常活跃和有趣的研究领域，因为现实世界中的应用需要在计算机视觉任务(自动驾驶汽车、机器人)中具有出色的性能。公司和大学定期就如何提高准确性提出新的想法。</p><p id="ac7e" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">存在另一类用于定位和对象检测的模型，称为单次检测器，其在过去几年中变得非常流行，因为它们甚至更快并且通常需要更少的计算成本。当然，它们不太精确，但它们非常适合嵌入式系统和类似的耗电应用。</p><p id="d4c6" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">但是要了解更多，你必须等待第 2 部分…</p><blockquote class="lk ll lm"><p id="cc14" class="jq jr ln js b jt ju jv jw jx jy jz ka lo kc kd ke lp kg kh ki lq kk kl km kn im bi translated"><strong class="js iu"> <em class="it">如果您有任何想法、评论、问题或者您只想了解我的最新内容，请随时在</em></strong><a class="ae lr" href="https://www.linkedin.com/in/sergios-karagiannakos/" rel="noopener ugc nofollow" target="_blank"><strong class="js iu">Linkedin</strong></a><strong class="js iu">，</strong><a class="ae lr" href="https://twitter.com/KarSergios" rel="noopener ugc nofollow" target="_blank"><strong class="js iu">Twitter</strong></a><strong class="js iu">，</strong><a class="ae lr" href="https://www.instagram.com/sergios_krg/" rel="noopener ugc nofollow" target="_blank"><strong class="js iu">insta gram</strong></a><strong class="js iu">，</strong><a class="ae lr" href="https://github.com/SergiosKar" rel="noopener ugc nofollow" target="_blank"><strong class="js iu">Github</strong></a><strong class="js iu">或在我的</strong></p></blockquote></div><div class="ab cl ne nf hx ng" role="separator"><span class="nh bw bk ni nj nk"/><span class="nh bw bk ni nj nk"/><span class="nh bw bk ni nj"/></div><div class="im in io ip iq"><p id="8bca" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><em class="ln">原载于 2019 年 3 月 25 日</em><a class="ae lr" href="https://sergioskar.github.io/Localization_and_Object_Detection/" rel="noopener ugc nofollow" target="_blank"><em class="ln">sergioskar . github . io</em></a><em class="ln">。</em></p></div></div>    
</body>
</html>