<html>
<head>
<title>Let’s Learn about the ROC AUC Curve by Predicting Spam</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">让我们通过预测垃圾邮件来了解 ROC AUC 曲线</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/lets-learn-about-the-roc-auc-curve-by-predicting-spam-d8007746a6f9?source=collection_archive---------24-----------------------#2019-11-23">https://towardsdatascience.com/lets-learn-about-the-roc-auc-curve-by-predicting-spam-d8007746a6f9?source=collection_archive---------24-----------------------#2019-11-23</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><figure class="gl gn jr js jt ju gh gi paragraph-image"><div class="gh gi jq"><img src="../Images/f53dc89ed6f028e976f8cd829e93d523.png" data-original-src="https://miro.medium.com/v2/resize:fit:1364/format:webp/1*l7HV0iw3JAHABWIB00bujQ.png"/></div></figure><p id="c2e1" class="pw-post-body-paragraph jx jy it jz b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku im bi translated">ROC AUC 曲线比较分类器不同分类阈值的 TPR 和 FPR。</p><p id="34fe" class="pw-post-body-paragraph jx jy it jz b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku im bi translated">ROC AUC 曲线通过评估模型区分不同类别的能力，帮助我们选择工作的最佳模型。</p><p id="acdc" class="pw-post-body-paragraph jx jy it jz b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku im bi translated"><strong class="jz iu">图例:</strong> <br/> ROC =受试者操作曲线<br/> AUC =曲线下面积<br/> TPR =真阳性率<br/> FPR =假阳性率</p><p id="3000" class="pw-post-body-paragraph jx jy it jz b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku im bi translated">在深入了解这一切意味着什么之前，让我们为一个真实的例子绘制一条曲线。</p><h1 id="da19" class="kv kw it bd kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls bi translated"><strong class="ak">举例:预测哪些短信是垃圾短信</strong></h1><p id="e534" class="pw-post-body-paragraph jx jy it jz b ka lt kc kd ke lu kg kh ki lv kk kl km lw ko kp kq lx ks kt ku im bi translated">首先，从<a class="ae ly" href="https://www.kaggle.com/uciml/sms-spam-collection-dataset" rel="noopener ugc nofollow" target="_blank"> Kaggle </a>下载数据集。</p><p id="05c8" class="pw-post-body-paragraph jx jy it jz b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku im bi translated">在熊猫数据框中打开它。</p><pre class="lz ma mb mc gt md me mf mg aw mh bi"><span id="69c3" class="mi kw it me b gy mj mk l ml mm">import pandas as pd</span><span id="6591" class="mi kw it me b gy mn mk l ml mm">df = pd.read_csv('~/Downloads/spam.csv', encoding='ISO-8859-1')<br/>df.head(3)</span></pre><figure class="lz ma mb mc gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="mp mq di mr bf ms"><div class="gh gi mo"><img src="../Images/135b5176873b339c6543c47f62526490.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_CmWS93w_P8qcA0TGb09ZA.png"/></div></div></figure><p id="40bc" class="pw-post-body-paragraph jx jy it jz b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku im bi translated">它看起来像是格式化不良的数据。数据通常就是这样——我们会解决它。</p><p id="8f12" class="pw-post-body-paragraph jx jy it jz b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku im bi translated">将<code class="fe mt mu mv me b">v1</code>转换成你的标签<code class="fe mt mu mv me b">y</code>，将<code class="fe mt mu mv me b">v2</code>转换成你的特征<code class="fe mt mu mv me b">X</code>。标签需要是整数才能输入到模型中，所以<code class="fe mt mu mv me b">if spam</code>设置为<code class="fe mt mu mv me b">1</code>，而<code class="fe mt mu mv me b">if ham</code>设置为<code class="fe mt mu mv me b">0</code>。不知道的话，<code class="fe mt mu mv me b">ham</code>表示不是<code class="fe mt mu mv me b">spam</code>。</p><pre class="lz ma mb mc gt md me mf mg aw mh bi"><span id="9259" class="mi kw it me b gy mj mk l ml mm">import numpy as np</span><span id="cd0a" class="mi kw it me b gy mn mk l ml mm">y = np.array([(1 if i=='spam' else 0) for i in df.v1.tolist()])<br/>X = np.array(df.v2.tolist())</span></pre><p id="847f" class="pw-post-body-paragraph jx jy it jz b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku im bi translated"><code class="fe mt mu mv me b">X</code>现在是字符串数组，<code class="fe mt mu mv me b">y</code>是<code class="fe mt mu mv me b">1's</code>和<code class="fe mt mu mv me b">0's</code>的数组。</p><p id="3d77" class="pw-post-body-paragraph jx jy it jz b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku im bi translated">将数据分成测试集和训练集。请注意，数据尚未矢量化。</p><pre class="lz ma mb mc gt md me mf mg aw mh bi"><span id="7ceb" class="mi kw it me b gy mj mk l ml mm">from sklearn.model_selection import StratifiedShuffleSplit</span><span id="e1a9" class="mi kw it me b gy mn mk l ml mm">splitter = StratifiedShuffleSplit(<br/>    n_splits=1, test_size=0.3, random_state=0<br/>)</span><span id="4761" class="mi kw it me b gy mn mk l ml mm">for train_index, test_index in splitter.split(X, y):<br/>    X_train_pre_vectorize, X_test_pre_vectorize = X[train_index], X[test_index]<br/>    y_train, y_test = y[train_index], y[test_index]</span></pre><p id="461c" class="pw-post-body-paragraph jx jy it jz b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku im bi translated">安装矢量器并转换测试和训练集。</p><pre class="lz ma mb mc gt md me mf mg aw mh bi"><span id="bb94" class="mi kw it me b gy mj mk l ml mm">from sklearn.feature_extraction.text import CountVectorizer</span><span id="304d" class="mi kw it me b gy mn mk l ml mm">vectorizer = CountVectorizer()</span><span id="57b9" class="mi kw it me b gy mn mk l ml mm">X_train = vectorizer.fit_transform(X_train_pre_vectorize)<br/>X_test = vectorizer.transform(X_test_pre_vectorize)</span></pre><p id="b587" class="pw-post-body-paragraph jx jy it jz b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku im bi translated">选择一个分类器并将其安装在训练集上。我任意选择了<code class="fe mt mu mv me b">LogisticRegression</code>。</p><pre class="lz ma mb mc gt md me mf mg aw mh bi"><span id="2267" class="mi kw it me b gy mj mk l ml mm">from sklearn.linear_model import LogisticRegression</span><span id="6179" class="mi kw it me b gy mn mk l ml mm">classifier = LogisticRegression()<br/>classifier.fit(X_train, y_train)</span></pre><p id="80bd" class="pw-post-body-paragraph jx jy it jz b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku im bi translated">通常这是我们预测测试集的类的地方，但是因为我们只是对构建 ROC AUC 曲线感兴趣，跳过它。</p><p id="c1a1" class="pw-post-body-paragraph jx jy it jz b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku im bi translated">让我们预测类的概率，并将结果转换成一个数组。</p><pre class="lz ma mb mc gt md me mf mg aw mh bi"><span id="1553" class="mi kw it me b gy mj mk l ml mm">y_score = classifier.predict_proba(X_test)<br/>y_score = np.array(y_score)<br/>print(y_score)</span></pre><figure class="lz ma mb mc gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="mp mq di mr bf ms"><div class="gh gi mw"><img src="../Images/2bd7cd4a4a13b1f96ccbd29734db86a7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*BwWWT1vfIArbBlMYKxFwkQ.png"/></div></div><figcaption class="mx my gj gh gi mz na bd b be z dk">The 1st index of each inner array is the probability the example’s class is 0. The 2nd index is the probability that example’s class is 1.</figcaption></figure><p id="da01" class="pw-post-body-paragraph jx jy it jz b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku im bi translated">下面的代码可能有点混乱。对 3 个(或更多)类使用<code class="fe mt mu mv me b">label_binarize()</code>会将单个<code class="fe mt mu mv me b">y</code>值<code class="fe mt mu mv me b">[2]</code>转换为<code class="fe mt mu mv me b">[0 0 1]</code>，或者将<code class="fe mt mu mv me b">[0]</code>转换为<code class="fe mt mu mv me b">[1 0 0]</code>，但是对仅有的 2 个类就不一样了。所以我们调用 numpy 的<code class="fe mt mu mv me b">hstack</code>来重新格式化输出。</p><pre class="lz ma mb mc gt md me mf mg aw mh bi"><span id="883b" class="mi kw it me b gy mj mk l ml mm">from sklearn.preprocessing import label_binarize</span><span id="9f45" class="mi kw it me b gy mn mk l ml mm">y_test_bin = label_binarize(y_test, neg_label=0, pos_label=1, classes=[0,1])</span><span id="6f15" class="mi kw it me b gy mn mk l ml mm">y_test_bin = np.hstack((1 - y_test_bin, y_test_bin))<br/>print(y_test_bin)</span></pre><figure class="lz ma mb mc gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="mp mq di mr bf ms"><div class="gh gi nb"><img src="../Images/25aee86b367e8d4d205bf45f4a8f904f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*cMSf_EpJBZkkxoBUlkI86g.png"/></div></div><figcaption class="mx my gj gh gi mz na bd b be z dk">Our label binarized output.</figcaption></figure><p id="f4c7" class="pw-post-body-paragraph jx jy it jz b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku im bi translated">生成曲线。</p><pre class="lz ma mb mc gt md me mf mg aw mh bi"><span id="96f5" class="mi kw it me b gy mj mk l ml mm">from sklearn.metrics import roc_curve, auc<br/>import matplotlib.pyplot as plt</span><span id="b127" class="mi kw it me b gy mn mk l ml mm">fpr = dict()<br/>tpr = dict()<br/>roc_auc = dict()</span><span id="d965" class="mi kw it me b gy mn mk l ml mm">for i in [0,1]:<br/>    # collect labels and scores for the current index<br/>    labels = y_test_bin[:, i]<br/>    scores = y_score[:, i]<br/>    <br/>    # calculates FPR and TPR for a number of thresholds<br/>    fpr[i], tpr[i], thresholds = roc_curve(labels, scores)<br/>    <br/>    # given points on a curve, this calculates the area under it<br/>    roc_auc[i] = auc(fpr[i], tpr[i])</span></pre><p id="ae4d" class="pw-post-body-paragraph jx jy it jz b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku im bi translated">此时，我们可以分别计算 0 类和 1 类的 ROC 曲线。但是为了简单起见，我们将把它们结合起来，生成一条曲线。</p><p id="c3cb" class="pw-post-body-paragraph jx jy it jz b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku im bi translated"><strong class="jz iu">免责声明:</strong>这在类平衡时更有意义，否则它可能会掩盖一个事实，即模型在一个类中表现很差，而在另一个类中表现很好。但是我们还是会在这里学习如何做。</p><p id="2cc1" class="pw-post-body-paragraph jx jy it jz b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku im bi translated">我们将使用“微平均”并对两个类别的 TPR 进行拉平，对 FPR 也是如此。会为我们做这件事。例如，<code class="fe mt mu mv me b">[[1,0],[0,1]]</code>变成了<code class="fe mt mu mv me b">[1,0,0,1]</code></p><pre class="lz ma mb mc gt md me mf mg aw mh bi"><span id="318d" class="mi kw it me b gy mj mk l ml mm">fpr["micro"], tpr["micro"], _ = roc_curve(y_test_bin.ravel(), y_score.ravel())<br/>roc_auc['micro'] = auc(fpr["micro"], tpr["micro"])</span></pre><p id="0bf8" class="pw-post-body-paragraph jx jy it jz b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku im bi translated">现在画出曲线。</p><pre class="lz ma mb mc gt md me mf mg aw mh bi"><span id="b90c" class="mi kw it me b gy mj mk l ml mm">plt.figure()<br/>lw = 2<br/>plt.plot(fpr[1], tpr[1], color='darkorange',<br/>         lw=lw, label='ROC curve (area = %0.2f)' % roc_auc[1])<br/>plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')<br/>plt.xlim([0.0, 1.0])<br/>plt.ylim([0.0, 1.05])<br/>plt.xlabel('False Positive Rate')<br/>plt.ylabel('True Positive Rate')<br/>plt.title('Receiver operating characteristic example')<br/>plt.legend(loc="lower right")<br/>plt.show()</span></pre><figure class="lz ma mb mc gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="mp mq di mr bf ms"><div class="gh gi nc"><img src="../Images/a4a1cbe03baf316c72498746fbe138f3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*NH4EsA7co32QN3gE8HteCg.png"/></div></div><figcaption class="mx my gj gh gi mz na bd b be z dk">My code for plotting was inspired by <a class="ae ly" href="https://scikit-learn.org/stable/auto_examples/model_selection/plot_roc.html" rel="noopener ugc nofollow" target="_blank">sklearn docs</a>.</figcaption></figure><p id="3a57" class="pw-post-body-paragraph jx jy it jz b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku im bi translated">不错！这是一个非常棒的曲线。</p><p id="7543" class="pw-post-body-paragraph jx jy it jz b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku im bi translated">橙色曲线下的面积越大，模型就能更好地区分类别。从另一个角度来看，曲线越靠近左上角越好。</p><h1 id="2c02" class="kv kw it bd kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls bi translated"><strong class="ak">我们所说的“不同的分类阈值”是什么意思？</strong></h1><p id="fedf" class="pw-post-body-paragraph jx jy it jz b ka lt kc kd ke lu kg kh ki lv kk kl km lw ko kp kq lx ks kt ku im bi translated">如果你习惯使用现成的 sklearn 分类器，你会知道<code class="fe mt mu mv me b">.predict</code>输出预测的类。但是您可能不知道这是基于默认的 50%分类阈值。</p><p id="e131" class="pw-post-body-paragraph jx jy it jz b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku im bi translated">大多数分类器，像<code class="fe mt mu mv me b">LogisticRegression</code>都有一个叫做<code class="fe mt mu mv me b">predict_proba()</code>的方法来预测一个例子落入每个类别的概率，而不是调用<code class="fe mt mu mv me b">.predict()</code>。</p><p id="4840" class="pw-post-body-paragraph jx jy it jz b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku im bi translated">使用这个你可以使用你指定的任何阈值重新计算输出的类。</p><h1 id="16c7" class="kv kw it bd kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls bi translated"><strong class="ak">高曲线好背后的直觉是什么？</strong></h1><p id="4de6" class="pw-post-body-paragraph jx jy it jz b ka lt kc kd ke lu kg kh ki lv kk kl km lw ko kp kq lx ks kt ku im bi translated">一个正确分类大多数例子，并且输出接近<code class="fe mt mu mv me b">0.0</code>(不是这个类)或者<code class="fe mt mu mv me b">1.0</code>(是这个类)的预测概率的模型，会有一条类似上面的曲线。</p><p id="ca6c" class="pw-post-body-paragraph jx jy it jz b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku im bi translated">它告诉我们，改变分类阈值不会对模型的分类输出产生太大影响，因为模型非常确信每个例子要么是一个<code class="fe mt mu mv me b">1</code>要么是一个<code class="fe mt mu mv me b">0</code>。</p><p id="201a" class="pw-post-body-paragraph jx jy it jz b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku im bi translated">例如，如果模型输出 SMS 消息是垃圾消息的预测概率为<code class="fe mt mu mv me b">0.9</code>，则将阈值从<code class="fe mt mu mv me b">0.5</code>改变为<code class="fe mt mu mv me b">0.6</code>对输出的类别没有影响。该模型对其输出的类非常有信心。</p><p id="3adf" class="pw-post-body-paragraph jx jy it jz b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku im bi translated">相反，如果模型在<code class="fe mt mu mv me b">0.3</code>到<code class="fe mt mu mv me b">0.7</code>范围内输出大多数预测概率，那么将阈值从<code class="fe mt mu mv me b">0.5</code>移动到<code class="fe mt mu mv me b">0.6</code>将改变输出的类别。你可以说像这样的模型对自己预测的分类不自信。</p><h1 id="c517" class="kv kw it bd kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls bi translated"><strong class="ak">为什么是 ROC 和 AUC？</strong></h1><p id="5b5e" class="pw-post-body-paragraph jx jy it jz b ka lt kc kd ke lu kg kh ki lv kk kl km lw ko kp kq lx ks kt ku im bi translated">该曲线是“ROC 曲线”,其描绘了不同阈值下的 TPR 和 FPR。</p><p id="5930" class="pw-post-body-paragraph jx jy it jz b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku im bi translated">AUC 只是曲线下面积的计算。这是一种不用看曲线就可以量化模型准确性的方法，或者是在目测曲线下的区域不能给出明确的赢家时，比较两个模型之间的曲线。</p><h1 id="36fa" class="kv kw it bd kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls bi translated">什么是 TPR？</h1><p id="78f4" class="pw-post-body-paragraph jx jy it jz b ka lt kc kd ke lu kg kh ki lv kk kl km lw ko kp kq lx ks kt ku im bi translated">真实阳性率。</p><figure class="lz ma mb mc gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="mp mq di mr bf ms"><div class="gh gi nd"><img src="../Images/d823ae8bcf0d94095ec45dac42b8a02f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*8_yjEq2VMV__F-ooWA_mOA.png"/></div></div></figure><p id="de4f" class="pw-post-body-paragraph jx jy it jz b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku im bi translated">TPR 是 TP 数除以 TP 和 FN 之和。</p><p id="246c" class="pw-post-body-paragraph jx jy it jz b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku im bi translated"><strong class="jz iu">示例 1: </strong>预测图像是否是狗的模型。<br/> <strong class="jz iu"> TP </strong>:正确预测了一个狗的形象就是狗。<br/> <strong class="jz iu"> FN: </strong>错误预测一个狗的形象是猫。</p><p id="d14e" class="pw-post-body-paragraph jx jy it jz b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku im bi translated"><strong class="jz iu">例 2 </strong>:预测消息是否为垃圾邮件的模型。<br/> <strong class="jz iu"> TP </strong>:正确预测出一条垃圾短信是垃圾短信。<br/> <strong class="jz iu"> FN </strong>:错误预测垃圾短信是 HAM。</p><h1 id="2c13" class="kv kw it bd kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls bi translated">什么是 FPR？</h1><p id="f99c" class="pw-post-body-paragraph jx jy it jz b ka lt kc kd ke lu kg kh ki lv kk kl km lw ko kp kq lx ks kt ku im bi translated">假阳性率。</p><figure class="lz ma mb mc gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="mp mq di mr bf ms"><div class="gh gi ne"><img src="../Images/f33e217d3e3a49bbf787138875d31776.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*mjDMp8hYl07JSIFGip_RKw.png"/></div></div></figure><p id="d7ab" class="pw-post-body-paragraph jx jy it jz b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku im bi translated">FPR 是 FP 的数除以 FP 和 TN 的和。</p><p id="2af3" class="pw-post-body-paragraph jx jy it jz b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku im bi translated"><strong class="jz iu">例 1: </strong>一个预测图片是否是狗的模型。<br/> <strong class="jz iu"> FP </strong>:错误预测一只猫的形象是一只狗。<br/> <strong class="jz iu"> TN: </strong>正确预测一个形象不是狗。</p><p id="8212" class="pw-post-body-paragraph jx jy it jz b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku im bi translated"><strong class="jz iu">例 2: </strong>预测消息是否为垃圾邮件的模型。<br/> <strong class="jz iu"> FP </strong>:错误地预测到一条 HAM 消息是垃圾消息。<br/> <strong class="jz iu"> TN </strong>:正确预测一条火腿消息是火腿。</p><h1 id="1bea" class="kv kw it bd kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls bi translated"><strong class="ak">ROC AUC 曲线做得不好的地方</strong></h1><p id="b040" class="pw-post-body-paragraph jx jy it jz b ka lt kc kd ke lu kg kh ki lv kk kl km lw ko kp kq lx ks kt ku im bi translated">ROC 曲线不是不平衡数据集的最佳选择。当两个阶层的人数持平时，他们是最好的。否则，模型在对特定类别进行分类时表现良好，可能会掩盖模型在预测其他类别时表现不佳的事实。</p><h1 id="799f" class="kv kw it bd kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls bi translated"><strong class="ak">外卖</strong></h1><ul class=""><li id="dd66" class="nf ng it jz b ka lt ke lu ki nh km ni kq nj ku nk nl nm nn bi translated">ROC AUC 曲线可以让我们深入了解模型在区分类别方面的预测能力。</li><li id="5b4d" class="nf ng it jz b ka no ke np ki nq km nr kq ns ku nk nl nm nn bi translated">AUC 较高的型号通常比 AUC 较低的型号性能更好。</li><li id="0879" class="nf ng it jz b ka no ke np ki nq km nr kq ns ku nk nl nm nn bi translated">ROC AUC 不是严重不平衡数据集的最佳选择。</li></ul></div></div>    
</body>
</html>