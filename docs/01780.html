<html>
<head>
<title>Deep Learning Literature with Kaggle and Google Cloud Platform</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">用 Kaggle 和 Google 云平台深度学习文献</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/deep-learning-literature-with-kaggle-and-google-cloud-platform-6d7d93d14997?source=collection_archive---------8-----------------------#2019-03-24">https://towardsdatascience.com/deep-learning-literature-with-kaggle-and-google-cloud-platform-6d7d93d14997?source=collection_archive---------8-----------------------#2019-03-24</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><figure class="ip iq gp gr ir is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi io"><img src="../Images/20fb2575c32bab63001b0d4ef6cfd053.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*0n_3a-1sRIAEaLQiOhUyDQ.jpeg"/></div></div></figure><div class=""/><p id="598b" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated"><em class="kw">创建自动更新数据集和内核</em></p><p id="b759" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">我第一次发现 Kaggle 是在大约 4 年前，当时我刚开始进入数据世界的旅程。他们的“巨大”数据集和相关内核帮助我了解了许多现代数据科学工具和技术，从那以后我就迷上了它们。</p><p id="a77b" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">该平台有几个部分，包括机器学习竞赛、数据集、内核、论坛和课程。数据集部分是我个人最喜欢的，因为它提供了一个广阔的游乐场来探索你能想象到的任何领域的开放数据。然后你可以通过内核(笔记本)分享你的工作，内核是文本、代码和代码输出的混合体。</p><p id="3990" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">最近，Kaggle 创建了一个 API，允许从命令行更新数据集和内核。通过使用谷歌云平台(GCP)，我们可以安排这种情况定期发生，提供一个自动更新的“仪表板”。这篇博客文章概述了这个过程。</p><h1 id="3864" class="kx ky jb bd kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu bi translated">谷歌云平台</h1><p id="ecb2" class="pw-post-body-paragraph jy jz jb ka b kb lv kd ke kf lw kh ki kj lx kl km kn ly kp kq kr lz kt ku kv ij bi translated">GCP 是一种云计算服务，不仅在注册时提供免费积分，还提供完全免费的计算和存储层。当然，付费的话，你也可以旋转巨大的虚拟机集群，更不用说其他几十种功能，包括一些令人惊叹的大数据和机器学习产品。也有其他的云平台，但是考虑到 Kaggle 是一家谷歌公司，Coursera 上有一系列优秀的<a class="ae ma" href="https://www.coursera.org/googlecloud" rel="noopener ugc nofollow" target="_blank">课程教授 it 的各个方面，我选择了 GCP 的路线。</a></p><h1 id="a214" class="kx ky jb bd kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu bi translated">教程目标</h1><p id="c964" class="pw-post-body-paragraph jy jz jb ka b kb lv kd ke kf lw kh ki kj lx kl km kn ly kp kq kr lz kt ku kv ij bi translated">内核的这一部分旨在向您展示如何，</p><ol class=""><li id="eb87" class="mb mc jb ka b kb kc kf kg kj md kn me kr mf kv mg mh mi mj bi translated">创建一个 GCP 帐户</li><li id="5b6e" class="mb mc jb ka b kb mk kf ml kj mm kn mn kr mo kv mg mh mi mj bi translated">创建虚拟机和存储桶</li><li id="5b81" class="mb mc jb ka b kb mk kf ml kj mm kn mn kr mo kv mg mh mi mj bi translated">从 API 获取数据</li><li id="9e3c" class="mb mc jb ka b kb mk kf ml kj mm kn mn kr mo kv mg mh mi mj bi translated">通过 GCP 在 Kaggle 上创建定期更新的数据集</li><li id="9683" class="mb mc jb ka b kb mk kf ml kj mm kn mn kr mo kv mg mh mi mj bi translated">通过 GCP 在 Kaggle 上创建一个定期更新的内核</li></ol><h1 id="bba5" class="kx ky jb bd kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu bi translated">具体的核心目标</h1><p id="eb90" class="pw-post-body-paragraph jy jz jb ka b kb lv kd ke kf lw kh ki kj lx kl km kn ly kp kq kr lz kt ku kv ij bi translated">这些年来，我或者和我一起工作的人有几次想要了解科学文献的某个特定领域在做什么。最近，这使我来到了<a class="ae ma" href="https://www.ncbi.nlm.nih.gov/home/develop/api/" rel="noopener ugc nofollow" target="_blank">国家生物技术信息中心(NCBI) API </a>，它允许下载科学论文的细节，包括特定日期范围内的完整摘要。这给了我一个想法，使用 R 脚本定期下载这样的细节，给我和我的同事一个过去的概述和现在的快照。一旦剧本写好了，我需要一种自动化的方法，这让我找到了 GCP。最后，我意识到这可能会引起其他人的兴趣，所以决定创建这个帖子来解释这个方法。</p><p id="1225" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">如果我没有告诉你 Rachael Tatman 在 dashboarding 上的伟大系列内核，那将是我的失职，这给了我这个项目的灵感。</p><p id="d038" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">下面是这个项目的概述，给你一个所有部分如何一起插槽的想法，</p><figure class="mq mr ms mt gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi mp"><img src="../Images/1a9b41cf44643ecccbd384a76d3b6657.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Z67YbII30hUqvvYKa7ssSQ.jpeg"/></div></div></figure><h1 id="2c85" class="kx ky jb bd kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu bi translated">创建一个谷歌云平台账户</h1><p id="526a" class="pw-post-body-paragraph jy jz jb ka b kb lv kd ke kf lw kh ki kj lx kl km kn ly kp kq kr lz kt ku kv ij bi translated">前往<a class="ae ma" href="https://cloud.google.com/" rel="noopener ugc nofollow" target="_blank"> GCP </a>并报名。现在，在某个时候，你会被要求建立一个账单账户，这是我最初不愿意做的。基本上，我能想到的就是…<em class="kw">“如果我不小心启动了世界上最大的集群，忘了停用 6 个月，结果破产了怎么办？”</em>。然而，我随后发现了他们的定价页面，并密切关注了所有免费内容的部分。也就是说，12 个月的 300 美元信用额<em class="kw">加上</em>一个完全免费的等级。更多详情见<a class="ae ma" href="https://cloud.google.com/free/" rel="noopener ugc nofollow" target="_blank">此处</a>。此外，随着时间的推移，留意我们账户的<strong class="ka jc">账单</strong>部分，以确保没有任何疯狂的事情发生。</p><h1 id="2928" class="kx ky jb bd kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu bi translated">创建实例</h1><p id="b020" class="pw-post-body-paragraph jy jz jb ka b kb lv kd ke kf lw kh ki kj lx kl km kn ly kp kq kr lz kt ku kv ij bi translated">一旦你进去了，你会看到这样的东西…</p><figure class="mq mr ms mt gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi mu"><img src="../Images/c90a695586d15a27e2e0060f9c961ac2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_n92Gd9xw3Ni3syv-8twCw.png"/></div></div></figure><p id="a429" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">一开始这可能有点吓人。我刚刚在 Coursera 上完成了出色的<a class="ae ma" href="https://www.coursera.org/specializations/gcp-data-machine-learning" rel="noopener ugc nofollow" target="_blank"> GCP 数据工程专业课程，并且只使用了提供的一小部分功能。在这篇文章中，我们将关注要点，即<strong class="ka jc">实例</strong>和<strong class="ka jc">桶</strong>。</a></p><p id="fd40" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">一个实例基本上就是 GCP 上的一个虚拟机。在左边的栏上，点击<strong class="ka jc">计算引擎</strong>，然后点击<strong class="ka jc">创建实例</strong>。现在，这就是钱可以进来的地方。从地理区域到 CPU 数量，您可以选择多种不同的方式来设置您的机器。幸运的是，右边有一个成本估算器，它会随着您对选项的操作而更新。</p><figure class="mq mr ms mt gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi mv"><img src="../Images/396409510db549cb4e3d77076ecc0a8e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*aLDGUNIBOYX-wza_6oqZPQ.png"/></div></div></figure><p id="a610" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">首先，给实例起一个自己选择的名字。其次，选择一个地区(我选择了<strong class="ka jc">美国-中央 1 </strong>，因为它包含在自由层中。并非所有都是如此，因此请查看右侧的定价估计)。第三，从<strong class="ka jc">机种</strong>部分选择了<strong class="ka jc"> micro (1 个共享 vCPU) </strong>。这(在撰写本文时)由自由层覆盖。</p><p id="ff9c" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">其余的我都默认了。点击<strong class="ka jc">创建</strong>。</p><h1 id="c734" class="kx ky jb bd kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu bi translated">创建一个桶</h1><p id="1a50" class="pw-post-body-paragraph jy jz jb ka b kb lv kd ke kf lw kh ki kj lx kl km kn ly kp kq kr lz kt ku kv ij bi translated">接下来，您需要一个地方来存储您的数据，尤其是如果您全天都在关闭实例的话。为此，通过点击左上角的<strong class="ka jc"> Google Cloud Platform </strong>返回主控制台屏幕，然后从左边的栏中点击<strong class="ka jc">存储</strong>，接着是<strong class="ka jc">创建存储桶</strong>。</p><figure class="mq mr ms mt gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi mw"><img src="../Images/9e0ba5def86a8d2b9249b663a98d95e4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*4tbW8ECTwOG36az4kuCbdg.png"/></div></div></figure><p id="860e" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">给它起一个你自己选择的名字，其他都保持默认，然后点击<strong class="ka jc"> CREATE </strong>。请注意，默认位置是美国。尽管我在英国，但我离开了这里，因为所有的数据传输都将通过 Kaggle 进行，所以让一切都在同一个国家是有意义的。</p><h1 id="4e4a" class="kx ky jb bd kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu bi translated">安装 Kaggle API</h1><p id="6ea7" class="pw-post-body-paragraph jy jz jb ka b kb lv kd ke kf lw kh ki kj lx kl km kn ly kp kq kr lz kt ku kv ij bi translated">现在是时候使用您创建的实例了。回到主控制台，然后点击<strong class="ka jc">计算引擎</strong>查看您的实例。然后，点击<strong class="ka jc"> SSH </strong>来访问它的 shell。从这一点开始，您可以做任何您通常在 Linux 上做的事情。</p><figure class="mq mr ms mt gt is gh gi paragraph-image"><div class="gh gi mx"><img src="../Images/d9efabc2cb0b19e6cd50f0167d685410.png" data-original-src="https://miro.medium.com/v2/resize:fit:1236/format:webp/1*Rt8lvSOZ7QWxtWdm1DCEdg.jpeg"/></div></figure><h1 id="d74c" class="kx ky jb bd kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu bi translated">安装 R</h1><p id="8cdc" class="pw-post-body-paragraph jy jz jb ka b kb lv kd ke kf lw kh ki kj lx kl km kn ly kp kq kr lz kt ku kv ij bi translated">在这一点上，你可能想做你自己的事情。例如，我使用 R 从 NCBI API 获取数据。但是，您可以使用不同的语言和/或不同的 API。</p><p id="f78b" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">对我来说，我通过键入<strong class="ka jc"> sudo apt-get update </strong>后跟<strong class="ka jc">sudo apt-get install R-base</strong>来安装 R。为了从 API 中获取数据，我使用了<strong class="ka jc"> RCurl </strong> R 包，在破解了一点 R 代码之后，我意识到我需要安装一些其他的东西…</p><ul class=""><li id="f96e" class="mb mc jb ka b kb kc kf kg kj md kn me kr mf kv my mh mi mj bi translated"><strong class="ka jc"> sudo apt-get 安装资质</strong></li><li id="6eab" class="mb mc jb ka b kb mk kf ml kj mm kn mn kr mo kv my mh mi mj bi translated"><strong class="ka jc">sudo apt-get install lib curl 4-OpenSSL-dev</strong></li><li id="ba82" class="mb mc jb ka b kb mk kf ml kj mm kn mn kr mo kv my mh mi mj bi translated"><strong class="ka jc"> sudo apt-get 安装 libxml2-dev </strong></li></ul><p id="6926" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">一旦完成，用<strong class="ka jc"> sudo R </strong>启动 R，然后键入<strong class="ka jc">install . packages(' RCurl ')</strong>并选择一个合适的镜像。再说一遍，用户网站是有意义的。对包<strong class="ka jc"> jsonlite </strong>和<strong class="ka jc"> XML </strong>做同样的操作。用<strong class="ka jc"> q() </strong>退出 R。它将询问您是否要保存工作区图像。键入<strong class="ka jc"> n </strong>并按回车键。</p><p id="746b" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">然后我用<strong class="ka jc"> nano literature_update 从命令行创建了一个 R 脚本。R </strong></p><p id="fcd0" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">下面的脚本是我用来从 API 获取最新论文细节的。它使用两个 API 命令。第一个获取给定日期范围内(实际上是从今天算起过去的天数)匹配特定搜索条件的所有论文。在这种情况下，我在最后一天使用术语“深入”和“学习”。这样做的结果是一个 XML 文件，其中包含每张纸的 ID 号。然后脚本遍历这个列表，请求每个 ID 的论文细节。这些细节包括您所期望的一切，比如文章标题、作者细节，甚至是完整的摘要。我将每个文件保存到一个单独的 XML 文件中。</p><p id="710b" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">复制并粘贴 R 脚本(或者使用适当的 API 命令编写自己的脚本)，然后保存并退出(CTRL-X，后跟' Y ')。</p><p id="58c2" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">注意，对于一些 API，比如 Kaggle API，您可能需要指定一个用户名和密钥，或者作为环境变量，或者在一个 JSON 文件中。您选择的 API 将在这方面为您提供指导。NCBI API 没有这样的要求。</p><pre class="mq mr ms mt gt mz na nb nc aw nd bi"><span id="5744" class="ne ky jb na b gy nf ng l nh ni">library('RCurl')<br/>library('jsonlite')<br/>library('XML')</span><span id="bc06" class="ne ky jb na b gy nj ng l nh ni">search1 = 'deep'<br/>search2 = 'learning'<br/>since = '1' #days</span><span id="1f99" class="ne ky jb na b gy nj ng l nh ni">xml_folder = paste('xml_files_', search1, '_', search2, '/', sep = "")<br/>dir.create(file.path(xml_folder), showWarnings = FALSE)</span><span id="8b8c" class="ne ky jb na b gy nj ng l nh ni">#Function to get paper data<br/>get_and_parse = function(id) {</span><span id="823e" class="ne ky jb na b gy nj ng l nh ni">  data &lt;- getURL(paste("https://eutils.ncbi.nlm.nih.gov/entrez/eutils/efetch.fcgi?db=pubmed&amp;retmode=xml&amp;rettype=abstract&amp;id=", id, sep = ""))<br/>  data &lt;- xmlParse(data)</span><span id="b51c" class="ne ky jb na b gy nj ng l nh ni">  return(data)</span><span id="9d95" class="ne ky jb na b gy nj ng l nh ni">}</span><span id="0d42" class="ne ky jb na b gy nj ng l nh ni">#Get the new papers<br/>new_papers &lt;- getURL(paste("https://eutils.ncbi.nlm.nih.gov/entrez/eutils/esearch.fcgi?db=pubmed&amp;term=",<br/>                           search1,<br/>                           "+AND+",<br/>                           search2,<br/>                           "&amp;reldate=",<br/>                           since,<br/>                           "&amp;retmode=json&amp;retmax=10000",<br/>                           sep=""))</span><span id="817f" class="ne ky jb na b gy nj ng l nh ni">new_papers_parsed &lt;- fromJSON(new_papers)<br/>new_paper_ids = new_papers_parsed$esearchresult$idlist<br/>l=length(new_paper_ids)</span><span id="a339" class="ne ky jb na b gy nj ng l nh ni">if(l==0) {'Nothing published!'} else { paste('Found', l, 'new articles in the last', since, 'days relating to', search1, 'and', search2) }</span><span id="4a48" class="ne ky jb na b gy nj ng l nh ni">#Get all the papers and save each one to an XML file</span><span id="2bba" class="ne ky jb na b gy nj ng l nh ni">i=1<br/>while (i&lt;=l) {</span><span id="e998" class="ne ky jb na b gy nj ng l nh ni">  data_temp = get_and_parse(new_paper_ids[i])<br/>#  saveXML(data_temp, file = paste(xml_folder, new_paper_ids[i], '.xml', sep = ""))<br/>  i=i+1</span><span id="c1ec" class="ne ky jb na b gy nj ng l nh ni">}</span></pre><p id="cdbd" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated"><strong class="ka jc">注意:</strong>在上面的代码中，我在搜索最近‘1’天的新论文。当我第一次运行这个脚本时，我运行它来搜索最近的 365 天以获得一年的数据，然后将它更改为 1 天以进行定期更新。</p><h1 id="660c" class="kx ky jb bd kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu bi translated">使用搜索词和您选择的日期范围运行 R 脚本</h1><p id="1597" class="pw-post-body-paragraph jy jz jb ka b kb lv kd ke kf lw kh ki kj lx kl km kn ly kp kq kr lz kt ku kv ij bi translated">现在我有了 R 脚本，我需要运行它。我这样做与<strong class="ka jc"> sudo 脚本文学 _ 更新。R </strong></p><h1 id="d1ea" class="kx ky jb bd kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu bi translated">授权访问存储桶</h1><p id="da70" class="pw-post-body-paragraph jy jz jb ka b kb lv kd ke kf lw kh ki kj lx kl km kn ly kp kq kr lz kt ku kv ij bi translated">我现在有一堆与我下载的所有文章相对应的 XML 文件，存储在一个专用文件夹中。现在，我想将它们备份到我创建的存储桶中。首先，我需要给这个实例访问 bucket 的权限。用下面的代码来做这件事，</p><p id="ac7e" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated"><strong class="ka jc"> gcloud 认证登录</strong></p><p id="e63f" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">这将带你到一组指令。按照它们提供对 bucket 的访问(您需要从浏览器中复制并粘贴代码)。</p><h1 id="e418" class="kx ky jb bd kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu bi translated">将 XML 复制到桶中</h1><p id="9999" class="pw-post-body-paragraph jy jz jb ka b kb lv kd ke kf lw kh ki kj lx kl km kn ly kp kq kr lz kt ku kv ij bi translated">是时候将 XMLs 复制到桶中了。然而，一次做一个文件是没有意义的。相反，让我们把它们放到一个 tar.gz 文件中并上传。用<strong class="ka jc">tar-zcvf literature.tar.gz XML _ files _ deep _ learning</strong>创建归档文件(你可能有不同的文件夹名)，然后用<strong class="ka jc">gsutil CP literature.tar.gz GS://ka ggle _ dataset _ data/</strong>(用你的 bucket 名)传输到 bucket。</p><p id="c50e" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">注意<strong class="ka jc"> gsutil </strong>的使用。这是一个从命令行访问 GCP 存储桶的有用工具。点击了解更多<a class="ae ma" href="https://cloud.google.com/storage/docs/gsutil" rel="noopener ugc nofollow" target="_blank">。</a></p><p id="670d" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">此时，我们已经准备好使用实例上的数据或桶中的数据来创建 Kaggle 数据集。然而，默认情况下，桶中的数据是不公开的，如果我们想使用 Kaggle 网站来创建它，就需要公开。用<strong class="ka jc">gsutil ACL ch-u all users:R GS://ka ggle _ dataset _ data/literature . tar . gz</strong>更改权限(相应更改桶名和文件名)。</p><h1 id="4286" class="kx ky jb bd kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu bi translated">准备使用 Kaggle API</h1><p id="7fcd" class="pw-post-body-paragraph jy jz jb ka b kb lv kd ke kf lw kh ki kj lx kl km kn ly kp kq kr lz kt ku kv ij bi translated">Kaggle API 允许您与 Kaggle 进行完全交互，并为我们提供更新数据集和内核所需的一切。更多详细信息，请参见此处的<a class="ae ma" href="https://github.com/Kaggle/kaggle-api" rel="noopener ugc nofollow" target="_blank"/>。</p><p id="3209" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">首先，我们需要安装 Kaggle API，这需要安装 Python 3。用<strong class="ka jc"> sudo 来安装 python python-dev python 3 python 3-dev</strong></p><p id="2f8a" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">二、用<strong class="ka jc">wget</strong><a class="ae ma" href="https://bootstrap.pypa.io/get-pip.py" rel="noopener ugc nofollow" target="_blank">T3】https://bootstrap.pypa.io/get-pip.pyT5】然后<strong class="ka jc"> sudo python get-pip.py </strong>安装 pip</a></p><p id="3651" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">第三，用<strong class="ka jc"> sudo pip 安装 Kaggle API 安装 kaggle </strong>。然后，进入你的 Kaggle 账户，点击“创建新的 API 令牌”。下载并打开文件，复制上下文，然后在您的 GCP shell 中键入<strong class="ka jc"> nano kaggle.json </strong>。在文件中，粘贴内容，然后保存并关闭文件。最后，用<strong class="ka jc"> mkdir 将它移动到所需的文件夹中。kaggle </strong>然后<strong class="ka jc"> mv kaggle.json。kaggle/ </strong>，并使用<strong class="ka jc"> chmod 600 /home//完成一些权限设置。kaggle/kaggle.json </strong></p><p id="cd8c" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">还有一件事。我后来在使用 kaggle API 时遇到了一个错误，特别是<em class="kw"> ImportError:没有名为 ordered_dict </em>的模块。经过一番搜索，运行下面的代码修复了这个问题…<strong class="ka jc">sudo pip install-U requests</strong></p><h1 id="6adf" class="kx ky jb bd kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu bi translated">从 XML tar 文件创建一个数据集</h1><p id="faed" class="pw-post-body-paragraph jy jz jb ka b kb lv kd ke kf lw kh ki kj lx kl km kn ly kp kq kr lz kt ku kv ij bi translated">此时，你有一个选择。如果您希望 Kaggle 进行更新，请从 bucket 中进行。如果您的数据非常大和/或您计划在大部分时间停用实例，则此选项是最佳选择。如果这是你的要求，从 GCP 控制台，转到<strong class="ka jc">存储</strong>，然后点击你的桶。你应该看到你新上传的 tar.gz 文件和“公共访问”列应设置为“公共”。在单词“Public”旁边，您应该会看到一个链接符号。右键单击并选择<strong class="ka jc">复制链接位置</strong>(或您选择的浏览器中的等效物)。</p><figure class="mq mr ms mt gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi nk"><img src="../Images/555470a73fb89604c37b234f183721b2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*lu-NpV8zh7IgHRrxXGDcCw.jpeg"/></div></div></figure><p id="8be0" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">接下来，在 Kaggle 中，转到<strong class="ka jc">数据集</strong>，然后是<strong class="ka jc">创建新数据集</strong>。给它一个标题，并选择“链接”符号(下面用红色突出显示)。粘贴你的 GCP 桶文件的地址，点击<strong class="ka jc">添加远程文件</strong>。</p><figure class="mq mr ms mt gt is gh gi paragraph-image"><div class="gh gi nl"><img src="../Images/763f3033b15b8e4a35ca77ccbdc2dc5d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1180/format:webp/1*Mfqtf4iENLe8ckp0U9XW2A.png"/></div></figure><p id="8ea5" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">一旦数据集被创建，转到<strong class="ka jc">设置</strong>并选择您选择的更新频率。</p><p id="6155" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">对我来说，假设实例在空闲层，我的数据很小，我将使用 API 从实例存储进行更新(注意，Bucket 指令对于备份数据和文件仍然很有用)。要做到这一点，请忘记上面从 Kaggle 网站创建数据集的说明。相反，从 GCP shell 中，首先用<strong class="ka jc"> kaggle 数据集 init -p /path/to/dataset </strong>创建一个新的 Kaggle 数据集。这将在相应的目录中创建一个元数据 JSON 文件。转到这个目录，并编辑文件。您将看到 slug 和 title 的默认值。将它们分别更改为您选择的目录名和标题。然后，退出并使用<strong class="ka jc"> chmod 777 file_name </strong>更改您将要上传的 tar.gz 文件的权限，然后返回到您的主目录并键入<strong class="ka jc">ka ggle datasets create-p/path/to/dataset</strong>。</p><p id="9576" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">您应该会得到消息<em class="kw">您的私有数据集正在被创建。请在… </em>检查进度。</p><p id="8a69" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">在我的项目中，</p><ul class=""><li id="8652" class="mb mc jb ka b kb kc kf kg kj md kn me kr mf kv my mh mi mj bi translated"><strong class="ka jc"> mkdir 深度学习 _ 文学</strong></li><li id="99b7" class="mb mc jb ka b kb mk kf ml kj mm kn mn kr mo kv my mh mi mj bi translated"><strong class="ka jc">mv literature.tar.gz 深度学习 _ 文学</strong></li><li id="5261" class="mb mc jb ka b kb mk kf ml kj mm kn mn kr mo kv my mh mi mj bi translated"><strong class="ka jc"> kaggle 数据集 init -p 深度学习 _ 文献/ </strong></li><li id="ad30" class="mb mc jb ka b kb mk kf ml kj mm kn mn kr mo kv my mh mi mj bi translated"><strong class="ka jc"> kaggle 数据集创建-p 深度学习 _ 文献/ </strong></li></ul><p id="21ce" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">接下来，转到 Kaggle 并检查数据集是否已经创建。用你认为合适的标题、副标题、背景图片等来调整它。</p><h1 id="7794" class="kx ky jb bd kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu bi translated">如你所愿创建一个内核分析</h1><p id="3b4c" class="pw-post-body-paragraph jy jz jb ka b kb lv kd ke kf lw kh ki kj lx kl km kn ly kp kq kr lz kt ku kv ij bi translated">我们现在有了一个使用 GCP 数据的数据集。此时，只需创建一个内核来分析您希望的数据。在 Kaggle 的内核中(下面的链接)，我有一些从 XML 文件中提取关键数据并绘制图表的代码。</p><h1 id="7daa" class="kx ky jb bd kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu bi translated">自动化流程</h1><p id="bdbe" class="pw-post-body-paragraph jy jz jb ka b kb lv kd ke kf lw kh ki kj lx kl km kn ly kp kq kr lz kt ku kv ij bi translated">如果您选择让 Kaggle 从您的 bucket 更新，那么您需要担心的就是更新 bucket 和您的内核。如果使用 API 从实例存储中更新数据集，也需要处理这个问题。</p><p id="e88c" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">我的方法是将所有这些放入一个 shell 脚本中，如下所示。这有三个部分。首先，脚本运行获取最新深度学习文章的 R 脚本。然后，它创建一个 tar.gz 文件，并将其复制到 bucket(用于备份或 Kaggle 自动更新)以及实例上的一个文件夹中。它还在 bucket 上设置文件的权限。</p><p id="3d00" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">接下来，它等待 15s，然后用<strong class="ka jc">ka ggle datasets version-p ~/deep _ learning _ literature-m“通过来自 Google Cloud 的 API 更新”</strong>来更新数据集。</p><p id="af03" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">最后，它等待 60 秒(以允许数据集得到更新)，然后使用<strong class="ka jc"> kaggle 内核拉 tentotheminus 9/deep-learning-literature-and-GCP-tutorial-m</strong>进行内核更新，然后<strong class="ka jc"> kaggle 内核推</strong>(更改文件夹、存储桶、数据集和内核的名称以匹配您的名称)。</p><p id="2cf0" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">这是完整的脚本。用<strong class="ka jc"> nano update_kaggle.sh </strong>或类似的创建一个合适的文件。</p><pre class="mq mr ms mt gt mz na nb nc aw nd bi"><span id="07fd" class="ne ky jb na b gy nf ng l nh ni">#!/usr/bin/env bash</span><span id="274e" class="ne ky jb na b gy nj ng l nh ni">sudo Rscript literature_update.R<br/>tar -zcvf literature.tar.gz xml_files_deep_learning<br/>gsutil cp literature.tar.gz gs://kaggle_dataset_data/<br/>gsutil acl ch -u AllUsers:R gs://kaggle_dataset_data/literature.tar.gz<br/>cp literature.tar.gz deep_learning_literature/ </span><span id="01d6" class="ne ky jb na b gy nj ng l nh ni">sleep 15s</span><span id="2970" class="ne ky jb na b gy nj ng l nh ni">kaggle datasets version -p ~/deep_learning_literature -m "Updated via API from Google Cloud"</span><span id="4f44" class="ne ky jb na b gy nj ng l nh ni">sleep 60s</span><span id="c477" class="ne ky jb na b gy nj ng l nh ni">kaggle kernels pull tentotheminus9/deep-learning-literature-and-gcp-tutorial -m<br/>kaggle kernels push</span></pre><p id="9837" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">好了，现在是最后一步。我需要告诉我的实例定期触发上面的脚本。首先，用<strong class="ka jc">chmod+x literature _ bucket . sh</strong>(或者随便你的脚本叫什么)使脚本可执行。然后，我们使用<strong class="ka jc"> cron </strong>来设置计时(cron 是 Linux 中调度作业的工具)。</p><p id="e681" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">通过键入<strong class="ka jc"> EDITOR="nano" crontab -e </strong>创建一个 cron 作业。在打开的文件中，以分钟、小时和天的格式设置计时。可能需要一段时间才能搞清楚，所以我推荐<a class="ae ma" href="https://crontab.guru/" rel="noopener ugc nofollow" target="_blank">这个在线工具</a>来帮忙。</p><p id="822c" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">下面是我的 cron 文件。开始时有一些设置，然后是每天早上 7 点触发我的 shell 脚本的命令，</p><pre class="mq mr ms mt gt mz na nb nc aw nd bi"><span id="6626" class="ne ky jb na b gy nf ng l nh ni">#!/usr/bin/env bash</span><span id="b0bc" class="ne ky jb na b gy nj ng l nh ni">SHELL=/bin/sh<br/>PATH=PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/home/tentotheminus9/</span><span id="2d5d" class="ne ky jb na b gy nj ng l nh ni">0 7 * * * 1-literature_bucket_update.sh</span></pre><p id="986f" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">当然，您可以(也应该)首先测试您的脚本。用<strong class="ka jc">做这个。/update_kaggle.sh </strong>(或者随便你怎么称呼)。</p><p id="fbd8" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">仅此而已。一切正常，每天早上下载新论文的细节，备份数据，更新 Kaggle 数据集，然后相应地更新内核。</p><h1 id="9553" class="kx ky jb bd kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu bi translated">未来的改进</h1><p id="037f" class="pw-post-body-paragraph jy jz jb ka b kb lv kd ke kf lw kh ki kj lx kl km kn ly kp kq kr lz kt ku kv ij bi translated">根据 Rachael Tatman 的第五本笔记本，第一个可能改进的地方是错误检查。我一直在研究 XML 验证，但是还没有完全理解。到目前为止，NCBI XML 文件看起来设置得很好，我还没有遇到任何错误。</p><p id="1e99" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">第二个方面是不仅安排 GCP 上脚本的触发，而且安排实例的加速和减速，每天都有一个实例启动脚本重新安装所有内容。从我目前所读到的来看，这种调度实现起来有点棘手，但我会看看将来能做些什么。这当然会为更大规模的资源节省很多钱。</p><h1 id="ed71" class="kx ky jb bd kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu bi translated">内核</h1><p id="57cd" class="pw-post-body-paragraph jy jz jb ka b kb lv kd ke kf lw kh ki kj lx kl km kn ly kp kq kr lz kt ku kv ij bi translated">看完整的 Kaggle 内核<a class="ae ma" href="https://www.kaggle.com/tentotheminus9/deep-learning-literature-and-gcp-tutorial?utm_medium=blog&amp;utm_source=medium&amp;utm_campaign=tentotheminus-medium" rel="noopener ugc nofollow" target="_blank">这里</a>。第一部分是这篇文章的重复，第二部分展示了数据集的一些可视化。例如，下面是最常见的深度学习论文作者的细分…</p><figure class="mq mr ms mt gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi nm"><img src="../Images/e90d3cda82cdff7c0ab952b43a74952b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*7AtEh7diH1NI9UwS.png"/></div></div></figure><p id="a66d" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">希望这篇帖子有用。谢谢！</p></div></div>    
</body>
</html>