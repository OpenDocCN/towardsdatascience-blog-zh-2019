<html>
<head>
<title>All In One Image Dehazing (AOD) — Paper Explanation &amp; Tensorflow Implementation</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">一体化图像去雾(AOD) —论文说明和 Tensorflow 实施</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/all-in-one-image-dehazing-aod-paper-explanation-tensorflow-implementation-bb97f6a6f1ef?source=collection_archive---------14-----------------------#2019-08-15">https://towardsdatascience.com/all-in-one-image-dehazing-aod-paper-explanation-tensorflow-implementation-bb97f6a6f1ef?source=collection_archive---------14-----------------------#2019-08-15</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="a244" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">李博一等对《网:一体化去雾网》论文的解读。艾尔。(ICCV 2017)以及在 Tensorflow 中实现相同功能的教程</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/a42d1fda653d507bdd5168114b25bf2b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*UFW2HGst37sYx28W"/></div></div></figure><h1 id="1774" class="kr ks iq bd kt ku kv kw kx ky kz la lb jw lc jx ld jz le ka lf kc lg kd lh li bi translated">介绍</h1><p id="b271" class="pw-post-body-paragraph lj lk iq ll b lm ln jr lo lp lq ju lr ls lt lu lv lw lx ly lz ma mb mc md me ij bi translated">雾霾会降低图像质量并限制可见度，尤其是在室外环境中。这因此影响了其他高级任务的性能，例如物体检测和识别。</p><p id="7812" class="pw-post-body-paragraph lj lk iq ll b lm mf jr lo lp mg ju lr ls mh lu lv lw mi ly lz ma mj mc md me ij bi translated">李博一等人提出的 AOD 网络。艾尔。是一个端到端的 CNN 来消除图像的模糊。AOD 将模糊图像作为输入，并生成去模糊图像。</p><p id="5798" class="pw-post-body-paragraph lj lk iq ll b lm mf jr lo lp mg ju lr ls mh lu lv lw mi ly lz ma mj mc md me ij bi translated">在这篇文章中，我解释了 AOD 网络论文的主要组成部分，并提供了在 Tensorflow 中实现 AOD 网络的分步指南。</p><p id="c0fc" class="pw-post-body-paragraph lj lk iq ll b lm mf jr lo lp mg ju lr ls mh lu lv lw mi ly lz ma mj mc md me ij bi translated">你可以在这里找到完整的代码。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ml"><img src="../Images/506228f4c4f1f9f6f03e019897a2be22.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*guGtcYLt5ZD_VJu_SmuXfQ.png"/></div></div><figcaption class="mm mn gj gh gi mo mp bd b be z dk"><strong class="bd mq">Left:</strong> Naturally hazy image of a forest scene. <strong class="bd mq">Right:</strong> De-hazed image generated by AOD-net.</figcaption></figure><h1 id="376e" class="kr ks iq bd kt ku kv kw kx ky kz la lb jw lc jx ld jz le ka lf kc lg kd lh li bi translated">论文解释</h1><p id="728a" class="pw-post-body-paragraph lj lk iq ll b lm ln jr lo lp lq ju lr ls lt lu lv lw lx ly lz ma mb mc md me ij bi translated">AOD 假定朦胧图像是根据下述大气散射模型产生的。</p><h2 id="4803" class="mr ks iq bd kt ms mt dn kx mu mv dp lb ls mw mx ld lw my mz lf ma na nb lh nc bi translated"><strong class="ak">大气散射模型</strong></h2><p id="c340" class="pw-post-body-paragraph lj lk iq ll b lm ln jr lo lp lq ju lr ls lt lu lv lw lx ly lz ma mb mc md me ij bi translated">根据 ASM:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi nd"><img src="../Images/47de773df790fa6eff31cc02e1e67a30.png" data-original-src="https://miro.medium.com/v2/resize:fit:1316/format:webp/1*1k4EjDBkQ6U2wnIslCOURw.png"/></div><figcaption class="mm mn gj gh gi mo mp bd b be z dk"><strong class="bd mq">Equation (1)</strong></figcaption></figure><p id="d98d" class="pw-post-body-paragraph lj lk iq ll b lm mf jr lo lp mg ju lr ls mh lu lv lw mi ly lz ma mj mc md me ij bi translated">其中，<br/> I(x):观测到的雾天图像<br/> J(x):原始图像<br/> A:全球大气光照<br/> t(x):传输矩阵</p><p id="6f1e" class="pw-post-body-paragraph lj lk iq ll b lm mf jr lo lp mg ju lr ls mh lu lv lw mi ly lz ma mj mc md me ij bi translated"><em class="ne"> A </em>指整个场景中大气的自然光。<br/> <em class="ne"> t(x) </em>代表物体到达相机的光量。<br/>计算如下:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi nf"><img src="../Images/47a5a444c961de74ced2d2a5e25ab9d2.png" data-original-src="https://miro.medium.com/v2/resize:fit:656/format:webp/1*Cg4AoxuWQ81EGb5FqaP4qg.png"/></div><figcaption class="mm mn gj gh gi mo mp bd b be z dk"><strong class="bd mq">Equation (2)</strong></figcaption></figure><p id="e4fe" class="pw-post-body-paragraph lj lk iq ll b lm mf jr lo lp mg ju lr ls mh lu lv lw mi ly lz ma mj mc md me ij bi translated">其中，<br/> β:散射系数(非负)<br/> d(x):物体与观察者之间的距离(非负)</p><p id="4924" class="pw-post-body-paragraph lj lk iq ll b lm mf jr lo lp mg ju lr ls mh lu lv lw mi ly lz ma mj mc md me ij bi translated">让我们试着理解这一点。</p><p id="b1f5" class="pw-post-body-paragraph lj lk iq ll b lm mf jr lo lp mg ju lr ls mh lu lv lw mi ly lz ma mj mc md me ij bi translated">这个想法是大气在光线到达相机之前会散射来自物体的光线。散射的光量取决于大气属性(由β捕捉)以及物体与相机的距离(由 d(x)捕捉)。其余的光被传输(到达)相机。</p><p id="624a" class="pw-post-body-paragraph lj lk iq ll b lm mf jr lo lp mg ju lr ls mh lu lv lw mi ly lz ma mj mc md me ij bi translated">由于β和 d(x)都是非负的，所以 t(x)的值在范围(0，1)内。0 表示没有来自对象的光到达相机(所有光都被散射)，1 表示来自对象的所有光到达相机(没有散射)。</p><p id="5e50" class="pw-post-body-paragraph lj lk iq ll b lm mf jr lo lp mg ju lr ls mh lu lv lw mi ly lz ma mj mc md me ij bi translated">β值越高，表示大气越倾向于散射光。此外，随着物体远离相机，更多的光被散射。</p><p id="13b9" class="pw-post-body-paragraph lj lk iq ll b lm mf jr lo lp mg ju lr ls mh lu lv lw mi ly lz ma mj mc md me ij bi translated">现在，给定透射值(对于每个像素)和全局大气光线，可以计算相机接收的光线。</p><p id="76f8" class="pw-post-body-paragraph lj lk iq ll b lm mf jr lo lp mg ju lr ls mh lu lv lw mi ly lz ma mj mc md me ij bi translated">如果 t(x)为 1，那么相机可以完美地看到来自物体的光(无散射)。<br/>如果 t(x)为 0，那么相机只看到大气光(完全散射)。<br/>否则，相机会看到物体发出的光和大气之间的线性插值。</p><h2 id="1840" class="mr ks iq bd kt ms mt dn kx mu mv dp lb ls mw mx ld lw my mz lf ma na nb lh nc bi translated"><strong class="ak">问题表述</strong></h2><p id="467b" class="pw-post-body-paragraph lj lk iq ll b lm ln jr lo lp lq ju lr ls lt lu lv lw lx ly lz ma mb mc md me ij bi translated">现有的去雾工作是基于单独估计<em class="ne"> t(x) </em>和<em class="ne"> A </em>。这样做的关键问题是估计误差可能会累积。<br/> AOD 的目的是用公式(1)的以下重新表述，以统一的方式估计这两个参数。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi ng"><img src="../Images/3f93fc259c4a4de555a3418a352ca0cf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1312/format:webp/1*ph_PZcp10OJGF3AohjTqEw.png"/></div><figcaption class="mm mn gj gh gi mo mp bd b be z dk"><strong class="bd mq">Equation (3)</strong></figcaption></figure><p id="fd1b" class="pw-post-body-paragraph lj lk iq ll b lm mf jr lo lp mg ju lr ls mh lu lv lw mi ly lz ma mj mc md me ij bi translated">在哪里，</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nh"><img src="../Images/8cf954d3316c588bc4251fe71afaa216.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*8VrYTU0TlWH8j4fkmvqjEQ.png"/></div></div><figcaption class="mm mn gj gh gi mo mp bd b be z dk"><strong class="bd mq">Equation (4)</strong></figcaption></figure><p id="0164" class="pw-post-body-paragraph lj lk iq ll b lm mf jr lo lp mg ju lr ls mh lu lv lw mi ly lz ma mj mc md me ij bi translated"><em class="ne"> t(x) </em>和<em class="ne"> A </em>被集成到一个变量<em class="ne"> K(x) </em>中，该变量依赖于输入<em class="ne"> I(x) </em>。一旦估计了<em class="ne"> K(x) </em>，就可以使用等式(3)来计算去模糊图像。</p><p id="ce4d" class="pw-post-body-paragraph lj lk iq ll b lm mf jr lo lp mg ju lr ls mh lu lv lw mi ly lz ma mj mc md me ij bi translated">因此，现在的目标是估计<em class="ne"> K(x) </em>使得它最小化去模糊和原始图像之间的均方误差(MSE)。这是通过训练 CNN 来实现的。</p><h2 id="acd6" class="mr ks iq bd kt ms mt dn kx mu mv dp lb ls mw mx ld lw my mz lf ma na nb lh nc bi translated"><strong class="ak">网络设计</strong></h2><p id="dd8f" class="pw-post-body-paragraph lj lk iq ll b lm ln jr lo lp lq ju lr ls lt lu lv lw lx ly lz ma mb mc md me ij bi translated">该网络有两个模块。</p><p id="d183" class="pw-post-body-paragraph lj lk iq ll b lm mf jr lo lp mg ju lr ls mh lu lv lw mi ly lz ma mj mc md me ij bi translated">第一个模块估计<em class="ne"> K(x) </em>。注意，对于尺寸为 W x H x 3 的图像，<em class="ne"> K(x) </em>也具有尺寸 W x H x 3。<br/>第二模块涉及使用等式(3)生成去模糊图像的元素式操作。</p><p id="90d5" class="pw-post-body-paragraph lj lk iq ll b lm mf jr lo lp mg ju lr ls mh lu lv lw mi ly lz ma mj mc md me ij bi translated">K 估计模块是关键的，因为它间接估计大气光和传输矩阵(隐含地计算图像中每个像素的深度)。</p><p id="cc7b" class="pw-post-body-paragraph lj lk iq ll b lm mf jr lo lp mg ju lr ls mh lu lv lw mi ly lz ma mj mc md me ij bi translated">它由 5 个卷积层组成(带有 ReLU 激活)。<br/>每层有 3 个过滤器，但内核大小不同(以生成多尺度特征)。此外，在进行卷积之前，先前层的激活与中间层连接，因为这补偿了卷积期间的信息丢失。</p><p id="d455" class="pw-post-body-paragraph lj lk iq ll b lm mf jr lo lp mg ju lr ls mh lu lv lw mi ly lz ma mj mc md me ij bi translated">网络架构如下所示。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ni"><img src="../Images/683e7e292b80b321abf948adaa6a26b7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*b29IMAdkl5qbnomBHFARkg.png"/></div></div><figcaption class="mm mn gj gh gi mo mp bd b be z dk">AOD-net Architecture</figcaption></figure><p id="1c6a" class="pw-post-body-paragraph lj lk iq ll b lm mf jr lo lp mg ju lr ls mh lu lv lw mi ly lz ma mj mc md me ij bi translated">因此，整个管道看起来像这样:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nj"><img src="../Images/0b17b73e4bcdd766bdd5376c18db9ae7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*2LapBn4GDZ9uQ4yim6YdmQ.png"/></div></div><figcaption class="mm mn gj gh gi mo mp bd b be z dk">AOD-net Prediction Pipeline. (Reference: <a class="ae mk" href="https://sites.google.com/site/boyilics/website-builder/project-page" rel="noopener ugc nofollow" target="_blank">https://sites.google.com/site/boyilics/website-builder/project-page</a>)</figcaption></figure><p id="82df" class="pw-post-body-paragraph lj lk iq ll b lm mf jr lo lp mg ju lr ls mh lu lv lw mi ly lz ma mj mc md me ij bi translated"><strong class="ll ir">数据生成&amp;培训</strong></p><p id="db52" class="pw-post-body-paragraph lj lk iq ll b lm mf jr lo lp mg ju lr ls mh lu lv lw mi ly lz ma mj mc md me ij bi translated">为了训练 AOD 网络，作者生成了人工模糊的图像。基于等式(1)，来自 NYU2 深度数据库(包括每个像素的深度信息)的图像被人工模糊化，具有不同的值<em class="ne"> β </em>和<em class="ne"> A </em>(从均匀随机分布中选择)。因此，对于大约 1500 幅地面真实图像，获得了大约 27K 的模糊图像。</p><p id="c55d" class="pw-post-body-paragraph lj lk iq ll b lm mf jr lo lp mg ju lr ls mh lu lv lw mi ly lz ma mj mc md me ij bi translated">该模型被训练了 10 个时期。权重用标准高斯分布初始化，权重衰减设置为 0.0001。梯度规范被剪切为 0.1。</p><p id="9b8c" class="pw-post-body-paragraph lj lk iq ll b lm mf jr lo lp mg ju lr ls mh lu lv lw mi ly lz ma mj mc md me ij bi translated"><strong class="ll ir">注:</strong>该论文没有提到所使用的确切学习速率，也没有提到确切的优化算法。(我在实现中使用了 0.0001 的学习率和 Adam Optimizer)。</p><p id="7979" class="pw-post-body-paragraph lj lk iq ll b lm mf jr lo lp mg ju lr ls mh lu lv lw mi ly lz ma mj mc md me ij bi translated">作者基于<a class="ae mk" href="https://en.wikipedia.org/wiki/Peak_signal-to-noise_ratio" rel="noopener ugc nofollow" target="_blank"> PSNR </a>和<a class="ae mk" href="https://en.wikipedia.org/wiki/Structural_similarity" rel="noopener ugc nofollow" target="_blank"> SSIM </a>指标，将 AOD 网络的性能与之前的去雾算法进行了比较。</p><p id="065d" class="pw-post-body-paragraph lj lk iq ll b lm mf jr lo lp mg ju lr ls mh lu lv lw mi ly lz ma mj mc md me ij bi translated">现在让我们深入研究一下实现。</p><h1 id="51dd" class="kr ks iq bd kt ku kv kw kx ky kz la lb jw lc jx ld jz le ka lf kc lg kd lh li bi translated">TENSORFLOW 实现</h1><h2 id="5c7e" class="mr ks iq bd kt ms mt dn kx mu mv dp lb ls mw mx ld lw my mz lf ma na nb lh nc bi translated">数据准备</h2><ol class=""><li id="5677" class="nk nl iq ll b lm ln lp lq ls nm lw nn ma no me np nq nr ns bi translated">在此下载训练 AOD 网<a class="ae mk" href="https://docs.google.com/viewer?a=v&amp;pid=sites&amp;srcid=ZGVmYXVsdGRvbWFpbnxib3lpbGljc3xneDpjMjBjM2E3ZTAxZTM0NDU" rel="noopener ugc nofollow" target="_blank">的数据集。有大约 1500 个清晰图像和大约 27K 的人工模糊图像。</a></li><li id="1796" class="nk nl iq ll b lm nt lp nu ls nv lw nw ma nx me np nq nr ns bi translated">将包含干净图像的文件夹重命名为“原始图像”，将包含模糊图像的文件夹重命名为“模糊图像”。</li><li id="9240" class="nk nl iq ll b lm nt lp nu ls nv lw nw ma nx me np nq nr ns bi translated">“原始图像”中的每个图像都有一个格式为“NYU2_x.jpg”的文件名，其中 x 是一个整数。<br/>“hazy _ images”中的每个图像都有一个格式为“NYU2_x_y_z”的文件名，其中 x、y 和 z 是整数。<br/>对于给定的原始图像“NYU2_x.jpg”，人工生成的朦胧图像对于某些 y 和 z 命名为“NYU2_x_y_z”，每个原始图像对应的朦胧图像可以有多个。</li></ol><h2 id="4e34" class="mr ks iq bd kt ms mt dn kx mu mv dp lb ls mw mx ld lw my mz lf ma na nb lh nc bi translated">数据加载</h2><p id="f52e" class="pw-post-body-paragraph lj lk iq ll b lm ln jr lo lp lq ju lr ls lt lu lv lw lx ly lz ma mb mc md me ij bi translated">我们将使用 Tensorflow 数据集 API。</p><ol class=""><li id="5a8c" class="nk nl iq ll b lm mf lp mg ls ny lw nz ma oa me np nq nr ns bi translated">从“orig_images”文件夹中读取原始图像路径并随机播放。将此列表分为两部分(90%-10%分割)，以生成分别用于训练和验证的图像路径列表。</li></ol><pre class="kg kh ki kj gt ob oc od oe aw of bi"><span id="6d65" class="mr ks iq oc b gy og oh l oi oj">orig_image_paths = glob.glob(orig_images_path + “/*.jpg”)<br/>n = len(orig_image_paths) <br/>random.shuffle(orig_image_paths)<br/> <br/>train_keys = orig_image_paths[:int(0.90*n)]<br/>val_keys = orig_image_paths[int(0.90*n):]</span></pre><p id="5da3" class="pw-post-body-paragraph lj lk iq ll b lm mf jr lo lp mg ju lr ls mh lu lv lw mi ly lz ma mj mc md me ij bi translated">2.创建一个字典，将每个原始图像路径映射到图像是用于“train”还是“val”。<br/>请注意，训练集中使用的原始图像集不应与验证集重叠(即使对应的模糊图像不同)，以避免任何信息泄漏。</p><pre class="kg kh ki kj gt ob oc od oe aw of bi"><span id="563c" class="mr ks iq oc b gy og oh l oi oj">split_dict = {}<br/>  <strong class="oc ir">for</strong> key <strong class="oc ir">in</strong> train_keys:<br/>    split_dict[key] = 'train'<br/>  <strong class="oc ir">for</strong> key <strong class="oc ir">in</strong> val_keys:<br/>    split_dict[key] = 'val'</span></pre><p id="fc9f" class="pw-post-body-paragraph lj lk iq ll b lm mf jr lo lp mg ju lr ls mh lu lv lw mi ly lz ma mj mc md me ij bi translated">3.现在，迭代“hazy_images”文件夹中的所有图像路径，提取对应的原始图像的路径(用基本的字符串操作)。<br/>如果原始图像路径对应于“列车”图像，则将<strong class="ll ir"> &lt;原始图像路径、模糊图像路径&gt; </strong>添加到<strong class="ll ir">列车数据</strong>列表中。<br/>否则，将其添加到<strong class="ll ir"> val_data </strong>列表中。</p><pre class="kg kh ki kj gt ob oc od oe aw of bi"><span id="2437" class="mr ks iq oc b gy og oh l oi oj">train_data = []<br/>  val_data = []<br/>  <br/>  hazy_image_paths = glob.glob(hazy_images_path + "/*.jpg")<br/>  <strong class="oc ir">for</strong> path <strong class="oc ir">in</strong> hazy_image_paths:<br/>    label = path.split('/')[-1]<br/>    orig_path = orig_images_path + "/" + label.split('_')[0] + '_' + label.split('_')[1] + ".jpg"<br/>    <strong class="oc ir">if</strong>(split_dict[orig_path] == 'train'):<br/>      train_data.append([path,orig_path])<br/>    <strong class="oc ir">else</strong>: val_data.append([path,orig_path])</span></pre><p id="ab2b" class="pw-post-body-paragraph lj lk iq ll b lm mf jr lo lp mg ju lr ls mh lu lv lw mi ly lz ma mj mc md me ij bi translated">4.使用 Tensorflow 数据集 API，创建训练和验证数据集。首先，通过对训练集的模糊图像路径应用<strong class="ll ir"> from_tensor_slices() </strong>函数来创建<strong class="ll ir"> train_ds_hazy </strong>数据集，随后是加载图像的映射函数(稍后解释)。<br/>接下来，使用训练集的原始图像路径创建一个<strong class="ll ir"> train_ds_orig </strong>数据集(以与之前相同的方式)。最后，压缩两个数据集以创建<strong class="ll ir"> train_ds </strong>。</p><p id="0bab" class="pw-post-body-paragraph lj lk iq ll b lm mf jr lo lp mg ju lr ls mh lu lv lw mi ly lz ma mj mc md me ij bi translated">按照类似的过程创建<strong class="ll ir"> val_ds </strong>。</p><pre class="kg kh ki kj gt ob oc od oe aw of bi"><span id="5004" class="mr ks iq oc b gy og oh l oi oj">train_ds_hazy = tf.data.Dataset.from_tensor_slices([data[0] <strong class="oc ir">for</strong> data <strong class="oc ir">in</strong> train_data]).map(<strong class="oc ir">lambda</strong> x: load_image(x))<br/>  train_ds_orig = tf.data.Dataset.from_tensor_slices([data[1] <strong class="oc ir">for</strong> data <strong class="oc ir">in</strong> train_data]).map(<strong class="oc ir">lambda</strong> x: load_image(x))<br/>  train_ds = tf.data.Dataset.zip((train_ds_hazy,train_ds_orig)).shuffle(100).repeat().batch(batch_size)<br/><br/>  val_ds_hazy = tf.data.Dataset.from_tensor_slices([data[0] <strong class="oc ir">for</strong> data <strong class="oc ir">in</strong> val_data]).map(<strong class="oc ir">lambda</strong> x: load_image(x))<br/>  val_ds_orig = tf.data.Dataset.from_tensor_slices([data[1] <strong class="oc ir">for</strong> data <strong class="oc ir">in</strong> val_data]).map(<strong class="oc ir">lambda</strong> x: load_image(x))<br/>  val_ds = tf.data.Dataset.zip((val_ds_hazy,val_ds_orig)).shuffle(100).repeat().batch(batch_size)</span></pre><p id="5e21" class="pw-post-body-paragraph lj lk iq ll b lm mf jr lo lp mg ju lr ls mh lu lv lw mi ly lz ma mj mc md me ij bi translated">请注意，我们也说过数据集应该被混洗，数据应该以<strong class="ll ir"> batch_size </strong>的批次提取。</p><p id="2f15" class="pw-post-body-paragraph lj lk iq ll b lm mf jr lo lp mg ju lr ls mh lu lv lw mi ly lz ma mj mc md me ij bi translated">5.现在，我们定义一个迭代器来迭代数据集元素。我们使用<strong class="ll ir"> from_structure() </strong> API，这样相同的迭代器可以用于训练和验证数据集。</p><pre class="kg kh ki kj gt ob oc od oe aw of bi"><span id="ddc3" class="mr ks iq oc b gy og oh l oi oj">iterator = tf.data.Iterator.from_structure(train_ds.output_types,train_ds.output_shapes)</span></pre><p id="5ed2" class="pw-post-body-paragraph lj lk iq ll b lm mf jr lo lp mg ju lr ls mh lu lv lw mi ly lz ma mj mc md me ij bi translated">然后我们定义<strong class="ll ir"> train_init_op </strong>和<strong class="ll ir"> val_init_op </strong>操作。运行这些操作告诉迭代器是分别从训练数据集还是验证数据集中选取数据。</p><pre class="kg kh ki kj gt ob oc od oe aw of bi"><span id="cf17" class="mr ks iq oc b gy og oh l oi oj">train_init_op = iterator.make_initializer(train_ds)<br/>val_init_op = iterator.make_initializer(val_ds)</span></pre><p id="335c" class="pw-post-body-paragraph lj lk iq ll b lm mf jr lo lp mg ju lr ls mh lu lv lw mi ly lz ma mj mc md me ij bi translated">6.最后，我们定义了<strong class="ll ir"> next_element </strong>操作，可以调用它从迭代器中读取下一批数据。</p><pre class="kg kh ki kj gt ob oc od oe aw of bi"><span id="c3b0" class="mr ks iq oc b gy og oh l oi oj">next_element = iterator.get_next()</span></pre><h2 id="954f" class="mr ks iq bd kt ms mt dn kx mu mv dp lb ls mw mx ld lw my mz lf ma na nb lh nc bi translated">数据预处理</h2><p id="c1a5" class="pw-post-body-paragraph lj lk iq ll b lm ln jr lo lp lq ju lr ls lt lu lv lw lx ly lz ma mb mc md me ij bi translated">我们定义了<strong class="ll ir"> load_image() </strong>函数，该函数将图像路径映射到预处理后的图像——准备好输入网络。<br/>我们将图像的高度调整为 480 像素，宽度调整为 640 像素，并将像素值标准化为[0，1]。</p><pre class="kg kh ki kj gt ob oc od oe aw of bi"><span id="371e" class="mr ks iq oc b gy og oh l oi oj"><strong class="oc ir">def</strong> load_image(X):<br/>  X = tf.io.read_file(X)<br/>  X = tf.image.decode_jpeg(X,channels=3)<br/>  X = tf.image.resize(X,(480,640))<br/>  X = X / 255.0<br/>  <strong class="oc ir">return</strong> X</span></pre><h2 id="3c01" class="mr ks iq bd kt ms mt dn kx mu mv dp lb ls mw mx ld lw my mz lf ma na nb lh nc bi translated">网络、损耗和优化</h2><ol class=""><li id="8592" class="nk nl iq ll b lm ln lp lq ls nm lw nn ma no me np nq nr ns bi translated">定义一个函数，该函数获取输入图像，并在将图像通过 AOD 网络架构后返回输出。</li></ol><pre class="kg kh ki kj gt ob oc od oe aw of bi"><span id="5503" class="mr ks iq oc b gy og oh l oi oj"><strong class="oc ir">def</strong> haze_net(X):<br/>  <br/>  conv1 = Conv2D(3,1,1,padding="SAME",activation="relu",use_bias=<strong class="oc ir">True</strong>,kernel_initializer=tf.initializers.random_normal(),<br/>                kernel_regularizer=tf.keras.regularizers.l2(weight_decay))(X)<br/>  conv2 = Conv2D(3,3,1,padding="SAME",activation="relu",use_bias=<strong class="oc ir">True</strong>,kernel_initializer=tf.initializers.random_normal(),<br/>                kernel_regularizer=tf.keras.regularizers.l2(weight_decay))(conv1)<br/>  concat1 = tf.concat([conv1,conv2],axis=-1)<br/>  <br/>  conv3 = Conv2D(3,5,1,padding="SAME",activation="relu",use_bias=<strong class="oc ir">True</strong>,kernel_initializer=tf.initializers.random_normal(),<br/>                kernel_regularizer=tf.keras.regularizers.l2(weight_decay))(concat1)<br/>  concat2 = tf.concat([conv2,conv3],axis=-1)<br/>  <br/>  conv4 = Conv2D(3,7,1,padding="SAME",activation="relu",use_bias=<strong class="oc ir">True</strong>,kernel_initializer=tf.initializers.random_normal(),<br/>                kernel_regularizer=tf.keras.regularizers.l2(weight_decay))(concat2)<br/>  concat3 = tf.concat([conv1,conv2,conv3,conv4],axis=-1)<br/>  <br/>  conv5 = Conv2D(3,3,1,padding="SAME",activation="relu",use_bias=<strong class="oc ir">True</strong>,kernel_initializer=tf.initializers.random_normal(),<br/>                kernel_regularizer=tf.keras.regularizers.l2(weight_decay))(concat3)<br/>  K = conv5<br/>  <br/>  output = ReLU(max_value=1.0)(tf.math.multiply(K,X) - K + 1.0)<br/>  <em class="ne">#output = output / 255.0</em><br/>  <br/>  <strong class="oc ir">return</strong> output</span></pre><p id="8d68" class="pw-post-body-paragraph lj lk iq ll b lm mf jr lo lp mg ju lr ls mh lu lv lw mi ly lz ma mj mc md me ij bi translated">注意:<br/> -权重初始化(kernel_initializer)是用高斯分布(均值 0.0，标准差 0.02)完成的。<br/> -使用参数为 0.0001 的 L2 正则化。<br/> -每次卷积后应用 ReLU 激活。<br/> -最大值为 1.0 的 ReLU 激活应用于元素倍增层之后。</p><p id="0984" class="pw-post-body-paragraph lj lk iq ll b lm mf jr lo lp mg ju lr ls mh lu lv lw mi ly lz ma mj mc md me ij bi translated">2.分别为输入(模糊)图像和原始图像定义占位符<strong class="ll ir"> X </strong>和<strong class="ll ir"> Y </strong>。<br/>定义<strong class="ll ir">去雾 _X </strong>为网络通过<strong class="ll ir"> X </strong>时的输出。</p><pre class="kg kh ki kj gt ob oc od oe aw of bi"><span id="20c3" class="mr ks iq oc b gy og oh l oi oj">X = tf.placeholder(shape=(<strong class="oc ir">None</strong>,480,640,3),dtype=tf.float32)<br/>Y = tf.placeholder(shape=(<strong class="oc ir">None</strong>,480,640,3),dtype=tf.float32)<br/>dehazed_X = haze_net(X)</span></pre><p id="a79c" class="pw-post-body-paragraph lj lk iq ll b lm mf jr lo lp mg ju lr ls mh lu lv lw mi ly lz ma mj mc md me ij bi translated">3.定义原始图像和去模糊图像之间的网络损耗 MSE。</p><pre class="kg kh ki kj gt ob oc od oe aw of bi"><span id="23e9" class="mr ks iq oc b gy og oh l oi oj">loss = tf.reduce_mean(tf.square(dehazed_X-Y))</span></pre><p id="f766" class="pw-post-body-paragraph lj lk iq ll b lm mf jr lo lp mg ju lr ls mh lu lv lw mi ly lz ma mj mc md me ij bi translated">4.定义<strong class="ll ir">优化器</strong>操作。<br/> a)定义 Adam 优化器，将<strong class="ll ir">&lt;learning _ rate&gt;</strong>设置为 0.001 <strong class="ll ir">。b)传递可训练变量列表，并计算每个变量的梯度。<br/> c)裁剪范数 0.1 上的梯度<br/> d)通过应用裁剪的梯度更新可训练变量。</strong></p><pre class="kg kh ki kj gt ob oc od oe aw of bi"><span id="72a8" class="mr ks iq oc b gy og oh l oi oj"># Step (a)<br/>optimizer = tf.train.AdamOptimizer(learning_rate)</span><span id="36ec" class="mr ks iq oc b gy ok oh l oi oj"># Step (b)<br/>trainable_variables = tf.trainable_variables()<br/>gradients_and_vars = <br/>optimizer.compute_gradients(loss,trainable_variables)</span><span id="a896" class="mr ks iq oc b gy ok oh l oi oj"># Step (c)<br/>clipped_gradients = [(tf.clip_by_norm(gradient,0.1),var) <strong class="oc ir">for</strong> gradient,var <strong class="oc ir">in</strong> gradients_and_vars]</span><span id="ed69" class="mr ks iq oc b gy ok oh l oi oj"># Step (d)<br/>optimizer = optimizer.apply_gradients(gradients_and_vars)</span></pre><h2 id="057b" class="mr ks iq bd kt ms mt dn kx mu mv dp lb ls mw mx ld lw my mz lf ma na nb lh nc bi translated">培养</h2><ol class=""><li id="192d" class="nk nl iq ll b lm ln lp lq ls nm lw nn ma no me np nq nr ns bi translated">定义<strong class="ll ir"> tf。训练时，避免存储模型权重。</strong></li></ol><pre class="kg kh ki kj gt ob oc od oe aw of bi"><span id="fe1e" class="mr ks iq oc b gy og oh l oi oj">saver = tf.train.Saver()</span></pre><p id="ad1b" class="pw-post-body-paragraph lj lk iq ll b lm mf jr lo lp mg ju lr ls mh lu lv lw mi ly lz ma mj mc md me ij bi translated">2.初始化所有全局变量。</p><p id="5971" class="pw-post-body-paragraph lj lk iq ll b lm mf jr lo lp mg ju lr ls mh lu lv lw mi ly lz ma mj mc md me ij bi translated">3.在每个时期，运行<strong class="ll ir"> train_init_op </strong>，以便迭代器从训练数据集中读取数据。</p><p id="93fb" class="pw-post-body-paragraph lj lk iq ll b lm mf jr lo lp mg ju lr ls mh lu lv lw mi ly lz ma mj mc md me ij bi translated">4.定义需要处理的批次数量，这相当于训练样本数量除以批次大小。</p><p id="8cbb" class="pw-post-body-paragraph lj lk iq ll b lm mf jr lo lp mg ju lr ls mh lu lv lw mi ly lz ma mj mc md me ij bi translated">5.对于每个批次，运行优化器操作并存储相应的损失(MSE)。每 1000 次迭代打印一次批次损失，以检查损失是否在减少。</p><pre class="kg kh ki kj gt ob oc od oe aw of bi"><span id="ab9b" class="mr ks iq oc b gy og oh l oi oj"><strong class="oc ir">with</strong> tf.device('/gpu:0'):<br/>  <strong class="oc ir">with</strong> tf.Session() <strong class="oc ir">as</strong> sess:<br/><br/>    sess.run(tf.global_variables_initializer())<br/>    <strong class="oc ir">for</strong> epoch <strong class="oc ir">in</strong> range(n_epochs):<br/>      <br/>      sess.run(train_init_op)<br/>      batches = len(train_data) // batch_size<br/>      epoch_loss = 0.0<br/>      <strong class="oc ir">for</strong> batch <strong class="oc ir">in</strong> range(batches):<br/><br/>        batch_data = sess.run(next_element)<br/>        <em class="ne">#print(batch_data[0].shape,batch_data[1].shape)</em><br/>        <em class="ne">#print(np.max(batch_data[0]),np.max(batch_data[1]))</em><br/>        batch_loss, _ = sess.run([loss,optimizer],feed_dict={X:batch_data[0],<br/>                                                            Y:batch_data[1]})<br/>        epoch_loss += batch_loss / float(batches)<br/>        <strong class="oc ir">if</strong> batch % 1000 == 0:<br/>          print("Training loss at batch <strong class="oc ir">%d</strong>: <strong class="oc ir">%f\n</strong>"%(batch,batch_loss))<br/>            <br/>      train_loss = epoch_loss</span></pre><p id="4b75" class="pw-post-body-paragraph lj lk iq ll b lm mf jr lo lp mg ju lr ls mh lu lv lw mi ly lz ma mj mc md me ij bi translated">6.要评估验证数据集的性能，重复相同的过程，只是不运行<strong class="ll ir">优化器</strong>操作。<br/>此外，每 100 批后，显示模糊、原始和去模糊图像(由网络生成),以供目视检查。</p><pre class="kg kh ki kj gt ob oc od oe aw of bi"><span id="0fec" class="mr ks iq oc b gy og oh l oi oj">sess.run(val_init_op)<br/>      batches= len(val_data) // batch_size<br/>      epoch_loss = 0.0<br/>      <strong class="oc ir">for</strong> batch <strong class="oc ir">in</strong> range(batches):<br/>        batch_data = sess.run(next_element)<br/>        batch_loss = sess.run(loss,feed_dict={X:batch_data[0],<br/>                                             Y:batch_data[1]})<br/>        epoch_loss += batch_loss / float(batches)<br/>        <strong class="oc ir">if</strong> batch % 100 == 0:<br/>          print("Validation loss at batch <strong class="oc ir">%d</strong>: <strong class="oc ir">%f\n</strong>"%(batch,batch_loss))<br/>          <strong class="oc ir">for</strong> j <strong class="oc ir">in</strong> range(batch_size//2):<br/>            x = batch_data[0][j].reshape((1,)+batch_data[0][j].shape)<br/>            y = batch_data[1][j].reshape((1,)+batch_data[1][j].shape)<br/>            dehazed_x = sess.run(dehazed_X,feed_dict={X:x,Y:y})<br/>            print("Image Number: <strong class="oc ir">%d\n</strong>"%(j))<br/>            showImage(x[0])<br/>            showImage(y[0])<br/>            showImage(dehazed_x[0])<br/>      val_loss = epoch_loss</span></pre><p id="da47" class="pw-post-body-paragraph lj lk iq ll b lm mf jr lo lp mg ju lr ls mh lu lv lw mi ly lz ma mj mc md me ij bi translated">6.在每个时期之后，保存模型权重。</p><pre class="kg kh ki kj gt ob oc od oe aw of bi"><span id="2ee5" class="mr ks iq oc b gy og oh l oi oj">saver.save(sess,'./models/model_checkpoint_' + str(epoch) + '.ckpt')</span></pre><h2 id="a74e" class="mr ks iq bd kt ms mt dn kx mu mv dp lb ls mw mx ld lw my mz lf ma na nb lh nc bi translated">结果</h2><p id="1f94" class="pw-post-body-paragraph lj lk iq ll b lm ln jr lo lp lq ju lr ls lt lu lv lw lx ly lz ma mb mc md me ij bi translated">我对网络进行了 10 个时期的训练，并在验证集上实现了大约 0.018 的 MSE。然而，在 3-4 个周期后，我没有观察到明显的改善。</p><p id="8d6f" class="pw-post-body-paragraph lj lk iq ll b lm mf jr lo lp mg ju lr ls mh lu lv lw mi ly lz ma mj mc md me ij bi translated">下面是一些自然朦胧图像的定性结果(不是人工生成的朦胧)。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ol"><img src="../Images/33c742907440e69333eceed6ec85695d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*rwhs-3K0veR6lqbvHfR5sg.png"/></div></div><figcaption class="mm mn gj gh gi mo mp bd b be z dk"><strong class="bd mq">Left:</strong> Naturally hazy image. <strong class="bd mq">Right:</strong> De-hazed image generated by AOD-net.</figcaption></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi om"><img src="../Images/a9fa14ace1329a49069a50694b3da092.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*s4gl7xYP7Njerm9x7-ojXw.png"/></div></div><figcaption class="mm mn gj gh gi mo mp bd b be z dk"><strong class="bd mq">Left:</strong> Naturally hazy image. <strong class="bd mq">Right:</strong> De-hazed image generated by AOD-net.</figcaption></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ml"><img src="../Images/841a7e82cd204b8356a2765ce3d11d34.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*6aTdFR0fC3jvcCJ_TQyD0w.png"/></div></div><figcaption class="mm mn gj gh gi mo mp bd b be z dk"><strong class="bd mq">Left:</strong> Naturally hazy image. <strong class="bd mq">Right:</strong> De-hazed image generated by AOD-net.</figcaption></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ol"><img src="../Images/929a91861b70f034660c91aaaa743bdd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*GsMOEzxFExgIV4qFVD7xQA.png"/></div></div><figcaption class="mm mn gj gh gi mo mp bd b be z dk"><strong class="bd mq">Left:</strong> Naturally hazy image. <strong class="bd mq">Right:</strong> De-hazed image generated by AOD-net.</figcaption></figure><p id="bf4a" class="pw-post-body-paragraph lj lk iq ll b lm mf jr lo lp mg ju lr ls mh lu lv lw mi ly lz ma mj mc md me ij bi translated">可以在<a class="ae mk" href="https://github.com/tusharsircar95/All-In-One-Image-Dehazing-Tensorflow" rel="noopener ugc nofollow" target="_blank">这里</a>找到整个代码以及经过训练的模型。是可以在 GoogleCollab 上运行的 Python 笔记本。</p><p id="42f7" class="pw-post-body-paragraph lj lk iq ll b lm mf jr lo lp mg ju lr ls mh lu lv lw mi ly lz ma mj mc md me ij bi translated">干杯！:D</p><h1 id="9de7" class="kr ks iq bd kt ku kv kw kx ky kz la lb jw lc jx ld jz le ka lf kc lg kd lh li bi translated">参考</h1><ol class=""><li id="c9eb" class="nk nl iq ll b lm ln lp lq ls nm lw nn ma no me np nq nr ns bi translated"><a class="ae mk" href="https://sites.google.com/site/boyilics/website-builder/project-page" rel="noopener ugc nofollow" target="_blank">https://sites . Google . com/site/boy ilics/website-builder/project-page</a></li><li id="34c0" class="nk nl iq ll b lm nt lp nu ls nv lw nw ma nx me np nq nr ns bi translated">【https://github.com/TheFairBear/PyTorch-Image-Dehazing T4】(py torch 实现)</li></ol></div></div>    
</body>
</html>