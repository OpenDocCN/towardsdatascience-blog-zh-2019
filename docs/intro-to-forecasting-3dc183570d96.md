# 预测简介

> 原文：<https://towardsdatascience.com/intro-to-forecasting-3dc183570d96?source=collection_archive---------31----------------------->

预测是另一种使用结构化数据(通常通过使用来自[自然语言处理](https://www.foundationai.com/thoughts/2018/11/9/intro-to-natural-language-processing)和[物体识别](https://www.foundationai.com/thoughts/2018/11/9/intro-to-object-recognition)的技术获得)来通知决策的技术。预测技术预测未来的结果或状态。

我们为什么要预测呢？说你要买房子。预测一年后你的投资价值可能会有用。如果你翻新了厨房呢？预测技术可以帮助你确定厨房改造可以增加多少价值。作为一个企业，预算非常重要。如果您可以预测需求、客户流失、预防性维护成本和收益等，您就可以在整个企业中高效地部署资源。如果你有一个网上商店，并能准确地预测你的客户下一步可能购买什么，你可以在他们的搜索结果或广告中显示该商品，以增加销售的可能性。

预测使用大量历史数据来创建历史上表现相似的组。然后，它可以将新数据点与其中一个组进行匹配，并使用该组的历史表现来预测未来。预测不同于优化，优化你可以在这里阅读更多关于[的内容](https://www.foundationai.com/thoughts/2018/11/9/intro-to-optimization)，因为它不需要决定采取哪些步骤来达到既定目标。它只是将新数据与历史数据中的模式进行匹配。您可能会注意到，预测的第一部分听起来很像聚类和分类，我们之前在这里讨论过。预测技术通常基于聚类和分类算法。

预测算法使用我们称之为“特征”的东西来识别行为相似的群体。这些特征是独立于我们试图预测的事物的可测量的特性。比方说，我们正试图预测一所房子的价格，就像我们之前提到的那样。我们可能使用的几个特征是房子的年龄和卧室的数量。房子的价格，也就是我们试图预测的东西，至少部分是由其特征决定的(在这种情况下，是其年龄和卧室数量)。我们说特征是独立的，是指特征本身，房子的房龄和卧室数量，不会因为价格的变化而增减。价格(我们的因变量)当然会随着房子变旧或者我们决定增加一间卧室而改变。

在这个简单的例子中，我们有两个特征。如果我们制作一个历史价格和卧室的年龄和数量的表格，我们可以做一些简单的数学，并且可能在不使用人工智能的情况下预测房子的价格。问题是，房子的价格不仅仅取决于我们在这个例子中使用的两个特征。房子有多大？有花园吗？门廊？它有多少故事？附近的学校有多好？这个地区的平均收入是多少？利率趋势如何？该地区就业情况好吗？我们可以考虑的特征数量几乎是压倒性的。住房甚至不是我们在预测中要解决的最复杂的问题。如果不使用人工智能，就很难为这些更复杂的问题开发出任何精确度的预测模型。

随着特征数量的增加，训练精确模型所需的训练数据量也在增加。这些数据被用来试图隔离每个特征对我们试图预测的东西的影响。在我们之前的房子示例中，如果我们的训练数据只有 1 间卧室的旧房子和 4 间卧室的新房子，我们的模型在预测价格时将无法从卧室数量中分离出年龄。我们希望有一个训练集，其变化代表接近所有的年龄和卧室数量的组合。正如您可能猜到的，当您开始添加更多功能时，您需要覆盖所有这些变化的训练数据量会显著增加。

如果我们试图解决一个有成百上千个特征的问题，事情会变得更加复杂。我们显然需要更多的训练数据，但我们也需要更多的计算能力。这增加了训练数据所需的时间，这意味着模型调整需要更长的时间，计算资源的成本也增加了。数据科学家开发了几种技术来帮助减少所需的计算资源量。

数据科学家用来降低必要计算能力的两种技术是“提升”和“打包”。这些技术不是同时在所有要素和所有历史数据上训练算法，而是划分训练数据并在数据的子集上训练算法。他们多次这样做，对不同的数据子集进行训练，然后将结果合并到一个模型中。提升保持所有特征不变，但是限制了训练样本的数量。在房价的例子中，这意味着在您拥有的所有历史房屋销售数据中，boosting 算法(例如 [XGBoost](https://machinelearningmastery.com/gentle-introduction-xgboost-applied-machine-learning/) )将只关注一些房屋销售。然后它会再次运行，关注不同的子集。一旦完成，它将合并结果。相比之下，Bagging 会关注所有的房屋销售，但只会关注我们正在考虑的一部分特征(比如年龄和卧室数量)。然后，bagging 算法(例如[随机森林](/the-random-forest-algorithm-d457d499ffcd))会考虑其他特征(比如地区收入中位数和学校排名)再次运行，然后合并结果。这只是对这两种“元算法”非常粗略的描述。我们将在以后的文章中进一步深入探讨。

关于预测，需要记住的一件重要事情是，它无法理解特征的含义。在我们之前的例子中，房子的年龄很可能是一辆车的年龄，或者是从某人的最后一个生日算起的天数。该算法无法理解它正在解决的问题背后的意义，而是在数据中寻找数学模式。这种缺乏理解可能是一个特征，因为它可以识别人类通常不能识别的模式。这也可能是一种限制。如果用于为算法定型的历史数据有内置偏差，则生成的算法也会有内置偏差。例如，亚马逊花了数年时间训练一个人工智能系统来整理简历，并根据过去的招聘数据预测哪些候选人最有可能被录用。这些简历随后会出现在负责面试这些候选人的招聘经理面前。然而，他们建立的算法一贯贬低女性候选人，因为在历史数据中，男性更有可能被录用。你可以在这里阅读更多关于亚马逊的人工智能招聘系统[。](http://fortune.com/2018/10/10/amazon-ai-recruitment-bias-women-sexist/)

另一个问题是，预测算法的决策过程可能是不透明的，这加剧了固有偏见的问题。虽然分类和回归树等更简单的模型为他们的决策过程如何工作提供了一些透明度，但更复杂的模型通常是人类难以理解的。如果预测算法预测某人更有可能在贷款上违约，我们将无法解释为什么该算法预测违约，只能说它反映在训练数据中。这使得很难识别预测系统中的固有偏差，除非通过观察其预测。我们将在以后的博客文章中讨论算法透明性和偏差消除技术的问题。

预测是目前人工智能研究中最活跃的领域之一。有了足够的无偏见的历史数据，人工智能可以对未来做出准确的预测。无论是预测客户流失、估价还是预测性维护，准确的预测都是无价的。

*原载于 2019 年 4 月 10 日*[*【https://www.foundationai.com】*](https://www.foundationai.com/thoughts/2018/12/17/intro-to-forecasting)*。*