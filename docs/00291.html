<html>
<head>
<title>Secret of Google Web-Based OCR Service</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">谷歌基于网络的 OCR 服务的秘密</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/secret-of-google-web-based-ocr-service-fe30eecedd01?source=collection_archive---------15-----------------------#2019-01-13">https://towardsdatascience.com/secret-of-google-web-based-ocr-service-fe30eecedd01?source=collection_archive---------15-----------------------#2019-01-13</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="e699" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">光学字符识别简介</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/f9e80c8b369d3dce88fa15696ddc8656.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*upu4oyqitrlTbTka"/></div></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk">Photo by <a class="ae ky" href="https://unsplash.com/@makcedward?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Edward Ma</a> on <a class="ae ky" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><p id="ee3c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">光学字符识别(OCR)是连接现实世界和虚拟世界的方法之一。第一个 OCR 系统是在 20 世纪 20 年代末推出的。OCR 的目标是从图像中识别文本。然而，由于许多因素，实现非常高的精度是非常具有挑战性的。在下面的故事中，我将介绍谷歌如何构建解决方案，这是谷歌云视觉 API 之一，以解决这个问题。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi lv"><img src="../Images/ac14e818c5a88fa7295db4193fe03801.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/0*HhUoYjTYLsYaVldd.png"/></div></figure><p id="c92a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">谈到 OCR，<a class="ae ky" href="https://github.com/tesseract-ocr/tesseract" rel="noopener ugc nofollow" target="_blank"> tesseract </a>是一个著名的开源库，每个人都可以利用它来执行 OCR。宇宙魔方由惠普发现，自 2006 年以来一直由谷歌赞助开发。Tesseract 3.x 模型是旧版本，而 4.x 版本是由深度学习(LSTM)构建的。如果你想了解 3.x 和 4.x 的区别，你可以访问<a class="ae ky" href="https://github.com/tesseract-ocr/docs/blob/master/das_tutorial2016/6ModernizationEfforts.pdf" rel="noopener ugc nofollow" target="_blank">分享</a>了解更多细节。</p><p id="8889" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">由于 tesseract 是由 C++实现的，我们不能像调用其他 python 库一样调用它。事实上，我们可以在 python 中调用<a class="ae ky" href="https://github.com/tesseract-ocr/tesseract/wiki/APIExample" rel="noopener ugc nofollow" target="_blank"> C-API，但是它对用户不太友好。因此，python 包装器</a><a class="ae ky" href="https://github.com/madmaze/pytesseract" rel="noopener ugc nofollow" target="_blank">pytesserac</a>的引入让我们的生活变得更加轻松。</p><h1 id="df0f" class="lw lx it bd ly lz ma mb mc md me mf mg jz mh ka mi kc mj kd mk kf ml kg mm mn bi translated">定义</h1><p id="9fea" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">在介绍架构设计之前，需要介绍一些定义。</p><ul class=""><li id="6cb5" class="mt mu it lb b lc ld lf lg li mv lm mw lq mx lu my mz na nb bi translated">脚本 vs 语言:脚本不同于语言。文字指的是书写系统，而语言大多数时候指的是口语。在下图中，“数据科学家”是罗马体的英语，而“书局科学家”是罗马体的中文。</li></ul><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nc"><img src="../Images/57194eeba659710d5a47ab714e61311c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1292/format:webp/1*9_-3JPVTOjzLfGtlY11Dcg.png"/></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk">Script vs Language</figcaption></figure><ul class=""><li id="c537" class="mt mu it lb b lc ld lf lg li mv lm mw lq mx lu my mz na nb bi translated">边界框:与其他 OCR 系统不同，边界框包括单行检测文本，而不是单个字符或单个单词。</li><li id="40ee" class="mt mu it lb b lc nd lf ne li nf lm ng lq nh lu my mz na nb bi translated">模型考虑:除了准确性，成本，通用性和可维护性也被考虑来建立模型。</li></ul><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="ab gu cl ni"><img src="../Images/394a81c92615231416328b2e23cb6ca9.png" data-original-src="https://miro.medium.com/v2/format:webp/1*tkAiRWvYmAi_RuRhRYgeiQ.jpeg"/></div></figure><p id="eb14" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">给出一幅图像，它要经过 5 个阶段才能在<a class="ae ky" href="https://cloud.google.com/vision/docs/fulltext-annotations" rel="noopener ugc nofollow" target="_blank">谷歌视觉 API </a>中得到最终结果。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nj"><img src="../Images/aa20c77c01255cc583d795673d6f2e79.png" data-original-src="https://miro.medium.com/v2/resize:fit:1088/format:webp/1*2aEAFgnCSpPaPf4wu0rP1g.png"/></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk">Google Cloud Vision API Architecture (Walker et al., 2018)</figcaption></figure><h2 id="f095" class="nk lx it bd ly nl nm dn mc nn no dp mg li np nq mi lm nr ns mk lq nt nu mm nv bi translated">文本检测</h2><p id="7fe0" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">第一步是使用传统的基于神经网络(CNN)的模型来检测和定位文本行，并生成一组边界框。</p><h2 id="8c21" class="nk lx it bd ly nl nm dn mc nn no dp mg li np nq mi lm nr ns mk lq nt nu mm nv bi translated">方向识别</h2><p id="bc6f" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">按边界框对方向进行分类。如果需要，一些边界框将被过滤掉，因为它被错误地检测为文本。</p><h2 id="6479" class="nk lx it bd ly nl nm dn mc nn no dp mg li np nq mi lm nr ns mk lq nt nu mm nv bi translated">脚本识别</h2><p id="169b" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">标识每个边界框的脚本。假设每个边界框有一个脚本，但允许每个图像有多个脚本。</p><h2 id="8b30" class="nk lx it bd ly nl nm dn mc nn no dp mg li np nq mi lm nr ns mk lq nt nu mm nv bi translated">文本识别</h2><p id="7763" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">这是 OCR 的核心部分，它从图像中识别文本。它不仅包括基于字符的语言模型，还包括初始风格的光学模型和自定义解码算法。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nw"><img src="../Images/3106f6cfac512a9aee9a87fe83f9bbd9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1040/format:webp/1*wV9w9max8cs4Cy3tE6pq0w.png"/></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk">Inception Model (Fujii et al., 2017)</figcaption></figure><h2 id="309e" class="nk lx it bd ly nl nm dn mc nn no dp mg li np nq mi lm nr ns mk lq nt nu mm nv bi translated">布局分析</h2><p id="7ea8" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">确定订单的阅读和区分标题、页眉等。</p><h1 id="0a85" class="lw lx it bd ly lz ma mb mc md me mf mg jz mh ka mi kc mj kd mk kf ml kg mm mn bi translated">实验</h1><p id="b62b" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">如前所述，宇宙魔方是由谷歌赞助的。我想这也是作者拿结果和宇宙魔方比较的原因之一。模型比较采用字符差错率(CER)。它被定义为编辑距离除以参考长度并乘以 100。越低越好。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nx"><img src="../Images/e8db6921692134af100c0fd1aed6f3b3.png" data-original-src="https://miro.medium.com/v2/resize:fit:934/format:webp/1*DrkWmB6h6uQtl4fkiB1bTg.png"/></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk">Tesseract vs Google Cloud Vision API (Walker et al. 2018)</figcaption></figure><h1 id="209e" class="lw lx it bd ly lz ma mb mc md me mf mg jz mh ka mi kc mj kd mk kf ml kg mm mn bi translated">拿走</h1><p id="1ce1" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">持有一，为什么图像处理步骤不包括在管道中？论文没有提到原因。我相信这是由于神经网络模型已经能够捕捉那些特征。</p><p id="ee8e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">除了性能，速度是另一个考虑因素。从我的经验来看，宇宙魔方在识别方面做得很好，但速度相当慢。</p><h1 id="59c3" class="lw lx it bd ly lz ma mb mc md me mf mg jz mh ka mi kc mj kd mk kf ml kg mm mn bi translated">关于我</h1><p id="49f6" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">我是湾区的数据科学家。专注于数据科学、人工智能，尤其是 NLP 和平台相关领域的最新发展。你可以通过<a class="ae ky" href="http://medium.com/@makcedward/" rel="noopener">媒体博客</a>、<a class="ae ky" href="https://www.linkedin.com/in/edwardma1026" rel="noopener ugc nofollow" target="_blank"> LinkedIn </a>或<a class="ae ky" href="https://github.com/makcedward" rel="noopener ugc nofollow" target="_blank"> Github </a>联系我。</p><h1 id="ae9a" class="lw lx it bd ly lz ma mb mc md me mf mg jz mh ka mi kc mj kd mk kf ml kg mm mn bi translated">参考</h1><p id="5345" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">沃克 j，藤井 y，Popat A. C..2018.基于网络的文档 OCR 服务。</p><p id="6a29" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">王晓东，王晓东，王晓东，王晓东，王晓东，王晓东。..2017.<a class="ae ky" href="https://arxiv.org/pdf/1708.04671.pdf" rel="noopener ugc nofollow" target="_blank">用于多语言 OCR 的序列到标签文字识别</a>。</p></div></div>    
</body>
</html>