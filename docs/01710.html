<html>
<head>
<title>Deep-dive into Convolutional Networks</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">深入了解卷积网络</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/deep-dive-into-convolutional-networks-48db75969fdf?source=collection_archive---------10-----------------------#2019-03-20">https://towardsdatascience.com/deep-dive-into-convolutional-networks-48db75969fdf?source=collection_archive---------10-----------------------#2019-03-20</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><figure class="ip iq gp gr ir is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi io"><img src="../Images/e59f16e765b9b996d53adcac3ca6d4fb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*TAE5OmIhf5ug6D4M4f0Jeg.png"/></div></div><figcaption class="iz ja gj gh gi jb jc bd b be z dk">Visualization from <a class="ae jd" href="http://terencebroad.com/convnetvis/vis.html" rel="noopener ugc nofollow" target="_blank">http://terencebroad.com/convnetvis/vis.html</a></figcaption></figure><div class=""/><div class=""><h2 id="db17" class="pw-subtitle-paragraph kd jf jg bd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku dk translated">从积木到最先进的架构，触及可解释性和偏见。</h2></div><figure class="kx ky kz la gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi kw"><img src="../Images/8fa83c805a3cd6ad6beee0b7635270cc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*XbuW8WuRrAY5pC4t-9DZAQ.jpeg"/></div></div><figcaption class="iz ja gj gh gi jb jc bd b be z dk">By the end of this post you will understand this diagram. Image courtesy of <a class="ae jd" href="https://blog.floydhub.com/building-your-first-convnet/" rel="noopener ugc nofollow" target="_blank">FloydHub</a>.</figcaption></figure><h1 id="827c" class="lb lc jg bd ld le lf lg lh li lj lk ll km lm kn ln kp lo kq lp ks lq kt lr ls bi translated">介绍</h1><p id="d322" class="pw-post-body-paragraph lt lu jg lv b lw lx kh ly lz ma kk mb mc md me mf mg mh mi mj mk ml mm mn mo ij bi translated">卷积网络(ConvNets)是一类高效的神经网络，在感知任务(如对象识别)中实现了令人印象深刻的性能。他们的建筑是由视觉皮层松散地启发而来的<a class="ae jd" href="https://www.deeplearningbook.org/contents/convnets.html#pf21" rel="noopener ugc nofollow" target="_blank">。2012 年</a><a class="ae jd" href="https://en.wikipedia.org/wiki/AlexNet" rel="noopener ugc nofollow" target="_blank"> AlexNet </a>，一种 ConvNet，以较大优势赢得了 ILSVRC 2012 竞赛，引发了对深度学习的巨大兴趣，这种兴趣一直持续到今天。2019 年，对象检测的最先进架构是 ResNet，这是一种 ConvNet。</p><p id="075b" class="pw-post-body-paragraph lt lu jg lv b lw mp kh ly lz mq kk mb mc mr me mf mg ms mi mj mk mt mm mn mo ij bi translated">在本文中，我假设对标准的全连接神经网络(或多层感知器，MLP)有所了解。在概述了 ConvNets 激活之后，我将深入了解卷积的概念和其他构建模块(池化、批处理规范化、1x1 过滤器等)。接下来，我将简要说明一些实现最先进结果的高级架构(Inception、ResNet)。在最后部分，我将触及<em class="mu">可解释性</em>和<em class="mu">偏见</em>的话题。每个部分都包含一个参考文献和链接列表，以供进一步研究。一些概念通常适用于深度神经网络，但我将在 ConvNets 的上下文中说明它们。</p><p id="3f31" class="pw-post-body-paragraph lt lu jg lv b lw mp kh ly lz mq kk mb mc mr me mf mg ms mi mj mk mt mm mn mo ij bi translated">如果您是 ConvNets 的新手，需要花一些时间来消化这些材料，慢慢来，阅读许多资料。你可以用这篇文章作为围绕 ConvNets 的想法的快速参考。如果您发现任何错误，或者如果您认为我错过了其他主题，请在评论部分告诉我。</p><h2 id="3800" class="mv lc jg bd ld mw mx dn lh my mz dp ll mc na nb ln mg nc nd lp mk ne nf lr ng bi translated">目录</h2><ul class=""><li id="1291" class="nh ni jg lv b lw lx lz ma mc nj mg nk mk nl mo nm nn no np bi translated"><a class="ae jd" href="https://medium.com/p/48db75969fdf#28b3" rel="noopener">一个 ConvNets 的概述</a></li><li id="4a39" class="nh ni jg lv b lw nq lz nr mc ns mg nt mk nu mo nm nn no np bi translated"><a class="ae jd" href="https://medium.com/p/48db75969fdf#53d2" rel="noopener">卷积步骤</a></li><li id="eb71" class="nh ni jg lv b lw nq lz nr mc ns mg nt mk nu mo nm nn no np bi translated"><a class="ae jd" href="https://medium.com/p/48db75969fdf#90eb" rel="noopener">感受野</a></li><li id="f60f" class="nh ni jg lv b lw nq lz nr mc ns mg nt mk nu mo nm nn no np bi translated"><a class="ae jd" href="https://medium.com/p/48db75969fdf#5738" rel="noopener">参数数量</a></li><li id="b59d" class="nh ni jg lv b lw nq lz nr mc ns mg nt mk nu mo nm nn no np bi translated"><a class="ae jd" href="https://medium.com/p/48db75969fdf#a105" rel="noopener">小批量</a></li><li id="01e6" class="nh ni jg lv b lw nq lz nr mc ns mg nt mk nu mo nm nn no np bi translated"><a class="ae jd" href="https://medium.com/p/48db75969fdf#a07c" rel="noopener">批量正常化</a></li><li id="d2b3" class="nh ni jg lv b lw nq lz nr mc ns mg nt mk nu mo nm nn no np bi translated"><a class="ae jd" href="https://medium.com/p/48db75969fdf#fbde" rel="noopener">其他标准化</a></li><li id="dae2" class="nh ni jg lv b lw nq lz nr mc ns mg nt mk nu mo nm nn no np bi translated"><a class="ae jd" href="https://medium.com/p/48db75969fdf#db48" rel="noopener">联营</a></li><li id="7917" class="nh ni jg lv b lw nq lz nr mc ns mg nt mk nu mo nm nn no np bi translated"><a class="ae jd" href="https://medium.com/p/48db75969fdf#d8f9" rel="noopener"> 1x1 卷积</a></li><li id="1b5d" class="nh ni jg lv b lw nq lz nr mc ns mg nt mk nu mo nm nn no np bi translated"><a class="ae jd" href="https://medium.com/p/48db75969fdf#9916" rel="noopener">盗梦空间</a></li><li id="398f" class="nh ni jg lv b lw nq lz nr mc ns mg nt mk nu mo nm nn no np bi translated"><a class="ae jd" href="https://medium.com/p/48db75969fdf#5055" rel="noopener"> ResNet </a></li><li id="dc64" class="nh ni jg lv b lw nq lz nr mc ns mg nt mk nu mo nm nn no np bi translated"><a class="ae jd" href="https://medium.com/p/48db75969fdf#d7d7" rel="noopener">可解释性</a></li><li id="d5a2" class="nh ni jg lv b lw nq lz nr mc ns mg nt mk nu mo nm nn no np bi translated"><a class="ae jd" href="https://medium.com/p/48db75969fdf#006f" rel="noopener">偏向</a></li><li id="1fb7" class="nh ni jg lv b lw nq lz nr mc ns mg nt mk nu mo nm nn no np bi translated"><a class="ae jd" href="https://medium.com/dataseries/deep-dive-into-convolutional-networks-48db75969fdf#11b2" rel="noopener">参考文献</a></li></ul><h1 id="28b3" class="lb lc jg bd ld le lf lg lh li lj lk ll km lm kn ln kp lo kq lp ks lq kt lr ls bi translated">一个网络的概述</h1><p id="991c" class="pw-post-body-paragraph lt lu jg lv b lw lx kh ly lz ma kk mb mc md me mf mg mh mi mj mk ml mm mn mo ij bi translated">卷积神经网络(ConvNets)是一类专门用于图像处理的神经网络。与其他神经网络一样，它们通过许多层将输入转换为输出。在<strong class="lv jh"> ConvNets </strong>中，层有一个<strong class="lv jh">卷积步骤</strong>，一个<strong class="lv jh">汇集步骤</strong>(可选)和一个<strong class="lv jh">非线性激活</strong>。神经网络中的每一层通过线性和非线性运算将输入张量转换为输出张量。所有这些中间张量(包括网络输入和输出)被称为<strong class="lv jh">激活</strong>，它们都是输入的不同<em class="mu">表示</em>。</p><figure class="kx ky kz la gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi nv"><img src="../Images/e0b8ed19531a63e1fb724c5bf5c8e842.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*WaURHHI263FwP5vvRVpvzA.png"/></div></div><figcaption class="iz ja gj gh gi jb jc bd b be z dk"><strong class="bd nw">Figure 1.</strong> Activation tensors in a convolutional neural net.</figcaption></figure><p id="9d63" class="pw-post-body-paragraph lt lu jg lv b lw mp kh ly lz mq kk mb mc mr me mf mg ms mi mj mk mt mm mn mo ij bi translated">当我们从输入到输出时，我喜欢通过可视化激活的形状来开始说明 ConvNets(参见<strong class="lv jh">图 1 </strong>)。每一层都通过线性和非线性操作来转换激活(我们将在下一节的<a class="ae jd" href="https://medium.com/p/48db75969fdf#53d2" rel="noopener">中看到细节)。当我们穿过这些层时，激活的空间维度会缩小，而深度会增加。ConvNet 的最后一部分将 3D 激活转换为 1D，通常通过平均池化(参见</a><a class="ae jd" href="https://medium.com/p/48db75969fdf#db48" rel="noopener">池化部分</a>)。最后，1 或 2 个完全连接的层将激活投射到最终分类的输出空间。在这篇文章中，我用分类作为最终任务的例子。一些架构通过直接生成长度与类别数量匹配的 1D 激活来避免最终的密集层。</p><p id="15b0" class="pw-post-body-paragraph lt lu jg lv b lw mp kh ly lz mq kk mb mc mr me mf mg ms mi mj mk mt mm mn mo ij bi translated">激活的流程显示了输入是如何在一个越来越“丰富”的特征空间(增加的深度)中表示的，同时牺牲了空间信息(降低的高度/宽度)。最后完全连接的层放弃任何空间信息，以实现最终的分类任务。当我们经过各层时，特征不仅在数量上(深度大小)增加，而且复杂性也增加，是前一层特征的组合。换句话说，网络构建输入的<em class="mu">层次表示</em>:第一层根据基本特征(如边)表示输入，第二层根据更复杂的特征(如角等)表示输入。更深的一层可以识别抽象的特征，如眼睛甚至人脸。引人注目的是，ConvNet 将在训练过程中自主学习这一特征层次。</p><p id="8a28" class="pw-post-body-paragraph lt lu jg lv b lw mp kh ly lz mq kk mb mc mr me mf mg ms mi mj mk mt mm mn mo ij bi translated">在训练过程中，网络将学习一种有利于解决指定任务的表示法。对于像 ImageNet(数百万张图像，分为 1000 个类别)这样的大型和多样化的数据集，学习到的表示将足够通用，可用于许多其他视觉感知任务，即使是在不同或非常特定的领域。这是<a class="ae jd" href="https://en.wikipedia.org/wiki/Transfer_learning" rel="noopener ugc nofollow" target="_blank">迁移学习</a>的基础:在大数据集上训练一次模型，然后在新的特定领域(可能很小)数据集上微调模型。这允许快速调整预先训练的网络，以快速和高精度地解决新问题。</p><h1 id="53d2" class="lb lc jg bd ld le lf lg lh li lj lk ll km lm kn ln kp lo kq lp ks lq kt lr ls bi translated">卷积步骤</h1><p id="48b5" class="pw-post-body-paragraph lt lu jg lv b lw lx kh ly lz ma kk mb mc md me mf mg mh mi mj mk ml mm mn mo ij bi translated">现在让我们放大到一个<em class="mu">卷积层</em>。请记住，我们在神经网络中所说的卷积与信号处理中的经典 2D 卷积有点不同。虽然广义的想法是相似的，但在数学上并不相同。</p><figure class="kx ky kz la gt is gh gi paragraph-image"><div class="gh gi nx"><img src="../Images/8d0c8d79ca7ffa7b613f2c4923420c69.png" data-original-src="https://miro.medium.com/v2/resize:fit:790/1*1VJDP6qDY9-ExTuQVEOlVg.gif"/></div><figcaption class="iz ja gj gh gi jb jc bd b be z dk"><strong class="bd nw"><em class="kv">Figure 1.1</em></strong><em class="kv"> Convolution of a 5x5 input (blue) with 3x3 kernel (grey) with a stride of 2 and padding of 1. The 3x3 output is in green (</em><a class="ae jd" href="https://github.com/vdumoulin/conv_arithmetic" rel="noopener ugc nofollow" target="_blank"><em class="kv">source</em></a><em class="kv">).</em></figcaption></figure><p id="aed1" class="pw-post-body-paragraph lt lu jg lv b lw mp kh ly lz mq kk mb mc mr me mf mg ms mi mj mk mt mm mn mo ij bi translated">经典卷积和深度学习卷积都是通过对输入数组应用核来计算输出的。每个输出像素是输入和内核之间的逐元素乘积之和(<em class="mu">点积</em>)。通过在输入上移动核，我们获得不同的输出像素。我们每步移动的像素数(1 或更多)称为<strong class="lv jh">步幅。</strong></p><p id="fe42" class="pw-post-body-paragraph lt lu jg lv b lw mp kh ly lz mq kk mb mc mr me mf mg ms mi mj mk mt mm mn mo ij bi translated">一个基本的区别是输入和输出张量的形状:在神经网络中，我们有额外的维度。</p><p id="6f81" class="pw-post-body-paragraph lt lu jg lv b lw mp kh ly lz mq kk mb mc mr me mf mg ms mi mj mk mt mm mn mo ij bi translated">如果你不熟悉 2D 卷积，看看这个<a class="ae jd" href="http://setosa.io/ev/image-kernels/" rel="noopener ugc nofollow" target="_blank">伟大的互动演示</a>获得一些直觉。</p><ul class=""><li id="7256" class="nh ni jg lv b lw mp lz mq mc ny mg nz mk oa mo nm nn no np bi translated"><a class="ae jd" href="http://setosa.io/ev/image-kernels/" rel="noopener ugc nofollow" target="_blank">http://setosa.io/ev/image-kernels/</a></li></ul><figure class="kx ky kz la gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi ob"><img src="../Images/106d2436f6c9086f5cbeb9cc46253322.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*SVviXuPrUOScemSth8BM9g.png"/></div></div><figcaption class="iz ja gj gh gi jb jc bd b be z dk"><strong class="bd nw">Figure 2.</strong> A single convolution layer. The convolution output is a tensor with increased depth. Each spatial position in the output (yellow “rod”, middle) depends on a portion of the input (the “receptive field”, left) and on a bank of filters (kernels).</figcaption></figure><h2 id="e273" class="mv lc jg bd ld mw mx dn lh my mz dp ll mc na nb ln mg nc nd lp mk ne nf lr ng bi translated">与经典 2D 卷积的区别</h2><p id="eee0" class="pw-post-body-paragraph lt lu jg lv b lw lx kh ly lz ma kk mb mc md me mf mg mh mi mj mk ml mm mn mo ij bi translated">在 2D 卷积网中，卷积具有以下性质:</p><ol class=""><li id="4fc6" class="nh ni jg lv b lw mp lz mq mc ny mg nz mk oa mo oc nn no np bi translated"><em class="mu">输入</em>和<em class="mu">输出</em>激活(也叫<strong class="lv jh">特征图</strong> ) <strong class="lv jh"> </strong>是 3D 数组(<em class="mu">高度、宽度、深度</em>)。第一层输入深度为 3 (RGB)。我们越深入地层，深度就越大。注意，当考虑小批量时，输入实际上是 4D。</li><li id="8729" class="nh ni jg lv b lw nq lz nr mc ns mg nt mk nu mo oc nn no np bi translated">和<em class="mu">输入</em>和<em class="mu">输出</em>一样，<strong class="lv jh">内核</strong>也是 3D 的。空间大小通常为 3x3、5x5 或 7x7，深度等于<em class="mu">输入深度</em>。内核也被称为<strong class="lv jh">过滤器</strong>。</li><li id="3bae" class="nh ni jg lv b lw nq lz nr mc ns mg nt mk nu mo oc nn no np bi translated">每层有<strong class="lv jh"> </strong> <em class="mu">多个内核</em> <strong class="lv jh"> </strong>称为一个<strong class="lv jh">滤波器组。</strong>内核的数量决定了输出的<em class="mu">深度(通常大于输入深度)。</em></li><li id="77f9" class="nh ni jg lv b lw nq lz nr mc ns mg nt mk nu mo oc nn no np bi translated">与经典卷积不同，在 ConvNets 中，我们在单个步骤中计算多个卷积(一个卷积对应一层中的一个内核)。</li><li id="747f" class="nh ni jg lv b lw nq lz nr mc ns mg nt mk nu mo oc nn no np bi translated">与经典卷积不同，在乘法之前，核不沿空间维度翻转(这使得卷积不可交换，但该属性与神经网络无关)。</li></ol><h2 id="90eb" class="mv lc jg bd ld mw mx dn lh my mz dp ll mc na nb ln mg nc nd lp mk ne nf lr ng bi translated">感受野</h2><p id="e5f1" class="pw-post-body-paragraph lt lu jg lv b lw lx kh ly lz ma kk mb mc md me mf mg mh mi mj mk ml mm mn mo ij bi translated"><em class="mu">感受域</em>是对输出像素有贡献的输入的 3D 区域(见图 2 中的黄色立方体)。注意，一个输出像素有许多“值”，每个内核一个(图 2 中的 64)。通过排列对应于不同感受野的所有输出向量，我们获得了完整的 3D 激活。</p><p id="cac5" class="pw-post-body-paragraph lt lu jg lv b lw mp kh ly lz mq kk mb mc mr me mf mg ms mi mj mk mt mm mn mo ij bi translated">通常，两个相邻输出位置的感受野会部分重叠。只有当步幅等于内核大小时，才没有重叠。</p><h2 id="5738" class="mv lc jg bd ld mw mx dn lh my mz dp ll mc na nb ln mg nc nd lp mk ne nf lr ng bi translated">参数数量</h2><p id="c768" class="pw-post-body-paragraph lt lu jg lv b lw lx kh ly lz ma kk mb mc md me mf mg mh mi mj mk ml mm mn mo ij bi translated">层中的所有核(图 2 中的 64)可以排列成单个 4-D 形状张量</p><blockquote class="od"><p id="d516" class="oe of jg bd og oh oi oj ok ol om mo dk translated">(#内核，内核大小，内核大小，输入深度)</p></blockquote><p id="7310" class="pw-post-body-paragraph lt lu jg lv b lw on kh ly lz oo kk mb mc op me mf mg oq mi mj mk or mm mn mo ij bi translated">这些参数包括核中的所有权重加上 1D 偏移向量。</p><p id="23fb" class="pw-post-body-paragraph lt lu jg lv b lw mp kh ly lz mq kk mb mc mr me mf mg ms mi mj mk mt mm mn mo ij bi translated"><strong class="lv jh">偏差</strong>为<em class="mu">每个内核</em>引入了一个额外的参数。像核一样，每个空间位置的偏差都是相同的，因此偏差参数与核的数量(或输出深度)一样多。</p><p id="04a1" class="pw-post-body-paragraph lt lu jg lv b lw mp kh ly lz mq kk mb mc mr me mf mg ms mi mj mk mt mm mn mo ij bi translated">将偏差和权重放在一起，层中的总参数总计为:</p><blockquote class="od"><p id="b37b" class="oe of jg bd og oh oi oj ok ol om mo dk translated">(#内核数 x 内核大小 x 内核大小 x 输入深度)</p><p id="f01e" class="oe of jg bd og oh oi oj ok ol om mo dk translated">+ #内核</p></blockquote><h2 id="a105" class="mv lc jg bd ld mw os dn lh my ot dp ll mc ou nb ln mg ov nd lp mk ow nf lr ng bi translated">小批量</h2><p id="b92d" class="pw-post-body-paragraph lt lu jg lv b lw lx kh ly lz ma kk mb mc md me mf mg mh mi mj mk ml mm mn mo ij bi translated">实际上，图 1 的激活不是针对单个图像计算的，而是针对小批量计算的。在这种情况下，所有激活都将有一个大小为<em class="mu"> batch_size </em>的额外维度。必须考虑批量大小，因为它直接影响训练和评估模型所需的 RAM。通常，我们使用 GPU RAM 中能够容纳的最大批量。</p><h1 id="a07c" class="lb lc jg bd ld le lf lg lh li lj lk ll km lm kn ln kp lo kq lp ks lq kt lr ls bi translated">批量标准化</h1><p id="bc7a" class="pw-post-body-paragraph lt lu jg lv b lw lx kh ly lz ma kk mb mc md me mf mg mh mi mj mk ml mm mn mo ij bi translated">批处理规范化(BatchNorm)是近年来深度学习领域最重要的进展之一。BatchNorm 可以在几乎任何神经网络架构上加速和稳定训练，包括 ConvNets。</p><figure class="kx ky kz la gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi ox"><img src="../Images/df06ea71b1bb9162ae8127704d3fd9b4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*YnW-WdVenmDceyO52UOoSA.png"/></div></div><figcaption class="iz ja gj gh gi jb jc bd b be z dk"><strong class="bd nw">Figure 3. </strong>The batch normalization algorithm from the original paper. Before entering the ReLU, each batch is normalized with zero mean and unit standard deviation. Then, each activation is scaled and shifted using two parameters (gamma and beta). This last addition turns out to be the critical step making BatchNorm so effective. The scale-shift transform allows the optimization to directly control the scale of each activation through one parameter (gamma). Without it, a change of scale can only be achieved with a coordinated change in multiple weights that contribute to the activation.</figcaption></figure><p id="409e" class="pw-post-body-paragraph lt lu jg lv b lw mp kh ly lz mq kk mb mc mr me mf mg ms mi mj mk mt mm mn mo ij bi translated">奇怪的是，最初的 BatchNorm 作者将性能的提高归因于“<em class="mu">内部协方差偏移</em>的减少。但最近发现，BatchNorm 反而平滑了优化前景，允许更大的学习率快速收敛到更准确的解决方案。只是提醒一下，理论，即使是令人信服的或“直觉的”，也必须经过经验验证。</p><ul class=""><li id="a1f7" class="nh ni jg lv b lw mp lz mq mc ny mg nz mk oa mo nm nn no np bi translated">“批量标准化:通过减少内部协变量转移加速深度网络训练”，Sergey Ioffe，Christian Szegedy，<a class="ae jd" href="https://arxiv.org/abs/1502.03167" rel="noopener ugc nofollow" target="_blank">arXiv:1502.03167</a>(<strong class="lv jh">2015</strong>)</li><li id="3dc3" class="nh ni jg lv b lw nq lz nr mc ns mg nt mk nu mo nm nn no np bi translated"><a class="ae jd" href="https://www.deeplearningbook.org/contents/optimization.html#pf2b" rel="noopener ugc nofollow" target="_blank">《批量归一化</a>》，I. Goodfellow，J. Bengio，a .库维尔，<strong class="lv jh">深度学习书</strong> Ch 8.7.1 ( <strong class="lv jh"> 2016 </strong>)</li><li id="7da6" class="nh ni jg lv b lw nq lz nr mc ns mg nt mk nu mo nm nn no np bi translated">"批处理规范化如何帮助优化？"、桑图尔卡<em class="mu">等人</em><a class="ae jd" href="https://arxiv.org/abs/1805.11604" rel="noopener ugc nofollow" target="_blank">arXiv:1805.11604</a>(<strong class="lv jh">2018</strong>)</li></ul><h2 id="fbde" class="mv lc jg bd ld mw mx dn lh my mz dp ll mc na nb ln mg nc nd lp mk ne nf lr ng bi translated">其他标准化</h2><p id="6ade" class="pw-post-body-paragraph lt lu jg lv b lw lx kh ly lz ma kk mb mc md me mf mg mh mi mj mk ml mm mn mo ij bi translated">BatchNorm 无疑是深度学习中最流行的规范化方法，但不是唯一的。这一领域的研究非常活跃，在不久的将来我们可能会看到新的进展。问题是双重的。一方面，BachNorm 难以应用于递归网络，因为它依赖于小批量均值和标准差。另一方面，BatchNorm 的效果是相当偶然的，对 BatchNorm 如何帮助优化的更多研究可以带来更好的规范化方法。</p><p id="2f0b" class="pw-post-body-paragraph lt lu jg lv b lw mp kh ly lz mq kk mb mc mr me mf mg ms mi mj mk mt mm mn mo ij bi translated">为了简洁起见，我将只提到一种替代的归一化方案:<strong class="lv jh">权重归一化。</strong>在该方案中，我们对权重进行归一化，而不是对激活进行归一化。特别地，我们将每个核(对单次激活有贡献的所有权重)归一化为具有单位范数。然后，为了保持模型的表现力，我们还为每个激活添加了一个比例参数。原则上，这应该有助于以类似于 BatchNorm 的方式进行训练，通过提供一个单一的直接“旋钮”来改变每个激活，从而提供一个通向最小值的“更容易”(即更平滑)的路径。</p><figure class="kx ky kz la gt is gh gi paragraph-image"><div class="gh gi oy"><img src="../Images/1cb9b0483a16338f213a4b5f0c89324f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1044/format:webp/1*2OuGQ8PHEth-u_mFffMZww.png"/></div><figcaption class="iz ja gj gh gi jb jc bd b be z dk"><strong class="bd nw">Figure 4.</strong> Different approaches to normalize of activations in a mini-batch. (<a class="ae jd" href="https://mlexplained.com/2018/11/30/an-overview-of-normalization-methods-in-deep-learning/" rel="noopener ugc nofollow" target="_blank">source</a>)</figcaption></figure><p id="5c17" class="pw-post-body-paragraph lt lu jg lv b lw mp kh ly lz mq kk mb mc mr me mf mg ms mi mj mk mt mm mn mo ij bi translated">已经提出了许多其他的归一化方法，每种方法都有其利弊。要获得出色的概述，请参见 Keita Kurita 的“<a class="ae jd" href="https://mlexplained.com/2018/11/30/an-overview-of-normalization-methods-in-deep-learning/" rel="noopener ugc nofollow" target="_blank">深度学习中的规范化方法概述</a>”。</p><ul class=""><li id="ff76" class="nh ni jg lv b lw mp lz mq mc ny mg nz mk oa mo nm nn no np bi translated">“权重归一化:加速深度神经网络训练的简单重新参数化”，Tim Salimans，Diederik P. Kingma，<a class="ae jd" href="https://arxiv.org/abs/1602.07868" rel="noopener ugc nofollow" target="_blank">arXiv:1602.07868</a>(<strong class="lv jh">2016</strong>)</li><li id="0953" class="nh ni jg lv b lw nq lz nr mc ns mg nt mk nu mo nm nn no np bi translated"><a class="ae jd" href="https://mlexplained.com/2018/11/30/an-overview-of-normalization-methods-in-deep-learning/" rel="noopener ugc nofollow" target="_blank">深度学习中归一化方法概述，</a> Keita Kurita，(2018 年 11 月 30 日<strong class="lv jh"/>)</li></ul><h1 id="db48" class="lb lc jg bd ld le lf lg lh li lj lk ll km lm kn ln kp lo kq lp ks lq kt lr ls bi translated">联营</h1><figure class="kx ky kz la gt is gh gi paragraph-image"><div class="gh gi oz"><img src="../Images/3e0fcac1c038243911d252d6ea56f715.png" data-original-src="https://miro.medium.com/v2/resize:fit:1140/format:webp/1*S86gKd43MIYquHIeR9m8JQ.png"/></div><figcaption class="iz ja gj gh gi jb jc bd b be z dk"><strong class="bd nw">Figure 5. </strong>Example of a max-pooling block.</figcaption></figure><p id="8317" class="pw-post-body-paragraph lt lu jg lv b lw mp kh ly lz mq kk mb mc mr me mf mg ms mi mj mk mt mm mn mo ij bi translated">卷积块之后通常是汇集块，以减少激活空间维度。池有助于减少更深层的内存消耗。这也是将空间信息转化为特征的重要步骤。根据伊恩·戈德费罗<em class="mu">等人</em>的<strong class="lv jh">深度学习书籍</strong></p><blockquote class="pa pb pc"><p id="3afc" class="lt lu mu lv b lw mp kh ly lz mq kk mb pd mr me mf pe ms mi mj pf mt mm mn mo ij bi translated">池化有助于使表示对于输入的小平移近似不变。</p></blockquote><p id="b81d" class="pw-post-body-paragraph lt lu jg lv b lw mp kh ly lz mq kk mb mc mr me mf mg ms mi mj mk mt mm mn mo ij bi translated">有不同的汇集策略。最常见的是<strong class="lv jh">最大轮询</strong>和<strong class="lv jh">平均池</strong>。在所有情况下，池化将输入“块”(感受野)减少为 1×1 输出块，同时保持深度不变。通过选择最大输入激活(max-pooling)或取平均值(average-pooling)来实现减少。与卷积类似，汇集块将感受野映射到输出中的单个“像素”。出于这个原因，我们可以定义一个轮询空间大小(2x2、3x3 等。)和大步走。通常，步幅被选择为具有不重叠的感受野，以实现空间尺寸的减小。通常，最后的汇集层是整个空间激活的平均值(<em class="mu">全局平均汇集</em>或<strong class="lv jh">间隙)</strong>，导致 1x1 输出激活(图 1 中大小为 512 的 1D 激活)。与卷积不同，池化没有任何参数，输出要素(深度)的数量始终与输入相同。</p><p id="671a" class="pw-post-body-paragraph lt lu jg lv b lw mp kh ly lz mq kk mb mc mr me mf mg ms mi mj mk mt mm mn mo ij bi translated">具有“可学习结构”的池层已被提出，但迄今为止受欢迎程度有限(<a class="ae jd" href="https://doi.org/10.1109/CVPR.2012.6248076" rel="noopener ugc nofollow" target="_blank">贾等人 2012 </a>)。</p><ul class=""><li id="25c2" class="nh ni jg lv b lw mp lz mq mc ny mg nz mk oa mo nm nn no np bi translated">网络中的网络，，，水城颜，<a class="ae jd" href="https://arxiv.org/abs/1312.4400" rel="noopener ugc nofollow" target="_blank">arXiv:1312.4400</a>(<strong class="lv jh">2013</strong>)</li><li id="95d5" class="nh ni jg lv b lw nq lz nr mc ns mg nt mk nu mo nm nn no np bi translated">"<a class="ae jd" href="https://www.deeplearningbook.org/contents/convnets.html#pfa" rel="noopener ugc nofollow" target="_blank">Ch 9.3:Pooling</a>" I . good fellow，J. Bengio，a .库维尔，<strong class="lv jh">深度学习书</strong><a class="ae jd" href="https://www.deeplearningbook.org/contents/convnets.html#pfa" rel="noopener ugc nofollow" target="_blank">Ch 9.3</a>(<strong class="lv jh">2016</strong>)</li><li id="beb2" class="nh ni jg lv b lw nq lz nr mc ns mg nt mk nu mo nm nn no np bi translated">“超越空间金字塔:融合图像特征的感受野学习”，贾，黄畅，Trevor Darrell doi:<a class="ae jd" href="https://doi.org/10.1109/CVPR.2012.6248076" rel="noopener ugc nofollow" target="_blank">10.1109/cvpr . 2012.6248076</a>(<strong class="lv jh">2012</strong>)</li></ul><h1 id="d8f9" class="lb lc jg bd ld le lf lg lh li lj lk ll km lm kn ln kp lo kq lp ks lq kt lr ls bi translated">1x1 卷积</h1><p id="8e49" class="pw-post-body-paragraph lt lu jg lv b lw lx kh ly lz ma kk mb mc md me mf mg mh mi mj mk ml mm mn mo ij bi translated">一些架构使用 1x1 滤波器。在这种情况下，过滤器映射形状的输入</p><blockquote class="od"><p id="c387" class="oe of jg bd og oh oi oj ok ol om mo dk translated">(数量 _ 过滤器 _i，高度 _i，宽度 _i)</p></blockquote><p id="1007" class="pw-post-body-paragraph lt lu jg lv b lw on kh ly lz oo kk mb mc op me mf mg oq mi mj mk or mm mn mo ij bi translated">到形状的输出:</p><blockquote class="od"><p id="e016" class="oe of jg bd og oh oi oj ok ol om mo dk translated">(数量 _ 过滤器 _o，高度 _i，宽度 _i)</p></blockquote><p id="91fd" class="pw-post-body-paragraph lt lu jg lv b lw on kh ly lz oo kk mb mc op me mf mg oq mi mj mk or mm mn mo ij bi translated">注意<strong class="lv jh">只有特征的数量发生变化</strong>，而高度和宽度保持不变。在这种情况下，每个输出像素是仅依赖于一个输入像素的<em class="mu"> num_filters_o </em>特征的向量(大小为<em class="mu"> num_filters_i </em>的向量)。<em class="mu"> </em>每个输出特征是同一像素的输入特征的(不同)线性组合，该像素是大小为 1x1 的感受野。</p><p id="9bdc" class="pw-post-body-paragraph lt lu jg lv b lw mp kh ly lz mq kk mb mc mr me mf mg ms mi mj mk mt mm mn mo ij bi translated">1x1 滤波器用于减少输出要素的数量，从而在保持空间维度不变的同时降低计算成本。例如,<strong class="lv jh"> inception network </strong>使用 1x1 过滤器来减少功能并创建“瓶颈”,从而使架构在计算上更加经济实惠。然而，如果瓶颈太紧，可能会损害网络性能。</p><p id="e503" class="pw-post-body-paragraph lt lu jg lv b lw mp kh ly lz mq kk mb mc mr me mf mg ms mi mj mk mt mm mn mo ij bi translated">当卷积核的大小大于 1×1 时，<br/>每个输出特征仍然是感受野中所有输入特征<br/>的线性组合，在这种情况下是&gt; 1 像素宽。</p><p id="0e13" class="pw-post-body-paragraph lt lu jg lv b lw mp kh ly lz mq kk mb mc mr me mf mg ms mi mj mk mt mm mn mo ij bi translated">在林等人<em class="mu">的<a class="ae jd" href="https://arxiv.org/abs/1312.4400" rel="noopener ugc nofollow" target="_blank">原始论文</a>中，1x1 卷积被称为网络</em>中的<em class="mu">网络</em>原始论文将其描述为 1x1 输入和输出特性之间的“迷你”全连接层。请注意，使用相同的权重将相同的全连接层应用于每个空间位置。</p><ul class=""><li id="e7b5" class="nh ni jg lv b lw mp lz mq mc ny mg nz mk oa mo nm nn no np bi translated">网络中的网络，，，水城颜，<a class="ae jd" href="https://arxiv.org/abs/1312.4400" rel="noopener ugc nofollow" target="_blank">arXiv:1312.4400</a>(<strong class="lv jh">2013</strong></li></ul><h1 id="9916" class="lb lc jg bd ld le lf lg lh li lj lk ll km lm kn ln kp lo kq lp ks lq kt lr ls bi translated">开始</h1><p id="dd3c" class="pw-post-body-paragraph lt lu jg lv b lw lx kh ly lz ma kk mb mc md me mf mg mh mi mj mk ml mm mn mo ij bi translated">ILSVRC 2014 获奖者是 Szgedy <em class="mu">等人</em>的 GoogLeNet 架构。其中介绍了下面所示的<strong class="lv jh">初始模块</strong>。</p><figure class="kx ky kz la gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi pg"><img src="../Images/cfc6a4303d10a3bfe0cf52d975b41724.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*OxU1aUGAwn9dV_mCfDxsaQ.png"/></div></div><figcaption class="iz ja gj gh gi jb jc bd b be z dk"><strong class="bd nw">Figure 6.</strong> Inception module, the building block of the GoogLeNet architecture.</figcaption></figure><p id="6f4c" class="pw-post-body-paragraph lt lu jg lv b lw mp kh ly lz mq kk mb mc mr me mf mg ms mi mj mk mt mm mn mo ij bi translated">在卷积网络中，一个重要的选择是卷积核的空间大小。第一层的大小通常为 7x7，后面所有层的大小通常为 3x3。初始模块并行执行许多卷积，而不是为卷积选择一个大小。图 5 显示了在 inception v1 论文中提出的 inception 块。对同一输入执行大小为 1x1、3x3 和 5x5 的卷积(<em class="mu">蓝色块</em>)以及最大池(<em class="mu">红色块</em>)。额外的 1x1 卷积(<em class="mu">黄色块</em>)减少了深度大小，从而大大降低了内存需求。这些平行路径产生输出张量(具有相同的空间大小),这些输出张量沿着深度被连接起来以形成层输出。</p><p id="4e13" class="pw-post-body-paragraph lt lu jg lv b lw mp kh ly lz mq kk mb mc mr me mf mg ms mi mj mk mt mm mn mo ij bi translated">自第一篇论文以来，已经提出了对<em class="mu"> inception </em>架构的许多更新，包括 inception v2、v3、v4 和<em class="mu"> inception-resnet </em>。后者结合了多重卷积和跳跃连接的初始思想(参见<a class="ae jd" href="https://medium.com/p/48db75969fdf#5055" rel="noopener">下一节</a>)。</p><ul class=""><li id="d0c4" class="nh ni jg lv b lw mp lz mq mc ny mg nz mk oa mo nm nn no np bi translated">“用卷积更深入”，C. Szegedy 等人(<strong class="lv jh">2014</strong>)<a class="ae jd" href="https://arxiv.org/abs/1409.4842" rel="noopener ugc nofollow" target="_blank">arXiv:1409.4842</a></li><li id="0b67" class="nh ni jg lv b lw nq lz nr mc ns mg nt mk nu mo nm nn no np bi translated">《Inception-v4、Inception-ResNet 以及剩余连接对学习的影响》，克里斯蒂安·塞格迪、谢尔盖·约菲、文森特·范霍克、亚历克斯·阿莱米，(<strong class="lv jh">2016</strong>)<a class="ae jd" href="https://arxiv.org/abs/1602.07261" rel="noopener ugc nofollow" target="_blank">arXiv:1602.07261</a></li><li id="6343" class="nh ni jg lv b lw nq lz nr mc ns mg nt mk nu mo nm nn no np bi translated"><a class="ae jd" rel="noopener" target="_blank" href="/a-simple-guide-to-the-versions-of-the-inception-network-7fc52b863202">盗梦空间网络</a>版本的简单指南，Bharath Raj(2018 年 5 月<strong class="lv jh"/>)</li></ul><h1 id="5055" class="lb lc jg bd ld le lf lg lh li lj lk ll km lm kn ln kp lo kq lp ks lq kt lr ls bi translated">雷斯内特</h1><p id="560f" class="pw-post-body-paragraph lt lu jg lv b lw lx kh ly lz ma kk mb mc md me mf mg mh mi mj mk ml mm mn mo ij bi translated">多层神经网络中的一个已知问题是消失梯度。本质上，在反向传播期间，导数乘以前一层的导数。所以，当我们到达第一层的时候，梯度会变得非常小或者爆炸(溢出)。这种效应使得很难训练深度神经网络，包括神经网络。为了解决这个问题，何<em class="mu">等人</em>引入了“跳过连接”这一构成 ResNet 架构的构建模块。</p><figure class="kx ky kz la gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi ph"><img src="../Images/e28e3f228f8b613f8e9d3a9db3fd8b02.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*mNJaWeG9DPmYd8U0bPmLBA.png"/></div></div><figcaption class="iz ja gj gh gi jb jc bd b be z dk"><strong class="bd nw">Figure 7. </strong>Illustration of the skip-connection, the building block of the ResNet architecture. (<a class="ae jd" href="https://arxiv.org/abs/1512.03385" rel="noopener ugc nofollow" target="_blank">source</a>)</figcaption></figure><p id="02e2" class="pw-post-body-paragraph lt lu jg lv b lw mp kh ly lz mq kk mb mc mr me mf mg ms mi mj mk mt mm mn mo ij bi translated">在 ResNet 中，一层的输出不仅被馈送到下一层，而且被馈送到前面两层的输入。输入被添加到层输出，然后被馈送到下一层。</p><p id="becd" class="pw-post-body-paragraph lt lu jg lv b lw mp kh ly lz mq kk mb mc mr me mf mg ms mi mj mk mt mm mn mo ij bi translated">自从赢得 ILSVRC 2015 竞赛以来，ResNet 仍然是最先进的 ConvNet 架构。预训练的 ResNet34 或 ResNet50 是<a class="ae jd" href="https://en.wikipedia.org/wiki/Transfer_learning" rel="noopener ugc nofollow" target="_blank">迁移学习</a>中事实上的标准，用于实现从医学成像到泰迪熊探测器的专业应用。</p><ul class=""><li id="ea02" class="nh ni jg lv b lw mp lz mq mc ny mg nz mk oa mo nm nn no np bi translated">《深度残差学习用于图像识别》，，，，，任，，(<strong class="lv jh">2015</strong>)<a class="ae jd" href="https://arxiv.org/abs/1512.03385" rel="noopener ugc nofollow" target="_blank">arXiv:1512.03385</a></li><li id="fbd2" class="nh ni jg lv b lw nq lz nr mc ns mg nt mk nu mo nm nn no np bi translated">“<a class="ae jd" rel="noopener" target="_blank" href="/an-overview-of-resnet-and-its-variants-5281e2f56035">ResNet 及其变种</a>概述”，Vincent Fung ( <strong class="lv jh"> 2017 </strong>)</li></ul><h1 id="d7d7" class="lb lc jg bd ld le lf lg lh li lj lk ll km lm kn ln kp lo kq lp ks lq kt lr ls bi translated">可解释性</h1><blockquote class="pa pb pc"><p id="8fe5" class="lt lu mu lv b lw mp kh ly lz mq kk mb pd mr me mf pe ms mi mj pf mt mm mn mo ij bi translated">为了建立对智能系统的信任，并将其有意义地融入我们的日常生活，很明显，我们必须建立“透明”的模型，解释它们为什么预测它们所预测的东西。</p></blockquote><p id="f4f7" class="pw-post-body-paragraph lt lu jg lv b lw mp kh ly lz mq kk mb mc mr me mf mg ms mi mj mk mt mm mn mo ij bi translated"><em class="mu">来自</em><strong class="lv jh"><em class="mu">Grad-CAM</em></strong><em class="mu"/><a class="ae jd" href="https://arxiv.org/abs/1610.02391" rel="noopener ugc nofollow" target="_blank"><em class="mu">arXiv:1610.02391</em></a><em class="mu">。</em></p><p id="b184" class="pw-post-body-paragraph lt lu jg lv b lw mp kh ly lz mq kk mb mc mr me mf mg ms mi mj mk mt mm mn mo ij bi translated">众所周知，理解神经网络如何做出决定是一项艰巨的任务。解释神经网络的结果不仅是重要的科学努力，也是许多应用所需要的。神经网络可解释性是一个活跃的研究课题，涉及多种网络可视化技术。</p><p id="937e" class="pw-post-body-paragraph lt lu jg lv b lw mp kh ly lz mq kk mb mc mr me mf mg ms mi mj mk mt mm mn mo ij bi translated">概括地说，有两种广义的可解释性技术。一个称为<strong class="lv jh">属性</strong>，旨在找到输入图像中用于做出决定的区域。第二种称为<strong class="lv jh">特征可视化</strong>，旨在可视化输入图像中的哪些特征激活了特定的神经元或神经元群。</p><figure class="kx ky kz la gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi pi"><img src="../Images/84f942de08bdd42d72a128ca6af0c9c8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*227IReUdT4bWKdGccVoCUA.png"/></div></div><figcaption class="iz ja gj gh gi jb jc bd b be z dk"><strong class="bd nw">Figure 8.</strong> Two approaches in interpreting ConvNets: feature visualization and attribution. Source <a class="ae jd" href="https://doi.org/10.23915/distill.00007" rel="noopener ugc nofollow" target="_blank">Olah et al. 2017.</a></figcaption></figure><p id="fdaf" class="pw-post-body-paragraph lt lu jg lv b lw mp kh ly lz mq kk mb mc mr me mf mg ms mi mj mk mt mm mn mo ij bi translated">在一些架构上，<strong class="lv jh">属性</strong>可以通过将隐藏层中的空间激活与输入图像叠加并绘制所谓的<em class="mu">显著性图</em>来完成(图 8，右图)。显著图具有与上一次 3D 激活相同的空间分辨率，这是低的，但通常是足够的。适用于任何架构的这种方法的扩展是 Grad-CAM，其中显著图是最后空间激活(具有 3D 形状的最后激活)的加权平均值。这个加权平均值中的权重是从关于每次激活的损失函数的梯度计算的。Grad-CAM 可以应用于任何网络，甚至非分类任务。</p><figure class="kx ky kz la gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi pj"><img src="../Images/4bba3d6d8e10aea823603349eacbf67a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*cUx1gwyFqziTntSWeFCmAg.png"/></div></div><figcaption class="iz ja gj gh gi jb jc bd b be z dk"><strong class="bd nw">Figure 9.</strong> Feature visualization. The top row shows the “optimization objective”: single neuron, channel, layer, a class before soft-max, a class after soft-max. The bottom row shows an input image resulting from optimizing the corresponding objective. Source <a class="ae jd" href="https://doi.org/10.23915/distill.00007" rel="noopener ugc nofollow" target="_blank">Olah et al. 2017.</a></figcaption></figure><p id="f709" class="pw-post-body-paragraph lt lu jg lv b lw mp kh ly lz mq kk mb mc mr me mf mg ms mi mj mk mt mm mn mo ij bi translated">对于<strong class="lv jh">特征可视化</strong>，我们可以在每一层中绘制内核权重。每个内核显示在层输入中检测到的模式。在这种情况下，解释在第一层比较容易，但在更深的层变得更加困难。另一种简单的方法是绘制给定输入的激活。</p><p id="c076" class="pw-post-body-paragraph lt lu jg lv b lw mp kh ly lz mq kk mb mc mr me mf mg ms mi mj mk mt mm mn mo ij bi translated">生成(通过优化)输入图像以最大限度地激活神经元、通道、层或类的更细致的方法(图 9)。这允许构建“特征”的地图集，其可视地表示网络在每一层中响应什么。这种方法的缺点是生成的图像缺乏多样性，可能无法代表网络所响应的全部空间特征。关于进一步的信息，Distill.pub 发表的论文既有深刻的见解，又有令人惊叹的图表。</p><ul class=""><li id="36d3" class="nh ni jg lv b lw mp lz mq mc ny mg nz mk oa mo nm nn no np bi translated">" Grad-CAM "，R. R. Selvaraju，M. Cogswell，A. Das，R. Vedantam，D. Parikh，D. Batra ( <strong class="lv jh"> 2016 </strong>)，<a class="ae jd" href="https://arxiv.org/abs/1610.02391" rel="noopener ugc nofollow" target="_blank"> arXiv:1610.02391 </a></li><li id="c6ca" class="nh ni jg lv b lw nq lz nr mc ns mg nt mk nu mo nm nn no np bi translated"><a class="ae jd" href="http://cs231n.github.io/understanding-cnn/" rel="noopener ugc nofollow" target="_blank">“理解 CNN </a>”，安德烈·卡帕西，CS231n 课程</li><li id="1ec8" class="nh ni jg lv b lw nq lz nr mc ns mg nt mk nu mo nm nn no np bi translated"><em class="mu"> " </em>特征可视化<em class="mu"> " </em>，克里斯奥拉，亚历山大莫尔德温采夫，路德维希舒伯特(<strong class="lv jh"> 2017 </strong>)，<strong class="lv jh">distilt . pub</strong>，<a class="ae jd" href="http://doi.org/10.23915/distill.00007" rel="noopener ugc nofollow" target="_blank">doi:10.23915/distilt . 00007</a></li><li id="a993" class="nh ni jg lv b lw nq lz nr mc ns mg nt mk nu mo nm nn no np bi translated">《用激活图谱探索神经网络》，Shan Carte，Zan Armstrong，Ludwig Schubert，Ian Johnson，Chris Olah ( <strong class="lv jh"> 2018 </strong>)，<strong class="lv jh">distilt . pub</strong>，<a class="ae jd" href="https://doi.org/10.23915/distill.00015" rel="noopener ugc nofollow" target="_blank">doi:10.23915/distilt . 00015</a></li></ul><h1 id="006f" class="lb lc jg bd ld le lf lg lh li lj lk ll km lm kn ln kp lo kq lp ks lq kt lr ls bi translated">偏见</h1><figure class="kx ky kz la gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi pk"><img src="../Images/98fd1695ea9dfbdbd16f138f1c09aae1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*RI1PfLSag9IwxyGZ_Y1bQg.png"/></div></div><figcaption class="iz ja gj gh gi jb jc bd b be z dk"><strong class="bd nw">Figure 10.</strong> Bias in state-of-the-art face-recognition systems <a class="ae jd" href="https://www.fast.ai/2019/01/29/five-scary-things/" rel="noopener ugc nofollow" target="_blank">(source)</a>.</figcaption></figure><p id="3b67" class="pw-post-body-paragraph lt lu jg lv b lw mp kh ly lz mq kk mb mc mr me mf mg ms mi mj mk mt mm mn mo ij bi translated">如果不提到偏倚问题，对 ConvNets 的讨论是不完整的。机器学习中的偏差来自数据集和/或算法中的偏差，这反过来反映了创建系统的人的偏差。虽然偏见是机器学习中的一个严重问题，但 ConvNets 应用程序提供了一些突出的例子，说明它如何影响人们的生活。</p><p id="d40f" class="pw-post-body-paragraph lt lu jg lv b lw mp kh ly lz mq kk mb mc mr me mf mg ms mi mj mk mt mm mn mo ij bi translated">请记住，网络将“学习”对解决任务有用的表示。例如，如果我们的目标是识别人脸，理想的数据集应该尽可能多样化，以便以平衡的方式表示所有的种族、年龄和性别组。实际上，大多数流行的数据集都过度代表了白人男性。正如研究员 Joy Buolamwini 发现的那样，这导致了当前商业人脸识别系统的严重偏见。在这些系统中，有色人种女性的面部识别准确率比男性低<em class="mu">个数量级</em>(图 4)。例如，这些系统已经或将要被部署来识别犯罪嫌疑人。不幸的是，如果你是一个黑皮肤的女人，你会被误认为是一个比白人高一百倍的罪犯！</p><p id="c252" class="pw-post-body-paragraph lt lu jg lv b lw mp kh ly lz mq kk mb mc mr me mf mg ms mi mj mk mt mm mn mo ij bi translated">作为机器学习实践者，我们不能放弃我们的道德责任。我们知道我们创造的系统会以前所未有的规模扰乱人们的生活。因此，我们必须采取措施克服这种偏见。根据《福布斯》杂志，雷切尔·托马斯是“人工智能领域 20 位不可思议的女性”之一，她写了很多关于偏见问题的文章，她的帖子是一个极好的信息来源。</p><ul class=""><li id="3d6e" class="nh ni jg lv b lw mp lz mq mc ny mg nz mk oa mo nm nn no np bi translated"><a class="ae jd" href="https://www.fast.ai/2019/01/29/five-scary-things/" rel="noopener ugc nofollow" target="_blank">关于 AI 让我害怕的五件事</a>，Rachel Thomas，fast.ai 博客(<strong class="lv jh"> 2019 </strong>)</li><li id="9ac2" class="nh ni jg lv b lw nq lz nr mc ns mg nt mk nu mo nm nn no np bi translated"><a class="ae jd" href="https://www.media.mit.edu/projects/gender-shades/" rel="noopener ugc nofollow" target="_blank">性别阴影</a>，Joy Buolamwini，(<strong class="lv jh"> 2018 </strong>)麻省理工学院媒体实验室</li><li id="a919" class="nh ni jg lv b lw nq lz nr mc ns mg nt mk nu mo nm nn no np bi translated"><a class="ae jd" href="https://distill.pub/2019/safety-needs-social-scientists/" rel="noopener ugc nofollow" target="_blank"> AI 安全需要社会科学家</a>，杰弗里欧文，阿曼达阿斯克尔，(<strong class="lv jh">2019</strong>doi:<a class="ae jd" href="https://doi.org/10.23915/distill.00014" rel="noopener ugc nofollow" target="_blank">10.23915/distilt . 00014</a></li></ul><h1 id="08ba" class="lb lc jg bd ld le lf lg lh li lj lk ll km lm kn ln kp lo kq lp ks lq kt lr ls bi translated">其他主题</h1><p id="638a" class="pw-post-body-paragraph lt lu jg lv b lw lx kh ly lz ma kk mb mc md me mf mg mh mi mj mk ml mm mn mo ij bi translated">这里涵盖的主题还远未完成。这里有几个我没有谈到的话题:</p><ul class=""><li id="2905" class="nh ni jg lv b lw mp lz mq mc ny mg nz mk oa mo nm nn no np bi translated"><strong class="lv jh">优化</strong>:培训需要使用<a class="ae jd" href="http://ruder.io/optimizing-gradient-descent/" rel="noopener ugc nofollow" target="_blank">众多优化方法</a>中的一种。</li><li id="0a57" class="nh ni jg lv b lw nq lz nr mc ns mg nt mk nu mo nm nn no np bi translated"><strong class="lv jh">卷积运算</strong>:步幅和填充的效果形成一个题目叫做“<a class="ae jd" href="https://arxiv.org/abs/1603.07285" rel="noopener ugc nofollow" target="_blank">卷积运算</a>”。一个<strong class="lv jh">分数步距</strong>定义了<em class="mu">转置卷积</em>(也称为不恰当的“去卷积”)，其在生成模型中用于生成图像。</li><li id="5a75" class="nh ni jg lv b lw nq lz nr mc ns mg nt mk nu mo nm nn no np bi translated">敌对攻击:网络很容易被<a class="ae jd" href="https://openai.com/blog/adversarial-example-research/" rel="noopener ugc nofollow" target="_blank">微小的敌对干扰</a>所欺骗。精心选择的图像扰动(人眼不可见)可以改变网络输出。使 ConvNets 对敌对例子具有鲁棒性的研究正在进行中。</li></ul><h1 id="e3e1" class="lb lc jg bd ld le lf lg lh li lj lk ll km lm kn ln kp lo kq lp ks lq kt lr ls bi translated">结论</h1><p id="29a1" class="pw-post-body-paragraph lt lu jg lv b lw lx kh ly lz ma kk mb mc md me mf mg mh mi mj mk ml mm mn mo ij bi translated">在这篇文章中，我谈到了 ConvNets 的几个基本方面。即使是最先进的架构也是基于卷积层的基本构建模块。</p><p id="233e" class="pw-post-body-paragraph lt lu jg lv b lw mp kh ly lz mq kk mb mc mr me mf mg ms mi mj mk mt mm mn mo ij bi translated">ConvNets 可能已经“解决”了图像识别问题，但许多问题仍然存在。尽管最近取得了进展，解释结果仍然是一个挑战，一个阻碍某些领域应用的问题。用更小的数据集进行更好的泛化也将极大地扩展可处理问题的类别。但是，最重要的是，我们需要承认并努力克服社会偏见。鉴于对个人和社区的巨大影响，在这些系统中争取更多的公平是至关重要的。</p><h1 id="11b2" class="lb lc jg bd ld le lf lg lh li lj lk ll km lm kn ln kp lo kq lp ks lq kt lr ls bi translated">参考</h1><p id="49a1" class="pw-post-body-paragraph lt lu jg lv b lw lx kh ly lz ma kk mb mc md me mf mg mh mi mj mk ml mm mn mo ij bi translated">在这里你可以找到关于 ConvNets 的一般参考资料。具体主题的参考资料在每一节的末尾。</p><ol class=""><li id="b94d" class="nh ni jg lv b lw mp lz mq mc ny mg nz mk oa mo oc nn no np bi translated"><a class="ae jd" href="https://www.deeplearningbook.org/contents/convnets.html" rel="noopener ugc nofollow" target="_blank"> Ch。9.卷积网络</a>》，I. Goodfellow，J. Bengio，a .库维尔，<strong class="lv jh">深度学习著作</strong> (2016)。</li><li id="0276" class="nh ni jg lv b lw nq lz nr mc ns mg nt mk nu mo oc nn no np bi translated"><a class="ae jd" href="https://course.fast.ai/videos/?lesson=6" rel="noopener ugc nofollow" target="_blank">“第六课:正规化；盘旋；数据伦理</a>、<strong class="lv jh"> Fast.ai 程序员实用深度学习、v3" </strong></li><li id="bde5" class="nh ni jg lv b lw nq lz nr mc ns mg nt mk nu mo oc nn no np bi translated"><a class="ae jd" href="http://neuralnetworksanddeeplearning.com/chap6.html" rel="noopener ugc nofollow" target="_blank">谓 Ch。6:深度学习</a>、<strong class="lv jh">神经网络与深度学习</strong>，迈克尔·尼尔森(<strong class="lv jh">2015</strong>)<a class="ae jd" href="https://neuralnetworksanddeeplearning.com/" rel="noopener ugc nofollow" target="_blank">https://neuralnetworksanddeeplearning.com/</a></li><li id="b8af" class="nh ni jg lv b lw nq lz nr mc ns mg nt mk nu mo oc nn no np bi translated"><a class="ae jd" href="http://cs231n.github.io/convolutional-networks/" rel="noopener ugc nofollow" target="_blank">用于视觉识别的 CS231n 卷积神经网络</a>安德烈·卡帕西<strong class="lv jh">斯坦福 CS231n 讲座</strong></li><li id="6b98" class="nh ni jg lv b lw nq lz nr mc ns mg nt mk nu mo oc nn no np bi translated">《深度学习的卷积算法指南》，文森特·杜穆林，弗朗切斯科·维辛(<strong class="lv jh"> 2016 </strong>)，<a class="ae jd" href="https://arxiv.org/abs/1603.07285" rel="noopener ugc nofollow" target="_blank"> arXiv:1603.07285 </a>(另见<a class="ae jd" href="https://github.com/vdumoulin/conv_arithmetic#convolution-arithmetic" rel="noopener ugc nofollow" target="_blank">他们的动画</a>)</li></ol><p id="49cd" class="pw-post-body-paragraph lt lu jg lv b lw mp kh ly lz mq kk mb mc mr me mf mg ms mi mj mk mt mm mn mo ij bi translated"><strong class="lv jh">其他博文:</strong></p><ol class=""><li id="3507" class="nh ni jg lv b lw mp lz mq mc ny mg nz mk oa mo oc nn no np bi translated">Adit Deshpande 的《理解卷积神经网络的初学者指南》</li><li id="48f3" class="nh ni jg lv b lw nq lz nr mc ns mg nt mk nu mo oc nn no np bi translated">Irhum Shafkat 的“直观理解用于深度学习的卷积”</li></ol><p id="ef1c" class="pw-post-body-paragraph lt lu jg lv b lw mp kh ly lz mq kk mb mc mr me mf mg ms mi mj mk mt mm mn mo ij bi translated">来自<a class="ae jd" href="http://terencebroad.com/convnetvis/vis.html" rel="noopener ugc nofollow" target="_blank">卷积神经网络</a>拓扑可视化的标题图像。</p></div></div>    
</body>
</html>