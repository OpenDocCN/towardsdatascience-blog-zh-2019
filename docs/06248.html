<html>
<head>
<title>Automate Hyperparameter Tuning for your models</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">为您的模型自动调整超参数</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/automate-hyperparameter-tuning-for-your-models-71b18f819604?source=collection_archive---------15-----------------------#2019-09-09">https://towardsdatascience.com/automate-hyperparameter-tuning-for-your-models-71b18f819604?source=collection_archive---------15-----------------------#2019-09-09</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><figure class="is it gp gr iu iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi ir"><img src="../Images/723109a52ce01c66f9f2699912718e6a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*_3YEwLX5G3wvvs0e"/></div></div><figcaption class="jc jd gj gh gi je jf bd b be z dk">Photo by <a class="ae jg" href="https://unsplash.com/@marcin?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Marcin Nowak</a> on <a class="ae jg" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><div class=""/><div class=""><h2 id="44ef" class="pw-subtitle-paragraph kg ji jj bd b kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx dk translated">因为你的时间比机器更重要</h2></div><p id="caff" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">当我们创建我们的机器学习模型时，我们面临的一个常见任务是如何调整它们。</p><p id="ba9f" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">人们最终采取不同的手动方法。有些有效，有些无效，大量时间花在预测和一遍又一遍地运行代码上。</p><p id="b927" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">这就给我们带来了一个本质问题:我们能自动化这个过程吗？T3】</p><p id="bf94" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">不久前，我正在参加 Coursera 课程的<a class="ae jg" href="https://www.coursera.org/specializations/aml?siteID=lVarvwc5BD0-BShznKdc3CUauhfsM7_8xw&amp;utm_content=2&amp;utm_medium=partners&amp;utm_source=linkshare&amp;utm_campaign=lVarvwc5BD0" rel="noopener ugc nofollow" target="_blank"> <strong class="la jk">【如何赢得数据科学竞赛】</strong> </a>的一次课堂竞赛。学到了很多新东西，其中之一就是 Hyperopt——一个贝叶斯参数调整框架。</p><p id="8dcc" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">我很惊讶。晚上我把我的 Mac 和远视留在一起了。早上我拿到了结果。这太棒了，我确实避免了很多尝试。</p><p id="be9b" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><strong class="la jk"> <em class="lu">这个帖子是关于自动化超参数调优的，因为我们的时间比机器更重要。</em>T11】</strong></p></div><div class="ab cl lv lw hx lx" role="separator"><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma"/></div><div class="im in io ip iq"><h1 id="88f2" class="mc md jj bd me mf mg mh mi mj mk ml mm kp mn kq mo ks mp kt mq kv mr kw ms mt bi translated">那么，什么是远视呢？</h1><figure class="mv mw mx my gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi mu"><img src="../Images/9d20526fcf06dd410f4aac9f50eb7258.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*oinG3zUk6rGzfrL7.jpg"/></div></div></figure><p id="255e" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">从 Hyperopt 网站:</p><blockquote class="mz na nb"><p id="56a2" class="ky kz lu la b lb lc kk ld le lf kn lg nc li lj lk nd lm ln lo ne lq lr ls lt im bi translated"><em class="jj"> Hyperopt 是一个 Python 库，用于对笨拙的搜索空间进行串行和并行优化，搜索空间可能包括实值、离散和条件维度</em></p></blockquote><p id="e02a" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><strong class="la jk"> <em class="lu">简单来说，这意味着我们得到了一个可以最小化/最大化任何函数的优化器。</em> </strong>例如，我们可以用这个来最小化日志损失或最大化准确性。</p><p id="9ee2" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">我们都知道网格搜索或随机网格搜索是如何工作的。</p><p id="df2c" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">网格搜索逐个遍历参数，而随机搜索随机遍历参数。</p><p id="00af" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><strong class="la jk"> </strong></p><blockquote class="nf"><p id="1cb4" class="ng nh jj bd ni nj nk nl nm nn no lt dk translated">因此，Hyperopt 旨在以一种明智的方式搜索参数空间。</p></blockquote><p id="e34f" class="pw-post-body-paragraph ky kz jj la b lb np kk ld le nq kn lg lh nr lj lk ll ns ln lo lp nt lr ls lt im bi translated">细节我就不多说了。但是如果你想知道更多关于它是如何工作的，看看 J Bergstra 的这篇<a class="ae jg" href="https://conference.scipy.org/proceedings/scipy2013/pdfs/bergstra_hyperopt.pdf" rel="noopener ugc nofollow" target="_blank"> <strong class="la jk">论文</strong> </a>。下面是来自 Github 的<a class="ae jg" href="https://github.com/hyperopt/hyperopt/wiki/FMin" rel="noopener ugc nofollow" target="_blank"> <strong class="la jk">文档</strong> </a>。</p></div><div class="ab cl lv lw hx lx" role="separator"><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma"/></div><div class="im in io ip iq"><h1 id="d99f" class="mc md jj bd me mf mg mh mi mj mk ml mm kp mn kq mo ks mp kt mq kv mr kw ms mt bi translated">我们的数据集</h1><p id="d244" class="pw-post-body-paragraph ky kz jj la b lb nu kk ld le nv kn lg lh nw lj lk ll nx ln lo lp ny lr ls lt im bi translated">为了解释 hyperopt 是如何工作的，我将处理来自 UCI 的<a class="ae jg" href="https://www.kaggle.com/ronitf/heart-disease-uci" rel="noopener ugc nofollow" target="_blank">心脏数据集</a>，因为它是一个简单的数据集。除了产生利润之外，为什么不利用数据科学做些好事呢？</p><p id="f9ae" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">给定一些变量，该数据集预测心脏病的存在。</p><p id="4420" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">这是数据集的快照:</p><figure class="mv mw mx my gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi nz"><img src="../Images/5522d97b3736df74cb8d9f18a06b3ed8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Apmr43Kj3ZUnJX2aYosw3Q.png"/></div></div></figure><p id="ebea" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">目标分布如下所示:</p><figure class="mv mw mx my gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi oa"><img src="../Images/6a8536d42ebe7845035bad325b175b2f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*QJ2XK2lRH_NnfBjUL4zPUA.png"/></div></div></figure></div><div class="ab cl lv lw hx lx" role="separator"><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma"/></div><div class="im in io ip iq"><h1 id="ea61" class="mc md jj bd me mf mg mh mi mj mk ml mm kp mn kq mo ks mp kt mq kv mr kw ms mt bi translated">远视循序渐进</h1><figure class="mv mw mx my gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi mu"><img src="../Images/75c8144e5669ae6c22f4cdf2865a8d95.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*N6adYrsGFQNxdiay.jpg"/></div></div></figure><p id="42a1" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">因此，在尝试运行 hyperopt 时，我们需要创建两个 Python 对象:</p><ol class=""><li id="6eff" class="ob oc jj la b lb lc le lf lh od ll oe lp of lt og oh oi oj bi translated"><strong class="la jk"> <em class="lu">一个目标函数:</em> </strong>目标函数以超参数空间为输入，返回损失。这里我们称我们的目标函数为<code class="fe ok ol om on b">objective</code></li><li id="949f" class="ob oc jj la b lb oo le op lh oq ll or lp os lt og oh oi oj bi translated"><strong class="la jk"> <em class="lu">一个超参数的字典:</em> </strong>我们将通过使用变量<code class="fe ok ol om on b">space</code>来定义一个超参数空间，这个变量实际上只是一个字典。我们可以为不同的超参数值选择不同的分布。</li></ol><p id="442c" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">最后，我们将使用 hyperopt 包中的<code class="fe ok ol om on b">fmin</code>功能，通过<code class="fe ok ol om on b">space</code>最小化我们的<code class="fe ok ol om on b">objective</code>。</p><p id="c60b" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">你可以跟随这个<a class="ae jg" href="https://www.kaggle.com/mlwhiz/how-to-use-hyperopt?scriptVersionId=20362799" rel="noopener ugc nofollow" target="_blank"> Kaggle 内核</a>中的代码。</p></div><div class="ab cl lv lw hx lx" role="separator"><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma"/></div><div class="im in io ip iq"><h2 id="ec93" class="ot md jj bd me ou ov dn mi ow ox dp mm lh oy oz mo ll pa pb mq lp pc pd ms pe bi translated">1.创建目标函数</h2><p id="f446" class="pw-post-body-paragraph ky kz jj la b lb nu kk ld le nv kn lg lh nw lj lk ll nx ln lo lp ny lr ls lt im bi translated">这里，我们创建一个目标函数，它将一个超参数空间作为输入:</p><ul class=""><li id="2d71" class="ob oc jj la b lb lc le lf lh od ll oe lp of lt pf oh oi oj bi translated">我们首先定义一个分类器，在本例中是 XGBoost。试着看看我们如何从空间获取参数。例如<code class="fe ok ol om on b">space[‘max_depth’]</code></li><li id="f194" class="ob oc jj la b lb oo le op lh oq ll or lp os lt pf oh oi oj bi translated">我们使分类器适合训练数据，然后在交叉验证集上进行预测。</li><li id="77b2" class="ob oc jj la b lb oo le op lh oq ll or lp os lt pf oh oi oj bi translated">我们计算想要最大化或最小化的所需指标。</li><li id="fd76" class="ob oc jj la b lb oo le op lh oq ll or lp os lt pf oh oi oj bi translated">因为我们只在 hyperopt 中最小化使用<code class="fe ok ol om on b">fmin</code>,如果我们想最小化<code class="fe ok ol om on b">logloss</code>,我们只发送我们的度量。如果我们想最大限度地提高精度，我们将尽量减少<code class="fe ok ol om on b">-accuracy</code></li></ul><figure class="mv mw mx my gt iv"><div class="bz fp l di"><div class="pg ph l"/></div></figure></div><div class="ab cl lv lw hx lx" role="separator"><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma"/></div><div class="im in io ip iq"><h2 id="32c8" class="ot md jj bd me ou ov dn mi ow ox dp mm lh oy oz mo ll pa pb mq lp pc pd ms pe bi translated">2.为您的分类器创建空间</h2><figure class="mv mw mx my gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi mu"><img src="../Images/aaee95d52488b111889ae5b04710fa98.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*93GEtyc-RnBcnL7O.jpg"/></div></div></figure><p id="40fa" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">现在，我们<strong class="la jk"> <em class="lu">为分类器创建超参数</em> </strong>的搜索空间。</p><p id="3f14" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">为此，我们最终使用了许多定义各种分布的 hyperopt 内置函数。</p><p id="a56f" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">正如您在下面的代码中看到的，我们对<code class="fe ok ol om on b">subsample</code>超参数使用 0.7 到 1 之间的均匀分布。我们还给出了子样本参数<code class="fe ok ol om on b">x_subsample</code>的标签。您需要为您定义的每个超参数提供不同的标签。我通常在我的参数名前添加一个<code class="fe ok ol om on b">x_</code>来创建这个标签。</p><figure class="mv mw mx my gt iv"><div class="bz fp l di"><div class="pg ph l"/></div></figure><p id="1d3a" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">你也可以定义很多其他的发行版。hyperopt 优化算法目前认可的一些最有用的随机表达式是:</p><ul class=""><li id="d8cb" class="ob oc jj la b lb lc le lf lh od ll oe lp of lt pf oh oi oj bi translated"><code class="fe ok ol om on b">hp.choice(label, options)</code> —返回选项之一，应为列表或元组。</li><li id="f3ec" class="ob oc jj la b lb oo le op lh oq ll or lp os lt pf oh oi oj bi translated"><code class="fe ok ol om on b">hp.randint(label, upper)</code> —返回范围[0，上限]内的随机整数。</li><li id="0392" class="ob oc jj la b lb oo le op lh oq ll or lp os lt pf oh oi oj bi translated"><code class="fe ok ol om on b">hp.uniform(label, low, high)</code> —统一返回一个介于<code class="fe ok ol om on b">low</code>和<code class="fe ok ol om on b">high</code>之间的值。</li><li id="51a3" class="ob oc jj la b lb oo le op lh oq ll or lp os lt pf oh oi oj bi translated"><code class="fe ok ol om on b">hp.quniform(label, low, high, q)</code> —返回一个类似 round(uniform(low，high) / q) * q 的值</li><li id="f685" class="ob oc jj la b lb oo le op lh oq ll or lp os lt pf oh oi oj bi translated"><code class="fe ok ol om on b">hp.normal(label, mu, sigma)</code> —返回一个正态分布的实数值，其平均值为μ，标准差为σ。</li></ul><p id="4668" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">还有很多其他发行版。你可以点击查看<a class="ae jg" href="https://github.com/hyperopt/hyperopt/wiki/FMin" rel="noopener ugc nofollow" target="_blank">。</a></p></div><div class="ab cl lv lw hx lx" role="separator"><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma"/></div><div class="im in io ip iq"><h2 id="a1b8" class="ot md jj bd me ou ov dn mi ow ox dp mm lh oy oz mo ll pa pb mq lp pc pd ms pe bi translated">3.最后，运行 Hyperopt</h2><figure class="mv mw mx my gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi mu"><img src="../Images/70d9c9310401bc58c346f41515e8ac0f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*cOt1Iu7B-8AIiRQ4.jpg"/></div></div></figure><p id="ec31" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">一旦我们运行这个，我们就能得到模型的最佳参数。事实证明，我们在这个问题上做到了 90%的准确率。</p><figure class="mv mw mx my gt iv"><div class="bz fp l di"><div class="pg ph l"/></div></figure><figure class="mv mw mx my gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi pi"><img src="../Images/7658a414798c5f3ee7e9b76ce8f32278.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*1cYghbkmt3-pBqv8LNcwhQ.png"/></div></div></figure><p id="840e" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">现在我们可以用这些最佳参数重新训练我们的 XGboost 算法，我们完成了。T11】</p></div><div class="ab cl lv lw hx lx" role="separator"><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma"/></div><div class="im in io ip iq"><h1 id="40ea" class="mc md jj bd me mf mg mh mi mj mk ml mm kp mn kq mo ks mp kt mq kv mr kw ms mt bi translated">结论</h1><p id="507c" class="pw-post-body-paragraph ky kz jj la b lb nu kk ld le nv kn lg lh nw lj lk ll nx ln lo lp ny lr ls lt im bi translated">运行上面的程序给我们的学习算法提供了很好的超参数。这让我节省了很多时间去思考各种其他的假设并测试它们。</p><p id="5c69" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">我倾向于在调优我的模型时大量使用这个。<strong class="la jk"> <em class="lu">根据我的经验，整个过程中最关键的部分是建立超参数空间，这需要经验和对模型的了解。</em>T15】</strong></p><p id="9500" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">所以，Hyperopt 是一个非常棒的工具，但是千万不要忘记理解你的模型是做什么的。从长远来看，这是很有帮助的。</p><p id="5da6" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">你可以在这个<a class="ae jg" href="https://www.kaggle.com/mlwhiz/how-to-use-hyperopt?scriptVersionId=20362799" rel="noopener ugc nofollow" target="_blank"> Kaggle 内核</a>中获得完整的代码。</p></div><div class="ab cl lv lw hx lx" role="separator"><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma"/></div><div class="im in io ip iq"><h1 id="aa94" class="mc md jj bd me mf mg mh mi mj mk ml mm kp mn kq mo ks mp kt mq kv mr kw ms mt bi translated">继续学习</h1><p id="9afa" class="pw-post-body-paragraph ky kz jj la b lb nu kk ld le nv kn lg lh nw lj lk ll nx ln lo lp ny lr ls lt im bi translated">如果你想了解更多关于实用数据科学的知识，请看看 Coursera 的<a class="ae jg" href="https://coursera.pxf.io/yRPoZB" rel="noopener ugc nofollow" target="_blank"> <strong class="la jk">“如何赢得数据科学竞赛”</strong> </a>课程。从这个课程中学到了很多新的东西，这个课程是由最多产的卡格勒教授的。</p><p id="e852" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">还有另一个叫做 Optuna 的框架，你可以用它来代替 Hyperopt。在这里阅读<a class="ae jg" href="https://bit.ly/3gn6k0E" rel="noopener ugc nofollow" target="_blank"/>。</p><p id="62bd" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">谢谢你的阅读。将来我也会写更多初学者友好的帖子。在<a class="ae jg" href="https://medium.com/@rahul_agarwal?source=post_page---------------------------" rel="noopener"><strong class="la jk"/></a>关注我或者订阅我的<a class="ae jg" href="http://eepurl.com/dbQnuX?source=post_page---------------------------" rel="noopener ugc nofollow" target="_blank"> <strong class="la jk">博客</strong> </a>了解他们。一如既往，我欢迎反馈和建设性的批评，可以通过 Twitter <a class="ae jg" href="https://twitter.com/MLWhiz?source=post_page---------------------------" rel="noopener ugc nofollow" target="_blank"> @mlwhiz </a>联系。</p><p id="3023" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">此外，一个小的免责声明-在这篇文章中可能会有一些相关资源的链接，因为分享知识从来都不是一个坏主意。</p></div></div>    
</body>
</html>