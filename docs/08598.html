<html>
<head>
<title>Convolutional Autoencoders for Image Noise Reduction</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">用于图像降噪的卷积自动编码器</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/convolutional-autoencoders-for-image-noise-reduction-32fce9fc1763?source=collection_archive---------0-----------------------#2019-11-20">https://towardsdatascience.com/convolutional-autoencoders-for-image-noise-reduction-32fce9fc1763?source=collection_archive---------0-----------------------#2019-11-20</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><figure class="gl gn jr js jt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi jq"><img src="../Images/df8979833a941cd73df72249539e87e9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*a1Yy2bG_zMnqRov93SWs4w.png"/></div></div></figure><p id="6d57" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">在“<a class="ae kz" rel="noopener" target="_blank" href="/anomaly-detection-with-autoencoder-b4cdce4866a6">自动编码器异常检测变得简单</a>中，我提到自动编码器已经广泛应用于<em class="la">降维</em>和<em class="la">图像降噪</em>。从那时起，许多读者问我是否可以使用自动编码器来降低图像噪声。这就是这篇文章的动机。</p><p id="94cc" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">在神经网络世界中，对图像数据建模需要一种特殊的方法。用于对图像数据建模的最著名的神经网络是<strong class="kd iu">卷积神经网络(CNN，或 ConvNet)。</strong>可以更好的保留一幅图像像素之间的连通信息。CNN 中各层的特殊设计使其成为处理图像数据的更好选择。</p><p id="23f9" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">CNN 设计可用于图(1)所示的<strong class="kd iu">图像识别/分类</strong>，或用于图(2)所示的<strong class="kd iu">图像降噪或着色</strong>。在图(1)中，我们通过将许多图像样本作为输入并将标签作为输出来训练 CNN 模型。然后我们用这个训练好的 CNN 模型对一个新的图像进行识别，看它是“狗”，还是“猫”等等。CNN 也可以用作图像降噪或着色的自动编码器。</p><p id="6246" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">当 CNN 用于图像降噪或着色时，它应用于自动编码器框架中，即，CNN 用于自动编码器的编码和解码部分。图(2)显示了一个 CNN 自动编码器。每个输入图像样本是具有噪声的图像，并且每个输出图像样本是没有噪声的对应图像。我们可以将训练好的模型应用于有噪声的图像，然后输出清晰的图像。同样，它可以用于训练图像着色的模型。图(2)是一个使用 CNN 自动编码器为图像着色的例子。</p><figure class="lc ld le lf gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi lb"><img src="../Images/d6f9d4ef7da31e155de6b9f786bfcbdf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*KxeovF6fhyN12cH4vbpOEA.png"/></div></div></figure><figure class="lc ld le lf gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi lg"><img src="../Images/4b3e411dfe6808e0e4be80700fac2970.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*gzJAJDLDavH_W7Zv2M2J7w.png"/></div></div><figcaption class="lh li gj gh gi lj lk bd b be z dk">Figure (2)</figcaption></figure><p id="b313" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">在这篇文章中，让我先简单介绍一下图像数据，因为并非所有读者都熟悉图像数据领域(如果您已经熟悉了，请随意跳过这一部分)。然后，我描述了一个简单的标准神经网络的图像数据。这将允许我演示为什么卷积自动编码器是处理图像数据的首选方法。最重要的是，我将演示卷积自动编码器如何减少图像中的噪声。我在这篇文章中使用了 Keras 模块和 MNIST 数据。笔记本可以通过 Github 链接获得。<a class="ae kz" href="https://keras.io/" rel="noopener ugc nofollow" target="_blank"> Keras </a>是一个高级神经网络 API，用 Python 编写，能够在<a class="ae kz" href="https://github.com/tensorflow/tensorflow" rel="noopener ugc nofollow" target="_blank"> TensorFlow </a>之上运行。这篇文章是我之前的文章“<a class="ae kz" rel="noopener" target="_blank" href="/module-6-image-recognition-for-insurance-claim-handling-part-i-a338d16c9de0">什么是图像识别”的延伸。</a>“我鼓励你去看一看。</p><p id="19a1" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">我认为提及三大数据类别是有帮助的。这三个数据类别是(1)多元数据(与串行数据相反)，(2)串行数据(包括文本和语音流数据)，以及(3)图像数据。<strong class="kd iu">深度学习有三种基本变化来解决每个数据类别:</strong> (1)标准前馈神经网络，(2) RNN/LSTM，以及(3)卷积神经网络(CNN)。对于正在寻找每种类型教程的读者，建议查看《<a class="ae kz" href="https://medium.com/swlh/a-tutorial-to-build-from-regression-to-deep-learning-b7354240d2d5" rel="noopener">用回归友好的方式解释深度学习</a>》的(1)，当前文章《<a class="ae kz" href="https://dataman-ai.medium.com/a-technical-guide-on-rnn-lstm-gru-for-stock-price-prediction-bce2f7f30346" rel="noopener">RNN/LSTM/GRU 股价预测技术指南</a>》的(2)，以及《<a class="ae kz" href="https://medium.com/analytics-vidhya/not-torturing-in-learning-pytorch-b2f7f169923a" rel="noopener">用 PyTorch 进行深度学习不是折磨</a>》，《<a class="ae kz" rel="noopener" target="_blank" href="/module-6-image-recognition-for-insurance-claim-handling-part-i-a338d16c9de0">什么是图像识别？</a>、<a class="ae kz" rel="noopener" target="_blank" href="/anomaly-detection-with-autoencoder-b4cdce4866a6">使用自动编码器的异常检测变得容易</a>、<a class="ae kz" rel="noopener" target="_blank" href="/convolutional-autoencoders-for-image-noise-reduction-32fce9fc1763">用于图像降噪的卷积自动编码器</a>(3)。您可以将摘要文章“<a class="ae kz" href="https://medium.com/analytics-vidhya/dataman-learning-paths-build-your-skills-drive-your-career-e1aee030ff6e" rel="noopener"> Dataman 学习之路——培养您的技能，推动您的职业发展</a>”加入书签。</p><p id="e4db" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated"><strong class="kd iu">理解图像数据</strong></p><p id="08a4" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">如图(A)所示，图像由“像素”组成。在黑白图像中，每个像素由一个从 0 到 255 的数字表示。今天大多数图像使用 24 位或更高的颜色。RGB 彩色图像意味着像素中的颜色是红色、绿色和蓝色的组合，每种颜色的范围从 0 到 255。RGB 颜色系统从红色、绿色和蓝色的组合中构建所有颜色，如<a class="ae kz" href="https://www.w3schools.com/colors/colors_picker.asp" rel="noopener ugc nofollow" target="_blank">该 RGB 颜色生成器</a>所示。所以一个像素包含一组三个值 RGB(102，255，102)指颜色<strong class="kd iu"> #66ff66。</strong></p><figure class="lc ld le lf gt ju gh gi paragraph-image"><div class="gh gi ll"><img src="../Images/e5dd9e762becaf3054839c178d272ce9.png" data-original-src="https://miro.medium.com/v2/resize:fit:696/format:webp/1*xnUsNdEqPHdv8D_0_H5MgQ.png"/></div><figcaption class="lh li gj gh gi lj lk bd b be z dk">Figure (A)</figcaption></figure><p id="c5aa" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">800 像素宽、600 像素高的图像具有 800 x 600 = 480，000 像素= 0.48 兆像素(“兆像素”是 100 万像素)。分辨率为 1024×768 的图像是具有 1，024 列和 768 行的网格，因此包含 1，024 × 768 = 0.78 兆像素。</p><div class="lm ln gp gr lo lp"><a href="https://dataman-ai.medium.com/membership" rel="noopener follow" target="_blank"><div class="lq ab fo"><div class="lr ab ls cl cj lt"><h2 class="bd iu gy z fp lu fr fs lv fu fw is bi translated">通过我的推荐链接加入 Medium-Chris Kuo/data man 博士</h2><div class="lw l"><h3 class="bd b gy z fp lu fr fs lv fu fw dk translated">阅读 Chris Kuo/data man 博士的每一个故事。你的会员费直接支持郭怡广/戴塔曼博士和其他…</h3></div><div class="lx l"><p class="bd b dl z fp lu fr fs lv fu fw dk translated">dataman-ai.medium.com</p></div></div><div class="ly l"><div class="lz l ma mb mc ly md jz lp"/></div></div></a></div><p id="f01f" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated"><strong class="kd iu"> MNIST </strong></p><p id="b153" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">MNIST 数据库(改进的国家标准和技术研究所数据库)是一个手写数字的大型数据库，通常用于训练各种图像处理系统。Keras 中的训练数据集有 60，000 条记录，测试数据集有 10，000 条记录。每条记录有 28 x 28 个像素。</p><figure class="lc ld le lf gt ju"><div class="bz fp l di"><div class="me mf l"/></div></figure><p id="5331" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">他们长什么样？让我们用<code class="fe mg mh mi mj b">matplotlib</code>和它的图像函数<code class="fe mg mh mi mj b">imshow()</code>来显示前十条记录。</p><figure class="lc ld le lf gt ju"><div class="bz fp l di"><div class="me mf l"/></div></figure><figure class="lc ld le lf gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi mk"><img src="../Images/f523cc7ac0633c47b4779a6b380951ac.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*yzewT0rh4JNsDjSN-gBBMg.png"/></div></div></figure><p id="7bb8" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated"><strong class="kd iu">堆叠用于训练的图像数据</strong></p><p id="ee9c" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">为了适合用于模型训练的神经网络框架，我们可以将所有 28 x 28 = 784 个值堆叠在一列中。第一条记录的堆叠列如下所示:(使用<code class="fe mg mh mi mj b">x_train[1].reshape(1,784)</code>):</p><figure class="lc ld le lf gt ju gh gi paragraph-image"><div class="gh gi ml"><img src="../Images/8c1cdc7c1968746a6ab73f593c23e089.png" data-original-src="https://miro.medium.com/v2/resize:fit:1230/format:webp/1*3lrHlwvkZQb0om8rEBVv5A.png"/></div><figcaption class="lh li gj gh gi lj lk bd b be z dk">Figure (B): Part of the values</figcaption></figure><p id="2377" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">然后我们可以用标准的神经网络来训练模型，如图(B)所示。784 个值中的每一个都是输入层中的一个节点。但是等等，我们叠加数据的时候不是损失了很多信息吗？是的。<em class="la">图像中的空间和时间关系已被丢弃。这是很大的信息损失。</em>让我们看看卷积自动编码器如何保留空间和时间信息。</p><figure class="lc ld le lf gt ju gh gi paragraph-image"><div class="gh gi mm"><img src="../Images/0ac9eb6c7163dade69a63fc409f7c275.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*ghgPQFpY11Ssx70kkMFyfQ.png"/></div><figcaption class="lh li gj gh gi lj lk bd b be z dk">Figure (B)</figcaption></figure><p id="6b70" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated"><strong class="kd iu">为什么卷积自动编码器适用于图像数据？</strong></p><p id="535b" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">当分割和堆叠数据时，我们看到大量信息丢失。卷积自动编码器不是堆叠数据，而是保持输入图像数据的空间信息不变，并在所谓的<strong class="kd iu">卷积层</strong>中温和地提取信息。图(D)展示了平面 2D 图像被提取到一个厚正方形(Conv1)，然后继续变成一个长立方体(Conv2)和另一个更长的立方体(Conv3)。此过程旨在保留数据中的空间关系。这是自动编码器中的编码过程。在中间，有一个全连接的自动编码器，其隐藏层仅由 10 个神经元组成。接下来是解码过程，使立方变平，然后变成 2D 平面图像。编码器和解码器在图(D)中是对称的。它们不需要对称，但是大多数从业者只是采用了这个规则，如“<a class="ae kz" rel="noopener" target="_blank" href="/anomaly-detection-with-autoencoder-b4cdce4866a6">使用自动编码器的异常检测变得容易</a>”中所解释的。</p><figure class="lc ld le lf gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi mn"><img src="../Images/96b24caff2b92949f34d1a2371c5cf3f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*nEtqhS8KEo39qwqj-MuLsg.png"/></div></div><figcaption class="lh li gj gh gi lj lk bd b be z dk">Figure (D)</figcaption></figure><p id="53e8" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated"><strong class="kd iu">卷积自动编码器如何工作？</strong></p><p id="aae7" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">上面的数据提取看起来很神奇。这是怎么回事？它包括以下三层:卷积层、reLu 层和池层。</p><figure class="lc ld le lf gt ju gh gi paragraph-image"><div class="gh gi mo"><img src="../Images/f92e497fa05682139bc6d11a0208cf9d.png" data-original-src="https://miro.medium.com/v2/resize:fit:798/format:webp/1*hIyvWKj3wKwuV495gFgysA.png"/></div><figcaption class="lh li gj gh gi lj lk bd b be z dk">Figure (E): The Feature Maps</figcaption></figure><ol class=""><li id="7cb4" class="mp mq it kd b ke kf ki kj km mr kq ms ku mt ky mu mv mw mx bi translated"><strong class="kd iu">卷积层</strong></li></ol><p id="b2c1" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">卷积步骤创建了许多称为<em class="la">特征地图</em>或<em class="la">特征</em>的小块，如图(E)中的绿色、红色或深蓝色方块。这些方块保留了输入图像中像素之间的关系。让每个特征扫描原始图像，如图(F)所示。这个产生分数的过程叫做<em class="la">过滤</em>。</p><figure class="lc ld le lf gt ju gh gi paragraph-image"><div class="gh gi my"><img src="../Images/c9edfb17aa91b30c0245c8b37561e176.png" data-original-src="https://miro.medium.com/v2/resize:fit:790/1*3ecOai7S4ah73bBY7Jp4EA.gif"/></div><figcaption class="lh li gj gh gi lj lk bd b be z dk">Figure (F): The Filtering Process</figcaption></figure><p id="fba6" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">在扫描原始图像后，每个特征产生一个如图(G)所示的具有高分和低分的<em class="la">过滤的</em>图像。如果完全匹配，则该方块得分高。如果匹配度低或不匹配，则得分低或为零。例如，红色方块在原始图像中找到了四个与该特征完全匹配的区域，因此这四个区域的得分很高。</p><figure class="lc ld le lf gt ju gh gi paragraph-image"><div class="gh gi mz"><img src="../Images/e24e511e42be99b06dcf0e1a4109c988.png" data-original-src="https://miro.medium.com/v2/resize:fit:560/format:webp/1*cdsUrylVBbPhbTjuMBS6uQ.png"/></div><figcaption class="lh li gj gh gi lj lk bd b be z dk">Figure (G)</figcaption></figure><p id="81bb" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">更多的过滤器意味着模型可以提取更多的特征。然而，更多的功能意味着更长的训练时间。因此建议您使用最少数量的过滤器来提取特征。</p><p id="d9ee" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated"><strong class="kd iu"> 1.1 填充</strong></p><p id="2628" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">特征如何确定匹配？一个超参数是填充，它提供了两个选项:(I)用零填充原始图像以适合该特征，或者(ii)丢弃原始图像中不适合的部分并保留有效部分。</p><p id="47db" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated"><strong class="kd iu"> 1.2 步</strong></p><p id="4b05" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">卷积层包括另一个参数:步幅。它是在输入矩阵上移动的像素数。当跨距为 1 时，滤镜一次移动一个像素。我们将在 Keras 代码中看到它作为一个超参数。</p><p id="d123" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated"><strong class="kd iu"> 2。重新执行步骤</strong></p><p id="135f" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">校正线性单元(ReLU)是与典型神经网络中的步骤相同的步骤。它会将任何负值修正为零，以保证数学运算正确进行。</p><p id="25a3" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated"><strong class="kd iu"> 3。最大池层</strong></p><p id="1ebb" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">池会缩小图像大小。在图(H)中，一个被称为<em class="la">池大小</em>的 2×2 窗口扫描通过每个过滤的图像，并将该 2×2 窗口的最大值分配给新图像中的 1×1 正方形。如图(H)所示，第一个 2 x 2 窗口中的最大值是高分(用红色表示)，因此高分被分配给 1 x 1 正方形。</p><figure class="lc ld le lf gt ju gh gi paragraph-image"><div class="gh gi na"><img src="../Images/bd16cb17af2038a113b6989813ca3636.png" data-original-src="https://miro.medium.com/v2/resize:fit:768/format:webp/1*PnfU8TCMuJ-dl5IoxGkQGA.png"/></div><figcaption class="lh li gj gh gi lj lk bd b be z dk">Figure (H): Max Pooling</figcaption></figure><p id="0ab1" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">除了取最大值，其他不太常用的汇集方法包括平均汇集(取平均值)或总和汇集(总和)。</p><figure class="lc ld le lf gt ju gh gi paragraph-image"><div class="gh gi nb"><img src="../Images/66818889443541d0eef33e3c26ebaba3.png" data-original-src="https://miro.medium.com/v2/resize:fit:198/format:webp/1*hf7JXiTiZjvltkwQ2RvLSA.png"/></div><figcaption class="lh li gj gh gi lj lk bd b be z dk">Figure (J)</figcaption></figure><p id="daaa" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">合并后，会产生一个新的较小的过滤图像堆栈。现在，我们分割较小的过滤图像，并将它们堆叠成一个列表，如图(J)所示。</p><p id="cf0a" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated"><strong class="kd iu">Keras 中的型号</strong></p><p id="64ea" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">以上三层是卷积神经网络的构造块。Keras 提供以下两种功能:</p><ul class=""><li id="e2d1" class="mp mq it kd b ke kf ki kj km mr kq ms ku mt ky nc mv mw mx bi translated"><code class="fe mg mh mi mj b">Conv2D(filters, kernel_size, activation = 'reLu', strides=1)</code>:<code class="fe mg mh mi mj b">kernel_size</code>是 2D 卷积窗的高度和宽度。因为我们在图(E)中使用了一个 2 乘 2 的正方形，所以在我们的例子中，kernel_size 将是(2，2)。<code class="fe mg mh mi mj b">stride</code>是在输入矩阵上移动的像素数。我们的步幅是 1，因为我们一次移动一个像素的过滤器。</li><li id="3e69" class="mp mq it kd b ke nd ki ne km nf kq ng ku nh ky nc mv mw mx bi translated"><code class="fe mg mh mi mj b">MaxPooling2D(pool_size=(2,2))</code>:在图(H)中，我们使用 2 乘 2 的窗口来表示池的大小。所以我们将在下面的代码中使用(2，2)。</li></ul><p id="faad" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">您可以在卷积自动编码器中构建许多卷积层。在图(E)中，编码部分有三层，分别标记为 Conv1、Conv2 和 Conv3。所以我们会相应地建造。</p><ul class=""><li id="356f" class="mp mq it kd b ke kf ki kj km mr kq ms ku mt ky nc mv mw mx bi translated">下面的代码<code class="fe mg mh mi mj b">input_img = Input(shape=(28,28,1)</code>声明输入的 2D 图像是 28 乘 28。</li><li id="fa72" class="mp mq it kd b ke nd ki ne km nf kq ng ku nh ky nc mv mw mx bi translated">然后构建三层 Conv1、Conv2 和 Conv3。</li><li id="386c" class="mp mq it kd b ke nd ki ne km nf kq ng ku nh ky nc mv mw mx bi translated">注意，Conv1 位于 Conv2 内部，Conv2 位于 Conv3 内部。</li><li id="f6af" class="mp mq it kd b ke nd ki ne km nf kq ng ku nh ky nc mv mw mx bi translated"><code class="fe mg mh mi mj b">padding</code>指定当滤波器不适合输入图像时该做什么。<code class="fe mg mh mi mj b">padding='valid'</code>表示当滤镜不适合时，丢弃图像的部分；<code class="fe mg mh mi mj b">padding='same'</code>用零填充图片以适合图片。</li></ul><figure class="lc ld le lf gt ju"><div class="bz fp l di"><div class="me mf l"/></div></figure><p id="38c2" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">然后继续添加解码过程。所以下面的<code class="fe mg mh mi mj b">decoding</code>部分有所有的编码和解码。</p><figure class="lc ld le lf gt ju"><div class="bz fp l di"><div class="me mf l"/></div></figure><p id="9cff" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated"><a class="ae kz" href="https://keras.io/models/model/" rel="noopener ugc nofollow" target="_blank"> Keras API </a>需要声明模型和优化方法:</p><ul class=""><li id="dd93" class="mp mq it kd b ke kf ki kj km mr kq ms ku mt ky nc mv mw mx bi translated"><code class="fe mg mh mi mj b">Model(inputs= input_img,outputs= decoded)</code>:给定输入数据<code class="fe mg mh mi mj b">input_img</code>，模型将包括计算输出<code class="fe mg mh mi mj b">decoded</code>所需的所有层。<code class="fe mg mh mi mj b">compile(optimizer='adadelta',loss='binary_crossentropy')</code>:优化器像梯度下降一样执行优化。最常见的是随机梯度下降(SGD)、适应梯度(Adagrad)和 Adadelta(Adagrad 的扩展)。详见<a class="ae kz" href="https://keras.io/optimizers/" rel="noopener ugc nofollow" target="_blank"> Keras 优化器文档</a>。损失函数可在<a class="ae kz" href="https://keras.io/losses/" rel="noopener ugc nofollow" target="_blank"> Keras 损失文件</a>中找到。</li></ul><figure class="lc ld le lf gt ju"><div class="bz fp l di"><div class="me mf l"/></div></figure><p id="f621" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">下面我使用 x_train 作为输入和输出来训练这个模型。<code class="fe mg mh mi mj b">batch_size</code>是样本数，<code class="fe mg mh mi mj b">epoch</code>是迭代次数。我指定<code class="fe mg mh mi mj b">shuffle=True</code>要求在每个时期之前混洗训练数据。</p><figure class="lc ld le lf gt ju"><div class="bz fp l di"><div class="me mf l"/></div></figure><p id="c70e" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">我们可以打印出前十幅原始图像和对这十幅图像的预测。</p><figure class="lc ld le lf gt ju"><div class="bz fp l di"><div class="me mf l"/></div></figure><figure class="lc ld le lf gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi mk"><img src="../Images/10b9f13d6fb28aa826b8cd4b490d381c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*5xPANmX5-PdC0jAHD1WR_g.png"/></div></div></figure><p id="1ea0" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated"><strong class="kd iu">如何构建图像降噪卷积自动编码器？</strong></p><p id="fc46" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">图像降噪的思想是用噪声数据作为输入，它们各自的清晰数据作为输出来训练模型。这是与上述模型的唯一区别。让我们首先给数据添加噪声。</p><figure class="lc ld le lf gt ju"><div class="bz fp l di"><div class="me mf l"/></div></figure><p id="81a7" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">前十幅有噪声的图像如下所示:</p><figure class="lc ld le lf gt ju"><div class="bz fp l di"><div class="me mf l"/></div></figure><figure class="lc ld le lf gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi ni"><img src="../Images/f2277ebbf6b9fb857fb8f6429fdb786b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ly4_mDH0_rP3b0WiPNJ74g.png"/></div></div></figure><p id="6451" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">然后，我们用有噪声的数据作为输入，干净的数据作为输出来训练模型。</p><figure class="lc ld le lf gt ju"><div class="bz fp l di"><div class="me mf l"/></div></figure><p id="1fc2" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">最后，我们打印出前十个噪声图像以及相应的去噪声图像。</p><figure class="lc ld le lf gt ju"><div class="bz fp l di"><div class="me mf l"/></div></figure><figure class="lc ld le lf gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi nj"><img src="../Images/b7d44eb78fa4035b5fd7fa0113a7ba4e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*b-1dhN29CmLYKrRf5MhZGg.png"/></div></div></figure><p id="78a8" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">笔记本可以通过<a class="ae kz" href="https://github.com/dataman-git/codes_for_articles/blob/master/Keras%20MNIST.ipynb" rel="noopener ugc nofollow" target="_blank">这个 Github 链接</a>获得。</p><p id="0eff" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated"><strong class="kd iu">有没有我可以使用的预先训练好的 CNN 代码？</strong></p><p id="ab3a" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">是的。如果你有兴趣学习代码，<a class="ae kz" href="https://keras.io/applications/" rel="noopener ugc nofollow" target="_blank"> Keras 有几个预先训练好的 CNN</a>，包括<a class="ae kz" href="https://keras.io/applications/#xception" rel="noopener ugc nofollow" target="_blank"> Xception </a>、<a class="ae kz" href="https://keras.io/applications/#vgg16" rel="noopener ugc nofollow" target="_blank"> VGG16 </a>、<a class="ae kz" href="https://keras.io/applications/#vgg19" rel="noopener ugc nofollow" target="_blank"> VGG19 </a>、<a class="ae kz" href="https://keras.io/applications/#resnet50" rel="noopener ugc nofollow" target="_blank"> ResNet50 </a>、<a class="ae kz" href="https://keras.io/applications/#inceptionv3" rel="noopener ugc nofollow" target="_blank"> InceptionV3 </a>、<a class="ae kz" href="https://keras.io/applications/#inceptionresnetv2" rel="noopener ugc nofollow" target="_blank"> InceptionResNetV2 </a>、<a class="ae kz" href="https://keras.io/applications/#mobilenet" rel="noopener ugc nofollow" target="_blank"> MobileNet </a>、<a class="ae kz" href="https://keras.io/applications/#densenet" rel="noopener ugc nofollow" target="_blank"> DenseNet </a>、<a class="ae kz" href="https://keras.io/applications/#nasnet" rel="noopener ugc nofollow" target="_blank">值得一提的是这个大型图像数据库</a><a class="ae kz" href="http://www.image-net.org/" rel="noopener ugc nofollow" target="_blank"> ImageNet </a>，你可以贡献或下载用于研究目的。</p></div><div class="ab cl nk nl hx nm" role="separator"><span class="nn bw bk no np nq"/><span class="nn bw bk no np nq"/><span class="nn bw bk no np"/></div><div class="im in io ip iq"><div class="lc ld le lf gt lp"><a href="https://dataman-ai.medium.com/membership" rel="noopener follow" target="_blank"><div class="lq ab fo"><div class="lr ab ls cl cj lt"><h2 class="bd iu gy z fp lu fr fs lv fu fw is bi translated">通过我的推荐链接加入 Medium-Chris Kuo/data man 博士</h2><div class="lw l"><h3 class="bd b gy z fp lu fr fs lv fu fw dk translated">阅读 Chris Kuo/data man 博士的每一个故事。你的会员费直接支持郭怡广/戴塔曼博士和其他…</h3></div><div class="lx l"><p class="bd b dl z fp lu fr fs lv fu fw dk translated">dataman-ai.medium.com</p></div></div><div class="ly l"><div class="lz l ma mb mc ly md jz lp"/></div></div></a></div></div></div>    
</body>
</html>