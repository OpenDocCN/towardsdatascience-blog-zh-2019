<html>
<head>
<title>Real time car/pedestrian/lane detection using Tensorflow object detection API and an iOS integration example</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用 Tensorflow 对象检测 API 和 iOS 集成示例进行实时汽车/行人/车道检测</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/real-time-car-pedestrian-lane-detection-using-tensorflow-object-detection-api-and-an-ios-fbb1b7cbb157?source=collection_archive---------5-----------------------#2019-04-26">https://towardsdatascience.com/real-time-car-pedestrian-lane-detection-using-tensorflow-object-detection-api-and-an-ios-fbb1b7cbb157?source=collection_archive---------5-----------------------#2019-04-26</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><figure class="gl gn jo jp jq jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi jn"><img src="../Images/404e20d48b4947930de4d8b8ac15bf2d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*z7v5Uzk6Y4RS1v_Ff6x1SA.png"/></div></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk">Prediction with mPA &gt; 80% using ssd_mobilenet_v1_pets.config with pretrained ssd_mobilenet_v1_coco_2018_01_28 nets</figcaption></figure><figure class="kd ke kf kg gt jr gh gi paragraph-image"><div class="gh gi kc"><img src="../Images/2c39af4c364fdaa7d3d8f85919d5f333.png" data-original-src="https://miro.medium.com/v2/resize:fit:1364/format:webp/1*xp6cBgtkvCWSUcMv5ln8mA.png"/></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk">Total Loss decrease with respect of optimization steps. 100 training photos and 20 testing photos. Better results can be achieved with more data.</figcaption></figure></div><div class="ab cl kh ki hu kj" role="separator"><span class="kk bw bk kl km kn"/><span class="kk bw bk kl km kn"/><span class="kk bw bk kl km"/></div><div class="ij ik il im in"><p id="44e8" class="pw-post-body-paragraph ko kp iq kq b kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">受到其他人在异议检测项目上的工作的启发，例如</p><ol class=""><li id="0d72" class="lm ln iq kq b kr ks kv kw kz lo ld lp lh lq ll lr ls lt lu bi translated"><a class="ae lv" rel="noopener" target="_blank" href="/how-to-train-your-own-object-detector-with-tensorflows-object-detector-api-bec72ecfe1d9">如何使用 TensorFlow 的对象检测器 API </a>训练您自己的对象检测器，它演示了如何使用 Tensorflow 的 API 来构建和训练用于对象检测的定制 DL 网络。</li><li id="4fff" class="lm ln iq kq b kr lw kv lx kz ly ld lz lh ma ll lr ls lt lu bi translated"><a class="ae lv" href="https://medium.com/@junjiwatanabe/how-to-build-real-time-object-recognition-ios-app-ca85c193865a" rel="noopener">如何构建实时物体识别 iOS app </a>，演示了如何将一个经过训练的 DL net 集成到 iOS app 中。</li></ol><p id="c423" class="pw-post-body-paragraph ko kp iq kq b kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">然后，我真的很想尝试如何使用类似的程序来建立自己的网络，在 iOS 的实时摄像头中检测汽车/行人/自行车(+车道)。结合我之前关于<a class="ae lv" href="https://medium.com/@wtlove876/adaptive-cruise-control-with-sensor-fusion-within-matlab-simulink-294aeb24e6e0" rel="noopener">自适应巡航控制</a>的帖子，集成的功能应该真的很有意思。</p><p id="b320" class="pw-post-body-paragraph ko kp iq kq b kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">在我进一步谈论技术细节之前，为了节省你的时间，使用的软件版本必须放在最前面。我在使用 Xcode 7.3 版本的 macOS EI Capitan 时遇到了一些问题，所以在我的尝试中，我不得不将我的系统更新到 Xcode 10.2 版本的 Moyawe。主要问题是我尝试<a class="ae lv" href="http://How to build real-time object recognition iOS app, which demonstrates how integrate a trained DL net into iOS" rel="noopener ugc nofollow" target="_blank">例 2 </a>的例子时，我 iphone 8 上安装的 app 一直碾压。</p><p id="d704" class="pw-post-body-paragraph ko kp iq kq b kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">Tensorflow 是使用 pip 虚拟环境 1.9.0 版安装的。在我使用 1.8 之前，问题是当我试图冻结用于 iOS 检测 app 的训练图时，它总是失败，并出现错误“non_max_suppression()”。</p><p id="26fd" class="pw-post-body-paragraph ko kp iq kq b kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">根据这篇<a class="ae lv" href="https://github.com/csharpseattle/tensorflowiOS" rel="noopener ugc nofollow" target="_blank">帖子</a>，tensor flow for iOS 版本为 v1.11。我也安装了最新版本，但是<a class="ae lv" href="http://How to build real-time object recognition iOS app, which demonstrates how integrate a trained DL net into iOS" rel="noopener ugc nofollow" target="_blank">例 2 </a>中的代码无法成功编译。因为我想将周围的框添加到检测到的项目中，所以我必须回到 1.11 版。</p><p id="fdd6" class="pw-post-body-paragraph ko kp iq kq b kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">如果你想知道更多的细节，请在下面评论，我会试着分享更多我的经验。</p><h1 id="327d" class="mb mc iq bd md me mf mg mh mi mj mk ml mm mn mo mp mq mr ms mt mu mv mw mx my bi translated">图片报和培训网</h1><ol class=""><li id="760d" class="lm ln iq kq b kr mz kv na kz nb ld nc lh nd ll lr ls lt lu bi translated">正在准备输入 TFRecord 文件</li></ol><p id="fe5d" class="pw-post-body-paragraph ko kp iq kq b kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">首先，我从<a class="ae lv" href="http://cbcl.mit.edu/software-datasets/streetscenes/" rel="noopener ugc nofollow" target="_blank">这里</a>得到合适的数据集。只使用了 120 张图片，100 张用于训练，20 张用于测试。记录的街道快照用于训练。然后我用 labelImg 来标记物体。我的标注地图包含三个项目，如下所示</p><figure class="kd ke kf kg gt jr gh gi paragraph-image"><div class="gh gi ne"><img src="../Images/283c3be3a5b2793fc553521c532bc4bc.png" data-original-src="https://miro.medium.com/v2/resize:fit:648/format:webp/1*2skNrVmt_OgNcWVXWvtUjg.png"/></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk">My model contains three items: car, pedestrian and bike</figcaption></figure><p id="d432" class="pw-post-body-paragraph ko kp iq kq b kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">手动给物品贴标签既无聊又对眼睛有害。所以我建议你使用一些聪明的方法来这样做，比如使用一些<a class="ae lv" href="https://github.com/opencv/cvat" rel="noopener ugc nofollow" target="_blank">自动注释工具</a>。实际上，这种注释过程也与使用机器学习(ML)技术的对象检测/分割/分类的主题相关。如果我有时间，我会写另一个关于它的故事。</p><p id="fa81" class="pw-post-body-paragraph ko kp iq kq b kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">在对来自 100 张训练图片和 20 张测试图片的对象进行人工标记之后，对象在 2D 图片中的位置被保存为 xml 格式。然后，我使用以下两个步骤来获得 TFRecord 格式，它将被直接提供给 TF 训练过程。使用的代码可以从我的 github 下载。有些文件是来自<a class="ae lv" href="https://towardsdatascience.com/@datitran" rel="noopener" target="_blank"> Dat Tran </a>的 github 库的令牌。</p><p id="0a00" class="pw-post-body-paragraph ko kp iq kq b kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated"><em class="nf">转换图片+xml = &gt; TFRecord 文件</em></p><ul class=""><li id="b6a8" class="lm ln iq kq b kr ks kv kw kz lo ld lp lh lq ll ng ls lt lu bi translated">为每个数据集将单独的<code class="fe nh ni nj nk b">*.xml</code>文件转换为统一的<code class="fe nh ni nj nk b">*.csv</code>文件。</li><li id="abc1" class="lm ln iq kq b kr lw kv lx kz ly ld lz lh ma ll ng ls lt lu bi translated">将每个数据集的<code class="fe nh ni nj nk b">*.csv</code>文件转换为<code class="fe nh ni nj nk b">*.record</code>文件(TFRecord 格式)。</li></ul><p id="27db" class="pw-post-body-paragraph ko kp iq kq b kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">2.设置培训配置</p><p id="bb2c" class="pw-post-body-paragraph ko kp iq kq b kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">我目前的目的不是从头构建一个新的网络，而是演示获得定制工作网络的过程。然后我用 TF 发布的 github 的预建配置<a class="ae lv" href="https://github.com/tensorflow/models/tree/master/research/object_detection/samples/configs" rel="noopener ugc nofollow" target="_blank">SSD _ mobilenet _ v1 _ pets . config</a>。不是从一个完全随机的初始化模型开始，而是采用了一个预先训练好的模型，<a class="ae lv" href="https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/detection_model_zoo.md" rel="noopener ugc nofollow" target="_blank">SSD _ mobilenet _ v1 _ coco _ 2018 _ 01 _ 28</a>，以加快训练过程，就像 TF 官网上建议的那样。然后，一些相应的参数设置如下</p><ul class=""><li id="7196" class="lm ln iq kq b kr ks kv kw kz lo ld lp lh lq ll ng ls lt lu bi translated">num_classes: 3 <em class="nf"> #设置不同标签类别的数量</em></li><li id="665f" class="lm ln iq kq b kr lw kv lx kz ly ld lz lh ma ll ng ls lt lu bi translated">键入:' ssd_mobilenet_v1' <em class="nf"> #设置为您选择的预训练模型的名称</em></li><li id="6ca4" class="lm ln iq kq b kr lw kv lx kz ly ld lz lh ma ll ng ls lt lu bi translated">fine _ tune _ check point:" pre-trained-model/model . ckpt "<em class="nf">#预训练模型提取文件路径</em></li><li id="d294" class="lm ln iq kq b kr lw kv lx kz ly ld lz lh ma ll ng ls lt lu bi translated">TF _ record _ input _ reader {<br/>input _ Path:" annotations/train . record "<em class="nf">#第一步训练 TFRecord 文件的路径</em><br/>}<br/>label _ map _ Path:" annotations/label _ map . Pb txt "<em class="nf">#标注地图文件的路径如前</em>所示</li><li id="262c" class="lm ln iq kq b kr lw kv lx kz ly ld lz lh ma ll ng ls lt lu bi translated">TF _ record _ input _ reader {<br/>input _ Path:" annotations/test . record "<em class="nf">#测试 TFRecord 的路径</em><br/>}<br/>label _ map _ Path:" annotations/label _ map . Pb txt "<em class="nf">#标签映射文件的路径</em></li></ul><p id="99df" class="pw-post-body-paragraph ko kp iq kq b kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">3.TF 培训流程</p><p id="c627" class="pw-post-body-paragraph ko kp iq kq b kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">使用以下命令进行训练过程(注意:—必须用两个减号(-)替换)</p><blockquote class="nl nm nn"><p id="f39f" class="ko kp nf kq b kr ks kt ku kv kw kx ky no la lb lc np le lf lg nq li lj lk ll ij bi translated">python train . py-logtostderr-train _ dir =。/training/—pipeline _ config _ path =。/training/SSD _ mobilenet _ v1 _ pets . config</p></blockquote><figure class="kd ke kf kg gt jr gh gi paragraph-image"><div class="gh gi nr"><img src="../Images/e78b72a2a1c5e1d4bdb3ab343ee3ce87.png" data-original-src="https://miro.medium.com/v2/resize:fit:960/format:webp/1*X5KxP3NizamveAlftUnsQA.png"/></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk">Configuration of my laptop</figcaption></figure><p id="de1f" class="pw-post-body-paragraph ko kp iq kq b kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">如果遇到一些错误，首先检查输入数据路径和 tensorflow 的版本。训练过程应该持续很长时间。我的训练是在我自己的笔记本电脑上进行的，花了大约 20 个小时/8k 步。通过调查损失，我终止了它，形成了一个用于 iOS 集成的次优模型。对于更精确的模型，必须使用更多的输入图片。训练过程也可以像<a class="ae lv" href="https://towardsdatascience.com/@datitran" rel="noopener" target="_blank"> Dat Tran </a>所做的那样从云中运行。</p><p id="b463" class="pw-post-body-paragraph ko kp iq kq b kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">4.训练数据观察和可视化</p><p id="bed6" class="pw-post-body-paragraph ko kp iq kq b kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">Tensorboard 用于即时可视化培训，使用</p><blockquote class="nl nm nn"><p id="5ef7" class="ko kp nf kq b kr ks kt ku kv kw kx ky no la lb lc np le lf lg nq li lj lk ll ij bi translated"><em class="iq">tensor board—logdir[你的日志目录] — host=127.0.0.1 </em></p></blockquote><p id="3db9" class="pw-post-body-paragraph ko kp iq kq b kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">如果你遇到关于 LC_ALL 的问题，使用下面的命令并重新运行 tensorboard</p><blockquote class="nl nm nn"><p id="5ab3" class="ko kp nf kq b kr ks kt ku kv kw kx ky no la lb lc np le lf lg nq li lj lk ll ij bi translated">export LC_ALL="en_US。UTF-8”</p><p id="0d10" class="ko kp nf kq b kr ks kt ku kv kw kx ky no la lb lc np le lf lg nq li lj lk ll ij bi translated">导出 LC_CTYPE="en_US。UTF-8”</p></blockquote><p id="e803" class="pw-post-body-paragraph ko kp iq kq b kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">根据来自终端的弹出信息执行以下操作。因为我对损失很满意，所以我终止了训练并提取了图形。</p><p id="b270" class="pw-post-body-paragraph ko kp iq kq b kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">5.提取/冻结图表</p><blockquote class="nl nm nn"><p id="704e" class="ko kp nf kq b kr ks kt ku kv kw kx ky no la lb lc np le lf lg nq li lj lk ll ij bi translated">输入类型=图像张量</p><p id="1f70" class="ko kp nf kq b kr ks kt ku kv kw kx ky no la lb lc np le lf lg nq li lj lk ll ij bi translated">管道配置路径=。/training/SSD _ mobilenet _ v1 _ pets . config</p><p id="e4d7" class="ko kp nf kq b kr ks kt ku kv kw kx ky no la lb lc np le lf lg nq li lj lk ll ij bi translated">特训 _ CKPT _ 前缀=。/training/model.ckpt-7265</p><p id="0615" class="ko kp nf kq b kr ks kt ku kv kw kx ky no la lb lc np le lf lg nq li lj lk ll ij bi translated">EXPORT_DIR=。/frozen_inference_graph</p><p id="ac93" class="ko kp nf kq b kr ks kt ku kv kw kx ky no la lb lc np le lf lg nq li lj lk ll ij bi translated">python ~/tensor flow/models/research/object _ detection/EXPORT _ inference _ graph . py-INPUT _ TYPE = $ { INPUT _ TYPE }-PIPELINE _ CONFIG _ PATH = $ { PIPELINE _ CONFIG _ PATH }-TRAINED _ check point _ PREFIX = $ { TRAINED _ CKPT _ PREFIX }-output _ directory = $ { EXPORT _ DIR }</p></blockquote><p id="bc11" class="pw-post-body-paragraph ko kp iq kq b kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">如果你遇到<strong class="kq ir"><em class="nf">【non _ max _ suppression()】</em></strong>的问题，尝试使用 TF v1.9.0</p></div><div class="ab cl kh ki hu kj" role="separator"><span class="kk bw bk kl km kn"/><span class="kk bw bk kl km kn"/><span class="kk bw bk kl km"/></div><div class="ij ik il im in"><h1 id="5e44" class="mb mc iq bd md me ns mg mh mi nt mk ml mm nu mo mp mq nv ms mt mu nw mw mx my bi translated">构建 iOS 应用程序</h1><p id="242c" class="pw-post-body-paragraph ko kp iq kq b kr mz kt ku kv na kx ky kz nx lb lc ld ny lf lg lh nz lj lk ll ij bi translated">直到现在我有了自己定制的训练图，然后我按照<a class="ae lv" href="https://medium.com/@junjiwatanabe/how-to-build-real-time-object-recognition-ios-app-ca85c193865a" rel="noopener">这篇文章</a>的步骤开发一个测试 iOS 应用。没有什么特别的事情发生，但是错误信息可能会再次出现。也看看这个<a class="ae lv" href="https://github.com/csharpseattle/tensorflowiOS" rel="noopener ugc nofollow" target="_blank"> github 帖子</a>，可能会有帮助。由于代码使用了 iphone 的后置摄像头，所以它不能正确地简单运行 Xcode 内的模拟器。应该特别注意一些设置，尤其是头文件和库的搜索和链接路径。其他技术细节可以从 ios 的<a class="ae lv" href="https://github.com/tensorflow/tensorflow/tree/master/tensorflow/examples/ios" rel="noopener ugc nofollow" target="_blank"> tensorflow 官方网站上查看。</a></p></div><div class="ab cl kh ki hu kj" role="separator"><span class="kk bw bk kl km kn"/><span class="kk bw bk kl km kn"/><span class="kk bw bk kl km"/></div><div class="ij ik il im in"><figure class="kd ke kf kg gt jr"><div class="bz fp l di"><div class="oa ob l"/></div></figure><p id="37eb" class="pw-post-body-paragraph ko kp iq kq b kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">我的 iOS 应用程序的最终实现示例，不完美，但足够好，可以更进一步。</p><h1 id="a787" class="mb mc iq bd md me mf mg mh mi mj mk ml mm mn mo mp mq mr ms mt mu mv mw mx my bi translated">未完待续…</h1><ol class=""><li id="4085" class="lm ln iq kq b kr mz kv na kz nb ld nc lh nd ll lr ls lt lu bi translated">车道检测</li><li id="b530" class="lm ln iq kq b kr lw kv lx kz ly ld lz lh ma ll lr ls lt lu bi translated">网速快一点的，试试 yolo net，不然对一个高速条件没用。</li><li id="59a4" class="lm ln iq kq b kr lw kv lx kz ly ld lz lh ma ll lr ls lt lu bi translated">距离计算</li></ol></div></div>    
</body>
</html>