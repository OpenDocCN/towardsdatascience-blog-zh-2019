<html>
<head>
<title>Simple and multiple linear regression with Python</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用 Python 进行简单和多元线性回归</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/simple-and-multiple-linear-regression-with-python-c9ab422ec29c?source=collection_archive---------1-----------------------#2019-07-27">https://towardsdatascience.com/simple-and-multiple-linear-regression-with-python-c9ab422ec29c?source=collection_archive---------1-----------------------#2019-07-27</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><figure class="gl gn jr js jt ju gh gi paragraph-image"><div class="gh gi jq"><img src="../Images/6514af2318160fad15e64ff95de018b2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1082/format:webp/1*Pc8EZljAb4X5IGyLd_Jvdw.png"/></div></figure><p id="ddf1" class="pw-post-body-paragraph jx jy it jz b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku im bi translated"><strong class="jz iu">线性回归</strong>是对单个<strong class="jz iu">因变量</strong>(目标变量)和一个(简单回归)或多个(多元回归)<strong class="jz iu">自变量</strong>之间的关系进行建模的方法。线性回归模型假设输入和输出变量之间存在线性关系。如果存在这种关系，我们就可以估计模型对新数据进行预测所需的系数。</p><p id="fc36" class="pw-post-body-paragraph jx jy it jz b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku im bi translated">在本文中，您将学习如何使用多个库，如<strong class="jz iu"> Pandas </strong>、<strong class="jz iu"> Numpy </strong>、<strong class="jz iu"> Scikit-Learn </strong>、<strong class="jz iu">、</strong>和<strong class="jz iu"> Scipy </strong>，从零开始在<strong class="jz iu"> Python </strong>中可视化和实现<strong class="jz iu">线性回归算法</strong>。此外，我们将使用<strong class="jz iu">皮尔森</strong> <strong class="jz iu">相关系数</strong>来衡量两个变量之间线性关系的方向和强度，以及使用<strong class="jz iu">均方差</strong>等评估指标来衡量线性回归模型的预测精度。</p><p id="6cf2" class="pw-post-body-paragraph jx jy it jz b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku im bi translated">现在！我们开始吧💜</p><h1 id="e1cd" class="kv kw it bd kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls bi translated">数据集的分析</h1><p id="6090" class="pw-post-body-paragraph jx jy it jz b ka lt kc kd ke lu kg kh ki lv kk kl km lw ko kp kq lx ks kt ku im bi translated">本文使用的<strong class="jz iu">数据集</strong>是在<a class="ae ly" href="https://www.kaggle.com/" rel="noopener ugc nofollow" target="_blank"> <strong class="jz iu"> Kaggle </strong> </a>中获取的。<a class="ae ly" href="https://www.kaggle.com/" rel="noopener ugc nofollow" target="_blank"> <strong class="jz iu"> Kaggle </strong> </a>是一个数据科学家和机器学习者的在线社区，在这里可以找到各种各样的<strong class="jz iu">数据集</strong>。所选的<strong class="jz iu">数据集</strong>包含 5000 名男性和 5000 名女性的身高和体重，可通过以下链接下载:</p><div class="lz ma gp gr mb mc"><a href="https://www.kaggle.com/mustafaali96/weight-height/downloads/weight-height.zip/1" rel="noopener  ugc nofollow" target="_blank"><div class="md ab fo"><div class="me ab mf cl cj mg"><h2 class="bd iu gy z fp mh fr fs mi fu fw is bi translated">你的数据科学之家</h2><div class="mj l"><h3 class="bd b gy z fp mh fr fs mi fu fw dk translated">编辑描述</h3></div><div class="mk l"><p class="bd b dl z fp mh fr fs mi fu fw dk translated">www.kaggle.com</p></div></div></div></a></div><p id="2aa9" class="pw-post-body-paragraph jx jy it jz b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku im bi translated">第一步是使用<a class="ae ly" href="https://pandas.pydata.org/" rel="noopener ugc nofollow" target="_blank"> <strong class="jz iu">熊猫</strong> </a>导入数据集。<a class="ae ly" href="https://pandas.pydata.org/" rel="noopener ugc nofollow" target="_blank"> <strong class="jz iu"> Pandas </strong> </a>是一个用于<strong class="jz iu">数据科学</strong>的<strong class="jz iu"> Python </strong>开源库，允许我们轻松处理结构化数据，如<strong class="jz iu"> csv 文件</strong>、<strong class="jz iu"> SQL 表</strong>或<strong class="jz iu"> Excel 电子表格</strong>。导入 csv 文件后，我们可以打印数据集的前五行、每列的数据类型以及空值的数量。</p><figure class="ml mm mn mo gt ju"><div class="bz fp l di"><div class="mp mq l"/></div></figure><figure class="ml mm mn mo gt ju gh gi paragraph-image"><div class="gh gi mr"><img src="../Images/6e41e1ed5a767302b23db28da69e8684.png" data-original-src="https://miro.medium.com/v2/resize:fit:452/format:webp/1*sY83jI-hTmHgtODYGw4VQg.png"/></div></figure><figure class="ml mm mn mo gt ju"><div class="bz fp l di"><div class="mp mq l"/></div></figure><figure class="ml mm mn mo gt ju gh gi paragraph-image"><div class="gh gi ms"><img src="../Images/d1702e2f01b21745cd29f44dbab34708.png" data-original-src="https://miro.medium.com/v2/resize:fit:616/format:webp/1*J2KNg1QFFca1qCKWl8o4Rg.png"/></div></figure><figure class="ml mm mn mo gt ju"><div class="bz fp l di"><div class="mp mq l"/></div></figure><p id="5f05" class="pw-post-body-paragraph jx jy it jz b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku im bi translated">正如我们可以很容易地观察到的那样，<strong class="jz iu">数据帧</strong>包含三列:性别、身高和体重。性别列包含 object 类型的两个唯一值:男性或女性。高度和重量列中使用了浮点数据类型。由于<strong class="jz iu">数据帧</strong>不包含空值，并且数据类型是预期的类型，因此没有必要清理数据。</p><p id="93a1" class="pw-post-body-paragraph jx jy it jz b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku im bi translated">为了更好地理解身高和体重这两个变量的分布，我们可以简单地用直方图来描述这两个变量。<strong class="jz iu">直方图</strong>是显示数字变量分布的图表，将数据分组到多个条块中。条形的高度代表每个箱的观察数量。</p><figure class="ml mm mn mo gt ju"><div class="bz fp l di"><div class="mp mq l"/></div></figure><figure class="ml mm mn mo gt ju gh gi paragraph-image"><div class="gh gi mt"><img src="../Images/c8349318209b52c63a3a051b8c7e0649.png" data-original-src="https://miro.medium.com/v2/resize:fit:1260/format:webp/1*DY2WUoaEJS_U2X5rpLdT4A.png"/></div></figure><figure class="ml mm mn mo gt ju gh gi paragraph-image"><div class="gh gi mt"><img src="../Images/a6c9f1b3dbe91251a6ffec4e0bc5a5fe.png" data-original-src="https://miro.medium.com/v2/resize:fit:1260/format:webp/1*sQJjZePGmYq4knZZsHOjDA.png"/></div></figure><p id="6beb" class="pw-post-body-paragraph jx jy it jz b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku im bi translated">前面的图表显示，身高和体重这两个变量呈现出<strong class="jz iu">正态分布</strong>。作为我们<strong class="jz iu">探索性分析</strong>的一部分，在单独的<strong class="jz iu">直方图</strong>中绘制男性和女性的分布也是很有趣的。</p><figure class="ml mm mn mo gt ju"><div class="bz fp l di"><div class="mp mq l"/></div></figure><figure class="ml mm mn mo gt ju gh gi paragraph-image"><div class="gh gi mt"><img src="../Images/bb490ad85f0f352aee26205cd8649b44.png" data-original-src="https://miro.medium.com/v2/resize:fit:1260/format:webp/1*Y1oIpbthiSPUgerKAk2_HQ.png"/></div></figure><figure class="ml mm mn mo gt ju"><div class="bz fp l di"><div class="mp mq l"/></div></figure><figure class="ml mm mn mo gt ju gh gi paragraph-image"><div class="gh gi mt"><img src="../Images/e6900ff6431b98a686861dc4d23fce13.png" data-original-src="https://miro.medium.com/v2/resize:fit:1260/format:webp/1*bo9wkmyPkXnEVJu32KkZBw.png"/></div></figure><p id="72e2" class="pw-post-body-paragraph jx jy it jz b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku im bi translated">前面的图显示，男性和女性的身高和体重都呈现出<strong class="jz iu">正态分布</strong>。虽然两种分布的平均值<strong class="jz iu">对于男性来说更大，但是<strong class="jz iu">两种性别的分布范围</strong>是相似的。<strong class="jz iu"> Pandas </strong>提供了一个名为<strong class="jz iu"> describe </strong>的方法，用于生成数据集的描述性统计数据(集中趋势、分散和形状)。</strong></p><figure class="ml mm mn mo gt ju"><div class="bz fp l di"><div class="mp mq l"/></div></figure><figure class="ml mm mn mo gt ju gh gi paragraph-image"><div class="gh gi mu"><img src="../Images/08dd74d579efc1d9270b19769b7835f0.png" data-original-src="https://miro.medium.com/v2/resize:fit:844/format:webp/1*AQ-0VW2z_uJ6zMK14O_ojw.png"/></div></figure><p id="5d67" class="pw-post-body-paragraph jx jy it jz b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku im bi translated"><strong class="jz iu">探索性数据分析</strong>包括分析数据集的主要特征，通常采用<strong class="jz iu">可视化方法</strong>和<strong class="jz iu">汇总统计</strong>。目标是理解数据，发现模式和异常，并在我们执行进一步评估之前检查假设。经过探索性分析，我们可以得出结论:身高和体重是正态分布。男性分布呈现出较大的平均值，但是与女性分布相比，分布的扩散确实是相似的。</p><p id="923a" class="pw-post-body-paragraph jx jy it jz b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku im bi translated">但也许此时你会问自己:身高和体重有关系吗？我可以用一个人的身高来预测他的体重吗？</p><p id="9ff2" class="pw-post-body-paragraph jx jy it jz b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku im bi translated">两个问题的答案都是肯定的！😃 💪让我们继续▶️ ▶️</p><h1 id="7dd1" class="kv kw it bd kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls bi translated">使用 Matplotlib 的散点图和使用 Numpy 的线性回归</h1><p id="6d0c" class="pw-post-body-paragraph jx jy it jz b ka lt kc kd ke lu kg kh ki lv kk kl km lw ko kp kq lx ks kt ku im bi translated"><strong class="jz iu">散点图</strong>是一种二维数据可视化，显示两个数值变量之间的关系——一个沿 x 轴绘制，另一个沿 y 轴绘制。<a class="ae ly" href="https://matplotlib.org/" rel="noopener ugc nofollow" target="_blank"> <strong class="jz iu"> Matplotlib </strong> </a>是一个 Python 2D 绘图库，包含一个内置函数来创建散点图<strong class="jz iu">Matplotlib . py plot . scatter()</strong>函数。</p><p id="d23a" class="pw-post-body-paragraph jx jy it jz b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku im bi translated">下图显示了男性和女性的身高和体重之间的关系。可视化包含 10000 个观察结果，这就是为什么我们观察到<strong class="jz iu">过度绘制</strong>。<strong class="jz iu">当数据在可视化中重叠时，会出现过度绘制</strong>，使得难以可视化单个数据点。在这种情况下，原因是大量的数据点(5000 个男性和 5000 个女性)。另一个原因可能是少量的唯一值；例如，当散点图的一个变量是离散变量时。</p><figure class="ml mm mn mo gt ju"><div class="bz fp l di"><div class="mp mq l"/></div></figure><figure class="ml mm mn mo gt ju gh gi paragraph-image"><div class="gh gi mv"><img src="../Images/b30b60590bca841badcb44777543ad22.png" data-original-src="https://miro.medium.com/v2/resize:fit:1246/format:webp/1*Lye8k2CESCAsyuHUpgSZ_A.png"/></div></figure><p id="79d4" class="pw-post-body-paragraph jx jy it jz b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku im bi translated">在下面的图中，我们随机选取了 500 名女性的身高和体重。该图没有<strong class="jz iu">过度绘制</strong>，我们可以更好地区分各个数据点。正如我们在前面的图中所观察到的，雄性和雌性的体重随着身高的增加而增加，在两种情况下都显示出线性关系。</p><figure class="ml mm mn mo gt ju"><div class="bz fp l di"><div class="mp mq l"/></div></figure><figure class="ml mm mn mo gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="mx my di mz bf na"><div class="gh gi mw"><img src="../Images/2d854d59a507efa598ae40440de10362.png" data-original-src="https://miro.medium.com/v2/resize:fit:1354/format:webp/1*oddhrnjqoxWx5e2YbALWcg.png"/></div></div></figure><p id="8c7d" class="pw-post-body-paragraph jx jy it jz b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku im bi translated"><strong class="jz iu">简单线性回归</strong>是一种对<strong class="jz iu">因变量</strong>和<strong class="jz iu">自变量</strong>之间的关系进行建模的线性方法，可获得最符合数据的直线。</p><blockquote class="nb"><p id="41be" class="nc nd it bd ne nf ng nh ni nj nk ku dk translated">y =a+bx</p></blockquote><p id="b00e" class="pw-post-body-paragraph jx jy it jz b ka nl kc kd ke nm kg kh ki nn kk kl km no ko kp kq np ks kt ku im bi translated">其中<strong class="jz iu"> x </strong>为<strong class="jz iu">自变量</strong>(身高)<strong class="jz iu"> y </strong>为<strong class="jz iu">因变量</strong>(体重)<strong class="jz iu"> b </strong>为<strong class="jz iu">斜率</strong>，<strong class="jz iu"> a </strong>为<strong class="jz iu">截距。</strong><strong class="jz iu">截距</strong>表示 x 为 0 时 y 的值，而<strong class="jz iu">斜率</strong>表示直线的陡度。目标是获得最符合我们数据的线(<strong class="jz iu">最小化误差平方和的线</strong>)。误差是实际值<strong class="jz iu"> y </strong>和预测值<strong class="jz iu"> y_hat </strong>之间的差值，预测值是使用计算的线性方程得到的值。</p><blockquote class="nb"><p id="07aa" class="nc nd it bd ne nf ng nh ni nj nk ku dk translated">误差= y(真实)-y(预测)= y(真实)-(a+bx)</p></blockquote><p id="5180" class="pw-post-body-paragraph jx jy it jz b ka nl kc kd ke nm kg kh ki nn kk kl km no ko kp kq np ks kt ku im bi translated">使用<a class="ae ly" href="https://numpy.org/" rel="noopener ugc nofollow" target="_blank"> <strong class="jz iu"> Numpy </strong> </a>我们很容易得到这条线。<a class="ae ly" href="https://numpy.org/" rel="noopener ugc nofollow" target="_blank"> <strong class="jz iu"> Numpy </strong> </a>是一个用于科学计算的 python 包，它提供了高性能的多维数组对象。numpy 函数 polyfit <a class="ae ly" href="https://docs.scipy.org/doc/numpy/reference/generated/numpy.polyfit.html" rel="noopener ugc nofollow" target="_blank"> <strong class="jz iu"> numpy.polyfit(x，y，deg) </strong> </a>将一个次数为<em class="nq"> deg </em>的多项式拟合到点<em class="nq"> (x，y)，</em>返回最小化平方误差的多项式系数。在下面几行代码中，我们获得了预测女性和男性体重的多项式。</p><figure class="ml mm mn mo gt ju"><div class="bz fp l di"><div class="mp mq l"/></div></figure><p id="b6d1" class="pw-post-body-paragraph jx jy it jz b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku im bi translated">下图描述了散点图以及之前的回归线。</p><figure class="ml mm mn mo gt ju"><div class="bz fp l di"><div class="mp mq l"/></div></figure><figure class="ml mm mn mo gt ju gh gi paragraph-image"><div class="gh gi mv"><img src="../Images/6db8f50394734b9726524291c5c682da.png" data-original-src="https://miro.medium.com/v2/resize:fit:1246/format:webp/1*YZnxaoduGntH1iE5wCxrew.png"/></div></figure><h1 id="677a" class="kv kw it bd kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls bi translated">带有 seaborn 的散点图和线性回归线</h1><p id="e1c3" class="pw-post-body-paragraph jx jy it jz b ka lt kc kd ke lu kg kh ki lv kk kl km lw ko kp kq lx ks kt ku im bi translated"><a class="ae ly" href="https://seaborn.pydata.org/" rel="noopener ugc nofollow" target="_blank"> Seaborn </a>是基于<a class="ae ly" href="https://matplotlib.org/" rel="noopener ugc nofollow" target="_blank"> matplotlib </a>的 Python 数据可视化库。我们可以使用<a class="ae ly" href="https://seaborn.pydata.org/generated/seaborn.regplot.html" rel="noopener ugc nofollow" target="_blank"><strong class="jz iu">seaborn . reg plot</strong></a>函数轻松地用 seaborn 创建回归图。与之前的方法相比，所需的线路数量要少得多。</p><figure class="ml mm mn mo gt ju"><div class="bz fp l di"><div class="mp mq l"/></div></figure><figure class="ml mm mn mo gt ju gh gi paragraph-image"><div class="gh gi nr"><img src="../Images/fcd75a633db4c41e901b8375cde6a2ce.png" data-original-src="https://miro.medium.com/v2/resize:fit:1250/format:webp/1*N4kGfVdI6c9GEBDbkLk0Bw.png"/></div></figure><p id="5a05" class="pw-post-body-paragraph jx jy it jz b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku im bi translated">前面的图显示了绘制 10000 个样本时的过度绘制。该图显示了男性和女性的身高和体重之间的正线性关系。为了更直观，下图显示了 300 个随机选择的样本的回归图。</p><figure class="ml mm mn mo gt ju"><div class="bz fp l di"><div class="mp mq l"/></div></figure><figure class="ml mm mn mo gt ju gh gi paragraph-image"><div class="gh gi mv"><img src="../Images/820376d3f4f87dbea9e497744bc3081e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1246/format:webp/1*Qgupt-n9NIzkaVXpu3UXtg.png"/></div></figure><h1 id="7106" class="kv kw it bd kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls bi translated">使用 sklearn 拟合简单的线性模型</h1><p id="c6c1" class="pw-post-body-paragraph jx jy it jz b ka lt kc kd ke lu kg kh ki lv kk kl km lw ko kp kq lx ks kt ku im bi translated"><a class="ae ly" href="https://scikit-learn.org/stable/" rel="noopener ugc nofollow" target="_blank"> <strong class="jz iu"> Scikit-learn </strong> </a>是一个免费的 python 机器学习库。我们可以使用 linear regression 类通过 Scikit-learn 轻松实现线性回归。创建线性回归对象后，我们可以通过调用 fit 方法来获得最适合我们的数据的直线。</p><figure class="ml mm mn mo gt ju"><div class="bz fp l di"><div class="mp mq l"/></div></figure><p id="689e" class="pw-post-body-paragraph jx jy it jz b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku im bi translated">使用<strong class="jz iu"> Sklearn </strong>线性回归获得的值与之前使用<strong class="jz iu"> Numpy </strong> polyfit 函数获得的值相匹配，因为两种方法都计算使<strong class="jz iu">平方误差</strong>最小的直线。如前所述，误差是因变量的实际值与模型预测值之间的差异。最小平方误差通过最小化<strong class="jz iu">平方误差</strong>的总和 S 找到最佳参数值。</p><p id="1a59" class="pw-post-body-paragraph jx jy it jz b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku im bi translated">一旦我们拟合了模型，我们就可以使用预测方法进行预测。我们还可以通过使用<a class="ae ly" href="https://docs.scipy.org/doc/numpy/reference/generated/numpy.polyval.html" rel="noopener ugc nofollow" target="_blank"> <strong class="jz iu"> polyval </strong> </a>函数，使用<strong class="jz iu"> Numpy </strong>中计算的多项式进行预测。使用<strong class="jz iu"> Scikit Learn </strong>和<strong class="jz iu"> Numpy </strong>获得的预测是相同的，因为这两种方法使用相同的方法来计算拟合线。</p><figure class="ml mm mn mo gt ju"><div class="bz fp l di"><div class="mp mq l"/></div></figure><h1 id="bf92" class="kv kw it bd kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls bi translated">皮尔逊相关系数</h1><p id="a642" class="pw-post-body-paragraph jx jy it jz b ka lt kc kd ke lu kg kh ki lv kk kl km lw ko kp kq lx ks kt ku im bi translated"><strong class="jz iu">相关性</strong>衡量两个变量相关的程度。<strong class="jz iu">皮尔逊相关系数</strong>用于衡量两个变量之间线性关系的<strong class="jz iu">强度</strong>和<strong class="jz iu">方向</strong>。该系数的计算方法是将变量的<a class="ae ly" href="https://en.wikipedia.org/wiki/Covariance" rel="noopener ugc nofollow" target="_blank"> <strong class="jz iu">协方差</strong> </a>除以其<a class="ae ly" href="https://en.wikipedia.org/wiki/Standard_deviation" rel="noopener ugc nofollow" target="_blank"> <strong class="jz iu">标准差</strong></a><strong class="jz iu"/><strong class="jz iu"/>的乘积，其值介于+1 和-1 之间，其中 1 表示完全正线性相关，0 表示没有线性相关，1 表示完全负线性相关。</p><p id="e464" class="pw-post-body-paragraph jx jy it jz b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku im bi translated">我们可以通过使用<a class="ae ly" href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.corr.html" rel="noopener ugc nofollow" target="_blank"> <strong class="jz iu">获得一个数据帧的变量的<strong class="jz iu">相关系数</strong>。</strong>corr()</a>法。默认情况下，计算皮尔逊相关系数；然而，也可以计算其他相关系数，例如 Kendall 或 Spearman 相关系数。</p><figure class="ml mm mn mo gt ju"><div class="bz fp l di"><div class="mp mq l"/></div></figure><figure class="ml mm mn mo gt ju gh gi paragraph-image"><div class="gh gi ns"><img src="../Images/1197e80cdd5f4dffc243939ce5bb64a6.png" data-original-src="https://miro.medium.com/v2/resize:fit:380/format:webp/1*mTMTKiT76P-uauW67eWF2Q.png"/></div></figure><figure class="ml mm mn mo gt ju"><div class="bz fp l di"><div class="mp mq l"/></div></figure><figure class="ml mm mn mo gt ju gh gi paragraph-image"><div class="gh gi nt"><img src="../Images/9edad820e47fd6a47e7c1ec2fece5ae5.png" data-original-src="https://miro.medium.com/v2/resize:fit:408/format:webp/1*vijhpK6wdSmhyqnkgtKVhQ.png"/></div></figure><p id="544f" class="pw-post-body-paragraph jx jy it jz b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku im bi translated">解释相关系数大小的经验法则如下:</p><ul class=""><li id="e7fd" class="nu nv it jz b ka kb ke kf ki nw km nx kq ny ku nz oa ob oc bi translated">1–0.8→非常强</li><li id="d597" class="nu nv it jz b ka od ke oe ki of km og kq oh ku nz oa ob oc bi translated">0.799–0.6→强</li><li id="ba93" class="nu nv it jz b ka od ke oe ki of km og kq oh ku nz oa ob oc bi translated">0.599–0.4→中等</li><li id="0871" class="nu nv it jz b ka od ke oe ki of km og kq oh ku nz oa ob oc bi translated">0.399–0.2→弱</li><li id="ad5f" class="nu nv it jz b ka od ke oe ki of km og kq oh ku nz oa ob oc bi translated">0.199–0→非常弱</li></ul><p id="82d1" class="pw-post-body-paragraph jx jy it jz b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku im bi translated">在之前的计算中，我们已经获得了大于 0.8 的<strong class="jz iu">皮尔逊</strong> <strong class="jz iu">相关系数</strong>，这意味着身高和体重对于男性和女性来说都是高度相关的。</p><p id="4d9d" class="pw-post-body-paragraph jx jy it jz b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku im bi translated">我们也可以使用<strong class="jz iu"> Scipy </strong>的<strong class="jz iu"> stats </strong>包计算<strong class="jz iu">皮尔逊相关系数</strong>。函数<a class="ae ly" href="https://docs.scipy.org/doc/scipy-0.14.0/reference/generated/scipy.stats.pearsonr.html" rel="noopener ugc nofollow" target="_blank"><strong class="jz iu">scipy . stats . Pearson r(<em class="nq">x</em>，<em class="nq"> y </em> ) </strong> </a> <strong class="jz iu"> </strong>返回两个值<strong class="jz iu"> Pearson 相关系数</strong>和<strong class="jz iu"> p 值</strong>。</p><figure class="ml mm mn mo gt ju"><div class="bz fp l di"><div class="mp mq l"/></div></figure><p id="ddc0" class="pw-post-body-paragraph jx jy it jz b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku im bi translated">可以看出，使用<strong class="jz iu">熊猫</strong>和<strong class="jz iu"> Scipy </strong>的<strong class="jz iu">相关系数</strong>是相同的:</p><ul class=""><li id="d26a" class="nu nv it jz b ka kb ke kf ki nw km nx kq ny ku nz oa ob oc bi translated">雌性相关系数:0.849608</li><li id="170f" class="nu nv it jz b ka od ke oe ki of km og kq oh ku nz oa ob oc bi translated">男性相关系数:0.8629788</li></ul><h1 id="a9a1" class="kv kw it bd kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls bi translated">残差图</h1><p id="ffc7" class="pw-post-body-paragraph jx jy it jz b ka lt kc kd ke lu kg kh ki lv kk kl km lw ko kp kq lx ks kt ku im bi translated">我们可以使用数值，如<strong class="jz iu">皮尔逊相关系数</strong>或可视化工具，如<strong class="jz iu">散点图</strong>来评估线性回归是否适合预测数据。进行这种评估的另一种方法是使用残差图。残差图显示实际值和预测值之间的差异。如果残差图中的点随机分布在水平轴周围，则线性回归模型适用于该数据；否则，非线性模型更合适。</p><p id="8806" class="pw-post-body-paragraph jx jy it jz b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku im bi translated">我们可以使用<strong class="jz iu"> Seaborn </strong>创建<strong class="jz iu">残差图</strong>，如下所示:</p><figure class="ml mm mn mo gt ju"><div class="bz fp l di"><div class="mp mq l"/></div></figure><figure class="ml mm mn mo gt ju gh gi paragraph-image"><div class="gh gi nr"><img src="../Images/9133df67a747db15562110e75aebed62.png" data-original-src="https://miro.medium.com/v2/resize:fit:1250/format:webp/1*bULNb42e3J7QyaGUugNGyw.png"/></div></figure><figure class="ml mm mn mo gt ju"><div class="bz fp l di"><div class="mp mq l"/></div></figure><figure class="ml mm mn mo gt ju gh gi paragraph-image"><div class="gh gi nr"><img src="../Images/7990857dc65fcd7c0a349628d8cafb30.png" data-original-src="https://miro.medium.com/v2/resize:fit:1250/format:webp/1*OvCRGkeCbtzqWacJ6fSg9g.png"/></div></figure><p id="3093" class="pw-post-body-paragraph jx jy it jz b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku im bi translated">正如我们所见，这些点随机分布在 0 附近，这意味着线性回归是预测我们数据的合适模型。如果残差图呈现曲率，则线性假设是不正确的。在这种情况下，非线性函数将更适合预测数据。</p><h1 id="a574" class="kv kw it bd kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls bi translated">多元线性回归</h1><p id="52ca" class="pw-post-body-paragraph jx jy it jz b ka lt kc kd ke lu kg kh ki lv kk kl km lw ko kp kq lx ks kt ku im bi translated"><strong class="jz iu">简单线性回归</strong>使用线性函数来预测目标变量<strong class="jz iu"> y </strong>的值，该函数只包含一个自变量<strong class="jz iu"> x₁ </strong>。</p><blockquote class="nb"><p id="b6e1" class="nc nd it bd ne nf ng nh ni nj nk ku dk translated">y =b ₀+b ₁x ₁</p></blockquote><p id="19b0" class="pw-post-body-paragraph jx jy it jz b ka nl kc kd ke nm kg kh ki nn kk kl km no ko kp kq np ks kt ku im bi translated">在将线性方程拟合到观测数据后，我们可以获得最符合数据的参数<strong class="jz iu"> b₀ </strong>和<strong class="jz iu"> b₁ </strong>的值，最小化<strong class="jz iu">平方误差</strong>。</p><p id="16e4" class="pw-post-body-paragraph jx jy it jz b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku im bi translated">之前，我们已经计算了两个线性模型，一个用于男性，另一个用于女性，以根据人的身高预测体重，获得了以下结果:</p><ul class=""><li id="0d39" class="nu nv it jz b ka kb ke kf ki nw km nx kq ny ku nz oa ob oc bi translated">男性→体重=-224.50+5.96 *身高</li><li id="ae41" class="nu nv it jz b ka od ke oe ki of km og kq oh ku nz oa ob oc bi translated">女性→体重=-246.01+5.99 *身高</li></ul><p id="9263" class="pw-post-body-paragraph jx jy it jz b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku im bi translated">到目前为止，我们已经采用了一个独立变量来预测人的体重<strong class="jz iu"> <em class="nq">【体重= f(身高)</em> </strong>，创建了两个不同的模型。也许你在想💭❓:我们可以用身高和性别作为独立变量建立一个预测体重的模型吗？答案是肯定的！😄⭐️，这就是多元线性回归发挥作用的地方！</p><p id="8a71" class="pw-post-body-paragraph jx jy it jz b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku im bi translated"><strong class="jz iu">多元线性回归</strong>使用线性函数预测目标变量<strong class="jz iu"> y </strong>的值，包含函数<strong class="jz iu"> n </strong>自变量<strong class="jz iu">x=[x₁,x₂,x₃,…,xₙ】</strong>。</p><blockquote class="nb"><p id="b04d" class="nc nd it bd ne nf ng nh ni nj nk ku dk translated">y = b ₀+b ₁x ₁+b<strong class="ak">₂x₂+b₃x₃+…+</strong>b<strong class="ak">ₙ</strong>x<strong class="ak">ₙ</strong></p></blockquote><p id="3335" class="pw-post-body-paragraph jx jy it jz b ka nl kc kd ke nm kg kh ki nn kk kl km no ko kp kq np ks kt ku im bi translated">我们使用与简单线性回归相同的技术(<strong class="jz iu">最小平方误差</strong>)获得参数<strong class="jz iu"> bᵢ </strong>的值。拟合模型后，我们可以用方程预测目标变量<strong class="jz iu"> y </strong>的值。在我们的例子中，我们用身高和性别来预测一个人的体重<strong class="jz iu"> <em class="nq">体重= f(身高，性别)。</em> </strong></p><h1 id="f323" class="kv kw it bd kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls bi translated">多元线性回归中的分类变量</h1><p id="f1c2" class="pw-post-body-paragraph jx jy it jz b ka lt kc kd ke lu kg kh ki lv kk kl km lw ko kp kq lx ks kt ku im bi translated">统计学中使用的变量有两种:<strong class="jz iu">数值型</strong>和<strong class="jz iu">分类变量</strong>。</p><ul class=""><li id="3e7d" class="nu nv it jz b ka kb ke kf ki nw km nx kq ny ku nz oa ob oc bi translated"><strong class="jz iu">数字变量</strong>代表可以测量并按升序和降序排序的值，如人的<strong class="jz iu">身高</strong>。</li><li id="347f" class="nu nv it jz b ka od ke oe ki of km og kq oh ku nz oa ob oc bi translated"><strong class="jz iu">分类变量</strong>是可以分组或分类的值，例如一个人的<strong class="jz iu">性别</strong>。</li></ul><p id="90fc" class="pw-post-body-paragraph jx jy it jz b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku im bi translated"><strong class="jz iu">多元线性回归</strong>不仅接受<strong class="jz iu">数值变量</strong>，还接受<strong class="jz iu">分类变量</strong>。要将<strong class="jz iu">分类变量</strong>包含在回归模型中，变量必须编码为<strong class="jz iu">二进制变量(虚拟变量)</strong>。在<strong class="jz iu"> Pandas </strong>中，我们可以使用<a class="ae ly" href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.get_dummies.html" rel="noopener ugc nofollow" target="_blank"><strong class="jz iu">Pandas . get _ dummies</strong></a>函数轻松地将<strong class="jz iu">分类变量</strong>转换为<strong class="jz iu">哑变量</strong>。该函数返回一个伪编码数据，其中 1 表示分类变量存在，0 表示不存在。</p><figure class="ml mm mn mo gt ju gh gi paragraph-image"><div class="gh gi oi"><img src="../Images/67ac9c2bb899d50ee03457d978c17fea.png" data-original-src="https://miro.medium.com/v2/resize:fit:726/format:webp/1*EmTRpGrtWmuEPfxPWvV2qA.png"/></div></figure><p id="d10e" class="pw-post-body-paragraph jx jy it jz b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku im bi translated">为了避免多重共线性，我们必须删除其中一个虚拟列。</p><figure class="ml mm mn mo gt ju"><div class="bz fp l di"><div class="mp mq l"/></div></figure><figure class="ml mm mn mo gt ju gh gi paragraph-image"><div class="gh gi oj"><img src="../Images/e1cb8a5c4b983fc5262f9384c8e8a296.png" data-original-src="https://miro.medium.com/v2/resize:fit:474/format:webp/1*rs4LDb5Qmgcd-TGmAxtQLw.png"/></div></figure><p id="cbf3" class="pw-post-body-paragraph jx jy it jz b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku im bi translated">然后，我们可以使用这个数据框架，使用<strong class="jz iu"> Scikit-learn </strong>获得一个<strong class="jz iu">多元线性回归</strong>模型。</p><figure class="ml mm mn mo gt ju"><div class="bz fp l di"><div class="mp mq l"/></div></figure><p id="305b" class="pw-post-body-paragraph jx jy it jz b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku im bi translated">在拟合线性方程后，我们得到以下多元线性回归模型:</p><ul class=""><li id="3114" class="nu nv it jz b ka kb ke kf ki nw km nx kq ny ku nz oa ob oc bi translated">体重=-244.9235+5.9769 *身高+19.3777 *性别</li></ul><p id="bb05" class="pw-post-body-paragraph jx jy it jz b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku im bi translated">如果我们想预测一个男性的体重，性别值是 1，得到下面的等式:</p><ul class=""><li id="50d6" class="nu nv it jz b ka kb ke kf ki nw km nx kq ny ku nz oa ob oc bi translated">男→体重=-244.9235+5.9769 *身高+19.3777 * 1 =-225.5458+5.9769 *身高</li></ul><p id="3469" class="pw-post-body-paragraph jx jy it jz b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku im bi translated">对于女性，性别值为 0。</p><ul class=""><li id="dc73" class="nu nv it jz b ka kb ke kf ki nw km nx kq ny ku nz oa ob oc bi translated">女→体重=-244.9235+5.9769 *身高+19.3777 * 0 =-244.9235+5.9769 *身高</li></ul><p id="ef33" class="pw-post-body-paragraph jx jy it jz b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku im bi translated">如果我们比较简单线性模型和多元线性模型，我们可以观察到类似的预测结果。多元线性回归模型的性别变量只改变直线的截距。🙌</p><h1 id="0064" class="kv kw it bd kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls bi translated">关键要点</h1><ol class=""><li id="732b" class="nu nv it jz b ka lt ke lu ki ok km ol kq om ku on oa ob oc bi translated"><strong class="jz iu">简单线性回归</strong>是对一个<strong class="jz iu">因变量</strong>和一个<strong class="jz iu">自变量</strong>之间的关系进行建模的线性方法。</li><li id="897c" class="nu nv it jz b ka od ke oe ki of km og kq oh ku on oa ob oc bi translated"><strong class="jz iu">多元线性回归</strong>使用线性函数来预测包含函数<strong class="jz iu"> n </strong>自变量的<strong class="jz iu">因变量</strong>的值。</li><li id="2164" class="nu nv it jz b ka od ke oe ki of km og kq oh ku on oa ob oc bi translated"><strong class="jz iu">探索性数据分析</strong>包括分析数据集的主要特征，通常采用<strong class="jz iu">可视化方法</strong>和<strong class="jz iu">汇总统计</strong>。</li><li id="d6d8" class="nu nv it jz b ka od ke oe ki of km og kq oh ku on oa ob oc bi translated"><strong class="jz iu">直方图</strong>是显示数值变量分布的图表，将数据分组到箱中。</li><li id="fae4" class="nu nv it jz b ka od ke oe ki of km og kq oh ku on oa ob oc bi translated"><strong class="jz iu"> Pandas </strong>提供探索性数据分析的方法和函数，如<strong class="jz iu"> Dataframe.describe()、Dataframe.info()、Dataframe.dtypes 和 Dataframe.shape. </strong></li><li id="92d6" class="nu nv it jz b ka od ke oe ki of km og kq oh ku on oa ob oc bi translated"><strong class="jz iu">散点图</strong>是二维数据可视化，显示两个数值变量之间的关系——一个沿 x 轴绘制，另一个沿 y 轴绘制。<strong class="jz iu"> Matplotlib </strong>和<strong class="jz iu"> Seaborn </strong>提供了绘制散点图的内置函数。</li><li id="202f" class="nu nv it jz b ka od ke oe ki of km og kq oh ku on oa ob oc bi translated">我们可以使用诸如<strong class="jz iu"> Numpy </strong>或<strong class="jz iu"> Scikit-learn </strong>之类的库来拟合一个<strong class="jz iu">简单线性回归</strong>模型。</li><li id="a11b" class="nu nv it jz b ka od ke oe ki of km og kq oh ku on oa ob oc bi translated"><strong class="jz iu">相关性</strong>衡量两个变量相关的程度。<strong class="jz iu">皮尔逊相关系数</strong>用于衡量<strong class="jz iu">强度</strong>和<strong class="jz iu">方向</strong>两个变量之间的线性关系。</li><li id="9c8e" class="nu nv it jz b ka od ke oe ki of km og kq oh ku on oa ob oc bi translated"><strong class="jz iu">残差图</strong>可用于分析<strong class="jz iu">线性回归模型</strong>是否适用于数据。</li><li id="66d3" class="nu nv it jz b ka od ke oe ki of km og kq oh ku on oa ob oc bi translated"><strong class="jz iu">分类变量</strong>必须转换成<strong class="jz iu">虚拟变量</strong>才能在<strong class="jz iu">多元线性回归模型</strong>中使用。</li></ol><p id="56ca" class="pw-post-body-paragraph jx jy it jz b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku im bi translated">感谢阅读🙌 😍 😉 🍀</p></div></div>    
</body>
</html>