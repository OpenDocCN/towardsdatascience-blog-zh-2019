<html>
<head>
<title>Getting Started with PySpark on AWS EMR</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">AWS EMR 上的 PySpark 入门</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/getting-started-with-pyspark-on-amazon-emr-c85154b6b921?source=collection_archive---------1-----------------------#2019-07-19">https://towardsdatascience.com/getting-started-with-pyspark-on-amazon-emr-c85154b6b921?source=collection_archive---------1-----------------------#2019-07-19</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="c2b9" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">使用 Spark on AWS 大规模处理数据的分步指南</h2></div><p id="8e72" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="kk iu">带有 PySpark 和 AWS EMR 的数据管道</strong>是一个多部分系列。这是第 1 部分，共 2 部分。如果您正在寻找如何将数据管道作为产品工作来运行的指导，请查看<a class="ae le" rel="noopener" target="_blank" href="/production-data-processing-with-apache-spark-96a58dfd3fe7">第 2 部分</a>。</p><ol class=""><li id="e20b" class="lf lg it kk b kl km ko kp kr lh kv li kz lj ld lk ll lm ln bi translated">AWS EMR 上的 PySpark 入门<strong class="kk iu">(本文)</strong></li><li id="9b96" class="lf lg it kk b kl lo ko lp kr lq kv lr kz ls ld lk ll lm ln bi translated"><a class="ae le" rel="noopener" target="_blank" href="/production-data-processing-with-apache-spark-96a58dfd3fe7">在 AWS EMR 上使用 PySpark 处理生产数据</a> <strong class="kk iu">(接下来)</strong></li></ol><figure class="lu lv lw lx gt ly gh gi paragraph-image"><div role="button" tabindex="0" class="lz ma di mb bf mc"><div class="gh gi lt"><img src="../Images/aa929a6d6c91b62c77945bed04623939.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*C1dm4-BygpqZI6L0Z11YQw.jpeg"/></div></div></figure><h1 id="df19" class="mf mg it bd mh mi mj mk ml mm mn mo mp jz mq ka mr kc ms kd mt kf mu kg mv mw bi translated">动机</h1><p id="4268" class="pw-post-body-paragraph ki kj it kk b kl mx ju kn ko my jx kq kr mz kt ku kv na kx ky kz nb lb lc ld im bi translated">如果您在过去十年中一直关注业务和技术趋势，您可能会意识到组织生成的数据量已经激增。企业渴望使用所有这些数据来获得洞察力和改进流程；然而，“大数据”意味着巨大的挑战。</p><p id="8340" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">必须发明全新的技术来处理越来越大的数据集。这些新技术包括云计算服务提供商的产品，如亚马逊网络服务(AWS)和开源的大规模数据处理引擎，如 Apache Spark。<strong class="kk iu">随着生成的数据量持续飙升，能够使用这些“大数据”工具的有抱负的数据科学家将在市场中脱颖而出。</strong></p><h1 id="760c" class="mf mg it bd mh mi mj mk ml mm mn mo mp jz mq ka mr kc ms kd mt kf mu kg mv mw bi translated">我们开始吧</h1><p id="f0fe" class="pw-post-body-paragraph ki kj it kk b kl mx ju kn ko my jx kq kr mz kt ku kv na kx ky kz nb lb lc ld im bi translated">在本指南中，我将教您如何在 Amazon EMR 集群上开始使用 PySpark 处理数据。本教程面向熟悉 Python，但刚开始使用 Spark 的当前和有抱负的数据科学家。</p><p id="697c" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">Spark 非常适合处理大型数据集，用于探索性数据分析和特征工程等日常数据科学任务。它还可以用于大规模实现许多流行的机器学习算法。</p><h1 id="bdf5" class="mf mg it bd mh mi mj mk ml mm mn mo mp jz mq ka mr kc ms kd mt kf mu kg mv mw bi translated">我们今天要讲的内容</h1><ol class=""><li id="c1a9" class="lf lg it kk b kl mx ko my kr nc kv nd kz ne ld lk ll lm ln bi translated">Spark、亚马逊 S3 和 EMR 概述</li><li id="3f5c" class="lf lg it kk b kl lo ko lp kr lq kv lr kz ls ld lk ll lm ln bi translated">在 Amazon EMR 上创建集群</li><li id="a9ad" class="lf lg it kk b kl lo ko lp kr lq kv lr kz ls ld lk ll lm ln bi translated">通过 Jupyter 笔记本连接到我们的集群</li><li id="3285" class="lf lg it kk b kl lo ko lp kr lq kv lr kz ls ld lk ll lm ln bi translated">从亚马逊 S3 加载数据</li></ol><h1 id="5782" class="mf mg it bd mh mi mj mk ml mm mn mo mp jz mq ka mr kc ms kd mt kf mu kg mv mw bi translated">大数据工具概述</h1><h2 id="4bad" class="nf mg it bd mh ng nh dn ml ni nj dp mp kr nk nl mr kv nm nn mt kz no np mv nq bi translated">火花</h2><p id="6277" class="pw-post-body-paragraph ki kj it kk b kl mx ju kn ko my jx kq kr mz kt ku kv na kx ky kz nb lb lc ld im bi translated">在<a class="ae le" href="https://spark.apache.org/" rel="noopener ugc nofollow" target="_blank">文档</a>中，“Apache Spark 是一个用于大规模数据处理的统一分析引擎。”Spark 的引擎允许您在分布式集群上并行处理大型数据处理任务。Spark 集群包含一个充当中央协调器的主节点和几个处理主节点分配的任务的工作节点。</p><p id="8d50" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在本指南中，我们将使用 Python，但是 Spark 开发人员也可以使用 Scala 或 Java。模块包含 Pandas 和 SQL 用户熟悉的语法。<code class="fe nr ns nt nu b">pyspark.ml</code>模块可以用来实现很多流行的机器学习模型。</p><p id="9eed" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">Spark 使用懒惰评估，这意味着它不做任何工作，直到你要求一个结果。通过这种方式，引擎可以决定执行 DAG(有向无环图-或您指定的操作列表)的最佳方式。当我定义一个操作时— <code class="fe nr ns nt nu b">new_df = df.filter(df.user_action == 'ClickAddToCart')</code> — Spark 将该操作添加到我的 DAG 中，但不执行。一旦我请求一个结果— <code class="fe nr ns nt nu b">new_df.collect()</code> — Spark 就会执行我的过滤器和我指定的任何其他操作。</p><p id="069d" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="kk iu"> <em class="nv">在我们继续之前有一个小提示:</em> </strong> <em class="nv">使用分布式云技术可能会令人沮丧。首先，您可能会发现 Spark 错误消息难以理解，难以调试。我鼓励你坚持下去！阅读错误。了解哪些部分信息丰富，然后谷歌一下。我不能保证你最终会停止敲键盘，但会变得更容易。如果没有学习曲线，这就不是一个让你与众不同的好方法！</em></p><h2 id="c3c8" class="nf mg it bd mh ng nh dn ml ni nj dp mp kr nk nl mr kv nm nn mt kz no np mv nq bi translated">亚马逊 S3</h2><p id="4ee6" class="pw-post-body-paragraph ki kj it kk b kl mx ju kn ko my jx kq kr mz kt ku kv na kx ky kz nb lb lc ld im bi translated"><a class="ae le" href="https://aws.amazon.com/s3/" rel="noopener ugc nofollow" target="_blank">亚马逊 S3 </a>(简单存储服务)是一种简单且相对便宜的安全存储大量数据的方式。典型的 Spark 工作流是从 S3 存储桶或其他源读取数据，执行一些转换，并将处理后的数据写回另一个 S3 存储桶。</p><h2 id="1932" class="nf mg it bd mh ng nh dn ml ni nj dp mp kr nk nl mr kv nm nn mt kz no np mv nq bi translated">亚马逊电子病历</h2><p id="bb4d" class="pw-post-body-paragraph ki kj it kk b kl mx ju kn ko my jx kq kr mz kt ku kv na kx ky kz nb lb lc ld im bi translated"><a class="ae le" href="https://aws.amazon.com/emr/" rel="noopener ugc nofollow" target="_blank">亚马逊 EMR </a> (Elastic Map Reduce)是一个大数据平台，将多个节点同步到一个可扩展的集群中，可以处理大量数据。如上所述，我们将作业提交给集群的主节点，它会计算出运行作业的最佳方式。然后，主节点相应地将任务分配给工作节点。</p><h1 id="32ad" class="mf mg it bd mh mi mj mk ml mm mn mo mp jz mq ka mr kc ms kd mt kf mu kg mv mw bi translated">在 Amazon EMR 上设置您的环境</h1><p id="b8c4" class="pw-post-body-paragraph ki kj it kk b kl mx ju kn ko my jx kq kr mz kt ku kv na kx ky kz nb lb lc ld im bi translated">首先，创建一个<a class="ae le" href="https://aws.amazon.com/?source=post_page---------------------------" rel="noopener ugc nofollow" target="_blank"> AWS 帐户</a>并登录控制台。我建议现在花时间<a class="ae le" href="https://docs.aws.amazon.com/IAM/latest/UserGuide/id_users_create.html#id_users_create_console" rel="noopener ugc nofollow" target="_blank">创建一个 IAM 用户</a>并<a class="ae le" href="https://docs.aws.amazon.com/IAM/latest/UserGuide/id_root-user.html" rel="noopener ugc nofollow" target="_blank">删除你的根访问键</a>。</p><p id="e600" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><em class="nv">更新:我已经创建了一个</em> <a class="ae le" rel="noopener" target="_blank" href="/quick-setup-guide-for-your-aws-account-423dadb61f99"> <em class="nv"> AWS 快速设置指南</em> </a> <em class="nv">引导您如何创建 IAM 用户和角色，创建一个 S3 桶，并配置 AWS CLI。</em></p><p id="d1bc" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在本教程中，我将使用美国西部地区(俄勒冈州)。您可以通过右上方的下拉菜单更改您所在的地区:</p><figure class="lu lv lw lx gt ly gh gi paragraph-image"><div role="button" tabindex="0" class="lz ma di mb bf mc"><div class="gh gi nw"><img src="../Images/8c310a95f33bad54e60d8c571d22aa00.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*01N0X-LjBTHN3v3XfQ_Tug.png"/></div></div></figure><p id="9276" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">关于 AWS 费用的警告:你需要提供一张信用卡来创建你的账户。 <strong class="kk iu"> <em class="nv">为了保持成本最低，不要忘记在使用完 EMR 集群后终止它</em> </strong> <em class="nv">。对于本指南，我们将使用 m5.xlarge 实例，在撰写本文时，每小时的成本为 0.192 美元。此外，在亚马逊 S3 上托管数据每月会收取少量费用——这一费用会随着你托管的数据量而增加。为避免持续成本，请在使用后删除存储桶。</em></p><h2 id="5b31" class="nf mg it bd mh ng nh dn ml ni nj dp mp kr nk nl mr kv nm nn mt kz no np mv nq bi translated">在亚马逊 S3 上存储配置文件</h2><p id="3e43" class="pw-post-body-paragraph ki kj it kk b kl mx ju kn ko my jx kq kr mz kt ku kv na kx ky kz nb lb lc ld im bi translated">为了在集群的所有节点上安装有用的包，我们需要创建文件<code class="fe nr ns nt nu b">emr_bootstrap.sh</code>并将其添加到 S3 上的 bucket 中。</p><pre class="lu lv lw lx gt nx nu ny nz aw oa bi"><span id="6d2c" class="nf mg it nu b gy ob oc l od oe">#!/bin/bash<br/>sudo pip install -U \<br/>    matplotlib \<br/>    pandas</span></pre><p id="e3c2" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">使用控制台中的“查找服务”搜索框搜索 S3，导航至该城市:</p><figure class="lu lv lw lx gt ly gh gi paragraph-image"><div role="button" tabindex="0" class="lz ma di mb bf mc"><div class="gh gi of"><img src="../Images/1df5b2eddf4caabff05ce4dd7110107a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*K-E7Y4wj_9AXVWt0Gp5iWA.png"/></div></div></figure><p id="feac" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">点击“创建存储桶”，填写“存储桶名称”字段，点击“创建”:</p><figure class="lu lv lw lx gt ly gh gi paragraph-image"><div role="button" tabindex="0" class="lz ma di mb bf mc"><div class="gh gi og"><img src="../Images/872178e61f1906fe1c823aef75e4616a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*vq7crJyX3_PDZ4zSqlJH_w.png"/></div></div></figure><p id="7bcc" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">点击“上传”、“添加文件”，打开您创建的文件<code class="fe nr ns nt nu b">emr_bootstrap.sh</code>。点击“上传”上传文件。</p><figure class="lu lv lw lx gt ly gh gi paragraph-image"><div role="button" tabindex="0" class="lz ma di mb bf mc"><div class="gh gi oh"><img src="../Images/110fcc229c2f47c269dd7417675e0639.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*j2BZxJZAddgHiFEU7X8wcA.png"/></div></div></figure><h2 id="1db6" class="nf mg it bd mh ng nh dn ml ni nj dp mp kr nk nl mr kv nm nn mt kz no np mv nq bi translated">创建密钥对文件</h2><p id="01dd" class="pw-post-body-paragraph ki kj it kk b kl mx ju kn ko my jx kq kr mz kt ku kv na kx ky kz nb lb lc ld im bi translated">从控制台主页导航到 EC2:</p><figure class="lu lv lw lx gt ly gh gi paragraph-image"><div role="button" tabindex="0" class="lz ma di mb bf mc"><div class="gh gi oi"><img src="../Images/9fc7e15125c50a708033c70b153dff38.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*szvEpfhcDQJtEZjQpAxekw.png"/></div></div></figure><p id="e580" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">选择“密钥对”</p><figure class="lu lv lw lx gt ly gh gi paragraph-image"><div role="button" tabindex="0" class="lz ma di mb bf mc"><div class="gh gi oj"><img src="../Images/893b29555e91c172d75235e1bc15ca09.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*om-yaXvGtqPdrPDPELrkqQ.png"/></div></div></figure><p id="2394" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">单击“创建密钥对”，然后输入名称并单击“创建”。</p><figure class="lu lv lw lx gt ly gh gi paragraph-image"><div role="button" tabindex="0" class="lz ma di mb bf mc"><div class="gh gi ok"><img src="../Images/610f4a9b0e81d375919c50bb432a240e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*dT3u-rkxejPfDTBQGCRNTw.png"/></div></div></figure><figure class="lu lv lw lx gt ly gh gi paragraph-image"><div role="button" tabindex="0" class="lz ma di mb bf mc"><div class="gh gi ol"><img src="../Images/5b0ebf381bc4eb61eaeb6ec7128637d1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*BBfkPiu9h2dyGWAkp8KZIQ.png"/></div></div></figure><p id="7b9e" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">你的文件<code class="fe nr ns nt nu b">emr-key.pem</code>应该会自动下载。把它存放在一个你会记住的目录里。我把我的<code class="fe nr ns nt nu b">.pem</code>文件放在<code class="fe nr ns nt nu b">~/.ssh</code>里。确保这个文件不要放在你的 GitHub repos 或任何其他公共场所，以保证你的 AWS 资源更加安全。</p><h2 id="f158" class="nf mg it bd mh ng nh dn ml ni nj dp mp kr nk nl mr kv nm nn mt kz no np mv nq bi translated">在 Amazon EMR 上创建集群</h2><p id="024e" class="pw-post-body-paragraph ki kj it kk b kl mx ju kn ko my jx kq kr mz kt ku kv na kx ky kz nb lb lc ld im bi translated">从您的控制台导航到 EMR，单击“创建集群”，然后“转到高级选项”。</p><figure class="lu lv lw lx gt ly gh gi paragraph-image"><div role="button" tabindex="0" class="lz ma di mb bf mc"><div class="gh gi om"><img src="../Images/69e9683e2a634cd9079744123139955d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*B5olXQYfd40p0ll7xRePew.png"/></div></div></figure><figure class="lu lv lw lx gt ly gh gi paragraph-image"><div role="button" tabindex="0" class="lz ma di mb bf mc"><div class="gh gi on"><img src="../Images/066cb01b1bc4438674ed8193b1b63894.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*tvtQPgyyYlnmotj1m62zOA.png"/></div></div></figure><figure class="lu lv lw lx gt ly gh gi paragraph-image"><div role="button" tabindex="0" class="lz ma di mb bf mc"><div class="gh gi oo"><img src="../Images/bf6609d4bc7ab5e133c4eb7972ef6100.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*zCqeZaa6fTz_ErIZOv2ypg.png"/></div></div></figure><p id="b86e" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">进行以下选择，从“版本”下拉列表中选择最新版本并选中“Spark”，然后单击“下一步”。</p><figure class="lu lv lw lx gt ly gh gi paragraph-image"><div role="button" tabindex="0" class="lz ma di mb bf mc"><div class="gh gi op"><img src="../Images/473aac139c28a0dcb2d3fa1ab03b86e4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*X4ThhePlVqdkAXANEtSq3g.png"/></div></div></figure><p id="86f1" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">选择“us-west-2a 中的默认”选项“EC2 子网”下拉列表，将您的实例类型更改为 m5.xlarge 以使用最新一代的通用实例，然后单击“下一步”。</p><figure class="lu lv lw lx gt ly gh gi paragraph-image"><div role="button" tabindex="0" class="lz ma di mb bf mc"><div class="gh gi oq"><img src="../Images/896301ee824eed6e57120fdc78182ad0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*w1xi62TuHk0IDv2vJwHaiA.png"/></div></div></figure><p id="6673" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">命名您的集群，添加<code class="fe nr ns nt nu b">emr_bootstrap.sh</code>作为引导操作，然后单击“Next”。你的引导动作的脚本位置将是你在教程前面上传<code class="fe nr ns nt nu b">emr_bootstrap.sh</code>的 S3 文件路径。您的引导操作将在集群中的每个节点上安装您指定的软件包。</p><figure class="lu lv lw lx gt ly gh gi paragraph-image"><div role="button" tabindex="0" class="lz ma di mb bf mc"><div class="gh gi or"><img src="../Images/c92e648fcdbec36c4c90bcd5b50eff96.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*PDT9NxLpj065FL3iErIK-g.png"/></div></div></figure><figure class="lu lv lw lx gt ly gh gi paragraph-image"><div role="button" tabindex="0" class="lz ma di mb bf mc"><div class="gh gi os"><img src="../Images/9cca6649e2f5d1673464cadb656b04b2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*YvoBYydVbF7lwXntCOCmvQ.png"/></div></div></figure><p id="9b97" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">选择您之前创建的密钥对，然后单击“创建集群”。您的集群将需要几分钟的时间来启动，但是一旦它进入“等待”状态，您就可以进入下一步了——使用 Jupyter 笔记本连接到您的集群。</p><figure class="lu lv lw lx gt ly gh gi paragraph-image"><div role="button" tabindex="0" class="lz ma di mb bf mc"><div class="gh gi or"><img src="../Images/5c337afb4522ebf14f2616ab6fc26afe.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*QYLZ_aqNmfc1iZETw1MZsQ.png"/></div></div></figure><h2 id="8ae7" class="nf mg it bd mh ng nh dn ml ni nj dp mp kr nk nl mr kv nm nn mt kz no np mv nq bi translated">使用 Jupyter 笔记本连接到您的集群</h2><p id="0d22" class="pw-post-body-paragraph ki kj it kk b kl mx ju kn ko my jx kq kr mz kt ku kv na kx ky kz nb lb lc ld im bi translated">导航至左侧面板中的“笔记本”。点击“创建笔记本”并按照以下步骤操作。</p><figure class="lu lv lw lx gt ly gh gi paragraph-image"><div role="button" tabindex="0" class="lz ma di mb bf mc"><div class="gh gi ot"><img src="../Images/68b3fe2657b1f29a1d9d02cdbd232efd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*NXstNlIdSXpnuQSUie1eZg.png"/></div></div></figure><p id="7f42" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">命名您的笔记本并选择您刚刚创建的集群。</p><figure class="lu lv lw lx gt ly gh gi paragraph-image"><div role="button" tabindex="0" class="lz ma di mb bf mc"><div class="gh gi op"><img src="../Images/0b6ec5799ccd1395869d20e5d7b53814.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*UiRRCBc39t3OFeEw1HmH-w.png"/></div></div></figure><figure class="lu lv lw lx gt ly gh gi paragraph-image"><div role="button" tabindex="0" class="lz ma di mb bf mc"><div class="gh gi ou"><img src="../Images/05e5213063641d86ddcedff10e0c79a2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*zqPa3dJI8QqxujM5iIckrw.png"/></div></div></figure><p id="5fde" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">一旦你的笔记本“准备好”，点击“打开”。您现在已经准备好开始在云上运行 Spark 了！</p><figure class="lu lv lw lx gt ly gh gi paragraph-image"><div role="button" tabindex="0" class="lz ma di mb bf mc"><div class="gh gi ov"><img src="../Images/f4fa5cf7153ed25dd96cafdba6d6067b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*fvVFlCGVxKi4CJNPVB9_fg.png"/></div></div></figure><h2 id="064f" class="nf mg it bd mh ng nh dn ml ni nj dp mp kr nk nl mr kv nm nn mt kz no np mv nq bi translated">连接到 S3 上的数据源</h2><p id="39c4" class="pw-post-body-paragraph ki kj it kk b kl mx ju kn ko my jx kq kr mz kt ku kv na kx ky kz nb lb lc ld im bi translated">在笔记本的第一个单元格中，导入您要使用的包。例如:</p><pre class="lu lv lw lx gt nx nu ny nz aw oa bi"><span id="a673" class="nf mg it nu b gy ob oc l od oe">from pyspark.sql import functions as F</span></pre><p id="c022" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">您应该得到以下输出:</p><figure class="lu lv lw lx gt ly gh gi paragraph-image"><div role="button" tabindex="0" class="lz ma di mb bf mc"><div class="gh gi os"><img src="../Images/501c1671eaf96c032426dcc44cf7f23b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*d2q2dqGgs_A6LdRJYLirdA.png"/></div></div></figure><p id="ed7e" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">注意:SparkSession 在笔记本中被自动定义为<code class="fe nr ns nt nu b">spark</code> —您必须在创建脚本作为 Spark 作业提交时自己定义。</p><p id="511d" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">接下来，让我们从 S3 导入一些数据。我们将使用亚马逊在公共桶中提供的数据。让我们看看<a class="ae le" href="https://registry.opendata.aws/amazon-reviews/" rel="noopener ugc nofollow" target="_blank">亚马逊客户评论数据集</a>。具体来说，我们来看看书评:</p><pre class="lu lv lw lx gt nx nu ny nz aw oa bi"><span id="ca5c" class="nf mg it nu b gy ob oc l od oe">input_bucket = 's3://amazon-reviews-pds'<br/>input_path = '/parquet/product_category=Books/*.parquet'<br/>df = spark.read.parquet(input_bucket + input_path)</span><span id="06b6" class="nf mg it nu b gy ow oc l od oe">df.show()</span></pre><p id="9fa7" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><code class="fe nr ns nt nu b">input_path</code>中的<code class="fe nr ns nt nu b">/*.parquet</code>语法告诉 Spark 读取<code class="fe nr ns nt nu b">s3://amazon-reviews-pds/parquet/product_category=Books/</code>桶目录中的所有<code class="fe nr ns nt nu b">.parquet</code>文件。</p><p id="512c" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我将很快推出一个关于 PySpark DataFrame API 的数据争论的教程，但是现在，请查看 DataCamp 的这个<a class="ae le" href="https://s3.amazonaws.com/assets.datacamp.com/blog_assets/PySpark_SQL_Cheat_Sheet_Python.pdf" rel="noopener ugc nofollow" target="_blank">优秀的备忘单开始吧。</a></p><h1 id="28a4" class="mf mg it bd mh mi mj mk ml mm mn mo mp jz mq ka mr kc ms kd mt kf mu kg mv mw bi translated">下一个</h1><p id="e07f" class="pw-post-body-paragraph ki kj it kk b kl mx ju kn ko my jx kq kr mz kt ku kv na kx ky kz nb lb lc ld im bi translated">一旦你在 Jupyter 笔记本上测试了你的 PySpark 代码，把它移到一个脚本中，然后<a class="ae le" href="https://medium.com/@brent_64035/production-data-processing-with-apache-spark-96a58dfd3fe7" rel="noopener">用 Spark 和 AWS 命令行界面创建一个生产数据处理工作流</a>。然后，你准备好<a class="ae le" rel="noopener" target="_blank" href="/set-up-an-airflow-environment-on-aws-in-minutes-f934cf10ec54">安排你的气流火花工作</a>。</p><h1 id="418c" class="mf mg it bd mh mi mj mk ml mm mn mo mp jz mq ka mr kc ms kd mt kf mu kg mv mw bi translated">保持联系</h1><p id="b2ff" class="pw-post-body-paragraph ki kj it kk b kl mx ju kn ko my jx kq kr mz kt ku kv na kx ky kz nb lb lc ld im bi translated">感谢您的阅读！请让我知道你是否喜欢这篇文章，或者你是否有任何批评。如果这篇指南对你有用，一定要关注我，这样你就不会错过我以后的任何文章。</p><p id="c4f9" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">如果你在一个数据项目上需要帮助或者想打声招呼，<strong class="kk iu">在</strong><a class="ae le" href="https://www.linkedin.com/in/brent-lemieux/?source=post_page---------------------------" rel="noopener ugc nofollow" target="_blank"><strong class="kk iu">LinkedIn</strong></a>上联系并给我发消息。干杯！</p></div></div>    
</body>
</html>