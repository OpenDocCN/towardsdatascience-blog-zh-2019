<html>
<head>
<title>Two Tasks, Two Datasets, One Network: Multi-task Learning with DnD</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">两个任务，两个数据集，一个网络:DnD 的多任务学习</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/two-tasks-two-datasets-one-network-multi-task-learning-with-dnd-eaef00b5e741?source=collection_archive---------12-----------------------#2019-06-03">https://towardsdatascience.com/two-tasks-two-datasets-one-network-multi-task-learning-with-dnd-eaef00b5e741?source=collection_archive---------12-----------------------#2019-06-03</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><figure class="is it gp gr iu iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi ir"><img src="../Images/599d87682fd98a0708e5cebfb5cfc996.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*SGUj5UzJ0ayVHjFKBOX68Q.jpeg"/></div></div><figcaption class="jc jd gj gh gi je jf bd b be z dk">elf/human (.95), rogue (.65). <a class="ae jg" rel="noopener" target="_blank" href="/two-tasks-two-datasets-one-network-multi-task-learning-with-dnd-eaef00b5e741?source=friends_link&amp;sk=113c9f9d9180a577e055242be6fb6bd2">HERE</a> is a link to view for free if you like</figcaption></figure><div class=""/><p id="5458" class="pw-post-body-paragraph kg kh jj ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">这篇文章的动机是我在 Shoprunner 的实际工作中一直试图解决的问题。对于上下文，我负责对不断增长的类别进行建模，我们可能永远不会有一个我们想要建模的事物的完整列表。因此，建立一个数据集来统治所有这些被我们需要的所有类别完全标记的数据并不特别可行。虽然这可以在物理上实现，但存在许多风险，例如新的类别在统一数据集中表现不足，然后我们必须用所有以前的类别标记一个全新的数据集。此外，它可能只是花费一堆额外的钱。</p><p id="3aad" class="pw-post-body-paragraph kg kh jj ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">有很多解决方案，我会考虑部分解决方案，如建立一堆特定类别的模型并部署这些模型，或者继续寻找用一个数据集来统治所有模型的方法。</p><p id="ad30" class="pw-post-body-paragraph kg kh jj ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">构建和部署单个模型似乎很容易，直到从现在起一年内您必须维护几十个模型，这时您可以使用单个模型来完成相同的任务。因此，如果能用一个单一的多任务网络解决所有这些问题，那就更好了。</p><p id="3871" class="pw-post-body-paragraph kg kh jj ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">为了继续追求“一个数据集来统治所有路径”，我一直在建立针对特定类别训练的较小模型，并使用这些模型来标记更大的图像池，以创建大型完全标记的数据集。然而，这个过程需要手动检查类别来测量清洁度，并且存在许多与保持完全标记的数据集的清洁度相关的问题。对我来说，这是一个权宜之计，可能很难维持。</p><p id="a0bf" class="pw-post-body-paragraph kg kh jj ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">对我来说，我真正需要的是一种训练多任务模型的方法，可以灵活地为单个任务使用多个数据集。</p><figure class="lf lg lh li gt iv gh gi paragraph-image"><div class="gh gi le"><img src="../Images/511ce1f653b98493a830f36fbcdbe71e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1382/format:webp/1*DToZwej0LxhQ38v8KVdndQ.png"/></div><figcaption class="jc jd gj gh gi je jf bd b be z dk">Dragonborn (.96) Paladin/Warrior (.91). When I looked at this image in my jupyter notebook I was confused as to what it was… then I saw the race and class was written on it. Gogo model I guess? The only label this image would have in the dataset was “dragonborn” so the model gets paladin right which is cool.</figcaption></figure><h1 id="7539" class="lj lk jj bd ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg bi translated">背景:滚动历史检查</h1><p id="9db5" class="pw-post-body-paragraph kg kh jj ki b kj mh kl km kn mi kp kq kr mj kt ku kv mk kx ky kz ml lb lc ld im bi translated">能够使用多个数据集来训练我的多任务网络，而不是依赖于一个统一的完全标记的数据集，这将给我带来相对容易地添加和删除类别的灵活性。在过去的几个月里，我对网络架构和管道做了很多实验，但是直到最近我才接近成功。</p><p id="c535" class="pw-post-body-paragraph kg kh jj ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">大约一周前，我很无聊，当天早些时候又听了一遍吴恩达的多任务学习讲座，但直到我在咏春练习中与一些人对练，我才真正理解了视频的细节。在对练过程中，我意识到吴恩达简要地提到了使用非统一数据集进行多任务学习(视频中大约 5:30)。这分散了我的注意力，我被打了几次，但这非常值得。</p><figure class="lf lg lh li gt iv"><div class="bz fp l di"><div class="mm mn l"/></div><figcaption class="jc jd gj gh gi je jf bd b be z dk">multi-task learning lecture from Andrew Ng’s deep learning course</figcaption></figure><p id="220f" class="pw-post-body-paragraph kg kh jj ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">虽然非常模糊，但吴恩达的基本思想是，通过只计算相关损失并将其用于反向传播，可以在部分标记的数据集上进行多任务学习。</p><p id="7ab7" class="pw-post-body-paragraph kg kh jj ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">这个高层次的想法看起来很直观，因为吴恩达在一次演讲中提到了它，所以我认为这是可能的。所以我经历了几次不同的管道迭代，试图做到这一点。所有失败。太好了，又回到起点了…我还是错过了一些东西。</p><p id="be77" class="pw-post-body-paragraph kg kh jj ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">对我有帮助的第二点信息来自于对 Google 的 Bert NLP 模型应用的最新研究。虽然我不喜欢芝麻街的命名趋势(ELMO，伯特，大鸟)，但如果你没有检查过的话，这些模型非常有趣。我在斯坦福黎明看到了一个帖子。对我来说，关键在于以下几点。</p><blockquote class="mo mp mq"><p id="9156" class="kg kh mr ki b kj kk kl km kn ko kp kq ms ks kt ku mt kw kx ky mu la lb lc ld im bi translated">我们的训练时间表也很简单:将所有参与的任务分成几批，随机排列，通过网络一次传送一个，这样每个任务中的每个训练例子在每个时期就可以看到一次。</p></blockquote><p id="f668" class="pw-post-body-paragraph kg kh jj ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我有一种相当强迫性的需要去做数据科学的事情，我自称是一个“数据科学迷”。所以当我读完这篇文章后，我基本上是下班回家，直到凌晨 2 点才开始修改我在这篇文章中使用的细节。</p><h1 id="71f6" class="lj lk jj bd ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg bi translated">数据集:主动滚动</h1><figure class="lf lg lh li gt iv gh gi paragraph-image"><div class="gh gi mv"><img src="../Images/b41a6dcc94d26ba6ca680c509e0569b9.png" data-original-src="https://miro.medium.com/v2/resize:fit:824/format:webp/1*AktW4KTDn-16k8dXlL2xHw.png"/></div><figcaption class="jc jd gj gh gi je jf bd b be z dk">humanoid (.57) warrior/paladin (.57). swords and plate armor for warrior/paladin. Dataset label is just warrior/paladin.</figcaption></figure><p id="f374" class="pw-post-body-paragraph kg kh jj ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">与所有项目一样，首先需要找到/构建一个数据集。然而，在这篇文章中，我使用了两个小数据集，它们是我收集的与两个 DnD 种族和阶层相关的图片/艺术品。</p><p id="9b0e" class="pw-post-body-paragraph kg kh jj ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">种族包括人形种族(精灵/人类)，侏儒，龙族，职业包括圣骑士/战士，盗贼，巫师/巫师。</p><p id="24e5" class="pw-post-body-paragraph kg kh jj ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">这些都包括在内，并能概括 DnD 的一切吗？绝对不是，但是它们符合我的目的，对于每个数据集，随机猜测大约是 35–40%</p><p id="c655" class="pw-post-body-paragraph kg kh jj ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">另一个细节是，我使用 fastai 讲座中提到的方法快速建立了这些数据集，该方法参考了来自<a class="ae jg" href="https://www.pyimagesearch.com/2017/12/04/how-to-create-a-deep-learning-dataset-using-google-images/" rel="noopener ugc nofollow" target="_blank"> pyimagesearch </a>的另一篇博客文章。</p><p id="5f6d" class="pw-post-body-paragraph kg kh jj ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">总的要点是，你可以使用谷歌图片搜索来挖掘数据集相对一致的类别，然后手动删除不相关的图片，以彻底清理它。作为一个曾经手工构建图像数据集并对其进行标记的人，这是生活质量的巨大提高，我强烈推荐你尽你所能使用它。目前，我仍在试图用这种方法解决多标签问题，但这可能是另一个话题。</p><h1 id="515c" class="lj lk jj bd ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg bi translated">版本 1 管道:滚动修补检查？</h1><p id="0068" class="pw-post-body-paragraph kg kh jj ki b kj mh kl km kn mi kp kq kr mj kt ku kv mk kx ky kz ml lb lc ld im bi translated">我建立这条管道的第一步主要是修改我现有的培训管道。下面是一些实现细节。</p><ul class=""><li id="166c" class="mw mx jj ki b kj kk kn ko kr my kv mz kz na ld nb nc nd ne bi translated">制作了两个数据集加载器，而不是一个。我将两者分开，这样我就可以对它们进行迭代，分别生成批次，并只计算网络中那个任务头的损失。</li><li id="d946" class="mw mx jj ki b kj nf kn ng kr nh kv ni kz nj ld nb nc nd ne bi translated">现在，我使用两个数据集中较小的一个来确定一个时期内要生成的批次数量。这可能是不必要的，可能只有在两个数据集具有相似数量的样本的用例中才是有意义的。</li><li id="69b2" class="mw mx jj ki b kj nf kn ng kr nh kv ni kz nj ld nb nc nd ne bi translated">我只做一次反向传播。我运行一个数据集的批处理，并计算该任务的相关损失(完全忽略吴恩达建议的另一个任务的损失计算)。然后运行第二个数据集的批处理，并计算第二个任务的损失。一旦这两个做了，我总结他们的损失，并执行反向传播</li></ul><blockquote class="mo mp mq"><p id="92a2" class="kg kh mr ki b kj kk kl km kn ko kp kq ms ks kt ku mt kw kx ky mu la lb lc ld im bi translated">请随意检查我做修补的笔记本。我制定培训计划的初始笔记本是<a class="ae jg" href="https://github.com/sugi-chan/DnD_multi_task_multi_dataset/blob/master/dnd_sepeated%20batches.ipynb" rel="noopener ugc nofollow" target="_blank">这里</a></p></blockquote><p id="2849" class="pw-post-body-paragraph kg kh jj ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我在让这个模型收敛时遇到了问题，但是我发现稍微低于正常的学习速度就能很好地工作。这可能有助于网络不过度适应某个特定的任务，避免它在两者之间来回跳跃。高度推测性的，它在我这边经得起进一步的测试。</p><p id="01ca" class="pw-post-body-paragraph kg kh jj ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">这条管道的最终结果是，我能够以大约 70%的准确率预测输入图像的种族和类别。</p><figure class="lf lg lh li gt iv gh gi paragraph-image"><div class="gh gi nk"><img src="../Images/305a101e8b559abc892ca1f1af4d4b62.png" data-original-src="https://miro.medium.com/v2/resize:fit:1360/format:webp/1*4dpWG3j2mVttHAyvuGobfg.jpeg"/></div></figure><p id="9d33" class="pw-post-body-paragraph kg kh jj ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">一方面，这是一个胜利，因为我得到了以上的随机猜测…然而，它仍然有点畏缩值得，因为我觉得它应该能够做得更好…所以，现在管道工程，我应该如何改善它？</p><p id="661d" class="pw-post-body-paragraph kg kh jj ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">由于我使用的学习率低于正常水平，我认为主干网 Resnet 模型很可能无法很好地适应这个 DnD 特有的领域。为了测试这个假设，我需要做的就是得到一个 DnD 微调模型。</p><h1 id="50af" class="lj lk jj bd ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg bi translated">具有微调主干的版本 2:滚动洞察检查</h1><p id="8414" class="pw-post-body-paragraph kg kh jj ki b kj mh kl km kn mi kp kq kr mj kt ku kv mk kx ky kz ml lb lc ld im bi translated">因为我已经有了数据集，所以我训练了一个 Resnet50 模型来预测种族类别。我对我的标准培训管道做了一些小的修改(大部分只是将它们转换回只做一项任务，因为我身边的大多数管道都是多任务学习者)。目标是将更多的领域专门化到主干模型中，主干模型承担了大部分繁重的工作。</p><p id="08f7" class="pw-post-body-paragraph kg kh jj ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">虽然我可能已经从这个模型中挤出了更高的性能，但它在任务中达到了 80%的准确率。因此，这超过了比赛任务 40%的随机猜测阈值和版本 1 多任务模型 70%的准确性。</p><blockquote class="mo mp mq"><p id="f4d1" class="kg kh mr ki b kj kk kl km kn ko kp kq ms ks kt ku mt kw kx ky mu la lb lc ld im bi translated">微调主干网 Resnet50 模型发生在<a class="ae jg" href="https://github.com/sugi-chan/DnD_multi_task_multi_dataset/blob/master/dnd_single_model_fine_tuning.ipynb" rel="noopener ugc nofollow" target="_blank">这里</a></p></blockquote><p id="1d1b" class="pw-post-body-paragraph kg kh jj ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我用这种新的微调过的 Resnet50 替换了 vanilla Resnet50 模型，并运行了几次培训管道。我发现，循环学习率并实际上让它使用稍高的学习率(低于正常水平，但高于我之前使用的水平)可以让模型在种族方面达到 83%的准确率，在类别方面达到 75%。</p><blockquote class="mo mp mq"><p id="1f9b" class="kg kh mr ki b kj kk kl km kn ko kp kq ms ks kt ku mt kw kx ky mu la lb lc ld im bi translated">具有微调主干的版本 2 管道在这里是<a class="ae jg" href="https://github.com/sugi-chan/DnD_multi_task_multi_dataset/blob/master/dnd_sepeated%20batches-version2_fine_tuned_backbone.ipynb" rel="noopener ugc nofollow" target="_blank"/>。当我基本上只是循环学习率时，我还记下了不同的跑步。</p></blockquote><p id="3163" class="pw-post-body-paragraph kg kh jj ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">这和我想要的一样高吗？仍然没有，但我认为它演示了一个相当有效的方法来训练这些模型，并表明一个微调的主干提高了这个设置的性能。</p><figure class="lf lg lh li gt iv gh gi paragraph-image"><div class="gh gi nl"><img src="../Images/86fd9787c770d310f562e02cad7d18ed.png" data-original-src="https://miro.medium.com/v2/resize:fit:1346/format:webp/1*yDSz8tNrDfTyaUNgcUg46g.png"/></div><figcaption class="jc jd gj gh gi je jf bd b be z dk">humanoid (.998) and wizard/sorcerer (.834). Staff and robes seem to equal wizard to the model.</figcaption></figure><h1 id="071e" class="lj lk jj bd ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg bi translated">结果:进行感知检查</h1><p id="51f3" class="pw-post-body-paragraph kg kh jj ki b kj mh kl km kn mi kp kq kr mj kt ku kv mk kx ky kz ml lb lc ld im bi translated">因此，与使用非微调模型的管道版本 1 相比，微调模型显示了显著的改进。版本 1 模型在最低损失 1.681 上具有 70%和 71.25%(种族和阶级)的最高准确度。相比之下，第二版模型提高了良好位得分 83.75%和 75%，最佳损失为 1.5751。</p><p id="342e" class="pw-post-body-paragraph kg kh jj ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">唯一的区别是用一个微调的模型替换了网络的主干，这很有帮助，因为它提供了一个很好的方法来解决我在 Shoprunner 面临的问题。基本上，您可以应用当前调整良好的模型，并使用这种多数据集训练方法添加其他类别。</p><p id="c4f6" class="pw-post-body-paragraph kg kh jj ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我感兴趣的另一件事是，这个网络的多任务版本能够在同一问题上胜过单一任务网络。</p><p id="c4a3" class="pw-post-body-paragraph kg kh jj ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">对于 DnD 竞赛类别，优化的 Resnet50 得分为 80%，但使用该网络作为主干的多任务网络在同一任务中得分为 85%。使用多任务学习的原因之一是因为在多任务上训练网络充当了一种正则化的形式。Sebastian Ruder 经历了多任务学习，并在这里谈到了一些<a class="ae jg" href="http://ruder.io/multi-task/index.html" rel="noopener ugc nofollow" target="_blank"/>。</p><p id="6750" class="pw-post-body-paragraph kg kh jj ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在不同的任务上训练一个网络比单独训练每个任务可以看到泛化能力的提高，因为网络因过度适应一个任务而受到惩罚。</p><p id="ffa1" class="pw-post-body-paragraph kg kh jj ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">这种性能提升也很有趣，因为当我向我的工作模型中添加更多类别时，随着更多任务的学习和网络获得比以前更多的主题专业知识，它可能会在以前的迭代中提供性能改进。</p><figure class="lf lg lh li gt iv gh gi paragraph-image"><div class="gh gi nm"><img src="../Images/82a32cd6cdfb52683e9f16071fd392ad.png" data-original-src="https://miro.medium.com/v2/resize:fit:802/format:webp/1*zf3gZz2Z2qfAA7kVEBR3lQ.png"/></div><figcaption class="jc jd gj gh gi je jf bd b be z dk">gnome (.778) rogue (.9112). Because of the way I constructed these classes paladin/warrior is mostly people wearing plate armor, rogue is for characters dressed fairly normally, and wizard/sorcerer is people with long robes who are using magic/have staffs. My fault, not really the model’s</figcaption></figure><h1 id="ebcf" class="lj lk jj bd ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg bi translated">结论:进行一次智慧检查</h1><figure class="lf lg lh li gt iv gh gi paragraph-image"><div class="gh gi nn"><img src="../Images/f108a56a751efd84ac2c5aaaf717cfbf.png" data-original-src="https://miro.medium.com/v2/resize:fit:912/format:webp/1*UpGkCjkIszKUFb9EFIn7BA.png"/></div><figcaption class="jc jd gj gh gi je jf bd b be z dk">humanoid (.995) wizard/sorcerer (.93). likely says wizard due to the robe-y feel?</figcaption></figure><p id="4d08" class="pw-post-body-paragraph kg kh jj ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">因为这主要是我在做实验，这方面还有很多需要改进的地方，我希望我会回顾这项工作，并从我攻击这个问题的方式中获得笑声。然而，就目前而言，这种方法似乎相对有前途，实施起来也不可怕。</p><p id="1953" class="pw-post-body-paragraph kg kh jj ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我认为，随机选择批次，而不是像我现在这样按顺序循环不同任务的批次，可能会提高性能，并给模型的训练周期增加更多变化。</p><p id="0796" class="pw-post-body-paragraph kg kh jj ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">对于计算损耗并将其反向传播回网络的最佳方式，也需要进行实验。我试着做了两个优化步骤，并得到了一些错误，这就是为什么我默认回到像其他多任务模型一样将损失加在一起。</p><p id="5497" class="pw-post-body-paragraph kg kh jj ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">也像其他多任务网络一样，我需要找出好的方法，在任务执行不良的情况下，改进特定的任务。</p><p id="93f1" class="pw-post-body-paragraph kg kh jj ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">即使有我认为可以改进的地方，这个管道对我目前的工作来说是一个很大的进步，也是我几个月来一直在纠结的一个问题。</p><p id="66e5" class="pw-post-body-paragraph kg kh jj ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">构建大型统一数据集既费时又费钱。也许之前的一些工作已经完成，所以在一个地方有特定类别的标签，另一个是全新的，所以你必须众包该类别的标签，第三个是来自一些已购买的数据集。在一个需要统一数据集的环境中，你需要做一些像我所做的工作一样的事情，我在每个问题上训练更小的模型，并用它来标记统一的数据集或支付众包标签。对于这两种情况，您需要花费大量精力来确保初始数据集和生成的标签都是干净和可用的，否则会有交叉污染的风险，并且最终模型的性能会下降。</p><p id="b238" class="pw-post-body-paragraph kg kh jj ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">您可以单独使用这三个数据集，并同时使用每个数据集对每个任务训练一个多任务网络，而不是找到某种方法来统一这三个数据集的标签以训练一个模型。这减少了需要训练的模型数量和需要进行的人工检查的数量。</p><p id="d781" class="pw-post-body-paragraph kg kh jj ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">能够使用为特定任务标记的数据集来训练多任务网络意味着您可以使用在任何给定点最有意义的任何方法来生成这些标签。</p><blockquote class="mo mp mq"><p id="237f" class="kg kh mr ki b kj kk kl km kn ko kp kq ms ks kt ku mt kw kx ky mu la lb lc ld im bi translated">这里是<a class="ae jg" href="https://github.com/sugi-chan/DnD_multi_task_multi_dataset" rel="noopener ugc nofollow" target="_blank">回购</a>的一般链接。它还包括一个笔记本，我只是在这个博客中使用的一堆不同的图像上运行这个模型。</p></blockquote><figure class="lf lg lh li gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi no"><img src="../Images/be64b56a65242e8fddc89e133552ac64.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*wR8k75ldGKNrUgTZN-Wa3A.png"/></div></div><figcaption class="jc jd gj gh gi je jf bd b be z dk">humanoid (.995) wizard/sorcerer(.964)</figcaption></figure></div></div>    
</body>
</html>