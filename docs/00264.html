<html>
<head>
<title>Andrew Ng’s Machine Learning Course in Python (Anomaly Detection)</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">吴恩达的 Python(异常检测)机器学习课程</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/andrew-ngs-machine-learning-course-in-python-anomaly-detection-1233d23dba95?source=collection_archive---------1-----------------------#2019-01-12">https://towardsdatascience.com/andrew-ngs-machine-learning-course-in-python-anomaly-detection-1233d23dba95?source=collection_archive---------1-----------------------#2019-01-12</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><figure class="gl gn jr js jt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi jq"><img src="../Images/941e27c1605831d7f656291e86ede35f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*nzmaKWTsXviRhsrYZDJcDA.png"/></div></div><figcaption class="kb kc gj gh gi kd ke bd b be z dk">Machine Learning — Andrew Ng</figcaption></figure><p id="82db" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi ld translated"><span class="l le lf lg bm lh li lj lk ll di"> T </span>这是吴恩达的机器学习课程 python 实现的最后一部分，我很高兴终于完成了这个系列。为了给你们一些视角，我花了一个月的时间将这些代码转换成 python，并为每个作业写了一篇文章。如果你们中的任何人正在犹豫要不要用 Python、R 或 Java 来实现，我强烈建议你们去做。从头开始编写这些算法不仅可以强化所教授的概念，还可以用自己熟悉的语言练习数据科学编程技能。</p><p id="1b1d" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">说了这么多，让我们进入最后一个编程作业</p></div><div class="ab cl lm ln hx lo" role="separator"><span class="lp bw bk lq lr ls"/><span class="lp bw bk lq lr ls"/><span class="lp bw bk lq lr"/></div><div class="im in io ip iq"><p id="b246" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">在这部分作业中，我们将使用高斯模型实现异常检测算法，首先检测 2D 数据集中的异常行为，然后检测高维数据集中的异常行为。</p><p id="e8da" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">加载相关的库和数据集</p><pre class="lt lu lv lw gt lx ly lz ma aw mb bi"><span id="8d6f" class="mc md it ly b gy me mf l mg mh">import numpy as np<br/>import matplotlib.pyplot as plt<br/>from scipy.io import loadmat</span><span id="854f" class="mc md it ly b gy mi mf l mg mh">mat = loadmat("ex8data1.mat")<br/>X = mat["X"]<br/>Xval = mat["Xval"]<br/>yval = mat["yval"]</span></pre><p id="2530" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">可视化数据</p><pre class="lt lu lv lw gt lx ly lz ma aw mb bi"><span id="b806" class="mc md it ly b gy me mf l mg mh">plt.scatter(X[:,0],X[:,1],marker="x")<br/>plt.xlim(0,30)<br/>plt.ylim(0,30)<br/>plt.xlabel("Latency (ms)")<br/>plt.ylabel("Throughput (mb/s)")</span></pre><figure class="lt lu lv lw gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi mj"><img src="../Images/85988bca9e39211fc1c3986338b5fb4f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1304/format:webp/1*-jQ3m4uYj9QowRaZlnJUCQ.png"/></div></div></figure><p id="3260" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">估计高斯模型的参数(均值和方差)</p><pre class="lt lu lv lw gt lx ly lz ma aw mb bi"><span id="ed38" class="mc md it ly b gy me mf l mg mh">def estimateGaussian(X):<br/>    """<br/>     This function estimates the parameters of a Gaussian distribution using the data in X<br/>    """<br/>    <br/>    m = X.shape[0]<br/>    <br/>    #compute mean<br/>    sum_ = np.sum(X,axis=0)<br/>    mu = 1/m *sum_<br/>    <br/>    # compute variance<br/>    var = 1/m * np.sum((X - mu)**2,axis=0)<br/>    <br/>    return mu,var</span><span id="2859" class="mc md it ly b gy mi mf l mg mh">mu, sigma2 = estimateGaussian(X)</span></pre><p id="e504" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">多元高斯分布是本课程的选修课，并给出了计算概率密度的代码。然而，为了让我继续这个任务，我需要从头开始编写<code class="fe mk ml mm ly b">multivariateGaussian </code>函数。</p><pre class="lt lu lv lw gt lx ly lz ma aw mb bi"><span id="5945" class="mc md it ly b gy me mf l mg mh">def multivariateGaussian(X, mu, sigma2):<br/>    """<br/>    Computes the probability density function of the multivariate gaussian distribution.<br/>    """<br/>    k = len(mu)<br/>    <br/>    sigma2=np.diag(sigma2)<br/>    X = X - mu.T<br/>    p = 1/((2*np.pi)**(k/2)*(np.linalg.det(sigma2)**0.5))* np.exp(-0.5* np.sum(X @ np.linalg.pinv(sigma2) * X,axis=1))<br/>    return p</span><span id="56e7" class="mc md it ly b gy mi mf l mg mh">p = multivariateGaussian(X, mu, sigma2)</span></pre><p id="a31b" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">我们在这里使用的一些有趣的函数来自 numpy 线性代数类。官方文件可以在<a class="ae mn" href="https://docs.scipy.org/doc/numpy-1.13.0/reference/routines.linalg.html" rel="noopener ugc nofollow" target="_blank">这里</a>找到。</p><p id="3649" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">一旦我们估计了高斯参数并获得了数据的概率密度，我们就可以可视化拟合。</p><pre class="lt lu lv lw gt lx ly lz ma aw mb bi"><span id="3ab1" class="mc md it ly b gy me mf l mg mh">plt.figure(figsize=(8,6))<br/>plt.scatter(X[:,0],X[:,1],marker="x")<br/>X1,X2 = np.meshgrid(np.linspace(0,35,num=70),np.linspace(0,35,num=70))<br/>p2 = multivariateGaussian(np.hstack((X1.flatten()[:,np.newaxis],X2.flatten()[:,np.newaxis])), mu, sigma2)<br/>contour_level = 10**np.array([np.arange(-20,0,3,dtype=np.float)]).T<br/>plt.contour(X1,X2,p2[:,np.newaxis].reshape(X1.shape),contour_level)<br/>plt.xlim(0,35)<br/>plt.ylim(0,35)<br/>plt.xlabel("Latency (ms)")<br/>plt.ylabel("Throughput (mb/s)")</span></pre><p id="7ce7" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">我之前没有解释过创建等高线图的过程，因为大多数都很简单。如果你理解起来有困难，这里的这篇文章可能会有所帮助。简单地说，我们首先在数据区域周围创建一个网格，并计算 Z 轴。<code class="fe mk ml mm ly b">plt.contour</code>然后使用 3 个轴(X，Y，Z)创建等高线图。</p><figure class="lt lu lv lw gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi mo"><img src="../Images/de5032d84e910f9d8be2c9ce29af2638.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ES7ov4IIQjvxnMhCXTrzPQ.png"/></div></div></figure><p id="2047" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">现在选择一个阈值，将一个示例标记为异常。</p><pre class="lt lu lv lw gt lx ly lz ma aw mb bi"><span id="e84d" class="mc md it ly b gy me mf l mg mh">def selectThreshold(yval, pval):<br/>    """<br/>    Find the best threshold (epsilon) to use for selecting outliers<br/>    """<br/>    best_epi = 0<br/>    best_F1 = 0<br/>    <br/>    stepsize = (max(pval) -min(pval))/1000<br/>    epi_range = np.arange(pval.min(),pval.max(),stepsize)<br/>    for epi in epi_range:<br/>        predictions = (pval&lt;epi)[:,np.newaxis]<br/>        tp = np.sum(predictions[yval==1]==1)<br/>        fp = np.sum(predictions[yval==0]==1)<br/>        fn = np.sum(predictions[yval==1]==0)<br/>        <br/>        # compute precision, recall and F1<br/>        prec = tp/(tp+fp)<br/>        rec = tp/(tp+fn)<br/>        <br/>        F1 = (2*prec*rec)/(prec+rec)<br/>        <br/>        if F1 &gt; best_F1:<br/>            best_F1 =F1<br/>            best_epi = epi<br/>        <br/>    return best_epi, best_F1</span><span id="72dc" class="mc md it ly b gy mi mf l mg mh">pval = multivariateGaussian(Xval, mu, sigma2)<br/>epsilon, F1 = selectThreshold(yval, pval)<br/>print("Best epsilon found using cross-validation:",epsilon)<br/>print("Best F1 on Cross Validation Set:",F1)</span></pre><figure class="lt lu lv lw gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi mp"><img src="../Images/1d99bf0f70b41a71bd99b04f887c9fb7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ig43i9RkSkKB-g-WNx_gLQ.png"/></div></div></figure><p id="1b30" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">如果您没有注意到，这里使用 F1 分数而不是准确性，因为数据集是高度不平衡的。为了了解更多关于评估机器学习模型性能的各种方法，这篇文章很好地总结了这个主题。</p><p id="b8b5" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">可视化最佳阈值</p><pre class="lt lu lv lw gt lx ly lz ma aw mb bi"><span id="c753" class="mc md it ly b gy me mf l mg mh">plt.figure(figsize=(8,6))</span><span id="9fe9" class="mc md it ly b gy mi mf l mg mh"># plot the data<br/>plt.scatter(X[:,0],X[:,1],marker="x")</span><span id="baea" class="mc md it ly b gy mi mf l mg mh"># potting of contour<br/>X1,X2 = np.meshgrid(np.linspace(0,35,num=70),np.linspace(0,35,num=70))<br/>p2 = multivariateGaussian(np.hstack((X1.flatten()[:,np.newaxis],X2.flatten()[:,np.newaxis])), mu, sigma2)<br/>contour_level = 10**np.array([np.arange(-20,0,3,dtype=np.float)]).T<br/>plt.contour(X1,X2,p2[:,np.newaxis].reshape(X1.shape),contour_level)</span><span id="e357" class="mc md it ly b gy mi mf l mg mh"># Circling of anomalies<br/>outliers = np.nonzero(p&lt;epsilon)[0]<br/>plt.scatter(X[outliers,0],X[outliers,1],marker ="o",facecolor="none",edgecolor="r",s=70)</span><span id="8ef9" class="mc md it ly b gy mi mf l mg mh">plt.xlim(0,35)<br/>plt.ylim(0,35)<br/>plt.xlabel("Latency (ms)")<br/>plt.ylabel("Throughput (mb/s)")</span></pre><figure class="lt lu lv lw gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi mq"><img src="../Images/11aef18dea8883e268ccd94a85148765.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*fkUgOrJBqI0q7fd8xRiLZQ.png"/></div></div></figure><p id="9edc" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">对于高维数据集，我们只需遵循与之前完全相同的步骤</p><pre class="lt lu lv lw gt lx ly lz ma aw mb bi"><span id="8ab4" class="mc md it ly b gy me mf l mg mh">mat2 = loadmat("ex8data2.mat")<br/>X2 = mat2["X"]<br/>Xval2 = mat2["Xval"]<br/>yval2 = mat2["yval"]</span><span id="b728" class="mc md it ly b gy mi mf l mg mh"># compute the mean and variance<br/>mu2, sigma2_2 = estimateGaussian(X2)</span><span id="2dbb" class="mc md it ly b gy mi mf l mg mh"># Training set<br/>p3 = multivariateGaussian(X2, mu2, sigma2_2)</span><span id="7509" class="mc md it ly b gy mi mf l mg mh"># cross-validation set<br/>pval2 = multivariateGaussian(Xval2, mu2, sigma2_2)</span><span id="4b5c" class="mc md it ly b gy mi mf l mg mh"># Find the best threshold<br/>epsilon2, F1_2 = selectThreshold(yval2, pval2)<br/>print("Best epsilon found using cross-validation:",epsilon2)<br/>print("Best F1 on Cross Validation Set:",F1_2)<br/>print("# Outliers found:",np.sum(p3&lt;epsilon2))</span></pre><figure class="lt lu lv lw gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi mr"><img src="../Images/b0148e0027d21f05eddf17827a85271f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*LhK8_XQjllW6LHsXAnJ_8g.png"/></div></div></figure></div><div class="ab cl lm ln hx lo" role="separator"><span class="lp bw bk lq lr ls"/><span class="lp bw bk lq lr ls"/><span class="lp bw bk lq lr"/></div><div class="im in io ip iq"><p id="fb6d" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">作业的第二部分包括实现一个协作过滤算法来建立一个电影分级推荐系统。</p><p id="da72" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">电影分级数据集的加载和可视化</p><pre class="lt lu lv lw gt lx ly lz ma aw mb bi"><span id="0d41" class="mc md it ly b gy me mf l mg mh">mat3 = loadmat("ex8_movies.mat")<br/>mat4 = loadmat("ex8_movieParams.mat")<br/>Y = mat3["Y"] # 1682 X 943 matrix, containing ratings (1-5) of 1682 movies on 943 user<br/>R = mat3["R"] # 1682 X 943 matrix, where R(i,j) = 1 if and only if user j give rating to movie i<br/>X = mat4["X"] # 1682 X 10 matrix , num_movies X num_features matrix of movie features<br/>Theta = mat4["Theta"] # 943 X 10 matrix, num_users X num_features matrix of user features</span><span id="4541" class="mc md it ly b gy mi mf l mg mh"># Compute average rating <br/>print("Average rating for movie 1 (Toy Story):",np.sum(Y[0,:]*R[0,:])/np.sum(R[0,:]),"/5")</span></pre><p id="5e23" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">打印语句将打印:<code class="fe mk ml mm ly b">Average rating for movie 1 (Toy Story): 3.8783185840707963 /5</code></p><pre class="lt lu lv lw gt lx ly lz ma aw mb bi"><span id="af5f" class="mc md it ly b gy me mf l mg mh">plt.figure(figsize=(8,16))<br/>plt.imshow(Y)<br/>plt.xlabel("Users")<br/>plt.ylabel("Movies")</span></pre><figure class="lt lu lv lw gt ju gh gi paragraph-image"><div class="gh gi ms"><img src="../Images/02641d7f9224f424bfd84f5e714b26f3.png" data-original-src="https://miro.medium.com/v2/resize:fit:940/format:webp/1*oIMgiEK8vZZM6zOxzHk-RQ.png"/></div></figure><p id="bce4" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">进入算法本身，我们从计算成本函数和梯度开始</p><pre class="lt lu lv lw gt lx ly lz ma aw mb bi"><span id="0c54" class="mc md it ly b gy me mf l mg mh">def  cofiCostFunc(params, Y, R, num_users, num_movies, num_features, Lambda):<br/>    """<br/>    Returns the cost and gradient for the collaborative filtering problem<br/>    """<br/>    <br/>    # Unfold the params<br/>    X = params[:num_movies*num_features].reshape(num_movies,num_features)<br/>    Theta = params[num_movies*num_features:].reshape(num_users,num_features)<br/>    <br/>    predictions =  X @ Theta.T<br/>    err = (predictions - Y)<br/>    J = 1/2 * np.sum((err**2) * R)<br/>    <br/>    #compute regularized cost function<br/>    reg_X =  Lambda/2 * np.sum(Theta**2)<br/>    reg_Theta = Lambda/2 *np.sum(X**2)<br/>    reg_J = J + reg_X + reg_Theta<br/>    <br/>    # Compute gradient<br/>    X_grad = err*R @ Theta<br/>    Theta_grad = (err*R).T @ X<br/>    grad = np.append(X_grad.flatten(),Theta_grad.flatten())<br/>    <br/>    # Compute regularized gradient<br/>    reg_X_grad = X_grad + Lambda*X<br/>    reg_Theta_grad = Theta_grad + Lambda*Theta<br/>    reg_grad = np.append(reg_X_grad.flatten(),reg_Theta_grad.flatten())<br/>    <br/>    return J, grad, reg_J, reg_grad</span></pre><p id="78da" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">与前面的方法类似，该任务要求我们在单独的步骤中计算成本函数、梯度、正则化成本函数，然后正则化梯度。只要你使用正确的索引，上面的代码块将允许你一步一步地跟随任务。</p><p id="233a" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">为了测试我们的成本函数，</p><pre class="lt lu lv lw gt lx ly lz ma aw mb bi"><span id="b2f8" class="mc md it ly b gy me mf l mg mh"># Reduce the data set size to run faster<br/>num_users, num_movies, num_features = 4,5,3<br/>X_test = X[:num_movies,:num_features]<br/>Theta_test= Theta[:num_users,:num_features]<br/>Y_test = Y[:num_movies,:num_users]<br/>R_test = R[:num_movies,:num_users]<br/>params = np.append(X_test.flatten(),Theta_test.flatten())</span><span id="0ada" class="mc md it ly b gy mi mf l mg mh"># Evaluate cost function<br/>J, grad = cofiCostFunc(params, Y_test, R_test, num_users, num_movies, num_features, 0)[:2]<br/>print("Cost at loaded parameters:",J)</span><span id="b5e2" class="mc md it ly b gy mi mf l mg mh">J2, grad2 = cofiCostFunc(params, Y_test, R_test, num_users, num_movies, num_features, 1.5)[2:]<br/>print("Cost at loaded parameters (lambda = 1.5):",J2)</span></pre><figure class="lt lu lv lw gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi mt"><img src="../Images/b25752f177860f42de3c6bb70b18f88a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*WtaNsebQKV-dQ_MMpQHXzw.png"/></div></div></figure><p id="8188" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">一旦我们得到了我们的成本函数和梯度，我们可以开始训练我们的算法。</p><p id="e73c" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">加载电影列表</p><pre class="lt lu lv lw gt lx ly lz ma aw mb bi"><span id="c5c5" class="mc md it ly b gy me mf l mg mh"># load movie list<br/>movieList = open("movie_ids.txt","r").read().split("\n")[:-1]</span><span id="1300" class="mc md it ly b gy mi mf l mg mh"># see movie list<br/>np.set_printoptions(threshold=np.nan)<br/>movieList</span></pre><figure class="lt lu lv lw gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi mu"><img src="../Images/7ab022300e41954b6b7df169b19f5d46.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*V5FKzEfPt1lnGWgzvr2gWQ.png"/></div></div></figure><p id="d084" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">你可以在这一步输入你自己的电影偏好，但我使用了与作业完全相同的评分来保持一致。</p><pre class="lt lu lv lw gt lx ly lz ma aw mb bi"><span id="4a8f" class="mc md it ly b gy me mf l mg mh"># Initialize my ratings<br/>my_ratings = np.zeros((1682,1))</span><span id="4d5f" class="mc md it ly b gy mi mf l mg mh"># Create own ratings<br/>my_ratings[0] = 4 <br/>my_ratings[97] = 2<br/>my_ratings[6] = 3<br/>my_ratings[11]= 5<br/>my_ratings[53] = 4<br/>my_ratings[63]= 5<br/>my_ratings[65]= 3<br/>my_ratings[68] = 5<br/>my_ratings[82]= 4<br/>my_ratings[225] = 5<br/>my_ratings[354]= 5</span><span id="8cdd" class="mc md it ly b gy mi mf l mg mh">print("New user ratings:\n")<br/>for i in range(len(my_ratings)):<br/>    if my_ratings[i]&gt;0:<br/>        print("Rated",int(my_ratings[i]),"for index",movieList[i])</span></pre><figure class="lt lu lv lw gt ju gh gi paragraph-image"><div class="gh gi mv"><img src="../Images/d9b5cf0ec72b816b24a1b4c027622f3a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1382/format:webp/1*UKjPFoGNuV5cXEzradMLZw.png"/></div></figure><p id="fc15" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">为了在输入到算法中之前准备我们的数据，我们需要标准化评级，设置一些随机的初始参数，并使用优化算法来更新参数。</p><pre class="lt lu lv lw gt lx ly lz ma aw mb bi"><span id="04fd" class="mc md it ly b gy me mf l mg mh">def normalizeRatings(Y, R):<br/>    """<br/>    normalized Y so that each movie has a rating of 0 on average, and returns the mean rating in Ymean.<br/>    """<br/>    <br/>    m,n = Y.shape[0], Y.shape[1]<br/>    Ymean = np.zeros((m,1))<br/>    Ynorm = np.zeros((m,n))<br/>    <br/>    for i in range(m):<br/>        Ymean[i] = np.sum(Y[i,:])/np.count_nonzero(R[i,:])<br/>        Ynorm[i,R[i,:]==1] = Y[i,R[i,:]==1] - Ymean[i]<br/>        <br/>    return Ynorm, Ymean</span><span id="7883" class="mc md it ly b gy mi mf l mg mh">def gradientDescent(initial_parameters,Y,R,num_users,num_movies,num_features,alpha,num_iters,Lambda):<br/>    """<br/>    Optimize X and Theta<br/>    """<br/>    # unfold the parameters<br/>    X = initial_parameters[:num_movies*num_features].reshape(num_movies,num_features)<br/>    Theta = initial_parameters[num_movies*num_features:].reshape(num_users,num_features)<br/>    <br/>    J_history =[]<br/>    <br/>    for i in range(num_iters):<br/>        params = np.append(X.flatten(),Theta.flatten())<br/>        cost, grad = cofiCostFunc(params, Y, R, num_users, num_movies, num_features, Lambda)[2:]<br/>        <br/>        # unfold grad<br/>        X_grad = grad[:num_movies*num_features].reshape(num_movies,num_features)<br/>        Theta_grad = grad[num_movies*num_features:].reshape(num_users,num_features)<br/>        X = X - (alpha * X_grad)<br/>        Theta = Theta - (alpha * Theta_grad)<br/>        J_history.append(cost)<br/>    <br/>    paramsFinal = np.append(X.flatten(),Theta.flatten())<br/>    return paramsFinal , J_history</span></pre><p id="44eb" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">再次，我选择批量梯度下降作为我的优化算法。在 python 中完成所有编程任务教会我的一件事是，梯度下降很少出错。在这一点上，梯度下降的代码应该是相当熟悉的。</p><pre class="lt lu lv lw gt lx ly lz ma aw mb bi"><span id="90cd" class="mc md it ly b gy me mf l mg mh">Y = np.hstack((my_ratings,Y))<br/>R =np.hstack((my_ratings!=0,R))</span><span id="68ef" class="mc md it ly b gy mi mf l mg mh"># Normalize Ratings<br/>Ynorm, Ymean = normalizeRatings(Y, R)</span><span id="7789" class="mc md it ly b gy mi mf l mg mh">num_users = Y.shape[1]<br/>num_movies = Y.shape[0]<br/>num_features = 10</span><span id="9cb8" class="mc md it ly b gy mi mf l mg mh"># Set initial Parameters (Theta,X)<br/>X = np.random.randn(num_movies, num_features)<br/>Theta = np.random.randn(num_users, num_features)<br/>initial_parameters = np.append(X.flatten(),Theta.flatten())<br/>Lambda = 10</span><span id="6777" class="mc md it ly b gy mi mf l mg mh"># Optimize parameters using Gradient Descent<br/>paramsFinal, J_history = gradientDescent(initial_parameters,Y,R,num_users,num_movies,num_features,0.001,400,Lambda)</span></pre><p id="3424" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">绘制成本函数以确保梯度下降有效</p><pre class="lt lu lv lw gt lx ly lz ma aw mb bi"><span id="eb2b" class="mc md it ly b gy me mf l mg mh">plt.plot(J_history)<br/>plt.xlabel("Iteration")<br/>plt.ylabel("$J(\Theta)$")<br/>plt.title("Cost function using Gradient Descent")</span></pre><figure class="lt lu lv lw gt ju gh gi paragraph-image"><div class="gh gi mw"><img src="../Images/7f1819c4b461603ba45d7bc121f37f56.png" data-original-src="https://miro.medium.com/v2/resize:fit:1362/format:webp/1*hpDFRwToEkN4IMun-jC3GQ.png"/></div></figure><p id="dc20" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">对你没有评级的电影进行预测</p><pre class="lt lu lv lw gt lx ly lz ma aw mb bi"><span id="c2bf" class="mc md it ly b gy me mf l mg mh"># unfold paramaters<br/>X = paramsFinal[:num_movies*num_features].reshape(num_movies,num_features)<br/>Theta = paramsFinal[num_movies*num_features:].reshape(num_users,num_features)</span><span id="0555" class="mc md it ly b gy mi mf l mg mh"># Predict rating<br/>p = X @ Theta.T<br/>my_predictions = p[:,0][:,np.newaxis] + Ymean</span><span id="bf05" class="mc md it ly b gy mi mf l mg mh">import pandas as pd<br/>df = pd.DataFrame(np.hstack((my_predictions,np.array(movieList)[:,np.newaxis])))<br/>df.sort_values(by=[0],ascending=False,inplace=True)<br/>df.reset_index(drop=True,inplace=True)</span><span id="6e26" class="mc md it ly b gy mi mf l mg mh">print("Top recommendations for you:\n")<br/>for i in range(10):<br/>    print("Predicting rating",round(float(df[0][i]),1)," for index",df[1][i])</span></pre><figure class="lt lu lv lw gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi mx"><img src="../Images/90e4fc2e69e5c7a7e36ef73f99ebdf1f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*0ro80HbJF7XGnVaQWkJVvA.png"/></div></div></figure></div><div class="ab cl lm ln hx lo" role="separator"><span class="lp bw bk lq lr ls"/><span class="lp bw bk lq lr ls"/><span class="lp bw bk lq lr"/></div><div class="im in io ip iq"><p id="b8fd" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">最后，我结束了吴恩达的 Python 机器学习课程。我希望这对你和我写这篇文章一样有益，我感谢你们所有人的支持。</p><p id="e9b9" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">Jupyter 笔记本会上传到我的 GitHub 上(<a class="ae mn" href="https://github.com/Benlau93/Machine-Learning-by-Andrew-Ng-in-Python" rel="noopener ugc nofollow" target="_blank">https://GitHub . com/Ben lau 93/Machine-Learning-by-Andrew-Ng-in-Python</a>)。</p><p id="5d56" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">对于本系列中的其他 python 实现，</p><ul class=""><li id="4ab9" class="my mz it kh b ki kj km kn kq na ku nb ky nc lc nd ne nf ng bi translated"><a class="ae mn" href="https://medium.com/@ben_lau93/andrew-ngs-machine-learning-course-in-python-linear-regression-dd04fba8e137" rel="noopener">线性回归</a></li><li id="71e4" class="my mz it kh b ki nh km ni kq nj ku nk ky nl lc nd ne nf ng bi translated"><a class="ae mn" href="https://medium.com/@ben_lau93/andrew-ngs-machine-learning-course-in-python-logistic-regression-c0ae25509feb" rel="noopener">逻辑回归</a></li><li id="acb3" class="my mz it kh b ki nh km ni kq nj ku nk ky nl lc nd ne nf ng bi translated"><a class="ae mn" href="https://medium.com/@ben_lau93/andrew-ngs-machine-learning-course-in-python-regularized-logistic-regression-lasso-regression-721f311130fb" rel="noopener">正则化逻辑回归</a></li><li id="d3d9" class="my mz it kh b ki nh km ni kq nj ku nk ky nl lc nd ne nf ng bi translated"><a class="ae mn" rel="noopener" target="_blank" href="/andrew-ngs-machine-learning-course-in-python-neural-networks-e526b41fdcd9">神经网络</a></li><li id="8969" class="my mz it kh b ki nh km ni kq nj ku nk ky nl lc nd ne nf ng bi translated"><a class="ae mn" href="https://medium.com/@ben_lau93/andrew-ngs-machine-learning-course-in-python-support-vector-machines-435fc34b7bf9" rel="noopener">支持向量机</a></li><li id="e465" class="my mz it kh b ki nh km ni kq nj ku nk ky nl lc nd ne nf ng bi translated"><a class="ae mn" rel="noopener" target="_blank" href="/andrew-ngs-machine-learning-course-in-python-kmeans-clustering-pca-b7ba6fafa74">无监督学习</a></li></ul><p id="a72e" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">感谢您的阅读。</p></div></div>    
</body>
</html>