<html>
<head>
<title>Exploratory Data Analysis, Categorical Data — Part II</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">探索性数据分析，分类数据—第二部分</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/exploratory-data-analysis-categorical-data-part-ii-5de835850f0f?source=collection_archive---------13-----------------------#2019-12-04">https://towardsdatascience.com/exploratory-data-analysis-categorical-data-part-ii-5de835850f0f?source=collection_archive---------13-----------------------#2019-12-04</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><figure class="ip iq gp gr ir is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi io"><img src="../Images/12b3271ea40f0686e4d763365f3de868.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Aj4WB0XSkHL5rSAJf_taPA.png"/></div></div></figure><div class=""/><p id="0441" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated"><em class="kw">“想出新功能很困难，很耗时，需要专业知识。‘应用机器学习’基本上是特征工程。”</em></p><p id="4f8f" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated"><em class="kw"> —吴恩达教授。</em></p><p id="e5d8" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">数据科学家花费将近 75%的时间来分析数据和工程特性，这确实是一个困难且耗时的过程。他们需要领域知识和数学计算。</p><p id="c877" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">探索性数据分析和特征工程是选择、描绘和转换数据为特征的过程，这些特征可以作为机器学习模型的输入来进行预测。我们应该记住，好的质量特性总是有助于提高<em class="kw"> </em>整体模型性能。很多时候，即使机器学习任务在不同的场景中可以是相同的，但是在分析每个场景中的数据之后提取的特征将会彼此不同。</p><figure class="ky kz la lb gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi kx"><img src="../Images/cf1441e187d1acd99eab77eb65c7e322.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*T80hVP6TIeWUMJPMFUkXKw.png"/></div></div></figure><p id="2b73" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">上述数据集具有特征<em class="kw">“预测 _ 类别”</em>，该特征基于在特征<em class="kw">“清洁 _hm”中呈现的人的陈述来检测该人的情绪。"</em> <strong class="ka jc">原始特征"<em class="kw"> </em> </strong>直接从数据集中获得，无需额外的数据操作或工程，而"<strong class="ka jc">衍生特征"</strong>从特征工程中获得，其中我们从现有数据属性中提取特征。</p><pre class="ky kz la lb gt lc ld le lf aw lg bi"><span id="7bb0" class="lh li jb ld b gy lj lk l ll lm">nycdata = pd.read_csv(“train.csv”)<br/>nycdata.head(5)</span></pre><figure class="ky kz la lb gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi ln"><img src="../Images/b7ac2820a981fecd8097c4cc66ebf227.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*CIF9orjCJ4JnjK-0Xp9TUw.png"/></div></div><figcaption class="lo lp gj gh gi lq lr bd b be z dk">Raw features</figcaption></figure><pre class="ky kz la lb gt lc ld le lf aw lg bi"><span id="af0a" class="lh li jb ld b gy lj lk l ll lm">nycdata.shape</span><span id="52b9" class="lh li jb ld b gy ls lk l ll lm">(50000, 8)</span></pre><p id="e058" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">现在，在完成某些功能工程后，让我们检查:</p><pre class="ky kz la lb gt lc ld le lf aw lg bi"><span id="99f3" class="lh li jb ld b gy lj lk l ll lm">nycdata.head(5)</span></pre><figure class="ky kz la lb gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi lt"><img src="../Images/861bc85d3c76dfd8f91bfdee774b82fc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*kOtrLjoTBIRyIWpx8Co4Cw.png"/></div></div></figure><pre class="ky kz la lb gt lc ld le lf aw lg bi"><span id="d919" class="lh li jb ld b gy lj lk l ll lm">nycdata.shape</span><span id="2cb3" class="lh li jb ld b gy ls lk l ll lm">(50000, 12)</span></pre><p id="ffa1" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">因此，我们通过特征工程从原始数据集中又提取了 4 个特征。</p><p id="a6c8" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">在本文中，我将处理数据分析和<strong class="ka jc">分类数据的一点特性工程。</strong></p><p id="0ddd" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">让我们考虑一个简单的例子，人们的陈述决定了他们的情绪。现在，如果我认为在这个数据集中所有人都是幸福的，幸福被分为几类——爱、成就、休闲、亲密。例如，某人在工作中获得了提升，他很高兴，这意味着<em class="kw">【成就】</em>，而另一个人很高兴，因为他在很长一段时间后与朋友进行了热烈的交谈，这清楚地表明了<em class="kw">【感情】</em>，一位母亲很高兴，因为她孩子的生日再次表明了<em class="kw">【感情】。</em>我们可以清楚地看到这里没有办法对“<em class="kw">幸福</em>属性的这些值进行排序。</p><p id="83c1" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">但是有一些有序的分类数据，如鞋码、t 恤尺寸或教育水平等。它们遵循特定的顺序。</p><p id="03be" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">我更喜欢总是从加载所有必需的依赖项开始。</p><pre class="ky kz la lb gt lc ld le lf aw lg bi"><span id="8c12" class="lh li jb ld b gy lj lk l ll lm">import numpy as np #linear algebra<br/>import pandas as pd #data processing<br/>import os #operating system dependent modules of python<br/>import matplotlib.pyplot as plt #visualization<br/>import seaborn as sns #visualization<br/>%matplotlib inline<br/>from nltk.corpus import stopwords<br/>from nltk.stem import PorterStemmer<br/>from sklearn.preprocessing import LabelEncoder<br/>import re<br/>from wordcloud import WordCloud, ImageColorGenerator<br/>from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer</span></pre><p id="2d06" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">正在加载。csv 文件</p><p id="87a6" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated"><code class="fe lu lv lw ld b">at.head(5)</code></p><figure class="ky kz la lb gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi lx"><img src="../Images/9a0965fbec9bd120e4350f6a1f7bed51.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*WV-obprJfGRNKwTXTFNp5A.png"/></div></div></figure><p id="b301" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">让我们获取数据集的信息。</p><pre class="ky kz la lb gt lc ld le lf aw lg bi"><span id="2a66" class="lh li jb ld b gy lj lk l ll lm">at.info()</span><span id="37cc" class="lh li jb ld b gy ls lk l ll lm">Output--</span><span id="b900" class="lh li jb ld b gy ls lk l ll lm">&lt;class 'pandas.core.frame.DataFrame'&gt;<br/>RangeIndex: 60321 entries, 0 to 60320<br/>Data columns (total 5 columns):<br/>hmid                  60321 non-null int64<br/>reflection_period     60321 non-null object<br/>cleaned_hm            60321 non-null object<br/>num_sentence          60321 non-null int64<br/>predicted_category    60321 non-null object<br/>dtypes: int64(2), object(3)<br/>memory usage: 2.3+ MB</span></pre><p id="ac08" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">如果一个大数据集有几个特性，我可以通过以下命令获得所有特性的名称:</p><pre class="ky kz la lb gt lc ld le lf aw lg bi"><span id="644b" class="lh li jb ld b gy lj lk l ll lm">dataset.columns</span></pre><p id="19b4" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">数据集的详细信息通过以下方式获得:</p><pre class="ky kz la lb gt lc ld le lf aw lg bi"><span id="4f77" class="lh li jb ld b gy lj lk l ll lm">at.describe()</span></pre><figure class="ky kz la lb gt is gh gi paragraph-image"><div class="gh gi ly"><img src="../Images/a93fc20c9024230ab821b2dcb9537c3c.png" data-original-src="https://miro.medium.com/v2/resize:fit:626/format:webp/1*2SOxKU-A5FxHQVE13r5SWw.png"/></div></figure><p id="476c" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">我可以得到那些有数字数据的特征的描述。如果我需要所有功能的描述，我会使用:</p><pre class="ky kz la lb gt lc ld le lf aw lg bi"><span id="dcbc" class="lh li jb ld b gy lj lk l ll lm">at.describe(include='all')</span></pre><p id="ba9e" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">这是一种描述性统计，用于总结数据集分布的集中趋势、分散和形状。</p><p id="9100" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated"><strong class="ka jc">编码分类变量:</strong></p><p id="060b" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">我需要根据句子预测<em class="kw">【幸福】</em>。最初，我为<em class="kw">“幸福”的不同标签绘制了一个索引:</em></p><pre class="ky kz la lb gt lc ld le lf aw lg bi"><span id="85ef" class="lh li jb ld b gy lj lk l ll lm">from sklearn.preprocessing import LabelEncoder<br/>cols = [‘predicted_category’]<br/>lbl = LabelEncoder()<br/>pred_lbl = lbl.fit_transform(at[cols])</span><span id="78e5" class="lh li jb ld b gy ls lk l ll lm">mappings = {index: label for index, label in enumerate(lbl.classes_)}<br/>mappings</span><span id="5616" class="lh li jb ld b gy ls lk l ll lm">{0: 'achievement',<br/> 1: 'affection',<br/> 2: 'bonding',<br/> 3: 'enjoy_the_moment',<br/> 4: 'exercise',<br/> 5: 'leisure',<br/> 6: 'nature'}</span></pre><p id="ce6b" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">通过函数<em class="kw">“标签编码器”</em>，一个对象<em class="kw">“LBL”</em>将一个数字映射到<em class="kw">“预测 _ 类别”</em>特征的每一个值。</p><p id="2c50" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">现在，我需要对我们的分类变量应用一个特定的编码方案。原因很简单。如果我直接将<code class="fe lu lv lw ld b">pred_lbl</code>属性作为机器学习模型中的一个特征，它会认为它是一个连续的数字特征，认为值 6(<em class="kw">Nature’</em>)大于 2(‘Bonding’)，但这是没有意义的，因为<em class="kw">‘Nature’</em>肯定不会大于或小于’<em class="kw">Bonding’</em>，这些实际上是不能直接比较的类别。因此，我需要一个额外的编码方案层，其中需要为每个唯一值创建虚拟特征。</p><pre class="ky kz la lb gt lc ld le lf aw lg bi"><span id="19f2" class="lh li jb ld b gy lj lk l ll lm">dummy_features = pd.get_dummies(at['predicted_category'])<br/>at=pd.concat([at[['hmid','cleaned_hm']],dummy_features],axis=1)<br/>at.head(9)</span></pre><figure class="ky kz la lb gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi lz"><img src="../Images/4df2c16a0b2c6156ee6aeafe2b2c2d08.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*K8fTRx9lEConIBaQxU2u5Q.png"/></div></div></figure><p id="cef7" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">由于我们的预测 _ 类别仅取决于人们的陈述，因此我们考虑了<em class="kw">“cleaned _ hm”</em>以及<em class="kw">“hmid”</em></p><p id="91e4" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated"><strong class="ka jc">清洁和预处理原始文本:</strong></p><p id="6c43" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">特征“cleaned_hm”包含了我们需要清理的杂乱的原始数据。</p><pre class="ky kz la lb gt lc ld le lf aw lg bi"><span id="b41a" class="lh li jb ld b gy lj lk l ll lm">stops = set(stopwords.words("english"))<br/>def cleanData(text, lowercase = False, remove_stops = False, stemming = False):<br/>    txt = str(text)<br/>#print(txt)<br/>    txt = re.sub(r'[^A-Za-z0-9\s]',r'',txt)<br/>#print(txt)<br/>    txt = re.sub(r'\n',r' ',txt)<br/>#print(txt)<br/>    <br/>#convert whole text to lower case &amp; remove stopwords and stemmers<br/>    if lowercase:<br/>        txt = " ".join([w.lower() for w in txt.split()])<br/>    <br/>    if remove_stops:<br/>        txt = " ".join([w for w in txt.split() if w not in stops])<br/>    <br/>    if stemming:<br/>        st = PorterStemmer()<br/>        txt = " ".join([st.stem(w) for w in txt.split()])<br/>#print(txt)<br/>    return txt</span><span id="da9f" class="lh li jb ld b gy ls lk l ll lm"># clean description<br/>at['cleaned_hm'] = at['cleaned_hm'].map(lambda x: cleanData(x, lowercase=True, remove_stops=True, stemming=True))</span></pre><figure class="ky kz la lb gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi ma"><img src="../Images/049da93e93fecccb5b992f53e5934783.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*CMeudCHJa-DbsEq70aAnDw.png"/></div></div></figure><p id="dbfb" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">与原始数据集不同，我现在有一个非常紧凑的信息，可以将我的数据输入到机器学习中。函数<em class="kw">“clean data”</em>删除了不需要的标点符号和单词，并将其转换为完整的小写字母。</p><p id="8f87" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">现在，除了<em class="kw">“cleaned _ hm”</em>，我所有的特征都是数字格式。我必须找到出现频率最高的单词。使用 WordCloud 也可以达到同样的效果。</p><pre class="ky kz la lb gt lc ld le lf aw lg bi"><span id="1fa6" class="lh li jb ld b gy lj lk l ll lm">#use word cloud to understand the word that has the most frequency<br/>text = ' '.join(at['cleaned_hm'].tolist())<br/>text = text.lower()<br/>wordcloud = WordCloud(background_color="white", height=2700, width=3600).generate(text)<br/>plt.figure( figsize=(14,8) )<br/>plt.imshow(wordcloud.recolor(colormap=plt.get_cmap('Set2')), interpolation='bilinear')<br/>plt.axis("off")</span></pre><p id="b3ea" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated"><strong class="ka jc">矢量化:</strong></p><p id="7369" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">为了理解可以在我们的机器学习模型中使用的特征<em class="kw">“cleaned _ hm”</em>，我们需要将每个语句转换为数字表示，我们称之为<em class="kw">矢量化。</em></p><p id="8e52" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">下一次我们将讨论各种矢量化的细节以及如何使用它们。</p></div></div>    
</body>
</html>