<html>
<head>
<title>The skin in the game heuristic for protection against disasters</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">游戏中的皮肤启发防止灾难</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/the-skin-in-the-game-heuristic-for-protection-against-disasters-eaa7bda8b026?source=collection_archive---------35-----------------------#2019-10-10">https://towardsdatascience.com/the-skin-in-the-game-heuristic-for-protection-against-disasters-eaa7bda8b026?source=collection_archive---------35-----------------------#2019-10-10</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="f0ad" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">为什么缺乏个人风险会将整个系统置于危险之中</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ki"><img src="../Images/9e34e84ed194b7e15bdddab1727bdb53.png" data-original-src="https://miro.medium.com/v2/resize:fit:684/format:webp/1*Inu1oFqkGUhbBC3tRdH8Ow.jpeg"/></div></figure><h1 id="846f" class="kq kr it bd ks kt ku kv kw kx ky kz la jz lb ka lc kc ld kd le kf lf kg lg lh bi translated"><strong class="ak">简介</strong></h1><p id="931f" class="pw-post-body-paragraph li lj it lk b ll lm ju ln lo lp jx lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated"><em class="me">“如果一个建筑者为一个人建造了一座房子，却不把建造的声音发出来，一堵墙裂开了，建筑者应该自费加固那堵墙。</em></p><p id="46c3" class="pw-post-body-paragraph li lj it lk b ll mf ju ln lo mg jx lq lr mh lt lu lv mi lx ly lz mj mb mc md im bi translated"><em class="me">“如果建筑者为一个人建造房屋，却不把建造的声音发出来，他所建造的房屋就倒塌了，导致房屋主人的死亡，那么建筑者就要被处死。</em></p><p id="a792" class="pw-post-body-paragraph li lj it lk b ll mf ju ln lo mg jx lq lr mh lt lu lv mi lx ly lz mj mb mc md im bi translated">人们可以在古老的汉谟拉比法典中找到这些规则，作为道德和风险管理策略的基础。</p><p id="a165" class="pw-post-body-paragraph li lj it lk b ll mf ju ln lo mg jx lq lr mh lt lu lv mi lx ly lz mj mb mc md im bi translated">生活中很常见的一件事是，为一项成就邀功，但却掩盖失败或责怪他人。当事情进展顺利时，我们倾向于从声称的奖励中受益，当我们运气不好时，我们试图逃避为我们的决定的后果买单。我们喜欢令人愉快的“我告诉过你！”但当事情突然出乎意料地出错时，保持沉默。<strong class="lk iu">没想到</strong>是这里的关键词。</p><p id="50c2" class="pw-post-body-paragraph li lj it lk b ll mf ju ln lo mg jx lq lr mh lt lu lv mi lx ly lz mj mb mc md im bi translated">用技术术语来说，在“<a class="ae mk" href="http://www.datascienceassn.org/sites/default/files/Probability%20and%20Risk%20in%20the%20Real%20World.pdf" rel="noopener ugc nofollow" target="_blank"> <em class="me">现实世界</em> </a>”中，大数定律收敛得非常慢，或者根本不收敛，给定决策所依据的有限的观察时间跨度。因此，观测者完全看不到罕见的灾难性尾部事件的统计特性。关键的问题是，这些罕见的尾部事件，通常被数据科学家标记为“异常值”并从分析中删除，恰恰是代表感兴趣的基本属性的观察结果。胖尾域<a class="ae mk" href="https://arxiv.org/pdf/1308.0958.pdf" rel="noopener ugc nofollow" target="_blank">描述</a>如下:统计性质的大部分来自极值；对于包含𝑛观测值的时间序列，随着𝑛变大，最大或最小观测值将与总和处于同一数量级。偏离分布中心的情况会残酷而剧烈地发生；罕见事件占主导地位。</p><p id="9277" class="pw-post-body-paragraph li lj it lk b ll mf ju ln lo mg jx lq lr mh lt lu lv mi lx ly lz mj mb mc md im bi translated"><em class="me">"现实世界</em>"经济、社会和政治变量都是极其厚尾的。此外，正如<a class="ae mk" href="https://arxiv.org/pdf/1308.0958.pdf" rel="noopener ugc nofollow" target="_blank">的 Nassim Taleb 和 Constantine Sandis 的</a>所述，标准经济理论意识到了<a class="ae mk" href="https://en.wikipedia.org/wiki/Principal%E2%80%93agent_problem" rel="noopener ugc nofollow" target="_blank">委托代理问题</a>，但没有意识到委托代理问题、信息不透明(数据收集的时间范围有限或信息不对称)和肥尾现象的结合。它不愿意接受厚尾事件不可预测、不可统计测量的事实，除非是由一个人造成的，或者是在一个上行空间小、下行空间大的环境中运营。</p><p id="6e28" class="pw-post-body-paragraph li lj it lk b ll mf ju ln lo mg jx lq lr mh lt lu lv mi lx ly lz mj mb mc md im bi translated">胖尾事件的一个问题是它们发生之前的时间周期延长了。例如，如果你是一名城市规划者，你的决策产生影响需要很长时间，以至于你会有动力去关注看似积极的短期影响，并倾向于忽视与你的决策相关的长期危险。当它发生时，你将不再负责。</p><p id="f8fa" class="pw-post-body-paragraph li lj it lk b ll mf ju ln lo mg jx lq lr mh lt lu lv mi lx ly lz mj mb mc md im bi translated">Taleb <a class="ae mk" href="https://arxiv.org/pdf/1308.0958.pdf" rel="noopener ugc nofollow" target="_blank">带来了</a>公司经理激励结构的例子。与公众的看法相反，公司经理不是企业家。2000 年至 2010 年间，在美国，与将资金投入现金或短期国库券相比，投资者在股市损失了高达两万亿美元(取决于人们如何衡量)。人们很容易想到，既然经理们因良好的业绩而获得高额报酬，那么如果他们表现不佳，他们就会遭受损失。根本不是:塔勒布说，这是一种非理性和不道德的不对称。由于他们职业中的嵌入式期权，经理们获得了超过 4000 亿美元的薪酬。亏损的经理不会返还奖金，也不会招致负奖金。</p><p id="5d6e" class="pw-post-body-paragraph li lj it lk b ll mf ju ln lo mg jx lq lr mh lt lu lv mi lx ly lz mj mb mc md im bi translated">那么我们如何解决厚尾环境下的委托代理问题呢？公司经理从一个随机变量中得到的比失去的多，这一事实造成了一种风险被简单地掩盖起来(在这种情况下是被掩盖起来)的局面，这种局面只能通过迫使他们为一些损失买单来解决。不只是开除他们，而是强迫他们在游戏 中拥有自己的<strong class="lk iu"> <em class="me">皮肤。这种启发也适用于政治家、经济学家、城市规划者和其他专业人士，他们的决策会对我们的生活产生重大影响。</em></strong></p><p id="18c6" class="pw-post-body-paragraph li lj it lk b ll mf ju ln lo mg jx lq lr mh lt lu lv mi lx ly lz mj mb mc md im bi translated">在这篇笔记中，我将用 Python 再现<a class="ae mk" href="https://arxiv.org/pdf/1308.0958.pdf" rel="noopener ugc nofollow" target="_blank"> Taleb 和 Sandis 的论文</a>中的关键思想，用随机变量及其属性来描述上述思想。</p><h1 id="4e7e" class="kq kr it bd ks kt ku kv kw kx ky kz la jz lb ka lc kc ld kd le kf lf kg lg lh bi translated">回报偏态和缺乏游戏中的皮肤</h1><p id="a33b" class="pw-post-body-paragraph li lj it lk b ll lm ju ln lo lp jx lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">塔勒布的目的是表明<strong class="lk iu">如果一个代理人有随机变量的收益的上行，没有下行，并且完全根据过去的业绩来判断，那么激励是使用业绩的负偏斜(或更一般地，不对称)分布来隐藏左尾中的风险。这可以推广到任何不承担自己行为的全部风险和负面后果的回报</strong>。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="mm mn di mo bf mp"><div class="gh gi ml"><img src="../Images/53568a0059ed36195085f92af1a08927.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*8cyeHtN3MSmgt3jKjiL_vw.jpeg"/></div></div></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="mm mn di mo bf mp"><div class="gh gi mq"><img src="../Images/b1ef2038d319816c82778019d4338b06.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*5W-QSFyLOQEE8QMBXUxkvA.jpeg"/></div></div></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="mm mn di mo bf mp"><div class="gh gi mr"><img src="../Images/2f05dd4cb41e6208a5e3f120a6b7d33a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*3ndE_csBWQOCXwS5kA1dvw.jpeg"/></div></div></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="mm mn di mo bf mp"><div class="gh gi ml"><img src="../Images/3fd869db5ec84b4cd21a6e60bac0d9d8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*STbNEvhD6raYH23dJxrhtg.jpeg"/></div></div></figure><h1 id="64da" class="kq kr it bd ks kt ku kv kw kx ky kz la jz lb ka lc kc ld kd le kf lf kg lg lh bi translated">计算预期收益</h1><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="mm mn di mo bf mp"><div class="gh gi ms"><img src="../Images/ea3f371def5bcb05571efeece823b1aa.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*KvvySJUrG7-vCIGkXfFGXA.jpeg"/></div></div></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="mm mn di mo bf mp"><div class="gh gi mt"><img src="../Images/0c4dcdd529ce8de1e97789f25caff34d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*IjNFX0TOUU92yqtA1AKDTA.jpeg"/></div></div></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="mm mn di mo bf mp"><div class="gh gi ml"><img src="../Images/3c0e21ca4b2054d9dbeb5d04345288f1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*v-9W9RrEQbk5tBPrjnUqwg.jpeg"/></div></div></figure><p id="e146" class="pw-post-body-paragraph li lj it lk b ll mf ju ln lo mg jx lq lr mh lt lu lv mi lx ly lz mj mb mc md im bi translated"><strong class="lk iu">无利益博弈的正向激励的预期收益取决于负偏度，而不是 m！</strong></p><h1 id="c8e0" class="kq kr it bd ks kt ku kv kw kx ky kz la jz lb ka lc kc ld kd le kf lf kg lg lh bi translated">让我们看看这是怎么回事！</h1><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="mm mn di mo bf mp"><div class="gh gi mt"><img src="../Images/72fae29de36890248c1b2ec6faf5c017.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*7Pksa4W4MZW0hsAy73UKHA.jpeg"/></div></div></figure><p id="cea2" class="pw-post-body-paragraph li lj it lk b ll mf ju ln lo mg jx lq lr mh lt lu lv mi lx ly lz mj mb mc md im bi translated">让我们设想一个幂律分布的移位镜像，其指数为𝛼=1.95，值域为∞，10:</p><pre class="kj kk kl km gt mu mv mw mx aw my bi"><span id="0ca9" class="mz kr it mv b gy na nb l nc nd"># import necessary libraries<br/><strong class="mv iu">import</strong> numpy <strong class="mv iu">as </strong>np<br/><strong class="mv iu">import</strong> matplotlib.pyplot <strong class="mv iu">as </strong>plt<br/><strong class="mv iu">import </strong>scipy.stats <strong class="mv iu">as </strong>stats<br/><strong class="mv iu">from </strong>scipy.stats <strong class="mv iu">import </strong>pareto<br/><strong class="mv iu">import </strong>scipy.integrate</span><span id="a8b8" class="mz kr it mv b gy ne nb l nc nd">#define pareto pdf <br/><strong class="mv iu">def </strong>pareto_pdf(x,alpha, loc, scale):<br/> <strong class="mv iu">return </strong>(alpha / ((-x — loc) / scale)**(alpha+<strong class="mv iu">1</strong>)) /scale</span><span id="cab1" class="mz kr it mv b gy ne nb l nc nd">alpha = <strong class="mv iu">1.95</strong><br/>loc = <strong class="mv iu">-11</strong><br/>scale = <strong class="mv iu">1</strong><br/>fig, ax = plt.subplots(figsize=(<strong class="mv iu">10</strong>,<strong class="mv iu">5</strong>))<br/>r = — pareto.rvs(alpha,loc=loc, scale=scale, size=<strong class="mv iu">500000</strong>)<br/>count, bins, ignored = plt.hist(r, bins=<strong class="mv iu">10000</strong>, density=<strong class="mv iu">True</strong>, alpha=0.5, label=r’$x_{min} = 10, P(X &gt; x) = -x^{-\alpha} x_{\min }^{\alpha}$’)<br/>plt.plot(np.array([<strong class="mv iu">10</strong>]*<strong class="mv iu">1000</strong>),np.linspace(<strong class="mv iu">0</strong>,<strong class="mv iu">1.5</strong>, <strong class="mv iu">1000</strong>), linestyle = ‘ — ‘, color=’r’, alpha=<strong class="mv iu">0.75</strong>, linewidth=<strong class="mv iu">0.75</strong>)<br/>plt.plot(bins, pareto_pdf(bins, alpha, loc, scale), color=’orange’)<br/>ax.set_xlim(-<strong class="mv iu">100,15</strong>)<br/>ax.set_ylim(<strong class="mv iu">0,1.5</strong>)<br/>ax.annotate(r’$x_{min} = <strong class="mv iu">10</strong>$’, <br/> xy=(<strong class="mv iu">10</strong>, <strong class="mv iu">1.5</strong>), <br/> xytext=(<strong class="mv iu">10</strong>, <strong class="mv iu">1.65</strong>), <br/> arrowprops = dict(edgecolor=’red’,facecolor=’red’, shrink=<strong class="mv iu">0.03</strong>))<br/>ax.set_xlabel(‘Pareto RV’)<br/>ax.set_ylabel(‘Frequency’)<br/>plt.title(‘Pareto distribution’)<br/>plt.legend()<br/>plt.show()</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="mm mn di mo bf mp"><div class="gh gi nf"><img src="../Images/025180db857bd29cd923fe18747de080.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*jdCEP20D_Lqlc2rs2WEZpw.jpeg"/></div></div></figure><p id="3e47" class="pw-post-body-paragraph li lj it lk b ll mf ju ln lo mg jx lq lr mh lt lu lv mi lx ly lz mj mb mc md im bi translated">现在，让我们看看著名的 80–20 帕累托分布的样本均值如何收敛到真实均值:</p><pre class="kj kk kl km gt mu mv mw mx aw my bi"><span id="9e7f" class="mz kr it mv b gy na nb l nc nd">pareto_alpha = <strong class="mv iu">1.15</strong><br/>Pareto_true_mean = -pareto_alpha/(pareto_alpha-<strong class="mv iu">1</strong>) — loc<br/><strong class="mv iu">print</strong>(‘Pareto <strong class="mv iu">80–20</strong> true mean: ‘, Pareto_true_mean)</span><span id="9628" class="mz kr it mv b gy ne nb l nc nd">means = []<br/>pareto_alpha = <strong class="mv iu">1.15</strong><br/>for n in range(<strong class="mv iu">1</strong>, <strong class="mv iu">10000</strong>):<br/> distr = — pareto.rvs(pareto_alpha,loc=loc, scale=scale, size=n)<br/> means.append(np.mean(distr))<br/>fig, ax = plt.subplots(figsize=(<strong class="mv iu">10,5</strong>)) <br/>ax.plot(np.arange(<strong class="mv iu">1, 10000</strong>), means, linewidth=<strong class="mv iu">0.5</strong>, c=’<strong class="mv iu">r</strong>’)<br/>ax.plot(np.arange(<strong class="mv iu">10000</strong>), np.array([Pareto_true_mean]*<strong class="mv iu">10000</strong>), linestyle=’ — ‘, color=’<strong class="mv iu">blue</strong>’, alpha=<strong class="mv iu">0.8</strong>, label=r’$P(X &gt; x) = -x^{-\alpha} x_{\min }^{\alpha}$’)<br/>ax.set_ylim(-<strong class="mv iu">3000</strong>, <strong class="mv iu">1000</strong>)<br/>ax.set_xlim(<strong class="mv iu">0</strong>, <strong class="mv iu">10000</strong>)<br/>ax.set_xlabel(r’$n$’)<br/>ax.set_ylabel(r’$\frac{1}{n}\sum_{i=1}^{n} x_{i}$’, rotation=<strong class="mv iu">0</strong>)<br/>plt.title(‘Convergence of mean for Pareto’)<br/>plt.legend()<br/>plt.show()</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="mm mn di mo bf mp"><div class="gh gi ng"><img src="../Images/bbde3c08031c26422ea2baca57b2337e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*JSRLDW1T19CsOqgYDWg0NA.jpeg"/></div></div></figure><pre class="kj kk kl km gt mu mv mw mx aw my bi"><span id="867d" class="mz kr it mv b gy na nb l nc nd">means = np.array(means)<br/>perc_above_mean = <strong class="mv iu">100</strong>*len(means[means&gt;Pareto_true_mean])/len(means)<br/>print(‘Percentage of observations above mean: ‘, perc_above_mean)</span></pre><p id="f911" class="pw-post-body-paragraph li lj it lk b ll mf ju ln lo mg jx lq lr mh lt lu lv mi lx ly lz mj mb mc md im bi translated">我们每隔一段时间就会看到典型的跳跃，对于𝛼=1.15 来说，大约 90%的观察值都高于平均值。厚尾分布隐藏了真实的平均值！</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="mm mn di mo bf mp"><div class="gh gi nh"><img src="../Images/f9b299fe0eb54190a1a3af79c4ae22b5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*q_5QMdMJqg9U7fD_GoAP4g.jpeg"/></div></div></figure><pre class="kj kk kl km gt mu mv mw mx aw my bi"><span id="b891" class="mz kr it mv b gy na nb l nc nd">#set up parameters<br/>gamma = <strong class="mv iu">0.1</strong><br/>scale= <strong class="mv iu">1</strong><br/>loc= -<strong class="mv iu">11</strong><br/>pareto_alpha = <strong class="mv iu">1.15</strong></span><span id="23c8" class="mz kr it mv b gy ne nb l nc nd"># define power law pdf and expected value functions<br/>power_law_pdf = <strong class="mv iu">lambda </strong>x: (pareto_alpha / ((-x — loc) / scale)**(pareto_alpha+1)) /scale<br/>expected_val = <strong class="mv iu">lambda </strong>x: x*(pareto_alpha / ((-x — loc) / scale)**(pareto_alpha+1)) /scale</span><span id="d6d8" class="mz kr it mv b gy ne nb l nc nd">#define the payoff function<br/><strong class="mv iu">def</strong> <strong class="mv iu">Payoff</strong>(alpha, gamma=gamma, loc=loc, scale=scale):<br/> true_mean = -alpha/(alpha-1) — loc<br/> F_right = scipy.integrate.quad(power_law_pdf, true_mean, <strong class="mv iu">10</strong>)[<strong class="mv iu">0</strong>]<br/> F_left = scipy.integrate.quad(power_law_pdf,-<strong class="mv iu">100000</strong>, true_mean)[<strong class="mv iu">0</strong>]<br/> expected_val_right = scipy.integrate.quad(expected_val, true_mean, <strong class="mv iu">10</strong>)[<strong class="mv iu">0</strong>]/scipy.integrate.quad(power_law_pdf, true_mean, <strong class="mv iu">10</strong>)[<strong class="mv iu">0</strong>]<br/> expected_val_left = scipy.integrate.quad(expected_val,-<strong class="mv iu">100000</strong>, true_mean)[<strong class="mv iu">0</strong>]/scipy.integrate.quad(power_law_pdf,-<strong class="mv iu">100000</strong>, true_mean)[<strong class="mv iu">0</strong>]<br/> <br/> <strong class="mv iu">return </strong>gamma*expected_val_right*F_right/(<strong class="mv iu">1</strong>-F_right)</span><span id="ccc4" class="mz kr it mv b gy ne nb l nc nd">alphas = np.linspace(<strong class="mv iu">1.1, 3, 1000</strong>)<br/>payoffs_1 = []<br/>payoffs_3 = []<br/>payoffs_5 = []<br/>payoffs_7 = []<br/>payoffs_9 = []<br/>for alph in alphas:<br/> payoffs_1.append(Payoff(alph, gamma=<strong class="mv iu">0.1</strong>))<br/> payoffs_3.append(Payoff(alph, gamma=<strong class="mv iu">0.3</strong>))<br/> payoffs_5.append(Payoff(alph, gamma=<strong class="mv iu">0.5</strong>))<br/> payoffs_7.append(Payoff(alph, gamma=<strong class="mv iu">0.7</strong>))<br/> payoffs_9.append(Payoff(alph, gamma=<strong class="mv iu">0.9</strong>)) <br/> <br/># set up the asymmetry measures<br/>vs = []<br/><strong class="mv iu">for</strong> alpha <strong class="mv iu">in </strong>alphas:<br/> true_mean = -alpha/(alpha-<strong class="mv iu">1</strong>) — loc<br/> F_right = scipy.integrate.quad(f, true_mean, <strong class="mv iu">10</strong>)[<strong class="mv iu">0</strong>]<br/> F_left = scipy.integrate.quad(f,-<strong class="mv iu">100000</strong>, true_mean)[<strong class="mv iu">0</strong>]<br/> vs.append(F_left/F_right)<br/>vs = np.array(vs)</span><span id="252c" class="mz kr it mv b gy ne nb l nc nd">fig, ax = plt.subplots(figsize=(<strong class="mv iu">10,8</strong>))<br/>ax.plot(vs, payoffs_1, label=r’$\gamma = <strong class="mv iu">0.1</strong>$’)<br/>ax.plot(vs, payoffs_3, label=r’$\gamma = <strong class="mv iu">0.3</strong>$’)<br/>ax.plot(vs, payoffs_5, label=r’$\gamma = <strong class="mv iu">0.5</strong>$’)<br/>ax.plot(vs, payoffs_7, label=r’$\gamma = <strong class="mv iu">0.7</strong>$’)<br/>ax.plot(vs, payoffs_9, label=r’$\gamma = <strong class="mv iu">0.9</strong>$’)<br/>ax.plot(np.array([<strong class="mv iu">0</strong>]*<strong class="mv iu">1000</strong>), np.linspace(<strong class="mv iu">-5, 125, 1000</strong>), linestyle=’ — ‘, color=’<strong class="mv iu">black</strong>’, alpha=<strong class="mv iu">0.5</strong>, linewidth=<strong class="mv iu">0.8</strong>)<br/>ax.plot(np.linspace(<strong class="mv iu">-0.05, 0.9, 1000</strong>),np.array([<strong class="mv iu">0</strong>]*<strong class="mv iu">1000</strong>), linestyle=’ — ‘, color=’<strong class="mv iu">black</strong>’, alpha=<strong class="mv iu">0.5</strong>, linewidth=<strong class="mv iu">0.8</strong>)<br/>ax.set_xlim(<strong class="mv iu">-0.05, 0.9</strong>)<br/>ax.set_ylim(<strong class="mv iu">-5, 125</strong>)<br/>ax.set_xlabel(r’$v_{j} \equiv \frac{F_{j}^{-}}{F_{j}^{+}}$’)<br/>ax.set_ylabel(‘Payoff’)<br/>plt.title(‘No $skin \ in \ the \ game$ payoffs under asymmetric fat tails’)<br/>plt.legend()<br/>plt.show()</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="mm mn di mo bf mp"><div class="gh gi ni"><img src="../Images/0b19cc41f67d2c3bc7a6ded50b386319.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*WVoGYERlTmPf5wd2zkeyug.jpeg"/></div></div></figure><p id="655d" class="pw-post-body-paragraph li lj it lk b ll mf ju ln lo mg jx lq lr mh lt lu lv mi lx ly lz mj mb mc md im bi translated">我们看到了什么？代理人从“好”的结果中受益，而没有承担“坏”的结果的成本，看到他们的预期收益随着𝑣𝑗的下降而增加。<strong class="lk iu">这意味着代理人有动机让左尾巴变长，从而累积风险，增加严重崩盘的可能性！</strong></p><h1 id="ebb6" class="kq kr it bd ks kt ku kv kw kx ky kz la jz lb ka lc kc ld kd le kf lf kg lg lh bi translated">结论</h1><p id="c28c" class="pw-post-body-paragraph li lj it lk b ll lm ju ln lo lp jx lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">讨论的例子显示了在大多数决策机构和运行它们的代理中危险的风险不对称，并呼吁一个古老的启发式方法作为补救:<strong class="lk iu">游戏中的皮肤。</strong></p><p id="d134" class="pw-post-body-paragraph li lj it lk b ll mf ju ln lo mg jx lq lr mh lt lu lv mi lx ly lz mj mb mc md im bi translated">正如塔勒布所言，“这种启发意味着，一个人应该是自己产品的第一个消费者，一个厨师应该自己测试自己的食物，直升机修理工应该随时准备乘坐他们维护的旋翼飞机进行随机飞行，对冲基金经理应该最大限度地投资于他们的基金。但这并不天真地暗示人们应该一直使用自己的产品:理发师不能给自己理发，癌症药物的制造商不应该使用自己的产品，除非他生病了。所以一个人应该有条件地使用他的产品，在被召唤使用它们的时候。然而，在涉及系统性风险的问题上，该规则要严格得多:简单地说，某些决定永远不应由某一类人做出。”</p><p id="5915" class="pw-post-body-paragraph li lj it lk b ll mf ju ln lo mg jx lq lr mh lt lu lv mi lx ly lz mj mb mc md im bi translated">有关游戏中皮肤试探法的伦理和哲学含义的更多细节，请参考<a class="ae mk" href="https://arxiv.org/pdf/1308.0958.pdf" rel="noopener ugc nofollow" target="_blank">原始论文</a>。</p><p id="15e6" class="pw-post-body-paragraph li lj it lk b ll mf ju ln lo mg jx lq lr mh lt lu lv mi lx ly lz mj mb mc md im bi translated">完整的 jupyter 笔记本和上面的笔记代码可以在这里找到。</p></div></div>    
</body>
</html>