# 更快的数据科学

> 原文：<https://towardsdatascience.com/faster-data-science-7ce9aa8d0b28?source=collection_archive---------29----------------------->

![](img/ea00516179c4f144ecb1c3ea13b46a63.png)

商业领袖经常问如何加速数据科学项目。众所周知，数据科学家花费 80%的时间在数据争论上。缩短这一时间可以加快数据科学项目的周转，并让数据科学家将更多的时间花在其他人无法完成的高价值活动上。随着数据科学团队规模的扩大，经济效益和工作效率会快速增长。这篇文章为数据工程的适度投资提供了一个案例，通过满足对较小的代表性数据集的需求，大大减少了花费在交互式数据探索上的时间。

# 减少分析查询的周转时间

减少花费在数据探索和代码开发上的时间的关键是最大限度地减少获得关于数据的基本问题的答案所花费的时间。当分析查询的典型运行时间从几个小时到一个小时到 10 分钟到不到一分钟到不到 10 秒钟时，开发过程的动态会发生巨大的变化。一旦查询响应时间达到几秒钟的范围，就可以提出许多问题来测试不同的假设，并最终在更短的时间内获得更好的结果。

# 大数据太大了

在研究项目和数据管道的开发过程中，数据科学家必须多次运行他们的查询，对它们进行提炼和改进，以便以他们想要的格式获得他们需要的数据。然而，处理大数据非常耗时，因为无论您使用的是 Hadoop 还是现代分布式数据仓库(如 Snowflake、Redshift 或 Vertica ),处理大型数据集都需要很长时间。使用共享计算资源的模式常常会加剧这个问题，在这种模式下，交互式查询会与较大的批处理进程竞争。

数据科学家对推进研究所需的时间感到沮丧，他们发明了避免长时间等待的捷径，但往往牺牲了分析结果的准确性或适用性。例如，处理一个小时的日志数据使查询时间变得可以忍受，从而可以取得进展。然而，这些结果不能用来得出关于整个数据集的结论。

数据工程师可以通过采用几种简单的方法来减少查询时间，只需要少量的工作和很少的额外成本，从而减轻数据争论的痛苦。这些方法旨在将数据的大小和范围缩减到与所提问题相关的子集，下面将对此进行详细介绍。

# 使用列式数据存储

数据的存储方式对数据的分析访问有很大的影响。列数据格式，如 [Parquet](https://parquet.apache.org/) ，被广泛使用并提供了许多好处。除了将数据扫描限制在查询中出现的列并允许更好的压缩之外，这些格式还以二进制格式而不是文本格式存储数据。即使在一个高效的 CSV 阅读器中，将文本解析为二进制数据类型也会消耗将数据加载到计算机内存所需时间的 80%。此外，正确解析文本字段本身也是一个挑战。一次预处理和以二进制格式存储数据避免了每次访问数据时的额外计算。数据仓库通常提供现成的二进制列数据存储。

# 创建始终在线的采样数据集

许多数据问题可以通过使用代表性的数据样本来回答。采样数据集比一小段时间的数据好得多，因为它们代表整个数据集，足以回答各种问题。尽管提取和更新样本是乏味的，但每个数据科学家迟早都会被诱惑这样做，仅仅是为了缩短他们查询的周转时间。一个更有效且成本不高的解决方案是定期提供自动生成的数据样本。理想情况下，采样数据的生成应依赖于产生完整数据集的流水线。

在数据代表一些事件(例如，广告印象、购买交易、网站访问等)的典型情况下。)与一些实体(例如，在线用户、公司等)相关。)，用不同类型的采样创建数据集是有益的。一个显而易见的方法是对事件进行采样，随机选择一定百分比的事件包含在数据集中。另一种抽样策略，对数据科学家或分析师来说，可能更有价值，也更难实现，就是覆盖与实体样本相关的所有记录。例如，我们可能希望包含 5%的站点用户的所有购买。这样的样本允许人们有效地执行基于用户的分析。采样策略，包括自适应采样，是另一篇文章的主题。

# 提取较小的相关数据集

当感兴趣的事件很少时，取样可能不是一个选项。例如，在数字广告设置中，人们可能对在有限的时间范围内提取特定广告活动的所有可用数据感兴趣。这样的数据集虽然包含所有必需的字段，但只是所有数据的一个小子集。与这些数据进行交互的分析师和数据科学家在处理一个项目时可能会发出数百个查询。如果数据工程团队构建工具，允许数据科学家为初始提取创建一个查询，并由另一个查询负责定期更新，则提取这样一个数据集并使其保持最新的过程可以自动化。项目完成后，不再需要这些数据，可以将其存档或删除。

# 将较小的数据集放在高效的 SQL 存储中

SQL 无疑是数据分析最常用的语言。因此，使用 SQL 使数据集可用于查询扩大了可以与数据交互的人数。抛开数据的民主化不谈，在高效的分析 SQL 查询引擎中提供更小的数据集可以进一步减少查询时间，从而减少数据科学家和分析师浪费的时间。根据数据的大小和对基础设施的要求，这种查询引擎的范围很广，从 MySQL 和 PostgreSQL 到 Snowflake 和 Redshift，再到完全托管的服务，如亚马逊的 Athena 和谷歌的 BigQuery。

# 提供专用的计算资源

数据探索中最大的挫折之一是不得不在一个共享队列中等待一个查询的结果，这个查询最终运行不到一分钟。在共享集群上为交互式查询提供单独的高优先级资源池(可能限制在工作时间内),对于改善整体查询周转时间大有帮助。此外，为数据科学和分析团队提供具有足够 CPU 和内存容量的专用计算资源，可以将较小的数据集加载到他们选择的工具中，以执行开发和深入分析。

# 投资是值得的！

人类的时间比计算机时间和数据存储成本要贵一个数量级。通过比较数据科学家的有效时薪和一台强大计算机的时薪，人们可以很容易地观察到这一点。此外，人力时间为公司创造了新的净价值。因此，将典型的分析查询完成时间缩短到不到一分钟可能是加速数据科学和分析项目的最有效的技术投资。

*Kelly sik kema 和 Glen Noble 在 Unsplash 上拍摄的照片由 Sergei Izrailev 合成*

这篇文章最初出现在[生活数据](http://www.lifearounddata.com/faster-data-science/)博客上。