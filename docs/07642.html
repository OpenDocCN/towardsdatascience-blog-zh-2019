<html>
<head>
<title>Transfer Learning Made Easy: Coding a Powerful Technique — Exxact</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">迁移学习变得容易:编码一种强大的技术— Exxact</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/transfer-learning-made-easy-coding-a-powerful-technique-exxact-f0f92baf4fb2?source=collection_archive---------36-----------------------#2019-10-23">https://towardsdatascience.com/transfer-learning-made-easy-coding-a-powerful-technique-exxact-f0f92baf4fb2?source=collection_archive---------36-----------------------#2019-10-23</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><p id="9a1e" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu">图</strong>:仅由第一个神经网络看到的前 5 类图像。</p><p id="af32" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">但我们实际上感兴趣的是为最后 5 类图像建立一个神经网络——<strong class="js iu">狗、青蛙、马、羊、</strong>或<strong class="js iu">卡车</strong>。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi ko"><img src="../Images/1b3d9b8aee50ab54343f5a1a15e5e3f4.png" data-original-src="https://miro.medium.com/v2/resize:fit:600/format:webp/0*b79etDjpuoAx1Bzv.png"/></div></figure><p id="5ce1" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu">图</strong>:最后 5 类图像，仅由第二神经网络看到。</p><p id="4dfd" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">接下来，我们定义两组/两种类型的层:特征(卷积)和分类(密集)。</p><p id="d13d" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">同样，不要担心这些代码片段的实现细节。你可以从 Keras 包的任何标准教程中了解细节。想法是理解概念。</p><p id="8fac" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">要素图层:</p><pre class="kp kq kr ks gt kw kx ky kz aw la bi"><span id="854c" class="lb lc it kx b gy ld le l lf lg">feature_layers = [ Conv2D(filters, kernel_size, padding='valid', input_shape=input_shape), Activation('relu'), Conv2D(filters, kernel_size), Activation('relu'), MaxPooling2D(pool_size=pool_size), Dropout(0.25), Flatten(), ]</span></pre><p id="fb3d" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">密集分类层:</p><pre class="kp kq kr ks gt kw kx ky kz aw la bi"><span id="9054" class="lb lc it kx b gy ld le l lf lg">classification_layers = [ Dense(128), Activation('relu'), Dropout(0.25), Dense(num_classes), Activation('softmax') ]</span></pre><p id="91a6" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">接下来，我们通过将<strong class="js iu">特征 _ 层</strong>和<strong class="js iu">分类 _ 层</strong>堆叠在一起来创建完整的模型。</p><pre class="kp kq kr ks gt kw kx ky kz aw la bi"><span id="3174" class="lb lc it kx b gy ld le l lf lg">model_1 = Sequential(feature_layers + classification_layers)</span></pre><p id="cde4" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">然后，我们定义一个用于训练模型的函数(未示出),并且只训练模型一定数量的时期，以达到足够好的性能:</p><pre class="kp kq kr ks gt kw kx ky kz aw la bi"><span id="b366" class="lb lc it kx b gy ld le l lf lg">train_model(model_1, (x_train_lt5, y_train_lt5), (x_test_lt5, y_test_lt5), num_classes)</span></pre><p id="9962" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">我们可以展示网络的准确性是如何随着训练时期而发展的:</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi ko"><img src="../Images/0da230a27e8221a1907608c1c4a1c0e5.png" data-original-src="https://miro.medium.com/v2/resize:fit:600/format:webp/0*V_Yx5OJeeY-FOG-B.png"/></div></figure><p id="49fe" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu">图</strong>:训练第一个网络时，验证各代的集合精度。</p><p id="b5d4" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">接下来，我们<strong class="js iu">冻结特征层并重建模型</strong>。</p><p id="3a4e" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">这种特征层的冻结是迁移学习的核心。这允许重新使用预训练的模型进行分类任务，因为用户可以在预训练的要素图层之上堆叠新的全连接图层，并获得良好的性能。</p><p id="74a9" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">我们将创建一个名为<strong class="js iu"> model_2 </strong>的全新模型，其中<strong class="js iu">不可训练</strong> <strong class="js iu">特征 _ 图层</strong>和<strong class="js iu">可训练</strong>如下图所示:<strong class="js iu">分类 _ 图层</strong>。</p><pre class="kp kq kr ks gt kw kx ky kz aw la bi"><span id="d874" class="lb lc it kx b gy ld le l lf lg">for l in feature_layers: l.trainable = False model_2 = Sequential(feature_layers + classification_layers)</span></pre><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi lh"><img src="../Images/8a1f855794a7c65242991ade62f453a2.png" data-original-src="https://miro.medium.com/v2/resize:fit:552/format:webp/0*ru3Eb5N_RzyNV0jj.png"/></div></figure><p id="f5ed" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu">图</strong>:第二网络的模型概要，显示了固定的和可训练的权重。固定权重直接从第一网络传输。</p><p id="2a38" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">现在，我们训练第二个模型，观察<strong class="js iu">它如何花费更少的总时间，仍然获得相同或更高的性能</strong>。</p><pre class="kp kq kr ks gt kw kx ky kz aw la bi"><span id="a27c" class="lb lc it kx b gy ld le l lf lg">train_model(model_2, (x_train_gte5, y_train_gte5),(x_test_gte5, y_test_gte5), num_classes)</span></pre><p id="6725" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">第二个模型的准确性甚至高于第一个模型，尽管情况可能并非总是如此，并且取决于模型架构和数据集。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi ko"><img src="../Images/4d45fa0a37a132b7dc2db7ecc0b7d286.png" data-original-src="https://miro.medium.com/v2/resize:fit:600/format:webp/0*H-QQIMWuFuHGx3w1.png"/></div></figure><p id="bae6" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu">图</strong>:在训练第二网络时，验证各时期的集合精度。</p><p id="b01a" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">训练两个模型所需的时间如下所示:</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi ko"><img src="../Images/32c3efa5387a7e0486c9c6c94e58b95d.png" data-original-src="https://miro.medium.com/v2/resize:fit:600/format:webp/0*3QIkr3EyXMJY_a8W.png"/></div></figure><p id="afe8" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu">图</strong>:两个网络的训练时间。</p><h1 id="ac98" class="li lc it bd lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me bi translated">我们取得了什么成就？</h1><p id="4e93" class="pw-post-body-paragraph jq jr it js b jt mf jv jw jx mg jz ka kb mh kd ke kf mi kh ki kj mj kl km kn im bi translated"><strong class="js iu"> model_2 </strong>不仅比<strong class="js iu"> model_1 </strong>训练得更快，它还以更高的基线精度开始，并在相同的时期数和相同的超参数(学习率、优化器、批量等)下实现了更好的最终精度。).并且在<strong class="js iu"> model_1 </strong>没有看到的图像上实现了这种训练。</p><p id="2c5e" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">这意味着，尽管<strong class="js iu"> model_1 </strong>是在<strong class="js iu">飞机、汽车、鸟、猫、</strong>或<strong class="js iu">鹿</strong>的图像上训练的，但它学习到的权重在转移到<strong class="js iu"> model_2 </strong>时，帮助<strong class="js iu"> model_2 </strong>在完全不同类别的图像上实现了出色的分类性能——狗、青蛙、马、羊、或<strong class="js iu">卡车</strong>。</p><p id="3aea" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">是不是很神奇？你现在可以用这么少的代码来构建这种迁移学习。同样，整个代码是开源的，在这里可以找到<a class="ae mk" href="https://github.com/tirthajyoti/Deep-learning-with-Python/blob/master/Notebooks/Transfer_learning_CIFAR.ipynb" rel="noopener ugc nofollow" target="_blank"><strong class="js iu"/></a>。</p><p id="5302" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><em class="ml">原载于 2019 年 10 月 23 日</em><a class="ae mk" href="https://blog.exxactcorp.com/transfer-learning-made-easy/" rel="noopener ugc nofollow" target="_blank"><em class="ml">https://blog.exxactcorp.com</em></a><em class="ml">。</em></p></div></div>    
</body>
</html>