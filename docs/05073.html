<html>
<head>
<title>Have you Optimized your Deep Learning Model Before Deployment?</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">你在部署之前优化过你的深度学习模型吗？</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/have-you-optimized-your-deep-learning-model-before-deployment-cdc3aa7f413d?source=collection_archive---------8-----------------------#2019-07-30">https://towardsdatascience.com/have-you-optimized-your-deep-learning-model-before-deployment-cdc3aa7f413d?source=collection_archive---------8-----------------------#2019-07-30</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><figure class="is it gp gr iu iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi ir"><img src="../Images/f12d6aca89274fc6b84973b1d7b7f971.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*RqwDtEJSexMeq5aymDqvKA.png"/></div></div><figcaption class="jc jd gj gh gi je jf bd b be z dk">Source: <a class="ae jg" href="https://developer.nvidia.com/tensorrt#" rel="noopener ugc nofollow" target="_blank">https://developer.nvidia.com/tensorrt#</a></figcaption></figure><div class=""/><div class=""><h2 id="ca57" class="pw-subtitle-paragraph kg ji jj bd b kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx dk translated">使用 NVIDIA TensorRT 在 GPU 上优化和加快推理时间。插图基于人工智能的计算机视觉与 YOLO。</h2></div><p id="9d56" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">本文组织如下:</p><ul class=""><li id="45b2" class="lu lv jj la b lb lc le lf lh lw ll lx lp ly lt lz ma mb mc bi translated">介绍</li><li id="3e57" class="lu lv jj la b lb md le me lh mf ll mg lp mh lt lz ma mb mc bi translated">英伟达 TensorRT 是什么？</li><li id="f697" class="lu lv jj la b lb md le me lh mf ll mg lp mh lt lz ma mb mc bi translated">使用 docker 设置开发环境</li><li id="f6fe" class="lu lv jj la b lb md le me lh mf ll mg lp mh lt lz ma mb mc bi translated">计算机视觉应用:YOLOv3 模型的目标检测</li><li id="f983" class="lu lv jj la b lb md le me lh mf ll mg lp mh lt lz ma mb mc bi translated">参考</li><li id="a00f" class="lu lv jj la b lb md le me lh mf ll mg lp mh lt lz ma mb mc bi translated">结论</li></ul><h1 id="4fd0" class="mi mj jj bd mk ml mm mn mo mp mq mr ms kp mt kq mu ks mv kt mw kv mx kw my mz bi translated">介绍</h1><p id="d2bd" class="pw-post-body-paragraph ky kz jj la b lb na kk ld le nb kn lg lh nc lj lk ll nd ln lo lp ne lr ls lt im bi translated">本文介绍了如何使用 NVIDIA TensorRT 来优化您想要部署在边缘设备(移动设备、相机、机器人、汽车等)上的深度学习模型。).比如航空电子公司的智能双光谱相机:<em class="nf">潘沙</em>https://pensarsdk.com/<a class="ae jg" href="https://pensarsdk.com/" rel="noopener ugc nofollow" target="_blank">T3】</a></p><figure class="nh ni nj nk gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi ng"><img src="../Images/383983f8b55fd07ad4c777ce5db60cfa.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*kF5CrVqanC408hSvNYO1lg.png"/></div></div><figcaption class="jc jd gj gh gi je jf bd b be z dk"><a class="ae jg" href="https://pensarsdk.com/" rel="noopener ugc nofollow" target="_blank">https://pensarsdk.com/</a></figcaption></figure><p id="1ff5" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">它拥有 NVIDIA Jetson TX2 GPU</p><figure class="nh ni nj nk gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi nl"><img src="../Images/7c99b6f435e403f87d2f10ebe79e2817.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*QRaU5AHVxGZeKAqwpriktg.png"/></div></div><figcaption class="jc jd gj gh gi je jf bd b be z dk"><a class="ae jg" href="https://developer.nvidia.com/embedded/jetson-tx2" rel="noopener ugc nofollow" target="_blank">https://developer.nvidia.com/embedded/jetson-tx2-developer-kit</a></figcaption></figure><h2 id="0e3a" class="nm mj jj bd mk nn no dn mo np nq dp ms lh nr ns mu ll nt nu mw lp nv nw my nx bi translated">为什么我需要一个优化的深度学习模型？</h2><p id="89a0" class="pw-post-body-paragraph ky kz jj la b lb na kk ld le nb kn lg lh nc lj lk ll nd ln lo lp ne lr ls lt im bi translated">举个例子，想想基于人工智能的计算机视觉应用，它们需要处理摄像机捕捉的每一帧。因此，每一帧向前通过模型的层来计算某一输出(检测、分割、分类……)。</p><p id="9afb" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">无论你的 GPU 有多强大，我们都希望输出端的每秒帧数(FPS)等于输入端的 1(例如 24，30 FPS…)。这意味着 GPU 正在实时处理每一帧。</p><p id="45d9" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">对于需要实时决策的计算机视觉应用来说，这种概念更为理想，例如，监控、欺诈检测或活动期间的人群计数等。</p><h2 id="f7dc" class="nm mj jj bd mk nn no dn mo np nq dp ms lh nr ns mu ll nt nu mw lp nv nw my nx bi translated">部署前优化工作流</h2><p id="9dbf" class="pw-post-body-paragraph ky kz jj la b lb na kk ld le nb kn lg lh nc lj lk ll nd ln lo lp ne lr ls lt im bi translated">数据科学家的任务之一是利用数据并开发/训练/测试神经网络架构。在模型验证之后，通常，架构和模型的参数被导出用于部署。有许多方法可以做到这一点，无论是在云上还是在边缘设备上。在本文中，我们重点关注边缘设备(相机、手机、机器人、汽车……)上的部署。</p><p id="da8b" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">一般来说，部署的工作流程遵循下图所示的框图:</p><figure class="nh ni nj nk gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi ny"><img src="../Images/f63f9e9a55032e3f3bc695d84d608929.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ftr5BLj4PitHbueEqS6JdQ.png"/></div></div></figure><p id="c5b2" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">从导出的、预先训练好的深度学习模型<strong class="la jk"> - &gt; </strong>框架解析器<strong class="la jk">-&gt;</strong>tensort 优化<strong class="la jk"> - &gt; </strong>对新数据进行推理</p></div><div class="ab cl nz oa hx ob" role="separator"><span class="oc bw bk od oe of"/><span class="oc bw bk od oe of"/><span class="oc bw bk od oe"/></div><div class="im in io ip iq"><h1 id="2dc9" class="mi mj jj bd mk ml og mn mo mp oh mr ms kp oi kq mu ks oj kt mw kv ok kw my mz bi translated">英伟达 TensorRT 是什么？</h1><figure class="nh ni nj nk gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi ol"><img src="../Images/cc414f1759f58139e482518a9085dccb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*EWiIvB6RjwEZrlSLF1Xttw.png"/></div></div><figcaption class="jc jd gj gh gi je jf bd b be z dk"><a class="ae jg" href="https://docs.nvidia.com/deeplearning/sdk/tensorrt-archived/tensorrt_210/tensorrt-user-guide/index.html" rel="noopener ugc nofollow" target="_blank">https://docs.nvidia.com/deeplearning/sdk/tensorrt-archived/tensorrt_210/tensorrt-user-guide/</a></figcaption></figure><blockquote class="om on oo"><p id="9f4c" class="ky kz nf la b lb lc kk ld le lf kn lg op li lj lk oq lm ln lo or lq lr ls lt im bi translated">NVIDIA TensorRT 的核心是一个 C++库，它有助于在 NVIDIA 图形处理单元(GPU)上进行高性能推理。TensorRT 采用一个由网络定义和一组训练参数组成的训练网络，并生成一个高度优化的运行时引擎，为该网络执行推理。</p><p id="2f22" class="ky kz nf la b lb lc kk ld le lf kn lg op li lj lk oq lm ln lo or lq lr ls lt im bi translated">您可以使用 C++或 Python API 描述 TensorRT 网络，也可以使用提供的解析器之一导入现有的 Caffe、ONNX 或 TensorFlow 模型。<br/> <br/> TensorRT 通过 C++和 Python 提供 API，帮助通过网络定义 API 表达深度学习模型，或通过解析器加载预定义的模型，允许 TensorRT 在 NVIDIA GPU 上优化和运行它们。TensorRT 应用了图形优化、层融合以及其他优化，同时还利用高度优化的内核的多样化集合找到了该模型的最快实现。TensorRT 还提供了一个运行时，您可以使用它在从开普勒一代开始的所有 NVIDIA GPU 上执行这个网络。<br/> <br/> TensorRT 还包括在 Tegra X1 中引入的可选高速混合精度功能，并通过 Pascal、Volta 和图灵架构进行了扩展。<br/> <br/>在【开发者指南】(<a class="ae jg" href="https://docs.nvidia.com/deeplearning/sdk/tensorrt-developer-guide/index.html" rel="noopener ugc nofollow" target="_blank">https://docs . NVIDIA . com/deep learning/SDK/TensorRT-developer-guide/index . html</a>)中了解如何使用 tensorrt，以及在【TensorRT 论坛】(https://dev talk . NVIDIA . com/default/board/304/tensor rt/)中与 tensor rt 社区互动</p></blockquote></div><div class="ab cl nz oa hx ob" role="separator"><span class="oc bw bk od oe of"/><span class="oc bw bk od oe of"/><span class="oc bw bk od oe"/></div><div class="im in io ip iq"><h1 id="3f3e" class="mi mj jj bd mk ml og mn mo mp oh mr ms kp oi kq mu ks oj kt mw kv ok kw my mz bi translated">使用 docker 设置开发环境</h1><h2 id="9cdc" class="nm mj jj bd mk nn no dn mo np nq dp ms lh nr ns mu ll nt nu mw lp nv nw my nx bi translated">Docker 图像</h2><p id="b6a1" class="pw-post-body-paragraph ky kz jj la b lb na kk ld le nb kn lg lh nc lj lk ll nd ln lo lp ne lr ls lt im bi translated">对于开发，我们使用一个 docker 映像，其中包含一个已安装的 NVIDIA TensorRT 版本。这使得开发环境在不同的操作系统(Windows、Linux、macOS)上更加可靠和可伸缩。</p><p id="1ded" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">下面是 docker 在应用程序和 GPU 之间的定位图。</p><figure class="nh ni nj nk gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi ny"><img src="../Images/29b5f7a868e2b2e8b937359a06d7869d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*-wpy3yNzLK_T2valKYMdVw.png"/></div></div></figure><p id="2b13" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><strong class="la jk">注:</strong>如果你从未听说过“docker”，那么我强烈建议你投资了解它，你从这里开始:<a class="ae jg" href="https://docs.docker.com/engine/docker-overview/" rel="noopener ugc nofollow" target="_blank">https://docs.docker.com/engine/docker-overview/</a></p><h2 id="86d4" class="nm mj jj bd mk nn no dn mo np nq dp ms lh nr ns mu ll nt nu mw lp nv nw my nx bi translated">安装 Docker-CE</h2><p id="1f88" class="pw-post-body-paragraph ky kz jj la b lb na kk ld le nb kn lg lh nc lj lk ll nd ln lo lp ne lr ls lt im bi translated">前往 docker 的官方网站，按照步骤安装“docker-ce ”( ce 代表社区版)。</p><p id="aa0f" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">我使用的是 Ubuntu 64 bit，因此，安装链接是:<a class="ae jg" href="https://docs.docker.com/v17.09/engine/installation/linux/docker-ce/ubuntu/" rel="noopener ugc nofollow" target="_blank">https://docs . docker . com/v 17.09/engine/installation/Linux/docker-ce/Ubuntu/</a></p><h2 id="afa5" class="nm mj jj bd mk nn no dn mo np nq dp ms lh nr ns mu ll nt nu mw lp nv nw my nx bi translated">安装 CUDA</h2><p id="e19d" class="pw-post-body-paragraph ky kz jj la b lb na kk ld le nb kn lg lh nc lj lk ll nd ln lo lp ne lr ls lt im bi translated">另外，你应该已经安装了最新版本的<a class="ae jg" href="https://developer.nvidia.com/cuda-downloads" rel="noopener ugc nofollow" target="_blank"> CUDA </a>。它是由 NVIDIA 创建的并行计算平台和应用编程接口模型。它允许软件开发人员和软件工程师使用支持 CUDA 的 GPU 进行通用处理(在<a class="ae jg" href="https://developer.nvidia.com/cuda-zone" rel="noopener ugc nofollow" target="_blank">https://developer.nvidia.com/cuda-zone</a>了解更多信息)。</p><p id="6d8c" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">要检查 CUDA 是否正确安装在您的机器上，只需在终端中输入</p><pre class="nh ni nj nk gt os ot ou ov aw ow bi"><span id="c972" class="nm mj jj ot b gy ox oy l oz pa">nvidia-smi</span></pre><p id="5905" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">输出应该是这样的(我有一个 NVIDIA GPU GeForce GTX 1660 Ti/PCIe/SSE 2)</p><pre class="nh ni nj nk gt os ot ou ov aw ow bi"><span id="44f0" class="nm mj jj ot b gy ox oy l oz pa"><br/>Thu Aug 1 10:43:37 2019 <br/>+ — — — — — — — — — — — — — — — — — — —— — — — — — — — — — — -+<br/>| NVIDIA-SMI 430.40 <strong class="ot jk">Driver Version: </strong>430.40 <strong class="ot jk">CUDA Version: </strong>10.1 |<br/>| — — — — — — — — — — — — -+ — — — — — — — — + — — — —— — — — +<br/>| GPU Name Persistence-M| Bus-Id Disp.A | Volatile Uncorr. ECC |<br/>| Fan Temp Perf Pwr:Usage/Cap| Memory-Usage | GPU-Util Compute M. |<br/>|=====================+===================+===================|<br/>| 0 GeForce GTX 166… Off | 00000000:01:00.0 Off | N/A |<br/>| N/A 47C P8 4W / N/A | 994MiB / 5944MiB | 8% Default |<br/>+ — — — — —— — — — — — — -+ — — — — — — — — + — — — — — — — — +</span></pre><h2 id="46b4" class="nm mj jj bd mk nn no dn mo np nq dp ms lh nr ns mu ll nt nu mw lp nv nw my nx bi translated">运行 docker 映像以使用 NVIDIA TensorRT</h2><p id="7441" class="pw-post-body-paragraph ky kz jj la b lb na kk ld le nb kn lg lh nc lj lk ll nd ln lo lp ne lr ls lt im bi translated">我已经创建了一个 docker 映像，其中包括在 Ubuntu 上安装 TensorRT，以及来自 NVIDIA、Python、OpenCV 等的必要先决条件。你可以直接从我在<a class="ae jg" href="https://hub.docker.com/u/aminehy" rel="noopener ugc nofollow" target="_blank"> docker hub </a>上的个人账户中调出图片。</p><div class="is it gp gr iu pb"><a href="https://hub.docker.com/r/aminehy/tensorrt-opencv-python3" rel="noopener  ugc nofollow" target="_blank"><div class="pc ab fo"><div class="pd ab pe cl cj pf"><h2 class="bd jk gy z fp pg fr fs ph fu fw ji bi translated">码头枢纽</h2><div class="pi l"><h3 class="bd b gy z fp pg fr fs ph fu fw dk translated">欢迎来到我的码头中心</h3></div><div class="pj l"><p class="bd b dl z fp pg fr fs ph fu fw dk translated">hub.docker.com</p></div></div></div></a></div><ul class=""><li id="3d46" class="lu lv jj la b lb lc le lf lh lw ll lx lp ly lt lz ma mb mc bi translated">首先，打开一个终端(ctrl+alt + t ),输入这个命令来提取 docker 图像</li></ul><pre class="nh ni nj nk gt os ot ou ov aw ow bi"><span id="1226" class="nm mj jj ot b gy ox oy l oz pa">docker pull aminehy/tensorrt-opencv-python3</span></pre><ul class=""><li id="8b76" class="lu lv jj la b lb lc le lf lh lw ll lx lp ly lt lz ma mb mc bi translated">通过输入以下命令，启用从 docker 容器内部启动 GUI 应用程序</li></ul><pre class="nh ni nj nk gt os ot ou ov aw ow bi"><span id="16e9" class="nm mj jj ot b gy ox oy l oz pa">xhost +</span></pre><ul class=""><li id="8d25" class="lu lv jj la b lb lc le lf lh lw ll lx lp ly lt lz ma mb mc bi translated">最后，用以下命令运行 docker 容器:</li></ul><pre class="nh ni nj nk gt os ot ou ov aw ow bi"><span id="8126" class="nm mj jj ot b gy ox oy l oz pa">docker run -it — rm -v $(pwd):/workspace — runtime=nvidia -w /workspace -v /tmp/.X11-unix:/tmp/.X11-unix -e DISPLAY=unix$DISPLAY aminehy/tensorrt-opencv-python3:v1.1</span></pre></div><div class="ab cl nz oa hx ob" role="separator"><span class="oc bw bk od oe of"/><span class="oc bw bk od oe of"/><span class="oc bw bk od oe"/></div><div class="im in io ip iq"><h1 id="a776" class="mi mj jj bd mk ml og mn mo mp oh mr ms kp oi kq mu ks oj kt mw kv ok kw my mz bi translated">计算机视觉应用:用 YOLOv3 进行物体检测</h1><p id="744a" class="pw-post-body-paragraph ky kz jj la b lb na kk ld le nb kn lg lh nc lj lk ll nd ln lo lp ne lr ls lt im bi translated">YOLO 是来自暗网项目的一个实时物体检测。你可以在这里的官方网站上了解这个项目的更多信息:【https://pjreddie.com/darknet/yolo/ T2】</p><figure class="nh ni nj nk gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi pk"><img src="../Images/6f8a8ea663eeeeb1e43cb950f2da6cef.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*aFeEgXtb0ar-Zrxujmu1oA.png"/></div></div><figcaption class="jc jd gj gh gi je jf bd b be z dk"><a class="ae jg" href="https://pjreddie.com/darknet/yolo/" rel="noopener ugc nofollow" target="_blank">https://pjreddie.com/darknet/yolo/</a></figcaption></figure><p id="ce6c" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">在本实验中，我们在 500 张图片上运行 YOLOv3 模型，并使用 NVIDIA TensorRT 比较模型优化前后的平均推理时间。本实验中使用的图像来自 COCO 数据集</p><div class="is it gp gr iu pb"><a href="http://cocodataset.org/#home" rel="noopener  ugc nofollow" target="_blank"><div class="pc ab fo"><div class="pd ab pe cl cj pf"><h2 class="bd jk gy z fp pg fr fs ph fu fw ji bi translated">COCO -上下文中的常见对象</h2><div class="pi l"><h3 class="bd b gy z fp pg fr fs ph fu fw dk translated">编辑描述</h3></div><div class="pj l"><p class="bd b dl z fp pg fr fs ph fu fw dk translated">cocodataset.org</p></div></div><div class="pl l"><div class="pm l pn po pp pl pq ja pb"/></div></div></a></div><h2 id="6d6c" class="nm mj jj bd mk nn no dn mo np nq dp ms lh nr ns mu ll nt nu mw lp nv nw my nx bi translated">1)从 Python 中的暗网中运行未优化的 YOLOv3</h2><div class="is it gp gr iu pb"><a href="https://gitlab.com/aminehy/yolov3-darknet" rel="noopener  ugc nofollow" target="_blank"><div class="pc ab fo"><div class="pd ab pe cl cj pf"><h2 class="bd jk gy z fp pg fr fs ph fu fw ji bi translated">胺 Hy / YOLOv3-DarkNet</h2><div class="pi l"><h3 class="bd b gy z fp pg fr fs ph fu fw dk translated">GitLab.com</h3></div><div class="pj l"><p class="bd b dl z fp pg fr fs ph fu fw dk translated">gitlab.com</p></div></div><div class="pl l"><div class="pr l pn po pp pl pq ja pb"/></div></div></a></div><ul class=""><li id="3e86" class="lu lv jj la b lb lc le lf lh lw ll lx lp ly lt lz ma mb mc bi translated">克隆存储库并通过我创建的脚本 docker _ tensort _ OpenCV _ python . sh 运行 docker 映像</li></ul><pre class="nh ni nj nk gt os ot ou ov aw ow bi"><span id="4dd1" class="nm mj jj ot b gy ox oy l oz pa">git clone <a class="ae jg" href="https://gitlab.com/aminehy/yolov3-darknet.git" rel="noopener ugc nofollow" target="_blank">https://gitlab.com/aminehy/yolov3-darknet.git</a></span><span id="b5cc" class="nm mj jj ot b gy ps oy l oz pa">cd yolov3-darknet</span><span id="9a84" class="nm mj jj ot b gy ps oy l oz pa">chmod +x docker_TensorRT_OpenCV_Python.sh</span><span id="8abd" class="nm mj jj ot b gy ps oy l oz pa">./docker_TensorRT_OpenCV_Python.sh run</span></pre><ul class=""><li id="88a3" class="lu lv jj la b lb lc le lf lh lw ll lx lp ly lt lz ma mb mc bi translated">下载并解压测试图像文件夹。/数据/</li></ul><pre class="nh ni nj nk gt os ot ou ov aw ow bi"><span id="f53b" class="nm mj jj ot b gy ox oy l oz pa">wget <a class="ae jg" href="http://images.cocodataset.org/zips/test2017.zip" rel="noopener ugc nofollow" target="_blank">http://images.cocodataset.org/zips/test2017.zip</a></span><span id="aad5" class="nm mj jj ot b gy ps oy l oz pa">unzip test2017.zip ../test2017/</span></pre><ul class=""><li id="3f86" class="lu lv jj la b lb lc le lf lh lw ll lx lp ly lt lz ma mb mc bi translated">下载重量文件` yolov3.weights '</li></ul><pre class="nh ni nj nk gt os ot ou ov aw ow bi"><span id="85b7" class="nm mj jj ot b gy ox oy l oz pa">wget <a class="ae jg" href="https://pjreddie.com/media/files/yolov3.weights" rel="noopener ugc nofollow" target="_blank">https://pjreddie.com/media/files/yolov3.weights</a></span></pre><ul class=""><li id="dec5" class="lu lv jj la b lb lc le lf lh lw ll lx lp ly lt lz ma mb mc bi translated">然后执行 YOLOv3 python 文件</li></ul><pre class="nh ni nj nk gt os ot ou ov aw ow bi"><span id="f659" class="nm mj jj ot b gy ox oy l oz pa">python darknet.py</span></pre><ul class=""><li id="9cb0" class="lu lv jj la b lb lc le lf lh lw ll lx lp ly lt lz ma mb mc bi translated"><strong class="la jk">成绩:</strong></li></ul><p id="65fe" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">结果应该保存在文件夹`。/数据/结果'</p><figure class="nh ni nj nk gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi pt"><img src="../Images/a8b9f5c98033cd1a0111c4fa3b6156a1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ySnKobAGy8_NFze7U0goYQ.png"/></div></div></figure><pre class="nh ni nj nk gt os ot ou ov aw ow bi"><span id="8a41" class="nm mj jj ot b gy ox oy l oz pa">Output: The mean recognition time over 500 images is 0.044 seconds</span></pre></div><div class="ab cl nz oa hx ob" role="separator"><span class="oc bw bk od oe of"/><span class="oc bw bk od oe of"/><span class="oc bw bk od oe"/></div><div class="im in io ip iq"><h2 id="dbc3" class="nm mj jj bd mk nn no dn mo np nq dp ms lh nr ns mu ll nt nu mw lp nv nw my nx bi translated">2)使用 Python 中的 NVIDIA TensorRT 优化并运行 YOLOv3</h2><figure class="nh ni nj nk gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi ny"><img src="../Images/4df18bb9be43a5bc685250020c5dfea7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*XM_KOVzJlT1F3sqP1Azfeg.png"/></div></div></figure><p id="ce30" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">第一步是导入模型，包括从磁盘上保存的文件中加载模型，并将其从原生框架或格式转换为 TensorRT 网络。我们的示例从 ONNX 模型加载 ONNX 格式的模型。</p><blockquote class="om on oo"><p id="6f39" class="ky kz nf la b lb lc kk ld le lf kn lg op li lj lk oq lm ln lo or lq lr ls lt im bi translated">ONNX 是一种表示深度学习模型的标准，使它们能够在框架之间转移。(许多框架如 Caffe2、Chainer、CNTK、PaddlePaddle、PyTorch 和 MXNet 都支持 ONNX 格式)。</p></blockquote><p id="e9b2" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">接下来，基于输入模型、目标 GPU 平台和指定的其他配置参数构建优化的 TensorRT 引擎。最后一步是向 TensorRT 引擎提供输入数据以执行推理。</p><p id="4073" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">该示例使用 TensorRT 中的以下组件来执行上述步骤:<br/> - ONNX 解析器:将 ONNX 格式的训练模型作为输入，并在 TensorRT 中填充网络对象<br/> -构建器:在 TensorRT 中获取网络，并生成针对目标平台优化的引擎<br/> -引擎:获取输入数据，执行推理并发出推理输出<br/> -记录器:与构建器和引擎相关联的对象，用于在构建和推理阶段捕获错误、警告和其他信息</p><div class="is it gp gr iu pb"><a href="https://gitlab.com/aminehy/YOLOv3-Darknet-ONNX-TensorRT" rel="noopener  ugc nofollow" target="_blank"><div class="pc ab fo"><div class="pd ab pe cl cj pf"><h2 class="bd jk gy z fp pg fr fs ph fu fw ji bi translated">胺 Hy/yolov 3-Darknet-ONNX-TensorRT</h2><div class="pi l"><h3 class="bd b gy z fp pg fr fs ph fu fw dk translated">GitLab.com</h3></div><div class="pj l"><p class="bd b dl z fp pg fr fs ph fu fw dk translated">gitlab.com</p></div></div><div class="pl l"><div class="pu l pn po pp pl pq ja pb"/></div></div></a></div><ul class=""><li id="7044" class="lu lv jj la b lb lc le lf lh lw ll lx lp ly lt lz ma mb mc bi translated">从 GitHub 获取项目并更改工作目录</li></ul><pre class="nh ni nj nk gt os ot ou ov aw ow bi"><span id="f98a" class="nm mj jj ot b gy ox oy l oz pa">git clone <a class="ae jg" href="https://gitlab.com/aminehy/YOLOv3-Darknet-ONNX-TensorRT.git" rel="noopener ugc nofollow" target="_blank">https://gitlab.com/aminehy/YOLOv3-Darknet-ONNX-TensorRT.git</a></span><span id="bfda" class="nm mj jj ot b gy ps oy l oz pa">cd YOLOv3-Darknet-ONNX-TensorRT/</span></pre><ul class=""><li id="b198" class="lu lv jj la b lb lc le lf lh lw ll lx lp ly lt lz ma mb mc bi translated">将模型从 Darknet 转换为 ONNX。这一步将创建一个名为` yolov3.onnx `的引擎</li></ul><pre class="nh ni nj nk gt os ot ou ov aw ow bi"><span id="2bb7" class="nm mj jj ot b gy ox oy l oz pa">python yolov3_to_onnx.py</span></pre><ul class=""><li id="00ea" class="lu lv jj la b lb lc le lf lh lw ll lx lp ly lt lz ma mb mc bi translated">将模型从 ONNX 转换为 TensorRT。这一步将创建一个名为 yolov3.trt 的引擎，并用于推理</li></ul><pre class="nh ni nj nk gt os ot ou ov aw ow bi"><span id="fe6f" class="nm mj jj ot b gy ox oy l oz pa">python onnx_to_tensorrt.py</span></pre><ul class=""><li id="455e" class="lu lv jj la b lb lc le lf lh lw ll lx lp ly lt lz ma mb mc bi translated">对于这个实验，我们设置这个参数:builder.fp16_mode = True</li></ul><pre class="nh ni nj nk gt os ot ou ov aw ow bi"><span id="af70" class="nm mj jj ot b gy ox oy l oz pa">builder.fp16_mode = True<br/>builder.strict_type_constraints = True</span></pre><ul class=""><li id="11b8" class="lu lv jj la b lb lc le lf lh lw ll lx lp ly lt lz ma mb mc bi translated"><strong class="la jk">成绩:</strong></li></ul><figure class="nh ni nj nk gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi pt"><img src="../Images/3c66b2bd7878fb4841c2bd30e508e2b3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*zcFERKUD21QuPYmK945eiw.png"/></div></div></figure><pre class="nh ni nj nk gt os ot ou ov aw ow bi"><span id="ce69" class="nm mj jj ot b gy ox oy l oz pa"><br/>Output: The mean recognition time over 500 images is 0.018 seconds using the precision fp16. </span></pre><p id="b84d" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi pv translated">因此，使用 NVIDIA TensorRT 比未优化版本快 2.31 倍！。</p></div><div class="ab cl nz oa hx ob" role="separator"><span class="oc bw bk od oe of"/><span class="oc bw bk od oe of"/><span class="oc bw bk od oe"/></div><div class="im in io ip iq"><h2 id="47b3" class="nm mj jj bd mk nn no dn mo np nq dp ms lh nr ns mu ll nt nu mw lp nv nw my nx bi translated">3)通过在 C++中导入 Caffe 模型，使用 NVIDIA TensorRT 优化并运行 YOLOv3</h2><figure class="nh ni nj nk gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi ny"><img src="../Images/beb33c509da5a97106948f4254a013e1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*N1LE_DRYsRdwHWJh6kkE_w.png"/></div></div></figure><ul class=""><li id="fc68" class="lu lv jj la b lb lc le lf lh lw ll lx lp ly lt lz ma mb mc bi translated">获取项目并更改工作目录</li></ul><div class="is it gp gr iu pb"><a href="https://gitlab.com/aminehy/YOLOv3-Caffe-TensorRT" rel="noopener  ugc nofollow" target="_blank"><div class="pc ab fo"><div class="pd ab pe cl cj pf"><h2 class="bd jk gy z fp pg fr fs ph fu fw ji bi translated">胺 Hy / YOLOv3-Caffe-TensorRT</h2><div class="pi l"><h3 class="bd b gy z fp pg fr fs ph fu fw dk translated">Yolov3 的 TensorRT</h3></div><div class="pj l"><p class="bd b dl z fp pg fr fs ph fu fw dk translated">gitlab.com</p></div></div><div class="pl l"><div class="qe l pn po pp pl pq ja pb"/></div></div></a></div><p id="58b4" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">如果文件夹`/Caffe '不存在(出于任何原因)，请下载 YOLOv3 的模型架构和权重(。prototxt 和。caffemodel)并将其插入到文件夹“Caffe”中。有两种选择，416 型和 608 型。这些参数表示 YOLOv3 网络输入端图像的高度/宽度。</p><ul class=""><li id="8920" class="lu lv jj la b lb lc le lf lh lw ll lx lp ly lt lz ma mb mc bi translated">从 Google Drive 文件夹下载文件:<a class="ae jg" href="http://cd TensorRT-Yolov3/ ./docker_TensorRT_OpenCV_Python.sh run" rel="noopener ugc nofollow" target="_blank">https://Drive . Google . com/Drive/folders/18 oxncrrdrcumoamgngjlhegglq 1 hqk _ NJ</a></li><li id="0167" class="lu lv jj la b lb md le me lh mf ll mg lp mh lt lz ma mb mc bi translated">编译并构建模型</li></ul><pre class="nh ni nj nk gt os ot ou ov aw ow bi"><span id="1d4f" class="nm mj jj ot b gy ox oy l oz pa">git submodule update — init — recursive</span><span id="a6a0" class="nm mj jj ot b gy ps oy l oz pa">mkdir build</span><span id="a29b" class="nm mj jj ot b gy ps oy l oz pa">cd build &amp;&amp; cmake .. &amp;&amp; make &amp;&amp; make install &amp;&amp; cd ..</span></pre><ul class=""><li id="b05b" class="lu lv jj la b lb lc le lf lh lw ll lx lp ly lt lz ma mb mc bi translated">编辑 YOLO 配置文件，并在以下设置中选择 YOLO 416 或 YOLO 608</li></ul><pre class="nh ni nj nk gt os ot ou ov aw ow bi"><span id="db19" class="nm mj jj ot b gy ox oy l oz pa">~/TensorRT-Yolov3/tensorRTWrapper/code/include/YoloConfigs.h</span></pre><ul class=""><li id="5771" class="lu lv jj la b lb lc le lf lh lw ll lx lp ly lt lz ma mb mc bi translated">您还需要查看位于</li></ul><pre class="nh ni nj nk gt os ot ou ov aw ow bi"><span id="da45" class="nm mj jj ot b gy ox oy l oz pa">~/TensorRT-Yolov3/include/configs.h</span></pre><ul class=""><li id="c9b8" class="lu lv jj la b lb lc le lf lh lw ll lx lp ly lt lz ma mb mc bi translated">如上所述创建 TensorRT 引擎，并在测试映像“dog.jpg”上运行 YOLOv3</li></ul><pre class="nh ni nj nk gt os ot ou ov aw ow bi"><span id="ec07" class="nm mj jj ot b gy ox oy l oz pa"># for yolov3–416 (don’t forget to edit YoloConfigs.h for YoloKernel)<br/>./install/runYolov3 — caffemodel=./caffe/yolov3_416.caffemodel — prototxt=./caffe/yolov3_416.prototxt — input=./dog.jpg — W=416 — H=416 — class=80 — mode=fp16</span></pre><ul class=""><li id="bf04" class="lu lv jj la b lb lc le lf lh lw ll lx lp ly lt lz ma mb mc bi translated">一旦创建了引擎，就可以将它作为参数传递</li></ul><pre class="nh ni nj nk gt os ot ou ov aw ow bi"><span id="2d8f" class="nm mj jj ot b gy ox oy l oz pa">./install/runYolov3 — caffemodel=./caffe/yolov3_416.caffemodel<br/> — prototxt=./caffe/yolov3_416.prototxt — input=./dog.jpg — W=416 — H=416 — class=80 — enginefile=./engine/yolov3_fp32.engine</span></pre><ul class=""><li id="de1a" class="lu lv jj la b lb lc le lf lh lw ll lx lp ly lt lz ma mb mc bi translated"><strong class="la jk">结果</strong>:</li></ul><pre class="nh ni nj nk gt os ot ou ov aw ow bi"><span id="9ba8" class="nm mj jj ot b gy ox oy l oz pa">Output: Time over all layers: 21.245 ms</span></pre></div><div class="ab cl nz oa hx ob" role="separator"><span class="oc bw bk od oe of"/><span class="oc bw bk od oe of"/><span class="oc bw bk od oe"/></div><div class="im in io ip iq"><p id="5a7f" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi pv translated"><span class="l pw px py bm pz qa qb qc qd di"> S </span>。</p><h1 id="91a6" class="mi mj jj bd mk ml mm mn mo mp mq mr ms kp mt kq mu ks mv kt mw kv mx kw my mz bi translated">结论</h1><p id="9a20" class="pw-post-body-paragraph ky kz jj la b lb na kk ld le nb kn lg lh nc lj lk ll nd ln lo lp ne lr ls lt im bi translated">本文介绍了优化预训练深度学习模型的重要性。我们在一个计算机视觉的目标检测应用的例子中说明了这一点，在这个例子中，我们获得了推理时间大于 2 的加速比。</p><p id="d14f" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><strong class="la jk">下一步怎么办？</strong></p><ul class=""><li id="4ac1" class="lu lv jj la b lb lc le lf lh lw ll lx lp ly lt lz ma mb mc bi translated">请在评论区告诉我你的想法，或者在 LinkedIn 上直接给我发消息。</li><li id="9b36" class="lu lv jj la b lb md le me lh mf ll mg lp mh lt lz ma mb mc bi translated">阅读我在 medium 上的另一篇文章:<a class="ae jg" rel="noopener" target="_blank" href="/convolutional-neural-network-for-image-classification-with-implementation-on-python-using-pytorch-7b88342c9ca9">使用 PyTorch 实现的图像分类深度学习</a></li></ul><h1 id="6e4b" class="mi mj jj bd mk ml mm mn mo mp mq mr ms kp mt kq mu ks mv kt mw kv mx kw my mz bi translated">参考</h1><ul class=""><li id="f8a9" class="lu lv jj la b lb na le nb lh qf ll qg lp qh lt lz ma mb mc bi translated">边缘摄像机 Pensar【https://pensarsdk.com/ T2】</li><li id="01c7" class="lu lv jj la b lb md le me lh mf ll mg lp mh lt lz ma mb mc bi translated">CUDA:【https://developer.nvidia.com/cuda-zone T4】</li><li id="4cad" class="lu lv jj la b lb md le me lh mf ll mg lp mh lt lz ma mb mc bi translated">https://docs.docker.com/</li><li id="c9e3" class="lu lv jj la b lb md le me lh mf ll mg lp mh lt lz ma mb mc bi translated">英伟达 TensorRT:<a class="ae jg" href="https://ngc.nvidia.com/catalog/containers/nvidia:tensorrt" rel="noopener ugc nofollow" target="_blank">https://ngc.nvidia.com/catalog/containers/nvidia:tensorrt</a></li><li id="a274" class="lu lv jj la b lb md le me lh mf ll mg lp mh lt lz ma mb mc bi translated">NVIDIA 容器最佳实践:<a class="ae jg" href="https://docs.nvidia.com/deeplearning/frameworks/bp-docker/index.html#docker-bp-topic" rel="noopener ugc nofollow" target="_blank">https://docs . NVIDIA . com/deep learning/frameworks/BP-docker/index . html # docker-BP-topic</a></li><li id="038d" class="lu lv jj la b lb md le me lh mf ll mg lp mh lt lz ma mb mc bi translated">tensor rt 19.05 版本:<a class="ae jg" href="https://docs.nvidia.com/deeplearning/sdk/tensorrt-container-release-notes/rel_19-05.html#rel_19-05" rel="noopener ugc nofollow" target="_blank">https://docs . NVIDIA . com/deep learning/SDK/tensor rt-container-Release-notes/rel _ 19-05 . html # rel _ 19-05</a></li></ul></div></div>    
</body>
</html>