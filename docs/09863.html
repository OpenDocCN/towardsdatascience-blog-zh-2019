<html>
<head>
<title>Keras for Beginners: Building Your First Neural Network</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">初学者的 Keras:建立你的第一个神经网络</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/keras-for-beginners-building-your-first-neural-network-f21cdf90789e?source=collection_archive---------14-----------------------#2019-12-26">https://towardsdatascience.com/keras-for-beginners-building-your-first-neural-network-f21cdf90789e?source=collection_archive---------14-----------------------#2019-12-26</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="bfb6" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">关于使用 Keras 在 Python 中实现简单神经网络的初学者友好指南。</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ki"><img src="../Images/dad0e9bdbc887a85f37c635b3de981d6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*qxZ4ZNqtOaICAMVK.png"/></div></figure><p id="6dec" class="pw-post-body-paragraph kq kr it ks b kt ku ju kv kw kx jx ky kz la lb lc ld le lf lg lh li lj lk ll im bi translated"><a class="ae lm" href="https://keras.io/" rel="noopener ugc nofollow" target="_blank"> Keras </a>是一个简单易用但功能强大的 Python 深度学习库。在这篇文章中，我们将看到建立一个前馈神经网络并训练它解决 Keras 的一个实际问题是多么容易。</p><p id="5f46" class="pw-post-body-paragraph kq kr it ks b kt ku ju kv kw kx jx ky kz la lb lc ld le lf lg lh li lj lk ll im bi translated">这篇文章是为完全初学 Keras 的人写的，但是假设他有神经网络的基础背景知识。我的<a class="ae lm" href="https://victorzhou.com/blog/intro-to-neural-networks/" rel="noopener ugc nofollow" target="_blank">关于神经网络的介绍</a>涵盖了这篇文章中你需要知道的一切(以及更多)——如果有必要的话，请先阅读。</p><p id="899a" class="pw-post-body-paragraph kq kr it ks b kt ku ju kv kw kx jx ky kz la lb lc ld le lf lg lh li lj lk ll im bi translated">我们开始吧！</p><blockquote class="ln lo lp"><p id="997b" class="kq kr lq ks b kt ku ju kv kw kx jx ky lr la lb lc ls le lf lg lt li lj lk ll im bi translated"><em class="it">只想要代码？下面是</em> <a class="ae lm" href="https://victorzhou.com/blog/keras-neural-network-tutorial/#the-full-code" rel="noopener ugc nofollow" target="_blank"> <em class="it">完整源代码</em> </a> <em class="it">。</em></p></blockquote><h1 id="4f79" class="lu lv it bd lw lx ly lz ma mb mc md me jz mf ka mg kc mh kd mi kf mj kg mk ml bi translated">问题:MNIST 数字分类</h1><p id="6ddf" class="pw-post-body-paragraph kq kr it ks b kt mm ju kv kw mn jx ky kz mo lb lc ld mp lf lg lh mq lj lk ll im bi translated">我们要解决一个经典的机器学习问题:<a class="ae lm" href="http://yann.lecun.com/exdb/mnist/" rel="noopener ugc nofollow" target="_blank"> MNIST </a>手写数字分类。很简单:给定一个图像，将其归类为一个数字。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi mr"><img src="../Images/eeed2a274919674a07d4e0ce21fef947.png" data-original-src="https://miro.medium.com/v2/resize:fit:1188/format:webp/0*wI5s4lKMnu0-1oqI.png"/></div><figcaption class="ms mt gj gh gi mu mv bd b be z dk">Sample images from the MNIST dataset</figcaption></figure><p id="23fc" class="pw-post-body-paragraph kq kr it ks b kt ku ju kv kw kx jx ky kz la lb lc ld le lf lg lh li lj lk ll im bi translated">MNIST 数据集中的每幅图像都是 28x28，包含一个居中的灰度数字。我们将把每个 28x28 展平成一个 784 维向量，我们将把它作为神经网络的输入。我们的输出将是 10 个可能的类之一:每个数字一个。</p><h1 id="124f" class="lu lv it bd lw lx ly lz ma mb mc md me jz mf ka mg kc mh kd mi kf mj kg mk ml bi translated">1.设置</h1><p id="ce96" class="pw-post-body-paragraph kq kr it ks b kt mm ju kv kw mn jx ky kz mo lb lc ld mp lf lg lh mq lj lk ll im bi translated">我假设您已经准备好了基本的 Python 安装(您可能已经准备好了)。让我们首先安装一些我们需要的软件包:</p><pre class="kj kk kl km gt mw mx my mz aw na bi"><span id="fd00" class="nb lv it mx b gy nc nd l ne nf">$ pip install keras tensorflow numpy mnist</span></pre><blockquote class="ln lo lp"><p id="1ac5" class="kq kr lq ks b kt ku ju kv kw kx jx ky lr la lb lc ls le lf lg lt li lj lk ll im bi translated"><em class="it">注意:我们需要安装</em> <code class="fe ng nh ni mx b"><em class="it">tensorflow</em></code> <em class="it">，因为我们要在一个</em><a class="ae lm" href="https://www.tensorflow.org/" rel="noopener ugc nofollow" target="_blank"><em class="it">TensorFlow</em></a><em class="it">后端上运行 Keras(即 tensor flow 将为 Keras 供电)。</em></p></blockquote><p id="0840" class="pw-post-body-paragraph kq kr it ks b kt ku ju kv kw kx jx ky kz la lb lc ld le lf lg lh li lj lk ll im bi translated">现在，您应该能够导入这些包并浏览 MNIST 数据集:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nj nk l"/></div></figure><h1 id="ec30" class="lu lv it bd lw lx ly lz ma mb mc md me jz mf ka mg kc mh kd mi kf mj kg mk ml bi translated">2.准备数据</h1><p id="9168" class="pw-post-body-paragraph kq kr it ks b kt mm ju kv kw mn jx ky kz mo lb lc ld mp lf lg lh mq lj lk ll im bi translated">如前所述，我们需要将每个图像展平，然后才能将其传递到我们的神经网络中。我们还将从[0，255]到[-0.5，0.5]归一化像素值，以使我们的网络更容易训练(使用较小的居中值通常更好)。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nj nk l"/></div></figure><p id="ee6f" class="pw-post-body-paragraph kq kr it ks b kt ku ju kv kw kx jx ky kz la lb lc ld le lf lg lh li lj lk ll im bi translated">我们准备好开始构建我们的神经网络了！</p><h1 id="1b09" class="lu lv it bd lw lx ly lz ma mb mc md me jz mf ka mg kc mh kd mi kf mj kg mk ml bi translated">3.构建模型</h1><p id="fb63" class="pw-post-body-paragraph kq kr it ks b kt mm ju kv kw mn jx ky kz mo lb lc ld mp lf lg lh mq lj lk ll im bi translated">每个 Keras 模型要么使用代表线性层堆栈的<a class="ae lm" href="https://keras.io/models/sequential/" rel="noopener ugc nofollow" target="_blank">顺序</a>类构建，要么使用可定制性更强的功能性<a class="ae lm" href="https://keras.io/models/model/" rel="noopener ugc nofollow" target="_blank">模型</a>类构建。我们将使用更简单的<code class="fe ng nh ni mx b">Sequential</code>模型，因为我们的网络实际上是层的线性堆叠。</p><p id="8647" class="pw-post-body-paragraph kq kr it ks b kt ku ju kv kw kx jx ky kz la lb lc ld le lf lg lh li lj lk ll im bi translated">我们从实例化一个<code class="fe ng nh ni mx b">Sequential</code>模型开始:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nj nk l"/></div></figure><p id="e583" class="pw-post-body-paragraph kq kr it ks b kt ku ju kv kw kx jx ky kz la lb lc ld le lf lg lh li lj lk ll im bi translated"><code class="fe ng nh ni mx b">Sequential</code>构造器接受一个 Keras <a class="ae lm" href="https://keras.io/layers/about-keras-layers/" rel="noopener ugc nofollow" target="_blank">层</a>的数组。因为我们只是在构建一个标准的前馈网络，所以我们只需要<a class="ae lm" href="https://keras.io/layers/core/#dense" rel="noopener ugc nofollow" target="_blank">密集</a>层，也就是常规的全连接(密集)网络层。</p><p id="12e6" class="pw-post-body-paragraph kq kr it ks b kt ku ju kv kw kx jx ky kz la lb lc ld le lf lg lh li lj lk ll im bi translated">让我们扔进 3 层<code class="fe ng nh ni mx b">Dense</code>:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nj nk l"/></div></figure><p id="e62e" class="pw-post-body-paragraph kq kr it ks b kt ku ju kv kw kx jx ky kz la lb lc ld le lf lg lh li lj lk ll im bi translated">前两层各有 64 个节点，使用<a class="ae lm" href="https://en.wikipedia.org/wiki/Rectifier_(neural_networks)" rel="noopener ugc nofollow" target="_blank"> ReLU </a>激活功能。最后一层是一个有 10 个节点的<a class="ae lm" href="https://victorzhou.com/blog/softmax/" rel="noopener ugc nofollow" target="_blank"> Softmax </a>输出层，每个类一个节点。</p><blockquote class="ln lo lp"><p id="93fc" class="kq kr lq ks b kt ku ju kv kw kx jx ky lr la lb lc ls le lf lg lt li lj lk ll im bi translated"><em class="it">如果需要复习，读我的</em> <a class="ae lm" href="https://victorzhou.com/blog/softmax/" rel="noopener ugc nofollow" target="_blank"> <em class="it">简单 Softmax 解释</em> </a> <em class="it">。</em></p></blockquote><p id="39b8" class="pw-post-body-paragraph kq kr it ks b kt ku ju kv kw kx jx ky kz la lb lc ld le lf lg lh li lj lk ll im bi translated">我们总是需要做的最后一件事是<strong class="ks iu">告诉 Keras 我们的网络的输入将会是什么样子</strong>。我们可以通过给<code class="fe ng nh ni mx b">Sequential</code>模型中的第一层指定一个<code class="fe ng nh ni mx b">input_shape</code>来实现:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nj nk l"/></div></figure><p id="4858" class="pw-post-body-paragraph kq kr it ks b kt ku ju kv kw kx jx ky kz la lb lc ld le lf lg lh li lj lk ll im bi translated">指定输入形状后，Keras 将自动推断后续图层的输入形状。我们已经完成了模型的定义！我们的情况是这样的:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nj nk l"/></div></figure><h1 id="6dff" class="lu lv it bd lw lx ly lz ma mb mc md me jz mf ka mg kc mh kd mi kf mj kg mk ml bi translated">4.编译模型</h1><p id="a765" class="pw-post-body-paragraph kq kr it ks b kt mm ju kv kw mn jx ky kz mo lb lc ld mp lf lg lh mq lj lk ll im bi translated">在开始培训之前，我们需要配置培训流程。在编译步骤中，我们决定 3 个关键因素:</p><ul class=""><li id="ae7a" class="nl nm it ks b kt ku kw kx kz nn ld no lh np ll nq nr ns nt bi translated"><strong class="ks iu">优化器</strong>。我们将坚持一个非常好的默认设置:基于梯度的优化器。Keras 还有许多其他的优化器，你也可以看看。</li><li id="7d38" class="nl nm it ks b kt nu kw nv kz nw ld nx lh ny ll nq nr ns nt bi translated"><strong class="ks iu">损失函数</strong>。由于我们使用的是 Softmax 输出层，我们将使用交叉熵损失。Keras 区分了<code class="fe ng nh ni mx b">binary_crossentropy</code> (2 类)和<code class="fe ng nh ni mx b">categorical_crossentropy</code> ( &gt; 2 类)，所以我们将使用后者。<a class="ae lm" href="https://keras.io/losses/" rel="noopener ugc nofollow" target="_blank">查看所有 Keras 损失</a>。</li><li id="f320" class="nl nm it ks b kt nu kw nv kz nw ld nx lh ny ll nq nr ns nt bi translated">一系列<strong class="ks iu">指标</strong>。由于这是一个分类问题，我们将让 Keras 报告<strong class="ks iu">准确性</strong>指标。</li></ul><p id="9315" class="pw-post-body-paragraph kq kr it ks b kt ku ju kv kw kx jx ky kz la lb lc ld le lf lg lh li lj lk ll im bi translated">这是编译后的样子:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nj nk l"/></div></figure><p id="e731" class="pw-post-body-paragraph kq kr it ks b kt ku ju kv kw kx jx ky kz la lb lc ld le lf lg lh li lj lk ll im bi translated">向前！</p><h1 id="b196" class="lu lv it bd lw lx ly lz ma mb mc md me jz mf ka mg kc mh kd mi kf mj kg mk ml bi translated">5.训练模型</h1><p id="e99f" class="pw-post-body-paragraph kq kr it ks b kt mm ju kv kw mn jx ky kz mo lb lc ld mp lf lg lh mq lj lk ll im bi translated">在 Keras 中训练一个模型实际上只包括调用<code class="fe ng nh ni mx b">fit()</code>和指定一些参数。有<a class="ae lm" href="https://keras.io/models/sequential/#fit" rel="noopener ugc nofollow" target="_blank">许多可能的参数</a>，但我们将只手动提供几个:</p><ul class=""><li id="4482" class="nl nm it ks b kt ku kw kx kz nn ld no lh np ll nq nr ns nt bi translated"><strong class="ks iu">训练数据</strong>(图像和标签)，分别俗称 X 和 Y。</li><li id="d998" class="nl nm it ks b kt nu kw nv kz nw ld nx lh ny ll nq nr ns nt bi translated">要训练的<strong class="ks iu">历元数</strong>(整个数据集的迭代次数)。</li><li id="0527" class="nl nm it ks b kt nu kw nv kz nw ld nx lh ny ll nq nr ns nt bi translated">训练时使用的<strong class="ks iu">批次大小</strong>(每次梯度更新的样本数)。</li></ul><p id="0295" class="pw-post-body-paragraph kq kr it ks b kt ku ju kv kw kx jx ky kz la lb lc ld le lf lg lh li lj lk ll im bi translated">看起来是这样的:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nj nk l"/></div></figure><p id="1619" class="pw-post-body-paragraph kq kr it ks b kt ku ju kv kw kx jx ky kz la lb lc ld le lf lg lh li lj lk ll im bi translated">然而，这实际上还没起作用——我们忽略了一件事。Keras 希望训练目标是<em class="lq"> 10 维向量</em>，因为在我们的 Softmax 输出层中有 10 个节点，但是我们提供了一个<em class="lq">单个整数来表示每个图像的类</em>。</p><p id="4e74" class="pw-post-body-paragraph kq kr it ks b kt ku ju kv kw kx jx ky kz la lb lc ld le lf lg lh li lj lk ll im bi translated">方便的是，Keras 有一个实用方法可以解决这个问题:<a class="ae lm" href="https://keras.io/utils/#to_categorical" rel="noopener ugc nofollow" target="_blank">to _ categorial</a>。相反，它将我们的类整数数组变成了一个由<a class="ae lm" href="https://en.wikipedia.org/wiki/One-hot" rel="noopener ugc nofollow" target="_blank">单热点</a>向量组成的数组。例如，<code class="fe ng nh ni mx b">2</code>会变成<code class="fe ng nh ni mx b">[0, 0, 1, 0, 0, 0, 0, 0, 0, 0]</code>(它是零索引的)。</p><p id="f475" class="pw-post-body-paragraph kq kr it ks b kt ku ju kv kw kx jx ky kz la lb lc ld le lf lg lh li lj lk ll im bi translated">我们现在可以将所有东西放在一起训练我们的网络:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nj nk l"/></div></figure><p id="27aa" class="pw-post-body-paragraph kq kr it ks b kt ku ju kv kw kx jx ky kz la lb lc ld le lf lg lh li lj lk ll im bi translated">运行这段代码会得到如下结果:</p><pre class="kj kk kl km gt mw mx my mz aw na bi"><span id="f7d8" class="nb lv it mx b gy nc nd l ne nf">Epoch 1/5<br/>60000/60000 [==============================] - 2s 35us/step - loss: 0.3772 - acc: 0.8859<br/>Epoch 2/5<br/>60000/60000 [==============================] - 2s 31us/step - loss: 0.1928 - acc: 0.9421<br/>Epoch 3/5<br/>60000/60000 [==============================] - 2s 31us/step - loss: 0.1469 - acc: 0.9536<br/>Epoch 4/5<br/>60000/60000 [==============================] - 2s 31us/step - loss: 0.1251 - acc: 0.9605<br/>Epoch 5/5<br/>60000/60000 [==============================] - 2s 31us/step - loss: 0.1079 - acc: 0.9663</span></pre><p id="b718" class="pw-post-body-paragraph kq kr it ks b kt ku ju kv kw kx jx ky kz la lb lc ld le lf lg lh li lj lk ll im bi translated">经过 5 个周期，我们达到了 96.6%的训练准确率。然而，这并没有告诉我们太多——我们可能过度适应了。真正的挑战将是看看我们的模型在我们的测试数据上表现如何。</p><h1 id="fc86" class="lu lv it bd lw lx ly lz ma mb mc md me jz mf ka mg kc mh kd mi kf mj kg mk ml bi translated">6.测试模型</h1><p id="9b51" class="pw-post-body-paragraph kq kr it ks b kt mm ju kv kw mn jx ky kz mo lb lc ld mp lf lg lh mq lj lk ll im bi translated">评估模型非常简单:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nj nk l"/></div></figure><p id="18fd" class="pw-post-body-paragraph kq kr it ks b kt ku ju kv kw kx jx ky kz la lb lc ld le lf lg lh li lj lk ll im bi translated">跑步带给我们:</p><pre class="kj kk kl km gt mw mx my mz aw na bi"><span id="34a2" class="nb lv it mx b gy nc nd l ne nf">10000/10000 [==============================] - 0s 15us/step<br/>[0.10821614159140736, 0.965]</span></pre><p id="1332" class="pw-post-body-paragraph kq kr it ks b kt ku ju kv kw kx jx ky kz la lb lc ld le lf lg lh li lj lk ll im bi translated"><a class="ae lm" href="https://keras.io/models/sequential/#evaluate" rel="noopener ugc nofollow" target="_blank"> evaluate() </a>返回一个数组，该数组包含测试损失，后跟我们指定的任何指标。因此，我们的模型实现了 0.108 的测试损失和 96.5%的测试精度！对你的第一个神经网络来说还不错。</p><h1 id="c6f6" class="lu lv it bd lw lx ly lz ma mb mc md me jz mf ka mg kc mh kd mi kf mj kg mk ml bi translated">7.使用模型</h1><p id="d96a" class="pw-post-body-paragraph kq kr it ks b kt mm ju kv kw mn jx ky kz mo lb lc ld mp lf lg lh mq lj lk ll im bi translated">现在我们有了一个工作的、经过训练的模型，让我们将它投入使用。我们要做的第一件事是将它保存到磁盘，这样我们就可以随时将它加载回来:</p><pre class="kj kk kl km gt mw mx my mz aw na bi"><span id="cf8e" class="nb lv it mx b gy nc nd l ne nf">model.save_weights('model.h5')</span></pre><p id="ee35" class="pw-post-body-paragraph kq kr it ks b kt ku ju kv kw kx jx ky kz la lb lc ld le lf lg lh li lj lk ll im bi translated">现在，我们可以随时通过重建模型并加载保存的权重来重新加载训练好的模型:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nj nk l"/></div></figure><p id="3928" class="pw-post-body-paragraph kq kr it ks b kt ku ju kv kw kx jx ky kz la lb lc ld le lf lg lh li lj lk ll im bi translated">使用训练好的模型进行预测很容易:我们将一个输入数组传递给<code class="fe ng nh ni mx b">predict()</code>，它返回一个输出数组。请记住，我们网络的输出是 10 个概率(因为 softmax)，所以我们将使用<a class="ae lm" href="https://docs.scipy.org/doc/numpy/reference/generated/numpy.argmax.html" rel="noopener ugc nofollow" target="_blank"> np.argmax() </a>将这些转换成实际的数字。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nj nk l"/></div></figure><h1 id="a60f" class="lu lv it bd lw lx ly lz ma mb mc md me jz mf ka mg kc mh kd mi kf mj kg mk ml bi translated">8.扩展ˌ扩张</h1><p id="8283" class="pw-post-body-paragraph kq kr it ks b kt mm ju kv kw mn jx ky kz mo lb lc ld mp lf lg lh mq lj lk ll im bi translated">到目前为止，我们所涉及的只是一个简单的介绍——我们还可以做更多的事情来试验和改进这个网络。我在下面列举了几个例子:</p><h2 id="6cdf" class="nb lv it bd lw nz oa dn ma ob oc dp me kz od oe mg ld of og mi lh oh oi mk oj bi translated">调谐超参数</h2><p id="8ef3" class="pw-post-body-paragraph kq kr it ks b kt mm ju kv kw mn jx ky kz mo lb lc ld mp lf lg lh mq lj lk ll im bi translated">一个好的超参数是<a class="ae lm" href="https://keras.io/optimizers/#adam" rel="noopener ugc nofollow" target="_blank">亚当</a>优化器的学习率。当你增加或减少它的时候会发生什么？</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nj nk l"/></div></figure><p id="0a96" class="pw-post-body-paragraph kq kr it ks b kt ku ju kv kw kx jx ky kz la lb lc ld le lf lg lh li lj lk ll im bi translated">批量大小和历元数呢？</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nj nk l"/></div></figure><h2 id="6a20" class="nb lv it bd lw nz oa dn ma ob oc dp me kz od oe mg ld of og mi lh oh oi mk oj bi translated">网络深度</h2><p id="9b21" class="pw-post-body-paragraph kq kr it ks b kt mm ju kv kw mn jx ky kz mo lb lc ld mp lf lg lh mq lj lk ll im bi translated">如果我们删除或添加更多全连接层，会发生什么？这对培训和/或模型的最终表现有什么影响？</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nj nk l"/></div></figure><h2 id="668c" class="nb lv it bd lw nz oa dn ma ob oc dp me kz od oe mg ld of og mi lh oh oi mk oj bi translated">激活</h2><p id="e7c5" class="pw-post-body-paragraph kq kr it ks b kt mm ju kv kw mn jx ky kz mo lb lc ld mp lf lg lh mq lj lk ll im bi translated">如果我们使用 ReLU 以外的激活，例如<a class="ae lm" href="https://en.wikipedia.org/wiki/Sigmoid_function" rel="noopener ugc nofollow" target="_blank"> sigmoid </a>，会怎么样？</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nj nk l"/></div></figure><h2 id="0d63" class="nb lv it bd lw nz oa dn ma ob oc dp me kz od oe mg ld of og mi lh oh oi mk oj bi translated">拒绝传统社会的人</h2><p id="8d97" class="pw-post-body-paragraph kq kr it ks b kt mm ju kv kw mn jx ky kz mo lb lc ld mp lf lg lh mq lj lk ll im bi translated">如果我们尝试添加<a class="ae lm" href="https://keras.io/layers/core/#dropout" rel="noopener ugc nofollow" target="_blank">下降</a>层，这是众所周知的防止过度拟合？</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nj nk l"/></div></figure><h2 id="8332" class="nb lv it bd lw nz oa dn ma ob oc dp me kz od oe mg ld of og mi lh oh oi mk oj bi translated">确认</h2><p id="6630" class="pw-post-body-paragraph kq kr it ks b kt mm ju kv kw mn jx ky kz mo lb lc ld mp lf lg lh mq lj lk ll im bi translated">我们还可以在训练期间使用测试数据集进行<strong class="ks iu">验证</strong>。Keras 将在每个时期结束时评估验证集上的模型，并报告损失和我们要求的任何指标。这使我们能够在训练期间监控模型的进度，这对于识别过度拟合甚至支持早期停止是有用的。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nj nk l"/></div></figure><h1 id="9585" class="lu lv it bd lw lx ly lz ma mb mc md me jz mf ka mg kc mh kd mi kf mj kg mk ml bi translated">结论</h1><p id="b62a" class="pw-post-body-paragraph kq kr it ks b kt mm ju kv kw mn jx ky kz mo lb lc ld mp lf lg lh mq lj lk ll im bi translated">你已经用 Keras 实现了你的第一个神经网络！我们在 5 个历元后在 MNIST 数据集上取得了<strong class="ks iu"> 96.5% </strong>的测试准确率，对于这样一个简单的网络来说已经不错了。我将在下面再次包含完整的源代码，供您参考。</p><p id="e7fc" class="pw-post-body-paragraph kq kr it ks b kt ku ju kv kw kx jx ky kz la lb lc ld le lf lg lh li lj lk ll im bi translated">如果你想了解接近 MNIST 的更先进的技术，我推荐查看我的<a class="ae lm" href="https://victorzhou.com/blog/intro-to-cnns-part-1/" rel="noopener ugc nofollow" target="_blank">卷积神经网络介绍</a>(CNN)。在这篇文章中，我们看到了如何使用更复杂的网络在 MNIST 上实现更高的准确率。我也推荐我的指南<a class="ae lm" href="https://victorzhou.com/blog/keras-cnn-tutorial/" rel="noopener ugc nofollow" target="_blank">用 Keras </a>实现一个 CNN，它类似于这篇文章。</p><p id="b86f" class="pw-post-body-paragraph kq kr it ks b kt ku ju kv kw kx jx ky kz la lb lc ld le lf lg lh li lj lk ll im bi translated">你可能感兴趣的进一步阅读材料包括:</p><ul class=""><li id="6c8a" class="nl nm it ks b kt ku kw kx kz nn ld no lh np ll nq nr ns nt bi translated">Keras 官方<a class="ae lm" href="https://keras.io/#getting-started-30-seconds-to-keras" rel="noopener ugc nofollow" target="_blank">入门</a>指南。</li><li id="e5ec" class="nl nm it ks b kt nu kw nv kz nw ld nx lh ny ll nq nr ns nt bi translated">这个<a class="ae lm" href="http://www.datastuff.tech/machine-learning/convolutional-neural-networks-an-introduction-tensorflow-eager/" rel="noopener ugc nofollow" target="_blank">用 Keras </a>介绍 CNN。</li><li id="f690" class="nl nm it ks b kt nu kw nv kz nw ld nx lh ny ll nq nr ns nt bi translated">一系列<a class="ae lm" href="https://github.com/keras-team/keras/tree/master/examples" rel="noopener ugc nofollow" target="_blank">的例子</a>。</li></ul><p id="8ac8" class="pw-post-body-paragraph kq kr it ks b kt ku ju kv kw kx jx ky kz la lb lc ld le lf lg lh li lj lk ll im bi translated">感谢阅读这篇文章！完整的源代码如下。</p><h1 id="ce72" class="lu lv it bd lw lx ly lz ma mb mc md me jz mf ka mg kc mh kd mi kf mj kg mk ml bi translated">完整的代码</h1><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nj nk l"/></div></figure></div><div class="ab cl ok ol hx om" role="separator"><span class="on bw bk oo op oq"/><span class="on bw bk oo op oq"/><span class="on bw bk oo op"/></div><div class="im in io ip iq"><p id="7ea5" class="pw-post-body-paragraph kq kr it ks b kt ku ju kv kw kx jx ky kz la lb lc ld le lf lg lh li lj lk ll im bi translated"><em class="lq">原载于</em><a class="ae lm" href="https://victorzhou.com/blog/keras-neural-network-tutorial/" rel="noopener ugc nofollow" target="_blank"><em class="lq">https://victorzhou.com</em></a><em class="lq">。</em></p></div></div>    
</body>
</html>