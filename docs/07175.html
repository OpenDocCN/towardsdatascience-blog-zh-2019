<html>
<head>
<title>Regression using sklearn on KC Housing Dataset</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">在 KC 住房数据集上使用 sklearn 进行回归</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/regression-using-sklearn-on-kc-housing-dataset-1ac80ca3d6d4?source=collection_archive---------4-----------------------#2019-10-10">https://towardsdatascience.com/regression-using-sklearn-on-kc-housing-dataset-1ac80ca3d6d4?source=collection_archive---------4-----------------------#2019-10-10</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><figure class="gl gn jr js jt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi jq"><img src="../Images/6fe8e78b6521fee02d121f2373f0cdef.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*N_8tfsb6pOJb71N8Mi5yvQ.png"/></div></div></figure><h1 id="8df7" class="kb kc it bd kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky bi translated">动机</h1><p id="224f" class="pw-post-body-paragraph kz la it lb b lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw im bi translated">为了预测 King County 的房价，我选择了来自 Kaggle 的房价数据集。该数据集包含 King 县(包括西雅图)的房屋销售价格。它包括 2014 年 5 月至 2015 年 5 月期间出售的房屋。它有很多学习的特点，数据集可以从<a class="ae lx" href="https://www.kaggle.com/harlfoxem/housesalesprediction" rel="noopener ugc nofollow" target="_blank">这里</a>下载。</p><h1 id="412d" class="kb kc it bd kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky bi translated">介绍</h1><p id="d99b" class="pw-post-body-paragraph kz la it lb b lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw im bi translated">回归的总体思路是考察两件事:(1)一组预测变量在预测一个结果(因变量)时是否做得很好？(2)哪些变量是结果变量的重要预测因子，它们是如何影响结果变量的——由β估计值的大小和符号表示？这些回归估计用于解释一个因变量和一个或多个自变量之间的关系。</p><h1 id="8ead" class="kb kc it bd kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky bi translated">执行的回归</h1><p id="aaa3" class="pw-post-body-paragraph kz la it lb b lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw im bi translated"><strong class="lb iu">简单线性回归</strong></p><ol class=""><li id="e75c" class="ly lz it lb b lc ma lg mb lk mc lo md ls me lw mf mg mh mi bi translated">卧室与价格</li><li id="40c4" class="ly lz it lb b lc mj lg mk lk ml lo mm ls mn lw mf mg mh mi bi translated">“等级”与“价格”</li></ol><p id="4188" class="pw-post-body-paragraph kz la it lb b lc ma le lf lg mb li lj lk mo lm ln lo mp lq lr ls mq lu lv lw im bi translated"><strong class="lb iu">多元回归</strong></p><ol class=""><li id="1d7b" class="ly lz it lb b lc ma lg mb lk mc lo md ls me lw mf mg mh mi bi translated">卧室'，'等级'，'居住面积'，'以上面积'</li><li id="2b2a" class="ly lz it lb b lc mj lg mk lk ml lo mm ls mn lw mf mg mh mi bi translated">'卧室'，'浴室'，' sqft_living '，' sqft_lot '，'楼层'，'海滨'，'景观'，'等级'，' sqft_above '，' sqft _ baseball '，' lat '，' sqft_living15 '</li></ol><p id="eac2" class="pw-post-body-paragraph kz la it lb b lc ma le lf lg mb li lj lk mo lm ln lo mp lq lr ls mq lu lv lw im bi translated"><strong class="lb iu">多项式回归</strong></p><ol class=""><li id="69bd" class="ly lz it lb b lc ma lg mb lk mc lo md ls me lw mf mg mh mi bi translated">度数=2</li><li id="5d46" class="ly lz it lb b lc mj lg mk lk ml lo mm ls mn lw mf mg mh mi bi translated">度数=3</li></ol><h1 id="c11a" class="kb kc it bd kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky bi translated">描述</h1><p id="95f6" class="pw-post-body-paragraph kz la it lb b lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw im bi translated">在该数据集中，显示了西雅图金县<strong class="lb iu">房屋的销售价格</strong>。它包括 2014 年 5 月至 2015 年 5 月期间出售的房屋。在做任何事情之前，我们应该首先了解数据集，它包含什么，它的特征是什么，以及数据的结构是什么。</p><p id="2f23" class="pw-post-body-paragraph kz la it lb b lc ma le lf lg mb li lj lk mo lm ln lo mp lq lr ls mq lu lv lw im bi translated">通过观察数据，我们可以知道<strong class="lb iu">价格取决于各种功能</strong>，如卧室(最依赖的功能)、浴室、sqft_living(第二重要的功能)、sqft_lot、地板等。价格也取决于房子所在的位置。像滨水景观这样的其他特色对价格的依赖性较小。在所有记录中，没有<strong class="lb iu">缺失值，这有助于我们创建更好的模型。</strong></p><h1 id="ca24" class="kb kc it bd kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky bi translated">数据预处理</h1><p id="d5b6" class="pw-post-body-paragraph kz la it lb b lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw im bi translated">导入所需的库。</p><pre class="mr ms mt mu gt mv mw mx my aw mz bi"><span id="bc9e" class="na kc it mw b gy nb nc l nd ne"><em class="nf">#importing numpy and pandas, seaborn</em><br/><br/>import numpy as np <em class="nf">#linear algebra</em><br/>import pandas as pd <em class="nf">#datapreprocessing, CSV file I/O</em><br/>import seaborn as sns <em class="nf">#for plotting graphs</em><br/>import matplotlib.pyplot as plt</span></pre><p id="2207" class="pw-post-body-paragraph kz la it lb b lc ma le lf lg mb li lj lk mo lm ln lo mp lq lr ls mq lu lv lw im bi translated">阅读 CSV 文件。</p><pre class="mr ms mt mu gt mv mw mx my aw mz bi"><span id="c104" class="na kc it mw b gy nb nc l nd ne">df = pd.read_csv("../input/housesalesprediction/kc_house_data.csv")</span></pre><p id="9d30" class="pw-post-body-paragraph kz la it lb b lc ma le lf lg mb li lj lk mo lm ln lo mp lq lr ls mq lu lv lw im bi translated">pandas<strong class="lb iu"><em class="nf">data frame . info()</em></strong>函数用于获取数据帧的简明摘要。在对数据进行探索性分析时，这非常方便。为了快速浏览数据集，我们使用了<strong class="lb iu"><em class="nf">data frame . info()</em></strong>函数。</p><pre class="mr ms mt mu gt mv mw mx my aw mz bi"><span id="ccf5" class="na kc it mw b gy nb nc l nd ne">df.info()</span></pre><figure class="mr ms mt mu gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi ng"><img src="../Images/edfc54e0e7b2a81125d42828dd86beab.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*qEKOSuaotn3gzbyqYobAQg.png"/></div></div></figure><p id="d251" class="pw-post-body-paragraph kz la it lb b lc ma le lf lg mb li lj lk mo lm ln lo mp lq lr ls mq lu lv lw im bi translated">Pandas <strong class="lb iu"> head </strong>()方法用于返回一个数据帧或系列的前 n(默认为 5)行。</p><pre class="mr ms mt mu gt mv mw mx my aw mz bi"><span id="9158" class="na kc it mw b gy nb nc l nd ne">df.head()</span></pre><figure class="mr ms mt mu gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi nh"><img src="../Images/61af293e421234d3b1795d2e02df5f52.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*tLh_ceH_HdTFoMx4rsCkLw.png"/></div></div></figure><p id="424c" class="pw-post-body-paragraph kz la it lb b lc ma le lf lg mb li lj lk mo lm ln lo mp lq lr ls mq lu lv lw im bi translated">熊猫形状函数用于返回大小、<strong class="lb iu">形状</strong>以及数据帧和系列的尺寸。</p><pre class="mr ms mt mu gt mv mw mx my aw mz bi"><span id="30e9" class="na kc it mw b gy nb nc l nd ne"><em class="nf">#finding no of rows and columns</em><br/>df.shape</span></pre><figure class="mr ms mt mu gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi ni"><img src="../Images/622deab2d894b092fa17d5d41ed46f01.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*3uVWaW4mvp3MXGAQdiY77w.png"/></div></div></figure><p id="aa2f" class="pw-post-body-paragraph kz la it lb b lc ma le lf lg mb li lj lk mo lm ln lo mp lq lr ls mq lu lv lw im bi translated">调用 isnull()返回的 DataFrame 的 sum()将给出一个包含每列中 NaN 计数的数据的序列。</p><pre class="mr ms mt mu gt mv mw mx my aw mz bi"><span id="7217" class="na kc it mw b gy nb nc l nd ne">df.isnull().sum()</span></pre><figure class="mr ms mt mu gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi ng"><img src="../Images/edfc54e0e7b2a81125d42828dd86beab.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*qEKOSuaotn3gzbyqYobAQg.png"/></div></div></figure><p id="af46" class="pw-post-body-paragraph kz la it lb b lc ma le lf lg mb li lj lk mo lm ln lo mp lq lr ls mq lu lv lw im bi translated">找出卧室的数量。</p><pre class="mr ms mt mu gt mv mw mx my aw mz bi"><span id="4901" class="na kc it mw b gy nb nc l nd ne">df['bedrooms'].value_counts()</span></pre><figure class="mr ms mt mu gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi nj"><img src="../Images/e1e62684dae3beb8c82304b999232430.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*B3-066omGByjsqIon38R9g.png"/></div></div></figure><p id="704c" class="pw-post-body-paragraph kz la it lb b lc ma le lf lg mb li lj lk mo lm ln lo mp lq lr ls mq lu lv lw im bi translated">寻找海滨的伯爵。</p><figure class="mr ms mt mu gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi nk"><img src="../Images/6de728deca57f2551a03023f6e4710cf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*sSECExDvpCqoJaoYoImQzQ.png"/></div></div></figure><p id="43bf" class="pw-post-body-paragraph kz la it lb b lc ma le lf lg mb li lj lk mo lm ln lo mp lq lr ls mq lu lv lw im bi translated">寻找分数。</p><pre class="mr ms mt mu gt mv mw mx my aw mz bi"><span id="c1c1" class="na kc it mw b gy nb nc l nd ne">df['grade'].value_counts()</span></pre><figure class="mr ms mt mu gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi nl"><img src="../Images/fbcc403f87b5a788bbf1edf3ef66ca21.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*bMWmYyyJhd0qoMQmVtka-w.png"/></div></div></figure><p id="87d9" class="pw-post-body-paragraph kz la it lb b lc ma le lf lg mb li lj lk mo lm ln lo mp lq lr ls mq lu lv lw im bi translated">寻找条件计数。</p><pre class="mr ms mt mu gt mv mw mx my aw mz bi"><span id="2953" class="na kc it mw b gy nb nc l nd ne">df['condition'].value_counts()</span></pre><figure class="mr ms mt mu gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi nm"><img src="../Images/a9b2a11d09b2a9b844aa8ee42297dae6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ERr7fxSBHbFE5L0LOxKIaw.png"/></div></div></figure><p id="6bed" class="pw-post-body-paragraph kz la it lb b lc ma le lf lg mb li lj lk mo lm ln lo mp lq lr ls mq lu lv lw im bi translated">为卧室绘制了一个计数图。</p><pre class="mr ms mt mu gt mv mw mx my aw mz bi"><span id="5b86" class="na kc it mw b gy nb nc l nd ne">sns.countplot(df.bedrooms,order=df['bedrooms'].value_counts().index)</span></pre><figure class="mr ms mt mu gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi nn"><img src="../Images/3bf445f5fad60b33e340662b0fa473a1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*9mFUM4xPQ_RyEgmyUTZo_w.png"/></div></div></figure><p id="a8c5" class="pw-post-body-paragraph kz la it lb b lc ma le lf lg mb li lj lk mo lm ln lo mp lq lr ls mq lu lv lw im bi translated">sqft living 和价格之间绘制了一个柱状图，以了解价格随 sqft 的变化情况。</p><figure class="mr ms mt mu gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi nn"><img src="../Images/24f05859689a41269f09d96c2ec2dc67.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*HCWD0j_JWLNLOCq9e4ldRw.png"/></div></div></figure><p id="4fac" class="pw-post-body-paragraph kz la it lb b lc ma le lf lg mb li lj lk mo lm ln lo mp lq lr ls mq lu lv lw im bi translated">在上面的平方英尺和价格之间绘制一个柱状图，以观察价格如何随着上面的平方英尺而变化。</p><pre class="mr ms mt mu gt mv mw mx my aw mz bi"><span id="094f" class="na kc it mw b gy nb nc l nd ne">fig,axes=plt.subplots(nrows=1,ncols=1,figsize=(15,10))<br/>plt.title("house prices by sqft_above")<br/>plt.xlabel('sqft_above')<br/>plt.ylabel('house prices')<br/>plt.legend()<br/>sns.barplot(x='sqft_above',y='price',data=df)</span></pre><figure class="mr ms mt mu gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi no"><img src="../Images/17698b92a6a2cfddf44b91522e414893.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ymt1uCLDnwo-vst-42A0QA.png"/></div></div></figure><p id="6735" class="pw-post-body-paragraph kz la it lb b lc ma le lf lg mb li lj lk mo lm ln lo mp lq lr ls mq lu lv lw im bi translated">绘制了生活平方英尺的直方图。</p><pre class="mr ms mt mu gt mv mw mx my aw mz bi"><span id="46a6" class="na kc it mw b gy nb nc l nd ne">plt.hist('sqft_living',data=df,bins=5)</span></pre><figure class="mr ms mt mu gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi np"><img src="../Images/fe374d91dc7941086c70a81b7d145df5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*LoOiP-CgDgSWeHGYcHculg.png"/></div></div></figure><p id="b615" class="pw-post-body-paragraph kz la it lb b lc ma le lf lg mb li lj lk mo lm ln lo mp lq lr ls mq lu lv lw im bi translated">为 sqft living 绘制了 distplot，以查看数据是否有偏差</p><pre class="mr ms mt mu gt mv mw mx my aw mz bi"><span id="1075" class="na kc it mw b gy nb nc l nd ne">fig,axes=plt.subplots(nrows=1,ncols=1,figsize=(15,10))<br/>sns.distplot(df['sqft_living'],hist=True,kde=True,rug=False,label='sqft_living',norm_hist=True)</span></pre><figure class="mr ms mt mu gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi nq"><img src="../Images/32557062e485c96fe89fbbf877d1ab45.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*nyUJfoGW2E027oBAI6zIzA.png"/></div></div></figure><p id="d31c" class="pw-post-body-paragraph kz la it lb b lc ma le lf lg mb li lj lk mo lm ln lo mp lq lr ls mq lu lv lw im bi translated">为上面的 sqft 绘制了 distplot，以查看数据是否有偏差</p><pre class="mr ms mt mu gt mv mw mx my aw mz bi"><span id="9cbd" class="na kc it mw b gy nb nc l nd ne">fig,axes=plt.subplots(nrows=1,ncols=1,figsize=(15,10))<br/>sns.distplot(df['sqft_above'],hist=True,kde=True,rug=False,label='sqft_above',norm_hist=True)</span></pre><figure class="mr ms mt mu gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi nr"><img src="../Images/6f88f17929013367c1a1a52ebdca2c08.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*0kiBlFGi8JGWjgVorFW0Rg.png"/></div></div></figure><p id="9ede" class="pw-post-body-paragraph kz la it lb b lc ma le lf lg mb li lj lk mo lm ln lo mp lq lr ls mq lu lv lw im bi translated">寻找平方英尺生活的均值、众数和中位数。</p><pre class="mr ms mt mu gt mv mw mx my aw mz bi"><span id="5e4d" class="na kc it mw b gy nb nc l nd ne">print('Mean',round(df['sqft_living'].mean(),2))<br/>print('Median',df['sqft_living'].median())<br/>print('Mode',df['sqft_living'].mode()[0])</span></pre><figure class="mr ms mt mu gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi ns"><img src="../Images/43eb1470cb624082f74d1e0dce05896a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Xw2tri_7c7TtdbUHQuaXUg.png"/></div></div></figure><p id="348a" class="pw-post-body-paragraph kz la it lb b lc ma le lf lg mb li lj lk mo lm ln lo mp lq lr ls mq lu lv lw im bi translated">通过图表我们观察到 sqft living=1300 有更多的值。</p><pre class="mr ms mt mu gt mv mw mx my aw mz bi"><span id="640c" class="na kc it mw b gy nb nc l nd ne">len(df[df['sqft_living']==1300])</span></pre><figure class="mr ms mt mu gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi nt"><img src="../Images/dda1251e470c05a951279c48f7e308db.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*bLU7hHpvCbu-kHAbMMWRlw.png"/></div></div></figure><p id="9bd3" class="pw-post-body-paragraph kz la it lb b lc ma le lf lg mb li lj lk mo lm ln lo mp lq lr ls mq lu lv lw im bi translated">为了确保我们涵盖了所有的关系，我们使用热图绘制了所有特征之间的关联。</p><p id="9d5b" class="pw-post-body-paragraph kz la it lb b lc ma le lf lg mb li lj lk mo lm ln lo mp lq lr ls mq lu lv lw im bi translated"><strong class="lb iu">热图</strong>是数据的二维图形表示，矩阵中包含的各个值用颜色表示。</p><pre class="mr ms mt mu gt mv mw mx my aw mz bi"><span id="32e4" class="na kc it mw b gy nb nc l nd ne">def correlation_heatmap(df1):<br/>    _,ax=plt.subplots(figsize=(15,10))<br/>    colormap=sns.diverging_palette(220,10,as_cmap=True)<br/>    sns.heatmap(df.corr(),annot=True,cmap=colormap)<br/>    <br/>correlation_heatmap(df)</span></pre><figure class="mr ms mt mu gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi nu"><img src="../Images/86b4cb0044fa105b0045e5277626f750.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*LHOOSv22AE4xNYN2Ppa3Qw.png"/></div></div></figure><p id="6ef6" class="pw-post-body-paragraph kz la it lb b lc ma le lf lg mb li lj lk mo lm ln lo mp lq lr ls mq lu lv lw im bi translated">既然我们已经获得了足够的数据信息，我们就开始线性回归。</p><h1 id="7094" class="kb kc it bd kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky bi translated">简单线性回归</h1><figure class="mr ms mt mu gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi jq"><img src="../Images/6061121f99036a718b7fbafe9733bfc1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*87aMm1RRoaxS4Sy8Q-XMDg.png"/></div></div></figure><p id="6d04" class="pw-post-body-paragraph kz la it lb b lc ma le lf lg mb li lj lk mo lm ln lo mp lq lr ls mq lu lv lw im bi translated">对于线性回归，我们使用来自<strong class="lb iu"> sklearn </strong>函数的 linear_model。</p><p id="3e97" class="pw-post-body-paragraph kz la it lb b lc ma le lf lg mb li lj lk mo lm ln lo mp lq lr ls mq lu lv lw im bi translated"><strong class="lb iu"> Scikit-learn </strong>通过 Python 中的一致接口提供了一系列监督和非监督学习算法。该库建立在 SciPy(科学 Python)之上，在使用 scikit-learn 之前必须安装该库。用于 SciPy care 的扩展或模块通常称为<a class="ae lx" href="http://scikits.appspot.com/scikits" rel="noopener ugc nofollow" target="_blank"> SciKits </a>。因此，该模块提供了学习算法，并被命名为 scikit-learn。</p><p id="94bf" class="pw-post-body-paragraph kz la it lb b lc ma le lf lg mb li lj lk mo lm ln lo mp lq lr ls mq lu lv lw im bi translated">我们导入<strong class="lb iu"><em class="nf">train _ test _ split</em></strong><em class="nf">。</em>这将数据分割成所需的比率(例如:80–20)，其中一个比率用于训练数据，其余比率用于测试数据。训练数据以预测一条线，然后使用测试数据来查看这条线是否完全符合。</p><p id="8c3c" class="pw-post-body-paragraph kz la it lb b lc ma le lf lg mb li lj lk mo lm ln lo mp lq lr ls mq lu lv lw im bi translated"><strong class="lb iu"> <em class="nf">多项式特征</em> </strong>生成一个新的特征矩阵，由次数小于或等于指定次数的特征的所有多项式组合组成。</p><p id="4e20" class="pw-post-body-paragraph kz la it lb b lc ma le lf lg mb li lj lk mo lm ln lo mp lq lr ls mq lu lv lw im bi translated">引入<strong class="lb iu"> <em class="nf">度量</em> </strong>是因为度量模块实现了针对特定目的评估预测误差的功能。</p><p id="b9c1" class="pw-post-body-paragraph kz la it lb b lc ma le lf lg mb li lj lk mo lm ln lo mp lq lr ls mq lu lv lw im bi translated">在<strong class="lb iu"><em class="nf">KNeighborsRegressor</em></strong>中，通过对训练集中最近邻相关的目标进行局部插值来预测目标。</p><pre class="mr ms mt mu gt mv mw mx my aw mz bi"><span id="e669" class="na kc it mw b gy nb nc l nd ne">from sklearn.model_selection import train_test_split<br/>from sklearn import linear_model<br/>from sklearn.neighbors import KNeighborsRegressor<br/>from sklearn.preprocessing import PolynomialFeatures<br/>from sklearn import metrics<br/>from mpl_toolkits.mplot3d import Axes3D<br/>%matplotlib inline</span></pre><p id="f9d2" class="pw-post-body-paragraph kz la it lb b lc ma le lf lg mb li lj lk mo lm ln lo mp lq lr ls mq lu lv lw im bi translated">在这里，我们将数据分成 80:20 的比例，其中 train_size 为 80%，test_size 为 20%。<strong class="lb iu"> train_test_split </strong>将数组或矩阵分割成<strong class="lb iu">随机</strong>训练和测试子集。这意味着每次在没有指定 random_state 的情况下运行它，都会得到不同的结果，这是意料之中的行为。为了得到相同的训练和测试子集，我们声明一个<strong class="lb iu">随机状态</strong>。这里的 x 是‘sqft _ living’，y 是‘price’。我们正在重塑 x_train 和 y_train，数据是拟合的。x 检验和 y 检验用于预测模型的准确性。这里我们首先计算 y_test 的均方误差。找出训练和测试的均方误差。找到直线的<strong class="lb iu">截距和系数</strong>。</p><pre class="mr ms mt mu gt mv mw mx my aw mz bi"><span id="89ba" class="na kc it mw b gy nb nc l nd ne">train_data,test_data=train_test_split(df,train_size=0.8,random_state=3)<br/>reg=linear_model.LinearRegression()<br/>x_train=np.array(train_data['sqft_living']).reshape(-1,1)<br/>y_train=np.array(train_data['price']).reshape(-1,1)<br/>reg.fit(x_train,y_train)<br/><br/>x_test=np.array(test_data['sqft_living']).reshape(-1,1)<br/>y_test=np.array(test_data['price']).reshape(-1,1)<br/>pred=reg.predict(x_test)<br/>print('linear model')<br/>mean_squared_error=metrics.mean_squared_error(y_test,pred)<br/>print('Sqaured mean error', round(np.sqrt(mean_squared_error),2))<br/>print('R squared training',round(reg.score(x_train,y_train),3))<br/>print('R sqaured testing',round(reg.score(x_test,y_test),3) )<br/>print('intercept',reg.intercept_)<br/>print('coefficient',reg.coef_)</span></pre><figure class="mr ms mt mu gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi nv"><img src="../Images/8ed3e90cf7b6a7d9f79475153b97ec92.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*meARE_jV5pPw5SYbT_o55Q.png"/></div></div></figure><p id="de03" class="pw-post-body-paragraph kz la it lb b lc ma le lf lg mb li lj lk mo lm ln lo mp lq lr ls mq lu lv lw im bi translated"><strong class="lb iu"> R 平方检验:0.496 </strong></p><p id="b830" class="pw-post-body-paragraph kz la it lb b lc ma le lf lg mb li lj lk mo lm ln lo mp lq lr ls mq lu lv lw im bi translated">为 x_test，y_test 绘制了散点图。数据分布在图表上。现在绘制从上面获得的线，看看它如何适合数据。</p><pre class="mr ms mt mu gt mv mw mx my aw mz bi"><span id="6d00" class="na kc it mw b gy nb nc l nd ne">_, ax = plt.subplots(figsize= (12, 10))<br/>plt.scatter(x_test, y_test, color= 'darkgreen', label = 'data')<br/>plt.plot(x_test, reg.predict(x_test), color='red', label= ' Predicted Regression line')<br/>plt.xlabel('Living Space (sqft)')<br/>plt.ylabel('price')<br/>plt.legend()<br/>plt.gca().spines['right'].set_visible(False)<br/>plt.gca().spines['right'].set_visible(False)</span></pre><figure class="mr ms mt mu gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi nw"><img src="../Images/b6fb8a91979e9111827b96da63de660a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*mb3W7PG7iHyp4JRMoA7QGQ.png"/></div></div></figure><p id="ca1b" class="pw-post-body-paragraph kz la it lb b lc ma le lf lg mb li lj lk mo lm ln lo mp lq lr ls mq lu lv lw im bi translated">这里我们以 80:20 的比例分割数据，其中 train_size 为 80%，test_size 为 20%。这里 x 是‘等级’，y 是‘价格’。我们正在重塑 x_train 和 y_train，数据是拟合的。x 检验和 y 检验用于预测模型的准确性。这里我们首先计算 y_test 的均方误差。找出训练和测试的均方误差。找到直线的<strong class="lb iu">截距和系数</strong>。</p><pre class="mr ms mt mu gt mv mw mx my aw mz bi"><span id="4b9b" class="na kc it mw b gy nb nc l nd ne">train_data,test_data=train_test_split(df,train_size=0.8,random_state=3)<br/>reg=linear_model.LinearRegression()<br/>x_train=np.array(train_data['grade']).reshape(-1,1)<br/>y_train=np.array(train_data['price']).reshape(-1,1)<br/>reg.fit(x_train,y_train)<br/><br/>x_test=np.array(test_data['grade']).reshape(-1,1)<br/>y_test=np.array(test_data['price']).reshape(-1,1)<br/>pred=reg.predict(x_test)<br/>print('linear model')<br/>mean_squared_error=metrics.mean_squared_error(y_test,pred)<br/>print('squared mean error',round(np.sqrt(mean_squared_error),2))<br/>print('R squared training',round(reg.score(x_train,y_train),3))<br/>print('R squared testing',round(reg.score(x_test,y_test),3))<br/>print('intercept',reg.intercept_)<br/>print('coeeficient',reg.coef_)</span></pre><figure class="mr ms mt mu gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi nx"><img src="../Images/4b1b13ed9c99887cfe90a3c1582bf8a5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*bHy3hPOuFWyUl-ripNStQA.png"/></div></div></figure><p id="e21a" class="pw-post-body-paragraph kz la it lb b lc ma le lf lg mb li lj lk mo lm ln lo mp lq lr ls mq lu lv lw im bi translated"><strong class="lb iu"> R 平方检验:0.46 </strong></p><h1 id="1d97" class="kb kc it bd kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky bi translated">多元线性回归</h1><figure class="mr ms mt mu gt ju gh gi paragraph-image"><div class="gh gi ny"><img src="../Images/6bcd4cad81e7f31ee2ab9fd55bf17555.png" data-original-src="https://miro.medium.com/v2/resize:fit:1082/format:webp/1*8S3GObkHcimU-QXl3zgTlg.png"/></div></figure><p id="9d0e" class="pw-post-body-paragraph kz la it lb b lc ma le lf lg mb li lj lk mo lm ln lo mp lq lr ls mq lu lv lw im bi translated">箱线图是根据“价格”绘制的“等级”、“卧室”和“浴室”。</p><pre class="mr ms mt mu gt mv mw mx my aw mz bi"><span id="130e" class="na kc it mw b gy nb nc l nd ne">fig,ax=plt.subplots(2,1,figsize=(15,10))<br/>sns.boxplot(x=train_data['grade'],y=train_data['price'],ax=ax[0])<br/>sns.boxplot(x=train_data['bedrooms'],y=train_data['price'],ax=ax[1])<br/>_ , axes = plt.subplots(1, 1, figsize=(15,10))<br/>sns.boxplot(x=train_data['bathrooms'],y=train_data['price'])</span></pre><figure class="mr ms mt mu gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi nz"><img src="../Images/a3f23d146a68a23c03673aef66e10ac2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*O8uoUqePxbQwFOAAZwauoQ.png"/></div></div></figure><figure class="mr ms mt mu gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi oa"><img src="../Images/a084d57c642a412329fed9a02c18190a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*5xNXtZJqnbdbmwz5qlhrbQ.png"/></div></div></figure><p id="2e69" class="pw-post-body-paragraph kz la it lb b lc ma le lf lg mb li lj lk mo lm ln lo mp lq lr ls mq lu lv lw im bi translated">我们正在考虑的功能是'卧室'，'品位'，'平方英尺 _ 生活'和'平方英尺 _ 以上'。这些被认为是一个特征，即<strong class="lb iu">特征 1 </strong>。现在数据被拟合到模型中，并且<strong class="lb iu">特征 1 </strong>的测试数据被用于预测。计算 y_test 的均方误差。均方误差四舍五入到小数点后两位。计算训练和测试的 r 平方误差。计算直线的截距和单个特征的系数。</p><pre class="mr ms mt mu gt mv mw mx my aw mz bi"><span id="3bb1" class="na kc it mw b gy nb nc l nd ne">features1=['bedrooms','grade','sqft_living','sqft_above']<br/>reg=linear_model.LinearRegression()<br/>reg.fit(train_data[features1],train_data['price'])<br/>pred=reg.predict(test_data[features1])<br/>print('complex_model 1')<br/>mean_squared_error=metrics.mean_squared_error(y_test,pred)<br/>print('mean squared error(MSE)', round(np.sqrt(mean_squared_error),2))<br/>print('R squared training',round(reg.score(train_data[features1],train_data['price']),3))<br/>print('R squared training', round(reg.score(test_data[features1],test_data['price']),3))<br/>print('Intercept: ', reg.intercept_)<br/>print('Coefficient:', reg.coef_)</span></pre><figure class="mr ms mt mu gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi ob"><img src="../Images/3c420da171d85cbe41446abd2ad6cdff.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*jhMMtSg3-ARJcmZKSLS3xg.png"/></div></div></figure><p id="fc5c" class="pw-post-body-paragraph kz la it lb b lc ma le lf lg mb li lj lk mo lm ln lo mp lq lr ls mq lu lv lw im bi translated"><strong class="lb iu"> R 平方检验:0.555 </strong></p><p id="c4d0" class="pw-post-body-paragraph kz la it lb b lc ma le lf lg mb li lj lk mo lm ln lo mp lq lr ls mq lu lv lw im bi translated">我们正在考虑的功能是'卧室'，'浴室'，' sqft_living '，' sqft_lot '，'楼层'，'海滨'，' view '，' grade '，' sqft_above '，' sqft _ baseball '，' lat '，' sqft_living15 '。这些被认为是一个特征，即<strong class="lb iu">特征 2 </strong>。现在数据被拟合到模型中，并且<strong class="lb iu">特征 2 </strong>的测试数据被用于预测。计算 y_test 的均方误差。均方误差四舍五入到小数点后两位。计算训练和测试的 r 平方误差。计算直线的截距和单个特征的系数。</p><pre class="mr ms mt mu gt mv mw mx my aw mz bi"><span id="e556" class="na kc it mw b gy nb nc l nd ne">features2 = ['bedrooms','bathrooms','sqft_living','sqft_lot','floors','waterfront','view','grade','sqft_above','sqft_basement','lat','sqft_living15']<br/>reg= linear_model.LinearRegression()<br/>reg.fit(train_data[features1],train_data['price'])<br/>pred = reg.predict(test_data[features1])<br/>print('Complex Model_2')<br/>mean_squared_error = metrics.mean_squared_error(y_test, pred)<br/>print('Mean Squared Error (MSE) ', round(np.sqrt(mean_squared_error), 2))<br/>print('R-squared (training) ', round(reg.score(train_data[features1], train_data['price']), 3))<br/>print('R-squared (testing) ', round(reg.score(test_data[features1], test_data['price']), 3))<br/>print('Intercept: ', reg.intercept_)<br/>print('Coefficient:', reg.coef_)</span></pre><figure class="mr ms mt mu gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi oc"><img src="../Images/b9dac8691195fb9ec2a409ba978a6b80.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*gtCr1-dxB4CuV3C99QT2LQ.png"/></div></div></figure><p id="0c14" class="pw-post-body-paragraph kz la it lb b lc ma le lf lg mb li lj lk mo lm ln lo mp lq lr ls mq lu lv lw im bi translated"><strong class="lb iu"> R 平方检验:0.672 </strong></p><h1 id="384f" class="kb kc it bd kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky bi translated">多项式回归</h1><figure class="mr ms mt mu gt ju gh gi paragraph-image"><div class="gh gi od"><img src="../Images/2f181c8f24526906c36a67f67a79568d.png" data-original-src="https://miro.medium.com/v2/resize:fit:650/format:webp/1*ETE3zZn0YWLGpCDmzTZwsw.png"/></div></figure><p id="48a0" class="pw-post-body-paragraph kz la it lb b lc ma le lf lg mb li lj lk mo lm ln lo mp lq lr ls mq lu lv lw im bi translated"><strong class="lb iu">多项式回归</strong>是线性<strong class="lb iu">回归</strong>的一种形式，其中自变量 x 和因变量 y 之间的关系被建模为 n 次<strong class="lb iu">多项式</strong>。<strong class="lb iu">多项式回归</strong>拟合 x 的值和 y 的相应条件均值之间的非线性关系，表示为 E(y |x)。</p><p id="25be" class="pw-post-body-paragraph kz la it lb b lc ma le lf lg mb li lj lk mo lm ln lo mp lq lr ls mq lu lv lw im bi translated">对于度=2，建立线性模型。计算均方误差，并为训练和测试找到 r 的平方。</p><pre class="mr ms mt mu gt mv mw mx my aw mz bi"><span id="a39f" class="na kc it mw b gy nb nc l nd ne">polyfeat=PolynomialFeatures(degree=2)<br/>xtrain_poly=polyfeat.fit_transform(train_data[features1])<br/>xtest_poly=polyfeat.fit_transform(test_data[features1])<br/><br/>poly=linear_model.LinearRegression()<br/>poly.fit(xtrain_poly,train_data['price'])<br/>polypred=poly.predict(xtest_poly)<br/><br/>print('Complex Model_3')<br/>mean_squared_error = metrics.mean_squared_error(test_data['price'], polypred)<br/>print('Mean Squared Error (MSE) ', round(np.sqrt(mean_squared_error), 2))<br/>print('R-squared (training) ', round(poly.score(xtrain_poly, train_data['price']), 3))<br/>print('R-squared (testing) ', round(poly.score(xtest_poly, test_data['price']), 3))</span></pre><figure class="mr ms mt mu gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi oe"><img src="../Images/38fa502ceb7ed4d35052dc2b678d930f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*1BxKz4rCl_zhEFesnGiI_A.png"/></div></div></figure><p id="bd01" class="pw-post-body-paragraph kz la it lb b lc ma le lf lg mb li lj lk mo lm ln lo mp lq lr ls mq lu lv lw im bi translated"><strong class="lb iu"> R 平方检验:0.759 </strong></p><p id="8a59" class="pw-post-body-paragraph kz la it lb b lc ma le lf lg mb li lj lk mo lm ln lo mp lq lr ls mq lu lv lw im bi translated">对于度数=3，建立线性模型。计算均方误差，并为训练和测试找到 r 的平方。</p><pre class="mr ms mt mu gt mv mw mx my aw mz bi"><span id="abd3" class="na kc it mw b gy nb nc l nd ne">polyfeat=PolynomialFeatures(degree=3)<br/>xtrain_poly=polyfeat.fit_transform(train_data[features1])<br/>xtest_poly=polyfeat.fit_transform(test_data[features1])<br/><br/>poly=linear_model.LinearRegression()<br/>poly.fit(xtrain_poly,train_data['price'])<br/>polypred=poly.predict(xtest_poly)<br/><br/>print('complex model_4')<br/>mean_squared_error=metrics.mean_squared_error(test_data['price'],polypred)<br/>print('Mean Squared Error (MSE) ', round(np.sqrt(mean_squared_error), 2))<br/>print('R-squared (training) ', round(poly.score(xtrain_poly, train_data['price']), 3))<br/>print('R-squared (testing) ', round(poly.score(xtest_poly, test_data['price']), 3))</span></pre><figure class="mr ms mt mu gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi of"><img src="../Images/6eb6c7d1c7ed9d08d9af1eb1a8e81876.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*umV0zchvoWQQQWj4oz9_Eg.png"/></div></div></figure><p id="b2ef" class="pw-post-body-paragraph kz la it lb b lc ma le lf lg mb li lj lk mo lm ln lo mp lq lr ls mq lu lv lw im bi translated"><strong class="lb iu"> R 平方检验:0.664 </strong></p><h1 id="8f44" class="kb kc it bd kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky bi translated">观察</h1><p id="c5de" class="pw-post-body-paragraph kz la it lb b lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw im bi translated">复杂模型 3 给我们的 R 平方(测试)分数为 0.759。从上述报告中，我们可以得出结论，次数=2 的多项式回归是最佳解决方案。</p><p id="7b2a" class="pw-post-body-paragraph kz la it lb b lc ma le lf lg mb li lj lk mo lm ln lo mp lq lr ls mq lu lv lw im bi translated">对于笔记本，请参见此处的<a class="ae lx" href="https://www.kaggle.com/nikhilkumarmutyala/sales-regression-sklearn-simple-multiple-poly" rel="noopener ugc nofollow" target="_blank"/>。我将很高兴收到关于上述任何反馈或问题。</p></div></div>    
</body>
</html>