# 第一次 Kaggle 比赛经历

> 原文：<https://towardsdatascience.com/first-kaggle-competition-experience-804011c56a31?source=collection_archive---------26----------------------->

## 我第一次参加 kaggle 比赛的经历

![](img/338e4a79db68988bc5d475b070532c38.png)

Photo by [Victoire Joncheray](https://unsplash.com/@victoire_jonch?utm_source=medium&utm_medium=referral) on [Unsplash](https://unsplash.com?utm_source=medium&utm_medium=referral)

在我今年自学机器学习之旅的最初计划中，我曾承诺在任何两场(直播)Kaggle 比赛中进入前 25%。

这是一篇关于“rm-rf /”团队如何在我们有史以来的第一次 kaggle 比赛中进入前 30%的记录:“快，抽！涂鸦识别挑战”，由[谷歌](https://hackernoon.com/tagged/google)人工智能团队主办，在 kaggle 上。

特别说明:团队“rm-rf /”是由我的商业伙伴和朋友 [Rishi Bhalodia](https://medium.com/u/5dd0ee4fe1b1?source=post_page-----804011c56a31--------------------------------) 和我组成的两人团队。

# 经验

想象一下:一场持续三个月的比赛。没有终点线，有高分。你是学校里经验丰富的跑步运动员。

有什么问题吗？

你反对我光着脚跑的时候有人开着超跑超速(经验丰富的特级大师)。当然，我很擅长对付我的朋友，但是对付一辆车呢？

从某种意义上说，这就像一个 PUBG 游戏，我们自由落体到战斗中，抓住任何我们能抓住的枪，试图到达“安全区”。

> 对我们来说，安全区是奖牌区。

那么为什么大家都那么沉迷 Kaggle 呢？

就我个人而言，在这一个月的比赛中，我学到的东西比我参加的任何一个月的 MOOC 都要多。

kaggle 上的“专家”总是慷慨地给出他们的想法。我们感到惊讶的是，许多人几乎给出了他们的完整解决方案——在最高的 LB 位置上！

每天晚上我们都会做一个很好的提交，第二天你醒来的时候，你会在磅上下降 20 级！点击重置，再次朝着更好的提交工作，然后每天重复一次。

最后，我们在 Private LB 上得到了 385/1316:我们在给定计算上的想法只允许达到这个等级。这绝对是一次奇妙的经历，我一定会参加更多的比赛，努力表现得更好。

在许多情况下，当我们在熟睡后设法获得前 100 名提交时，我们会醒来发现一个公共内核会将我们完全抛下 LB 50 个位置！！

参加竞赛的人是真正有激情的，总是有溢出的想法，总是有溢出的才华。对我们来说，这只是尽我们最大的努力，用最少的睡眠生活几个星期，打破和建立 conda 环境，同时试图将讨论中分享的想法转换成代码。

最终，我真正了解了为什么 Kaggle 是数据科学之家。

# 目标

在高尔夫比赛中表现出色一直是我的梦想目标。首先，我保持了前 25%提交的门槛。

涂鸦挑战:

尽管比赛有大量的文件大小和一些有趣的挑战，我们的目标是我们最好的奖牌。

# 竞争

**目标:**目标是从包含“绘制”或创建涂鸦信息的 CSV(s)文件数据集中识别涂鸦。

挑战是:挑战中的文件数量约为 5000 万！

就我个人而言，我已经完成了大量的 MOOC(s ),而且我很有信心，因为我已经过了多少次 CNN 的定义，获得铜牌是相当容易的。当然，我错得很离谱。

# 不起作用的东西

我们非常感谢 Kaggle 大师 [Radek Osmulski](https://medium.com/u/4b74af654f57?source=post_page-----804011c56a31--------------------------------) 分享他的 Fast.ai 入门包——我们是在它的基础上加上白鲸大师的一些技巧构建的。

错误 1:作为初学者，在竞争还新鲜的时候开始一场纸牌游戏比赛总是有启发性的。

为什么？

竞赛中溢出的想法数量是巨大的！即使是 LB 的最高得分者也非常慷慨地分享他们的方法——这只是一个我们是否能找出丢失的信息并能将他们的想法转换成代码的问题。

自从比赛开始以来，我们已经进行了将近一半。

错误 2:我们学习了“实验”，验证。

starter pack 适用于 1%的数据，我尝试用 5%的数据进行试验，然后用 10%的数据进行试验，结果显示性能持续提高。

接下来:我决定把所有的数据都扔给模型，训练在我的 8 GB GPU 上运行了大约 50 个小时。我们期望这种方法能获得最高分，但是模型的准确性却下降了！

经验教训:实验非常重要，验证也是如此。starter pack 依赖于将图像“绘制”到内存中，然后在其上训练模型。Linux 的问题是，它对文件的数量有限制，除非有专门的格式。

我们没有进行验证检查，而是根据一部分数据进行训练。反射验证集肯定是您在开始时必须安装的东西。

# 有效的想法

渐进式训练和调整规模:

*   用 256 图像大小对 1%的数据训练模型。
*   将模型微调为 128 图像大小的 5%的数据。
*   此外，微调模型到 20%的数据与 64 图像大小。
*   当在数据集的相同部分上进行训练时，ResNet 18 < ResNet 34 < ResNet 50 < ResNet 152。

这种方法显示了性能的持续提高。

集成:我们最好的提交是在 20%的数据集上用 fastai (v1)训练的 ResNet 152 和 Kaggle GM Beluga 的 MobileNet 内核的“混合”。

# 摘要

你会在竞赛讨论中发现许多更好的讨论，所以如果这些想法没有让你获得最高的 LB 分数，请原谅这篇文章。

这真的是我在比赛中学到的东西的个人总结。

最后，我保证会参加更多的比赛，希望你会在最近的比赛中发现“rm-rf /”队。

我已经被“Kaggle Bug”咬了一口，比起注册更多的 MOOC，我可能更喜欢未来的比赛

LB 上见，快乐的卡格林！

*如果你觉得这些面试很有趣，并且想成为我的学习之路*[](https://hackernoon.com/launching-my-company-a-scholarship-and-a-webinar-277e3b66e351)**[*的一部分，你可以在 twitter 上找到我*](http://twitter.com/bhutanisanyam1) *。***

***如果你有兴趣阅读关于深度* [*学习*](https://hackernoon.com/tagged/learning) *和计算机视觉的新闻，可以查看我的* [*简讯这里*](http://tinyletter.com/sanyambhutani/) *。***