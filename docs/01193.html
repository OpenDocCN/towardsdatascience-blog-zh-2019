<html>
<head>
<title>FastText sentiment analysis for tweets: A straightforward guide</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">推特快速文本情感分析:简单指南</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/fasttext-sentiment-analysis-for-tweets-a-straightforward-guide-9a8c070449a2?source=collection_archive---------6-----------------------#2019-02-24">https://towardsdatascience.com/fasttext-sentiment-analysis-for-tweets-a-straightforward-guide-9a8c070449a2?source=collection_archive---------6-----------------------#2019-02-24</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="0320" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">快速文本架构、清理、上采样和推文情感的本质</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ki"><img src="../Images/8799b6c7b2acd1642e22fd966f9d97d5.png" data-original-src="https://miro.medium.com/v2/resize:fit:944/1*Yb-AvSJE8mN0Oax8agzSQw.gif"/></div><figcaption class="kq kr gj gh gi ks kt bd b be z dk">A robot learning sentiments</figcaption></figure><p id="8267" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">在这篇文章中，我们介绍了<strong class="kw iu"> fastText </strong>库，它如何在文本分类方面比一些深度神经网络实现更快的速度和类似的准确性。接下来，我们将展示如何借助由<strong class="kw iu">AWS comprehende</strong>生成的数据来训练情感分析模型。在<a class="ae lq" href="https://medium.com/@charlesmalafosse/deploy-a-machine-learning-model-with-aws-elasticbeanstalk-dfcc47b6043e" rel="noopener">的另一篇文章</a>中，我们展示了如何使用<strong class="kw iu"> AWS Elastic Beanstalk </strong>创建一个机器学习服务器来服务你的模型。</p></div><div class="ab cl lr ls hx lt" role="separator"><span class="lu bw bk lv lw lx"/><span class="lu bw bk lv lw lx"/><span class="lu bw bk lv lw"/></div><div class="im in io ip iq"><h1 id="7dab" class="ly lz it bd ma mb mc md me mf mg mh mi jz mj ka mk kc ml kd mm kf mn kg mo mp bi translated">fast text——浅层神经网络架构</h1><p id="58aa" class="pw-post-body-paragraph ku kv it kw b kx mq ju kz la mr jx lc ld ms lf lg lh mt lj lk ll mu ln lo lp im bi translated">FastText 是由 facebook AI 开发的开源 NLP 库，最初于 2016 年发布。它的目标是高效地提供<strong class="kw iu">单词嵌入</strong>和<strong class="kw iu">文本分类</strong>。据他们的作者称，在准确性方面，它通常与深度学习分类器不相上下，并且在训练和评估方面<strong class="kw iu">快许多数量级</strong>。[1]</p><p id="96fa" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">这使得<strong class="kw iu"> fastText 成为构建 NLP 模型</strong>并为生产环境生成实时预测的优秀工具。</p><h1 id="8154" class="ly lz it bd ma mb mv md me mf mw mh mi jz mx ka mk kc my kd mm kf mz kg mo mp bi translated">FastText 架构概述</h1><p id="f702" class="pw-post-body-paragraph ku kv it kw b kx mq ju kz la mr jx lc ld ms lf lg lh mt lj lk ll mu ln lo lp im bi translated">FastText 的核心依赖于用于单词表示的<a class="ae lq" href="https://en.wikipedia.org/wiki/Bag-of-words_model" rel="noopener ugc nofollow" target="_blank">连续单词包</a> (CBOW)模型和一个分层分类器来加速训练。</p><p id="21eb" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">连续单词包(CBOW)是一个浅层神经网络，它被训练来从其邻居预测一个单词。FastText 用预测类别取代了预测单词的目标。这些单层模型训练速度非常快，并且可以很好地扩展。</p><p id="b11b" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">此外，fastText 用分层的 softmax 替换标签上的 softmax。这里每个节点代表一个标签。这减少了计算量，因为我们不需要计算所有标签的概率。有限数量的参数减少了训练时间。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi na"><img src="../Images/32da9b21ed084ed22bbb78d5f6928ee5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1378/format:webp/1*TMXr2yCPXRCU0rX2o6wP9Q.png"/></div><figcaption class="kq kr gj gh gi ks kt bd b be z dk">fastText hierarchical architecture for sentiment analysis.</figcaption></figure><h1 id="3e27" class="ly lz it bd ma mb mv md me mf mw mh mi jz mx ka mk kc my kd mm kf mz kg mo mp bi translated">训练速度更快，但结果相似</h1><p id="58d6" class="pw-post-body-paragraph ku kv it kw b kx mq ju kz la mr jx lc ld ms lf lg lh mt lj lk ll mu ln lo lp im bi translated">根据最初的论文[1]，fastText 实现了与其他算法类似的结果，同时训练速度快得多。</p><p id="8bd8" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">正如您在下面看到的，fastText 的训练时间在 1 到 10 秒之间，而其他型号的训练时间为几分钟或几小时。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="nc nd di ne bf nf"><div class="gh gi nb"><img src="../Images/d7a649a63284a39ac458659b4b4caa5e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*N4Fw9dPeHqJhyvPriRO6Dw.png"/></div></div><figcaption class="kq kr gj gh gi ks kt bd b be z dk">Bag of Tricks for Efficient Text Classification — Joulin 2016</figcaption></figure><h1 id="fb63" class="ly lz it bd ma mb mv md me mf mw mh mi jz mx ka mk kc my kd mm kf mz kg mo mp bi translated">打开用于情感分析的数据集</h1><p id="4667" class="pw-post-body-paragraph ku kv it kw b kx mq ju kz la mr jx lc ld ms lf lg lh mt lj lk ll mu ln lo lp im bi translated">大多数用于文本分类的开放数据集都很小，我们注意到，除了英语之外，很少(如果有的话)可以用于其他语言。因此，除了为情感分析提供指导，我们还想为情感分析提供<a class="ae lq" href="https://github.com/charlesmalafosse/open-dataset-for-sentiment-analysis" rel="noopener ugc nofollow" target="_blank">开放数据集</a>【2】。</p><p id="3771" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">出于这些原因<strong class="kw iu"> </strong>我们提供了包含推文列表及其观点的文件:</p><ul class=""><li id="e63c" class="ng nh it kw b kx ky la lb ld ni lh nj ll nk lp nl nm nn no bi translated"><strong class="kw iu">英语推文数据集=&gt;630 万条推文可用。</strong></li><li id="71c3" class="ng nh it kw b kx np la nq ld nr lh ns ll nt lp nl nm nn no bi translated"><strong class="kw iu">西班牙语推文数据集=&gt;120 万推文。</strong></li><li id="3985" class="ng nh it kw b kx np la nq ld nr lh ns ll nt lp nl nm nn no bi translated"><strong class="kw iu">法语推文数据集= &gt; 25 万条推文</strong></li><li id="ab25" class="ng nh it kw b kx np la nq ld nr lh ns ll nt lp nl nm nn no bi translated"><strong class="kw iu">意大利推文数据集= &gt; 425 000 条推文</strong></li><li id="60a4" class="ng nh it kw b kx np la nq ld nr lh ns ll nt lp nl nm nn no bi translated"><strong class="kw iu">德国推文数据集= &gt; 210 000 条推文</strong></li></ul><p id="4969" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">这些都是得益于<a class="ae lq" href="https://aws.amazon.com/comprehend/" rel="noopener ugc nofollow" target="_blank"> <strong class="kw iu"> AWS 领悟 API </strong> </a>生成的。对于西班牙语和法语，首先使用谷歌翻译将推文翻译成英语，然后使用 AWS 领悟进行分析。情绪分为积极、消极、中性或混合。</p><p id="6057" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">对于本文，我们使用的是英语推文数据集。</p><h1 id="26a0" class="ly lz it bd ma mb mv md me mf mw mh mi jz mx ka mk kc my kd mm kf mz kg mo mp bi translated">为情绪清理推文。</h1><p id="10f6" class="pw-post-body-paragraph ku kv it kw b kx mq ju kz la mr jx lc ld ms lf lg lh mt lj lk ll mu ln lo lp im bi translated">他们说清理通常是数据科学家 80%的时间。可悲的是，这里没有例外。为了获得最好的结果，我们必须确保数据接近正确的英语，因为我们在处理推文，这不是一件容易的事情。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nu"><img src="../Images/8acc84faa763261e17c6c898b1bda489.png" data-original-src="https://miro.medium.com/v2/resize:fit:1306/format:webp/1*CHsTDJWUw40AfKUFP3TcAw.jpeg"/></div><figcaption class="kq kr gj gh gi ks kt bd b be z dk">Example of (funny) misspelled tweets — source: thepoke.co.uk</figcaption></figure><p id="0f6f" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">我们的目标是清理推文，使它们更容易被机器阅读。有许多技术可以清理文本。最著名的是<strong class="kw iu">词汇化</strong>、<strong class="kw iu">词干化</strong>和<strong class="kw iu">停用词</strong>。</p><ul class=""><li id="5048" class="ng nh it kw b kx ky la lb ld ni lh nj ll nk lp nl nm nn no bi translated"><strong class="kw iu">词干化和词条化</strong>的目标都是将一个单词的屈折形式和派生相关形式简化为一个通用的基本形式。例如:am，are，is = &gt; be / dog，dogs，dogs’s，dogs =&gt;dog。)这些减少了语料库的大小及其复杂性，允许更简单的单词嵌入(am、are 和 is 共享相同的精确单词向量)。</li><li id="bcd4" class="ng nh it kw b kx np la nq ld nr lh ns ll nt lp nl nm nn no bi translated"><strong class="kw iu">停用词</strong>过滤增加噪音或对机器理解文本没有价值的常用词。例子:a，and，the…</li></ul><p id="e996" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">虽然词干化和词汇化有助于情感分析，但停用词过滤并不简单。停用词的目标是删除不必要的词，但是如果您查看可用的停用词列表，例如来自 NLTK 库的列表，您会发现可能传达负面情绪的词，例如:not，don 't，has not…但是对于情感分析问题，我们希望保留负面词汇。很明显，“这是一个好游戏”和“这不是一个好游戏”提供了相反的观点。因此，用户需要<strong class="kw iu">编辑停用词列表以排除传达负面含义的词，或者根本不使用停用词。我们选择了后者。</strong></p><p id="8f0f" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">此外，<strong class="kw iu"> tweets 是包含大量表情符号、缩写、标签、拼写错误的单词和俚语的短信</strong>。其中大多数对情感分析没有什么价值，需要清理:</p><ul class=""><li id="b3ae" class="ng nh it kw b kx ky la lb ld ni lh nj ll nk lp nl nm nn no bi translated"><strong class="kw iu">缩写/俚语清理</strong>。如果我们想简化我们的问题，当有合适的替代方法时，我们需要去掉缩写并翻译俚语。然而，很难找到这样的词汇库或数据库。为此，我们必须创建一个列表。去我的 GitHub 页面看看吧。</li></ul><pre class="kj kk kl km gt nv nw nx ny aw nz bi"><span id="6175" class="oa lz it nw b gy ob oc l od oe">#CONTRACTIONS is a list of contractions and slang and their conversion. { "you've":"you have", "luv":"love", etc...}<br/>tweet = tweet.replace("’","'")<br/>words = tweet.split()<br/>reformed = [CONTRACTIONS[word] if word in CONTRACTIONS else word for word in words]<br/>tweet = " ".join(reformed)</span></pre><ul class=""><li id="e238" class="ng nh it kw b kx ky la lb ld ni lh nj ll nk lp nl nm nn no bi translated"><strong class="kw iu">修复拼错的单词。</strong>这里我们使用一个正则表达式，使用 regex 来删除单词中的重复字符。除了 regex 之外，您还可以使用其他能够检测和修复拼写错误的库。遗憾的是，它们非常慢，当你每天有数千条推文要分析时，这在生产中是不可接受的。</li></ul><pre class="kj kk kl km gt nv nw nx ny aw nz bi"><span id="618e" class="oa lz it nw b gy ob oc l od oe">import itertools<br/>tweet = ''.join(''.join(s)[:2] for _, s in itertools.groupby(tweet))</span></pre><ul class=""><li id="dcd2" class="ng nh it kw b kx ky la lb ld ni lh nj ll nk lp nl nm nn no bi translated"><strong class="kw iu">转义 HTML 字符</strong>:Twitter API 有时会返回 HTML 字符。当这种情况发生时，我们需要将它们转换成 ASCII 形式。比如，<strong class="kw iu"> %20 </strong>转换成空格，<strong class="kw iu">&amp;amp</strong>；被转换为&amp;。为此，我们使用 Beautiful Soup，一个用于解析 HTML 和 XML 文档的 Python 包。</li></ul><pre class="kj kk kl km gt nv nw nx ny aw nz bi"><span id="59a7" class="oa lz it nw b gy ob oc l od oe">from bs4 import BeautifulSoup<br/>tweet = BeautifulSoup(tweet).get_text()</span></pre><ul class=""><li id="e27b" class="ng nh it kw b kx ky la lb ld ni lh nj ll nk lp nl nm nn no bi translated"><strong class="kw iu">移除标签/账户</strong>:需要移除使用 Twitter 标签(#)和账户(@)的名称。我们不希望一个足球运动员的名字被我们的模型永远归类为“负面”，仅仅因为他在我们的数据集中与糟糕的评论相关联。</li></ul><pre class="kj kk kl km gt nv nw nx ny aw nz bi"><span id="8a13" class="oa lz it nw b gy ob oc l od oe">tweet = ' '.join(re.sub("(@[A-Za-z0-9]+)|(#[A-Za-z0-9]+)", " ", tweet).split())</span></pre><ul class=""><li id="8f6e" class="ng nh it kw b kx ky la lb ld ni lh nj ll nk lp nl nm nn no bi translated"><strong class="kw iu">删除网址</strong>:</li></ul><pre class="kj kk kl km gt nv nw nx ny aw nz bi"><span id="ad94" class="oa lz it nw b gy ob oc l od oe">tweet = ' '.join(re.sub("(\w+:\/\/\S+)", " ", tweet).split())</span></pre><ul class=""><li id="dfff" class="ng nh it kw b kx ky la lb ld ni lh nj ll nk lp nl nm nn no bi translated"><strong class="kw iu">去除标点符号</strong>:标点符号不用于“单词袋”技术。</li></ul><pre class="kj kk kl km gt nv nw nx ny aw nz bi"><span id="1225" class="oa lz it nw b gy ob oc l od oe">tweet = ' '.join(re.sub("[\.\,\!\?\:\;\-\=]", " ", tweet).split())</span></pre><ul class=""><li id="49f6" class="ng nh it kw b kx ky la lb ld ni lh nj ll nk lp nl nm nn no bi translated"><strong class="kw iu">小写</strong>:将所有内容转换为小写，以避免区分大小写的问题:</li></ul><pre class="kj kk kl km gt nv nw nx ny aw nz bi"><span id="4465" class="oa lz it nw b gy ob oc l od oe">#Lower case<br/>tweet = tweet.lower()</span></pre><ul class=""><li id="fd64" class="ng nh it kw b kx ky la lb ld ni lh nj ll nk lp nl nm nn no bi translated"><strong class="kw iu">表情符号/表情符号</strong>:在一条推文中，表情符号和表情符号用“\\”或标点符号表示，因此没有正确标记。为了保持它们的意义，我们需要将它们转换成更简单的形式。对于表情符号，有一个<strong class="kw iu"> python 库“e moji”</strong>通过将表情符号代码转换为标签来实现这一点。对于表情符号:-)，您必须提供您的列表，我们会在 GitHub 页面上提供。</li></ul><pre class="kj kk kl km gt nv nw nx ny aw nz bi"><span id="ac00" class="oa lz it nw b gy ob oc l od oe">#Part for smileys - SMILEY is a list of smiley and their conversion. {"&lt;3" : "love", ":-)" : "smiley", etc...}<br/>words = tweet.split()<br/>reformed = [SMILEY[word] if word in SMILEY else word for word in words]<br/>tweet = " ".join(reformed)<br/>#Part for emojis<br/>tweet = emoji.demojize(tweet)</span></pre><ul class=""><li id="9a2e" class="ng nh it kw b kx ky la lb ld ni lh nj ll nk lp nl nm nn no bi translated">口音只限于英语，但广泛用于其他语言，口音经常被放错地方或遗忘。对付它们最简单的方法就是摆脱它们。</li></ul><pre class="kj kk kl km gt nv nw nx ny aw nz bi"><span id="d4a4" class="oa lz it nw b gy ob oc l od oe">def strip_accents(text):<br/>    if 'ø' in text or  'Ø' in text:<br/>        #Do nothing when finding ø <br/>        return text   <br/>    text = text.encode('ascii', 'ignore')<br/>    text = text.decode("utf-8")<br/>    return str(text)</span></pre><p id="f190" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">要查看所有相关内容，请查看我的 GitHub 页面上的代码[2]。</p><h1 id="3d44" class="ly lz it bd ma mb mv md me mf mw mh mi jz mx ka mk kc my kd mm kf mz kg mo mp bi translated">格式化数据</h1><p id="fc4d" class="pw-post-body-paragraph ku kv it kw b kx mq ju kz la mr jx lc ld ms lf lg lh mt lj lk ll mu ln lo lp im bi translated">FastText 需要标记数据来训练监督分类器。标签必须以前缀<code class="fe of og oh nw b">__label__</code>开头，这是它识别标签或单词的方式。下面是标签为正面和负面的推文所需格式的示例。</p><pre class="kj kk kl km gt nv nw nx ny aw nz bi"><span id="dbd7" class="oa lz it nw b gy ob oc l od oe">__label__POSITIVE congratulations you played very well yesterday.<br/>__label__NEGATIVE disappointing result today.<br/>...</span></pre><p id="efdc" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">我们使用下面的代码来格式化数据。</p><pre class="kj kk kl km gt nv nw nx ny aw nz bi"><span id="1fe7" class="oa lz it nw b gy ob oc l od oe">def transform_instance(row):<br/>    cur_row = []<br/>    #Prefix the index-ed label with __label__<br/>    label = "__label__" + row[0]  <br/>    cur_row.append(label)<br/>    #Clean tweet and tokenize it<br/>    cur_row.extend( nltk.word_tokenize(tweet_cleaning_for_sentiment_analysis(row[1].lower())))</span><span id="3daa" class="oa lz it nw b gy oi oc l od oe">def preprocess(input_file, output_file, keep=1):</span><span id="751c" class="oa lz it nw b gy oi oc l od oe">    with open(output_file, 'w') as csvoutfile:<br/>        csv_writer = csv.writer(csvoutfile, delimiter=' ', lineterminator='\n')<br/>        with open(input_file, 'r', newline='') as csvinfile: #,encoding='latin1'<br/>            csv_reader = csv.reader(csvinfile, delimiter=',', quotechar='"')<br/>            for row in csv_reader:<br/>                if row[0].upper() in ['POSITIVE','NEGATIVE','NEUTRAL','MIXED']:<br/>                    row_output = transform_instance(row)<br/>                    csv_writer.writerow(row_output)</span><span id="b725" class="oa lz it nw b gy oi oc l od oe"># Preparing the training dataset <br/>preprocess('BetSentimentTweetAnalyzed.csv', 'tweets.train')</span></pre><h1 id="2051" class="ly lz it bd ma mb mv md me mf mw mh mi jz mx ka mk kc my kd mm kf mz kg mo mp bi translated">向上采样以抵消类别不平衡。</h1><p id="d1ad" class="pw-post-body-paragraph ku kv it kw b kx mq ju kz la mr jx lc ld ms lf lg lh mt lj lk ll mu ln lo lp im bi translated">当一个标签比其他标签出现得更频繁时，就会出现类别不平衡的问题。在这种情况下，分类器往往会被大类淹没，而忽略小类。</p><p id="1c3c" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">应用于我们的英语推特数据集[2]，我们注意到中性与积极/消极类别的不平衡。<strong class="kw iu">因此，将所有事物分类为中性的原始策略将给出 73%的准确率</strong>(见下表)。出于同样的原因，我们的模型可能倾向于中性。如果不加以管理，类别不平衡将使我们的模型简单化和不准确。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi oj"><img src="../Images/8a703ff4868209bcb9b2745f208cd964.png" data-original-src="https://miro.medium.com/v2/resize:fit:986/format:webp/1*4PUz-Y4_OC3BLxNhYIY-HQ.png"/></div><figcaption class="kq kr gj gh gi ks kt bd b be z dk">Example of imbalance in labels</figcaption></figure><p id="ba04" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">为了解决这个问题，我们必须使用上采样。<strong class="kw iu">上采样(或过采样)包括为少数类</strong>添加新的推文，正的和负的，以使它们达到与多数类相等的推文数量，这里是中性的。我们提供了一个简单的代码来做到这一点。</p><pre class="kj kk kl km gt nv nw nx ny aw nz bi"><span id="ab29" class="oa lz it nw b gy ob oc l od oe">def upsampling(input_file, output_file, ratio_upsampling=1):<br/>    #<br/>    # Create a file with equal number of tweets for each label<br/>    #    input_file: path to file<br/>    #    output_file: path to the output file<br/>    #    ratio_upsampling: ratio of each minority classes vs majority one. 1 mean there will be as much of each class than there is for the majority class.<br/>    i=0<br/>    counts = {}<br/>    dict_data_by_label = {}</span><span id="0ae3" class="oa lz it nw b gy oi oc l od oe">    i=0<br/>    counts = {}<br/>    dict_data_by_label = {}</span><span id="2278" class="oa lz it nw b gy oi oc l od oe"># GET LABEL LIST AND GET DATA PER LABEL<br/>    with open(input_file, 'r', newline='') as csvinfile:<br/>        csv_reader = csv.reader(csvinfile, delimiter=',', quotechar='"')<br/>        for row in csv_reader:<br/>            counts[row[0].split()[0]] = counts.get(row[0].split()[0], 0) + 1<br/>            if not row[0].split()[0] in dict_data_by_label:<br/>                dict_data_by_label[row[0].split()[0]]=[row[0]]<br/>            else:<br/>                dict_data_by_label[row[0].split()[0]].append(row[0])<br/>            i=i+1<br/>            if i%10000 ==0:<br/>                print("read" + str(i))</span><span id="ecf7" class="oa lz it nw b gy oi oc l od oe"># FIND MAJORITY CLASS<br/>    majority_class=""<br/>    count_majority_class=0<br/>    for item in dict_data_by_label:<br/>        if len(dict_data_by_label[item])&gt;count_majority_class:<br/>            majority_class= item<br/>            count_majority_class=len(dict_data_by_label[item])  <br/>    <br/>    # UPSAMPLE MINORITY CLASS<br/>    data_upsampled=[]<br/>    for item in dict_data_by_label:<br/>        data_upsampled.extend(dict_data_by_label[item])<br/>        if item != majority_class:<br/>            items_added=0<br/>            items_to_add = count_majority_class - len(dict_data_by_label[item])<br/>            while items_added&lt;items_to_add:<br/>                data_upsampled.extend(dict_data_by_label[item][:max(0,min(items_to_add-items_added,len(dict_data_by_label[item])))])<br/>                items_added = items_added + max(0,min(items_to_add-items_added,len(dict_data_by_label[item])))</span><span id="9a4e" class="oa lz it nw b gy oi oc l od oe"># WRITE ALL<br/>    i=0</span><span id="f1cd" class="oa lz it nw b gy oi oc l od oe">with open(output_file, 'w') as txtoutfile:<br/>        for row in data_upsampled:<br/>            txtoutfile.write(row+ '\n' )<br/>            i=i+1<br/>            if i%10000 ==0:<br/>                print("writer" + str(i))</span><span id="73cb" class="oa lz it nw b gy oi oc l od oe">upsampling( 'tweets.train','uptweets.train')</span></pre><p id="1971" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">通过上采样，你冒着过度拟合的风险，一遍又一遍地重复同样的推文。但是如果你的数据集足够大，这应该不是问题。</p><h1 id="3b59" class="ly lz it bd ma mb mv md me mf mw mh mi jz mx ka mk kc my kd mm kf mz kg mo mp bi translated">使用 fastText 进行培训</h1><p id="72d8" class="pw-post-body-paragraph ku kv it kw b kx mq ju kz la mr jx lc ld ms lf lg lh mt lj lk ll mu ln lo lp im bi translated">现在是有趣的部分。是时候训练我们的机器了！</p><p id="4b17" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">我们使用 fastText python 包装器来训练我们的模型。你可以在脸书研究院的 GitHub 页面<a class="ae lq" href="https://github.com/facebookresearch/fastText/tree/master/python" rel="noopener ugc nofollow" target="_blank">上找到实现示例和文档。请确保您使用“git clone …”安装 fastText，而不是使用“pip install fasttext”。</a></p><p id="c604" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">由于我们已经准备好了数据，现在我们需要做的就是使用函数<code class="fe of og oh nw b">fastText.train_supervised</code>。此功能有大量选项，但为了简单起见，我们主要关注以下内容:</p><ul class=""><li id="9764" class="ng nh it kw b kx ky la lb ld ni lh nj ll nk lp nl nm nn no bi translated"><strong class="kw iu">输入</strong>:我们训练数据的路径。</li><li id="7217" class="ng nh it kw b kx np la nq ld nr lh ns ll nt lp nl nm nn no bi translated"><strong class="kw iu"> lr </strong>:学习率。我们将其设置为 0.01。</li><li id="1700" class="ng nh it kw b kx np la nq ld nr lh ns ll nt lp nl nm nn no bi translated"><strong class="kw iu"> epoch </strong>:我们遍历整个数据集的次数。我们用 20。</li><li id="a64d" class="ng nh it kw b kx np la nq ld nr lh ns ll nt lp nl nm nn no bi translated"><strong class="kw iu"> wordNgrams </strong>:一个 n 元文法是来自给定文本样本的最大 n 个单词的连续序列。我们把它设置为 2。</li><li id="2d87" class="ng nh it kw b kx np la nq ld nr lh ns ll nt lp nl nm nn no bi translated"><strong class="kw iu"> dim </strong>:字向量的维度。我们用 20。</li></ul><p id="02d7" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">以下 python 代码显示了我们模型的训练。</p><pre class="kj kk kl km gt nv nw nx ny aw nz bi"><span id="05ac" class="oa lz it nw b gy ob oc l od oe">hyper_params = {"lr": 0.01,<br/>    "epoch": 20,<br/>    "wordNgrams": 2,<br/>    "dim": 20}     <br/>        <br/># Train the model.<br/>model = fastText.train_supervised(input=training_data_path, **hyper_params)<br/>print("Model trained with the hyperparameter \n {}".format(hyper_params))</span></pre><p id="e717" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">一旦经过训练，我们需要评估我们的模型在情感分析方面有多好。为此，我们可以使用<strong class="kw iu">两个度量精度和召回率，它们是 fastText </strong>函数<code class="fe of og oh nw b">model.test</code>的输出。然而，由于我们的问题的性质，精度和召回给出类似的数字，我们可以只关注精度。</p><p id="b822" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">下面的代码对训练和验证数据执行<code class="fe of og oh nw b">model.test</code>，以比较我们模型的准确性。请注意，为了验证，我们采用了不同的数据集，在该数据集上我们使用了相同的清理过程，但没有上采样。</p><pre class="kj kk kl km gt nv nw nx ny aw nz bi"><span id="b565" class="oa lz it nw b gy ob oc l od oe"># CHECK PERFORMANCE      <br/>result = model.test(training_data_path)<br/>validation = model.test(validation_data_path)<br/>        <br/># DISPLAY ACCURACY OF TRAINED MODEL<br/>text_line = str(hyper_params) + ",accuracy:" + str(result[1])  + ",validation:" + str(validation[1]) + '\n' <br/>print(text_line)</span></pre><p id="2359" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">总的来说，该模型对训练数据给出了 97.5%的准确度，对验证数据给出了 79.7%的准确度。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="nc nd di ne bf nf"><div class="gh gi ok"><img src="../Images/b3e332e2fd364b131b60f51ccec1951b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*g7StR_H8wql5ErnYK7kUUw.png"/></div></div></figure><p id="8f99" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">考虑到我们没有调整超参数，还不错。此外，研究估计<strong class="kw iu">人在判断对一段特定文本的情感时，只有</strong> <a class="ae lq" href="http://ceur-ws.org/Vol-1096/paper1.pdf" rel="noopener ugc nofollow" target="_blank"> <strong class="kw iu">同意约 60%到 80%的次数</strong> </a>。因此，虽然我们可以尝试达到 100%的准确性，但我们必须记住，人类是会犯错的……最重要的是，我们在推特上工作！！</p><h1 id="8c87" class="ly lz it bd ma mb mv md me mf mw mh mi jz mx ka mk kc my kd mm kf mz kg mo mp bi translated">结论</h1><p id="d8d9" class="pw-post-body-paragraph ku kv it kw b kx mq ju kz la mr jx lc ld ms lf lg lh mt lj lk ll mu ln lo lp im bi translated">我们刚刚展示了 fastText 如何工作，以及如何训练一个英语情感分析模型。我们使用了由<strong class="kw iu">AWS comprehensive</strong>产生的情感数据。在<a class="ae lq" href="https://medium.com/@charlesmalafosse/deploy-a-machine-learning-model-with-aws-elasticbeanstalk-dfcc47b6043e" rel="noopener">的另一篇文章</a>中，我们解释了如何使用<strong class="kw iu"> AWS Elastic Beanstalk </strong>和 Python <strong class="kw iu"> Flask </strong>应用程序为您的模型提供健壮的云基础设施。</p><p id="d696" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">如果你想重现结果，只要去我的 gitHub。如果需要完整的英文数据集，可以问我(对 GitHub 来说太大了)。我很乐意与你分享它。</p><h1 id="3411" class="ly lz it bd ma mb mv md me mf mw mh mi jz mx ka mk kc my kd mm kf mz kg mo mp bi translated">成为中等会员，在平台上支持我！</h1><p id="fc9d" class="pw-post-body-paragraph ku kv it kw b kx mq ju kz la mr jx lc ld ms lf lg lh mt lj lk ll mu ln lo lp im bi translated"><a class="ae lq" href="https://medium.com/@charlesmalafosse/membership" rel="noopener">https://medium.com/@charlesmalafosse/membership</a></p><h1 id="4d0d" class="ly lz it bd ma mb mv md me mf mw mh mi jz mx ka mk kc my kd mm kf mz kg mo mp bi translated">参考</h1><p id="d2a1" class="pw-post-body-paragraph ku kv it kw b kx mq ju kz la mr jx lc ld ms lf lg lh mt lj lk ll mu ln lo lp im bi translated">[1] <em class="ol"> </em> <a class="ae lq" href="https://arxiv.org/abs/1607.01759" rel="noopener ugc nofollow" target="_blank"> <em class="ol">高效文本分类的锦囊妙计，</em> </a>阿曼德·茹林，爱德华·格雷夫，彼得·博亚诺夫斯基，托马斯·米科洛夫，2016</p><p id="b11a" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated"><a class="ae lq" href="https://github.com/charlesmalafosse" rel="noopener ugc nofollow" target="_blank">https://github.com/charlesmalafosse</a>。我的 GitHub 页面，包含本文的全部代码。</p><p id="3a85" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">[3]脸书 GitHub，带有 fastText python 包装器。<a class="ae lq" href="https://github.com/facebookresearch/fastText/tree/master/python" rel="noopener ugc nofollow" target="_blank">https://github . com/Facebook research/fast text/tree/master/python</a></p><p id="dab0" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">[4]用 AWS Elastic Beanstalk 部署一个机器学习模型<a class="ae lq" href="https://medium.com/@charlesmalafosse/deploy-a-machine-learning-model-with-aws-elasticbeanstalk-dfcc47b6043e" rel="noopener">https://medium . com/@ charlesmalafosse/Deploy-a-machine-learning-model-with-AWS-Elastic Beanstalk-dfcc 47 b 6043 e</a></p></div></div>    
</body>
</html>