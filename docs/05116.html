<html>
<head>
<title>The How of Explainable AI: Pre-modelling Explainability</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">可解释人工智能的方法:预建模可解释性</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/the-how-of-explainable-ai-pre-modelling-explainability-699150495fe4?source=collection_archive---------13-----------------------#2019-07-31">https://towardsdatascience.com/the-how-of-explainable-ai-pre-modelling-explainability-699150495fe4?source=collection_archive---------13-----------------------#2019-07-31</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><figure class="gl gn jr js jt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi jq"><img src="../Images/5ee6a956f7d9e87ebaf91f4524e8e64c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*5a7sHMpoIqMB4QYo"/></div></div></figure><p id="253e" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">人工智能可解释性是一个广泛的多学科领域，正在多个领域进行研究，包括机器学习、知识表示和推理、人机交互和社会科学。相应地，XAI 文献包括大量且不断增加的方法论。</p><p id="1ca3" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">有许多因素可以影响人工智能模型如何运行和做出预测，因此有许多方法来解释它们。这也部分是由于缺乏对 XAI 的一致认可的定义。一般来说，可解释性可以应用于整个人工智能开发流程。具体来说，可以在建模阶段之前(<strong class="kd iu">前建模可解释性)</strong>、期间(<strong class="kd iu">可解释建模</strong>)和之后(<strong class="kd iu">后建模可解释性</strong>)应用。</p><p id="700f" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">以下是一些最重要的 XAI 方法和途径的非穷尽性概述，分为这三个阶段:建模前的可解释性、可解释的建模和建模后的可解释性。</p><blockquote class="la"><p id="33ed" class="lb lc it bd ld le lf lg lh li lj ky dk translated">有许多因素可以影响人工智能模型如何运行并做出预测，因此有许多方法来解释它们。</p></blockquote><figure class="lk ll lm ln lo ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi jq"><img src="../Images/494666526301fd412dab8d3e0244eb2e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*rXoGlA5oICgpUEXQ"/></div></div><figcaption class="lp lq gj gh gi lr ls bd b be z dk"><strong class="bd lt">The three stages of AI explainability: Pre-modelling explainability, Explainable modelling and post-modelling explainability.</strong></figcaption></figure><p id="9361" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">建模前可解释性是不同方法的集合，其共同目标是更好地理解用于模型开发的数据集。这种方法的动机是，人工智能模型的行为在很大程度上是由用于训练它的数据集驱动的。</p><h1 id="a455" class="lu lv it bd lw lx ly lz ma mb mc md me mf mg mh mi mj mk ml mm mn mo mp mq mr bi translated">建模前可解释性</h1><p id="17f3" class="pw-post-body-paragraph kb kc it kd b ke ms kg kh ki mt kk kl km mu ko kp kq mv ks kt ku mw kw kx ky im bi translated">建模前可解释性文献可以分为四大类:探索性数据分析、数据集描述标准化、可解释特征工程和数据集总结方法。</p><blockquote class="la"><p id="b016" class="lb lc it bd ld le lf lg lh li lj ky dk translated">建模前可解释性是不同方法的集合，其共同目标是更好地理解用于模型开发的数据集。</p></blockquote><h2 id="977c" class="mx lv it bd lw my mz dn ma na nb dp me km nc nd mi kq ne nf mm ku ng nh mq ni bi translated">探索性数据分析</h2><p id="9d32" class="pw-post-body-paragraph kb kc it kd b ke ms kg kh ki mt kk kl km mu ko kp kq mv ks kt ku mw kw kx ky im bi translated">探索性数据分析的目标是提取数据集主要特征的摘要。该摘要通常包括数据集的各种统计属性，如其维度、均值、标准差、范围、缺失样本等。Google Facets 是一个强大的工具包的例子，可以从给定的数据集中快速提取这些属性。</p><p id="7911" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">作为一个例子，考虑一个简单的监督二进制分类问题，其中开发了一个模型来检测有缺陷和无缺陷的产品。假设所提供的数据集包含装配线的高架摄像机提供的大量图像，每个图像都被标记为有缺陷或无缺陷。让我们进一步假设为该模型开发的初步分类器模型表现不佳。检查缺陷和非缺陷图像的相对频率的探索性数据分析<strong class="kd iu"> </strong>任务可以揭示类别不平衡问题，即缺陷图像比非缺陷图像少得多。在训练数据集中发现这一挑战后，可以利用各种解决方案来缓解这一挑战并提高分类器的性能。</p><figure class="nj nk nl nm gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi jq"><img src="../Images/4758d36cdc40f24e236ea7dda638bbde.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*lv2hjJcWPvPgPWf0"/></div></div><figcaption class="lp lq gj gh gi lr ls bd b be z dk"><strong class="bd lt">An example of datasets with identical mean and standard deviation, and different graphs to demonstrate the </strong><a class="ae kz" href="https://dl.acm.org/citation.cfm?id=3025912" rel="noopener ugc nofollow" target="_blank"><strong class="bd lt">importance of visualization</strong></a><strong class="bd lt"> in exploratory data analysis.</strong></figcaption></figure><p id="9717" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">然而，在分析数据集时，仅仅依靠统计属性通常是不够的。例如，已经表明数据集可以有<a class="ae kz" href="https://dl.acm.org/citation.cfm?id=3025912" rel="noopener ugc nofollow" target="_blank">相同的统计属性，但在图表上显示时却有不同的外观</a>。因此，数据可视化方法构成了探索性数据分析机制的一大部分。数据可视化提供了多种方法来使用<a class="ae kz" href="https://datavizcatalogue.com/" rel="noopener ugc nofollow" target="_blank">各种类型的图表</a>绘制数据集。选择适当类型的图表取决于给定的数据集、给定的应用程序以及我们想要传达的特定统计属性。</p><p id="efb9" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">现实世界的数据集通常是复杂的和高维的，也就是说，具有大量的要素。可视化这样的高维数据可能是一个挑战，因为人类只能轻松地想象最多三个维度。</p><blockquote class="la"><p id="b15c" class="lb lc it bd ld le lf lg lh li lj ky dk translated">在分析数据集时，仅仅依靠统计属性通常是不够的。</p></blockquote><p id="a81e" class="pw-post-body-paragraph kb kc it kd b ke nn kg kh ki no kk kl km np ko kp kq nq ks kt ku nr kw kx ky im bi translated">应对这一挑战的一种方法是使用专门类型的图表，例如<a class="ae kz" href="https://arxiv.org/pdf/1905.10035.pdf" rel="noopener ugc nofollow" target="_blank">平行坐标图</a>，以允许人类感知大于三的维度。或者，可以将高维数据集投影到低维表示中，同时尽可能保留其底层结构。这就是降维方法的目标。这一类别中的一些流行方法包括主成分分析(PCA)和 t-SNE。<a class="ae kz" href="https://projector.tensorflow.org/" rel="noopener ugc nofollow" target="_blank">嵌入式投影仪工具包</a>提供了这两种方法的简单易用的实现。如果已知数据集的基础结构是相对线性的，那么主成分分析是首选方法，否则，t-SNE 通常是正确的选择。不幸的是，t-SNE 在应用于大型数据集时速度太慢。在这种情况下，可以使用最近的替代方法，如<a class="ae kz" href="https://github.com/lmcinnes/umap" rel="noopener ugc nofollow" target="_blank"> UMAP </a>降维技术。事实上，UMAP 被认为比 t-SNE 更具扩展性，也更准确。</p><h2 id="0dab" class="mx lv it bd lw my ns dn ma na nt dp me km nu nd mi kq nv nf mm ku nw nh mq ni bi translated">数据集描述标准化</h2><p id="d311" class="pw-post-body-paragraph kb kc it kd b ke ms kg kh ki mt kk kl km mu ko kp kq mv ks kt ku mw kw kx ky im bi translated">数据集通常是在文档不足的情况下发布的。标准化可以确保数据集的创建者和用户之间的适当沟通，并有助于缓解人工智能模型中的系统偏差或数据滥用等问题。在这一观察的推动下，已经提出了许多关于标准化数据集描述的建议。</p><p id="bff4" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">其中一些建议包括数据集的数据表、<a class="ae kz" href="https://openreview.net/pdf?id=By4oPeX9f" rel="noopener ugc nofollow" target="_blank">数据表</a>和<a class="ae kz" href="https://ahmedhosny.github.io/datanutrition/" rel="noopener ugc nofollow" target="_blank">数据集营养标签</a>。它们本质上都为伴随数据集的特定信息提出了各种模式，以记录数据集的创建、组成、数据收集过程、法律/伦理考虑等。例如，数据集营养标签框架建议在数据集文档中包含几个类似于包装食品营养事实标签的信息模块。与消费者可以根据营养事实选择他们想要的食物的方式类似，人工智能专家可以使用数据集营养标签来有效地选择最佳数据集以用于建模目的。</p><figure class="nj nk nl nm gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi jq"><img src="../Images/ab907da79e43a407d12597f5c0faf4f9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*QZwbbxNNPgIQS9j-"/></div></div><figcaption class="lp lq gj gh gi lr ls bd b be z dk"><strong class="bd lt">The information modules proposed by the</strong><a class="ae kz" href="https://arxiv.org/pdf/1805.03677.pdf" rel="noopener ugc nofollow" target="_blank"><strong class="bd lt"> Dataset Nutrition Label framework</strong></a><strong class="bd lt"> as a standard for providing a distilled yet comprehensive overview of datasets.</strong></figcaption></figure><h2 id="ff0c" class="mx lv it bd lw my ns dn ma na nt dp me km nu nd mi kq nv nf mm ku nw nh mq ni bi translated">可解释的特征工程</h2><p id="d46f" class="pw-post-body-paragraph kb kc it kd b ke ms kg kh ki mt kk kl km mu ko kp kq mv ks kt ku mw kw kx ky im bi translated">除了对提高人工智能模型的性能非常有用之外，数据集可解释性还可以有助于开发可解释的模型，并使事后模型解释更具可解释性。</p><p id="3e81" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">特征属性是一种流行的事后解释类型，它涉及确定输入特征对于给定模型预测的相对重要性。为了让特性属性解释对最终用户更有用，相关的<a class="ae kz" href="https://arxiv.org/pdf/1901.04592.pdf" rel="noopener ugc nofollow" target="_blank">特性本身也应该是可解释的</a>，换句话说，用户应该能够赋予它们直观的含义。换句话说，<a class="ae kz" href="http://export.arxiv.org/pdf/1801.09808" rel="noopener ugc nofollow" target="_blank">的解释和他们用</a>来解释模型预测的特性一样好。可解释的特征工程旨在解决这一挑战。</p><p id="7331" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">实现可解释特征工程有两种主要途径，即<a class="ae kz" href="https://arxiv.org/pdf/1901.04592.pdf" rel="noopener ugc nofollow" target="_blank">特定领域和基于模型的</a>特征工程。特定于领域的方法依赖于领域专家的知识和从探索性数据分析中获得的洞察力来提取和/或识别特征。例如，由于冰/雪与云的定性相似性，检测北极卫星图像中的多云像素是一项具有挑战性的任务。遵循特定领域的特征工程方法，Shi 等人<a class="ae kz" href="https://www.tandfonline.com/doi/abs/10.1198/016214507000001283" rel="noopener ugc nofollow" target="_blank">开发了三个可解释的有效特征</a>，由二元分类器使用来解决这个问题。</p><blockquote class="la"><p id="c3cd" class="lb lc it bd ld le lf lg lh li lj ky dk translated">解释的好坏取决于它们用来解释模型预测的特征。</p></blockquote><p id="b2f8" class="pw-post-body-paragraph kb kc it kd b ke nn kg kh ki no kk kl km np ko kp kq nq ks kt ku nr kw kx ky im bi translated">另一方面，基于模型的特征工程方法应用各种数学模型来揭示数据集的底层结构。一些相关的方法包括<a class="ae kz" href="https://arxiv.org/pdf/1901.04592.pdf" rel="noopener ugc nofollow" target="_blank">聚类和字典学习</a>。另一个有趣且相关的研究领域是<a class="ae kz" href="https://arxiv.org/pdf/1812.02230.pdf" rel="noopener ugc nofollow" target="_blank">解开表征学习</a>，其目的是学习给定数据集的表征，其中其生成潜在因素是孤立的。这些潜在因素可以被认为是描述数据集的可解释特征。例如，上图显示了一个名为<a class="ae kz" href="https://openreview.net/references/pdf?id=Sy2fzU9gl" rel="noopener ugc nofollow" target="_blank">VAE</a>的解开表征学习模型，该模型使用从不同角度拍摄的椅子图像数据集(也称为 3D 椅子数据集)进行训练。如图所示，该模型似乎已经成功地隔离了该数据集的三个潜在因素，即方位角、椅子宽度和椅子腿风格。</p><figure class="nj nk nl nm gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi nx"><img src="../Images/36c2fb01628268bcd3c4ce5b023bf35d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*7F9gyc9Uth_mE57a"/></div></div><figcaption class="lp lq gj gh gi lr ls bd b be z dk"><strong class="bd lt">Manipulating three latent factors of the 3D chairs dataset, namely, azimuth angle, width, and leg style, using the </strong><a class="ae kz" href="https://openreview.net/references/pdf?id=Sy2fzU9gl" rel="noopener ugc nofollow" target="_blank"><strong class="bd lt">ß-VAE distentagled representation learning approach</strong></a><strong class="bd lt">.</strong></figcaption></figure><h2 id="975c" class="mx lv it bd lw my ns dn ma na nt dp me km nu nd mi kq nv nf mm ku nw nh mq ni bi translated">数据集汇总</h2><p id="22a8" class="pw-post-body-paragraph kb kc it kd b ke ms kg kh ki mt kk kl km mu ko kp kq mv ks kt ku mw kw kx ky im bi translated">基于案例的推理是一种可解释的建模方法，它根据某种距离度量，基于与之相似的训练样本(案例)对给定样本进行预测。这些<a class="ae kz" href="https://europepmc.org/backend/ptpmcrender.fcgi?accid=PMC2232607&amp;blobtype=pdf" rel="noopener ugc nofollow" target="_blank">相似的训练样本可以与模型预测一起呈现给最终用户</a>，作为解释。然而，基于案例的推理方法的一个重要限制是需要存储整个训练数据集，这对于非常大的数据集来说成本太高或者根本不可能。缓解这个问题的一种方法是存储仍然代表数据集本质的训练数据集的子集。数据集摘要旨在应对这一挑战。</p><p id="67d1" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">总结一个数据集通常意味着寻找一个代表样本(也称为原型)的最小子集，以提供它的浓缩视图。这个领域的早期工作可以追溯到 20 世纪 80 年代，使用的方法有<a class="ae kz" href="https://www.researchgate.net/profile/Peter_Rousseeuw/publication/243777819_Clustering_by_Means_of_Medoids/links/00b7d531493fad342c000000.pdf" rel="noopener ugc nofollow" target="_blank"> K-medoid 聚类</a>。最近，主要由于大数据集可用性的增加，人们对数据摘要的兴趣重新燃起。例如，已经为<a class="ae kz" href="https://www.computer.org/csdl/proceedings-article/iccv/2007/04408863/12OmNywfKEO" rel="noopener ugc nofollow" target="_blank">场景摘要</a>、<a class="ae kz" href="https://dl.acm.org/citation.cfm?id=2002537" rel="noopener ugc nofollow" target="_blank">文档摘要</a>和<a class="ae kz" href="https://arxiv.org/pdf/1202.5933.pdf" rel="noopener ugc nofollow" target="_blank">分类</a>任务提出了许多方法。第一种方法依赖于专门的聚类算法，而后两种方法都被公式化为优化问题。此外，所有这些方法都提取目标应用程序的数据集摘要。</p><figure class="nj nk nl nm gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi ny"><img src="../Images/ad570f4d51f2ea7de61cb306dbe0bdfd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*KfhYSQCO5U0eheJq"/></div></div><figcaption class="lp lq gj gh gi lr ls bd b be z dk"><strong class="bd lt">A random subset of prototype and criticism examples extracted for the USPS dataset using the </strong><a class="ae kz" href="http://people.csail.mit.edu/beenkim/papers/KIM2016NIPS_MMD.pdf" rel="noopener ugc nofollow" target="_blank"><strong class="bd lt">MMD-critic data summarization method</strong></a><strong class="bd lt">.</strong></figcaption></figure><p id="9873" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">最近有人认为原型例子不足以理解大型复杂的数据集，我们也需要批评。一个<a class="ae kz" href="https://christophm.github.io/interpretable-ml-book/proto.html" rel="noopener ugc nofollow" target="_blank">批评</a>是一组原型不能很好描述的通常(相对)罕见的数据点。Kim 等人提出了一种<a class="ae kz" href="https://people.csail.mit.edu/beenkim/papers/KIM2016NIPS_MMD.pdf" rel="noopener ugc nofollow" target="_blank">无监督学习方法来提取给定数据集的原型和批评</a>，并进行人体研究来验证他们方法的结果。首先，给人类受试者展示一些动物种类的原型和批评图像。然后，他们被要求预测给定测试图像的类别标签。研究显示，同时看到原型和批评图像的人比只看到原型的人表现更好。</p><p id="1fcb" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">所谓的数据压缩与数据汇总有关。<a class="ae kz" href="http://www.cs.princeton.edu/courses/archive/spr04/cos598B/bib/DuMouchel.pdf" rel="noopener ugc nofollow" target="_blank">数据压缩</a>的目标是构建一个更小的数据集替代物，以获得大致相同的分析结果。与数据汇总相比，替代数据集中的样本通常具有与之相关的权重。最近关于所谓的<a class="ae kz" href="https://github.com/trevorcampbell/bayesian-coresets" rel="noopener ugc nofollow" target="_blank">贝叶斯核心集</a>的工作就属于这一类。换句话说，它可以被认为是一个在贝叶斯学习设置中公式化的数据挤压问题。</p><blockquote class="la"><p id="6d90" class="lb lc it bd ld le lf lg lh li lj ky dk translated">原型例子不足以理解大而复杂的数据集，我们也需要批评。</p></blockquote><h1 id="4adf" class="lu lv it bd lw lx ly lz ma mb mc md me mf nz mh mi mj oa ml mm mn ob mp mq mr bi translated">下一步是什么？</h1><p id="3eeb" class="pw-post-body-paragraph kb kc it kd b ke ms kg kh ki mt kk kl km mu ko kp kq mv ks kt ku mw kw kx ky im bi translated">建模前可解释性是一组不同的方法，它们有一个共同的目标，那就是更好地理解可用于建模的给定数据集。通过预建模可解释性提取的数据相关的见解能够开发更有效、可解释和健壮的人工智能解决方案。</p><p id="6e80" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">本系列的下一部分将关注人工智能开发的建模阶段。特别是，它探索了开发既可解释又可执行的人工智能模型的各种方法。</p></div><div class="ab cl oc od hx oe" role="separator"><span class="of bw bk og oh oi"/><span class="of bw bk og oh oi"/><span class="of bw bk og oh"/></div><div class="im in io ip iq"><p id="82d5" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated"><em class="oj">特别感谢</em> <a class="ae kz" href="https://wxs.ca/" rel="noopener ugc nofollow" target="_blank"> <em class="oj">泽维尔·斯内尔格罗夫</em></a><em class="oj"/><a class="ae kz" href="https://ca.linkedin.com/in/elnaz-barshan-845964ba" rel="noopener ugc nofollow" target="_blank"><em class="oj">埃尔纳兹·巴尔尚</em></a><em class="oj"/><a class="ae kz" href="http://www.lindsaydbrin.com/" rel="noopener ugc nofollow" target="_blank"><em class="oj">林赛·布林</em></a><em class="oj"/><a class="ae kz" href="https://ca.linkedin.com/in/santiagosalcido" rel="noopener ugc nofollow" target="_blank"><em class="oj">圣地亚哥·萨尔西多</em> </a> <em class="oj">，以及</em> <a class="ae kz" href="http://manongruaz.com/" rel="noopener ugc nofollow" target="_blank"> <em class="oj">情妇玛侬·格鲁阿兹</em> </a> <em class="oj">的宝贵意见由</em> <a class="ae kz" href="https://www.linkedin.com/in/pnhenderson/" rel="noopener ugc nofollow" target="_blank"> <em class="oj">彼得亨德森</em> </a> <em class="oj">编辑。</em></p></div></div>    
</body>
</html>