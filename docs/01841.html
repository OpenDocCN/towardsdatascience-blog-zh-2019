<html>
<head>
<title>Analytics Building Blocks: Binary Classification</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">分析构建模块:二元分类</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/analytics-building-blocks-binary-classification-d205890314fc?source=collection_archive---------11-----------------------#2019-03-26">https://towardsdatascience.com/analytics-building-blocks-binary-classification-d205890314fc?source=collection_archive---------11-----------------------#2019-03-26</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="d319" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated"><em class="kf">模块化笔记本电脑，以控制面板的方式用最少的编码调整和比较 9 种分类算法</em></h2></div><figure class="kh ki kj kk gt kl gh gi paragraph-image"><div role="button" tabindex="0" class="km kn di ko bf kp"><div class="gh gi kg"><img src="../Images/e553ad04a6b2d086ba5cdbd8e99752e8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*xpRoFLy0BHsCr62Uf1FfTQ.png"/></div></div><figcaption class="ks kt gj gh gi ku kv bd b be z dk">Common Binary Classification Task</figcaption></figure><p id="9a35" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">欢迎来到第二期分析构建模块！我的回归笔记本上的反馈是出版分类笔记本的巨大动力。如果您已经使用了回归笔记本，您可以滚动到底部，从我的 GitHub repo 访问该笔记本，因为结构保持不变。如果没有，请继续阅读…</p><p id="4121" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">本文总结并解释了我的分类模块(我正在开发的用于执行常见分析任务的简单模块化笔记本之一)的关键模块。该笔记本旨在帮助对分类模型和 Python 编程有一定了解的用户更快地进行实验。然而，这一次我已经包括了一些其他的伟大的文章，给用户关于这个主题的先验知识。GitHub 到笔记本的链接在文章底部！</p><h2 id="5b08" class="ls lt iq bd lu lv lw dn lx ly lz dp ma lf mb mc md lj me mf mg ln mh mi mj mk bi translated">介绍</h2><p id="b479" class="pw-post-body-paragraph kw kx iq ky b kz ml jr lb lc mm ju le lf mn lh li lj mo ll lm ln mp lp lq lr ij bi translated">与回归问题类似，分类也是分析学中的经典问题之一。通过预测数据属于某一类的概率，任何分类都可以转化为回归问题，但我们暂时不会深入探讨。这是我分享创建这些笔记本的标准动机:很多时候，在执行分析任务时，通过测试不同的模型形式来确定最合适的模型，以根据手头的问题提供准确性、复杂性和执行效率的良好平衡，这是很好的快速失败。RapidMiner 等一些软件提供此功能。然而，出于这个目的使用软件产品会导致在调整模型和探索一些复杂性方面的黑盒方法。因此，我决定创建一个简单的 python 脚本，它具有足够的模块化和参数化，能够测试和调整许多广泛使用的分类算法，只需对代码进行最小的更改。<br/>本笔记本摘要如下:</p><h2 id="b558" class="ls lt iq bd lu lv lw dn lx ly lz dp ma lf mb mc md lj me mf mg ln mh mi mj mk bi translated">目标:</h2><p id="0242" class="pw-post-body-paragraph kw kx iq ky b kz ml jr lb lc mm ju le lf mn lh li lj mo ll lm ln mp lp lq lr ij bi translated">在 Python 中以最少的人工干预测试、调整和比较各种分类模型。<br/>本模块包含的车型有:</p><ul class=""><li id="a47d" class="mq mr iq ky b kz la lc ld lf ms lj mt ln mu lr mv mw mx my bi translated">逻辑回归</li><li id="2623" class="mq mr iq ky b kz mz lc na lf nb lj nc ln nd lr mv mw mx my bi translated">脊线分类器</li><li id="dde1" class="mq mr iq ky b kz mz lc na lf nb lj nc ln nd lr mv mw mx my bi translated">k 个最近邻居</li><li id="0a96" class="mq mr iq ky b kz mz lc na lf nb lj nc ln nd lr mv mw mx my bi translated">决策树分类器</li><li id="f2cc" class="mq mr iq ky b kz mz lc na lf nb lj nc ln nd lr mv mw mx my bi translated">随机森林</li><li id="68f6" class="mq mr iq ky b kz mz lc na lf nb lj nc ln nd lr mv mw mx my bi translated">打包(默认使用决策树)</li><li id="030c" class="mq mr iq ky b kz mz lc na lf nb lj nc ln nd lr mv mw mx my bi translated">梯度推进</li><li id="29da" class="mq mr iq ky b kz mz lc na lf nb lj nc ln nd lr mv mw mx my bi translated">XGBoost</li><li id="c0c9" class="mq mr iq ky b kz mz lc na lf nb lj nc ln nd lr mv mw mx my bi translated">支持向量机</li></ul><h2 id="525c" class="ls lt iq bd lu lv lw dn lx ly lz dp ma lf mb mc md lj me mf mg ln mh mi mj mk bi translated">用户熟练程度:</h2><p id="610b" class="pw-post-body-paragraph kw kx iq ky b kz ml jr lb lc mm ju le lf mn lh li lj mo ll lm ln mp lp lq lr ij bi translated">用户应该对每种算法的工作原理有一个直观的了解，并且很好地理解改变一个特定的超参数会如何影响结果。需要对 python 有基本的了解，以便能够有效地利用代码，并根据需求进一步定制代码。</p><p id="2744" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">尽管如此，我还是包含了一些很棒的文章的链接，以便理解这些算法的基础:</p><ul class=""><li id="9e4d" class="mq mr iq ky b kz la lc ld lf ms lj mt ln mu lr mv mw mx my bi translated">逻辑回归:</li></ul><div class="ne nf gp gr ng nh"><a rel="noopener follow" target="_blank" href="/logistic-regression-detailed-overview-46c4da4303bc"><div class="ni ab fo"><div class="nj ab nk cl cj nl"><h2 class="bd ir gy z fp nm fr fs nn fu fw ip bi translated">逻辑回归—详细概述</h2><div class="no l"><h3 class="bd b gy z fp nm fr fs nn fu fw dk translated">逻辑回归在二十世纪早期被用于生物科学。它后来被用于许多社会…</h3></div><div class="np l"><p class="bd b dl z fp nm fr fs nn fu fw dk translated">towardsdatascience.com</p></div></div><div class="nq l"><div class="nr l ns nt nu nq nv kq nh"/></div></div></a></div><ul class=""><li id="7650" class="mq mr iq ky b kz la lc ld lf ms lj mt ln mu lr mv mw mx my bi translated">决策树分类:</li></ul><div class="ne nf gp gr ng nh"><a href="https://medium.com/@chiragsehra42/decision-trees-explained-easily-28f23241248" rel="noopener follow" target="_blank"><div class="ni ab fo"><div class="nj ab nk cl cj nl"><h2 class="bd ir gy z fp nm fr fs nn fu fw ip bi translated">决策树很容易解释</h2><div class="no l"><h3 class="bd b gy z fp nm fr fs nn fu fw dk translated">决策树(DTs)是一种用于分类和回归的非参数监督学习方法。决定…</h3></div><div class="np l"><p class="bd b dl z fp nm fr fs nn fu fw dk translated">medium.com</p></div></div><div class="nq l"><div class="nw l ns nt nu nq nv kq nh"/></div></div></a></div><ul class=""><li id="4693" class="mq mr iq ky b kz la lc ld lf ms lj mt ln mu lr mv mw mx my bi translated">集合模型:</li></ul><div class="ne nf gp gr ng nh"><a rel="noopener follow" target="_blank" href="/two-is-better-than-one-ensembling-models-611ee4fa9bd8"><div class="ni ab fo"><div class="nj ab nk cl cj nl"><h2 class="bd ir gy z fp nm fr fs nn fu fw ip bi translated">两个比一个好:集合模型</h2><div class="no l"><h3 class="bd b gy z fp nm fr fs nn fu fw dk translated">组装起初听起来像是一个非常吓人的词，但实际上看起来很简单…让我解释一下组装…</h3></div><div class="np l"><p class="bd b dl z fp nm fr fs nn fu fw dk translated">towardsdatascience.com</p></div></div><div class="nq l"><div class="nx l ns nt nu nq nv kq nh"/></div></div></a></div><ul class=""><li id="f53f" class="mq mr iq ky b kz la lc ld lf ms lj mt ln mu lr mv mw mx my bi translated">评估分类模型的指标:</li></ul><div class="ne nf gp gr ng nh"><a href="https://neptune.ai/blog/f1-score-accuracy-roc-auc-pr-auc" rel="noopener  ugc nofollow" target="_blank"><div class="ni ab fo"><div class="nj ab nk cl cj nl"><h2 class="bd ir gy z fp nm fr fs nn fu fw ip bi translated">F1 评分 vs ROC AUC vs 准确性 vs PR AUC:应该选择哪种评价指标？|海王星的…</h2><div class="no l"><h3 class="bd b gy z fp nm fr fs nn fu fw dk translated">所以你在做一个机器学习项目，并且在想:什么时候准确度是比 ROC AUC 更好的度量？什么是…</h3></div><div class="np l"><p class="bd b dl z fp nm fr fs nn fu fw dk translated">海王星. ai</p></div></div><div class="nq l"><div class="ny l ns nt nu nq nv kq nh"/></div></div></a></div><div class="ne nf gp gr ng nh"><a rel="noopener follow" target="_blank" href="/understanding-auc-roc-curve-68b2303cc9c5"><div class="ni ab fo"><div class="nj ab nk cl cj nl"><h2 class="bd ir gy z fp nm fr fs nn fu fw ip bi translated">理解 AUC-ROC 曲线</h2><div class="no l"><h3 class="bd b gy z fp nm fr fs nn fu fw dk translated">在机器学习中，性能测量是一项基本任务。所以说到分类问题，我们可以…</h3></div><div class="np l"><p class="bd b dl z fp nm fr fs nn fu fw dk translated">towardsdatascience.com</p></div></div><div class="nq l"><div class="nz l ns nt nu nq nv kq nh"/></div></div></a></div><h2 id="a3e4" class="ls lt iq bd lu lv lw dn lx ly lz dp ma lf mb mc md lj me mf mg ln mh mi mj mk bi translated">关键可修改输入:</h2><p id="3a99" class="pw-post-body-paragraph kw kx iq ky b kz ml jr lb lc mm ju le lf mn lh li lj mo ll lm ln mp lp lq lr ij bi translated">以下是关键输入(行内注释中为每个输入提供了更多详细信息)。这些部分在代码中用注释“<strong class="ky ir">突出显示，在此处进行修改</strong>”:</p><ul class=""><li id="2743" class="mq mr iq ky b kz la lc ld lf ms lj mt ln mu lr mv mw mx my bi translated">用于分类分析的输入数据集:在本例中，我使用了来自熊猫默认数据集的“乳腺癌”数据集</li><li id="2d39" class="mq mr iq ky b kz mz lc na lf nb lj nc ln nd lr mv mw mx my bi translated">测试数据比例:0 到 1 之间，默认为 0.3(或 30%)</li><li id="19d9" class="mq mr iq ky b kz mz lc na lf nb lj nc ln nd lr mv mw mx my bi translated">归一化:0-无归一化，1-最小-最大缩放，2-Z 分数缩放</li><li id="a2dc" class="mq mr iq ky b kz mz lc na lf nb lj nc ln nd lr mv mw mx my bi translated">要测试的模型对象列表</li><li id="0ae6" class="mq mr iq ky b kz mz lc na lf nb lj nc ln nd lr mv mw mx my bi translated">网格搜索的折叠次数(超参数调整)</li><li id="2da3" class="mq mr iq ky b kz mz lc na lf nb lj nc ln nd lr mv mw mx my bi translated">确定最佳模型的评分标准(例如，准确性)—代码注释中提供了更多详细信息</li><li id="7c43" class="mq mr iq ky b kz mz lc na lf nb lj nc ln nd lr mv mw mx my bi translated">在模型拟合期间查看端子详细程度的标志:0-无输出，1-所有详细信息，2-进度条</li><li id="7779" class="mq mr iq ky b kz mz lc na lf nb lj nc ln nd lr mv mw mx my bi translated">超参数库:代码中的一个全局字典，为每个模型表单提供一组超参数进行调整</li></ul><h2 id="b05a" class="ls lt iq bd lu lv lw dn lx ly lz dp ma lf mb mc md lj me mf mg ln mh mi mj mk bi translated">一般执行步骤:</h2><p id="0e04" class="pw-post-body-paragraph kw kx iq ky b kz ml jr lb lc mm ju le lf mn lh li lj mo ll lm ln mp lp lq lr ij bi translated">获取这些输入后，对考虑中的<strong class="ky ir">每个</strong>模型形式执行以下动作:</p><p id="949a" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">*正向特征选择<br/> *标准化<br/> *网格搜索超参数调整<br/> *最佳模型的度量计算</p><h2 id="c18f" class="ls lt iq bd lu lv lw dn lx ly lz dp ma lf mb mc md lj me mf mg ln mh mi mj mk bi translated">输出:</h2><p id="571a" class="pw-post-body-paragraph kw kx iq ky b kz ml jr lb lc mm ju le lf mn lh li lj mo ll lm ln mp lp lq lr ij bi translated">创建了一个 pandas 数据框架“结果”,它为标签 1 测试的每个模型提供了以下指标。您可能需要根据哪个类对基于上下文的分析更重要来调整输入数据。</p><ul class=""><li id="84da" class="mq mr iq ky b kz la lc ld lf ms lj mt ln mu lr mv mw mx my bi translated">具有最佳超参数的模型细节</li><li id="c66e" class="mq mr iq ky b kz mz lc na lf nb lj nc ln nd lr mv mw mx my bi translated">模型精度</li><li id="c51c" class="mq mr iq ky b kz mz lc na lf nb lj nc ln nd lr mv mw mx my bi translated">精确度和召回率</li><li id="fcd1" class="mq mr iq ky b kz mz lc na lf nb lj nc ln nd lr mv mw mx my bi translated">f-测度</li><li id="860b" class="mq mr iq ky b kz mz lc na lf nb lj nc ln nd lr mv mw mx my bi translated">受试者工作特征曲线下面积(AUC)</li></ul><p id="db59" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">此表有助于比较各种模型形式。精确度和召回率指标有助于选择更符合业务目标而不仅仅是精确度的模型。</p><h2 id="b908" class="ls lt iq bd lu lv lw dn lx ly lz dp ma lf mb mc md lj me mf mg ln mh mi mj mk bi translated">重要提示:</h2><p id="2532" class="pw-post-body-paragraph kw kx iq ky b kz ml jr lb lc mm ju le lf mn lh li lj mo ll lm ln mp lp lq lr ij bi translated">该模块不以任何方式处理特征工程，仅基于输入数据执行特征选择。为了改善任何模型的结果，执行有效的特征工程是非常重要的。用户可能会观察到一种模型形式比另一种给出更好的结果，但是任何模型的整体性能都可以随着预测变量的改进而显著提高。</p><h2 id="f281" class="ls lt iq bd lu lv lw dn lx ly lz dp ma lf mb mc md lj me mf mg ln mh mi mj mk bi translated">剧本:</h2><h2 id="8d49" class="ls lt iq bd lu lv lw dn lx ly lz dp ma lf mb mc md lj me mf mg ln mh mi mj mk bi translated">各种任务的模块</h2><p id="798e" class="pw-post-body-paragraph kw kx iq ky b kz ml jr lb lc mm ju le lf mn lh li lj mo ll lm ln mp lp lq lr ij bi translated">第一个函数根据用户在控制面板中指定的条件，为标准化和网格搜索创建管道。</p><pre class="kh ki kj kk gt oa ob oc od aw oe bi"><span id="f079" class="ls lt iq ob b gy of og l oh oi">def create_pipeline(norm, model):<br/>    if norm == 1:<br/>        scale = StandardScaler()<br/>        pipe = Pipeline([('norm', scale), ('reg', model)])<br/>    elif norm == 2:<br/>        scale = MinMaxScaler()<br/>        pipe = Pipeline([('norm', scale), ('reg', model)])<br/>    else:<br/>        pipe = Pipeline([('reg', model)])<br/>    return pipe</span></pre><p id="e27c" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">第二个函数执行正向特征选择，并返回最佳特征的索引。</p><pre class="kh ki kj kk gt oa ob oc od aw oe bi"><span id="2e33" class="ls lt iq ob b gy of og l oh oi">def select_features(model, X_train, Y_train, selection,<br/>                    score_criteria, see_details, norm=0):<br/>    pipe = create_pipeline(norm, model)<br/>    sfs = SequentialFeatureSelector(pipe,<br/>                                    forward=selection,<br/>                                    k_features='best',<br/>                                    scoring=score_criteria,<br/>                                    verbose=see_details)<br/>    sfs = sfs.fit(X_train, Y_train)<br/>    return list(sfs.k_feature_idx_)</span></pre><p id="4bba" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">该函数对所提供的参数网格执行网格搜索，并返回最佳模型对象。</p><pre class="kh ki kj kk gt oa ob oc od aw oe bi"><span id="02ef" class="ls lt iq ob b gy of og l oh oi">def run_model(model, param_grid, X_train, Y_train,<br/>              X, Y, score_criteria, folds,<br/>              see_details, norm=0):<br/>    pipe = create_pipeline(norm, model)<br/>    model_grid = GridSearchCV(pipe,<br/>                              param_grid,<br/>                              cv=folds,<br/>                              scoring=score_criteria,<br/>                              verbose=see_details)<br/>    model_grid.fit(X_train, Y_train)</span><span id="d072" class="ls lt iq ob b gy oj og l oh oi">pipe = create_pipeline(norm, model_grid.best_estimator_)<br/>    return model_grid.best_estimator_</span></pre><p id="feff" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">最后一个函数计算最佳超参数组合的所有相关指标，并返回这些指标的 pandas 系列。</p><pre class="kh ki kj kk gt oa ob oc od aw oe bi"><span id="97af" class="ls lt iq ob b gy of og l oh oi">def get_model_eval(model, X_train, Y_train, X_test, Y_test):<br/>    cm = confusion_matrix(Y_test, model.predict(X_test))<br/>    t1, f1, t0, f0 = cm[1, 1], cm[1, 0], cm[0, 0], cm[0, 1]<br/>    precision = precision_score(Y_test, model.predict(X_test))<br/>    recall = recall_score(Y_test, model.predict(X_test))<br/>    return pd.Series([model,<br/>                      (t1 + t0) / (t1 + t0 + f1 + f0),<br/>                      precision,<br/>                      recall,<br/>                      2 * precision * recall / (precision + recall),<br/>                      -1 if type(model.steps[1][1]) == RidgeClassifier else roc_auc_score(Y_test, model.predict_proba(X_test)[:, 1])])</span></pre><h2 id="1b98" class="ls lt iq bd lu lv lw dn lx ly lz dp ma lf mb mc md lj me mf mg ln mh mi mj mk bi translated">全局超参数字典(在此进行修改)</h2><p id="4556" class="pw-post-body-paragraph kw kx iq ky b kz ml jr lb lc mm ju le lf mn lh li lj mo ll lm ln mp lp lq lr ij bi translated">这是该模块中所有模型的各种模型参数的全局字典。在基于癌症数据集的典型范围的代码中已经填充了一些缺省值集。该词典包含每个模型的一些关键超参数，但并不详尽。鼓励用户访问 scikit-learn 文档以获得所有参数的列表，并根据他们的要求添加到下面的字典中。</p><pre class="kh ki kj kk gt oa ob oc od aw oe bi"><span id="af5d" class="ls lt iq ob b gy of og l oh oi"># Global model paramater grid dictionary------------------------------------<br/># Change your hyperparameter ranges for grid search in this section<br/>PARAM_DICT = {<br/>  LogisticRegression: {<br/>    'reg__tol': [1e-2, 1e-4, 1e-6],<br/>    'reg__fit_intercept': [True, False],<br/>    'reg__penalty': ['l1', 'l2']<br/>  },<br/>  RidgeClassifier: {<br/>    'reg__alpha': [0.1, 1, 100],<br/>    'reg__copy_X': [True, False],<br/>    'reg__fit_intercept': [True, False],<br/>    'reg__tol': [0.1, 1],<br/>    'reg__solver': ['auto', 'svd', 'cholesky', 'lsqr',<br/>      'sparse_cg', 'sag', 'saga'<br/>    ]<br/>  },</span><span id="aa45" class="ls lt iq ob b gy oj og l oh oi">KNeighborsClassifier: {<br/>    'reg__n_neighbors': [5, 30, 100]<br/>  },<br/>  GaussianNB: {<br/>  },</span><span id="0305" class="ls lt iq ob b gy oj og l oh oi">DecisionTreeClassifier: {<br/>    'reg__max_depth': [5, 10, 20],<br/>    'reg__max_features': [0.3, 0.7, 1.0],<br/>    'reg__max_leaf_nodes': [10, 50, 100],<br/>    'reg__splitter': ['best', 'random']<br/>  },</span><span id="a3f7" class="ls lt iq ob b gy oj og l oh oi">BaggingClassifier: {<br/>    'reg__bootstrap': [True, False],<br/>    'reg__bootstrap_features': [True, False],<br/>    'reg__max_features': [0.3, 0.7, 1.0],<br/>    'reg__max_samples': [0.3, 0.7, 1.0],<br/>    'reg__n_estimators': [10, 50, 100]<br/>  },<br/>  RandomForestClassifier: {<br/>    'reg__bootstrap': [True, False],<br/>    'reg__max_depth': [5, 10, 20],<br/>    'reg__max_features': [0.3, 0.7, 1.0],<br/>    'reg__max_leaf_nodes': [10, 50, 100],<br/>    'reg__min_impurity_decrease': [0, 0.1, 0.2],<br/>    'reg__n_estimators': [10, 50, 100]<br/>  },</span><span id="4e68" class="ls lt iq ob b gy oj og l oh oi">SVC: {<br/>    'reg__C': [10 ** -3, 1, 1000],<br/>    'reg__kernel': ['linear', 'poly', 'rbf'],<br/>    'reg__shrinking': [True, False],<br/>    'reg__probability': [True]<br/>  },</span><span id="435a" class="ls lt iq ob b gy oj og l oh oi">GradientBoostingClassifier: {<br/>    'reg__learning_rate': [0.1, 0.2, 0.5],<br/>    # 'reg__loss': ['ls', 'lad', 'huber', 'quantile'],<br/>    'reg__max_depth': [10, 20, 50],<br/>    'reg__max_features': [0.5, 0.8, 1.0],<br/>    'reg__max_leaf_nodes': [10, 50, 100],<br/>    'reg__min_impurity_decrease': [0, 0.1, 0.2],<br/>    'reg__min_samples_leaf': [5, 10, 20],<br/>    'reg__min_samples_split': [5, 10, 20],<br/>    'reg__n_estimators': [10, 50, 100]<br/>  },<br/>  XGBClassifier: {<br/>    'reg__booster': ['gbtree', 'gblinear', 'dart'],<br/>    'reg__learning_rate': [0.2, 0.5, 0.8],<br/>    'reg__max_depth': [5, 10, 20],<br/>    'reg__n_estimators': [10, 50, 100],<br/>    'reg__reg_alpha': [0.1, 1, 10],<br/>    'reg__reg_lambda': [0.1, 1, 10],<br/>    'reg__subsample': [0.3, 0.5, 0.8],<br/>    'reg__probability': [True]<br/>  }</span><span id="749b" class="ls lt iq ob b gy oj og l oh oi">}</span></pre><h2 id="4513" class="ls lt iq bd lu lv lw dn lx ly lz dp ma lf mb mc md lj me mf mg ln mh mi mj mk bi translated">按键输入的用户控制面板(在此进行修改)</h2><p id="6d69" class="pw-post-body-paragraph kw kx iq ky b kz ml jr lb lc mm ju le lf mn lh li lj mo ll lm ln mp lp lq lr ij bi translated">可以在此处更改模块的输入。这是这个脚本的控制面板，介绍中提到的所有变量都可以在这里修改，以测试各种场景。请参考评论了解变量。</p><pre class="kh ki kj kk gt oa ob oc od aw oe bi"><span id="e626" class="ls lt iq ob b gy of og l oh oi"># --------------------------------------------------------------------------<br/># USER CONTROL PANEL, CHANGE THE VARIABLES, MODEL FORMS ETC. HERE</span><span id="496e" class="ls lt iq ob b gy oj og l oh oi"># Read data here, define X (features) and Y (Target variable)<br/>data = datasets.load_breast_cancer()<br/>X = pd.DataFrame(data['data'])<br/>X.columns = data['feature_names']<br/>Y = data['target']</span><span id="5c20" class="ls lt iq ob b gy oj og l oh oi"># Specify size of test data (%)<br/>size = 0.3</span><span id="9e2d" class="ls lt iq ob b gy oj og l oh oi"># Set random seed for sampling consistency<br/>random.seed(100)</span><span id="e46f" class="ls lt iq ob b gy oj og l oh oi"># Set type of normalization you want to perform<br/># 0 - No Normalization, 1 - Min-max scaling, 2 - Zscore scaling<br/>norm = 1</span><span id="36bb" class="ls lt iq ob b gy oj og l oh oi"># Mention all model forms you want to run<br/>to_run = [DecisionTreeClassifier,<br/>          BaggingClassifier,<br/>          RandomForestClassifier,<br/>          GradientBoostingClassifier,<br/>          XGBClassifier,<br/>          SVC,<br/>          KNeighborsClassifier,<br/>          RidgeClassifier,<br/>          GaussianNB,<br/>          LogisticRegression]</span><span id="171a" class="ls lt iq ob b gy oj og l oh oi"># Specify number of crossvalidation folds<br/>folds = 2</span><span id="f3d2" class="ls lt iq ob b gy oj og l oh oi"># Specify model selection criteria<br/># Possible values are:<br/># 'accuracy'<br/># 'precision'<br/># 'recall'<br/># 'f1'<br/># 'roc_auc'</span><span id="194f" class="ls lt iq ob b gy oj og l oh oi">score_criteria = 'accuracy'</span><span id="8a3d" class="ls lt iq ob b gy oj og l oh oi"># Specify details of terminal output you'd like to see<br/># 0 - No output, 1 - All details, 2 - Progress bar<br/># Outputs might vary based on individual functions<br/>see_details = 0</span></pre><h2 id="b934" class="ls lt iq bd lu lv lw dn lx ly lz dp ma lf mb mc md lj me mf mg ln mh mi mj mk bi translated">模型执行</h2><p id="67f6" class="pw-post-body-paragraph kw kx iq ky b kz ml jr lb lc mm ju le lf mn lh li lj mo ll lm ln mp lp lq lr ij bi translated">该部分迭代地为用户指定的每个模型找到最佳的超参数集，计算度量并填充结果表，用于进一步的分析/实验。</p><pre class="kh ki kj kk gt oa ob oc od aw oe bi"><span id="8eb0" class="ls lt iq ob b gy of og l oh oi"># Model execution part, results will be stored in the dataframe 'results'<br/># Best model can be selected based on these criteria</span><span id="55b9" class="ls lt iq ob b gy oj og l oh oi">results = pd.DataFrame(columns=['model', 'Accuracy', 'PrecisionLab1', 'RecallLab1',<br/>                                'FMeasureLab1', 'AUC'])</span><span id="45ad" class="ls lt iq ob b gy oj og l oh oi">X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=size)</span><span id="cbc0" class="ls lt iq ob b gy oj og l oh oi">for model in to_run:<br/>    with warnings.catch_warnings():<br/>        warnings.simplefilter('ignore')<br/>        best_feat = select_features(model(), X_train, Y_train, True,<br/>                                    score_criteria, see_details, norm)<br/>        model = run_model(model(), PARAM_DICT[model],<br/>                          X_train.iloc[:, best_feat],<br/>                          Y_train,<br/>                          X.iloc[:, best_feat], Y,<br/>                          score_criteria, folds, see_details, norm)<br/>        stats = get_model_eval(model, X_train.iloc[:, best_feat], Y_train,<br/>                               X_test.iloc[:, best_feat], Y_test)<br/>        stats.index = results.columns<br/>        results = results.append(stats, ignore_index=True)</span><span id="fabd" class="ls lt iq ob b gy oj og l oh oi">print(results)<br/>results['Form'] = [str(i).split()[-1].split('.')[-1] for i in to_run]<br/>sb.lmplot('RecallLab1', 'Accuracy', hue='Form', data=results, fit_reg=False)</span></pre><h2 id="b459" class="ls lt iq bd lu lv lw dn lx ly lz dp ma lf mb mc md lj me mf mg ln mh mi mj mk bi translated">结论</h2><figure class="kh ki kj kk gt kl gh gi paragraph-image"><div class="gh gi ok"><img src="../Images/46b99d8afcdc0ca7cc1ef3c590194d70.png" data-original-src="https://miro.medium.com/v2/resize:fit:1128/format:webp/1*bGtVlKC9_UflwbyPQo9xNQ.png"/></div></figure><p id="899a" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在癌症患者检测的情况下，从形式上来说，检测所有患者对于我们的模型具有尽可能高的召回率是非常重要的。从上图中，我们可以观察到有三种模型能够达到完美的召回率:岭分类器、逻辑回归和支持向量机。在这种情况下，最好的方法是在这些模型中选择精度最高的模型，即 SVM 模型。</p><p id="5c87" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">与回归笔记本中的示例类似，逻辑回归和岭分类器等更简单的模型比集成模型表现得更好。</p><p id="1eef" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我希望这个模块能够加快实验速度，并提供一个机会，根据您的需求在它的基础上构建进一步的定制！</p><p id="2a78" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">点击此处查看完整的笔记本:</p><div class="ne nf gp gr ng nh"><a href="https://github.com/himanshu0394/AnalyticsToolkit/blob/master/Classification%20Block.ipynb" rel="noopener  ugc nofollow" target="_blank"><div class="ni ab fo"><div class="nj ab nk cl cj nl"><h2 class="bd ir gy z fp nm fr fs nn fu fw ip bi translated">himanshu0394/AnalyticsToolkit</h2><div class="no l"><h3 class="bd b gy z fp nm fr fs nn fu fw dk translated">通过在 GitHub 上创建一个帐户，为 himanshu0394/AnalyticsToolkit 开发做出贡献。</h3></div><div class="np l"><p class="bd b dl z fp nm fr fs nn fu fw dk translated">github.com</p></div></div><div class="nq l"><div class="ol l ns nt nu nq nv kq nh"/></div></div></a></div></div></div>    
</body>
</html>