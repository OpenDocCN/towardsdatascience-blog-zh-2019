<html>
<head>
<title>Preprocessing: Regression Imputation of Missing Continuous Values</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">预处理:缺失连续值的回归插补</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/preprocessing-regression-imputation-of-missing-continuous-values-f612179bafb4?source=collection_archive---------15-----------------------#2019-11-30">https://towardsdatascience.com/preprocessing-regression-imputation-of-missing-continuous-values-f612179bafb4?source=collection_archive---------15-----------------------#2019-11-30</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><figure class="is it gp gr iu iv gh gi paragraph-image"><div class="gh gi ir"><img src="../Images/f3c668744402130b050ad5ef7f23b493.png" data-original-src="https://miro.medium.com/v2/resize:fit:958/format:webp/1*NKwvP6GeeEYY9-VS17f_kw.jpeg"/></div></figure><div class=""/><p id="ce7b" class="pw-post-body-paragraph jx jy ja jz b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku im bi translated">作为编码和输入分类值的后续，本文将介绍使用回归技术来输入连续变量的缺失值。</p><p id="9ebf" class="pw-post-body-paragraph jx jy ja jz b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku im bi translated">在决定如何处理数据中的缺失值时，有三种选择:移除带有缺失数据的观测值、将缺失值保留在原位或估算(使用占位符)值。如果决定使用占位符值，实际选择是平均值、中间值或众数。如果缺失值很少和/或数据的变化不显著，这就足够了。</p><p id="106a" class="pw-post-body-paragraph jx jy ja jz b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku im bi translated">如果有一个特性非常重要，需要保留，但却缺少大量的变量值，该怎么办？Sci-kit Learn 和他们的迭代输入包。</p><p id="b263" class="pw-post-body-paragraph jx jy ja jz b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku im bi translated">我们将使用一个随机生成的数据集，其中包含有目的地放置的空值。首先，让我们来谈谈我们将要加载的包，并深入了解一下 IterativeImputer。</p><pre class="kv kw kx ky gt kz la lb lc aw ld bi"><span id="6ebc" class="le lf ja la b gy lg lh l li lj">import pandas as pd<br/>import numpy as np<br/># explicitly require this experimental feature<br/>from sklearn.experimental import enable_iterative_imputer<br/># now you can import normally from sklearn.impute<br/>from sklearn.impute import IterativeImputer<br/>from sklearn.ensemble import ExtraTreesRegressor<br/>from sklearn.linear_model import BayesianRidge<br/>import random</span></pre><p id="2869" class="pw-post-body-paragraph jx jy ja jz b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku im bi translated">如您所见，迭代输入在 sci-kit learn 库中仍处于实验阶段。在某些情况下，使用这种插补技术会牺牲模型的准确性，因此一定要比较没有使用插补技术的数据集的验证结果。如果你也注意到了，我们已经加载了几个回归模型。IterativeImputer 包允许灵活地选择预加载的 sci-kit 学习模型来迭代数据以估算缺失值。这里重点介绍了三种型号，文档中提供了型号列表和更详细的说明:</p><div class="is it gp gr iu lk"><a href="https://scikit-learn.org/stable/modules/generated/sklearn.impute.IterativeImputer.html#sklearn.impute.IterativeImputer" rel="noopener  ugc nofollow" target="_blank"><div class="ll ab fo"><div class="lm ab ln cl cj lo"><h2 class="bd jb gy z fp lp fr fs lq fu fw iz bi translated">sk learn . input . iterativeinputr-sci kit-learn 0 . 21 . 3 文档</h2><div class="lr l"><h3 class="bd b gy z fp lp fr fs lq fu fw dk translated">sk learn . impute . iterative imputr(estimator = None，missing_values=nan，sample_posterior=False，max_iter=10…</h3></div><div class="ls l"><p class="bd b dl z fp lp fr fs lq fu fw dk translated">scikit-learn.org</p></div></div><div class="lt l"><div class="lu l lv lw lx lt ly iw lk"/></div></div></a></div><p id="cbb4" class="pw-post-body-paragraph jx jy ja jz b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku im bi translated">还要注意，我们使用的方法都是回归模型。这是基于数据的偏好。检查数据并寻找最适合估算值的模型的线索是一种很好的做法。</p><p id="73b7" class="pw-post-body-paragraph jx jy ja jz b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku im bi translated">现在，我们可以生成一个随机数据集，添加 10%的缺失数据，然后将它们混在一起。</p><pre class="kv kw kx ky gt kz la lb lc aw ld bi"><span id="8f3e" class="le lf ja la b gy lg lh l li lj">data = np.random.random([1000,20])<br/>null_data = np.empty([1000,2])<br/>null_data[:] = np.nan<br/>full_data = np.concatenate((data,null_data), axis=1)<br/>full_data = np.random.permutation(full_data.flat)<br/>full_data = full_data.reshape([1000,22])</span></pre><p id="0d7b" class="pw-post-body-paragraph jx jy ja jz b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku im bi translated">这就是 IterativeImputer 的美妙之处，两行代码处理了所有的空值。BayesianRidge 是用于估算的默认方法，但是我们将调用它来展示一个例子，说明将所选模型实例化到代码中是多么简单。</p><pre class="kv kw kx ky gt kz la lb lc aw ld bi"><span id="4ab7" class="le lf ja la b gy lg lh l li lj">imputer = IterativeImputer(BayesianRidge())<br/>impute_data = pd.DataFrame(imputer.fit_transform(full_data))</span></pre><p id="352a" class="pw-post-body-paragraph jx jy ja jz b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku im bi translated">我对你的挑战是创建一个目标值集，并比较可用的回归和分类模型的结果以及带有缺失值的原始数据。该笔记本包含在上周预处理文章的分类插补笔记本中(<a class="ae lz" href="https://github.com/Jason-M-Richards/Encode-and-Impute-Categorical-Variables" rel="noopener ugc nofollow" target="_blank">https://github . com/Jason-M-Richards/Encode-and-Impute-categorial-Variables</a>)。感谢所有的支持，我真心希望你的感恩节过得愉快！下周见。</p></div></div>    
</body>
</html>