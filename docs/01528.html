<html>
<head>
<title>E-commerce Reviews Analysis Using NLP and Unsupervised Learning</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">基于自然语言处理和无监督学习的电子商务评论分析</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/e-commerce-reviews-analysis-902210726d47?source=collection_archive---------14-----------------------#2019-03-11">https://towardsdatascience.com/e-commerce-reviews-analysis-902210726d47?source=collection_archive---------14-----------------------#2019-03-11</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><figure class="gl gn jr js jt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi jq"><img src="../Images/bf92b687e59ea80059ab871ff2a0e3eb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*fZbyVhxtOUD47LHQXvwXwg.jpeg"/></div></div><figcaption class="kb kc gj gh gi kd ke bd b be z dk">picture credits to <a class="ae kf" href="http://www.oberlo.com" rel="noopener ugc nofollow" target="_blank">www.oberlo.com</a></figcaption></figure><p id="6dbd" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi le translated"><span class="l lf lg lh bm li lj lk ll lm di">在</span>这个项目中，我想练习<a class="ae kf" href="https://en.wikipedia.org/wiki/Natural_language_processing" rel="noopener ugc nofollow" target="_blank">自然语言处理</a>和<a class="ae kf" href="https://en.wikipedia.org/wiki/Unsupervised_learning" rel="noopener ugc nofollow" target="_blank">无监督机器学习</a>。在对我能从网上获得的数据集做了一些研究后，我找到了一个真实的电子商务企业的<a class="ae kf" href="https://www.kaggle.com/nicapotato/womens-ecommerce-clothing-reviews" rel="noopener ugc nofollow" target="_blank">女装数据集</a>。我认为，如果我能为企业开发一种从他们的服装评论中提取见解的自动化工具，这可能会很酷，对企业很有用。因为阅读成千上万的评论并不容易，而且是一项耗时的任务。</p><p id="d9ca" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">由于各种原因，这可能是有价值的。例如:</p><ol class=""><li id="5461" class="ln lo it ki b kj kk kn ko kr lp kv lq kz lr ld ls lt lu lv bi translated">了解趋势:了解人们在谈论什么，他们喜欢什么或不喜欢什么。</li><li id="de3a" class="ln lo it ki b kj lw kn lx kr ly kv lz kz ma ld ls lt lu lv bi translated">根据用户反馈改进产品。</li><li id="14e4" class="ln lo it ki b kj lw kn lx kr ly kv lz kz ma ld ls lt lu lv bi translated">跟进用户不喜欢的产品，进一步了解问题所在。</li><li id="94ba" class="ln lo it ki b kj lw kn lx kr ly kv lz kz ma ld ls lt lu lv bi translated">为了降低退货率，重新进货费用是电子商务成功甚至生存的一大开支。</li></ol><p id="1203" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">以上是你可以对顾客评论做的一些事情。</p><h2 id="3fab" class="mb mc it bd md me mf dn mg mh mi dp mj kr mk ml mm kv mn mo mp kz mq mr ms mt bi translated"><strong class="ak">我想解决的问题</strong></h2><p id="e3a7" class="pw-post-body-paragraph kg kh it ki b kj mu kl km kn mv kp kq kr mw kt ku kv mx kx ky kz my lb lc ld im bi translated">因此，为了这个项目的目的，我想探索以下几点:</p><ol class=""><li id="cb90" class="ln lo it ki b kj kk kn ko kr lp kv lq kz lr ld ls lt lu lv bi translated"><a class="ae kf" href="https://en.wikipedia.org/wiki/Topic_model" rel="noopener ugc nofollow" target="_blank">话题建模</a>:比如人们在谈论的那个服装/鞋子有哪些正面和负面的东西。通过计算某个主题中出现的单词或单词组合的频率，看看我是否能找到任何主题。</li><li id="f285" class="ln lo it ki b kj lw kn lx kr ly kv lz kz ma ld ls lt lu lv bi translated">使用<a class="ae kf" href="https://www.geeksforgeeks.org/clustering-in-machine-learning/" rel="noopener ugc nofollow" target="_blank">聚类</a>将好的和坏的评论“分离”:通过聚类的方法，将不同产品的好的和坏的评论分离出来或找到模式，以便发送给相应的部门关注。这可能非常困难，因为聚类方法是一种无监督的机器学习技术，可以从数据中找到隐藏的模式。</li></ol><h2 id="8d09" class="mb mc it bd md me mf dn mg mh mi dp mj kr mk ml mm kv mn mo mp kz mq mr ms mt bi translated"><strong class="ak">项目设计</strong></h2><ol class=""><li id="ac9d" class="ln lo it ki b kj mu kn mv kr mz kv na kz nb ld ls lt lu lv bi translated"><a class="ae kf" href="https://en.wikipedia.org/wiki/Data_cleansing" rel="noopener ugc nofollow" target="_blank">清理</a>并对我的数据执行<a class="ae kf" href="https://en.wikipedia.org/wiki/Exploratory_data_analysis" rel="noopener ugc nofollow" target="_blank">探索性数据分析(EDA) </a>。</li><li id="bdde" class="ln lo it ki b kj lw kn lx kr ly kv lz kz ma ld ls lt lu lv bi translated"><a class="ae kf" href="https://medium.com/@paritosh_30025/natural-language-processing-text-data-vectorization-af2520529cf7" rel="noopener">我清理的文本数据的矢量化</a>(计数矢量化器和 TF-IDF)。</li><li id="e3d8" class="ln lo it ki b kj lw kn lx kr ly kv lz kz ma ld ls lt lu lv bi translated">生成一个单词云，看看人们谈论的最频繁的单词是什么。</li><li id="796b" class="ln lo it ki b kj lw kn lx kr ly kv lz kz ma ld ls lt lu lv bi translated">进行主题建模，看看我是否能找到一些人们正在谈论的不同主题。</li><li id="41a6" class="ln lo it ki b kj lw kn lx kr ly kv lz kz ma ld ls lt lu lv bi translated">使用聚类方法从我的文本数据中聚类出模式，看看我是否能聚类出那些不好的评论(或不同类型的评论)。并使用 TSNE 可视化我的集群。</li><li id="675f" class="ln lo it ki b kj lw kn lx kr ly kv lz kz ma ld ls lt lu lv bi translated">最后，使用数据集中的评级列执行监督学习问题，以对好评和差评进行分类。</li></ol><h2 id="74ed" class="mb mc it bd md me mf dn mg mh mi dp mj kr mk ml mm kv mn mo mp kz mq mr ms mt bi translated"><strong class="ak">我使用的数据和技术</strong></h2><p id="ef4a" class="pw-post-body-paragraph kg kh it ki b kj mu kl km kn mv kp kq kr mw kt ku kv mx kx ky kz my lb lc ld im bi translated">我使用的数据集可以从<a class="ae kf" href="https://www.kaggle.com/nicapotato/womens-ecommerce-clothing-reviews" rel="noopener ugc nofollow" target="_blank"> Kaggle </a>获得，由 23486 条不同的服装评论和 11 个不同的栏目组成。</p><figure class="nd ne nf ng gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi nc"><img src="../Images/0c60b72b654b852015c5dbdde58e35a4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*4XgADqnzQM8AtgDGf6U_rg.png"/></div></div><figcaption class="kb kc gj gh gi kd ke bd b be z dk">snapshot of the data</figcaption></figure><p id="d59d" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我在这个项目中使用的工具有 numpy、pandas、matplotlib、seaborn、wordcloud、<a class="ae kf" href="https://scikit-learn.org/stable/" rel="noopener ugc nofollow" target="_blank"> sklearn </a>特别是与<a class="ae kf" href="https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html" rel="noopener ugc nofollow" target="_blank"> CountVectorizer </a>、<a class="ae kf" href="https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html" rel="noopener ugc nofollow" target="_blank"> TfidfVectorizer </a>、<a class="ae kf" href="https://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html" rel="noopener ugc nofollow" target="_blank"> Kmeans </a>、<a class="ae kf" href="https://scikit-learn.org/stable/modules/generated/sklearn.manifold.TSNE.html" rel="noopener ugc nofollow" target="_blank"> TSNE </a>、<a class="ae kf" href="https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.NMF.html" rel="noopener ugc nofollow" target="_blank"> NMF </a>、<a class="ae kf" href="https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.TruncatedSVD.html" rel="noopener ugc nofollow" target="_blank"> TruncatedSVD </a>、<a class="ae kf" href="https://scikit-learn.org/stable/modules/generated/sklearn.metrics.silhouette_score.html" rel="noopener ugc nofollow" target="_blank"> silhouette_score </a>、<a class="ae kf" href="https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.MultinomialNB.html" rel="noopener ugc nofollow" target="_blank"> MultinomialNB</a></p><h2 id="7514" class="mb mc it bd md me mf dn mg mh mi dp mj kr mk ml mm kv mn mo mp kz mq mr ms mt bi translated"><strong class="ak">数据清洗&amp;探索性数据分析(EDA) </strong></h2><figure class="nd ne nf ng gt ju gh gi paragraph-image"><div class="gh gi nh"><img src="../Images/566e47421e5c82ebcf20e6acb7005d33.png" data-original-src="https://miro.medium.com/v2/resize:fit:1284/format:webp/1*wep41bRO-Xy81G0N8lq07w.png"/></div><figcaption class="kb kc gj gh gi kd ke bd b be z dk">how many NAs in the dataset</figcaption></figure><ul class=""><li id="0de2" class="ln lo it ki b kj kk kn ko kr lp kv lq kz lr ld ni lt lu lv bi translated">数据集中有一些 NAs，我将把它们放在这里。</li><li id="5109" class="ln lo it ki b kj lw kn lx kr ly kv lz kz ma ld ni lt lu lv bi translated">ReviewText 列将是我的 NLP 主要列。</li><li id="9bed" class="ln lo it ki b kj lw kn lx kr ly kv lz kz ma ld ni lt lu lv bi translated">除了 ReviewText 列，我还创建了另一个名为 CombinedText 的列，它将 Title 和 ReviewText 列连接在一起。因为我认为你也可以从评论标题中得到一些隐藏的数据。</li><li id="a905" class="ln lo it ki b kj lw kn lx kr ly kv lz kz ma ld ni lt lu lv bi translated">最后，我将清理后的数据保存起来以备将来使用。</li></ul><h2 id="493e" class="mb mc it bd md me mf dn mg mh mi dp mj kr mk ml mm kv mn mo mp kz mq mr ms mt bi translated"><strong class="ak"> WordCloud </strong></h2><p id="d690" class="pw-post-body-paragraph kg kh it ki b kj mu kl km kn mv kp kq kr mw kt ku kv mx kx ky kz my lb lc ld im bi translated">接下来我要做的是创建一个单词云，看看人们谈论/使用最多的单词是什么。在此之前，我需要:</p><ol class=""><li id="fc7c" class="ln lo it ki b kj kk kn ko kr lp kv lq kz lr ld ls lt lu lv bi translated">将我的文本全部修改成小写</li><li id="d792" class="ln lo it ki b kj lw kn lx kr ly kv lz kz ma ld ls lt lu lv bi translated">删除评论中可能存在的一些不太有用的常用词，如连衣裙、连衣裙等。</li><li id="4044" class="ln lo it ki b kj lw kn lx kr ly kv lz kz ma ld ls lt lu lv bi translated">然后使用 Count 和 TF-IDF 矢量器对文本数据进行矢量化。例如:</li></ol><pre class="nd ne nf ng gt nj nk nl nm aw nn bi"><span id="7dbe" class="mb mc it nk b gy no np l nq nr">count_vectorizer = CountVectorizer(ngram_range=(1, 2),  <br/>                                   stop_words='english', <br/>                                   token_pattern="<strong class="nk iu">\\</strong>b[a-z][a-z]+<strong class="nk iu">\\</strong>b",<br/>                                   lowercase=<strong class="nk iu">True</strong>,<br/>                                   max_df = 0.6, max_features=4000)<br/>tfidf_vectorizer = TfidfVectorizer(ngram_range=(1, 2),  <br/>                                   stop_words='english', <br/>                                   token_pattern="<strong class="nk iu">\\</strong>b[a-z][a-z]+<strong class="nk iu">\\</strong>b",<br/>                                   lowercase=<strong class="nk iu">True</strong>,<br/>                                   max_df = 0.6, max_features=4000)<br/><br/>cv_data = count_vectorizer.fit_transform(df.ReviewTextLower)<br/>tfidf_data = tfidf_vectorizer.fit_transform(df.ReviewTextLower)</span></pre><p id="ae39" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">代码基本上是说将文本矢量化为<a class="ae kf" href="https://en.wikipedia.org/wiki/N-gram" rel="noopener ugc nofollow" target="_blank"> 1-gram </a>和 2-gram(也尝试了 3-gram)，使用包中预设的“英语”停用词，所有内容和模式都是小写，忽略文档中频率高于 0.6 的词，最多 4000 个特征/尺寸。</p><p id="90bb" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">然后我用下面的代码创建一个单词云:</p><pre class="nd ne nf ng gt nj nk nl nm aw nn bi"><span id="b267" class="mb mc it nk b gy no np l nq nr">for_wordcloud = count_vectorizer.get_feature_names()<br/>for_wordcloud = for_wordcloud<br/>for_wordcloud_str = ' '.join(for_wordcloud)<br/><br/>wordcloud = WordCloud(width=800, height=400, background_color ='black',<br/>                      min_font_size = 7).generate(for_wordcloud_str)<br/><br/>plt.figure(figsize=(20, 10), facecolor=<strong class="nk iu">None</strong>)<br/>plt.imshow(wordcloud)<br/>plt.axis("off")<br/>plt.tight_layout(pad=0)<br/> <br/>plt.show()</span></pre><figure class="nd ne nf ng gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi ns"><img src="../Images/84942d3d965554386d3941c6ff30d72b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*wEuUhK5LSYCoKspakJrZLA.png"/></div></div><figcaption class="kb kc gj gh gi kd ke bd b be z dk">most frequent words that customers are talking about</figcaption></figure><h2 id="28c5" class="mb mc it bd md me mf dn mg mh mi dp mj kr mk ml mm kv mn mo mp kz mq mr ms mt bi translated"><strong class="ak">话题建模</strong></h2><p id="4937" class="pw-post-body-paragraph kg kh it ki b kj mu kl km kn mv kp kq kr mw kt ku kv mx kx ky kz my lb lc ld im bi translated">在我做主题建模之前还有一步，就是使用<a class="ae kf" href="https://en.wikipedia.org/wiki/Latent_semantic_analysis" rel="noopener ugc nofollow" target="_blank"> LSA </a>和<a class="ae kf" href="https://en.wikipedia.org/wiki/Non-negative_matrix_factorization" rel="noopener ugc nofollow" target="_blank"> NMF </a>来降低我输入文本数据的维度。例如:</p><pre class="nd ne nf ng gt nj nk nl nm aw nn bi"><span id="b7ad" class="mb mc it nk b gy no np l nq nr"><em class="nt"># try using 10 dimensions</em><br/>n_comp = 10<br/>lsa_tfidf = TruncatedSVD(n_components=n_comp)<br/>lsa_cv = TruncatedSVD(n_components=n_comp)<br/>nmf_tfidf = NMF(n_components=n_comp)<br/>nmf_cv = NMF(n_components=n_comp)<br/><br/>lsa_tfidf_data = lsa_tfidf.fit_transform(tfidf_data)<br/>lsa_cv_data = lsa_cv.fit_transform(cv_data)<br/>nmf_tfidf_data = nmf_tfidf.fit_transform(tfidf_data)<br/>nmf_cv_data = nmf_cv.fit_transform(cv_data)</span></pre><p id="7a2b" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">然后我们可以进行主题建模，下面是一个输出示例:</p><figure class="nd ne nf ng gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi nu"><img src="../Images/03b5ffda413ea5ae1d597ce760b7ba57.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*UoQeFeClPJtoj7nZenMd5A.png"/></div></div><figcaption class="kb kc gj gh gi kd ke bd b be z dk">example of a few topics</figcaption></figure><p id="21af" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">您可以生成不同数量的主题，通过测试不同数量的主题来找到最佳数量，并查看这些主题对您是否有意义。</p><h2 id="1cd5" class="mb mc it bd md me mf dn mg mh mi dp mj kr mk ml mm kv mn mo mp kz mq mr ms mt bi translated"><strong class="ak">聚类</strong></h2><p id="5778" class="pw-post-body-paragraph kg kh it ki b kj mu kl km kn mv kp kq kr mw kt ku kv mx kx ky kz my lb lc ld im bi translated">在运行聚类算法之前，最好<a class="ae kf" href="https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html" rel="noopener ugc nofollow" target="_blank">将</a>您的输入数据标准化为平均值 0 和标准差 1。因为您的要素可能不在同一比例上，换句话说，这可能与从要素 a 增加 1 个单位和从要素 b 增加 1 个单位不是一回事。</p><pre class="nd ne nf ng gt nj nk nl nm aw nn bi"><span id="a36a" class="mb mc it nk b gy no np l nq nr"><em class="nt"># initialize standardscaler</em><br/><strong class="nk iu">from</strong> <strong class="nk iu">sklearn.preprocessing</strong> <strong class="nk iu">import</strong> StandardScaler<br/>SS = StandardScaler()<br/><br/><em class="nt"># transform my reducer data using standardscaler</em><br/>lsa_tfidf_data_sclaed = SS.fit_transform(lsa_tfidf_data)<br/>lsa_cv_data_sclaed = SS.fit_transform(lsa_cv_data)<br/>nmf_tfidf_data_scaled = SS.fit_transform(nmf_tfidf_data)<br/>nmf_cv_data_scaled = SS.fit_transform(nmf_cv_data)</span></pre><p id="16b4" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">然后你可以使用无监督的机器学习算法，针对不同的话题或者不同类型的评论做聚类。在这个项目中，我使用了<a class="ae kf" href="https://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html" rel="noopener ugc nofollow" target="_blank"> KMeans </a>，还使用了惯性和轮廓分数作为代理来帮助我确定我应该使用的最佳聚类数。然后使用<a class="ae kf" href="https://scikit-learn.org/stable/modules/generated/sklearn.manifold.TSNE.html" rel="noopener ugc nofollow" target="_blank"> TSNE </a>来帮助我可视化生成的集群。例如:</p><div class="nd ne nf ng gt ab cb"><figure class="nv ju nw nx ny nz oa paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><img src="../Images/3c0b37b3308f7db6c9be749db922a678.png" data-original-src="https://miro.medium.com/v2/resize:fit:668/0*wl4JfgbJIMeQSmVI"/></div></figure><figure class="nv ju nw nx ny nz oa paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><img src="../Images/5903f06d963f941d7eaa737821d48070.png" data-original-src="https://miro.medium.com/v2/resize:fit:668/0*-Y2JEsiU241277xZ"/></div></figure><figure class="nv ju ob nx ny nz oa paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><img src="../Images/6bd1b7fca14521114504b9a15e1f5431.png" data-original-src="https://miro.medium.com/v2/resize:fit:668/0*O2A7O3gk5HbXSIKX"/></div><figcaption class="kb kc gj gh gi kd ke bd b be z dk oc di od oe">TSNE plots for different number of clusters</figcaption></figure></div><p id="9742" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在确定了多少个聚类是最佳聚类之后，您可以打印出最接近每个聚类质心的文档以供检查。例如:</p><pre class="nd ne nf ng gt nj nk nl nm aw nn bi"><span id="bca1" class="mb mc it nk b gy no np l nq nr">indices_max = [index <strong class="nk iu">for</strong> index, value <strong class="nk iu">in</strong> enumerate(kmeans.labels_) <strong class="nk iu">if</strong> value==3]<br/><strong class="nk iu">for</strong> rev_index <strong class="nk iu">in</strong> indices_max[:5]:<br/>    print(rev_index, str(df.ReviewText[rev_index]))<br/>    print("<strong class="nk iu">\n</strong>")</span></pre><figure class="nd ne nf ng gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi of"><img src="../Images/ebbd8708b679b6621081b7b81c555ffe.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*QtF7R0RbwbrDM9pSWOHC8A.png"/></div></div><figcaption class="kb kc gj gh gi kd ke bd b be z dk">example of a few documents</figcaption></figure><h2 id="df63" class="mb mc it bd md me mf dn mg mh mi dp mj kr mk ml mm kv mn mo mp kz mq mr ms mt bi translated"><strong class="ak">分类</strong></h2><p id="6de8" class="pw-post-body-paragraph kg kh it ki b kj mu kl km kn mv kp kq kr mw kt ku kv mx kx ky kz my lb lc ld im bi translated">我们可以尝试从分析文本数据中分离好的或坏的评论的另一件事是执行分类问题。</p><figure class="nd ne nf ng gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi nc"><img src="../Images/0c60b72b654b852015c5dbdde58e35a4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*4XgADqnzQM8AtgDGf6U_rg.png"/></div></div><figcaption class="kb kc gj gh gi kd ke bd b be z dk">snapshot of the data</figcaption></figure><p id="38fc" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在我们的数据中，我们有一个名为 Rating 的特性，它是客户对产品的评分，1 表示最不满意，5 表示最满意。</p><p id="37e4" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我们可以将 Rating 列设置为目标变量，将 engineered CombinedText 列设置为独立变量，看看是否可以构建一个分类器来自动对评论进行分类。</p><p id="e1a3" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我做的第一件事是将排名 1 到 4 归为差评(标记为 1)，而排名 5 是我们的好评(标记为 5)。这两个等级并不完全平衡，但都在可接受的范围内。我用<a class="ae kf" href="https://scikit-learn.org/stable/modules/naive_bayes.html" rel="noopener ugc nofollow" target="_blank">朴素贝叶斯</a>和<a class="ae kf" href="https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html" rel="noopener ugc nofollow" target="_blank">逻辑分类器</a>构建了分类模型。</p><div class="nd ne nf ng gt ab cb"><figure class="nv ju og nx ny nz oa paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><img src="../Images/eeeaebc8fb15599de5fb6726e00869f4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/0*h9YPS7T2VTQdOqaq"/></div></figure><figure class="nv ju oh nx ny nz oa paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><img src="../Images/1ae6e32387e66a5a366c22a96584acb5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1002/0*whQ4YyxSrHWGwQi3"/></div><figcaption class="kb kc gj gh gi kd ke bd b be z dk oi di oj oe">Before and After modification of the Rating column</figcaption></figure></div><p id="d212" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我用于模型评估的指标，我使用<a class="ae kf" href="https://en.wikipedia.org/wiki/Precision_and_recall" rel="noopener ugc nofollow" target="_blank">回忆</a>分数，因为我关心当我预测审查是好的审查但实际上不是时的情况。我得到的最好的召回分数是 0.74，没有太多的工程。如果在模型上有更多的时间和探索，分数可能会更好。</p><figure class="nd ne nf ng gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi ca"><img src="../Images/95ee13585aa7d83550253650391d3a21.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*6gviAWJrepApeJj-sjiMWQ.png"/></div></div><figcaption class="kb kc gj gh gi kd ke bd b be z dk">recall score fo both bad (rank 1) and good (rank 5) reviews</figcaption></figure><h2 id="ba29" class="mb mc it bd md me mf dn mg mh mi dp mj kr mk ml mm kv mn mo mp kz mq mr ms mt bi translated"><strong class="ak">吸取的教训</strong></h2><ul class=""><li id="2c05" class="ln lo it ki b kj mu kn mv kr mz kv na kz nb ld ni lt lu lv bi translated">无监督学习和有监督学习真的是天壤之别，因为它的本质！</li><li id="f5f4" class="ln lo it ki b kj lw kn lx kr ly kv lz kz ma ld ni lt lu lv bi translated">您将会花费大量时间来尝试理解如何对您的数据进行聚类，除了 KMeans 之外，还有许多聚类方法。</li><li id="0ee7" class="ln lo it ki b kj lw kn lx kr ly kv lz kz ma ld ni lt lu lv bi translated">在进行文本分析或 NLP 时，您可能会花费大量时间清理文本数据以获得最佳结果。例如，如何根据您的数据和您想要解决的问题的上下文来决定使用什么停用词，如何进行词条整理，如何进行向量化，如何降低维度并避免<a class="ae kf" href="https://en.wikipedia.org/wiki/Curse_of_dimensionality" rel="noopener ugc nofollow" target="_blank">维度诅咒</a>等等。</li></ul><h2 id="a42f" class="mb mc it bd md me mf dn mg mh mi dp mj kr mk ml mm kv mn mo mp kz mq mr ms mt bi translated"><strong class="ak">未来</strong></h2><p id="88b3" class="pw-post-body-paragraph kg kh it ki b kj mu kl km kn mv kp kq kr mw kt ku kv mx kx ky kz my lb lc ld im bi translated">如果我有机会延长该项目，我想跟进以下内容:</p><ul class=""><li id="3dde" class="ln lo it ki b kj kk kn ko kr lp kv lq kz lr ld ni lt lu lv bi translated">探索不同类型的聚类算法和 NLP 技术。</li><li id="b306" class="ln lo it ki b kj lw kn lx kr ly kv lz kz ma ld ni lt lu lv bi translated">添加新的停用词。</li><li id="789d" class="ln lo it ki b kj lw kn lx kr ly kv lz kz ma ld ni lt lu lv bi translated">构建一个 Flask 原型应用程序来创建一个自动流程，从用户评论中推荐(分离)不同的主题。</li></ul></div><div class="ab cl ok ol hx om" role="separator"><span class="on bw bk oo op oq"/><span class="on bw bk oo op oq"/><span class="on bw bk oo op"/></div><div class="im in io ip iq"><p id="0aca" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">非常感谢您的阅读，如果您有兴趣探索我使用的代码和资源，这个项目在我的<a class="ae kf" href="https://github.com/khsio/project_fletcher" rel="noopener ugc nofollow" target="_blank"> github repo </a>上。</p></div></div>    
</body>
</html>