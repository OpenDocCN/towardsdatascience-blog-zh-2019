<html>
<head>
<title>Negative Binomial Regression: A Step by Step Guide</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">负二项式回归:逐步指南</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/negative-binomial-regression-f99031bb25b4?source=collection_archive---------0-----------------------#2019-10-06">https://towardsdatascience.com/negative-binomial-regression-f99031bb25b4?source=collection_archive---------0-----------------------#2019-10-06</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><figure class="is it gp gr iu iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi ir"><img src="../Images/0915618634a3d42bec2d2c9b49440885.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*YXhunRK8mF2r__AQrojwNw.jpeg"/></div></div><figcaption class="jc jd gj gh gi je jf bd b be z dk"><a class="ae jg" href="https://en.wikipedia.org/wiki/Brooklyn_Bridge#/media/File:Brooklyn_Bridge_und_Lower_Manhattan.jpg" rel="noopener ugc nofollow" target="_blank">Brooklyn Bridge with Manhattan in the background</a> ( <a class="ae jg" href="https://creativecommons.org/licenses/by-sa/4.0" rel="noopener ugc nofollow" target="_blank">CC BY-SA 4.0</a>)</figcaption></figure><div class=""/><div class=""><h2 id="0f11" class="pw-subtitle-paragraph kg ji jj bd b kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx dk translated">外加一个关于负二项式回归的 Python 教程</h2></div></div><div class="ab cl ky kz hx la" role="separator"><span class="lb bw bk lc ld le"/><span class="lb bw bk lc ld le"/><span class="lb bw bk lc ld"/></div><div class="im in io ip iq"><p id="f50a" class="pw-post-body-paragraph lf lg jj lh b li lj kk lk ll lm kn ln lo lp lq lr ls lt lu lv lw lx ly lz ma im bi translated">在本文中，我们将讨论以下主题:</p><ol class=""><li id="15f9" class="mb mc jj lh b li lj ll lm lo md ls me lw mf ma mg mh mi mj bi translated">我们将介绍<strong class="lh jk">负二项式(NB)回归模型。</strong>NB 模型对于预测基于计数的数据非常有用。</li><li id="83c6" class="mb mc jj lh b li mk ll ml lo mm ls mn lw mo ma mg mh mi mj bi translated">我们将一步一步地讲解如何使用<strong class="lh jk"> statsmodels </strong>的<strong class="lh jk"> GLM 类</strong>在<strong class="lh jk"> Python </strong>中创建和测试负二项式回归模型。</li></ol></div><div class="ab cl ky kz hx la" role="separator"><span class="lb bw bk lc ld le"/><span class="lb bw bk lc ld le"/><span class="lb bw bk lc ld"/></div><div class="im in io ip iq"><h2 id="e46c" class="mp mq jj bd mr ms mt dn mu mv mw dp mx lo my mz na ls nb nc nd lw ne nf ng nh bi translated">使用负二项式回归模型的动机</h2><p id="b38f" class="pw-post-body-paragraph lf lg jj lh b li ni kk lk ll nj kn ln lo nk lq lr ls nl lu lv lw nm ly lz ma im bi translated">在我的<a class="ae jg" rel="noopener" target="_blank" href="/an-illustrated-guide-to-the-poisson-regression-model-50cccba15958">上一篇文章</a>中，我们介绍了泊松回归模型，并了解了如何将其应用于基于计数的数据，例如布鲁克林大桥上骑自行车者计数的数据集:</p><figure class="no np nq nr gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi nn"><img src="../Images/c24b016656eace7cf789dc18c0b996c0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*WYZrqmgD2f7UYNl40mxhfg.png"/></div></div><figcaption class="jc jd gj gh gi je jf bd b be z dk">Background image: <a class="ae jg" href="https://en.wikipedia.org/wiki/Brooklyn_Bridge#/media/File:Brooklyn_Bridge_Postdlf.jpg" rel="noopener ugc nofollow" target="_blank">The Brooklyn bridge as seen from Manhattan island</a></figcaption></figure><p id="e950" class="pw-post-body-paragraph lf lg jj lh b li lj kk lk ll lm kn ln lo lp lq lr ls lt lu lv lw lx ly lz ma im bi translated">我们还看到，泊松回归模型被证明是不够的建模我们的自行车数据集。</p><p id="0f68" class="pw-post-body-paragraph lf lg jj lh b li lj kk lk ll lm kn ln lo lp lq lr ls lt lu lv lw lx ly lz ma im bi translated">尽管泊松回归模型做出了视觉上令人满意的预测:</p><figure class="no np nq nr gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi ns"><img src="../Images/eeaa8597ee0f956256fb3898e1aea848.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*cxbTOC3pJtiiBO0S8y971A.png"/></div></div><figcaption class="jc jd gj gh gi je jf bd b be z dk">Actual daily counts of bicyclists, versus the values predicted by the Poisson regression model. (Data Source: The <a class="ae jg" rel="noopener" target="_blank" href="/an-illustrated-guide-to-the-poisson-regression-model-50cccba15958">Poisson Regression Model</a>) (Image by <a class="ae jg" href="https://sachin-date.medium.com/" rel="noopener">Author</a>)</figcaption></figure><p id="2de2" class="pw-post-body-paragraph lf lg jj lh b li lj kk lk ll lm kn ln lo lp lq lr ls lt lu lv lw lx ly lz ma im bi translated">…其结果在统计学上不令人满意:</p><figure class="no np nq nr gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi nt"><img src="../Images/6faf8d41a77378b16e4f6320565443f8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*uIuUFv6mGpj_Y3MToUX02w.png"/></div></div><figcaption class="jc jd gj gh gi je jf bd b be z dk">Training summary for the Poisson regression model showing unacceptably high values for deviance and Pearson chi-squared statistics (Image by <a class="ae jg" href="https://sachin-date.medium.com/" rel="noopener">Author</a>)</figcaption></figure><p id="b35c" class="pw-post-body-paragraph lf lg jj lh b li lj kk lk ll lm kn ln lo lp lq lr ls lt lu lv lw lx ly lz ma im bi translated">模型表现不佳是因为数据不符合泊松回归模型要求的<strong class="lh jk"> <em class="nu">方差=均值</em> </strong>准则。</p><p id="bde5" class="pw-post-body-paragraph lf lg jj lh b li lj kk lk ll lm kn ln lo lp lq lr ls lt lu lv lw lx ly lz ma im bi translated">这个相当严格的标准通常不满足真实世界的数据。通常，方差大于均值，这种性质称为<strong class="lh jk">过度分散，</strong>有时方差小于均值，称为<strong class="lh jk">分散不足</strong>。在这种情况下，需要使用一个回归模型，该模型不会使<strong class="lh jk"> <em class="nu">等分散假设</em> </strong>即<strong class="lh jk"> <em class="nu"> </em> </strong>假设方差=均值。</p><p id="fc1a" class="pw-post-body-paragraph lf lg jj lh b li lj kk lk ll lm kn ln lo lp lq lr ls lt lu lv lw lx ly lz ma im bi translated"><strong class="lh jk">负二项式(NB) </strong>回归模型就是这样一种模型，它不做关于数据的<strong class="lh jk"> <em class="nu">方差=均值</em> </strong>假设。</p><p id="c79e" class="pw-post-body-paragraph lf lg jj lh b li lj kk lk ll lm kn ln lo lp lq lr ls lt lu lv lw lx ly lz ma im bi translated">在本文的其余部分，我们将了解 NB 模型，并了解如何在骑自行车者计数数据集上使用它。</p></div><div class="ab cl ky kz hx la" role="separator"><span class="lb bw bk lc ld le"/><span class="lb bw bk lc ld le"/><span class="lb bw bk lc ld"/></div><div class="im in io ip iq"><h2 id="108a" class="mp mq jj bd mr ms mt dn mu mv mw dp mx lo my mz na ls nb nc nd lw ne nf ng nh bi translated">文章的布局</h2><p id="a641" class="pw-post-body-paragraph lf lg jj lh b li ni kk lk ll nj kn ln lo nk lq lr ls nl lu lv lw nm ly lz ma im bi translated">文章布局如下:</p><ol class=""><li id="945a" class="mb mc jj lh b li lj ll lm lo md ls me lw mf ma mg mh mi mj bi translated">我们将介绍一个真实世界的计数数据集，我们将在本文的其余部分使用它。</li><li id="060c" class="mb mc jj lh b li mk ll ml lo mm ls mn lw mo ma mg mh mi mj bi translated">我们将在这个数据集上定义我们的回归目标。</li><li id="59e6" class="mb mc jj lh b li mk ll ml lo mm ls mn lw mo ma mg mh mi mj bi translated">我们将使用 NB 模型作为我们的回归模型来制定回归策略。</li><li id="8fa1" class="mb mc jj lh b li mk ll ml lo mm ls mn lw mo ma mg mh mi mj bi translated">我们将配置 NB 模型，在数据集上训练它，并在测试数据集上进行一些预测。我们将使用<strong class="lh jk"><em class="nu">Python stats models</em></strong>库来完成所有这些工作。</li><li id="1f40" class="mb mc jj lh b li mk ll ml lo mm ls mn lw mo ma mg mh mi mj bi translated">最后，我们将检验 NB 模型的性能是否真的优于泊松模型的性能。</li></ol></div><div class="ab cl ky kz hx la" role="separator"><span class="lb bw bk lc ld le"/><span class="lb bw bk lc ld le"/><span class="lb bw bk lc ld"/></div><div class="im in io ip iq"><h2 id="c141" class="mp mq jj bd mr ms mt dn mu mv mw dp mx lo my mz na ls nb nc nd lw ne nf ng nh bi translated">真实世界的计数数据集</h2><p id="30f7" class="pw-post-body-paragraph lf lg jj lh b li ni kk lk ll nj kn ln lo nk lq lr ls nl lu lv lw nm ly lz ma im bi translated">下表包含了骑自行车穿过纽约市各种桥梁的人数。从 2017 年 4 月 1 日到 2017 年 10 月 31 日每天测量计数。</p><figure class="no np nq nr gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi nv"><img src="../Images/0f650c5c984a3160c4daa3c8403fd29d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*F4rEeygQ8YE5iEXd.png"/></div></div><figcaption class="jc jd gj gh gi je jf bd b be z dk">Source: <a class="ae jg" href="https://data.cityofnewyork.us/Transportation/Bicycle-Counts-for-East-River-Bridges/gua4-p9wg" rel="noopener ugc nofollow" target="_blank">Bicycle Counts for East River Bridges</a> (Data source: NYC OpenData) (Image by <a class="ae jg" href="https://sachin-date.medium.com/" rel="noopener">Author</a>)</figcaption></figure><p id="d517" class="pw-post-body-paragraph lf lg jj lh b li lj kk lk ll lm kn ln lo lp lq lr ls lt lu lv lw lx ly lz ma im bi translated">我们将集中分析每天通过布鲁克林大桥的骑自行车的人数。这是布鲁克林大桥上自行车数量的时间顺序图:</p><figure class="no np nq nr gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi nn"><img src="../Images/c09d495850334244449dab0e8e2f0c68.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*96lzwRma7Us0VXSP.png"/></div></div><figcaption class="jc jd gj gh gi je jf bd b be z dk">Daily bicyclist counts on the Brooklyn bridge (Background: <a class="ae jg" href="https://en.wikipedia.org/wiki/Brooklyn_Bridge#/media/File:Brooklyn_Bridge_Postdlf.jpg" rel="noopener ugc nofollow" target="_blank">The Brooklyn bridge as seen from Manhattan island</a>)</figcaption></figure></div><div class="ab cl ky kz hx la" role="separator"><span class="lb bw bk lc ld le"/><span class="lb bw bk lc ld le"/><span class="lb bw bk lc ld"/></div><div class="im in io ip iq"><h2 id="4c32" class="mp mq jj bd mr ms mt dn mu mv mw dp mx lo my mz na ls nb nc nd lw ne nf ng nh bi translated">我们的回归目标</h2><p id="66c4" class="pw-post-body-paragraph lf lg jj lh b li ni kk lk ll nj kn ln lo nk lq lr ls nl lu lv lw nm ly lz ma im bi translated">我们回归的目标是预测任意一天穿过布鲁克林大桥的骑自行车的人数。</p></div><div class="ab cl ky kz hx la" role="separator"><span class="lb bw bk lc ld le"/><span class="lb bw bk lc ld le"/><span class="lb bw bk lc ld"/></div><div class="im in io ip iq"><h2 id="0c45" class="mp mq jj bd mr ms mt dn mu mv mw dp mx lo my mz na ls nb nc nd lw ne nf ng nh bi translated">我们的回归策略</h2><p id="80fa" class="pw-post-body-paragraph lf lg jj lh b li ni kk lk ll nj kn ln lo nk lq lr ls nl lu lv lw nm ly lz ma im bi translated">给定某一天的一组回归变量的值，我们将使用 NB 模型来预测那天布鲁克林大桥上骑自行车的人数。</p><p id="281f" class="pw-post-body-paragraph lf lg jj lh b li lj kk lk ll lm kn ln lo lp lq lr ls lt lu lv lw lx ly lz ma im bi translated">我们需要详细说明这个策略，所以让我们更深入地挖掘。让我们从定义一些变量开始:</p><p id="4dd5" class="pw-post-body-paragraph lf lg jj lh b li lj kk lk ll lm kn ln lo lp lq lr ls lt lu lv lw lx ly lz ma im bi translated"><strong class="lh jk"> <em class="nu"> y </em> </strong> <em class="nu"> = </em>在第<em class="nu"> 1 </em>到第<em class="nu"> n </em>天看到的<strong class="lh jk">骑车人计数的矢量</strong>。<br/>从而<strong class="lh jk"><em class="nu">y =</em></strong><em class="nu">【y _ 1，y_2，y_3，…，y_n】。<br/> y_i </em>是第<em class="nu"> i. </em>日骑自行车的人数</p><p id="7211" class="pw-post-body-paragraph lf lg jj lh b li lj kk lk ll lm kn ln lo lp lq lr ls lt lu lv lw lx ly lz ma im bi translated"><strong class="lh jk"> <em class="nu"> X </em> </strong> =预测值矩阵<strong class="lh jk">预测值矩阵</strong>又名<strong class="lh jk">回归变量矩阵</strong>又名<strong class="lh jk">解释变量矩阵</strong>又名<strong class="lh jk">回归变量矩阵</strong>。矩阵<strong class="lh jk"> <em class="nu"> X </em> </strong>的大小是一个<em class="nu">(n×m)</em>，因为在数据集中有<em class="nu"> n 个</em>独立的观察值(行)，并且每一行包含<em class="nu"> m 个</em>解释变量的值。</p><p id="4e29" class="pw-post-body-paragraph lf lg jj lh b li lj kk lk ll lm kn ln lo lp lq lr ls lt lu lv lw lx ly lz ma im bi translated"><strong class="lh jk"> λ </strong> =事件率的向量。向量<strong class="lh jk"> λ </strong>是基于计数的数据集的主要特征。<strong class="lh jk"> λ </strong>是一个大小为(n×1)的向量。它包含计数向量<strong class="lh jk"><em class="nu">【y</em></strong><em class="nu">中的<em class="nu"> n </em>个观测计数对应的<em class="nu"> n </em>个速率<em class="nu">【λ_ 0，λ_1，λ_2，…，λ_ n】</em><strong class="lh jk">，</strong>。</em>假设观测值<em class="nu">‘I’</em>的速率<em class="nu"> λ_i </em>驱动计数向量<strong class="lh jk"> <em class="nu"> y </em> </strong>中的实际观测计数<em class="nu"> y_i </em>。输入数据中不存在<strong class="lh jk"> <em class="nu"> λ </em> </strong>列。相反，<strong class="lh jk"> <em class="nu"> λ </em> </strong>向量是由回归模型在训练阶段计算的推导变量。</p><p id="6e70" class="pw-post-body-paragraph lf lg jj lh b li lj kk lk ll lm kn ln lo lp lq lr ls lt lu lv lw lx ly lz ma im bi translated">对于骑自行车者计数数据，每一个<em class="nu">λI</em>值被定义为在<em class="nu"> i </em>日的“单位”时间内骑自行车者过桥的人数。单位时间可以是 1 秒、1 小时、1 天、1 周——我们想要测量速率的任何单位时间间隔。假设该速率<em class="nu"> λ_i </em>驱动第<em class="nu"> i </em>天观察到的骑自行车者数量<em class="nu"> y_i </em>。</p><p id="f0a6" class="pw-post-body-paragraph lf lg jj lh b li lj kk lk ll lm kn ln lo lp lq lr ls lt lu lv lw lx ly lz ma im bi translated">下图说明了我们的自行车计数数据集子集上的这些定义:</p><figure class="no np nq nr gt iv gh gi paragraph-image"><div class="gh gi nw"><img src="../Images/d5c6d29fcfebd8ff548cbc5cc1f258a4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1150/format:webp/0*le6zWXHZxsQagwiM.png"/></div><figcaption class="jc jd gj gh gi je jf bd b be z dk">The regression variables matrix <strong class="bd nx">X</strong> and the vector of observed bicyclist counts <strong class="bd nx">y</strong> (Image by <a class="ae jg" href="https://sachin-date.medium.com/" rel="noopener">Author</a>)</figcaption></figure><blockquote class="ny"><p id="42fb" class="nz oa jj bd ob oc od oe of og oh ma dk translated">负二项式回归模型的训练算法将使观察计数 y <strong class="ak"> </strong>与回归矩阵 X <strong class="ak">拟合。</strong></p></blockquote><p id="fcfe" class="pw-post-body-paragraph lf lg jj lh b li oi kk lk ll oj kn ln lo ok lq lr ls ol lu lv lw om ly lz ma im bi translated">一旦模型被训练，我们将在一个模型在训练期间根本没有见过的持续测试数据集上测试它的性能。</p><p id="ff6d" class="pw-post-body-paragraph lf lg jj lh b li lj kk lk ll lm kn ln lo lp lq lr ls lt lu lv lw lx ly lz ma im bi translated">回想一下，负二项式回归模型并不像<a class="ae jg" rel="noopener" target="_blank" href="/an-illustrated-guide-to-the-poisson-regression-model-50cccba15958">泊松回归模型</a>那样做出<strong class="lh jk"> <em class="nu">方差=均值</em> </strong>的假设。</p><p id="a019" class="pw-post-body-paragraph lf lg jj lh b li lj kk lk ll lm kn ln lo lp lq lr ls lt lu lv lw lx ly lz ma im bi translated">相反，NB 模型要求我们定义一个新的参数<em class="nu"> α </em>，它用这个参数来表示均值的方差，如下所示<em class="nu"> : </em></p><figure class="no np nq nr gt iv gh gi paragraph-image"><div class="gh gi on"><img src="../Images/ec21750ebabb58f7b3aedaeb12db501d.png" data-original-src="https://miro.medium.com/v2/resize:fit:876/format:webp/1*Euxgqf9GsKYNQymurPx3fw.png"/></div><figcaption class="jc jd gj gh gi je jf bd b be z dk">The NB model’s variance function (Image by <a class="ae jg" href="https://sachin-date.medium.com/" rel="noopener">Author</a>)</figcaption></figure><p id="e8b5" class="pw-post-body-paragraph lf lg jj lh b li lj kk lk ll lm kn ln lo lp lq lr ls lt lu lv lw lx ly lz ma im bi translated">实际上，这个等式有两种常见的形式:</p><p id="316a" class="pw-post-body-paragraph lf lg jj lh b li lj kk lk ll lm kn ln lo lp lq lr ls lt lu lv lw lx ly lz ma im bi translated"><strong class="lh jk">当 p = 1 时:</strong></p><figure class="no np nq nr gt iv gh gi paragraph-image"><div class="gh gi oo"><img src="../Images/6f77728a2f0d04c0c106af0447a53018.png" data-original-src="https://miro.medium.com/v2/resize:fit:836/format:webp/1*m8Hh0cF_m8gt5VK5m8KrwA.png"/></div><figcaption class="jc jd gj gh gi je jf bd b be z dk">The NB1 model’s variance function (Image by <a class="ae jg" href="https://sachin-date.medium.com/" rel="noopener">Author</a>)</figcaption></figure><p id="d13a" class="pw-post-body-paragraph lf lg jj lh b li lj kk lk ll lm kn ln lo lp lq lr ls lt lu lv lw lx ly lz ma im bi translated">在回归文献中，p=1 的情况被称为<strong class="lh jk"> NB1 模型</strong>。参见<a class="ae jg" href="https://onlinelibrary.wiley.com/doi/abs/10.1002/jae.3950010104" rel="noopener ugc nofollow" target="_blank"> <em class="nu"> Cameron，A.C .和 P.K. Trivedi (1986)，“基于计数数据的经济计量模型:一些估计量的比较和应用</em> </a></p><p id="6e79" class="pw-post-body-paragraph lf lg jj lh b li lj kk lk ll lm kn ln lo lp lq lr ls lt lu lv lw lx ly lz ma im bi translated"><strong class="lh jk">当 p=2 时:</strong></p><figure class="no np nq nr gt iv gh gi paragraph-image"><div class="gh gi op"><img src="../Images/5c09a8ef36098984e9f91433b7cf0de7.png" data-original-src="https://miro.medium.com/v2/resize:fit:864/format:webp/1*NIqqLpTXfym3zba-7D44NA.png"/></div><figcaption class="jc jd gj gh gi je jf bd b be z dk">The NB2 model’s variance function (Image by <a class="ae jg" href="https://sachin-date.medium.com/" rel="noopener">Author</a>)</figcaption></figure><p id="2bfa" class="pw-post-body-paragraph lf lg jj lh b li lj kk lk ll lm kn ln lo lp lq lr ls lt lu lv lw lx ly lz ma im bi translated">p=2 的情况称为<strong class="lh jk"> NB2 </strong>模型。</p><p id="018d" class="pw-post-body-paragraph lf lg jj lh b li lj kk lk ll lm kn ln lo lp lq lr ls lt lu lv lw lx ly lz ma im bi translated">我们将使用 NB2 模型。</p><p id="bb5e" class="pw-post-body-paragraph lf lg jj lh b li lj kk lk ll lm kn ln lo lp lq lr ls lt lu lv lw lx ly lz ma im bi translated"><strong class="lh jk"><em class="nu">Python stats models</em></strong>库也支持 NB2 模型，作为它提供的<a class="ae jg" href="https://www.statsmodels.org/stable/glm.html" rel="noopener ugc nofollow" target="_blank">广义线性模型类</a>的一部分。</p><p id="192d" class="pw-post-body-paragraph lf lg jj lh b li lj kk lk ll lm kn ln lo lp lq lr ls lt lu lv lw lx ly lz ma im bi translated">事实上，<code class="fe oq or os ot b">statsmodels.genmod.families.family</code> <strong class="lh jk"> <em class="nu"> </em> </strong>包中有整整一个类致力于 NB2 模型:</p><pre class="no np nq nr gt ou ot ov ow aw ox bi"><span id="5ca0" class="mp mq jj ot b gy oy oz l pa pb"><strong class="ot jk"><em class="nu">class </em></strong>statsmodels.genmod.families.family.<strong class="ot jk">NegativeBinomial</strong>(<em class="nu">link=None</em>, <em class="nu">alpha=1.0</em>)</span></pre><p id="343c" class="pw-post-body-paragraph lf lg jj lh b li lj kk lk ll lm kn ln lo lp lq lr ls lt lu lv lw lx ly lz ma im bi translated">注意，这个类假定的默认值<em class="nu"> alpha=1 </em>，并不总是所有数据集的正确值。那么，我们如何为我们的自行车计数数据集确定正确的值呢？</p><h2 id="2914" class="mp mq jj bd mr ms mt dn mu mv mw dp mx lo my mz na ls nb nc nd lw ne nf ng nh bi translated">找到<em class="pc"> α </em>的正确值</h2><p id="ad6f" class="pw-post-body-paragraph lf lg jj lh b li ni kk lk ll nj kn ln lo nk lq lr ls nl lu lv lw nm ly lz ma im bi translated">卡梅伦和特里维迪先生又一次拯救了我们。在他们的书《计数数据的回归分析》中， Cameron 和 Trivedi 提出了一种聪明的方法来计算<em class="nu"> α </em>，使用了一种他们称之为<em class="nu">辅助的没有常数</em>的 OLS 回归的技术。他们推荐的回归方程<em class="nu"> </em>如下:</p><figure class="no np nq nr gt iv gh gi paragraph-image"><div class="gh gi pd"><img src="../Images/e5d1f779cd19cf68ece59b30aa77682d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1394/format:webp/1*88KV30WQFC_MUctTtSqRHQ.png"/></div><figcaption class="jc jd gj gh gi je jf bd b be z dk">Auxiliary OLS regression to find <em class="pc">α for the NB2 model </em>(Image by <a class="ae jg" href="https://sachin-date.medium.com/" rel="noopener">Author</a>)</figcaption></figure><p id="1b39" class="pw-post-body-paragraph lf lg jj lh b li lj kk lk ll lm kn ln lo lp lq lr ls lt lu lv lw lx ly lz ma im bi translated">你马上就能看出奥克斯 OLS 方程与直线回归方程的关系:<strong class="lh jk"><em class="nu">Y</em></strong><em class="nu">=</em><strong class="lh jk"><em class="nu">B _ 1</em></strong><em class="nu">*</em><strong class="lh jk"><em class="nu">X</em></strong><em class="nu">+</em><strong class="lh jk"><em class="nu">B _ 0</em></strong>。</p><p id="3bb0" class="pw-post-body-paragraph lf lg jj lh b li lj kk lk ll lm kn ln lo lp lq lr ls lt lu lv lw lx ly lz ma im bi translated">如果你很好奇，估计 NB1 模型的<em class="nu"> α </em>的公式如下:</p><figure class="no np nq nr gt iv gh gi paragraph-image"><div class="gh gi pe"><img src="../Images/19b5e00c5ea0054b6c82497e81a5733e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1036/format:webp/1*e9NDGQs71c0RKpyFK7NQ0Q.png"/></div><figcaption class="jc jd gj gh gi je jf bd b be z dk">Estimator for <em class="pc">α </em>for the NB1 model (Image by <a class="ae jg" href="https://sachin-date.medium.com/" rel="noopener">Author</a>)</figcaption></figure><p id="bc45" class="pw-post-body-paragraph lf lg jj lh b li lj kk lk ll lm kn ln lo lp lq lr ls lt lu lv lw lx ly lz ma im bi translated">在本文的其余部分，我们将使用 NB2 模型。</p><p id="e570" class="pw-post-body-paragraph lf lg jj lh b li lj kk lk ll lm kn ln lo lp lq lr ls lt lu lv lw lx ly lz ma im bi translated">一旦我们使用普通最小二乘回归技术对我们的计数数据集<em class="nu">拟合了辅助回归方程，我们就可以找到<em class="nu"> α </em>的值。我们很快就会看到如何做到这一点。</em></p><p id="528c" class="pw-post-body-paragraph lf lg jj lh b li lj kk lk ll lm kn ln lo lp lq lr ls lt lu lv lw lx ly lz ma im bi translated">但是如何找到包含在辅助 OLS 回归方程<em class="nu">中的<em class="nu"> λ_i </em>？</em></p><p id="e66d" class="pw-post-body-paragraph lf lg jj lh b li lj kk lk ll lm kn ln lo lp lq lr ls lt lu lv lw lx ly lz ma im bi translated">为了找到<em class="nu"> λ_i </em> <strong class="lh jk">，</strong>我们将<a class="ae jg" rel="noopener" target="_blank" href="/an-illustrated-guide-to-the-poisson-regression-model-50cccba15958">泊松回归模型</a>拟合到我们的数据集！实际上，这样做给了我们完整的速率向量<strong class="lh jk"><em class="nu">λ</em></strong><em class="nu">=【λ_ 1，λ_2，λ_3，…，λ_ n】</em>对应于数据集中所有<em class="nu"> n </em>个观测值。</p><p id="4a52" class="pw-post-body-paragraph lf lg jj lh b li lj kk lk ll lm kn ln lo lp lq lr ls lt lu lv lw lx ly lz ma im bi translated">我们现在已经有了 NB2 回归策略的所有要素。我们来总结一下。</p></div><div class="ab cl ky kz hx la" role="separator"><span class="lb bw bk lc ld le"/><span class="lb bw bk lc ld le"/><span class="lb bw bk lc ld"/></div><div class="im in io ip iq"><h2 id="4846" class="mp mq jj bd mr ms mt dn mu mv mw dp mx lo my mz na ls nb nc nd lw ne nf ng nh bi translated">NB2 回归策略总结</h2><ul class=""><li id="80b5" class="mb mc jj lh b li ni ll nj lo pf ls pg lw ph ma pi mh mi mj bi translated"><strong class="lh jk">第一步:</strong>对数据集拟合泊松回归模型。这将给我们拟合率的向量<strong class="lh jk"> <em class="nu"> λ。</em>T59】</strong></li><li id="091e" class="mb mc jj lh b li mk ll ml lo mm ls mn lw mo ma pi mh mi mj bi translated"><strong class="lh jk">步骤 2: </strong>在数据集上拟合辅助 OLS 回归模型。这将给出<em class="nu"> α的值。</em></li><li id="55d1" class="mb mc jj lh b li mk ll ml lo mm ls mn lw mo ma pi mh mi mj bi translated"><strong class="lh jk">第 3 步:</strong>使用第 2 步中的<em class="nu"> α </em>将 NB2 回归模型拟合到数据集。</li><li id="b117" class="mb mc jj lh b li mk ll ml lo mm ls mn lw mo ma pi mh mi mj bi translated"><strong class="lh jk">步骤 4: </strong>使用拟合的 NB2 模型对测试数据集的预期计数进行预测。</li><li id="138a" class="mb mc jj lh b li mk ll ml lo mm ls mn lw mo ma pi mh mi mj bi translated"><strong class="lh jk">第五步:</strong>测试 NB2 模型的拟合优度。</li></ul><p id="33c8" class="pw-post-body-paragraph lf lg jj lh b li lj kk lk ll lm kn ln lo lp lq lr ls lt lu lv lw lx ly lz ma im bi translated">既然我们的回归策略已经勾勒出来了，让我们使用 Python、Pandas 和 statsmodels 来实现它。</p></div><div class="ab cl ky kz hx la" role="separator"><span class="lb bw bk lc ld le"/><span class="lb bw bk lc ld le"/><span class="lb bw bk lc ld"/></div><div class="im in io ip iq"><h2 id="01fa" class="mp mq jj bd mr ms mt dn mu mv mw dp mx lo my mz na ls nb nc nd lw ne nf ng nh bi translated">如何在 Python 中进行负二项回归</h2><p id="fc02" class="pw-post-body-paragraph lf lg jj lh b li ni kk lk ll nj kn ln lo nk lq lr ls nl lu lv lw nm ly lz ma im bi translated">我们将从导入所有需要的包开始。</p><pre class="no np nq nr gt ou ot ov ow aw ox bi"><span id="1c3d" class="mp mq jj ot b gy oy oz l pa pb">import pandas as pd<br/>from patsy import dmatrices<br/>import numpy as np<br/>import statsmodels.api as sm<br/>import matplotlib.pyplot as plt</span></pre><p id="e948" class="pw-post-body-paragraph lf lg jj lh b li lj kk lk ll lm kn ln lo lp lq lr ls lt lu lv lw lx ly lz ma im bi translated">接下来，为计数数据集创建一个熊猫数据框架。</p><pre class="no np nq nr gt ou ot ov ow aw ox bi"><span id="95c9" class="mp mq jj ot b gy oy oz l pa pb">df = pd.read_csv('nyc_bb_bicyclist_counts.csv', header=0, infer_datetime_format=True, parse_dates=[0], index_col=[0])</span></pre><p id="e061" class="pw-post-body-paragraph lf lg jj lh b li lj kk lk ll lm kn ln lo lp lq lr ls lt lu lv lw lx ly lz ma im bi translated">我们将向<strong class="lh jk"> X </strong>矩阵添加一些派生的回归变量。</p><pre class="no np nq nr gt ou ot ov ow aw ox bi"><span id="5379" class="mp mq jj ot b gy oy oz l pa pb">ds = df.index.to_series()<br/>df['MONTH'] = ds.dt.month<br/>df['DAY_OF_WEEK'] = ds.dt.dayofweek<br/>df['DAY'] = ds.dt.day</span></pre><p id="f075" class="pw-post-body-paragraph lf lg jj lh b li lj kk lk ll lm kn ln lo lp lq lr ls lt lu lv lw lx ly lz ma im bi translated">我们将不使用<em class="nu">日期</em>变量作为回归变量，因为它包含一个绝对日期值，但是我们不需要做任何特殊的事情来删除<em class="nu">日期</em>，因为它已经作为熊猫数据帧的索引被使用。因此它在<strong class="lh jk"> X </strong>矩阵中对我们不可用。</p><p id="d575" class="pw-post-body-paragraph lf lg jj lh b li lj kk lk ll lm kn ln lo lp lq lr ls lt lu lv lw lx ly lz ma im bi translated">让我们创建训练和测试数据集。</p><pre class="no np nq nr gt ou ot ov ow aw ox bi"><span id="2411" class="mp mq jj ot b gy oy oz l pa pb">mask = np.random.rand(len(df)) &lt; 0.8<br/>df_train = df[mask]<br/>df_test = df[~mask]<br/>print('Training data set length='+str(len(df_train)))<br/>print('Testing data set length='+str(len(df_test)))</span></pre><p id="caef" class="pw-post-body-paragraph lf lg jj lh b li lj kk lk ll lm kn ln lo lp lq lr ls lt lu lv lw lx ly lz ma im bi translated"><strong class="lh jk">步骤 1:我们现在将在训练数据集上配置和拟合泊松回归模型。</strong></p><p id="cf7c" class="pw-post-body-paragraph lf lg jj lh b li lj kk lk ll lm kn ln lo lp lq lr ls lt lu lv lw lx ly lz ma im bi translated">在<a class="ae jg" href="https://patsy.readthedocs.io/en/latest/quickstart.html" rel="noopener ugc nofollow" target="_blank"> patsy </a>符号中设置回归表达式。我们告诉 patsy，BB_COUNT 是我们的因变量，它取决于回归变量:DAY、DAY_OF_WEEK、MONTH、HIGH_T、LOW_T 和 PRECIP。</p><pre class="no np nq nr gt ou ot ov ow aw ox bi"><span id="18c4" class="mp mq jj ot b gy oy oz l pa pb">expr = """BB_COUNT ~ DAY  + DAY_OF_WEEK + MONTH + HIGH_T + LOW_T + PRECIP"""</span></pre><p id="8907" class="pw-post-body-paragraph lf lg jj lh b li lj kk lk ll lm kn ln lo lp lq lr ls lt lu lv lw lx ly lz ma im bi translated">为训练和测试数据集设置<strong class="lh jk"> X </strong>和<strong class="lh jk"> y </strong>矩阵。patsy 让这变得非常简单。</p><pre class="no np nq nr gt ou ot ov ow aw ox bi"><span id="4d8d" class="mp mq jj ot b gy oy oz l pa pb">y_train, X_train = dmatrices(expr, df_train, return_type='dataframe')<br/>y_test, X_test = dmatrices(expr, df_test, return_type='dataframe')</span></pre><p id="e1ff" class="pw-post-body-paragraph lf lg jj lh b li lj kk lk ll lm kn ln lo lp lq lr ls lt lu lv lw lx ly lz ma im bi translated">使用<strong class="lh jk"><em class="nu">stats models GLM</em></strong>类，在训练数据集上训练泊松回归模型。</p><pre class="no np nq nr gt ou ot ov ow aw ox bi"><span id="6cf0" class="mp mq jj ot b gy oy oz l pa pb">poisson_training_results = sm.GLM(y_train, X_train, family=sm.families.Poisson()).fit()</span></pre><p id="34c6" class="pw-post-body-paragraph lf lg jj lh b li lj kk lk ll lm kn ln lo lp lq lr ls lt lu lv lw lx ly lz ma im bi translated">这就完成了泊松回归模型的训练。要查看培训的结果，您可以打印出培训总结。</p><pre class="no np nq nr gt ou ot ov ow aw ox bi"><span id="1513" class="mp mq jj ot b gy oy oz l pa pb">print(poisson_training_results.summary())</span></pre><p id="69f5" class="pw-post-body-paragraph lf lg jj lh b li lj kk lk ll lm kn ln lo lp lq lr ls lt lu lv lw lx ly lz ma im bi translated">这会打印出以下内容:</p><figure class="no np nq nr gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi pj"><img src="../Images/2c0e5de9134a8e01883729e048359f64.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*wsf0HH7sDoZjzWJiLbGHwQ.png"/></div></div><figcaption class="jc jd gj gh gi je jf bd b be z dk">Training summary for the Poisson regression model (Image by <a class="ae jg" href="https://sachin-date.medium.com/" rel="noopener">Author</a>)</figcaption></figure><p id="484e" class="pw-post-body-paragraph lf lg jj lh b li lj kk lk ll lm kn ln lo lp lq lr ls lt lu lv lw lx ly lz ma im bi translated">我们真正感兴趣的是由训练产生的拟合率向量<strong class="lh jk"><em class="nu"/></strong>。这个速率向量包含在参数泊松 _ 训练 _ 结果μ中</p><pre class="no np nq nr gt ou ot ov ow aw ox bi"><span id="82c8" class="mp mq jj ot b gy oy oz l pa pb">print(poisson_training_results.mu)<br/>print(len(poisson_training_results.mu))</span></pre><p id="2d2c" class="pw-post-body-paragraph lf lg jj lh b li lj kk lk ll lm kn ln lo lp lq lr ls lt lu lv lw lx ly lz ma im bi translated">以下输出显示了拟合的λ向量的前几个和后几个值:</p><pre class="no np nq nr gt ou ot ov ow aw ox bi"><span id="ffff" class="mp mq jj ot b gy oy oz l pa pb">[1920.39434028 2544.81549207 2651.79330653  743.45309242 1072.77132837 1892.9428398  2320.70412868 3269.73598361 3313.21764921 2915.25363322 2614.39482509 2594.44594144 2415.29471195 3181.91998369 2154.15471026 2268.25625592 1793.29625903 2535.31903414 2566.70835529 970.82159668<br/> 2510.70775659 3016.19901465 2260.265944 3365.04650316 2695.6143122...<br/>...2340.12964253 2568.40001641 2232.26752534 2604.97128321  145.92037793 2060.10442187 2518.70470296]</span></pre><p id="90f4" class="pw-post-body-paragraph lf lg jj lh b li lj kk lk ll lm kn ln lo lp lq lr ls lt lu lv lw lx ly lz ma im bi translated">这就完成了<strong class="lh jk">步骤 1: </strong>拟合泊松回归模型。</p><p id="1cff" class="pw-post-body-paragraph lf lg jj lh b li lj kk lk ll lm kn ln lo lp lq lr ls lt lu lv lw lx ly lz ma im bi translated"><strong class="lh jk">步骤 2:我们现在将在数据集上拟合辅助 OLS 回归模型，并使用拟合的模型来获得<em class="nu"> α的值。</em> </strong></p><p id="8513" class="pw-post-body-paragraph lf lg jj lh b li lj kk lk ll lm kn ln lo lp lq lr ls lt lu lv lw lx ly lz ma im bi translated">导入<em class="nu"> api </em>包。</p><pre class="no np nq nr gt ou ot ov ow aw ox bi"><span id="662a" class="mp mq jj ot b gy oy oz l pa pb">import statsmodels.formula.api as smf</span></pre><p id="c8dc" class="pw-post-body-paragraph lf lg jj lh b li lj kk lk ll lm kn ln lo lp lq lr ls lt lu lv lw lx ly lz ma im bi translated">将<strong class="lh jk"> <em class="nu"> λ </em> </strong>向量作为名为‘BB _ LAMBDA’的新列添加到训练数据集的数据帧中。回想一下<strong class="lh jk"><em class="nu">λ’</em></strong>s 的维数是(n×1)。在我们的例子中，它将是(161 x 1)。还记得<strong class="lh jk"> <em class="nu"> λ </em> </strong>向量在<code class="fe oq or os ot b">poisson_training_results.mu</code>中可用:</p><pre class="no np nq nr gt ou ot ov ow aw ox bi"><span id="a308" class="mp mq jj ot b gy oy oz l pa pb">df_train['BB_LAMBDA'] = poisson_training_results.mu</span></pre><p id="0290" class="pw-post-body-paragraph lf lg jj lh b li lj kk lk ll lm kn ln lo lp lq lr ls lt lu lv lw lx ly lz ma im bi translated">接下来，让我们向熊猫数据框添加一个名为“奥克斯 _OLS_DEP”的派生列。这个新列将存储 OLS 回归的因变量<strong class="lh jk">的值。它是下面 OLS 回归方程的左侧:</strong></p><figure class="no np nq nr gt iv gh gi paragraph-image"><div class="gh gi pd"><img src="../Images/e5d1f779cd19cf68ece59b30aa77682d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1394/format:webp/1*88KV30WQFC_MUctTtSqRHQ.png"/></div><figcaption class="jc jd gj gh gi je jf bd b be z dk">Auxiliary OLS regression to find <em class="pc">α for the NB2 model </em>(Image by <a class="ae jg" href="https://sachin-date.medium.com/" rel="noopener">Author</a>)</figcaption></figure><pre class="no np nq nr gt ou ot ov ow aw ox bi"><span id="86be" class="mp mq jj ot b gy oy oz l pa pb">df_train['AUX_OLS_DEP'] = df_train.apply(lambda x: ((<strong class="ot jk">x['BB_COUNT'] - x['BB_LAMBDA'])**2 - x['BB_LAMBDA']) / x['BB_LAMBDA']</strong>, axis=1)</span></pre><p id="1d96" class="pw-post-body-paragraph lf lg jj lh b li lj kk lk ll lm kn ln lo lp lq lr ls lt lu lv lw lx ly lz ma im bi translated">在上面的代码片段中，粗体部分是上面的辅助 OLSR 方程的左侧。</p><p id="64c5" class="pw-post-body-paragraph lf lg jj lh b li lj kk lk ll lm kn ln lo lp lq lr ls lt lu lv lw lx ly lz ma im bi translated">让我们使用 patsy 来形成 OLSR 的模型规范。我们想告诉 patsy，AUX_OLS_DEP 是因变量，用 BB_LAMBDA 来解释(它是速率向量<strong class="lh jk"> <em class="nu"> λ </em> </strong>)。表达式末尾的'-1 '是 patsy 语法，表示:不要使用回归的截距；即就像卡梅伦和特里维迪先生建议的那样，拟合一条穿过原点的直线。</p><pre class="no np nq nr gt ou ot ov ow aw ox bi"><span id="9377" class="mp mq jj ot b gy oy oz l pa pb">ols_expr = """AUX_OLS_DEP ~ BB_LAMBDA - 1"""</span></pre><p id="12b1" class="pw-post-body-paragraph lf lg jj lh b li lj kk lk ll lm kn ln lo lp lq lr ls lt lu lv lw lx ly lz ma im bi translated">我们现在准备好安装一个 OLSR 模型。</p><p id="5940" class="pw-post-body-paragraph lf lg jj lh b li lj kk lk ll lm kn ln lo lp lq lr ls lt lu lv lw lx ly lz ma im bi translated">配置并适应 OLSR 模型:</p><pre class="no np nq nr gt ou ot ov ow aw ox bi"><span id="8b59" class="mp mq jj ot b gy oy oz l pa pb">aux_olsr_results = smf.ols(ols_expr, df_train).fit()</span></pre><p id="4d06" class="pw-post-body-paragraph lf lg jj lh b li lj kk lk ll lm kn ln lo lp lq lr ls lt lu lv lw lx ly lz ma im bi translated">打印回归参数:</p><pre class="no np nq nr gt ou ot ov ow aw ox bi"><span id="b534" class="mp mq jj ot b gy oy oz l pa pb">print(aux_olsr_results.params)</span></pre><p id="add9" class="pw-post-body-paragraph lf lg jj lh b li lj kk lk ll lm kn ln lo lp lq lr ls lt lu lv lw lx ly lz ma im bi translated">您将看到下面的单个系数被打印出来，对应于单个回归变量 BB_LAMBDA。这个系数就是我们正在寻找的<em class="nu"> α </em>:</p><pre class="no np nq nr gt ou ot ov ow aw ox bi"><span id="1c2f" class="mp mq jj ot b gy oy oz l pa pb">BB_LAMBDA    0.037343</span></pre><h2 id="ebeb" class="mp mq jj bd mr ms mt dn mu mv mw dp mx lo my mz na ls nb nc nd lw ne nf ng nh bi translated"><em class="pc"> α </em>有统计学意义吗？</h2><p id="cd14" class="pw-post-body-paragraph lf lg jj lh b li ni kk lk ll nj kn ln lo nk lq lr ls nl lu lv lw nm ly lz ma im bi translated">我们现在需要回答一个非常重要的问题。<em class="nu"> α的这个值(</em> 0.037343 <em class="nu"> ) </em>有统计学意义吗？或者可以认为在所有实际用途中为零吗？</p><p id="7340" class="pw-post-body-paragraph lf lg jj lh b li lj kk lk ll lm kn ln lo lp lq lr ls lt lu lv lw lx ly lz ma im bi translated">为什么找出这一点如此重要？回想一下，如果<em class="nu"> α </em>为零，那么下面的等式:</p><figure class="no np nq nr gt iv gh gi paragraph-image"><div class="gh gi op"><img src="../Images/5c09a8ef36098984e9f91433b7cf0de7.png" data-original-src="https://miro.medium.com/v2/resize:fit:864/format:webp/1*NIqqLpTXfym3zba-7D44NA.png"/></div><figcaption class="jc jd gj gh gi je jf bd b be z dk">The NB2 model’s variance function (Image by <a class="ae jg" href="https://sachin-date.medium.com/" rel="noopener">Author</a>)</figcaption></figure><p id="4ad1" class="pw-post-body-paragraph lf lg jj lh b li lj kk lk ll lm kn ln lo lp lq lr ls lt lu lv lw lx ly lz ma im bi translated">…减少到<strong class="lh jk"> <em class="nu">方差=平均值</em> </strong> <em class="nu">。</em>这是泊松回归模型的方差函数。</p><blockquote class="ny"><p id="6b09" class="nz oa jj bd ob oc pk pl pm pn po ma dk translated">如果α的值在统计上不显著，则负二项式回归模型不能比泊松回归模型更好地拟合训练数据集。</p></blockquote><p id="f95f" class="pw-post-body-paragraph lf lg jj lh b li oi kk lk ll oj kn ln lo ok lq lr ls ol lu lv lw om ly lz ma im bi translated"><em class="nu"> OLSResults </em>对象包含回归系数<em class="nu"> α的 t 分数。</em>让我们把它打印出来:</p><pre class="no np nq nr gt ou ot ov ow aw ox bi"><span id="6aa0" class="mp mq jj ot b gy oy oz l pa pb">aux_olsr_results.tvalues</span></pre><p id="2916" class="pw-post-body-paragraph lf lg jj lh b li lj kk lk ll lm kn ln lo lp lq lr ls lt lu lv lw lx ly lz ma im bi translated">这将打印出:</p><pre class="no np nq nr gt ou ot ov ow aw ox bi"><span id="fb42" class="mp mq jj ot b gy oy oz l pa pb">BB_LAMBDA    4.814096</span></pre><p id="5821" class="pw-post-body-paragraph lf lg jj lh b li lj kk lk ll lm kn ln lo lp lq lr ls lt lu lv lw lx ly lz ma im bi translated">从一个<a class="ae jg" href="https://goodcalculators.com/student-t-value-calculator/" rel="noopener ugc nofollow" target="_blank"> t 值计算器</a>可以看出，在 99%置信水平下的临界 t 值(右尾)，自由度=(161 个观测值)——(1 个离散参数α)=160 为<strong class="lh jk"> 2.34988 </strong>。这远远小于 t 统计量<em class="nu"> α </em>的 4.814096 <strong class="lh jk">。我们的结论是，</strong></p><blockquote class="ny"><p id="8176" class="nz oa jj bd ob oc pk pl pm pn po ma dk translated"><em class="pc"> α= </em> 0.037343 <em class="pc"> </em>有统计学意义。</p></blockquote><p id="b443" class="pw-post-body-paragraph lf lg jj lh b li oi kk lk ll oj kn ln lo ok lq lr ls ol lu lv lw om ly lz ma im bi translated">这就完成了<strong class="lh jk">步骤 2: </strong>确定<em class="nu"> α。</em></p><p id="92c6" class="pw-post-body-paragraph lf lg jj lh b li lj kk lk ll lm kn ln lo lp lq lr ls lt lu lv lw lx ly lz ma im bi translated"><strong class="lh jk">步骤 3:我们将步骤 2 中找到的 alpha 的值提供给</strong> <code class="fe oq or os ot b">statsmodels.genmod.families.family.<strong class="lh jk">NegativeBinomial</strong></code> <strong class="lh jk">类，并在训练数据集上训练 NB2 模型。</strong></p><p id="b1c6" class="pw-post-body-paragraph lf lg jj lh b li lj kk lk ll lm kn ln lo lp lq lr ls lt lu lv lw lx ly lz ma im bi translated">这是 statsmodels 中的一步操作:</p><pre class="no np nq nr gt ou ot ov ow aw ox bi"><span id="b01f" class="mp mq jj ot b gy oy oz l pa pb">nb2_training_results = sm.GLM(y_train, X_train,family=sm.families.NegativeBinomial(alpha=aux_olsr_results.params[0])).fit()</span></pre><p id="fe11" class="pw-post-body-paragraph lf lg jj lh b li lj kk lk ll lm kn ln lo lp lq lr ls lt lu lv lw lx ly lz ma im bi translated">和以前一样，我们将打印培训总结:</p><pre class="no np nq nr gt ou ot ov ow aw ox bi"><span id="9eb2" class="mp mq jj ot b gy oy oz l pa pb">print(nb2_training_results.summary())</span></pre><p id="377f" class="pw-post-body-paragraph lf lg jj lh b li lj kk lk ll lm kn ln lo lp lq lr ls lt lu lv lw lx ly lz ma im bi translated">它打印以下摘要:</p><figure class="no np nq nr gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi pp"><img src="../Images/d4f3db95a9c9e50a6793899222a061a7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*7uhPWF0wSvFyGwSCiH1Q2A.png"/></div></div><figcaption class="jc jd gj gh gi je jf bd b be z dk">NB2 model’s training summary (Image by <a class="ae jg" href="https://sachin-date.medium.com/" rel="noopener">Author</a>)</figcaption></figure><p id="dc62" class="pw-post-body-paragraph lf lg jj lh b li lj kk lk ll lm kn ln lo lp lq lr ls lt lu lv lw lx ly lz ma im bi translated">第四步:让我们用训练好的 NB2 模型做一些预测。</p><p id="2534" class="pw-post-body-paragraph lf lg jj lh b li lj kk lk ll lm kn ln lo lp lq lr ls lt lu lv lw lx ly lz ma im bi translated">在 stats 模型中，预测也是一个单步程序:</p><pre class="no np nq nr gt ou ot ov ow aw ox bi"><span id="da41" class="mp mq jj ot b gy oy oz l pa pb">nb2_predictions = nb2_training_results.get_prediction(X_test)</span></pre><p id="5a6a" class="pw-post-body-paragraph lf lg jj lh b li lj kk lk ll lm kn ln lo lp lq lr ls lt lu lv lw lx ly lz ma im bi translated">让我们把预测打印出来:</p><pre class="no np nq nr gt ou ot ov ow aw ox bi"><span id="b120" class="mp mq jj ot b gy oy oz l pa pb">predictions_summary_frame = nb2_predictions.summary_frame()<br/>print(predictions_summary_frame)</span></pre><p id="0050" class="pw-post-body-paragraph lf lg jj lh b li lj kk lk ll lm kn ln lo lp lq lr ls lt lu lv lw lx ly lz ma im bi translated">以下是输出的前几行:</p><figure class="no np nq nr gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi pq"><img src="../Images/67c79ffd7ca32fb45d1bef5419b3532f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*YbSScTAIol_d5F4cPAQbWw.png"/></div></div><figcaption class="jc jd gj gh gi je jf bd b be z dk">First few rows of output from <strong class="bd nx">nb2_predictions.summary_frame() </strong>(Image by <a class="ae jg" href="https://sachin-date.medium.com/" rel="noopener">Author</a>)</figcaption></figure><p id="5e0c" class="pw-post-body-paragraph lf lg jj lh b li lj kk lk ll lm kn ln lo lp lq lr ls lt lu lv lw lx ly lz ma im bi translated">让我们也画出测试数据的预测计数和实际计数。</p><pre class="no np nq nr gt ou ot ov ow aw ox bi"><span id="f391" class="mp mq jj ot b gy oy oz l pa pb">predicted_counts=predictions_summary_frame['mean']</span><span id="e81f" class="mp mq jj ot b gy pr oz l pa pb">actual_counts = y_test['BB_COUNT']</span><span id="8033" class="mp mq jj ot b gy pr oz l pa pb">fig = plt.figure()</span><span id="fd9f" class="mp mq jj ot b gy pr oz l pa pb">fig.suptitle('Predicted versus actual bicyclist counts on the Brooklyn bridge')</span><span id="aa41" class="mp mq jj ot b gy pr oz l pa pb">predicted, = plt.plot(X_test.index, predicted_counts, 'go-', label='Predicted counts')</span><span id="43a3" class="mp mq jj ot b gy pr oz l pa pb">actual, = plt.plot(X_test.index, actual_counts, 'ro-', label='Actual counts')</span><span id="6e7b" class="mp mq jj ot b gy pr oz l pa pb">plt.legend(handles=[predicted, actual])</span><span id="ee67" class="mp mq jj ot b gy pr oz l pa pb">plt.show()</span></pre><p id="f3b6" class="pw-post-body-paragraph lf lg jj lh b li lj kk lk ll lm kn ln lo lp lq lr ls lt lu lv lw lx ly lz ma im bi translated">以下是输出结果:</p><figure class="no np nq nr gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi ps"><img src="../Images/4f49a0bd81c3b0ab160b8c946994fd83.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*rQHVkOccSH-I2XwQAe68VA.png"/></div></div><figcaption class="jc jd gj gh gi je jf bd b be z dk">Predicted versus actual bicyclist counts on the Brooklyn bridge using the NB2 model</figcaption></figure><p id="c0ec" class="pw-post-body-paragraph lf lg jj lh b li lj kk lk ll lm kn ln lo lp lq lr ls lt lu lv lw lx ly lz ma im bi translated">不算太差！NB2 模型似乎或多或少地跟踪了自行车数量的趋势。正如<a class="ae jg" rel="noopener" target="_blank" href="/an-illustrated-guide-to-the-poisson-regression-model-50cccba15958">泊松回归模型的表现</a>，在某些情况下，它的预测与实际值相差甚远。</p><p id="48b3" class="pw-post-body-paragraph lf lg jj lh b li lj kk lk ll lm kn ln lo lp lq lr ls lt lu lv lw lx ly lz ma im bi translated">以下是用于训练负二项式回归模型并测试其预测的完整 Python 源代码:</p><figure class="no np nq nr gt iv"><div class="bz fp l di"><div class="pt pu l"/></div></figure><p id="beff" class="pw-post-body-paragraph lf lg jj lh b li lj kk lk ll lm kn ln lo lp lq lr ls lt lu lv lw lx ly lz ma im bi translated">我们面临的最后一个问题是:</p><p id="c221" class="pw-post-body-paragraph lf lg jj lh b li lj kk lk ll lm kn ln lo lp lq lr ls lt lu lv lw lx ly lz ma im bi translated"><strong class="lh jk">从统计上看，我们的 NB2 回归模型比泊松回归模型做得更好吗？</strong></p><p id="6ccd" class="pw-post-body-paragraph lf lg jj lh b li lj kk lk ll lm kn ln lo lp lq lr ls lt lu lv lw lx ly lz ma im bi translated">让我们找出答案。</p></div><div class="ab cl ky kz hx la" role="separator"><span class="lb bw bk lc ld le"/><span class="lb bw bk lc ld le"/><span class="lb bw bk lc ld"/></div><div class="im in io ip iq"><h2 id="b0ab" class="mp mq jj bd mr ms mt dn mu mv mw dp mx lo my mz na ls nb nc nd lw ne nf ng nh bi translated">步骤 5:测量 NB2 模型的拟合优度</h2><p id="ab60" class="pw-post-body-paragraph lf lg jj lh b li ni kk lk ll nj kn ln lo nk lq lr ls nl lu lv lw nm ly lz ma im bi translated">从拟合优度的角度来看，在 NB2 模型的训练总结中有三件有趣的事情。它们在下图中用红框标出。我们将从对数似然性开始研究每一种方法。</p><figure class="no np nq nr gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi pv"><img src="../Images/65aaaeeddb2f013b5e1154f6e0fdda58.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*SVvu6jB-j9rDOmWcDLeHAg.png"/></div></div><figcaption class="jc jd gj gh gi je jf bd b be z dk">NB2 model’s training summary (Image by <a class="ae jg" href="https://sachin-date.medium.com/" rel="noopener">Author</a>)</figcaption></figure><p id="4363" class="pw-post-body-paragraph lf lg jj lh b li lj kk lk ll lm kn ln lo lp lq lr ls lt lu lv lw lx ly lz ma im bi translated">让我们首先比较 NB2 模型和泊松回归模型在相同数据集上的训练摘要:</p><figure class="no np nq nr gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi pw"><img src="../Images/aafee92ab1cd6faf18610d9f4ffce45f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*AC4wPGPzPZPiogJrJ3U26g.png"/></div></div><figcaption class="jc jd gj gh gi je jf bd b be z dk">(Image by <a class="ae jg" href="https://sachin-date.medium.com/" rel="noopener">Author</a>)</figcaption></figure><p id="7e49" class="pw-post-body-paragraph lf lg jj lh b li lj kk lk ll lm kn ln lo lp lq lr ls lt lu lv lw lx ly lz ma im bi translated">首先要看的统计数据是<strong class="lh jk">对数似然</strong>值。最大对数似然是通过<strong class="lh jk">最大似然估计(MLE </strong>)技术生成的，该技术由 statsmodels 在泊松和 NB2 模型训练期间执行。MLE 技术用于将所有模型系数的值固定为一些最佳值，这些最佳值将最大化在训练数据集中看到计数向量<strong class="lh jk"> <em class="nu"> y </em> </strong>的可能性。要了解更多关于 MLE 及其如何用于模型训练的信息，请参考我关于<a class="ae jg" rel="noopener" target="_blank" href="/an-illustrated-guide-to-the-poisson-regression-model-50cccba15958">泊松回归模型</a>的文章。</p><h2 id="ae96" class="mp mq jj bd mr ms mt dn mu mv mw dp mx lo my mz na ls nb nc nd lw ne nf ng nh bi translated">似然比检验</h2><p id="e715" class="pw-post-body-paragraph lf lg jj lh b li ni kk lk ll nj kn ln lo nk lq lr ls nl lu lv lw nm ly lz ma im bi translated"><a class="ae jg" href="https://en.wikipedia.org/wiki/Likelihood-ratio_test" rel="noopener ugc nofollow" target="_blank">似然比</a>测试用于比较两个模型对数据的拟合程度。</p><p id="176b" class="pw-post-body-paragraph lf lg jj lh b li lj kk lk ll lm kn ln lo lp lq lr ls lt lu lv lw lx ly lz ma im bi translated">LR 检验统计量是两个模型拟合对数似然性差异的两倍。</p><p id="d96d" class="pw-post-body-paragraph lf lg jj lh b li lj kk lk ll lm kn ln lo lp lq lr ls lt lu lv lw lx ly lz ma im bi translated">在我们的例子中，NB2 的对数似然是-1383.2，而泊松回归模型是-12616。所以 LR 检验统计量是 2 *(12616–1383.2)= 22465.6。在 1%的显著性水平上，该值远大于<a class="ae jg" href="https://www.medcalc.org/manual/chi-square-table.php" rel="noopener ugc nofollow" target="_blank"> χ2(1) </a>的临界值 5.412。</p><blockquote class="px py pz"><p id="10b5" class="lf lg nu lh b li lj kk lk ll lm kn ln qa lp lq lr qb lt lu lv qc lx ly lz ma im bi translated">根据 LR 测试，与泊松回归模型相比，经过训练的 NB2 回归模型在自行车运动员数据集上表现出更好的拟合优度。</p></blockquote><p id="61b2" class="pw-post-body-paragraph lf lg jj lh b li lj kk lk ll lm kn ln lo lp lq lr ls lt lu lv lw lx ly lz ma im bi translated">现在让我们比较一下 NB2 回归模型的绝对拟合优度。</p><h2 id="8f57" class="mp mq jj bd mr ms mt dn mu mv mw dp mx lo my mz na ls nb nc nd lw ne nf ng nh bi translated">偏差和皮尔逊卡方统计</h2><p id="de25" class="pw-post-body-paragraph lf lg jj lh b li ni kk lk ll nj kn ln lo nk lq lr ls nl lu lv lw nm ly lz ma im bi translated">NB2 模型的偏差和皮尔逊卡方的报告值分别为 330.99 和 310。为了在某个置信水平(比如 95% (p=0.05))下定量确定拟合优度，我们在<em class="nu"> χ2 </em>表中查找 p=0.05 和残差自由度=165 的值。我们将该卡方值与观察到的统计值进行比较，在这种情况下，它是 GLMResults 中报告的偏差或皮尔逊卡方值。我们发现，在 p=0.05 且 DF 残差= 165 时，来自<a class="ae jg" href="https://www.medcalc.org/manual/chi-square-table.php" rel="noopener ugc nofollow" target="_blank">标准卡方表</a>的卡方值为 195.973，小于报告的统计值 330.99 和 310。因此，根据该测试，尽管 NB2 回归模型显示出比泊松回归模型更好的拟合，但仍然是次优的。我们<em class="nu">也许</em>能够做得更好。</p></div><div class="ab cl ky kz hx la" role="separator"><span class="lb bw bk lc ld le"/><span class="lb bw bk lc ld le"/><span class="lb bw bk lc ld"/></div><div class="im in io ip iq"><h1 id="a1da" class="qd mq jj bd mr qe qf qg mu qh qi qj mx kp qk kq na ks ql kt nd kv qm kw ng qn bi translated">结论和下一步措施</h1><p id="b848" class="pw-post-body-paragraph lf lg jj lh b li ni kk lk ll nj kn ln lo nk lq lr ls nl lu lv lw nm ly lz ma im bi translated">泊松和负二项式回归模型用于对基于计数的数据集进行建模。这两种模型产生的结果是:</p><ul class=""><li id="d400" class="mb mc jj lh b li lj ll lm lo md ls me lw mf ma pi mh mi mj bi translated">可解释的</li><li id="622c" class="mb mc jj lh b li mk ll ml lo mm ls mn lw mo ma pi mh mi mj bi translated">可比较的</li><li id="5391" class="mb mc jj lh b li mk ll ml lo mm ls mn lw mo ma pi mh mi mj bi translated">可辩护的</li><li id="e1e8" class="mb mc jj lh b li mk ll ml lo mm ls mn lw mo ma pi mh mi mj bi translated">可用的</li></ul><p id="3529" class="pw-post-body-paragraph lf lg jj lh b li lj kk lk ll lm kn ln lo lp lq lr ls lt lu lv lw lx ly lz ma im bi translated">这两个模型都有强大且被充分理解的统计理论支持。</p><p id="4179" class="pw-post-body-paragraph lf lg jj lh b li lj kk lk ll lm kn ln lo lp lq lr ls lt lu lv lw lx ly lz ma im bi translated">对于基于计数的数据集进行回归，一个好的策略是从<a class="ae jg" rel="noopener" target="_blank" href="/an-illustrated-guide-to-the-poisson-regression-model-50cccba15958">泊松回归模型</a>开始，然后看看是否可以通过使用负二项式回归模型获得更好的结果。</p><p id="a897" class="pw-post-body-paragraph lf lg jj lh b li lj kk lk ll lm kn ln lo lp lq lr ls lt lu lv lw lx ly lz ma im bi translated">如果 Poisson 和 NB2 都不适合您的数据集，请考虑使用更高级的技术，例如:</p><ol class=""><li id="2cad" class="mb mc jj lh b li lj ll lm lo md ls me lw mf ma mg mh mi mj bi translated">泊松回归模型的复杂变体，如<a class="ae jg" href="https://en.wikipedia.org/wiki/Zero-inflated_model" rel="noopener ugc nofollow" target="_blank">零膨胀模型</a>。</li><li id="2625" class="mb mc jj lh b li mk ll ml lo mm ls mn lw mo ma mg mh mi mj bi translated"><a class="ae jg" href="https://data.library.virginia.edu/getting-started-with-hurdle-models/" rel="noopener ugc nofollow" target="_blank">跨栏模型</a></li><li id="038f" class="mb mc jj lh b li mk ll ml lo mm ls mn lw mo ma mg mh mi mj bi translated">一个<a class="ae jg" href="https://en.wikipedia.org/wiki/Random_forest" rel="noopener ugc nofollow" target="_blank">基于随机森林的回归模型</a></li><li id="1d7b" class="mb mc jj lh b li mk ll ml lo mm ls mn lw mo ma mg mh mi mj bi translated">一个基于<a class="ae jg" href="https://en.wikipedia.org/wiki/Long_short-term_memory" rel="noopener ugc nofollow" target="_blank">长短期记忆(LSTM) </a>神经网络的回归模型</li></ol></div><div class="ab cl ky kz hx la" role="separator"><span class="lb bw bk lc ld le"/><span class="lb bw bk lc ld le"/><span class="lb bw bk lc ld"/></div><div class="im in io ip iq"><h2 id="34dc" class="mp mq jj bd mr ms mt dn mu mv mw dp mx lo my mz na ls nb nc nd lw ne nf ng nh bi translated">相关阅读</h2><div class="is it gp gr iu qo"><a rel="noopener follow" target="_blank" href="/an-illustrated-guide-to-the-poisson-regression-model-50cccba15958"><div class="qp ab fo"><div class="qq ab qr cl cj qs"><h2 class="bd jk gy z fp qt fr fs qu fu fw ji bi translated">泊松回归模型图解指南</h2><div class="qv l"><h3 class="bd b gy z fp qt fr fs qu fu fw dk translated">和使用 Python 的泊松回归教程</h3></div><div class="qw l"><p class="bd b dl z fp qt fr fs qu fu fw dk translated">towardsdatascience.com</p></div></div><div class="qx l"><div class="qy l qz ra rb qx rc ja qo"/></div></div></a></div></div><div class="ab cl ky kz hx la" role="separator"><span class="lb bw bk lc ld le"/><span class="lb bw bk lc ld le"/><span class="lb bw bk lc ld"/></div><div class="im in io ip iq"><p id="a315" class="pw-post-body-paragraph lf lg jj lh b li lj kk lk ll lm kn ln lo lp lq lr ls lt lu lv lw lx ly lz ma im bi translated"><em class="nu">感谢阅读！如果你喜欢这篇文章，请在</em><a class="ae jg" href="https://timeseriesreasoning.medium.com" rel="noopener"><strong class="lh jk"><em class="nu">Sachin Date</em></strong></a><em class="nu">关注我，以获得关于回归、时间序列分析和预测主题的提示、操作方法和编程建议。</em></p></div></div>    
</body>
</html>