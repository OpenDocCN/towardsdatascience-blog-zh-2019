<html>
<head>
<title>11 Evaluation Metrics Data Scientists Should Be Familiar with— Lessons from A High-rank Kagglers’ New Book</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">数据科学家应该熟悉的 11 个评估指标——来自高级 Kagglers 新书的教训</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/11-evaluation-metrics-data-scientists-should-be-familiar-with-lessons-from-a-high-rank-kagglers-8596f75e58a7?source=collection_archive---------8-----------------------#2019-11-29">https://towardsdatascience.com/11-evaluation-metrics-data-scientists-should-be-familiar-with-lessons-from-a-high-rank-kagglers-8596f75e58a7?source=collection_archive---------8-----------------------#2019-11-29</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><h2 id="222a" class="io ip iq bd b dl ir is it iu iv iw dk ix translated" aria-label="kicker paragraph">《赢得 Kaggle 的数据分析技术》一书</h2><div class=""/><div class=""><h2 id="43ee" class="pw-subtitle-paragraph jw iz iq bd b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn dk translated">是关于损失函数的，对吗？不，不是的。</h2></div><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi ko"><img src="../Images/1f5d37d3ff7958d826dc29de8edb13c3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*Du6CkHdWdIZ9PpWx"/></div></div><figcaption class="la lb gj gh gi lc ld bd b be z dk">Photo by <a class="ae le" href="https://unsplash.com/@waguluz_?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Andreas Wagner</a> on <a class="ae le" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><p id="daa1" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">这是一本新书<em class="mb">“赢得 Kaggle 的数据分析技术”</em>中介绍的技巧，由三位高级 Kaggle 作者撰写(不包括我自己，因此这不是个人推广！:) )</p><p id="4b4a" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">这本书的完整目录见我的<a class="ae le" href="https://medium.com/@daydreamersjp/a-new-book-data-analysis-techniques-to-win-kaggle-is-a-current-best-and-complete-for-table-data-4af66a88388" rel="noopener">其他帖子</a>。</p></div><div class="ab cl mc md hu me" role="separator"><span class="mf bw bk mg mh mi"/><span class="mf bw bk mg mh mi"/><span class="mf bw bk mg mh"/></div><div class="ij ik il im in"><h1 id="67aa" class="mj mk iq bd ml mm mn mo mp mq mr ms mt kf mu kg mv ki mw kj mx kl my km mz na bi translated">目录:</h1><h2 id="5878" class="nb mk iq bd ml nc nd dn mp ne nf dp mt lo ng nh mv ls ni nj mx lw nk nl mz iw bi translated"><a class="ae le" href="#ad3e" rel="noopener ugc nofollow">评估指标与损失函数</a></h2><h2 id="a81e" class="nb mk iq bd ml nc nd dn mp ne nf dp mt lo ng nh mv ls ni nj mx lw nk nl mz iw bi translated"><a class="ae le" href="#96c6" rel="noopener ugc nofollow">回归任务中使用的评估指标</a></h2><p id="8bb8" class="pw-post-body-paragraph lf lg iq lh b li nm ka lk ll nn kd ln lo no lq lr ls np lu lv lw nq ly lz ma ij bi translated"><a class="ae le" href="#a94a" rel="noopener ugc nofollow"> #1 — RMSE(均方根误差)</a></p><p id="ed53" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated"><a class="ae le" href="#5185" rel="noopener ugc nofollow"> #2 — RMSLE(均方根对数误差)</a></p><p id="fadc" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated"><a class="ae le" href="#2b4e" rel="noopener ugc nofollow"> #3 —平均绝对误差</a></p><p id="7113" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated"><a class="ae le" href="#ad72" rel="noopener ugc nofollow"> #4 — R 平方(R ) </a></p><h2 id="bc8e" class="nb mk iq bd ml nc nd dn mp ne nf dp mt lo ng nh mv ls ni nj mx lw nk nl mz iw bi translated"><a class="ae le" href="#89e8" rel="noopener ugc nofollow">用于二进制分类任务中 0/1 预测的评估指标</a></h2><p id="51bd" class="pw-post-body-paragraph lf lg iq lh b li nm ka lk ll nn kd ln lo no lq lr ls np lu lv lw nq ly lz ma ij bi translated"><a class="ae le" href="#c637" rel="noopener ugc nofollow"> #5 —准确度和误差率</a></p><p id="ea11" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated"><a class="ae le" href="#a2e7" rel="noopener ugc nofollow"># 6——精度和召回</a></p><p id="5fe6" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated"><a class="ae le" href="#0213" rel="noopener ugc nofollow"> #7 — F1 分数和 Fbeta 分数</a></p><p id="3943" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated"><a class="ae le" href="#9e24" rel="noopener ugc nofollow"> #8 — MCC(马修斯相关系数)</a></p><p id="b382" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated"><a class="ae le" href="#96e3" rel="noopener ugc nofollow"> #9 —平衡精度</a></p><p id="db6e" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated"><a class="ae le" href="#e1bc" rel="noopener ugc nofollow"> #10 —对数损失(或交叉熵或负对数似然)</a></p><p id="a0a9" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated"><a class="ae le" href="#bd6b" rel="noopener ugc nofollow"> #11 — AUCROC(受试者工作特性曲线下面积)</a></p></div><div class="ab cl mc md hu me" role="separator"><span class="mf bw bk mg mh mi"/><span class="mf bw bk mg mh mi"/><span class="mf bw bk mg mh"/></div><div class="ij ik il im in"><h1 id="ad3e" class="mj mk iq bd ml mm mn mo mp mq mr ms mt kf mu kg mv ki mw kj mx kl my km mz na bi translated">评估指标与损失函数</h1><p id="7953" class="pw-post-body-paragraph lf lg iq lh b li nm ka lk ll nn kd ln lo no lq lr ls np lu lv lw nq ly lz ma ij bi translated"><em class="mb">评估指标</em>，这个帖子的一个主题，对于 ML 初学者来说，是一个与另一个相关但独立的概念<em class="mb">损失函数</em>有些混淆的概念。它们在某种意义上是相似的，当我们足够幸运时，它们可能是相同的，但这不会每次都发生。</p><blockquote class="nr"><p id="cd96" class="ns nt iq bd nu nv nw nx ny nz oa ma dk translated"><em class="ob">评估度量</em>是通过建模过程“我们想要”最小化或最大化的度量，而<em class="ob">损失函数</em>是通过模型训练“模型将”最小化的度量。</p></blockquote><figure class="od oe of og oh kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi oc"><img src="../Images/6f248e776f0270dd85fdd6923e7a0d49.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*sFAdGl9t9NNKuk2I"/></div></div><figcaption class="la lb gj gh gi lc ld bd b be z dk">Photo by <a class="ae le" href="https://unsplash.com/@freegraphictoday?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">AbsolutVision</a> on <a class="ae le" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><p id="6f85" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">举一个简单逻辑回归的例子:</p><ul class=""><li id="d86d" class="oi oj iq lh b li lj ll lm lo ok ls ol lw om ma on oo op oq bi translated"><strong class="lh ja">损失函数</strong>是模型将在训练中最小化的量。它也被称为成本函数或目标函数。逻辑回归的非常基本的版本使用<a class="ae le" href="#e1bc" rel="noopener ugc nofollow">负对数似然</a>作为损失函数。搜索模型的参数以最小化负对数似然性是在训练模型时完成的事情。</li><li id="7ef3" class="oi oj iq lh b li or ll os lo ot ls ou lw ov ma on oo op oq bi translated"><strong class="lh ja">评估指标</strong>是我们希望模型最大化的指标。它独立于模型培训流程，并且<em class="mb">理想情况下，评估指标应该反映我们的业务需求</em>。根据业务应用，我们可能希望最大化<a class="ae le" href="#bd6b" rel="noopener ugc nofollow"> AUC </a>，或者我们可能关心<a class="ae le" href="#a2e7" rel="noopener ugc nofollow">召回</a>有多好。</li></ul><p id="b7c8" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">损失函数与模型紧密相关，通常模型具有损失函数候选的限制性列表，例如，逻辑回归的[ <em class="mb">负对数似然、带惩罚项的负对数似然][</em>]，因为损失函数的选择是模型算法创建者核心决定的一部分。</p><p id="f551" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">另一方面，评估指标可以是我们想要设置的任何值。最终，我们可以将“1”用于任何模型，尽管使用通用的“1”作为评估指标从来没有意义。评估指标有多高通常由训练中未使用的数据来衡量，如折叠外数据或测试数据。</p></div><div class="ab cl mc md hu me" role="separator"><span class="mf bw bk mg mh mi"/><span class="mf bw bk mg mh mi"/><span class="mf bw bk mg mh"/></div><div class="ij ik il im in"><p id="7240" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">评估分数广泛用于超参数调整，但对于更有经验的数据科学人员来说，理解损失函数和评估度量的区别的最有用的案例之一是<strong class="lh ja">提前停止</strong>。早期停止是一种通常用于确定何时停止训练的技术，以避免在增强类型的模型或神经网络类型的模型中过拟合。</p><blockquote class="ow ox oy"><p id="104d" class="lf lg mb lh b li lj ka lk ll lm kd ln oz lp lq lr pa lt lu lv pb lx ly lz ma ij bi translated">[提前停止]</p><p id="39f3" class="lf lg mb lh b li lj ka lk ll lm kd ln oz lp lq lr pa lt lu lv pb lx ly lz ma ij bi translated">当模型基于<strong class="lh ja">损失函数</strong>的最小化来调整参数时，检查一次迭代对<strong class="lh ja">评估度量</strong>的改善程度，如果没有更多改善，则停止学习。</p></blockquote></div><div class="ab cl mc md hu me" role="separator"><span class="mf bw bk mg mh mi"/><span class="mf bw bk mg mh mi"/><span class="mf bw bk mg mh"/></div><div class="ij ik il im in"><p id="dad9" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">在 Kaggle 中，比赛参与者按“排行榜分数”进行排名。排行榜分数有两种类型，公开和私人，但这是另一个故事。排行榜分数可以归类为竞赛主持人为满足其业务目标或需求而设定的评估指标。</p><blockquote class="nr"><p id="e4e7" class="ns nt iq bd nu nv nw nx ny nz oa ma dk translated">那么，了解评价得分，以及如何通过模型训练使其最大化，应该是赢得 Kaggle 比赛的一条道路。</p></blockquote></div><div class="ab cl mc md hu me" role="separator"><span class="mf bw bk mg mh mi"/><span class="mf bw bk mg mh mi"/><span class="mf bw bk mg mh"/></div><div class="ij ik il im in"><p id="d35e" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">所以，现在你明白了评价指标和损失函数的区别。接下来，我们将进一步了解常见的评估指标及其属性。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi pc"><img src="../Images/c3d37841dc82218809b84299083bbffb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*xo5U3KdfbQvCm21z"/></div></div><figcaption class="la lb gj gh gi lc ld bd b be z dk">Photo by <a class="ae le" href="https://unsplash.com/@tierramallorca?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Tierra Mallorca</a> on <a class="ae le" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure></div><div class="ab cl mc md hu me" role="separator"><span class="mf bw bk mg mh mi"/><span class="mf bw bk mg mh mi"/><span class="mf bw bk mg mh"/></div><div class="ij ik il im in"><h1 id="96c6" class="mj mk iq bd ml mm mn mo mp mq mr ms mt kf mu kg mv ki mw kj mx kl my km mz na bi translated">回归任务中使用的评估指标</h1><h2 id="a94a" class="nb mk iq bd ml nc nd dn mp ne nf dp mt lo ng nh mv ls ni nj mx lw nk nl mz iw bi translated">#1 — RMSE(均方根误差)</h2><p id="9262" class="pw-post-body-paragraph lf lg iq lh b li nm ka lk ll nn kd ln lo no lq lr ls np lu lv lw nq ly lz ma ij bi translated"><em class="mb">(用于 Kaggle 比赛</em><a class="ae le" href="https://www.kaggle.com/c/elo-merchant-category-recommendation/overview/evaluation" rel="noopener ugc nofollow" target="_blank"><em class="mb">【Elo 商家类别推荐】</em> </a> <em class="mb"> ) </em></p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi pd"><img src="../Images/8be29b2a1ec4bacc0b5d272ab6264257.png" data-original-src="https://miro.medium.com/v2/resize:fit:594/format:webp/1*w8liRJGcNNgfdUmPHos6Tg.png"/></div><figcaption class="la lb gj gh gi lc ld bd b be z dk">Formula of RMSE</figcaption></figure><ul class=""><li id="fb33" class="oi oj iq lh b li lj ll lm lo ok ls ol lw om ma on oo op oq bi translated">当假设误差是正态分布时，RMSE 有相当于最大似然法的解。因此，当 y 的分布在一些基础结构周围是正态分布时是有利的。</li><li id="f02d" class="oi oj iq lh b li or ll os lo ot ls ou lw ov ma on oo op oq bi translated">RMSE 对异常值很敏感。因此，预先裁剪或移除异常值是很重要的。</li></ul><figure class="kp kq kr ks gt kt"><div class="bz fp l di"><div class="pe pf l"/></div></figure></div><div class="ab cl mc md hu me" role="separator"><span class="mf bw bk mg mh mi"/><span class="mf bw bk mg mh mi"/><span class="mf bw bk mg mh"/></div><div class="ij ik il im in"><h2 id="5185" class="nb mk iq bd ml nc nd dn mp ne nf dp mt lo ng nh mv ls ni nj mx lw nk nl mz iw bi translated">#2 — RMSLE(均方根对数误差)</h2><p id="359b" class="pw-post-body-paragraph lf lg iq lh b li nm ka lk ll nn kd ln lo no lq lr ls np lu lv lw nq ly lz ma ij bi translated"><em class="mb">(用于 Kaggle 竞赛中的</em> <a class="ae le" href="https://www.kaggle.com/c/recruit-restaurant-visitor-forecasting/overview/evaluation" rel="noopener ugc nofollow" target="_blank"> <em class="mb">招募餐厅访客预测</em></a><em class="mb">)</em></p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi pg"><img src="../Images/9be0dfe636fb89d7c9fe329dfd1ebea4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1346/format:webp/1*HcVLNiX6ojmhLKOGUsR8AA.png"/></div><figcaption class="la lb gj gh gi lc ld bd b be z dk">Formula of RMSLE</figcaption></figure><ul class=""><li id="64fc" class="oi oj iq lh b li lj ll lm lo ok ls ol lw om ma on oo op oq bi translated">当 y 具有长尾分布，或者我们对真实值和预测值的比值感兴趣时，使用 RMSLE。</li><li id="0385" class="oi oj iq lh b li or ll os lo ot ls ou lw ov ma on oo op oq bi translated">当 y 为零时，增加 1 以避免发散。</li></ul><figure class="kp kq kr ks gt kt"><div class="bz fp l di"><div class="pe pf l"/></div></figure></div><div class="ab cl mc md hu me" role="separator"><span class="mf bw bk mg mh mi"/><span class="mf bw bk mg mh mi"/><span class="mf bw bk mg mh"/></div><div class="ij ik il im in"><h2 id="2b4e" class="nb mk iq bd ml nc nd dn mp ne nf dp mt lo ng nh mv ls ni nj mx lw nk nl mz iw bi translated">#3 —平均绝对误差</h2><p id="66a6" class="pw-post-body-paragraph lf lg iq lh b li nm ka lk ll nn kd ln lo no lq lr ls np lu lv lw nq ly lz ma ij bi translated"><em class="mb">(用于 Kaggle 竞赛中)</em> <a class="ae le" href="https://www.kaggle.com/c/allstate-claims-severity/overview/evaluation" rel="noopener ugc nofollow" target="_blank"> <em class="mb"> Allstate 索赔严重程度</em></a><em class="mb">)</em></p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi ph"><img src="../Images/ef15c15d21d6dd879d71517c1ef7dafc.png" data-original-src="https://miro.medium.com/v2/resize:fit:464/format:webp/1*dcSXypV-ureRxsMVg1c9LQ.png"/></div><figcaption class="la lb gj gh gi lc ld bd b be z dk">Formula of MAE</figcaption></figure><ul class=""><li id="1cab" class="oi oj iq lh b li lj ll lm lo ok ls ol lw om ma on oo op oq bi translated">与 RMSE 相比，对异常值稳健。</li><li id="ee81" class="oi oj iq lh b li or ll os lo ot ls ou lw ov ma on oo op oq bi translated">在真 y =预测 y 处不是二阶可微的，因此 xgboost 等一些算法不允许 MAE 作为损失函数。</li><li id="3cff" class="oi oj iq lh b li or ll os lo ot ls ou lw ov ma on oo op oq bi translated">代替 MAE，诸如“公平函数”或“伪 Huber 函数”的近似函数可能是可用的。</li></ul><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi pi"><img src="../Images/c33527d4abf80e6d168dbeae7d053097.png" data-original-src="https://miro.medium.com/v2/resize:fit:740/format:webp/1*9DoDmnRubsQWcnwBQYDhKQ.png"/></div><figcaption class="la lb gj gh gi lc ld bd b be z dk">Fair Function</figcaption></figure><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi pj"><img src="../Images/58c6cfbdbddae56341c3bd5223ce5133.png" data-original-src="https://miro.medium.com/v2/resize:fit:684/format:webp/1*Sz2trTS1tV-t0B_hP_b0zg.png"/></div><figcaption class="la lb gj gh gi lc ld bd b be z dk">Pseudo-Huber Function</figcaption></figure><figure class="kp kq kr ks gt kt"><div class="bz fp l di"><div class="pe pf l"/></div></figure><p id="bff0" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">另见<a class="ae le" href="https://www.researchgate.net/figure/On-the-left-a-comparison-between-the-1-norm-the-Huber-and-the-Pseudo-Huber-function-and_fig1_329477768" rel="noopener ugc nofollow" target="_blank">这张由 Ioannis Dassios </a>发布的 MAE 与 Fair 函数和 Pseudo-Huber 函数的对比图。</p></div><div class="ab cl mc md hu me" role="separator"><span class="mf bw bk mg mh mi"/><span class="mf bw bk mg mh mi"/><span class="mf bw bk mg mh"/></div><div class="ij ik il im in"><h2 id="ad72" class="nb mk iq bd ml nc nd dn mp ne nf dp mt lo ng nh mv ls ni nj mx lw nk nl mz iw bi translated">#4 — R 平方(R)</h2><p id="e1a0" class="pw-post-body-paragraph lf lg iq lh b li nm ka lk ll nn kd ln lo no lq lr ls np lu lv lw nq ly lz ma ij bi translated"><em class="mb">(用于 Kaggle 比赛】</em> <a class="ae le" href="https://www.kaggle.com/c/mercedes-benz-greener-manufacturing/overview/evaluation" rel="noopener ugc nofollow" target="_blank"> <em class="mb">奔驰更环保制造</em></a><em class="mb">)</em></p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi pk"><img src="../Images/d6559218838bfc35083e2789d9daa900.png" data-original-src="https://miro.medium.com/v2/resize:fit:766/format:webp/1*mwgZgki-2yBnbd-l9bzViw.png"/></div><figcaption class="la lb gj gh gi lc ld bd b be z dk">Formula of R-Squared</figcaption></figure><ul class=""><li id="afc7" class="oi oj iq lh b li lj ll lm lo ok ls ol lw om ma on oo op oq bi translated">0≤R ≤1(通常情况下，但在一些最坏的情况下，您会看到负值)，R 越高越好，这意味着预测更接近数据。</li><li id="de5c" class="oi oj iq lh b li or ll os lo ot ls ou lw ov ma on oo op oq bi translated">分母不依赖于预测，并且一旦设定数据就固定不变。因此，<strong class="lh ja">最大化 R 等价于最小化 RMSE </strong>。</li></ul><figure class="kp kq kr ks gt kt"><div class="bz fp l di"><div class="pe pf l"/></div></figure><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi pl"><img src="../Images/b4b9efe2d2f38da379b6276c994ab9bd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*nY5c47H3-KLo_vP_"/></div></div><figcaption class="la lb gj gh gi lc ld bd b be z dk">Photo by <a class="ae le" href="https://unsplash.com/@ricpalla?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Riccardo Pallaoro</a> on <a class="ae le" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure></div><div class="ab cl mc md hu me" role="separator"><span class="mf bw bk mg mh mi"/><span class="mf bw bk mg mh mi"/><span class="mf bw bk mg mh"/></div><div class="ij ik il im in"><h1 id="89e8" class="mj mk iq bd ml mm mn mo mp mq mr ms mt kf mu kg mv ki mw kj mx kl my km mz na bi translated">二元分类任务中 0/1 预测的评价指标</h1><h2 id="c637" class="nb mk iq bd ml nc nd dn mp ne nf dp mt lo ng nh mv ls ni nj mx lw nk nl mz iw bi translated">#5 —精确度和误差率</h2><p id="3977" class="pw-post-body-paragraph lf lg iq lh b li nm ka lk ll nn kd ln lo no lq lr ls np lu lv lw nq ly lz ma ij bi translated"><em class="mb">(用于 Kaggle 竞赛中的</em> <a class="ae le" href="https://www.kaggle.com/c/text-normalization-challenge-english-language/overview/evaluation" rel="noopener ugc nofollow" target="_blank"> <em class="mb">文字规范化挑战——英语</em></a><em class="mb">)</em></p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi pm"><img src="../Images/6cff2337aed2c95ecb024a293b234796.png" data-original-src="https://miro.medium.com/v2/resize:fit:976/format:webp/1*iBz8CA_yKFx9KWcAF31WTA.png"/></div><figcaption class="la lb gj gh gi lc ld bd b be z dk">Formula of Accuracy and Error Rate</figcaption></figure><p id="dc96" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">在这里，两个字母的字母表当然来自混淆矩阵。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi pn"><img src="../Images/413e9b04246d15b9ea5afba5d36fa1af.png" data-original-src="https://miro.medium.com/v2/resize:fit:870/format:webp/1*xUdrn7cQEWwFAH8L8ZTr-w.png"/></div><figcaption class="la lb gj gh gi lc ld bd b be z dk">Confusion Matrix</figcaption></figure><ul class=""><li id="1d2d" class="oi oj iq lh b li lj ll lm lo ok ls ol lw om ma on oo op oq bi translated"><strong class="lh ja"> NG 用于不平衡数据</strong>因为预测一切为正或为负的非常糟糕的模型很容易破解不平衡数据中的高精度。</li><li id="35cf" class="oi oj iq lh b li or ll os lo ot ls ou lw ov ma on oo op oq bi translated"><strong class="lh ja">对于不平衡数据，使用 F1-score、Fbeta-score、MCC 或稍后介绍的平衡精确度</strong>。</li></ul><figure class="kp kq kr ks gt kt"><div class="bz fp l di"><div class="pe pf l"/></div></figure></div><div class="ab cl mc md hu me" role="separator"><span class="mf bw bk mg mh mi"/><span class="mf bw bk mg mh mi"/><span class="mf bw bk mg mh"/></div><div class="ij ik il im in"><h2 id="a2e7" class="nb mk iq bd ml nc nd dn mp ne nf dp mt lo ng nh mv ls ni nj mx lw nk nl mz iw bi translated">#6 —精确度和召回率</h2><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi po"><img src="../Images/99f831e5960e9153675692cbd45c453e.png" data-original-src="https://miro.medium.com/v2/resize:fit:722/format:webp/1*9pMfTQV68Mxn0RoKidXFEw.png"/></div><figcaption class="la lb gj gh gi lc ld bd b be z dk">Formula of precision and recall</figcaption></figure><ul class=""><li id="2389" class="oi oj iq lh b li lj ll lm lo ok ls ol lw om ma on oo op oq bi translated">精确度和召回率分别表示混淆矩阵中第一水平行或第一垂直列上 TP 的比例。</li><li id="4220" class="oi oj iq lh b li or ll os lo ot ls ou lw ov ma on oo op oq bi translated">介于 0 和 1 之间，越高越好。</li><li id="ca4c" class="oi oj iq lh b li or ll os lo ot ls ou lw ov ma on oo op oq bi translated">当截止点(=根据概率确定预测是 0 还是 1 的阈值)移动时，精确度和召回率会向相反的方向移动。</li><li id="4b74" class="oi oj iq lh b li or ll os lo ot ls ou lw ov ma on oo op oq bi translated"><strong class="lh ja">与正负互换</strong>是不对称的，这意味着当我们改变哪个称之为“正”(无论 y=1 还是 0)时，精度和召回率都会改变。</li></ul><figure class="kp kq kr ks gt kt"><div class="bz fp l di"><div class="pe pf l"/></div></figure></div><div class="ab cl mc md hu me" role="separator"><span class="mf bw bk mg mh mi"/><span class="mf bw bk mg mh mi"/><span class="mf bw bk mg mh"/></div><div class="ij ik il im in"><h2 id="0213" class="nb mk iq bd ml nc nd dn mp ne nf dp mt lo ng nh mv ls ni nj mx lw nk nl mz iw bi translated">#7 — F1 分数和 Fbeta 分数</h2><p id="30a7" class="pw-post-body-paragraph lf lg iq lh b li nm ka lk ll nn kd ln lo no lq lr ls np lu lv lw nq ly lz ma ij bi translated"><em class="mb">(用于 Kaggle 比赛中)</em> <a class="ae le" href="https://www.kaggle.com/c/quora-insincere-questions-classification/overview/evaluation" rel="noopener ugc nofollow" target="_blank"> <em class="mb"> Quora 言不由衷问题分类</em></a><em class="mb">)</em></p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi pp"><img src="../Images/a8b38be07d8a597b7541536d0e553749.png" data-original-src="https://miro.medium.com/v2/resize:fit:1010/format:webp/1*XxsIocsA6aWWhn7BVx8gUw.png"/></div><figcaption class="la lb gj gh gi lc ld bd b be z dk">Formula of F1-Score and Fbeta-Score</figcaption></figure><ul class=""><li id="37a5" class="oi oj iq lh b li lj ll lm lo ok ls ol lw om ma on oo op oq bi translated">它被称为精确度和召回率的“调和平均值”。</li><li id="a1ac" class="oi oj iq lh b li or ll os lo ot ls ou lw ov ma on oo op oq bi translated">介于 0 和 1 之间，越高越好。</li><li id="9d8d" class="oi oj iq lh b li or ll os lo ot ls ou lw ov ma on oo op oq bi translated">Fbeta-score 可以改变查全率和查准率之间的平衡，当<strong class="lh ja"> β &lt; 1 加权到查准率，β &gt; 1 加权到查全率</strong>。当我们更喜欢一个而不是另一个时，可能会有用，就像医学诊断通常更喜欢假阳性而不是假阴性，因为前者只会带来额外的成本，而后者会带来晚期治疗并可能导致死亡。</li><li id="43b3" class="oi oj iq lh b li or ll os lo ot ls ou lw ov ma on oo op oq bi translated">同样，<strong class="lh ja">这些对于正负互换来说是不对称的</strong>，就像精度和召回也不是一样。</li></ul><figure class="kp kq kr ks gt kt"><div class="bz fp l di"><div class="pe pf l"/></div></figure></div><div class="ab cl mc md hu me" role="separator"><span class="mf bw bk mg mh mi"/><span class="mf bw bk mg mh mi"/><span class="mf bw bk mg mh"/></div><div class="ij ik il im in"><h2 id="9e24" class="nb mk iq bd ml nc nd dn mp ne nf dp mt lo ng nh mv ls ni nj mx lw nk nl mz iw bi translated">#8 — MCC(马修斯相关系数)</h2><p id="a14f" class="pw-post-body-paragraph lf lg iq lh b li nm ka lk ll nn kd ln lo no lq lr ls np lu lv lw nq ly lz ma ij bi translated"><em class="mb">(用于 Kaggle 竞赛的</em> <a class="ae le" href="https://www.kaggle.com/c/bosch-production-line-performance/overview/evaluation" rel="noopener ugc nofollow" target="_blank"> <em class="mb">博世生产线性能</em></a><em class="mb">)</em></p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi pq"><img src="../Images/58accf49a6a33652d9423883ef07f4fa.png" data-original-src="https://miro.medium.com/v2/resize:fit:782/format:webp/1*S_4zhwUBbhrRRLJFnXgapA.png"/></div></div><figcaption class="la lb gj gh gi lc ld bd b be z dk">Formula of MCC</figcaption></figure><ul class=""><li id="6aaa" class="oi oj iq lh b li lj ll lm lo ok ls ol lw om ma on oo op oq bi translated">取-1 和 1 之间的值，越高越好。0 表示预测等同于随机。</li><li id="0f3c" class="oi oj iq lh b li or ll os lo ot ls ou lw ov ma on oo op oq bi translated">最后，<strong class="lh ja">这是对称正反互换！</strong></li></ul><figure class="kp kq kr ks gt kt"><div class="bz fp l di"><div class="pe pf l"/></div></figure></div><div class="ab cl mc md hu me" role="separator"><span class="mf bw bk mg mh mi"/><span class="mf bw bk mg mh mi"/><span class="mf bw bk mg mh"/></div><div class="ij ik il im in"><h2 id="96e3" class="nb mk iq bd ml nc nd dn mp ne nf dp mt lo ng nh mv ls ni nj mx lw nk nl mz iw bi translated">#9 —平衡的精度</h2><p id="cb03" class="pw-post-body-paragraph lf lg iq lh b li nm ka lk ll nn kd ln lo no lq lr ls np lu lv lw nq ly lz ma ij bi translated">平衡精度是可用于二元分类和多类分类的度量。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi pr"><img src="../Images/4f6f9997085c7c6b909cbb0a4d2c5479.png" data-original-src="https://miro.medium.com/v2/resize:fit:580/format:webp/1*TLVKp2qA1efdQTWZv0WXaA.png"/></div><figcaption class="la lb gj gh gi lc ld bd b be z dk">Formula of balanced accuracy</figcaption></figure><p id="4695" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">其中，M:类别数，n_m:数据大小属于类别 M，r_m:准确预测属于类别 M 的数据数。</p><p id="133f" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">这里，如果问题是二进制分类，</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi ps"><img src="../Images/09ae36b3337e097a169aa4d9973e1866.png" data-original-src="https://miro.medium.com/v2/resize:fit:1172/format:webp/1*V55VfjapQPV1-Fa54ViV-Q.png"/></div><figcaption class="la lb gj gh gi lc ld bd b be z dk">Balanced accuracy when binary classification</figcaption></figure><ul class=""><li id="2a91" class="oi oj iq lh b li lj ll lm lo ok ls ol lw om ma on oo op oq bi translated">适用于多类分类和二类分类。</li><li id="af4a" class="oi oj iq lh b li or ll os lo ot ls ou lw ov ma on oo op oq bi translated">介于 0 和 1 之间的值，越高越好。</li><li id="793c" class="oi oj iq lh b li or ll os lo ot ls ou lw ov ma on oo op oq bi translated">对较小类别的准确预测赋予较高的权重，因此<strong class="lh ja">适用于不平衡数据</strong>。</li></ul><figure class="kp kq kr ks gt kt"><div class="bz fp l di"><div class="pe pf l"/></div></figure><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi pt"><img src="../Images/f52c24d7ed7bf25b5c29b6ca60367b22.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*2EyVe1u6cJm4Ehhc"/></div></div><figcaption class="la lb gj gh gi lc ld bd b be z dk">Photo by <a class="ae le" href="https://unsplash.com/@dnevozhai?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Denys Nevozhai</a> on <a class="ae le" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure></div><div class="ab cl mc md hu me" role="separator"><span class="mf bw bk mg mh mi"/><span class="mf bw bk mg mh mi"/><span class="mf bw bk mg mh"/></div><div class="ij ik il im in"><h1 id="5754" class="mj mk iq bd ml mm mn mo mp mq mr ms mt kf mu kg mv ki mw kj mx kl my km mz na bi translated">二元分类任务中概率预测的评价指标</h1><h2 id="e1bc" class="nb mk iq bd ml nc nd dn mp ne nf dp mt lo ng nh mv ls ni nj mx lw nk nl mz iw bi translated">#10 —对数损失(或交叉熵或负对数可能性)</h2><p id="bfd8" class="pw-post-body-paragraph lf lg iq lh b li nm ka lk ll nn kd ln lo no lq lr ls np lu lv lw nq ly lz ma ij bi translated"><em class="mb">(用于 Kaggle 比赛中的</em> <a class="ae le" href="https://www.kaggle.com/c/quora-question-pairs/overview/evaluation" rel="noopener ugc nofollow" target="_blank"> <em class="mb"> Quora 问题对</em></a><em class="mb">)</em></p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi pu"><img src="../Images/03e56e043c3eac2f760f3d29e79b70b3.png" data-original-src="https://miro.medium.com/v2/resize:fit:906/format:webp/1*9gj1iTgQXS2EIIL-W2Pb2w.png"/></div><figcaption class="la lb gj gh gi lc ld bd b be z dk">Formula of logloss</figcaption></figure><ul class=""><li id="0e65" class="oi oj iq lh b li lj ll lm lo ok ls ol lw om ma on oo op oq bi translated">分类中常见的嫌疑人。</li><li id="207c" class="oi oj iq lh b li or ll os lo ot ls ou lw ov ma on oo op oq bi translated">这是<em class="mb">损失</em>并且越高越糟糕。</li><li id="22e3" class="oi oj iq lh b li or ll os lo ot ls ou lw ov ma on oo op oq bi translated">当 p_i 较低而 y_i=1 时，意味着不是好的概率预测，或者相反，logloss 变高。</li><li id="e73c" class="oi oj iq lh b li or ll os lo ot ls ou lw ov ma on oo op oq bi translated">在许多模型的损失函数中也很常见。</li></ul><figure class="kp kq kr ks gt kt"><div class="bz fp l di"><div class="pe pf l"/></div></figure></div><div class="ab cl mc md hu me" role="separator"><span class="mf bw bk mg mh mi"/><span class="mf bw bk mg mh mi"/><span class="mf bw bk mg mh"/></div><div class="ij ik il im in"><h2 id="bd6b" class="nb mk iq bd ml nc nd dn mp ne nf dp mt lo ng nh mv ls ni nj mx lw nk nl mz iw bi translated">#11 — AUCROC(受试者操作特征曲线下的面积)</h2><p id="de83" class="pw-post-body-paragraph lf lg iq lh b li nm ka lk ll nn kd ln lo no lq lr ls np lu lv lw nq ly lz ma ij bi translated"><em class="mb">(用于 Kaggle 竞赛中)</em> <a class="ae le" href="https://www.kaggle.com/c/home-credit-default-risk/overview/evaluation" rel="noopener ugc nofollow" target="_blank"> <em class="mb">家庭信用违约风险</em></a><em class="mb">)</em></p><p id="9605" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">这通常也称为 AUC，但为了避免与 AUCPR(精确召回曲线下面积)混淆，我坚持使用 AUCROC。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi pv"><img src="../Images/d104cb7ca8599e9c9e2360a4913dc1d3.png" data-original-src="https://miro.medium.com/v2/resize:fit:694/format:webp/1*YNrSCF59FZFSeh3q03HK6w.png"/></div><figcaption class="la lb gj gh gi lc ld bd b be z dk">Illustration of AUCROC and ROC</figcaption></figure><ul class=""><li id="50d0" class="oi oj iq lh b li lj ll lm lo ok ls ol lw om ma on oo op oq bi translated">从 0 到 1 的值。0.5 表示预测相当于随机的。</li><li id="c275" class="oi oj iq lh b li or ll os lo ot ls ou lw ov ma on oo op oq bi translated">分类中的另一个常见疑点，但只针对二元分类而非多类分类。</li><li id="0460" class="oi oj iq lh b li or ll os lo ot ls ou lw ov ma on oo op oq bi translated">与基尼系数的关系如下。AUCROC 的最大化相当于基尼系数的最大化。</li></ul><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi pw"><img src="../Images/9623048dab4293896b3d8abf2ae0110e.png" data-original-src="https://miro.medium.com/v2/resize:fit:484/format:webp/1*6_04MREg9DLTH3AygJbPEQ.png"/></div><figcaption class="la lb gj gh gi lc ld bd b be z dk">Relation with Gini and AUCROC</figcaption></figure><ul class=""><li id="78cf" class="oi oj iq lh b li lj ll lm lo ok ls ol lw om ma on oo op oq bi translated">可以用以下形式等价地表示:</li></ul><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi px"><img src="../Images/a4e6d5b1fc115d28a006086e7f9a1ed0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1026/format:webp/1*4NVAlx3KdcSrezB9wxF9TA.png"/></div><figcaption class="la lb gj gh gi lc ld bd b be z dk">Alternative representation of AUCROC</figcaption></figure><ul class=""><li id="6a20" class="oi oj iq lh b li lj ll lm lo ok ls ol lw om ma on oo op oq bi translated">因此，<strong class="lh ja">只有预测概率的顺序与</strong>有关，这意味着当四个记录的概率为[0.1，0.3，0.7，0.9]或[0.01，0.02，0.3，0.99]时，AUCROC 是相同的，只要顺序保持不变。</li><li id="d873" class="oi oj iq lh b li or ll os lo ot ls ou lw ov ma on oo op oq bi translated">与原始定义相比，这种替代表示更容易知道模型预测改进对分数改进有多大贡献。</li><li id="3a15" class="oi oj iq lh b li or ll os lo ot ls ou lw ov ma on oo op oq bi translated">在不平衡数据的情况下(例如，正数据是小类到负数据)，正小类数据的概率始终很高对于 AUCROC 很重要，而负大类数据的概率对噪声不敏感。</li></ul><figure class="kp kq kr ks gt kt"><div class="bz fp l di"><div class="pe pf l"/></div></figure><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi py"><img src="../Images/76e58c0a420d79b5c77600147d32023e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1002/format:webp/1*cdJspa2LoNPAGoOpmyhzdQ.png"/></div><figcaption class="la lb gj gh gi lc ld bd b be z dk">ROC curve and AUCROC visualized by code</figcaption></figure><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi pz"><img src="../Images/722d36f667ec1344cf39c3980ca368f2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*kyu-o-Sky-614tpl"/></div></div><figcaption class="la lb gj gh gi lc ld bd b be z dk">Photo by <a class="ae le" href="https://unsplash.com/@kellysikkema?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Kelly Sikkema</a> on <a class="ae le" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure></div><div class="ab cl mc md hu me" role="separator"><span class="mf bw bk mg mh mi"/><span class="mf bw bk mg mh mi"/><span class="mf bw bk mg mh"/></div><div class="ij ik il im in"><h1 id="a0f7" class="mj mk iq bd ml mm mn mo mp mq mr ms mt kf mu kg mv ki mw kj mx kl my km mz na bi translated">结论</h1><p id="effa" class="pw-post-body-paragraph lf lg iq lh b li nm ka lk ll nn kd ln lo no lq lr ls np lu lv lw nq ly lz ma ij bi translated">在 Kaggle 内部和外部，评估指标有许多可能的选择。每个评估指标都有它们的属性，当我们优化它们或者选择正确的评估指标时，理解它们的行为是很重要的。</p><p id="1789" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">在另一篇帖子中，我将讨论我们在多类分类和推荐中使用的评估指标，我们还将找到优化评估指标的技巧，同时通过最小化损失函数来调整模型。</p></div></div>    
</body>
</html>