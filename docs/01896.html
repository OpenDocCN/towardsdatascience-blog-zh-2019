<html>
<head>
<title>Paper Summary. Stiffness: A New Perspective on Generalization in Neural Networks</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">论文总结。刚度:神经网络泛化的新视角</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/paper-summary-stiffness-a-new-perspective-on-generalization-in-neural-networks-25f4995eb317?source=collection_archive---------23-----------------------#2019-03-28">https://towardsdatascience.com/paper-summary-stiffness-a-new-perspective-on-generalization-in-neural-networks-25f4995eb317?source=collection_archive---------23-----------------------#2019-03-28</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><figure class="gl gn jr js jt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi jq"><img src="../Images/770d143d0f41a05758c33e0e72e49049.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*pMyjLhg5lRhyxMCSJ_jOaQ.jpeg"/></div></div><figcaption class="kb kc gj gh gi kd ke bd b be z dk"><a class="ae kf" href="http://alpha.math.uga.edu/~topology/2001/index.html" rel="noopener ugc nofollow" target="_blank">Source</a></figcaption></figure><p id="09eb" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">这是对<a class="ae kf" href="https://arxiv.org/pdf/1901.09491.pdf" rel="noopener ugc nofollow" target="_blank">刚度的总结:神经网络泛化的新视角</a> (01/2019)。</p><h1 id="3b56" class="le lf it bd lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb bi translated">僵硬？</h1><p id="c30f" class="pw-post-body-paragraph kg kh it ki b kj mc kl km kn md kp kq kr me kt ku kv mf kx ky kz mg lb lc ld im bi translated">本文旨在从<em class="mh">刚度</em>的角度提高我们对神经网络如何泛化的理解。刚度背后的直觉是一个点上的梯度更新如何影响另一个点:</p><blockquote class="mi mj mk"><p id="cac0" class="kg kh mh ki b kj kk kl km kn ko kp kq ml ks kt ku mm kw kx ky mn la lb lc ld im bi translated"><em class="it">【它】描述了由于基于其中一个应用梯度更新而导致的两个损失变化之间的相关量。(4.1、结果和讨论)</em></p></blockquote><p id="eec4" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">刚度表示为梯度的预期符号<code class="fe mo mp mq mr b">g</code>:</p><figure class="mt mu mv mw gt ju gh gi paragraph-image"><div class="gh gi ms"><img src="../Images/ff4e3efe40d4103198e90d29f0d6db27.png" data-original-src="https://miro.medium.com/v2/resize:fit:972/format:webp/0*3mdjaSzHL-Xj8w-_.png"/></div></figure><p id="4c26" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">改善 X1 和 X2 损失的权重更新是刚性的，如果损失有益于其中一个点而无助于另一个点，则该权重更新被描述为反刚性的。</p><figure class="mt mu mv mw gt ju gh gi paragraph-image"><div class="gh gi mx"><img src="../Images/840f0890908dc823bba64dcb2c88d720.png" data-original-src="https://miro.medium.com/v2/resize:fit:1036/format:webp/0*J-Bevab_q-s1HXkQ.png"/></div></figure><p id="9458" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">现在的问题是我们如何选择 X1 和 X2。作者探索了两种方法:按类成员或按距离。</p><h1 id="d29a" class="le lf it bd lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb bi translated">基于类成员的刚度</h1><p id="dfdb" class="pw-post-body-paragraph kg kh it ki b kj mc kl km kn md kp kq kr me kt ku kv mf kx ky kz mg lb lc ld im bi translated">我们可以看看 A 类中一个点的梯度更新如何影响属于 b 类的另一个点的损失。在本文中，他们制作了一个*类刚度矩阵`，这是按类分组的每个点之间的平均刚度:</p><figure class="mt mu mv mw gt ju gh gi paragraph-image"><div class="gh gi my"><img src="../Images/e909bfb95ae9dc3ecdc9b82cc1ee5746.png" data-original-src="https://miro.medium.com/v2/resize:fit:1082/format:webp/0*JYJH0rpKlgHypJwV.png"/></div></figure><p id="c17c" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">该矩阵的对角线表示模型的类内泛化能力。你可以在训练阶段的不同阶段找到一个刚度等级矩阵的例子:</p><figure class="mt mu mv mw gt ju gh gi paragraph-image"><div class="gh gi mz"><img src="../Images/720e72dd9e95e91c0a77994743f93e77.png" data-original-src="https://miro.medium.com/v2/resize:fit:1062/format:webp/0*yndlywaqLP-alhxK.png"/></div></figure><p id="ecf8" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在早期阶段，同一类成员之间的刚度较高(因此出现红色对角线)。大多数单元提高它们的刚度，直到达到过度拟合点:刚度达到 0。</p><h1 id="8e87" class="le lf it bd lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb bi translated">刚度作为距离和学习率的函数</h1><p id="3c97" class="pw-post-body-paragraph kg kh it ki b kj mc kl km kn md kp kq kr me kt ku kv mf kx ky kz mg lb lc ld im bi translated">然后通过距离透镜研究刚度，它们区分两种距离:像素方向(在输入空间)和层方向(在表示空间)。</p><figure class="mt mu mv mw gt ju gh gi paragraph-image"><div class="gh gi na"><img src="../Images/b86e448ab611546b1522d6bb0ec80192.png" data-original-src="https://miro.medium.com/v2/resize:fit:976/format:webp/0*Rh_tJiLmmMGfRixz.png"/></div></figure><blockquote class="mi mj mk"><p id="d1c2" class="kg kh mh ki b kj kk kl km kn ko kp kq ml ks kt ku mm kw kx ky mn la lb lc ld im bi translated"><em class="it">图 9 中可见的一般模式是存在一个临界距离，在该距离内，输入数据点倾向于在梯度更新下一起移动，即具有正刚度。这适用于网络中的所有层，更深的层倾向于具有更小的硬磁畴尺寸。</em></p></blockquote><p id="f9de" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">作者将刚性区域定义为“当应用梯度更新时一起移动的数据空间区域”。</p><figure class="mt mu mv mw gt ju gh gi paragraph-image"><div class="gh gi nb"><img src="../Images/810925419f81c68e8ab4044328c20da4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1098/format:webp/0*i3-6bQ4Id5I3cSCS.png"/></div></figure><p id="dd68" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我们可以看到，较高的学习率增加了僵硬区域的大小，这表明较高的学习率有助于泛化。</p><h1 id="e972" class="le lf it bd lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb bi translated">tldr</h1><ul class=""><li id="9977" class="nc nd it ki b kj mc kn md kr ne kv nf kz ng ld nh ni nj nk bi translated">硬度量化了一组点上梯度更新对另一组点的影响程度</li><li id="ea6a" class="nc nd it ki b kj nl kn nm kr nn kv no kz np ld nh ni nj nk bi translated">僵硬与概括紧密相连</li><li id="0165" class="nc nd it ki b kj nl kn nm kr nn kv no kz np ld nh ni nj nk bi translated">当系统过度拟合时，刚度趋于 0</li><li id="a2a1" class="nc nd it ki b kj nl kn nm kr nn kv no kz np ld nh ni nj nk bi translated">更高的学习率增加了点一起移动的区域</li></ul></div><div class="ab cl nq nr hx ns" role="separator"><span class="nt bw bk nu nv nw"/><span class="nt bw bk nu nv nw"/><span class="nt bw bk nu nv"/></div><div class="im in io ip iq"><p id="25cc" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">补充资源:</p><ul class=""><li id="db86" class="nc nd it ki b kj kk kn ko kr nx kv ny kz nz ld nh ni nj nk bi translated">流形混合:通过内插隐藏状态更好的表现——<a class="ae kf" href="https://arxiv.org/abs/1806.05236" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/abs/1806.05236</a>(文章引用)</li></ul></div><div class="ab cl nq nr hx ns" role="separator"><span class="nt bw bk nu nv nw"/><span class="nt bw bk nu nv nw"/><span class="nt bw bk nu nv"/></div><div class="im in io ip iq"><p id="caf8" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><em class="mh">原载于 data-soup.github.io/blog/</em><a class="ae kf" href="https://data-soup.github.io/blog/" rel="noopener ugc nofollow" target="_blank"/></p></div></div>    
</body>
</html>