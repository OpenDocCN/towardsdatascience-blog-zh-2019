# 数据科学中最少的可行领域知识

> 原文：<https://towardsdatascience.com/minimum-viable-domain-knowledge-in-data-science-5be7bc99eca9?source=collection_archive---------15----------------------->

![](img/75d6099745f6fc4151c2ad27b3961d4e.png)

Image by [Gerd Altmann](https://pixabay.com/users/geralt-9301/?utm_source=link-attribution&utm_medium=referral&utm_campaign=image&utm_content=1632912) from [Pixabay](https://pixabay.com/?utm_source=link-attribution&utm_medium=referral&utm_campaign=image&utm_content=1632912)

大约十年前，当我完成物理学博士学位时，源源不断的物理学家转向金融、生物学和其他非常需要定量技能的领域。这种举动在很大程度上是由一种信念推动的，这种信念带有一丝傲慢，即一个人在攻读物理学博士学位时获得的建模专业知识可以转移到其他领域。这些举措有些成功，有些失败。据我所知，最终取得成功的物理学家是那些谦逊地认识到高效建模在很大程度上取决于某个领域的语义，并有毅力学习相关领域知识的人。

在我读完博士后的几年里，小溪变成了波浪。现在有一个从定量领域到各种工业和研究部门的大规模迁移。在完成博士学位后的某个时候，我也加入了这群领域移民——数据科学家。从我自己和我的同行的经验来看，我很确定十年前对我的物理学家同行来说是正确的，对数据科学家来说也是正确的。没有足够的领域知识，根本不可能进行有用的数据科学研究。

这不是一个新的认识。数据科学家最古老的原型来自 Drew Conway，他把数据科学家描绘成精通数学/统计、编程(黑客技能)和领域知识(实质性专业知识)的人。然而，尽管有大量的书籍、文章、课程和自助指南致力于数据科学的数学/统计和编程方面，但很少有关于数据科学的关键领域方面的文章。在这篇文章中，我将根据我和我的同龄人的经验，提出我自己对这个话题的观点。

自从“数据科学家”被[宣布为 21 世纪最性感的工作](https://hbr.org/2012/10/data-scientist-the-sexiest-job-of-the-21st-century)，数据科学对不同的人有着不同的含义。我认为数据科学是为复杂系统建立计算模型的行为，同时利用适度到大量的数据。领域知识为构建这些模型提供了背景。领域知识有三个主要的可区分但又相互关联的方面:问题上下文、信息上下文和数据收集机制。

**问题语境**

如果一个人不明白自己需要解决什么，那么他解决问题的机会就很小。但是理解数据科学中的问题上下文真正意味着什么呢？考虑推荐系统的例子。没有人愿意为了建推荐系统而建推荐系统；也许一个企业想增加收入，并相信建立一个推荐系统将有助于实现这一目标。

第一步是明确并正式确定目标，例如增加收入。数据科学家构建的模型将用于计算某些东西。数据科学家需要具备领域知识，以清楚地阐明领域特定的假设，这些假设可用于将问题目标与计算的数量相关联。在推荐系统的例子中，该模型可以计算用户对产品的亲和力。使用这种计算，可以向用户显示他最接近的产品(由模型计算)。这里的假设是，如果向用户展示他们最喜欢的产品，那么他们就有更大的可能性购买这些产品，从而增加企业的收入。

通常情况下，无法直接衡量一个模型是否实现了它的目标。相反，我们需要基于代理——评估指标——来做出判断。数据科学家需要能够提供推理(最好是定量的和数据驱动的),说明为什么选择的评估指标是合适的。通常，这归结为一个归属问题。例如，可以使用点击率作为在线产品推荐系统的评估指标。然后，我们需要一个合理的模型，将一部分收入归因于推荐产生的点击。这需要数据科学家了解用户如何浏览网上商店。

给定一个模型和一个数据集，人们只能计算出一定精度的数量。通常，建立具有中等至良好精度的模型相对容易，但是需要大量投资来提高超过这一点的精度。另一方面，实际需要的准确度在很大程度上取决于手头的问题。数据科学家应该非常清楚准确性的不断提高所产生的价值。在许多情况下，价值与准确度的关系图看起来像一个 s。如果低于某个阈值，模型将生成几乎为零或负值的值，之后会有一个范围，在该范围内，准确度的小增量将导致价值的成比例或指数回报，然后会有一个阈值，在该阈值之后，准确度的任何进一步增加都将导致回报递减。值对精度图的其他轮廓也是可能的。见[这篇阐述这个话题的优秀作品](/how-to-build-an-ai-moat-386c81a79900)。只有当数据科学家很好地理解了提高准确性带来的回报(即产生的额外价值)时，他才能就什么级别的准确性足够好做出明智的决策。

数据科学问题几乎从来都不是无约束优化问题，总是存在约束。这些限制中的一些本质上是技术性的，例如对可用计算资源量的上限。其他约束将是与域相关的，例如与公平性和隐私相关的约束或者与用户体验相关的约束。数据科学家需要具备领域知识，以理解这些约束设置的界限，并确保模型保持在这些界限内——否则，模型在生产中就没有什么希望了。

如果可能的话，数据科学家会理解问题的背景

*   将问题目标形式化，并将其与模型的计算量和评估指标联系起来
*   至少画一个价值与准确度的半定量图表
*   表明模型与问题的约束是一致的

**信息背景**

问题上下文处理模型的输出。信息语境处理其输入。围绕大数据和机器学习的大肆宣传已经在某些方面产生了[的想法](https://www.wired.com/2008/06/pb-theory/)，即人们可以简单地将原始数据放在算法的一端，而在另一端生成有意义的见解。**那个算法不存在** —深度学习或者其他。

深度学习相当成功的一个领域是图像识别(尽管考虑到深度神经网络对敌对攻击的敏感性，人们应该小心不要夸大这种情况)。如今，我们甚至有预先训练好的图像识别模型，人们可以下载并使用，只需很少甚至不需要微调。

让我们考虑一下这一成功背后的原因。图像总是由像素组成。像素具有颜色和强度的属性，并且它们总是排列在规则的网格上。出于图像识别的目的，我们希望答案在某些变换下不变，例如平移、旋转和光照变化。这些信息都不是从 math/stat 或黑客那里获得的。相反，它们是图像领域知识的一部分。在图像识别方面取得成功的机器学习模型，例如那些使用卷积神经网络的模型，就是建立在这一领域知识的基础上的。

从某种意义上说，图像识别是一个“容易”的领域。图像是几何对象，因此更容易形式化关于图像的领域知识。自然语言处理最近在建立通用模型方面也取得了一些成功。同样，虽然书面文本不像图像那样结构化，但人们仍然可以将单词识别为语言的基本实体，文档是单词的有序列表，即数据有一些自然的结构。

不幸的是，大多数领域中的数据并不具有这样的自然结构。对于大型跨国公司或研究机构来说，它们也不够大或有趣，不足以投资构建特定领域的算法。在这些领域中，由在战壕中工作的数据科学家来确定数据的信息上下文。

有人可能认为信息上下文只不过是数据中的结构。但远不止如此。算法的训练数据或模型的输入，如一组向量或张量，或有序的标记列表，它们都有结构。但是，它们本身没有任何信息上下文。信息上下文本质上由领域中可识别的概念组成——实体、关系及其属性。例如，像素(实体)、它们的颜色和亮度(属性)以及它们在网格中的相对位置(关系)形成了图像域中的信息上下文。数据科学家应该能够确定相关的信息上下文，并将其分配给数据。

强调信息背景的原因之一是可解释性。记住，可解释性总是特定于领域的。如果一个人不理解领域的概念，他就很难建立可解释的模型。但是，它超越了模型的可解释性，进入了模型的可改进性。尽管模型与数据一起工作，但建模发生在概念层面。对于一个名副其实的“数据科学家”来说，她应该能够设计出明智的策略来逐步改进模型，而不仅仅是基于试错法(hyper)的参数调整。没有对该领域的概念性理解，根本不可能设计出这样的策略。

如果可能的话，数据科学家会理解信息上下文

*   根据实体、关系及其属性，形式化领域的相关概念
*   将算法的训练数据集和结果模型的输入/输出映射到前面提到的概念形式。

**数据收集机制**

大多数(如果不是全部的话)数据驱动的建模方法对可用数据集相对于感兴趣的总体的代表性做出一些假设。在实践中，这种假设很少得到满足，这限制了人们对最终模型的信任。数据集的非代表性程度强烈地依赖于数据收集机制，而数据收集机制又依赖于领域。[在其他地方](/trust-and-interpretability-in-machine-learning-b7be41f01704)，我已经详细讨论了这个代表性假设在不同的场景中是如何被违反的。我将不在这里重复讨论。可以说，数据科学家需要对数据收集机制有一个清晰的理解，以理解模型输出的健壮性。

理解数据收集机制也很重要，还有另一个原因。一般来说，有两种方法可以提高模型性能— (i)更强大的算法，(ii)更高质量和/或更多数量的数据。数据科学家需要对数据收集机制有足够的了解，以确定是否有任何手段可以获得更高质量或更多的数据。

考虑这样一个场景，我们被要求对所有在一个房间中生成的图像进行分类(包括带标签的数据)。假设我们已经建立了一个相当精确的模型。基于更强大算法的任何进一步改进都需要在算法开发方面进行大量投资。然而，假设我们可以控制房间里的照明。在这种情况下，我们可能会调整照明以获得更好的图像质量，从而更好地建模，而无需在构建更强大的算法方面进行巨额投资。

如果可能的话，数据科学家会理解数据收集机制

*   确定由于数据集的非代表性而导致的模型的局限性
*   设计减轻非代表性问题的技术，例如，为显示随机预测制定勘探预算
*   建议调整数据收集机制，这可能会导致更好的模型性能。

—

在这篇文章的结尾，我将重申我在开头说过的话。一个人在定量领域学到的建模技能可以高度转移到其他领域。但是，你只能建立正确的模型，如果你知道什么是正确的模型。世界上所有的数学或黑客都不足以解决这个问题。花点时间去真正理解你要塑造的是什么，威尔。语境才是王道！