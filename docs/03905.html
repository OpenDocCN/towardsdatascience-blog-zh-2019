<html>
<head>
<title>Building a Personal assistant like Alexa through Ontology Based Knowledge Search</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">通过基于本体的知识搜索构建类似 Alexa 的个人助理</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/building-a-personal-assistant-like-alexa-open-domain-question-answering-7e9aa1e8ed90?source=collection_archive---------24-----------------------#2019-06-19">https://towardsdatascience.com/building-a-personal-assistant-like-alexa-open-domain-question-answering-7e9aa1e8ed90?source=collection_archive---------24-----------------------#2019-06-19</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><figure class="gl gn jo jp jq jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi jn"><img src="../Images/6c796bfce9433a65def5d61981c06b23.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*x7QHnsoWHF4WAtfh.jpg"/></div></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk">personal assistant battle</figcaption></figure><p id="7bbc" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">你有没有想过“如何打造一个私人助理？”像<a class="ae la" href="https://www.alexa.com/" rel="noopener ugc nofollow" target="_blank"> Alexa </a>、<a class="ae la" href="https://assistant.google.com/#?modal_active=none" rel="noopener ugc nofollow" target="_blank">谷歌个人助理</a>或<a class="ae la" href="https://store.google.com/product/google_home" rel="noopener ugc nofollow" target="_blank">谷歌主页</a>覆盖多个意图以及开放领域问答视角。</p><p id="882e" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">在这篇文章中，我将尝试在更高的层次上介绍基于本体的问答知识搜索。</p><blockquote class="lb lc ld"><p id="a93f" class="kc kd le ke b kf kg kh ki kj kk kl km lf ko kp kq lg ks kt ku lh kw kx ky kz ij bi translated">有两种广泛知识搜索方法</p></blockquote><ol class=""><li id="e5ba" class="li lj iq ke b kf kg kj kk kn lk kr ll kv lm kz ln lo lp lq bi translated">基于本体的知识搜索(主要通过知识图)</li><li id="d2bd" class="li lj iq ke b kf lr kj ls kn lt kr lu kv lv kz ln lo lp lq bi translated">基于开放领域问答的知识搜索</li></ol><p id="a8ed" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">在这篇文章中，我们将在更广的层面上讨论基于本体的知识搜索。</p><p id="772f" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">构建像<a class="ae la" href="https://www.alexa.com/" rel="noopener ugc nofollow" target="_blank"> alexa </a>这样的个人助理需要各种构建模块，我们将在本文中介绍核心组件的高级架构。并将在接下来的系列中深入探讨。</p><blockquote class="lb lc ld"><p id="8986" class="kc kd le ke b kf kg kh ki kj kk kl km lf ko kp kq lg ks kt ku lh kw kx ky kz ij bi translated">积木</p></blockquote><ol class=""><li id="82f9" class="li lj iq ke b kf kg kj kk kn lk kr ll kv lm kz ln lo lp lq bi translated">可扩展的<a class="ae la" href="https://www.alexa.com/" rel="noopener ugc nofollow" target="_blank">知识图</a></li><li id="e7b3" class="li lj iq ke b kf lr kj ls kn lt kr lu kv lv kz ln lo lp lq bi translated">从结构化和非结构化来源到<a class="ae la" href="https://en.wikipedia.org/wiki/Knowledge_Graph" rel="noopener ugc nofollow" target="_blank">知识图</a>的知识消耗</li><li id="632f" class="li lj iq ke b kf lr kj ls kn lt kr lu kv lv kz ln lo lp lq bi translated">结构化查询的自然语言理解</li><li id="c23b" class="li lj iq ke b kf lr kj ls kn lt kr lu kv lv kz ln lo lp lq bi translated">自然语言生成来回答问题</li><li id="28ca" class="li lj iq ke b kf lr kj ls kn lt kr lu kv lv kz ln lo lp lq bi translated">语音转文本</li><li id="d2b8" class="li lj iq ke b kf lr kj ls kn lt kr lu kv lv kz ln lo lp lq bi translated">文本到语音</li><li id="7dbb" class="li lj iq ke b kf lr kj ls kn lt kr lu kv lv kz ln lo lp lq bi translated">文本 2 内容模块</li></ol><blockquote class="lb lc ld"><p id="618a" class="kc kd le ke b kf kg kh ki kj kk kl km lf ko kp kq lg ks kt ku lh kw kx ky kz ij bi translated">问答模块的高级架构(还不包括家庭自动化等)。</p></blockquote><figure class="lx ly lz ma gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi lw"><img src="../Images/b93fbd76ef20daba14a4d860990648a7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*sbAR0BSuof6bgKUcv6zNUA.png"/></div></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk">Question Answering Architecture</figcaption></figure><p id="9358" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">该架构非常简单明了，目前还不包括可扩展性，但包含了问题回答模块的核心组件，如“谷歌个人助理”或“Alexa”。</p><blockquote class="lb lc ld"><p id="a8f5" class="kc kd le ke b kf kg kh ki kj kk kl km lf ko kp kq lg ks kt ku lh kw kx ky kz ij bi translated"><strong class="ke ir"> NLU 层</strong></p></blockquote><p id="775d" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">NLU 层的主要目的是从文本中构建图形查询。这是基于本体的知识搜索的瓶颈之一，即从自由文本流中进行结构化查询(在 GQL 中)(开放领域问答试图以神经方式解决这个问题)</p><blockquote class="lb lc ld"><p id="e4f9" class="kc kd le ke b kf kg kh ki kj kk kl km lf ko kp kq lg ks kt ku lh kw kx ky kz ij bi translated">机器翻译块</p></blockquote><p id="4853" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">在语言不可知知识图的情况下，这也不是强制性的。有两种方法可以建立语言不可知和语言感知的知识图。大多数公共知识图是语言不可知的(超出了本文的范围。</p><blockquote class="lb lc ld"><p id="8a8c" class="kc kd le ke b kf kg kh ki kj kk kl km lf ko kp kq lg ks kt ku lh kw kx ky kz ij bi translated">步伐</p></blockquote><ol class=""><li id="e26b" class="li lj iq ke b kf kg kj kk kn lk kr ll kv lm kz ln lo lp lq bi translated">为支持的每种语言训练语音到文本模型</li><li id="1250" class="li lj iq ke b kf lr kj ls kn lt kr lu kv lv kz ln lo lp lq bi translated">将结构化知识(主语、谓语、宾语)如<a class="ae la" href="https://www.wikidata.org/wiki/Wikidata:Main_Page" rel="noopener ugc nofollow" target="_blank">维基数据</a>或 dbpedia(抓取的维基百科)存储到<a class="ae la" href="https://en.wikipedia.org/wiki/Knowledge_Graph" rel="noopener ugc nofollow" target="_blank">知识图</a>中</li><li id="99e6" class="li lj iq ke b kf lr kj ls kn lt kr lu kv lv kz ln lo lp lq bi translated">将来自非结构化新闻文章和其他来源的知识丰富并存储到知识图中。</li><li id="39d1" class="li lj iq ke b kf lr kj ls kn lt kr lu kv lv kz ln lo lp lq bi translated"><a class="ae la" href="https://medium.com/@brijrajsingh/chat-bots-designing-intents-and-entities-for-your-nlp-models-35c385b7730d" rel="noopener"> Text2Intent </a>层理解(分类)用户意图</li><li id="c655" class="li lj iq ke b kf lr kj ls kn lt kr lu kv lv kz ln lo lp lq bi translated">构建<a class="ae la" href="https://en.wikipedia.org/wiki/Natural-language_understanding" rel="noopener ugc nofollow" target="_blank"> NLU </a>(自然语言理解)层，以理解用户查询或命令或意图(查看<a class="ae la" href="https://rasa.com/" rel="noopener ugc nofollow" target="_blank"> rasa </a>)</li><li id="d177" class="li lj iq ke b kf lr kj ls kn lt kr lu kv lv kz ln lo lp lq bi translated">面向意向图查询语言(GQL)的知识图查询适配器层</li><li id="0fb1" class="li lj iq ke b kf lr kj ls kn lt kr lu kv lv kz ln lo lp lq bi translated">与家庭自动化或其他第三方应用程序的集成挂钩</li><li id="68be" class="li lj iq ke b kf lr kj ls kn lt kr lu kv lv kz ln lo lp lq bi translated"><a class="ae la" href="https://en.wikipedia.org/wiki/Natural-language_generation" rel="noopener ugc nofollow" target="_blank"> NLG(自然语言生成)</a>层</li><li id="c3bb" class="li lj iq ke b kf lr kj ls kn lt kr lu kv lv kz ln lo lp lq bi translated">对话聊天机器人设计</li><li id="3376" class="li lj iq ke b kf lr kj ls kn lt kr lu kv lv kz ln lo lp lq bi translated">机器翻译层将英语翻译成支持的语言(可选)。</li><li id="ea5e" class="li lj iq ke b kf lr kj ls kn lt kr lu kv lv kz ln lo lp lq bi translated"><a class="ae la" href="https://en.wikipedia.org/wiki/Speech_synthesis" rel="noopener ugc nofollow" target="_blank">支持的每种语言的 Text2Speech </a>型号</li></ol><blockquote class="mb"><p id="e266" class="mc md iq bd me mf mg mh mi mj mk kz dk translated">参考故事“<a class="ae la" href="https://medium.com/@iitr.samrat/demystify-wiki-ontology-and-knowledge-graph-part-1-ba919b0d9ce4?source=friends_link&amp;sk=c86df3f4bad504f9ef3f1f69697735e4" rel="noopener">揭秘 wiki 本体</a> -part1”了解 wiki 本体，这有助于将 wiki 数据摄取到我们选择的<a class="ae la" href="https://en.wikipedia.org/wiki/Knowledge_Graph" rel="noopener ugc nofollow" target="_blank">知识图</a>中。</p></blockquote><h2 id="c59e" class="ml mm iq bd mn mo mp dn mq mr ms dp mt kn mu mv mw kr mx my mz kv na nb nc nd bi translated">个人助理的高级架构(基于本体的知识搜索)</h2><figure class="lx ly lz ma gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi ne"><img src="../Images/729515e085345b6567468bbc1cbcd6ff.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*1ll-y9JtV7q-81CD_ZRFeA.png"/></div></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk">Personal assistant architecture</figcaption></figure><p id="0f19" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">上面是一个个人助理的高级架构，它不同于一个纯粹的开放领域的问题回答助理，因为它并不总是我们想问的问题。</p><blockquote class="mb"><p id="834a" class="mc md iq bd me mf nf ng nh ni nj kz dk translated">我们还希望我们的助手“预订出租车”、“预订餐馆”、“告诉我我的约会”等。所以我们需要额外的一层意图分类。</p></blockquote><p id="dfe3" class="pw-post-body-paragraph kc kd iq ke b kf nk kh ki kj nl kl km kn nm kp kq kr nn kt ku kv no kx ky kz ij bi translated">让我们逐一探索每个模块，并深入了解可用的选项。前往<a class="ae la" href="https://medium.com/@iitr.samrat/demystify-wiki-ontology-and-knowledge-graph-part-1-ba919b0d9ce4" rel="noopener">揭开维基本体和知识图的神秘面纱——第一部分</a>，这将有助于从<a class="ae la" href="https://www.wikidata.org/wiki/Wikidata:Main_Page" rel="noopener ugc nofollow" target="_blank">维基数据</a>中填充知识图。</p><h2 id="1508" class="ml mm iq bd mn mo np dn mq mr nq dp mt kn nr mv mw kr ns my mz kv nt nb nc nd bi translated">NLU 层</h2><p id="03c3" class="pw-post-body-paragraph kc kd iq ke b kf nu kh ki kj nv kl km kn nw kp kq kr nx kt ku kv ny kx ky kz ij bi translated">从上面的架构可以看出，NLU 层仅仅是为了理解开放领域的问题而构建的。文本 2 内容层过滤并仅将开放域问题传递给 NLU 层。</p><blockquote class="mb"><p id="028b" class="mc md iq bd me mf nf ng nh ni nj kz dk translated"><strong class="ak">让我们使用 Stanford CoreNLP 来探索一个基于模式的简单 NLU 层，这将是一个</strong> <a class="ae la" href="https://grpc.io/" rel="noopener ugc nofollow" target="_blank"> <strong class="ak"> grpc </strong> </a> <strong class="ak">微服务，并使用</strong> <a class="ae la" href="https://developers.google.com/protocol-buffers/docs/overview" rel="noopener ugc nofollow" target="_blank"> <strong class="ak"> google 协议缓冲区</strong> </a> <strong class="ak">来交换消息。</strong></p></blockquote><h2 id="c052" class="ml mm iq bd mn mo mp dn mq mr ms dp mt kn mu mv mw kr mx my mz kv na nb nc nd bi translated">斯坦福大学 NLU 分校</h2><p id="0530" class="pw-post-body-paragraph kc kd iq ke b kf nu kh ki kj nv kl km kn nw kp kq kr nx kt ku kv ny kx ky kz ij bi translated">让我们看看几个与电影相关的问题和相应的<a class="ae la" href="https://universaldependencies.org/format.html" rel="noopener ugc nofollow" target="_blank">集</a>集。</p><blockquote class="mb"><p id="0fab" class="mc md iq bd me mf nf ng nh ni nj kz dk translated">电影《阿拉达纳》的导演是谁？</p><p id="5ada" class="mc md iq bd me mf nf ng nh ni nj kz dk translated">电影《肖莱》的导演是谁？</p><p id="3650" class="mc md iq bd me mf nf ng nh ni nj kz dk translated">电影《肖莱》的制片人是谁？</p></blockquote><p id="60a1" class="pw-post-body-paragraph kc kd iq ke b kf nk kh ki kj nl kl km kn nm kp kq kr nn kt ku kv no kx ky kz ij bi translated">这类问题可以归为一组，我们问的是在电影中扮演特定角色的人。</p><blockquote class="mb"><p id="aca6" class="mc md iq bd me mf nf ng nh ni nj kz dk translated">对应<a class="ae la" href="https://universaldependencies.org/format.html" rel="noopener ugc nofollow" target="_blank"> conll </a>文集</p></blockquote><figure class="oa ob oc od oe jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi nz"><img src="../Images/2939dba7f662bb2a32e927bef7a23ec4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*3iAxObaSdbGXE1Jwphhixw.png"/></div></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk"><a class="ae la" href="https://universaldependencies.org/format.html" rel="noopener ugc nofollow" target="_blank">conll</a> corpus (9 columns for each sentence)</figcaption></figure><blockquote class="mb"><p id="9f38" class="mc md iq bd me mf mg mh mi mj mk kz dk translated">正如我们在上面看到的，在<a class="ae la" href="https://universaldependencies.org/format.html" rel="noopener ugc nofollow" target="_blank"> conll </a>语料库中的第二列是<a class="ae la" href="https://en.wikipedia.org/wiki/Named-entity_recognition" rel="noopener ugc nofollow" target="_blank"> NER </a>标签和使用<a class="ae la" href="https://nlp.stanford.edu/software/regexner.html" rel="noopener ugc nofollow" target="_blank"> regexner </a>分类为标题(自定义 NER)的导演、制片人等。</p></blockquote><figure class="oa ob oc od oe jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi of"><img src="../Images/fc07df68702564dae87f71e8ffb8a152.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*p3Ah0elJChPNBS0eyB7LiQ.png"/></div></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk">Modified architecture add a layer before NLU</figcaption></figure><p id="5467" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">如果你把领域压缩得足够小，以理解每个类别中的问题，比如电影问题，regexner 就很棒，如图所示。</p><p id="45e4" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">人们可以把 regexner 放到斯坦福 corenlp 管道中，如下所示。</p><pre class="lx ly lz ma gt og oh oi oj aw ok bi"><span id="6e68" class="ml mm iq oh b gy ol om l on oo">Properties props = new Properties();<br/>props.put("annotators", "tokenize, ssplit, pos, lemma, ner, regexner");<br/>props.put("regexner.mapping", "org/foo/resources/jg-regexner.txt");<br/>StanfordCoreNLP pipeline = new StanfordCoreNLP(props);</span></pre><h2 id="f10e" class="ml mm iq bd mn mo np dn mq mr nq dp mt kn nr mv mw kr ns my mz kv nt nb nc nd bi translated"><a class="ae la" href="https://nlp.stanford.edu/software/tokensregex.html" rel="noopener ugc nofollow" target="_blank"> TokenRegex </a>文件</h2><p id="d62d" class="pw-post-body-paragraph kc kd iq ke b kf nu kh ki kj nv kl km kn nw kp kq kr nx kt ku kv ny kx ky kz ij bi translated">TokensRegex 是一个通用框架，包含在 Stanford CoreNLP 中，用于定义文本(标记序列)的模式，并将其映射到表示为 Java 对象的语义对象。(摘自 S<a class="ae la" href="https://nlp.stanford.edu/software/tokensregex.html" rel="noopener ugc nofollow" target="_blank">tanford Corenlp token regex</a>)</p><pre class="lx ly lz ma gt og oh oi oj aw ok bi"><span id="b12b" class="ml mm iq oh b gy ol om l on oo">//author samrat.saha<br/>//tokensregex.extractor.rules</span><span id="7432" class="ml mm iq oh b gy op om l on oo">ner = { type: "CLASS", value: "edu.stanford.nlp.ling.CoreAnnotations$NamedEntityTagAnnotation" }</span><span id="fcbd" class="ml mm iq oh b gy op om l on oo">tag = { type: "CLASS", value: "edu.stanford.nlp.ling.CoreAnnotations$PartOfSpeechAnnotation" }</span><span id="bf42" class="ml mm iq oh b gy op om l on oo">normalized = { type: "CLASS", value: "edu.stanford.nlp.ling.CoreAnnotations$NormalizedNamedEntityTagAnnotation" }</span><span id="fcbe" class="ml mm iq oh b gy op om l on oo">ENV.defaultStringPatternFlags = 2</span><span id="3bea" class="ml mm iq oh b gy op om l on oo">{</span><span id="2d0f" class="ml mm iq oh b gy op om l on oo">ruleType: "tokens",</span><span id="e62f" class="ml mm iq oh b gy op om l on oo">pattern: ( ( [ { tag:WP } ] ) ( [ { ner:O} ]* ) ([ { ner:TITLE} ]+ ) ( [ { ner:O} ]* ) ( [ { ner:MOVIE} ]+  ) ( [ { tag:NNP } ]+ )   ),</span><span id="cb14" class="ml mm iq oh b gy op om l on oo">result: Format( "MOVIE_ROLE %s %s %s %s", "##", $$6.text, "##", $$3.text),</span><span id="d7b7" class="ml mm iq oh b gy op om l on oo">stage: 1</span><span id="8eb6" class="ml mm iq oh b gy op om l on oo">}</span></pre><h2 id="b2d1" class="ml mm iq bd mn mo np dn mq mr nq dp mt kn nr mv mw kr ns my mz kv nt nb nc nd bi translated">Java 代码</h2><pre class="lx ly lz ma gt og oh oi oj aw ok bi"><span id="7e39" class="ml mm iq oh b gy ol om l on oo"><strong class="oh ir">public</strong> <strong class="oh ir">static</strong> <strong class="oh ir">void</strong> main(String[] args) <strong class="oh ir">throws</strong> Exception {</span><span id="2e11" class="ml mm iq oh b gy op om l on oo">String rules = "..../src/main/resources/tokenregexrule.txt";</span><span id="4a50" class="ml mm iq oh b gy op om l on oo">String exampleQuestions = IOUtils.<em class="le">stringFromFile</em>("src/main/resources/question.txt");</span><span id="e2d8" class="ml mm iq oh b gy op om l on oo">//pipeline have regexner as well as statistical ner</span><span id="25ba" class="ml mm iq oh b gy op om l on oo">Properties properties = PropertiesUtils.<em class="le">asProperties</em>("annotators", "tokenize,ssplit,pos,lemma,ner,regexner");</span><span id="df18" class="ml mm iq oh b gy op om l on oo">properties.setProperty("ssplit.eolonly", "true");</span><span id="e7ab" class="ml mm iq oh b gy op om l on oo">properties.setProperty("regexner.mapping", "src/main/resources/movieregex.txt");</span><span id="eb7f" class="ml mm iq oh b gy op om l on oo">//tokenregex rule file from above<br/>properties.setProperty("tokensregex.extractor.rules", rules);</span><span id="f7f4" class="ml mm iq oh b gy op om l on oo">StanfordCoreNLP pipeline = <strong class="oh ir">new</strong> StanfordCoreNLP(properties);</span><span id="584e" class="ml mm iq oh b gy op om l on oo">Annotation annotation = <strong class="oh ir">new</strong> Annotation(exampleQuestions);</span><span id="9232" class="ml mm iq oh b gy op om l on oo"><em class="le">env</em> = TokenSequencePattern.<em class="le">getNewEnv</em>();</span><span id="9d79" class="ml mm iq oh b gy op om l on oo"><em class="le">extractor</em> = CoreMapExpressionExtractor.<em class="le">createExtractorFromFiles</em>(<em class="le">env</em>, properties.getProperty("tokensregex.extractor.rules"));</span><span id="a254" class="ml mm iq oh b gy op om l on oo">pipeline.annotate(annotation);</span><span id="70e4" class="ml mm iq oh b gy op om l on oo"><em class="le">extractConcepts</em>(annotation);</span><span id="8da1" class="ml mm iq oh b gy op om l on oo">}</span></pre><h2 id="2fa7" class="ml mm iq bd mn mo np dn mq mr nq dp mt kn nr mv mw kr ns my mz kv nt nb nc nd bi translated">使用 tokenregex 提取概念代码</h2><p id="237c" class="pw-post-body-paragraph kc kd iq ke b kf nu kh ki kj nv kl km kn nw kp kq kr nx kt ku kv ny kx ky kz ij bi translated">代码会提取主语宾语和我们说的概念，这个叫做<a class="ae la" href="https://en.wikipedia.org/wiki/Relationship_extraction" rel="noopener ugc nofollow" target="_blank">关系提取</a>(主语、谓语、宾语)。</p><p id="be50" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">在知识图中，主体和客体将是实体，谓词将是关系。</p><pre class="lx ly lz ma gt og oh oi oj aw ok bi"><span id="96de" class="ml mm iq oh b gy ol om l on oo"><strong class="oh ir">public</strong> <strong class="oh ir">static</strong> <strong class="oh ir">void</strong> extractConcepts(Annotation annotation) {</span><span id="d29b" class="ml mm iq oh b gy op om l on oo"><strong class="oh ir">boolean</strong> flag = Boolean.<strong class="oh ir"><em class="le">FALSE</em></strong>;</span><span id="af1d" class="ml mm iq oh b gy op om l on oo">List&lt;CoreMap&gt; sentences = annotation.get(CoreAnnotations.SentencesAnnotation.<strong class="oh ir">class</strong>);</span><span id="195c" class="ml mm iq oh b gy op om l on oo"><strong class="oh ir">int</strong> id = 0;</span><span id="01c6" class="ml mm iq oh b gy op om l on oo"><strong class="oh ir">for</strong> (CoreMap sentence : sentences) {</span><span id="25fd" class="ml mm iq oh b gy op om l on oo">System.<strong class="oh ir"><em class="le">out</em></strong>.println(sentence.toString());</span><span id="7dfb" class="ml mm iq oh b gy op om l on oo">List&lt;CoreLabel&gt; tokens = sentence.get(CoreAnnotations.TokensAnnotation.<strong class="oh ir">class</strong>);</span><span id="0582" class="ml mm iq oh b gy op om l on oo">id++;</span><span id="99fe" class="ml mm iq oh b gy op om l on oo">List&lt;MatchedExpression&gt; matchedExpressions = <em class="le">extractor</em>.extractExpressions(sentence);</span><span id="fd5d" class="ml mm iq oh b gy op om l on oo"><strong class="oh ir">for</strong> (MatchedExpression matched:matchedExpressions) {</span><span id="c447" class="ml mm iq oh b gy op om l on oo">// Print out matched text and value</span><span id="b6d0" class="ml mm iq oh b gy op om l on oo">System.<strong class="oh ir"><em class="le">out</em></strong>.println("--------------------");</span><span id="f42f" class="ml mm iq oh b gy op om l on oo">//System.out.println(matched.getText());</span><span id="3a09" class="ml mm iq oh b gy op om l on oo">//System.out.println(matched.getValue().toString());</span><span id="13f6" class="ml mm iq oh b gy op om l on oo">String subj = "";</span><span id="29ec" class="ml mm iq oh b gy op om l on oo">String obj = "";</span><span id="f806" class="ml mm iq oh b gy op om l on oo">CoreMap cm = matched.getAnnotation();</span><span id="6ded" class="ml mm iq oh b gy op om l on oo">String matchedText = matched.getValue().toString();</span><span id="23e5" class="ml mm iq oh b gy op om l on oo">String matchedTextMod = matchedText.replace("(", " ").replace(")", "").replace("STRING", "");</span><span id="3c5c" class="ml mm iq oh b gy op om l on oo">StringTokenizer st = <strong class="oh ir">new</strong> StringTokenizer(matchedTextMod);</span><span id="1487" class="ml mm iq oh b gy op om l on oo">String predicate = st.nextToken("##").trim();</span><span id="ebc6" class="ml mm iq oh b gy op om l on oo">subj = st.nextToken("##").trim();</span><span id="5c0a" class="ml mm iq oh b gy op om l on oo">obj = st.nextToken("##").trim().replace("-LRB-", "(").replace("-RRB-", ")");</span><span id="b62c" class="ml mm iq oh b gy op om l on oo"><strong class="oh ir">if</strong>(obj.substring(0, obj.length()/2).replaceAll("\\s|\\W", "").equalsIgnoreCase(obj.substring(obj.length()/2, obj.length()).replaceAll("\\s|\\W", ""))){</span><span id="0bbf" class="ml mm iq oh b gy op om l on oo">obj = obj.substring(0, obj.length()/2);</span><span id="fb91" class="ml mm iq oh b gy op om l on oo">}</span><span id="2058" class="ml mm iq oh b gy op om l on oo">System.<strong class="oh ir"><em class="le">out</em></strong>.println(subj + "-&gt;" + predicate + "-&gt;" + obj);</span><span id="320f" class="ml mm iq oh b gy op om l on oo">System.<strong class="oh ir"><em class="le">out</em></strong>.println("--------------------\n");</span><span id="6e98" class="ml mm iq oh b gy op om l on oo">}</span><span id="611a" class="ml mm iq oh b gy op om l on oo">}</span><span id="575d" class="ml mm iq oh b gy op om l on oo">annotation = <strong class="oh ir">null</strong>;</span><span id="6883" class="ml mm iq oh b gy op om l on oo"><strong class="oh ir">return</strong>;</span><span id="523e" class="ml mm iq oh b gy op om l on oo">}</span></pre><blockquote class="lb lc ld"><p id="5e8b" class="kc kd le ke b kf kg kh ki kj kk kl km lf ko kp kq lg ks kt ku lh kw kx ky kz ij bi translated"><strong class="ke ir">输出:</strong></p></blockquote><pre class="lx ly lz ma gt og oh oi oj aw ok bi"><span id="eca3" class="ml mm iq oh b gy ol om l on oo">Who is the director of the film Aradhana ?</span><span id="0f09" class="ml mm iq oh b gy op om l on oo">--------------------</span><span id="9a9a" class="ml mm iq oh b gy op om l on oo">Aradhana-&gt;MOVIE_ROLE-&gt;director</span><span id="1b18" class="ml mm iq oh b gy op om l on oo">--------------------</span><span id="223c" class="ml mm iq oh b gy op om l on oo">Who is the director of the film Sholay ?</span><span id="3585" class="ml mm iq oh b gy op om l on oo">--------------------</span><span id="1132" class="ml mm iq oh b gy op om l on oo">Sholay-&gt;MOVIE_ROLE-&gt;director</span><span id="2b25" class="ml mm iq oh b gy op om l on oo">--------------------</span><span id="363b" class="ml mm iq oh b gy op om l on oo">Who is the producer of the film Sholay?</span><span id="adf9" class="ml mm iq oh b gy op om l on oo">--------------------</span><span id="5d6e" class="ml mm iq oh b gy op om l on oo">Sholay-&gt;MOVIE_ROLE-&gt;producer</span><span id="8f0c" class="ml mm iq oh b gy op om l on oo">--------------------</span></pre><p id="cf7c" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">可以注意到，这对于下面这样的复杂问题是绝对不够的。</p><p id="d4ed" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">多主题问题</p><blockquote class="mb"><p id="e180" class="mc md iq bd me mf nf ng nh ni nj kz dk translated">汤姆·克鲁斯和布拉德·皮特主演的电影有哪些？</p></blockquote><h2 id="2b33" class="ml mm iq bd mn mo mp dn mq mr ms dp mt kn mu mv mw kr mx my mz kv na nb nc nd bi translated">统计 CRF 关系提取器</h2><p id="2949" class="pw-post-body-paragraph kc kd iq ke b kf nu kh ki kj nv kl km kn nw kp kq kr nx kt ku kv ny kx ky kz ij bi translated">Stanford coreNLP 还支持<a class="ae la" href="https://nlp.stanford.edu/software/relationExtractor.html" rel="noopener ugc nofollow" target="_blank">关系提取</a>，可用于从简单问题中提取主语、宾语和谓语。</p><p id="e388" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">人们需要为他们感兴趣的关系注释 conll 语料库文件，例如参见下面的 conll 语料库。</p><figure class="lx ly lz ma gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi oq"><img src="../Images/fe048a00f79ba7e8f6f55a8b4a6b5f90.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*lBD7LAHYJDl5ILjS-r2hsg.png"/></div></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk">movie role relation annotation</figcaption></figure><p id="d3d6" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">上面的注释说，在令牌 3 和 7 之间存在一个我们正在询问的 MOVIE_ROLE 关系。</p><blockquote class="mb"><p id="60d7" class="mc md iq bd me mf nf ng nh ni nj kz dk translated">也看到如何分类阿拉达纳被归类为我们需要为电影数据集定制 NER 模型的人。训练一个 NER 模型超出了这些博客的范围。</p></blockquote><p id="bfa7" class="pw-post-body-paragraph kc kd iq ke b kf nk kh ki kj nl kl km kn nm kp kq kr nn kt ku kv no kx ky kz ij bi translated">使用带注释的数据集训练一个定制模型，如这里提到的<a class="ae la" href="https://stackoverflow.com/questions/34922368/how-to-make-the-custom-relationshipextractor-understand-custom-entities" rel="noopener ugc nofollow" target="_blank"/>。</p><p id="072b" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">一旦模型训练完毕，加载模型并使用下面的代码从简单的问题中提取主客体谓词。</p><pre class="lx ly lz ma gt og oh oi oj aw ok bi"><span id="5377" class="ml mm iq oh b gy ol om l on oo"><strong class="oh ir">public</strong> CustomRelationExtractAnnotator(Properties props){</span><span id="aaeb" class="ml mm iq oh b gy op om l on oo"><em class="le"><br/>verbose</em> = Boolean.<em class="le">parseBoolean</em>(props.getProperty("sup.relation.verbose", "false"));</span><span id="e98a" class="ml mm iq oh b gy op om l on oo">//Load the model<br/>String relationModel = props.getProperty("sup.relation.model", "model/simple-question-relation-model.ser");</span><span id="d527" class="ml mm iq oh b gy op om l on oo"><strong class="oh ir">try</strong> {</span><span id="264f" class="ml mm iq oh b gy op om l on oo">Extractor entityExtractor = <strong class="oh ir">new</strong> SimpleQuestionEntityExtractor();</span><span id="dfa3" class="ml mm iq oh b gy op om l on oo">BasicRelationExtractor relationExtractor = BasicRelationExtractor.<em class="le">load</em>(relationModel);</span><span id="96bc" class="ml mm iq oh b gy op om l on oo">System.<strong class="oh ir"><em class="le">out</em></strong>.println("Loading relation model " + relationModel + " and the features are " + relationExtractor.featureFactory);</span><span id="6a1e" class="ml mm iq oh b gy op om l on oo">mr = MachineReading.<em class="le">makeMachineReadingForAnnotation</em>(<strong class="oh ir">new</strong> SimpleQuestionConllReader(), entityExtractor, relationExtractor, <strong class="oh ir">null</strong>, <strong class="oh ir">null</strong>,</span><span id="145d" class="ml mm iq oh b gy op om l on oo"><strong class="oh ir">null</strong>, <strong class="oh ir">true</strong>, <em class="le">verbose</em>);</span><span id="850f" class="ml mm iq oh b gy op om l on oo">} <strong class="oh ir">catch</strong>(Exception e){</span><span id="badf" class="ml mm iq oh b gy op om l on oo">e.printStackTrace();</span><span id="debf" class="ml mm iq oh b gy op om l on oo"><strong class="oh ir">throw</strong> <strong class="oh ir">new</strong> RuntimeException(e);</span><span id="2039" class="ml mm iq oh b gy op om l on oo">}</span><span id="90f2" class="ml mm iq oh b gy op om l on oo">}</span><span id="cca4" class="ml mm iq oh b gy op om l on oo">@Override</span><span id="3e43" class="ml mm iq oh b gy op om l on oo"><strong class="oh ir">public</strong> <strong class="oh ir">void</strong> annotate(Annotation annotation) {</span><span id="28b9" class="ml mm iq oh b gy op om l on oo">// extract entities and relations</span><span id="5c4a" class="ml mm iq oh b gy op om l on oo">Annotation output = mr.annotate(annotation);</span><span id="a5bb" class="ml mm iq oh b gy op om l on oo">// transfer entities/relations back to the original annotation</span><span id="269a" class="ml mm iq oh b gy op om l on oo">List&lt;CoreMap&gt; outputSentences = output.get(SentencesAnnotation.<strong class="oh ir">class</strong>);</span><span id="3b1c" class="ml mm iq oh b gy op om l on oo">List&lt;CoreMap&gt; origSentences = annotation.get(SentencesAnnotation.<strong class="oh ir">class</strong>);</span><span id="f168" class="ml mm iq oh b gy op om l on oo"><strong class="oh ir">for</strong>(<strong class="oh ir">int</strong> i = 0; i &lt; outputSentences.size(); i ++){</span><span id="5e9b" class="ml mm iq oh b gy op om l on oo">CoreMap outSent = outputSentences.get(i);</span><span id="be08" class="ml mm iq oh b gy op om l on oo">CoreMap origSent = origSentences.get(i);</span><span id="676f" class="ml mm iq oh b gy op om l on oo">// set entities</span><span id="1b4e" class="ml mm iq oh b gy op om l on oo">List&lt;EntityMention&gt; entities = outSent.get(MachineReadingAnnotations.EntityMentionsAnnotation.<strong class="oh ir">class</strong>);</span><span id="28c4" class="ml mm iq oh b gy op om l on oo">origSent.set(MachineReadingAnnotations.EntityMentionsAnnotation.<strong class="oh ir">class</strong>, entities);</span><span id="585c" class="ml mm iq oh b gy op om l on oo"><strong class="oh ir">if</strong>(<em class="le">verbose</em> &amp;&amp; entities != <strong class="oh ir">null</strong>){</span><span id="70d6" class="ml mm iq oh b gy op om l on oo">System.<strong class="oh ir"><em class="le">err</em></strong>.println("Extracted the following entities:");</span><span id="57af" class="ml mm iq oh b gy op om l on oo"><strong class="oh ir">for</strong>(EntityMention e: entities){</span><span id="2bfb" class="ml mm iq oh b gy op om l on oo">System.<strong class="oh ir"><em class="le">err</em></strong>.println("\t" + e);</span><span id="281b" class="ml mm iq oh b gy op om l on oo">}</span><span id="a263" class="ml mm iq oh b gy op om l on oo">}</span><span id="7015" class="ml mm iq oh b gy op om l on oo">// set relations</span><span id="7758" class="ml mm iq oh b gy op om l on oo">List&lt;RelationMention&gt; relations = outSent.get(MachineReadingAnnotations.RelationMentionsAnnotation.<strong class="oh ir">class</strong>);</span><span id="3074" class="ml mm iq oh b gy op om l on oo">origSent.set(MachineReadingAnnotations.RelationMentionsAnnotation.<strong class="oh ir">class</strong>, relations);</span><span id="eca5" class="ml mm iq oh b gy op om l on oo"><strong class="oh ir">if</strong>(<em class="le">verbose</em> &amp;&amp; relations != <strong class="oh ir">null</strong>){</span><span id="53ca" class="ml mm iq oh b gy op om l on oo">System.<strong class="oh ir"><em class="le">err</em></strong>.println("Extracted the following relations:");</span><span id="8e5b" class="ml mm iq oh b gy op om l on oo"><strong class="oh ir">for</strong>(RelationMention r: relations){</span><span id="e0ce" class="ml mm iq oh b gy op om l on oo"><strong class="oh ir">if</strong>(! r.getType().equals(RelationMention.<strong class="oh ir"><em class="le">UNRELATED</em></strong>)){</span><span id="98eb" class="ml mm iq oh b gy op om l on oo">System.<strong class="oh ir"><em class="le">err</em></strong>.println(r);</span><span id="4acc" class="ml mm iq oh b gy op om l on oo">}</span><span id="b386" class="ml mm iq oh b gy op om l on oo">}</span><span id="cc92" class="ml mm iq oh b gy op om l on oo">}</span><span id="c792" class="ml mm iq oh b gy op om l on oo">}</span><span id="4012" class="ml mm iq oh b gy op om l on oo">}</span></pre><p id="07a0" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">以上是对 CoreNLP 如何用于从简单问题中提取关系的快速解释。</p><p id="eb59" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">你会发现很多关于斯坦福 CoreNLP 的在线文章，如果有疑问，请在下面评论澄清。</p><p id="ff7d" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">在这篇文章中，我们使用<a class="ae la" href="https://nlp.stanford.edu/software/tokensregex.html" rel="noopener ugc nofollow" target="_blank"> tokenregex </a>和<a class="ae la" href="https://nlp.stanford.edu/software/relationExtractor.html" rel="noopener ugc nofollow" target="_blank">Stanford relation extraction</a>介绍了一些架构选项和基本 NLU 程序块，它们可以提取单个主语、单个谓语和单个宾语。</p><blockquote class="mb"><p id="b17d" class="mc md iq bd me mf nf ng nh ni nj kz dk translated">注意，单个问题可以用多个关系来注释，也可以从单个问题中提取多个关系，这可能导致精度问题。基于你的训练数据有多好，统计的 CRF 方法一般会有较高的<a class="ae la" href="https://en.wikipedia.org/wiki/Precision_and_recall" rel="noopener ugc nofollow" target="_blank">召回较低的精度</a>。</p></blockquote><p id="33fd" class="pw-post-body-paragraph kc kd iq ke b kf nk kh ki kj nl kl km kn nm kp kq kr nn kt ku kv no kx ky kz ij bi translated">将在即将到来的博客中讨论高级 NLU 和问题理解。</p><p id="502c" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">感谢阅读..</p></div><div class="ab cl or os hu ot" role="separator"><span class="ou bw bk ov ow ox"/><span class="ou bw bk ov ow ox"/><span class="ou bw bk ov ow"/></div><div class="ij ik il im in"><p id="5a7b" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated"><a class="ae la" href="https://github.com/iitrsamrat/nlp-stanford" rel="noopener ugc nofollow" target="_blank"><strong class="ke ir">Git Link </strong></a>:<a class="ae la" href="https://github.com/iitrsamrat/nlp-stanford" rel="noopener ugc nofollow" target="_blank">https://github.com/iitrsamrat/nlp-stanford </a></p><p id="d72c" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">References:</p><p id="58fc" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">[1] <a class="ae la" href="https://www.wikidata.org/wiki/Wikidata:Main_Page" rel="noopener ugc nofollow" target="_blank">https://www.wikidata.org/wiki/Wikidata:Main_Page </a></p><p id="466b" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">[2] <a class="ae la" href="https://wiki.dbpedia.org/" rel="noopener ugc nofollow" target="_blank">https://wiki.dbpedia.org/ </a></p><p id="9096" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">[3] <a class="ae la" href="https://en.wikipedia.org/wiki/Knowledge_Graph" rel="noopener ugc nofollow" target="_blank"> https://en.wikipedia.org/wiki/Knowledge_Graph </a></p><p id="fc20" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">[4] <a class="ae la" href="https://en.wikipedia.org/wiki/Question_answering" rel="noopener ugc nofollow" target="_blank"> https://en.wikipedia.org/wiki/Question_answering </a></p><p id="f5aa" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">[5] <a class="ae la" href="https://www.conll.org/2019" rel="noopener ugc nofollow" target="_blank">https://www.conll.org/2019 </a></p><p id="a326" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">[6] <a class="ae la" href="https://stanfordnlp.github.io/CoreNLP/" rel="noopener ugc nofollow" target="_blank">https://stanfordnlp.github.io/CoreNLP/</a></p></div></div>    
</body>
</html>