<html>
<head>
<title>Features that Maximizes Mutual Information, How do they Look Like?</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">最大化互信息的特征，它们看起来怎么样？</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/features-that-maximizes-mutual-information-how-do-they-look-like-95267da510aa?source=collection_archive---------9-----------------------#2019-02-26">https://towardsdatascience.com/features-that-maximizes-mutual-information-how-do-they-look-like-95267da510aa?source=collection_archive---------9-----------------------#2019-02-26</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="2ab2" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">我们可以通过最大化交互信息来创建潜在特征，但是它们看起来会是什么样的呢？</h2></div><figure class="kk kl km kn gt ko gh gi paragraph-image"><div role="button" tabindex="0" class="kp kq di kr bf ks"><div class="gh gi kj"><img src="../Images/aa66807e70f54c10209ad196084b4ae4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*iSZiKO5bcJQ7izrm6s_dQA.jpeg"/></div></div><figcaption class="kv kw gj gh gi kx ky bd b be z dk">Image from <a class="ae kz" href="https://pixabay.com/illustrations/woman-face-head-identity-search-565127/" rel="noopener ugc nofollow" target="_blank">pixabay</a></figcaption></figure><p id="f89c" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">我要感谢<a class="ae kz" href="https://www.idiap.ch/~fleuret/" rel="noopener ugc nofollow" target="_blank">Fran ois Fleuret</a>博士、<a class="ae kz" href="https://www.linkedin.com/in/devon-hjelm-a54b175/?originalSubdomain=ca" rel="noopener ugc nofollow" target="_blank">Devon Hjelm</a>博士、<a class="ae kz" href="http://www.iro.umontreal.ca/~bengioy/yoshua_en/" rel="noopener ugc nofollow" target="_blank">yo shua beng io</a>博士提供了令人惊叹的<a class="ae kz" href="https://arxiv.org/abs/1808.06670" rel="noopener ugc nofollow" target="_blank">论文</a>和<a class="ae kz" href="https://fleuret.org/files/complement-slides-MI-estimator.pdf" rel="noopener ugc nofollow" target="_blank">参考资料</a>。最后，我要感谢我的导师布鲁斯博士的鼓励、耐心和有益的讨论。</p></div><div class="ab cl lw lx hx ly" role="separator"><span class="lz bw bk ma mb mc"/><span class="lz bw bk ma mb mc"/><span class="lz bw bk ma mb"/></div><div class="im in io ip iq"><p id="c08e" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated"><strong class="lc iu">简介</strong></p><p id="c706" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">由于最近的发展，如<a class="ae kz" href="https://arxiv.org/abs/1801.04062" rel="noopener ugc nofollow" target="_blank"> MINE </a>和<a class="ae kz" href="https://arxiv.org/abs/1808.06670" rel="noopener ugc nofollow" target="_blank"> DeepInfoMax </a>，我们不仅能够估计两个高维随机变量的互信息，而且能够创建潜在特征，使输入数据的互信息最大化。</p><p id="8e1c" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">就我个人而言，我认为创造有意义的潜在变量的想法与本吉奥博士的<a class="ae kz" href="https://www.youtube.com/watch?v=Yr1mOzC93xs" rel="noopener ugc nofollow" target="_blank">演讲有些关联。简而言之，更好的数据表示(也称为抽象表示)对机器学习模型有益。这也与我们想要最小化/最大化的目标函数不在像素空间中，而是在信息空间中的想法有关。</a></p><p id="672a" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">在这篇文章中，我将把重点放在可视化潜在变量上，这是通过最大化交互信息而产生的。而不是选择可用于任何下游任务的最佳“最佳”表示。</p></div><div class="ab cl lw lx hx ly" role="separator"><span class="lz bw bk ma mb mc"/><span class="lz bw bk ma mb mc"/><span class="lz bw bk ma mb"/></div><div class="im in io ip iq"><p id="06e9" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated"><strong class="lc iu">方法</strong></p><figure class="kk kl km kn gt ko gh gi paragraph-image"><div role="button" tabindex="0" class="kp kq di kr bf ks"><div class="gh gi md"><img src="../Images/b965596dd3739a06899c7ceec4f5b723.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*uOLIXEFAAZSxW35w2NcIdg.png"/></div></div></figure><p id="a36e" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated"><strong class="lc iu">蓝色球体→ </strong>来自 STL 数据集的输入图像(96*96) <strong class="lc iu"> <br/>蓝色矩形→ </strong>编码器网络<strong class="lc iu"> <br/>绿色矩形→ </strong>局部信息最大化器<strong class="lc iu"> <br/>红色矩形→ </strong>全局信息最大化器<strong class="lc iu"> <br/>黄色矩形→ </strong>先验分布作为正则化</p><p id="bded" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">请注意，输入图像已经转换为灰度，因此没有任何颜色通道。此外，我们可以注意到，我们有三个网络作为目标函数，但是，它们都不是在像素空间，而是在信息空间。(详情请阅读论文<a class="ae kz" href="https://arxiv.org/abs/1808.06670" rel="noopener ugc nofollow" target="_blank"> DeepinfoMax </a>)。</p><blockquote class="me mf mg"><p id="4875" class="la lb mh lc b ld le ju lf lg lh jx li mi lk ll lm mj lo lp lq mk ls lt lu lv im bi translated">此外，请注意，所有的目标函数网络都采用两个变量来最大化它们之间的互信息。在我们所有的例子中，我们给这些网络提供了<strong class="lc iu">原始图像(如果需要，可以调整大小)和编码的潜在变量</strong>。</p></blockquote></div><div class="ab cl lw lx hx ly" role="separator"><span class="lz bw bk ma mb mc"/><span class="lz bw bk ma mb mc"/><span class="lz bw bk ma mb"/></div><div class="im in io ip iq"><p id="9536" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated"><strong class="lc iu">实验设置</strong></p><p id="ff0e" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated"><em class="mh">情况 A)潜在变量具有较小的维数</em></p><p id="b10e" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">这种情况下，编码器仅由卷积层组成，没有任何填充。因此，在每次卷积操作之后，图像的空间维度将减小。</p><p id="4f2e" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated"><strong class="lc iu">维数:(96，96)→(94，94)→(92，92)→(90，90)→(88，88) </strong></p><p id="9d8e" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated"><em class="mh">情况 B)潜在变量具有更大维度</em></p><p id="286b" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">这是编码器由转置卷积层组成的情况。因此，在每一层之后，图像的空间维度将增加。</p><p id="2d1b" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated"><strong class="lc iu">维度:(96，96)→(98，98)→(100，100)→(102，102)→(104，104) </strong></p><p id="b7eb" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated"><em class="mh">情况 C)潜在变量具有相同的维度</em></p><p id="9588" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">在这种情况下，我们使用零填充执行典型的卷积运算，因此空间维度不会改变。</p><p id="e392" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated"><strong class="lc iu">维数:(96，96)→(96，96)→(96，96)→(96，96)→(96，96) </strong></p><p id="52df" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated"><em class="mh">情况 D)潜在变量具有相同的维数(反向自动编码器)</em></p><p id="db31" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">在这种情况下，我们首先通过转置卷积来增加空间维度，但是在没有任何填充的情况下应用卷积来立即减小空间维度。(因此反向自动编码器)。</p><p id="4fa6" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated"><strong class="lc iu">维数:(96，96)→(98，98)→(100，100)→(98，98)→(96，96) </strong></p><p id="fb46" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">对于上述所有方法，我们将通过创建两幅图像的直方图来测量原始图像和潜在变量之间的互信息，更多细节<a class="ae kz" href="https://stackoverflow.com/questions/20491028/optimal-way-to-compute-pairwise-mutual-information-using-numpy" rel="noopener ugc nofollow" target="_blank">在此</a>或<a class="ae kz" href="https://matthew-brett.github.io/teaching/mutual_information.html" rel="noopener ugc nofollow" target="_blank">在此</a>。此外，所有超参数保持不变，例如学习速率、迭代次数和批量大小。</p></div><div class="ab cl lw lx hx ly" role="separator"><span class="lz bw bk ma mb mc"/><span class="lz bw bk ma mb mc"/><span class="lz bw bk ma mb"/></div><div class="im in io ip iq"><p id="7794" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated"><strong class="lc iu">结果</strong></p><figure class="kk kl km kn gt ko gh gi paragraph-image"><div class="gh gi ml"><img src="../Images/26069b2c01a32a34fe74725a8f4dbca4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1186/format:webp/1*ydO4zEJpOH66cBtUGUWxfg.png"/></div></figure><p id="ecc8" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">当我们比较 50 次迭代的损失时，我们可以清楚地看到，当我们保持空间维度与输入数据相同时，互信息最大化。</p><figure class="kk kl km kn gt ko gh gi paragraph-image"><div class="gh gi mm"><img src="../Images/0a5b160592e76f2cb35d6d06eeac0c67.png" data-original-src="https://miro.medium.com/v2/resize:fit:936/format:webp/1*4lAlmF0BNBKvYY6BkQNX5g.png"/></div></figure><p id="4e92" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">让我们按照情况 a、b、c 和 d 的顺序，比较每种方法创建的不同特征图。</p><div class="kk kl km kn gt ab cb"><figure class="mn ko mo mp mq mr ms paragraph-image"><div role="button" tabindex="0" class="kp kq di kr bf ks"><img src="../Images/c11fbda8654a04b4b3b924e5ef4c398c.png" data-original-src="https://miro.medium.com/v2/resize:fit:994/format:webp/1*cFHUvL3VKm2OMe4VipJV4w.png"/></div></figure><figure class="mn ko mt mp mq mr ms paragraph-image"><div role="button" tabindex="0" class="kp kq di kr bf ks"><img src="../Images/c997f9747d5081013650be035b2a825e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1008/format:webp/1*Ag1R8lzYUFHMyzSJ2dGo0Q.png"/></div><figcaption class="kv kw gj gh gi kx ky bd b be z dk mu di mv mw">Left Case a Right Case b</figcaption></figure></div><div class="ab cb"><figure class="mn ko mx mp mq mr ms paragraph-image"><div role="button" tabindex="0" class="kp kq di kr bf ks"><img src="../Images/1b0ddafe063a002cbaa93c0e991f69f0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*qdTdx0YlY7VrTinyNPQAVQ.png"/></div></figure><figure class="mn ko mx mp mq mr ms paragraph-image"><div role="button" tabindex="0" class="kp kq di kr bf ks"><img src="../Images/e595bab7ac1cfe6ea1c28c8b10dfe8ba.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*FOkkk0G3Tnc7WiPMsVUS5Q.png"/></div><figcaption class="kv kw gj gh gi kx ky bd b be z dk my di mz mw">Left Case c Right Case d</figcaption></figure></div><p id="e9a2" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">当我们考虑原始图像和 32 个特征图之间的平均互信息时，我们可以看到互信息对于情况 c 是最高的。</p><figure class="kk kl km kn gt ko gh gi paragraph-image"><div class="gh gi mm"><img src="../Images/6ed134c963cd419fb2858cd4bc9e20d3.png" data-original-src="https://miro.medium.com/v2/resize:fit:936/format:webp/1*EdZkrfIZZcRoRR52dZAyzA.png"/></div></figure><p id="91d8" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">让我们比较另一幅图像，这次是一匹马的图像。</p><div class="kk kl km kn gt ab cb"><figure class="mn ko mo mp mq mr ms paragraph-image"><div role="button" tabindex="0" class="kp kq di kr bf ks"><img src="../Images/998d3b651b241d161b4312e63064d7bc.png" data-original-src="https://miro.medium.com/v2/resize:fit:994/format:webp/1*i8E3ogr-PcXQ02RObplwag.png"/></div></figure><figure class="mn ko mt mp mq mr ms paragraph-image"><div role="button" tabindex="0" class="kp kq di kr bf ks"><img src="../Images/a91a522f3ed878b2656d760a6c37e362.png" data-original-src="https://miro.medium.com/v2/resize:fit:1008/format:webp/1*97U-pFHkoHV1EuJXq5dTdQ.png"/></div><figcaption class="kv kw gj gh gi kx ky bd b be z dk mu di mv mw">Left Case a Right Case b</figcaption></figure></div><div class="ab cb"><figure class="mn ko mx mp mq mr ms paragraph-image"><div role="button" tabindex="0" class="kp kq di kr bf ks"><img src="../Images/9a4ff95df457a4620711026e58a358ea.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*XeBI5yYu0ApXXn0PbbwwbA.png"/></div></figure><figure class="mn ko mx mp mq mr ms paragraph-image"><div role="button" tabindex="0" class="kp kq di kr bf ks"><img src="../Images/0ba79a0500be4a88002214e6265b8c21.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*sYMSsmGGZlQFrtpWlRCDRA.png"/></div><figcaption class="kv kw gj gh gi kx ky bd b be z dk my di mz mw">Left Case c Right Case d</figcaption></figure></div><p id="510d" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">对于马的图像也获得了类似的结果。</p><div class="kk kl km kn gt ab cb"><figure class="mn ko mx mp mq mr ms paragraph-image"><div role="button" tabindex="0" class="kp kq di kr bf ks"><img src="../Images/04da356c69f00505c8fabd457dcdd63b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*NOMc-1VB5tkEB9wY00ZhjA.png"/></div></figure><figure class="mn ko mx mp mq mr ms paragraph-image"><div role="button" tabindex="0" class="kp kq di kr bf ks"><img src="../Images/19d9406deaded39b31112f4147888c74.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*L7B01bHP8CuElP9Y7SCJRg.png"/></div></figure></div><div class="ab cb"><figure class="mn ko mx mp mq mr ms paragraph-image"><div role="button" tabindex="0" class="kp kq di kr bf ks"><img src="../Images/8ee33384fd1b192a8b999fd44a97ad8c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*BI87OnTlGdMaeT-BMyFOkQ.png"/></div></figure><figure class="mn ko mx mp mq mr ms paragraph-image"><div role="button" tabindex="0" class="kp kq di kr bf ks"><img src="../Images/64bfd233fc16d31abb8fd933bb51ed1c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*GrVXzEL_coGCc5EO1B3_xA.png"/></div></figure></div><p id="ff1a" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">最后，当我们比较 STL 数据集中所有 5000 个图像的最大互信息时，我们可以看到，相对于输入数据保持维度相同具有最高频率的生成具有高互信息的潜在变量。</p></div><div class="ab cl lw lx hx ly" role="separator"><span class="lz bw bk ma mb mc"/><span class="lz bw bk ma mb mc"/><span class="lz bw bk ma mb"/></div><div class="im in io ip iq"><p id="ea2b" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated"><strong class="lc iu">结论/交互代码</strong></p><p id="5b3e" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">要访问案例 a 的代码，<a class="ae kz" href="https://github.com/JaeDukSeo/Daily-Neural-Network-Practice-2/blob/master/Personal%20Milestones/first/1%20View%20Maximize/a%20smaller.ipynb" rel="noopener ugc nofollow" target="_blank">请点击此处。</a> <br/>要访问案例 b 的代码，<a class="ae kz" href="https://github.com/JaeDukSeo/Daily-Neural-Network-Practice-2/blob/master/Personal%20Milestones/first/1%20View%20Maximize/b%20larger%20.ipynb" rel="noopener ugc nofollow" target="_blank">请点击这里</a>。<br/>要获取案例 c 的代码，<a class="ae kz" href="https://nbviewer.jupyter.org/github/JaeDukSeo/Daily-Neural-Network-Practice-2/blob/master/Personal%20Milestones/first/1%20View%20Maximize/c%20same.ipynb" rel="noopener ugc nofollow" target="_blank">请点击此处。</a> <br/>要访问案例 d 的代码，<a class="ae kz" href="https://nbviewer.jupyter.org/github/JaeDukSeo/Daily-Neural-Network-Practice-2/blob/master/Personal%20Milestones/first/1%20View%20Maximize/d%20same%20%28auto%20encoder%29.ipynb" rel="noopener ugc nofollow" target="_blank">请点击此处</a>。<br/>要访问用于创建可视化效果的代码<a class="ae kz" href="https://nbviewer.jupyter.org/github/JaeDukSeo/Daily-Neural-Network-Practice-2/blob/master/Personal%20Milestones/first/1%20View%20Maximize/e%20analyze.ipynb" rel="noopener ugc nofollow" target="_blank">，请点击此处</a>。</p><p id="501f" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">请注意，我已经修改了来自<a class="ae kz" href="https://github.com/DuaneNielsen/DeepInfomaxPytorch" rel="noopener ugc nofollow" target="_blank"> DuaneNielsen 的原始实现。</a></p></div><div class="ab cl lw lx hx ly" role="separator"><span class="lz bw bk ma mb mc"/><span class="lz bw bk ma mb mc"/><span class="lz bw bk ma mb"/></div><div class="im in io ip iq"><p id="7db8" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated"><strong class="lc iu">遗言</strong></p><p id="756a" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">为什么这和我有关系？我认为这种创造潜在变量的形式可能是克服过度拟合的一个好主意。诚然，我们可以使用生成模型来创建新的数据点，这些数据点可以用作数据扩充，但它们也有自己的一系列问题，如模式崩溃。拥有多样化的数据扩充方法对每个人都有好处。</p><p id="4a8b" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">最后，所有的参考文献都被链接到<a class="ae kz" href="https://medium.com/@SeoJaeDuk/archived-post-reference-for-features-that-maximizes-mutual-information-how-do-they-look-like-3bb6ce4904ab" rel="noopener">这里</a>。</p></div></div>    
</body>
</html>