# 逻辑回归——源自直觉[逻辑三部曲，第 1 部分]

> 原文：<https://towardsdatascience.com/logistic-regression-derived-from-intuition-d1211fc09b10?source=collection_archive---------25----------------------->

## 让我们通过一个故事从头开始推导逻辑回归。我希望它对你来说是有趣的和好玩的。

所以目前两个人正在相互交流。一个是我，作者，另一个是你，读者。在互动的最后，你将自己从线性回归中推导出逻辑回归。我这边只要一个条件，我们就推导出只有一个自变量 x 的回归设置

让我们先从**简单线性回归**说起。我们有一个因变量 Y，只有一个自变量 x。因此，模型看起来像 Y=a+bX+e，其中 a 和 b 是未知系数，e 是误差项。你知道模型的所有假设以及违反这些假设的后果。这个问题基本上归结为未知参数 a 和 b 的估计。有两种方法可以做到这一点。**最小二乘法**和**最大似然法。我们仅限于 MLE。**

> ***为什么？***

因为在估计之后，为了测试的目的，你需要一个分布假设。对于最小二乘估计过程，你不需要任何与之相关的概率分布。但是对于 MLE，我们需要假设误差项独立地遵循均值为 0 且方差恒定的正态分布**。**

因此，我们现在的模型是 Y=a+bX+e，其中 Y 遵循正态分布，平均值为 a+bX，a 具有恒定的方差。这会导致什么？意思是 Y 可以取实线上的任意值。我的问题是如果这个假设被违背了呢？如果 Y 只能取几个受限值呢？如果 Y 只能取两个值呢？说它表示任何事件的不存在或存在。如何解决这个问题？有什么建议吗？

> ***有一点是肯定的，常态的假设在这里是无效的。因为如果误差遵循正态分布，那么 Y 也遵循正态分布，但是因为 Y 在这里是离散的，所以假设完全不成立。***

完全正确，非常正确。我们稍微偏离了线性回归。我们现在有一个非常令人不安的等式。Y=a+bX+e，其中 r.h.s 可以取任何实数值，但是 l.h.s 只能取 0 或 1(编码存在为 1，不存在为 0)。怎么办？

作为解决方案，让我们稍微改变一下等式。改变最符合逻辑的部分是什么？y 还是 X 还是 e？我给个提示吧。假设有两个量，一个是随机的，另一个是非随机的。你觉得哪个更可控？

> ***当然非随机量。随机量受某种自然规律的控制。我们对它没有太多的控制。***

非常好的回答读者。那 Y，X，e 换哪个呢？非随机的，也就是 x，在我们的例子中，它实际上是 a+bX。我说我们找一个函数 f(。)使得 f(a+bX)位于 0 和 1 之间并且基于数据选择阈值 c 使得如果 f(a+bX)

> ***否，如果最后我们需要选择阈值，那么将 a+bX 转换成由 0 和 1 限定的东西的需要是什么。我们能不能不做这样的事情，如果 a+bX < d 那么 Y=0，如果 a+bX > d 那么 Y=1？***

非常好的问题。再次关注简单线性回归。假设在估算之后，你有一个**回归方程**作为 Y= *a+b* X。对于 X=x0，你将得到值 y0=a+b*x0。每次你把 X=x0 代入方程，每次你都会得到 Y=y0。但是在现实中，如果你有 n 个 X 值为 x0 的观察值，你认为对于每一个观察值，Y 都是 y0 吗？假设 Y 是体重，X 是年龄。你认为每个 24 岁的人体重都一样吗？当然不是。

这是诀窍。Y 服从均值为 a+bX 的正态分布，Y 在这里是随机的。X=x0 的 n 个观测值的 Y 值只不过是来自平均值为 a+b*x0 的正态分布的大小为 n 的随机样本。那么样本均值的期望值是多少？**确实是 a+b*x0=y0。**

***记住！！！！！在线性回归中，我们不预测 Y，我们估计 Y 的期望值，即 E[Y]。y 是随机的。对于相同的 X=x0，它应该给出不同的值，但是 E[Y]将是固定的，因为它是非随机的。***

现在让我们回到我们的问题上来。y 只能取两个值 0 和 1。描述这种随机变量的最佳概率分布是什么？

> 伯努利分布？

完全正确的读者，完全正确。假设 Y 服从参数为 p(比方说)的伯努利分布，0≤p≤1。因此 P[Y=1]=p=1-P[Y=0]和 E[Y]=p。因此 0≤E[Y]≤1。我想现在清楚了为什么我们需要把 a+bX 转换成 0≤f(a+bX)≤1。😊

对于逻辑回归，我们选择 sigmoid 函数。我的问题是有很多函数的值域是(0，1)，那么为什么是 sigmoid 呢？让我们一起找出答案，为了简单起见，暂时考虑 a=0，b=1。

> 这样的函数有很多，比如说 f(x)=|sin(x)|或者 f(x)=|x|/(|x|+1)。为什么这些没有被用作我们的例子的转换函数？

是的，事实上它们位于 0 和 1 之间，但由于稍后我们需要通过优化技术最大化似然函数，因此最好限制为处处可微的函数。所以我给函数加了一个限制，它们应该处处可微，因此是连续的。现在给我这样的函数。

> 好吧，那怎么样

![](img/0ad7fb8892eaa1407a6d61d63787605d.png)

是的。这些到处都是可微的。但是你有没有想过为什么 logistic 回归被称为**广义线性模型而不是非线性回归模型？** Y 和 X 是线性相关的，意思是如果 X 增加(减少)一定量，那么 Y 也增加(减少)或减少(增加)。也就是说，Y 和 X 成正比或反比，并且由于我们处理的是广义的**“线性”**模型，所以必须捕捉到这种关系，如果不是完全的话，至少在某种意义上进入模型。

在上述函数中，此属性被违反。在第二个函数中，如果 X 从 4 增加到 5，那么 f(x)增加，并且如果 X 从-4 减少到-5，那么 f(x)也增加。对于 sin 函数来说也是微不足道的。

所以我提出了另一个限制。随处处可微，连续；该函数应该是单调递增的。(因为我们实际上是在用 a+bX，对于递减函数，我们将相应地改变 b 的符号)。

能否给我一个处处连续，处处可微，单调递增，值域为(0，1)，定义域为整条实直线的函数？ **Statistics** 提供了一堆这样的函数，它们非常有名，实际上非常有用。发现什么了吗？

> 连续随机变量的累积分布函数

太棒了。！举出一些连续的随机变量，它们可以在整条实线上取任意值？让我们关注标准分布，即均值为 0，方差为 1。

> 标准正态分布，标准逻辑分布。

对于标准正态分布，标准逻辑分布的 pdf 和 cdf 是

![](img/54ba1ba35e369691658392b60bea5bdc.png)

让我们看看另一个分布，广义耿贝尔分布的最小值，这是一个极值分布。它的 pdf 和 cdf 如下:

![](img/8d522e54acae6bf5798582be1ce2a0b6.png)

让我们一个一个地解决。对于标准正态分布，我们的模型是，

![](img/7854cdb5e3e366a4dcebb140912f8f74.png)

不就是 **Probit 模型吗？**

对于标准的物流配送，

![](img/55a8decd0b7eb6c3610d55d12b64a648.png)

是的，这是我们非常熟悉的 logit 模型。(因此得名物流，因为它源自物流配送)

最后是广义耿贝尔分布的最小值，

![](img/3830e7fa170d5d62adfe37ffb21cc169.png)

**免费的双对数模型。**

在所有上述情况下，右手边的参数是线性的。因此广义的“线性”模型。

现在为了估计，我们首先需要一个大小为 n 的数据集(Y，X ),假设 Yi ~ Bernoulli(πI)独立。

那么可能性函数是

![](img/17c119a1b34d8d988765ba060aa2b1f0.png)

likelihood function

在 logit 模型设置下，

![](img/34ce83b88758872b234c44781b3a549f.png)

在似然方程中替换相同的，我们可以得到似然函数 L(a，b ),并需要通过一些优化技术使其最大化。

恭喜你！！！！！**你已经从纯粹的直觉**推导出了逻辑回归。(*你猜怎么着，你根本没用过“链接函数或反向链接函数”这个术语*)有那么难吗？希望你喜欢这个逻辑之旅。

如果你不相信，或者有任何问题或疑问，请在评论区提问。或者通过我的 LinkedIn 个人资料联系我。

[](https://www.linkedin.com/in/soumalya-nandi-95176569/) [## SOUMALYA NANDI -联合健康组织助理数据科学家| LinkedIn

### 查看 SOUMALYA NANDI 在全球最大的职业社区 LinkedIn 上的个人资料。SOUMALYA 有 4 份工作列在…

www.linkedin.com](https://www.linkedin.com/in/soumalya-nandi-95176569/)