<html>
<head>
<title>An Expert’s guide to moving from Keras to Pytorch</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">从喀拉斯到皮托尔彻的专家指南</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/a-laymans-guide-to-moving-from-keras-to-pytorch-37fe56b6f588?source=collection_archive---------26-----------------------#2019-01-06">https://towardsdatascience.com/a-laymans-guide-to-moving-from-keras-to-pytorch-37fe56b6f588?source=collection_archive---------26-----------------------#2019-01-06</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="1272" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">说真的，是时候搬家了</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/0b907a41296f93ace391e793a83f1208.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*_27c0awhQy_uoS6a.png"/></div></div></figure><p id="e7eb" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">最近我在 Kaggle 上开始了一场关于文本分类的比赛，作为比赛的一部分，我不得不设法转移到 Pytorch 上以获得确定性的结果。现在，我过去一直与 keras 一起工作，它给了我相当好的结果，但不知何故，我知道 Keras 中的<strong class="kw iu"> CuDNNGRU/CuDNNLSTM 层不是确定性的</strong>，即使在设置种子之后。所以 Pytorch 来营救了。我很高兴我考虑过搬家。</p><p id="d303" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">作为<strong class="kw iu">边注</strong>:如果你想了解更多关于<strong class="kw iu"> NLP </strong>的知识，我在此推荐<a class="ae lq" href="https://www.coursera.org/specializations/aml?siteID=lVarvwc5BD0-AqkGMb7JzoCMW0Np1uLfCA&amp;utm_content=2&amp;utm_medium=partners&amp;utm_source=linkshare&amp;utm_campaign=lVarvwc5BD0" rel="noopener ugc nofollow" target="_blank"> <strong class="kw iu">高级机器学习专精</strong> </a>中关于<a class="ae lq" href="https://www.coursera.org/specializations/aml?siteID=lVarvwc5BD0-AqkGMb7JzoCMW0Np1uLfCA&amp;utm_content=2&amp;utm_medium=partners&amp;utm_source=linkshare&amp;utm_campaign=lVarvwc5BD0" rel="noopener ugc nofollow" target="_blank"> <strong class="kw iu">自然语言处理</strong> </a>的这门牛逼课程。本课程涵盖了自然语言处理中从基础到高级的各种任务:情感分析、摘要、对话状态跟踪等等。</p><p id="a6a3" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">好吧，回到手头的任务。虽然 Keras 从深度学习开始很好，但随着时间的推移，你会对它的一些局限性感到不满。我考虑过搬到 Tensorflow。这似乎是一个很好的过渡，因为 TF 是 Keras 的后端。但是这很难吗？对于整个<code class="fe ls lt lu lv b">session.run</code>命令和张量流会话，我有点困惑。它根本不是毕氏的。</p><p id="9477" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">Pytorch 在这方面有所帮助，因为它看起来像是 python 做事的方式。一切都在你的掌控之中，在性能方面没有任何损失。用安德烈·卡帕西的话说:</p><blockquote class="lw lx ly"><p id="f2e4" class="ku kv lr kw b kx ky ju kz la lb jx lc lz le lf lg ma li lj lk mb lm ln lo lp im bi translated">我已经使用 PyTorch 几个月了，从来没有感觉这么好过。我有更多的精力。我的皮肤更干净了。我的视力提高了。</p><p id="45ca" class="ku kv lr kw b kx ky ju kz la lb jx lc lz le lf lg ma li lj lk mb lm ln lo lp im bi translated"><em class="it"> —安德烈·卡帕西(@卡帕西)</em><a class="ae lq" href="https://twitter.com/karpathy/status/868178954032513024?ref_src=twsrc%5Etfw" rel="noopener ugc nofollow" target="_blank"><em class="it">2017 年 5 月 26 日</em> </a></p></blockquote><p id="9e38" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">所以事不宜迟，让我为你把 Keras 翻译成 Pytorch。</p></div><div class="ab cl mc md hx me" role="separator"><span class="mf bw bk mg mh mi"/><span class="mf bw bk mg mh mi"/><span class="mf bw bk mg mh"/></div><div class="im in io ip iq"><h1 id="6b95" class="mj mk it bd ml mm mn mo mp mq mr ms mt jz mu ka mv kc mw kd mx kf my kg mz na bi translated">写你的网络的经典方式？</h1><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nb"><img src="../Images/307fcfb0fa1aae5f1134716c56ad2b9d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*CxVgscZmQN3Md7r_.jpeg"/></div></div></figure><p id="110d" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">好，让我们首先在 keras 中创建一个示例网络，我们将尝试将它移植到 Pytorch 中。在这里，我也想给你一个建议。当你试图从 Keras 迁移到 Pytorch <strong class="kw iu">时，使用你拥有的任何网络，并尝试将其移植到 Pytorch </strong>。这会让你更好地理解 Pytorch。在这里，我试着写一个在 Quora 虚假问题分类挑战中给我很好结果的网络。这个模型具有至少任何文本分类深度学习网络可以包含的所有功能，包括 GRU、LSTM 和嵌入层，以及元输入层。因此可以作为一个很好的例子。如果你想了解更多关于比尔斯特姆/GRU 和注意力模型是如何工作的，请访问我的帖子<a class="ae lq" href="https://mlwhiz.com/blog/2018/12/17/text_classification/" rel="noopener ugc nofollow" target="_blank">这里</a>。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nc nd l"/></div></figure><p id="7f1b" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">因此 pytorch 中的模型被定义为一个从<code class="fe ls lt lu lv b">nn.module</code>继承而来的类(因此更优雅一点)。每个类都必须包含一个<code class="fe ls lt lu lv b">__init__</code>程序块和一个<code class="fe ls lt lu lv b">forward</code>通道块。</p><ul class=""><li id="2121" class="ne nf it kw b kx ky la lb ld ng lh nh ll ni lp nj nk nl nm bi translated">在<code class="fe ls lt lu lv b">__init__</code>部分，用户定义了网络将要拥有的所有层，但还没有定义这些层如何相互连接</li><li id="a8da" class="ne nf it kw b kx nn la no ld np lh nq ll nr lp nj nk nl nm bi translated">在正向传递模块中，用户定义数据如何在网络中从一层流向另一层。</li></ul><h1 id="e03e" class="mj mk it bd ml mm ns mo mp mq nt ms mt jz nu ka mv kc nv kd mx kf nw kg mz na bi translated">为什么这是经典？</h1><p id="573c" class="pw-post-body-paragraph ku kv it kw b kx nx ju kz la ny jx lc ld nz lf lg lh oa lj lk ll ob ln lo lp im bi translated">显然是因为上课而显得优雅。咄！但玩笑归玩笑，我发现它是有益的，原因有几个:</p><p id="c200" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">1)它让你对如何构建你的网络有很大的控制权。</p><p id="5a96" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">2)当您构建网络时，您对网络有很多了解，因为您必须指定输入和输出维度。所以<strong class="kw iu">出错的几率更小</strong>。(虽然这个真的要看技能水平了)</p><p id="b24a" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">3) <strong class="kw iu">易于调试的</strong>网络。任何时候你发现网络有任何问题，只要在正向传递中使用类似<code class="fe ls lt lu lv b">print("avg_pool", avg_pool.size())</code>的东西来检查层的大小，你就可以很容易地调试网络</p><p id="9067" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">4)您可以<strong class="kw iu">从正向层返回多个输出</strong>。这在编码器-解码器架构中非常有用，因为您可以返回编码器和解码器的输出。或者在 autoencoder 的情况下，您可以返回模型的输出和数据的隐藏层嵌入。</p><p id="b0e8" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">5) <strong class="kw iu"> Pytorch 张量的工作方式与 numpy 数组非常相似</strong>。例如，我可以使用 Pytorch Maxpool 函数来编写 Maxpool 层，但是<code class="fe ls lt lu lv b">max_pool, _ = torch.max(h_gru, 1)</code>也可以。</p><p id="4422" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">6)您可以用不同的初始化方案设置<strong class="kw iu">不同的层。一些你在喀拉斯做不到的事。例如，在下面的网络中，我改变了我的 LSTM 层的初始化方案。LSTM 图层对于偏差、输入图层权重和隐藏图层权重具有不同的初始化。</strong></p><p id="aba7" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">7)等到你看到 Pytorch 中的<strong class="kw iu">训练循环时，你会对它提供的<strong class="kw iu">控制</strong>感到惊讶。</strong></p><p id="164c" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">现在 Pytorch 中的同一个模型看起来会像这样。请仔细阅读代码注释，了解更多关于如何移植的信息。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nc nd l"/></div></figure><p id="f647" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">希望你还和我在一起。我想在这里强调的一点是，你需要用 Pytorch 编写一些代码来真正理解它是如何工作的。并且知道一旦你这样做了，你会很高兴你付出了努力。进入下一部分。</p></div><div class="ab cl mc md hx me" role="separator"><span class="mf bw bk mg mh mi"/><span class="mf bw bk mg mh mi"/><span class="mf bw bk mg mh"/></div><div class="im in io ip iq"><h1 id="c3a8" class="mj mk it bd ml mm mn mo mp mq mr ms mt jz mu ka mv kc mw kd mx kf my kg mz na bi translated">定制或现成:高度可定制的训练循环的最佳选择</h1><p id="e50a" class="pw-post-body-paragraph ku kv it kw b kx nx ju kz la ny jx lc ld nz lf lg lh oa lj lk ll ob ln lo lp im bi translated">在上面的部分，我写道，一旦你看到训练循环，你会感到惊讶。这是一种夸张。第一次尝试时，你会有点困惑。但是一旦你不止一次地通读这个循环，你会有很多直观的感觉。再次阅读注释和代码以获得更好的理解。</p><p id="1db4" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">该训练循环对训练数据进行 k 重交叉验证，并输出对测试数据的运行进行平均的非折叠 train_preds 和 test_preds。如果这个流程看起来像是从 kaggle 竞赛中直接出来的，我很抱歉，但是如果你明白这一点，你就能够为自己的工作流程创建一个训练循环。这就是 Pytorch 的魅力。</p><p id="8d6c" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">所以这个循环的简要总结如下:</p><ul class=""><li id="0d76" class="ne nf it kw b kx ky la lb ld ng lh nh ll ni lp nj nk nl nm bi translated">使用培训数据创建分层拆分</li><li id="d10d" class="ne nf it kw b kx nn la no ld np lh nq ll nr lp nj nk nl nm bi translated">循环遍历拆分。</li><li id="8f4d" class="ne nf it kw b kx nn la no ld np lh nq ll nr lp nj nk nl nm bi translated">使用<code class="fe ls lt lu lv b">X_train_fold = torch.tensor(x_train[train_idx.astype(int)], dtype=torch.long).cuda()</code>命令将训练和 CV 数据转换为张量并将数据加载到 GPU</li><li id="dcbd" class="ne nf it kw b kx nn la no ld np lh nq ll nr lp nj nk nl nm bi translated">使用<code class="fe ls lt lu lv b">model.cuda()</code>命令将模型加载到 GPU 上</li><li id="725c" class="ne nf it kw b kx nn la no ld np lh nq ll nr lp nj nk nl nm bi translated">定义损失函数、调度程序和优化程序</li><li id="6e72" class="ne nf it kw b kx nn la no ld np lh nq ll nr lp nj nk nl nm bi translated">创建<code class="fe ls lt lu lv b">train_loader</code>和 valid_loader `来迭代批处理。</li><li id="04b8" class="ne nf it kw b kx nn la no ld np lh nq ll nr lp nj nk nl nm bi translated">开始运行纪元。在每个时代</li><li id="6fdf" class="ne nf it kw b kx nn la no ld np lh nq ll nr lp nj nk nl nm bi translated">使用<code class="fe ls lt lu lv b">model.train()</code>将模型模式设置为训练。</li><li id="d9dc" class="ne nf it kw b kx nn la no ld np lh nq ll nr lp nj nk nl nm bi translated">检查<code class="fe ls lt lu lv b">train_loader</code>中的批次并向前运行</li><li id="3019" class="ne nf it kw b kx nn la no ld np lh nq ll nr lp nj nk nl nm bi translated">运行调度程序步骤以更改学习率</li><li id="5016" class="ne nf it kw b kx nn la no ld np lh nq ll nr lp nj nk nl nm bi translated">计算损失</li><li id="8c49" class="ne nf it kw b kx nn la no ld np lh nq ll nr lp nj nk nl nm bi translated">将优化器中的现有梯度设置为零</li><li id="73a8" class="ne nf it kw b kx nn la no ld np lh nq ll nr lp nj nk nl nm bi translated">通过网络反向传播损失</li><li id="af25" class="ne nf it kw b kx nn la no ld np lh nq ll nr lp nj nk nl nm bi translated">剪切渐变</li><li id="2ab8" class="ne nf it kw b kx nn la no ld np lh nq ll nr lp nj nk nl nm bi translated">采取优化步骤来改变整个网络中的权重</li><li id="4db9" class="ne nf it kw b kx nn la no ld np lh nq ll nr lp nj nk nl nm bi translated">使用<code class="fe ls lt lu lv b">model.eval()</code>将模型模式设置为评估。</li><li id="6ddd" class="ne nf it kw b kx nn la no ld np lh nq ll nr lp nj nk nl nm bi translated">使用<code class="fe ls lt lu lv b">valid_loader</code>获得验证数据的预测，并存储在变量<code class="fe ls lt lu lv b">valid_preds_fold</code>中</li><li id="5499" class="ne nf it kw b kx nn la no ld np lh nq ll nr lp nj nk nl nm bi translated">计算损失并打印</li><li id="fe26" class="ne nf it kw b kx nn la no ld np lh nq ll nr lp nj nk nl nm bi translated">所有历元完成后，预测测试数据并存储预测。这些预测将在分割循环结束时进行平均，以获得最终的<code class="fe ls lt lu lv b">test_preds</code></li><li id="8370" class="ne nf it kw b kx nn la no ld np lh nq ll nr lp nj nk nl nm bi translated">使用<code class="fe ls lt lu lv b">train_preds[valid_idx] = valid_preds_fold</code>获得列车组的离差(OOF)预测</li><li id="384d" class="ne nf it kw b kx nn la no ld np lh nq ll nr lp nj nk nl nm bi translated">然后，这些 OOF 预测可用于计算模型的局部 CV 分数。</li></ul><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nc nd l"/></div></figure><h2 id="a7a9" class="oc mk it bd ml od oe dn mp of og dp mt ld oh oi mv lh oj ok mx ll ol om mz on bi translated">但是为什么呢？为什么这么多代码？</h2><p id="33c4" class="pw-post-body-paragraph ku kv it kw b kx nx ju kz la ny jx lc ld nz lf lg lh oa lj lk ll ob ln lo lp im bi translated">好吧。我明白了。这可能是少数。在 keras 中用一个简单的<code class="fe ls lt lu lv b">.fit</code>就可以完成的事情，在 Pytorch 中需要大量代码才能完成。但要明白，你也获得了很多权力。您需要了解的一些使用案例:</p><ul class=""><li id="a56e" class="ne nf it kw b kx ky la lb ld ng lh nh ll ni lp nj nk nl nm bi translated">在 Keras 中，您有预先指定的调度程序，如<code class="fe ls lt lu lv b">ReduceLROnPlateau</code>(编写它们是一项任务)，而在 Pytorch 中，您可以疯狂地尝试。<strong class="kw iu">如果你知道如何写 Python，你会过得很好</strong></li><li id="98fa" class="ne nf it kw b kx nn la no ld np lh nq ll nr lp nj nk nl nm bi translated">想在两个时期之间改变模型的结构。是的，你能做到。动态更改卷积网络的输入大小。</li><li id="cf82" class="ne nf it kw b kx nn la no ld np lh nq ll nr lp nj nk nl nm bi translated">还有更多。只有你的想象会阻止你。</li></ul></div><div class="ab cl mc md hx me" role="separator"><span class="mf bw bk mg mh mi"/><span class="mf bw bk mg mh mi"/><span class="mf bw bk mg mh"/></div><div class="im in io ip iq"><h1 id="652b" class="mj mk it bd ml mm mn mo mp mq mr ms mt jz mu ka mv kc mw kd mx kf my kg mz na bi translated">想自己经营吗？</h1><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/ef8bf4bb914a45d39ebc11c3a1ab5632.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*9GCcc51yy5uIU6jg.jpg"/></div></div><figcaption class="oo op gj gh gi oq or bd b be z dk">You have all the tools! Do something…</figcaption></figure><p id="2a2e" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">这里还有一个小小的坦白。上面的代码将不会运行，因为有一些代码工件，我没有在这里显示。我这样做是为了让帖子更具可读性。就像你在上面的代码中看到的<code class="fe ls lt lu lv b">seed_everything</code>、<code class="fe ls lt lu lv b">MyDataset</code>和<code class="fe ls lt lu lv b">CyclicLR</code>(来自杰瑞米·霍华德课程)函数和类，它们并没有真正包含在 Pytorch 中。但别担心，我的朋友。</p><p id="dcc1" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">我试过用完整的运行代码写一个<a class="ae lq" href="https://www.kaggle.com/mlwhiz/third-place-model-for-toxic-comments-in-pytorch" rel="noopener ugc nofollow" target="_blank"> <strong class="kw iu"> Kaggle 内核</strong> </a> <strong class="kw iu"> </strong>。<a class="ae lq" href="https://www.kaggle.com/mlwhiz/third-place-model-for-toxic-comments-in-pytorch" rel="noopener ugc nofollow" target="_blank"> <strong class="kw iu"> <em class="lr">您可以在这里看到代码，并将其包含在您的项目中。</em> </strong> </a></p><p id="7a41" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">如果你喜欢这个帖子，<strong class="kw iu">请不要忘记也投票支持</strong> <a class="ae lq" href="https://www.kaggle.com/mlwhiz/third-place-model-for-toxic-comments-in-pytorch" rel="noopener ugc nofollow" target="_blank"> <strong class="kw iu">内核</strong> </a> <strong class="kw iu">。我将不胜感激。</strong></p></div><div class="ab cl mc md hx me" role="separator"><span class="mf bw bk mg mh mi"/><span class="mf bw bk mg mh mi"/><span class="mf bw bk mg mh"/></div><div class="im in io ip iq"><h1 id="ded1" class="mj mk it bd ml mm mn mo mp mq mr ms mt jz mu ka mv kc mw kd mx kf my kg mz na bi translated">尾注和参考文献</h1><p id="4d5c" class="pw-post-body-paragraph ku kv it kw b kx nx ju kz la ny jx lc ld nz lf lg lh oa lj lk ll ob ln lo lp im bi translated">这篇文章是许多优秀的 Kagglers 们努力的结果，我将在这一部分尝试引用他们。如果我漏掉了某个人，请理解我不是故意的。</p><ul class=""><li id="2ba6" class="ne nf it kw b kx ky la lb ld ng lh nh ll ni lp nj nk nl nm bi translated"><a class="ae lq" href="https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge/discussion/52644" rel="noopener ugc nofollow" target="_blank">关于毒性评论第三名获奖者模型的讨论</a></li><li id="b9cd" class="ne nf it kw b kx nn la no ld np lh nq ll nr lp nj nk nl nm bi translated"><a class="ae lq" href="https://www.kaggle.com/larryfreeman/toxic-comments-code-for-alexander-s-9872-model" rel="noopener ugc nofollow" target="_blank">Larry Freeman 在 Keras 获得第三名</a></li><li id="bb33" class="ne nf it kw b kx nn la no ld np lh nq ll nr lp nj nk nl nm bi translated"><a class="ae lq" href="https://www.kaggle.com/spirosrap/bilstm-attention-kfold-clr-extra-features-capsule" rel="noopener ugc nofollow" target="_blank"> Pytorch 启动器胶囊型号</a></li><li id="a265" class="ne nf it kw b kx nn la no ld np lh nq ll nr lp nj nk nl nm bi translated"><a class="ae lq" href="https://www.kaggle.com/christofhenkel/how-to-preprocessing-when-using-embeddings" rel="noopener ugc nofollow" target="_blank">如何:使用嵌入时进行预处理</a></li><li id="653c" class="ne nf it kw b kx nn la no ld np lh nq ll nr lp nj nk nl nm bi translated"><a class="ae lq" href="https://www.kaggle.com/theoviel/improve-your-score-with-some-text-preprocessing" rel="noopener ugc nofollow" target="_blank">通过一些文本预处理提高你的分数</a></li><li id="f5e8" class="ne nf it kw b kx nn la no ld np lh nq ll nr lp nj nk nl nm bi translated"><a class="ae lq" href="https://www.kaggle.com/ziliwang/baseline-pytorch-bilstm" rel="noopener ugc nofollow" target="_blank"> Pytorch 基线</a></li><li id="ab7f" class="ne nf it kw b kx nn la no ld np lh nq ll nr lp nj nk nl nm bi translated"><a class="ae lq" href="https://www.kaggle.com/hengzheng/pytorch-starter" rel="noopener ugc nofollow" target="_blank"> Pytorch 启动器</a></li></ul></div><div class="ab cl mc md hx me" role="separator"><span class="mf bw bk mg mh mi"/><span class="mf bw bk mg mh mi"/><span class="mf bw bk mg mh"/></div><div class="im in io ip iq"><p id="3528" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated"><em class="lr">原载于 2019 年 1 月 6 日</em><a class="ae lq" href="https://mlwhiz.com/blog/2019/01/06/pytorch_keras_conversion/" rel="noopener ugc nofollow" target="_blank"><em class="lr">mlwhiz.com</em></a><em class="lr">。</em></p></div></div>    
</body>
</html>