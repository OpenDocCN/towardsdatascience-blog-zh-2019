<html>
<head>
<title>Review: FPN — Feature Pyramid Network (Object Detection)</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">综述:FPN —特征金字塔网络(目标检测)</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/review-fpn-feature-pyramid-network-object-detection-262fc7482610?source=collection_archive---------0-----------------------#2019-01-17">https://towardsdatascience.com/review-fpn-feature-pyramid-network-object-detection-262fc7482610?source=collection_archive---------0-----------------------#2019-01-17</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="51e7" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">超越单一模式的参赛作品，包括 COCO 检测挑战赛冠军、G-RMI 和 MultiPathNet</h2></div><p id="8db8" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi lb translated"><span class="l lc ld le bm lf lg lh li lj di">在</span>这篇论文中，<strong class="kh ir">【FPN】(特征金字塔网络)</strong>，由<strong class="kh ir">【脸书】AI Research(FAIR)</strong><strong class="kh ir">康奈尔大学</strong>和<strong class="kh ir">康奈尔理工</strong>共同评述。通过在卷积神经网络(CNN)中引入一个用于构建特征金字塔的简洁而简单的框架，与几个强基线和竞争获胜者相比，如<a class="ae lk" rel="noopener" target="_blank" href="/review-g-rmi-winner-in-2016-coco-detection-object-detection-af3f2eaf87e4"> G-RMI </a>、<a class="ae lk" rel="noopener" target="_blank" href="/review-multipath-mpn-1st-runner-up-in-2015-coco-detection-segmentation-object-detection-ea9741e7c413"> MultiPathNet </a>和<a class="ae lk" rel="noopener" target="_blank" href="/review-ion-inside-outside-net-2nd-runner-up-in-2015-coco-detection-object-detection-da19993f4766"> ION </a>，表现出了显著的改进。与<a class="ae lk" rel="noopener" target="_blank" href="/review-deepmask-instance-segmentation-30327a072339"> DeepMask </a>、<a class="ae lk" rel="noopener" target="_blank" href="/review-sharpmask-instance-segmentation-6509f7401a61"> SharpMask </a>和<a class="ae lk" rel="noopener" target="_blank" href="/review-instancefcn-instance-sensitive-score-maps-instance-segmentation-dbfe67d4ee92"> InstanceFCN </a>相比，FPN 拥有更高的分段提议 AR。是一篇<strong class="kh ir"> 2017 CVPR </strong>论文，引用<strong class="kh ir"> 700 多篇</strong>。(<a class="ll lm ep" href="https://medium.com/u/aff72a0c1243?source=post_page-----262fc7482610--------------------------------" rel="noopener" target="_blank"> Sik-Ho Tsang </a> @中)</p><figure class="lo lp lq lr gt ls gh gi paragraph-image"><div role="button" tabindex="0" class="lt lu di lv bf lw"><div class="gh gi ln"><img src="../Images/3f5e0b956b2a439fb4d66586052b74cf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*9g-AkB11IJsS9mQqm_sQIg.png"/></div></div><figcaption class="lz ma gj gh gi mb mc bd b be z dk"><strong class="bd md">COCO Detection and Segmentation Challenge</strong></figcaption></figure></div><div class="ab cl me mf hu mg" role="separator"><span class="mh bw bk mi mj mk"/><span class="mh bw bk mi mj mk"/><span class="mh bw bk mi mj"/></div><div class="ij ik il im in"><h1 id="bf29" class="ml mm iq bd mn mo mp mq mr ms mt mu mv jw mw jx mx jz my ka mz kc na kd nb nc bi translated">涵盖哪些内容</h1><ol class=""><li id="df2e" class="nd ne iq kh b ki nf kl ng ko nh ks ni kw nj la nk nl nm nn bi translated"><strong class="kh ir">文学中的各种建筑</strong></li><li id="c4a2" class="nd ne iq kh b ki no kl np ko nq ks nr kw ns la nk nl nm nn bi translated"><strong class="kh ir">特色金字塔网络(FPN) </strong></li><li id="9e3e" class="nd ne iq kh b ki no kl np ko nq ks nr kw ns la nk nl nm nn bi translated"><strong class="kh ir"> FPN 地区提案网络(RPN) </strong></li><li id="4d69" class="nd ne iq kh b ki no kl np ko nq ks nr kw ns la nk nl nm nn bi translated"><strong class="kh ir"> FPN 探测网</strong></li><li id="1d60" class="nd ne iq kh b ki no kl np ko nq ks nr kw ns la nk nl nm nn bi translated"><strong class="kh ir">消融实验</strong></li><li id="6d89" class="nd ne iq kh b ki no kl np ko nq ks nr kw ns la nk nl nm nn bi translated"><strong class="kh ir">与最先进方法的比较</strong></li></ol></div><div class="ab cl me mf hu mg" role="separator"><span class="mh bw bk mi mj mk"/><span class="mh bw bk mi mj mk"/><span class="mh bw bk mi mj"/></div><div class="ij ik il im in"><h1 id="fd04" class="ml mm iq bd mn mo mp mq mr ms mt mu mv jw mw jx mx jz my ka mz kc na kd nb nc bi translated">1.文学中的各种建筑</h1><figure class="lo lp lq lr gt ls gh gi paragraph-image"><div role="button" tabindex="0" class="lt lu di lv bf lw"><div class="gh gi nt"><img src="../Images/60509fa0edadf26adf1188e4d41f6194.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*XOumTDx4QEZ6qd_z1Rgf5g.png"/></div></div><figcaption class="lz ma gj gh gi mb mc bd b be z dk"><strong class="bd md">Different Architectures for Detection</strong></figcaption></figure><h2 id="ca44" class="nu mm iq bd mn nv nw dn mr nx ny dp mv ko nz oa mx ks ob oc mz kw od oe nb of bi translated"><strong class="ak">(一)特征化图像金字塔</strong></h2><ul class=""><li id="f3a8" class="nd ne iq kh b ki nf kl ng ko nh ks ni kw nj la og nl nm nn bi translated">在手工设计的时代，它被大量使用。</li></ul><h2 id="d5df" class="nu mm iq bd mn nv nw dn mr nx ny dp mv ko nz oa mx ks ob oc mz kw od oe nb of bi translated"><strong class="ak"> (b)单一特征地图</strong></h2><ul class=""><li id="6619" class="nd ne iq kh b ki nf kl ng ko nh ks ni kw nj la og nl nm nn bi translated">这是一个标准的 ConvNet 解决方案，对一个单一的输入图像有预测在网络的末端。</li></ul><h2 id="5d4b" class="nu mm iq bd mn nv nw dn mr nx ny dp mv ko nz oa mx ks ob oc mz kw od oe nb of bi translated"><strong class="ak"> (c)金字塔特征层次</strong></h2><ul class=""><li id="c314" class="nd ne iq kh b ki nf kl ng ko nh ks ni kw nj la og nl nm nn bi translated">在每一层，就像<a class="ae lk" rel="noopener" target="_blank" href="/review-ssd-single-shot-detector-object-detection-851a94607d11"> SSD </a>一样进行预测。它重用了前向过程中计算的不同图层的多尺度特征地图，因此是免费的。</li><li id="6f3a" class="nd ne iq kh b ki no kl np ko nq ks nr kw ns la og nl nm nn bi translated">然而，它错过了重用特征层次的高分辨率地图的机会，因此错过了对小物体的检测。</li></ul><h2 id="b72c" class="nu mm iq bd mn nv nw dn mr nx ny dp mv ko nz oa mx ks ob oc mz kw od oe nb of bi translated"><strong class="ak"> (d)特征金字塔网络</strong></h2><ul class=""><li id="54e0" class="nd ne iq kh b ki nf kl ng ko nh ks ni kw nj la og nl nm nn bi translated"><strong class="kh ir">它通过自上而下的路径和横向连接将低分辨率、语义强的特征与高分辨率、语义弱的特征结合起来。</strong></li><li id="ecf2" class="nd ne iq kh b ki no kl np ko nq ks nr kw ns la og nl nm nn bi translated">这种特征金字塔在所有级别上都具有丰富的语义，并且可以从单个输入图像尺度快速构建，从而不会牺牲表示能力、速度或内存。一些并发作品如<a class="ae lk" rel="noopener" target="_blank" href="/review-dssd-deconvolutional-single-shot-detector-object-detection-d4821a2bbeb5"/>也采用这种方式。</li></ul><h2 id="8687" class="nu mm iq bd mn nv nw dn mr nx ny dp mv ko nz oa mx ks ob oc mz kw od oe nb of bi translated"><strong class="ak"> (e)类似架构</strong></h2><ul class=""><li id="a994" class="nd ne iq kh b ki nf kl ng ko nh ks ni kw nj la og nl nm nn bi translated">最近的一些研究采用了类似的自顶向下和跳过连接，如<a class="ae lk" href="https://medium.com/datadriveninvestor/review-tdm-top-down-modulation-object-detection-3f0efe9e0151" rel="noopener"> TDM </a>，<a class="ae lk" rel="noopener" target="_blank" href="/review-sharpmask-instance-segmentation-6509f7401a61"> SharpMask </a>，<a class="ae lk" href="https://medium.com/datadriveninvestor/review-red-net-residual-encoder-decoder-network-denoising-super-resolution-cb6364ae161e" rel="noopener"> RED-Net </a>，<a class="ae lk" rel="noopener" target="_blank" href="/review-u-net-biomedical-image-segmentation-d02bf06ca760"> U-Net </a>，这些连接在当时相当流行，但只是在最后阶段进行预测。</li></ul></div><div class="ab cl me mf hu mg" role="separator"><span class="mh bw bk mi mj mk"/><span class="mh bw bk mi mj mk"/><span class="mh bw bk mi mj"/></div><div class="ij ik il im in"><h1 id="0e32" class="ml mm iq bd mn mo mp mq mr ms mt mu mv jw mw jx mx jz my ka mz kc na kd nb nc bi translated"><strong class="ak"> 2。特征金字塔网络(FPN) </strong></h1><figure class="lo lp lq lr gt ls gh gi paragraph-image"><div class="gh gi oh"><img src="../Images/ab35ae3bef9b798460bfd3f0298abfb2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1380/format:webp/1*D_EAjMnlR9v4LqHhEYZJLg.png"/></div><figcaption class="lz ma gj gh gi mb mc bd b be z dk"><strong class="bd md">Feature Pyramid Network (FPN)</strong></figcaption></figure><h2 id="00bf" class="nu mm iq bd mn nv nw dn mr nx ny dp mv ko nz oa mx ks ob oc mz kw od oe nb of bi translated"><strong class="ak"> 2.1。自下而上路径</strong></h2><ul class=""><li id="9d9c" class="nd ne iq kh b ki nf kl ng ko nh ks ni kw nj la og nl nm nn bi translated">自底向上的路径是主干通信网的前馈计算。定义了一个金字塔等级用于每个阶段。每个阶段的最后一层的输出将被用作通过横向连接来丰富自顶向下路径的参考特征图集。</li></ul><h2 id="0810" class="nu mm iq bd mn nv nw dn mr nx ny dp mv ko nz oa mx ks ob oc mz kw od oe nb of bi translated"><strong class="ak"> 2.2。自上而下的路径和横向连接</strong></h2><ul class=""><li id="3623" class="nd ne iq kh b ki nf kl ng ko nh ks ni kw nj la og nl nm nn bi translated">较高分辨率的特征是从较高金字塔等级向上采样的空间上更粗糙但语义上更强的特征图。更具体地说，为了简单起见，使用最近邻将空间分辨率<strong class="kh ir">上采样 2 倍。</strong></li><li id="0cfe" class="nd ne iq kh b ki no kl np ko nq ks nr kw ns la og nl nm nn bi translated">每个横向连接合并来自自下而上路径和自上而下路径的相同空间大小的特征地图。</li><li id="e145" class="nd ne iq kh b ki no kl np ko nq ks nr kw ns la og nl nm nn bi translated">具体来说，<strong class="kh ir">来自自底向上路径的特征图经历 1×1 卷积以降低通道维度。</strong></li><li id="205e" class="nd ne iq kh b ki no kl np ko nq ks nr kw ns la og nl nm nn bi translated">并且<strong class="kh ir">来自自下而上路径和自上而下路径的特征图通过逐元素添加来合并。</strong></li></ul><h2 id="d260" class="nu mm iq bd mn nv nw dn mr nx ny dp mv ko nz oa mx ks ob oc mz kw od oe nb of bi translated">2.3.预言；预测；预告</h2><ul class=""><li id="7e45" class="nd ne iq kh b ki nf kl ng ko nh ks ni kw nj la og nl nm nn bi translated">最后，<strong class="kh ir">在每个合并后的图上附加一个 3×3 的卷积，生成最终的特征图，这是为了减少上采样的混叠效应。</strong>这最后一组特征地图称为{P2，P3，P4，P5}，分别对应{C2，C3，C4，C5}，它们的空间大小相同。</li><li id="f651" class="nd ne iq kh b ki no kl np ko nq ks nr kw ns la og nl nm nn bi translated">因为金字塔的所有级别都像在传统特征化图像金字塔中一样使用共享的分类器/回归器，所以输出<em class="oi"> d </em>处的特征维度固定为<em class="oi"> d </em> = 256。因此，所有额外的卷积层都有 256 通道输出。</li></ul></div><div class="ab cl me mf hu mg" role="separator"><span class="mh bw bk mi mj mk"/><span class="mh bw bk mi mj mk"/><span class="mh bw bk mi mj"/></div><div class="ij ik il im in"><h1 id="2560" class="ml mm iq bd mn mo mp mq mr ms mt mu mv jw mw jx mx jz my ka mz kc na kd nb nc bi translated"><strong class="ak"> 3。FPN 地区提案网络(RPN) </strong></h1><ul class=""><li id="dc4a" class="nd ne iq kh b ki nf kl ng ko nh ks ni kw nj la og nl nm nn bi translated">在<a class="ae lk" rel="noopener" target="_blank" href="/review-faster-r-cnn-object-detection-f5685cb30202">fast R-CNN</a>中的原始 RPN 设计中，在密集的 3×3 滑动窗口上评估一个小子网，在单尺度卷积特征图的顶部，执行对象/非对象二元分类和边界框回归。</li><li id="733f" class="nd ne iq kh b ki no kl np ko nq ks nr kw ns la og nl nm nn bi translated">这是通过一个 3×3 卷积层来实现的，其后是用于对象/非对象分类和回归的<strong class="kh ir">两个兄弟 1×1 卷积</strong>，我们称之为网络<strong class="kh ir">头</strong>。</li><li id="a6b3" class="nd ne iq kh b ki no kl np ko nq ks nr kw ns la og nl nm nn bi translated">此处，RPN 中的单比例尺要素地图被 FPN 所取代。因此，没有必要在特定层上设置多尺度锚盒。</li><li id="023d" class="nd ne iq kh b ki no kl np ko nq ks nr kw ns la og nl nm nn bi translated"><strong class="kh ir">每个级别都有一个标度</strong>分配给每个级别。形式上定义锚点分别在{P2，P3，P4，P5，P6}上有{ T16 }个{32，64，128，256，512 }像素的区域。</li><li id="d9fd" class="nd ne iq kh b ki no kl np ko nq ks nr kw ns la og nl nm nn bi translated">并且<strong class="kh ir">在每个级别，使用{1:2，1:1，2:1}的多个纵横比</strong>。</li><li id="6693" class="nd ne iq kh b ki no kl np ko nq ks nr kw ns la og nl nm nn bi translated">如果对于给定的基础事实框，锚具有最高的 IoU，或者对于任何基础事实框，其 IoU 超过 0.7，则锚被分配正标签，如果对于所有基础事实框，其 IoU 低于 0.3，则锚被分配负标签。</li><li id="1771" class="nd ne iq kh b ki no kl np ko nq ks nr kw ns la og nl nm nn bi translated">头部的参数在所有特征金字塔等级中共享。</li></ul></div><div class="ab cl me mf hu mg" role="separator"><span class="mh bw bk mi mj mk"/><span class="mh bw bk mi mj mk"/><span class="mh bw bk mi mj"/></div><div class="ij ik il im in"><h1 id="93a9" class="ml mm iq bd mn mo mp mq mr ms mt mu mv jw mw jx mx jz my ka mz kc na kd nb nc bi translated">4.探测网络的 FPN</h1><ul class=""><li id="da2c" class="nd ne iq kh b ki nf kl ng ko nh ks ni kw nj la og nl nm nn bi translated">在<a class="ae lk" rel="noopener" target="_blank" href="/review-faster-r-cnn-object-detection-f5685cb30202">fast R-CNN</a>中的原始检测网络中，使用了单尺度特征图。</li><li id="b3a6" class="nd ne iq kh b ki no kl np ko nq ks nr kw ns la og nl nm nn bi translated">这里，为了检测对象，需要将不同尺度的 ROI 分配给金字塔等级。</li><li id="9572" class="nd ne iq kh b ki no kl np ko nq ks nr kw ns la og nl nm nn bi translated">形式上，<strong class="kh ir">宽<em class="oi">宽</em>高<em class="oi">高</em>(在网络的输入图像上)的 ROI 被分配到我们的特征金字塔</strong>的层次<em class="oi"> Pk </em>上，通过:</li></ul><figure class="lo lp lq lr gt ls gh gi paragraph-image"><div class="gh gi oj"><img src="../Images/bfb00ecf72afbc9d850d8117f464d98c.png" data-original-src="https://miro.medium.com/v2/resize:fit:716/format:webp/1*8uSkM4Dx5it_eH-pTQKzLQ.png"/></div></figure><ul class=""><li id="a732" class="nd ne iq kh b ki kj kl km ko ok ks ol kw om la og nl nm nn bi translated">使用 224，因为这是标准的 ImageNet 预训练大小。</li><li id="e670" class="nd ne iq kh b ki no kl np ko nq ks nr kw ns la og nl nm nn bi translated">而<a class="ae lk" rel="noopener" target="_blank" href="/review-faster-r-cnn-object-detection-f5685cb30202">更快的 R-CNN </a>使用 C4 作为单尺度特征图，<em class="oi"> k </em> 0 设置为 4。</li><li id="1d28" class="nd ne iq kh b ki no kl np ko nq ks nr kw ns la og nl nm nn bi translated">因此，如果 224×224，k = 4。我们用 P4。</li><li id="8f72" class="nd ne iq kh b ki no kl np ko nq ks nr kw ns la og nl nm nn bi translated">如果 112×112，k = 3。它被映射到 P3 的更高分辨率级别。</li><li id="0d46" class="nd ne iq kh b ki no kl np ko nq ks nr kw ns la og nl nm nn bi translated">预测器头部(在<a class="ae lk" href="https://medium.com/coinmonks/review-fast-r-cnn-object-detection-a82e172e87ba" rel="noopener">快速 R-CNN </a>中，头部是特定于类别的分类器和包围盒回归器)被附加到所有级别的所有 ROI。同样，无论级别如何，磁头都共享参数。</li><li id="1d7d" class="nd ne iq kh b ki no kl np ko nq ks nr kw ns la og nl nm nn bi translated">采用 RoI pooling 提取 7×7 特征，并在最终分类和包围盒回归层之前附加两个隐藏的 1024 维全连通(fc)层。</li></ul></div><div class="ab cl me mf hu mg" role="separator"><span class="mh bw bk mi mj mk"/><span class="mh bw bk mi mj mk"/><span class="mh bw bk mi mj"/></div><div class="ij ik il im in"><h1 id="e234" class="ml mm iq bd mn mo mp mq mr ms mt mu mv jw mw jx mx jz my ka mz kc na kd nb nc bi translated"><strong class="ak"> 5。消融实验</strong></h1><h2 id="3af4" class="nu mm iq bd mn nv nw dn mr nx ny dp mv ko nz oa mx ks ob oc mz kw od oe nb of bi translated">5.1.RPN 的烧蚀实验</h2><figure class="lo lp lq lr gt ls gh gi paragraph-image"><div role="button" tabindex="0" class="lt lu di lv bf lw"><div class="gh gi on"><img src="../Images/734fde5180b14b03c8fe9a31af443839.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Fzc7YB1mnLYvpwec6eO5ng.png"/></div></div><figcaption class="lz ma gj gh gi mb mc bd b be z dk"><strong class="bd md">Bounding box proposal results of RPN on the COCO minival set</strong></figcaption></figure><h2 id="6719" class="nu mm iq bd mn nv nw dn mr nx ny dp mv ko nz oa mx ks ob oc mz kw od oe nb of bi translated">5.1.1.与基线的比较</h2><ul class=""><li id="1c90" class="nd ne iq kh b ki nf kl ng ko nh ks ni kw nj la og nl nm nn bi translated"><strong class="kh ir"> (b)使用 conv5 与(A)使用 conv4 </strong>相比没有优势:单个更高级的特征地图是不够的，因为在更粗糙的分辨率和更强的语义之间存在权衡。</li><li id="421c" class="nd ne iq kh b ki no kl np ko nq ks nr kw ns la og nl nm nn bi translated"><strong class="kh ir"> (c)将 FPN 放入 RPN 将 AR1k 提高到 56.3 </strong>，比单一等级 RPN 基线提高了 8.0 点。</li><li id="a6a9" class="nd ne iq kh b ki no kl np ko nq ks nr kw ns la og nl nm nn bi translated">此外，<strong class="kh ir">小对象(AR1ks)上的性能大幅提升了 12.9 分</strong>。</li><li id="3721" class="nd ne iq kh b ki no kl np ko nq ks nr kw ns la og nl nm nn bi translated">因此，RPN 上的 FPN 对目标尺度变化具有鲁棒性。</li></ul><h2 id="5ab8" class="nu mm iq bd mn nv nw dn mr nx ny dp mv ko nz oa mx ks ob oc mz kw od oe nb of bi translated">5.1.2.自上而下浓缩</h2><ul class=""><li id="5fc7" class="nd ne iq kh b ki nf kl ng ko nh ks ni kw nj la og nl nm nn bi translated"><strong class="kh ir"> (d)是 FPN，但没有自上而下的路径</strong>。通过这种修改，1×1 横向连接后面跟着 3×3 回旋被附加到自底向上的金字塔上。它<strong class="kh ir">模拟了重用金字塔特征层次</strong>的效果。(即第一幅图中(c)的架构)</li><li id="9ad3" class="nd ne iq kh b ki no kl np ko nq ks nr kw ns la og nl nm nn bi translated">与 FPN (c) 相比<strong class="kh ir">的结果稍逊一筹。</strong></li><li id="bc6b" class="nd ne iq kh b ki no kl np ko nq ks nr kw ns la og nl nm nn bi translated">据推测，这是因为<strong class="kh ir">在自下而上的金字塔(b) </strong>上，不同层次之间存在很大的语义鸿沟，特别是对于非常深的<a class="ae lk" rel="noopener" target="_blank" href="/review-resnet-winner-of-ilsvrc-2015-image-classification-localization-detection-e39402bfa5d8">结果网</a>。</li><li id="5f0d" class="nd ne iq kh b ki no kl np ko nq ks nr kw ns la og nl nm nn bi translated">还评估了不共享磁头参数的(d)的变体，但是观察到类似的性能下降。</li></ul><h2 id="a238" class="nu mm iq bd mn nv nw dn mr nx ny dp mv ko nz oa mx ks ob oc mz kw od oe nb of bi translated">5.1.3.横向连接</h2><ul class=""><li id="527b" class="nd ne iq kh b ki nf kl ng ko nh ks ni kw nj la og nl nm nn bi translated"><strong class="kh ir"> (e)，没有 1×1 横向连接的自上而下的特征金字塔</strong>。这个自上而下的金字塔具有很强的语义特征和精细的分辨率。</li><li id="7fc9" class="nd ne iq kh b ki no kl np ko nq ks nr kw ns la og nl nm nn bi translated">有人认为这些特征的位置并不精确，因为这些地图已经过多次降采样和升采样。</li><li id="275f" class="nd ne iq kh b ki no kl np ko nq ks nr kw ns la og nl nm nn bi translated">(c)中的 FPN 的 AR1k 得分比(e)高 10 分。</li></ul><h2 id="280c" class="nu mm iq bd mn nv nw dn mr nx ny dp mv ko nz oa mx ks ob oc mz kw od oe nb of bi translated">5.1.4.金字塔表示法</h2><ul class=""><li id="b1ce" class="nd ne iq kh b ki nf kl ng ko nh ks ni kw nj la og nl nm nn bi translated"><strong class="kh ir"> (f)，头部被附加到 P2 的最高分辨率、强语义特征地图上。</strong>所有锚点都被分配到 P2 特征地图。</li><li id="4a58" class="nd ne iq kh b ki no kl np ko nq ks nr kw ns la og nl nm nn bi translated">这个变量比基线好，但比 FPN 差。</li></ul><h2 id="f268" class="nu mm iq bd mn nv nw dn mr nx ny dp mv ko nz oa mx ks ob oc mz kw od oe nb of bi translated">5.2.探测网络烧蚀实验</h2><figure class="lo lp lq lr gt ls gh gi paragraph-image"><div role="button" tabindex="0" class="lt lu di lv bf lw"><div class="gh gi oo"><img src="../Images/c690b2d3951c498bd2f98339f8655a3f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*cDCaEgg9nYy6aGtSpRMmsQ.png"/></div></div><figcaption class="lz ma gj gh gi mb mc bd b be z dk"><strong class="bd md">Object detection results of detection network on the COCO minival set</strong></figcaption></figure><ul class=""><li id="737e" class="nd ne iq kh b ki kj kl km ko ok ks ol kw om la og nl nm nn bi translated">消融是在一组固定的建议上进行的。FPN 为 RPN 计算的建议被冻结。检测网络和 RPN 之间的特征是不共享的。</li><li id="46ea" class="nd ne iq kh b ki no kl np ko nq ks nr kw ns la og nl nm nn bi translated">相对于 conv4 (a)上的基线，FPN (c)将 AP 提高了 2.0，将小物体 AP 提高了 2.1。</li><li id="2ae0" class="nd ne iq kh b ki no kl np ko nq ks nr kw ns la og nl nm nn bi translated">移除自上而下的连接(d)或移除横向连接(e)会导致较差的结果。</li><li id="16bd" class="nd ne iq kh b ki no kl np ko nq ks nr kw ns la og nl nm nn bi translated"><strong class="kh ir">去除自上而下的连接(d)会显著降低精度。</strong>在高分辨率地图上使用低级特征会有问题。</li><li id="904e" class="nd ne iq kh b ki no kl np ko nq ks nr kw ns la og nl nm nn bi translated">使用 P2 (e)的单一最精细比例特征地图，其结果(33.4 AP)比 FPN (c)稍差。</li></ul><h2 id="21c3" class="nu mm iq bd mn nv nw dn mr nx ny dp mv ko nz oa mx ks ob oc mz kw od oe nb of bi translated">5.3.检测网络和 RPN 的一致主干架构</h2><figure class="lo lp lq lr gt ls gh gi paragraph-image"><div role="button" tabindex="0" class="lt lu di lv bf lw"><div class="gh gi op"><img src="../Images/29c92c52a97d2c61dad7cc334120bac2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*bgjBxxU9KoXN8eWIVMEUpg.png"/></div></div><figcaption class="lz ma gj gh gi mb mc bd b be z dk"><strong class="bd md">Object detection results with shared features on the COCO minival set</strong></figcaption></figure><ul class=""><li id="6ae6" class="nd ne iq kh b ki kj kl km ko ok ks ol kw om la og nl nm nn bi translated">RPN 和检测网络都使用一致的主干架构。(但尚未共享功能)</li><li id="0dee" class="nd ne iq kh b ki no kl np ko nq ks nr kw ns la og nl nm nn bi translated">FPN (c)比这个强基线好 2.3 点 AP 和 3.8 点 AP@0.5。(( a)和(b)中的基线优于<a class="ae lk" rel="noopener" target="_blank" href="/review-resnet-winner-of-ilsvrc-2015-image-classification-localization-detection-e39402bfa5d8"> ResNet </a>中显示的基线。)</li></ul><h2 id="c02f" class="nu mm iq bd mn nv nw dn mr nx ny dp mv ko nz oa mx ks ob oc mz kw od oe nb of bi translated">5.4.检测网络和 RPN 的共享功能</h2><figure class="lo lp lq lr gt ls gh gi paragraph-image"><div class="gh gi oq"><img src="../Images/d21d4c4fc92e0d5984289af92d222cc3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1026/format:webp/1*K_j00lwjOxTlaA1GWFXpmQ.png"/></div><figcaption class="lz ma gj gh gi mb mc bd b be z dk"><strong class="bd md">Object detection results with shared features using </strong><a class="ae lk" rel="noopener" target="_blank" href="/review-resnet-winner-of-ilsvrc-2015-image-classification-localization-detection-e39402bfa5d8"><strong class="bd md">ResNet</strong></a><strong class="bd md"> on the COCO minival set</strong></figcaption></figure><ul class=""><li id="37ce" class="nd ne iq kh b ki kj kl km ko ok ks ol kw om la og nl nm nn bi translated">共享要素可以略微提高精确度。特性共享也减少了测试时间。FPN 在单个 NVIDIA M40 GPU 上对<a class="ae lk" rel="noopener" target="_blank" href="/review-resnet-winner-of-ilsvrc-2015-image-classification-localization-detection-e39402bfa5d8"> ResNet-50 </a>的每幅图像的推理时间为 0.148 秒，对<a class="ae lk" rel="noopener" target="_blank" href="/review-resnet-winner-of-ilsvrc-2015-image-classification-localization-detection-e39402bfa5d8"> ResNet-101 </a>的推理时间为 0.172 秒。</li></ul></div><div class="ab cl me mf hu mg" role="separator"><span class="mh bw bk mi mj mk"/><span class="mh bw bk mi mj mk"/><span class="mh bw bk mi mj"/></div><div class="ij ik il im in"><h1 id="a051" class="ml mm iq bd mn mo mp mq mr ms mt mu mv jw mw jx mx jz my ka mz kc na kd nb nc bi translated"><strong class="ak"> 6。与最先进方法的比较</strong></h1><h2 id="045c" class="nu mm iq bd mn nv nw dn mr nx ny dp mv ko nz oa mx ks ob oc mz kw od oe nb of bi translated">6.1.可可检测挑战</h2><figure class="lo lp lq lr gt ls gh gi paragraph-image"><div role="button" tabindex="0" class="lt lu di lv bf lw"><div class="gh gi or"><img src="../Images/1938b9b150f2e4132ebaac3b8fdecd10.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Z6TnCWIb3ZiYPL5qtcdHfA.png"/></div></div><figcaption class="lz ma gj gh gi mb mc bd b be z dk"><strong class="bd md">Comparisons of single-model results on the COCO detection benchmark</strong></figcaption></figure><ul class=""><li id="1a48" class="nd ne iq kh b ki kj kl km ko ok ks ol kw om la og nl nm nn bi translated">在测试开发集上，我们的方法比现有的最佳结果增加了 0.5 点的 AP (36.2 对 35.7)和 3.4 点的 AP@0.5 (59.1 对 55.7)。</li><li id="f830" class="nd ne iq kh b ki no kl np ko nq ks nr kw ns la og nl nm nn bi translated"><a class="ae lk" rel="noopener" target="_blank" href="/review-g-rmi-winner-in-2016-coco-detection-object-detection-af3f2eaf87e4"><strong class="kh ir">G-RMI</strong></a>:2016 年冠军。</li><li id="872d" class="nd ne iq kh b ki no kl np ko nq ks nr kw ns la og nl nm nn bi translated"><strong class="kh ir">更快的 R-cnn++</strong>:使用<a class="ae lk" rel="noopener" target="_blank" href="/review-faster-r-cnn-object-detection-f5685cb30202">更快的 R-CNN </a>、<a class="ae lk" rel="noopener" target="_blank" href="/review-resnet-winner-of-ilsvrc-2015-image-classification-localization-detection-e39402bfa5d8"> ResNet </a>和<a class="ae lk" href="https://medium.com/datadriveninvestor/review-noc-winner-in-2015-coco-ilsvrc-detection-object-detection-d5cc84e372a" rel="noopener">NOC</a>的 2016 年获胜者。</li><li id="02e6" class="nd ne iq kh b ki no kl np ko nq ks nr kw ns la og nl nm nn bi translated"><a class="ae lk" rel="noopener" target="_blank" href="/review-ion-inside-outside-net-2nd-runner-up-in-2015-coco-detection-object-detection-da19993f4766"><strong class="kh ir">ION</strong></a>:2015 年亚军，它使用了修改的 IRNN 和跳过池来提取多个尺度和抽象层次的信息。</li><li id="53be" class="nd ne iq kh b ki no kl np ko nq ks nr kw ns la og nl nm nn bi translated">FPN 在这里没有利用许多流行的改进，如迭代回归、硬负挖掘、上下文建模、更强的数据扩充等。</li></ul><h2 id="f358" class="nu mm iq bd mn nv nw dn mr nx ny dp mv ko nz oa mx ks ob oc mz kw od oe nb of bi translated">6.2.扩展:细分建议</h2><figure class="lo lp lq lr gt ls gh gi paragraph-image"><div class="gh gi os"><img src="../Images/3d7761208cb51b5ddc8cfa37319a87c9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1282/format:webp/1*Ha3gguQtVGHEqoAU1DNGrw.png"/></div><figcaption class="lz ma gj gh gi mb mc bd b be z dk"><strong class="bd md">FPN for object segment proposals</strong></figcaption></figure><figure class="lo lp lq lr gt ls gh gi paragraph-image"><div class="gh gi ot"><img src="../Images/bfc3ab7429a2de39889ef9744c4ed8d0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1242/format:webp/1*dHDZUlNNJZfx0DpD5nUJ3w.png"/></div><figcaption class="lz ma gj gh gi mb mc bd b be z dk"><strong class="bd md">Instance segmentation proposals evaluated on the first 5k COCO val images</strong></figcaption></figure><ul class=""><li id="cd1e" class="nd ne iq kh b ki kj kl km ko ok ks ol kw om la og nl nm nn bi translated">fpn 按照<a class="ae lk" rel="noopener" target="_blank" href="/review-deepmask-instance-segmentation-30327a072339">深度掩码</a> / <a class="ae lk" rel="noopener" target="_blank" href="/review-sharpmask-instance-segmentation-6509f7401a61">清晰度掩码</a>框架生成分割建议。</li><li id="d0a1" class="nd ne iq kh b ki no kl np ko nq ks nr kw ns la og nl nm nn bi translated">windows 上的 MLP，用于生成密集的对象片段，输出维度为 14×14 掩码和对象分数。</li><li id="006b" class="nd ne iq kh b ki no kl np ko nq ks nr kw ns la og nl nm nn bi translated">与<a class="ae lk" rel="noopener" target="_blank" href="/review-deepmask-instance-segmentation-30327a072339"> DeepMask </a>、<a class="ae lk" rel="noopener" target="_blank" href="/review-sharpmask-instance-segmentation-6509f7401a61"> SharpMask </a>和<a class="ae lk" rel="noopener" target="_blank" href="/review-instancefcn-instance-sensitive-score-maps-instance-segmentation-dbfe67d4ee92"> InstanceFCN </a>相比，FPN <strong class="kh ir">比这些方法的精度高出 8.3 个百分点以上</strong>，而<strong class="kh ir">在小物体上的精度几乎是后者的两倍</strong>。</li><li id="c40f" class="nd ne iq kh b ki no kl np ko nq ks nr kw ns la og nl nm nn bi translated">现有的掩模建议方法是基于密集采样的图像金字塔，使得它们在计算上很昂贵。</li><li id="ebab" class="nd ne iq kh b ki no kl np ko nq ks nr kw ns la og nl nm nn bi translated">FPN 以每秒 6 到 7 帧的速度运行要快得多。</li></ul></div><div class="ab cl me mf hu mg" role="separator"><span class="mh bw bk mi mj mk"/><span class="mh bw bk mi mj mk"/><span class="mh bw bk mi mj"/></div><div class="ij ik il im in"><p id="08c9" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">尽管<a class="ae lk" rel="noopener" target="_blank" href="/review-resnet-winner-of-ilsvrc-2015-image-classification-localization-detection-e39402bfa5d8"> ResNet </a>和<a class="ae lk" rel="noopener" target="_blank" href="/review-faster-r-cnn-object-detection-f5685cb30202">fast R-CNN</a>卓有成效，但 FPN 在几个强劲的基线和竞赛获胜者方面仍有显著进步。</p></div><div class="ab cl me mf hu mg" role="separator"><span class="mh bw bk mi mj mk"/><span class="mh bw bk mi mj mk"/><span class="mh bw bk mi mj"/></div><div class="ij ik il im in"><h2 id="d664" class="nu mm iq bd mn nv nw dn mr nx ny dp mv ko nz oa mx ks ob oc mz kw od oe nb of bi translated">参考</h2><p id="3d70" class="pw-post-body-paragraph kf kg iq kh b ki nf jr kk kl ng ju kn ko ou kq kr ks ov ku kv kw ow ky kz la ij bi translated">【2017 CVPR】【FPN】<br/><a class="ae lk" href="https://arxiv.org/abs/1612.03144" rel="noopener ugc nofollow" target="_blank">用于物体检测的特征金字塔网络</a></p><h2 id="24a7" class="nu mm iq bd mn nv nw dn mr nx ny dp mv ko nz oa mx ks ob oc mz kw od oe nb of bi translated">我的相关评论</h2><p id="4da9" class="pw-post-body-paragraph kf kg iq kh b ki nf jr kk kl ng ju kn ko ou kq kr ks ov ku kv kw ow ky kz la ij bi translated">)(我)(们)(都)(不)(想)(到)(这)(些)(人)(,)(我)(们)(都)(不)(想)(要)(到)(这)(些)(人)(,)(但)(是)(这)(些)(人)(还)(不)(想)(到)(这)(些)(人)(,)(我)(们)(还)(没)(想)(到)(这)(些)(事)(,)(我)(们)(就)(想)(到)(了)(这)(些)(人)(们)(,)(我)(们)(们)(都)(不)(想)(要)(到)(这)(些)(人)(,)(但)(我)(们)(还)(没)(想)(到)(这)(些)(事)(,)(我)(们)(还)(没)(想)(到)(这)(里)(来)(。 )(我)(们)(都)(不)(知)(道)(,)(我)(们)(还)(是)(不)(知)(道)(,)(我)(们)(还)(是)(不)(知)(道)(,)(我)(们)(还)(是)(不)(知)(道)(,)(我)(们)(还)(是)(不)(知)(道)(,)(我)(们)(还)(是)(不)(知)(道)(,)(我)(们)(还)(是)(不)(知)(道)(,)(我)(们)(还)(是)(不)(知)(道)(。</p><p id="8b77" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir">物体检测<br/></strong><a class="ae lk" href="https://medium.com/coinmonks/review-of-overfeat-winner-of-ilsvrc-2013-localization-task-object-detection-a6f8b9044754" rel="noopener">过食</a><a class="ae lk" href="https://medium.com/coinmonks/review-r-cnn-object-detection-b476aba290d1" rel="noopener">R-CNN</a><a class="ae lk" href="https://medium.com/coinmonks/review-fast-r-cnn-object-detection-a82e172e87ba" rel="noopener">快 R-CNN</a><a class="ae lk" rel="noopener" target="_blank" href="/review-faster-r-cnn-object-detection-f5685cb30202">快 R-CNN</a><a class="ae lk" rel="noopener" target="_blank" href="/review-deepid-net-def-pooling-layer-object-detection-f72486f1a0f6">DeepID-Net</a>】<a class="ae lk" rel="noopener" target="_blank" href="/review-r-fcn-positive-sensitive-score-maps-object-detection-91cd2389345c">R-FCN</a>】<a class="ae lk" rel="noopener" target="_blank" href="/review-ion-inside-outside-net-2nd-runner-up-in-2015-coco-detection-object-detection-da19993f4766">离子</a><a class="ae lk" rel="noopener" target="_blank" href="/review-multipath-mpn-1st-runner-up-in-2015-coco-detection-segmentation-object-detection-ea9741e7c413">多路径网</a><a class="ae lk" href="https://medium.com/datadriveninvestor/review-noc-winner-in-2015-coco-ilsvrc-detection-object-detection-d5cc84e372a" rel="noopener">NoC</a></p><p id="6582" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir">语义切分<br/></strong><a class="ae lk" rel="noopener" target="_blank" href="/review-fcn-semantic-segmentation-eb8c9b50d2d1">FCN</a><a class="ae lk" rel="noopener" target="_blank" href="/review-deconvnet-unpooling-layer-semantic-segmentation-55cf8a6e380e">de convnet</a><a class="ae lk" rel="noopener" target="_blank" href="/review-deeplabv1-deeplabv2-atrous-convolution-semantic-segmentation-b51c5fbde92d">deeplabv 1&amp;deeplabv 2</a>】<a class="ae lk" href="https://medium.com/datadriveninvestor/review-parsenet-looking-wider-to-see-better-semantic-segmentation-aa6b6a380990" rel="noopener">parse net</a>】<a class="ae lk" rel="noopener" target="_blank" href="/review-dilated-convolution-semantic-segmentation-9d5a5bd768f5">dilated net</a><a class="ae lk" rel="noopener" target="_blank" href="/review-pspnet-winner-in-ilsvrc-2016-semantic-segmentation-scene-parsing-e089e5df177d">PSPNet</a>]</p><p id="fc65" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir">生物医学图像分割<br/></strong></p><p id="3134" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir">实例分割<br/>T28】[<a class="ae lk" rel="noopener" target="_blank" href="/review-deepmask-instance-segmentation-30327a072339">深度掩码</a> ] [ <a class="ae lk" rel="noopener" target="_blank" href="/review-sharpmask-instance-segmentation-6509f7401a61">锐度掩码</a> ] [ <a class="ae lk" rel="noopener" target="_blank" href="/review-multipath-mpn-1st-runner-up-in-2015-coco-detection-segmentation-object-detection-ea9741e7c413">多路径网络</a> ] [ <a class="ae lk" rel="noopener" target="_blank" href="/review-mnc-multi-task-network-cascade-winner-in-2015-coco-segmentation-instance-segmentation-42a9334e6a34"> MNC </a> ] [ <a class="ae lk" rel="noopener" target="_blank" href="/review-instancefcn-instance-sensitive-score-maps-instance-segmentation-dbfe67d4ee92">实例中心</a> ] [ <a class="ae lk" rel="noopener" target="_blank" href="/review-fcis-winner-in-2016-coco-segmentation-instance-segmentation-ee2d61f465e2"> FCIS </a></strong></p><p id="58de" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir">超分辨率<br/></strong><a class="ae lk" href="https://medium.com/coinmonks/review-srcnn-super-resolution-3cb3a4f67a7c" rel="noopener">Sr CNN</a><a class="ae lk" rel="noopener" target="_blank" href="/review-fsrcnn-super-resolution-80ca2ee14da4">fsr CNN</a><a class="ae lk" rel="noopener" target="_blank" href="/review-vdsr-super-resolution-f8050d49362f">VDSR</a><a class="ae lk" href="https://medium.com/datadriveninvestor/review-espcn-real-time-sr-super-resolution-8dceca249350" rel="noopener">ESPCN</a><a class="ae lk" href="https://medium.com/datadriveninvestor/review-red-net-residual-encoder-decoder-network-denoising-super-resolution-cb6364ae161e" rel="noopener">红网</a>】</p></div></div>    
</body>
</html>