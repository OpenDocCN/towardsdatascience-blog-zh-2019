<html>
<head>
<title>Analytics Building Blocks: Prediction</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">分析构建模块:预测</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/regression-block-a-modularized-approach-to-test-multiple-regression-algorithms-with-b446ac5160e?source=collection_archive---------14-----------------------#2019-01-27">https://towardsdatascience.com/regression-block-a-modularized-approach-to-test-multiple-regression-algorithms-with-b446ac5160e?source=collection_archive---------14-----------------------#2019-01-27</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><blockquote class="jn jo jp"><p id="ab70" class="jq jr js jt b ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko ij bi translated">一款模块化笔记本电脑，可在控制面板中使用最少的编码来调整和比较 11 种预测算法</p></blockquote><p id="70cd" class="pw-post-body-paragraph jq jr iq jt b ju jv jw jx jy jz ka kb kp kd ke kf kq kh ki kj kr kl km kn ko ij bi translated">本文总结并解释了我的回归模块的关键模块(我正在开发的用于执行常见分析任务的简单模块化笔记本之一)。该笔记本旨在帮助对回归模型和 Python 编程有一定了解的用户更快地进行实验。GitHub 到笔记本的链接在文章底部！</p><figure class="kt ku kv kw gt kx gh gi paragraph-image"><div role="button" tabindex="0" class="ky kz di la bf lb"><div class="gh gi ks"><img src="../Images/a8d30e7aba1dafdf23b5fd25ab44f844.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*gZ--d3VD3OtEwxaZazTC4w.png"/></div></div></figure><h2 id="fa43" class="le lf iq bd lg lh li dn lj lk ll dp lm kp ln lo lp kq lq lr ls kr lt lu lv lw bi translated">介绍</h2><p id="b479" class="pw-post-body-paragraph jq jr iq jt b ju lx jw jx jy ly ka kb kp lz ke kf kq ma ki kj kr mb km kn ko ij bi translated">在从事我最喜欢的一个项目时，我意识到有时测试不同的模型形式以确定最合适的模型更好，这种模型根据手头的问题提供了准确性、复杂性和执行效率的良好平衡。RapidMiner 等一些软件提供此功能。然而，出于这个目的使用软件产品会导致在调整模型和探索一些复杂性方面的黑盒方法。因此，我决定创建一个简单的 python 脚本，它具有足够的模块化和参数化，能够测试和调整许多广泛使用的预测算法，只需对代码进行最小的更改。<br/>本笔记本摘要如下:</p><h2 id="7c45" class="le lf iq bd lg lh li dn lj lk ll dp lm kp ln lo lp kq lq lr ls kr lt lu lv lw bi translated">目标:</h2><p id="0242" class="pw-post-body-paragraph jq jr iq jt b ju lx jw jx jy ly ka kb kp lz ke kf kq ma ki kj kr mb km kn ko ij bi translated">在 Python 中以最少的人工干预测试、调整和比较各种回归模型。<br/>本模块包含的车型有:</p><p id="a47d" class="pw-post-body-paragraph jq jr iq jt b ju jv jw jx jy jz ka kb kp kd ke kf kq kh ki kj kr kl km kn ko ij bi translated">*线性回归<br/> *岭回归<br/> *拉索回归<br/> * K 近邻<br/> *贝叶斯岭<br/> *决策树回归<br/> *随机森林<br/> *装袋(默认使用决策树)<br/> *梯度提升<br/> * XGBoost <br/> *支持向量机</p><h2 id="1fc4" class="le lf iq bd lg lh li dn lj lk ll dp lm kp ln lo lp kq lq lr ls kr lt lu lv lw bi translated">用户熟练程度:</h2><p id="610b" class="pw-post-body-paragraph jq jr iq jt b ju lx jw jx jy ly ka kb kp lz ke kf kq ma ki kj kr mb km kn ko ij bi translated">用户应该对每种算法的工作原理有一个直观的了解，并且很好地理解改变一个特定的超参数会如何影响结果。需要对 python 有基本的了解，以便能够有效地利用代码，并根据需求进一步定制代码。</p><h2 id="8a41" class="le lf iq bd lg lh li dn lj lk ll dp lm kp ln lo lp kq lq lr ls kr lt lu lv lw bi translated">关键可修改输入:</h2><p id="3a99" class="pw-post-body-paragraph jq jr iq jt b ju lx jw jx jy ly ka kb kp lz ke kf kq ma ki kj kr mb km kn ko ij bi translated">以下是关键输入(行内注释中为每个输入提供了更多详细信息)。这些部分在代码中以注释'<strong class="jt ir">突出显示，在此处进行修改</strong>':</p><p id="2743" class="pw-post-body-paragraph jq jr iq jt b ju jv jw jx jy jz ka kb kp kd ke kf kq kh ki kj kr kl km kn ko ij bi translated">*用于回归分析的输入数据集:在本例中，我使用了来自 pandas 默认数据集的“糖尿病”数据集<br/> *测试数据比例:在 0 到 1 之间，默认为 0.3(或 30%) <br/> *归一化:0 —无归一化，1 —最小-最大缩放， 2 — Z-score scaling <br/> *要测试的模型对象列表<br/> *网格搜索的折叠数(超参数调整)<br/> *确定最佳模型的评分标准(例如均方误差)—代码注释中提供了更多详细信息<br/> * Flag 用于查看模型拟合期间终端上的详细程度:0 —无输出，1 —所有详细信息，2 —进度条<br/> *超参数库:代码中的全局字典，为要调整的每个模型表单提供一组超参数</p><h2 id="10cc" class="le lf iq bd lg lh li dn lj lk ll dp lm kp ln lo lp kq lq lr ls kr lt lu lv lw bi translated">一般执行步骤:</h2><p id="0e04" class="pw-post-body-paragraph jq jr iq jt b ju lx jw jx jy ly ka kb kp lz ke kf kq ma ki kj kr mb km kn ko ij bi translated">获取这些输入后，对考虑中的每个模型形式的<strong class="jt ir">执行以下操作:</strong></p><p id="949a" class="pw-post-body-paragraph jq jr iq jt b ju jv jw jx jy jz ka kb kp kd ke kf kq kh ki kj kr kl km kn ko ij bi translated">*正向特征选择<br/> *标准化<br/> *网格搜索超参数调整<br/> *最佳模型的度量计算</p><h2 id="c18f" class="le lf iq bd lg lh li dn lj lk ll dp lm kp ln lo lp kq lq lr ls kr lt lu lv lw bi translated">输出:</h2><p id="571a" class="pw-post-body-paragraph jq jr iq jt b ju lx jw jx jy ly ka kb kp lz ke kf kq ma ki kj kr mb km kn ko ij bi translated">创建 pandas 数据框架“结果”,为您测试的每个模型提供以下指标</p><p id="84da" class="pw-post-body-paragraph jq jr iq jt b ju jv jw jx jy jz ka kb kp kd ke kf kq kh ki kj kr kl km kn ko ij bi translated">*具有最佳超参数的模型细节<br/> *训练和测试均方根误差<br/> *训练和测试平均绝对百分比误差</p><p id="db59" class="pw-post-body-paragraph jq jr iq jt b ju jv jw jx jy jz ka kb kp kd ke kf kq kh ki kj kr kl km kn ko ij bi translated">该表有助于在各种模型形式之间进行比较，而训练和测试度量可以是发现过度拟合的良好指标。</p><h2 id="677b" class="le lf iq bd lg lh li dn lj lk ll dp lm kp ln lo lp kq lq lr ls kr lt lu lv lw bi translated">重要提示:</h2><p id="2532" class="pw-post-body-paragraph jq jr iq jt b ju lx jw jx jy ly ka kb kp lz ke kf kq ma ki kj kr mb km kn ko ij bi translated">该模块不以任何方式处理特征工程，仅基于输入数据执行特征选择。为了改善任何模型的结果，执行有效的特征工程是非常重要的。用户可能会观察到一种模型形式比另一种给出更好的结果，但是任何模型的整体性能都可以随着预测变量的改进而显著提高。</p><h2 id="fef0" class="le lf iq bd lg lh li dn lj lk ll dp lm kp ln lo lp kq lq lr ls kr lt lu lv lw bi translated">剧本:</h2><h2 id="8d49" class="le lf iq bd lg lh li dn lj lk ll dp lm kp ln lo lp kq lq lr ls kr lt lu lv lw bi translated">各种任务的模块</h2><p id="798e" class="pw-post-body-paragraph jq jr iq jt b ju lx jw jx jy ly ka kb kp lz ke kf kq ma ki kj kr mb km kn ko ij bi translated">第一个函数根据用户在控制面板中指定的条件，为标准化和网格搜索创建管道。</p><pre class="kt ku kv kw gt mc md me mf aw mg bi"><span id="66dc" class="le lf iq md b gy mh mi l mj mk">def create_pipeline(norm, model):<br/>    if norm == 1:<br/>        scale = StandardScaler()<br/>        pipe = Pipeline([('norm', scale), ('reg', model)])<br/>    elif norm == 2:<br/>        scale = MinMaxScaler()<br/>        pipe = Pipeline([('norm', scale), ('reg', model)])<br/>    else:<br/>        pipe = Pipeline([('reg', model)])<br/>    return pipe</span></pre><p id="fc39" class="pw-post-body-paragraph jq jr iq jt b ju jv jw jx jy jz ka kb kp kd ke kf kq kh ki kj kr kl km kn ko ij bi translated">第二个函数执行正向特征选择，并返回最佳特征的索引。</p><pre class="kt ku kv kw gt mc md me mf aw mg bi"><span id="c277" class="le lf iq md b gy mh mi l mj mk">def select_features(model, X_train, Y_train, selection,<br/>                    score_criteria, see_details, norm=0):<br/>    pipe = create_pipeline(norm, model)<br/>    sfs = SequentialFeatureSelector(pipe,<br/>                                    forward=selection,<br/>                                    k_features='best',<br/>                                    scoring=score_criteria,<br/>                                    verbose=see_details)<br/>    sfs = sfs.fit(X_train, Y_train)<br/>    return list(sfs.k_feature_idx_)</span></pre><p id="0b4c" class="pw-post-body-paragraph jq jr iq jt b ju jv jw jx jy jz ka kb kp kd ke kf kq kh ki kj kr kl km kn ko ij bi translated">此函数对提供的参数网格执行网格搜索，并返回最佳模型对象。</p><pre class="kt ku kv kw gt mc md me mf aw mg bi"><span id="b54a" class="le lf iq md b gy mh mi l mj mk">def run_model(model, param_grid, X_train, Y_train,<br/>              X, Y, score_criteria, folds,<br/>              see_details, norm=0):<br/>    pipe = create_pipeline(norm, model)<br/>    model_grid = GridSearchCV(pipe,<br/>                              param_grid,<br/>                              cv=folds,<br/>                              scoring=score_criteria,<br/>                              verbose=see_details)<br/>    model_grid.fit(X_train, Y_train)</span><span id="d8bf" class="le lf iq md b gy ml mi l mj mk">return model_grid.best_estimator_</span></pre><p id="15b1" class="pw-post-body-paragraph jq jr iq jt b ju jv jw jx jy jz ka kb kp kd ke kf kq kh ki kj kr kl km kn ko ij bi translated">最后一个函数计算最佳超参数组合的所有相关指标，并返回这些指标的 pandas 系列。</p><pre class="kt ku kv kw gt mc md me mf aw mg bi"><span id="99f2" class="le lf iq md b gy mh mi l mj mk">def get_model_eval(model, X_train, Y_train, X_test, Y_test):<br/>    return pd.Series([model, mean_squared_error(Y_train, model.predict(X_train)),<br/>                      mean_squared_error(Y_test, model.predict(X_test)),<br/>                      (abs(model.predict(X_train) - Y_train) / Y_train).mean(),<br/>                      (abs(model.predict(X_test) - Y_test) / Y_test).mean()])</span></pre><h2 id="5ee6" class="le lf iq bd lg lh li dn lj lk ll dp lm kp ln lo lp kq lq lr ls kr lt lu lv lw bi translated">全局超参数字典(<strong class="ak">在此修改</strong>)</h2><p id="4556" class="pw-post-body-paragraph jq jr iq jt b ju lx jw jx jy ly ka kb kp lz ke kf kq ma ki kj kr mb km kn ko ij bi translated">这是该模块中所有模型的各种模型参数的全局字典。基于糖尿病数据集的典型范围的代码中已经填充了一些缺省值集。该词典包含每个模型的一些关键超参数，但并不详尽。鼓励用户访问 scikit-learn 文档以获得所有参数的列表，并根据他们的要求添加到下面的字典中。</p><pre class="kt ku kv kw gt mc md me mf aw mg bi"><span id="7f2c" class="le lf iq md b gy mh mi l mj mk">PARAM_DICT = {<br/>              LinearRegression: {'reg__copy_X': [True, False],<br/>                                 'reg__fit_intercept': [True, False],<br/>                                 'reg__n_jobs': [10, 20]},<br/>              Ridge: {'reg__alpha': [0.1, 1, 100],<br/>                      'reg__copy_X': [True, False],<br/>                      'reg__fit_intercept': [True, False],<br/>                      'reg__tol': [0.1, 1],<br/>                      'reg__solver': ['auto', 'svd', 'cholesky', 'lsqr',<br/>                                      'sparse_cg', 'sag', 'saga']},<br/>              Lasso: {'reg__alpha': [0.1, 1, 100],<br/>                      'reg__copy_X': [True, False],<br/>                      'reg__fit_intercept': [True, False],<br/>                      'reg__tol': [0.1, 1]},</span><span id="7545" class="le lf iq md b gy ml mi l mj mk">KNeighborsRegressor: {'reg__n_neighbors': [5, 30, 100]},<br/>              BayesianRidge: {'reg__alpha_1': [10**-6, 10**-3],<br/>                              'reg__alpha_2': [10**-6, 10**-3],<br/>                              'reg__copy_X': [True, False],<br/>                              'reg__fit_intercept': [True, False],<br/>                              'reg__lambda_1': [10**-6, 10**-3],<br/>                              'reg__lambda_2': [10**-6, 10**-3],<br/>                              'reg__n_iter': [300, 500, 1000],<br/>                              'reg__tol': [0.001, 0.01, 0.1]},</span><span id="dc48" class="le lf iq md b gy ml mi l mj mk">DecisionTreeRegressor: {'reg__max_depth': [5, 10, 20],<br/>                                      'reg__max_features': [0.3, 0.7, 1.0],<br/>                                      'reg__max_leaf_nodes': [10, 50, 100],<br/>                                      'reg__splitter': ['best', 'random']},</span><span id="c704" class="le lf iq md b gy ml mi l mj mk">BaggingRegressor: {<br/>                                 'reg__bootstrap': [True, False],<br/>                                 'reg__bootstrap_features': [True, False],<br/>                                 'reg__max_features': [0.3, 0.7, 1.0],<br/>                                 'reg__max_samples': [0.3, 0.7, 1.0],<br/>                                 'reg__n_estimators': [10, 50, 100]},<br/>              RandomForestRegressor: {'reg__bootstrap': [True, False],<br/>                                      'reg__max_depth': [5, 10, 20],<br/>                                      'reg__max_features': [0.3, 0.7, 1.0],<br/>                                      'reg__max_leaf_nodes': [10, 50, 100],<br/>                                      'reg__min_impurity_decrease': [0, 0.1, 0.2],<br/>                                      'reg__n_estimators': [10, 50, 100]},</span><span id="4671" class="le lf iq md b gy ml mi l mj mk">SVR: {'reg__C': [10**-3, 1, 1000],<br/>                    'reg__kernel': ['linear', 'poly', 'rbf'],<br/>                    'reg__shrinking': [True, False]},</span><span id="dd30" class="le lf iq md b gy ml mi l mj mk">GradientBoostingRegressor: {'reg__learning_rate': [0.1, 0.2, 0.5],<br/>                                          'reg__loss': ['ls', 'lad', 'huber', 'quantile'],<br/>                                          'reg__max_depth': [10, 20, 50],<br/>                                          'reg__max_features': [0.5, 0.8, 1.0],<br/>                                          'reg__max_leaf_nodes': [10, 50, 100],<br/>                                          'reg__min_impurity_decrease': [0, 0.1, 0.2],<br/>                                          'reg__min_samples_leaf': [5, 10, 20],<br/>                                          'reg__min_samples_split': [5, 10, 20],<br/>                                          'reg__n_estimators': [10, 50, 100]},<br/>              XGBRegressor: {'reg__booster': ['gbtree', 'gblinear', 'dart'],<br/>                             'reg__learning_rate': [0.2, 0.5, 0.8],<br/>                             'reg__max_depth': [5, 10, 20],<br/>                             'reg__n_estimators': [10, 50, 100],<br/>                             'reg__reg_alpha': [0.1, 1, 10],<br/>                             'reg__reg_lambda': [0.1, 1, 10],<br/>                             'reg__subsample': [0.3, 0.5, 0.8]},</span><span id="0e6a" class="le lf iq md b gy ml mi l mj mk">}</span></pre><h2 id="58f9" class="le lf iq bd lg lh li dn lj lk ll dp lm kp ln lo lp kq lq lr ls kr lt lu lv lw bi translated">按键输入的用户控制面板(在此进行修改)</h2><p id="6d69" class="pw-post-body-paragraph jq jr iq jt b ju lx jw jx jy ly ka kb kp lz ke kf kq ma ki kj kr mb km kn ko ij bi translated">可以在此处更改模块的输入。这是这个脚本的控制面板，介绍中提到的所有变量都可以在这里修改，以测试各种场景。请参考评论了解变量。</p><pre class="kt ku kv kw gt mc md me mf aw mg bi"><span id="9228" class="le lf iq md b gy mh mi l mj mk"># --------------------------------------------------------------------------<br/># USER CONTROL PANEL, CHANGE THE VARIABLES, MODEL FORMS ETC. HERE</span><span id="578b" class="le lf iq md b gy ml mi l mj mk"># Read data here, define X (features) and Y (Target variable)<br/>data = datasets.load_diabetes()<br/>X = pd.DataFrame(data['data'])<br/>X.columns = data['feature_names']<br/>Y = data['target']</span><span id="5046" class="le lf iq md b gy ml mi l mj mk"># Specify size of test data (%)<br/>size = 0.3</span><span id="062d" class="le lf iq md b gy ml mi l mj mk"># Set random seed for sampling consistency<br/>random.seed(100)</span><span id="4bee" class="le lf iq md b gy ml mi l mj mk"># Set type of normalization you want to perform<br/># 0 - No Normalization, 1 - Min-max scaling, 2 - Zscore scaling<br/>norm = 0</span><span id="1ea5" class="le lf iq md b gy ml mi l mj mk"># Mention all model forms you want to run - Model Objects<br/>to_run = [LinearRegression,<br/>          Ridge,<br/>          Lasso,<br/>          KNeighborsRegressor,<br/>          DecisionTreeRegressor,<br/>          BaggingRegressor,<br/>          SVR,<br/>          XGBRegressor]</span><span id="76f2" class="le lf iq md b gy ml mi l mj mk"># Specify number of crossvalidation folds<br/>folds = 5</span><span id="4bc6" class="le lf iq md b gy ml mi l mj mk"># Specify model selection criteria<br/># Possible values are:<br/># ‘explained_variance’<br/># ‘neg_mean_absolute_error’<br/># ‘neg_mean_squared_error’<br/># ‘neg_mean_squared_log_error’<br/># ‘neg_median_absolute_error’<br/># ‘r2’<br/>score_criteria = 'neg_mean_absolute_error'</span><span id="5b32" class="le lf iq md b gy ml mi l mj mk"># Specify details of terminal output you'd like to see<br/># 0 - No output, 1 - All details, 2 - Progress bar<br/># Outputs might vary based on individual functions<br/>see_details = 1</span><span id="903f" class="le lf iq md b gy ml mi l mj mk"># --------------------------------------------------------------------------</span></pre><h2 id="c459" class="le lf iq bd lg lh li dn lj lk ll dp lm kp ln lo lp kq lq lr ls kr lt lu lv lw bi translated">模型执行</h2><p id="67f6" class="pw-post-body-paragraph jq jr iq jt b ju lx jw jx jy ly ka kb kp lz ke kf kq ma ki kj kr mb km kn ko ij bi translated">该部分迭代地为用户指定的每个模型找到最佳的超参数集，计算度量并填充结果表，用于进一步的分析/实验。</p><pre class="kt ku kv kw gt mc md me mf aw mg bi"><span id="18e4" class="le lf iq md b gy mh mi l mj mk"># Model execution part, resuts will be stored in the dataframe 'results'<br/># Best model can be selected based on these criteria</span><span id="f4ad" class="le lf iq md b gy ml mi l mj mk">results = pd.DataFrame(columns=['ModelForm', 'TrainRMSE', 'TestRMSE',<br/>                                'TrainMAPE', 'TestMAPE'])</span><span id="5829" class="le lf iq md b gy ml mi l mj mk">X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=size)</span><span id="3dad" class="le lf iq md b gy ml mi l mj mk">for model in to_run:<br/>    with warnings.catch_warnings():<br/>        warnings.simplefilter('ignore')<br/>        best_feat = select_features(model(), X_train, Y_train, True,<br/>                                    score_criteria, see_details, norm)<br/>        model = run_model(model(), PARAM_DICT[model],<br/>                          X_train.iloc[:, best_feat],<br/>                          Y_train,<br/>                          X.iloc[:, best_feat], Y,<br/>                          score_criteria, folds, see_details, norm)<br/>        stats = get_model_eval(model, X_train.iloc[:, best_feat], Y_train,<br/>                               X_test.iloc[:, best_feat], Y_test)<br/>        stats.index = results.columns<br/>        results = results.append(stats, ignore_index=True)</span><span id="3878" class="le lf iq md b gy ml mi l mj mk">print(results)</span></pre><h2 id="3dd5" class="le lf iq bd lg lh li dn lj lk ll dp lm kp ln lo lp kq lq lr ls kr lt lu lv lw bi translated">结论</h2><figure class="kt ku kv kw gt kx gh gi paragraph-image"><div class="gh gi mm"><img src="../Images/6c1f4dd8761d077218ae697fd704211b.png" data-original-src="https://miro.medium.com/v2/resize:fit:928/format:webp/1*v4bIQgmNC9S0IdfZixMhfA.png"/></div><figcaption class="mn mo gj gh gi mp mq bd b be z dk">Results data frame</figcaption></figure><p id="1eef" class="pw-post-body-paragraph jq jr iq jt b ju jv jw jx jy jz ka kb kp kd ke kf kq kh ki kj kr kl km kn ko ij bi translated">从结果表中可以看出，在该场景中测试的所有模型形式中，最基本的线性回归模型提供了最佳且一致的性能。这也强调了特征工程的重要性，因为我们期望集合模型总体上表现出更好的性能。另一方面，基于训练和测试指标，XGB 回归器显示出过度拟合的迹象。所有其他型号都提供类似的性能。这表明还需要测试不同范围的超参数。我希望这个模块能够加快实验速度，并提供一个机会，根据您的需求在它的基础上进行进一步的定制！</p><p id="2a78" class="pw-post-body-paragraph jq jr iq jt b ju jv jw jx jy jz ka kb kp kd ke kf kq kh ki kj kr kl km kn ko ij bi translated">点击此处查看完整的笔记本:</p><div class="mr ms gp gr mt mu"><a href="https://github.com/himanshu0394/AnalyticsBuildingBlocks/blob/master/Prediction%20Block.ipynb" rel="noopener  ugc nofollow" target="_blank"><div class="mv ab fo"><div class="mw ab mx cl cj my"><h2 class="bd ir gy z fp mz fr fs na fu fw ip bi translated">himan Shu 0394/分析构建模块</h2><div class="nb l"><h3 class="bd b gy z fp mz fr fs na fu fw dk translated">在 GitHub 上创建一个帐户，为 himan Shu 0394/AnalyticsBuildingBlocks 开发做贡献。</h3></div><div class="nc l"><p class="bd b dl z fp mz fr fs na fu fw dk translated">github.com</p></div></div><div class="nd l"><div class="ne l nf ng nh nd ni lc mu"/></div></div></a></div><p id="2e54" class="pw-post-body-paragraph jq jr iq jt b ju jv jw jx jy jz ka kb kp kd ke kf kq kh ki kj kr kl km kn ko ij bi translated">请随时提供任何建议和反馈！</p></div></div>    
</body>
</html>