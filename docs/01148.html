<html>
<head>
<title>Exploring virtual worlds with reinforcement learning</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">用强化学习探索虚拟世界</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/exploring-virtual-worlds-with-reinforcement-learning-25a245e9afea?source=collection_archive---------28-----------------------#2019-02-21">https://towardsdatascience.com/exploring-virtual-worlds-with-reinforcement-learning-25a245e9afea?source=collection_archive---------28-----------------------#2019-02-21</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><p id="4765" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">你在办公室里走来走去，你花了很多时间努力工作，喝咖啡，和同事打乒乓球。突然，一个危险的影子出现了。你转过身，看到一个巨大的黄色球向你滚来。他张开大嘴，准备把你整个吃掉，而你开始逃跑。那个黄色的球一直跟着你，好像它是一个真正的人。你躲不了。你逃不掉的。吃豆人会来抓你的。</p><figure class="kn ko kp kq gt kr gh gi paragraph-image"><div role="button" tabindex="0" class="ks kt di ku bf kv"><div class="gh gi km"><img src="../Images/d61b52a9417632788455593b81649a2e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*V1vEt1fgw_OggcmxggOiBQ.png"/></div></div></figure><p id="55c2" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">上面的场景可能听起来很可怕，但它描述了一种游戏，这种游戏可以通过我们正在研究的东西来开发:增强现实和人工智能的结合。‘我们’，就是口袋里的<a class="ae ky" href="https://inthepocket.com/blog" rel="noopener ugc nofollow" target="_blank"> <strong class="jp ir">的人</strong> </a>，欧洲最好的数码产品工作室。我们公司由多个团队组成，其中一个团队专注于 AR，另一个团队专注于 AI。第一个是和<strong class="jp ir"> Unity </strong>合作，而后者对<strong class="jp ir"> TensorFlow </strong>了如指掌。最近他们联手创造了一些奇迹。</p><p id="f925" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我们的增强现实团队 masters Unity——他们去年夏天为室内导航的内部演示建立了我们办公室的 3D 模型。两个物体被添加到这个环境中:一个绿色的玩具坦克和一个黄色的积木。<strong class="jp ir">我们的目标很简单:奖励碰撞的坦克&amp;在我们的虚拟办公室中捕获随机放置的方块。</strong>为了做到这一点，我们——尤其是我们的实习生 Fabrice——利用了来自 Unity 员工的<a class="ae ky" href="https://github.com/Unity-Technologies/ml-agents" rel="noopener ugc nofollow" target="_blank"> ml-agents </a>。这是一个很好的框架，可以帮助你用机器学习的方法立刻创建代理。最先进的强化学习算法，如有耐心的近似策略优化，都是现成的，并且<a class="ae ky" href="https://arxiv.org/abs/1707.06347" rel="noopener ugc nofollow" target="_blank">被证明非常有效</a>。</p><p id="8ba5" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">起初，代理人有点愚蠢，当它被随意扔在一个房间时，他没能逃出去。但几个小时后，它学会了走出房间，尽管撞到了很多墙。我们更新了我们的奖励功能，以惩罚当它撞上墙壁和继续训练的代理人。代理开始越来越好地捕捉黄色块！我们注意到，当它们在视线范围内但距离很远时，它经常会错过它们。所以我们增加了光线投射的密度，代理人再次得到改善。<strong class="jp ir">强化学习 Kaizen！</strong></p><p id="f406" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">看看最终的模型，看看它在我们的办公室里是如何学会自我导航的:</p><figure class="kn ko kp kq gt kr"><div class="bz fp l di"><div class="kz la l"/></div><figcaption class="lb lc gj gh gi ld le bd b be z dk">An example of the Agent catching cubes in our Digital Office</figcaption></figure><p id="839b" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">Unity 作为一个游戏平台，非常擅长将这些环境和模型编译到移动设备上。为了实现创建一个在我们办公室里跑来跑去的 AR Pacman 的目标，我们已经将这个环境编译到 iOS 上，只是为了看到坦克在我们的走廊里捕捉积木。这里有一个这样的印象:</p><figure class="kn ko kp kq gt kr"><div class="bz fp l di"><div class="kz la l"/></div></figure><p id="bc86" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">接下来，在 Hololens、Magic Leap 或 HTC Vive 上旋转一下吧！</p><h1 id="97eb" class="lf lg iq bd lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc bi translated">真正的交易</h1><p id="b12a" class="pw-post-body-paragraph jn jo iq jp b jq md js jt ju me jw jx jy mf ka kb kc mg ke kf kg mh ki kj kk ij bi translated">你可能认为我们的创造只是为了好玩，但我们对它的潜力是非常认真的。想象一下在商店、机场或游乐园有类似的东西指引你？创建一个 AR 寻路应用程序是一回事，但是如果你能够<strong class="jp ir">跳过人工编程，让代理根据你的需求训练自己，那就更好了(并且更具可扩展性)。</strong></p><p id="219d" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">真正有趣的是，这些代理可以显示人类的行为和模式。虚拟机器人可能生活在模型中，但它知道真实世界。想象一下，如果你正在开发一个公共建筑——无论是医院、火车站还是机场——你组织了一场建筑设计竞赛。<strong class="jp ir">我们的代理可以做的事情之一是通过进行数百万次模拟“行走”来测试建筑的可达性和安全性。</strong>人们走哪条路？他们被卡在哪里？危险情况下的人群控制呢？</p><p id="6aaa" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">目前最大的警告是，代理人生活在三维世界中，并没有感觉到现实世界。我们的桌子还没有在 Unity 环境中建模，所以如果你用 HoloLens 或其他 AR 设备观看，坦克只会穿过桌子。我们正在思考和探索如何在 Unity 模型中反推环境的 3D 网格信息。我们还通过在 3D 环境中放置随机障碍物来使坦克更加坚固，这样它就可以学会有效地绕过它们，预测现实世界中的实时变化。虽然观察代理和手动调整奖励函数很有趣，但它威胁到虚拟代理学习自己导航新环境的可扩展性。我们正在探索多阶段学习的新途径；首先掌握在我们办公室导航的基本知识，然后掌握如何快速和避开障碍物。</p><p id="fdcc" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">障碍不一定会阻止你。如果你碰壁了，不要转身放弃。想办法爬上去，穿过去，或者绕过它。来吧，吃豆人，你有一整晚的时间和一千万次的尝试！</p><p id="b34a" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><em class="kl">特别感谢 Fabrice Cops 和 Dieter Vanhooren，他们为这个项目提供了支持。</em></p></div></div>    
</body>
</html>