# 为什么人工智能必须是道德的——以及我们如何做到这一点

> 原文：<https://towardsdatascience.com/why-ai-must-be-ethical-and-how-we-make-it-so-b52cdb1dd15f?source=collection_archive---------21----------------------->

![](img/254c788f97ef9b528d743894f7b63f29.png)

## 当人工智能决定谁是值得的，谁是对的，谁是罪犯时，你只能希望它做出正确的决定。

现在是 2021 年。外面正下着瓢泼大雨。你在喝下午茶，同时在笔记本电脑上处理下一个项目。一个电话打断了你的工作流程。我是《微妙》的丹妮尔。上周五你去参加了一个令你兴奋的工作面试。满怀期待，你接了电话。丹妮尔说，她不得不遗憾地告诉你，他们已经和其他申请人一起走了——这是你没有得到这份工作的一种委婉说法。“为什么？”，你问，希望至少能得到建设性的反馈，让你在下一次面试中做得更好。“我们的系统确定你不是这个职位的合适人选”，Danielle 解释道。“为什么不呢？”，你问。“我真的不知道”，丹妮尔回答。微妙不太清楚他们的人工智能系统如何决定哪些候选人被认为是职位的好选择。他们的人工智能分析简历和测试，比较经验，在搜索引擎上对候选人进行彻底的自动搜索——简而言之，它检查了数十万个数据点。微妙对人工智能看什么有一个粗略的想法，但不能说人工智能更重视什么，或者它如何决定哪种体验比任何其他体验更好。你感谢丹妮尔抽出时间，然后挂断电话。你的思维开始加速——为什么他们的人工智能认为你不合适？你停顿一下。当然了。这不是什么新鲜事。你生命中的每一天都会经历这种情况。是因为你的种族。又是一年，又是一种创新的辨别方式，你心里想。你又喝了一口茶，把注意力放回到你的笔记本电脑上。

**现在是 2023 年。**你刚刚下班回家。外面很冷，今年冬天来得很早。你收到了一些邮件，大部分是广告，但有一个信封很突出。是亚马逊 Go 的。你打开它，发现里面有一张金额适中的发票。奇怪的是，你心里想，你什么也没买，却整整齐齐地列了十五样东西。没错，你在 Amazendor 有一个帐户，但是你已经有半年多没去过他们的 Go 商店了。Amazendor 的 Go 连锁商店使用面部识别——顾客只需走进去，挑选他们想买的任何东西，出去时他们只需看一眼相机，他们的钱就会自动从他们的银行账户中取出。或者，如果用户愿意，他们可以通过发票支付。相机一定是把别人误认为你了。烦人，但这只是一笔不多的钱，你不想浪费时间争论，所以你付了帐，继续你的夜晚。

现在是 2024 年。你一大早醒来，听到一声砰砰的敲门声。“是警察，开门！”，一个声音从另一边喊道。你发现自己进入的困倦状态是短暂的，因为你很快进入了恐惧和不确定的状态。你或你认识的人发生了什么事吗？或者你的一个邻居出了事，警察想知道你是否看到了什么？嗯，当你走到门口打开门时，你不必考虑太久。三个警察进来了。“乔纳森？”。你点头。你被捕了。为什么？一个人工智能辅助安全系统看到你偷了一辆车，在实际看到你的脸后，警察同意你与安全摄像头的镜头相匹配。人工智能说有 93%的把握是你。你被带到警察局。你试图通过解释你不在那里来证明你的清白，但一个人工智能测谎仪认为你在撒谎。幸运的是，你能够证明在抢劫发生时你在其他地方，使用你的谷歌地图历史，以及一张借记卡购买，发生在离盗窃现场太远的地方，以至于你无法偷到车。你可以回家了。那天晚上你睡不着。你想知道如果你无法证明自己的清白会发生什么。

![](img/d257b0571f55524fcc7ccd826c0aa5ba.png)

Photo by [John Noonan](https://unsplash.com/@theonlynoonan?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText).

# 这就是为什么我们需要有道德的人工智能。

以上短篇故事中描述的所有技术都已经存在。它们在 2019 年的采用率相当有限，但在未来几年将会增加。

错误可以、已经并将继续发生。

*   **面部识别。**去年，一个主要的人工智能面部识别工具[错误地将 28 名美国国会议员识别为因犯罪而被捕的人](https://www.aclu.org/blog/privacy-technology/surveillance-technologies/amazons-face-recognition-falsely-matched-28)，另一个工具[同样错误地将一名中国亿万富翁识别为乱穿马路者](https://www.telegraph.co.uk/technology/2018/11/25/chinese-businesswoman-accused-jaywalking-ai-camera-spots-face/)。虽然面部识别将随着时间的推移而改进，并且通常是一种相当可靠的工具，但它仍然会出错，同样，人类在解释面部识别工具产生的结果时也会出错。
*   **偏见。如果训练不当，人工智能会产生强烈的偏见。2018 年，[亚马逊放弃了一个人工智能招聘工具，因为它开始偏爱一种性别而不是另一种性别](https://www.theguardian.com/technology/2018/oct/10/amazon-hiring-ai-gender-bias-recruiting-engine)。这种偏差可能发生在任何变量上，并且比你想象的更难避免。例如，不幸的是，避免性别偏见并不像告诉人工智能不要在乎性别那么简单。其原因是不同性别可能以不同的方式写作和说话，而人工智能可以学习更喜欢一种风格。这也适用于除性别之外的许多其他变量，如种族、社会地位、经济财富，或者坦率地说，绝对是任何可以想象的数据变量。由于人工智能是在历史数据上训练的，它也将学习根据我们非常种族主义和性别歧视的人类历史上存在的理想做出决定，这已经[给被送进监狱的人带来了问题](https://www.technologyreview.com/s/612775/algorithms-criminal-justice-ai/)。**
*   **过度依赖。人工智能也会犯错。严重的错误。 [AI 已经因过度依赖而杀人](https://www.nytimes.com/interactive/2018/03/20/us/self-driving-uber-pedestrian-killed.html)。当像亚马逊这样的公司积极试图创建一个监视社会，将恐惧作为一种产品出售时，你最好相信我希望人工智能的用户知道，尽管训练有素的人工智能往往比人类更擅长预测，但它也可能犯错误。谢天谢地，佛罗里达朱庇特医院的医生明白这一点，当时 IBM Watson 推荐了可能有致命后果的治疗方法。**

人工智能可以错误地识别、错误地分析或曲解任何人和任何事。

不要误会我的意思，我坚信人工智能是一项非常有用的技术，它将带来巨大的好处。它可以使我们的生活方便、快捷、简单。它可以发现疾病的治疗方法，它可以使我们富有创造力，它可以使我们的生活更加有趣。但必须加以规范。

## AI 必须有一个可解释的日志。

如果不能解释，就不能相信。AI 必须是透明的。人类必须总是能够知道为什么人工智能会做出特定的决定。

## 人类必须负责。

我们的未来无疑将由人机协作组成。计算机和智能手机等机器已经大大增强了人类的能力，人工智能只会在这方面有所增加。但是人类必须一直控制人工智能。

## 必须减轻偏见。

一个人工智能系统总是会偏向某一方，但它可以被训练得不那么偏向某一方。人工智能在做出判断时必须公平。输入给人工智能的数据必须是多样的。

## AI 必须治理。

毫无疑问:人类总是要对任何技术做出的任何行为负责。唯一的问题是谁。责任必须明确。

## 人类不能过度依赖 AI。

一般来说，在做出预测性的、基于数据的决策时，机器比人类更好，人工智能应该成为任何企业战略的一部分。但这并不意味着人们应该过度依赖机器，尤其是在人工智能与人类打交道的时候。

![](img/abfa7e54140c038e6ad39e4be9831db3.png)

Photo by [Laurentiu Robu](https://www.pexels.com/@laurentiu-robu-898058?utm_content=attributionCopyText&utm_medium=referral&utm_source=pexels).

# AI 一定是伦理的。

不得不说，AI 在实现得当的情况下是很奇妙的。还必须说，AI 不受监管的时候是很可怕的。

人工智能的开拓者们正致力于建立人工智能伦理——取得了不同程度的成功。一些早期的尝试已经失败，比如谷歌今年早些时候试图建立一个人工智能道德委员会，但仅仅一周之后就被解散了。相反，我认为建立道德人工智能的未来在于合作。例如，欧洲委员会[邀请欧洲人讨论伦理人工智能](https://ec.europa.eu/futurium/en/eu-ai-alliance)。在我看来，邀请广泛的个人和实体建立道德准则是处理人工智能道德的最佳方法。希望在不久的将来，此类举措将开始以更大的规模出现。

为了确保人工智能变得——并保持——道德，我们必须通过广泛、包容性的讨论实现多元化的道德委员会。

因为很快有一天，AI *会*决定你是不是罪犯。

你所能做的就是希望人工智能做出正确的决定。