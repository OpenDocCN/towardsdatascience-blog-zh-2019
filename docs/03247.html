<html>
<head>
<title>Why and How to do Cross Validation for Machine Learning</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">为什么以及如何对机器学习进行交叉验证</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/why-and-how-to-do-cross-validation-for-machine-learning-d5bd7e60c189?source=collection_archive---------13-----------------------#2019-05-24">https://towardsdatascience.com/why-and-how-to-do-cross-validation-for-machine-learning-d5bd7e60c189?source=collection_archive---------13-----------------------#2019-05-24</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><figure class="gl gn jr js jt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi jq"><img src="../Images/a0cdd26531524f17d14210ffa09c974e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*VN6bGHQnYkd-l2eJlDA_yA.jpeg"/></div></div></figure><blockquote class="kb kc kd"><p id="381b" class="ke kf kg kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">想获得灵感？快来加入我的<a class="ae ld" href="https://www.superquotes.co/?utm_source=mediumtech&amp;utm_medium=web&amp;utm_campaign=sharing" rel="noopener ugc nofollow" target="_blank"> <strong class="kh iu">超级行情快讯</strong> </a>。😎</p></blockquote><p id="c34e" class="pw-post-body-paragraph ke kf it kh b ki kj kk kl km kn ko kp le kr ks kt lf kv kw kx lg kz la lb lc im bi translated">交叉验证是一种测试机器学习模型性能的统计技术。特别是，一个好的交叉验证方法给了我们一个模型在整个<em class="kg">数据集中的性能的综合度量。</em></p><p id="f561" class="pw-post-body-paragraph ke kf it kh b ki kj kk kl km kn ko kp le kr ks kt lf kv kw kx lg kz la lb lc im bi translated">所有交叉验证方法都遵循相同的基本程序:</p><p id="ed96" class="pw-post-body-paragraph ke kf it kh b ki kj kk kl km kn ko kp le kr ks kt lf kv kw kx lg kz la lb lc im bi translated">(1)将数据集分成两部分:训练和测试</p><p id="f331" class="pw-post-body-paragraph ke kf it kh b ki kj kk kl km kn ko kp le kr ks kt lf kv kw kx lg kz la lb lc im bi translated">(2)在训练集上训练模型</p><p id="6155" class="pw-post-body-paragraph ke kf it kh b ki kj kk kl km kn ko kp le kr ks kt lf kv kw kx lg kz la lb lc im bi translated">(3)在测试集上评估模型</p><p id="f237" class="pw-post-body-paragraph ke kf it kh b ki kj kk kl km kn ko kp le kr ks kt lf kv kw kx lg kz la lb lc im bi translated">(4)可选地，对一组不同的数据点重复步骤 1 至 3</p><p id="4042" class="pw-post-body-paragraph ke kf it kh b ki kj kk kl km kn ko kp le kr ks kt lf kv kw kx lg kz la lb lc im bi translated">包括步骤 4 的更彻底的交叉验证方法，因为这样的测量对于选择特定分割可能带来的偏差更稳健。选择数据的特定部分产生的偏差称为<a class="ae ld" href="https://en.wikipedia.org/wiki/Selection_bias" rel="noopener ugc nofollow" target="_blank"> <em class="kg">选择偏差</em> </a>。</p><p id="c044" class="pw-post-body-paragraph ke kf it kh b ki kj kk kl km kn ko kp le kr ks kt lf kv kw kx lg kz la lb lc im bi translated">这种方法将花费更多的时间，因为模型将被多次训练和验证。但它确实提供了更彻底的显著优势，以及有机会潜在地找到挤出最后一点准确性的分裂。</p><p id="ce85" class="pw-post-body-paragraph ke kf it kh b ki kj kk kl km kn ko kp le kr ks kt lf kv kw kx lg kz la lb lc im bi translated">除了选择偏差，交叉验证也有助于我们避免过度拟合。通过将数据集划分为训练集和验证集，我们可以具体地检查我们的模型在训练期间看到的数据上是否表现良好。如果没有交叉验证，我们永远不会知道我们的模型是在全球范围内令人惊叹，还是仅仅在我们的保护性训练中令人惊叹！</p><p id="372d" class="pw-post-body-paragraph ke kf it kh b ki kj kk kl km kn ko kp le kr ks kt lf kv kw kx lg kz la lb lc im bi translated">说了这么多理论之后，让我们来看看 3 种常见的交叉验证技术。</p><figure class="li lj lk ll gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi lh"><img src="../Images/2e1870396c82ca553d4cbe7122c254e2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*NzuvTWIyw_fym6zC.png"/></div></div><figcaption class="lm ln gj gh gi lo lp bd b be z dk">An illustration of how overfitting works</figcaption></figure><h1 id="08b7" class="lq lr it bd ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk ml mm mn bi translated">坚持</h1><p id="ac24" class="pw-post-body-paragraph ke kf it kh b ki mo kk kl km mp ko kp le mq ks kt lf mr kw kx lg ms la lb lc im bi translated">维持交叉验证是最简单也是最常见的。我们简单地将数据分成两组:训练和测试。训练和测试数据不能有任何相同的数据点。通常，这种分割将接近 85%的数据用于训练，15%的数据用于测试。下图说明了维持交叉验证的工作方式。</p><figure class="li lj lk ll gt ju gh gi paragraph-image"><div class="gh gi mt"><img src="../Images/bb77303e95df28f8b80ac4a8c8dbb283.png" data-original-src="https://miro.medium.com/v2/resize:fit:716/format:webp/1*lUTgVK-A4F1yMYuUEdWtVw.png"/></div></figure><p id="cf78" class="pw-post-body-paragraph ke kf it kh b ki kj kk kl km kn ko kp le kr ks kt lf kv kw kx lg kz la lb lc im bi translated">使用非常简单的维持交叉验证的优点是我们只需要训练一个模型。如果它表现得足够好，我们可以继续在任何我们想要的应用程序中使用它。只要您的数据集在分布和“难度”方面相对一致，这就非常合适</p><p id="9259" class="pw-post-body-paragraph ke kf it kh b ki kj kk kl km kn ko kp le kr ks kt lf kv kw kx lg kz la lb lc im bi translated">当数据集不完全均匀时，会出现维持交叉验证的危险和缺点。在分割我们的数据集时，我们可能会以这样一种方式结束分割，即我们的训练集与测试集非常不同，或更容易，或更难。</p><p id="42e6" class="pw-post-body-paragraph ke kf it kh b ki kj kk kl km kn ko kp le kr ks kt lf kv kw kx lg kz la lb lc im bi translated">因此，我们对维持执行的单一测试不够全面，不足以正确评估我们的模型。我们最终会遇到一些不好的事情，比如过度拟合或者不准确地测量我们的模型预测的真实世界的性能。</p><p id="dd6a" class="pw-post-body-paragraph ke kf it kh b ki kj kk kl km kn ko kp le kr ks kt lf kv kw kx lg kz la lb lc im bi translated">如何在 Scikit-Learn 中实现维持交叉验证:<code class="fe mu mv mw mx b">sklearn.model_selection.train_test_split</code></p><h1 id="95a5" class="lq lr it bd ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk ml mm mn bi translated">k 倍交叉验证</h1><p id="1408" class="pw-post-body-paragraph ke kf it kh b ki mo kk kl km mp ko kp le mq ks kt lf mr kw kx lg ms la lb lc im bi translated">使用 K-Fold 交叉验证将帮助您克服使用 Holdout 带来的许多缺点。</p><p id="c482" class="pw-post-body-paragraph ke kf it kh b ki kj kk kl km kn ko kp le kr ks kt lf kv kw kx lg kz la lb lc im bi translated">使用 K-Fold，我们将把我们的数据集随机分成<em class="kg"> K </em>个大小相等的部分。然后我们将训练我们的模型<em class="kg"> K </em>次。对于每次训练运行，我们从我们的<em class="kg"> K </em>部分中选择一个分区作为测试集，并使用其余的进行训练。</p><p id="341c" class="pw-post-body-paragraph ke kf it kh b ki kj kk kl km kn ko kp le kr ks kt lf kv kw kx lg kz la lb lc im bi translated">例如，如果我们在下面的示例中设置 K = 10，那么我们将训练 10 个模型。每个模型都将在一个独特的训练集上接受训练——蓝色显示的部分。每个模型也将在一个独特的测试装置上进行测试——绿色部分。</p><p id="cfb2" class="pw-post-body-paragraph ke kf it kh b ki kj kk kl km kn ko kp le kr ks kt lf kv kw kx lg kz la lb lc im bi translated">为了获得最终的准确性度量，我们对每个模型在各自的测试集上评估的结果进行平均。</p><figure class="li lj lk ll gt ju gh gi paragraph-image"><div class="gh gi my"><img src="../Images/0bb9abd070f6de9c17435a20cc3285d9.png" data-original-src="https://miro.medium.com/v2/resize:fit:542/format:webp/1*V2M_qfMJmpTExljjwoNXZA.png"/></div></figure><p id="9eb7" class="pw-post-body-paragraph ke kf it kh b ki kj kk kl km kn ko kp le kr ks kt lf kv kw kx lg kz la lb lc im bi translated">K-Fold 交叉验证带来的最大优势是它不容易产生选择偏差，因为训练和测试是在几个不同的部分上进行的。特别是，如果我们增加 K 的值，我们甚至可以更加确定我们模型的稳健性，因为我们已经在如此多的不同子数据集上进行了训练和测试。</p><p id="4d24" class="pw-post-body-paragraph ke kf it kh b ki kj kk kl km kn ko kp le kr ks kt lf kv kw kx lg kz la lb lc im bi translated">这种方法唯一可能的缺点是，当我们通过增加 K 来获得鲁棒性时，我们还必须训练更多的模型——这是一个潜在的冗长且昂贵的过程。</p><p id="6afe" class="pw-post-body-paragraph ke kf it kh b ki kj kk kl km kn ko kp le kr ks kt lf kv kw kx lg kz la lb lc im bi translated">如何在 Scikit-Learn 中实现 K-Fold 交叉验证:<code class="fe mu mv mw mx b">sklearn.model_selection.KFold</code></p><h1 id="61e8" class="lq lr it bd ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk ml mm mn bi translated">重复随机子采样</h1><p id="40f5" class="pw-post-body-paragraph ke kf it kh b ki mo kk kl km mp ko kp le mq ks kt lf mr kw kx lg ms la lb lc im bi translated">重复随机子抽样也许是交叉验证方法中最稳健的。</p><p id="8992" class="pw-post-body-paragraph ke kf it kh b ki kj kk kl km kn ko kp le kr ks kt lf kv kw kx lg kz la lb lc im bi translated">类似于 K-Fold，我们为 K 设置一个值，它表示我们将训练我们的模型的次数。然而，在这种情况下，K 将<strong class="kh iu">而不是</strong>表示大小相等的分区的数量。</p><p id="b130" class="pw-post-body-paragraph ke kf it kh b ki kj kk kl km kn ko kp le kr ks kt lf kv kw kx lg kz la lb lc im bi translated">相反，在每次训练迭代中，我们随机选择点作为测试集。我们选择的点数将是我们为测试集设置的某个百分比。例如，如果我们选择 15%，那么在每次训练迭代中，我们将在数据集中随机选择 15%的点来进行训练。</p><p id="b120" class="pw-post-body-paragraph ke kf it kh b ki kj kk kl km kn ko kp le kr ks kt lf kv kw kx lg kz la lb lc im bi translated">其余的程序以与 K-Fold 相同的方式继续。在训练集上进行训练，在其独特的测试集上测试每个模型，最后平均结果以获得最终精度。</p><figure class="li lj lk ll gt ju gh gi paragraph-image"><div class="gh gi mz"><img src="../Images/3d088944abf0d6fb339bc93808c3a6ed.png" data-original-src="https://miro.medium.com/v2/resize:fit:522/format:webp/1*2nxkYZbM6rArC2UxBKR56A.png"/></div></figure><p id="5bd8" class="pw-post-body-paragraph ke kf it kh b ki kj kk kl km kn ko kp le kr ks kt lf kv kw kx lg kz la lb lc im bi translated">这种方法相对于 K-Fold 的明显优势是训练-测试分割的比例不依赖于迭代的次数。如果我们愿意，我们甚至可以在每次迭代中为测试集设置不同的百分比。随机化也可能对选择偏差更具鲁棒性。</p><p id="5dc7" class="pw-post-body-paragraph ke kf it kh b ki kj kk kl km kn ko kp le kr ks kt lf kv kw kx lg kz la lb lc im bi translated">这种方法的缺点是，有些点可能永远不会被选入测试子集中，同时，有些点可能会被选择多次。这是随机化的直接结果。然而，使用 K-Fold 可以保证所有点在某个时候都将被测试。</p></div><div class="ab cl na nb hx nc" role="separator"><span class="nd bw bk ne nf ng"/><span class="nd bw bk ne nf ng"/><span class="nd bw bk ne nf"/></div><div class="im in io ip iq"><h1 id="4f0c" class="lq lr it bd ls lt nh lv lw lx ni lz ma mb nj md me mf nk mh mi mj nl ml mm mn bi translated">喜欢学习？</h1><p id="d0a7" class="pw-post-body-paragraph ke kf it kh b ki mo kk kl km mp ko kp le mq ks kt lf mr kw kx lg ms la lb lc im bi translated">在 twitter 上关注我，我会在这里发布所有最新最棒的人工智能、技术和科学！也在<a class="ae ld" href="https://www.linkedin.com/in/georgeseif/" rel="noopener ugc nofollow" target="_blank"> LinkedIn </a>上和我联系吧！</p></div></div>    
</body>
</html>