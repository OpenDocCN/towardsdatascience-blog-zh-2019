<html>
<head>
<title>Introduction to Federated Learning and Privacy Preservation</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">联合学习和隐私保护简介</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/introduction-to-federated-learning-and-privacy-preservation-75644686b559?source=collection_archive---------14-----------------------#2019-07-16">https://towardsdatascience.com/introduction-to-federated-learning-and-privacy-preservation-75644686b559?source=collection_archive---------14-----------------------#2019-07-16</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="e78d" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">使用 PySyft 框架的联邦学习和附加秘密共享。</h2></div><p id="bad6" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi le translated">深度学习包括对存在于多个客户端设备上的大量高质量分散数据进行训练。该模型在客户端设备上被训练，因此不需要上传用户的数据。将个人数据保存在客户的设备上，使他们能够直接和实际控制自己的数据。</p><figure class="lo lp lq lr gt ls gh gi paragraph-image"><div role="button" tabindex="0" class="lt lu di lv bf lw"><div class="gh gi ln"><img src="../Images/8f9d4ae198c387adc7ddb4283857d359.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Bbgj7VNT-01KD3U2lWXDgw.png"/></div></div><figcaption class="lz ma gj gh gi mb mc bd b be z dk">Figure 1: Federated Learning</figcaption></figure><p id="9c08" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">服务器在预先可用的代理数据上训练初始模型。初始模型被发送到选定数量的合格客户端设备。合格标准确保用户的体验不会因为试图训练模型而被破坏。选择最佳数量的客户端设备来参与训练过程。处理完用户数据后，模型更新将与服务器共享。服务器聚集这些梯度并改进全局模型。</p><p id="c81b" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">所有的模型更新都在内存中进行<em class="md">处理</em>，而<em class="md">在服务器上只持续很短的一段时间</em>。然后，服务器将改进的模型发送回参与下一轮训练的客户端设备。达到所需的精确度后，设备上的模型可以根据用户的个性化进行调整。然后，他们不再有资格参加培训。在整个过程中，数据不会离开客户端设备。</p><h2 id="05f3" class="me mf it bd mg mh mi dn mj mk ml dp mm kr mn mo mp kv mq mr ms kz mt mu mv mw bi translated">这与分散计算有什么不同？</h2><p id="6d2c" class="pw-post-body-paragraph ki kj it kk b kl mx ju kn ko my jx kq kr mz kt ku kv na kx ky kz nb lb lc ld im bi translated">联合学习与分散计算的不同之处在于:</p><ul class=""><li id="5feb" class="nc nd it kk b kl km ko kp kr ne kv nf kz ng ld nh ni nj nk bi translated">客户端设备(如智能手机)的网络带宽有限。它们不能传输大量数据，上传速度通常低于下载速度。</li><li id="1dc6" class="nc nd it kk b kl nl ko nm kr nn kv no kz np ld nh ni nj nk bi translated">客户端设备并不总是能够参与训练会话。最佳条件，如充电状态、连接到未计量的 Wi-Fi 网络、空闲等。并不总是可以实现的。</li><li id="dd6e" class="nc nd it kk b kl nl ko nm kr nn kv no kz np ld nh ni nj nk bi translated">设备上的数据更新很快，并且不总是相同的。[数据并不总是可以获得。]</li><li id="7966" class="nc nd it kk b kl nl ko nm kr nn kv no kz np ld nh ni nj nk bi translated">客户端设备可以选择不参与培训。</li><li id="c274" class="nc nd it kk b kl nl ko nm kr nn kv no kz np ld nh ni nj nk bi translated">可用的客户端设备数量非常多，但是不一致。</li><li id="4cc5" class="nc nd it kk b kl nl ko nm kr nn kv no kz np ld nh ni nj nk bi translated">联合学习将隐私保护与大规模群体的分布式训练和聚合结合在一起。</li><li id="7cb7" class="nc nd it kk b kl nl ko nm kr nn kv no kz np ld nh ni nj nk bi translated">数据通常是不平衡的，因为数据是用户特定的并且是自相关的。</li></ul><blockquote class="nq"><p id="0a6c" class="nr ns it bd nt nu nv nw nx ny nz ld dk translated">联合学习是“将代码带给数据，而不是将数据带给代码”这种更普遍方法的一个例子，它解决了数据的隐私、所有权和位置等基本问题。</p></blockquote><p id="0dd5" class="pw-post-body-paragraph ki kj it kk b kl oa ju kn ko ob jx kq kr oc kt ku kv od kx ky kz oe lb lc ld im bi translated">在联合学习中:</p><ul class=""><li id="57e2" class="nc nd it kk b kl km ko kp kr ne kv nf kz ng ld nh ni nj nk bi translated">某些技术用于压缩模型更新。</li><li id="d01c" class="nc nd it kk b kl nl ko nm kr nn kv no kz np ld nh ni nj nk bi translated">执行质量更新，而不是简单的梯度步骤。</li><li id="a793" class="nc nd it kk b kl nl ko nm kr nn kv no kz np ld nh ni nj nk bi translated">在执行聚合之前，由服务器添加噪声，以掩盖个体对学习模型的影响。[全局差分隐私]</li><li id="bbea" class="nc nd it kk b kl nl ko nm kr nn kv no kz np ld nh ni nj nk bi translated">如果渐变更新太大，则会被裁剪。</li></ul><h2 id="a3bd" class="me mf it bd mg mh mi dn mj mk ml dp mm kr mn mo mp kv mq mr ms kz mt mu mv mw bi translated">PYSYFT 简介</h2><p id="e772" class="pw-post-body-paragraph ki kj it kk b kl mx ju kn ko my jx kq kr mz kt ku kv na kx ky kz nb lb lc ld im bi translated">我们将使用 PySyft 实现一个联邦学习模型。PySyft 是一个用于安全和私有深度学习的 Python 库。</p><h2 id="f09f" class="me mf it bd mg mh mi dn mj mk ml dp mm kr mn mo mp kv mq mr ms kz mt mu mv mw bi translated">装置</h2><p id="6990" class="pw-post-body-paragraph ki kj it kk b kl mx ju kn ko my jx kq kr mz kt ku kv na kx ky kz nb lb lc ld im bi translated">PySyft 要求 Python &gt;= 3.6 和 PyTorch 1.1.0。确保你符合这些要求。</p><figure class="lo lp lq lr gt ls"><div class="bz fp l di"><div class="of og l"/></div></figure><h2 id="2951" class="me mf it bd mg mh mi dn mj mk ml dp mm kr mn mo mp kv mq mr ms kz mt mu mv mw bi translated">基础</h2><p id="35ec" class="pw-post-body-paragraph ki kj it kk b kl mx ju kn ko my jx kq kr mz kt ku kv na kx ky kz nb lb lc ld im bi translated">让我们从导入库和初始化钩子开始。</p><figure class="lo lp lq lr gt ls"><div class="bz fp l di"><div class="of og l"/></div></figure><p id="0da1" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">这样做是为了覆盖 PyTorch 的方法，在一个 worker 上执行命令，这些命令在本地 worker 控制的 tensors 上调用。它还允许我们在工人之间移动张量。工人解释如下。</p><figure class="lo lp lq lr gt ls"><div class="bz fp l di"><div class="of og l"/></div></figure><pre class="lo lp lq lr gt oh oi oj ok aw ol bi"><span id="6016" class="me mf it oi b gy om on l oo op">Jake has: {}</span></pre><p id="8d11" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">虚拟工作者是存在于我们本地机器上的实体。它们用于模拟实际工人的行为。</p><p id="4c86" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">为了与分布在网络中的工作者一起工作，PySyft 提供了两种类型的工作者:</p><ul class=""><li id="d4e5" class="nc nd it kk b kl km ko kp kr ne kv nf kz ng ld nh ni nj nk bi translated">网络套接字工人</li><li id="5c1a" class="nc nd it kk b kl nl ko nm kr nn kv no kz np ld nh ni nj nk bi translated">Web 套接字工人</li></ul><p id="34e4" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">Web sockets workers 可以从浏览器实例化，每个 worker 位于一个单独的选项卡上。</p><p id="756f" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在这里，Jake 是我们的虚拟工作者，可以将其视为设备上的一个独立实体。我们给他发些数据吧。</p><figure class="lo lp lq lr gt ls"><div class="bz fp l di"><div class="of og l"/></div></figure><pre class="lo lp lq lr gt oh oi oj ok aw ol bi"><span id="308f" class="me mf it oi b gy om on l oo op">x: (Wrapper)&gt;[PointerTensor | me:50034657126 -&gt; jake:55209454569]<br/>Jake has: {55209454569: tensor([1, 2, 3, 4, 5])}</span></pre><p id="f14d" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">当我们向 Jake 发送一个张量时，我们返回一个指向这个张量的指针。所有的操作都将通过这个指针来执行。这个指针保存另一台机器上的数据信息。现在，<em class="md"> x </em>是一个点张量。</p><p id="e9c0" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">使用<em class="md"> get() </em>方法从杰克的设备中获取<em class="md"> x </em>的值。然而，这样做的话，杰克设备上的张量就被删除了。</p><figure class="lo lp lq lr gt ls"><div class="bz fp l di"><div class="of og l"/></div></figure><pre class="lo lp lq lr gt oh oi oj ok aw ol bi"><span id="c704" class="me mf it oi b gy om on l oo op">x: tensor([1, 2, 3, 4, 5])<br/>Jake has: {}</span></pre><p id="4905" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">当我们将 PointTensor <em class="md"> x </em>(指向 Jake 机器上的一个张量)发送给另一个工人 John 时，整个链被发送给 John，并返回一个指向 John 设备上的节点的 PointTensor。张量仍在杰克的设备上。</p><figure class="lo lp lq lr gt ls"><div class="bz fp l di"><div class="of og l"/></div></figure><pre class="lo lp lq lr gt oh oi oj ok aw ol bi"><span id="86f1" class="me mf it oi b gy om on l oo op">x: (Wrapper)&gt;[PointerTensor | me:70034574375 -&gt; john:19572729271]<br/>John has: {19572729271: (Wrapper)&gt;[PointerTensor | john:19572729271 -&gt; jake:55209454569]}<br/>Jake has: {55209454569: tensor([1, 2, 3, 4, 5])}</span></pre><figure class="lo lp lq lr gt ls gh gi paragraph-image"><div class="gh gi oq"><img src="../Images/3b6ad422cfc8cd874fb37694a3fb7580.png" data-original-src="https://miro.medium.com/v2/resize:fit:830/format:webp/1*SDNxBsuTJr_48leyXfBi0g.png"/></div><figcaption class="lz ma gj gh gi mb mc bd b be z dk">Figure 2: Using the send() method on a PointTensor [Step 2].</figcaption></figure><p id="7df3" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">方法的作用是:从一个工作线程中移除所有的对象。</p><figure class="lo lp lq lr gt ls"><div class="bz fp l di"><div class="of og l"/></div></figure><pre class="lo lp lq lr gt oh oi oj ok aw ol bi"><span id="8eb6" class="me mf it oi b gy om on l oo op">Jake has: {}<br/>John has: {}</span></pre><p id="16e1" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">假设我们想把一个张量从杰克的机器移到约翰的机器上。我们可以通过使用<em class="md"> send() </em>方法将“指向张量的指针”发送给 John，并让他调用<em class="md"> get() </em>方法。PySfyt 为此提供了一个<em class="md"> remote_get() </em>方法。还有一个方便的方法——<em class="md">move()</em>，来执行这个操作。</p><figure class="lo lp lq lr gt ls"><div class="bz fp l di"><div class="of og l"/></div></figure><pre class="lo lp lq lr gt oh oi oj ok aw ol bi"><span id="4999" class="me mf it oi b gy om on l oo op">(Wrapper)&gt;[PointerTensor | me:86076501268 -&gt; john:86076501268]<br/>Jake has: {}<br/>John has: {86076501268: tensor([ 6,  7,  8,  9, 10])}</span></pre><figure class="lo lp lq lr gt ls gh gi paragraph-image"><div class="gh gi or"><img src="../Images/ed0c9b5634725680306f0250cde067b4.png" data-original-src="https://miro.medium.com/v2/resize:fit:816/format:webp/1*4XYNf3y287c2i4aWs9xXwA.png"/></div><figcaption class="lz ma gj gh gi mb mc bd b be z dk">Figure 3: Using the move() method on a PointTensor. [Step 2]</figcaption></figure><h2 id="85b7" class="me mf it bd mg mh mi dn mj mk ml dp mm kr mn mo mp kv mq mr ms kz mt mu mv mw bi translated">战略</h2><p id="d03c" class="pw-post-body-paragraph ki kj it kk b kl mx ju kn ko my jx kq kr mz kt ku kv na kx ky kz nb lb lc ld im bi translated">我们可以通过以下步骤在客户端设备上执行联合学习:</p><ol class=""><li id="7cf4" class="nc nd it kk b kl km ko kp kr ne kv nf kz ng ld os ni nj nk bi translated">将模型发送到设备，</li><li id="1c8a" class="nc nd it kk b kl nl ko nm kr nn kv no kz np ld os ni nj nk bi translated">使用设备上的数据进行正常训练，</li><li id="253e" class="nc nd it kk b kl nl ko nm kr nn kv no kz np ld os ni nj nk bi translated">拿回更聪明的模型。</li></ol><p id="1859" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">然而，如果有人截获了与服务器共享的 smarter 模型，他可以执行<em class="md">逆向工程</em>并提取关于数据集的敏感数据。差分隐私方法解决了这个问题并保护了数据。</p><p id="ea7a" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">当更新被发送回服务器时，服务器在聚集梯度时不应该能够辨别。让我们使用一种叫做附加秘密共享的加密形式。</p><p id="4294" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我们希望在执行聚合之前加密这些梯度(或模型更新),这样就没有人能够看到梯度。我们可以通过附加秘密共享来实现这一点。</p><h2 id="6c8a" class="me mf it bd mg mh mi dn mj mk ml dp mm kr mn mo mp kv mq mr ms kz mt mu mv mw bi translated">附加秘密共享</h2><p id="1b8f" class="pw-post-body-paragraph ki kj it kk b kl mx ju kn ko my jx kq kr mz kt ku kv na kx ky kz nb lb lc ld im bi translated">在秘密共享中，我们将一个秘密分成多个份额，并在一组秘密持有者中分发。秘密<em class="md"> x </em>只有当它被分割成的所有份额都可用时才能被构造。</p><p id="adba" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">比如说我们把<em class="md"> x </em>拆分成 3 份:<em class="md"> x1 </em>、<em class="md"> x2、</em>和<em class="md"> x3 </em>。我们随机初始化前两个份额，计算第三个份额为<em class="md">x3</em>=<em class="md">x</em>-(<em class="md">x1</em>+<em class="md">x2</em>)。然后我们将这些股份分配给三个秘密持有者。这个秘密仍然是隐藏的，因为每个人只持有一份，不知道总价值。</p><p id="c9d4" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我们可以通过选择股票价值的范围来使其更加安全。设大质数<em class="md"> Q </em>为上限。现在第三份，<em class="md"> x3 </em>，等于<em class="md">Q-</em>(<em class="md">x1</em>+<em class="md">x2</em>)<em class="md">% Q</em>+<em class="md">x</em>。</p><figure class="lo lp lq lr gt ls"><div class="bz fp l di"><div class="of og l"/></div></figure><pre class="lo lp lq lr gt oh oi oj ok aw ol bi"><span id="687b" class="me mf it oi b gy om on l oo op">Shares: (6191537984105042523084, 13171802122881167603111, 4377289736774029360531)</span></pre><figure class="lo lp lq lr gt ls gh gi paragraph-image"><div role="button" tabindex="0" class="lt lu di lv bf lw"><div class="gh gi ot"><img src="../Images/77575b09b6fe28b994a9699773c90035.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*viyFQ3N0v7n2adSmRxazBw.jpeg"/></div></div><figcaption class="lz ma gj gh gi mb mc bd b be z dk">Figure 4: Encrypting x in three shares.</figcaption></figure><p id="1d67" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">解密过程将股份求和在一起得到模数<em class="md"> Q </em>。</p><figure class="lo lp lq lr gt ls"><div class="bz fp l di"><div class="of og l"/></div></figure><pre class="lo lp lq lr gt oh oi oj ok aw ol bi"><span id="e1ab" class="me mf it oi b gy om on l oo op">Value after decrypting: 3</span></pre><figure class="lo lp lq lr gt ls gh gi paragraph-image"><div role="button" tabindex="0" class="lt lu di lv bf lw"><div class="gh gi ou"><img src="../Images/d6f754a52cbbdeafaedbd2a73225b5d5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*jXbK2X7usTMmnBs9Ad4fHg.jpeg"/></div></div><figcaption class="lz ma gj gh gi mb mc bd b be z dk">Figure 5: Decrypting x from the three shares.</figcaption></figure><h2 id="1ffe" class="me mf it bd mg mh mi dn mj mk ml dp mm kr mn mo mp kv mq mr ms kz mt mu mv mw bi translated">同态加密</h2><p id="cd4c" class="pw-post-body-paragraph ki kj it kk b kl mx ju kn ko my jx kq kr mz kt ku kv na kx ky kz nb lb lc ld im bi translated">同态加密是一种加密形式，它允许我们对加密的操作数执行计算，从而产生加密的输出。解密后的加密输出与对实际操作数执行相同计算得到的结果相匹配。</p><p id="2f1d" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">附加秘密共享技术已经具有同态性质。如果我们把<em class="md"> x </em>拆分成<em class="md"> x1 </em>、<em class="md"> x2、</em>和<em class="md"> x3 </em>，把<em class="md"> y </em>拆分成<em class="md"> y1 </em>、<em class="md"> y2、</em>和<em class="md"> y3 </em>，那么<em class="md"> x+y </em>就等于三份之和解密后的值:(<em class="md"> x1+y1 </em></p><figure class="lo lp lq lr gt ls"><div class="bz fp l di"><div class="of og l"/></div></figure><pre class="lo lp lq lr gt oh oi oj ok aw ol bi"><span id="6299" class="me mf it oi b gy om on l oo op">Shares encrypting x: (17500273560307623083756, 20303731712796325592785, 9677254414416530296911)<br/>Shares encrypting y: (2638247288257028636640, 9894151868679961125033, 11208230686823249725058)<br/>Sum of shares: (20138520848564651720396, 6457253737716047231095, 20885485101239780021969)<br/>Sum of original values (x + y): 14</span></pre><p id="e507" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我们能够在不知道<em class="md"> x </em>和<em class="md"> y </em>的值的情况下计算聚合函数加法的值。</p><h2 id="97c9" class="me mf it bd mg mh mi dn mj mk ml dp mm kr mn mo mp kv mq mr ms kz mt mu mv mw bi translated">使用 PYSYFT 的秘密共享</h2><p id="4f74" class="pw-post-body-paragraph ki kj it kk b kl mx ju kn ko my jx kq kr mz kt ku kv na kx ky kz nb lb lc ld im bi translated">PySyft 提供了一个<em class="md"> share() </em>方法，将数据拆分成附加的秘密份额，并发送给指定的 workers。为了处理十进制数，<em class="md"> fix_precision() </em>方法用于将小数表示为整数值。</p><figure class="lo lp lq lr gt ls"><div class="bz fp l di"><div class="of og l"/></div></figure><pre class="lo lp lq lr gt oh oi oj ok aw ol bi"><span id="faf5" class="me mf it oi b gy om on l oo op">Jake has: {}<br/>John has: {}<br/>Secure_worker has: {}</span></pre><p id="0efa" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">份额法用于在几个工人之间分配股份。每个指定的工人都得到一份，但不知道实际价值。</p><figure class="lo lp lq lr gt ls"><div class="bz fp l di"><div class="of og l"/></div></figure><pre class="lo lp lq lr gt oh oi oj ok aw ol bi"><span id="958a" class="me mf it oi b gy om on l oo op">x: (Wrapper)&gt;[AdditiveSharingTensor]<br/>	-&gt; (Wrapper)&gt;[PointerTensor | me:61668571578 -&gt; jake:46010197955]<br/>	-&gt; (Wrapper)&gt;[PointerTensor | me:98554485951 -&gt; john:16401048398]<br/>	-&gt; (Wrapper)&gt;[PointerTensor | me:86603681108 -&gt; secure_worker:10365678011]<br/>	*crypto provider: me*<br/>Jake has: {46010197955: tensor([3763264486363335961])}<br/>John has: {16401048398: tensor([-3417241240056123075])}<br/>Secure_worker has: {10365678011: tensor([-346023246307212880])}</span></pre><p id="dc61" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">如您所见，<em class="md"> x </em>现在分别指向 Jake、John 和 Secure_worker 机器上的三个共享。</p><figure class="lo lp lq lr gt ls gh gi paragraph-image"><div role="button" tabindex="0" class="lt lu di lv bf lw"><div class="gh gi ov"><img src="../Images/319e26a9de8e1bae79df4b00dd954bc8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*tBBfvKzQlNPpTK_KY899ZA.png"/></div></div><figcaption class="lz ma gj gh gi mb mc bd b be z dk">Figure 6: Encryption of x into three shares.</figcaption></figure><figure class="lo lp lq lr gt ls gh gi paragraph-image"><div role="button" tabindex="0" class="lt lu di lv bf lw"><div class="gh gi ow"><img src="../Images/000ea8a9372294900b42b05988648b8e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*OLfGcROtFznUSdP-xO2CtQ.png"/></div></div><figcaption class="lz ma gj gh gi mb mc bd b be z dk">Figure 7: Distributing the shares of x among 3 VirtualWorkers.</figcaption></figure><figure class="lo lp lq lr gt ls"><div class="bz fp l di"><div class="of og l"/></div></figure><pre class="lo lp lq lr gt oh oi oj ok aw ol bi"><span id="5d0d" class="me mf it oi b gy om on l oo op">(Wrapper)&gt;[AdditiveSharingTensor]<br/>	-&gt; (Wrapper)&gt;[PointerTensor | me:86494036026 -&gt; jake:42086952684]<br/>	-&gt; (Wrapper)&gt;[PointerTensor | me:25588703909 -&gt; john:62500454711]<br/>	-&gt; (Wrapper)&gt;[PointerTensor | me:69281521084 -&gt; secure_worker:18613849202]<br/>	*crypto provider: me*</span></pre><figure class="lo lp lq lr gt ls gh gi paragraph-image"><div role="button" tabindex="0" class="lt lu di lv bf lw"><div class="gh gi ox"><img src="../Images/baf1684fc807d812d48d5a9849e1e447.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*yKV4jdfJfEswmGHR84ergA.png"/></div></div><figcaption class="lz ma gj gh gi mb mc bd b be z dk">Figure 8: Encryption of y into 3 shares.</figcaption></figure><figure class="lo lp lq lr gt ls gh gi paragraph-image"><div role="button" tabindex="0" class="lt lu di lv bf lw"><div class="gh gi ow"><img src="../Images/e94116a831b6aa88eb3fd75616597cff.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Os8fDnZyodlhga9HdjzBfw.png"/></div></div><figcaption class="lz ma gj gh gi mb mc bd b be z dk">Figure 9: Distributing the shares of y among 3 VirtualWorkers.</figcaption></figure><figure class="lo lp lq lr gt ls"><div class="bz fp l di"><div class="of og l"/></div></figure><pre class="lo lp lq lr gt oh oi oj ok aw ol bi"><span id="2910" class="me mf it oi b gy om on l oo op">(Wrapper)&gt;[AdditiveSharingTensor]<br/>	-&gt; (Wrapper)&gt;[PointerTensor | me:42086114389 -&gt; jake:42886346279]<br/>	-&gt; (Wrapper)&gt;[PointerTensor | me:17211757051 -&gt; john:23698397454]<br/>	-&gt; (Wrapper)&gt;[PointerTensor | me:83364958697 -&gt; secure_worker:94704923907]<br/>	*crypto provider: me*</span></pre><p id="7be6" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">注意将<em class="md"> x </em>和<em class="md"> y </em>相加后得到的<em class="md"> z </em>的值存储在三台工人机中。<em class="md"> z </em>也加密了。</p><figure class="lo lp lq lr gt ls gh gi paragraph-image"><div role="button" tabindex="0" class="lt lu di lv bf lw"><div class="gh gi oy"><img src="../Images/a8d3394178ac39483e82e755aff31e0b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_ZBM0DdLKLPMPiS7EPthZw.png"/></div></div><figcaption class="lz ma gj gh gi mb mc bd b be z dk">Figure 10: Performing computation on encrypted inputs.</figcaption></figure><figure class="lo lp lq lr gt ls"><div class="bz fp l di"><div class="of og l"/></div></figure><pre class="lo lp lq lr gt oh oi oj ok aw ol bi"><span id="8717" class="me mf it oi b gy om on l oo op">tensor([14])</span></pre><figure class="lo lp lq lr gt ls gh gi paragraph-image"><div role="button" tabindex="0" class="lt lu di lv bf lw"><div class="gh gi oz"><img src="../Images/3dda8f06f40717cb7901fd585b5ebbeb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*M3wZea3zXQV26Dq9Cm0nuQ.png"/></div></div><figcaption class="lz ma gj gh gi mb mc bd b be z dk">Figure 11: Decryption of result obtained after computation on encrypted inputs.</figcaption></figure><p id="3eb6" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在对加密的份额执行加法之后获得的值等于通过将实际数字相加获得的值。</p><h2 id="9d8a" class="me mf it bd mg mh mi dn mj mk ml dp mm kr mn mo mp kv mq mr ms kz mt mu mv mw bi translated">使用 PYSYFT 的联邦学习</h2><p id="13f0" class="pw-post-body-paragraph ki kj it kk b kl mx ju kn ko my jx kq kr mz kt ku kv na kx ky kz nb lb lc ld im bi translated">现在，我们将使用两个工人:杰克和约翰，实现联合学习方法，在 MNIST 数据集上训练一个简单的神经网络。应用联邦学习方法只需要做一些修改。</p><ol class=""><li id="aa00" class="nc nd it kk b kl km ko kp kr ne kv nf kz ng ld os ni nj nk bi translated">导入库和模块。</li></ol><figure class="lo lp lq lr gt ls"><div class="bz fp l di"><div class="of og l"/></div></figure><p id="59db" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">2.加载数据集。</p><p id="fb69" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在实际应用中，数据存在于客户端设备上。为了复制这个场景，我们向虚拟工作者发送数据。</p><figure class="lo lp lq lr gt ls"><div class="bz fp l di"><div class="of og l"/></div></figure><p id="c72b" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">请注意，我们以不同的方式创建了训练数据集。<em class="md"> train_set.federate((jake，john)) </em>创建了一个<em class="md"> FederatedDataset </em>，其中<em class="md"> train_set </em>在 jake 和 john(我们的两个虚拟工作者)之间被拆分。<em class="md"> FederatedDataset </em>类旨在像 PyTorch 的<em class="md">数据集</em>类一样使用。将创建的<em class="md"> FederatedDataset </em>传递给联邦数据加载器“<em class="md"> FederatedDataLoader </em>”，以联邦的方式对其进行迭代。这些批次来自不同的设备。</p><p id="4790" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">3.建立模型</p><figure class="lo lp lq lr gt ls"><div class="bz fp l di"><div class="of og l"/></div></figure><p id="a481" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">4.训练模型</p><p id="6e05" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">因为数据存在于客户端设备上，所以我们通过<em class="md"> location </em>属性获得它的位置。对代码的重要补充是从客户端设备取回改进的模型和损失值的步骤。</p><figure class="lo lp lq lr gt ls"><div class="bz fp l di"><div class="of og l"/></div></figure><pre class="lo lp lq lr gt oh oi oj ok aw ol bi"><span id="0f2f" class="me mf it oi b gy om on l oo op">Epoch:  1 [    0/60032 (  0%)]	Loss: 2.306809<br/>Epoch:  1 [ 6400/60032 ( 11%)]	Loss: 1.439327<br/>Epoch:  1 [12800/60032 ( 21%)]	Loss: 0.857306<br/>Epoch:  1 [19200/60032 ( 32%)]	Loss: 0.648741<br/>Epoch:  1 [25600/60032 ( 43%)]	Loss: 0.467296<br/>...<br/>...<br/>...<br/>Epoch:  5 [32000/60032 ( 53%)]	Loss: 0.151630<br/>Epoch:  5 [38400/60032 ( 64%)]	Loss: 0.135291<br/>Epoch:  5 [44800/60032 ( 75%)]	Loss: 0.202033<br/>Epoch:  5 [51200/60032 ( 85%)]	Loss: 0.303086<br/>Epoch:  5 [57600/60032 ( 96%)]	Loss: 0.130088</span></pre><p id="8ba5" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">5.测试模型</p><figure class="lo lp lq lr gt ls"><div class="bz fp l di"><div class="of og l"/></div></figure><pre class="lo lp lq lr gt oh oi oj ok aw ol bi"><span id="b16c" class="me mf it oi b gy om on l oo op">Test set: Average loss: 0.2428, Accuracy: 9300/10000 (93%)</span></pre><p id="c19d" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">就是这样。我们已经使用联合学习方法训练了一个模型。与传统训练相比，使用联邦方法训练模型需要更多的时间。</p><h2 id="863a" class="me mf it bd mg mh mi dn mj mk ml dp mm kr mn mo mp kv mq mr ms kz mt mu mv mw bi translated">保护模型</h2><p id="c71a" class="pw-post-body-paragraph ki kj it kk b kl mx ju kn ko my jx kq kr mz kt ku kv na kx ky kz nb lb lc ld im bi translated">在客户端设备上训练模型保护了用户的隐私。但是，模特的隐私呢？下载模型会威胁到组织的知识产权！</p><p id="5a4b" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">安全多方计算由秘密加法共享组成，为我们提供了一种在不公开模型的情况下进行模型训练的方法。</p><p id="2f2c" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">为了保护模型的权重，我们在客户端设备之间秘密共享模型。</p><figure class="lo lp lq lr gt ls"><div class="bz fp l di"><div class="of og l"/></div></figure><p id="a0dc" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">要做到这一点，需要对上面的联邦学习示例进行一些更改。</p><p id="3382" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">如使用 PYSYFT 的秘密共享部分所示，现在是模型、输入、模型输出、权重等。也会被加密。处理加密的输入将产生加密的输出。</p><h2 id="1a48" class="me mf it bd mg mh mi dn mj mk ml dp mm kr mn mo mp kv mq mr ms kz mt mu mv mw bi translated">参考</h2><p id="147e" class="pw-post-body-paragraph ki kj it kk b kl mx ju kn ko my jx kq kr mz kt ku kv na kx ky kz nb lb lc ld im bi translated">[1] Theo Ryffel，Andrew Trask，Morten Dahl，Bobby Wagner，Jason Mancuso，Daniel Rueckert，Jonathan Passerat-Palmbach，<a class="ae pa" href="https://arxiv.org/abs/1811.04017" rel="noopener ugc nofollow" target="_blank">保护隐私的深度学习通用框架(2018) </a>，arXiv</p><p id="9baa" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">[2] Andrew Hard，Kanishka Rao，Rajiv Mathews，Swaroop Ramaswamy，Franç oise Beaufays，Sean Augenstein，Hubert Eichner，Chloé Kiddon，Daniel Ramage，<a class="ae pa" href="https://arxiv.org/abs/1811.03604" rel="noopener ugc nofollow" target="_blank">用于移动键盘预测的联邦学习(2019) </a>，arXiv</p><p id="bffe" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">[3]基思·博纳维茨、休伯特·艾希纳、沃尔夫冈·格里斯坎普、迪米特里·胡巴、亚历克斯·英格曼、弗拉基米尔·伊万诺夫、克洛伊·基登、雅各布·科涅纳、斯特凡诺·马佐基、h .布伦丹·麦克马汉、蒂蒙·范·奥弗代尔、戴维·彼得鲁、丹尼尔·拉梅奇、杰森·罗斯兰德、<a class="ae pa" href="https://arxiv.org/abs/1902.01046" rel="noopener ugc nofollow" target="_blank">《走向大规模联合学习:系统设计》(2019) </a>、arXiv</p><p id="b676" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">[4] Brendan McMahan，Daniel Ramage，<a class="ae pa" href="https://ai.googleblog.com/2017/04/federated-learning-collaborative.html" rel="noopener ugc nofollow" target="_blank">联合学习:没有集中训练数据的协作机器学习(2017) </a>，谷歌 AI 博客</p><p id="6367" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">[5]苹果差分隐私团队，<a class="ae pa" href="https://machinelearning.apple.com/2017/12/06/learning-with-privacy-at-scale.html" rel="noopener ugc nofollow" target="_blank">大规模隐私学习(2017) </a>，苹果机器学习杂志</p><p id="26fb" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">[6] Daniel Ramage，Emily Glanz，<a class="ae pa" href="https://www.youtube.com/watch?v=89BGjQYA0uE" rel="noopener ugc nofollow" target="_blank">联合学习:分散数据上的机器学习(2019) </a>，Google I/O'19</p><p id="2b45" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">[7] OpenMind，<a class="ae pa" href="https://github.com/OpenMined/PySyft/" rel="noopener ugc nofollow" target="_blank"> PySyft </a>，GitHub</p></div></div>    
</body>
</html>