<html>
<head>
<title>The 5 most useful Techniques to Handle Imbalanced datasets</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">处理不平衡数据集的 5 种最有用的技术</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/the-5-most-useful-techniques-to-handle-imbalanced-datasets-6cdba096d55a?source=collection_archive---------8-----------------------#2019-11-20">https://towardsdatascience.com/the-5-most-useful-techniques-to-handle-imbalanced-datasets-6cdba096d55a?source=collection_archive---------8-----------------------#2019-11-20</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><figure class="is it gp gr iu iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi ir"><img src="../Images/765aa8d3ed67054fe165f074e5bef640.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*UE5wL8mCyc4gaSXmWfWmHw.png"/></div></div><figcaption class="jc jd gj gh gi je jf bd b be z dk">Image by <a class="ae jg" href="https://pixabay.com/users/thatsphotography-3017066/?utm_source=link-attribution&amp;utm_medium=referral&amp;utm_campaign=image&amp;utm_content=1562025" rel="noopener ugc nofollow" target="_blank">thatsphotography</a> from <a class="ae jg" href="https://pixabay.com/?utm_source=link-attribution&amp;utm_medium=referral&amp;utm_campaign=image&amp;utm_content=1562025" rel="noopener ugc nofollow" target="_blank">Pixabay</a></figcaption></figure><div class=""/><div class=""><h2 id="232f" class="pw-subtitle-paragraph kg ji jj bd b kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx dk translated">如果您还没有遇到不平衡的数据集，您将会</h2></div><p id="5ff0" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">您是否遇到过这样的问题:数据集中的正类样本如此之少，以至于模型无法学习？</p><p id="cb5d" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><strong class="la jk"> <em class="lu">在这种情况下，你仅仅通过预测多数类就能获得相当高的准确度，但是你无法捕捉到少数类，这通常是首先创建模型的目的。</em> </strong></p><p id="bdc4" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">这种数据集非常常见，被称为不平衡数据集。</p><blockquote class="lv"><p id="facc" class="lw lx jj bd ly lz ma mb mc md me lt dk translated">不平衡数据集是分类问题的一种特殊情况，其中类之间的分布不均匀。通常，它们由两类组成:多数(消极)类和少数(积极)类</p></blockquote><p id="e883" class="pw-post-body-paragraph ky kz jj la b lb mf kk ld le mg kn lg lh mh lj lk ll mi ln lo lp mj lr ls lt im bi translated">对于不同领域的不同用例，可能会发现不平衡的数据集:</p><ul class=""><li id="573b" class="mk ml jj la b lb lc le lf lh mm ll mn lp mo lt mp mq mr ms bi translated"><strong class="la jk">金融</strong>:欺诈检测数据集的欺诈率通常约为 1–2%</li><li id="3864" class="mk ml jj la b lb mt le mu lh mv ll mw lp mx lt mp mq mr ms bi translated"><strong class="la jk">广告投放</strong>:点击预测数据集也没有很高的点击率。</li><li id="2072" class="mk ml jj la b lb mt le mu lh mv ll mw lp mx lt mp mq mr ms bi translated"><strong class="la jk">交通</strong> / <strong class="la jk">航空公司</strong>:飞机会发生故障吗？</li><li id="35a1" class="mk ml jj la b lb mt le mu lh mv ll mw lp mx lt mp mq mr ms bi translated"><strong class="la jk">医学</strong>:患者是否有癌症？</li><li id="00db" class="mk ml jj la b lb mt le mu lh mv ll mw lp mx lt mp mq mr ms bi translated"><strong class="la jk">内容审核</strong>:一个帖子包含 NSFW 内容吗？</li></ul><p id="f0b1" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">那么我们如何解决这样的问题呢？</p><p id="a54f" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><strong class="la jk"> <em class="lu">这篇文章是关于解释你可以用来处理不平衡数据集的各种技术。</em> </strong></p></div><div class="ab cl my mz hx na" role="separator"><span class="nb bw bk nc nd ne"/><span class="nb bw bk nc nd ne"/><span class="nb bw bk nc nd"/></div><div class="im in io ip iq"><h1 id="718b" class="nf ng jj bd nh ni nj nk nl nm nn no np kp nq kq nr ks ns kt nt kv nu kw nv nw bi translated">1.随机欠采样和过采样</h1><figure class="ny nz oa ob gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi nx"><img src="../Images/cb87b4520652af7cf03e50353c7884ba.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*FeIp1t4uEcW5LmSM.png"/></div></div><figcaption class="jc jd gj gh gi je jf bd b be z dk"><a class="ae jg" href="https://www.kaggle.com/rafjaa/resampling-strategies-for-imbalanced-datasets#t1" rel="noopener ugc nofollow" target="_blank">Source</a></figcaption></figure><p id="cbf5" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">一种被广泛采用并且可能是最直接的处理高度不平衡数据集的方法叫做重采样。它包括从多数类中移除样本(欠采样)和/或从少数类中添加更多样本(过采样)。</p><p id="bf43" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">让我们首先创建一些不平衡数据的例子。</p><pre class="ny nz oa ob gt oc od oe of aw og bi"><span id="c166" class="oh ng jj od b gy oi oj l ok ol">from sklearn.datasets import make_classification</span><span id="a7cd" class="oh ng jj od b gy om oj l ok ol">X, y = make_classification(<br/>    n_classes=2, class_sep=1.5, weights=[0.9, 0.1],<br/>    n_informative=3, n_redundant=1, flip_y=0,<br/>    n_features=20, n_clusters_per_class=1,<br/>    n_samples=100, random_state=10<br/>)</span><span id="73b2" class="oh ng jj od b gy om oj l ok ol">X = pd.DataFrame(X)<br/>X['target'] = y</span></pre><p id="bb44" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">我们现在可以使用以下工具进行随机过采样和欠采样:</p><pre class="ny nz oa ob gt oc od oe of aw og bi"><span id="296c" class="oh ng jj od b gy oi oj l ok ol">num_0 = len(X[X['target']==0])<br/>num_1 = len(X[X['target']==1])<br/>print(num_0,num_1)</span><span id="214b" class="oh ng jj od b gy om oj l ok ol"># random undersample</span><span id="62ce" class="oh ng jj od b gy om oj l ok ol">undersampled_data = pd.concat([ X[X['target']==0].sample(num_1) , X[X['target']==1] ])<br/>print(len(undersampled_data))</span><span id="c8d5" class="oh ng jj od b gy om oj l ok ol"># random oversample</span><span id="1a71" class="oh ng jj od b gy om oj l ok ol">oversampled_data = pd.concat([ X[X['target']==0] , X[X['target']==1].sample(num_0, replace=True) ])<br/>print(len(oversampled_data))</span><span id="f711" class="oh ng jj od b gy om oj l ok ol">------------------------------------------------------------<br/>OUTPUT:<br/>90 10<br/>20<br/>180</span></pre></div><div class="ab cl my mz hx na" role="separator"><span class="nb bw bk nc nd ne"/><span class="nb bw bk nc nd ne"/><span class="nb bw bk nc nd"/></div><div class="im in io ip iq"><h1 id="58f5" class="nf ng jj bd nh ni nj nk nl nm nn no np kp nq kq nr ks ns kt nt kv nu kw nv nw bi translated">2.使用不平衡学习的欠采样和过采样</h1><p id="8ec7" class="pw-post-body-paragraph ky kz jj la b lb on kk ld le oo kn lg lh op lj lk ll oq ln lo lp or lr ls lt im bi translated">不平衡学习(<code class="fe os ot ou od b">imblearn</code>)是一个 Python 包，用来解决不平衡数据集的问题。</p><p id="9f9d" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">它提供了多种欠采样和过采样方法。</p><h2 id="ecae" class="oh ng jj bd nh ov ow dn nl ox oy dp np lh oz pa nr ll pb pc nt lp pd pe nv pf bi translated">a.使用 Tomek 链接的欠采样:</h2><p id="ef29" class="pw-post-body-paragraph ky kz jj la b lb on kk ld le oo kn lg lh op lj lk ll oq ln lo lp or lr ls lt im bi translated">它提供的一种方法叫做 Tomek 链接。托梅克链是相邻的相反类的成对例子。</p><p id="1829" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">在该算法中，我们最终从 Tomek 链接中移除多数元素，这为分类器提供了更好的决策边界。</p><figure class="ny nz oa ob gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi pg"><img src="../Images/26a2b5127cc54ac0d45e0969e3cc77ac.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*YWVxE7SbWKnTnbZi"/></div></div><figcaption class="jc jd gj gh gi je jf bd b be z dk"><a class="ae jg" href="https://www.kaggle.com/rafjaa/resampling-strategies-for-imbalanced-datasets#t1" rel="noopener ugc nofollow" target="_blank">Source</a></figcaption></figure></div><div class="ab cl my mz hx na" role="separator"><span class="nb bw bk nc nd ne"/><span class="nb bw bk nc nd ne"/><span class="nb bw bk nc nd"/></div><div class="im in io ip iq"><pre class="ny nz oa ob gt oc od oe of aw og bi"><span id="30f1" class="oh ng jj od b gy oi oj l ok ol">from imblearn.under_sampling import TomekLinks</span><span id="179f" class="oh ng jj od b gy om oj l ok ol">tl = TomekLinks(return_indices=True, ratio='majority')</span><span id="85af" class="oh ng jj od b gy om oj l ok ol">X_tl, y_tl, id_tl = tl.fit_sample(X, y)</span></pre><h2 id="9aeb" class="oh ng jj bd nh ov ow dn nl ox oy dp np lh oz pa nr ll pb pc nt lp pd pe nv pf bi translated">b.使用 SMOTE 进行过采样:</h2><p id="e375" class="pw-post-body-paragraph ky kz jj la b lb on kk ld le oo kn lg lh op lj lk ll oq ln lo lp or lr ls lt im bi translated">在 SMOTE(合成少数过采样技术)中，我们在已经存在的元素附近合成少数类的元素。</p><figure class="ny nz oa ob gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi ph"><img src="../Images/3edc03beda3eb04ecf682d24f5c04f5c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*_XpwY9GznmejI4WN.png"/></div></div><figcaption class="jc jd gj gh gi je jf bd b be z dk"><a class="ae jg" href="https://www.kaggle.com/rafjaa/resampling-strategies-for-imbalanced-datasets#t1" rel="noopener ugc nofollow" target="_blank">Source</a></figcaption></figure><pre class="ny nz oa ob gt oc od oe of aw og bi"><span id="a7cc" class="oh ng jj od b gy oi oj l ok ol">from imblearn.over_sampling import SMOTE</span><span id="53d4" class="oh ng jj od b gy om oj l ok ol">smote = SMOTE(ratio='minority')</span><span id="d4bb" class="oh ng jj od b gy om oj l ok ol">X_sm, y_sm = smote.fit_sample(X, y)</span></pre><p id="1910" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">在<code class="fe os ot ou od b"><a class="ae jg" href="https://github.com/scikit-learn-contrib/imbalanced-learn#id3" rel="noopener ugc nofollow" target="_blank">imblearn</a></code>包中有各种各样的其他方法用于欠采样(聚类质心、近似缺失等)。)和过采样(ADASYN 和 bSMOTE)，您可以查看一下。</p></div><div class="ab cl my mz hx na" role="separator"><span class="nb bw bk nc nd ne"/><span class="nb bw bk nc nd ne"/><span class="nb bw bk nc nd"/></div><div class="im in io ip iq"><h1 id="33f1" class="nf ng jj bd nh ni nj nk nl nm nn no np kp nq kq nr ks ns kt nt kv nu kw nv nw bi translated">3.模型中的类权重</h1><figure class="ny nz oa ob gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi pi"><img src="../Images/46d760dc85ff1c376b3b5780888c84cd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*tWZiI8yEHxUW0P9P.jpg"/></div></div></figure><p id="eb9a" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">大多数机器学习模型都提供了一个叫做<code class="fe os ot ou od b">class_weights</code>的参数。例如，在使用<code class="fe os ot ou od b">class_weights</code>的随机森林分类器中，我们可以使用字典为少数类指定更高的权重。</p><pre class="ny nz oa ob gt oc od oe of aw og bi"><span id="642e" class="oh ng jj od b gy oi oj l ok ol">from sklearn.linear_model import <strong class="od jk">LogisticRegression</strong></span><span id="9545" class="oh ng jj od b gy om oj l ok ol"><em class="lu">clf = </em><strong class="od jk">LogisticRegression</strong>(<strong class="od jk"><em class="lu">class_weight={0:1,1:10}</em></strong>)</span></pre><p id="f21b" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><strong class="la jk"> <em class="lu">但是后台到底发生了什么？</em> </strong></p><p id="ab1c" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">在逻辑回归中，我们使用二元交叉熵计算每个示例的损失:</p><pre class="ny nz oa ob gt oc od oe of aw og bi"><span id="890b" class="oh ng jj od b gy oi oj l ok ol">Loss = −<em class="lu">y</em>log(<em class="lu">p) </em>−<em class="lu"> </em>(1−<em class="lu">y</em>)log(1−<em class="lu">p</em>)</span></pre><p id="4a5a" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">在这种特殊的形式下，我们对积极的和消极的两类都给予同等的重视。当我们将 class_weight 设置为<code class="fe os ot ou od b">class_weight = {0:1,1:20}</code>时，后台的分类器试图最小化:</p><pre class="ny nz oa ob gt oc od oe of aw og bi"><span id="185e" class="oh ng jj od b gy oi oj l ok ol">NewLoss = −20*<em class="lu">y</em>log(<em class="lu">p) </em>−<em class="lu"> 1*</em>(1−<em class="lu">y</em>)log(1−<em class="lu">p</em>)</span></pre><p id="543d" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><strong class="la jk"> <em class="lu">那么这里到底发生了什么？</em>T12】</strong></p><ul class=""><li id="c847" class="mk ml jj la b lb lc le lf lh mm ll mn lp mo lt mp mq mr ms bi translated">如果我们的模型给出的概率为 0.3，并且我们错误地对一个正例进行了分类，则新损失的值为-20log(0.3) = 10.45</li><li id="0cbd" class="mk ml jj la b lb mt le mu lh mv ll mw lp mx lt mp mq mr ms bi translated">如果我们的模型给出的概率为 0.7，并且我们对一个负面的例子进行了错误分类，那么新的损失值将为-log(0.3) = 0.52</li></ul><p id="ac0e" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">这意味着，在这种情况下，当我们的模型错误地分类了一个积极的少数群体的例子时，我们会惩罚它大约 20 倍以上。</p><p id="a47b" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">如何计算 class_weights？ </p><p id="b570" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><em class="lu">没有一种方法可以做到这一点，这应该被构建为针对您的特定问题的超参数搜索问题。</em></p><p id="d11d" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">但是如果你想使用 y 变量的分布来获得 class_weights，你可以使用下面这个来自<code class="fe os ot ou od b">sklearn</code>的实用程序。</p><pre class="ny nz oa ob gt oc od oe of aw og bi"><span id="14d8" class="oh ng jj od b gy oi oj l ok ol"><strong class="od jk">from</strong> sklearn.utils.class_weight <strong class="od jk">import</strong> compute_class_weight</span><span id="2f82" class="oh ng jj od b gy om oj l ok ol">class_weights = compute_class_weight('balanced', np.unique(y), y)</span></pre></div><div class="ab cl my mz hx na" role="separator"><span class="nb bw bk nc nd ne"/><span class="nb bw bk nc nd ne"/><span class="nb bw bk nc nd"/></div><div class="im in io ip iq"><h1 id="2ed9" class="nf ng jj bd nh ni nj nk nl nm nn no np kp nq kq nr ks ns kt nt kv nu kw nv nw bi translated">4.更改您的评估标准</h1><figure class="ny nz oa ob gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi pj"><img src="../Images/4c0b328efa628a5f31bec5ac4bf7088b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*T90oJoRGS9khxB-K"/></div></div></figure><p id="a7e3" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">每当我们处理不平衡的数据集时，选择正确的评估指标是非常重要的。一般来说，在这样的情况下，F1 的分数就是我想要的作为我的<a class="ae jg" rel="noopener" target="_blank" href="/the-5-classification-evaluation-metrics-you-must-know-aa97784ff226"> <strong class="la jk"> <em class="lu">评价指标的</em> </strong> </a>。</p><p id="0dc5" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">F1 分数是一个介于 0 和 1 之间的数字，是精确度和召回率的调和平均值。</p><figure class="ny nz oa ob gt iv gh gi paragraph-image"><div class="gh gi pk"><img src="../Images/a0daf69092af53bea32399a5ce84e743.png" data-original-src="https://miro.medium.com/v2/resize:fit:752/format:webp/0*HZ1eOpKgyjnxMBQV.png"/></div></figure><p id="23f1" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><strong class="la jk"> <em class="lu">那么它有什么帮助呢？</em> </strong></p><p id="f566" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">让我们从一个二元预测问题开始。我们正在预测一颗小行星是否会撞击地球。 </p><p id="cdb9" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">因此，我们创建了一个模型，对整个训练集预测“否”。</p><p id="dbc8" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><strong class="la jk"> <em class="lu">什么是准确度(通常是最常用的评估指标)？</em> </strong></p><p id="773a" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">它超过了 99%,所以根据精确度，这个模型相当不错，但是毫无价值。</p><p id="50e9" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><strong class="la jk"> <em class="lu">现在 F1 的成绩是多少？</em>T3】</strong></p><p id="1b6a" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">我们这里的精度是 0。我们正课的回忆是什么？它是零。因此 F1 分数也是 0。</p><p id="7b7d" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">因此，我们知道准确率为 99%的分类器对我们的情况毫无价值。因此它解决了我们的问题。</p><figure class="ny nz oa ob gt iv gh gi paragraph-image"><div class="gh gi pl"><img src="../Images/b0bdd9a119ebd7a9615af9b8ed676043.png" data-original-src="https://miro.medium.com/v2/resize:fit:524/format:webp/0*LujSG8K7j-rOotdf.png"/></div><figcaption class="jc jd gj gh gi je jf bd b be z dk">Precision-Recall Tradeoff</figcaption></figure><p id="e4ce" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">简单来说，<strong class="la jk"> <em class="lu"> F1 分数在某种程度上维持了你的分类器</em> </strong>的精确度和召回率之间的平衡。如果你的准确率低，F1 就低，如果召回率再低，你的 F1 分数就低。</p><blockquote class="lv"><p id="94ac" class="lw lx jj bd ly lz ma mb mc md me lt dk translated">如果你是一名警督，你想抓罪犯，你想确定你抓的人是罪犯(精确)，你也想尽可能多地抓到罪犯(回忆)。F1 分数管理这种权衡。</p></blockquote><h2 id="dbac" class="oh ng jj bd nh ov pm dn nl ox pn dp np lh po pa nr ll pp pc nt lp pq pe nv pf bi translated">怎么用？</h2><p id="9719" class="pw-post-body-paragraph ky kz jj la b lb on kk ld le oo kn lg lh op lj lk ll oq ln lo lp or lr ls lt im bi translated">您可以使用以下公式计算二元预测问题的 F1 分数:</p><pre class="ny nz oa ob gt oc od oe of aw og bi"><span id="c0ae" class="oh ng jj od b gy oi oj l ok ol"><strong class="od jk">from</strong> <strong class="od jk">sklearn.metrics</strong> <strong class="od jk">import</strong> f1_score<br/>y_true = [0, 1, 1, 0, 1, 1]<br/>y_pred = [0, 0, 1, 0, 0, 1]<br/><strong class="od jk"><em class="lu">f1_score(y_true, y_pred)</em></strong></span></pre><p id="c982" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">这是我的一个函数，我用它来获得最佳阈值，使二元预测的 F1 值最大化。below 函数遍历可能的阈值，以找到给出最佳 F1 分数的阈值。</p><pre class="ny nz oa ob gt oc od oe of aw og bi"><span id="9f6b" class="oh ng jj od b gy oi oj l ok ol"># y_pred is an array of predictions<br/>def bestThresshold(y_true,y_pred):<br/>    best_thresh = None<br/>    best_score = 0<br/>    for thresh <strong class="od jk">in</strong> np.arange(0.1, 0.501, 0.01):<br/>        score = f1_score(y_true, np.array(y_pred)&gt;thresh)<br/>        if score &gt; best_score:<br/>            best_thresh = thresh<br/>            best_score = score<br/>    return best_score , best_thresh</span></pre></div><div class="ab cl my mz hx na" role="separator"><span class="nb bw bk nc nd ne"/><span class="nb bw bk nc nd ne"/><span class="nb bw bk nc nd"/></div><div class="im in io ip iq"><h1 id="cd56" class="nf ng jj bd nh ni nj nk nl nm nn no np kp nq kq nr ks ns kt nt kv nu kw nv nw bi translated">5.多方面的</h1><figure class="ny nz oa ob gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi pr"><img src="../Images/179fb00db1806a1231de22b01773e3db.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*SRHX8KMhOOE1f6Fj"/></div></div><figcaption class="jc jd gj gh gi je jf bd b be z dk">Try new things and explore new places</figcaption></figure><p id="d683" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">根据您的用例以及您试图解决的问题，各种其他方法也可能有效:</p><h2 id="d8e9" class="oh ng jj bd nh ov ow dn nl ox oy dp np lh oz pa nr ll pb pc nt lp pd pe nv pf bi translated">a)收集更多数据</h2><p id="fc67" class="pw-post-body-paragraph ky kz jj la b lb on kk ld le oo kn lg lh op lj lk ll oq ln lo lp or lr ls lt im bi translated">如果可以的话，这绝对是你应该尝试的事情。通过更多正面的例子获得更多的数据将有助于您的模型从更多样的角度来看待多数群体和少数群体。</p><h2 id="26af" class="oh ng jj bd nh ov ow dn nl ox oy dp np lh oz pa nr ll pb pc nt lp pd pe nv pf bi translated">b)将问题视为异常检测</h2><p id="0f7a" class="pw-post-body-paragraph ky kz jj la b lb on kk ld le oo kn lg lh op lj lk ll oq ln lo lp or lr ls lt im bi translated">您可能希望将您的分类问题视为异常检测问题。</p><p id="4798" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><strong class="la jk">异常检测</strong>是对罕见项目、事件或观察结果的识别，这些项目、事件或观察结果通过与大多数数据的显著不同而引起怀疑</p><p id="92b7" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">您可以使用隔离林或自动编码器进行异常检测。</p><h2 id="9038" class="oh ng jj bd nh ov ow dn nl ox oy dp np lh oz pa nr ll pb pc nt lp pd pe nv pf bi translated">c)基于模型</h2><p id="f488" class="pw-post-body-paragraph ky kz jj la b lb on kk ld le oo kn lg lh op lj lk ll oq ln lo lp or lr ls lt im bi translated">有些模型特别适合不平衡的数据集。</p><p id="6fb1" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">例如，在 boosting 模型中，我们给在每次树迭代中被错误分类的案例更多的权重。</p></div><div class="ab cl my mz hx na" role="separator"><span class="nb bw bk nc nd ne"/><span class="nb bw bk nc nd ne"/><span class="nb bw bk nc nd"/></div><div class="im in io ip iq"><h1 id="17fc" class="nf ng jj bd nh ni nj nk nl nm nn no np kp nq kq nr ks ns kt nt kv nu kw nv nw bi translated">结论</h1><p id="8e94" class="pw-post-body-paragraph ky kz jj la b lb on kk ld le oo kn lg lh op lj lk ll oq ln lo lp or lr ls lt im bi translated">在处理不平衡的数据集时，不存在放之四海而皆准的方法。你必须根据你的问题尝试多种方法。</p><p id="d634" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">在这篇文章中，我谈到了每当我面临这样的问题时，我脑海中通常会出现的怀疑。</p><p id="4bbd" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">一个建议是尝试使用以上所有的方法，看看哪个最适合你的用例。</p></div><div class="ab cl my mz hx na" role="separator"><span class="nb bw bk nc nd ne"/><span class="nb bw bk nc nd ne"/><span class="nb bw bk nc nd"/></div><div class="im in io ip iq"><p id="e65b" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">如果你想<a class="ae jg" rel="noopener" target="_blank" href="/how-did-i-start-with-data-science-3f4de6b501b0?source=---------8------------------">了解</a>更多关于不平衡数据集及其带来的问题，我想推荐吴恩达的这个<a class="ae jg" href="https://coursera.pxf.io/NKERRq" rel="noopener ugc nofollow" target="_blank"> <strong class="la jk"> <em class="lu">精品课程</em> </strong> </a>。这是我开始的原因。一定要去看看。</p><p id="6ed3" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">谢谢你的阅读。将来我也会写更多初学者友好的帖子。在<a class="ae jg" href="https://medium.com/@rahul_agarwal?source=post_page---------------------------" rel="noopener"><strong class="la jk"/></a>关注我或者订阅我的<a class="ae jg" href="http://eepurl.com/dbQnuX?source=post_page---------------------------" rel="noopener ugc nofollow" target="_blank"> <strong class="la jk">博客</strong> </a>了解他们。一如既往，我欢迎反馈和建设性的批评，可以通过 Twitter <a class="ae jg" href="https://twitter.com/MLWhiz?source=post_page---------------------------" rel="noopener ugc nofollow" target="_blank"> @mlwhiz </a>联系。</p><p id="1e88" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">此外，一个小小的免责声明——这篇文章中可能会有一些相关资源的附属链接，因为分享知识从来都不是一个坏主意。</p></div></div>    
</body>
</html>