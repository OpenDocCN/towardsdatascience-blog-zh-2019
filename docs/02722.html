<html>
<head>
<title>Speedup your CNN using Fast Dense Feature Extraction and PyTorch</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用快速密集特征提取和 PyTorch 加速 CNN</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/speedup-your-cnn-using-fast-dense-feature-extraction-and-pytorch-dc32acbf12ef?source=collection_archive---------13-----------------------#2019-05-03">https://towardsdatascience.com/speedup-your-cnn-using-fast-dense-feature-extraction-and-pytorch-dc32acbf12ef?source=collection_archive---------13-----------------------#2019-05-03</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><figure class="gl gn jr js jt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi jq"><img src="../Images/18ff19dd46d06a53d25e14943583885a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*KC3RTyxsbu5wGlRAGPNBvQ.jpeg"/></div></div></figure><p id="d17e" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">早在 3 月份，我们开源了我们的“使用具有池化或跨越层的 CNN 的快速密集特征提取”的<a class="ae kz" href="https://github.com/erezposner/Fast_Dense_Feature_Extraction" rel="noopener ugc nofollow" target="_blank">实现，尽管并不广为人知，但 2017 年 BMVC 发表的论文提供了一种高效而优雅的解决方案，介绍了如何在使用基于面片的卷积神经网络时避免计算冗余。所以在这篇文章中，我将解释这个模型是如何工作的，并展示如何在实际应用中使用它。</a></p><p id="37c4" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">我将介绍两件事:首先，概述名为“使用具有池化或跨越层的 CNN 进行快速密集特征提取”的方法。第二，如何在现有的经过训练的补丁网络上使用这种方法来加快推理时间。</p></div><div class="ab cl la lb hx lc" role="separator"><span class="ld bw bk le lf lg"/><span class="ld bw bk le lf lg"/><span class="ld bw bk le lf"/></div><div class="im in io ip iq"><h1 id="5b4b" class="lh li it bd lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me bi translated">什么是基于补丁的方法？问题出在哪里？</h1><p id="d4c0" class="pw-post-body-paragraph kb kc it kd b ke mf kg kh ki mg kk kl km mh ko kp kq mi ks kt ku mj kw kx ky im bi translated">基于小块的 CNN 通常应用于图像的单个小块，其中每个小块被单独分类。当试图在图像中相邻的重叠的小块上多次执行相同的 CNN 时，通常使用这种方法。这包括基于任务的特征提取，如相机校准、补丁匹配、光流估计和立体匹配。此外，还有不被视为特征提取的基于补丁的应用，如滑动窗口对象检测或识别。</p><p id="5756" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">在所有这种基于补丁的任务中，在相邻 CNN 的计算之间会有很多冗余。比如看下图。</p><p id="02fc" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">在左边你可以看到一个简单的一维 CNN。从底部开始，每个像素在输出层中只贡献一个结果，没有任何冗余。在<strong class="kd iu"> </strong>上相反，在右边，如果在一个图像的每个像素位置执行这个 CNN 来创建特征，许多中间层结果在网络之间被无缘无故地共享。</p><figure class="ml mm mn mo gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi mk"><img src="../Images/b8d257ae545f47cff2b5ade231909a4f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*gJ2-wfOzBnreesLDfKTxlw.png"/></div></div><figcaption class="mp mq gj gh gi mr ms bd b be z dk">The numbers in nodes state how often a node is shared. The red connections show how the red node is shared. Pooling with stride 2 halves the output resolution. Thus, we need two pooling layers: the original one (blue) and one shifted by one pixel (green) to avoid halving the output resolution.</figcaption></figure><h1 id="e61c" class="lh li it bd lj lk mt lm ln lo mu lq lr ls mv lu lv lw mw ly lz ma mx mc md me bi translated">快速密集特征提取</h1><p id="cdb0" class="pw-post-body-paragraph kb kc it kd b ke mf kg kh ki mg kk kl km mh ko kp kq mi ks kt ku mj kw kx ky im bi translated">这种方法的主要思想是，不是对图像中的每个小块分别执行我们的基于 CNN <strong class="kd iu"> Cp </strong>(它是在训练小块<strong class="kd iu"> <em class="my"> P </em> </strong>上训练的)，而是让我们一次对输入图像<strong class="kd iu"> <em class="my"> I </em> </strong>中的所有小块<em class="my"> P(x，y) </em>高效地执行它。</p><p id="6123" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">为了一致起见，让我们将输入图像<strong class="kd iu"> <em class="my"> I </em> </strong>定义为宽度<em class="my"> Iw </em>和高度<em class="my"> Ih </em>，我们可以将宽度<em class="my"> Pw </em>和高度<em class="my"> Ph </em>的面片<em class="my">定义为以输入图像中的每个像素位置<em class="my"> (x，y)，x∈0…Iw 1，y∈0…Ih 1</em>为中心</em>输出向量<em class="my"> O(x，y) = CP(P(x，y)) </em>是一个<strong class="kd iu"> <em class="my"> k </em> </strong>通道向量，属于<strong class="kd iu"> <em class="my"> (Ih，Iw，k) </em> </strong>维输出矩阵<strong class="kd iu"> <em class="my"> O </em> </strong>包含对所有图像面片<em class="my"> P(x，y)执行<strong class="kd iu"> <em class="my"> Cp </em> </strong>的结果</em></p><p id="4bea" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">为此，我们可以创建一个网络<strong class="kd iu"> <em class="my"> CI </em> </strong>，直接从<strong class="kd iu"><em class="my"/></strong>计算<strong class="kd iu"><em class="my"/></strong>，同时避免在每个图像块上独立执行<strong class="kd iu"> <em class="my"> Cp </em> </strong>时出现的冗余。<strong class="kd iu"> <em class="my"> Cp </em> </strong>和<strong class="kd iu"> <em class="my"> CI </em> </strong>的架构差异如下图所示。这里，特征提取器中的所有池层都被多池层替换</p><figure class="ml mm mn mo gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi mz"><img src="../Images/8cdaead3ec63f3b56f7b0e8f86dc56ed.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ODSczWzvVFPTxiYe1bk18w.png"/></div></div><figcaption class="mp mq gj gh gi mr ms bd b be z dk">Architecture of <strong class="bd na"><em class="nb">Cp (Left) </em></strong>and <strong class="bd na"><em class="nb">CI (Right)</em></strong></figcaption></figure></div><div class="ab cl la lb hx lc" role="separator"><span class="ld bw bk le lf lg"/><span class="ld bw bk le lf lg"/><span class="ld bw bk le lf"/></div><div class="im in io ip iq"><p id="a01d" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">值得一提的是，<strong class="kd iu"> <em class="my"> CI </em> </strong>将给出与独立地在图像<strong class="kd iu"> <em class="my"> I </em> </strong>的每个补丁上执行网络<strong class="kd iu"> <em class="my"> Cp </em> </strong>相同的结果。但是，<strong class="kd iu"> <em class="my"> CI </em> </strong>运行速度更快，因为它避免了重叠补丁之间的冗余。</p><p id="cf2b" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">当我们处理层的类型时，让我们检查从<strong class="kd iu"> <em class="my"> Cp </em> </strong>到<strong class="kd iu"> <em class="my"> CI </em> </strong>的必要步骤——主要是普通层(没有汇集或跨步)和异常层(包括汇集或跨步)。</p><h2 id="e52f" class="nc li it bd lj nd ne dn ln nf ng dp lr km nh ni lv kq nj nk lz ku nl nm md nn bi translated">1.普通层</h2><p id="13b3" class="pw-post-body-paragraph kb kc it kd b ke mf kg kh ki mg kk kl km mh ko kp kq mi ks kt ku mj kw kx ky im bi translated">在没有跨越或合并的情况下，<strong class="kd iu"> <em class="my"> Cp </em> </strong>和<strong class="kd iu"> <em class="my"> CI </em> </strong>的层是相同的，即</p><figure class="ml mm mn mo gt ju gh gi paragraph-image"><div class="gh gi no"><img src="../Images/51a08e82983265f96a0334298daa9b7c.png" data-original-src="https://miro.medium.com/v2/resize:fit:758/format:webp/1*CVuD_jup22rXlXaJHNrCkw.png"/></div></figure><p id="763a" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">这是因为它们的输出不取决于输入的空间位置，而只取决于输入值本身。</p><h2 id="1140" class="nc li it bd lj nd ne dn ln nf ng dp lr km nh ni lv kq nj nk lz ku nl nm md nn bi translated">2.异常层(包括汇集或跨步)</h2><p id="895e" class="pw-post-body-paragraph kb kc it kd b ke mf kg kh ki mg kk kl km mh ko kp kq mi ks kt ku mj kw kx ky im bi translated">与普通层不同，跨层和池层必须明确处理。下图显示了池的主要问题:第一个面片<em class="my"> P(x，y) </em>与第二个面片<em class="my"> P(x+1，y) </em>(绿色)需要不同的 2 x 2 池，因此不能共享池输出。</p><p id="b128" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">但是，补丁<em class="my"> P(x+2，y) </em>可以再次与原始池一起工作(蓝色)。<em class="my"> P(x，y) </em>和<em class="my"> P(x + 2，y) </em>的重叠位置提供相同的结果，因此可以共享(亮黄色)。</p><p id="68fa" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">对于该示例的概括将是，<strong class="kd iu"> <em class="my"> s </em> </strong>是汇集/步幅大小，并且<strong class="kd iu"> <em class="my"> u </em> </strong>和<strong class="kd iu"> <em class="my"> v </em> </strong>是整数，面片<em class="my"> P(x，y) </em>和<em class="my"> P(x+su，y+sv) </em>仍然共享由两个面片共享的像素的汇集输出。</p><figure class="ml mm mn mo gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi np"><img src="../Images/25a8b096ea43784f71b75bbbfc09627c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*8yvQGOABPPUlsW75eyp-lw.png"/></div></div><figcaption class="mp mq gj gh gi mr ms bd b be z dk">Patches P at different image positions (in red). Sharing between patches that are using blue and the ones that are using green pooling is not possible</figcaption></figure><p id="df80" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">这一起创建了<em class="my"> s × s </em>不同的汇集情况，这些情况必须在我们的汇集层的输入<strong class="kd iu">I’</strong>上独立计算，其中<strong class="kd iu">T27】I’</strong>是第<strong class="kd iu"> <em class="my"> l- </em> </strong>层的输入图像。由于<strong class="kd iu"> s×s </strong>池层将输出大小减小到<em class="my"> Iw/s </em> <strong class="kd iu">，</strong> <em class="my"> Ih/s </em>(具有输入大小<em class="my"> Iw </em> <strong class="kd iu">，</strong> <em class="my"> Ih </em>)很明显，要求<em class="my"> s × s </em>这样的输出仍然获得空间大小<em class="my">的输出<strong class="kd iu"> <em class="my"> O </em> </strong></em></p><p id="b540" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">不同的池输出堆叠在标记为<strong class="kd iu"> M </strong>的额外输出维度中。所有标注为通道的不同汇集输出现在将被后续层视为独立样本(类似于批次维度)。</p><figure class="ml mm mn mo gt ju gh gi paragraph-image"><div class="gh gi nq"><img src="../Images/3e9e990b8b6ea20319bb47f4711c7cce.png" data-original-src="https://miro.medium.com/v2/resize:fit:1120/1*tsvAGxrnLrDMO6oc7buyhQ.gif"/></div></figure><p id="7cfd" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">上面的动画更直观地展示了该过程是如何完成的，每个通道执行一次汇集，最终堆叠在<strong class="kd iu"> <em class="my"> M. </em> </strong>中</p></div><div class="ab cl la lb hx lc" role="separator"><span class="ld bw bk le lf lg"/><span class="ld bw bk le lf lg"/><span class="ld bw bk le lf"/></div><div class="im in io ip iq"><h2 id="81c5" class="nc li it bd lj nd ne dn ln nf ng dp lr km nh ni lv kq nj nk lz ku nl nm md nn bi translated">3.解除警戒</h2><p id="a92e" class="pw-post-body-paragraph kb kc it kd b ke mf kg kh ki mg kk kl km mh ko kp kq mi ks kt ku mj kw kx ky im bi translated">有了一个多池层，我们得到一个输出<strong class="kd iu"> <em class="my"> W </em> </strong>，尺寸<em class="my"> W = (M = s×s，Ih/s，Iw/s，k) </em>，我们希望将它反卷积到最终输出<strong class="kd iu"> <em class="my"> </em> </strong> <em class="my"> O = (Ih，Iw，k) </em>。对于<em class="my"> 2×2 </em>合并，下面的图像直观地显示了取消撤销过程背后的直觉。这里，所有通道应该交错在一起，以生成最终输出<strong class="kd iu"> <em class="my"> O </em> </strong> <em class="my">。</em></p><figure class="ml mm mn mo gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi nr"><img src="../Images/c87c331034ab05439995b71f8341dd32.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*yRc8AJfuyu5WY1i5HcAd2A.png"/></div></div><figcaption class="mp mq gj gh gi mr ms bd b be z dk">On the left, the<strong class="bd na"> </strong>2×2 = 4 output images from 2×2 multipooling and on the Right, the final unwarping output O.</figcaption></figure></div><div class="ab cl la lb hx lc" role="separator"><span class="ld bw bk le lf lg"/><span class="ld bw bk le lf lg"/><span class="ld bw bk le lf"/></div><div class="im in io ip iq"><p id="ca66" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">直接取消 warping 是复杂的，尤其是对于几个池层。这可能是以前的工作避免合并层的原因。然而，如果我们观察维度空间中的问题，它可以很容易地通过单独的转置和整形操作来解决。这样的操作被大多数深度学习框架支持为层。</p><p id="d6c3" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">我不会详细讨论扭曲过程是如何完成的，因为这远远超出了本文的范围。<a class="ae kz" href="https://www.dfki.de/fileadmin/user_upload/import/9245_FastCNNFeature_BMVC.pdf" rel="noopener ugc nofollow" target="_blank">更多详情请参考论文</a>。</p><h1 id="b36e" class="lh li it bd lj lk mt lm ln lo mu lq lr ls mv lu lv lw mw ly lz ma mx mc md me bi translated">实验</h1><p id="4f63" class="pw-post-body-paragraph kb kc it kd b ke mf kg kh ki mg kk kl km mh ko kp kq mi ks kt ku mj kw kx ky im bi translated">作者展示了比较改进的网络<strong class="kd iu"> <em class="my"> CI </em> </strong>和基于块的 CNN <strong class="kd iu"> <em class="my"> Cp </em> </strong>在图像的所有块上运行的基准测试结果。实验是在 GeForce GTX 泰坦 x 上进行的</p><p id="6bef" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">从下表可以看出，<strong class="kd iu"> <em class="my"> Cp </em> </strong>的执行时间大致与图像像素成线性比例(如预期)。<strong class="kd iu"> <em class="my"> CI </em> </strong>另一方面，对于较大的图像几乎不需要更多的时间。另一方面，<strong class="kd iu"> <em class="my"> CI </em> </strong>的内存消耗几乎线性增加。如果没有足够的内存可用，可以将输入图像分割成多个部分，并且可以单独处理每个部分。</p><p id="d085" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">检查加速栏可以清楚地看到<strong class="kd iu"> <em class="my"> CI </em> </strong>的执行速度要快得多，尤其是在较大的图像上。</p><figure class="ml mm mn mo gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi ns"><img src="../Images/4bbe4a3b63e116416e62310f520fbda9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*A0Jw80ce4GjCgcXt5tKp4g.png"/></div></div><figcaption class="mp mq gj gh gi mr ms bd b be z dk">Speed benchmark for <strong class="bd na"><em class="nb">CI </em></strong><em class="nb">and </em><strong class="bd na"><em class="nb">Cp</em></strong></figcaption></figure><h1 id="62d4" class="lh li it bd lj lk mt lm ln lo mu lq lr ls mv lu lv lw mw ly lz ma mx mc md me bi translated">让我们加速基于补丁的 CNN</h1><p id="d6a2" class="pw-post-body-paragraph kb kc it kd b ke mf kg kh ki mg kk kl km mh ko kp kq mi ks kt ku mj kw kx ky im bi translated">在这里，我将解释如何使用我的<a class="ae kz" href="https://github.com/erezposner/Fast_Dense_Feature_Extraction" rel="noopener ugc nofollow" target="_blank">实现“使用具有池化或跨越层的 CNN 的快速密集特征提取</a>”来加速任何基于 CNN 的补丁。</p><p id="4ddd" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">项目结构很简单，您有两个实现:pytorch 和 tensforflow，每个都包含以下内容:</p><ul class=""><li id="8707" class="nt nu it kd b ke kf ki kj km nv kq nw ku nx ky ny nz oa ob bi translated"><code class="fe oc od oe of b">FDFE.py</code> -实施文件中描述的所有方法层和预&amp;后处理方法</li><li id="b3b9" class="nt nu it kd b ke og ki oh km oi kq oj ku ok ky ny nz oa ob bi translated"><code class="fe oc od oe of b">BaseNet.py</code> -这是指<strong class="kd iu"> <em class="my">你的</em> </strong>预训练 CNN <strong class="kd iu"> Cp </strong>在训练补丁<strong class="kd iu"> P </strong>上的一个实现</li><li id="8d96" class="nt nu it kd b ke og ki oh km oi kq oj ku ok ky ny nz oa ob bi translated"><code class="fe oc od oe of b">SlimNet.py</code>——这是指实施<strong class="kd iu"> <em class="my"> CI </em> </strong></li><li id="e1c0" class="nt nu it kd b ke og ki oh km oi kq oj ku ok ky ny nz oa ob bi translated"><code class="fe oc od oe of b">sample_code.py</code> -试运行</li></ul></div><div class="ab cl la lb hx lc" role="separator"><span class="ld bw bk le lf lg"/><span class="ld bw bk le lf lg"/><span class="ld bw bk le lf"/></div><div class="im in io ip iq"><h2 id="6ddd" class="nc li it bd lj nd ne dn ln nf ng dp lr km nh ni lv kq nj nk lz ku nl nm md nn bi translated">1.实施您改进的网络— <strong class="ak"> <em class="nb"> CI </em> </strong></h2><p id="7690" class="pw-post-body-paragraph kb kc it kd b ke mf kg kh ki mg kk kl km mh ko kp kq mi ks kt ku mj kw kx ky im bi translated">为了使用您自己的预训练网络来运行补丁程序，您需要:</p><blockquote class="ol om on"><p id="a2a7" class="kb kc my kd b ke kf kg kh ki kj kk kl oo kn ko kp op kr ks kt oq kv kw kx ky im bi translated">1.在<code class="fe oc od oe of b">BaseNet.net</code>实施您的网络</p><p id="5b17" class="kb kc my kd b ke kf kg kh ki kj kk kl oo kn ko kp op kr ks kt oq kv kw kx ky im bi translated">2.相应修改<code class="fe oc od oe of b">SlimNet.py</code>:</p></blockquote><ul class=""><li id="f3a5" class="nt nu it kd b ke kf ki kj km nv kq nw ku nx ky ny nz oa ob bi translated">根据顺序复制<code class="fe oc od oe of b">BsetNet.py</code>模型层，例如</li></ul><pre class="ml mm mn mo gt or of os ot aw ou bi"><span id="4e52" class="nc li it of b gy ov ow l ox oy">self.conv1 = list(base_net.modules())[change_this_index]</span></pre><ul class=""><li id="8007" class="nt nu it kd b ke kf ki kj km nv kq nw ku nx ky ny nz oa ob bi translated">对于每个<code class="fe oc od oe of b">MaxPool2d</code>层，用决定的步幅值(<em class="my"> sLn </em>)代替<code class="fe oc od oe of b">multiMaxPooling</code></li><li id="844a" class="nt nu it kd b ke og ki oh km oi kq oj ku ok ky ny nz oa ob bi translated">根据模型中<code class="fe oc od oe of b">multiMaxPooling</code>的数量，去除缠绕层</li><li id="2b20" class="nt nu it kd b ke og ki oh km oi kq oj ku ok ky ny nz oa ob bi translated">不要移除以下图层 multiPoolPrepare，unwrapPrepare</li></ul><h2 id="c1a9" class="nc li it bd lj nd ne dn ln nf ng dp lr km nh ni lv kq nj nk lz ku nl nm md nn bi translated">2.在改进后的网络上运行示例代码</h2><p id="940d" class="pw-post-body-paragraph kb kc it kd b ke mf kg kh ki mg kk kl km mh ko kp kq mi ks kt ku mj kw kx ky im bi translated">现在你应该<code class="fe oc od oe of b">sample_code.py</code>确保项目正常运行。该测试生成大小为<code class="fe oc od oe of b">imH X imW</code>的随机输入图像<strong class="kd iu"> <em class="my"> I </em> </strong>，并在<strong class="kd iu"> <em class="my"> Cp </em> </strong>和<strong class="kd iu"> <em class="my"> CI </em> </strong>上对其进行评估。</p><p id="ccf3" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">该脚本继续并评估两个 CNN 输出之间的差异，并执行速度基准标记。<strong class="kd iu"> <em class="my"> Cp </em> </strong>有两种操作模式</p><ul class=""><li id="f51d" class="nt nu it kd b ke kf ki kj km nv kq nw ku nx ky ny nz oa ob bi translated"><em class="my"> singlePatch </em> mode-在将从输入图像<strong class="kd iu"> <em class="my"> I </em> </strong>中裁剪的单个补丁<code class="fe oc od oe of b">pH x pW</code>上运行<strong class="kd iu"> <em class="my"> Cp </em> </strong></li><li id="32f6" class="nt nu it kd b ke og ki oh km oi kq oj ku ok ky ny nz oa ob bi translated">allPatches 模式——一次对多个补丁运行<strong class="kd iu"> <em class="my"> Cp </em> </strong>。这里<code class="fe oc od oe of b">batch_size</code>将决定一次评估多少补丁。</li></ul><blockquote class="ol om on"><p id="86e1" class="kb kc my kd b ke kf kg kh ki kj kk kl oo kn ko kp op kr ks kt oq kv kw kx ky im bi translated">可能的参数—在<code class="fe oc od oe of b">sample_code.py</code>中，有可以调整的初始参数，如图像高度、图像宽度、补丁宽度、补丁高度等…</p></blockquote><h2 id="fa6e" class="nc li it bd lj nd ne dn ln nf ng dp lr km nh ni lv kq nj nk lz ku nl nm md nn bi translated">3.我应该期待看到什么？</h2><p id="cf3d" class="pw-post-body-paragraph kb kc it kd b ke mf kg kh ki mg kk kl km mh ko kp kq mi ks kt ku mj kw kx ky im bi translated">该脚本输出以下内容:</p><ul class=""><li id="295f" class="nt nu it kd b ke kf ki kj km nv kq nw ku nx ky ny nz oa ob bi translated">base_net <strong class="kd iu"> <em class="my"> Cp </em> </strong>输出和 slim_net 输出<strong class="kd iu"> <em class="my"> CI — </em> </strong> <em class="my">之间的合计差异如上所述，这两个输出之间应该没有任何重大差异。</em></li><li id="7f07" class="nt nu it kd b ke og ki oh km oi kq oj ku ok ky ny nz oa ob bi translated">对于<strong class="kd iu"> <em class="my"> Cp，</em> </strong>每个补丁的平均评估</li><li id="9ef8" class="nt nu it kd b ke og ki oh km oi kq oj ku ok ky ny nz oa ob bi translated">对于<strong class="kd iu"> <em class="my"> CI，</em> </strong>每帧总评价。即整个输入图像</li></ul><p id="62a3" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">预期的详细信息应如下所示:</p><pre class="ml mm mn mo gt or of os ot aw ou bi"><span id="b814" class="nc li it of b gy ov ow l ox oy">Total time for C_P: 0.017114248275756836 sec<br/>------------------------------------------------------------<br/>Averaged time for C_I per Patch without warm up: 0.0010887398617342114 sec<br/>------- Comparison between a base_net over all patches output and slim_net -------<br/>aggregated difference percentage = 0.0000000000 %<br/>maximal abs difference = 0.0000000000 at index i=0,j=0<br/>------------------------------------------------------------</span></pre><p id="ff9f" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">这就对了。你极大地提升了你的人际网络。就在这个例子中，我们将运行时间提高了大约 10 倍。</p><h1 id="c168" class="lh li it bd lj lk mt lm ln lo mu lq lr ls mv lu lv lw mw ly lz ma mx mc md me bi translated">感谢</h1><p id="68cc" class="pw-post-body-paragraph kb kc it kd b ke mf kg kh ki mg kk kl km mh ko kp kq mi ks kt ku mj kw kx ky im bi translated">非常感谢下面这个人帮助我们发现并实现了这个方法。</p><p id="738d" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">Arnon Kahani——一位好朋友和优秀的 ML 工程师</p><h1 id="6405" class="lh li it bd lj lk mt lm ln lo mu lq lr ls mv lu lv lw mw ly lz ma mx mc md me bi translated">结论</h1><p id="6722" class="pw-post-body-paragraph kb kc it kd b ke mf kg kh ki mg kk kl km mh ko kp kq mi ks kt ku mj kw kx ky im bi translated">如果你对源代码感兴趣，可以在我的<a class="ae kz" href="https://github.com/erezposner/Fast_Dense_Feature_Extraction" rel="noopener ugc nofollow" target="_blank">CNN 快速密集特征提取</a> GitHub 知识库中找到。</p><p id="bad9" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">一如既往，如果您有任何问题或意见，请随时在下面留下您的反馈，或者您可以随时通过<a class="ae kz" href="http://www.linkedin.com/in/erezposner" rel="noopener ugc nofollow" target="_blank"> LinkedIn </a>联系我。</p><p id="530c" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">在那之前，下一篇文章再见！😄</p></div></div>    
</body>
</html>