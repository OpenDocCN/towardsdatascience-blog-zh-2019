<html>
<head>
<title>A Machine Learning Approach to Author Identification of Horror Novels from Text Snippets</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">从文本片段中识别恐怖小说作者的机器学习方法</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/a-machine-learning-approach-to-author-identification-of-horror-novels-from-text-snippets-3f1ef5dba634?source=collection_archive---------3-----------------------#2019-01-23">https://towardsdatascience.com/a-machine-learning-approach-to-author-identification-of-horror-novels-from-text-snippets-3f1ef5dba634?source=collection_archive---------3-----------------------#2019-01-23</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="2d13" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">让我们开始吧…</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/a9b80cc4fad3082f6468d2da076c1bc0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*M1hYXODiQnh8nobB9YF3RA.jpeg"/></div></div></figure><p id="fa9d" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">有许多小说正在被创作，但其中一些在多年后获得了狂热的地位，并被人们铭记了很久。小说有几种体裁和跨体裁(几种体裁的混合)。恐怖小说是一种特殊的小说类型。有许多著名的恐怖小说，即使在发行几十年后，仍然是读者的绝对最爱。例如，RL Stine 的<em class="lq">鸡皮疙瘩系列(1998–2016)</em>已经家喻户晓，是现代最著名的恐怖小说之一。但是许多经典的恐怖小说出现在 21 世纪之前。比如 H.P .洛夫克拉夫特的恐怖小说<strong class="kw iu"> </strong> <em class="lq">【未知卡达思的寻梦(1943) </em>已经是 20 世纪必读的恐怖小说之一。从这里，如果我们再回到 19 世纪，怎么会有人忘记玛丽·雪莱的<em class="lq">弗兰肯斯坦(1818 &amp; 1823) </em>和埃德加·爱伦·坡的<em class="lq">厄舍古屋的倒塌(1839) </em>？但是有一点很明显，</p><p id="2ec2" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated"><strong class="kw iu"> <em class="lq">每位作家，无论是洛夫克拉夫特、玛丽·雪莱还是爱伦坡，都有自己的写作风格，其中包括使用特定词汇的标志性时尚，这使得他们的文学作品独一无二，易于辨认</em> </strong></p><p id="9dee" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">所以，让我们利用这一事实，从他们的恐怖小说中摘录或引用的文字片段中确定作者(洛夫克拉夫特/玛丽·雪莱/坡)。自然语言处理(NLP)支持的机器学习是解决上述问题的一个很好的方案。所以，我们把问题陈述清楚，开始行动吧！！！</p><p id="ff63" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated"><strong class="kw iu">问题陈述</strong>:<em class="lq">给出埃德加·爱伦·坡、玛丽·雪莱和惠普·洛夫克拉夫特的著名小说中的文字片段/引文，指出该文字片段或引文的作者是谁</em></p><p id="d0bb" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">为此，考虑由 Kaggle 准备的<a class="ae lr" href="https://www.kaggle.com/c/spooky-author-identification/data" rel="noopener ugc nofollow" target="_blank"> <strong class="kw iu"> <em class="lq">幽灵作者识别数据集</em> </strong> </a>。</p><p id="d1ef" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">所以，让我们使用 NLTK(自然语言工具包)和 Scikit-Learn 开始用 Python 开发机器学习模型吧！！！</p><p id="ec86" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">I. <strong class="kw iu">使用 Pandas 加载(读取)数据集:</strong></p><pre class="kj kk kl km gt ls lt lu lv aw lw bi"><span id="cbc9" class="lx ly it lt b gy lz ma l mb mc">import pandas as pd</span><span id="ba82" class="lx ly it lt b gy md ma l mb mc">df = pd.read_csv('train.csv')<br/>df.head(5) # <strong class="lt iu">for showing a snapshot of the dataset</strong></span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi me"><img src="../Images/60c1f8c877309b8108c229a45cf726c4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1126/format:webp/1*mMNovkZfDEhIuXAMRoAWdw.png"/></div></div><figcaption class="mf mg gj gh gi mh mi bd b be z dk">Snapshot of the Dataset in which under label <strong class="bd mj">author</strong>, <strong class="bd mj">EAP</strong> -&gt; (<strong class="bd mj">Edgar Allan Poe</strong>), <strong class="bd mj">HPL</strong> -&gt; (<strong class="bd mj">HP Lovecraft</strong>) and <strong class="bd mj">MWS</strong> -&gt; (<strong class="bd mj">Mary</strong> <strong class="bd mj">Wollstonecraft Shelley</strong>)</figcaption></figure><p id="2192" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">二。<strong class="kw iu">文本处理步骤:</strong></p><ol class=""><li id="e5aa" class="mk ml it kw b kx ky la lb ld mm lh mn ll mo lp mp mq mr ms bi translated">删除标点符号→从数据集(语料库)的所有文本片段(实例或文档)中删除所有标点符号。</li><li id="2433" class="mk ml it kw b kx mt la mu ld mv lh mw ll mx lp mp mq mr ms bi translated">一个词的词形变化叫做引理。例如，(正在学习，已学习)是词根单词 study 的变形形式或引理。因此，一个单词的词条被分组在单个词根下。这样做是为了使语料库中的词汇只包含不同的单词。</li><li id="3272" class="mk ml it kw b kx mt la mu ld mv lh mw ll mx lp mp mq mr ms bi translated">停用词的去除→停用词通常是冠词(a，an，the)，介词(in，on，under，…)以及其他不提供任何关键或必要信息的频繁出现的词。它们被从数据集(语料库)中存在的所有文本片段中移除。</li></ol><pre class="kj kk kl km gt ls lt lu lv aw lw bi"><span id="4305" class="lx ly it lt b gy lz ma l mb mc"># <strong class="lt iu">Importing necessary libraries<br/></strong>import string<br/>from nltk.corpus import stopwords<br/>from nltk.stem import WordNetLemmatizer</span><span id="6214" class="lx ly it lt b gy md ma l mb mc">lemmatiser = WordNetLemmatizer()</span><span id="7cd1" class="lx ly it lt b gy md ma l mb mc"># <strong class="lt iu">Defining a module for Text Processing<br/></strong>def text_process(tex):<br/>    # <strong class="lt iu">1. Removal of Punctuation Marks</strong> <br/>    nopunct=[char for char in tex if char not in string.punctuation]<br/>    nopunct=''.join(nopunct)<br/>    # <strong class="lt iu">2. Lemmatisation <br/>    </strong>a=''<br/>    i=0<br/>    for i in range(len(nopunct.split())):<br/>        b=lemmatiser.lemmatize(nopunct.split()[i], pos="v")<br/>        a=a+b+' '<br/>    # <strong class="lt iu">3. Removal of Stopwords<br/>    </strong>return [word for word in a.split() if word.lower() not <br/>            in stopwords.words('english')]</span></pre><p id="b18b" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">三。<strong class="kw iu">类别标签编码:</strong></p><p id="1e7d" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">因为这是一个分类问题，这里的类是上面提到的三个作者。但是在数据集中，可以看到标签是非数字的(MWS、EAP 和 HPL)。这些是标签编码，使其成为数字，从 0 开始，按字母顺序描述每个标签，即(0 → EAP，1 → HPL 和 2 → MWS)</p><pre class="kj kk kl km gt ls lt lu lv aw lw bi"><span id="baef" class="lx ly it lt b gy lz ma l mb mc"># <strong class="lt iu">Importing necessary libraries<br/></strong>from sklearn.preprocessing import LabelEncoder</span><span id="356c" class="lx ly it lt b gy md ma l mb mc">y = df['author']<br/>labelencoder = LabelEncoder()<br/>y = labelencoder.fit_transform(y)</span></pre><p id="e18d" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">四。<strong class="kw iu">字云可视化:</strong></p><p id="915d" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">随着机器学习模型的开发，基于作者在文本中使用特定单词时有自己独特的风格这一事实，在单词云的帮助下，取分别属于 3 个作者的 3 个文本片段，完成 3 个作者最常用的单词到最少使用的单词的可视化。</p><pre class="kj kk kl km gt ls lt lu lv aw lw bi"><span id="22fe" class="lx ly it lt b gy lz ma l mb mc"># <strong class="lt iu">Importing necessary libraries<br/></strong>from PIL import Image<br/>from wordcloud import WordCloud<br/>import matplotlib.pyplot as plt</span><span id="39da" class="lx ly it lt b gy md ma l mb mc">X = df['text']</span><span id="7acd" class="lx ly it lt b gy md ma l mb mc">wordcloud1 = WordCloud().generate(X[0]) # <strong class="lt iu">for EAP</strong><br/>wordcloud2 = WordCloud().generate(X[1]) # <strong class="lt iu">for HPL</strong><br/>wordcloud3 = WordCloud().generate(X[3]) # <strong class="lt iu">for MWS</strong> </span><span id="658b" class="lx ly it lt b gy md ma l mb mc">print(X[0])<br/>print(df['author'][0])<br/>plt.imshow(wordcloud1, interpolation='bilinear')<br/>plt.show()</span><span id="9996" class="lx ly it lt b gy md ma l mb mc">print(X[1])<br/>print(df['author'][1])<br/>plt.imshow(wordcloud2, interpolation='bilinear')<br/>plt.show()</span><span id="b99f" class="lx ly it lt b gy md ma l mb mc">print(X[3])<br/>print(df['author'][3])<br/>plt.imshow(wordcloud3, interpolation='bilinear')<br/>plt.show()</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi my"><img src="../Images/cffe6dfdcdea8daf85b9b93816ab3407.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*rKnoK3ioE1SAUONj9V-wtg.png"/></div></div><figcaption class="mf mg gj gh gi mh mi bd b be z dk"><strong class="bd mj">Word Clouds for the 3 authors taking their text-snippet samples</strong></figcaption></figure><p id="965e" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">动词 （verb 的缩写）<strong class="kw iu">特色工程用词袋:</strong></p><p id="d078" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">机器学习算法只对数字数据有效。但是在这里，数据仅以文本的形式出现。为此，通过某种方式，需要将文本数据转换成数字形式。这样做的一种方法是特征工程。在这种方法中，从文本数据中提取或设计数字特征。存在许多特征工程技术。在这个问题中，使用了特征工程的词袋技术。</p><p id="a876" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">= &gt;词汇袋:</p><p id="2bb9" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">这里，存在于语料库中的词汇被维护。这些单词充当每个实例或文档(这里是文本片段)的特征。针对作为特征的每个单词，考虑其在当前文档(文本片段)中的频率。因此，以这种方式，从文本数据或语料库中设计或提取单词特征。</p><pre class="kj kk kl km gt ls lt lu lv aw lw bi"><span id="76f2" class="lx ly it lt b gy lz ma l mb mc"># <strong class="lt iu">Importing necessary libraries</strong><br/>from sklearn.feature_extraction.text import CountVectorizer<br/>from sklearn.model_selection import train_test_split</span><span id="e0e1" class="lx ly it lt b gy md ma l mb mc"># <strong class="lt iu">80-20 splitting the dataset (80%-&gt;Training and 20%-&gt;Validation)<br/></strong>X_train, X_test, y_train, y_test = train_test_split(X, y<br/>                                  ,test_size=0.2, random_state=1234)</span><span id="ff44" class="lx ly it lt b gy md ma l mb mc"># <strong class="lt iu">defining the bag-of-words transformer on the text-processed corpus </strong>#<strong class="lt iu"> i.e., text_process() declared in II is executed...<br/></strong>bow_transformer=CountVectorizer(analyzer=text_process).fit(X_train)</span><span id="36d2" class="lx ly it lt b gy md ma l mb mc"># <strong class="lt iu">transforming into Bag-of-Words and hence textual data to numeric..</strong><br/>text_bow_train=bow_transformer.transform(X_train)#<strong class="lt iu">ONLY TRAINING DATA</strong></span><span id="1893" class="lx ly it lt b gy md ma l mb mc"># <strong class="lt iu">transforming into Bag-of-Words and hence textual data to numeric..<br/></strong>text_bow_test=bow_transformer.transform(X_test)#<strong class="lt iu">TEST DATA</strong></span></pre><p id="aef9" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">不及物动词<strong class="kw iu">训练模型:</strong></p><p id="3ade" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">多项式朴素贝叶斯算法(分类器)已经被用作分类机器学习算法[1]。</p><pre class="kj kk kl km gt ls lt lu lv aw lw bi"><span id="394c" class="lx ly it lt b gy lz ma l mb mc"># <strong class="lt iu">Importing necessary libraries<br/></strong>from sklearn.naive_bayes import MultinomialNB</span><span id="4a22" class="lx ly it lt b gy md ma l mb mc"># <strong class="lt iu">instantiating the model with Multinomial Naive Bayes..<br/></strong>model = MultinomialNB()</span><span id="83da" class="lx ly it lt b gy md ma l mb mc"># <strong class="lt iu">training the model...<br/></strong>model = model.fit(text_bow_train, y_train)</span></pre><p id="a00d" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">七。<strong class="kw iu">车型性能分析:</strong></p><p id="783e" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">= &gt;训练准确度</p><pre class="kj kk kl km gt ls lt lu lv aw lw bi"><span id="a9e7" class="lx ly it lt b gy lz ma l mb mc">model.score(text_bow_train, y_train)</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi mz"><img src="../Images/65a135ede46b2e1f437a830fdd544c97.png" data-original-src="https://miro.medium.com/v2/resize:fit:742/format:webp/1*wEuK4wW61HKMMFDnk09qAw.png"/></div><figcaption class="mf mg gj gh gi mh mi bd b be z dk"><strong class="bd mj">Training Accuracy</strong></figcaption></figure><p id="5ec7" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">= &gt;验证准确性</p><pre class="kj kk kl km gt ls lt lu lv aw lw bi"><span id="e031" class="lx ly it lt b gy lz ma l mb mc">model.score(text_bow_test, y_test)</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi na"><img src="../Images/b01feb127987c2f5cebfbf5ef0fd8a1b.png" data-original-src="https://miro.medium.com/v2/resize:fit:708/format:webp/1*NGFdCqauKPf-tK42I8aeRQ.png"/></div><figcaption class="mf mg gj gh gi mh mi bd b be z dk"><strong class="bd mj">Test/Validation Accuracy</strong></figcaption></figure><p id="72d1" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">= &gt;精确度、召回率和 F1–分数</p><pre class="kj kk kl km gt ls lt lu lv aw lw bi"><span id="7ce2" class="lx ly it lt b gy lz ma l mb mc"># <strong class="lt iu">Importing necessary libraries<br/></strong>from sklearn.metrics import classification_report<br/> <br/># <strong class="lt iu">getting the predictions of the Validation Set...</strong><br/>predictions = model.predict(text_bow_test)<br/># <strong class="lt iu">getting the Precision, Recall, F1-Score<br/></strong>print(classification_report(y_test,predictions))</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nb"><img src="../Images/84bc689081c13ee255da68c33449d1c2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1052/format:webp/1*AhTri7n5VuO-dCOz0yhJMg.png"/></div><figcaption class="mf mg gj gh gi mh mi bd b be z dk"><strong class="bd mj">Classification Report</strong></figcaption></figure><p id="b689" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">= &gt;混淆矩阵</p><pre class="kj kk kl km gt ls lt lu lv aw lw bi"><span id="3aed" class="lx ly it lt b gy lz ma l mb mc"># <strong class="lt iu">Importing necessary libraries<br/></strong>from sklearn.metrics import confusion_matrix<br/>import numpy as np<br/>import itertools<br/>import matplotlib.pyplot as plt</span><span id="af8e" class="lx ly it lt b gy md ma l mb mc"># <strong class="lt iu">Defining a module for Confusion Matrix...<br/></strong>def plot_confusion_matrix(cm, classes,<br/>                          normalize=False,<br/>                          title='Confusion matrix',<br/>                          cmap=plt.cm.Blues):<br/>    """<br/>    This function prints and plots the confusion matrix.<br/>    Normalization can be applied by setting `normalize=True`.<br/>    """<br/>    if normalize:<br/>        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]<br/>        print("Normalized confusion matrix")<br/>    else:<br/>        print('Confusion matrix, without normalization')</span><span id="02e9" class="lx ly it lt b gy md ma l mb mc">print(cm)</span><span id="6af7" class="lx ly it lt b gy md ma l mb mc">plt.imshow(cm, interpolation='nearest', cmap=cmap)<br/>    plt.title(title)<br/>    plt.colorbar()<br/>    tick_marks = np.arange(len(classes))<br/>    plt.xticks(tick_marks, classes, rotation=45)<br/>    plt.yticks(tick_marks, classes)</span><span id="a94f" class="lx ly it lt b gy md ma l mb mc">fmt = '.2f' if normalize else 'd'<br/>    thresh = cm.max() / 2.<br/>    for i, j in itertools.product(range(cm.shape[0])<br/>                                  , range(cm.shape[1])):<br/>        plt.text(j, i, format(cm[i, j], fmt),<br/>                 horizontalalignment="center",<br/>                 color="white" if cm[i, j] &gt; thresh else "black")</span><span id="279c" class="lx ly it lt b gy md ma l mb mc">plt.tight_layout()<br/>    plt.ylabel('True label')<br/>    plt.xlabel('Predicted label')</span><span id="b784" class="lx ly it lt b gy md ma l mb mc">cm = confusion_matrix(y_test,predictions)<br/>plt.figure()<br/>plot_confusion_matrix(cm, classes=[0,1,2], normalize=True,<br/>                      title='Confusion Matrix')</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nc"><img src="../Images/94c699c3a2e6b1ccf412a4d45a133eeb.png" data-original-src="https://miro.medium.com/v2/resize:fit:864/format:webp/1*eurIfIpTVH9jT4TRxiajMQ.png"/></div><figcaption class="mf mg gj gh gi mh mi bd b be z dk"><strong class="bd mj">Normalized Confusion Matrix</strong></figcaption></figure><p id="5071" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">根据性能分析，可以得出结论，NLP 驱动的机器学习模型已经成功地有效地正确分类了 84.14%的未知(验证集)样本。换句话说，84.14%的文本片段被正确地识别出属于三个作者中的哪一个。</p><p id="97c1" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated"><strong class="kw iu">基于我们的模特表演，能不能得出哪位作者的文笔最独特？</strong></p><p id="fc6b" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">答案是肯定的！！！让我们看看归一化的混淆矩阵。这里标签 2 是最正确的分类。由于标签 2 指的是玛莉·渥斯顿克雷福特·雪莱，因此可以得出结论</p><p id="394b" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">玛莉·渥斯顿克雷福特·雪莱写恐怖小说的风格最独特的是埃德加·爱伦·坡和惠普·洛夫克拉夫特。T3】</p><p id="4155" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">另外，换个角度，<strong class="kw iu">我们能说玛丽·雪莱、埃德加·爱伦·坡和惠普·洛夫克拉夫特谁是最多才多艺的作家吗？</strong></p><p id="ad2d" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">同样，答案是肯定的！！！再次查看混淆矩阵，标签 0 是分类最不正确的。标签 0 指的是埃德加·爱伦·坡，所以可以得出结论</p><p id="ef44" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">埃德加·爱伦·坡比惠普·洛夫克拉夫特和玛丽·雪莱都多才多艺。T9】</p></div><div class="ab cl nd ne hx nf" role="separator"><span class="ng bw bk nh ni nj"/><span class="ng bw bk nh ni nj"/><span class="ng bw bk nh ni"/></div><div class="im in io ip iq"><p id="0b49" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">这样，可以使用机器学习和自然语言处理来开发文本检测模型。</p><p id="41fe" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">使用经过训练的伯努利朴素贝叶斯(而不是多项式朴素贝叶斯)的相关网络应用程序也已经使用 Flask API 在 Heroku 开发和部署。Web 应用程序的链接如下所示:</p><p id="d3ba" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated"><a class="ae lr" href="https://authoridentifier.herokuapp.com/" rel="noopener ugc nofollow" target="_blank">https://authoridentifier.herokuapp.com/</a></p><p id="6b71" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated"><strong class="kw iu">参考文献</strong></p><p id="673e" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">[1]<a class="ae lr" rel="noopener" target="_blank" href="/multinomial-naive-bayes-classifier-for-text-analysis-python-8dd6825ece67">https://towards data science . com/multinomial-naive-Bayes-classifier-for-text-analysis-python-8dd 6825 ECE 67</a></p></div></div>    
</body>
</html>