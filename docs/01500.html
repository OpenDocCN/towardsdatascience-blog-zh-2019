<html>
<head>
<title>Machine Learning Classifier evaluation using ROC and CAP Curves</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用 ROC 和 CAP 曲线的机器学习分类器评估</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/machine-learning-classifier-evaluation-using-roc-and-cap-curves-7db60fe6b716?source=collection_archive---------2-----------------------#2019-03-10">https://towardsdatascience.com/machine-learning-classifier-evaluation-using-roc-and-cap-curves-7db60fe6b716?source=collection_archive---------2-----------------------#2019-03-10</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><figure class="gl gn jo jp jq jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi jn"><img src="../Images/edd6a99566f0a69145c8abb3d7883b7f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*R315pYPEvPVMaS6l"/></div></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk">Photo by <a class="ae kc" href="https://unsplash.com/@isaacmsmith?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Isaac Smith</a> on <a class="ae kc" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><p id="d62c" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">虽然有几个度量标准，如准确性和召回率，来衡量机器学习模型的性能，但 ROC 曲线和 CAP 曲线非常适合分类问题。在本文中，我将探讨什么是 ROC 和 CAP，以及我们如何使用 Python 和虚拟数据集来创建这些曲线。</p><blockquote class="lb lc ld"><p id="c573" class="kd ke le kf b kg kh ki kj kk kl km kn lf kp kq kr lg kt ku kv lh kx ky kz la ij bi translated"><em class="iq">即使在探索了许多关于 CAP Curve 的文章后，我也找不到一篇详细解释如何创建它们的文章，这就是我写这篇文章的原因。</em></p></blockquote><p id="56e5" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">完整的代码被上传到下面的 GitHub 库。</p><div class="li lj gp gr lk ll"><a href="https://github.com/kb22/ML-Performance-Evaluation" rel="noopener  ugc nofollow" target="_blank"><div class="lm ab fo"><div class="ln ab lo cl cj lp"><h2 class="bd ir gy z fp lq fr fs lr fu fw ip bi translated">kb22/ML-性能评估</h2><div class="ls l"><h3 class="bd b gy z fp lq fr fs lr fu fw dk translated">在这个知识库中，我讨论了各种机器学习模型的性能评估指标。…</h3></div><div class="lt l"><p class="bd b dl z fp lq fr fs lr fu fw dk translated">github.com</p></div></div><div class="lu l"><div class="lv l lw lx ly lu lz jw ll"/></div></div></a></div><h1 id="5e3b" class="ma mb iq bd mc md me mf mg mh mi mj mk ml mm mn mo mp mq mr ms mt mu mv mw mx bi translated">资料组</h1><p id="f664" class="pw-post-body-paragraph kd ke iq kf b kg my ki kj kk mz km kn ko na kq kr ks nb ku kv kw nc ky kz la ij bi translated">我创建了自己的数据集。有两个特性，<code class="fe nd ne nf ng b">age</code>和<code class="fe nd ne nf ng b">experience</code>。基于这两个特征，输出标签为<code class="fe nd ne nf ng b">0.0</code>表示工资低于 20 万美元，而<code class="fe nd ne nf ng b">1.0</code>表示工资高于或等于 20 万美元。</p><figure class="ni nj nk nl gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi nh"><img src="../Images/016809b2b79522f662e45cfbdc0f9f7d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*NlFWhfTI2vVdz86RnmD_9g.png"/></div></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk">Complete dataset</figcaption></figure><p id="893d" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><code class="fe nd ne nf ng b">GREEN</code>点数代表超过或等于 20 万美元的薪资，而<code class="fe nd ne nf ng b">RED</code>点数代表低于 20 万美元的薪资。我还确保了这两个类之间有一些重叠，所以数据更真实一些，不容易分离。</p><h1 id="24c7" class="ma mb iq bd mc md me mf mg mh mi mj mk ml mm mn mo mp mq mr ms mt mu mv mw mx bi translated">分类</h1><p id="75e0" class="pw-post-body-paragraph kd ke iq kf b kg my ki kj kk mz km kn ko na kq kr ks nb ku kv kw nc ky kz la ij bi translated">首先，我将数据分成两组，70%的训练数据和 30%的测试数据。我用<code class="fe nd ne nf ng b">Support Vector Classifier</code>和<code class="fe nd ne nf ng b">linear kernel</code>对训练数据进行训练，然后在测试数据上测试模型。该模型取得了 95% 的<strong class="kf ir">评分。</strong></p><figure class="ni nj nk nl gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi nm"><img src="../Images/672a3762fb13d9bab3aa342642224aff.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*1zGjdyyIBmtj6IZfHy7yyA.png"/></div></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk">Classification on Test data</figcaption></figure><h1 id="143b" class="ma mb iq bd mc md me mf mg mh mi mj mk ml mm mn mo mp mq mr ms mt mu mv mw mx bi translated">性能赋值</h1><h2 id="0c60" class="nn mb iq bd mc no np dn mg nq nr dp mk ko ns nt mo ks nu nv ms kw nw nx mw ny bi translated">受试者工作特性曲线</h2><p id="e7ec" class="pw-post-body-paragraph kd ke iq kf b kg my ki kj kk mz km kn ko na kq kr ks nb ku kv kw nc ky kz la ij bi translated">接收器操作特性曲线，更好地称为<strong class="kf ir"> ROC 曲线，</strong>是测量分类模型性能的极好方法。针对分类器预测的概率，将<strong class="kf ir">真阳性率(TPR) </strong>与<strong class="kf ir">假阳性率(FPR) </strong>作图。然后，计算地块下的面积。</p><blockquote class="nz"><p id="69f7" class="oa ob iq bd oc od oe of og oh oi la dk translated">曲线下的面积越大，模型区分类别的能力就越强。</p></blockquote><p id="237b" class="pw-post-body-paragraph kd ke iq kf b kg oj ki kj kk ok km kn ko ol kq kr ks om ku kv kw on ky kz la ij bi translated"><strong class="kf ir">导入文件并创建基线<br/> </strong>首先，我从<code class="fe nd ne nf ng b">sklearn.metrics</code>导入<code class="fe nd ne nf ng b">roc_curve</code>和<code class="fe nd ne nf ng b">auc</code>，这样我可以创建 ROC 曲线并计算曲线下的面积。我还将图形大小定义为 20x12，并创建一条从<code class="fe nd ne nf ng b">(0,0)</code>到<code class="fe nd ne nf ng b">(1,1)</code>的基线。</p><figure class="ni nj nk nl gt jr"><div class="bz fp l di"><div class="oo op l"/></div></figure><p id="24b0" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">值<code class="fe nd ne nf ng b">r--</code>表示线条颜色为红色，是一条虚线(<code class="fe nd ne nf ng b">— — — — — — — — — — — — —</code>)。</p><p id="e63b" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kf ir">计算概率并确定 TPR 和 FPR <br/> </strong>接下来，使用<code class="fe nd ne nf ng b">predict_proba</code>我计算预测的概率并将其存储在<code class="fe nd ne nf ng b">probs</code>中。它由两列组成，第一列包括第一类的概率(薪金&lt; $20 万)，第二列包括第二类的概率(薪金≥ $20 万)。所以，我用<code class="fe nd ne nf ng b">probs[:, 1]</code>选择第二类的概率。</p><figure class="ni nj nk nl gt jr"><div class="bz fp l di"><div class="oo op l"/></div></figure><p id="c301" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><code class="fe nd ne nf ng b">roc_curve</code>生成 roc 曲线并返回<code class="fe nd ne nf ng b">fpr</code>、<code class="fe nd ne nf ng b">tpr</code>和<code class="fe nd ne nf ng b">thresholds</code>。最后，使用<code class="fe nd ne nf ng b">fpr</code>和<code class="fe nd ne nf ng b">tpr</code>作为<code class="fe nd ne nf ng b">auc</code>中的输入，我计算出该模型曲线下的面积，并将其保存在<code class="fe nd ne nf ng b">roc_auc</code>中。<code class="fe nd ne nf ng b">roc_auc</code>现在有了我们的支持向量分类器生成的曲线下的面积。</p><p id="9722" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kf ir">绘制 ROC 曲线<br/> </strong>我使用<code class="fe nd ne nf ng b">fpr</code>作为 x 值和<code class="fe nd ne nf ng b">tpr</code>作为 y 值绘制曲线，颜色为绿色，线宽为 4。这条曲线的标签包括曲线下的区域。x 轴标签设置为<code class="fe nd ne nf ng b">False Positive Rate</code>，y 轴标签设置为<code class="fe nd ne nf ng b">True Positive Rate</code>。标题为<code class="fe nd ne nf ng b">Receiver Operating Characteristic</code>，图例出现在图的右下角。文本大小设置为 16。</p><figure class="ni nj nk nl gt jr"><div class="bz fp l di"><div class="oo op l"/></div></figure><figure class="ni nj nk nl gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi oq"><img src="../Images/6993eeb8597b61ab12b94e80c0ad3b73.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*vJK5zW93JtZmBtkZ9-M1qA.png"/></div></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk">ROC Curve</figcaption></figure><p id="fb31" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">曲线下面积为 0.98，这真是令人惊讶，提供了我们的模型表现良好的信息。</p><h2 id="9f1e" class="nn mb iq bd mc no np dn mg nq nr dp mk ko ns nt mo ks nu nv ms kw nw nx mw ny bi translated">累积精度曲线</h2><p id="aad6" class="pw-post-body-paragraph kd ke iq kf b kg my ki kj kk mz km kn ko na kq kr ks nb ku kv kw nc ky kz la ij bi translated">CAP 曲线试图分析如何使用最少的尝试次数有效地识别给定类别的所有数据点。在这个数据集中，我试图确定<code class="fe nd ne nf ng b">Support Vector Classifier</code>能够多快地识别出所有工资高于或等于 20 万美元的个人。</p><p id="f2e2" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kf ir">计算每个类的计数<br/> </strong>首先，我在测试数据(60)中找到总的数据点，并保存在变量<code class="fe nd ne nf ng b">total</code>中。测试标签要么是<code class="fe nd ne nf ng b">0.0</code>要么是<code class="fe nd ne nf ng b">1.0</code>，所以如果我把所有的值加起来，我将得到类<code class="fe nd ne nf ng b">1.0</code> (31)的计数，我可以把它保存在<code class="fe nd ne nf ng b">class_1_count</code>中。从<code class="fe nd ne nf ng b">total</code>中减去这个数将得到<code class="fe nd ne nf ng b">class_0_count</code> (29)。</p><figure class="ni nj nk nl gt jr"><div class="bz fp l di"><div class="oo op l"/></div></figure><p id="883d" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我还将图形尺寸设置为 20x12，使其比正常尺寸大。</p><p id="6d92" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kf ir">随机模型<br/> </strong>首先，我们绘制一个随机模型，该随机模型基于类别<code class="fe nd ne nf ng b">1.0</code>的正确检测将线性增长的事实。</p><figure class="ni nj nk nl gt jr"><div class="bz fp l di"><div class="oo op l"/></div></figure><p id="50a3" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">颜色为<code class="fe nd ne nf ng b">red</code>，样式为使用<code class="fe nd ne nf ng b">--</code>定义的<code class="fe nd ne nf ng b">dashed</code>。我已经将标签设置为<code class="fe nd ne nf ng b">Random Model</code>。</p><figure class="ni nj nk nl gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi or"><img src="../Images/4aa57e0ec0c827565ca9369bf81fff7e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*GqyENkRVTPz53P5fCm-RaA.png"/></div></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk">Random Model</figcaption></figure><p id="b1b9" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kf ir">完美模型</strong> <br/>接下来，我绘制完美模型。一个完美的模型将在与类别<code class="fe nd ne nf ng b">1.0</code>数据点相同的尝试次数中检测所有类别<code class="fe nd ne nf ng b">1.0</code>数据点。完美模型需要 31 次尝试来识别 31 类<code class="fe nd ne nf ng b">1.0</code>数据点。</p><p id="36e0" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我把这块地涂成灰色。标签设置为<code class="fe nd ne nf ng b">Perfect Model</code>。</p><figure class="ni nj nk nl gt jr"><div class="bz fp l di"><div class="oo op l"/></div></figure><figure class="ni nj nk nl gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi os"><img src="../Images/adf76ebe87d402821026d13a91283a7f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*OWOUneca-kQv4-ti3wmi4Q.png"/></div></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk">Perfect Model</figcaption></figure><p id="d314" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kf ir">经过训练的模型(支持向量分类器)</strong> <br/>最后，我绘制出<code class="fe nd ne nf ng b">Support Vector Classifier</code>的结果。首先，像在 ROC 曲线中一样，我提取变量<code class="fe nd ne nf ng b">probs</code>中类<code class="fe nd ne nf ng b">1.0</code>的概率。</p><figure class="ni nj nk nl gt jr"><div class="bz fp l di"><div class="oo op l"/></div></figure><p id="0596" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我把<code class="fe nd ne nf ng b">probs</code>和<code class="fe nd ne nf ng b">y_test</code>拉上拉链。然后，我按照概率的逆序对这个 zip 文件进行排序，最大概率排在最前面，然后是较小的概率。我只提取数组中的<code class="fe nd ne nf ng b">y_test</code>值，并将其存储在<code class="fe nd ne nf ng b">model_y</code>中。</p><p id="d67b" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><code class="fe nd ne nf ng b">np.cumsum()</code>创建一个值数组，同时将数组中所有以前的值累加到当前值中。例如，如果我们有一个数组<code class="fe nd ne nf ng b">[1, 1, 1, 1, 1]</code>。应用<code class="fe nd ne nf ng b">cumsum</code>将导致<code class="fe nd ne nf ng b">[1, 2, 3, 4, 5]</code>。我用它来计算 y 值。此外，我们需要在数组前面追加<code class="fe nd ne nf ng b">0</code>作为起始点<code class="fe nd ne nf ng b">(0,0)</code>。x 值的范围从<code class="fe nd ne nf ng b">0</code>到<code class="fe nd ne nf ng b">total + 1</code>。我添加一个，因为<code class="fe nd ne nf ng b">np.arange()</code>不包括终点，我希望终点是<code class="fe nd ne nf ng b">total</code>。</p><figure class="ni nj nk nl gt jr"><div class="bz fp l di"><div class="oo op l"/></div></figure><p id="055c" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">然后我用蓝色标出结果，并标上<code class="fe nd ne nf ng b">Support Vector Classifier</code>。我还将另外两个模型包含在情节中。</p><figure class="ni nj nk nl gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi ot"><img src="../Images/1cc5fe250442d821956b3ba36ca48db0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*k0u2t82ICAZQklzDfw4z1w.png"/></div></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk">Support Vector Classifier</figcaption></figure><p id="019c" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kf ir">使用曲线下面积<br/>的 CAP 分析</strong>分析 CAP 曲线的第一种方法是使用<strong class="kf ir">曲线下面积</strong>。让我们考虑随机模型下的面积为<code class="fe nd ne nf ng b">a</code>。我们使用以下步骤计算准确率:</p><ol class=""><li id="e47b" class="ou ov iq kf b kg kh kk kl ko ow ks ox kw oy la oz pa pb pc bi translated">计算完美模型(<code class="fe nd ne nf ng b">aP</code>)到随机模型(<code class="fe nd ne nf ng b">a</code>)下的面积</li><li id="ff13" class="ou ov iq kf b kg pd kk pe ko pf ks pg kw ph la oz pa pb pc bi translated">计算预测模型(<code class="fe nd ne nf ng b">aR</code>)到随机模型(<code class="fe nd ne nf ng b">a</code>)下的面积</li><li id="56f5" class="ou ov iq kf b kg pd kk pe ko pf ks pg kw ph la oz pa pb pc bi translated">计算准确率(<code class="fe nd ne nf ng b">AR</code> ) = aR / aP</li></ol><p id="e800" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">准确率越接近 1，模型越好。</p><figure class="ni nj nk nl gt jr"><div class="bz fp l di"><div class="oo op l"/></div></figure><p id="79dc" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">使用<code class="fe nd ne nf ng b">auc</code>，我计算了所有面积，然后使用这些值计算了准确率。该比率约为 0.97，非常接近于 1，表明我们的模型非常有效。</p><p id="7083" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kf ir">使用图进行 CAP 分析<br/> </strong>另一种分析 CAP 曲线的方法是读取我们上面生成的图。相同的步骤如下:</p><ol class=""><li id="b8fa" class="ou ov iq kf b kg kh kk kl ko ow ks ox kw oy la oz pa pb pc bi translated">从 x 轴的 50%处画一条垂直线，直到它穿过<code class="fe nd ne nf ng b">Support Vector Classifier</code>图。</li><li id="161b" class="ou ov iq kf b kg pd kk pe ko pf ks pg kw ph la oz pa pb pc bi translated">在垂直线与训练模型相交的点上，画一条水平线，使其与 y 轴相交。</li><li id="9c96" class="ou ov iq kf b kg pd kk pe ko pf ks pg kw ph la oz pa pb pc bi translated">计算 1 类标签占 1 类标签总数的百分比。</li></ol><p id="5dd3" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">一旦我们知道了百分比，我们就可以用下面的括号来分析它。低于 60%:垃圾型号<br/> 2。60% — 70%:差模<br/> 3。70% — 80%:好型号<br/> 4。80% — 90%:非常好的型号<br/> 5。超过 90%:好得难以置信<br/>请注意，如果该值超过 90%，测试过度拟合是一个很好的做法。</p><figure class="ni nj nk nl gt jr"><div class="bz fp l di"><div class="oo op l"/></div></figure><p id="9deb" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">首先，我通过计算总测试数据的 50%的 int 值来找到索引。我用它来画一条从这个点到训练好的模型的垂直虚线(<code class="fe nd ne nf ng b">— — —</code>)。接下来，我画出从这个交点到 y 轴的直线。我通过将目前观察到的类<code class="fe nd ne nf ng b">1.0</code>值除以总的类<code class="fe nd ne nf ng b">1.0</code>数据点并乘以 100 来确定百分比。我得到的值为<strong class="kf ir"> 93.55% </strong>。</p><figure class="ni nj nk nl gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi pi"><img src="../Images/b078ca57c6e128820090069c7078991d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*hYWGGOMQpDi8aZT9JRhpYQ.png"/></div></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk">CAP Curve Analysis</figcaption></figure><p id="edf4" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">尽管百分比是 93.55%，大于 90%，但结果是预期的。正如我们在开始时看到的数据集和分类，该模型在拆分数据方面非常有效。虽然我对测试数据使用了 CAP 分析，但我们也可以对训练数据使用同样的方法，并分析我们的模型对训练数据的了解程度。</p><h1 id="a547" class="ma mb iq bd mc md me mf mg mh mi mj mk ml mm mn mo mp mq mr ms mt mu mv mw mx bi translated">结论</h1><p id="8d9b" class="pw-post-body-paragraph kd ke iq kf b kg my ki kj kk mz km kn ko na kq kr ks nb ku kv kw nc ky kz la ij bi translated">本文总结了如何用 Python 计算 ROC 曲线和 CAP 曲线，以及如何对它们进行分析。</p></div><div class="ab cl pj pk hu pl" role="separator"><span class="pm bw bk pn po pp"/><span class="pm bw bk pn po pp"/><span class="pm bw bk pn po"/></div><div class="ij ik il im in"><p id="df5c" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">请随时分享你的想法和想法。与 ROC 和 CAP 一起工作对我来说也是全新的，所以请分享我可能错过的任何信息。感谢阅读！</p></div></div>    
</body>
</html>