<html>
<head>
<title>Simple Linear Regression in Python</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">Python 中的简单线性回归</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/simple-linear-regression-in-python-8cf596ac6a7c?source=collection_archive---------11-----------------------#2019-09-03">https://towardsdatascience.com/simple-linear-regression-in-python-8cf596ac6a7c?source=collection_archive---------11-----------------------#2019-09-03</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="72cc" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">一个带有简化解释的机器学习模型…</h2></div><figure class="ki kj kk kl gt km"><div class="bz fp l di"><div class="kn ko l"/></div><figcaption class="kp kq gj gh gi kr ks bd b be z dk">Video version of the story, if you are into that sort of thing | Performed by the author</figcaption></figure><p id="6357" class="pw-post-body-paragraph kt ku it kv b kw kx ju ky kz la jx lb lc ld le lf lg lh li lj lk ll lm ln lo im bi lp translated">简单线性回归是一种寻找两个连续变量之间关系的统计方法。在现有的两个变量中，一个是自变量，另一个是因变量。统计关系在确定两个变量之间的关系时不准确。比如身高和体重的关系。</p><p id="a65a" class="pw-post-body-paragraph kt ku it kv b kw kx ju ky kz la jx lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">这种关系是由著名的线方程定义的，你们在高中应该学过。</p><blockquote class="ly"><p id="542a" class="lz ma it bd mb mc md me mf mg mh lo dk translated"><strong class="ak"> <em class="mi"> y = b0 + b1*x </em> </strong></p></blockquote><p id="7372" class="pw-post-body-paragraph kt ku it kv b kw mj ju ky kz mk jx lb lc ml le lf lg mm li lj lk mn lm ln lo im bi translated">在哪里，</p><p id="5fcd" class="pw-post-body-paragraph kt ku it kv b kw kx ju ky kz la jx lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated"><em class="mo"> y </em>是因变量</p><p id="c732" class="pw-post-body-paragraph kt ku it kv b kw kx ju ky kz la jx lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated"><em class="mo"> x </em>是自变量</p><p id="74fb" class="pw-post-body-paragraph kt ku it kv b kw kx ju ky kz la jx lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated"><em class="mo"> b0 </em>是关系的基值</p><p id="137f" class="pw-post-body-paragraph kt ku it kv b kw kx ju ky kz la jx lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated"><em class="mo"> b1 </em>是解释<em class="mo"> y &amp; x. </em>关系的直线的斜率</p><p id="144b" class="pw-post-body-paragraph kt ku it kv b kw kx ju ky kz la jx lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">例如，y 指的是一个人的工资如何随着他所拥有的经验年限而变化。因此，在这种情况下，工资将是因变量，经验将是自变量，基本价值将是一个没有经验的人的工资。在我们的代码示例中，我们将处理这样的数据集。</p><p id="3829" class="pw-post-body-paragraph kt ku it kv b kw kx ju ky kz la jx lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">为了确定什么是最佳拟合线，让我们看看下面的曲线。</p><figure class="ki kj kk kl gt km gh gi paragraph-image"><div role="button" tabindex="0" class="mq mr di ms bf mt"><div class="gh gi mp"><img src="../Images/5021c7bf45f6ddec6efb8c1e237690d0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*MzKbePYWng2z1LI9wL9hmw.png"/></div></div></figure><p id="e7b5" class="pw-post-body-paragraph kt ku it kv b kw kx ju ky kz la jx lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">带有红叉的点是实际或真实的数据点，而带有绿叉的点是回归模型的预测值。这里的目标是建立这样一个回归模型，使得误差平方和最小。</p></div><div class="ab cl mw mx hx my" role="separator"><span class="mz bw bk na nb nc"/><span class="mz bw bk na nb nc"/><span class="mz bw bk na nb"/></div><div class="im in io ip iq"><blockquote class="nd ne nf"><p id="9e5c" class="kt ku mo kv b kw kx ju ky kz la jx lb ng ld le lf nh lh li lj ni ll lm ln lo im bi translated">I <strong class="kv iu">导入数据集并进行数据预处理</strong></p></blockquote><p id="a02f" class="pw-post-body-paragraph kt ku it kv b kw kx ju ky kz la jx lb lc ld le lf lg lh li lj lk ll lm ln lo im bi lp translated">今天，我们进入代码的数据集。我们有一个业务问题，一家公司希望在员工的工资和他们的经验之间建立一种关系。我们将使用简单的线性回归来研究这种相关性。</p><p id="a400" class="pw-post-body-paragraph kt ku it kv b kw kx ju ky kz la jx lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">简单的线性回归会告诉我们这种关系的最佳拟合线是什么。让我们来看看数据集。你可以点击下载<a class="ae nj" href="https://github.com/tarunlnmiit/machine_learning/blob/master/SimpleLinearRegression.csv" rel="noopener ugc nofollow" target="_blank">数据集。</a></p><figure class="ki kj kk kl gt km gh gi paragraph-image"><div role="button" tabindex="0" class="mq mr di ms bf mt"><div class="gh gi nk"><img src="../Images/5265fe3be59d0f838145b820f0347c7a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ke0lcYGNdg3k7FGtedWJdw.png"/></div></div></figure><p id="b593" class="pw-post-body-paragraph kt ku it kv b kw kx ju ky kz la jx lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">我们的数据由总共 30 个对象和两个属性组成，<strong class="kv iu"> <em class="mo">年经历</em> </strong>和<strong class="kv iu"> <em class="mo">薪水</em> </strong>。属性<strong class="kv iu"><em class="mo">years experience</em></strong>是独立属性，属性<strong class="kv iu"> <em class="mo"> Salary </em> </strong>是从属属性。</p></div><div class="ab cl mw mx hx my" role="separator"><span class="mz bw bk na nb nc"/><span class="mz bw bk na nb nc"/><span class="mz bw bk na nb"/></div><div class="im in io ip iq"><p id="d4ca" class="pw-post-body-paragraph kt ku it kv b kw kx ju ky kz la jx lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">我将使用<strong class="kv iu"> Spyder </strong>来编写这个机器学习模型。在进入模型的回归部分之前，我们需要对数据集执行<a class="ae nj" rel="noopener" target="_blank" href="/data-preprocessing-in-python-b52b652e37d5">数据预处理</a>。我将直接为其编写代码，但是如果您想了解更多，请访问下面的文章。</p><p id="5acb" class="pw-post-body-paragraph kt ku it kv b kw kx ju ky kz la jx lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">概念性数据预处理文章:</p><div class="nl nm gp gr nn no"><a rel="noopener follow" target="_blank" href="/data-preprocessing-in-data-mining-machine-learning-79a9662e2eb"><div class="np ab fo"><div class="nq ab nr cl cj ns"><h2 class="bd iu gy z fp nt fr fs nu fu fw is bi translated">数据挖掘和机器学习中的数据预处理</h2><div class="nv l"><h3 class="bd b gy z fp nt fr fs nu fu fw dk translated">有了详细的概念…</h3></div><div class="nw l"><p class="bd b dl z fp nt fr fs nu fu fw dk translated">towardsdatascience.com</p></div></div><div class="nx l"><div class="ny l nz oa ob nx oc mu no"/></div></div></a></div><p id="5310" class="pw-post-body-paragraph kt ku it kv b kw kx ju ky kz la jx lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">编程数据预处理文章:</p><div class="nl nm gp gr nn no"><a rel="noopener follow" target="_blank" href="/data-preprocessing-in-python-b52b652e37d5"><div class="np ab fo"><div class="nq ab nr cl cj ns"><h2 class="bd iu gy z fp nt fr fs nu fu fw is bi translated">Python 中的数据预处理</h2><div class="nv l"><h3 class="bd b gy z fp nt fr fs nu fu fw dk translated">对于机器学习与工作代码的例子…</h3></div><div class="nw l"><p class="bd b dl z fp nt fr fs nu fu fw dk translated">towardsdatascience.com</p></div></div><div class="nx l"><div class="ny l nz oa ob nx oc mu no"/></div></div></a></div><pre class="ki kj kk kl gt od oe of og aw oh bi"><span id="1fcc" class="oi oj it oe b gy ok ol l om on"># Importing the libraries<br/>import numpy as np<br/>import matplotlib.pyplot as plt<br/>import pandas as pd</span><span id="4ee0" class="oi oj it oe b gy oo ol l om on"># Importing the dataset<br/>dataset = pd.read_csv('SimpleLinearRegression.csv')<br/>X = dataset.iloc[:, :-1].values<br/>y = dataset.iloc[:, -1].values</span><span id="2a32" class="oi oj it oe b gy oo ol l om on"># Splitting the dataset into the Training set and Test set<br/>from sklearn.model_selection import train_test_split<br/>X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 1/3, random_state = 0)</span></pre><p id="b30e" class="pw-post-body-paragraph kt ku it kv b kw kx ju ky kz la jx lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">执行完这段代码后，我们将训练集和测试集分别与独立属性和从属属性的数组和向量分开。它们应该是这样的:</p><figure class="ki kj kk kl gt km gh gi paragraph-image"><div role="button" tabindex="0" class="mq mr di ms bf mt"><div class="gh gi op"><img src="../Images/f9cf387aee0521d9624c36c0aab73163.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*RBSttoKl3dB4ovIJuTP74g.png"/></div></div></figure><figure class="ki kj kk kl gt km gh gi paragraph-image"><div role="button" tabindex="0" class="mq mr di ms bf mt"><div class="gh gi oq"><img src="../Images/bbc859163c6af3df98f7178a08b8ca8f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*XhHgKjVLuHz7tQt5zSHZSg.png"/></div></div></figure></div><div class="ab cl mw mx hx my" role="separator"><span class="mz bw bk na nb nc"/><span class="mz bw bk na nb nc"/><span class="mz bw bk na nb"/></div><div class="im in io ip iq"><blockquote class="nd ne nf"><p id="526c" class="kt ku mo kv b kw kx ju ky kz la jx lb ng ld le lf nh lh li lj ni ll lm ln lo im bi translated"><strong class="kv iu">将数据集拟合到简单的线性回归模型中</strong></p></blockquote><p id="e242" class="pw-post-body-paragraph kt ku it kv b kw kx ju ky kz la jx lb lc ld le lf lg lh li lj lk ll lm ln lo im bi lp translated"><span class="l lq lr ls bm lt lu lv lw lx di">在</span>中，为了使数据适合我们的回归模型，我们需要导入一个库，调用回归方法，并使我们的训练数据适合该回归模型。我们的做法如下:</p><pre class="ki kj kk kl gt od oe of og aw oh bi"><span id="1107" class="oi oj it oe b gy ok ol l om on"># Fitting Simple Linear Regression to the Training set<br/>from sklearn.linear_model import LinearRegression<br/>regressor = LinearRegression()<br/>regressor.fit(X_train, y_train)</span></pre><p id="0856" class="pw-post-body-paragraph kt ku it kv b kw kx ju ky kz la jx lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">由于我们的机器学习模型已经知道了我们的训练集的相关性，我们现在将预测我们的测试集的值，然后稍后将它们与测试集的实际值进行比较。</p><p id="e42b" class="pw-post-body-paragraph kt ku it kv b kw kx ju ky kz la jx lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">为了预测测试集的值，我们需要编写以下代码:</p><pre class="ki kj kk kl gt od oe of og aw oh bi"><span id="e530" class="oi oj it oe b gy ok ol l om on"># Predicting the Test set results<br/>y_pred = regressor.predict(X_test)</span></pre><p id="db5c" class="pw-post-body-paragraph kt ku it kv b kw kx ju ky kz la jx lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">在执行完代码之后，我们可以手动查看预测的测试集值和实际的测试集值，看看它们有什么不同。</p><figure class="ki kj kk kl gt km gh gi paragraph-image"><div role="button" tabindex="0" class="mq mr di ms bf mt"><div class="gh gi or"><img src="../Images/0f99267efc9584dab5e07d8b752d586b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*VWhIX-LzouIVj3mGvEPILQ.png"/></div></div></figure><p id="40b1" class="pw-post-body-paragraph kt ku it kv b kw kx ju ky kz la jx lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">如您所见，这些值互不相同。一些具有非常低的差异，如第 4 个条目，而一些具有稍高的差异，如第 8 个条目。</p></div><div class="ab cl mw mx hx my" role="separator"><span class="mz bw bk na nb nc"/><span class="mz bw bk na nb nc"/><span class="mz bw bk na nb"/></div><div class="im in io ip iq"><blockquote class="nd ne nf"><p id="42ff" class="kt ku mo kv b kw kx ju ky kz la jx lb ng ld le lf nh lh li lj ni ll lm ln lo im bi translated"><strong class="kv iu">可视化数据集中的相关性</strong></p></blockquote><p id="ea57" class="pw-post-body-paragraph kt ku it kv b kw kx ju ky kz la jx lb lc ld le lf lg lh li lj lk ll lm ln lo im bi lp translated"><span class="l lq lr ls bm lt lu lv lw lx di">在</span>中，为了判断数据之间的实际相关性，我们将绘制两条曲线。</p><ul class=""><li id="1c68" class="os ot it kv b kw kx kz la lc ou lg ov lk ow lo ox oy oz pa bi translated">可视化训练集结果</li></ul><p id="eda2" class="pw-post-body-paragraph kt ku it kv b kw kx ju ky kz la jx lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">我们使用以下代码来实现这一点:</p><pre class="ki kj kk kl gt od oe of og aw oh bi"><span id="1e61" class="oi oj it oe b gy ok ol l om on"># Visualising the Training set results<br/>plt.scatter(X_train, y_train, color = 'red')<br/>plt.plot(X_train, regressor.predict(X_train), color = 'blue')<br/>plt.title('Salary vs Experience (Training set)')<br/>plt.xlabel('Years of Experience')<br/>plt.ylabel('Salary')<br/>plt.show()</span></pre><figure class="ki kj kk kl gt km gh gi paragraph-image"><div role="button" tabindex="0" class="mq mr di ms bf mt"><div class="gh gi pb"><img src="../Images/439e3a81a763c81d4a2043dd72e591e9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*2ZxJ2-oXXpYB3F9rlz5whg.png"/></div></div></figure><p id="6b4d" class="pw-post-body-paragraph kt ku it kv b kw kx ju ky kz la jx lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">可以看出，这里的线并没有那么差，因为只有几个点离它很远，大多数点都在线的周围。</p><ul class=""><li id="1015" class="os ot it kv b kw kx kz la lc ou lg ov lk ow lo ox oy oz pa bi translated">可视化测试集结果</li></ul><p id="9a26" class="pw-post-body-paragraph kt ku it kv b kw kx ju ky kz la jx lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">我们使用以下代码来实现这一点:</p><pre class="ki kj kk kl gt od oe of og aw oh bi"><span id="0ae8" class="oi oj it oe b gy ok ol l om on"># Visualising the Test set results<br/>plt.scatter(X_test, y_test, color = 'red')<br/>plt.plot(X_train, regressor.predict(X_train), color = 'blue')<br/>plt.title('Salary vs Experience (Test set)')<br/>plt.xlabel('Years of Experience')<br/>plt.ylabel('Salary')<br/>plt.show()</span></pre><p id="3ed4" class="pw-post-body-paragraph kt ku it kv b kw kx ju ky kz la jx lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">这里，关于为什么在<code class="fe pc pd pe oe b">plt.plot(X_train, regressor.predict(X_train), color = 'blue')</code>到<code class="fe pc pd pe oe b">X_test</code>中<code class="fe pc pd pe oe b">regressor.predict()</code>的参数没有被改变，可能存在混淆。这是因为，如果我们这样做，我们将得到一个新的行，但我们希望将我们的测试集与我们从训练集中得到的行进行比较。曲线看起来会像这样:</p><figure class="ki kj kk kl gt km gh gi paragraph-image"><div role="button" tabindex="0" class="mq mr di ms bf mt"><div class="gh gi pf"><img src="../Images/2c2741b2ea253f7364a6f9d9b51691f9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*w_Jd8zpUVEDOayCXT1c3VA.png"/></div></div></figure><p id="8e5e" class="pw-post-body-paragraph kt ku it kv b kw kx ju ky kz la jx lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">这里可以看到，10 个数据点中有 5 个数据点位于直线上。10 分中有 3 分非常接近终点线，10 分中只有 2 分稍微远一点。</p><p id="7c8b" class="pw-post-body-paragraph kt ku it kv b kw kx ju ky kz la jx lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">这篇关于 Python 中用于机器学习建模的简单线性回归的文章到此结束。</p></div><div class="ab cl mw mx hx my" role="separator"><span class="mz bw bk na nb nc"/><span class="mz bw bk na nb nc"/><span class="mz bw bk na nb"/></div><div class="im in io ip iq"><p id="5042" class="pw-post-body-paragraph kt ku it kv b kw kx ju ky kz la jx lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">我将免费赠送一本关于一致性的电子书。在这里获得你的免费电子书。</p></div><div class="ab cl mw mx hx my" role="separator"><span class="mz bw bk na nb nc"/><span class="mz bw bk na nb nc"/><span class="mz bw bk na nb"/></div><div class="im in io ip iq"><p id="8cdb" class="pw-post-body-paragraph kt ku it kv b kw kx ju ky kz la jx lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">如果你喜欢阅读这样的故事，那么你应该<a class="ae nj" href="https://tarun-gupta.medium.com/subscribe" rel="noopener"> <strong class="kv iu">在你的收件箱</strong> </a>中收到我的帖子，如果你想支持我成为一名作家，考虑<a class="ae nj" href="https://tarun-gupta.medium.com/membership" rel="noopener">注册成为一名媒体成员</a>。每月 5 美元，你可以无限制地阅读媒体上的故事。如果你注册使用我的链接，我会赚一小笔佣金，不需要你额外付费。</p><div class="nl nm gp gr nn no"><a href="https://tarun-gupta.medium.com/membership" rel="noopener follow" target="_blank"><div class="np ab fo"><div class="nq ab nr cl cj ns"><h2 class="bd iu gy z fp nt fr fs nu fu fw is bi translated">加入我的推荐链接-塔伦古普塔</h2><div class="nv l"><h3 class="bd b gy z fp nt fr fs nu fu fw dk translated">作为一个媒体会员，你的会员费的一部分会给你阅读的作家，你可以完全接触到每一个故事…</h3></div><div class="nw l"><p class="bd b dl z fp nt fr fs nu fu fw dk translated">tarun-gupta.medium.com</p></div></div><div class="nx l"><div class="pg l nz oa ob nx oc mu no"/></div></div></a></div><p id="537b" class="pw-post-body-paragraph kt ku it kv b kw kx ju ky kz la jx lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">感谢阅读。如果你喜欢这个，可以看看我的其他帖子:</p><div class="nl nm gp gr nn no"><a href="https://tarun-gupta.medium.com/thank-you-for-visiting-my-profile-9f708062c75e" rel="noopener follow" target="_blank"><div class="np ab fo"><div class="nq ab nr cl cj ns"><h2 class="bd iu gy z fp nt fr fs nu fu fw is bi translated">标记故事列表的快速链接—感谢您的访问</h2><div class="nv l"><h3 class="bd b gy z fp nt fr fs nu fu fw dk translated">我也有一份以快节奏出版为目标的出版物。读书成为作家。</h3></div><div class="nw l"><p class="bd b dl z fp nt fr fs nu fu fw dk translated">tarun-gupta.medium.com</p></div></div></div></a></div></div></div>    
</body>
</html>