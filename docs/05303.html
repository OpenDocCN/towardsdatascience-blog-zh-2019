<html>
<head>
<title>Self Organizing Maps</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">自组织地图</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/self-organizing-maps-1b7d2a84e065?source=collection_archive---------6-----------------------#2019-08-07">https://towardsdatascience.com/self-organizing-maps-1b7d2a84e065?source=collection_archive---------6-----------------------#2019-08-07</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="603d" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">(<strong class="ak">科霍宁的地图)</strong></h2></div><blockquote class="ki kj kk"><p id="4205" class="kl km kn ko b kp kq ju kr ks kt jx ku kv kw kx ky kz la lb lc ld le lf lg lh im bi translated"><strong class="ko iu">简介</strong></p></blockquote><p id="b54f" class="pw-post-body-paragraph kl km it ko b kp kq ju kr ks kt jx ku li kw kx ky lj la lb lc lk le lf lg lh im bi translated">自组织映射或 Kohenin 映射是由<a class="ae ll" href="https://en.wikipedia.org/wiki/Teuvo_Kohonen" rel="noopener ugc nofollow" target="_blank"> Teuvo Kohonen </a>在 20 世纪 80 年代推出的一种人工神经网络。(论文<a class="ae ll" href="https://sci2s.ugr.es/keel/pdf/algorithm/articulo/1990-Kohonen-PIEEE.pdf" rel="noopener ugc nofollow" target="_blank">链接</a>)</p><p id="f3ed" class="pw-post-body-paragraph kl km it ko b kp kq ju kr ks kt jx ku li kw kx ky lj la lb lc lk le lf lg lh im bi translated">SOM 使用无监督学习来训练，它与其他人工神经网络略有不同，SOM 不是通过 SGD 的反向传播来学习，而是使用竞争学习来调整神经元中的权重。我们使用这种类型的人工神经网络进行降维，通过创建空间组织的表示来减少我们的数据，还帮助我们发现数据之间的相关性。</p><blockquote class="ki kj kk"><p id="10fd" class="kl km kn ko b kp kq ju kr ks kt jx ku kv kw kx ky kz la lb lc ld le lf lg lh im bi translated"><strong class="ko iu"> SOM 的架构:</strong></p></blockquote><p id="0e2f" class="pw-post-body-paragraph kl km it ko b kp kq ju kr ks kt jx ku li kw kx ky lj la lb lc lk le lf lg lh im bi translated">自组织地图有两层，第一层是输入层，第二层是输出层或要素地图。</p><p id="a84a" class="pw-post-body-paragraph kl km it ko b kp kq ju kr ks kt jx ku li kw kx ky lj la lb lc lk le lf lg lh im bi translated">与其他神经网络类型不同，SOM 在神经元中没有激活函数，我们直接将权重传递给输出层，而不做任何事情。</p><p id="3c29" class="pw-post-body-paragraph kl km it ko b kp kq ju kr ks kt jx ku li kw kx ky lj la lb lc lk le lf lg lh im bi translated">SOM 中的每个神经元被分配一个与输入空间具有相同维数 d 的权重向量。</p><figure class="ln lo lp lq gt lr gh gi paragraph-image"><div class="gh gi lm"><img src="../Images/82b3ef6eb7c06b6325e114b3564ce7eb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1310/format:webp/1*eehec1ZZ_4vMSe69GTzYCg.png"/></div></figure><blockquote class="ki kj kk"><p id="f656" class="kl km kn ko b kp kq ju kr ks kt jx ku kv kw kx ky kz la lb lc ld le lf lg lh im bi translated"><strong class="ko iu">自组织地图训练</strong></p></blockquote><p id="f8cd" class="pw-post-body-paragraph kl km it ko b kp kq ju kr ks kt jx ku li kw kx ky lj la lb lc lk le lf lg lh im bi translated">正如我们之前提到的，SOM 不使用 SGD 的反向传播来更新权重，这种类型的无监督人工神经网络使用竞争学习来更新其权重。</p><p id="3982" class="pw-post-body-paragraph kl km it ko b kp kq ju kr ks kt jx ku li kw kx ky lj la lb lc lk le lf lg lh im bi translated">竞争学习基于三个过程:</p><ul class=""><li id="0627" class="lu lv it ko b kp kq ks kt li lw lj lx lk ly lh lz ma mb mc bi translated">竞争</li><li id="1773" class="lu lv it ko b kp md ks me li mf lj mg lk mh lh lz ma mb mc bi translated">合作</li><li id="af0a" class="lu lv it ko b kp md ks me li mf lj mg lk mh lh lz ma mb mc bi translated">适应</li></ul><p id="adaf" class="pw-post-body-paragraph kl km it ko b kp kq ju kr ks kt jx ku li kw kx ky lj la lb lc lk le lf lg lh im bi translated">让我们解释一下那些过程。</p><p id="f5d7" class="pw-post-body-paragraph kl km it ko b kp kq ju kr ks kt jx ku li kw kx ky lj la lb lc lk le lf lg lh im bi translated"><strong class="ko iu"> <em class="kn"> 1)竞争:</em> </strong></p><p id="499e" class="pw-post-body-paragraph kl km it ko b kp kq ju kr ks kt jx ku li kw kx ky lj la lb lc lk le lf lg lh im bi translated">正如我们之前所说的，SOM 中的每个神经元都被分配了一个与输入空间维数相同的权重向量。</p><p id="c8e9" class="pw-post-body-paragraph kl km it ko b kp kq ju kr ks kt jx ku li kw kx ky lj la lb lc lk le lf lg lh im bi translated">在下面的例子中，在输出层的每个神经元中，我们将有一个维数为 n 的向量。</p><p id="5489" class="pw-post-body-paragraph kl km it ko b kp kq ju kr ks kt jx ku li kw kx ky lj la lb lc lk le lf lg lh im bi translated">我们计算每个神经元(来自输出层的神经元)与输入数据之间的距离，距离最小的神经元将成为竞争的赢家。</p><p id="0e6e" class="pw-post-body-paragraph kl km it ko b kp kq ju kr ks kt jx ku li kw kx ky lj la lb lc lk le lf lg lh im bi translated">欧几里德度量通常用于测量距离。</p><figure class="ln lo lp lq gt lr gh gi paragraph-image"><div role="button" tabindex="0" class="mj mk di ml bf mm"><div class="gh gi mi"><img src="../Images/ed1fd106c1002e20414c1eda4cfc74ab.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Gf70S1DYJyhq_mVzXr3G7Q.png"/></div></div></figure><p id="db76" class="pw-post-body-paragraph kl km it ko b kp kq ju kr ks kt jx ku li kw kx ky lj la lb lc lk le lf lg lh im bi translated"><strong class="ko iu"> <em class="kn"> 2)公司:</em> </strong></p><p id="ab23" class="pw-post-body-paragraph kl km it ko b kp kq ju kr ks kt jx ku li kw kx ky lj la lb lc lk le lf lg lh im bi translated">我们将在最后的过程(适应)中更新获胜神经元的向量，但它不是唯一的一个，它的邻居也将被更新。</p><p id="7438" class="pw-post-body-paragraph kl km it ko b kp kq ju kr ks kt jx ku li kw kx ky lj la lb lc lk le lf lg lh im bi translated">我们如何选择邻居？</p><p id="dcb4" class="pw-post-body-paragraph kl km it ko b kp kq ju kr ks kt jx ku li kw kx ky lj la lb lc lk le lf lg lh im bi translated">为了选择邻居，我们使用邻域核函数，该函数取决于两个因素:时间(每次新输入数据增加的时间)和获胜神经元与另一个神经元之间的距离(该神经元离获胜神经元有多远)。</p><p id="5b77" class="pw-post-body-paragraph kl km it ko b kp kq ju kr ks kt jx ku li kw kx ky lj la lb lc lk le lf lg lh im bi translated">下图向我们展示了如何根据距离和时间因素选择获胜神经元(中间最绿的神经元)的邻居。</p><figure class="ln lo lp lq gt lr gh gi paragraph-image"><div class="gh gi mn"><img src="../Images/097cda1bd9ad8b59ee009be6f50f6b95.png" data-original-src="https://miro.medium.com/v2/resize:fit:1218/format:webp/1*OBoUEzgu1Y-xm_sQW1GoqQ.png"/></div><figcaption class="mo mp gj gh gi mq mr bd b be z dk">Time and distance factors</figcaption></figure><p id="e0e4" class="pw-post-body-paragraph kl km it ko b kp kq ju kr ks kt jx ku li kw kx ky lj la lb lc lk le lf lg lh im bi translated"><strong class="ko iu"> <em class="kn"> 3)改编:</em> </strong></p><p id="83c4" class="pw-post-body-paragraph kl km it ko b kp kq ju kr ks kt jx ku li kw kx ky lj la lb lc lk le lf lg lh im bi translated">在选择胜出的神经元和它的邻居后，我们计算神经元更新。这些选择的神经元将被更新，但不是相同的更新，神经元和输入数据之间的距离越大，我们调整它，如下图所示:</p><figure class="ln lo lp lq gt lr gh gi paragraph-image"><div class="gh gi ms"><img src="../Images/b45366e719a6f16f892f104556050294.png" data-original-src="https://miro.medium.com/v2/resize:fit:1162/format:webp/1*5H8fuicZ2ABNdxgQ7GR9mw.png"/></div><figcaption class="mo mp gj gh gi mq mr bd b be z dk">neurons of the output layer update</figcaption></figure><p id="b0cb" class="pw-post-body-paragraph kl km it ko b kp kq ju kr ks kt jx ku li kw kx ky lj la lb lc lk le lf lg lh im bi translated">将使用以下公式更新优胜神经元及其相邻神经元:</p><figure class="ln lo lp lq gt lr gh gi paragraph-image"><div class="gh gi mt"><img src="../Images/b6f37c707d8c5294bb3854d68cd5dd51.png" data-original-src="https://miro.medium.com/v2/resize:fit:836/format:webp/1*iKarZL0dmCb_oluxi9QPbQ.png"/></div></figure><figure class="ln lo lp lq gt lr gh gi paragraph-image"><div role="button" tabindex="0" class="mj mk di ml bf mm"><div class="gh gi mu"><img src="../Images/cf40c33d6c4d539feeffaae3636adb52.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*S7VLMxQx0QOT997rzpgBjw.png"/></div></div></figure><p id="f3e9" class="pw-post-body-paragraph kl km it ko b kp kq ju kr ks kt jx ku li kw kx ky lj la lb lc lk le lf lg lh im bi translated">这个学习率表明了我们想要调整权重的程度。</p><p id="9f2f" class="pw-post-body-paragraph kl km it ko b kp kq ju kr ks kt jx ku li kw kx ky lj la lb lc lk le lf lg lh im bi translated">在时间 t(正无穷大)之后，这个学习速率将收敛到零，因此我们将没有更新，即使对于神经元赢家也是如此。</p><figure class="ln lo lp lq gt lr gh gi paragraph-image"><div role="button" tabindex="0" class="mj mk di ml bf mm"><div class="gh gi mv"><img src="../Images/abdc5c3712af3b962365aff076b0d591.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*RrOyISVGFPLszcWNSrlxWQ.png"/></div></div></figure><p id="cc24" class="pw-post-body-paragraph kl km it ko b kp kq ju kr ks kt jx ku li kw kx ky lj la lb lc lk le lf lg lh im bi translated">邻域核取决于赢家神经元和另一个神经元之间的距离(它们成比例地相反:d 增加使 h(t)减少)和邻域大小，邻域大小本身取决于时间(随着时间增加而减少)，这也使邻域核函数减少。</p><p id="038a" class="pw-post-body-paragraph kl km it ko b kp kq ju kr ks kt jx ku li kw kx ky lj la lb lc lk le lf lg lh im bi translated">完整 SOM 算法:</p><figure class="ln lo lp lq gt lr gh gi paragraph-image"><div role="button" tabindex="0" class="mj mk di ml bf mm"><div class="gh gi mw"><img src="../Images/27ec9cbdbd8e3d31b6d2a1c9509d469e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*twwdTdpNfQXZZ0DypV3s2g.png"/></div></div></figure><blockquote class="ki kj kk"><p id="2399" class="kl km kn ko b kp kq ju kr ks kt jx ku kv kw kx ky kz la lb lc ld le lf lg lh im bi translated"><strong class="ko iu">例子:</strong></p></blockquote><p id="12ef" class="pw-post-body-paragraph kl km it ko b kp kq ju kr ks kt jx ku li kw kx ky lj la lb lc lk le lf lg lh im bi translated">现在让我们看一些例子</p><p id="4654" class="pw-post-body-paragraph kl km it ko b kp kq ju kr ks kt jx ku li kw kx ky lj la lb lc lk le lf lg lh im bi translated">示例 1:</p><figure class="ln lo lp lq gt lr gh gi paragraph-image"><div role="button" tabindex="0" class="mj mk di ml bf mm"><div class="gh gi mx"><img src="../Images/b322fc2227815f692cc586901af27939.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*LraKI0qQyxBOzBZ5-TIa1A.png"/></div></div></figure><p id="4173" class="pw-post-body-paragraph kl km it ko b kp kq ju kr ks kt jx ku li kw kx ky lj la lb lc lk le lf lg lh im bi translated">正如你在这个例子中所看到的，特征图采用了在二维空间中描述数据集的形状。</p><p id="7fe1" class="pw-post-body-paragraph kl km it ko b kp kq ju kr ks kt jx ku li kw kx ky lj la lb lc lk le lf lg lh im bi translated">示例 2:</p><figure class="ln lo lp lq gt lr"><div class="bz fp l di"><div class="my mz l"/></div><figcaption class="mo mp gj gh gi mq mr bd b be z dk">SOM with 3D feature map</figcaption></figure></div></div>    
</body>
</html>