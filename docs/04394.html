<html>
<head>
<title>3 Ways to Optimize and Export BERT Model for Online Serving</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">优化和导出在线服务 BERT 模型的 3 种方法</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/3-ways-to-optimize-and-export-bert-model-for-online-serving-8f49d774a501?source=collection_archive---------19-----------------------#2019-07-08">https://towardsdatascience.com/3-ways-to-optimize-and-export-bert-model-for-online-serving-8f49d774a501?source=collection_archive---------19-----------------------#2019-07-08</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><figure class="gl gn jr js jt ju gh gi paragraph-image"><div class="gh gi jq"><img src="../Images/071b884d2988e7213cbf9c1c3e28b00e.png" data-original-src="https://miro.medium.com/v2/resize:fit:874/format:webp/1*rRDNBlUf-NFabtqnPNbAHw.png"/></div><figcaption class="jx jy gj gh gi jz ka bd b be z dk">Image taken from <a class="ae kb" href="https://ai.googleblog.com/2018/11/open-sourcing-bert-state-of-art-pre.html" rel="noopener ugc nofollow" target="_blank">Google AI Blog</a></figcaption></figure><p id="6bc3" class="pw-post-body-paragraph kc kd it ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz im bi translated">今天的主题是关于优化和导出 BERT 模型，以便根据字符串列表的预测在线提供服务。与我之前的教程不同，我将保持这篇文章简短。</p><p id="195e" class="pw-post-body-paragraph kc kd it ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz im bi translated">本文包含以下几个部分:</p><ol class=""><li id="99c1" class="la lb it ke b kf kg kj kk kn lc kr ld kv le kz lf lg lh li bi translated">问题陈述</li><li id="526b" class="la lb it ke b kf lj kj lk kn ll kr lm kv ln kz lf lg lh li bi translated">减小微调 BERT 模型的大小。</li><li id="e88b" class="la lb it ke b kf lj kj lk kn ll kr lm kv ln kz lf lg lh li bi translated">将模型导出到 pb 文件中。</li><li id="0b5c" class="la lb it ke b kf lj kj lk kn ll kr lm kv ln kz lf lg lh li bi translated">从字符串列表进行预测</li><li id="b039" class="la lb it ke b kf lj kj lk kn ll kr lm kv ln kz lf lg lh li bi translated">结论</li></ol><h1 id="4f2b" class="lo lp it bd lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk ml bi translated">[第 1 部分]问题陈述</h1><p id="a5d8" class="pw-post-body-paragraph kc kd it ke b kf mm kh ki kj mn kl km kn mo kp kq kr mp kt ku kv mq kx ky kz im bi translated">如果你一直在关注我的<a class="ae kb" rel="noopener" target="_blank" href="/beginners-guide-to-bert-for-multi-classification-task-92f5445c2d7c">上一篇关于针对多分类任务微调 BERT 模型的文章</a>，你会注意到以下问题:</p><ol class=""><li id="d872" class="la lb it ke b kf kg kj kk kn lc kr ld kv le kz lf lg lh li bi translated">输出模型比原始模型大 3 倍(适用于 BERT-Base 和 BERT-Large)。</li><li id="1aea" class="la lb it ke b kf lj kj lk kn ll kr lm kv ln kz lf lg lh li bi translated">输出模型是 ckpt 文件。你可能需要一个 pb 文件。</li><li id="0186" class="la lb it ke b kf lj kj lk kn ll kr lm kv ln kz lf lg lh li bi translated">该代码是基于读取一个输入文件和输出概率到输出文件。您可能需要单个输入文本，而不是单个概率输出。</li></ol><p id="b430" class="pw-post-body-paragraph kc kd it ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz im bi translated">通过阅读这篇文章，你将学会解决上述问题。说到这里，本文不涉及以下内容:</p><ol class=""><li id="d904" class="la lb it ke b kf kg kj kk kn lc kr ld kv le kz lf lg lh li bi translated">如何使用导出的 pb 文件？</li><li id="9550" class="la lb it ke b kf lj kj lk kn ll kr lm kv ln kz lf lg lh li bi translated">如何加快推断时间？</li><li id="036f" class="la lb it ke b kf lj kj lk kn ll kr lm kv ln kz lf lg lh li bi translated">如何在线上为模特服务？</li></ol></div><div class="ab cl mr ms hx mt" role="separator"><span class="mu bw bk mv mw mx"/><span class="mu bw bk mv mw mx"/><span class="mu bw bk mv mw"/></div><div class="im in io ip iq"><h1 id="8151" class="lo lp it bd lq lr my lt lu lv mz lx ly lz na mb mc md nb mf mg mh nc mj mk ml bi translated">[第 2 节]减小微调 BERT 模型的大小</h1><p id="62d6" class="pw-post-body-paragraph kc kd it ke b kf mm kh ki kj mn kl km kn mo kp kq kr mp kt ku kv mq kx ky kz im bi translated">根据来自 BERT 团队的一名成员提供的响应，由于每个权重变量包含了亚当<strong class="ke iu">动量</strong>和<strong class="ke iu">方差</strong>变量，微调后的模型比分布式检查点大 3 倍。暂停和恢复训练都需要这两个变量。换句话说，如果您打算在没有任何进一步训练的情况下服务于您的微调模型，您可以移除变量和，大小将或多或少类似于分布式模型。创建一个 python 文件，并在其中键入以下代码(相应地进行修改):</p><figure class="nd ne nf ng gt ju"><div class="bz fp l di"><div class="nh ni l"/></div></figure><p id="887a" class="pw-post-body-paragraph kc kd it ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz im bi translated">由于内存问题，建议在终端/命令提示符下运行它，而不是在 jupyter notebook 中运行(如果遇到无法加载张量的错误，只需通过 cmd 运行它)。</p><p id="8a98" class="pw-post-body-paragraph kc kd it ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz im bi translated">您应该得到如下 3 个 ckpt 文件(取决于您在 saver.save 过程中设置的名称):</p><ol class=""><li id="e8b0" class="la lb it ke b kf kg kj kk kn lc kr ld kv le kz lf lg lh li bi translated">model . ckpt . data-00000/00001</li><li id="c8f3" class="la lb it ke b kf lj kj lk kn ll kr lm kv ln kz lf lg lh li bi translated">模型.检查点.索引</li><li id="8acb" class="la lb it ke b kf lj kj lk kn ll kr lm kv ln kz lf lg lh li bi translated">model.ckpt.meta</li></ol></div><div class="ab cl mr ms hx mt" role="separator"><span class="mu bw bk mv mw mx"/><span class="mu bw bk mv mw mx"/><span class="mu bw bk mv mw"/></div><div class="im in io ip iq"><h1 id="c381" class="lo lp it bd lq lr my lt lu lv mz lx ly lz na mb mc md nb mf mg mh nc mj mk ml bi translated">[第 3 节]在 pb 文件中导出模型</h1><p id="89b1" class="pw-post-body-paragraph kc kd it ke b kf mm kh ki kj mn kl km kn mo kp kq kr mp kt ku kv mq kx ky kz im bi translated">对于那些喜欢 pb 图的人来说，从下面的<a class="ae kb" href="https://github.com/yajian/bert/blob/master/model_exporter.py" rel="noopener ugc nofollow" target="_blank">链接</a>下载 py 文件(功劳归于原创者)。将它放在您选择的目录中，并在终端中运行以下命令:</p><pre class="nd ne nf ng gt nj nk nl nm aw nn bi"><span id="0218" class="no lp it nk b gy np nq l nr ns">CUDA_VISIBLE_DEVICES=0 python model_exporter.py --data_path=./bert_output/ --labels_num=3 --export_path=./model_export/pb_graph/</span></pre><p id="2b46" class="pw-post-body-paragraph kc kd it ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz im bi translated">您需要修改三个参数:</p><ol class=""><li id="cbc4" class="la lb it ke b kf kg kj kk kn lc kr ld kv le kz lf lg lh li bi translated"><strong class="ke iu"> data_path </strong>:包含三个 ckpt 文件的微调模型的路径。我把所有的文件都放在<strong class="ke iu"> bert_output </strong>文件夹里。</li><li id="0c7d" class="la lb it ke b kf lj kj lk kn ll kr lm kv ln kz lf lg lh li bi translated"><strong class="ke iu">标签</strong>:你拥有的标签数量。我有三节课。</li><li id="e7ea" class="la lb it ke b kf lj kj lk kn ll kr lm kv ln kz lf lg lh li bi translated"><strong class="ke iu">导出路径</strong>:输出模型的路径。它将被自动创建。如果遇到与输出路径相关的错误。请从目录中删除输出路径。</li></ol><p id="f9db" class="pw-post-body-paragraph kc kd it ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz im bi translated">完成后，您应该有一个包含以下文件的 pb_graph 文件夹:</p><ol class=""><li id="a9ed" class="la lb it ke b kf kg kj kk kn lc kr ld kv le kz lf lg lh li bi translated">保存 _ 模型. pb</li><li id="1365" class="la lb it ke b kf lj kj lk kn ll kr lm kv ln kz lf lg lh li bi translated">变量</li></ol><p id="87d3" class="pw-post-body-paragraph kc kd it ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz im bi translated">在下面的 github <a class="ae kb" href="https://github.com/yajian/bert/blob/master/run_multilabels_classifier.py" rel="noopener ugc nofollow" target="_blank">链接</a>中，主人做了一个脚本，可以用来训练一个多标签分类的 BERT 模型。基于当前模型，我们只能执行多分类任务，即来自所有类别的单个标签。如果您打算从所有的类中预测多标签，您可以尝试使用这个脚本。在我写这篇文章的时候，我还没有测试过它，但是你可以自己探索它。</p></div><div class="ab cl mr ms hx mt" role="separator"><span class="mu bw bk mv mw mx"/><span class="mu bw bk mv mw mx"/><span class="mu bw bk mv mw"/></div><div class="im in io ip iq"><h1 id="71d8" class="lo lp it bd lq lr my lt lu lv mz lx ly lz na mb mc md nb mf mg mh nc mj mk ml bi translated">[第 4 节]从字符串列表预测</h1><p id="dc6f" class="pw-post-body-paragraph kc kd it ke b kf mm kh ki kj mn kl km kn mo kp kq kr mp kt ku kv mq kx ky kz im bi translated">本节是关于对字符串列表执行推理，而不是从文件中读取。在与<em class="nt"> run_classifier.py </em>相同的目录中创建另一个 py 文件，并键入以下内容:</p><figure class="nd ne nf ng gt ju"><div class="bz fp l di"><div class="nh ni l"/></div></figure><p id="c7a0" class="pw-post-body-paragraph kc kd it ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz im bi translated">该函数接受字符串列表作为参数。让我们看看函数的每一行:</p><ol class=""><li id="870b" class="la lb it ke b kf kg kj kk kn lc kr ld kv le kz lf lg lh li bi translated">使用列表理解遍历列表中的每个元素，并将其转换为功能转换所需的适当格式。</li><li id="9043" class="la lb it ke b kf lj kj lk kn ll kr lm kv ln kz lf lg lh li bi translated">根据标签、最大序列长度和标记化将其转换为预测所需的特征。稍后我们将初始化所需的变量。</li><li id="1d69" class="la lb it ke b kf lj kj lk kn ll kr lm kv ln kz lf lg lh li bi translated">创建一个要传递给 TPUEstimator 的<strong class="ke iu"> input_fn </strong>闭包。</li><li id="610c" class="la lb it ke b kf lj kj lk kn ll kr lm kv ln kz lf lg lh li bi translated">基于输入要素执行预测。</li></ol><p id="6210" class="pw-post-body-paragraph kc kd it ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz im bi translated">转换时间通常很长，这取决于你的内存和 GPU。如果您打算进一步优化它，请检查<em class="nt">convert _ examples _ to _ features</em>和<em class="nt"> input_fn_builder </em>。供您参考，上面提到的两个功能消耗的时间和内存最多。</p><p id="6ec3" class="pw-post-body-paragraph kc kd it ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz im bi translated">我们现在将初始化所需的变量。继续添加以下代码:</p><figure class="nd ne nf ng gt ju"><div class="bz fp l di"><div class="nh ni l"/></div></figure><p id="9bce" class="pw-post-body-paragraph kc kd it ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz im bi translated">完成后，最后一部分是调用<strong class="ke iu"> getListPrediction </strong>函数，将一个列表作为参数传递:</p><pre class="nd ne nf ng gt nj nk nl nm aw nn bi"><span id="89d1" class="no lp it nk b gy np nq l nr ns">pred_sentences = ['I am a little burnt out after the event.']</span><span id="42ad" class="no lp it nk b gy nu nq l nr ns">result = list(getListPrediction(pred_sentences)))</span></pre><p id="bf7a" class="pw-post-body-paragraph kc kd it ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz im bi translated">您需要将结果转换为列表才能查看。您应该能够获得以下结果(3 个类的示例):</p><pre class="nd ne nf ng gt nj nk nl nm aw nn bi"><span id="1c9c" class="no lp it nk b gy np nq l nr ns">[{'probabilities': array([2.4908668e-06,<br/>       2.4828103e-06, 9.9996364e-01], dtype=float32)}]</span></pre><p id="d92c" class="pw-post-body-paragraph kc kd it ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz im bi translated">结果表示每个标签的概率，最高的是预测标签。您可以简单地使用输出结果并将其映射到相应的标签。</p></div><div class="ab cl mr ms hx mt" role="separator"><span class="mu bw bk mv mw mx"/><span class="mu bw bk mv mw mx"/><span class="mu bw bk mv mw"/></div><div class="im in io ip iq"><h1 id="b4a7" class="lo lp it bd lq lr my lt lu lv mz lx ly lz na mb mc md nb mf mg mh nc mj mk ml bi translated">[第五节]结论</h1><p id="981a" class="pw-post-body-paragraph kc kd it ke b kf mm kh ki kj mn kl km kn mo kp kq kr mp kt ku kv mq kx ky kz im bi translated">正如我前面提到的，这是一篇相当短的文章，为了在线服务，它解决了一些与 BERT 相关的问题。如果你有兴趣通过 GPU 优化加快推理时间，敬请查看以下<a class="ae kb" href="https://github.com/google-research/bert/pull/255" rel="noopener ugc nofollow" target="_blank">链接</a>。请记住，来自 BERT 的团队成员之一已经冻结了存储库，以防止任何代码失败。然而，将来可能会有一个单独的存储库，其中包含 GPU 优化的代码。请继续关注更多关于编程和人工智能的文章！</p></div><div class="ab cl mr ms hx mt" role="separator"><span class="mu bw bk mv mw mx"/><span class="mu bw bk mv mw mx"/><span class="mu bw bk mv mw"/></div><div class="im in io ip iq"><h1 id="07a3" class="lo lp it bd lq lr my lt lu lv mz lx ly lz na mb mc md nb mf mg mh nc mj mk ml bi translated">伯特相关的故事</h1><ol class=""><li id="6624" class="la lb it ke b kf mm kj mn kn nv kr nw kv nx kz lf lg lh li bi translated"><a class="ae kb" rel="noopener" target="_blank" href="/beginners-guide-to-bert-for-multi-classification-task-92f5445c2d7c">针对多分类任务的 BERT 初学者指南</a></li></ol></div><div class="ab cl mr ms hx mt" role="separator"><span class="mu bw bk mv mw mx"/><span class="mu bw bk mv mw mx"/><span class="mu bw bk mv mw"/></div><div class="im in io ip iq"><h1 id="0041" class="lo lp it bd lq lr my lt lu lv mz lx ly lz na mb mc md nb mf mg mh nc mj mk ml bi translated">参考</h1><ol class=""><li id="2978" class="la lb it ke b kf mm kj mn kn nv kr nw kv nx kz lf lg lh li bi translated"><a class="ae kb" rel="noopener" target="_blank" href="/beginners-guide-to-bert-for-multi-classification-task-92f5445c2d7c">https://towards data science . com/beginners-guide-to-Bert-for-multi-class ification-task-92f 5445 c2d 7 c</a></li><li id="88bf" class="la lb it ke b kf lj kj lk kn ll kr lm kv ln kz lf lg lh li bi translated"><a class="ae kb" href="https://github.com/yajian/bert" rel="noopener ugc nofollow" target="_blank">https://github.com/yajian/bert</a></li><li id="2287" class="la lb it ke b kf lj kj lk kn ll kr lm kv ln kz lf lg lh li bi translated"><a class="ae kb" href="https://github.com/google-research/bert/issues/99" rel="noopener ugc nofollow" target="_blank">https://github.com/google-research/bert/issues/99</a></li><li id="29ee" class="la lb it ke b kf lj kj lk kn ll kr lm kv ln kz lf lg lh li bi translated"><a class="ae kb" href="https://github.com/google-research/bert/issues/63" rel="noopener ugc nofollow" target="_blank">https://github.com/google-research/bert/issues/63</a></li><li id="cc34" class="la lb it ke b kf lj kj lk kn ll kr lm kv ln kz lf lg lh li bi translated"><a class="ae kb" href="https://github.com/google-research/bert/issues/146" rel="noopener ugc nofollow" target="_blank">https://github.com/google-research/bert/issues/146</a></li><li id="bd46" class="la lb it ke b kf lj kj lk kn ll kr lm kv ln kz lf lg lh li bi translated"><a class="ae kb" href="https://github.com/google-research/bert/pull/255" rel="noopener ugc nofollow" target="_blank">https://github.com/google-research/bert/pull/255</a></li></ol></div></div>    
</body>
</html>