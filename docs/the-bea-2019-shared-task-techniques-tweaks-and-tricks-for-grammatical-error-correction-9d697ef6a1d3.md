# BEA 2019 共享任务:语法错误纠正的技术、调整和技巧

> 原文：<https://towardsdatascience.com/the-bea-2019-shared-task-techniques-tweaks-and-tricks-for-grammatical-error-correction-9d697ef6a1d3?source=collection_archive---------32----------------------->

最近的 [BEA 语法错误纠正共享任务](https://www.cl.cam.ac.uk/research/nl/bea2019st/)共有 24 个团队参与，他们提出了许多有趣的解决问题的方法——其中许多都取得了令人印象深刻的结果！使用了各种各样的技术、调整和技巧，为了呈现一个更容易理解的概述，我列出了我的主要收获。

纵观提交的材料，有两个总体趋势很明显:

1.  神经机器翻译方法占主导地位。以前基于规则、分类器和统计机器翻译的最先进的方法，现在已经远远落在后面了。
2.  在大量人工生成的错误示例或弱监督数据(例如，来自维基百科修订历史)上训练系统已经成为标准做法。

在描述更详细的组件时，我将它们分为三个部分:

1.  **模型**:模型的架构和解码技术
2.  **数据**:用于训练模型的(人工)数据
3.  **训练**:训练程序

# 模型

**架构**绝大多数提交的内容都基于神经机器翻译方法，其中三分之二使用 transformer 架构，而其余的则基于卷积序列到序列架构或两者的结合。比较两种架构时，[袁等人](https://www.aclweb.org/anthology/W19-4424)发现变压器模型的性能增益非常大。
[Choe 等人](https://www.aclweb.org/anthology/W19-4423)也利用了复制增强的变压器架构。这最初是由[赵等人](https://arxiv.org/pdf/1903.00138.pdf)提出用于语法错误纠正的，他们通过引入一种允许复制输入标记的输出机制显示了改进。这是有意义的，因为每当纠错系统不纠正错误时，它只是简单地复制输入。

**重新排序**受限赛道的两个顶级系统也对 beam 搜索的输出句子进行重新排序。
[Choe 等人](https://www.aclweb.org/anthology/W19-4423)注意到，他们的模型的许多修正是不自然或不正确的，他们通过使用预先训练的神经语言模型重新排序来改善这些修正。 [Grundkiewicz 等人](https://kheafield.com/papers/edinburgh/bea19.pdf)在重新排序时使用额外的从右到左神经语言模型作为特征——其动机是从右到左模型可以补充标准的从左到右解码。
其他方法使用错误检测模型进行重新排序:[袁等人](https://www.aclweb.org/anthology/W19-4424)基于从错误检测系统导出的特征进行重新排序，而 [Kaneko 等人](https://www.aclweb.org/anthology/W19-4422)在句子级错误检测任务上微调 BERT，并使用其预测作为重新排序的特征。随着系统被推向纠正更多错误，这两种方法的总体得分都有所提高，尤其是召回率。

**过滤**这种方法对于工业用例也很有趣，因为它可以显著减少处理时间，因为一般来说，大多数句子不包含错误。

**迭代解码**通过迭代解码，一个句子不断地通过翻译模型，直到模型输出不变的句子。这允许以增量而不是仅通过一遍来校正句子，从而使得模型能够生成更多的校正。 [Náplava 等人](https://www.aclweb.org/anthology/W19-4419)看到了使用迭代解码的改进，但是它们以牺牲精度为代价提高了召回率。相反， [Grundkiewicz 等人](https://kheafield.com/papers/edinburgh/bea19.pdf)放弃迭代解码，因为他们认为只有在系统召回率低的情况下才有必要。

# 数据

一般来说，存在两种方法来生成错误的人工示例:

1.  基于规则，使用从真实数据和混淆集收集的错误统计数据，混淆集由通常被错误混淆的单词组成
2.  反向翻译，其中反向训练校正模型以将错误插入到正确的文本中

**基于规则的生成**受限领域的前两个贡献都使用了基于规则的方法。
[Grundkiewicz 等人](https://kheafield.com/papers/edinburgh/bea19.pdf)将他们的错误生成方法基于从拼写检查器 Aspell 中提取的混淆集，该拼写检查器基于词汇和语音相似性提出建议。在概率与开发集中的单词错误率相匹配的情况下，一个单词要么被删除，与其相邻单词交换，用其混淆集中的一个单词替换，要么插入一个随机单词。此外，为了处理拼写错误，通过在字符级别上使用上述相同的操作，将词汇噪声引入单词。
亚军 [Choe 等人](https://www.aclweb.org/anthology/W19-4423)试图通过将真实错误中的 n-gram 模式插入到正确的文本中来制造真实的错误。他们还利用规则来创建特定的错误类型，如介词、名词数和动词错误。当将他们的错误生成方法与基于随机替换、删除、插入和重新排序的方法进行比较时，他们看到了明显的好处。然而，如果模型根据实际误差进行微调，差异就会变得均匀。

**由于不能保证注入错误，只能简单转述句子，为了控制数据质量[袁等](https://www.aclweb.org/anthology/W19-4424)过滤掉可能转述的人工句子对。这样，如果生成的句子不具有比从真实错误示例中学习到的阈值更高的降低的语言模型概率，则句子对被过滤。**

# **培养**

****检查点平均** [Náplava 等人](https://www.aclweb.org/anthology/W19-4419)通过使最终模型的权重为多个先前检查点的平均值，看到了性能的提高和方差的降低。对于他们的最终模型，他们最终平均了 8 个最新的检查点。**

****加权最大似然估计**由于语法纠错系统倾向于收敛到局部最优，其中模型通常简单地将输入不变地复制到输出， [Grundkiewicz 等人](https://kheafield.com/papers/edinburgh/bea19.pdf)和 [Náplava 等人](https://www.aclweb.org/anthology/W19-4419)修改 MLE 损失函数，以给予应该改变的标记更高的权重。**

****域适应**提出了几种方法来处理不同域中错误类型和频率的差异。在一种方法中， [Náplava 等人](https://www.aclweb.org/anthology/W19-4419)通过对共享测试集域的较小数据集进行过采样来生成他们的训练集。
作为过采样的替代方案， [Choe 等人](https://www.aclweb.org/anthology/W19-4423)使用顺序迁移学习方法。这样，他们的模型在三个阶段的过程中被训练:1)去噪自动编码器 2)训练 3)微调。在每个阶段，模型都在一个逐渐变小的数据集上进行训练，该数据集更接近测试域。**

****多任务学习**他们的系统在错误检测方面表现非常好，表明辅助检测任务是有益的。**

# **结论**

**BEA 2019 共享任务中系统令人印象深刻的表现表明，自上一个共享任务 CONLL14 以来的 5 年中，语法纠错领域取得了巨大的飞跃。特别是，通过将问题建模为低资源神经机器翻译任务，已经取得了很多成功。即使在这种相对狭窄的环境中，系统仍在朝着许多不同的方向发展，许多不同的技术正在被应用。展望未来，我列出的每一个组件都应该进一步探索，以开发一套最佳实践，作为工业系统和未来研究方向的基础。**

***原载于*[*http://www . flachs . io*](http://www.flachs.io/2019/08/14/BEA-overview.html)*。***