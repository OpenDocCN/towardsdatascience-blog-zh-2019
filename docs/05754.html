<html>
<head>
<title>How to create TV Sitcom Dataset from raw web transcripts?</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">如何从原始网络脚本创建电视情景喜剧数据集？</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/now-we-have-tv-sitcom-f-r-i-e-n-d-s-dataset-created-from-web-transcripts-908af7777977?source=collection_archive---------18-----------------------#2019-08-22">https://towardsdatascience.com/now-we-have-tv-sitcom-f-r-i-e-n-d-s-dataset-created-from-web-transcripts-908af7777977?source=collection_archive---------18-----------------------#2019-08-22</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><p id="daef" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">到目前为止，除了网络记录之外，还没有可用的 F.R.I.E.N.D.S 或任何流行情景喜剧的数据集(在这次演示中，我使用了来自这个链接的记录-<a class="ae kl" href="https://fangj.github.io/friends/" rel="noopener ugc nofollow" target="_blank">https://fangj.github.io/friends/</a>)。因此，我创建了这个数据集，供对探索这个数据集感兴趣的每个人使用，并使用这里描述的方法创建类似的数据集。</p><h1 id="47cf" class="km kn iq bd ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj bi translated">先睹为快数据:</h1><p id="eb4a" class="pw-post-body-paragraph jn jo iq jp b jq lk js jt ju ll jw jx jy lm ka kb kc ln ke kf kg lo ki kj kk ij bi translated">最终创建的数据集如下所示。关于这个的 csv 文件可以在<a class="ae kl" href="https://raw.githubusercontent.com/shilpibhattacharyya/Friends_Analysis/master/friends_dataset.csv" rel="noopener ugc nofollow" target="_blank">https://raw . githubusercontent . com/shilpbhattacharyya/Friends _ Analysis/master/Friends _ dataset . CSV</a>获得</p><figure class="lq lr ls lt gt lu gh gi paragraph-image"><div role="button" tabindex="0" class="lv lw di lx bf ly"><div class="gh gi lp"><img src="../Images/d1c7b32e7766e95b50f6575cc585d5af.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*KG1J7lkhhPHyGu9SZM5C9g.png"/></div></div><figcaption class="mb mc gj gh gi md me bd b be z dk">A peek into the created dataset</figcaption></figure><h1 id="db3a" class="km kn iq bd ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj bi translated">代码演练:</h1><p id="064b" class="pw-post-body-paragraph jn jo iq jp b jq lk js jt ju ll jw jx jy lm ka kb kc ln ke kf kg lo ki kj kk ij bi translated">这种方法和数据集创建的完整代码可以在我的 github repo(【https://github.com/shilpibhattacharyya/Friends_Analysis】T4)中找到。此数据有一个 93335 行 5 列的形状(93335，5)。我在这里粘贴一个片段来说明我是如何创建这个数据集的。</p><p id="af0c" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">下面是网页文字链接(<a class="ae kl" href="https://fangj.github.io/friends/" rel="noopener ugc nofollow" target="_blank">https://fangj.github.io/friends/</a>)的一瞥:</p><div class="lq lr ls lt gt ab cb"><figure class="mf lu mg mh mi mj mk paragraph-image"><div role="button" tabindex="0" class="lv lw di lx bf ly"><img src="../Images/dd1c8e5cb84b7555ea6d4b59796e9697.png" data-original-src="https://miro.medium.com/v2/resize:fit:618/format:webp/1*_UFL4FM7JVaaAIyAQUWQAg.png"/></div></figure><figure class="mf lu ml mh mi mj mk paragraph-image"><div role="button" tabindex="0" class="lv lw di lx bf ly"><img src="../Images/2d21c43e4555199367a05cd9ab867582.png" data-original-src="https://miro.medium.com/v2/resize:fit:782/format:webp/1*CP_G0NtAldQfeWzB8uX-pg.png"/></div></figure><figure class="mf lu mm mh mi mj mk paragraph-image"><div role="button" tabindex="0" class="lv lw di lx bf ly"><img src="../Images/d89351fe58e597c33956c45b12a89505.png" data-original-src="https://miro.medium.com/v2/resize:fit:602/format:webp/1*MYrkRIxOauYtrA7jUrht0Q.png"/></div><figcaption class="mb mc gj gh gi md me bd b be z dk mn di mo mp">Transcript files for the Friends different seasons (only 3 shown)</figcaption></figure></div><figure class="lq lr ls lt gt lu gh gi paragraph-image"><div role="button" tabindex="0" class="lv lw di lx bf ly"><div class="gh gi mq"><img src="../Images/f4d7b88b6c3f96dc4fe0ddff22d58854.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*kQZKF2jSZxj3vTwNOnqbfA.png"/></div></div><figcaption class="mb mc gj gh gi md me bd b be z dk">Transcript file for Season1 Episode1 to get an idea of the transcripts</figcaption></figure><p id="e706" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">该算法可以总结如下:</p><ol class=""><li id="bf02" class="mr ms iq jp b jq jr ju jv jy mt kc mu kg mv kk mw mx my mz bi translated">将每集的 html 内容复制/转换为 txt/csv 文件。</li><li id="4881" class="mr ms iq jp b jq na ju nb jy nc kc nd kg ne kk mw mx my mz bi translated">为每一季的所有剧集副本创建单独的文件夹。</li></ol><figure class="lq lr ls lt gt lu gh gi paragraph-image"><div role="button" tabindex="0" class="lv lw di lx bf ly"><div class="gh gi nf"><img src="../Images/e16c09941bbd6ad9351b90f295e8ebd1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*kQMQjpqL7KP3ZP7VCFtQpQ.png"/></div></div><figcaption class="mb mc gj gh gi md me bd b be z dk">Folder layout in the github repo</figcaption></figure><ol class=""><li id="a74b" class="mr ms iq jp b jq jr ju jv jy mt kc mu kg mv kk mw mx my mz bi translated">将每一季的剧集合并成一个. csv 文件(mergedx.csv ),我们可以从中读取数据。</li><li id="04b3" class="mr ms iq jp b jq na ju nb jy nc kc nd kg ne kk mw mx my mz bi translated">我首先提取了上图中的场景内容，然后根据逗号(，)分隔符将其分割成[Location，Scene]。</li><li id="9272" class="mr ms iq jp b jq na ju nb jy nc kc nd kg ne kk mw mx my mz bi translated">然后提取每个字符对应的文本，保存在以关键字为‘字符’的字典中。</li><li id="0835" class="mr ms iq jp b jq na ju nb jy nc kc nd kg ne kk mw mx my mz bi translated">用文本加场景创建一个熊猫系列，并分割以创建一个由列[位置、场景、季节、演讲者、文本]组成的数据帧，定义如下。</li></ol><p id="0c95" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">地点:说这段文字的地方</p><p id="eca1" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">场景:</strong>画周围环境的活动</p><p id="7c88" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">季节</strong>:说这段文字的季节</p><p id="3565" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">说话者</strong>:说这段文字的人物【瑞秋，钱德勒，菲比，乔伊，莫妮卡，罗斯】</p><p id="2ad7" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">文本</strong>:对应以上属性的角色所说的文本。</p><p id="8484" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">5.我打乱了数据，使其在分布中更加分散。</p><pre class="lq lr ls lt gt ng nh ni nj aw nk bi"><span id="4e3c" class="nl kn iq nh b gy nm nn l no np">import re<br/>friends_chars={} <br/>Rachel=''<br/>Ross=''<br/>Joey=''<br/>Chandler=''<br/>Phoebe=''<br/>Monica=''<br/>Scene=''<br/>with open("transcripts_friends/season1/merged1.csv", "r+") as fp:<br/>    for cnt, line in enumerate(fp):<br/>        if line.startswith('[Scene:'):<br/>            Scene=(line[7:].replace("]", "").replace(":", ","))<br/>        if line.startswith('Rachel:'):<br/>            string=Scene.replace("\n", "")+"*"+(line[8:].replace(":", ""))<br/>            Rachel=Rachel+re.sub(r'\(.*\)', '', string)<br/>        elif line.startswith('Ross:'):<br/>            string=Scene.replace("\n", "")+"*"+(line[6:].replace(":", ""))<br/>            Ross=Ross+re.sub(r'\(.*\)', '', string)<br/>        elif line.startswith('Monica:'):<br/>            string=Scene.replace("\n", "")+"*"+(line[8:].replace(":", ""))<br/>            Monica=Monica+re.sub(r'\(.*\)', '', string)<br/>        elif line.startswith('Chandler:'):<br/>            string=Scene.replace("\n", "")+"*"+(line[10:].replace(":", ""))<br/>            Chandler=Chandler+re.sub(r'\(.*\)', '', string)<br/>        if line.startswith('Phoebe:'):<br/>            string=Scene.replace("\n", "")+"*"+(line[8:].replace(":", ""))<br/>            Phoebe=Phoebe+re.sub(r'\(.*\)', '', string)<br/>        if line.startswith('Joey:'):<br/>            string=Scene.replace("\n", "")+"*"+(line[6:].replace(":", ""))<br/>            Joey=Joey+re.sub(r'\(.*\)', '', string)</span><span id="d019" class="nl kn iq nh b gy nq nn l no np">friends_chars['RACHEL']=Rachel<br/>friends_chars['ROSS']=Ross<br/>friends_chars['MONICA']=Monica<br/>friends_chars['PHOEBE']=Phoebe<br/>friends_chars['CHANDLER']=Chandler<br/>friends_chars['JOEY']=Joey</span><span id="cbd3" class="nl kn iq nh b gy nq nn l no np">s=pd.Series(friends_chars['RACHEL'].split('\n'))<br/>df1 = pd.DataFrame({'Text':s.values})<br/>df1 = pd.DataFrame(df1.Text.str.split('*',1).tolist(), columns = ['Scene','Text'])<br/>s=df1.Text<br/>df1=  pd.DataFrame(df1.Scene.str.split(',',1).tolist(),<br/>                                   columns = ['Location','Scene'])<br/>df1['Text']=s<br/>df1['Speaker']='Rachel'<br/>df1['Season']='1'<br/>df1.head(20)</span><span id="1cd1" class="nl kn iq nh b gy nq nn l no np">s2=pd.Series(friends_chars['ROSS'].split('\n'))<br/>df2 = pd.DataFrame({'Text':s2.values})<br/>df2 = pd.DataFrame(df2.Text.str.split('*',1).tolist(), columns = ['Scene','Text'])<br/>s=df2.Text<br/>df2=  pd.DataFrame(df2.Scene.str.split(',',1).tolist(),<br/>                                   columns = ['Location','Scene'])<br/>df2['Text']=s<br/>df2['Speaker']='Ross'<br/>df2['Season']='1' <br/>df2.head(20)</span><span id="404a" class="nl kn iq nh b gy nq nn l no np">s3=pd.Series(friends_chars['MONICA'].split('\n'))<br/>df3 = pd.DataFrame({'Text':s3.values})<br/>df3 = pd.DataFrame(df3.Text.str.split('*',1).tolist(), columns = ['Scene','Text'])<br/>s=df3.Text<br/>df3=  pd.DataFrame(df3.Scene.str.split(',',1).tolist(),<br/>                                   columns = ['Location','Scene'])<br/>df3['Text']=s<br/>df3['Speaker']='Monica'<br/>df3['Season']='1'                         <br/>df3.head(20)</span><span id="dc49" class="nl kn iq nh b gy nq nn l no np">s4=pd.Series(friends_chars['JOEY'].split('\n'))<br/>df4 = pd.DataFrame({'Text':s4.values})<br/>df4 = pd.DataFrame(df4.Text.str.split('*',1).tolist(), columns = ['Scene','Text'])<br/>s=df4.Text<br/>df4=  pd.DataFrame(df4.Scene.str.split(',',1).tolist(),<br/>                                   columns = ['Location','Scene'])<br/>df4['Text']=s<br/>df4['Speaker']='Joey'<br/>df4['Season']='1'                            <br/>df4.head(20)</span><span id="19f4" class="nl kn iq nh b gy nq nn l no np">s5=pd.Series(friends_chars['PHOEBE'].split('\n'))<br/>df5 = pd.DataFrame({'Text':s5.values})<br/>df5 = pd.DataFrame(df5.Text.str.split('*',1).tolist(), columns = ['Scene','Text'])<br/>s=df5.Text<br/>df5=  pd.DataFrame(df5.Scene.str.split(',',1).tolist(),<br/>                                   columns = ['Location','Scene'])<br/>df5['Text']=s<br/>df5['Speaker']='Phoebe'<br/>df5['Season']='1'                           <br/>df5.head(20)</span><span id="2793" class="nl kn iq nh b gy nq nn l no np">s6=pd.Series(friends_chars['CHANDLER'].split('\n'))<br/>df6 = pd.DataFrame({'Text':s6.values})<br/>df6 = pd.DataFrame(df6.Text.str.split('*',1).tolist(), columns = ['Scene','Text'])<br/>s=df6.Text<br/>df6=  pd.DataFrame(df6.Scene.str.split(',',1).tolist(),<br/>                                   columns = ['Location','Scene'])<br/>df6['Text']=s<br/>df6['Speaker']='Chandler'<br/>df6['Season']='1'                            <br/>df6.head(20)</span><span id="c482" class="nl kn iq nh b gy nq nn l no np">df_1 = pd.concat([df1, df2,df3,df4,df5,df6])<br/>df_1 = df_1.sample(frac=1).reset_index(drop=True)</span><span id="6f50" class="nl kn iq nh b gy nq nn l no np">df_1.head()<br/>df2.head()</span></pre><p id="2648" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">6.我将这十个季节的内容结合起来，并将内容写入。csv 文件，这是我们创建的数据集。</p><pre class="lq lr ls lt gt ng nh ni nj aw nk bi"><span id="5c36" class="nl kn iq nh b gy nm nn l no np">df = pd.concat([df_10, df_9,df_8,df_7,df_6,df_5,df_4,df_3,df_2,df_1])<br/>df = df.sample(frac=1).reset_index(drop=True)</span><span id="0af9" class="nl kn iq nh b gy nq nn l no np">df.to_csv('friends_dataset.csv')</span></pre><p id="9061" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">同样，可以从在线提供的网络脚本中为所有想要的电视情景喜剧创建数据集。</p><h1 id="0ce9" class="km kn iq bd ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj bi translated"><strong class="ak">备注:</strong></h1><ol class=""><li id="4870" class="mr ms iq jp b jq lk ju ll jy nr kc ns kg nt kk mw mx my mz bi translated">创建这个数据集的动机是有一个简单的方法来为电视情景喜剧创建结构化数据，我们今天只有非结构化的 web 脚本可用。</li></ol><p id="1e0d" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">2.如果你正在使用这个数据集或方法，请注明链接(【https://github.com/shilpibhattacharyya/Friends_Analysis】T2)或这篇文章的链接。</p></div></div>    
</body>
</html>