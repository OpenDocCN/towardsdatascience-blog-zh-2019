<html>
<head>
<title>My Experiments In Replacing Deep Learning Backpropagation (SGD) With A Genetic Algorithm</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">我用遗传算法代替深度学习反向传播(SGD)的实验</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/my-experiments-in-replacing-deep-learning-backpropagation-sgd-with-a-genetic-algorithm-c6e308382926?source=collection_archive---------19-----------------------#2019-10-08">https://towardsdatascience.com/my-experiments-in-replacing-deep-learning-backpropagation-sgd-with-a-genetic-algorithm-c6e308382926?source=collection_archive---------19-----------------------#2019-10-08</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><p id="ffe9" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">本文描述了我用遗传算法(GA)取代深度学习模型中的随机梯度下降(SGD)和反向传播的实验。</p><p id="af83" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">作为一个剧透，让我说，这些早期的实验并没有表现出接近 SGD。然而，我在结论中对此说得更多。</p><h2 id="b3ab" class="ko kp it bd kq kr ks dn kt ku kv dp kw kb kx ky kz kf la lb lc kj ld le lf lg bi translated">语境</h2><p id="27a0" class="pw-post-body-paragraph jq jr it js b jt lh jv jw jx li jz ka kb lj kd ke kf lk kh ki kj ll kl km kn im bi translated">出于本文的目的，我将使用下图来提供今天在训练深度学习模型时使用的突出流程。</p><figure class="ln lo lp lq gt lr gh gi paragraph-image"><div class="gh gi lm"><img src="../Images/7f7a3549ca8f1e1ab2396ba8890aec59.png" data-original-src="https://miro.medium.com/v2/resize:fit:1312/format:webp/1*Ye5M9lfDq1z9vTe-9a9SEw.png"/></div></figure><p id="2c10" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">成本函数通过比较训练结果和预期结果(基本事实)来计算误差量(<strong class="js iu"> <em class="lu"> E </em> </strong>)。反过来，SGD 将更改应用于模型参数，以改进下一个训练结果。值得注意的是，模型中使用的函数必须是可微的，以便 SGD 搜索最优解。</p><p id="d7ef" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">参数更新循环继续，直到达到所需的精度(图中未显示)。</p><p id="cfcc" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">我将用<strong class="js iu"> <em class="lu"> W </em> </strong>来表示模型参数集。深度学习模型可以轻松包含数千万(如果不是数亿)的参数。训练完成后，<strong class="js iu"> <em class="lu"> W </em> </strong>将形成训练好的模型的基础。</p><h2 id="800a" class="ko kp it bd kq kr ks dn kt ku kv dp kw kb kx ky kz kf la lb lc kj ld le lf lg bi translated">遗传算法方法概述</h2><p id="a991" class="pw-post-body-paragraph jq jr it js b jt lh jv jw jx li jz ka kb lj kd ke kf lk kh ki kj ll kl km kn im bi translated">下图显示了 SGD 被 GA 替换，单个的<strong class="js iu"> <em class="lu"> W </em> </strong>被群体<strong class="js iu"> <em class="lu"> W </em> </strong>替换，我将用<strong class="js iu">[<em class="lu">W</em></strong>来表示。</p><figure class="ln lo lp lq gt lr gh gi paragraph-image"><div class="gh gi lv"><img src="../Images/6e02fef4f04c96df7326af93f1c38754.png" data-original-src="https://miro.medium.com/v2/resize:fit:1282/format:webp/1*p0RW19vl_23Cm2DajRWeHw.png"/></div></figure><p id="5990" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">成本函数被移除，并由精度函数代替，该精度函数在 GA 术语中提供适应度函数。适合度值是给定一些标准的群体成员的适合度。适合度是一个 0 到 1 的值，0 表示最适合。我用【T24【F】来代表<strong class="js iu"> [ <em class="lu"> W </em> ]每个成员的适合度。</strong></p><p id="651f" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">注意，在 GA 方法中，模型函数不必是可微的，因为 GA 不会使用函数导数来收敛于解。</p><h2 id="bad3" class="ko kp it bd kq kr ks dn kt ku kv dp kw kb kx ky kz kf la lb lc kj ld le lf lg bi translated">遗传算法概述</h2><p id="0fca" class="pw-post-body-paragraph jq jr it js b jt lh jv jw jx li jz ka kb lj kd ke kf lk kh ki kj ll kl km kn im bi translated">有许多关于 GAs 的学术性和详细的书籍，例如，Goldberg 的“搜索、优化和机器学习中的遗传算法”。在这里，我会停留在(非常)高的水平。</p><p id="deb5" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">给定一个种群<strong class="js iu"> [ <em class="lu"> W </em> ] </strong>，以及种群中每个成员的适应度值<strong class="js iu"> [ <em class="lu"> F </em> ] </strong>，GA 将决定下一代种群的构成。</p><p id="5cfc" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu"><em class="lu">W</em></strong>T5】下一个=<strong class="js iu"><em class="lu">GA</em></strong>(<strong class="js iu"><em class="lu">W</em></strong><em class="lu">当前</em>，<strong class="js iu"><em class="lu">F</em></strong><em class="lu">当前</em>)</p><p id="df4a" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">一个简单的遗传算法可以描述为:</p><ol class=""><li id="f6b7" class="lw lx it js b jt ju jx jy kb ly kf lz kj ma kn mb mc md me bi translated">选择——将适应度作为一个偏差来配对成员</li><li id="0156" class="lw lx it js b jt mf jx mg kb mh kf mi kj mj kn mb mc md me bi translated">组合(combination )-组合所选对以创建下一代。这也被称为交叉，父母的基因在下一代中交叉。</li><li id="f73f" class="lw lx it js b jt mf jx mg kb mh kf mi kj mj kn mb mc md me bi translated">突变——在释放新群体之前，应用(少量)随机突变</li></ol><h2 id="cbdf" class="ko kp it bd kq kr ks dn kt ku kv dp kw kb kx ky kz kf la lb lc kj ld le lf lg bi translated">实验</h2><p id="d5df" class="pw-post-body-paragraph jq jr it js b jt lh jv jw jx li jz ka kb lj kd ke kf lk kh ki kj ll kl km kn im bi translated">我最初从一个简单的 XOR 问题开始，测试 GA 的流程。GA 确实相对较快地收敛于一个解决方案。然而，对于这篇文章，我将描述一个更实质性的问题。</p><p id="f783" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">该实验基于 TensorFlow MNIST 深度示例(mnist _ Deep . py as found the tensor flow GitHub repos)。这是一个用于识别 MNIST 手写数字数据集的深度卷积神经网络。该模型包含数千万个参数；我认为这将是一个很好的非玩具的例子。</p><p id="9ff1" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">我将所有的模型参数(权重和偏差)外化到 TensorFlow 变量中，这样就可以很容易地操纵 TensorFlow 张量之外的值。使用“feed_dict”将参数<strong class="js iu"> <em class="lu"> W </em> </strong>载入 TensorFlow 模型图。</p><p id="d539" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">人口规模参数化为<strong class="js iu"> <em class="lu"> N </em> </strong>。使用<code class="fe mk ml mm mn b">numpy.random.randn</code>(平均值为 0 且方差为 1 的高斯分布)初始化<strong class="js iu"><em class="lu"/></strong>N 个起始模型中的每一个。</p><p id="d271" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">然后，对于<strong class="js iu"> [ <em class="lu"> W </em> ] </strong>中的每个<strong class="js iu"> <em class="lu"> W </em> </strong>，计算适应度值。要运行的代数是<strong class="js iu"> <em class="lu"> G </em> </strong>(或者直到解收敛)。</p><pre class="ln lo lp lq gt mo mn mp mq aw mr bi"><span id="ffe6" class="ko kp it mn b gy ms mt l mu mv">for generation = 1 to G<br/>   for index = 1 to N<br/>       F[index] = session.run(accuracy, feed_dict = W[index])</span></pre><p id="d61f" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">计算下一代<strong class="js iu"><em class="lu">W</em></strong>的过程是:</p><pre class="ln lo lp lq gt mo mn mp mq aw mr bi"><span id="ef35" class="ko kp it mn b gy ms mt l mu mv">Random pairing of [W], biased towards fitter members</span><span id="4b31" class="ko kp it mn b gy mw mt l mu mv">Crossover of each pair in [W]</span><span id="8a68" class="ko kp it mn b gy mw mt l mu mv">Random mutation of each member of [W]</span></pre><h2 id="c2a5" class="ko kp it bd kq kr ks dn kt ku kv dp kw kb kx ky kz kf la lb lc kj ld le lf lg bi translated">交叉</h2><p id="5608" class="pw-post-body-paragraph jq jr it js b jt lh jv jw jx li jz ka kb lj kd ke kf lk kh ki kj ll kl km kn im bi translated">每个<strong class="js iu"> <em class="lu"> W </em> </strong>由一组矩阵形成，其中每个矩阵代表机器学习模型的一部分(权重和偏差)。给定一对中的两个成员:</p><pre class="ln lo lp lq gt mo mn mp mq aw mr bi"><span id="7778" class="ko kp it mn b gy ms mt l mu mv">Wa -&gt; [a1, a2, a3, ...] # where each a is a matrix<br/>Wb -&gt; [b1, b2, b3, ...] # where each b is a matrix </span></pre><p id="43ba" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">有许多方法可以跨越 Wa 和 Wb。在这个实验中，我选择随机交叉相应矩阵中的元素。例如:</p><pre class="ln lo lp lq gt mo mn mp mq aw mr bi"><span id="4a97" class="ko kp it mn b gy ms mt l mu mv">mask = random 0 or 1 in shape of a1<br/>mask_inv = opposite of mask</span><span id="bc93" class="ko kp it mn b gy mw mt l mu mv">new_a1 = a1 * mask + b1 * mask_inv<br/>new_b1 = b1 * mask + a1 * mask_inv</span><span id="0617" class="ko kp it mn b gy mw mt l mu mv">and so on for (a2,b2), (a3, b3), etc.</span></pre><h2 id="7bf3" class="ko kp it bd kq kr ks dn kt ku kv dp kw kb kx ky kz kf la lb lc kj ld le lf lg bi translated">变化</h2><p id="d988" class="pw-post-body-paragraph jq jr it js b jt lh jv jw jx li jz ka kb lj kd ke kf lk kh ki kj ll kl km kn im bi translated">作为 GA 超参数，有一个“变异量”，但变异量本身根据当前解收敛的远近而变化。最终，我发现理解和应用突变是一个挑战。</p><h2 id="83e7" class="ko kp it bd kq kr ks dn kt ku kv dp kw kb kx ky kz kf la lb lc kj ld le lf lg bi translated">结果</h2><p id="168d" class="pw-post-body-paragraph jq jr it js b jt lh jv jw jx li jz ka kb lj kd ke kf lk kh ki kj ll kl km kn im bi translated">第一张图显示了 300 代 200 人的种群规模。</p><figure class="ln lo lp lq gt lr gh gi paragraph-image"><div role="button" tabindex="0" class="my mz di na bf nb"><div class="gh gi mx"><img src="../Images/63e0d13f3733c8e75797533f927d740e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*rxAOJ0vAoNrEYkKmItc10A.png"/></div></div></figure><p id="0e95" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">上图显示了每一代的最佳结果(橙色)。回想一下，MNIST 数据有 10 位数字，因此在上述范围内随机选择 0.9。随着跑步的进行，有一个明显的拉平。对于每一代，最好的模型也是根据验证数据运行的(数据放在一边，不被视为训练的一部分)。</p><p id="5943" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">尽管精确度显然不是最先进的，但在某种程度上，遗传算法能够筛选数百万个参数，并随着时间的推移创建更好的模型；都没有反向传播。</p><p id="c3f0" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">在同一次运行中，下图描绘了每代中最佳模型的 100 个数值。图表显示了最初的波动性和随后的稳定值:</p><figure class="ln lo lp lq gt lr gh gi paragraph-image"><div role="button" tabindex="0" class="my mz di na bf nb"><div class="gh gi nc"><img src="../Images/4f1fd95d8c26567fd9b22e4d93117c07.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*tILueX7FCJeBBny6a-g4XQ.png"/></div></div></figure><p id="0af3" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">挑战在于早期的稳定会导致性能的上限，但是不稳定会导致在解决方案空间中的随机行走和没有收敛。突变的程度应该是达到平衡的一个因素。</p><p id="15be" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">下图显示了将人口规模增加到 1000 的效果。验证精度从 0.65 提高到大约 0.5。然而，验证准确性似乎在训练准确性之前趋于平稳。</p><figure class="ln lo lp lq gt lr gh gi paragraph-image"><div role="button" tabindex="0" class="my mz di na bf nb"><div class="gh gi nd"><img src="../Images/cb7a5bd64b80b65633c58493cd8b8127.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*JUK4kvCqPi07RkXOhTl-wg.png"/></div></div></figure><h2 id="4de8" class="ko kp it bd kq kr ks dn kt ku kv dp kw kb kx ky kz kf la lb lc kj ld le lf lg bi translated">结论和讨论</h2><p id="7bfa" class="pw-post-body-paragraph jq jr it js b jt lh jv jw jx li jz ka kb lj kd ke kf lk kh ki kj ll kl km kn im bi translated">公平地说，200 人甚至 1000 人的人口规模可能太小，不足以取得有意义的结果。也许人口数量应该以百万计。</p><p id="7548" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">除了人口规模，还有其他几个超参数可以考虑。一些例子是:</p><ol class=""><li id="b50f" class="lw lx it js b jt ju jx jy kb ly kf lz kj ma kn mb mc md me bi translated">排名和成对选择。有多少偏向于更适合的成员？在我的实验中，我提升了表现最好的人，这样他们的影响力就超过了严格意义上的健康水平。</li><li id="c3cc" class="lw lx it js b jt mf jx mg kb mh kf mi kj mj kn mb mc md me bi translated">突变。变异有多大？如何应用？是否随收敛而变化？</li><li id="ef45" class="lw lx it js b jt mf jx mg kb mh kf mi kj mj kn mb mc md me bi translated">交叉。两个模型如何交叉？我选择在矩阵粒度上均匀交叉。两者中较强的一方应该保留更多的价值观吗？矩阵应该被分割然后连接吗？交叉是否应该定义在整个矩阵的交换上？</li><li id="8ac9" class="lw lx it js b jt mf jx mg kb mh kf mi kj mj kn mb mc md me bi translated">批量大小。我尝试了各种批量大小，最终确定为 64。</li><li id="5c24" class="lw lx it js b jt mf jx mg kb mh kf mi kj mj kn mb mc md me bi translated">过度拟合。看一看 1000 人的运行，可以看到训练结果可能正在改善，而验证结果已经稳定在更高的值。</li></ol><p id="fd98" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">对我来说，接下来的步骤还没有确定，因为验证收敛的平稳化一直是一个难以克服的障碍(至少在我的计算机能力范围内，MacBook Pro 2018)。</p><p id="482f" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">如果你已经做到这一步，感谢你的关注和时间，我希望你喜欢这篇文章！</p></div></div>    
</body>
</html>