<html>
<head>
<title>Brain Tumor Segmentation using Pyramid Scene Parsing (PSPNet)</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">基于金字塔场景分析的脑肿瘤分割</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/brain-tumour-segmentation-using-pyramid-scene-parsing-pspnet-198168d22235?source=collection_archive---------17-----------------------#2019-06-14">https://towardsdatascience.com/brain-tumour-segmentation-using-pyramid-scene-parsing-pspnet-198168d22235?source=collection_archive---------17-----------------------#2019-06-14</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><p id="ae9f" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><em class="ko">用数据做酷事！</em></p><h1 id="8efb" class="kp kq it bd kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm bi translated"><strong class="ak">简介</strong></h1><p id="b829" class="pw-post-body-paragraph jq jr it js b jt ln jv jw jx lo jz ka kb lp kd ke kf lq kh ki kj lr kl km kn im bi translated">癌症是自古以来人类面临的最致命的疾病之一。<a class="ae ls" href="https://www.cancer.ca/en/cancer-information/cancer-101/cancer-statistics-at-a-glance/?region=on" rel="noopener ugc nofollow" target="_blank">全世界每年有近 30%的人口死于癌症。如果肿瘤在早期被发现，存活的机会会大大增加。深度学习(CNN)已经改变了计算机视觉，包括对医学图像的诊断。在这篇文章中，我们将利用 CNN 的力量从脑 MRI 图像中检测和分割肿瘤。</a></p><p id="3a9f" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">见下图中带有肿瘤的脑部 MRI 图像示例和分割结果。左图是绿色肿瘤的脑部核磁共振扫描。右图用红色显示了肿瘤的机器预测。这是惊人的准确！</p><figure class="lu lv lw lx gt ly gh gi paragraph-image"><div class="gh gi lt"><img src="../Images/75873ce0ef87e00ca8628faf6ceb36b4.png" data-original-src="https://miro.medium.com/v2/resize:fit:994/format:webp/1*zNQ5DiT6VCC2UzDhYPHlvg.jpeg"/></div><figcaption class="mb mc gj gh gi md me bd b be z dk">Tumor prediction example</figcaption></figure><p id="1642" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">我们已经与初创公司合作，使用语义分割构建各种应用程序。请联系我们，了解更多信息。</p><h1 id="7c58" class="kp kq it bd kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm bi translated"><strong class="ak">语义分割</strong></h1><p id="0085" class="pw-post-body-paragraph jq jr it js b jt ln jv jw jx lo jz ka kb lp kd ke kf lq kh ki kj lr kl km kn im bi translated">语义分割是将图像中的像素标记为一类。在上图中，我们将图像中的所有像素标记为肿瘤或背景类。已经公布了许多基于深度学习的高效语义分割方法，例如(按时间顺序) :</p><ol class=""><li id="c878" class="mf mg it js b jt ju jx jy kb mh kf mi kj mj kn mk ml mm mn bi translated"><a class="ae ls" href="https://people.eecs.berkeley.edu/~jonlong/long_shelhamer_fcn.pdf" rel="noopener ugc nofollow" target="_blank"> FCN </a></li><li id="4038" class="mf mg it js b jt mo jx mp kb mq kf mr kj ms kn mk ml mm mn bi translated"><a class="ae ls" href="https://lmb.informatik.uni-freiburg.de/people/ronneber/u-net/" rel="noopener ugc nofollow" target="_blank"> UNet </a></li><li id="56ea" class="mf mg it js b jt mo jx mp kb mq kf mr kj ms kn mk ml mm mn bi translated"><a class="ae ls" href="http://mi.eng.cam.ac.uk/projects/segnet/" rel="noopener ugc nofollow" target="_blank"> SegNet </a></li><li id="e00d" class="mf mg it js b jt mo jx mp kb mq kf mr kj ms kn mk ml mm mn bi translated">扩张的回旋</li><li id="e9f0" class="mf mg it js b jt mo jx mp kb mq kf mr kj ms kn mk ml mm mn bi translated">深度实验室(v1 和 v2)</li><li id="1260" class="mf mg it js b jt mo jx mp kb mq kf mr kj ms kn mk ml mm mn bi translated">精制网</li><li id="bb78" class="mf mg it js b jt mo jx mp kb mq kf mr kj ms kn mk ml mm mn bi translated">金字塔场景解析网络</li><li id="690f" class="mf mg it js b jt mo jx mp kb mq kf mr kj ms kn mk ml mm mn bi translated"><a class="ae ls" href="https://arxiv.org/abs/1706.05587" rel="noopener ugc nofollow" target="_blank"> DeepLab v3 </a></li></ol><p id="5bc4" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">对于这个博客，我们选择了 PSP-Net，因为它非常有效，并且比许多先进的方法如 U-net，FCN，DeepLab (v1，v2)和扩张卷积等都要好。</p><p id="3750" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">DeepLabV3 是另一个流行且强大的模型。我最近写了一篇关于如何使用 DeepLabV3 以 30 FPS 进行<a class="ae ls" href="https://deeplearninganalytics.org/semantic-segmentation/" rel="noopener ugc nofollow" target="_blank">语义分割的博客</a></p><p id="62cc" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">要了解以上列出的不同分段架构的更多信息，请参考这篇<a class="ae ls" href="http://blog.qure.ai/notes/semantic-segmentation-deep-learning-review" rel="noopener ugc nofollow" target="_blank">帖子</a>。</p><h1 id="f9ae" class="kp kq it bd kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm bi translated"><strong class="ak">金字塔场景解析网</strong></h1><p id="ad8c" class="pw-post-body-paragraph jq jr it js b jt ln jv jw jx lo jz ka kb lp kd ke kf lq kh ki kj lr kl km kn im bi translated">最新的场景解析框架大多基于全卷积网络(FCN)。基于深度卷积神经网络(CNN)的方法促进了动态对象理解，但仍然面临着考虑不同场景和无限制词汇的挑战。一个例子是船被误认为汽车。这些错误是由于对象的相似外观造成的。但是当查看关于场景被描述为河边的船屋之前的上下文的图像时，应该产生正确的预测。</p><p id="d2b0" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">准确的场景分类依赖于对全局场景类别的先验知识。<strong class="js iu">金字塔池模块</strong>通过应用具有大内核的池层来帮助捕获这些信息。使用膨胀卷积(参考:<a class="ae ls" href="http://blog.qure.ai/notes/semantic-segmentation-deep-learning-review#dilation" rel="noopener ugc nofollow" target="_blank">膨胀卷积论文</a>)对 Resnet 进行修改，并增加了一个金字塔池模块。该模块将来自 ResNet 的特征映射与并行池层的上采样输出连接起来，其中内核覆盖整个图像、图像的一半和一小部分。</p><p id="fcad" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">下图描述了 PSPNet 架构。你可以在他们的论文<a class="ae ls" href="https://arxiv.org/pdf/1612.01105.pdf" rel="noopener ugc nofollow" target="_blank">这里</a>中读到更多关于 PSPNet 的内容。</p><figure class="lu lv lw lx gt ly gh gi paragraph-image"><div role="button" tabindex="0" class="mu mv di mw bf mx"><div class="gh gi mt"><img src="../Images/c24e7ab4d87e70bb6e1c03700c1820c1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*70KDRVI-d0wy8uB2"/></div></div><figcaption class="mb mc gj gh gi md me bd b be z dk">PSPNet Architecture</figcaption></figure><h1 id="425d" class="kp kq it bd kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm bi translated">利用 PSPNet 建立脑图像分割模型</h1><h2 id="988e" class="my kq it bd kr mz na dn kv nb nc dp kz kb nd ne ld kf nf ng lh kj nh ni ll nj bi translated"><strong class="ak">数据集</strong></h2><p id="0271" class="pw-post-body-paragraph jq jr it js b jt ln jv jw jx lo jz ka kb lp kd ke kf lq kh ki kj lr kl km kn im bi translated">数据集是从<a class="ae ls" href="https://www.kaggle.com/mateuszbuda/lgg-mri-segmentation/version/2" rel="noopener ugc nofollow" target="_blank"> Kaggle </a>获得的。之所以选择这种方法，是因为标记的数据是二进制掩模图像的形式，易于处理并用于训练和测试。或者，这款来自 VGG 集团的基于网络的注释工具可以用来标记自定义数据集。</p><p id="413d" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">数据集遵循以下文件夹层次结构:</p><p id="cad7" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">资料组</p><p id="c1f1" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">| _ images—png 格式的 RGB 图像</p><p id="95ec" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">| _ masks 屏蔽 png 格式的 RGB 图像，其中区域填充有各自的标签值。</p><p id="25b9" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">我们的标签是:1 代表肿瘤，0 代表其他</p><p id="7d0d" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">例如:</p><p id="af73" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">假设像素(10，10)属于肿瘤，它包含值 1。</p><h2 id="6d01" class="my kq it bd kr mz na dn kv nb nc dp kz kb nd ne ld kf nf ng lh kj nh ni ll nj bi translated"><strong class="ak">培训框架</strong></h2><p id="285e" class="pw-post-body-paragraph jq jr it js b jt ln jv jw jx lo jz ka kb lp kd ke kf lq kh ki kj lr kl km kn im bi translated">虽然存在许多令人惊叹的框架来使用 Keras 培训和评估语义分割模型，但以下 repo 因其易用性、支持的不同模型数量以及最新的文档而脱颖而出:</p><p id="e0fe" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><a class="ae ls" href="https://github.com/divamgupta/image-segmentation-keras" rel="noopener ugc nofollow" target="_blank">https://github.com/divamgupta/image-segmentation-keras</a></p><p id="cd40" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">我们选择了“vgg_pspnet”，这是一个在预训练的 vgg 主干网上实现的 pspnet。</p><p id="825a" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">要遵循的步骤是:</p><ul class=""><li id="0289" class="mf mg it js b jt ju jx jy kb mh kf mi kj mj kn nk ml mm mn bi translated">https://github.com/divamgupta/image-segmentation-keras.git</li><li id="7e1d" class="mf mg it js b jt mo jx mp kb mq kf mr kj ms kn nk ml mm mn bi translated">按照 repo 自述文件中的说明进行安装</li></ul><p id="e4bd" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">一旦安装了回购，就可以开始培训了！</p><pre class="lu lv lw lx gt nl nm nn no aw np bi"><span id="38f2" class="my kq it nm b gy nq nr l ns nt"># Navigate to the <strong class="nm iu">Semantic_segmentation/image-segmentation-keras</strong> folder</span><span id="f12f" class="my kq it nm b gy nu nr l ns nt"><strong class="nm iu">import keras</strong></span><span id="c33e" class="my kq it nm b gy nu nr l ns nt"><strong class="nm iu">from keras.models import model_from_json</strong></span><span id="ba79" class="my kq it nm b gy nu nr l ns nt"><strong class="nm iu">import keras_segmentation as ks</strong></span><span id="3f17" class="my kq it nm b gy nu nr l ns nt"># Initialise the pretrained model .</span><span id="e147" class="my kq it nm b gy nu nr l ns nt"># Note that the input height and width need not be same as image height and width since the network takes care of the input sizes.</span><span id="1836" class="my kq it nm b gy nu nr l ns nt"><strong class="nm iu">model = ks.models.pspnet.vgg_pspnet( n_classes=2,</strong></span><span id="f31f" class="my kq it nm b gy nu nr l ns nt"><strong class="nm iu">input_height=384,</strong></span><span id="62e7" class="my kq it nm b gy nu nr l ns nt"><strong class="nm iu">input_width=384)</strong></span><span id="e28f" class="my kq it nm b gy nu nr l ns nt"># Training</span><span id="d5eb" class="my kq it nm b gy nu nr l ns nt"><strong class="nm iu">model.train(</strong></span><span id="08d1" class="my kq it nm b gy nu nr l ns nt"><strong class="nm iu">train_images = “datasets/brain/images”,</strong></span><span id="2bfe" class="my kq it nm b gy nu nr l ns nt"><strong class="nm iu">train_annotations = “datasets/brain/masks”,</strong></span><span id="2e50" class="my kq it nm b gy nu nr l ns nt"><strong class="nm iu">checkpoints_path = “ckpts/brain” , epochs=50 ,</strong></span><span id="e1b3" class="my kq it nm b gy nu nr l ns nt"><strong class="nm iu">auto_resume_checkpoint = True,</strong></span><span id="c931" class="my kq it nm b gy nu nr l ns nt"><strong class="nm iu">steps_per_epoch = 50</strong></span><span id="71ea" class="my kq it nm b gy nu nr l ns nt"><strong class="nm iu">)</strong></span></pre><h2 id="35f2" class="my kq it bd kr mz na dn kv nb nc dp kz kb nd ne ld kf nf ng lh kj nh ni ll nj bi translated">通过训练好的模型运行推理</h2><pre class="lu lv lw lx gt nl nm nn no aw np bi"><span id="3195" class="my kq it nm b gy nq nr l ns nt"># Load Neural Network</span><span id="d14a" class="my kq it nm b gy nu nr l ns nt"><strong class="nm iu">model = ks.predict.model_from_checkpoint_path(‘ckpts/brain’)</strong></span><span id="fe46" class="my kq it nm b gy nu nr l ns nt"># Predicted output will be a mask image similar to the mask images specified in the input</span><span id="28db" class="my kq it nm b gy nu nr l ns nt"><strong class="nm iu">pred_mask = ks.predict.predict( model = model , inp = ‘image.png’ )</strong></span></pre><p id="1234" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">下面是我们在数据集的一个小子集上获得的结果。虽然数据集很容易过拟合，但高精度的结果显示了这种方法的潜力。</p><p id="4d44" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">图像顺序:原始图像(左)、预测遮罩(中)、覆盖遮罩边界(右)</p><figure class="lu lv lw lx gt ly gh gi paragraph-image"><div role="button" tabindex="0" class="mu mv di mw bf mx"><div class="gh gi nv"><img src="../Images/2b1efd47c14514439c89e480181d1a81.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*mpNEKAJu3QCABE-K"/></div></div></figure><figure class="lu lv lw lx gt ly gh gi paragraph-image"><div role="button" tabindex="0" class="mu mv di mw bf mx"><div class="gh gi nv"><img src="../Images/c4a0e22d72b8070c605e1f3a991f3564.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*0M0plODD3wIBShXP"/></div></div></figure><figure class="lu lv lw lx gt ly gh gi paragraph-image"><div role="button" tabindex="0" class="mu mv di mw bf mx"><div class="gh gi nv"><img src="../Images/37c6c9690c2abbf40455ac37c5196e56.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*76f2vp6lad8BLWnu"/></div></div></figure><figure class="lu lv lw lx gt ly gh gi paragraph-image"><div role="button" tabindex="0" class="mu mv di mw bf mx"><div class="gh gi nv"><img src="../Images/37928dc48f4b2b0bf93bb0d61791476f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*X56AzuVd-qQYLEgf"/></div></div></figure><h1 id="5535" class="kp kq it bd kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm bi translated"><strong class="ak">结论</strong></h1><p id="51e9" class="pw-post-body-paragraph jq jr it js b jt ln jv jw jx lo jz ka kb lp kd ke kf lq kh ki kj lr kl km kn im bi translated">希望你喜欢这个博客，并尝试自己的代码。这个博客表明，我们可以使用预训练的模型在半天的工作中获得良好的分割结果！它真正展示了基于深度学习的计算机视觉的力量。</p><p id="cf52" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">我们可以将该代码扩展到任何具有待分割特征的医学图像。例子包括不同种类的癌症肿瘤、微生物、骨折、洞等。</p><p id="b93f" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">我有自己的深度学习咨询公司，喜欢研究有趣的问题。我已经帮助许多初创公司部署了基于人工智能的创新解决方案。在 http://deeplearninganalytics.org/的<a class="ae ls" href="http://deeplearninganalytics.org/" rel="noopener ugc nofollow" target="_blank">入住我们的酒店。如果你有一个我们可以合作的项目，那么请通过我的网站或者在<strong class="js iu">info@deeplearninganalytics.org</strong>联系我</a></p><p id="9712" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">你也可以在<a class="ae ls" href="https://medium.com/@priya.dwivedi" rel="noopener">https://medium.com/@priya.dwivedi</a>看到我的其他作品</p><p id="e779" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu">参考文献:</strong></p><ul class=""><li id="a8bf" class="mf mg it js b jt ju jx jy kb mh kf mi kj mj kn nk ml mm mn bi translated"><a class="ae ls" href="https://arxiv.org/abs/1612.01105" rel="noopener ugc nofollow" target="_blank"> PSPNet </a></li><li id="7e76" class="mf mg it js b jt mo jx mp kb mq kf mr kj ms kn nk ml mm mn bi translated"><a class="ae ls" href="https://www.kaggle.com/mateuszbuda/lgg-mri-segmentation/version/2" rel="noopener ugc nofollow" target="_blank"> Kaggle 脑部 MRI 数据集</a></li><li id="f601" class="mf mg it js b jt mo jx mp kb mq kf mr kj ms kn nk ml mm mn bi translated"><a class="ae ls" rel="noopener" target="_blank" href="/semantic-segmentation-popular-architectures-dff0a75f39d0">语义分割</a></li></ul></div></div>    
</body>
</html>