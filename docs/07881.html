<html>
<head>
<title>Know about Categorical Encoding, even New Ones!</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">了解分类编码，甚至是新的编码！</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/know-about-categorical-encoding-even-new-ones-c266227b9cbd?source=collection_archive---------7-----------------------#2019-10-31">https://towardsdatascience.com/know-about-categorical-encoding-even-new-ones-c266227b9cbd?source=collection_archive---------7-----------------------#2019-10-31</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><p id="eb6d" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">对分类数据进行编码会对 ML 模型的性能产生影响。在本文中，我将向您介绍广泛的编码方法:最常用的<strong class="js iu"/>和最近使用的<strong class="js iu"/>。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi ko"><img src="../Images/e3e10b3663735b8b65007c0400c72dcd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*HqIsZrR1koS2GZJT"/></div></div><figcaption class="la lb gj gh gi lc ld bd b be z dk">Photo by <a class="ae le" href="https://unsplash.com/@patrickian4?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Patrick Fore</a> on <a class="ae le" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><h1 id="bb30" class="lf lg it bd lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc bi translated">介绍</h1><p id="8993" class="pw-post-body-paragraph jq jr it js b jt md jv jw jx me jz ka kb mf kd ke kf mg kh ki kj mh kl km kn im bi translated">在数据科学问题中，数据集通常会包含分类特征。分类变量通常包含固定数量的可能值。<br/>这些值中的每一个都被称为一个<strong class="js iu">电平。<br/> </strong>与分类变量相关的概率分布称为<strong class="js iu">分类分布</strong>(伯努利或多项式分布)。</p><p id="c264" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">不幸的是，大多数机器学习算法无法处理分类特征。因此，我们必须对这些变量进行编码，以收集尽可能多的信息。</p><p id="a9e2" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">本文旨在介绍其中的一些方法。在处理更复杂的方法之前，我们先介绍一种简单的技术。</p><p id="c130" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu">方法列表</strong>:</p><ul class=""><li id="f9b0" class="mi mj it js b jt ju jx jy kb mk kf ml kj mm kn mn mo mp mq bi translated">一键编码</li><li id="7bf3" class="mi mj it js b jt mr jx ms kb mt kf mu kj mv kn mn mo mp mq bi translated">标签编码</li><li id="c9f2" class="mi mj it js b jt mr jx ms kb mt kf mu kj mv kn mn mo mp mq bi translated">目标编码</li><li id="115a" class="mi mj it js b jt mr jx ms kb mt kf mu kj mv kn mn mo mp mq bi translated">特征散列</li><li id="a60d" class="mi mj it js b jt mr jx ms kb mt kf mu kj mv kn mn mo mp mq bi translated">证据的重要性</li><li id="067d" class="mi mj it js b jt mr jx ms kb mt kf mu kj mv kn mn mo mp mq bi translated">轻型 G-Boost 编码</li></ul></div><div class="ab cl mw mx hx my" role="separator"><span class="mz bw bk na nb nc"/><span class="mz bw bk na nb nc"/><span class="mz bw bk na nb"/></div><div class="im in io ip iq"><h1 id="19e1" class="lf lg it bd lh li nd lk ll lm ne lo lp lq nf ls lt lu ng lw lx ly nh ma mb mc bi translated"><strong class="ak">一键编码</strong></h1><p id="a9c8" class="pw-post-body-paragraph jq jr it js b jt md jv jw jx me jz ka kb mf kd ke kf mg kh ki kj mh kl km kn im bi translated">独热编码包括为给定定性变量的每个类别生成一个<strong class="js iu">布尔列</strong>。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi ni"><img src="../Images/3bcbfc0e0a18561bb60c82dc7b9a2e9b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*80tflY8LxDFRmkD16u25RQ.png"/></div></div></figure><h2 id="8170" class="nj lg it bd lh nk nl dn ll nm nn dp lp kb no np lt kf nq nr lx kj ns nt mb nu bi translated"><strong class="ak">一键编码的限制</strong></h2><p id="b100" class="pw-post-body-paragraph jq jr it js b jt md jv jw jx me jz ka kb mf kd ke kf mg kh ki kj mh kl km kn im bi translated">一键编码是对分类变量的一种非常流行的转换。然而，它<strong class="js iu">增加了</strong>数据的<strong class="js iu">维度(</strong>维度的诅咒)。<br/>当数据集中的定性变量有多种模态时，通过一键编码进行的转换将导致大小显著增加。这是不可取的，尤其是当原始数据集已经很大的时候。</p></div><div class="ab cl mw mx hx my" role="separator"><span class="mz bw bk na nb nc"/><span class="mz bw bk na nb nc"/><span class="mz bw bk na nb"/></div><div class="im in io ip iq"><h1 id="d979" class="lf lg it bd lh li nd lk ll lm ne lo lp lq nf ls lt lu ng lw lx ly nh ma mb mc bi translated">标签编码</h1><p id="3d05" class="pw-post-body-paragraph jq jr it js b jt md jv jw jx me jz ka kb mf kd ke kf mg kh ki kj mh kl km kn im bi translated">标签编码就是用一个介于<strong class="js iu"> 0 </strong>和<strong class="js iu"> n_classes -1 </strong>之间的值来替换一个类别值的过程(类别数)。然后，机器学习算法可以更好地决定应该如何操纵这些标签。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi nv"><img src="../Images/64865e04718e6926d07f5746ea0293a4.png" data-original-src="https://miro.medium.com/v2/resize:fit:772/format:webp/1*QQe-4476Oy3_dI1vhb3dDg.png"/></div></figure><h2 id="9b81" class="nj lg it bd lh nk nl dn ll nm nn dp lp kb no np lt kf nq nr lx kj ns nt mb nu bi translated"><strong class="ak">标签编码的限制</strong></h2><p id="9702" class="pw-post-body-paragraph jq jr it js b jt md jv jw jx me jz ka kb mf kd ke kf mg kh ki kj mh kl km kn im bi translated">这里的问题是模型可能会误解数据。<br/>事实上，通过应用标签编码，分类特征可以被视为连续特征。</p><p id="73d0" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">这种方法的另一个限制是，具有高值的标签可能被认为比具有较低值的标签具有更高的优先级。</p></div><div class="ab cl mw mx hx my" role="separator"><span class="mz bw bk na nb nc"/><span class="mz bw bk na nb nc"/><span class="mz bw bk na nb"/></div><div class="im in io ip iq"><h1 id="ba89" class="lf lg it bd lh li nd lk ll lm ne lo lp lq nf ls lt lu ng lw lx ly nh ma mb mc bi translated"><strong class="ak">目标编码</strong></h1><p id="280b" class="pw-post-body-paragraph jq jr it js b jt md jv jw jx me jz ka kb mf kd ke kf mg kh ki kj mh kl km kn im bi translated">目标编码是指通过用特定目标的<strong class="js iu">后验概率</strong>和训练数据上所有目标的<strong class="js iu">先验概率</strong>的混合来替换特征，从而将标签转换成数字形式。<br/>好像我们在为每个目标值计算类别的频率。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi nw"><img src="../Images/e7a7b0f577411ba98784f968fa151c2c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*w1MYvwKMMdcJOs1mvWqCgw.png"/></div></div></figure><h2 id="bf60" class="nj lg it bd lh nk nl dn ll nm nn dp lp kb no np lt kf nq nr lx kj ns nt mb nu bi translated">标签编码的局限性</h2><p id="894a" class="pw-post-body-paragraph jq jr it js b jt md jv jw jx me jz ka kb mf kd ke kf mg kh ki kj mh kl km kn im bi translated">这种方法的主要缺点是它依赖于目标的分布，并且它的预测能力低于二进制编码方法。</p></div><div class="ab cl mw mx hx my" role="separator"><span class="mz bw bk na nb nc"/><span class="mz bw bk na nb nc"/><span class="mz bw bk na nb"/></div><div class="im in io ip iq"><h1 id="0883" class="lf lg it bd lh li nd lk ll lm ne lo lp lq nf ls lt lu ng lw lx ly nh ma mb mc bi translated">特征散列</h1><p id="ae59" class="pw-post-body-paragraph jq jr it js b jt md jv jw jx me jz ka kb mf kd ke kf mg kh ki kj mh kl km kn im bi translated">特征哈希，被称为<strong class="js iu">哈希技巧</strong>，是<strong class="js iu">降维</strong>和实用非参数估计的有效策略。</p><p id="0b47" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">但是，在我们深入这个方法的定义之前，我们将解释一下<strong class="js iu">数组</strong>和<strong class="js iu">链表</strong>的一些基本概念。</p><ul class=""><li id="75f7" class="mi mj it js b jt ju jx jy kb mk kf ml kj mm kn mn mo mp mq bi translated"><strong class="js iu">数组:<br/> </strong>数组是具有<strong class="js iu">固定大小</strong>的项目集合。所有元素都有索引，我们使用索引来访问数组中的特定项。</li></ul><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi nx"><img src="../Images/de7f67549dab9e0b739c1d8ecd758114.png" data-original-src="https://miro.medium.com/v2/resize:fit:1200/format:webp/1*MdgilQkp8O2nXVX94o2jAg.jpeg"/></div><figcaption class="la lb gj gh gi lc ld bd b be z dk"><a class="ae le" href="https://o7planning.org/fr/11567/tableaux-array-en-java" rel="noopener ugc nofollow" target="_blank">https://o7planning.org/fr/11567</a></figcaption></figure><ul class=""><li id="2677" class="mi mj it js b jt ju jx jy kb mk kf ml kj mm kn mn mo mp mq bi translated"><strong class="js iu">链表:<br/>T15】链表是数据元素的线性集合。当您不想担心数组大小时，这是一种非常流行的数据结构。<br/>链表可以<strong class="js iu">动态增长</strong>。我们简单地将下一个元素的地址存储在前一个元素中。这样，我们就可以把它长到任何大小。但是我们总是需要以一种<strong class="js iu">顺序的方式从一个元素到另一个元素。</strong></strong></li></ul><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi ny"><img src="../Images/ac9e459516ef1491212e862397155b2d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1100/format:webp/1*UsbQUXKfnQjTJzvmW_UWeA.png"/></div><figcaption class="la lb gj gh gi lc ld bd b be z dk"><a class="ae le" href="https://hackernoon.com/implementing-singly-linked-list-with-ruby-om2df3ya6" rel="noopener ugc nofollow" target="_blank">https://hackernoon.com/implementing-singly-linked-list-with-ruby-om2df3ya6</a></figcaption></figure><p id="1c20" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">这些概念构成了方法<strong class="js iu">散列技巧</strong>的基础。</p><p id="5dc7" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">顾名思义，我们将一个<strong class="js iu">散列函数</strong>应用于特性，并直接使用它们的散列值作为索引，而不是在关联数组中查找索引。</p><p id="cb1d" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">现在，我们将逐步解释“特征散列”算法<strong class="js iu"/>:</p><h2 id="8856" class="nj lg it bd lh nk nl dn ll nm nn dp lp kb no np lt kf nq nr lx kj ns nt mb nu bi translated">1 — MOD 功能:</h2><p id="af40" class="pw-post-body-paragraph jq jr it js b jt md jv jw jx me jz ka kb mf kd ke kf mg kh ki kj mh kl km kn im bi translated">我们为什么使用 MOD？我们需要创建一个散列表来存储 MOD 值。提醒指示了索引号<strong class="js iu">和</strong>，我们可以将分类值(<em class="nz">蓝色</em>))存储在散列表中。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi oa"><img src="../Images/39f5c9f352bd4c115a8c8bb84603d9c0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*kWNNkputkFSIggBKC0Isbw.png"/></div></div></figure><h2 id="b064" class="nj lg it bd lh nk nl dn ll nm nn dp lp kb no np lt kf nq nr lx kj ns nt mb nu bi translated">2-哈希表:</h2><p id="420f" class="pw-post-body-paragraph jq jr it js b jt md jv jw jx me jz ka kb mf kd ke kf mg kh ki kj mh kl km kn im bi translated">我们使用<strong class="js iu">散列位大小</strong>来指定创建散列表时使用的位数。例如，在我们的例子中，我们有 MOD 8，那么比特大小是 8。</p><p id="87da" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">如果我们对“blue”的哈希值 7 进行 mod 8，它会将值“Blue”存储在哈希表的索引 7 中，如下所示。</p><p id="8c8e" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">有时候，我们会遇到<strong class="js iu">碰撞</strong>的问题(比如“蓝色”&amp;“绿色”)，所以我们可以通过使用<strong class="js iu">分离链接</strong>来解决这个问题，分离链接是<strong class="js iu">表</strong>和<strong class="js iu">链表</strong>的组合。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi ob"><img src="../Images/a299b3b11c5932c06b5f77db79b103f9.png" data-original-src="https://miro.medium.com/v2/resize:fit:874/format:webp/1*p5YjyY0bOEutanwFVEP4_g.png"/></div></figure><h2 id="bc39" class="nj lg it bd lh nk nl dn ll nm nn dp lp kb no np lt kf nq nr lx kj ns nt mb nu bi translated">3-单独链接:</h2><p id="8c72" class="pw-post-body-paragraph jq jr it js b jt md jv jw jx me jz ka kb mf kd ke kf mg kh ki kj mh kl km kn im bi translated">在上面的例子中，我们需要在索引 7 中插入单词“Blue”和“Green”。因此，我们简单地在散列表的索引 7 中创建一个链表。</p><p id="7322" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu">数组</strong>和<strong class="js iu">链表</strong>的组合称为<strong class="js iu">分离链接</strong>。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi oc"><img src="../Images/1752d15a0945f48166460b5950bd3b09.png" data-original-src="https://miro.medium.com/v2/resize:fit:894/format:webp/1*nrbueG6UEo51dlsqjC1xOw.png"/></div></figure><h2 id="a141" class="nj lg it bd lh nk nl dn ll nm nn dp lp kb no np lt kf nq nr lx kj ns nt mb nu bi translated">3-特征散列:</h2><p id="9482" class="pw-post-body-paragraph jq jr it js b jt md jv jw jx me jz ka kb mf kd ke kf mg kh ki kj mh kl km kn im bi translated">综上所述，我们首先需要找出分类值(颜色)的<strong class="js iu">哈希值</strong>。然后，我们对哈希值应用<strong class="js iu"> MOD 函数</strong>，得到这些数字的提示。最后，我们创建<strong class="js iu">新特性集</strong>，并用相应的值填充表格。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi od"><img src="../Images/3777fa9a582b2a4634a406247b97c7f6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*dMMWR6IETmDMkeu9-j51dQ.png"/></div></div></figure><h2 id="f697" class="nj lg it bd lh nk nl dn ll nm nn dp lp kb no np lt kf nq nr lx kj ns nt mb nu bi translated">有用的小技巧！</h2><p id="1f5a" class="pw-post-body-paragraph jq jr it js b jt md jv jw jx me jz ka kb mf kd ke kf mg kh ki kj mh kl km kn im bi translated">通常，我们在<strong class="js iu">文本挖掘</strong>中使用哈希技巧，我们可以将可变长度的文本文档表示为等长的数字特征向量，并实现降维。</p><p id="1a86" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">下面我们来对比一下<strong class="js iu">单词袋</strong>法和<strong class="js iu">哈希法</strong>。<br/>单词包创建稀疏的特征矩阵。然而，特征散列技术可以用较少数量的特征构建预定义长度的向量。</p><p id="6d9e" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu">散列位大小</strong>取决于训练集中类别的<strong class="js iu">数量或 n 元语法</strong>词汇的<strong class="js iu">大小。如果词汇表很大，可能需要更多的空间来避免冲突。</strong></p></div><div class="ab cl mw mx hx my" role="separator"><span class="mz bw bk na nb nc"/><span class="mz bw bk na nb nc"/><span class="mz bw bk na nb"/></div><div class="im in io ip iq"><h1 id="515b" class="lf lg it bd lh li nd lk ll lm ne lo lp lq nf ls lt lu ng lw lx ly nh ma mb mc bi translated">证据的重要性</h1><p id="a67f" class="pw-post-body-paragraph jq jr it js b jt md jv jw jx me jz ka kb mf kd ke kf mg kh ki kj mh kl km kn im bi translated">证据权重(WOE)的目标是有效地识别分类预测值列表的证据权重值的最佳记录，并为每个类别分配唯一的证据权重值。</p><p id="e12f" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">证据权重可用于<strong class="js iu">组合</strong>变量组/级别，这个过程称为<strong class="js iu">粗分类</strong>。我们组合具有相似 WOE 的类别，然后用连续的 WOE 值替换这些类别。</p><p id="a536" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">现在，通过取<strong class="js iu">非事件</strong>的百分比与<strong class="js iu">事件</strong>的百分比之比的自然对数来计算 WOE。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi oe"><img src="../Images/8430c6baa6ad84a5df42d43fc42c8c5f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1064/format:webp/1*X8Q9cqpnma9qWRK7ghCkKg.png"/></div></figure><p id="b722" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">证据权重(WOE)是为<strong class="js iu">信贷</strong>和<strong class="js iu">金融部门</strong>开发的，主要用于创建预测贷款违约风险的更好模型(信贷风险模型)。</p><p id="e1fe" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">有一个经典的例子来突出 WEO 方法，在这里我们可以通过测量“<strong class="js iu">信用评分</strong>来区分<strong class="js iu">好客户</strong>和<strong class="js iu">坏客户</strong>。WOE 公式表示为:</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi of"><img src="../Images/5d9a939a71503bd18c51408493131679.png" data-original-src="https://miro.medium.com/v2/resize:fit:972/format:webp/1*r1VRPmu9H8Ke5bUCUt9rCQ.png"/></div></figure><ul class=""><li id="f11a" class="mi mj it js b jt ju jx jy kb mk kf ml kj mm kn mn mo mp mq bi translated"><strong class="js iu">商品的分布</strong>——集团内良好顾客的百分比</li><li id="d00e" class="mi mj it js b jt mr jx ms kb mt kf mu kj mv kn mn mo mp mq bi translated"><strong class="js iu">不良分布</strong>——不良客户在一个组中的百分比</li></ul><h2 id="dd74" class="nj lg it bd lh nk nl dn ll nm nn dp lp kb no np lt kf nq nr lx kj ns nt mb nu bi translated">分类转换:</h2><p id="2abe" class="pw-post-body-paragraph jq jr it js b jt md jv jw jx me jz ka kb mf kd ke kf mg kh ki kj mh kl km kn im bi translated">对于分类变量，我们计算每组中事件和非事件的数量和百分比。然后，我们通过取非事件百分比和事件百分比的自然对数来计算权重。</p><p id="9f95" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">我们将举一个<strong class="js iu">的例子</strong>来说清楚。</p><p id="fa0e" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">在本例中，我们有一个分类变量(<em class="nz">“特征”</em>)和三个组(<em class="nz">“A”、“B”和“C”</em>)以及一个二元目标变量(<em class="nz">“结果”</em>)和两个类(<em class="nz"> 1 和 0 </em>)。<br/>我们将目标变量中的 2 个类视为“事件”(类 1)和“非事件”(类 0)。然后我们计算 WOE 值，如下所示。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi og"><img src="../Images/2cbcfb388629b6dbe6b8dd05af43cc53.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*a5fjOdDthK-B3TNlGj0gWg.png"/></div></div></figure><p id="31aa" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu">转换变量</strong>将是一个具有 WOE 值的连续变量。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi oh"><img src="../Images/8273b29c66ec5b22adf465581b5d85a7.png" data-original-src="https://miro.medium.com/v2/resize:fit:686/format:webp/1*BnzBGu00LvYvyHDlCUAABg.png"/></div></figure><h2 id="e438" class="nj lg it bd lh nk nl dn ll nm nn dp lp kb no np lt kf nq nr lx kj ns nt mb nu bi translated">信息价值:</h2><p id="c260" class="pw-post-body-paragraph jq jr it js b jt md jv jw jx me jz ka kb mf kd ke kf mg kh ki kj mh kl km kn im bi translated">通常，我们将证据权重与信息值相关联，该信息值表示用于<strong class="js iu">将事件与非事件</strong>分开的变量的信息量。这有助于根据变量的重要性对其进行排序。<br/>使用以下公式计算 IV:</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi oi"><img src="../Images/b8cb1bc21bfc733a7c347057aec53376.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*99rtfOPPI0RwGw6QttCj8A.png"/></div></div></figure><p id="8469" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">我们计算上例中的 IV 值:</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi oj"><img src="../Images/016549931f0c682ad911b551e3ed74ae.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*18B8HTjAXwM_q9tpG9jh4A.png"/></div></div></figure><p id="2697" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu">信息值相关规则:</strong></p><p id="e130" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">在本例中,“特征”变量的 IV 值为<strong class="js iu"> 0.221 </strong>，则该预测因子与事件/非事件比值比具有中等强度关系。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi ok"><img src="../Images/935c3f9d46beaa6beabf5bc237a172d4.png" data-original-src="https://miro.medium.com/v2/resize:fit:858/format:webp/1*3OicgCqnLfwVMtUTOqV0aw.png"/></div><figcaption class="la lb gj gh gi lc ld bd b be z dk"><a class="ae le" href="https://www.listendata.com/2015/03/weight-of-evidence-woe-and-information.html" rel="noopener ugc nofollow" target="_blank">https://www.listendata.com/2015/03/weight-of-evidence-woe-and-information.html</a></figcaption></figure><h2 id="2fee" class="nj lg it bd lh nk nl dn ll nm nn dp lp kb no np lt kf nq nr lx kj ns nt mb nu bi translated">有用的小技巧！</h2><p id="c588" class="pw-post-body-paragraph jq jr it js b jt md jv jw jx me jz ka kb mf kd ke kf mg kh ki kj mh kl km kn im bi translated">WOE 转换的优点是:</p><ul class=""><li id="fd83" class="mi mj it js b jt ju jx jy kb mk kf ml kj mm kn mn mo mp mq bi translated">处理缺失值</li><li id="df9f" class="mi mj it js b jt mr jx ms kb mt kf mu kj mv kn mn mo mp mq bi translated">处理分类变量，因此不需要虚拟变量。</li><li id="2fb0" class="mi mj it js b jt mr jx ms kb mt kf mu kj mv kn mn mo mp mq bi translated">该变换基于分布的对数值。这与逻辑回归输出函数一致</li></ul><p id="86ef" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">对于分类预测器，我们可以<strong class="js iu">将</strong>组与<strong class="js iu">相似的</strong>观察值<strong class="js iu">权重</strong>组合，以创建具有连续证据权重值的新编码预测器。</p><p id="03e5" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">为什么要合并具有相似 WOE 的类别？具有相似权重的类别具有几乎相同的事件和非事件比例。换句话说，两个类别的行为是相同的。</p></div><div class="ab cl mw mx hx my" role="separator"><span class="mz bw bk na nb nc"/><span class="mz bw bk na nb nc"/><span class="mz bw bk na nb"/></div><div class="im in io ip iq"><h1 id="6f03" class="lf lg it bd lh li nd lk ll lm ne lo lp lq nf ls lt lu ng lw lx ly nh ma mb mc bi translated">轻型 G-Boost 编码</h1><p id="194d" class="pw-post-body-paragraph jq jr it js b jt md jv jw jx me jz ka kb mf kd ke kf mg kh ki kj mh kl km kn im bi translated">首先简单介绍一下<strong class="js iu"> Light-GBM </strong>(光梯度提升)。</p><h2 id="5534" class="nj lg it bd lh nk nl dn ll nm nn dp lp kb no np lt kf nq nr lx kj ns nt mb nu bi translated">什么是梯度增强？</h2><p id="340f" class="pw-post-body-paragraph jq jr it js b jt md jv jw jx me jz ka kb mf kd ke kf mg kh ki kj mh kl km kn im bi translated">这是一种升压算法，使用梯度下降法将损耗降至最低。我们所说的增强是指将一组弱学习者结合起来形成一个强规则。这是一个反复的过程。</p><h2 id="d7de" class="nj lg it bd lh nk nl dn ll nm nn dp lp kb no np lt kf nq nr lx kj ns nt mb nu bi translated">为什么很轻？</h2><p id="a21a" class="pw-post-body-paragraph jq jr it js b jt md jv jw jx me jz ka kb mf kd ke kf mg kh ki kj mh kl km kn im bi translated">Light GBM 是一个快速、分布式、高性能的梯度推进框架。与其他 boosting 算法不同的是，它按叶方式而不是按层方式<strong class="js iu">分割树<strong class="js iu">。LGBM 跑的非常快，所以才有了“<em class="nz">光</em>这个词。</strong></strong></p><h2 id="637c" class="nj lg it bd lh nk nl dn ll nm nn dp lp kb no np lt kf nq nr lx kj ns nt mb nu bi translated">分类特征支持:</h2><p id="2e33" class="pw-post-body-paragraph jq jr it js b jt md jv jw jx me jz ka kb mf kd ke kf mg kh ki kj mh kl km kn im bi translated">LightGBM 可以直接使用分类特征(没有独热或标签编码)。它有一种独特的方式来处理分类变量。</p><p id="222a" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">LGBM 应用<a class="ae le" href="http://www.csiss.org/SPACE/workshops/2004/SAC/files/fisher.pdf" rel="noopener ugc nofollow" target="_blank"> <strong class="js iu"> Fisher 的</strong> </a> <strong class="js iu">方法</strong>来寻找类别上的最优<strong class="js iu">拆分</strong>。</p><p id="ba60" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">我们经常用一键编码来表示分类变量，但最佳解决方案是通过将分类划分为<strong class="js iu"> 2 个子集</strong>来分割分类特征。<br/>如果特征有<strong class="js iu"> k </strong>个类别，则有<strong class="js iu">个 2^(k-1)-1 </strong>个可能的分区。然后我们需要找到最佳分区。</p><p id="d565" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">LightGBM 实现了<strong class="js iu">独占特性捆绑(EFB) </strong>技术，该技术基于(<strong class="js iu"> D. Fisher，1958 </strong>)的研究，以找到类别的最佳分割。</p><h2 id="6c92" class="nj lg it bd lh nk nl dn ll nm nn dp lp kb no np lt kf nq nr lx kj ns nt mb nu bi translated">独家功能捆绑:</h2><p id="32b0" class="pw-post-body-paragraph jq jr it js b jt md jv jw jx me jz ka kb mf kd ke kf mg kh ki kj mh kl km kn im bi translated">给定一组类别，将它们分组以使组内的<strong class="js iu">差异</strong>最小化的实用程序是什么？<br/>这里，注意力将被限制在原始类别到组中的各种可能的组合，假设在每个组内按比例分配。</p><p id="1ad5" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">因此，为了找到最佳分组，计算每个可能的<strong class="js iu">2^(k-1-1</strong>分区的<strong class="js iu"> D </strong>值就足够了。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi ol"><img src="../Images/daf0ecc85d90b33b4146a8e052a0f0d8.png" data-original-src="https://miro.medium.com/v2/resize:fit:638/format:webp/1*YnQZrIaslau_VnW4tT1Ywg.png"/></div></figure><blockquote class="om on oo"><p id="a288" class="jq jr nz js b jt ju jv jw jx jy jz ka op kc kd ke oq kg kh ki or kk kl km kn im bi translated"><strong class="js iu"> N : </strong>一个分区中元素的数量。<br/> <strong class="js iu"> w_i </strong>:元素 I 的权重<br/> <strong class="js iu"> a_i : </strong>元素 I 的数值度量</p></blockquote><p id="6e1c" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu"> D </strong>被称为<strong class="js iu"> <em class="nz">最小二乘划分</em> </strong>，其代表与一般平均值的平方偏差之和。为了找到最佳分割，我们选择具有最小 D 值的分区。</p><h2 id="4c42" class="nj lg it bd lh nk nl dn ll nm nn dp lp kb no np lt kf nq nr lx kj ns nt mb nu bi translated">有用的小技巧！</h2><p id="1917" class="pw-post-body-paragraph jq jr it js b jt md jv jw jx me jz ka kb mf kd ke kf mg kh ki kj mh kl km kn im bi translated">轻量级 GBM 支持分类变量，它的方法对于树学习者来说是次优的。</p><p id="09f3" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">这种方法通常比一键编码执行得更好。<br/>此外，在具有高基数的分类特征的情况下，建立在独热特征上的树往往是不平衡的，并且需要增长得非常深以实现良好的准确性。</p><p id="27a6" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">leaf-wise 方法(Light GBM 使用)的一个缺点是，当数据很小时，它可能会导致过度拟合。</p></div><div class="ab cl mw mx hx my" role="separator"><span class="mz bw bk na nb nc"/><span class="mz bw bk na nb nc"/><span class="mz bw bk na nb"/></div><div class="im in io ip iq"><h1 id="9947" class="lf lg it bd lh li nd lk ll lm ne lo lp lq nf ls lt lu ng lw lx ly nh ma mb mc bi translated">总结:</h1><p id="9f18" class="pw-post-body-paragraph jq jr it js b jt md jv jw jx me jz ka kb mf kd ke kf mg kh ki kj mh kl km kn im bi translated">在机器学习中，我们通常处理在一列或多列中包含多个标签的数据集。这些标签可以是分类的。因此，我们必须将这些特征转换成机器可读的形式。</p><p id="4ce0" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">在本文中，我们讨论了数据科学问题中一些最常用的编码方法，如上所述。</p><h1 id="8a20" class="lf lg it bd lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc bi translated">参考</h1><p id="e57a" class="pw-post-body-paragraph jq jr it js b jt md jv jw jx me jz ka kb mf kd ke kf mg kh ki kj mh kl km kn im bi translated">[1] <a class="ae le" href="https://www.linkedin.com/in/deepanshubhalla" rel="noopener ugc nofollow" target="_blank"> Deepanshu Bhalla </a>，<a class="ae le" href="https://www.listendata.com/2015/03/weight-of-evidence-woe-and-information.html" rel="noopener ugc nofollow" target="_blank">证据权重(WOE)和信息价值(IV)解释</a></p><p id="4f9f" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">[2] <a class="ae le" href="https://lightgbm.readthedocs.io/en/latest/index.html" rel="noopener ugc nofollow" target="_blank"> LightGBM 的文档</a></p><p id="cc00" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">[3]证据权重(WoE)介绍性概述，<a class="ae le" href="https://documentation.statsoft.com/STATISTICAHelp.aspx?path=WeightofEvidence/WeightofEvidenceWoEIntroductoryOverview#targetText=Weight%20of%20Evidence,Distribution%20of%20Bad%20Credit%20Outcomes%29" rel="noopener ugc nofollow" target="_blank"> Statsoft 网站</a></p><p id="e92b" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">[4]目标编码器，<a class="ae le" href="https://contrib.scikit-learn.org/categorical-encoding/targetencoder.html" rel="noopener ugc nofollow" target="_blank"> Scikit-Learn 网站</a></p><h1 id="fe64" class="lf lg it bd lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc bi translated">脚注:</h1><p id="c87e" class="pw-post-body-paragraph jq jr it js b jt md jv jw jx me jz ka kb mf kd ke kf mg kh ki kj mh kl km kn im bi translated">在这项研究中，我们提出了非常著名的技术，这些技术通常用于特征工程，以提高最大似然模型的准确性。</p><p id="fb22" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">我感谢你们所有人一直和我们在一起。</p><p id="98de" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">感谢阅读。:)<br/> <em class="nz">尽情享受吧！</em></p></div></div>    
</body>
</html>