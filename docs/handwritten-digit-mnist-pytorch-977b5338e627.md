# ä½¿ç”¨ PyTorch çš„æ‰‹å†™æ•°å­—è¯†åˆ«â€”â€”ç¥ç»ç½‘ç»œä»‹ç»

> åŸæ–‡ï¼š<https://towardsdatascience.com/handwritten-digit-mnist-pytorch-977b5338e627?source=collection_archive---------1----------------------->

![](img/b52c25bf3920afad2c3f3effb5f0f239.png)

å¯¹å—ï¼Ÿâ€”â€”å¼„æ¸…æ¥šä¸Šé¢çš„å›¾ç‰‡ä»£è¡¨æ•°å­—**å››**ï¼Œå¯¹ä½ æ¥è¯´æ²¡ä»€ä¹ˆã€‚ä½ ç”šè‡³æ²¡æœ‰ä¸ºå›¾åƒçš„åˆ†è¾¨ç‡å·®è€Œçƒ¦æ¼ï¼Œå¤šç¥å¥‡å•Šã€‚æˆ‘ä»¬éƒ½åº”è¯¥èŠ±ç‚¹æ—¶é—´æ„Ÿè°¢æˆ‘ä»¬çš„*å¤§è„‘*ï¼æˆ‘æƒ³çŸ¥é“æˆ‘ä»¬çš„å¤§è„‘å¯¹å›¾åƒè¿›è¡Œå¤„ç†ã€åˆ†ç±»å’Œåé¦ˆæ˜¯å¤šä¹ˆè‡ªç„¶ã€‚æˆ‘ä»¬æ˜¯å¤©æ‰ï¼

æ¨¡ä»¿äººè„‘ä¼šæœ‰å¤šéš¾ï¼Ÿæ·±åº¦å­¦ä¹ ï¼Œ*ç®€å•æ¥è¯´ï¼Œ*æ˜¯æœºå™¨å­¦ä¹ ç ”ç©¶çš„é¢†åŸŸï¼Œå®ƒå…è®¸è®¡ç®—æœºå­¦ä¹ æ‰§è¡Œå¤§è„‘è‡ªç„¶çš„ä»»åŠ¡ï¼Œå¦‚æ‰‹å†™æ•°å­—è¯†åˆ«ã€‚ä»æŠ€æœ¯ä¸Šæ¥è¯´ï¼Œå®ƒæ¶‰åŠæ›´å¤šçš„*å±‚*(æˆ‘ä»¬åé¢ä¼šè®²åˆ°)å’Œæ›´å¤šçš„*æ•°æ®*ã€‚

åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬å°†è®¨è®ºç¥ç»ç½‘ç»œï¼Œå¹¶ä»å¤´å¼€å§‹å¼€å‘ä¸€ä¸ªæ‰‹å†™æ•°å­—åˆ†ç±»å™¨ã€‚æˆ‘ä»¬å°†ä½¿ç”¨ ***PyTorch*** å› ä¸ºå®ƒ*å¾ˆé…·*ï¼

![](img/c8be38bc46d6930cdef9be2027729051.png)

æœ¬æ–‡çš„å”¯ä¸€å…ˆå†³æ¡ä»¶æ˜¯ Python è¯­æ³•çš„åŸºç¡€çŸ¥è¯†ã€‚åä¸‹æ¥ï¼Œå–æ¯å’–å•¡ï¼Œè·Ÿç€æˆ‘èµ°ã€‚

![](img/316dcd3124e39577f7bfce2b88aeed19.png)

Only Good Coffee Please!

## æ­¥éª¤ 1 â€”äº†è§£æ•°æ®é›†

ä½œä¸ºæ•°æ®ç§‘å­¦å®¶ï¼Œæœ€é‡è¦çš„ä»»åŠ¡æ˜¯æ”¶é›†å®Œç¾çš„æ•°æ®é›†ï¼Œå¹¶å½»åº•ç†è§£å®ƒã€‚ç›¸ä¿¡æˆ‘ï¼Œå‰©ä¸‹çš„å°±ç®€å•å¤šäº†ã€‚å¯¹äºè¿™ä¸ªé¡¹ç›®ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨æµè¡Œçš„ [MNIST æ•°æ®åº“](https://en.wikipedia.org/wiki/MNIST_database)ã€‚å®ƒæ˜¯ 70000 ä¸ªæ‰‹å†™æ•°å­—çš„é›†åˆï¼Œåˆ†ä¸ºåˆ†åˆ«ç”± 60000 ä¸ªå’Œ 10000 ä¸ªå›¾åƒç»„æˆçš„è®­ç»ƒé›†å’Œæµ‹è¯•é›†ã€‚

![](img/e7620493a3de60425cfd89c7d99be1f0.png)

Source: Wikimedia

è¯¥æ•°æ®é›†æœ€åˆå¯åœ¨ Yann Lecun çš„ç½‘ç«™ä¸Šè·å¾—ã€‚æ¸…ç†æ•°æ®æ˜¯æœ€å¤§çš„ä»»åŠ¡ä¹‹ä¸€ã€‚åˆ«å¿˜äº†â€” ***â€œåƒåœ¾è¿›ï¼Œåƒåœ¾å‡ºï¼â€*** ã€‚å¹¸è¿çš„æ˜¯ï¼Œå¯¹æˆ‘ä»¬æ¥è¯´ï¼ŒPyTorch æä¾›äº†ä¸€ä¸ªç®€å•çš„å®ç°ï¼Œä½¿ç”¨å‡ è¡Œä»£ç å°±å¯ä»¥ä¸‹è½½å¹²å‡€çš„å’Œå·²ç»å‡†å¤‡å¥½çš„æ•°æ®ã€‚åœ¨å¼€å§‹ä¹‹å‰ï¼Œæˆ‘ä»¬éœ€è¦åšæ‰€æœ‰å¿…è¦çš„è¿›å£ã€‚

```
import numpy as np
import torch
import torchvision
import matplotlib.pyplot as plt
from time import time
from torchvision import datasets, transforms
from torch import nn, optim
```

åœ¨ä¸‹è½½æ•°æ®ä¹‹å‰ï¼Œè®©æˆ‘ä»¬å®šä¹‰åœ¨å°†æ•°æ®è¾“å…¥ç®¡é“ä¹‹å‰ï¼Œæˆ‘ä»¬å¸Œæœ›å¯¹æ•°æ®æ‰§è¡Œå“ªäº›è½¬æ¢ã€‚æ¢å¥è¯è¯´ï¼Œæ‚¨å¯ä»¥å°†å®ƒè§†ä¸ºå¯¹å›¾åƒæ‰§è¡Œçš„æŸç§è‡ªå®šä¹‰ç¼–è¾‘ï¼Œä»¥ä¾¿æ‰€æœ‰å›¾åƒéƒ½å…·æœ‰ç›¸åŒçš„å°ºå¯¸å’Œå±æ€§ã€‚æˆ‘ä»¬ä½¿ç”¨ **torchvision.transforms** æ¥å®ç°ã€‚

```
transform = transforms.Compose([transforms.ToTensor(),
                              transforms.Normalize((0.5,), (0.5,)),
                              ])
```

1.  ***æ‘‡èº«ä¸€å˜ã€‚ToTensor()*** â€”å°†å›¾åƒè½¬æ¢æˆç³»ç»Ÿå¯ç†è§£çš„æ•°å­—ã€‚å®ƒå°†å›¾åƒåˆ†æˆä¸‰ä¸ªé¢œè‰²é€šé“(å•ç‹¬çš„å›¾åƒ):*çº¢è‰²ã€ç»¿è‰²&è“è‰²*ã€‚ç„¶åï¼Œå®ƒå°†æ¯ä¸ªå›¾åƒçš„åƒç´ è½¬æ¢ä¸ºå…¶é¢œè‰²åœ¨ 0 åˆ° 255 ä¹‹é—´çš„äº®åº¦ã€‚ç„¶åå°†è¿™äº›å€¼ç¼©å°åˆ° 0 åˆ° 1 ä¹‹é—´çš„èŒƒå›´ã€‚å›¾åƒç°åœ¨æ˜¯ä¸€ä¸ª[ç«ç‚¬å¼ é‡](https://pytorch.org/docs/stable/tensors.html)ã€‚
2.  ***å˜æ¢å˜æ¢ã€‚Normalize()***

ç°åœ¨ï¼Œæˆ‘ä»¬ç»ˆäºä¸‹è½½äº†æ•°æ®é›†ï¼Œå¯¹å®ƒä»¬è¿›è¡Œäº†æ´—ç‰Œå’Œè½¬æ¢ã€‚æˆ‘ä»¬ä¸‹è½½æ•°æ®é›†å¹¶å°†å®ƒä»¬åŠ è½½åˆ° *DataLoader* ï¼Œå®ƒå°†æ•°æ®é›†å’Œé‡‡æ ·å™¨ç»“åˆåœ¨ä¸€èµ·ï¼Œå¹¶åœ¨æ•°æ®é›†ä¸Šæä¾›å•è¿›ç¨‹æˆ–å¤šè¿›ç¨‹è¿­ä»£å™¨ã€‚

```
trainset = datasets.MNIST('PATH_TO_STORE_TRAINSET', download=**True**, train=**True**, transform=transform)valset = datasets.MNIST('PATH_TO_STORE_TESTSET', download=**True**, train=**False**, transform=transform)trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=**True**)valloader = torch.utils.data.DataLoader(valset, batch_size=64, shuffle=**True**)
```

åœ¨ä¸€è¡Œä¸­ï¼Œ*æ‰¹é‡å¤§å°*æ˜¯æˆ‘ä»¬æƒ³è¦ä¸€æ¬¡è¯»å–çš„å›¾åƒæ•°é‡ã€‚

## æ­¥éª¤ 2-æ›´å¥½åœ°äº†è§£æ•°æ®é›†

åœ¨è¿™ä¸ªé˜¶æ®µï¼Œæˆ‘ä»¬å°†å¯¹æˆ‘ä»¬çš„å›¾åƒå’Œå¼ é‡è¿›è¡Œä¸€äº›æ¢ç´¢æ€§çš„æ•°æ®åˆ†æã€‚è®©æˆ‘ä»¬æ£€æŸ¥ä¸€ä¸‹å›¾åƒå’Œæ ‡ç­¾çš„å½¢çŠ¶ã€‚

```
dataiter = iter(trainloader)
images, labels = dataiter.next()

print(images.shape)
print(labels.shape)
```

æ‚¨å°†å‘ç°å›¾åƒçš„å½¢çŠ¶æ˜¯ï¼Œ`torch.Size([64,1,28,28])`ï¼Œè¿™è¡¨æ˜æ¯æ‰¹ä¸­æœ‰ 64 ä¸ªå›¾åƒï¼Œæ¯ä¸ªå›¾åƒçš„å°ºå¯¸ä¸º 28 x 28 åƒç´ ã€‚ç±»ä¼¼åœ°ï¼Œæ ‡ç­¾çš„å½¢çŠ¶ä¸º`torch.Size([64])`ã€‚çŒœçŒœä¸ºä»€ä¹ˆï¼Ÿâ€”æ˜¯çš„ï¼Œä½ è¯´å¾—å¯¹ï¼64 å¼ å›¾ç‰‡åº”è¯¥åˆ†åˆ«æœ‰ 64 ä¸ªæ ‡ç­¾ã€‚å°±æ˜¯è¿™æ ·ã€‚è½»æ¾ç‚¹ã€‚

![](img/9cb431bf437dd0092708a0f24ea1ff57.png)

è®©æˆ‘ä»¬æ˜¾ç¤ºè®­ç»ƒé›†ä¸­çš„ä¸€å¹…å›¾åƒï¼Œä¾‹å¦‚ç¬¬ä¸€å¹…ã€‚

```
plt.imshow(images[0].numpy().squeeze(), cmap='gray_r');
```

é…·å§ï¼è®©æˆ‘ä»¬å±•ç¤ºæ›´å¤šçš„å›¾åƒï¼Œè¿™å°†è®©æˆ‘ä»¬æ„Ÿå—ä¸€ä¸‹æ•°æ®é›†çš„æ ·å­ã€‚

```
figure = plt.figure()
num_of_images = 60
**for** index **in** range(1, num_of_images + 1):
    plt.subplot(6, 10, index)
    plt.axis('off')
    plt.imshow(images[index].numpy().squeeze(), cmap='gray_r')
```

è¿™å°†ç”Ÿæˆä¸€ä¸ªéšæœºæ’åˆ—çš„å›¾åƒç½‘æ ¼ã€‚ç°åœ¨ï¼Œæ˜¯æ—¶å€™å¼€å§‹å®šä¹‰æˆ‘ä»¬å°†è¦ä½¿ç”¨çš„ç¥ç»ç½‘ç»œäº†ã€‚

## æ­¥éª¤ 3â€”â€”å»ºç«‹ç¥ç»ç½‘ç»œ

æˆ‘ä»¬å°†æ„å»ºä¸‹é¢çš„ç½‘ç»œï¼Œæ­£å¦‚ä½ æ‰€çœ‹åˆ°çš„ï¼Œå®ƒåŒ…å«ä¸€ä¸ªè¾“å…¥å±‚(ç¬¬ä¸€å±‚)ï¼Œä¸€ä¸ªç”±åä¸ª*ç¥ç»å…ƒ*(æˆ–å•å…ƒï¼Œåœ†åœˆ)ç»„æˆçš„è¾“å‡ºå±‚ï¼Œä»¥åŠä¸­é—´çš„ä¸¤ä¸ªéšè—å±‚ã€‚

![](img/04cd3c8c6424a8cb8cf065a0c5a5812c.png)

PyTorch çš„`torch.nn`æ¨¡å—å…è®¸æˆ‘ä»¬éå¸¸ç®€å•åœ°æ„å»ºä¸Šè¿°ç½‘ç»œã€‚è¿™ä¹Ÿéå¸¸å®¹æ˜“ç†è§£ã€‚çœ‹çœ‹ä¸‹é¢çš„ä»£ç ã€‚

```
input_size = 784
hidden_sizes = [128, 64]
output_size = 10

model = nn.Sequential(nn.Linear(input_size, hidden_sizes[0]),
                      nn.ReLU(),
                      nn.Linear(hidden_sizes[0], hidden_sizes[1]),
                      nn.ReLU(),
                      nn.Linear(hidden_sizes[1], output_size),
                      nn.LogSoftmax(dim=1))
print(model)
```

`nn.Sequential`åŒ…è£¹ç½‘ç»œä¸­çš„å±‚ã€‚æœ‰ä¸‰ä¸ªå¸¦ **ReLU æ¿€æ´»**çš„**çº¿æ€§å±‚**(ä¸€ä¸ªå…è®¸æ­£å€¼é€šè¿‡çš„ç®€å•å‡½æ•°ï¼Œè€Œè´Ÿå€¼è¢«ä¿®æ”¹ä¸ºé›¶)ã€‚è¾“å‡ºå›¾å±‚æ˜¯æ¿€æ´»äº† [**LogSoftmax**](https://pytorch.org/docs/stable/nn.html#logsoftmax) çš„çº¿æ€§å›¾å±‚ï¼Œå› ä¸ºè¿™æ˜¯ä¸€ä¸ªåˆ†ç±»é—®é¢˜ã€‚

ä»æŠ€æœ¯ä¸Šæ¥è¯´ï¼Œä¸€ä¸ª LogSoftmax å‡½æ•°æ˜¯ä¸€ä¸ª **Softmax** å‡½æ•°çš„å¯¹æ•°ï¼Œé¡¾åæ€ä¹‰ï¼Œå®ƒçœ‹èµ·æ¥åƒè¿™æ ·ï¼Œå¦‚ä¸‹æ‰€ç¤ºã€‚

![](img/705b8ba471b43ad9a867339cb10df9f1.png)

æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬å®šä¹‰ [**è´Ÿå¯¹æ•°ä¼¼ç„¶æŸå¤±**](https://pytorch.org/docs/stable/nn.html#nllloss) ã€‚ç”¨ C ç±»è®­ç»ƒä¸€ä¸ªåˆ†ç±»é—®é¢˜å¾ˆæœ‰ç”¨ã€‚ **LogSoftmax()** å’Œ **NLLLoss()** ä¸€èµ·å……å½“äº¤å‰ç†µæŸå¤±ï¼Œå¦‚ä¸Šé¢çš„ç½‘ç»œæ¶æ„å›¾æ‰€ç¤ºã€‚

å¦å¤–ï¼Œä½ ä¸€å®šæƒ³çŸ¥é“ä¸ºä»€ä¹ˆæˆ‘ä»¬åœ¨ç¬¬ä¸€å±‚æœ‰ 784 ä¸ªå•å…ƒã€‚å¾ˆå¥½ï¼è¿™æ˜¯å› ä¸ºæˆ‘ä»¬åœ¨å°†æ¯å¹…å›¾åƒå‘é€åˆ°ç¥ç»ç½‘ç»œä¹‹å‰å°†å…¶å±•å¹³ã€‚ *(28 x 28 = 784)*

```
criterion = nn.NLLLoss()
images, labels = next(iter(trainloader))
images = images.view(images.shape[0], -1)

logps = model(images) #log probabilities
loss = criterion(logps, labels) #calculate the NLL loss
```

æˆ‘ä»¬å°†åœ¨ä»¥åçš„æ–‡ç« ä¸­è®¨è®ºæ›´å¤šçš„ç¥ç»ç½‘ç»œï¼Œæ¿€æ´»å‡½æ•°ï¼Œä¼˜åŒ–ç®—æ³•ç­‰ã€‚

**æ­¥éª¤ 4 â€”è°ƒæ•´é‡é‡**

ç¥ç»ç½‘ç»œ*é€šè¿‡å¯¹å¯ç”¨æ•°æ®è¿›è¡Œå¤šæ¬¡è¿­ä»£æ¥å­¦ä¹ *ã€‚ ***å­¦ä¹ *** æ˜¯æŒ‡è°ƒæ•´ç½‘ç»œçš„æƒå€¼ï¼Œä½¿æŸè€—æœ€å°ã€‚è®©æˆ‘ä»¬æƒ³è±¡ä¸€ä¸‹å®ƒæ˜¯å¦‚ä½•å·¥ä½œçš„ã€‚

```
print('Before backward pass: **\n**', model[0].weight.grad)
loss.backward()
print('After backward pass: **\n**', model[0].weight.grad)
```

åœ¨å‘åä¼ é€’ä¹‹å‰ï¼Œæ¨¡å‹æƒé‡è¢«è®¾ç½®ä¸ºé»˜è®¤çš„**æ— **å€¼ã€‚ä¸€æ¬¡ï¼Œæˆ‘ä»¬è°ƒç”¨ **backward()** å‡½æ•°æ¥æ›´æ–°æƒé‡ã€‚

```
Before backward pass: 
 None
After backward pass: 
 tensor([[-0.0003, -0.0003, -0.0003,  ..., -0.0003, -0.0003, -0.0003],
        [ 0.0008,  0.0008,  0.0008,  ...,  0.0008,  0.0008,  0.0008],
        [-0.0037, -0.0037, -0.0037,  ..., -0.0037, -0.0037, -0.0037],
        ...,
        [-0.0005, -0.0005, -0.0005,  ..., -0.0005, -0.0005, -0.0005],
        [ 0.0043,  0.0043,  0.0043,  ...,  0.0043,  0.0043,  0.0043],
        [-0.0006, -0.0006, -0.0006,  ..., -0.0006, -0.0006, -0.0006]])
```

## æ­¥éª¤ 5 â€”æ ¸å¿ƒåŸ¹è®­æµç¨‹

è¿™æ˜¯çœŸæ­£çš„å¥‡è¿¹å‘ç”Ÿçš„åœ°æ–¹ã€‚æ‚¨çš„ç¥ç»ç½‘ç»œè¿­ä»£è®­ç»ƒé›†å¹¶æ›´æ–°æƒé‡ã€‚æˆ‘ä»¬ä½¿ç”¨ PyTorch æä¾›çš„æ¨¡å—`torch.optim`æ¥ä¼˜åŒ–æ¨¡å‹ï¼Œæ‰§è¡Œæ¢¯åº¦ä¸‹é™ï¼Œå¹¶é€šè¿‡åå‘ä¼ æ’­æ¥æ›´æ–°æƒé‡ã€‚å› æ­¤ï¼Œåœ¨æ¯ä¸ª**æ—¶æœŸ**(æˆ‘ä»¬è¿­ä»£è®­ç»ƒé›†çš„æ¬¡æ•°)ï¼Œæˆ‘ä»¬å°†çœ‹åˆ°è®­ç»ƒæŸå¤±é€æ¸å‡å°‘ã€‚

```
optimizer = optim.SGD(model.parameters(), lr=0.003, momentum=0.9)
time0 = time()
epochs = 15
**for** e **in** range(epochs):
    running_loss = 0
    **for** images, labels **in** trainloader:
        *# Flatten MNIST images into a 784 long vector*
        images = images.view(images.shape[0], -1)

        *# Training pass*
        optimizer.zero_grad()

        output = model(images)
        loss = criterion(output, labels)

        *#This is where the model learns by backpropagating*
        loss.backward()

        *#And optimizes its weights here*
        optimizer.step()

        running_loss += loss.item()
    **else**:
        print("Epoch **{}** - Training loss: **{}**".format(e, running_loss/len(trainloader)))print("**\n**Training Time (in minutes) =",(time()-time0)/60)
```

è¿™å¯èƒ½éœ€è¦ä¸€äº›æ—¶é—´æ¥æ‰§è¡Œï¼Œå¹¶ä¸”ä¼šå› ç³»ç»Ÿè€Œå¼‚ã€‚æˆ‘åœ¨äº‘ç¬”è®°æœ¬ä¸ŠèŠ±äº† 2.5 åˆ†é’Ÿã€‚

## æ­¥éª¤ 6 â€”æµ‹è¯•å’Œè¯„ä¼°

æˆ‘ä»¬çš„å·¥ä½œå¿«å®Œæˆäº†ã€‚æ¨¡å‹åšå¥½äº†ï¼Œä½†æˆ‘ä»¬è¦å…ˆè¯„ä¼°ä¸€ä¸‹ã€‚æˆ‘åˆ›å»ºäº†ä¸€ä¸ªå®ç”¨å‡½æ•° **view_classify()** æ¥æ˜¾ç¤ºé¢„æµ‹çš„å›¾åƒå’Œç±»åˆ«æ¦‚ç‡ã€‚ä»£ç å¯ä»¥åœ¨ GitHub ä¸Šæ‰¾åˆ°ã€‚(ä¸‹é¢å‚è€ƒèµ„æ–™éƒ¨åˆ†çš„é“¾æ¥)ã€‚

æˆ‘å°†æˆ‘ä»¬ä¹‹å‰åˆ›å»ºçš„éªŒè¯é›†ä¸­çš„ä¸€ä¸ªå›¾åƒä¼ é€’ç»™è®­ç»ƒå¥½çš„æ¨¡å‹ï¼Œä»¥æŸ¥çœ‹æ¨¡å‹æ˜¯å¦‚ä½•å·¥ä½œçš„ã€‚

```
images, labels = next(iter(valloader))

img = images[0].view(1, 784)**with** torch.no_grad():
    logps = model(img)

ps = torch.exp(logps)
probab = list(ps.numpy()[0])
print("Predicted Digit =", probab.index(max(probab)))
**view_classify**(img.view(1, 28, 28), ps)
```

![](img/8f6f78b60f13d0da3c8c203322c7303a.png)

Prediction Result. Perfect Prediction!

ç°åœ¨ï¼Œæˆ‘ä»¬ä½¿ç”¨ for å¾ªç¯éå†éªŒè¯é›†ï¼Œå¹¶è®¡ç®—æ­£ç¡®é¢„æµ‹çš„æ€»æ•°ã€‚è¿™æ˜¯æˆ‘ä»¬è®¡ç®—ç²¾ç¡®åº¦çš„æ–¹æ³•ã€‚

```
correct_count, all_count = 0, 0
**for** images,labels **in** valloader:
  **for** i **in** range(len(labels)):
    img = images[i].view(1, 784)
    **with** torch.no_grad():
        logps = model(img)

    ps = torch.exp(logps)
    probab = list(ps.numpy()[0])
    pred_label = probab.index(max(probab))
    true_label = labels.numpy()[i]
    **if**(true_label == pred_label):
      correct_count += 1
    all_count += 1

print("Number Of Images Tested =", all_count)
print("**\n**Model Accuracy =", (correct_count/all_count))
```

ç°åœ¨æ¥çœ‹çœ‹ç»“æœã€‚è¿™æ˜¯æœ€æœ‰è¶£çš„éƒ¨åˆ†ï¼

```
Number Of Images Tested = 10000
Model Accuracy = 0.9751
```

å“‡ï¼æˆ‘ä»¬æœ‰è¶…è¿‡ 97.5%çš„å‡†ç¡®ç‡ã€‚è¿™æ˜¯å€¼å¾—åº†ç¥çš„äº‹æƒ…ã€‚æˆ‘ä»¬è·å¾—å¦‚æ­¤é«˜ç²¾åº¦çš„åŸå› æ˜¯ï¼Œæˆ‘ä»¬çš„æ•°æ®é›†æ˜¯å¹²å‡€çš„ï¼Œæœ‰å„ç§å„æ ·ç»è¿‡è‰¯å¥½æ´—ç‰Œçš„å›¾åƒï¼Œè€Œä¸”æ•°é‡å¾ˆå¤§ã€‚è¿™ä½¿å¾—æˆ‘ä»¬çš„æ¨¡å‹èƒ½å¤Ÿå¾ˆå¥½åœ°è¯†åˆ«å¤§é‡çœ‹ä¸è§çš„æ•°å­—ã€‚

## æ­¥éª¤ 7 â€”ä¿å­˜æ¨¡å‹

ç°åœ¨æˆ‘ä»¬å·²ç»å®Œæˆäº†æ‰€æœ‰çš„å·¥ä½œï¼Œæˆ‘ä»¬ä¸æƒ³å¤±å»è®­ç»ƒå¥½çš„æ¨¡å‹ã€‚æˆ‘ä»¬ä¸æƒ³æ¯æ¬¡ç”¨çš„æ—¶å€™éƒ½è®­ç»ƒå®ƒã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬å°†ä¿å­˜æ¨¡å‹ã€‚ä»¥åéœ€è¦çš„æ—¶å€™ï¼Œå¯ä»¥ç›´æ¥åŠ è½½ä½¿ç”¨ï¼Œä¸éœ€è¦è¿›ä¸€æ­¥çš„è®­ç»ƒã€‚

```
torch**.save**(model, './my_mnist_model.pt') 
```

ç¬¬ä¸€ä¸ªå‚æ•°æ˜¯æ¨¡å‹å¯¹è±¡ï¼Œç¬¬äºŒä¸ªå‚æ•°æ˜¯è·¯å¾„ã€‚PyTorch å‹å·ä¸€èˆ¬ç”¨`.pt`æˆ–`.pth`æ‰©å±•åä¿å­˜ã€‚[æŸ¥é˜…æ–‡ä»¶](https://pytorch.org/tutorials/beginner/saving_loading_models.html#save-load-entire-model)ã€‚

## ç»“è®º

æˆ‘å¸Œæœ›ä½ å–œæ¬¢å»ºç«‹ä¸€ä¸ªç¥ç»ç½‘ç»œï¼Œè®­ç»ƒå®ƒï¼Œæµ‹è¯•å®ƒï¼Œæœ€åä¿å­˜å®ƒçš„è¿‡ç¨‹ã€‚åœ¨æ„å»ºä¸€ä¸ªå¾ˆé…·çš„é¡¹ç›®çš„åŒæ—¶ï¼Œä½ è‚¯å®šå·²ç»æŒæ¡äº†ä¸€äº›æ¦‚å¿µï¼Œå­¦åˆ°äº†ä¸€äº›æ–°ä¸œè¥¿ã€‚æˆ‘å¾ˆæƒ³çŸ¥é“å®ƒæ˜¯å¦‚ä½•ä¸ºä½ å·¥ä½œçš„ã€‚ ***å¹¶ä¸”ï¼Œå¦‚æœä½ å–œæ¬¢è¯·é¼“æŒï¼Œè¿™å¯¹æˆ‘æ˜¯ä¸€ç§é¼“åŠ±ã€‚*** :) *æ›´å¤šç‚«é…·æ–‡ç« ä¸€å­—æ’å¼€ã€‚å³å°†æ¨å‡ºï¼*

å¦‚æœä½ æœ‰å¿ƒæƒ…è¯·æˆ‘å–å•¤é…’ğŸ¤©> >[https://www.buymeacoffee.com/amitrajit](https://www.buymeacoffee.com/amitrajit)

å“¦ï¼å¹¶ä¸”ï¼Œ [*æ•´ä¸ªç¬”è®°æœ¬åœ¨è¿™é‡Œ*](https://github.com/amitrajitbose/handwritten-digit-recognition) éƒ½æœ‰ã€‚ç¬”è®°æœ¬ç”µè„‘çš„ GPU ç‰ˆæœ¬ä¸åŒäº CPU ç‰ˆæœ¬ã€‚ä½ å¯ä»¥æ ¹æ®ä½ çš„éœ€è¦å‚è€ƒã€‚

## å‚è€ƒæ–‡çŒ®

[1] [*PyTorch å®˜æ–¹ Doc*](https://pytorch.org/docs/stable/index.html)*s* ã€2ã€‘[*MNIST ç»´åŸºç™¾ç§‘*](https://en.wikipedia.org/wiki/MNIST_database)ã€3ã€‘*Cool GIFs æ¥è‡ª*[*GIPHY*](https://giphy.com)
ã€4ã€‘[*GitHub ä¸Šçš„å…¨éƒ¨ä»£ç *](https://github.com/amitrajitbose/handwritten-digit-recognition)

## æ‰¿è®¤

*æ„Ÿè°¢*[*Zykrr*](https://zykrr.com/)*å·¥ç¨‹ç»™äºˆçš„çµæ„Ÿã€‚åœ¨ï¼Œ*[*Zykrr*](https://www.linkedin.com/company/zykrr/)*æˆ‘ä»¬ä¸* [*å®¢æˆ·ä½“éªŒå’Œåé¦ˆåˆ†æ*](https://medium.com/zykrrtech) *é¢†åŸŸçš„å°–ç«¯æŠ€æœ¯åˆä½œã€‚*