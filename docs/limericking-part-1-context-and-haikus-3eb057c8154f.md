# Limericking 第 1 部分:背景和俳句。

> 原文：<https://towardsdatascience.com/limericking-part-1-context-and-haikus-3eb057c8154f?source=collection_archive---------23----------------------->

## 石灰工程

## 使用自然语言处理产生诗歌

![](img/438fe1763566eeee5e20c75b52260fe8.png)

Watson: Jeopardy champ and future poet laureate?

机器学习和数据科学中最令人兴奋的领域之一是自然语言处理。让一台机器能够解析并生成听起来像人类的语言，这既有巨大的实用价值，也是众所周知的困难。人类的语言是混乱的，充满了计算机无法处理的那种不规则性。即使是相对简单的任务，比如标记一个给定单词的词性，也可能很难，并且依赖于上下文(permit 是名词还是动词？).

即使是最强大、最成功的 NLP 实现也会让人感觉有些不舒服。我仍然非常清楚地记得观看 IBM 的沃森与全明星肯·詹宁斯和布拉德·鲁特一起玩 Jeopardy。沃森的表现确实令人印象深刻，在两天的比赛中，沃森最终轻松获胜，但有时它感觉机器并没有真正执行它被设计来做的任务——正确解释自然语言——一点也不出色。在一场最后的危险游戏中，沃森在“美国城市”类别中找不到正确答案，他猜是多伦多:

如果沃森真的能够理解这项任务，它大概至少会猜对一个国家的城市，尽管我不完全相信它不是在故意开玩笑。我还记得在常规播放中的一个线索，询问了甲壳虫乐队的歌曲“挥舞银锤”的名字麦克斯韦尔，沃森回答了整个短语“麦克斯韦尔的银锤”。他们给沃森的回答加分，但也许他们不应该这样。沃森可以建立足够的联系来判断线索在问哪首歌，但不知道线索实际上在问什么。

这一切只是为了重申自然语言处理是辛苦的！将维基百科的全部内容输入一台最先进的超级计算机是很容易的。即使是最先进的超级计算机也能理解基本英语，这需要极大的创造力。

我对计算机生成文本的能力特别感兴趣。沃森相对容易，因为危险反应遵循严格的模式。让计算机生成更长更复杂的段落，尤其是那些需要恰当的变化和一致的段落，怎么样？在这篇文章中，也可能在未来的一系列文章中，我想探索如何生成这样的文本，着眼于创作热门打油诗。

这篇文章的灵感来自 twitter 账户 [Limericking](https://twitter.com/Limericking) 。打油诗背后的匿名天才在新闻报道后写打油诗。出于我无法完全说清楚的原因，我认为利默瑞金的打油诗中最好的确实非常出色，是我所知道的最好的现代诗歌中的一些:

A brilliant limerick about rising tensions with Iran

我一直在考虑将 Limericking 的输出自动化的所有事情。你能输入一篇新闻文章，让计算机产生一首热门打油诗吗？其他尝试产生像这样的样式化文本的方法是使用递归神经网络，该网络在输入语料库上被训练，它们将试图模仿该输入语料库。例如，这位[数据科学家](https://medium.com/@DenisKrivitski/generation-of-poems-with-a-recurrent-neural-network-128a5f62b483)用莎士比亚训练了一个 RNN，在超过 19 个小时的大约 35000 个训练步骤之后，计算机产生了这个文本片段:

> 泰特斯·安德洛尼克斯:
> 
> 现在，我的安全和死亡是什么？
> 
> 国王理查德二世:
> 
> 你认为会有什么结果？
> 
> 这是什么？

结果是非常令人印象深刻的，完全缺乏。这篇课文无疑是莎士比亚的，但毫无意义。这种不直接的方式擅长模仿风格，但不擅长产生“意义”。你可以想象用足够多的打油诗来训练 RNN，让它对格式有所了解，但是这个网络需要有多深才能创造出清晰的内容呢？或者让它把新闻文本处理成一首易读的摘要打油诗？

直觉上，更好的过程应该更程序化。您可以想象一个函数或一系列函数按顺序执行以下步骤:

1.  分析新闻文本的含义，提取关键词或中心人物
2.  用两三句话总结一下
3.  搜索同义词库和押韵词典，找到符合押韵方案的备选单词
4.  重新调整新的押韵句子，以正确扫描打油诗的形式。

问题是，每一个步骤本身都是一个棘手的数据科学问题。第一步:阅读文本，找到主题或中心人物。计算机如何知道如何将文本分配给特定主题？通常，这可以通过类似于朴素贝叶斯分类器的东西来完成，该分类器查看任何给定主题中特定单词的频率(例如，包含单词“gigabyte”的文本更可能来自关于技术的文章，而提到联合国的文章更可能是关于世界事务的)。这需要一个大的、标记良好的数据集来训练你的模型，这意味着，像许多大数据问题一样，这不仅仅是一个数据科学问题，也是一个数据生产问题。(也有无人监督的文本聚类方法，尽管让计算机决定分组方式会有风险)。

也许，你认为，有一个更简单的方法。你可能会稍微欺骗一下，认为一篇文章的主题会用一个在文章中相对频繁出现的名字或名词来表示。通过将文本中最常出现的专有名词集合起来，并猜测其中一个是主题，你会比随机选择做得更好。这本身也是一个复杂的分类问题，因为虽然计算机很容易计算实例，但计算机很难区分什么是专有名词。

幸运的是，如果你像我一样，突然对打油诗产生了热情，想要一头扎进去，那么大量的资源已经存在了。自然语言工具包( [NLTK](https://www.nltk.org/) )是一个强大的 Python 文本操作和分析工具库，除了许多其他东西之外，它还包含一个已经相当不错的词性标记器(如果您认为自己可以做得更好，还可以使用其他工具来构建自己的标记器)。在一系列的文章中，我想探究解析和产生文本的每一项任务，看看我是否能慢慢地建立起类似自动缩词法的功能。

为此，我决定从简单开始。而不是从头开始构建必要的工具，而是开始使用 NLTK 自带的一些工具，并致力于产生一种更简单的文本类型。与其写一首带有韵律和语法要求的打油诗，不如写一首只需要韵律的俳句。鉴于俳句如此简短，当它们是印象式的时侯，似乎效果最好，所以没有必要太关注语法。正如比利·穆雷告诉我们的，如果俳句没有意义也没关系:

以下是我的入门俳句生成器的工作原理:

1.  它接受一个来自 NPR 的新闻文章的 id 号。为什么是 NPR？因为他们有一个非常方便的[纯文本版本的网站](https://text.npr.org/)，这应该是一个练习语言处理而不是网络抓取
2.  检索文本并对其进行“标记”——将其转换为机器可以逐段评估的单词列表
3.  通过为每个文本标记词性并查看最常出现的专有名词，尝试确定文本的主题——这实际上非常有效。(我的函数还通过查看文本的二元模型来检查专有名词是否是名称的一部分，也就是说，作为一个集合紧挨着出现的一组单词，并将返回完整的名称。)
4.  它通过从集合中移除“停用词”——像“a”、“the”、“is”等常见词——并收集形容词、名词和动名词(再次感谢 NLTK 词性标记器)来收集要使用的词
5.  单词的语料库被“词条化”——像那些标记复数的屈折词尾被删除
6.  然后它组合俳句:如果少于 5 个音节，它将主题放在第一行，如果有 6 或 7 个音节，它将主题放在第二行。然后，它用从语料库中随机抽取的词来填充俳句的其余部分，但倾向于在文本中出现频率更高的词。

这个简单的程序产生了一些令人惊讶的暗示性结果，这证明了语言的灵活性和人类思维的创造性暗示性。鉴于[这篇文章](https://www.npr.org/2019/06/22/735076936/amazon-explores-having-its-drones-provide-home-surveillance-for-customers)关于亚马逊考虑使用送货无人机提供家庭监控，它正确地收集了这篇文章的主题是“亚马逊”,并创作了这首俳句:

> 亚马逊报告
> 
> 计划监督部
> 
> 无人机安全

这种方式触及了问题的核心，而且看起来像人类。事实上，我认为只要在“plan”这个词后面加上一个“s ”,结果看起来甚至会合乎语法。鉴于[这篇](https://www.npr.org/2019/06/24/735348880/eldorado-resorts-buys-caesars-for-17-3-billion)关于埃尔多拉多度假村收购凯撒赌场名气的文章，结果不太令人信服，但也不可怕:

> 投机运动
> 
> 凯撒娱乐新闻
> 
> 品牌公司名称

当然，形体短小，印象深刻的时候很容易显得印象深刻。即使是一首不太好的打油诗，要写出更长、更符合语法的作品也要困难得多。