# 自动化和可管理的管道:数据科学工厂的关键组成部分

> 原文：<https://towardsdatascience.com/automated-and-manageable-pipelines-key-components-of-a-data-science-factory-2779a9b99b51?source=collection_archive---------33----------------------->

![](img/e90697bc36914389f8752f737ca7e21d.png)

[Image source](https://pixabay.com/photos/architecture-gang-modern-3357028/)

数据科学可能是一项棘手的工作，来自无数来源的原始数据不断涌入不断发展的管道，试图满足不断变化的期望。为了利用所有这些混乱的潜力，企业努力创建数据科学工厂，在减少低效的同时简化流程；然而，数据不会等着公司赶上来。在处理大量数据的同时生产一个高功能的数据科学工厂就像试图制造一架飞机并驾驶它一样。

构建有效的数据科学工厂的关键是在流程的每个步骤中实施智能自动化和评分管道，以便为业务合作伙伴和客户生成分析产品，如 API、评分文件和数据丰富。每个组件都必须产生合理的结果，以使操作具有可伸缩性并产生可靠的见解。让我们来看看起作用的组件以及如何最大化每一个组件。

# 三种类型的管道

**数据管道:**数据从起点到它在美丽的图形中的最终归宿，或者最终到数据仓库，有一个漫长而痛苦的旅程。数据管道软件将数据从一个点移动到另一个点，并且在该过程中经常涉及转换。高效的数据管道减少了手动步骤，每个步骤都依赖于自动化:提取、清理、转换、组合、验证和加载以供进一步分析。传输数据会增加损坏和潜在延迟的风险，在小范围内降低风险的努力越多，当流程扩展时，输出的质量就越高。

**机器学习评分管道:**干净、准备好的数据准备好被输入到机器学习评分算法中，在那里生成通知商业决策的分数。有效的 ML 评分管道在很大程度上依赖于其模型的质量。

**反馈和响应管道:**由 ML 管道产生的规定决策必须被记录并通过反馈和响应管道被返回用于进一步学习。这一过程既可以实时进行，如网站产品推荐，也可以要求对购买周期较长的产品进行潜在响应，如抵押贷款申请或人寿保险报价。

# 数据管道的三种速度

数据管道可以以三种不同的速度进行处理，每种方式都有独特的优势和局限性。

**批处理:**批处理是处理大量数据的有效方式。在一段时间内收集的交易作为一批进行处理。这种方法通常用于建模预测分析，因为大量的数据可确保更准确的结果和更强的洞察力。

**实时:**许多数字操作需要立即行动，因此当代数据科学家经常依赖实时数据处理。这种方法需要不断的输入、处理和输出。流媒体创造了快速数据现象，许多企业提供关键的实时服务，如欺诈检测、语音识别和推荐。

**事件驱动:**为了节省资源和限制冗余，一些管道应用事件驱动处理。事件可以是指示特定温度、时间段的智能机器，或者与库存相关的销售点通知。事件驱动的管道被优化以产生实时结果，但是仅在特定的、预先确定的情况下。

# 高度可扩展管道的关键要素

**1。底层基础设施**

基础设施是指产生机器学习算法所需的技术栈。成功的运营需要密封的解决方案和坚实的基础设施。难以控制的管道系统会导致不可收回的技术债务，这一直是 ML 开发中的一个[问题](https://storage.googleapis.com/pub-tools-public-publication-data/pdf/43146.pdf),或者使结果和工作流不可能重现的纠缠不清的“管道丛林”。

**2。自动化质量控制**

人工智能正在彻底改变各行各业的质量控制，但同样重要的是，该技术可以监控自身输出的质量。实施在线和超时自动质量控制解决方案可确保更可靠的结果，并减少手动检查受损数据所花费的时间。

**3。自动化漂移和异常检测**

概念漂移是机器学习中的一种常见现象，会导致不准确的结果；然而，目标变量的变化可以被自动标记，触发重新训练以保护模型的完整性。此外，当数据点超出预测模式时，自动异常检测可以触发适当的操作或进一步的调查。

**4。为数据治理和自我记录管道集成现代数据目录**

人们越来越认识到数据对公司来说是无价的，这使得数据的管理、存储和监管成为重中之重。能够自我记录的管道增加了未来项目的功能和价值，集成现代数据目录提高了任何算法预测的相关性。

**5。实施强大的日志记录和诊断功能**

正如古老的英国谚语所说:*及时一针可省九针。*一旦数据移动，调试就变得非常困难。在开发和部署阶段建立日志记录和诊断功能是非常重要的，以避免在过程的后期进行数据修复。

# 建立期望

1790 年，塞缪尔·斯莱特建立了美国第一家生产加工棉花的工厂。新摘的棉花收了进去；加工棉花出来了。近 230 年后，随着数据成为世界上最有价值的资源,“工厂”的概念也随之演变。单一静态输入的时代已经成为历史，新的标准是找出如何将每天产生的 2.5 万亿字节的数据转化为可操作的见解。构建高效的数据科学工厂需要持续的工作进展，即使是在企业的最高级别。虽然不可能交流所涉及的无数动态变量，但是集成这些基本组件是朝着正确方向迈出的一步。

关于高功能数据科学工厂的更多组件，[阅读关于特性存储库](https://www.quickpath.com/resources/2019/8/30/feature-stores-components-of-a-data-science-factory)。

*本帖最初发表于* [*Quickpath 的博客*](https://www.quickpath.com/resources/2019/9/17/automated-and-manageable-pipelines-key-components-of-a-data-science-factory) *。*