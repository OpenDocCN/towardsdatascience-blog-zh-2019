<html>
<head>
<title>Automate Stacking In Python</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">Python 中的自动化堆栈</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/automate-stacking-in-python-fc3e7834772e?source=collection_archive---------3-----------------------#2019-01-10">https://towardsdatascience.com/automate-stacking-in-python-fc3e7834772e?source=collection_archive---------3-----------------------#2019-01-10</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="ea70" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">如何在节省时间的同时提高性能</h2></div><h1 id="e959" class="kf kg iq bd kh ki kj kk kl km kn ko kp jw kq jx kr jz ks ka kt kc ku kd kv kw bi translated">介绍</h1><p id="1eb7" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">当谈到将机器学习算法推向新的高度时，利用堆叠(堆叠概括)是一个非常热门的话题。例如，现在大多数获奖的 Kaggle 提交文件都使用了某种形式的堆叠或其变体。戴维·沃伯特<em class="lt">在 1992 年的论文<em class="lt">中首次介绍了叠加泛化</em>，</em>它们的主要目的是减少泛化误差。根据沃伯特的说法，它们可以被理解为“交叉验证的更复杂版本”<em class="lt">。虽然沃伯特本人当时指出，大部分堆叠概括是“黑色艺术”，但似乎构建越来越大的堆叠概括会战胜较小的堆叠概括。然而，随着这些模型的规模不断增加，它们的复杂性也在增加。自动化构建不同架构的过程将大大简化这一过程。本文的剩余部分将处理我最近遇到的包<strong class="kz ir"> <em class="lt"> vecstack </em> </strong>，它正在尝试这个<strong class="kz ir"> <em class="lt">。</em>T15】</strong></em></p><figure class="lv lw lx ly gt lz gh gi paragraph-image"><div class="gh gi lu"><img src="../Images/60361931d904e73ef7e7714a056dda53.png" data-original-src="https://miro.medium.com/v2/resize:fit:800/1*8bY4deuFLgE5NXOuIFVUNA.gif"/></div><figcaption class="mc md gj gh gi me mf bd b be z dk">Source: <a class="ae mg" href="https://giphy.com/gifs/funny-food-hRsayJrDAx8WY" rel="noopener ugc nofollow" target="_blank">https://giphy.com/gifs/funny-food-hRsayJrDAx8WY</a></figcaption></figure><h1 id="fedd" class="kf kg iq bd kh ki kj kk kl km kn ko kp jw kq jx kr jz ks ka kt kc ku kd kv kw bi translated">堆叠式概化看起来像什么？</h1><p id="c01e" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">堆叠概化结构背后的主要思想是使用一个或多个一级模型，使用这些模型进行预测，然后使用这些预测作为要素来拟合一个或多个二级模型。为了避免过度拟合，通常使用交叉验证来预测训练集的 OOF(折叠外)部分。该套件中有两种不同的变体，但我将在本段中描述“变体 A”。为了得到这个变量的最终预测，我们取所有预测的平均值或众数。可以使用 vecstacks 文档中的这张 GIF 来可视化整个过程:</p><figure class="lv lw lx ly gt lz gh gi paragraph-image"><div class="gh gi mh"><img src="../Images/4e1eaca387e43ab3348f97db48eb63de.png" data-original-src="https://miro.medium.com/v2/resize:fit:1318/1*9uCwjY5uRkRrX2VNST7R0w.gif"/></div></figure><h1 id="8f1a" class="kf kg iq bd kh ki kj kk kl km kn ko kp jw kq jx kr jz ks ka kt kc ku kd kv kw bi translated">用例:构建用于分类的堆叠式概化</h1><p id="9180" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">看了文档之后，是时候自己尝试使用这个包了，看看它是如何工作的。为此，我决定使用 UCI 机器学习库中的葡萄酒数据集。这个数据集的问题陈述是使用 13 个特征，它们都代表了葡萄酒的不同方面，来预测葡萄酒来自意大利的三个栽培品种中的哪一个。</p><p id="2161" class="pw-post-body-paragraph kx ky iq kz b la mi jr lc ld mj ju lf lg mk li lj lk ml lm ln lo mm lq lr ls ij bi translated">首先，让我们导入我们的项目需要的包:</p><pre class="lv lw lx ly gt mn mo mp mq aw mr bi"><span id="30ef" class="ms kg iq mo b gy mt mu l mv mw"><strong class="mo ir">import pandas as</strong> pd<br/><strong class="mo ir">from</strong> <strong class="mo ir">sklearn.datasets</strong> <strong class="mo ir">import</strong> load_iris<br/><strong class="mo ir">from</strong> <strong class="mo ir">sklearn.model_selection</strong> <strong class="mo ir">import</strong> train_test_split<br/><strong class="mo ir">from</strong> <strong class="mo ir">sklearn.metrics</strong> <strong class="mo ir">import</strong> accuracy_score<br/><strong class="mo ir">from sklearn.neighbors import</strong> KNeighborsClassifier<br/><strong class="mo ir">from</strong> <strong class="mo ir">sklearn.ensemble</strong> <strong class="mo ir">import</strong> RandomForestClassifier<br/><strong class="mo ir">from</strong> <strong class="mo ir">xgboost</strong> <strong class="mo ir">import</strong> XGBClassifier<br/><strong class="mo ir">from</strong> <strong class="mo ir">vecstack</strong> <strong class="mo ir">import</strong> stacking</span></pre><p id="a73c" class="pw-post-body-paragraph kx ky iq kz b la mi jr lc ld mj ju lf lg mk li lj lk ml lm ln lo mm lq lr ls ij bi translated">现在，我们准备导入数据并查看它，以便更好地理解它的样子:</p><pre class="lv lw lx ly gt mn mo mp mq aw mr bi"><span id="ce30" class="ms kg iq mo b gy mt mu l mv mw"><strong class="mo ir">link</strong> = '<a class="ae mg" href="https://archive.ics.uci.edu/ml/machine-learning-databases/wine/wine.data'" rel="noopener ugc nofollow" target="_blank">https://archive.ics.uci.edu/ml/machine-learning-databases/wine/wine.data'</a><br/><strong class="mo ir">names</strong> = ['Class', 'Alcohol', 'Malic acid', 'Ash',<br/>         'Alcalinity of ash' ,'Magnesium', 'Total phenols',<br/>         'Flavanoids', 'Nonflavanoid phenols', 'Proanthocyanins',     'Color intensity', 'Hue', 'OD280/OD315 of diluted wines',<br/>         'Proline']</span><span id="e919" class="ms kg iq mo b gy mx mu l mv mw"><strong class="mo ir">df</strong> = <strong class="mo ir">pd</strong>.<strong class="mo ir">read_csv</strong>(link, header=None, names=names)<br/><strong class="mo ir">df</strong>.<strong class="mo ir">sample</strong>(5)</span></pre><p id="81da" class="pw-post-body-paragraph kx ky iq kz b la mi jr lc ld mj ju lf lg mk li lj lk ml lm ln lo mm lq lr ls ij bi translated">运行上面的代码块给我们带来了:</p><figure class="lv lw lx ly gt lz gh gi paragraph-image"><div role="button" tabindex="0" class="mz na di nb bf nc"><div class="gh gi my"><img src="../Images/223f3e8e5cad2cb6834046222e8ff48a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*GRhVv2cujurPkNPpXFYLXg.png"/></div></div></figure><p id="1c5e" class="pw-post-body-paragraph kx ky iq kz b la mi jr lc ld mj ju lf lg mk li lj lk ml lm ln lo mm lq lr ls ij bi translated">注意我用的是<strong class="kz ir">。样()</strong>改为 if <strong class="kz ir">。head() </strong>避免由于假设整个数据集具有前五行的结构而被误导。幸运的是，这个数据集没有任何缺失值，所以我们可以很容易地使用它来测试我们的包，而不需要任何通常需要的数据清理和准备。</p><p id="d57e" class="pw-post-body-paragraph kx ky iq kz b la mi jr lc ld mj ju lf lg mk li lj lk ml lm ln lo mm lq lr ls ij bi translated">接下来，我们将从输入变量中分离出响应，并按照 vecstacks 文档中的示例执行 80:20 的训练测试分割。</p><pre class="lv lw lx ly gt mn mo mp mq aw mr bi"><span id="2550" class="ms kg iq mo b gy mt mu l mv mw"><strong class="mo ir">y</strong> = df[['Class']]<br/><strong class="mo ir">X</strong> = df.iloc[:,1:]</span><span id="436c" class="ms kg iq mo b gy mx mu l mv mw"><strong class="mo ir">X_train, X_test, y_train, y_test</strong> = train_test_split(X, y, test_size=0.2, random_state=0)</span></pre><p id="acb3" class="pw-post-body-paragraph kx ky iq kz b la mi jr lc ld mj ju lf lg mk li lj lk ml lm ln lo mm lq lr ls ij bi translated">我们越来越接近有趣的部分了。还记得之前的 GIF 吗？现在是时候为我们的堆叠概括定义一些第一级模型了。这一步绝对值得单独写一篇文章，但是为了简单起见，我们将使用三个模型:KNN 分类器、随机森林分类器和 XGBoost 分类器。</p><pre class="lv lw lx ly gt mn mo mp mq aw mr bi"><span id="b500" class="ms kg iq mo b gy mt mu l mv mw"><strong class="mo ir">models</strong> = [<br/>    <strong class="mo ir">KNeighborsClassifier</strong>(n_neighbors=5,<br/>                        n_jobs=-1),<br/>        <br/>    <strong class="mo ir">RandomForestClassifier</strong>(random_state=0, n_jobs=-1, <br/>                           n_estimators=100, max_depth=3),<br/>        <br/>    <strong class="mo ir">XGBClassifier</strong>(random_state=0, n_jobs=-1, learning_rate=0.1, <br/>                  n_estimators=100, max_depth=3)<br/>]</span></pre><p id="4e19" class="pw-post-body-paragraph kx ky iq kz b la mi jr lc ld mj ju lf lg mk li lj lk ml lm ln lo mm lq lr ls ij bi translated">这些参数在设置之前没有被调优，因为本文的目的是测试这个包。如果你要优化性能，你不应该只是复制和粘贴这些。</p><p id="59aa" class="pw-post-body-paragraph kx ky iq kz b la mi jr lc ld mj ju lf lg mk li lj lk ml lm ln lo mm lq lr ls ij bi translated">从文档中取出下一部分代码，我们实际上是使用第一级模型进行预测来执行 GIF 的第一部分:</p><pre class="lv lw lx ly gt mn mo mp mq aw mr bi"><span id="d94f" class="ms kg iq mo b gy mt mu l mv mw"><strong class="mo ir">S_train, S_test</strong> = <strong class="mo ir">stacking</strong>(models,                   <br/>                           X_train, y_train, X_test,   <br/>                           regression=False, <br/>     <br/>                           mode='oof_pred_bag', <br/>       <br/>                           needs_proba=False,<br/>         <br/>                           save_dir=None, <br/>            <br/>                           metric=accuracy_score, <br/>    <br/>                           n_folds=4, <br/>                 <br/>                           stratified=True,<br/>            <br/>                           shuffle=True,  <br/>            <br/>                           random_state=0,    <br/>         <br/>                           verbose=2)</span></pre><p id="0d95" class="pw-post-body-paragraph kx ky iq kz b la mi jr lc ld mj ju lf lg mk li lj lk ml lm ln lo mm lq lr ls ij bi translated">堆叠函数接受几个输入:</p><ul class=""><li id="2e4d" class="nd ne iq kz b la mi ld mj lg nf lk ng lo nh ls ni nj nk nl bi translated"><strong class="kz ir"> <em class="lt">车型</em> </strong>:我们前面定义的第一级车型</li><li id="5f46" class="nd ne iq kz b la nm ld nn lg no lk np lo nq ls ni nj nk nl bi translated"><strong class="kz ir"> <em class="lt"> X_train，y_train，X_test </em> </strong>:我方数据</li><li id="0fe7" class="nd ne iq kz b la nm ld nn lg no lk np lo nq ls ni nj nk nl bi translated"><strong class="kz ir"> <em class="lt">回归</em> </strong>:布尔值，表示是否要使用函数进行回归。在我们的例子中设置为 False，因为这是一个分类</li><li id="b158" class="nd ne iq kz b la nm ld nn lg no lk np lo nq ls ni nj nk nl bi translated"><strong class="kz ir"> <em class="lt">模式:</em> </strong>使用前面描述的出叠方式进行交叉验证</li><li id="795e" class="nd ne iq kz b la nm ld nn lg no lk np lo nq ls ni nj nk nl bi translated"><strong class="kz ir"> <em class="lt"> needs_proba </em> </strong>:布尔值，表示是否需要类别标签的概率</li><li id="87f0" class="nd ne iq kz b la nm ld nn lg no lk np lo nq ls ni nj nk nl bi translated"><strong class="kz ir"> <em class="lt"> save_dir </em> </strong>:将结果保存到目录 Boolean</li><li id="2633" class="nd ne iq kz b la nm ld nn lg no lk np lo nq ls ni nj nk nl bi translated"><strong class="kz ir"> <em class="lt">度量</em> </strong>:使用什么评估度量(我们一开始导入了 accuracy_score)</li><li id="1886" class="nd ne iq kz b la nm ld nn lg no lk np lo nq ls ni nj nk nl bi translated"><strong class="kz ir"> <em class="lt"> n_folds </em> </strong>:交叉验证使用多少个折叠</li><li id="0f7d" class="nd ne iq kz b la nm ld nn lg no lk np lo nq ls ni nj nk nl bi translated"><strong class="kz ir"><em class="lt"/></strong>:是否使用分层交叉验证</li><li id="d6aa" class="nd ne iq kz b la nm ld nn lg no lk np lo nq ls ni nj nk nl bi translated"><strong class="kz ir"> <em class="lt">洗牌</em> </strong>:是否洗牌</li><li id="33be" class="nd ne iq kz b la nm ld nn lg no lk np lo nq ls ni nj nk nl bi translated"><strong class="kz ir"> <em class="lt"> random_state </em> </strong>:设定再现性的随机状态</li><li id="cb72" class="nd ne iq kz b la nm ld nn lg no lk np lo nq ls ni nj nk nl bi translated"><strong class="kz ir"> <em class="lt">详细</em> </strong> : 2 这里是指打印所有信息</li></ul><p id="78aa" class="pw-post-body-paragraph kx ky iq kz b la mi jr lc ld mj ju lf lg mk li lj lk ml lm ln lo mm lq lr ls ij bi translated">这样，我们得到以下输出:</p><pre class="lv lw lx ly gt mn mo mp mq aw mr bi"><span id="63c0" class="ms kg iq mo b gy mt mu l mv mw">task:         [classification]<br/>n_classes:    [3]<br/>metric:       [accuracy_score]<br/>mode:         [oof_pred_bag]<br/>n_models:     [4]</span><span id="e848" class="ms kg iq mo b gy mx mu l mv mw">model  0:     [KNeighborsClassifier]<br/>    fold  0:  [0.72972973]<br/>    fold  1:  [0.61111111]<br/>    fold  2:  [0.62857143]<br/>    fold  3:  [0.76470588]<br/>    ----<br/>    MEAN:     [0.68352954] + [0.06517070]<br/>    FULL:     [0.68309859]</span><span id="0814" class="ms kg iq mo b gy mx mu l mv mw">model  1:     [ExtraTreesClassifier]<br/>    fold  0:  [0.97297297]<br/>    fold  1:  [1.00000000]<br/>    fold  2:  [0.94285714]<br/>    fold  3:  [1.00000000]<br/>    ----<br/>    MEAN:     [0.97895753] + [0.02358296]<br/>    FULL:     [0.97887324]</span><span id="0208" class="ms kg iq mo b gy mx mu l mv mw">model  2:     [RandomForestClassifier]<br/>    fold  0:  [1.00000000]<br/>    fold  1:  [1.00000000]<br/>    fold  2:  [0.94285714]<br/>    fold  3:  [1.00000000]<br/>    ----<br/>    MEAN:     [0.98571429] + [0.02474358]<br/>    FULL:     [0.98591549]</span><span id="165d" class="ms kg iq mo b gy mx mu l mv mw">model  3:     [XGBClassifier]<br/>    fold  0:  [1.00000000]<br/>    fold  1:  [0.97222222]<br/>    fold  2:  [0.91428571]<br/>    fold  3:  [0.97058824]<br/>    ----<br/>    MEAN:     [0.96427404] + [0.03113768]<br/>    FULL:     [0.96478873]</span></pre><p id="fff3" class="pw-post-body-paragraph kx ky iq kz b la mi jr lc ld mj ju lf lg mk li lj lk ml lm ln lo mm lq lr ls ij bi translated">再一次，参考 GIF，现在剩下要做的就是在我们的预测上拟合我们选择的第二层模型，以做出我们的最终预测。在我们的例子中，我们将使用 XGBoost 分类器。这一步与 sklearn 中的常规拟合和预测没有显著不同，除了这样一个事实，即我们不是使用 X_train 来训练我们的模型，而是使用我们的预测 S_train。</p><pre class="lv lw lx ly gt mn mo mp mq aw mr bi"><span id="0eeb" class="ms kg iq mo b gy mt mu l mv mw"><strong class="mo ir">model</strong> = <strong class="mo ir">XGBClassifier</strong>(random_state=0, n_jobs=-1, learning_rate=0.1, <br/>                      n_estimators=100, max_depth=3)<br/>    <br/><strong class="mo ir">model</strong> = model.fit(<strong class="mo ir">S_train</strong>, y_train)</span><span id="de4e" class="ms kg iq mo b gy mx mu l mv mw"><strong class="mo ir">y_pred</strong> = model.predict(S_test)</span><span id="f39d" class="ms kg iq mo b gy mx mu l mv mw">print('Final prediction score: [%.8f]' % accuracy_score(y_test, y_pred))</span><span id="4290" class="ms kg iq mo b gy mx mu l mv mw">Output: Final prediction score: [0.97222222]</span></pre><h1 id="d957" class="kf kg iq bd kh ki kj kk kl km kn ko kp jw kq jx kr jz ks ka kt kc ku kd kv kw bi translated">结论</h1><p id="4374" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">使用 vecstacks 的堆叠自动化，我们成功预测了正确的葡萄酒品种，准确率约为 97.2%！如您所见，该 API 与 sklearn API 并不冲突，因此可以在尝试加速堆叠工作流时提供一个有用的工具。</p><p id="9396" class="pw-post-body-paragraph kx ky iq kz b la mi jr lc ld mj ju lf lg mk li lj lk ml lm ln lo mm lq lr ls ij bi translated">一如既往，如果您有任何反馈或发现错误，请随时联系我。</p></div><div class="ab cl nr ns hu nt" role="separator"><span class="nu bw bk nv nw nx"/><span class="nu bw bk nv nw nx"/><span class="nu bw bk nv nw"/></div><div class="ij ik il im in"><p id="cde7" class="pw-post-body-paragraph kx ky iq kz b la mi jr lc ld mj ju lf lg mk li lj lk ml lm ln lo mm lq lr ls ij bi translated"><em class="lt">参考文献</em>:</p><p id="1ee4" class="pw-post-body-paragraph kx ky iq kz b la mi jr lc ld mj ju lf lg mk li lj lk ml lm ln lo mm lq lr ls ij bi translated">[1]戴维·h·沃尔波特，<a class="ae mg" href="https://www.researchgate.net/publication/222467943_Stacked_Generalization" rel="noopener ugc nofollow" target="_blank"/>(1992)，神经网络</p><p id="6e6c" class="pw-post-body-paragraph kx ky iq kz b la mi jr lc ld mj ju lf lg mk li lj lk ml lm ln lo mm lq lr ls ij bi translated">[2]伊戈尔·伊万诺夫，<a class="ae mg" href="https://github.com/vecxoz/vecstack" rel="noopener ugc nofollow" target="_blank"> Vecstack </a> (2016)，GitHub</p><p id="4e2b" class="pw-post-body-paragraph kx ky iq kz b la mi jr lc ld mj ju lf lg mk li lj lk ml lm ln lo mm lq lr ls ij bi translated">[3] M. Forina 等人，<a class="ae mg" href="https://archive.ics.uci.edu/ml/datasets/wine" rel="noopener ugc nofollow" target="_blank">葡萄酒数据集</a> (1991)，UCI 机器学习知识库</p></div></div>    
</body>
</html>