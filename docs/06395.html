<html>
<head>
<title>PySpark: CountVectorizer|HashingTF</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">py spark:count vectorizer | HashingTF</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/countvectorizer-hashingtf-e66f169e2d4e?source=collection_archive---------0-----------------------#2019-09-14">https://towardsdatascience.com/countvectorizer-hashingtf-e66f169e2d4e?source=collection_archive---------0-----------------------#2019-09-14</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><figure class="gl gn jo jp jq jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi jn"><img src="../Images/2f17446d3f11871958ba9f4140af503b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*CIZO-ZsHMrqHSTvFvNV4PA.png"/></div></div></figure><p id="9fb7" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">我在将商业实体与其相应的品牌名称进行匹配时，偶然发现了这些术语。但是，让我用一些更简单的例子向您介绍一下。</p><p id="4656" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">在深入研究 CountVectorizer 和 HashingTF 之前，让我们先大致了解一下它们是做什么的。</p><p id="51ee" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">计数矢量器和哈希函数估计器用于生成术语频率向量。它们基本上将文档转换为数字表示，可以直接输入或进一步处理为其他算法，如 LDA、Jaccard 距离的 MinHash、余弦距离等。</p><p id="9717" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">假设我们的数据库中只有 2 个文档，我们希望将它们转换成一个特征向量。</p><figure class="kx ky kz la gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi kw"><img src="../Images/1bac975ea6162ef7cf0f23fae1036b13.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Ib2mkLvMLIqLaVC0biUFuw.png"/></div></div></figure><p id="845d" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">我们可以继续使用特征提取算法，例如术语频率-逆文档频率(TF-IDF)</p><h1 id="e361" class="lb lc iq bd ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly bi translated"><strong class="ak"> TF-IDF </strong></h1><p id="16cd" class="pw-post-body-paragraph jy jz iq ka b kb lz kd ke kf ma kh ki kj mb kl km kn mc kp kq kr md kt ku kv ij bi translated">这是一种将文档转换成向量的方法，使得向量反映术语对于语料库中的文档的重要性。</p><p id="79e8" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">如果我们用 t 表示术语，用 D 表示文档，用 D 表示语料库</p><p id="4949" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated"><strong class="ka ir">术语频率(TF(t，d)) </strong>:术语 t 在文档 d 中出现的次数</p><p id="7f41" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">这里，TF(PYTHON，Document 1)= 1；TF(HIVE，文档 1) = 2</p><p id="000a" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated"><strong class="ka ir"> <em class="me">必须注意的是，HashingTF 和 CountVectorizer 都可以用来生成术语频率向量</em> </strong></p><p id="44d1" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated"><strong class="ka ir">文档频率(DF(t，D)) </strong>:包含术语 t 的文档的数量</p><p id="60f3" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">这里 DF(PYTHON，Document 1)= 1；DF(HIVE，文档 1) = 1</p><p id="d293" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">然而，像 a、an 等这样的停用词。在语料库中出现频率很高，但没有特殊含义。为了解决这个问题，我们使用了逆文档频率(IDF)。</p><p id="3776" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated"><strong class="ka ir"> IDF(t，D) </strong>:术语提供多少信息的数值度量</p><figure class="kx ky kz la gt jr gh gi paragraph-image"><div class="gh gi mf"><img src="../Images/910f114bcfe481d50c674865eff95948.png" data-original-src="https://miro.medium.com/v2/resize:fit:550/format:webp/1*6LU1JQBUigPVtdwhBfkK8A.png"/></div></figure><p id="5302" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">这里 IDF(PYTHON，Document 1)= log((2+1)/(1+1))~ 0.405</p><p id="320c" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">类似地，IDF(HIVE，文献 1) ~0.405</p><p id="290a" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated"><strong class="ka ir">TF-IDF:</strong>TF 与 IDF 的乘积。</p><figure class="kx ky kz la gt jr gh gi paragraph-image"><div class="gh gi mg"><img src="../Images/bffb744e3aa4e49bf23971bfaa3e75ba.png" data-original-src="https://miro.medium.com/v2/resize:fit:706/format:webp/1*yG0c274pRIjgUCTcYdz2_w.png"/></div></figure><p id="751b" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">这里 TF-IDF(PYTHON，文档 1，语料库)~ 0.405</p><p id="fbd0" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">同样，TF-IDF(HIVE，文档 1，语料库)~0.81</p><p id="6954" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">因此，TF-IDF 确保了在文档中具有高频率的术语将具有高 TF，但是如果一个术语在语料库中具有高频率，则它的重要性被 IDF 降低。语料库中所有文档中出现的术语将具有等于 0 的 TF-IDF。</p><p id="8af4" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">正如我们已经看到的，HashingTF 和 CountVectorizer 都可以用来生成术语频率向量。因此，现在让我们深入了解每一种方法，了解它们的优点和缺点。</p><h1 id="35a8" class="lb lc iq bd ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly bi translated"><strong class="ak">计数矢量器</strong></h1><p id="d3dc" class="pw-post-body-paragraph jy jz iq ka b kb lz kd ke kf ma kh ki kj mb kl km kn mc kp kq kr md kt ku kv ij bi translated">CountVectorizer 将文本文档转换为提供令牌计数信息的向量。</p><p id="7e13" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">让我们继续讨论前面讨论过的具有 2 个文档的相同语料库。我们想把文档转换成词频向量</p><pre class="kx ky kz la gt mh mi mj mk aw ml bi"><span id="ae1c" class="mm lc iq mi b gy mn mo l mp mq"><em class="me"># Input data: Each row is a bag of words with an ID</em><br/>df = hiveContext.createDataFrame([<br/>    (0, "PYTHON HIVE HIVE".split(" ")),<br/>    (1, "JAVA JAVA SQL".split(" "))<br/>], ["id", "words"])</span><span id="4e0b" class="mm lc iq mi b gy mr mo l mp mq">df.show(truncate = False)</span></pre><figure class="kx ky kz la gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi ms"><img src="../Images/82b0b65a2bdc6ad5a8bda3df44872847.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ORA8fgFhtHfQvRcx1yGm8A.png"/></div></div></figure><p id="1543" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">首先，CountVectorizer 将生成一个词汇表，以防没有先验词汇表。例如，在这个例子中，CountVectorizer 将创建一个大小为 4 的词汇表，其中包括 PYTHON、HIVE、JAVA 和 SQL 术语。接下来是计数矢量器模型的拟合。在拟合过程中，CountVectorizer 将选择按词频排序的顶级词汇。该模型将产生一个稀疏向量，可以馈入其他算法。</p><pre class="kx ky kz la gt mh mi mj mk aw ml bi"><span id="1b8e" class="mm lc iq mi b gy mn mo l mp mq"><em class="me"># Fit a CountVectorizerModel from the corpus</em><br/>from pyspark.ml.feature import CountVectorizer<br/>cv = CountVectorizer(inputCol="words", outputCol="features")</span><span id="c5e8" class="mm lc iq mi b gy mr mo l mp mq">model = cv.fit(df)</span><span id="8e07" class="mm lc iq mi b gy mr mo l mp mq">result = model.transform(df)<br/>result.show(truncate=False)</span></pre><figure class="kx ky kz la gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi ms"><img src="../Images/276bc513de7ab1be7876e4907f250571.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*cE0fIDQbIWoHuFLcvujqmw.png"/></div></div></figure><p id="b637" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">为了便于理解，特征向量可以分成 3 个部分</p><figure class="kx ky kz la gt jr gh gi paragraph-image"><div class="gh gi mt"><img src="../Images/4993b333f9f4c0d87b5f324d4bc3bc50.png" data-original-src="https://miro.medium.com/v2/resize:fit:1376/format:webp/1*LvsokJXq_I77pgKb9ZckUg.png"/></div></figure><ul class=""><li id="b17a" class="mu mv iq ka b kb kc kf kg kj mw kn mx kr my kv mz na nb nc bi translated">开头的数字代表向量的大小。在这里，是 4。</li><li id="983c" class="mu mv iq ka b kb nd kf ne kj nf kn ng kr nh kv mz na nb nc bi translated">第一列数字代表矢量索引。</li></ul><figure class="kx ky kz la gt jr gh gi paragraph-image"><div class="gh gi ni"><img src="../Images/c3a9eefaad05b085a16b04669f483011.png" data-original-src="https://miro.medium.com/v2/resize:fit:742/format:webp/1*BXTQ7nnRNtc9DLadnYeBAQ.png"/></div></figure><p id="8f29" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">例如，与频率为 1 的术语“SQL”相比，“JAVA”术语的频率为 2。因此，“JAVA”的索引是 1，而“SQL”的索引是 2</p><ul class=""><li id="74dc" class="mu mv iq ka b kb kc kf kg kj mw kn mx kr my kv mz na nb nc bi translated">第二列数字代表与这些指数相对应的值。</li></ul><p id="db00" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">在文档 2 中可以看出，索引为 1 的‘JAVA’的值为 2，索引为 2 的‘SQL’的值为 1</p><p id="f2e2" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">然而，应该注意的是，由于“HIVE”和“JAVA”的频率相同，所以索引是可以互换的。</p><figure class="kx ky kz la gt jr gh gi paragraph-image"><div class="gh gi nj"><img src="../Images/9c8322be90f5747c6ad81eca36bfe99a.png" data-original-src="https://miro.medium.com/v2/resize:fit:992/format:webp/1*PdzU9Mp3-pC4baRyjK09Tw.png"/></div><figcaption class="nk nl gj gh gi nm nn bd b be z dk">Here, ’HIVE’ has index 0 and ‘JAVA’ has index 1</figcaption></figure><figure class="kx ky kz la gt jr gh gi paragraph-image"><div class="gh gi no"><img src="../Images/8ca17e4461e66d39eb98c54a63f5d420.png" data-original-src="https://miro.medium.com/v2/resize:fit:976/format:webp/1*QuUdQrgdEv1fhKWMmDW9QA.png"/></div><figcaption class="nk nl gj gh gi nm nn bd b be z dk">Here, ’HIVE’ has index 1 and ‘JAVA’ has index 0</figcaption></figure><p id="5a05" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">类似的，其他具有相同频率的术语也是如此。</p><h1 id="0c34" class="lb lc iq bd ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly bi translated"><strong class="ak"> HashingTF </strong></h1><p id="9354" class="pw-post-body-paragraph jy jz iq ka b kb lz kd ke kf ma kh ki kj mb kl km kn mc kp kq kr md kt ku kv ij bi translated">HashingTF 将文档转换为固定大小的矢量。默认特征尺寸为 262，144。使用散列函数将术语映射到索引。使用的哈希函数是 MurmurHash 3。相对于映射的索引来计算项频率。</p><pre class="kx ky kz la gt mh mi mj mk aw ml bi"><span id="f4b6" class="mm lc iq mi b gy mn mo l mp mq"><em class="me"># Get term frequency vector through HashingTF</em><br/>from pyspark.ml.feature import HashingTF</span><span id="09e4" class="mm lc iq mi b gy mr mo l mp mq">ht = HashingTF(inputCol="words", outputCol="features")</span><span id="1afb" class="mm lc iq mi b gy mr mo l mp mq">result = ht.transform(df)<br/>result.show(truncate=False)</span></pre><figure class="kx ky kz la gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi ms"><img src="../Images/e4fe744a1fb09ea97063eb7fb1006335.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ewi6TzvNlFGZgxIyY6U9BQ.png"/></div></div></figure><p id="714c" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">从上面的例子中可以看出，向量的维数被设置为默认值，即 262，144。此外，术语“PYTHON”通过散列函数被映射到索引 134160，并且具有等于 1 的频率。类似地，可以获得关于其他术语的见解。</p><h1 id="8a34" class="lb lc iq bd ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly bi translated"><strong class="ak">对比与结论</strong></h1><p id="99df" class="pw-post-body-paragraph jy jz iq ka b kb lz kd ke kf ma kh ki kj mb kl km kn mc kp kq kr md kt ku kv ij bi translated">我们已经看到，CountVectorizer 和 HashingTF 都可以被实现来生成频率向量。然而，这两种实现各有优缺点。让我们仔细看看它们之间的差异，以选择最适合我们要求的算法。-</p><ul class=""><li id="10dd" class="mu mv iq ka b kb kc kf kg kj mw kn mx kr my kv mz na nb nc bi translated">通过 CountVectorizer 生成的向量的大小取决于训练语料库和文档，而通过 HashingTF 生成的向量的大小是固定的。默认大小为 262，144</li><li id="a51d" class="mu mv iq ka b kb nd kf ne kj nf kn ng kr nh kv mz na nb nc bi translated">在计数矢量器的情况下，每个原始特征被映射到一个索引。然而，HashingTF 遭受潜在的哈希冲突，即 2 个或更多的项可能被映射到相同的索引，从而在哈希之后变得相同。然而，为了避免哈希冲突，我们可以增加目标特征的维数</li><li id="d899" class="mu mv iq ka b kb nd kf ne kj nf kn ng kr nh kv mz na nb nc bi translated">由于全局项到索引的映射，CountVectorizer 与使用哈希技巧的 HashingTF 相比，计算开销更大。</li><li id="4e1d" class="mu mv iq ka b kb nd kf ne kj nf kn ng kr nh kv mz na nb nc bi translated">很难解释通过 HashingTF 创建的向量，因为散列是不可逆的，所以无法恢复原始输入。但是，在使用 CountVectorizer 的情况下，可以恢复输入</li></ul><p id="befb" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">显然，这两种算法之间有一个权衡。但是，我们可以得出结论，在拥有大量数据集的情况下，使用比 HashingTF 稍低的精度会更合适，而在需要反向映射的情况下，CountVectorizer 会更合适。</p><p id="5eba" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">希望有所帮助:)</p></div></div>    
</body>
</html>