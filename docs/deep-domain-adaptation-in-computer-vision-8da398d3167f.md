# 计算机视觉中的深度域适应

> 原文：<https://towardsdatascience.com/deep-domain-adaptation-in-computer-vision-8da398d3167f?source=collection_archive---------6----------------------->

在过去的十年中，计算机视觉领域取得了巨大的进步。这一进步主要是由于卷积神经网络(CNN)不可否认的有效性。如果用高质量的带注释的训练数据进行训练，CNN 允许非常精确的预测。例如，在分类设置中，您通常会使用标准网络架构之一(ResNet、VGG 等)。)并使用您的数据集对其进行训练。这可能会带来非常好的性能。

另一方面，如果您没有针对您的特定问题的大量人工注释数据集，CNN 还允许通过迁移学习来利用已经针对类似问题训练了网络的其他人。在这种情况下，您可以采用一个在大型数据集上进行预训练的网络，并使用您自己的小型带注释的数据集来调整它的一些上层。

这两种方法都假设您的训练数据(无论大小)代表了基本分布。但是，如果测试时的输入与定型数据显著不同，则模型的性能可能不会很好。例如，让我们假设你是一名自动驾驶汽车工程师，你想分割汽车摄像头拍摄的图像，以便了解前方的情况(建筑物、树木、其他汽车、行人、交通灯等)。).您的 NYC 数据集有很好的人工生成的注释，并且您使用这些注释训练了一个大型网络。你在曼哈顿的街道上测试你的自动驾驶汽车，一切似乎都很好。然后你在巴黎测试同样的系统，突然事情变得非常糟糕。汽车不再能够检测交通灯，汽车看起来非常不同(巴黎没有黄色出租车)，街道也不再笔直。

您的模型在这些场景中表现不佳的原因是问题域发生了变化。在这种特殊情况下，输入数据的域发生了变化，而任务域(标签)保持不变。在其他情况下，您可能希望使用来自同一域的数据(为同一基础分布绘制)来完成一项新任务。类似地，输入和任务域可以同时不同。在这些情况下，**领域适应**会帮助你。领域自适应是机器学习的一个子学科，处理**场景，其中在源分布上训练的模型被用于不同(但相关)目标分布的上下文中**。一般来说，领域自适应使用一个或多个源领域中的标记数据来解决目标领域中的新任务。因此，源域和目标域之间的相关程度通常决定了适配的成功程度。

领域适应有多种方法。在**“浅”(非深)域适应**中，通常使用两种方法:**重新加权源样本**并对重新加权的样本进行训练，并尝试**学习共享空间以匹配源和目标数据集的分布**。虽然这些技术也可以应用于深度学习的环境中，但深度神经网络学习的深度特征( **DNNs** )通常会产生更多可转移的表示(通常在较低层中学习高度可转移的特征，而在较高层中可转移性急剧下降，参见例如 Donahue 等人的[这篇论文)。在**深度域适配**中，我们尝试利用 DNNs 的这一特性。](https://arxiv.org/pdf/1310.1531.pdf)

# 领域适应类别

以下总结主要基于[Wang 等人的这篇综述论文](https://arxiv.org/pdf/1802.03601v4.pdf)和[Wilson 等人的这篇综述](https://arxiv.org/pdf/1812.02849v2.pdf)。在该工作中，作者根据任务的复杂性、可用的标记/未标记数据的数量以及输入特征空间的差异来区分不同类型的领域适应。**他们特别将领域适应定义为一个问题，其中任务空间相同，差异仅在于输入领域发散**。基于该定义，域自适应可以是同质的(输入特征空间是相同的，但是具有不同的数据分布)或者异质的(特征空间及其维度可以不同)。

域适配也可以在一个步骤中发生(**一步域适配**)，或者通过多个步骤，在过程中遍历一个或多个域(**多步域适配**)。在这篇文章中，我们将只讨论一步域适应，因为这是最常见的域适应类型。

根据您从目标领域获得的数据，领域适应可以进一步分为**监督的**(您确实有来自目标领域的标记数据，尽管这个数量对于训练整个模型来说太小了)、**半监督的**(您有标记和未标记的数据)，以及**非监督的**(您没有来自目标领域的任何标记数据)。

# 任务相关性

我们如何确定在源领域中训练的模型是否可以适应我们的目标领域？事实证明，这个问题并不容易回答，任务相关性仍然是一个活跃的研究课题。如果两个任务使用相同的特征进行决策，我们可以将它们定义为相似的。另一种可能性是，如果两个任务的参数向量(即分类边界)接近，则将这两个任务定义为相似的(参见薛等人的[本文](http://jmlr.csail.mit.edu/papers/volume8/xue07a/xue07a.pdf))。另一方面， [Ben-David 等人](https://doi.org/10.1007/978-3-540-45167-9_41)提出，如果两个任务的数据可以使用一组变换 F 从固定的概率分布中生成，则这两个任务是 F 相关的

尽管有这些理论上的考虑，但在实践中，可能有必要在您自己的数据集上尝试域适应，看看您是否可以通过使用来自源任务的模型来为您的目标任务获得一些好处。通常，任务相关性可以通过简单的推理来确定，例如来自不同视角或不同照明条件的图像，或者在医学领域中，来自不同设备的图像等等。

# 一步域自适应技术及其应用

一步域适配有三种基本技术:

*   基于散度的域自适应，
*   使用生成模型(GANs)或使用领域混淆损失的基于对抗的领域适应，以及
*   使用堆叠自动编码器(SAE)或 GANs 的基于重构的域自适应。

## 基于散度的领域适应

基于散度的域自适应通过**最小化源和目标数据分布**之间的一些散度标准来工作，从而实现**域不变特征表示**。如果我们找到这样的特征表示，分类器将能够在两个域上同样好地执行。这当然假设这样的表示存在，这又假设任务以某种方式相关。

四种最常用的差异度量是**最大平均差异**(MMD)**相关比对**(CORAL)**对比域差异** (CCD)和 Wasserstein 度量。

MMD 是一种假设检验，在将两个样本映射到再生核希尔伯特空间(RKHS)后，通过比较特征的平均值来检验这两个样本是否来自同一分布。如果均值不同，分布也可能不同。这通常通过使用内核嵌入技巧和使用高斯内核比较样本来实现。这里的直觉是，如果两个分布是相同的，则来自每个分布的样本之间的平均相似性应该等于来自两个分布的混合样本之间的平均相似性。在域自适应中使用 MMD 的一个示例是 Rozantsev 等人的[这篇论文](https://arxiv.org/pdf/1603.06432.pdf)在这篇论文中，使用了双流架构，其权重不共享，但通过使用分类、正则化和域差异(MMD)损失的组合来产生相似的特征表示，如下图所示。

![](img/0f2c8cbe4ad3c1218f609938c414fb6a.png)

Two-stream architecture by Rozantsev et al.

因此，该设置可以是监督的、半监督的或者甚至是无监督的(在目标域中没有分类损失)。

CORAL ( [链接](https://arxiv.org/pdf/1511.05547.pdf))类似于 MMD，但是它试图对齐源和目标分布的二阶统计量(相关性)，而不是使用线性变换的平均值。[Sun 等人的论文](https://arxiv.org/pdf/1607.01719.pdf)通过使用源和目标协方差矩阵之间的 Frobenius 范数构造可微分的 CORAL 损失，在深度学习的上下文中使用 CORAL。

CCD 也是基于 MMD，但也通过查看条件分布来利用标签分布。这确保了联合域特征仍然保持对标签的预测性。最小化 CCD 最小化类内差异，同时最大化类间差异。这需要源和目标域标签。为了摆脱这种约束， [Kang 等人](https://arxiv.org/pdf/1901.00976.pdf)提出在联合优化目标标签和特征表示的迭代过程中使用聚类来估计丢失的目标标签。因此，通过聚类找到目标标签，然后最小化 CCD 以适应这些特征。

最后，源和目标域中的特征和标签分布可以通过考虑最优传输问题及其相应的距离，即 Wasserstein 距离来对齐。这是在 [DeepJDOT](https://arxiv.org/pdf/1803.10081.pdf) (Damodaran 等人)中提出的。作者建议通过最佳传输来最小化联合深度特征表示和标签之间的差异。

## 基于对抗的领域适应

这种技术试图通过使用对抗训练来实现领域适应。

一种方法是使用**生成对抗网络** (GANs)生成与源域有某种关联的合成目标数据(例如通过保留标签)。这些合成数据然后用于训练目标模型。

[**CoGAN 模型**](https://arxiv.org/pdf/1606.07536.pdf) 试图通过为源和目标分布使用两个生成器/鉴别器对来实现这一点。生成器和鉴别器的一些权重被共享以学习域不变特征空间。以这种方式，可以生成标记的目标数据，其可以进一步用于诸如分类的任务中。

![](img/600f6c025be66d7e8d5b076acafdaf8c.png)

CoGAN architecture by Liu et al.

在另一个装置中， [Yoo 等人](https://arxiv.org/pdf/1603.07442.pdf)试图通过使用两个鉴别器来学习**源/目标转换器网络**:一个用于确保目标数据是真实的，另一个用于保持源和目标域之间的相关性。**发生器**在此**以源数据**为条件。这种方法只需要目标域中未标记的数据。

除了用于当前任务的分类损失之外，如果我们使用所谓的**域混淆损失**，我们还可以**完全去除生成器**，并且一次执行域适应。域混淆损失类似于 GANs 中的鉴别器，因为它试图匹配源和目标域的分布，以便“混淆”高级分类层。这种网络最著名的例子可能是 Ganin 等人的**域对抗神经网络** (DANN)。该网络包括两个损失，分类损失和域混淆损失。它包含一个**梯度反转层**来匹配特征分布。通过最小化源样本的分类损失和所有样本的域混淆损失(同时最大化特征提取的域混淆损失)，这确保了样本对于分类器是相互不可区分的。

![](img/149e3aa86585d3fa4939ba418cea7a5e.png)

Domain-adversarial neural network architecture by [Ganin et al.](https://arxiv.org/pdf/1409.7495.pdf)

## 基于重构的域适应

这种方法使用**辅助重建任务**来为每个域创建共享表示。例如， [**深度重建分类网络**](https://arxiv.org/pdf/1607.03516.pdf)【DRCN】试图同时解决这两个任务:(I)源数据的分类，和(ii)未标记目标数据的重建。这确保了网络不仅学会了正确区分，而且还保存了关于目标数据的信息。在该论文中，作者还提到重建管道学习将源图像转换成类似于目标数据集的图像，这表明为两者学习了共同的表示。

![](img/f010731cfd7c7866c470efb9cd1666dc.png)

The DRCN architecture by Ghifary et al.

另一种可能性是使用所谓的**循环杆**。Cycle GANs 的灵感来源于机器翻译中双重学习的概念。这个概念同时训练两个相反的语言翻译者(A-B，B-A)。循环中的反馈信号由相应的语言模型和相互 BLEU 分数组成。使用 im2im 框架可以对图像进行同样的处理。在本文的[中，从一个图像域到另一个图像域的映射是在不使用任何成对图像样本的情况下学习的。这是通过同时训练分别在两个域中生成图像的两个 gan 来实现的。为了确保一致性，引入了**周期一致性损失**。这确保了从一个域到另一个域的变换，以及从一个域到另一个域的变换，会产生与输入大致相同的图像。因此，两个配对网络的全部损耗是两个鉴别器的 GAN 损耗和周期一致性损耗的总和。](https://arxiv.org/pdf/1703.10593.pdf)

最后，通过对来自另一个域的图像的输入进行调节，GANs 也可以用于编码器-解码器设置。在 Isola 等人的[论文中，](https://arxiv.org/pdf/1611.07004.pdf) **条件 GANs** 用于通过在输入端调节鉴别器和发生器的输出，将图像从一个域转换到另一个域。这可以使用简单的编码器-解码器架构或者使用具有跳跃连接的 U-Net 架构来实现。

![](img/769ed4cd822cac40baa9b2cfec0c3de5.png)

Several results from the conditional GAN by Isola et al.

# 结论

深度领域适应允许我们将特定 DNN 在源任务上学习的知识转移到新的相关目标任务。它已成功应用于图像分类或风格转换等任务中。在某种意义上，深度领域适应使我们能够在特定的新计算机视觉任务所需的训练数据量方面更接近人类水平的表现。因此，我认为这一领域的进展对整个计算机视觉领域至关重要，我希望它最终将引领我们在视觉任务中实现有效而简单的知识重用。