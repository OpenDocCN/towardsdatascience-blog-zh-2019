<html>
<head>
<title>Using the Vector Error Correction Model to predict FANG Stock Prices</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">利用向量误差修正模型预测方股票价格</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/predicting-fang-stock-prices-ecac4ddd27c1?source=collection_archive---------10-----------------------#2019-08-26">https://towardsdatascience.com/predicting-fang-stock-prices-ecac4ddd27c1?source=collection_archive---------10-----------------------#2019-08-26</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><figure class="ir is gp gr it iu gh gi paragraph-image"><div class="ab gu cl iv"><img src="../Images/24e35f08843323286d15b7f2e39873a4.png" data-original-src="https://miro.medium.com/v2/format:webp/1*kNxl3qeyK655kQTtbyRffg.png"/></div><figcaption class="iy iz gj gh gi ja jb bd b be z dk">Source: All images in this article were generated by the author in R using dygraphs</figcaption></figure><div class=""/><div class=""><h2 id="4c7c" class="pw-subtitle-paragraph kb jd je bd b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks dk translated">基于向量误差修正模型的协整时间序列数据建模</h2></div><p id="4c6e" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">金融数据是时间序列数据最著名的资源。一个多世纪以来，股票价格的记录被一丝不苟地记录下来，提供了丰富的数据集。所谓的“方”公司，即脸书、亚马逊、网飞和谷歌/Alphabet 的股票因其令人印象深刻的回报率和这些高科技公司的“酷”因素而受到了很多关注。但是这些股票真的相互关联吗？或者这是华尔街营销一堆不相关商品的一个例子？还有一种可能是，投资者认为他们之间存在关联，这足以导致他们的股票一起波动。即使我们不知道它们为什么一起移动，如果它们一起移动，我们至少可以确定你是否可以预测一只股票和其他股票。</p><p id="15a5" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">我从雅虎财经获得了方股票的收盘价数据。脸书的首次公开募股是在 2012 年，所以这是样本期的限制因素。我们的样本期从 2012 年 5 月 18 日到 2019 年 8 月 23 日。我截掉了 2019 年的所有交易日作为测试数据集，把剩下的观测值留给训练数据集。这意味着数据集缺乏这些公司的股票在衰退中如何表现的数据。不管怎样，我继续我的分析。我测试了整合度、格兰杰因果关系和约翰森整合。基于这些结果，我继续进行向量误差修正模型(VECM)，这是一种同时估计至少有一个协整关系的多个时间序列的技术。</p><figure class="lp lq lr ls gt iu gh gi paragraph-image"><div class="ab gu cl iv"><img src="../Images/24e35f08843323286d15b7f2e39873a4.png" data-original-src="https://miro.medium.com/v2/format:webp/1*kNxl3qeyK655kQTtbyRffg.png"/></div></figure><h1 id="6adc" class="lt lu je bd lv lw lx ly lz ma mb mc md kk me kl mf kn mg ko mh kq mi kr mj mk bi translated"><strong class="ak">平稳性测试</strong></h1><p id="a32f" class="pw-post-body-paragraph kt ku je kv b kw ml kf ky kz mm ki lb lc mn le lf lg mo li lj lk mp lm ln lo im bi translated">平稳性是指时间序列的均值方差不依赖于时间。当用图表表示时，它看起来像白噪声。由于对非平稳时间序列建模所引起的几个问题，主要是自相关，你需要在建模之前检查一个时间序列是否是平稳的。如果它不是静止的，你需要通过差分得到它。</p><p id="b876" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">上图显示了 4 个绝对看起来不稳定的时间序列。但是，在继续之前，我们需要对它进行正式测试。</p><p id="b464" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">无差异股票的自相关函数(ACF)图表明，股票肯定不是平稳的。差异变量的 ACF 看起来可能是稳定的。这表明每只股票都是综合 I(1)。增强的 Dickey-Fuller (ADF)测试可以证实这一点。</p><h2 id="2a84" class="mq lu je bd lv mr ms dn lz mt mu dp md lc mv mw mf lg mx my mh lk mz na mj nb bi translated"><strong class="ak">脸书的自相关函数图</strong></h2><figure class="lp lq lr ls gt iu gh gi paragraph-image"><div class="ab gu cl iv"><img src="../Images/70ebb73924009a19a61bb4862ce249b4.png" data-original-src="https://miro.medium.com/v2/format:webp/1*E40ES-bvihNAKCx0X30P6w.png"/></div></figure><figure class="lp lq lr ls gt iu gh gi paragraph-image"><div class="ab gu cl iv"><img src="../Images/9651ae7ed05b535d655e71a565b7c847.png" data-original-src="https://miro.medium.com/v2/format:webp/1*MWs-F1u7l6W28-jCN0_Zfw.png"/></div></figure><h2 id="8832" class="mq lu je bd lv mr ms dn lz mt mu dp md lc mv mw mf lg mx my mh lk mz na mj nb bi translated"><strong class="ak">亚马逊的自相关函数图</strong></h2><figure class="lp lq lr ls gt iu gh gi paragraph-image"><div class="ab gu cl iv"><img src="../Images/52bde8a4e5cb9724bd6347fad3a9cc7e.png" data-original-src="https://miro.medium.com/v2/format:webp/1*V2eY4cnm5P755usVy0Dtcw.png"/></div></figure><figure class="lp lq lr ls gt iu gh gi paragraph-image"><div class="ab gu cl iv"><img src="../Images/71c93a9185aba53417fc5c26328ec8f0.png" data-original-src="https://miro.medium.com/v2/format:webp/1*xdQY2swPY9s9baEzuohCNQ.png"/></div></figure><h2 id="d93b" class="mq lu je bd lv mr ms dn lz mt mu dp md lc mv mw mf lg mx my mh lk mz na mj nb bi translated"><strong class="ak">网飞的自相关函数图</strong></h2><figure class="lp lq lr ls gt iu gh gi paragraph-image"><div class="ab gu cl iv"><img src="../Images/1d2db8cca41d7b669d5426c37642716b.png" data-original-src="https://miro.medium.com/v2/format:webp/1*zMjdIHP7FMmulokRFPohpw.png"/></div></figure><figure class="lp lq lr ls gt iu gh gi paragraph-image"><div class="ab gu cl iv"><img src="../Images/f4fe0d6bb787e59c854584a6dc055491.png" data-original-src="https://miro.medium.com/v2/format:webp/1*Hm6ip9B85vdhjdm89dEHFg.png"/></div></figure><h2 id="3d3a" class="mq lu je bd lv mr ms dn lz mt mu dp md lc mv mw mf lg mx my mh lk mz na mj nb bi translated"><strong class="ak">谷歌的自相关函数图</strong></h2><figure class="lp lq lr ls gt iu gh gi paragraph-image"><div class="ab gu cl iv"><img src="../Images/ac9a4f7f97aea7b4458e83a4d49f1e0d.png" data-original-src="https://miro.medium.com/v2/format:webp/1*A7ait6uowKADZaIYzMGzmQ.png"/></div></figure><figure class="lp lq lr ls gt iu gh gi paragraph-image"><div class="ab gu cl iv"><img src="../Images/2b4d6c7eff19b2ba6bbd5eefa5a6d026.png" data-original-src="https://miro.medium.com/v2/format:webp/1*o_r9uqqtf-5h9Vjo_-vkKA.png"/></div></figure><p id="38ac" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">无差异和有差异的 ADF 测试的输出强烈支持股票是整合的 I(1)的假设。在建模之前，需要对这些股票价格进行一次区分。许多用于集成时间序列模型的时间序列包会自动完成这项工作。</p><h2 id="6c98" class="mq lu je bd lv mr ms dn lz mt mu dp md lc mv mw mf lg mx my mh lk mz na mj nb bi translated"><strong class="ak">针对脸书的增强迪基-富勒测验</strong></h2><pre class="lp lq lr ls gt nc nd ne nf aw ng bi"><span id="ca8a" class="mq lu je nd b gy nh ni l nj nk">Non-<!-- -->Differenced</span><span id="9c89" class="mq lu je nd b gy nl ni l nj nk">## Augmented Dickey-Fuller Test <br/>## alternative: stationary <br/>##  <br/>## Type 1: no drift no trend <br/>##      lag   ADF p.value<br/>## [1,]   0 0.405   0.760<br/>## [2,]   1 0.441   0.771<br/>## [3,]   2 0.483   0.783<br/>## [4,]   3 0.508   0.790<br/>## [5,]   4 0.542   0.800<br/>## [6,]   5 0.608   0.819<br/>## [7,]   6 0.639   0.828<br/>## [8,]   7 0.692   0.843<br/>## Type 2: with drift no trend <br/>##      lag   ADF p.value<br/>## [1,]   0 -1.11   0.661<br/>## [2,]   1 -1.16   0.644<br/>## [3,]   2 -1.19   0.634<br/>## [4,]   3 -1.17   0.642<br/>## [5,]   4 -1.14   0.651<br/>## [6,]   5 -1.14   0.651<br/>## [7,]   6 -1.19   0.635<br/>## [8,]   7 -1.19   0.635<br/>## Type 3: with drift and trend <br/>##      lag   ADF p.value<br/>## [1,]   0 -2.42   0.399<br/>## [2,]   1 -2.25   0.469<br/>## [3,]   2 -2.08   0.541<br/>## [4,]   3 -2.01   0.572<br/>## [5,]   4 -1.88   0.628<br/>## [6,]   5 -1.60   0.745<br/>## [7,]   6 -1.47   0.803<br/>## [8,]   7 -1.28   0.881<br/>## ---- <br/>## Note: in fact, p.value = 0.01 means p.value &lt;= 0.01</span><span id="c7d5" class="mq lu je nd b gy nl ni l nj nk">Differenced</span><span id="a4ed" class="mq lu je nd b gy nl ni l nj nk">## Augmented Dickey-Fuller Test <br/>## alternative: stationary <br/>##  <br/>## Type 1: no drift no trend <br/>##      lag   ADF p.value<br/>## [1,]   0 -41.5    0.01<br/>## [2,]   1 -29.8    0.01<br/>## [3,]   2 -24.6    0.01<br/>## [4,]   3 -21.7    0.01<br/>## [5,]   4 -20.1    0.01<br/>## [6,]   5 -18.3    0.01<br/>## [7,]   6 -17.3    0.01<br/>## [8,]   7 -16.4    0.01<br/>## Type 2: with drift no trend <br/>##      lag   ADF p.value<br/>## [1,]   0 -41.5    0.01<br/>## [2,]   1 -29.8    0.01<br/>## [3,]   2 -24.6    0.01<br/>## [4,]   3 -21.7    0.01<br/>## [5,]   4 -20.2    0.01<br/>## [6,]   5 -18.4    0.01<br/>## [7,]   6 -17.4    0.01<br/>## [8,]   7 -16.5    0.01<br/>## Type 3: with drift and trend <br/>##      lag   ADF p.value<br/>## [1,]   0 -41.5    0.01<br/>## [2,]   1 -29.8    0.01<br/>## [3,]   2 -24.6    0.01<br/>## [4,]   3 -21.7    0.01<br/>## [5,]   4 -20.2    0.01<br/>## [6,]   5 -18.4    0.01<br/>## [7,]   6 -17.4    0.01<br/>## [8,]   7 -16.5    0.01<br/>## ---- <br/>## Note: in fact, p.value = 0.01 means p.value &lt;= 0.01</span></pre><h2 id="8386" class="mq lu je bd lv mr ms dn lz mt mu dp md lc mv mw mf lg mx my mh lk mz na mj nb bi translated"><strong class="ak">亚马逊增强的迪基-富勒测试</strong></h2><pre class="lp lq lr ls gt nc nd ne nf aw ng bi"><span id="5a38" class="mq lu je nd b gy nh ni l nj nk">Non-<!-- -->Differenced</span><span id="9d03" class="mq lu je nd b gy nl ni l nj nk">## Augmented Dickey-Fuller Test <br/>## alternative: stationary <br/>##  <br/>## Type 1: no drift no trend <br/>##      lag  ADF p.value<br/>## [1,]   0 1.54   0.969<br/>## [2,]   1 1.60   0.974<br/>## [3,]   2 1.60   0.974<br/>## [4,]   3 1.67   0.977<br/>## [5,]   4 1.76   0.980<br/>## [6,]   5 1.62   0.975<br/>## [7,]   6 1.63   0.976<br/>## [8,]   7 1.75   0.980<br/>## Type 2: with drift no trend <br/>##      lag      ADF p.value<br/>## [1,]   0 -0.03873   0.953<br/>## [2,]   1  0.00509   0.956<br/>## [3,]   2  0.00206   0.956<br/>## [4,]   3  0.04246   0.959<br/>## [5,]   4  0.08628   0.963<br/>## [6,]   5  0.01241   0.957<br/>## [7,]   6  0.02187   0.957<br/>## [8,]   7  0.07776   0.962<br/>## Type 3: with drift and trend <br/>##      lag   ADF p.value<br/>## [1,]   0 -1.93   0.605<br/>## [2,]   1 -1.90   0.619<br/>## [3,]   2 -1.89   0.622<br/>## [4,]   3 -1.86   0.637<br/>## [5,]   4 -1.80   0.663<br/>## [6,]   5 -1.87   0.631<br/>## [7,]   6 -1.87   0.634<br/>## [8,]   7 -1.80   0.664<br/>## ---- <br/>## Note: in fact, p.value = 0.01 means p.value &lt;= 0.01</span><span id="1cd9" class="mq lu je nd b gy nl ni l nj nk">Differenced</span><span id="27ca" class="mq lu je nd b gy nl ni l nj nk">## Augmented Dickey-Fuller Test <br/>## alternative: stationary <br/>##  <br/>## Type 1: no drift no trend <br/>##      lag   ADF p.value<br/>## [1,]   0 -41.9    0.01<br/>## [2,]   1 -29.1    0.01<br/>## [3,]   2 -24.3    0.01<br/>## [4,]   3 -21.7    0.01<br/>## [5,]   4 -17.8    0.01<br/>## [6,]   5 -16.4    0.01<br/>## [7,]   6 -15.9    0.01<br/>## [8,]   7 -16.9    0.01<br/>## Type 2: with drift no trend <br/>##      lag   ADF p.value<br/>## [1,]   0 -41.9    0.01<br/>## [2,]   1 -29.2    0.01<br/>## [3,]   2 -24.4    0.01<br/>## [4,]   3 -21.8    0.01<br/>## [5,]   4 -17.9    0.01<br/>## [6,]   5 -16.5    0.01<br/>## [7,]   6 -16.0    0.01<br/>## [8,]   7 -17.1    0.01<br/>## Type 3: with drift and trend <br/>##      lag   ADF p.value<br/>## [1,]   0 -41.9    0.01<br/>## [2,]   1 -29.2    0.01<br/>## [3,]   2 -24.5    0.01<br/>## [4,]   3 -21.8    0.01<br/>## [5,]   4 -18.0    0.01<br/>## [6,]   5 -16.5    0.01<br/>## [7,]   6 -16.1    0.01<br/>## [8,]   7 -17.1    0.01<br/>## ---- <br/>## Note: in fact, p.value = 0.01 means p.value &lt;= 0.01</span></pre><h2 id="8087" class="mq lu je bd lv mr ms dn lz mt mu dp md lc mv mw mf lg mx my mh lk mz na mj nb bi translated"><strong class="ak">为网飞增加了迪基-富勒测验</strong></h2><pre class="lp lq lr ls gt nc nd ne nf aw ng bi"><span id="2d66" class="mq lu je nd b gy nh ni l nj nk">Non-<!-- -->Differenced</span><span id="ef06" class="mq lu je nd b gy nl ni l nj nk">## Augmented Dickey-Fuller Test <br/>## alternative: stationary <br/>##  <br/>## Type 1: no drift no trend <br/>##      lag   ADF p.value<br/>## [1,]   0 0.837   0.885<br/>## [2,]   1 0.833   0.884<br/>## [3,]   2 0.799   0.874<br/>## [4,]   3 0.701   0.846<br/>## [5,]   4 0.670   0.837<br/>## [6,]   5 0.880   0.897<br/>## [7,]   6 0.890   0.900<br/>## [8,]   7 0.946   0.907<br/>## Type 2: with drift no trend <br/>##      lag    ADF p.value<br/>## [1,]   0 -0.516   0.873<br/>## [2,]   1 -0.517   0.873<br/>## [3,]   2 -0.541   0.864<br/>## [4,]   3 -0.598   0.844<br/>## [5,]   4 -0.618   0.837<br/>## [6,]   5 -0.492   0.882<br/>## [7,]   6 -0.486   0.884<br/>## [8,]   7 -0.455   0.895<br/>## Type 3: with drift and trend <br/>##      lag   ADF p.value<br/>## [1,]   0 -2.00   0.576<br/>## [2,]   1 -2.01   0.574<br/>## [3,]   2 -2.04   0.562<br/>## [4,]   3 -2.14   0.517<br/>## [5,]   4 -2.18   0.501<br/>## [6,]   5 -1.95   0.597<br/>## [7,]   6 -1.94   0.602<br/>## [8,]   7 -1.89   0.623<br/>## ---- <br/>## Note: in fact, p.value = 0.01 means p.value &lt;= 0.01</span><span id="c056" class="mq lu je nd b gy nl ni l nj nk">Differenced</span><span id="a18c" class="mq lu je nd b gy nl ni l nj nk">## Augmented Dickey-Fuller Test <br/>## alternative: stationary <br/>##  <br/>## Type 1: no drift no trend <br/>##      lag   ADF p.value<br/>## [1,]   0 -40.6    0.01<br/>## [2,]   1 -28.2    0.01<br/>## [3,]   2 -21.9    0.01<br/>## [4,]   3 -18.8    0.01<br/>## [5,]   4 -19.2    0.01<br/>## [6,]   5 -17.5    0.01<br/>## [7,]   6 -16.5    0.01<br/>## [8,]   7 -16.7    0.01<br/>## Type 2: with drift no trend <br/>##      lag   ADF p.value<br/>## [1,]   0 -40.6    0.01<br/>## [2,]   1 -28.2    0.01<br/>## [3,]   2 -21.9    0.01<br/>## [4,]   3 -18.8    0.01<br/>## [5,]   4 -19.3    0.01<br/>## [6,]   5 -17.6    0.01<br/>## [7,]   6 -16.6    0.01<br/>## [8,]   7 -16.9    0.01<br/>## Type 3: with drift and trend <br/>##      lag   ADF p.value<br/>## [1,]   0 -40.6    0.01<br/>## [2,]   1 -28.2    0.01<br/>## [3,]   2 -21.9    0.01<br/>## [4,]   3 -18.8    0.01<br/>## [5,]   4 -19.3    0.01<br/>## [6,]   5 -17.6    0.01<br/>## [7,]   6 -16.6    0.01<br/>## [8,]   7 -16.9    0.01<br/>## ---- <br/>## Note: in fact, p.value = 0.01 means p.value &lt;= 0.01</span></pre><h2 id="6d90" class="mq lu je bd lv mr ms dn lz mt mu dp md lc mv mw mf lg mx my mh lk mz na mj nb bi translated"><strong class="ak">谷歌的增强 Dickey-Fuller 测试</strong></h2><pre class="lp lq lr ls gt nc nd ne nf aw ng bi"><span id="6ac5" class="mq lu je nd b gy nh ni l nj nk">Non-Differenced</span><span id="e739" class="mq lu je nd b gy nl ni l nj nk">## Augmented Dickey-Fuller Test <br/>## alternative: stationary <br/>##  <br/>## Type 1: no drift no trend <br/>##      lag  ADF p.value<br/>## [1,]   0 1.21   0.940<br/>## [2,]   1 1.15   0.933<br/>## [3,]   2 1.23   0.943<br/>## [4,]   3 1.16   0.935<br/>## [5,]   4 1.20   0.939<br/>## [6,]   5 1.28   0.950<br/>## [7,]   6 1.36   0.956<br/>## [8,]   7 1.34   0.954<br/>## Type 2: with drift no trend <br/>##      lag   ADF p.value<br/>## [1,]   0 -1.07   0.677<br/>## [2,]   1 -1.07   0.679<br/>## [3,]   2 -1.06   0.680<br/>## [4,]   3 -1.07   0.678<br/>## [5,]   4 -1.07   0.676<br/>## [6,]   5 -1.07   0.677<br/>## [7,]   6 -1.04   0.687<br/>## [8,]   7 -1.06   0.680<br/>## Type 3: with drift and trend <br/>##      lag   ADF p.value<br/>## [1,]   0 -3.52  0.0404<br/>## [2,]   1 -3.64  0.0275<br/>## [3,]   2 -3.49  0.0430<br/>## [4,]   3 -3.63  0.0292<br/>## [5,]   4 -3.56  0.0364<br/>## [6,]   5 -3.36  0.0598<br/>## [7,]   6 -3.22  0.0851<br/>## [8,]   7 -3.26  0.0768<br/>## ---- <br/>## Note: in fact, p.value = 0.01 means p.value &lt;= 0.01</span><span id="b33c" class="mq lu je nd b gy nl ni l nj nk">Differenced</span><span id="4da6" class="mq lu je nd b gy nl ni l nj nk">## Augmented Dickey-Fuller Test <br/>## alternative: stationary <br/>##  <br/>## Type 1: no drift no trend <br/>##      lag   ADF p.value<br/>## [1,]   0 -39.6    0.01<br/>## [2,]   1 -29.5    0.01<br/>## [3,]   2 -23.1    0.01<br/>## [4,]   3 -20.4    0.01<br/>## [5,]   4 -19.1    0.01<br/>## [6,]   5 -18.0    0.01<br/>## [7,]   6 -16.3    0.01<br/>## [8,]   7 -16.8    0.01<br/>## Type 2: with drift no trend <br/>##      lag   ADF p.value<br/>## [1,]   0 -39.6    0.01<br/>## [2,]   1 -29.6    0.01<br/>## [3,]   2 -23.2    0.01<br/>## [4,]   3 -20.5    0.01<br/>## [5,]   4 -19.2    0.01<br/>## [6,]   5 -18.1    0.01<br/>## [7,]   6 -16.4    0.01<br/>## [8,]   7 -16.9    0.01<br/>## Type 3: with drift and trend <br/>##      lag   ADF p.value<br/>## [1,]   0 -39.6    0.01<br/>## [2,]   1 -29.6    0.01<br/>## [3,]   2 -23.2    0.01<br/>## [4,]   3 -20.5    0.01<br/>## [5,]   4 -19.2    0.01<br/>## [6,]   5 -18.1    0.01<br/>## [7,]   6 -16.4    0.01<br/>## [8,]   7 -16.9    0.01<br/>## ---- <br/>## Note: in fact, p.value = 0.01 means p.value &lt;= 0.01</span></pre><h1 id="3000" class="lt lu je bd lv lw lx ly lz ma mb mc md kk me kl mf kn mg ko mh kq mi kr mj mk bi translated"><strong class="ak">格兰杰因果关系</strong></h1><p id="fabf" class="pw-post-body-paragraph kt ku je kv b kw ml kf ky kz mm ki lb lc mn le lf lg mo li lj lk mp lm ln lo im bi translated">众所周知，在观察数据中建立因果关系非常困难。格兰杰因果关系是一个较低的酒吧。它只是说，如果 X 的以前值可以预测 y 的未来值，那么 X 格兰杰原因是 y。它是通过估计 X 对 y 的滞后值的回归并执行 f 检验来执行的。如果 p 值足够小，你拒绝零假设，即 X 的所有滞后值的系数都是 0。简单地说，小 p 值表示滞后的 x 对未来的 y 有预测能力，并有相应的置信度。</p><p id="1942" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">下面的输出简单地说明了 FANG 的每只股票都比其他股票具有预测能力。这意味着同步建模是一个好方法。</p><pre class="lp lq lr ls gt nc nd ne nf aw ng bi"><span id="9eb7" class="mq lu je nd b gy nh ni l nj nk">## Granger causality test<br/>## <br/>## Model 1: j ~ Lags(j, 1:30) + Lags(i, 1:30)<br/>## Model 2: j ~ Lags(j, 1:30)<br/>##   Res.Df  Df      F    Pr(&gt;F)    <br/>## 1   1574                         <br/>## 2   1604 -30 2.9968 1.226e-07 ***<br/>## ---<br/>## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1<br/>## Granger causality test<br/>## <br/>## Model 1: j ~ Lags(j, 1:30) + Lags(i, 1:30)<br/>## Model 2: j ~ Lags(j, 1:30)<br/>##   Res.Df  Df      F    Pr(&gt;F)    <br/>## 1   1574                         <br/>## 2   1604 -30 2.4849 1.635e-05 ***<br/>## ---<br/>## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1<br/>## Granger causality test<br/>## <br/>## Model 1: j ~ Lags(j, 1:30) + Lags(i, 1:30)<br/>## Model 2: j ~ Lags(j, 1:30)<br/>##   Res.Df  Df      F   Pr(&gt;F)    <br/>## 1   1574                        <br/>## 2   1604 -30 2.5479 9.15e-06 ***<br/>## ---<br/>## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1<br/>## Granger causality test<br/>## <br/>## Model 1: j ~ Lags(j, 1:30) + Lags(i, 1:30)<br/>## Model 2: j ~ Lags(j, 1:30)<br/>##   Res.Df  Df      F   Pr(&gt;F)    <br/>## 1   1574                        <br/>## 2   1604 -30 2.5026 1.39e-05 ***<br/>## ---<br/>## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1<br/>## Granger causality test<br/>## <br/>## Model 1: j ~ Lags(j, 1:30) + Lags(i, 1:30)<br/>## Model 2: j ~ Lags(j, 1:30)<br/>##   Res.Df  Df     F    Pr(&gt;F)    <br/>## 1   1574                        <br/>## 2   1604 -30 3.838 2.082e-11 ***<br/>## ---<br/>## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1<br/>## Granger causality test<br/>## <br/>## Model 1: j ~ Lags(j, 1:30) + Lags(i, 1:30)<br/>## Model 2: j ~ Lags(j, 1:30)<br/>##   Res.Df  Df      F    Pr(&gt;F)    <br/>## 1   1574                         <br/>## 2   1604 -30 2.0986 0.0004837 ***<br/>## ---<br/>## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1<br/>## Granger causality test<br/>## <br/>## Model 1: j ~ Lags(j, 1:30) + Lags(i, 1:30)<br/>## Model 2: j ~ Lags(j, 1:30)<br/>##   Res.Df  Df      F   Pr(&gt;F)    <br/>## 1   1574                        <br/>## 2   1604 -30 2.0299 0.000852 ***<br/>## ---<br/>## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1<br/>## Granger causality test<br/>## <br/>## Model 1: j ~ Lags(j, 1:30) + Lags(i, 1:30)<br/>## Model 2: j ~ Lags(j, 1:30)<br/>##   Res.Df  Df      F    Pr(&gt;F)    <br/>## 1   1574                         <br/>## 2   1604 -30 3.3817 2.497e-09 ***<br/>## ---<br/>## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1<br/>## Granger causality test<br/>## <br/>## Model 1: j ~ Lags(j, 1:30) + Lags(i, 1:30)<br/>## Model 2: j ~ Lags(j, 1:30)<br/>##   Res.Df  Df      F    Pr(&gt;F)    <br/>## 1   1574                         <br/>## 2   1604 -30 3.0723 5.784e-08 ***<br/>## ---<br/>## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1<br/>## Granger causality test<br/>## <br/>## Model 1: j ~ Lags(j, 1:30) + Lags(i, 1:30)<br/>## Model 2: j ~ Lags(j, 1:30)<br/>##   Res.Df  Df      F   Pr(&gt;F)   <br/>## 1   1574                       <br/>## 2   1604 -30 1.7205 0.009195 **<br/>## ---<br/>## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1<br/>## Granger causality test<br/>## <br/>## Model 1: j ~ Lags(j, 1:30) + Lags(i, 1:30)<br/>## Model 2: j ~ Lags(j, 1:30)<br/>##   Res.Df  Df     F   Pr(&gt;F)   <br/>## 1   1574                      <br/>## 2   1604 -30 1.728 0.008712 **<br/>## ---<br/>## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1<br/>## Granger causality test<br/>## <br/>## Model 1: j ~ Lags(j, 1:30) + Lags(i, 1:30)<br/>## Model 2: j ~ Lags(j, 1:30)<br/>##   Res.Df  Df      F    Pr(&gt;F)    <br/>## 1   1574                         <br/>## 2   1604 -30 3.3607 3.101e-09 ***<br/>## ---<br/>## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1</span></pre><h1 id="fab2" class="lt lu je bd lv lw lx ly lz ma mb mc md kk me kl mf kn mg ko mh kq mi kr mj mk bi translated"><strong class="ak">协整检验</strong></h1><p id="aacd" class="pw-post-body-paragraph kt ku je kv b kw ml kf ky kz mm ki lb lc mn le lf lg mo li lj lk mp lm ln lo im bi translated">协整是我反复提到的一个词。这仅仅意味着我们的股票中至少有两只之间存在长期关系。协整检验被称为 Johansen 检验，以开发它的统计学家/计量经济学家的名字命名。它可以用两种方式来表述，迹检验和最大特征值检验，它们有不同的假设。细节是相当技术性的，所以 TL；它的 dr 版本是，如果长期关系矩阵的秩 r 为 0 或等于被测试的时间序列的数量，则不存在协整，不同的建模技术是合适的。如果 r 大于 0 且小于时间序列数，则存在 r 个协整关系。</p><p id="cd56" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">从下面的输出中，我们可以非常确定存在大于 0 的协整关系，但是我们不能在任何合理的统计显著性水平上确定存在大于 1 的协整关系。因此，我们在建模时将假设 FANG 股票之间存在一种协整关系。</p><pre class="lp lq lr ls gt nc nd ne nf aw ng bi"><span id="e225" class="mq lu je nd b gy nh ni l nj nk">###################### <br/># Johansen-Procedure # <br/>######################</span><span id="bced" class="mq lu je nd b gy nl ni l nj nk">Test type: trace statistic , with linear trend in cointegration</span><span id="67c3" class="mq lu je nd b gy nl ni l nj nk">Eigenvalues (lambda):<br/>[1] 2.054935e-02 1.133947e-02 6.555429e-03 4.658323e-03 -2.362375e-18</span><span id="1f95" class="mq lu je nd b gy nl ni l nj nk">Values of teststatistic and critical values of test:</span><span id="437b" class="mq lu je nd b gy nl ni l nj nk">test 10pct 5pct 1pct<br/>r &lt;= 3 | 7.63 10.49 12.25 16.26<br/>r &lt;= 2 | 18.39 22.76 25.32 30.45<br/>r &lt;= 1 | 37.03 39.06 42.44 48.45<br/>r = 0 | 70.98 59.14 62.99 70.05</span><span id="18d5" class="mq lu je nd b gy nl ni l nj nk">Eigenvectors, normalised to first column:<br/>(These are the cointegration relations)</span><span id="9b62" class="mq lu je nd b gy nl ni l nj nk">Close.fb.l30 Close.amzn.l30 Close.nflx.l30 Close.googl.l30 trend.l30<br/>Close.fb.l30 1.000000000 1.0000000 1.0000000 1.000000000 1.0000000<br/>Close.amzn.l30 -0.004276658 1.0364900 0.2719707 0.102530094 -0.1327168<br/>Close.nflx.l30 0.159547714 -1.8623141 -1.2702538 -0.746632744 0.5949550<br/>Close.googl.l30 -0.143075556 -1.9821424 0.4921765 -0.150661845 0.2315739<br/>trend.l30 -0.054567826 0.2916345 -0.3575875 0.005284555 -0.3248181</span><span id="0912" class="mq lu je nd b gy nl ni l nj nk">Weights W:<br/>(This is the loading matrix)</span><span id="1ccd" class="mq lu je nd b gy nl ni l nj nk">Close.fb.l30 Close.amzn.l30 Close.nflx.l30 Close.googl.l30 trend.l30<br/>Close.fb.d -0.00219271 -0.0006776299 -0.003233474 0.00356431 1.732653e-17<br/>Close.amzn.d 0.18630132 -0.0084137379 -0.008556667 0.01693689 -8.853648e-16<br/>Close.nflx.d 0.02105269 -0.0006557141 0.001122418 0.01106052 -1.271123e-16<br/>Close.googl.d 0.10670446 0.0031632593 -0.012012380 0.01474776 -9.437844e-16</span></pre><h1 id="adbe" class="lt lu je bd lv lw lx ly lz ma mb mc md kk me kl mf kn mg ko mh kq mi kr mj mk bi translated"><strong class="ak">选择模型的滞后数量</strong></h1><p id="8df9" class="pw-post-body-paragraph kt ku je kv b kw ml kf ky kz mm ki lb lc mn le lf lg mo li lj lk mp lm ln lo im bi translated">为了选择包含在最终模型中的滞后数量，我选取了我的训练数据的一个小子集；从 2018 年 5 月 9 日开始到年底。这个日期在小型测试数据集中留下了 163 个观察值，这与测试数据集中的观察值数量相等。然后，我用 1 到 30 个小训练数据估计模型，然后用该模型估计小测试数据集。我计算了每只股票的平均绝对百分比误差(MAPE ),并将它们相加。然后我选择了使每只股票的 MAPE 总和最小的滞后数。最小化该调谐数据集中的总 MAPE 的滞后数量是 5。</p><h1 id="0d13" class="lt lu je bd lv lw lx ly lz ma mb mc md kk me kl mf kn mg ko mh kq mi kr mj mk bi translated"><strong class="ak">模型有多精确？</strong></h1><p id="5f69" class="pw-post-body-paragraph kt ku je kv b kw ml kf ky kz mm ki lb lc mn le lf lg mo li lj lk mp lm ln lo im bi translated">评估模型准确性时，进行基线比较会有所帮助。对于分类，它可能是总是预测模式的误分类率。对于横截面回归，它可以是因变量的平均值。对于时间序列，我希望我的预测是前一段时间的值。这意味着我的基准准确度等级是说明天的股价就是今天的股价的准确度。</p><p id="248b" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">这样，脸书的基准 MAPE 为 1.36%，亚马逊为 1.20%，网飞为 1.70%，谷歌为 1.15%。对于一种不依赖复杂统计模型的预测方法来说，这还不算太糟糕。VECM 能胜过这个吗？</p><pre class="lp lq lr ls gt nc nd ne nf aw ng bi"><span id="b83f" class="mq lu je nd b gy nh ni l nj nk">## [1] "Close.fb"<br/>## [1] 1.360928<br/>## [1] "Close.amzn"<br/>## [1] 1.203783<br/>## [1] "Close.nflx"<br/>## [1] 1.697295<br/>## [1] "Close.googl"<br/>## [1] 1.150686</span></pre><p id="9793" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">现在我们可以估计 VECM。它将具有下面的简化形式，其中α的列向量是对长期调整的速度，β的行向量包含长期关系系数。</p><figure class="lp lq lr ls gt iu gh gi paragraph-image"><div role="button" tabindex="0" class="nn no di np bf nq"><div class="gh gi nm"><img src="../Images/600067e2495d9cab58223cc6fe5e5561.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Xh6_vFQdOY4l8w2k6oxgyg.png"/></div></div><figcaption class="iy iz gj gh gi ja jb bd b be z dk">Formulation of the VECM with L lags</figcaption></figure><p id="34fc" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">是的。VECM 得出脸书的 MAPE 为 0.30%，亚马逊为 0.28%，网飞为 0.40%，谷歌为 0.29%，这还不算太差。这些 MAPE 大约是基线错误率的四分之一。</p><pre class="lp lq lr ls gt nc nd ne nf aw ng bi"><span id="1cf2" class="mq lu je nd b gy nh ni l nj nk">## [1] "Close.fb"<br/>## [1] 0.2972355<br/>## [1] "Close.amzn"<br/>## [1] 0.277129<br/>## [1] "Close.nflx"<br/>## [1] 0.3978918<br/>## [1] "Close.googl"<br/>## [1] 0.2943474</span></pre><p id="0e4a" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">绘制每只股票的预测收盘价和实际收盘价表明，预测股价非常接近实际股价。由于股票价格比例的差异，每只股票都有自己的图表，以便更好地查看拟合值和预测值。</p><figure class="lp lq lr ls gt iu gh gi paragraph-image"><div class="ab gu cl iv"><img src="../Images/521f3fd1110ec91e483e928baebf4f4d.png" data-original-src="https://miro.medium.com/v2/format:webp/1*bmbWC1qjcB_7mH0SwTMhLA.png"/></div></figure><figure class="lp lq lr ls gt iu gh gi paragraph-image"><div class="ab gu cl iv"><img src="../Images/a645cc2793ca0840bed74d8af8ea9f3a.png" data-original-src="https://miro.medium.com/v2/format:webp/1*zM2nxPi1QxKZxytvjVA6cw.png"/></div></figure><figure class="lp lq lr ls gt iu gh gi paragraph-image"><div class="ab gu cl iv"><img src="../Images/7e50c683dbd92c831fc791b0e62b8a54.png" data-original-src="https://miro.medium.com/v2/format:webp/1*WHdkB_qlR5uFE3w-8WyEHA.png"/></div></figure><figure class="lp lq lr ls gt iu gh gi paragraph-image"><div class="ab gu cl iv"><img src="../Images/66f86a74e91b0b87770fb1b4f1b258a6.png" data-original-src="https://miro.medium.com/v2/format:webp/1*du_RN7Sea8HqEzrhKEGnjQ.png"/></div></figure><h1 id="51bf" class="lt lu je bd lv lw lx ly lz ma mb mc md kk me kl mf kn mg ko mh kq mi kr mj mk bi translated"><strong class="ak">关闭思路</strong></h1><p id="eafa" class="pw-post-body-paragraph kt ku je kv b kw ml kf ky kz mm ki lb lc mn le lf lg mo li lj lk mp lm ln lo im bi translated">所以这个模型表现不错。有什么意义？该模型预测收盘股价。因此，如果交易价格远低于预测的收盘价，远低于预测的收盘价是置信区间和你的风险承受能力的函数，在收盘前买入并卖出股票是有意义的；前提是没有充足的理由让股价持续下跌。如果价格远高于预测的收盘价格，卖出它是有意义的(<strong class="kv jf">)我不是在提供财务建议。只是陈述如果我愿意，我会如何使用这个模型。</strong>)。只有当你是日内交易者时，这些行为才有意义，但是这个模型的洞察力是有限的，因为它只预测前一天。</p><p id="4cc4" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">模型的准确性告诉我们模型是适合方股票的。从这里开始，重新构建模型来预测更远的时间，以决定一个期权是否被正确定价是一个合乎逻辑的地方。记住预测越来越远的未来是困难的，这一点很重要。随着人们对未来的预测越来越远，误差带变得越来越宽。在实施交易策略之前，严格的回溯测试和过去的表现不能保证未来的表现是关键。</p><p id="d8cc" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">我希望你对协整时间序列和 VEC 建模有所了解。还有很多工作没有在这里讨论，比如解释长期关系矩阵和脉冲响应函数。我希望这个博客能激发人们对此类数据的兴趣。</p><p id="4377" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">我的代码和数据可以在<a class="ae nr" href="https://github.com/jkclem/FANG-stock-prediction" rel="noopener ugc nofollow" target="_blank">https://github.com/jkclem/FANG-stock-prediction</a>获得。</p></div></div>    
</body>
</html>