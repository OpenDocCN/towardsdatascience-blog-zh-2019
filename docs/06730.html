<html>
<head>
<title>How to get a fuller picture of a model’s accuracy</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">如何更全面地了解模型的准确性</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/how-to-get-a-fuller-picture-of-a-models-accuracy-e3e6f45becb2?source=collection_archive---------21-----------------------#2019-09-25">https://towardsdatascience.com/how-to-get-a-fuller-picture-of-a-models-accuracy-e3e6f45becb2?source=collection_archive---------21-----------------------#2019-09-25</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="1ef0" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">交叉验证的案例以及如何实现一个版本(k-fold)</h2></div><p id="0c40" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">使用单个训练测试分割给你一个机器学习模型或算法的性能的单个快照。这就像根据一场比赛来评价一支足球队(美国队或其他球队)。如果你真的想知道一个团队总体表现如何，你需要的不仅仅是这张快照。同样，我们不应该在一次随机分割中评估我们的算法。幸运的是，有更好的方法。我给你带来 k 倍交叉验证。</p><h1 id="8674" class="le lf it bd lg lh li lj lk ll lm ln lo jz lp ka lq kc lr kd ls kf lt kg lu lv bi translated">当火车测试分裂使你误入歧途</h1><p id="28ac" class="pw-post-body-paragraph ki kj it kk b kl lw ju kn ko lx jx kq kr ly kt ku kv lz kx ky kz ma lb lc ld im bi translated">今天，我使用的是 Gareth James 的经典广告数据集，其中有 200 条电视、广播和报纸广告支出的记录以及相应的销售数据。</p><figure class="mc md me mf gt mg gh gi paragraph-image"><div class="gh gi mb"><img src="../Images/6ccefd5311c92b934a3b17fe74b500e6.png" data-original-src="https://miro.medium.com/v2/resize:fit:800/format:webp/1*fqnFWT5KYJPpM_fvCt2_WQ.png"/></div></figure><p id="26b2" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我创建了一个线性回归模型来预测基于 TV*Radio 的销售，并在测试数据集上进行验证:</p><pre class="mc md me mf gt mj mk ml mm aw mn bi"><span id="0bc4" class="mo lf it mk b gy mp mq l mr ms">from sklearn.linear_model import LinearRegression<br/>from sklearn.model_selection import train_test_split<br/>import pandas as pd<br/>import numpy as np</span><span id="2405" class="mo lf it mk b gy mt mq l mr ms">df = pd.read_csv(‘data/advertising.csv’) # import data<br/>df[‘TVxradio’] = df[‘TV’] * df[‘radio’] # create feature</span><span id="1d51" class="mo lf it mk b gy mt mq l mr ms">x = np.array(df[‘TVxradio’]).reshape(-1, 1)<br/>y = np.array(df[‘sales’])</span><span id="d496" class="mo lf it mk b gy mt mq l mr ms">x_train, x_test, y_train, y_test = train_test_split(<br/>     x1, y1, test_size=0.3, random_state=54546)</span><span id="8d44" class="mo lf it mk b gy mt mq l mr ms">model = LinearRegression()<br/>model.fit(x_train, y_train)<br/>print(f’model accuracy on test set: {model.score(x_test, y_test)}’)</span></pre><p id="d41d" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">结果:</p><pre class="mc md me mf gt mj mk ml mm aw mn bi"><span id="ec35" class="mo lf it mk b gy mp mq l mr ms">model accuracy on test set: 0.9721866564067523</span></pre><p id="ac2b" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">厉害！！模特太棒了！</p><figure class="mc md me mf gt mg gh gi paragraph-image"><div class="gh gi mu"><img src="../Images/e129489d2cfb77ce473898c38edd5456.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*0AB3yzAAxCzoi6AkCMcxqw.jpeg"/></div><figcaption class="mv mw gj gh gi mx my bd b be z dk"><a class="ae mz" href="https://www.flickr.com/photos/kjarrett/7818669582" rel="noopener ugc nofollow" target="_blank">Kevin Jarrett</a> CC 2.0</figcaption></figure><p id="5584" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">或者是？</p><figure class="mc md me mf gt mg gh gi paragraph-image"><div class="gh gi na"><img src="../Images/166d1c965c35b182588c4a9e88f0246e.png" data-original-src="https://miro.medium.com/v2/resize:fit:850/format:webp/1*dFPoc9imAwfjCuSh-a3aOA.jpeg"/></div><figcaption class="mv mw gj gh gi mx my bd b be z dk">Image by <a class="ae mz" href="https://pixabay.com/users/htuuli-2596972/?utm_source=link-attribution&amp;utm_medium=referral&amp;utm_campaign=image&amp;utm_content=2878336" rel="noopener ugc nofollow" target="_blank">htuuli</a> from <a class="ae mz" href="https://pixabay.com/?utm_source=link-attribution&amp;utm_medium=referral&amp;utm_campaign=image&amp;utm_content=2878336" rel="noopener ugc nofollow" target="_blank">Pixabay</a></figcaption></figure><p id="99ba" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">这个分数不能向你展示模型的真正预测能力。在这种情况下，你是在根据一场比赛来评判足球队。你不知道这是不是一种‘幸运’<code class="fe nb nc nd mk b">train_test_split</code>。在这种情况下，是的。我作弊了。选择新的<code class="fe nb nc nd mk b">random_state</code> (71464)使我们的模型精度下降到 0.80。</p><p id="2ca2" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">有一种更好的方法来优化模型，而不是随心所欲。一种提供对分数分布的洞察并降低过度适应测试数据集的风险的方法。</p><h1 id="a698" class="le lf it bd lg lh li lj lk ll lm ln lo jz lp ka lq kc lr kd ls kf lt kg lu lv bi translated">为什么/何时使用 k-fold 交叉验证</h1><ul class=""><li id="9c7b" class="ne nf it kk b kl lw ko lx kr ng kv nh kz ni ld nj nk nl nm bi translated"><strong class="kk iu">在较小的数据集上。</strong>如果你有一个庞大的数据集，你可以将它分成三个有代表性的部分——训练、测试和最终评估。不幸的是，你并不总是有这种奢侈；您的数据集可能不够大，无法分成三个有代表性的部分。这就是交叉验证的用武之地。K-fold 交叉验证可以防止过度拟合测试数据，而不会进一步减小训练数据集的大小。</li><li id="6ef2" class="ne nf it kk b kl nn ko no kr np kv nq kz nr ld nj nk nl nm bi translated"><strong class="kk iu">让你的模型得到一个不那么偏颇(理解:乐观)的评价。</strong> K-fold 交叉验证报告模型在来自训练集的几个(K)样本上的性能。这使您能够洞察模型中可能看到的精度分布。</li><li id="9088" class="ne nf it kk b kl nn ko no kr np kv nq kz nr ld nj nk nl nm bi translated"><strong class="kk iu">当你有足够的计算资源/时间。K-fold 交叉验证比将数据分割成三部分的计算量更大。它重新拟合模型，并在每次迭代中测试 k 次，而不是一次。因此，对于运行时/计算成本不显著的小数据集，它更有价值，并且额外的分区会显著减少训练数据集。</strong></li></ul><h1 id="6c71" class="le lf it bd lg lh li lj lk ll lm ln lo jz lp ka lq kc lr kd ls kf lt kg lu lv bi translated"><strong class="ak">了解 k 倍交叉验证</strong></h1><figure class="mc md me mf gt mg gh gi paragraph-image"><div role="button" tabindex="0" class="nt nu di nv bf nw"><div class="gh gi ns"><img src="../Images/b44e584804bbcd8e2eb7b4dc73cbc41a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*KHXxfTtUnRU2Xru2"/></div></div><figcaption class="mv mw gj gh gi mx my bd b be z dk">Image from <a class="ae mz" href="https://scikit-learn.org/stable/modules/cross_validation.html" rel="noopener ugc nofollow" target="_blank">Scikit-learn Developers</a></figcaption></figure><p id="6cdb" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">当您在交叉验证分割策略(cv)设置为整数的情况下运行<code class="fe nb nc nd mk b">cross_val_score</code>时，它会执行以下操作:</p><ol class=""><li id="8c6a" class="ne nf it kk b kl km ko kp kr nx kv ny kz nz ld oa nk nl nm bi translated">将数据集随机分割成 k 个“折叠”(又名。较小的数据集)</li><li id="6481" class="ne nf it kk b kl nn ko no kr np kv nq kz nr ld oa nk nl nm bi translated">留出一个切片，并在其他切片上训练模型。</li><li id="95a5" class="ne nf it kk b kl nn ko no kr np kv nq kz nr ld oa nk nl nm bi translated">在保存的集合上验证模型并记录分数。</li><li id="58c7" class="ne nf it kk b kl nn ko no kr np kv nq kz nr ld oa nk nl nm bi translated">重复第二步和第三步，每次折叠一次。</li></ol><p id="bb9d" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">然后，您可以使用这些分数来获得模型准确性的平均值、标准偏差和 95%置信区间的估计值。</p><p id="9769" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="kk iu">如何使用 k 倍交叉验证</strong></p><p id="b05c" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">scikit-learn 的<code class="fe nb nc nd mk b">cross_val_score</code>的基本用途包括以下参数:</p><ul class=""><li id="67f2" class="ne nf it kk b kl km ko kp kr nx kv ny kz nz ld nj nk nl nm bi translated">估计值-用于拟合数据的模型</li><li id="2c8d" class="ne nf it kk b kl nn ko no kr np kv nq kz nr ld nj nk nl nm bi translated">x-要拟合的数据</li><li id="ad01" class="ne nf it kk b kl nn ko no kr np kv nq kz nr ld nj nk nl nm bi translated">y —目标变量(如果使用监督学习)[可选]</li><li id="fde1" class="ne nf it kk b kl nn ko no kr np kv nq kz nr ld nj nk nl nm bi translated">cv-您想要的折叠次数[默认为三次]</li></ul><p id="f77f" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">注意:没有一个“正确”的折叠次数。您需要考虑每个文件夹中数据集的大小。理想情况下，折叠的大小应该相等，这在非常小的数据集中尤其重要，因此可以考虑选择一个 k 值来均匀划分数据集。斯坦福大学的 Hastie 和 Tibshirani 指出 k=5 或 k=10 是典型的 k 值。</p><p id="f9cd" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">还要注意:<code class="fe nb nc nd mk b">cross_val_score</code>不会自动洗牌。如果你想多次运行它(类似于引导)，确保包含一个 shuffle。</p><p id="3e8e" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">一如既往，查看<a class="ae mz" href="https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_score.html#sklearn.model_selection.cross_val_score" rel="noopener ugc nofollow" target="_blank">文档</a>和<a class="ae mz" href="https://scikit-learn.org/stable/modules/cross_validation.html#cross-validation" rel="noopener ugc nofollow" target="_blank">用户指南</a>了解更多信息。</p></div><div class="ab cl ob oc hx od" role="separator"><span class="oe bw bk of og oh"/><span class="oe bw bk of og oh"/><span class="oe bw bk of og"/></div><div class="im in io ip iq"><h1 id="401b" class="le lf it bd lg lh oi lj lk ll oj ln lo jz ok ka lq kc ol kd ls kf om kg lu lv bi translated"><strong class="ak">例 1:单一回归</strong></h1><p id="d7b1" class="pw-post-body-paragraph ki kj it kk b kl lw ju kn ko lx jx kq kr ly kt ku kv lz kx ky kz ma lb lc ld im bi translated">回到广告数据集，同样的单因素线性回归模型(电视花费*电台花费)，只需要几个变化就可以实现 k 倍<code class="fe nb nc nd mk b">cross_val_score</code>。</p><pre class="mc md me mf gt mj mk ml mm aw mn bi"><span id="5238" class="mo lf it mk b gy mp mq l mr ms"># import necessary python modules and classes<br/><strong class="mk iu">from sklearn.model_selection import cross_val_score</strong><br/>from sklearn.linear_model import LinearRegression # your model here<br/>from sklearn.model_selection import train_test_split<br/>import pandas as pd<br/>import numpy as np</span><span id="a3d9" class="mo lf it mk b gy mt mq l mr ms"># import data<br/>df = pd.read_csv('data/advertising.csv')</span><span id="d49e" class="mo lf it mk b gy mt mq l mr ms"># engineer feature of interest<br/>df['TVxradio'] = df['TV'] * df['radio']</span><span id="a866" class="mo lf it mk b gy mt mq l mr ms"># slice data<br/>x = np.array(df['TVxradio']).reshape(-1, 1)<br/>y = np.array(df['sales'])</span><span id="c3ad" class="mo lf it mk b gy mt mq l mr ms"># train-test split<br/>x_train, x_test, y_train, y_test = train_test_split(<br/>     x, y, random_state=0)</span><span id="18c5" class="mo lf it mk b gy mt mq l mr ms"># select model<br/>model = LinearRegression()</span><span id="65b1" class="mo lf it mk b gy mt mq l mr ms"><strong class="mk iu"># k-fold cross validation<br/>scores = cross_val_score(model, x_train, y_train, cv=10)<br/>print(scores)<br/>print(<br/>     f"95% CI Accuracy: "<br/>     f"{round(scores.mean(), 2)} "<br/>     f"(+/- {round(scores.std() * 2, 2)})"<br/>)</strong></span><span id="c694" class="mo lf it mk b gy mt mq l mr ms"># test model on test set<br/>model.fit(x_train, y_train)<br/>print(f'model accuracy on test set: {model.score(x_test, y_test)}')</span></pre><p id="5e6c" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">结果:</p><pre class="mc md me mf gt mj mk ml mm aw mn bi"><span id="e042" class="mo lf it mk b gy mp mq l mr ms">[0.87595678, 0.97943611, 0.8740311, 0.93150634, 0.94679878, 0.89219105, 0.91211392, 0.97882041, 0.8539725, 0.95655506]</span><span id="4c57" class="mo lf it mk b gy mt mq l mr ms">95% CI Accuracy: 0.92 (+/- 0.09)</span><span id="9ac1" class="mo lf it mk b gy mt mq l mr ms">model accuracy on test set: 0.9041657637532045</span></pre><p id="4a6f" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在这里，你得到了比单一快照更多的东西:重复试验的精确度的平均值和标准偏差。在这种情况下，我打印了大约 95%的置信区间。这才是值得兴奋的。</p><figure class="mc md me mf gt mg gh gi paragraph-image"><div role="button" tabindex="0" class="nt nu di nv bf nw"><div class="gh gi on"><img src="../Images/538c5521317bfa289afeb19143e0f614.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*kkIlnrVrAUnRG6EXXh7tbg.png"/></div></div><figcaption class="mv mw gj gh gi mx my bd b be z dk"><a class="ae mz" href="https://www.flickr.com/photos/edanley/3246241416" rel="noopener ugc nofollow" target="_blank">Eric Danley</a> via Flickr CC 2.0</figcaption></figure><h1 id="699e" class="le lf it bd lg lh li lj lk ll lm ln lo jz lp ka lq kc lr kd ls kf lt kg lu lv bi translated"><strong class="ak">示例 2:使用预处理</strong></h1><p id="16c0" class="pw-post-body-paragraph ki kj it kk b kl lw ju kn ko lx jx kq kr ly kt ku kv lz kx ky kz ma lb lc ld im bi translated">当使用预处理时，交叉验证需要多一点额外的代码，但是仍然是完全可行的，并且为了更好地理解模型的准确性是值得的。</p><p id="dc9d" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">通常，当使用预处理时，您不应该包含您的验证数据，这样这些数据在测试阶段对模型来说是“新的”,而不是通过预处理泄露进来。为了在使用 k-fold 交叉验证时避免这种情况，您需要使用一个<code class="fe nb nc nd mk b">Pipeline</code>将这些数据转换传递给第一个参数中的<code class="fe nb nc nd mk b">cross_val_score</code>。尽管这增加了代码的复杂性，但它相当简单，并且对于生成模型性能的有效评估是必不可少的。</p><p id="a5ad" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在这个例子中，我使用了同样的广告数据集和多元回归。这些特征包括电视消费、广播消费、报纸消费和电视消费*广播消费，并且该模型预测产品销售。随着管道进入<code class="fe nb nc nd mk b">cross_val_score</code>，该功能将首先将数据分成训练和验证，然后按照<code class="fe nb nc nd mk b">make_pipeline</code>指示的顺序使用转换器转换训练数据集，在这种情况下，在拟合到<code class="fe nb nc nd mk b">LinearRegression()</code>之前使用<code class="fe nb nc nd mk b">StandardScaler()</code>。</p><pre class="mc md me mf gt mj mk ml mm aw mn bi"><span id="43f9" class="mo lf it mk b gy mp mq l mr ms"># import necessary python modules and classes<br/>from sklearn.model_selection import cross_val_score<br/>from sklearn.linear_model import LinearRegression # your model here<br/>from sklearn.model_selection import train_test_split<br/>from sklearn.pipeline import make_pipeline<br/>from sklearn import preprocessing<br/>import pandas as pd<br/>import numpy as np</span><span id="4aa6" class="mo lf it mk b gy mt mq l mr ms"># import data<br/>df = pd.read_csv('data/advertising.csv')</span><span id="a6ea" class="mo lf it mk b gy mt mq l mr ms"># engineer additional feature of interest<br/>df['TVxradio'] = df['TV'] * df['radio']</span><span id="0495" class="mo lf it mk b gy mt mq l mr ms"># slice data<br/>X = np.array(df[['TV', 'radio', 'newspaper', 'TVxradio']])<br/>y = np.array(df['sales'])</span><span id="2c5f" class="mo lf it mk b gy mt mq l mr ms"># train-test split<br/>X_train, X_test, y_train, y_test = train_test_split(<br/>     X, y, random_state=5)</span><span id="d6a8" class="mo lf it mk b gy mt mq l mr ms"><strong class="mk iu"># setup pipeline with preprocessing transformers<br/>lr = make_pipeline(preprocessing.StandardScaler(),<br/>                   LinearRegression())</strong></span><span id="3821" class="mo lf it mk b gy mt mq l mr ms"># k-fold cross validation<br/>scores = cross_val_score(lr, X_train, y_train, cv=10)<br/>print(scores)<br/>print(<br/>     f"95% CI Accuracy: "<br/>     f"{round(scores.mean(), 2)} "<br/>     f"(+/- {round(scores.std() * 2, 2)})"<br/>)</span><span id="aa0b" class="mo lf it mk b gy mt mq l mr ms"># test model on test set<br/>model = LinearRegression().fit(X_train, y_train)<br/>print(f'model accuracy on test set: {model.score(X_test, y_test)}')</span></pre><p id="e596" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">结果:</p><pre class="mc md me mf gt mj mk ml mm aw mn bi"><span id="92d2" class="mo lf it mk b gy mp mq l mr ms">[0.9859427, 0.97482388, 0.97914505, 0.82607816, 0.97520017, 0.98505002, 0.96018605, 0.973842, 0.984283, 0.8727062]</span><span id="f1eb" class="mo lf it mk b gy mt mq l mr ms">95% CI Accuracy: 0.95 (+/- 0.11)</span><span id="49e7" class="mo lf it mk b gy mt mq l mr ms">model accuracy on test set: 0.9715483746381636</span></pre><p id="4496" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">您在这里可以看到，随着这些特征的增加，平均模型精度增加，并且 95%的精度置信区间也变宽了。与我上面的更简单的模型相比，这个模型的准确性随着训练数据集的变化而变化。</p></div><div class="ab cl ob oc hx od" role="separator"><span class="oe bw bk of og oh"/><span class="oe bw bk of og oh"/><span class="oe bw bk of og"/></div><div class="im in io ip iq"><h1 id="2b42" class="le lf it bd lg lh oi lj lk ll oj ln lo jz ok ka lq kc ol kd ls kf om kg lu lv bi translated"><strong class="ak">期末笔记</strong></h1><p id="6243" class="pw-post-body-paragraph ki kj it kk b kl lw ju kn ko lx jx kq kr ly kt ku kv lz kx ky kz ma lb lc ld im bi translated">K-fold 交叉验证是一种很好的方式，通过提供更广泛的评估，而不是单一的高度调整的试验，来提供对团队真实质量和机器学习模型准确性的洞察。它允许你最大限度地利用你的训练集，同时仍然避免由于过度适应测试集而导致的偏差。</p><p id="dec2" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">请随意查看这个博客的<a class="ae mz" href="https://github.com/allisonhonold/k_fold_cross_validation_blog" rel="noopener ugc nofollow" target="_blank"> GitHub 库</a>。</p><h2 id="854f" class="mo lf it bd lg oo op dn lk oq or dp lo kr os ot lq kv ou ov ls kz ow ox lu oy bi translated">有关更多信息:</h2><div class="oz pa gp gr pb pc"><a href="https://machinelearningmastery.com/k-fold-cross-validation/" rel="noopener  ugc nofollow" target="_blank"><div class="pd ab fo"><div class="pe ab pf cl cj pg"><h2 class="bd iu gy z fp ph fr fs pi fu fw is bi translated">k-fold 交叉验证的简单介绍</h2><div class="pj l"><h3 class="bd b gy z fp ph fr fs pi fu fw dk translated">交叉验证是一种统计方法，用于评估机器学习模型的技能。它通常用于…</h3></div><div class="pk l"><p class="bd b dl z fp ph fr fs pi fu fw dk translated">machinelearningmastery.com</p></div></div><div class="pl l"><div class="pm l pn po pp pl pq mh pc"/></div></div></a></div></div></div>    
</body>
</html>