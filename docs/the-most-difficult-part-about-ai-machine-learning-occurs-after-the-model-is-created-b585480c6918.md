# 重新思考人工智能/机器学习的 DEVOPS

> 原文：<https://towardsdatascience.com/the-most-difficult-part-about-ai-machine-learning-occurs-after-the-model-is-created-b585480c6918?source=collection_archive---------8----------------------->

## 对 AI/ML 敏捷性的需求正迫使企业开发人员进行调整。这里有一些实用的步骤来加速你的 AI/ML 生命周期。

![](img/abb1e743ab9049ccb54768fdde16bbf2.png)

Photo by [wu yi](https://unsplash.com/@takeshi2?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText) on [Unsplash](https://unsplash.com/search/photos/flow?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)

# 模型不同于应用程序

现代企业 IT 环境极其复杂。对于应用程序，DEVOPS(一组功能、工具和自动化程序)有助于管理这种复杂性，从而显著提高了企业的交付速度。

然而，AI/ML 模型的生产之路带来了几个额外的挑战，超出了大多数企业 DEVOPS 环境的能力。事实上，这些挑战的影响相当大:麻省理工学院斯隆管理学院和波士顿咨询公司的一项研究强调，只有 5%的公司在业务中广泛使用模型。事实证明，将一款车型投入生产是一个艰难的过程。

*很明显，AI/ML 最困难的部分发生在模型实际创建之后。这个问题的根源是基于一个错误的信念，即因为模型和应用程序“仅仅”是软件代码，它们可以以类似的方式管理。相反，企业开发运维能力必须适应 AI/ML 生命周期的需求。*

# AI/ML 的生命周期是由数据变化的速度驱动的

企业应用程序通常是具有编码逻辑的自包含单元，以一致和确定的方式运行，独立于它们所作用的数据。另一方面，一个模型在生产中只会对与它被训练的模式相似的数据作出一致的反应。

如果数据中的模式在生产中“漂移”很大，那么模型对该数据的响应可能会产生重大的意外和潜在的负面后果。当一个模型的效能由于数据漂移而下降时，那么只有一个反应:尽快重新训练和重新部署该模型。

*这种对更频繁甚至按需发布周期的需求将迫使企业 DEVOPS 适应 AI/ML 生命周期所需的速度和敏捷性的新水平。*

# AI/ML 需要新的工具、环境和安全考虑

AI/ML 开发使用许多与传统应用程序开发类似的工具，例如编辑器、源代码管理，但是用于创建模型的语言、支持库和框架对于典型的企业 IT 团队来说可能是陌生的。

此外，在企业投资分析功能的情况下，它在很大程度上专注于更传统的商业智能工具或专有分析功能(例如，SAS)，但是，新的 AI/ML 工具和框架在很大程度上是开源的(例如，TensorFlow/Keras)。虽然不一定是一个大的障碍，但是新的工具、库和框架必须引入到企业开发运维能力中。

在“代码”级别，模型是寻求识别数据模式的算法。这些模型基于大量数据进行训练，需要的计算空间不同于大多数企业中可能提供的计算空间，而且要大得多。

在企业内部建立必要的基础设施(例如，GPU farms)已经被证明是困难的、昂贵的和耗时的，并且已经成为许多企业内模型交付的障碍。这些障碍促使许多企业考虑将模型开发和培训迁移到云中。然而，虽然云提供商显然拥有必要的可扩展计算足迹，但将训练数据迁移到云会带来巨大的数据安全挑战。

如今，只有少数行业(例如，拥有 [PII](https://en.wikipedia.org/wiki/Privacy_Act_of_1974) 或 [HIPAA](https://en.wikipedia.org/wiki/Health_Insurance_Portability_and_Accountability_Act) 的金融服务、医疗保健)受到严格的数据法规的影响，但是，在未来，安全考虑因素肯定会成为大多数企业优先考虑的问题。事实上，世界上最大的单一市场欧盟最近制定了[通用数据保护条例(GDPR)](https://eugdpr.org/) ，严格管理数据隐私。

就连脸书，正如脸书首席执行官马克·扎克伯格在最近的一篇文章中所强调的，也在为更广泛、更强有力的数据隐私和保护监管提供令人信服的理由。

显然，数据隐私和保护将很快影响并极大地改变企业的数据管理和开发运维能力。因此，关键问题是:DEVOPS 功能如何发展以满足 AI/ML 模型开发所需的关键数据隐私、保护和安全？

随着 AI/ML 在企业中的采用明显加快，传统的 DEVOPS 流程必须改变，以适应:(a)新的工具和框架，其中大多数是开源的，(b)将 AI/ML 工作负载从内部数据中心迁移到云，以及(c)随着企业 AI/ML 工作负载迁移到云，不断发展的安全策略和技术需要管理数据访问权限。

![](img/20fccf8442b96bf6ef27d6174986c770.png)

Photo by [Christopher Burns](https://unsplash.com/@christopher__burns?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText) on [Unsplash](https://unsplash.com/search/photos/tools?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)

# AI/ML 治理提出了新的要求

AI/ML 治理的目标是确保提供证据来证明一个模型及其交付过程能够生成可重现、可追踪和可验证的结果。

今天，包括银行、医疗保健、生物技术和政府许多部门在内的许多行业已经有了这些监管要求，但是，很少有人会讨论拥有一个规范的 AI/ML 生命周期的好处，它可以提供可重复、可跟踪和可验证的结果。(关于这个主题的更多信息，请参见我的 [AI/ML 治理](https://medium.com/@ericbroda/ai-and-machine-learning-governance-692b245bb6d7)文章)。

提供这些能力的含义强加了它们自己的挑战:**再现性**不仅需要维护模型源代码，还需要维护与用于训练模型的文件的永久关联；**可追溯性**要求维护模型及其训练文件与原始数据文件之间的关联，以及用于创建训练文件的任何转换脚本；并且**可验证性**要求模型生命周期生成的输出——例如，培训验证日志，或者证明道德/偏见验证的模型测试输出——也必须归档并链接到模型。

*大多数传统企业应用程序将越来越需要人工智能/ML 所需的深度和广度的工件和指标捕获。企业开发运维必须被扩展以支持 AI/ML 强加的需求，从而解决模型的可再现性、可追溯性和可验证性。*

# 企业开发运维只是 AI/ML 的一个起点

模型不同于传统的应用程序，这对企业开发运维能力提出了新的挑战:模型对数据的依赖推动了开发运维速度的提高；新工具、增加的安全约束和云功能的集成对企业的开发运维流程提出了新的要求；模型需要新的治理级别来确保可再现性、可追溯性和可验证性，这需要模型生命周期工件和度量捕获的新深度和广度。

这些挑战并不是不可克服的，但必须有所计划。在许多方面，企业 DEVOPS 必须被视为一个起点，必须为可伸缩和敏捷的 AI/ML 进行扩展。