# å‰©ä½™ç½‘ç»œ:åœ¨ Pytorch ä¸­å®ç° ResNet

> åŸæ–‡ï¼š<https://towardsdatascience.com/residual-network-implementing-resnet-a7da63c7b278?source=collection_archive---------1----------------------->

![](img/a476c54194e79e53c6dd27d6f9f6b646.png)

Image by the Author

***æˆ‘åœ¨***[***LinkedIn***](https://www.linkedin.com/in/francesco-saverio-zuppichini-94659a150/?originalSubdomain=ch)***ï¼Œå¿«æ¥æ‰“ä¸ªæ‹›å‘¼*** ğŸ‘‹

ä»Šå¤©æˆ‘ä»¬å°†åœ¨ [Pytorch](https://pytorch.org/) ä¸­å®ç°ä½•ç­‰äºº(å¾®è½¯ç ”ç©¶é™¢)è‘—åçš„ ResNetã€‚å®ƒåœ¨ ILSVRC 2015 åˆ†ç±»ä»»åŠ¡ä¸­è·å¾—ç¬¬ä¸€åã€‚

**ResNet åŠå…¶æ‰€æœ‰å˜ç§å·²ç»åœ¨æˆ‘çš„åº“ä¸­å®ç°** [**çœ¼é•œ**](https://github.com/FrancescoSaverioZuppichini/glasses)

ä»£ç æ˜¯[è¿™é‡Œ](https://github.com/FrancescoSaverioZuppichini/ResNet)ï¼Œè¿™ç¯‡æ–‡ç« çš„äº’åŠ¨ç‰ˆå¯ä»¥åœ¨[è¿™é‡Œä¸‹è½½](https://github.com/FrancescoSaverioZuppichini/ResNet/blob/master/ResNet.ipynb)åŸæ–‡å¯ä»¥ä»[è¿™é‡Œé˜…è¯»](https://arxiv.org/abs/1512.03385)(å¾ˆå®¹æ˜“ç†è§£)é™„åŠ ææ–™å¯ä»¥åœ¨è¿™ä¸ª [quora ç­”æ¡ˆ](https://www.quora.com/)ä¸­æ‰¾åˆ°

![](img/bd90dfc8a364eb8cdb7ff9e44356f967.png)

# ä»‹ç»

è¿™ä¸æ˜¯ä¸€ç¯‡æŠ€æœ¯æ–‡ç« ï¼Œæˆ‘ä¹Ÿæ²¡æœ‰èªæ˜åˆ°æ¯”åŸä½œè€…æ›´å¥½åœ°è§£é‡Šå‰©ä½™è¿æ¥ã€‚å› æ­¤æˆ‘ä»¬å°†ä»…é™äºå¿«é€Ÿæ¦‚è¿°ã€‚

*è¶Šæ·±çš„ç¥ç»ç½‘ç»œè¶Šéš¾è®­ç»ƒã€‚*ä¸ºä»€ä¹ˆï¼Ÿæ·±å±‚ç½‘ç»œçš„ä¸€ä¸ªå¤§é—®é¢˜æ˜¯æ¶ˆå¤±æ¢¯åº¦é—®é¢˜ã€‚åŸºæœ¬ä¸Šæ˜¯è¶Šæ·±è¶Šéš¾ç»ƒã€‚

ä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œä½œè€…å»ºè®®ä½¿ç”¨å¯¹å‰ä¸€å±‚çš„å¼•ç”¨æ¥è®¡ç®—ç»™å®šå±‚çš„è¾“å‡ºã€‚åœ¨ ResNet ä¸­ï¼Œä¸Šä¸€å±‚çš„è¾“å‡º(ç§°ä¸ºæ®‹å·®)è¢«æ·»åŠ åˆ°å½“å‰å±‚çš„è¾“å‡ºä¸­ã€‚ä¸‹å›¾æ˜¾ç¤ºäº†è¿™ä¸€æ“ä½œ

æˆ‘ä»¬å°†ä½¿ç”¨å¤§å¤šæ•°æ•°æ®ç§‘å­¦å®¶éƒ½ä¸çŸ¥é“çš„ä¸œè¥¿:é¢å‘å¯¹è±¡ç¼–ç¨‹ï¼Œä½¿æˆ‘ä»¬çš„å®ç°å°½å¯èƒ½å…·æœ‰å¯ä¼¸ç¼©æ€§

# åŸºæœ¬å—

å¥½çš„ï¼Œé¦–å…ˆè¦è€ƒè™‘æˆ‘ä»¬éœ€è¦ä»€ä¹ˆã€‚é¦–å…ˆï¼Œæˆ‘ä»¬å¿…é¡»æœ‰ä¸€ä¸ªå·ç§¯å±‚ï¼Œå› ä¸º PyTorch åœ¨ Conv2d ä¸­æ²¡æœ‰â€œè‡ªåŠ¨â€å¡«å……ï¼Œæˆ‘ä»¬å¿…é¡»è‡ªå·±ç¼–ç ï¼

```
Conv2dAuto(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
```

æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬ä½¿ç”¨`ModuleDict`åˆ›å»ºä¸€ä¸ªå…·æœ‰ä¸åŒæ¿€æ´»åŠŸèƒ½çš„å­—å…¸ï¼Œè¿™åœ¨ä»¥åä¼šå¾ˆæ–¹ä¾¿ã€‚

å¦‚æœä½ å¯¹`ModuleDict`ä¸ç†Ÿæ‚‰ï¼Œæˆ‘å»ºè®®é˜…è¯»æˆ‘ä»¥å‰çš„æ–‡ç«  [Pytorch:å¦‚ä½•ä»¥åŠä½•æ—¶ä½¿ç”¨æ¨¡å—ã€é¡ºåºã€æ¨¡å—åˆ—è¡¨å’Œæ¨¡å—æŒ‡ä»¤](/pytorch-how-and-when-to-use-module-sequential-modulelist-and-moduledict-7a54597b5f17)

# æ®‹ä½™å—

åˆ›å»ºå¹²å‡€çš„ä»£ç å¿…é¡»è€ƒè™‘åº”ç”¨ç¨‹åºçš„ä¸»è¦æ„ä»¶ï¼Œæˆ–è€…åœ¨æˆ‘ä»¬çš„ä¾‹å­ä¸­æ˜¯ç½‘ç»œçš„ä¸»è¦æ„ä»¶ã€‚æ®‹å·®å—é‡‡ç”¨å¸¦æœ‰`in_channels`çš„è¾“å…¥ï¼Œåº”ç”¨å·ç§¯å±‚çš„ä¸€äº›å—å°†å…¶å‡å°‘åˆ°`out_channels`ï¼Œå¹¶å°†å…¶åŠ èµ·æ¥ä½œä¸ºåŸå§‹è¾“å…¥ã€‚å¦‚æœå®ƒä»¬çš„å¤§å°ä¸åŒ¹é…ï¼Œé‚£ä¹ˆè¾“å…¥è¿›å…¥`identity`ã€‚æˆ‘ä»¬å¯ä»¥æŠ½è±¡è¿™ä¸ªè¿‡ç¨‹ï¼Œå¹¶åˆ›å»ºä¸€ä¸ªå¯æ‰©å±•çš„æ¥å£ã€‚

```
ResidualBlock(
  (blocks): Identity()
  (activate): ReLU(inplace)
  (shortcut): Identity()
)
```

è®©æˆ‘ä»¬ç”¨ä¸€ä¸ª 1 çš„è™šæ‹Ÿå‘é‡æ¥æµ‹è¯•å®ƒï¼Œæˆ‘ä»¬åº”è¯¥å¾—åˆ°ä¸€ä¸ª 2 çš„å‘é‡

```
tensor([[[[2.]]]])
```

åœ¨ ResNet ä¸­ï¼Œæ¯ä¸ªå—éƒ½æœ‰ä¸€ä¸ªæ‰©å±•å‚æ•°ï¼Œä»¥ä¾¿åœ¨éœ€è¦æ—¶å¢åŠ `out_channels`ã€‚åŒæ ·ï¼Œèº«ä»½è¢«å®šä¹‰ä¸ºä¸€ä¸ªå·ç§¯ï¼Œåè·Ÿä¸€ä¸ª BatchNorm å±‚ï¼Œè¿™è¢«ç§°ä¸º`shortcut`ã€‚ç„¶åï¼Œæˆ‘ä»¬å¯ä»¥æ‰©å±•`ResidualBlock`å¹¶å®šä¹‰`shortcut`å‡½æ•°ã€‚

```
ResNetResidualBlock(
  (blocks): Identity()
  (activate): ReLU(inplace)
  (shortcut): Sequential(
    (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
```

# åŸºæœ¬å—

ä¸€ä¸ªåŸºæœ¬çš„ ResNet å—ç”±ä¸¤å±‚`3x3` conv/batchnorm/relu ç»„æˆã€‚å›¾ä¸­ï¼Œçº¿æ¡ä»£è¡¨å‰©ä½™è¿ç®—ã€‚è™šçº¿è¡¨ç¤ºåº”ç”¨äº†å¿«æ·æ–¹å¼æ¥åŒ¹é…è¾“å…¥å’Œè¾“å‡ºç»´åº¦ã€‚

![](img/e6b778594d916d25df48c9a86e8c0f66.png)

Basic ResNet Block

è®©æˆ‘ä»¬é¦–å…ˆåˆ›å»ºä¸€ä¸ªæ–¹ä¾¿çš„å‡½æ•°æ¥å †å ä¸€ä¸ª conv å’Œ batchnorm å±‚

```
ResNetBasicBlock(
  (blocks): Sequential(
    (0): Sequential(
      (0): Conv2dAuto(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (1): ReLU(inplace)
    (2): Sequential(
      (0): Conv2dAuto(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (activate): ReLU(inplace)
  (shortcut): Sequential(
    (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
```

# ç“¶é¢ˆ

ä¸ºäº†å¢åŠ ç½‘ç»œæ·±åº¦ï¼ŒåŒæ—¶ä¿æŒå‚æ•°å¤§å°å°½å¯èƒ½ä½ï¼Œä½œè€…å®šä¹‰äº†ä¸€ä¸ªç“¶é¢ˆå—ï¼Œå³â€œä¸‰å±‚æ˜¯ 1x1ã€3x3 å’Œ 1x1 å·ç§¯ï¼Œå…¶ä¸­ 1Ã—1 å±‚è´Ÿè´£å‡å°‘ç„¶åå¢åŠ (æ¢å¤)ç»´åº¦ï¼Œè€Œ 3Ã—3 å±‚æ˜¯å…·æœ‰è¾ƒå°è¾“å…¥/è¾“å‡ºç»´åº¦çš„ç“¶é¢ˆã€‚â€æˆ‘ä»¬å¯ä»¥æ‰©å±•`ResNetResidualBlock`å¹¶åˆ›å»ºè¿™äº›å—ã€‚

```
ResNetBottleNeckBlock(
  (blocks): Sequential(
    (0): Sequential(
      (0): Conv2dAuto(32, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (1): ReLU(inplace)
    (2): Sequential(
      (0): Conv2dAuto(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (3): ReLU(inplace)
    (4): Sequential(
      (0): Conv2dAuto(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (activate): ReLU(inplace)
  (shortcut): Sequential(
    (0): Conv2d(32, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
```

# å±‚

ResNet çš„å±‚ç”±ä¸€ä¸ªæ¥ä¸€ä¸ªå †å çš„ç›¸åŒå—ç»„æˆã€‚

![](img/fb543a9524e6be4f3fa5211d23feedf4.png)

ResNet Layer

æˆ‘ä»¬å¯ä»¥é€šè¿‡ä¸€ä¸ªæ¥ä¸€ä¸ªåœ°ç²˜è´´`n`å—æ¥è½»æ¾å®šä¹‰å®ƒï¼Œåªéœ€è®°ä½ç¬¬ä¸€ä¸ªå·ç§¯å—çš„æ­¥é•¿ä¸º 2ï¼Œå› ä¸ºâ€œæˆ‘ä»¬é€šè¿‡æ­¥é•¿ä¸º 2 çš„å·ç§¯å±‚ç›´æ¥æ‰§è¡Œä¸‹é‡‡æ ·â€ã€‚

```
torch.Size([1, 128, 24, 24])
```

# ç¼–ç å™¨

ç±»ä¼¼åœ°ï¼Œç¼–ç å™¨ç”±ç‰¹å¾å°ºå¯¸é€æ¸å¢åŠ çš„å¤šå±‚ç»„æˆã€‚

![](img/a2ece30661ab2c61d7092da7e8f84de9.png)

ResNet Encoder

# è§£ç å™¨

è§£ç å™¨æ˜¯æˆ‘ä»¬åˆ›å»ºå®Œæ•´ç½‘ç»œæ‰€éœ€çš„æœ€åä¸€å—ã€‚å®ƒæ˜¯ä¸€ä¸ªå®Œå…¨è¿æ¥çš„å±‚ï¼Œå°†ç½‘ç»œå­¦ä¹ åˆ°çš„ç‰¹å¾æ˜ å°„åˆ°å®ƒä»¬å„è‡ªçš„ç±»ã€‚å¾ˆå®¹æ˜“ï¼Œæˆ‘ä»¬å¯ä»¥å°†å…¶å®šä¹‰ä¸º:

# é›·æ–¯å†…ç‰¹

æœ€åï¼Œæˆ‘ä»¬å¯ä»¥å°†æ‰€æœ‰çš„éƒ¨åˆ†æ”¾åœ¨ä¸€èµ·ï¼Œåˆ›å»ºæœ€ç»ˆçš„æ¨¡å‹ã€‚

![](img/bd90dfc8a364eb8cdb7ff9e44356f967.png)

ResNet34

æˆ‘ä»¬ç°åœ¨å¯ä»¥å®šä¹‰ä½œè€…æå‡ºçš„äº”ä¸ªæ¨¡å‹ï¼Œ`resnet18,34,50,101,152`

è®©æˆ‘ä»¬ç”¨[ç«ç‚¬æ¦‚è¦](https://github.com/sksq96/pytorch-summary)æ¥æµ‹è¯•è¿™ä¸ªæ¨¡å‹

```
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1         [-1, 64, 112, 112]           9,408
       BatchNorm2d-2         [-1, 64, 112, 112]             128
              ReLU-3         [-1, 64, 112, 112]               0
         MaxPool2d-4           [-1, 64, 56, 56]               0
        Conv2dAuto-5           [-1, 64, 56, 56]          36,864
       BatchNorm2d-6           [-1, 64, 56, 56]             128
              ReLU-7           [-1, 64, 56, 56]               0
        Conv2dAuto-8           [-1, 64, 56, 56]          36,864
       BatchNorm2d-9           [-1, 64, 56, 56]             128
             ReLU-10           [-1, 64, 56, 56]               0
 ResNetBasicBlock-11           [-1, 64, 56, 56]               0
       Conv2dAuto-12           [-1, 64, 56, 56]          36,864
      BatchNorm2d-13           [-1, 64, 56, 56]             128
             ReLU-14           [-1, 64, 56, 56]               0
       Conv2dAuto-15           [-1, 64, 56, 56]          36,864
      BatchNorm2d-16           [-1, 64, 56, 56]             128
             ReLU-17           [-1, 64, 56, 56]               0
 ResNetBasicBlock-18           [-1, 64, 56, 56]               0
      ResNetLayer-19           [-1, 64, 56, 56]               0
           Conv2d-20          [-1, 128, 28, 28]           8,192
      BatchNorm2d-21          [-1, 128, 28, 28]             256
       Conv2dAuto-22          [-1, 128, 28, 28]          73,728
      BatchNorm2d-23          [-1, 128, 28, 28]             256
             ReLU-24          [-1, 128, 28, 28]               0
       Conv2dAuto-25          [-1, 128, 28, 28]         147,456
      BatchNorm2d-26          [-1, 128, 28, 28]             256
             ReLU-27          [-1, 128, 28, 28]               0
 ResNetBasicBlock-28          [-1, 128, 28, 28]               0
       Conv2dAuto-29          [-1, 128, 28, 28]         147,456
      BatchNorm2d-30          [-1, 128, 28, 28]             256
             ReLU-31          [-1, 128, 28, 28]               0
       Conv2dAuto-32          [-1, 128, 28, 28]         147,456
      BatchNorm2d-33          [-1, 128, 28, 28]             256
             ReLU-34          [-1, 128, 28, 28]               0
 ResNetBasicBlock-35          [-1, 128, 28, 28]               0
      ResNetLayer-36          [-1, 128, 28, 28]               0
           Conv2d-37          [-1, 256, 14, 14]          32,768
      BatchNorm2d-38          [-1, 256, 14, 14]             512
       Conv2dAuto-39          [-1, 256, 14, 14]         294,912
      BatchNorm2d-40          [-1, 256, 14, 14]             512
             ReLU-41          [-1, 256, 14, 14]               0
       Conv2dAuto-42          [-1, 256, 14, 14]         589,824
      BatchNorm2d-43          [-1, 256, 14, 14]             512
             ReLU-44          [-1, 256, 14, 14]               0
 ResNetBasicBlock-45          [-1, 256, 14, 14]               0
       Conv2dAuto-46          [-1, 256, 14, 14]         589,824
      BatchNorm2d-47          [-1, 256, 14, 14]             512
             ReLU-48          [-1, 256, 14, 14]               0
       Conv2dAuto-49          [-1, 256, 14, 14]         589,824
      BatchNorm2d-50          [-1, 256, 14, 14]             512
             ReLU-51          [-1, 256, 14, 14]               0
 ResNetBasicBlock-52          [-1, 256, 14, 14]               0
      ResNetLayer-53          [-1, 256, 14, 14]               0
           Conv2d-54            [-1, 512, 7, 7]         131,072
      BatchNorm2d-55            [-1, 512, 7, 7]           1,024
       Conv2dAuto-56            [-1, 512, 7, 7]       1,179,648
      BatchNorm2d-57            [-1, 512, 7, 7]           1,024
             ReLU-58            [-1, 512, 7, 7]               0
       Conv2dAuto-59            [-1, 512, 7, 7]       2,359,296
      BatchNorm2d-60            [-1, 512, 7, 7]           1,024
             ReLU-61            [-1, 512, 7, 7]               0
 ResNetBasicBlock-62            [-1, 512, 7, 7]               0
       Conv2dAuto-63            [-1, 512, 7, 7]       2,359,296
      BatchNorm2d-64            [-1, 512, 7, 7]           1,024
             ReLU-65            [-1, 512, 7, 7]               0
       Conv2dAuto-66            [-1, 512, 7, 7]       2,359,296
      BatchNorm2d-67            [-1, 512, 7, 7]           1,024
             ReLU-68            [-1, 512, 7, 7]               0
 ResNetBasicBlock-69            [-1, 512, 7, 7]               0
      ResNetLayer-70            [-1, 512, 7, 7]               0
    ResNetEncoder-71            [-1, 512, 7, 7]               0
AdaptiveAvgPool2d-72            [-1, 512, 1, 1]               0
           Linear-73                 [-1, 1000]         513,000
    ResnetDecoder-74                 [-1, 1000]               0
================================================================
Total params: 11,689,512
Trainable params: 11,689,512
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.57
Forward/backward pass size (MB): 65.86
Params size (MB): 44.59
Estimated Total Size (MB): 111.03
----------------------------------------------------------------
```

ä¸ºäº†æ£€æŸ¥æ­£ç¡®æ€§ï¼Œè®©æˆ‘ä»¬çœ‹çœ‹åŸå§‹å®ç°çš„å‚æ•°æ•°é‡

```
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1         [-1, 64, 112, 112]           9,408
       BatchNorm2d-2         [-1, 64, 112, 112]             128
              ReLU-3         [-1, 64, 112, 112]               0
         MaxPool2d-4           [-1, 64, 56, 56]               0
            Conv2d-5           [-1, 64, 56, 56]          36,864
       BatchNorm2d-6           [-1, 64, 56, 56]             128
              ReLU-7           [-1, 64, 56, 56]               0
            Conv2d-8           [-1, 64, 56, 56]          36,864
       BatchNorm2d-9           [-1, 64, 56, 56]             128
             ReLU-10           [-1, 64, 56, 56]               0
       BasicBlock-11           [-1, 64, 56, 56]               0
           Conv2d-12           [-1, 64, 56, 56]          36,864
      BatchNorm2d-13           [-1, 64, 56, 56]             128
             ReLU-14           [-1, 64, 56, 56]               0
           Conv2d-15           [-1, 64, 56, 56]          36,864
      BatchNorm2d-16           [-1, 64, 56, 56]             128
             ReLU-17           [-1, 64, 56, 56]               0
       BasicBlock-18           [-1, 64, 56, 56]               0
           Conv2d-19          [-1, 128, 28, 28]          73,728
      BatchNorm2d-20          [-1, 128, 28, 28]             256
             ReLU-21          [-1, 128, 28, 28]               0
           Conv2d-22          [-1, 128, 28, 28]         147,456
      BatchNorm2d-23          [-1, 128, 28, 28]             256
           Conv2d-24          [-1, 128, 28, 28]           8,192
      BatchNorm2d-25          [-1, 128, 28, 28]             256
             ReLU-26          [-1, 128, 28, 28]               0
       BasicBlock-27          [-1, 128, 28, 28]               0
           Conv2d-28          [-1, 128, 28, 28]         147,456
      BatchNorm2d-29          [-1, 128, 28, 28]             256
             ReLU-30          [-1, 128, 28, 28]               0
           Conv2d-31          [-1, 128, 28, 28]         147,456
      BatchNorm2d-32          [-1, 128, 28, 28]             256
             ReLU-33          [-1, 128, 28, 28]               0
       BasicBlock-34          [-1, 128, 28, 28]               0
           Conv2d-35          [-1, 256, 14, 14]         294,912
      BatchNorm2d-36          [-1, 256, 14, 14]             512
             ReLU-37          [-1, 256, 14, 14]               0
           Conv2d-38          [-1, 256, 14, 14]         589,824
      BatchNorm2d-39          [-1, 256, 14, 14]             512
           Conv2d-40          [-1, 256, 14, 14]          32,768
      BatchNorm2d-41          [-1, 256, 14, 14]             512
             ReLU-42          [-1, 256, 14, 14]               0
       BasicBlock-43          [-1, 256, 14, 14]               0
           Conv2d-44          [-1, 256, 14, 14]         589,824
      BatchNorm2d-45          [-1, 256, 14, 14]             512
             ReLU-46          [-1, 256, 14, 14]               0
           Conv2d-47          [-1, 256, 14, 14]         589,824
      BatchNorm2d-48          [-1, 256, 14, 14]             512
             ReLU-49          [-1, 256, 14, 14]               0
       BasicBlock-50          [-1, 256, 14, 14]               0
           Conv2d-51            [-1, 512, 7, 7]       1,179,648
      BatchNorm2d-52            [-1, 512, 7, 7]           1,024
             ReLU-53            [-1, 512, 7, 7]               0
           Conv2d-54            [-1, 512, 7, 7]       2,359,296
      BatchNorm2d-55            [-1, 512, 7, 7]           1,024
           Conv2d-56            [-1, 512, 7, 7]         131,072
      BatchNorm2d-57            [-1, 512, 7, 7]           1,024
             ReLU-58            [-1, 512, 7, 7]               0
       BasicBlock-59            [-1, 512, 7, 7]               0
           Conv2d-60            [-1, 512, 7, 7]       2,359,296
      BatchNorm2d-61            [-1, 512, 7, 7]           1,024
             ReLU-62            [-1, 512, 7, 7]               0
           Conv2d-63            [-1, 512, 7, 7]       2,359,296
      BatchNorm2d-64            [-1, 512, 7, 7]           1,024
             ReLU-65            [-1, 512, 7, 7]               0
       BasicBlock-66            [-1, 512, 7, 7]               0
AdaptiveAvgPool2d-67            [-1, 512, 1, 1]               0
           Linear-68                 [-1, 1000]         513,000
================================================================
Total params: 11,689,512
Trainable params: 11,689,512
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.57
Forward/backward pass size (MB): 62.79
Params size (MB): 44.59
Estimated Total Size (MB): 107.96
----------------------------------------------------------------
```

æ˜¯ä¸€æ ·çš„ï¼

# ç”¨æˆ·åŒ–

é¢å‘å¯¹è±¡ç¼–ç¨‹çš„ä¸€ä¸ªä¼˜ç‚¹æ˜¯æˆ‘ä»¬å¯ä»¥å¾ˆå®¹æ˜“åœ°å®šåˆ¶æˆ‘ä»¬çš„ç½‘ç»œã€‚

# æ”¹å˜è¡—åŒº

å¦‚æœæˆ‘ä»¬æƒ³ä½¿ç”¨ä¸åŒçš„åŸºæœ¬å—å‘¢ï¼Ÿä¹Ÿè®¸æˆ‘ä»¬åªæƒ³è¦ä¸€ä¸ª 3x3 çš„ convï¼Œä¹Ÿè®¸è¿˜è¦é€€å­¦ï¼Ÿã€‚åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œæˆ‘ä»¬å¯ä»¥å­ç±»åŒ–`ResNetResidualBlock`å¹¶æ”¹å˜`.blocks`å­—æ®µï¼

è®©æˆ‘ä»¬æŠŠè¿™ä¸ªæ–°çš„åŒºå—äº¤ç»™`resnet18`ï¼Œåˆ›å»ºä¸€ä¸ªæ–°çš„æ¶æ„ï¼

```
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1         [-1, 64, 112, 112]           9,408
       BatchNorm2d-2         [-1, 64, 112, 112]             128
              ReLU-3         [-1, 64, 112, 112]               0
         MaxPool2d-4           [-1, 64, 56, 56]               0
        Conv2dAuto-5           [-1, 64, 56, 56]          36,864
         Dropout2d-6           [-1, 64, 56, 56]               0
              ReLU-7           [-1, 64, 56, 56]               0
              ReLU-8           [-1, 64, 56, 56]               0
AnOtherResNetBlock-9           [-1, 64, 56, 56]               0
       Conv2dAuto-10           [-1, 64, 56, 56]          36,864
        Dropout2d-11           [-1, 64, 56, 56]               0
             ReLU-12           [-1, 64, 56, 56]               0
             ReLU-13           [-1, 64, 56, 56]               0
AnOtherResNetBlock-14           [-1, 64, 56, 56]               0
      ResNetLayer-15           [-1, 64, 56, 56]               0
           Conv2d-16          [-1, 128, 28, 28]           8,192
      BatchNorm2d-17          [-1, 128, 28, 28]             256
       Conv2dAuto-18          [-1, 128, 28, 28]          73,728
        Dropout2d-19          [-1, 128, 28, 28]               0
             ReLU-20          [-1, 128, 28, 28]               0
             ReLU-21          [-1, 128, 28, 28]               0
AnOtherResNetBlock-22          [-1, 128, 28, 28]               0
       Conv2dAuto-23          [-1, 128, 28, 28]         147,456
        Dropout2d-24          [-1, 128, 28, 28]               0
             ReLU-25          [-1, 128, 28, 28]               0
             ReLU-26          [-1, 128, 28, 28]               0
AnOtherResNetBlock-27          [-1, 128, 28, 28]               0
      ResNetLayer-28          [-1, 128, 28, 28]               0
           Conv2d-29          [-1, 256, 14, 14]          32,768
      BatchNorm2d-30          [-1, 256, 14, 14]             512
       Conv2dAuto-31          [-1, 256, 14, 14]         294,912
        Dropout2d-32          [-1, 256, 14, 14]               0
             ReLU-33          [-1, 256, 14, 14]               0
             ReLU-34          [-1, 256, 14, 14]               0
AnOtherResNetBlock-35          [-1, 256, 14, 14]               0
       Conv2dAuto-36          [-1, 256, 14, 14]         589,824
        Dropout2d-37          [-1, 256, 14, 14]               0
             ReLU-38          [-1, 256, 14, 14]               0
             ReLU-39          [-1, 256, 14, 14]               0
AnOtherResNetBlock-40          [-1, 256, 14, 14]               0
      ResNetLayer-41          [-1, 256, 14, 14]               0
           Conv2d-42            [-1, 512, 7, 7]         131,072
      BatchNorm2d-43            [-1, 512, 7, 7]           1,024
       Conv2dAuto-44            [-1, 512, 7, 7]       1,179,648
        Dropout2d-45            [-1, 512, 7, 7]               0
             ReLU-46            [-1, 512, 7, 7]               0
             ReLU-47            [-1, 512, 7, 7]               0
AnOtherResNetBlock-48            [-1, 512, 7, 7]               0
       Conv2dAuto-49            [-1, 512, 7, 7]       2,359,296
        Dropout2d-50            [-1, 512, 7, 7]               0
             ReLU-51            [-1, 512, 7, 7]               0
             ReLU-52            [-1, 512, 7, 7]               0
AnOtherResNetBlock-53            [-1, 512, 7, 7]               0
      ResNetLayer-54            [-1, 512, 7, 7]               0
    ResNetEncoder-55            [-1, 512, 7, 7]               0
AdaptiveAvgPool2d-56            [-1, 512, 1, 1]               0
           Linear-57                 [-1, 1000]         513,000
    ResnetDecoder-58                 [-1, 1000]               0
================================================================
Total params: 5,414,952
Trainable params: 5,414,952
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.57
Forward/backward pass size (MB): 54.38
Params size (MB): 20.66
Estimated Total Size (MB): 75.61
----------------------------------------------------------------
```

# æ”¹å˜æ¿€æ´»åŠŸèƒ½

å®¹æ˜“çš„äº‹

```
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1         [-1, 64, 112, 112]           9,408
       BatchNorm2d-2         [-1, 64, 112, 112]             128
         LeakyReLU-3         [-1, 64, 112, 112]               0
         MaxPool2d-4           [-1, 64, 56, 56]               0
        Conv2dAuto-5           [-1, 64, 56, 56]          36,864
       BatchNorm2d-6           [-1, 64, 56, 56]             128
         LeakyReLU-7           [-1, 64, 56, 56]               0
        Conv2dAuto-8           [-1, 64, 56, 56]          36,864
       BatchNorm2d-9           [-1, 64, 56, 56]             128
        LeakyReLU-10           [-1, 64, 56, 56]               0
 ResNetBasicBlock-11           [-1, 64, 56, 56]               0
       Conv2dAuto-12           [-1, 64, 56, 56]          36,864
      BatchNorm2d-13           [-1, 64, 56, 56]             128
        LeakyReLU-14           [-1, 64, 56, 56]               0
       Conv2dAuto-15           [-1, 64, 56, 56]          36,864
      BatchNorm2d-16           [-1, 64, 56, 56]             128
        LeakyReLU-17           [-1, 64, 56, 56]               0
 ResNetBasicBlock-18           [-1, 64, 56, 56]               0
      ResNetLayer-19           [-1, 64, 56, 56]               0
           Conv2d-20          [-1, 128, 28, 28]           8,192
      BatchNorm2d-21          [-1, 128, 28, 28]             256
       Conv2dAuto-22          [-1, 128, 28, 28]          73,728
      BatchNorm2d-23          [-1, 128, 28, 28]             256
        LeakyReLU-24          [-1, 128, 28, 28]               0
       Conv2dAuto-25          [-1, 128, 28, 28]         147,456
      BatchNorm2d-26          [-1, 128, 28, 28]             256
        LeakyReLU-27          [-1, 128, 28, 28]               0
 ResNetBasicBlock-28          [-1, 128, 28, 28]               0
       Conv2dAuto-29          [-1, 128, 28, 28]         147,456
      BatchNorm2d-30          [-1, 128, 28, 28]             256
        LeakyReLU-31          [-1, 128, 28, 28]               0
       Conv2dAuto-32          [-1, 128, 28, 28]         147,456
      BatchNorm2d-33          [-1, 128, 28, 28]             256
        LeakyReLU-34          [-1, 128, 28, 28]               0
 ResNetBasicBlock-35          [-1, 128, 28, 28]               0
      ResNetLayer-36          [-1, 128, 28, 28]               0
           Conv2d-37          [-1, 256, 14, 14]          32,768
      BatchNorm2d-38          [-1, 256, 14, 14]             512
       Conv2dAuto-39          [-1, 256, 14, 14]         294,912
      BatchNorm2d-40          [-1, 256, 14, 14]             512
        LeakyReLU-41          [-1, 256, 14, 14]               0
       Conv2dAuto-42          [-1, 256, 14, 14]         589,824
      BatchNorm2d-43          [-1, 256, 14, 14]             512
        LeakyReLU-44          [-1, 256, 14, 14]               0
 ResNetBasicBlock-45          [-1, 256, 14, 14]               0
       Conv2dAuto-46          [-1, 256, 14, 14]         589,824
      BatchNorm2d-47          [-1, 256, 14, 14]             512
        LeakyReLU-48          [-1, 256, 14, 14]               0
       Conv2dAuto-49          [-1, 256, 14, 14]         589,824
      BatchNorm2d-50          [-1, 256, 14, 14]             512
        LeakyReLU-51          [-1, 256, 14, 14]               0
 ResNetBasicBlock-52          [-1, 256, 14, 14]               0
      ResNetLayer-53          [-1, 256, 14, 14]               0
           Conv2d-54            [-1, 512, 7, 7]         131,072
      BatchNorm2d-55            [-1, 512, 7, 7]           1,024
       Conv2dAuto-56            [-1, 512, 7, 7]       1,179,648
      BatchNorm2d-57            [-1, 512, 7, 7]           1,024
        LeakyReLU-58            [-1, 512, 7, 7]               0
       Conv2dAuto-59            [-1, 512, 7, 7]       2,359,296
      BatchNorm2d-60            [-1, 512, 7, 7]           1,024
        LeakyReLU-61            [-1, 512, 7, 7]               0
 ResNetBasicBlock-62            [-1, 512, 7, 7]               0
       Conv2dAuto-63            [-1, 512, 7, 7]       2,359,296
      BatchNorm2d-64            [-1, 512, 7, 7]           1,024
        LeakyReLU-65            [-1, 512, 7, 7]               0
       Conv2dAuto-66            [-1, 512, 7, 7]       2,359,296
      BatchNorm2d-67            [-1, 512, 7, 7]           1,024
        LeakyReLU-68            [-1, 512, 7, 7]               0
 ResNetBasicBlock-69            [-1, 512, 7, 7]               0
      ResNetLayer-70            [-1, 512, 7, 7]               0
    ResNetEncoder-71            [-1, 512, 7, 7]               0
AdaptiveAvgPool2d-72            [-1, 512, 1, 1]               0
           Linear-73                 [-1, 1000]         513,000
    ResnetDecoder-74                 [-1, 1000]               0
================================================================
Total params: 11,689,512
Trainable params: 11,689,512
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.57
Forward/backward pass size (MB): 65.86
Params size (MB): 44.59
Estimated Total Size (MB): 111.03
----------------------------------------------------------------
```

# ç»“è®º

åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬çœ‹åˆ°äº†å¦‚ä½•ä»¥ä¸€ç§è‰¯å¥½çš„ã€å¯ä¼¸ç¼©çš„å’Œå¯å®šåˆ¶çš„æ–¹å¼å®ç° ResNetã€‚åœ¨ä¸‹ä¸€ç¯‡æ–‡ç« ä¸­ï¼Œæˆ‘ä»¬å°†è¿›ä¸€æ­¥æ‰©å±•è¿™ä¸ªæ¶æ„ï¼Œè®­ç»ƒå®ƒå¹¶ä½¿ç”¨å¦å¤–ä¸¤ä¸ªæŠ€å·§:é¢„æ¿€æ´»å’ŒæŒ¤å‹å’Œæ¿€åŠ±ã€‚

è¿™é‡Œæ‰€æœ‰çš„ä»£ç éƒ½æ˜¯[è¿™é‡Œæ˜¯](https://github.com/FrancescoSaverioZuppichini/ResNet)

å¦‚æœä½ å¯¹ç†è§£æ›´å¥½çš„ç¥ç»ç½‘ç»œæ„Ÿå…´è¶£ï¼Œæˆ‘å»ºè®®ä½ è¯»ä¸€è¯»æˆ‘å†™çš„å¦ä¸€ç¯‡æ–‡ç« 

[](/a-journey-into-convolutional-neural-network-visualization-1abc71605209) [## å·ç§¯ç¥ç»ç½‘ç»œå¯è§†åŒ–ä¹‹æ—…

### å¼—æœ—è¥¿æ–¯ç§‘Â·è¨ç»´é‡Œå¥¥Â·ç¥–çš®å¥‡å°¼

towardsdatascience.com](/a-journey-into-convolutional-neural-network-visualization-1abc71605209) 

æƒ³çŸ¥é“å¦‚ä½•å®ç° RepVGGï¼ŸResNet çš„æ›´å¥½ç‰ˆæœ¬ï¼Ÿ

[](/implementing-repvgg-in-pytorch-fc8562be58f9) [## åœ¨ PyTorch ä¸­å®ç° RepVGG

### è®©æ‚¨çš„ CNN é€Ÿåº¦å¿« 100 å€ä»¥ä¸Š

towardsdatascience.com](/implementing-repvgg-in-pytorch-fc8562be58f9) 

äº†è§£ PyTorch ä¸­çš„éæœ€å¤§æŠ‘åˆ¶

[](https://medium.com/@FrancescoZ/non-max-suppression-nms-in-pytorch-35f77397a0aa) [## PyTorch ä¸­çš„éæœ€å¤§æŠ‘åˆ¶(NMS)

### åœ¨ PyTorch ä¸­å®ç°éæœ€å¤§æŠ‘åˆ¶

medium.com](https://medium.com/@FrancescoZ/non-max-suppression-nms-in-pytorch-35f77397a0aa) 

æ„Ÿè°¢æ‚¨çš„é˜…è¯»

å¼—æœ—è¥¿æ–¯ç§‘Â·è¨ç»´é‡Œå¥¥Â·ç¥–çš®å¥‡å°¼