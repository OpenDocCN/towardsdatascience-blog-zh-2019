<html>
<head>
<title>Developing a DCGAN Model in Tensorflow 2.0</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">在 Tensorflow 2.0 中开发 DCGAN 模型</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/developing-a-dcgan-model-in-tensorflow-2-0-396bc1a101b2?source=collection_archive---------6-----------------------#2019-03-16">https://towardsdatascience.com/developing-a-dcgan-model-in-tensorflow-2-0-396bc1a101b2?source=collection_archive---------6-----------------------#2019-03-16</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><h1 id="491d" class="jn jo iq bd jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk bi translated">介绍</h1><p id="3a81" class="pw-post-body-paragraph kl km iq kn b ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">2019 年 3 月初，TensorFlow 2.0 发布，我们决定基于<a class="ae lj" href="https://github.com/carpedm20/DCGAN-tensorflow" rel="noopener ugc nofollow" target="_blank"> Taehoon Kim </a>的 DCGAN 实现创建一个图像生成器。下面是如何在 TensorFlow 2.0 中开发 DCGAN 模型的教程。</p><blockquote class="lk"><p id="760b" class="ll lm iq bd ln lo lp lq lr ls lt li dk translated"><em class="lu">“为了避免 D(鉴别器)网络的快速收敛，G(生成器)网络每更新一次 D 网络就更新两次，与原论文不同。”</em></p><p id="80d3" class="ll lm iq bd ln lo lp lq lr ls lt li dk translated"><strong class="ak"> <em class="lu"> —金泰勋</em> </strong></p></blockquote><h1 id="810e" class="jn jo iq bd jp jq jr js jt ju jv jw jx jy lv ka kb kc lw ke kf kg lx ki kj kk bi translated">先决条件</h1><ul class=""><li id="940a" class="ly lz iq kn b ko kp ks kt kw ma la mb le mc li md me mf mg bi translated">Jupyter 笔记本</li><li id="be6c" class="ly lz iq kn b ko mh ks mi kw mj la mk le ml li md me mf mg bi translated">张量流 2.0</li><li id="acf4" class="ly lz iq kn b ko mh ks mi kw mj la mk le ml li md me mf mg bi translated">访问高性能 GPU</li></ul><h1 id="f5d1" class="jn jo iq bd jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk bi translated">DCGAN 架构</h1><p id="f6b5" class="pw-post-body-paragraph kl km iq kn b ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">下图显示了 DCGAN 论文中引用的生成器。本质上，该网络接收一个 100x1 噪声矢量，标记为<em class="mm"> 100z </em>，并将其映射到 64x64x3 的 G(Z)输出。</p><blockquote class="mn mo mp"><p id="c0cf" class="kl km mm kn b ko mq kq kr ks mr ku kv ms mt ky kz mu mv lc ld mw mx lg lh li ij bi translated">100 x 1→1024 x 4 x 4→512 x 8 x 8→256 x 16 x 16→128 x 32 x 32→64 x 64 x 3</p></blockquote><p id="797f" class="pw-post-body-paragraph kl km iq kn b ko mq kq kr ks mr ku kv kw mt ky kz la mv lc ld le mx lg lh li ij bi translated">第一层通过在每一步投影和整形来扩展随机噪声</p><figure class="mz na nb nc gt nd gh gi paragraph-image"><div class="gh gi my"><img src="../Images/5f75e89886e9633e504dd644e27f3655.png" data-original-src="https://miro.medium.com/v2/resize:fit:1292/format:webp/1*N7J314AzyF_RlteW2xqPuA.png"/></div><figcaption class="ng nh gj gh gi ni nj bd b be z dk">Source: carpedm20</figcaption></figure><h2 id="08a5" class="nk jo iq bd jp nl nm dn jt nn no dp jx kw np nq kb la nr ns kf le nt nu kj nv bi translated">大步</h2><p id="d746" class="pw-post-body-paragraph kl km iq kn b ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">跨距指定了卷积沿高度和宽度的“步数”。这里有一个动画示例:</p><figure class="mz na nb nc gt nd gh gi paragraph-image"><div class="gh gi nw"><img src="../Images/ff83f2ef8299d68bd7a24031dc278872.png" data-original-src="https://miro.medium.com/v2/resize:fit:790/0*o4wHLoN6pf9UdFFx.gif"/></div><figcaption class="ng nh gj gh gi ni nj bd b be z dk">An example of strides</figcaption></figure><h2 id="f00c" class="nk jo iq bd jp nl nm dn jt nn no dp jx kw np nq kb la nr ns kf le nt nu kj nv bi translated">输入噪声</h2><pre class="mz na nb nc gt nx ny nz oa aw ob bi"><span id="1107" class="nk jo iq ny b gy oc od l oe of">generator = make_generator_model()</span><span id="3f07" class="nk jo iq ny b gy og od l oe of">noise = tf.random.normal([1,100]) # shape is 1, 100<br/>generated_image = generator(noise, training = False)</span><span id="5457" class="nk jo iq ny b gy og od l oe of">plt.imshow(generated_image[0, :, :, 0], cmap =”gist_rainbow”)</span></pre><h2 id="ef66" class="nk jo iq bd jp nl nm dn jt nn no dp jx kw np nq kb la nr ns kf le nt nu kj nv bi translated">致密层</h2><p id="83ff" class="pw-post-body-paragraph kl km iq kn b ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">在 Keras 中，您可以创建层来开发模型。模型通常是层的网络，其中最常见的类型是层的堆叠</p><p id="2aeb" class="pw-post-body-paragraph kl km iq kn b ko mq kq kr ks mr ku kv kw mt ky kz la mv lc ld le mx lg lh li ij bi translated">将密集连接的图层添加到模型将接受 shape (*，100)的输入数组。第一层之后数据的形状将为(*，4*4*1024)。在这种情况下，由于自动形状推断<br/> <br/>批处理标准化功能类似于网络每一层的预处理，您不需要指定向前移动的输入的大小。</p><p id="5b38" class="pw-post-body-paragraph kl km iq kn b ko mq kq kr ks mr ku kv kw mt ky kz la mv lc ld le mx lg lh li ij bi translated">ReLU 对于所有正值都是线性的，对于所有负值都设置为零。泄漏 ReLU 对于负值具有较小的斜率，而不是完全为零。</p><blockquote class="lk"><p id="d706" class="ll lm iq bd ln lo lp lq lr ls lt li dk translated">例如，当 x &lt; 0</p></blockquote><pre class="oh oi oj ok ol nx ny nz oa aw ob bi"><span id="0be6" class="nk jo iq ny b gy oc od l oe of">def <strong class="ny ir">make_generator_model</strong>():<br/><br/> model = tf.keras.Sequential()<br/> <br/><br/> model.add(layers.Dense(4*4*1024, use_bias = False, input_shape = (100,)))<br/> <br/><br/> model.add(layers.BatchNormalization())<br/><br/> model.add(layers.LeakyReLU())</span></pre></div><div class="ab cl om on hu oo" role="separator"><span class="op bw bk oq or os"/><span class="op bw bk oq or os"/><span class="op bw bk oq or"/></div><div class="ij ik il im in"><h2 id="c460" class="nk jo iq bd jp nl nm dn jt nn no dp jx kw np nq kb la nr ns kf le nt nu kj nv bi translated">First Layer</h2><p id="2533" class="pw-post-body-paragraph kl km iq kn b ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">The generator uses a transposed convolutional layer (upsampling) to produce an image from seed (random noise).</p><ul class=""><li id="f984" class="ly lz iq kn b ko mq ks mr kw ot la ou le ov li md me mf mg bi translated"><strong class="kn ir"> 512 </strong>是输出空间的维度时，泄漏 ReLU 可以具有 y = 0.01x</li><li id="6d34" class="ly lz iq kn b ko mh ks mi kw mj la mk le ml li md me mf mg bi translated"><strong class="kn ir"> (5，5) </strong>指定 2D 卷积窗口的高度和宽度</li><li id="5d60" class="ly lz iq kn b ko mh ks mi kw mj la mk le ml li md me mf mg bi translated"><strong class="kn ir">步幅= (2，2) </strong></li></ul><pre class="mz na nb nc gt nx ny nz oa aw ob bi"><span id="1097" class="nk jo iq ny b gy oc od l oe of">model.add(layers.Conv2DTranspose(512, (5, 5), strides = (2,2), padding = “same”, use_bias = False))<br/> <br/>assert model.output_shape == (None, 8, 8, 512)<br/>model.add(layers.BatchNormalization())<br/>model.add(layers.LeakyReLU())</span></pre></div><div class="ab cl om on hu oo" role="separator"><span class="op bw bk oq or os"/><span class="op bw bk oq or os"/><span class="op bw bk oq or"/></div><div class="ij ik il im in"><h2 id="f0ef" class="nk jo iq bd jp nl nm dn jt nn no dp jx kw np nq kb la nr ns kf le nt nu kj nv bi translated">第二层</h2><p id="643d" class="pw-post-body-paragraph kl km iq kn b ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">生成器使用转置卷积层(上采样)从前一层生成图像。</p><ul class=""><li id="18a5" class="ly lz iq kn b ko mq ks mr kw ot la ou le ov li md me mf mg bi translated">256 是输出空间的维数</li><li id="fe36" class="ly lz iq kn b ko mh ks mi kw mj la mk le ml li md me mf mg bi translated"><strong class="kn ir"> (5，5) </strong>指定 2D 卷积窗口的高度和宽度</li><li id="c9d4" class="ly lz iq kn b ko mh ks mi kw mj la mk le ml li md me mf mg bi translated"><strong class="kn ir">步幅= (2，2) </strong></li></ul><pre class="mz na nb nc gt nx ny nz oa aw ob bi"><span id="2182" class="nk jo iq ny b gy oc od l oe of">model.add(layers.Conv2DTranspose(256, (5,5), strides = (2,2), padding = “same”, use_bias = False))</span><span id="fb75" class="nk jo iq ny b gy og od l oe of">assert model.output_shape == (None, 16, 16, 256)<br/>model.add(layers.BatchNormalization())<br/>model.add(layers.LeakyReLU())</span></pre></div><div class="ab cl om on hu oo" role="separator"><span class="op bw bk oq or os"/><span class="op bw bk oq or os"/><span class="op bw bk oq or"/></div><div class="ij ik il im in"><h2 id="b139" class="nk jo iq bd jp nl nm dn jt nn no dp jx kw np nq kb la nr ns kf le nt nu kj nv bi translated">第三层</h2><p id="8638" class="pw-post-body-paragraph kl km iq kn b ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">生成器使用转置卷积层(上采样)从前一层生成图像。</p><ul class=""><li id="79ae" class="ly lz iq kn b ko mq ks mr kw ot la ou le ov li md me mf mg bi translated">128 是输出空间的维数</li><li id="50a3" class="ly lz iq kn b ko mh ks mi kw mj la mk le ml li md me mf mg bi translated"><strong class="kn ir"> (5，5) </strong>指定 2D 卷积窗口的高度和宽度</li><li id="6a6f" class="ly lz iq kn b ko mh ks mi kw mj la mk le ml li md me mf mg bi translated"><strong class="kn ir">步幅= (2，2) </strong></li></ul><pre class="mz na nb nc gt nx ny nz oa aw ob bi"><span id="1a76" class="nk jo iq ny b gy oc od l oe of">model.add(layers.Conv2DTranspose(128, (5,5), strides = (2,2), padding = “same”, use_bias = False))</span><span id="f74f" class="nk jo iq ny b gy og od l oe of">assert model.output_shape == (None, 32, 32, 128)<br/>model.add(layers.BatchNormalization())<br/>model.add(layers.LeakyReLU())</span></pre></div><div class="ab cl om on hu oo" role="separator"><span class="op bw bk oq or os"/><span class="op bw bk oq or os"/><span class="op bw bk oq or"/></div><div class="ij ik il im in"><h2 id="4a3a" class="nk jo iq bd jp nl nm dn jt nn no dp jx kw np nq kb la nr ns kf le nt nu kj nv bi translated">最后一层</h2><p id="b40a" class="pw-post-body-paragraph kl km iq kn b ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">生成器使用转置卷积层(上采样)从前一层生成图像。</p><ul class=""><li id="4820" class="ly lz iq kn b ko mq ks mr kw ot la ou le ov li md me mf mg bi translated">64 是输出空间的维数</li><li id="89a6" class="ly lz iq kn b ko mh ks mi kw mj la mk le ml li md me mf mg bi translated"><strong class="kn ir"> (5，5) </strong>指定 2D 卷积窗口的高度和宽度</li><li id="14b9" class="ly lz iq kn b ko mh ks mi kw mj la mk le ml li md me mf mg bi translated"><strong class="kn ir">步幅= (2，2) </strong>指定卷积沿高度和宽度的步幅</li></ul><pre class="mz na nb nc gt nx ny nz oa aw ob bi"><span id="d7b4" class="nk jo iq ny b gy oc od l oe of">model.add(layers.Conv2DTranspose(3, (5,5), strides = (2,2), padding = “same”, use_bias = False, activation = “tanh”))</span><span id="3904" class="nk jo iq ny b gy og od l oe of">assert model.output_shape == (None, 64, 64, 3)<br/> return model</span></pre></div><div class="ab cl om on hu oo" role="separator"><span class="op bw bk oq or os"/><span class="op bw bk oq or os"/><span class="op bw bk oq or"/></div><div class="ij ik il im in"><h2 id="e75f" class="nk jo iq bd jp nl nm dn jt nn no dp jx kw np nq kb la nr ns kf le nt nu kj nv bi translated">价值函数</h2><p id="f1ea" class="pw-post-body-paragraph kl km iq kn b ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">发电机的损耗量化了它欺骗鉴别器的能力。直观地说，如果生成器运行良好，鉴别器会将假图像分类为真实图像(或 1)。</p><p id="79b2" class="pw-post-body-paragraph kl km iq kn b ko mq kq kr ks mr ku kv kw mt ky kz la mv lc ld le mx lg lh li ij bi translated">这里，我们将把鉴别器对生成的图像的决定与 1 的数组进行比较。</p><pre class="mz na nb nc gt nx ny nz oa aw ob bi"><span id="ce42" class="nk jo iq ny b gy oc od l oe of">def <strong class="ny ir">generator_loss</strong>(fake_output):<br/> return cross_entropy(tf.ones_like(fake_output), fake_output)</span></pre></div><div class="ab cl om on hu oo" role="separator"><span class="op bw bk oq or os"/><span class="op bw bk oq or os"/><span class="op bw bk oq or"/></div><div class="ij ik il im in"><h2 id="94b6" class="nk jo iq bd jp nl nm dn jt nn no dp jx kw np nq kb la nr ns kf le nt nu kj nv bi translated">【计算机】优化程序</h2><p id="b151" class="pw-post-body-paragraph kl km iq kn b ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">鉴别器和生成器优化器是不同的，因为我们将分别训练两个网络。Adam 优化算法是随机梯度下降的扩展。</p><p id="c5b7" class="pw-post-body-paragraph kl km iq kn b ko mq kq kr ks mr ku kv kw mt ky kz la mv lc ld le mx lg lh li ij bi translated">随机梯度下降为所有权重更新保持单一学习率(称为 alpha ),而学习率在训练期间不变。<br/>为每个网络权重(参数)保持一个学习速率，并随着学习的展开而调整。</p><pre class="mz na nb nc gt nx ny nz oa aw ob bi"><span id="a905" class="nk jo iq ny b gy oc od l oe of">generator_optimizer = tf.keras.optimizers.Adam(1e-4)<br/>discriminator_optimizer = tf.keras.optimizers.Adam(1e-4)</span></pre></div><div class="ab cl om on hu oo" role="separator"><span class="op bw bk oq or os"/><span class="op bw bk oq or os"/><span class="op bw bk oq or"/></div><div class="ij ik il im in"><h1 id="f804" class="jn jo iq bd jp jq ow js jt ju ox jw jx jy oy ka kb kc oz ke kf kg pa ki kj kk bi translated">结果— MNIST</h1><p id="9874" class="pw-post-body-paragraph kl km iq kn b ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">首先，我们在 MNIST 数据集(28 x 28 灰度图像)上使用 3 个反卷积层来训练我们的 DCGAN 模型，这产生了更清晰的渲染，如下所示:</p><figure class="mz na nb nc gt nd"><div class="bz fp l di"><div class="pb pc l"/></div></figure></div><div class="ab cl om on hu oo" role="separator"><span class="op bw bk oq or os"/><span class="op bw bk oq or os"/><span class="op bw bk oq or"/></div><div class="ij ik il im in"><h1 id="9cbc" class="jn jo iq bd jp jq ow js jt ju ox jw jx jy oy ka kb kc oz ke kf kg pa ki kj kk bi translated">结果— CelebA</h1><p id="112c" class="pw-post-body-paragraph kl km iq kn b ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">使用在 CelebA 数据集(25，600 / 202，599 张图像)的子集上训练的具有 4 个 DC 层的 DCGAN 模型，我们能够生成运行 100 个时期的类似人脸的图像。</p><figure class="mz na nb nc gt nd"><div class="bz fp l di"><div class="pd pc l"/></div></figure></div><div class="ab cl om on hu oo" role="separator"><span class="op bw bk oq or os"/><span class="op bw bk oq or os"/><span class="op bw bk oq or"/></div><div class="ij ik il im in"><h1 id="d7b7" class="jn jo iq bd jp jq ow js jt ju ox jw jx jy oy ka kb kc oz ke kf kg pa ki kj kk bi translated">工具/资源</h1><h2 id="d9d6" class="nk jo iq bd jp nl nm dn jt nn no dp jx kw np nq kb la nr ns kf le nt nu kj nv bi translated"><a class="ae lj" href="http://paperspace.com" rel="noopener ugc nofollow" target="_blank">纸张空间</a></h2><ul class=""><li id="b6fd" class="ly lz iq kn b ko kp ks kt kw ma la mb le mc li md me mf mg bi translated">TensorFlow 1.5 — GPU — Py3 — P5000</li><li id="37fe" class="ly lz iq kn b ko mh ks mi kw mj la mk le ml li md me mf mg bi translated">TensorFlow 2.0 — GPU — Py3 — P5000</li><li id="f331" class="ly lz iq kn b ko mh ks mi kw mj la mk le ml li md me mf mg bi translated">tensor flow 2.0—GPU—Py3—Tesla V100</li></ul><h2 id="c369" class="nk jo iq bd jp nl nm dn jt nn no dp jx kw np nq kb la nr ns kf le nt nu kj nv bi translated"><strong class="ak"> MNIST 数据集</strong></h2><ul class=""><li id="1edc" class="ly lz iq kn b ko kp ks kt kw ma la mb le mc li md me mf mg bi translated">60，000 张图片</li><li id="bd40" class="ly lz iq kn b ko mh ks mi kw mj la mk le ml li md me mf mg bi translated">128 x 128</li></ul><h2 id="5a60" class="nk jo iq bd jp nl nm dn jt nn no dp jx kw np nq kb la nr ns kf le nt nu kj nv bi translated">CelebA 数据集</h2><ul class=""><li id="abe5" class="ly lz iq kn b ko kp ks kt kw ma la mb le mc li md me mf mg bi translated">202，599 张图片</li><li id="42bc" class="ly lz iq kn b ko mh ks mi kw mj la mk le ml li md me mf mg bi translated">从 218 x 178 转换为 64 x 64</li></ul></div><div class="ab cl om on hu oo" role="separator"><span class="op bw bk oq or os"/><span class="op bw bk oq or os"/><span class="op bw bk oq or"/></div><div class="ij ik il im in"><h1 id="db97" class="jn jo iq bd jp jq ow js jt ju ox jw jx jy oy ka kb kc oz ke kf kg pa ki kj kk bi translated">挑战</h1><ul class=""><li id="7421" class="ly lz iq kn b ko kp ks kt kw ma la mb le mc li md me mf mg bi translated">了解使用 Tensorflow 创建的 GAN 模型</li><li id="07e8" class="ly lz iq kn b ko mh ks mi kw mj la mk le ml li md me mf mg bi translated">利用 Tensorflow 2.0 开发 DCGAN 模型</li><li id="432f" class="ly lz iq kn b ko mh ks mi kw mj la mk le ml li md me mf mg bi translated">将数据集图像从 218 x 178 调整/裁剪为 64 x 64</li><li id="3618" class="ly lz iq kn b ko mh ks mi kw mj la mk le ml li md me mf mg bi translated">训练新模型时 Jupyter 笔记本出现内存泄漏</li><li id="3fe9" class="ly lz iq kn b ko mh ks mi kw mj la mk le ml li md me mf mg bi translated">与 TensorFlow 1.3 和 2.0 不兼容</li><li id="b2af" class="ly lz iq kn b ko mh ks mi kw mj la mk le ml li md me mf mg bi translated">12 小时后纸张空间自动关闭</li></ul></div><div class="ab cl om on hu oo" role="separator"><span class="op bw bk oq or os"/><span class="op bw bk oq or os"/><span class="op bw bk oq or"/></div><div class="ij ik il im in"><h1 id="1a66" class="jn jo iq bd jp jq ow js jt ju ox jw jx jy oy ka kb kc oz ke kf kg pa ki kj kk bi translated">未来的工作</h1><ul class=""><li id="dd81" class="ly lz iq kn b ko kp ks kt kw ma la mb le mc li md me mf mg bi translated">将模型迁移到可以使用 CelebA 数据集完整计算 100 个历元的环境中</li><li id="21b7" class="ly lz iq kn b ko mh ks mi kw mj la mk le ml li md me mf mg bi translated">调整模型架构以生成更好的图像</li><li id="d5f9" class="ly lz iq kn b ko mh ks mi kw mj la mk le ml li md me mf mg bi translated">开发一种解决方案来更有效地调整图像大小</li></ul><div class="pe pf gp gr pg ph"><a href="https://github.com/skywall34/BabyGan" rel="noopener  ugc nofollow" target="_blank"><div class="pi ab fo"><div class="pj ab pk cl cj pl"><h2 class="bd ir gy z fp pm fr fs pn fu fw ip bi translated">skywall34/BabyGan</h2><div class="po l"><h3 class="bd b gy z fp pm fr fs pn fu fw dk translated">带 DCGAN 的图像发生器。在 GitHub 上创建一个帐户，为 skywall34/BabyGan 开发做贡献。</h3></div><div class="pp l"><p class="bd b dl z fp pm fr fs pn fu fw dk translated">github.com</p></div></div><div class="pq l"><div class="pr l ps pt pu pq pv ne ph"/></div></div></a></div><h1 id="f590" class="jn jo iq bd jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk bi translated">参考</h1><p id="6687" class="pw-post-body-paragraph kl km iq kn b ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">没有互联网的伟大人们，我们不可能完成这个项目。请为您的下一个数据科学项目查阅以下资源:</p><ul class=""><li id="7f9c" class="ly lz iq kn b ko mq ks mr kw ot la ou le ov li md me mf mg bi translated"><strong class="kn ir">深度卷积生成对抗网络的无监督表示学习</strong>——<a class="ae lj" href="https://arxiv.org/abs/1511.06434" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/abs/1511.06434</a></li><li id="c0f4" class="ly lz iq kn b ko mh ks mi kw mj la mk le ml li md me mf mg bi translated"><strong class="kn ir">使用生成模型的压缩感知</strong>——【https://arxiv.org/pdf/1703.03208.pdf T2】</li><li id="5bed" class="ly lz iq kn b ko mh ks mi kw mj la mk le ml li md me mf mg bi translated">在 TensorFlow 中使用深度学习的<strong class="kn ir">图像完成</strong>—<a class="ae lj" href="http://bamos.github.io/2016/08/09/deep-completion/" rel="noopener ugc nofollow" target="_blank">http://bamos.github.io/2016/08/09/deep-completion/</a></li></ul></div></div>    
</body>
</html>