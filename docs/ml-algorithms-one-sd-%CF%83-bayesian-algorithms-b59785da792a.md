# ML 算法:一种 SD (σ)-贝叶斯算法

> 原文：<https://towardsdatascience.com/ml-algorithms-one-sd-%CF%83-bayesian-algorithms-b59785da792a?source=collection_archive---------13----------------------->

## 机器学习贝叶斯算法介绍

![](img/20c0403ae2c82ad7c613c722c6946cf3.png)

当面对各种各样的机器学习算法时，要问的明显问题是“哪种算法更适合特定的任务，我应该使用哪种算法？”

> *回答这些问题取决于几个因素，包括:(1)数据的大小、质量和性质；(2)可用的计算时间；(3)任务的紧迫性；以及(4)你想用这些数据做什么。*

这是我在之前的[文章](/ml-algorithms-one-sd-σ-74bcb28fafb6)中写的许多算法中的一部分。在这一部分中，我试图尽可能简单地展示和简要解释可用于贝叶斯任务的主要算法(尽管不是全部)。

# **贝叶斯算法:**

> 一个算法家族，其中所有算法都有一个共同的原则，即每对被分类的特征都是相互独立的。朴素贝叶斯分类器是一组基于贝叶斯定理的分类算法。贝叶斯公式提供了 P(A|B)和 P(B|A)之间的关系

![](img/587981170d9673a873878bbe1fd2f614.png)

**朴素贝叶斯**

![](img/7a8d660b1a14ecd977c2fe1f74e8dd77.png)

朴素贝叶斯算法假设它使用的每个特征在给定某个类的情况下有条件地相互独立。它提供了一种从 P(c)，P(x)和 P(x|c)计算后验概率 P(c|x)的方法。例如，假设你有几封邮件已经被归类为垃圾邮件。现在假设您想将一封新邮件分类为垃圾邮件或垃圾邮件。朴素贝叶斯认为这个问题是“给定包含特定单词的新电子邮件是垃圾邮件/垃圾邮件的概率是多少”(例如，包含单词“伟哥”的电子邮件被分类为垃圾邮件/垃圾邮件的概率)。

*需要考虑的一些事情:*

适用于非常大的数据集-您可以对小数据集使用朴素贝叶斯分类算法，但精度和召回率会非常低

由于算法有一个独立性的假设，你确实失去了利用特征之间的相互作用的能力。

**高斯朴素贝叶斯**

![](img/64fcb915f1881f2e83313d3838083c4e.png)

一般术语朴素贝叶斯指的是模型中的独立性假设，而不是每个特征的特定分布。到目前为止，我们还没有提到每个特征的分布，但是在高斯朴素贝叶斯中，我们假设概率的分布是高斯的(正态)。由于正态分布的假设，高斯朴素贝叶斯用于我们所有特征都是连续的情况。例如，如果我们考虑虹膜数据集，特征是萼片宽度、花瓣宽度等。它们在数据集中可以有不同的值，如宽度和长度，因此我们不能根据它们的出现次数来表示它们，我们需要在这里使用高斯朴素贝叶斯。

*需要考虑的一些事情:*

它假设要素的分布是正态的

当我们所有的特征都是连续的时，通常使用它

**多项式朴素贝叶斯**

![](img/ac3e2e34f6e69cd9461ab8e4e63b9380.png)

术语多项式朴素贝叶斯简单地告诉我们每个特征都有一个多项式分布。当我们有离散数据时使用它(例如，电影分级从 1 到 5，因为每个分级都有一定的频率来表示)。在文本学习中，我们有每个单词的计数来预测类别或标签。该算法主要用于文档分类问题(文档是否属于体育、政治、科技等类别)。).分类器使用的特征/预测值是文档中出现的单词的频率。

*需要考虑的一些事情:*

用于离散数据

适用于容易转换为计数的数据，例如文本中的字数。

**平均单相关估计量(AODE)**

![](img/3e5a84e05bfd8980e9076556d4c51aa9.png)

AODE 是一种半朴素贝叶斯学习方法。它是为了解决流行的朴素贝叶斯分类器的属性独立性问题而开发的。它通过对所有模型进行平均来实现，在所有模型中，所有属性都依赖于该类和一个单独的其他属性。它经常以少量增加计算量为代价开发比朴素贝叶斯更精确的分类器。

*需要考虑的一些事情:*

将它用于名义数据在计算上比常规的朴素贝叶斯更有效，并且实现了非常低的错误率。

**贝叶斯信念网络(BBN)**

![](img/a4afeb9fb1b7b9f53dcd2ece2f218eea.png)

一种概率图形模型，通过有向非循环图表示一组变量及其条件依赖关系。例如，贝叶斯网络可以表示疾病和症状之间的概率关系。在给定症状的情况下，该网络可用于计算各种疾病出现的概率(另一个例子见上图)。BBN 是一种特殊类型的图表(称为有向图)以及一组相关的概率表。另一个例子是扔硬币。硬币可以有两个值——正面或反面，各有 50%的概率。我们把这些概率称为“信念”(即我们认为国家硬币=头像是 50%)。

*需要考虑的一些事情:*

BBNs 使我们能够对不确定性进行建模和推理

BBNs 最重要的用途是根据对事件的实际观察修正概率

可用于了解导致某个问题的原因，或者在计算生物学和医学等领域的风险分析和决策支持中，给定一个操作产生不同影响的概率。

**贝叶斯网络**

![](img/e116aee989467a6f775fb13b906bae5f.png)

贝叶斯网络是一种概率图形模型(概率性的，因为它们是根据概率分布构建的)。这些网络可用于预测、异常检测、诊断、自动洞察、推理、时间序列预测和不确定情况下的决策。这些网络的目标是模拟条件依赖，因此也是因果关系。例如:如果你在屋外，开始下雨，你的狗很可能会开始叫。这反过来会增加猫藏在沙发下的可能性。所以你可以看到关于一个事件(雨)的信息是如何让你对一个看似不相关的事件(藏在沙发下的猫)做出推断的。

*需要考虑的一些事情:*

你可以用它们来预测未来

有助于解释观察结果

贝叶斯网络非常便于表示多个事件之间的相似概率关系。

**隐马尔可夫模型(HMM)**

![](img/1fdee3f4801bf44c55868a3b1756aa01.png)

HMM 是一类概率图形模型，它允许我们从一组观察变量中预测一系列未知(隐藏)变量。比如根据某人穿的衣服类型(观察到的)来预测天气(隐藏变量)。这可以是泳衣、雨伞等。这些基本都是证据。

已知 HMM 用于强化学习和时间模式识别，例如手写、语音、词性标注、手势识别和生物信息学。

HMM 回答这样的问题:给定一个模型，序列 S 发生的可能性有多大？给定序列 S 和隐藏状态数，使 S 的概率最大化的最佳模型是什么？

*需要考虑的一些事情:*

隐马尔可夫模型适用于基于特征序列进行识别的应用。

hmm 可用于建模由以确定的(或典型的)顺序发生的不同阶段组成的过程。

HMM 需要在一组种子序列上训练，并且通常需要比简单马尔可夫模型更大的种子。

**条件随机字段**

![](img/8f1e7939e1272bf86d024e2ba02e9283.png)

训练序列模型的经典 ML 模型。它是一种区分分类器，模拟不同类别之间的决策边界。判别模型和生成模型之间的区别在于，判别模型试图模拟条件概率分布，即 P(y|x)，而生成模型试图模拟联合概率分布，即 P(x，y)。他们的基本原则是，他们对连续输入应用逻辑回归。隐马尔可夫模型与 CRF 有一些相似之处，其中之一是它们也用于顺序输入。CRF 最常用于 NLP 任务。

假设你有朋友生活中某一天的一系列快照。你的目标是给每张图片贴上它所代表的活动的标签(吃饭、睡觉、开车等等。).一种方法是忽略快照具有顺序性质的事实，并建立每个图像的分类器。例如，您可以了解到在凌晨 5 点拍摄的黑暗图像通常与睡眠有关，而带有食物的图像往往与吃有关，等等。然而，由于忽略了顺序方面，我们丢失了很多信息。举个例子，如果你看到一张嘴的特写照片会发生什么——是关于说话还是吃东西？如果你知道之前的快照是你朋友吃东西的照片，那么这张照片更有可能是关于吃东西的。因此，为了增加我们的标签器的准确性，我们应该考虑附近照片的标签，而这正是条件随机场所做的。

![](img/7b873792810c5461d3ac79ecab0758ad.png)

*需要考虑的一些事情:*

CRF 预测对应于输入序列的最可能的标签序列

与 HMM 相比，由于 CRF 没有 HMM 那样严格的独立性假设，所以它可以适应任何上下文信息。

CRF 也避免了标签偏差问题。

在算法的训练阶段，CRF 在计算上非常复杂。当有新数据可用时，很难重新训练模型。

> 如果你对我的更多作品感兴趣，你可以看看我的 [Github](https://github.com/shaier) ，我的[学者页面](https://scholar.google.com/citations?user=paO-O00AAAAJ&hl=en&oi=sra)，或者我的[网站](https://shaier.github.io/)