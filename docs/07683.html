<html>
<head>
<title>Big, fast human-in-the-loop NLP with Elasticsearch</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">具有弹性搜索的大型快速人在回路 NLP</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/big-fast-nlp-with-elasticsearch-72ffd7ef8f2e?source=collection_archive---------2-----------------------#2019-10-25">https://towardsdatascience.com/big-fast-nlp-with-elasticsearch-72ffd7ef8f2e?source=collection_archive---------2-----------------------#2019-10-25</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><blockquote class="jn jo jp"><p id="d800" class="jq jr js jt b ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko ij bi translated"><strong class="jt ir">第一部分:关键词工厂</strong>TL；dr:如果你 1)在 Elasticsearch 中存储你的数据 2)使用<code class="fe kq kr ks kt b"><a class="ae kp" href="https://github.com/nestauk/clio-lite#keywords-getting-under-the-hood" rel="noopener ugc nofollow" target="_blank">clio-lite</a></code>包中的<code class="fe kq kr ks kt b">clio_keywords</code>函数，指向你的 Elasticsearch 端点 3)在 Flask 应用中托管它，<a class="ae kp" href="https://github.com/nestauk/arxlive/blob/b76fda906901d1f3afab1cdb9b24cddfb717d9d2/arxlive/views.py#L10" rel="noopener ugc nofollow" target="_blank">比如这个</a>。</p><p id="ca90" class="jq jr js jt b ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko ij bi translated"><strong class="jt ir">第二部分:上下文搜索引擎</strong>TL；dr:如果你 1)将你的数据存储在 Elasticsearch 中 2)使用<code class="fe kq kr ks kt b"><a class="ae kp" href="https://github.com/nestauk/clio-lite" rel="noopener ugc nofollow" target="_blank"><em class="iq">clio-lite</em></a></code>托管一个 lambda API 网关 3)用你自己的前端询问它，或者使用像<a class="ae kp" href="http://www.searchkit.co/" rel="noopener ugc nofollow" target="_blank"> searchkit </a>这样的开箱即用的东西，你可以使<a class="ae kp" href="https://arxlive.org/hierarxy" rel="noopener ugc nofollow" target="_blank">成为其中之一</a></p></blockquote><p id="b777" class="pw-post-body-paragraph jq jr iq jt b ju jv jw jx jy jz ka kb ku kd ke kf kv kh ki kj kw kl km kn ko ij bi translated">许多 NLP 数据科学家目前的日常工作范式是打开笔记本电脑，启动 Python 或 R，制作一些模型，总结一些结论。这对于探索性分析来说非常有效，但是如果你需要把一个人(比如一个专家，你的老板，甚至你自己)放入循环中，这可能会变得非常慢。在这篇由两部分组成的博客中，我将试图让你相信有更大、更快的方法来实现 NLP。</p><figure class="ky kz la lb gt lc gh gi paragraph-image"><div role="button" tabindex="0" class="ld le di lf bf lg"><div class="gh gi kx"><img src="../Images/813802a4e6db0c9c4ae30163407c1f0a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*4O5p4h88t1td3AAid3M7UQ.png"/></div></div><figcaption class="lj lk gj gh gi ll lm bd b be z dk">Big fast human-in-the-loop NLP (Photo by <a class="ae kp" href="https://unsplash.com/@shateley?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank">Stephen Hateley</a> on <a class="ae kp" href="https://unsplash.com/s/photos/rollercoaster?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank">Unsplash</a>)</figcaption></figure><h1 id="2032" class="ln lo iq bd lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk bi translated">人在回路 NLP 和我</h1><p id="fb31" class="pw-post-body-paragraph jq jr iq jt b ju ml jw jx jy mm ka kb ku mn ke kf kv mo ki kj kw mp km kn ko ij bi translated">在我<a class="ae kp" href="https://www.nesta.org.uk/team/joel-klinger/" rel="noopener ugc nofollow" target="_blank">Nesta</a><a class="ae kp" href="https://www.nesta.org.uk/" rel="noopener ugc nofollow" target="_blank">的日常工作</a>中，我开发工具和基础设施，让人们能够做出更好的决策，让人们能够利用最新的数据做出这些决策。我们为地方、国家和国际决策者和资助者提供工具，他们依赖于与科学、技术和社会的最新创新保持同步。由于这些人对他们的决定负责，这通常排除了采用黑盒程序的工具。“人在回路中的自然语言处理”是我们解决这些需求的方式，尤其是因为非结构化文本数据是最丰富、最可用和最新的数据形式之一。</p><h1 id="e211" class="ln lo iq bd lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk bi translated">弹性搜索</h1><p id="7524" class="pw-post-body-paragraph jq jr iq jt b ju ml jw jx jy mm ka kb ku mn ke kf kv mo ki kj kw mp km kn ko ij bi translated">数据工程师、数据库管理员和 devops 工程师都应该熟悉“elastic stack”(elastic search 是其核心)，它是存储和分析日志文件或构建搜索引擎的首选技术，尽管他们中的许多人可能不太了解数据科学研究的巨大潜力。与此同时，许多数据科学家充其量对作为数据存储技术的 Elasticsearch 有一个基本的了解。</p><p id="ece7" class="pw-post-body-paragraph jq jr iq jt b ju jv jw jx jy jz ka kb ku kd ke kf kv kh ki kj kw kl km kn ko ij bi translated"><strong class="jt ir">简而言之</strong> : Elasticsearch 是一个搜索引擎的数据库，因为<strong class="jt ir"> <em class="js">数据的存储方式</em> </strong>而能够进行闪电般的搜索。</p><p id="d92f" class="pw-post-body-paragraph jq jr iq jt b ju jv jw jx jy jz ka kb ku kd ke kf kv kh ki kj kw kl km kn ko ij bi translated">在 Elasticsearch 中，文档被存储为<strong class="jt ir">词频向量</strong>(一个被称为“倒排索引”的过程)，并且<strong class="jt ir">文档频率</strong>是为每个词预先计算的。这意味着几件事:</p><ol class=""><li id="a81b" class="mq mr iq jt b ju jv jy jz ku ms kv mt kw mu ko mv mw mx my bi translated">一个术语接一个术语的同现以令人难以置信的速度快速从<strong class="jt ir">中提取</strong><em class="js"/>。</li><li id="f938" class="mq mr iq jt b ju mz jy na ku nb kv nc kw nd ko mv mw mx my bi translated">重要术语可通过标准数据科学‘TF-IDF’程序<em class="js">即时识别</em>。</li></ol><p id="f26b" class="pw-post-body-paragraph jq jr iq jt b ju jv jw jx jy jz ka kb ku kd ke kf kv kh ki kj kw kl km kn ko ij bi translated">从数据科学家的角度来看，Elasticsearch 数据库是一个非常基本(但功能强大)的预训练模型，用于提取关键字、同义词、相似文档和离群值。在这个由两部分组成的博客中，我将使用开箱即用的功能来触及所有这些内容(尽管当然也可以采用更复杂的方法)。</p><h1 id="8ee8" class="ln lo iq bd lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk bi translated">第一部分:关键词工厂</h1><h2 id="2e3e" class="ne lo iq bd lp nf ng dn lt nh ni dp lx ku nj nk mb kv nl nm mf kw nn no mj np bi translated">最简单的情况:允许非专家识别他们自己的关键字和同义词</h2><p id="cae3" class="pw-post-body-paragraph jq jr iq jt b ju ml jw jx jy mm ka kb ku mn ke kf kv mo ki kj kw mp km kn ko ij bi translated">生成关键字(或同义词)列表是数据科学家的一项常见 NLP 任务。它可以有从维度减少到主题建模的应用，并且还可以通过向人类分析师提供可以用于更费力的任务的一组数据驱动的术语来用于人在回路中的分析。</p><p id="e63f" class="pw-post-body-paragraph jq jr iq jt b ju jv jw jx jy jz ka kb ku kd ke kf kv kh ki kj kw kl km kn ko ij bi translated">许多数据科学家会使用适当的 python(或 R)包来处理这个问题，以便产生相当静态的输出，这对于报告或论文来说是很好的。大多数时候，我们都希望我们的结果能够被非专家访问，但是实际上，人们最终得到的是他们所得到的:静态输出。我们有哪些可供非专家使用的可扩展且灵活的工具？</p><h2 id="62b3" class="ne lo iq bd lp nf ng dn lt nh ni dp lx ku nj nk mb kv nl nm mf kw nn no mj np bi translated">Python(或 R)包:错误工作的正确工具</h2><p id="0b4d" class="pw-post-body-paragraph jq jr iq jt b ju ml jw jx jy mm ka kb ku mn ke kf kv mo ki kj kw mp km kn ko ij bi translated">有大量基于 python 的方法可以解决这个问题，如主题建模(如潜在的狄利克雷分配或相关性解释)、单词向量聚类(如单词嵌入或香草计数向量)或使用共现矩阵或网络。</p><p id="2df8" class="pw-post-body-paragraph jq jr iq jt b ju jv jw jx jy jz ka kb ku kd ke kf kv kh ki kj kw kl km kn ko ij bi translated">所有这些方法都可以给出非常合理的结果，老实说，我并不想在感知准确性上击败这些方法。如果我的任务是进行一次性的特别分析，我可以考虑以上任何一种方法。</p><p id="6d9c" class="pw-post-body-paragraph jq jr iq jt b ju jv jw jx jy jz ka kb ku kd ke kf kv kh ki kj kw kl km kn ko ij bi translated">然而，我喜欢可扩展、可共享和灵活的问题解决方案:</p><ul class=""><li id="ca9b" class="mq mr iq jt b ju jv jy jz ku ms kv mt kw mu ko nq mw mx my bi translated"><strong class="jt ir">可伸缩性</strong>:我建议的所有 python 解决方案都要求数据和模型驻留在内存中。对于大量的文档或大量的词汇，内存消耗会很大。对此的一个解决方案是以牺牲模型的“深度”为代价对数据进行采样。</li><li id="f0f2" class="mq mr iq jt b ju mz jy na ku nb kv nc kw nd ko nq mw mx my bi translated">可共享性:如果你没有在非专家的笔记本电脑上安装 python 包，同时又希望你的设置与他们的笔记本电脑兼容，你如何与他们共享结果？两种可能是在远程服务器上托管你的机器学习模型(可以是从集群模型到共生矩阵的任何东西)(但是要小心那巨大的内存开销！)，或者您可以预先生成静态的关键字集(这非常简单)。</li><li id="e9e0" class="mq mr iq jt b ju mz jy na ku nb kv nc kw nd ko nq mw mx my bi translated"><strong class="jt ir">灵活性:</strong>想象一下，你想用多一个文档来更新你的模型，或者决定就地过滤你的数据——用常规的机器学习模型来做这件事并不简单。您的最佳方法可能是为每个预定义的过滤器预生成一个模型，这在计算上是昂贵的。</li></ul><h2 id="e9ba" class="ne lo iq bd lp nf ng dn lt nh ni dp lx ku nj nk mb kv nl nm mf kw nn no mj np bi translated">弹性搜索:适合工作的合适工具</h2><p id="d5fe" class="pw-post-body-paragraph jq jr iq jt b ju ml jw jx jy mm ka kb ku mn ke kf kv mo ki kj kw mp km kn ko ij bi translated">请记住，Elasticsearch 实际上是一个预先训练好的词共现模型，可以根据词的重要性进行过滤，这就很清楚为什么它可以动态地生成关键字列表。此外，我们应用于 Elasticsearch 的任何方法都具有内在的可扩展性、可共享性和灵活性:</p><ul class=""><li id="f174" class="mq mr iq jt b ju jv jy jz ku ms kv mt kw mu ko nq mw mx my bi translated"><strong class="jt ir">可伸缩性</strong> : Elasticsearch 的性能高达 Pb 级。</li><li id="fe78" class="mq mr iq jt b ju mz jy na ku nb kv nc kw nd ko nq mw mx my bi translated"><strong class="jt ir">可共享性</strong> : Elasticsearch 通过一个简单的 REST API 公开数据上的方法。要完成复杂的任务，您可以简单地将一些托管在远程服务器上的轻量级 python 代码串在一起。</li><li id="30e2" class="mq mr iq jt b ju mz jy na ku nb kv nc kw nd ko nq mw mx my bi translated"><strong class="jt ir">灵活性</strong>:更新您的“模型”就像向服务器添加新文档一样简单。按任何字段过滤数据都是一项基本操作。</li></ul><h2 id="6be3" class="ne lo iq bd lp nf ng dn lt nh ni dp lx ku nj nk mb kv nl nm mf kw nn no mj np bi translated">“重要文本”集合</h2><p id="7e00" class="pw-post-body-paragraph jq jr iq jt b ju ml jw jx jy mm ka kb ku mn ke kf kv mo ki kj kw mp km kn ko ij bi translated">原则上，我们可以从零开始实现我们自己的提取关键词的程序，但是有一些快捷方式，你可以通过使用 Elasticsearch 的开箱即用功能来使用。</p><p id="e907" class="pw-post-body-paragraph jq jr iq jt b ju jv jw jx jy jz ka kb ku kd ke kf kv kh ki kj kw kl km kn ko ij bi translated">下面的 python 代码包装了一个对 Elasticsearch API 的查询(用您自己的端点替换<code class="fe kq kr ks kt b">URL</code>,用您想要查询的数据库中的字段名称替换<code class="fe kq kr ks kt b">FIELD_NAME</code>):</p><pre class="ky kz la lb gt nr kt ns nt aw nu bi"><span id="7003" class="ne lo iq kt b gy nv nw l nx ny">import requests<br/>import json<br/><br/>def make_query(url, q, alg, field, shard_size=1000, size=25):<br/>    """See <a class="ae kp" href="https://gist.github.com/jaklinger/6a644956f32e3e8b0d5e41c543ee49e1" rel="noopener ugc nofollow" target="_blank">this gist</a> for docs"""<br/>    query = {"query" : { "match" : {field : q } },<br/>             "size": 0,<br/>             "aggregations" : {<br/>                 "my_sample" : {<br/>                     "sampler" : {"shard_size" : shard_size},<br/>                     "aggregations": {<br/>                        "keywords" : {<br/>                            "significant_text" : {<br/>                                "size": size,<br/>                                "field" : field,<br/>                                alg:{}<br/>                             }<br/>                        }<br/>                    }<br/>                }<br/>            }<br/>        }<br/>    return [row['key'] <br/>            for row in requests.post(f'{url}/_search',<br/>                                     data=json.dumps(query),<br/>                                     headers={'Content-Type':'application/json'}).json()['aggregations']['my_sample']['keywords']['buckets']]</span></pre><p id="68af" class="pw-post-body-paragraph jq jr iq jt b ju jv jw jx jy jz ka kb ku kd ke kf kv kh ki kj kw kl km kn ko ij bi translated">在幕后，该查询执行以下操作:</p><ol class=""><li id="3f6f" class="mq mr iq jt b ju jv jy jz ku ms kv mt kw mu ko mv mw mx my bi translated">在字段<code class="fe kq kr ks kt b">field</code>中查找包含文本<code class="fe kq kr ks kt b">query</code>的所有文档。</li><li id="0e3c" class="mq mr iq jt b ju mz jy na ku nb kv nc kw nd ko mv mw mx my bi translated">从<code class="fe kq kr ks kt b">field</code>中提取<code class="fe kq kr ks kt b">size</code>最高有效项，根据<code class="fe kq kr ks kt b">jlh</code>算法计算。</li></ol><p id="a9a8" class="pw-post-body-paragraph jq jr iq jt b ju jv jw jx jy jz ka kb ku kd ke kf kv kh ki kj kw kl km kn ko ij bi translated">最重要的是，增加<code class="fe kq kr ks kt b">shard_size</code>的大小将增加你的“模型”的稳定性(和深度),代价是计算性能。实际上，您只会期望您的模型在极少数情况下变得不太稳定——在这种情况下，您可以构建一个解决方法。</p><h2 id="04f2" class="ne lo iq bd lp nf ng dn lt nh ni dp lx ku nj nk mb kv nl nm mf kw nn no mj np bi translated">tweeks 之前的性能:arXiv 数据</h2><p id="cdb7" class="pw-post-body-paragraph jq jr iq jt b ju ml jw jx jy mm ka kb ku mn ke kf kv mo ki kj kw mp km kn ko ij bi translated">我的 Elasticsearch 数据库中有 arXiv 的所有科学出版物，下面是它对以下查询的抽象文本的表现:</p><pre class="ky kz la lb gt nr kt ns nt aw nu bi"><span id="28f4" class="ne lo iq kt b gy nv nw l nx ny">python pandas</span><span id="c437" class="ne lo iq kt b gy nz nw l nx ny">['pandas', 'numpy', 'package', 'scipy', 'scikit', 'library', 'pypi', 'cython', 'github']</span><span id="cabe" class="ne lo iq kt b gy nz nw l nx ny">-----------------------------</span><span id="8ba9" class="ne lo iq kt b gy nz nw l nx ny">elasticsearch</span><span id="6ae0" class="ne lo iq kt b gy nz nw l nx ny">['kibana', 'lucene', 'hadoop', 'retrieving', 'apache', 'engine', 'textual', 'documents', 'ranking']</span><span id="adb2" class="ne lo iq kt b gy nz nw l nx ny">-----------------------------</span><span id="8450" class="ne lo iq kt b gy nz nw l nx ny">machine learning</span><span id="54d8" class="ne lo iq kt b gy nz nw l nx ny">['learning', 'training', 'algorithms', 'neural', 'supervised', 'automl', 'intelligence', 'deep', 'tasks']</span><span id="61e2" class="ne lo iq kt b gy nz nw l nx ny">----------------------------------------------------------</span><span id="bb7a" class="ne lo iq kt b gy nz nw l nx ny">drones and robots</span><span id="0756" class="ne lo iq kt b gy nz nw l nx ny">['robot', 'drones', 'robotics', 'robotic', 'humanoid', "robot's", 'drone', 'autonomous', 'mobile']</span><span id="a3f4" class="ne lo iq kt b gy nz nw l nx ny">-----------------------------</span></pre><p id="0a90" class="pw-post-body-paragraph jq jr iq jt b ju jv jw jx jy jz ka kb ku kd ke kf kv kh ki kj kw kl km kn ko ij bi translated">…这是开箱即用的功能！一些简单的批评是:</p><ol class=""><li id="ac1f" class="mq mr iq jt b ju jv jy jz ku ms kv mt kw mu ko mv mw mx my bi translated">无论是在查询中还是在结果中，n 元语法都没有被利用。例如，<code class="fe kq kr ks kt b">machine learning</code>被视为<code class="fe kq kr ks kt b">{machine, learning}</code>，而不是<code class="fe kq kr ks kt b">{machine learning, machine, learning}</code>。</li><li id="96d6" class="mq mr iq jt b ju mz jy na ku nb kv nc kw nd ko mv mw mx my bi translated">搜索结果中出现停用词并非不可能。</li><li id="f298" class="mq mr iq jt b ju mz jy na ku nb kv nc kw nd ko mv mw mx my bi translated">样本外的拼写错误根本不会被处理。</li><li id="49bf" class="mq mr iq jt b ju mz jy na ku nb kv nc kw nd ko mv mw mx my bi translated">名词的复数和所有格形式以及所有动词的变化都单独列出。</li></ol><p id="b63a" class="pw-post-body-paragraph jq jr iq jt b ju jv jw jx jy jz ka kb ku kd ke kf kv kh ki kj kw kl km kn ko ij bi translated">我不打算在这里解决后两点，但是处理它们是相当琐碎的。例如，<strong class="jt ir">拼写错误</strong>至少可以用两种方式处理，例如使用:</p><ul class=""><li id="71a9" class="mq mr iq jt b ju jv jy jz ku ms kv mt kw mu ko nq mw mx my bi translated"><a class="ae kp" href="https://www.elastic.co/guide/en/elasticsearch/reference/current/analysis-ngram-tokenizer.html" rel="noopener ugc nofollow" target="_blank"> Elasticsearch 的 n-gram 标记器</a>(注意，Elasticsearch 在字符级定义 n-gram，不要与数据科学家的术语级 n-gram 混淆)</li><li id="f134" class="mq mr iq jt b ju mz jy na ku nb kv nc kw nd ko nq mw mx my bi translated">或者使用<a class="ae kp" href="https://www.elastic.co/guide/en/elasticsearch/plugins/7.3/analysis-phonetic.html" rel="noopener ugc nofollow" target="_blank">注音符号化插件</a>。</li></ul><p id="5b9e" class="pw-post-body-paragraph jq jr iq jt b ju jv jw jx jy jz ka kb ku kd ke kf kv kh ki kj kw kl km kn ko ij bi translated"><strong class="jt ir">为了处理 n-gram 查询</strong>(比如<code class="fe kq kr ks kt b">machine learning</code>)我在我的 Elasticsearch 数据库中创建了一个包含预标记摘要的字段，在其中我已经识别了 n-gram。请注意，该字段的“模式”可在此处找到<a class="ae kp" href="https://github.com/nestauk/nesta/blob/arxiv-ngrams/nesta/core/orms/arxiv_es_config.json#L93" rel="noopener ugc nofollow" target="_blank">。如果你想知道，我通过使用基于 wiki tionary</a>的<a class="ae kp" href="https://github.com/nestauk/nesta/blob/dev/nesta/packages/nlp_utils/ngrammer.py" rel="noopener ugc nofollow" target="_blank"> n-grams 的查找表来处理我的 n-grams(但是更数据驱动的方法也可以)。</a></p><p id="a4e9" class="pw-post-body-paragraph jq jr iq jt b ju jv jw jx jy jz ka kb ku kd ke kf kv kh ki kj kw kl km kn ko ij bi translated">虽然我自己没有实现这一点，但是可以对<strong class="jt ir">复数/所有格/变形</strong>进行类似的预处理，有效地将所有非简单形式的术语替换为它们的简单形式。</p><p id="d28f" class="pw-post-body-paragraph jq jr iq jt b ju jv jw jx jy jz ka kb ku kd ke kf kv kh ki kj kw kl km kn ko ij bi translated">最后，为了避免<strong class="jt ir">返回停用词</strong>的潜在尴尬，我使用我的<code class="fe kq kr ks kt b">make_query</code>函数从数据中生成它们:</p><pre class="ky kz la lb gt nr kt ns nt aw nu bi"><span id="49ee" class="ne lo iq kt b gy nv nw l nx ny">and of but yes with however</span><span id="63ba" class="ne lo iq kt b gy nz nw l nx ny">[‘however’, ‘but’, ‘not’, ‘answer’, ‘with’, ‘the’, ‘is’, ‘of’, ‘to’, ‘a’, ‘in’, ‘and’, ‘that’, ‘no’, ‘this’, ‘we’, ‘only’, ‘for’, ‘are’, ‘be’, ‘it’, ‘can’, ‘by’, ‘on’, ‘an’, ‘question’, ‘also’, ‘have’, ‘has’, ‘which’, ‘there’, ‘as’, ‘or’, ‘such’, ‘if’, ‘whether’, ‘does’, ‘more’, ‘from’, ‘one’, ‘been’, ‘these’, ‘show’, ‘at’, ‘do’]</span></pre><p id="39c0" class="pw-post-body-paragraph jq jr iq jt b ju jv jw jx jy jz ka kb ku kd ke kf kv kh ki kj kw kl km kn ko ij bi translated">我只是将这些从返回的结果中排除。</p><h2 id="a910" class="ne lo iq bd lp nf ng dn lt nh ni dp lx ku nj nk mb kv nl nm mf kw nn no mj np bi translated">把所有的放在一起</h2><p id="641d" class="pw-post-body-paragraph jq jr iq jt b ju ml jw jx jy mm ka kb ku mn ke kf kv mo ki kj kw mp km kn ko ij bi translated">在 arXlive 网站上查看正在运行的<a class="ae kp" href="https://arxlive.org/keywords" rel="noopener ugc nofollow" target="_blank">关键字工厂，其特色是 n-grams 和停用词移除。你可以使用<code class="fe kq kr ks kt b"><a class="ae kp" href="https://github.com/nestauk/clio-lite#keywords-getting-under-the-hood" rel="noopener ugc nofollow" target="_blank">clio-lite</a></code>包中的<code class="fe kq kr ks kt b">clio_keywords</code>函数制作自己的 Flask 应用程序。玩得开心！</a></p><h1 id="433e" class="ln lo iq bd lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk bi translated">第二部分:上下文搜索引擎</h1><p id="6e0d" class="pw-post-body-paragraph jq jr iq jt b ju ml jw jx jy mm ka kb ku mn ke kf kv mo ki kj kw mp km kn ko ij bi translated">考虑一个技术性很强的数据集，比如来自全球最大的物理、定量和计算科学预印本库<a class="ae kp" href="https://arxiv.org/search/" rel="noopener ugc nofollow" target="_blank"> arXiv </a>的数据集。假设您不是博学的学者，您会采取什么策略来查找与<strong class="jt ir"> <em class="js">大数据和安全</em> </strong>相关的 arXiv 最新研究？如果你在 arXiv 上<a class="ae kp" href="https://arxiv.org/search/?query=big+data+security&amp;searchtype=all&amp;abstracts=show&amp;order=-announced_date_first&amp;size=50" rel="noopener ugc nofollow" target="_blank">进行精确的搜索，你会发现自己有一组不错的结果，但问题是，当你搜索<strong class="jt ir"> <em class="js">大数据</em> </strong>时，你可能没有意识到你还想在查询中包括一些不太相关的术语，如<em class="js"> {hadoop、spark、云计算} </em>。如果在<strong class="jt ir"> <em class="js">云计算和安全</em> </strong>领域有一些你一直错过的重大突破，会怎么样？(TL；博士</a><a class="ae kp" href="https://arxlive.org/hierarxy/?q=big%20data%20security&amp;metric_novelty_article[min]=113&amp;metric_novelty_article[max]=250" rel="noopener ugc nofollow" target="_blank"> <strong class="jt ir"> <em class="js">这是相同的搜索与一个‘上下文’搜索引擎</em> </strong> </a>)</p><p id="80ef" class="pw-post-body-paragraph jq jr iq jt b ju jv jw jx jy jz ka kb ku kd ke kf kv kh ki kj kw kl km kn ko ij bi translated">我将把这个问题分成两部分，通过使用 Python 中的一些 Elasticsearch 功能来解决它:</p><ul class=""><li id="2565" class="mq mr iq jt b ju jv jy jz ku ms kv mt kw mu ko nq mw mx my bi translated">首先，你如何在不是天才的情况下做出一个像样的搜索查询？</li><li id="c3c1" class="mq mr iq jt b ju mz jy na ku nb kv nc kw nd ko nq mw mx my bi translated">其次，如何定义新奇？</li></ul><h2 id="c1d1" class="ne lo iq bd lp nf ng dn lt nh ni dp lx ku nj nk mb kv nl nm mf kw nn no mj np bi translated">做一个像样的查询，而不是一个天才</h2><p id="998f" class="pw-post-body-paragraph jq jr iq jt b ju ml jw jx jy mm ka kb ku mn ke kf kv mo ki kj kw mp km kn ko ij bi translated">回到制作一个像样的搜索查询的问题。天才可能会采取哪些方法？嗯，他们可以沿着'<strong class="jt ir">关键词扩展</strong>的路线走下去，例如通过考虑所有的<em class="js"> {hadoop、spark、云计算} </em>以及<strong class="jt ir"> <em class="js">大数据</em> </strong>，以及所有的<em class="js">{攻击、加密、认证} </em>以及<strong class="jt ir"> <em class="js">安全</em> </strong> <em class="js">。</em>这可能是一条很有前途的道路，我们已经在之前的博客中编写了工具来帮助实现这一点。然而，“关键字扩展”方法的主要问题是它缺少<strong class="jt ir"> <em class="js">上下文</em> </strong>。对此的一个自然扩展是'<strong class="jt ir">文档扩展</strong>'，谢天谢地，Elasticsearch 内置了这个特性。</p><h2 id="0c22" class="ne lo iq bd lp nf ng dn lt nh ni dp lx ku nj nk mb kv nl nm mf kw nn no mj np bi translated">更像这样</h2><p id="1ad4" class="pw-post-body-paragraph jq jr iq jt b ju ml jw jx jy mm ka kb ku mn ke kf kv mo ki kj kw mp km kn ko ij bi translated">好吧，老实说，Elasticsearch 的<a class="ae kp" href="https://www.elastic.co/guide/en/elasticsearch/reference/current/query-dsl-mlt-query.html" rel="noopener ugc nofollow" target="_blank"> <em class="js">更像是——这个</em> </a>查询实际上是‘关键词扩展<strong class="jt ir">++</strong>’，而不是‘文档扩展’，就像你在向量空间中想象的那样。在引擎盖下，从您想要“扩展”的输入文档中选择有代表性的术语(根据高度可配置的过程)。与纯粹的“关键词扩展”方法相比，这样做的优点在于，与所有输入项共现的项被认为比那些仅与输入项的子集共现的项更重要。结果是，可以假设用于播种“文档扩展”的扩展的关键字集具有高度的上下文相关性。</p><p id="723f" class="pw-post-body-paragraph jq jr iq jt b ju jv jw jx jy jz ka kb ku kd ke kf kv kh ki kj kw kl km kn ko ij bi translated">所以我的策略是:</p><ul class=""><li id="7c13" class="mq mr iq jt b ju jv jy jz ku ms kv mt kw mu ko nq mw mx my bi translated">对 Elasticsearch 进行常规查询，检索 10-25 个最相关的文档。这些将是我们的“种子”文档。</li><li id="6462" class="mq mr iq jt b ju mz jy na ku nb kv nc kw nd ko nq mw mx my bi translated">使用种子文档，用一个<em class="js"> more-like-this </em>查询跟进。</li></ul><p id="f538" class="pw-post-body-paragraph jq jr iq jt b ju jv jw jx jy jz ka kb ku kd ke kf kv kh ki kj kw kl km kn ko ij bi translated">这种策略看起来有点像这样(实际上代码要多一点，所以实际上<a class="ae kp" href="https://github.com/nestauk/clio-lite" rel="noopener ugc nofollow" target="_blank">看起来像这个</a>):</p><pre class="ky kz la lb gt nr kt ns nt aw nu bi"><span id="3e10" class="ne lo iq kt b gy nv nw l nx ny"><strong class="kt ir"># Make the initial vanilla query<br/></strong>r = simple_query(url, old_query, event, fields)<br/>data, docs = extract_docs(r)</span><span id="8619" class="ne lo iq kt b gy nz nw l nx ny"><strong class="kt ir"># Formulate the MLT query<br/></strong>total = data['hits']['total']<br/>max_doc_freq = int(max_doc_frac*total)<br/>min_doc_freq = int(min_doc_freq*total)<br/>mlt_query = {"query":<br/>             {"more_like_this":<br/>              {"fields": fields,  <strong class="kt ir"># the fields to consider</strong><br/>               "like": docs,  <strong class="kt ir"># the seed docs</strong><br/>               "min_term_freq": min_term_freq,<br/>               "max_query_terms": max_query_terms,<br/>               "min_doc_freq": min_doc_freq,<br/>               "max_doc_freq": max_doc_freq,<br/>               "boost_terms": 1.,<br/>               "minimum_should_match": minimum_should_match,<br/>               "include": True  <strong class="kt ir"># include the seed docs</strong><br/>              }<br/>             }<br/>            }</span><span id="326a" class="ne lo iq kt b gy nz nw l nx ny"><strong class="kt ir"># Make the MLT query<br/></strong>query = json.dumps(dict(**query, **mlt_query))<br/>params = {"search_type":"dfs_query_then_fetch"}<br/>r_mlt = requests.post(url, data=query,<br/>                      headers=headers,<br/>                      params=params)</span><span id="9edb" class="ne lo iq kt b gy nz nw l nx ny"><strong class="kt ir"># Extract the results<br/></strong>_data, docs = extract_docs(r_mlt)</span></pre><p id="d256" class="pw-post-body-paragraph jq jr iq jt b ju jv jw jx jy jz ka kb ku kd ke kf kv kh ki kj kw kl km kn ko ij bi translated"><em class="js">注意，我通过 AWS API Gateway 在 Lambda 函数中提供此功能。部署上述功能的代码也可以在同一个 repo 中找到。</em></p><h2 id="9b19" class="ne lo iq bd lp nf ng dn lt nh ni dp lx ku nj nk mb kv nl nm mf kw nn no mj np bi translated">定义新颖性</h2><p id="6de0" class="pw-post-body-paragraph jq jr iq jt b ju ml jw jx jy mm ka kb ku mn ke kf kv mo ki kj kw mp km kn ko ij bi translated">新奇没有特别狭窄的定义，我承认我对这个博客的定义会相当狭窄…</p><p id="c40c" class="pw-post-body-paragraph jq jr iq jt b ju jv jw jx jy jz ka kb ku kd ke kf kv kh ki kj kw kl km kn ko ij bi translated">新奇通常可以被定义为任何(或更多)的{新的、原创的、不寻常的}，我的定义将跨越{原创的、不寻常的}概念。更正式一点(但不是很正式)我是问 Elasticsearch 里每个文档的以下问题:</p><blockquote class="jn jo jp"><p id="3a26" class="jq jr js jt b ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko ij bi translated">你和你最近的邻居有多大的不同？</p></blockquote><p id="6160" class="pw-post-body-paragraph jq jr iq jt b ju jv jw jx jy jz ka kb ku kd ke kf kv kh ki kj kw kl km kn ko ij bi translated">只是为了理清这里的逻辑:如果文档的总样本是不平衡的，那么一个属于小众话题的文档会和一般的文档有很大的不同。我们可以通过比较最近的邻居来避免这种情况。还有什么比再次使用<em class="js">more-like-this</em>(<a class="ae kp" href="https://github.com/nestauk/nesta/blob/dev/nesta/packages/novelty/lolvelty.py" rel="noopener ugc nofollow" target="_blank">完整代码在此</a>)更好的获取最近邻居的方法呢:</p><pre class="ky kz la lb gt nr kt ns nt aw nu bi"><span id="1af1" class="ne lo iq kt b gy nv nw l nx ny">mlt_query = {<br/>    "query": {<br/>        "more_like_this": {<br/>            "fields": fields,  <strong class="kt ir"># field you want to query</strong><br/>            "like": [{'_id':doc_id,     <strong class="kt ir"># the doc we're analysing</strong><br/>                      '_index':index}], <br/>            "min_term_freq": 1,<br/>            "max_query_terms": max_query_terms, <br/>            "min_doc_freq": 1,<br/>            "max_doc_freq": max_doc_freq, <br/>            "boost_terms": 1., <br/>            "minimum_should_match": minimum_should_match,<br/>            "include": True<br/>        }<br/>    },<br/>    "size":1000,  <strong class="kt ir"># the number of nearest neighbours</strong><br/>    "_source":["_score"]<br/>}</span><span id="9e37" class="ne lo iq kt b gy nz nw l nx ny"><strong class="kt ir"># Make the search and normalise the scores<br/></strong>r = es.search(index=index, body=mlt_query)<br/>scores = [h['_score']/r['hits']['max_score'] <br/>          for h in r['hits']['hits']]</span><span id="3088" class="ne lo iq kt b gy nz nw l nx ny"><strong class="kt ir"># Calculate novelty as the distance to a low percentile<br/></strong>delta = np.percentile(scores, similar_perc)<br/>return 1 - delta</span></pre><p id="57a3" class="pw-post-body-paragraph jq jr iq jt b ju jv jw jx jy jz ka kb ku kd ke kf kv kh ki kj kw kl km kn ko ij bi translated">自然，任何包含“不寻常”概念的像样的新颖性定义都应该包含坏数据，因为人们希望这些数据是不寻常的。我发现，通过对 arXiv 数据应用上面的新颖性评分器，我能够找出一大堆糟糕的数据，比如<a class="ae kp" href="https://arxiv.org/abs/hep-ph/0304042" rel="noopener ugc nofollow" target="_blank">抄袭的</a>和“<a class="ae kp" href="https://arxiv.org/abs/1804.08090" rel="noopener ugc nofollow" target="_blank">评论</a>的文章。我继续给这些标上 0 的新奇度，但是我相信你可以找到自己的方法！</p><p id="93aa" class="pw-post-body-paragraph jq jr iq jt b ju jv jw jx jy jz ka kb ku kd ke kf kv kh ki kj kw kl km kn ko ij bi translated">这种新颖性评分方法的一个缺点是实现起来相对较慢(它必须在逐个文档的基础上计算)，因此我对我的 Elasticsearch 数据库中的所有文档进行了预处理。</p><h2 id="0805" class="ne lo iq bd lp nf ng dn lt nh ni dp lx ku nj nk mb kv nl nm mf kw nn no mj np bi translated">把所有的放在一起</h2><p id="8bc2" class="pw-post-body-paragraph jq jr iq jt b ju ml jw jx jy mm ka kb ku mn ke kf kv mo ki kj kw mp km kn ko ij bi translated">因此，通过过度使用 Elasticsearch 的<em class="js"> more-like-this </em>查询，我们能够进行广泛的搜索，同时衍生出一种非常轻量级的新奇度。查看<code class="fe kq kr ks kt b"><a class="ae kp" href="https://github.com/nestauk/clio-lite" rel="noopener ugc nofollow" target="_blank">clio-lite</a></code>以更好地理解代码，并且<strong class="jt ir">如果您想看到这在行动中</strong>，请查看 arXiv 数据的<a class="ae kp" href="https://arxlive.org/hierarxy" rel="noopener ugc nofollow" target="_blank"><strong class="jt ir"><em class="js">hierar xy</em></strong>搜索引擎</a>。请注意，我还使用了与第一部分中描述的相同的预处理，以及本博客中描述的数据清理。感谢阅读！</p></div></div>    
</body>
</html>