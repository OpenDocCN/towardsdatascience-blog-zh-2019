# 为机器学习模型正确准备数据的 5 个步骤。

> 原文：<https://towardsdatascience.com/5-steps-to-correctly-prep-your-data-for-your-machine-learning-model-c06c24762b73?source=collection_archive---------5----------------------->

## 如何准备数据集以充分利用它？

![](img/d9e0324dbe90cc8029460256f5ce41ac.png)

Photo by Brett Sayles from [Pexels](http://pexels.com)

描述任何机器学习项目的最简单方式是，它是一个程序，当给定它以前从未见过的数据时，它将根据以前的*经验*处理它们，并且**告诉你一些你还不知道的事情。**

> “数据是新的石油。”—**Clive Humb—**Starcount 首席数据科学家兼执行董事

数据是几乎所有商业决策的核心。人力资源总监们正在从网上资源中收集数据，以确定招聘的最佳人选，并确认他们的详细信息。营销部门正在利用市场细分数据寻找愿意购买的消费者，尽可能地加快成交过程。企业高管必须审视市场中更大的趋势，比如资源、航运或制造业的价格变化。

你的项目只和你带来的数据一样强大。

## 步骤 1:收集数据

数据的选择完全取决于你要解决的问题。选择正确的数据肯定是你的目标，幸运的是，你能想到的几乎每个主题都有几个免费的公共数据集。
我最喜欢的 3 个免费搜索数据集的网站是:

1.  [Kaggle](https://www.kaggle.com/datasets) 就是这么组织的。你会喜欢他们的数据集有多详细，他们给你关于特征、数据类型、记录数量的信息。你也可以使用他们的内核，而不必下载数据集。
2.  [Reddit](https://www.reddit.com/r/datasets) 这对于请求您想要的数据集来说非常有用。
3.  [谷歌数据集搜索](https://toolbox.google.com/datasetsearch)这还是测试版，但很神奇。
4.  [UCI 机器学习库](https://archive.ics.uci.edu/ml/index.php?fbclid=IwAR09F5grBOTCr1SS4v8gONEYeqk0DqqWpPdt1blmYF9ucZkhsQeM5T0E7ew)，它维护 468 个数据集，作为对机器学习社区的服务。

好的一面是，**数据是达到目的的手段，**换句话说，数据的数量很重要，但不如数据的质量重要。所以，如果你想成为*独立的*，创建你自己的数据集，从几百行开始，然后在你前进的过程中建立其余的。那也可以。有一个 python 库叫做[美汤](https://www.crummy.com/software/BeautifulSoup/bs4/doc/)。这是一个从 HTML 和 XML 文件中提取数据的库。它与您喜欢的解析器一起工作，提供导航、搜索和修改解析树的惯用方式。它通常为程序员节省数小时或数天的工作。

![](img/3151d16b2d18b5ae29b381823472cb7e.png)

[pexels](http://pexels.com)

## 步骤 2:处理缺失数据

这是最难的一步，也可能是耗时最长的一步，除非你幸运地拥有一个完整的数据集，但这种情况很少发生。以错误的方式处理丢失的数据会导致灾难。

一般来说，有许多解决方案，例如:

*   空值替换
*   众数/中值/平均值替换
*   删除整个记录
*   基于模型的插补—回归、k 近邻等
*   插值\外推
*   正向填充\反向填充—热甲板
*   多重插补

但你必须聪明。
例如，你在一家旅行社工作，你一直在收集关于旅行者的数据，出于某种原因，你的数据集中大约有 5%的人没有旅行者的国籍。用空值填充那些丢失的值是一个可怕的错误。因为一个人的国籍很大程度上影响着他们旅行时必须办理的旅行证件手续。在这种情况下，国籍是一个敏感的领域。你最好删除整个记录。

另一方面，年龄可以安全地用平均值代替。在这种情况下没那么敏感。

## 步骤 3:通过特征提取进一步获取数据

特征提取可以成为你的一个转折点。这是数据集的独特之处。通过在特征之间建立联系来获得洞察力是一件杰出的创造性的事情。

例如，你仍然在旅行社漫不经心地工作，**他们要求你创建一个模型，使用聚类对你的客户进行优先排序。**
数据集中有 3 个要素:

*   **票务请求日期**:个人请求其票务的日期。
*   **出发日期**:一个人想要旅行的日期。
*   **退货日期**:退货日期。

您知道您不能为您的模型提供非数字数据，但是，您仍然希望包含它们。
**数据科学家在你可以观察到的一些洞见:** 1) **停留时长**:出发日与返回日之差。那是他们停留的时间。
2) **请求持续时间**:到达日期与请求日期的差值。好的，很好。
使**请求持续时间**越来越远。3 名旅行者，每年分别申请 3 天、3 周&。显然，3 天的家伙是最紧迫的，所以他们是我们目前的首要任务。
然而，将这一概念(出发日期的接近程度)应用于其他两个可能是错误的。你上次提前一年订机票是什么时候？**此人可能是每年随旅行社出差的常客**。那也会让他成为优先考虑的对象。也许是时候送他们一些免费公里了。

## 第四步:决定哪些关键因素是重要的

现在，这个很棘手。本来这应该是模特的工作。你可以简单地转储你拥有的整个数据集，让人工智能变得聪明。人工智能能够决定哪些功能真正影响输出，哪些不会。不利的一面是，你给你的模型的数据越多，你就要花费金钱(计算机能力)和时间。两者并不总是可用的。因此，给你的程序一点帮助并不总是一个坏主意。如果你确定某个特性与输出完全无关，你应该完全忽略它。

## 步骤 5:将数据分成训练集和测试集

分割数据的著名规则是 80–20%的训练集和测试集。有时，测试集的那 20%应该以一种不仅仅是随机从数据集中删除的方式来设计。例如，你在旅行社工作，他们希望你开发一个程序来检测一个人今年是否会订票。
所以你继续收集旅行社成立以来所有旅行者的数据，处理你的数据。现在是分割数据集的时候了。您会有这样的感觉，您想要以一种跨越所有年份的方式来削减测试集。这真的很聪明吗？如果你想预测一个人是否会在 2019 年旅行，为什么要关心他(或类似的人)是否在 2008 年旅行？自那以后，发生了许多全球性的变化。也许他们来自的国家和你的国家有问题，也许在他的国家不太顺利。在这种情况下，**一个聪明的做法是把测试集设计成只在最近几年。**
你的训练集可能包含多年来的所有数据，原因越多越开心。**但是根据年份给权重是个明智的想法。**来自 2008 年的客户记录应该比来自 2018 年的记录具有更轻的权重。

在大多数情况下，设计测试集使其跨越许多年是一个很好的建议。但不是在所有情况下。

交叉验证是一个重要的程序，用于评估模型对新数据的技能。例如:K-fold，将训练集分成 K 个组。对于每个组，您将该组作为小型测试集，在其他组上训练和调整您的模型，并在该小型测试集上评估您的模型，保留评估分数并丢弃模型，然后继续下一组。

***底线是，为了最大限度地利用您的数据，您必须从整体上更深入地研究 it &。不仅仅是运用你学到的技巧&策略，而是这些策略是否适合你的情况。***