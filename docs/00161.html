<html>
<head>
<title>A Quick Exploration of NLP for text Classification on Echo Reviews</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">回声评论文本分类的自然语言处理快速探索</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/a-quick-exploration-of-nlp-for-text-classification-on-echo-reviews-6b65a9e2cc9e?source=collection_archive---------22-----------------------#2019-01-07">https://towardsdatascience.com/a-quick-exploration-of-nlp-for-text-classification-on-echo-reviews-6b65a9e2cc9e?source=collection_archive---------22-----------------------#2019-01-07</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="0a12" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">简单几步的情感分析</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/ab05b28a3843894a23a591d6865c1d65.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ssA-LvuPQOXohz2bGxMLvw.jpeg"/></div></div></figure><p id="cbbf" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">Alexa，把你的评论分类。</p><p id="b82d" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">自然语言处理(NLP)是以计算机可以“解释”的方式处理语言数据的领域/科学。Siri、Alexa、Google 等工具和服务。使用这些技术通过语言输入与人类互动，并解释文本数据。机器使用数字信息，这与语言学有本质的不同；因此，这项任务并不容易，需要创造性和复杂的解决方案。</p><p id="d1a8" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">在本文中，我们将使用 NLP 来预测用户对产品的评级，在本例中，是基于评论文本的 Amazon Echo Dot。这个例子需要对情感和极性以及数字分类输出等概念有一些低级的理解。让我们开始吧！</p><h1 id="b7b9" class="ln lo iq bd lp lq lr ls lt lu lv lw lx jw ly jx lz jz ma ka mb kc mc kd md me bi translated">数据和预处理</h1><p id="5456" class="pw-post-body-paragraph kr ks iq kt b ku mf jr kw kx mg ju kz la mh lc ld le mi lg lh li mj lk ll lm ij bi translated">第一步是打开一个 Google Colab python 笔记本，我们将使用这个环境来处理和可视化数据，构建模型，并做出最终预测。</p><p id="dfd0" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">本文的数据由 Kaggle 在以下位置提供:<a class="ae mk" href="https://www.kaggle.com/sid321axn/amazon-alexa-reviews" rel="noopener ugc nofollow" target="_blank">https://www.kaggle.com/sid321axn/amazon-alexa-reviews</a></p><p id="7bb5" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">数据由以下字段组成:评级、日期、变化和审阅文本。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ml"><img src="../Images/ee3aed3345ad28083d30256fcadd1719.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*QWACa7S26_oNMMRnRoHdYw.png"/></div></div></figure><p id="0d48" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">第一步是将这些数据导入我们的 Python 笔记本。要做到这一点，你需要一个 Kaggle 的账户，它是免费的，你可以用谷歌证书注册。</p><p id="45e6" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">首先，我们需要安装允许我们与 Kaggle API 交互的包。</p><pre class="kg kh ki kj gt mm mn mo mp aw mq bi"><span id="f432" class="mr lo iq mn b gy ms mt l mu mv">!pip install kaggle</span></pre><p id="e46c" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">现在，我们需要上传我们的 Kaggle 凭证。这是一个. json 文件，可以从 Kaggle 下载，有很多这方面的教程。只需执行下面几行代码并上传 kaggle.json 文件。</p><pre class="kg kh ki kj gt mm mn mo mp aw mq bi"><span id="266a" class="mr lo iq mn b gy ms mt l mu mv">from google.colab import files<br/>files.upload()</span></pre><p id="be8a" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">我们需要将刚刚上传的文件放入正确的目录中，以符合 API 协议。</p><pre class="kg kh ki kj gt mm mn mo mp aw mq bi"><span id="eb0a" class="mr lo iq mn b gy ms mt l mu mv">!mkdir -p ~/.kaggle<br/>!cp kaggle.json ~/.kaggle/<br/>!chmod 600 ~/.kaggle/kaggle.json</span></pre><p id="d690" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">现在我们准备下载数据。只需进入 Kaggle 页面，将链接复制到数据，或者复制下面的行。</p><pre class="kg kh ki kj gt mm mn mo mp aw mq bi"><span id="830e" class="mr lo iq mn b gy ms mt l mu mv">!kaggle datasets download -d sid321axn/amazon-alexa-reviews</span></pre><p id="f015" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">解压缩文件:</p><pre class="kg kh ki kj gt mm mn mo mp aw mq bi"><span id="8780" class="mr lo iq mn b gy ms mt l mu mv">!unzip amazon-alexa-reviews.zip</span></pre><p id="737a" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">现在我们将数据导入到熊猫数据框架中；但是首先，我们需要进口熊猫。</p><pre class="kg kh ki kj gt mm mn mo mp aw mq bi"><span id="a143" class="mr lo iq mn b gy ms mt l mu mv">import pandas as pd<br/>df = pd.read_table('amazon_alexa.tsv')<br/>df.head()</span></pre><p id="0ead" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">数据帧中的一列包含代表用户正在查看的回声变化的分类值。给定有限数量的类别，对模型使用一次性编码来理解这个变量将是最有效的。一键编码为每个可能的类别创建一列，并根据相应的行是否包含相应的类别值给出 1 或 0。如果您只想专注于文本分析，请随意从输入变量中排除“variation”列！</p><pre class="kg kh ki kj gt mm mn mo mp aw mq bi"><span id="0c5c" class="mr lo iq mn b gy ms mt l mu mv">df1 = df[['variation']]<br/>df2 = df.drop(['variation'], axis = 1)<br/>df1 = pd.get_dummies(df1)<br/>df = pd.concat([df1,df2], axis = 1)<br/>df.head()</span></pre><p id="b1ec" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">需要处理的下一列是日期；在这种情况下，它以 dd-MMM-yy(例如 2018 年 7 月 31 日)。只接受数字输入的模型将无法解释这些信息。</p><p id="d99a" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">解决方案是将字符串分解成独立的日、月和年的数字表示，然后将它们放在各自的列中。原始日期列也将被删除。</p><pre class="kg kh ki kj gt mm mn mo mp aw mq bi"><span id="ee3a" class="mr lo iq mn b gy ms mt l mu mv">#df['Year'] = pd.DatetimeIndex(df['date']).year<br/>df['Month'] = pd.DatetimeIndex(df['date']).month<br/>df['Day'] = pd.DatetimeIndex(df['date']).day<br/>df = df.drop(['date'], axis = 1)<br/>df.head()</span></pre><p id="a9ef" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">你可能注意到我把“年”注释掉了。所有审查的年份(2018 年)相同；因此，具有该列不必要地增加了计算负担，而没有提供任何好处。如果这个数据集的某个版本有更新的旧日期，请随意使用“Year”。</p><p id="a129" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">下一步将是收集一些与评论文本本身相关的信息。出于这个例子的目的，我们将使用一个工具 TextBlob，它将分析文本字符串并提供与情感相关的数字输出。TextBlob 将以元组的形式输出极性(范围-1 到 1)和主观性(范围 0 到 1)。这个过程的结果可以映射到分别包含极性和主观性的列中。</p><p id="7da7" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">首先，让我们开始导入 TextBlob 并定义一个函数，该函数在给定一个字符串输入的情况下输出情感，如果输入无法处理，它将返回一个中性的输出。</p><pre class="kg kh ki kj gt mm mn mo mp aw mq bi"><span id="6564" class="mr lo iq mn b gy ms mt l mu mv">from textblob import TextBlob<br/>def sentiment_calc(text):<br/>    try:<br/>        return TextBlob(text).sentiment<br/>    except:<br/>        return TextBlob('hello').sentiment</span></pre><p id="b92b" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">现在，让我们使用一个 lambda 函数将这个新创建的函数应用于包含评论数据的列，并将输出设置为一个新列，我们称之为“情绪”然后，我们将情感元组映射到各个变量的各个列，并删除“情感”列。</p><pre class="kg kh ki kj gt mm mn mo mp aw mq bi"><span id="e6bb" class="mr lo iq mn b gy ms mt l mu mv">df['sentiment'] = df['verified_reviews'].apply(lambda text: sentiment_calc(text))<br/>df[['polarity', 'subjectivity']] = df['sentiment'].apply(pd.Series)<br/>df = df.drop(['sentiment'], axis = 1)<br/>df.head()</span></pre><p id="052e" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">接下来，我们可以收集一些关于文本本身性质的附加元数据，包括字符数、字数、平均单词长度和停用词数。这将允许模型识别这些特征和评级输出之间的任何关系。</p><p id="1d87" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">首先让我们定义一个返回平均单词长度的函数:</p><pre class="kg kh ki kj gt mm mn mo mp aw mq bi"><span id="7e4c" class="mr lo iq mn b gy ms mt l mu mv">def avg_word(sentence):<br/>  try:<br/>    words = sentence.split()<br/>    return (sum(len(word) for word in words)/len(words))<br/>  except:<br/>    return 0</span></pre><p id="2273" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">现在，让我们基于 review 文本列为上述元数据元素创建新列。</p><pre class="kg kh ki kj gt mm mn mo mp aw mq bi"><span id="26a2" class="mr lo iq mn b gy ms mt l mu mv">df['number_words'] = df['verified_reviews'].str.split().str.len()<br/>df['number_character'] = df['verified_reviews'].str.len()<br/>df['avg_word'] = df['verified_reviews'].apply(lambda x: avg_word(x))</span></pre><p id="5574" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">现在我们将创建一个包含评论文本中停用词数量的列。停用词通常被认为是更常见、意义更小的词，如“a”、“the”和“I”。我们还不知道这个变量和这个特定应用的输出之间是否有相关性；然而，我们有一个小的数据集和充足的内存，包含它不会有什么坏处！</p><p id="3fd5" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">我们将从 NLTK 导入“停用词”工具(我鼓励那些不知道这个工具包是什么的人去查一下)。导入工具包，然后使用 lambda 函数，通过执行以下代码行将其应用到评审中。</p><pre class="kg kh ki kj gt mm mn mo mp aw mq bi"><span id="72dd" class="mr lo iq mn b gy ms mt l mu mv">import nltk<br/>nltk.download("stopwords")<br/>from nltk.corpus import stopwords<br/>stop = stopwords.words('english')</span><span id="fd84" class="mr lo iq mn b gy mw mt l mu mv">df['stopwords'] = df['verified_reviews'].apply(lambda x: len([x for x in x.split() if x in stop]))<br/>df.head()</span></pre><p id="ba42" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">让我们对这些输入应用一个定标器(Scikit-Learn MinMaxScaler ),以便于模型解释:</p><pre class="kg kh ki kj gt mm mn mo mp aw mq bi"><span id="9612" class="mr lo iq mn b gy ms mt l mu mv">from sklearn.preprocessing import MinMaxScaler<br/>scaler = MinMaxScaler()</span><span id="b256" class="mr lo iq mn b gy mw mt l mu mv">columns = ['number_character','number_words', 'avg_word', 'stopwords']<br/>for col in columns:<br/>  df[[col]] = scaler.fit_transform(df[[col]])<br/>df.head()</span></pre><p id="51e3" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">此时，我们可以开始构建模型了！如果你喜欢，请随意这样做，因为有足够多的信息来做出一些可靠的预测。然而，我将通过一些额外的步骤来帮助从评论中挤出更多的信息！</p><p id="894d" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">这个过程将涉及文本摘要。我要做的是总结每次复习，然后应用前面的步骤。理论上，这应该从评论中分离出最重要的句子，然后收集最重要的观点。让我们试一试！</p><p id="6291" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">从 Gensim 导入汇总工具，然后定义一个可应用于列的函数。注意:如果摘要过程中有错误，这个函数将返回原始文本的副本。</p><pre class="kg kh ki kj gt mm mn mo mp aw mq bi"><span id="383b" class="mr lo iq mn b gy ms mt l mu mv">from gensim.summarization import summarize</span><span id="6ae8" class="mr lo iq mn b gy mw mt l mu mv">def sum_text(text):<br/>  try:<br/>    summed_text = summarize(text)<br/>    return summed_text<br/>  except:<br/>    return text</span></pre><p id="e9a8" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">现在，让我们应用这个函数，并收集与之相关的情绪。没有必要缩放输出，因为情感分数将总是在模型容易理解的范围内给出。</p><pre class="kg kh ki kj gt mm mn mo mp aw mq bi"><span id="70a0" class="mr lo iq mn b gy ms mt l mu mv">df['summed_text'] = df['verified_reviews'].apply(lambda x: sum_text(x))<br/>df['sentiment_sum'] = df['summed_text'].apply(lambda text: sentiment_calc(text))<br/>df[['polarity_sum', 'subjectivity_sum']] = df['sentiment_sum'].apply(pd.Series)<br/>df = df.drop(['sentiment_sum'], axis = 1)<br/>df.head()</span></pre><p id="046a" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">现在，让我们创建一个可以输入到模型中的新数据帧。我们可以通过创建 dataframe 的副本来做到这一点，该副本排除了带有字符串的列。</p><pre class="kg kh ki kj gt mm mn mo mp aw mq bi"><span id="aaba" class="mr lo iq mn b gy ms mt l mu mv">df2 = df.drop(['verified_reviews', 'summed_text'], axis = 1)<br/>df2.head()</span></pre><h1 id="d694" class="ln lo iq bd lp lq lr ls lt lu lv lw lx jw ly jx lz jz ma ka mb kc mc kd md me bi translated">数据可视化</h1><p id="2367" class="pw-post-body-paragraph kr ks iq kt b ku mf jr kw kx mg ju kz la mh lc ld le mi lg lh li mj lk ll lm ij bi translated">为了更好的理解数据，我们用 Seaborn 来可视化吧！</p><p id="1626" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">导入依赖项:</p><pre class="kg kh ki kj gt mm mn mo mp aw mq bi"><span id="e7e2" class="mr lo iq mn b gy ms mt l mu mv">import seaborn as sns<br/>from matplotlib import pyplot as plt</span></pre><p id="07d7" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">绘制所需变量的图表:</p><pre class="kg kh ki kj gt mm mn mo mp aw mq bi"><span id="28e5" class="mr lo iq mn b gy ms mt l mu mv">sns_plot = sns.pairplot(df, hue = 'rating', vars=['polarity','subjectivity', 'number_words', 'number_character'])<br/>#sns_plot.savefig('name_of_file.png')<br/>#files.download('name_of_file.png')</span></pre><p id="a84d" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">请注意，最后两行被注释掉了，如果您想保存文件，可以随意取消注释！</p><p id="f869" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">以下是输出:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi mx"><img src="../Images/cd13ec16bd05727b8eb84717acea2b66.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*PA2Y7q8qAAz9KzEPYT4eSg.png"/></div></div></figure><p id="9eb3" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">总结文本的数据呢？</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi mx"><img src="../Images/2026360fd2d6b72961ae5e5843eb601f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Yr2ZTrsYfWzL5q4BVo_AEQ.png"/></div></div></figure><p id="3dfe" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">正如您所看到的，存在某种程度的聚类，让我们希望我们的模型能够捕捉到细微差别！</p><h1 id="7a84" class="ln lo iq bd lp lq lr ls lt lu lv lw lx jw ly jx lz jz ma ka mb kc mc kd md me bi translated">构建和执行模型</h1><p id="142b" class="pw-post-body-paragraph kr ks iq kt b ku mf jr kw kx mg ju kz la mh lc ld le mi lg lh li mj lk ll lm ij bi translated">我们已经完成了数据预处理，最困难的部分已经过去了！</p><p id="a621" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">下一步我们将使用 Scikit-Learn 实现一个随机森林分类器。如果您不理解这种形式的分类器是如何工作的，这是一个查找它的好机会！</p><p id="9be2" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">让我们从创建测试和训练数据开始。我们需要将数据帧转换为标签的 numpy 数组和输入的 numpy 矩阵。我们将使用内置的 Scikit-Learn 测试训练函数来拆分数据。</p><pre class="kg kh ki kj gt mm mn mo mp aw mq bi"><span id="e311" class="mr lo iq mn b gy ms mt l mu mv">from sklearn.model_selection import train_test_split<br/>import numpy as np</span><span id="e48d" class="mr lo iq mn b gy mw mt l mu mv">df1=np.matrix(df2.drop(['rating'], axis = 1))<br/>y=np.array(df2['rating'])</span><span id="8553" class="mr lo iq mn b gy mw mt l mu mv">X_train, X_test, y_train, y_test = train_test_split(df1, y, test_size=0.2)</span></pre><p id="f8d4" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">现在让我们初始化模型，并使其适合训练数据。由于数据集很小，这应该会很快收敛。完成后会显示分数。</p><pre class="kg kh ki kj gt mm mn mo mp aw mq bi"><span id="1d26" class="mr lo iq mn b gy ms mt l mu mv">from sklearn.tree import DecisionTreeClassifier</span><span id="90df" class="mr lo iq mn b gy mw mt l mu mv">rfc = RandomForestClassifier(n_estimators=500, criterion='gini', max_depth=None, min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_features='auto', max_leaf_nodes=None, min_impurity_decrease=0.0, min_impurity_split=None, bootstrap=True, oob_score=False, n_jobs=None, random_state=None, verbose=0, warm_start=False, class_weight=None)</span><span id="80fe" class="mr lo iq mn b gy mw mt l mu mv">rfc.fit(X_train,y_train)<br/>score = rfc.score(X_test,y_test)<br/>print(score)</span></pre><p id="06e8" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">最后，让我们将结果可视化。</p><pre class="kg kh ki kj gt mm mn mo mp aw mq bi"><span id="1e47" class="mr lo iq mn b gy ms mt l mu mv">from sklearn.metrics import confusion_matrix</span><span id="ad59" class="mr lo iq mn b gy mw mt l mu mv">predictions = rfc.predict(X_test)<br/>cm = confusion_matrix(y_test, predictions)<br/>labels = ['1','2','3','4','5']<br/>fig = plt.figure()<br/>ax = fig.add_subplot(111)<br/>cax = ax.matshow(cm)<br/>plt.title('Confusion matrix of the classifier')<br/>fig.colorbar(cax)<br/>ax.set_xticklabels([''] + labels)<br/>ax.set_yticklabels([''] + labels)<br/>plt.xlabel('Predicted')<br/>plt.ylabel('True')<br/>plt.show()<br/>#print(cm)</span></pre><p id="de01" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">要查看结果的数值，只需取消最后一行的注释，以 numpy 矩阵的形式打印出混淆矩阵。</p><p id="b393" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">输出应该类似于以下内容:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi my"><img src="../Images/f911384d7c3d15063d21f608d7f75121.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Uqhs6r2Wa7fA-Zh8i9UNfw.png"/></div></div></figure><p id="4e10" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">成绩还算不错！我们达到了大约 84%的准确率，大多数不正确的预测都在相邻的方块中(a 5 被归类为 a 4 或反之亦然)。</p><h1 id="1cd4" class="ln lo iq bd lp lq lr ls lt lu lv lw lx jw ly jx lz jz ma ka mb kc mc kd md me bi translated">结论</h1><p id="a432" class="pw-post-body-paragraph kr ks iq kt b ku mf jr kw kx mg ju kz la mh lc ld le mi lg lh li mj lk ll lm ij bi translated">在这篇文章中，我们已经下载了 Alexa 评论，预处理文本以创建我们的模型可以解释的数据框架，可视化数据，建立模型，并做出一些预测！</p><p id="836b" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">要进行更全面的分析，请考虑建立一个回归模型，将预测强制为 0 到 5 范围内最接近的整数。由于等级是线性数字等级，回归模型方法可能具有优势。</p><p id="9396" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">NLP 是一个强大的工具，我们只是触及了可能性的表面，我希望你能在这个主题上了解更多，并构建自己的应用程序和实现！</p><p id="8525" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">一如既往，有任何问题请联系我，我很乐意帮助您。</p></div></div>    
</body>
</html>