# 自动化科学数据分析第 1 部分:

> 原文：<https://towardsdatascience.com/automating-scientific-data-analysis-part-1-c9979cd0817e?source=collection_archive---------3----------------------->

## 为什么以及如何编写能够自动分析科学数据集的 Python 程序

![](img/cfab0f735188ba7efa211b72c5b9ccc5.png)

许多人都熟悉数据科学技术的典型应用。一家拥有巨大数据集的公司要求某人挖掘数据集以进行理解，开发针对数据集训练的算法，并让公司使用他们的模型来推动业务决策。数据科学写作通常关注这种有价值的应用，但也有其他应用，人们可以从这些技术和思维模式中受益。例如，科学研究人员。

科学研究与数据科学有许多共同之处。经常有大量的数据集需要研究。这些数据集通常包含重要问题的答案。这些答案通常对决策很重要。主要区别在于，科学研究人员通常在电子表格中手动进行数据分析，而数据科学家通常利用 Python 中许多强大的软件包。

这篇文章的目的是向科学家介绍数据科学技术和思维方式可以改善科学研究的一些方法，以及为什么科学家应该考虑使用这些技术而不是他们当前的方法。基本原理很简单:大多数科学数据分析的数据分析部分是例行的，可以用 Python 脚本自动完成。这种自动化使科学家能够在一段时间内处理比竞争对手更大的数据集，错误更少。

# 我为什么要自动化我的数据分析？

这也许是最重要的问题。没有人会去学习一项新技能，在这里是 Python 编程和数据分析自动化这两项新技能，如果他们认为这对他们没有好处的话。幸运的是，科学家应该自动化数据分析的原因有很多，包括以下几点:

*   **更快的数据处理速度**:分析科学数据集可能会耗费数周或每年数月的时间。每个项目，无论是实验室实验、现场研究还是模拟研究，都会产生数百个甚至数千个数据文件。这些文件中的每一个都必须打开，研究以确保测试/监控/模拟正确进行，并分析以找到包含在该文件中的结果。然后，必须将结果添加到另一个文件中，并保存以供以后分析。手动执行此操作需要大量时间。它是昂贵的。又重复又无聊。自动化解决了所有这些问题。如果项目提前计划好，科学家可以编写一个 Python 脚本，自动对每个数据文件执行所有这些任务。那么这个过程可以在几分钟而不是几个月内完成。
*   **减少的错误可能性**:人类会犯错误。这只是人类的一部分。分析数百个测试文件需要数千次计算。它包括创造数百个情节。它需要在正确的位置保存数百个数据点。这些操作中的每一个都有可能出现打字错误、不正确地记忆常数、将文件保存在错误的位置、不一致的绘图轴标签等等。这一直是过程的一部分，需要大量的关注和时间来避免。同样，自动化有可能完全避免这个问题。科学家只需要确保一个 Python 脚本是正确的，而不是确保数百个数据文件中的所有计算和绘图都是正确的。然后将该脚本应用于每个文件。如果脚本中有一个错误，没有必要翻遍数百个文件来检查错误在哪里；只需更新脚本并在所有文件上重新运行即可。喝咖啡的时候。
*   **访问 Python 包**:有许多 Python 包是专门为让科学家的生活更轻松而设计的。Scikit-learn 对于需要进行回归或实现机器学习的科学家来说是一个优秀的软件包。Numpy 是一个数字软件包，能够执行科学家需要的大多数计算。Matplotlib 和 Bokeh 都提供了具有不同功能的绘图选项，允许灵活地创建绘图。Pandas 用数据框架取代了 Excel 表格，使数据能够以熟悉的方式进行结构化和操作。
*   **可用于其他目的的时间**:由于自动化数据分析让你可以在更短的时间内完成那部分工作，突然你就有时间从事其他活动了。也许你更愿意把时间花在业务拓展和提案写作上。或者你有一个你想指导的员工。或者你想花更多时间的客户关系。不管你觉得什么活动更有意义，分析你的数据分析会帮助你在那里花更多的时间。

我相信这些原因为学习自动化数据分析提供了坚实的理由，并且任何科学家这样做都是明智的。但我确信这些不是全部原因。你认为你还能获得什么好处？

由于实验室实验和相关的数据分析是科学研究的一个常见部分，本系列文章将重点关注如何自动化这一过程。

# 我需要采取什么步骤来自动化实验室数据分析？

首先，在更深入地讨论几个主题之前，我们将介绍项目的结构和总体设计。这一系列的文章将集中在这个过程的计划和数据分析方面。

不幸的是，每个项目都必须单独处理，详细的通用解决方案并不存在。然而，有一个基本的方法可以应用于每个项目，具体的编程(主要是计算)在项目之间有所不同。下面的一般过程提供了自动化数据分析项目的结构。

## 1.创建测试计划

确定需要执行哪些测试来生成回答研究问题所需的数据集。这确保了在项目结束时生成回归时有令人满意的数据集可用，并避免了执行额外测试的需要。

## 2.设计数据集以允许自动化

这包括指定哪些信号将被用来识别测试中最重要的部分，或者将被脚本分析的部分。这确保了有一种简单的方法来构建脚本，以识别每个单独测试的结果。

## 3.创建一个清晰的文件命名系统

要么创建一个数据打印方法，使每个测试中的测试条件的识别变得简单明了，要么与实验室测试人员合作来完成。这确保了程序能够识别每个测试的条件，这对于分析数据和存储结果是必要的。

## 4.将结果数据文件存储在特定文件夹中

这允许使用 Python 包“glob”来依次打开和分析来自每个单独测试的数据。

## 5.分析单个测试的结果

创建一个程序来自动循环所有的数据文件，并分析每个数据集。这个程序可能会使用 for 循环和 glob 来自动分析每个数据文件。它可能会使用 pandas 来执行计算，以确定测试的预期结果，并创建检查来确保测试正确执行。它还可能包括使用散景或 matplotlib 的绘图功能。

## 6.包括错误检查选项

在这个过程中可能会出现许多错误。也许有些测试有错误。也许程序计算有错误。通过确保程序提供足够的输出来检查测试结果和后续数据分析的质量，使您的生活更加轻松。这可能意味着打印测试图，以便进行视觉检查，或者添加一种算法，将测量数据和计算结果与预期进行比较，并报告错误。

## 7.逻辑地存储数据

每次测试的计算值需要存储在表格和数据文件中，以备后用。这些值的存储方式可能会使剩下的步骤变得容易，也可能变得不可能。数据通常应该存储在不同的表中，这些表提供了以后执行回归所需的数据集。

## 8.从产生的数据集生成回归

创建一个程序，该程序将打开步骤 7 中存储的数据并创建回归。它应该包括一个算法来创建每个期望的回归，匹配步骤 7 中确定的数据存储结构。确保该程序提供足够的统计和视觉输出，以便对结果进行彻底验证。

## 9.验证结果

使用步骤 8 中提供的统计和可视化输出来验证回归结果。确定模型是否足够精确。如果没有，要么返回步骤 7 并生成不同的回归，要么返回步骤 1 并添加额外的测试以创建更全面的数据集。如果模型足够精确，就公布它的优点和缺点的详细描述，以便将来的用户了解应该/不应该使用该模型的情况。

# 后续步骤

这篇文章介绍了使用 Python 脚本自动化科学数据分析的概念、动机和过程。本系列的其余文章将指导你完成上述 9 个步骤。下一篇文章将讨论第 1 步到第 6 步，让你对如何自动分析单个实验室测试有一个明确的理解。第三篇也是最后一篇文章将讨论如何存储每次测试的数据，并将其组合起来形成回归。当这两篇文章中涉及的主题结合在一起时，您将能够编写脚本来自动执行特定项目的整个数据分析过程。

我希望在那里见到你，也希望你觉得这些帖子有用。