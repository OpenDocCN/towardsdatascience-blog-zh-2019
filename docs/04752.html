<html>
<head>
<title>How Do Neural Style Transfers Work?</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">神经类型转换是如何工作的？</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/how-do-neural-style-transfers-work-b76de101eb3?source=collection_archive---------13-----------------------#2019-07-19">https://towardsdatascience.com/how-do-neural-style-transfers-work-b76de101eb3?source=collection_archive---------13-----------------------#2019-07-19</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><h2 id="39ef" class="io ip iq bd b dl ir is it iu iv iw dk ix translated" aria-label="kicker paragraph">#InsideNST</h2><div class=""/><div class=""><h2 id="bf6b" class="pw-subtitle-paragraph jw iz iq bd b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn dk translated">深度学习可以捕捉一幅图像的内容，并将其与另一幅图像的风格相结合。这种技术被称为神经风格转移。但是，神经风格转移是如何运作的呢？在这篇博客文章中，我们将探讨神经风格转移(NST)的潜在机制。</h2></div><h1 id="28d1" class="ko kp iq bd kq kr ks kt ku kv kw kx ky kf kz kg la ki lb kj lc kl ld km le lf bi translated">高级直觉</h1><figure class="lh li lj lk gt ll gh gi paragraph-image"><div role="button" tabindex="0" class="lm ln di lo bf lp"><div class="gh gi lg"><img src="../Images/6e3d15bf2de4cdf14c522c9dc072298d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*bWkWBhe1HbidTTL6.png"/></div></div></figure><p id="03a1" class="pw-post-body-paragraph ls lt iq lu b lv lw ka lx ly lz kd ma mb mc md me mf mg mh mi mj mk ml mm mn ij bi translated">神经类型转换概述</p><p id="12dd" class="pw-post-body-paragraph ls lt iq lu b lv lw ka lx ly lz kd ma mb mc md me mf mg mh mi mj mk ml mm mn ij bi translated">正如我们所看到的，生成的图像具有内容图像的内容和样式图像的样式。可以看出，上述结果不能简单地通过重叠图像来获得。现在，问题仍然是，我们如何确保生成的图像具有内容图像的内容和风格图像的风格？我们如何捕捉各自图像的内容和风格？<br/>为了回答上述问题，我们来看看卷积神经网络(CNN)实际在学习什么。</p><h1 id="017f" class="ko kp iq bd kq kr ks kt ku kv kw kx ky kf kz kg la ki lb kj lc kl ld km le lf bi translated">卷积神经网络捕获了什么？</h1><p id="db2e" class="pw-post-body-paragraph ls lt iq lu b lv mo ka lx ly mp kd ma mb mq md me mf mr mh mi mj ms ml mm mn ij bi translated">看下面的图片。</p><figure class="lh li lj lk gt ll gh gi paragraph-image"><div role="button" tabindex="0" class="lm ln di lo bf lp"><div class="gh gi lg"><img src="../Images/424a690b52d1fe99729b950ed7dd6b9a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*PW4Iu1EO9Kckn5lN.jpeg"/></div></div></figure><p id="b298" class="pw-post-body-paragraph ls lt iq lu b lv lw ka lx ly lz kd ma mb mc md me mf mg mh mi mj mk ml mm mn ij bi translated">卷积神经网络的不同层次</p><p id="e028" class="pw-post-body-paragraph ls lt iq lu b lv lw ka lx ly lz kd ma mb mc md me mf mg mh mi mj mk ml mm mn ij bi translated">现在，在第 1 层，使用 32 个过滤器，网络可以捕捉简单的模式，比如一条直线或一条水平线，这可能对我们来说没有意义，但对网络来说非常重要，慢慢地，当我们向下移动到有 64 个过滤器的第 2 层时，网络开始捕捉越来越复杂的特征，可能是狗的脸，也可能是汽车的轮子。这种对不同简单和复杂特征的捕捉称为特征表示。<br/>这里需要注意的是，中枢神经系统不知道图像是什么，但它们学习对特定图像所代表的内容进行编码。卷积神经网络的这种编码性质可以帮助我们进行神经风格转换。让我们再深入一点。</p><h1 id="79a8" class="ko kp iq bd kq kr ks kt ku kv kw kx ky kf kz kg la ki lb kj lc kl ld km le lf bi translated">如何使用卷积神经网络来捕获图像的内容和风格？</h1><p id="721e" class="pw-post-body-paragraph ls lt iq lu b lv mo ka lx ly mp kd ma mb mq md me mf mr mh mi mj ms ml mm mn ij bi translated">VGG19 网络用于神经类型转换。VGG-19 是一个卷积神经网络，它是在来自 ImageNet 数据库的 100 多万幅图像上训练的。该网络有 19 层深，基于数百万幅图像进行训练。因此，它能够检测图像中的高级特征。<br/>现在，CNN 的这种“编码本质”是神经风格转移的关键。首先，我们初始化一个有噪声的图像，这将是我们的输出图像(G)。然后，我们计算此图像与网络中特定层(VGG 网络)的内容和样式图像的相似程度。由于我们希望输出图像(G)具有内容图像(C)的内容和风格图像(S)的样式，因此我们计算生成的图像(G)相对于相应的内容(C)和风格图像的损失。<br/>基于以上的直觉，我们来定义随机生成的噪声图像的内容丢失和风格丢失。</p><figure class="lh li lj lk gt ll gh gi paragraph-image"><div role="button" tabindex="0" class="lm ln di lo bf lp"><div class="gh gi mt"><img src="../Images/c45265d1de144bbd4dc32ed492312506.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*35-GmlSqciWqWaCC.png"/></div></div><figcaption class="mu mv gj gh gi mw mx bd b be z dk">Working of NST model</figcaption></figure><h1 id="82c2" class="ko kp iq bd kq kr ks kt ku kv kw kx ky kf kz kg la ki lb kj lc kl ld km le lf bi translated">内容丢失</h1><p id="94da" class="pw-post-body-paragraph ls lt iq lu b lv mo ka lx ly mp kd ma mb mq md me mf mr mh mi mj ms ml mm mn ij bi translated">计算内容丢失意味着随机生成的有噪声图像(G)与内容图像(C)的相似程度。为了计算内容损失:</p><p id="7274" class="pw-post-body-paragraph ls lt iq lu b lv lw ka lx ly lz kd ma mb mc md me mf mg mh mi mj mk ml mm mn ij bi translated">假设我们在预先训练的网络(VGG 网络)中选择一个隐藏层(L)来计算损失。因此，设 P 和 F 是原始图像和生成的图像。并且，F[l]和 P[l]是层 L 中各个图像的特征表示。现在，内容损失定义如下:</p><figure class="lh li lj lk gt ll gh gi paragraph-image"><div class="gh gi my"><img src="../Images/db749910b730d249b4b26462fe085728.png" data-original-src="https://miro.medium.com/v2/resize:fit:1362/format:webp/0*PJK8-P3tBWrUV1q1.png"/></div><figcaption class="mu mv gj gh gi mw mx bd b be z dk">Content Cost Function</figcaption></figure><p id="d884" class="pw-post-body-paragraph ls lt iq lu b lv lw ka lx ly lz kd ma mb mc md me mf mg mh mi mj mk ml mm mn ij bi translated">这就结束了内容损失函数。</p><h1 id="0c3e" class="ko kp iq bd kq kr ks kt ku kv kw kx ky kf kz kg la ki lb kj lc kl ld km le lf bi translated">风格丧失</h1><p id="f0cb" class="pw-post-body-paragraph ls lt iq lu b lv mo ka lx ly mp kd ma mb mq md me mf mr mh mi mj ms ml mm mn ij bi translated">在计算风格损失之前，让我们看看“<strong class="lu ja">图像风格</strong>是什么意思，或者我们如何捕捉图像的风格。</p><h1 id="3a33" class="ko kp iq bd kq kr ks kt ku kv kw kx ky kf kz kg la ki lb kj lc kl ld km le lf bi translated">我们如何捕捉图像的风格？</h1><figure class="lh li lj lk gt ll gh gi paragraph-image"><div class="gh gi mz"><img src="../Images/0a4b0eac20387388fd4887cb33413d9b.png" data-original-src="https://miro.medium.com/v2/resize:fit:352/format:webp/0*dyVKNRn36XORjr9v.png"/></div><figcaption class="mu mv gj gh gi mw mx bd b be z dk">Different channels or Feature maps in layer l</figcaption></figure><p id="d4d1" class="pw-post-body-paragraph ls lt iq lu b lv lw ka lx ly lz kd ma mb mc md me mf mg mh mi mj mk ml mm mn ij bi translated">该图像显示了在特定选择的层 l 的不同通道或特征图或过滤器。现在，为了捕捉图像的风格，我们将计算这些过滤器彼此的“相关”程度，即这些特征图的相似程度。<strong class="lu ja">但是相关性是什么意思呢？</strong></p><p id="fd73" class="pw-post-body-paragraph ls lt iq lu b lv lw ka lx ly lz kd ma mb mc md me mf mg mh mi mj mk ml mm mn ij bi translated">让我们借助一个例子来理解它:</p><p id="3430" class="pw-post-body-paragraph ls lt iq lu b lv lw ka lx ly lz kd ma mb mc md me mf mg mh mi mj mk ml mm mn ij bi translated">让上面的图像中的前两个通道是红色和黄色。假设，红色通道捕捉一些简单的特征(比如垂直线)，如果这两个通道相关，那么只要图像中有一条垂直线被红色通道检测到，就会有第二个通道的黄色效果。</p><p id="ae6a" class="pw-post-body-paragraph ls lt iq lu b lv lw ka lx ly lz kd ma mb mc md me mf mg mh mi mj mk ml mm mn ij bi translated">现在，让我们看看如何计算这些相关性(数学上)。</p><p id="a3c4" class="pw-post-body-paragraph ls lt iq lu b lv lw ka lx ly lz kd ma mb mc md me mf mg mh mi mj mk ml mm mn ij bi translated">为了计算不同滤波器或通道之间的相关性，我们计算两个滤波器的激活向量之间的点积。这样得到的矩阵称为<strong class="lu ja">克矩阵</strong>。</p><p id="b3a1" class="pw-post-body-paragraph ls lt iq lu b lv lw ka lx ly lz kd ma mb mc md me mf mg mh mi mj mk ml mm mn ij bi translated">但是我们如何知道它们是否相关呢？</p><p id="0744" class="pw-post-body-paragraph ls lt iq lu b lv lw ka lx ly lz kd ma mb mc md me mf mg mh mi mj mk ml mm mn ij bi translated">如果两个滤波器激活的点积很大，那么两个通道被认为是相关的，如果它很小，那么图像是不相关的。<strong class="lu ja">从数学上来说:</strong></p><p id="8985" class="pw-post-body-paragraph ls lt iq lu b lv lw ka lx ly lz kd ma mb mc md me mf mg mh mi mj mk ml mm mn ij bi translated">样式图像的 Gram 矩阵:</p><p id="3070" class="pw-post-body-paragraph ls lt iq lu b lv lw ka lx ly lz kd ma mb mc md me mf mg mh mi mj mk ml mm mn ij bi translated">这里 k 和 k '代表层 l 的不同滤波器或通道，我们称之为 Gkk'[l][S]。</p><figure class="lh li lj lk gt ll gh gi paragraph-image"><div class="gh gi na"><img src="../Images/7d40b23c94e2e31b5354d6132c07742c.png" data-original-src="https://miro.medium.com/v2/resize:fit:76/0*Zp5g7npg6yhwM3MF"/></div></figure><figure class="lh li lj lk gt ll gh gi paragraph-image"><div class="gh gi nb"><img src="../Images/9070426b7a06affd87384414b82a8a42.png" data-original-src="https://miro.medium.com/v2/resize:fit:830/format:webp/0*L8Y_zB0tWkcxFKMh.png"/></div></figure><p id="d260" class="pw-post-body-paragraph ls lt iq lu b lv lw ka lx ly lz kd ma mb mc md me mf mg mh mi mj mk ml mm mn ij bi translated">样式图像的 Gram 矩阵</p><p id="7b46" class="pw-post-body-paragraph ls lt iq lu b lv lw ka lx ly lz kd ma mb mc md me mf mg mh mi mj mk ml mm mn ij bi translated">生成图像的 Gram 矩阵(G):</p><p id="ced8" class="pw-post-body-paragraph ls lt iq lu b lv lw ka lx ly lz kd ma mb mc md me mf mg mh mi mj mk ml mm mn ij bi translated">这里 k 和 k '代表层 L 的不同滤波器或通道，我们称之为 Gkk'[l][G]。</p><figure class="lh li lj lk gt ll gh gi paragraph-image"><div class="gh gi na"><img src="../Images/ab57cd86c75a2cd10243c48e0061a3ba.png" data-original-src="https://miro.medium.com/v2/resize:fit:76/0*Y5tb6gh4j9WcIpNO"/></div></figure><figure class="lh li lj lk gt ll gh gi paragraph-image"><div class="gh gi nc"><img src="../Images/c3f2fc85064453e0a627eb3bb84ecd84.png" data-original-src="https://miro.medium.com/v2/resize:fit:1040/format:webp/0*yjkYrNf7A_oMB_2V.png"/></div><figcaption class="mu mv gj gh gi mw mx bd b be z dk">Gram Matrix for generated Image</figcaption></figure><p id="0366" class="pw-post-body-paragraph ls lt iq lu b lv lw ka lx ly lz kd ma mb mc md me mf mg mh mi mj mk ml mm mn ij bi translated">现在，我们可以定义风格损失了:</p><p id="3bec" class="pw-post-body-paragraph ls lt iq lu b lv lw ka lx ly lz kd ma mb mc md me mf mg mh mi mj mk ml mm mn ij bi translated">样式和生成图像之间的成本函数是样式图像的 Gram 矩阵和生成图像的 Gram 矩阵之间的差的平方。</p><figure class="lh li lj lk gt ll gh gi paragraph-image"><div class="gh gi na"><img src="../Images/93dec79b98646e225b7f085cd90ded05.png" data-original-src="https://miro.medium.com/v2/resize:fit:76/0*EWbEArntM2KX6prE"/></div></figure><figure class="lh li lj lk gt ll gh gi paragraph-image"><div class="gh gi nd"><img src="../Images/247dd52fb4f3b8429a6245a5cf46474f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1164/format:webp/0*2LrpMFwbhD8OePdd.png"/></div><figcaption class="mu mv gj gh gi mw mx bd b be z dk">Style cost Function</figcaption></figure><p id="fbf2" class="pw-post-body-paragraph ls lt iq lu b lv lw ka lx ly lz kd ma mb mc md me mf mg mh mi mj mk ml mm mn ij bi translated">现在，让我们定义神经类型转移的总损失。</p><h1 id="6fc7" class="ko kp iq bd kq kr ks kt ku kv kw kx ky kf kz kg la ki lb kj lc kl ld km le lf bi translated">总损失函数:</h1><p id="a7a7" class="pw-post-body-paragraph ls lt iq lu b lv mo ka lx ly mp kd ma mb mq md me mf mr mh mi mj ms ml mm mn ij bi translated">总损失函数是内容和风格图像的成本之和。数学上，它可以表示为:</p><figure class="lh li lj lk gt ll gh gi paragraph-image"><div role="button" tabindex="0" class="lm ln di lo bf lp"><div class="gh gi lg"><img src="../Images/4fb47a46d0b7eb4205166340e620c8b9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*JPXny-rYTIeZRSb4.png"/></div></div><figcaption class="mu mv gj gh gi mw mx bd b be z dk">Total Loss Function for Neural Style Transfer</figcaption></figure><p id="834e" class="pw-post-body-paragraph ls lt iq lu b lv lw ka lx ly lz kd ma mb mc md me mf mg mh mi mj mk ml mm mn ij bi translated">你可能已经注意到了上式中的α和β。它们分别用于衡量内容和风格成本。通常，它们定义了生成的输出图像中每个成本的权重。</p><p id="8c1f" class="pw-post-body-paragraph ls lt iq lu b lv lw ka lx ly lz kd ma mb mc md me mf mg mh mi mj mk ml mm mn ij bi translated">一旦损失被计算出来，那么这个损失可以通过使用<strong class="lu ja">反向传播</strong>来最小化，这反过来会优化我们的<strong class="lu ja">随机生成的图像</strong>成为一个<strong class="lu ja">有意义的艺术品</strong>。</p><p id="09d5" class="pw-post-body-paragraph ls lt iq lu b lv lw ka lx ly lz kd ma mb mc md me mf mg mh mi mj mk ml mm mn ij bi translated">这总结了神经类型转移的工作。</p><h1 id="d567" class="ko kp iq bd kq kr ks kt ku kv kw kx ky kf kz kg la ki lb kj lc kl ld km le lf bi translated">使用张量流实现神经类型转换；</h1><p id="720c" class="pw-post-body-paragraph ls lt iq lu b lv mo ka lx ly mp kd ma mb mq md me mf mr mh mi mj ms ml mm mn ij bi translated">在我的 Github 账号上实现:<a class="ae ne" href="https://github.com/blackburn07x/Convolutional-Neural-network/tree/main/Neural%20Style%20Transfer" rel="noopener ugc nofollow" target="_blank">https://Github . com/Blackburn 07x/convolutionary-Neural-network/tree/main/Neural % 20 style % 20 transfer</a></p><h1 id="8d0e" class="ko kp iq bd kq kr ks kt ku kv kw kx ky kf kz kg la ki lb kj lc kl ld km le lf bi translated">结论</h1><p id="2548" class="pw-post-body-paragraph ls lt iq lu b lv mo ka lx ly mp kd ma mb mq md me mf mr mh mi mj ms ml mm mn ij bi translated">在这篇博客中，我们深入了解了神经风格转移是如何工作的。我们还研究了 NST 背后的数学原理。我很想在评论区和你聊聊。希望这有助于你理解<strong class="lu ja">神经类型转移</strong></p><p id="4972" class="pw-post-body-paragraph ls lt iq lu b lv lw ka lx ly lz kd ma mb mc md me mf mg mh mi mj mk ml mm mn ij bi translated">我很乐意在# I<a class="ae ne" href="https://www.instagram.com/ayushsingh.__/?source=post_page---------------------------" rel="noopener ugc nofollow" target="_blank">insta gram</a>上与您联系。谢谢你与我分享你的时间。</p></div></div>    
</body>
</html>