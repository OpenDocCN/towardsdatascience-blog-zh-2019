<html>
<head>
<title>A Minimalist End-to-End Scrapy Tutorial (Part III)</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">一个极简的端到端剪贴簿教程(第三部分)</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/a-minimalist-end-to-end-scrapy-tutorial-part-iii-bcd94a2e8bf3?source=collection_archive---------3-----------------------#2019-09-12">https://towardsdatascience.com/a-minimalist-end-to-end-scrapy-tutorial-part-iii-bcd94a2e8bf3?source=collection_archive---------3-----------------------#2019-09-12</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="7e09" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">面向初学者的系统化网页抓取</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/043e19be9567425b5ab6b177f9d9d886.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*pq9a-Pxm2eTV4B33"/></div></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk">Photo by <a class="ae kv" href="https://unsplash.com/@sarahdorweiler?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Sarah Dorweiler</a> on <a class="ae kv" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><p id="d0a3" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><a class="ae kv" href="https://medium.com/@HarryWang/a-minimalist-end-to-end-scrapy-tutorial-part-i-11e350bcdec0?source=friends_link&amp;sk=c9f8e32f28a88c61987ec60f93b93e6d" rel="noopener">第一部分</a>，<a class="ae kv" rel="noopener" target="_blank" href="/a-minimalist-end-to-end-scrapy-tutorial-part-ii-b917509b73f7?source=friends_link&amp;sk=ebd3a9cee8b2097b3857194fee3821a6">第二部分</a>，<a class="ae kv" rel="noopener" target="_blank" href="/a-minimalist-end-to-end-scrapy-tutorial-part-iii-bcd94a2e8bf3?source=friends_link&amp;sk=a1fdde9c9dd5383d8de2e08395ee3f98">第三部分</a>，<a class="ae kv" href="https://medium.com/@HarryWang/a-minimalist-end-to-end-scrapy-tutorial-part-iv-3290d76a2aef?sk=6f0902f9a15092575814ab533a56f8ef" rel="noopener">第四部分</a>，<a class="ae kv" href="https://medium.com/@HarryWang/a-minimalist-end-to-end-scrapy-tutorial-part-v-e7743ee9a8ef?source=friends_link&amp;sk=c1c5110f63c7ccbe4eb8c6209ee2f57c" rel="noopener">第五部分</a></p><p id="7bdd" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在第二部分中，您已经从网站中提取了所有需要的数据，并将它们存储在 Items 中。在第三部分中，我将引入项目管道，使用<a class="ae kv" href="https://blog.bitsrc.io/what-is-an-orm-and-why-you-should-use-it-b2b6f75f5e2a" rel="noopener ugc nofollow" target="_blank"> ORM </a> (SQLAlchemy)将提取的数据保存到数据库中，并处理重复数据问题。</p><p id="a5ee" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">由蜘蛛返回的每个项目被顺序发送到项目管道(如果有的话),以进行额外的处理，例如将项目保存到数据库、数据验证、删除重复项等。项目管道在<code class="fe ls lt lu lv b">pipelines.py</code>文件中被定义为类，打开这个自动生成的文件，可以看到一个空管道被定义为“TutorialPipeline”:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi lw"><img src="../Images/27948887100ccd6112547e17b3ad47a2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*oi1rOppOMmwGb9T4zHrDow.png"/></div></div></figure><p id="766f" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">您需要在<code class="fe ls lt lu lv b">settings.py</code>文件中指定启用哪个管道以及管道的顺序——默认情况下，没有管道被启用。要启用上面的空管道，请在<code class="fe ls lt lu lv b">settings.py</code>中注释掉以下部分:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi lx"><img src="../Images/2850aef6efd48967a24ea4bc00b34c2a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*et59SNgkpI4XRw86BE8Z6Q.png"/></div></div></figure><p id="8644" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">整数值(通常范围从 0 到 1000)，例如上面所示的 300，决定了管道的执行顺序(较低值的管道首先运行)。</p><p id="aa20" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">接下来，让我们开发一个管道来将项目保存到数据库中。在这里，我使用面向对象的范例，使用对象关系映射(ORM)来查询和操作数据库中的数据。特别是，我使用<a class="ae kv" href="https://www.sqlalchemy.org" rel="noopener ugc nofollow" target="_blank"> SQLAlchemy </a>。我不会涉及 ORM 的细节，请参考<a class="ae kv" href="https://blog.bitsrc.io/what-is-an-orm-and-why-you-should-use-it-b2b6f75f5e2a" rel="noopener ugc nofollow" target="_blank">这篇文章</a>了解一些利弊。</p><p id="1b6b" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">首先，让我们设计数据库模式。注意，该项目有 6 个字段，如<code class="fe ls lt lu lv b">quote_content</code>、<code class="fe ls lt lu lv b">tags</code>、<code class="fe ls lt lu lv b">author_name</code>、<code class="fe ls lt lu lv b">author_birthday</code>、<code class="fe ls lt lu lv b">author_bornlocation</code>和<code class="fe ls lt lu lv b">bio</code>。我将使用三个表来存储这些数据，即报价、标签、作者。引用和标记之间存在多对多关系(一个引用可以有一个或多个标记，一个标记可以与一个或多个引用相关联)，作者和引用之间存在一对多关系(一个作者可以有一个或多个引用，但是一个引用只属于一个作者)。</p><p id="46d4" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">要通过 SQLAlchemy 使用 ORM 定义这个模式，您需要:</p><ul class=""><li id="0b00" class="ly lz iq ky b kz la lc ld lf ma lj mb ln mc lr md me mf mg bi translated">在<code class="fe ls lt lu lv b">requirements.txt</code>中添加<code class="fe ls lt lu lv b">SQLAlchemy&gt;=1.3.6</code>，在虚拟环境中运行<code class="fe ls lt lu lv b">pip install -r requirements.txt</code>安装软件包</li><li id="4774" class="ly lz iq ky b kz mh lc mi lf mj lj mk ln ml lr md me mf mg bi translated">用以下内容创建一个<code class="fe ls lt lu lv b">models.py</code>:</li></ul><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi mm"><img src="../Images/ae34bab016a488a8c289a1076a2247cb.png" data-original-src="https://miro.medium.com/v2/resize:fit:812/format:webp/1*m7mQuobjGx1fmA9_urXvFg.png"/></div></figure><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mn mo l"/></div></figure><p id="702d" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><code class="fe ls lt lu lv b">db_connect()</code>功能使用<code class="fe ls lt lu lv b">create_engine(get_project_settings().get(“CONNECTION_STRING”))</code>连接到数据库。<code class="fe ls lt lu lv b">CONNECTION_STRING</code>在<code class="fe ls lt lu lv b">settings.py</code>文件中指定。您可以更改连接字符串以连接到不同的数据库系统，如 SQLite、MySQL、Postgres，而无需更改代码。在本教程中，我使用 SQLite，它本质上是一个名为<code class="fe ls lt lu lv b">scrapy_quotes.db</code>的本地文件，在蜘蛛第一次运行时在根文件夹中创建。</p><p id="3f08" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><code class="fe ls lt lu lv b">CONNECTION_STRING = ‘sqlite:///scrapy_quotes.db’</code></p><p id="5045" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我还提供了一个连接 MySQL 的示例(注释掉了):</p><pre class="kg kh ki kj gt mp lv mq mr aw ms bi"><span id="9af9" class="mt mu iq lv b gy mv mw l mx my"># MySQL<br/>CONNECTION_STRING = "{drivername}://{user}:{passwd}@{host}:{port}/{db_name}?charset=utf8".format(<br/>     drivername="mysql",<br/>     user="harrywang",<br/>     passwd="tutorial",<br/>     host="localhost",<br/>     port="3306",<br/>     db_name="scrapy_quotes",<br/>)</span></pre><p id="fe27" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">现在，让我们创建将项目保存到数据库的管道。打开<code class="fe ls lt lu lv b">pipelines.py</code>文件，添加以下类(管道):</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mn mo l"/></div></figure><p id="35b4" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">确保您还导入了所需的包和函数:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi mz"><img src="../Images/0c65a525b2b720061fd72f50f84de2c2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*NEHRD49PVXV9ysYVdgZlEQ.png"/></div></div></figure><p id="779b" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">下面的 init 函数使用<code class="fe ls lt lu lv b">models.py</code>中的函数连接到数据库(<code class="fe ls lt lu lv b">db_connect</code>)并创建表格(<code class="fe ls lt lu lv b">create_table</code>)，如果表格还不存在的话(否则被忽略)。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi na"><img src="../Images/477acffb7beb7bd1a19c4164b7242712.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*xuNXDb_r1KR8_VK-IkadzA.png"/></div></div></figure><p id="7b8e" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在<code class="fe ls lt lu lv b">process_item</code>函数中，我首先为数据库会话和三个表创建实例。然后，我将作者信息和引用文本值分配给相应的表列。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nb"><img src="../Images/ef364441df2c0c1ed1540fe4cd4dd30a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*0yVm5Fo8UQadI4GlZsnFOg.png"/></div></div></figure><p id="826a" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">接下来，我们需要检查当前条目的作者和标签是否已经存在于数据库中，如果到目前为止它们还不存在，则只创建新的作者/标签:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nc"><img src="../Images/75a176ca984a648118d00a06468f7929.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*vQlkyChNHlvaU93LwWUWUg.png"/></div></div></figure><p id="4af9" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">最后，我将报价添加到数据库中:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi nd"><img src="../Images/d283aa495653455f296aa64ce691cbe3.png" data-original-src="https://miro.medium.com/v2/resize:fit:852/format:webp/1*WNKoyTnHR5SACdMNlIA-YA.png"/></div></figure><p id="f87a" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">请注意，由于您在 ORM ( <code class="fe ls lt lu lv b">quote.author</code>和<code class="fe ls lt lu lv b">quote.tags</code>)中指定的关系，您不需要显式添加作者和标签—新的作者/标签(如果有)将由 SQLAlchemy 自动创建和插入。</p><p id="51bc" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">现在，运行蜘蛛<code class="fe ls lt lu lv b">scrapy crawl quotes</code>，你应该看到一个名为<code class="fe ls lt lu lv b">scrapy_quotes.db</code>的 SQLite 文件被创建。您可以使用 SQLite 命令行打开文件以查看提取的内容:</p><pre class="kg kh ki kj gt mp lv mq mr aw ms bi"><span id="79c7" class="mt mu iq lv b gy mv mw l mx my">$ sqlite3 scrapy_quotes.db<br/>...</span><span id="3d41" class="mt mu iq lv b gy ne mw l mx my">sqlite&gt; .tables<br/>author     quote      quote_tag  tag</span><span id="ad4f" class="mt mu iq lv b gy ne mw l mx my">sqlite&gt; select * from quote limit 3;</span><span id="a48b" class="mt mu iq lv b gy ne mw l mx my">1|The world as we have created it is a process of our thinking. It cannot be changed without changing our thinking.|1</span><span id="06a4" class="mt mu iq lv b gy ne mw l mx my">2|Imperfection is beauty, madness is genius and it's better to be absolutely ridiculous than absolutely boring.|2</span><span id="effa" class="mt mu iq lv b gy ne mw l mx my">3|The person, be it gentleman or lady, who has not pleasure in a good novel, must be intolerably stupid.|3</span><span id="a263" class="mt mu iq lv b gy ne mw l mx my">sqlite&gt; .quit</span></pre><p id="bd4e" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">或者用于 SQLite 的<a class="ae kv" href="https://sqlitebrowser.org" rel="noopener ugc nofollow" target="_blank"> DB 浏览器</a>:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nf"><img src="../Images/52ae417627d1c53439326d56c4ef37b3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*UBtynP99CV2iJ3PcZlQEZA.png"/></div></div></figure><p id="43c2" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">请注意，我们提取了 50 个报价。假设网站可能会添加额外的报价，并且您希望每周运行一次蜘蛛来收集新报价(如果有的话)。所以，让我们再次运行蜘蛛<code class="fe ls lt lu lv b">scrapy crawl quotes</code>，你可能会注意到一个问题:我们现在在数据库中有 100 个报价——同样的 50 个报价被再次提取和存储！</p><p id="ce42" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">接下来，让我们添加另一个管道来检查该项，以查看该项是否是重复的，如果是，则删除该项，以便该项不会通过其余的管道。</p><p id="e881" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">打开 pipelines.py 文件并添加以下类(pipeline):</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mn mo l"/></div></figure><p id="f4e4" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">确保导入 DropItem 异常:<code class="fe ls lt lu lv b">from scrapy.exceptions import DropItem</code>。逻辑很简单:执行数据库查询，查看当前商品的报价文本是否已经存在，如果存在，则删除该商品。现在，您需要在<code class="fe ls lt lu lv b">settings.py</code>中启用这个管道，并确保在保存到数据库管道之前执行复制管道:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ng"><img src="../Images/12ebb5a0d278e3d0b67889aae178dd42.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*TayvMH8QIEhQYHb6cHEyUg.png"/></div></div></figure><p id="9cea" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">您可以先删除 SQLite 文件，然后运行几次蜘蛛程序，您将看到只有第一次数据库被填充了 50 个引号。之后，您可以看到警告信息，指示重复的项目已被删除。</p><pre class="kg kh ki kj gt mp lv mq mr aw ms bi"><span id="fb76" class="mt mu iq lv b gy mv mw l mx my">2019-09-12 11:16:04 [scrapy.core.scraper] WARNING: Dropped: Duplicate item found</span><span id="1654" class="mt mu iq lv b gy ne mw l mx my">...<br/>2019-09-12 11:16:04 [scrapy.core.engine] INFO: Closing spider (finished)</span><span id="4b16" class="mt mu iq lv b gy ne mw l mx my">2019-09-12 11:16:04 [scrapy.statscollectors] INFO: Dumping Scrapy stats:<br/>...</span><span id="7a10" class="mt mu iq lv b gy ne mw l mx my">'item_dropped_count': 50,</span><span id="f082" class="mt mu iq lv b gy ne mw l mx my">'item_dropped_reasons_count/DropItem': 50,</span><span id="3e25" class="mt mu iq lv b gy ne mw l mx my">...</span></pre><p id="63fe" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">你已经完成了第三部分！！干杯。在第四部分中，我将向您展示如何部署蜘蛛来进行周期性的爬行和监视，例如，每 10 分钟自动运行一次蜘蛛。</p><p id="28c3" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><a class="ae kv" href="https://medium.com/@HarryWang/a-minimalist-end-to-end-scrapy-tutorial-part-i-11e350bcdec0?source=friends_link&amp;sk=c9f8e32f28a88c61987ec60f93b93e6d" rel="noopener">第一部分</a>、<a class="ae kv" rel="noopener" target="_blank" href="/a-minimalist-end-to-end-scrapy-tutorial-part-ii-b917509b73f7?source=friends_link&amp;sk=ebd3a9cee8b2097b3857194fee3821a6">第二部分</a>、<a class="ae kv" rel="noopener" target="_blank" href="/a-minimalist-end-to-end-scrapy-tutorial-part-iii-bcd94a2e8bf3?source=friends_link&amp;sk=a1fdde9c9dd5383d8de2e08395ee3f98">第三部分</a>、<a class="ae kv" href="https://medium.com/@HarryWang/a-minimalist-end-to-end-scrapy-tutorial-part-iv-3290d76a2aef?sk=6f0902f9a15092575814ab533a56f8ef" rel="noopener">第四部分</a>、<a class="ae kv" href="https://medium.com/@HarryWang/a-minimalist-end-to-end-scrapy-tutorial-part-v-e7743ee9a8ef?source=friends_link&amp;sk=c1c5110f63c7ccbe4eb8c6209ee2f57c" rel="noopener">第五部分</a></p></div></div>    
</body>
</html>