<html>
<head>
<title>Using Random Forest to tell if you have a representative Validation Set</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用随机森林来判断是否有代表性的验证集</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/using-random-forest-to-tell-if-you-have-a-representative-validation-set-4b58414267f6?source=collection_archive---------17-----------------------#2019-05-28">https://towardsdatascience.com/using-random-forest-to-tell-if-you-have-a-representative-validation-set-4b58414267f6?source=collection_archive---------17-----------------------#2019-05-28</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="0cfb" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">这是一个快速检查，检查您最重要的机器学习任务之一是否设置正确</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/9cdf525d871e4203c76f16eed24dc0a0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*j4k28i3b8tDIvBSg"/></div></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk">Photo by <a class="ae ky" href="https://unsplash.com/@joaosilas?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">João Silas</a> on <a class="ae ky" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><p id="d701" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">当运行预测模型时，无论是在 Kaggle 比赛中还是在现实世界中，您都需要一个代表性的验证集来检查您正在训练的模型是否具有良好的泛化能力，也就是说，该模型可以对它从未见过的数据做出良好的预测。</p><p id="5904" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">那么，我所说的“代表”是什么意思呢？嗯，它真正的意思是，你的训练和验证数据集是相似的，即遵循相同的分布或模式。如果不是这样，那么你就用苹果来训练你的模型，然后试着用橙子来预测。结果将是非常糟糕的预测。</p><p id="5436" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">您可以进行大量探索性数据分析(EDA ),并检查两个数据集中的每个要素的行为是否相似。但那可能真的很费时间。测试您是否有一个有代表性的或好的验证集的一个简洁而快速的方法是运行一个随机的森林分类器。</p><p id="6979" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在这个<a class="ae ky" href="https://www.kaggle.com/akosciansky/do-train-and-test-set-share-the-same-distribution" rel="noopener ugc nofollow" target="_blank"> Kaggle 内核</a>中，我正是这样做的。我首先准备了训练和验证数据，然后添加了一个额外的列“train ”,当数据是训练数据时，它的值为 1，当数据是验证数据时，它的值为 0。这是随机森林分类器将要预测的目标。</p><pre class="kj kk kl km gt lv lw lx ly aw lz bi"><span id="2300" class="ma mb it lw b gy mc md l me mf"># Create the new target<br/>train_set['train'] = 1<br/>validation_set['train'] = 0</span><span id="51f0" class="ma mb it lw b gy mg md l me mf"># Concatenate the two datasets<br/>train_validation = pd.concat([train_set, validation_set], axis=0)</span></pre><p id="f88b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">下一步是准备好独立(X)和从属(y)特性，设置随机森林分类器，并运行交叉验证。</p><p id="b762" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我使用的是度量标准<strong class="lb iu"> ROC AUC </strong>，这是分类任务的常用度量标准。如果指标是 1，那么你的预测是完美的。如果分数是 0.5，那么你和基线一样好，这是如果你总是预测最常见的结果，你会得到的分数。如果分数低于 0.5，那么你做错了。</p><pre class="kj kk kl km gt lv lw lx ly aw lz bi"><span id="b40b" class="ma mb it lw b gy mc md l me mf"># Import the libraries<br/>from sklearn.ensemble import RandomForestClassifier<br/>from sklearn.model_selection import cross_val_score</span><span id="4391" class="ma mb it lw b gy mg md l me mf"># Split up the dependent and independent variables<br/>X = train_validation.drop('train', axis=1)<br/>y = train_validation['train']</span><span id="5387" class="ma mb it lw b gy mg md l me mf"># Set up the model<br/>rfc = RandomForestClassifier(n_estimators=10, random_state=1)</span><span id="dd07" class="ma mb it lw b gy mg md l me mf"># Run cross validation<br/>cv_results = cross_val_score(rfc, X, y, cv=5, scoring='roc_auc')</span></pre><p id="cf68" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">现在，如果训练集和验证集表现相同，您认为 ROC AUC 应该是多少？……没错，<strong class="lb iu"> 0.5 </strong>！如果分数是 0.5，那么这意味着训练和验证数据是不可区分的，这正是我们想要的。</p><p id="5aaa" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">一旦我们运行了交叉验证，让我们得到分数…和好消息！分数确实是 0.5。这意味着 Kaggle 主机已经为我们建立了一个代表性的验证集。有时情况并非如此，这是一个很好的快速检查方法。然而，在现实生活中，你必须自己想出一个验证集，这有望派上用场，以确保你设置了一个正确的验证集。</p><pre class="kj kk kl km gt lv lw lx ly aw lz bi"><span id="4ff9" class="ma mb it lw b gy mc md l me mf">print(cv_results)<br/>print(np.mean(cv_results))</span><span id="c2d0" class="ma mb it lw b gy mg md l me mf">[0.5000814  0.50310124 0.50416737 0.49976049 0.50078978]<br/>0.5015800562639847</span></pre></div></div>    
</body>
</html>