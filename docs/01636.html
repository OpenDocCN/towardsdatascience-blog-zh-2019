<html>
<head>
<title>Optimizing pandas.read_sql for Postgres</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">为 Postgres 优化 pandas.read_sql</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/optimizing-pandas-read-sql-for-postgres-f31cd7f707ab?source=collection_archive---------4-----------------------#2019-03-17">https://towardsdatascience.com/optimizing-pandas-read-sql-for-postgres-f31cd7f707ab?source=collection_archive---------4-----------------------#2019-03-17</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><p id="27a5" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">将 SQL 查询读入 Pandas 数据帧是一项常见的任务，可能会非常慢。根据所使用的数据库，这可能很难避免，但是对于我们这些使用 Postgres 的人来说，我们可以使用 COPY 命令大大加快速度。然而，有几种方法可以使用 COPY 命令将 SQL 中的数据放入 pandas，但需要不同的内存/速度权衡。在本文中，我们将测试几种不同的方法。</p><p id="81ce" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">测试数据集只是样本<a class="ae kl" href="http://github.com/dssg/triage" rel="noopener ugc nofollow" target="_blank"> Triage </a>预测表的前五百万行，这只是我手边的一个。我试图使用本地 Postgres 数据库中的 1300 万行，但是 pandas.read_sql 崩溃了，所以我决定将数据集降低到它可以作为基准处理的水平。</p><p id="7949" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">每种方法都包括三种统计数据:</p><p id="3a81" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">峰值内存</strong>—SQL 读取代码期间使用的最高内存量。这是重要的一点，看看你的程序是否会崩溃！</p><p id="6ebd" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">增量内存</strong>—SQL 读取代码结束时仍在使用的内存量。理论上，这对于所有的方法都是一样的，但是内存泄漏会使不同的方法保留更多的内存。</p><p id="d3bf" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">经过时间</strong> —程序使用的时钟时间。</p><p id="5f44" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">这里用的熊猫版本是 0.24.1。</p><p id="d1ef" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">首先，快速概述一下正在测试的不同方法:</p><ul class=""><li id="aeac" class="km kn iq jp b jq jr ju jv jy ko kc kp kg kq kk kr ks kt ku bi translated">pandas.read_sql —基线</li><li id="1dda" class="km kn iq jp b jq kv ju kw jy kx kc ky kg kz kk kr ks kt ku bi translated">临时文件—使用临时文件模块在磁盘上创建一个临时文件，以便在数据帧读入复制结果之前，将它们存放在其中</li><li id="0e3f" class="km kn iq jp b jq kv ju kw jy kx kc ky kg kz kk kr ks kt ku bi translated">StringIO——使用 StringIO 代替磁盘；使用更多内存，但磁盘 I/O 更少</li><li id="b3e4" class="km kn iq jp b jq kv ju kw jy kx kc ky kg kz kk kr ks kt ku bi translated">压缩 BytesIO，pandas 解压——用 BytesIO 代替 StringIO，压缩数据；应该使用更少的内存，但需要更长的时间</li><li id="c09c" class="km kn iq jp b jq kv ju kw jy kx kc ky kg kz kk kr ks kt ku bi translated">压缩字节，gzip 解压缩—与其他压缩字节相同，但是使用 GzipFile 而不是 pandas 来解压缩</li><li id="15e2" class="km kn iq jp b jq kv ju kw jy kx kc ky kg kz kk kr ks kt ku bi translated">压缩的临时文件——将压缩思想应用于磁盘文件；应该会减少所需的磁盘 I/O</li><li id="9ceb" class="km kn iq jp b jq kv ju kw jy kx kc ky kg kz kk kr ks kt ku bi translated">压缩字节数，低压缩级别—尝试分割未压缩方法和压缩方法之间差异的较低压缩级别</li></ul><h2 id="7b50" class="la lb iq bd lc ld le dn lf lg lh dp li jy lj lk ll kc lm ln lo kg lp lq lr ls bi translated">pandas.read_sql</h2><p id="a1c1" class="pw-post-body-paragraph jn jo iq jp b jq lt js jt ju lu jw jx jy lv ka kb kc lw ke kf kg lx ki kj kk ij bi translated">这是基线。这里没什么特别的。</p><p id="8281" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">峰值内存:3832.7 MiB /增量内存:3744.9 MiB /运行时间:35.91s </strong></p><h2 id="fdb4" class="la lb iq bd lc ld le dn lf lg lh dp li jy lj lk ll kc lm ln lo kg lp lq lr ls bi translated">使用临时文件</h2><p id="4946" class="pw-post-body-paragraph jn jo iq jp b jq lt js jt ju lu jw jx jy lv ka kb kc lw ke kf kg lx ki kj kk ij bi translated">这是我们第一次尝试使用复制命令。来自 COPY 命令的数据必须使用 filehandle:还有比使用临时文件更简单的方法吗？</p><figure class="ly lz ma mb gt mc"><div class="bz fp l di"><div class="md me l"/></div></figure><p id="382f" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">峰值内存:434.3 MB /增量内存:346.6 MB /运行时间:8.93 秒</strong></p><p id="d9ce" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">那……好多了。对于运行时间比 read_sql 快得多，我并不感到惊讶，但我有点惊讶的是，内存使用量相差如此之大。不管怎样，我们继续吧</p><h2 id="3038" class="la lb iq bd lc ld le dn lf lg lh dp li jy lj lk ll kc lm ln lo kg lp lq lr ls bi translated">使用弦乐器</h2><p id="1594" class="pw-post-body-paragraph jn jo iq jp b jq lt js jt ju lu jw jx jy lv ka kb kc lw ke kf kg lx ki kj kk ij bi translated">磁盘 I/O 可能很昂贵，尤其是取决于可用的磁盘类型。我们可以通过使用 StringIO 作为文件句柄来加速它吗？当然，这会占用更多的内存，但也许这是我们可以做的一个折衷。</p><figure class="ly lz ma mb gt mc"><div class="bz fp l di"><div class="md me l"/></div></figure><p id="8b86" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">峰值内存:434.2 MB /增量内存:346.6 MB /运行时间:9.82 秒</strong></p><p id="06ef" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">这是一个令人惊讶的结果。我本以为这会占用更多的内存，速度会更快，但事实并非如此。我的假设是，StringIO 使用的内存峰值最终会在数据帧创建过程中被一个峰值超过。</p><p id="71e7" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">还要注意:增量内存与临时文件版本相同，这可能告诉我们，346.6 MB 是在没有任何内存泄漏的情况下内存基线的一个很好的参考。</p><h2 id="026c" class="la lb iq bd lc ld le dn lf lg lh dp li jy lj lk ll kc lm ln lo kg lp lq lr ls bi translated">使用压缩字节，熊猫解压。</h2><p id="5cde" class="pw-post-body-paragraph jn jo iq jp b jq lt js jt ju lu jw jx jy lv ka kb kc lw ke kf kg lx ki kj kk ij bi translated">我们能降低内存选项所需的内存吗？鉴于之前的结果，这可能看起来像一个傻瓜的差事，但我已经写了代码，所以我不会提前停止测试！Python 的 GzipFile 接口包装了一个 filehandle(在本例中是一个 BytesIO)并处理压缩。我们让 pandas 通过将“compression='gzip '”传递给 read_csv 来处理解压缩</p><figure class="ly lz ma mb gt mc"><div class="bz fp l di"><div class="md me l"/></div></figure><p id="32a4" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">峰值内存:613.6 MB 增量内存:525.8 MB，耗时:1:30 分钟</strong></p><p id="f64a" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">不好！与未压缩版本相比，它实际上使用了更多的内存(并泄漏了一些)。</p><h2 id="d0da" class="la lb iq bd lc ld le dn lf lg lh dp li jy lj lk ll kc lm ln lo kg lp lq lr ls bi translated">使用压缩字节，Gzip 解压缩</h2><p id="d499" class="pw-post-body-paragraph jn jo iq jp b jq lt js jt ju lu jw jx jy lv ka kb kc lw ke kf kg lx ki kj kk ij bi translated">和上一个一样，除了我们绕过熊猫的解压程序，以防它们带来问题。GzipFile 也可以为我们处理解压缩！</p><figure class="ly lz ma mb gt mc"><div class="bz fp l di"><div class="md me l"/></div></figure><p id="1792" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">峰值内存:504.6 MB 增量内存:416.8 MB，耗时:1:42m </strong></p><p id="5c2d" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">当然，这比熊猫的解压缩版本在内存方面要好，但是这仍然比未压缩的版本差。</p><h2 id="6aa5" class="la lb iq bd lc ld le dn lf lg lh dp li jy lj lk ll kc lm ln lo kg lp lq lr ls bi translated">使用压缩的临时文件</h2><p id="7fb4" class="pw-post-body-paragraph jn jo iq jp b jq lt js jt ju lu jw jx jy lv ka kb kc lw ke kf kg lx ki kj kk ij bi translated">压缩思想也可以应用到以前的 tempfile 方法。在这种情况下，压缩应该可以帮助我们减少磁盘 I/O。</p><figure class="ly lz ma mb gt mc"><div class="bz fp l di"><div class="md me l"/></div></figure><p id="ddc3" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">峰值内存:517.2 MB 增量内存:429.5 MB，耗时:1 分 35 秒</strong></p><p id="c16d" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">类似于其他 gzip 示例。不是一个好的选择。</p><h2 id="8c18" class="la lb iq bd lc ld le dn lf lg lh dp li jy lj lk ll kc lm ln lo kg lp lq lr ls bi translated">使用压缩字节，低压缩级别</h2><p id="ccea" class="pw-post-body-paragraph jn jo iq jp b jq lt js jt ju lu jw jx jy lv ka kb kc lw ke kf kg lx ki kj kk ij bi translated">既然我们正在尝试，我们还有一个途径可以探索:gzip 压缩级别。前面所有示例的默认值是 9，这是可能的最高压缩率。在这样做的过程中，除了额外的时间之外，还可能需要额外的内存来进行压缩。如果我们将其中一个翻转到最低压缩级别(1)会怎么样？</p><figure class="ly lz ma mb gt mc"><div class="bz fp l di"><div class="md me l"/></div></figure><p id="2f88" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">峰值内存:761.5 MB 增量内存:673.8 MB，运行时间:1 分 13 秒</strong></p><p id="32c9" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">在时间上稍微好一点，但是在 RAM 上更差:看起来 gzipping 进程无论如何都要使用大量的内存，并且不能很好地传输。</p><h1 id="b8db" class="mf lb iq bd lc mg mh mi lf mj mk ml li mm mn mo ll mp mq mr lo ms mt mu lr mv bi translated">结论</h1><p id="3231" class="pw-post-body-paragraph jn jo iq jp b jq lt js jt ju lu jw jx jy lv ka kb kc lw ke kf kg lx ki kj kk ij bi translated">我们在这里学到了什么？</p><ol class=""><li id="8049" class="km kn iq jp b jq jr ju jv jy ko kc kp kg kq kk mw ks kt ku bi translated">pandas.read_sql 很烂，无论是时间还是内存。</li><li id="2ae0" class="km kn iq jp b jq kv ju kw jy kx kc ky kg kz kk mw ks kt ku bi translated">使用带有 COPY 的 StringIO 或 tempfile 可以执行类似的操作。很容易将 tempfile 称为赢家，但我要强调的是，这完全是基于对您来说便宜的东西。这个测试在我的笔记本电脑上运行，使用本地磁盘。根据设置的不同，使用磁盘 I/O 可能会更昂贵！但是这两个例子一般来说都非常快，应该是你的首选！</li><li id="8fb1" class="km kn iq jp b jq kv ju kw jy kx kc ky kg kz kk mw ks kt ku bi translated">压缩的想法似乎是在转移视线，至少在用 gzip 实现的时候是这样。GzipFile，它的内部我并不完全熟悉。可能有其他更复杂的方法可以工作(例如 zlib.compressobj，或者其他完全的压缩类型)，但是这里没有。</li></ol></div></div>    
</body>
</html>