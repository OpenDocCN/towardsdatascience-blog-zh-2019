<html>
<head>
<title>Unlabelled Data’s Stock is Rising</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">无标签数据的股票正在上涨</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/unlabelled-datas-stock-is-rising-71ed1cf909b7?source=collection_archive---------34-----------------------#2019-10-21">https://towardsdatascience.com/unlabelled-datas-stock-is-rising-71ed1cf909b7?source=collection_archive---------34-----------------------#2019-10-21</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><figure class="gl gn jo jp jq jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi jn"><img src="../Images/0502ddb9615cd2267701162b4409cf52.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*bBEodN1eyKUQ9ESyeJGfKg.png"/></div></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk">Facebook’s latest Semi-Weak Supervised Learning framework is a novel approach to leveraging unlabelled datasets for Computer Vision. <a class="ae kc" href="https://ai.facebook.com/blog/billion-scale-semi-supervised-learning/" rel="noopener ugc nofollow" target="_blank">https://ai.facebook.com/blog/billion-scale-semi-supervised-learning/</a></figcaption></figure><p id="057e" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">脸书大学的研究人员一直在探索使用 Instagram 标签作为 ImageNet 分类模型的弱监督预训练手段。在这项研究中，“弱监督”学习描述了使用有噪声的标签进行监督学习，即 Instagram 图片上的标签。这是有利的，因为大数据是计算机视觉中的王者，他们能够利用<strong class="kf ir">10 亿张</strong>这些 Instagram 图片进行预训练(ImageNet 包含 120 万张图片，以供参考)。</p><p id="8485" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><a class="ae kc" href="https://research.fb.com/wp-content/uploads/2018/05/exploring_the_limits_of_weakly_supervised_pretraining.pdf?" rel="noopener ugc nofollow" target="_blank">他们基于这种弱监督学习范式的模型</a>已经记录了最先进的 ImageNet 分类结果，准确率高达 85.4%。他们目前通过使用<a class="ae kc" href="https://arxiv.org/pdf/1906.06423v2.pdf" rel="noopener ugc nofollow" target="_blank">分辨率增强</a>扩展弱监督学习，以<a class="ae kc" href="https://paperswithcode.com/sota/image-classification-on-imagenet" rel="noopener ugc nofollow" target="_blank"> 86.4% </a>的成绩获得 ImageNet 奖杯。</p><p id="e80c" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">脸书的最新框架<a class="ae kc" href="https://ai.facebook.com/blog/billion-scale-semi-supervised-learning/" rel="noopener ugc nofollow" target="_blank">半弱监督学习</a>是这种思想的最新体现，取得了令人印象深刻的结果，并自然产生了高效的模型。<a class="ae kc" href="https://www.networkworld.com/article/3325397/idc-expect-175-zettabytes-of-data-worldwide-by-2025.html" rel="noopener ugc nofollow" target="_blank">随着数据量持续爆炸</a>，脸书的半弱监督学习等研究正在寻找新的方法<strong class="kf ir">利用大规模未标记数据集</strong>并解决图像网络分类等计算机视觉任务。</p><h1 id="e5df" class="lb lc iq bd ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly bi translated">半监督和弱监督学习</h1><p id="e3f8" class="pw-post-body-paragraph kd ke iq kf b kg lz ki kj kk ma km kn ko mb kq kr ks mc ku kv kw md ky kz la ij bi translated">脸书在这项研究中对“半监督学习”提出了独特的观点。他们将模型提取描述为半监督学习任务，这不是不正确的，只是不符合文献的常规。模型提取指的是使用更大容量的教师网络来产生类标签上的 softmax 分布。然后，较低容量的学生网络在该分布上被训练。模型提取是模型压缩中最强大的技术之一，为像<a class="ae kc" href="https://medium.com/huggingface/distilbert-8cf3380435b5" rel="noopener"> HuggingFace 的 DistilBERT </a>这样的模型提供动力。</p><p id="609c" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">半监督学习描述了从未标记数据中构造监督学习信号的范例。这是 Word2Vec、DeepWalk 或 Wav2Vec 等技术的想法，其中一部分输入被屏蔽掉，模型的任务是预测哪些被删除了。这种扩展到图像的想法被称为“修复”。然而，更常见的是做一些像人工旋转图像，然后让模型预测旋转角度。这就是驱动诸如“自监督 GAN”的自监督模型的机制。</p><p id="f906" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在脸书的“半弱监督学习”框架中，教师模型最初用弱监督数据集(Instagram hashtags 的监督学习)训练，在 ImageNet 上微调，然后教师模型预测原始弱监督数据集上的班级分布，学生模型训练自己预测相同的分布，最后，学生模型在 ImageNet 数据集上微调。</p><h1 id="4467" class="lb lc iq bd ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly bi translated"><strong class="ak">未标记数据集中的类别不平衡</strong></h1><p id="8ad5" class="pw-post-body-paragraph kd ke iq kf b kg lz ki kj kk ma km kn ko mb kq kr ks mc ku kv kw md ky kz la ij bi translated">类别不平衡描述了在训练数据中严重偏向一个类别的数据集。例如，包含 80%狗和 20%猫的训练集将产生偏向于将图像标记为狗的模型。Instagram 图片等海量无标签数据集自然包含类别不平衡和长尾分布。比如 Instagram 上有成吨的狗图片，有多少叶甲？</p><p id="5c39" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">脸书大学的研究人员通过使用教师网络预测标签的 top-K 评分系统来解决这个问题，并使用该参数来平衡图像的数量。随着 K 变大，接近分布末端的图像相对于它们的类别标签变得更有噪声。在叶甲虫的情况下，可能只有 8K 甲虫图像，因此如果 K 被扩展到 16 或 32K，则从 8001 到 16000 的图像将被错误地标记。然而，这个想法是教师模型对 bettle 图像有足够的感觉，使得不是甲虫的图像 8001 在语义/视觉上仍然是相似的。</p><h1 id="148a" class="lb lc iq bd ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly bi translated"><strong class="ak">大规模模型蒸馏的推理加速</strong></h1><figure class="mf mg mh mi gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi me"><img src="../Images/c912c003be52f55d91ff1454341392b3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*oaB6CKUM2y99ES596CFLEw.png"/></div></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk">High-level idea of NVIDIA’s TensorRT inference accelerator. <a class="ae kc" href="https://developer.nvidia.com/tensorrt" rel="noopener ugc nofollow" target="_blank">https://developer.nvidia.com/tensorrt</a></figcaption></figure><p id="a1e8" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">从这个框架中产生的另一个有趣的部分是，当教师在未标记的数据集上预测标签时，推理加速的重要性。教师网络必须进行大约 10 亿次预测，以产生学生网络的精选标签。通常，用模型提取训练的模型不会解决推理瓶颈，但是在以这种方式标记 10 亿张图像的情况下，这显然是重要的。这提供了推理加速器的额外贡献，如 NVIDIA 的 TensorRT 和针对小推理延迟优化的模型。</p><h1 id="7030" class="lb lc iq bd ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly bi translated">弱监督数据集的最佳来源是什么？</h1><figure class="mf mg mh mi gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi mj"><img src="../Images/9ee6bb3f3586a0dec8b643c5add378c5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*EkqzuTBdupuMqw5dykrotg.jpeg"/></div></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk">Photo by <a class="ae kc" href="https://unsplash.com/@neonbrand?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank">NeONBRAND</a> on <a class="ae kc" href="https://unsplash.com/s/photos/instagram?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><p id="aa05" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">想想 Instagram 的标签很有趣。这是弱监督数据集的最佳来源吗？YouTube 视频包含上传者提供的标签，但这种标签比 Instagram hashtagging 噪音大得多。</p><h1 id="82f5" class="lb lc iq bd ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly bi translated">精华建筑搜索</h1><p id="eefb" class="pw-post-body-paragraph kd ke iq kf b kg lz ki kj kk ma km kn ko mb kq kr ks mc ku kv kw md ky kz la ij bi translated">脸书最近的论文改变了学生网络体系结构，从 ResNet-18 到 ResNet-50 以及递增的更大版本的 ResNeXt。在一大堆探索各种背景下的神经架构搜索的研究论文中，对升华师生架构关系的研究相对较少。ResNet 变型从较大容量转换到较小容量似乎很直观。这种想法可能更好地体现在一个更结构化的进展，如从 EfficientNet-E7 到 E5。此外，通过搜索最适合从教师的预测标签分布中学习的特定架构，可能会实现性能提升。</p><h1 id="ae01" class="lb lc iq bd ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly bi translated">生成模型能进一步增加预训练数据集的大小吗？</h1><figure class="mf mg mh mi gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi mk"><img src="../Images/283c6d39ed095fd4fe373e55625425d0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*BOXJyGepkPN-foarzprMdQ.png"/></div></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk">Generated face images from NVIDIA’s Progressively Growing GAN models. What happens if these models are married with the 1 billion Instagram images used for pre-training? <a class="ae kc" href="https://arxiv.org/pdf/1710.10196.pdf" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/pdf/1710.10196.pdf</a></figcaption></figure><p id="3d84" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">使用 GANs 从现有数据集生成新的训练数据的想法似乎很有前途。这已被证明在极其有限的数据集(如<a class="ae kc" href="https://news.developer.nvidia.com/ai-can-generate-synthetic-mris-to-advance-medical-research/" rel="noopener ugc nofollow" target="_blank">医学图像分析</a>)的情况下是成功的，但对于常规任务(如<a class="ae kc" href="https://openreview.net/forum?id=rJMw747l_4" rel="noopener ugc nofollow" target="_blank"> ImageNet 分类或 COCO 对象检测)尚未奏效。</a>使用“半弱”监督训练框架，GANs 或变分自动编码器能否应用于 10 亿张未标记图像，以产生 20 亿或 100 亿张图像？这会产生新颖的图像来改善计算机视觉模型的预训练吗？</p><h1 id="0215" class="lb lc iq bd ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly bi translated">结论</h1><p id="9c87" class="pw-post-body-paragraph kd ke iq kf b kg lz ki kj kk ma km kn ko mb kq kr ks mc ku kv kw md ky kz la ij bi translated">脸书的半弱监督学习框架对半监督学习、弱监督学习、模型提取中的类不平衡以及模型提取的推理加速是一个非常有趣的视角。随着越来越多的人使用 Instagram，数据集自然会变得更大，他们使用 Instagram 图片的方法似乎会自然地扩展到数十亿张图片。top-K 评分法是解决大规模未标记数据集中明显的类别不平衡的一个很好的策略。有趣的是，如果生成模型可以进一步增加这些未标记的数据集。感谢您的阅读，如果您对本文的详细内容感兴趣，请查看下面的视频！</p><figure class="mf mg mh mi gt jr"><div class="bz fp l di"><div class="ml mm l"/></div></figure></div></div>    
</body>
</html>