<html>
<head>
<title>Advanced Ensemble Classifiers</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">高级集成分类器</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/advanced-ensemble-classifiers-8d7372e74e40?source=collection_archive---------11-----------------------#2019-06-14">https://towardsdatascience.com/advanced-ensemble-classifiers-8d7372e74e40?source=collection_archive---------11-----------------------#2019-06-14</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><p id="39ee" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">系综这个词是一个拉丁语派生词，意思是“各部分的结合”。常用的常规分类器容易出错。虽然这些错误是不可避免的，但是可以通过学习分类器的适当构造来减少它们。</p><p id="feeb" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><em class="kl">集成学习是一种生成各种基本分类器的方法，从这些基本分类器中导出一个新的分类器，其性能优于任何组成分类器</em>。这些基本分类器可能在使用的算法、超参数、表示或训练集方面有所不同。</p><p id="3fda" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">集成方法的关键目标是减少<strong class="jp ir">偏差</strong>和<strong class="jp ir">方差</strong>。</p><figure class="kn ko kp kq gt kr gh gi paragraph-image"><div role="button" tabindex="0" class="ks kt di ku bf kv"><div class="gh gi km"><img src="../Images/2abe6a37e7eb8259d6d21224309d66a9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*3C_F3p_rE9sRSG0N8kO4-w.png"/></div></div><figcaption class="ky kz gj gh gi la lb bd b be z dk">The figure shows a basic outline of ensemble techniques.</figcaption></figure><p id="b2a5" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">一些高级集成分类器是:</p><ol class=""><li id="5e6d" class="lc ld iq jp b jq jr ju jv jy le kc lf kg lg kk lh li lj lk bi translated">堆垛</li><li id="4248" class="lc ld iq jp b jq ll ju lm jy ln kc lo kg lp kk lh li lj lk bi translated">混合</li><li id="6eb3" class="lc ld iq jp b jq ll ju lm jy ln kc lo kg lp kk lh li lj lk bi translated">制袋材料</li><li id="2365" class="lc ld iq jp b jq ll ju lm jy ln kc lo kg lp kk lh li lj lk bi translated">助推</li></ol><p id="97a4" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">堆叠:</strong>堆叠是一种将单个训练数据集给多个模型并进行训练的方法。使用 k-fold 验证进一步划分训练集，并形成结果模型。这里，每个模型表示使用的不同算法。</p><figure class="kn ko kp kq gt kr gh gi paragraph-image"><div role="button" tabindex="0" class="ks kt di ku bf kv"><div class="gh gi lq"><img src="../Images/7a2bb54b5cb5dccc347bfd2000298afa.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*H5yKraLv-vObGVIgFiZEBA.png"/></div></div><figcaption class="ky kz gj gh gi la lb bd b be z dk">size of the training data=m*n | no. of models=M</figcaption></figure><p id="94c9" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><em class="kl">从这 M 个模型中做出的预测被用作最终模型的预测器</em>。如此共同形成的变量用于预测最终分类，比每个基础模型更精确</p><p id="ef9c" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">混合:</strong>与叠加相比，混合是一种类似的技术，但唯一的区别是数据集直接分为训练和验证，而不是 k 倍验证。</p><p id="42e2" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">Bagging</strong>(Bootstrap aggregation):在这种方法中，<em class="kl">通过替换从训练数据中选取各种数据项，产生 n 个训练数据样本。</em></p><p id="177a" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">装袋时，由于数据是未加权的，所以抽样中的项目是随机选择的。</p><p id="57d2" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">对于每次迭代，</p><ol class=""><li id="d923" class="lc ld iq jp b jq jr ju jv jy le kc lf kg lg kk lh li lj lk bi translated">在这些样本中的每一个上创建一个基础模型。</li><li id="8842" class="lc ld iq jp b jq ll ju lm jy ln kc lo kg lp kk lh li lj lk bi translated">这些模型并行运行，相互独立。</li><li id="a8b8" class="lc ld iq jp b jq ll ju lm jy ln kc lo kg lp kk lh li lj lk bi translated">通过组合所有模型的预测来确定最终预测。</li></ol><p id="285c" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">这些模型共同形成更高等级的模型，以产生更高的准确性。最终模型的平均值为:</p><p id="cffa" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">e =(<strong class="jp ir">σ</strong>eᵢ)/n</p><p id="1481" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">e₁,e₂…在哪里..eₙ =基本分类器</p><p id="1656" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">e =最终分类器</p><p id="e880" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">打包算法:</p><ul class=""><li id="9b81" class="lc ld iq jp b jq jr ju jv jy le kc lf kg lg kk lr li lj lk bi translated">Bagging 元估计量</li><li id="10da" class="lc ld iq jp b jq ll ju lm jy ln kc lo kg lp kk lr li lj lk bi translated">随机森林</li></ul><figure class="kn ko kp kq gt kr gh gi paragraph-image"><div role="button" tabindex="0" class="ks kt di ku bf kv"><div class="gh gi ls"><img src="../Images/27c9ed0a8a1d67b1b13acc65500b5377.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*aGvX2vxzApSexF98bAGjKw.png"/></div></div></figure><p id="f129" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">升压:</strong>升压是一种自学习技术。它通过为数据中的各种项目分配权重来学习。提升技术最初以相等的权重开始，但是在每个模型之后，每个模型基于其性能被分配一个权重。</p><p id="067f" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">类似地，在评估每个模型之后，错误分类的数据被赋予更多的权重，以便下一个模型更加关注这些项目。</p><p id="fc35" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">对于每次迭代，</p><ol class=""><li id="2743" class="lc ld iq jp b jq jr ju jv jy le kc lf kg lg kk lh li lj lk bi translated">它根据分类的不正确程度对每个训练样本进行加权。</li><li id="31ff" class="lc ld iq jp b jq ll ju lm jy ln kc lo kg lp kk lh li lj lk bi translated">做一个假设</li><li id="ba64" class="lc ld iq jp b jq ll ju lm jy ln kc lo kg lp kk lh li lj lk bi translated">权衡假设</li></ol><p id="61a6" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">因此，通过基于权重对数据组进行投票，最终模型是从关注不同数据组的各种模型中得出的。</p><p id="77ab" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">使用加权平均法对最终模型进行平均</p><p id="0cbf" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">e =((<strong class="jp ir">σ</strong>eᵢwᵢ)/*<strong class="jp ir">σ</strong>wᵢ))/n</p><p id="285a" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">哪里，e₁,e₂…..eₙ =基本分类器</p><p id="ac46" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">w₁,w₂…..wₙ=重量</p><p id="6e8d" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">n =模型数量</p><p id="50ad" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">e =最终分类器</p><p id="56f9" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">升压算法:</p><ul class=""><li id="54c8" class="lc ld iq jp b jq jr ju jv jy le kc lf kg lg kk lr li lj lk bi translated">adaboost 算法</li><li id="2ad9" class="lc ld iq jp b jq ll ju lm jy ln kc lo kg lp kk lr li lj lk bi translated">马恩岛</li><li id="7755" class="lc ld iq jp b jq ll ju lm jy ln kc lo kg lp kk lr li lj lk bi translated">XGBM</li><li id="92ec" class="lc ld iq jp b jq ll ju lm jy ln kc lo kg lp kk lr li lj lk bi translated">轻型 GBM</li><li id="5630" class="lc ld iq jp b jq ll ju lm jy ln kc lo kg lp kk lr li lj lk bi translated">CatBoost</li></ul><p id="fa1f" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">注意:在 bagging 中，模型并行运行并且相互独立，而在 boosting 中，模型按顺序运行并且依赖于前面的模型。</p></div></div>    
</body>
</html>