<html>
<head>
<title>Effective Data Mining is Essential to Devise Effective Marketing Strategy</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">有效的数据挖掘对于制定有效的营销策略至关重要</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/data-driven-decision-support-system-to-predict-the-success-of-marketing-campaign-719e8541515f?source=collection_archive---------12-----------------------#2019-10-05">https://towardsdatascience.com/data-driven-decision-support-system-to-predict-the-success-of-marketing-campaign-719e8541515f?source=collection_archive---------12-----------------------#2019-10-05</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><h2 id="e8dd" class="ir is it bd b dl iu iv iw ix iy iz dk ja translated" aria-label="kicker paragraph">营销活动中的有效自动化</h2><div class=""/><div class=""><h2 id="7c79" class="pw-subtitle-paragraph jz jc it bd b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq dk translated">使用 ML 算法的营销分析和决策支持系统</h2></div><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi kr"><img src="../Images/56216465eae47a1bd6a4ec181cb8c96e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Whr745OyYHuYpjobCp_SXg.png"/></div></div></figure><p id="5e62" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi lz translated">数据挖掘方法通常用于预测不同营销产品的销售成功与否。我们听到了许多时髦的词汇，如商业智能、决策科学、数据科学等。等等。；从广义上讲，他们都支持使用工具&amp;技术将数据转化为商业见解的相同目标。在这里，我们将分析与银行客户、确定的产品和社会经济属性相关的 100 多个特征。</p><h2 id="7b71" class="mi mj it bd mk ml mm dn mn mo mp dp mq lm mr ms mt lq mu mv mw lu mx my mz iz bi translated">用例与问题陈述:</h2><p id="9f73" class="pw-post-body-paragraph ld le it lf b lg na kd li lj nb kg ll lm nc lo lp lq nd ls lt lu ne lw lx ly im bi translated">持续的收入损失迫使一家著名银行重新审视其内部流程并进行根本原因分析。他们发现的一个原因是，客户不像以前那样频繁地选择定期存款。因此，银行希望识别现有客户，即那些更有可能选择定期存款的客户，并希望将营销工作集中在这些客户上。</p><p id="03d2" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">在建模阶段，基于业务知识，我们执行了半自动特征选择，以将维度减少到 17 个相关特征，用于进一步分析。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi nf"><img src="../Images/37f57ff108d54f73e582d747c66b28ec.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_tZ4w2GM1jl3PLFtsySvRg.png"/></div></div></figure><h2 id="2480" class="mi mj it bd mk ml mm dn mn mo mp dp mq lm mr ms mt lq mu mv mw lu mx my mz iz bi translated">特征工程:</h2><p id="6b89" class="pw-post-body-paragraph ld le it lf b lg na kd li lj nb kg ll lm nc lo lp lq nd ls lt lu ne lw lx ly im bi translated">特征工程是数据挖掘的关键。除了常用的银行客户端和产品属性之外，这里我还在特性中使用了社会和经济指标。为了保持简单，没有显示整个数据挖掘过程。经过预处理后，数据集的统计概要—</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi ng"><img src="../Images/a040f37563a163b1cb0feffc08eb1b2e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*HqrRo7OSxWyJhyS4afMJ7Q.png"/></div></div></figure><p id="7ac7" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">平均余额为 1，528.53，但标准偏差(std)为 3，225.41，因此我们可以通过这一点了解到余额在整个数据集内分布很广。期限与潜在客户是否会购买定期存款高度相关。</p><p id="0b95" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">平均活动持续时间为 372 (~371.99)，让我们看看高于该平均值的客户是否更有可能开立定期存款账户。因此，需要删除 duration 列；此外，持续时间是在向潜在客户发出呼叫之后获得的，因此如果目标客户从未收到过呼叫，则该功能就没有多大用处。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi nh"><img src="../Images/2ca0fb8c923767c260d26895a1754949.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*UFnPgakNjnFhtjEmtMf3_g.png"/></div></div></figure><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi ni"><img src="../Images/1466f7d671d491acf08cae5bbcbe91c6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*L7H3jxtPSui490wOHZDCfg.png"/></div></div></figure><p id="549a" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">超过期限状态的人更有可能开立定期存款账户。持续时间高于平均值的群体中有 77%开立了定期存款账户，而低于平均值的群体中有 32%开立了定期存款账户(<em class="nj">应为 77/33 或 78/32 </em>)。显然，一个好主意是瞄准那些在平均水平以上的人。</p><p id="2671" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">我们可以进行聚类和数据分析，找出历史上哪个变量对定期存款有最重要的影响，例如-</p><ul class=""><li id="ebfe" class="nk nl it lf b lg lh lj lk lm nm lq nn lu no ly np nq nr ns bi translated">婚姻状况&amp;教育、职业、教育、贷款、期限、住房等。</li></ul><p id="0c31" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">为了简单起见，我将跳过本文中的所有分析。为了便于理解，我将采用一种简单的方法，通过绘制相关图来检查哪些变量与存款相关。</p><pre class="ks kt ku kv gt nt nu nv nw aw nx bi"><span id="c97b" class="mi mj it nu b gy ny nz l oa ob">corr = df.corr()<br/>sns.heatmap(corr, xticklabels=corr.columns.values, yticklabels=corr.columns.values, annot = True, annot_kws={‘size’:12})<br/>heat_map=plt.gcf()<br/>heat_map.set_size_inches(20,15)<br/>plt.xticks(fontsize=10)<br/>plt.yticks(fontsize=10)<br/>plt.show()</span></pre><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi oc"><img src="../Images/f8b0ef1d94ff094d161d6b3c750ef29f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*SmU98l8qV86IkM7q9AhkVA.png"/></div></div></figure><p id="c146" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">从上面我们可以看出，“住房”和“贷款”是最重要的两个，分别与存款有-20%和-11%的相关性。这里我们将重点讨论“贷款”;让我们看看贷款分布模式。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi od"><img src="../Images/dde79789569648ba803bf361038a7549.png" data-original-src="https://miro.medium.com/v2/resize:fit:1116/format:webp/1*DgThoa6ZxWnGMayTjb4EmQ.png"/></div></figure><pre class="ks kt ku kv gt nt nu nv nw aw nx bi"><span id="e5d4" class="mi mj it nu b gy ny nz l oa ob">ax = (df['deposit'].value_counts() /len(df)*100).plot(kind='bar', stacked = True, rot = 0)<br/>ax.yaxis.set_major_formatter(mtick.PercentFormatter())<br/>ax.set_ylabel('% Customers')<br/>ax.set_xlabel('Personal loan')<br/>ax.set_title('Frequency Percentage by Class')</span><span id="126d" class="mi mj it nu b gy oe nz l oa ob">totals = []  # list to collect the plt.patches data</span><span id="96c8" class="mi mj it nu b gy oe nz l oa ob"># values and append to list<br/>for i in ax.patches:<br/>    totals.append(i.get_width())</span><span id="0938" class="mi mj it nu b gy oe nz l oa ob">total = sum(totals)  # setting individual bar labels using above list</span><span id="cfcb" class="mi mj it nu b gy oe nz l oa ob">for i in ax.patches:<br/>    ax.text(i.get_x()+.15, i.get_height()-3.5,         str(round((i.get_height()/total), 1))+'%’, color = 'white’, weight = 'bold')</span></pre><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi of"><img src="../Images/b9907b0e61af2ec8acf83d47c5f3daf4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*kBfL4MaLWtFeSAqJtakc8w.png"/></div></div></figure><p id="a1d4" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">“贷款”一栏包含 87%(86.9%)的“没有”(没有个人贷款)，13%(13.1%)的“有”(有个人贷款)。数据集严重失真。</p><p id="3cb1" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">你可以在这里访问<a class="ae og" rel="noopener" target="_blank" href="/forensic-analytics-application-of-machine-learning-to-anomaly-detection-ccd7bef58097"><strong class="lf jd"><em class="nj"/></strong></a>来寻找其他不对称数据集的用例。这里，我们希望确保我们的训练和测试集包含相同的比率，即 87%“否”和 13%“是”。</p><blockquote class="oh"><p id="32be" class="oi oj it bd ok ol om on oo op oq ly dk translated">为了避免过度拟合，分层抽样或交叉验证很重要，但是，我们必须确保至少对标签有最大影响的特征(潜在客户是否会开立定期存款)是平均分布的。</p></blockquote><p id="7cdc" class="pw-post-body-paragraph ld le it lf b lg or kd li lj os kg ll lm ot lo lp lq ou ls lt lu ov lw lx ly im bi translated">这里，我们将数据分为训练集和测试集，并实现了分层。</p><pre class="ks kt ku kv gt nt nu nv nw aw nx bi"><span id="d456" class="mi mj it nu b gy ny nz l oa ob"># Creating pipelines<br/>numerical_pipeline = Pipeline([("select_numeric", DataFrameSelector(["age", "balance", "day", "campaign", "pdays", "previous","duration"])),("std_scaler", StandardScaler())])<br/><br/>categorical_pipeline = Pipeline([("select_cat", DataFrameSelector(["job", "education", "marital", "default", "housing", "loan", "contact", "month","poutcome"])),("cat_encoder", CategoricalEncoder(encoding='onehot-dense'))])<br/><br/>preprocess_pipeline = FeatureUnion(transformer_list=[("numerical_pipeline",  numerical_pipeline),("categorical_pipeline", categorical_pipeline)])</span></pre><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi ow"><img src="../Images/f71f47ca25ca815dfab952c077fcc210.png" data-original-src="https://miro.medium.com/v2/resize:fit:1338/format:webp/1*1w2usd35e-2aEeyrFX0zjQ.png"/></div></figure><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi ox"><img src="../Images/67ff5c80c39f3838de87992356ef86f9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1090/format:webp/1*653EIeDFu-xmg4sNC2T4Jw.png"/></div></figure><h2 id="74ab" class="mi mj it bd mk ml mm dn mn mo mp dp mq lm mr ms mt lq mu mv mw lu mx my mz iz bi translated">分类算法:</h2><p id="cb58" class="pw-post-body-paragraph ld le it lf b lg na kd li lj nb kg ll lm nc lo lp lq nd ls lt lu ne lw lx ly im bi translated">现在，训练和测试集已经准备好，让我们通过训练如下 8 个模型来检查哪个分类算法适合我们的情况—</p><pre class="ks kt ku kv gt nt nu nv nw aw nx bi"><span id="fc4c" class="mi mj it nu b gy ny nz l oa ob">dict_classifiers = {"Logistic Regression": LogisticRegression(solver='lbfgs', max_iter=5000), "Nearest Neighbors": KNeighborsClassifier(),"Linear SVM": SVC(gamma = 'auto'),"Gradient Boosting Classifier": GradientBoostingClassifier(),"Decision Tree": tree.DecisionTreeClassifier(),"Random Forest": RandomForestClassifier(n_estimators=18),"Neural Net": MLPClassifier(alpha=1),"Naive Bayes": GaussianNB()}</span><span id="c058" class="mi mj it nu b gy oe nz l oa ob">no_classifiers = len(dict_classifiers.keys())<br/><br/><strong class="nu jd">def</strong> batch_classify(X_train, Y_train, verbose = <strong class="nu jd">True</strong>):<br/>    df_results = pd.DataFrame(data=np.zeros(shape= (no_classifiers,3)), columns = ['classifier', 'train_score', 'training_time'])<br/>    count = 0<br/><strong class="nu jd">for</strong> key, classifier <strong class="nu jd">in</strong> dict_classifiers.items():<br/>    t_start = time.process_time()<br/>    classifier.fit(X_train, Y_train)<br/>    t_end = time.process_time()<br/>    t_diff = t_end - t_start<br/>    train_score = classifier.score(X_train, Y_train)<br/>    df_results.loc[count,'classifier'] = key<br/>    df_results.loc[count,'train_score'] = train_score<br/>    df_results.loc[count,'training_time'] = t_diff<br/><strong class="nu jd">if</strong> verbose:<br/>    print("trained <strong class="nu jd">{c}</strong> in <strong class="nu jd">{f:.2f}</strong> s".format(c=key, f=t_diff))<br/>    count+=1<br/><strong class="nu jd">return</strong> df_results</span><span id="8154" class="mi mj it nu b gy oe nz l oa ob">df_results = batch_classify(X_train, y_train)<br/>print(df_results.sort_values(by='train_score', ascending=<strong class="nu jd">False</strong>))</span></pre><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi oy"><img src="../Images/199e2439dcd343ed21ce2ec1db41a8ae.png" data-original-src="https://miro.medium.com/v2/resize:fit:1206/format:webp/1*xo_aOGzArd332OWlmvcmcA.png"/></div></figure><p id="1cae" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">我们在这里看到，最有可能的是决策树分类器和随机森林分类器过拟合，因为我们得到了接近完美的分数(100%和 99.62%)准确度分数。</p><h2 id="9935" class="mi mj it bd mk ml mm dn mn mo mp dp mq lm mr ms mt lq mu mv mw lu mx my mz iz bi translated">欠拟合(偏差)和过拟合(方差):</h2><p id="9838" class="pw-post-body-paragraph ld le it lf b lg na kd li lj nb kg ll lm nc lo lp lq nd ls lt lu ne lw lx ly im bi translated">如果数据本质上更复杂，我们将永远无法用一条线来很好地描述数据集。这种现象被称为欠拟合。它没有足够的模型灵活性来适当地考虑数据中的所有特征；另一种说法是模型有很高的偏差。</p><p id="a4c8" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">如果模型拟合具有足够的灵活性，几乎完美地解释了数据中的所有特征，并导致数据的过度拟合。过多的模型灵活性最终会导致随机错误和底层数据分布。换句话说，模型有很高的方差。</p><p id="4d24" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">我们必须采用交叉验证过程来避免这种情况。这样做的主要目的是将数据的整体模式提供给模型。</p><pre class="ks kt ku kv gt nt nu nv nw aw nx bi"><span id="d3a7" class="mi mj it nu b gy ny nz l oa ob"># Logistic Regression<br/>log_reg = LogisticRegression(solver=’lbfgs’, max_iter=5000)<br/>log_scores = cross_val_score(log_reg, X_train, y_train, cv=3)<br/>log_reg_mean = log_scores.mean()</span><span id="548f" class="mi mj it nu b gy oe nz l oa ob"># SVC<br/>svc_clf = SVC(gamma=’auto’)<br/>svc_scores = cross_val_score(svc_clf, X_train, y_train, cv=3)<br/>svc_mean = svc_scores.mean()</span><span id="d997" class="mi mj it nu b gy oe nz l oa ob"># KNearestNeighbors<br/>knn_clf = KNeighborsClassifier()<br/>knn_scores = cross_val_score(knn_clf, X_train, y_train, cv=3)<br/>knn_mean = knn_scores.mean()</span><span id="a0d2" class="mi mj it nu b gy oe nz l oa ob"># Decision Tree<br/>tree_clf = tree.DecisionTreeClassifier()<br/>tree_scores = cross_val_score(tree_clf, X_train, y_train, cv=3)<br/>tree_mean = tree_scores.mean()</span><span id="f216" class="mi mj it nu b gy oe nz l oa ob"># Gradient Boosting Classifier<br/>grad_clf = GradientBoostingClassifier()<br/>grad_scores = cross_val_score(grad_clf, X_train, y_train, cv=3)<br/>grad_mean = grad_scores.mean()</span><span id="f8a6" class="mi mj it nu b gy oe nz l oa ob"># Random Forest Classifier<br/>rand_clf = RandomForestClassifier(n_estimators=18)<br/>rand_scores = cross_val_score(rand_clf, X_train, y_train, cv=3)<br/>rand_mean = rand_scores.mean()</span><span id="1bc0" class="mi mj it nu b gy oe nz l oa ob"># NeuralNet Classifier<br/>neural_clf = MLPClassifier(alpha=1)<br/>neural_scores = cross_val_score(neural_clf, X_train, y_train, cv=3)<br/>neural_mean = neural_scores.mean()</span><span id="d55c" class="mi mj it nu b gy oe nz l oa ob"># Naives Bayes<br/>nav_clf = GaussianNB()<br/>nav_scores = cross_val_score(nav_clf, X_train, y_train, cv=3)<br/>nav_mean = neural_scores.mean()</span><span id="667e" class="mi mj it nu b gy oe nz l oa ob"># Create a Dataframe with the results.<br/>d = {‘Classifiers’: [‘Logistic Reg.’, ‘SVC’, ‘KNN’, ‘Dec Tree’, ‘Grad B CLF’, ‘Rand FC’, ‘Neural Classifier’, ‘Naives Bayes’], <br/> ‘Crossval Mean Scores’: [log_reg_mean, svc_mean, knn_mean, tree_mean, grad_mean, rand_mean, neural_mean, nav_mean]}</span><span id="7748" class="mi mj it nu b gy oe nz l oa ob">result_df = result_df.sort_values(by=['Crossval Mean Scores'], ascending=<strong class="nu jd">False</strong>)<br/>result_df</span></pre><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi oz"><img src="../Images/37016b0059bc18c5bf4a9d635d95be05.png" data-original-src="https://miro.medium.com/v2/resize:fit:800/format:webp/1*WyQY7-u7XEcFOGuQ_fz5gw.png"/></div></figure><p id="d80e" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">我们将以 84.51%的分数进行梯度提升。</p><pre class="ks kt ku kv gt nt nu nv nw aw nx bi"><span id="6b1c" class="mi mj it nu b gy ny nz l oa ob">y_train_pred = cross_val_predict(grad_clf, X_train, y_train, cv=3)<br/>grad_clf.fit(X_train, y_train)<br/>print ("Gradient Boost Classifier accuracy is <strong class="nu jd">%2.2f</strong>" % accuracy_score(y_train, y_train_pred))</span><span id="33c2" class="mi mj it nu b gy oe nz l oa ob"># Gradient Boost Classifier accuracy is 0.85</span></pre><h2 id="514c" class="mi mj it bd mk ml mm dn mn mo mp dp mq lm mr ms mt lq mu mv mw lu mx my mz iz bi translated">分类报告:</h2><p id="fbd0" class="pw-post-body-paragraph ld le it lf b lg na kd li lj nb kg ll lm nc lo lp lq nd ls lt lu ne lw lx ly im bi translated">此报告显示了每个类别的主要分类指标。</p><blockquote class="oh"><p id="dc4f" class="oi oj it bd ok ol om on oo op oq ly dk translated">分类报告提供了对分类器行为的更深层次的直觉，而不是全局准确性，这可以掩盖多类问题中某一类的功能缺陷。</p></blockquote><p id="7d05" class="pw-post-body-paragraph ld le it lf b lg or kd li lj os kg ll lm ot lo lp lq ou ls lt lu ov lw lx ly im bi translated">该报告显示模型的精确度、召回率、F1 和支持度分数。</p><pre class="ks kt ku kv gt nt nu nv nw aw nx bi"><span id="64b5" class="mi mj it nu b gy ny nz l oa ob">conf_matrix = confusion_matrix(y_train, y_train_pred)<br/>f, ax = plt.subplots(figsize=(10, 6))<br/>sns.heatmap(conf_matrix, annot=<strong class="nu jd">True</strong>, fmt="d", linewidths=.5, ax=ax)<br/>plt.title("Confusion Matrix", fontsize=12)<br/>plt.subplots_adjust(left=0.15, right=0.99, bottom=0.15, top=0.99)<br/>ax.set_yticks(np.arange(conf_matrix.shape[0]) + 0.5, minor=<strong class="nu jd">False</strong>)<br/>ax.set_xticklabels("")<br/>ax.set_yticklabels(['Refused T. Deposits', 'Accepted T. Deposits'], fontsize=12, rotation=360)<br/>plt.show()</span></pre><p id="9f4e" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">从上表我们可以看出，阳性预测值为{4150 /( 4150+826)} 83.4%，阴性预测值为{3857/(654+3857)} 85.5%。这主要是由我们选择的阈值决定的。</p><p id="2660" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">为了确定我们的模型有多好，我们需要度量标准，如<strong class="lf jd">真阳性率</strong> ( <strong class="lf jd"> TPR/即</strong> <strong class="lf jd">回忆</strong>)，<strong class="lf jd">假阳性率</strong> ( <strong class="lf jd"> FPR </strong>)和<strong class="lf jd">精度</strong>，这将<strong class="lf jd"> <em class="nj">随<strong class="lf jd">阈值</strong>变化</em>，我们选择将预测概率转化为预测类别(0 或 1)。</strong></p><p id="3bff" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">如果我们检查<strong class="lf jd">每一个可能的阈值</strong>并计算这些<em class="nj">度量</em>，我们可以为给定的模型建立<strong class="lf jd">接收器工作特性</strong> ( <strong class="lf jd"> ROC </strong>)曲线和<strong class="lf jd">精确召回</strong> ( <strong class="lf jd"> PR </strong>)曲线。</p><h2 id="7237" class="mi mj it bd mk ml mm dn mn mo mp dp mq lm mr ms mt lq mu mv mw lu mx my mz iz bi translated">精确度、召回率、f1 分数和排队率的可视化:</h2><p id="a779" class="pw-post-body-paragraph ld le it lf b lg na kd li lj nb kg ll lm nc lo lp lq nd ls lt lu ne lw lx ly im bi translated">辨别阈值是肯定类别被选择超过否定类别的概率或分数。通常，该值设置为 50%,但可以调整阈值，以增加或减少对误报或其他应用因素的敏感度。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi pa"><img src="../Images/ec49e05b39c2e07d157343e91e9611c7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*vYvHVecg_TsmWRn5AhQ5EA.png"/></div></div></figure><p id="481d" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">在上图中，我们看到可视化工具被调整为寻找最佳 F1 分数，该分数被标注为阈值 0.41。如果概率&gt; 0.41，则选择正类，否则选择负类。然而，该阈值可能不是最佳阈值:相对于区分阈值，精确度和召回率之间通常存在反比关系。通过调整分类器的阈值，可以将 F1 分数(精确度和召回率的调和平均值)调整到最佳拟合，或者调整分类器以针对特定应用表现最佳。通过考虑以下指标来调整分类器:</p><ul class=""><li id="793a" class="nk nl it lf b lg lh lj lk lm nm lq nn lu no ly np nq nr ns bi translated">精确度:精确度的提高意味着假阳性数量的减少；当特殊待遇的成本很高时(例如在定期存款市场活动中浪费时间)，应优化该指标。</li><li id="cba8" class="nk nl it lf b lg pb lj pc lm pd lq pe lu pf ly np nq nr ns bi translated">回忆:回忆的增加减少了肯定类被错过的可能性；当即使以更多的假阳性为代价也要抓住这个案例时，这个度量应该被优化。</li><li id="ea09" class="nk nl it lf b lg pb lj pc lm pd lq pe lu pf ly np nq nr ns bi translated">F1 分数:F1 分数是精确度和召回率之间的调和平均值。fbeta 参数确定计算此指标时精度和召回的相对权重，默认设置为 1 或 F1。优化这一指标可以在精确度和召回率之间取得最佳平衡。</li><li id="6e72" class="nk nl it lf b lg pb lj pc lm pd lq pe lu pf ly np nq nr ns bi translated">排队率:“排队”是存款查询的术语。此度量描述必须审查的实例的百分比。如果定期存款的审查成本很高，则必须根据业务要求尽量降低成本。如果没有，这可以被优化以确保查询框是干净的。</li></ul><p id="d205" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">我们看到，该图被调整为寻找最佳 F1 分数，该分数被标注为阈值 0.40。该模型在多个训练/测试分割上运行多次，以说明模型相对于指标的可变性(显示为中间曲线周围的填充区域)。</p><h1 id="7e38" class="pg mj it bd mk ph pi pj mn pk pl pm mq ki pn kj mt kl po km mw ko pp kp mz pq bi translated">ROC 曲线(受试者操作特征)AUC(曲线下面积):</h1><p id="1430" class="pw-post-body-paragraph ld le it lf b lg na kd li lj nb kg ll lm nc lo lp lq nd ls lt lu ne lw lx ly im bi translated">如果我们绘制一系列分界点的真阳性结果的分数(真阳性数/有存款的数)与假阳性结果的分数(假阳性数/无存款的数)的关系图，它将生成一条 ROC 曲线。该曲线以图形方式描述了调整截止点时灵敏度和特异性之间的权衡</p><p id="e78d" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">ROC 测量分类器的预测质量，并可视化模型的灵敏度和特异性之间的权衡。在 Y 轴上绘制的 TP 比率和在 X 轴上绘制的 FP 比率基于全球平均值和每个类别。因此，理想点是图的左上角:FP 为零，TP 为一。这就引出了 AUC，也就是 FP 和 TP 的关系。AUC 越高，模型越好。然而，检查曲线的“陡度”也很重要，因为这描述了 TP 率的最大化同时 FP 率的最小化。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi pr"><img src="../Images/c81c3c23c6b3987e2345ce62da4371ae.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*-zwQNJMR0BJdbWeQOiMTJg.png"/></div></div></figure><p id="783c" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">现在我们可以说，如果我们愿意接受 20%的<em class="nj"> FPR </em>，我们将得到 60%以上的<em class="nj"> TPR </em>。</p><h2 id="d724" class="mi mj it bd mk ml mm dn mn mo mp dp mq lm mr ms mt lq mu mv mw lu mx my mz iz bi translated">精确召回曲线:</h2><p id="c36a" class="pw-post-body-paragraph ld le it lf b lg na kd li lj nb kg ll lm nc lo lp lq nd ls lt lu ne lw lx ly im bi translated">用于评估分类器质量的精确召回曲线度量。精度-召回曲线显示了精度(结果相关性的度量)和召回(返回多少相关结果的度量)之间的权衡。曲线下的大部分区域表示高召回率和高精度，这是分类器的最佳情况，显示了为其选择的大多数类返回准确结果的模型。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi ps"><img src="../Images/d5630748f657b4e9bafacbc790f87abe.png" data-original-src="https://miro.medium.com/v2/resize:fit:1288/format:webp/1*h8HmkR2p6-qdjQvD20qi8g.png"/></div></figure><p id="cf60" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">在上图中，我们可以看到 y 轴上的精度与 x 轴上的召回率的关系。填充区域越大，分类器越强。红线标注了平均精度，这是整个图的摘要，计算为每个阈值达到的精度的加权平均值，因此权重是与前一个阈值的召回差异。这里说，我们的模型预测平均准确率为 88%。</p><h2 id="93b3" class="mi mj it bd mk ml mm dn mn mo mp dp mq lm mr ms mt lq mu mv mw lu mx my mz iz bi translated">学习曲线:</h2><p id="5e38" class="pw-post-body-paragraph ld le it lf b lg na kd li lj nb kg ll lm nc lo lp lq nd ls lt lu ne lw lx ly im bi translated">学习曲线显示了具有不同数量训练样本的评估者的训练分数与交叉验证测试分数之间的关系。它是一种工具，可以发现我们从添加更多的训练数据中获益多少，以及估计量是更容易受到方差误差还是偏差误差的影响。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi pt"><img src="../Images/6c44fc911abca42c2fb9a26cc766ccc6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1380/format:webp/1*IveI2mUMaSGFEF4MWNGHBg.png"/></div></figure><p id="70ff" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">随着更多数据的添加，训练和交叉验证分数会聚合在一起，因此模型可能不会从更多数据中受益。曲线以平均分数绘制，但是交叉验证期间的可变性以阴影区域显示，代表所有交叉验证平均值上下的标准偏差。我们可以看到，训练分数和交叉验证分数最后都不是很好。然而，曲线的形状显示，训练分数在开始时非常高(超过 92%)，并且下降到接近 86%，交叉验证分数在开始时非常低(接近 82%)，并且上升到接近 85%。因此，我们看到训练和验证分数最终几乎相等。添加更多的训练样本很可能会提高泛化能力。</p><h2 id="3040" class="mi mj it bd mk ml mm dn mn mo mp dp mq lm mr ms mt lq mu mv mw lu mx my mz iz bi translated">升力/增益曲线:</h2><blockquote class="oh"><p id="fa15" class="oi oj it bd ok ol om on oo op oq ly dk translated">“累积收益和提升曲线是一种简单而有用的方法，基于使用预测模型锁定最有前景的客户，可以了解我们开展营销活动可能获得的回报以及我们应该联系多少客户”</p></blockquote><p id="5add" class="pw-post-body-paragraph ld le it lf b lg or kd li lj os kg ll lm ot lo lp lq ou ls lt lu ov lw lx ly im bi translated">提升/累积收益图表用于评估结果，因为每个结果都有成本。这些信息还可以用来决定打电话的次数，以平衡营销成本和最终电话的预期回报。每个目标客户都有相关的成本(<em class="nj">直接&amp;间接</em>)，因此我们的目标是最大限度地增加通过电话营销获得的受访者数量。现实情况是，挖掘模型很可能介于两个极端之间；在随机猜测和完美预测之间。随机猜测的任何改进都被认为是提升。</p><h2 id="070e" class="mi mj it bd mk ml mm dn mn mo mp dp mq lm mr ms mt lq mu mv mw lu mx my mz iz bi translated">十分位数组:</h2><p id="c6c1" class="pw-post-body-paragraph ld le it lf b lg na kd li lj nb kg ll lm nc lo lp lq nd ls lt lu ne lw lx ly im bi translated">使用拟合的模型，我们可以将从历史营销活动中观察到的结果(即，谁回应了谁没有回应)与该活动中联系的每个客户的预测回应概率进行比较。在实践中，该模型适用于数据的子集，并使用该模型来预测“拒绝”样本中每个客户的响应概率，以更准确地评估该模型对新客户的表现。</p><p id="203c" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">可以通过按照客户的预测概率从最高(最接近 1)到最低(最接近 0)的降序对客户进行排序来制作图表。将客户分成大小相等的部分，我们创建包含相同数量客户的组。因此，我们预测最有可能做出响应的客户位于十分之一组 1，其次是十分之一组 2，依此类推。检查每个十分位数组，我们可以生成一个十分位数汇总，总结每个十分位数中客户和受访者的数量和比例。</p><h2 id="e6a5" class="mi mj it bd mk ml mm dn mn mo mp dp mq lm mr ms mt lq mu mv mw lu mx my mz iz bi translated">累积收益:</h2><p id="c5a9" class="pw-post-body-paragraph ld le it lf b lg na kd li lj nb kg ll lm nc lo lp lq nd ls lt lu ne lw lx ly im bi translated">从十分位数汇总，我们还可以计算出模型提供的<strong class="lf jd"><em class="nj"/></strong>累计收益。我们将调查对象的累计百分比与营销活动中各组接触的累计百分比进行比较。这是针对使用最高响应概率的客户总数的给定百分比的<strong class="lf jd"> <em class="nj">【增益】</em> </strong>，而不是随机针对他们。</p><p id="f484" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">该图显示了该模型将受访者和非受访者区分开来的效果。在这里，人口被分为十分之一，根据他们成功的预测概率递减的顺序。</p><pre class="ks kt ku kv gt nt nu nv nw aw nx bi"><span id="ff10" class="mi mj it nu b gy ny nz l oa ob">skplt.metrics.plot_cumulative_gain(y_test, predicted_probas)<br/>plt.show()</span></pre><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi pu"><img src="../Images/af4ab51334b4ec17983fdbc93035315c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1356/format:webp/1*rS8sJ3h9cUtEOjwJd4a8VQ.png"/></div></figure><p id="721a" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">斜虚线表示随机猜测的结果，是评估 lift 的基线。我们得到另外两行:一行显示训练数据集的理想结果，第二行显示模型的实际提升，或者结果的改进。这里，过滤模型的理想线显示在等级 1 中，而实际升力线显示在等级 0 中。我们可以从图表中看出，理想线的峰值在 60%左右，这意味着我们可以通过向总人口的 60%发送邮件来接触到 100%的目标客户。</p><p id="e527" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">根据发送每个电话的相关成本和每个回答者的预期收入，累积收益图可用于决定联系的最佳客户数量。</p><pre class="ks kt ku kv gt nt nu nv nw aw nx bi"><span id="c492" class="mi mj it nu b gy ny nz l oa ob">skplt.metrics.plot_lift_curve(y_test, predicted_probas, title=’Lift Curve’, ax=None, ﬁgsize=None, title_fontsize=’large’, text_fontsize=’medium’)</span></pre><h2 id="c384" class="mi mj it bd mk ml mm dn mn mo mp dp mq lm mr ms mt lq mu mv mw lu mx my mz iz bi translated">电梯:</h2><p id="55d1" class="pw-post-body-paragraph ld le it lf b lg na kd li lj nb kg ll lm nc lo lp lq nd ls lt lu ne lw lx ly im bi translated">我们还可以看一下<strong class="lf jd"> <em class="nj">提升</em> </strong> <em class="nj"> </em>所实现的目标客户群百分比递增，按概率递减排序。<strong class="lf jd"> <em class="nj">提升</em> </strong>简单来说就是调查对象的百分比与联系客户的百分比之比。所以，与随机联系客户相比，1 的提升相当于没有收获。然而，举个例子来说，lift 值为 2 时，与我们通过随机联系相同数量的客户所预期的数量相比，联系到的受访者数量是两倍。因此，我们可能只接触了 40%的客户，但我们可能接触到了客户群中 80%的受访者。因此，与联系随机抽样的客户相比，我们将目标群体的受访者数量增加了一倍。</p><p id="843f" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">这些数字可以显示在升力曲线上。理想情况下，我们希望提升曲线尽可能高地延伸到图的左上角，这表明我们与一小部分客户的联系有很大的提升。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi pv"><img src="../Images/9656decd001eac669218a96e30ccb879.png" data-original-src="https://miro.medium.com/v2/resize:fit:1384/format:webp/1*1MNltqvqWti597C0dsS-sg.png"/></div></figure><p id="942b" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">现在，我们的预测模型已经准备好了，让我们找出影响<strong class="lf jd"><em class="nj"/></strong>定期存款认购结果的特征。这可以使用决策树、XGB 或 RandomForest 等来完成。为此我使用了决策树。</p><h2 id="7bd1" class="mi mj it bd mk ml mm dn mn mo mp dp mq lm mr ms mt lq mu mv mw lu mx my mz iz bi translated">决策树分类器:</h2><p id="f5c9" class="pw-post-body-paragraph ld le it lf b lg na kd li lj nb kg ll lm nc lo lp lq nd ls lt lu ne lw lx ly im bi translated">我们的分类器的三个最重要的特征是-</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi pw"><img src="../Images/8b9e0532cc2daec2ab07609bc6d6ff06.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Fjk1TKCJp-rATLdru5apaw.png"/></div></div></figure><ul class=""><li id="faf9" class="nk nl it lf b lg lh lj lk lm nm lq nn lu no ly np nq nr ns bi translated">持续时间(销售代表和潜在客户之间的对话持续了多长时间)，</li><li id="0d8b" class="nk nl it lf b lg pb lj pc lm pd lq pe lu pf ly np nq nr ns bi translated">联系人(同一营销活动中潜在客户的联系人数量)，</li><li id="eb11" class="nk nl it lf b lg pb lj pc lm pd lq pe lu pf ly np nq nr ns bi translated">月份(一年中的月份)。</li></ul><h1 id="af44" class="pg mj it bd mk ph pi pj mn pk pl pm mq ki pn kj mt kl po km mw ko pp kp mz pq bi translated">摘要</h1><p id="2bae" class="pw-post-body-paragraph ld le it lf b lg na kd li lj nb kg ll lm nc lo lp lq nd ls lt lu ne lw lx ly im bi translated">现在我们已经完成了所有的分析和预测模型，是时候设计一个营销策略了</p><ul class=""><li id="9b85" class="nk nl it lf b lg lh lj lk lm nm lq nn lu no ly np nq nr ns bi translated">从历史数据中，我们可以找出营销活动水平最高的月份。在此基础上，可以决定活动的时间。</li><li id="c0bb" class="nk nl it lf b lg pb lj pc lm pd lq pe lu pf ly np nq nr ns bi translated">从年龄类别中，我们可以向下钻取并找出现有存款人的平均年龄。在此基础上，活动可以在下一次活动中瞄准这个年龄。</li><li id="796b" class="nk nl it lf b lg pb lj pc lm pd lq pe lu pf ly np nq nr ns bi translated">职业也可能对存款有影响，这也可以从数据中挖掘出来。所以，这也给营销人员一些提示。</li><li id="a85b" class="nk nl it lf b lg pb lj pc lm pd lq pe lu pf ly np nq nr ns bi translated">从统计汇总中我们看到，持续时间越长(&gt; 372 ~371.99)，该目标群体开立定期存款账户的可能性越大。这个群体开立定期存款账户的可能性为 78%，这是相当高的。这将使得下一次营销活动的成功率非常高。</li></ul><p id="c103" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated"><strong class="lf jd"> <em class="nj">我这里可以到达</em></strong><a class="ae og" href="https://www.linkedin.com/in/saritmaitra/" rel="noopener ugc nofollow" target="_blank"><strong class="lf jd"><em class="nj"/></strong></a><strong class="lf jd"><em class="nj">。</em>T13】</strong></p></div></div>    
</body>
</html>