<html>
<head>
<title>Linear Regression from Scratch</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">从头开始线性回归</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/linear-regression-from-scratch-977cd3a1db16?source=collection_archive---------9-----------------------#2019-02-01">https://towardsdatascience.com/linear-regression-from-scratch-977cd3a1db16?source=collection_archive---------9-----------------------#2019-02-01</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><p id="ac3c" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">在过去的几周里，我一直在快速学习 Goodfellow 和 Bengio 的深度学习。我从中学到了很多。这本书探索了广泛的机器学习+深度学习主题，并深入研究了这些技术背后的数学。这是一个很好的资源，可以让你对这个领域有一个基本的了解。</p><p id="bc50" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">为了巩固我正在阅读的内容，我决定用 vanilla Python 和 numpy 对我正在研究的模型进行编码。如果可能的话，我还会创建一些正在发生的事情的基本可视化。</p><p id="2985" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">在这里，我将从本书的第一个也是最基本的模型开始:线性回归。事不宜迟，以下是我所做工作的概要。</p><h1 id="d538" class="km kn iq bd ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj bi translated">动机</h1><p id="03db" class="pw-post-body-paragraph jn jo iq jp b jq lk js jt ju ll jw jx jy lm ka kb kc ln ke kf kg lo ki kj kk ij bi translated">在我进入实现的肮脏细节之前，我想首先给出为什么要使用线性回归的一般概念。我们正在做的事情的动机是什么？</p><p id="ac17" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">嗯，一般来说，线性回归是一个很好的预测连续变量的模型，<strong class="jp ir"> y </strong>，基于一个连续的(有时是离散的)输入，<strong class="jp ir"> x </strong>。线性回归模型将输入<strong class="jp ir"> x </strong>组合在一起，对输出<strong class="jp ir"> y </strong>进行良好的预测。例如，我们可以使用一个线性回归模型来预测房子的价格，<strong class="jp ir"> y </strong>，<strong class="jp ir"> </strong>基于一些输入特征，<strong class="jp ir"> x </strong>(例如，平方英尺、卧室数量等。).</p><p id="f482" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><em class="lp">需要注意的一点是，首先需要数据(</em> <strong class="jp ir"> <em class="lp"> x </em> </strong> <em class="lp">，</em> <strong class="jp ir"> <em class="lp"> y </em> </strong> <em class="lp">对)来训练线性回归模型，然后才能做出准确的预测。稍后我们将详细讨论这是如何实现的。</em></p><h1 id="8d91" class="km kn iq bd ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj bi translated"><strong class="ak">实现！</strong></h1><p id="3521" class="pw-post-body-paragraph jn jo iq jp b jq lk js jt ju ll jw jx jy lm ka kb kc ln ke kf kg lo ki kj kk ij bi translated">线性回归模型的实施有<strong class="jp ir"> 5 个主要组成部分</strong>:模型、成本函数、参数、梯度和优化算法(如正常方程、梯度下降)。我们将在下面更深入地探讨每一个问题。</p><p id="7d9d" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><em class="lp">注意，这种实现推广到更高维度的空间。换句话说，它可以用(</em> <strong class="jp ir"> <em class="lp"> x </em> ₁ </strong> <em class="lp">，</em> <strong class="jp ir"> <em class="lp"> y </em> </strong> <em class="lp">)数据做线性回归，用(</em> <strong class="jp ir"> <em class="lp"> x </em> ₁ </strong> <em class="lp">，</em> <strong class="jp ir"> <em class="lp"> x </em> ₂ </strong> <em class="lp">，</em> <strong class="jp ir"> <em class="lp"> y </em> </strong> <em class="lp">) </em> <strong class="jp ir"> <em class="lp"> x </em> ₂ </strong> <em class="lp">，</em> <strong class="jp ir"> <em class="lp"> x </em> ₃ </strong> <em class="lp">，</em><strong class="jp ir"><em class="lp">y</em></strong><em class="lp">)4 个维度的数据，以此类推。 通常，我们的模型将(n-1)维超平面拟合到 n 维空间中的数据。</em></p><figure class="lr ls lt lu gt lv gh gi paragraph-image"><div role="button" tabindex="0" class="lw lx di ly bf lz"><div class="gh gi lq"><img src="../Images/ada1caa2f22311c2306cdadc3621b94d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*wURQXHrNjq7MmWHUkAeanQ.png"/></div></div></figure><h2 id="9c41" class="mc kn iq bd ko md me dn ks mf mg dp kw jy mh mi la kc mj mk le kg ml mm li mn bi translated">模型</h2><p id="f5c5" class="pw-post-body-paragraph jn jo iq jp b jq lk js jt ju ll jw jx jy lm ka kb kc ln ke kf kg lo ki kj kk ij bi translated">该模型由一个权重矩阵<strong class="jp ir"> W </strong>与我们的数据<strong class="jp ir"> X </strong>的基本线性组合来定义，其中添加了一个偏差项<strong class="jp ir"> b </strong>以使我们的预测偏离原点。</p><p id="44d2" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><em class="lp">这里注意@符号是矩阵乘法的。</em></p><figure class="lr ls lt lu gt lv"><div class="bz fp l di"><div class="mo mp l"/></div></figure><h2 id="f122" class="mc kn iq bd ko md me dn ks mf mg dp kw jy mh mi la kc mj mk le kg ml mm li mn bi translated">成本函数</h2><p id="fdee" class="pw-post-body-paragraph jn jo iq jp b jq lk js jt ju ll jw jx jy lm ka kb kc ln ke kf kg lo ki kj kk ij bi translated">成本函数设定线性回归的目标。它定义了我们想要达到的目标。一般来说，清楚地定义你的成本函数是很重要的。你不能击中一个目标，直到你定义它是什么，对不对？这里，我们将成本函数定义为所有训练示例中我们对<strong class="jp ir"> y </strong>的预测和<strong class="jp ir"> y </strong>的实际值之间的平均平方距离。</p><figure class="lr ls lt lu gt lv"><div class="bz fp l di"><div class="mo mp l"/></div></figure><h2 id="529f" class="mc kn iq bd ko md me dn ks mf mg dp kw jy mh mi la kc mj mk le kg ml mm li mn bi translated">参数</h2><p id="b258" class="pw-post-body-paragraph jn jo iq jp b jq lk js jt ju ll jw jx jy lm ka kb kc ln ke kf kg lo ki kj kk ij bi translated">我们需要初始参数的值。参数不需要接近完美，只是一些开始预测的东西。这里，我们将初始化<strong class="jp ir"> W </strong>为一个零向量，并将<strong class="jp ir"> b </strong>初始化为 0。参数初始化有点像你刚出生时的知识。你真的不知道发生了什么，但这是一个开始！</p><figure class="lr ls lt lu gt lv"><div class="bz fp l di"><div class="mo mp l"/></div></figure><h2 id="6092" class="mc kn iq bd ko md me dn ks mf mg dp kw jy mh mi la kc mj mk le kg ml mm li mn bi translated"><strong class="ak">坡度</strong></h2><p id="4618" class="pw-post-body-paragraph jn jo iq jp b jq lk js jt ju ll jw jx jy lm ka kb kc ln ke kf kg lo ki kj kk ij bi translated">我们使用梯度来学习我们的参数应该取什么值，以便最小化我们的成本函数。梯度公式是通过对我们的成本函数相对于<strong class="jp ir"> W </strong>和<strong class="jp ir"> b </strong>求导得到的。梯度为我们提供了移动<strong class="jp ir"> W </strong>和<strong class="jp ir"> b </strong>的方向，以便最小化我们的成本函数。请记住:通过最小化我们的成本函数，根据定义<em class="lp"/>，减少我们的模型对我们的训练数据的 T84 预测 T85 和地面真实值<strong class="jp ir">y</strong>之间的平方距离。</p><figure class="lr ls lt lu gt lv"><div class="bz fp l di"><div class="mo mp l"/></div></figure><h2 id="3d7c" class="mc kn iq bd ko md me dn ks mf mg dp kw jy mh mi la kc mj mk le kg ml mm li mn bi translated">优化算法</h2><p id="ed0c" class="pw-post-body-paragraph jn jo iq jp b jq lk js jt ju ll jw jx jy lm ka kb kc ln ke kf kg lo ki kj kk ij bi translated">我将在这里介绍两种优化算法:<strong class="jp ir">梯度下降</strong>，和<strong class="jp ir">正常方程</strong>。</p><p id="f14f" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">梯度下降包括使用梯度在多次连续迭代中最小化成本函数，直到它收敛(即，达到它的最低点)。梯度下降有两个需要调整的主要参数:历元数(即迭代次数)和学习速率(一个调整我们的<strong class="jp ir"> W </strong>和<strong class="jp ir"> b </strong>值的速率的值)。如果历元数和学习率设置充分，梯度下降应收敛于<strong class="jp ir"> W </strong>和<strong class="jp ir"> b </strong>的值。</p><figure class="lr ls lt lu gt lv"><div class="bz fp l di"><div class="mo mp l"/></div></figure><p id="34cf" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">法线方程是求解<strong class="jp ir"> W </strong>和<strong class="jp ir"> b </strong>的替代技术。注意这个算法是<em class="lp"> O </em> (n)其中 n 是训练样本的数量。</p><figure class="lr ls lt lu gt lv"><div class="bz fp l di"><div class="mo mp l"/></div></figure><h2 id="aa4a" class="mc kn iq bd ko md me dn ks mf mg dp kw jy mh mi la kc mj mk le kg ml mm li mn bi translated">把它放在一起</h2><p id="45d7" class="pw-post-body-paragraph jn jo iq jp b jq lk js jt ju ll jw jx jy lm ka kb kc ln ke kf kg lo ki kj kk ij bi translated">让我们把它们放在一起，运行模型！首先，我们将初始化参数，<strong class="jp ir"> W </strong>和<strong class="jp ir"> b </strong>。然后，我们将使用这些参数、<strong class="jp ir"> </strong>和我们的训练数据、<strong class="jp ir"> X </strong>和<strong class="jp ir"> y </strong>运行梯度下降，给出我们训练的<strong class="jp ir"> W </strong>和<strong class="jp ir"> b </strong>。由此，我们可以计算所有训练示例的平均成本。下面是我们的模型可以做什么的例子！</p><figure class="lr ls lt lu gt lv"><div class="bz fp l di"><div class="mo mp l"/></div></figure><figure class="lr ls lt lu gt lv gh gi paragraph-image"><div role="button" tabindex="0" class="lw lx di ly bf lz"><div class="gh gi lq"><img src="../Images/c66bbef29bc1854daa52c50199a8ea2b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/1*w7xxhJu2HSnw8BGAhDukcw.gif"/></div></div></figure><h1 id="0aaa" class="km kn iq bd ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj bi translated">回顾这次演习</h1><p id="4e8e" class="pw-post-body-paragraph jn jo iq jp b jq lk js jt ju ll jw jx jy lm ka kb kc ln ke kf kg lo ki kj kk ij bi translated">当我第一次从头开始编写线性回归代码时，我没有条理，老实说，我对这个问题没有很好的理解。我是说这能有多难？只是<em class="lp">基本的</em>线性回归。所以我开始写代码。</p><p id="eebe" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">嗯，我肯定是搬起石头砸了自己的脚，以为这很容易。我没有制定一个很好的计划来保持我的数据和我的模型的兼容性，也没有真正计划好模型的每一部分如何组合在一起。</p><p id="0860" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">这导致了一些抛出错误的 bug，这些 bug 很容易修复，但是其他的 bug 就不那么容易了。例如，我在我的代码中发现的最后一个错误发生在 numpy 会<a class="ae kl" href="https://docs.scipy.org/doc/numpy-1.15.0/user/basics.broadcasting.html" rel="noopener ugc nofollow" target="_blank">在整个<strong class="jp ir"> W </strong>矩阵中广播</a>一个错误计算的 d <strong class="jp ir"> W </strong>值时。</p><p id="21b1" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">因此，这里的经验教训是:(1)保持你的维度有组织，并有一个如何将你的模型和你的数据结合在一起的计划，(2)不要假设数据科学是容易的。</p><p id="f6af" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">总的来说，实施线性回归确实有助于巩固和构建我对该主题的理论理解。我期待将来实现更复杂的模型！</p></div></div>    
</body>
</html>