# 神经网络生成的上帝的羔羊鼓轨道

> 原文：<https://towardsdatascience.com/neural-networks-generated-lamb-of-god-drum-tracks-45d3a235e13a?source=collection_archive---------11----------------------->

## *使用不同神经网络结构生成鼓点的实验。*

![](img/7fac4fdffa31317c06ee3ebb89e7ae4c.png)

Photo by [Michael Dobrinski](https://unsplash.com/@micrinski?utm_source=medium&utm_medium=referral) on [Unsplash](https://unsplash.com?utm_source=medium&utm_medium=referral)

# 介绍

从去年 10 月开始，我就有了实现一些简单的神经网络来生成音乐的想法。我当时在 Jupyter 笔记本上做了一些快速实验，最近我终于有时间重写代码并写了一篇关于它的博客。 [LSTMetallica](https://keunwoochoi.wordpress.com/2016/02/23/lstmetallica/) 和[# neuralabeats](https://medium.com/@snikolov/neuralbeats-generative-techno-with-recurrent-neural-networks-3824d7ba7972)已经做了类似的工作。两位作者都使用 LSTM 在他们选择的几个鼓轨道上进行训练。对我来说，我选择上帝的羔羊。

*注:如果只对听成绩感兴趣，可以直接去成绩区。而代码可以在这里* *找到* [*。*](https://github.com/Witsung/machine_beats)

## 为什么打鼓？上帝的羔羊？

我的目标是敲鼓，这对我来说相当简单，因为在我决定出国留学之前，我一直和我的朋友在一个乐队打鼓。与《上帝的羔羊》相比，我们以前演奏的音乐要柔和得多，但我很欣赏克里斯·阿德勒的[低音鼓技巧](https://youtu.be/qQRww_NVJoQ?t=34)。(看看他在视频中演示的“简单”节拍。)此外，歌曲中还有更多有趣的鼓点图案。

选择 LoG 的另一个原因可能是因为与我喜欢的其他鼓手如史蒂夫·乔丹和亚伦·斯皮尔斯相比，它有更多的 MIDI 文件资源。

# 数据预处理

首先，让我们看看人类如何打鼓，以及为什么神经网络可能是产生鼓点的有前途的工具。演奏乐器是一门艺术，它可能受到多种原因的影响:情感、技巧、演奏者的技能等。然而，为了使音乐连贯，最重要的因素之一可能是过去演奏过的模式。

同样，我们可以认为打鼓是一个不断预测节奏的过程，我们要根据之前演奏过的节奏和模式来演奏。(当然，如果你在乐队演奏，需要考虑更多的信息，但这是另一个故事，我们在这里处理的是一个单一的鼓轨道。)

我没有直接在原始音频上训练模型，而是决定使用 MIDI 文件作为数据源，因为这种格式更容易为人理解，在调整模型时给我提供了更多的直觉。在谷歌上搜索一些关键词后，我能够找到一些 [LoG MIDI 音轨](http://en.midimelody.ru/lamb-of-god/)。在这个实验中，数据预处理几乎花费了我 70%的时间，所以我会更详细地研究这个过程。

为了在 python 中处理 MIDI 格式，我选择使用 [Mido](https://mido.readthedocs.io/en/latest/#) 来解析 MIDI 文件。Mido 将 MIDI 文件解析为一个对象，它由几个音轨组成，一般来说，每个音轨包含一个乐器的所有音符。

```
[<midi track '' 68 messages>,
 <midi track '' 4015 messages>,
 <midi track '' 3946 messages>,
 <midi track '' 3340 messages>,
 <midi track '' 5430 messages>,
 <midi track '' 839 messages>]
```

每个轨道都有几条信息，控制如何以及何时弹奏音符。如下所示，信息类型“音符开”和“音符关”控制乐器(“通道”)何时播放。通道 9 指示[打击乐器](https://en.wikipedia.org/wiki/General_MIDI#Percussion)和‘音符’代表应该演奏的确切乐器。还有其他类型的信息，但对于这个实验来说，“note_on”是最重要的一种。打击乐器通常不需要“note_off ”,因为它们没有长度，尽管建议在音符打开时使用“note_off”。

```
{'type': 'note_on', 'time': 0, 'note': 49, 'velocity': 95, 'channel': 9}
{'type': 'note_off', 'time': 240, 'note': 49, 'velocity': 95, 'channel': 9}
```

有了这些知识，首先要做的是量化，这意味着将信号限制在一个离散的集合中。在这种情况下，我想让每个音符都精确地在 32 个音符上演奏。我知道这可能会扭曲三连音和六连音，但大多数音符可以量化为一个 32 音。下图给出了一些音符经过一键编码后的数据框视图，其中 1 表示播放，0 表示不播放。列中的数字代表仪器。例如 36:大鼓。因此，我们要做的是**预测接下来的 32 个音符，根据我们之前的信息**应该演奏什么乐器。

![](img/141103469f98b1ea97dbfaf7db5ef90f.png)

为了降低复杂性，我删除了列，只保留了最常用的 n (6 或 8)种乐器，你可能已经注意到了，我也忽略了速度。

还有另一种编码方法，您可以对工具的每种组合进行编码，并创建一个新的分类变量。例如，如果我们选择编码 4 种乐器，那么总共我们将有 2⁴ = 16 种组合。这正是[# neural eats](https://medium.com/@snikolov/neuralbeats-generative-techno-with-recurrent-neural-networks-3824d7ba7972)所做的。然而，我发现在我的例子中，图中所示的编码方案效果更好。

# 型号

长短期记忆(LSTM)可能是大多数人在使用神经网络处理序列数据时会想到的。据说 LSTM 能够记住长期的依赖关系。我在这里不再赘述，因为已经有大量的[资源](http://colah.github.io/posts/2015-08-Understanding-LSTMs/)解释 LSTM。

另一方面，卷积神经网络(CNN)以图像分类、识别等而闻名，但最近的研究表明，它们也可以很好地处理序列数据。一个例子是 [WaveNet](https://deepmind.com/blog/wavenet-generative-model-raw-audio/) ，这是一个最先进的文本到语音的生成模型。作者还表明，它可以用于音乐生成。

我用 Keras 构建并训练了这两个模型。在大多数机器学习项目中，我使用早期停止来防止模型过度拟合，特别是我们不希望模型产生与他们看到的完全相同的节拍。除了模型结构，我还试验了两种模型的不同长度，32 个音符和 128 个音符。下图显示了具有 128 个输入长度的两个模型的训练损失和验证损失。正如你所看到的，CNN 能够很快捕捉模式，但开始在训练集上过度适应，而 LSTM 慢慢改善，直到最后一个时代结束，它仍然优于 CNN。虽然在我增加了周期之后，模型能够进一步改进，但我发现在我的实验中，LSTM 在输入长度较短的情况下工作得更好。我本可以继续尝试不同的 LSTM 设置，比如有状态的 LSTM，甚至是 CNN 和 LSTM 的组合。然而，调整模型以获得最佳性能并不是这个实验的目标。

![](img/159b409fad801108d8207b534f25beb0.png)

TensorBoard

# 结果

## 预期的

如果我们真的思考我们如何表述这个问题，它实际上并没有那么聪明。音乐中的大多数鼓点在大多数小节中都是重复的。最常见的模式是在每第四个小节的末尾添加鼓填充。从下面的鼓点音符可以看出，通常每行的结尾都有不同的节拍。比方说，如果我们将 32 个 32 音符拟合到一个模型，并要求它预测下一个音符。那么它只需要准确预测输入序列中的第一个 32 音符。困难的部分可能是检测这个 4-bar 循环和预测相应的鼓填充。

![](img/605a0e08885ce4a36d85dd095e0069d4.png)

Source: [https://alanlinmusic.blogspot.com/](https://alanlinmusic.blogspot.com/)

除了查看评估指标之外，我决定通过直接听它在两种场景中生成的节拍来检查模型的质量。

首先，由于输入-输出设置，我们需要提前多步预测来创建模式，否则，模型只会提前一步进行预测。(一个 32 注)有几种方法可以做到这一点，其中一种是递归预测，这意味着我们把预测的结果带到下一个输入，递归预测，直到我们达到理想的长度。在递归设置中，我希望模型至少能以相同的长度复制给定的音符，并继续这样做直到结束。

第二个设置是连接所有提前一步的预测，以获得目标长度的鼓点。期望值应该更高，因为在每个时间步，模型都得到鼓手演奏的真实情况。一个好的模型不仅应该能够复制给定的节拍，而且**还应该能够检测真正的歌曲所显示的鼓填充和循环**。

## 音乐时间！

最后，我们先来听听模型在这两种场景下的表现。

***LSTM:递归***

节拍全部由在 128 个输入长度上训练的模型生成。我在开始的时候连接了真实的输入，这样我们就可以听到模型实际得到了什么。你可以发现这个模型做得很差，它甚至不能检测到轨道 1 和 2 的 1 条形图案。第三轨道由在 32 个输入长度上训练的 LSTM 产生。幸运的是，它至少捕获了 1 barpattern，并重复生成它，直到结束。

LSTM Recursive

***LSTM:直接***

正如我们所预期的，由于模型每一步都获得了基本事实，因此模型不会重复预测。但是产生的节拍还是不太好听，尤其是音轨 1 的有线低音鼓。我猜它试图预测六连音，但被迫量化为 32 音。总的来说，我认为 LSTM 可以通过增加周期和减少合理批量的输入长度来改善。如前所述，人们也可以尝试不同的结构。在这篇文章中，我只想展示一个糟糕的模型和一个更好的模型相比听起来会是什么样子。如果你对更好的结果感兴趣，让我们继续。

LSTM Direct

**CNN:递归**

酷！看起来 CNN 不仅能探测到 1 个条形图案，还能“随机应变”一点。请注意，前 4 个小节是输入。

CNN Recursive

**CNN:直接**

生成的轨迹越来越逼真。

CNN Direct

## 模式条形图

除了直接听生成的音轨，我在想一个目测模型质量的方法。对于基数时间序列分析，有自相关图、时间图等。训练模型后，可以使用这些工具来检查残差，看看您的模型是否仍然遗漏了一些有用的信息。

然而，我们处理的是分类时间序列数据，分类变量缺乏自然顺序。最终，我找到了这篇[论文](https://www.sciencedirect.com/science/article/abs/pii/S1572312707000329)，它展示了一些可视化工具，尤其是针对分类时间序列数据。其中之一是模式直方图，我认为比较生成的模式和真实的模式是一种很好的可视化方式。

基本思想是计算事件发生后直到期望时间的频率。例如，如果我们想要得到长度为 128 的低音鼓模式，我们得到所有出现的低音鼓及其后面的 128 个音符，以查看低音鼓在 128 个步骤中每一步演奏的频率。你可以看到下面的数字。低音鼓似乎是最常见的。(是克里斯·阿德勒……)一般来说，每个 8，16，32 音符等都有尖锋。

![](img/68f8ffac4d3b57ebb21b92d7e68d78b8.png)

Bass Drum Pattern

![](img/c472a16fcf5d6b3338bb15f743591bff.png)

Snare Drum Pattern

![](img/5763d04b9a099fea1d22a005bf86edce.png)

Open Hi-hat Pattern

![](img/abb2e5c298567882bc2db75babb0db06.png)

Crash Pattern

如果我们直接将预测的模式条形图与真实的模式条形图进行比较，我们可以看到该模型能够捕捉整个低音鼓模式，对于小鼓，该模型可以检测到每第 16 个音符的尖峰，但似乎无法找到其间的模式。然而，仅仅通过视觉上的比较，很难发现低音鼓有什么不同。更好的解决方法是从真实值中减去预测值。

![](img/a087260bad5308e4cf32f0ef0f6b8c56.png)

Patterns Comparison

我认为扣除后的值是某种鼓形预测的残差。如下图所示，一般来说，模型预测的演奏节拍比真实模式少，因为所有乐器都有显著的正差异(真实预测)。例如，这可以通过将阈值从 0.5 降低到 0.4 来解决。

![](img/e269b1a63c3d8f0ae29c682d382ac828.png)

Pattern “Residuals” Comparison

# 结论

用算法生成音乐并不是什么新鲜事。而且严格来说，经过训练的模型并没有真正“生成”鼓轨。模型的损失函数(二进制交叉熵)的设置只是简单地要求模型完全像 Chris Adler 那样运行，这是分类问题的典型设置。这个小实验中最接近的一个可能是让模型递归预测，但是正如我们可以看到的，模型往往在一定长度后重复相同的模式，而没有捕捉到长期结构。我们不能责怪模型，这只是基于模型训练的最安全的猜测。一些[研究](https://magenta.tensorflow.org/2016/07/15/lookback-rnn-attention-rnn)引入了额外的结构，如注意力 RNN 和回望 RNN 来解决这个问题。对于 CNN，模型检测长期结构的最直接的方法可能是增加输入的长度以包括大多数模式。

然而，为了更好地实现应用神经网络生成音乐的想法，有一些先进的神经网络结构，如[生成对抗网络](https://skymind.ai/wiki/generative-adversarial-network-gan)或[变化自动编码器](http://kvfrans.com/variational-autoencoders-explained/)。它们已经被应用到图像和[音乐](https://arxiv.org/abs/1703.10847)一代。实现一个生成网络来生成鼓点将是写另一篇博文的好主意。

[1]韦奥希，2008 年。分类时间序列的可视化分析。*统计方法论*， *5* (1)，第 56–71 页。

[2]杨立春，周思燕，杨耀辉，2017。一个用于符号域音乐生成的卷积生成对抗网络。 *arXiv 预印本 arXiv:1703.10847* 。