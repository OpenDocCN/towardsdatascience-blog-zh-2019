# NLP ç¬¬ 1 éƒ¨åˆ†|ä½¿ç”¨ BeautifulSoup å’Œ Python æŠ“å– Web

> åŸæ–‡ï¼š<https://towardsdatascience.com/scraping-the-web-using-beautifulsoup-and-python-5df8e63d9de3?source=collection_archive---------3----------------------->

![](img/828486085c10d727d20e8c91f2ead867.png)

Photo by [Patrick Selin](https://unsplash.com/@patuphotos?utm_source=medium&utm_medium=referral) on [Unsplash](https://unsplash.com?utm_source=medium&utm_medium=referral)

æ•°æ®æ˜¯ä»»ä½•æ•°æ®ç§‘å­¦é¡¹ç›®çš„æ ¸å¿ƒï¼Œç„¶è€Œæˆ‘ä»¬å¸¸å¸¸è®¤ä¸ºæ•°æ®çš„å¯ç”¨æ€§æ˜¯ç†æ‰€å½“ç„¶çš„ï¼Œå°¤å…¶æ˜¯å½“å®ƒæ•´é½åœ°å‡ºç°åœ¨ SQL æ•°æ®åº“ä¸­æˆ–è€…æ›´å¥½åœ°å‡ºç°åœ¨æˆ‘ä»¬çš„æ”¶ä»¶ç®±ä¸­æ—¶ã€‚

ä¹Ÿå°±æ˜¯è¯´ï¼Œç”±äºå…¶ç‰¹å®šçš„æ€§è´¨ï¼Œæœ‰æ—¶æ‚¨æ­£åœ¨å¯»æ‰¾çš„æ•°æ®å¹¶ä¸å®¹æ˜“è·å¾—ã€‚è¿™ä¸ªé—®é¢˜çš„ä¸€ä¸ªå¯èƒ½çš„è§£å†³æ–¹æ¡ˆæ˜¯**ç½‘ç»œæŠ“å–**çš„æƒ³æ³•ï¼Œæˆ–è€…é€šè¿‡ä»”ç»†é˜…è¯»ç‰¹å®šç½‘ç«™çš„ HTML ä»è¯¥ç½‘ç«™æå–ä¿¡æ¯ã€‚ä¾‹å¦‚ï¼Œè®©æˆ‘ä»¬è¯´ä½ æ­£åœ¨è®¡åˆ’ä¸€ä¸ªå‡æœŸï¼Œä½ åœ¨å¯»æ‰¾æœºç¥¨ä½•æ—¶å¼€å§‹é”€å”®ã€‚æ˜¯çš„ï¼Œä½ å¯ä»¥æ¯å°æ—¶æµè§ˆåŒä¸€ä¸ªæ—…æ¸¸ç½‘ç«™ï¼Œå¸Œæœ›ä»·æ ¼ä¼šä¸‹é™ï¼Œä½†æ›´æœ‰æ•ˆçš„æ–¹æ³•æ˜¯æ¯å°æ—¶æµè§ˆæ—…æ¸¸ç½‘ç«™ï¼Œå¹¶æœ‰ä¸€ä¸ªè¾“å‡ºæ–‡ä»¶ä¸ºä½ æä¾›æœ€æ–°çš„ç¥¨ä»·ã€‚

## æ”¾å¼ƒ

è®¸å¤šç½‘ç«™ä¸å¸Œæœ›è‡ªå·±çš„æ•°æ®è¢«çªƒå–ï¼Œå°¤å…¶æ˜¯å½“è¿™äº›æ•°æ®åŒ…å«å¯è¯†åˆ«çš„ç”¨æˆ·ä¿¡æ¯æ—¶(å¦‚è„¸ä¹¦ã€Linkedin ç­‰)ã€‚).è¯·è€ƒè™‘æ‚¨é€‰æ‹©åˆ®å–å“ªäº›æ•°æ®ä»¥åŠåˆ®å–çš„é¢‘ç‡ã€‚

## NLP ç³»åˆ—

è¿™ä¸ªç®€çŸ­çš„æ•™ç¨‹æ˜¯å…³äºè‡ªç„¶è¯­è¨€å¤„ç†(NLP)çš„ 3 éƒ¨åˆ†ç³»åˆ—çš„ç¬¬ä¸€éƒ¨åˆ†ã€‚åœ¨è¿™ä¸ªç³»åˆ—ä¸­ï¼Œæˆ‘ä»¬å°†æ¢ç´¢æŠ“å–ç½‘ç«™æ•°æ®çš„æŠ€æœ¯ï¼Œé¢„å¤„ç†å¹¶å‡†å¤‡å¥½æ•°æ®ä»¥ä¾›åˆ†æï¼Œæœ€åä»æˆ‘ä»¬çš„ NLP æ•°æ®ä¸­æ”¶é›†è§è§£ã€‚

[NLP ç¬¬äºŒéƒ¨](https://medium.com/@kamilmysiak/preprocessing-text-data-using-python-576206753c28)

[NLP ç¬¬ä¸‰éƒ¨](https://medium.com/@kamilmysiak/nlp-part-3-exploratory-data-analysis-of-text-data-1caa8ab3f79d)

# ä» Indeed.com æœé›†å…¬å¸è¯„è®º

åœ¨è¿™ä¸ªä¾‹å­ä¸­ï¼Œè®©æˆ‘ä»¬å°è¯•æŠ“å– indeed.comï¼Œä½†å…·ä½“æ¥è¯´æ˜¯å…¬å¸è¯„è®ºã€‚è®©æˆ‘ä»¬é’ˆå¯¹å‘˜å·¥çš„è¯„åˆ†ã€è¯„ä¼°èŒç§°ã€è¯„ä¼°æè¿°ä»¥åŠä¼˜ç‚¹å’Œç¼ºç‚¹ã€‚

![](img/0fe9687a9a55f5260c3fb06613ca5328.png)

## HTML åŸºç¡€

åœ¨æˆ‘ä»¬çœŸæ­£å¼€å§‹æ”¶é›†ä¿¡æ¯ä¹‹å‰ï¼Œæˆ‘ä»¬éœ€è¦ç†Ÿæ‚‰ HTML çš„åŸºæœ¬ç»“æ„ï¼Œå› ä¸ºæˆ‘ä»¬å®é™…ä¸Šå°†ä½¿ç”¨ HTML æ ‡ç­¾æ¥æ ‡è¯†æˆ‘ä»¬å¸Œæœ›æ”¶é›†çš„ä¿¡æ¯ã€‚

æˆ‘ä»¬å¯ä»¥é€šè¿‡åœ¨æ‚¨å½“å‰çš„æµè§ˆå™¨ä¸­æ‰“å¼€å¼€å‘è€…å·¥å…·æ¥è®¿é—®ç½‘ç«™çš„ HTMLã€‚æ¯”å¦‚ Firefox(é€‰é¡¹â†’ Web Developer â†’ Inspector)ã€‚æ‰€æœ‰è¿™äº›è“è‰²çš„â€œdivâ€æ ‡ç­¾ã€ç®­å¤´ã€ç±»å’Œ id å°±æ˜¯ä½ å½“å‰æ‰€åœ¨ç½‘ç«™çš„ HTMLã€‚

![](img/6d9f205e94f9f93b826ab1e41b96c04d.png)

åœ¨æˆ‘ä»¬ç ”ç©¶ indeed.com çš„ HTML ä¹‹å‰ï¼Œè®©æˆ‘ä»¬ç”¨ä¸‹é¢çš„ä¾‹å­å›é¡¾ä¸€ä¸‹å®ƒçš„åŸºæœ¬ç»“æ„ã€‚

![](img/7ffb698d4f13a8383660180acd7e0f0d.png)

HTML æè¿°äº†ç½‘ç«™çš„åº•å±‚ç»“æ„ã€‚æ¢å¥è¯è¯´ï¼Œå®ƒæ ‡è¯†äº†ç½‘ç«™å°†æœ‰ä¸€ä¸ªæ ‡é¢˜ï¼Œå¤šä¸ªæ®µè½ï¼Œä¸€ä¸ªåµŒå…¥çš„è§†é¢‘ï¼Œä¸€ä¸ªç»“æŸé¡µè„šï¼Œç­‰ç­‰ã€‚HTML ä¸ä¼šæè¿°è¿™äº›ç»„ä»¶å°†å¦‚ä½•æ’åˆ—ï¼Œå®ƒä»¬çš„æ ·å¼ã€å¤§å°ã€é¢œè‰²ç­‰ã€‚

HTML ä»£ç æœ¬è´¨ä¸Šæ˜¯åˆ†å±‚çš„ï¼Œç¼©è¿›çš„æ ‡ç­¾(å³ã€‚

ã€

## Python ä»£ç 

é¦–å…ˆï¼Œæˆ‘ä»¬éœ€è¦å¯¼å…¥æ‰€éœ€çš„åº“ã€‚

```
from bs4 import BeautifulSoup
import lxml
import requests
import pandas as pd
import numpy as np
```

å¯¼å…¥çš„â€œrequestâ€åº“æœ‰ä¸€ä¸ª get()å‡½æ•°ï¼Œå®ƒå°†å‘ indeed.com æœåŠ¡å™¨è¯·æ±‚ URL çš„å†…å®¹ï¼Œå¹¶å°†æœåŠ¡å™¨çš„å“åº”å­˜å‚¨åœ¨â€œbase_urlâ€å˜é‡ä¸­ã€‚å¦‚æœæˆ‘ä»¬æ‰“å°â€œbase_urlâ€å˜é‡ï¼Œæˆ‘ä»¬å°†å®é™…çœ‹åˆ°é¡µé¢çš„æ•´ä¸ª HTMLã€‚

```
base_url = requests.get('[https://www.indeed.com/cmp/Google/reviews?fcountry=ALL&start='](https://www.indeed.com/cmp/Google/reviews?fcountry=ALL&start='), timeout=5)print(base_url.text)
```

![](img/10462758cd1d9c95dd23c19dc4fe2e6f.png)

è®©æˆ‘ä»¬é¦–å…ˆå®šä¹‰ä¸€ä¸ªåä¸ºâ€œparseâ€çš„å‡½æ•°ï¼Œå®ƒéœ€è¦ä¸€ä¸ªå‚æ•°ï¼Œè¿™ä¸ªå‚æ•°å°†æ˜¯æˆ‘ä»¬è¯•å›¾è§£æ/æŠ“å–çš„é¡µé¢çš„å®é™… URLã€‚æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨ BeautifulSoup ç±»åˆ›å»ºå™¨æ¥è§£ææ‰€æä¾›ç½‘ç«™çš„å†…å®¹(HTML ä»£ç )ã€‚æˆ‘ä»¬å°†ä½¿ç”¨â€œlxmlâ€è§£æå™¨ï¼Œä»¥é˜² HTML æ ¼å¼ä¸å®Œç¾ã€‚æ›´å¤šå…³äº BeautifulSoup å¯ç”¨çš„ä¸åŒè§£æå™¨çš„ä¿¡æ¯ï¼Œè¯·è®¿é—®è¿™ä¸ª[é“¾æ¥](https://www.crummy.com/software/BeautifulSoup/bs4/doc/#specifying-the-parser-to-use)ã€‚

> è¯·è®°ä½ï¼Œç½‘ç«™é€šå¸¸ä¼šé€šè¿‡æ›´æ”¹å®¹å™¨ä¸­é¡¹ç›®çš„åç§°æˆ–çˆ¶/å­å…³ç³»æ¥è°ƒæ•´å…¶ HTML è„šæœ¬ã€‚è¿™äº›å˜åŒ–éœ€è¦ä½ è°ƒæ•´ä½ çš„èŒèƒ½ã€‚è¯¥å‡½æ•°äº 6 æœˆ 20 æ—¥è¿›è¡Œäº†è°ƒæ•´ï¼Œä»¥ä¿®å¤æ–°å®ç°çš„ indeed.com HTML è„šæœ¬

```
def parse(full_url):
    **page_content = BeautifulSoup(full_url.content, 'lxml')**
    containers = page_content.findAll('div', 
                 {'class':'cmp-Review-container'})
    df = pd.DataFrame(columns = 
         ['rating', 'rating_title',  'rating_description',
                         'rating_pros', 'rating_cons'])

    for item in containers:
        try:
            rating = item.find('div', 
                     {'class': 'cmp-ReviewRating-text'})
                     .text.replace('\n', '')
        except:
            rating = None
        try:
            rating_title = item.find('div', 
                           {'class': 'cmp-Review-title'})
                           .text.replace('\n', '')
        except:
            rating_title = None
        try:
            rating_description = item.find('span', 
                                 {'itemprop': 'reviewBody'})
                                 .text.replace('\r', '. ')
        except:
            rating_description = None
        try:
            rating_pros = item.find('div', 
                          {'class': 'cmp-ReviewProsCons-prosText'})
                          .text.replace('\n', '')
        except:
            rating_pros = None
        try:
            rating_cons = item.find('div', 
                          {'class': 'cmp-ReviewProsCons-consText'})
                          .text.replace('\n', '')
        except:
            rating_cons = None
        df = df.append({'rating': rating, 
             'rating_title': rating_title, 
             'rating_description': rating_description,
             'rating_pros': rating_pros, 
             'rating_cons': rating_cons}, ignore_index=True)
    return df
```

æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬éœ€è¦æ›´ä»”ç»†åœ°æ£€æŸ¥ HTML ä»¥è¯†åˆ«å“ªä¸ªæ ¹å®¹å™¨(å³å“ªä¸ªçˆ¶æ ‡ç­¾)å®¹çº³åŒ…å«æˆ‘ä»¬è¦æŠ“å–çš„ä¿¡æ¯çš„å­/åµŒå¥—æ ‡ç­¾ã€‚è®©æˆ‘ä»¬å¯¼èˆªåˆ°â€œ[https://www.indeed.com/cmp/Google/reviews?fcountry=ALL&start =](https://www.indeed.com/cmp/Google/reviews?fcountry=ALL&start=)â€ï¼Œå› ä¸ºæˆ‘ä»¬å°†æ”¶é›†å‘˜å·¥å¯¹è°·æ­Œçš„è¯„è®ºã€‚æ‰“å¼€æ‚¨çš„å¼€å‘å·¥å…·ï¼Œè§‚å¯Ÿç½‘ç«™çš„ HTMLã€‚è¯·æ³¨æ„ï¼Œä¸€æ—¦æ‚¨è®¿é—®äº†ç½‘ç«™çš„ HTMLï¼Œåœ¨ç½‘ç«™ä¸Šç§»åŠ¨é¼ æ ‡å…‰æ ‡ä¼šå¯¼è‡´ç‰¹å®šåŒºåŸŸé«˜äº®æ˜¾ç¤ºï¼Œå¹¶ä¸” HTML ä¼¼ä¹ä¼šéšç€æ‚¨ç§»åŠ¨å…‰æ ‡è€Œæ”¹å˜ã€‚å½“æ‚¨ç§»åŠ¨å…‰æ ‡æ—¶ï¼Œæ‚¨çš„å¼€å‘è€…å·¥å…·ä¼šè‡ªåŠ¨å°†æ‚¨å¸¦åˆ°ç½‘é¡µä¸Šçªå‡ºæ˜¾ç¤ºéƒ¨åˆ†çš„ HTML éƒ¨åˆ†ã€‚è¿™éå¸¸æœ‰å¸®åŠ©ï¼Œå› ä¸ºæˆ‘ä»¬å¯ä»¥å¿«é€Ÿè¯†åˆ« HTML ä»£ç ä¸­éœ€è¦æ›´è¯¦ç»†æ£€æŸ¥çš„éƒ¨åˆ†ã€‚

å¦‚æœæ‚¨è¿˜è®°å¾—ï¼Œåœ¨æœ¬æ•™ç¨‹ä¸­ï¼Œæˆ‘ä»¬æ„Ÿå…´è¶£çš„æ˜¯æ”¶é›†å‘˜å·¥çš„æ€»ä½“è¯„åˆ†ã€è€ƒæ ¸æ ‡é¢˜ã€è€ƒæ ¸æè¿°ã€ä¼˜ç‚¹å’Œç¼ºç‚¹ã€‚æˆ‘ä»¬éœ€è¦è¯†åˆ«å“ªä¸ª HTML æ ‡ç­¾æ˜¯æ‰€æœ‰è¿™äº›ä¿¡æ¯çš„å®¹å™¨æˆ–å®¶ã€‚é€šè¿‡å°†é¼ æ ‡å…‰æ ‡ç§»åŠ¨åˆ°é€‚å½“çš„ä½ç½®ï¼Œæˆ‘ä»¬çœ‹åˆ°æ‰€æœ‰æˆ‘ä»¬æƒ³è¦æŠ“å–çš„ä¿¡æ¯éƒ½æ•´é½åœ°åŒ…å«åœ¨ä¸€ä¸ªæ ¹å…ƒç´ ä¸­ã€‚é€šè¿‡æ£€æŸ¥ä¸‹é¢çš„ HTMLï¼Œæˆ‘ä»¬å¯ä»¥çœ‹åˆ°â€œ

â€ç°åœ¨ç§»åŠ¨åˆ°ä¸€ä¸ªä¸åŒçš„è¯„è®ºï¼Œæ‚¨å°†çœ‹åˆ°åä¸ºâ€œcmp-Review-containerâ€çš„åŒä¸€ä¸ªç±»å±æ€§ï¼Œå®ƒå­˜å‚¨è¯¥è¯„è®ºçš„æ•°æ®ã€‚![](img/d87b3c7e8019256a542e48016809b696.png)

å› æ­¤ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨â€œfindall()â€æ–¹æ³•æå–æ‰€æœ‰å…·æœ‰â€œcmp-Review-containerâ€ç±»å±æ€§çš„â€œdivâ€å®¹å™¨ã€‚æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬å°†åˆ›å»ºä¸€ä¸ªåä¸ºâ€œdfâ€çš„ç©º pandas æ•°æ®å¸§ï¼Œæˆ‘ä»¬å°†æŠŠæŠ“å–çš„æ•°æ®è¿½åŠ åˆ°è¯¥æ•°æ®å¸§ä¸­ã€‚

```
def parse(full_url):
    page_content = BeautifulSoup(full_url.content, 'lxml')
    **containers = page_content.findAll('div', 
                 {'class':'cmp-Review-container'})
    df = pd.DataFrame(columns = 
         ['rating', 'rating_title',  'rating_description',
                         'rating_pros', 'rating_cons'])**

    for item in containers:        
        try:
            rating = item.find('div', 
                     {'class': 'cmp-ReviewRating-text'})
                     .text.replace('\n', '')
        except:
            rating = None
        try:
            rating_title = item.find('div', 
                           {'class': 'cmp-Review-title'})
                           .text.replace('\n', '')
        except:
            rating_title = None
        try:
            rating_description = item.find('span', 
                                 {'itemprop': 'reviewBody'})
                                 .text.replace('\r', '. ')
        except:
            rating_description = None
        try:
            rating_pros = item.find('div', 
                          {'class': 'cmp-ReviewProsCons-prosText'})
                          .text.replace('\n', '')
        except:
            rating_pros = None
        try:
            rating_cons = item.find('div', 
                          {'class': 'cmp-ReviewProsCons-consText'})
                          .text.replace('\n', '')
        except:
            rating_cons = None
        df = df.append({'rating': rating, 
             'rating_title': rating_title, 
             'rating_description': rating_description,
             'rating_pros': rating_pros, 
             'rating_cons': rating_cons}, ignore_index=True)
    return df
```

æ—¢ç„¶æˆ‘ä»¬å·²ç»ä¸ºæ‰€æœ‰æƒ³è¦æŠ“å–çš„æ•°æ®ç¡®å®šäº†å®¹å™¨ï¼Œé‚£ä¹ˆè®©æˆ‘ä»¬æ›´æ·±å…¥åœ°ç ”ç©¶ HTMLï¼Œä»¥ç¡®å®šåŒ…å«å®é™…æ•°æ®çš„å…ƒç´ ã€‚é¦–å…ˆï¼Œè¯„è®ºè¯„çº§å†æ¬¡ä½äºâ€œcmp-Review-containerâ€å®¹å™¨ä¸­ï¼Œä½†æ˜¯å‘ä¸‹é’»å‡ å±‚ï¼Œæˆ‘ä»¬ä¼šå‘ç°â€œ< divâ€æ ‡è®°å…·æœ‰â€œcmp-ReviewRating-textâ€ç±»å±æ€§ï¼Œå®ƒå®é™…ä¸Šå­˜å‚¨äº†â€œ5.0â€è¯„çº§ã€‚è®©æˆ‘ä»¬è®°ä¸‹å­˜å‚¨è¿™äº›æ•°æ®çš„æ ‡ç­¾å’Œç±»å±æ€§ï¼Œå› ä¸ºä¸‹é¢çš„ python è„šæœ¬éœ€è¦è¿™äº›ä¿¡æ¯ã€‚æˆ‘ä»¬å¯¹å¸Œæœ›æå–çš„æ‰€æœ‰å‰©ä½™æ•°æ®é‡å¤è¯¥è¿‡ç¨‹ã€‚

![](img/9f84238d96efc42f446690f3ba84665e.png)![](img/eacc80d16df49d120a76debd32c44cec.png)

> è¿™æ˜¯å¯¹ä½ çš„æŒ‘æˆ˜ã€‚ä¸ºä»€ä¹ˆæˆ‘ä»¬è¦ç”¨(")æ›¿æ¢å›è½¦(" \r "))ä¸ºæˆ‘ä»¬è¯„åˆ† _ æè¿°ï¼Ÿæç¤º:æ ‡é¢˜ä¸ºâ€œå·¥ä½œç¯å¢ƒæ£’â€å’Œâ€œå·¥ä½œç¯å¢ƒå¥½â€çš„è¯„è®ºæœ‰ä»€ä¹ˆåŒºåˆ«ï¼Ÿåœ¨ä¸‹é¢çš„è¯„è®ºä¸­å‘è¡¨ä½ çš„ç­”æ¡ˆå§ï¼ğŸ˜‰

ä¸€æ—¦æˆ‘ä»¬ä¸ºæ•°æ®ç¡®å®šäº†åˆé€‚çš„æ ‡ç­¾ï¼Œè®©æˆ‘ä»¬æŠŠæ³¨æ„åŠ›è½¬å›åˆ° python ä»£ç ä¸Šã€‚æˆ‘ä»¬å¯ä»¥åœ¨ for å¾ªç¯ä¸­ä½¿ç”¨ try/except å—ï¼Œé€šè¿‡ find()æ–¹æ³•åœ¨å®¹å™¨ä¸­æœç´¢å·²è¯†åˆ«çš„æ ‡ç­¾ã€‚æˆ‘ä»¬ä½¿ç”¨ find()è€Œä¸æ˜¯ findall()ï¼Œå› ä¸ºæˆ‘ä»¬åªå¸Œæœ›è¿”å›ç¬¬ä¸€ä¸ªåŒ¹é…ï¼Œå› ä¸ºæˆ‘ä»¬ä½¿ç”¨äº† for å¾ªç¯ã€‚æœ€åï¼Œæˆ‘ä»¬å°†æŠ“å–çš„æ•°æ®è¿½åŠ å›ä¹‹å‰åˆ›å»ºçš„ç©ºæ•°æ®å¸§ä¸­ã€‚

```
def parse(full_url):
    page_content = BeautifulSoup(full_url.content, 'lxml')
    containers = page_content.findAll('div', 
                 {'class':'cmp-Review-container'})
    df = pd.DataFrame(columns = 
         ['rating', 'rating_title',  'rating_description',
                         'rating_pros', 'rating_cons']**)**

    for item in containers:        
        try:
            **rating = item.find('div', 
                     {'class': 'cmp-ReviewRating-text'})
                     .text.replace('\n', '')**
        except:
            rating = None
        try:
            **rating_title = item.find('div', 
                           {'class': 'cmp-Review-title'})
                           .text.replace('\n', '')**
        except:
            rating_title = None
        try:
            **rating_description = item.find('span', 
                                 {'itemprop': 'reviewBody'})
                                 .text.replace('\r', '. ')**
        except:
            rating_description = None
        try:
            **rating_pros = item.find('div', 
                          {'class': 'cmp-ReviewProsCons-prosText'})
                          .text.replace('\n', '')**
        except:
            rating_pros = None
        try:
            **rating_cons = item.find('div', 
                          {'class': 'cmp-ReviewProsCons-consText'})
                          .text.replace('\n', '')**
        **except:
            rating_cons = None
        df = df.append({'rating': rating, 
             'rating_title': rating_title, 
             'rating_description': rating_description,
             'rating_pros': rating_pros, 
             'rating_cons': rating_cons}, ignore_index=True)**
    return df
```

æˆ‘ä»¬è¿˜æ²¡æœ‰å®Œæˆï¼Œå› ä¸ºå¦‚æœæ‚¨è¦æ‰§è¡Œâ€œparse()â€å‡½æ•°ï¼Œæ‚¨å°†è·å¾—ä¸€ä¸ªåªæœ‰ 20 æ¡è®°å½•çš„æ•°æ®å¸§ï¼Œè¿™æ˜¯å› ä¸ºæˆ‘ä»¬åªæŠ“å–äº†ä¸€é¡µã€‚

ä¸ºäº†æŠ“å–æ‰€æœ‰å‰©ä½™çš„è¯„è®ºé¡µé¢ï¼Œæˆ‘ä»¬é¦–å…ˆåˆ›å»ºä¸€ä¸ªæ–°çš„ç©ºæ•°æ®æ¡†æ¶ï¼Œåœ¨éå†æ‰€æœ‰é¡µé¢æ—¶æ”¶é›†æ‰€æœ‰çš„è¯„è®ºã€‚æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬åˆå§‹åŒ–ä¸€ä¸ªè®¡æ•°å™¨å˜é‡ 20ï¼Œå› ä¸ºæ¯é¡µæœ‰ 20 æ¡è¯„è®ºã€‚æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬åˆ›å»ºä¸€ä¸ª while-loopï¼Œå®ƒå°†è¿­ä»£ç›´åˆ°è¯„è®ºçš„æ•°é‡ç­‰äºæˆ–å¤§äº 4000ã€‚ä¸ºä»€ä¹ˆæ˜¯ 4000ï¼Ÿæ‰€æœ‰é¡µé¢ä¸Šæœ‰å°†è¿‘ 4000 æ¡ä¸ªäººè¯„è®º(åœ¨æ’°å†™æœ¬æ–‡æ—¶)ã€‚æ¥ä¸‹æ¥ï¼Œå½“ while å¾ªç¯éå†æ¯ä¸ªé¡µé¢æ—¶ï¼Œæˆ‘ä»¬åœ¨ base_url çš„æœ«å°¾æ·»åŠ å¢é‡ 20ã€‚åœ¨ base_url çš„æœ«å°¾å¢åŠ  20 å°†ä¸ºæ‚¨å¸Œæœ›è®¿é—®çš„é¡µé¢åˆ›å»ºä¸€ä¸ªæ–°çš„ urlã€‚ä¾‹å¦‚ï¼Œâ€œ[https://www.indeed.com/cmp/Google/reviews?fcountry=ALL&start =](https://www.indeed.com/cmp/Google/reviews?fcountry=ALL&start=)40â€å°†æŠŠæˆ‘ä»¬å¸¦åˆ°è¯„è®ºçš„ç¬¬äºŒé¡µã€‚æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬å†æ¬¡è¯·æ±‚å¹¶è·å– while å¾ªç¯æ­£åœ¨è¿­ä»£çš„é¡µé¢çš„æ•´ä¸ª HTMLã€‚æˆ‘ä»¬åœ¨é¡µé¢ä¸Šåº”ç”¨ parse()å‡½æ•°ï¼Œå°†æ–°æŠ“å–çš„è¯„è®ºæ·»åŠ åˆ°æˆ‘ä»¬çš„æ•°æ®å¸§ä¸­ã€‚æœ€åï¼Œæˆ‘ä»¬å°†è®¡æ•°å™¨å¢åŠ  20ï¼Œä»¥ä¾¿ while å¾ªç¯åœ¨ä¸‹ä¸€é¡µä¸Šè¿­ä»£ã€‚

```
base_url = '[https://www.indeed.com/cmp/Google/reviews?fcountry=ALL&start='](https://www.indeed.com/cmp/Google/reviews?fcountry=ALL&start=')all_reviews_df = pd.DataFrame(columns = ['rating', 'rating_title', 
'rating_description','rating_pros', 'rating_cons'])num_reviews = 20# you can adjust this number on how many reviews you which to scrape
while num_reviews < 3000:  

    full_url = base_url + str(num_reviews)

    get_url = requests.get(full_url, timeout=5)  

    partial_reviews_df = parse(get_url)       all_reviews_df = all_reviews_df.append(
                     partial_reviews_df, ignore_index=True) 

    num_reviews += 20
```

![](img/8b69c19fd72a886ffda14f293825f013.png)

å‰©ä¸‹è¦åšçš„å°±æ˜¯å°†æˆ‘ä»¬çš„æ•°æ®å¸§ç§»åŠ¨åˆ°ä¸€ä¸ª csv æ–‡ä»¶ä¸­ã€‚

```
all_reviews_df.to_csv('indeed_scrape.csv')
```

æˆ‘å¸Œæœ›ä½ å–œæ¬¢è¿™ä¸ªæ•™ç¨‹ã€‚æˆ‘å–œæ¬¢ä½ çš„åé¦ˆï¼Œæ¬¢è¿åœ¨ä¸‹é¢è¯„è®ºã€‚

åˆ«å¿˜äº†æŒ‘æˆ˜ï¼

# è°¢è°¢ï¼