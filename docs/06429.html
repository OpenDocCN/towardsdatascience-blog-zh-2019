<html>
<head>
<title>RFMT Segmentation Using K-Means Clustering</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">基于 K 均值聚类的 RFMT 分割</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/rfmt-segmentation-using-k-means-clustering-76bc5040ead5?source=collection_archive---------11-----------------------#2019-09-15">https://towardsdatascience.com/rfmt-segmentation-using-k-means-clustering-76bc5040ead5?source=collection_archive---------11-----------------------#2019-09-15</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><p id="61b0" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu">重要提示</strong>:这是我个人学习 python 数据科学过程的一部分。当我把它写下来的时候，我发现它非常有帮助，可以帮助我学得更好更快。这是 DataCamp 课程的一部分，代码基于我使用的课程和其他在线资源。请访问 DataCamp 获取原始教学大纲。我不属于任何形式的 DataCamp，只是作为一名学习者使用他们的资源。</p><p id="6ad5" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">在我们客户细分旅程的最后一部分，我们将应用 K-Means 聚类方法来细分我们的客户数据。我们将继续使用我们在 RFM 车型中设计的功能。此外，我们将把<strong class="js iu">任期</strong>作为我们模型的一个新特性，以创建 RFMT 模型。</p><h1 id="e3f2" class="ko kp it bd kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll bi translated">什么是 K-Means？</h1><p id="1bac" class="pw-post-body-paragraph jq jr it js b jt lm jv jw jx ln jz ka kb lo kd ke kf lp kh ki kj lq kl km kn im bi translated">K-Means 是一种流行且简单的无监督机器学习算法。简单地说，K-means 算法识别<em class="lr"> k </em>个质心，然后将每个数据点分配到最近的簇，同时保持质心尽可能小。我们不会深入研究 K-Means 如何工作的细节，所以让我们深入研究客户细分的实现。</p><h1 id="6fee" class="ko kp it bd kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll bi translated">k-均值假设</h1><p id="0930" class="pw-post-body-paragraph jq jr it js b jt lm jv jw jx ln jz ka kb lo kd ke kf lp kh ki kj lq kl km kn im bi translated">这是我们将要用来实现 K-Means 模型的 4 个特征。在我们将 K-Means 模型拟合到我们的数据之前，我们需要确保这些关键假设得到满足。</p><ol class=""><li id="e359" class="ls lt it js b jt ju jx jy kb lu kf lv kj lw kn lx ly lz ma bi translated">变量的分布</li><li id="9b1e" class="ls lt it js b jt mb jx mc kb md kf me kj mf kn lx ly lz ma bi translated">平均值相同的变量</li><li id="f1ea" class="ls lt it js b jt mb jx mc kb md kf me kj mf kn lx ly lz ma bi translated">方差相同的变量</li></ol><p id="5254" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">查看我们的 RFMT 汇总统计数据，我们可以看到我们的数据集目前不满足这些关键假设。让我们创建一个数据预处理管道，为 K-Means 准备好数据。</p><h1 id="73be" class="ko kp it bd kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll bi translated">数据预处理流水线</h1><p id="f8b5" class="pw-post-body-paragraph jq jr it js b jt lm jv jw jx ln jz ka kb lo kd ke kf lp kh ki kj lq kl km kn im bi translated">下面是我们执行数据转换需要采取的步骤，并详细介绍了每个步骤:</p><ol class=""><li id="4f57" class="ls lt it js b jt ju jx jy kb lu kf lv kj lw kn lx ly lz ma bi translated">取消对数据的分类—我们将使用日志转换来完成这项工作</li><li id="5d73" class="ls lt it js b jt mb jx mc kb md kf me kj mf kn lx ly lz ma bi translated">标准化到相同的平均值</li><li id="0786" class="ls lt it js b jt mb jx mc kb md kf me kj mf kn lx ly lz ma bi translated">缩放到相同的标准偏差</li><li id="b1a4" class="ls lt it js b jt mb jx mc kb md kf me kj mf kn lx ly lz ma bi translated">存储为单独的数组，用于聚类分析</li></ol><h2 id="5f44" class="mg kp it bd kq mh mi dn ku mj mk dp ky kb ml mm lc kf mn mo lg kj mp mq lk mr bi translated">数据偏斜度</h2><p id="0c1c" class="pw-post-body-paragraph jq jr it js b jt lm jv jw jx ln jz ka kb lo kd ke kf lp kh ki kj lq kl km kn im bi translated">让我们检查一下当前数据集的分布形状。</p><pre class="ms mt mu mv gt mw mx my mz aw na bi"><span id="a8e3" class="mg kp it mx b gy nb nc l nd ne"># Plot RFM distributions<br/>plt.figure(figsize=(16,14))</span><span id="4816" class="mg kp it mx b gy nf nc l nd ne"># Plot distribution of R<br/>plt.subplot(4, 1, 1); sns.distplot(data_process['Recency'])</span><span id="89b0" class="mg kp it mx b gy nf nc l nd ne"># Plot distribution of F<br/>plt.subplot(4, 1, 2); sns.distplot(data_process['Frequency'])</span><span id="6011" class="mg kp it mx b gy nf nc l nd ne"># Plot distribution of M<br/>plt.subplot(4, 1, 3); sns.distplot(data_process['MonetaryValue'])</span><span id="395f" class="mg kp it mx b gy nf nc l nd ne"># Plot distribution of T<br/>plt.subplot(4, 1, 4); sns.distplot(data_process['Tenure'])</span><span id="044b" class="mg kp it mx b gy nf nc l nd ne"># Show the plot<br/>plt.show()</span></pre><figure class="ms mt mu mv gt nh gh gi paragraph-image"><div role="button" tabindex="0" class="ni nj di nk bf nl"><div class="gh gi ng"><img src="../Images/a4514878e082304bfc014ed1e068fca6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*-r8k3qA8T8JvNZsT-3lLrg.png"/></div></div><figcaption class="no np gj gh gi nq nr bd b be z dk">There is skewness in our RFMT data</figcaption></figure><p id="ffe0" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">如你所见，这是 R、F 和 M 向右的一般偏斜度。t 具有更均匀分布的形状。为了解决这个问题，我们将对数据进行对数转换。</p><pre class="ms mt mu mv gt mw mx my mz aw na bi"><span id="6979" class="mg kp it mx b gy nb nc l nd ne"># Apply Log Transformation<br/>data_process['MonetaryValue'] = data_process['MonetaryValue'] + 0.0000000001<br/>recency_log = np.log(data_process['Recency'])<br/>frequency_log = np.log(data_process['Frequency'])<br/>monetary_log = np.log(data_process['MonetaryValue'])<br/>tenure_log = np.log(data_process['Tenure'])</span><span id="ce0c" class="mg kp it mx b gy nf nc l nd ne"># Plot RFM distributions<br/>plt.figure(figsize=(16,14))</span><span id="6ab4" class="mg kp it mx b gy nf nc l nd ne"># Plot distribution of R<br/>plt.subplot(4, 1, 1); sns.distplot(recency_log)</span><span id="bc2a" class="mg kp it mx b gy nf nc l nd ne"># Plot distribution of F<br/>plt.subplot(4, 1, 2); sns.distplot(frequency_log)</span><span id="0a16" class="mg kp it mx b gy nf nc l nd ne"># Plot distribution of M<br/>plt.subplot(4, 1, 3); sns.distplot(monetary_log)</span><span id="5fcd" class="mg kp it mx b gy nf nc l nd ne"># Plot distribution of M<br/>plt.subplot(4, 1, 4); sns.distplot(tenure_log)</span><span id="ef9c" class="mg kp it mx b gy nf nc l nd ne"># Show the plot<br/>plt.show()</span></pre><figure class="ms mt mu mv gt nh gh gi paragraph-image"><div role="button" tabindex="0" class="ni nj di nk bf nl"><div class="gh gi ns"><img src="../Images/7053e143ffcc4d46d13992a7e7437228.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*jtvMhlzekGTsyGJzbml9rQ.png"/></div></div><figcaption class="no np gj gh gi nq nr bd b be z dk">After applying log transformation, we see a much more normally distributed data set</figcaption></figure><p id="7299" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">太好了！看起来我们已经正常化了我们的 RFM 特征。但是，请注意，通过 log 变换 T，我们已经使数据向左倾斜。我们在通过可视化检查或其他方式转换数据时必须始终小心谨慎，以确保我们创建了最准确的客户群表示。</p><h2 id="847f" class="mg kp it bd kq mh mi dn ku mj mk dp ky kb ml mm lc kf mn mo lg kj mp mq lk mr bi translated">标准化平均值和标准偏差</h2><figure class="ms mt mu mv gt nh gh gi paragraph-image"><div class="ab gu cl nt"><img src="../Images/a558f04482a7e7d3667a161cb693241c.png" data-original-src="https://miro.medium.com/v2/format:webp/1*nv9_32F7aKH70oeEYy0cVQ.png"/></div></figure><p id="de3b" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">为了标准平均值和标准偏差，我们可以使用下面的公式:</p><pre class="ms mt mu mv gt mw mx my mz aw na bi"><span id="5fcc" class="mg kp it mx b gy nb nc l nd ne">datamart_centered = datamart_rfm - datamart_rfm.mean()<br/>datamart_scaled = datamart_rfm / datamart_rfm.std()</span></pre><p id="7c14" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">然而，让我们利用 SKLearn 库的 StandardScaler 来集中和缩放我们的数据。</p><pre class="ms mt mu mv gt mw mx my mz aw na bi"><span id="26bc" class="mg kp it mx b gy nb nc l nd ne">from sklearn.preprocessing import StandardScaler</span><span id="78b7" class="mg kp it mx b gy nf nc l nd ne">scaler = StandardScaler()<br/>scaler.fit(data_process_log)<br/>data_process_norm = scaler.transform(data_process_log)</span><span id="cba3" class="mg kp it mx b gy nf nc l nd ne">data_process_norm_df = pd.DataFrame(data_process_norm)<br/>data_process_norm_df.describe().round(2)</span></pre><figure class="ms mt mu mv gt nh gh gi paragraph-image"><div class="gh gi nu"><img src="../Images/7a3a953afd69e0586525fa4a67183299.png" data-original-src="https://miro.medium.com/v2/resize:fit:652/format:webp/1*zbinshera0TGxIboQVRCsQ.png"/></div><figcaption class="no np gj gh gi nq nr bd b be z dk">Our feature set post-scaling has a mean of 0 and standard deviation of 1</figcaption></figure><p id="49b0" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">厉害！现在，我们已经实现了关键假设，以便我们能够正确、准确地应用 K-Means 聚类对我们的客户进行细分。</p><h1 id="a252" class="ko kp it bd kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll bi translated">应用 K-均值</h1><p id="ed2e" class="pw-post-body-paragraph jq jr it js b jt lm jv jw jx ln jz ka kb lo kd ke kf lp kh ki kj lq kl km kn im bi translated">现在让我们进入任何机器学习项目中最激动人心的部分——应用 ML 模型！</p><p id="7ec8" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">但是在此之前，我们需要为我们的 K-Means 模型选择聚类数。这可以通过几种方式实现:</p><ol class=""><li id="0012" class="ls lt it js b jt ju jx jy kb lu kf lv kj lw kn lx ly lz ma bi translated">可视化方法——肘部标准</li><li id="7732" class="ls lt it js b jt mb jx mc kb md kf me kj mf kn lx ly lz ma bi translated">数学方法——轮廓系数</li><li id="b7d7" class="ls lt it js b jt mb jx mc kb md kf me kj mf kn lx ly lz ma bi translated">最具商业意义的实验和诠释</li></ol><p id="aa35" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">我们将使用肘准则法。</p><h2 id="6752" class="mg kp it bd kq mh mi dn ku mj mk dp ky kb ml mm lc kf mn mo lg kj mp mq lk mr bi translated">相对于组内误差平方和(SSE)绘制组数</h2><p id="0ed9" class="pw-post-body-paragraph jq jr it js b jt lm jv jw jx ln jz ka kb lo kd ke kf lp kh ki kj lq kl km kn im bi translated">误差平方和(SSE)是每个数据点到其聚类中心的距离平方和。我们希望选择最佳的聚类数量，在不过度拟合的情况下减少 SSE 的数量。让我们画出肘图来确定这一点。</p><pre class="ms mt mu mv gt mw mx my mz aw na bi"><span id="b6cc" class="mg kp it mx b gy nb nc l nd ne"># Fit KMeans and calculate SSE for each *k*<br/>sse = {}<br/>for k in range(1, 11):<br/>    kmeans = KMeans(n_clusters=k, random_state=1)<br/>    kmeans.fit(data_process_norm)<br/>    sse[k] = kmeans.inertia_</span><span id="51fd" class="mg kp it mx b gy nf nc l nd ne"># Plot SSE for each *k*<br/>plt.title('The Elbow Method')<br/>plt.xlabel('k'); plt.ylabel('SSE')<br/>sns.pointplot(x=list(sse.keys()), y=list(sse.values()))<br/>plt.show()</span></pre><figure class="ms mt mu mv gt nh gh gi paragraph-image"><div class="gh gi nv"><img src="../Images/9d040e04dcb0735426bde329b6bf6de7.png" data-original-src="https://miro.medium.com/v2/resize:fit:810/format:webp/1*XP_1Ssah-c5GheouR5kXtA.png"/></div><figcaption class="no np gj gh gi nq nr bd b be z dk">SSE plot against number of clusters</figcaption></figure><p id="10a9" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">理想情况下，我们希望在肘形图上选择一个点，在该点上，SSE 停止以递增的速率下降，即，在该点上，多个聚类之间的变化梯度变得恒定。对于我们的模型，我们将选择 k=4。</p><h2 id="efba" class="mg kp it bd kq mh mi dn ku mj mk dp ky kb ml mm lc kf mn mo lg kj mp mq lk mr bi translated">将我们的数据集拟合到 K 均值</h2><pre class="ms mt mu mv gt mw mx my mz aw na bi"><span id="5836" class="mg kp it mx b gy nb nc l nd ne"># Import KMeans from skLearn<br/>from sklearn.cluster import KMeans</span><span id="b1d1" class="mg kp it mx b gy nf nc l nd ne"># Choose k=4 and fit data set to k-means model<br/>kmeans = KMeans(n_clusters=4, random_state=1)<br/>kmeans.fit(data_process_norm)</span><span id="6cd6" class="mg kp it mx b gy nf nc l nd ne"># Assign k-means labels to cluster labels<br/>cluster_labels = kmeans.labels_</span><span id="33ed" class="mg kp it mx b gy nf nc l nd ne"># Assign cluster labels to original pre-transformed data set<br/>data_process_k4 = data_process.assign(Cluster = cluster_labels)</span><span id="34de" class="mg kp it mx b gy nf nc l nd ne"># Group data set by k-means cluster<br/>data_process_k4.groupby(['Cluster']).agg({<br/>    'Recency': 'mean',<br/>    'Frequency': 'mean',<br/>    'MonetaryValue': 'mean',<br/>    'Tenure': ['mean', 'count']<br/>}).round(0)</span></pre><figure class="ms mt mu mv gt nh gh gi paragraph-image"><div class="gh gi nw"><img src="../Images/99de4c0b3a40dd1f18fb5462c34ada3c.png" data-original-src="https://miro.medium.com/v2/resize:fit:930/format:webp/1*4bRtUvxJXhOiyp6AG1df1Q.png"/></div><figcaption class="no np gj gh gi nq nr bd b be z dk">Our RFMT data set grouped by their K-Means clusters</figcaption></figure><p id="b587" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">我们可以看到，我们对 R、F、M 和 T 均值的分组总结表明，每个客户群对我们的 4 个特征有不同的侧重:</p><ul class=""><li id="92ee" class="ls lt it js b jt ju jx jy kb lu kf lv kj lw kn nx ly lz ma bi translated"><strong class="js iu">聚类 0 </strong>具有最高的月均值、最低的最近均值和最高的频率均值——这是我们理想的客户群</li><li id="6b88" class="ls lt it js b jt mb jx mc kb md kf me kj mf kn nx ly lz ma bi translated"><strong class="js iu">集群 1 </strong>在 R、F 和 M 领域表现不佳，在我们的数据库中也存在很长时间——我们需要设计活动来再次激活它们</li><li id="d6f1" class="ls lt it js b jt mb jx mc kb md kf me kj mf kn nx ly lz ma bi translated"><strong class="js iu"> Cluster 2 </strong>最近在我们这里购物，但没有像我们希望的那样花费那么多或那么频繁——也许一些针对他们的个性化产品可以帮助他们实现终身价值最大化？</li><li id="a33d" class="ls lt it js b jt mb jx mc kb md kf me kj mf kn nx ly lz ma bi translated"><strong class="js iu"> Cluster 3 </strong>在我们这里花了相当多的钱，但是已经有 3-4 个月没有和我们一起购物了——我们需要在失去他们之前做点什么！</li></ul><h2 id="1431" class="mg kp it bd kq mh mi dn ku mj mk dp ky kb ml mm lc kf mn mo lg kj mp mq lk mr bi translated">RFMT 在 K 均值聚类中的相对重要性</h2><p id="343c" class="pw-post-body-paragraph jq jr it js b jt lm jv jw jx ln jz ka kb lo kd ke kf lp kh ki kj lq kl km kn im bi translated">我们可以通过热图来直观显示 4 个集群中每个功能的相对重要性。</p><pre class="ms mt mu mv gt mw mx my mz aw na bi"><span id="4a83" class="mg kp it mx b gy nb nc l nd ne"># Calculate average RFM values for each cluster<br/>cluster_avg = data_process_k4.groupby(['Cluster']).mean()</span><span id="d784" class="mg kp it mx b gy nf nc l nd ne"># Calculate average RFM values for the total customer population<br/>population_avg = data_process.mean()</span><span id="caf0" class="mg kp it mx b gy nf nc l nd ne"># Calculate relative importance of cluster's attribute value compared to population<br/>relative_imp = cluster_avg / population_avg - 1</span><span id="e7d6" class="mg kp it mx b gy nf nc l nd ne"># Initialize a plot with a figure size of 8 by 2 inches <br/>plt.figure(figsize=(8, 4))</span><span id="bb07" class="mg kp it mx b gy nf nc l nd ne"># Add the plot title<br/>plt.title('Relative importance of attributes')</span><span id="894f" class="mg kp it mx b gy nf nc l nd ne"># Plot the heatmap<br/>sns.heatmap(data=relative_imp, annot=True, fmt='.2f', cmap='RdYlGn')<br/>plt.show()</span></pre><figure class="ms mt mu mv gt nh gh gi paragraph-image"><div class="gh gi ny"><img src="../Images/2cbb21186312756f174179e6aea4cb59.png" data-original-src="https://miro.medium.com/v2/resize:fit:932/format:webp/1*zO0CmQqSLL9qPgQtCiuI9Q.png"/></div><figcaption class="no np gj gh gi nq nr bd b be z dk">Relative Importance of RFMT for each of our 3 clusters</figcaption></figure><p id="0560" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">热图提供了一种简单易行的方法来理解我们的 K-Means 模型如何将我们的 RFMT 属性的相对重要性分配到每个客户各自的细分市场。</p><h1 id="df6d" class="ko kp it bd kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll bi translated">可视化我们的 K 均值聚类</h1><p id="559d" class="pw-post-body-paragraph jq jr it js b jt lm jv jw jx ln jz ka kb lo kd ke kf lp kh ki kj lq kl km kn im bi translated">最后，让我们在散点图中可视化我们的 K-Means 聚类，以结束我们的客户细分之旅。</p><pre class="ms mt mu mv gt mw mx my mz aw na bi"><span id="6bb4" class="mg kp it mx b gy nb nc l nd ne"># Plot RFM distributions<br/>plt.figure(figsize=(20,20))<br/>plt.subplot(3, 1, 1);<br/>plt.scatter(data_process_k4[cluster_labels == 0].loc[:,'Recency'], data_process_k4[cluster_labels == 0].loc[:,'MonetaryValue'], s= 10, cmap='rainbow', label = 'Cluster 1', alpha=0.2)<br/>plt.scatter(data_process_k4[cluster_labels == 1].loc[:,'Recency'], data_process_k4[cluster_labels == 1].loc[:,'MonetaryValue'], s= 10, cmap='rainbow', label = 'Cluster 2', alpha=0.2)<br/>plt.scatter(data_process_k4[cluster_labels == 2].loc[:,'Recency'], data_process_k4[cluster_labels == 2].loc[:,'MonetaryValue'], s= 10, cmap='rainbow', label = 'Cluster 3', alpha=0.3)<br/>plt.scatter(data_process_k4[cluster_labels == 3].loc[:,'Recency'], data_process_k4[cluster_labels == 3].loc[:,'MonetaryValue'], s= 10, cmap='rainbow', label = 'Cluster 4', alpha=0.3)<br/>plt.xticks(np.arange(0, 1000, 100)) <br/>plt.yticks(np.arange(0, 10000, 1000))<br/>axes = plt.gca()<br/>axes.set_xlim(0, 500)<br/>axes.set_ylim(0, 10000)<br/>plt.title('Cusomter Clusters')<br/>plt.xlabel('Recency')<br/>plt.ylabel('Monetary Value')<br/>plt.legend()</span><span id="75a3" class="mg kp it mx b gy nf nc l nd ne">plt.subplot(3, 1, 2);<br/>plt.scatter(data_process_k4[cluster_labels == 0].loc[:,'Frequency'], data_process_k4[cluster_labels == 0].loc[:,'MonetaryValue'], s= 10, cmap='rainbow', label = 'Cluster 1', alpha=0.2)<br/>plt.scatter(data_process_k4[cluster_labels == 1].loc[:,'Frequency'], data_process_k4[cluster_labels == 1].loc[:,'MonetaryValue'], s= 10, cmap='rainbow', label = 'Cluster 2', alpha=0.2)<br/>plt.scatter(data_process_k4[cluster_labels == 2].loc[:,'Frequency'], data_process_k4[cluster_labels == 2].loc[:,'MonetaryValue'], s= 10, cmap='rainbow', label = 'Cluster 3', alpha=0.3)<br/>plt.scatter(data_process_k4[cluster_labels == 3].loc[:,'Frequency'], data_process_k4[cluster_labels == 3].loc[:,'MonetaryValue'], s= 10, cmap='rainbow', label = 'Cluster 4', alpha=0.3)<br/>plt.xticks(np.arange(0, 1000, 100)) <br/>plt.yticks(np.arange(0, 10000, 1000))<br/>axes = plt.gca()<br/>axes.set_xlim(0, 500)<br/>axes.set_ylim(0, 10000)<br/>plt.title('Cusomter Clusters')<br/>plt.xlabel('Frequency')<br/>plt.ylabel('Monetary Value')<br/>plt.legend()</span><span id="693c" class="mg kp it mx b gy nf nc l nd ne">plt.subplot(3, 1, 3);<br/>plt.scatter(data_process_k4[cluster_labels == 0].loc[:,'Tenure'], data_process_k4[cluster_labels == 0].loc[:,'MonetaryValue'], s= 10, cmap='rainbow', label = 'Cluster 1', alpha=0.2)<br/>plt.scatter(data_process_k4[cluster_labels == 1].loc[:,'Tenure'], data_process_k4[cluster_labels == 1].loc[:,'MonetaryValue'], s= 10, cmap='rainbow', label = 'Cluster 2', alpha=0.2)<br/>plt.scatter(data_process_k4[cluster_labels == 2].loc[:,'Tenure'], data_process_k4[cluster_labels == 2].loc[:,'MonetaryValue'], s= 10, cmap='rainbow', label = 'Cluster 3', alpha=0.3)<br/>plt.scatter(data_process_k4[cluster_labels == 3].loc[:,'Tenure'], data_process_k4[cluster_labels == 3].loc[:,'MonetaryValue'], s= 10, cmap='rainbow', label = 'Cluster 4', alpha=0.3)<br/>plt.xticks(np.arange(0, 1000, 100)) <br/>plt.yticks(np.arange(0, 10000, 1000))<br/>axes = plt.gca()<br/>axes.set_xlim(0, 500)<br/>axes.set_ylim(0, 10000)<br/>plt.title('Cusomter Clusters')<br/>plt.xlabel('Tenure')<br/>plt.ylabel('Monetary Value')<br/>plt.legend()</span><span id="1f16" class="mg kp it mx b gy nf nc l nd ne">plt.show()</span></pre><figure class="ms mt mu mv gt nh gh gi paragraph-image"><div role="button" tabindex="0" class="ni nj di nk bf nl"><div class="gh gi nz"><img src="../Images/7848332530b7770ee2c831ecf980d260.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*-T6Jwuo1NjRA3Ykb6py09Q.png"/></div></div></figure><p id="98d3" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">感谢您花时间通过这个由 3 部分组成的系列来探索客户细分。如果你喜欢这些内容，请继续关注，我将探索更多的数据，也许还会用 Python 构建其他有趣的项目。</p></div></div>    
</body>
</html>