<html>
<head>
<title>Finding Needle in the Haystack with Apache Spark</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">用 Apache Spark 大海捞针</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/finding-needle-in-haystack-with-apache-spark-eb4c846f998d?source=collection_archive---------29-----------------------#2019-09-24">https://towardsdatascience.com/finding-needle-in-haystack-with-apache-spark-eb4c846f998d?source=collection_archive---------29-----------------------#2019-09-24</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><figure class="gl gn jr js jt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi jq"><img src="../Images/3de6eb888d9575a7e02fa28e8231319c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*NfNwu4uCbPbH5YHH.jpg"/></div></div><figcaption class="kb kc gj gh gi kd ke bd b be z dk"><a class="ae kf" href="https://www.behance.net/gallery/43892087/HearU-Music" rel="noopener ugc nofollow" target="_blank"><em class="kg">“HearU Music”</em></a><em class="kg"> by Yi Mao is licensed under </em><a class="ae kf" href="https://creativecommons.org/licenses/by-nc-nd/4.0/?ref=ccsearch&amp;atype=rich" rel="noopener ugc nofollow" target="_blank"><em class="kg">CC BY-NC-ND 4.0</em></a></figcaption></figure></div><div class="ab cl kh ki hx kj" role="separator"><span class="kk bw bk kl km kn"/><span class="kk bw bk kl km kn"/><span class="kk bw bk kl km"/></div><div class="im in io ip iq"><p id="b1d2" class="pw-post-body-paragraph ko kp it kq b kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll im bi translated"><strong class="kq iu">TL；DR: </strong>客户流失对企业来说是一个真实的问题，在不断增长的(大)数据中预测哪个用户可能会流失可能很困难。Apache Spark 允许数据科学家在大数据中轻松地进行大规模数据清理/建模/预测。</p><p id="2700" class="pw-post-body-paragraph ko kp it kq b kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll im bi lm translated"><span class="l ln lo lp bm lq lr ls lt lu di">大多数数据科学家都知道处理数据并不总是一帆风顺。像清理、输入缺失值、特征工程、建模和预测这样的过程，即使数据小到可以放入笔记本电脑的内存中，其本身也是一个巨大的问题。如果数据比这大得多，事情很容易变得更复杂。解决这个问题的一个非常常见的方法是将数据放在 SQL 或非 SQL 数据库中，在汇总数据并将汇总的数据移动到本地工作站进行建模之前，在那里进行大部分的争论/清理。</span></p><p id="5acd" class="pw-post-body-paragraph ko kp it kq b kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll im bi translated">然而，有时数据科学家需要大量数据输入到他们的模型中，并根据大数据进行训练和预测。对于传统的库，如 Python Pandas、scikit-learn 或 R dplyr，这并不容易，因为我们只有有限的内存来容纳。</p><p id="92bb" class="pw-post-body-paragraph ko kp it kq b kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll im bi translated">Apache Spark 是大数据生态系统中最大的明星之一。它允许数据科学家使用熟悉的工具工作，但允许 Spark 做所有繁重的工作，如并行化和任务扩展。它提供了类似 Spark 数据帧的工具，类似于 R 数据帧或 Pandas 数据帧。如果您更喜欢传统的 SQL，您可以使用 SQL 来处理数据，而不是使用数据框。Spark 通过 MLlib 库支持许多开箱即用的机器学习算法。它还通过 Spark Streaming 为数据工程师提供流支持，最后，它通过 GraphX 支持原生图形处理。Spark 是数据科学家/工程师在处理大数据时的一把瑞士军刀。</p><p id="7026" class="pw-post-body-paragraph ko kp it kq b kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll im bi translated">在本帖中，我们将研究一个商业案例，这是许多数据科学家的共同任务，因为它对商业营销或战略工作有非常直接的影响。我们将尝试预测可能会为音乐流媒体平台流失的用户。基于良好的预测，通过促销或折扣来保持用户的参与，以流失用户，这一点至关重要。</p><p id="df6c" class="pw-post-body-paragraph ko kp it kq b kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll im bi translated">在本例中，我们有完整数据集(12GB)的一个小子集(128MB)。由于我在本地集群上工作(仅指我的笔记本电脑，而不是一组服务器)，我将对小数据集进行分析，但我们将探索的所有方法都适用于较大的数据，没有什么根本不同，只是 Spark 将在大多数情况下处理并行性。</p><blockquote class="lv lw lx"><p id="9252" class="ko kp ly kq b kr ks kt ku kv kw kx ky lz la lb lc ma le lf lg mb li lj lk ll im bi translated">我们使用的数据来自<a class="ae kf" href="https://d20vrrgs8k4bvw.cloudfront.net/documents/en-US/Data+Scientist+Nanodegree+Syllabus.pdf" rel="noopener ugc nofollow" target="_blank"> Udacity 数据科学家纳米学位计划 Apache Spark 顶点计划</a></p></blockquote><figure class="mc md me mf gt ju"><div class="bz fp l di"><div class="mg mh l"/></div><figcaption class="kb kc gj gh gi kd ke bd b be z dk">Import necessary libraries. We will import some of them again for clarity later</figcaption></figure><p id="d77f" class="pw-post-body-paragraph ko kp it kq b kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll im bi translated">Spark 需要一个叫做 Spark Session 的东西，这是你的代码和主节点之间的驱动。让我们创建一个，如果还没有的话，或者如果已经有了就返回它。</p><figure class="mc md me mf gt ju"><div class="bz fp l di"><div class="mg mh l"/></div><figcaption class="kb kc gj gh gi kd ke bd b be z dk">Creating/getting Spark session. Note that our cluster is a local one.</figcaption></figure><h1 id="927b" class="mi mj it bd mk ml mm mn mo mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne nf bi translated">加载和清理 Sparkify 数据集</h1><p id="558b" class="pw-post-body-paragraph ko kp it kq b kr ng kt ku kv nh kx ky kz ni lb lc ld nj lf lg lh nk lj lk ll im bi translated">我们将用户活动数据集<code class="fe nl nm nn no b">mini_sparkify_event_data.json</code>导入 Spark，然后清除一些缺失的值。</p><figure class="mc md me mf gt ju"><div class="bz fp l di"><div class="mg mh l"/></div><figcaption class="kb kc gj gh gi kd ke bd b be z dk">Read data into Spark and do few simple checks on data</figcaption></figure><p id="5522" class="pw-post-body-paragraph ko kp it kq b kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll im bi translated">让我们浏览一下前几行，感受一下我们的数据</p><pre class="mc md me mf gt np no nq nr aw ns bi"><span id="9a75" class="nt mj it no b gy nu nv l nw nx">data.take(5)</span><span id="0bc3" class="nt mj it no b gy ny nv l nw nx">[Row(artist='Martha Tilston', auth='Logged In', firstName='Colin', gender='M', itemInSession=50, lastName='Freeman', length=277.89016, level='paid', location='Bakersfield, CA', method='PUT', page='NextSong', registration=1538173362000, sessionId=29, song='Rockpools', status=200, ts=1538352117000, userAgent='Mozilla/5.0 (Windows NT 6.1; WOW64; rv:31.0) Gecko/20100101 Firefox/31.0', userId='30'),</span><span id="7f69" class="nt mj it no b gy ny nv l nw nx"> Row(artist='Five Iron Frenzy', auth='Logged In', firstName='Micah', gender='M', itemInSession=79, lastName='Long', length=236.09424, level='free', location='Boston-Cambridge-Newton, MA-NH', method='PUT', page='NextSong', registration=1538331630000, sessionId=8, song='Canada', status=200, ts=1538352180000, userAgent='"Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/37.0.2062.103 Safari/537.36"', userId='9'),</span><span id="8fef" class="nt mj it no b gy ny nv l nw nx"> Row(artist='Adam Lambert', auth='Logged In', firstName='Colin', gender='M', itemInSession=51, lastName='Freeman', length=282.8273, level='paid', location='Bakersfield, CA', method='PUT', page='NextSong', registration=1538173362000, sessionId=29, song='Time For Miracles', status=200, ts=1538352394000, userAgent='Mozilla/5.0 (Windows NT 6.1; WOW64; rv:31.0) Gecko/20100101 Firefox/31.0', userId='30'),</span><span id="db87" class="nt mj it no b gy ny nv l nw nx"> Row(artist='Enigma', auth='Logged In', firstName='Micah', gender='M', itemInSession=80, lastName='Long', length=262.71302, level='free', location='Boston-Cambridge-Newton, MA-NH', method='PUT', page='NextSong', registration=1538331630000, sessionId=8, song='Knocking On Forbidden Doors', status=200, ts=1538352416000, userAgent='"Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/37.0.2062.103 Safari/537.36"', userId='9'),</span><span id="4c3f" class="nt mj it no b gy ny nv l nw nx"> Row(artist='Daft Punk', auth='Logged In', firstName='Colin', gender='M', itemInSession=52, lastName='Freeman', length=223.60771, level='paid', location='Bakersfield, CA', method='PUT', page='NextSong', registration=1538173362000, sessionId=29, song='Harder Better Faster Stronger', status=200, ts=1538352676000, userAgent='Mozilla/5.0 (Windows NT 6.1; WOW64; rv:31.0) Gecko/20100101 Firefox/31.0', userId='30')]</span></pre><p id="7d59" class="pw-post-body-paragraph ko kp it kq b kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll im bi translated">每行标识一个用户活动，如当前艺术家、歌曲、会话 Id、用户 Id，以及用户正在从哪个设备收听、unix 时间戳、性别、用户是否登录和付费用户、用户详细信息..等等</p><h1 id="28ef" class="mi mj it bd mk ml mm mn mo mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne nf bi translated">数据清理</h1><p id="b442" class="pw-post-body-paragraph ko kp it kq b kr ng kt ku kv nh kx ky kz ni lb lc ld nj lf lg lh nk lj lk ll im bi translated">我们应该检查数据集中的空值。根据结构，我们可以省略一些列或估算(如果我们的分析需要的话)。让我们从统计和视觉两方面来看看</p><figure class="mc md me mf gt ju"><div class="bz fp l di"><div class="mg mh l"/></div><figcaption class="kb kc gj gh gi kd ke bd b be z dk">Checking Null and NaN values in our dataset</figcaption></figure><p id="8d03" class="pw-post-body-paragraph ko kp it kq b kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll im bi translated">我们有大量的空值，特别是在某些列中，比如<code class="fe nl nm nn no b">artist</code>、<code class="fe nl nm nn no b">length</code>或<code class="fe nl nm nn no b">song</code>。</p><p id="d3e3" class="pw-post-body-paragraph ko kp it kq b kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll im bi translated">我们还观察到，在列组之间的空值计数方面可能存在相关性，例如<code class="fe nl nm nn no b">artist</code>、<code class="fe nl nm nn no b">length</code>或<code class="fe nl nm nn no b">song</code>都具有相同数量的空值。对于<code class="fe nl nm nn no b">firstName</code>、<code class="fe nl nm nn no b">gender</code>、<code class="fe nl nm nn no b">lastName</code>、<code class="fe nl nm nn no b">location</code>、<code class="fe nl nm nn no b">registration</code>、<code class="fe nl nm nn no b">userAgent</code>都是如此。</p><p id="f97e" class="pw-post-body-paragraph ko kp it kq b kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll im bi translated">其他列都没有任何缺失值。</p><p id="102e" class="pw-post-body-paragraph ko kp it kq b kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll im bi translated">同样，让我们直观地检查缺失值，看看我们之前的相关性声明是否得到支持。如果这是真的，我们可以说不仅空计数是相同的，而且空值出现的行数也应该是相同的。</p><p id="85dd" class="pw-post-body-paragraph ko kp it kq b kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll im bi translated">由于 pyspark 没有可视化库，我们采样 spark 数据帧并将其转换为 pandas 数据帧，然后使用 Seaborn 进行可视化。</p><pre class="mc md me mf gt np no nq nr aw ns bi"><span id="53a6" class="nt mj it no b gy nu nv l nw nx">plt.figure(figsize=(12, 12))<br/>sns.heatmap(data.sample(False, 0.1, 42).toPandas().isnull())</span></pre><figure class="mc md me mf gt ju gh gi paragraph-image"><div class="gh gi nz"><img src="../Images/68dc623f23353169aded0582cd16df2d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1354/format:webp/1*EgEjtgzP_ov8NSkRj-ZZiQ.png"/></div><figcaption class="kb kc gj gh gi kd ke bd b be z dk">Using Python Seaborn heatmap we can visualise NULL values in the dataset</figcaption></figure><p id="4feb" class="pw-post-body-paragraph ko kp it kq b kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll im bi translated">上面的热图支持我们的说法，列在缺失值、数字和索引方面是相关的。</p><p id="b463" class="pw-post-body-paragraph ko kp it kq b kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll im bi translated">我想检查的最后一件事是，如果<code class="fe nl nm nn no b">firstName</code>和其他类似字段为空，那么<code class="fe nl nm nn no b">artist</code>和类似字段是否也为空？</p><pre class="mc md me mf gt np no nq nr aw ns bi"><span id="5ab5" class="nt mj it no b gy nu nv l nw nx">sns.heatmap(data.filter(data.firstName.isNull()).toPandas().isnull())</span></pre><figure class="mc md me mf gt ju gh gi paragraph-image"><div class="gh gi oa"><img src="../Images/7915919cbd46a6afe78ed1e7a495fa2e.png" data-original-src="https://miro.medium.com/v2/resize:fit:730/format:webp/1*hQuUy26reJn0uvMpF3XaBw.png"/></div><figcaption class="kb kc gj gh gi kd ke bd b be z dk">Filelds like `artist`, `location`.. etc all are null when `fistName` is null</figcaption></figure><p id="f91c" class="pw-post-body-paragraph ko kp it kq b kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll im bi translated">是的，它们是相关的，所以不仅空计数相等的组内部相关，而且组间空模式也相关。用简单的英语来说，如果<code class="fe nl nm nn no b">firstName</code>为空，那么<code class="fe nl nm nn no b">gender</code>也为空，因为它们的空计数相等，但是上面的图表也表明<code class="fe nl nm nn no b">artist</code> col 也将为空</p></div><div class="ab cl kh ki hx kj" role="separator"><span class="kk bw bk kl km kn"/><span class="kk bw bk kl km kn"/><span class="kk bw bk kl km"/></div><div class="im in io ip iq"><p id="adae" class="pw-post-body-paragraph ko kp it kq b kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll im bi translated">根据下面的两个表，当用户注销或作为来宾收听时，<code class="fe nl nm nn no b">firstName</code>、<code class="fe nl nm nn no b">gender</code>、<code class="fe nl nm nn no b">lastName</code>、<code class="fe nl nm nn no b">location</code>、<code class="fe nl nm nn no b">registration</code>、<code class="fe nl nm nn no b">userAgent</code>和<code class="fe nl nm nn no b">auth</code>列具有空值。因为我们真正感兴趣的是那些已经注册并可能流失的用户，所以我们可以删除这些行，因为它们不是登录用户。</p><pre class="mc md me mf gt np no nq nr aw ns bi"><span id="526d" class="nt mj it no b gy nu nv l nw nx">data.filter(data.firstName.isNull())\<br/>    .groupBy('firstName','gender', 'lastName',<br/>             'location', 'registration','userAgent', 'auth')\<br/>    .count()\.show()</span></pre><figure class="mc md me mf gt ju gh gi paragraph-image"><div class="gh gi ob"><img src="../Images/cbf07f7522244b5db20f61922c11c85e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1310/format:webp/1*ArU-zJHrms8JYzUSMSLmJQ.png"/></div></figure><pre class="mc md me mf gt np no nq nr aw ns bi"><span id="728a" class="nt mj it no b gy nu nv l nw nx">data.groupBy('auth').count().show()</span></pre><figure class="mc md me mf gt ju gh gi paragraph-image"><div class="gh gi oc"><img src="../Images/c84662a58dafd0870edf8627e96a3ca4.png" data-original-src="https://miro.medium.com/v2/resize:fit:344/format:webp/1*N3AWr_w4zXxDHVKEi8aLBA.png"/></div><figcaption class="kb kc gj gh gi kd ke bd b be z dk">Rows where firstName .. etc are null they all are either Guest or Logged out.</figcaption></figure><pre class="mc md me mf gt np no nq nr aw ns bi"><span id="3a7d" class="nt mj it no b gy nu nv l nw nx"># Drop the rows with null values for the columns below<br/>data = data.na.drop(subset=['firstName','gender', <br/>                            'lastName','location','registration',<br/>                            'userAgent', 'auth'])</span><span id="a015" class="nt mj it no b gy ny nv l nw nx">sns.heatmap(data.toPandas().isnull())</span></pre><figure class="mc md me mf gt ju gh gi paragraph-image"><div class="gh gi od"><img src="../Images/5249fcb39846b6bb560ee72a264eba72.png" data-original-src="https://miro.medium.com/v2/resize:fit:754/format:webp/1*84nvqpadgXlF5X6ujiH5fw.png"/></div><figcaption class="kb kc gj gh gi kd ke bd b be z dk">Removing <strong class="bd oe">logged out</strong> users gives us a cleaner dataset</figcaption></figure><p id="7ee0" class="pw-post-body-paragraph ko kp it kq b kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll im bi translated">现在，我们有了一个更清晰的用户登录数据集。</p><p id="dfa9" class="pw-post-body-paragraph ko kp it kq b kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll im bi translated"><code class="fe nl nm nn no b">ts </code>列是 unix epoch 格式的时间戳，我们最好转换成时间戳格式，并添加到<code class="fe nl nm nn no b">timestamp</code>列中</p><pre class="mc md me mf gt np no nq nr aw ns bi"><span id="f460" class="nt mj it no b gy nu nv l nw nx">data = data\<br/>    .withColumn('timestamp', from_unixtime(data.ts/1000))</span><span id="d5e2" class="nt mj it no b gy ny nv l nw nx">data.take(2)</span><span id="a375" class="nt mj it no b gy ny nv l nw nx">[Row(artist='Martha Tilston', auth='Logged In', firstName='Colin', gender='M', itemInSession=50, lastName='Freeman', length=277.89016, level='paid', location='Bakersfield, CA', method='PUT', page='NextSong', registration=1538173362000, sessionId=29, song='Rockpools', status=200, <strong class="no iu">ts=1538352117000</strong>, userAgent='Mozilla/5.0 (Windows NT 6.1; WOW64; rv:31.0) Gecko/20100101 Firefox/31.0', userId='30', <strong class="no iu">timestamp='2018-10-01 00:01:57'</strong>),</span><span id="7a54" class="nt mj it no b gy ny nv l nw nx"> Row(artist='Five Iron Frenzy', auth='Logged In', firstName='Micah', gender='M', itemInSession=79, lastName='Long', length=236.09424, level='free', location='Boston-Cambridge-Newton, MA-NH', method='PUT', page='NextSong', registration=1538331630000, sessionId=8, song='Canada', status=200, <strong class="no iu">ts=1538352180000</strong>, userAgent='"Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/37.0.2062.103 Safari/537.36"', userId='9', <strong class="no iu">timestamp='2018-10-01 00:03:00'</strong>)]</span></pre><p id="de37" class="pw-post-body-paragraph ko kp it kq b kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll im bi translated">对于我们的模型，我们将删除一些我们不需要的字段，可能它们在其他列中有重复的信息或者只是不相关。在这一点上，我决定不在我的模型中使用它们，但是由于模型构建是一个迭代过程，如果我相信添加这些列会有所不同，我可能会在以后决定不删除这些列。</p><pre class="mc md me mf gt np no nq nr aw ns bi"><span id="ac7f" class="nt mj it no b gy nu nv l nw nx">cols_to_drop = ['userAgent', 'artist', 'firstName', <br/>                'lastName', 'location', 'song', <br/>                'ts', 'registration', 'length', <br/>                'method', 'status']</span><span id="dc94" class="nt mj it no b gy ny nv l nw nx">data = data.drop(*cols_to_drop)</span><span id="b93c" class="nt mj it no b gy ny nv l nw nx">data.show()</span></pre><figure class="mc md me mf gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi of"><img src="../Images/f3aa67af27e0f7b38ff62bb561fe2441.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ZJyPe5m-GgrLZE1GoofYlw.png"/></div></div><figcaption class="kb kc gj gh gi kd ke bd b be z dk">User music after adding <code class="fe nl nm nn no b"><strong class="bd oe">timestamp</strong></code> and removing irrelevant columns for prediction</figcaption></figure><p id="8213" class="pw-post-body-paragraph ko kp it kq b kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll im bi translated">下表告诉我们，免费和付费用户都可以取消他们的服务，但只有付费用户可以降级服务。嗯，有道理。我相信我们可以进一步过滤我们的数据框架来清理几行，因为像<strong class="kq iu">设置</strong>或<strong class="kq iu">帮助</strong>这样的页面不会告诉我们太多关于客户流失的信息。</p><figure class="mc md me mf gt ju gh gi paragraph-image"><div class="gh gi og"><img src="../Images/881c1aa68ba67a2e669c8111d7249058.png" data-original-src="https://miro.medium.com/v2/resize:fit:690/format:webp/1*YgYj2T2myypWJmIumWCn0Q.png"/></div><figcaption class="kb kc gj gh gi kd ke bd b be z dk">Pages vs User Level. Next Song is the dominant as expected. There are 52 Cancellations (churns)</figcaption></figure><pre class="mc md me mf gt np no nq nr aw ns bi"><span id="789b" class="nt mj it no b gy nu nv l nw nx">pages_to_keep = ['NextSong', 'Downgrade', <br/>                 'Cancellation Confirmation', 'Upgrade', <br/>                 'Add to Playlist', 'Cancel', 'Submit Upgrade', ]</span><span id="760f" class="nt mj it no b gy ny nv l nw nx">data = data.filter(col('page').isin(pages_to_keep))</span><span id="b959" class="nt mj it no b gy ny nv l nw nx">data.groupBy('auth', 'page').count().orderBy('auth').show()</span></pre><figure class="mc md me mf gt ju gh gi paragraph-image"><div class="gh gi oh"><img src="../Images/5fb1205ab9195554150ed58dc4223205.png" data-original-src="https://miro.medium.com/v2/resize:fit:666/format:webp/1*qnkWQZhowl5cstleg2po7A.png"/></div><figcaption class="kb kc gj gh gi kd ke bd b be z dk">After filtering out pages like Help, we are left with these above. <strong class="bd oe">Cancellation Confirmation </strong>is the churn KPI</figcaption></figure><h1 id="a8ad" class="mi mj it bd mk ml mm mn mo mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne nf bi translated">探索性数据分析</h1><p id="c6c9" class="pw-post-body-paragraph ko kp it kq b kr ng kt ku kv nh kx ky kz ni lb lc ld nj lf lg lh nk lj lk ll im bi translated"><code class="fe nl nm nn no b">Cancellation Confirmation</code>是对流失最明确的 KPI。<code class="fe nl nm nn no b">Downgrade</code>页面被访问了数百次，但是数据并没有清楚地告诉我们用户在访问该页面后是否被降级，比如我们没有<code class="fe nl nm nn no b">Downgrade Confirmed</code>后面跟有<code class="fe nl nm nn no b">Downgrade</code>页面。此外，数据集中的<code class="fe nl nm nn no b">Downgrade</code>行数远远大于唯一用户数。因此，我坚持使用<code class="fe nl nm nn no b">Cancellation Confirmation</code>作为客户流失指示器。</p><pre class="mc md me mf gt np no nq nr aw ns bi"><span id="973c" class="nt mj it no b gy nu nv l nw nx"># In our final dataset we do not have any null values<br/>data.select([count(when(col(c).isNull(), c)).alias(c) <br/>               for c in data.columns])\<br/>           .head()\<br/>           .asDict()</span><span id="1176" class="nt mj it no b gy ny nv l nw nx">{'auth': 0,<br/> 'gender': 0,<br/> 'itemInSession': 0,<br/> 'level': 0,<br/> 'page': 0,<br/> 'sessionId': 0,<br/> 'userId': 0,<br/> 'timestamp': 0}</span></pre><p id="8c18" class="pw-post-body-paragraph ko kp it kq b kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll im bi translated">我们的数据集中有多少不同的用户？</p><pre class="mc md me mf gt np no nq nr aw ns bi"><span id="37e9" class="nt mj it no b gy nu nv l nw nx">data.select('userId').distinct().count()</span><span id="cf59" class="nt mj it no b gy ny nv l nw nx">&gt;&gt; 225</span></pre><p id="65b1" class="pw-post-body-paragraph ko kp it kq b kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll im bi translated">让我们来看看一个随机用户的听力活动。 <code class="fe nl nm nn no b"><em class="ly">itemInSession</em></code> <em class="ly">连续收听时单调递增。我们可以提取每个会话的最大值，以了解用户参与度(稍后在功能工程部分)</em></p><pre class="mc md me mf gt np no nq nr aw ns bi"><span id="5e33" class="nt mj it no b gy nu nv l nw nx">data.filter(col('userId') == 30).show(20)</span></pre><figure class="mc md me mf gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi oi"><img src="../Images/5c0e0ceb94b6a8273ac35ee4390974b6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*1jOm1csqEqs7MNT89ZsOCg.png"/></div></div><figcaption class="kb kc gj gh gi kd ke bd b be z dk">User activity for user with userId 30. Note that itemInSession increases when the page changes. sessionID stays the same for a continuous music streaming session.</figcaption></figure><p id="82b6" class="pw-post-body-paragraph ko kp it kq b kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll im bi translated">让我们简要地看一下被搅动的用户/订户。看起来<code class="fe nl nm nn no b">free</code>和<code class="fe nl nm nn no b">paid</code>的客户都会流失。我们将这些数据保存到<code class="fe nl nm nn no b">churn_data</code>中，因为我们将在以后加入特征工程部分时使用这些数据</p><pre class="mc md me mf gt np no nq nr aw ns bi"><span id="b159" class="nt mj it no b gy nu nv l nw nx">churn_data = data.filter(col('page')=='Cancellation Confirmation')<br/>churn_data.show(10)</span></pre><figure class="mc md me mf gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi oj"><img src="../Images/f5a2f9403c87126d13cd34cde1945f43.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*y9ZIv5EmE9VWydgISfAXDA.png"/></div></div><figcaption class="kb kc gj gh gi kd ke bd b be z dk">List of churned users, there are both free and paid customers. We store the userId for joining later with other summarised dataset</figcaption></figure><p id="4d97" class="pw-post-body-paragraph ko kp it kq b kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll im bi translated">我们稍后将需要一个用户列表，当在特征工程部分加入数据集时，创建一个新的列名<code class="fe nl nm nn no b">churned</code></p><pre class="mc md me mf gt np no nq nr aw ns bi"><span id="0ae1" class="nt mj it no b gy nu nv l nw nx">churn_data_summary = churn_data.select('userId')\<br/>                               .withColumn('churned', F.lit(True))</span><span id="24cd" class="nt mj it no b gy ny nv l nw nx">churn_data_summary.show(10)</span></pre><figure class="mc md me mf gt ju gh gi paragraph-image"><div class="gh gi ok"><img src="../Images/2206b040b13c3459a7ab84d6b364d1d7.png" data-original-src="https://miro.medium.com/v2/resize:fit:428/format:webp/1*wEiHsp-7wGeCNhVroSvUrg.png"/></div><figcaption class="kb kc gj gh gi kd ke bd b be z dk">Churned userIds</figcaption></figure><h1 id="8028" class="mi mj it bd mk ml mm mn mo mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne nf bi translated">特征工程</h1><p id="3598" class="pw-post-body-paragraph ko kp it kq b kr ng kt ku kv nh kx ky kz ni lb lc ld nj lf lg lh nk lj lk ll im bi translated">在这一部分中，我们将构建一些特征/预测器来预测不稳定的用户。这通常意味着使用现有的列创建新的列，并进行转换，以便我们可以输入到 ML 管道中。</p><p id="8b6c" class="pw-post-body-paragraph ko kp it kq b kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll im bi translated"><strong class="kq iu">平均会话间隔时间</strong></p><p id="3818" class="pw-post-body-paragraph ko kp it kq b kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll im bi translated">衡量用户参与度的一个有用功能是查看用户收听 Sparkify 平台的频率。我们会查看用户有多少个会话以及会话之间的平均时间。如果用户经常访问我们的应用程序/平台，他们可能会更加投入，因此，对于投入的用户来说，平均会话间隔时间应该更短。</p><figure class="mc md me mf gt ju"><div class="bz fp l di"><div class="mg mh l"/></div></figure><figure class="mc md me mf gt ju gh gi paragraph-image"><div class="gh gi ol"><img src="../Images/e2186a1a80c59aef3f82628254b4d045.png" data-original-src="https://miro.medium.com/v2/resize:fit:1360/format:webp/1*X56-f-wsYQIh20_QPCt0ew.png"/></div><figcaption class="kb kc gj gh gi kd ke bd b be z dk">userId 10 has 6 streaming sessions and mean time between sessions is 7 days.</figcaption></figure><p id="f5bd" class="pw-post-body-paragraph ko kp it kq b kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll im bi translated">在我们的模型中，我们只需要将<code class="fe nl nm nn no b">sessionsFreqDay</code>作为我们的特征，而<code class="fe nl nm nn no b">userId</code>是连接下面其他数据集的关键，剩余的列是不必要的，所以我们要过滤掉</p><pre class="mc md me mf gt np no nq nr aw ns bi"><span id="4eb0" class="nt mj it no b gy nu nv l nw nx">listen_freq = listen_freq.select('userId', 'sessionsFreqDay')</span><span id="1365" class="nt mj it no b gy ny nv l nw nx">listen_freq.show(10)</span></pre><figure class="mc md me mf gt ju gh gi paragraph-image"><div class="gh gi om"><img src="../Images/4fe9d082e1137cd116ac5af9a9a09ed8.png" data-original-src="https://miro.medium.com/v2/resize:fit:466/format:webp/1*AYJ7jSizCkCmesaVoR0v_w.png"/></div><figcaption class="kb kc gj gh gi kd ke bd b be z dk">we use userId as key when joining with other data. sessionsFreqDay is a new feature engineered predictor</figcaption></figure><p id="c14d" class="pw-post-body-paragraph ko kp it kq b kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll im bi translated"><strong class="kq iu">会话计数，平均歌曲计数/会话</strong></p><p id="dd33" class="pw-post-body-paragraph ko kp it kq b kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll im bi translated">另外两个好的预测指标是给定用户的总会话数和每次会话收听的平均歌曲数。如果用户有更多的会话，并且每个会话听很多首歌，他们可能会更投入。</p><p id="7f30" class="pw-post-body-paragraph ko kp it kq b kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll im bi translated">下面是另一个聚合数据集，显示了每个用户的收听活动摘要、他们收听了多少个会话以及所有会话的平均歌曲数。</p><figure class="mc md me mf gt ju"><div class="bz fp l di"><div class="mg mh l"/></div></figure><figure class="mc md me mf gt ju gh gi paragraph-image"><div class="gh gi on"><img src="../Images/4d65da376dc93a335a1c52d781e6c587.png" data-original-src="https://miro.medium.com/v2/resize:fit:692/format:webp/1*F-UebdwC_i_fLE2gGIMSDg.png"/></div><figcaption class="kb kc gj gh gi kd ke bd b be z dk">user with id 10, has 6 sessions and on average he/she listened to 133.7 songs/session, whereas user with id 100006 has only 1 session and listened to 45 songs. User 100006 is engaged less.</figcaption></figure><p id="06d3" class="pw-post-body-paragraph ko kp it kq b kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll im bi translated">下面是上面用于<code class="fe nl nm nn no b">user_engagement</code>的 pyspark 代码的 SQL 等价物，我只是在这里添加作为参考，它给出了完全相同的数据，但是使用了更容易阅读的参考。对于那些更喜欢 SQL 而不是 Dataframe 方法的人来说，他们会很高兴地看到他们几乎可以只用 SQL 来进行数据操作。</p><figure class="mc md me mf gt ju"><div class="bz fp l di"><div class="mg mh l"/></div></figure><figure class="mc md me mf gt ju gh gi paragraph-image"><div class="gh gi on"><img src="../Images/4d65da376dc93a335a1c52d781e6c587.png" data-original-src="https://miro.medium.com/v2/resize:fit:692/format:webp/1*F-UebdwC_i_fLE2gGIMSDg.png"/></div><figcaption class="kb kc gj gh gi kd ke bd b be z dk">Same result is achieved with SQL</figcaption></figure><p id="a53b" class="pw-post-body-paragraph ko kp it kq b kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll im bi translated"><strong class="kq iu">用户功能</strong></p><p id="c0f0" class="pw-post-body-paragraph ko kp it kq b kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll im bi translated"><em class="ly">像</em> <code class="fe nl nm nn no b"><em class="ly">gender</em></code> <em class="ly">和</em> <code class="fe nl nm nn no b"><em class="ly">level</em></code> <em class="ly">这样的用户特征在预测客户流失时会很有用，因为免费用户和付费用户或者女性和男性用户的行为可能会有所不同。让我们将这些特征保存到</em> <code class="fe nl nm nn no b"><em class="ly">user_feature</em></code> <em class="ly">数据帧</em>中</p><pre class="mc md me mf gt np no nq nr aw ns bi"><span id="4756" class="nt mj it no b gy nu nv l nw nx">user_features = data.select('gender', 'userid', 'level')\<br/>                    .distinct().orderBy('userId')</span><span id="91d5" class="nt mj it no b gy ny nv l nw nx">user_features.show(10)</span></pre><figure class="mc md me mf gt ju gh gi paragraph-image"><div class="gh gi oo"><img src="../Images/ee7affb1aa62c03afa5ee9f1c5c5d10c.png" data-original-src="https://miro.medium.com/v2/resize:fit:430/format:webp/1*4FUyuVRkUm59Q2Ii0QZK9Q.png"/></div><figcaption class="kb kc gj gh gi kd ke bd b be z dk">User Features</figcaption></figure><p id="1fbc" class="pw-post-body-paragraph ko kp it kq b kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll im bi translated">最后，让我们将上面创建的所有功能加入到一个<code class="fe nl nm nn no b">joined</code>数据框架中</p><figure class="mc md me mf gt ju"><div class="bz fp l di"><div class="mg mh l"/></div></figure><figure class="mc md me mf gt ju gh gi paragraph-image"><div class="gh gi op"><img src="../Images/7e08d0ed264c3f6e0618162244b4f45e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1366/format:webp/1*-poUcZ6A4PgWyhnNCKCzUw.png"/></div><figcaption class="kb kc gj gh gi kd ke bd b be z dk">churned column is the target variable and all other columns (except userId) are predictors</figcaption></figure><p id="439d" class="pw-post-body-paragraph ko kp it kq b kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll im bi translated">现在我们有 5 个流失预测列:</p><ul class=""><li id="732a" class="oq or it kq b kr ks kv kw kz os ld ot lh ou ll ov ow ox oy bi translated"><code class="fe nl nm nn no b">gender</code> : M 或 F</li><li id="59df" class="oq or it kq b kr oz kv pa kz pb ld pc lh pd ll ov ow ox oy bi translated"><code class="fe nl nm nn no b">level</code> : <strong class="kq iu">付费</strong>或<strong class="kq iu">免费</strong></li><li id="6523" class="oq or it kq b kr oz kv pa kz pb ld pc lh pd ll ov ow ox oy bi translated"><code class="fe nl nm nn no b">sessionCount</code>:用户听了多少次音乐？每个会话有多首歌曲</li><li id="ef6b" class="oq or it kq b kr oz kv pa kz pb ld pc lh pd ll ov ow ox oy bi translated"><code class="fe nl nm nn no b">meanSongCount</code>:对于给定的会话，每个用户平均听了多少首歌？(一次会议持续多长时间)</li><li id="4608" class="oq or it kq b kr oz kv pa kz pb ld pc lh pd ll ov ow ox oy bi translated"><code class="fe nl nm nn no b">sessionFreqDay</code>:会话之间的平均天数是多少？更低意味着更多的参与。</li></ul><p id="529d" class="pw-post-body-paragraph ko kp it kq b kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll im bi translated">在继续之前，让我们做一个理智检查，看看我们的预测是否有意义。下面是每个<code class="fe nl nm nn no b">churned</code>和<code class="fe nl nm nn no b">gender</code>组的<code class="fe nl nm nn no b">sessionCount</code>、<code class="fe nl nm nn no b">meanSongCount</code>和<code class="fe nl nm nn no b">SessionFreqDay</code>的平均值</p><pre class="mc md me mf gt np no nq nr aw ns bi"><span id="3c86" class="nt mj it no b gy nu nv l nw nx">joined.groupBy('churned','gender')\<br/>      .agg({'sessionCount': 'mean', <br/>            'meanSongCount': 'mean',<br/>            'sessionsFreqDay': 'mean'})\<br/>      .orderBy('churned','gender')\<br/>      .show()</span></pre><figure class="mc md me mf gt ju gh gi paragraph-image"><div class="gh gi pe"><img src="../Images/c017fcaabaac99b677debc4ed8e2565c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1282/format:webp/1*eXYh7X-aOBki4UrJHnEJOA.png"/></div></figure><p id="d780" class="pw-post-body-paragraph ko kp it kq b kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll im bi translated">根据上表，易激动用户倾向于拥有较低的<code class="fe nl nm nn no b">sessionCount</code>，他们在会话中听较少的音乐，但是更频繁地使用平台<em class="ly">(易激动用户的会话间隔为 2 - 2.5 天，非易激动用户为 4 - 4.8 天)。最后一个观察结果与我们的预期有点相反，但这仍然是一个有用的预测。一个有趣的发现是，女性用户比男性用户更喜欢这个平台，这对我们的模型也很有用</em></p><pre class="mc md me mf gt np no nq nr aw ns bi"><span id="e92a" class="nt mj it no b gy nu nv l nw nx">joined.groupBy('churned','level')\<br/>      .agg({'sessionCount': 'mean', <br/>            'meanSongCount': 'mean',<br/>            'sessionsFreqDay': 'mean'})\<br/>      .orderBy('churned','level')\<br/>      .show()</span></pre><figure class="mc md me mf gt ju gh gi paragraph-image"><div class="gh gi pf"><img src="../Images/abbb0ede96f92eb7322a3718c45065d5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1260/format:webp/1*eV00ZhoLtpCGl8m4ClKGlg.png"/></div></figure><p id="e55a" class="pw-post-body-paragraph ko kp it kq b kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll im bi translated">当我们从<em class="ly">免费</em>或<em class="ly">付费</em>用户的角度看数据时，也有类似的观察。<code class="fe nl nm nn no b">sessionCount</code>和<code class="fe nl nm nn no b">meanSongCount</code>对于非搅动用户来说都高于预期，但是搅动用户更频繁地使用该平台。这是否意味着他们不是因为缺乏兴趣，而是因为找不到想要的音乐而烦恼，并因此离开了平台？这将是一个有趣的想法，供以后探讨。但是我们不会在这篇博文中看到它。问问题总是一个好习惯，如果有矛盾的发现，问更多的问题来发现潜在的事实。</p><p id="6643" class="pw-post-body-paragraph ko kp it kq b kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll im bi translated">我们有一个矛盾发现的另一个原因可能只是统计学上的怪癖。辛普森悖论在某些情况下可能会困扰我们。为了确保我们没有陷入辛普森悖论的统计谬误，让我们一起来看看 T10 和 T11。</p><pre class="mc md me mf gt np no nq nr aw ns bi"><span id="14d2" class="nt mj it no b gy nu nv l nw nx">joined.groupBy('churned','level', 'gender')\<br/>      .agg({'sessionCount': 'mean', <br/>            'meanSongCount': 'mean',<br/>            'sessionsFreqDay': 'mean'})\<br/>      .orderBy('churned','level', 'gender')\<br/>      .show()</span></pre><figure class="mc md me mf gt ju gh gi paragraph-image"><div class="gh gi pg"><img src="../Images/4882099309a525957cde7f74969efeb9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1378/format:webp/1*Ct0O0IOeU8444kXQW5OrwQ.png"/></div></figure><p id="1547" class="pw-post-body-paragraph ko kp it kq b kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll im bi translated">通过<code class="fe nl nm nn no b">level</code>和<code class="fe nl nm nn no b">gender</code>的划分仍然显示，被搅动的用户有更频繁的参与。从这个角度来看，不存在辛普森悖论</p></div><div class="ab cl kh ki hx kj" role="separator"><span class="kk bw bk kl km kn"/><span class="kk bw bk kl km kn"/><span class="kk bw bk kl km"/></div><div class="im in io ip iq"><p id="41bf" class="pw-post-body-paragraph ko kp it kq b kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll im bi translated">Spark 中的机器学习模型只能处理数字，因此我们需要将我们的分类特征转换成数字。</p><p id="0c31" class="pw-post-body-paragraph ko kp it kq b kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll im bi translated">我们将使用<code class="fe nl nm nn no b">StringIndexer</code>，将数字分配给<code class="fe nl nm nn no b">level</code>和<code class="fe nl nm nn no b">gender</code>，并使用<code class="fe nl nm nn no b">OneHotEncoderEstimator</code>将它们编码成<code class="fe nl nm nn no b">SparseVector</code>。</p><figure class="mc md me mf gt ju"><div class="bz fp l di"><div class="mg mh l"/></div><figcaption class="kb kc gj gh gi kd ke bd b be z dk">Converting Strings into indexes then One Hot Encoding into Sparse Vector</figcaption></figure><pre class="mc md me mf gt np no nq nr aw ns bi"><span id="f454" class="nt mj it no b gy nu nv l nw nx"># Dropping gender and level (temporarily), just to fit the cell into # screen for readability</span><span id="1df5" class="nt mj it no b gy ny nv l nw nx">joined.drop('gender', 'level').show()</span></pre><figure class="mc md me mf gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi ph"><img src="../Images/c8ab4383d6c56ada2a672ffff81ab22c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ciI-xcnE3YnGjgmnZUeVFg.png"/></div></div><figcaption class="kb kc gj gh gi kd ke bd b be z dk">String Indexers created level_idx and gender_idx and OneHotEncoderEstimator created dummy columns</figcaption></figure><p id="9715" class="pw-post-body-paragraph ko kp it kq b kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll im bi translated">如果数字列中的数据是偏斜的，预测值强度会降低，因此我们还应该检查数字列<code class="fe nl nm nn no b">sessionCount</code>、<code class="fe nl nm nn no b">meanSongCount</code>和<code class="fe nl nm nn no b">sessionsFreqDay</code>的分布。让我们目测一下</p><pre class="mc md me mf gt np no nq nr aw ns bi"><span id="54d4" class="nt mj it no b gy nu nv l nw nx">joined_pandas = joined.select('sessionCount', <br/>                              'meanSongCount',<br/>                              'sessionsFreqDay')\<br/>                      .toPandas()</span><span id="f847" class="nt mj it no b gy ny nv l nw nx">f, axes = plt.subplots(2, 3, figsize=(14, 7), sharex=False)</span><span id="4bbe" class="nt mj it no b gy ny nv l nw nx">sns.distplot( joined_pandas["sessionCount"] , color="skyblue", ax=axes[0, 0])</span><span id="ffbb" class="nt mj it no b gy ny nv l nw nx">sns.distplot( joined_pandas["meanSongCount"] , color="olive", ax=axes[0, 1])</span><span id="7a7a" class="nt mj it no b gy ny nv l nw nx">sns.distplot( joined_pandas["sessionsFreqDay"] , color="gold", ax=axes[0, 2])</span></pre><figure class="mc md me mf gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi pi"><img src="../Images/4eba19d90b97e9652c45a291c214cfa9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*aWpRgKQGGVT28-dDZoVbyQ.png"/></div></div><figcaption class="kb kc gj gh gi kd ke bd b be z dk">All numeric features seems left skewed. We better transform them before modelling.</figcaption></figure><p id="11c5" class="pw-post-body-paragraph ko kp it kq b kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll im bi translated">所有看起来都向左倾斜，让我们应用<code class="fe nl nm nn no b">log</code>和<code class="fe nl nm nn no b">sqrt</code>变换来处理倾斜</p><figure class="mc md me mf gt ju"><div class="bz fp l di"><div class="mg mh l"/></div></figure><figure class="mc md me mf gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi pj"><img src="../Images/60e26634b4079f94635fe86d3ae5aeee.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*i5XudHWwUBl9YGirChBYhQ.png"/></div></div><figcaption class="kb kc gj gh gi kd ke bd b be z dk">Original distribution (top row) and features after transformation. Transformation helped to fix skew.</figcaption></figure><p id="a012" class="pw-post-body-paragraph ko kp it kq b kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll im bi translated">这看起来更好，我们回到我们的 spark 数据框架<code class="fe nl nm nn no b">joined</code>并在那里应用转换。</p><pre class="mc md me mf gt np no nq nr aw ns bi"><span id="9d3f" class="nt mj it no b gy nu nv l nw nx">joined = joined\<br/>         .withColumn('logSessionCount', F.log('sessionCount'))\<br/>         .withColumn('sqrtMeanSongCount', F.sqrt('meanSongCount'))\<br/>         .withColumn('sqrtSessionsFreqDay', F.sqrt('sessionsFreqDay'))</span><span id="ae16" class="nt mj it no b gy ny nv l nw nx">joined.cache()<br/>joined.take(1)</span></pre><figure class="mc md me mf gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi pk"><img src="../Images/0423ee547954a98fc722bafb3e662390.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ENnaPkXmYDwVBbhihARjQw.png"/></div></div><figcaption class="kb kc gj gh gi kd ke bd b be z dk">New Columns logSessionCount, sqrtMeanSongCount and sqrtSessionsFreqDay are created</figcaption></figure><p id="4afb" class="pw-post-body-paragraph ko kp it kq b kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll im bi translated">最后，我们需要创建两列，<code class="fe nl nm nn no b">label</code>和<code class="fe nl nm nn no b">features</code>。Spark ML 需要<code class="fe nl nm nn no b">label</code>列，它必须是数字，这意味着我们需要通过转换成整数将<code class="fe nl nm nn no b">churned</code>列转换成<code class="fe nl nm nn no b">label</code></p><p id="3d6b" class="pw-post-body-paragraph ko kp it kq b kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll im bi translated">我们还需要所有的预测器都在一个向量中，Spark ML 处理向量，所以我们需要连接所有这 5 个预测器。</p><figure class="mc md me mf gt ju"><div class="bz fp l di"><div class="mg mh l"/></div><figcaption class="kb kc gj gh gi kd ke bd b be z dk">Spark needs a features vector, therefore we add all our predictors into a Dense Vector using VectorAssembler</figcaption></figure><figure class="mc md me mf gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi pl"><img src="../Images/3bfda51ce80eed2ea02388ca3a34010b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*hUIemfPMzSIuPNonKkkPTg.png"/></div></div><figcaption class="kb kc gj gh gi kd ke bd b be z dk"><strong class="bd oe">nonScaledFeatures</strong> is a DenseVector created from other features</figcaption></figure><p id="2264" class="pw-post-body-paragraph ko kp it kq b kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll im bi translated">仅关注<code class="fe nl nm nn no b">nonScaledFeatures</code>和<code class="fe nl nm nn no b">label</code>:</p><pre class="mc md me mf gt np no nq nr aw ns bi"><span id="8f91" class="nt mj it no b gy nu nv l nw nx">joined_vector.select('nonScaledFeatures', 'label')\<br/>              .show(10, truncate=False)</span></pre><figure class="mc md me mf gt ju gh gi paragraph-image"><div class="gh gi pm"><img src="../Images/1f2b4acd44b0083fab943705c8e10331.png" data-original-src="https://miro.medium.com/v2/resize:fit:1252/format:webp/1*QRjlQXKO7NQeOAnOV3ykeA.png"/></div></figure><p id="a8f4" class="pw-post-body-paragraph ko kp it kq b kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll im bi translated">机器学习模型更好地处理标准化/规模化数据，因此我们需要在进入建模阶段之前标准化/规模化我们的特征</p><pre class="mc md me mf gt np no nq nr aw ns bi"><span id="e176" class="nt mj it no b gy nu nv l nw nx">scaled = StandardScaler(inputCol="nonScaledFeatures", <br/>                        outputCol="features",<br/>                        withStd=True, <br/>                        withMean=True)\<br/>                        .fit(joined_vector)\<br/>                        .transform(joined_vector)</span><span id="113a" class="nt mj it no b gy ny nv l nw nx">scaled.select('features', 'label').show(10, truncate=False)</span></pre><figure class="mc md me mf gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi pn"><img src="../Images/b7079eeca865fbdbfb3aed01acc3acaa.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Wnun7w9cvzWKcfcaXd3tHw.png"/></div></div></figure><h1 id="3482" class="mi mj it bd mk ml mm mn mo mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne nf bi translated">建模</h1><p id="5803" class="pw-post-body-paragraph ko kp it kq b kr ng kt ku kv nh kx ky kz ni lb lc ld nj lf lg lh nk lj lk ll im bi translated">现在我们在向量中有了缩放/标准化的特征，并标记为预测因子，我们可以进入建模阶段。</p><p id="67a1" class="pw-post-body-paragraph ko kp it kq b kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll im bi translated">这里，我们需要将完整的数据集分成训练集、测试集和测试几种机器学习方法。我们将评估各种模型的准确性，必要时调整参数。我们将根据测试准确性确定获胜模型，并在验证集上报告结果。</p><p id="ecfe" class="pw-post-body-paragraph ko kp it kq b kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll im bi translated">我们评估三个模型，<code class="fe nl nm nn no b">DecisionTreeClassifier</code>和<code class="fe nl nm nn no b">RandomForestClassifier</code>和<code class="fe nl nm nn no b">GBTClassifier</code>。<code class="fe nl nm nn no b">RandomForestClassifer</code>和<code class="fe nl nm nn no b">GBTClassifier</code>将许多<code class="fe nl nm nn no b">DecisionTreeClassifiers</code>结合起来，通过使分类器不容易过度拟合来获得更好的精度。<code class="fe nl nm nn no b">DecisionTreeClassifer</code>一般倾向于过度拟合。</p><p id="9599" class="pw-post-body-paragraph ko kp it kq b kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll im bi translated">我们的第一个模型是带有默认输入的<code class="fe nl nm nn no b">DecisionTreeClassifier</code></p><pre class="mc md me mf gt np no nq nr aw ns bi"><span id="2d3b" class="nt mj it no b gy nu nv l nw nx">train, test = scaled.randomSplit([0.8, 0.2], seed=42)</span><span id="cd33" class="nt mj it no b gy ny nv l nw nx">tree = DecisionTreeClassifier()<br/>prediction_tree = tree.fit(train).transform(test)<br/>prediction_tree.groupBy('label', 'prediction').count().show()</span></pre><figure class="mc md me mf gt ju gh gi paragraph-image"><div class="gh gi po"><img src="../Images/470b382657bf707195284c875d406bf9.png" data-original-src="https://miro.medium.com/v2/resize:fit:418/format:webp/1*HH8pNlE5ZNySOrshm9NSAQ.png"/></div><figcaption class="kb kc gj gh gi kd ke bd b be z dk">DecisionTreeClassifier predicted 9 churns correctly, but missed 8 churns</figcaption></figure><p id="6ff1" class="pw-post-body-paragraph ko kp it kq b kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll im bi translated">为了更深入的了解，我们可以看看每个预测的概率值</p><pre class="mc md me mf gt np no nq nr aw ns bi"><span id="0db0" class="nt mj it no b gy nu nv l nw nx">prediction_tree.select('label', 'prediction', 'probability')\<br/>               .show(20, False)</span></pre><figure class="mc md me mf gt ju gh gi paragraph-image"><div class="gh gi pp"><img src="../Images/342fb7ff38ba50a85d63cc7d49c7d049.png" data-original-src="https://miro.medium.com/v2/resize:fit:1030/format:webp/1*P2yRFDsYHSvRAb6La83rgw.png"/></div><figcaption class="kb kc gj gh gi kd ke bd b be z dk">labels, predictions and probability values for each user</figcaption></figure><p id="62ad" class="pw-post-body-paragraph ko kp it kq b kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll im bi translated">流失事件相当稀疏，基本决策树分类器能够成功预测 9 个流失事件，错过 8 个，错误预测 2 个客户将流失，但没有。</p><p id="4705" class="pw-post-body-paragraph ko kp it kq b kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll im bi translated">现在我们来看一下带有默认超参数的<code class="fe nl nm nn no b">RandomForestClassifier</code></p><pre class="mc md me mf gt np no nq nr aw ns bi"><span id="942e" class="nt mj it no b gy nu nv l nw nx">prediction_forest = RandomForestClassifier()\<br/>                           .fit(train)\<br/>                           .transform(test)</span><span id="2103" class="nt mj it no b gy ny nv l nw nx">prediction_forest.groupBy('label', 'prediction').count().show()</span></pre><figure class="mc md me mf gt ju gh gi paragraph-image"><div class="gh gi ok"><img src="../Images/77894d8492044012e6bb1b3296ad6530.png" data-original-src="https://miro.medium.com/v2/resize:fit:428/format:webp/1*KekYyz6gRpnwsZy7sr0A2g.png"/></div><figcaption class="kb kc gj gh gi kd ke bd b be z dk">RandomForestClassifier predictions</figcaption></figure><p id="276e" class="pw-post-body-paragraph ko kp it kq b kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll im bi translated">与<code class="fe nl nm nn no b">DecisionTreeClassifier</code>相比，<code class="fe nl nm nn no b">RandomForestClassifier</code>在这种情况下并没有表现得特别好</p><p id="9f7c" class="pw-post-body-paragraph ko kp it kq b kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll im bi translated">最后让我们看看梯度增强树分类器</p><pre class="mc md me mf gt np no nq nr aw ns bi"><span id="d0cb" class="nt mj it no b gy nu nv l nw nx">from pyspark.ml.classification import GBTClassifier</span><span id="e994" class="nt mj it no b gy ny nv l nw nx">gbt = GBTClassifier(featuresCol='features', labelCol='label')<br/>pred_gbt = gbt.fit(train).transform(test)</span><span id="ef10" class="nt mj it no b gy ny nv l nw nx">pred_gbt.groupBy('label', 'prediction').count().show()</span></pre><figure class="mc md me mf gt ju gh gi paragraph-image"><div class="gh gi pq"><img src="../Images/eae09e5075d5107e4ebc3be9950e3474.png" data-original-src="https://miro.medium.com/v2/resize:fit:420/format:webp/1*oWjhyEGCNVBM3JjRQOBJSw.png"/></div><figcaption class="kb kc gj gh gi kd ke bd b be z dk">GBTClassifier has better prediction capability in this test set</figcaption></figure><p id="f70d" class="pw-post-body-paragraph ko kp it kq b kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll im bi translated"><code class="fe nl nm nn no b">GBTClassifier</code>能够超越简单的<code class="fe nl nm nn no b">DecisionTreeClassifier</code>和<code class="fe nl nm nn no b">RandomForestClasssifier</code>。它能够成功地预测 11 次搅拌，只错过了 6 次搅拌。</p><h1 id="3145" class="mi mj it bd mk ml mm mn mo mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne nf bi translated">模型评估、管道、交叉验证和网格搜索</h1><p id="5ef1" class="pw-post-body-paragraph ko kp it kq b kr ng kt ku kv nh kx ky kz ni lb lc ld nj lf lg lh nk lj lk ll im bi translated">尽管我们通过创建几个表来检查我们的预测准确性，但是 Apache Spark ML 库已经内置了评估器来评估我们的模型是否成功。在我们的例子中，我们的标签是我们可以使用的唯一一个二进制类<code class="fe nl nm nn no b">BinaryClassificationEvaluator</code>。</p><p id="bc1c" class="pw-post-body-paragraph ko kp it kq b kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll im bi translated">另一方面，管道对于创建健壮的 ML 管道和避免测试数据泄漏到模型训练中非常有用。管道也让我们的代码更加整洁。</p><p id="5d61" class="pw-post-body-paragraph ko kp it kq b kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll im bi translated">交叉验证允许我们将训练数据集划分为折叠，并在每个折叠上进行训练，以找到更好的模型。</p><p id="a5c0" class="pw-post-body-paragraph ko kp it kq b kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll im bi translated">许多模型、转换器和索引器都有超参数。GridSearch 允许我们尝试许多不同的超参数，并使用这些超参数的笛卡尔乘积自动构建许多模型。找到理想的参数被称为模型调整，GridSeach 使这变得轻而易举。</p><p id="ede9" class="pw-post-body-paragraph ko kp it kq b kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll im bi translated">让我们再次获取连接的数据，并在输入管道之前应用<code class="fe nl nm nn no b">log</code>或<code class="fe nl nm nn no b">sqrt</code>转换</p><pre class="mc md me mf gt np no nq nr aw ns bi"><span id="b778" class="nt mj it no b gy nu nv l nw nx">joined = user_features\<br/>    .join(churn_data_summary, <br/>          on=['userId'], <br/>          how='left')\<br/>    .join(user_engagement, <br/>          on=['userId'], <br/>          how='left')\<br/>    .join(listen_freq,<br/>          on=['userId'],<br/>          how='left')\<br/>    .orderBy('userId')\<br/>    .fillna(False, subset=['churned'])\<br/>    .withColumn('churned', <br/>                col('churned').cast('integer'))\<br/>    .withColumn('logSessionCount', F.log('sessionCount'))\<br/>    .withColumn('sqrtMeanSongCount', F.sqrt('meanSongCount'))\<br/>    .withColumn('sqrtSessionsFreqDay', F.sqrt('sessionsFreqDay'))</span><span id="b667" class="nt mj it no b gy ny nv l nw nx">joined.cache()<br/>joined.show(5)</span></pre><figure class="mc md me mf gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi pr"><img src="../Images/a5a5d9d29a7bfb23c64691f169f0751b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*mG_JHBzygeKxilJ9qeA8Ww.png"/></div></div><figcaption class="kb kc gj gh gi kd ke bd b be z dk">cleaned dataset, ready for Pipeline</figcaption></figure><p id="9937" class="pw-post-body-paragraph ko kp it kq b kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll im bi translated">现在定义 ML 管道的每个阶段</p><figure class="mc md me mf gt ju"><div class="bz fp l di"><div class="mg mh l"/></div><figcaption class="kb kc gj gh gi kd ke bd b be z dk">Stages define the order of transformations to be applied</figcaption></figure><pre class="mc md me mf gt np no nq nr aw ns bi"><span id="02c2" class="nt mj it no b gy nu nv l nw nx">[StringIndexer_68305429c317,<br/> StringIndexer_c98ace58d733,<br/> OneHotEncoderEstimator_0216ca1e6769,<br/> VectorAssembler_45b1ace90533,<br/> MinMaxScaler_bfcb63301c7e,<br/> StandardScaler_dd543c1f0b07,<br/> RandomForestClassifier_dce35260ff2f]</span></pre><p id="17f1" class="pw-post-body-paragraph ko kp it kq b kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll im bi translated">创建一个网格搜索对象，我们定义不同的<code class="fe nl nm nn no b">RandomForestClassifer</code>参数，如<code class="fe nl nm nn no b">maxDepth</code>或<code class="fe nl nm nn no b">featureSubsetStrategy</code></p><p id="842d" class="pw-post-body-paragraph ko kp it kq b kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll im bi translated">还要定义评估器，该评估器将评估由网格搜索创建的模型的性能，并且将选择具有基于评估器的 bets 度量的模型。</p><figure class="mc md me mf gt ju"><div class="bz fp l di"><div class="mg mh l"/></div></figure><pre class="mc md me mf gt np no nq nr aw ns bi"><span id="7a84" class="nt mj it no b gy nu nv l nw nx">"Number of models to be tested with 5 crossfolds = {}".format(5*len(params))</span></pre><p id="bf3d" class="pw-post-body-paragraph ko kp it kq b kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll im bi translated"><code class="fe nl nm nn no b">&gt; Number of models to be tested with 5 crossfolds = 60</code></p><p id="de15" class="pw-post-body-paragraph ko kp it kq b kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll im bi translated">由于我们正在安装 60 个模型，这可能需要一些时间。Spark 可以并行拟合模型以加速训练，但在这种情况下，我们串行进行，因为我们只有本地集群。</p><pre class="mc md me mf gt np no nq nr aw ns bi"><span id="64fe" class="nt mj it no b gy nu nv l nw nx">train, test = joined.randomSplit([0.8, 0.2], seed=42)<br/>model = cv.fit(train)</span><span id="2e48" class="nt mj it no b gy ny nv l nw nx">model.avgMetrics</span></pre><figure class="mc md me mf gt ju gh gi paragraph-image"><div class="gh gi ps"><img src="../Images/96c11f044ac32f079dd47ed5f56e0fbc.png" data-original-src="https://miro.medium.com/v2/resize:fit:356/format:webp/1*xyReEADLeaLUtp4Rl6zwAw.png"/></div><figcaption class="kb kc gj gh gi kd ke bd b be z dk">Evaluator results for each model 3 x 4 hyperparameters</figcaption></figure><p id="c16e" class="pw-post-body-paragraph ko kp it kq b kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll im bi translated">我们确实有很多模型，但是<code class="fe nl nm nn no b">cv.transform() </code>会根据评估器自动选择最佳模型。</p><p id="ebec" class="pw-post-body-paragraph ko kp it kq b kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll im bi translated">让我们用最好的模型来预测</p><pre class="mc md me mf gt np no nq nr aw ns bi"><span id="27eb" class="nt mj it no b gy nu nv l nw nx">predictions = model.transform(test)<br/>predictions.groupBy('churned', 'prediction').count().show()</span></pre><figure class="mc md me mf gt ju gh gi paragraph-image"><div class="gh gi ok"><img src="../Images/77894d8492044012e6bb1b3296ad6530.png" data-original-src="https://miro.medium.com/v2/resize:fit:428/format:webp/1*KekYyz6gRpnwsZy7sr0A2g.png"/></div><figcaption class="kb kc gj gh gi kd ke bd b be z dk">Prediction results with RandomForestClassifier with optimum params</figcaption></figure><p id="67e9" class="pw-post-body-paragraph ko kp it kq b kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll im bi translated">在这种情况下，与普通的<code class="fe nl nm nn no b">RandomForestClassifier</code>相比，我们没有得到不同的结果，但是我们看到了如何使用<em class="ly">管道</em>、<em class="ly">交叉验证</em>和<em class="ly">评估器</em>使我们的生活变得更容易。</p><h1 id="c9f7" class="mi mj it bd mk ml mm mn mo mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne nf bi translated">结论</h1><p id="e7a3" class="pw-post-body-paragraph ko kp it kq b kr ng kt ku kv nh kx ky kz ni lb lc ld nj lf lg lh nk lj lk ll im bi translated">作为数据科学家，我们总是试图用数据回答问题，并遵循数学和统计的严谨性。在这篇文章中，问题是预测用户流失，使用一种系统的方法，我们取得了一些成功。这是第一次迭代，通常模型构建需要多次迭代，通过添加更好的预测器或更多数据来进一步优化预测。</p><p id="9dcd" class="pw-post-body-paragraph ko kp it kq b kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll im bi translated">我们还看到了如何使用 Apache Spark 来处理数据、创建新功能、构建模型并对其进行评估。尽管这一转换基于一小部分数据，但同样的转换可以应用于更大的数据集，而无需更改代码。</p><p id="763a" class="pw-post-body-paragraph ko kp it kq b kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll im bi translated">这是一个很长的阅读，但希望你喜欢它</p></div></div>    
</body>
</html>