<html>
<head>
<title>Maximum Likelihood Estimation in Real Life : Optimizing Study Time</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">现实生活中的最大似然估计:优化学习时间</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/maximum-likelihood-estimation-in-real-life-optimizing-study-time-d5cc083d25b4?source=collection_archive---------15-----------------------#2019-01-02">https://towardsdatascience.com/maximum-likelihood-estimation-in-real-life-optimizing-study-time-d5cc083d25b4?source=collection_archive---------15-----------------------#2019-01-02</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><figure class="gl gn jo jp jq jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi jn"><img src="../Images/1763cdbb20f571d4276317d5d3855656.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*143qCDpww31xSFrimYJlqg.jpeg"/></div></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk">Photo by <a class="ae kc" href="https://unsplash.com/photos/Wpnoqo2plFA?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank">Mika Baumeister</a> on <a class="ae kc" href="https://unsplash.com/?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><p id="11c8" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><a class="ae kc" href="https://en.wikipedia.org/wiki/Maximum_likelihood_estimation" rel="noopener ugc nofollow" target="_blank">最大似然估计</a>是一种广泛应用于机器学习的统计技术。它用于选择模型的参数。</p></div><div class="ab cl lb lc hu ld" role="separator"><span class="le bw bk lf lg lh"/><span class="le bw bk lf lg lh"/><span class="le bw bk lf lg"/></div><div class="ij ik il im in"><p id="2f6c" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">考试季节到了，这一次你想更有效地利用你的学习时间。你提前做了计划，并确保跟踪你在过去几轮中为每场考试学习了多少，以及你得了多少分。你最终得到了这个数据集</p><div class="li lj lk ll gt ab cb"><figure class="lm jr ln lo lp lq lr paragraph-image"><img src="../Images/8dba4e1a9ef8bb6c450417dbb9b777af.png" data-original-src="https://miro.medium.com/v2/resize:fit:340/format:webp/1*yWldwG3F8Nr7rhJY3RpOag.jpeg"/></figure><figure class="lm jr ls lo lp lq lr paragraph-image"><img src="../Images/343010770d5e1b02256754a38cc63111.png" data-original-src="https://miro.medium.com/v2/resize:fit:1280/format:webp/1*Hz7w9NJkLr38nofjWOKaJg.jpeg"/><figcaption class="jy jz gj gh gi ka kb bd b be z dk lt di lu lv">Beautiful dummy data 😁</figcaption></figure></div><p id="7485" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">绘制数据可以更容易地看出你花在考试学习上的时间和最终成绩之间的相关性。</p><p id="e02f" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">和前几轮考试一样，你面临的最大挑战是，你有多场考试，每场考试相隔几天。你想制定一个学习计划，让你最大限度地提高成绩，但保证你有足够的时间投入到每场考试中。</p><p id="b0b4" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">你是做什么的？</p><h2 id="003b" class="lw lx iq bd ly lz ma dn mb mc md dp me ko mf mg mh ks mi mj mk kw ml mm mn mo bi translated"><strong class="ak">线性模型来救援了！</strong></h2><p id="44e1" class="pw-post-body-paragraph kd ke iq kf b kg mp ki kj kk mq km kn ko mr kq kr ks ms ku kv kw mt ky kz la ij bi translated">根据每次考试的学习时间，思考一种最大化成绩的方法，你记得上面散点图中的相关性。你可以使用<a class="ae kc" rel="noopener" target="_blank" href="/linear-regression-in-real-life-4a78d7159f16">线性回归</a>来帮助计算出你会得到多少分数，给定你可以为考试投入的学习时间。</p><p id="7e2b" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这是最能描述当前问题的模型</p><figure class="li lj lk ll gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi mu"><img src="../Images/390a63ef3b14a607011ac3c00f1435d0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Dg-eyQ-jVSh-GHK-5qdHvA.jpeg"/></div></div></figure><p id="b330" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">你是根据你学习的时间来预测考试成绩的。你可以使用自己选择的统计软件，对数据集进行线性模型拟合。</p><figure class="li lj lk ll gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi mv"><img src="../Images/0dc94ed40550ed30b13e92580f8b5573.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*iGltLrgIZhFnakaYg4aH7A.jpeg"/></div></div></figure><p id="1e41" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">现在你可以<em class="mw">输入</em>你计划学习多长时间，并根据模型的方程式检查你可能获得的分数。</p><p id="5de0" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这里是我们模型的总结，使用 Python 的<a class="ae kc" href="https://www.statsmodels.org/dev/generated/statsmodels.regression.linear_model.OLS.html" rel="noopener ugc nofollow" target="_blank"> statsmodels 模块</a>获得。</p><figure class="li lj lk ll gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi mx"><img src="../Images/a75ade6e636c4ee34c8b88f442039575.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*X-uJwkoQ4lyWEwVHckuoig.jpeg"/></div></div></figure><p id="8c8f" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们可以看到,<a class="ae kc" href="https://en.wikipedia.org/wiki/Ordinary_least_squares" rel="noopener ugc nofollow" target="_blank">最小二乘法</a>用于将模型(粉色线)拟合到数据集。参数<em class="mw">β0</em>和<em class="mw">β1，</em>也称为模型的系数，分别对应于<em class="mw"> const </em>和<em class="mw"> time </em>。</p><p id="0d82" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">因此，我们有了模型，并用 Python 计算了参数，但问题仍然存在:<strong class="kf ir">我们实际上是如何估计参数的？</strong></p></div><div class="ab cl lb lc hu ld" role="separator"><span class="le bw bk lf lg lh"/><span class="le bw bk lf lg lh"/><span class="le bw bk lf lg"/></div><div class="ij ik il im in"><h1 id="6ca3" class="my lx iq bd ly mz na nb mb nc nd ne me nf ng nh mh ni nj nk mk nl nm nn mn no bi translated">幕后的数学</h1><p id="8100" class="pw-post-body-paragraph kd ke iq kf b kg mp ki kj kk mq km kn ko mr kq kr ks ms ku kv kw mt ky kz la ij bi translated">很棒的是，我们可以使用统计软件来完成所有繁重的工作，并为我们的数据集拟合一个线性模型。</p><p id="89e2" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">但是参数是怎么得到<strong class="kf ir">预估</strong>的呢？</p><p id="21fd" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这些值是随机选取的吗？</p><p id="3c1a" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这就是统计学家 R. A .菲舍尔想出一个好主意的地方！他发现，我们可以建立一个模型，然后<strong class="kf ir">估计参数，使它们最大化获得数据集中观察到的值的可能性。</strong></p><p id="a12d" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">换句话说，我们正在估计参数，以使观察到数据集中的值的概率(即可能性)尽可能高。</p><p id="6dad" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">但在我们开始钻研数学之前，这里有一些关于我们数据集的假设:</p><ul class=""><li id="5438" class="np nq iq kf b kg kh kk kl ko nr ks ns kw nt la nu nv nw nx bi translated">每个数据点都是独立的</li><li id="106a" class="np nq iq kf b kg ny kk nz ko oa ks ob kw oc la nu nv nw nx bi translated">我们的数据集遵循正态分布</li><li id="465f" class="np nq iq kf b kg ny kk nz ko oa ks ob kw oc la nu nv nw nx bi translated">我们模型中的误差也遵循正态分布</li><li id="41b9" class="np nq iq kf b kg ny kk nz ko oa ks ob kw oc la nu nv nw nx bi translated">我们的产出是连续的</li></ul><p id="eff6" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在计算参数时，这些假设非常方便。它们促进了某些数学属性的使用，最终简化了计算！</p><h2 id="25a8" class="lw lx iq bd ly lz ma dn mb mc md dp me ko mf mg mh ks mi mj mk kw ml mm mn mo bi translated">1.解码似然函数</h2><p id="5c4f" class="pw-post-body-paragraph kd ke iq kf b kg mp ki kj kk mq km kn ko mr kq kr ks ms ku kv kw mt ky kz la ij bi translated">到目前为止，我们知道参数必须最大化似然函数</p><figure class="li lj lk ll gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi od"><img src="../Images/a07e96b761a308a68ebf9b7aa42dc299.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Y1NaZsSERWBDxyDht-NAQg.jpeg"/></div></div></figure><p id="e038" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">可能性函数实际上是一种条件概率。它依赖于参数，因为我们将只选择最大化观察数据概率的参数值。</p><p id="c3bc" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">让我们用<em class="mw">θ</em>来表示参数。</p><figure class="li lj lk ll gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi oe"><img src="../Images/d7f71e20d0ebba150d326c0f2b0a609d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*RmAmkpTWQTPFupUsXRi1xg.jpeg"/></div></div></figure><p id="5c17" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们的线性模型，有两个未知参数—<em class="mw">β0，β1</em>。</p><figure class="li lj lk ll gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi of"><img src="../Images/3b3d951b635349b2ec488133ae8b92af.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*7xRASxL6Gz6gRjs2wWSxeQ.jpeg"/></div></div></figure><p id="6c04" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">所以我们可以将似然函数改写为</p><figure class="li lj lk ll gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi og"><img src="../Images/3bdbfbe1ee2b76a97bf911210bd20bdc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*r1MHvRju6rFOSJ61cecGFA.jpeg"/></div></div></figure><p id="27f8" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">迄今为止，我们</p><ul class=""><li id="ab80" class="np nq iq kf b kg kh kk kl ko nr ks ns kw nt la nu nv nw nx bi translated">解读可能性的含义</li><li id="00c1" class="np nq iq kf b kg ny kk nz ko oa ks ob kw oc la nu nv nw nx bi translated">写下线性模型的可能性表达式，作为条件概率</li></ul><h2 id="e3bf" class="lw lx iq bd ly lz ma dn mb mc md dp me ko mf mg mh ks mi mj mk kw ml mm mn mo bi translated">2.概率密度函数</h2><p id="8a30" class="pw-post-body-paragraph kd ke iq kf b kg mp ki kj kk mq km kn ko mr kq kr ks ms ku kv kw mt ky kz la ij bi translated">现在我们知道可能性是一个条件概率，是时候开始深入数学了。</p><p id="3c48" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">根据我们的假设，我们的数据集遵循正态分布，我们正在处理连续数据。因此，我们将使用正态分布的<a class="ae kc" href="https://en.wikipedia.org/wiki/Probability_density_function" rel="noopener ugc nofollow" target="_blank">概率密度函数</a>来定义可能性。</p><p id="0935" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">因为每个数据点都是相互独立的，所以通过使用概率密度函数中的 Pi 符号，数据集中所有点的概率被表示为乘积。</p><figure class="li lj lk ll gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi oh"><img src="../Images/81e1dd31b38c4a2e955573287a724235.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*JKGFUK8CGNOTBbj0rIzfsQ.jpeg"/></div></div></figure><p id="560f" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">为了简化即将到来的计算，我们可以将可能性转化为对数可能性。</p><figure class="li lj lk ll gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi oi"><img src="../Images/d0f4e94e77ffaf418cd52080c8e3a180.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*hlcWQsmnm_-t60mBH0gGgw.jpeg"/></div></div></figure><p id="b412" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">当选择每个参数的值时，这是我们想要最大化的！</p><p id="6313" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">但是我们可以让这个表达式更简单。由于我们最大化了与参数<em class="mw"> beta 0 </em>和<em class="mw"> beta 1 </em>相关的可能性，我们实际上可以忽略其中不包含<em class="mw"> beta 0 </em>或<em class="mw"> beta 1 </em>的任何术语。</p><p id="69d7" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">可能性表达式就变成了</p><figure class="li lj lk ll gt jr gh gi paragraph-image"><div class="gh gi oj"><img src="../Images/1ead6b2105e6c156a31c77d09e9ba4d9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1072/format:webp/1*JvgfYoR7-VFRS5T3nXPbhA.jpeg"/></div></figure><p id="3bcd" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><em class="mw">这个求和看起来眼熟吗？</em></p><p id="7863" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">大家回想一下，我们的线性模型定义为<em class="mw"> y = beta0 + beta1x +误差。</em>如果我们求解这个误差方程，我们得到<em class="mw">误差= y-β0-β1。</em></p><p id="7bee" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kf ir">以上是</strong> <a class="ae kc" href="https://en.wikipedia.org/wiki/Residual_sum_of_squares" rel="noopener ugc nofollow" target="_blank"> <strong class="kf ir">误差平方和</strong> </a> <strong class="kf ir">！</strong></p><p id="ab0c" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">而且，因为我们也假设我们模型中的误差遵循正态分布，在这种情况下使用最大似然法进行参数估计与计算<a class="ae kc" href="https://en.wikipedia.org/wiki/Ordinary_least_squares" rel="noopener ugc nofollow" target="_blank">普通最小二乘法</a>完全相同！</p><p id="8251" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kf ir">在实践中，在这些假设下，最大化可能性与最小化误差平方和是相同的。</strong></p><p id="53b4" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这就是为什么大多数时候我们会看到普通的最小二乘法用于将线性模型拟合到数据集。</p><h2 id="b6c3" class="lw lx iq bd ly lz ma dn mb mc md dp me ko mf mg mh ks mi mj mk kw ml mm mn mo bi translated">3.(最后)估计参数</h2><p id="bcb5" class="pw-post-body-paragraph kd ke iq kf b kg mp ki kj kk mq km kn ko mr kq kr ks ms ku kv kw mt ky kz la ij bi translated">这是我们停下来的地方</p><figure class="li lj lk ll gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi od"><img src="../Images/b0a80c6bd7acb842177bf852ce94721c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*cKRmde_DnB6lQ05_DnaaCw.jpeg"/></div></div></figure><p id="d580" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">为了得到参数值，我们将计算关于<em class="mw">β0</em>和<em class="mw">β1 的偏导数。</em></p><p id="edff" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">从相对于<em class="mw">β0 的偏导数开始。</em></p><figure class="li lj lk ll gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi ok"><img src="../Images/2820a073cca1f0f7b19522b13b57c5f9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_Qy8YXJDIb2Y3BNzx5uXug.jpeg"/></div></div></figure><p id="56af" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">搞定一个，还剩一个！</p><p id="44c0" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">计算关于<em class="mw">β1</em>的偏导数，我们得到</p><figure class="li lj lk ll gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi ol"><img src="../Images/eb350bdcec5f415ddb89ab5c690546e5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*fI5nQRuRWhlLURVM8klgYg.jpeg"/></div></div></figure><p id="7ab5" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">每当我们使用一些统计软件将线性模型拟合到我们的数据集时，这些都是在幕后发生的计算。</p><p id="3983" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">如果我们计算数据集的每个表达式，我们将确认<em class="mw"> beta 0= 37.4571 </em>和<em class="mw"> beta 1= 12.0495 </em>，这是模型摘要中显示的确切值。</p><p id="de13" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><em class="mw">感谢阅读！</em></p></div></div>    
</body>
</html>