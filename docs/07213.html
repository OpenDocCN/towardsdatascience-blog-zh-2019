<html>
<head>
<title>6 Deep Learning models — When should you use them?</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">6 种深度学习模型——什么时候应该使用它们？</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/6-deep-learning-models-10d20afec175?source=collection_archive---------2-----------------------#2019-10-11">https://towardsdatascience.com/6-deep-learning-models-10d20afec175?source=collection_archive---------2-----------------------#2019-10-11</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><figure class="is it gp gr iu iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi ir"><img src="../Images/7cca91aed3d0b6c195c30438bf457279.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*clvumtM8bO2w28Hs"/></div></div><figcaption class="jc jd gj gh gi je jf bd b be z dk">Photo by <a class="ae jg" href="https://unsplash.com/@vlisidis?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Terry Vlisidis</a> on <a class="ae jg" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><h2 id="0173" class="jh ji jj bd b dl jk jl jm jn jo jp dk jq translated" aria-label="kicker paragraph">如何以及何时使用不同的深度学习模型。</h2><div class=""/><div class=""><h2 id="dc8f" class="pw-subtitle-paragraph kp js jj bd b kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg dk translated">从人工神经网络到自动编码器</h2></div><h1 id="88ae" class="lh li jj bd lj lk ll lm ln lo lp lq lr ky ls kz lt lb lu lc lv le lw lf lx ly bi translated">介绍</h1><p id="78a6" class="pw-post-body-paragraph lz ma jj mb b mc md kt me mf mg kw mh mi mj mk ml mm mn mo mp mq mr ms mt mu im bi translated">深度学习是一个不断发展的领域，其应用跨越了许多用例。对于这个领域的任何新手来说，了解和理解深度学习中使用的不同类型的模型是很重要的。在本文中，我将解释以下每个模型:</p><h2 id="4637" class="mv li jj bd lj mw mx dn ln my mz dp lr mi na nb lt mm nc nd lv mq ne nf lx jp bi translated">监督模型</h2><ul class=""><li id="aed0" class="ng nh jj mb b mc md mf mg mi ni mm nj mq nk mu nl nm nn no bi translated">经典神经网络(多层感知器)</li><li id="8ee9" class="ng nh jj mb b mc np mf nq mi nr mm ns mq nt mu nl nm nn no bi translated">卷积神经网络</li><li id="db16" class="ng nh jj mb b mc np mf nq mi nr mm ns mq nt mu nl nm nn no bi translated">递归神经网络</li></ul><h2 id="286b" class="mv li jj bd lj mw mx dn ln my mz dp lr mi na nb lt mm nc nd lv mq ne nf lx jp bi translated">无监督模型</h2><ul class=""><li id="f460" class="ng nh jj mb b mc md mf mg mi ni mm nj mq nk mu nl nm nn no bi translated">自组织映射(SOMs)</li><li id="974b" class="ng nh jj mb b mc np mf nq mi nr mm ns mq nt mu nl nm nn no bi translated">玻尔兹曼机器</li><li id="0f17" class="ng nh jj mb b mc np mf nq mi nr mm ns mq nt mu nl nm nn no bi translated">自动编码器</li></ul><h1 id="3fd8" class="lh li jj bd lj lk ll lm ln lo lp lq lr ky ls kz lt lb lu lc lv le lw lf lx ly bi translated">监督与非监督模型</h1><p id="276e" class="pw-post-body-paragraph lz ma jj mb b mc md kt me mf mg kw mh mi mj mk ml mm mn mo mp mq mr ms mt mu im bi translated">有许多特征可以区分这两者，但最重要的区别在于这些模型是如何训练的。虽然监督模型是通过特定数据集的示例来训练的，但非监督模型只给定了输入数据，没有可以学习的结果集。所以我们一直试图预测的 y 柱，在无监督的模型中是不存在的。监督模型具有回归和分类等任务，并将生成公式，而非监督模型具有聚类和关联规则学习。</p><figure class="nv nw nx ny gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi nu"><img src="../Images/3a4f9c1777f729ea398fbb1ba52973b5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*gTgZJwKKS2M3kUj5T2cdKA.png"/></div></div></figure></div><div class="ab cl nz oa hx ob" role="separator"><span class="oc bw bk od oe of"/><span class="oc bw bk od oe of"/><span class="oc bw bk od oe"/></div><div class="im in io ip iq"><h1 id="898e" class="lh li jj bd lj lk og lm ln lo oh lq lr ky oi kz lt lb oj lc lv le ok lf lx ly bi translated">经典神经网络(多层感知器)</h1><figure class="nv nw nx ny gt iv gh gi paragraph-image"><div class="gh gi ol"><img src="../Images/bae55b74d15554ca7636bceab0a75986.png" data-original-src="https://miro.medium.com/v2/resize:fit:1038/format:webp/1*r3SHKVGYbFsFi9JYrVdWlg.png"/></div></figure><p id="10e5" class="pw-post-body-paragraph lz ma jj mb b mc om kt me mf on kw mh mi oo mk ml mm op mo mp mq oq ms mt mu im bi translated">经典的神经网络也可以被称为多层感知器。感知器模型是美国心理学家弗兰克·罗森布拉特在 1958 年创造的。它的独特性质允许它通过一系列输入来适应基本的二进制模式，模拟人脑的学习模式。多层感知器是由两层以上组成的经典神经网络模型。</p><h2 id="8723" class="mv li jj bd lj mw mx dn ln my mz dp lr mi na nb lt mm nc nd lv mq ne nf lx jp bi translated"><strong class="ak">何时使用</strong></h2><ul class=""><li id="6b30" class="ng nh jj mb b mc md mf mg mi ni mm nj mq nk mu nl nm nn no bi translated">行和列格式的表格数据集(CSV 文件)</li><li id="c02c" class="ng nh jj mb b mc np mf nq mi nr mm ns mq nt mu nl nm nn no bi translated">给定一组实值作为输入的分类和回归问题。</li><li id="8084" class="ng nh jj mb b mc np mf nq mi nr mm ns mq nt mu nl nm nn no bi translated">您的模型需要更高的灵活性。人工神经网络可以应用于不同类型的数据。</li></ul><p id="1a68" class="pw-post-body-paragraph lz ma jj mb b mc om kt me mf on kw mh mi oo mk ml mm op mo mp mq oq ms mt mu im bi translated"><a class="ae jg" href="https://medium.com/swlh/building-an-artificial-neural-network-in-less-than-10-minutes-cbe59dbb903c" rel="noopener">点击这里学习如何用 Python 从头开始构建 ANN。</a></p></div><div class="ab cl nz oa hx ob" role="separator"><span class="oc bw bk od oe of"/><span class="oc bw bk od oe of"/><span class="oc bw bk od oe"/></div><div class="im in io ip iq"><h1 id="0024" class="lh li jj bd lj lk og lm ln lo oh lq lr ky oi kz lt lb oj lc lv le ok lf lx ly bi translated">卷积神经网络</h1><figure class="nv nw nx ny gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi or"><img src="../Images/c0f1111ab96ab848c40c3dc2e46c32b3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*hQSbnWcmmr71C4h6vQtW_g.png"/></div></div></figure><p id="2f1a" class="pw-post-body-paragraph lz ma jj mb b mc om kt me mf on kw mh mi oo mk ml mm op mo mp mq oq ms mt mu im bi translated">卷积神经网络(CNN)是经典人工神经网络的一种更强大、更高级的变体，旨在处理大量复杂的预处理和数据计算。</p><p id="747c" class="pw-post-body-paragraph lz ma jj mb b mc om kt me mf on kw mh mi oo mk ml mm op mo mp mq oq ms mt mu im bi translated">CNN 是为图像数据设计的，可能是图像分类问题中最有效和最灵活的模型。尽管 CNN 并不是专门为处理非图像数据而构建的，但它们也可以用非图像数据获得令人惊叹的结果。</p><p id="e568" class="pw-post-body-paragraph lz ma jj mb b mc om kt me mf on kw mh mi oo mk ml mm op mo mp mq oq ms mt mu im bi translated">将输入数据导入模型后，构建 CNN 有 4 个部分:<br/> 1 .<strong class="mb jt">卷积</strong>:从我们的输入数据中创建特征图的过程。然后应用一个函数来过滤地图。<br/> 2。<strong class="mb jt"> Max-Pooling </strong>:使我们的 CNN 能够检测到修改后的图像。<br/> 3。<strong class="mb jt">展平</strong>:将数据展平成一个数组，这样 CNN 就可以读取了。<br/> 4。<strong class="mb jt">全连接</strong>:隐藏层，也为我们的模型计算损失函数。</p><h2 id="0039" class="mv li jj bd lj mw mx dn ln my mz dp lr mi na nb lt mm nc nd lv mq ne nf lx jp bi translated">何时使用</h2><ul class=""><li id="7fda" class="ng nh jj mb b mc md mf mg mi ni mm nj mq nk mu nl nm nn no bi translated">图像数据集(包括 OCR 文档分析)。</li><li id="4f62" class="ng nh jj mb b mc np mf nq mi nr mm ns mq nt mu nl nm nn no bi translated">输入数据是一个二维字段，但可以在内部转换为一维，以便更快地处理。</li><li id="ff4c" class="ng nh jj mb b mc np mf nq mi nr mm ns mq nt mu nl nm nn no bi translated">当模型在计算输出时可能需要很大的复杂性时。</li></ul><p id="1c37" class="pw-post-body-paragraph lz ma jj mb b mc om kt me mf on kw mh mi oo mk ml mm op mo mp mq oq ms mt mu im bi translated"><a class="ae jg" href="https://medium.com/swlh/deep-learning-predicting-skin-cancer-379084c33573" rel="noopener">点击这里学习如何用 Python 从头开始构建 CNN。</a></p></div><div class="ab cl nz oa hx ob" role="separator"><span class="oc bw bk od oe of"/><span class="oc bw bk od oe of"/><span class="oc bw bk od oe"/></div><div class="im in io ip iq"><h1 id="f675" class="lh li jj bd lj lk og lm ln lo oh lq lr ky oi kz lt lb oj lc lv le ok lf lx ly bi translated">递归神经网络</h1><p id="6a3d" class="pw-post-body-paragraph lz ma jj mb b mc md kt me mf mg kw mh mi mj mk ml mm mn mo mp mq mr ms mt mu im bi translated">递归神经网络(RNNs)是为预测序列而发明的。LSTM(长短期记忆)是一种流行的 RNN 算法，有许多可能的用例:</p><figure class="nv nw nx ny gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi os"><img src="../Images/57c378f3a612119914a711a34b86726f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*DfEML1rzonIVq0nz3xVuLw.png"/></div></div></figure><h2 id="c152" class="mv li jj bd lj mw mx dn ln my mz dp lr mi na nb lt mm nc nd lv mq ne nf lx jp bi translated">何时使用:</h2><ol class=""><li id="5253" class="ng nh jj mb b mc md mf mg mi ni mm nj mq nk mu ot nm nn no bi translated"><strong class="mb jt">一对一:</strong>单个输入映射到单个输出。<br/>例如—图像分类</li><li id="347c" class="ng nh jj mb b mc np mf nq mi nr mm ns mq nt mu ot nm nn no bi translated"><strong class="mb jt">一对多:</strong>单个输入映射到一系列输出。<br/>例如——图像字幕(单幅图像中的多个单词)</li><li id="2cf5" class="ng nh jj mb b mc np mf nq mi nr mm ns mq nt mu ot nm nn no bi translated">多对一:一系列的输入产生单一的输出。<br/>例如——情感分析(多个单词的二进制输出)</li><li id="9f3a" class="ng nh jj mb b mc np mf nq mi nr mm ns mq nt mu ot nm nn no bi translated"><strong class="mb jt">多对多:</strong>一个输入序列产生一个输出序列。<br/>例如，视频分类(将视频分割成帧，并分别标记每一帧)</li></ol></div><div class="ab cl nz oa hx ob" role="separator"><span class="oc bw bk od oe of"/><span class="oc bw bk od oe of"/><span class="oc bw bk od oe"/></div><div class="im in io ip iq"><h1 id="05cc" class="lh li jj bd lj lk og lm ln lo oh lq lr ky oi kz lt lb oj lc lv le ok lf lx ly bi translated">自组织地图</h1><p id="a49c" class="pw-post-body-paragraph lz ma jj mb b mc md kt me mf mg kw mh mi mj mk ml mm mn mo mp mq mr ms mt mu im bi translated">自组织映射或 som 处理无监督的数据，通常有助于降维(减少模型中的随机变量)。对于自组织地图，输出维度始终是二维的。因此，如果我们有两个以上的输入特征，输出减少到二维。每个连接输入和输出节点的突触都有一个权重。然后，每个数据点竞争模型中的表示。最近的节点称为 BMU(最佳匹配单元)，SOM 更新其权重以更接近 BMU。随着模型的进展，BMU 的邻居不断减少。节点越靠近 BMU，其权重变化越大。<br/> <strong class="mb jt">注</strong>:权重是节点本身的一个特性，它代表节点在输入空间中的位置。这里没有激活函数(权重不同于人工神经网络中的权重)。</p><h2 id="5a6a" class="mv li jj bd lj mw mx dn ln my mz dp lr mi na nb lt mm nc nd lv mq ne nf lx jp bi translated">何时使用:</h2><ul class=""><li id="aa95" class="ng nh jj mb b mc md mf mg mi ni mm nj mq nk mu nl nm nn no bi translated">当提供的数据不包含输出或 Y 列时。</li><li id="2cde" class="ng nh jj mb b mc np mf nq mi nr mm ns mq nt mu nl nm nn no bi translated">探索项目，了解数据集背后的框架。</li><li id="c7a8" class="ng nh jj mb b mc np mf nq mi nr mm ns mq nt mu nl nm nn no bi translated">创意项目(AI 制作的音乐/文字/视频)。</li><li id="32e1" class="ng nh jj mb b mc np mf nq mi nr mm ns mq nt mu nl nm nn no bi translated">用于特征检测的降维方法。</li></ul><p id="e4e8" class="pw-post-body-paragraph lz ma jj mb b mc om kt me mf on kw mh mi oo mk ml mm op mo mp mq oq ms mt mu im bi translated"><a class="ae jg" href="http://www.ai-junkie.com/ann/som/som1.html" rel="noopener ugc nofollow" target="_blank">点击此处查看自组织地图的示例</a></p></div><div class="ab cl nz oa hx ob" role="separator"><span class="oc bw bk od oe of"/><span class="oc bw bk od oe of"/><span class="oc bw bk od oe"/></div><div class="im in io ip iq"><h1 id="ccbd" class="lh li jj bd lj lk og lm ln lo oh lq lr ky oi kz lt lb oj lc lv le ok lf lx ly bi translated">玻尔兹曼机器</h1><p id="d7b2" class="pw-post-body-paragraph lz ma jj mb b mc md kt me mf mg kw mh mi mj mk ml mm mn mo mp mq mr ms mt mu im bi translated">在上面的 4 个模型中，有一个共同点。这些模型在某个方向起作用。即使 som 是无监督的，它们仍然像有监督的模型一样在特定的方向上工作。我说的方向是指:<br/>输入→隐藏层→输出。</p><figure class="nv nw nx ny gt iv gh gi paragraph-image"><div class="gh gi ou"><img src="../Images/e52c10b96e4edd350dcbc6ef9cd4edfd.png" data-original-src="https://miro.medium.com/v2/resize:fit:866/format:webp/0*dUj9XPj_Fk8REpAs.png"/></div></figure><p id="e377" class="pw-post-body-paragraph lz ma jj mb b mc om kt me mf on kw mh mi oo mk ml mm op mo mp mq oq ms mt mu im bi translated">玻尔兹曼机器并不遵循某个方向。所有的节点在一个圆形的超空间中相互连接，就像图中一样。<br/>玻尔兹曼机器也可以生成模型的所有参数，而不是用固定的输入参数工作。<br/>这种模型被称为随机模型，不同于上述所有确定性模型。受限玻尔兹曼机更实用。</p><h2 id="3ea0" class="mv li jj bd lj mw mx dn ln my mz dp lr mi na nb lt mm nc nd lv mq ne nf lx jp bi translated"><strong class="ak">何时使用:</strong></h2><ul class=""><li id="af87" class="ng nh jj mb b mc md mf mg mi ni mm nj mq nk mu nl nm nn no bi translated">监控系统时(因为 BM 将学会调节)</li><li id="3bff" class="ng nh jj mb b mc np mf nq mi nr mm ns mq nt mu nl nm nn no bi translated">构建二元推荐系统</li><li id="6932" class="ng nh jj mb b mc np mf nq mi nr mm ns mq nt mu nl nm nn no bi translated">当处理一组非常具体的数据时</li></ul></div><div class="ab cl nz oa hx ob" role="separator"><span class="oc bw bk od oe of"/><span class="oc bw bk od oe of"/><span class="oc bw bk od oe"/></div><div class="im in io ip iq"><h1 id="0029" class="lh li jj bd lj lk og lm ln lo oh lq lr ky oi kz lt lb oj lc lv le ok lf lx ly bi translated">自动编码器</h1><figure class="nv nw nx ny gt iv gh gi paragraph-image"><div class="gh gi ov"><img src="../Images/b20a38f589a775fc13874d21899bff2f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1354/format:webp/0*t7YIgyT_cecMTL_4.png"/></div></figure><p id="1df0" class="pw-post-body-paragraph lz ma jj mb b mc om kt me mf on kw mh mi oo mk ml mm op mo mp mq oq ms mt mu im bi translated">自动编码器的工作原理是基于输入值自动编码数据，然后执行激活功能，最后解码数据以输出。对输入要素施加了某种瓶颈，将它们压缩成更少的类别。因此，如果数据中存在某种固有结构，自动编码器模型将识别并利用它来获得输出。</p><h2 id="9856" class="mv li jj bd lj mw mx dn ln my mz dp lr mi na nb lt mm nc nd lv mq ne nf lx jp bi translated"><strong class="ak">自动编码器的类型/变化:</strong></h2><p id="439c" class="pw-post-body-paragraph lz ma jj mb b mc md kt me mf mg kw mh mi mj mk ml mm mn mo mp mq mr ms mt mu im bi translated">- <strong class="mb jt">稀疏自动编码器</strong>:隐藏层大于输入层，但应用了正则化技术来减少过拟合。对损失函数添加约束，防止自动编码器一次使用其所有节点。<br/> - <strong class="mb jt">去噪自动编码器:</strong>另一种正则化技术，其中我们采用我们的输入值的修改版本，其中我们的一些输入值随机变为 0。<br/> - <strong class="mb jt">收缩自动编码器:</strong>当隐藏层大于输入层时，为损失函数增加一个惩罚，以防止值的过度拟合和复制。<br/> - <strong class="mb jt">堆叠自动编码器:</strong>当你添加另一个隐藏层时，你得到一个堆叠自动编码器。它有两个编码阶段和一个解码阶段。</p><h2 id="feb5" class="mv li jj bd lj mw mx dn ln my mz dp lr mi na nb lt mm nc nd lv mq ne nf lx jp bi translated"><strong class="ak">何时使用:</strong></h2><ul class=""><li id="61de" class="ng nh jj mb b mc md mf mg mi ni mm nj mq nk mu nl nm nn no bi translated">维度缩减/特征检测</li><li id="3f09" class="ng nh jj mb b mc np mf nq mi nr mm ns mq nt mu nl nm nn no bi translated">构建强大的推荐系统(比 BM 更强大)</li><li id="0b79" class="ng nh jj mb b mc np mf nq mi nr mm ns mq nt mu nl nm nn no bi translated">对海量数据集中的要素进行编码</li></ul></div><div class="ab cl nz oa hx ob" role="separator"><span class="oc bw bk od oe of"/><span class="oc bw bk od oe of"/><span class="oc bw bk od oe"/></div><div class="im in io ip iq"><h1 id="2ec4" class="lh li jj bd lj lk og lm ln lo oh lq lr ky oi kz lt lb oj lc lv le ok lf lx ly bi translated">链接</h1><p id="9147" class="pw-post-body-paragraph lz ma jj mb b mc md kt me mf mg kw mh mi mj mk ml mm mn mo mp mq mr ms mt mu im bi translated">感谢阅读！希望你学到了新的有用的东西。</p><div class="is it gp gr iu ow"><a href="https://www.quora.com/How-can-I-choose-between-one-to-one-one-to-many-many-to-one-many-to-one-and-many-to-many-in-long-short-term-memory-LSTM" rel="noopener  ugc nofollow" target="_blank"><div class="ox ab fo"><div class="oy ab oz cl cj pa"><h2 class="bd jt gy z fp pb fr fs pc fu fw js bi translated">我如何在一对一、一对多、多对一、多对一和多对多之间选择…</h2><div class="pd l"><h3 class="bd b gy z fp pb fr fs pc fu fw dk translated">答:这取决于应用。引用 Andrej(来自循环神经的不合理有效性…</h3></div><div class="pe l"><p class="bd b dl z fp pb fr fs pc fu fw dk translated">www.quora.com</p></div></div><div class="pf l"><div class="pg l ph pi pj pf pk ja ow"/></div></div></a></div><div class="is it gp gr iu ow"><a href="http://www.ai-junkie.com/ann/som/som1.html" rel="noopener  ugc nofollow" target="_blank"><div class="ox ab fo"><div class="oy ab oz cl cj pa"><h2 class="bd jt gy z fp pb fr fs pc fu fw js bi translated">SOM 教程第 1 部分</h2><div class="pd l"><h3 class="bd b gy z fp pb fr fs pc fu fw dk translated">Kohonen 的自组织特征图“我无法清楚地表达我对那些认为……</h3></div><div class="pe l"><p class="bd b dl z fp pb fr fs pc fu fw dk translated">www.ai-junkie.com</p></div></div><div class="pf l"><div class="pl l ph pi pj pf pk ja ow"/></div></div></a></div><div class="is it gp gr iu ow"><a href="https://machinelearningmastery.com/when-to-use-mlp-cnn-and-rnn-neural-networks/" rel="noopener  ugc nofollow" target="_blank"><div class="ox ab fo"><div class="oy ab oz cl cj pa"><h2 class="bd jt gy z fp pb fr fs pc fu fw js bi translated">何时使用 MLP、CNN 和 RNN 神经网络</h2><div class="pd l"><h3 class="bd b gy z fp pb fr fs pc fu fw dk translated">什么样的神经网络适合你的预测建模问题？对初学者来说……可能很难</h3></div><div class="pe l"><p class="bd b dl z fp pb fr fs pc fu fw dk translated">machinelearningmastery.com</p></div></div><div class="pf l"><div class="pm l ph pi pj pf pk ja ow"/></div></div></a></div><div class="is it gp gr iu ow"><a href="https://www.jeremyjordan.me/autoencoders/" rel="noopener  ugc nofollow" target="_blank"><div class="ox ab fo"><div class="oy ab oz cl cj pa"><h2 class="bd jt gy z fp pb fr fs pc fu fw js bi translated">自动编码器介绍。</h2><div class="pd l"><h3 class="bd b gy z fp pb fr fs pc fu fw dk translated">自动编码器是一种无监督的学习技术，其中我们利用神经网络来完成表示的任务…</h3></div><div class="pe l"><p class="bd b dl z fp pb fr fs pc fu fw dk translated">www.jeremyjordan.me</p></div></div></div></a></div></div><div class="ab cl nz oa hx ob" role="separator"><span class="oc bw bk od oe of"/><span class="oc bw bk od oe of"/><span class="oc bw bk od oe"/></div><div class="im in io ip iq"><blockquote class="pn"><p id="ef13" class="po pp jj bd pq pr ps pt pu pv pw mu dk translated">关注更多机器学习/AI 相关内容<br/> <a class="ae jg" href="https://medium.com/u/f463f1bf80e2?source=post_page-----cbe59dbb903c----------------------" rel="noopener">罗汉·古普塔</a></p></blockquote></div></div>    
</body>
</html>