<html>
<head>
<title>Machine learning for anomaly detection and condition monitoring</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">用于异常检测和状态监控的机器学习</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/machine-learning-for-anomaly-detection-and-condition-monitoring-d4614e7de770?source=collection_archive---------1-----------------------#2019-04-23">https://towardsdatascience.com/machine-learning-for-anomaly-detection-and-condition-monitoring-d4614e7de770?source=collection_archive---------1-----------------------#2019-04-23</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><figure class="is it gp gr iu iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi ir"><img src="../Images/12d85b0c36212460f6186a562f88354d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*WQH9UHGGcRdaOxOb8KtvUg.jpeg"/></div></div></figure><div class=""/><div class=""><h2 id="c797" class="pw-subtitle-paragraph kb jd je bd b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks dk translated">从数据导入到模型输出的分步教程</h2></div><p id="161d" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">我上一篇关于异常检测和条件监控的文章收到了很多反馈。我收到的许多问题涉及技术方面以及如何建立模型等。由于这个原因，我决定写一篇后续文章，详细介绍所有必要的步骤，从预处理数据到构建模型和可视化结果。</p><p id="2f78" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">对于异常检测和状态监控的介绍，我建议首先阅读我关于这个主题的原始文章。这为如何利用机器学习和数据驱动分析从传感器数据中提取有价值的信息提供了必要的背景信息。</p><p id="f845" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">当前的文章主要集中在技术方面，包括建立基于多元统计分析和自动编码器神经网络的异常检测模型所需的所有代码。</p></div><div class="ab cl lq lr hx ls" role="separator"><span class="lt bw bk lu lv lw"/><span class="lt bw bk lu lv lw"/><span class="lt bw bk lu lv"/></div><div class="im in io ip iq"><h2 id="09bd" class="lx ly je bd lz ma mb dn mc md me dp mf lc mg mh mi lg mj mk ml lk mm mn mo mp bi translated">下载数据集:</h2><p id="227e" class="pw-post-body-paragraph kt ku je kv b kw mq kf ky kz mr ki lb lc ms le lf lg mt li lj lk mu lm ln lo im bi translated">为了复制原始文章中的结果，首先需要从 NASA 声学和振动数据库下载<a class="ae lp" href="http://data-acoustics.com/measurements/bearing-faults/bearing-4/" rel="noopener ugc nofollow" target="_blank">数据集。有关实验和可用数据的更多信息，请参见下载的 IMS 轴承数据自述文件。</a></p><p id="c3bc" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">每个数据集由单独的文件组成，这些文件是以特定间隔记录的 1 秒振动信号快照。每个文件由 20.480 个点组成，采样率设置为 20 kHz。文件名表示收集数据的时间。数据文件中的每条记录(行)都是一个数据点。较大的时间戳间隔(显示在文件名中)表示在下一个工作日恢复实验。</p><h2 id="d725" class="lx ly je bd lz ma mb dn mc md me dp mf lc mg mh mi lg mj mk ml lk mm mn mo mp bi translated">导入包和库:</h2><p id="da0a" class="pw-post-body-paragraph kt ku je kv b kw mq kf ky kz mr ki lb lc ms le lf lg mt li lj lk mu lm ln lo im bi translated">第一步是为分析导入一些有用的包和库:</p><pre class="mv mw mx my gt mz na nb nc aw nd bi"><span id="dcf4" class="lx ly je na b gy ne nf l ng nh"><em class="ni"># Common imports</em><br/><strong class="na jf">import</strong> <strong class="na jf">os</strong><br/><strong class="na jf">import</strong> <strong class="na jf">pandas</strong> <strong class="na jf">as</strong> <strong class="na jf">pd</strong><br/><strong class="na jf">import</strong> <strong class="na jf">numpy</strong> <strong class="na jf">as</strong> <strong class="na jf">np</strong><br/><strong class="na jf">from</strong> <strong class="na jf">sklearn</strong> <strong class="na jf">import</strong> preprocessing<br/><strong class="na jf">import</strong> <strong class="na jf">seaborn</strong> <strong class="na jf">as</strong> <strong class="na jf">sns</strong><br/>sns.set(color_codes=<strong class="na jf">True</strong>)<br/><strong class="na jf">import</strong> <strong class="na jf">matplotlib.pyplot</strong> <strong class="na jf">as</strong> <strong class="na jf">plt</strong><br/>%<strong class="na jf">matplotlib</strong> inline<br/><br/><strong class="na jf">from</strong> <strong class="na jf">numpy.random</strong> <strong class="na jf">import</strong> seed<br/><strong class="na jf">from</strong> <strong class="na jf">tensorflow</strong> <strong class="na jf">import</strong> set_random_seed<br/><br/><strong class="na jf">from</strong> <strong class="na jf">keras.layers</strong> <strong class="na jf">import</strong> Input, Dropout<br/><strong class="na jf">from</strong> <strong class="na jf">keras.layers.core</strong> <strong class="na jf">import</strong> Dense <br/><strong class="na jf">from</strong> <strong class="na jf">keras.models</strong> <strong class="na jf">import</strong> Model, Sequential, load_model<br/><strong class="na jf">from</strong> <strong class="na jf">keras</strong> <strong class="na jf">import</strong> regularizers<br/><strong class="na jf">from</strong> <strong class="na jf">keras.models</strong> <strong class="na jf">import</strong> model_from_json</span></pre><h2 id="956f" class="lx ly je bd lz ma mb dn mc md me dp mf lc mg mh mi lg mj mk ml lk mm mn mo mp bi translated">数据加载和预处理:</h2><p id="9bfa" class="pw-post-body-paragraph kt ku je kv b kw mq kf ky kz mr ki lb lc ms le lf lg mt li lj lk mu lm ln lo im bi translated">假设随着时间推移，齿轮逐渐退化，所以在下面的分析中，我们每 10 分钟使用一个数据点。通过使用每个文件中 20.480 个数据点的振动记录的平均绝对值，汇总每个 10 分钟的数据点。然后，我们将所有内容合并到一个数据帧中。</p><p id="0e33" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">在下面的例子中，我使用了来自第二档齿轮故障测试的数据(参见 readme 文档以获得关于该实验的更多信息)。</p><pre class="mv mw mx my gt mz na nb nc aw nd bi"><span id="67ed" class="lx ly je na b gy ne nf l ng nh">data_dir = '2nd_test'<br/>merged_data = pd.DataFrame()<br/><br/><strong class="na jf">for</strong> filename <strong class="na jf">in</strong> os.listdir(data_dir):<br/>    print(filename)<br/>    dataset=pd.read_csv(os.path.join(data_dir, filename), sep='<strong class="na jf">\t</strong>')<br/>    dataset_mean_abs = np.array(dataset.abs().mean())<br/>    dataset_mean_abs = pd.DataFrame(dataset_mean_abs.reshape(1,4))<br/>    dataset_mean_abs.index = [filename]<br/>    merged_data = merged_data.append(dataset_mean_abs)<br/><br/>merged_data.columns = ['Bearing 1','Bearing 2','Bearing 3','Bearing 4']</span></pre><p id="dfa1" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">加载振动数据后，我们将索引转换为日期时间格式(使用遵循惯例的<a class="ae lp" href="https://docs.python.org/3.4/library/datetime.html" rel="noopener ugc nofollow" target="_blank">，然后在将合并的数据集保存为. csv 文件之前，按时间顺序按索引对数据进行排序</a></p><pre class="mv mw mx my gt mz na nb nc aw nd bi"><span id="6597" class="lx ly je na b gy ne nf l ng nh">merged_data.index = pd.to_datetime(merged_data.index, format='%Y.%m.<strong class="na jf">%d</strong>.%H.%M.%S')</span><span id="b146" class="lx ly je na b gy nj nf l ng nh">merged_data = merged_data.sort_index()<br/>merged_data.to_csv('merged_dataset_BearingTest_2.csv')<br/>merged_data.head()</span></pre><figure class="mv mw mx my gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi nk"><img src="../Images/1c171b02d7daaadbc93852ccde1b153f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Z1mw-kBOtAKmYe_FzHL1Fg.jpeg"/></div></div><figcaption class="nl nm gj gh gi nn no bd b be z dk">Resulting dataframe: “merged_data”</figcaption></figure><h2 id="befb" class="lx ly je bd lz ma mb dn mc md me dp mf lc mg mh mi lg mj mk ml lk mm mn mo mp bi translated">定义训练/测试数据:</h2><p id="99f6" class="pw-post-body-paragraph kt ku je kv b kw mq kf ky kz mr ki lb lc ms le lf lg mt li lj lk mu lm ln lo im bi translated">在建立模型之前，我们需要定义训练/测试数据。为此，我们执行一个简单的分割，在数据集的第一部分(应该代表正常运行条件)上进行训练，并在导致轴承故障的数据集的其余部分上进行测试。</p><pre class="mv mw mx my gt mz na nb nc aw nd bi"><span id="5061" class="lx ly je na b gy ne nf l ng nh">dataset_train = merged_data['2004-02-12 11:02:39':'2004-02-13 23:52:39']<br/>dataset_test = merged_data['2004-02-13 23:52:39':]</span><span id="d38a" class="lx ly je na b gy nj nf l ng nh">dataset_train.plot(figsize = (12,6))</span></pre><figure class="mv mw mx my gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi np"><img src="../Images/7423ebcfa310c36f621252272de6e3b4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*7QfUsut5-OeSymRK_Z8mNg.jpeg"/></div></div><figcaption class="nl nm gj gh gi nn no bd b be z dk">Training data: Normal operating conditions</figcaption></figure><h2 id="c7d7" class="lx ly je bd lz ma mb dn mc md me dp mf lc mg mh mi lg mj mk ml lk mm mn mo mp bi translated">标准化数据:</h2><p id="47eb" class="pw-post-body-paragraph kt ku je kv b kw mq kf ky kz mr ki lb lc ms le lf lg mt li lj lk mu lm ln lo im bi translated">然后我使用 Scikit-learn 的预处理工具<a class="ae lp" href="https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MinMaxScaler.html" rel="noopener ugc nofollow" target="_blank">来缩放模型的输入变量。“最小最大缩放器”只是将数据重新缩放到范围[0，1]内。</a></p><pre class="mv mw mx my gt mz na nb nc aw nd bi"><span id="8f5f" class="lx ly je na b gy ne nf l ng nh">scaler = preprocessing.MinMaxScaler()<br/><br/>X_train = pd.DataFrame(scaler.fit_transform(dataset_train), <br/>                              columns=dataset_train.columns, <br/>                              index=dataset_train.index)</span><span id="b01c" class="lx ly je na b gy nj nf l ng nh"><em class="ni"># Random shuffle training data</em><br/>X_train.sample(frac=1)<br/><br/>X_test = pd.DataFrame(scaler.transform(dataset_test), <br/>                             columns=dataset_test.columns, <br/>                             index=dataset_test.index)</span></pre><h1 id="b3bc" class="nq ly je bd lz nr ns nt mc nu nv nw mf kk nx kl mi kn ny ko ml kq nz kr mo oa bi translated">异常检测的 PCA 型模型；</h1><p id="5461" class="pw-post-body-paragraph kt ku je kv b kw mq kf ky kz mr ki lb lc ms le lf lg mt li lj lk mu lm ln lo im bi translated">由于处理高维传感器数据通常具有挑战性，因此有几种技术可以减少变量的数量(<a class="ae lp" href="https://en.wikipedia.org/wiki/Dimensionality_reduction" rel="noopener ugc nofollow" target="_blank">降维</a>)。主要技术之一是<a class="ae lp" href="https://en.wikipedia.org/wiki/Principal_component_analysis" rel="noopener ugc nofollow" target="_blank">主成分分析</a> (PCA)。关于更详细的介绍，我参考了我关于这个主题的原始文章。</p><p id="90f7" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">作为初步尝试，让我们将传感器读数压缩到两个主要分量。</p><pre class="mv mw mx my gt mz na nb nc aw nd bi"><span id="bea0" class="lx ly je na b gy ne nf l ng nh"><strong class="na jf">from</strong> <strong class="na jf">sklearn.decomposition</strong> <strong class="na jf">import</strong> PCA</span><span id="1c28" class="lx ly je na b gy nj nf l ng nh">pca = PCA(n_components=2, svd_solver= 'full')</span><span id="e3d8" class="lx ly je na b gy nj nf l ng nh">X_train_PCA = pca.fit_transform(X_train)<br/>X_train_PCA = pd.DataFrame(X_train_PCA)<br/>X_train_PCA.index = X_train.index<br/><br/>X_test_PCA = pca.transform(X_test)<br/>X_test_PCA = pd.DataFrame(X_test_PCA)<br/>X_test_PCA.index = X_test.index</span></pre><h2 id="494a" class="lx ly je bd lz ma mb dn mc md me dp mf lc mg mh mi lg mj mk ml lk mm mn mo mp bi translated">马哈拉诺比斯距离度量:</h2><p id="b153" class="pw-post-body-paragraph kt ku je kv b kw mq kf ky kz mr ki lb lc ms le lf lg mt li lj lk mu lm ln lo im bi translated"><a class="ae lp" href="https://en.wikipedia.org/wiki/Mahalanobis_distance" rel="noopener ugc nofollow" target="_blank">马氏距离</a>广泛用于聚类分析和分类技术。为了使用 Mahalanobis 距离将测试点分类为属于 N 个类别之一，首先估计每个类别的协方差矩阵，通常基于已知属于每个类别的样本。在我们的例子中，由于我们只对“正常”与“异常”的分类感兴趣，我们使用只包含正常操作条件的训练数据来计算协方差矩阵。然后，给定一个测试样本，我们计算到“正常”类的 Mahalanobis 距离，如果距离超过某个阈值，则将测试点分类为“异常”。</p><p id="2567" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">关于这些技术方面的更详细的介绍，你可以看看<a class="ae lp" rel="noopener" target="_blank" href="/how-to-use-machine-learning-for-anomaly-detection-and-condition-monitoring-6742f82900d7">我以前的文章</a>，它更详细地涵盖了这些主题。</p><h2 id="c09f" class="lx ly je bd lz ma mb dn mc md me dp mf lc mg mh mi lg mj mk ml lk mm mn mo mp bi translated">定义 PCA 模型中使用的函数:</h2><p id="91f7" class="pw-post-body-paragraph kt ku je kv b kw mq kf ky kz mr ki lb lc ms le lf lg mt li lj lk mu lm ln lo im bi translated">计算协方差矩阵:</p><pre class="mv mw mx my gt mz na nb nc aw nd bi"><span id="3541" class="lx ly je na b gy ne nf l ng nh"><strong class="na jf">def</strong> cov_matrix(data, verbose=<strong class="na jf">False</strong>):<br/>    covariance_matrix = np.cov(data, rowvar=<strong class="na jf">False</strong>)<br/>    <strong class="na jf">if</strong> is_pos_def(covariance_matrix):<br/>        inv_covariance_matrix = np.linalg.inv(covariance_matrix)<br/>        <strong class="na jf">if</strong> is_pos_def(inv_covariance_matrix):<br/>            <strong class="na jf">return</strong> covariance_matrix, inv_covariance_matrix<br/>        <strong class="na jf">else</strong>:<br/>            print("Error: Inverse of Covariance Matrix is not positive definite!")<br/>    <strong class="na jf">else</strong>:<br/>        print("Error: Covariance Matrix is not positive definite!")</span></pre><p id="f2da" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">计算马哈拉诺比斯距离:</p><pre class="mv mw mx my gt mz na nb nc aw nd bi"><span id="776b" class="lx ly je na b gy ne nf l ng nh"><strong class="na jf">def</strong> MahalanobisDist(inv_cov_matrix, mean_distr, data, verbose=<strong class="na jf">False</strong>):<br/>    inv_covariance_matrix = inv_cov_matrix<br/>    vars_mean = mean_distr<br/>    diff = data - vars_mean<br/>    md = []<br/>    <strong class="na jf">for</strong> i <strong class="na jf">in</strong> range(len(diff)):<br/>        md.append(np.sqrt(diff[i].dot(inv_covariance_matrix).dot(diff[i])))<br/>    <strong class="na jf">return</strong> md</span></pre><p id="97cb" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">检测异常值:</p><pre class="mv mw mx my gt mz na nb nc aw nd bi"><span id="f5f2" class="lx ly je na b gy ne nf l ng nh"><strong class="na jf">def</strong> MD_detectOutliers(dist, extreme=<strong class="na jf">False</strong>, verbose=<strong class="na jf">False</strong>):<br/>    k = 3. <strong class="na jf">if</strong> extreme <strong class="na jf">else</strong> 2.<br/>    threshold = np.mean(dist) * k<br/>    outliers = []<br/>    <strong class="na jf">for</strong> i <strong class="na jf">in</strong> range(len(dist)):<br/>        <strong class="na jf">if</strong> dist[i] &gt;= threshold:<br/>            outliers.append(i)  <em class="ni"># index of the outlier</em><br/>    <strong class="na jf">return</strong> np.array(outliers)</span></pre><p id="8770" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">计算将数据点分类为异常的阈值:</p><pre class="mv mw mx my gt mz na nb nc aw nd bi"><span id="58a7" class="lx ly je na b gy ne nf l ng nh"><strong class="na jf">def</strong> MD_threshold(dist, extreme=<strong class="na jf">False</strong>, verbose=<strong class="na jf">False</strong>):<br/>    k = 3. <strong class="na jf">if</strong> extreme <strong class="na jf">else</strong> 2.<br/>    threshold = np.mean(dist) * k<br/>    <strong class="na jf">return</strong> threshold</span></pre><p id="cf16" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">检查矩阵是否正定:</p><pre class="mv mw mx my gt mz na nb nc aw nd bi"><span id="a799" class="lx ly je na b gy ne nf l ng nh"><strong class="na jf">def</strong> is_pos_def(A):<br/>    <strong class="na jf">if</strong> np.allclose(A, A.T):<br/>        <strong class="na jf">try</strong>:<br/>            np.linalg.cholesky(A)<br/>            <strong class="na jf">return</strong> <strong class="na jf">True</strong><br/>        <strong class="na jf">except</strong> np.linalg.LinAlgError:<br/>            <strong class="na jf">return</strong> <strong class="na jf">False</strong><br/>    <strong class="na jf">else</strong>:<br/>        <strong class="na jf">return</strong> <strong class="na jf">False</strong></span></pre><h2 id="c496" class="lx ly je bd lz ma mb dn mc md me dp mf lc mg mh mi lg mj mk ml lk mm mn mo mp bi translated">设置 PCA 模型:</h2><p id="08b7" class="pw-post-body-paragraph kt ku je kv b kw mq kf ky kz mr ki lb lc ms le lf lg mt li lj lk mu lm ln lo im bi translated">从两个主要部分定义训练/测试集:</p><pre class="mv mw mx my gt mz na nb nc aw nd bi"><span id="3966" class="lx ly je na b gy ne nf l ng nh">data_train = np.array(X_train_PCA.values)<br/>data_test = np.array(X_test_PCA.values)</span></pre><p id="d981" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">根据训练集中的数据计算协方差矩阵及其逆矩阵:</p><pre class="mv mw mx my gt mz na nb nc aw nd bi"><span id="3b32" class="lx ly je na b gy ne nf l ng nh">cov_matrix, inv_cov_matrix  = cov_matrix(data_train)</span></pre><p id="0421" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">我们还计算训练集中输入变量的平均值，因为这在以后用于计算测试集中数据点的 Mahalanobis 距离</p><pre class="mv mw mx my gt mz na nb nc aw nd bi"><span id="5acf" class="lx ly je na b gy ne nf l ng nh">mean_distr = data_train.mean(axis=0)</span></pre><p id="0b8e" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">使用协方差矩阵及其逆矩阵，我们可以计算定义“正常条件”的训练数据的 Mahalanobis 距离，并找到阈值以将数据点标记为异常。然后可以计算测试集中数据点的 Mahalanobis 距离，并将其与异常阈值进行比较。</p><pre class="mv mw mx my gt mz na nb nc aw nd bi"><span id="33e9" class="lx ly je na b gy ne nf l ng nh">dist_test = MahalanobisDist(inv_cov_matrix, mean_distr, data_test, verbose=<strong class="na jf">False</strong>)<br/>dist_train = MahalanobisDist(inv_cov_matrix, mean_distr, data_train, verbose=<strong class="na jf">False</strong>)<br/>threshold = MD_threshold(dist_train, extreme = <strong class="na jf">True</strong>)</span></pre><h2 id="51b1" class="lx ly je bd lz ma mb dn mc md me dp mf lc mg mh mi lg mj mk ml lk mm mn mo mp bi translated">标记异常的阈值:</h2><p id="bcae" class="pw-post-body-paragraph kt ku je kv b kw mq kf ky kz mr ki lb lc ms le lf lg mt li lj lk mu lm ln lo im bi translated">如果满足正态分布输入变量的假设，到分布质心的马氏距离的平方应遵循χ2 分布。这也是上述用于标记异常的“阈值”计算背后的假设。由于这种假设在我们的情况下不一定成立，因此可视化 Mahalanobis 距离的分布以设置标记异常的良好阈值是有益的。再次，我参考<a class="ae lp" rel="noopener" target="_blank" href="/how-to-use-machine-learning-for-anomaly-detection-and-condition-monitoring-6742f82900d7">我的前一篇文章</a>，获得关于这些技术方面的更详细的介绍。</p><p id="bceb" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">我们首先想象马哈拉诺比斯距离的平方，它应该理想地遵循χ2 分布。</p><pre class="mv mw mx my gt mz na nb nc aw nd bi"><span id="cbe5" class="lx ly je na b gy ne nf l ng nh">plt.figure()<br/>sns.distplot(np.square(dist_train),<br/>             bins = 10, <br/>             kde= <strong class="na jf">False</strong>);<br/>plt.xlim([0.0,15])</span></pre><figure class="mv mw mx my gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi ob"><img src="../Images/e8e3c661ee05d2444a21b51ff54d912c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ZVouogmcR03PD2Hrl0Jvkw.jpeg"/></div></div><figcaption class="nl nm gj gh gi nn no bd b be z dk">Square of the Mahalanobis distance</figcaption></figure><p id="01e7" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">然后想象马哈拉诺比斯距离本身:</p><pre class="mv mw mx my gt mz na nb nc aw nd bi"><span id="0c18" class="lx ly je na b gy ne nf l ng nh">plt.figure()<br/>sns.distplot(dist_train,<br/>             bins = 10, <br/>             kde= <strong class="na jf">True</strong>, <br/>            color = 'green');<br/>plt.xlim([0.0,5])<br/>plt.xlabel('Mahalanobis dist')</span></pre><figure class="mv mw mx my gt iv gh gi paragraph-image"><div class="gh gi oc"><img src="../Images/76051cf3faa137e5334514a543d9d384.png" data-original-src="https://miro.medium.com/v2/resize:fit:864/format:webp/1*p-aQy4JuuQu9OsniN1PWwQ.jpeg"/></div></figure><p id="fcc4" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">从上述分布来看，计算出的用于标记异常的阈值 3.8 似乎是合理的(定义为距分布中心的 3 个标准偏差)</p><p id="71bd" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">然后，我们可以保存 Mahalanobis 距离，以及数据帧中训练和测试数据的阈值和“异常标志”变量:</p><pre class="mv mw mx my gt mz na nb nc aw nd bi"><span id="db73" class="lx ly je na b gy ne nf l ng nh">anomaly_train = pd.DataFrame()<br/>anomaly_train['Mob dist']= dist_train<br/>anomaly_train['Thresh'] = threshold<br/><em class="ni"># If Mob dist above threshold: Flag as anomaly</em><br/>anomaly_train['Anomaly'] = anomaly_train['Mob dist'] &gt; anomaly_train['Thresh']<br/>anomaly_train.index = X_train_PCA.index</span><span id="fd10" class="lx ly je na b gy nj nf l ng nh">anomaly = pd.DataFrame()<br/>anomaly['Mob dist']= dist_test<br/>anomaly['Thresh'] = threshold<br/><em class="ni"># If Mob dist above threshold: Flag as anomaly</em><br/>anomaly['Anomaly'] = anomaly['Mob dist'] &gt; anomaly['Thresh']<br/>anomaly.index = X_test_PCA.index<br/>anomaly.head()</span></pre><figure class="mv mw mx my gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi od"><img src="../Images/80ffc1b001024894105327f396cd6048.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*EW7Rzkiojld00fVpJkyOnQ.jpeg"/></div></div><figcaption class="nl nm gj gh gi nn no bd b be z dk">Resulting dataframe for the test data</figcaption></figure><p id="f48e" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">基于计算的统计数据，任何高于阈值的距离都将被标记为异常。</p><p id="1b2e" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">我们现在可以将数据合并到单个数据帧中，并将其保存为. csv 文件:</p><pre class="mv mw mx my gt mz na nb nc aw nd bi"><span id="9fc9" class="lx ly je na b gy ne nf l ng nh">anomaly_alldata = pd.concat([anomaly_train, anomaly])<br/>anomaly_alldata.to_csv('Anomaly_distance.csv')</span></pre><h2 id="40c8" class="lx ly je bd lz ma mb dn mc md me dp mf lc mg mh mi lg mj mk ml lk mm mn mo mp bi translated">在测试数据上验证 PCA 模型:</h2><p id="7b7e" class="pw-post-body-paragraph kt ku je kv b kw mq kf ky kz mr ki lb lc ms le lf lg mt li lj lk mu lm ln lo im bi translated">我们现在可以绘制计算的异常度量(Mob dist)，并检查它何时超过异常阈值(注意对数 y 轴)。</p><pre class="mv mw mx my gt mz na nb nc aw nd bi"><span id="2ec9" class="lx ly je na b gy ne nf l ng nh">anomaly_alldata.plot(logy=<strong class="na jf">True</strong>, figsize = (10,6), ylim = [1e-1,1e3], color = ['green','red'])</span></pre><figure class="mv mw mx my gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi oe"><img src="../Images/db3618307f7fe4fab89ed09ca0979cf6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*gff6BQiMq-eClSXurOknTw.jpeg"/></div></div></figure><p id="881c" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">从上图中，我们看到模型能够在实际轴承故障前大约 3 天检测到异常。</p><h1 id="933d" class="nq ly je bd lz nr ns nt mc nu nv nw mf kk nx kl mi kn ny ko ml kq nz kr mo oa bi translated">其他方法:用于异常检测的自动编码器模型</h1><p id="c983" class="pw-post-body-paragraph kt ku je kv b kw mq kf ky kz mr ki lb lc ms le lf lg mt li lj lk mu lm ln lo im bi translated">这里的基本思想是使用自动编码器神经网络将传感器读数“压缩”为低维表示，这捕捉了各种变量之间的相关性和相互作用。(基本上与 PCA 模型的原理相同，但是这里我们也允许输入变量之间的非线性)。</p><p id="a660" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">关于自动编码器的更详细的介绍，你可以看看<a class="ae lp" rel="noopener" target="_blank" href="/how-to-use-machine-learning-for-anomaly-detection-and-condition-monitoring-6742f82900d7">我以前的文章</a>，它更详细地涵盖了这个主题。</p><h2 id="b51d" class="lx ly je bd lz ma mb dn mc md me dp mf lc mg mh mi lg mj mk ml lk mm mn mo mp bi translated">定义自动编码器网络:</h2><p id="eb98" class="pw-post-body-paragraph kt ku je kv b kw mq kf ky kz mr ki lb lc ms le lf lg mt li lj lk mu lm ln lo im bi translated">我们使用一个 3 层神经网络:第一层有 10 个节点，中间层有 2 个节点，第三层有 10 个节点。我们使用均方误差作为损失函数，并使用<a class="ae lp" href="https://keras.io/optimizers/" rel="noopener ugc nofollow" target="_blank">“Adam”优化器训练模型。</a></p><pre class="mv mw mx my gt mz na nb nc aw nd bi"><span id="2245" class="lx ly je na b gy ne nf l ng nh">seed(10)<br/>set_random_seed(10)<br/>act_func = 'elu'<br/><br/><em class="ni"># Input layer:</em><br/>model=Sequential()<br/><em class="ni"># First hidden layer, connected to input vector X. </em><br/>model.add(Dense(10,activation=act_func,<br/>                kernel_initializer='glorot_uniform',<br/>                kernel_regularizer=regularizers.l2(0.0),<br/>                input_shape=(X_train.shape[1],)<br/>               )<br/>         )<br/><br/>model.add(Dense(2,activation=act_func,<br/>                kernel_initializer='glorot_uniform'))<br/><br/>model.add(Dense(10,activation=act_func,<br/>                kernel_initializer='glorot_uniform'))<br/><br/>model.add(Dense(X_train.shape[1],<br/>                kernel_initializer='glorot_uniform'))<br/><br/>model.compile(loss='mse',optimizer='adam')<br/><br/><em class="ni"># Train model for 100 epochs, batch size of 10: </em><br/>NUM_EPOCHS=100<br/>BATCH_SIZE=10</span></pre><h2 id="63bf" class="lx ly je bd lz ma mb dn mc md me dp mf lc mg mh mi lg mj mk ml lk mm mn mo mp bi translated">拟合模型:</h2><p id="b625" class="pw-post-body-paragraph kt ku je kv b kw mq kf ky kz mr ki lb lc ms le lf lg mt li lj lk mu lm ln lo im bi translated">为了跟踪训练期间的准确性，我们在每个时期后使用 5%的训练数据进行验证(validation_split = 0.05)</p><pre class="mv mw mx my gt mz na nb nc aw nd bi"><span id="932a" class="lx ly je na b gy ne nf l ng nh">history=model.fit(np.array(X_train),np.array(X_train),<br/>                  batch_size=BATCH_SIZE, <br/>                  epochs=NUM_EPOCHS,<br/>                  validation_split=0.05,<br/>                  verbose = 1)</span></pre><figure class="mv mw mx my gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi of"><img src="../Images/8d6f51c878605e80bc397f1af89d4b63.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*rOD-ZM99woAHcDy7QfVb8Q.jpeg"/></div></div><figcaption class="nl nm gj gh gi nn no bd b be z dk">Training process</figcaption></figure><h2 id="e169" class="lx ly je bd lz ma mb dn mc md me dp mf lc mg mh mi lg mj mk ml lk mm mn mo mp bi translated">可视化培训/验证损失:</h2><pre class="mv mw mx my gt mz na nb nc aw nd bi"><span id="062b" class="lx ly je na b gy ne nf l ng nh">plt.plot(history.history['loss'],<br/>         'b',<br/>         label='Training loss')<br/>plt.plot(history.history['val_loss'],<br/>         'r',<br/>         label='Validation loss')<br/>plt.legend(loc='upper right')<br/>plt.xlabel('Epochs')<br/>plt.ylabel('Loss, [mse]')<br/>plt.ylim([0,.1])<br/>plt.show()</span></pre><figure class="mv mw mx my gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi og"><img src="../Images/755ca87fac88996675b17699aa385426.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*2DXazyE-vUxEYPP-5GJlWg.jpeg"/></div></div><figcaption class="nl nm gj gh gi nn no bd b be z dk">Train/validation loss</figcaption></figure><h2 id="0ea0" class="lx ly je bd lz ma mb dn mc md me dp mf lc mg mh mi lg mj mk ml lk mm mn mo mp bi translated">训练集中损失函数的分布:</h2><p id="a8e6" class="pw-post-body-paragraph kt ku je kv b kw mq kf ky kz mr ki lb lc ms le lf lg mt li lj lk mu lm ln lo im bi translated">通过在训练集中绘制计算损失的分布，可以使用它来识别用于识别异常的合适阈值。在这样做时，可以确保该阈值被设置在“噪声水平”之上，并且任何被标记的异常应该在噪声背景之上具有统计显著性。</p><pre class="mv mw mx my gt mz na nb nc aw nd bi"><span id="f556" class="lx ly je na b gy ne nf l ng nh">X_pred = model.predict(np.array(X_train))<br/>X_pred = pd.DataFrame(X_pred, <br/>                      columns=X_train.columns)<br/>X_pred.index = X_train.index<br/><br/>scored = pd.DataFrame(index=X_train.index)<br/>scored['Loss_mae'] = np.mean(np.abs(X_pred-X_train), axis = 1)</span><span id="0300" class="lx ly je na b gy nj nf l ng nh">plt.figure()<br/>sns.distplot(scored['Loss_mae'],<br/>             bins = 10, <br/>             kde= <strong class="na jf">True</strong>,<br/>            color = 'blue');<br/>plt.xlim([0.0,.5])</span></pre><figure class="mv mw mx my gt iv gh gi paragraph-image"><div class="gh gi oc"><img src="../Images/b8c9ca2c00c2db9c15c5fa744e19894c.png" data-original-src="https://miro.medium.com/v2/resize:fit:864/format:webp/1*CQXfujCTvDfx5s6W37fWZA.jpeg"/></div><figcaption class="nl nm gj gh gi nn no bd b be z dk">Loss distribution, training set</figcaption></figure><p id="9efc" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">根据上面的损失分布，让我们尝试使用阈值 0.3 来标记异常。然后，我们可以计算测试集中的损失，以检查输出何时超过异常阈值。</p><pre class="mv mw mx my gt mz na nb nc aw nd bi"><span id="9a93" class="lx ly je na b gy ne nf l ng nh">X_pred = model.predict(np.array(X_test))<br/>X_pred = pd.DataFrame(X_pred, <br/>                      columns=X_test.columns)<br/>X_pred.index = X_test.index<br/><br/>scored = pd.DataFrame(index=X_test.index)<br/>scored['Loss_mae'] = np.mean(np.abs(X_pred-X_test), axis = 1)<br/>scored['Threshold'] = 0.3<br/>scored['Anomaly'] = scored['Loss_mae'] &gt; scored['Threshold']<br/>scored.head()</span></pre><figure class="mv mw mx my gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi oh"><img src="../Images/250d7eee4a2532350bed0f71cffd5e4a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*9mX0tCgi--96RGpocDsucQ.jpeg"/></div></div></figure><p id="5ded" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">然后，我们也为训练集计算相同的指标，并将所有数据合并到单个数据帧中:</p><pre class="mv mw mx my gt mz na nb nc aw nd bi"><span id="165f" class="lx ly je na b gy ne nf l ng nh">X_pred_train = model.predict(np.array(X_train))<br/>X_pred_train = pd.DataFrame(X_pred_train, <br/>                      columns=X_train.columns)<br/>X_pred_train.index = X_train.index<br/><br/>scored_train = pd.DataFrame(index=X_train.index)<br/>scored_train['Loss_mae'] = np.mean(np.abs(X_pred_train-X_train), axis = 1)<br/>scored_train['Threshold'] = 0.3<br/>scored_train['Anomaly'] = scored_train['Loss_mae'] &gt; scored_train['Threshold']</span><span id="73e4" class="lx ly je na b gy nj nf l ng nh">scored = pd.concat([scored_train, scored])</span></pre><h2 id="b570" class="lx ly je bd lz ma mb dn mc md me dp mf lc mg mh mi lg mj mk ml lk mm mn mo mp bi translated">自动编码器模型的结果:</h2><p id="542b" class="pw-post-body-paragraph kt ku je kv b kw mq kf ky kz mr ki lb lc ms le lf lg mt li lj lk mu lm ln lo im bi translated">计算了损耗分布和异常阈值后，我们可以将轴承故障前的模型输出可视化:</p><pre class="mv mw mx my gt mz na nb nc aw nd bi"><span id="8794" class="lx ly je na b gy ne nf l ng nh">scored.plot(logy=<strong class="na jf">True</strong>,  figsize = (10,6), ylim = [1e-2,1e2], color = ['blue','red'])</span></pre><figure class="mv mw mx my gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi oi"><img src="../Images/da19808f6e68d18c5a51cd67127b2983.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*YJqJifMAmGUFD83lbgdzaw.jpeg"/></div></div></figure><h1 id="3d01" class="nq ly je bd lz nr ns nt mc nu nv nw mf kk nx kl mi kn ny ko ml kq nz kr mo oa bi translated">总结:</h1><p id="4a63" class="pw-post-body-paragraph kt ku je kv b kw mq kf ky kz mr ki lb lc ms le lf lg mt li lj lk mu lm ln lo im bi translated">两种建模方法给出了相似的结果，它们能够在实际故障之前很好地标记即将发生的轴承故障。主要的区别本质上是如何为标记异常定义合适的阈值，以避免在正常操作条件下出现许多假阳性。</p><p id="88cc" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">我希望这篇教程能给你启发，让你自己尝试这些异常检测模型。一旦你成功地建立了模型，是时候开始试验模型参数了。并在新的数据集上测试同样的方法。如果你遇到一些有趣的用例，请在下面的评论中告诉我。</p><p id="5997" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">玩得开心！</p></div><div class="ab cl lq lr hx ls" role="separator"><span class="lt bw bk lu lv lw"/><span class="lt bw bk lu lv lw"/><span class="lt bw bk lu lv"/></div><div class="im in io ip iq"><p id="54c0" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">如果你有兴趣了解更多与人工智能/机器学习和数据科学相关的主题，你也可以看看我写的其他一些文章。你会发现他们都列在我的中型作者简介，<a class="ae lp" href="https://medium.com/@vflovik" rel="noopener">，你可以在这里找到。</a></p><p id="d35b" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">而且，如果你想成为一个媒体会员，免费访问平台上的所有资料，你也可以使用下面我的推荐链接。(注意:如果您使用此链接注册，我也会收到一部分会员费)</p><div class="is it gp gr iu oj"><a href="https://medium.com/@vflovik/membership" rel="noopener follow" target="_blank"><div class="ok ab fo"><div class="ol ab om cl cj on"><h2 class="bd jf gy z fp oo fr fs op fu fw jd bi translated">通过我的推荐链接加入媒体- Vegard Flovik</h2><div class="oq l"><h3 class="bd b gy z fp oo fr fs op fu fw dk translated">作为一个媒体会员，你的会员费的一部分会给你阅读的作家，你可以完全接触到每一个故事…</h3></div><div class="or l"><p class="bd b dl z fp oo fr fs op fu fw dk translated">medium.com</p></div></div><div class="os l"><div class="ot l ou ov ow os ox ja oj"/></div></div></a></div><h1 id="cff0" class="nq ly je bd lz nr ns nt mc nu nv nw mf kk nx kl mi kn ny ko ml kq nz kr mo oa bi translated">更多来自 Vegard Flovik 媒体:</h1><ol class=""><li id="4ec2" class="oy oz je kv b kw mq kz mr lc pa lg pb lk pc lo pd pe pf pg bi translated"><a class="ae lp" rel="noopener" target="_blank" href="/a-gentle-introduction-to-monte-carlo-methods-98451674018d">蒙特卡洛方法简介</a></li><li id="5385" class="oy oz je kv b kw ph kz pi lc pj lg pk lk pl lo pd pe pf pg bi translated"><a class="ae lp" rel="noopener" target="_blank" href="/q-a-with-a-data-scientist-1f872518315f">从物理学到数据科学的转变</a></li><li id="a112" class="oy oz je kv b kw ph kz pi lc pj lg pk lk pl lo pd pe pf pg bi translated"><a class="ae lp" href="https://builtin.com/machine-learning/graph-theory" rel="noopener ugc nofollow" target="_blank">什么是图论，你为什么要关心它？</a></li><li id="38fd" class="oy oz je kv b kw ph kz pi lc pj lg pk lk pl lo pd pe pf pg bi translated"><a class="ae lp" rel="noopener" target="_blank" href="/deep-transfer-learning-for-image-classification-f3c7e0ec1a14">用于图像分类的深度迁移学习</a></li><li id="fed8" class="oy oz je kv b kw ph kz pi lc pj lg pk lk pl lo pd pe pf pg bi translated"><a class="ae lp" href="https://www.linkedin.com/pulse/building-ai-can-read-your-mind-vegard-flovik-phd/" rel="noopener ugc nofollow" target="_blank">建造一个能读懂你思想的人工智能</a></li><li id="aeaa" class="oy oz je kv b kw ph kz pi lc pj lg pk lk pl lo pd pe pf pg bi translated"><a class="ae lp" rel="noopener" target="_blank" href="/machine-learning-from-hype-to-real-world-applications-69de7afb56b6">机器学习:从炒作到现实应用</a></li><li id="7866" class="oy oz je kv b kw ph kz pi lc pj lg pk lk pl lo pd pe pf pg bi translated"><a class="ae lp" rel="noopener" target="_blank" href="/the-hidden-risk-of-ai-and-big-data-3332d77dfa6">人工智能和大数据隐藏的风险</a></li><li id="7159" class="oy oz je kv b kw ph kz pi lc pj lg pk lk pl lo pd pe pf pg bi translated"><a class="ae lp" rel="noopener" target="_blank" href="/how-to-use-machine-learning-for-anomaly-detection-and-condition-monitoring-6742f82900d7">如何使用机器学习进行异常检测和状态监控</a></li><li id="48ea" class="oy oz je kv b kw ph kz pi lc pj lg pk lk pl lo pd pe pf pg bi translated"><a class="ae lp" rel="noopener" target="_blank" href="/artificial-intelligence-in-supply-chain-management-predictive-analytics-for-demand-forecasting-80d2d512f155">用于供应链管理的人工智能:预测分析和需求预测</a></li><li id="ac17" class="oy oz je kv b kw ph kz pi lc pj lg pk lk pl lo pd pe pf pg bi translated"><a class="ae lp" rel="noopener" target="_blank" href="/how-not-to-use-machine-learning-for-time-series-forecasting-avoiding-the-pitfalls-19f9d7adf424">如何(不)使用机器学习进行时间序列预测:避免陷阱</a></li><li id="78b0" class="oy oz je kv b kw ph kz pi lc pj lg pk lk pl lo pd pe pf pg bi translated"><a class="ae lp" rel="noopener" target="_blank" href="/machine-learning-for-production-optimization-e460a0b82237">如何利用机器学习进行生产优化:利用数据提高绩效</a></li><li id="e795" class="oy oz je kv b kw ph kz pi lc pj lg pk lk pl lo pd pe pf pg bi translated">你如何向人工智能系统教授物理学？</li><li id="e244" class="oy oz je kv b kw ph kz pi lc pj lg pk lk pl lo pd pe pf pg bi translated">我们能使用纳米级磁铁建立人工大脑网络吗？</li></ol><h2 id="0b33" class="lx ly je bd lz ma mb dn mc md me dp mf lc mg mh mi lg mj mk ml lk mm mn mo mp bi translated">人工智能研讨会——从宣传到现实应用</h2><figure class="mv mw mx my gt iv"><div class="bz fp l di"><div class="pm pn l"/></div></figure></div></div>    
</body>
</html>