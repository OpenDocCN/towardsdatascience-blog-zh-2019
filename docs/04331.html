<html>
<head>
<title>The evolution of skill discovery in virtual assistants</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">虚拟助手中技能发现的演变</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/the-evolution-of-skill-discovery-in-virtual-assistants-229c9363ac58?source=collection_archive---------20-----------------------#2019-07-05">https://towardsdatascience.com/the-evolution-of-skill-discovery-in-virtual-assistants-229c9363ac58?source=collection_archive---------20-----------------------#2019-07-05</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><figure class="gl gn jr js jt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi jq"><img src="../Images/b82d0ae86de7f143f29e7ce427d803b0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*XDCICuUdPAjpbk9eMDUygw.png"/></div></div><figcaption class="kb kc gj gh gi kd ke bd b be z dk">Skill discovery in virtual assistants (Illustration: <a class="ae kf" href="http://www.luniapilot.com/" rel="noopener ugc nofollow" target="_blank">Luniapilot</a>)</figcaption></figure><p id="26ff" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">这篇博文是来自<a class="ae kf" href="http://www.embodiedai.co/" rel="noopener ugc nofollow" target="_blank"> <strong class="ki iu"> Embodied AI </strong> </a> <strong class="ki iu">，</strong>的一期，由<a class="ae kf" href="https://20bn.com/" rel="noopener ugc nofollow" target="_blank"> TwentyBN </a>撰写的关于 AI 化身、虚拟生物和数字人类背后的最新新闻、技术和趋势的双周刊。</p></div><div class="ab cl le lf hx lg" role="separator"><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj"/></div><div class="im in io ip iq"><p id="2a5e" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">上周五，化身 AI 在几个朋友的公寓里喝着酒，突然瞥见角落里放着一个新买的 Google Home。他对所有人工智能的好奇心占据了他的头脑，他问他们用新技术做什么。“除了播放音乐，”他们回答说，“我们还问它时间、天气，以及……开灯和关灯。”</p><p id="6623" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">和很多消费者一样，Embodied AI 的朋友们遇到了基于语音的智能技术中的<strong class="ki iu"> <em class="ll">技能发现问题</em> </strong>。虽然智能扬声器可以做的不仅仅是报告天气、开灯和点餐——仅谷歌助手就有 4200 件事情——但它不能有效地传达它可以帮助我们的无数方式。由于技能发现是使虚拟助手更有效和更像人类的一个关键因素，我们将探索技能发现的演变，包括它的挑战，目前的进展，以及它将如何在未来继续发展。</p><h1 id="09cf" class="lm ln it bd lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj bi translated">技能发现:2 项挑战和 8 项建议</h1><p id="1c69" class="pw-post-body-paragraph kg kh it ki b kj mk kl km kn ml kp kq kr mm kt ku kv mn kx ky kz mo lb lc ld im bi translated"><a class="ae kf" href="https://www.ben-evans.com/" rel="noopener ugc nofollow" target="_blank"><strong class="ki iu">Benedict Evans</strong></a>(Andre essen Horowitz)将智能音箱中的技能发现称为<a class="ae kf" href="https://www.ben-evans.com/benedictevans/2019/1/29/is-alexa-working" rel="noopener ugc nofollow" target="_blank">基本的 UX 难题</a>:例如，Alexa 的纯音频界面很方便，直到你希望它向用户逐一背诵其<a class="ae kf" href="https://voicebot.ai/2019/01/31/amazon-announces-80000-alexa-skills-worldwide-and-jeff-bezos-earnings-release-quote-focuses-solely-on-alexa-momentum/" rel="noopener ugc nofollow" target="_blank"> 80，000 项技能</a>。</p><p id="c279" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">有两个因素使得技能发现特别具有挑战性:</p><ul class=""><li id="4ddd" class="mp mq it ki b kj kk kn ko kr mr kv ms kz mt ld mu mv mw mx bi translated">可用性:虚拟助理的技能正在迅速扩展。<a class="ae kf" href="https://voicebot.ai/2019/02/15/google-assistant-actions-total-4253-in-january-2019-up-2-5x-in-past-year-but-7-5-the-total-number-alexa-skills-in-u-s/" rel="noopener ugc nofollow" target="_blank"> Voicebot </a>报告称，自 2018 年以来，谷歌助手的能力增长了 2.5 倍，达到 4253 个动作，Alexa 的能力增长了 2.2 倍，达到近 8 万个动作。</li><li id="b3c0" class="mp mq it ki b kj my kn mz kr na kv nb kz nc ld mu mv mw mx bi translated"><strong class="ki iu">启示:</strong>用户不确定他们的虚拟助手有什么能力，导致期望偏差，他们中的许多人忽视了使用互联网来了解他们助手的技能的全部范围。</li></ul><figure class="ne nf ng nh gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi nd"><img src="../Images/25a3e33cacb03730116fbb056004d9c7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*xdjjS228cZ95kOyZUvREXQ.png"/></div></div><figcaption class="kb kc gj gh gi kd ke bd b be z dk">Alexa and her many skills (Credit: Ryen W. White, Communications of the ACM)</figcaption></figure><h2 id="fb65" class="ni ln it bd lo nj nk dn ls nl nm dp lw kr nn no ma kv np nq me kz nr ns mi nt bi translated">虚拟演讲者帮助人们发现他们所能做的 8 种方式</h2><p id="fb6a" class="pw-post-body-paragraph kg kh it ki b kj mk kl km kn ml kp kq kr mm kt ku kv mn kx ky kz mo lb lc ld im bi translated">在这篇<a class="ae kf" href="http://ryenwhite.com/papers/WhiteCACM2018a.pdf" rel="noopener ugc nofollow" target="_blank">文章</a>，<a class="ae kf" href="https://www.microsoft.com/en-us/research/people/ryenw/" rel="noopener ugc nofollow" target="_blank"> <strong class="ki iu"> Ryen W. White </strong> </a>(微软研究院)列出了虚拟扬声器的 8 项改进，以便用户可以更容易地发现他们日常需要的新技能:</p><ul class=""><li id="64f8" class="mp mq it ki b kj kk kn ko kr mr kv ms kz mt ld mu mv mw mx bi translated"><strong class="ki iu">积极主动:</strong>让虚拟助理主动利用他们的技能吸引用户，而不是被动的、用户发起的交互。</li><li id="66a1" class="mp mq it ki b kj my kn mz kr na kv nb kz nc ld mu mv mw mx bi translated"><strong class="ki iu">时机决定一切:</strong>在需要的时候向用户提供技能建议，以确保这些能力在将来更容易被记住。</li><li id="b17e" class="mp mq it ki b kj my kn mz kr na kv nb kz nc ld mu mv mw mx bi translated"><strong class="ki iu">使用情境和个人信号:</strong>利用用户情境和个人信号的组合，包括长期习惯和模式</li><li id="8e0e" class="mp mq it ki b kj my kn mz kr na kv nb kz nc ld mu mv mw mx bi translated"><strong class="ki iu">检查附加信号:</strong>还不可访问的上下文和个人信息，例如只能用视觉观察的人类活动，是用于个性化推荐的未开发的机会。</li><li id="1ad6" class="mp mq it ki b kj my kn mz kr na kv nb kz nc ld mu mv mw mx bi translated"><strong class="ki iu">考虑隐私和效用:</strong>在正确的时间提供正确的帮助，并通过推荐解释主动将其归因于许可的数据访问。</li><li id="e890" class="mp mq it ki b kj my kn mz kr na kv nb kz nc ld mu mv mw mx bi translated"><strong class="ki iu">允许多个推荐:</strong>当推荐模型的置信度低于某个阈值时，建议多个技能，在该阈值时通常会建议一个确定的技能。</li><li id="150c" class="mp mq it ki b kj my kn mz kr na kv nb kz nc ld mu mv mw mx bi translated"><strong class="ki iu">利用配套设备:</strong>允许通过 WiFi 或蓝牙连接访问各种屏幕，如智能手机、平板电脑或台式电脑，以丰富上下文并帮助提供更相关的技能建议。</li><li id="72af" class="mp mq it ki b kj my kn mz kr na kv nb kz nc ld mu mv mw mx bi translated"><strong class="ki iu">支持持续学习:</strong>根据以前的活动模式提出新的技能。</li></ul><h1 id="1bce" class="lm ln it bd lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj bi translated">提高技能发现的研究进展</h1><p id="8f76" class="pw-post-body-paragraph kg kh it ki b kj mk kl km kn ml kp kq kr mm kt ku kv mn kx ky kz mo lb lc ld im bi translated">最近，亚马逊推出了<a class="ae kf" href="https://developer.amazon.com/blogs/alexa/post/44499221-01ff-460a-a9ee-d4e9198ef98d/introducing-alexa-conversations-preview" rel="noopener ugc nofollow" target="_blank"><strong class="ki iu">Alexa Conversations</strong></a>，这是一种深度学习方法，允许开发人员以更少的努力、更少的代码行和更少的训练数据更有效地提高技能发现。虽然仍处于“预览”阶段，但 Alexa Conversations 已经<a class="ae kf" href="https://voicebot.ai/2019/06/06/alexa-conversations-to-automate-elements-of-skill-building-using-ai-and-make-user-experiences-more-natural-while-boosting-discovery/" rel="noopener ugc nofollow" target="_blank">在为智能扬声器培养技能的开发人员中引起了相当大的兴奋</a>。</p><figure class="ne nf ng nh gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi nu"><img src="../Images/9fe1cb86d5ad524ff8cbeb61e1237e70.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*08ZAXzOJdZ-r_7iziGTH1A.png"/></div></div><figcaption class="kb kc gj gh gi kd ke bd b be z dk">Alexa Conversations claims to utilize machine learning to predict a user’s true goal from the dialogue and proactively enable the conversation flow across skills. (Credit: <a class="ae kf" href="https://developer.amazon.com/blogs/alexa/post/9615b190-9c95-452c-b04d-0a29f6a96dd1/amazon-unveils-novel-alexa-dialog-modeling-for-natural-cross-skill-conversations" rel="noopener ugc nofollow" target="_blank">Alexa Blog</a>)</figcaption></figure><p id="044e" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">本质上，Alexa Conversations 旨在建立一个更自然和流畅的互动，在一个单一的技能范围内，Alexa 和它的用户之间。在未来的版本中，该软件有望在一次对话中引入多种技能。它还声称能够处理模糊的引用，例如，“附近有意大利餐馆吗？”(哪里附近？)，以及从一种技能过渡到另一种技能时的上下文保留，例如在建议附近的餐馆时记住某个电影院的位置。</p><p id="2fb8" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在 6 月份亚马逊的 re:MARS AI 和 ML 大会上，Alexa 副总裁兼首席科学家 Rohit Prasad 提到<a class="ae kf" href="https://developer.amazon.com/blogs/alexa/post/9615b190-9c95-452c-b04d-0a29f6a96dd1/amazon-unveils-novel-alexa-dialog-modeling-for-natural-cross-skill-conversations" rel="noopener ugc nofollow" target="_blank"> Alexa Conversations 的机器学习功能</a>可以帮助它从对话的方向预测客户的真实意图和目标，从而在对话过程中主动实现多种技能的流动。如果这些承诺得到满足，与 Alexa 的命令-查询交互肯定会开始感觉更像自然的人类交互。</p><h1 id="b59b" class="lm ln it bd lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj bi translated">未来:看见和具体化的虚拟助手</h1><p id="7b9d" class="pw-post-body-paragraph kg kh it ki b kj mk kl km kn ml kp kq kr mm kt ku kv mn kx ky kz mo lb lc ld im bi translated">Alexa 团队取得的进展确实令人兴奋，但对话式人工智能并不是唯一有改进空间的领域。在 Embodied AI，我们支持将对话式人工智能和视频理解集成到拟人化的具体化助手中，这是通过在现有的扬声器界面上添加摄像头和屏幕实现的。</p><p id="9547" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">随着我们对自然语言处理和计算机视觉的理解不断进步，没有理由将虚拟助手局限于音频。最近发布的<a class="ae kf" href="https://www.theverge.com/2019/5/29/18643451/amazon-echo-show-5-alexa-screen-price-availability-89" rel="noopener ugc nofollow" target="_blank">亚马逊 Echo Show 5 </a>、<a class="ae kf" href="https://portal.facebook.com/" rel="noopener ugc nofollow" target="_blank">脸书门户</a>和<a class="ae kf" href="https://www.theverge.com/2019/5/7/18301161/google-nest-hub-max-camera-home-announcement-io-2019-keynote" rel="noopener ugc nofollow" target="_blank">谷歌的 Nest Hub Max </a>，所有这些都带有摄像头和屏幕，已经预示着该行业向虚拟助手的发展，有一天虚拟助手可以看到和被看到。人们可以合理地推测，大型科技公司正在致力于视觉化和具体化的虚拟助理，以在不久的将来取代他们的智能扬声器。这是他们现有产品线的自然延伸。</p><p id="3642" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">具有照相机、屏幕和拟人化实施例的虚拟助理的好处包括:</p><ul class=""><li id="710a" class="mp mq it ki b kj kk kn ko kr mr kv ms kz mt ld mu mv mw mx bi translated"><strong class="ki iu">多模式 I/O: </strong>配备语音 I/O 和视频 I/O 的虚拟助理不再局限于音频，而是拥有更高的智能和更具吸引力的图形用户界面。</li><li id="541d" class="mp mq it ki b kj my kn mz kr na kv nb kz nc ld mu mv mw mx bi translated"><strong class="ki iu">改进的技能发现体验:</strong>利用计算机视觉捕捉目前纯音频设备未利用的上下文和个人信号，允许从用户发起的交互过渡到主动协助。</li><li id="5bd5" class="mp mq it ki b kj my kn mz kr na kv nb kz nc ld mu mv mw mx bi translated"><strong class="ki iu">陪伴而不是仆人:</strong>有了数字化、类人的身体，虚拟助理将不再被视为仆人，而是帮手。虽然这不会直接改善技能发现，但它丰富了虚拟助理的整体体验。</li></ul><figure class="ne nf ng nh gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi nv"><img src="../Images/b4b35bf7d3dccae4e16158e91e83514d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*M2qRertS2BYXAMKVEEQWSg.png"/></div></div><figcaption class="kb kc gj gh gi kd ke bd b be z dk">Roland Memisevic, TwentyBN’s CEO, believes that computer vision, by unlocking context awareness for virtual assistants, will shift the assistant paradigm from query-response to memory-infused companionship. (Credit: LDV Capital)</figcaption></figure><p id="6309" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">TwentyBN 的首席执行官 Roland Memisevic  设想了一个未来，我们与虚拟助手的对话将不会像现在的智能扬声器那样感觉像打电话:</p><blockquote class="nw"><p id="1d77" class="nx ny it bd nz oa ob oc od oe of ld dk translated"><em class="og"> " </em>化身不一定需要唤醒词，但可以一直在这里，看到和听到，特别是当他们是边缘驱动的并且没有隐私问题时。使用计算机视觉来解锁虚拟助手的上下文感知，我们将把助手范式从查询-响应转变为注入记忆的陪伴。问我们未来的同伴他们有什么技能，就像问你最好的朋友他们是否呼吸氧气一样可笑。<em class="og"/></p></blockquote><h1 id="02a4" class="lm ln it bd lo lp lq lr ls lt lu lv lw lx oh lz ma mb oi md me mf oj mh mi mj bi translated">“嘿，谷歌，让我们结束吧！”</h1><p id="09d2" class="pw-post-body-paragraph kg kh it ki b kj mk kl km kn ml kp kq kr mm kt ku kv mn kx ky kz mo lb lc ld im bi translated">或许在不久的将来，在另一个周五的晚上，化身人工智能将重访他朋友的屋顶公寓，并发现一个新的虚拟助理，一个不仅精通对话，而且拥有理解上下文和识别语言无法捕捉的需求的眼睛的虚拟助理。也许它甚至可能有一个数字化的人体，成为一个虚拟的朋友，分享并增加柏林仲夏夜晚的活跃气氛。</p><p id="30a5" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">化身 AI 伸手从他的酒杯中抿了一口，当发现它是空的时，听到他朋友的谷歌助手从角落里喊道，“我想我们准备好再来一瓶白葡萄酒了！”</p></div><div class="ab cl le lf hx lg" role="separator"><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj"/></div><div class="im in io ip iq"><p id="9f89" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><em class="ll">作者</em> <a class="ae kf" href="https://twitter.com/nahuakang" rel="noopener ugc nofollow" target="_blank"> <em class="ll">那华</em> </a> <em class="ll">编辑</em> <a class="ae kf" href="https://twitter.com/david_greenberg" rel="noopener ugc nofollow" target="_blank"> <em class="ll">大卫</em></a><em class="ll"/><a class="ae kf" href="https://www.linkedin.com/in/william-hackett-95950517a/" rel="noopener ugc nofollow" target="_blank"><em class="ll">将</em></a><em class="ll"/><a class="ae kf" href="https://twitter.com/muellerfreitag" rel="noopener ugc nofollow" target="_blank"><em class="ll">莫里茨</em> </a> <em class="ll">，以及</em> <a class="ae kf" href="https://medium.com/@isaacwu_10508" rel="noopener"> <em class="ll">萨克</em> </a> <em class="ll">。插图由</em> <a class="ae kf" href="http://www.luniapilot.com/" rel="noopener ugc nofollow" target="_blank"> <em class="ll">氹欞侊</em> </a> <em class="ll">组成。</em></p><p id="9b2e" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><a class="ae kf" href="http://www.embodiedai.co/" rel="noopener ugc nofollow" target="_blank"><strong class="ki iu">Embodied AI</strong></a><strong class="ki iu"/>是一份关于 AI 化身和虚拟生物背后的最新新闻、技术和趋势的双周刊。<strong class="ki iu">订阅下面:</strong></p><div class="ok ol gp gr om on"><a href="http://www.embodiedai.co/" rel="noopener  ugc nofollow" target="_blank"><div class="oo ab fo"><div class="op ab oq cl cj or"><h2 class="bd iu gy z fp os fr fs ot fu fw is bi translated">人工智能化身时事通讯</h2><div class="ou l"><h3 class="bd b gy z fp os fr fs ot fu fw dk translated">具体化的人工智能是权威的人工智能化身时事通讯。报名参加最新新闻、技术…</h3></div><div class="ov l"><p class="bd b dl z fp os fr fs ot fu fw dk translated">www.embodiedai.co</p></div></div><div class="ow l"><div class="ox l oy oz pa ow pb jz on"/></div></div></a></div></div></div>    
</body>
</html>