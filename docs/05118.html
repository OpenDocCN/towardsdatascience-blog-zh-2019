<html>
<head>
<title>Support Vector Machine Explained</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">支持向量机解释</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/support-vector-machine-explained-8bfef2f17e71?source=collection_archive---------15-----------------------#2019-07-31">https://towardsdatascience.com/support-vector-machine-explained-8bfef2f17e71?source=collection_archive---------15-----------------------#2019-07-31</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="96dd" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">理论、实现和可视化</h2></div><p id="c162" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">支持向量机(SVM)可能是数据科学家使用的最流行的 ML 算法之一。SVM 是强大的，易于解释，并在许多情况下推广良好。在本文中，我将解释 SVM 背后的基本原理，并展示 Python 中的实现。为了简单起见，本文中我将重点讨论二进制分类问题。然而，SVM 支持多分类。</p><h1 id="f96c" class="lb lc iq bd ld le lf lg lh li lj lk ll jw lm jx ln jz lo ka lp kc lq kd lr ls bi translated">1.理论</h1><h2 id="3057" class="lt lc iq bd ld lu lv dn lh lw lx dp ll ko ly lz ln ks ma mb lp kw mc md lr me bi translated">1.1 背后的总体思路</h2><p id="a427" class="pw-post-body-paragraph kf kg iq kh b ki mf jr kk kl mg ju kn ko mh kq kr ks mi ku kv kw mj ky kz la ij bi translated">SVM 寻求最佳决策边界，该边界将具有最高概括能力的两个类分开(为什么关注概括？我会在后面的内核部分解释)。人们问的第一个问题是 SVM 如何定义最优性。</p><figure class="ml mm mn mo gt mp gh gi paragraph-image"><div class="gh gi mk"><img src="../Images/c6242e202a8e08229386ab1a8bb4a616.png" data-original-src="https://miro.medium.com/v2/resize:fit:1066/format:webp/1*dOtW6xcSwuem4Pkx7guhCg.png"/></div><figcaption class="ms mt gj gh gi mu mv bd b be z dk">Which decision boundary should we pick? from <a class="ae mw" href="http://web.mit.edu/6.034/wwwbob/svm.pdf" rel="noopener ugc nofollow" target="_blank">MIT</a></figcaption></figure><p id="4669" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">与通过总体概率定义最优性的逻辑回归不同，SVM 希望数据点和决策边界之间的最小距离尽可能大。换句话说，如果你把决策边界想象成街道的中心线，SVM 更喜欢 8 线高速公路，而不是乡村公路。街道的宽度被称为<strong class="kh ir">边缘</strong>。</p><figure class="ml mm mn mo gt mp gh gi paragraph-image"><div role="button" tabindex="0" class="my mz di na bf nb"><div class="gh gi mx"><img src="../Images/89dab9bada3203c6c889720f31a0f6c2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*7rICgvTcJzODzvHZhfKYrA.png"/></div></div><figcaption class="ms mt gj gh gi mu mv bd b be z dk">from Vapnik, <a class="ae mw" href="http://image.diku.dk/imagecanon/material/cortes_vapnik95.pdf" rel="noopener ugc nofollow" target="_blank">Support-Vector Network</a></figcaption></figure><h2 id="faa5" class="lt lc iq bd ld lu lv dn lh lw lx dp ll ko ly lz ln ks ma mb lp kw mc md lr me bi translated">1.2 数学</h2><p id="04b7" class="pw-post-body-paragraph kf kg iq kh b ki mf jr kk kl mg ju kn ko mh kq kr ks mi ku kv kw mj ky kz la ij bi translated"><strong class="kh ir">定义边距</strong></p><p id="b7f0" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">好吧，这个想法很直观。让我们找出边距的表达式。在我们开始之前，请记住本文中使用的符号:</p><figure class="ml mm mn mo gt mp gh gi paragraph-image"><div role="button" tabindex="0" class="my mz di na bf nb"><div class="gh gi nc"><img src="../Images/c3ad7519df12dc69b3763ce371507a86.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*J8GV4JYYxd4-MjpkxTmYug.png"/></div></div></figure><p id="7f0b" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">如果我们知道决策边界的权重和截距，则该边界可以由以下等式表示:</p><figure class="ml mm mn mo gt mp gh gi paragraph-image"><div role="button" tabindex="0" class="my mz di na bf nb"><div class="gh gi nd"><img src="../Images/fa01d6040e0cf18fffeba6d5dfaab87d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*IVqwXgPDeHKcqTOTYQkzhA.png"/></div></div><figcaption class="ms mt gj gh gi mu mv bd b be z dk">The equation for the broken line in the last figure</figcaption></figure><p id="e61e" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">从数据点到边界的距离为:</p><figure class="ml mm mn mo gt mp gh gi paragraph-image"><div role="button" tabindex="0" class="my mz di na bf nb"><div class="gh gi ne"><img src="../Images/f0e66e5fe2bc2b6bd120c59d9c20ad6b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*uwno1I8oyFTh0FT-niKzCQ.png"/></div></div></figure><figure class="ml mm mn mo gt mp gh gi paragraph-image"><div class="gh gi nf"><img src="../Images/dd2255a14560b03c2e6c99856ea9b0c2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1086/format:webp/1*Df2t3iRcbZ4YSYPGcRxudQ.png"/></div><figcaption class="ms mt gj gh gi mu mv bd b be z dk">from <a class="ae mw" href="https://www.youtube.com/watch?v=eHsErlPJWUU" rel="noopener ugc nofollow" target="_blank">Lecture 14-Support Vector Machine, Caltech</a></figcaption></figure><p id="eedd" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">边距是从最近点到边界的距离:</p><figure class="ml mm mn mo gt mp gh gi paragraph-image"><div role="button" tabindex="0" class="my mz di na bf nb"><div class="gh gi ng"><img src="../Images/e0f0ab1b9dcff080d7b63f26594d5081.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*4-0DQ9jOylGKi4y54skizA.png"/></div></div></figure><p id="1df6" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir">最终目标</strong></p><p id="dff7" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">现在我们知道了如何计算利润，让我们尝试将需要优化的问题形式化:</p><figure class="ml mm mn mo gt mp gh gi paragraph-image"><div role="button" tabindex="0" class="my mz di na bf nb"><div class="gh gi nh"><img src="../Images/809333e93e913c6b137ddf08645becdf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*dxolBcNd3ntOC4JfVo2FSA.png"/></div></div><figcaption class="ms mt gj gh gi mu mv bd b be z dk">Final Objective</figcaption></figure><p id="d919" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我不得不承认这是一个奇怪的函数。只要记住这一点:这就像线性回归的 RMSE，逻辑回归的交叉熵，一个需要优化的函数。</p><h2 id="ada8" class="lt lc iq bd ld lu lv dn lh lw lx dp ll ko ly lz ln ks ma mb lp kw mc md lr me bi translated"><strong class="ak"> 1.3 Python 实现</strong></h2><p id="6266" class="pw-post-body-paragraph kf kg iq kh b ki mf jr kk kl mg ju kn ko mh kq kr ks mi ku kv kw mj ky kz la ij bi translated">现在我们了解了 svm 是如何工作的，让我们试试 SVM。Scikit-Learn 提供的 SVC 功能</p><figure class="ml mm mn mo gt mp gh gi paragraph-image"><div role="button" tabindex="0" class="my mz di na bf nb"><div class="gh gi ni"><img src="../Images/a5de0a213d2a7db7255e45a2cd108188.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*emr44J4SUgnkMZADd5vnPg.png"/></div></div><figcaption class="ms mt gj gh gi mu mv bd b be z dk"><a class="ae mw" href="https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html" rel="noopener ugc nofollow" target="_blank">from scikit-learn.org</a></figcaption></figure><p id="dbd4" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">等等，这些参数是什么？目标中没有 C 或“内核”。你确定这是正确的功能吗？不幸的是，是的，我们只需要稍微深入一点 SVM 背后的数学。</p><h2 id="c937" class="lt lc iq bd ld lu lv dn lh lw lx dp ll ko ly lz ln ks ma mb lp kw mc md lr me bi translated">1.4 又是理论…</h2><p id="6de5" class="pw-post-body-paragraph kf kg iq kh b ki mf jr kk kl mg ju kn ko mh kq kr ks mi ku kv kw mj ky kz la ij bi translated">现在我们需要谈谈如何优化目标函数。回想一下，该函数是:</p><figure class="ml mm mn mo gt mp gh gi paragraph-image"><div role="button" tabindex="0" class="my mz di na bf nb"><div class="gh gi nj"><img src="../Images/1cd04536fb3156ac2d55285e28bb309c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Zx1LpT9PqJAFexYYnzcVkg.png"/></div></div></figure><p id="1182" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们究竟如何最大化这个等式？我们不能求导就完事了，因为最终的 W 和 b 可能不满足约束。幸运的是，一个高中数学班的男生来拯救我们——拉格朗日。</p><p id="0628" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir">消除约束</strong></p><blockquote class="nk nl nm"><p id="4116" class="kf kg nn kh b ki kj jr kk kl km ju kn no kp kq kr np kt ku kv nq kx ky kz la ij bi translated">拉格朗日乘子的<strong class="kh ir">方法是一种策略，用于寻找服从<a class="ae mw" href="https://en.wikipedia.org/wiki/Constraint_(mathematics)" rel="noopener ugc nofollow" target="_blank">等式约束</a>(即服从一个或多个<a class="ae mw" href="https://en.wikipedia.org/wiki/Equation" rel="noopener ugc nofollow" target="_blank">方程</a>必须由所选变量值精确满足的条件)的<a class="ae mw" href="https://en.wikipedia.org/wiki/Function_(mathematics)" rel="noopener ugc nofollow" target="_blank">函数</a>的局部<a class="ae mw" href="https://en.wikipedia.org/wiki/Maxima_and_minima" rel="noopener ugc nofollow" target="_blank">最大值和最小值</a>。<a class="ae mw" href="https://en.wikipedia.org/wiki/Lagrange_multiplier#cite_note-1" rel="noopener ugc nofollow" target="_blank">【1】</a>基本思想是将一个有约束的问题转换成一种形式，使得无约束问题的<a class="ae mw" href="https://en.wikipedia.org/wiki/Derivative_test" rel="noopener ugc nofollow" target="_blank">导数测试</a>仍然可以应用— <a class="ae mw" href="https://en.wikipedia.org/wiki/Lagrange_multiplier" rel="noopener ugc nofollow" target="_blank">维基百科</a></strong></p></blockquote><figure class="ml mm mn mo gt mp gh gi paragraph-image"><div role="button" tabindex="0" class="my mz di na bf nb"><div class="gh gi nr"><img src="../Images/ec1add051266ab9c679560509ae38d95.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*PdOW3EqvnJuU2U4Wy4-2IA.png"/></div></div><figcaption class="ms mt gj gh gi mu mv bd b be z dk">from <a class="ae mw" href="http://web.mit.edu/6.034/wwwbob/svm.pdf" rel="noopener ugc nofollow" target="_blank">MIT</a></figcaption></figure><p id="d8b6" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在拉格朗日乘数的帮助下，我们可以通过求解这个函数来找到上述问题的解:</p><figure class="ml mm mn mo gt mp gh gi paragraph-image"><div role="button" tabindex="0" class="my mz di na bf nb"><div class="gh gi ns"><img src="../Images/d980e9f8b0eb2d7b13cf333655e52f91.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*7GuGfAdg6WJ0kRECAsTpZw.png"/></div></div><figcaption class="ms mt gj gh gi mu mv bd b be z dk">Unconstrained objective function</figcaption></figure><p id="923d" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir">算出 W 和 b </strong></p><p id="fb05" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">现在，W，b 和α都是未知的。天哪，我们该怎么办？幸运的是，Vapnik Vladimir 为我们指出了这一点:</p><p id="7b94" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">首先相对于 W 和 b 最小化 L(假设我们知道α)</p><figure class="ml mm mn mo gt mp gh gi paragraph-image"><div role="button" tabindex="0" class="my mz di na bf nb"><div class="gh gi nt"><img src="../Images/025528efa1f6dc7452004f92f0aaea6e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*R10URnqKAeKfWQZtZpXleA.png"/></div></div><figcaption class="ms mt gj gh gi mu mv bd b be z dk">W and b are easy to find as long as we know alpha</figcaption></figure><p id="91a7" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">用我们刚找到的 W 和 b 最大化 L w.r.t。</p><figure class="ml mm mn mo gt mp gh gi paragraph-image"><div role="button" tabindex="0" class="my mz di na bf nb"><div class="gh gi nu"><img src="../Images/457bd9909794e134b0de8425fc9290fc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*x1bECGqI8AguGIe4mHB6nA.png"/></div></div></figure><p id="68e1" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">等等，为什么这突然变成最大化了？这被称为拉格朗日对偶。</p><blockquote class="nk nl nm"><p id="0d76" class="kf kg nn kh b ki kj jr kk kl km ju kn no kp kq kr np kt ku kv nq kx ky kz la ij bi translated">拉格朗日对偶问题:我们可以根据之前获得的 w 和 b 的关系，在α(对偶变量)上最大化，而不是在 w，b 上最小化，受到α的约束—<a class="ae mw" href="http://web.mit.edu/6.034/wwwbob/svm.pdf" rel="noopener ugc nofollow" target="_blank">SVM 白痴指南</a></p></blockquote><p id="14d9" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">上述函数有一个很好的形式，可以用<a class="ae mw" href="https://scaron.info/blog/quadratic-programming-in-python.html" rel="noopener ugc nofollow" target="_blank">二次规划软件</a>求解。只要把这个函数和约束传递给任何商业 QP 软件，它就会返回一个阿尔法列表。现在α解出来了，就可以计算 W 和 b 了。搞定了。</p><h2 id="4c0d" class="lt lc iq bd ld lu lv dn lh lw lx dp ll ko ly lz ln ks ma mb lp kw mc md lr me bi translated"><strong class="ak"> 1.5 什么是参数‘C’</strong></h2><p id="28bf" class="pw-post-body-paragraph kf kg iq kh b ki mf jr kk kl mg ju kn ko mh kq kr ks mi ku kv kw mj ky kz la ij bi translated">在上面的定义中，我们假设所有点都必须在页边空白的边界上或超出它(一个所谓的硬 SVM)。实际上，通常不是这样。我们需要定义一个<strong class="kh ir">软 SVM，允许轻微违反规则的行为受到一些处罚</strong>:</p><figure class="ml mm mn mo gt mp gh gi paragraph-image"><div class="gh gi nv"><img src="../Images/21e581f4528272a8c6d3985d26ff7c94.png" data-original-src="https://miro.medium.com/v2/resize:fit:916/format:webp/1*UylttRyv51Pz0ADkNt4goA.png"/></div><figcaption class="ms mt gj gh gi mu mv bd b be z dk">violation of constraints, from <a class="ae mw" href="https://www.youtube.com/watch?v=XUj5JbQihlU" rel="noopener ugc nofollow" target="_blank">Caltech</a></figcaption></figure><figure class="ml mm mn mo gt mp gh gi paragraph-image"><div role="button" tabindex="0" class="my mz di na bf nb"><div class="gh gi nw"><img src="../Images/f75265f564343418d79ecce472a07039.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*I0Iea4K-o4r8V8wlmibb8A.png"/></div></div></figure><p id="9c3c" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">如您所见，C 决定了 SVM 对违规的严重程度。如果 C 是 0，那么 SVM 根本不关心违例，因为惩罚项已经没有了。如果 C 非常巨大，微小的违反将导致目标函数的巨大增量。这个函数的解可以用上面解释的相同方法导出。</p><h2 id="c815" class="lt lc iq bd ld lu lv dn lh lw lx dp ll ko ly lz ln ks ma mb lp kw mc md lr me bi translated"><strong class="ak"> 1.6 什么是参数‘内核’</strong></h2><p id="1a87" class="pw-post-body-paragraph kf kg iq kh b ki mf jr kk kl mg ju kn ko mh kq kr ks mi ku kv kw mj ky kz la ij bi translated">内核技巧是一种强大的转换技术，它将数据从原始空间投影到转换后的空间，希望使数据更具线性可分性。</p><figure class="ml mm mn mo gt mp gh gi paragraph-image"><div role="button" tabindex="0" class="my mz di na bf nb"><div class="gh gi nx"><img src="../Images/7945cdb64dc44d6aef75fbb29788531e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_oJ8tU5vTpH1GF2CdZ9hlw.png"/></div></div><figcaption class="ms mt gj gh gi mu mv bd b be z dk">Radial kernel, fr<a class="ae mw" href="http://web.mit.edu/6.034/wwwbob/svm.pdf" rel="noopener ugc nofollow" target="_blank">om An Idiot’s Guide to SVM</a></figcaption></figure><p id="d1dd" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">更严格地说，我们需要一个转换函数:</p><figure class="ml mm mn mo gt mp gh gi paragraph-image"><div role="button" tabindex="0" class="my mz di na bf nb"><div class="gh gi ny"><img src="../Images/daef1cbe320099cf82799fad0636bbc5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*8gWfxfwMORFqe4_sgPnueQ.png"/></div></div></figure><p id="19ad" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">回想一下我们之前推导的目标函数:</p><figure class="ml mm mn mo gt mp gh gi paragraph-image"><div role="button" tabindex="0" class="my mz di na bf nb"><div class="gh gi nz"><img src="../Images/1b744596fe0c1c0e17bd9c512431aad4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Fuh8YBrDRQz8Kt2Tv5Rwtw.png"/></div></div></figure><p id="4e4f" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在新的空间中，我们必须计算这个函数:</p><figure class="ml mm mn mo gt mp gh gi paragraph-image"><div role="button" tabindex="0" class="my mz di na bf nb"><div class="gh gi oa"><img src="../Images/ab27f3bbe7739b34006770b7ac84a3a2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Yzx_qxhbIEwGfZh836u_bQ.png"/></div></div></figure><p id="e9da" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在内核转换的帮助下，我们将能够将数据映射到更高维度，并有更大的机会用超平面将它们分开。</p><figure class="ml mm mn mo gt mp gh gi paragraph-image"><div role="button" tabindex="0" class="my mz di na bf nb"><div class="gh gi ob"><img src="../Images/6095c0968e67b10f97dfba1d2bbb78e4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*A6Eq954leeXInLqeI6yS1g.png"/></div></div><figcaption class="ms mt gj gh gi mu mv bd b be z dk">Decision boundary obtained with kernel methods, 3 classes, from <a class="ae mw" href="https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html" rel="noopener ugc nofollow" target="_blank">Scikit-Learn</a></figcaption></figure><p id="3752" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">等等，为什么我们会得到非线性的边界？SVM 应该只找到线性边界。<strong class="kh ir"> </strong>是的，你说对了一部分！你看到的决策边界是高维空间的投影。在我们在转换后的空间中完成分类后，<strong class="kh ir">我们可以将超平面映射回来，边界可能会变成非线性的！</strong></p><figure class="ml mm mn mo gt mp gh gi paragraph-image"><div role="button" tabindex="0" class="my mz di na bf nb"><div class="gh gi oc"><img src="../Images/5853dcea55a1d7f3fe6112f1e3a1efd1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*3im1D7qkQkrcbj-N0utTPQ.png"/></div></div><figcaption class="ms mt gj gh gi mu mv bd b be z dk">transformation of space, from <a class="ae mw" href="https://sebastianraschka.com/faq/docs/select_svm_kernels.html" rel="noopener ugc nofollow" target="_blank">Sebastian Raschka</a></figcaption></figure><p id="d9c8" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir">当前转换的小问题</strong></p><p id="b4c2" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">变换函数将数据点投影到不同的空间。当投影空间变得更加复杂时，这个过程非常耗时。在某些情况下，我们甚至不知道变换方程。应该没有办法将一个数据点映射到一个无限维的空间。还是有？</p><p id="9ede" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">如果我们再看一下变换后的目标函数，我们可以对它进行微小的修改:</p><figure class="ml mm mn mo gt mp gh gi paragraph-image"><div role="button" tabindex="0" class="my mz di na bf nb"><div class="gh gi od"><img src="../Images/dc09a34d2112ae976f1708d9a544080e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*gi8_iUBWo2FdEedxXmroNA.png"/></div></div></figure><p id="9eb7" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">你可能会说:好吧，另一个定义，那又怎样？但是看，这是天才的部分。只要我们知道 K(xi，xj)是什么，我们就不需要变换函数。这意味着我们可以选择想要的空间，而不用担心中间的细节。有了这个，我可以定义在没有变换函数φ的情况下，变换后的空间的点积是什么样子。例如，一个无限的。</p><figure class="ml mm mn mo gt mp gh gi paragraph-image"><div role="button" tabindex="0" class="my mz di na bf nb"><div class="gh gi oe"><img src="../Images/c7c9cd3a94468644e29ad470da9fd71f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Pp2OdG2HKRA2UwqmaJkDfA.png"/></div></div><figcaption class="ms mt gj gh gi mu mv bd b be z dk">the See the proof <a class="ae mw" href="https://www.youtube.com/watch?v=XUj5JbQihlU" rel="noopener ugc nofollow" target="_blank">here</a></figcaption></figure><p id="3b94" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">您可能想知道一些著名的、经过充分测试的内核:</p><figure class="ml mm mn mo gt mp gh gi paragraph-image"><div role="button" tabindex="0" class="my mz di na bf nb"><div class="gh gi of"><img src="../Images/88dd5b12bac030db8cc0f7c4a5245b82.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*vBfGDujLmBnbTV7smayCJQ.png"/></div></div><figcaption class="ms mt gj gh gi mu mv bd b be z dk">fr<a class="ae mw" href="http://web.mit.edu/6.034/wwwbob/svm.pdf" rel="noopener ugc nofollow" target="_blank">om An Idiot’s Guide to SVM</a></figcaption></figure><h1 id="ce3e" class="lb lc iq bd ld le lf lg lh li lj lk ll jw lm jx ln jz lo ka lp kc lq kd lr ls bi translated">2.又是 Python 实现</h1><p id="6a7f" class="pw-post-body-paragraph kf kg iq kh b ki mf jr kk kl mg ju kn ko mh kq kr ks mi ku kv kw mj ky kz la ij bi translated">这一次，我们理解了这些参数的含义。让我们看看每个参数的效果。</p><h2 id="af3e" class="lt lc iq bd ld lu lv dn lh lw lx dp ll ko ly lz ln ks ma mb lp kw mc md lr me bi translated"><strong class="ak">C 的影响</strong></h2><figure class="ml mm mn mo gt mp"><div class="bz fp l di"><div class="og oh l"/></div></figure><figure class="ml mm mn mo gt mp gh gi paragraph-image"><div class="gh gi oi"><img src="../Images/e88f06e0e45ab0193e9b7b351890d5c6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1386/format:webp/1*btaKZjPOtA6ktb1GnaFMuA.png"/></div></figure><p id="a315" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">控制对错误分类点的关注。较大的 C 将迫使模型牺牲余量以支持正确的预测(可能导致过度拟合)</p><h2 id="4f51" class="lt lc iq bd ld lu lv dn lh lw lx dp ll ko ly lz ln ks ma mb lp kw mc md lr me bi translated"><strong class="ak">内核的影响</strong></h2><figure class="ml mm mn mo gt mp"><div class="bz fp l di"><div class="og oh l"/></div></figure><figure class="ml mm mn mo gt mp gh gi paragraph-image"><div class="gh gi oj"><img src="../Images/acf92feb908b973c77fa0db5529a8e1d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1384/format:webp/1*Zi34kt35xbQtxEdmiOQq4Q.png"/></div><figcaption class="ms mt gj gh gi mu mv bd b be z dk">Effects of different kernel</figcaption></figure><h1 id="e727" class="lb lc iq bd ld le lf lg lh li lj lk ll jw lm jx ln jz lo ka lp kc lq kd lr ls bi translated">优势和劣势</h1><figure class="ml mm mn mo gt mp gh gi paragraph-image"><div role="button" tabindex="0" class="my mz di na bf nb"><div class="gh gi ok"><img src="../Images/290db96164e65341a8a9c84d97977690.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*kKa5QkRufyrSpQH2S-V-Fw.png"/></div></div><figcaption class="ms mt gj gh gi mu mv bd b be z dk">from<a class="ae mw" href="https://scikit-learn.org/stable/modules/svm.html" rel="noopener ugc nofollow" target="_blank"> Scikit-Learn.org</a></figcaption></figure><h1 id="c3f4" class="lb lc iq bd ld le lf lg lh li lj lk ll jw lm jx ln jz lo ka lp kc lq kd lr ls bi translated">摘要</h1><p id="2611" class="pw-post-body-paragraph kf kg iq kh b ki mf jr kk kl mg ju kn ko mh kq kr ks mi ku kv kw mj ky kz la ij bi translated">SVM 寻求决策边界的余量和错误分类点的数量之间的平衡。核技巧使 SVM 能够在不增加目标函数局部极小值的情况下引入强大的非线性。现在你明白了 SVM 是如何工作的，是时候在实际项目中尝试一下了！</p></div></div>    
</body>
</html>