<html>
<head>
<title>Map-Reduce: Gradient Descent</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">Map-Reduce:梯度下降</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/map-reduce-gradient-descent-276e6ed0b002?source=collection_archive---------21-----------------------#2019-12-11">https://towardsdatascience.com/map-reduce-gradient-descent-276e6ed0b002?source=collection_archive---------21-----------------------#2019-12-11</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="446a" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">使用 PySpark 和 vanilla Python</h2></div><p id="0805" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">一些统计模型𝑓(𝑥通过优化依赖于一组参数θ的损失函数𝐿(θ来学习。有几种方法可以找到损失函数的最佳θ，其中一种方法是按照梯度迭代更新:</p><figure class="lf lg lh li gt lj gh gi paragraph-image"><div class="gh gi le"><img src="../Images/8131ece928a94332761a1294a80e4459.png" data-original-src="https://miro.medium.com/v2/resize:fit:592/format:webp/1*Z5lF_tbTjWKu0xWSPT0KWg.png"/></div></figure><p id="99e4" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">然后，计算更新:</p><figure class="lf lg lh li gt lj gh gi paragraph-image"><div class="gh gi lm"><img src="../Images/3f85c1917d38da86442f4a8a9785dc6d.png" data-original-src="https://miro.medium.com/v2/resize:fit:398/format:webp/1*qfOUVr6cAg1UkxCBLGgWBQ.png"/></div></figure><p id="9662" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">因为我们假设数据点之间是独立的，所以梯度变成了求和:</p><figure class="lf lg lh li gt lj gh gi paragraph-image"><div class="gh gi ln"><img src="../Images/7a901ce13b934a13caf295918db796b9.png" data-original-src="https://miro.medium.com/v2/resize:fit:356/format:webp/1*KB64vDLAL8kz6QmdOFypBw.png"/></div></figure><p id="29fe" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">其中𝐿𝑖是𝑖-th 数据点的损失函数。</p><figure class="lf lg lh li gt lj gh gi paragraph-image"><div role="button" tabindex="0" class="lp lq di lr bf ls"><div class="gh gi lo"><img src="../Images/6b4e7c2f1a845f90f9acf943c2061ad0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*N10FutTXJKMUo9XLx1gWaQ.jpeg"/></div></div><figcaption class="lt lu gj gh gi lv lw bd b be z dk">Image by <a class="ae lx" href="https://pixabay.com/users/geralt-9301/?utm_source=link-attribution&amp;utm_medium=referral&amp;utm_campaign=image&amp;utm_content=70509" rel="noopener ugc nofollow" target="_blank">Gerd Altmann</a> from <a class="ae lx" href="https://pixabay.com/?utm_source=link-attribution&amp;utm_medium=referral&amp;utm_campaign=image&amp;utm_content=70509" rel="noopener ugc nofollow" target="_blank">Pixabay</a></figcaption></figure><p id="89e3" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">以统计模型𝑓(𝑥)=𝑏0+𝑏1𝑥和损失函数𝐿(θ)=(𝑓(𝑥)−𝑦为例)。如果我们有一组三个数据点𝐷={(𝑥=1,𝑦=2),(𝑥=−2,𝑦=−1),(𝑥=4,𝑦=3)}</p><p id="201f" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">那么它们中每一个的损失函数是</p><p id="03a4" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">𝐿1=(𝑏0+𝑏1−2)、𝐿2=(𝑏0−2𝑏1+1)和𝐿3=(𝑏0+4𝑏1−3)与</p><figure class="lf lg lh li gt lj gh gi paragraph-image"><div class="gh gi ly"><img src="../Images/37b6532385bf45f3d492fd5bdad32095.png" data-original-src="https://miro.medium.com/v2/resize:fit:694/format:webp/1*pVuM3if1OOcBFd_EhYhhlg.png"/></div></figure><p id="2fb6" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">如果我们从𝑏1=1 𝑏0=0 的解决方案开始，那么梯度是:</p><figure class="lf lg lh li gt lj gh gi paragraph-image"><div class="gh gi lz"><img src="../Images/69725c081dac75e6ff38654f401ca005.png" data-original-src="https://miro.medium.com/v2/resize:fit:416/format:webp/1*2lE7lem63yon7qjsZo7YLg.png"/></div></figure><p id="3df2" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">积累后会产生</p><figure class="lf lg lh li gt lj gh gi paragraph-image"><div class="gh gi ma"><img src="../Images/2158a3365a631e6a417d409d230aa7bc.png" data-original-src="https://miro.medium.com/v2/resize:fit:328/format:webp/1*yUPnorgJxFC-jMnjmjNrJg.png"/></div></figure><p id="fd75" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">现在，我们创建一个函数，它将接收参数 b 和一个数据点 x 作为列表，并返回该数据点的预测值(y)。</p><figure class="lf lg lh li gt lj"><div class="bz fp l di"><div class="mb mc l"/></div><figcaption class="lt lu gj gh gi lv lw bd b be z dk"><strong class="ak">Ex: f_linear([0, 1], [1]) will give an output of 1</strong></figcaption></figure><p id="f247" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我们定义一个接收预测 y 和实际 y 并返回它们之间的平方误差的函数。</p><figure class="lf lg lh li gt lj"><div class="bz fp l di"><div class="mb mc l"/></div><figcaption class="lt lu gj gh gi lv lw bd b be z dk"><strong class="ak">Ex: L(1, 1) will give an output of 0</strong></figcaption></figure><p id="b721" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">函数 gf_linear(f，b，x，y)将返回具有参数 b 的函数 f 相对于平方损失函数的梯度，在 x 和实际结果 y 处评估。此函数应返回每个元素𝑗对应于相对于𝑏𝑗和𝑗={0,1,…,𝑝}.的梯度的向量</p><figure class="lf lg lh li gt lj"><div class="bz fp l di"><div class="mb mc l"/></div><figcaption class="lt lu gj gh gi lv lw bd b be z dk"><strong class="ak">Ex: x = [1], y = 2, b = [0, 1], gf_linear(f_linear, b, x, y) will give an output of [-2,-2]</strong></figcaption></figure><h1 id="4af2" class="md me it bd mf mg mh mi mj mk ml mm mn jz mo ka mp kc mq kd mr kf ms kg mt mu bi translated"><strong class="ak">地图缩小:</strong></h1><p id="d34f" class="pw-post-body-paragraph ki kj it kk b kl mv ju kn ko mw jx kq kr mx kt ku kv my kx ky kz mz lb lc ld im bi translated">我们开发了一个生成值的地图缩减作业，因此该值的第一个元素是所有数据的平均损失函数。我们将映射函数实现为<code class="fe na nb nc nd b">map_mse(f, b, L, xy)</code>，其中<code class="fe na nb nc nd b">f</code>是函数<code class="fe na nb nc nd b">b</code>是函数的参数<code class="fe na nb nc nd b">L</code>是损失函数<code class="fe na nb nc nd b">xy</code>是数据。假设数据将以 RDD 的形式出现，其中每个元素的格式如下:</p><p id="69f9" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><code class="fe na nb nc nd b">[x, y]</code>其中<code class="fe na nb nc nd b">x</code>是列表，<code class="fe na nb nc nd b">y</code>是标量</p><figure class="lf lg lh li gt lj"><div class="bz fp l di"><div class="mb mc l"/></div></figure><p id="f7c7" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="kk iu">Ex:</strong>rdd _ data . map(lambda x:map _ MSE(f _ linear，[0，0，0]，L，x))。collect()会给出一个<strong class="kk iu">输出</strong>为:[[1，[9，1]]，[1，[16，1]]，[1，[0.0，1]]，[1，[0，1]]。这里 key 是 1，b=[0，0，0]，我们从 rdd_data 得到 x。map 的输出是每个数据点的键和值。</p><p id="f9bb" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">现在，我们创建一个 reduce 作业，它接收前一个 reduce(或 map)的两个值，并适当地合并它们。在 reduce 作业结束时，值的第一个元素是均方误差。</p><figure class="lf lg lh li gt lj"><div class="bz fp l di"><div class="mb mc l"/></div></figure><p id="0afd" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="kk iu">例如:</strong> rdd_data。\<br/>map(lambda x:map _ MSE(f _ linear，[0，0，0]，L，x))。\ <br/> reduceByKey(reduce_mse)。first()[1][0]会给我们一个 6.25 的<strong class="kk iu">均方误差</strong>。(x 和 y 值请遵循 rdd_data)</p><p id="a58c" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">因此，现在我们将计算数据模型的累积梯度。我们将定义一个映射函数<code class="fe na nb nc nd b">map_gradient(f, gf, b, xy)</code>，它将接收一个函数<code class="fe na nb nc nd b">f</code>，它的梯度<code class="fe na nb nc nd b">gf</code>，它的参数<code class="fe na nb nc nd b">b</code>，以及一个数据点<code class="fe na nb nc nd b">xy = [x, y]</code>。此外，我们将定义一个函数<code class="fe na nb nc nd b">reduce_gradient(v1, v2)</code>来适当地组合这两个值。</p><figure class="lf lg lh li gt lj"><div class="bz fp l di"><div class="mb mc l"/></div></figure><figure class="lf lg lh li gt lj"><div class="bz fp l di"><div class="mb mc l"/></div></figure><p id="e619" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="kk iu">Ex:</strong>rdd _ data . map(lambda xy:map _ gradient(f _ linear，gf_linear，[0，0，0]，xy))。reduceByKey(reduce_gradient)。first()[1]将给出[-14.0，-30.0，-20.0]的<strong class="kk iu">输出</strong></p><p id="384f" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">现在，为了得到一个优化的值，我们运行下面的代码，使 MSE 每次都减少。</p><figure class="lf lg lh li gt lj"><div class="bz fp l di"><div class="mb mc l"/></div></figure><p id="2e4b" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">感谢你的阅读，我希望你能学会或至少理解梯度下降是如何工作的，以及如何使用 Map-Reduce 实现它。</p><p id="1821" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">Linkedin:</p><div class="ne nf gp gr ng nh"><a href="https://www.linkedin.com/in/harshdarji23/" rel="noopener  ugc nofollow" target="_blank"><div class="ni ab fo"><div class="nj ab nk cl cj nl"><h2 class="bd iu gy z fp nm fr fs nn fu fw is bi translated">Harsh Darji -特约撰稿人- Medium | LinkedIn</h2><div class="no l"><h3 class="bd b gy z fp nm fr fs nn fu fw dk translated">我是一名数据科学爱好者，追求应用高级分析，建立大数据分析工具…</h3></div><div class="np l"><p class="bd b dl z fp nm fr fs nn fu fw dk translated">www.linkedin.com</p></div></div></div></a></div><p id="15e5" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">GitHub:</p><div class="ne nf gp gr ng nh"><a href="https://github.com/harshdarji23" rel="noopener  ugc nofollow" target="_blank"><div class="ni ab fo"><div class="nj ab nk cl cj nl"><h2 class="bd iu gy z fp nm fr fs nn fu fw is bi translated">harshdarji23 -概述</h2><div class="no l"><h3 class="bd b gy z fp nm fr fs nn fu fw dk translated">在 GitHub 上注册您自己的个人资料，这是托管代码、管理项目和与 40…</h3></div><div class="np l"><p class="bd b dl z fp nm fr fs nn fu fw dk translated">github.com</p></div></div><div class="nq l"><div class="nr l ns nt nu nq nv lk nh"/></div></div></a></div></div></div>    
</body>
</html>