<html>
<head>
<title>Custom Object Detection using TensorFlow from Scratch</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">从头开始使用 TensorFlow 进行自定义对象检测</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/custom-object-detection-using-tensorflow-from-scratch-e61da2e10087?source=collection_archive---------0-----------------------#2019-05-28">https://towardsdatascience.com/custom-object-detection-using-tensorflow-from-scratch-e61da2e10087?source=collection_archive---------0-----------------------#2019-05-28</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><h2 id="335a" class="ir is it bd b dl iu iv iw ix iy iz dk ja translated" aria-label="kicker paragraph"><a class="ae ep" href="https://medium.com/towards-data-science/inside-ai/home" rel="noopener">内部 AI </a></h2><div class=""/><div class=""><h2 id="6c4b" class="pw-subtitle-paragraph jz jc it bd b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq dk translated">基于自定义数据集的 TensorFlow 对象检测训练</h2></div><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi kr"><img src="../Images/e4a02498e2dd22c2fe0b20b4d78eb23f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/1*VBUJnaBvkBtsJzcNPeoeeg.gif"/></div></div><figcaption class="ld le gj gh gi lf lg bd b be z dk">Custom Object Detection source: <a class="ae lh" href="https://github.com/bourdakos1/Custom-Object-Detection" rel="noopener ugc nofollow" target="_blank">https://github.com/bourdakos1/Custom-Object-Detection</a></figcaption></figure><p id="a8e4" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">在本教程中，我们将尝试使用预先训练好的 SSD MobileNet V2 模型来训练我们自己的狗(corgi)检测器。</p><p id="d12b" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">您无需从头开始训练自己的模型，而是可以在现有模型的基础上进行构建，并根据自己的目的对其进行微调，而不需要太多的计算能力。</p><h1 id="aba1" class="me mf it bd mg mh mi mj mk ml mm mn mo ki mp kj mq kl mr km ms ko mt kp mu mv bi translated">1.装置</h1><h1 id="face" class="me mf it bd mg mh mi mj mk ml mm mn mo ki mp kj mq kl mr km ms ko mt kp mu mv bi translated">1.1 张量流</h1><p id="df5e" class="pw-post-body-paragraph li lj it lk b ll mw kd ln lo mx kg lq lr my lt lu lv mz lx ly lz na mb mc md im bi translated">使用以下命令安装 Tensorflow:</p><p id="c44a" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated"><code class="fe nb nc nd ne b">$ pip install tensorflow</code></p><p id="b353" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">如果您有可以与 Tensorflow 一起使用的 GPU:</p><p id="f297" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated"><code class="fe nb nc nd ne b">$ pip install tensorflow-gpu</code></p><h1 id="f0f3" class="me mf it bd mg mh mi mj mk ml mm mn mo ki mp kj mq kl mr km ms ko mt kp mu mv bi translated">1.2 其他依赖关系</h1><p id="a22f" class="pw-post-body-paragraph li lj it lk b ll mw kd ln lo mx kg lq lr my lt lu lv mz lx ly lz na mb mc md im bi translated"><code class="fe nb nc nd ne b">$ pip install pillow Cython lxml jupyter matplotlib</code></p><p id="b8c6" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">使用自制软件安装 protobuf(你可以在这里了解更多关于自制软件的信息)</p><p id="976e" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated"><code class="fe nb nc nd ne b">$ brew install protobuf</code></p><p id="15f5" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">对于在其他操作系统上安装 protobuf，请遵循此处的说明<a class="ae lh" href="http://google.github.io/proto-lens/installing-protoc.html" rel="noopener ugc nofollow" target="_blank">。</a></p><h1 id="f6b6" class="me mf it bd mg mh mi mj mk ml mm mn mo ki mp kj mq kl mr km ms ko mt kp mu mv bi translated">1.3 克隆 Tensorflow 模型库</h1><p id="0c33" class="pw-post-body-paragraph li lj it lk b ll mw kd ln lo mx kg lq lr my lt lu lv mz lx ly lz na mb mc md im bi translated">在本教程中，我们将使用 Tensorflow 模型存储库中的资源。因为 Tensorflow 安装没有附带它，所以我们需要从他们的 Github repo 中克隆它:</p><p id="6ffc" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">首先进入张量流目录:</p><pre class="ks kt ku kv gt nf ne ng nh aw ni bi"><span id="f5d3" class="nj mf it ne b gy nk nl l nm nn"># <em class="no">For example: ~/anaconda/envs/&lt;your_env_name&gt;/lib/python3.6/site-packages/tensorflow</em></span><span id="934f" class="nj mf it ne b gy np nl l nm nn">$ cd &lt;path_to_your_tensorflow_installation&gt;</span></pre><p id="171c" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">克隆 Tensorflow 模型库:</p><p id="c363" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated"><code class="fe nb nc nd ne b">$ git clone <a class="ae lh" href="https://github.com/tensorflow/models.git" rel="noopener ugc nofollow" target="_blank">https://github.com/tensorflow/models.git</a></code></p><p id="8cb7" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated"><strong class="lk jd">从此时起，该目录将被称为</strong> <code class="fe nb nc nd ne b"><strong class="lk jd">models</strong></code> <strong class="lk jd">目录</strong></p><h1 id="eaf8" class="me mf it bd mg mh mi mj mk ml mm mn mo ki mp kj mq kl mr km ms ko mt kp mu mv bi translated">1.4 设置环境</h1><p id="afe6" class="pw-post-body-paragraph li lj it lk b ll mw kd ln lo mx kg lq lr my lt lu lv mz lx ly lz na mb mc md im bi translated">每当您启动一个新的终端窗口来处理预训练的模型时，编译 Protobuf 并更改您的<code class="fe nb nc nd ne b">PYTHONPATH</code>是非常重要的。</p><p id="e8d4" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">从终端运行以下命令:</p><pre class="ks kt ku kv gt nf ne ng nh aw ni bi"><span id="8d85" class="nj mf it ne b gy nk nl l nm nn">$ cd &lt;path_to_your_tensorflow_installation&gt;/models/research/</span><span id="3ba2" class="nj mf it ne b gy np nl l nm nn">$ protoc object_detection/protos/*.proto --python_out=.</span><span id="13b6" class="nj mf it ne b gy np nl l nm nn">$ export PYTHONPATH=$PYTHONPATH:`pwd`:`pwd`/slim</span></pre><p id="753e" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">运行快速测试以确认对象检测 API 工作正常:</p><p id="4267" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated"><code class="fe nb nc nd ne b">$ python object_detection/builders/model_builder_test.py</code></p><p id="2938" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">如果结果如下所示，您就可以继续下一步了！</p><pre class="ks kt ku kv gt nf ne ng nh aw ni bi"><span id="bab7" class="nj mf it ne b gy nk nl l nm nn">...............<br/>----------------------------------------------------------------------<br/>Ran 15 tests in 0.123s</span><span id="599c" class="nj mf it ne b gy np nl l nm nn">OK</span></pre><h1 id="5b56" class="me mf it bd mg mh mi mj mk ml mm mn mo ki mp kj mq kl mr km ms ko mt kp mu mv bi translated">1.5 推荐的文件夹结构</h1><p id="a0db" class="pw-post-body-paragraph li lj it lk b ll mw kd ln lo mx kg lq lr my lt lu lv mz lx ly lz na mb mc md im bi translated">为了使本教程更容易理解，在刚刚克隆的<code class="fe nb nc nd ne b">models</code>目录中创建以下文件夹结构:</p><pre class="ks kt ku kv gt nf ne ng nh aw ni bi"><span id="7a01" class="nj mf it ne b gy nk nl l nm nn">models <br/>    ├── annotations<br/>    |   └── xmls    <br/>    ├── images<br/>    ├── checkpoints<br/>    ├── tf_record<br/>    ├── research<br/>    ...</span></pre><p id="60b8" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">这些文件夹将用于存储我们的模型所需的组件。</p><h1 id="9f96" class="me mf it bd mg mh mi mj mk ml mm mn mo ki mp kj mq kl mr km ms ko mt kp mu mv bi translated">2.收集图像</h1><p id="f721" class="pw-post-body-paragraph li lj it lk b ll mw kd ln lo mx kg lq lr my lt lu lv mz lx ly lz na mb mc md im bi translated">您可以收集图像或视频格式的数据。这里我提到了收集数据的两种方法。</p><h1 id="229a" class="me mf it bd mg mh mi mj mk ml mm mn mo ki mp kj mq kl mr km ms ko mt kp mu mv bi translated">2.1 从互联网上收集图像(谷歌搜索)</h1><p id="b93e" class="pw-post-body-paragraph li lj it lk b ll mw kd ln lo mx kg lq lr my lt lu lv mz lx ly lz na mb mc md im bi translated">数据准备是训练自己模型最重要的部分。既然要训练一只柯基探测器，就必须收集柯基的图片！大约 200 个就足够了。</p><p id="32cd" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">我推荐使用<a class="ae lh" href="https://github.com/hardikvasa/google-images-download" rel="noopener ugc nofollow" target="_blank"> google-images-download </a>下载图片。它搜索谷歌图片，然后根据你提供的输入下载图片。在输入中，您可以指定搜索参数，如关键字、图像数量、图像格式、图像大小和使用权。</p><p id="e4e2" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">因为我们一次下载 100 多张图片，所以我们需要在<code class="fe nb nc nd ne b">models</code>目录中有一个<code class="fe nb nc nd ne b">chromedriver</code>(在这里下载<a class="ae lh" href="https://sites.google.com/a/chromium.org/chromedriver/downloads" rel="noopener ugc nofollow" target="_blank"/>)。一旦您准备好了<code class="fe nb nc nd ne b">chromedriver</code>，您就可以使用这个示例命令来下载图像。<strong class="lk jd">确保您所有的图像都是 jpg 格式</strong>:</p><pre class="ks kt ku kv gt nf ne ng nh aw ni bi"><span id="e10c" class="nj mf it ne b gy nk nl l nm nn"><em class="no"># From the models directory</em></span><span id="e34d" class="nj mf it ne b gy np nl l nm nn">$ googleimagesdownload --keywords 'welsh corgi dog' \<br/>--limit 200 \<br/>--size medium \<br/>--chromedriver ./chromedriver \<br/>--format jpg</span></pre><p id="2566" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">下载后，将所有图像保存到<code class="fe nb nc nd ne b">models/images/</code>。为了使后续过程更容易，让我们通过运行以下脚本将图像重命名为数字(例如<code class="fe nb nc nd ne b">1.jpg</code>、<code class="fe nb nc nd ne b">2.jpg</code>):</p><pre class="ks kt ku kv gt nf ne ng nh aw ni bi"><span id="8f57" class="nj mf it ne b gy nk nl l nm nn">import os</span><span id="2e43" class="nj mf it ne b gy np nl l nm nn">path = 'models/images/'<br/>counter = 1<br/>for f in os.listdir(path):<br/>    suffix = f.split('.')[-1]<br/>    if suffix == 'jpg' or suffix == 'png':<br/>        new = '{}.{}'.format(str(counter), suffix)<br/>        os.rename(path + f, path + new)<br/>        counter = int(counter) + 1</span></pre><h1 id="385c" class="me mf it bd mg mh mi mj mk ml mm mn mo ki mp kj mq kl mr km ms ko mt kp mu mv bi translated">2.2 从视频中收集图像</h1><div class="nq nr gp gr ns nt"><a href="https://medium.com/@iKhushPatel/convert-video-to-images-images-to-video-using-opencv-python-db27a128a481" rel="noopener follow" target="_blank"><div class="nu ab fo"><div class="nv ab nw cl cj nx"><h2 class="bd jd gy z fp ny fr fs nz fu fw jc bi translated">使用 OpenCV (Python)将视频转换为图像以及将图像转换为视频</h2><div class="oa l"><h3 class="bd b gy z fp ny fr fs nz fu fw dk translated">使用 Python 中的 OpenCV 库从视频生成图像(帧)和从图像(帧)生成视频</h3></div><div class="ob l"><p class="bd b dl z fp ny fr fs nz fu fw dk translated">medium.com</p></div></div><div class="oc l"><div class="od l oe of og oc oh lb nt"/></div></div></a></div><h1 id="10ce" class="me mf it bd mg mh mi mj mk ml mm mn mo ki mp kj mq kl mr km ms ko mt kp mu mv bi translated">3.标记您的数据集</h1><p id="f8ac" class="pw-post-body-paragraph li lj it lk b ll mw kd ln lo mx kg lq lr my lt lu lv mz lx ly lz na mb mc md im bi translated">一旦你收集了所有你需要的图片，你需要手动标记它们。有许多服务于此目的的软件包。标签是一个受欢迎的选择。</p><p id="756c" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">labelImg 提供了一个用户友好的 GUI。另外，它以流行的 Pascal VOC 格式保存标签文件(<code class="fe nb nc nd ne b">.xml</code>)。如果你想用这些图片来训练 YOLO(你只看一次)，那就用 YOLO。只需设置当前目录，并按照我们的结构保存目录。</p><p id="0a12" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">以下是标签图像在 labelImg 中的样子:</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi oi"><img src="../Images/0b803074bbb195ef25478b5f38ad837d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*S-GsFf5z_B10vox5swoBuw.png"/></div></div><figcaption class="ld le gj gh gi lf lg bd b be z dk">Example of a labeled corgi in labelImg</figcaption></figure><p id="bc16" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">仔细检查每个图像是否有相应的<code class="fe nb nc nd ne b">.xml</code>文件，并将其保存在<code class="fe nb nc nd ne b">models/annotations/xmls/</code>中。</p><p id="7d2b" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">对于大量注释，您可以使用下面提到的不同快捷键:</p><pre class="ks kt ku kv gt nf ne ng nh aw ni bi"><span id="9492" class="nj mf it ne b gy nk nl l nm nn">Ctrl + u - Load all of the images from a directory<br/>Ctrl + r - Change the default annotation target dir<br/>Ctrl + s - Save<br/>w - Create a rect box<br/>d - Next image<br/>a - Previous image<br/>del - Delete the selected rect box<br/>Ctrl++ - Zoom in<br/>Ctrl-- - Zoom out<br/>Ctrl + d - Copy the current label and rect box<br/>Space - Flag the current image as verified<br/>↑→↓←Keyboard arrows to move selected rect box</span></pre><h1 id="7750" class="me mf it bd mg mh mi mj mk ml mm mn mo ki mp kj mq kl mr km ms ko mt kp mu mv bi translated">4.创建标签地图(<code class="fe nb nc nd ne b">.pbtxt</code>)</h1><p id="afb4" class="pw-post-body-paragraph li lj it lk b ll mw kd ln lo mx kg lq lr my lt lu lv mz lx ly lz na mb mc md im bi translated">类别需要在标签映射中列出。由于我们只检测地理信息系统，标签地图应该只包含一个项目，如下所示:</p><pre class="ks kt ku kv gt nf ne ng nh aw ni bi"><span id="52cd" class="nj mf it ne b gy nk nl l nm nn">item {<br/>    id: 1<br/>    name: 'corgi'<br/>}</span></pre><p id="3d63" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">注意<code class="fe nb nc nd ne b">id</code>必须从 1 开始，因为 0 是保留 id。</p><p id="b500" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">将该文件另存为<code class="fe nb nc nd ne b">models/annotations/</code>中的<code class="fe nb nc nd ne b">label_map.pbtxt</code></p><h1 id="bc7b" class="me mf it bd mg mh mi mj mk ml mm mn mo ki mp kj mq kl mr km ms ko mt kp mu mv bi translated">5.创建<code class="fe nb nc nd ne b">trainval.txt</code></h1><p id="bdaa" class="pw-post-body-paragraph li lj it lk b ll mw kd ln lo mx kg lq lr my lt lu lv mz lx ly lz na mb mc md im bi translated"><code class="fe nb nc nd ne b">trainval.txt</code>是没有文件扩展名的图像名称列表。因为我们有图像名称的序列号，所以列表应该是这样的:</p><pre class="ks kt ku kv gt nf ne ng nh aw ni bi"><span id="21cf" class="nj mf it ne b gy nk nl l nm nn">1<br/>2<br/>3<br/>...<br/>198<br/>199<br/>200</span></pre><p id="cfba" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">将该文件保存为<code class="fe nb nc nd ne b">models/annotations/</code>中的<code class="fe nb nc nd ne b">trainval.txt</code></p><h1 id="79ae" class="me mf it bd mg mh mi mj mk ml mm mn mo ki mp kj mq kl mr km ms ko mt kp mu mv bi translated">6.将 XML 转换为 CSV 文件(<code class="fe nb nc nd ne b">.csv</code>)</h1><p id="afd0" class="pw-post-body-paragraph li lj it lk b ll mw kd ln lo mx kg lq lr my lt lu lv mz lx ly lz na mb mc md im bi translated">您可以使用这个<a class="ae lh" href="https://gist.github.com/iKhushPatel/ed1f837656b155d9b94d45b42e00f5e4" rel="noopener ugc nofollow" target="_blank">链接</a>来创建 CSV 格式的 XML 文件。我们有所有的图像和它们的边界框都是 XML 格式。此外，所有的图像都有单独的 XML 文件，所以使用这个代码，我们正在创建一个 CSV 文件，其中包含所有的 XML 文件和他们的边界框坐标到一个 CSV 文件，这是创建 TFrecords 的输入。</p><h1 id="3943" class="me mf it bd mg mh mi mj mk ml mm mn mo ki mp kj mq kl mr km ms ko mt kp mu mv bi translated">7.创建 TFRecord ( <code class="fe nb nc nd ne b">.record</code>)</h1><p id="81b9" class="pw-post-body-paragraph li lj it lk b ll mw kd ln lo mx kg lq lr my lt lu lv mz lx ly lz na mb mc md im bi translated">TFRecord 是为 Tensorflow 设计的重要数据格式。(点击了解更多信息<a class="ae lh" href="https://www.skcript.com/svr/why-every-tensorflow-developer-should-know-about-tfrecord/" rel="noopener ugc nofollow" target="_blank">)。在训练自定义对象检测器之前，必须将数据转换为 TFRecord 格式。</a></p><p id="9450" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">由于我们需要训练和验证我们的模型，数据集将被分成训练集(<code class="fe nb nc nd ne b">train.record</code>)和验证集(<code class="fe nb nc nd ne b">val.record</code>)。训练集的目的很简单——它是模型学习的样本集。验证集是在训练期间使用的一组示例，用于反复评估模型准确性。</p><p id="f45d" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">我们将使用<code class="fe nb nc nd ne b">create_tf_record.py</code>将我们的数据集转换成<code class="fe nb nc nd ne b">train.record</code>和<code class="fe nb nc nd ne b">val.record</code>。在这里下载<a class="ae lh" href="https://gist.github.com/iKhushPatel/5614a36f26cf6459cc49c8248e8b5b48" rel="noopener ugc nofollow" target="_blank">并保存到<code class="fe nb nc nd ne b">models/research/object_detection/dataset_tools/</code>。</a></p><p id="a5f2" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated"><strong class="lk jd">根据您的分类，只需更改</strong> <code class="fe nb nc nd ne b">if row_label == ‘Label1’:</code> <strong class="lk jd">中的标签名称即可。</strong></p><p id="b6e2" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">该脚本预先配置为进行 70–30 列车阀分割。通过运行以下命令来执行它:</p><pre class="ks kt ku kv gt nf ne ng nh aw ni bi"><span id="9d80" class="nj mf it ne b gy nk nl l nm nn"># <em class="no">From the models directory</em></span><span id="9401" class="nj mf it ne b gy np nl l nm nn">$ python research/object_detection/dataset_tools/create_tf_record.py</span></pre><p id="6bf8" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">如果脚本执行成功，<code class="fe nb nc nd ne b">train.record</code>和<code class="fe nb nc nd ne b">val.record</code>应该会出现在您的<code class="fe nb nc nd ne b">models/research/</code>目录中。将它们移动到<code class="fe nb nc nd ne b">models/tf_record/</code>目录。</p><h1 id="a130" class="me mf it bd mg mh mi mj mk ml mm mn mo ki mp kj mq kl mr km ms ko mt kp mu mv bi translated">8.下载预先训练的模型</h1><p id="48e3" class="pw-post-body-paragraph li lj it lk b ll mw kd ln lo mx kg lq lr my lt lu lv mz lx ly lz na mb mc md im bi translated">在<a class="ae lh" href="https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/detection_model_zoo.md" rel="noopener ugc nofollow" target="_blank">模型动物园</a>中有很多预先训练好的物体检测模型可用。为了使用我们的定制数据集训练它们，模型需要使用它们的检查点(<code class="fe nb nc nd ne b">.ckpt</code>文件)在 Tensorflow 中<em class="no">恢复</em>，这些检查点是以前模型状态的记录。</p><p id="fbab" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">对于本教程，我们将在这里下载<code class="fe nb nc nd ne b">ssd_mobilenet_v2_coco</code><a class="ae lh" href="http://download.tensorflow.org/models/object_detection/ssd_mobilenet_v2_coco_2018_03_29.tar.gz" rel="noopener ugc nofollow" target="_blank"/>，并将其模型检查点文件(<code class="fe nb nc nd ne b">model.ckpt.meta, model.ckpt.index, model.ckpt.data-00000-of-00001</code>)保存到我们的<code class="fe nb nc nd ne b">models/checkpoints/</code>目录中。</p><h1 id="2b2f" class="me mf it bd mg mh mi mj mk ml mm mn mo ki mp kj mq kl mr km ms ko mt kp mu mv bi translated">9.修改配置(<code class="fe nb nc nd ne b">.config</code>)文件</h1><p id="9ce3" class="pw-post-body-paragraph li lj it lk b ll mw kd ln lo mx kg lq lr my lt lu lv mz lx ly lz na mb mc md im bi translated">每个预训练的模型都有一个包含模型细节的配置文件。为了检测我们的自定义类，需要相应地修改配置文件。</p><p id="2140" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">配置文件包含在您一开始克隆的<code class="fe nb nc nd ne b">models</code>目录中。您可以在以下位置找到它们:</p><p id="0bab" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated"><code class="fe nb nc nd ne b">models/research/object_detection/samples/configs</code></p><p id="7d81" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">在我们的例子中，我们将修改<code class="fe nb nc nd ne b">ssd_mobilenet_v2_coco</code>的配置文件。先复制一份，保存在<code class="fe nb nc nd ne b">models/</code>目录下。</p><p id="3134" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">以下是我们需要更改的项目:</p><ol class=""><li id="4b5a" class="oj ok it lk b ll lm lo lp lr ol lv om lz on md oo op oq or bi translated">因为我们只试图检测柯基，所以将<code class="fe nb nc nd ne b">num_classes</code>改为 1</li><li id="2ddc" class="oj ok it lk b ll os lo ot lr ou lv ov lz ow md oo op oq or bi translated"><code class="fe nb nc nd ne b">fine_tune_checkpoint</code>告诉模型使用哪个检查点文件。将此设置为<code class="fe nb nc nd ne b">checkpoints/model.ckpt</code></li><li id="9c22" class="oj ok it lk b ll os lo ot lr ou lv ov lz ow md oo op oq or bi translated">模型还需要知道训练集和验证集的 TFRecord 文件和标签映射在哪里。由于我们的<code class="fe nb nc nd ne b">train.record</code>和<code class="fe nb nc nd ne b">val.record</code>保存在<code class="fe nb nc nd ne b">tf_record</code>文件夹中，我们的配置应该反映出:</li></ol><pre class="ks kt ku kv gt nf ne ng nh aw ni bi"><span id="a2e1" class="nj mf it ne b gy nk nl l nm nn">train_input_reader: {<br/>  tf_record_input_reader {<br/>    input_path: "tf_record/train.record"<br/>  }<br/>  label_map_path: "annotations/label_map.pbtxt"<br/>}</span><span id="deee" class="nj mf it ne b gy np nl l nm nn">eval_input_reader: {<br/>  tf_record_input_reader {<br/>    input_path: "tf_record/val.record"<br/>  }<br/>  label_map_path: "annotations/label_map.pbtxt"<br/>  shuffle: false<br/>  num_readers: 1<br/>}</span></pre><h1 id="c7c1" class="me mf it bd mg mh mi mj mk ml mm mn mo ki mp kj mq kl mr km ms ko mt kp mu mv bi translated">10.火车</h1><p id="edd3" class="pw-post-body-paragraph li lj it lk b ll mw kd ln lo mx kg lq lr my lt lu lv mz lx ly lz na mb mc md im bi translated">此时，您的<code class="fe nb nc nd ne b">models</code>目录应该如下所示:</p><pre class="ks kt ku kv gt nf ne ng nh aw ni bi"><span id="65cc" class="nj mf it ne b gy nk nl l nm nn">models <br/>    ├── annotations<br/>    |   ├── label_map.pbtxt<br/>    |   ├── trainval.txt<br/>    |   └── xmls<br/>    |       ├── 1.xml<br/>    |       ├── 2.xml<br/>    |       ├── ...<br/>    |<br/>    ├── images<br/>    |   ├── 1.jpg<br/>    |   ├── 2.jpg<br/>    |   ├── ...    <br/>    |<br/>    ├── checkpoints<br/>    |   ├── model.ckpt.data-00000-of-00001<br/>    |   ├── model.ckpt.index<br/>    |   └── model.ckpt.meta<br/>    |<br/>    ├── tf_record<br/>    |   ├── train.record<br/>    |   └── val.record<br/>    |<br/>    ├── research<br/>    |   ├── ...<br/>    ...</span></pre><p id="bfbb" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">如果您成功完成了之前的所有步骤，您就可以开始训练了！</p><p id="ca3d" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">请遵循以下步骤:</p><pre class="ks kt ku kv gt nf ne ng nh aw ni bi"><span id="314b" class="nj mf it ne b gy nk nl l nm nn"># <em class="no">Change into the models directory</em><br/>$ cd tensorflow/models</span><span id="d8a2" class="nj mf it ne b gy np nl l nm nn"># <em class="no">Make directory for storing training progress</em><br/>$ mkdir train</span><span id="118e" class="nj mf it ne b gy np nl l nm nn"># <em class="no">Make directory for storing validation results</em><br/>$ mkdir eval</span><span id="cebf" class="nj mf it ne b gy np nl l nm nn"># <em class="no">Begin training</em><br/>$ python research/object_detection/train.py \<br/>    --logtostderr \<br/>    --train_dir=train \<br/>    --pipeline_config_path=ssd_mobilenet_v2_coco.config</span></pre><p id="4b78" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">训练时间因机器的计算能力而异。</p><h1 id="485c" class="me mf it bd mg mh mi mj mk ml mm mn mo ki mp kj mq kl mr km ms ko mt kp mu mv bi translated">11.估价</h1><p id="3d39" class="pw-post-body-paragraph li lj it lk b ll mw kd ln lo mx kg lq lr my lt lu lv mz lx ly lz na mb mc md im bi translated">评估可以与培训同时进行。<code class="fe nb nc nd ne b">eval.py</code>脚本检查<code class="fe nb nc nd ne b">train</code>目录的进度，并根据最近的检查点评估模型。</p><pre class="ks kt ku kv gt nf ne ng nh aw ni bi"><span id="e0ef" class="nj mf it ne b gy nk nl l nm nn"><em class="no"># From the models directory</em></span><span id="a979" class="nj mf it ne b gy np nl l nm nn">$ python research/object_detection/eval.py \<br/>    --logtostderr \<br/>    --pipeline_config_path=ssd_mobilenet_v2_coco.config \<br/>    --checkpoint_dir=train \<br/>    --eval_dir=eval</span></pre><p id="c155" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">您可以使用 Tensorboard 可视化模型训练进度:</p><pre class="ks kt ku kv gt nf ne ng nh aw ni bi"><span id="ecc5" class="nj mf it ne b gy nk nl l nm nn"><em class="no"># From the models directory</em></span><span id="f9b6" class="nj mf it ne b gy np nl l nm nn">$ tensorboard --logdir=./</span></pre><p id="1f82" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">根据 Tensorboard 输出的图表，您可以决定何时停止训练。通常，当损失函数逐渐减少并且不再显著减少时，你可以停止这个过程。在我的例子中，我停止在步骤 3258。</p><h1 id="ac85" class="me mf it bd mg mh mi mj mk ml mm mn mo ki mp kj mq kl mr km ms ko mt kp mu mv bi translated">12.模型导出</h1><p id="8e1a" class="pw-post-body-paragraph li lj it lk b ll mw kd ln lo mx kg lq lr my lt lu lv mz lx ly lz na mb mc md im bi translated">一旦完成模型的训练，就可以导出模型用于推理。如果您一直遵循文件夹结构，请使用以下命令:</p><pre class="ks kt ku kv gt nf ne ng nh aw ni bi"><span id="29e7" class="nj mf it ne b gy nk nl l nm nn"><em class="no"># From the models directory</em></span><span id="640e" class="nj mf it ne b gy np nl l nm nn">$ mkdir fine_tuned_model</span><span id="9689" class="nj mf it ne b gy np nl l nm nn">$ python research/object_detection/export_inference_graph.py \    <br/>--input_type image_tensor \    <br/>--pipeline_config_path ssd_mobilenet_v2_coco.config \    <br/>--trained_checkpoint_prefix  train/model.ckpt-&lt;the_highest_checkpoint_number&gt; \    <br/>--output_directory fine_tuned_model</span></pre><h1 id="f79d" class="me mf it bd mg mh mi mj mk ml mm mn mo ki mp kj mq kl mr km ms ko mt kp mu mv bi translated">13.分类图像</h1><p id="0617" class="pw-post-body-paragraph li lj it lk b ll mw kd ln lo mx kg lq lr my lt lu lv mz lx ly lz na mb mc md im bi translated">现在你有了一个模型，你可以用它来检测图片和视频中的柯基犬！出于演示的目的，我们将检测图像中的 CORBA。在继续之前，选择一个您想要用来测试模型的图像。</p><p id="e811" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated"><code class="fe nb nc nd ne b">models</code>目录附带了一个笔记本文件(<code class="fe nb nc nd ne b">.ipynb</code>)，我们可以使用它进行一些调整来获得推论。它位于<code class="fe nb nc nd ne b">models/research/object_detection/object_detection_tutorial.ipynb</code>。按照以下步骤调整笔记本:</p><ol class=""><li id="e9c9" class="oj ok it lk b ll lm lo lp lr ol lv om lz on md oo op oq or bi translated"><code class="fe nb nc nd ne b">MODEL_NAME = 'ssd_mobilenet_v2_coco_2018_03_29'</code></li><li id="3aee" class="oj ok it lk b ll os lo ot lr ou lv ov lz ow md oo op oq or bi translated"><code class="fe nb nc nd ne b">PATH_TO_CKPT = 'path/to/your/frozen_inference_graph.pb'</code></li><li id="a2d4" class="oj ok it lk b ll os lo ot lr ou lv ov lz ow md oo op oq or bi translated"><code class="fe nb nc nd ne b">PATH_TO_LABELS = 'models/annotations/label_map.pbtxt'</code></li><li id="5c13" class="oj ok it lk b ll os lo ot lr ou lv ov lz ow md oo op oq or bi translated"><code class="fe nb nc nd ne b">NUM_CLASSES = 1</code></li><li id="f47c" class="oj ok it lk b ll os lo ot lr ou lv ov lz ow md oo op oq or bi translated">完全注释掉单元格#5(就在<code class="fe nb nc nd ne b">Download Model</code>下面)</li><li id="6113" class="oj ok it lk b ll os lo ot lr ou lv ov lz ow md oo op oq or bi translated">因为我们只对一个图像进行测试，注释掉单元格#9 中的<code class="fe nb nc nd ne b">PATH_TO_TEST_IMAGES_DIR</code>和<code class="fe nb nc nd ne b">TEST_IMAGE_PATHS</code>(就在<code class="fe nb nc nd ne b">Detection</code>下面)</li><li id="6540" class="oj ok it lk b ll os lo ot lr ou lv ov lz ow md oo op oq or bi translated">在单元格#11(最后一个单元格)中，删除 for 循环，取消其内容，并添加测试图像的路径:</li></ol><p id="f6b8" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated"><code class="fe nb nc nd ne b">imagepath = 'path/to/image_you_want_to_test.jpg</code></p><p id="f485" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">完成这些步骤后，运行笔记本，您应该会看到测试图像中的 corgi 被一个边界框高亮显示！</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi ox"><img src="../Images/b6a4c1658bcee055fb1f4e0d3e4525d9.png" data-original-src="https://miro.medium.com/v2/resize:fit:956/format:webp/1*r9ROLF7LsGM6rW-s3HOqMQ.png"/></div><figcaption class="ld le gj gh gi lf lg bd b be z dk">Corgi found by our custom object detector</figcaption></figure><p id="4fab" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">那里你有你的自定义柯基探测器！</p><blockquote class="oy oz pa"><p id="39a1" class="li lj no lk b ll lm kd ln lo lp kg lq pb ls lt lu pc lw lx ly pd ma mb mc md im bi translated"><strong class="lk jd">你可能想知道，在训练完你的第一个模型后，我想改进我的模型并跟踪我的实验细节，什么是好工具？</strong></p></blockquote><p id="32ae" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">然后就可以结账<a class="ae lh" href="https://neptune.ai/" rel="noopener ugc nofollow" target="_blank"> https://neptune.ai </a>了，它提供了清晰简洁的模型追踪。您可以跟踪所有的超参数，并将模型保存在模型注册表中，并实时比较您的模型。Neptune 支持在一个地方记录、存储、查询、显示、组织和比较所有的模型元数据。更多信息，你可以参考下面的博客来训练物体检测模型。</p><p id="abe7" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated"><a class="ae lh" href="https://neptune.ai/blog/tensorflow-object-detection-api-best-practices-to-training-evaluation-deployment" rel="noopener ugc nofollow" target="_blank">https://Neptune . ai/blog/tensor flow-object-detection-API-最佳实践-培训-评估-部署</a></p><h1 id="2ee0" class="me mf it bd mg mh mi mj mk ml mm mn mo ki mp kj mq kl mr km ms ko mt kp mu mv bi translated">更多细节</h1><p id="c6a7" class="pw-post-body-paragraph li lj it lk b ll mw kd ln lo mx kg lq lr my lt lu lv mz lx ly lz na mb mc md im bi translated"><a class="ae lh" href="https://github.com/tensorflow/models/tree/master/research/object_detection/g3doc" rel="noopener ugc nofollow" target="_blank"> Tensorflow 对象检测模型文档</a></p></div><div class="ab cl pe pf hx pg" role="separator"><span class="ph bw bk pi pj pk"/><span class="ph bw bk pi pj pk"/><span class="ph bw bk pi pj"/></div><div class="im in io ip iq"><p id="e244" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">请访问我的网站:【http://www.khushpatel.com】<strong class="lk jd"><em class="no"/></strong></p></div></div>    
</body>
</html>