<html>
<head>
<title>Checklist for debugging neural networks</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">调试神经网络的清单</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/checklist-for-debugging-neural-networks-d8b2a9434f21?source=collection_archive---------2-----------------------#2019-03-14">https://towardsdatascience.com/checklist-for-debugging-neural-networks-d8b2a9434f21?source=collection_archive---------2-----------------------#2019-03-14</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="d6ee" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">您可以采取切实可行的步骤来识别和解决机器学习模型的训练、泛化和优化问题</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/e5e4aaf8e7851ca5ba655bcc9b121cb9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*e7O7A5rM79ng6b8Dc3EbEg.jpeg"/></div></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk">Photo by <a class="ae kv" href="https://unsplash.com/photos/RLw-UC03Gwc?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank">Glenn Carstens-Peters</a> on <a class="ae kv" href="https://unsplash.com/search/photos/list?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><p id="f728" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">众所周知，机器学习代码很难调试，因为寻找错误的代价很高。即使对于简单的<a class="ae kv" href="https://cs.stanford.edu/people/eroberts/courses/soco/projects/neural-networks/Architecture/feedforward.html" rel="noopener ugc nofollow" target="_blank">前馈神经网络</a>，你也经常不得不围绕网络架构、权重初始化和网络优化做出几个决定——所有这些都可能导致你的机器学习代码中潜在的错误。</p><p id="594a" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">正如 Chase Roberts 在一篇关于“<a class="ae kv" href="https://medium.com/@keeper6928/how-to-unit-test-machine-learning-code-57cf6fd81765" rel="noopener">如何对机器学习代码</a>进行单元测试”的优秀文章中所写的那样，他的挫折源于常见的陷阱，比如:</p><ol class=""><li id="f044" class="ls lt iq ky b kz la lc ld lf lu lj lv ln lw lr lx ly lz ma bi translated">代码不会崩溃，不会引发异常，甚至不会变慢。</li><li id="1508" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr lx ly lz ma bi translated">网络仍在训练，损失仍会下降。</li><li id="92e1" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr lx ly lz ma bi translated">几个小时后，这些值收敛，但结果很差</li></ol><p id="ead2" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">那么，对此应该做些什么呢？</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi mg"><img src="../Images/6c86994b5e6f39c07d6982dcdc4a7d15.png" data-original-src="https://miro.medium.com/v2/resize:fit:908/format:webp/1*GKw0mvo1_oSpHdc9Ly1Z_g.png"/></div></figure></div><div class="ab cl mh mi hu mj" role="separator"><span class="mk bw bk ml mm mn"/><span class="mk bw bk ml mm mn"/><span class="mk bw bk ml mm"/></div><div class="ij ik il im in"><p id="76b7" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">本文将提供一个框架来帮助您调试您的神经网络:</p><ol class=""><li id="5b1e" class="ls lt iq ky b kz la lc ld lf lu lj lv ln lw lr lx ly lz ma bi translated"><strong class="ky ir">开始简单</strong></li><li id="8cf7" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr lx ly lz ma bi translated"><strong class="ky ir">确认你的损失</strong></li><li id="91a3" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr lx ly lz ma bi translated"><strong class="ky ir">检查中间输出和连接</strong></li><li id="9342" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr lx ly lz ma bi translated"><strong class="ky ir">诊断参数</strong></li><li id="967a" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr lx ly lz ma bi translated"><strong class="ky ir">跟踪你的工作</strong></li></ol><p id="a84b" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">请随意跳到特定部分或通读下面的内容！请注意:我们不涉及数据预处理或具体的模型算法选择。网上有很多关于这些主题的资源(例如，查看<a class="ae kv" href="https://hackernoon.com/choosing-the-right-machine-learning-algorithm-68126944ce1f" rel="noopener ugc nofollow" target="_blank">‘选择正确的机器学习算法’</a>)。</p><h1 id="5b50" class="mo mp iq bd mq mr ms mt mu mv mw mx my jw mz jx na jz nb ka nc kc nd kd ne nf bi translated">1.从简单开始</h1><p id="58f0" class="pw-post-body-paragraph kw kx iq ky b kz ng jr lb lc nh ju le lf ni lh li lj nj ll lm ln nk lp lq lr ij bi translated">具有带正则化和学习率调度器的复杂架构的神经网络将比简单网络更难调试。我们在第一点上有点欺骗，因为它与调试你已经建立的网络并不真正相关，但它仍然是一个重要的建议！</p><p id="a115" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">从简单开始:</p><ul class=""><li id="03d8" class="ls lt iq ky b kz la lc ld lf lu lj lv ln lw lr nm ly lz ma bi translated">首先构建一个更简单的模型</li><li id="25bf" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr nm ly lz ma bi translated">在单个数据点上训练您的模型</li></ul><h2 id="9ca9" class="nn mp iq bd mq no np dn mu nq nr dp my lf ns nt na lj nu nv nc ln nw nx ne ny bi translated"><strong class="ak">先建立一个更简单的模型</strong></h2><p id="5699" class="pw-post-body-paragraph kw kx iq ky b kz ng jr lb lc nh ju le lf ni lh li lj nj ll lm ln nk lp lq lr ij bi translated">首先，构建一个只有一个隐藏层的小型网络，并验证一切都正常工作。然后逐渐增加模型的复杂性，同时检查模型结构的每个方面(附加层、参数等)..)在继续前进之前起作用。</p><h2 id="00cf" class="nn mp iq bd mq no np dn mu nq nr dp my lf ns nt na lj nu nv nc ln nw nx ne ny bi translated">在单个数据点上训练您的模型</h2><p id="933f" class="pw-post-body-paragraph kw kx iq ky b kz ng jr lb lc nh ju le lf ni lh li lj nj ll lm ln nk lp lq lr ij bi translated">作为快速的健全性检查，您可以使用一两个训练数据点来确认您的模型是否能够过度拟合。神经网络应该立即以 100%的训练精度和与你的模型随机猜测相称的验证精度过度拟合。如果你的模型不能适应这些数据点，那么要么它太小，要么有一个错误。</p><p id="b73f" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">即使你已经验证了你的模型是有效的，在继续之前尝试训练一个(或几个)时期。</p><h1 id="7b8d" class="mo mp iq bd mq mr ms mt mu mv mw mx my jw mz jx na jz nb ka nc kc nd kd ne nf bi translated">2.确认你的损失</h1><p id="d8c5" class="pw-post-body-paragraph kw kx iq ky b kz ng jr lb lc nh ju le lf ni lh li lj nj ll lm ln nk lp lq lr ij bi translated">模型的损失是评估模型性能的主要方式，也是模型评估以设置重要参数的内容，因此您需要确保:</p><ul class=""><li id="8e59" class="ls lt iq ky b kz la lc ld lf lu lj lv ln lw lr nm ly lz ma bi translated">损失适合于任务(对于多分类问题使用类别交叉熵损失，或者使用焦点损失来解决类别不平衡)</li><li id="0463" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr nm ly lz ma bi translated">你的<a class="ae kv" href="https://blog.algorithmia.com/introduction-to-loss-functions/" rel="noopener ugc nofollow" target="_blank">损失函数</a>正在正确的尺度上被测量。如果您在网络中使用了一种以上的损失类型，如 MSE、对抗性、L1、<a class="ae kv" href="https://arxiv.org/pdf/1603.08155.pdf" rel="noopener ugc nofollow" target="_blank">特征损失</a>，那么请确保所有损失都被适当地缩放到相同的数量级</li></ul><p id="5381" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">注意你最初的损失也很重要。如果你的模型是通过随机猜测开始的，检查初始损失是否接近你的预期损失。在<a class="ae kv" href="http://cs231n.github.io/neural-networks-3/#baby" rel="noopener ugc nofollow" target="_blank">的斯坦福 CS231n 课程作业</a>中，安德烈·卡帕西提出了以下建议:</p><blockquote class="nz oa ob"><p id="bb52" class="kw kx nl ky b kz la jr lb lc ld ju le oc lg lh li od lk ll lm oe lo lp lq lr ij bi translated">寻找正确的机会表现损失。当你用小参数初始化时，确保你得到了你期望的损失。最好先单独检查数据丢失(所以把正则化强度设置为零)。例如，对于具有 Softmax 分类器的 CIFAR-10，我们预计初始损失为 2.302，因为我们预计每个类别的扩散概率为 0.1(因为有 10 个类别)，Softmax 损失是正确类别的负对数概率，因此:-ln(0.1) = 2.302。</p></blockquote><p id="7b4a" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">对于一个二进制的例子，你可以简单地为你的每个类做一个相似的计算。假设您的数据中有 20%为 0，80%为 1，那么您的预期初始损耗将为 0.2 ln(0.5)0.8 ln(0.5)= 0.693147。如果您的初始损失远大于 1，这可能表明您的神经网络权重没有正确平衡(即，您的初始化很差)或您的数据没有标准化。</p><h1 id="6b55" class="mo mp iq bd mq mr ms mt mu mv mw mx my jw mz jx na jz nb ka nc kc nd kd ne nf bi translated">3.检查中间输出和连接</h1><p id="f6ea" class="pw-post-body-paragraph kw kx iq ky b kz ng jr lb lc nh ju le lf ni lh li lj nj ll lm ln nk lp lq lr ij bi translated">若要侦错类神经网路，瞭解类神经网路内部的动态、个别中间层所扮演的角色，以及各层之间的连接方式，通常会很有用。您可能会在以下方面遇到错误:</p><ul class=""><li id="3914" class="ls lt iq ky b kz la lc ld lf lu lj lv ln lw lr nm ly lz ma bi translated">梯度更新的表达式不正确</li><li id="1c4a" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr nm ly lz ma bi translated">未应用权重更新</li><li id="31b2" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr nm ly lz ma bi translated">消失或爆炸渐变</li></ul><p id="67cf" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">如果您的梯度值为零，这可能意味着优化器中的学习率太小，或者您遇到了上面的错误#1，梯度更新的表达式不正确。</p><p id="f259" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">除了查看梯度更新的绝对值之外，确保监控每个层匹配的激活、权重和更新的幅度。例如，参数(权重和偏差)<a class="ae kv" href="https://cs231n.github.io/neural-networks-3/#summary" rel="noopener ugc nofollow" target="_blank">的更新幅度应该是 1-e3 </a>。</p><p id="48e1" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">有一种现象称为“死亡 ReLU”或“消失梯度问题”,其中 ReLU 神经元在学习了其权重的大的负偏差项后将输出零。这些神经元再也不会在任何数据点激活。</p><p id="4956" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">您可以通过使用数值方法近似梯度，使用梯度检查来检查这些错误。如果它接近计算的梯度，则反向传播被正确地执行。要实现渐变检查，请查看 CS231 <a class="ae kv" href="http://cs231n.github.io/neural-networks-3/#gradcheck" rel="noopener ugc nofollow" target="_blank">这里</a>和<a class="ae kv" href="http://cs231n.github.io/optimization-1/#gradcompute" rel="noopener ugc nofollow" target="_blank">这里</a>以及吴恩达<a class="ae kv" href="https://www.youtube.com/watch?v=P6EtCVrvYPU" rel="noopener ugc nofollow" target="_blank">关于该主题的具体课程</a>中的这些伟大资源。</p><p id="5a47" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><a class="ae kv" href="https://www.linkedin.com/in/faizankshaikh/" rel="noopener ugc nofollow" target="_blank"> Faizan Shaikh </a>讲述了可视化神经网络的三种主要方法:</p><ul class=""><li id="2b6b" class="ls lt iq ky b kz la lc ld lf lu lj lv ln lw lr nm ly lz ma bi translated"><strong class="ky ir">初步方法</strong> —简单的方法，向我们展示一个训练好的模型的整体结构。这些方法包括打印出神经网络各层的形状或过滤器以及每层中的参数。</li><li id="d2bc" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr nm ly lz ma bi translated"><strong class="ky ir">基于激活的方法</strong> —在这些方法中，我们破译单个神经元或一组神经元的激活，以获得它们正在做什么的直觉</li><li id="8cae" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr nm ly lz ma bi translated"><strong class="ky ir">基于梯度的方法— </strong>这些方法倾向于在训练模型(包括显著性图和类别激活图)时操纵由正向和反向传递形成的梯度。</li></ul><p id="9949" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">有许多有用的工具用于可视化各个层的激活和连接，如<a class="ae kv" href="https://conx.readthedocs.io/en/latest/Getting%20Started%20with%20conx.html#What-is-ConX?" rel="noopener ugc nofollow" target="_blank"> ConX </a>和<a class="ae kv" href="https://www.tensorflow.org/guide/tensorboard_histograms" rel="noopener ugc nofollow" target="_blank"> Tensorboard </a>。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi of"><img src="../Images/ba76b48f475f4d02d5a3373d0d2a4a43.png" data-original-src="https://miro.medium.com/v2/resize:fit:1300/format:webp/1*6hqHPhp7Msp1_ClaTnsccQ.png"/></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk">A sample dynamic, rendered visualization made with <a class="ae kv" href="https://conx.readthedocs.io/en/latest/README.html" rel="noopener ugc nofollow" target="_blank">ConX</a></figcaption></figure><blockquote class="nz oa ob"><p id="0da3" class="kw kx nl ky b kz la jr lb lc ld ju le oc lg lh li od lk ll lm oe lo lp lq lr ij bi translated">处理图像数据？Erik Rippel 在<a class="ae kv" href="https://hackernoon.com/visualizing-parts-of-convolutional-neural-networks-using-keras-and-cats-5cc01b214e59" rel="noopener ugc nofollow" target="_blank">“使用 Keras 和 Cats 可视化部分卷积神经网络”</a>上发表了一篇精彩多彩的文章</p></blockquote><h1 id="181b" class="mo mp iq bd mq mr ms mt mu mv mw mx my jw mz jx na jz nb ka nc kc nd kd ne nf bi translated"><strong class="ak"> 4。诊断参数</strong></h1><p id="312e" class="pw-post-body-paragraph kw kx iq ky b kz ng jr lb lc nh ju le lf ni lh li lj nj ll lm ln nk lp lq lr ij bi translated">神经网络有大量相互影响的参数，使得优化变得困难。请注意，这是一个活跃的研究领域，所以下面的建议只是一个起点。</p><ul class=""><li id="09a9" class="ls lt iq ky b kz la lc ld lf lu lj lv ln lw lr nm ly lz ma bi translated"><strong class="ky ir">批量</strong>(技术上称为小批量)—您希望批量足够大，以获得准确的误差梯度估计，但又足够小，以使小批量随机梯度下降(SGD)可以调整您的网络。小批量将导致学习过程以训练过程中的噪音为代价快速收敛，并且<em class="nl">可能</em>导致优化困难。论文<a class="ae kv" href="https://arxiv.org/abs/1609.04836" rel="noopener ugc nofollow" target="_blank">‘关于深度学习的大批量训练:泛化差距和尖锐极小’</a>描述了如何:</li></ul><blockquote class="nz oa ob"><p id="690d" class="kw kx nl ky b kz la jr lb lc ld ju le oc lg lh li od lk ll lm oe lo lp lq lr ij bi translated">在实践中已经观察到，当使用较大批量时，模型的质量会下降，这通过其概括能力来衡量。我们调查了大批量模式中这种泛化能力下降的原因，并提供了支持以下观点的数字证据:l <strong class="ky ir">大批量方法倾向于收敛到训练和测试函数的尖锐极小值，众所周知，尖锐极小值导致较差的泛化能力</strong>。相比之下，小批量方法始终收敛于平坦极小值，我们的实验支持一个普遍持有的观点，即这是由于梯度估计中的固有噪声。</p></blockquote><ul class=""><li id="e64b" class="ls lt iq ky b kz la lc ld lf lu lj lv ln lw lr nm ly lz ma bi translated"><strong class="ky ir">学习率</strong>—学习率太低会导致收敛缓慢或陷入局部最小值的风险，而学习率太大会导致优化发散，因为你有跳过损失函数更深但更窄部分的风险。考虑纳入学习率计划，以随着培训的进展降低学习率。CS231n 课程有很大一部分是关于<a class="ae kv" href="http://cs231n.github.io/neural-networks-3/" rel="noopener ugc nofollow" target="_blank">实现退火学习率的不同技术</a>。</li></ul><blockquote class="nz oa ob"><p id="645b" class="kw kx nl ky b kz la jr lb lc ld ju le oc lg lh li od lk ll lm oe lo lp lq lr ij bi translated">Keras、Tensorflow、PyTorch、MXNet 等机器学习框架现在都有关于使用学习率调度器/decay 的文档或示例:</p><p id="bfb3" class="kw kx nl ky b kz la jr lb lc ld ju le oc lg lh li od lk ll lm oe lo lp lq lr ij bi translated">https://keras.io/callbacks/#learningratescheduler</p><p id="e65c" class="kw kx nl ky b kz la jr lb lc ld ju le oc lg lh li od lk ll lm oe lo lp lq lr ij bi translated">tensor flow—<a class="ae kv" href="https://www.tensorflow.org/api_docs/python/tf/train/exponential_decay" rel="noopener ugc nofollow" target="_blank">https://www . tensor flow . org/API _ docs/python/TF/train/exponential _ decay</a></p><p id="9479" class="kw kx nl ky b kz la jr lb lc ld ju le oc lg lh li od lk ll lm oe lo lp lq lr ij bi translated">py torch—<a class="ae kv" href="https://pytorch.org/docs/stable/_modules/torch/optim/lr_scheduler.html" rel="noopener ugc nofollow" target="_blank">https://py torch . org/docs/stable/_ modules/torch/optim/lr _ scheduler . html</a></p><p id="7604" class="kw kx nl ky b kz la jr lb lc ld ju le oc lg lh li od lk ll lm oe lo lp lq lr ij bi translated">MXNet—<a class="ae kv" href="https://mxnet.incubator.apache.org/versions/master/tutorials/gluon/learning_rate_schedules.html" rel="noopener ugc nofollow" target="_blank">https://MXNet . incubator . Apache . org/versions/master/tutorials/gluon/learning _ rate _ schedules . html</a></p></blockquote><ul class=""><li id="3356" class="ls lt iq ky b kz la lc ld lf lu lj lv ln lw lr nm ly lz ma bi translated"><strong class="ky ir">梯度剪辑</strong> —这将在反向传播过程中以最大值或最大范数剪辑参数的梯度。有助于解决您在上述步骤 3 中可能遇到的任何爆炸渐变</li><li id="61b0" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr nm ly lz ma bi translated"><strong class="ky ir">批量标准化</strong>—批量标准化用于标准化每一层的输入，以对抗内部协变量偏移问题。<em class="nl">如果您同时使用 Dropout 和 Batch Norma，请务必阅读以下关于 Dropout 的要点。</em></li></ul><blockquote class="nz oa ob"><p id="2be4" class="kw kx nl ky b kz la jr lb lc ld ju le oc lg lh li od lk ll lm oe lo lp lq lr ij bi translated">这篇文章来自<a class="ae kv" href="https://towardsdatascience.com/@theshank" rel="noopener" target="_blank">di shank Bansal</a>'<a class="ae kv" rel="noopener" target="_blank" href="/pitfalls-of-batch-norm-in-tensorflow-and-sanity-checks-for-training-networks-e86c207548c8">tensor flow 中批处理规范的缺陷和训练网络的健全性检查</a>'，是批处理规范化常见错误的重要资源。</p></blockquote><ul class=""><li id="d784" class="ls lt iq ky b kz la lc ld lf lu lj lv ln lw lr nm ly lz ma bi translated"><strong class="ky ir">随机梯度下降(SGD) </strong> —有几种风格的 SGD 使用动量、自适应学习率和内斯特罗夫更新，在训练性能和泛化能力方面没有明显的赢家(参见 Sebastian Ruder 的精彩文章<a class="ae kv" href="http://ruder.io/optimizing-gradient-descent/" rel="noopener ugc nofollow" target="_blank">‘梯度下降优化算法概述’</a>和这个有趣的实验’<a class="ae kv" href="https://shaoanlu.wordpress.com/2017/05/29/sgd-all-which-one-is-the-best-optimizer-dogs-vs-cats-toy-experiment/" rel="noopener ugc nofollow" target="_blank">SGD&gt;亚当</a>？))一个推荐的起点是具有内斯特罗夫动量的亚当或普通新币。</li><li id="f45a" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr nm ly lz ma bi translated"><strong class="ky ir">正则化</strong>-正则化对于构建概化模型至关重要，因为它会增加模型复杂性或极端参数值的损失。它显著降低了模型的方差，而没有显著增加其偏差。如<a class="ae kv" href="http://cs231n.github.io/neural-networks-3/#ratio" rel="noopener ugc nofollow" target="_blank">cs 231n 课程</a>所述:</li></ul><blockquote class="nz oa ob"><p id="e306" class="kw kx nl ky b kz la jr lb lc ld ju le oc lg lh li od lk ll lm oe lo lp lq lr ij bi translated">通常情况下，损失函数是数据损失和正则化损失之和(例如，L2 权重罚)。需要注意的一个危险是，正则化损失可能会超过数据损失，在这种情况下，梯度将主要来自正则化项(通常具有简单得多的梯度表达式)。这可以掩盖数据丢失梯度的不正确实现。</p></blockquote><p id="78c1" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">要对此进行审核，您应该关闭正则化并独立检查您的数据丢失梯度。</p><ul class=""><li id="36a4" class="ls lt iq ky b kz la lc ld lf lu lj lv ln lw lr nm ly lz ma bi translated"><strong class="ky ir">辍学</strong>——辍学是另一种规范你的人际网络以防止过度适应的方法。在训练时，仅通过以某个概率 p(超参数)保持神经元活动来实现退出，否则将其设置为零。结果，网络必须在每个训练批次中使用不同的参数子集，这减少了特定参数的变化相对于其他参数变得占优势。</li><li id="3888" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr nm ly lz ma bi translated">这里重要的一点是:如果你同时使用丢弃和批处理规范化(批处理规范),要注意这些操作的顺序，甚至是同时使用它们。这仍然是一个活跃的研究领域，但你可以看到最新的讨论:</li></ul><blockquote class="nz oa ob"><p id="187e" class="kw kx nl ky b kz la jr lb lc ld ju le oc lg lh li od lk ll lm oe lo lp lq lr ij bi translated"><a class="ae kv" href="https://stackoverflow.com/questions/39691902/ordering-of-batch-normalization-and-dropout" rel="noopener ugc nofollow" target="_blank"> <strong class="ky ir"> From Stackoverflow 用户</strong></a><code class="fe og oh oi oj b">MiloMinderBinder</code>:“Dropout 是指完全阻断某些神经元的信息，以确保神经元不协同适应。因此，批处理规范化必须在丢失之后进行，否则您将通过规范化统计传递信息。”</p><p id="eb32" class="kw kx nl ky b kz la jr lb lc ld ju le oc lg lh li od lk ll lm oe lo lp lq lr ij bi translated"><a class="ae kv" href="https://arxiv.org/abs/1801.05134" rel="noopener ugc nofollow" target="_blank"> <strong class="ky ir"> From arXiv </strong> </a> : <em class="iq">通过方差移位理解丢失和批量归一化之间的不协调(</em> <a class="ae kv" href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+X" rel="noopener ugc nofollow" target="_blank">李翔</a>，<a class="ae kv" href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chen%2C+S" rel="noopener ugc nofollow" target="_blank">硕辰</a>，<a class="ae kv" href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hu%2C+X" rel="noopener ugc nofollow" target="_blank">胡小林</a>，<a class="ae kv" href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yang%2C+J" rel="noopener ugc nofollow" target="_blank">杨坚</a>)——“理论上，我们发现当我们将那个网络的状态从训练转移到测试时，丢失会使特定神经单元的方差发生移位。然而，在测试阶段，BN 将保持其从整个学习过程中积累的统计方差。方差不一致性(我们称此方案为“方差移位”)导致推理中不稳定的数值行为，当在 BN 之前应用丢失时，最终导致更多的错误预测</p></blockquote><h1 id="d708" class="mo mp iq bd mq mr ms mt mu mv mw mx my jw mz jx na jz nb ka nc kc nd kd ne nf bi translated">5.跟踪您的工作</h1><p id="8100" class="pw-post-body-paragraph kw kx iq ky b kz ng jr lb lc nh ju le lf ni lh li lj nj ll lm ln nk lp lq lr ij bi translated">人们很容易忽视记录实验的重要性，直到你忘记了你使用的学习率或班级权重。有了更好的跟踪，你可以很容易地回顾和重现以前的实验，以减少重复工作(也就是遇到同样的错误)。</p><p id="70a9" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">然而，手动记录信息可能很难做到，也很难扩展到多个实验。<strong class="ky ir">像</strong><a class="ae kv" href="http://bit.ly/2J6dxWA" rel="noopener ugc nofollow" target="_blank"><strong class="ky ir">comet . ml</strong></a><strong class="ky ir">这样的工具可以帮助自动跟踪数据集、代码变更、实验历史和生产模型</strong>(这包括关于您的模型的关键信息，如超参数、模型性能指标和环境细节)。</p><p id="0cb4" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">您的神经网络可能对数据、参数甚至包版本的微小变化非常敏感，从而导致模型性能下降。跟踪您的工作是开始标准化您的环境和建模工作流的第一步。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ok"><img src="../Images/9588d43a1df0209d1d1cee47c90f267f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*u4OWW-JarrZ19cWjunBv0g.png"/></div></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk">Check out model performance metrics and retrieve the code used to train the model from within <a class="ae kv" href="http://bit.ly/2J6dxWA" rel="noopener ugc nofollow" target="_blank">Comet.ml</a>. There’s an example of Comet’s automatic experiment tracking <a class="ae kv" href="https://www.youtube.com/watch?v=xaybRkapeNE&amp;t=5s" rel="noopener ugc nofollow" target="_blank">here</a>.</figcaption></figure></div><div class="ab cl mh mi hu mj" role="separator"><span class="mk bw bk ml mm mn"/><span class="mk bw bk ml mm mn"/><span class="mk bw bk ml mm"/></div><div class="ij ik il im in"><h1 id="996b" class="mo mp iq bd mq mr ol mt mu mv om mx my jw on jx na jz oo ka nc kc op kd ne nf bi translated">快速回顾</h1><p id="9bf1" class="pw-post-body-paragraph kw kx iq ky b kz ng jr lb lc nh ju le lf ni lh li lj nj ll lm ln nk lp lq lr ij bi translated">我们希望这篇文章为调试你的神经网络提供一个坚实的起点。为了总结要点，您应该:</p><ol class=""><li id="aea1" class="ls lt iq ky b kz la lc ld lf lu lj lv ln lw lr lx ly lz ma bi translated"><strong class="ky ir">从简单开始— </strong>首先构建一个更简单的模型，通过训练几个数据点进行测试</li><li id="0b0f" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr lx ly lz ma bi translated">确认你的损失——检查你是否使用了正确的损失，并回顾你的初始损失</li><li id="c0d9" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr lx ly lz ma bi translated"><strong class="ky ir">检查中间输出和连接— </strong>使用梯度检查和可视化来检查您的层是否正确连接，以及您的梯度是否按预期更新</li><li id="a7b0" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr lx ly lz ma bi translated"><strong class="ky ir">诊断参数</strong> —从 SGD 到学习率，识别正确的组合(或找出错误的组合)😅</li><li id="0c70" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr lx ly lz ma bi translated"><strong class="ky ir">跟踪你的工作</strong>——作为基线，跟踪你的实验过程和关键的建模工件</li></ol><h1 id="e8e2" class="mo mp iq bd mq mr ms mt mu mv mw mx my jw mz jx na jz nb ka nc kc nd kd ne nf bi translated"><em class="oq">觉得这个帖子有用？觉得它少了点什么？请在下面评论您的反馈和问题！👩🏻‍🎓</em></h1><blockquote class="nz oa ob"><p id="4a9b" class="kw kx nl ky b kz la jr lb lc ld ju le oc lg lh li od lk ll lm oe lo lp lq lr ij bi translated"><a class="ae kv" href="https://news.ycombinator.com/item?id=19392173" rel="noopener ugc nofollow" target="_blank">关注黑客新闻</a>上的讨论！</p></blockquote></div></div>    
</body>
</html>