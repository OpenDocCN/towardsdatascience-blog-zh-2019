<html>
<head>
<title>LineFlow: Simple NLP Dataset Handler for PyTorch or Any Framework</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">line flow:py torch 或任何框架的简单 NLP 数据集处理程序</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/lineflow-introduction-1caf7851125e?source=collection_archive---------20-----------------------#2019-08-22">https://towardsdatascience.com/lineflow-introduction-1caf7851125e?source=collection_archive---------20-----------------------#2019-08-22</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="f0e6" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">代码越少，痛苦越少</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/4250dc1cab24dd0d2282e2bf110e01ad.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*5fsSNNAOjAexHzx29VAbog.jpeg"/></div></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk">Photo by <a class="ae ky" href="https://unsplash.com/@designhorf?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank">Ferenc Horvath</a> on <a class="ae ky" href="https://unsplash.com/?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><p id="8ac2" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">对于 NLP 任务，您可能需要在预处理中标记文本或构建词汇表。而且你大概也体验过，预处理代码跟你的桌子一样乱。原谅我，如果你的桌子很干净:)我也有这样的经历。这就是为什么我创造了<a class="ae ky" href="https://github.com/tofunlp/lineflow" rel="noopener ugc nofollow" target="_blank"> LineFlow </a>来减轻你的痛苦！它会让你的“桌子”尽可能的干净。真正的代码是什么样的？看一下下图。预处理包括标记化、构建词汇表和索引。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi lv"><img src="../Images/ea3283b22761d01baac353f6c63cf381.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*qdXyG19rYO5GzoBH_IJpPw.png"/></div></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk">I used <a class="ae ky" href="https://codeimg.io" rel="noopener ugc nofollow" target="_blank">Codeimg.io</a> for this picture.</figcaption></figure><p id="a348" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">左边部分是来自<a class="ae ky" href="https://github.com/pytorch/examples/blob/master/word_language_model/data.py#L20" rel="noopener ugc nofollow" target="_blank"> PyTorch 官方示例库</a>的示例代码，它对文本数据进行常见的预处理。右边部分用 LineFlow 编写，实现完全相同的处理。你应该明白线条流是如何减轻你的疼痛的。你可以从<a class="ae ky" href="https://gist.github.com/yasufumy/ba73b587bd3c516b66fb94b3a90bac71" rel="noopener ugc nofollow" target="_blank">这个链接</a>查看完整代码。</p><p id="e2c8" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在这篇文章中，我将详细解释右边部分的代码，并向您展示 LineFlow 的用法。让我们开始一个干净的“办公桌”生活吧！</p><h1 id="25dd" class="lw lx it bd ly lz ma mb mc md me mf mg jz mh ka mi kc mj kd mk kf ml kg mm mn bi translated">1.加载您的文本数据</h1><p id="b974" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">加载文本数据是通过上面代码的第 8 行完成的。稍后我会解释地图。<code class="fe mt mu mv mw b">lf.TextDataset</code>将文本文件的路径作为参数并加载它。</p><pre class="kj kk kl km gt mx mw my mz aw na bi"><span id="2b4a" class="nb lx it mw b gy nc nd l ne nf">dataset = lf.TextDataset(path, encoding='utf-8').map(...)</span></pre><p id="bedf" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><code class="fe mt mu mv mw b">lf.TextDataset</code>期望的数据格式是每行对应一个数据。如果您的文本数据满足这个条件，您可以加载任何类型的文本数据。</p><div class="kj kk kl km gt ab cb"><figure class="ng kn nh ni nj nk nl paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><img src="../Images/0325a79d30fb6d03cbfaf68c260a59d8.png" data-original-src="https://miro.medium.com/v2/resize:fit:818/format:webp/1*Xv2AzytOKTBZM1u5QZL8BQ.png"/></div></figure><figure class="ng kn nh ni nj nk nl paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><img src="../Images/79ef5864c5d3bf163d4514907baf02fc.png" data-original-src="https://miro.medium.com/v2/resize:fit:818/format:webp/1*4QdYdC7OiLwsj8jNQ5Ifww.png"/></div></figure></div><p id="4595" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">加载后，将文本数据转换为列表。列表中的项目对应于文本数据中的行。</strong>看下图。这是对<code class="fe mt mu mv mw b">lf.TextDataset</code>的直观形象。图中的<code class="fe mt mu mv mw b">d</code>代表代码中的<code class="fe mt mu mv mw b">dataset</code>。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nm"><img src="../Images/8d806f8d3f547b5f4ac306cb03a10386.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*-cq3AmBTl_nR1pb3p2oEyg.png"/></div></div></figure><p id="1f61" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">LineFlow 已经提供了一些公开的数据集。所以你可以立即使用它。您可以在此查看提供的数据集<a class="ae ky" href="https://github.com/tofunlp/lineflow#datasets" rel="noopener ugc nofollow" target="_blank">。</a></p><h1 id="b462" class="lw lx it bd ly lz ma mb mc md me mf mg jz mh ka mi kc mj kd mk kf ml kg mm mn bi translated">2.标记化</h1><p id="9089" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">第 8 行也完成了文本标记化。<code class="fe mt mu mv mw b">map</code>将作为参数传递的处理应用于文本数据的每一行。</p><pre class="kj kk kl km gt mx mw my mz aw na bi"><span id="c634" class="nb lx it mw b gy nc nd l ne nf">dataset = lf.TextDataset(...).map(lambda x: x.split() + ['&lt;eos&gt;'])</span></pre><p id="ef34" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">看下图。这是<code class="fe mt mu mv mw b">lf.TextDataset.map</code>的直观形象。图中的<code class="fe mt mu mv mw b">d</code>代表代码中的<code class="fe mt mu mv mw b">dataset</code>。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nn"><img src="../Images/5519afd2d637eb8981fc09b21769b32c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*sT79k2xMC7xfxFYuLlz2rg.png"/></div></div></figure><p id="cece" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">下面让我们深入实际的处理过程。</p><pre class="kj kk kl km gt mx mw my mz aw na bi"><span id="355f" class="nb lx it mw b gy nc nd l ne nf">lambda x: x.split() + ['&lt;eos&gt;']</span></pre><p id="8bcb" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这里，我们用空格将文本数据中的每一行分割成标记，然后在这些标记的末尾添加<code class="fe mt mu mv mw b">&lt;eos&gt;</code>。我们按照<a class="ae ky" href="https://blog.einstein.ai/the-wikitext-long-term-dependency-language-modeling-dataset/" rel="noopener ugc nofollow" target="_blank"> WikiText 官方页面</a>的处理方式。</p><p id="9ba0" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">此时，我们使用<code class="fe mt mu mv mw b">str.split</code>进行标记化。我们可以使用其他标记化方法，如<a class="ae ky" href="https://github.com/explosion/spaCy" rel="noopener ugc nofollow" target="_blank"> spaCy </a>、<a class="ae ky" href="https://github.com/stanfordnlp/stanfordnlp" rel="noopener ugc nofollow" target="_blank"> StanfordNLP </a>和<a class="ae ky" href="https://github.com/microsoft/BlingFire" rel="noopener ugc nofollow" target="_blank"> Bling Fire </a>等。例如，如果你想使用 Bling Fire，我们会得到下面的代码。</p><pre class="kj kk kl km gt mx mw my mz aw na bi"><span id="5646" class="nb lx it mw b gy nc nd l ne nf">&gt;&gt;&gt; from blingfire import text_to_words<br/>&gt;&gt;&gt; d = lf.TextDataset('/path/to/your/text')<br/>&gt;&gt;&gt; d.map(text_to_words).map(str.split)</span></pre><p id="66ad" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">此外，我们可以做任何我们想要的处理，只要我们的处理将每行文本数据作为参数。例如，我们可以计算令牌的数量。在下面的代码中，标记的数量在第二个元素中定义。</p><pre class="kj kk kl km gt mx mw my mz aw na bi"><span id="467a" class="nb lx it mw b gy nc nd l ne nf">&gt;&gt;&gt; d = lf.TextDataset('/path/to/text')<br/>&gt;&gt;&gt; d.map(tokenize).map(lambda x: (x, len(x)))</span></pre><p id="ba5b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">当我们想要制作注意力机制或 LSTM 的面具时，这种处理是很有用的。</p><h1 id="c46d" class="lw lx it bd ly lz ma mb mc md me mf mg jz mh ka mi kc mj kd mk kf ml kg mm mn bi translated">3.索引</h1><p id="4eed" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">从第 9 行到第 12 行完成索引。这些线条如下图所示。在这个代码块中，我们构建了词汇表和索引。让我们按顺序来看这些。</p><pre class="kj kk kl km gt mx mw my mz aw na bi"><span id="af4b" class="nb lx it mw b gy nc nd l ne nf">for word in dataset.flat_map(lambda x: x):<br/>    self.dictionary.add_word(word)<br/>return torch.LongTensor(dataset.flat_map(...))</span></pre><p id="0515" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">首先，我们将看到构建词汇的模块。在下面的代码块中，我们构建了词汇表。<code class="fe mt mu mv mw b">flat_map</code>将作为参数传递的处理应用于数据中的每一行，然后将其展平。所以我们会在<code class="fe mt mu mv mw b">dataset.flat_map(lambda x: x)</code>后得到个人令牌。</p><pre class="kj kk kl km gt mx mw my mz aw na bi"><span id="3c21" class="nb lx it mw b gy nc nd l ne nf">for word in dataset.flat_map(lambda x: x):<br/>    self.dictionary.add_word(word)</span></pre><p id="41fa" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">看下图。这是对<code class="fe mt mu mv mw b">dataset.flat_map(lambda x: x)</code>的直观形象。图中的<code class="fe mt mu mv mw b">d</code>代表代码中的<code class="fe mt mu mv mw b">dataset</code>。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi no"><img src="../Images/90f59bfdce5c07cc4bc5f444cd1b7d29.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_kh8uuJQT73JT5l4NPhHYw.png"/></div></div></figure><p id="e667" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><code class="fe mt mu mv mw b">flat_map</code>有点令人困惑，但它相当于下面的代码。</p><pre class="kj kk kl km gt mx mw my mz aw na bi"><span id="9db7" class="nb lx it mw b gy nc nd l ne nf">&gt;&gt;&gt; from itertools import chain<br/>&gt;&gt;&gt; chain.from_iterable(map(lambda x: x, dataset))<br/>&gt;&gt;&gt;<br/>&gt;&gt;&gt; dataset.flat_map(lambda x: x) # same as above</span></pre><p id="a7c7" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在使用<code class="fe mt mu mv mw b">flat_map</code>提取每个标记之后，我们将标记传递给<code class="fe mt mu mv mw b">self.dictionary.add_word</code>，后者构建词汇表。我不解释它是如何工作的，因为它与这篇文章无关。但是如果你对它的内部实现感兴趣，请查看<a class="ae ky" href="https://github.com/pytorch/examples/blob/master/word_language_model/data.py#L10" rel="noopener ugc nofollow" target="_blank">这个链接</a>。</p><pre class="kj kk kl km gt mx mw my mz aw na bi"><span id="9736" class="nb lx it mw b gy nc nd l ne nf">self.dictionary.add_word(word)</span></pre><p id="3999" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">接下来，我们将看到索引的代码块。索引由下面的块完成。这里，我们还使用<code class="fe mt mu mv mw b">flat_map</code>来索引每个令牌并将其展平。这是因为 PyTorch 的例子需要平坦记号的张量。所以我们跟着它。</p><pre class="kj kk kl km gt mx mw my mz aw na bi"><span id="c053" class="nb lx it mw b gy nc nd l ne nf">dataset.flat_map(<br/>    [lambda x: self.dictionary.word2idx[token] for token in x)])</span></pre><p id="83c6" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">看下图。这是<code class="fe mt mu mv mw b">dataset.flat_map(indexer)</code>的直观形象。图中的<code class="fe mt mu mv mw b">d</code>代表代码中的<code class="fe mt mu mv mw b">dataset</code>。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi np"><img src="../Images/074a16ae5fde2f84143285fd789baf19.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*cmIoJh4id19ZR8V81mA98g.png"/></div></div></figure><p id="a8ec" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这个代码等同于下面的代码。</p><pre class="kj kk kl km gt mx mw my mz aw na bi"><span id="cdec" class="nb lx it mw b gy nc nd l ne nf">&gt;&gt;&gt; from itertools import chain<br/>&gt;&gt;&gt; chain.from_iterable(map(indexer, dataset))<br/>&gt;&gt;&gt;<br/>&gt;&gt;&gt; dataset.flat_map(indexer) # same as above</span></pre><p id="6eff" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">最后，我们用<code class="fe mt mu mv mw b">torch.LongTensor</code>把它包裹起来，使之成为张量。我们完成了文本数据的加载。</p><pre class="kj kk kl km gt mx mw my mz aw na bi"><span id="8fea" class="nb lx it mw b gy nc nd l ne nf">return torch.LongTensor(dataset.flat_map(...))</span></pre><p id="afe3" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们可以在下面查看到的全部代码。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nq nr l"/></div></figure><p id="87d8" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">解释到此为止。LineFlow 通过对文本数据进行矢量化来完成较少的循环和较少的嵌套代码。我们可以通过使用 Python 的地图来做同样的事情。但是 LineFlow 为我们提供了可读和干净的代码，因为它像管道一样构建处理(<a class="ae ky" href="https://en.wikipedia.org/wiki/Fluent_interface" rel="noopener ugc nofollow" target="_blank">流畅接口</a>)。</p><p id="82dd" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">如果你喜欢 LineFlow 并想了解更多，请访问下面的知识库。</p><div class="ns nt gp gr nu nv"><a href="https://github.com/tofunlp/lineflow/tree/master/examples" rel="noopener  ugc nofollow" target="_blank"><div class="nw ab fo"><div class="nx ab ny cl cj nz"><h2 class="bd iu gy z fp oa fr fs ob fu fw is bi translated">tofunlp/lineflow</h2><div class="oc l"><h3 class="bd b gy z fp oa fr fs ob fu fw dk translated">此时您不能执行该操作。您已使用另一个标签页或窗口登录。您已在另一个选项卡中注销，或者…</h3></div><div class="od l"><p class="bd b dl z fp oa fr fs ob fu fw dk translated">github.com</p></div></div></div></a></div><p id="6ad6" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">感谢您的阅读！</p></div></div>    
</body>
</html>