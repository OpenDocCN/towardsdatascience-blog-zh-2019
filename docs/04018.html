<html>
<head>
<title>Intuitive Understanding of Logistic Regression (python)</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">对逻辑回归(python)的直观理解</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/univariate-logistic-regression-example-in-python-acbefde8cc14?source=collection_archive---------21-----------------------#2019-06-24">https://towardsdatascience.com/univariate-logistic-regression-example-in-python-acbefde8cc14?source=collection_archive---------21-----------------------#2019-06-24</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="4437" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">二元例子</h2></div></div><div class="ab cl ki kj hx kk" role="separator"><span class="kl bw bk km kn ko"/><span class="kl bw bk km kn ko"/><span class="kl bw bk km kn"/></div><div class="im in io ip iq"><figure class="kq kr ks kt gt ku gh gi paragraph-image"><div role="button" tabindex="0" class="kv kw di kx bf ky"><div class="gh gi kp"><img src="../Images/132b48f37901bd9bdc68b9c134d9ee0e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*dF4L5qVBJTvyyvvP7LZf1Q.png"/></div></div><figcaption class="lb lc gj gh gi ld le bd b be z dk">Source: <a class="ae lf" href="https://unsplash.com/photos/ORDz1m1-q0I" rel="noopener ugc nofollow" target="_blank">Anne Spratt</a></figcaption></figure></div><div class="ab cl ki kj hx kk" role="separator"><span class="kl bw bk km kn ko"/><span class="kl bw bk km kn ko"/><span class="kl bw bk km kn"/></div><div class="im in io ip iq"><p id="05ef" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi mc translated"><span class="l md me mf bm mg mh mi mj mk di"/>逻辑回归是一种用于预测目标变量“非此即彼”的模型。我们将研究的例子是:</p><ul class=""><li id="b51f" class="ml mm it li b lj lk lm ln lp mn lt mo lx mp mb mq mr ms mt bi translated"><strong class="li iu">目标变量:</strong>学生将通过或未通过考试。</li><li id="d031" class="ml mm it li b lj mu lm mv lp mw lt mx lx my mb mq mr ms mt bi translated"><strong class="li iu">自变量:</strong>每周学习时间</li></ul><p id="3048" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">逻辑模型本质上是带有额外步骤的线性模型。在逻辑模型中，线性回归通过“sigmoid 函数”运行，该函数将其输出压缩成二分的 1 和 0。</p><blockquote class="mz na nb"><p id="1b7e" class="lg lh nc li b lj lk ju ll lm ln jx lo nd lq lr ls ne lu lv lw nf ly lz ma mb im bi translated">如果我们想预测实际的考试成绩，我们会使用线性模型。如果我们想预测“通过”/“失败”，我们将使用逻辑回归模型。</p></blockquote><h1 id="da22" class="ng nh it bd ni nj nk nl nm nn no np nq jz nr ka ns kc nt kd nu kf nv kg nw nx bi translated"><strong class="ak">线性(预测数值测试分数):</strong></h1><p id="fc8f" class="pw-post-body-paragraph lg lh it li b lj ny ju ll lm nz jx lo lp oa lr ls lt ob lv lw lx oc lz ma mb im bi translated"><strong class="li iu"> y = b0 + b1x </strong></p><h1 id="d234" class="ng nh it bd ni nj nk nl nm nn no np nq jz nr ka ns kc nt kd nu kf nv kg nw nx bi translated"><strong class="ak">逻辑(预测“通过/失败”):</strong></h1><p id="e9c6" class="pw-post-body-paragraph lg lh it li b lj ny ju ll lm nz jx lo lp oa lr ls lt ob lv lw lx oc lz ma mb im bi translated"><strong class="li iu"> p = 1 / 1 + e ^-(b0 + b1x) </strong></p><h1 id="3ade" class="ng nh it bd ni nj nk nl nm nn no np nq jz nr ka ns kc nt kd nu kf nv kg nw nx bi translated">可视化:</h1><p id="3471" class="pw-post-body-paragraph lg lh it li b lj ny ju ll lm nz jx lo lp oa lr ls lt ob lv lw lx oc lz ma mb im bi translated">下图中，直线是线性的，“S”形线是逻辑的。由于其形状，逻辑回归在用于“非此即彼”模型时具有更高的准确性。</p><figure class="kq kr ks kt gt ku gh gi paragraph-image"><div role="button" tabindex="0" class="kv kw di kx bf ky"><div class="gh gi od"><img src="../Images/d81bbd6bf365d86c58ef0b1f97591e85.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*7Be4lOjVtwlMau-LHaG1cw.png"/></div></div><figcaption class="lb lc gj gh gi ld le bd b be z dk">Logistic Regressions are “S” shaped. Linear Regressions are straight.</figcaption></figure></div><div class="ab cl ki kj hx kk" role="separator"><span class="kl bw bk km kn ko"/><span class="kl bw bk km kn ko"/><span class="kl bw bk km kn"/></div><div class="im in io ip iq"><h1 id="139a" class="ng nh it bd ni nj oe nl nm nn of np nq jz og ka ns kc oh kd nu kf oi kg nw nx bi translated">理解数据:</h1><pre class="kq kr ks kt gt oj ok ol om aw on bi"><span id="5877" class="oo nh it ok b gy op oq l or os">import numpy as np<br/>import pandas as pd<br/>import matplotlib.pyplot as plt<br/>%matplotlib inline<br/>df = pd.read_excel(r”C:\Users\x\x\Log_test.xlsx”)<br/>x = df[‘W_hours’]<br/>y = df[‘Y’]</span><span id="2448" class="oo nh it ok b gy ot oq l or os">plt.scatter(x,y)<br/>plt.show()</span></pre><figure class="kq kr ks kt gt ku gh gi paragraph-image"><div role="button" tabindex="0" class="kv kw di kx bf ky"><div class="gh gi ou"><img src="../Images/473841891d99f1952ec62f0a5f4eb132.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*RemHBmGzU9NUrnMNACl2yA.png"/></div></div></figure><pre class="kq kr ks kt gt oj ok ol om aw on bi"><span id="1d69" class="oo nh it ok b gy op oq l or os">df.info()<br/>x.plot.hist()<br/>y.plot.hist()</span></pre><figure class="kq kr ks kt gt ku gh gi paragraph-image"><div class="gh gi ov"><img src="../Images/0c0b00e9cf9c01e22fb439472d3d684e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1050/format:webp/1*uy6Zr2NUYy-AjztzNI__4w.png"/></div></figure><p id="228c" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">数据集中有 23 行。以下是学习时间的分布情况:</p><figure class="kq kr ks kt gt ku gh gi paragraph-image"><div class="gh gi ow"><img src="../Images/14ac0439b2c647de2260372414929caf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1368/format:webp/1*dYWqWo3Q1n3LQVpE1X-O1g.png"/></div></figure><p id="8fac" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">下面是通过(1)/失败(0)的分布情况:</p><figure class="kq kr ks kt gt ku gh gi paragraph-image"><div class="gh gi ox"><img src="../Images/9150ce3409364d48fb3346ce53c184b2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1378/format:webp/1*SHHf8_ETnSuZm4T7WamgrQ.png"/></div></figure><h1 id="9f32" class="ng nh it bd ni nj nk nl nm nn no np nq jz nr ka ns kc nt kd nu kf nv kg nw nx bi translated">数据准备/建模</h1><p id="a20d" class="pw-post-body-paragraph lg lh it li b lj ny ju ll lm nz jx lo lp oa lr ls lt ob lv lw lx oc lz ma mb im bi translated">接下来，我们将使用 sklearn 库导入“LogisticRegression”。关于参数的详细信息可以在这里找到<a class="ae lf" href="https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html" rel="noopener ugc nofollow" target="_blank">。</a></p><p id="094c" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">我们把我们的双变量模型转换成二维的。shape()函数。我们定义了 1 列，但是我们将行数保留为数据集的大小。所以我们得到 x 的新形状为(23，1)，一个垂直数组。这是使 sklearn 功能正常工作所必需的。</p><p id="0679" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">使用“logreg.fit(x，y)”来拟合回归。</p><pre class="kq kr ks kt gt oj ok ol om aw on bi"><span id="ac6a" class="oo nh it ok b gy op oq l or os">from sklearn.linear_model import LogisticRegression<br/>logreg = LogisticRegression(C=1.0, solver=’lbfgs’, multi_class=’ovr’)</span><span id="003b" class="oo nh it ok b gy ot oq l or os">#Convert a 1D array to a 2D array in numpy<br/>x = x.reshape(-1,1)</span><span id="361e" class="oo nh it ok b gy ot oq l or os">#Run Logistic Regression<br/>logreg.fit(x, y)</span></pre><h1 id="e68f" class="ng nh it bd ni nj nk nl nm nn no np nq jz nr ka ns kc nt kd nu kf nv kg nw nx bi translated">使用和可视化模型</h1><p id="0483" class="pw-post-body-paragraph lg lh it li b lj ny ju ll lm nz jx lo lp oa lr ls lt ob lv lw lx oc lz ma mb im bi translated">让我们写一个程序，通过学习的小时数，我们可以得到通过和失败的预测概率。我们在下面的代码中输入学习时间:学习 12、16 和 20 小时的例子。</p><pre class="kq kr ks kt gt oj ok ol om aw on bi"><span id="5c5c" class="oo nh it ok b gy op oq l or os">print(logreg.predict_proba([[12]]))<br/>print(logreg.predict_proba([[16]]))<br/>print(logreg.predict_proba([[20]]))</span></pre><figure class="kq kr ks kt gt ku gh gi paragraph-image"><div class="gh gi oy"><img src="../Images/25813e87fe9db9d3359559d0756defd8.png" data-original-src="https://miro.medium.com/v2/resize:fit:756/format:webp/1*EqQIR5amIDPGyGaHvqi1rg.png"/></div></figure><p id="16ea" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">左边的输出是失败的概率，右边的输出是通过。</p><p id="1ec3" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">为了形象化模型，让我们做一个循环，将每半小时的学习时间放入从 0 到 33 的回归中。</p><pre class="kq kr ks kt gt oj ok ol om aw on bi"><span id="59ca" class="oo nh it ok b gy op oq l or os">hours = np.arange(0, 33, 0.5)<br/>probabilities= []<br/>for i in hours:<br/>    p_fail, p_pass = logreg.predict_proba([[i]])[0]<br/>    probabilities.append(p_pass)</span><span id="5127" class="oo nh it ok b gy ot oq l or os">plt.scatter(hours,probabilities)<br/>plt.title("Logistic Regression Model")<br/>plt.xlabel('Hours')<br/>plt.ylabel('Status (1:Pass, 0:Fail)')<br/>plt.show()</span></pre><figure class="kq kr ks kt gt ku gh gi paragraph-image"><div role="button" tabindex="0" class="kv kw di kx bf ky"><div class="gh gi oz"><img src="../Images/e1a9a873ed72ba33d999a8106f034b74.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*-j5LmRNcMpG1iNK4JKAxQQ.png"/></div></div></figure><p id="6729" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">在这组虚构的数据中，如果一个学生学习超过 20 个小时，他/她就一定会通过，如果不到 10 个小时，他/她就一定会不及格。17 小时是 50/50 的界限。</p><p id="eeb8" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">感谢阅读，</p><ul class=""><li id="e9c5" class="ml mm it li b lj lk lm ln lp mn lt mo lx mp mb mq mr ms mt bi translated"><a class="ae lf" rel="noopener" target="_blank" href="/is-random-forest-better-than-logistic-regression-a-comparison-7a0f068963e4"> <em class="nc">随机森林是否优于 Logistic 回归？</em>(一比较)</a></li><li id="f6bc" class="ml mm it li b lj mu lm mv lp mw lt mx lx my mb mq mr ms mt bi translated"><a class="ae lf" rel="noopener" target="_blank" href="/excel-vs-sql-a-conceptual-comparison-dcfbee640c83"> <em class="nc"> Excel vs SQL:概念上的比较</em> </a></li><li id="2a04" class="ml mm it li b lj mu lm mv lp mw lt mx lx my mb mq mr ms mt bi translated"><a class="ae lf" rel="noopener" target="_blank" href="/predicting-cancer-with-logistic-regression-in-python-7b203ace16bc"> <em class="nc">用 Python 中的逻辑回归预测癌症</em> </a></li><li id="4d79" class="ml mm it li b lj mu lm mv lp mw lt mx lx my mb mq mr ms mt bi translated"><a class="ae lf" rel="noopener" target="_blank" href="/portfolio-linear-optimization-breakdown-f519546ed1ff"> <em class="nc">利用数学和 Python 优化投资</em> </a></li><li id="b99e" class="ml mm it li b lj mu lm mv lp mw lt mx lx my mb mq mr ms mt bi translated"><a class="ae lf" rel="noopener" target="_blank" href="/uber-reviews-text-analysis-11613675046d"> <em class="nc">优步点评文本分析</em> </a></li></ul></div></div>    
</body>
</html>