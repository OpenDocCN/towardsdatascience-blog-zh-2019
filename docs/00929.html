<html>
<head>
<title>Predicting presence of Heart Diseases using Machine Learning</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用机器学习预测心脏病的存在</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/predicting-presence-of-heart-diseases-using-machine-learning-36f00f3edb2c?source=collection_archive---------0-----------------------#2019-02-12">https://towardsdatascience.com/predicting-presence-of-heart-diseases-using-machine-learning-36f00f3edb2c?source=collection_archive---------0-----------------------#2019-02-12</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><figure class="gl gn jo jp jq jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi jn"><img src="../Images/7876898085fde018a976b319648229ce.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*DAIwT7v6R8oQbJfu"/></div></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk">Photo by <a class="ae kc" href="https://unsplash.com/@rawpixel?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">rawpixel</a> on <a class="ae kc" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><p id="83ab" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">机器学习在世界各地的许多领域都有应用。医疗保健行业也不例外。机器学习可以在预测运动障碍、心脏病等疾病的存在/不存在方面发挥重要作用。如果提前预测，这些信息可以为医生提供重要的见解，然后医生可以针对每个患者调整他们的诊断和治疗。</p><p id="c3aa" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在这篇文章中，我将讨论一个项目，在这个项目中，我使用机器学习算法来预测人们潜在的心脏病。这些算法包括<code class="fe lb lc ld le b">K Neighbors Classifier</code>、<code class="fe lb lc ld le b">Support Vector Classifier</code>、<code class="fe lb lc ld le b">Decision Tree Classifier</code>和<code class="fe lb lc ld le b">Random Forest Classifier</code>。数据集取自<a class="ae kc" href="https://www.kaggle.com/ronitf/heart-disease-uci" rel="noopener ugc nofollow" target="_blank"> Kaggle </a>。我的完整项目可在<a class="ae kc" href="https://github.com/kb22/Heart-Disease-Prediction" rel="noopener ugc nofollow" target="_blank">心脏病预测</a>获得。</p><h1 id="1894" class="lf lg iq bd lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc bi translated">导入库</h1><p id="4200" class="pw-post-body-paragraph kd ke iq kf b kg md ki kj kk me km kn ko mf kq kr ks mg ku kv kw mh ky kz la ij bi translated">我为这个项目导入了几个库:</p><ol class=""><li id="c36c" class="mi mj iq kf b kg kh kk kl ko mk ks ml kw mm la mn mo mp mq bi translated"><strong class="kf ir"> numpy </strong>:使用数组</li><li id="5c5a" class="mi mj iq kf b kg mr kk ms ko mt ks mu kw mv la mn mo mp mq bi translated"><strong class="kf ir"> pandas </strong>:处理 csv 文件和数据帧</li><li id="c9bd" class="mi mj iq kf b kg mr kk ms ko mt ks mu kw mv la mn mo mp mq bi translated"><strong class="kf ir"> matplotlib </strong>:用<code class="fe lb lc ld le b">pyplot</code>创建图表，用<code class="fe lb lc ld le b">rcParams</code>定义参数，用<code class="fe lb lc ld le b">cm.rainbow</code>着色</li><li id="1d42" class="mi mj iq kf b kg mr kk ms ko mt ks mu kw mv la mn mo mp mq bi translated"><strong class="kf ir">警告</strong>:忽略笔记本中可能出现的所有警告，这些警告可能是由于某项功能过去/未来的折旧</li><li id="4aab" class="mi mj iq kf b kg mr kk ms ko mt ks mu kw mv la mn mo mp mq bi translated"><strong class="kf ir"> train_test_split </strong>:将数据集拆分成训练和测试数据</li><li id="c20a" class="mi mj iq kf b kg mr kk ms ko mt ks mu kw mv la mn mo mp mq bi translated"><strong class="kf ir"> StandardScaler </strong>:对所有特征进行缩放，使机器学习模型更好地适应数据集</li></ol><p id="4493" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">接下来，我导入了所有必要的机器学习算法。</p><figure class="mw mx my mz gt jr"><div class="bz fp l di"><div class="na nb l"/></div></figure><h1 id="e427" class="lf lg iq bd lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc bi translated">导入数据集</h1><p id="65d7" class="pw-post-body-paragraph kd ke iq kf b kg md ki kj kk me km kn ko mf kq kr ks mg ku kv kw mh ky kz la ij bi translated">从 Kaggle 下载数据集后，我将它保存到我的工作目录中，命名为<code class="fe lb lc ld le b">dataset.csv</code>。接下来，我使用<code class="fe lb lc ld le b">read_csv()</code>读取数据集并将其保存到<code class="fe lb lc ld le b">dataset</code>变量中。</p><p id="3d31" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在做任何分析之前，我只想看一看数据。所以，我用了<code class="fe lb lc ld le b">info()</code>的方法。</p><figure class="mw mx my mz gt jr"><div class="bz fp l di"><div class="na nb l"/></div></figure><p id="f1a7" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">从上面的输出可以看出，总共有 13 个特性和 1 个目标变量。此外，没有丢失的值，所以我们不需要关心任何空值。接下来我用了<code class="fe lb lc ld le b">describe()</code>的方法。</p><figure class="mw mx my mz gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi nc"><img src="../Images/93c1977c8acee8636989fb3b31dbba7b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*kfMvH8ajndCT1mz4aNgOOw.png"/></div></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk">dataset.describe()</figcaption></figure><p id="f6d6" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">该方法揭示了每个变量的范围是不同的。<code class="fe lb lc ld le b">age</code>的最大值是 77，而<code class="fe lb lc ld le b">chol</code>的最大值是 564。因此，必须对数据集执行要素缩放。</p><h1 id="c47f" class="lf lg iq bd lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc bi translated">理解数据</h1><h2 id="45c7" class="nd lg iq bd lh ne nf dn ll ng nh dp lp ko ni nj lt ks nk nl lx kw nm nn mb no bi translated">相关矩阵</h2><p id="f237" class="pw-post-body-paragraph kd ke iq kf b kg md ki kj kk me km kn ko mf kq kr ks mg ku kv kw mh ky kz la ij bi translated">首先，让我们看看特征的相关矩阵，并尝试分析它。使用<code class="fe lb lc ld le b">rcParams</code>将图形尺寸定义为 12 x 8。然后，我用 pyplot 展示了相关矩阵。使用<code class="fe lb lc ld le b">xticks</code>和<code class="fe lb lc ld le b">yticks</code>，我将名字添加到关联矩阵中。<code class="fe lb lc ld le b">colorbar()</code>显示矩阵的颜色条。</p><figure class="mw mx my mz gt jr"><div class="bz fp l di"><div class="na nb l"/></div></figure><figure class="mw mx my mz gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi np"><img src="../Images/af4021c6e2a1bae0942e8e9a1ff7e612.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*gqqGj31JybvsgmyiVexEHQ.png"/></div></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk">Correlation Matrix</figcaption></figure><p id="fe95" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">很容易看出，没有一个单一的特征与我们的目标值有非常高的相关性。此外，一些特征与目标值负相关，一些特征与目标值正相关。</p><h2 id="9eef" class="nd lg iq bd lh ne nf dn ll ng nh dp lp ko ni nj lt ks nk nl lx kw nm nn mb no bi translated">柱状图</h2><p id="c2c1" class="pw-post-body-paragraph kd ke iq kf b kg md ki kj kk me km kn ko mf kq kr ks mg ku kv kw mh ky kz la ij bi translated">这种类型的图最好的部分是，它只需要一个命令来绘制图，并提供如此多的信息作为回报。用<code class="fe lb lc ld le b">dataset.hist()</code>就行了。</p><figure class="mw mx my mz gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi nq"><img src="../Images/2dc5429637aca20fef7743b1098267e2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*cHqMJGoTSkJyzIKyXLc8TQ.png"/></div></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk">dataset.hist()</figcaption></figure><p id="a3eb" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们来看看剧情。它显示了每个要素和标注在不同范围内的分布情况，这进一步证实了缩放的必要性。接下来，无论你在哪里看到离散的条，它基本上意味着这些实际上是一个分类变量。在应用机器学习之前，我们需要处理这些分类变量。我们的目标标签有两类，0 表示无疾病，1 表示有疾病。</p><h2 id="e8d8" class="nd lg iq bd lh ne nf dn ll ng nh dp lp ko ni nj lt ks nk nl lx kw nm nn mb no bi translated">目标类的条形图</h2><p id="6839" class="pw-post-body-paragraph kd ke iq kf b kg md ki kj kk me km kn ko mf kq kr ks mg ku kv kw mh ky kz la ij bi translated">我们正在处理的数据集应该大致平衡，这一点非常重要。一个极度不平衡的数据集会使整个模型训练变得无用，因此是没有用的。我们用一个例子来理解一下。</p><blockquote class="nr ns nt"><p id="752e" class="kd ke nu kf b kg kh ki kj kk kl km kn nv kp kq kr nw kt ku kv nx kx ky kz la ij bi translated">假设我们有一个 100 人的数据集，其中有 99 名非患者和 1 名患者。甚至不需要训练和学习任何东西，该模型总是可以说任何新人都将是非患者，并且准确率为 99%。然而，由于我们更感兴趣的是识别患者，我们需要平衡的数据集，以便我们的模型实际学习。</p></blockquote><figure class="mw mx my mz gt jr"><div class="bz fp l di"><div class="na nb l"/></div></figure><p id="2184" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">对于 x 轴，我使用了来自<code class="fe lb lc ld le b">target</code>列的<code class="fe lb lc ld le b">unique()</code>值，然后使用<code class="fe lb lc ld le b">xticks</code>设置它们的名称。对于 y 轴，我使用<code class="fe lb lc ld le b">value_count()</code>来获取每个类的值。我把条形涂成绿色和红色。</p><figure class="mw mx my mz gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi ny"><img src="../Images/376e357a0141f65131aa83d6cc021faa.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*yA60ANYLiYMUDYca3iEWKA.png"/></div></div></figure><p id="5bf2" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">从图中，我们可以看到，类几乎是平衡的，我们很好地进行数据处理。</p><h1 id="b75b" class="lf lg iq bd lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc bi translated">数据处理</h1><p id="a114" class="pw-post-body-paragraph kd ke iq kf b kg md ki kj kk me km kn ko mf kq kr ks mg ku kv kw mh ky kz la ij bi translated">为了处理分类变量，我们应该将每个分类列分成包含 1 和 0 的伪列。</p><p id="9d63" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">假设我们有一个列<code class="fe lb lc ld le b">Gender</code>，值 1 表示男性，值 0 表示女性。它需要被转换成两列，其中值 1 表示该列为真，值 0 表示该列为假。看看下面的要点。</p><figure class="mw mx my mz gt jr"><div class="bz fp l di"><div class="na nb l"/></div></figure><p id="5481" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">为了做到这一点，我们使用熊猫的<code class="fe lb lc ld le b">get_dummies()</code>方法。接下来，我们需要缩放数据集，我们将使用 StandardScaler。缩放器的<code class="fe lb lc ld le b">fit_transform()</code>方法缩放数据，我们更新列。</p><figure class="mw mx my mz gt jr"><div class="bz fp l di"><div class="na nb l"/></div></figure><p id="1bba" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">数据集现在准备好了。我们可以从训练我们的模型开始。</p><h1 id="c1c6" class="lf lg iq bd lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc bi translated">机器学习</h1><p id="4a3a" class="pw-post-body-paragraph kd ke iq kf b kg md ki kj kk me km kn ko mf kq kr ks mg ku kv kw mh ky kz la ij bi translated">在这个项目中，我采用了 4 种算法，改变了它们的各种参数，并比较了最终的模型。我将数据集分为<code class="fe lb lc ld le b">67% training data</code>和<code class="fe lb lc ld le b">33% testing data</code>。</p><figure class="mw mx my mz gt jr"><div class="bz fp l di"><div class="na nb l"/></div></figure><h2 id="ec0e" class="nd lg iq bd lh ne nf dn ll ng nh dp lp ko ni nj lt ks nk nl lx kw nm nn mb no bi translated">k 近邻分类器</h2><p id="b326" class="pw-post-body-paragraph kd ke iq kf b kg md ki kj kk me km kn ko mf kq kr ks mg ku kv kw mh ky kz la ij bi translated">该分类器寻找给定数据点的 K 个最近邻的类别，并且基于多数类别，它将类别分配给该数据点。然而，邻居的数量可以变化。我让他们从 1 到 20 个邻居变来变去，计算每种情况下的测试分数。</p><figure class="mw mx my mz gt jr"><div class="bz fp l di"><div class="na nb l"/></div></figure><p id="4916" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">然后，我绘制了邻居数量和每种情况下的测试分数的线图。</p><figure class="mw mx my mz gt jr"><div class="bz fp l di"><div class="na nb l"/></div></figure><figure class="mw mx my mz gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi nz"><img src="../Images/476ebefddf0599fddfb19952759a6c35.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*1asFggIVWTdULtS2YgUW-Q.png"/></div></div></figure><blockquote class="oa"><p id="6d08" class="ob oc iq bd od oe of og oh oi oj la dk translated">如您所见，当邻居数量选择为 8 时，我们获得了 87%的最高分数。</p></blockquote><h2 id="6bd9" class="nd lg iq bd lh ne ok dn ll ng ol dp lp ko om nj lt ks on nl lx kw oo nn mb no bi translated">支持向量分类器</h2><p id="95ff" class="pw-post-body-paragraph kd ke iq kf b kg md ki kj kk me km kn ko mf kq kr ks mg ku kv kw mh ky kz la ij bi translated">该分类器旨在通过调整数据点和超平面之间的距离来形成一个能够尽可能多地分离类别的超平面。基于几个<code class="fe lb lc ld le b">kernels</code>来决定超平面。我试了四个内核，分别是，<em class="nu">线性</em>，<em class="nu"> poly </em>，<em class="nu"> rbf </em>，和<em class="nu"> sigmoid </em>。</p><figure class="mw mx my mz gt jr"><div class="bz fp l di"><div class="na nb l"/></div></figure><p id="8d1c" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">一旦我得到了每个人的分数，我就使用<code class="fe lb lc ld le b">rainbow</code>方法为每个条选择不同的颜色，并绘制出每个人所获得分数的条形图。</p><figure class="mw mx my mz gt jr"><div class="bz fp l di"><div class="na nb l"/></div></figure><figure class="mw mx my mz gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi op"><img src="../Images/a96a03beba788795b25c39cf64768dd0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*3-O6tRdC3u8JIobwCu58eQ.png"/></div></div></figure><blockquote class="oa"><p id="576c" class="ob oc iq bd od oe of og oh oi oj la dk translated">从上面的图中可以看出，<code class="fe lb lc ld le b">linear</code>内核在这个数据集上表现最好，获得了 83%的分数。</p></blockquote><h2 id="1f40" class="nd lg iq bd lh ne ok dn ll ng ol dp lp ko om nj lt ks on nl lx kw oo nn mb no bi translated">决策树分类器</h2><p id="3b18" class="pw-post-body-paragraph kd ke iq kf b kg md ki kj kk me km kn ko mf kq kr ks mg ku kv kw mh ky kz la ij bi translated">该分类器创建一个决策树，并基于该决策树将类值分配给每个数据点。在这里，我们可以改变创建模型时要考虑的最大特征数。我将特征的范围从 1 到 30(添加虚拟列后数据集中的全部特征)。</p><figure class="mw mx my mz gt jr"><div class="bz fp l di"><div class="na nb l"/></div></figure><p id="4770" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">一旦我们有了分数，我们就可以绘制一个线图，看看特征的数量对模型分数的影响。</p><figure class="mw mx my mz gt jr"><div class="bz fp l di"><div class="na nb l"/></div></figure><figure class="mw mx my mz gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi oq"><img src="../Images/3126b5557206a343b803f4ae76c87d1f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*EuJvYy6NBsWLwP0TDZAzgw.png"/></div></div></figure><blockquote class="oa"><p id="4b53" class="ob oc iq bd od oe of og oh oi oj la dk translated">从上面的线形图中，我们可以清楚地看到，最高得分为 79%，并且是在最大特征被选择为 2、4 或 18 的情况下实现的。</p></blockquote><h2 id="b042" class="nd lg iq bd lh ne ok dn ll ng ol dp lp ko om nj lt ks on nl lx kw oo nn mb no bi translated">随机森林分类器</h2><p id="74ba" class="pw-post-body-paragraph kd ke iq kf b kg md ki kj kk me km kn ko mf kq kr ks mg ku kv kw mh ky kz la ij bi translated">这个分类器将决策树的概念带到了下一个层次。它创建了一个树的森林，其中每棵树都是由从所有要素中随机选择的要素组成的。在这里，我们可以改变用于预测类别的树的数量。我计算了 10、100、200、500 和 1000 棵树的测试分数。</p><figure class="mw mx my mz gt jr"><div class="bz fp l di"><div class="na nb l"/></div></figure><p id="0a8f" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">接下来，我将这些分数绘制在一个条形图上，看看哪个给出了最好的结果。您可能会注意到，我没有直接将 X 值设置为数组<code class="fe lb lc ld le b">[10, 100, 200, 500, 1000]</code>。它将显示从 10 到 1000 的连续图，这将是不可能破译的。所以，为了解决这个问题，我首先使用 X 值作为<code class="fe lb lc ld le b">[1, 2, 3, 4, 5]</code>。然后，我用<code class="fe lb lc ld le b">xticks</code>给它们重新命名。</p><figure class="mw mx my mz gt jr"><div class="bz fp l di"><div class="na nb l"/></div></figure><figure class="mw mx my mz gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi or"><img src="../Images/d7669e2a2336ada3fb4f723874ee3ff7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*HrZ4UM5u6WH1N-1OlepUew.png"/></div></div></figure><blockquote class="oa"><p id="35a2" class="ob oc iq bd od oe of og oh oi oj la dk translated">看一下条形图，我们可以看到 100 和 500 棵树都达到了 84%的最高分数。</p></blockquote><h1 id="bd28" class="lf lg iq bd lh li lj lk ll lm ln lo lp lq os ls lt lu ot lw lx ly ou ma mb mc bi translated">结论</h1><p id="8fec" class="pw-post-body-paragraph kd ke iq kf b kg md ki kj kk me km kn ko mf kq kr ks mg ku kv kw mh ky kz la ij bi translated">该项目涉及通过适当的数据处理对心脏病患者数据集进行分析。然后，对 4 个模型进行训练和测试，最高得分如下:</p><ol class=""><li id="4a83" class="mi mj iq kf b kg kh kk kl ko mk ks ml kw mm la mn mo mp mq bi translated">k 近邻分类器:87%</li><li id="5de9" class="mi mj iq kf b kg mr kk ms ko mt ks mu kw mv la mn mo mp mq bi translated">支持向量分类器:83%</li><li id="ce33" class="mi mj iq kf b kg mr kk ms ko mt ks mu kw mv la mn mo mp mq bi translated">决策树分类器:79%</li><li id="a6a7" class="mi mj iq kf b kg mr kk ms ko mt ks mu kw mv la mn mo mp mq bi translated">随机森林分类器:84%</li></ol><h2 id="fde3" class="nd lg iq bd lh ne nf dn ll ng nh dp lp ko ni nj lt ks nk nl lx kw nm nn mb no bi translated">k 个邻居分类器在 8 个邻居的情况下取得了 87%的最好成绩。</h2></div><div class="ab cl ov ow hu ox" role="separator"><span class="oy bw bk oz pa pb"/><span class="oy bw bk oz pa pb"/><span class="oy bw bk oz pa"/></div><div class="ij ik il im in"><p id="88a4" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">感谢您的阅读！请随意分享你的想法和主意。</p></div></div>    
</body>
</html>