<html>
<head>
<title>Andrew Ng’s Machine Learning Course in Python (Support Vector Machines)</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">吴恩达的 Python(支持向量机)机器学习教程</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/andrew-ngs-machine-learning-course-in-python-support-vector-machines-435fc34b7bf9?source=collection_archive---------11-----------------------#2019-01-03">https://towardsdatascience.com/andrew-ngs-machine-learning-course-in-python-support-vector-machines-435fc34b7bf9?source=collection_archive---------11-----------------------#2019-01-03</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><figure class="gl gn jr js jt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi jq"><img src="../Images/89c054f3f9f1146644d5e0dab6fe6a6b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*nWOP-b9Kz7Wh843nqIT-fQ.png"/></div></div><figcaption class="kb kc gj gh gi kd ke bd b be z dk">Machine Learning — Andrew Ng</figcaption></figure><p id="58aa" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">继续这个系列，我们将继续学习编程作业 6 的支持向量机。如果你注意到了，我没有写作业 5，因为大多数任务只需要绘制和解释学习曲线。不过你还是可以在我的 GitHub 里找到代码，网址是<a class="ae ld" href="https://github.com/Benlau93/Machine-Learning-by-Andrew-Ng-in-Python/tree/master/Bias_Vs_Variance" rel="noopener ugc nofollow" target="_blank">https://GitHub . com/Ben lau 93/Machine-Learning-by-Andrew-Ng-in-Python/tree/master/Bias _ Vs _ Variance</a>。</p></div><div class="ab cl le lf hx lg" role="separator"><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj"/></div><div class="im in io ip iq"><p id="978e" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi ll translated">T4:这个作业有两个部分。首先，我们将在几个 2D 数据集上实现支持向量机(SVM ),以直观地了解算法及其工作原理。接下来，我们将在电子邮件数据集上使用 SVM 来尝试对垃圾邮件进行分类。</p><p id="cf0f" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">为了加载数据集，使用来自 scipy.io 的 loadmat 来打开 mat 文件</p><pre class="lu lv lw lx gt ly lz ma mb aw mc bi"><span id="2383" class="md me it lz b gy mf mg l mh mi">import numpy as np<br/>import pandas as pd<br/>import matplotlib.pyplot as plt<br/>from scipy.io import loadmat</span><span id="4bf1" class="md me it lz b gy mj mg l mh mi">mat = loadmat("ex6data1.mat")<br/>X = mat["X"]<br/>y = mat["y"]</span></pre><p id="5520" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">数据集的绘图</p><pre class="lu lv lw lx gt ly lz ma mb aw mc bi"><span id="26ac" class="md me it lz b gy mf mg l mh mi">m,n = X.shape[0],X.shape[1]<br/>pos,neg= (y==1).reshape(m,1), (y==0).reshape(m,1)<br/>plt.scatter(X[pos[:,0],0],X[pos[:,0],1],c="r",marker="+",s=50)<br/>plt.scatter(X[neg[:,0],0],X[neg[:,0],1],c="y",marker="o",s=50)</span></pre><figure class="lu lv lw lx gt ju gh gi paragraph-image"><div class="gh gi mk"><img src="../Images/5fe5dce14567c1dd9bc21660df868556.png" data-original-src="https://miro.medium.com/v2/resize:fit:1226/format:webp/1*1FO-e-ezwzVcVjPELLV3XQ.png"/></div></figure><p id="1be4" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">我们从一个简单的数据集开始，它在训练示例之间有一个清晰的线性边界。</p><p id="5423" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">正如讲座中所建议的，我们尽量不从头开始编写 SVM，而是利用高度优化的库，如 sklearn 来完成这项任务。官方文档可以在<a class="ae ld" href="https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html" rel="noopener ugc nofollow" target="_blank">这里</a>找到。</p><pre class="lu lv lw lx gt ly lz ma mb aw mc bi"><span id="c265" class="md me it lz b gy mf mg l mh mi">from sklearn.svm import SVC<br/>classifier = SVC(kernel="linear")<br/>classifier.fit(X,np.ravel(y))</span></pre><figure class="lu lv lw lx gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi ml"><img src="../Images/f19ab074153396ca9c871ab8ca33e2a0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*jBci0T36aGd18fOw-6CZUw.png"/></div></div></figure><p id="e19b" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">由于这是一个线性分类问题，我们将不会为这个任务使用任何内核。这相当于在 SVC 中使用线性核(注意 SVC 的默认核设置是“rbf”，代表径向基函数)。这里的<code class="fe mm mn mo lz b">ravel()</code>函数返回一个大小为(m)的数组，这是 SVC 所需要的。</p><pre class="lu lv lw lx gt ly lz ma mb aw mc bi"><span id="e78c" class="md me it lz b gy mf mg l mh mi">plt.figure(figsize=(8,6))<br/>plt.scatter(X[pos[:,0],0],X[pos[:,0],1],c="r",marker="+",s=50)<br/>plt.scatter(X[neg[:,0],0],X[neg[:,0],1],c="y",marker="o",s=50)</span><span id="3c0b" class="md me it lz b gy mj mg l mh mi"># plotting the decision boundary<br/>X_1,X_2 = np.meshgrid(np.linspace(X[:,0].min(),X[:,1].max(),num=100),np.linspace(X[:,1].min(),X[:,1].max(),num=100))<br/>plt.contour(X_1,X_2,classifier.predict(np.array([X_1.ravel(),X_2.ravel()]).T).reshape(X_1.shape),1,colors="b")<br/>plt.xlim(0,4.5)<br/>plt.ylim(1.5,5)</span></pre><figure class="lu lv lw lx gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi mp"><img src="../Images/0d7fe8d12b12b5ab4d32eff1787600ee.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*nEFRXYJcHnUSSW8VajgvEg.png"/></div></div><figcaption class="kb kc gj gh gi kd ke bd b be z dk">C=1, kernel = “linear”</figcaption></figure><p id="1511" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">在默认设置为 C = 1.0(记住 C = 1/λ)的情况下，这就是我们得到的决策边界。</p><pre class="lu lv lw lx gt ly lz ma mb aw mc bi"><span id="4af9" class="md me it lz b gy mf mg l mh mi"># Test C = 100<br/>classifier2 = SVC(C=100,kernel="linear")<br/>classifier2.fit(X,np.ravel(y))</span></pre><figure class="lu lv lw lx gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi mq"><img src="../Images/cddd6c82c9a28d1c8dd076b3393bc8e2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*NYxV-0IbWiXtdwN-cueu2A.png"/></div></div></figure><pre class="lu lv lw lx gt ly lz ma mb aw mc bi"><span id="7b5f" class="md me it lz b gy mf mg l mh mi">plt.figure(figsize=(8,6))<br/>plt.scatter(X[pos[:,0],0],X[pos[:,0],1],c="r",marker="+",s=50)<br/>plt.scatter(X[neg[:,0],0],X[neg[:,0],1],c="y",marker="o",s=50)</span><span id="b574" class="md me it lz b gy mj mg l mh mi"># plotting the decision boundary<br/>X_3,X_4 = np.meshgrid(np.linspace(X[:,0].min(),X[:,1].max(),num=100),np.linspace(X[:,1].min(),X[:,1].max(),num=100))<br/>plt.contour(X_3,X_4,classifier2.predict(np.array([X_3.ravel(),X_4.ravel()]).T).reshape(X_3.shape),1,colors="b")<br/>plt.xlim(0,4.5)<br/>plt.ylim(1.5,5)</span></pre><figure class="lu lv lw lx gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi mr"><img src="../Images/fad6d185955fcde2686447f8a48a08e9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*RqaGOmwjMjN1vcDcA5gx7w.png"/></div></div><figcaption class="kb kc gj gh gi kd ke bd b be z dk">C= 100, kernel =”linear”</figcaption></figure><p id="61e8" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">更改 C=100，给出一个超过训练示例的决策边界。</p><p id="fce2" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">接下来，我们将看一个不能线性分离的数据集。这就是内核发挥作用的地方，为我们提供非线性分类器的功能。对于那些理解内核概念有困难的人来说，我找到的这篇<a class="ae ld" rel="noopener" target="_blank" href="/understanding-the-kernel-trick-e0bc6112ef78">文章</a>给出了一个很好的关于内核的直觉和一些数学解释。对于这部分作业，我们需要完成函数<code class="fe mm mn mo lz b">gaussianKernel</code>来帮助实现高斯核的 SVM。我将跳过这一步，因为 SVC 包含它自己的径向基函数(rbf)形式的高斯核实现。<a class="ae ld" href="https://en.wikipedia.org/wiki/Radial_basis_function_kernel" rel="noopener ugc nofollow" target="_blank">这里的</a>是维基百科的页面，上面有 rbf 的方程，正如你看到的，它与课程中的高斯核函数相同。</p><p id="b696" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">示例数据集 2 的加载和绘图</p><pre class="lu lv lw lx gt ly lz ma mb aw mc bi"><span id="72a3" class="md me it lz b gy mf mg l mh mi">mat2 = loadmat("ex6data2.mat")<br/>X2 = mat2["X"]<br/>y2 = mat2["y"]</span><span id="9247" class="md me it lz b gy mj mg l mh mi">m2,n2 = X2.shape[0],X2.shape[1]<br/>pos2,neg2= (y2==1).reshape(m2,1), (y2==0).reshape(m2,1)<br/>plt.figure(figsize=(8,6))<br/>plt.scatter(X2[pos2[:,0],0],X2[pos2[:,0],1],c="r",marker="+")<br/>plt.scatter(X2[neg2[:,0],0],X2[neg2[:,0],1],c="y",marker="o")<br/>plt.xlim(0,1)<br/>plt.ylim(0.4,1)</span></pre><figure class="lu lv lw lx gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi ms"><img src="../Images/8e591ff465177d07b518446700bba98c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*PK896LHMEm_Pk-viVnNK0w.png"/></div></div></figure><p id="2438" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">用高斯核实现 SVM</p><pre class="lu lv lw lx gt ly lz ma mb aw mc bi"><span id="74ea" class="md me it lz b gy mf mg l mh mi">classifier3 = SVC(kernel="rbf",gamma=30)<br/>classifier3.fit(X2,y2.ravel())</span></pre><figure class="lu lv lw lx gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi mt"><img src="../Images/4417d6c4a2d4edaa886986c11b953b79.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*MF37tkt13fggW4sTGspKBg.png"/></div></div></figure><p id="910e" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">对于径向基函数核的 SVM 的参数，它使用 gamma 代替 sigma。参数文档可以在<a class="ae ld" href="https://scikit-learn.org/stable/auto_examples/svm/plot_rbf_parameters.html" rel="noopener ugc nofollow" target="_blank">这里</a>找到。我发现 gamma 类似于 1/σ，但不完全是，我希望一些领域专家能给我解释这个 gamma 项的见解。至于这个数据集，我发现 gamma 值为 30 表示与作业中的优化参数最相似(课程中 sigma 为 0.1)。</p><pre class="lu lv lw lx gt ly lz ma mb aw mc bi"><span id="8e9c" class="md me it lz b gy mf mg l mh mi">plt.figure(figsize=(8,6))<br/>plt.scatter(X2[pos2[:,0],0],X2[pos2[:,0],1],c="r",marker="+")<br/>plt.scatter(X2[neg2[:,0],0],X2[neg2[:,0],1],c="y",marker="o")</span><span id="ea64" class="md me it lz b gy mj mg l mh mi"># plotting the decision boundary<br/>X_5,X_6 = np.meshgrid(np.linspace(X2[:,0].min(),X2[:,1].max(),num=100),np.linspace(X2[:,1].min(),X2[:,1].max(),num=100))<br/>plt.contour(X_5,X_6,classifier3.predict(np.array([X_5.ravel(),X_6.ravel()]).T).reshape(X_5.shape),1,colors="b")<br/>plt.xlim(0,1)<br/>plt.ylim(0.4,1)</span></pre><figure class="lu lv lw lx gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi mr"><img src="../Images/b83951531ff2c206420b386ba1f863cf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*oTtowQ2qFPoZllq_QtJoUQ.png"/></div></div><figcaption class="kb kc gj gh gi kd ke bd b be z dk">C = 1, gamma = 30, kernel = “rbf”</figcaption></figure><p id="ff18" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">对于本部分的最后一个数据集，我们执行一个简单的超参数调整，以确定要使用的最佳 C 值和 gamma 值。</p><p id="4b7c" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">示例数据集 3 的加载和绘图</p><pre class="lu lv lw lx gt ly lz ma mb aw mc bi"><span id="fc27" class="md me it lz b gy mf mg l mh mi">mat3 = loadmat("ex6data3.mat")<br/>X3 = mat3["X"]<br/>y3 = mat3["y"]<br/>Xval = mat3["Xval"]<br/>yval = mat3["yval"]</span><span id="a3f5" class="md me it lz b gy mj mg l mh mi">m3,n3 = X3.shape[0],X3.shape[1]<br/>pos3,neg3= (y3==1).reshape(m3,1), (y3==0).reshape(m3,1)<br/>plt.figure(figsize=(8,6))<br/>plt.scatter(X3[pos3[:,0],0],X3[pos3[:,0],1],c="r",marker="+",s=50)<br/>plt.scatter(X3[neg3[:,0],0],X3[neg3[:,0],1],c="y",marker="o",s=50)</span></pre><figure class="lu lv lw lx gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi mr"><img src="../Images/808cc0dd6e093e77f4f2007354ec8bc9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*FyRmNNjbPRn30FdrYw4UNA.png"/></div></div></figure><pre class="lu lv lw lx gt ly lz ma mb aw mc bi"><span id="fa4d" class="md me it lz b gy mf mg l mh mi">def dataset3Params(X, y, Xval, yval,vals):<br/>    """<br/>    Returns your choice of C and sigma. You should complete this function to return the optimal C and <br/>    sigma based on a cross-validation set.<br/>    """<br/>    acc = 0<br/>    best_c=0<br/>    best_gamma=0<br/>    for i in vals:<br/>        C= i<br/>        for j in vals:<br/>            gamma = 1/j<br/>            classifier = SVC(C=C,gamma=gamma)<br/>            classifier.fit(X,y)<br/>            prediction = classifier.predict(Xval)<br/>            score = classifier.score(Xval,yval)<br/>            if score&gt;acc:<br/>                acc =score<br/>                best_c =C<br/>                best_gamma=gamma<br/>    return best_c, best_gamma</span></pre><p id="830e" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated"><code class="fe mm mn mo lz b">dataset3Params</code>遍历函数中给出的<code class="fe mm mn mo lz b">vals</code>列表，将 C 设置为 val，将 gamma 设置为 1/val。使用每个参数组合构建 SVC 模型，并计算验证集的准确度。基于精度，选择最佳模型，并返回相应的 C 和 gamma 值。</p><pre class="lu lv lw lx gt ly lz ma mb aw mc bi"><span id="fa89" class="md me it lz b gy mf mg l mh mi">vals = [0.01, 0.03, 0.1, 0.3, 1, 3, 10, 30]<br/>C, gamma = dataset3Params(X3, y3.ravel(), Xval, yval.ravel(),vals)<br/>classifier4 = SVC(C=C,gamma=gamma)<br/>classifier4.fit(X3,y3.ravel())</span></pre><figure class="lu lv lw lx gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi mu"><img src="../Images/8707807f128ffc6fa09db3dc2bd985c2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*NFfO-J9OSSu9UnpGc0YJsQ.png"/></div></div></figure><pre class="lu lv lw lx gt ly lz ma mb aw mc bi"><span id="d149" class="md me it lz b gy mf mg l mh mi">plt.figure(figsize=(8,6))<br/>plt.scatter(X3[pos3[:,0],0],X3[pos3[:,0],1],c="r",marker="+",s=50)<br/>plt.scatter(X3[neg3[:,0],0],X3[neg3[:,0],1],c="y",marker="o",s=50)</span><span id="6e0e" class="md me it lz b gy mj mg l mh mi"># plotting the decision boundary<br/>X_7,X_8 = np.meshgrid(np.linspace(X3[:,0].min(),X3[:,1].max(),num=100),np.linspace(X3[:,1].min(),X3[:,1].max(),num=100))<br/>plt.contour(X_7,X_8,classifier4.predict(np.array([X_7.ravel(),X_8.ravel()]).T).reshape(X_7.shape),1,colors="b")<br/>plt.xlim(-0.6,0.3)<br/>plt.ylim(-0.7,0.5)</span></pre><figure class="lu lv lw lx gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi mv"><img src="../Images/e7670777491be65962e2748697aa56b9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*U0iMifNkeLXo_XLhTimN5A.png"/></div></div><figcaption class="kb kc gj gh gi kd ke bd b be z dk">C = 0.3, gamma = 100, kernel =”rbf”</figcaption></figure><p id="b015" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">C 的最佳值是 0.3，γ的最佳值是 100，这导致了与分配相似的决策边界。</p></div><div class="ab cl le lf hx lg" role="separator"><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj"/></div><div class="im in io ip iq"><p id="9294" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">继续垃圾邮件分类。这个问题是独特的，因为它更侧重于数据预处理，而不是实际的建模过程。电子邮件需要以一种可以用作模型输入的方式进行处理。一种方法是根据常用词汇列表获取电子邮件中所有单词的索引。</p><p id="3326" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">加载数据</p><pre class="lu lv lw lx gt ly lz ma mb aw mc bi"><span id="9dc8" class="md me it lz b gy mf mg l mh mi">import re<br/>from nltk.stem import PorterStemmer</span><span id="be95" class="md me it lz b gy mj mg l mh mi">file_contents = open("emailSample1.txt","r").read()<br/>vocabList = open("vocab.txt","r").read()</span></pre><figure class="lu lv lw lx gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi mw"><img src="../Images/16dcd558341663cdd97edcb00acbc2b4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*nkMlwpW8xTUhAPzmp2N2ZA.png"/></div></div><figcaption class="kb kc gj gh gi kd ke bd b be z dk">Content of the email</figcaption></figure><p id="3be2" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">给出了词汇列表及其相应的索引，我将该列表存储为字典，以词汇作为键，索引作为值。你也许可以用另一种方式来做，但是我想让访问词汇更容易(比如用<code class="fe mm mn mo lz b"> if keys in dict</code>)</p><pre class="lu lv lw lx gt ly lz ma mb aw mc bi"><span id="ce27" class="md me it lz b gy mf mg l mh mi">vocabList=vocabList.split("\n")[:-1]</span><span id="7afc" class="md me it lz b gy mj mg l mh mi">vocabList_d={}<br/>for ea in vocabList:<br/>    value,key = ea.split("\t")[:]<br/>    vocabList_d[key] = value</span></pre><p id="af5b" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">至于邮件的预处理，作业中为我们概述了几个步骤。</p><pre class="lu lv lw lx gt ly lz ma mb aw mc bi"><span id="3fb4" class="md me it lz b gy mf mg l mh mi">def processEmail(email_contents,vocabList_d):<br/>    """<br/>    Preprocesses the body of an email and returns a list of indices of the words contained in the email. <br/>    """<br/>    # Lower case<br/>    email_contents = email_contents.lower()<br/>    <br/>    # Handle numbers<br/>    email_contents = re.sub("[0-9]+","number",email_contents)<br/>    <br/>    # Handle URLS<br/>    email_contents = re.sub("[http|https]://[^\s]*","httpaddr",email_contents)<br/>    <br/>    # Handle Email Addresses<br/>    email_contents = re.sub("[^\s]+@[^\s]+","emailaddr",email_contents)<br/>    <br/>    # Handle $ sign<br/>    email_contents = re.sub("[$]+","dollar",email_contents)<br/>    <br/>    # Strip all special characters<br/>    specialChar = ["&lt;","[","^","&gt;","+","?","!","'",".",",",":"]<br/>    for char in specialChar:<br/>        email_contents = email_contents.replace(str(char),"")<br/>    email_contents = email_contents.replace("\n"," ")    <br/>    <br/>    # Stem the word<br/>    ps = PorterStemmer()<br/>    email_contents = [ps.stem(token) for token in email_contents.split(" ")]<br/>    email_contents= " ".join(email_contents)<br/>    <br/>    # Process the email and return word_indices<br/>    <br/>    word_indices=[]<br/>    <br/>    for char in email_contents.split():<br/>        if len(char) &gt;1 and char in vocabList_d:<br/>            word_indices.append(int(vocabList_d[char]))<br/>    <br/>    return word_indices</span><span id="d7af" class="md me it lz b gy mj mg l mh mi">word_indices= processEmail(file_contents,vocabList_d)</span></pre><p id="13eb" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">正则表达式的使用在这里非常方便，python 大师的这个<a class="ae ld" href="https://thepythonguru.com/python-regular-expression/" rel="noopener ugc nofollow" target="_blank">教程</a>可以帮助你开始 re。这里另一个有用的库是 nlkt，其中的<code class="fe mm mn mo lz b">PorterStemmer() </code>函数有助于词干化。另一个好的教程是 pythonprogramming.net 的。</p><p id="6b7e" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">在得到单词的索引后，我们需要将索引转换成一个特征向量。</p><pre class="lu lv lw lx gt ly lz ma mb aw mc bi"><span id="35bf" class="md me it lz b gy mf mg l mh mi">def emailFeatures(word_indices, vocabList_d):<br/>    """<br/>    Takes in a word_indices vector and  produces a feature vector from the word indices. <br/>    """<br/>    n = len(vocabList_d)<br/>    <br/>    features = np.zeros((n,1))<br/>    <br/>    for i in word_indices:<br/>        features[i] =1<br/>        <br/>    return features</span><span id="37e0" class="md me it lz b gy mj mg l mh mi">features = emailFeatures(word_indices,vocabList_d)<br/>print("Length of feature vector: ",len(features))<br/>print("Number of non-zero entries: ",np.sum(features))</span></pre><p id="30aa" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">打印语句将打印:<code class="fe mm mn mo lz b">Length of feature vector: 1899</code>和<code class="fe mm mn mo lz b">Number of non-zero entries: 43.0</code>。这与赋值略有不同，因为在赋值中,<code class="fe mm mn mo lz b">you’re</code>被捕获为“你”和“re ”,而我的代码将它识别为“你的”,导致更少的非零条目。</p><p id="e06d" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">训练 SVM 就像将特征作为输入传递一样简单。然而，这只是一个训练示例，我们需要更多的训练数据来训练分类器。</p><pre class="lu lv lw lx gt ly lz ma mb aw mc bi"><span id="38aa" class="md me it lz b gy mf mg l mh mi">spam_mat = loadmat("spamTrain.mat")<br/>X_train =spam_mat["X"]<br/>y_train = spam_mat["y"]</span></pre><p id="f5a4" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">训练示例在<code class="fe mm mn mo lz b">spamTrain.mat</code>中给出，用于训练我们的分类器，而测试示例在<code class="fe mm mn mo lz b">spamTest.mat</code>中给出，用于确定我们的模型可推广性。</p><pre class="lu lv lw lx gt ly lz ma mb aw mc bi"><span id="23dc" class="md me it lz b gy mf mg l mh mi">C =0.1<br/>spam_svc = SVC(C=0.1,kernel ="linear")<br/>spam_svc.fit(X_train,y_train.ravel())<br/>print("Training Accuracy:",(spam_svc.score(X_train,y_train.ravel()))*100,"%")</span></pre><p id="9a7b" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">打印语句将打印:<code class="fe mm mn mo lz b">Training Accuracy: 99.825 %</code></p><pre class="lu lv lw lx gt ly lz ma mb aw mc bi"><span id="a1f9" class="md me it lz b gy mf mg l mh mi">spam_mat_test = loadmat("spamTest.mat")<br/>X_test = spam_mat_test["Xtest"]<br/>y_test =spam_mat_test["ytest"]</span><span id="7017" class="md me it lz b gy mj mg l mh mi">spam_svc.predict(X_test)<br/>print("Test Accuracy:",(spam_svc.score(X_test,y_test.ravel()))*100,"%")</span></pre><p id="50ba" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">打印语句将打印:<code class="fe mm mn mo lz b"> Test Accuracy: 98.9 %</code></p><p id="f7bd" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">为了更好地理解我们的模型，我们可以查看每个单词的权重，并找出最能预测垃圾邮件的单词。</p><pre class="lu lv lw lx gt ly lz ma mb aw mc bi"><span id="5a9f" class="md me it lz b gy mf mg l mh mi">weights = spam_svc.coef_[0]<br/>weights_col = np.hstack((np.arange(1,1900).reshape(1899,1),weights.reshape(1899,1)))<br/>df = pd.DataFrame(weights_col)</span><span id="1992" class="md me it lz b gy mj mg l mh mi">df.sort_values(by=[1],ascending = False,inplace=True)</span><span id="3a5e" class="md me it lz b gy mj mg l mh mi">predictors = []<br/>idx=[]<br/>for i in df[0][:15]:<br/>    for keys, values in vocabList_d.items():<br/>        if str(int(i)) == values:<br/>            predictors.append(keys)<br/>            idx.append(int(values))</span><span id="dcdc" class="md me it lz b gy mj mg l mh mi">print("Top predictors of spam:")</span><span id="32da" class="md me it lz b gy mj mg l mh mi">for _ in range(15):<br/>    print(predictors[_],"\t\t",round(df[1][idx[_]-1],6))</span></pre><figure class="lu lv lw lx gt ju gh gi paragraph-image"><div class="gh gi mx"><img src="../Images/54c128b080eff9ad9273b698943905a2.png" data-original-src="https://miro.medium.com/v2/resize:fit:862/format:webp/1*_KAMB0SVDh_hXKpyxw5dAg.png"/></div></figure></div><div class="ab cl le lf hx lg" role="separator"><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj"/></div><div class="im in io ip iq"><p id="091f" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">支持向量机就是这样！jupyter 笔记本会上传到我的 GitHub 上(<a class="ae ld" href="https://github.com/Benlau93/Machine-Learning-by-Andrew-Ng-in-Python" rel="noopener ugc nofollow" target="_blank">https://GitHub . com/Ben lau 93/Machine-Learning-by-Andrew-Ng-in-Python</a>)。</p><p id="5d56" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">对于本系列中的其他 python 实现，</p><ul class=""><li id="4ab9" class="my mz it kh b ki kj km kn kq na ku nb ky nc lc nd ne nf ng bi translated"><a class="ae ld" href="https://medium.com/@ben_lau93/andrew-ngs-machine-learning-course-in-python-linear-regression-dd04fba8e137" rel="noopener">线性回归</a></li><li id="71e4" class="my mz it kh b ki nh km ni kq nj ku nk ky nl lc nd ne nf ng bi translated"><a class="ae ld" href="https://medium.com/@ben_lau93/andrew-ngs-machine-learning-course-in-python-logistic-regression-c0ae25509feb" rel="noopener">逻辑回归</a></li><li id="acb3" class="my mz it kh b ki nh km ni kq nj ku nk ky nl lc nd ne nf ng bi translated"><a class="ae ld" href="https://medium.com/@ben_lau93/andrew-ngs-machine-learning-course-in-python-regularized-logistic-regression-lasso-regression-721f311130fb" rel="noopener">正则化逻辑回归</a></li><li id="d3d9" class="my mz it kh b ki nh km ni kq nj ku nk ky nl lc nd ne nf ng bi translated"><a class="ae ld" rel="noopener" target="_blank" href="/andrew-ngs-machine-learning-course-in-python-neural-networks-e526b41fdcd9">神经网络</a></li><li id="f6ea" class="my mz it kh b ki nh km ni kq nj ku nk ky nl lc nd ne nf ng bi translated"><a class="ae ld" href="https://medium.com/@ben_lau93/andrew-ngs-machine-learning-course-in-python-kmeans-clustering-pca-b7ba6fafa74" rel="noopener">无监督学习</a></li><li id="b560" class="my mz it kh b ki nh km ni kq nj ku nk ky nl lc nd ne nf ng bi translated"><a class="ae ld" href="https://medium.com/@ben_lau93/andrew-ngs-machine-learning-course-in-python-anomaly-detection-1233d23dba95" rel="noopener">异常检测</a></li></ul><p id="a72e" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">感谢您的阅读。</p></div></div>    
</body>
</html>