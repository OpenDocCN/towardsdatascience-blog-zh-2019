<html>
<head>
<title>Review: InstanceFCN — Instance-Sensitive Score Maps (Instance Segmentation)</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">评审:实例分数图-实例敏感分数图(实例分段)</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/review-instancefcn-instance-sensitive-score-maps-instance-segmentation-dbfe67d4ee92?source=collection_archive---------20-----------------------#2019-01-07">https://towardsdatascience.com/review-instancefcn-instance-sensitive-score-maps-instance-segmentation-dbfe67d4ee92?source=collection_archive---------20-----------------------#2019-01-07</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="f8cb" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">全卷积网络(FCN)，具有实例敏感得分图，优于 DeepMask，可与 MNC 竞争</h2></div><p id="431b" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi lb translated"><span class="l lc ld le bm lf lg lh li lj di">在</span>这个故事中，由<strong class="kh ir">微软研究院</strong>、<strong class="kh ir">清华大学</strong>和<strong class="kh ir">中国科学技术大学</strong>开发的<strong class="kh ir">实例</strong> ( <strong class="kh ir">实例敏感全卷积网络</strong>)被简要回顾。</p><p id="1e75" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">通过使用<strong class="kh ir">全卷积网络(</strong> <a class="ae lk" rel="noopener" target="_blank" href="/review-fcn-semantic-segmentation-eb8c9b50d2d1"> <strong class="kh ir">、FCN </strong> </a> <strong class="kh ir"> ) </strong>、<strong class="kh ir">实例敏感得分映射</strong>被引入，并且所有全连接(FC)层被移除。在 PASCAL VOC 和 MS COCO 上获得了<strong class="kh ir">实例段提议</strong>的竞争结果。发表在<strong class="kh ir"> 2016 ECCV </strong>上，被引用<strong class="kh ir"> 100 多次</strong>。(<a class="ll lm ep" href="https://medium.com/u/aff72a0c1243?source=post_page-----dbfe67d4ee92--------------------------------" rel="noopener" target="_blank"> Sik-Ho Tsang </a> @中)</p></div><div class="ab cl ln lo hu lp" role="separator"><span class="lq bw bk lr ls lt"/><span class="lq bw bk lr ls lt"/><span class="lq bw bk lr ls"/></div><div class="ij ik il im in"><h1 id="612e" class="lu lv iq bd lw lx ly lz ma mb mc md me jw mf jx mg jz mh ka mi kc mj kd mk ml bi translated">涵盖哪些内容</h1><ol class=""><li id="ef3a" class="mm mn iq kh b ki mo kl mp ko mq ks mr kw ms la mt mu mv mw bi translated"><strong class="kh ir">网络结构</strong></li><li id="8b34" class="mm mn iq kh b ki mx kl my ko mz ks na kw nb la mt mu mv mw bi translated"><strong class="kh ir">实例敏感得分图</strong></li><li id="2017" class="mm mn iq kh b ki mx kl my ko mz ks na kw nb la mt mu mv mw bi translated"><strong class="kh ir">消融研究</strong></li><li id="fb7e" class="mm mn iq kh b ki mx kl my ko mz ks na kw nb la mt mu mv mw bi translated"><strong class="kh ir">结果</strong></li></ol></div><div class="ab cl ln lo hu lp" role="separator"><span class="lq bw bk lr ls lt"/><span class="lq bw bk lr ls lt"/><span class="lq bw bk lr ls"/></div><div class="ij ik il im in"><h1 id="46d3" class="lu lv iq bd lw lx ly lz ma mb mc md me jw mf jx mg jz mh ka mi kc mj kd mk ml bi translated">1.网络结构</h1><figure class="nd ne nf ng gt nh gh gi paragraph-image"><div role="button" tabindex="0" class="ni nj di nk bf nl"><div class="gh gi nc"><img src="../Images/623d741d78f777d1739d534d731bcc1e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*xXecc1960tCfk2mMXIaekA.png"/></div></div><figcaption class="no np gj gh gi nq nr bd b be z dk"><strong class="bd ns">Network Structure</strong></figcaption></figure><ul class=""><li id="114f" class="mm mn iq kh b ki kj kl km ko nt ks nu kw nv la nw mu mv mw bi translated">使用 ImageNet 上预先训练的<a class="ae lk" href="https://medium.com/coinmonks/paper-review-of-vggnet-1st-runner-up-of-ilsvlc-2014-image-classification-d02355543a11" rel="noopener"><strong class="kh ir">【VGG-16】</strong></a><strong class="kh ir">作为特征提取器。</strong>最大池层 pool4 从跨距 2 修改为跨距 1。相应地，conv5_1 至 conv5_3 由<strong class="kh ir"> hole 算法</strong>调整，该算法以前由<a class="ae lk" rel="noopener" target="_blank" href="/review-deeplabv1-deeplabv2-atrous-convolution-semantic-segmentation-b51c5fbde92d">deep lab</a>&amp;<a class="ae lk" rel="noopener" target="_blank" href="/review-dilated-convolution-semantic-segmentation-9d5a5bd768f5">dilated net</a>使用，以便<strong class="kh ir">减小输出步幅，即增大输出特征图尺寸</strong>。</li><li id="f05c" class="mm mn iq kh b ki mx kl my ko mz ks na kw nb la nw mu mv mw bi translated">在特征图的顶部，有<strong class="kh ir">两个完全卷积分支</strong>、<strong class="kh ir">一个用于估计片段实例</strong>和<strong class="kh ir">另一个用于对实例进行评分</strong>。</li></ul><h2 id="733f" class="nx lv iq bd lw ny nz dn ma oa ob dp me ko oc od mg ks oe of mi kw og oh mk oi bi translated"><strong class="ak">对实例敏感的分数映射分支</strong></h2><ul class=""><li id="ed5b" class="mm mn iq kh b ki mo kl mp ko mq ks mr kw ms la nw mu mv mw bi translated">对于<strong class="kh ir">第一个分支</strong>(顶部路径)，我们采用 1×1 的 512-d 卷积层进行特征变换，然后用 3×3 的卷积层生成<strong class="kh ir">一组<em class="oj"> k </em>实例敏感评分图</strong>，也就是<strong class="kh ir"> <em class="oj"> k </em>输出通道</strong>。(<em class="oj"> k </em> =5 最后。)</li><li id="e209" class="mm mn iq kh b ki mx kl my ko mz ks na kw nb la nw mu mv mw bi translated">组装模块用于在分辨率为<em class="oj"> m </em> × <em class="oj"> m </em>的滑动窗口中生成对象实例。(<em class="oj"> m </em> =21 此处。)</li><li id="166b" class="mm mn iq kh b ki mx kl my ko mz ks na kw nb la nw mu mv mw bi translated">这个想法非常类似于<a class="ae lk" rel="noopener" target="_blank" href="/review-r-fcn-positive-sensitive-score-maps-object-detection-91cd2389345c"> R-FCN </a>中的阳性敏感得分图。但是<strong class="kh ir"/><a class="ae lk" rel="noopener" target="_blank" href="/review-r-fcn-positive-sensitive-score-maps-object-detection-91cd2389345c"><strong class="kh ir">R-FCN</strong></a><strong class="kh ir">使用正面敏感得分图进行对象检测</strong>，而<strong class="kh ir"> InstanceFCN 使用实例敏感得分图来生成建议</strong>。</li></ul><h2 id="de64" class="nx lv iq bd lw ny nz dn ma oa ob dp me ko oc od mg ks oe of mi kw og oh mk oi bi translated"><strong class="ak">客观分数映射分支</strong></h2><ul class=""><li id="2787" class="mm mn iq kh b ki mo kl mp ko mq ks mr kw ms la nw mu mv mw bi translated">对于<strong class="kh ir">评分实例</strong>的<strong class="kh ir">第二分支</strong>(底部路径)，我们使用 3×3 的 512-d 卷积层，后跟 1×1 的卷积层。这个 1×1 层是针对以该像素为中心的滑动窗口的<strong class="kh ir">分类实例/非实例</strong>的每像素逻辑回归。因此，这是一个<strong class="kh ir">客观分数图</strong>。</li></ul><h2 id="caf3" class="nx lv iq bd lw ny nz dn ma oa ob dp me ko oc od mg ks oe of mi kw og oh mk oi bi translated">损失函数</h2><figure class="nd ne nf ng gt nh gh gi paragraph-image"><div class="gh gi ok"><img src="../Images/5c7729e54679f06f36b2dccd3abb20b5.png" data-original-src="https://miro.medium.com/v2/resize:fit:870/format:webp/1*iEBISyDOILqdHABJfwlNTQ.png"/></div></figure><ul class=""><li id="d390" class="mm mn iq kh b ki kj kl km ko nt ks nu kw nv la nw mu mv mw bi translated">这里<em class="oj"> i </em>是采样窗口的索引，<em class="oj"> pi </em>是该窗口中实例的预测客观分数，如果该窗口是正样本，则<em class="oj"> pi </em>为 1，如果是负样本，则为 0。<em class="oj"> Si </em>是该窗口中组装的线段实例，<em class="oj"> Si </em>是地面真实线段实例，<em class="oj"> j </em>是该窗口中的像素索引。<em class="oj"> L </em>是 logistic 回归损失。</li><li id="380a" class="mm mn iq kh b ki mx kl my ko mz ks na kw nb la nw mu mv mw bi translated">256 个采样窗口具有 1∶1 的正/负采样比。</li></ul></div><div class="ab cl ln lo hu lp" role="separator"><span class="lq bw bk lr ls lt"/><span class="lq bw bk lr ls lt"/><span class="lq bw bk lr ls"/></div><div class="ij ik il im in"><h1 id="7118" class="lu lv iq bd lw lx ly lz ma mb mc md me jw mf jx mg jz mh ka mi kc mj kd mk ml bi translated"><strong class="ak"> 2。实例敏感得分图</strong></h1><h2 id="bc2f" class="nx lv iq bd lw ny nz dn ma oa ob dp me ko oc od mg ks oe of mi kw og oh mk oi bi translated">2.1.与<a class="ae lk" rel="noopener" target="_blank" href="/review-fcn-semantic-segmentation-eb8c9b50d2d1">相比，FCN </a></h2><figure class="nd ne nf ng gt nh gh gi paragraph-image"><div role="button" tabindex="0" class="ni nj di nk bf nl"><div class="gh gi ol"><img src="../Images/17f237cc364ea04d8c2482d4118a1957.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*jh_GtjMU7pd48Yd935iC7A.png"/></div></div><figcaption class="no np gj gh gi nq nr bd b be z dk"><strong class="bd ns">Top: FCN, Bottom: InstanceFCN (k=3)</strong></figcaption></figure><ul class=""><li id="1a7b" class="mm mn iq kh b ki kj kl km ko nt ks nu kw nv la nw mu mv mw bi translated">在<a class="ae lk" rel="noopener" target="_blank" href="/review-fcn-semantic-segmentation-eb8c9b50d2d1"> FCN </a>(上)中，当两个人靠得太近时，生成的比分图很难让他们分开。</li><li id="e1fa" class="mm mn iq kh b ki mx kl my ko mz ks na kw nb la nw mu mv mw bi translated">但是，使用 InstanceFCN(底部)，每个分数贴图负责捕捉对象实例的相对位置。例如:左上分数图负责捕捉对象实例的左上部分。组装后，可以生成分离的人物面具。</li><li id="e408" class="mm mn iq kh b ki mx kl my ko mz ks na kw nb la nw mu mv mw bi translated">下面显示了一些带有<em class="oj"> k </em> =3 的实例遮罩示例:</li></ul><figure class="nd ne nf ng gt nh gh gi paragraph-image"><div role="button" tabindex="0" class="ni nj di nk bf nl"><div class="gh gi om"><img src="../Images/2bd0c526fae42c4c74d272f86b1696a5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*o4uSQm-9Kpd2UYWhpeOkvw.png"/></div></div><figcaption class="no np gj gh gi nq nr bd b be z dk"><strong class="bd ns">Some examples of instance masks with <em class="on">k</em>=3</strong></figcaption></figure><h2 id="bef4" class="nx lv iq bd lw ny nz dn ma oa ob dp me ko oc od mg ks oe of mi kw og oh mk oi bi translated">2.2.与<a class="ae lk" rel="noopener" target="_blank" href="/review-deepmask-instance-segmentation-30327a072339">深掩模</a>相比</h2><figure class="nd ne nf ng gt nh gh gi paragraph-image"><div role="button" tabindex="0" class="ni nj di nk bf nl"><div class="gh gi oo"><img src="../Images/04e6bbe91683c44bd4acd77faaf5e0d3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*k6KNM90qms_knb8HF951_Q.png"/></div></div><figcaption class="no np gj gh gi nq nr bd b be z dk"><strong class="bd ns">DeepMask</strong></figcaption></figure><ul class=""><li id="30ca" class="mm mn iq kh b ki kj kl km ko nt ks nu kw nv la nw mu mv mw bi translated">在<a class="ae lk" rel="noopener" target="_blank" href="/review-deepmask-instance-segmentation-30327a072339">深度蒙版</a>中，使用了 FC 层，使得模型变大。</li><li id="af8e" class="mm mn iq kh b ki mx kl my ko mz ks na kw nb la nw mu mv mw bi translated">在 InstanceFCN 中，没有 FC 层，这使得模型更加紧凑。</li></ul><h1 id="5f26" class="lu lv iq bd lw lx op lz ma mb oq md me jw or jx mg jz os ka mi kc ot kd mk ml bi translated">3.消融研究</h1><figure class="nd ne nf ng gt nh gh gi paragraph-image"><div class="gh gi ou"><img src="../Images/a12cccc2572a6665d46020aa981f917f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1134/format:webp/1*AK5Na-r5_cXAA38l1e0Xbg.png"/></div><figcaption class="no np gj gh gi nq nr bd b be z dk"><strong class="bd ns">Average Recall with Different k</strong></figcaption></figure><ul class=""><li id="7f23" class="mm mn iq kh b ki kj kl km ko nt ks nu kw nv la nw mu mv mw bi translated">平均召回率(AR)是在 10，100，1000 个提议下测量的。</li><li id="b9d0" class="mm mn iq kh b ki mx kl my ko mz ks na kw nb la nw mu mv mw bi translated"><em class="oj"> k </em> =5 和<em class="oj"> k </em> =7 具有可比性。以及下面实验中的<em class="oj"> k </em> =5。</li></ul><figure class="nd ne nf ng gt nh gh gi paragraph-image"><div role="button" tabindex="0" class="ni nj di nk bf nl"><div class="gh gi ov"><img src="../Images/65f012d8f25a856154f948b1ef205e2d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*4hXwli6qi4NIVmVj-3q4Tw.png"/></div></div><figcaption class="no np gj gh gi nq nr bd b be z dk"><strong class="bd ns">Train and Test Image Sizes</strong></figcaption></figure><ul class=""><li id="a643" class="mm mn iq kh b ki kj kl km ko nt ks nu kw nv la nw mu mv mw bi translated"><strong class="kh ir">~深度屏蔽</strong>:作者实现的<a class="ae lk" rel="noopener" target="_blank" href="/review-deepmask-instance-segmentation-30327a072339">深度屏蔽</a>。<strong class="kh ir">使用 2 个 FC 层需要 53M 个参数。(</strong>512×14×14×512+512×56 = 53M<strong class="kh ir">)</strong></li><li id="9158" class="mm mn iq kh b ki mx kl my ko mz ks na kw nb la nw mu mv mw bi translated">发现使用<strong class="kh ir">全尺寸图像进行训练</strong>具有高得多的<strong class="kh ir">AR</strong>。而<strong class="kh ir">最后的 k -d 卷积层只有 0.1M 的参数</strong>。(512×3×3×25 = 0.1 米)</li></ul><h1 id="01b2" class="lu lv iq bd lw lx op lz ma mb oq md me jw or jx mg jz os ka mi kc ot kd mk ml bi translated">4.结果</h1><h2 id="189c" class="nx lv iq bd lw ny nz dn ma oa ob dp me ko oc od mg ks oe of mi kw og oh mk oi bi translated">4.1.帕斯卡 VOC 2012</h2><figure class="nd ne nf ng gt nh gh gi paragraph-image"><div role="button" tabindex="0" class="ni nj di nk bf nl"><div class="gh gi ow"><img src="../Images/e72e6d9ca2490fc9891b1a773d18aec9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*zXhSdLG2Jmu9t0UvU7xCUQ.png"/></div></div><figcaption class="no np gj gh gi nq nr bd b be z dk"><strong class="bd ns">Segment Proposals on PASCAL VOC 2012 Validation Set</strong></figcaption></figure><figure class="nd ne nf ng gt nh gh gi paragraph-image"><div role="button" tabindex="0" class="ni nj di nk bf nl"><div class="gh gi ox"><img src="../Images/9e32b6b5e3ab1fc656efaabebe2efcfc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*RLu6S2HLhK-glT3uAu1GUw.png"/></div></div><figcaption class="no np gj gh gi nq nr bd b be z dk"><strong class="bd ns">Recall vs IoU</strong></figcaption></figure><ul class=""><li id="e65f" class="mm mn iq kh b ki kj kl km ko nt ks nu kw nv la nw mu mv mw bi translated">InstanceFCN 是<strong class="kh ir">好多了 SS(选择性搜索)和</strong><a class="ae lk" rel="noopener" target="_blank" href="/review-deepmask-instance-segmentation-30327a072339"><strong class="kh ir">deep mask</strong></a>。</li><li id="b689" class="mm mn iq kh b ki mx kl my ko mz ks na kw nb la nw mu mv mw bi translated">InstanceFCN 在 AR@10 时的 AR 比<a class="ae lk" rel="noopener" target="_blank" href="/review-mnc-multi-task-network-cascade-winner-in-2015-coco-segmentation-instance-segmentation-42a9334e6a34"><strong class="kh ir">MNC</strong></a><strong class="kh ir">高<strong class="kh ir">，在 AR@100 和 AR@1000 </strong>时的 AR 也与</strong><a class="ae lk" rel="noopener" target="_blank" href="/review-mnc-multi-task-network-cascade-winner-in-2015-coco-segmentation-instance-segmentation-42a9334e6a34"><strong class="kh ir">MNC</strong></a><strong class="kh ir">不相上下。</strong></li></ul><figure class="nd ne nf ng gt nh gh gi paragraph-image"><div role="button" tabindex="0" class="ni nj di nk bf nl"><div class="gh gi oy"><img src="../Images/022a4d5790327267d362030e9db3739a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*x3e_83jBsRamhQqmbrZgbQ.png"/></div></div><figcaption class="no np gj gh gi nq nr bd b be z dk"><strong class="bd ns">Instance Segmentation on PASCAL VOC 2012 Validation Set (N = 300 Proposals)</strong></figcaption></figure><p id="4e8f" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">使用 InstanceFCN 为<a class="ae lk" rel="noopener" target="_blank" href="/review-mnc-multi-task-network-cascade-winner-in-2015-coco-segmentation-instance-segmentation-42a9334e6a34"> MNC </a>生成建议，它具有与<a class="ae lk" rel="noopener" target="_blank" href="/review-mnc-multi-task-network-cascade-winner-in-2015-coco-segmentation-instance-segmentation-42a9334e6a34"> MNC </a>相当的映射。(<a class="ae lk" rel="noopener" target="_blank" href="/review-mnc-multi-task-network-cascade-winner-in-2015-coco-segmentation-instance-segmentation-42a9334e6a34"> MNC </a>目前是并发作品。)</p><h2 id="7c00" class="nx lv iq bd lw ny nz dn ma oa ob dp me ko oc od mg ks oe of mi kw og oh mk oi bi translated">4.2.可可女士</h2><figure class="nd ne nf ng gt nh gh gi paragraph-image"><div role="button" tabindex="0" class="ni nj di nk bf nl"><div class="gh gi oz"><img src="../Images/d0977e10ffe624e0faa092ce435442e3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*tlNqEQMY79_iZagddhyeRg.png"/></div></div><figcaption class="no np gj gh gi nq nr bd b be z dk"><strong class="bd ns">Segment Proposals on the First 5k Images of MS COCO Validation Set</strong></figcaption></figure><figure class="nd ne nf ng gt nh gh gi paragraph-image"><div role="button" tabindex="0" class="ni nj di nk bf nl"><div class="gh gi pa"><img src="../Images/2e79958dac08d64ad350b8839b037f0e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*z5Zw0-EeiJEGXMWYhehCgg.png"/></div></div><figcaption class="no np gj gh gi nq nr bd b be z dk"><strong class="bd ns">Recall vs IoU</strong></figcaption></figure><ul class=""><li id="b0de" class="mm mn iq kh b ki kj kl km ko nt ks nu kw nv la nw mu mv mw bi translated">InstanceFCN 的 ARs 比<a class="ae lk" rel="noopener" target="_blank" href="/review-deepmask-instance-segmentation-30327a072339"> DeepMask </a>和<a class="ae lk" rel="noopener" target="_blank" href="/review-deepmask-instance-segmentation-30327a072339"> DeepMaskZoom </a>高。</li></ul><figure class="nd ne nf ng gt nh gh gi paragraph-image"><div role="button" tabindex="0" class="ni nj di nk bf nl"><div class="gh gi pb"><img src="../Images/64e7a5d500fbe8132b9f5d85fc7942f0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*X8ylBh2gq6ivMYt9yAZy0Q.png"/></div></div><figcaption class="no np gj gh gi nq nr bd b be z dk"><strong class="bd ns">Comparisons with DeepMask on MS COCO Validation Set</strong></figcaption></figure><figure class="nd ne nf ng gt nh gh gi paragraph-image"><div role="button" tabindex="0" class="ni nj di nk bf nl"><div class="gh gi pc"><img src="../Images/4bfae30dfa4f1d85443254eefd314522.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*-mTsfGx0v1tY29qZT78-Gw.png"/></div></div><figcaption class="no np gj gh gi nq nr bd b be z dk"><strong class="bd ns">More Examples on MS COCO validation set</strong></figcaption></figure></div><div class="ab cl ln lo hu lp" role="separator"><span class="lq bw bk lr ls lt"/><span class="lq bw bk lr ls lt"/><span class="lq bw bk lr ls"/></div><div class="ij ik il im in"><h2 id="f1f6" class="nx lv iq bd lw ny nz dn ma oa ob dp me ko oc od mg ks oe of mi kw og oh mk oi bi translated">参考</h2><p id="5118" class="pw-post-body-paragraph kf kg iq kh b ki mo jr kk kl mp ju kn ko pd kq kr ks pe ku kv kw pf ky kz la ij bi translated">【2016 ECCV】【Instance fcn】<br/><a class="ae lk" href="https://arxiv.org/abs/1603.08678" rel="noopener ugc nofollow" target="_blank">实例敏感全卷积网络</a></p><h2 id="4cb3" class="nx lv iq bd lw ny nz dn ma oa ob dp me ko oc od mg ks oe of mi kw og oh mk oi bi translated">我的相关评论</h2><p id="4da9" class="pw-post-body-paragraph kf kg iq kh b ki mo jr kk kl mp ju kn ko pd kq kr ks pe ku kv kw pf ky kz la ij bi translated">)(我)(们)(都)(不)(想)(到)(这)(些)(人)(,)(我)(们)(都)(不)(想)(要)(到)(这)(些)(人)(,)(但)(是)(这)(些)(人)(还)(不)(想)(到)(这)(些)(人)(,)(我)(们)(还)(没)(想)(到)(这)(些)(事)(,)(我)(们)(就)(想)(到)(了)(这)(些)(人)(们)(,)(我)(们)(们)(都)(不)(想)(要)(到)(这)(些)(人)(,)(但)(我)(们)(还)(没)(想)(到)(这)(些)(事)(,)(我)(们)(还)(没)(想)(到)(这)(里)(来)(。 )(我)(们)(都)(不)(知)(道)(,)(我)(们)(还)(是)(不)(知)(道)(,)(我)(们)(还)(是)(不)(知)(道)(,)(我)(们)(还)(是)(不)(知)(道)(,)(我)(们)(还)(是)(不)(知)(道)(,)(我)(们)(还)(是)(不)(知)(道)(,)(我)(们)(还)(是)(不)(知)(道)(,)(我)(们)(还)(是)(不)(知)(道)(。</p><p id="8b77" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir">物体检测<br/></strong><a class="ae lk" href="https://medium.com/coinmonks/review-of-overfeat-winner-of-ilsvrc-2013-localization-task-object-detection-a6f8b9044754" rel="noopener">过食</a><a class="ae lk" href="https://medium.com/coinmonks/review-r-cnn-object-detection-b476aba290d1" rel="noopener">R-CNN</a><a class="ae lk" href="https://medium.com/coinmonks/review-fast-r-cnn-object-detection-a82e172e87ba" rel="noopener">快 R-CNN</a><a class="ae lk" rel="noopener" target="_blank" href="/review-faster-r-cnn-object-detection-f5685cb30202">快 R-CNN</a><a class="ae lk" rel="noopener" target="_blank" href="/review-deepid-net-def-pooling-layer-object-detection-f72486f1a0f6">DeepID-Net</a><a class="ae lk" rel="noopener" target="_blank" href="/review-r-fcn-positive-sensitive-score-maps-object-detection-91cd2389345c">R-FCN</a>】<a class="ae lk" rel="noopener" target="_blank" href="/review-ion-inside-outside-net-2nd-runner-up-in-2015-coco-detection-object-detection-da19993f4766">离子</a><a class="ae lk" rel="noopener" target="_blank" href="/review-multipath-mpn-1st-runner-up-in-2015-coco-detection-segmentation-object-detection-ea9741e7c413">多路</a><a class="ae lk" rel="noopener" target="_blank" href="/review-ssd-single-shot-detector-object-detection-851a94607d11">SSD</a><a class="ae lk" rel="noopener" target="_blank" href="/review-dssd-deconvolutional-single-shot-detector-object-detection-d4821a2bbeb5">DSSD</a></p><p id="6582" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir">语义切分<br/></strong>[<a class="ae lk" rel="noopener" target="_blank" href="/review-fcn-semantic-segmentation-eb8c9b50d2d1">FCN</a>][<a class="ae lk" rel="noopener" target="_blank" href="/review-deconvnet-unpooling-layer-semantic-segmentation-55cf8a6e380e">de convnet</a>][<a class="ae lk" rel="noopener" target="_blank" href="/review-deeplabv1-deeplabv2-atrous-convolution-semantic-segmentation-b51c5fbde92d">deeplab v1&amp;deeplab v2</a>][<a class="ae lk" href="https://medium.com/datadriveninvestor/review-parsenet-looking-wider-to-see-better-semantic-segmentation-aa6b6a380990" rel="noopener">parse net</a>][<a class="ae lk" rel="noopener" target="_blank" href="/review-dilated-convolution-semantic-segmentation-9d5a5bd768f5">dilated net</a>][<a class="ae lk" rel="noopener" target="_blank" href="/review-pspnet-winner-in-ilsvrc-2016-semantic-segmentation-scene-parsing-e089e5df177d">PSPNet</a>]</p><p id="bd29" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir">实例分割<br/></strong><a class="ae lk" rel="noopener" target="_blank" href="/review-deepmask-instance-segmentation-30327a072339">深度屏蔽</a><a class="ae lk" rel="noopener" target="_blank" href="/review-sharpmask-instance-segmentation-6509f7401a61">锐度屏蔽</a><a class="ae lk" rel="noopener" target="_blank" href="/review-multipath-mpn-1st-runner-up-in-2015-coco-detection-segmentation-object-detection-ea9741e7c413">多路径</a><a class="ae lk" rel="noopener" target="_blank" href="/review-mnc-multi-task-network-cascade-winner-in-2015-coco-segmentation-instance-segmentation-42a9334e6a34">MNC</a>]</p></div></div>    
</body>
</html>