<html>
<head>
<title>Recurrent Neural Networks: Deep Learning for NLP</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">递归神经网络:NLP 的深度学习</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/recurrent-neural-networks-deep-learning-for-nlp-37baa188aef5?source=collection_archive---------9-----------------------#2019-02-23">https://towardsdatascience.com/recurrent-neural-networks-deep-learning-for-nlp-37baa188aef5?source=collection_archive---------9-----------------------#2019-02-23</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="03bf" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">这篇文章涵盖了不同类型的 RNN，包括 LSTM 和 CRF 网络</h2></div><p id="a495" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">每当你问<em class="le"> Alexa </em>一道菜的配方或一位艺术家的新歌时，一个复杂的代码就会在后台运行，为你提供相关的答案。这只是在最近几年才成为可能。到目前为止，从非结构化文本数据中理解和提取信息只能通过手工操作，更不用说自动确认用户请求了。</p><figure class="lg lh li lj gt lk gh gi paragraph-image"><div role="button" tabindex="0" class="ll lm di ln bf lo"><div class="gh gi lf"><img src="../Images/1a65816ee0f5a4874a6186c7254889fe.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ZkSCDZPtrZcJNJh3puOD3w.jpeg"/></div></div><figcaption class="lr ls gj gh gi lt lu bd b be z dk">Image by Author</figcaption></figure><p id="85a0" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">将文本数据暴露给各种数学和统计技术的革命性想法背后的基本概念是自然语言处理(NLP)。顾名思义，目标是理解人类所说的自然语言，并在此基础上做出响应和/或采取行动，就像人类一样。不久，改变生活的决定将仅仅通过与机器人交谈来做出。</p><p id="3ed3" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在本文中，我将尝试提供对神经网络的一些基本理解，这对 NLP 的目的特别有用。我们不会深入研究每种算法的数学原理，但是，我们会尝试理解其背后的直觉，这将使我们处于一个舒适的位置，开始将每种算法应用于现实世界的数据。</p><p id="33ba" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我们开始吧。</p><p id="5f4b" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="kk iu">递归神经网络(RNN) </strong></p><p id="b78d" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">RNN 是广泛用于自然语言处理的神经网络结构。在建立语言模型和语音识别任务中，它被证明是相对准确和有效的。</p><p id="c1b7" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">如果预测必须在单词级别，例如命名实体识别(NER)或词性(POS)标注，rnn 特别有用。因为它存储了当前特征以及用于预测的相邻特征的信息。RNN 维护基于历史信息的记忆，这使得模型能够预测基于长距离特征的当前输出。下面是 NER 使用 RNN 的一个例子。</p><figure class="lg lh li lj gt lk gh gi paragraph-image"><div class="gh gi lv"><img src="../Images/897e0747f9305e6e3e59f056771a16da.png" data-original-src="https://miro.medium.com/v2/resize:fit:644/format:webp/1*r8ksKFC1V_4OFGLgJn0Rrw.png"/></div><figcaption class="lr ls gj gh gi lt lu bd b be z dk"><strong class="bd lw">Recurrent Neural Network (RNN) — </strong>Image by Author</figcaption></figure><p id="6ac3" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="kk iu">长短期记忆细胞(LSTM) </strong></p><p id="048b" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">尽管 RNN 可以学习依赖性，但是它只能学习最近的信息。LSTM 可以帮助解决这个问题，因为它可以理解上下文以及最近的依赖性。因此，LSTM 是一种特殊的 RNN，在这种情况下，理解背景会有所帮助。</p><p id="e989" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">LSTM 网络类似于 rnn，一个主要区别是隐藏层更新由存储单元代替。这使他们更善于发现和揭示数据中的长期依赖关系，这对句子结构是必不可少的。下图显示了 LSTM 序列标签模型的表示，该模型用 LSTM 记忆单元代替了隐藏层。</p><figure class="lg lh li lj gt lk gh gi paragraph-image"><div class="gh gi lx"><img src="../Images/cb90c0da85b2cb6c59efdd9a1b3ada3c.png" data-original-src="https://miro.medium.com/v2/resize:fit:728/format:webp/1*vE1YvriNKuiuAH_oAs8EGg.png"/></div><figcaption class="lr ls gj gh gi lt lu bd b be z dk"><strong class="bd lw">LSTM network — </strong>Image by Author</figcaption></figure><p id="bd31" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="kk iu">双向 LSTM 网络</strong></p><p id="1a4f" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">顾名思义，这些网络是双向的，也就是说，在给定时间内，它可以访问过去和未来的输入要素。这在序列标记中尤其重要。</p><figure class="lg lh li lj gt lk gh gi paragraph-image"><div class="gh gi ly"><img src="../Images/e6808e7e6f594e0dad9f2a0f7e174671.png" data-original-src="https://miro.medium.com/v2/resize:fit:646/format:webp/1*jNXows1TTuJmfTLG1qqqhg.png"/></div><figcaption class="lr ls gj gh gi lt lu bd b be z dk"><strong class="bd lw">Bidirectional LSTM — </strong>Image by Author</figcaption></figure><p id="7598" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="kk iu"> CRF 网络</strong></p><p id="e870" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">条件随机场(CRF)在进行预测时会考虑上下文。BiLSTM 和 CRF 的区别在于前者使用两个方向的输入特征，而后者使用标签生成。这里，输入和输出是直接相连的，而不是 LSTMs 网络。此外，如下所示，连接的是输出标签信息，而不是输入要素。</p><figure class="lg lh li lj gt lk gh gi paragraph-image"><div class="gh gi lz"><img src="../Images/f00a437598bc3b4aede4cfceabcdce09.png" data-original-src="https://miro.medium.com/v2/resize:fit:508/format:webp/1*-NJgV46FliCYTM-BFE-T2Q.png"/></div><figcaption class="lr ls gj gh gi lt lu bd b be z dk"><strong class="bd lw">CRF network — </strong>Image by Author</figcaption></figure><p id="1cf3" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="kk iu"> LSTM-CRF 网络</strong></p><p id="4968" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">该网络是 LSTM 和 CRF 网络的结合，利用了两者的优点。该网络可以通过 LSTM 层有效地使用过去的输入特征，并通过 CRF 层有效地使用句子级标签信息。</p><figure class="lg lh li lj gt lk gh gi paragraph-image"><div class="gh gi ma"><img src="../Images/168de213c5091ee3c3430fadf5440a76.png" data-original-src="https://miro.medium.com/v2/resize:fit:620/format:webp/1*uJNYiwKRDuoSV4MlFh3Y7A.png"/></div><figcaption class="lr ls gj gh gi lt lu bd b be z dk"><strong class="bd lw">LSTM-CRF model — </strong>Image by Author</figcaption></figure><p id="1c92" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="kk iu">双 LSTM-CRF 网络</strong></p><p id="3895" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">该网络与之前的网络相似，唯一的区别是 LSTM 网络被双 LSTM 网络所取代，从而实现了更高的性能。正如我们已经知道的，双 LSTM 使用过去和未来的输入特征，这有助于提高标记的准确性。</p><figure class="lg lh li lj gt lk gh gi paragraph-image"><div role="button" tabindex="0" class="ll lm di ln bf lo"><div class="gh gi mb"><img src="../Images/2db47aa4b7e2ca7f26dfd44b1a9b3652.png" data-original-src="https://miro.medium.com/v2/resize:fit:626/format:webp/1*s3pg7ZpafRz4CAhVB6id6w.png"/></div></div><figcaption class="lr ls gj gh gi lt lu bd b be z dk"><strong class="bd lw">BiLSTM-CRF model — </strong>Image by Author</figcaption></figure><p id="7f06" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">这提供了可以应用于文本数据的深度学习网络的基本思想。下一个合理的步骤是获取一些文本数据并开始实现这些算法，以查看真实的结果并进行比较，这是我将在下一篇文章中讨论的内容。敬请关注。</p></div></div>    
</body>
</html>