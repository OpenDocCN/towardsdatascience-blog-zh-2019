<html>
<head>
<title>Efficient Products Clustering Can Drive Retail Sales</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">高效的产品集群可以推动零售销售</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/clustering-machine-learning-combination-in-sales-prediction-330a7a205102?source=collection_archive---------7-----------------------#2019-10-18">https://towardsdatascience.com/clustering-machine-learning-combination-in-sales-prediction-330a7a205102?source=collection_archive---------7-----------------------#2019-10-18</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><h2 id="aea3" class="ir is it bd b dl iu iv iw ix iy iz dk ja translated" aria-label="kicker paragraph">无监督学习和统计分析</h2><div class=""/><div class=""><h2 id="c311" class="pw-subtitle-paragraph jz jc it bd b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq dk translated">零售业的聚类与库存预测</h2></div><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi kr"><img src="../Images/541de11432a6f4bde6f6f7b5a76acb26.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Oza1ACPFNiMwE0KxSm2dzA.png"/></div></div><figcaption class="ld le gj gh gi lf lg bd b be z dk">Image by author</figcaption></figure><p id="3d66" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated"><a class="ae md" href="https://sarit-maitra.medium.com/membership" rel="noopener">https://sarit-maitra.medium.com/membership</a></p><p id="928b" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi me translated"><span class="l mf mg mh bm mi mj mk ml mm di">对未来的预测是商业中必不可少的组成部分。这些技术的有效实施导致成功的客户关系管理(CRM) &amp;商业中的库存管理。通常用作数据挖掘技术的聚类有助于发现数据中有趣的模式。</span></p><p id="e175" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">尽管我们谈论的是 CRM 和库存管理，但是，集群已经成为高级规划和优化流程的主要来源，并且可以在多个方面使业务受益:</p><ol class=""><li id="8c86" class="mn mo it lj b lk ll ln lo lq mp lu mq ly mr mc ms mt mu mv bi translated"><em class="mw">商店聚类根据绩效和非绩效参数对商店进行分组。</em></li><li id="6557" class="mn mo it lj b lk mx ln my lq mz lu na ly nb mc ms mt mu mv bi translated"><em class="mw">减少不必要的库存</em></li><li id="8f7f" class="mn mo it lj b lk mx ln my lq mz lu na ly nb mc ms mt mu mv bi translated"><em class="mw">关注目标细分市场</em></li><li id="586a" class="mn mo it lj b lk mx ln my lq mz lu na ly nb mc ms mt mu mv bi translated"><em class="mw">以客户为中心的方法创造一致性和熟悉度</em></li></ol><p id="3e66" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">我们将研究销售交易数据，并根据历史记录分析和预测交易。这里，数据是高层次的，不考虑每笔交易的金额和其他业务因素..数据集包含 1 年/ 52 周内每周购买的 800 件产品。</p><pre class="ks kt ku kv gt nc nd ne nf aw ng bi"><span id="43fe" class="nh ni it nd b gy nj nk l nl nm">df &lt;- read.csv("Sales_Transactions_Dataset_Weekly.csv", header = TRUE)<br/>print(is.data.frame(df))<br/>print(ncol(df))<br/>print(nrow(df))<br/>print(names(df))</span></pre><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi nn"><img src="../Images/2b51b0e1d090e9758c392dbde37ea7e1.png" data-original-src="https://miro.medium.com/v2/resize:fit:274/format:webp/1*HaDYh--m5mHQUxjdwQUtuw.png"/></div></figure><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi no"><img src="../Images/5bbf9fdf88138a61b1b889d55d43ceca.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Qr6KCPnUKy9l0YJA3kOxJQ.png"/></div></div></figure><pre class="ks kt ku kv gt nc nd ne nf aw ng bi"><span id="a6a4" class="nh ni it nd b gy nj nk l nl nm"># number of weeks<br/>DF &lt;- data.frame(df[, 2:53], row.names = df$Product_Code)<br/>print(names(DF));</span><span id="aae0" class="nh ni it nd b gy np nk l nl nm">#Check whether there is missing value.<br/>print(sum(is.na(DF)))</span></pre><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi nq"><img src="../Images/ff564a0d66ad01fe6853b28674c18764.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*yvT567NXCECsKJK1u3o9-A.png"/></div></div></figure><p id="c3a8" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">我们在这个数据集中有 800 种产品，分析所有 800 种产品的数据是不切实际的。因此，让我们根据 52 周内交易的相似性将产品分类。</p><p id="cdee" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">我们将使用无监督学习进行聚类。</p><h2 id="b08b" class="nh ni it bd nr ns nt dn nu nv nw dp nx lq ny nz oa lu ob oc od ly oe of og iz bi translated">聚类:</h2><p id="b033" class="pw-post-body-paragraph lh li it lj b lk oh kd lm ln oi kg lp lq oj ls lt lu ok lw lx ly ol ma mb mc im bi translated">这是一个优化问题。为了进行优化，我们需要根据最小距离进行决策，或者根据约束条件确定聚类的数量。在这里，我们将使用一些集群。因为在我们开始算法之前必须设置聚类的数量(k ),所以让我们用几个不同的 k 值进行尝试，并检查结果中的差异。</p><p id="ba0e" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">可以定义上述内容的标准算法是—</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi om"><img src="../Images/0d8be6bd26db6626f696e09b2f6a32f4.png" data-original-src="https://miro.medium.com/v2/resize:fit:688/format:webp/1*rv8CIORGeoU4DhObhIU2Kw.png"/></div></figure><p id="c1e2" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">其中:xi 是属于聚类 Ck 的数据点，μk 是分配给聚类 Ck 的点的平均值。每个观测 xi 被分配给给定的聚类，使得观测到它们被分配的聚类中心μk 的距离平方和最小。</p><p id="5ff1" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">现在，有相当多的聚类算法可用，但没有简单的方法为我们的数据找到正确的算法。我们必须进行实验，为任何给定的数据集找到最适合的算法。</p><h2 id="3e01" class="nh ni it bd nr ns nt dn nu nv nw dp nx lq ny nz oa lu ob oc od ly oe of og iz bi translated">主成分分析:</h2><pre class="ks kt ku kv gt nc nd ne nf aw ng bi"><span id="34ef" class="nh ni it nd b gy nj nk l nl nm"># principal component analysis<br/>res.pca &lt;- PCA(DF,  graph = FALSE)</span><span id="cbc2" class="nh ni it nd b gy np nk l nl nm"># Extract eigenvalues/variances<br/>print(get_eig(res.pca))</span><span id="bdbd" class="nh ni it nd b gy np nk l nl nm"># Visualize eigenvalues/variances<br/>fviz_screeplot(res.pca, addlabels = TRUE, ylim = c(0, 50))</span></pre><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi on"><img src="../Images/12653c4eedf1315d1e3b8af2effe3f1c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1034/format:webp/1*MFfrMVpS2Yx8bHeYo_3dRQ.png"/></div></div></figure><pre class="ks kt ku kv gt nc nd ne nf aw ng bi"><span id="045c" class="nh ni it nd b gy nj nk l nl nm">fviz_pca_var(res.pca, col.var="contrib",<br/>             gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"),<br/>             repel = TRUE # Avoid text overlapping<br/>             )</span></pre><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi oo"><img src="../Images/02a019ce282a20da290be071439e77c0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1098/format:webp/1*zM_yxMlcWWJDqscXzruv1Q.png"/></div></figure><h2 id="e885" class="nh ni it bd nr ns nt dn nu nv nw dp nx lq ny nz oa lu ob oc od ly oe of og iz bi translated">对主轴的可变贡献:</h2><pre class="ks kt ku kv gt nc nd ne nf aw ng bi"><span id="a90c" class="nh ni it nd b gy nj nk l nl nm">fviz_contrib(res.pca, choice = "var", axes = 1, top = 10) fviz_contrib(res.pca, choice = "var", axes = 2, top = 10)</span></pre><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi op"><img src="../Images/555e27fbbd91985ee71bce99aece6c51.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*DBLiLNxqOfKlEQkkdl0sww.png"/></div></div></figure><pre class="ks kt ku kv gt nc nd ne nf aw ng bi"><span id="7d09" class="nh ni it nd b gy nj nk l nl nm"># Extract the results for individuals<br/>ind &lt;- get_pca_ind(res.pca)<br/>ind</span><span id="b179" class="nh ni it nd b gy np nk l nl nm"># Coordinates of individuals<br/>head(ind$coord)</span><span id="6a6b" class="nh ni it nd b gy np nk l nl nm">fviz_pca_ind(res.pca, col.ind = "cos2",<br/>             gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"),<br/>             repel = TRUE)</span></pre><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi oq"><img src="../Images/b27536d29d59d5190f85e1e675c31ca0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1224/format:webp/1*5NJObXYyzghhehbCPfEhbg.png"/></div></figure><p id="c1c5" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">主成分分析让我们清楚地看到我们所拥有的产品的聚类数。这是我们数据挖掘工作的第一步，非常重要。</p><p id="fd90" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">让我们使用 factoextra 软件包，它可以处理来自几个软件包的 PCA、CA、MCA、MFA、FAMD 和 HMFA 的结果，用于提取和可视化我们数据中包含的最重要的信息。更重要的是，它给出了人类可以理解的输出。</p><pre class="ks kt ku kv gt nc nd ne nf aw ng bi"><span id="b73b" class="nh ni it nd b gy nj nk l nl nm">set.seed(123)<br/>k1 &lt;- kmeans(DF, centers = 2, nstart = 25)<br/>k2 &lt;- kmeans(DF, centers = 3, nstart = 25)<br/>k3 &lt;- kmeans(DF, centers = 4, nstart = 25)<br/>k4 &lt;- kmeans(DF, centers = 5, nstart = 25)</span><span id="8af9" class="nh ni it nd b gy np nk l nl nm"># plots to compare<br/>p1 &lt;- fviz_cluster(k1, geom = "point", DF) + ggtitle("k = 2")<br/>p2 &lt;- fviz_cluster(k2, geom = "point", DF) + ggtitle("k = 3")<br/>p3 &lt;- fviz_cluster(k3, geom = "point", DF) + ggtitle("k = 4")<br/>p4 &lt;- fviz_cluster(k4, geom = "point", DF) + ggtitle("k = 5")</span><span id="921e" class="nh ni it nd b gy np nk l nl nm">grid.arrange(p1, p2, p3, p4, nrow = 2)</span></pre><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi or"><img src="../Images/59da018f9ce6db894f99fdb01a7f9989.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*veFE_0EyhihlaDTTSeAtFQ.png"/></div></div></figure><p id="6552" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">这种评估给了我们关于聚类之间 k=3 或 4 的想法，但是，我们不确定最佳聚类。如果我们知道我们想要的聚类数，那么 k-means 可能是我们用例的一个好选择。</p><p id="046b" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">除了肘方法之外，用于确定最佳聚类的其他流行方法是剪影方法和间隙统计</p><h2 id="f0db" class="nh ni it bd nr ns nt dn nu nv nw dp nx lq ny nz oa lu ob oc od ly oe of og iz bi translated">k 均值聚类:</h2><pre class="ks kt ku kv gt nc nd ne nf aw ng bi"><span id="71c9" class="nh ni it nd b gy nj nk l nl nm"># Elbow method<br/>set.seed(101)<br/>fviz_nbclust(DF, kmeans, method = "wss")</span><span id="19c6" class="nh ni it nd b gy np nk l nl nm"># WSS means the sum of distances between the points <br/># and the corresponding centroids for each cluster</span></pre><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi os"><img src="../Images/6690d298800c6d7a2d80cd6b33bfd4c7.png" data-original-src="https://miro.medium.com/v2/resize:fit:900/format:webp/1*W2M4zRK-TUswQDCa3kkKzw.png"/></div></figure><p id="ff42" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">在这里，我们尝试为从 1 到 10 的每一个集群数建模，并收集每个模型的 WSS 值。看下面的剧情。随着集群的增加，WSS 值降低。肘点为 3 表示 3 个簇。</p><h2 id="3b82" class="nh ni it bd nr ns nt dn nu nv nw dp nx lq ny nz oa lu ob oc od ly oe of og iz bi translated">剪影法:</h2><pre class="ks kt ku kv gt nc nd ne nf aw ng bi"><span id="55ad" class="nh ni it nd b gy nj nk l nl nm">silhouette_score = function(k){<br/>  km = kmeans(DF, centers = k, nstart=25)<br/>  ss = silhouette(km$cluster, dist(DF))<br/>  mean(ss[, 3])}<br/>k = 2:10<br/>avg_sil = sapply(k,silhouette_score )<br/>plot(k, type = 'b', avg_sil, xlab = 'number of clusters', ylab ='average silhouette scores', frame = 'False')</span></pre><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi ot"><img src="../Images/9217b1c834229fd4ef1e129cd260b06d.png" data-original-src="https://miro.medium.com/v2/resize:fit:852/format:webp/1*-h-eP2D6hR4ie1AMFCogfg.png"/></div></figure><p id="1f32" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">这里，最佳数字看起来也是 3</p><h2 id="dc18" class="nh ni it bd nr ns nt dn nu nv nw dp nx lq ny nz oa lu ob oc od ly oe of og iz bi translated">差距统计:</h2><p id="503f" class="pw-post-body-paragraph lh li it lj b lk oh kd lm ln oi kg lp lq oj ls lt lu ok lw lx ly ol ma mb mc im bi translated">间隙统计将 log(Wk)图标准化，其中 Wk 是群内离差，通过将其与数据的适当零参考分布下的预期值进行比较。</p><pre class="ks kt ku kv gt nc nd ne nf aw ng bi"><span id="3906" class="nh ni it nd b gy nj nk l nl nm">fviz_nbclust(DF, kmeans, method = "gap_stat")</span></pre><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi ou"><img src="../Images/d2a500c4a23dce3e054cbc8bb5f41805.png" data-original-src="https://miro.medium.com/v2/resize:fit:764/format:webp/1*K6Intk3TMebObTE3LdWONQ.png"/></div></figure><p id="317d" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">这将不同的输出显示为 4 个集群。让我们根据 Gap-Statistic 方法的发现将此应用于 4 个聚类，并根据 k-means 列的聚类绘制周模式。</p><pre class="ks kt ku kv gt nc nd ne nf aw ng bi"><span id="814c" class="nh ni it nd b gy nj nk l nl nm">cluster_4 &lt;- kmeans(DF,centers = 4,nstart = 10)<br/>cluster_4$cluster &lt;- as.factor(cluster_4$cluster)<br/>cluster_4</span><span id="aeed" class="nh ni it nd b gy np nk l nl nm"># plotting pattern of weeks as per clustering from kmeans columns</span><span id="e97e" class="nh ni it nd b gy np nk l nl nm">ggplot(DF, aes(W1,W44,color =cluster_4$cluster)) +geom_point()</span></pre><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi ov"><img src="../Images/0de42aa2b12639b9867abe355a491fb9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1236/format:webp/1*uLQAEjOgS4kVzFuJ1ZtlBg.png"/></div></figure><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi ow"><img src="../Images/9ccbc946bcc87ceec51fca9751bc31b8.png" data-original-src="https://miro.medium.com/v2/resize:fit:924/format:webp/1*uuvpcR_G_3Ruv_tkWdFoow.png"/></div></figure><p id="fc1b" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">这里我们可以解读为，每组分别有 124、197、490 款产品。聚类图显示了明显分开的三个聚类，between_SS / total_SS = 88.6 %表明该聚类模型非常适合该数据。具体来说，有 490 种产品归入第 1 组。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi ox"><img src="../Images/42587a769943a65ba55c2bd1c316fc66.png" data-original-src="https://miro.medium.com/v2/resize:fit:726/format:webp/1*TL3JR3Pn0F3Z9QkxAjo9MA.png"/></div></figure><pre class="ks kt ku kv gt nc nd ne nf aw ng bi"><span id="56c6" class="nh ni it nd b gy nj nk l nl nm">group1 = data.frame(t(DF[cluster_3$cluster == 3,]))<br/>summary(sapply(group1, mean))</span><span id="818b" class="nh ni it nd b gy np nk l nl nm">hist(sapply(group1, mean), main = "Histogram of Product Group 1", xlab = "Number of Transactions")</span></pre><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi oy"><img src="../Images/cb8feb81616165b1a7cc034c2eb71af5.png" data-original-src="https://miro.medium.com/v2/resize:fit:960/format:webp/1*Glxu5IN_W-7hotfLplomKQ.png"/></div></figure><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi oz"><img src="../Images/cfa22e65b1df1550b18fc1d5b0424e97.png" data-original-src="https://miro.medium.com/v2/resize:fit:800/format:webp/1*lVFQ26WsWO-PVSmfijewWg.png"/></div></figure><p id="9e3b" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">在这里，平均每周交易量为 1.66。有相当多的产品每周交易少于 1 次(柱状图中的长条)。其他产品的交易看起来遵循正态分布。让我们将第一组分成两部分:</p><ul class=""><li id="b16f" class="mn mo it lj b lk ll ln lo lq mp lu mq ly mr mc pa mt mu mv bi translated">平均每周交易&lt; 2 的组 0，以及</li><li id="8ccb" class="mn mo it lj b lk mx ln my lq mz lu na ly nb mc pa mt mu mv bi translated">包含剩余产品的新组 1。</li></ul><pre class="ks kt ku kv gt nc nd ne nf aw ng bi"><span id="9de2" class="nh ni it nd b gy nj nk l nl nm">group0 &lt;- group1[,sapply(group1, mean) &lt;= 2]<br/>group1 &lt;- group1[,sapply(group1, mean) &gt; 2]</span><span id="0d41" class="nh ni it nd b gy np nk l nl nm">group2 &lt;- data.frame(t(DF[cluster_3$cluster == 1]))<br/>group3 &lt;- data.frame(t(DF[cluster_3$cluster == 2]))</span><span id="b016" class="nh ni it nd b gy np nk l nl nm"># pie chart<br/>slices &lt;- c(ncol(group0), ncol(group1), ncol(group2), ncol(group3))<br/>lbls &lt;- c("Group 0:", "Group 1:", "Group 2:", "Group 3:")<br/>lbls &lt;- paste(lbls, percent(slices/sum(slices)))<br/>pie(slices,labels = lbls, col=rainbow(length(lbls)), main ="Pie Chart of Product Segmentation")</span></pre><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi pb"><img src="../Images/daecf516335d7526a8a34e06511966f7.png" data-original-src="https://miro.medium.com/v2/resize:fit:742/format:webp/1*xyjMCEWNEv4n5JFid5dw6g.png"/></div></figure><p id="ce9d" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">我们可以看到，</p><ul class=""><li id="3467" class="mn mo it lj b lk ll ln lo lq mp lu mq ly mr mc pa mt mu mv bi translated">37.2%的产品属于第 0 组，</li><li id="e4ac" class="mn mo it lj b lk mx ln my lq mz lu na ly nb mc pa mt mu mv bi translated">23.2%属于第 1 组，</li><li id="7aaa" class="mn mo it lj b lk mx ln my lq mz lu na ly nb mc pa mt mu mv bi translated">第二组 15.3%，以及</li><li id="3d34" class="mn mo it lj b lk mx ln my lq mz lu na ly nb mc pa mt mu mv bi translated">24.3%属于第三组。</li></ul><h2 id="c3c5" class="nh ni it bd nr ns nt dn nu nv nw dp nx lq ny nz oa lu ob oc od ly oe of og iz bi translated">产品细分的箱线图:</h2><pre class="ks kt ku kv gt nc nd ne nf aw ng bi"><span id="2c85" class="nh ni it nd b gy nj nk l nl nm">group1_mean &lt;- sapply(group1, mean)<br/>group2_mean &lt;- sapply(group2, mean)<br/>group3_mean &lt;- sapply(group3, mean)<br/>boxplot(group1_mean, group2_mean, group3_mean, main = "Box-Plot of Product Segmentation", names = c("Group 1", "Group 2", "Group 3"))</span><span id="9a78" class="nh ni it nd b gy np nk l nl nm">lapply(list(group1_mean, group2_mean, group3_mean), summary)</span></pre><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi pc"><img src="../Images/df3ae34d980368e313167d8d78d27673.png" data-original-src="https://miro.medium.com/v2/resize:fit:978/format:webp/1*8xIo1SIRqy_mtKhnZ6xkXg.png"/></div></figure><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi pd"><img src="../Images/63b8a1210b0f9b9b7834bea1f58d372b.png" data-original-src="https://miro.medium.com/v2/resize:fit:820/format:webp/1*ePBHDwOgw1rQkq-aQRxhJg.png"/></div></figure><p id="ebe0" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">显示的结果显示，产品分为四个独立的组。</p><ul class=""><li id="6c5a" class="mn mo it lj b lk ll ln lo lq mp lu mq ly mr mc pa mt mu mv bi translated">组 0 的每周交易次数最少；和</li><li id="f87a" class="mn mo it lj b lk mx ln my lq mz lu na ly nb mc pa mt mu mv bi translated">组 2 的事务数量最多。</li></ul><h2 id="dd18" class="nh ni it bd nr ns nt dn nu nv nw dp nx lq ny nz oa lu ob oc od ly oe of og iz bi translated">分析和预测:</h2><p id="c24d" class="pw-post-body-paragraph lh li it lj b lk oh kd lm ln oi kg lp lq oj ls lt lu ok lw lx ly ol ma mb mc im bi translated">我们将分别分析每个组，这是一种迭代过程。</p><h2 id="f64b" class="nh ni it bd nr ns nt dn nu nv nw dp nx lq ny nz oa lu ob oc od ly oe of og iz bi translated">分析(第 0 组):</h2><pre class="ks kt ku kv gt nc nd ne nf aw ng bi"><span id="78bd" class="nh ni it nd b gy nj nk l nl nm">summary(group0_mean)</span><span id="8201" class="nh ni it nd b gy np nk l nl nm">par(mfrow = c(1, 2))<br/>hist(group0_mean, main = "Histogram of Group 1", xlab = "Number of Transactions")<br/>boxplot(group0_mean, main = "Box-plot of Group 1", names = c("Group0"))</span></pre><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi pe"><img src="../Images/6cbe401ff3abd246d8045d62ba661535.png" data-original-src="https://miro.medium.com/v2/resize:fit:952/format:webp/1*PQA-7BCzjERhTwr-UjDgIg.png"/></div></figure><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi pf"><img src="../Images/60b0b88fc8673898346eb5c53e848dd2.png" data-original-src="https://miro.medium.com/v2/resize:fit:748/format:webp/1*RhII3uF6iNS0gRj-AIjguA.png"/></div></figure><p id="2cae" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">根据直方图，组 0 的平均每周交易的分布是右偏的。此外，箱线图显示第三个四分位数约为 0.5，这意味着该组中的大多数产品每周的交易量不到 1 笔。尽管有些产品的周交易量大于 1，但考虑到所有产品中的一小部分，这些产品在箱线图中被视为异常值。因此，可以得出结论，这个群体的需求很低。</p><p id="78b4" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">为了进一步分析，我们希望选择一种代表性产品，其平均周交易量最接近目标值(即中值或平均值)。在这种情况下，由于分布是右偏的，我们选择中位数作为我们的目标值。这一组的代表产品是交易数量与中位数相差最小的产品。</p><h2 id="0520" class="nh ni it bd nr ns nt dn nu nv nw dp nx lq ny nz oa lu ob oc od ly oe of og iz bi translated">预测:</h2><pre class="ks kt ku kv gt nc nd ne nf aw ng bi"><span id="0b39" class="nh ni it nd b gy nj nk l nl nm">idx0 &lt;- which.min(abs(group0_mean-summary(group0_mean)['Median']))<br/>print(idx0)</span><span id="0d4c" class="nh ni it nd b gy np nk l nl nm"># First row and all columns<br/>DF[215,]</span><span id="8722" class="nh ni it nd b gy np nk l nl nm">#Convert P215 data to time series<br/>ts0 &lt;- ts(group0[,idx0], frequency = 365.25/7)<br/>plot(ts0)</span></pre><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi pg"><img src="../Images/d5ece69f12ffa5cc1b568d59f165d29c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*idcve3uOz8eyHIol0NRZww.png"/></div></div></figure><p id="b635" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">我们已经将数据转换成时间序列。在<a class="ae md" href="https://en.wikipedia.org/wiki/Year" rel="noopener ugc nofollow" target="_blank"> <em class="mw">儒略历</em> </a>中，一年的平均长度为 365.25 天。不过这个也可以用 365 试试。第 0 组的代表产品是 P214。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi ot"><img src="../Images/aa5edd1a89fef520a082f521e59d2915.png" data-original-src="https://miro.medium.com/v2/resize:fit:852/format:webp/1*YCB_4KFDc2bpOHvK9fdMug.png"/></div></figure><p id="aa7a" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">我们可以看到，P214 每周大部分时间都有零个事务，部分时间有 1 个事务，还有 1/4 个事务。</p><h2 id="e3ce" class="nh ni it bd nr ns nt dn nu nv nw dp nx lq ny nz oa lu ob oc od ly oe of og iz bi translated">分析(第一组):</h2><pre class="ks kt ku kv gt nc nd ne nf aw ng bi"><span id="fb13" class="nh ni it nd b gy nj nk l nl nm">summary(group1_mean)</span><span id="0936" class="nh ni it nd b gy np nk l nl nm">par(mfrow = c(1, 2))<br/>hist(group1_mean, main = "Histogram of Group 1", xlab = "Number of Transactions")<br/>boxplot(group1_mean, main = "Box-plot of Group 1", names = c("Group1"))</span></pre><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi ph"><img src="../Images/ff477b9ecc36368a645fcf5144ac83bb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*ZJ7Cz9iC-f1Kq4n9PBB5yg.png"/></div></figure><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi pi"><img src="../Images/cecac2aa485cd6ec999c63410900c65e.png" data-original-src="https://miro.medium.com/v2/resize:fit:850/format:webp/1*OhFmvlu42f-0RSnzotmcsQ.png"/></div></figure><p id="9d69" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">在这里，分布几乎以 4 为中心。箱线图中的分布有点偏右，有一个异常值。Q3 百分位&gt; 4 (4.23)，组 1 中的大多数产品是&lt; 4. Therefore, it can be safely assumed that, the products in this group have low demands too.</p><pre class="ks kt ku kv gt nc nd ne nf aw ng bi"><span id="f145" class="nh ni it nd b gy nj nk l nl nm">idx1 &lt;- which.min(abs(group1_mean-summary(group1_mean)['Mean']))<br/>print(idx1)</span><span id="0153" class="nh ni it nd b gy np nk l nl nm"># First row and all columns<br/>DF[318,]</span><span id="626a" class="nh ni it nd b gy np nk l nl nm">#Convert P215 data to time series<br/>ts1 &lt;- ts(group1[,idx1], frequency = 365.25/7)<br/>plot(ts1)</span></pre><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi pg"><img src="../Images/5e0b277001e44e9046dc1ccdb50dfffa.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*oQ52kD2IvRanVPs2YiVWtA.png"/></div></div></figure><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi pj"><img src="../Images/ad86e5c9675bbd873513024387b4f59a.png" data-original-src="https://miro.medium.com/v2/resize:fit:760/format:webp/1*Non3-NCkud_1qSUZEyjBEQ.png"/></div></figure><p id="2670" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">The representative product of Group1 is P318.</p><pre class="ks kt ku kv gt nc nd ne nf aw ng bi"><span id="d252" class="nh ni it nd b gy nj nk l nl nm">summary(group1[,idx1])<br/>boxplot(group1[,idx1], main = "Box-Plot of P318")</span></pre><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi pk"><img src="../Images/80a941304273dc5703d99a3684e30b11.png" data-original-src="https://miro.medium.com/v2/resize:fit:672/format:webp/1*gUwzgn8QRJ6B7rtO48UpMw.png"/></div></figure><p id="db5e" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">The distribution is a little bit right skewed. The average number of weekly transaction is 3.67.</p><h2 id="34fc" class="nh ni it bd nr ns nt dn nu nv nw dp nx lq ny nz oa lu ob oc od ly oe of og iz bi translated">Decomposition (Group1):</h2><pre class="ks kt ku kv gt nc nd ne nf aw ng bi"><span id="260a" class="nh ni it nd b gy nj nk l nl nm"># set up plot region<br/>par(mfrow = c(1, 2))<br/># plot normal variates with mean<br/>acf(ts1, main = "")</span><span id="6e70" class="nh ni it nd b gy np nk l nl nm">whitenoise.test(ts1)</span></pre><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi pl"><img src="../Images/e412519b86bb09c8fe311c45865449cd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*e49joeqU9xXqnCXvvY8t5w.png"/></div></div></figure><p id="8f62" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">According to the time plot, the majority of the number of transactions is between 2 and 5 per week. It is clear that there is no trend or seasonality in this time series. Moreover, the auto correlation plot displays white noise in the data. In this way, there is no need to perform decomposition for this time series prior building a forecasting model.</p><p id="9b80" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">We will apply (1) ETS(Exponential Smoothing) and (2) ARIMA (Autoregressive Integrated Moving Average ). Moreover, other forecasting methods e.g. average, drift, and naïve will be applied based on the characteristic of the data. With only 52 weeks of transaction data, it is difficult to make long-term forecasting.</p><h2 id="b875" class="nh ni it bd nr ns nt dn nu nv nw dp nx lq ny nz oa lu ob oc od ly oe of og iz bi translated">ETS(Exponential Smoothing):</h2><p id="8052" class="pw-post-body-paragraph lh li it lj b lk oh kd lm ln oi kg lp lq oj ls lt lu ok lw lx ly ol ma mb mc im bi translated">Prediction produced using exponential smoothing methods are weighted averages of past observations, with the weights decaying exponentially as the observations get older.</p><pre class="ks kt ku kv gt nc nd ne nf aw ng bi"><span id="fd08" class="nh ni it nd b gy nj nk l nl nm">fit_ets &lt;- ets(ts1)<br/>summary(fit_ets)<br/>checkresiduals(fit_ets)</span></pre><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi pm"><img src="../Images/2551adf2203e5eaf15252729031874ba.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*eNzLK4M8Gln4tseie_saWQ.png"/></div></div></figure><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi pk"><img src="../Images/02cc5ac7892c15f92ec75f8bd44ca2f9.png" data-original-src="https://miro.medium.com/v2/resize:fit:672/format:webp/1*fpRrgMOvHUKbdaxISI3GBQ.png"/></div></figure><p id="cd60" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">Ljung-Box statistic p‐value &gt;。显著性水平(\alpha)使我们不拒绝零假设，或者换句话说，时间序列是白色检验。下图显示了模型生成的点预测和预测区间。</p><pre class="ks kt ku kv gt nc nd ne nf aw ng bi"><span id="aeff" class="nh ni it nd b gy nj nk l nl nm">autoplot(fit_ets)</span></pre><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi pk"><img src="../Images/a3da539c7306c54b82c69e13525aaf07.png" data-original-src="https://miro.medium.com/v2/resize:fit:672/format:webp/1*md7858b400lspTZVPKTVMA.png"/></div></figure><pre class="ks kt ku kv gt nc nd ne nf aw ng bi"><span id="d4e1" class="nh ni it nd b gy nj nk l nl nm">plot(forecast(fit_ets, h = 4))</span></pre><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi kr"><img src="../Images/911562a7e8a6fb1d4e2e51cbd20d2366.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*QRGUIt6WiDQWxF04qcAbsQ.png"/></div></div></figure><p id="de1a" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">残差图显示残差具有恒定的方差和零均值，并且彼此之间没有显著的自相关。尽管这表明该模型非常适合；此外，Ljung-Box 检验的 p 值也表明了残差的独立性。但是，显示预测区间的预测结果过宽，具有负值。所以，ETS 模型对于这个时间序列来说不是一个好的选择。</p><p id="4dda" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">ETS(A，N，N)是带有附加误差的简单指数平滑。这是意料之中的，因为原始时间序列是白噪声，没有趋势性和季节性。</p><h2 id="004c" class="nh ni it bd nr ns nt dn nu nv nw dp nx lq ny nz oa lu ob oc od ly oe of og iz bi translated">ARIMA(第一组):</h2><pre class="ks kt ku kv gt nc nd ne nf aw ng bi"><span id="c8e4" class="nh ni it nd b gy nj nk l nl nm">summary(ur.kpss(ts1))<br/>adf.test(ts1)<br/>ur.df(ts1, type='trend', lags = 10, selectlags = "BIC")</span></pre><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi pn"><img src="../Images/0c0598cdf8087af28ef13e7471d4449d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1264/format:webp/1*JpCiib9fNU2To6hxU3ea8A.png"/></div></figure><pre class="ks kt ku kv gt nc nd ne nf aw ng bi"><span id="3623" class="nh ni it nd b gy nj nk l nl nm">p1 = ggAcf(ts1)<br/>p2 = ggPacf(ts1)<br/>grid.arrange(p1, p2, ncol = 2)</span></pre><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi pk"><img src="../Images/00587d2caa96f28ab4e7592bfd863615.png" data-original-src="https://miro.medium.com/v2/resize:fit:672/format:webp/1*AcHL46WgBRyIu-BpY8zjFA.png"/></div></figure><p id="77c8" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">P318 这个时间序列是白噪声，是平稳数据。这里，ACF 和 PACF 图具有相同的平稳性观察。</p><h2 id="4052" class="nh ni it bd nr ns nt dn nu nv nw dp nx lq ny nz oa lu ob oc od ly oe of og iz bi translated">ARIMA(第一组):</h2><pre class="ks kt ku kv gt nc nd ne nf aw ng bi"><span id="2856" class="nh ni it nd b gy nj nk l nl nm">fit_arima = auto.arima(ts1, seasonal = FALSE)<br/>summary(fit_arima)<br/>checkresiduals(fit_arima)</span></pre><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi po"><img src="../Images/743a4be16efbebd863994d844b08d4b9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1052/format:webp/1*T1bExF8VYP4T5ufApkcgag.png"/></div></figure><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi pp"><img src="../Images/6f5dbfacacf1d8aaab613fd671b58215.png" data-original-src="https://miro.medium.com/v2/resize:fit:888/format:webp/1*_GaEnNUGfpszZ5h_3PwW6g.png"/></div></figure><p id="65dd" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">就模型性能而言，ARIMA 可能更好，然而，与 ETS 模型相比，预测输出与 ETS 非常相似，具有不可接受的宽预测区间。</p><pre class="ks kt ku kv gt nc nd ne nf aw ng bi"><span id="cd9b" class="nh ni it nd b gy nj nk l nl nm">autoplot(forecast(fit_arima, h = 4)) + xlab("Week") + <br/>ylab("Number of Transactions") + ggtitle("Group 1: Forecast using ARIMA Method")</span></pre><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi pq"><img src="../Images/08ab861ea99b71922c8d744786d8a47d.png" data-original-src="https://miro.medium.com/v2/resize:fit:840/format:webp/1*J6oPedtLL1pcBcsCjzMpTg.png"/></div></figure><h2 id="cbf9" class="nh ni it bd nr ns nt dn nu nv nw dp nx lq ny nz oa lu ob oc od ly oe of og iz bi translated">平均法、简单法和漂移法:</h2><pre class="ks kt ku kv gt nc nd ne nf aw ng bi"><span id="530b" class="nh ni it nd b gy nj nk l nl nm">p1 = autoplot(ts1) + autolayer(meanf(ts1, h = 4)) + xlab(“Week”) + <br/>ylab(“Number of Transactions”) + ggtitle(“Group 1: Average Method”)</span><span id="8697" class="nh ni it nd b gy np nk l nl nm">p2 = autoplot(ts1) + autolayer(naive(ts1, h = 4)) + xlab(“Week”) + <br/>ylab(“Number of Transactions”) + ggtitle(“Group 1: Naive Method”)</span><span id="4eab" class="nh ni it nd b gy np nk l nl nm">p3 = autoplot(ts1) + autolayer(rwf(ts1, h = 4)) + xlab(“Week”) + <br/>ylab(“Number of Transactions”) + ggtitle(“Group 1: Drift Method”)</span><span id="7b81" class="nh ni it nd b gy np nk l nl nm">grid.arrange(p1, p2, p3, ncol = 3)</span></pre><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi pr"><img src="../Images/2f34b4637a4b0eac86791074881d6ecb.png" data-original-src="https://miro.medium.com/v2/resize:fit:868/format:webp/1*NB87EOFVdKSCgQfwlKbN6A.png"/></div></figure><p id="cb88" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">总的来说，这些方法中没有一种比 ARIMA 或 ETS 方法更适合数据。具体来说，使用平均法的预测具有非常相似的结果。然而，朴素方法和漂移方法的预测区间甚至更宽。因此，这些方法不是好的选择。</p><p id="be58" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">由于 P318 的原始数据是白噪声，所以很难对这个时间序列进行很好的预测。我们注意到 ARIMA 和 ETS 模型的预测结果都等于 P318 的平均值(3.673/3.68)。</p><p id="0775" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">然而，由于预测区间较宽，如果我们只直接使用预测结果，会使业务面临风险。因此，建议不要使用平均值，而是使用第三个四分位值，即每周 5 次交易，这样，我们可以满足 75%的业务需求。</p><h2 id="3b67" class="nh ni it bd nr ns nt dn nu nv nw dp nx lq ny nz oa lu ob oc od ly oe of og iz bi translated">分析(第三组):</h2><pre class="ks kt ku kv gt nc nd ne nf aw ng bi"><span id="22ba" class="nh ni it nd b gy nj nk l nl nm">idx3 &lt;- which.min(abs(group3_mean-summary(group3_mean)['Median']))<br/>print(idx3)</span><span id="daa0" class="nh ni it nd b gy np nk l nl nm">summary(group3_mean)</span><span id="de90" class="nh ni it nd b gy np nk l nl nm">par(mfrow = c(1, 2))<br/>hist(group3_mean, main = "Histogram of Group 3", xlab = "Number of Transactions")<br/>boxplot(group3_mean, main = "Box-plot of Group 3", names = c("Group3"))</span></pre><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi ps"><img src="../Images/196ff8cb61120854e1309caa2f4bcba6.png" data-original-src="https://miro.medium.com/v2/resize:fit:866/format:webp/1*E2KM6wytSPFJ2u8wCgDWtA.png"/></div></figure><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi pt"><img src="../Images/76cb58bd19fb100b04678313b33e8294.png" data-original-src="https://miro.medium.com/v2/resize:fit:738/format:webp/1*TziIe6qYE7ZelVBbyBpEOQ.png"/></div></figure><p id="b4b6" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">根据直方图，每周交易的分布是右偏的。在箱线图中，分布是右偏的，有一些异常值。此外，第 25 百分位是 32.17，这意味着组 3 中的大多数产品的周交易量都大于 32。因此，我们可以得出结论，组 3 中的产品有很高的需求。这里，分布也是居中的，因此，我们选择平均值作为目标值。</p><pre class="ks kt ku kv gt nc nd ne nf aw ng bi"><span id="41c3" class="nh ni it nd b gy nj nk l nl nm">summary(group3[,idx3])<br/>boxplot(group3[,idx3], main = "Box-Plot of P209")</span></pre><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi pu"><img src="../Images/50906e187067a2b660e80902a8f2c05a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*aoLR0SiG7UkZ64YB0Cymdg.png"/></div></div></figure><p id="32ca" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">数据分布几乎居中。周成交平均数为 9.9，第三四分位数为 12。</p><h2 id="b4f1" class="nh ni it bd nr ns nt dn nu nv nw dp nx lq ny nz oa lu ob oc od ly oe of og iz bi translated">分解(第三组):</h2><pre class="ks kt ku kv gt nc nd ne nf aw ng bi"><span id="42af" class="nh ni it nd b gy nj nk l nl nm">ts3 = ts(group3[,idx3], frequency = 365.25/7)<br/>p1 = autoplot(ts3) + xlab("Week") + ylab("Number of Transaction") + ggtitle("Time Plot (Group 2)")<br/>p2 = ggAcf(ts3)<br/>grid.arrange(p1, p2, ncol = 2)</span></pre><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi pv"><img src="../Images/58dbd4a7dbb8e3e9015245ad1afa8033.png" data-original-src="https://miro.medium.com/v2/resize:fit:828/format:webp/1*jJa5ldLO5JSUuUESYrIizg.png"/></div></figure><p id="2eb7" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">从时间图来看，大部分交易次数在每周 6 到 13 次之间。</p><p id="3edd" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">原始时间序列由趋势分量和不规则分量组成，但没有季节分量。因此，使用简单移动平均法进行平滑是合适的。</p><pre class="ks kt ku kv gt nc nd ne nf aw ng bi"><span id="2d55" class="nh ni it nd b gy nj nk l nl nm">autoplot(ts3, series = "Data") + autolayer(ma(ts3, 5), series = "5-MA" ) + autolayer(ma(ma(ts3, 5), 3), series = "3x5-MA") + scale_colour_manual(values=c("Data"="grey50","5-MA"="blue", "3x5-MA" = "red"), breaks=c("Data","5-MA", "3x5-MA"))</span></pre><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi pw"><img src="../Images/458385005af3c2ea3053c42b7b34329a.png" data-original-src="https://miro.medium.com/v2/resize:fit:812/format:webp/1*0twZF6vXpyN_2FZZcs19sA.png"/></div></figure><p id="8b9e" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">阶数为 5 时，估计趋势不会像预期的那样平滑。因此，执行移动平均的移动平均。“3x5-MA”趋势更适合。我们将重复应用 ETS(指数平滑)和 ARIMA(自回归综合移动平均)的类似过程，还将研究其他预测方法，如平均、漂移和朴素等。</p><p id="2022" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">这里可以执行类似的练习，如 group0 和 group1，以找到最适合的模型。</p><h1 id="70b6" class="px ni it bd nr py pz qa nu qb qc qd nx ki qe kj oa kl qf km od ko qg kp og qh bi translated">关键要点:</h1><p id="23ef" class="pw-post-body-paragraph lh li it lj b lk oh kd lm ln oi kg lp lq oj ls lt lu ok lw lx ly ol ma mb mc im bi translated">聚类在零售业务决策过程中非常重要。它是有效数据挖掘技术的一部分，在处理大数据时，有效的数据挖掘是至关重要的。数据挖掘涵盖了广泛的数据分析和知识发现任务，从数据表征和鉴别到关联和相关分析、分类、回归、聚类、异常值分析、序列分析以及趋势和演变分析。</p><p id="b06b" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">然而，我们必须记住，现实生活中的数据是杂乱的，可能包含噪音、错误、异常或不确定性。错误和噪声可能会混淆数据挖掘过程，导致错误模式的产生。数据清理、数据预处理、异常值检测和去除以及不确定性推理是需要与数据挖掘过程集成以进行任何有效分割和预测的技术示例。</p><p id="c0ad" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated"><strong class="lj jd"> <em class="mw">我这里可以联系到</em></strong><a class="ae md" href="https://www.linkedin.com/in/saritmaitra/" rel="noopener ugc nofollow" target="_blank"><strong class="lj jd"><em class="mw"/></strong></a><em class="mw">。</em></p></div></div>    
</body>
</html>