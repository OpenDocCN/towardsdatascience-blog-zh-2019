<html>
<head>
<title>Features correlations: data leakage, confounded features and other things that can make your Deep Learning model fail</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">特征相关性:数据泄露、混淆的特征和其他可能使你的深度学习模型失败的事情</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/features-correlations-data-leakage-confounded-features-and-other-things-that-can-make-your-deep-771bcaf84f9f?source=collection_archive---------31-----------------------#2019-12-04">https://towardsdatascience.com/features-correlations-data-leakage-confounded-features-and-other-things-that-can-make-your-deep-771bcaf84f9f?source=collection_archive---------31-----------------------#2019-12-04</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><p id="2532" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">在现象学科学中，尤其是在深度学习中，最容易被忽视的概念之一是输入特征之间的相关性。</p><p id="734a" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">什么是相关性？查看这幅漫画:</p><figure class="km kn ko kp gt kq gh gi paragraph-image"><div role="button" tabindex="0" class="kr ks di kt bf ku"><div class="gh gi kl"><img src="../Images/20060f1849557eaacd0f3d4f72cf8635.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*-ayDAjhkP2ZaafX4MnvbSg.jpeg"/></div></div></figure><p id="add3" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">从 boss 正在展示的情节来看，剃光头的员工越多，公司销售额增长越多。如果你是老板，你会考虑对你的员工采取同样的行动吗？大概不会。</p><p id="a283" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">事实上，你认识到两组事件之间没有<a class="ae kx" href="https://en.wikipedia.org/wiki/Correlation_does_not_imply_causation" rel="noopener ugc nofollow" target="_blank"><em class="ky"/></a>的因果关系，它们的行为相似只是偶然。更清楚的是:剃光头不会导致销售。</p><p id="e770" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">所以，我们发现了至少两种可能的相关性:没有因果关系和有因果关系。我们还一致认为，只有第二个是有趣的，而另一个是无用的，当不误导。但是让我们更深入一点。</p><h1 id="b59a" class="kz la iq bd lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw bi translated">深度学习中的相关性</h1><p id="dbea" class="pw-post-body-paragraph jn jo iq jp b jq lx js jt ju ly jw jx jy lz ka kb kc ma ke kf kg mb ki kj kk ij bi translated">让我介绍一个深度学习领域的例子，特别是在计算机视觉领域，特征之间的非因果相关性实际上使模型失败。</p><h2 id="17ac" class="mc la iq bd lb md me dn lf mf mg dp lj jy mh mi ln kc mj mk lr kg ml mm lv mn bi translated">一张图有哪些「特色」？</h2><p id="5538" class="pw-post-body-paragraph jn jo iq jp b jq lx js jt ju ly jw jx jy lz ka kb kc ma ke kf kg mb ki kj kk ij bi translated">一般来说，要素是模型用来构建预测的任何东西。但是，在这种情况下，指定什么是特性可能更好:</p><p id="1205" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">考虑一张脸的照片。功能可以是:</p><ol class=""><li id="501f" class="mo mp iq jp b jq jr ju jv jy mq kc mr kg ms kk mt mu mv mw bi translated">大量的绿色像素</li><li id="ce98" class="mo mp iq jp b jq mx ju my jy mz kc na kg nb kk mt mu mv mw bi translated">充满绿色像素的圆圈</li><li id="aef6" class="mo mp iq jp b jq mx ju my jy mz kc na kg nb kk mt mu mv mw bi translated">一组白色像素，包含由绿色像素填充的圆圈</li><li id="72d5" class="mo mp iq jp b jq mx ju my jy mz kc na kg nb kk mt mu mv mw bi translated">…以上所有内容构成了一只眼睛</li><li id="23ea" class="mo mp iq jp b jq mx ju my jy mz kc na kg nb kk mt mu mv mw bi translated">…所有之前的和更多的来构成脸部。</li></ol><p id="3c64" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">都是特色。为了保持关注，特征“虹膜”与特征“眼睛”相关联。</p><h2 id="9ce6" class="mc la iq bd lb md me dn lf mf mg dp lj jy mh mi ln kc mj mk lr kg ml mm lv mn bi translated">给老虎分类</h2><p id="cf5b" class="pw-post-body-paragraph jn jo iq jp b jq lx js jt ju ly jw jx jy lz ka kb kc ma ke kf kg mb ki kj kk ij bi translated">现在，假设您训练一个模型来识别老虎，并假设训练集由成千上万张类似于下图的图片组成。</p><figure class="km kn ko kp gt kq gh gi paragraph-image"><div class="gh gi nc"><img src="../Images/3f7052b5571fce4e4fde7006ae877124.png" data-original-src="https://miro.medium.com/v2/resize:fit:1200/format:webp/1*1Kbhic3JKYps_-Mbxpbn7g.png"/></div><figcaption class="nd ne gj gh gi nf ng bd b be z dk">Tiger examples in the Training set.</figcaption></figure><p id="f544" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">当然，训练集包括描述什么不是老虎的其他图片；也许是其他动物，汽车，直升机等。</p><p id="5477" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">假设您在这样的数据集上训练的模型在测试集上表现得非常好。你对自己的模型很满意，于是你去了一个动物园，想用一张老虎的照片来试试:</p><figure class="km kn ko kp gt kq gh gi paragraph-image"><div role="button" tabindex="0" class="kr ks di kt bf ku"><div class="gh gi nh"><img src="../Images/7e73bc23f5468a2880b37f4ff1b0a62c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*dTQed5Xy-___BRyKNkmu2Q.jpeg"/></div></div><figcaption class="nd ne gj gh gi nf ng bd b be z dk">The picture you took in the zoo.</figcaption></figure><p id="05d4" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">您希望模型举起绿色旗帜，将图片识别为包含一只老虎。但是这个模型实际上完全失败了，说它不是。哪里出了问题？</p><h2 id="4fbb" class="mc la iq bd lb md me dn lf mf mg dp lj jy mh mi ln kc mj mk lr kg ml mm lv mn bi translated">有罪者:相关的、非因果的特征</h2><p id="1a6c" class="pw-post-body-paragraph jn jo iq jp b jq lx js jt ju ly jw jx jy lz ka kb kc ma ke kf kg mb ki kj kk ij bi translated">也许您已经发现了这个问题:训练集中的图片显示的是森林中的老虎，而动物园中的图片显示的是笼子中的老虎。用技术术语来说，你拍的照片属于与训练集不同的发行版。</p><p id="dc80" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">正在发生的是:模型认为老虎是你所知道的被“森林”包围的动物，因为在我们的训练集中它总是这样。因为在动物园的照片中没有森林，所以模型不认为照片中有老虎。</p><p id="e1f4" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">现在我们可以更好地区分相关性，引入第三个类别，即由<a class="ae kx" href="https://en.wikipedia.org/wiki/Confounding" rel="noopener ugc nofollow" target="_blank">混杂</a>因素引起的相关性。它的效果实际上可以混淆模型，让它相信在动物和森林之间存在实际上并不存在的因果关系。</p><p id="9b35" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">在我们的例子中，混杂因素，又名<em class="ky">隐藏特征</em> (H)导致特征“老虎”和“森林”出现在同一张图片中。h 是一系列事件，如:生物学，发现老虎的机会，还有摄影师的心情，媒体的兴趣，以及任何能让老虎出现在森林中的事物。</p><p id="b3f9" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">所以当这一组事件 H 发生时，就生成了一张森林中有老虎的图片。但是 H 是不可概括的:并不是每一次老虎出现的时候，森林也会出现，就像动物园里的照片或者雪地里的老虎。</p><p id="74d6" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">换句话说，我们的模型 do 相信老虎<em class="ky">是隐藏的特征 H </em>，而不仅仅是我们所知道的老虎这种动物。</p><h2 id="d5d4" class="mc la iq bd lb md me dn lf mf mg dp lj jy mh mi ln kc mj mk lr kg ml mm lv mn bi translated">示意图</h2><p id="f91b" class="pw-post-body-paragraph jn jo iq jp b jq lx js jt ju ly jw jx jy lz ka kb kc ma ke kf kg mb ki kj kk ij bi translated">我们刚刚介绍了在构建数据模型时应该辨别的三种类型的相关性。让我们在一个模式中看到它们</p><figure class="km kn ko kp gt kq gh gi paragraph-image"><div role="button" tabindex="0" class="kr ks di kt bf ku"><div class="gh gi ni"><img src="../Images/6b6fbb9dec08b28e0fe9b50ea5d8bfeb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*zx-A3TyY1Mw_jGURV4rPGw.png"/></div></div></figure><ol class=""><li id="8b3c" class="mo mp iq jp b jq jr ju jv jy mq kc mr kg ms kk mt mu mv mw bi translated">第一种情况最容易识别，就像文章开头的漫画。这种情况在机器学习领域的一种表现形式被称为<a class="ae kx" href="https://machinelearningmastery.com/data-leakage-machine-learning/" rel="noopener ugc nofollow" target="_blank">数据泄露</a>。<br/>作为例子，考虑老虎分类器，并且假设每张包含老虎的图片都被标注了一些标记，比如图片左上角的绿色十字。由于像梯度下降这样的最小化方法是懒惰的，所以模型识别标记比识别老虎更容易。因此，模型将只检查标记的存在来识别老虎图片。显而易见的推论是，这样的模型实际上是没有用的，因为在生产中，你不会找到你在训练集中得到的分数。</li><li id="54ae" class="mo mp iq jp b jq mx ju my jy mz kc na kg nb kk mt mu mv mw bi translated">第二种情况是我们唯一可以放心接受的。老虎身上的条纹就是一个例子:因为没有没有条纹的老虎，所以当且仅当老虎身上有条纹时，模型对老虎进行分类是安全的。</li><li id="cd8c" class="mo mp iq jp b jq mx ju my jy mz kc na kg nb kk mt mu mv mw bi translated">第三种情况更加微妙，很难向模型教授。但往往可以简单忍受。<br/> —微妙，因为它在培训阶段很容易被忽略，只有在生产中才能发现，就像 tiger 的例子。<br/> —由于统计数据而难以教授:假设您刚刚发现了我们在上一段中描述的模型中的问题，为了解决它，您将您拍摄的照片添加到训练集中。在这样的基础上，模型仍然很难忽略“森林”这一特征，而当面对笼子里的老虎时，训练过程更有可能接受更大的误差。从技术上来说，你添加的图片并没有改变超空间权重的最小值，因为它只是一个超过 1001 的样本。这意味着当你在除了森林以外的任何环境中面对老虎时，你的模型很可能会在生产中失败。<br/>但是也许你的模型被期望用于森林，所以你可以接受你的模型包括这个混杂因素。</li></ol><h1 id="665d" class="kz la iq bd lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw bi translated">结论和进一步阅读</h1><p id="b8e6" class="pw-post-body-paragraph jn jo iq jp b jq lx js jt ju ly jw jx jy lz ka kb kc ma ke kf kg mb ki kj kk ij bi translated">对特征相关性的控制可能是至关重要的，尤其是当您根据不适合您的应用的数据来训练模型时。</p><p id="d235" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">原则上，非因果关联问题可以通过选择一个符合<a class="ae kx" href="https://en.wikipedia.org/wiki/Independent_and_identically_distributed_random_variables" rel="noopener ugc nofollow" target="_blank">I . I . d .</a>的数据集来训练模型来解决，但正如您所理解的，这对于大多数用例来说是不可能的。</p><p id="c254" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">有一些非常聪明的人专门研究这些被低估的问题。作为参考，查看<a class="ae kx" href="http://pengcui.thumedialab.com/" rel="noopener ugc nofollow" target="_blank">崔鹏教授</a>的作品。</p><p id="a61c" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">数据科学家实际上(应该)做的是建立一个相当好的训练数据集，也使用数据扩充，以便获得足够的数据方差，并最终缓解这些问题。而且，非常重要的是，在部署到生产环境中之后，要监控模型做出的预测。</p></div></div>    
</body>
</html>