<html>
<head>
<title>Torchvision &amp; Transfer Learning</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">火炬视觉和迁移学习</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/torchvision-transfer-learning-1d4778b807cc?source=collection_archive---------23-----------------------#2019-09-09">https://towardsdatascience.com/torchvision-transfer-learning-1d4778b807cc?source=collection_archive---------23-----------------------#2019-09-09</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="eea3" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">试图直接操纵预先训练好的火炬视觉模型</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/1faba7eeb90f59b46ecc5eae3cfbf2a7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*LLeZXj_vgXtzWHo4"/></div></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk">Photo by <a class="ae ky" href="https://unsplash.com/@possessedphotography?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Possessed Photography</a> on <a class="ae ky" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><p id="3c1f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这篇文章可能对刚开始深度学习的人或相对来说不熟悉 PyTorch 的人最感兴趣。这是我最近尝试修改 torchvision 包的 CNN 的经验总结，这些 CNN 已经根据来自 Imagenet 的数据进行了预训练。目的是使多体系结构分类器更容易编程。</p></div><div class="ab cl lv lw hx lx" role="separator"><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma"/></div><div class="im in io ip iq"><p id="e1db" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">众所周知，机器学习实践者可以通过保留预训练模型的最后一层以外的所有层来利用预训练模型，冻结剩余层中的参数，然后将自定义分类器附加到模型的末尾，稍后使用用户数据进行训练。</p><p id="6e6e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我在 2019 年 3 月下旬完成了 Udacity 所谓的纳米学位“用 Python 进行人工智能编程”。对于本课程的期末项目，学生必须使用至少两种不同类型的 CNN 架构来正确分类不同类型的植物和野花的照片。</p><p id="fd0e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">可供学生使用的 CNN 架构由 PyTorch 的 torchvision 模块提供，并在 Imagenet 的图像上进行了预处理。面临的挑战是采用这些不同的预训练 CNN 架构，然后利用迁移学习的概念，将我们自己的利用 PyTorch 的分类层附加到模型的末尾。然后，该分类器将根据互联网上某个来源提供的植物和野花照片进行训练。</p><p id="ab6c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">为了检查 torchvision 中包含的预训练模型的架构，我使用了 Python 解释器中的以下过程:</p><pre class="kj kk kl km gt mc md me mf aw mg bi"><span id="cba2" class="mh mi it md b gy mj mk l ml mm">&gt;&gt;&gt; from torchvision import models                                                                                                                                                                   <br/>&gt;&gt;&gt; model = models.vgg13(pretrained=True)                                                                                                                                                            <br/>&gt;&gt;&gt; model                                                                                                                                                                                            <br/>VGG(                                                                                                                                                                                                 <br/>  (features): Sequential(                                                                                                                                                                            <br/>    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))                                                                                                                            <br/>    (1): ReLU(inplace=True)                                                                                                                                                                          <br/>    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))                                                                                                                           <br/>    (3): ReLU(inplace=True)                                                                                                                                                                          <br/>    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)                                                                                                                  <br/>[…snip…]                                                                                                             <br/>    (24): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)                                                                                                                 <br/>  )                                                                                                                                                                                                  <br/>  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))                                                                                                                                                   <br/>  (classifier): Sequential(                                                                                                                                                                          <br/>    (0): Linear(in_features=25088, out_features=4096, bias=True)                                                                                                                                     <br/>    (1): ReLU(inplace=True)                                                                                                                                                                          <br/>    (2): Dropout(p=0.5, inplace=False)                                                                                                                                                               <br/>    (3): Linear(in_features=4096, out_features=4096, bias=True)                                                                                                                                      <br/>    (4): ReLU(inplace=True)                                                                                                                                                                          <br/>    (5): Dropout(p=0.5, inplace=False)                                                                                                                                                               <br/>    (6): Linear(in_features=4096, out_features=1000, bias=True)                                                                                                                                      <br/>  )                                                                                                                                                                                                  <br/>)</span></pre><p id="ab98" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">请注意，对于 torchvision vgg13 预训练实现，最后一个父模块，即被学生的分类器替换的模块，被命名为“分类器”。</p><p id="8093" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">由于任务的目标是使用至少两种不同的预训练 CNN 架构，我看了看 torchvision 模块提供的其他模型。我发现火炬视觉预训练 CNN 模型的分类部分至少有两个不同的名字。除了“分类器”，resnet101 预训练 CNN 使用“fc”(大概代表“完全连接”)作为其最终分类模块。</p><p id="97cb" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">最终，我的自定义分类层需要使用类似下面的语句连接到预训练的 CNN:</p><pre class="kj kk kl km gt mc md me mf aw mg bi"><span id="b81c" class="mh mi it md b gy mj mk l ml mm">model.classifier = my_custom_classifier</span></pre><p id="7ba0" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">但是，如果用户从命令行指定一个 resnet101 架构，会发生什么呢？既然架构的名称与“分类器”不同，我该如何用上面的技术覆盖最后一个模块呢？</p><p id="a257" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">因为我想在项目中重用尽可能多的代码，所以我有几个选择。第一，我可以为分类模块选择具有相同名称的架构，第二，我可以看看是否可以找到一种方法来实现<strong class="lb iu"> <em class="mn">任何通用架构</em> </strong>，并找到一种方法来处理不同架构对分类模块具有不同名称的事实。第三种选择是根据用户选择的模型将自定义分类器附加到用户选择的架构上。比如“如果”用户选择了 resnet101，“那么”我们使用“fc”，否则，我们使用“分类器”。</p><p id="8aeb" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">最终，我选择了第二个选项。我的决定是试图将“分类器”模块名等同于“fc”模块名。换句话说，我选择了做类似这样的事情:</p><pre class="kj kk kl km gt mc md me mf aw mg bi"><span id="f6f0" class="mh mi it md b gy mj mk l ml mm">model.classifier = model.fc = my_custom_classifier</span></pre><p id="6605" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">目标是为我的自定义分类器提供多个名称，这样无论我选择什么架构，我都可以使用名称“fc”来引用分类层。这个<strong class="lb iu"> <em class="mn">看起来</em> </strong>起作用了，这是我最后一个项目(通过了)用的。</p></div><div class="ab cl lv lw hx lx" role="separator"><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma"/></div><div class="im in io ip iq"><p id="a2c9" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在 2019 年 8 月完成“深度学习”纳米学位项目(我的第二个人工智能相关纳米学位)后，我想回到我最初的“用 Python 进行人工智能编程”项目，花多一点时间熟悉 PyTorch，因为大多数深度学习项目都使用 Tensorflow。我还想添加一个命令行参数，以便用户可以指定分类器可以区分的类别数量，而不是在代码库中固定数量。</p><p id="5e0d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">很快，我开始研究几个月前完成的项目代码，准备修改它以接受分类器可以从命令行区分的类别数量。</p><p id="1a79" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">没过多久，我就发现我的“诡计”根本没有达到我的预期目的。代码运行得很好，但不像我最初设计的那样。</p><p id="cd11" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">代码没有让我用多个名称引用我的自定义分类器，而是在我选择的预训练架构的末尾添加了两个自定义分类器<strong class="lb iu"><em class="mn"/></strong>。例如，我对 vgg13 架构的总结如下:</p><pre class="kj kk kl km gt mc md me mf aw mg bi"><span id="d8e5" class="mh mi it md b gy mj mk l ml mm">VGG(                                                                                                                                                                                                                                               <br/>  (features): Sequential(                                                                                                                                                                                                                          <br/>    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))                                                                                                                                                                          <br/>    (1): ReLU(inplace=True)                                                                                                                                                                                                                        <br/>    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))                                                                                                                                                                         <br/>    (3): ReLU(inplace=True)                                                                                                                                                                                                                        <br/>    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)                                                                                                                                                                <br/>[…snip…]                                                                                                                                                       <br/>    (24): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)                                                                                                                                                               <br/>  )                                                                                                                                                                                                                                                <br/>  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))                                                                                                                                                                                                 <br/>  (classifier): Network(                                                                                                                                                                                                                           <br/>    (hidden_layers): ModuleList(                                                                                                                                                                                                                   <br/>      (0): Linear(in_features=25088, out_features=256, bias=True)                                                                                                                                                                                  <br/>    )                                                                                                                                                                                                                                              <br/>    (output): Linear(in_features=256, out_features=102, bias=True)                                                                                                                                                                                 <br/>    (dropout): Dropout(p=0.2, inplace=False)                                                                                                                                                                                                       <br/>  )                                                                                                                                                                                                                                                <br/>  (fc): Network(                                                                                                                                                                                                                                   <br/>    (hidden_layers): ModuleList(                                                                                                                                                                                                                   <br/>      (0): Linear(in_features=25088, out_features=256, bias=True)                                                                                                                                                                                  <br/>    )                                                                                                                                                                                                                                              <br/>    (output): Linear(in_features=256, out_features=102, bias=True)                                                                                                                                                                                 <br/>    (dropout): Dropout(p=0.2, inplace=False)                                                                                                                                                                                                       <br/>  )                                                                                                                                                                                                                                                <br/>)</span></pre><p id="df6f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">正如您从名为' classifier '和' fc '的模块中看到的，我尝试为自定义分类器提供多个名称的最终结果失败了。它所做的只是将自定义分类模块的两个副本放在预训练的 vgg13 CNN 的末尾。更糟糕的是，我的辍学层出现在了错误的地方。我希望它在隐藏层之后显示出来。回到众所周知的绘图板。</p><p id="f144" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我意识到我需要的是一种方法，可以用来操纵 torchvision 模块提供的预训练模型的架构。如果我能够操纵这个架构，我就可以对 torchvision 提供的任何预训练 CNN 的最后一个模块执行相当于“删除”(或者“重命名”)的操作。然后，我想，在预先训练的 CNN 中，分类模块的名称是什么并不重要，我可以随便叫它什么，而不必担心分类模块的名称。更好的是，我不必担心决策代码来处理不同架构的使用。</p><p id="7002" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在这一点上，我决定看看 torchvision 模型到底有哪些可用的方法和属性。为了做到这一点，我再次回到解释器:</p><pre class="kj kk kl km gt mc md me mf aw mg bi"><span id="deeb" class="mh mi it md b gy mj mk l ml mm">&gt;&gt;&gt; from torchvision import models                                                                                                                                                                   <br/>&gt;&gt;&gt; x = models.vgg13(pretrained=True)                                                                                                                                                                <br/>&gt;&gt;&gt; x.&lt;tab&gt;&lt;tab&gt;                                                                                                                                                                                               <br/>x.add_module(                 x.cpu(                        x.features(                   x.named_buffers(              x.register_buffer(            x.state_dict(                                  <br/>x.apply(                     x.cuda(                      x.float(                     x.named_children(            x.register_forward_hook(     x.to(                                          <br/>x.avgpool(                   x.double(                    x.forward(                   x.named_modules(             x.register_forward_pre_hook( x.train(                                       <br/>x.buffers(                   x.dump_patches               x.half(                      x.named_parameters(          x.register_parameter(        x.training                                     <br/>x.children(                  x.eval(                      x.load_state_dict(           x.parameters(                x.requires_grad_(            x.type(                                        <br/>x.classifier(                x.extra_repr(                x.modules(                   x.register_backward_hook(    x.share_memory(              x.zero_grad(</span></pre><p id="02e3" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">通过查看上面的输出，我学到的第一件事是，每个顶级模块都有对应的方法。例如，每个“特性”、“avgpool”和“分类器”都有相应的方法。其中名称根据火炬视觉模型而不同，因此方法也不同。例如，resnet101 模型没有“classifer”方法。它有一个用于分类器的“fc”方法。</p><p id="7b9d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我花了一些时间来试验不同的方法，并利用 Python 的帮助工具来探索它们，并提出了我的第一个(尽管是天真的)想法，即使用从 nn 继承的“add_module”方法。模块:</p><pre class="kj kk kl km gt mc md me mf aw mg bi"><span id="9f73" class="mh mi it md b gy mj mk l ml mm">&gt;&gt;&gt; help(model.add_module)                                                                                                                                                                           <br/>Help on method add_module in module torch.nn.modules.module:                                                                                                                                         <br/>                                                                                                                                                                                                     <br/>add_module(name, module) method of torch.nn.modules.container.Sequential instance                                                                                                                    <br/>    Adds a child module to the current module.                                                                                                                                                       <br/>                                                                                                                                                                                                     <br/>    The module can be accessed as an attribute using the given name.                                                                                                                                 <br/>                                                                                                                                                                                                     <br/>    Args:                                                                                                                                                                                            <br/>        name (string): name of the child module. The child module can be                                                                                                                             <br/>            accessed from this module using the given name                                                                                                                                           <br/>        module (Module): child module to be added to the module.</span></pre><p id="7731" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">根据上面的信息，这似乎正是我所需要的，我对实现进行了如下测试:</p><pre class="kj kk kl km gt mc md me mf aw mg bi"><span id="1b90" class="mh mi it md b gy mj mk l ml mm">&gt;&gt;&gt; from torchvision import models                                                                                                                                                                   <br/>&gt;&gt;&gt; from torch import nn                                                                                                                                                                             <br/>&gt;&gt;&gt; tv_model = models.vgg13(pretrained=True)                                                                                                                                                         <br/>&gt;&gt;&gt; model = nn.Sequential()                                                                                                                                                                          <br/>&gt;&gt;&gt; tv_model_children = list(tv_model.children())[:-1]                                                                                                                                               <br/>&gt;&gt;&gt; tv_model_children                                                                                                                                                                                <br/>[Sequential(                                                                                                                                                                                         <br/>  (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))                                                                                                                              <br/>  (1): ReLU(inplace=True)                                                                                                                                                                            <br/>  (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))                                                                                                                             <br/>  (3): ReLU(inplace=True)                                                                                                                                                                            <br/>  (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)                                                                                                                    <br/>[…snip…]                                                                                                                                                                           <br/>  (24): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)                                                                                                                   <br/>), AdaptiveAvgPool2d(output_size=(7, 7))]                                                                                                                                                            <br/>&gt;&gt;&gt;</span></pre><p id="3297" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">请注意，tv_model_children 列表中没有列出“分类器”模块。由于我们最终将把我们自己的分类器附加到上面创建的名为“model”的模型上，这正是我们想要的。</p><p id="30ff" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">现在，让我们将 tv_model_children 列表中的模块添加到我们的新模型中:</p><pre class="kj kk kl km gt mc md me mf aw mg bi"><span id="3f4c" class="mh mi it md b gy mj mk l ml mm">&gt;&gt;&gt; for i in range(len(tv_model_children)):                                                                                                                                                          <br/>...     model.add_module(str(i), tv_model_children[i])                                                                                                                                               <br/>...                                                                                                                                                                                                  <br/>&gt;&gt;&gt; model                                                                                                                                                                                            <br/>Sequential(                                                                                                                                                                                          <br/>  (0): Sequential(                                                                                                                                                                                   <br/>    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))                                                                                                                            <br/>    (1): ReLU(inplace=True)                                                                                                                                                                          <br/>    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))                                                                                                                           <br/>    (3): ReLU(inplace=True)                                                                                                                                                                          <br/>    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)                                                                                                                  <br/>[…snip…]                        <br/>    (24): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)                                                                                                                 <br/>  )                                                                                                                                                                                                  <br/>  (1): AdaptiveAvgPool2d(output_size=(7, 7))                                                                                                                                                         <br/>)</span></pre><p id="78dd" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">此时，一切似乎都如我所愿。我已经有效地从 torchvision vgg13 预训练模型中“删除”了分类器模块。现在，我可以用我选择的任何名称将分类器附加到模型上。我的下一步是在我的程序中复制这种方法，看看它是如何工作的:</p><pre class="kj kk kl km gt mc md me mf aw mg bi"><span id="9e6e" class="mh mi it md b gy mj mk l ml mm">python train.py --arch vgg13 --dropout 0.2 --epochs 7 --gpu --hidden_units 1024 512 256 --learning_rate 0.003 /opt/data/flowers</span><span id="2400" class="mh mi it md b gy mo mk l ml mm">Constructing vgg13 pretrained neural network:                                                                                                                                                        <br/>        Hidden units:  [1024, 512, 256]                                                                                                                                                              <br/>                                                                                                                                                                                                     <br/>Establishing training, validation and testing loaders...                                                                                                                                             <br/>                                                                                                                                                                                                     <br/>Training classification layer:                                                                                                                                                                       <br/>        Epochs:  7                                                                                                                                                                                   <br/>        Learning Rate:  0.003                                                                                                                                                                        <br/>        Dropout Prob:  0.2                                                                                                                                                                           <br/>        GPU:  True</span><span id="8df3" class="mh mi it md b gy mo mk l ml mm">Traceback (most recent call last):                                                                                                                                                                   <br/>  File "train.py", line 38, in &lt;module&gt;                                                                                                                                                              <br/>    checkpoint = trainmodel(args, model, loader_dict)                                                                                                                                                <br/>  File "/home/rsbrownjr/work/test/aikit.py", line 369, in trainmodel                                                                                                                                 <br/>    output = model.forward(images)                                                                                                                                                                   <br/>  File "/home/rsbrownjr/anaconda3/envs/imgclassifier/lib/python3.6/site-packages/torch/nn/modules/container.py", line 92, in forward                                                                 <br/>    input = module(input)                                                                                                                                                                            <br/>  File "/home/rsbrownjr/anaconda3/envs/imgclassifier/lib/python3.6/site-packages/torch/nn/modules/module.py", line 547, in __call__                                                                  <br/>    result = self.forward(*input, **kwargs)                                                                                                                                                          <br/>  File "/home/rsbrownjr/work/test/aikit.py", line 37, in forward                                                                                                                                     <br/>    x = F.relu(linear(x))                                                                                                                                                                            <br/>  File "/home/rsbrownjr/anaconda3/envs/imgclassifier/lib/python3.6/site-packages/torch/nn/modules/module.py", line 547, in __call__                                                                  <br/>    result = self.forward(*input, **kwargs)                                                                                                                                                          <br/>  File "/home/rsbrownjr/anaconda3/envs/imgclassifier/lib/python3.6/site-packages/torch/nn/modules/linear.py", line 87, in forward                                                                    <br/>    return F.linear(input, self.weight, self.bias)                                                                                                                                                   <br/>  File "/home/rsbrownjr/anaconda3/envs/imgclassifier/lib/python3.6/site-packages/torch/nn/functional.py", line 1371, in linear                                                                       <br/>    output = input.matmul(weight.t())                                                                                                                                                                <br/>RuntimeError: size mismatch, m1: [114688 x 7], m2: [25088 x 1024] at /pytorch/aten/src/THC/generic/THCTensorMathBlas.cu:273</span></pre><p id="7b4b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">好吧，这可不太管用，不是吗？让我们看看生成的模型，并将其与预训练的 vgg13 架构进行比较，因为异常输出提到了乘法步骤中涉及的张量大小问题。也许在创建模型的过程中有些东西被破坏了？</p><pre class="kj kk kl km gt mc md me mf aw mg bi"><span id="e4f7" class="mh mi it md b gy mj mk l ml mm">Sequential(                                                                                                                                                                                          <br/>  (0): Sequential(                                                                                                                                                                                   <br/>    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))                                                                                                                            <br/>    (1): ReLU(inplace=True)                                                                                                                                                                          <br/>    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))                                                                                                                           <br/>    (3): ReLU(inplace=True)                                                                                                                                                                          <br/>[…snip…]                                                                                                                                   <br/>    (24): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)                                                                                                                 <br/>  )                                                                                                                                                                                                  <br/>  (1): AdaptiveAvgPool2d(output_size=(7, 7))                                                                                                                                                         <br/>  (fc): Network(                                                                                                                                                                                     <br/>    (hidden_layers): ModuleList(                                                                                                                                                                     <br/>      (0): Linear(in_features=25088, out_features=1024, bias=True)</span><span id="708c" class="mh mi it md b gy mo mk l ml mm">(1): Dropout(p=0.2, inplace=False)                                                                                                                                   <br/>      (2): Linear(in_features=1024, out_features=512, bias=True)                                                                                                                                     <br/>      (3): Linear(in_features=512, out_features=256, bias=True)                                                                                                                                      <br/>    )                                                                                                                                                                                                                                                                                                                                                          <br/>    (output): Linear(in_features=256, out_features=34, bias=True)                                                                                                                                    <br/>  )                                                                                                                                                                                                  <br/>)</span></pre><p id="a740" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">一切看起来井然有序。我的分类器只有一个名为“fc”的副本，dropout 层现在位于正确的位置，尽管我完成后会有更多的分类器。此时，我被难住了。我去了谷歌的搜索引擎。</p><p id="0ded" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">搜索类似于“删除火炬视觉模型的最后一个模块”的字符串会提供大量线索。有人建议 Python 的“del”函数可以和我想要移除的图层的名称一起使用。这是行不通的，因为 PyTorch 的“Sequential”对象没有“del”方法。许多其他的线索包含了和我自己相似的问题，但是都没有答案。</p><p id="a352" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">还有其他线索包含一个共同主题的变化。这些线程依赖于使用“children()”方法，但是它们直接绕过了 add_module()方法。例如:</p><pre class="kj kk kl km gt mc md me mf aw mg bi"><span id="634b" class="mh mi it md b gy mj mk l ml mm">model = models.resnet152(pretrained=True)<br/>newmodel = torch.nn.Sequential(*(list(model.children())[:-1]))<br/>print(newmodel)</span></pre><p id="9a98" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这看起来和我之前尝试的方法非常相似。但是，因为它没有直接使用 add_module 方法，所以我想在我的代码中尝试一下。再次执行程序后，我得到了完全相同的异常输出。这里也不走运。</p><p id="b4fa" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">此时，我开始考虑尺寸不匹配的潜在来源。由于我的新模型与预训练模型的架构几乎相同，我开始想知道这两个模型之间有什么不同。当我直接使用 torchvision vgg13 型号时，它工作正常。当我在试图删除分类模块时“复制”它时，它没有。</p><p id="2f07" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我又回头看了一遍回溯，发现提到了对“forward”的调用。这给了我一个想法。如果仅仅是将模块从一个架构复制到另一个架构，而不包括与模型相关联的 forward()方法的副本，那会怎么样呢？在偶然发现这个想法后，我回到我的代码，添加了下面一行:</p><pre class="kj kk kl km gt mc md me mf aw mg bi"><span id="654f" class="mh mi it md b gy mj mk l ml mm">model.forward = tv_model.forward</span></pre><p id="8b35" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">再次运行该程序产生了另一个异常，但这一次非常不同，它的内容帮助我认识到:</p><pre class="kj kk kl km gt mc md me mf aw mg bi"><span id="8c3d" class="mh mi it md b gy mj mk l ml mm">Traceback (most recent call last):                                                                                                                                                                   <br/>  File "train.py", line 38, in &lt;module&gt;                                                                                                                                                              <br/>    checkpoint = trainmodel(args, model, loader_dict)                                                                                                                                                <br/>  File "/home/rsbrownjr/work/test/aikit.py", line 371, in trainmodel                                                                                                                                 <br/>    output = model.forward(images)                                                                                                                                                                   <br/>  File "/home/rsbrownjr/anaconda3/envs/imgclassifier/lib/python3.6/site-packages/torchvision/models/vgg.py", line 46, in forward                                                                     <br/>    x = self.classifier(x)                                                                                                                                                                           <br/>  File "/home/rsbrownjr/anaconda3/envs/imgclassifier/lib/python3.6/site-packages/torch/nn/modules/module.py", line 547, in __call__                                                                  <br/>    result = self.forward(*input, **kwargs)                                                                                                                                                          <br/>  File "/home/rsbrownjr/anaconda3/envs/imgclassifier/lib/python3.6/site-packages/torch/nn/modules/container.py", line 92, in forward                                                                 <br/>    input = module(input)                                                                                                                                                                            <br/>  File "/home/rsbrownjr/anaconda3/envs/imgclassifier/lib/python3.6/site-packages/torch/nn/modules/module.py", line 547, in __call__                                                                  <br/>    result = self.forward(*input, **kwargs)                                                                                                                                                          <br/>  File "/home/rsbrownjr/anaconda3/envs/imgclassifier/lib/python3.6/site-packages/torch/nn/modules/linear.py", line 87, in forward                                                                    <br/>    return F.linear(input, self.weight, self.bias)                                                                                                                                                   <br/>  File "/home/rsbrownjr/anaconda3/envs/imgclassifier/lib/python3.6/site-packages/torch/nn/functional.py", line 1369, in linear                                                                       <br/>    ret = torch.addmm(bias, input, weight.t())                                                                                                                                                       <br/>RuntimeError: Expected object of backend CPU but got backend CUDA for argument #4 'mat1'</span></pre><p id="d4d2" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">请注意，这个异常不仅不同，而且它似乎是基于对一个名为“classifier”而不是“fc”的方法的调用！换句话说，将向前方法转移到我的新模型<strong class="lb iu"> <em class="mn">中，解决了尺寸不匹配的问题</em> </strong>。但是 torchvision vgg13 模型内部的前向代码仍然在寻找一个叫做“分类器”而不是“fc”的方法。如果我想让这种方法工作，我就要编写我自己的 forward 方法，以便通过每个不同层的输入产生正确大小的输入，进入我的分类器<strong class="lb iu"> <em class="mn">，其中</em> </strong>是分类器的正确名称。不值得。</p><p id="af1e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我也开始想知道与火炬视觉 vgg13 模型相关的参数。很可能我也要照顾这些。同样，不值得。</p><p id="cac5" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">作为我尝试操作 torchvision 预训练模型的层的研究结果，我得出的结论是，没有任何方法可以让我将我的方法推广到我的训练代码中的不同网络。</p><p id="21ec" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我必须考虑代码内部层名的差异，或者干脆选择与最终分类模块同名的 torchvision 架构。我至少可以说，通过这次练习，我学到了很多东西，并享受了这段旅程。</p><p id="8e3d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我希望你发现这是一份有价值的资料。</p></div></div>    
</body>
</html>