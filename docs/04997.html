<html>
<head>
<title>How To Build a Recommendation Engine for Starbucks</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">如何为星巴克搭建推荐引擎</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/how-to-build-a-recommendation-engine-for-starbucks-662a982df0c2?source=collection_archive---------14-----------------------#2019-07-27">https://towardsdatascience.com/how-to-build-a-recommendation-engine-for-starbucks-662a982df0c2?source=collection_archive---------14-----------------------#2019-07-27</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><figure class="gl gn jr js jt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi jq"><img src="../Images/acc57a7fc332d9647e7838615b1d8012.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*CIRa2Zftrw-uI9BuAWRbMw.jpeg"/></div></div><figcaption class="kb kc gj gh gi kd ke bd b be z dk">The Embarcadero, San Francisco, CA</figcaption></figure><p id="c035" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">咖啡对我们生活和文化的影响怎么强调都不为过。2018 年，64%的 18 岁或以上的美国人说他们前一天喝了一杯咖啡，而星巴克约占美国咖啡连锁行业的 40%。</p><p id="52bf" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">在这篇文章中，我们将探索不同的方法来建立一个推荐引擎，推荐 10 种未指定的星巴克产品。这些优惠可以是<em class="le">买一送一</em> (BOGO)，折扣或信息。共有 10 个优惠，它们在难度、持续时间和奖励方面各不相同。</p><p id="8c6d" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">对于每一种方法，我们将用数学公式抽象出问题，解释它如何应用到方法中，并用 python 代码解释它。</p><h1 id="bd9d" class="lf lg it bd lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc bi translated">获取数据</h1><figure class="me mf mg mh gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi md"><img src="../Images/fdcf821e89ecf47c6ec710dbb04bb7d7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*qMYLVFiqdBexeekU"/></div></div><figcaption class="kb kc gj gh gi kd ke bd b be z dk">Photo by <a class="ae ld" href="https://unsplash.com/@nate_dumlao?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Nathan Dumlao</a> on <a class="ae ld" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><p id="6cc5" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">用户的<a class="ae ld" href="https://github.com/NadimKawwa/starbucks/tree/master/data" rel="noopener ugc nofollow" target="_blank">数据</a>已经被清理，在<a class="ae ld" href="https://github.com/NadimKawwa/starbucks/blob/master/03_Starbucks_Capstone_notebook_RecommendationEngine.ipynb" rel="noopener ugc nofollow" target="_blank"> GitHub </a>上有 python 的详细实现。虽然没有在这篇文章中讨论，但是<a class="ae ld" rel="noopener" target="_blank" href="/a-z-feature-engineering-with-starbucks-b40c47462de9">清洗过程</a>在设置中注入了一些变化，并且影响了我们的输出。</p><p id="15a9" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">任何数据科学项目的症结都在于数据收集、争论以及在此过程中做出的许多假设。这个项目绝不是一个例外。当我们讨论不同的方法时，请记住数据的质量是支持我们结论的基石。</p><p id="397c" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">第一条信息是用户特征矩阵，其中行是 Starbucks 用户 id，列是关于这些用户的属性。我们总共有大约 17，000 个用户和 23 个功能，有些是直接观察到的，例如:</p><ul class=""><li id="fdb6" class="mi mj it kh b ki kj km kn kq mk ku ml ky mm lc mn mo mp mq bi translated">收到的报价数量</li><li id="257e" class="mi mj it kh b ki mr km ms kq mt ku mu ky mv lc mn mo mp mq bi translated">报价类型(电子邮件、社交媒体等)</li><li id="0126" class="mi mj it kh b ki mr km ms kq mt ku mu ky mv lc mn mo mp mq bi translated">收入</li></ul><p id="e7d5" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">其他的来源于用户抄本，例如:</p><ul class=""><li id="9651" class="mi mj it kh b ki kj km kn kq mk ku ml ky mm lc mn mo mp mq bi translated">回应或完成报价的平均时间</li><li id="5ca1" class="mi mj it kh b ki mr km ms kq mt ku mu ky mv lc mn mo mp mq bi translated">每次出价的平均奖励</li><li id="8aff" class="mi mj it kh b ki mr km ms kq mt ku mu ky mv lc mn mo mp mq bi translated">因为出价而花费的总金额</li></ul><p id="7998" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">下面是用户数据框架的示例截图:</p><figure class="me mf mg mh gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi mw"><img src="../Images/8069ff07eabad5398ac28fe730228a2e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*T0wcFl8yN4VBo2_HE699eQ.png"/></div></div><figcaption class="kb kc gj gh gi kd ke bd b be z dk">User-Feature Matrix</figcaption></figure><p id="9d95" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">还有一份抄本的样本:</p><figure class="me mf mg mh gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi mx"><img src="../Images/a6c8cacb1227abf435c47a0033d65dfd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*2VZkMnlvZNEBWy7v8EM5tw.png"/></div></div><figcaption class="kb kc gj gh gi kd ke bd b be z dk">Transcript of User Behavior</figcaption></figure><p id="5f2b" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">第三个数据帧是一个用户项目矩阵，其中行是用户，列是报价 id，这也是一个非常稀疏的矩阵。我们的条目将是多少次，如果有的话，用户已经查看了报价。如果没有收到报价，我们输入一个<a class="ae ld" href="https://en.wikipedia.org/wiki/NaN" rel="noopener ugc nofollow" target="_blank"> NaN </a>值，因为我们无法衡量未被请求的参与度。</p><figure class="me mf mg mh gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi my"><img src="../Images/c8aabfebdc82c1c74831cc81a28c02ef.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Q5FAQzC8Jlt8RKWTVxyhDQ.png"/></div></div><figcaption class="kb kc gj gh gi kd ke bd b be z dk">User-Item Matrix</figcaption></figure><h1 id="d725" class="lf lg it bd lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc bi translated">推荐什么最受欢迎</h1><figure class="me mf mg mh gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi mz"><img src="../Images/b0c3efc30b569531d014e2e3e83d5a71.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*aAqcxx3btGTteDrp"/></div></div><figcaption class="kb kc gj gh gi kd ke bd b be z dk">Photo by <a class="ae ld" href="https://unsplash.com/@heftiba?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Toa Heftiba</a> on <a class="ae ld" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><p id="8482" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">美国最受欢迎的咖啡饮料是拿铁，美国人在 2017 年 6 月至 2018 年 6 月期间喝了超过<a class="ae ld" href="https://squareup.com/us/en/townsquare/coffee-day-2018" rel="noopener ugc nofollow" target="_blank"> 67，000，000 </a>杯拿铁。我们应该总是建议喝杯拿铁吗？</p><p id="ed68" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">第一种方法是最简单的:建议什么是最流行的。人们的假设是，受大众欢迎的东西也受个人欢迎。</p><p id="4ed6" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">出现的一个问题是，我们如何定义流行度，在这种情况下，我们提出两种方法:</p><ul class=""><li id="f12b" class="mi mj it kh b ki kj km kn kq mk ku ml ky mm lc mn mo mp mq bi translated">浏览量最多的出价</li><li id="93d8" class="mi mj it kh b ki mr km ms kq mt ku mu ky mv lc mn mo mp mq bi translated">每次观看回报率最高的报价</li></ul><p id="2cd0" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">最受欢迎视图的实现方式如下:</p><figure class="me mf mg mh gt ju"><div class="bz fp l di"><div class="na nb l"/></div></figure><p id="88d6" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">这种方法在新颖性和用户的意外收获方面有所欠缺。它还可以通过已经流行的方式使项目变得流行。</p><p id="580d" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">然而，这是一个稳健的解决方案，这也意味着我们总是有地方开始，并且不受冷启动问题的影响。此外，将这个工具放在用户手中也很有用，他们可以选择“最流行”或“最近”的项目。这是一个基于<a class="ae ld" href="https://en.wikipedia.org/wiki/Knowledge-based_recommender_system" rel="noopener ugc nofollow" target="_blank">知识的</a>方法的例子。</p><p id="5607" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">当我们探索其他方法时，我们的基本假设是视图会带来更多的用户参与和金钱回报。</p><h1 id="454a" class="lf lg it bd lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc bi translated">协同过滤:用户-用户相似性</h1><figure class="me mf mg mh gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi nc"><img src="../Images/10ba1bd1a59609b502aaa56b2644e483.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*IhSNod2RMvg2Y0IC"/></div></div><figcaption class="kb kc gj gh gi kd ke bd b be z dk">Photo by <a class="ae ld" href="https://unsplash.com/@nanihana?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Nani Williams</a> on <a class="ae ld" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><p id="bb3a" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">我们的消费习惯经常受到身边人的行为影响。我们向朋友询问他们最喜欢的商品，或者在网上寻找评论。</p><p id="db2a" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">下一种方法是利用用户之间的相似性来提出建议。这里的假设是，无论我们如何定义相似性，相似的人都会喜欢相似的东西。随着那些相似的邻居被识别，我们向我们的原始用户建议我们的邻居喜欢的新奇物品。</p><p id="1c1d" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">这种方法被称为<a class="ae ld" href="https://en.wikipedia.org/wiki/Collaborative_filtering" rel="noopener ugc nofollow" target="_blank">协同过滤</a>，我们给出了三种实现方法。我们首先创建一个简单的函数来收集单个用户看到的报价。</p><figure class="me mf mg mh gt ju"><div class="bz fp l di"><div class="na nb l"/></div></figure><p id="376d" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">然后，我们可以构建一个字典来存储用户看到的报价。</p><figure class="me mf mg mh gt ju"><div class="bz fp l di"><div class="na nb l"/></div></figure><p id="c121" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">我们现在可以着手测量用户之间的相似性。</p><h2 id="e076" class="nd lg it bd lh ne nf dn ll ng nh dp lp kq ni nj lt ku nk nl lx ky nm nn mb no bi translated">欧几里德距离</h2><p id="2381" class="pw-post-body-paragraph kf kg it kh b ki np kk kl km nq ko kp kq nr ks kt ku ns kw kx ky nt la lb lc im bi translated">如果我们把用户想象成空间中的点，那么我们可以认为占据同一个邻域的用户非常相似。因此，如果我们取一个用户，k 个最近邻居应该是最相似的。如果这听起来很熟悉，那是因为它确实是<a class="ae ld" href="https://en.wikipedia.org/wiki/K-nearest_neighbors_algorithm" rel="noopener ugc nofollow" target="_blank">K-最近邻</a>算法。</p><p id="9fd9" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">对于两个向量<strong class="kh iu"> x </strong>和<strong class="kh iu"> y </strong>，我们计算欧几里德距离为:</p><figure class="me mf mg mh gt ju gh gi paragraph-image"><div class="gh gi nu"><img src="../Images/03b48c35d0987fb5d24abc030acd107d.png" data-original-src="https://miro.medium.com/v2/resize:fit:910/format:webp/1*MhZ0y949BX_3oL_JwfAJCg.png"/></div></figure><p id="03ec" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">在 python 代码中:</p><figure class="me mf mg mh gt ju"><div class="bz fp l di"><div class="na nb l"/></div></figure><p id="84c5" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">和 KNN 一样，欧几里得距离对比例很敏感。或者，我们可以用<a class="ae ld" href="https://en.wikipedia.org/wiki/Taxicab_geometry" rel="noopener ugc nofollow" target="_blank">曼哈顿距离</a> ( <em class="le"> L1 范数</em>)来度量相似性。</p><h2 id="575a" class="nd lg it bd lh ne nf dn ll ng nh dp lp kq ni nj lt ku nk nl lx ky nm nn mb no bi translated">相互关系</h2><p id="9d39" class="pw-post-body-paragraph kf kg it kh b ki np kk kl km nq ko kp kq nr ks kt ku ns kw kx ky nt la lb lc im bi translated"><a class="ae ld" href="https://en.wikipedia.org/wiki/Pearson_correlation_coefficient" rel="noopener ugc nofollow" target="_blank">皮尔逊相关系数</a>返回一个介于-1 和+1 之间的值，其中+1 表示非常强的正相关，而-1 表示非常强的负相关。</p><p id="42cf" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">相关系数<em class="le"> ρ </em>由下式给出:</p><figure class="me mf mg mh gt ju gh gi paragraph-image"><div class="gh gi nv"><img src="../Images/ceec67627dcc6497b2480fd733db196a.png" data-original-src="https://miro.medium.com/v2/resize:fit:542/format:webp/1*YFYvsAHEkjKqA4ABrbegww.png"/></div></figure><p id="ed8c" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">到这样的程度</p><ul class=""><li id="45c7" class="mi mj it kh b ki kj km kn kq mk ku ml ky mm lc mn mo mp mq bi translated">cov(X，Y)=<a class="ae ld" href="https://en.wikipedia.org/wiki/Covariance" rel="noopener ugc nofollow" target="_blank">X 和 Y 的协方差</a></li><li id="7bed" class="mi mj it kh b ki mr km ms kq mt ku mu ky mv lc mn mo mp mq bi translated"><em class="le"> σ </em> = <a class="ae ld" href="https://en.wikipedia.org/wiki/Variance" rel="noopener ugc nofollow" target="_blank">方差</a></li></ul><p id="5de5" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">在 python 代码中:</p><figure class="me mf mg mh gt ju"><div class="bz fp l di"><div class="na nb l"/></div></figure><p id="22b0" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">虽然还有其他方法，如<a class="ae ld" href="https://en.wikipedia.org/wiki/Spearman's_rank_correlation_coefficient" rel="noopener ugc nofollow" target="_blank"> Kendall </a>的 Tau 和<a class="ae ld" href="https://en.wikipedia.org/wiki/Spearman%27s_rank_correlation_coefficient" rel="noopener ugc nofollow" target="_blank"> Spearman 的等级相关性</a>，但选择正确的方法取决于数据分布。</p><p id="7d48" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">皮尔逊系数的一个关键优势是它对缩放比例不变。然而，它对异常值并不鲁棒，并且对底层数据分布做出假设。</p><p id="f11f" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">如果数据按照各自变量的样本均值移动，也就是说减去均值，皮尔逊相关就是两个变量之间夹角的余弦值，我们接下来将讨论这个问题。</p><h2 id="ae15" class="nd lg it bd lh ne nf dn ll ng nh dp lp kq ni nj lt ku nk nl lx ky nm nn mb no bi translated">余弦相似性</h2><p id="9e53" class="pw-post-body-paragraph kf kg it kh b ki np kk kl km nq ko kp kq nr ks kt ku ns kw kx ky nt la lb lc im bi translated">测量相似性的最后一种方法是测量两个向量之间的余弦。对于两个矢量<em class="le"> X </em>和<em class="le"> Y </em>，由下式给出:</p><figure class="me mf mg mh gt ju gh gi paragraph-image"><div class="gh gi nw"><img src="../Images/dd8290b115ff7bed0bc7f42911eda8bc.png" data-original-src="https://miro.medium.com/v2/resize:fit:664/format:webp/1*dTiWhcNnqhM233Ig8iubbw.png"/></div></figure><p id="1695" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">使得<em class="le"> ||X|| </em>和<em class="le"> ||Y|| </em>是向量的<a class="ae ld" href="https://en.wikipedia.org/wiki/Norm_(mathematics)" rel="noopener ugc nofollow" target="_blank">范数</a>。回想一下，零的余弦等于 1，这意味着两个向量具有相同的方向。我们可以用 scipy 实现这一点:</p><figure class="me mf mg mh gt ju"><div class="bz fp l di"><div class="na nb l"/></div></figure><h1 id="878f" class="lf lg it bd lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc bi translated">矩阵分解</h1><figure class="me mf mg mh gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi nx"><img src="../Images/e829402312fe71cbf8ef01a7312c6b4d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*aUSl0RChp_Vbc0er"/></div></div><figcaption class="kb kc gj gh gi kd ke bd b be z dk">Photo by <a class="ae ld" href="https://unsplash.com/@nousnou?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">nousnou iwasaki</a> on <a class="ae ld" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><p id="16d3" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">实际上，我们想知道客户对我们的产品有什么反应。请记住，发出要约是有成本的。在我们的例子中，我们想要测量用户参与度:如果我们提出一些建议，用户真的会看到吗？</p><p id="2451" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">假设检验似乎很有吸引力，因为这是衡量成功的一个好方法。如果我们可以离线测试我们的推荐会怎么样？如果我们还可以预测还没看过的项目的评分呢？我们将在本节中尝试回答这些问题。</p><p id="9a59" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">奇异值分解(<a class="ae ld" href="https://en.wikipedia.org/wiki/Singular_value_decomposition" rel="noopener ugc nofollow" target="_blank"> SVD </a>)是一个实数或复数矩阵的因式分解，让我们看到<a class="ae ld" href="https://en.wikipedia.org/wiki/Latent_variable" rel="noopener ugc nofollow" target="_blank">无法直接观察到的潜在特征</a>。它将一个<em class="le"> mxn </em>矩阵分解成:</p><ul class=""><li id="5a8d" class="mi mj it kh b ki kj km kn kq mk ku ml ky mm lc mn mo mp mq bi translated">U: <a class="ae ld" href="https://en.wikipedia.org/wiki/Unitary_matrix" rel="noopener ugc nofollow" target="_blank">酉矩阵</a>，显示用户与潜在因素的关系</li><li id="68a4" class="mi mj it kh b ki mr km ms kq mt ku mu ky mv lc mn mo mp mq bi translated">∑: <a class="ae ld" href="https://en.wikipedia.org/wiki/Diagonal_matrix#Rectangular_diagonal_matrices" rel="noopener ugc nofollow" target="_blank">对角矩阵</a>以值降序排列，条目为潜在因素</li><li id="3aa6" class="mi mj it kh b ki mr km ms kq mt ku mu ky mv lc mn mo mp mq bi translated">v:酉矩阵，显示项目如何与潜在因素相关</li></ul><p id="f719" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">这三个矩阵通过以下方式与原始用户项矩阵相关联:</p><figure class="me mf mg mh gt ju gh gi paragraph-image"><div class="gh gi ny"><img src="../Images/587e0e62ef1e379ef3f36d150aaec378.png" data-original-src="https://miro.medium.com/v2/resize:fit:1294/format:webp/1*uRFmZk2NWROM1iCIbDhMrQ.png"/></div></figure><ul class=""><li id="9c20" class="mi mj it kh b ki kj km kn kq mk ku ml ky mm lc mn mo mp mq bi translated">n =用户数量</li><li id="409a" class="mi mj it kh b ki mr km ms kq mt ku mu ky mv lc mn mo mp mq bi translated">k =潜在特征的数量</li><li id="0da5" class="mi mj it kh b ki mr km ms kq mt ku mu ky mv lc mn mo mp mq bi translated">m =项目数量</li></ul><p id="0487" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">我们将只使用 SVD 的属性，不会深入研究它的工作原理。为了更好的解释，我们推荐<a class="ae ld" href="http://infolab.stanford.edu/~ullman/mmds/ch11.pdf" rel="noopener ugc nofollow" target="_blank">斯坦福 CS246 </a>和这个<a class="ae ld" href="http://web.mit.edu/be.400/www/SVD/Singular_Value_Decomposition.htm" rel="noopener ugc nofollow" target="_blank">麻省理工学院教程</a>。</p><p id="7e24" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">∑ ( <em class="le"> sigma </em>)矩阵告诉我们许多关于用户项目矩阵中的原始可变性有多少被每个潜在特征所捕获。要解释的可变性总量是对角线元素的平方之和。</p><p id="6441" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">此外，由第一个分量解释的可变性的量是对角线上第一个值的平方，第二个值也是如此，以此类推。这意味着我们可以选择较少数量的潜在特征(<em class="le"> k </em>)并捕捉原始矩阵的几乎所有可变性，这是一个有助于节省计算的特性。</p><p id="e157" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">在我们拥有的真实用户条目矩阵中，许多值都丢失了。这意味着 SVD 不起作用。在 Netflix 颁奖期间，一个名叫西蒙·芬克的用户开发了 T2·芬克 SVD，作为一种计算缺失数据的方法。我们将通过这个算法的一个小例子，并推广到数据集。</p><p id="60da" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">初始化两个填充了随机值的矩阵<em class="le"> U </em>和<em class="le"> V.T </em>。我们转到原始的用户项矩阵，搜索第一个非缺失值。然后，我们取与用户相关的行和与电影相关的列的点积。</p><p id="5845" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">在我们的例子中，我们看到<em class="le"> person 0 </em>的第一个值是<em class="le"> offer_id </em> 4。以此为例，我们计算点积如下:</p><figure class="me mf mg mh gt ju gh gi paragraph-image"><div class="gh gi nz"><img src="../Images/2237eed4ce1c0ad76bbc358ea81cfae3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1268/format:webp/1*T-zPT5ptACoWTFMTuTdgvw.png"/></div></figure><figure class="me mf mg mh gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi oa"><img src="../Images/f493fea6fb3bda1a197469c6e711ec5c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*yuXqFD9hvfK2JPCBr9I0iQ.png"/></div></div></figure><figure class="me mf mg mh gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi ob"><img src="../Images/817ea43b1bffe25d8951f3474da9969c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ubKcP9llSnCArp9ktfiT_Q.png"/></div></div></figure><p id="5744" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">从这里我们可以计算出误差:</p><figure class="me mf mg mh gt ju gh gi paragraph-image"><div class="gh gi oc"><img src="../Images/e88fd15ef195db7f051c788195fbfcfb.png" data-original-src="https://miro.medium.com/v2/resize:fit:900/format:webp/1*LV7dhP2F9abY-DDAQATLew.png"/></div></figure><p id="2cf7" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">对于真实值 1，我们的误差是 4.24。我们的目标是通过改变每个矩阵中的权重来最小化所有已知值的误差，我们可以通过<a class="ae ld" href="https://en.wikipedia.org/wiki/Gradient_descent" rel="noopener ugc nofollow" target="_blank">梯度下降</a>来实现。</p><p id="5d4f" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">在用户矩阵中，我们取误差相对于每个值<em class="le"> ui </em>的导数。</p><figure class="me mf mg mh gt ju gh gi paragraph-image"><div class="gh gi od"><img src="../Images/3401c7c17de1c135714e2bc313f29c4b.png" data-original-src="https://miro.medium.com/v2/resize:fit:936/format:webp/1*VlAa1hrOHIBonFh9p3P9Gw.png"/></div></figure><p id="f488" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">在电影矩阵中，我们对每个值<em class="le"> vi </em>取误差的导数。</p><figure class="me mf mg mh gt ju gh gi paragraph-image"><div class="gh gi oe"><img src="../Images/b6c99ec000a7e2598742e12e8ca6ef34.png" data-original-src="https://miro.medium.com/v2/resize:fit:942/format:webp/1*WUVcM5UEO8T1tu8u1Pzb0g.png"/></div></figure><p id="d5d6" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">然后，我们通过向渐变的相反方向移动来更新高亮显示的值:</p><figure class="me mf mg mh gt ju gh gi paragraph-image"><div class="gh gi of"><img src="../Images/f3d5b150c4525cab9ebc756f29f9bc2a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1182/format:webp/1*vcvHUSGhG58BeamYhe_EjA.png"/></div></figure><p id="c9be" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">我们对用户项目矩阵中的所有已知评级进行相同的计算，并对设定数量的时期重复。</p><p id="2ded" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">用 python 实现这一点:</p><figure class="me mf mg mh gt ju"><div class="bz fp l di"><div class="na nb l"/></div></figure><p id="3043" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">我们现在想建立一种方法来验证我们的预测。我们在训练和验证中拆分数据，使 FunkSVD 适合训练数据，并在验证数据中为用户做出预测:</p><figure class="me mf mg mh gt ju"><div class="bz fp l di"><div class="na nb l"/></div></figure><p id="efbe" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">让我们用直方图和<a class="ae ld" href="https://en.wikipedia.org/wiki/Confusion_matrix" rel="noopener ugc nofollow" target="_blank">混淆矩阵</a>来看看我们的预测。</p><figure class="me mf mg mh gt ju gh gi paragraph-image"><div class="gh gi og"><img src="../Images/01245198c44f4eb1217e2355b32abe06.png" data-original-src="https://miro.medium.com/v2/resize:fit:1152/format:webp/1*XjZpTZrqLim3hOc8wjxmCA.png"/></div></figure><figure class="me mf mg mh gt ju gh gi paragraph-image"><div class="gh gi oh"><img src="../Images/3472ffff84754ed8546ca71abb3125cd.png" data-original-src="https://miro.medium.com/v2/resize:fit:864/format:webp/1*Pz-gzoegtj2Q7j5kv3RvnQ.png"/></div></figure><p id="2a14" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">我们可以看到 w 在某些方面是错误的，但是能够预测看不见的项目是一个非常有用的特性。我们也可以使用<a class="ae ld" href="https://en.wikipedia.org/wiki/Hyperparameter_optimization#Grid_search" rel="noopener ugc nofollow" target="_blank">网格搜索</a>来调整我们的超参数。改进这种方法的研究正在进行中，如赵等人<a class="ae ld" href="https://www.hindawi.com/journals/mpe/2015/380472/" rel="noopener ugc nofollow" target="_blank">的论文</a>。</p><h1 id="691b" class="lf lg it bd lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc bi translated">结论</h1><p id="787c" class="pw-post-body-paragraph kf kg it kh b ki np kk kl km nq ko kp kq nr ks kt ku ns kw kx ky nt la lb lc im bi translated">我们看到有多种方法可以提供建议，每种方法都有其优势。没有明确的答案，通常使用混合方法的项目可能是最好的解决方案。</p><p id="8dc2" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">与大多数数据科学项目一样，我们拥有的高质量数据越多，结果就越好。希望你喜欢这篇文章！</p><p id="0221" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated"><em class="le">鸣谢:帮助撰写本文的咖啡因是由三号</em><em class="le"/><a class="ae ld" href="https://goo.gl/maps/aNBha9XBEZDWRvZh6" rel="noopener ugc nofollow" target="_blank"><em class="le">菲尔茨在福尔松</em> </a> <em class="le">和</em> <a class="ae ld" href="https://goo.gl/maps/mAoCp2icg4Y1uv1L8" rel="noopener ugc nofollow" target="_blank"> <em class="le"> Illy on Battery 的</em> </a><a class="ae ld" href="https://goo.gl/maps/5MkcTTEUhZAmkFdp9" rel="noopener ugc nofollow" target="_blank"> <em class="le">星巴克的了不起的咖啡师准备的。</em> </a> <em class="le">特别感谢</em><a class="ae ld" href="https://www.udacity.com" rel="noopener ugc nofollow" target="_blank"><em class="le">uda city</em></a><em class="le">和星巴克提供这些数据！</em></p></div></div>    
</body>
</html>