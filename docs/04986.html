<html>
<head>
<title>Object Detection with YOLOv3 using Keras</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用 Keras 的 YOLOv3 对象检测</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/object-detection-using-yolov3-using-keras-80bf35e61ce1?source=collection_archive---------3-----------------------#2019-07-27">https://towardsdatascience.com/object-detection-using-yolov3-using-keras-80bf35e61ce1?source=collection_archive---------3-----------------------#2019-07-27</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><p id="8719" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><a class="ae ko" href="https://medium.com/datadriveninvestor/computer-vision-a-journey-from-cnn-to-mask-r-cnn-and-yolo-1d141eba6e04" rel="noopener"> <strong class="js iu"> <em class="kp">第一部分——CNN，R-CNN，快 R-CNN，更快 R-CNN</em></strong>T5】</a></p><p id="49bb" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><a class="ae ko" href="https://medium.com/@arshren/computer-vision-a-journey-from-cnn-to-mask-r-cnn-and-yolo-part-2-b0b9e67762b1" rel="noopener"> <strong class="js iu"> <em class="kp">第二部分——了解 YOLO、约洛夫 2、YOLO v3 </em> </strong> </a></p><p id="c0ed" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">这是本系列的第三篇文章，我们将使用 YOLOv3 预测边界框和类。代码可用<a class="ae ko" href="https://github.com/arshren/YOLOV3/blob/master/YOLO%20Step%20by%20Step.ipynb" rel="noopener ugc nofollow" target="_blank"><strong class="js iu"><em class="kp">github</em></strong></a></p><figure class="kr ks kt ku gt kv gh gi paragraph-image"><div class="gh gi kq"><img src="../Images/08d5fe670046d060b5069f5c3bf64d0f.png" data-original-src="https://miro.medium.com/v2/resize:fit:878/format:webp/1*5QxLHrHA2odQUwCUHhnEfw.png"/></div><figcaption class="ky kz gj gh gi la lb bd b be z dk">output from YOLO v3</figcaption></figure><blockquote class="lc"><p id="6343" class="ld le it bd lf lg lh li lj lk ll kn dk translated">你只需要看一次(YOLO)图像，就可以使用一个卷积网络来预测什么物体存在以及它们在哪里。YOLO 预测多个边界框和这些框的类别概率。</p></blockquote><p id="a25b" class="pw-post-body-paragraph jq jr it js b jt ln jv jw jx lo jz ka kb lp kd ke kf lq kh ki kj lr kl km kn im bi translated">这段代码将使用 yolo v3 中预先训练的权重，然后使用 keras 库预测边界框和类概率</p><p id="78ea" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">该代码受到 experiencor 的 keras-yolo3 projec 的强烈启发，用于使用 YOLOv3 模型执行对象检测。代码是将代码分解成简单的步骤，使用 yolov3 模型来预测边界框和类。<a class="ae ko" href="https://github.com/experiencor/keras-yolo3/blob/master/yolo3_one_file_to_detect_them_all.py" rel="noopener ugc nofollow" target="_blank">原始代码可从 Huynh Ngoc Anh 的 github 获得</a>。<strong class="js iu"> Yolo3 预训练权重可从</strong> <a class="ae ko" href="https://pjreddie.com/media/files/yolov3.weights" rel="noopener ugc nofollow" target="_blank"> <strong class="js iu"> YOLOv3 预训练权重</strong> </a> <strong class="js iu">下载。</strong></p><p id="4756" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">YOLOv3 模型使用预先训练的权重来解决标准对象检测问题，如袋鼠数据集、浣熊数据集、红细胞检测等。该模型将用于新图像上的对象检测。</p><p id="9a47" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu">第一步:</strong>导入所需的库</p><pre class="kr ks kt ku gt ls lt lu lv aw lw bi"><span id="8aaf" class="lx ly it lt b gy lz ma l mb mc">import os<br/>import scipy.io<br/>import scipy.misc<br/>import numpy as np<br/>import pandas as pd<br/>import PIL<br/>import struct<br/>import cv2<br/>from numpy import expand_dims</span><span id="9e06" class="lx ly it lt b gy md ma l mb mc">import tensorflow as tf<br/>from skimage.transform import resize<br/>from keras import backend as K<br/>from keras.layers import Input, Lambda, Conv2D, BatchNormalization, LeakyReLU, ZeroPadding2D, UpSampling2D</span><span id="e6c8" class="lx ly it lt b gy md ma l mb mc">from keras.models import load_model, Model<br/>from keras.layers.merge import add, concatenate<br/>from keras.preprocessing.image import load_img<br/>from keras.preprocessing.image import img_to_array</span><span id="8643" class="lx ly it lt b gy md ma l mb mc">import matplotlib.pyplot as plt<br/>from matplotlib.pyplot import imshow<br/>from matplotlib.patches import Rectangle<br/>%matplotlib inline</span></pre><p id="6944" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu">第二步:创建一个类 WeightReader 来加载 yolov3 </strong>的预训练权重</p><p id="34c1" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">WeightReader 类将解析该文件并将模型权重加载到内存中，以在我们的 Keras 模型中设置它。</p><pre class="kr ks kt ku gt ls lt lu lv aw lw bi"><span id="979b" class="lx ly it lt b gy lz ma l mb mc"># class to load the pretrained Weights<br/><strong class="lt iu">class WeightReader:</strong><br/>    <strong class="lt iu">def __init__(self, weight_file)</strong>:<br/>        with open(weight_file, 'rb') as w_f:<br/>            major,    = struct.unpack('i', w_f.read(4))<br/>            minor,    = struct.unpack('i', w_f.read(4))<br/>            revision, = struct.unpack('i', w_f.read(4))</span><span id="c9aa" class="lx ly it lt b gy md ma l mb mc">if (major*10 + minor) &gt;= 2 and major &lt; 1000 and minor &lt; 1000:<br/>                w_f.read(8)<br/>            else:<br/>                w_f.read(4)</span><span id="d5be" class="lx ly it lt b gy md ma l mb mc">transpose = (major &gt; 1000) or (minor &gt; 1000)<br/>            <br/>            binary = w_f.read()</span><span id="d961" class="lx ly it lt b gy md ma l mb mc">self.offset = 0<br/>        self.all_weights = np.frombuffer(binary, dtype='float32')<br/>        <br/>    <strong class="lt iu">def read_bytes(self, size)</strong>:<br/>        self.offset = self.offset + size<br/>        return self.all_weights[self.offset-size:self.offset]</span><span id="83d1" class="lx ly it lt b gy md ma l mb mc"><strong class="lt iu">def load_weights(self, model):</strong><br/>        for i in range(106):<br/>            try:<br/>                conv_layer = model.get_layer('conv_' + str(i))<br/>                print("loading weights of convolution #" + str(i))</span><span id="3c27" class="lx ly it lt b gy md ma l mb mc">if i not in [81, 93, 105]:<br/>                    norm_layer = model.get_layer('bnorm_' + str(i))</span><span id="b81a" class="lx ly it lt b gy md ma l mb mc">size = np.prod(norm_layer.get_weights()[0].shape)</span><span id="3f94" class="lx ly it lt b gy md ma l mb mc">beta  = self.read_bytes(size) # bias<br/>                    gamma = self.read_bytes(size) # scale<br/>                    mean  = self.read_bytes(size) # mean<br/>                    var   = self.read_bytes(size) # variance</span><span id="d532" class="lx ly it lt b gy md ma l mb mc">weights = norm_layer.set_weights([gamma, beta, mean, var])</span><span id="c72c" class="lx ly it lt b gy md ma l mb mc">if len(conv_layer.get_weights()) &gt; 1:<br/>                    bias   = self.read_bytes(np.prod(conv_layer.get_weights()[1].shape))<br/>                    kernel = self.read_bytes(np.prod(conv_layer.get_weights()[0].shape))<br/>                    <br/>                    kernel = kernel.reshape(list(reversed(conv_layer.get_weights()[0].shape)))<br/>                    kernel = kernel.transpose([2,3,1,0])<br/>                    conv_layer.set_weights([kernel, bias])<br/>                else:<br/>                    kernel = self.read_bytes(np.prod(conv_layer.get_weights()[0].shape))<br/>                    kernel = kernel.reshape(list(reversed(conv_layer.get_weights()[0].shape)))<br/>                    kernel = kernel.transpose([2,3,1,0])<br/>                    conv_layer.set_weights([kernel])<br/>            except ValueError:<br/>                print("no convolution #" + str(i))     <br/>    <br/>    def reset(self):<br/>        self.offset = 0</span></pre><p id="7f59" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu">第三步:创建 Yolo v3 模型。</strong></p><p id="696f" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">我们首先创建一个函数来创建卷积块</p><pre class="kr ks kt ku gt ls lt lu lv aw lw bi"><span id="40ea" class="lx ly it lt b gy lz ma l mb mc"><strong class="lt iu">def _conv_block(inp, convs, skip=True):</strong><br/>    x = inp<br/>    count = 0<br/>    <br/>    for conv in convs:<br/>        if count == (len(convs) - 2) and skip:<br/>            skip_connection = x<br/>        count += 1<br/>        <br/>        if conv['stride'] &gt; 1: x = ZeroPadding2D(((1,0),(1,0)))(x) # peculiar padding as darknet prefer left and top<br/>        x = Conv2D(conv['filter'], <br/>                   conv['kernel'], <br/>                   strides=conv['stride'], <br/>                   padding='valid' if conv['stride'] &gt; 1 else 'same', # peculiar padding as darknet prefer left and top<br/>                   name='conv_' + str(conv['layer_idx']), <br/>                   use_bias=False if conv['bnorm'] else True)(x)<br/>        if conv['bnorm']: x = BatchNormalization(epsilon=0.001, name='bnorm_' + str(conv['layer_idx']))(x)<br/>        if conv['leaky']: x = LeakyReLU(alpha=0.1, name='leaky_' + str(conv['layer_idx']))(x)</span><span id="7fdd" class="lx ly it lt b gy md ma l mb mc">return add([skip_connection, x]) if skip else x</span></pre><p id="4952" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">接下来，我们创建一个有 108 个卷积层的<strong class="js iu">暗网</strong>。我在 CPU 上运行它，在 GPU 上它几乎快了 500 倍</p><pre class="kr ks kt ku gt ls lt lu lv aw lw bi"><span id="1b33" class="lx ly it lt b gy lz ma l mb mc"><strong class="lt iu"># creating the YOLO model</strong><br/>def make_yolov3_model():<br/>    input_image = Input(shape=(None, None, 3))</span><span id="b147" class="lx ly it lt b gy md ma l mb mc"># Layer  0 =&gt; 4<br/>    x = _conv_block(input_image, [{'filter': 32, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 0},<br/>                                  {'filter': 64, 'kernel': 3, 'stride': 2, 'bnorm': True, 'leaky': True, 'layer_idx': 1},<br/>                                  {'filter': 32, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 2},<br/>                                  {'filter': 64, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 3}])</span><span id="444e" class="lx ly it lt b gy md ma l mb mc"># Layer  5 =&gt; 8<br/>    x = _conv_block(x, [{'filter': 128, 'kernel': 3, 'stride': 2, 'bnorm': True, 'leaky': True, 'layer_idx': 5},<br/>                        {'filter':  64, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 6},<br/>                        {'filter': 128, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 7}])</span><span id="5403" class="lx ly it lt b gy md ma l mb mc"># Layer  9 =&gt; 11<br/>    x = _conv_block(x, [{'filter':  64, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 9},<br/>                        {'filter': 128, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 10}])</span><span id="356f" class="lx ly it lt b gy md ma l mb mc"># Layer 12 =&gt; 15<br/>    x = _conv_block(x, [{'filter': 256, 'kernel': 3, 'stride': 2, 'bnorm': True, 'leaky': True, 'layer_idx': 12},<br/>                        {'filter': 128, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 13},<br/>                        {'filter': 256, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 14}])</span><span id="c3c6" class="lx ly it lt b gy md ma l mb mc"># Layer 16 =&gt; 36<br/>    for i in range(7):<br/>        x = _conv_block(x, [{'filter': 128, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 16+i*3},<br/>                            {'filter': 256, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 17+i*3}])<br/>        <br/>    skip_36 = x<br/>        <br/>    # Layer 37 =&gt; 40<br/>    x = _conv_block(x, [{'filter': 512, 'kernel': 3, 'stride': 2, 'bnorm': True, 'leaky': True, 'layer_idx': 37},<br/>                        {'filter': 256, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 38},<br/>                        {'filter': 512, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 39}])</span><span id="1b9c" class="lx ly it lt b gy md ma l mb mc"># Layer 41 =&gt; 61<br/>    for i in range(7):<br/>        x = _conv_block(x, [{'filter': 256, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 41+i*3},<br/>                            {'filter': 512, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 42+i*3}])<br/>        <br/>    skip_61 = x<br/>        <br/>    # Layer 62 =&gt; 65<br/>    x = _conv_block(x, [{'filter': 1024, 'kernel': 3, 'stride': 2, 'bnorm': True, 'leaky': True, 'layer_idx': 62},<br/>                        {'filter':  512, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 63},<br/>                        {'filter': 1024, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 64}])</span><span id="fdf0" class="lx ly it lt b gy md ma l mb mc"># Layer 66 =&gt; 74<br/>    for i in range(3):<br/>        x = _conv_block(x, [{'filter':  512, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 66+i*3},<br/>                            {'filter': 1024, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 67+i*3}])<br/>        <br/>    # Layer 75 =&gt; 79<br/>    x = _conv_block(x, [{'filter':  512, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 75},<br/>                        {'filter': 1024, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 76},<br/>                        {'filter':  512, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 77},<br/>                        {'filter': 1024, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 78},<br/>                        {'filter':  512, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 79}], skip=False)</span><span id="168a" class="lx ly it lt b gy md ma l mb mc"># Layer 80 =&gt; 82<br/>    yolo_82 = _conv_block(x, [{'filter': 1024, 'kernel': 3, 'stride': 1, 'bnorm': True,  'leaky': True,  'layer_idx': 80},<br/>                              {'filter':  255, 'kernel': 1, 'stride': 1, 'bnorm': False, 'leaky': False, 'layer_idx': 81}], skip=False)</span><span id="bcd4" class="lx ly it lt b gy md ma l mb mc"># Layer 83 =&gt; 86<br/>    x = _conv_block(x, [{'filter': 256, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 84}], skip=False)<br/>    x = UpSampling2D(2)(x)<br/>    x = concatenate([x, skip_61])</span><span id="1719" class="lx ly it lt b gy md ma l mb mc"># Layer 87 =&gt; 91<br/>    x = _conv_block(x, [{'filter': 256, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 87},<br/>                        {'filter': 512, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 88},<br/>                        {'filter': 256, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 89},<br/>                        {'filter': 512, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 90},<br/>                        {'filter': 256, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 91}], skip=False)</span><span id="3d71" class="lx ly it lt b gy md ma l mb mc"># Layer 92 =&gt; 94<br/>    yolo_94 = _conv_block(x, [{'filter': 512, 'kernel': 3, 'stride': 1, 'bnorm': True,  'leaky': True,  'layer_idx': 92},<br/>                              {'filter': 255, 'kernel': 1, 'stride': 1, 'bnorm': False, 'leaky': False, 'layer_idx': 93}], skip=False)</span><span id="0a98" class="lx ly it lt b gy md ma l mb mc"># Layer 95 =&gt; 98<br/>    x = _conv_block(x, [{'filter': 128, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True,   'layer_idx': 96}], skip=False)<br/>    x = UpSampling2D(2)(x)<br/>    x = concatenate([x, skip_36])</span><span id="cae5" class="lx ly it lt b gy md ma l mb mc"># Layer 99 =&gt; 106<br/>    yolo_106 = _conv_block(x, [{'filter': 128, 'kernel': 1, 'stride': 1, 'bnorm': True,  'leaky': True,  'layer_idx': 99},<br/>                               {'filter': 256, 'kernel': 3, 'stride': 1, 'bnorm': True,  'leaky': True,  'layer_idx': 100},<br/>                               {'filter': 128, 'kernel': 1, 'stride': 1, 'bnorm': True,  'leaky': True,  'layer_idx': 101},<br/>                               {'filter': 256, 'kernel': 3, 'stride': 1, 'bnorm': True,  'leaky': True,  'layer_idx': 102},<br/>                               {'filter': 128, 'kernel': 1, 'stride': 1, 'bnorm': True,  'leaky': True,  'layer_idx': 103},<br/>                               {'filter': 256, 'kernel': 3, 'stride': 1, 'bnorm': True,  'leaky': True,  'layer_idx': 104},<br/>                               {'filter': 255, 'kernel': 1, 'stride': 1, 'bnorm': False, 'leaky': False, 'layer_idx': 105}], skip=False)</span><span id="ce06" class="lx ly it lt b gy md ma l mb mc">model = Model(input_image, [yolo_82, yolo_94, yolo_106])    <br/>    return model</span></pre><p id="468c" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu">步骤 4:我们现在创建 yolo 模型并加载预训练的权重</strong></p><pre class="kr ks kt ku gt ls lt lu lv aw lw bi"><span id="440c" class="lx ly it lt b gy lz ma l mb mc"><strong class="lt iu"># create the yolo v3</strong><br/>yolov3 = make_yolov3_model()</span><span id="c15d" class="lx ly it lt b gy md ma l mb mc"><strong class="lt iu"># load the weights trained on COCO into the model</strong></span><span id="eb39" class="lx ly it lt b gy md ma l mb mc">weight_reader = WeightReader(‘yolov3.weights’)<br/>weight_reader.load_weights(yolov3)</span></pre><p id="3b86" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu">第五步:设置变量。</strong></p><p id="593a" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">Yolov3 的输入图像大小是 416 x 416，我们使用 net_h 和 net_w 来设置。</p><p id="1118" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">对象阈值设定为 0.5，非最大抑制阈值设定为 0.45</p><p id="9e20" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">我们设置锚框，然后为上下文中的公共对象(COCO)模型定义 80 个标签以进行预测</p><pre class="kr ks kt ku gt ls lt lu lv aw lw bi"><span id="bc39" class="lx ly it lt b gy lz ma l mb mc"><strong class="lt iu">net_h, net_w = 416, 416</strong></span><span id="e029" class="lx ly it lt b gy md ma l mb mc"><strong class="lt iu">obj_thresh, nms_thresh = 0.5, 0.45</strong></span><span id="76a4" class="lx ly it lt b gy md ma l mb mc"><strong class="lt iu">anchors</strong> = [[116,90, 156,198, 373,326], [30,61, 62,45, 59,119], [10,13, 16,30, 33,23]]</span><span id="e9d3" class="lx ly it lt b gy md ma l mb mc"><strong class="lt iu">labels</strong> = [“person”, “bicycle”, “car”, “motorbike”, “aeroplane”, “bus”, “train”, “truck”, “boat”, “traffic light”, “fire hydrant”, “stop sign”, “parking meter”, “bench”, “bird”, “cat”, “dog”, “horse”, “sheep”, “cow”, “elephant”, “bear”, “zebra”, “giraffe”, \<br/> “backpack”, “umbrella”, “handbag”, “tie”, “suitcase”, “frisbee”, “skis”, “snowboard”, “sports ball”, “kite”, “baseball bat”, “baseball glove”, “skateboard”, “surfboard”, “tennis racket”, “bottle”, “wine glass”, “cup”, “fork”, “knife”, “spoon”, “bowl”, “banana”, “apple”, “sandwich”, “orange”, “broccoli”, “carrot”, “hot dog”, “pizza”, “donut”, “cake”, “chair”, “sofa”, “pottedplant”, “bed”, “diningtable”, “toilet”, “tvmonitor”, “laptop”, “mouse”, \<br/> “remote”, “keyboard”, “cell phone”, “microwave”, “oven”, “toaster”, “sink”, “refrigerator”, “book”, “clock”, “vase”, “scissors”, “teddy bear”, “hair drier”, “toothbrush”]</span></pre><p id="e690" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu">第六步:将图像加载到右边 416 x 416 的输入形状</strong></p><pre class="kr ks kt ku gt ls lt lu lv aw lw bi"><span id="8397" class="lx ly it lt b gy lz ma l mb mc">from numpy import expand_dims</span><span id="1181" class="lx ly it lt b gy md ma l mb mc">def <strong class="lt iu">load_image_pixels(filename, shape)</strong>:<br/> # load the image to get its shape<br/> image = load_img(filename)<br/> width, height = image.size<br/> <br/># load the image with the required size<br/> image = load_img(filename, target_size=shape)</span><span id="378d" class="lx ly it lt b gy md ma l mb mc"> # convert to numpy array<br/> image = img_to_array(image)<br/> <br/># scale pixel values to [0, 1]<br/> image = image.astype(‘float32’)<br/> image /= 255.0<br/> <br/># add a dimension so that we have one sample<br/> image = expand_dims(image, 0)<br/> <strong class="lt iu">return image, width, height</strong></span></pre><p id="4e78" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">步骤 7:为边界框创建一个类。</p><p id="a388" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">BoundBox 在输入图像形状和类别概率的上下文中定义每个边界框的角。</p><pre class="kr ks kt ku gt ls lt lu lv aw lw bi"><span id="f3e2" class="lx ly it lt b gy lz ma l mb mc"><strong class="lt iu">class BoundBox:</strong><br/><strong class="lt iu"> def __init__</strong>(self, xmin, ymin, xmax, ymax, objness = None, classes = None):<br/> self.xmin = xmin<br/> self.ymin = ymin<br/> self.xmax = xmax<br/> self.ymax = ymax<br/> <br/> self.objness = objness<br/> self.classes = classes</span><span id="ad4d" class="lx ly it lt b gy md ma l mb mc">self.label = -1<br/> self.score = -1</span><span id="cb97" class="lx ly it lt b gy md ma l mb mc"><strong class="lt iu">def get_label(self)</strong>:<br/> if self.label == -1:<br/> self.label = np.argmax(self.classes)<br/> <br/> return self.label<br/> <br/> <strong class="lt iu">def get_score(self)</strong>:<br/> if self.score == -1:<br/> self.score = self.classes[self.get_label()]<br/> <br/> return self.score</span></pre><p id="b7b3" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu">步骤 8:为</strong>定义函数</p><ul class=""><li id="30c6" class="me mf it js b jt ju jx jy kb mg kf mh kj mi kn mj mk ml mm bi translated">间隔重叠-检查两个间隔是否重叠。当一个间隔在另一个间隔开始之前结束时，两个间隔不重叠。</li><li id="1359" class="me mf it js b jt mn jx mo kb mp kf mq kj mr kn mj mk ml mm bi translated">两个盒子的并集交集(IoU)</li><li id="a90f" class="me mf it js b jt mn jx mo kb mp kf mq kj mr kn mj mk ml mm bi translated">非最大抑制，将包含对象的框以及非最大阈值作为参数</li><li id="7413" class="me mf it js b jt mn jx mo kb mp kf mq kj mr kn mj mk ml mm bi translated">Sigmoid 函数</li></ul><pre class="kr ks kt ku gt ls lt lu lv aw lw bi"><span id="ad03" class="lx ly it lt b gy lz ma l mb mc"><strong class="lt iu">def _sigmoid(x)</strong>:<br/> return 1. / (1. + np.exp(-x))</span><span id="52e5" class="lx ly it lt b gy md ma l mb mc"><strong class="lt iu">def _interval_overlap(interval_a, interval_b</strong>):<br/> x1, x2 = interval_a<br/> x3, x4 = interval_b</span><span id="074f" class="lx ly it lt b gy md ma l mb mc">if x3 &lt; x1:<br/> if x4 &lt; x1:<br/> return 0<br/> else:<br/> return min(x2,x4) — x1<br/> else:<br/> if x2 &lt; x3:<br/> return 0<br/> else:<br/> return min(x2,x4) — x3<br/> <br/><strong class="lt iu">def bbox_iou(box1, box2</strong>):<br/> intersect_w = _interval_overlap([box1.xmin, box1.xmax], [box2.xmin, box2.xmax])<br/> intersect_h = _interval_overlap([box1.ymin, box1.ymax], [box2.ymin, box2.ymax])<br/> <br/> intersect = intersect_w * intersect_h</span><span id="a942" class="lx ly it lt b gy md ma l mb mc">w1, h1 = box1.xmax-box1.xmin, box1.ymax-box1.ymin<br/> w2, h2 = box2.xmax-box2.xmin, box2.ymax-box2.ymin<br/> <br/> union = w1*h1 + w2*h2 — intersect<br/> <br/> return float(intersect) / union</span><span id="a8a3" class="lx ly it lt b gy md ma l mb mc"><strong class="lt iu">def do_nms(boxes, nms_thresh)</strong>:<br/> if len(boxes) &gt; 0:<br/> nb_class = len(boxes[0].classes)<br/> else:<br/> return<br/> <br/> for c in range(nb_class):<br/> sorted_indices = np.argsort([-box.classes[c] for box in boxes])</span><span id="8990" class="lx ly it lt b gy md ma l mb mc">for i in range(len(sorted_indices)):<br/> index_i = sorted_indices[i]</span><span id="f52c" class="lx ly it lt b gy md ma l mb mc">if boxes[index_i].classes[c] == 0: continue</span><span id="0243" class="lx ly it lt b gy md ma l mb mc">for j in range(i+1, len(sorted_indices)):<br/> index_j = sorted_indices[j]</span><span id="60b6" class="lx ly it lt b gy md ma l mb mc">if bbox_iou(boxes[index_i], boxes[index_j]) &gt;= nms_thresh:<br/> boxes[index_j].classes[c] = 0</span></pre><p id="6a10" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu">第九步:解码网络的输出。</strong></p><p id="0d21" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">我们将遍历 NumPy 数组中的每一个，一次一个，并基于对象阈值解码候选边界框和类预测。</p><p id="0945" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">前 4 个元素将是边界框的坐标，第 5 个元素将是对象分数，后跟类别概率</p><pre class="kr ks kt ku gt ls lt lu lv aw lw bi"><span id="f67a" class="lx ly it lt b gy lz ma l mb mc"><strong class="lt iu">def decode_netout(netout, anchors, obj_thresh, net_h, net_w):</strong><br/> grid_h, grid_w = netout.shape[:2]<br/> nb_box = 3<br/> netout = netout.reshape((grid_h, grid_w, nb_box, -1))<br/> nb_class = netout.shape[-1] — 5</span><span id="8724" class="lx ly it lt b gy md ma l mb mc">boxes = []</span><span id="d7d6" class="lx ly it lt b gy md ma l mb mc"> netout[…, :2] = _sigmoid(netout[…, :2])<br/> netout[…, 4:] = _sigmoid(netout[…, 4:])<br/> netout[…, 5:] = netout[…, 4][…, np.newaxis] * netout[…, 5:]<br/> netout[…, 5:] *= netout[…, 5:] &gt; obj_thresh</span><span id="422a" class="lx ly it lt b gy md ma l mb mc">for i in range(grid_h*grid_w):<br/> row = i / grid_w<br/> col = i % grid_w<br/> <br/> for b in range(nb_box):<br/> # 4th element is objectness score<br/> objectness = netout[int(row)][int(col)][b][4]<br/> #objectness = netout[…, :4]<br/> <br/> if(objectness.all() &lt;= obj_thresh): continue<br/> <br/> # first 4 elements are x, y, w, and h<br/> x, y, w, h = netout[int(row)][int(col)][b][:4]</span><span id="c57f" class="lx ly it lt b gy md ma l mb mc">x = (col + x) / grid_w # center position, unit: image width<br/> y = (row + y) / grid_h # center position, unit: image height<br/> w = anchors[2 * b + 0] * np.exp(w) / net_w # unit: image width<br/> h = anchors[2 * b + 1] * np.exp(h) / net_h # unit: image height <br/> <br/> # last elements are class probabilities<br/> classes = netout[int(row)][col][b][5:]<br/> <br/> <strong class="lt iu">box = BoundBox(x-w/2, y-h/2, x+w/2, y+h/2, objectness, classes)</strong><br/> </span><span id="b1e8" class="lx ly it lt b gy md ma l mb mc">boxes.append(box)</span><span id="131d" class="lx ly it lt b gy md ma l mb mc"><strong class="lt iu">return boxes</strong></span></pre><p id="3c4e" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu">步骤 10:纠正 Yolo 框。</strong></p><p id="c9f0" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">我们有边界框，但它们需要被拉伸回原始图像的形状。这将允许绘制原始图像和边界框，检测真实对象。</p><pre class="kr ks kt ku gt ls lt lu lv aw lw bi"><span id="ca58" class="lx ly it lt b gy lz ma l mb mc"><br/><strong class="lt iu">def correct_yolo_boxes(boxes, image_h, image_w, net_h, net_w):</strong><br/> if (float(net_w)/image_w) &lt; (float(net_h)/image_h):<br/> new_w = net_w<br/> new_h = (image_h*net_w)/image_w<br/> else:<br/> new_h = net_w<br/> new_w = (image_w*net_h)/image_h<br/> <br/> for i in range(len(boxes)):<br/> x_offset, x_scale = (net_w — new_w)/2./net_w, float(new_w)/net_w<br/> y_offset, y_scale = (net_h — new_h)/2./net_h, float(new_h)/net_h<br/> <br/> boxes[i].xmin = int((boxes[i].xmin — x_offset) / x_scale * image_w)<br/> boxes[i].xmax = int((boxes[i].xmax — x_offset) / x_scale * image_w)<br/> boxes[i].ymin = int((boxes[i].ymin — y_offset) / y_scale * image_h)<br/> boxes[i].ymax = int((boxes[i].ymax — y_offset) / y_scale * image_h)</span></pre><p id="b75e" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">步骤 11:获取所有高于指定阈值的盒子。</p><p id="a23c" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu"> <em class="kp"> get_boxes </em> </strong>函数将盒子、标签和阈值的列表作为参数，并返回盒子、标签和分数的并行列表。</p><pre class="kr ks kt ku gt ls lt lu lv aw lw bi"><span id="cb10" class="lx ly it lt b gy lz ma l mb mc"><br/><strong class="lt iu">def get_boxes(boxes, labels, thresh):</strong><br/>    v_boxes, v_labels, v_scores = list(), list(), list()<br/>    # enumerate all boxes<br/>    for box in boxes:<br/>        # enumerate all possible labels<br/>        for i in range(len(labels)):<br/>            # check if the threshold for this label is high enough<br/>            if box.classes[i] &gt; thresh:<br/>                v_boxes.append(box)<br/>                v_labels.append(labels[i])<br/>                v_scores.append(box.classes[i]*100)<br/>                # don't break, many labels may trigger for one box<br/>    return v_boxes, v_labels, v_scores</span></pre><p id="13a7" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">步骤 12:在图像中的物体周围画一个白框。</p><pre class="kr ks kt ku gt ls lt lu lv aw lw bi"><span id="6d99" class="lx ly it lt b gy lz ma l mb mc">from matplotlib.patches import Rectangle</span><span id="f6f9" class="lx ly it lt b gy md ma l mb mc"><strong class="lt iu">def draw_boxes(filename, v_boxes, v_labels, v_scores):</strong><br/> <br/># load the image<br/> data = plt.imread(filename)<br/> <br/># plot the image<br/> plt.imshow(data)<br/> <br/># get the context for drawing boxes<br/> ax = plt.gca()<br/> <br/># plot each box<br/> for i in range(len(v_boxes)):</span><span id="449d" class="lx ly it lt b gy md ma l mb mc">box = v_boxes[i]<br/>        # get coordinates<br/>        y1, x1, y2, x2 = box.ymin, box.xmin, box.ymax, box.xmax<br/>        # calculate width and height of the box<br/>        width, height = x2 - x1, y2 - y1<br/>        # create the shape<br/>        rect = Rectangle((x1, y1), width, height, fill=False, color='red')<br/>        # draw the box<br/>        ax.add_patch(rect)<br/>        # draw text and score in top left corner<br/>        label = "%s (%.3f)" % (v_labels[i], v_scores[i])<br/>        plt.text(x1, y1, label, color='red')<br/>    # show the plot<br/>plt.show()</span></pre><p id="c046" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">最后，我们结合代码对新图像进行预测。</p><p id="4857" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">首先我们使用<strong class="js iu"><em class="kp">load _ image _ pixels()</em></strong>函数将图像加载到 416 x 416 的输入形状中。</p><p id="78ee" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">预测盒子起诉 yolov 3<strong class="js iu">T23 预测()</strong>方法</p><p id="39ea" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">Yolov3 模型将预测同一对象的多个框。</p><p id="af28" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">然后，我们使用<strong class="js iu"><em class="kp">decode _ netout()</em></strong>函数基于对象阈值对候选包围盒和类别预测进行解码</p><p id="ee06" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">我们通过使用<strong class="js iu"><em class="kp">correct _ yolo _ boxes()</em></strong>函数来校正边界框，以将其拉伸回原始图像的形状</p><p id="23a1" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">边界框将根据 IoU 定义的重叠进行过滤，然后使用<strong class="js iu"> <em class="kp"> do_nms() </em> </strong>函数应用非最大值抑制。</p><p id="9852" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">我们使用<strong class="js iu"> <em class="kp"> get_boxes() </em> </strong>得到高于指定类阈值 0.6 的盒子，然后使用<strong class="js iu"> <em class="kp"> draw_boxes() </em> </strong>函数在图像上绘制这些盒子。</p><pre class="kr ks kt ku gt ls lt lu lv aw lw bi"><span id="e874" class="lx ly it lt b gy lz ma l mb mc"># define our new image<br/>photo_filename = 'eagle.png'</span><span id="9eda" class="lx ly it lt b gy md ma l mb mc"># load and prepare image<br/>image, image_w, image_h = <strong class="lt iu">load_image_pixels</strong>(photo_filename, (net_w, net_w))</span><span id="c43d" class="lx ly it lt b gy md ma l mb mc"># make prediction<br/><strong class="lt iu">yolos = yolov3.predict(image)</strong></span><span id="c413" class="lx ly it lt b gy md ma l mb mc"># summarize the shape of the list of arrays<br/>print([a.shape for a in yolos])</span><span id="248d" class="lx ly it lt b gy md ma l mb mc"># define the anchors<br/>anchors = [[116,90, 156,198, 373,326], [30,61, 62,45, 59,119], [10,13, 16,30, 33,23]]</span><span id="dad7" class="lx ly it lt b gy md ma l mb mc"># define the probability threshold for detected objects<br/>class_threshold = 0.6</span><span id="ac5b" class="lx ly it lt b gy md ma l mb mc">boxes = list()</span><span id="7dbb" class="lx ly it lt b gy md ma l mb mc">for i in range(len(yolos)):<br/>        # decode the output of the network<br/>    boxes += <strong class="lt iu"><em class="kp">decode_netout</em></strong>(yolos[i][0], anchors[i], obj_thresh, nms_thresh, net_h, net_w)</span><span id="6ad3" class="lx ly it lt b gy md ma l mb mc"># correct the sizes of the bounding boxes<br/><strong class="lt iu">correct_yolo_boxes(boxes, image_h, image_w, net_h, net_w)</strong></span><span id="10b7" class="lx ly it lt b gy md ma l mb mc"># suppress non-maximal boxes<br/><strong class="lt iu">do_nms</strong>(boxes, nms_thresh)</span><span id="baa3" class="lx ly it lt b gy md ma l mb mc"># get the details of the detected objects<br/>v_boxes, v_labels, v_scores = <strong class="lt iu">get_boxes</strong>(boxes, labels, class_threshold)<br/># summarize what we found<br/>for i in range(len(v_boxes)):<br/>    print(v_labels[i], v_scores[i])<br/># draw what we found<br/><strong class="lt iu">draw_boxes</strong>(photo_filename, v_boxes, v_labels, v_scores)</span></pre><p id="4567" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">原象</p><figure class="kr ks kt ku gt kv gh gi paragraph-image"><div class="gh gi ms"><img src="../Images/fa44e7018ad52f80b809e4e71422f61f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1054/format:webp/1*Jo7HAV6Fh8IAN6_pob9Mwg.png"/></div></figure><p id="5563" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">绘制边界框和类后的图像</p><figure class="kr ks kt ku gt kv gh gi paragraph-image"><div class="gh gi ms"><img src="../Images/f69fe6b12ce6ba1763448ac1316baf3b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1054/format:webp/1*rGNUrlbnRKPadwf8n9eOzw.png"/></div></figure><p id="d1c5" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">代码可从<a class="ae ko" href="https://github.com/arshren/YOLOV3/blob/master/YOLO%20Step%20by%20Step.ipynb" rel="noopener ugc nofollow" target="_blank"> Github </a>获得</p><h2 id="41e5" class="lx ly it bd mt mu mv dn mw mx my dp mz kb na nb nc kf nd ne nf kj ng nh ni nj bi translated">参考资料:</h2><p id="bc16" class="pw-post-body-paragraph jq jr it js b jt nk jv jw jx nl jz ka kb nm kd ke kf nn kh ki kj no kl km kn im bi translated"><a class="ae ko" href="https://pjreddie.com/media/files/papers/YOLOv3.pdf" rel="noopener ugc nofollow" target="_blank"> YOLO V3 论文</a>作者约瑟夫·雷德蒙、阿里·法尔哈迪</p><p id="dd6f" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><a class="ae ko" href="https://pjreddie.com/darknet/yolo/" rel="noopener ugc nofollow" target="_blank">https://pjreddie.com/darknet/yolo/</a></p><div class="np nq gp gr nr ns"><a href="https://github.com/experiencor/keras-yolo3" rel="noopener  ugc nofollow" target="_blank"><div class="nt ab fo"><div class="nu ab nv cl cj nw"><h2 class="bd iu gy z fp nx fr fs ny fu fw is bi translated">experiencor/keras-yolo3</h2><div class="nz l"><h3 class="bd b gy z fp nx fr fs ny fu fw dk translated">从 https://pjreddie.com/media/files/yolov3.weights. python 中抓取 yolo3 的预训练重量…</h3></div><div class="oa l"><p class="bd b dl z fp nx fr fs ny fu fw dk translated">github.com</p></div></div><div class="ob l"><div class="oc l od oe of ob og kw ns"/></div></div></a></div><div class="np nq gp gr nr ns"><a href="https://machinelearningmastery.com/how-to-perform-object-detection-with-yolov3-in-keras/" rel="noopener  ugc nofollow" target="_blank"><div class="nt ab fo"><div class="nu ab nv cl cj nw"><h2 class="bd iu gy z fp nx fr fs ny fu fw is bi translated">如何在 Keras 中使用 YOLOv3 执行对象检测</h2><div class="nz l"><h3 class="bd b gy z fp nx fr fs ny fu fw dk translated">目标检测是计算机视觉中的一项任务，涉及识别一个或多个目标的存在、位置和类型</h3></div><div class="oa l"><p class="bd b dl z fp nx fr fs ny fu fw dk translated">machinelearningmastery.com</p></div></div><div class="ob l"><div class="oh l od oe of ob og kw ns"/></div></div></a></div></div></div>    
</body>
</html>