# 普学习

> 原文：<https://towardsdatascience.com/pu-learning-e2059f4f9b52?source=collection_archive---------15----------------------->

## 处理隐藏在未标记数据中的负类

![](img/62fe93a6892dabb6ef0b0e3954f9d323.png)

PU Learning — finding a needle in a haystack

在工作中不断出现的一个挑战是，在需要训练二进制分类器的情况下，没有标记的负类。通常，这个问题伴随着严重不平衡的数据集，在时间紧迫的情况下，我经常采取简单的方法，对未知数据集进行子采样，并将其视为未知。显然，这并不理想，因为未知集合被污染了，因此分类器不能很好地训练。然而，在野外，在现实生活的最后期限内，这种方法是省时的，而且结果常常出人意料地有用。

最近，我很幸运有几天时间稍微围绕这个话题阅读。我发现了一些有趣的方法，并认为值得做一些笔记，它们变成了这个帖子。

有几种不同的 PU 方法。所有的方法都包括从未知数据集中分离出一组所谓的可靠否定(RNs)。据我所知，最广泛引用的初始方法是刘等人在 2002 年和 2003 年提出的，其中一组 RNs 是从未知类中迭代生长出来的。

Fusilier 等人在 2015 年描述了另一种吸引我的方法。在他们的论文中，作者描述了一种方法，该方法迭代地从未知类中减少 rn 的集合，有效地收紧围绕那些与正类最不相似的情况的网。这种方法吸引了我，因为它含蓄地处理了阶级不平衡。

我遇到的第三种方法(Mordelet & Vert 2013)也隐含地说明了类别不平衡，它涉及装袋，或从未知类别中随机抽样，并将样本视为阴性。这与我上面提到的天真方法的不同之处在于，该过程被重复多次，并且训练了一系列模型。该模型针对具有不同污染程度的未知数据集来表征正类。得到的模型分数被集合，并且结果应该更好地将可靠的否定从未知类别中分离出来。

下面，我将详细介绍这三种方法。

# 方法

# “原创”方法(刘等，2002 和 2003)

给定一个只包含阳性(P)和未知(U)类的训练集，遵循以下步骤:

1.  将所有 U 视为否定(N)训练分类器 P 对 U
2.  使用分类器，对未知类别进行评分，并分离出“可靠的”否定集合(RN)。
3.  在 P 对 RN 上训练一个新的分类器，用它对剩余的 U 进行评分，分离出额外的 RN，放大 RN。
4.  重复步骤 3，迭代地扩大 RN 的集合，直到满足停止条件。

当没有新的阴性病例被分类时，满足停止条件。

其中`Q`被定义为分类为负数的未知集合，而`i`是迭代器，停止条件被定义为:

> `|Qi| > 0`

# 改良方法(Fusilier 等人，2014 年)

给定一个只包含阳性(P)和未知(U)类的训练集，遵循以下步骤:

1.  将所有 U 视为否定(N)训练分类器 P 对 U
2.  使用分类器，对未知类别进行评分，并分离出“可靠的”否定集合(RN)。
3.  在 P 对 RN 上训练新的分类器。对 RN 评分并从 RN 中排除预测阳性
4.  重复步骤 3，迭代地改进 RN 集合，直到满足停止条件。

其中`Q`被定义为被归类为否定的未知集合，`i`是迭代器，停止条件被定义为:

> `|Qi| <= |Q(i-1)| & |P| < |Qi|`

停止条件确保 Q 的大小减小(避免 RN 大小突然大幅度减小),同时 RN 集永远不会变得小于 P 集。更明确地说:

> 虽然在这次迭代中被分类为否定的未知集合的大小小于或等于在先前迭代中被分类为否定的未知集合的大小，并且肯定类别集合的大小小于从这次迭代得到的精炼 rn 集合

# 装袋方法(归纳)(Mordelet & Vert，2013 年)

给定仅包含阳性(P)和未知(U)的训练集，其中 K =引导样本的大小，T =样本的数量，遵循以下步骤:1 .从 U ^ 2 中抽取大小为 K 的 bootstrap 样本 Ut。训练一个分类器 P 对 Ut 3。重复步骤 1 和 2，共 4 次。使用袋装模型通过集成方法对测试数据进行评分。

这里的停止标准是由 T 的值决定的，作者认为将 T 设置为> 100 通常不会获得太多的附加值。然而，从它们的曲线图来看，在`|P|`和`K`都很大的地方，T = 5 以上几乎没有变化。我怀疑，如果可能的话，在训练期间尝试跟踪这一点是值得的，或者在您的函数中设置早期停止类型标准，因为根据您的时间限制，训练 100 个模型可能是不可行的。

> 需要跟进的事项:
> 
> -大部分文章使用 SVM，但也往往是 NLP 问题。分类器家族很重要吗？
> 
> -原始文件如何确定确定“可靠性”的截止点
> 
> -改进的方法:WRT 停止准则，为什么 Q 会随着迭代而变大？
> 
> -打包方法:考虑如何最好地惩罚假阴性。
> 
> -截止选择？

# 结论

这三种方法为 PU 学习问题提供了合理的方法，但是只有改进的和 bagging 方法提供了处理不平衡数据的固有方法。我的计划是尝试并实现这两种方法，并比较它们的结果。虽然我不能公开分享数据，但我会试着在博客和 GitHub 上分享代码和一般结果。我们主要在 Python/PySpark 或 Scala/Spark 中工作。一些不错的链接:

*   [https://github.com/ispras/pu4spark](https://github.com/ispras/pu4spark)用 Scala/Spark 编写的 PU 学习库
*   https://astrakhantsev.com/pu-learning/[pu4s park 的作者写了一篇不错的帖子](https://astrakhantsev.com/pu-learning/)
*   [https://Roy Wright . me/2017/11/16/positive-unlabeled-learning/](https://roywright.me/2017/11/16/positive-unlabeled-learning/)PU 学习方法的精彩概述

# 参考

Fusilier DH，Montes-y-Gómez M，Rosso P，Guzmán Cabrera R (2015)使用 PU-learning 检测正面和负面欺骗性观点。Inf 流程管理 51:433–443。doi:10.1016/j . IPM 2014 . 11 . 001

刘波，戴 Y，李 X，等(2003)利用正例和未标记样本构造文本分类器。第三届 IEEE 数据挖掘国际会议。第 179-186 页

刘 B，李伟生，俞平山，李 X (2002)文本文档的部分监督分类。在:过程中。第 19 国际机场。糖膏剂关于机器学习。第 387 至 394 页

Mordelet F，Vert J-P (2014) A bagging SVM 从正面和无标签的例子中学习。模式识别列特 37:201–209。2013 年 6 月 10 日

*原载于*[*philmassie . github . io*](https://philmassie.github.io/post/20190111/pu_learning/)*。*