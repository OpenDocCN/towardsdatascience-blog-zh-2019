<html>
<head>
<title>Strategies for Global Optimization</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">全局优化策略</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/strategies-for-global-optimization-79fca001c8bb?source=collection_archive---------6-----------------------#2019-06-08">https://towardsdatascience.com/strategies-for-global-optimization-79fca001c8bb?source=collection_archive---------6-----------------------#2019-06-08</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><figure class="gl gn jo jp jq jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi jn"><img src="../Images/db9c46655c98bcc28ea59e01995cc698.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*hCC93XGDW67QjSsyZS1U6g.png"/></div></div></figure><p id="3335" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">一旦我们离开高中微积分，局部和全局优化通常是已知的，但有些被忽略了。快速回顾一下，看看这篇博客的封面图片。对于一个给定的函数，在空间上有多个点有倾角。每次下降都是最小的。但是，你可以看到只有一个点是最深的，称为全局最小值。所有其他点都是局部最小值。第一部分，我将回顾计算一个已知函数的全局值。然而，一旦我们离开高中数学的这个已知函数的领域，大多数优化问题只处理局部优化。即使这样，我也要说明原因。快速注意，还有很多其他的策略我没有在这篇博客中提到。然而，我希望它能让你有足够的兴趣去探索更多的选择。</p><h1 id="05a9" class="kw kx iq bd ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt bi translated">已知函数</h1><p id="5118" class="pw-post-body-paragraph jy jz iq ka b kb lu kd ke kf lv kh ki kj lw kl km kn lx kp kq kr ly kt ku kv ij bi translated">我们来复习一些基础的高中微积分。首先，看一下这个简单的一元函数:</p><figure class="ma mb mc md gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi lz"><img src="../Images/52317b9a6c72794bdefc2deb431560f4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*0wB2qgravu6XfKdZoD0tnw.png"/></div></div><figcaption class="me mf gj gh gi mg mh bd b be z dk">f(x) = 1/4x⁴ + 1/3x³ — 3x² — 7</figcaption></figure><p id="412f" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">从图表中，我们可以看到全球最小值在-3 左右。然而，让我们尝试使用微积分，因为我们知道这个情节的功能。</p><figure class="ma mb mc md gt jr gh gi paragraph-image"><div class="gh gi mi"><img src="../Images/f2f25ebce18899cdc4c079f4aa602cad.png" data-original-src="https://miro.medium.com/v2/resize:fit:1358/format:webp/1*2i1_Mxia82Mm2SqR0W9FQg.png"/></div></figure><p id="7b87" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">我们看到<strong class="ka ir"> f(-3)=-22.75 </strong>，f(x)的最小可能值。我们甚至可以超越 2D，进入多元微积分领域来解决这个问题。</p><h1 id="4fe1" class="kw kx iq bd ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt bi translated">未知函数</h1><p id="1260" class="pw-post-body-paragraph jy jz iq ka b kb lu kd ke kf lv kh ki kj lw kl km kn lx kp kq kr ly kt ku kv ij bi translated">在处理数据科学的大部分时间里，我们无法访问函数来执行任何演算。通常，f(x)是一个系统，我们可以输入变量 x，并获得一些输出 y。一个可能的解决方案是执行随机梯度下降，我们迭代地沿着斜坡下降，直到我们达到最小值。</p><figure class="ma mb mc md gt jr gh gi paragraph-image"><div class="gh gi mj"><img src="../Images/8f29383742c07300ec6a3b854cde8290.png" data-original-src="https://miro.medium.com/v2/resize:fit:852/format:webp/1*PpF4YthtCgMyi9Pg-mmPBw.png"/></div><figcaption class="me mf gj gh gi mg mh bd b be z dk">Stochastic Gradient Descent</figcaption></figure><p id="c58e" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">现在让我们用 python 来实现这个问题，假设 f 是一个黑盒函数。</p><pre class="ma mb mc md gt mk ml mm mn aw mo bi"><span id="4666" class="mp kx iq ml b gy mq mr l ms mt">#Unknown Function<br/>f = lambda x:(1/4*x**4)+(1/3*x**3)-(3*x**2)-7</span><span id="1ed7" class="mp kx iq ml b gy mu mr l ms mt">def next_step(x,f,step_size):<br/>  y=f(x)<br/>  #Left Point<br/>  x_left=x-step_size<br/>  y_left=f(x_left)<br/>  diff_left=y_left-y<br/>  #Right Point<br/>  x_right=x+step_size<br/>  y_right=f(x_right)<br/>  diff_right=y_right-y<br/>  #Comparison<br/>  if diff_right&lt;diff_left:<br/>    return x_right, y_right, diff_right<br/>  else:<br/>    return x_left, y_left, diff_left</span><span id="4484" class="mp kx iq ml b gy mu mr l ms mt">def gradient_descent(f,start,step_size=0.01,tol=0.1, debug=False):<br/>  x=start<br/>  diff=9999999<br/>  while abs(diff)&gt;tol:<br/>    x, y, diff=next_step(x,f,step_size)<br/>    if debug:<br/>      print("Current Point: (%.2f,%.2f), Change: %.2f"%(x,y,diff))<br/>  print("Minimum Point: (%.2f,%.2f)"%(x,y))</span></pre><p id="f11f" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">现在我们有了函数，让我们试着从 x=4 开始搜索。</p><pre class="ma mb mc md gt mk ml mm mn aw mo bi"><span id="268b" class="mp kx iq ml b gy mq mr l ms mt">gradient_descent(f, start=4)</span><span id="24b6" class="mp kx iq ml b gy mu mr l ms mt">#Minimum Point: (2.65,-9.54)</span></pre><p id="6efc" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">这给了我们 2.65 的最低分。现在，让我们对另一个起点 x=-4 做同样的尝试。</p><pre class="ma mb mc md gt mk ml mm mn aw mo bi"><span id="66e7" class="mp kx iq ml b gy mq mr l ms mt">gradient_descent(f, start=-4)</span><span id="0c4b" class="mp kx iq ml b gy mu mr l ms mt">#Minimum Point: (-3.51,-20.43)</span></pre><p id="0c22" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">使用 x=-5，我们得到全局最小值-3.51。这是寻找全局和局部最小值变得棘手的时候。我们的最终结果取决于起点。</p><figure class="ma mb mc md gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi mv"><img src="../Images/171d0a37af4ed5c3461e99f5e4335609.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*LRepH5MpUHb1C72oaqPwVQ.png"/></div></div><figcaption class="me mf gj gh gi mg mh bd b be z dk">Stochastic Gradient Descent gives different minima based on starting point</figcaption></figure><p id="d5c6" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">由于它是一个未知函数，我们不知道:</p><ul class=""><li id="bf37" class="mw mx iq ka b kb kc kf kg kj my kn mz kr na kv nb nc nd ne bi translated">理想的起点</li><li id="1545" class="mw mx iq ka b kb nf kf ng kj nh kn ni kr nj kv nb nc nd ne bi translated">理想的步长</li><li id="ee2a" class="mw mx iq ka b kb nf kf ng kj nh kn ni kr nj kv nb nc nd ne bi translated">理想域(我们不能穿越无限大的 x 空间)</li></ul><p id="f9b5" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">一个可能的解决方案是使用模拟退火，它给我们一个达到全局最小值的合理概率。</p><h1 id="7143" class="kw kx iq bd ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt bi translated">模拟退火</h1><p id="cb04" class="pw-post-body-paragraph jy jz iq ka b kb lu kd ke kf lv kh ki kj lw kl km kn lx kp kq kr ly kt ku kv ij bi translated">这个名字和灵感来自冶金中的<a class="ae nk" href="https://en.wikipedia.org/wiki/Annealing_(metallurgy)" rel="noopener ugc nofollow" target="_blank">退火</a>，一种涉及加热和控制冷却材料以增加其晶体尺寸并减少其缺陷的技术。两者都是依赖于热力学自由能的物质属性。加热和冷却材料会影响温度和热力学自由能。退火的模拟可用于寻找具有大量变量的函数的全局最小值的近似。</p><p id="fc36" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">在模拟退火算法中实现的这种缓慢冷却的概念被解释为随着解空间的探索，接受更差解的概率缓慢降低。接受更差的解是元启发式算法的一个基本属性，因为它允许对全局最优解进行更广泛的搜索。</p><p id="f407" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">一般来说，模拟退火算法工作如下:</p><ul class=""><li id="4edf" class="mw mx iq ka b kb kc kf kg kj my kn mz kr na kv nb nc nd ne bi translated">设<em class="nl"> x </em> = <em class="nl"> x </em> 0</li><li id="494e" class="mw mx iq ka b kb nf kf ng kj nh kn ni kr nj kv nb nc nd ne bi translated">对于<em class="nl"> k </em> = 0 到<em class="nl"> k </em> max(不含):<br/> - <em class="nl"> T </em>每步递减<br/> -随机选取一个邻居，<em class="nl"> x_ </em> new ←邻居(<em class="nl">x</em>)<br/>-If<em class="nl">P</em>(<em class="nl">E</em>(<em class="nl">x【T22))，<em class="nl"> E </em> ( 【T25</em></li><li id="1600" class="mw mx iq ka b kb nf kf ng kj nh kn ni kr nj kv nb nc nd ne bi translated">输出:最终状态 x</li></ul><p id="d35a" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">以下是我们特定函数的 Python 实现:</p><pre class="ma mb mc md gt mk ml mm mn aw mo bi"><span id="42d1" class="mp kx iq ml b gy mq mr l ms mt">import numpy as np</span><span id="3d4d" class="mp kx iq ml b gy mu mr l ms mt">#Unknown Function<br/>f = lambda x:(1/4*x**4)+(1/3*x**3)-(3*x**2)-7</span><span id="42f5" class="mp kx iq ml b gy mu mr l ms mt">def acceptance_probability(E, E_new, T):<br/>    return np.exp(-(E-E_new)/T)</span><span id="a92c" class="mp kx iq ml b gy mu mr l ms mt">def random_neighbour(x):<br/>    return x += np.random.uniform(-1,1)</span><span id="0cc4" class="mp kx iq ml b gy mu mr l ms mt">def simulated_annealing(f, steps):<br/>    x = np.random.random()<br/>    E = f(x)<br/>    print("x=%.2f, fmin=%.2f"%(x, E))<br/>    for k in range(steps):<br/>        T = T*0.9<br/>        x = random_neighbour(x)<br/>        E_new = f(x)<br/>        P = acceptance_probability(E, E_new, T)<br/>        if P &gt; np.random.random():<br/>            E = E_new<br/>        print("x=%.4f, fmin=%.4f, Prob.=%.4f"%(x,E,P))<br/>    return E</span><span id="0942" class="mp kx iq ml b gy mu mr l ms mt">simulated_annealing(f,20)</span></pre><p id="b7ce" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">运行该等式，我们得到以下输出:</p><pre class="ma mb mc md gt mk ml mm mn aw mo bi"><span id="3971" class="mp kx iq ml b gy mq mr l ms mt">x=0.62, fmin=-8.04<br/>x=-0.3446, fmin=-7.3664, Prob.=0.4753<br/>x=-0.8717, fmin=-9.3559, Prob.=11.6601<br/>x=-0.8329, fmin=-9.1534, Prob.=0.7575<br/>x=-1.6213, fmin=-14.5791, Prob.=3903.7178<br/>x=-2.3907, fmin=-20.5342, Prob.=23982.6510<br/>x=-1.8220, fmin=-20.5342, Prob.=0.0003<br/>x=-1.1582, fmin=-20.5342, Prob.=0.0000<br/>x=-0.2298, fmin=-20.5342, Prob.=0.0000<br/>x=-0.8731, fmin=-20.5342, Prob.=0.0000<br/>x=-1.8032, fmin=-20.5342, Prob.=0.0000<br/>x=-2.1873, fmin=-20.5342, Prob.=0.0110<br/>x=-1.8673, fmin=-20.5342, Prob.=0.0000<br/>x=-2.7618, fmin=-22.3598, Prob.=1315.6210<br/>x=-2.3266, fmin=-22.3598, Prob.=0.0001<br/>x=-2.5017, fmin=-22.3598, Prob.=0.0036<br/>x=-2.6164, fmin=-22.3598, Prob.=0.0466<br/>x=-1.7016, fmin=-22.3598, Prob.=0.0000<br/>x=-1.7248, fmin=-22.3598, Prob.=0.0000<br/>x=-1.6569, fmin=-22.3598, Prob.=0.0000<br/>x=-1.5051, fmin=-22.3598, Prob.=0.0000</span></pre><p id="2f28" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">如上所示，该值收敛到-22.75。虽然这种方法不能保证全局最优，但是如果我们不限制我们的领域，它是相当接近的。还要注意，尽管初始值非常接近局部最小值，但它仍然设法找到了全局最小值。</p><h1 id="eed8" class="kw kx iq bd ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt bi translated">动态规划</h1><p id="ec96" class="pw-post-body-paragraph jy jz iq ka b kb lu kd ke kf lv kh ki kj lw kl km kn lx kp kq kr ly kt ku kv ij bi translated">这部分更多的是时间复杂性而不是准确性。动态编程主要是对普通<a class="ae nk" href="https://www.geeksforgeeks.org/recursion/" rel="noopener ugc nofollow" target="_blank">递归</a>的优化。每当我们看到递归解决方案重复调用相同的输入时，我们可以使用动态编程来优化它。其思想是简单地存储子问题的结果，这样我们就不必在以后需要时重新计算它们。这种简单的优化将时间复杂度从指数级降低到多项式级。例如，如果我们为<a class="ae nk" href="https://www.geeksforgeeks.org/program-for-nth-fibonacci-number/" rel="noopener ugc nofollow" target="_blank">斐波纳契数</a>编写简单的递归解决方案，我们得到指数时间复杂度，如果我们通过存储子问题的解决方案来优化它，时间复杂度降低到线性。</p><p id="d1f9" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">让我们以斐波那契数列为例:</p><pre class="ma mb mc md gt mk ml mm mn aw mo bi"><span id="394e" class="mp kx iq ml b gy mq mr l ms mt">def f(n):<br/>    if n &lt;= 1:<br/>        return n<br/>    else:<br/>        return f(n-1)+f(n-2)</span></pre><p id="c9b8" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">这个问题的复杂性在于 O(2^n).如果你问我，我会觉得非常复杂！然而，让我们更好地分析这个问题。</p><figure class="ma mb mc md gt jr gh gi paragraph-image"><div class="gh gi nm"><img src="../Images/edec31111a59f29517fac86268f77f9f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1208/format:webp/1*HnZo9bn8dytFmruZgq7wXQ.png"/></div><figcaption class="me mf gj gh gi mg mh bd b be z dk">Fibonacci at n=6</figcaption></figure><p id="ea0b" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">如果你看一个 n=6 的递归树，有很多重复。只需计算 f(3)的值的个数。在动态编程中，我们将把值存储在内存中，如果再次调用，就不会重新计算。下面是斐波那契的动态编程版本:</p><pre class="ma mb mc md gt mk ml mm mn aw mo bi"><span id="f105" class="mp kx iq ml b gy mq mr l ms mt">store = {}<br/>store[0] = 0<br/>store[1] = 1</span><span id="f2ec" class="mp kx iq ml b gy mu mr l ms mt">def f(n):<br/>    store[n] = f(n-1)+f(n-2)<br/>    return store[n]</span></pre><p id="a2e5" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">使用新方法，每一步的复杂度为 O(1)。这允许我们探索 n 的整个域，以找到具有最小时间复杂度的最优解。</p></div></div>    
</body>
</html>