# 不再做实验了

> 原文：<https://towardsdatascience.com/no-more-experiments-4919630675d9?source=collection_archive---------30----------------------->

## 大数据和算法是对自由项目的重大挑战。收集透明胶片可能是一个解决方案。

![](img/9c29dbf15e855e54c108e15fd4153fe0.png)

Photo by [Kristina V](https://unsplash.com/@christya_v?utm_source=medium&utm_medium=referral) on [Unsplash](https://unsplash.com?utm_source=medium&utm_medium=referral)

1960 年，经济学家弗雷德里希·冯·哈耶克出版了《自由宪法[](https://iea.org.uk/sites/default/files/publications/files/Hayek's%20Constitution%20of%20Liberty.pdf)*。这是一本非凡的书，散发着作者的智慧，似乎是深刻和批判性思考的典范指南，并且根据哈耶克帮助建立的世界，无疑对现在有所启发。*

*然而，哈耶克构建的世界正在发生变化，随之而来的是哈耶克自由的支柱开始出现裂缝。当然，自由是一件有趣而又难以实现的事情。例如，(市场)自由意志论者是最先抗议任何削减其自由的概念的人之一，但自由似乎只存在于资本主义现实主义的核心中。美国人对自由主义一词的挪用无助于这种混乱，社会自由主义和财政保守主义等术语更多地表达了我们对资本主义的顺从，而不是我们对自由的看法。*

*接下来是哲学上的自由辩论，在那些相信我们生来自由，社会摆脱了强加的约束(积极自由)的人和那些相信我们生来受约束的人之间，我们应该努力废除所有仍然不合理的强制焦点(消极自由)。人们可能会问自己是哪种类型的自由主义者，但我认为这个问题没有说到点子上。像许多事物一样，自由不是一系列的绝对，而是一个光谱。至少，自由太复杂了，无法用政治象限来理解…*

## *最好的方法是你自己的方法*

*在*的《自由的宪法*中，哈耶克对于他认为自由是什么以及何时可以受到限制的解释非常简短，这与约翰·斯图亚特·密尔在 [*中关于自由*](https://eet.pixel-online.org/files/etranslation/original/Mill,%20On%20Liberty.pdf) 的思想以及密尔的伤害原则非常接近。考虑到哈耶克花了一段时间管理穆勒的著作，这并不奇怪。*

*那么，更有趣的是哈耶克在本书其余部分的讨论——这一讨论肯定受到了当时地缘政治形势的影响——为什么以个人为中心的自由(尽管不是严格的自由民主)优于替代的集体化制度。其中一个论点是我称之为“多次实验”的论点。*

*自由思想的很大一部分是犯错误并从中吸取教训的能力。这就是为什么伤害原则只在保护他人的自由时证明胁迫是正当的；我们完全有权利犯自己的错误，在这样做的过程中，我们从错误中学习并发展。穆勒认为这一点，哈耶克当然也同意。哈耶克认为，通过人们的尝试和偶尔的成功(但经常失败)，社会进步了。因此，允许人们自由地走自己的路并进行试验，将比集体化下更快地产生更多的成功(和更多的失败)，在集体化下，单个行动者——比如说国家——一次只能尝试一个计划。*

*这是一个非常政治化的想法，但在资本主义内部，它非常重要。最好的方法是你自己的方法。*

## *数据更了解*

*“许多实验”的论点能经得起数据、算法和 21 世纪的考验吗？让我们假设论点是正确的；那么，如果我们能把每一种结果模拟一万亿次，我们还需要人类自由吗？这难道不是更合乎道德吗？因为现在人们不必为了一些人的成功而失败。在越来越短的时间内，最大限度地增加我们可以进行的实验数量，难道不是更有效率吗？*

*显然，这是一个有争议的论点。首先，模拟世界有多精确？几十年来，金融家和学者在数十亿美元的帮助下，试图对股票市场进行建模，但弥漫在交易大厅的许多动物精神仍未被驯服。*

*第二，接受我们可以模拟世界，我们应该选择谁或者从谁的角度来构建模拟？对算法偏见的研究已经表明[刑事司法算法中的负面种族偏见](http://ambailcoalition.org/download/24/risk-assessments/865/the-biased-algorithm-evidence-of-disparate-impact-on-hispanics.pdf)，以及[面部识别软件](http://proceedings.mlr.press/v81/buolamwini18a/buolamwini18a.pdf)。这些偏见的原因似乎不同，但效果是一样的——现实的均质化。*

*第三，在算法的 cosh 下，社会和进步到底意味着什么？这就是我称之为“矩阵问题”的东西，在关于狗屁工作的[文献](https://www.vox.com/2018/5/8/17308744/bullshit-jobs-book-david-graeber-occupy-wall-street-karl-marx)中有广泛涉及。如果算法的目的是服务于人类的进步，但是人类的进步存在于一个服务和等级的社会内部，那么任何结果都可以被描述为进步吗？或者，我们必须给这个世界贴上静止的标签吗？压迫感？超真实？*

## *裂缝出现的地方*

*大数据的激增使得第一个论点变得大胆，而且很可能不正确。随着数据和算法对社会的影响——从 [YouTube 激进化](https://www.nytimes.com/2018/03/10/opinion/sunday/youtube-politics-radical.html)到[脸书大选推动](https://www.theguardian.com/news/2018/mar/17/cambridge-analytica-facebook-influence-us-election)——显著增长，数据的价值越来越被认识到。是的，我们可能还没有驯服动物精神，但随着我们的数据基础设施扩展数据的能力和亲密度，我们很可能会达到这一点——我将这样的概念称为[数据景观](https://medium.com/@stuartmmills/mana-capitalism-74d9a747315d)。*

*剩下的争论继续对数据的统治地位提出挑战，但只是在我们继续关心它们的范围内。刑事司法算法歧视黑人男性的趋势是因为[长期持有的执法偏见](https://www.perpetuallineup.org/)，而面部识别软件识别白人男性的效率是因为[主要是白人男性编写程序。](https://www.nytimes.com/2018/02/09/technology/facial-recognition-race-artificial-intelligence.html)这些都是社会问题，也是一个例子，说明允许少数观点(如果不是少数个人)来创造我们的数据驱动的未来将如何使该项目变得非常不自由。*

## *重拾动物精神*

*不过，有一些防止这种情况发生的建议。数据经济学家恩斯特·哈芬(Ernst Hafen)建议，所有人都应该被赋予获得副本的权利:要求任何收集我们数据的人向我们提供副本的权利。他建议我们可以将这些副本集体化——我称之为集体透明的概念——创建一个数据中心:一个数据公共区。这将为算法提供相对无偏见并反映社会的数据，但也将使数据收集民主化和非货币化。*

*想象一下，如果脸书的价值在于提供高质量的服务，而不是因为你和你所有的朋友已经给了他们太多的数据，让你很容易地换到另一家公司？想象一下，如果我们决定，出于道德原因，一些数据不应用于算法，就像我们在道德上反对人体器官市场一样？*

*反常的是，这种数据集体化可能是自由主义项目的未来；一个解决数据垄断、扩大数据自由和使数据使用民主化的系统。所有这一切，同时继续受益于大数据和算法。一个不再有实验的世界，我们被赋予了前所未有的实验能力。*