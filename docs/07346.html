<html>
<head>
<title>Enhancing the power of Cross-Entropy loss for image classification</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">增强交叉熵损失的能力用于图像分类</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/enhancing-the-power-of-softmax-for-image-classification-4f8f85141739?source=collection_archive---------25-----------------------#2019-10-15">https://towardsdatascience.com/enhancing-the-power-of-softmax-for-image-classification-4f8f85141739?source=collection_archive---------25-----------------------#2019-10-15</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><figure class="gl gn jo jp jq jr gh gi paragraph-image"><a href="https://pixabay.com/photos/sphere-nature-ball-shaped-bubble-3277626/"><div class="gh gi jn"><img src="../Images/791b657b2e6d5266cc74580ce5f7e242.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*uLobtHzI6WXF8hqUQvALtA.jpeg"/></div></a></figure><p id="8e83" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">交叉熵损失已经在许多分类任务中取得了最先进的结果。但是，对于其类具有相似特征的数据集，它不会像预期的那样执行。原因是，交叉熵损失无法学习区分度不够的可分离特征。为了解决这个问题，已经提出了许多方法。一个非常有效的方法是用角距离(边距)来分离学习到的特征，这将在本文中解释。</p></div><div class="ab cl ks kt hu ku" role="separator"><span class="kv bw bk kw kx ky"/><span class="kv bw bk kw kx ky"/><span class="kv bw bk kw kx"/></div><div class="ij ik il im in"><h1 id="d9f9" class="kz la iq bd lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw bi translated">使用 SoftMax 和交叉熵损失进行训练</h1><p id="812a" class="pw-post-body-paragraph ju jv iq jw b jx lx jz ka kb ly kd ke kf lz kh ki kj ma kl km kn mb kp kq kr ij bi translated">首先，让我们在 mnist 数据集中训练一个 VGG16 Cnn 模型(Simonyan &amp; Zisserman，2014)(图 1)。</p><figure class="md me mf mg gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="mh mi di mj bf mk"><div class="gh gi mc"><img src="../Images/43d46829b56d2d8c21fb95912d31e495.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*aBxPOC9dj68qzczTX2NQUQ.png"/></div></div><figcaption class="ml mm gj gh gi mn mo bd b be z dk">Figure 1: VGG16 model for Mnist</figcaption></figure><p id="db86" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">mnist 数据集中的每个图像都有(28x28x1)个维度，但是我们在 VGG16 网络中只能馈送一个以(32x32x1)为下限的图像。因此，在每个图像的边界添加了额外的零填充，以达到最小输入大小。此外，“通道优先”顺序被证明可以加速 GPU 中的训练，因此维度被转换为(1x32x32)。除了标准的 VGG16 架构之外，我们还可以添加全连接的层，然后使用 SoftMax 为每个类生成最终预测。最后一个完全连接的层也可以用于提取特征。这些特征可以使用 2D 或 3D 欧几里德空间中的 PCA 或 T-SNE 等降维技术来绘制，以提供关于训练的见解。</p><p id="e89d" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">在 VGG16 训练之后，我们可以使用它的权重在看不见的图像(测试集)中进行预测。测试集中最后一个全连接层(特征)的神经元的输出在下面使用 PCA 在 3D 欧几里得空间中被可视化。</p><figure class="md me mf mg gt jr gh gi paragraph-image"><div class="gh gi mp"><img src="../Images/0a70ee65c21473e10ed0209ef9ced732.png" data-original-src="https://miro.medium.com/v2/resize:fit:1156/1*RtQho0bETivR1ZZGEw9jRQ.gif"/></div></figure><p id="eae9" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">很快有人可以理解，仅使用交叉熵损失的训练不能提供足够的类内紧密度和类间差异，以用于具有相似特征(例如人脸)的数千个类的数据集。</p><p id="5ce4" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated"><strong class="jw ir">注意</strong>当使用 PCA 降低维度时，总方差下降，因此特征的拓扑是近似的。例如，在图 2 中，红点(代表一个类别的要素)之间的距离相对较大。如果它们被投射到 PCA1 中，它们的最终距离将相对较小。因此，红色要素的差异很小，该类的可视化结果也不准确。</p><figure class="md me mf mg gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="mh mi di mj bf mk"><div class="gh gi mq"><img src="../Images/e3a1ffe822726b378c1ae40e346c6145.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*L-dqIjwVwYyBlhF7iwmuoA.png"/></div></div><figcaption class="ml mm gj gh gi mn mo bd b be z dk">Figure 2: Dimensionality reduction using PCA</figcaption></figure></div><div class="ab cl ks kt hu ku" role="separator"><span class="kv bw bk kw kx ky"/><span class="kv bw bk kw kx ky"/><span class="kv bw bk kw kx"/></div><div class="ij ik il im in"><h1 id="a895" class="kz la iq bd lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw bi translated">转换交叉熵损失</h1><p id="1dba" class="pw-post-body-paragraph ju jv iq jw b jx lx jz ka kb ly kd ke kf lz kh ki kj ma kl km kn mb kp kq kr ij bi translated">变换的思想是将所有特征分布在超球面上，并在每类特征之间增加一个角裕度，以增强它们的区分能力(刘等，2017)。</p><p id="69cf" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">首先让我们回忆一下交叉熵损失函数:</p><figure class="md me mf mg gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="mh mi di mj bf mk"><div class="gh gi mr"><img src="../Images/141aa5f2d274d53663797c3a9645dad2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*IhqfCKvLJ9GebMqwTC0ewQ.png"/></div></div></figure><figure class="md me mf mg gt jr gh gi paragraph-image"><div class="gh gi ms"><img src="../Images/59a44a8ea342be05fffd455c15e7638b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1200/format:webp/1*65sqqFdqZPyuGZrcL4A9mw.png"/></div></figure><p id="386b" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">我们可以重写逻辑</p><figure class="md me mf mg gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="mh mi di mj bf mk"><div class="gh gi mr"><img src="../Images/4c4b0ccbfa6a2dc6c1e998c215d3fb72.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*PzW8DQ4whOAPJOUfA8jGcQ.png"/></div></div></figure><p id="1974" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">作为第一项加上第二项的内积</p><figure class="md me mf mg gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="mh mi di mj bf mk"><div class="gh gi mr"><img src="../Images/f55cfa6f340274dd3c3a1f1a9ed11beb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*U3N1QHkAIQwOiGlTz1SXag.png"/></div></div></figure><p id="eb57" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">其中θ是权重和特征之间的角度。此外，如果我们将权重标准化，将偏差归零</p><figure class="md me mf mg gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="mh mi di mj bf mk"><div class="gh gi mr"><img src="../Images/e90b373a416714ab6dd6faa0c84459b9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Qnk65UStHMs5L6P55y-p3A.png"/></div></div></figure><p id="97c5" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">请注意，的最终预测值仅取决于角度θ(刘等，2017)。因此，交叉熵损失函数被转换为</p><figure class="md me mf mg gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="mh mi di mj bf mk"><div class="gh gi mr"><img src="../Images/2023900e1d01b653b575a9ca94490075.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*IMVnxC0HnZ5FmESrrF_GIg.png"/></div></div></figure><p id="eb88" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">我们应该做的另一个修改是归一化特征向量的范数，以消除径向方向上的变化。因此，特征位于半径为“s”的超球面的表面上，并且学习仅依赖于余弦值来开发辨别能力(王等人，2018)。</p><figure class="md me mf mg gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="mh mi di mj bf mk"><div class="gh gi mr"><img src="../Images/f8fa8fb9e9d15f40c858c6fa2153a106.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*DZ0KFii17UhWI58JE87kUQ.png"/></div></div></figure><p id="df4f" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">通过这种修改的交叉熵损失，我们的网络可以学习用角度边界分隔的特征，但这并不意味着它足够强，可以满足我们最初的假设。因此，我们将在权重和特征之间添加附加的角度裕度损失，以同时增强类内紧凑性和类间差异。已经提出了许多角裕度罚值，但是加性罚值比其他罚值具有更好的几何属性，与超球流形上的测地距离精确对应(邓，郭，薛，&amp; Zafeiriou，2018)。添加余量后的最终转换交叉熵损失如下所示:</p><figure class="md me mf mg gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="mh mi di mj bf mk"><div class="gh gi mr"><img src="../Images/15d038fef4c71095687879b1d9572cd0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*c1ShwTagHZmv_vzc8EQcig.png"/></div></div></figure><p id="c41f" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">在图 3 中示出了修改的整个过程</p><figure class="md me mf mg gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="mh mi di mj bf mk"><div class="gh gi mt"><img src="../Images/73c3bba1f4290f078b390be2f718a148.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Q1ZCprO-gcNzvmne-QIEqA.png"/></div></div><figcaption class="ml mm gj gh gi mn mo bd b be z dk">Figure 3: Visualization of the whole Cross-Entropy loss modification</figcaption></figure><p id="70fd" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">在最后一个全连接层的测试集中计算的特征在下面使用 PCA 在 3D 欧几里得空间中被可视化。</p><figure class="md me mf mg gt jr gh gi paragraph-image"><div class="gh gi ms"><img src="../Images/279d97da31b6cd37a3309bcdc9ae8a79.png" data-original-src="https://miro.medium.com/v2/resize:fit:1200/1*h9zR_XlxtbpP8cf0-_IGSw.gif"/></div></figure><p id="f13a" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">正如我们所观察到的，由于附加的角度裕度“m”(上面的 0.5)，每一类的特征都非常紧凑，并且可以与其他类分开。因此，这种方法适用于包含成千上万个类别的数据集，这些类别的特征不具有很高的区分度。</p><p id="3906" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">在 tf.keras 中，我们可以简单地修改 SoftMax 层来实现这种所需的行为。以下是使用两个输入(要素，正确 _ 标签)进行训练的修改后的 SoftMax 图层的代码:</p><figure class="md me mf mg gt jr"><div class="bz fp l di"><div class="mu mv l"/></div></figure><p id="a7f5" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">完整的代码可以在我的<a class="ae mw" href="https://github.com/christk1/MSH_tensorflow_keras" rel="noopener ugc nofollow" target="_blank"> github 链接</a>中找到。您可以试验不同的“m”值，以查看其在最终可视化中的影响。</p></div><div class="ab cl ks kt hu ku" role="separator"><span class="kv bw bk kw kx ky"/><span class="kv bw bk kw kx ky"/><span class="kv bw bk kw kx"/></div><div class="ij ik il im in"><h1 id="6fb1" class="kz la iq bd lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw bi translated">进一步分析</h1><h2 id="b88c" class="mx la iq bd lb my mz dn lf na nb dp lj kf nc nd ln kj ne nf lr kn ng nh lv ni bi translated">移除特征提取器中的 ReLU</h2><p id="2c2e" class="pw-post-body-paragraph ju jv iq jw b jx lx jz ka kb ly kd ke kf lz kh ki kj ma kl km kn mb kp kq kr ij bi translated">上述层的第一个输入是作为最后一个全连接层的输出的特征。现代 CNN 通常在几乎每一层之后使用 ReLU 非线性，使得输出位于范围[0，+∞]内。如果 ReLU 存在于使用上述交叉熵损失备选方案的网络中的最后一个全连接层之后，则可以放置特征的角度是有限的。从该层的顶部移除 ReLU(Liu 等人，2017)可以有利于特征学习，因为特征可以分布在更宽的空间中。</p><h2 id="592e" class="mx la iq bd lb my mz dn lf na nb dp lj kf nc nd ln kj ne nf lr kn ng nh lv ni bi translated">从另一个角度标准化权重</h2><p id="31ec" class="pw-post-body-paragraph ju jv iq jw b jx lx jz ka kb ly kd ke kf lz kh ki kj ma kl km kn mb kp kq kr ij bi translated">我们看到权重的归一化给出了更好的几何解释。权重的归一化也可以帮助解决训练数据不平衡的问题，因为同一类中的样本数量越大，与该类相关联的权重的范数就越大。因此，对修正的交叉熵损失中的权重范数进行归一化，解决了这个问题(刘等，2017)。</p><h2 id="7a7a" class="mx la iq bd lb my mz dn lf na nb dp lj kf nc nd ln kj ne nf lr kn ng nh lv ni bi translated">消除偏见</h2><p id="9556" class="pw-post-body-paragraph ju jv iq jw b jx lx jz ka kb ly kd ke kf lz kh ki kj ma kl km kn mb kp kq kr ij bi translated">通过将偏差归零，修正的交叉熵损失具有清晰的几何解释，因此变得更容易分析(刘等人，2017)。通过实验，这对特征分布没有直接影响，并且学习的特征同样强。</p></div><div class="ab cl ks kt hu ku" role="separator"><span class="kv bw bk kw kx ky"/><span class="kv bw bk kw kx ky"/><span class="kv bw bk kw kx"/></div><div class="ij ik il im in"><h1 id="6711" class="kz la iq bd lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw bi translated">参考</h1><p id="6f77" class="pw-post-body-paragraph ju jv iq jw b jx lx jz ka kb ly kd ke kf lz kh ki kj ma kl km kn mb kp kq kr ij bi translated">邓军，郭军，薛，n .，&amp; Zafeiriou，S. (2018，1)。ArcFace:深度人脸识别的附加角裕度损失。<em class="nj"> arXiv 电子版</em>，arXiv:1801.07698。</p><p id="33c9" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">刘文伟，文，于，李，李，宋，李(2017，4)。用于人脸识别的深度超球面嵌入。<em class="nj"> arXiv 电子版</em>，arXiv:1704.08063。</p><p id="75fd" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">Simonyan，k .，&amp; Zisserman，A. (2014，9)。用于大规模图像识别的非常深的卷积网络。<em class="nj"> arXiv 电子印花</em>，arXiv:1409.1556。</p><p id="4b40" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">王，洪，王，周，钟，季，谢，龚，周。。。刘，W. (2018，1)。CosFace:深度人脸识别的大幅度余弦损失。<em class="nj"> arXiv 电子印花</em>，arXiv:1801.09414。</p></div></div>    
</body>
</html>