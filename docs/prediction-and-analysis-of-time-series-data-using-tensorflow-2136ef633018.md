# 张量流在时间序列数据预测和分析中的应用

> 原文：<https://towardsdatascience.com/prediction-and-analysis-of-time-series-data-using-tensorflow-2136ef633018?source=collection_archive---------4----------------------->

![](img/669d08a74aa06b0f82ad2b72fc98e38a.png)

Photo by [Jason Briscoe](https://unsplash.com/@jbriscoe?utm_source=medium&utm_medium=referral) on [Unsplash](https://unsplash.com?utm_source=medium&utm_medium=referral)

嘿大家好！在这篇文章中，我试图总结 Deeplearning.ai 关于[序列、时间序列和预测](https://www.coursera.org/learn/tensorflow-sequences-time-series-and-prediction?)的课程。

在这篇文章中，我们关注“时间序列数据”，它是序列模型的一部分。本质上，这代表了一种随时间变化的数据类型，例如特定地方的天气、一群人的行为趋势、数据的变化率、身体在 2D 或 3D 空间中的运动或者市场中特定股票的收盘价。

时间序列数据的分析可以对任何包含“时间”因素的事物进行。

那么机器学习可以帮助我们在时间序列数据上实现什么呢？

**1)预测** —最显著的应用是根据收集的历史数据预测未来。

**2)数据插补** —预测过去的数据，从而预测过去的数据，即使我们没有收集这些数据。它还可以用来预测数据中缺失的值。

**3)检测异常** —可用于检测潜在的拒绝服务攻击。

**4)检测模式** —可用于预测声波系列数据中的单词。

在处理时间序列数据时，总会出现某些关键词。

# **趋势**

![](img/87213c6b75a3f549fa70fcaa9d33c0c1.png)

时间序列有一个特定的数据移动方向。上图是一系列具有向上趋势的数据。

# **季节性**

![](img/b8a5e95e5245be67d1c5be7eaf4692e4.png)

以可预测的间隔重复的模式。以上是一个软件开发者网站的数据。该数据向上值为 5 个单位，向下值为 2 个单位。因此，我们可以对每个单独的峰进行推断，峰开始和结束时的下降对应于周末，中间的数据对应于工作日

# **组合**

![](img/9e4a7a366c48072678d986d3a2d74d60.png)

上面的 pic 是具有上升趋势和季节性的数据类型的组合。

# **白噪声**

![](img/cbb45dc950728c7cdb34889e5e5a2dc0.png)

这只是一组随机值，不能用于预测。因此，这被称为白噪声。

# **自相关**

![](img/f1675ef4a187e59fefe10e5b23d2e9cc.png)

没有季节性或趋势，峰值似乎是随机出现的，但峰值不是随机的。在尖峰之间，有一种非常确定的衰变类型。

![](img/68955c0b2fcf010f40dc66c649fe2a08.png)

下一个时间步长是前一个时间步长值的 99%加上一个偶然的尖峰。上面是一个自相关序列，也就是说，它与自身的延迟拷贝(也称为滞后)相关。

![](img/2a62e06a56104eba29911df198d55347.png)

上面突出显示的框中的值似乎具有很强的自相关性， ***像这样的时间序列被描述为具有记忆，其中步骤依赖于先前的步骤。这些尖峰通常被称为创新*** 。换句话说，这些创新不能用过去的价值来预测。

因此我们现在知道时间序列数据是由**趋势、季节性、自相关**和**噪声**组合而成。

![](img/d9690c917235cd6597b726522bfb2164.png)

机器学习模型被训练来发现模式，并基于这些模式来预测未来。因此，这在很大程度上与时间序列相关，除了不可预测的噪声，但这仍然给了模型一种直觉，即过去存在的模式可能在未来存在。

![](img/9b051ebd591166b966f4560797c2b423.png)

***平稳(时间)序列是指其均值、方差、自相关等统计特性在一段时间内均为常数的序列*** 。因此，非平稳序列的统计特性会随时间而改变。

当然，现实生活中的时间序列，也可能有不可预见的事件，可能会影响数据。以上面的图表为例。如果上图是一只股票，那么可能导致这种变化的“*大事件*”可能是由于某种金融危机或丑闻。

![](img/5f5f1da5f696c07b7d3d8f60ff8cd5f9.png)

预测数据的一种方法是使用“**简单预测**”，即取上一个值并假设下一个值将是相同的值。

![](img/3c9ddfda1cf73a7b3809ebe13869750d.png)

将数据分成三部分用于训练、验证和测试，称为“**固定部分**”。在这样做的时候，必须确保每个时期包含一个整数个季节。

例如:如果时间序列具有年度季节性，那么每个周期必须包含 1 年、2 年或 3 年的季节性。如果我们取一个跨度为一年半的周期，那么某些月份会比其他月份表现得更多。

与非时间序列数据集相比，这有一点不同，在非时间序列数据集中，我们选择随机值来做同样的事情，这不会影响最终结果。但是，在这里，我们会注意到跨度和周期的选择会影响最终结果，因为数据是时间敏感的。

另一件需要考虑的事情是，在训练时，我们可以使用如上所述的策略将数据分成三个部分，但是一旦训练完成并且我们准备好模型，我们应该对整个数据进行再训练，因为用于测试的数据部分与当前时间点的最新数据相关，并且是确定未来值的最强信号。

![](img/d4fcf8a332239795dd596354d1d5c2f3.png)

# **绩效评估指标**

![](img/f1a07197b5a72f9055e64265a1551fd2.png)![](img/bf1ed2e3b84f5311df43cd04df4d0dde.png)

最基本的预测方法是“**移动平均线**”。其思想是，上图中的 ***黄色*** 线是在一个称为“**平均窗口**”的特定固定时间帧中获取的蓝色值的平均值。

上面的曲线给出了时间序列的平滑曲线，但是它 ***没有预测趋势或季节性*** 。它甚至可以给出比天真预测差的性能，给出大的 MSE。

![](img/d4489e49db75b1f2dc7796d0f0f9decb.png)

消除这种情况的一种方法是通过一种叫做“**差异**的方法来消除趋势或季节性。在这种方法中，我们研究时间' **t** '和时间' **t-365** '的值。根据时间序列的时间段，进行差分的时间段可以改变。

这样做我们得到了上面的结果。以上数值没有趋势性，也没有季节性。

![](img/a07423a9751bef368d08cd923a890d3c.png)

然后，我们可以使用移动平均线来预测时间序列。因此，黄线给出了上述数据的移动平均值，但这只是时间序列中**差异**的预测。为了得到真实的数据，我们将'**差分的**数据与' **t-365** 的数据相加。

在下图中，由于季节性周期是 **365** ，我们将从时间 **t** 的值中减去 **t-365** 的值。

![](img/8d82c0e68180dc1d0c1b4dbca5654617.png)![](img/e3de486393c3615e4c2d41ae59065d00.png)

上述操作的结果如上图所示。与之前的*移动平均线预测*相比，我们得到了一个较低的“ **MSE** ”。这是比*幼稚的*方法稍微好一点的版本。

我们会注意到预测有很多噪音。这是因为在取差值时，来自' **t-365** '数据的噪声被加入到我们的预测中。为了避免这种情况，我们可以对 t **-365** 数据进行移动平均，然后将其添加到我们的**差分**数据中。

![](img/bb7372c850288446d8d33ce04be92d23.png)

如果我们这样做，我们最终会得到上面用黄线表示的预测。以上曲线平滑，具有较好的' **MSE** '。

让我们先接触一下实际的编码部分。我们将遵循下面提到的几个步骤来模拟时间序列数据集，并尝试在其上构建模型。

我们创建一个值范围从 0 到 9 的数据集，并显式地将其转换为 ***numpy*** 数组。

![](img/f215a1829ed73633ae6ca4488e11cc7d.png)

数据集被分成大小为 5 的窗口，即每个数据窗口包含 5 个数据实例。1 的**移位**导致下一个数据窗口将第一个数据实例移位 1 个单位。

![](img/4559178c832d8d87c998e5b4e7227f20.png)

**drop_remainder** 导致不包含一组 5 个数据点的剩余窗口被丢弃。

![](img/10d4a52aec62d0bec46470eecdbbd0c0.png)

每个数据窗口被**平面映射**成 5 个一批。

![](img/41553dacaac189766ada32194cd33640.png)

进行映射以包含前 4 个实例作为训练数据，剩余的数据在每个窗口的末尾作为标签。然后，数据集以与数据范围大小相同的缓冲区大小进行混洗。

数据被混洗是为了避免 ***序列偏差*** 。

***顺序偏差是当事物的顺序能够影响对事物的选择时。例如，如果我问你最喜欢的电视节目，并按顺序列出“权力的游戏”、“杀死夏娃”、“旅行者”和“神秘博士”，你可能更有可能选择你熟悉的“权力的游戏”，这是你看到的第一个节目。哪怕和其他电视剧持平。因此，当训练数据集中的数据时，我们不希望序列以类似的方式影响训练，所以最好将它们打乱。***

![](img/06d9679ee423dc2d9b5f0fe9ecb63075.png)

数据集被分成每批 2 个，每个 X 作为包含训练数据的列表，每个 Y 作为标签映射到数据。

![](img/35bf4085bb7d8699bd9a97e945e38441.png)

数据被拆分，以便训练数据包含要合并到训练数据中的季节性和趋势。

![](img/c8088b8930c2606b85a4d52875a4feda.png)

使用下面的函数将数据分解到不同的窗口中。

![](img/64a36854d79c176fb21320762ea8678c.png)

数据集的窗口实例通过名称 ***数据集*** 创建，模型创建。

![](img/ec1a1e21790327411ebb44aaadc44ae4.png)

迭代每个窗口，我们试图预测验证数据。

![](img/ae2bdd91cf04a5fd933a8b3858d1f9f6.png)

我们结合了一个学习率调度器，试图测量模型的最佳学习率。

![](img/83db14ade49d835bb04d44fa21e8b1bb.png)

我们绘制了一系列已经实现的不同学习率，并确定了最适合我们模型的学习率。

![](img/cf9e5af1e2ca3073c298afbd1b760d2f.png)

从上面的图表中，我们观察到与学习率相关的最低成本大约是 1e-5。然而，这里要注意的一件有趣的事情是，图表在这一点和随后的几个点上似乎很不稳定。使用这个学习率可能会对我们的预测模型产生负面影响。因此，最适合的学习速率似乎是 1e-6，既平滑又低。

![](img/ec1a1e21790327411ebb44aaadc44ae4.png)

我们现在绘制关于时期的损失函数。

![](img/a282e2a2d091778d9cad7398d288d224.png)

该模型似乎已经停止学习，因此，该图似乎在前几个时期已经饱和，但事实并非如此。当我们绘制前 10 个时期的损失函数时，我们注意到损失持续减少。这意味着，即使学习速度非常慢，模型仍会继续学习。

![](img/532de0091ee1d943a859f22b175d8a12.png)

最后，我们为数据绘制图表。 ***蓝色*** 为原始， ***黄色*** 为预测，

![](img/8ec6f9a4c87161807400d52acde49cea.png)

我们的均方误差如下所示。

![](img/caa75b86ad9cd15dd7d2ae9492c6376c.png)

# **轮回层**

![](img/a1974349f73b1feb68b955cc6380fb71.png)

我们开始使用机器学习技术来预测数据的未来值。在上图中，我们有一个大小为(4，1)的输入批量向量。想象一下，如果 ***存储单元*** 有 3 个神经元，那么 ***存储单元*** 的输出将具有(4，3)的形状。因此，如果整个系列有 30 个存储单元，网络输出的总大小将是(4，3，30)。

![](img/5b0a0d0b3b00f25d4f120aa96ab86f49.png)

上图是**序列到序列**网络的一个例子，其中一个序列作为输入给出，一个序列作为输出接收，即输出为(4，3，30)的形状。当我们需要将一个 RNN 层堆叠在另一个之上时，这种类型的架构非常有用。

上图是一个**序列到向量**网络，其中一个序列作为输入给出，但我们接收一个向量作为输出，即输出是(4，3，1)的形状。

![](img/6c9fa7e5773fa290c390eb7947f0b5bb.png)

为了演示**序列到向量**模型的工作原理，我们使用上图。对于第一层，命令“**return _ sequences = True”**使下一层的每个时间步返回一个序列输出。这然后被馈送到下一层。默认情况下，下一层有" **return_sequences = False** "，这导致只给出一个向量作为输出。

请注意 **input_shape = [None，1]** 参数。Tensorflow 假设第一维是批量大小，它被设置为**“无”**意味着它可以有任何大小作为输入批量大小，下一维是时间步数，它可以被设置为**“无”**意味着 RNN 模型可以处理任何长度的序列，最终值为“1”，因为数据是单变量的。

![](img/9426c77e41e1af35e0687f51d56331f3.png)

如果我们在上面的模型中加入**“return _ sequences = True”**的参数，那么模型的第二层现在给出的是一个序列作为输出，而不是一个向量。**密集**层现在得到一个序列作为输入。Tensorflow 通过使用相同的**密集**层独立处理每个时间步长的输出。

# **LSTMs**

![](img/9ca9ace832d22ba7c3402bb83a5c9673.png)

当我们观察 RNN 时，它看起来就像上面的图表。这里，各个节点被输入批量大小的数据 **X[i]** ，并给出输出 **y[i]** ，同时将单元状态从该节点传递到下一个节点，该状态是计算后续输出的重要因素。

这种方法的问题是，随着单元状态从一个节点传递到另一个节点，它的值会减少，其效果会逐渐消失。

为了解决这个问题，应用了一种叫做 **LSTMs** 的新方法。

**LSTMs** 通过引入一种**单元状态**来消除这个问题，该单元状态在单元之间和时间步长之间传递，因此可以更好地保持**状态**。

![](img/70e82311199b4d54e2204899395b505a.png)

单元状态可以是如上图所示的**单向**或如下图所示的**双向**。

![](img/60b400b2ce8be732c0a345a6627fa863.png)

这意味着，与 RNNs 的情况相比，早期窗口中的数据对整体预测具有更大的影响。

在我们的代码中实现 LSTMs。

![](img/860eee8dcca177518daf857e3b7760b0.png)![](img/f9b24e00d9219e012c3829ea7749c10d.png)

在我们的模型中增加了另一层双向 LSTM。

![](img/ae9c8af9ffae8306e881be33c8f58658.png)

上面的代码给出了以下输出:-

![](img/1db6501432e9d64526e811dfe911ebd0.png)

通过在下面添加一层新的**双向**代码，我们得到以下结果。

![](img/ca80b17a5663cdd1908147ab16e87cb8.png)

我们没有观察到太大的差异，事实上， **MAE** 似乎已经倒下，也就是说，我们的模型性能已经下降。

![](img/6fee78921d1ab1ed88abe69232b3a62f.png)

因此，必须在模型中试验不同类型的层，并选择最佳层。

# **对模型进行卷积**

*为什么我们要在时间序列分析问题中使用卷积？*

一个原因是因为他们的训练成本更低。

第二，它们最适合解决许多实际问题。例如，在我们应用 RNNs 的某些情况下，我们假设先前出现的“每一个”数据将被要求猜测下一个数据。rnn 在这个概念上工作，因为它考虑了所有的历史数据来预测下一项数据。事实上，我们并不真的需要所有的数据。

为了理解这一点，让我们考虑一个子弹射弹的例子。为了预测抛射体的下一个值，我们实际上并不需要所有的历史抛射体数据。假设投射数据是一组*‘n’*实例，我们将只需要最新的*‘k’*实例来预测下一个投射数据，其中 *k < n.*

因此，人们可以限制时间依赖性，而是使用 CNN 架构来模拟时间序列。所以现在每个假设变成了依赖于前一个' *k* ' 实例的时间实例，前一个实例是卷积上的感受域。每个 CNN 过滤器学习一组规则，并将这些规则应用到最适合该规则的特定数据部分。因此，这成为一个非线性系统。

![](img/a00ec6ecab8926f3ee48b6b861503337.png)

我们注意到“*输入形状*，它将数据转换为一维数据，而不是卷积通常用来处理图像的二维数据(图像是二维数据)。

![](img/626ef6ea8c96f24b535cea79d0e09543.png)

上面的图是我们应用了 *conv* 图层后得到的。与早期的情节相比，这是一个巨大的进步。然而，情节仍然可以通过以下方式进行改进

1.  **对它进行更长时间的训练。**

![](img/fa9a59d88b01008e843f30ea2414895c.png)

从图中可以看出，模型仍在学习，也许学习速度很慢，因此，如果我们继续训练模型一段更长的时间，模型的整体效率可以提高。

**2。另一种方法是使模型双向化。**

![](img/e682332561b05fbc43ad5e8b1141558c.png)![](img/614a42de1574f9497991b095a67a533c.png)

然而，我们注意到模型现在开始过度拟合数据，并且“ *MAE* ”实际上已经增加。

![](img/b7a7de386170bc16c66da30f8c16248a.png)

当我们绘制数据时，我们可以清楚地看到数据中有很多噪声，因为我们是以小批量的方式向模型提供数据，所以我们最终得到了这个结果。因此，这使我们能够得出结论，上述步骤是朝着正确方向迈出的一步，通过对批量大小等超参数进行一些调整，我们可以改善我们的结果。我们可以试验批量大小，并尝试得到适当的结果。

# **调整我们模型的过程**

![](img/4b4f4c417f537a0a31419c4a0c0364d8.png)

我们以“太阳黑子活动数据集”为例。我们使用基本的“密集”层网络来训练我们的模型，该网络具有两层，每层具有 10 个神经元。我们因此得到上述结果。

![](img/2c61816d4309191ad4300ac47909cd3c.png)

事实上，当我们放大时，我们可以看到我们的预测与原始数据相比表现如何。

![](img/d148fb55a51f3ea41c91567c6e77bf03.png)

我们可以看到，火车窗口大小为 20，这基本上意味着我们有 20 个时间片的数据。每个时间片对应一个月。

![](img/eb1b21447adb0f8efb83e0d5f242bf0d.png)

通过查看数据，我们意识到我们有 11 到 22 年的季节性。

因此，我们现在使用的时间片为 132，也等于 11 年(132 个月= 11 年)。

![](img/1634beed41b411166a198dbaf146b5e3.png)

但是我们注意到 MAE 实际上增加了。因此，增加窗口大小不起作用。

![](img/2163b8fd576c5518332929ed70df9419.png)

当我们分析我们的数据时，我们发现即使数据具有 11 年的季节性，噪声也使其表现为典型的时间序列数据。

![](img/529526f8fb04de930fb221ff1b209925.png)

因此，我们将“*窗口大小*更改为 30，并更加关注为训练和测试提供的数据量。为训练提供更多数据可以提高模型的效率。

![](img/55da122ec3b052475009a7bbc10edc54.png)

现在' *MAE'* 已经降到了 15.14。我们可以通过改变输入节点的数量来进一步做出改变。现在我们的输入数据已经增加到 30，我们可以有 30 个输入节点。然而，这导致我们的网络性能比以前更差，另一方面，调整'*学习率*'提高了模型的效率。

让我们意识到这样一个事实，尽管改变了:-

1.批量

2.神经元数量

3.窗口大小

4.训练数据大小

5.学习率

导致我们的模型发生了许多变化，有些促进了预测效率，有些则降低了预测效率，每一个变化都同样重要，需要进行试验以获得更好的结果。

这就把我们带到了记录课程的结尾。人们应该意识到机器学习可以用于对顺序和时间序列数据进行预测的多种方式。然而，我们在这里看到的只是表面现象，还有很多需要深入研究的。通过本文的学习，我们已经准备好迎接新的复杂的挑战。举一个…‘多元时间序列数据’。

我希望这能激励你真正开始学习这门课程，并尝试自己去实施。

感谢您阅读这篇博客。我希望听到你对此的想法。