<html>
<head>
<title>Text Feature Extraction With Scikit-Learn Pipeline</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">基于 Scikit-Learn 流水线的文本特征提取</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/the-triune-pipeline-for-three-major-transformers-in-nlp-18c14e20530?source=collection_archive---------15-----------------------#2019-12-13">https://towardsdatascience.com/the-triune-pipeline-for-three-major-transformers-in-nlp-18c14e20530?source=collection_archive---------15-----------------------#2019-12-13</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="0dec" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">使用 2020 年初选辩论记录</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/3aabb13249559774b4e08a1ecb6a88e9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*603D9vvsE8abqjzHqP46Rw.jpeg"/></div></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk">Image <a class="ae ky" href="https://www.looper.com/122484/best-worst-movies-blockbuster-franchises/" rel="noopener ugc nofollow" target="_blank">Source</a></figcaption></figure><h1 id="868a" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">这篇文章的目的是双重的。</h1><p id="cd3c" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated"><strong class="lt iu">首先</strong>，如我所承诺的，我将跟进之前的<a class="ae ky" rel="noopener" target="_blank" href="/which-presidential-candidate-talks-like-that-b2b16060ff8b?source=friends_link&amp;sk=521c1d6609bdfb96e41fa2439d5b18d1">帖子</a>，在那篇帖子中，我比较了 2020 年 21 位民主党初选总统候选人的演讲特性。我确定了一系列语言特征，这些特征将在描述层面上区分我们的总统候选人。</p><p id="bc00" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">在这篇文章中，我想使用这些特征来建立一个分类模型，可以预测谁将有资格参加 12 月 19 日的辩论。当然，我们现在知道谁有资格参加辩论，但我想这项任务背后的真正动机是更全面地了解一个人以某种方式说话(在辩论舞台上)对于作为总统候选人被认真对待(并被允许进入下一轮)有多重要。</p><p id="a6c1" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated"><strong class="lt iu">第二个</strong>(也是更重要的一个)<strong class="lt iu"> </strong>在构建这个模型的过程中，我想分享一些我最近在 scikit-learn 的世界中非常高兴地发现的事情:<code class="fe ms mt mu mv b">Pipeline</code>(我知道我已经迟到了。:)<strong class="lt iu">这个非常强大的类使我的整个 ML 工作流程——从预处理到评估——变得更加容易处理、更加健壮，并且更少受到猜测的影响</strong>，尤其是在超参数调优阶段。正如我的一位同事所说，它真的应该成为每一个基于 sklearn 的 ML 项目的一部分！下面是它的功能描述:</p><blockquote class="mw mx my"><p id="0e4e" class="lr ls mz lt b lu mn ju lw lx mo jx lz na mp mc md nb mq mg mh nc mr mk ml mm im bi translated">顺序应用一列<strong class="lt iu">变换</strong>和一个<strong class="lt iu">最终</strong> <strong class="lt iu">估计器</strong>。管道的中间步骤必须是“转换”，也就是说，它们必须实现 fit 和 transform 方法。最终的估计器只需要实现 fit。<em class="it"/><a class="ae ky" href="https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html" rel="noopener ugc nofollow" target="_blank"><em class="it">1</em></a><em class="it"/></p></blockquote><p id="0768" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">如果你想要更多的背景信息和深入描述性分析的结果，请参考我之前的文章，但是在这篇文章中，我将直接利用文章来构建所谓的三位一体管道🔱，其组件管道可以将原始文本转换为 NLP 任务的三个主要特征构建块:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nd"><img src="../Images/364ec0920ae3f9f55f6172dc386026cc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*uIbG5UaFrkFFmq18qcTfug.jpeg"/></div></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk">Three types of feature representation in NLP</figcaption></figure><p id="c3b4" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">根据您正在处理的特定任务或模型，维恩图中的一个或多个特征类型可能对您的模型的性能特别重要，例如，单词嵌入伴随着一些自定义语言特征的子集。要了解哪些重叠或不重叠的要素集是最重要的，我们需要设置一个训练流来测试每种要素类型的影响。这就是<code class="fe ms mt mu mv b">Pipeline</code>来拯救我们的地方。</p></div><div class="ab cl ne nf hx ng" role="separator"><span class="nh bw bk ni nj nk"/><span class="nh bw bk ni nj nk"/><span class="nh bw bk ni nj"/></div><div class="im in io ip iq"><h1 id="5268" class="kz la it bd lb lc nl le lf lg nm li lj jz nn ka ll kc no kd ln kf np kg lp lq bi translated">但首先要做的是。</h1><p id="58cb" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">使用前一篇<a class="ae ky" rel="noopener" target="_blank" href="/which-presidential-candidate-talks-like-that-b2b16060ff8b">文章</a>中准备好的数据帧，我们想为目标变量<code class="fe ms mt mu mv b">qualified</code>添加一列(1 或 0 表示是或否)，它表示谁有资格参加 12 月的辩论。八名候选人有资格参加辩论(包括退出的哈里斯):</p><pre class="kj kk kl km gt nq mv nr ns aw nt bi"><span id="14be" class="nu la it mv b gy nv nw l nx ny">import numpy as np<br/>import pandas as pd</span><span id="884a" class="nu la it mv b gy nz nw l nx ny"><strong class="mv iu">QUALIFIED_CANDIDATES</strong> = ["BIDEN", "WARREN", "SANDERS", "BUTTIGIEG", "HARRIS", "KLOBUCHAR", "STEYER", "YANG"]</span><span id="e8a2" class="nu la it mv b gy nz nw l nx ny">CANDIDATE_TO_TARGET = {}<br/>[CANDIDATE_TO_TARGET.update({c: 1}) if c in QUALIFIED_CANDIDATES else CANDIDATE_TO_TARGET.update({c: 0}) for c in ALL_CANDIDATE_NAMES]</span><span id="8371" class="nu la it mv b gy nz nw l nx ny"># add the target variable column <br/>qualified = df['speaker'].apply(lambda x: CANDIDATE_TO_TARGET[x] if x in CANDIDATE_TO_TARGET else np.NaN)<br/>df['qualified'] = qualified</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oa"><img src="../Images/7f3bd2a7d03d4e0245d9544a46801444.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*gzjeJxTjXjWb9Afk-hyWuQ.png"/></div></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk">A dataframe containing the features and target variable (not all features shown)</figcaption></figure><p id="c62e" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">然后，我们将数据集分为训练集和测试集:</p><pre class="kj kk kl km gt nq mv nr ns aw nt bi"><span id="e5da" class="nu la it mv b gy nv nw l nx ny">from sklearn.model_selection import train_test_split</span><span id="79aa" class="nu la it mv b gy nz nw l nx ny">train_df, test_df = train_test_split(df, test_size=0.1)</span><span id="11af" class="nu la it mv b gy nz nw l nx ny">train_data = train_df["segment"]<br/>train_target = train_df["qualified"]</span><span id="4071" class="nu la it mv b gy nz nw l nx ny">test_data = test_df["segment"]<br/>test_target = test_df["qualified"]</span></pre><p id="a351" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">现在我们准备好了有趣的部分！</p></div><div class="ab cl ne nf hx ng" role="separator"><span class="nh bw bk ni nj nk"/><span class="nh bw bk ni nj nk"/><span class="nh bw bk ni nj"/></div><div class="im in io ip iq"><h1 id="72ee" class="kz la it bd lb lc nl le lf lg nm li lj jz nn ka ll kc no kd ln kf np kg lp lq bi translated">设置三位一体管道。</h1><p id="f921" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated"><code class="fe ms mt mu mv b"><strong class="lt iu">Pipeline</strong></code> <strong class="lt iu">提供了一种方便直观的方式来构建我们的 ML 流程，其特征在于一系列可预测的核心任务</strong>，包括预处理、特征选择、标准化/规范化和分类。<code class="fe ms mt mu mv b">Pipeline</code>通过连续调用每个估算器上的<code class="fe ms mt mu mv b">fit</code>，将<code class="fe ms mt mu mv b">transform</code>应用到输入，并将转换后的输入传递到下一步，来自动化拟合/转换过程的多个实例。这意味着<code class="fe ms mt mu mv b">Pipeline</code>中的每个估计器(除了最后一个)都必须有一个<code class="fe ms mt mu mv b">transform</code>方法[ <a class="ae ky" href="https://scikit-learn.org/stable/modules/compose.html#notes" rel="noopener ugc nofollow" target="_blank"> 2 </a> ]，就像这个友好的 sklearn transformer <code class="fe ms mt mu mv b">TfidfVectorizer</code>:</p><pre class="kj kk kl km gt nq mv nr ns aw nt bi"><span id="faaa" class="nu la it mv b gy nv nw l nx ny">class TfidfVectorizer(CountVectorizer):<br/>    ...</span><span id="fd90" class="nu la it mv b gy nz nw l nx ny">    def fit(self, raw_documents, y=None):<br/>        <em class="mz"># Learn vocabulary and idf from training set.</em></span><span id="32f7" class="nu la it mv b gy nz nw l nx ny"><em class="mz">        </em>self._check_params()<br/>        X = super().fit_transform(raw_documents)<br/>        self._tfidf.fit(X)<br/>        return self    </span><span id="e428" class="nu la it mv b gy nz nw l nx ny">    def <strong class="mv iu">transform</strong>(self, raw_documents, copy=True):<br/>        <em class="mz"># Transform documents to document-term matrix.</em></span><span id="2016" class="nu la it mv b gy nz nw l nx ny"><em class="mz">        </em>check_is_fitted(self, '_tfidf', 'The tfidf vector is not fitted')<br/><br/>        X = super().transform(raw_documents)<br/>        return self._tfidf.transform(X, copy=False)</span></pre><p id="ed0b" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated"><code class="fe ms mt mu mv b">Pipeline</code>中的最后一个估计器不一定是转换器(即有一个<code class="fe ms mt mu mv b">transform</code>方法)，但可以是(通常是)一个分类器，像<code class="fe ms mt mu mv b">SVC</code>。这种结构将允许您在整个安装好的管道上调用<code class="fe ms mt mu mv b">predict</code>。</p></div><div class="ab cl ne nf hx ng" role="separator"><span class="nh bw bk ni nj nk"/><span class="nh bw bk ni nj nk"/><span class="nh bw bk ni nj"/></div><div class="im in io ip iq"><h2 id="1d5b" class="nu la it bd lb ob oc dn lf od oe dp lj ma of og ll me oh oi ln mi oj ok lp ol bi translated">管道 I:使用 tfidf 矢量器的单词包</h2><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi om"><img src="../Images/6b5e27980c2ebeff4a51aab2de9fc9b2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*LR51lPVUqpKSsRaCX1QWiA.jpeg"/></div></div></figure><p id="8dc6" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">以我们的辩论记录文本为例，我们创建了一个简单的<code class="fe ms mt mu mv b">Pipeline</code>对象，该对象(1)将输入数据转换为 TF-IDF 特征矩阵，以及(2)使用随机森林分类器对测试数据进行分类:</p><pre class="kj kk kl km gt nq mv nr ns aw nt bi"><span id="3162" class="nu la it mv b gy nv nw l nx ny"><strong class="mv iu">bow_pipeline</strong> = Pipeline(<br/>    steps=[<br/>        ("tfidf", TfidfVectorizer()),<br/>        ("classifier", RandomForestClassifier()),<br/>    ]<br/>)</span><span id="1e1c" class="nu la it mv b gy nz nw l nx ny">bow_pipeline.fit(train_data, train_target)<br/>y_pred = bow_pipeline.predict(test_data)<br/>cr = classification_report(test_target, y_pred)</span></pre><p id="f8f2" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">然后我们可以在整个管道上调用<code class="fe ms mt mu mv b">fit</code>,在测试数据上调用<code class="fe ms mt mu mv b">predict</code>。正如您所看到的，除了提供有序的估计量之外，没有什么别的了。当然，您可以通过在<code class="fe ms mt mu mv b">“classifier”</code>步骤之前添加一个规范化或标准化步骤来扩展管道。(您将在下一个管道中看到一个降维步骤的示例。)</p><p id="f1a7" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">在下面的分类报告中，<code class="fe ms mt mu mv b">0</code>代表“没有资格参加 12 月的辩论”，<code class="fe ms mt mu mv b">1</code>代表“有资格”。我们看到，仅使用辩论记录数据— <strong class="lt iu">而不了解候选人的其他信息</strong>(例如他们的投票状况、性别、受欢迎程度和政治经验水平)—我们能够以 70%的准确率预测谁将参加或不参加下一场辩论。他们在辩论舞台上说的话真的很重要，与他们如何说无关(第三条管道将在下面讨论)，也与他们是谁无关。</p><pre class="kj kk kl km gt nq mv nr ns aw nt bi"><span id="f1fb" class="nu la it mv b gy nv nw l nx ny"># tf-idf features only</span><span id="21d3" class="nu la it mv b gy nz nw l nx ny">              precision    recall  f1-score   support<br/><br/>           0       0.66      0.54      0.59       165<br/>           1       0.72      0.81      0.76       242<br/><br/>    accuracy                           <strong class="mv iu">0.70 </strong>      407<br/>   macro avg       0.69      0.67      0.68       407<br/>weighted avg       0.70      0.70      0.69       407</span></pre></div><div class="ab cl ne nf hx ng" role="separator"><span class="nh bw bk ni nj nk"/><span class="nh bw bk ni nj nk"/><span class="nh bw bk ni nj"/></div><div class="im in io ip iq"><h2 id="6e76" class="nu la it bd lb ob oc dn lf od oe dp lj ma of og ll me oh oi ln mi oj ok lp ol bi translated">管道 II:使用定制转换器的单词嵌入</h2><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi om"><img src="../Images/69250de520e798c5821319b5ace4fda6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*kuyuep7nvlpSBZG9CvqtIw.jpeg"/></div></div></figure><p id="af68" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">第二个管道需要创建一个<strong class="lt iu">自定义转换器</strong>，它基于单词嵌入将文本转换成数字向量。有几种方法可以做到这一点，包括从<a class="ae ky" href="https://nlp.stanford.edu/projects/glove/" rel="noopener ugc nofollow" target="_blank">这里</a>下载预先训练好的手套单词向量，并编写一个自定义函数来加载模型，如下所示:</p><pre class="kj kk kl km gt nq mv nr ns aw nt bi"><span id="8bf9" class="nu la it mv b gy nv nw l nx ny">path_to_word_vectors = "/Users/jlee/glove.6B.50d.txt"</span><span id="7292" class="nu la it mv b gy nz nw l nx ny">def load_glove(path_to_word_vectors):<br/>    f = open(path_to_word_vectors, "r")<br/>    word2vec = {}<br/>    for line in f:<br/>        split_line = line.split()<br/>        word = split_line[0]<br/>        embedding = np.array([float(val) for val in split_line[1:]])<br/>        model[word] = embedding<br/>    return word2vec</span><span id="9598" class="nu la it mv b gy nz nw l nx ny">word2vec = load_glove(path_to_word_vectors)</span></pre><p id="2670" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">或者，您可以使用 spaCy 的内置单词向量模型，可以通过下面的<code class="fe ms mt mu mv b">.vector</code>属性访问。下面我加载了<code class="fe ms mt mu mv b">"en_core_web_md"</code>模型，它提供了 685k 个键和 20k 个唯一向量(300 维)。这个模型被存储为<code class="fe ms mt mu mv b">SpacyVectorTransformer</code>的一个属性，这是一个返回向量平均值的定制转换器。</p><pre class="kj kk kl km gt nq mv nr ns aw nt bi"><span id="898a" class="nu la it mv b gy nv nw l nx ny">import spacy <br/>from sklearn.base import BaseEstimator, TransformerMixin</span><span id="5956" class="nu la it mv b gy nz nw l nx ny">nlp = spacy.load("en_core_web_md")  # this model will give you 300D</span><span id="8285" class="nu la it mv b gy nz nw l nx ny">class <strong class="mv iu">SpacyVectorTransformer</strong>(BaseEstimator, TransformerMixin):<br/>    def __init__(self, nlp):<br/>        self.nlp = nlp<br/>        self.dim = 300<br/><br/>    def fit(self, X, y):<br/>        return self<br/><br/>    def transform(self, X):<br/>        # Doc.vector defaults to an <strong class="mv iu">average</strong> of the token vectors.<br/>        # https://spacy.io/api/doc#vector<br/>        return [self.nlp(text).vector for text in X]</span></pre><p id="b6ec" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">一旦我们得到 300 维的平均嵌入，我们可以选择使用<code class="fe ms mt mu mv b">TrancatedSVD</code>来降低这些特征的维数。</p><pre class="kj kk kl km gt nq mv nr ns aw nt bi"><span id="e757" class="nu la it mv b gy nv nw l nx ny"><strong class="mv iu">embeddings_pipeline</strong> = Pipeline(<br/>    steps=[<br/>        ("mean_embeddings", SpacyVectorTransformer(nlp)),<br/>        ("reduce_dim", TruncatedSVD(50)),<br/>        ("classifier", RandomForestClassifier()),<br/>    ]<br/>)</span><span id="8465" class="nu la it mv b gy nz nw l nx ny">embeddings_pipeline.fit(train_data, train_target)<br/>y_pred = embeddings_pipeline.predict(test_data)<br/>cr = classification_report(test_target, y_pred)</span></pre><p id="cf97" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">结果是:</p><pre class="kj kk kl km gt nq mv nr ns aw nt bi"><span id="4ffa" class="nu la it mv b gy nv nw l nx ny"># embeddings only </span><span id="7704" class="nu la it mv b gy nz nw l nx ny">              precision    recall  f1-score   support<br/><br/>           0       0.56      0.61      0.58       165<br/>           1       0.72      0.67      0.69       242<br/><br/>    accuracy                           <strong class="mv iu">0.65 </strong>      407<br/>   macro avg       0.64      0.64      0.64       407<br/>weighted avg       0.65      0.65      0.65       407</span></pre><p id="556f" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">我们看到结果不如更简单的 TF-IDF 模型的结果好。</p></div><div class="ab cl ne nf hx ng" role="separator"><span class="nh bw bk ni nj nk"/><span class="nh bw bk ni nj nk"/><span class="nh bw bk ni nj"/></div><div class="im in io ip iq"><h2 id="f9f2" class="nu la it bd lb ob oc dn lf od oe dp lj ma of og ll me oh oi ln mi oj ok lp ol bi translated">管道三:定制语言功能管道</h2><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi om"><img src="../Images/3449350b24d2747a08414d7693790d5c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*u9CNBZQ2msUTuOtZPv1JQw.jpeg"/></div></div></figure><p id="7173" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">所谓“自定义语言特征”，我指的是那种你可以通过对你的数据应用一些规则来手动提取的特征。在这个例子中，我使用空间依赖解析器提取特性<code class="fe ms mt mu mv b">number of words before the main verb</code>:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="on oo l"/></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk">An example of a custom rule-extracted linguistic feature</figcaption></figure><p id="5aba" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">更多基于规则的定制语言特性的例子可以在以下两篇文章中找到:</p><div class="op oq gp gr or os"><a rel="noopener follow" target="_blank" href="/linguistic-rule-writing-for-nlp-ml-64d9af824ee8"><div class="ot ab fo"><div class="ou ab ov cl cj ow"><h2 class="bd iu gy z fp ox fr fs oy fu fw is bi translated">为自然语言处理编写语言规则</h2><div class="oz l"><h3 class="bd b gy z fp ox fr fs oy fu fw dk translated">用 spaCy 提取问题类型的指南</h3></div><div class="pa l"><p class="bd b dl z fp ox fr fs oy fu fw dk translated">towardsdatascience.com</p></div></div><div class="pb l"><div class="pc l pd pe pf pb pg ks os"/></div></div></a></div><div class="op oq gp gr or os"><a rel="noopener follow" target="_blank" href="/which-presidential-candidate-talks-like-that-b2b16060ff8b"><div class="ot ab fo"><div class="ou ab ov cl cj ow"><h2 class="bd iu gy z fp ox fr fs oy fu fw is bi translated">超越演讲时间:民主党总统辩论分析</h2><div class="oz l"><h3 class="bd b gy z fp ox fr fs oy fu fw dk translated">使用真实世界数据进行预测建模的数据准备和特征工程</h3></div><div class="pa l"><p class="bd b dl z fp ox fr fs oy fu fw dk translated">towardsdatascience.com</p></div></div><div class="pb l"><div class="ph l pd pe pf pb pg ks os"/></div></div></a></div><p id="7a23" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">第三个管道需要一个定制的转换器，就像上一个一样；<code class="fe ms mt mu mv b">CustomLinguisticFeatureTransformer</code>采用一个<code class="fe ms mt mu mv b">fit</code>方法(它返回自身)和一个<code class="fe ms mt mu mv b">transform</code>方法。后者返回<code class="fe ms mt mu mv b">featurize</code>的输出，这是我创建的另一个名为<code class="fe ms mt mu mv b">SegmentFeaturizer</code>的类的方法。</p><pre class="kj kk kl km gt nq mv nr ns aw nt bi"><span id="f255" class="nu la it mv b gy nv nw l nx ny">segment_featurizer = SegmentFeaturizer()  # more on this below</span><span id="5c8f" class="nu la it mv b gy nz nw l nx ny">class <!-- -->CustomLinguisticFeatureTransformer<!-- -->(BaseEstimator, TransformerMixin):<br/>    def __init__(self):<br/>        pass</span><span id="9d72" class="nu la it mv b gy nz nw l nx ny">    def fit(self, x, y=None):<br/>        return self</span><span id="7a1f" class="nu la it mv b gy nz nw l nx ny">    def transform(self, data):<br/>        return <strong class="mv iu">segment_featurizer.featurize</strong>(data)</span></pre><p id="48bf" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated"><code class="fe ms mt mu mv b">SegmentFeaturizer</code>定义用于提取一组语言特征的方法。下面是它的基本结构，其中一些特征提取函数后面是返回特征字典列表的主<code class="fe ms mt mu mv b">featurize</code>函数:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="on oo l"/></div></figure><p id="ef7a" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">(要了解更多关于<code class="fe ms mt mu mv b">featurize</code>的信息，请看这篇<a class="ae ky" rel="noopener" target="_blank" href="/how-to-build-a-reusable-nlp-code-pipeline-with-scikit-learn-with-an-emphasis-on-feature-504f8aa14699?source=friends_link&amp;sk=135abfa127e7094b1a17963b254ab678">帖子</a>。)然后，<code class="fe ms mt mu mv b">transform</code>的输出作为流水线的下一个部件，即<code class="fe ms mt mu mv b">DictVectorizer</code>的输入。完整的管道如下:</p><pre class="kj kk kl km gt nq mv nr ns aw nt bi"><span id="84c6" class="nu la it mv b gy nv nw l nx ny">manual_pipeline = Pipeline(<br/>    steps=[<br/>        ("stats", <!-- -->CustomLinguisticFeatureTransformer<!-- -->()),<br/>        ("dict_vect", DictVectorizer()),<br/>        ("classifier", RandomForestClassifier()),<br/>    ]<br/>)</span><span id="9740" class="nu la it mv b gy nz nw l nx ny">manual_pipeline.fit(train_data, train_target)<br/>y_pred = manual_pipeline.predict(test_data)<br/>cr = classification_report(test_target, y_pred)</span></pre><p id="4c27" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">结果:</p><pre class="kj kk kl km gt nq mv nr ns aw nt bi"><span id="a34c" class="nu la it mv b gy nv nw l nx ny"># manual linguistic features only</span><span id="416d" class="nu la it mv b gy nz nw l nx ny">              precision    recall  f1-score   support<br/><br/>           0       0.62      0.56      0.59       165<br/>           1       0.72      0.77      0.74       242<br/><br/>    accuracy                           <strong class="mv iu">0.68</strong>       407<br/>   macro avg       0.67      0.66      0.67       407<br/>weighted avg       0.68      0.68      0.68       407</span></pre><p id="23ad" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">不如词袋模型好，但比平均嵌入要好。下面是三个管道指标的对比汇总表:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pi"><img src="../Images/f4a937a5cbfb6acb40733e8fd8e29909.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*wPuQ3d5Wb-AmO9yfjEbrMw.png"/></div></div></figure><p id="1960" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">(显示了<a class="ae ky" href="https://scikit-learn.org/stable/modules/model_evaluation.html#from-binary-to-multiclass-and-multilabel" rel="noopener ugc nofollow" target="_blank">宏</a>的精确度、召回率和 f 分数的平均值。)</p></div><div class="ab cl ne nf hx ng" role="separator"><span class="nh bw bk ni nj nk"/><span class="nh bw bk ni nj nk"/><span class="nh bw bk ni nj"/></div><div class="im in io ip iq"><h1 id="846a" class="kz la it bd lb lc nl le lf lg nm li lj jz nn ka ll kc no kd ln kf np kg lp lq bi translated">在一起更好。</h1><p id="a1b3" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">已经看到单词袋管道和自定义语言特征管道独立地产生最佳结果，我想知道如果我们创建一个结合两者特征的新管道会有什么效果。幸运的是，有一个简单的方法可以做到这一点！</p><h2 id="3c0e" class="nu la it bd lb ob oc dn lf od oe dp lj ma of og ll me oh oi ln mi oj ok lp ol bi translated">管道四:组合功能</h2><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi om"><img src="../Images/2dd27f55ded849d6cdb8e56fbe4b36da.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*fPOH7W8nInFhjnVC5y7WQg.jpeg"/></div></div></figure><p id="fb90" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">组合特征集由<code class="fe ms mt mu mv b"><strong class="lt iu">FeatureUnion</strong></code>完成:</p><blockquote class="mw mx my"><p id="fea0" class="lr ls mz lt b lu mn ju lw lx mo jx lz na mp mc md nb mq mg mh nc mr mk ml mm im bi translated"><a class="ae ky" href="https://scikit-learn.org/0.16/modules/generated/sklearn.pipeline.FeatureUnion.html#sklearn.pipeline.FeatureUnion" rel="noopener ugc nofollow" target="_blank"> FeatureUnion </a>将几个 transformer 对象组合成一个新的 transformer，该 transformer 将它们的输出进行组合。FeatureUnion 接受一个 transformer 对象列表。在拟合期间，<strong class="lt iu">每一个都独立地拟合到数据</strong>。为了转换数据，转换器被并行应用<strong class="lt iu"/>，并且它们输出的样本向量被<strong class="lt iu">首尾相连</strong>成更大的向量。</p></blockquote><p id="b080" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">下面，<code class="fe ms mt mu mv b">"classifier"</code>步骤已经从每个管道中删除，因为该步骤需要在我们应用了<code class="fe ms mt mu mv b">FeatureUnion</code>之后出现。</p><pre class="kj kk kl km gt nq mv nr ns aw nt bi"><span id="2dd6" class="nu la it mv b gy nv nw l nx ny"># individual pipelines minus the estimator step: </span><span id="d6c4" class="nu la it mv b gy nz nw l nx ny"><strong class="mv iu">bow_pipeline</strong> = Pipeline(<br/>    steps=[<br/>        ("tfidf", TfidfVectorizer()),<br/>    ]<br/>)</span><span id="0dcd" class="nu la it mv b gy nz nw l nx ny"><strong class="mv iu">manual_pipeline</strong> = Pipeline(<br/>    steps=[<br/>        ("stats", ManualTransformer()),<br/>        ("dict_vect", DictVectorizer()),<br/>    ]<br/>)</span></pre><p id="57ea" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">最终管道由通过<code class="fe ms mt mu mv b">FeatureUnion</code>和最终分类器连接的组合特征组成:</p><pre class="kj kk kl km gt nq mv nr ns aw nt bi"><span id="1527" class="nu la it mv b gy nv nw l nx ny">combined_features = FeatureUnion(<br/>    transformer_list=[<br/>        ("bow", bow_pipeline),<br/>        ("manual", manual_pipeline),<br/>    ]<br/>)</span><span id="6acc" class="nu la it mv b gy nz nw l nx ny"><strong class="mv iu">final_pipeline</strong> = Pipeline(<br/>    steps=[<br/>        ("combined_features", combined_features),<br/>        ("classifier", RandomForestClassifier()),<br/>    ]<br/>)</span></pre><p id="baed" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">此时，我们可以拟合<code class="fe ms mt mu mv b">final_pipeine</code>并计算指标，但是为了更好地测量，我将对拟合的随机森林分类器的参数执行随机搜索。(您也可以运行网格搜索，但这需要更长时间。)</p><pre class="kj kk kl km gt nq mv nr ns aw nt bi"><span id="ea27" class="nu la it mv b gy nv nw l nx ny">from sklearn.model_selection import RandomizedSearchCV</span><span id="51bd" class="nu la it mv b gy nz nw l nx ny"># the keys can be accessed with <strong class="mv iu">final_pipeline.get_params().keys()</strong><br/>params = {<br/>    "combined_features__bow__tfidf__use_idf": [True, False],<br/>    "combined_features__bow__tfidf__ngram_range": [(1, 1), (1, 2)],<br/>    "classifier__bootstrap": [True, False],<br/>    "classifier__class_weight": ["balanced", None],<br/>    "classifier__n_estimators": [100, 300, 500, 800, 1200],<br/>    "classifier__max_depth": [5, 8, 15, 25, 30],<br/>    "classifier__min_samples_split": [2, 5, 10, 15, 100],<br/>    "classifier__min_samples_leaf": [1, 2, 5, 10]<br/>}</span><span id="1167" class="nu la it mv b gy nz nw l nx ny">search = RandomizedSearchCV(final_pipeline, params)<br/>search.fit(train_data, train_target)<br/>y_pred = search.predict(test_data)<br/>classification_report(test_target, y_pred)</span></pre><p id="c53b" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">酷！结果<em class="mz">比</em>更好，具有特征统一和网格搜索支持的参数优化！</p><pre class="kj kk kl km gt nq mv nr ns aw nt bi"><span id="acb4" class="nu la it mv b gy nv nw l nx ny"># combined features + randomized search </span><span id="43eb" class="nu la it mv b gy nz nw l nx ny">              precision    recall  f1-score   support<br/><br/>           0       0.70      0.55      0.61       165<br/>           1       0.73      0.84      0.78       242<br/><br/>    accuracy                           <strong class="mv iu">0.72</strong>       407<br/>   macro avg       0.72      0.69      0.70       407<br/>weighted avg       0.72      0.72      0.71       407</span></pre><p id="08a6" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">在每项指标上，混合渠道的得分都高于表现最佳的单个渠道:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pj"><img src="../Images/025beb1ef3dc97c7d6778108b09dafc3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*HNCvGiMYoFSJf67iin5yQw.png"/></div></div></figure><p id="d4a8" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">作为正确的下一步，您可以尝试组合所有三个特性集，看看会发生什么，从而创建一个真正的“triune”(三合一)管道。🔱</p><h1 id="d754" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">结束了。</h1><p id="3fb3" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">在这篇文章中，我演示了如何建立三位一体管道来预测总统候选人有资格参加下一场辩论的可能性。他们是:</p><ol class=""><li id="2bd8" class="pk pl it lt b lu mn lx mo ma pm me pn mi po mm pp pq pr ps bi translated">使用标准<strong class="lt iu">字袋</strong>模型的管道</li><li id="1f62" class="pk pl it lt b lu pt lx pu ma pv me pw mi px mm pp pq pr ps bi translated">使用<strong class="lt iu">字嵌入的管道</strong></li><li id="f84d" class="pk pl it lt b lu pt lx pu ma pv me pw mi px mm pp pq pr ps bi translated">一条管道使用<strong class="lt iu">手动(自定义)功能</strong></li></ol><p id="daa2" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">每个组件管道包括一个转换器，它输出 NLP 中的主要特征类型/表示。我还展示了我们可以组合来自不同管道的不同特性集来获得更好的结果，尤其是与<code class="fe ms mt mu mv b">RandomizedSearchCV</code>结合使用时。我认为另一个很好的收获是结合 ML 驱动和基于规则的方法来提升模型性能的价值。</p><p id="d52a" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">我确实发现，候选人的演讲特性<em class="mz">本身——不受任何其他人口统计特征或候选人政治成就信息的影响</em>——<em class="mz"/>能够相当准确地预测某人是否有资格参加下一场辩论，这是预测我们下一任总统的众多预测因素之一。</p></div><div class="ab cl ne nf hx ng" role="separator"><span class="nh bw bk ni nj nk"/><span class="nh bw bk ni nj nk"/><span class="nh bw bk ni nj"/></div><div class="im in io ip iq"><p id="b453" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">如果你想要不那么罗嗦的东西:</p><div class="op oq gp gr or os"><a href="https://medium.com/swlh/randomized-or-grid-search-with-pipeline-cheatsheet-719c72eda68" rel="noopener follow" target="_blank"><div class="ot ab fo"><div class="ou ab ov cl cj ow"><h2 class="bd iu gy z fp ox fr fs oy fu fw is bi translated">管道随机(或网格)搜索超级快速指南</h2><div class="oz l"><h3 class="bd b gy z fp ox fr fs oy fu fw dk translated">使用 scikit 的五个步骤-学习</h3></div><div class="pa l"><p class="bd b dl z fp ox fr fs oy fu fw dk translated">medium.com</p></div></div><div class="pb l"><div class="py l pd pe pf pb pg ks os"/></div></div></a></div></div></div>    
</body>
</html>