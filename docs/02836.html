<html>
<head>
<title>Optimize your CPU for Deep Learning</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">为深度学习优化您的 CPU</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/optimize-your-cpu-for-deep-learning-424a199d7a87?source=collection_archive---------3-----------------------#2019-05-08">https://towardsdatascience.com/optimize-your-cpu-for-deep-learning-424a199d7a87?source=collection_archive---------3-----------------------#2019-05-08</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><p id="0954" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">在过去的几年里，深度学习已经在学术界和工业界加快了步伐。每个公司现在都在寻找基于人工智能的问题解决方案。这种繁荣有其自身的优点和缺点，但这是另一篇文章，另一天。机器学习从业者的激增已经渗透到了学术界的根部，几乎每个领域的每个学生都可以通过课程、MOOCs、书籍、文章和课程论文获得人工智能和人工智能知识。</p><p id="8352" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">然而，这种增长受到硬件资源可用性的限制。有人建议，并证明了图形处理器是最好的设备之一，你可以有执行你的 ML 任务的速度。但是，一个好的高性能 GPU 的价格标签甚至可以高达 20，449.00 美元一个<a class="ae ko" href="https://www.dell.com/en-us/work/shop/dell-nvidia-tesla-v100-32gb-passive-gpu/apd/490-beob/graphic-video-cards" rel="noopener ugc nofollow" target="_blank">英伟达特斯拉 V100 32GB GPU </a>，它具有类似服务器的计算能力。此外，一台配有像样 GPU 的消费笔记本电脑价格约为<strong class="js iu">2000 美元</strong>，GPU 为 1050Ti 或 1080Ti。为了减轻痛苦，谷歌、Kaggle、英特尔和英伟达免费提供基于云的高计算系统，对空间、计算能力、内存或时间都有限制。但是这些在线服务有其缺点，包括管理数据(上传/下载)、数据隐私等。这些问题引出了我的文章的主要观点，“为什么不优化我们的 CPU，以提高深度学习任务的速度？”。</p><p id="c24e" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">英特尔已经为 Python、Tensorflow、Pytorch 等提供了优化。拥有一整套英特尔优化支持库，如 NumPy、scikit-learn 等。这些都可以免费下载和设置，并在英特尔酷睿 i7 这样的 CPU 上提供 2 倍甚至 5 倍的速度，而英特尔酷睿 i7 也不是至强系列这样的高性能 CPU。在本文的剩余部分，我将演示如何在您的 PC/笔记本电脑中设置英特尔优化，并将提供我观察到的加速数据。</p><h1 id="4f86" class="kp kq it bd kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm bi translated">获得性能提升</h1><p id="e616" class="pw-post-body-paragraph jq jr it js b jt ln jv jw jx lo jz ka kb lp kd ke kf lq kh ki kj lr kl km kn im bi translated">对于下面提到的各种实验，我将展示我观察到的时间和利用率提升。</p><ol class=""><li id="edda" class="ls lt it js b jt ju jx jy kb lu kf lv kj lw kn lx ly lz ma bi translated">用于 CIFAR-100 图像分类的 10 层深度 CNN。</li><li id="0b59" class="ls lt it js b jt mb jx mc kb md kf me kj mf kn lx ly lz ma bi translated">用于 IMDB 情感分析的 3 层深度 LSTM。</li><li id="5d80" class="ls lt it js b jt mb jx mc kb md kf me kj mf kn lx ly lz ma bi translated">6 层深密 ANN 用于 MNIST 影像分类。</li><li id="9615" class="ls lt it js b jt mb jx mc kb md kf me kj mf kn lx ly lz ma bi translated">用于 MNIST 的 9 层深度全卷积自动编码器。</li></ol><p id="9d7c" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">这些任务已使用 tensorflow 后端在 Keras 中编码，数据集与代码和可执行库位于同一硬盘中。使用的硬盘是 SSD。</p><p id="f6a8" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">我们将考虑以下六种优化组合。</p><ol class=""><li id="161e" class="ls lt it js b jt ju jx jy kb lu kf lv kj lw kn lx ly lz ma bi translated">英特尔酷睿 i7 处理器。</li><li id="3a3e" class="ls lt it js b jt mb jx mc kb md kf me kj mf kn lx ly lz ma bi translated">英特尔至强处理器 E3–1535m V6。</li><li id="6802" class="ls lt it js b jt mb jx mc kb md kf me kj mf kn lx ly lz ma bi translated">英特尔酷睿 i7 和英特尔 Python(英特尔 i7*)。</li><li id="9b08" class="ls lt it js b jt mb jx mc kb md kf me kj mf kn lx ly lz ma bi translated">英特尔至强处理器 E3–1535m V6，采用英特尔 Python(英特尔至强*)。</li><li id="6e91" class="ls lt it js b jt mb jx mc kb md kf me kj mf kn lx ly lz ma bi translated">采用英特尔 Python 和处理器线程优化的英特尔酷睿 i7(英特尔 i7(O))。</li><li id="863a" class="ls lt it js b jt mb jx mc kb md kf me kj mf kn lx ly lz ma bi translated">英特尔至强处理器 E3–1535m V6，采用英特尔 Python 和处理器线程优化(英特尔至强处理器)。</li></ol><p id="47a9" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">对于每项任务，历元数固定为 50。在下面的图表中，我们可以看到，对于一个<strong class="js iu">英特尔(R)酷睿(TM)i7–7700 HQ CPU @ 2.80 GHz CPU</strong>，每个时期的平均时间接近 4.67 秒，经过适当的优化后，它下降到 1.48 秒，提升了 3.2 倍。对于一个英特尔至强处理器 E3–1535m V6 @ 3.10 GHz CPU，每个周期的平均时间接近 2.21 秒，经过适当优化后下降到 0.64 秒，提升了 3.45 倍。</p><figure class="mh mi mj mk gt ml gh gi paragraph-image"><div class="gh gi mg"><img src="../Images/96b506dd3dc6d7067609e31e8994c316.png" data-original-src="https://miro.medium.com/v2/resize:fit:962/format:webp/1*vZpSy5ICkrEcdmtqlZWjyg.png"/></div><figcaption class="mo mp gj gh gi mq mr bd b be z dk">Average time per epoch</figcaption></figure><p id="5f94" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">优化不仅是及时的，优化的分布还优化了 CPU 利用率，最终导致更好的热量管理，并且您的笔记本电脑不会像过去那样受热，而训练深度神经网络。</p><figure class="mh mi mj mk gt ml gh gi paragraph-image"><div class="gh gi ms"><img src="../Images/c658a4bdad742255b6248a75a47978ce.png" data-original-src="https://miro.medium.com/v2/resize:fit:960/format:webp/1*_AKlnXHUAqk9oil6U11Rjg.png"/></div><figcaption class="mo mp gj gh gi mq mr bd b be z dk">Utilization</figcaption></figure><p id="a3bd" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">我们可以看到，在没有任何优化的情况下，训练时的 CPU 利用率达到了 100%，降低了所有其他进程的速度，并使系统发热。然而，通过适当的优化，i7 的利用率下降到 70%,至强的利用率下降到 65%,尽管在时间方面提供了性能增益。</p><p id="4214" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">这两个指标可以相对概括如下。</p><figure class="mh mi mj mk gt ml gh gi paragraph-image"><div class="gh gi mg"><img src="../Images/769573c84b8e9c0b49b0f5ff5c1c3b1a.png" data-original-src="https://miro.medium.com/v2/resize:fit:962/format:webp/1*hPOhOAOc0Jry1V94L03QZg.png"/></div></figure><p id="870a" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">在上图中，<strong class="js iu">值越低越好</strong>，也就是说，相对而言，经过所有优化的英特尔至强处理器是性能指标评测的基准，在优化使用后，英特尔酷睿 i7 处理器每周期的时间几乎是至强处理器的两倍。上图清楚地显示了英特尔 Python 优化在训练神经网络所用时间和 CPU 使用方面的光明面。</p><h1 id="1121" class="kp kq it bd kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm bi translated">设置英特尔的 Python 发行版</h1><figure class="mh mi mj mk gt ml gh gi paragraph-image"><div role="button" tabindex="0" class="mu mv di mw bf mx"><div class="gh gi mt"><img src="../Images/4e47f03844cbc13b2469524264462081.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*d35H7vAXadSeckkMw4WF0Q.png"/></div></div></figure><p id="2ce8" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">英特尔软件提供了关于如何设置的详尽资源列表，但我们可能会经常遇到一些问题。更多关于发行的细节可以在<a class="ae ko" href="https://software.intel.com/en-us/distribution-for-python" rel="noopener ugc nofollow" target="_blank">这里</a>找到。您可以选择安装类型，即本机 pip 或 conda。我更喜欢 conda，因为它为我节省了大量的麻烦，我可以专注于 ML 而不是解决我的库的兼容性问题。</p><h2 id="e936" class="my kq it bd kr mz na dn kv nb nc dp kz kb nd ne ld kf nf ng lh kj nh ni ll nj bi translated">1)下载并安装 Anaconda</h2><p id="22b5" class="pw-post-body-paragraph jq jr it js b jt ln jv jw jx lo jz ka kb lp kd ke kf lq kh ki kj lr kl km kn im bi translated">你可以从<a class="ae ko" href="https://www.anaconda.com/distribution/" rel="noopener ugc nofollow" target="_blank">这里</a>下载 Anaconda。他们的网站列出了在 windows、ubuntu 和 macOS 环境下安装 Anaconda 的所有步骤，并且很容易掌握。</p><h2 id="fa48" class="my kq it bd kr mz na dn kv nb nc dp kz kb nd ne ld kf nf ng lh kj nh ni ll nj bi translated">2)在您的 Anaconda 发行版中设置英特尔 python</h2><p id="7927" class="pw-post-body-paragraph jq jr it js b jt ln jv jw jx lo jz ka kb lp kd ke kf lq kh ki kj lr kl km kn im bi translated">这一步通常会变得棘手。最好为英特尔分发创建一个虚拟环境，这样您就可以随时在一个地方添加/更改您的优化库。让我们创建一个名为“<strong class="js iu"> <em class="nk"> intel”的新虚拟环境</em>T13】</strong></p><pre class="mh mi mj mk gt nl nm nn no aw np bi"><span id="2f12" class="my kq it nm b gy nq nr l ns nt">conda create -n intel -c intel <a class="ae ko" href="https://anaconda.org/intel/intelpython3_full" rel="noopener ugc nofollow" target="_blank">intelpython3_ful</a>l</span></pre><p id="95c4" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">这里<strong class="js iu"> <em class="nk"> -c </em> </strong>代表通道，所以我们不把 Intel 加为通道，而是把那个通道称为 via <strong class="js iu"> <em class="nk"> -c </em> </strong>。在这里，intelpython3_full 将自动从英特尔的发行版中获取必要的库，并将它们安装到您的虚拟环境中。此命令将安装下列库。</p><pre class="mh mi mj mk gt nl nm nn no aw np bi"><span id="64e1" class="my kq it nm b gy nq nr l ns nt">The following NEW packages will be INSTALLED:</span><span id="479e" class="my kq it nm b gy nu nr l ns nt">asn1crypto         intel/win-64::asn1crypto-0.24.0-py36_3<br/>bzip2              intel/win-64::bzip2-1.0.6-vc14_17<br/>certifi            intel/win-64::certifi-2018.1.18-py36_2<br/>cffi               intel/win-64::cffi-1.11.5-py36_3<br/>chardet            intel/win-64::chardet-3.0.4-py36_3<br/>cryptography       intel/win-64::cryptography-2.3-py36_1<br/>cycler             intel/win-64::cycler-0.10.0-py36_7<br/>cython             intel/win-64::cython-0.29.3-py36_1<br/>daal               intel/win-64::daal-2019.3-intel_203<br/>daal4py            intel/win-64::daal4py-2019.3-py36h7b7c402_6<br/>freetype           intel/win-64::freetype-2.9-vc14_3<br/>funcsigs           intel/win-64::funcsigs-1.0.2-py36_7<br/>icc_rt             intel/win-64::icc_rt-2019.3-intel_203<br/>idna               intel/win-64::idna-2.6-py36_3<br/>impi_rt            intel/win-64::impi_rt-2019.3-intel_203<br/>intel-openmp       intel/win-64::intel-openmp-2019.3-intel_203<br/>intelpython        intel/win-64::intelpython-2019.3-0<br/>intelpython3_core  intel/win-64::intelpython3_core-2019.3-0<br/>intelpython3_full  intel/win-64::intelpython3_full-2019.3-0<br/>kiwisolver         intel/win-64::kiwisolver-1.0.1-py36_2<br/>libpng             intel/win-64::libpng-1.6.36-vc14_2<br/>llvmlite           intel/win-64::llvmlite-0.27.1-py36_0<br/>matplotlib         intel/win-64::matplotlib-3.0.1-py36_1<br/>menuinst           intel/win-64::menuinst-1.4.1-py36_6<br/>mkl                intel/win-64::mkl-2019.3-intel_203<br/>mkl-service        intel/win-64::mkl-service-1.0.0-py36_7<br/>mkl_fft            intel/win-64::mkl_fft-1.0.11-py36h7b7c402_0<br/>mkl_random         intel/win-64::mkl_random-1.0.2-py36h7b7c402_4<br/>mpi4py             intel/win-64::mpi4py-3.0.0-py36_3<br/>numba              intel/win-64::numba-0.42.1-np116py36_0<br/>numexpr            intel/win-64::numexpr-2.6.8-py36_2<br/>numpy              intel/win-64::numpy-1.16.1-py36h7b7c402_3<br/>numpy-base         intel/win-64::numpy-base-1.16.1-py36_3<br/>openssl            intel/win-64::openssl-1.0.2r-vc14_0<br/>pandas             intel/win-64::pandas-0.24.1-py36_3<br/>pip                intel/win-64::pip-10.0.1-py36_0<br/>pycosat            intel/win-64::pycosat-0.6.3-py36_3<br/>pycparser          intel/win-64::pycparser-2.18-py36_2<br/>pyopenssl          intel/win-64::pyopenssl-17.5.0-py36_2<br/>pyparsing          intel/win-64::pyparsing-2.2.0-py36_2<br/>pysocks            intel/win-64::pysocks-1.6.7-py36_1<br/>python             intel/win-64::python-3.6.8-6<br/>python-dateutil    intel/win-64::python-dateutil-2.6.0-py36_12<br/>pytz               intel/win-64::pytz-2018.4-py36_3<br/>pyyaml             intel/win-64::pyyaml-4.1-py36_3<br/>requests           intel/win-64::requests-2.20.1-py36_1<br/>ruamel_yaml        intel/win-64::ruamel_yaml-0.11.14-py36_4<br/>scikit-learn       intel/win-64::scikit-learn-0.20.2-py36h7b7c402_2<br/>scipy              intel/win-64::scipy-1.2.0-py36_3<br/>setuptools         intel/win-64::setuptools-39.0.1-py36_0<br/>six                intel/win-64::six-1.11.0-py36_3<br/>sqlite             intel/win-64::sqlite-3.27.2-vc14_2<br/>tbb                intel/win-64::tbb-2019.4-vc14_intel_203<br/>tbb4py             intel/win-64::tbb4py-2019.4-py36_intel_0<br/>tcl                intel/win-64::tcl-8.6.4-vc14_22<br/>tk                 intel/win-64::tk-8.6.4-vc14_28<br/>urllib3            intel/win-64::urllib3-1.24.1-py36_2<br/>vc                 intel/win-64::vc-14.0-2<br/>vs2015_runtime     intel/win-64::vs2015_runtime-14.0.25420-intel_2<br/>wheel              intel/win-64::wheel-0.31.0-py36_3<br/>win_inet_pton      intel/win-64::win_inet_pton-1.0.1-py36_4<br/>wincertstore       intel/win-64::wincertstore-0.2-py36_3<br/>xz                 intel/win-64::xz-5.2.3-vc14_2<br/>zlib               intel/win-64::zlib-1.2.11-vc14h21ff451_5</span></pre><p id="daa4" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">您可以看到，对于每个库，轮盘的描述以“<strong class="js iu"><em class="nk">【Intel/…”</em></strong>开头，这表示该库正在从英特尔的分销渠道下载。一旦您同意安装这些库，它们将开始被下载和安装。</p><p id="135a" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">这一步是第一个问题的来源。有时，这些库没有被下载，列表传播，或者我们得到一个 SSL 错误，命令退出。这个问题甚至可能会被延迟，也就是说，现在所有的东西都会被下载和安装，但是稍后如果你想添加任何新的库，提示会抛出 SSL 错误。如上所述，在为英特尔创建虚拟环境之前，有一个简单的方法可以解决这个问题。</p><p id="ab9c" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">在您的 shell 或命令提示符下，通过以下命令关闭 anaconda 的默认 SSL 验证</p><pre class="mh mi mj mk gt nl nm nn no aw np bi"><span id="cf40" class="my kq it nm b gy nq nr l ns nt">conda config --set ssl_verify false</span></pre><p id="d7cb" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">关闭 SLL 验证后，您可以通过删除之前创建的环境并重新启动来重复步骤 2。</p><h2 id="ac0d" class="my kq it bd kr mz na dn kv nb nc dp kz kb nd ne ld kf nf ng lh kj nh ni ll nj bi translated">3)建立张量流</h2><figure class="mh mi mj mk gt ml gh gi paragraph-image"><div role="button" tabindex="0" class="mu mv di mw bf mx"><div class="gh gi nv"><img src="../Images/a992782760db456f3f88fbb525cb91ac.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*fMK7Y6XKoeHlJ5o9wGrMVQ.png"/></div></div></figure><p id="84b3" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">恭喜你！！现在，您已经在您的 PC/笔记本电脑中设置了英特尔的 python 发行版。是时候进入 ML 管道了。</p><figure class="mh mi mj mk gt ml"><div class="bz fp l di"><div class="nw nx l"/></div></figure><p id="3a13" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">英特尔已通过所有分销渠道为 tensorflow 提供了优化，安装非常顺利。你可以在这里了解更多信息<a class="ae ko" href="https://software.intel.com/en-us/ai/frameworks/tensorflow" rel="noopener ugc nofollow" target="_blank">。让我们看看如何为我们的 CPU 安装优化的 tensorflow。英特尔软件提供了一个优化的数学内核库(mkl ),它可以优化数学运算，并为用户提供所需的加速。因此，我们将如下安装 tensorflow-mkl。</a></p><pre class="mh mi mj mk gt nl nm nn no aw np bi"><span id="3f5e" class="my kq it nm b gy nq nr l ns nt">conda install<!-- --> <!-- -->tensorflow-mkl</span></pre><p id="1972" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">或者使用 pip，可以按如下方式进行设置。</p><pre class="mh mi mj mk gt nl nm nn no aw np bi"><span id="a5a6" class="my kq it nm b gy nq nr l ns nt">pip install<!-- --> <!-- -->intel-tensorflow</span></pre><p id="f475" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">瞧啊。！Tensorflow 现已启动并在您的系统中运行，并进行了必要的优化。如果你是一个<strong class="js iu"> <em class="nk"> Keras </em> </strong>粉丝，你可以用一个简单的命令来设置它</p><pre class="mh mi mj mk gt nl nm nn no aw np bi"><span id="b285" class="my kq it nm b gy nq nr l ns nt">conda install keras -c intel</span></pre><h2 id="6d36" class="my kq it bd kr mz na dn kv nb nc dp kz kb nd ne ld kf nf ng lh kj nh ni ll nj bi translated">4)建立 Jupyter</h2><p id="2dd4" class="pw-post-body-paragraph jq jr it js b jt ln jv jw jx lo jz ka kb lp kd ke kf lq kh ki kj lr kl km kn im bi translated">由于我们已经创建了一个新的虚拟环境，默认情况下它不会与 spyder 或 jupyter 笔记本一起提供。然而，设置这些是很简单的。只要一句话，我们就能创造奇迹。</p><pre class="mh mi mj mk gt nl nm nn no aw np bi"><span id="1bee" class="my kq it nm b gy nq nr l ns nt">conda install jupyter -c intel</span></pre><h2 id="8c32" class="my kq it bd kr mz na dn kv nb nc dp kz kb nd ne ld kf nf ng lh kj nh ni ll nj bi translated">5)激活环境，开始实验</h2><p id="f74f" class="pw-post-body-paragraph jq jr it js b jt ln jv jw jx lo jz ka kb lp kd ke kf lq kh ki kj lr kl km kn im bi translated">现在我们已经设置好了所有的东西，是时候开始在我们优化的 CPU 系统上用各种 ML 和 DL 方法进行编码和实验了。首先，在执行任何代码之前，确保您正在使用正确的环境。您需要激活虚拟环境，然后才能使用其中安装的库。这个激活步骤是一个全天候的过程，而且毫不费力。在 anaconda 提示符下编写以下命令，就可以开始了。</p><pre class="mh mi mj mk gt nl nm nn no aw np bi"><span id="8114" class="my kq it nm b gy nq nr l ns nt">conda activate intel</span></pre><p id="bbd7" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">要对您的环境进行健全性检查，请在激活环境后，在命令提示符/shell 中键入以下内容。</p><pre class="mh mi mj mk gt nl nm nn no aw np bi"><span id="712d" class="my kq it nm b gy nq nr l ns nt">python</span></pre><p id="74ec" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">键入 python 后按 enter 键，命令提示符中应该会出现以下文本。确保在管道之间有“英特尔公司”字样，并有消息“英特尔公司为您提供 Python 的英特尔(R)发行版。”。这些验证了英特尔 Python 发行版的正确安装。</p><pre class="mh mi mj mk gt nl nm nn no aw np bi"><span id="f5a6" class="my kq it nm b gy nq nr l ns nt">Python 3.6.8 |Intel Corporation| (default, Feb 27 2019, 19:55:17) [MSC v.1900 64 bit (AMD64)] on win32<br/>Type "help", "copyright", "credits" or "license" for more information.<br/>Intel(R) Distribution for Python is brought to you by Intel Corporation.<br/>Please check out: <a class="ae ko" href="https://software.intel.com/en-us/python-distribution" rel="noopener ugc nofollow" target="_blank">https://software.intel.com/en-us/python-distribution</a></span></pre><p id="ae8f" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">现在，您可以使用命令行来试验或在其他地方编写您的脚本，并使用。py 扩展名。然后，可以通过“cd”命令导航到文件的位置并通过以下方式运行脚本来访问这些文件:-</p><pre class="mh mi mj mk gt nl nm nn no aw np bi"><span id="8575" class="my kq it nm b gy nq nr l ns nt">(intel) C:\Users\User&gt;python script.py</span></pre><p id="0b50" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">通过执行步骤 1 到 4，您的系统将具备上述性能指标评测图表中提到的<em class="nk">英特尔 xyz* </em>水平。这些仍然不是基于多处理器的线程优化。我将在下面讨论如何为您的多核 CPU 实现进一步的优化。</p><h1 id="4afb" class="kp kq it bd kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm bi translated">多核优化</h1><p id="48eb" class="pw-post-body-paragraph jq jr it js b jt ln jv jw jx lo jz ka kb lp kd ke kf lq kh ki kj lr kl km kn im bi translated">要为您的多核系统添加进一步的优化，您可以将以下代码行添加到您的。py 文件，它将相应地执行脚本。这里<strong class="js iu"><em class="nk">NUM _ PARALLEL _ EXEC _ UNITS</em></strong>代表你拥有的核心数；我有一台四核 i7。因此数字是 4。对于 Windows 用户，您可以通过导航到任务管理器- &gt;性能- &gt; CPU - &gt;核心来检查任务管理器中的核心数。</p><pre class="mh mi mj mk gt nl nm nn no aw np bi"><span id="b9fb" class="my kq it nm b gy nq nr l ns nt">from keras import backend as K<br/>import tensorflow as tf</span><span id="61c1" class="my kq it nm b gy nu nr l ns nt">NUM_PARALLEL_EXEC_UNITS = 4<br/>config = tf.ConfigProto(intra_op_parallelism_threads=NUM_PARALLEL_EXEC_UNITS, inter_op_parallelism_threads=2,<br/>                       allow_soft_placement=True, device_count={'CPU': NUM_PARALLEL_EXEC_UNITS})</span><span id="5480" class="my kq it nm b gy nu nr l ns nt">session = tf.Session(config=config)</span><span id="9291" class="my kq it nm b gy nu nr l ns nt">K.set_session(session)</span><span id="4539" class="my kq it nm b gy nu nr l ns nt">os.environ["OMP_NUM_THREADS"] = "4"</span><span id="a0d0" class="my kq it nm b gy nu nr l ns nt">os.environ["KMP_BLOCKTIME"] = "30"</span><span id="7ead" class="my kq it nm b gy nu nr l ns nt">os.environ["KMP_SETTINGS"] = "1"</span><span id="a72f" class="my kq it nm b gy nu nr l ns nt">os.environ["KMP_AFFINITY"] = "granularity=fine,verbose,compact,1,0"</span></pre><p id="4429" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">如果您不使用 Keras，而更喜欢使用 core tensorflow，那么脚本几乎保持不变，只需删除以下两行。</p><pre class="mh mi mj mk gt nl nm nn no aw np bi"><span id="6bfd" class="my kq it nm b gy nq nr l ns nt">from keras import backend as K<br/><br/>K.set_session(session)</span></pre><p id="83ff" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">在您的代码中添加这些行之后，速度应该可以与上面性能图表中的<em class="nk">英特尔 xyz(O) </em>条目相媲美。</p><p id="4aad" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">如果您的系统中有一个 GPU，并且它与当前的库集冲突或抛出 cudnn 错误，那么您可以在代码中添加以下行来禁用 GPU。</p><pre class="mh mi mj mk gt nl nm nn no aw np bi"><span id="53d2" class="my kq it nm b gy nq nr l ns nt">os.environ["CUDA_VISIBLE_DEVICES"] = "-1"</span></pre><h1 id="7ea7" class="kp kq it bd kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm bi translated">结论</h1><p id="ab54" class="pw-post-body-paragraph jq jr it js b jt ln jv jw jx lo jz ka kb lp kd ke kf lq kh ki kj lr kl km kn im bi translated">就是这样。你现在有一个优化的管道来测试和开发机器学习项目和想法。这一渠道为参与学术研究的学生提供了很多机会，让他们可以利用自己的系统继续工作。该管道还将防止从业者可能正在处理的私人数据的隐私担忧。</p><p id="a908" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">还可以观察到，通过适当的微调，人们可以在工作流程中获得 3.45 倍的加速，这意味着如果您正在试验您的想法，您现在的工作速度可以是以前的三倍。</p></div></div>    
</body>
</html>