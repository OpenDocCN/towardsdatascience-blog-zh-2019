<html>
<head>
<title>Multi-Label Classification using BERT, RoBERTa, XLNet, XLM, and DistilBERT with Simple Transformers</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用 BERT、RoBERTa、XLNet、XLM 和 DistilBERT 以及简单变压器进行多标签分类</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/multi-label-classification-using-bert-roberta-xlnet-xlm-and-distilbert-with-simple-transformers-b3e0cda12ce5?source=collection_archive---------0-----------------------#2019-11-09">https://towardsdatascience.com/multi-label-classification-using-bert-roberta-xlnet-xlm-and-distilbert-with-simple-transformers-b3e0cda12ce5?source=collection_archive---------0-----------------------#2019-11-09</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="9043" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">了解如何使用 Transformer 模型，仅用简单的 Transformer 的 3 行代码来执行多标签分类。</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/a0ea16ccf9b7b335a2a94056f350ac53.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*fGRNc86Moy4fQodi21Ds1g.jpeg"/></div></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk">Photo by <a class="ae ky" href="https://unsplash.com/@russn_fckr?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank">russn_fckr</a> on <a class="ae ky" href="https://unsplash.com/s/photos/choice?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><h1 id="0add" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">前言</h1><p id="0284" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated"><a class="ae ky" href="https://github.com/ThilinaRajapakse/simpletransformers" rel="noopener ugc nofollow" target="_blank">简单变形金刚</a>库是在优秀的<a class="ae ky" href="https://github.com/huggingface/transformers" rel="noopener ugc nofollow" target="_blank">变形金刚</a>库的基础上通过抱脸的方式构建的。你们太不可思议了！</p><p id="e8f5" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">简单变压器现在支持:</p><ul class=""><li id="86e8" class="ms mt it lt b lu mn lx mo ma mu me mv mi mw mm mx my mz na bi translated"><a class="ae ky" rel="noopener" target="_blank" href="/simple-transformers-introducing-the-easiest-bert-roberta-xlnet-and-xlm-library-58bf8c59b2a3">二进制分类</a></li><li id="d7ea" class="ms mt it lt b lu nb lx nc ma nd me ne mi nf mm mx my mz na bi translated"><a class="ae ky" href="https://medium.com/swlh/simple-transformers-multi-class-text-classification-with-bert-roberta-xlnet-xlm-and-8b585000ce3a" rel="noopener">多类分类</a></li><li id="756d" class="ms mt it lt b lu nb lx nc ma nd me ne mi nf mm mx my mz na bi translated"><a class="ae ky" rel="noopener" target="_blank" href="/simple-transformers-named-entity-recognition-with-transformer-models-c04b9242a2a0">命名实体识别</a>(以及类似的令牌级任务)</li><li id="dd73" class="ms mt it lt b lu nb lx nc ma nd me ne mi nf mm mx my mz na bi translated"><strong class="lt iu">多标签分类</strong></li></ul><p id="0540" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">还有很多正在筹备中。</p><h1 id="bc94" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">介绍</h1><p id="cc5f" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">变压器模型和迁移学习方法继续以惊人的速度推动自然语言处理领域向前发展。然而，最先进的性能往往是以大量(复杂)代码为代价的。</p><p id="d006" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">Simple Transformers 避免了所有的复杂性，让您开始关注重要的事情，训练和使用 Transformer 模型。绕过所有复杂的设置、样板文件和其他常见的不愉快，在一行中初始化一个模型，在下一行中训练，然后用第三行进行评估。</p><p id="3639" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">本指南展示了如何使用简单的变压器来执行多标签分类。在多标签分类中，每个样本可以具有来自给定标签集的任意标签组合<em class="ng">(无、一个、一些或全部)</em>。</p><p id="2737" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated"><em class="ng">所有的源代码都可以在</em><a class="ae ky" href="https://github.com/ThilinaRajapakse/simpletransformers" rel="noopener ugc nofollow" target="_blank"><em class="ng">Github Repo</em></a><em class="ng">上找到。如果您有任何问题或疑问，这是解决它们的地方。请务必检查一下！</em></p><h1 id="0236" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">装置</h1><ol class=""><li id="19f3" class="ms mt it lt b lu lv lx ly ma nh me ni mi nj mm nk my mz na bi translated">从<a class="ae ky" href="https://www.anaconda.com/distribution/" rel="noopener ugc nofollow" target="_blank">这里</a>安装 Anaconda 或 Miniconda 包管理器。</li><li id="dd37" class="ms mt it lt b lu nb lx nc ma nd me ne mi nf mm nk my mz na bi translated">创建新的虚拟环境并安装软件包。<br/> <code class="fe nl nm nn no b">conda create -n simpletransformers python pandas tqdm</code> <br/> <code class="fe nl nm nn no b">conda activate simpletransformers</code> <br/>如果使用 cuda: <br/> <code class="fe nl nm nn no b">conda install pytorch cudatoolkit=10.0 -c pytorch</code> <br/>其他:<br/><code class="fe nl nm nn no b">conda install pytorch cpuonly -c pytorch</code><br/><code class="fe nl nm nn no b">conda install -c anaconda scipy</code><br/><code class="fe nl nm nn no b">conda install -c anaconda scikit-learn</code><br/><code class="fe nl nm nn no b">pip install transformers</code><br/><code class="fe nl nm nn no b">pip install seqeval</code><br/><code class="fe nl nm nn no b">pip install tensorboardx</code></li><li id="f27c" class="ms mt it lt b lu nb lx nc ma nd me ne mi nf mm nk my mz na bi translated">如果您使用 fp16 培训，请安装 Apex。请遵循此处的说明<a class="ae ky" href="https://github.com/NVIDIA/apex" rel="noopener ugc nofollow" target="_blank">。(从 pip 安装 Apex 给一些人带来了问题。)</a></li><li id="039e" class="ms mt it lt b lu nb lx nc ma nd me ne mi nf mm nk my mz na bi translated">安装简单变压器。<br/> <code class="fe nl nm nn no b">pip install simpletransformers</code></li></ol><h1 id="9647" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">多标签分类</h1><p id="7e84" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">为了演示多标签分类，我们将使用 Kaggle 的<a class="ae ky" href="https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge/" rel="noopener ugc nofollow" target="_blank">毒性评论</a>数据集。从上面的链接下载数据集，并将<code class="fe nl nm nn no b">csv</code>文件放在<code class="fe nl nm nn no b">data/</code>目录中。</p><h2 id="a511" class="np la it bd lb nq nr dn lf ns nt dp lj ma nu nv ll me nw nx ln mi ny nz lp oa bi translated">数据准备</h2><p id="a713" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">数据集中的评论已经根据下面的标准进行了标注。</p><ul class=""><li id="617a" class="ms mt it lt b lu mn lx mo ma mu me mv mi mw mm mx my mz na bi translated"><code class="fe nl nm nn no b">toxic</code></li><li id="fb7b" class="ms mt it lt b lu nb lx nc ma nd me ne mi nf mm mx my mz na bi translated"><code class="fe nl nm nn no b">severe_toxic</code></li><li id="ac70" class="ms mt it lt b lu nb lx nc ma nd me ne mi nf mm mx my mz na bi translated"><code class="fe nl nm nn no b">obscene</code></li><li id="8e0c" class="ms mt it lt b lu nb lx nc ma nd me ne mi nf mm mx my mz na bi translated"><code class="fe nl nm nn no b">threat</code></li><li id="33fc" class="ms mt it lt b lu nb lx nc ma nd me ne mi nf mm mx my mz na bi translated"><code class="fe nl nm nn no b">insult</code></li><li id="612f" class="ms mt it lt b lu nb lx nc ma nd me ne mi nf mm mx my mz na bi translated"><code class="fe nl nm nn no b">identity_hate</code></li></ul><p id="3bee" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">数据集包含每个标准的一列，用布尔值 1 或 0 表示注释是否包含相应的毒性。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="ob oc l"/></div></figure><p id="b185" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">然而，简单的 Transformers 需要一个包含多热点编码标签列表的列<code class="fe nl nm nn no b">labels</code>,以及一个包含所有文本的列<code class="fe nl nm nn no b">text</code>(废话！).</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="ob oc l"/></div></figure><p id="5985" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">让我们将<code class="fe nl nm nn no b">df</code>分成训练和评估数据集，这样我们就可以轻松地验证模型。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="ob oc l"/></div></figure><p id="4e59" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">现在数据集已经可以使用了！</p><h2 id="50b7" class="np la it bd lb nq nr dn lf ns nt dp lj ma nu nv ll me nw nx ln mi ny nz lp oa bi translated">多标签分类模型</h2><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="ob oc l"/></div></figure><p id="1f2e" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">这创建了一个<code class="fe nl nm nn no b">MultiLabelClassificationModel</code>,可用于多标签分类任务的训练、评估和预测。第一个参数是<em class="ng"> model_type，</em>第二个是<em class="ng"> model_name </em>，第三个是数据中标签的个数。</p><ul class=""><li id="7a51" class="ms mt it lt b lu mn lx mo ma mu me mv mi mw mm mx my mz na bi translated"><code class="fe nl nm nn no b">model_type</code>可能是<code class="fe nl nm nn no b">['bert', 'xlnet', 'xlm', 'roberta', 'distilbert'].</code>中的一个</li><li id="7439" class="ms mt it lt b lu nb lx nc ma nd me ne mi nf mm mx my mz na bi translated">关于可用于<code class="fe nl nm nn no b">model_name</code>的预训练模型的完整列表，请参考<a class="ae ky" href="https://github.com/ThilinaRajapakse/simpletransformers#current-pretrained-models" rel="noopener ugc nofollow" target="_blank">当前预训练模型</a>。</li></ul><p id="daf2" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated"><code class="fe nl nm nn no b">args</code>参数接受一个可选的 Python 字典，其中包含超参数值和配置选项。我强烈推荐在这里查看所有选项<a class="ae ky" href="https://github.com/ThilinaRajapakse/simpletransformers/blob/master/README.md#default-settings" rel="noopener ugc nofollow" target="_blank"/>。</p><p id="351d" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">默认值如下所示。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="ob oc l"/></div></figure><p id="c6f8" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">要加载一个先前保存的模型而不是默认模型，您可以将<em class="ng"> model_name </em>更改为包含已保存模型的<strong class="lt iu">目录</strong>的路径。</p><pre class="kj kk kl km gt od no oe of aw og bi"><span id="ef7b" class="np la it no b gy oh oi l oj ok">model = <!-- -->MultiLabelClassificationModel<!-- -->('xlnet', 'path_to_model/', num_labels=6)</span></pre><h1 id="b5b8" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">培养</h1><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="ob oc l"/></div></figure><p id="d54d" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">这将根据训练数据训练模型。您还可以通过将包含相关属性的<code class="fe nl nm nn no b">dict</code>传递给<code class="fe nl nm nn no b">train_model</code>方法来更改超参数。请注意，这些修改<strong class="lt iu">将持续</strong>甚至在训练完成后。</p><p id="00e7" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated"><code class="fe nl nm nn no b">train_model</code>方法将在每第<em class="ng"> n </em>步创建一个模型的检查点(保存)，其中<em class="ng"> n </em>为<code class="fe nl nm nn no b">self.args['save_steps']</code>。训练完成后，最终模型将保存到<code class="fe nl nm nn no b">self.args['output_dir']</code>。</p><h1 id="1ccd" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">估价</h1><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="ob oc l"/></div></figure><p id="79dd" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated"><code class="fe nl nm nn no b">eval_model</code>方法用于对评估数据集进行评估。这个方法有三个返回值。</p><ul class=""><li id="1f6d" class="ms mt it lt b lu mn lx mo ma mu me mv mi mw mm mx my mz na bi translated">result:以<code class="fe nl nm nn no b">dict</code>的形式给出评估结果。默认情况下，对于多标注分类，仅报告标注等级平均精度(LRAP)。</li><li id="215e" class="ms mt it lt b lu nb lx nc ma nd me ne mi nf mm mx my mz na bi translated">model_outputs:评估数据集中每个项目的模型输出的一个<code class="fe nl nm nn no b">list</code>。如果您需要每个类别的概率，而不是单个预测，这将非常有用。请注意，<code class="fe nl nm nn no b">sigmoid</code>函数已应用于每个输出，以压缩 0 和<code class="fe nl nm nn no b">.</code>之间的值</li><li id="40c3" class="ms mt it lt b lu nb lx nc ma nd me ne mi nf mm mx my mz na bi translated">错误预测:每个错误预测的第<code class="fe nl nm nn no b">InputFeature</code>个<code class="fe nl nm nn no b">list</code>。文本可以从<code class="fe nl nm nn no b">InputFeature.text_a</code>属性中获得。<em class="ng">(</em><code class="fe nl nm nn no b"><em class="ng">InputFeature</em></code><em class="ng">类可以在</em> <code class="fe nl nm nn no b"><em class="ng">utils.py</em></code> <em class="ng">文件中的</em> <a class="ae ky" href="https://github.com/ThilinaRajapakse/simpletransformers" rel="noopener ugc nofollow" target="_blank"> <em class="ng">回购</em> </a> <em class="ng"> ) </em></li></ul><p id="5e3f" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">您还可以包括评估中使用的其他指标。只需将度量函数作为关键字参数传递给<code class="fe nl nm nn no b">eval_model</code>方法。度量函数应该接受两个参数，第一个是真实标签，第二个是预测。这遵循了 sklearn 标准。</p><p id="b3ad" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated"><em class="ng">确保度量函数与多标签分类兼容。</em></p><h2 id="0b0f" class="np la it bd lb nq nr dn lf ns nt dp lj ma nu nv ll me nw nx ln mi ny nz lp oa bi translated">预测/测试</h2><p id="eeed" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">虽然当我们知道正确的标签并且只需要评估模型的性能时,<code class="fe nl nm nn no b">eval_model</code>是有用的，但是我们很少在现实世界的任务中知道真正的标签(我确信这里面有一些深刻的哲学)。在这种情况下，<code class="fe nl nm nn no b">predict</code>方法就派上了用场。它类似于<code class="fe nl nm nn no b">eval_model</code>方法，除了它不需要真正的标签并返回预测和模型输出。</p><p id="a0b3" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">我们可以在有毒评论数据集中提供的测试数据上进行尝试。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="ob oc l"/></div></figure><p id="830f" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">将此提交给 Kaggle 使我获得了 0.98468 的<strong class="lt iu">分数，再次证明了自变形金刚和迁移学习出现以来 NLP 取得了多大的进步。请记住，我在这里没有做太多的超参数调优！</strong></p><h2 id="3604" class="np la it bd lb nq nr dn lf ns nt dp lj ma nu nv ll me nw nx ln mi ny nz lp oa bi translated">结论</h2><p id="70f6" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">伯特及其衍生产品太棒了！我希望简单的变形金刚有助于在使用它们的过程中消除一些障碍。</p></div></div>    
</body>
</html>