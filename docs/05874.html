<html>
<head>
<title>Learning in Graphs with Python (Part 3)</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">用 Python 学习图形(第 3 部分)</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/learning-in-graphs-with-python-part-3-8d5513eef62d?source=collection_archive---------6-----------------------#2019-08-27">https://towardsdatascience.com/learning-in-graphs-with-python-part-3-8d5513eef62d?source=collection_archive---------6-----------------------#2019-08-27</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><h2 id="b44c" class="ir is it bd b dl iu iv iw ix iy iz dk ja translated" aria-label="kicker paragraph"><a class="ae ep" href="https://medium.com/towards-data-science/inside-ai/home" rel="noopener">内线艾</a></h2><div class=""/><div class=""><h2 id="5758" class="pw-subtitle-paragraph jz jc it bd b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq dk translated">Python 的概念、应用和示例</h2></div><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi kr"><img src="../Images/82d0268f5bf49485e39c2cd091cfae39.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*DDAX3wQfIKOKWgoZkF12Wg.png"/></div></div><figcaption class="ld le gj gh gi lf lg bd b be z dk">A wonderful evening in Greenland, back in 2016</figcaption></figure></div><div class="ab cl lh li hx lj" role="separator"><span class="lk bw bk ll lm ln"/><span class="lk bw bk ll lm ln"/><span class="lk bw bk ll lm"/></div><div class="im in io ip iq"><p id="602d" class="pw-post-body-paragraph lo lp it lq b lr ls kd lt lu lv kg lw lx ly lz ma mb mc md me mf mg mh mi mj im bi mk translated"><span class="l ml mm mn bm mo mp mq mr ms di"> G </span>如今，raphs 正成为机器学习的核心，例如，无论你是想通过预测潜在的联系来了解社交网络的结构，检测欺诈，了解汽车租赁服务的客户行为，还是提出实时建议。</p><p id="cc8b" class="pw-post-body-paragraph lo lp it lq b lr ls kd lt lu lv kg lw lx ly lz ma mb mc md me mf mg mh mi mj im bi translated">在本文中，我们将讨论:</p><ul class=""><li id="fa20" class="mt mu it lq b lr ls lu lv lx mv mb mw mf mx mj my mz na nb bi translated">主要的图学习算法</li><li id="8d6e" class="mt mu it lq b lr nc lu nd lx ne mb nf mf ng mj my mz na nb bi translated">Python 中的用例及实现</li></ul><p id="4f5a" class="pw-post-body-paragraph lo lp it lq b lr ls kd lt lu lv kg lw lx ly lz ma mb mc md me mf mg mh mi mj im bi translated">我在这个资源库上发布我所有的文章和相应的代码:</p><div class="nh ni gp gr nj nk"><a href="https://github.com/maelfabien/Machine_Learning_Tutorials" rel="noopener  ugc nofollow" target="_blank"><div class="nl ab fo"><div class="nm ab nn cl cj no"><h2 class="bd jd gy z fp np fr fs nq fu fw jc bi translated">mael fabien/机器学习教程</h2><div class="nr l"><h3 class="bd b gy z fp np fr fs nq fu fw dk translated">本报告包含练习、代码、教程和我的个人博客文章</h3></div><div class="ns l"><p class="bd b dl z fp np fr fs nq fu fw dk translated">github.com</p></div></div><div class="nt l"><div class="nu l nv nw nx nt ny lb nk"/></div></div></a></div><p id="8a19" class="pw-post-body-paragraph lo lp it lq b lr ls kd lt lu lv kg lw lx ly lz ma mb mc md me mf mg mh mi mj im bi translated">这是我的图形系列的最后一篇文章。如果您还没有，请务必阅读本系列的第一篇文章:</p><div class="nh ni gp gr nj nk"><a rel="noopener follow" target="_blank" href="/introduction-to-graphs-part-1-2de6cda8c5a5"><div class="nl ab fo"><div class="nm ab nn cl cj no"><h2 class="bd jd gy z fp np fr fs nq fu fw jc bi translated">图表介绍(第一部分)</h2><div class="nr l"><h3 class="bd b gy z fp np fr fs nq fu fw dk translated">Python 中的主要概念、属性和应用</h3></div><div class="ns l"><p class="bd b dl z fp np fr fs nq fu fw dk translated">towardsdatascience.com</p></div></div><div class="nt l"><div class="nz l nv nw nx nt ny lb nk"/></div></div></a></div><div class="nh ni gp gr nj nk"><a rel="noopener follow" target="_blank" href="/graph-algorithms-part-2-dce0b2734a1d"><div class="nl ab fo"><div class="nm ab nn cl cj no"><h2 class="bd jd gy z fp np fr fs nq fu fw jc bi translated">图形算法(第二部分)</h2><div class="nr l"><h3 class="bd b gy z fp np fr fs nq fu fw dk translated">Python 中的主要概念、属性和应用</h3></div><div class="ns l"><p class="bd b dl z fp np fr fs nq fu fw dk translated">towardsdatascience.com</p></div></div><div class="nt l"><div class="oa l nv nw nx nt ny lb nk"/></div></div></a></div></div><div class="ab cl lh li hx lj" role="separator"><span class="lk bw bk ll lm ln"/><span class="lk bw bk ll lm ln"/><span class="lk bw bk ll lm"/></div><div class="im in io ip iq"><p id="5d63" class="pw-post-body-paragraph lo lp it lq b lr ls kd lt lu lv kg lw lx ly lz ma mb mc md me mf mg mh mi mj im bi translated">接下来，打开 Jupyter 笔记本，导入以下包:</p><pre class="ks kt ku kv gt ob oc od oe aw of bi"><span id="266e" class="og oh it oc b gy oi oj l ok ol">import numpy as np<br/>import random<br/>import networkx as nx<br/>from IPython.display import Image<br/>import matplotlib.pyplot as plt</span></pre><p id="085b" class="pw-post-body-paragraph lo lp it lq b lr ls kd lt lu lv kg lw lx ly lz ma mb mc md me mf mg mh mi mj im bi translated">以下文章将使用最新版本的<code class="fe om on oo oc b">networkx</code><code class="fe om on oo oc b">2.x</code>。NetworkX 是一个 Python 包，用于创建、操作和研究复杂网络的结构、动态和功能。</p><p id="f3a1" class="pw-post-body-paragraph lo lp it lq b lr ls kd lt lu lv kg lw lx ly lz ma mb mc md me mf mg mh mi mj im bi translated">我将尽量保持一种实用的方法，并举例说明大多数概念。</p></div><div class="ab cl lh li hx lj" role="separator"><span class="lk bw bk ll lm ln"/><span class="lk bw bk ll lm ln"/><span class="lk bw bk ll lm"/></div><div class="im in io ip iq"><p id="d239" class="pw-post-body-paragraph lo lp it lq b lr ls kd lt lu lv kg lw lx ly lz ma mb mc md me mf mg mh mi mj im bi translated">在本文中，我们将讨论图形学习中的三个主要任务:</p><ul class=""><li id="2acf" class="mt mu it lq b lr ls lu lv lx mv mb mw mf mx mj my mz na nb bi translated">链接预测</li><li id="0787" class="mt mu it lq b lr nc lu nd lx ne mb nf mf ng mj my mz na nb bi translated">节点标签预测</li><li id="3254" class="mt mu it lq b lr nc lu nd lx ne mb nf mf ng mj my mz na nb bi translated">图形嵌入</li></ul><p id="7028" class="pw-post-body-paragraph lo lp it lq b lr ls kd lt lu lv kg lw lx ly lz ma mb mc md me mf mg mh mi mj im bi translated">先说链接预测！</p><h1 id="ac2b" class="op oh it bd oq or os ot ou ov ow ox oy ki oz kj pa kl pb km pc ko pd kp pe pf bi translated">I .链接预测</h1><blockquote class="pg ph pi"><p id="f0f8" class="lo lp pj lq b lr ls kd lt lu lv kg lw pk ly lz ma pl mc md me pm mg mh mi mj im bi translated"><em class="it">在</em> <strong class="lq jd"> <em class="it">链接预测</em> </strong> <em class="it">中，给定一个图 G，我们旨在预测新的边。预测对于</em> <strong class="lq jd"> <em class="it">预测未来的关系或者缺失的边</em> </strong> <em class="it">很有用，例如当图表没有被完全观察到时，或者当新的客户加入一个平台时(例如一个新的 LinkedIn 用户)。</em></p></blockquote><p id="e6be" class="pw-post-body-paragraph lo lp it lq b lr ls kd lt lu lv kg lw lx ly lz ma mb mc md me mf mg mh mi mj im bi translated">LinkedIn 新用户的链接预测只是对他可能认识的人的建议。</p><p id="81ce" class="pw-post-body-paragraph lo lp it lq b lr ls kd lt lu lv kg lw lx ly lz ma mb mc md me mf mg mh mi mj im bi translated">在链接预测中，我们简单地尝试在成对的节点和<strong class="lq jd">节点之间建立一个相似性度量，链接最相似的</strong> <strong class="lq jd">节点</strong>。现在的问题是识别和计算正确的相似性分数！</p><p id="c995" class="pw-post-body-paragraph lo lp it lq b lr ls kd lt lu lv kg lw lx ly lz ma mb mc md me mf mg mh mi mj im bi translated">为了说明不同的相似性得分，让我们考虑下图:</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi pn"><img src="../Images/04017fd96e3d98cf943a015e50eab352.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*6rFC3f4MerE3F9IeY-jdHA.png"/></div></div><figcaption class="ld le gj gh gi lf lg bd b be z dk">Initial graph</figcaption></figure><p id="d399" class="pw-post-body-paragraph lo lp it lq b lr ls kd lt lu lv kg lw lx ly lz ma mb mc md me mf mg mh mi mj im bi translated">设 N(i)是节点 I 的一组邻居。在上图中，节点 I 和 j 的邻居可以表示为:</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi po"><img src="../Images/4f9d913a2b73aae5261dfa37f9ffbc7b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*6IeCwlborbi2GcvzLjytEQ.png"/></div></div><figcaption class="ld le gj gh gi lf lg bd b be z dk">Neighbors of j</figcaption></figure><p id="45be" class="pw-post-body-paragraph lo lp it lq b lr ls kd lt lu lv kg lw lx ly lz ma mb mc md me mf mg mh mi mj im bi translated">和我的邻居:</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi pp"><img src="../Images/ae08233e1ae27cbea43319af7fd4ba52.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*BZHBFFhX9ZHAgpetIrduzA.png"/></div></div><figcaption class="ld le gj gh gi lf lg bd b be z dk">Neighbors of i</figcaption></figure><h2 id="8367" class="og oh it bd oq pq pr dn ou ps pt dp oy lx pu pv pa mb pw px pc mf py pz pe iz bi translated">1.相似性得分</h2><p id="72be" class="pw-post-body-paragraph lo lp it lq b lr qa kd lt lu qb kg lw lx qc lz ma mb qd md me mf qe mh mi mj im bi translated">我们可以基于它们的邻域为这两个节点建立几个相似性分数。</p><ul class=""><li id="c51d" class="mt mu it lq b lr ls lu lv lx mv mb mw mf mx mj my mz na nb bi translated"><strong class="lq jd">共同邻居:</strong> S(i,j)=∣N(i)∩N(j)∣，即共同邻居的数量。在本例中，分数仅为 12，因为它们只有两个共同的邻居。</li></ul><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi qf"><img src="../Images/32f6544f4c83126e96eab317cf3d254e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*JLnyyuTRe7LgQ89IDP0ElA.png"/></div></div><figcaption class="ld le gj gh gi lf lg bd b be z dk">Common Neighbors</figcaption></figure><ul class=""><li id="610c" class="mt mu it lq b lr ls lu lv lx mv mb mw mf mx mj my mz na nb bi translated"><strong class="lq jd"> Jaccard 系数:</strong>一个归一化的共同邻居版本。</li></ul><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi qg"><img src="../Images/66de1dc160e71d40451e761b4a521d56.png" data-original-src="https://miro.medium.com/v2/resize:fit:832/format:webp/1*PPw0Syg3F3RcMLOfN6-dpA.png"/></div></figure><p id="48f3" class="pw-post-body-paragraph lo lp it lq b lr ls kd lt lu lv kg lw lx ly lz ma mb mc md me mf mg mh mi mj im bi translated">交集是共同的邻居，并集是:</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi qh"><img src="../Images/48e6b8ddbe2ad59193a5102484018cd5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*VeKA_M0JdGKgZzAQh-oyWQ.png"/></div></div><figcaption class="ld le gj gh gi lf lg bd b be z dk">Union</figcaption></figure><p id="08c4" class="pw-post-body-paragraph lo lp it lq b lr ls kd lt lu lv kg lw lx ly lz ma mb mc md me mf mg mh mi mj im bi translated">因此，Jaccard 系数由粉红色与黄色之比给出:</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi qi"><img src="../Images/066f5278fad685827a4b17332be66fd6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*IPyIiYV0MIXQUPnTLUW-ZA.png"/></div></div><figcaption class="ld le gj gh gi lf lg bd b be z dk">Jaccard Coefficient</figcaption></figure><p id="50aa" class="pw-post-body-paragraph lo lp it lq b lr ls kd lt lu lv kg lw lx ly lz ma mb mc md me mf mg mh mi mj im bi translated">值是 2/7。</p><ul class=""><li id="be9c" class="mt mu it lq b lr ls lu lv lx mv mb mw mf mx mj my mz na nb bi translated"><strong class="lq jd"> Adamic-Adar 索引:</strong>对于节点 I 和 j 的每个共同邻居，我们加 1 除以该节点的邻居总数。其概念是，当预测两个节点之间的连接时，与少量节点之间共享的元素相比，具有非常大的邻域的公共元素不太重要。</li></ul><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi qj"><img src="../Images/047895f30d2a64f35f5214032dee968f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1288/format:webp/1*hvRWvDAv0XvB23GsYnuzOA.png"/></div></figure><ul class=""><li id="bab1" class="mt mu it lq b lr ls lu lv lx mv mb mw mf mx mj my mz na nb bi translated"><strong class="lq jd">优先附件</strong> : S(i,j)=∣N(i,j)∣∗∣N(j)∣</li><li id="29e4" class="mt mu it lq b lr nc lu nd lx ne mb nf mf ng mj my mz na nb bi translated">我们也可以使用可用的社区信息。</li></ul><h2 id="cf22" class="og oh it bd oq pq pr dn ou ps pt dp oy lx pu pv pa mb pw px pc mf py pz pe iz bi translated">2.性能指标</h2><p id="a9d2" class="pw-post-body-paragraph lo lp it lq b lr qa kd lt lu qb kg lw lx qc lz ma mb qd md me mf qe mh mi mj im bi translated">我们如何执行链接预测的评估？我们必须隐藏节点对的子集，并根据上面定义的规则预测它们的链接。这相当于监督学习中的训练-测试-分割。</p><p id="5cf4" class="pw-post-body-paragraph lo lp it lq b lr ls kd lt lu lv kg lw lx ly lz ma mb mc md me mf mg mh mi mj im bi translated">然后，我们评估密集图形的正确预测比例，或者使用稀疏图形的曲线标准下的面积。</p><h2 id="a37f" class="og oh it bd oq pq pr dn ou ps pt dp oy lx pu pv pa mb pw px pc mf py pz pe iz bi translated">3.履行</h2><p id="063f" class="pw-post-body-paragraph lo lp it lq b lr qa kd lt lu qb kg lw lx qc lz ma mb qd md me mf qe mh mi mj im bi translated">让我们用 Python 来实现我们在前两篇文章中使用的空手道图！首先，打印关于图形的信息:</p><pre class="ks kt ku kv gt ob oc od oe aw of bi"><span id="d235" class="og oh it oc b gy oi oj l ok ol">n = G_karate.number_of_nodes()<br/>m = G_karate.number_of_edges()<br/>print("Number of nodes :", str(n))<br/>print("Number of edges :", str(m))<br/>print("Number of connected components :" str(nx.number_connected_components(G_karate)))</span></pre><p id="1aa0" class="pw-post-body-paragraph lo lp it lq b lr ls kd lt lu lv kg lw lx ly lz ma mb mc md me mf mg mh mi mj im bi translated">然后，绘制图表本身:</p><pre class="ks kt ku kv gt ob oc od oe aw of bi"><span id="466b" class="og oh it oc b gy oi oj l ok ol">plt.figure(figsize=(12,8))<br/>nx.draw(G_karate)</span></pre><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi qk"><img src="../Images/afb4342286795fad9174bf484d1e0446.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*D1SCbN2qOSgpQ6U1iRXw9w.png"/></div></div></figure><p id="e603" class="pw-post-body-paragraph lo lp it lq b lr ls kd lt lu lv kg lw lx ly lz ma mb mc md me mf mg mh mi mj im bi translated">现在，让我们删除一些连接，例如 25%的节点:</p><pre class="ks kt ku kv gt ob oc od oe aw of bi"><span id="7abd" class="og oh it oc b gy oi oj l ok ol"># Take a random sample of edges<br/>edge_subset = random.sample(G_karate.edges(), int(0.25 * G_karate.number_of_edges()))</span><span id="e547" class="og oh it oc b gy ql oj l ok ol"># Remove some edges<br/>G_karate_train = G_karate.copy()<br/>G_karate_train.remove_edges_from(edge_subset)</span></pre><p id="a3be" class="pw-post-body-paragraph lo lp it lq b lr ls kd lt lu lv kg lw lx ly lz ma mb mc md me mf mg mh mi mj im bi translated">并绘制部分观察到的图形:</p><pre class="ks kt ku kv gt ob oc od oe aw of bi"><span id="177b" class="og oh it oc b gy oi oj l ok ol">plt.figure(figsize=(12,8))<br/>nx.draw(G_karate_train)</span></pre><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi qm"><img src="../Images/1443eb35935d45be5f6aca516bb48603.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ItWMMgh4fKBdfSGGPoDWyw.png"/></div></div><figcaption class="ld le gj gh gi lf lg bd b be z dk">Partially observed graph</figcaption></figure><p id="92a8" class="pw-post-body-paragraph lo lp it lq b lr ls kd lt lu lv kg lw lx ly lz ma mb mc md me mf mg mh mi mj im bi translated">您可以打印我们删除的边数和剩余的边数:</p><pre class="ks kt ku kv gt ob oc od oe aw of bi"><span id="bd90" class="og oh it oc b gy oi oj l ok ol">edge_subset_size = len(list(edge_subset))<br/>print("Deleted : ", str(edge_subset_size))<br/>print("Remaining : ", str((m - edge_subset_size)))</span></pre><p id="2f80" class="pw-post-body-paragraph lo lp it lq b lr ls kd lt lu lv kg lw lx ly lz ma mb mc md me mf mg mh mi mj im bi translated">这个标题是:</p><pre class="ks kt ku kv gt ob oc od oe aw of bi"><span id="2028" class="og oh it oc b gy oi oj l ok ol">Deleted : 15<br/>Remaining : 63</span></pre><p id="51d8" class="pw-post-body-paragraph lo lp it lq b lr ls kd lt lu lv kg lw lx ly lz ma mb mc md me mf mg mh mi mj im bi translated"><strong class="lq jd">雅克卡系数</strong></p><p id="ff7d" class="pw-post-body-paragraph lo lp it lq b lr ls kd lt lu lv kg lw lx ly lz ma mb mc md me mf mg mh mi mj im bi translated">我们可以首先使用 Jaccard 系数进行预测:</p><pre class="ks kt ku kv gt ob oc od oe aw of bi"><span id="5a03" class="og oh it oc b gy oi oj l ok ol">prediction_jaccard = list(nx.jaccard_coefficient(G_karate_train))<br/>score, label = zip(*[(s, (u,v) in edge_subset) for (u,v,s) in prediction_jaccard])</span></pre><p id="419a" class="pw-post-body-paragraph lo lp it lq b lr ls kd lt lu lv kg lw lx ly lz ma mb mc md me mf mg mh mi mj im bi translated">预测看起来像这样，第一个节点，第二个节点，和一个 Jaccard 分数(或者直接是一个标签):</p><pre class="ks kt ku kv gt ob oc od oe aw of bi"><span id="09a9" class="og oh it oc b gy oi oj l ok ol">[(0, 32, 0.15),<br/>(0, 33, 0.125),<br/>(0, 3, 0.21428571428571427),<br/>(0, 9, 0.0),<br/>(0, 14, 0.0),<br/>(0, 15, 0.0),<br/>...</span></pre><p id="3b6b" class="pw-post-body-paragraph lo lp it lq b lr ls kd lt lu lv kg lw lx ly lz ma mb mc md me mf mg mh mi mj im bi translated">我们可以使用 ROC-AUC 标准来比较不同模型的性能，因为我们既有标签又有概率。</p><p id="814e" class="pw-post-body-paragraph lo lp it lq b lr ls kd lt lu lv kg lw lx ly lz ma mb mc md me mf mg mh mi mj im bi translated"><strong class="lq jd"> Adamic-Adar </strong></p><p id="8620" class="pw-post-body-paragraph lo lp it lq b lr ls kd lt lu lv kg lw lx ly lz ma mb mc md me mf mg mh mi mj im bi translated">我们现在可以对 Adamic-Adar 指数重复这一过程:</p><pre class="ks kt ku kv gt ob oc od oe aw of bi"><span id="c796" class="og oh it oc b gy oi oj l ok ol">prediction_adamic = list(nx.adamic_adar_index(G_karate_train))<br/>score, label = zip(*[(s, (u,v) in edge_subset) for (u,v,s) in prediction_adamic])</span></pre><p id="ce42" class="pw-post-body-paragraph lo lp it lq b lr ls kd lt lu lv kg lw lx ly lz ma mb mc md me mf mg mh mi mj im bi translated"><strong class="lq jd">优先附件</strong></p><p id="5bf2" class="pw-post-body-paragraph lo lp it lq b lr ls kd lt lu lv kg lw lx ly lz ma mb mc md me mf mg mh mi mj im bi translated">对于优先附件分数:</p><pre class="ks kt ku kv gt ob oc od oe aw of bi"><span id="1ded" class="og oh it oc b gy oi oj l ok ol">prediction_pref = list(nx.preferential_attachment(G_karate_train))<br/>score, label = zip(*[(s, (u,v) in edge_subset) for (u,v,s) in prediction_pref])</span></pre><p id="314b" class="pw-post-body-paragraph lo lp it lq b lr ls kd lt lu lv kg lw lx ly lz ma mb mc md me mf mg mh mi mj im bi translated">然后，我们选择最大化曲线下面积的模型，例如，或您选择的任何其他标准。到目前为止，我们讨论了链接预测最常见的相似性得分。</p><p id="6a0b" class="pw-post-body-paragraph lo lp it lq b lr ls kd lt lu lv kg lw lx ly lz ma mb mc md me mf mg mh mi mj im bi translated">我们现在将更详细地介绍节点标记算法。</p><h1 id="ead6" class="op oh it bd oq or os ot ou ov ow ox oy ki oz kj pa kl pb km pc ko pd kp pe pf bi translated">二。节点标记</h1><blockquote class="pg ph pi"><p id="29b9" class="lo lp pj lq b lr ls kd lt lu lv kg lw pk ly lz ma pl mc md me pm mg mh mi mj im bi translated"><em class="it">给定一个图，其中一些节点没有被标记，我们想要预测它们的标记。这在某种意义上是一个半监督学习问题。</em></p></blockquote><p id="0ba5" class="pw-post-body-paragraph lo lp it lq b lr ls kd lt lu lv kg lw lx ly lz ma mb mc md me mf mg mh mi mj im bi translated">处理这类问题的一个常见方法是假设图上有某个<strong class="lq jd">平滑度</strong>。<em class="pj">平滑假设</em>指出，通过数据上高密度区域的路径连接的点<em class="pj">可能具有相似的标签</em>。这是<strong class="lq jd">标签传播算法</strong>背后的主要假设。</p><p id="7a43" class="pw-post-body-paragraph lo lp it lq b lr ls kd lt lu lv kg lw lx ly lz ma mb mc md me mf mg mh mi mj im bi translated">标签传播算法(LPA)是一种快速算法，用于仅使用网络结构作为其向导来在图中发现社区，而不需要任何预定义的目标函数或关于社区的先验信息。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi qn"><img src="../Images/461e58d6900734fadb1209b39fb5e16e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*kJf4iuXMQEtGv4Hg6UkNJw.png"/></div></div><figcaption class="ld le gj gh gi lf lg bd b be z dk">Neo4J Illustration of LPA</figcaption></figure><p id="613d" class="pw-post-body-paragraph lo lp it lq b lr ls kd lt lu lv kg lw lx ly lz ma mb mc md me mf mg mh mi mj im bi translated">单个标签可以在连接密集的节点群中迅速占据主导地位，但在穿越连接稀疏的区域时会遇到困难。</p><p id="e48c" class="pw-post-body-paragraph lo lp it lq b lr ls kd lt lu lv kg lw lx ly lz ma mb mc md me mf mg mh mi mj im bi translated">半监督标签传播是如何工作的？</p><p id="0855" class="pw-post-body-paragraph lo lp it lq b lr ls kd lt lu lv kg lw lx ly lz ma mb mc md me mf mg mh mi mj im bi translated">首先我们有一些数据:x1，…，xl，xl+1，…，xn ∈ Rp，前 l 个点的标签:y1，…，yl ∈ 1…C。</p><p id="0602" class="pw-post-body-paragraph lo lp it lq b lr ls kd lt lu lv kg lw lx ly lz ma mb mc md me mf mg mh mi mj im bi translated">我们定义初始标签矩阵 Y ∈ R(n×C ),使得如果 xi 具有标签 yi=j，则 Yij=1，否则为 0。</p><p id="f992" class="pw-post-body-paragraph lo lp it lq b lr ls kd lt lu lv kg lw lx ly lz ma mb mc md me mf mg mh mi mj im bi translated">该算法将生成一个预测矩阵 F∈R(n×C ),我们将在下面详述。然后，我们通过找到最可能的标签来预测节点的标签:</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi qo"><img src="../Images/e7a1c008af01b0feaed3a77d1004f967.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*2ZuW6l9zdQyGQeBewTIdIw.png"/></div></div></figure><p id="bdf9" class="pw-post-body-paragraph lo lp it lq b lr ls kd lt lu lv kg lw lx ly lz ma mb mc md me mf mg mh mi mj im bi translated">什么是预测矩阵 F？</p><p id="2759" class="pw-post-body-paragraph lo lp it lq b lr ls kd lt lu lv kg lw lx ly lz ma mb mc md me mf mg mh mi mj im bi translated">预测矩阵是最小化平滑度和准确度标准的矩阵 F*。因此，在我们的结果的平滑度和准确性之间有一个折衷。</p><p id="595f" class="pw-post-body-paragraph lo lp it lq b lr ls kd lt lu lv kg lw lx ly lz ma mb mc md me mf mg mh mi mj im bi translated">问题表达比较复杂，就不赘述了。然而，解决方案由下式给出:</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi qp"><img src="../Images/368e18c5092ae66f1686566bde43b210.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Abws_-eSApriKsxLeCXzJg.png"/></div></div></figure><p id="a209" class="pw-post-body-paragraph lo lp it lq b lr ls kd lt lu lv kg lw lx ly lz ma mb mc md me mf mg mh mi mj im bi translated">如果你想在这个主题上更进一步，检查图函数的光滑性和流形正则化的概念。这部分的实现我就不赘述了，不过如果你感兴趣的话，斯坦福有一组很棒的带标签的图可以下载:<a class="ae qq" href="https://snap.stanford.edu/data/" rel="noopener ugc nofollow" target="_blank">https://snap.stanford.edu/data/</a>，Networkx 有一个标签传播的直接实现:<a class="ae qq" href="https://networkx.github.io/documentation/latest/reference/algorithms/generated/networkx.algorithms.community.label_propagation.label_propagation_communities.html" rel="noopener ugc nofollow" target="_blank">https://Networkx . github . io/documentation/latest/reference/algorithms/generated/Networkx . algorithms . community . label _ propagation . label _ propagation _ communities . html</a></p><h1 id="a95d" class="op oh it bd oq or os ot ou ov ow ox oy ki oz kj pa kl pb km pc ko pd kp pe pf bi translated">三。图形嵌入</h1><p id="6d46" class="pw-post-body-paragraph lo lp it lq b lr qa kd lt lu qb kg lw lx qc lz ma mb qd md me mf qe mh mi mj im bi translated">当处理 NLP 或计算机视觉问题时，我们习惯于在深度神经网络中嵌入图像或文本。到目前为止，我们所看到的图形的局限性之一是缺少矢量特征。但是，我们可以学习图的一个嵌入！图中有几个嵌入级别:</p><ul class=""><li id="4ba0" class="mt mu it lq b lr ls lu lv lx mv mb mw mf mx mj my mz na nb bi translated">嵌入图形组件(节点、边、特征…) ( <a class="ae qq" href="https://snap.stanford.edu/node2vec/" rel="noopener ugc nofollow" target="_blank"> Node2Vec </a>)</li><li id="438c" class="mt mu it lq b lr nc lu nd lx ne mb nf mf ng mj my mz na nb bi translated">嵌入图的子部分或整个图(<a class="ae qq" href="https://arxiv.org/abs/1707.05005" rel="noopener ugc nofollow" target="_blank"> Graph2Vec </a>)</li></ul><h2 id="b916" class="og oh it bd oq pq pr dn ou ps pt dp oy lx pu pv pa mb pw px pc mf py pz pe iz bi translated">1.节点嵌入</h2><p id="dab1" class="pw-post-body-paragraph lo lp it lq b lr qa kd lt lu qb kg lw lx qc lz ma mb qd md me mf qe mh mi mj im bi translated">我们将首先关注图组件的嵌入。有几种方法可以嵌入节点或边。例如，<a class="ae qq" href="http://www.perozzi.net/projects/deepwalk/" rel="noopener ugc nofollow" target="_blank"> DeepWalk </a>使用短时间的随机行走来学习图中边的表示。我们会谈到<a class="ae qq" href="https://snap.stanford.edu/node2vec/" rel="noopener ugc nofollow" target="_blank"> Node2Vec </a>，一篇由来自斯坦福大学的 Aditya Grover 和 Jure Leskovec 于 2016 年发表的论文。</p><p id="03e0" class="pw-post-body-paragraph lo lp it lq b lr ls kd lt lu lv kg lw lx ly lz ma mb mc md me mf mg mh mi mj im bi translated">根据作者的说法:“<strong class="lq jd"> node2vec </strong>是一个在图上进行表征学习的算法框架。给定任何图形，它都可以学习节点的连续特征表示，然后可以用于各种下游机器学习任务。”</p><p id="f296" class="pw-post-body-paragraph lo lp it lq b lr ls kd lt lu lv kg lw lx ly lz ma mb mc md me mf mg mh mi mj im bi translated">该模型通过使用<strong class="lq jd">随机行走</strong>优化邻域保持目标来学习节点的低维表示。</p><p id="a3b7" class="pw-post-body-paragraph lo lp it lq b lr ls kd lt lu lv kg lw lx ly lz ma mb mc md me mf mg mh mi mj im bi translated">Node2Vec 的代码在 GitHub 上有:<a class="ae qq" href="https://github.com/eliorc/node2vec" rel="noopener ugc nofollow" target="_blank">https://github.com/eliorc/node2vec</a></p><p id="ad09" class="pw-post-body-paragraph lo lp it lq b lr ls kd lt lu lv kg lw lx ly lz ma mb mc md me mf mg mh mi mj im bi translated">要安装该软件包，只需运行:</p><pre class="ks kt ku kv gt ob oc od oe aw of bi"><span id="a386" class="og oh it oc b gy oi oj l ok ol">pip install node2vec</span></pre><p id="f65c" class="pw-post-body-paragraph lo lp it lq b lr ls kd lt lu lv kg lw lx ly lz ma mb mc md me mf mg mh mi mj im bi translated">然后，在你的笔记本上，我们会嵌入空手道图:</p><pre class="ks kt ku kv gt ob oc od oe aw of bi"><span id="de4f" class="og oh it oc b gy oi oj l ok ol">from node2vec import Node2Vec</span></pre><p id="bd94" class="pw-post-body-paragraph lo lp it lq b lr ls kd lt lu lv kg lw lx ly lz ma mb mc md me mf mg mh mi mj im bi translated">然后，预先计算概率并生成行走:</p><pre class="ks kt ku kv gt ob oc od oe aw of bi"><span id="01d4" class="og oh it oc b gy oi oj l ok ol">node2vec = Node2Vec(G_karate, dimensions=64, walk_length=30, num_walks=200, workers=4)</span></pre><p id="8ff9" class="pw-post-body-paragraph lo lp it lq b lr ls kd lt lu lv kg lw lx ly lz ma mb mc md me mf mg mh mi mj im bi translated">然后我们可以嵌入节点:</p><pre class="ks kt ku kv gt ob oc od oe aw of bi"><span id="9994" class="og oh it oc b gy oi oj l ok ol">model = node2vec.fit(window=10, min_count=1, batch_words=4)</span></pre><p id="f7bd" class="pw-post-body-paragraph lo lp it lq b lr ls kd lt lu lv kg lw lx ly lz ma mb mc md me mf mg mh mi mj im bi translated">要获得一个节点的向量，比如说节点“2”，使用 get_vector:</p><pre class="ks kt ku kv gt ob oc od oe aw of bi"><span id="6934" class="og oh it oc b gy oi oj l ok ol">model.wv.get_vector(‘2’)</span></pre><p id="4857" class="pw-post-body-paragraph lo lp it lq b lr ls kd lt lu lv kg lw lx ly lz ma mb mc md me mf mg mh mi mj im bi translated">结果具有以下形式:</p><pre class="ks kt ku kv gt ob oc od oe aw of bi"><span id="013a" class="og oh it oc b gy oi oj l ok ol">array([-0.03066591,  0.52942747, -0.14170371,  0.5471569 ,  0.07588464, -0.5693364 , -0.3017375 ,  0.21902356,  0.05244258 ...</span></pre><p id="a402" class="pw-post-body-paragraph lo lp it lq b lr ls kd lt lu lv kg lw lx ly lz ma mb mc md me mf mg mh mi mj im bi translated">因为我们在上面将维度定义为 64，所以它的长度为 64。我们能用这种嵌入做什么？例如，第一选项之一是识别最相似的节点！</p><pre class="ks kt ku kv gt ob oc od oe aw of bi"><span id="3ea0" class="og oh it oc b gy oi oj l ok ol">model.wv.most_similar(‘2’)</span></pre><p id="678c" class="pw-post-body-paragraph lo lp it lq b lr ls kd lt lu lv kg lw lx ly lz ma mb mc md me mf mg mh mi mj im bi translated">它返回最相似节点和相应概率的列表:</p><pre class="ks kt ku kv gt ob oc od oe aw of bi"><span id="18d4" class="og oh it oc b gy oi oj l ok ol">[('3', 0.6494477391242981),<br/> ('13', 0.6262941360473633),<br/> ('7', 0.6137452721595764),<br/>...</span></pre><p id="6e66" class="pw-post-body-paragraph lo lp it lq b lr ls kd lt lu lv kg lw lx ly lz ma mb mc md me mf mg mh mi mj im bi translated">如果节点有标签，我们可以训练一个基于嵌入的算法并附加一个标签(节点标签，最相似节点…)</p><h2 id="71e9" class="og oh it bd oq pq pr dn ou ps pt dp oy lx pu pv pa mb pw px pc mf py pz pe iz bi translated">2.边缘嵌入</h2><p id="f072" class="pw-post-body-paragraph lo lp it lq b lr qa kd lt lu qb kg lw lx qc lz ma mb qd md me mf qe mh mi mj im bi translated">边缘也可以被嵌入，并且嵌入可以进一步用于分类。</p><pre class="ks kt ku kv gt ob oc od oe aw of bi"><span id="102e" class="og oh it oc b gy oi oj l ok ol">from node2vec.edges import HadamardEmbedder<br/>edges_embs = HadamardEmbedder(keyed_vectors=model.wv)</span></pre><p id="53c6" class="pw-post-body-paragraph lo lp it lq b lr ls kd lt lu lv kg lw lx ly lz ma mb mc md me mf mg mh mi mj im bi translated">然后，通过指定两个链接节点的名称来检索向量:</p><pre class="ks kt ku kv gt ob oc od oe aw of bi"><span id="c871" class="og oh it oc b gy oi oj l ok ol">edges_embs[(‘1’, ‘2’)]</span></pre><p id="12ef" class="pw-post-body-paragraph lo lp it lq b lr ls kd lt lu lv kg lw lx ly lz ma mb mc md me mf mg mh mi mj im bi translated">哪些标题:</p><pre class="ks kt ku kv gt ob oc od oe aw of bi"><span id="442e" class="og oh it oc b gy oi oj l ok ol">array([-8.1781112e-03, -1.8037426e-01,  4.9451444e-02,  2.8731486e-01...</span></pre><p id="ea08" class="pw-post-body-paragraph lo lp it lq b lr ls kd lt lu lv kg lw lx ly lz ma mb mc md me mf mg mh mi mj im bi translated">同样，我们可以检索最相似的边，这可用于缺失边预测，例如:</p><pre class="ks kt ku kv gt ob oc od oe aw of bi"><span id="8be9" class="og oh it oc b gy oi oj l ok ol">edges_kv = edges_embs.as_keyed_vectors()<br/>edges_kv.most_similar(str((‘1’, ‘2’)))</span></pre><p id="cbfb" class="pw-post-body-paragraph lo lp it lq b lr ls kd lt lu lv kg lw lx ly lz ma mb mc md me mf mg mh mi mj im bi translated">这个标题是:</p><pre class="ks kt ku kv gt ob oc od oe aw of bi"><span id="7c36" class="og oh it oc b gy oi oj l ok ol">[("('2', '21')", 0.8726599216461182),<br/> ("('2', '7')", 0.856759786605835),<br/> ("('2', '3')", 0.8566413521766663),<br/>...</span></pre><h2 id="4707" class="og oh it bd oq pq pr dn ou ps pt dp oy lx pu pv pa mb pw px pc mf py pz pe iz bi translated">3.图形嵌入</h2><p id="d004" class="pw-post-body-paragraph lo lp it lq b lr qa kd lt lu qb kg lw lx qc lz ma mb qd md me mf qe mh mi mj im bi translated">也有直接嵌入图或子图的方法。这种方法是在<a class="ae qq" href="https://arxiv.org/abs/1707.05005" rel="noopener ugc nofollow" target="_blank"> Graph2Vec </a>论文中开发的，可用于将图形或子图形表示为向量，从而允许图形分类或图形相似性度量。我不会深入研究这种技术，但是可以随意查看这个项目的 Github:</p><div class="nh ni gp gr nj nk"><a href="https://github.com/benedekrozemberczki/graph2vec" rel="noopener  ugc nofollow" target="_blank"><div class="nl ab fo"><div class="nm ab nn cl cj no"><h2 class="bd jd gy z fp np fr fs nq fu fw jc bi translated">benedekrozemberczki/graph2vec</h2><div class="nr l"><h3 class="bd b gy z fp np fr fs nq fu fw dk translated">《graph2vec:学习图的分布式表示》(MLGWorkshop 2017)的并行实现。…</h3></div><div class="ns l"><p class="bd b dl z fp np fr fs nq fu fw dk translated">github.com</p></div></div><div class="nt l"><div class="qr l nv nw nx nt ny lb nk"/></div></div></a></div><p id="87be" class="pw-post-body-paragraph lo lp it lq b lr ls kd lt lu lv kg lw lx ly lz ma mb mc md me mf mg mh mi mj im bi translated">要运行嵌入，非常简单:</p><pre class="ks kt ku kv gt ob oc od oe aw of bi"><span id="87fd" class="og oh it oc b gy oi oj l ok ol">python src/graph2vec.py --input-path data_folder/ --output-path output.csv</span></pre><h1 id="b2d3" class="op oh it bd oq or os ot ou ov ow ox oy ki oz kj pa kl pb km pc ko pd kp pe pf bi translated">四。更进一步</h1><p id="834e" class="pw-post-body-paragraph lo lp it lq b lr qa kd lt lu qb kg lw lx qc lz ma mb qd md me mf qe mh mi mj im bi translated">我们现在已经介绍了图的介绍、图的主要类型、不同的图算法、它们在 Python 和 Networkx 中的实现，以及用于节点标记、链接预测和图嵌入的图学习技术。</p><p id="92ec" class="pw-post-body-paragraph lo lp it lq b lr ls kd lt lu lv kg lw lx ly lz ma mb mc md me mf mg mh mi mj im bi translated">不用说，这只是冰山一角。图论正在不断扩展，我认为列出一些资源会有所帮助:</p><ul class=""><li id="8ae7" class="mt mu it lq b lr ls lu lv lx mv mb mw mf mx mj my mz na nb bi translated">图卷积网络:<a class="ae qq" rel="noopener" target="_blank" href="/how-to-do-deep-learning-on-graphs-with-graph-convolutional-networks-7d2250723780">https://towards data science . com/how-to-do-deep-learning-on-graphs-with-graph-convolutionary-Networks-7d 2250723780</a></li><li id="60aa" class="mt mu it lq b lr nc lu nd lx ne mb nf mf ng mj my mz na nb bi translated">图形和流形上的几何深度学习:【http://www.geometricdeeplearning.com/ T2】T3</li><li id="cce2" class="mt mu it lq b lr nc lu nd lx ne mb nf mf ng mj my mz na nb bi translated">一个可能有所帮助的 MOOC:<a class="ae qq" href="https://www.edx.org/course/advanced-algorithmics-and-graph-theory-with-python" rel="noopener ugc nofollow" target="_blank">https://www . EDX . org/course/advanced-algorithmics-and-graph-theory-with-python</a></li></ul><p id="0456" class="pw-post-body-paragraph lo lp it lq b lr ls kd lt lu lv kg lw lx ly lz ma mb mc md me mf mg mh mi mj im bi translated">如果你有任何你认为有用的资源，不要犹豫留下评论，我会把它添加到列表中！</p><p id="658c" class="pw-post-body-paragraph lo lp it lq b lr ls kd lt lu lv kg lw lx ly lz ma mb mc md me mf mg mh mi mj im bi translated">我希望这一系列的文章是有趣的后续！如果您有任何问题或意见，请随时评论。</p><p id="5333" class="pw-post-body-paragraph lo lp it lq b lr ls kd lt lu lv kg lw lx ly lz ma mb mc md me mf mg mh mi mj im bi translated">注:本文最初发表在我的个人博客:<a class="ae qq" href="https://maelfabien.github.io/ml/#" rel="noopener ugc nofollow" target="_blank">https://maelfabien.github.io/</a></p><h2 id="d73a" class="og oh it bd oq pq pr dn ou ps pt dp oy lx pu pv pa mb pw px pc mf py pz pe iz bi translated">来源:</h2><ul class=""><li id="0682" class="mt mu it lq b lr qa lu qb lx qs mb qt mf qu mj my mz na nb bi translated">Neo4j 中的图形算法综合指南</li><li id="326c" class="mt mu it lq b lr nc lu nd lx ne mb nf mf ng mj my mz na nb bi translated">网络 x 文档，<a class="ae qq" href="https://networkx.github.io/documentation/stable/" rel="noopener ugc nofollow" target="_blank">https://networkx.github.io/documentation/stable/</a></li><li id="5c2c" class="mt mu it lq b lr nc lu nd lx ne mb nf mf ng mj my mz na nb bi translated">巴黎电信的图论课程</li></ul></div></div>    
</body>
</html>