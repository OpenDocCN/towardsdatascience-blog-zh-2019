<html>
<head>
<title>K-Means Clustering in SAS</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">SAS 中的 k-均值聚类</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/k-means-clustering-in-sas-9d19efd4fb1b?source=collection_archive---------2-----------------------#2019-05-01">https://towardsdatascience.com/k-means-clustering-in-sas-9d19efd4fb1b?source=collection_archive---------2-----------------------#2019-05-01</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><figure class="gl gn jo jp jq jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi jn"><img src="../Images/dbfc95b29356106cb5df6785555f83ae.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*gB8j2VBZxO7T-3NS.png"/></div></div></figure><p id="ccc5" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated"><strong class="ka ir">什么是聚类？</strong></p><blockquote class="kw kx ky"><p id="9df8" class="jy jz kz ka b kb kc kd ke kf kg kh ki la kk kl km lb ko kp kq lc ks kt ku kv ij bi translated"><strong class="ka ir">“</strong>聚类是将数据集分成由相似数据点组成的组的过程”。聚类是一种无监督的机器学习，当您有未标记的数据时使用。</p></blockquote><p id="782c" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">让我们理解在真实的场景中，</p><p id="aaac" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">坐在餐馆里的一群食客。让我们假设餐馆里的两张桌子叫做 T1 和 T2。表 T1 中的人可能彼此相关，或者可能是一组家庭成员或同事或任何其他人。</p><figure class="le lf lg lh gt jr gh gi paragraph-image"><div class="gh gi ld"><img src="../Images/e6b458047df7b393f62d457a4f193d55.png" data-original-src="https://miro.medium.com/v2/resize:fit:1204/format:webp/1*40RRLkAUOLoRlIgFjZuHmA.png"/></div><figcaption class="li lj gj gh gi lk ll bd b be z dk">Group of diners</figcaption></figure><p id="71ed" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">同样，T2 餐桌上的人们可能是彼此相关的，或者可能是一组同事或任何东西。但是，当比较坐在 T1 桌的人和坐在 T2 桌的人时，他们是完全不同的，彼此没有任何联系。</p><p id="3fc0" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">集群也以同样的方式工作。一个群集中的数据点与另一个群集中的数据点完全不同。同一聚类中的所有点要么相同，要么彼此相关。</p><p id="869b" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">另一个很好的例子是网飞电影推荐。</p><figure class="le lf lg lh gt jr gh gi paragraph-image"><div class="gh gi ld"><img src="../Images/424b722a339044a334a8231748aff4a9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1204/format:webp/1*KdRSShIuGjyoCI48dIbO0g.png"/></div><figcaption class="li lj gj gh gi lk ll bd b be z dk">Netflix movie recommendation</figcaption></figure><p id="92bb" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">网飞根据用户的观看历史推荐电影。无论人们看什么；与之相关的类似电影也会上映。聚类算法生成所有这些推荐列表。</p><p id="81bc" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">聚类可用于分割和许多其他应用。它有不同的技术。K -Means 聚类是最流行、最简单和最有趣的算法之一。</p><h1 id="8021" class="lm ln iq bd lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj bi translated"><strong class="ak">什么是 K 均值聚类？</strong></h1><p id="f87e" class="pw-post-body-paragraph jy jz iq ka b kb mk kd ke kf ml kh ki kj mm kl km kn mn kp kq kr mo kt ku kv ij bi translated">K-Means 是一种聚类算法，其主要目标是将相似的元素或数据点分组到一个聚类中。<strong class="ka ir">K-means 中的“K”代表簇的个数。</strong></p><p id="95f5" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated"><strong class="ka ir"> K-means 聚类步骤:</strong></p><figure class="le lf lg lh gt jr gh gi paragraph-image"><div class="gh gi mp"><img src="../Images/70c44c2d772ba3b2c77a9b01d0a06615.png" data-original-src="https://miro.medium.com/v2/resize:fit:682/format:webp/1*QJjTHX3YgjY34AVsxTfJiQ.png"/></div></figure><p id="9561" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">距离度量将确定两个元素之间的相似性，并且它将影响聚类的形状。通常，欧几里德距离将用于 K-均值聚类</p><p id="4423" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">欧几里得距离是“普通的”直线。它是欧几里得空间中两点之间的距离。</p><figure class="le lf lg lh gt jr gh gi paragraph-image"><div class="gh gi ld"><img src="../Images/a22a9c1aa7ef129b505334f7b7126cc9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1204/format:webp/1*kRy0Zn3-fajLE3qoXXcYgw.png"/></div></figure><p id="6199" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated"><strong class="ka ir">K-Means 算法是如何工作的？</strong></p><p id="905d" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">我们来看两个数据点。假设 K =2。然后，它将在数据中的任意位置取两个随机质心，并以此为基础在中间画一条线。一个质心用红色表示，另一个用黄色表示。那么所有数据都指向分类为黄色的黄色质心。所有数据都指向分类为红色的红色质心。这是第一个迭代步骤。</p><figure class="le lf lg lh gt jr gh gi paragraph-image"><div class="gh gi mq"><img src="../Images/668018050b1976677c80df9c3d408253.png" data-original-src="https://miro.medium.com/v2/resize:fit:1284/format:webp/1*bLnWTOKWTfEQeEfbBqOyvw.png"/></div></figure><figure class="le lf lg lh gt jr gh gi paragraph-image"><div class="gh gi mr"><img src="../Images/e44eb7656404167221f1ae6b807cc004.png" data-original-src="https://miro.medium.com/v2/resize:fit:1200/format:webp/1*by8tUbkERdT_X15K19PE0g.png"/></div></figure><p id="a4a9" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">下一步，使用欧几里德方法计算从质心到数据点的距离。并且通过计算所有点的平均值，红色和黄色质心点都移动到新点中。</p><p id="bbb7" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">同样，它在新的质心点之间绘制一条新的线。自动地，所有落向红色质心的点将被识别为红色组，而黄色质心将被识别为黄色组。</p><figure class="le lf lg lh gt jr gh gi paragraph-image"><div class="gh gi ms"><img src="../Images/919cdac5cdedcd09c9bbb25fd8ebfb73.png" data-original-src="https://miro.medium.com/v2/resize:fit:700/format:webp/1*moz_QFK5l0WozObDdikEtA.png"/></div></figure><p id="c6a3" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">同样的步骤将重复新的点，它将计算新的质心。我们可以清楚地看到数据点已经被移动到不同的组中。</p><figure class="le lf lg lh gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi mt"><img src="../Images/5b8d2503fc76078d96c3f95aadfd790f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*-dtIMe1HUTF173WEImS19Q.png"/></div></div></figure><p id="5353" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">它继续下去，直到质心运动变得几乎可以忽略不计。然后，它变成集群 1 和集群 2。这里，输出 Y 标签将给出 0 和 1。0 表示聚类 1，1 表示聚类 2。如果是三个集群，那么它给出 0，1，2。</p><h1 id="99ff" class="lm ln iq bd lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj bi translated"><strong class="ak">SAS 中的 K-均值聚类</strong></h1><p id="0388" class="pw-post-body-paragraph jy jz iq ka b kb mk kd ke kf ml kh ki kj mm kl km kn mn kp kq kr mo kt ku kv ij bi translated">让我们看一个著名的虹膜数据集。使用 proc 方法检查数据集</p><pre class="le lf lg lh gt mu mv mw mx aw my bi"><span id="1bc1" class="mz ln iq mv b gy na nb l nc nd">/* Checking the contents of the datasets */</span><span id="70c3" class="mz ln iq mv b gy ne nb l nc nd"><strong class="mv ir">proc</strong> <strong class="mv ir">means</strong> data=work.iris N Nmiss mean median max min;</span><span id="210e" class="mz ln iq mv b gy ne nb l nc nd"><strong class="mv ir">run</strong>;</span></pre><figure class="le lf lg lh gt jr gh gi paragraph-image"><div class="gh gi nf"><img src="../Images/9dac010d1b630804fd3bdc7230daec2b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1136/format:webp/1*QdGM-NhBYvxSt_mfSTVpvw.png"/></div></figure><p id="a25a" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">它有 150 个观察值和 5 个变量。未检测到缺失值或异常值。我们将只使用四个变量，即萼片长度、萼片宽度、花瓣长度和花瓣宽度。“cm”中的数据集。“Target”变量可以删除，因为它是一个类别变量。</p><p id="0d82" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">关于鸢尾花数据集的小介绍。这是一个多元数据集，由英国<a class="ae ng" href="https://en.wikipedia.org/wiki/Statistician" rel="noopener ugc nofollow" target="_blank">统计学家</a>和<a class="ae ng" href="https://en.wikipedia.org/wiki/Biologist" rel="noopener ugc nofollow" target="_blank">生物学家</a> <a class="ae ng" href="https://en.wikipedia.org/wiki/Ronald_Fisher" rel="noopener ugc nofollow" target="_blank">罗纳德·费雪</a>在 1936 年为他的研究论文引入。下图是关于萼片和花瓣的。</p><figure class="le lf lg lh gt jr gh gi paragraph-image"><div class="gh gi nh"><img src="../Images/cca423c6f277675fc47a8974719be5ff.png" data-original-src="https://miro.medium.com/v2/resize:fit:770/format:webp/1*y7AlNg94t9Ark_f6o5jaZg.png"/></div></figure><p id="fae5" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">在分析数据集之前先了解它会很有意思。</p><pre class="le lf lg lh gt mu mv mw mx aw my bi"><span id="7184" class="mz ln iq mv b gy na nb l nc nd">/* Dropping the variable target and stored the dataset in the name of IRIS1 */</span><span id="e7b9" class="mz ln iq mv b gy ne nb l nc nd"><strong class="mv ir">data</strong> iris1;</span><span id="85d2" class="mz ln iq mv b gy ne nb l nc nd">    set work.iris;</span><span id="ac5e" class="mz ln iq mv b gy ne nb l nc nd">    drop target;</span><span id="9a7c" class="mz ln iq mv b gy ne nb l nc nd"><strong class="mv ir">run</strong>;</span></pre><p id="9cdb" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">在运行聚类分析之前，我们需要将所有的分析变量(实数变量)标准化到平均值为零，标准差为一(转换为 z 分数)。在这里，我们的数据集已经标准化了。</p><pre class="le lf lg lh gt mu mv mw mx aw my bi"><span id="5f0f" class="mz ln iq mv b gy na nb l nc nd">/* Perfoming Cluster Analysis */</span><span id="5be0" class="mz ln iq mv b gy ne nb l nc nd">ods graphics on;</span><span id="a4d8" class="mz ln iq mv b gy ne nb l nc nd"><strong class="mv ir">proc</strong> <strong class="mv ir">cluster</strong> data = iris1 method = centroid ccc print=<strong class="mv ir">15</strong> outtree=Tree;</span><span id="5d2c" class="mz ln iq mv b gy ne nb l nc nd">var sepal_length--petal_width;</span><span id="dcb2" class="mz ln iq mv b gy ne nb l nc nd"><strong class="mv ir">run</strong>;</span><span id="80d3" class="mz ln iq mv b gy ne nb l nc nd">ods graphics off;</span></pre><p id="2e32" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated"><strong class="ka ir"> METHOD = &gt; </strong>规范决定了过程使用的聚类方法。这里，我们使用的是质心方法。<br/><br/>CCC——立方聚类准则——有助于找出最佳聚类点。</p><figure class="le lf lg lh gt jr gh gi paragraph-image"><div class="gh gi ni"><img src="../Images/ae5c3b8f7d0f1d5b417da52012f50594.png" data-original-src="https://miro.medium.com/v2/resize:fit:884/format:webp/1*k35NPuN2lGP4ObBM7OlBJA.png"/></div></figure><p id="52ad" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">需要找出最佳的集群。</p><p id="f768" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">前三个特征值约占总方差的 99.48%，因此，建议采用三个聚类。但是，可以在 ccc 图中交叉检查。</p><figure class="le lf lg lh gt jr gh gi paragraph-image"><div class="gh gi ld"><img src="../Images/6d0c066a34635dd93c19a472ce6acb2e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1204/format:webp/1*3T3ZWKgdYCSAxs7nR9JSbg.png"/></div></figure><p id="a889" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">如果我们从集群历史中看到，有 15 个观察值(如我们在代码中给出的= 15)</p><figure class="le lf lg lh gt jr gh gi paragraph-image"><div class="gh gi nj"><img src="../Images/8860607bbd7892dec4f78cd5b7de6446.png" data-original-src="https://miro.medium.com/v2/resize:fit:1040/format:webp/1*PymzaqWNwK58ARDHtFu91w.png"/></div></figure><p id="e352" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">从上面的 CCC 图可以看出，肘在三点下降了。因此，最佳聚类将是 3。<strong class="ka ir">“在 Python 中的 Elbow 方法中可以找到最佳聚类”</strong></p><p id="dd7e" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">为了将 150 个观察值中的每个观察值分成三组，我们可以使用 proc tree。ncl = 3(我们的最佳聚类是 3)。</p><pre class="le lf lg lh gt mu mv mw mx aw my bi"><span id="b6a8" class="mz ln iq mv b gy na nb l nc nd">/* Retaining 3 clusters */</span><span id="e829" class="mz ln iq mv b gy ne nb l nc nd"><strong class="mv ir">proc</strong> <strong class="mv ir">tree</strong> noprint ncl=<strong class="mv ir">3</strong> out=out;</span><span id="06cd" class="mz ln iq mv b gy ne nb l nc nd">copy sepal_length--petal_width;</span><span id="a32e" class="mz ln iq mv b gy ne nb l nc nd"><strong class="mv ir">run</strong>;</span></pre><figure class="le lf lg lh gt jr gh gi paragraph-image"><div class="gh gi nk"><img src="../Images/d915e4e9205650b6957ea09480c3aacd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1068/format:webp/1*ZDUQSG5i_tnx56Zd55nqNw.png"/></div></figure><p id="a21d" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">150 次观察分为三组。</p><p id="0bc3" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">使用 proc candisc 和 proc sgplot 创建散点图</p><pre class="le lf lg lh gt mu mv mw mx aw my bi"><span id="f39b" class="mz ln iq mv b gy na nb l nc nd">/* To create a Scatterplot */</span><span id="f696" class="mz ln iq mv b gy ne nb l nc nd"><strong class="mv ir">proc</strong> <strong class="mv ir">candisc</strong> out = can;</span><span id="1636" class="mz ln iq mv b gy ne nb l nc nd">class cluster;</span><span id="9e0f" class="mz ln iq mv b gy ne nb l nc nd">var petal_width: sepal_length:;</span><span id="0bd6" class="mz ln iq mv b gy ne nb l nc nd"><strong class="mv ir">run</strong>;</span><span id="97ac" class="mz ln iq mv b gy ne nb l nc nd"><strong class="mv ir">proc</strong> <strong class="mv ir">sgplot</strong> data = can;</span><span id="6dec" class="mz ln iq mv b gy ne nb l nc nd">title "Cluster Analysis for IRIS datasets";</span><span id="1de8" class="mz ln iq mv b gy ne nb l nc nd">scatter y = can2 x = can1 / group = cluster;</span><span id="3d39" class="mz ln iq mv b gy ne nb l nc nd"><strong class="mv ir">run</strong>;</span></pre><figure class="le lf lg lh gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi ld"><img src="../Images/72265036a747dba5672bc2e46052c47c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1204/format:webp/1*b-ZRCHje1mWA0ByUQKV5Lg.png"/></div></div></figure><p id="f11d" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">我们可以看到，我们的分析清楚地分为三类。聚类 1 是蓝色的，聚类 2 是红色的，聚类 3 是绿色的。</p><p id="3f26" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated"><strong class="ka ir">K-means 聚类的优缺点</strong></p><p id="2adf" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated"><strong class="ka ir">优势:</strong></p><p id="8bf3" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">1)实际上工作良好，即使一些假设被打破。</p><p id="7908" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">2)简单，易于实现。</p><p id="03d7" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">3)易于解释聚类结果。</p><p id="75c1" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">4)在计算成本方面快速有效。</p><p id="0b39" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated"><strong class="ka ir">劣势:</strong></p><p id="2871" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">1)均匀效应通常产生具有相对均匀大小的聚类，即使输入数据具有不同的聚类大小。</p><p id="36d8" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">2)不同的密度对于集群可能效果不佳。</p><p id="e9c4" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">3)对异常值敏感。</p><p id="db18" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">4) K 值需要在 K-means 聚类之前知道。</p><p id="a66c" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">我的 GIT 里有完整的 SAS 代码【https://github.com/sdhilip200/IRIS-datasets T2】</p><p id="1087" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">如果您发现任何错误或需要改进的地方，请不吝赐教。</p></div></div>    
</body>
</html>