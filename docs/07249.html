<html>
<head>
<title>An Easier Way to Encode Categorical Features</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">一种编码分类特征的简单方法</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/an-easier-way-to-encode-categorical-features-d840ff6b3900?source=collection_archive---------9-----------------------#2019-10-12">https://towardsdatascience.com/an-easier-way-to-encode-categorical-features-d840ff6b3900?source=collection_archive---------9-----------------------#2019-10-12</a></blockquote><div><div class="fc ii ij ik il im"/><div class="in io ip iq ir"><figure class="it iu gq gs iv iw gi gj paragraph-image"><div role="button" tabindex="0" class="ix iy di iz bf ja"><div class="gi gj is"><img src="../Images/eca640159625e79814f04e14b593ca01.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Rcws6K8FP4aQhTpgGz9HXQ.jpeg"/></div></div><figcaption class="jd je gk gi gj jf jg bd b be z dk">Photo by <a class="ae jh" href="https://unsplash.com/@badashproducts?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank">Ash Edmonds</a> on <a class="ae jh" href="https://unsplash.com/s/photos/code?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><div class=""/><div class=""><h2 id="09f7" class="pw-subtitle-paragraph kh jj jk bd b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky dk translated">使用 python 类别编码器库处理机器学习中的高基数变量</h2></div><p id="5bf7" class="pw-post-body-paragraph kz la jk lb b lc ld kl le lf lg ko lh li lj lk ll lm ln lo lp lq lr ls lt lu in bi lv translated">我最近一直在做一个机器学习项目，这个项目有几个分类特征。这些要素中的许多都具有很高的基数，或者说，具有大量的唯一值。处理分类变量最简单的方法通常是执行<a class="ae jh" href="https://hackernoon.com/what-is-one-hot-encoding-why-and-when-do-you-have-to-use-it-e3c6186d008f" rel="noopener ugc nofollow" target="_blank">一键编码</a>，其中每个唯一值被转换成一个新列，用 1 或 0 表示该值的存在或不存在。然而，当一个特征的基数很高时，这种方法通常会产生太多的新特征，从而降低模型性能。</p><p id="24bb" class="pw-post-body-paragraph kz la jk lb b lc ld kl le lf lg ko lh li lj lk ll lm ln lo lp lq lr ls lt lu in bi translated">我开始编写自己的编码器，尝试用其他方法对一些特征进行编码，从所谓的证据权重开始。在二元分类问题中<a class="ae jh" href="https://www.listendata.com/2015/03/weight-of-evidence-woe-and-information.html" rel="noopener ugc nofollow" target="_blank">证据权重</a>使用正负类中特征的唯一值分布，并创建与这些值相关的新特征。自然，这需要一段时间来编码，然后让它在我现有的 scikit-learn 管道中工作。</p><p id="6083" class="pw-post-body-paragraph kz la jk lb b lc ld kl le lf lg ko lh li lj lk ll lm ln lo lp lq lr ls lt lu in bi translated">然后，我偶然发现了这个名为<a class="ae jh" href="http://contrib.scikit-learn.org/categorical-encoding/" rel="noopener ugc nofollow" target="_blank"> category_encoders </a>的库，它不仅有证据的权重，而且有几乎所有可能的方式来编码已经编写好并准备好使用的分类特征。这意味着我不再需要编写这个定制的编码器，我现在可以快速评估一大堆不同的编码器并选择最好的一个。在这篇文章中，我想分享这个库，并举例说明如何在<a class="ae jh" href="https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html" rel="noopener ugc nofollow" target="_blank"> scikit-learn 管道</a>中使用它。</p><h2 id="5481" class="me mf jk bd mg mh mi dn mj mk ml dp mm li mn mo mp lm mq mr ms lq mt mu mv mw bi translated">类别编码器</h2><p id="b441" class="pw-post-body-paragraph kz la jk lb b lc mx kl le lf my ko lh li mz lk ll lm na lo lp lq nb ls lt lu in bi translated">该库包含一组遵循 scikit-learn 风格的转换器，这意味着它们不仅可以单独使用，还可以在 scikit-learn 管道中使用。转换器提供了多种方法来转换分类数据，包括非常流行的 one-hot 编码。这个库对于处理高基数特性特别有用，在这种情况下，一次性编码方法可能会导致较差的模型性能。</p><p id="57bb" class="pw-post-body-paragraph kz la jk lb b lc ld kl le lf lg ko lh li lj lk ll lm ln lo lp lq lr ls lt lu in bi translated">让我们看一个使用中的例子。在下面的例子中，我使用的是从 UCI 机器学习库下载的<code class="fe nc nd ne nf b">adults</code>数据集。该数据包括每个人的一组特征和目标变量，该变量表示他们的年收入是低于还是高于 5 万美元。</p><p id="9d49" class="pw-post-body-paragraph kz la jk lb b lc ld kl le lf lg ko lh li lj lk ll lm ln lo lp lq lr ls lt lu in bi translated">该库可以通过 pip 安装。</p><pre class="ng nh ni nj gu nk nf nl nm aw nn bi"><span id="a031" class="me mf jk nf b gz no np l nq nr">pip install category_encoders</span></pre><p id="aa0e" class="pw-post-body-paragraph kz la jk lb b lc ld kl le lf lg ko lh li lj lk ll lm ln lo lp lq lr ls lt lu in bi translated">或者康达。</p><pre class="ng nh ni nj gu nk nf nl nm aw nn bi"><span id="b6e9" class="me mf jk nf b gz no np l nq nr">conda install -c conda-forge category_encoders</span></pre><p id="9369" class="pw-post-body-paragraph kz la jk lb b lc ld kl le lf lg ko lh li lj lk ll lm ln lo lp lq lr ls lt lu in bi translated">首先，这里是我正在使用的进口。</p><pre class="ng nh ni nj gu nk nf nl nm aw nn bi"><span id="3eb3" class="me mf jk nf b gz no np l nq nr">import pandas as pd<br/>import numpy as np</span><span id="167d" class="me mf jk nf b gz ns np l nq nr">from sklearn import preprocessing<br/>from sklearn.model_selection import train_test_split<br/>from sklearn.pipeline import Pipeline<br/>from sklearn.ensemble import RandomForestClassifier<br/>from sklearn.impute import SimpleImputer<br/>from sklearn.preprocessing import StandardScaler<br/>from sklearn.compose import ColumnTransformer<br/>from sklearn.metrics import f1_score<br/>import category_encoders as ce</span></pre><p id="bce2" class="pw-post-body-paragraph kz la jk lb b lc ld kl le lf lg ko lh li lj lk ll lm ln lo lp lq lr ls lt lu in bi translated">接下来，我将下载数据并将其转换成熊猫数据框。</p><pre class="ng nh ni nj gu nk nf nl nm aw nn bi"><span id="78c0" class="me mf jk nf b gz no np l nq nr">url_data = '<a class="ae jh" href="https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data'" rel="noopener ugc nofollow" target="_blank">https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data'</a><br/>column_names = ['age', 'workclass', 'fnlwgt', 'education', 'educational-num','marital-status',<br/>                'occupation', 'relationship', 'race', 'gender','capital-gain', 'capital-loss', <br/>                'hours-per-week', 'native-country','income']<br/>adults_data = pd.read_csv(url_data, names=column_names)</span></pre><p id="c59d" class="pw-post-body-paragraph kz la jk lb b lc ld kl le lf lg ko lh li lj lk ll lm ln lo lp lq lr ls lt lu in bi translated">然后，我为每个特征类型(分类的和数字的)创建一个变量，供以后在管道中使用，并将值分成测试和训练数据集。需要注意的一点是，尽管 scikit-learn 可以处理非数字目标变量，但 category_encoders 库不能。所以这里的一个额外步骤是使用<a class="ae jh" href="https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelEncoder.html" rel="noopener ugc nofollow" target="_blank">标签编码器</a>来转换 y 标签。</p><pre class="ng nh ni nj gu nk nf nl nm aw nn bi"><span id="e6c0" class="me mf jk nf b gz no np l nq nr">numeric_features = adults_data.select_dtypes(include=['int64', 'float64']).columns<br/>categorical_features = adults_data.select_dtypes(include=['object']).drop(['income'], axis=1).columns</span><span id="99da" class="me mf jk nf b gz ns np l nq nr">X = adults_data.drop('income', axis=1)<br/>y = adults_data['income']</span><span id="8680" class="me mf jk nf b gz ns np l nq nr">le = preprocessing.LabelEncoder()<br/>label_encoder = le.fit(y)<br/>y = label_encoder.transform(y)</span><span id="636c" class="me mf jk nf b gz ns np l nq nr">X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)</span></pre><p id="b307" class="pw-post-body-paragraph kz la jk lb b lc ld kl le lf lg ko lh li lj lk ll lm ln lo lp lq lr ls lt lu in bi translated">接下来，我运行下面的代码，它构建了一个管道，并循环遍历 category_encoders 列表，为每个模型打印分数。我使用了一个随机森林模型作为简单的例子。</p><pre class="ng nh ni nj gu nk nf nl nm aw nn bi"><span id="3171" class="me mf jk nf b gz no np l nq nr">encoder_list = [ce.backward_difference.BackwardDifferenceEncoder, <br/>               ce.basen.BaseNEncoder,<br/>               ce.binary.BinaryEncoder,<br/>                ce.cat_boost.CatBoostEncoder,<br/>                ce.hashing.HashingEncoder,<br/>                ce.helmert.HelmertEncoder,<br/>                ce.james_stein.JamesSteinEncoder,<br/>                ce.one_hot.OneHotEncoder,<br/>                ce.leave_one_out.LeaveOneOutEncoder,<br/>                ce.m_estimate.MEstimateEncoder,<br/>                ce.ordinal.OrdinalEncoder,<br/>                ce.polynomial.PolynomialEncoder,<br/>                ce.sum_coding.SumEncoder,<br/>                ce.target_encoder.TargetEncoder,<br/>                ce.woe.WOEEncoder<br/>                ]</span><span id="3c5e" class="me mf jk nf b gz ns np l nq nr">for encoder in encoder_list:<br/>    <br/>    numeric_transformer = Pipeline(steps=[<br/>    ('imputer', SimpleImputer(strategy='median')),<br/>    ('scaler', StandardScaler())])<br/>    categorical_transformer = Pipeline(steps=[<br/>    ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),<br/>    ('woe', encoder())])<br/>    <br/>    preprocessor = ColumnTransformer(<br/>    transformers=[<br/>        ('num', numeric_transformer, numeric_features),<br/>        ('cat', categorical_transformer, categorical_features)])<br/>    <br/>    pipe = Pipeline(steps=[('preprocessor', preprocessor),<br/>                      ('classifier', RandomForestClassifier(n_estimators=500))])<br/>    <br/>    model = pipe.fit(X_train, y_train)<br/>    <br/>    y_pred = model.predict(X_test)<br/>    print(encoder)<br/>    print(f1_score(y_test, y_pred, average='macro'))</span></pre><p id="7b6a" class="pw-post-body-paragraph kz la jk lb b lc ld kl le lf lg ko lh li lj lk ll lm ln lo lp lq lr ls lt lu in bi translated">输出如下。从下面可以看出，对于这个模型，顺序编码器给出了最好的分数，而留一编码器给出了最低的分数。</p><figure class="ng nh ni nj gu iw gi gj paragraph-image"><div role="button" tabindex="0" class="ix iy di iz bf ja"><div class="gi gj nt"><img src="../Images/b33127a4a30619a3e52e259603aab372.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*3LTsC4NqUE_erCwXD8gBOw.png"/></div></div></figure><p id="2666" class="pw-post-body-paragraph kz la jk lb b lc ld kl le lf lg ko lh li lj lk ll lm ln lo lp lq lr ls lt lu in bi translated">处理分类变量只是调整机器学习模型的一个方面，当然还有许多其他步骤。category_encoder 库提供了一种快速评估处理这些特性的不同方法的方法。在未来的项目中，我肯定会经常用到它。</p><p id="9db9" class="pw-post-body-paragraph kz la jk lb b lc ld kl le lf lg ko lh li lj lk ll lm ln lo lp lq lr ls lt lu in bi translated">感谢阅读！</p></div></div>    
</body>
</html>