# 机器学习:管理风险的实用指南

> 原文：<https://towardsdatascience.com/machine-learning-a-practical-guide-to-managing-risk-52624cf03f3a?source=collection_archive---------20----------------------->

## 本文的最终目的是让数据科学和合规团队能够创建更好、更准确、更合规的 ML 模型。

![](img/a4c257f6d3642d1d3e76299c3d74a72a.png)

Photo by [Riley McCullough](https://unsplash.com/@rileyhphotos?utm_source=medium&utm_medium=referral) on [Unsplash](https://unsplash.com?utm_source=medium&utm_medium=referral)

机器学习(ML)的使用越来越多，由此引发的一个基本问题正在迅速成为全球数据驱动型组织、数据科学家和法律人员面临的最大挑战之一。这一挑战以各种形式出现，从业者和学者也以各种方式进行了描述，但都与断言模型输入之间的因果关系以及输入数据如何影响模型输出的基本能力有关。

据贝恩公司称，未来几年，仅美国在自动化方面的投资就将接近 8 万亿美元，其中许多投资都是基于 ML 的最新进展。但是这些进步远远超过了管理这项技术的法律和道德框架。对于管理与洗钱相关的风险—*—法律的、声誉的、道德的等等——根本没有一个公认的框架。*

这篇文章旨在提供一个在实践中有效管理这种风险的模板，目的是为律师、合规人员、数据科学家和工程师提供一个框架，以安全地创建、部署和维护 ML 模型，并在这些不同的组织视角之间实现有效的沟通。本文的最终目的是让数据科学和合规团队能够创建更好、更准确、更合规的 ML 模型。

> **关键目标&三道防线**

涉及 ML 的项目从一开始就有明确的目标，将处于最有利的地位。为此，所有 ML 项目都应该从清晰记录的初始目标和潜在假设开始。这些目标还应包括主要的期望和不期望的结果，并应在所有关键利益相关方之间传阅。例如，数据科学家可能最适合描述关键的预期结果，而法律人员可能描述可能导致法律责任的具体的不期望的结果。这样的结果，包括适当用例的清晰边界，应该从任何 ML 项目的开始就很明显。此外，模型的预期消费者——从个人到采用其建议的系统——也应该明确指定。

一旦总体目标明确，就应该清楚地列出三道“防线”。防线—指数据科学家和其他参与创建、部署和审计 ML 过程的人员的角色和职责。例如，在整个模型生命周期中，多方的“有效挑战”作为一个关键步骤的重要性，必须与模型开发本身相区别。这些措施的最终目标是开发指导多层人员评估模型的过程，并确保模型的安全性。概括地说，第一条线集中于模型的开发和测试，第二条线集中于模型验证、法律和数据审查，第三条线集中于定期审计。防线应由以下五个角色组成:

*   **数据所有者:**负责模型使用的数据，通常被称为“数据库管理员”、“数据工程师”或“数据管家”
*   **数据科学家:**创建和维护模型。
*   **领域专家:**拥有模型所要解决的问题的专业知识，也被称为“企业所有者”
*   **验证者:**审核和批准由数据所有者和数据科学家创建的工作，重点关注技术准确性。通常，验证者是数据科学家，他们与手头的特定模型或项目无关。
*   **治理人员:**审查和批准由数据所有者和数据科学家创建的工作，重点关注法律风险。

一些组织依靠模型治理委员会(代表受特定模型部署影响的一系列利益相关者)来确保上述每个组的成员履行他们的职责，并且在部署任何模型之前，适当的防线已经就位。虽然有所帮助，但这种审查委员会也可能阻碍高效和可扩展的生产。因此，执行领导的模型评审委员会应该将他们的重点转移到围绕上述每个组的角色和职责的开发和实现过程上。这些委员会应在执行这些流程之前以及在定期的事后审计中制定和审查这些流程，而不是在部署之前单独审查每个模型。

至关重要的是，这些建议应该在不同的程度上实施，与每个模型相关的总体风险相一致。每个模型都有不可预见的风险，但有些部署比其他部署更有可能出现偏差并导致不良后果。因此，建议将审查的深度、强度和频率纳入特征因素，包括模型的预期用途和任何使用限制(如消费者选择退出的要求)、模型对个人权利的潜在影响、模型的成熟度、培训数据的质量、可解释性水平以及测试和审查的预测质量。

> 关注数据输入

一旦适当的角色和过程已经就位，在培训和部署期间，没有比理解模型所使用的数据更重要的风险管理方面了。在实践中，维护这种数据基础设施——从数据到模型的管道——是治理 ML 的最关键的方面之一，也是最容易被忽视的方面。一般来说，基础数据的有效风险管理应基于以下建议:

*   **记录模型需求:**所有模型都有需求——从数据的新鲜度，到所需的特定特性，到预期的用途，以及更多可能影响模型性能的需求，所有这些都需要清楚地记录下来。这使得验证者能够正确地审查每个项目，并确保模型可以随着时间的推移和跨人员进行维护。同样，数据依赖将不可避免地存在于将数据输入模型的周围系统中；如果存在这些依赖性，就应该对它们进行记录和监控。此外，文档应包括对个人身份信息的位置、原因、数据保护方式(通过加密、哈希或其他方式)以及数据可追溯性的讨论。
*   **数据质量评估:**了解输入模型的数据质量是模型风险的关键组成部分，应该包括对有效性、准确性、完整性、及时性、可用性、可再现性、一致性和来源的分析。许多风险管理框架依赖于所谓的“交通灯系统”来进行这种类型的评估，它利用红色、琥珀色和绿色来创建一个可视化的仪表板来表示这种评估。
*   **封装模型:**将模型从底层基础设施中分离出来，可以对模型本身和周围的流程进行严格的测试。为此，每个步骤——从配置到特性提取，再到服务基础设施等等——都应该清楚地记录下来，并且清楚地封装起来，这样调试和更新就不会太复杂。通常，这种复杂性随着模型部署周期的推移而增加，并且是使用 ML 的最大风险来源之一。
*   **底层数据监控:**应该监控输入数据以检测“数据漂移”，即生产数据不同于训练数据，重点是这种漂移如何影响模型性能。用于训练模型的数据应该以统计方式表示，并且在部署期间获取的数据应该与这种表示进行比较。还应该对模型进行彻底的留一要素评估，这可以突出基础数据中最具决定性的要素。这些评估可用于了解是否应格外小心地监控数据中的特定功能，以及模型可能不需要摄取的潜在未充分利用的功能。
*   **使警报具有可操作性:**监控底层数据允许检测模型行为中潜在的不期望的变化——但是监控只和现有的警报系统一样有用。建议警报会通知第一道防线中的数据所有者和数据科学家，并且会保存所有警报以用于记录目的，以便第二道防线和第三道防线的审查者可以审核警报是如何生成的以及它们是如何超时响应的。

> **使用模型输出数据作为进入模型的窗口**

了解模型的输出(在培训期间和部署后)对于监控其健康状况和任何相关风险至关重要。为此，建议数据所有者、数据科学家、验证者和治理人员:

*   **暴露偏差:**数据可能不准确地代表真实世界，例如当数据集以系统的方式忽略或隔离了一部分人口时。数据也可能以对特定群体有害的方式反映社会衍生的产物。因此，从模型中消除偏差并不总是可行的，而是寻求量化该偏差，并在可能的情况下将其最小化。对于人类受试者的数据，也许可以通过将私人持有的数据集与公共信息(如来自国家统计局的信息)相互参照来验证输出结果。在这种验证不可行的情况下，应用于数据的策略可能还需要限制敏感数据(如关于种族或性别的数据)，并且应该执行输出分析以检测敏感特征的潜在替代(如邮政编码)。干扰输入数据中的敏感特征，并使用生成的模型输出来确定模型对这些敏感特征的依赖程度，此外还检测充当代理的任何特征(如年龄)的存在。实际上，检测偏差需要对模型输入和输出进行混合数据分析。对偏差的评估应该发生在模型设计和实现的所有阶段，并且贯穿每一条防线。
*   **持续监控:**模型的输出应该以统计方式表示，就像模型接收的底层培训和部署数据一样。这将需要清楚地了解每个模型的决策存储在哪里，并在训练期间建立正确行为的统计“基础事实”。在某些情况下，这些表示将能够及时发现异常检测或模型不当行为。这些表示还有助于检测输入数据是否偏离了训练数据，并可以指示何时应该在刷新的数据集上重新训练模型。这些方法的全面影响将有所不同，例如，取决于模型在部署期间是否继续训练，以及许多其他因素，但它们将实现更快的风险评估、调试和更有意义的警报。
*   **检测反馈循环:**当一个模型的行为影响到它用来更新其参数的数据时，就会出现反馈循环。例如，当内容选择系统和广告选择系统存在于同一页面上，但是不共享参数并且没有被联合训练时，这可能发生。随着时间的推移，这两个选择系统会相互影响，尤其是当两个系统都在不断更新其内部参数时。检测这样的反馈循环可能具有挑战性并且耗时。部署多个模型的组织在监控模型输出时应该特别注意这种现象，这些模型可能会随着时间的推移而相互影响。
*   **记录所有测试:**所有此类分析和测试，尤其是侧重于模型中的偏差的测试，都应该清楚地记录下来——既可以作为尝试最小化或避免不希望的结果的证据，也可以帮助第二道和第三道防线的成员评估和理解项目的开发和潜在风险。测试文档应详细说明谁进行了测试、测试的性质、审查和响应过程，并描述测试发生的阶段。至关重要的是，第一道、第二道和第三道防线的每一个成员都应该很容易获得所有这些文档。使这个文档易于访问将有助于确保测试是彻底的，并将使参与模型部署的每个人清楚地理解相关的风险。

与上述关于底层数据转移的建议一样，可操作的警报也应该是监控模型输出的优先事项。这些警报必须由正确的人员接收，并且必须保存以备审计。

# 结论

有效的洗钱风险管理是一个持续的过程。虽然这篇文章关注的是单个模型的部署，但是在实践中可能会一次部署多个模型，或者同一个团队可能负责生产中的多个模型，所有这些模型都处于不同的阶段。因此，拥有一个所有相关人员都能轻松访问的模型清单至关重要。随着时间的推移，模型或底层数据或基础设施通常会发生变化，这些变化也应该很容易被发现。如上所述，某些更改应该会生成特定的警报。

在创建、测试、部署和审计生产 ML 的过程中，没有一个时间点可以将模型“认证”为没有风险。然而，有许多方法可以在整个生命周期中完整地记录和监控 ML，以保持风险可控，并使组织能够应对影响此风险的因素的波动。

为了取得成功，组织需要确保所有的内部利益相关者在模型的整个生命周期中都了解并参与其中。

*感谢你阅读我的帖子。*