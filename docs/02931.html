<html>
<head>
<title>Bot realtime object detection in Overwatch on Ubuntu 18.04</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">Ubuntu 18.04 上的机器人实时物体检测</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/bot-realtime-object-detection-in-overwatch-on-ubuntu-18-04-5571c4c85ec6?source=collection_archive---------17-----------------------#2019-05-12">https://towardsdatascience.com/bot-realtime-object-detection-in-overwatch-on-ubuntu-18-04-5571c4c85ec6?source=collection_archive---------17-----------------------#2019-05-12</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="d493" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">在本教程中，我会告诉你，如何安装 Overwatch，从你的实际游戏中收集图像数据，在上面训练模型，并将这个模型应用于实时物体检测。</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/1dd8b10d2c8eb81242e9c47b8ecbc115.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*V8tbW-YbHQEXF2gdf1nkBA.png"/></div></div></figure><p id="f3b3" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">为此，请确保您已经安装了 Tensorflow。最好有 GPU 支持，以获得更快的速度。没有它，你将会有更小的 fps，训练模型将会花费相当多的时间，并且实时性能可能无法实现。</p><p id="e97d" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated"><strong class="kt ir"> Part1:在 Ubuntu 18.04 上安装 Overwatch</strong></p><p id="56f2" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">在几次使用 Wine 和 DXVK 安装 Overwatch 的失败尝试后，我开始使用 Flatpak，它似乎很容易在 Linux 上运行 Windows 应用程序。事实也的确如此，除了驱动程序版本的特殊时刻。稍后将详细介绍。</p><p id="0882" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">在已安装的 Flatpak 和 Battle.net 启动器上运行这些命令:</p><pre class="kg kh ki kj gt ln lo lp lq aw lr bi"><span id="69ac" class="ls lt iq lo b gy lu lv l lw lx">sudo apt install flatpak <!-- -->gnome-software-plugin-flatpak<br/>sudo flatpak remote-add --if-not-exists flathub https:<strong class="lo ir">//</strong>dl.flathub.org<strong class="lo ir">/</strong>repo<strong class="lo ir">/</strong>flathub.flatpakrepo<br/>sudo flatpak remote-add --if-not-exists winepak https:<strong class="lo ir">//</strong>dl.winepak.org<strong class="lo ir">/</strong>repo<strong class="lo ir">/</strong>winepak.flatpakrepo<br/>sudo flatpak install winepak com.blizzard.Overwatch</span></pre><p id="1fec" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">重新启动电脑后，键入:</p><pre class="kg kh ki kj gt ln lo lp lq aw lr bi"><span id="5bbc" class="ls lt iq lo b gy lu lv l lw lx">sudo flatpak run com.blizzard.Overwatch</span></pre><p id="4bd9" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">你会看到:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ly"><img src="../Images/67a21fbceff14b443e4c2ae40a3cd9f7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*BZf7UYYwnVf-wnMlxPeIKA.png"/></div></div><figcaption class="lz ma gj gh gi mb mc bd b be z dk">Niiiice, aren’t?</figcaption></figure><p id="788d" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">为了更多的 FPS 和流畅的体验，你需要安装额外的 nvidia 驱动程序(因为现在游戏使用 OpenGL 引擎)。在少数情况下，没有图形驱动，游戏根本无法运行。</p><p id="25f2" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated"><strong class="kt ir">重要提示:</strong>您当前从 nvidia-smi 命令输出的版本和 flatpak 版本必须相同。否则，你会得到错误时，点击播放在看守部分在 Battle.net 发射器。请注意，你需要两个版本的 Flatpak 驱动程序。</p><p id="dc88" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">例如，目前我有这个版本的 nvidia 驱动程序:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi md"><img src="../Images/6ce9a9e87f3c826efa3a40c2a55e4d55.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Ywb872dfM4hvi2u5L1LWVg.png"/></div></div><figcaption class="lz ma gj gh gi mb mc bd b be z dk">Version of drivers: 410.104</figcaption></figure><p id="397e" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">下一步:我检查 Flatpak 中是否有该版本的驱动程序:</p><pre class="kg kh ki kj gt ln lo lp lq aw lr bi"><span id="cbc9" class="ls lt iq lo b gy lu lv l lw lx">flatpak remote-ls flathub | grep nvidia</span></pre><p id="9b32" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">是的，在 FlatHub 有 410-104 版本的 Nvidia 运行时包(不要在这里放屏幕，因为输出很大)。</p><p id="f82c" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">这样我就可以使用这些命令在 Flatpak 中安装 32 位和 64 位版本(提醒，您需要这两个版本！):</p><pre class="kg kh ki kj gt ln lo lp lq aw lr bi"><span id="1f32" class="ls lt iq lo b gy lu lv l lw lx">flatpak install flathub org.freedesktop.Platform.GL32.nvidia-410–104<br/>flatpak install flathub org.freedesktop.Platform.GL.nvidia-410-104</span></pre><p id="aabe" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">如果一切顺利，你就可以开始游戏了！</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/1dd8b10d2c8eb81242e9c47b8ecbc115.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*V8tbW-YbHQEXF2gdf1nkBA.png"/></div></div><figcaption class="lz ma gj gh gi mb mc bd b be z dk">Yeaaah!</figcaption></figure><p id="31f3" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">最后:为了录制和获得更舒适的 fps，进入选项-视频，选择窗口模式，1280*720 分辨率，30 fps 锁定和低设置。当你在玩警戒时，当模型一起工作时，这允许你在游戏中达到大约 30/3 = 10 fps 性能。是的，运行模型是一个详尽的过程，你的 GPU 会 100%的工作。实际上取决于你的 GPU。但在我的 1060 上这是真的。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/641be7770636e6ff5235bc762c3c38b1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*9v22HY1IO9SbVrcSv6Ka9A.png"/></div></div></figure><p id="c590" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">在本教程的下一部分，我将向你展示如何为你的模型获取训练数据，训练模型(如果你想的话)，并在游戏时进行实时检测。</p><p id="7c5f" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated"><strong class="kt ir">附言:</strong>如果你坚持选择正确的驱动程序，请查看这篇小文章(你也可以找到更多解释)如何克服这个问题:</p><div class="me mf gp gr mg mh"><a href="https://www.linuxuprising.com/2018/06/how-to-get-flatpak-apps-and-games-built.html" rel="noopener  ugc nofollow" target="_blank"><div class="mi ab fo"><div class="mj ab mk cl cj ml"><h2 class="bd ir gy z fp mm fr fs mn fu fw ip bi translated">如何让使用 OpenGL 构建的 Flatpak 应用和游戏与专有的 Nvidia 显卡一起工作…</h2><div class="mo l"><h3 class="bd b gy z fp mm fr fs mn fu fw dk translated">一些用 OpenGL 支持构建并打包成 Flatpak 的应用程序和游戏无法用专有的 Nvidia 启动…</h3></div><div class="mp l"><p class="bd b dl z fp mm fr fs mn fu fw dk translated">www.linuxuprising.com</p></div></div><div class="mq l"><div class="mr l ms mt mu mq mv kp mh"/></div></div></a></div><p id="6abf" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated"><strong class="kt ir">第二部分:记录游戏过程并准备训练图像</strong></p><p id="26dc" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">让我们安装这些库，它允许我们捕获游戏:</p><pre class="kg kh ki kj gt ln lo lp lq aw lr bi"><span id="2584" class="ls lt iq lo b gy lu lv l lw lx">pip3 install --user pyscreenshot<br/>pip3 install --user mss</span></pre><p id="be9a" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">安装 Overwatch 后，你可以使用 simplestream.py 实时记录游戏过程(大约 80-100 fps)</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mw mx l"/></div></figure><p id="0120" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">请看第 17 行:在这里您选择屏幕的一部分来捕获。你需要用显示器字典中的值来适应你的窗口游戏。请随意用值替换这一行代码，这样您会感觉最舒服。例如，我对它们进行了硬编码，并在屏幕中央设置了监视窗口；你可能更喜欢把窗口放在左上角等等。花几分钟在上面；你只能做一次。</p><p id="c9ef" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">只需在控制台中键入:</p><pre class="kg kh ki kj gt ln lo lp lq aw lr bi"><span id="677f" class="ls lt iq lo b gy lu lv l lw lx">python3 simplestream.py</span></pre><p id="3c66" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">回到游戏中。当你完成后，点击窗口框架，并按下 q。脚本完成，你可以在这里看到输出. avi 文件。那是你的玩法，会在哪个模型上训练。</p><p id="5767" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated"><strong class="kt ir">重要提示:</strong>您第一次可以使用 my repo 中的训练模型，不要制作图像、训练模型等(请跳过这一步，进入下一部分)。如果你会从结果中得到启发，欢迎使用你自己的数据来训练你自己的模型。</p><p id="23b9" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated"><strong class="kt ir">获取图像</strong></p><p id="b925" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">为了从 output.avi 中提取帧，你需要 ffmpeg:所以让我们安装它吧！</p><pre class="kg kh ki kj gt ln lo lp lq aw lr bi"><span id="915c" class="ls lt iq lo b gy lu lv l lw lx">pip3 install --user ffmpeg</span></pre><p id="9331" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">使用 ffmpeg 从创建的视频中获取帧(首先创建文件夹/图像！):</p><pre class="kg kh ki kj gt ln lo lp lq aw lr bi"><span id="222a" class="ls lt iq lo b gy lu lv l lw lx">ffmpeg -i output.avi -vf fps=10 images/thumb%04d.jpg -hide_banner</span></pre><p id="4c21" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">这让我们每秒钟从视频输出. avi 中获得 10 帧，并将这些帧(图像)保存在图像文件夹中。</p><p id="49c2" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated"><strong class="kt ir">用 python3 resizer.py 调整大小</strong></p><p id="5b86" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">你可以用 now resizer.py 让图片比现在更小。</p><pre class="kg kh ki kj gt ln lo lp lq aw lr bi"><span id="cdfe" class="ls lt iq lo b gy lu lv l lw lx">python3 resizer.py</span></pre><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mw mx l"/></div></figure><p id="dcc8" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">我评论了第 20 行，因为发现，分辨率 960*540 最适合初始分辨率在 1280*720 左右的图片。嘶！第 20 行和第 21 行做的东西一样，所以你可以用你最喜欢的那一行)。但是不要忘记评论另一行——否则你会破坏你的图像！(开个玩笑——在这种情况下，你将每张图片的大小调整两次，结果会非常糟糕)。</p><p id="0ded" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated"><strong class="kt ir">用标签标注</strong></p><p id="8e8c" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">我们来注释图像。为此，我建议使用标签。</p><pre class="kg kh ki kj gt ln lo lp lq aw lr bi"><span id="b3f2" class="ls lt iq lo b gy lu lv l lw lx">git clone <a class="ae my" href="https://github.com/tzutalin/labelImg.git" rel="noopener ugc nofollow" target="_blank">https://github.com/tzutalin/labelImg.git</a><br/>cd labelImg<br/>sudo apt-get install pyqt5-dev-tools<br/>sudo pip3 install -r requirements/requirements-linux-python3.txt<br/>make qt5py3<br/>python3 labelImg.py</span></pre><p id="f4b8" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">pip3 为什么不装 labelImg？因为我已经试过了，不能启动这个程序。所以从源代码安装只是一种方式，对我来说很有效。你可以试着从 pip3 安装，也许你可以启动它并节省几分钟。</p><p id="ad1f" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">我使用一个类“bot”来注释图像，因为我想检测 bot(显然，不是吗？).如果你想检测很多类，这部分消耗的时间会增加很多，因为你出错和选择错误类的机会很高(特别是当你在帧上有很多对象的时候)。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi mz"><img src="../Images/f140870630835c4ba84542d1070797ad.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Y-CgvWP6y32QZO7vJYox3w.png"/></div></div></figure><p id="b81a" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">因此，现在您需要注释 images/train 和 images/test 文件夹中的每个图像。这是耗时的部分，所以要冷静，专心，不要动作太快。</p><p id="0039" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated"><strong class="kt ir">重要:</strong>删除至少没有一个类的坏帧。如果您丢失了至少一个文件，您将无法为此图像创建注释。而且模型训练还没有开始，因为你将没有等量的图像和 xml 文件(注释)！</p><p id="f60a" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated"><strong class="kt ir">创建测试和训练目录</strong></p><p id="fc91" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">为此，使用 split.py:</p><pre class="kg kh ki kj gt ln lo lp lq aw lr bi"><span id="c5a9" class="ls lt iq lo b gy lu lv l lw lx">python3 split.py</span></pre><p id="9f50" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">此脚本中的代码:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mw mx l"/></div><figcaption class="lz ma gj gh gi mb mc bd b be z dk">Place this script in place, where exists images as subdirectory</figcaption></figure><p id="4182" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">之后，将 images 文件夹放在 object_detection 文件夹中，进入 tensorflow 部分(第 3 部分)。</p><p id="300c" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated"><strong class="kt ir">第三部分:张量流部分</strong></p><p id="5d4f" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">你可以跳过这一部分，第一次使用我训练过的模型(我在一个 github repo 上提供了所有文件)。在这两种情况下，您都需要安装这些库:</p><pre class="kg kh ki kj gt ln lo lp lq aw lr bi"><span id="641b" class="ls lt iq lo b gy lu lv l lw lx">pip3 install pillow<br/>pip3 install lxml<br/>pip3 install jupyter<br/>pip3 install matplotlib<br/>pip3 install opencv-python opencv-contrib-python<br/>sudo apt install protobuf-compiler</span></pre><p id="bd06" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">这部分是最费时间的，在这个过程中你会遇到很多问题。我的指南基于来自<a class="ae my" href="https://github.com/EdjeElectronics/TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10" rel="noopener ugc nofollow" target="_blank">的精彩教程。它适用于 windows 10，但区别并不太大。只有当你想用你自己的数据训练你自己的模型时(比如从 quickplay match 中检测 Hanzo ),你才可以做下面所有的步骤。</a></p><p id="9e0b" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">下载模型，重新加载原型，重新加载变量(别忘了把/home/Dmitry 改成/home/*your_username*/):</p><pre class="kg kh ki kj gt ln lo lp lq aw lr bi"><span id="87d1" class="ls lt iq lo b gy lu lv l lw lx">git clone <a class="ae my" href="https://github.com/tensorflow/models.git" rel="noopener ugc nofollow" target="_blank">https://github.com/tensorflow/models.git</a><br/>cd models-master/research<br/>protoc object_detection/protos/*.proto — python_out=.<br/>export PYTHONPATH=$PYTHONPATH:`pwd`:`pwd`/slim<br/>sudo gedit ~/.bashrc <br/>export PYTHONPATH=$PYTHONPATH=/home/dmitriy/models/research:/home/dmitriy/models/research/slim<br/>source ~/.bashrc</span></pre><p id="159d" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">来自研究目录:</p><pre class="kg kh ki kj gt ln lo lp lq aw lr bi"><span id="31ee" class="ls lt iq lo b gy lu lv l lw lx">sudo python3 setup.py build<br/>sudo python3 setup.py install</span></pre><p id="84f3" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">然后运行(在注释完所有图像后):</p><pre class="kg kh ki kj gt ln lo lp lq aw lr bi"><span id="a045" class="ls lt iq lo b gy lu lv l lw lx">python3 xml_to_csv.py</span></pre><p id="2bb5" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">这将在\object_detection\images 文件夹中创建一个 train_labels.csv 和 test_labels.csv 文件。在 generate_tfrecord.py 中进行更改。例如，我的文件:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mw mx l"/></div></figure><p id="f319" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">如您所见，您需要在第 30–35 行修改所有的类(在我的例子中是“bot”)。其他的你都不需要改变。之后(从 object_detection 文件夹):</p><pre class="kg kh ki kj gt ln lo lp lq aw lr bi"><span id="53be" class="ls lt iq lo b gy lu lv l lw lx">python3 generate_tfrecord.py --csv_input=images/train_labels.csv --image_dir=images/train --output_path=train.record<br/>python3 generate_tfrecord.py --csv_input=images/test_labels.csv --image_dir=images/test --output_path=test.record</span></pre><p id="e735" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">它们在\object_detection 中生成一个 train.record 和一个 test.record 文件。这些将用于训练新的对象检测分类器。</p><p id="bc2d" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">从 tensorflow zoo 下载模型作为配置，并放入 object_detection/training 文件夹:</p><pre class="kg kh ki kj gt ln lo lp lq aw lr bi"><span id="d308" class="ls lt iq lo b gy lu lv l lw lx">wget <a class="ae my" href="http://download.tensorflow.org/models/object_detection/faster_rcnn_inception_v2_coco_2018_01_28.tar.gz" rel="noopener ugc nofollow" target="_blank">http://download.tensorflow.org/models/object_detection/faster_rcnn_inception_v2_coco_2018_01_28.tar.gz</a><br/>tar xvzf faster_rcnn_inception_v2_coco_2018_01_28.tar.gz</span></pre><p id="9e0d" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">在 labelmap.pbtxt 中进行更改。例如，我的文件:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mw mx l"/></div></figure><p id="0bc5" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">所以，比如你想检测半藏类，就把 bot 改名为半藏。</p><p id="cf26" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">然后在 fast _ rcnn _ inception _ v2 _ pets . config 中进行更改。</p><p id="27e8" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">代码:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mw mx l"/></div></figure><p id="9f3d" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">我们开始吧:</p><p id="8897" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">将第 9 行的 num_classes 更改为您的类的总数。例如，如果我只想检测一个机器人，它将是 1；</p><p id="aa4a" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">在第 106 行将 fine_tune_checkpoint 更改为放置 fast _ rcnn _ inception _ v2 _ pets . config 的路径；</p><p id="1d93" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">在第 112 行 nums_steps 更改为你想要训练模型的多少(通常 10–20k 就够了)；</p><p id="f9eb" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">在第 122 行 input_path 处切换到您的 train.record 所在的位置；</p><p id="e11b" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">在第 124 行 label_map_path 更改为您的 labelmap.pbtxt 所在的位置；</p><p id="ea75" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">将第 128 行的 num_examples 更改为\images\test 目录中的图像数；</p><p id="a873" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">在第 136 行 input_path 处切换到您的 train.record 所在的位置；</p><p id="3124" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">在第 138 行 label_map_path 更改为 labelmap.pbtxt 所在的位置。</p><p id="7eee" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">请注意正确地更改这些路径！</p><p id="c607" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">并将这些文件(labelmap.pbtxt 和 faster _ rcnn _ inception _ v2 _ pets . config)放在 training 文件夹中。</p><p id="f87e" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">将 train.py 从旧文件夹移到主文件夹。</p><p id="f505" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">之后，你可以开始训练:</p><pre class="kg kh ki kj gt ln lo lp lq aw lr bi"><span id="db42" class="ls lt iq lo b gy lu lv l lw lx">python3 train.py --logtostderr --train_dir=training/ --pipeline_config_path=training/faster_rcnn_inception_v2_pets.config tensorboard --logdir=’training’</span></pre><p id="2d14" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">请确保 inference_graph 为空或未创建。</p><pre class="kg kh ki kj gt ln lo lp lq aw lr bi"><span id="6574" class="ls lt iq lo b gy lu lv l lw lx">python3 export_inference_graph.py --input_type image_tensor --pipeline_config_path training/faster_rcnn_inception_v2_pets.config --trained_checkpoint_prefix training/model.ckpt-10000 --output_directory inference_graph</span></pre><p id="d1c7" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">请随意将 model.ckpt-number_of_epochs 更改为您的号码。因此，如果您训练了 1000 个历元，请将 trained _ check point _ prefix training/model . ckpt-10000 更改为 trained _ check point _ prefix training/model . ckpt-1000。</p><p id="56b0" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">这将在\ object _ detection \ inference _ graph 文件夹中创建一个 freezed _ inference _ graph . Pb 文件。的。pb 文件包含对象检测分类器。</p><p id="18d2" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">对于教程的下一部分，您需要来自\object_detection\training 文件夹的 freezed _ inference _ graph 和 labelmap.pbtxt。还有 fast _ rcnn _ inception _ v2 _ pets . config，文件夹 protos，utils，training 和 core。</p><p id="c373" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">因此，在某个地方创建 object_detection 文件夹，并将其全部移入其中。现在，您已经准备好了最后一部分(第 4 部分:实时检测)。</p><p id="d63c" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated"><strong class="kt ir">第四部分:运行实时检测</strong></p><p id="d179" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">经过上述所有的艰苦工作，这一步成为最容易的一步。</p><p id="7eb7" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">如果你只是想测试训练模型，然后下载我的回购使用以下命令:</p><pre class="kg kh ki kj gt ln lo lp lq aw lr bi"><span id="2424" class="ls lt iq lo b gy lu lv l lw lx">git clone <a class="ae my" href="https://github.com/Oysiyl/Bot-object-detection-in-Overwatch.git" rel="noopener ugc nofollow" target="_blank">https://github.com/Oysiyl/Bot-object-detection-in-Overwatch.git</a></span></pre><p id="3865" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">然后将此文件夹重命名为 object_detection，并移动到此文件夹。</p><p id="2105" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">我建议你第一次运行 Object_detection_image.py，以确保一切正常。所以运行这些:</p><pre class="kg kh ki kj gt ln lo lp lq aw lr bi"><span id="bf32" class="ls lt iq lo b gy lu lv l lw lx">python3 Object_detection_image.py</span></pre><p id="20df" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">在等待初始化 Tensorflow 并将模型加载到 GPU 内存中大约 5-10 秒后，您将看到此图片，其中包含两个已识别的框(按 Q 退出):</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi na"><img src="../Images/0bc1278760012afa871391c6542b29e3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Pje27ydH6ZHuCKV0l-Bc6w.jpeg"/></div></div><figcaption class="lz ma gj gh gi mb mc bd b be z dk">I think, we might customize text on boxes later</figcaption></figure><p id="68da" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">以及检测到的箱子的坐标:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi md"><img src="../Images/8d60735f55fbe0584cfaba84d2754542.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_5afX3ljXLXoQW0wx-ME1A.png"/></div></div><figcaption class="lz ma gj gh gi mb mc bd b be z dk">So, bots are successfully detected. Niiice!</figcaption></figure><p id="9896" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">我们将在(realtime_detect_stream.py)之后运行的脚本代码:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mw mx l"/></div></figure><p id="d4ae" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">运行 realtime_detect_stream.py(要退出，请单击框架窗口并按 Q 键):</p><pre class="kg kh ki kj gt ln lo lp lq aw lr bi"><span id="a71b" class="ls lt iq lo b gy lu lv l lw lx">python3 realtime_detect_stream.py</span></pre><p id="2c72" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">如果你有超宽显示器或者只有第二台显示器，体验会更舒服。你会看到实时对象检测！我不能在这里显示一个漂亮的屏幕，因为我只有一个全高清显示器，实际上游戏窗口和识别游戏的窗口都不合适。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi mz"><img src="../Images/31606a3c7c2d49542c869368917ea106.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*oLRqv5Zjl07psEAhLPHNYA.png"/></div></div><figcaption class="lz ma gj gh gi mb mc bd b be z dk">Such that</figcaption></figure><p id="295d" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">小提示:您可以将 123 行更改为 cv2.resize(img，(300，300))并获得更健壮的图片(或选择更多少量的像素):</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi mz"><img src="../Images/a000d00bd49fa70b3e65c04c5d1b9910.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*CB50s8D4cTq2dHbGaU7K2g.png"/></div></div><figcaption class="lz ma gj gh gi mb mc bd b be z dk">You are almost see the whole picture</figcaption></figure><p id="d625" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">退出后，您会看到 output2.avi 文件已经创建。在这里，您可以观看视频，了解模型的表现:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nb mx l"/></div></figure><p id="a7a4" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated"><strong class="kt ir">额外部分:使用训练过的模型击败机器人</strong></p><p id="bf9b" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">嘶！确定谁是你的敌人后，你就可以打败他。所以，opencv 可以用机器人检测盒子的坐标。您可以使用 pyautogui 来击败他们！</p><pre class="kg kh ki kj gt ln lo lp lq aw lr bi"><span id="8876" class="ls lt iq lo b gy lu lv l lw lx">pip3 install --user pyautogui<br/>sudo apt-get install python3-tk python3-dev</span></pre><p id="37af" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">不同的距离对精确度有很大的影响。请看这个演示:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nb mx l"/></div></figure><p id="dad5" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">这是从更大的距离(我使用 WASD 接近目标):</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nb mx l"/></div></figure><p id="5bd9" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">我在鳏夫制造者身上测试过。所以，一秒钟的延迟让她可以毫无延迟地瞄准并打出有力的一击，而不是无力的一击。你只要向机器人走去，opencv 就会检测到机器人，并在他周围建一个盒子，然后程序就会尝试投篮。我用盒子中头部的可能位置来表示这一点，所以程序将继续移动相机到这一点，并在达到这一点后单击。</p><p id="4a36" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">请注意，使用 time.sleep(1.0)会导致在录制视频时损失 1 秒，因为程序暂停了 1 秒(10 fps)。你可以用 time.sleep(1.0)把这一行改成 pyautogui。PAUSE=1.0 并在单击返回到默认 pyautogui 设置后添加(通过以下方式— pyautogui。暂停=0.01)。我不建议你这么做，因为 programm accuracy 会做出一些奇怪的动作(比如向目标点移动时开枪)。使用这些方法的好处——当你瞄准时，你记录的视频将是完整的，不会丢失 10 fps (1 秒)。</p><p id="0ac1" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated"><strong class="kt ir">重要提示:</strong>要从 pyautogui 中获得正确的操作，您需要在游戏选项-视频-显示模式中进行更改，并设置为“无边框窗口”。如果没有这个程序，每次都不能正确的点击和移动你的相机到任意的位置。不要忘记，如果你想记录这个，你需要改变显示器字典(看第 116 行)，因为你的游戏窗口现在将是无边框窗口，而不是之前的窗口。</p><p id="cacf" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">这段代码插入 realtime_detect_stream.py 中的名称定义之后。如果你不知道在哪里添加，看看这个完整的例子:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mw mx l"/></div></figure><p id="49b7" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">重要代码行的简短说明:</p><p id="2d28" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">在行 152 中，我们仅选择通过 90%极限检测的盒子；第 167–181 行—找到盒子的坐标；使用 if 语句(第 183-185 行)每帧只需要选择和跟踪一个框。这很重要，因为如果模型检测到两个或更多的盒子，她会从一个跳到另一个，没有任何动作(但它的工作并不完美，有些问题)。</p><p id="355d" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">然后我们找到了中心 x 和中心 y 坐标——我们的模型将移动到这一点。用于移动计算的 moveX 和 moveY。如果移动得很大(第 191-194 行),我们将使这个移动变得更小——提高移动精度(第 195-198 行):如果模型接近目标(5 px 或更小),使下一个移动等于 0(因此不允许在这个轴上移动，在大于 5 的另一个轴上移动)。如果我们达到了“中心”，模型将执行我们假设的一组动作(第 204-212 行)。在这里你可以尝试使用 pyautogui。没有时间的暂停。睡眠(1.0)。如果我们还没有到达“中心”，那么根据当前摄像机位置的坐标执行移动(第 214-226 行)。</p><p id="74a2" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">在每一帧的下一行画一个圆(我们要移动的点)，并输出许多文本，直接放在你的帧上以便进一步监控(这非常非常有用，当出错时)。例如，当 defeat_bots.py 移动不是你无法理解的时候，那些监视输出可以帮助你看到，在下一帧中什么模型将做，哪些移动选择，接下来在哪个方向移动，多少像素...您可以注释这些输出(第 232–237 行)。</p><p id="233c" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">在第 240 行，opencv 将给定的帧保存到视频中，然后向您展示这一帧(第 241 行)。像往常一样，按键盘上的 Q 将停止程序，保存视频(第 250 行)后，opencv 将关闭(第 251 行)。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nc"><img src="../Images/740d0bd8423fcd7617f467c3a1c60305.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*rrkGUW2u1qHoHZ7W9vKIaA.png"/></div></div><figcaption class="lz ma gj gh gi mb mc bd b be z dk">Monitoring outputs in upper left corner</figcaption></figure><p id="2ea3" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">正如你从下面的图像中看到的，模型在中心射击机器人，并开始向下一个目标移动。这是我激活的 ult，程序现在不能这样做。我只是好奇 ult 是否在模型准确性上有所努力(但没有发现任何努力)。我用 WASD 组合按角色表演所有的动作。</p><p id="b2a9" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">运行 defeat_bots.py:</p><pre class="kg kh ki kj gt ln lo lp lq aw lr bi"><span id="d9ce" class="ls lt iq lo b gy lu lv l lw lx">python3 defeat_bots.py</span></pre><p id="afc9" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">像往常一样，去训练室值班。如果 opencv 检测到至少一个机器人——程序将使用鼠标移动相机到这个识别的边界框，并点击直到框消失(机器人被击败)。耶希！</p><p id="1aa2" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated"><strong class="kt ir">加成:</strong>在训练室其他英雄 vs bots 上测试并不难。例如，将第(204–212)行的动作更改为仅 pyautogui.click()允许您使用这样的字符，其主要攻击是左键单击:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nb mx l"/></div><figcaption class="lz ma gj gh gi mb mc bd b be z dk">Such as bastion (Beep-beep!)</figcaption></figure><p id="44d2" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">正如你所看到的，侦查并不依赖于所选的英雄，考虑到英雄的游戏性和他/她拥有的能力的差异，你可以为几乎任何你想要的英雄采用脚本。</p><p id="cc20" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated"><strong class="kt ir">重要:</strong>本文中的所有内容，尤其是额外部分，都是出于科学目的和我的好奇心。我不建议你用模型对抗其他玩家，因为:</p><p id="f2ac" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">零:当物体远离或者英雄只看到物体的一部分时，模型无法检测到。你需要训练模型理解效果(比如每个英雄的莱因哈特盾或者最后通牒能力)。</p><p id="66cf" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">第一:因为你需要在大约一千个(！！！)类认每个英雄(现在 30 左右)每个皮肤(不知道多少)。</p><p id="5e9e" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">第二:你需要在许多不同的地图上训练(因为不同的环境，在绿洲上训练的模型在南极洲几乎不工作)。</p><p id="64f6" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">第三:我的数据集有近 600 张图片，经过 1000 步训练，应该足以在一张没有任何皮肤的地图上检测一个类(机器人)(但你看这种检测远远不够理想)。想象一下，你需要创建和注释多少图像才能达到好的效果。以及训练时需要多少计算能力才能得到好的结果并达到至少每秒 60 帧的实时速度。</p><p id="d02f" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">第四:模特不能动！我不知道逻辑如何实现这一点。</p><p id="a2a1" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">此外，因为这是作弊，你可能应该被禁止，当与真人，而不是机器人玩。</p><p id="6476" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">希望你成功，这项工作将激励你从这个游戏或另一个(你最喜欢的)更有趣的模型。</p><p id="6357" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">祝你愉快，这是你应得的！</p></div></div>    
</body>
</html>