<html>
<head>
<title>Learning how to perform Twitter Sentiment Analysis</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">学习如何执行 Twitter 情绪分析</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/keras-challenges-the-avengers-541346acb804?source=collection_archive---------6-----------------------#2019-01-31">https://towardsdatascience.com/keras-challenges-the-avengers-541346acb804?source=collection_archive---------6-----------------------#2019-01-31</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><figure class="is it gp gr iu iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi ir"><img src="../Images/c1549bfac5f0e2a1e880cb873fb7475b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ex3gjAfvaV3Ub9Me7kYPXQ.png"/></div></div></figure><div class=""/><div class=""><h2 id="2ed0" class="pw-subtitle-paragraph kb jd je bd b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks dk translated">Keras 挑战复仇者联盟</h2></div></div><div class="ab cl kt ku hx kv" role="separator"><span class="kw bw bk kx ky kz"/><span class="kw bw bk kx ky kz"/><span class="kw bw bk kx ky"/></div><div class="im in io ip iq"><p id="b59a" class="pw-post-body-paragraph la lb je lc b ld le kf lf lg lh ki li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">情感分析，也称为意见挖掘，是自然语言处理中的一个有用工具，它允许我们识别、量化和研究主观信息。由于每天都会产生数十亿字节的数据，这种技术使我们有可能提取这些数据的属性，例如关于某个主题的负面或正面意见，以及关于正在谈论的主题和表达该意见的个人或实体的特征的信息。</p><p id="8bf3" class="pw-post-body-paragraph la lb je lc b ld le kf lf lg lh ki li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">Twitter 越来越受欢迎，如今，人们每天都在使用它来表达对不同话题的看法，如产品、电影、音乐、政治家、事件、社会事件等。每年都有很多电影上映，但如果你像我一样是漫威的粉丝，你可能会迫不及待地想最终观看新的《复仇者联盟》电影。就我个人而言，我想知道人们对此的感受。</p><p id="4df3" class="pw-post-body-paragraph la lb je lc b ld le kf lf lg lh ki li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">在之前的中，我们已经讨论了如何使用 Twitter API 来传输推文，并将其存储在关系数据库中。现在，我们将使用这些信息来执行情感分析。但在此之前，我们应该考虑一些事情。首先，我们使用“复仇者”这个词来发布推文，但没有任何额外的考虑。很有可能我们有成千上万条重复的推文。就情感分析而言，处理它们不会增加任何额外的价值，相反，它将是计算上昂贵的。因此，我们需要访问数据库，删除重复的推文，保留第一个事件。第二，我们有一个未标记的数据库。为了让模型在训练期间学习，我们应该声明推文是正面的还是负面的。理想的解决方案是手动标注数据集，这非常准确，但需要大量时间。然而，有几个选择<a class="ae lw" href="https://www.altexsoft.com/blog/datascience/how-to-organize-data-labeling-for-machine-learning-approaches-and-tools/" rel="noopener ugc nofollow" target="_blank"/>比如使用开源数据集标记工具，比如<a class="ae lw" href="https://stanfordnlp.github.io/CoreNLP/#human-languages-supported" rel="noopener ugc nofollow" target="_blank"> <em class="lx">斯坦福 CoreNLP </em> </a> <em class="lx">。</em></p><p id="1e08" class="pw-post-body-paragraph la lb je lc b ld le kf lf lg lh ki li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">有许多框架可以用于机器学习任务，但是，我们将使用<a class="ae lw" href="https://keras.io/" rel="noopener ugc nofollow" target="_blank"><strong class="lc jf"><em class="lx">Keras</em></strong></a><strong class="lc jf"><em class="lx"/></strong>，因为它<strong class="lc jf"> <em class="lx"> </em> </strong>提供了一致而简单的 API，最大限度地减少了所需的用户操作数量，更重要的是，它易于学习和使用。我们还将利用<a class="ae lw" href="https://www.nltk.org/" rel="noopener ugc nofollow" target="_blank"> <strong class="lc jf"> <em class="lx">自然语言工具包</em> </strong> </a> (NLTK)，它提供了许多语料库和词汇资源，这些资源将方便地用于标记、解析和语义推理，以及<a class="ae lw" href="https://scikit-learn.org/stable/" rel="noopener ugc nofollow" target="_blank"><strong class="lc jf"><em class="lx">Scikit-learn</em></strong></a>，它为数据挖掘和数据分析提供了有用的工具。</p><p id="abb8" class="pw-post-body-paragraph la lb je lc b ld le kf lf lg lh ki li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">准备好开始了吗？让我们看看 Keras 能从《复仇者联盟》中学到什么。</p><p id="912e" class="pw-post-body-paragraph la lb je lc b ld le kf lf lg lh ki li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">首先，我们需要检索之前存储在 PostgreSQL 数据库中的 tweets。为此，我们将利用<code class="fe ly lz ma mb b"><a class="ae lw" href="https://www.sqlalchemy.org/" rel="noopener ugc nofollow" target="_blank">sqlalchemy</a></code>，这是一个 Python SQL 工具包和对象关系映射器，允许我们以一种简单的方式连接和查询数据库。sqlalchemy 的一个特点是包含了最常见数据库的方言(它用来与数据库通信的系统)实现，比如 MySQL、SQLite 和 PostgreSQL 等等。我们将使用<code class="fe ly lz ma mb b">create_engine()</code>函数，该函数基于给定的数据库 URL 生成一个引擎对象，其典型形式如下:<code class="fe ly lz ma mb b">dialect+driver://username:password<strong class="lc jf">@host</strong>:port/database</code>。在我们的例子中，方言是 PostgreSQL，而驱动程序是 psycopg2。创建引擎对象后，我们将使用来自<code class="fe ly lz ma mb b">pandas</code>模块的函数<code class="fe ly lz ma mb b">read_sql_query</code>来查询数据库，以获取存储在我们的<code class="fe ly lz ma mb b">tweet </code>表中的所有数据(‘select * from tweet _ table’)并收集在<code class="fe ly lz ma mb b">DataFrame</code>中检索的信息:</p><figure class="mc md me mf gt iv"><div class="bz fp l di"><div class="mg mh l"/></div></figure><p id="d1b0" class="pw-post-body-paragraph la lb je lc b ld le kf lf lg lh ki li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">在我们深入分析“复仇者联盟”的公众意见之前，我们需要采取一个重要步骤:预处理推文文本。但这意味着什么呢？文本预处理包括遵循一组常用的简单规则的基本文本清理，但也包括考虑语法和词汇信息的高级技术。在我们的项目中，我们将执行以下步骤:</p><ul class=""><li id="4df9" class="mi mj je lc b ld le lg lh lj mk ln ml lr mm lv mn mo mp mq bi translated"><strong class="lc jf">使用</strong> <code class="fe ly lz ma mb b"><strong class="lc jf">.lower()</strong></code> <strong class="lc jf">函数</strong>将推文转换成小写，以使所有推文保持一致的形式。通过这样做，我们可以确保进一步的转换和分类任务不会受到数据中不一致或大小写敏感问题的影响。</li><li id="d2b5" class="mi mj je lc b ld mr lg ms lj mt ln mu lr mv lv mn mo mp mq bi translated"><strong class="lc jf">删除</strong> <code class="fe ly lz ma mb b"><strong class="lc jf">‘RT’</strong></code>、<strong class="lc jf">用户提及</strong>和<strong class="lc jf">链接:</strong>在 tweet 文本中，我们通常可以看到每一句都包含一个引用，它是一个转发(' RT ')、一个用户提及或一个 URL。因为它通过许多推文被重复，并且它没有给我们任何关于情绪的有用信息，我们可以删除它们。</li><li id="4796" class="mi mj je lc b ld mr lg ms lj mt ln mu lr mv lv mn mo mp mq bi translated"><strong class="lc jf">删除数字:</strong>同样，数字不包含任何情绪，因此从 tweet 文本中删除它们也是常见的做法。</li><li id="4110" class="mi mj je lc b ld mr lg ms lj mt ln mu lr mv lv mn mo mp mq bi translated"><strong class="lc jf">删除标点符号和特殊字符:</strong>因为这会生成高频率的标记，从而影响我们的分析，所以删除它们很重要。</li><li id="5b48" class="mi mj je lc b ld mr lg ms lj mt ln mu lr mv lv mn mo mp mq bi translated"><strong class="lc jf">替换拉长的单词:</strong>拉长的单词定义为包含两次以上重复字符的单词，例如<em class="lx">‘awesooome’。</em>替换这些单词非常重要，因为分类器会将它们视为与源单词不同的单词，从而降低它们的频率。但是，有一些英语单词包含重复的字符，主要是辅音，所以我们将使用 NLTK 中的 wordnet 来与英语词典进行比较。</li><li id="8e52" class="mi mj je lc b ld mr lg ms lj mt ln mu lr mv lv mn mo mp mq bi translated">移除停用词:停用词是在所有推文中出现频率很高的功能词。没有必要分析它们，因为它们没有提供有用的信息。我们可以从 NLTK stopwords 函数中获得这些单词的列表。</li><li id="1ad0" class="mi mj je lc b ld mr lg ms lj mt ln mu lr mv lv mn mo mp mq bi translated"><a class="ae lw" href="http://www.jcomputers.us/vol12/jcp1205-11.pdf" rel="noopener ugc nofollow" target="_blank"> <strong class="lc jf">用反义词处理否定</strong> </a> <strong class="lc jf"> : </strong>分析情绪时出现的一个问题就是处理否定及其对后续词语的影响。让我们举一个例子:假设我们找到了推文“我不喜欢这部电影”,我们丢弃了停用词，我们将去掉“我”和“没有”的词。所以最后，我们将得到“喜欢”和“电影”的标记，这与原始推文的意思相反。有几种处理否定的方法，并且有很多关于这个的研究正在进行；然而，对于这个项目，特别是，我们将扫描我们的推文，并用我们的否定词后面的名词、动词或形容词的反义词(我们将从 wordnet 的词条中获得)来替换。</li></ul><p id="71dd" class="pw-post-body-paragraph la lb je lc b ld le kf lf lg lh ki li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">在我们清理了数据之后，但在我们开始构建情绪分析模型之前，我们可以进行探索性的数据分析，看看在我们的“复仇者联盟”推文中出现最频繁的词是什么。对于这一部分，我们将展示关于被标记为正面的推文和被标记为负面的推文的图表。</p><p id="1f7e" class="pw-post-body-paragraph la lb je lc b ld le kf lf lg lh ki li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">首先，我们将使用 WordCloud 来表示所有推文中的单词使用情况，根据每个单词的频率按比例调整其大小。尽管出于不同的原因，这个图表似乎不是最合适的，但它提供了一个文本分析和一个关于哪种类型的词在我们的推文中出现得更频繁的总体想法。Python 有一个<code class="fe ly lz ma mb b"><a class="ae lw" href="http://amueller.github.io/word_cloud/" rel="noopener ugc nofollow" target="_blank">WordCloud</a></code>库，允许我们使用从硬盘上传的图像应用遮罩，选择背景、单词颜色图、最大字数、字体大小以及图形的其他特征。</p><figure class="mc md me mf gt iv"><div class="bz fp l di"><div class="mg mh l"/></div></figure><p id="fa0e" class="pw-post-body-paragraph la lb je lc b ld le kf lf lg lh ki li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">正面推文的 WordCloud:</p><figure class="mc md me mf gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi mw"><img src="../Images/fc42eb98af0e4bb1d1eccf564c188613.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*z2jnwPAOCVhpubNyWDHjYg.png"/></div></div></figure><p id="7d7e" class="pw-post-body-paragraph la lb je lc b ld le kf lf lg lh ki li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">负面推文的 WordCloud:</p><figure class="mc md me mf gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi mw"><img src="../Images/05410bd51a51e4090d73ba329954017d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*kxSkKv-0uMzOO0hL1E-53w.png"/></div></div></figure><p id="ca59" class="pw-post-body-paragraph la lb je lc b ld le kf lf lg lh ki li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">当我们观察正面推文的词云时，一些以较大尺寸出现的词没有特定的内涵，可以被解释为中性的，如“惊奇队长”、“无限战争”。另一方面，其他单词，即使有些较小，也可以被解释为在推文中具有积极的意义，如“好”、“很好”、“最好”和“喜欢”。相反，负面推文的 WordCloud 显示的大多是中性词，如“电影”、“残局”和带有负面内涵的非常小的词，如“从不”和“操”。</p><p id="b34a" class="pw-post-body-paragraph la lb je lc b ld le kf lf lg lh ki li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">之后，我们可以在一张图表中列出正面和负面推文中与“复仇者联盟”词语共现的 50 个最频繁的词。我们将从使用来自<code class="fe ly lz ma mb b">sklearn</code>的函数<code class="fe ly lz ma mb b">CountVectorizer</code>开始，该函数将把 tweets 的集合转换成令牌计数的矩阵，产生计数的稀疏表示。然后，我们对每个令牌的所有计数求和，获得频率，并将它们存储为数据帧。</p><figure class="mc md me mf gt iv"><div class="bz fp l di"><div class="mg mh l"/></div></figure><p id="df74" class="pw-post-body-paragraph la lb je lc b ld le kf lf lg lh ki li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">我们现在可以通过使用<code class="fe ly lz ma mb b">matplotlib</code>函数<code class="fe ly lz ma mb b">bar</code>在柱状图中绘制这些值。</p><figure class="mc md me mf gt iv"><div class="bz fp l di"><div class="mg mh l"/></div></figure><figure class="mc md me mf gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi ca"><img src="../Images/0587cb66febdbca02852e753bc8927b7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*sfkh5vOUPFOu35a4iadGhQ.png"/></div></div></figure><figure class="mc md me mf gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi mx"><img src="../Images/e87101a72619927639ae4e1f4dee2683.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*JrULxd1gs8T3J4LKmwdaCg.png"/></div></div></figure><p id="a75f" class="pw-post-body-paragraph la lb je lc b ld le kf lf lg lh ki li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">我们可以看到，正面和负面推文中的第一个常用词是:“漫威”、“残局”，此外，除了正面推文中的“好”、“太棒了”、“爱”、“最喜欢”和“最好”等词之外，大多数词都有中性的含义。</p><p id="0b9e" class="pw-post-body-paragraph la lb je lc b ld le kf lf lg lh ki li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">我们最终可以检查在正面和负面推文中出现的单词的频率之间是否有任何相关性。我们将连接两个词频数据帧，之后，我们将使用 seaborn <code class="fe ly lz ma mb b">regplot</code>图:</p><figure class="mc md me mf gt iv"><div class="bz fp l di"><div class="mg mh l"/></div></figure><figure class="mc md me mf gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi my"><img src="../Images/d0e876a92215353610aa4d45067b07a3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*EurGOPDo69mdC2lCV4ssDQ.png"/></div></div></figure><p id="0453" class="pw-post-body-paragraph la lb je lc b ld le kf lf lg lh ki li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">除了一两点看起来相关之外，从上面的图表中无法得出正面和负面推文中出现的单词之间有任何有意义的联系。</p><p id="29a6" class="pw-post-body-paragraph la lb je lc b ld le kf lf lg lh ki li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">在可视化我们的数据之后，下一步是将数据集分成训练集和测试集。为此，我们将利用<code class="fe ly lz ma mb b">sklearn</code>包的<code class="fe ly lz ma mb b">train_test_split</code>功能。我们将按照 20–80%规则抽取 20%的数据集进行测试。剩下的 80%用于训练集，我们将保留一部分用于验证我们的模型。</p><figure class="mc md me mf gt iv"><div class="bz fp l di"><div class="mg mh l"/></div></figure><p id="1026" class="pw-post-body-paragraph la lb je lc b ld le kf lf lg lh ki li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">我们还需要将我们的情感列转换成我们的模型可以理解的类别。我们将使用 0 代表负面，1 代表中性，2 代表正面。</p><figure class="mc md me mf gt iv"><div class="bz fp l di"><div class="mg mh l"/></div></figure><p id="c739" class="pw-post-body-paragraph la lb je lc b ld le kf lf lg lh ki li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">最后，我们需要使用<code class="fe ly lz ma mb b">TfidfVectorizer </code>处理我们的输入 tweet 列，这将把 tweet 的集合转换成一个术语频率/反转文档频率(TF-IDF)特征矩阵。这个函数非常关键的一点是，它将返回归一化的频率；特征归一化是构建机器学习算法的关键步骤。经过几次尝试，3500 是返回的最大特征数，它最适合我们的模型。</p><figure class="mc md me mf gt iv"><div class="bz fp l di"><div class="mg mh l"/></div></figure><p id="1047" class="pw-post-body-paragraph la lb je lc b ld le kf lf lg lh ki li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">现在，是时候建立我们的模型了:<em class="lx">一个神经网络</em>。如果不熟悉神经网络的工作原理，可以查看<a class="ae lw" rel="noopener" target="_blank" href="/understanding-neural-networks-what-how-and-why-18ec703ebd31">我之前的帖子</a>。幸运的是，Keras 使构建神经网络变得非常简单和容易，只需几行代码。</p><figure class="mc md me mf gt iv"><div class="bz fp l di"><div class="mg mh l"/></div></figure><p id="e904" class="pw-post-body-paragraph la lb je lc b ld le kf lf lg lh ki li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">让我们来剖析一下我们的模型:<code class="fe ly lz ma mb b">Sequential()</code>是一种由层组成的网络，这些层按照给出的顺序堆叠和执行。那么，我们有哪种类型的层？我们注意到，我们已经为我们的三个层(输入、隐藏和输出层)添加了<code class="fe ly lz ma mb b">Dense</code>层，这意味着一个层中的每个节点都接收来自前一层中所有节点的输入，实现了以下操作:<code class="fe ly lz ma mb b"><a class="ae lw" href="https://www.tensorflow.org/api_docs/python/tf/keras/layers/Dense" rel="noopener ugc nofollow" target="_blank">output = activation(dot(input, weights) + bias)</a></code>。在它们之间，我们使用了<code class="fe ly lz ma mb b">Dropout</code>方法，该方法采用一个介于 0 和 1 之间的浮点数(我们将把它作为<code class="fe ly lz ma mb b">drop</code>传递，稍后再进行调整),表示在训练期间将被随机丢弃的神经元部分，以防止过度拟合。关键层是输入层和输出层，因为它们将决定我们网络的形状，正确了解我们的期望是很重要的。因为我们将使用<code class="fe ly lz ma mb b">3500</code>作为矢量化过程中返回的<code class="fe ly lz ma mb b">maximum features</code>，所以我们需要使用这个确切的数字作为输入形状的大小。我们还将包括第一层将产生多少输出(作为<code class="fe ly lz ma mb b">layer1</code>传递)，稍后我们将修改该参数，以便使该层更简单或更复杂。在这种情况下，我们将选择<code class="fe ly lz ma mb b">relu</code>作为我们的激活函数，它比其他函数有几个好处，比如减少消失梯度的可能性。对于最后一层，我们将选择对应于三个不同输出的三个节点，因为我们想要获得分类分布，我们将使用<code class="fe ly lz ma mb b">softmax</code>作为激活函数。对于隐藏层，我们也将大小作为<code class="fe ly lz ma mb b">layer2 </code>传递，它通常是<code class="fe ly lz ma mb b">layer1</code>的一半，因为这是一个分类问题，我们将使用<code class="fe ly lz ma mb b">sigmoid</code>激活(如果你想知道更多关于使用哪个激活函数，检查这个<a class="ae lw" href="https://www.youtube.com/watch?v=-7scQpJT7uo" rel="noopener ugc nofollow" target="_blank">视频</a>)。</p><p id="11b5" class="pw-post-body-paragraph la lb je lc b ld le kf lf lg lh ki li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">之后，应该说明要使用的优化器及其参数。我们将使用具有固定衰减和β的 AdamOptimizer，但稍后我们将调整学习速率和ε值。<a class="ae lw" href="https://arxiv.org/abs/1412.6980v8" rel="noopener ugc nofollow" target="_blank"> Adam </a>是一种随机优化，它具有几个优点，例如实现简单、计算效率高、内存需求小、对梯度的对角线重定标不变，以及非常适合于数据和/或参数较大的问题。</p><p id="157d" class="pw-post-body-paragraph la lb je lc b ld le kf lf lg lh ki li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">训练前的最后步骤之一是编译网络，澄清我们想要的损失。在这种情况下，我们将使用<code class="fe ly lz ma mb b">sparse_categorical_crossentropy</code>,因为我们将类别表示为数字。我们还需要澄清优化器，以及要评估的指标(对我们来说，就是准确性)。此外，我们需要拟合模型，说明 X 和 Y 值的集合、<code class="fe ly lz ma mb b">batch size</code>(通过网络传播的样本数量)、<code class="fe ly lz ma mb b">epochs</code>(我们将扫描所有数据的次数，我们还将调整的参数)、<code class="fe ly lz ma mb b">validation split</code>(将保存哪个百分比以验证我们的结果)，以及我们是否每次都以相同的方式呈现数据，或者，我们将对其进行洗牌(<code class="fe ly lz ma mb b">shuffle</code>)。</p><p id="ee12" class="pw-post-body-paragraph la lb je lc b ld le kf lf lg lh ki li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">在尝试了<code class="fe ly lz ma mb b">dropout</code>、<code class="fe ly lz ma mb b">features</code>、<code class="fe ly lz ma mb b">shuffle</code>、<code class="fe ly lz ma mb b">learning rate</code>、<code class="fe ly lz ma mb b"> layer size</code>、<code class="fe ly lz ma mb b">epsilon</code>、<code class="fe ly lz ma mb b">validation_split</code>、<code class="fe ly lz ma mb b">epochs</code>几个参数后，我们最终得出了以下模型:</p><figure class="mc md me mf gt iv"><div class="bz fp l di"><div class="mg mh l"/></div></figure><figure class="mc md me mf gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi mz"><img src="../Images/d4ad18c0194b2eaf5477ed7070002a0a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*8sRJoax8gKK7hOfZFgA5GQ.png"/></div></div></figure><p id="4f43" class="pw-post-body-paragraph la lb je lc b ld le kf lf lg lh ki li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">我们可以看到，我们的最终验证准确度从时段 1 的 71.91 提高到时段 5 的 76.54%。此外，增加，甚至更多，纪元提高了训练精度，但降低了验证精度。</p><p id="3085" class="pw-post-body-paragraph la lb je lc b ld le kf lf lg lh ki li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">尽管我们总是希望有更高的准确性，但我们现在可以继续尝试在我们创建的新数据集中识别观点，就像我们用于训练和验证的数据集一样。</p><p id="4d32" class="pw-post-body-paragraph la lb je lc b ld le kf lf lg lh ki li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">为此，我们将查询我们的新数据库，执行相同的文本预处理步骤，对我们的推文进行标记，并使用我们训练的模型使用<code class="fe ly lz ma mb b">model.predict()</code>预测对“复仇者联盟”的情绪。如果我们想让人类更容易阅读，我们可以将数字预测转换为我们的分类标签‘正、中和、负’。</p><figure class="mc md me mf gt iv"><div class="bz fp l di"><div class="mg mh l"/></div></figure><p id="1f50" class="pw-post-body-paragraph la lb je lc b ld le kf lf lg lh ki li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">现在是真相大白的时候了！我们可以使用饼图来绘制每个情感类别中包含了多少条推文:</p><figure class="mc md me mf gt iv"><div class="bz fp l di"><div class="mg mh l"/></div></figure><figure class="mc md me mf gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi na"><img src="../Images/456525ccb4fb37dc60d44d71c70d2801.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*JhGdi93ybbDmbSkGeQDSzg.png"/></div></div></figure><p id="74ab" class="pw-post-body-paragraph la lb je lc b ld le kf lf lg lh ki li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">正如你所看到的，53.1%的推文对“复仇者联盟”有正面的含义，而剩下的 46.9%是中性的或有负面的含义。如果我在推特上谈论这个话题，我应该被列入积极的一面，或者至少我可以有 76%的信心我会。你呢？</p><p id="a2f4" class="pw-post-body-paragraph la lb je lc b ld le kf lf lg lh ki li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">接下来，我们将通过 NetworkX 使用 Tweets 信息<a class="ae lw" href="https://medium.com/@meinzaugarat/visualizing-twitter-interactions-with-networkx-a391da239af5" rel="noopener">来可视化 Twitter 上的用户交互。</a></p><p id="9ee4" class="pw-post-body-paragraph la lb je lc b ld le kf lf lg lh ki li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated"><em class="lx">如果你想了解这个项目的全部代码，请查看我的</em> <a class="ae lw" href="https://github.com/ugis22/analysing_twitter" rel="noopener ugc nofollow" target="_blank"> <em class="lx"> GitHub 库</em> </a> <em class="lx">。</em></p></div></div>    
</body>
</html>