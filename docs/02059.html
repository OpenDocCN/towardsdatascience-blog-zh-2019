<html>
<head>
<title>Text Classification with BERT and Tensorflow in Ten Lines of Code</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">用十行代码实现 BERT 和 Tensorflow 文本分类</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/how-to-do-text-binary-classification-with-bert-f1348a25d905?source=collection_archive---------4-----------------------#2019-04-05">https://towardsdatascience.com/how-to-do-text-binary-classification-with-bert-f1348a25d905?source=collection_archive---------4-----------------------#2019-04-05</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="2eb4" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">免费试用 Google Colab 上最先进的语言建模技术！</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ki"><img src="../Images/f703cc09e137928e84090ae7e0f0a3ea.png" data-original-src="https://miro.medium.com/v2/resize:fit:1220/format:webp/1*PD-PyafBI-GUXT45MVwefQ.png"/></div></figure><h1 id="77a8" class="kq kr it bd ks kt ku kv kw kx ky kz la jz lb ka lc kc ld kd le kf lf kg lg lh bi translated">需求</h1><p id="9509" class="pw-post-body-paragraph li lj it lk b ll lm ju ln lo lp jx lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">我们都知道 BERT 是一个引人注目的语言模型，已经被应用于各种下游任务，如<strong class="lk iu">情感分析</strong>和<strong class="lk iu">问答</strong> (QA)。在某些方面，它超越了人类！</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="mf mg di mh bf mi"><div class="gh gi me"><img src="../Images/3ec0fe0b4e565be8c07fb20101613385.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*W-hrRSKgfkAGc0jl.png"/></div></div></figure><p id="fefa" class="pw-post-body-paragraph li lj it lk b ll mj ju ln lo mk jx lq lr ml lt lu lv mm lx ly lz mn mb mc md im bi translated">有没有在文本二元分类上尝试过？</p><p id="8fc0" class="pw-post-body-paragraph li lj it lk b ll mj ju ln lo mk jx lq lr ml lt lu lv mm lx ly lz mn mb mc md im bi translated">老实说，直到最近，我的答案仍然是<strong class="lk iu">不</strong>。</p><p id="2cf1" class="pw-post-body-paragraph li lj it lk b ll mj ju ln lo mk jx lq lr ml lt lu lv mm lx ly lz mn mb mc md im bi translated">为什么不呢？</p><p id="46a1" class="pw-post-body-paragraph li lj it lk b ll mj ju ln lo mk jx lq lr ml lt lu lv mm lx ly lz mn mb mc md im bi translated">因为 BERT 官方 GitHub repo 上的示例代码<strong class="lk iu">不太用户友好</strong>。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="mf mg di mh bf mi"><div class="gh gi mo"><img src="../Images/1553f3b91bb0faaf1f3a5e41769e28a8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*AxKjFgeMIWzuuAMT.jpeg"/></div></div></figure><p id="f62f" class="pw-post-body-paragraph li lj it lk b ll mj ju ln lo mk jx lq lr ml lt lu lv mm lx ly lz mn mb mc md im bi translated">首先，我想要一个 IPython 笔记本，而不是 Python 脚本文件，因为我想在运行代码块时获得即时反馈。当然，谷歌 Colab 笔记本会更好，因为我可以通过免费的 GPU/TPU 立即使用代码。</p><p id="88eb" class="pw-post-body-paragraph li lj it lk b ll mj ju ln lo mk jx lq lr ml lt lu lv mm lx ly lz mn mb mc md im bi translated">其次，除了我在乎的人，我不想知道细节。我想控制有用的参数，比如时期数和批量大小。但是，我需要知道所有的“处理器”、“标志”和日志功能吗？</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="mf mg di mh bf mi"><div class="gh gi mo"><img src="../Images/19b41f0e23e2df629dd4fd39592a5c3b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*EYnQySuwhcY6Lb66.jpeg"/></div></div></figure><p id="91ce" class="pw-post-body-paragraph li lj it lk b ll mj ju ln lo mk jx lq lr ml lt lu lv mm lx ly lz mn mb mc md im bi translated">在我尝试了所有其他友好的框架之后，我是一个被宠坏的机器学习用户。</p><p id="d64f" class="pw-post-body-paragraph li lj it lk b ll mj ju ln lo mk jx lq lr ml lt lu lv mm lx ly lz mn mb mc md im bi translated">例如，在 Scikit-learn 中，如果你试图构建一个树分类器，这里(几乎)是你所有的代码。</p><pre class="kj kk kl km gt mp mq mr ms aw mt bi"><span id="b358" class="mu kr it mq b gy mv mw l mx my">from sklearn.datasets import load_iris<br/>from sklearn import tree<br/>iris = load_iris()<br/>clf = tree.DecisionTreeClassifier()<br/>clf = clf.fit(iris.data, iris.target)</span></pre><p id="f237" class="pw-post-body-paragraph li lj it lk b ll mj ju ln lo mk jx lq lr ml lt lu lv mm lx ly lz mn mb mc md im bi translated">如果想在 fast.ai 中做图像分类，需要输入这几行。</p><pre class="kj kk kl km gt mp mq mr ms aw mt bi"><span id="0e08" class="mu kr it mq b gy mv mw l mx my">!git clone https://github.com/wshuyi/demo-image-classification-fastai.git<br/>from fastai.vision import *<br/>path = Path("demo-image-classification-fastai/imgs/")<br/>data = ImageDataBunch.from_folder(path, test='test', size=224)<br/>learn = cnn_learner(data, models.resnet18, metrics=accuracy)<br/>learn.fit_one_cycle(1)<br/>interp = ClassificationInterpretation.from_learner(learn)<br/>interp.plot_top_losses(9, figsize=(8, 8))</span></pre><p id="e370" class="pw-post-body-paragraph li lj it lk b ll mj ju ln lo mk jx lq lr ml lt lu lv mm lx ly lz mn mb mc md im bi translated">你不仅可以得到分类结果，还可以得到激活图。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi mz"><img src="../Images/5653903bb16bfbacd0733d9c93503278.png" data-original-src="https://miro.medium.com/v2/resize:fit:1016/format:webp/0*SMpfwrgy9Pv9KR3G.png"/></div></figure><p id="4a66" class="pw-post-body-paragraph li lj it lk b ll mj ju ln lo mk jx lq lr ml lt lu lv mm lx ly lz mn mb mc md im bi translated">为什么 Google 开发者不能给我们一个类似的界面来使用 BERT 进行文本分类呢？</p><p id="5afd" class="pw-post-body-paragraph li lj it lk b ll mj ju ln lo mk jx lq lr ml lt lu lv mm lx ly lz mn mb mc md im bi translated">周一发现<a class="ae na" href="https://colab.research.google.com/github/google-research/bert/blob/master/predicting_movie_reviews_with_bert_on_tf_hub.ipynb" rel="noopener ugc nofollow" target="_blank">这个 Colab 笔记本</a>。这是预测影评情绪的一个例子。</p><p id="62a7" class="pw-post-body-paragraph li lj it lk b ll mj ju ln lo mk jx lq lr ml lt lu lv mm lx ly lz mn mb mc md im bi translated">我非常兴奋，因为我知道伯特现在已经加入了 Tensorflow 中心。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="mf mg di mh bf mi"><div class="gh gi mo"><img src="../Images/b8ddce315b1f37372e148db110d9bd33.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*S8rIAZ3Z7l_9IJgC.jpeg"/></div></div></figure><p id="3fce" class="pw-post-body-paragraph li lj it lk b ll mj ju ln lo mk jx lq lr ml lt lu lv mm lx ly lz mn mb mc md im bi translated">但是打开之后发现，对于一个只关心文本分类应用的用户来说，细节还是太多了。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="mf mg di mh bf mi"><div class="gh gi nb"><img src="../Images/2df0c6847f5b861f226c6fc4592d4b52.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*uO6iUn6aOKry9EWM.png"/></div></div></figure><p id="0563" class="pw-post-body-paragraph li lj it lk b ll mj ju ln lo mk jx lq lr ml lt lu lv mm lx ly lz mn mb mc md im bi translated">所以我试着重构代码，我做到了。</p><p id="eea2" class="pw-post-body-paragraph li lj it lk b ll mj ju ln lo mk jx lq lr ml lt lu lv mm lx ly lz mn mb mc md im bi translated">然而，原来，笔记本里还有很多代码。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="mf mg di mh bf mi"><div class="gh gi nb"><img src="../Images/d4a485186672e288890905d00c72f396.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*KesUNFgx_4ccfR2N.png"/></div></div></figure><p id="7e11" class="pw-post-body-paragraph li lj it lk b ll mj ju ln lo mk jx lq lr ml lt lu lv mm lx ly lz mn mb mc md im bi translated">所以我让我的读者帮我打包。很快，<a class="ae na" href="https://github.com/SunYanCN?tab=repositories" rel="noopener ugc nofollow" target="_blank">华中科技大学计算机科学专业研究生孙岩</a>就这么做了，并把它做成一个 PYPI 包，命名为<code class="fe nc nd ne mq b"><a class="ae na" href="https://github.com/SunYanCN/bert-text" rel="noopener ugc nofollow" target="_blank">bert-text</a></code>。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="mf mg di mh bf mi"><div class="gh gi mo"><img src="../Images/daae15a9dc31ab6b3462225af13907fa.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*D8UUkWqK06ODL020.jpeg"/></div></div></figure><h1 id="a2d2" class="kq kr it bd ks kt ku kv kw kx ky kz la jz lb ka lc kc ld kd le kf lf kg lg lh bi translated">笔记本</h1><p id="7105" class="pw-post-body-paragraph li lj it lk b ll lm ju ln lo lp jx lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">请点击<a class="ae na" href="https://github.com/wshuyi/demo-text-binary-classification-with-bert/blob/master/bert_text_classification.ipynb" rel="noopener ugc nofollow" target="_blank">这个链接</a>，你会在 github 上看到 IPynb 笔记本文件。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="mf mg di mh bf mi"><div class="gh gi mo"><img src="../Images/c24fa2e8d33f10ec71cbee45977e6e9f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*Wq9AWVu7dZzCRVV1.jpeg"/></div></div></figure><p id="4ab1" class="pw-post-body-paragraph li lj it lk b ll mj ju ln lo mk jx lq lr ml lt lu lv mm lx ly lz mn mb mc md im bi translated">点按“在 Colab 中打开”按钮。Google Colab 会自动打开。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="mf mg di mh bf mi"><div class="gh gi nb"><img src="../Images/0f47fd32fbaaeb00997f3fee2301b53b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*kfHb72KwlPxUJLhF.png"/></div></div></figure><p id="c5da" class="pw-post-body-paragraph li lj it lk b ll mj ju ln lo mk jx lq lr ml lt lu lv mm lx ly lz mn mb mc md im bi translated">您需要<strong class="lk iu">点击“复制到驱动器”按钮，将副本</strong>保存到您自己的 Google Drive。</p><p id="c066" class="pw-post-body-paragraph li lj it lk b ll mj ju ln lo mk jx lq lr ml lt lu lv mm lx ly lz mn mb mc md im bi translated">之后你只需要做四件事。</p><ol class=""><li id="c2b4" class="nf ng it lk b ll mj lo mk lr nh lv ni lz nj md nk nl nm nn bi translated">安装必要的软件包。</li><li id="69c2" class="nf ng it lk b ll no lo np lr nq lv nr lz ns md nk nl nm nn bi translated">准备熊猫数据框格式的数据。我估计对大多数深度学习用户来说很容易。</li><li id="877d" class="nf ng it lk b ll no lo np lr nq lv nr lz ns md nk nl nm nn bi translated">如有必要，调整四个参数。</li><li id="a379" class="nf ng it lk b ll no lo np lr nq lv nr lz ns md nk nl nm nn bi translated">运行笔记本并显示您的结果。</li></ol><p id="15e3" class="pw-post-body-paragraph li lj it lk b ll mj ju ln lo mk jx lq lr ml lt lu lv mm lx ly lz mn mb mc md im bi translated">让我们安装<code class="fe nc nd ne mq b">bert-text</code>包并加载 API。</p><pre class="kj kk kl km gt mp mq mr ms aw mt bi"><span id="2fd5" class="mu kr it mq b gy mv mw l mx my">!pip install bert-text<br/>from bert_text import run_on_dfs</span></pre><p id="c0f0" class="pw-post-body-paragraph li lj it lk b ll mj ju ln lo mk jx lq lr ml lt lu lv mm lx ly lz mn mb mc md im bi translated">我的例子是 IMDB 评论的样本数据集。它在训练集中包含 1000 个正样本和 1000 个负样本，而测试集包含 500 个正样本和 500 个负样本。</p><pre class="kj kk kl km gt mp mq mr ms aw mt bi"><span id="28a1" class="mu kr it mq b gy mv mw l mx my">import pickle</span><span id="bf8b" class="mu kr it mq b gy nt mw l mx my">!wget https://github.com/wshuyi/info-5731-public/raw/master/imdb-sample.pickle</span><span id="43b9" class="mu kr it mq b gy nt mw l mx my">with open("imdb-sample.pickle", 'rb') as f:<br/>    train, test = pickle.load(f)</span></pre><p id="5fec" class="pw-post-body-paragraph li lj it lk b ll mj ju ln lo mk jx lq lr ml lt lu lv mm lx ly lz mn mb mc md im bi translated">我在 UNT 大学的 INFO 5731 课堂上使用它，让学生比较 textblob 包、单词包模型、带有单词嵌入的简单 LSTM 和 ULMfit 的结果。</p><p id="058b" class="pw-post-body-paragraph li lj it lk b ll mj ju ln lo mk jx lq lr ml lt lu lv mm lx ly lz mn mb mc md im bi translated">现在我终于可以把伯特加入名单了。</p><p id="da8c" class="pw-post-body-paragraph li lj it lk b ll mj ju ln lo mk jx lq lr ml lt lu lv mm lx ly lz mn mb mc md im bi translated">您需要运行下面一行来确保训练数据被正确地打乱。</p><pre class="kj kk kl km gt mp mq mr ms aw mt bi"><span id="11ef" class="mu kr it mq b gy mv mw l mx my">train = train.sample(len(train))</span></pre><p id="ab1a" class="pw-post-body-paragraph li lj it lk b ll mj ju ln lo mk jx lq lr ml lt lu lv mm lx ly lz mn mb mc md im bi translated">您的数据集应存储在 Pandas 数据框中。应该有一个称为<code class="fe nc nd ne mq b">train</code>的训练集和一个称为<code class="fe nc nd ne mq b">test</code>的测试集。</p><p id="47d9" class="pw-post-body-paragraph li lj it lk b ll mj ju ln lo mk jx lq lr ml lt lu lv mm lx ly lz mn mb mc md im bi translated">它们都应该至少包含两列。一列用于文本，另一列用于二进制标签。强烈建议选择 0 和 1 作为标签值。</p><p id="66d4" class="pw-post-body-paragraph li lj it lk b ll mj ju ln lo mk jx lq lr ml lt lu lv mm lx ly lz mn mb mc md im bi translated">现在数据已经准备好了，可以设置参数了。</p><pre class="kj kk kl km gt mp mq mr ms aw mt bi"><span id="7b88" class="mu kr it mq b gy mv mw l mx my">myparam = {<br/>        "DATA_COLUMN": "text",<br/>        "LABEL_COLUMN": "sentiment",<br/>        "LEARNING_RATE": 2e-5,<br/>        "NUM_TRAIN_EPOCHS":10<br/>    }</span></pre><p id="2ec2" class="pw-post-body-paragraph li lj it lk b ll mj ju ln lo mk jx lq lr ml lt lu lv mm lx ly lz mn mb mc md im bi translated">前两个参数只是数据框的列名。您可以相应地更改它们。</p><p id="3ca0" class="pw-post-body-paragraph li lj it lk b ll mj ju ln lo mk jx lq lr ml lt lu lv mm lx ly lz mn mb mc md im bi translated">第三个参数是学习率。你需要阅读原始论文，以找出如何明智地选择它。或者，您可以使用此默认设置。</p><p id="3f34" class="pw-post-body-paragraph li lj it lk b ll mj ju ln lo mk jx lq lr ml lt lu lv mm lx ly lz mn mb mc md im bi translated">最后一个参数是设置希望 BERT 运行多少个时期。我在这里选择 10，因为训练数据集非常小，我不想让它过拟合。</p><p id="44f3" class="pw-post-body-paragraph li lj it lk b ll mj ju ln lo mk jx lq lr ml lt lu lv mm lx ly lz mn mb mc md im bi translated">默认情况下，预先训练的语言模型是“<code class="fe nc nd ne mq b">bert_uncased_L-12_H-768_A-12</code>”。它已经在英文维基百科和图书语料库上接受了训练。除此之外，现在还有五个选项可供你选择。</p><ul class=""><li id="16b1" class="nf ng it lk b ll mj lo mk lr nh lv ni lz nj md nu nl nm nn bi translated"><code class="fe nc nd ne mq b">bert_multi_cased_L-12_H-768_A-12</code></li><li id="7285" class="nf ng it lk b ll no lo np lr nq lv nr lz ns md nu nl nm nn bi translated"><code class="fe nc nd ne mq b">bert_uncased_L-24_H-1024_A-16</code></li><li id="5df7" class="nf ng it lk b ll no lo np lr nq lv nr lz ns md nu nl nm nn bi translated"><code class="fe nc nd ne mq b">bert_cased_L-12_H-768_A-12</code></li><li id="2bef" class="nf ng it lk b ll no lo np lr nq lv nr lz ns md nu nl nm nn bi translated"><code class="fe nc nd ne mq b">bert_chinese_L-12_H-768_A-12</code></li><li id="c802" class="nf ng it lk b ll no lo np lr nq lv nr lz ns md nu nl nm nn bi translated"><code class="fe nc nd ne mq b">bert_cased_L-24_H-1024_A-16</code></li></ul><p id="7a7b" class="pw-post-body-paragraph li lj it lk b ll mj ju ln lo mk jx lq lr ml lt lu lv mm lx ly lz mn mb mc md im bi translated">如果您想换成另一个预先训练好的模型，比如处理法语或德语的多语言模型，请按如下方式更改<code class="fe nc nd ne mq b">myparam</code>设置:</p><pre class="kj kk kl km gt mp mq mr ms aw mt bi"><span id="78da" class="mu kr it mq b gy mv mw l mx my">myparam = {<br/>        "DATA_COLUMN": "comment",<br/>        "LABEL_COLUMN": "sentiment",<br/>        "LEARNING_RATE": 2e-5,<br/>        "NUM_TRAIN_EPOCHS":3,<br/>        "bert_model_hub":"https://tfhub.dev/google/bert_multi_cased_L-12_H-768_A-12/1"<br/>    }</span></pre><p id="4164" class="pw-post-body-paragraph li lj it lk b ll mj ju ln lo mk jx lq lr ml lt lu lv mm lx ly lz mn mb mc md im bi translated">汉语是一个特例。您可能需要这样设置<code class="fe nc nd ne mq b">myparam</code>:</p><pre class="kj kk kl km gt mp mq mr ms aw mt bi"><span id="b7a4" class="mu kr it mq b gy mv mw l mx my">myparam = {<br/>        "DATA_COLUMN": "comment",<br/>        "LABEL_COLUMN": "sentiment",<br/>        "LEARNING_RATE": 2e-5,<br/>        "NUM_TRAIN_EPOCHS":3,<br/>        "bert_model_hub":"https://tfhub.dev/google/bert_chinese_L-12_H-768_A-12/1"<br/>    }</span></pre><p id="812d" class="pw-post-body-paragraph li lj it lk b ll mj ju ln lo mk jx lq lr ml lt lu lv mm lx ly lz mn mb mc md im bi translated">如果您想看到整个输出(可选)，您应该添加下面两行代码。</p><pre class="kj kk kl km gt mp mq mr ms aw mt bi"><span id="d2af" class="mu kr it mq b gy mv mw l mx my">import tensorflow as tf<br/>tf.logging.set_verbosity(tf.logging.INFO)</span></pre><p id="0dc6" class="pw-post-body-paragraph li lj it lk b ll mj ju ln lo mk jx lq lr ml lt lu lv mm lx ly lz mn mb mc md im bi translated">好吧。现在你可以跑伯特了！</p><pre class="kj kk kl km gt mp mq mr ms aw mt bi"><span id="d2c2" class="mu kr it mq b gy mv mw l mx my">result, estimator = run_on_dfs(train, test, **myparam)</span></pre><p id="6405" class="pw-post-body-paragraph li lj it lk b ll mj ju ln lo mk jx lq lr ml lt lu lv mm lx ly lz mn mb mc md im bi translated">警告！这一行花了你一些时间来运行。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="mf mg di mh bf mi"><div class="gh gi nv"><img src="../Images/2a05671557d48ad4fe6669c9c6d3d040.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*9TdDfWT1EHH6uOsA.png"/></div></div></figure><p id="827f" class="pw-post-body-paragraph li lj it lk b ll mj ju ln lo mk jx lq lr ml lt lu lv mm lx ly lz mn mb mc md im bi translated">完成后，您可以运行最后一行来获得您的分类模型的评估结果(在 BERT 上)。</p><pre class="kj kk kl km gt mp mq mr ms aw mt bi"><span id="f801" class="mu kr it mq b gy mv mw l mx my">result</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nw"><img src="../Images/0b8d4d6da4be94c529434864db062e4a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1044/format:webp/0*2WOOy11wQfUojBT7.jpeg"/></div></figure><p id="d034" class="pw-post-body-paragraph li lj it lk b ll mj ju ln lo mk jx lq lr ml lt lu lv mm lx ly lz mn mb mc md im bi translated">对于这么小的训练集来说，我觉得结果还是挺不错的。</p><p id="c121" class="pw-post-body-paragraph li lj it lk b ll mj ju ln lo mk jx lq lr ml lt lu lv mm lx ly lz mn mb mc md im bi translated">仅此而已。</p><p id="4c03" class="pw-post-body-paragraph li lj it lk b ll mj ju ln lo mk jx lq lr ml lt lu lv mm lx ly lz mn mb mc md im bi translated">现在你也可以使用最先进的语言建模技术来训练你的文本二进制分类器！</p><h1 id="8f38" class="kq kr it bd ks kt ku kv kw kx ky kz la jz lb ka lc kc ld kd le kf lf kg lg lh bi translated">相关博客</h1><p id="aca9" class="pw-post-body-paragraph li lj it lk b ll lm ju ln lo lp jx lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">如果你对这篇博客文章感兴趣，你可能也想看看下面几篇:</p><ul class=""><li id="96bf" class="nf ng it lk b ll mj lo mk lr nh lv ni lz nj md nu nl nm nn bi translated"><a class="ae na" rel="noopener" target="_blank" href="/how-to-practice-python-with-google-colab-45fc6b7d118b">如何用 Google Colab 练习 Python？</a></li><li id="d385" class="nf ng it lk b ll no lo np lr nq lv nr lz ns md nu nl nm nn bi translated"><a class="ae na" rel="noopener" target="_blank" href="/how-to-predict-severe-traffic-jams-with-python-and-recurrent-neural-networks-e53b6d411e8d">如何用 Python 和递归神经网络预测严重的交通堵塞？</a></li><li id="06cc" class="nf ng it lk b ll no lo np lr nq lv nr lz ns md nu nl nm nn bi translated"><a class="ae na" href="https://medium.com/datadriveninvestor/deep-learning-with-python-and-fast-ai-part-1-image-classification-with-pre-trained-model-cd9364107872" rel="noopener">使用 Python 和 fast.ai 进行深度学习，第 1 部分:使用预训练模型进行图像分类</a></li><li id="21d7" class="nf ng it lk b ll no lo np lr nq lv nr lz ns md nu nl nm nn bi translated"><a class="ae na" href="https://medium.com/datadriveninvestor/deep-learning-with-python-and-fast-ai-part-2-nlp-classification-with-transfer-learning-e7aaf7514e04" rel="noopener">使用 Python 和 fast.ai 的深度学习，第 2 部分:使用迁移学习的 NLP 分类</a></li></ul></div></div>    
</body>
</html>