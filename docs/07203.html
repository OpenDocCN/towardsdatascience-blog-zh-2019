<html>
<head>
<title>CNN &amp; ResNets — a more liberal understanding</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">CNN &amp; ResNets——一种更自由的理解</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/cnn-resnets-a-more-liberal-understanding-a0143a3ddac9?source=collection_archive---------32-----------------------#2019-10-10">https://towardsdatascience.com/cnn-resnets-a-more-liberal-understanding-a0143a3ddac9?source=collection_archive---------32-----------------------#2019-10-10</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="bd5e" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated"><em class="kf">这个博客解释了卷积网络背后发生的事情，以及它们是如何工作的。我将使用 fastai 和 PyTorch 库。如果你想更广泛地了解 fastai cnn 的实现，可以参考文章</em> <a class="ae kg" href="https://medium.com/analytics-vidhya/image-classification-using-fastai-5ff5b374d414" rel="noopener"> <em class="kf">这里</em> </a> <em class="kf">。让我们开始吧。</em></h2></div><figure class="ki kj kk kl gt km gh gi paragraph-image"><div role="button" tabindex="0" class="kn ko di kp bf kq"><div class="gh gi kh"><img src="../Images/ad8fee1c010a2f8b0b41a4e047820669.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*gzMYO-m4-2mE3zl0GK4osg.jpeg"/></div></div><figcaption class="kt ku gj gh gi kv kw bd b be z dk">Photo by <a class="ae kg" href="https://unsplash.com/@starburst1977?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank">Sven Read</a> on <a class="ae kg" href="https://unsplash.com/s/photos/convolutional-neural-networks?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><h2 id="ea61" class="kx ky iq bd kz la lb dn lc ld le dp lf lg lh li lj lk ll lm ln lo lp lq lr ls bi translated">❓如何创建一个卷积神经网络</h2><p id="5647" class="pw-post-body-paragraph lt lu iq lv b lw lx jr ly lz ma ju mb lg mc md me lk mf mg mh lo mi mj mk ml ij bi translated">如果你熟悉 fastai，特别是 fastai 中的计算机视觉，那么你就知道我们是如何创建卷积神经网络的。我们用来创建网络。如果想了解<code class="fe mm mn mo mp b">create_cnn</code>背后的语义，可以参考介绍中分享的链接。</p><p id="c7e6" class="pw-post-body-paragraph lt lu iq lv b lw mq jr ly lz mr ju mb lg ms md me lk mt mg mh lo mu mj mk ml ij bi translated">现在，我们有了 CNN，我们想知道 CNN 正在发生什么。幕后发生的事情如下:</p><figure class="ki kj kk kl gt km gh gi paragraph-image"><div role="button" tabindex="0" class="kn ko di kp bf kq"><div class="gh gi mv"><img src="../Images/5195efe9ce46cc55aa5fdcd4088ef72c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ZNtToiK0uD_qM_jgDj4hpQ.png"/></div></div><figcaption class="kt ku gj gh gi kv kw bd b be z dk"><strong class="bd mw">Basic neural network</strong></figcaption></figure><p id="05ad" class="pw-post-body-paragraph lt lu iq lv b lw mq jr ly lz mr ju mb lg ms md me lk mt mg mh lo mu mj mk ml ij bi translated">现在，在卷积神经网络中，卷积发生，而不是矩阵乘法。卷积也是一种矩阵乘法，但它也有一些其他的磁性。让我们深入了解卷积神经网络。</p><ul class=""><li id="63fd" class="mx my iq lv b lw mq lz mr lg mz lk na lo nb ml nc nd ne nf bi translated">卷积神经网络由内核组成。内核是另一个任意大小的矩阵，如 2X2、3X3、4X4 或 1X1。这个矩阵有一些数字，它们基本上定义了一个特定的特征。</li><li id="34d1" class="mx my iq lv b lw ng lz nh lg ni lk nj lo nk ml nc nd ne nf bi translated">我的意思是，第一层中的核可以滤除输入矩阵(表示图像的像素矩阵)中的顶部边缘，第二层中的核可以滤除左角，第三层中的核可以滤除对角线图案，等等。</li><li id="221f" class="mx my iq lv b lw ng lz nh lg ni lk nj lo nk ml nc nd ne nf bi translated">现在，当输入矩阵与内核相乘时，输出被称为<code class="fe mm mn mo mp b">Channel</code>。现在，我们想要多少层就有多少层。ResNet34 有 34 层以上操作。</li><li id="830b" class="mx my iq lv b lw ng lz nh lg ni lk nj lo nk ml nc nd ne nf bi translated">因此，大体上，我们可以说，我们有许多层矩阵乘法，在每一层矩阵乘法中，我们将一个内核与输入像素矩阵相乘，在输出中得到一个通道。</li></ul><blockquote class="nl"><p id="dde5" class="nm nn iq bd no np nq nr ns nt nu ml dk translated"><em class="kf">用新手的语言，想出任何一个图像，把手电筒的光照在图像上。让光线从左上到右下穿过图像的小部分。图像的一小部分变亮的部分实际上是核心，火炬光在整个图像上运行的过程是一种卷积。</em></p></blockquote><p id="65e7" class="pw-post-body-paragraph lt lu iq lv b lw nv jr ly lz nw ju mb lg nx md me lk ny mg mh lo nz mj mk ml ij bi translated">让我们用图解法来理解上面的操作。</p><figure class="ki kj kk kl gt km gh gi paragraph-image"><div role="button" tabindex="0" class="kn ko di kp bf kq"><div class="gh gi oa"><img src="../Images/e3351cc3b6b851e6b6407894fef940bb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*CSZy3Dw6qLVfVvUVyrH2Sg.png"/></div></div><figcaption class="kt ku gj gh gi kv kw bd b be z dk">Convolution()</figcaption></figure><figure class="ki kj kk kl gt km gh gi paragraph-image"><div class="gh gi ob"><img src="../Images/eb1b3f6ea421059363d4d13b526f27f0.png" data-original-src="https://miro.medium.com/v2/resize:fit:694/format:webp/1*S08ydQMUJ5ij8vE0Q5punA.png"/></div><figcaption class="kt ku gj gh gi kv kw bd b be z dk">Output of convolution</figcaption></figure><p id="0524" class="pw-post-body-paragraph lt lu iq lv b lw mq jr ly lz mr ju mb lg ms md me lk mt mg mh lo mu mj mk ml ij bi translated">形成的方程式数量如下:</p><figure class="ki kj kk kl gt km gh gi paragraph-image"><div class="gh gi oc"><img src="../Images/9441e30dbd82da612a9d5b843ce75ba7.png" data-original-src="https://miro.medium.com/v2/resize:fit:964/format:webp/1*KyHAktaiiQRo1GNXpl5bKQ.png"/></div></figure><p id="5308" class="pw-post-body-paragraph lt lu iq lv b lw mq jr ly lz mr ju mb lg ms md me lk mt mg mh lo mu mj mk ml ij bi translated">因此，输入图像被简化为一个更小的矩阵，称为表示某个特征的通道。</p><p id="c7e7" class="pw-post-body-paragraph lt lu iq lv b lw mq jr ly lz mr ju mb lg ms md me lk mt mg mh lo mu mj mk ml ij bi translated">现在，我们可能以如下的传统神经网络方式理解它:</p><figure class="ki kj kk kl gt km gh gi paragraph-image"><div role="button" tabindex="0" class="kn ko di kp bf kq"><div class="gh gi od"><img src="../Images/55c80228f8eec861694c51874dce67db.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*WFzfM1GaFECYf6qevF-z5w.png"/></div></div></figure><p id="0477" class="pw-post-body-paragraph lt lu iq lv b lw mq jr ly lz mr ju mb lg ms md me lk mt mg mh lo mu mj mk ml ij bi translated">我们可以用传统的神经网络方式进行运算，但这需要大量的内存和时间。相反，我们用上面提到的另一种方式来执行它，这样会花费更少的时间和内存。</p><p id="75b7" class="pw-post-body-paragraph lt lu iq lv b lw mq jr ly lz mr ju mb lg ms md me lk mt mg mh lo mu mj mk ml ij bi translated">现在，让我们考虑卷积神经网络的另一种情况。如果我们的输入矩阵和内核大小相同会怎样？处理这种情况有两种选择:</p><ul class=""><li id="e4d6" class="mx my iq lv b lw mq lz mr lg mz lk na lo nb ml nc nd ne nf bi translated">我们可以对完整的输入矩阵进行卷积，得到秩为 1 的张量。</li><li id="eb34" class="mx my iq lv b lw ng lz nh lg ni lk nj lo nk ml nc nd ne nf bi translated">否则，我们在输入矩阵周围添加零填充或反射填充，然后卷积输入矩阵，如下所述。Fastai 尽可能频繁地使用反射填充。</li></ul><figure class="ki kj kk kl gt km gh gi paragraph-image"><div role="button" tabindex="0" class="kn ko di kp bf kq"><div class="gh gi oa"><img src="../Images/68271916a0d1fb734a9042874d73cb94.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*xaoiY_fPcO-FPNaikEEimw.png"/></div></div></figure><p id="27af" class="pw-post-body-paragraph lt lu iq lv b lw mq jr ly lz mr ju mb lg ms md me lk mt mg mh lo mu mj mk ml ij bi translated">换句话说，卷积就是一个矩阵乘法，其中会发生两件事:</p><ul class=""><li id="bfd6" class="mx my iq lv b lw mq lz mr lg mz lk na lo nb ml nc nd ne nf bi translated">一些条目一直被设置为零</li><li id="d755" class="mx my iq lv b lw ng lz nh lg ni lk nj lo nk ml nc nd ne nf bi translated">相同的核权重被相乘以计算不同的通道</li></ul><p id="6d7b" class="pw-post-body-paragraph lt lu iq lv b lw mq jr ly lz mr ju mb lg ms md me lk mt mg mh lo mu mj mk ml ij bi translated">所以当你有多个重量相同的东西时，这叫做<strong class="lv ir">重量捆绑</strong>。</p><p id="d23f" class="pw-post-body-paragraph lt lu iq lv b lw mq jr ly lz mr ju mb lg ms md me lk mt mg mh lo mu mj mk ml ij bi translated">这就是对卷积神经网络的大部分理论理解。现在，让我们从实用的角度来理解卷积神经网络。</p><ul class=""><li id="6b90" class="mx my iq lv b lw mq lz mr lg mz lk na lo nb ml nc nd ne nf bi translated">实际上，我们有 3D 输入图像，而不是 2D 图像。每个图像具有不同的红色、绿色和蓝色像素。因此，我们没有秩 2 张量核，而是秩 3 张量核，代表红色、绿色和蓝色的不同值。因此，我们不是对 9 个事物进行逐元素的乘法运算(如果 2D 核有 9 个值)，而是对 27 个事物进行逐元素的乘法运算(3 乘 3 乘 3)，然后我们仍然要将它们相加为一个数字。</li><li id="9d01" class="mx my iq lv b lw ng lz nh lg ni lk nj lo nk ml nc nd ne nf bi translated">现在，当我们卷积图像时，我们不仅要找到顶部边缘，还要检测图像中的重复、颜色梯度等。为了涵盖所有不同的特性，我们需要越来越多的内核，这就是实际发生的情况。在每一层中，我们使用许多内核来处理图像。因此，每一层都由大量的通道组成。</li><li id="e8e1" class="mx my iq lv b lw ng lz nh lg ni lk nj lo nk ml nc nd ne nf bi translated">为了避免我们的内存由于大量通道而失控，我们不时地创建一个卷积，其中我们不跨越每一个 3x3 的集合(考虑到内核的大小)，而是一次跳过两个。我们将从一个以(2，2)为中心的 3x3 开始，然后跳到(2，4)，(2，6)，(2，8)，等等。<strong class="lv ir">那叫一步两回旋</strong>。它的作用是，看起来是一样的，它仍然只是一堆内核，但我们只是一次跳过两个。我们跳过每隔一个输入像素。所以它的输出是 H/2 乘以 W/2。(<em class="oe">我们可以定义步长-n 卷积</em></li></ul><p id="ec1b" class="pw-post-body-paragraph lt lu iq lv b lw mq jr ly lz mr ju mb lg ms md me lk mt mg mh lo mu mj mk ml ij bi translated">让我们看看步幅-4 卷积。</p><figure class="ki kj kk kl gt km gh gi paragraph-image"><div role="button" tabindex="0" class="kn ko di kp bf kq"><div class="gh gi of"><img src="../Images/85fa86088ada5124a257906c24bbcace.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*d9RYs5usyL1pg5DqaJUQzg.png"/></div></div><figcaption class="kt ku gj gh gi kv kw bd b be z dk">stride-4 convolution as we are shifting by 4 places.</figcaption></figure><p id="8f9a" class="pw-post-body-paragraph lt lu iq lv b lw mq jr ly lz mr ju mb lg ms md me lk mt mg mh lo mu mj mk ml ij bi translated">现在，让我们评估 MNIST 数据集，并使用我们的卷积神经网络。我使用 google colab 是出于实际目的。</p><pre class="ki kj kk kl gt og mp oh oi aw oj bi"><span id="5cb7" class="kx ky iq mp b gy ok ol l om on">from fastai.vision import *</span></pre><p id="ed5f" class="pw-post-body-paragraph lt lu iq lv b lw mq jr ly lz mr ju mb lg ms md me lk mt mg mh lo mu mj mk ml ij bi translated">Fastai 提供学术数据集，我们可以解开并使用它。</p><pre class="ki kj kk kl gt og mp oh oi aw oj bi"><span id="f631" class="kx ky iq mp b gy ok ol l om on">path = untar_data(URLs.MNIST)<br/>path.ls()</span></pre><figure class="ki kj kk kl gt km gh gi paragraph-image"><div class="gh gi oo"><img src="../Images/8e1e33aaa020be0fd3f388975ed7d43c.png" data-original-src="https://miro.medium.com/v2/resize:fit:916/format:webp/1*2XSaAsQrh_tGFTTX1QUVuw.png"/></div><figcaption class="kt ku gj gh gi kv kw bd b be z dk">It consists of training and validation data</figcaption></figure><p id="109f" class="pw-post-body-paragraph lt lu iq lv b lw mq jr ly lz mr ju mb lg ms md me lk mt mg mh lo mu mj mk ml ij bi translated">提取数据后，我们必须创建数据串。让我们来证明这一点。</p><p id="e08a" class="pw-post-body-paragraph lt lu iq lv b lw mq jr ly lz mr ju mb lg ms md me lk mt mg mh lo mu mj mk ml ij bi translated">你首先说的是你有什么样的物品清单。所以，在这种情况下，它是图像列表。那你从哪里得到的文件名列表？在这种情况下，我们有文件夹。</p><pre class="ki kj kk kl gt og mp oh oi aw oj bi"><span id="80c8" class="kx ky iq mp b gy ok ol l om on">imagelist = ImageList.from_folder(path); imagelist</span></pre><figure class="ki kj kk kl gt km gh gi paragraph-image"><div role="button" tabindex="0" class="kn ko di kp bf kq"><div class="gh gi op"><img src="../Images/e25f8af8a0fea0cc8b558178e6bad0ed.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*aA-cm5iHaGB3ndySE7nphA.png"/></div></div><figcaption class="kt ku gj gh gi kv kw bd b be z dk">It has a total of 7000 images. Each image has three channels and is 28*28.</figcaption></figure><p id="472e" class="pw-post-body-paragraph lt lu iq lv b lw mq jr ly lz mr ju mb lg ms md me lk mt mg mh lo mu mj mk ml ij bi translated">所以在一个条目列表里面是一个<code class="fe mm mn mo mp b">items</code>属性，而<code class="fe mm mn mo mp b">items</code>属性是你赋予它的那种东西。它将用于创建您的项目。在这种情况下，你给它的是一个文件名列表。这是它从文件夹里得到的。</p><pre class="ki kj kk kl gt og mp oh oi aw oj bi"><span id="e472" class="kx ky iq mp b gy ok ol l om on">imagelist.items</span></pre><figure class="ki kj kk kl gt km gh gi paragraph-image"><div role="button" tabindex="0" class="kn ko di kp bf kq"><div class="gh gi oq"><img src="../Images/0de044ed3799c389d79abe6c9f162afd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*L0YXXGpX2Z5MDHVZOZ86Og.png"/></div></div><figcaption class="kt ku gj gh gi kv kw bd b be z dk">It consists of a list of images from training and testing folder</figcaption></figure><p id="852c" class="pw-post-body-paragraph lt lu iq lv b lw mq jr ly lz mr ju mb lg ms md me lk mt mg mh lo mu mj mk ml ij bi translated">当你显示图像时，它通常以 RGB 显示。在这种情况下，我们希望使用二进制颜色图。</p><pre class="ki kj kk kl gt og mp oh oi aw oj bi"><span id="2888" class="kx ky iq mp b gy ok ol l om on">defaults.cmap='binary'<br/>imagelist[22].show()</span></pre><figure class="ki kj kk kl gt km gh gi paragraph-image"><div class="gh gi or"><img src="../Images/d0266af8ae29501b33510c4565f3fc51.png" data-original-src="https://miro.medium.com/v2/resize:fit:418/format:webp/1*IM2FQXshFZTf1y2Haccbsg.png"/></div></figure><p id="e22d" class="pw-post-body-paragraph lt lu iq lv b lw mq jr ly lz mr ju mb lg ms md me lk mt mg mh lo mu mj mk ml ij bi translated">一旦你有了一个图片列表，你就可以把它分成训练和验证两部分。你几乎总是想要被认可。如果没有，可以使用<code class="fe mm mn mo mp b">.no_split</code>方法创建一个空的验证集。不能完全跳过。所有这些都在 fastai <a class="ae kg" href="https://docs.fast.ai/data_block.html" rel="noopener ugc nofollow" target="_blank">数据块 API </a>中定义。</p><pre class="ki kj kk kl gt og mp oh oi aw oj bi"><span id="57e3" class="kx ky iq mp b gy ok ol l om on">splitData = imagelist.split_by_folder(train='training', valid='testing'); splitData</span></pre><figure class="ki kj kk kl gt km gh gi paragraph-image"><div role="button" tabindex="0" class="kn ko di kp bf kq"><div class="gh gi os"><img src="../Images/8fdb12ba73105650dcea1ad3d036ecd5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*LKbC4b0zZCV3tnbz1de_4g.png"/></div></div><figcaption class="kt ku gj gh gi kv kw bd b be z dk">60000 items in training dataset and 10000 items in the validation dataset</figcaption></figure><p id="2bfe" class="pw-post-body-paragraph lt lu iq lv b lw mq jr ly lz mr ju mb lg ms md me lk mt mg mh lo mu mj mk ml ij bi translated">顺序总是这样。首先，创建你的物品清单，然后决定如何分割。在这种情况下，我们将基于文件夹进行操作。MNIST 的验证文件夹叫做 <code class="fe mm mn mo mp b"><em class="oe">testing</em></code> <em class="oe">，因此我们在方法中也提到了它。</em></p><p id="e1ec" class="pw-post-body-paragraph lt lu iq lv b lw mq jr ly lz mr ju mb lg ms md me lk mt mg mh lo mu mj mk ml ij bi translated">现在，我们想要标记我们的数据，并且我们想要使用数据所在的文件夹来标记数据。</p><figure class="ki kj kk kl gt km gh gi paragraph-image"><div class="gh gi ot"><img src="../Images/850435ac38386bb34c663ea57b13a4f8.png" data-original-src="https://miro.medium.com/v2/resize:fit:928/format:webp/1*_sGLSckX16KcSdvzd0IQRQ.png"/></div><figcaption class="kt ku gj gh gi kv kw bd b be z dk">Number 4 images are present in 4 numbered folder and same for others also.</figcaption></figure><pre class="ki kj kk kl gt og mp oh oi aw oj bi"><span id="8785" class="kx ky iq mp b gy ok ol l om on">labelist = splitData.label_from_folder()</span></pre><figure class="ki kj kk kl gt km gh gi paragraph-image"><div role="button" tabindex="0" class="kn ko di kp bf kq"><div class="gh gi ou"><img src="../Images/4160578d2185d3dbe0336a4a48488ec5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*q3U7D0kqYXAoVvRR-MSJgQ.png"/></div></div><figcaption class="kt ku gj gh gi kv kw bd b be z dk">The category list is defined for the sample images in the image.</figcaption></figure><blockquote class="ov ow ox"><p id="db6e" class="lt lu oe lv b lw mq jr ly lz mr ju mb oy ms md me oz mt mg mh pa mu mj mk ml ij bi translated">所以首先你要创建一个物品列表，然后分割它，再给它贴上标签。</p></blockquote><pre class="ki kj kk kl gt og mp oh oi aw oj bi"><span id="73db" class="kx ky iq mp b gy ok ol l om on">x,y = labelist.train[0] or labelist.valid[0]</span><span id="bb2d" class="kx ky iq mp b gy pb ol l om on">x.show()<br/>print(x.shape, y)</span></pre><figure class="ki kj kk kl gt km gh gi paragraph-image"><div class="gh gi pc"><img src="../Images/cbfe3e4e173caa3e672e70deeb0748c7.png" data-original-src="https://miro.medium.com/v2/resize:fit:486/format:webp/1*8oHcBAFsWt7R3FnVdopMIg.png"/></div></figure><p id="ba1f" class="pw-post-body-paragraph lt lu iq lv b lw mq jr ly lz mr ju mb lg ms md me lk mt mg mh lo mu mj mk ml ij bi translated">现在，添加变换。转换是数据扩充的一部分。我们为表格数据添加的过程和为图像添加的转换之间有很大的区别。</p><ul class=""><li id="b3d6" class="mx my iq lv b lw mq lz mr lg mz lk na lo nb ml nc nd ne nf bi translated">在训练数据上添加一次过程，并且对验证和测试数据进行相同的验证</li><li id="62c4" class="mx my iq lv b lw ng lz nh lg ni lk nj lo nk ml nc nd ne nf bi translated">每次我们需要一堆图像时，都会应用变换。</li></ul><p id="b81f" class="pw-post-body-paragraph lt lu iq lv b lw mq jr ly lz mr ju mb lg ms md me lk mt mg mh lo mu mj mk ml ij bi translated">由于我们正在进行数字识别，因此我们不想对数据应用默认值，因为它包含一些我们确实不想要的转换，如垂直/水平翻转数字会改变数字，缩放文本会改变图像的像素，图像会变得模糊。因此，我们将添加我们的转换，他们毫不费力，添加随机填充和少量的裁剪。</p><pre class="ki kj kk kl gt og mp oh oi aw oj bi"><span id="3016" class="kx ky iq mp b gy ok ol l om on">tfms = ([*rand_pad(padding=3, size=28, mode='zeros')], [])<br/><em class="oe">(empty array refers to the validaion set transforms)</em></span><span id="3ade" class="kx ky iq mp b gy pb ol l om on">transformedlist = labelist.transform(tfms)</span></pre><p id="b49d" class="pw-post-body-paragraph lt lu iq lv b lw mq jr ly lz mr ju mb lg ms md me lk mt mg mh lo mu mj mk ml ij bi translated">现在是最后一步的时候了，那就是创建数据束。这里我没有使用图像统计数据进行标准化，因为我没有使用预先训练的模型，如 ResNet34、ResNet56 等。另外，我将使用 128 的批量大小。</p><pre class="ki kj kk kl gt og mp oh oi aw oj bi"><span id="5cfd" class="kx ky iq mp b gy ok ol l om on">bs = 128<br/>data = transformedlist.databunch(bs=bs).normalize()</span><span id="d3d4" class="kx ky iq mp b gy pb ol l om on">x,y = data.train_ds[0]<br/>x.show()<br/>print(y)</span></pre><figure class="ki kj kk kl gt km gh gi paragraph-image"><div class="gh gi pd"><img src="../Images/39c5babac5060b8221986f4d253175c0.png" data-original-src="https://miro.medium.com/v2/resize:fit:512/format:webp/1*hHANRWvRdCJe0vqcYgyogw.png"/></div></figure><p id="c17c" class="pw-post-body-paragraph lt lu iq lv b lw mq jr ly lz mr ju mb lg ms md me lk mt mg mh lo mu mj mk ml ij bi translated">最有趣的是，训练数据集现在有了数据扩充，因为我们添加了转换。<code class="fe mm mn mo mp b">plot_multi</code>是一个 fast.ai 函数，它将绘制对每个项目调用某个函数的结果。</p><pre class="ki kj kk kl gt og mp oh oi aw oj bi"><span id="f7e7" class="kx ky iq mp b gy ok ol l om on">def _plot(i,j,ax): data.train_ds[0][0].show(ax, cmap='gray')<br/>plot_multi(_plot, 3, 3, figsize=(7, 7))</span></pre><figure class="ki kj kk kl gt km gh gi paragraph-image"><div class="gh gi pe"><img src="../Images/72353dd6a502c4bc7eb0e305fbbb8b78.png" data-original-src="https://miro.medium.com/v2/resize:fit:856/format:webp/1*J8SQVGRfw4t_Pk8uE5F06g.png"/></div><figcaption class="kt ku gj gh gi kv kw bd b be z dk">Check different padding and cropping in the images</figcaption></figure><pre class="ki kj kk kl gt og mp oh oi aw oj bi"><span id="513a" class="kx ky iq mp b gy ok ol l om on">xb,yb = data.one_batch()<br/>xb.shape,yb.shape</span></pre><figure class="ki kj kk kl gt km gh gi paragraph-image"><div class="gh gi pf"><img src="../Images/e2f13dde8e0332c743d4f77724fddc19.png" data-original-src="https://miro.medium.com/v2/resize:fit:850/format:webp/1*Or6tvsq6tgiN2tAtEVtLNA.png"/></div><figcaption class="kt ku gj gh gi kv kw bd b be z dk">Since we selected the batch size of 128. Thus there are 128 images.</figcaption></figure><pre class="ki kj kk kl gt og mp oh oi aw oj bi"><span id="f7f4" class="kx ky iq mp b gy ok ol l om on">data.show_batch(rows=3, figsize=(5,5))</span></pre><figure class="ki kj kk kl gt km gh gi paragraph-image"><div class="gh gi pg"><img src="../Images/6fbc65c72560f7d74739b76411452bd4.png" data-original-src="https://miro.medium.com/v2/resize:fit:698/format:webp/1*Ul1MErBrC0jlB3L-7BlByQ.png"/></div><figcaption class="kt ku gj gh gi kv kw bd b be z dk">Images with the labels</figcaption></figure><p id="0419" class="pw-post-body-paragraph lt lu iq lv b lw mq jr ly lz mr ju mb lg ms md me lk mt mg mh lo mu mj mk ml ij bi translated">现在，我们完成了数据束。现在，我们将创建学习者，并通过我们自己的 CNN 对其进行训练。</p><h1 id="a815" class="ph ky iq bd kz pi pj pk lc pl pm pn lf jw po jx lj jz pp ka ln kc pq kd lr pr bi translated">批量归一化的基本 CNN</h1><pre class="ki kj kk kl gt og mp oh oi aw oj bi"><span id="1c6f" class="kx ky iq mp b gy ok ol l om on">def <strong class="mp ir">conv</strong>(ni,nf): return nn.Conv2d(ni, nf, kernel_size=3, stride=2, padding=1)</span><span id="5716" class="kx ky iq mp b gy pb ol l om on">model = nn.Sequential(<br/>    conv(3, 8), <strong class="mp ir"><em class="oe"># 14</em></strong><br/>    nn.BatchNorm2d(8),<br/>    nn.ReLU(),</span><span id="2154" class="kx ky iq mp b gy pb ol l om on">conv(8, 16), <strong class="mp ir"><em class="oe"># 7</em></strong><br/>    nn.BatchNorm2d(16),<br/>    nn.ReLU(),</span><span id="438b" class="kx ky iq mp b gy pb ol l om on">conv(16, 32), <strong class="mp ir"><em class="oe"># 4</em></strong><br/>    nn.BatchNorm2d(32),<br/>    nn.ReLU(),</span><span id="31ae" class="kx ky iq mp b gy pb ol l om on">conv(32, 16), <strong class="mp ir"><em class="oe"># 2</em></strong><br/>    nn.BatchNorm2d(16),<br/>    nn.ReLU(),</span><span id="2a14" class="kx ky iq mp b gy pb ol l om on">conv(16, 10), <strong class="mp ir"><em class="oe"># 1</em></strong><br/>    nn.BatchNorm2d(10),<br/>    Flatten()     <strong class="mp ir"><em class="oe"># remove (1,1) grid</em></strong><br/>)</span></pre><p id="4515" class="pw-post-body-paragraph lt lu iq lv b lw mq jr ly lz mr ju mb lg ms md me lk mt mg mh lo mu mj mk ml ij bi translated">让我们来理解一下上面的函数。</p><ul class=""><li id="c47e" class="mx my iq lv b lw mq lz mr lg mz lk na lo nb ml nc nd ne nf bi translated">我们声明内核大小为 3 * 3。</li><li id="4aa9" class="mx my iq lv b lw ng lz nh lg ni lk nj lo nk ml nc nd ne nf bi translated">我们要执行步长为 2 的卷积。</li><li id="1773" class="mx my iq lv b lw ng lz nh lg ni lk nj lo nk ml nc nd ne nf bi translated">现在，我们想执行顺序操作，这就是为什么我们写了<code class="fe mm mn mo mp b">nn.Sequential</code>。</li><li id="8ef5" class="mx my iq lv b lw ng lz nh lg ni lk nj lo nk ml nc nd ne nf bi translated">模型的第一层是 conv(3，8)。<code class="fe mm mn mo mp b">3</code>暗示要输入的通道数。因为我们的图像有三个输入通道，所以我们声明了这个数字。见下图。</li></ul><figure class="ki kj kk kl gt km gh gi paragraph-image"><div class="gh gi ps"><img src="../Images/29d4ea7412cb7db9de09715a1d741237.png" data-original-src="https://miro.medium.com/v2/resize:fit:548/format:webp/1*Dl2pq2-PW-P22L3hfnFGXw.png"/></div><figcaption class="kt ku gj gh gi kv kw bd b be z dk">Images with 3 channels</figcaption></figure><ul class=""><li id="84f3" class="mx my iq lv b lw mq lz mr lg mz lk na lo nb ml nc nd ne nf bi translated"><code class="fe mm mn mo mp b">8</code>是输出的通道总数。正如上一节所讨论的，这个数字意味着过滤器的总数。</li><li id="3bef" class="mx my iq lv b lw ng lz nh lg ni lk nj lo nk ml nc nd ne nf bi translated">一层输出的通道数输入到下一层。我们已经提到过使用步长 2 卷积。因此，我们从 28 * 28 的图像尺寸开始。在第二层，它将变成 14 * 14，在下一层变成 7 * 7，然后变成 4 * 4，然后变成 2 * 2，最后变成 1 * 1。</li><li id="17c9" class="mx my iq lv b lw ng lz nh lg ni lk nj lo nk ml nc nd ne nf bi translated">输出将采用[128，10，1，1]的形式，这一批 128 个图像中的每个图像在输出中有 10 个 1 * 1 的通道，作为秩 3 张量。我们把它拉平，排列成一个张量。</li><li id="3391" class="mx my iq lv b lw ng lz nh lg ni lk nj lo nk ml nc nd ne nf bi translated">在卷积层之间，我们添加了批量标准化和 ReLu 作为非线性层。</li></ul><p id="9efc" class="pw-post-body-paragraph lt lu iq lv b lw mq jr ly lz mr ju mb lg ms md me lk mt mg mh lo mu mj mk ml ij bi translated">这就是全部(͡ᵔ ͜ʖ ͡ᵔ)，我们已经创建了我们的卷积神经网络。</p><p id="d026" class="pw-post-body-paragraph lt lu iq lv b lw mq jr ly lz mr ju mb lg ms md me lk mt mg mh lo mu mj mk ml ij bi translated">现在是按照 fastai 中的定义创建学习者的时候了。</p><pre class="ki kj kk kl gt og mp oh oi aw oj bi"><span id="ee7d" class="kx ky iq mp b gy ok ol l om on">learn = Learner(data, model, loss_func = nn.CrossEntropyLoss(), metrics=accuracy)</span><span id="5668" class="kx ky iq mp b gy pb ol l om on">learn.summary()</span></pre><figure class="ki kj kk kl gt km gh gi paragraph-image"><div class="gh gi pt"><img src="../Images/d935ec197ec5d47945f8fb6355fdbd4e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1190/format:webp/1*AZhbl1ZuDqI-lCrNyx-Yew.png"/></div><figcaption class="kt ku gj gh gi kv kw bd b be z dk">[8, 14, 14] — [channels, dimension, dimention]</figcaption></figure><pre class="ki kj kk kl gt og mp oh oi aw oj bi"><span id="e5d0" class="kx ky iq mp b gy ok ol l om on">learn.lr_find(end_lr=100)</span><span id="6874" class="kx ky iq mp b gy pb ol l om on">learn.recorder.plot()</span></pre><figure class="ki kj kk kl gt km gh gi paragraph-image"><div class="gh gi pu"><img src="../Images/184993820b8c7b227437352ebeb7befc.png" data-original-src="https://miro.medium.com/v2/resize:fit:820/format:webp/1*WG0hyMPX6FDzCHBUY-2nUQ.png"/></div><figcaption class="kt ku gj gh gi kv kw bd b be z dk">Learning rate plot</figcaption></figure><pre class="ki kj kk kl gt og mp oh oi aw oj bi"><span id="6552" class="kx ky iq mp b gy ok ol l om on">learn.fit_one_cycle(10, max_lr=0.1)</span></pre><figure class="ki kj kk kl gt km gh gi paragraph-image"><div class="gh gi pv"><img src="../Images/6f664178d549773a8735d196f0c797ec.png" data-original-src="https://miro.medium.com/v2/resize:fit:860/format:webp/1*MnTGme-ualdU9B19ksflfg.png"/></div><figcaption class="kt ku gj gh gi kv kw bd b be z dk">We have reached 99% accuracy</figcaption></figure><p id="e073" class="pw-post-body-paragraph lt lu iq lv b lw mq jr ly lz mr ju mb lg ms md me lk mt mg mh lo mu mj mk ml ij bi translated">现在，让我们了解 ResNet，然后我会将它包括在我们的模型中，看看精度提高了多少。</p><h2 id="47ca" class="kx ky iq bd kz la lb dn lc ld le dp lf lg lh li lj lk ll lm ln lo lp lq lr ls bi translated">❓什么是 ResNet</h2><p id="6053" class="pw-post-body-paragraph lt lu iq lv b lw lx jr ly lz ma ju mb lg mc md me lk mf mg mh lo mi mj mk ml ij bi translated">设 X 为输出。根据 ResNet，而不是做喜欢</p><p id="b0d6" class="pw-post-body-paragraph lt lu iq lv b lw mq jr ly lz mr ju mb lg ms md me lk mt mg mh lo mu mj mk ml ij bi translated"><code class="fe mm mn mo mp b">Y = conv2(conv1(X))</code>，</p><p id="bafe" class="pw-post-body-paragraph lt lu iq lv b lw mq jr ly lz mr ju mb lg ms md me lk mt mg mh lo mu mj mk ml ij bi translated">的确如此，</p><p id="4ebf" class="pw-post-body-paragraph lt lu iq lv b lw mq jr ly lz mr ju mb lg ms md me lk mt mg mh lo mu mj mk ml ij bi translated"><code class="fe mm mn mo mp b">Y = X + conv2(conv1(X))</code>——这个东西叫做身份连接或者跳过连接。</p><figure class="ki kj kk kl gt km gh gi paragraph-image"><div role="button" tabindex="0" class="kn ko di kp bf kq"><div class="gh gi pw"><img src="../Images/75f12bc4554babed5f59df7427c020b6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1208/format:webp/1*CoRXTtmLnZoKCz3bbwZMkA.png"/></div></div><figcaption class="kt ku gj gh gi kv kw bd b be z dk">Basics of ResNet — ResBlock</figcaption></figure><p id="7efe" class="pw-post-body-paragraph lt lu iq lv b lw mq jr ly lz mr ju mb lg ms md me lk mt mg mh lo mu mj mk ml ij bi translated">ResNet 极大地改善了损失函数曲面。没有 ResNet，损失函数有很多凸起，而有了 ResNet，它就变得平滑了。</p><p id="32f5" class="pw-post-body-paragraph lt lu iq lv b lw mq jr ly lz mr ju mb lg ms md me lk mt mg mh lo mu mj mk ml ij bi translated">我们可以像下面这样创建 ResBock:</p><pre class="ki kj kk kl gt og mp oh oi aw oj bi"><span id="42ab" class="kx ky iq mp b gy ok ol l om on">class ResBlock(nn.Module):<br/>    def __init__(self, nf):<br/>        super().__init__()<br/>        self.conv1 = conv_layer(nf,nf)<br/>        self.conv2 = conv_layer(nf,nf)<br/>        <br/>    def forward(self, x): return x + self.conv2(self.conv1(x))</span></pre><p id="d691" class="pw-post-body-paragraph lt lu iq lv b lw mq jr ly lz mr ju mb lg ms md me lk mt mg mh lo mu mj mk ml ij bi translated">让我们更改我们的模型，以包含 ResNet 块。让我们稍微重构一下。fast.ai 已经有了一个名为<code class="fe mm mn mo mp b">conv_layer</code>的东西，可以让你创建 conv、批处理范数、ReLU 组合，而不是一直说 conv、批处理范数、ReLU。</p><pre class="ki kj kk kl gt og mp oh oi aw oj bi"><span id="20ad" class="kx ky iq mp b gy ok ol l om on">def conv2(ni,nf): return conv_layer(ni,nf,stride=2)</span><span id="0442" class="kx ky iq mp b gy pb ol l om on">model = nn.Sequential(<br/>    conv2(1, 8),<br/>    res_block(8),<br/>    conv2(8, 16),<br/>    res_block(16),<br/>    conv2(16, 32),<br/>    res_block(32),<br/>    conv2(32, 16),<br/>    res_block(16),<br/>    conv2(16, 10),<br/>    Flatten()<br/>)</span><span id="c6f9" class="kx ky iq mp b gy pb ol l om on">learn = Learner(data, model, loss_func = nn.CrossEntropyLoss(), metrics=accuracy)<br/>learn.fit_one_cycle(12, max_lr=0.05)</span></pre><figure class="ki kj kk kl gt km gh gi paragraph-image"><div class="gh gi pf"><img src="../Images/5a905dc6237666d838013c63da84bdd0.png" data-original-src="https://miro.medium.com/v2/resize:fit:850/format:webp/1*9zzZkFrtlKY32rXJ8LYpXg.png"/></div><figcaption class="kt ku gj gh gi kv kw bd b be z dk">Accuracy is improved a bit to 99.23%.</figcaption></figure><p id="298b" class="pw-post-body-paragraph lt lu iq lv b lw mq jr ly lz mr ju mb lg ms md me lk mt mg mh lo mu mj mk ml ij bi translated">仅此而已。我希望你可能已经理解了 CNN 和 ResNets 背后的逻辑。</p></div></div>    
</body>
</html>