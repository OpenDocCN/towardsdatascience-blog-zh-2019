<html>
<head>
<title>OpenAI GPT-2 writes alternate endings for Game of Thrones</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">《开放的 GPT 2》为《权力的游戏》写了不同的结局</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/openai-gpt-2-writes-alternate-endings-for-game-of-thrones-c9be75cd2425?source=collection_archive---------4-----------------------#2019-05-23">https://towardsdatascience.com/openai-gpt-2-writes-alternate-endings-for-game-of-thrones-c9be75cd2425?source=collection_archive---------4-----------------------#2019-05-23</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><p id="1760" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">我在 GRRM 的书系列<em class="ko">《冰与火之歌》</em>上训练了 GPT-2 语言模型，并让它完成了 HBO 节目的故事情节。它能比 HBO 的第八季《火车残骸》更好吗？</p><figure class="kq kr ks kt gt ku gh gi paragraph-image"><div role="button" tabindex="0" class="kv kw di kx bf ky"><div class="gh gi kp"><img src="../Images/a5756e9e8d1c80533f736f98623fcde6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*kGm85F4A1unw1qiGDrX64A.jpeg"/></div></div><figcaption class="lb lc gj gh gi ld le bd b be z dk">Game of Thrones season 8 storyline has left its fandom divided with millions of fans disappointed by its rushed and unsatisfactory ending. Disclaimer: <strong class="bd lf"><em class="lg">Opinions expressed in this article are solely my own.</em></strong></figcaption></figure><p id="11d4" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><a class="ae lh" href="https://www.hbo.com/game-of-thrones" rel="noopener ugc nofollow" target="_blank">《权力的游戏》</a>第八季的故事情节让粉丝们产生分歧，<a class="ae lh" href="https://www.change.org/p/hbo-remake-game-of-thrones-season-8-with-competent-writers" rel="noopener ugc nofollow" target="_blank">数百万</a>粉丝(包括我自己)对其仓促且不尽如人意的结局感到失望。许多人呼吁重写这部电视剧的最后一季，而其他人则提出了他们自己版本的结局，以获得一个满意的结局。其他人正在等待 GRRM 完成他的书，希望他能为人物的不可信行为提供一个更令人信服的构建，但这可能需要很多年。因此，我想让一个人工智能学习 GRRM 的写作风格，并让它完成节目的结尾。</p><p id="9291" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">在这篇文章中，我将解释我们如何通过使用名为<a class="ae lh" href="https://openai.com/blog/better-language-models/" rel="noopener ugc nofollow" target="_blank"> GPT-2 </a>的文本生成语言模型来实现这一点，该模型由 Open AI 的研究人员在 2019 年初推出。然后，我将分享这一季三个主要反派的故事情节的模型预测结果:夜王、瑟曦·兰尼斯特和丹妮莉丝·坦格利安。</p><figure class="kq kr ks kt gt ku gh gi paragraph-image"><div class="gh gi li"><img src="../Images/44778469845ec0f9c1f2f96309b07527.png" data-original-src="https://miro.medium.com/v2/resize:fit:1192/format:webp/1*UyTBrPkgAqb8a4r3d2t9AA.jpeg"/></div></figure><h1 id="00aa" class="lj lk it bd ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg bi translated">生成式预训练变压器 2 (GPT-2)</h1><p id="4609" class="pw-post-body-paragraph jq jr it js b jt mh jv jw jx mi jz ka kb mj kd ke kf mk kh ki kj ml kl km kn im bi translated">GPT-2 是目前人工智能语言建模中最先进的文本生成模型。它能够产生类似人类的连贯句子，并且能够长时间专注于一个主题。与其他语言模型相比，它令人印象深刻的改进归功于这项研究的两个主要贡献</p><ol class=""><li id="81e0" class="mm mn it js b jt ju jx jy kb mo kf mp kj mq kn mr ms mt mu bi translated"><strong class="js iu">大量数据:</strong>搜集并整理了 800 万个网页，形成了一个 40GB 的文本语料库，可以对其进行无监督训练。它涵盖了各种各样的主题，这就是为什么预训练模型非常适合将学习转移到特定领域，就像我们的 GoT 书籍一样。</li><li id="02ed" class="mm mn it js b jt mv jx mw kb mx kf my kj mz kn mr ms mt mu bi translated"><strong class="js iu">大量计算:</strong>它使用 15 亿(！！)在其基于变压器的网络架构中的参数。然而，他们只发布了这个模型的一个较小版本，包含“仅”3.45 亿个参数，引用了<a class="ae lh" href="https://www.theverge.com/2019/2/21/18234500/ai-ethics-debate-researchers-harmful-programs-openai" rel="noopener ugc nofollow" target="_blank">安全原因</a>。我们将使用这个版本的预训练模型来执行 GoT 脚本的迁移学习。</li></ol><h2 id="2c30" class="na lk it bd ll nb nc dn lp nd ne dp lt kb nf ng lx kf nh ni mb kj nj nk mf nl bi translated">变压器模型</h2><p id="2c4c" class="pw-post-body-paragraph jq jr it js b jt mh jv jw jx mi jz ka kb mj kd ke kf mk kh ki kj ml kl km kn im bi translated">GPT-2 使用变压器网络架构，而不是通常用于序列建模的传统 RNN/LSTM/GRU 网络。Transformer 使用基于注意力的机制和一对编码器/解码器，而不是带有“记忆”门和时间步长的循环单元。</p><p id="8b46" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">编码器在字节对和位置嵌入的帮助下处理输入，字节对和位置嵌入描述输入句子中单词的“是什么”和“在哪里”(嵌入)。同一个编码器将字节和位置嵌入转换为矢量编码，然后进入解码器，解码器的任务是将编码转换为目标文本序列。该输出和来自前一步骤的编码被馈送到下一编码-解码步骤，并且被重复多次以产生进一步的文本。这里有一篇优秀的<a class="ae lh" href="https://blog.floydhub.com/the-transformer-in-pytorch/" rel="noopener ugc nofollow" target="_blank">文章</a>详细解释了这个模型架构。</p><figure class="kq kr ks kt gt ku gh gi paragraph-image"><div role="button" tabindex="0" class="kv kw di kx bf ky"><div class="gh gi nm"><img src="../Images/94d4174071afe725b10cb68bbbd31bab.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*zashbcHkygPg0GGEzrmemg.png"/></div></div><figcaption class="lb lc gj gh gi ld le bd b be z dk">Overview of a general attention-based Transformer model. [source: Attention Is All You Need’ by Vaswani et al.]</figcaption></figure><p id="81e2" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">请注意，GPT-2 被训练为预测给定输入句子中的下一个单词，其假设是，为了相当准确地预测下一个单词，模型将被迫学习到目前为止它遇到的所有单词的上下文含义。如果不理解文本，语言模型可能只能预测语法正确的单词，但生成的文本不会完全有意义。因此，这种使网络预测足够好的下一个单词的公式，GPT-2 能够获得对输入文本的深刻理解。<a class="ae lh" href="https://www.youtube.com/watch?v=T0I88NhR_9M" rel="noopener ugc nofollow" target="_blank">这里</a>是伊利亚·苏茨基弗对这个概念的一个很好的解释。</p><p id="2363" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">GPT-2 在文本生成期间不需要编码器，因为它不是像语言翻译那样的 seq2seq 转换任务。所以一旦训练结束，编码器就不再需要了。GPT-2 仅使用来自预训练转换器的解码器来生成后续文本。</p><h2 id="7a24" class="na lk it bd ll nb nc dn lp nd ne dp lt kb nf ng lx kf nh ni mb kj nj nk mf nl bi translated"><strong class="ak">训练模特</strong></h2><p id="2524" class="pw-post-body-paragraph jq jr it js b jt mh jv jw jx mi jz ka kb mj kd ke kf mk kh ki kj ml kl km kn im bi translated">我从乔治·R·R·马丁的书系列<em class="ko">“冰与火之歌”</em>的所有 5 本书中提取了文本，并将它们连接起来准备训练文本。使用具有 345M 参数的预训练的 GPT-2 模型对该文本执行迁移学习。</p><figure class="kq kr ks kt gt ku gh gi paragraph-image"><div role="button" tabindex="0" class="kv kw di kx bf ky"><div class="gh gi nn"><img src="../Images/3c45900f90e135e066332005cec14d92.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*LIyTzBfBel72t-7qVJYmMQ.jpeg"/></div></div><figcaption class="lb lc gj gh gi ld le bd b be z dk">George R.R. Martin’s Book Series <strong class="bd lf">“A Song of Ice and Fire”.</strong></figcaption></figure><p id="6ac5" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">令人惊讶的是，我注意到预先训练的模型也非常擅长写关于《权力的游戏》角色的内容，这意味着它在 800 万网页的初始训练中接触过这些内容。不管怎样，我决定缩小这个“一般化”模型的范围，只按照 GRRM 的风格编写，所以继续在我们的 GoT 数据集上进行训练。该模型在 Google Colab 的 K80 GPU 上训练了大约 12 个小时。</p><h1 id="e0f3" class="lj lk it bd ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg bi translated">结果</h1><p id="b9bc" class="pw-post-body-paragraph jq jr it js b jt mh jv jw jx mi jz ka kb mj kd ke kf mk kh ki kj ml kl km kn im bi translated">让我们尝试解决一些令人失望的结局或故事情节的转折，并尝试使用我们训练有素的 GPT-2 模型预测这些场景的替代结局。</p><p id="ea26" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">下面是视频格式的结果，后面是文本格式的结果。选择自己的冒险。</p><figure class="kq kr ks kt gt ku"><div class="bz fp l di"><div class="no np l"/></div></figure><h2 id="c33f" class="na lk it bd ll nb nc dn lp nd ne dp lt kb nf ng lx kf nh ni mb kj nj nk mf nl bi translated">失望 1:夜王虎头蛇尾的结局</h2><figure class="kq kr ks kt gt ku gh gi paragraph-image"><div role="button" tabindex="0" class="kv kw di kx bf ky"><div class="gh gi nq"><img src="../Images/732b4a2998e6ccdd534b4cad06596da7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*TNf4wmmQoDyna-wQaxsqQQ.png"/></div></div></figure><blockquote class="nr ns nt"><p id="9c20" class="jq jr ko js b jt ju jv jw jx jy jz ka nu kc kd ke nv kg kh ki nw kk kl km kn im bi translated"><strong class="js iu">输入:</strong>夜王慢慢走到三眼乌鸦面前。琼恩被冰龙挡住，丹妮莉丝被怀特一家团团围住。夜王伸出他的冰剑想要杀死布兰，但突然</p><p id="2275" class="jq jr ko js b jt ju jv jw jx jy jz ka nu kc kd ke nv kg kh ki nw kk kl km kn im bi translated"><strong class="js iu">输出:</strong>阿多阻止了他，他仍然用他的大手抓着冰原狼。“阿多！”乌鸦叫道。“阿多！阿多！”黑魔王脸上带着失落的表情。他用树桩刺穿布兰的背部，开始搏斗、翻滚、旋转。怀特，巨人，半身人，稻草人。布兰与夏莫、老鹰、笨狗和陌生人并肩作战，但光之王绝不会以剑挡剑。乌鸦在说，只是爬上阿多的厚雪白的腿。</p></blockquote><figure class="kq kr ks kt gt ku gh gi paragraph-image"><div class="gh gi nx"><img src="../Images/03e5c9001616fb018657c4b791e2b16f.png" data-original-src="https://miro.medium.com/v2/resize:fit:440/format:webp/1*UHKl36xPJMcYQRYw5DTi6w.jpeg"/></div></figure><p id="03fe" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">据 GPT 2 号说，阿多还活着，他来营救布兰，真是个意外！或者它可能是被布兰注入的阿多的不死之身。但是之后我就不知道模特想说什么了，哈哈！</p></div><div class="ab cl ny nz hx oa" role="separator"><span class="ob bw bk oc od oe"/><span class="ob bw bk oc od oe"/><span class="ob bw bk oc od"/></div><div class="im in io ip iq"><blockquote class="nr ns nt"><p id="595b" class="jq jr ko js b jt ju jv jw jx jy jz ka nu kc kd ke nv kg kh ki nw kk kl km kn im bi translated"><strong class="js iu">输入:</strong>夜王慢慢走向三眼乌鸦。琼恩被冰龙托起，丹妮莉丝被狼人包围。夜王伸出他的冰剑想要杀死布兰，但突然意想不到的事情发生了。</p><p id="c39b" class="jq jr ko js b jt ju jv jw jx jy jz ka nu kc kd ke nv kg kh ki nw kk kl km kn im bi translated"><strong class="js iu">输出:</strong>剑发出炽热的红光。当剑刃击中夜之眼时，它周围的绿色玻璃裂开了，光溶解了，剑像死冰一样发光。然后乌鸦开始尖叫，远处的猫头鹰在龙的左边和右边，有东西正在还击，撞开门，杀死所有长着娃娃脸的傻瓜。我猜 Osha 在给 Rickon 演示如何装弹。也许战斗结束后，他们都会是很好的倾诉对象。</p></blockquote><figure class="kq kr ks kt gt ku gh gi paragraph-image"><div class="gh gi of"><img src="../Images/f2e6c90e49f8b8ef627567938c948adc.png" data-original-src="https://miro.medium.com/v2/resize:fit:800/format:webp/1*DX1yAFWirVZ-zASLUJ_4sQ.jpeg"/></div></figure><p id="a3bc" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">尽管节目主持人忘记了，GPT-2 记得亚梭尔·亚亥的预言，并围绕着杀死夜王的剑光明使者的想法起舞。如果夜王的冰剑最终被证明是光明使者并杀死他，那该有多酷啊？！</p></div><div class="ab cl ny nz hx oa" role="separator"><span class="ob bw bk oc od oe"/><span class="ob bw bk oc od oe"/><span class="ob bw bk oc od"/></div><div class="im in io ip iq"><blockquote class="nr ns nt"><p id="65e7" class="jq jr ko js b jt ju jv jw jx jy jz ka nu kc kd ke nv kg kh ki nw kk kl km kn im bi translated">输入:布兰说，“席恩，你是个好人。谢谢大家。”！席恩，带着他的救赎之弧，奔向夜王的死亡。就在他要用长矛刺穿夜王的时候，</p><p id="fbf3" class="jq jr ko js b jt ju jv jw jx jy jz ka nu kc kd ke nv kg kh ki nw kk kl km kn im bi translated"><strong class="js iu">输出:</strong>龙——还是另一个？——朝他的脸开了一枪，而夜王平静地看着。世界缩小到三个人，肩并肩站在一起；红色的牧师和他的长矛，国王穿着蓝色，他的皇冠在他的头上。一股寒风穿过冰冷的空气吹进席恩的脑袋，他也能听到他的兄弟们在喊叫。如果我不是那么坚强。。。杀了他，他想喊，但是勇气从他身上消失了，就像他身体的一部分被迫保持沉默。取而代之的是，他弯曲他残废的手臂，扔掉他的矛杆。他告诉自己，给自己留点伤，尽你所能跑吧。</p></blockquote><figure class="kq kr ks kt gt ku gh gi paragraph-image"><div class="gh gi og"><img src="../Images/11bf06e598a98784bc06cd312da861c2.png" data-original-src="https://miro.medium.com/v2/resize:fit:600/format:webp/1*3V8WxsutACPEY11ctZSaxw.jpeg"/></div></figure><p id="abb9" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">这一篇让我大吃一惊，不是因为它写得很棒(其实不是)，而是因为模型知道龙实际上是一个“他者”(这意味着书中的白行者)。它怎么会知道维塞隆是一条被夜王控制的不死龙呢？韦赛里翁向席恩喷火，折断了他的长矛。席恩，在这一刻，决定在恐惧中逃跑，就像他在这个节目中所做的一样。把所有这些细节都写在一段话里，这太巧合了。令人惊讶的是，模特已经知道了角色的这些细节！</p></div><div class="ab cl ny nz hx oa" role="separator"><span class="ob bw bk oc od oe"/><span class="ob bw bk oc od oe"/><span class="ob bw bk oc od"/></div><div class="im in io ip iq"><h2 id="c3b7" class="na lk it bd ll nb nc dn lp nd ne dp lt kb nf ng lx kf nh ni mb kj nj nk mf nl bi translated"><strong class="ak">失望 2: </strong>瑟曦·兰尼斯特在没有任何计划和适当战斗的情况下被轻易击倒</h2><figure class="kq kr ks kt gt ku gh gi paragraph-image"><div role="button" tabindex="0" class="kv kw di kx bf ky"><div class="gh gi nq"><img src="../Images/38fa0a22cbc78721e3cfaa9799f9660f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Tk-oc11Up_L_M8BK35oL7w.jpeg"/></div></div></figure><blockquote class="nr ns nt"><p id="b364" class="jq jr ko js b jt ju jv jw jx jy jz ka nu kc kd ke nv kg kh ki nw kk kl km kn im bi translated"><strong class="js iu">输入:</strong>巨龙已经烧毁了整个兰尼斯特的军队，钢铁舰队和黄金军团，但是瑟曦依然坚信红堡不会陷落。当恶龙即将烧毁红堡的塔楼时，詹姆前来营救瑟曦。此时此刻，</p><p id="ae9a" class="jq jr ko js b jt ju jv jw jx jy jz ka nu kc kd ke nv kg kh ki nw kk kl km kn im bi translated">他的心提到了嗓子眼，手掐着喉咙……他不知道如何呼吸……”艾莉亚颤抖着提利昂说兰尼斯特家有刀。"“他说他们有剑，”詹姆承认道。"詹姆杀托曼不是为了保住托曼的贞操，”艾莉亚说，把自己的故事告诉了身旁脸红的男孩提利昂·兰尼斯特。他的小弟弟只是咧嘴一笑。”不，我没有。"詹姆狠狠地瞪了她一眼。"很好。你撒谎。是的，你对那个吻撒了谎。你用嘴杀死了托曼，这既不是吻也不是承诺。只有一两把剑。你伤得很重，小家伙。不管怎样，只要那个脏男孩珍惜你给他的礼物，你姐姐就会把他留在她的床上。"</p></blockquote><p id="e460" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">嗯，好吧，这个完全是垃圾。但我还是留着它，因为它太傻了，实际上很有趣。不管怎样，让我们再试一次！</p></div><div class="ab cl ny nz hx oa" role="separator"><span class="ob bw bk oc od oe"/><span class="ob bw bk oc od oe"/><span class="ob bw bk oc od"/></div><div class="im in io ip iq"><blockquote class="nr ns nt"><p id="9aca" class="jq jr ko js b jt ju jv jw jx jy jz ka nu kc kd ke nv kg kh ki nw kk kl km kn im bi translated"><strong class="js iu">输入:</strong>龙族已经烧毁了整个兰尼斯特军、铁血舰队和黄金连队的军队，但瑟曦依然坚信红堡不会陷落。当恶龙即将烧毁红堡的塔楼时，詹姆前来营救瑟曦。此时此刻，</p><p id="d61a" class="jq jr ko js b jt ju jv jw jx jy jz ka nu kc kd ke nv kg kh ki nw kk kl km kn im bi translated"><strong class="js iu">输出:</strong>根据她的预言，疯王将进攻这座城市……“瑟曦，”詹姆又说了一遍，尽量让声音听起来严厉而遥远，“静静地，哦，甜蜜，哦，甜蜜。”他给特罗特写道:“瑟曦，记住，你是凯岩城的国王。记住你是谁，你是什么。还记得你是如何杀死疯王的吗？原谅我，如果我让你犹豫不决。”她没有回答。“原谅我，”他热情地重复道，“为了我从未有过的母亲，你从未有过的母亲，一个所有人都认识并爱着却不认识的母亲。”当刀刃入鞘时，鹰在油的波纹上闪着微光，天花板上的字闪闪发光，又亮又暗…</p></blockquote><figure class="kq kr ks kt gt ku gh gi paragraph-image"><div class="gh gi oh"><img src="../Images/1d82b5e90a6b2c6390c42b7a090f2152.png" data-original-src="https://miro.medium.com/v2/resize:fit:732/format:webp/1*Mcz5N4AGALAiYyr3g7Bvdw.jpeg"/></div></figure><p id="b2f2" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">这次稍微好一点！虽然这个模型在某些细节上出错了，特别是关于疯王的，但我确实喜欢詹姆在那一刻试图给瑟曦力量的想法。也许在这个时候使用某种野火会给她的故事情节带来一些正义感。两个疯狂的女王，以火攻火，烧毁了城市的其余部分。这将是一个更好的结局，表明为什么争夺铁王座的战争是不好的。</p></div><div class="ab cl ny nz hx oa" role="separator"><span class="ob bw bk oc od oe"/><span class="ob bw bk oc od oe"/><span class="ob bw bk oc od"/></div><div class="im in io ip iq"><h2 id="e17e" class="na lk it bd ll nb nc dn lp nd ne dp lt kb nf ng lx kf nh ni mb kj nj nk mf nl bi translated"><strong class="ak">失望 3: </strong>丹妮莉丝不劳而获的脚后跟转弯</h2><figure class="kq kr ks kt gt ku gh gi paragraph-image"><div role="button" tabindex="0" class="kv kw di kx bf ky"><div class="gh gi oi"><img src="../Images/953a4298665aec14dc83e392e6f1a8e7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*2gL2ANiXt-4GBcNnuK6QZA.jpeg"/></div></div></figure><blockquote class="nr ns nt"><p id="e73f" class="jq jr ko js b jt ju jv jw jx jy jz ka nu kc kd ke nv kg kh ki nw kk kl km kn im bi translated"><strong class="js iu">输入:</strong>丹妮莉丝在埃索斯和弥林拥有爱和恐惧。但在维斯特洛，她觉得自己只有恐惧。在她赢得铁王座之战的那一刻，她只能想着给她将要统治的人民灌输恐惧。丹妮莉丝在君临坐在她的龙上，她决定要</p><p id="8320" class="jq jr ko js b jt ju jv jw jx jy jz ka nu kc kd ke nv kg kh ki nw kk kl km kn im bi translated"><strong class="js iu">输出:</strong>吃。“有牙齿的食物，”乔拉爵士说。“我想尝尝那个，”丹妮抱怨道。"吃红肉喝麦芽酒不太像多斯拉克人."她想起了过去的时光，那时她的卡拉萨在长枪党统治时期是国王的住所，多斯拉克人肥胖的卡拉萨在骑马南下消灭其他多斯拉克人之前，会在他们的杯子里倒满美酒、鱼餐和烤芜菁。这只是供思考的食粮。我会大吃大喝，假装休息，直到龙再次出现，杀死我们所有人。</p></blockquote><figure class="kq kr ks kt gt ku gh gi paragraph-image"><div class="gh gi oj"><img src="../Images/50cd9a14357d0ee2b25047351212135f.png" data-original-src="https://miro.medium.com/v2/resize:fit:668/format:webp/1*qDlehYNap1SP6nX04AUFoA.jpeg"/></div></figure><p id="b1ac" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">总是吃喝的好时机，对吧？我听说君临有一家不错的咖啡店，丹妮可以去试试(如果它还没被烧毁的话)。这很糟糕，让我们再试一次。</p></div><div class="ab cl ny nz hx oa" role="separator"><span class="ob bw bk oc od oe"/><span class="ob bw bk oc od oe"/><span class="ob bw bk oc od"/></div><div class="im in io ip iq"><blockquote class="nr ns nt"><p id="242b" class="jq jr ko js b jt ju jv jw jx jy jz ka nu kc kd ke nv kg kh ki nw kk kl km kn im bi translated">丹妮莉丝在埃索斯和弥林拥有爱和恐惧。但在维斯特洛，她觉得自己只有恐惧。在她赢得铁王座之战的那一刻，她只能想着给她将要统治的人民灌输恐惧。丹妮莉丝在君临坐在她的龙上，她决定要</p><p id="2979" class="jq jr ko js b jt ju jv jw jx jy jz ka nu kc kd ke nv kg kh ki nw kk kl km kn im bi translated">保护这座城市，并为任何试图逃跑的人准备好坦格利安的灾难和恐怖，是的，包括人类。有人告诉她，一些巨人可能会杀死她，但丹妮莉丝摇摇头说:“没有巨人喜欢长得像巨人一样大。后来，后来，没有人愿意孤独地死在树林里。”她又读了一遍信。“昆汀王子，我忠诚的仆人们，我见过你们这样愚蠢的傻瓜，但我从未见过你们这样愚蠢的傻瓜。你的生命在众目睽睽之下被夺走了。丹妮莉丝是唯一能救你的人。”</p></blockquote><figure class="kq kr ks kt gt ku gh gi paragraph-image"><div class="gh gi ok"><img src="../Images/1d11665ec88c543ece6253a210bb5dae.png" data-original-src="https://miro.medium.com/v2/resize:fit:676/format:webp/1*F78U0AVJt5lyVCG8WYbAMA.jpeg"/></div></figure><p id="ab17" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">所以这也没什么意义，但似乎坚持了丹妮想把君临的人民从那些准备“屈膝”且不打算逃跑的暴君手中解放出来的叙事。</p></div><div class="ab cl ny nz hx oa" role="separator"><span class="ob bw bk oc od oe"/><span class="ob bw bk oc od oe"/><span class="ob bw bk oc od"/></div><div class="im in io ip iq"><h1 id="c793" class="lj lk it bd ll lm ol lo lp lq om ls lt lu on lw lx ly oo ma mb mc op me mf mg bi translated">结论</h1><p id="d279" class="pw-post-body-paragraph jq jr it js b jt mh jv jw jx mi jz ka kb mj kd ke kf mk kh ki kj ml kl km kn im bi translated">我试图为这些故事情节生成更多的样本，但没有一个在整个节目的背景下有很大的意义。即使对故事情节的理解不是很好，该模型也清楚地展示了学习该剧角色及其某些特质的能力，并在其输出中创建这些角色之间的关联。比如，我看到乔拉爵士在故事情节中出现在谈论丹妮的时候，阿多在谈论布兰的时候出现。而且它往往把这些角色之间的关系处理得恰到好处，真的让人印象深刻！</p><p id="410c" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">我认为这显示了随着 OpenAI 的 GPT-2 研究工作，NLP 研究已经前进了多远。我很想知道最大的 GPT-2 型号在这项任务中表现得有多好。也许如果更大的模型被发布，我会回来更新这篇文章。</p><p id="0410" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">至于想要一个令人满意和明智的《权力的游戏》结局，我想当代的人工智能帮不了我们，我们必须等待乔治·R·R·马丁完成他的书。愿他万岁！</p></div><div class="ab cl ny nz hx oa" role="separator"><span class="ob bw bk oc od oe"/><span class="ob bw bk oc od oe"/><span class="ob bw bk oc od"/></div><div class="im in io ip iq"><p id="bc30" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">想在你的浏览器上试试《GPT 2》的《权力的游戏》模型吗？用于测试预训练模型的 Google Colab 笔记本链接如下(<a class="ae lh" href="https://github.com/ak9250" rel="noopener ugc nofollow" target="_blank">为该笔记本提供</a>)。</p><div class="oq or gp gr os ot"><a href="https://colab.research.google.com/drive/18pLqrk1j4RQ1RNh69Fa-5WkoTeD4uzwq" rel="noopener  ugc nofollow" target="_blank"><div class="ou ab fo"><div class="ov ab ow cl cj ox"><h2 class="bd iu gy z fp oy fr fs oz fu fw is bi translated">谷歌联合实验室</h2><div class="pa l"><h3 class="bd b gy z fp oy fr fs oz fu fw dk translated">权力的游戏 GPT-2 文本生成器</h3></div><div class="pb l"><p class="bd b dl z fp oy fr fs oz fu fw dk translated">colab.research.google.com</p></div></div><div class="pc l"><div class="pd l pe pf pg pc ph kz ot"/></div></div></a></div></div><div class="ab cl ny nz hx oa" role="separator"><span class="ob bw bk oc od oe"/><span class="ob bw bk oc od oe"/><span class="ob bw bk oc od"/></div><div class="im in io ip iq"><p id="175e" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu">参考文献</strong></p><ul class=""><li id="20ec" class="mm mn it js b jt ju jx jy kb mo kf mp kj mq kn pi ms mt mu bi translated"><a class="ae lh" href="https://blog.floydhub.com/gpt2/" rel="noopener ugc nofollow" target="_blank">如何构建 OpenAI 的 GPT-2:“太危险而无法释放的 AI”</a></li><li id="9a45" class="mm mn it js b jt mv jx mw kb mx kf my kj mz kn pi ms mt mu bi translated"><a class="ae lh" href="https://blog.floydhub.com/the-transformer-in-pytorch/" rel="noopener ugc nofollow" target="_blank">如何在 PyTorch 中对变压器进行编码</a></li><li id="0df5" class="mm mn it js b jt mv jx mw kb mx kf my kj mz kn pi ms mt mu bi translated"><a class="ae lh" href="https://mchromiak.github.io/articles/2017/Sep/12/Transformer-Attention-is-all-you-need/#.XOTHdMhKiM8" rel="noopener ugc nofollow" target="_blank">变形金刚:注意力是你需要的全部</a></li><li id="8f1b" class="mm mn it js b jt mv jx mw kb mx kf my kj mz kn pi ms mt mu bi translated"><a class="ae lh" href="https://gpt2.apps.allenai.org" rel="noopener ugc nofollow" target="_blank">在浏览器上玩 GPT-2</a></li></ul></div><div class="ab cl ny nz hx oa" role="separator"><span class="ob bw bk oc od oe"/><span class="ob bw bk oc od oe"/><span class="ob bw bk oc od"/></div><div class="im in io ip iq"><p id="5495" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">感谢您的阅读。如果你喜欢这篇文章，你可以在<a class="ae lh" href="https://medium.com/@chintan.t93" rel="noopener">媒体</a>、<a class="ae lh" href="https://github.com/ChintanTrivedi" rel="noopener ugc nofollow" target="_blank"> GitHub </a>上关注我的更多作品，或者订阅我的<a class="ae lh" href="http://youtube.com/c/DeepGamingAI" rel="noopener ugc nofollow" target="_blank"> YouTube 频道</a>。动手吧。弯曲膝盖。或者面对我的龙。</p></div></div>    
</body>
</html>