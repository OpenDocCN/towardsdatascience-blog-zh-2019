<html>
<head>
<title>Pyspark — wrap your feature engineering in a pipeline</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">Pyspark —将您的特征工程包装在管道中</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/pyspark-wrap-your-feature-engineering-in-a-pipeline-ee63bdb913?source=collection_archive---------14-----------------------#2019-09-16">https://towardsdatascience.com/pyspark-wrap-your-feature-engineering-in-a-pipeline-ee63bdb913?source=collection_archive---------14-----------------------#2019-09-16</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="092d" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">将变量创建集成到 spark 管道的指南</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/c642dff3a6b7d10764cc9b447e82d151.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*jvxJNDq39isZ-Kgf9VsSAQ.png"/></div></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk"><a class="ae ky" href="https://upload.wikimedia.org/wikipedia/commons/f/f3/Apache_Spark_logo.svg" rel="noopener ugc nofollow" target="_blank">https://upload.wikimedia.org/wikipedia/commons/f/f3/Apache_Spark_logo.svg</a></figcaption></figure><p id="d959" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">为了有一个更干净和更工业化的代码，创建一个处理特征工程的管道对象可能是有用的。假设我们有这种类型的数据帧:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="lv lw l"/></div></figure><pre class="kj kk kl km gt lx ly lz ma aw mb bi"><span id="43d9" class="mc md it ly b gy me mf l mg mh">df.show()</span><span id="a134" class="mc md it ly b gy mi mf l mg mh">+----------+-----+<br/>|      date|sales|<br/>+----------+-----+<br/>|2018-12-22|   17|<br/>|2017-01-08|   22|<br/>|2015-08-25|   48|<br/>|2015-03-12|  150|<br/>+----------+-----+</span></pre><p id="7721" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">然后我们想创建从日期派生的变量。大多数时候，我们会做这样的事情:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="lv lw l"/></div></figure><p id="8434" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">现在，我们希望将这些变量的创建集成到 spark 的管道中，此外，在它们的计算之前采取一些保护措施。为此，我们将创建一个继承 spark 管道的<code class="fe mj mk ml ly b"><a class="ae ky" href="https://spark.apache.org/docs/latest/ml-pipeline.html#transformers" rel="noopener ugc nofollow" target="_blank">Transformer</a></code>方法的<strong class="lb iu">的类，并且我们将添加一个在计算前检查输入的函数。</strong></p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="lv lw l"/></div></figure><ul class=""><li id="fabc" class="mm mn it lb b lc ld lf lg li mo lm mp lq mq lu mr ms mt mu bi translated">我们的类继承了 Spark <code class="fe mj mk ml ly b"><a class="ae ky" href="https://spark.apache.org/docs/latest/ml-pipeline.html#transformers" rel="noopener ugc nofollow" target="_blank">Transforme</a>r</code>的属性，这允许我们将其插入到管道中。</li><li id="b21a" class="mm mn it lb b lc mv lf mw li mx lm my lq mz lu mr ms mt mu bi translated"><code class="fe mj mk ml ly b"><a class="ae ky" href="https://spark.apache.org/docs/latest/api/java/org/apache/spark/ml/util/Identifiable.html" rel="noopener ugc nofollow" target="_blank">this</a></code>函数允许我们通过给对象分配一个唯一的 ID 来使我们的对象在管道中可识别和不可变</li><li id="ddcb" class="mm mn it lb b lc mv lf mw li mx lm my lq mz lu mr ms mt mu bi translated"><code class="fe mj mk ml ly b"><a class="ae ky" href="https://spark.apache.org/docs/1.5.1/api/java/org/apache/spark/ml/param/Params.html#defaultCopy(org.apache.spark.ml.param.ParamMap)" rel="noopener ugc nofollow" target="_blank">defaultCopy</a></code>尝试创建一个具有相同 UID 的新实例。然后，它复制嵌入的和额外的参数，并返回新的实例。</li><li id="c1ee" class="mm mn it lb b lc mv lf mw li mx lm my lq mz lu mr ms mt mu bi translated">然后使用 check_input_type 函数检查输入字段的格式是否正确，最后我们简单地实现<code class="fe mj mk ml ly b"><a class="ae ky" href="https://spark.apache.org/docs/2.3.0/api/sql/index.html" rel="noopener ugc nofollow" target="_blank">SQL Functions</a></code> F.day of month 来返回我们的列。</li></ul><p id="158e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们将重用这个框架来创建我们需要的其他变量，他唯一要做的改变就是 ID 和 _transform 函数</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="lv lw l"/></div></figure><p id="afb9" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们已经定义了具有相同框架的 MonthQuarterExtractor，与<code class="fe mj mk ml ly b"><a class="ae ky" href="https://spark.apache.org/docs/1.6.1/api/java/org/apache/spark/sql/DataFrame.html#withColumn(java.lang.String,%20org.apache.spark.sql.Column)" rel="noopener ugc nofollow" target="_blank">withColumn</a> </code>方法相比，它可能看起来有点冗长，但是要干净得多！</p><p id="4d8d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">最后，我们对年份变量做同样的处理。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="lv lw l"/></div></figure><p id="8633" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">现在让我们将它们集成到我们的管道中。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="lv lw l"/></div></figure><pre class="kj kk kl km gt lx ly lz ma aw mb bi"><span id="42ad" class="mc md it ly b gy me mf l mg mh">df.show()</span><span id="3cff" class="mc md it ly b gy mi mf l mg mh">+----------+-----+----------+----+------------+<br/>|      date|sales|dayofmonth|year|monthquarter|<br/>+----------+-----+----------+----+------------+<br/>|2018-12-22|   17|        22|2018|           2|<br/>|2017-01-08|   22|         8|2017|           0|<br/>|2015-08-25|   48|        25|2015|           3|<br/>|2015-03-12|  150|        12|2015|           1|<br/>+----------+-----+----------+----+------------+</span></pre><p id="4e4e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">诀窍是，我们创建了一个“海关”变压器，并将其插入火花管道。也可以将它们与其他对象、向量汇编器、字符串索引器或其他对象一起插入管道。</p><h1 id="5150" class="na md it bd nb nc nd ne nf ng nh ni nj jz nk ka nl kc nm kd nn kf no kg np nq bi translated">最后</h1><p id="93d7" class="pw-post-body-paragraph kz la it lb b lc nr ju le lf ns jx lh li nt lk ll lm nu lo lp lq nv ls lt lu im bi translated">Spark 管道是一个非常强大的工具，我们可以在一个管道中管理几乎整个数据科学项目，同时保持每个对象的可追溯性，并允许更简单的代码工业化，不要犹豫滥用它！</p></div><div class="ab cl nw nx hx ny" role="separator"><span class="nz bw bk oa ob oc"/><span class="nz bw bk oa ob oc"/><span class="nz bw bk oa ob"/></div><div class="im in io ip iq"><p id="3d97" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">感谢您阅读我，如果您对 Pyspark 的更多技巧|教程感兴趣，请不要犹豫，留下您的评论。<em class="od"> (Y </em> ou 可以在这里找到代码<em class="od">:</em><a class="ae ky" href="https://github.com/AlexWarembourg/Medium" rel="noopener ugc nofollow" target="_blank"><em class="od"/></a><em class="od">)</em></p></div></div>    
</body>
</html>