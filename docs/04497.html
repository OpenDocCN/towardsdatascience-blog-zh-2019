<html>
<head>
<title>Anomaly Detection in Images</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">图像中的异常检测</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/anomaly-detection-in-images-777534980aeb?source=collection_archive---------7-----------------------#2019-07-11">https://towardsdatascience.com/anomaly-detection-in-images-777534980aeb?source=collection_archive---------7-----------------------#2019-07-11</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="02e9" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">用卷积神经网络对异常进行分类和个性化</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/f1c399c574e2a335cd4df5e0a24171df.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*9ftroLImbTTkLSgc"/></div></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk">Photo by <a class="ae ky" href="https://unsplash.com/@dissii?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">mahdis mousavi</a> on <a class="ae ky" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><p id="f89d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在机器学习中处理异常检测任务是正常的。数据科学家经常会遇到一些问题，他们必须显示、解释和预测异常。</p><p id="873a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我还发表了一篇关于时间序列的<a class="ae ky" rel="noopener" target="_blank" href="/anomaly-detection-with-lstm-in-keras-8d8d7e50ab1b">异常检测的帖子，其中我研究了内部系统行为，并提供了未来的异常预测。</a></p><p id="f35b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在这篇文章中，我试图解决一个不同的挑战。我改变感兴趣的领域:从时间序列转换到图像。给定一幅图像，我们想要达到双重目的:<strong class="lb iu">预测异常的存在并对其进行个性化</strong>，给出结果的彩色表示。</p><h1 id="b238" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">数据集</h1><p id="f5bd" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">我从网上得到的数据:<a class="ae ky" href="https://www.kaggle.com/arunrk7/surface-crack-detection" rel="noopener ugc nofollow" target="_blank">裂缝数据集</a>包含墙壁裂缝的图像。一半的图像显示了新的和未被破坏的墙体；其余部分显示了不同尺寸和类型的裂缝。</p><p id="5afb" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">正如你从下面的样本中看到的，我们的数据显示了不同类型的墙体裂缝，其中一些对我来说也不容易识别。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ms"><img src="../Images/7fe0d463f2985a14a25272a7f0bf6aff.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*e5a_5IdxX0BIp8Lmh_xDOw.png"/></div></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk">Examples of Crack and No Crack</figcaption></figure><h1 id="638f" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">模型</h1><p id="05dc" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">我们希望建立一个机器学习模型，它能够对墙壁图像进行分类，同时检测出异常所在的位置。为了达到这个双重目的，最有效的方法是建立一个强分类器。它将能够读取我们的输入图像，并将其分类为“受损”或“未受损”。在最后一步，我们将利用我们的分类器学习的知识来提取有用的信息，这将有助于我们检测哪里有异常。</p><p id="7c0c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">但是让我们按顺序进行，开始组装我们的神经网络…</p><p id="8263" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">对于这种任务，我选择了计算机视觉的银弹，忠诚 VGG16。我们装载并改造了 VGG16 列车。这在 Keras 中很容易做到，只需要几行代码。</p><pre class="kj kk kl km gt mt mu mv mw aw mx bi"><span id="8e16" class="my lw it mu b gy mz na l nb nc">vgg_conv = vgg16.VGG16(weights='imagenet', include_top=False, input_shape = (224, 224, 3))</span><span id="9bcb" class="my lw it mu b gy nd na l nb nc">for layer in vgg_conv.layers[:-8]:<br/>    layer.trainable = False</span></pre><p id="dbc8" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">具体来说，我们引入了 VGG 架构，允许训练最后两个卷积块。这将允许我们的模型专门处理我们的分类任务。为此，我们还排除了原始模型的顶层，用另一个结构替换它们。</p><pre class="kj kk kl km gt mt mu mv mw aw mx bi"><span id="cb82" class="my lw it mu b gy mz na l nb nc">x = vgg_conv.output<br/>x = GlobalAveragePooling2D()(x)<br/>x = Dense(2, activation="softmax")(x)<br/>model = Model(vgg_conv.input, x)</span><span id="366d" class="my lw it mu b gy nd na l nb nc">model.compile(loss = "categorical_crossentropy", optimizer = optimizers.SGD(lr=0.0001, momentum=0.9), metrics=["accuracy"])</span></pre><p id="c1e8" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在分类阶段，GlobalAveragePooling 图层通过取每个要素地图的平均值来减小前一图层的大小。这种选择，加上中间致密层的省略使用，允许<a class="ae ky" href="https://arxiv.org/pdf/1312.4400.pdf" rel="noopener ugc nofollow" target="_blank">避免过度拟合</a>。</p><p id="a542" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">如果你有一个图形处理器，训练是简单和容易的。COLAB 或 Kaggle 给了我们加速这一进程所需的武器。我们还使用了一个由 Keras 提供的简单的数据生成器来增强图像。</p><p id="98b0" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">最终我们能够做到 0.90 的整体准确率，还不错！</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ne"><img src="../Images/05acd90652ee45608776c0de52c18cb9.png" data-original-src="https://miro.medium.com/v2/resize:fit:990/format:webp/1*2e1eFzE2QTx-98a29gWBPg.png"/></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk">From <a class="ae ky" href="https://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html" rel="noopener ugc nofollow" target="_blank">sklearn documentation</a></figcaption></figure><h1 id="210d" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">定位异常</h1><p id="90a0" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">现在，随着我们的模型被训练，我们使用<em class="nf"> </em>来提取所有有用的信息，这些信息允许我们在墙壁图像中显示裂缝。我们试图用<a class="ae ky" href="https://alexisbcook.github.io/2017/global-average-pooling-layers-for-object-localization/" rel="noopener ugc nofollow" target="_blank">热图表示法</a>让这个过程变得简单易懂。</p><p id="de64" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们需要的有用信息位于顶部。特别是，我们可以访问:</p><ul class=""><li id="6840" class="ng nh it lb b lc ld lf lg li ni lm nj lq nk lu nl nm nn no bi translated"><em class="nf">卷积层</em>:我们在 VGG 结构中走得更高，网络创造了更重要的特征。我们已经选择了最后一个卷积层(<em class="nf">block 5 _ con v3</em>’)，并在这里剪切我们的分类模型。我们重新创建了一个中间模型，给定原始图像作为输入，输出相关的激活图。考虑到维度，我们的中间模型增加了通道(新特征)并减少了初始图像的维度(高度和宽度)。</li><li id="4483" class="ng nh it lb b lc np lf nq li nr lm ns lq nt lu nl nm nn no bi translated"><em class="nf">最终密集层</em>:对于每个感兴趣的类，我们需要这些权重，它们负责提供分类的最终结果。</li></ul><p id="a9f5" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">有了这些压缩物体在手，我们就有了定位裂缝的所有知识。我们希望将它们“画”在原始图像上，以使结果易于理解和观看。在 python 中,“解压缩”这些信息很容易:我们只需进行双线性上采样来调整每个激活图的大小，并计算点积。</p><p id="35df" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这种魔力可以通过执行一个简单的函数来实现:</p><pre class="kj kk kl km gt mt mu mv mw aw mx bi"><span id="1658" class="my lw it mu b gy mz na l nb nc">def plot_activation(img):</span><span id="e89f" class="my lw it mu b gy nd na l nb nc">    pred = model.predict(img[np.newaxis,:,:,:])<br/>    pred_class = np.argmax(pred)</span><span id="5abb" class="my lw it mu b gy nd na l nb nc">    weights = model.layers[-1].get_weights()[0]<br/>    class_weights = weights[:, pred_class]</span><span id="b909" class="my lw it mu b gy nd na l nb nc">    intermediate = Model(model.input,<br/>                         model.get_layer("block5_conv3").output)<br/>    conv_output = intermediate.predict(img[np.newaxis,:,:,:])<br/>    conv_output = np.squeeze(conv_output)</span><span id="3ee5" class="my lw it mu b gy nd na l nb nc">    h = int(img.shape[0]/conv_output.shape[0])<br/>    w = int(img.shape[1]/conv_output.shape[1])</span><span id="5dbf" class="my lw it mu b gy nd na l nb nc">    act_maps = sp.ndimage.zoom(conv_output, (h, w, 1), order=1)<br/>    out = np.dot(act_maps.reshape((img.shape[0]*img.shape[1],512)), <br/>                 class_weights).reshape(img.shape[0],img.shape[1])</span><span id="8a86" class="my lw it mu b gy nd na l nb nc">    plt.imshow(img.astype('float32').reshape(img.shape[0],<br/>               img.shape[1],3))<br/>    plt.imshow(out, cmap='jet', alpha=0.35)<br/>    plt.title('Crack' if pred_class == 1 else 'No Crack')</span></pre><p id="9ba1" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我在下图中显示了结果，我在分类为裂纹的测试图像上绘制了裂纹热图。我们可以看到，热图能够很好地概括和指出含有裂缝的墙体。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nu"><img src="../Images/cda3ff50736e711ff1ad6b77508d1320.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*I57fduJpnY3sbmZmB16A0A.png"/></div></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk">Show anomalies in Crack images</figcaption></figure><h1 id="045d" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">摘要</h1><p id="c5e4" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">在这篇文章中，我们提出了一个用于异常识别和定位的机器学习解决方案。所有这些功能都可以通过实现单个分类模型来实现。在训练过程中，我们的神经网络获取所有相关信息，使其能够进行分类操作。在这一阶段之后，我们已经组装了最终的碎片，这些碎片告诉我们图像中的裂缝在哪里，不需要额外的工作！</p></div><div class="ab cl nv nw hx nx" role="separator"><span class="ny bw bk nz oa ob"/><span class="ny bw bk nz oa ob"/><span class="ny bw bk nz oa"/></div><div class="im in io ip iq"><p id="5c69" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><a class="ae ky" href="https://github.com/cerlymarco/MEDIUM_NoteBook" rel="noopener ugc nofollow" target="_blank"> <strong class="lb iu">查看我的 GITHUB 回购</strong> </a></p><p id="7e0d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">保持联系:<a class="ae ky" href="https://www.linkedin.com/in/marco-cerliani-b0bba714b/" rel="noopener ugc nofollow" target="_blank"> Linkedin </a></p></div></div>    
</body>
</html>