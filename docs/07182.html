<html>
<head>
<title>Creating a Weapon Detector in 5 simple steps</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">用 5 个简单的步骤制作武器探测器</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/plug-and-play-object-detection-code-in-5-simple-steps-f1975804373e?source=collection_archive---------11-----------------------#2019-10-10">https://towardsdatascience.com/plug-and-play-object-detection-code-in-5-simple-steps-f1975804373e?source=collection_archive---------11-----------------------#2019-10-10</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><figure class="is it gp gr iu iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi ir"><img src="../Images/86a7663f1676774ac9a903a2cfbfc5d7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*nLt_6mSQMYvmRfytWXNZSQ.png"/></div></div><figcaption class="jc jd gj gh gi je jf bd b be z dk"><a class="ae jg" href="https://storage.googleapis.com/openimages/web/index.html" rel="noopener ugc nofollow" target="_blank">Source</a></figcaption></figure><h2 id="3c3b" class="jh ji jj bd b dl jk jl jm jn jo jp dk jq translated" aria-label="kicker paragraph">目标检测</h2><div class=""/><div class=""><h2 id="a62a" class="pw-subtitle-paragraph kp js jj bd b kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg dk translated">在自定义数据集上使用 mask-RCNN 进行目标检测</h2></div><p id="74a7" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">对象检测是编码库中的一个有用工具。</p><p id="7c2c" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">它构成了许多奇妙工业应用的基础。其中一些是自动驾驶汽车、医学成像和人脸检测。</p><p id="d9db" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">在我上一篇关于物体检测的文章中，我谈到了物体检测模型是如何发展的。</p><p id="32dc" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">但是如果我们不能实现它，理论有什么用呢？</p><p id="837a" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated"><strong class="lj jt"> <em class="md">这篇文章是关于在我们定制的武器数据集上实现并获得一个物体探测器。</em> </strong></p><p id="4b92" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">我们今天要特别解决的问题是使用 Mask-RCNN 的实例分割。</p></div><div class="ab cl me mf hx mg" role="separator"><span class="mh bw bk mi mj mk"/><span class="mh bw bk mi mj mk"/><span class="mh bw bk mi mj"/></div><div class="im in io ip iq"><h1 id="cba2" class="ml mm jj bd mn mo mp mq mr ms mt mu mv ky mw kz mx lb my lc mz le na lf nb nc bi translated">实例分割</h1><p id="bff3" class="pw-post-body-paragraph lh li jj lj b lk nd kt lm ln ne kw lp lq nf ls lt lu ng lw lx ly nh ma mb mc im bi translated"><em class="md">我们可以为图像中的每个物体创建</em> <strong class="lj jt">蒙版</strong> <em class="md">吗？具体来说就是:</em></p><figure class="nj nk nl nm gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi ni"><img src="../Images/d4d95c8a530d8fd2456b5c4e869b4725.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*SZWUVZ5JoYEqc1ZB.png"/></div></div></figure><p id="e569" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">解决这个问题最常见的方法是使用 Mask-RCNN。Mask-RCNN 的架构如下所示:</p><figure class="nj nk nl nm gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi nn"><img src="../Images/ceced10377c3b3bcf2e1aa39f5158211.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*hZZ96XZKApETfWCW.png"/></div></div><figcaption class="jc jd gj gh gi je jf bd b be z dk"><a class="ae jg" href="https://medium.com/@jonathan_hui/image-segmentation-with-mask-r-cnn-ebe6d793272" rel="noopener">Source</a></figcaption></figure><p id="8b11" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">基本上，它包括:</p><ul class=""><li id="efa0" class="no np jj lj b lk ll ln lo lq nq lu nr ly ns mc nt nu nv nw bi translated">像 resnet50/resnet101 这样的主干网络</li><li id="8495" class="no np jj lj b lk nx ln ny lq nz lu oa ly ob mc nt nu nv nw bi translated">区域提案网络</li><li id="60d3" class="no np jj lj b lk nx ln ny lq nz lu oa ly ob mc nt nu nv nw bi translated">ROI-对齐层</li><li id="d731" class="no np jj lj b lk nx ln ny lq nz lu oa ly ob mc nt nu nv nw bi translated">两个输出图层-一个用于预测掩膜，一个用于预测类和边界框。</li></ul><p id="7545" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">还有很多事情要做。如果你想了解更多的理论，请阅读我的上一篇文章。</p><div class="is it gp gr iu oc"><a rel="noopener follow" target="_blank" href="/a-hitchhikers-guide-to-object-detection-and-instance-segmentation-ac0146fe8e11"><div class="od ab fo"><div class="oe ab of cl cj og"><h2 class="bd jt gy z fp oh fr fs oi fu fw js bi translated">为数据科学家揭秘对象检测和实例分割</h2><div class="oj l"><h3 class="bd b gy z fp oh fr fs oi fu fw dk translated">简单解释！！！我试过了</h3></div><div class="ok l"><p class="bd b dl z fp oh fr fs oi fu fw dk translated">towardsdatascience.com</p></div></div><div class="ol l"><div class="om l on oo op ol oq ja oc"/></div></div></a></div><p id="6f02" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">这篇文章主要是关于<a class="ae jg" href="https://github.com/MLWhiz/object_detection" rel="noopener ugc nofollow" target="_blank">代码</a>。</p></div><div class="ab cl me mf hx mg" role="separator"><span class="mh bw bk mi mj mk"/><span class="mh bw bk mi mj mk"/><span class="mh bw bk mi mj"/></div><div class="im in io ip iq"><h1 id="8010" class="ml mm jj bd mn mo mp mq mr ms mt mu mv ky mw kz mx lb my lc mz le na lf nb nc bi translated">1.为实例分段创建自定义数据集</h1><figure class="nj nk nl nm gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi or"><img src="../Images/546c85926a7953192958bd93958d9c4f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*tYtU3F1u6SQyn62V.jpg"/></div></div><figcaption class="jc jd gj gh gi je jf bd b be z dk">Our Dataset</figcaption></figure><p id="0341" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">我们将要研究的用例是一个武器探测器。武器探测器是一种可以与街头摄像机和闭路电视一起使用来打击犯罪的东西。所以它非常漂亮。</p><p id="cca3" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">因此，我开始从<a class="ae jg" href="https://storage.googleapis.com/openimages/web/index.html" rel="noopener ugc nofollow" target="_blank">开放图像数据集</a>下载 40 张枪和剑的图像，并使用 VIA 工具对它们进行注释。现在在 VIA 中设置注释项目是非常重要的，所以我将尝试一步一步地解释它。</p><h2 id="3342" class="os mm jj bd mn ot ou dn mr ov ow dp mv lq ox oy mx lu oz pa mz ly pb pc nb jp bi translated">1.通过设置</h2><p id="2e39" class="pw-post-body-paragraph lh li jj lj b lk nd kt lm ln ne kw lp lq nf ls lt lu ng lw lx ly nh ma mb mc im bi translated">VIA 是一个注释工具，使用它你可以注释图像的边界框和遮罩。我发现它是最好的注释工具之一，因为它是在线的，可以在浏览器中运行。</p><p id="ed81" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">要使用它，打开<a class="ae jg" href="http://www.robots.ox.ac.uk/~vgg/software/via/via.html" rel="noopener ugc nofollow" target="_blank">http://www.robots.ox.ac.uk/~vgg/software/via/via.html</a></p><p id="9726" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">您将看到如下页面:</p><figure class="nj nk nl nm gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi pd"><img src="../Images/715906ed470417c6febbbf43373f4b7d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*FN0kkG1RGug-pm9yJec1tw.png"/></div></div></figure><p id="039e" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">接下来我们要做的是在 region_attributes 中添加不同的类名。在这里，我根据我们的用例添加了“枪”和“剑”,因为这是我想要注释的两个不同的目标。</p><figure class="nj nk nl nm gt iv gh gi paragraph-image"><div class="gh gi pe"><img src="../Images/f0e5d22eceac10a3b98e8b5d91d90d16.png" data-original-src="https://miro.medium.com/v2/resize:fit:1164/format:webp/1*p6Y2XvBtuWkP9EVYsSoEZA.png"/></div></figure><h2 id="e664" class="os mm jj bd mn ot ou dn mr ov ow dp mv lq ox oy mx lu oz pa mz ly pb pc nb jp bi translated">2.注释图像</h2><p id="d211" class="pw-post-body-paragraph lh li jj lj b lk nd kt lm ln ne kw lp lq nf ls lt lu ng lw lx ly nh ma mb mc im bi translated">我把所有的文件都放在了文件夹<code class="fe pf pg ph pi b">data</code>里。下一步是添加我们想要注释的文件。我们可以使用 VIA 工具中的“添加文件”按钮在<code class="fe pf pg ph pi b">data</code>文件夹中添加文件。并在选择折线工具后开始标注标签，如下所示。</p><figure class="nj nk nl nm gt iv gh gi paragraph-image"><div class="gh gi pj"><img src="../Images/b0cb5d1b24f29003578c32098c570b0c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1280/1*b3bRETW_qNt0JFOrbAh_eg.gif"/></div><figcaption class="jc jd gj gh gi je jf bd b be z dk">Click, Click, Enter, Escape, Select</figcaption></figure><h2 id="268b" class="os mm jj bd mn ot ou dn mr ov ow dp mv lq ox oy mx lu oz pa mz ly pb pc nb jp bi translated">3.下载注释文件</h2><p id="86e7" class="pw-post-body-paragraph lh li jj lj b lk nd kt lm ln ne kw lp lq nf ls lt lu ng lw lx ly nh ma mb mc im bi translated">点击 VIA 工具顶部菜单上的<code class="fe pf pg ph pi b">save project</code>。</p><figure class="nj nk nl nm gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi pk"><img src="../Images/68a33bc2146333c5dffc8809dd62c61a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*bocbcRD4JZ433BDR1IuLYg.png"/></div></div></figure><p id="d4d9" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">通过更改项目名称字段，将文件另存为<code class="fe pf pg ph pi b">via_region_data.json</code>。这将把注释保存为 COCO 格式。</p><h2 id="280e" class="os mm jj bd mn ot ou dn mr ov ow dp mv lq ox oy mx lu oz pa mz ly pb pc nb jp bi translated">4.设置数据目录结构</h2><p id="10ea" class="pw-post-body-paragraph lh li jj lj b lk nd kt lm ln ne kw lp lq nf ls lt lu ng lw lx ly nh ma mb mc im bi translated">我们将需要首先设置数据目录，以便我们可以进行对象检测。在下面的代码中，我创建了一个我们将要使用的模型所需要的目录结构。</p><figure class="nj nk nl nm gt iv"><div class="bz fp l di"><div class="pl pm l"/></div></figure><p id="8e66" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">运行上述代码后，我们将获得以下文件夹结构中的数据:</p><pre class="nj nk nl nm gt pn pi po pp aw pq bi"><span id="5a02" class="os mm jj pi b gy pr ps l pt pu">- procdata<br/>     - train<br/>         - img1.jpg<br/>         - img2.jpg<br/>         - via_region_data.json<br/>     - val<br/>         - img3.jpg<br/>         - img4.jpg<br/>         - via_region_data.json</span></pre></div><div class="ab cl me mf hx mg" role="separator"><span class="mh bw bk mi mj mk"/><span class="mh bw bk mi mj mk"/><span class="mh bw bk mi mj"/></div><div class="im in io ip iq"><h1 id="7a3e" class="ml mm jj bd mn mo mp mq mr ms mt mu mv ky mw kz mx lb my lc mz le na lf nb nc bi translated">2.设置编码环境</h1><p id="a39e" class="pw-post-body-paragraph lh li jj lj b lk nd kt lm ln ne kw lp lq nf ls lt lu ng lw lx ly nh ma mb mc im bi translated">我们将使用来自<code class="fe pf pg ph pi b"><a class="ae jg" href="https://github.com/matterport/Mask_RCNN" rel="noopener ugc nofollow" target="_blank">matterport/Mask_RCNN</a></code> GitHub 库的代码。您可以从克隆存储库和安装所需的库开始。</p><pre class="nj nk nl nm gt pn pi po pp aw pq bi"><span id="f293" class="os mm jj pi b gy pr ps l pt pu">git clone <a class="ae jg" href="https://github.com/matterport/Mask_RCNN" rel="noopener ugc nofollow" target="_blank">https://github.com/matterport/Mask_RCNN</a><br/>cd Mask_RCNN<br/>pip install -r requirements.txt</span></pre><p id="cb10" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">一旦我们完成了依赖项的安装和 repo 的克隆，我们就可以开始实现我们的项目了。</p><p id="cabc" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">我们在<code class="fe pf pg ph pi b">Mask_RCNN</code>文件夹中复制了一份<code class="fe pf pg ph pi b">samples/balloon</code>目录，并创建了一个<code class="fe pf pg ph pi b"><strong class="lj jt"><em class="md">samples/guns_and_swords</em></strong></code> <strong class="lj jt"> <em class="md"> </em> </strong>目录，我们将在这里继续我们的工作:</p><pre class="nj nk nl nm gt pn pi po pp aw pq bi"><span id="cf9d" class="os mm jj pi b gy pr ps l pt pu">cp -r samples/balloon <strong class="pi jt"><em class="md">samples/guns_and_swords</em></strong></span></pre><h2 id="0001" class="os mm jj bd mn ot ou dn mr ov ow dp mv lq ox oy mx lu oz pa mz ly pb pc nb jp bi translated">设置代码</h2><figure class="nj nk nl nm gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi or"><img src="../Images/d959eb3ed447e81e862aa107d28a6058.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*UDCgIvSBnE6f3OA8.jpg"/></div></div><figcaption class="jc jd gj gh gi je jf bd b be z dk">Yes. We are doing AI</figcaption></figure><p id="fa8b" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">我们从重命名开始，将<code class="fe pf pg ph pi b"><strong class="lj jt"><em class="md">samples/guns_and_swords</em></strong></code> <strong class="lj jt"> <em class="md">目录中的 balloon.py 改为</em> </strong> <code class="fe pf pg ph pi b"><strong class="lj jt"><em class="md">gns</em>.py</strong></code>。<code class="fe pf pg ph pi b">balloon.py</code>文件现在只训练一个目标。我已经扩展到使用多个目标。在这个文件中，我们更改了:</p><ol class=""><li id="53aa" class="no np jj lj b lk ll ln lo lq nq lu nr ly ns mc pv nu nv nw bi translated"><code class="fe pf pg ph pi b">balloonconfig</code>至<code class="fe pf pg ph pi b">gnsConfig</code></li><li id="a952" class="no np jj lj b lk nx ln ny lq nz lu oa ly ob mc pv nu nv nw bi translated"><code class="fe pf pg ph pi b">BalloonDataset</code>到<code class="fe pf pg ph pi b">gnsDataset</code>:我们在这里修改了一些代码，以便从我们的注释数据中获取目标名称，并给出多个目标。</li><li id="b35b" class="no np jj lj b lk nx ln ny lq nz lu oa ly ob mc pv nu nv nw bi translated">以及<code class="fe pf pg ph pi b">train</code>功能的一些变化</li></ol><p id="5b32" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">此处仅显示更改后的<code class="fe pf pg ph pi b">gnsConfig</code>以让您有所了解。你可以在这里看一下整个<code class="fe pf pg ph pi b"><a class="ae jg" href="https://github.com/MLWhiz/data_science_blogs/blob/master/object_detection/guns_and_swords/gns.py" rel="noopener ugc nofollow" target="_blank">gns.py</a></code>代码。</p><figure class="nj nk nl nm gt iv"><div class="bz fp l di"><div class="pl pm l"/></div></figure></div><div class="ab cl me mf hx mg" role="separator"><span class="mh bw bk mi mj mk"/><span class="mh bw bk mi mj mk"/><span class="mh bw bk mi mj"/></div><div class="im in io ip iq"><h1 id="5eb5" class="ml mm jj bd mn mo mp mq mr ms mt mu mv ky mw kz mx lb my lc mz le na lf nb nc bi translated">3.可视化图像和遮罩</h1><p id="b8df" class="pw-post-body-paragraph lh li jj lj b lk nd kt lm ln ne kw lp lq nf ls lt lu ng lw lx ly nh ma mb mc im bi translated">一旦我们完成了对<code class="fe pf pg ph pi b">gns.py</code>文件的修改，我们就可以可视化我们的遮罩和图像了。简单按照这个<code class="fe pf pg ph pi b"><a class="ae jg" href="https://github.com/MLWhiz/data_science_blogs/blob/master/object_detection/guns_and_swords/1.%20Visualize%20Dataset.ipynb" rel="noopener ugc nofollow" target="_blank">Visualize Dataset.ipynb</a></code> <a class="ae jg" href="https://github.com/MLWhiz/data_science_blogs/blob/master/object_detection/guns_and_swords/1.%20Visualize%20Dataset.ipynb" rel="noopener ugc nofollow" target="_blank"> </a>笔记本就可以了。</p><div class="nj nk nl nm gt ab cb"><figure class="pw iv px py pz qa qb paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><img src="../Images/a4655f24b27adb39d48cbd75dcf4251a.png" data-original-src="https://miro.medium.com/v2/resize:fit:716/format:webp/1*WGxEqOqn02CR9GDHFEUJVw.png"/></div></figure><figure class="pw iv qc py pz qa qb paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><img src="../Images/50816b352eecd7b689587d2f1bc8c399.png" data-original-src="https://miro.medium.com/v2/resize:fit:1286/format:webp/1*IoO6HtnBjo8TgYx9vZ3oag.png"/></div></figure></div><div class="ab cb"><figure class="pw iv qd py pz qa qb paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><img src="../Images/ca6884f693cbb6f6c3132b2ba0d98968.png" data-original-src="https://miro.medium.com/v2/resize:fit:1046/format:webp/1*ybwL8L4AuzluJmIj-IqObA.png"/></div></figure><figure class="pw iv qe py pz qa qb paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><img src="../Images/15c4d099e9b599028430fa7e4f9f6c6a.png" data-original-src="https://miro.medium.com/v2/resize:fit:956/format:webp/1*zkZEBxiaRqkjjfmYyxgKkA.png"/></div></figure></div></div><div class="ab cl me mf hx mg" role="separator"><span class="mh bw bk mi mj mk"/><span class="mh bw bk mi mj mk"/><span class="mh bw bk mi mj"/></div><div class="im in io ip iq"><h1 id="5010" class="ml mm jj bd mn mo mp mq mr ms mt mu mv ky mw kz mx lb my lc mz le na lf nb nc bi translated">4.用迁移学习训练 MaskRCNN 模型</h1><p id="addf" class="pw-post-body-paragraph lh li jj lj b lk nd kt lm ln ne kw lp lq nf ls lt lu ng lw lx ly nh ma mb mc im bi translated">为了训练 maskRCNN 模型，在 Guns and Swords 数据集上，我们需要在命令行上运行以下命令之一，这取决于我们是否要用 COCO 权重或 imagenet 权重初始化我们的模型:</p><pre class="nj nk nl nm gt pn pi po pp aw pq bi"><span id="9353" class="os mm jj pi b gy pr ps l pt pu"># Train a new model starting from pre-trained COCO weights<br/> python3 gns.py train — dataset=/path/to/dataset — weights=coco</span><span id="e88f" class="os mm jj pi b gy qf ps l pt pu"># Resume training a model that you had trained earlier<br/> python3 gns.py train — dataset=/path/to/dataset — weights=last</span><span id="5948" class="os mm jj pi b gy qf ps l pt pu"># Train a new model starting from ImageNet weights<br/> python3 gns.py train — dataset=/path/to/dataset — weights=imagenet</span></pre><p id="4496" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">与<code class="fe pf pg ph pi b">weights=last</code>的命令将从最后一个纪元恢复训练。重量将保存在<code class="fe pf pg ph pi b">Mask_RCNN</code>文件夹的<code class="fe pf pg ph pi b">logs</code>目录中。</p><p id="95bc" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">这就是我们最后一个纪元后的损失。</p><figure class="nj nk nl nm gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi qg"><img src="../Images/97e925393dfd8f774a7a4785614215b4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*gKwKv6-64J6MnDGJskOj2Q.png"/></div></div></figure><h2 id="26de" class="os mm jj bd mn ot ou dn mr ov ow dp mv lq ox oy mx lu oz pa mz ly pb pc nb jp bi translated">使用 Tensorboard 可视化损失</h2><p id="18a8" class="pw-post-body-paragraph lh li jj lj b lk nd kt lm ln ne kw lp lq nf ls lt lu ng lw lx ly nh ma mb mc im bi translated">你可以利用 tensorboard 来可视化你的网络是如何运行的。只需运行:</p><pre class="nj nk nl nm gt pn pi po pp aw pq bi"><span id="be00" class="os mm jj pi b gy pr ps l pt pu">tensorboard --logdir ~/objectDetection/Mask_RCNN/logs/gns20191010T1234</span></pre><p id="4e3f" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">你可以在</p><pre class="nj nk nl nm gt pn pi po pp aw pq bi"><span id="0401" class="os mm jj pi b gy pr ps l pt pu"><a class="ae jg" href="https://localhost:6006" rel="noopener ugc nofollow" target="_blank">https://localhost:6006</a></span></pre><p id="015d" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">这是我们面具损失的样子:</p><figure class="nj nk nl nm gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi qh"><img src="../Images/554d85373562e6f97f86d24b837c4714.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*GzJfSqX_e4o_RbLk9U-1Sw.png"/></div></div></figure><p id="1060" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">我们可以看到，验证损失表现得相当突然。这是意料之中的，因为我们在验证集中只保留了 20 张图像。</p></div><div class="ab cl me mf hx mg" role="separator"><span class="mh bw bk mi mj mk"/><span class="mh bw bk mi mj mk"/><span class="mh bw bk mi mj"/></div><div class="im in io ip iq"><h1 id="412d" class="ml mm jj bd mn mo mp mq mr ms mt mu mv ky mw kz mx lb my lc mz le na lf nb nc bi translated">5.新图像预测</h1><p id="0712" class="pw-post-body-paragraph lh li jj lj b lk nd kt lm ln ne kw lp lq nf ls lt lu ng lw lx ly nh ma mb mc im bi translated">预测一个新的图像也很容易。使用我们训练过的模型，按照<code class="fe pf pg ph pi b"><a class="ae jg" href="https://github.com/MLWhiz/data_science_blogs/blob/master/object_detection/guns_and_swords/2.%20predict.ipynb" rel="noopener ugc nofollow" target="_blank">prediction.ipynb</a></code>笔记本来看一个最小的例子。下面是代码的主要部分。</p><figure class="nj nk nl nm gt iv"><div class="bz fp l di"><div class="pl pm l"/></div></figure><p id="19d9" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">这是验证集中一些图像的结果:</p><div class="nj nk nl nm gt ab cb"><figure class="pw iv qi py pz qa qb paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><img src="../Images/79250b7c25fd3f0706307f0da76fb866.png" data-original-src="https://miro.medium.com/v2/resize:fit:592/format:webp/1*_GB_vZ-7xE_CYjhPZjDDAA.png"/></div></figure><figure class="pw iv qj py pz qa qb paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><img src="../Images/445851550ce672ea33e78f3d10487a4f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1410/format:webp/1*RRBzzpKxZ3xfHxY44KqVbQ.png"/></div></figure></div></div><div class="ab cl me mf hx mg" role="separator"><span class="mh bw bk mi mj mk"/><span class="mh bw bk mi mj mk"/><span class="mh bw bk mi mj"/></div><div class="im in io ip iq"><h1 id="f41a" class="ml mm jj bd mn mo mp mq mr ms mt mu mv ky mw kz mx lb my lc mz le na lf nb nc bi translated">丰富</h1><p id="30ff" class="pw-post-body-paragraph lh li jj lj b lk nd kt lm ln ne kw lp lq nf ls lt lu ng lw lx ly nh ma mb mc im bi translated">结果看起来不是很有希望，还有很多需要改进的地方，但这是意料之中的，因为训练数据非常少(60 张图像)。人们可以尝试做以下事情来提高这种武器探测器的模型性能。</p><ol class=""><li id="046d" class="no np jj lj b lk ll ln lo lq nq lu nr ly ns mc pv nu nv nw bi translated">由于时间限制，我们只对 60 幅图像进行了训练。当我们使用迁移学习时，数据仍然太少——注释更多的数据。</li><li id="6964" class="no np jj lj b lk nx ln ny lq nz lu oa ly ob mc pv nu nv nw bi translated">训练更多的时代和更长的时间。看看验证损失和培训损失是什么样子的。</li><li id="cfb4" class="no np jj lj b lk nx ln ny lq nz lu oa ly ob mc pv nu nv nw bi translated">更改<code class="fe pf pg ph pi b">Mask_RCNN</code>目录下<code class="fe pf pg ph pi b">mrcnn/config </code>文件中的超参数。关于这些超参数意味着什么的信息，看看我以前的帖子。你可以看看主要的几个:</li></ol><pre class="nj nk nl nm gt pn pi po pp aw pq bi"><span id="0254" class="os mm jj pi b gy pr ps l pt pu"># if you want to provide different weights to different losses<br/>LOSS_WEIGHTS ={'rpn_class_loss': 1.0, 'rpn_bbox_loss': 1.0, 'mrcnn_class_loss': 1.0, 'mrcnn_bbox_loss': 1.0, 'mrcnn_mask_loss': 1.0}</span><span id="d785" class="os mm jj pi b gy qf ps l pt pu"># Length of square anchor side in pixels<br/>RPN_ANCHOR_SCALES = (32, 64, 128, 256, 512)</span><span id="df8a" class="os mm jj pi b gy qf ps l pt pu"># Ratios of anchors at each cell (width/height)<br/># A value of 1 represents a square anchor, and 0.5 is a wide anchor<br/>RPN_ANCHOR_RATIOS = [0.5, 1, 2]</span></pre></div><div class="ab cl me mf hx mg" role="separator"><span class="mh bw bk mi mj mk"/><span class="mh bw bk mi mj mk"/><span class="mh bw bk mi mj"/></div><div class="im in io ip iq"><h1 id="9447" class="ml mm jj bd mn mo mp mq mr ms mt mu mv ky mw kz mx lb my lc mz le na lf nb nc bi translated">结论</h1><figure class="nj nk nl nm gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi qk"><img src="../Images/20d78928ebc0f3dbac416b8a68e1b6bc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*3y9qSscAXKkpPBBU"/></div></div><figcaption class="jc jd gj gh gi je jf bd b be z dk">Photo by <a class="ae jg" href="https://unsplash.com/@cgower?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Christopher Gower</a> on <a class="ae jg" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><p id="a518" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">在这篇文章中，我谈到了如何使用 Mask-RCNN 为自定义数据集实现实例分割。T13】</p><p id="0fde" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">我试图使编码部分尽可能简单，并希望你发现代码有用。在本文的下一部分，我将使用 web 应用程序部署这个模型。敬请关注。</p><p id="6a3f" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">你可以在 Github 下载带注释的武器数据和代码。</p></div><div class="ab cl me mf hx mg" role="separator"><span class="mh bw bk mi mj mk"/><span class="mh bw bk mi mj mk"/><span class="mh bw bk mi mj"/></div><div class="im in io ip iq"><p id="db18" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">如果你想了解更多关于各种<strong class="lj jt"> <em class="md">物体检测技术，运动估计，视频中的物体跟踪等</em> </strong>。，我想推荐这个关于计算机视觉深度学习<a class="ae jg" href="https://coursera.pxf.io/7mKnnY" rel="noopener ugc nofollow" target="_blank">的很棒的课程</a></p></div><div class="ab cl me mf hx mg" role="separator"><span class="mh bw bk mi mj mk"/><span class="mh bw bk mi mj mk"/><span class="mh bw bk mi mj"/></div><div class="im in io ip iq"><p id="873c" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">谢谢你的阅读。将来我也会写更多初学者友好的帖子。在<a class="ae jg" href="https://medium.com/@rahul_agarwal" rel="noopener"> <strong class="lj jt">媒体</strong> </a>关注我，或者订阅我的<a class="ae jg" href="http://eepurl.com/dbQnuX" rel="noopener ugc nofollow" target="_blank"> <strong class="lj jt">博客</strong> </a>了解他们。一如既往，我欢迎反馈和建设性的批评，可以通过 Twitter <a class="ae jg" href="https://twitter.com/MLWhiz" rel="noopener ugc nofollow" target="_blank"> @mlwhiz </a>联系。</p><p id="1792" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">此外，一个小小的免责声明——在这篇文章中可能会有一些相关资源的附属链接，因为分享知识从来都不是一个坏主意。</p></div></div>    
</body>
</html>