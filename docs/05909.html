<html>
<head>
<title>Web Scraping Using Python: A Step By Step Guide</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用 Python 进行 Web 抓取:一步一步的指南</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/web-scraping-using-python-a-step-by-step-guide-36ca0fb87074?source=collection_archive---------15-----------------------#2019-08-28">https://towardsdatascience.com/web-scraping-using-python-a-step-by-step-guide-36ca0fb87074?source=collection_archive---------15-----------------------#2019-08-28</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><figure class="gl gn jr js jt ju gh gi paragraph-image"><div class="gh gi jq"><img src="../Images/f7e969ea68cf02bfc74499dee3925b7a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1374/format:webp/0*CtDeoLw7vi_eZvU4.png"/></div><figcaption class="jx jy gj gh gi jz ka bd b be z dk">Photoed by <a class="ae kb" href="https://unsplash.com/photos/iy_l7I-sD_0" rel="noopener ugc nofollow" target="_blank">Heidi Sandstrom</a> on <a class="ae kb" href="https://unsplash.com/?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><p id="fbc3" class="pw-post-body-paragraph kc kd it ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz im bi translated">从网站提取数据的需求正在增加。当我们进行与数据相关的项目时，如价格监控、商业分析或新闻聚合，我们总是需要记录来自网站的数据。但是，一行一行的复制粘贴数据已经过时了。在这篇文章中，我们将教你如何成为从网站中提取数据的“内部人员”，也就是用 python 做<a class="ae kb" href="https://www.octoparse.com/blog/how-to-build-a-web-crawler-from-scratch-a-guide-for-beginners" rel="noopener ugc nofollow" target="_blank">网络搜集。</a></p><h2 id="4697" class="la lb it bd lc ld le dn lf lg lh dp li kn lj lk ll kr lm ln lo kv lp lq lr ls bi translated"><strong class="ak">第 0 步:介绍</strong></h2><p id="682c" class="pw-post-body-paragraph kc kd it ke b kf lt kh ki kj lu kl km kn lv kp kq kr lw kt ku kv lx kx ky kz im bi translated">Web 抓取是一种技术，可以帮助我们将 HTML 非结构化数据转换为电子表格或数据库中的结构化数据。除了使用 python 编写代码，使用 API 或<a class="ae kb" href="https://www.octoparse.com/blog/top-30-free-web-scraping-software" rel="noopener ugc nofollow" target="_blank">数据提取工具</a>如<a class="ae kb" href="http://www.octoparse.com" rel="noopener ugc nofollow" target="_blank"> Octoparse </a>访问网站数据也是网络抓取的其他选择。</p><p id="052d" class="pw-post-body-paragraph kc kd it ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz im bi translated">对于一些大型网站，如 Airbnb 或 Twitter，他们会为开发者提供 API 来访问他们的数据。API 代表应用程序编程接口，是两个应用程序相互通信的通道。对于大多数人来说，API 是从网站获取数据的最佳途径。</p><p id="a7d3" class="pw-post-body-paragraph kc kd it ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz im bi translated">但是，大多数网站没有 API 服务。有时候即使他们提供了 API，你得到的数据也不是你想要的。因此，编写 python 脚本来构建网络爬虫成为另一种强大而灵活的解决方案。</p><p id="56aa" class="pw-post-body-paragraph kc kd it ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz im bi translated"><strong class="ke iu">那么为什么要用 python 而不是其他语言呢？</strong></p><ul class=""><li id="e361" class="ly lz it ke b kf kg kj kk kn ma kr mb kv mc kz md me mf mg bi translated">灵活性:众所周知，网站更新很快。不仅仅是内容，网站结构也会经常变化。Python 是一种易于使用的语言，因为它可以动态输入并且非常高效。因此，人们可以很容易地改变他们的代码，并跟上网络更新的速度。</li><li id="4fc6" class="ly lz it ke b kf mh kj mi kn mj kr mk kv ml kz md me mf mg bi translated"><strong class="ke iu">强大</strong> : Python 拥有大量成熟的库。例如，请求，beautifulsoup4 可以帮助我们从网页中获取 URL 和信息。Selenium 通过赋予网络爬虫模仿人类浏览行为的能力，可以帮助我们避免一些反抓取技术。此外，re、numpy 和 pandas 可以帮助我们清理和处理数据。</li></ul><p id="7eea" class="pw-post-body-paragraph kc kd it ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz im bi translated">现在让我们开始使用 Python 进行 web 抓取的旅程吧！</p><h2 id="2e4f" class="la lb it bd lc ld le dn lf lg lh dp li kn lj lk ll kr lm ln lo kv lp lq lr ls bi translated"><strong class="ak">第一步:导入 Python 库</strong></h2><p id="64f5" class="pw-post-body-paragraph kc kd it ke b kf lt kh ki kj lu kl km kn lv kp kq kr lw kt ku kv lx kx ky kz im bi translated">在本教程中，我们将向你展示如何从 Yelp 上抓取评论。我们将使用两个库:bs4 中的<a class="ae kb" href="https://www.crummy.com/software/BeautifulSoup/bs4/doc/" rel="noopener ugc nofollow" target="_blank"> BeautifulSoup </a>和 urllib 中的<a class="ae kb" href="https://realpython.com/python-requests/" rel="noopener ugc nofollow" target="_blank"> request </a>。这两个库通常用于用 Python 构建网络爬虫。第一步是用 Python 导入这两个库，这样我们就可以使用这些库中的函数。</p><figure class="mn mo mp mq gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="mr ms di mt bf mu"><div class="gh gi mm"><img src="../Images/99596b7f22e0eb2cbe754e923dec6f65.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*FKRWRSMa6K368VMr.png"/></div></div></figure><h2 id="6a87" class="la lb it bd lc ld le dn lf lg lh dp li kn lj lk ll kr lm ln lo kv lp lq lr ls bi translated"><strong class="ak">第二步:从网页中提取 HTML】</strong></h2><p id="7a97" class="pw-post-body-paragraph kc kd it ke b kf lt kh ki kj lu kl km kn lv kp kq kr lw kt ku kv lx kx ky kz im bi translated">我们需要从"<a class="ae kb" href="https://www.yelp.com/biz/milk-and-cream-cereal-bar-new-york?osq=Ice+Cream" rel="noopener ugc nofollow" target="_blank">https://www . yelp . com/biz/milk-and-cream-麦片-酒吧-纽约？osq =冰淇淋+奶油</a>”。首先，让我们将 URL 保存在一个名为 URL 的变量中。然后我们可以访问该网页上的内容，并通过使用请求中的<em class="mv"> urlopen() </em>函数将 HTML 保存在“ourUrl”中。</p><figure class="mn mo mp mq gt ju gh gi paragraph-image"><div class="gh gi mw"><img src="../Images/57e476d792788cb5ef8f27f24f39b5ab.png" data-original-src="https://miro.medium.com/v2/resize:fit:1294/format:webp/0*cFqoCR3LGVON2iUr.png"/></div></figure><p id="b9b7" class="pw-post-body-paragraph kc kd it ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz im bi translated">然后我们应用漂亮的汤来解析页面。</p><figure class="mn mo mp mq gt ju gh gi paragraph-image"><div class="gh gi mw"><img src="../Images/dff48a4ee3a1b88a169cab25535a2392.png" data-original-src="https://miro.medium.com/v2/resize:fit:1294/format:webp/0*MtpIEqh_Wk7uoHDi.png"/></div></figure><p id="cd43" class="pw-post-body-paragraph kc kd it ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz im bi translated">现在我们有了“汤”，这是这个网站的原始 HTML，我们可以使用一个名为<em class="mv">pretify()</em>的函数来清理原始数据并打印出来，以查看“汤”中 HTML 的嵌套结构。</p><figure class="mn mo mp mq gt ju gh gi paragraph-image"><div class="gh gi mw"><img src="../Images/302aee6c85bbee6bbc45c0e5b2b7932a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1294/format:webp/0*tSVyGON-jf-C1AR0.png"/></div></figure><h2 id="b335" class="la lb it bd lc ld le dn lf lg lh dp li kn lj lk ll kr lm ln lo kv lp lq lr ls bi translated"><strong class="ak">第三步:定位并抓取评论</strong></h2><p id="d716" class="pw-post-body-paragraph kc kd it ke b kf lt kh ki kj lu kl km kn lv kp kq kr lw kt ku kv lx kx ky kz im bi translated">接下来，我们应该找到这个网页上的 HTML 评论，提取并存储它们。对于网页中的每个元素，它们总是有一个唯一的 HTML“ID”。为了检查他们的 ID，我们需要在网页上检查他们。</p><figure class="mn mo mp mq gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="mr ms di mt bf mu"><div class="gh gi mx"><img src="../Images/211ec4b63cc7fc0d27e49129090ba280.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*ouq7fSrIiRnp_yCf.png"/></div></div></figure><p id="1a06" class="pw-post-body-paragraph kc kd it ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz im bi translated">点击“Inspect element”(或“Inspect”，取决于不同的浏览器)，我们可以看到评论的 HTML。</p><figure class="mn mo mp mq gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="mr ms di mt bf mu"><div class="gh gi my"><img src="../Images/7eaba98a6408098cf431b17b473d2331.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*PX7j1Uu-8YLGusvN.png"/></div></div></figure><p id="e86a" class="pw-post-body-paragraph kc kd it ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz im bi translated">在这种情况下，评论位于名为“p”的标签下。所以我们将首先使用名为 find_all()的函数来查找这些评论的父节点。然后在循环中定位父节点下带有标签“p”的所有元素。找到所有“p”元素后，我们将它们存储在一个名为“review”的空列表中。</p><figure class="mn mo mp mq gt ju gh gi paragraph-image"><div class="gh gi mz"><img src="../Images/c51915b8318538b54296092672dbb2e8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1286/format:webp/0*mQO-gQZDFa79WfE9.png"/></div></figure><p id="e7cb" class="pw-post-body-paragraph kc kd it ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz im bi translated">现在我们从那个页面得到所有的评论。看看我们提取了多少评论。</p><figure class="mn mo mp mq gt ju gh gi paragraph-image"><div class="gh gi na"><img src="../Images/1fe4c0dea23a976311eb917ce9492acc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1290/format:webp/0*0QVsFxfKjPS1Jx9-.png"/></div></figure><h2 id="c6c9" class="la lb it bd lc ld le dn lf lg lh dp li kn lj lk ll kr lm ln lo kv lp lq lr ls bi translated"><strong class="ak">第四步:清理评论</strong></h2><p id="1311" class="pw-post-body-paragraph kc kd it ke b kf lt kh ki kj lu kl km kn lv kp kq kr lw kt ku kv lx kx ky kz im bi translated">你一定注意到了，还有一些无用的文本，比如每次复习开始时的“<em class="mv"> &lt; p lang='en' &gt; </em>”、复习中间的“<em class="mv">&lt;/&gt;</em>”、每次复习结束时的“<em class="mv"> &lt; /p &gt; </em>”。</p><p id="c9bf" class="pw-post-body-paragraph kc kd it ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz im bi translated"><em class="mv">&lt;br/&gt;</em>代表单行符。我们不需要任何评论换行，所以我们需要删除它们。另外，"<em class="mv"> &lt; p lang='en' &gt; </em>"和"<em class="mv"> &lt; /p &gt; </em>"是 HTML 的开头和结尾，我们也需要删除它们。</p><figure class="mn mo mp mq gt ju gh gi paragraph-image"><div class="gh gi nb"><img src="../Images/f61bfaa67948f45f8e8f5a3b9e88dabf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1288/format:webp/0*owMor9XYCR1sP59c.png"/></div></figure><p id="8b32" class="pw-post-body-paragraph kc kd it ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz im bi translated">最后，我们用不到 20 行代码成功地获得了所有干净的评论。</p><p id="9be4" class="pw-post-body-paragraph kc kd it ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz im bi translated">这只是一个从 Yelp 收集 20 条评论的演示。但在现实情况下，我们可能需要面对很多其他情况。例如，我们将需要分页等步骤，以转到其他页面，并提取该商店的其余评论。或者，我们还需要收集其他信息，如审核者姓名、审核者位置、审核时间、评分、签到……</p><p id="b1ff" class="pw-post-body-paragraph kc kd it ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz im bi translated">为了实现上面的操作并获得更多的数据，我们需要学习更多的函数和库，比如 selenium 或正则表达式。花更多的时间研究网络抓取的挑战是很有趣的。</p></div><div class="ab cl nc nd hx ne" role="separator"><span class="nf bw bk ng nh ni"/><span class="nf bw bk ng nh ni"/><span class="nf bw bk ng nh"/></div><div class="im in io ip iq"><p id="fb8e" class="pw-post-body-paragraph kc kd it ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz im bi translated"><em class="mv">原载于 2019 年 8 月 28 日</em><a class="ae kb" href="https://www.octoparse.com/blog/web-scraping-using-python" rel="noopener ugc nofollow" target="_blank"><em class="mv">【https://www.octoparse.com】</em></a><em class="mv">。</em></p></div></div>    
</body>
</html>