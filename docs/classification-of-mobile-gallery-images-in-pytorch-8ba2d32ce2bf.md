# PyTorch 手机图库图像分类

> 原文：<https://towardsdatascience.com/classification-of-mobile-gallery-images-in-pytorch-8ba2d32ce2bf?source=collection_archive---------33----------------------->

![](img/a249bc6b02d443e03ff8059c376a27cf.png)

A Meme which is going to be used to train an Image Classifier !

我经常发现自己的移动厨房一团糟。我喜欢我的移动画廊井然有序。这就是我脑海中出现构建移动图库图像分类器的想法的原因！

这个迷你项目对我来说听起来像是一个基于深度神经网络的图像分类器的很好的实际应用。这将是一个有趣的经验，建立自己的移动画廊图像分类器。

所以让我们开始吧！:D

## 步骤 1:构建自定义数据集

我们需要列出我们希望图像分类器输出结果的所有类别。

由于这是一个移动画廊图像分类项目，我会选择我经常遇到的类别，而通过我的移动画廊。

以下是我选择的课程-

*   汽车
*   模因
*   山脉
*   自拍
*   树
*   Whataspp _ 截图

一旦我们有了所有需要的类的列表，我们就必须为这些类收集图像。

收集图像数据有几种不同的方式

*   手动收集-我们可以使用手机图库中的现有图片，也可以点击我们列为目标类别的图片。
*   Web scraping——有很多方法可以从 web 上抓取图像。这是一个这样的 python 脚本，可用于下载特定类的图像。

一旦图像被下载，我们必须把它们分成不同的目录。因此，我们有 6 个目录，包含各个类别的图像。

上面提到的两种数据收集方法，我个人都用过。我确实用 python 脚本下载了大部分课程的图片，这种脚本可以很容易地在像 [**stackoverflow**](https://stackoverflow.com/questions/20716842/python-download-images-from-google-image-search) 这样的网站上找到。但由于我在网上找不到 whatsapp 截图的好看图片，我只好从手机里收集。

对你们来说是个好消息！我已经建立了一个**移动图库图像数据集**，我将在这个博客中使用它，并且我已经将它公之于众！所以你们可以免费使用它，而不用麻烦为自己做一个:D

[](https://www.kaggle.com/n0obcoder/mobile-gallery-image-classification-data) [## 手机 _ 图库 _ 图片 _ 分类

### 下载数千个项目的开放数据集+在一个平台上共享项目。探索热门话题，如政府…

www.kaggle.com](https://www.kaggle.com/n0obcoder/mobile-gallery-image-classification-data) 

您可以下载上面提到的数据集，并将其提取到根目录中，这样 python 脚本或 jupyter 笔记本文件就与数据集目录位于同一个目录中。确保数据集目录的路径如下所示。

以下是移动图库影像数据集中的一些样本。

![](img/0f5f150cb3edec139251b20e1c9a0f35.png)

These are few of the sample images taken from the training data from the Mobile Image Gallery Dataset. Their respective classes: Memes (top-left), Cars (top-right), Trees (bottom-right) and Mountains (bottom-left)

## 步骤 2:数据预处理和制作数据加载器

数据集准备好之后，我们需要做的下一件事就是做一些数据预处理。对于数据预处理，我的意思是执行一些简单的图像处理操作，如调整大小、在水平轴上随机翻转图像、将图像(具有范围从 0 到 255 的整数值的像素)转换为张量(具有范围从 0.0 到 1.0 的浮点数的像素值)，以及最后但并非最不重要的，通过使用 ImageNet 统计数据(mean = [0.485，0.456，0.406)，std = [0.229，0.224，0.225 请注意，我们正在处理 **BGR** (彩色)图像，而不是灰度(黑白)图像。

接下来，我们通过使用数据路径和我们想要应用于图像数据的转换/预处理来创建数据集对象。

我们通过定义分割百分比将数据集随机分割成训练数据集和验证数据集。

最后，我们通过定义批量大小来训练和验证数据加载器对象。通过利用矩阵乘法，这将使训练和验证过程惊人地快。

## 步骤 3:定义一个合适的模型并进行必要的调整

首先，我们将使用基于卷积神经网络的架构，因为在处理图像或任何具有空间关系的数据时，没有什么能打败 CNN。既然已经有这么多基于 CNN 的经过测试的架构，我们就不需要试验新的架构了。

我们不打算自己编写基于 CNN 模型的架构，而是使用现有的架构。这样做有两个主要原因-

1.  这些体系结构已经在各种数据集上进行了成功的尝试和测试，并显示出了很好的结果。
2.  这些架构已经在巨大的公共数据集上进行了训练，并且它们的预训练权重已经公开。

在[火炬视觉](https://pytorch.org/docs/stable/torchvision/index.html#torchvision)中有很多预训练的模型可用，像 AlexNet、Resnet、VGG、InceptionNet、DenseNet 等。可供选择。我们选择名为 Resnet34 的型号，因为它既不太深也不太浅。如果你打算在一台没有 GPU 卡的机器上使用它，在训练时它应该不会占用很多计算能力。

但是有一点我们必须注意。这种基于 CNN 的架构的最后一个线性层中的神经元数量代表了我们的数据集中存在的所有类别。最初，Resnet34 用于在具有 1000 个类的 ImageNet 数据集上进行训练。但是我们希望这个模型只输出数据集中的类的数量的预测(在我们的例子中是 6 个)。因此，我们简单地用具有 6 个神经元的新线性层替换该模型的最后一个线性层，输出对 6 个类别的预测。

## 步骤 4:通过冻结和解冻层来转移学习

值得注意的是，由于我们使用的是预训练模型，它的过滤器或内核已经学会识别某些功能。让我更详细地解释给你听，这些过滤器已经学会识别的特征到底是什么。

初始卷积层中的滤波器学习简单和基本的特征，如边缘、颜色和纹理；中间层的孩子可能会学习圆形和多边形等形状；而较深层中的过滤器学习更复杂的图案，如脸或花瓣等。看下面的图片会更清楚。

![](img/3ffd0f401c0ab5114c87c863d7192b7d.png)

Low-Level Features include edges, colors, textures. Mid-Level Features include simple shapes and geometries. High-Level Features include complex shapes and objects like faces, flowers etc.

显然，我们可以利用初始层和中间层中的过滤器，因为我们需要它们来识别输入图像中的边缘、颜色、纹理和简单形状。我们可能不想保留最后几个卷积和线性层中的滤波器。所以我们训练模型……或者我应该说，我们应该在我们的自定义数据集上对模型进行微调，只对最后几层(无论是卷积层还是线性层)进行少量学习。

我们看到所有的参数在开始时都是可训练的(requires_grad = True 表示参数是可学习的)

让我们看看层的名称是什么，以便我们可以冻结最后两个层

所以我们冻结了所有的层，只保留了网络末端的几层。这将确保只有网络末端的未冻结层得到微调，而其他层保持不变。

让我们打印出所有参数的 requires_grad，并确保已经进行了所需的更改

是的，改变已经发生了！(参见,“层 4”和“fc”中的参数 requires_grad = True，其余所有参数 requires_grad = False)

## 步骤 5:损失函数和优化器

好的。我们已经准备好将数据输入到模型中，模型将返回预测结果。但是我们如何知道预测是否正确呢？

这就是损失函数发挥作用的地方！:D

只有当我们有两个事物的标量表示时，我们才能比较它们。而损失函数给了我们一个标量，这让我们有可能进行比较。就这么简单: )

但是，我们如何确保在训练模型时损失不断减少，并在每次迭代中使预测越来越好呢？

是，你找对人了！优化程序来拯救 B)

交叉熵损失是全世界用于解决多类分类问题的标准损失函数。Adam optimizer 是最受欢迎的优化程序选择之一。

我们现在都准备好了。开始训练吧！！！

## 步骤 6:培训和验证

在完成了所有的数据预处理工作、挑选了一个合适的模型、冻结了一些层、选择了损失函数和优化器之后，我们终于准备好开始训练我们的神经网络了。

让我们释放 Resnet34，让它从训练数据中吸收所有它能吸收的东西！

![](img/818066688903fa673cfa98caacd901de.png)

查看 [**本博客**](/everything-you-need-to-know-about-saving-weights-in-pytorch-572651f3f8de) 了解更多关于保存已学权重或整个训练模型(包括权重)的方法。

![](img/181adcdf8ea88fe409a0dfeb293a2475.png)

Loss Plots after training for 5 epochs

但是等等！我有一个小技巧想和你们分享。我们训练网络几个时期，然后我们冻结所有的层，除了最后的线性层。您可能想知道为什么需要这一步。

你们还记得吗，我们已经丢弃了预训练模型的最后一个线性层，并添加了一个新的层，其神经元数量等于我们自定义数据集中的类的数量。当我们这样做时，最后的线性层的权重被随机初始化，一旦所有的卷积层被训练(能够从输入图像中提取不同的特征)，这需要被适当地训练。

以下是冻结第 4 层后的损失图。

![](img/72a8500ba60beb4c8672442dfbef3355.png)

Loss Plots after freezing Layer 4.

这一招在实践中很管用。训练网络有标准的方法，但没有硬性的规则。所以你可能想尝试一下训练程序。请在下面的评论区分享你们的方法，让我知道你们是否通过其他训练程序取得了好的结果。

## 第七步:测试时间到了！

我们已经在移动画廊图像的自定义数据集上训练了我们的神经网络，现在它应该将任何给定的图像分类到它已被训练的数据集中存在的 6 个类别之一。

现在，我们需要做的就是读取测试图像，对它进行我们在训练网络时对图像所做的同样的预处理，并希望看到一些好的预测从我们的网络返回。

![](img/b7329d624751df662a68fd124071539b.png)

Test Image

它似乎工作得很好！:D

恭喜你！你刚刚做了一个移动画廊图像分类器:D，这只是一个使用图像分类器的想法。您可以使用图像分类器来构建各种创造性的应用程序。唯一的限制是你的想象力。

我希望你喜欢读这篇博客，就像我喜欢写它一样: )

如果您有任何疑问或问题，或者如果您想与我合作某个计算机视觉项目，请随时联系我。

干杯，下次再见！:D

## **我强烈推荐你们叉这个**[**public Kaggle kernel**](https://www.kaggle.com/n0obcoder/mobile-gallery-image-classification-using-pytorch)**并摆弄代码，以获得它的感觉！**

## **或**

## **也许下载包含 jupyter 笔记本文件的 G** [**itHub 仓库**](https://github.com/n0obcoder/Mobile-Gallery-Image-Classification-in-PyTorch) **。**

我写这篇博客是因为我通过阅读别人的博客学到了很多东西，我觉得我也应该尽可能多地写下并分享我的学习和知识。所以请在下面的评论区留下你的反馈。此外，我是写博客的新手，所以任何关于如何提高我的写作的建议将不胜感激！:D

我也是一个独立的音乐艺术家，喜欢在空闲时间演奏和录制音乐。也许你可以看看我的艺人页面，表示支持:)
[Spotify 上的 8 楼和声！](https://open.spotify.com/artist/7G2BgSnludIYl1gFyJKG6X?si=Bv5L4ZAVQrmIsl5SgGRAUw)