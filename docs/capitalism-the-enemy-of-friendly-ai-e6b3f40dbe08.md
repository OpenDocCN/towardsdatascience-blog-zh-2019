# 资本主义:友好人工智能的敌人

> 原文：<https://towardsdatascience.com/capitalism-the-enemy-of-friendly-ai-e6b3f40dbe08?source=collection_archive---------25----------------------->

## 先发优势如何导致人类灭绝

![](img/b8793a007151d2f8c58878240aaf233e.png)

Photo by [Sharon McCutcheon](https://unsplash.com/@sharonmccutcheon?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText) on [Unsplash](https://unsplash.com/s/photos/money?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)

我们需要谈论我们的未来；具体来说，我们的未来受到高级人工智能(AI)的影响。在不久的将来，许多专家预计人类将创造出第一个人工通用智能(AGI):一个大致和人类一样聪明的人工智能。相对不久之后，一种人工超级智能(ASI:一种比任何人都聪明得多的人工智能)将很有可能出现。注意，人类统治这个星球是因为他们的智力超群；一个人工智能很可能接管，因为它的智能比我们的智能更高。一个人工智能并不默认我们的道德价值观，许多思想家，如已故的物理学家斯蒂芬·霍金，警告说创造一个人工智能可能会导致人类的灭绝。

## 什么是友军 AI？

让我们从定义友好的 AI 开始。人工智能研究者 Eliezer Yudkowsky 创造的一个术语，它指的是对人类有益而不是有害的人工智能。就像我们在引言中讨论的，一个 ASI 默认不分享我们的道德；友好的人工智能就是这样。友好的人工智能的重要性怎么强调都不为过，可以用一个名为回形针最大化器的思维实验来说明，这个实验首先由[尼克·博斯特罗姆](https://en.wikipedia.org/wiki/Nick_Bostrom)描述。这个思维实验描述了一个 AGI，它被赋予了一个看似天真的目标，即最大化其收藏中回形针的数量。

> ASI 是如此的成功，以至于它最终把地球变成了纸夹制造工厂。

为了更成功地优化回形针的数量，AGI 提高了自己的智能，以成为一个 ASI。然后，ASI 发明了制造越来越多回形针的新方法；它是如此的成功，以至于最终将地球变成了纸夹制造工厂。当然，作为副作用，人类灭绝了。这并不是说 ASI 讨厌我们；只是我们是由它可以为自己所用的材料制成的。

请注意，人类灭绝可能是 ASI 的许多目标的副作用，而不仅仅是最大化回形针的数量。人类灭绝甚至可能有助于 ASI 的目标。假设你给一个 ASI 设定了一个目标，那就是最大限度地减少你收件箱里的垃圾邮件数量。为了实现这一点，ASI 可以简单地消灭人类，因为这将保证你再也不会收到垃圾邮件。

## 资本主义和这有什么关系？

我希望回形针 maximizer 思想实验已经表明“友好”不是 ASI 的默认属性。这正是问题所在:构建一个人工智能是一个(巨大的)挑战，但是让它变得友好(一个友好的人工智能)*需要在*之上的一些挑战。关键在于，资本主义会奖励那些更快上市的公司:公司会赶在竞争对手推出产品之前将产品投放市场，因为它们明白第一是至关重要的。

> 作为第一家创立 ASI 的公司，金钱回报将是难以置信的。

ASI 也将如此:公司已经在向 AI 投资数十亿美元，但在未来，总投资只会增长，特别是当创建 ASI 的可能性变得更加可行时。作为第一家创立 ASI 的公司，金钱回报将是难以置信的。一个人工智能可以比任何人做得更好、更快、更有价值的工作，其先发优势是难以形容的。现在记住我们讨论过的:友好的人工智能需要在人工智能之上的额外挑战。为了成为第一个创造 ASI 的公司，公司很可能不会考虑太多友好性，这就是灾难的开始。

## 如何解决这个问题？

关心友好人工智能的公司可能很容易被不关心的公司超越。但是如果我们拥有的第一个人工智能是友好的，那么我们在人类这一方拥有更高的智慧。这种友好的人工智能可能会帮助我们保护自己免受未来可能的 ASIs。因此，我们不应该把第一个 ASI 的创建留给公司。第一个 ASI 应该建在一个非盈利的研究中心，那里没有盈利的压力。这个研究中心必须足够大，才能真正赢得大公司的第一次 ASI 竞赛，所以它可能应该是由许多不同政府资助的跨国努力。让它成为一个多国的努力也将有助于美国航天局造福于全人类，而不仅仅是一个国家牺牲其他国家。你怎么想呢?