# å¦‚ä½•é—ªç”µèˆ¬ä¸‹è½½æ–‡ä»¶

> åŸæ–‡ï¼š<https://towardsdatascience.com/https-towardsdatascience-com-how-to-download-files-in-a-lightning-speed-a8e8dcc694f7?source=collection_archive---------11----------------------->

## ä»¥åŠä¸åŒè§£æå·¥å…·ä¹‹é—´çš„è¯¦ç»†æ¯”è¾ƒ

![](img/f6a1806fb1b5f7058fdc14e1606510ec.png)

> ä½ å¯ä»¥æœ‰æ²¡æœ‰ä¿¡æ¯çš„æ•°æ®ï¼Œä½†ä½ ä¸èƒ½æœ‰æ²¡æœ‰æ•°æ®çš„ä¿¡æ¯ã€‚â€” [ä¸¹å°¼å°”Â·å‡¯æ–¯Â·è«å…°](http://en.wikipedia.org/wiki/Daniel_Keys_Moran)

éšç€åˆ†ææŠ€èƒ½åœ¨æœ€è¿‘å‡ å¤©å—åˆ°é«˜åº¦é‡è§†ï¼Œå¦‚ä½•è·å¾—é«˜è´¨é‡çš„æ•°æ®ä¹Ÿå¾ˆé‡è¦ã€‚å¦‚æœæ²¡æœ‰æ›´å¤šæˆ–é«˜è´¨é‡çš„æ•°æ®ï¼Œä¼Ÿå¤§çš„åˆ†ææ€»æ˜¯æ— æ³•è¿›è¡Œã€‚

æœ‰ä¸€å¤©ï¼Œ

æˆ‘çš„ä¸€ä¸ªæœ‹å‹é—®æˆ‘ã€‚

â€œä¼Ÿé¸¿ï¼Œåœ¨ç‚¹å‡»ä¸‹è½½éŸ³ä¹æ–‡ä»¶çš„é“¾æ¥ä¹‹å‰ï¼Œä½ çŸ¥é“åª’ä½“æ–‡ä»¶æ˜¯å¦ä¼šç«‹å³ä¸‹è½½å—ï¼Ÿ

å¦‚æœé“¾æ¥æŒ‡å‘å¦ä¸€ä¸ªç½‘ç«™ï¼Œå¹¶æ˜¾ç¤ºé”™è¯¯ä¿¡æ¯ï¼Œè¯¥æ€ä¹ˆåŠï¼Ÿæˆ‘ä¸æƒ³ä¸‹è½½é‚®ä»¶ï¼Œæˆ‘åªéœ€è¦åª’ä½“æ–‡ä»¶ã€‚"

æˆ‘è¯´ï¼Œâ€œè¿™æ˜¯ä¸ªå¥½é—®é¢˜ã€‚è®©æˆ‘æƒ³æ¸…æ¥šï¼Œç„¶åå°½å¿«å›å¤ä½ ã€‚â€

è¿‡äº†ä¸€ä¼šå„¿ï¼Œæˆ‘è¯´:â€œç»™ä½ ï¼â€

![](img/1edca08f12dfd1424b788d8e014b1e21.png)

```
def is_downloadable(url):
    """
    Does the url contain a downloadable resource
    """
    h = requests.head(url, allow_redirects=True)
    header = h.headers
    content_type = header.get('content-type')
    if 'text' in content_type.lower():
        return False
    if 'html' in content_type.lower():
        return False
    return True
```

ä¸Šè¿°å‡½æ•°å°†ç”¨äºæ£€æŸ¥ URL æ˜¯å¦åŒ…å«å¯ä¸‹è½½çš„æºï¼Œå…¶é€»è¾‘å¦‚ä¸‹æ‰€ç¤º:

1.  ä¸æ˜¯ç›´æ¥ä¸‹è½½ URL çš„å†…å®¹å¹¶æ£€æŸ¥æºçš„ç±»å‹ï¼Œè€Œæ˜¯æ£€æŸ¥ URL çš„è¯·æ±‚å¤´ã€‚
2.  æ£€æŸ¥æ ‡é¢˜çš„å†…å®¹ç±»å‹ï¼Œå¦‚æœå®ƒæ—¢ä¸æ˜¯æ–‡æœ¬ä¹Ÿä¸æ˜¯ Htmlï¼Œè¿™æ„å‘³ç€ URL å¸¦æœ‰å¯ä»¥ä¸‹è½½çš„æºã€‚

æ¥ä¸‹æ¥ï¼Œæˆ‘åœ¨è€ƒè™‘åŠ é€Ÿä»£ç ã€‚é™¤äº†ä½¿ç”¨ BeautifulSoup æ¥è§£æ Htmlï¼Œæœ‰æ²¡æœ‰å…¶ä»–æ›¿ä»£æ–¹æ³•å¯ä»¥å¾—åˆ°åŒæ ·çš„ç»“æœï¼Œä½†æ¯” BeautifulSoup æ›´å¿«ï¼Ÿ

ç­”æ¡ˆæ˜¯è‚¯å®šçš„ï¼Œä¸‹é¢æˆ‘å°†å‘ä½ å±•ç¤ºå¦‚ä½•ä½¿ç”¨å…¶ä»–æ›´å¿«çš„ Html è§£æå™¨ã€‚åœ¨æ­¤ä¹‹å‰ï¼Œè®©æˆ‘ä»¬æ¯”è¾ƒä¸€ä¸‹ä» Html ä¸­æå–æ•°æ®çš„å„ç§æ¯”è¾ƒè‘—åçš„å·¥å…·ã€‚

1.  ç¾ä¸½çš„å£°éŸ³
2.  Lxml
3.  html è§£æå™¨
4.  Selectolax

![](img/2296427b859abd398ffdd8d1f4b05ffb.png)

è¿™æ˜¯æˆ‘ä»¬å°†è¦æŠ“å–çš„[ç½‘ç«™](http://kern.humdrum.org/search?s=t&keyword=Bach%20Johann&fbclid=IwAR39fsc8gUWjN6eYAUkewldNkeV499lX0Ew6VP8Nrrd_T1T7plaIIIb5nFQ)ï¼Œæˆ‘ä»¬å°†ç‚¹å‡» **M** æ¥ä¸‹è½½å·´èµ«çº¦ç¿°çš„éŸ³ä¹ã€‚

## ç¾ä¸½çš„å£°éŸ³

```
from bs4 import BeautifulSoup
import wget
soup = BeautifulSoup(r.text, 'lxml')css_path = 'tr > td:nth-child(2) > a:nth-child(3)'for node_link in soup.select(css_path):
   url = node_link['href']
   if is_downloadable(url):
        wget.download(url, 
                     './data/' +\
                     url.split('&file=')[-1].split('&format')[0] +\
                     '.mid')
```

ä¸Šé¢çš„ä»£ç ç‰‡æ®µæ˜¯ä½¿ç”¨ BeautifulSoup ä½œä¸ºæˆ‘ä»¬å·¥å…·çš„ä»£ç ã€‚

å¦‚ BeautifulSoup æ–‡æ¡£ä¸­æ‰€è¿°ï¼Œ

> æ¼‚äº®çš„æ±¤æ°¸è¿œä¸ä¼šåƒå®ƒä¸Šé¢çš„è§£æå™¨ä¸€æ ·å¿«ã€‚

å› ä¸ºå®ƒæ˜¯å»ºç«‹åœ¨ LXML ä¹‹ä¸Šçš„ï¼Œæ‰€ä»¥æˆ‘ä»¬å°†æŠŠå®ƒç”¨ä½œæˆ‘ä»¬çš„è§£æå™¨ã€‚å¦‚æ‚¨æ‰€çŸ¥ï¼Œæˆ‘ä»¬ä½¿ç”¨ CSS æ¥å®šä½æ•°æ®ã€‚

## LXML

```
import lxml.html
import wgetdom = lxml.html.fromstring(r.text)
css_path = 'tr > td:nth-child(2) > a:nth-child(3)'for node_link in dom.cssselect(css_path):
    url = node_link.get('href') # OR node_link.attrib['href'] # check whether the url is downloadable
    if is_downloadable(url):
        wget.download(url, 
                     './data/' +\
                     url.split('&file=')[-1].split('&format')[0] +\
                     '.mid')
```

ä¸Šé¢çš„ä»£ç è¯´æ˜äº†å¦‚ä½•ä½¿ç”¨ LXML è§£æå™¨è®¿é—® HTMLã€‚æ­£å¦‚æ‚¨æ‰€è§‚å¯Ÿåˆ°çš„ï¼Œè¯­æ³•çœ‹èµ·æ¥éå¸¸ç±»ä¼¼äº BeautifulSoupã€‚æ­¤å¤–ï¼ŒLxml ä¸ä»…æ”¯æŒ CSSï¼Œè¿˜æ”¯æŒ Xpathï¼Œå› æ­¤å¦‚æœæ‚¨æ›´ç†Ÿæ‚‰ä½¿ç”¨ Xpathï¼Œé‚£ä¹ˆ LXML å°†æ˜¯æ‚¨æ›´å¥½çš„é€‰æ‹©ï¼Œè€Œä¸æ˜¯ BeautifulSoupã€‚

## html è§£æå™¨

```
from html.parser import HTMLParser
import wgetclass MyHTMLParser(HTMLParser):
    links = []
    def handle_starttag(self, tag, attrs):
        if tag != 'a':
            returnfor attr in attrs:
            if 'href' in attr[0]:
                if attr[1].endswith('format=midi'):
                    self.links.append(attr[1])
                    breakparser = MyHTMLParser()
parser.feed(r.text)for url in parser.links:
   if is_downloadable(url):
       wget.download(url, 
                     './data/' +\
                     url.split('&file=')[-1].split('&format')[0] +\
                     '.mid')
```

Python æ¡†æ¶å†…ç½®äº†ä¸€ä¸ª [HTML è§£æå™¨](https://docs.python.org/3.7/library/html.parser.html?highlight=htmlparser)ï¼Œä¸Šé¢çš„ä»£ç ç”¨å®ƒæ¥æå– URLã€‚è¿™æœ‰ç‚¹å¤æ‚ï¼Œå› ä¸ºæˆ‘ä»¬éœ€è¦åˆ›å»ºè‡ªå·±çš„ HTMLParser ç±»æ¥è¦†ç›–åŸå§‹ç±»ä¸­çš„`handle_starttag`æ–¹æ³•ã€‚å¯¹æˆ‘æ¥è¯´ï¼Œæˆ‘å¾ˆå°‘ä½¿ç”¨ HTMLParserï¼Œå› ä¸ºå…¶ä»–å¯ç”¨çš„å·¥å…·æ›´å®¹æ˜“å®ç°ã€‚

## Selectolax

```
from selectolax.parser import HTMLParser
import wgetfor node_link in dom.css(selector):
   url = node_link.attributes['href'] if is_downloadable(url):
       wget.download(url, 
                     './data/' +\
                     url.split('&file=')[-1].split('&format')[0] +\
                     '.mid')
```

æˆ‘å¼€å§‹çŸ¥é“ Selectolax åŒ…æ˜¯å½“æœ‰äººå›å¤æˆ‘çš„ Reddit è¯„è®ºï¼Œå‘Šè¯‰æˆ‘è¯•è¯•è¿™ä¸ªåŒ…ã€‚(æ„Ÿè°¢è¿™ä½ Reddit çš„æœ‹å‹ï¼ğŸ¤—)åŸºæœ¬ä¸Šï¼Œå®ƒæ˜¯ä¸€ä¸ªé€‚åº¦çš„å¼•æ“çš„ Cython åŒ…è£…å™¨ã€‚ç»è¿‡å°è¯•ï¼Œè§£æ HTML é¡µé¢çš„é€Ÿåº¦æœ‰æ‰€æé«˜ï¼Œä½†å¹…åº¦ä¸å¤§ã€‚åŒæ ·çš„å»ºè®®ï¼Œå¦‚æœä½ æ›´ç†Ÿæ‚‰ XPATHï¼Œå°±ç”¨ LXML ä»£æ›¿ã€‚

![](img/1475c7c628b3b9c99474aa28b566f3a2.png)

## æ€§èƒ½æ¦‚è¿°

ä½œä¸ºå®éªŒï¼Œæˆ‘ä½¿ç”¨ä¸åŒçš„å·¥å…·æ€»å…±ä¸‹è½½äº† **1349 ä¸ª** MID æ–‡ä»¶ã€‚è¿è¡Œ **20** æ¬¡åï¼Œå¹³å‡æ¯ä¸ªå·¥å…·æ‰€ç”¨çš„æ—¶é—´ï¼Œç»“æœå¦‚ä¸‹:

```
+---------------+--------------------+
| Package       | Average Time taken |
+---------------+--------------------+
| BeautifulSoup | 1300.94s           |
| LXML          | 1258.89s           |
| Selectolax    | 1241.85s           |
| HTMLParser    | 1265.95s           |
+---------------+--------------------+
```

Selectolax æ˜¯æœ€å¿«çš„ï¼Œä½†å·®åˆ«å¹¶ä¸æ˜æ˜¾ã€‚

æ€»ä¹‹ï¼Œå¦‚æœä½ çœŸçš„éœ€è¦æé«˜ä½ çš„é“²è¿æœºæˆ–çˆ¬è™«çš„é€Ÿåº¦ï¼Œé‚£ä¹ˆä¹Ÿè®¸é€‰æ‹© Selectolax æ›´å¥½ã€‚å¦‚æœæ‚¨æ›´ç†Ÿæ‚‰ Xpathï¼Œè¯·ä½¿ç”¨ LXMLã€‚æ­¤å¤–ï¼Œä¹Ÿè®¸ä½ æ­£åœ¨å¤„ç†ä¸€ä¸ªè®¾è®¡ç³Ÿç³•çš„ç½‘ç«™(å°± Html æ–‡æ¡£ç»“æ„è€Œè¨€)ï¼Œæœ€å¥½é€‰æ‹© BeautifulSoupã€‚æœ€åä½†åŒæ ·é‡è¦çš„æ˜¯ï¼Œå¦‚æœæ‚¨æƒ³æŒ‘æˆ˜è‡ªå·±ï¼Œé‚£ä¹ˆå°±ä½¿ç”¨ HTMLParser å§ğŸ˜ğŸ˜ğŸ˜ã€‚

åˆ°ç›®å‰ä¸ºæ­¢ï¼Œæˆ‘å¸Œæœ›æ‚¨å¯¹ç”¨äºè§£æ Html é¡µé¢çš„æ¯ä¸ª Python åŒ…æœ‰äº†æ›´å¥½çš„ç†è§£ã€‚

## å‚è€ƒ

1.  [https://stack overflow . com/questions/4967103/beautiful soup-and-lxml-html-what-to-preferred](https://stackoverflow.com/questions/4967103/beautifulsoup-and-lxml-html-what-to-prefer)
2.  [https://www . mschweighauser . com/fast-URL-parsing-with-python/](https://www.mschweighauser.com/fast-url-parsing-with-python/)
3.  [https://www . code mentor . io/aviar Yan/downloading-files-from-URLs-in-python-77 q3b S10 un](https://www.codementor.io/aviaryan/downloading-files-from-urls-in-python-77q3bs0un)
4.  [https://stack overflow . com/questions/71151/html-parser-in-python](https://stackoverflow.com/questions/71151/html-parser-in-python)
5.  [https://stack overflow . com/questions/6126789/selecting-attribute-values-from-lxml](https://stackoverflow.com/questions/6126789/selecting-attribute-values-from-lxml)

# å…³äºä½œè€…

[Low é­å®](https://www.linkedin.com/in/lowweihong/?source=post_page---------------------------)æ˜¯ Shopee çš„æ•°æ®ç§‘å­¦å®¶ã€‚ä»–çš„ç»éªŒæ›´å¤šåœ°æ¶‰åŠæŠ“å–ç½‘ç«™ï¼Œåˆ›å»ºæ•°æ®ç®¡é“ï¼Œä»¥åŠå®æ–½æœºå™¨å­¦ä¹ æ¨¡å‹æ¥è§£å†³ä¸šåŠ¡é—®é¢˜ã€‚

ä»–æä¾›çˆ¬è¡ŒæœåŠ¡ï¼Œèƒ½å¤Ÿä¸ºä½ æä¾›ä½ æ‰€éœ€è¦çš„å‡†ç¡®å’Œå¹²å‡€çš„æ•°æ®ã€‚ä½ å¯ä»¥è®¿é—® [**è¿™ä¸ªç½‘ç«™**](https://www.thedataknight.com/) æŸ¥çœ‹ä»–çš„ä½œå“é›†ï¼Œä¹Ÿå¯ä»¥è”ç³»ä»–è·å–**æŠ“å–æœåŠ¡**ã€‚

ä½ å¯ä»¥åœ¨ [LinkedIn](https://www.linkedin.com/in/lowweihong/?source=post_page---------------------------) å’Œ [Medium](https://medium.com/@lowweihong?source=post_page---------------------------) ä¸Šå’Œä»–è”ç³»ã€‚

[](https://medium.com/@lowweihong?source=post_page-----3efb6878f8db----------------------) [## ä½å¾®çº¢â€”ä¸­ç­‰

### åœ¨åª’ä½“ä¸Šé˜…è¯»ä½çº¬é¸¿çš„ä½œå“ã€‚æ•°æ®ç§‘å­¦å®¶|ç½‘ç»œæœé›†æœåŠ¡:http://datainfinite.mystrikingly.com/â€¦

medium.com](https://medium.com/@lowweihong?source=post_page-----3efb6878f8db----------------------)