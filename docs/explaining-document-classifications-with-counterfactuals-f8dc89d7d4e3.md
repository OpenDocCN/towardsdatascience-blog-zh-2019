# 用反事实解释文档分类

> 原文：<https://towardsdatascience.com/explaining-document-classifications-with-counterfactuals-f8dc89d7d4e3?source=collection_archive---------31----------------------->

## D. Martens 和 F. Provost 的论文“解释数据驱动的文档分类”的摘要。

![](img/2b28c922887a00ebcfb1f977377dc1b7.png)

Photo by [Amador Loureiro](https://unsplash.com/photos/BVyNlchWqzs?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText) on [Unsplash](https://unsplash.com/?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)

注意:可解释性和可解释性在本文中可以互换使用。

# 需要解释

测试集度量可能无法提供模型优势和劣势的整体视图。对模型预测的解释有助于人类理解为什么会做出预测，并且在某些情况下，能够一致地预测模型的结果。这是有益的，因为:

*   受决策影响的客户可以被告知为什么要采取与他们相关的特定行动。
*   它帮助管理人员理解模型工作良好的用例。
*   数据科学家可以使用这些解释来迭代改进模型。
*   当模型是真实世界的准确表示时，对模型行为的解释可以提高对业务领域的理解。

此外，对如何做出决策的解释有时是法律或监管要求。

## 什么是“好”的解释？

由于输入和预测之间的关系易于理解，因此具有少量特征的较小决策树和逻辑回归模型被认为是可解释的。

然而，当这些模型涉及数百个特征时，分析特定特征对预测的影响或导致特定决策的主要因素变得势不可挡。

简明扼要并突出最重要因素的解释比提供完整因素列表的解释更容易理解。

## 不同种类技术的概述

*   **模型不可知与模型特定** 模型不可知技术独立于模型的内部工作，因此可以用于任何模型，而模型特定技术则绑定于特定类型的模型。模型不可知技术的明显优势在于，可以在不改变可解释性技术的情况下改变所使用的模型。
*   **全局与局部** 全局解释适用于模型做出的所有预测，并提供了模型如何做出决策的总体概述，而局部解释适用于单个预测或一组类似的预测。

该论文提出了一种模型不可知的技术来解释个人的预测。

## 反事实

反事实具有对比性。他们解释为什么做出一个决定而不是另一个决定。预测的反事实解释可以定义为:*【2】*

> 将预测更改为预定义输出的特征值的最小变化。

本文探讨了从文档中删除某些单词如何改变其预测类别。所提出的方法不同于大多数反事实技术，因为它产生一组单词，而不是代表不同实例的特征向量。

# 自然语言处理解释的特质

*   **高维度:** 文档的特征向量表示通常具有数量级大于结构化数据分类问题中存在的特征数量的变量数量。
    高维度使得传统的可解释模型和许多全局解释技术失效。为了保持分类树的可读性，它不能包含成千上万的变量(或节点)。
    另一方面，计算不同特征对预测的贡献的局部解释技术使得不清楚哪个词的组合实际上导致了给定的分类，并且对于大量的特征来说，通常在计算上非常昂贵。
*   **稀疏性:**
    大多数文档只包含总词汇表中出现的单词的一小部分，因此，文档的基于计数的特征向量是高度稀疏的。

# 所提出的方法

该文件主要集中于解释为什么一个文件已收到(正确或错误的)“积极的”分类。

在本文的上下文中，一个**解释**被定义为；

> 文档中存在的一组单词，删除这些单词会导致预测类发生变化。

单词集是*最小*。也就是说，删除单词的任何子集都不会改变类别。

## 完整搜索

这种方法首先检查从文档中删除一个特定的单词是否会改变预测的类。如果类别没有因为一个单词而改变，则接下来考虑 2 个不同单词的组合。如果删除任何两个单词也没有导致类别变化，则考虑三个不同单词的组合，以此类推。

下面这个例子的解释是 E = {'computer'}。

![](img/583d30e5e3ede424f822d3b362173269.png)

illustrated example

该方法利用了文档表示的稀疏性，因为候选单词组合是文档中的所有单词组合，而不是整个词汇表中的单词组合。然而，这对于大型文档来说仍然是不可行的，因为其复杂性随着文档中唯一单词的数量呈指数增长。

![](img/a1c5d9269b9c9361c35f7e233f8d4be8.png)

## 启发式方法

**贪婪搜索**模型通常计算实例属于特定类别的概率，而不是硬分类，这可以被用作启发，以指导通过贪婪搜索选择接下来要移除的单词组合。
在检查了所有一个单词的解释并计算了预测类别的概率的相应变化后，在后续的单词组合中使用降低概率最大的单词。
更一般； *在搜索的每一步，给定表示部分解释的当前单词组合集，算法接下来将扩展输出分数在类别变化方向上变化最大的部分解释。扩展部分解释需要创建一组新的候选解释，包括与来自文档的一个附加单词的所有组合，该附加单词还没有包括在部分解释中。[1]*

**搜索空间修剪** 当目标是找到多个解释时，在搜索其他解释时，不需要考虑构成解释的单词组 *E* 。

## 非线性模型

对于非线性模型，不可能估计特征相互作用对预测分类概率的影响。这导致了以下问题:

*   获得的解释可能不包含解释定义所要求的最小单词子集。也就是说，找到的解释可能会导致预测类的变化，即使在一个或多个单词从其中删除之后。
    这在局部搜索后处理阶段中解决，该阶段验证从获得的解释 *E* 中移除一个或多个单词是否也提供了解释*E*’,在这种情况下，用较小的解释 *E* 替换 *E* 。
*   可能存在比获得的更小的不同单词的解释。
    这在第二局部搜索后处理阶段中解决。对于每个解释，两个单词被文档中的另一个单词替换，而不是在解释中。接下来，三个词的解释由两个词的文件，还没有在解释，等等。这产生了大量要检查的潜在组合:用 m 个单词替换对一个文档的解释的一组 k 个单词产生了ᵐ⁻ᵏCₖ组合。为了处理要检查的大量新单词组合，作者进行的实验被限制在 k = 5 个单词，最多 5000 个组合。

# 个案研究

本文提出了一个关于将网页归类为包含不良内容的问题的实证案例研究，目的是允许广告商选择不在网页上显示他们的广告。

关于新闻故事主题分类的第二个实证演示使用了 20 个新闻组基准数据集。

## 其他方法的缺点

人们发现，以决策树或最具指示性的词语清单的形式进行的全面解释并没有提供令人满意的解决方案。

使用 C4.5 算法生成的具有 327 个节点的代理决策树模型的保真度仅为 87%。修剪会减小树的大小，但也会降低保真度。

在检查线性模型的单词特征权重的情况下，解释单个决策仅仅需要太多的单个单词；在解释一半的文档之前，需要超过两千个最重要的单词(3%的词汇)。

这与文档术语矩阵的稀疏性相结合，表明各个解释中的单词变化很大，并支持使用实例级解释算法。

下图也证明了这一点，该图描绘了通过考虑根据不同方法加权的前 k 个单词来解释的测试实例分类的百分比。

![](img/04564ec682f136922f7e3ea5bf9849b1.png)

Source: [1]

下面具有最大面积的线是根据单词在解释中出现的频率排列的单词获得的。

## 解释的差异

![](img/ca2708a9fb2bd03c8c6c58885728a548.png)

Source: [1]

*   PE:解释的测试实例的百分比(%)
*   AWS:最小解释的平均字数(数字)
*   答:给出的最小解释的平均数(个)
*   ANT:给出的所有解释的平均数(数字)
*   ADF:找到第一个解释的平均持续时间(秒)
*   ADA:找到所有解释的平均持续时间(秒)

几乎所有的文件都有少于三十几个字的解释，超过一半的文件有少于二十几个字的解释。换句话说，每个解释都非常简洁，

*这些图还显示了文档解释大小变化相当平稳，并且似乎有许多不同的文档解释。前一种观察表明，单个证据的强度差异很大:一些案件通过汇总许多薄弱的证据进行分类，另一些案件通过几个强有力的证据进行分类(还有一些案件，大概是通过强证据和弱证据的组合进行分类)。后一种观察表明存在大量冗余。[1]*

# 调试模型

解释对于调试模型很有用，特别是当它们不直观的时候。这种解释被称为*过度解释*。

## 假阴性

这种解释可能表明没有证据支持正类；更确切地说，没有与模型相关的证据。在这种情况下，模型词汇表可能需要扩展。

也有可能是负面的证据比正面的证据更重要。这里，解释技术可以被应用于寻找为什么该示例被分类为否定类别的解释，因为它们将突出模型感觉胜过文档中的肯定类别指示词的词。这将提供一个机会来更新模型的权重(通过主动特征标记)或检查包含这些单词的文档的标签。

分类器将 20 个新闻组数据集中的文章分类为“符合”或“不符合”时产生的假阴性的解释示例；

*“提供销售分销”*

## 假阳性

该解释可以表明用于将该例子分类为肯定的词实际上并不与肯定类相关联。这种解释为交互式模型开发提供了有用的支持，因为可以结合背景知识来对抗错误分类。

在其他情况下，解释可能会突出一些单词的模糊含义。

分类器将 20 个新闻组数据集中的文章分类为“符合”或“不符合”时产生的误报的解释示例；

*《窗口呼叫》*

这篇报道实际上属于“rec.autos”新闻组。

在解释提供的单词似乎与积极类合理相关的情况下，可以验证示例的标签。

# 扩展ˌ扩张

本文介绍的技术也可用于其他高维分类问题，只要单个维度(及其子集)是可解释的。

例如，根据 web 用户访问的网页对他们进行分类。每个用户可以由一个非常大的集合中的一组网页 URL 来表示。然后，用户可以通过这个词汇表上的模型进行分类。

# 参考

[1] D. Martens 和 F. Provost，解释数据驱动的文档分类，MIS Q .，38(1)，(2014)。

[2] [C. Molnar，可解释的机器学习。让黑盒模型变得可解释的指南，(2019)。](https://christophm.github.io/interpretable-ml-book/)