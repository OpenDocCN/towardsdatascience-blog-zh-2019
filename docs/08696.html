<html>
<head>
<title>Training RetinaNet on Google Colab to detect pliers, hammers, and screwdrivers from KTH Handtools Dataset.</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">在 Google Colab 上训练 RetinaNet 从 KTH 手工工具数据集中检测钳子、锤子和螺丝刀。</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/training-retinanet-to-detect-pliers-4dd47eb8b226?source=collection_archive---------18-----------------------#2019-11-22">https://towardsdatascience.com/training-retinanet-to-detect-pliers-4dd47eb8b226?source=collection_archive---------18-----------------------#2019-11-22</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><p id="273d" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">在本文中，RetinaNet 在 Google Colab 中接受了检测钳子、锤子和螺丝刀工具的训练。该数据集取自一个名为<a class="ae ko" href="https://www.nada.kth.se/cas/data/handtool/" rel="noopener ugc nofollow" target="_blank"> KTH 手工工具数据集</a>的开放来源。它包括三种类型的手工具的图像:锤子，钳子和螺丝刀在不同的照明和不同的位置。</p><figure class="kq kr ks kt gt ku gh gi paragraph-image"><div class="gh gi kp"><img src="../Images/6b96f4b3b831e34a65e5da20d2ccefb7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1250/format:webp/1*7q1HXteh8tlyjh86QO8XTQ.png"/></div><figcaption class="kx ky gj gh gi kz la bd b be z dk">Example of images of KTH Handtool Dataset [<a class="ae ko" href="https://www.nada.kth.se/cas/data/handtool/" rel="noopener ugc nofollow" target="_blank">https://www.nada.kth.se/cas/data/handtool/</a>].</figcaption></figure><p id="0a09" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">Jupyter 文章的笔记本代码可以在我的 github 中的<a class="ae ko" href="https://github.com/yustiks/retina_transfer_learning/blob/master/retina_kth_dataset_training.ipynb" rel="noopener ugc nofollow" target="_blank">中找到。</a></p><p id="8396" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">首先在本地从<a class="ae ko" href="https://www.nada.kth.se/cas/data/handtool/" rel="noopener ugc nofollow" target="_blank">源</a>下载数据集(解压文件并重命名为 KTH _ 手工具 _ 数据集)，然后将文件夹下载到 google drive。之后，我们应该将 google disc 安装到 google colab:</p><pre class="kq kr ks kt gt lb lc ld le aw lf bi"><span id="932e" class="lg lh it lc b gy li lj l lk ll"><strong class="lc iu">from</strong> <strong class="lc iu">google.colab</strong> <strong class="lc iu">import</strong> drive<br/>drive.mount('/content/drive')</span></pre><p id="9c28" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">其次，需要准备数据来训练 RetinaNet:初始数据集中的所有图像都应该保存在不同的文件夹中，每个图像都有相关的边界框。为了训练 RetinaNet，我们需要创建一个 CSV 文件:该文件中的每一行都应该包含来自数据集的图像文件的名称、每个对象的边界框坐标以及该对象的类名。下面的脚本解析所有的文件夹(有 3 个文件夹是蓝色、白色和棕色背景的图片)。</p><p id="44e3" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">要解析的第一个文件夹是“Blue_background”。此文件夹与“棕色 _ 背景”或“白色 _ 背景”的区别在于，带有乐器的文件夹不包含“Kinect”和“网络摄像头”子文件夹。</p><pre class="kq kr ks kt gt lb lc ld le aw lf bi"><span id="3306" class="lg lh it lc b gy li lj l lk ll"><strong class="lc iu">from</strong> <strong class="lc iu">bs4</strong> <strong class="lc iu">import</strong> BeautifulSoup<br/><strong class="lc iu">import</strong> <strong class="lc iu">os</strong><br/><strong class="lc iu">import</strong> <strong class="lc iu">csv</strong><br/><br/>folder = '/content/drive/My Drive/KTH_Handtool_Dataset'<br/>subfolder = ['Blue_background']<br/>in_subfolder = ['Artificial', 'Cloudy', 'Directed']<br/>instruments = ['hammer1', 'hammer2', 'hammer3', 'plier1', 'plier2', 'plier3', 'screw1', 'screw2', 'screw3']<br/><br/><strong class="lc iu">with</strong> open('train.csv', mode='w') <strong class="lc iu">as</strong> file:<br/>  writer = csv.writer(file, delimiter=',', quotechar='"', quoting=csv.QUOTE_MINIMAL)  <br/>  <strong class="lc iu">for</strong> folder_name <strong class="lc iu">in</strong> subfolder:<br/>    <strong class="lc iu">for</strong> in_folder_name <strong class="lc iu">in</strong> in_subfolder:<br/>      <strong class="lc iu">for</strong> instrument <strong class="lc iu">in</strong> instruments:<br/>        directory_name = os.path.join(folder, folder_name, 'rgb', in_folder_name, instrument)<br/>        directory_name_xml = os.path.join(folder, folder_name, 'bboxes', in_folder_name, instrument)<br/>        <strong class="lc iu">for</strong> filename <strong class="lc iu">in</strong> os.listdir(directory_name_xml):<br/>          label = instrument<br/>          filename_jpg = filename[:-4] + '.jpg'<br/>          filename_str = os.path.join(directory_name, filename_jpg)<br/>          handler = open(os.path.join(directory_name_xml, filename)).read()<br/>          soup = BeautifulSoup(handler, "xml")<br/>          xmin = int(soup.xmin.string)<br/>          xmax = int(soup.xmax.string)<br/>          ymin = int(soup.ymin.string)<br/>          ymax = int(soup.ymax.string)<br/>          row = [filename_str, xmin, ymin, xmax, ymax, label]<br/>          writer.writerow(row)</span></pre><blockquote class="lm ln lo"><p id="9126" class="jq jr lp js b jt ju jv jw jx jy jz ka lq kc kd ke lr kg kh ki ls kk kl km kn im bi translated">参数文件夹-存储所有数据的目录(提取的 KTH _ 手工具 _ 数据集文件夹的父目录)。</p></blockquote><p id="8c42" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">对于“白色 _ 背景”和“棕色 _ 背景”，脚本应该不同，因为它们在乐器的文件夹中包含子文件夹“Kinect”和“网络摄像头”(“锤子 1”、“锤子 2”、“锤子 3”、“plier1”、“plier2”、“plier3”、“screw1”、“screw2”、“screw3”)。我添加了这一行来包含这些文件夹</p><pre class="kq kr ks kt gt lb lc ld le aw lf bi"><span id="f6fa" class="lg lh it lc b gy li lj l lk ll"><strong class="lc iu">for</strong> sub_instrument <strong class="lc iu">in</strong> sub_instruments:</span></pre><p id="bc3c" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">另一个诀窍是，kinect 的“rgb”文件夹和“bbox”文件夹有不同的名称:在一些文件夹中是“Kinect”，在另一些文件夹中是“Kinect”，因此我决定用不同的方法来解析图像目录(“rgb”文件夹)和边框目录(“bbox”文件夹)。字典用于更改名称:</p><pre class="kq kr ks kt gt lb lc ld le aw lf bi"><span id="e142" class="lg lh it lc b gy li lj l lk ll">dict_instr = {'Kinect': 'kinect'}</span></pre><p id="d6e6" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">下一步:如果名称“kinect”不在 xml path 文件夹中，则它会变成小写的“Kinect”:</p><pre class="kq kr ks kt gt lb lc ld le aw lf bi"><span id="03ff" class="lg lh it lc b gy li lj l lk ll">dir_name_xml = os.path.join(folder, folder_name, 'bbox', in_folder_name, instrument)<br/>          <strong class="lc iu">if</strong> sub_instrument <strong class="lc iu">not</strong> <strong class="lc iu">in</strong> os.listdir(dir_name_xml):<br/>            sub_instrument = dict_instr[sub_instrument]</span></pre><p id="82eb" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">结果，“棕色背景”和“白色背景”的脚本如下:</p><pre class="kq kr ks kt gt lb lc ld le aw lf bi"><span id="2857" class="lg lh it lc b gy li lj l lk ll">subfolder = ['Brown_background', 'White_background']<br/>sub_instruments = ['Kinect', 'webcam']<br/>dict_instr = {'Kinect': 'kinect'}<br/><br/><em class="lp"># open file to write to the end of a file</em><br/><strong class="lc iu">with</strong> open('train.csv', mode='a') <strong class="lc iu">as</strong> file:<br/>  writer = csv.writer(file, delimiter=',', quotechar='"', quoting=csv.QUOTE_MINIMAL)  <br/>  <strong class="lc iu">for</strong> folder_name <strong class="lc iu">in</strong> subfolder:<br/>    <strong class="lc iu">for</strong> in_folder_name <strong class="lc iu">in</strong> in_subfolder:<br/>      <strong class="lc iu">for</strong> instrument <strong class="lc iu">in</strong> instruments:<br/>        <strong class="lc iu">for</strong> sub_instrument <strong class="lc iu">in</strong> sub_instruments:<br/>          directory_name = os.path.join(folder, folder_name, 'rgb', in_folder_name, instrument, sub_instrument)<br/>          dir_name_xml = os.path.join(folder, folder_name, 'bbox', in_folder_name, instrument)<br/>          <strong class="lc iu">if</strong> sub_instrument <strong class="lc iu">not</strong> <strong class="lc iu">in</strong> os.listdir(dir_name_xml):<br/>            sub_instrument = dict_instr[sub_instrument]<br/>          directory_name_xml = os.path.join(dir_name_xml, sub_instrument)<br/>          <strong class="lc iu">for</strong> filename <strong class="lc iu">in</strong> os.listdir(directory_name_xml):<br/>            label = instrument<br/>            filename_jpg = filename[:-4] + '.jpg'<br/>            filename_str = os.path.join(directory_name, filename_jpg)<br/>            handler = open(os.path.join(directory_name_xml, filename)).read()<br/>            soup = BeautifulSoup(handler, "xml")<br/>            xmin = int(soup.xmin.string)<br/>            xmax = int(soup.xmax.string)<br/>            ymin = int(soup.ymin.string)<br/>            ymax = int(soup.ymax.string)<br/>            row = [filename_str, xmin, ymin, xmax, ymax, label]<br/>            writer.writerow(row)</span></pre><p id="8856" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">运行上面的代码后，我们应该进行预处理，因为一些 xml 文件没有相关的图像:</p><pre class="kq kr ks kt gt lb lc ld le aw lf bi"><span id="57c4" class="lg lh it lc b gy li lj l lk ll"><strong class="lc iu">import</strong> <strong class="lc iu">pandas</strong> <strong class="lc iu">as</strong> <strong class="lc iu">pd</strong><br/><strong class="lc iu">import</strong> <strong class="lc iu">os.path</strong><br/><br/>list_indexes_to_drop = []<br/>data = pd.read_csv("train.csv", header=<strong class="lc iu">None</strong>)<br/><strong class="lc iu">with</strong> open('train_new.csv', mode='a') <strong class="lc iu">as</strong> file:<br/>  <strong class="lc iu">for</strong> i <strong class="lc iu">in</strong> range(len(data)):<br/>    fname = data.iloc[i, 0]<br/>    <strong class="lc iu">if</strong> <strong class="lc iu">not</strong> os.path.isfile(fname):<br/>      list_indexes_to_drop.append(i)<br/><br/>data = data.drop(data.index[list_indexes_to_drop])<br/>data.to_csv(path_or_buf='train.csv', index=<strong class="lc iu">False</strong>, header=<strong class="lc iu">None</strong>)</span></pre><p id="5be0" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">预处理后，数据应该被分割。CSV 文件中的所有元素都被随机打乱</p><pre class="kq kr ks kt gt lb lc ld le aw lf bi"><span id="b340" class="lg lh it lc b gy li lj l lk ll">data = pd.read_csv("train.csv", header=<strong class="lc iu">None</strong>)<br/>data = data.sample(frac=1).reset_index(drop=<strong class="lc iu">True</strong>)</span></pre><p id="011a" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">然后，通过下一个代码将数据分为训练集(80%)和测试集(20%)。</p><pre class="kq kr ks kt gt lb lc ld le aw lf bi"><span id="44ec" class="lg lh it lc b gy li lj l lk ll">amount_80 = int(0.8*len(data))<br/>train_data = data[:amount_80]<br/>test_data = data[amount_80:]</span><span id="2fd2" class="lg lh it lc b gy lt lj l lk ll">print(len(train_data))<br/>print(len(test_data))</span></pre><p id="e829" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">我们应该将 train_data 保存为 train_annotations.csv:</p><pre class="kq kr ks kt gt lb lc ld le aw lf bi"><span id="94a4" class="lg lh it lc b gy li lj l lk ll">train_data.to_csv(path_or_buf='train_annotations', index=False)</span></pre><p id="b94a" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">下一步是从网站上下载用于训练神经网络的权重，并将其放入“权重”文件夹中:</p><pre class="kq kr ks kt gt lb lc ld le aw lf bi"><span id="77c0" class="lg lh it lc b gy li lj l lk ll">!mkdir weights<br/>!wget -O /content/weights/resnet50_coco_best_v2.h5 https://github.com/fizyr/keras-retinanet/releases/download/0.5.1/resnet50_coco_best_v2.1.0.h5</span></pre><p id="6140" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">我们还应该创建文件夹“快照”, RetinaNet 将在训练期间保存重量，以及“tensorboard ”,其中将解决关于训练的信息:</p><pre class="kq kr ks kt gt lb lc ld le aw lf bi"><span id="116d" class="lg lh it lc b gy li lj l lk ll">!mkdir /content/drive/My\ Drive/kth_article/snapshots<br/>!mkdir /content/drive/My\ Drive/kth_article/tensorboard</span></pre><p id="494f" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">下一步是创建 csv 文件“classes.csv”(包含仪器名称):</p><pre class="kq kr ks kt gt lb lc ld le aw lf bi"><span id="9278" class="lg lh it lc b gy li lj l lk ll">dict_classes = {<br/>    'hammer1': 0,<br/>    'hammer2': 1,<br/>    'hammer3': 2,<br/>    'plier1': 3,<br/>    'plier2': 4,<br/>    'plier3': 5,<br/>    'screw1': 6,<br/>    'screw2': 7,<br/>    'screw3': 8<br/>}<br/><strong class="lc iu">with</strong> open('classes.csv', mode='w') <strong class="lc iu">as</strong> file:<br/>  writer = csv.writer(file, delimiter=',', quotechar='"', quoting=csv.QUOTE_MINIMAL)<br/>  <strong class="lc iu">for</strong> key, val <strong class="lc iu">in</strong> dict_classes.items():  <br/>    row = [key, val]<br/>    print(row)<br/>    writer.writerow(row)</span></pre><p id="26cb" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">我们还需要安装 RetinaNet:</p><pre class="kq kr ks kt gt lb lc ld le aw lf bi"><span id="c5bf" class="lg lh it lc b gy li lj l lk ll">!cd ~</span><span id="66a7" class="lg lh it lc b gy lt lj l lk ll">!git clone <a class="ae ko" href="https://github.com/fizyr/keras-retinanet" rel="noopener ugc nofollow" target="_blank">https://github.com/fizyr/keras-retinanet</a><br/>%cd keras-retinanet</span><span id="69b2" class="lg lh it lc b gy lt lj l lk ll">!git checkout 42068ef9e406602d92a1afe2ee7d470f7e9860df</span><span id="99cf" class="lg lh it lc b gy lt lj l lk ll">!python setup.py install<br/>!python setup.py build_ext --inplace</span></pre><p id="112b" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">我们需要返回到父目录:</p><pre class="kq kr ks kt gt lb lc ld le aw lf bi"><span id="ad06" class="lg lh it lc b gy li lj l lk ll">%cd ..</span></pre><p id="505f" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">下一个脚本用于训练神经网络:</p><pre class="kq kr ks kt gt lb lc ld le aw lf bi"><span id="3df0" class="lg lh it lc b gy li lj l lk ll">!retinanet-train --weights /weights/resnet50_coco_best_v2.h5 \<br/>--batch-size 4 --steps 4001 --epochs 20 \<br/>--snapshot-path snapshots --tensorboard-dir tensorboard \<br/>csv train_annotations.csv classes.csv</span></pre><p id="4368" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu"> train_annotations.csv </strong>:包含来自训练数据的所有图像的信息的文件，每个图像的格式应按照以下模板制作:&lt; path_to_image &gt;，&lt; xmin &gt;，&lt; ymin &gt;，&lt; xmax &gt;，&lt; ymax &gt;，&lt; label &gt;，其中 xmin，ymin，xmax，ymax 为以像素为单位的包围盒，label 为 a</p><p id="d2c9" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu"> labels.csv </strong>:带有类标签的文件，后面应该是模板:&lt; class_name &gt;，&lt; id &gt;</p><p id="63f0" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">经过 3 个纪元的训练，我们会得到一些准确性。我们可以在训练数据上验证模型。另一种选择是在一些真实图像上测试准确性:</p><figure class="kq kr ks kt gt ku gh gi paragraph-image"><div role="button" tabindex="0" class="lv lw di lx bf ly"><div class="gh gi lu"><img src="../Images/486dc38904d5eaba76d00cf2ec6e3006.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*9ZsJFo9AEAhcjcvOPvolfg.jpeg"/></div></div><figcaption class="kx ky gj gh gi kz la bd b be z dk">Image of real plier image (IKEA plier).</figcaption></figure><p id="7a31" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">要在验证集上测试模型，我们需要将权重转换为测试格式:</p><pre class="kq kr ks kt gt lb lc ld le aw lf bi"><span id="b41a" class="lg lh it lc b gy li lj l lk ll">!retinanet-convert-model snapshots/resnet50_csv_03.h5 weights/resnet50_csv_03.h5</span></pre><p id="cf90" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">要检查测试集的结果:</p><pre class="kq kr ks kt gt lb lc ld le aw lf bi"><span id="cb26" class="lg lh it lc b gy li lj l lk ll">!retinanet-evaluate csv val_annotations.csv classes.csv weights/resnet50_csv_03.h5</span></pre><p id="b31d" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">我们可以看到，在测试集上，经过多次训练后的结果已经很好了，平均精度为 66%:</p><pre class="kq kr ks kt gt lb lc ld le aw lf bi"><span id="b1ef" class="lg lh it lc b gy li lj l lk ll">116 instances of class hammer1 with average precision: 0.7571<br/>113 instances of class hammer2 with average precision: 0.6968<br/>110 instances of class hammer3 with average precision: 0.8040<br/>123 instances of class plier1 with average precision: 0.5229<br/>119 instances of class plier2 with average precision: 0.5567<br/>122 instances of class plier3 with average precision: 0.8953<br/>126 instances of class screw1 with average precision: 0.4729<br/>152 instances of class screw2 with average precision: 0.5130<br/>131 instances of class screw3 with average precision: 0.7651<br/>mAP: 0.6649</span></pre><p id="c3c0" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">同时，在真实环境中也不太好:为了检查它，我们可以在我们的图像上运行 Retinanet 的预测。</p><pre class="kq kr ks kt gt lb lc ld le aw lf bi"><span id="9445" class="lg lh it lc b gy li lj l lk ll"><em class="lp"># show images inline</em><br/>%matplotlib inline<br/><br/><em class="lp"># automatically reload modules when they have changed</em><br/>%load_ext autoreload<br/>%autoreload 2<br/><br/><em class="lp"># import keras</em><br/><strong class="lc iu">import</strong> <strong class="lc iu">keras</strong><br/><br/><em class="lp"># import keras_retinanet</em><br/><strong class="lc iu">from</strong> <strong class="lc iu">keras_retinanet</strong> <strong class="lc iu">import</strong> models<br/><strong class="lc iu">from</strong> <strong class="lc iu">keras_retinanet.utils.image</strong> <strong class="lc iu">import</strong> read_image_bgr, preprocess_image, resize_image<br/><strong class="lc iu">from</strong> <strong class="lc iu">keras_retinanet.utils.visualization</strong> <strong class="lc iu">import</strong> draw_box, draw_caption<br/><strong class="lc iu">from</strong> <strong class="lc iu">keras_retinanet.utils.colors</strong> <strong class="lc iu">import</strong> label_color<br/><em class="lp">#from keras_retinanet.keras_retinanet.utils.gpu import setup_gpu</em><br/><br/><em class="lp"># import miscellaneous modules</em><br/><strong class="lc iu">import</strong> <strong class="lc iu">matplotlib.pyplot</strong> <strong class="lc iu">as</strong> <strong class="lc iu">plt</strong><br/><strong class="lc iu">import</strong> <strong class="lc iu">cv2</strong><br/><strong class="lc iu">import</strong> <strong class="lc iu">os</strong><br/><strong class="lc iu">import</strong> <strong class="lc iu">numpy</strong> <strong class="lc iu">as</strong> <strong class="lc iu">np</strong><br/><strong class="lc iu">import</strong> <strong class="lc iu">time</strong><br/><br/><em class="lp"># use this to change which GPU to use</em><br/>gpu = 0<br/><br/><em class="lp"># set the modified tf session as backend in keras</em><br/><em class="lp">#setup_gpu(gpu)</em><br/><br/><em class="lp"># adjust this to point to your downloaded/trained model</em><br/><em class="lp"># models can be downloaded here: https://github.com/fizyr/keras-retinanet/releases</em><br/>model_path = os.path.join('..', 'weights', 'resnet50_csv_04.h5')<br/><br/>model = models.load_model(model_path, backbone_name='resnet50')<br/><br/><em class="lp"># if the model is not converted to an inference model, use the line below</em><br/><em class="lp"># see: https://github.com/fizyr/keras-retinanet#converting-a-training-model-to-inference-model</em><br/><em class="lp">#model = models.convert_model(model)</em><br/><br/><em class="lp">#print(model.summary())</em><br/><br/><em class="lp"># load label to names mapping for visualization purposes</em><br/>labels_to_names = {<br/>    0: 'hammer1', <br/>    1: 'hammer2',<br/>    3: 'hammer3',<br/>    4: 'plier1',<br/>    5: 'plier2',<br/>    6: 'plier3',<br/>    7: 'screw1',<br/>    8: 'screw2',<br/>    9: 'screw3'}<br/><br/><em class="lp"># load image</em><br/>image = read_image_bgr('/content/img.jpg')<br/><br/><em class="lp"># copy to draw on</em><br/>draw = image.copy()<br/>draw = cv2.cvtColor(draw, cv2.COLOR_BGR2RGB)<br/><br/><em class="lp"># preprocess image for network</em><br/>image = preprocess_image(image)<br/>image, scale = resize_image(image)<br/><br/><em class="lp"># process image</em><br/>start = time.time()<br/>boxes, scores, labels = model.predict_on_batch(np.expand_dims(image, axis=0))<br/>print("processing time: ", time.time() - start)<br/><br/><em class="lp"># correct for image scale</em><br/>boxes /= scale<br/><br/><em class="lp"># visualize detections</em><br/><strong class="lc iu">for</strong> box, score, label <strong class="lc iu">in</strong> zip(boxes[0], scores[0], labels[0]):<br/>    <em class="lp"># scores are sorted so we can break</em><br/>    <strong class="lc iu">if</strong> score &lt; 0.21:<br/>        <strong class="lc iu">break</strong><br/>        <br/>    color = label_color(label)<br/>    <br/>    b = box.astype(int)<br/>    draw_box(draw, b, color=color)<br/>    <br/>    caption = "<strong class="lc iu">{}</strong> <strong class="lc iu">{:.3f}</strong>".format(labels_to_names[label], score)<br/>    draw_caption(draw, b, caption)<br/>    <br/>plt.figure(figsize=(15, 15))<br/>plt.axis('off')<br/>plt.imshow(draw)<br/>plt.show()</span></pre><p id="a3c0" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">我取了 21%的阈值，所以模型预测仪器的准确率是 22%。</p><figure class="kq kr ks kt gt ku gh gi paragraph-image"><div role="button" tabindex="0" class="lv lw di lx bf ly"><div class="gh gi lz"><img src="../Images/484dee73a91eef5601b9ec28f5dd1461.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*1ngU7aa0Lonfde7Ly2IZ3A.png"/></div></div><figcaption class="kx ky gj gh gi kz la bd b be z dk">Retinanet prediction on a real photo after 4 epochs of training on KTH_Dataset.</figcaption></figure><p id="0e00" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">我们可以进一步训练模型以改进模型，并且训练模型超过 4 个时期。</p><p id="a7ff" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu">结论。</strong></p><p id="e857" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">本文是研究的一部分，我们想要创建一个模型，它可以识别视频中的乐器。我们使用 KTH 手工工具数据集来提高模型的准确性。实验表明，额外的图像改善了对象检测。可以对模型进行一些改进(可以使用额外的数据集来改进仪器检测，可以进行更多的时期训练)。</p><p id="f007" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu">参考文献</strong></p><ol class=""><li id="d5b0" class="ma mb it js b jt ju jx jy kb mc kf md kj me kn mf mg mh mi bi translated"><a class="ae ko" href="https://arxiv.org/abs/1708.02002" rel="noopener ugc nofollow" target="_blank">密集物体探测的焦点损失</a></li><li id="055d" class="ma mb it js b jt mj jx mk kb ml kf mm kj mn kn mf mg mh mi bi translated"><a class="ae ko" href="https://github.com/fizyr/keras-retinanet" rel="noopener ugc nofollow" target="_blank"> Keras-retinanet </a></li><li id="acbc" class="ma mb it js b jt mj jx mk kb ml kf mm kj mn kn mf mg mh mi bi translated"><a class="ae ko" href="https://medium.com/@abdulwahabamin/an-introduction-to-implementing-retinanet-in-keras-for-multi-object-detection-on-custom-dataset-be746024c653" rel="noopener">介绍如何在 Keras 中实现 Retinanet，以便在自定义数据集上进行多目标检测</a></li><li id="1f7d" class="ma mb it js b jt mj jx mk kb ml kf mm kj mn kn mf mg mh mi bi translated"><a class="ae ko" href="https://www.nada.kth.se/cas/data/handtool/" rel="noopener ugc nofollow" target="_blank">h 手动工具数据集</a></li></ol></div></div>    
</body>
</html>