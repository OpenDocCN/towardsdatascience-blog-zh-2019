# 人工智能是我们文明中最好的，还是最坏的？

> 原文：<https://towardsdatascience.com/is-artificial-intelligence-the-best-that-has-happened-to-our-civilisation-or-the-worst-2bcec4e86d79?source=collection_archive---------36----------------------->

![](img/6644f39aa5e56877947ff89d419483db.png)

Photo by [@andreasdress](https://unsplash.com/@andreasdress)

这将是一个剧透警告说:两者都有。然而，我们能同时拥抱两个极端吗？看来人们必须有自己的看法。如果我们将人工智能视为一种工具，我们可以说，它最好由正确的人使用，最坏由错误的人使用。另一方面，这两者之间很少有明确的界限。

如果我们将人工智能视为对社会产生系统性后果的技术进步，那么我们可以说，加剧当前的气候危机或地球上可能经历的不平等是糟糕的。控制人口的数量信息并不新奇，但其规模和范围确实可以说是无所不包。因此，我们可以说，这种气候观点和社会关注是争论它是最糟糕的一条途径。

## 人工智能和能力

相反，考虑一下如果一颗流星撞击地球，这并不是不可思议的。2019 年 10 月，三颗小行星掠过地球，其中一颗据说只有 [24 小时通知](https://www.space.com/four-asteroids-fly-by-earth-october-2019.html)。如果是这样的话，或者任何其他对地球上生命的威胁被煽动起来，我们可能希望拥有最先进的技术来帮助解决可能出现的潜在问题。

潘多拉魔盒的描述可能会发现这样说很有用:好吧，魔盒已经打开，你无法收回已经揭示的东西。盒子不能不打开，但是我们可以降低人工智能的使用，降低技术的等级或将其保持在最低限度的使用在[玻璃珠游戏](https://www.nytimes.com/1970/01/04/archives/the-glass-bead-game-glass-bead.html)中完成，这是一部写于战前的小说，在战争期间出版，并在 1946 年获得了诺贝尔文学奖。

在死亡和毁灭中，一本书问世了，思考乌托邦会是什么样子。我不是一个幻想乌托邦或任何此类事情的人，而是务实地认为，随着时间的推移，一个稍微好一点的世界是可以想象的。在与人工智能相关的担忧中说出这一点很奇怪。赤贫与人权问题特别报告员菲利普·奥尔斯顿最近以相当清晰的措辞描述了对穷人的监督:

> “数字福利国家要么已经成为现实，要么正在全球许多国家兴起。在这些国家，社会保护和援助系统越来越多地受到数字数据和技术的驱动，这些数据和技术被用于自动化、预测、识别、监视、检测、瞄准和惩罚。这份报告承认，政府朝着这个方向前进有着不可抗拒的吸引力，但警告称，有一个严重的风险，即陷入僵尸般的数字福利乌托邦。”

因此，以一种被描述为发生在社会上的*【最好的事情】*的方式使用技术或*【数字】*似乎是极其无知的。是的，根据一些标准，我们可以说世界正在改善，大多数人都指向统计数据。《垂死的世界》和《着火的房子》等的统计数据。似乎很乐观。

## AI &乐观主义

中国共产党革命家毛泽东在“大跃进”中宣扬的正是乐观主义——为了更好地种植庄稼而捕杀鸟类，但换来的却是虫灾和饥荒。美国*的“自由”在形式或形态上似乎[只是另一个词](https://blogs.eui.eu/wp-content/uploads/sites/20/2014/03/Harvey-Freedoms-Just-Another-Word.pdf)再次成为一种可能，与新自由主义看似相反的叙事。如果你愿意，你可以将任何政治意识形态置于人工智能领域之前。*

*资本驱动或自由的人工智能在某种程度上是科技公司更好地了解人口的情况，一些人将其称为心理图形结合社会计量指标。因此，定量和定性的社会科学家都致力于*“采用”或确保某种技术得到应用。如果你有一项交易，那么你会希望确保这项交易继续下去，这让人想起香港最初是如何被撮合的——第一次鸦片战争。**

**我不能确定这与真实性有关，或者这有多正确。我不是历史学家，然而历史学家现在似乎想谈论更多的未来。我已经提到把勾勒未来作为一种实践。提前计划或解释过去以采取行动有这种*历史化*的意味。当我们问这个更好或更坏的问题时，我们对人工智能做出了哪些解释？**

## **AI 与悲观主义**

**想到的陈词滥调是老电影中的终结者或哈尔，代表人类或某些人类的末日。这当然被某些技术专家用来赚取与投资相关的紧迫感，埃隆·马斯克就是一个支持者。他可能会因此受到批评，但我在技术领域遇到的人，尤其是开发人员，似乎仍然担心这种想法会成为现实。不是拟人化的方式，像人类一样的复仇，更多的是我们应该或不应该犯的简单错误。**

**前几天提到核战争。如果我们在末日列车上，那么那将是第一批目的地之一。流行病或人为疾病可能是另一个原因。接下来可能是贸易战、经济危机或生态系统崩溃。有很多事情要担心，但是…**

**人工智能是我们文明发生的最好的事情吗？提到这一点，我不禁想起了川普总统在周四宣布“文明的伟大一天”的画面，此前迈克·彭斯显然促成了与土耳其的停火。一位被指控首先通过撤军挑起这场战争的领导人。国际关系并不简单，国防也是如此。**

**战争中的自主武器引起了广泛的讨论和越来越多的抗议。反对黑仔机器人的运动已经巡回展示了这些进展。我记得我坐下来看到不同国家正在研发的武器的例子:美国、俄罗斯、中国、英国等等。战争中以各种方式破坏或毁灭的能力正在增加。**

## **AI & Power**

**人工智能以提取或关闭的方式入侵或扭曲解决方案是有记录的，但是在改变决策过程方面则记录较少。人们认为，人工智能正在赋予世界上一些最富有的人更多的权力，以控制国家贸易或权力的消长。**

**Amazon.com 的主人杰夫·贝索斯据说是世界上最富有的人。据说比尔·盖茨是世界上第二富有的人。这两位成功地利用了不仅仅是简单的机器学习技术或人工智能作为一个领域，但可以说这是他们持续崛起的原因。另外两位最富有的人都是谷歌的联合创始人，据说他们的公司现在是*、【人工智能优先】*。**

**设计范式并没有如此关注技术，但它首先是*以自我为中心*，然后是*以人为中心*。现在有人声称我们必须将它改为以生命为中心的设计。这听起来空泛或模糊，然而在设计过程中考虑生态系统应该不是一个新颖的想法。如果人工智能领域可以变得以生活为中心，那会是什么样子？如果是这样的话，难道就没有权力和声望可言了吗？设计是一个计划或规范，而算法是过程和规则，然而这两个领域的考虑并非没有政治。**

**我越来越多地受到政治科学领域的影响，这一领域倾向于现实主义，从这个角度来看，尤其是在国际安全政策方面，艾既诱人又危险。如果你可以在*【敌人】*不知情的情况下发动一场战争或获取信息，或者如果你可以发动一场没有任何生命损失的战争——这听起来很像无人机战争，尽管这些都是由人类控制的技术。**

## **人工智能与控制**

**当我们说由人类控制时，这是一个奇怪的说法，好像有区别。什么不受人类控制？并不是说一个决定会立即生效，尤其是如果它是程序化的。再说一次，人类也做投资，公司有个人身份，有时有更多的权利。有人建议对“人工智能”的应用也这样做，在这个框架内给予“人工智能”作为人的法律地位。然而，将错误归咎于一个系统而不是一个人或一家公司是很奇怪的。我们循环循环，公司是人是公司，我跑题了。**

**当我们说:这是由制度决定的——我们错了，也是对的。我们是错误的，因为一个人做了决定，我们是正确的，因为一个决定是共同做出的。系统是作为一个机制或一个互连网络的一部分一起工作的一组事物；复杂的整体。人类是这个系统的一部分，他们就是这个系统。**

**我们可以谈论人机交互，一种跨学科或学科分布的奇怪混合，并混合到科学和技术研究中。有了人工智能，我们就能融入 UX(用户体验)和 UI(用户界面)。我们设计的界面可以识别人脸，并将其归入一个类别——定罪或被定罪，使用或被使用，然后采取行动。也许是人类的行为。**

## **人工智能与证伪**

**从人类学的角度来看，伪造这些系统是重要的，但却被忽视了。人类学家研究的是经济理论，而不是经济的实际含义，并发现缺乏框架或效果。在技术或人工智能领域，我们似乎需要一名律师来陈述不公正的行为，这是该行业的管辖范围。尽管有这些担忧:人工智能当然是一个[【巨大的机会】](https://www.un.org/en/chronicle/article/towards-ethics-artificial-intelligence)，联合国在不同的情况下都是这样描述的。**

**随着科技公司向联合国提供的发展资金不断增加，可疑的问题可能会出现。我听说过一个边缘决定，拒绝一家医疗公司在获得资助后想要测试他们的药物，有些人说不。然而其他人不这样认为，他们说是，我们可以广泛地想知道，我们允许哪些国外的人工智能实验在警务、卫生或其他领域发生？**

**我认为说我们的文明发生了最好的事情有点夸张，但是进步是不可低估的。我回想起我的父亲和他的帕金森症，或者想在我妻子生病时救她。我也想到了人工智能在绘制气候危机或贫困地图方面可能产生的巨大影响。然而，我不会公开表示乐观，不加考虑的“无国界”创新似乎更不负责任。**

**石油公司利用气候信息为气候变化做准备，这是有据可查的。从技术公司内部，或者通过人工智能领域解决方案的应用，我们可以看到哪些我们没有立即看到的效果。一个典型的指责是硅谷技术大师的孩子，因为他们限制他们的孩子使用设备，或者旧金山禁止面部识别。**

**我认为对技术的恐惧和兴奋是一种奇怪的感情鸡尾酒。我可以承认，在处理这些问题或我的流中的各种声明时，我是矛盾的。意识流就是意识流，它似乎经常是某些技术专家在他们的机器中“突破界限”所想要的。如果我们把这种表达带回以前的问题，那么推进我们的行星生态系统的边界似乎是同时进行的冒险。**

## **人工智能与气候危机**

**制冷、运输、矿物、采矿、电力、带宽、凯斯勒综合症、卫星、月球旅行等等。在技术上突破地球的界限是一种追求，它将这个问题推向了极端，变得夸张。太空旅行和气候友好的梦想在进步和向过去致敬的思想中运作。灭绝的物种会被记住，或者新的行星会被发现。无论是新丝绸之路还是让美国再次伟大，我们本质上都被束缚在途中的某个地方。**

**我说过我们需要停止展望未来，转而解决目前的状况，然而这似乎是不可能的。不可避免的是，任何改变都与可能是什么或不应该是什么的愿景有关。这个问题立即推进了这个场景制作的空间。这是真实的或错误的，不仅仅是在回顾过去的时候，当看着笔记本电脑的屏幕或在报纸上的时候。什么时候智力是真实的？情报的第二个含义是收集具有军事或政治价值的信息。**

**我们说的智能是指信息吗？如果是这样的话，那么我们正处于一个前所未有的聪明时刻，前所未有的聪明让人类有可能做出决策。因此，如果我们放下理性的伪装，那么作为一个文明，也许我们可以做得最好或者最好。如果我们不再表现得好像智力比理解、同情意识或理解力更重要。**

**如果对所提供的信息不做任何处理或处理的价值很小，那么信息就没有什么价值。因此，无论我们收集什么样的情报，我们都必须认为自己对其使用负有责任，并努力理解其好坏。我们决定我们是否真的有能力这样做，无论是独立地还是联合地，无论是好是坏。**

**这里是#500daysofAI，您正在阅读第 140 篇文章。500 天来，我每天都写一篇关于人工智能或与之相关的新文章。**

**感谢您的阅读，感谢您的宝贵时间。如果你能分享你由此产生的任何想法，那将是很有价值的。**