<html>
<head>
<title>Evaluating Machine Learning Classification Problems in Python: 6+1 Metrics That Matter</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">评估 Python 中的机器学习分类问题:重要的 6+1 度量</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/evaluating-machine-learning-classification-problems-in-python-5-1-metrics-that-matter-792c6faddf5?source=collection_archive---------6-----------------------#2019-07-08">https://towardsdatascience.com/evaluating-machine-learning-classification-problems-in-python-5-1-metrics-that-matter-792c6faddf5?source=collection_archive---------6-----------------------#2019-07-08</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="bed0" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">评估您的 ML 分类项目性能的指南</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/e97d8e718ca2a69a29857f87585b235b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*vx7LXlYqXo80f13w"/></div></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk">Photo by <a class="ae ky" href="https://unsplash.com/@franckinjapan?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Franck V.</a> on <a class="ae ky" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><p id="863f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">机器学习分类和评估模型可能是一项艰巨的任务。本文将试图通过解释“混淆矩阵”、评估指标以及二元分类问题的 ROC AUC 来消除这种“混淆”。对于每个部分，还提供了一个示例<strong class="lb iu"> Python </strong>代码，以帮助读者理解 Python 中的机器学习二进制分类和评估。</p><h1 id="9503" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated"><strong class="ak">分类 vs 回归</strong></h1><p id="f8b0" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">数据科学家通常利用机器学习(ML)工具和库来开发代码，这些代码在不使用显式指令的情况下有效地执行特定任务，而是依靠模式和推理来预测连续变量或变量的类别/类别。一般来说，我们可以把这些 ML 问题分为三类:</p><p id="7658" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">回归</strong>:这些问题涉及到预测一个连续变量，比如温度、价格、年龄等。例如:</p><ul class=""><li id="1214" class="ms mt it lb b lc ld lf lg li mu lm mv lq mw lu mx my mz na bi translated">"根据房子的特点，它的售价是多少？"</li><li id="d429" class="ms mt it lb b lc nb lf nc li nd lm ne lq nf lu mx my mz na bi translated">"客户将在这个网站上订购多少产品？"</li></ul><p id="a206" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">二元分类:</strong>这些问题通常涉及需要是/否或 1/0 结果的问题。例如:</p><ul class=""><li id="bb0b" class="ms mt it lb b lc ld lf lg li mu lm mv lq mw lu mx my mz na bi translated">“这是欺诈交易吗？”</li><li id="b3b3" class="ms mt it lb b lc nb lf nc li nd lm ne lq nf lu mx my mz na bi translated">“这个客户会订购这个产品吗？”</li></ul><p id="17e3" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">多类分类:</strong>这些类似于二元分类，但是在这种情况下，问题涉及在两个以上的类别之间进行选择。例如:</p><ul class=""><li id="7a61" class="ms mt it lb b lc ld lf lg li mu lm mv lq mw lu mx my mz na bi translated">“这是什么样的交易？借方、贷方等。”</li><li id="4802" class="ms mt it lb b lc nb lf nc li nd lm ne lq nf lu mx my mz na bi translated">"这位顾客对哪类产品感兴趣？"</li></ul></div><div class="ab cl ng nh hx ni" role="separator"><span class="nj bw bk nk nl nm"/><span class="nj bw bk nk nl nm"/><span class="nj bw bk nk nl"/></div><div class="im in io ip iq"><h1 id="36e3" class="lv lw it bd lx ly nn ma mb mc no me mf jz np ka mh kc nq kd mj kf nr kg ml mm bi translated"><strong class="ak">评估二元分类问题</strong></h1><p id="74c5" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">通常，在回归和分类模型中，数据集被分为训练数据集和测试数据集。然后，该模型在“训练数据集”上进行训练和拟合，并用于基于“测试数据集”进行预测，以<strong class="lb iu"> <em class="ns">评估</em> </strong>性能。这种训练/测试分割的原因是为了模拟未来的数据集，也是为了避免模型过度适应训练数据集。这种方法的好处是测试数据集中目标的实际值是已知的，这对于评估模型是至关重要的。<strong class="lb iu"> <em class="ns">但是这个测评是怎么做的呢？</em>T19】</strong></p><p id="eb16" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">对于二元分类问题，可以计算多种度量来评估预测模型的性能。这些指标是基于所谓的“<strong class="lb iu">混淆矩阵</strong>”计算出来的。</p><h2 id="0019" class="nt lw it bd lx nu nv dn mb nw nx dp mf li ny nz mh lm oa ob mj lq oc od ml oe bi translated">混乱矩阵</h2><p id="7b77" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated"><a class="ae ky" href="http://www2.cs.uregina.ca/~dbd/cs831/notes/confusion_matrix/confusion_matrix.html" rel="noopener ugc nofollow" target="_blank">《关于混淆矩阵的理论》</a>把矩阵描述为:</p><blockquote class="of og oh"><p id="06cd" class="kz la ns lb b lc ld ju le lf lg jx lh oi lj lk ll oj ln lo lp ok lr ls lt lu im bi translated">混淆矩阵包含关于由分类系统完成的实际和预测分类的信息。通常使用矩阵中的数据来评估这种系统的性能。</p></blockquote><p id="1d9f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">下面给出的这个矩阵是所有二进制分类问题的基础，并且广泛用于机器学习模型中。表中的缩略语也有描述。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ol"><img src="../Images/29253b7b8870f8eadd023d10a8575bd4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1094/format:webp/1*haREV2swuFBBmRc2bSHMzg.png"/></div></figure><p id="d569" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu"> <em class="ns">正</em> </strong>在这种情况下就是<strong class="lb iu"> <em class="ns">的类息</em> </strong>。例如，“识别欺诈交易”。</p><p id="d6de" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">真阳性(TP): </strong>当模型预测为阳性，并且它们实际上为阳性时(例如，欺诈交易被识别为欺诈)。</p><p id="4b70" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">真阴性(TN) </strong>:模型预测为阴性，实际为阴性(例如，非欺诈交易被识别为非欺诈)。</p><p id="8be3" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">假阳性(FP)(也称为 I 型错误):</strong>当模型预测为阳性，但实际上却为阴性时(例如，非欺诈性交易被识别为欺诈性交易)。</p><p id="21a5" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">假阴性(FN)(也称为第二类错误):</strong>当模型预测为阴性，但它们为阳性时(例如，欺诈性交易被识别为非欺诈性交易)。</p><p id="5d5e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">通常，第二类错误(FN)具有更严重的后果，而在 ML 中，目标是最小化第二类错误。另一方面，第一类错误的后果较小。然而，在理想情况下，一个完美的模型应该没有这些错误。</p><p id="41bf" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">让我们用 Python 写一个函数来创建混淆矩阵。<a class="ae ky" href="https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html" rel="noopener ugc nofollow" target="_blank"> Scikit Learn (SKLearn)库有一个</a> <code class="fe om on oo op b"><a class="ae ky" href="https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html" rel="noopener ugc nofollow" target="_blank">metrics</a></code> <a class="ae ky" href="https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html" rel="noopener ugc nofollow" target="_blank">包，其中包含了</a> <code class="fe om on oo op b"><a class="ae ky" href="https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html" rel="noopener ugc nofollow" target="_blank">confusion_matrix</a></code> <a class="ae ky" href="https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html" rel="noopener ugc nofollow" target="_blank">方法</a>。</p><pre class="kj kk kl km gt oq op or os aw ot bi"><span id="ce60" class="nt lw it op b gy ou ov l ow ox"># Importing the metrics package from sklearn library<br/>from sklearn import metrics</span><span id="2d84" class="nt lw it op b gy oy ov l ow ox"># Creating the confusion matrix<br/>cm = metrics.confusion_matrix(y_test, y_pred)</span><span id="b837" class="nt lw it op b gy oy ov l ow ox"># Assigning columns names<br/>cm_df = pd.DataFrame(cm, <br/>            columns = ['Predicted Negative', 'Predicted Positive'],<br/>            index = ['Actual Negative', 'Actual Positive'])</span><span id="d292" class="nt lw it op b gy oy ov l ow ox"># Showing the confusion matrix<br/>cm_df</span></pre><h2 id="df2d" class="nt lw it bd lx nu nv dn mb nw nx dp mf li ny nz mh lm oa ob mj lq oc od ml oe bi translated"><strong class="ak">重要的六项指标</strong></h2><p id="faf8" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">在统计书籍中有许多评估混淆矩阵的度量，但其中六个在 ML 问题中使用得更广泛。</p><p id="77db" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">准确度是正确预测占预测总数的比例。</p><p id="33c3" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><em class="ns">准确率= (TP + TN) /所有预测</em></p><p id="f170" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">误分类</strong>为(1-准确性)，指预测总数中的所有错误预测。</p><p id="efb5" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu"> <em class="ns">灵敏度(又名回忆)</em> </strong>表示“在所有实际阳性中，我们预测为阳性的有多少”，可以解释为:</p><p id="a883" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><em class="ns">灵敏度(回忆)= TP / (FN + TP) </em></p><p id="dc92" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">特异性(又名选择性或真阴性率，TNR) </strong>表示“在所有实际阴性中，我们预测多少为阴性”，可以写成:</p><p id="9008" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><em class="ns">特异性= TN / (TN + FP) </em></p><p id="b87a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">精度(又名阳性预测值，PPV) </strong>表示“在所有预测的阳性病例中，有多少实际上是阳性的”，或</p><p id="8372" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><em class="ns">精度= TP / (TP + FP) </em></p><p id="5361" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu"> F1 得分</strong>是精确度和灵敏度的调和或加权平均值，是分类问题精确度的一种广泛使用的测量方法。其计算方法如下:</p><p id="4a53" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">F1 得分= 2 *(精度*灵敏度)/(精度+灵敏度)</p><p id="8bcb" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">Python 中的这个函数将计算并报告混淆矩阵的这六个指标。</p><pre class="kj kk kl km gt oq op or os aw ot bi"><span id="c063" class="nt lw it op b gy ou ov l ow ox"># Creating a function to report confusion metrics</span><span id="4a14" class="nt lw it op b gy oy ov l ow ox">def confusion_metrics (conf_matrix):</span><span id="e2ce" class="nt lw it op b gy oy ov l ow ox"># save confusion matrix and slice into four pieces</span><span id="0265" class="nt lw it op b gy oy ov l ow ox">    TP = conf_matrix[1][1]<br/>    TN = conf_matrix[0][0]<br/>    FP = conf_matrix[0][1]<br/>    FN = conf_matrix[1][0]</span><span id="96e9" class="nt lw it op b gy oy ov l ow ox">    print('True Positives:', TP)<br/>    print('True Negatives:', TN)<br/>    print('False Positives:', FP)<br/>    print('False Negatives:', FN)<br/>    <br/>    # calculate accuracy<br/>    conf_accuracy = (float (TP+TN) / float(TP + TN + FP + FN))<br/>    <br/>    # calculate mis-classification<br/>    conf_misclassification = 1- conf_accuracy<br/>    <br/>    # calculate the sensitivity<br/>    conf_sensitivity = (TP / float(TP + FN))</span><span id="8759" class="nt lw it op b gy oy ov l ow ox">    # calculate the specificity<br/>    conf_specificity = (TN / float(TN + FP))<br/>    <br/>    # calculate precision<br/>    conf_precision = (TN / float(TN + FP))</span><span id="87ce" class="nt lw it op b gy oy ov l ow ox">    # calculate f_1 score<br/>    conf_f1 = 2 * ((conf_precision * conf_sensitivity) / (conf_precision + conf_sensitivity))</span><span id="1fdb" class="nt lw it op b gy oy ov l ow ox">    print('-'*50)<br/>    print(f'Accuracy: {round(conf_accuracy,2)}') <br/>    print(f'Mis-Classification: {round(conf_misclassification,2)}') <br/>    print(f'Sensitivity: {round(conf_sensitivity,2)}') <br/>    print(f'Specificity: {round(conf_specificity,2)}') <br/>    print(f'Precision: {round(conf_precision,2)}')<br/>    print(f'f_1 Score: {round(conf_f1,2)}')</span></pre><h2 id="43c0" class="nt lw it bd lx nu nv dn mb nw nx dp mf li ny nz mh lm oa ob mj lq oc od ml oe bi translated">加一指标:ROC AUC[或受试者工作特征曲线下面积(ROC)]</h2><p id="cbaa" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">据<a class="ae ky" href="https://en.wikipedia.org/wiki/Receiver_operating_characteristic" rel="noopener ugc nofollow" target="_blank">维基百科</a>:</p><blockquote class="of og oh"><p id="c38f" class="kz la ns lb b lc ld ju le lf lg jx lh oi lj lk ll oj ln lo lp ok lr ls lt lu im bi translated">受试者操作特征曲线，或 ROC 曲线，是一种图示，说明了二元分类器系统在其辨别阈值变化时的诊断能力。ROC 曲线是通过在各种阈值设置下绘制真阳性率(TPR)对假阳性率(FPR)来创建的。在机器学习中，真阳性率也称为灵敏度、召回率或检测概率[4]。</p></blockquote><p id="c60f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们可以利用 ROC 曲线来可视化阳性和阴性类别之间的重叠。为此，我们可以遵循以下步骤:</p><p id="c3a9" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">1)将分类阈值设置为 0，这意味着所有预测都被分类为第 1 类(阳性)。</p><p id="09dc" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">2)计算该阈值的灵敏度和 1-特异性。</p><p id="e607" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">3)绘制数值(x = 1-特异性，y =敏感性)。</p><p id="9a37" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">4)提高小数字的分类阈值(如 0.005)。</p><p id="215c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">5)重复步骤 1–4。</p><p id="e144" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">6)重复直到阈值等于 1(这意味着所有预测都是 0 类，负的)。</p><p id="bf8c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这个过程的结果看起来会像这个图表。曲线下面积(AUC)是我们可以用于分类模型的另一个评估指标。45 度线是 AUC 为 0.5 的基线。完美模型的 AUC 为 1.0。AUC 越接近 1.0，预测越好。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi oz"><img src="../Images/b7f27ba6f08ac7e042c3dfe1277b0dae.png" data-original-src="https://miro.medium.com/v2/resize:fit:578/format:webp/0*USSlPSR45GyQdcZT.png"/></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk">ROC Curve (from <a class="ae ky" href="https://www.medcalc.org/manual/roc-curves.php" rel="noopener ugc nofollow" target="_blank">https://www.medcalc.org/manual/roc-curves.php</a>)</figcaption></figure><p id="14f9" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">让我们用 python 构建一个 ROC AUC，使用<code class="fe om on oo op b">Logistic Regression</code>模型。</p><pre class="kj kk kl km gt oq op or os aw ot bi"><span id="237a" class="nt lw it op b gy ou ov l ow ox"># The codes below is partly copied from the code written by Matt Brem, Global Instructor at General Assembly.</span><span id="517f" class="nt lw it op b gy oy ov l ow ox"># Imports</span><span id="42aa" class="nt lw it op b gy oy ov l ow ox">import matplotlib.pyplot as plt<br/>import numpy as np<br/>import pandas as pd<br/>from sklearn.model_selection import train_test_split<br/>from sklearn.linear_model import LogisticRegression</span><span id="07f1" class="nt lw it op b gy oy ov l ow ox"># Train/test split<br/>X_train, X_test, y_train, y_test = train_test_split(X,y, random_state = 42)</span><span id="c93b" class="nt lw it op b gy oy ov l ow ox"># Instantiating a logisitic regression model<br/>logreg = LogisiticRegression()<br/>logreg.fit(X_train, y_train)    # model fitting<br/>y_pred = logreg.predict(X_test)   # Predictions</span><span id="fa46" class="nt lw it op b gy oy ov l ow ox"># Calculating class probabilities<br/>pred_proba = [i[1] for i in logreg.predict_proba(X_test)]</span><span id="76cf" class="nt lw it op b gy oy ov l ow ox">pred_df = pd.DataFrame({'true_values': y_test,<br/>                        'pred_probs':pred_proba})</span><span id="b029" class="nt lw it op b gy oy ov l ow ox"># The codes below is motly copied from the code written by Matt Brem, Global Instructor at General Assembly.</span><span id="b189" class="nt lw it op b gy oy ov l ow ox"># Create figure.<br/>plt.figure(figsize = (10,7))</span><span id="69fa" class="nt lw it op b gy oy ov l ow ox"># Create threshold values. <br/>thresholds = np.linspace(0, 1, 200)</span><span id="aecd" class="nt lw it op b gy oy ov l ow ox"># Define function to calculate sensitivity. (True positive rate.)<br/>def TPR(df, true_col, pred_prob_col, threshold):<br/>    true_positive = df[(df[true_col] == 1) &amp; (df[pred_prob_col] &gt;= threshold)].shape[0]<br/>    false_negative = df[(df[true_col] == 1) &amp; (df[pred_prob_col] &lt; threshold)].shape[0]<br/>    return true_positive / (true_positive + false_negative)<br/>    <br/># Define function to calculate 1 - specificity. (False positive rate.)<br/>def FPR(df, true_col, pred_prob_col, threshold):<br/>    true_negative = df[(df[true_col] == 0) &amp; (df[pred_prob_col] &lt;= threshold)].shape[0]<br/>    false_positive = df[(df[true_col] == 0) &amp; (df[pred_prob_col] &gt; threshold)].shape[0]<br/>    return 1 - (true_negative / (true_negative + false_positive))<br/>    <br/># Calculate sensitivity &amp; 1-specificity for each threshold between 0 and 1.<br/>tpr_values = [TPR(pred_df, 'true_values', 'pred_probs', prob) for prob in thresholds]<br/>fpr_values = [FPR(pred_df, 'true_values', 'pred_probs', prob) for prob in thresholds]</span><span id="524c" class="nt lw it op b gy oy ov l ow ox"># Plot ROC curve.<br/>plt.plot(fpr_values, # False Positive Rate on X-axis<br/>         tpr_values, # True Positive Rate on Y-axis<br/>         label='ROC Curve')</span><span id="244e" class="nt lw it op b gy oy ov l ow ox"># Plot baseline. (Perfect overlap between the two populations.)<br/>plt.plot(np.linspace(0, 1, 200),<br/>         np.linspace(0, 1, 200),<br/>         label='baseline',<br/>         linestyle='--')</span><span id="94fb" class="nt lw it op b gy oy ov l ow ox"># Label axes.<br/>plt.title(f"ROC Curve with AUC = {round(metrics.roc_auc_score(pred_df['true_values'], pred_df['pred_probs']),3)}", fontsize=22)<br/>plt.ylabel('Sensitivity', fontsize=18)<br/>plt.xlabel('1 - Specificity', fontsize=18)</span><span id="6fb0" class="nt lw it op b gy oy ov l ow ox"># Create legend.<br/>plt.legend(fontsize=16);</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi pa"><img src="../Images/fa6d14df62d21dcec38ce0c9025c14e8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1234/format:webp/1*qZCjX4SxRKhXO58H60nAag.png"/></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk">Sample Output of the Above Code</figcaption></figure><h1 id="e309" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated"><strong class="ak">多类分类的混淆矩阵</strong></h1><p id="47e4" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">评估多类分类问题与评估二元问题没有什么不同，但是在这种情况下，将为每个类单独计算上面讨论的度量。在具有<code class="fe om on oo op b">N</code>类的分类模型中，混淆矩阵将是<code class="fe om on oo op b">NxN</code>，左轴显示实际的类(如测试集中已知的)，顶轴显示预测的类。矩阵的每个元素𝑖,𝑗将是被分类为预测类别𝑗.中的具有实际类别𝑖的项目的数量</p><p id="c2a9" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><a class="ae ky" href="https://docs.aws.amazon.com/machine-learning/latest/dg/multiclass-classification.html" rel="noopener ugc nofollow" target="_blank">亚马逊 AWS ML 文档</a>提到:</p><blockquote class="of og oh"><p id="c843" class="kz la ns lb b lc ld ju le lf lg jx lh oi lj lk ll oj ln lo lp ok lr ls lt lu im bi translated">与二元分类问题的过程不同，您不需要选择分数阈值来进行预测。预测答案是具有最高预测分数的类别(即标签)。在某些情况下，您可能希望仅在预测的答案得分较高时才使用它。在这种情况下，您可以选择预测分数的阈值，根据该阈值您是否接受预测答案。</p></blockquote><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi pb"><img src="../Images/14e1afb74bf15c4106008618d939385a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1116/format:webp/0*pdL12IjLKgx-yFE0.png"/></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk">Multi-Class Confusion Matrix (from Amazon AWS website <a class="ae ky" href="https://docs.aws.amazon.com/machine-learning/latest/dg/multiclass-classification.html" rel="noopener ugc nofollow" target="_blank">https://docs.aws.amazon.com/machine-learning/latest/dg/multiclass-classification.html</a>)</figcaption></figure><p id="8338" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">亚马逊 AWS 文档中也提到:</p><blockquote class="of og oh"><p id="da95" class="kz la ns lb b lc ld ju le lf lg jx lh oi lj lk ll oj ln lo lp ok lr ls lt lu im bi translated">多分类中使用的典型度量与二分类情况中使用的度量相同。在将所有其他类分组为属于第二类之后，通过将每个类视为二元分类问题来计算每个类的度量。然后，对所有类别的二进制度量进行平均，以获得宏平均(平等对待每个类别)或加权平均(按类别频率加权)度量。</p></blockquote><h1 id="ddd7" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">将所有这些整合在一起…</h1><p id="2bd6" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">正如本文中所解释的，有许多度量标准可以用来评估分类模型的性能。本文介绍了二进制分类模型、评估此类模型的指标，并提供了一组 python 代码片段来帮助读者进行此类评估。</p><p id="f566" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">还讨论了多类分类并与二元分类进行了比较。</p></div><div class="ab cl ng nh hx ni" role="separator"><span class="nj bw bk nk nl nm"/><span class="nj bw bk nk nl nm"/><span class="nj bw bk nk nl"/></div><div class="im in io ip iq"><p id="0457" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu"> <em class="ns">尼克·米奈博士</em></strong><em class="ns">(</em><a class="ae ky" href="https://www.linkedin.com/in/nickminaie/?source=post_page---------------------------" rel="noopener ugc nofollow" target="_blank"><em class="ns">LinkedIn 简介</em> </a> <em class="ns">)是一位资深顾问和富有远见的数据科学家，代表了领导技能、世界级数据科学专业知识、商业敏锐度和领导组织变革能力的独特组合。他的使命是推进人工智能(AI)和机器学习在行业中的实践。</em></p></div></div>    
</body>
</html>