<html>
<head>
<title>Building K-pop Idol Identifier with Amazon Rekognition</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用 Amazon Rekognition 构建韩国流行偶像标识符</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/building-k-pop-idol-identifier-with-amazon-rekognition-92302442d763?source=collection_archive---------6-----------------------#2019-05-25">https://towardsdatascience.com/building-k-pop-idol-identifier-with-amazon-rekognition-92302442d763?source=collection_archive---------6-----------------------#2019-05-25</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="1a69" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">人脸识别简明指南</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/ad8aa59ca329a7025764a9fb697f5920.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*nTlUfIVsBOUIyO0g"/></div></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk">Photo by <a class="ae kv" href="https://unsplash.com/@bachtran2000?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Bach Tran</a> on <a class="ae kv" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><p id="9f7e" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">从头开始构建数据科学模型是一项相当大的工作。有许多元素组成一个单一的模型，涉及许多步骤，并且需要许多迭代来创建一个像样的模型。尽管完成这些步骤肯定会帮助您更深入地理解模型中使用的算法，但有时您没有足够的时间来完成所有的试验和错误，特别是当您有一个紧迫的截止日期要满足时。</p><p id="fb8c" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">图像识别是机器学习中的一个领域，已经被许多科技巨头如谷歌、亚马逊、微软深入探索。在图像处理的所有功能中，可能讨论最多的是面部识别。关于这项技术的伦理方面有很多争论，但这超出了本文的范围。我将简单地分享我在 Amazon Rekognition 上的尝试，希望你能从这篇文章中有所收获。</p><p id="56bd" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">写这篇文章的冲动始于我在他们的网络界面上玩了一下亚马逊的 Rekognition 演示。它提供许多有用的服务，如“对象和场景检测”、“面部识别”、“面部分析”和“名人识别”。我试了几张图，一切都很顺利，直到我到了“名人识别”。在我尝试使用韩国明星的照片之前，名人识别起初似乎还不错。韩国明星的认知度表现明显下降。有时它给我正确的答案，有时它不能识别，有时它给我错误的名字。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ls"><img src="../Images/f9800ccc8bd0742df2047d0e227a6906.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*hBO4OQiVxP9lPk_OAkdz3g.png"/></div></div></figure><p id="6157" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">顺便说一下，上面的照片是周子瑜来自一个名为 Twice 的组合，这是我最喜欢的 K-pop 女子组合，我不能接受亚马逊承认这张照片是 Seolhyun(她是另一个名为 AOA 的组合的成员)。</p><p id="dcc3" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">所以我决定使用 Amazon Rekognition 编写一个简单的 Python 脚本，它可以准确地检测两次。</p><ul class=""><li id="988c" class="lt lu iq ky b kz la lc ld lf lv lj lw ln lx lr ly lz ma mb bi translated">除了你可以在文章中找到的简短代码块，我会在文章末尾附上整个 Jupyter 笔记本的链接。</li><li id="3a6d" class="lt lu iq ky b kz mc lc md lf me lj mf ln mg lr ly lz ma mb bi translated">这篇文章基于教程“<a class="ae kv" href="https://aws.amazon.com/blogs/machine-learning/build-your-own-face-recognition-service-using-amazon-rekognition/" rel="noopener ugc nofollow" target="_blank">使用 Amazon Rekognition </a>构建自己的人脸识别服务”，但对原始代码进行了修改，以适应该项目的特定目的。</li></ul><h1 id="e7b1" class="mh mi iq bd mj mk ml mm mn mo mp mq mr jw ms jx mt jz mu ka mv kc mw kd mx my bi translated">使用 Amazon Rekognition 进行人脸检测</h1><p id="1a72" class="pw-post-body-paragraph kw kx iq ky b kz mz jr lb lc na ju le lf nb lh li lj nc ll lm ln nd lp lq lr ij bi translated">要运行 Jupyter 笔记本中的以下步骤，有几个先决条件。</p><ol class=""><li id="9019" class="lt lu iq ky b kz la lc ld lf lv lj lw ln lx lr ne lz ma mb bi translated">亚马逊 AWS 帐户</li><li id="6ea7" class="lt lu iq ky b kz mc lc md lf me lj mf ln mg lr ne lz ma mb bi translated">使用 AWS CLI 配置的 AWS 凭据</li><li id="747f" class="lt lu iq ky b kz mc lc md lf me lj mf ln mg lr ne lz ma mb bi translated">Boto3 的最新版本</li></ol><p id="fb72" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">让我们首先从导入一些将直接用于下一步的包开始。</p><pre class="kg kh ki kj gt nf ng nh ni aw nj bi"><span id="c0f8" class="nk mi iq ng b gy nl nm l nn no">import boto3<br/>from PIL import Image</span><span id="5c25" class="nk mi iq ng b gy np nm l nn no">%matplotlib inline</span></pre><p id="e4f2" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">现在我们需要一个我们想要处理的图像。我选择了与上面的 web 界面演示相同的图像，我们将把这个图像发送给 Rekognition API 以获得其图像识别的结果。(图片也可以在我将在本文末尾分享的 Github 链接中找到。)我们来快速看一下图像。</p><pre class="kg kh ki kj gt nf ng nh ni aw nj bi"><span id="f421" class="nk mi iq ng b gy nl nm l nn no">display(Image.open('Tzuyu.jpeg'))</span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nq"><img src="../Images/958d6044582d9ca1dc911d577dc26440.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*zUsmISdI30a3GN-sUlN-2A.png"/></div></div></figure><p id="aa46" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我们可以要求 Rekognition 执行的最基本的任务是用给定的图像进行面部识别，这只需要几行代码就可以完成。</p><pre class="kg kh ki kj gt nf ng nh ni aw nj bi"><span id="b666" class="nk mi iq ng b gy nl nm l nn no">import io</span><span id="4ea5" class="nk mi iq ng b gy np nm l nn no">rekognition = boto3.client('rekognition')</span><span id="ded0" class="nk mi iq ng b gy np nm l nn no">image = Image.open("Tzuyu.jpeg")<br/>stream = io.BytesIO()<br/>image.save(stream,format="JPEG")<br/>image_binary = stream.getvalue()</span><span id="4938" class="nk mi iq ng b gy np nm l nn no">rekognition.detect_faces(<br/>Image={'Bytes':image_binary},<br/>    Attributes=['ALL']<br/>)</span></pre><p id="ec61" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">您可以将图像作为内存中的二进制文件对象直接从您的本地机器发送到 rekognition，或者将您的图像上传到 S3，并在调用 rekognition.detect_faces()时将您的桶和密钥详细信息作为参数给出。在上面的例子中，我直接从本地机器发送二进制对象。您将从上面的调用中得到的响应将会很长，包含您可以从 Rekognition 的 detect_faces 函数中得到的所有信息。</p><pre class="kg kh ki kj gt nf ng nh ni aw nj bi"><span id="d5a0" class="nk mi iq ng b gy nl nm l nn no">{'FaceDetails': [{'AgeRange': {'High': 38, 'Low': 20},<br/>   'Beard': {'Confidence': 99.98848724365234, 'Value': False},<br/>   'BoundingBox': {'Height': 0.1584049016237259,<br/>    'Left': 0.4546355605125427,<br/>    'Top': 0.0878104418516159,<br/>    'Width': 0.09999311715364456},<br/>   'Confidence': 100.0,<br/>   'Emotions': [{'Confidence': 37.66959762573242, 'Type': 'SURPRISED'},<br/>    {'Confidence': 29.646778106689453, 'Type': 'CALM'},<br/>    {'Confidence': 3.8459930419921875, 'Type': 'SAD'},<br/>    {'Confidence': 3.134934186935425, 'Type': 'DISGUSTED'},<br/>    {'Confidence': 2.061260938644409, 'Type': 'HAPPY'},<br/>    {'Confidence': 18.516468048095703, 'Type': 'CONFUSED'},<br/>    {'Confidence': 5.1249613761901855, 'Type': 'ANGRY'}],<br/>   'Eyeglasses': {'Confidence': 99.98339080810547, 'Value': False},<br/>   'EyesOpen': {'Confidence': 99.9864730834961, 'Value': True},<br/>   'Gender': {'Confidence': 99.84709167480469, 'Value': 'Female'},<br/>   'Landmarks': [{'Type': 'eyeLeft',<br/>     'X': 0.47338899970054626,<br/>     'Y': 0.15436244010925293},<br/>    {'Type': 'eyeRight', 'X': 0.5152773261070251, 'Y': 0.1474122554063797},<br/>    {'Type': 'mouthLeft', 'X': 0.48312342166900635, 'Y': 0.211111381649971},<br/>    {'Type': 'mouthRight', 'X': 0.5174261927604675, 'Y': 0.20560002326965332},<br/>    {'Type': 'nose', 'X': 0.4872787892818451, 'Y': 0.1808750480413437},<br/>    {'Type': 'leftEyeBrowLeft',<br/>     'X': 0.45876359939575195,<br/>     'Y': 0.14424000680446625},<br/>    {'Type': 'leftEyeBrowRight',<br/>     'X': 0.4760720133781433,<br/>     'Y': 0.13612663745880127},<br/>    {'Type': 'leftEyeBrowUp',<br/>     'X': 0.4654795229434967,<br/>     'Y': 0.13559915125370026},<br/>    {'Type': 'rightEyeBrowLeft',<br/>     'X': 0.5008187890052795,<br/>     'Y': 0.1317606270313263},<br/>    {'Type': 'rightEyeBrowRight',<br/>     'X': 0.5342025756835938,<br/>     'Y': 0.1317359358072281},<br/>    {'Type': 'rightEyeBrowUp',<br/>     'X': 0.5151524543762207,<br/>     'Y': 0.12679456174373627},<br/>    {'Type': 'leftEyeLeft', 'X': 0.4674917757511139, 'Y': 0.15510375797748566},<br/>    {'Type': 'leftEyeRight',<br/>     'X': 0.4817998707294464,<br/>     'Y': 0.15343616902828217},<br/>    {'Type': 'leftEyeUp', 'X': 0.47253310680389404, 'Y': 0.1514900177717209},<br/>    {'Type': 'leftEyeDown',<br/>     'X': 0.47370508313179016,<br/>     'Y': 0.15651680529117584},<br/>    {'Type': 'rightEyeLeft',<br/>     'X': 0.5069678425788879,<br/>     'Y': 0.14930757880210876},<br/>    {'Type': 'rightEyeRight',<br/>     'X': 0.5239912867546082,<br/>     'Y': 0.1460886150598526},<br/>    {'Type': 'rightEyeUp', 'X': 0.5144344568252563, 'Y': 0.1447771191596985},<br/>    {'Type': 'rightEyeDown',<br/>     'X': 0.5150220394134521,<br/>     'Y': 0.14997448027133942},<br/>    {'Type': 'noseLeft', 'X': 0.4858757555484772, 'Y': 0.18927086889743805},<br/>    {'Type': 'noseRight', 'X': 0.5023624897003174, 'Y': 0.1855706423521042},<br/>    {'Type': 'mouthUp', 'X': 0.4945952594280243, 'Y': 0.2002507448196411},<br/>    {'Type': 'mouthDown', 'X': 0.4980264902114868, 'Y': 0.21687346696853638},<br/>    {'Type': 'leftPupil', 'X': 0.47338899970054626, 'Y': 0.15436244010925293},<br/>    {'Type': 'rightPupil', 'X': 0.5152773261070251, 'Y': 0.1474122554063797},<br/>    {'Type': 'upperJawlineLeft',<br/>     'X': 0.46607205271720886,<br/>     'Y': 0.15965013206005096},<br/>    {'Type': 'midJawlineLeft',<br/>     'X': 0.47901660203933716,<br/>     'Y': 0.21797965466976166},<br/>    {'Type': 'chinBottom', 'X': 0.5062429904937744, 'Y': 0.24532964825630188},<br/>    {'Type': 'midJawlineRight',<br/>     'X': 0.5554487109184265,<br/>     'Y': 0.20579127967357635},<br/>    {'Type': 'upperJawlineRight',<br/>     'X': 0.561174750328064,<br/>     'Y': 0.14439250528812408}],<br/>   'MouthOpen': {'Confidence': 99.0997543334961, 'Value': True},<br/>   'Mustache': {'Confidence': 99.99714660644531, 'Value': False},<br/>   'Pose': {'Pitch': 1.8594770431518555,<br/>    'Roll': -11.335309982299805,<br/>    'Yaw': -33.68760681152344},<br/>   'Quality': {'Brightness': 89.57070922851562,<br/>    'Sharpness': 86.86019134521484},<br/>   'Smile': {'Confidence': 99.23001861572266, 'Value': False},<br/>   'Sunglasses': {'Confidence': 99.99723815917969, 'Value': False}}],<br/> 'ResponseMetadata': {'HTTPHeaders': {'connection': 'keep-alive',<br/>   'content-length': '3297',<br/>   'content-type': 'application/x-amz-json-1.1',<br/>   'date': 'Sun, 19 May 2019 08:45:56 GMT',<br/>   'x-amzn-requestid': '824f5dc3-7a12-11e9-a384-dfb84e388b7e'},<br/>  'HTTPStatusCode': 200,<br/>  'RequestId': '824f5dc3-7a12-11e9-a384-dfb84e388b7e',<br/>  'RetryAttempts': 0}}</span></pre><p id="cf87" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">从上面 detect_faces 调用的示例响应中可以看出，它不仅具有图片中人脸位置的包围盒信息，还具有更高级的特征，如情绪、性别、年龄范围等。</p><h1 id="5d68" class="mh mi iq bd mj mk ml mm mn mo mp mq mr jw ms jx mt jz mu ka mv kc mw kd mx my bi translated">比较面孔</h1><p id="9596" class="pw-post-body-paragraph kw kx iq ky b kz mz jr lb lc na ju le lf nb lh li lj nc ll lm ln nd lp lq lr ij bi translated">有了 Amazon Rekognition，你可以对比两张图片中的人脸。例如，如果我将一张周子瑜的图片设置为我的源图片，然后发送一张两倍于我的目标图片的集体照，Rekognition 会在目标图片中找到与源图片最相似的人脸。下面是我将使用的两次集体照。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nr"><img src="../Images/69a9c47681fb8ba054f201cc013fc498.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*zfk5oXhorAL45Irg3eXg3Q.jpeg"/></div></div></figure><p id="aa4f" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">即使对人类来说也可能很难，尤其是如果你不是亚洲人(或者不是 Twice 粉丝)。你可以猜猜照片中的周子瑜是谁。作为一个韩国人，同时也是两次粉丝，我知道答案，但让我们看看 Rekognition 能从这张照片中找到周子瑜有多好。</p><pre class="kg kh ki kj gt nf ng nh ni aw nj bi"><span id="d729" class="nk mi iq ng b gy nl nm l nn no">sourceFile='Tzuyu.jpeg'<br/>targetFile='twice_group.jpg'<br/>   <br/>imageSource=open(sourceFile,'rb')<br/>imageTarget=open(targetFile,'rb')</span><span id="37f5" class="nk mi iq ng b gy np nm l nn no">response = rekognition.compare_faces(SimilarityThreshold=80,<br/>                              SourceImage={'Bytes': imageSource.read()},<br/>                              TargetImage={'Bytes': imageTarget.read()})<br/>response['FaceMatches']</span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ns"><img src="../Images/455337d8cd0cd6601e33e46bfeef2135.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*w8qBnkBn-3eF8hAqTkO9Cg.png"/></div></div></figure><p id="8fe3" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">上面 compare_faces 的响应还会输出组图中所有不匹配人脸的信息，这可能会变得相当长，所以我只是输出 Rekognition 通过指定 response['FaceMatches']找到的匹配。看起来像是从一组照片中找到了一张相似度在 97%左右的匹配脸。有了边界框信息，让我们检查 Rekognition 指的是周子瑜的哪张脸。</p><p id="45e2" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">顺便说一下，BoundingBox 部分中的值是整个图像大小的比率。因此，为了用 BoundingBox 中的值绘制方框，需要通过乘以实际图像高度或宽度的比率来计算方框中每个点的位置。您可以在下面的代码片段中找到如何做到这一点。</p><pre class="kg kh ki kj gt nf ng nh ni aw nj bi"><span id="aeab" class="nk mi iq ng b gy nl nm l nn no">from PIL import ImageDraw</span><span id="90d5" class="nk mi iq ng b gy np nm l nn no">image = Image.open("twice_group.jpg")<br/>imgWidth,imgHeight  = image.size  <br/>draw = ImageDraw.Draw(image)<br/>box = response['FaceMatches'][0]['Face']['BoundingBox']<br/>left = imgWidth * box['Left']<br/>top = imgHeight * box['Top']<br/>width = imgWidth * box['Width']<br/>height = imgHeight * box['Height']<br/>points = (<br/>            (left,top),<br/>            (left + width, top),<br/>            (left + width, top + height),<br/>            (left , top + height),<br/>            (left, top)</span><span id="4b51" class="nk mi iq ng b gy np nm l nn no">)<br/>draw.line(points, fill='#00d400', width=2)</span><span id="6479" class="nk mi iq ng b gy np nm l nn no">display(image)</span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nt"><img src="../Images/66d6aa96e531735741768b99895a7d14.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ZapgBSv_5t_ocImCUBxbjg.png"/></div></div></figure><p id="eeba" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">是啊！干得好，雷科尼提翁！那确实是周子瑜！</p><h1 id="e854" class="mh mi iq bd mj mk ml mm mn mo mp mq mr jw ms jx mt jz mu ka mv kc mw kd mx my bi translated">正在创建收藏</h1><p id="6413" class="pw-post-body-paragraph kw kx iq ky b kz mz jr lb lc na ju le lf nb lh li lj nc ll lm ln nd lp lq lr ij bi translated">现在我们可以从一张图片中检测人脸，从目标图片中找到与源图片最相似的人脸。但是，这些都是一次性调用，我们需要更多的东西来存储每个成员的脸和他们的名字的信息，以便当我们发送两次新的图片时，它可以检索数据并检测每个成员的脸并显示他们的名字。为了实现这一点，我们需要使用亚马逊所谓的“<a class="ae kv" href="https://docs.aws.amazon.com/rekognition/latest/dg/how-it-works-storage-non-storage.html" rel="noopener ugc nofollow" target="_blank">基于存储的 API 操作</a>”。这种类型的操作有两个亚马逊特有的术语。“集合”是一个虚拟空间，Rekognition 在其中存储有关检测到的人脸的信息。使用集合，我们可以“索引”人脸，这意味着检测图像中的人脸，然后将信息存储在指定的集合中。重要的是，Rekognition 存储在集合中的信息不是实际的图像，而是由 Rekognition 的算法提取的特征向量。让我们看看如何创建一个集合并添加索引。</p><pre class="kg kh ki kj gt nf ng nh ni aw nj bi"><span id="d405" class="nk mi iq ng b gy nl nm l nn no">collectionId='test-collection'<br/>rekognition.create_collection(CollectionId=collectionId)</span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nu"><img src="../Images/a9dc0c60a81c3f61b25d989e1bef33c8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*QSXVA_ttZ0moUDm5hFO3Vg.png"/></div></div></figure><p id="e6d5" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">是的。就这么简单。由于这是我们刚刚创建的新集合，因此集合中没有存储任何信息。但是，让我们仔细检查一下。</p><pre class="kg kh ki kj gt nf ng nh ni aw nj bi"><span id="c0d6" class="nk mi iq ng b gy nl nm l nn no">rekognition.describe_collection(CollectionId=collectionId)</span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nv"><img src="../Images/99d7c66ddc3e68f93531a6c8f86c6b37.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*EQZXHoptQcVWTnTd4lp4Hg.png"/></div></div></figure><p id="9a70" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在上面的响应中，您可以看到“FaceCount”为 0。如果我们索引任何人脸并将该信息存储在集合中，这种情况将会改变。</p><h1 id="e968" class="mh mi iq bd mj mk ml mm mn mo mp mq mr jw ms jx mt jz mu ka mv kc mw kd mx my bi translated">索引面</h1><p id="6500" class="pw-post-body-paragraph kw kx iq ky b kz mz jr lb lc na ju le lf nb lh li lj nc ll lm ln nd lp lq lr ij bi translated">使用 Rekognition 为人脸建立索引同样简单，只需一行代码。</p><pre class="kg kh ki kj gt nf ng nh ni aw nj bi"><span id="df96" class="nk mi iq ng b gy nl nm l nn no">sourceFile='Tzuyu.jpeg'   <br/>imageSource=open(sourceFile,'rb')</span><span id="0c97" class="nk mi iq ng b gy np nm l nn no">rekognition.index_faces(Image={'Bytes':imageSource.read()},ExternalImageId='Tzuyu',CollectionId=collectionId)</span></pre><p id="5177" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">从上面的代码，你可以看到我正在传递 ExternalImageId 参数，并给它的值字符串“周子瑜”。稍后，当我们试图从一张新照片中识别周子瑜时，Rekognition 将搜索与任何索引人脸相匹配的人脸。正如您将在后面看到的，当索引一个面时，Rekognition 会给它一个唯一的面 ID。但是，当在新图片中找到匹配的人脸时，我想显示“周子瑜”这个名字。为此，我使用 ExternalImageId。现在，如果我们检查我们的集合，我们可以看到 1 张脸被添加到集合中。</p><pre class="kg kh ki kj gt nf ng nh ni aw nj bi"><span id="60ed" class="nk mi iq ng b gy nl nm l nn no">rekognition.describe_collection(CollectionId=collectionId)</span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nw"><img src="../Images/513d15ce11536328461398ba76d37da2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*rtriKF7p0SkgJwwjVD05Og.png"/></div></div></figure><h1 id="de16" class="mh mi iq bd mj mk ml mm mn mo mp mq mr jw ms jx mt jz mu ka mv kc mw kd mx my bi translated">通过图像搜索面孔</h1><p id="61ca" class="pw-post-body-paragraph kw kx iq ky b kz mz jr lb lc na ju le lf nb lh li lj nc ll lm ln nd lp lq lr ij bi translated">现在，随着周子瑜的脸在我们的集合中被编入索引，我们可以向 Rekognition 发送一张新的看不见的照片，并找到匹配的脸。但是 search_faces_by_image 函数的一个问题是只能检测一张脸(图像中最大的)。因此，如果我们想发送两次的团体照片，并从那里找到周子瑜，我们将需要做一个额外的步骤。下面我们先用 detect_faces 检测图片中的所有人脸，然后有了每个人脸的包围盒信息，我们再逐个调用 search_faces_by_image。首先让我们检测每张脸。</p><pre class="kg kh ki kj gt nf ng nh ni aw nj bi"><span id="8c09" class="nk mi iq ng b gy nl nm l nn no">imageSource=open('twice_group.jpg','rb')<br/>resp = rekognition.detect_faces(Image={'Bytes':imageSource.read()})<br/>all_faces = resp['FaceDetails']<br/>len(all_faces)</span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nx"><img src="../Images/959ed0185d3f03317f3ffa24d32bf56a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Qm41r8lZhltXzBKk2oFuMQ.png"/></div></div></figure><p id="0998" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">Rekognition 从群组图片中检测到 9 张人脸。很好。现在让我们裁剪每个面，并逐个调用 serach_faces_by_image。</p><pre class="kg kh ki kj gt nf ng nh ni aw nj bi"><span id="7512" class="nk mi iq ng b gy nl nm l nn no">image = Image.open("twice_group.jpg")<br/>image_width,image_height  = image.size</span><span id="d100" class="nk mi iq ng b gy np nm l nn no">for face in all_faces:<br/>    box=face['BoundingBox']<br/>    x1 = box['Left'] * image_width<br/>    y1 = box['Top'] * image_height<br/>    x2 = x1 + box['Width'] * image_width<br/>    y2 = y1 + box['Height']  * image_height<br/>    image_crop = image.crop((x1,y1,x2,y2))<br/>    <br/>    stream = io.BytesIO()<br/>    image_crop.save(stream,format="JPEG")<br/>    image_crop_binary = stream.getvalue()</span><span id="1604" class="nk mi iq ng b gy np nm l nn no">response = rekognition.search_faces_by_image(<br/>            CollectionId=collectionId,<br/>            Image={'Bytes':image_crop_binary}                                       <br/>            )<br/>    print(response)<br/>    print('-'*100)</span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ny"><img src="../Images/ffe30ee9bff800bc2c28350847436922.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*lYvChfNzn-N6oU8AS05C9w.png"/></div></div></figure><p id="5edc" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在我们进行的 9 次 search_faces_by_image 调用中，Rekognition 找到了一个与我们的集合中的索引人脸相匹配的人脸。我们只索引了周子瑜的一张脸，所以它从组图中找到的是周子瑜的脸。让我们用边界框和名称在图像上显示它。对于名称部分，我们将使用我们在索引面部时设置的 ExternalImageId。顺便说一下，从 search_faces_by_image 响应来看，‘face matches’部分是一个数组，如果从集合中找到多个匹配，那么它会显示所有匹配。根据 Amazon 的说法，这个数组是按照相似性得分排序的，相似性最高的排在最前面。我们将通过指定数组的第一项来获得最高分的匹配。</p><pre class="kg kh ki kj gt nf ng nh ni aw nj bi"><span id="7923" class="nk mi iq ng b gy nl nm l nn no">from PIL import ImageFont<br/>import io</span><span id="6d1b" class="nk mi iq ng b gy np nm l nn no">image = Image.open("twice_group.jpg")<br/>image_width,image_height  = image.size <br/>   <br/>for face in all_faces:<br/>    box=face['BoundingBox']<br/>    x1 = box['Left'] * image_width<br/>    y1 = box['Top'] * image_height<br/>    x2 = x1 + box['Width'] * image_width<br/>    y2 = y1 + box['Height']  * image_height<br/>    image_crop = image.crop((x1,y1,x2,y2))<br/>    <br/>    stream = io.BytesIO()<br/>    image_crop.save(stream,format="JPEG")<br/>    image_crop_binary = stream.getvalue()</span><span id="7c9b" class="nk mi iq ng b gy np nm l nn no">response = rekognition.search_faces_by_image(<br/>            CollectionId=collectionId,<br/>            Image={'Bytes':image_crop_binary}                                       <br/>            )<br/>    <br/>    if len(response['FaceMatches']) &gt; 0:<br/>        draw = ImageDraw.Draw(image)<br/>        points = (<br/>                    (x1,y1),<br/>                    (x2, y1),<br/>                    (x2, y2),<br/>                    (x1 , y2),<br/>                    (x1, y1)</span><span id="b4e3" class="nk mi iq ng b gy np nm l nn no">)<br/>        draw.line(points, fill='#00d400', width=2)<br/>        fnt = ImageFont.truetype('/Library/Fonts/Arial.ttf', 15)<br/>        draw.text((x1,y2),response['FaceMatches'][0]['Face']['ExternalImageId'], font=fnt, fill=(255, 255, 0))<br/>        display(image)</span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nz"><img src="../Images/f8bd9c4cf774e95b6b0c8ea58288e672.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*P4svkyRpaY3WWziLY1M25Q.png"/></div></div></figure><p id="a9e2" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">万岁！又是正确答案！</p><h1 id="7a7d" class="mh mi iq bd mj mk ml mm mn mo mp mq mr jw ms jx mt jz mu ka mv kc mw kd mx my bi translated">两次识别所有组成员</h1><p id="ad94" class="pw-post-body-paragraph kw kx iq ky b kz mz jr lb lc na ju le lf nb lh li lj nc ll lm ln nd lp lq lr ij bi translated">现在，让我们扩展项目，从组图片中识别所有成员。为了做到这一点，我们首先需要索引所有成员的脸(有 9 个成员)。我为每个成员准备了 4 张照片。我按照 Christian Petters 写的<a class="ae kv" href="https://aws.amazon.com/blogs/machine-learning/build-your-own-face-recognition-service-using-amazon-rekognition/" rel="noopener ugc nofollow" target="_blank">亚马逊教程</a>的逻辑添加了同一个人的多张图片。根据 Petters 的说法，“为每个人添加多个参考图像大大提高了一个人的潜在匹配率”，这具有直观的意义。从我将在最后分享的 Github 链接中，你会找到这个项目中使用的所有图片。</p><pre class="kg kh ki kj gt nf ng nh ni aw nj bi"><span id="f13e" class="nk mi iq ng b gy nl nm l nn no">collectionId='twice'<br/>rekognition.create_collection(CollectionId=collectionId)</span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi oa"><img src="../Images/171f8e8819e22620cb6925f34edf7e7e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*OhmtahAkQypKC5njUd9fCA.png"/></div></div></figure><pre class="kg kh ki kj gt nf ng nh ni aw nj bi"><span id="7761" class="nk mi iq ng b gy nl nm l nn no">import os</span><span id="da89" class="nk mi iq ng b gy np nm l nn no">path = 'Twice'</span><span id="fa1b" class="nk mi iq ng b gy np nm l nn no">for r, d, f in os.walk(path):<br/>    for file in f:<br/>        if file != '.DS_Store':<br/>            sourceFile = os.path.join(r,file)<br/>            imageSource=open(sourceFile,'rb')<br/>            rekognition.index_faces(Image={'Bytes':imageSource.read()},ExternalImageId=file.split('_')[0],CollectionId=collectionId)<br/>rekognition.describe_collection(CollectionId=collectionId)</span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi oa"><img src="../Images/171f8e8819e22620cb6925f34edf7e7e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*OhmtahAkQypKC5njUd9fCA.png"/></div></div></figure><p id="7e7c" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">好的。似乎所有 36 张照片都被编入了我们的“两次”收藏。现在是检查最终结果的时候了。可以增强 Rekognition 来识别两次的每个成员吗？</p><pre class="kg kh ki kj gt nf ng nh ni aw nj bi"><span id="c070" class="nk mi iq ng b gy nl nm l nn no">from PIL import ImageFont</span><span id="961e" class="nk mi iq ng b gy np nm l nn no">image = Image.open("twice_group.jpg")<br/>image_width,image_height  = image.size <br/>   <br/>for face in all_faces:<br/>    box=face['BoundingBox']<br/>    x1 = box['Left'] * image_width<br/>    y1 = box['Top'] * image_height<br/>    x2 = x1 + box['Width'] * image_width<br/>    y2 = y1 + box['Height']  * image_height<br/>    image_crop = image.crop((x1,y1,x2,y2))<br/>    <br/>    stream = io.BytesIO()<br/>    image_crop.save(stream,format="JPEG")<br/>    image_crop_binary = stream.getvalue()</span><span id="eeac" class="nk mi iq ng b gy np nm l nn no">response = rekognition.search_faces_by_image(<br/>            CollectionId=collectionId,<br/>            Image={'Bytes':image_crop_binary}                                       <br/>            )<br/>    <br/>    if len(response['FaceMatches']) &gt; 0:<br/>        draw = ImageDraw.Draw(image)<br/>        points = (<br/>                    (x1,y1),<br/>                    (x2, y1),<br/>                    (x2, y2),<br/>                    (x1 , y2),<br/>                    (x1, y1)</span><span id="1c72" class="nk mi iq ng b gy np nm l nn no">)<br/>        draw.line(points, fill='#00d400', width=2)<br/>        fnt = ImageFont.truetype('/Library/Fonts/Arial.ttf', 15)<br/>        draw.text((x1,y2),response['FaceMatches'][0]['Face']['ExternalImageId'], font=fnt, fill=(255, 255, 0))</span><span id="9cde" class="nk mi iq ng b gy np nm l nn no">display(image)</span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ob"><img src="../Images/6b9a6bc34102aef8500c3e0e36cb23cc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*zkhEehguY-Mveieo8Gp7dQ.png"/></div></div></figure><p id="349e" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">是啊！可以的！它正确地识别了所有成员！</p><p id="049a" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">感谢您的阅读。你可以从下面的链接中找到 Jupyter 笔记本和用于这个项目的图片。</p><p id="4ebb" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">https://github.com/tthustla/twice_recognition<a class="ae kv" href="https://github.com/tthustla/twice_recognition" rel="noopener ugc nofollow" target="_blank"/></p></div></div>    
</body>
</html>