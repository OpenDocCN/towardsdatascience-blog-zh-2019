<html>
<head>
<title>Using machine learning to predict Kickstarter success</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用机器学习预测 Kickstarter 的成功</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/using-machine-learning-to-predict-kickstarter-success-e371ab56a743?source=collection_archive---------4-----------------------#2019-04-09">https://towardsdatascience.com/using-machine-learning-to-predict-kickstarter-success-e371ab56a743?source=collection_archive---------4-----------------------#2019-04-09</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="cdad" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">Kickstarter 适合你的项目吗？你如何优化以获得成功？</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/5381da0a40b708268680389748d29124.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Im43-qT3fat1r6DCuewOow.png"/></div></div></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ku"><img src="../Images/017629ac446df4a0b48fcf9d24c3a284.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*vEV9S0MX6ZxEf6vjR7-x4Q.png"/></div></div></figure><h1 id="911d" class="kv kw it bd kx ky kz la lb lc ld le lf jz lg ka lh kc li kd lj kf lk kg ll lm bi translated"><strong class="ak">项目目标</strong></h1><p id="b320" class="pw-post-body-paragraph ln lo it lp b lq lr ju ls lt lu jx lv lw lx ly lz ma mb mc md me mf mg mh mi im bi translated">近年来，个人和小公司创建的项目的融资选择范围大大扩大。除了储蓄、银行贷款、朋友和家人的资助以及其他传统选择，众筹已经成为一种流行且容易获得的替代方式。<a class="ae mj" href="https://www.kickstarter.com/" rel="noopener ugc nofollow" target="_blank"> Kickstarter </a>，成立于 2009 年，是一个特别知名和受欢迎的众筹平台。它有一个全有或全无的资助模式，即一个项目只有在达到其目标金额时才能获得资助；否则，资助者不会给项目提供资金。</p><p id="ffe0" class="pw-post-body-paragraph ln lo it lp b lq mk ju ls lt ml jx lv lw mm ly lz ma mn mc md me mo mg mh mi im bi translated">一个项目的成败取决于各种各样的因素——一般来说，Kickstarter 也是如此。其中一些能够被量化或分类，这允许构建一个模型来尝试预测一个项目是否会成功。这个项目的目的是构建这样一个模型，并更广泛地分析 Kickstarter 项目数据，以帮助潜在的项目创建者评估 Kickstarter 对他们来说是否是一个好的融资选择，以及他们成功的机会有多大。</p><h1 id="d48d" class="kv kw it bd kx ky kz la lb lc ld le lf jz lg ka lh kc li kd lj kf lk kg ll lm bi translated">数据源</h1><p id="d054" class="pw-post-body-paragraph ln lo it lp b lq lr ju ls lt lu jx lv lw lx ly lz ma mb mc md me mf mg mh mi im bi translated">本项目中使用的数据集下载于。csv 格式，来自一个名为<a class="ae mj" href="https://webrobots.io/kickstarter-datasets/" rel="noopener ugc nofollow" target="_blank"> Web Robots </a>的网络抓取网站。该数据集包含 Kickstarter 上托管的所有项目的数据，这些项目是从该公司 2009 年 4 月启动到 2019 年 3 月 14 日的网络搜集之日。该数据集包含 209，222 个项目，尽管其中一些是重复的。</p><h1 id="37de" class="kv kw it bd kx ky kz la lb lc ld le lf jz lg ka lh kc li kd lj kf lk kg ll lm bi translated">清洁和预处理</h1><p id="5309" class="pw-post-body-paragraph ln lo it lp b lq lr ju ls lt lu jx lv lw lx ly lz ma mb mc md me mf mg mh mi im bi translated">为了将数据集转换成适合应用机器学习模型的格式，需要进行大量的清理工作。如果你对<code class="fe mp mq mr ms b">df.isna()</code>和<code class="fe mp mq mr ms b">df.drop()</code>还不够，你可以在我的<a class="ae mj" href="https://github.com/L-Lewis/Kickstarter-success-machine-learning" rel="noopener ugc nofollow" target="_blank"> GitHub 库</a>中查看完整的 Jupyter 笔记本代码。</p><p id="134b" class="pw-post-body-paragraph ln lo it lp b lq mk ju ls lt ml jx lv lw mm ly lz ma mn mc md me mo mg mh mi im bi translated">在删除了重复的和不相关的行(例如，在活动中期取消的项目，或者仍然有效的项目)之后，我得到了一个相当大的数据集，包含 168，979 个项目。</p><p id="4c6f" class="pw-post-body-paragraph ln lo it lp b lq mk ju ls lt ml jx lv lw mm ly lz ma mn mc md me mo mg mh mi im bi translated">保留或计算的列有:</p><ul class=""><li id="1671" class="mt mu it lp b lq mk lt ml lw mv ma mw me mx mi my mz na nb bi translated">项目目标(美元)</li><li id="9b12" class="mt mu it lp b lq nc lt nd lw ne ma nf me ng mi my mz na nb bi translated">活动持续时间——从发布到截止日期的天数</li><li id="403b" class="mt mu it lp b lq nc lt nd lw ne ma nf me ng mi my mz na nb bi translated">从页面创建到项目启动的天数</li><li id="80cf" class="mt mu it lp b lq nc lt nd lw ne ma nf me ng mi my mz na nb bi translated">广告词长度</li><li id="e5a4" class="mt mu it lp b lq nc lt nd lw ne ma nf me ng mi my mz na nb bi translated">名字字长</li><li id="88b3" class="mt mu it lp b lq nc lt nd lw ne ma nf me ng mi my mz na nb bi translated">项目是否突出显示为员工选择(一键编码)</li><li id="6ab4" class="mt mu it lp b lq nc lt nd lw ne ma nf me ng mi my mz na nb bi translated">类别(一键编码)</li><li id="5cf8" class="mt mu it lp b lq nc lt nd lw ne ma nf me ng mi my mz na nb bi translated">国家(一键编码)</li><li id="9733" class="mt mu it lp b lq nc lt nd lw ne ma nf me ng mi my mz na nb bi translated">项目启动的月份(一键编码)</li><li id="73f2" class="mt mu it lp b lq nc lt nd lw ne ma nf me ng mi my mz na nb bi translated">项目截止日期的月份(一次性编码)</li><li id="22cb" class="mt mu it lp b lq nc lt nd lw ne ma nf me ng mi my mz na nb bi translated">项目启动的星期几(一键编码)</li><li id="f1f2" class="mt mu it lp b lq nc lt nd lw ne ma nf me ng mi my mz na nb bi translated">项目截止日期的星期几(一键编码)</li><li id="e842" class="mt mu it lp b lq nc lt nd lw ne ma nf me ng mi my mz na nb bi translated">项目启动的两小时时间窗口(一键编码)</li><li id="cf7b" class="mt mu it lp b lq nc lt nd lw ne ma nf me ng mi my mz na nb bi translated">项目期限的两小时时间窗口(一键编码)</li></ul><p id="617b" class="pw-post-body-paragraph ln lo it lp b lq mk ju ls lt ml jx lv lw mm ly lz ma mn mc md me mo mg mh mi im bi translated">一些功能最初是为了探索性数据分析(EDA)的目的而保留的，但后来为了使用机器学习模型而被放弃了。这些包括与结果相关的特征(例如承诺的金额和支持者的数量)，而不是与项目本身的属性相关的特征(例如类别、目标、活动的长度)。</p><h1 id="66e3" class="kv kw it bd kx ky kz la lb lc ld le lf jz lg ka lh kc li kd lj kf lk kg ll lm bi translated">探索性数据分析</h1><p id="9e90" class="pw-post-body-paragraph ln lo it lp b lq lr ju ls lt lu jx lv lw lx ly lz ma mb mc md me mf mg mh mi im bi translated">现在是精彩的部分。</p><p id="a7e2" class="pw-post-body-paragraph ln lo it lp b lq mk ju ls lt ml jx lv lw mm ly lz ma mn mc md me mo mg mh mi im bi translated">自 2009 年推出以来，Kickstarter 已经大幅增长，特别是在 2014 年，扩张真正开始加速。然而，在这一点上，成功的项目的比例大大降低了，因为站点被大量的项目淹没了。尽管近年来成功率一直在上升，但还是有希望的。</p><blockquote class="nh ni nj"><p id="4d76" class="ln lo nk lp b lq mk ju ls lt ml jx lv nl mm ly lz nm mn mc md nn mo mg mh mi im bi translated"><strong class="lp iu">总体而言，56%的已完成项目(即那些已经完成且未被取消或暂停的项目)是成功的。</strong></p></blockquote><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi no"><img src="../Images/c9b8bc23cdd91b02780ebdb956a4c180.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_iolPaPstJZZjNbxMFucDQ.png"/></div></div><figcaption class="np nq gj gh gi nr ns bd b be z dk">Changes over time in the number of projects launched on Kickstarter</figcaption></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nt"><img src="../Images/53969620766b4f58f11f6094926f5f2f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*6ArYgZ9kQez440v13vCFTw.png"/></div></div><figcaption class="np nq gj gh gi nr ns bd b be z dk">Changes over time in project successes and failures</figcaption></figure><p id="cb9a" class="pw-post-body-paragraph ln lo it lp b lq mk ju ls lt ml jx lv lw mm ly lz ma mn mc md me mo mg mh mi im bi translated">下图显示了成功项目和失败项目在某些特征上的差异。这里的关键要点是:</p><ul class=""><li id="9fc0" class="mt mu it lp b lq mk lt ml lw mv ma mw me mx mi my mz na nb bi translated">不出所料，<strong class="lp iu">成功的项目往往有更小(因此更现实)的目标</strong> —成功项目寻求的金额中位数是失败项目的一半左右(使用中位数是因为资金和目标金额的正偏高)。</li><li id="c2ab" class="mt mu it lp b lq nc lt nd lw ne ma nf me ng mi my mz na nb bi translated">每个项目的承诺金额中位数的差异更令人惊讶。每个成功项目的承诺金额中值明显高于申请金额中值，这表明<strong class="lp iu">达到目标的项目往往会获得更多资金，并变得“资金过剩”</strong>。</li><li id="8f26" class="mt mu it lp b lq nc lt nd lw ne ma nf me ng mi my mz na nb bi translated">与此相关的是，与目标金额相比，失败的公司和成功的公司在承诺金额和支持者数量方面的差异要大得多。可能一旦潜在的资助者看到一个项目看起来会成功，他们就更有可能加入并资助它。</li><li id="41c2" class="mt mu it lp b lq nc lt nd lw ne ma nf me ng mi my mz na nb bi translated">成功的项目活动时间<strong class="lp iu">稍短</strong>，但启动时间稍长(从项目首次在网站上创建时算起)。</li><li id="f43e" class="mt mu it lp b lq nc lt nd lw ne ma nf me ng mi my mz na nb bi translated">大约 20%的成功项目在网站上以员工选择的方式突出显示。在这里提出一种因果关系似乎是合理的，也就是说，被选作员工选择的<strong class="lp iu">项目更有可能继续成功</strong>，只有少数员工选择继续失败。</li></ul><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nu"><img src="../Images/a52a267fd1ad52178b879c5b69212a05.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Da99gT3KygU44_TxtZZwgA.png"/></div></div><figcaption class="np nq gj gh gi nr ns bd b be z dk">Comparison of features between successful and failed projects</figcaption></figure><p id="c5ba" class="pw-post-body-paragraph ln lo it lp b lq mk ju ls lt ml jx lv lw mm ly lz ma mn mc md me mo mg mh mi im bi translated">在项目数量、目标和资金数额、支持者和成功率方面，探讨了各种其他特征。例如，下图显示了不同项目类别之间的差异(也提供了代码)。这里的关键要点是:</p><ul class=""><li id="b1a9" class="mt mu it lp b lq mk lt ml lw mv ma mw me mx mi my mz na nb bi translated">在 Kickstarter 上推出的最佳项目类型是<strong class="lp iu">漫画</strong>(根据成功率、支持人数和承诺金额)、<strong class="lp iu">舞蹈</strong>(成功率和承诺金额)和<strong class="lp iu">游戏</strong>(承诺金额和支持人数)。这可能至少部分是由于它们相对较小的筹资目标——如上所述，目标较小的项目往往更成功。</li><li id="746c" class="mt mu it lp b lq nc lt nd lw ne ma nf me ng mi my mz na nb bi translated">虽然<strong class="lp iu">漫画</strong>和<strong class="lp iu">游戏</strong>往往吸引最多的支持者，但每个支持者往往认捐相对较少。<strong class="lp iu">舞蹈</strong>和<strong class="lp iu">电影&amp;视频</strong>往往吸引最慷慨的资助者。</li><li id="dbea" class="mt mu it lp b lq nc lt nd lw ne ma nf me ng mi my mz na nb bi translated"><strong class="lp iu">技术</strong>项目到目前为止拥有最高的中值目标规模。然而，就实际承诺的中值金额而言，他们在排行榜上垫底。</li><li id="7357" class="mt mu it lp b lq nc lt nd lw ne ma nf me ng mi my mz na nb bi translated">表现最差的类别是<strong class="lp iu">食品</strong>、<strong class="lp iu">新闻</strong>和<strong class="lp iu">科技。</strong></li></ul><pre class="kj kk kl km gt nv ms nw nx aw ny bi"><span id="e016" class="nz kw it ms b gy oa ob l oc od"># Code used to create the graphs below</span><span id="5ffc" class="nz kw it ms b gy oe ob l oc od"># Importing the required libraries<br/>import pandas as pd<br/>import matplotlib.pyplot as plt<br/>from matplotlib import cm<br/>import numpy as np</span><span id="8986" class="nz kw it ms b gy oe ob l oc od"># Creating a dataframe grouped by category with columns for failed and successful<br/>cat_df = pd.get_dummies(df.set_index('category').state).groupby('category').sum()</span><span id="cda1" class="nz kw it ms b gy oe ob l oc od"># Plotting<br/>fig, ((ax1, ax2), (ax3, ax4), (ax5, ax6)) = plt.subplots(3, 2, figsize=(12,12))</span><span id="c929" class="nz kw it ms b gy oe ob l oc od">color = cm.CMRmap(np.linspace(0.1,0.8,df.category.nunique()))</span><span id="25fe" class="nz kw it ms b gy oe ob l oc od">df.groupby('category').category.count().plot(kind='bar', ax=ax1, color=color)<br/>ax1.set_title('Number of projects')<br/>ax1.set_xlabel('')</span><span id="0ac1" class="nz kw it ms b gy oe ob l oc od">df.groupby('category').usd_goal.median().plot(kind='bar', ax=ax2, color=color)<br/>ax2.set_title('Median project goal ($)')<br/>ax2.set_xlabel('')</span><span id="7ca0" class="nz kw it ms b gy oe ob l oc od">df.groupby('category').usd_pledged.median().plot(kind='bar', ax=ax3, color=color)<br/>ax3.set_title('Median pledged per project ($)')<br/>ax3.set_xlabel('')</span><span id="c450" class="nz kw it ms b gy oe ob l oc od">cat_df.div(cat_df.sum(axis=1), axis=0).successful.plot(kind='bar', ax=ax4, color=color) # Normalizes counts across rows<br/>ax4.set_title('Proportion of successful projects')<br/>ax4.set_xlabel('')</span><span id="dffe" class="nz kw it ms b gy oe ob l oc od">df.groupby('category').backers_count.median().plot(kind='bar', ax=ax5, color=color)<br/>ax5.set_title('Median backers per project')<br/>ax5.set_xlabel('')</span><span id="f336" class="nz kw it ms b gy oe ob l oc od">df.groupby('category').pledge_per_backer.median().plot(kind='bar', ax=ax6, color=color)<br/>ax6.set_title('Median pledged per backer ($)')<br/>ax6.set_xlabel('')</span><span id="49e9" class="nz kw it ms b gy oe ob l oc od">fig.subplots_adjust(hspace=0.6)<br/>plt.show()</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nt"><img src="../Images/0e570a527649da7d21ae9d2fe90580f7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*TMDwY4IGztVkO0YuXgvA7w.png"/></div></div><figcaption class="np nq gj gh gi nr ns bd b be z dk">Exploring the ‘category’ feature</figcaption></figure><p id="e4de" class="pw-post-body-paragraph ln lo it lp b lq mk ju ls lt ml jx lv lw mm ly lz ma mn mc md me mo mg mh mi im bi translated">为了空间和视网膜的利益，只有“成功比例”图表将显示在下面的额外功能。同样，要了解更多细节，请随时查看我的<a class="ae mj" href="https://github.com/L-Lewis/Kickstarter-success-machine-learning" rel="noopener ugc nofollow" target="_blank"> GitHub 库</a>。这里的关键要点是:</p><ul class=""><li id="b3e4" class="mt mu it lp b lq mk lt ml lw mv ma mw me mx mi my mz na nb bi translated">香港的成功项目比例更高(它们的支持者人数和资助金额的中位数也更高)。</li><li id="97f7" class="mt mu it lp b lq nc lt nd lw ne ma nf me ng mi my mz na nb bi translated"><strong class="lp iu">周二是启动一个项目的最佳日子</strong>，周末最糟糕(筹集的金额和支持者的数量也是如此)。</li><li id="9f04" class="mt mu it lp b lq nc lt nd lw ne ma nf me ng mi my mz na nb bi translated"><strong class="lp iu">世界标准时间下午 12 点到下午 2 点</strong>是启动项目的最佳时间——这也是支持者人数和资金数额最多的时候。<strong class="lp iu">世界协调时下午 6 点到凌晨 4 点</strong>是最差的发射时间。</li><li id="646c" class="mt mu it lp b lq nc lt nd lw ne ma nf me ng mi my mz na nb bi translated">十月是启动一个项目的最佳月份——它也拥有最多的支持者和资金。七月和十二月是最糟糕的月份。</li></ul><div class="kj kk kl km gt ab cb"><figure class="of kn og oh oi oj ok paragraph-image"><img src="../Images/df194c04a0722d827a7b4c299aa61d3d.png" data-original-src="https://miro.medium.com/v2/resize:fit:886/format:webp/1*1TGJKCObwZVRelNq0aUdRQ.png"/></figure><figure class="of kn ol oh oi oj ok paragraph-image"><img src="../Images/166a832a8c03c733afaf3c5c00747db1.png" data-original-src="https://miro.medium.com/v2/resize:fit:780/format:webp/1*7zqgnbqqZ9euKgckJO6u5A.png"/></figure></div><div class="ab cb"><figure class="of kn om oh oi oj ok paragraph-image"><img src="../Images/4d656c00469460da7fafe6152a31896e.png" data-original-src="https://miro.medium.com/v2/resize:fit:780/format:webp/1*GISfiQ-wg0_W6W4sHfBUnw.png"/></figure><figure class="of kn on oh oi oj ok paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><img src="../Images/db533d07d97bf2190b081543798a43b0.png" data-original-src="https://miro.medium.com/v2/resize:fit:778/format:webp/1*tFizlIDHjb5qGFB0hf4-Xw.png"/></div><figcaption class="np nq gj gh gi nr ns bd b be z dk oo di op oq">Top left: success rates by country. Top right: success rates by the day of the week on which projects were launched. Bottom left: success rates by the time of day at which projects were launched (in UTC/GMT). Bottom right: success rates by the month in which projects were launched.</figcaption></figure></div><h1 id="d7ef" class="kv kw it bd kx ky kz la lb lc ld le lf jz lg ka lh kc li kd lj kf lk kg ll lm bi translated">为机器学习准备数据</h1><p id="39d3" class="pw-post-body-paragraph ln lo it lp b lq lr ju ls lt lu jx lv lw lx ly lz ma mb mc md me mf mg mh mi im bi translated">这个项目的最终目标是创建一个模型，该模型能够以较高的准确度预测一个项目是成功还是失败。</p><p id="9c74" class="pw-post-body-paragraph ln lo it lp b lq mk ju ls lt ml jx lv lw mm ly lz ma mn mc md me mo mg mh mi im bi translated">为了准备机器学习的数据，采取了以下步骤(代码如下):</p><ol class=""><li id="58cf" class="mt mu it lp b lq mk lt ml lw mv ma mw me mx mi or mz na nb bi translated">一次性编码分类变量。</li><li id="f815" class="mt mu it lp b lq nc lt nd lw ne ma nf me ng mi or mz na nb bi translated">将数据分为从属目标变量“y”(在本例中为“状态”，即项目成功或失败)和独立特征“X”。</li><li id="66e9" class="mt mu it lp b lq nc lt nd lw ne ma nf me ng mi or mz na nb bi translated">变换 X 轴上的要素，使其比例相同。对于这个项目，使用 Scikit-learn 的 StandardScaler 将每个特征转换为平均值 0 和标准差 1。</li><li id="a729" class="mt mu it lp b lq nc lt nd lw ne ma nf me ng mi or mz na nb bi translated">数据被分成训练集和测试集，用于模型的稳健评估。</li></ol><pre class="kj kk kl km gt nv ms nw nx aw ny bi"><span id="eea4" class="nz kw it ms b gy oa ob l oc od"># Importing the required libraries<br/>import pandas as pd<br/>from sklearn.preprocessing import StandardScaler<br/>from sklearn.model_selection import train_test_split</span><span id="7301" class="nz kw it ms b gy oe ob l oc od"># 1) Creating dummy variables<br/>df_transformed = pd.get_dummies(df_transformed)</span><span id="9876" class="nz kw it ms b gy oe ob l oc od"># 2) Separating into X and y<br/>X_unscaled = df_transformed.drop('state', axis=1)<br/>y = df_transformed.state</span><span id="5eea" class="nz kw it ms b gy oe ob l oc od"># 3) Transforming the data<br/>scaler = StandardScaler()<br/>X = pd.DataFrame(scaler.fit_transform(X_unscaled), columns=list(X_unscaled.columns))</span><span id="d093" class="nz kw it ms b gy oe ob l oc od"># 4) Splitting into train and test sets<br/>X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.3, random_state=123)</span></pre><p id="2075" class="pw-post-body-paragraph ln lo it lp b lq mk ju ls lt ml jx lv lw mm ly lz ma mn mc md me mo mg mh mi im bi translated">在运行机器学习模型之前，而不是之后，选择一种评估方法是一种很好的做法。选择加权平均 F1 分数。F1 分数计算精确度和召回率之间的调和平均值，并且是一个合适的度量，因为在这种情况下没有对假阳性或假阴性的偏好(两者都同样不好)。将使用加权平均值，因为这些类的大小略有不同，并且我们希望能够预测成功和失败。</p><blockquote class="os"><p id="dcaf" class="ot ou it bd ov ow ox oy oz pa pb mi dk translated">在运行机器学习模型之前，而不是之后，选择一种评估方法是一种很好的做法。</p></blockquote><h1 id="8d05" class="kv kw it bd kx ky kz la lb lc ld le lf jz pc ka lh kc pd kd lj kf pe kg ll lm bi translated">模型 1:标准逻辑回归</h1><p id="079b" class="pw-post-body-paragraph ln lo it lp b lq lr ju ls lt lu jx lv lw lx ly lz ma mb mc md me mf mg mh mi im bi translated">逻辑回归可用作二元分类器，以预测数据点属于两个类别中的哪一个。</p><p id="13fe" class="pw-post-body-paragraph ln lo it lp b lq mk ju ls lt ml jx lv lw mm ly lz ma mn mc md me mo mg mh mi im bi translated">为了创建一个基线模型进行改进，使用默认参数将逻辑回归模型拟合到数据中。</p><pre class="kj kk kl km gt nv ms nw nx aw ny bi"><span id="af20" class="nz kw it ms b gy oa ob l oc od"># Importing the required libraries<br/>from sklearn.linear_model import LogisticRegression<br/>from sklearn.metrics import classification_report</span><span id="ccff" class="nz kw it ms b gy oe ob l oc od"># Fitting a logistic regression model with default parameters<br/>logreg = LogisticRegression()<br/>logreg.fit(X_train,y_train)</span><span id="4daa" class="nz kw it ms b gy oe ob l oc od"># Making predictions<br/>y_hat_train = logreg.predict(X_train)<br/>y_hat_test = logreg.predict(X_test)</span><span id="83ba" class="nz kw it ms b gy oe ob l oc od"># Logistic regression scores<br/>print("Logistic regression score for training set:", round(logreg.score(X_train, y_train),5))<br/>print("Logistic regression score for test set:", round(logreg.score(X_test, y_test),5))<br/>print("\nClassification report:")<br/>print(classification_report(y_test, y_hat_test))</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi pf"><img src="../Images/44be48ef73c91a29377bef9f9a5d61f8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1078/format:webp/1*SmVpN3g3H-wcxfR5Iogmrw.png"/></div><figcaption class="np nq gj gh gi nr ns bd b be z dk">Results of the vanilla linear regression model</figcaption></figure><p id="d088" class="pw-post-body-paragraph ln lo it lp b lq mk ju ls lt ml jx lv lw mm ly lz ma mn mc md me mo mg mh mi im bi translated">还不错。该模型的加权平均 F1 分数为 0.70。现在的目标是提高这个分数。</p><h1 id="f28c" class="kv kw it bd kx ky kz la lb lc ld le lf jz lg ka lh kc li kd lj kf lk kg ll lm bi translated">主成分分析</h1><p id="6a77" class="pw-post-body-paragraph ln lo it lp b lq lr ju ls lt lu jx lv lw lx ly lz ma mb mc md me mf mg mh mi im bi translated">用于初始逻辑回归模型的数据集中有大量的要素(106)。PCA(主成分分析)被用于将其减少到更少数量的成分，这些成分仍然可以解释尽可能多的数据变化。这有助于提高模型拟合度和精确度。</p><p id="45c6" class="pw-post-body-paragraph ln lo it lp b lq mk ju ls lt ml jx lv lw mm ly lz ma mn mc md me mo mg mh mi im bi translated">下图(由下面的代码生成)显示 PCA 中使用的组件数量没有明显的界限。</p><pre class="kj kk kl km gt nv ms nw nx aw ny bi"><span id="2a53" class="nz kw it ms b gy oa ob l oc od"># Importing the required libraries<br/>import matplotlib.pyplot as plt<br/>from sklearn.decomposition import PCA</span><span id="9d87" class="nz kw it ms b gy oe ob l oc od"># Fitting PCA<br/>pca = PCA()<br/>pca.fit_transform(X)<br/>explained_var = np.cumsum(pca.explained_variance_ratio_)</span><span id="c546" class="nz kw it ms b gy oe ob l oc od"># Plotting the amount of variation explained by PCA with different numbers of components<br/>plt.plot(list(range(1, len(explained_var)+1)), explained_var)<br/>plt.title('Amount of variation explained by PCA', fontsize=14)<br/>plt.xlabel('Number of components')<br/>plt.ylabel('Explained variance');</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nt"><img src="../Images/a0a1d680d6a64e8916cf2d21a23a5190.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*xW2oJHT10vZVzppgmHqQzA.png"/></div></div><figcaption class="np nq gj gh gi nr ns bd b be z dk">Plotting the amount of variation in the data explained by PCA using various numbers of components</figcaption></figure><p id="fb49" class="pw-post-body-paragraph ln lo it lp b lq mk ju ls lt ml jx lv lw mm ly lz ma mn mc md me mo mg mh mi im bi translated">发现了以下结果:</p><pre class="kj kk kl km gt nv ms nw nx aw ny bi"><span id="1845" class="nz kw it ms b gy oa ob l oc od">Number of components explaining 80% of variance: 58<br/>Number of components explaining 90% of variance: 70<br/>Number of components explaining 99% of variance: 90</span></pre><p id="fcfc" class="pw-post-body-paragraph ln lo it lp b lq mk ju ls lt ml jx lv lw mm ly lz ma mn mc md me mo mg mh mi im bi translated">为了选择在机器学习模型中使用的组件数量，使用默认参数将这些值中的每一个插入到逻辑回归模型的管道中:</p><pre class="kj kk kl km gt nv ms nw nx aw ny bi"><span id="9684" class="nz kw it ms b gy oa ob l oc od"># Running a for loop to test different values of n_components<br/>n_comps = [58,70,90]<br/>for n in n_comps:<br/> pipe = Pipeline([(‘pca’, PCA(n_components=n)), (‘clf’, LogisticRegression())])<br/> pipe.fit(X_train, y_train)<br/> print(“\nNumber of components:”, n)<br/> print(“Score:”, round(pipe.score(X_test, y_test),5))</span></pre><p id="4ba7" class="pw-post-body-paragraph ln lo it lp b lq mk ju ls lt ml jx lv lw mm ly lz ma mn mc md me mo mg mh mi im bi translated">结果显示，90 个组件的得分最高，尽管差异很小(从 58 个组件改进了约 3%):</p><pre class="kj kk kl km gt nv ms nw nx aw ny bi"><span id="3c05" class="nz kw it ms b gy oa ob l oc od">Number of components: 58<br/>Score: 0.67831</span><span id="f2c6" class="nz kw it ms b gy oe ob l oc od">Number of components: 70<br/>Score: 0.6858</span><span id="b07d" class="nz kw it ms b gy oe ob l oc od">Number of components: 90<br/>Score: 0.70799</span></pre><h1 id="23c3" class="kv kw it bd kx ky kz la lb lc ld le lf jz lg ka lh kc li kd lj kf lk kg ll lm bi translated">模型 2:具有 PCA 和参数优化的逻辑回归</h1><p id="ff92" class="pw-post-body-paragraph ln lo it lp b lq lr ju ls lt lu jx lv lw lx ly lz ma mb mc md me mf mg mh mi im bi translated">逻辑回归模型可以通过优化其参数来进一步改进。GridSearchCV 用于测试多个不同的正则化参数(C 值)、惩罚(l1 或 l2)以及有截距和无截距的模型。</p><pre class="kj kk kl km gt nv ms nw nx aw ny bi"><span id="413e" class="nz kw it ms b gy oa ob l oc od"># Importing the required libraries<br/>from sklearn.model_selection import GridSearchCV</span><span id="c722" class="nz kw it ms b gy oe ob l oc od"># Timing how long the model takes to run<br/>logreg_start = time.time()</span><span id="e159" class="nz kw it ms b gy oe ob l oc od"># Building the pipeline<br/>pipe_logreg = Pipeline([('pca', PCA(n_components=90)),<br/>                    ('clf', LogisticRegression())])</span><span id="bbbf" class="nz kw it ms b gy oe ob l oc od"># Creating the parameters to test<br/>params_logreg = [<br/>    {'clf__penalty': ['l1', 'l2'],<br/>     'clf__fit_intercept': [True, False],<br/>        'clf__C': [0.001, 0.01, 1, 10]<br/>    }<br/>]</span><span id="ae22" class="nz kw it ms b gy oe ob l oc od"># Using GridSearchCV to test multiple different parameters<br/>grid_logreg = GridSearchCV(estimator=pipe_logreg,<br/>                  param_grid=params_logreg,<br/>                  cv=5)</span><span id="b455" class="nz kw it ms b gy oe ob l oc od">grid_logreg.fit(X_train, y_train)</span><span id="9b9c" class="nz kw it ms b gy oe ob l oc od">logreg_end = time.time()</span><span id="f9fd" class="nz kw it ms b gy oe ob l oc od">logreg_best_score = grid_logreg.best_score_<br/>logreg_best_params = grid_logreg.best_params_</span><span id="e942" class="nz kw it ms b gy oe ob l oc od"># Printing the results<br/>print(f"Time taken to run: {round((logreg_end - logreg_start)/60,1)} minutes")<br/>print("Best accuracy:", round(logreg_best_score,2))<br/>print("Best parameters:", logreg_best_params)</span></pre><p id="1313" class="pw-post-body-paragraph ln lo it lp b lq mk ju ls lt ml jx lv lw mm ly lz ma mn mc md me mo mg mh mi im bi translated">结果:</p><pre class="kj kk kl km gt nv ms nw nx aw ny bi"><span id="f6f6" class="nz kw it ms b gy oa ob l oc od">Time taken to run: 48.56 minutes<br/>Best accuracy: 0.71<br/>Best parameters: {‘clf__C’: 10, ‘clf__fit_intercept’: True, ‘clf__penalty’: ‘l2’}</span></pre><p id="ce77" class="pw-post-body-paragraph ln lo it lp b lq mk ju ls lt ml jx lv lw mm ly lz ma mn mc md me mo mg mh mi im bi translated">然后使用最佳参数(根据准确度得分)为逻辑回归模型生成分类报告和混淆矩阵。</p><p id="7a1a" class="pw-post-body-paragraph ln lo it lp b lq mk ju ls lt ml jx lv lw mm ly lz ma mn mc md me mo mg mh mi im bi translated">使用以下函数生成混淆矩阵:</p><pre class="kj kk kl km gt nv ms nw nx aw ny bi"><span id="e88e" class="nz kw it ms b gy oa ob l oc od">def plot_cf(y_true, y_pred, class_names=None, model_name=None):<br/>    """Plots a confusion matrix"""<br/>    cf = confusion_matrix(y_true, y_pred)<br/>    plt.imshow(cf, cmap=plt.cm.Blues)<br/>    plt.grid(b=None)<br/>    if model_name:<br/>        plt.title("Confusion Matrix: {}".format(model_name))<br/>    else:<br/>        plt.title("Confusion Matrix")<br/>    plt.ylabel('True Label')<br/>    plt.xlabel('Predicted Label')<br/>    <br/>    class_names = set(y_true)<br/>    tick_marks = np.arange(len(class_names))<br/>    if class_names:<br/>        plt.xticks(tick_marks, class_names)<br/>        plt.yticks(tick_marks, class_names)<br/>    <br/>    thresh = cf.max() / 2.<br/>    <br/>    for i, j in itertools.product(range(cf.shape[0]), range(cf.shape[1])):<br/>        plt.text(j, i, cf[i, j], horizontalalignment='center', color='white' if cf[i, j] &gt; thresh else 'black')</span><span id="c129" class="nz kw it ms b gy oe ob l oc od">plt.colorbar()</span></pre><p id="05c4" class="pw-post-body-paragraph ln lo it lp b lq mk ju ls lt ml jx lv lw mm ly lz ma mn mc md me mo mg mh mi im bi translated">最佳逻辑回归模型的完整结果如下:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi pg"><img src="../Images/7b7e4d400b1c520be5402d66c1f34dda.png" data-original-src="https://miro.medium.com/v2/resize:fit:1048/format:webp/1*7550I5VIykyexGMUqhahsg.png"/></div><figcaption class="np nq gj gh gi nr ns bd b be z dk">Results of the best logistic regression model</figcaption></figure><p id="d34b" class="pw-post-body-paragraph ln lo it lp b lq mk ju ls lt ml jx lv lw mm ly lz ma mn mc md me mo mg mh mi im bi translated">超参数调整后，模型的准确度得分与使用默认参数的逻辑回归模型相同(加权平均 F1 得分为 0.70)。令人失望。</p><h1 id="2629" class="kv kw it bd kx ky kz la lb lc ld le lf jz lg ka lh kc li kd lj kf lk kg ll lm bi translated">模型 3:随机森林</h1><p id="802e" class="pw-post-body-paragraph ln lo it lp b lq lr ju ls lt lu jx lv lw lx ly lz ma mb mc md me mf mg mh mi im bi translated">接下来，使用随机森林分类器。随机森林算法是一种监督学习算法，可用于分类。它通过构建多个不同的决策树来预测数据点属于哪个类别。</p><p id="00db" class="pw-post-body-paragraph ln lo it lp b lq mk ju ls lt ml jx lv lw mm ly lz ma mn mc md me mo mg mh mi im bi translated">同样，GridSearchCV 用于测试多个不同的超参数，以优化模型。</p><pre class="kj kk kl km gt nv ms nw nx aw ny bi"><span id="f56e" class="nz kw it ms b gy oa ob l oc od"># Importing the required libraries<br/>from sklearn.ensemble import RandomForestClassifier</span><span id="95b2" class="nz kw it ms b gy oe ob l oc od"># Using GridSearchCV to test multiple different parameters<br/>rf_start = time.time()</span><span id="ad5c" class="nz kw it ms b gy oe ob l oc od">pipe_rf = Pipeline([('pca', PCA(n_components=90)),<br/>                    ('clf', RandomForestClassifier())])</span><span id="26f5" class="nz kw it ms b gy oe ob l oc od">params_rf = [ <br/>  {'clf__n_estimators': [100],<br/>   'clf__max_depth': [20, 30, 40],    <br/>   'clf__min_samples_split':[0.001, 0.01]<br/>  }<br/>]</span><span id="bbdf" class="nz kw it ms b gy oe ob l oc od">grid_rf = GridSearchCV(estimator=pipe_rf,<br/>                  param_grid=params_rf,<br/>                  cv=5)</span><span id="69b3" class="nz kw it ms b gy oe ob l oc od">grid_rf.fit(X_train, y_train)</span><span id="3195" class="nz kw it ms b gy oe ob l oc od">rf_end = time.time()</span><span id="18ff" class="nz kw it ms b gy oe ob l oc od">rf_best_score = grid_rf.best_score_<br/>rf_best_params = grid_rf.best_params_</span><span id="5483" class="nz kw it ms b gy oe ob l oc od">print(f"Time taken to run: {round((rf_end - rf_start)/60,1)} minutes")<br/>print("Best accuracy:", round(rf_best_score,2))<br/>print("Best parameters:", rf_best_params)</span></pre><p id="0cae" class="pw-post-body-paragraph ln lo it lp b lq mk ju ls lt ml jx lv lw mm ly lz ma mn mc md me mo mg mh mi im bi translated">结果:</p><pre class="kj kk kl km gt nv ms nw nx aw ny bi"><span id="8dc3" class="nz kw it ms b gy oa ob l oc od">Time taken to run: 72.2 minutes<br/>Best accuracy: 0.7<br/>Best parameters: {'clf__max_depth': 30, 'clf__min_samples_split': 0.001, 'clf__n_estimators': 100}</span></pre><p id="4830" class="pw-post-body-paragraph ln lo it lp b lq mk ju ls lt ml jx lv lw mm ly lz ma mn mc md me mo mg mh mi im bi translated">最佳随机森林模型的完整结果如下:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ph"><img src="../Images/d2f3c69d2ca7c09599c227b44008cf64.png" data-original-src="https://miro.medium.com/v2/resize:fit:1060/format:webp/1*BVAsFMJVB7hVZ-q6OoS28Q.png"/></div><figcaption class="np nq gj gh gi nr ns bd b be z dk">Results of the best Random Forest model</figcaption></figure><p id="3953" class="pw-post-body-paragraph ln lo it lp b lq mk ju ls lt ml jx lv lw mm ly lz ma mn mc md me mo mg mh mi im bi translated">在超参数调整之后，模型的加权平均 F1 分数从具有默认设置的模型的 0.65 增加到 0.69。这类似于逻辑回归模型，尽管比它稍差。此外，训练集和测试集的得分之间的差异表明可能存在一些过度拟合。这里可能有更多的超参数调整空间来进一步改进模型，但是时间不允许。</p><h1 id="724e" class="kv kw it bd kx ky kz la lb lc ld le lf jz lg ka lh kc li kd lj kf lk kg ll lm bi translated">模型 4: XGBoost</h1><p id="8a84" class="pw-post-body-paragraph ln lo it lp b lq lr ju ls lt lu jx lv lw lx ly lz ma mb mc md me mf mg mh mi im bi translated">啊，卡格尔世界的宠儿。XGBoost 现在非常流行。这是一种梯度推进算法。与随机森林类似，它是一种生成多个决策树以改善数据点分类的集成方法，但它使用梯度下降来改善特别难以分类的数据点的模型性能。</p><p id="c6c6" class="pw-post-body-paragraph ln lo it lp b lq mk ju ls lt ml jx lv lw mm ly lz ma mn mc md me mo mg mh mi im bi translated">返回用于超参数测试的 good ol' GridSearchCV:</p><pre class="kj kk kl km gt nv ms nw nx aw ny bi"><span id="a926" class="nz kw it ms b gy oa ob l oc od"># Importing the required libraries<br/>from sklearn.model_selection import GridSearchCV</span><span id="4a6a" class="nz kw it ms b gy oe ob l oc od"># Using GridSearchCV to test multiple different parameters<br/>xgb_start = time.time()</span><span id="7804" class="nz kw it ms b gy oe ob l oc od">pipe_xgb = Pipeline([('pca', PCA(n_components=90)),<br/>                    ('clf', xgb.XGBClassifier())])</span><span id="c8d1" class="nz kw it ms b gy oe ob l oc od">params_xgb = [ <br/>  {'clf__n_estimators': [100],<br/>   'clf__max_depth': [25, 35],<br/>   'clf__learning_rate': [0.01, 0.1],<br/>   'clf__subsample': [0.7, 1],<br/>   'clf__min_child_weight': [20, 100]<br/>  }<br/>]</span><span id="e09b" class="nz kw it ms b gy oe ob l oc od">grid_xgb = GridSearchCV(estimator=pipe_xgb,<br/>                  param_grid=params_xgb,<br/>                  cv=5)</span><span id="b84d" class="nz kw it ms b gy oe ob l oc od">grid_xgb.fit(X_train, y_train)</span><span id="86d0" class="nz kw it ms b gy oe ob l oc od">xgb_end = time.time()</span><span id="701a" class="nz kw it ms b gy oe ob l oc od">xgb_best_score = grid_xgb.best_score_<br/>xgb_best_params = grid_xgb.best_params_</span><span id="dfce" class="nz kw it ms b gy oe ob l oc od">print(f"Time taken to run: {round((xgb_end - xgb_start)/60,1)} minutes")<br/>print("Best accuracy:", round(xgb_best_score,2))<br/>print("Best parameters:", xgb_best_params)</span></pre><p id="af7b" class="pw-post-body-paragraph ln lo it lp b lq mk ju ls lt ml jx lv lw mm ly lz ma mn mc md me mo mg mh mi im bi translated">结果:</p><pre class="kj kk kl km gt nv ms nw nx aw ny bi"><span id="a3eb" class="nz kw it ms b gy oa ob l oc od">Time taken to run: 865.4 minutes<br/>Best accuracy: 0.7<br/>Best parameters: {'clf__learning_rate': 0.1, 'clf__max_depth': 35, 'clf__min_child_weight': 100, 'clf__n_estimators': 100, 'clf__subsample': 0.7}</span></pre><p id="48d9" class="pw-post-body-paragraph ln lo it lp b lq mk ju ls lt ml jx lv lw mm ly lz ma mn mc md me mo mg mh mi im bi translated">呀。14 个半小时，它仍然只能达到与初始回归模型相同的精度(这也仅比使用默认参数运行的 XGBoost 模型提高了 0.01 个精度)。</p><p id="dd3d" class="pw-post-body-paragraph ln lo it lp b lq mk ju ls lt ml jx lv lw mm ly lz ma mn mc md me mo mg mh mi im bi translated">最佳 XGBoost 模型的完整结果如下:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi pi"><img src="../Images/8b0f9fec6acf3a1f1d7c5e101441caeb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1064/format:webp/1*TnrmAZZ65UIxlZZwdTRMeQ.png"/></div><figcaption class="np nq gj gh gi nr ns bd b be z dk">Results of the best XGBoost model</figcaption></figure><p id="afdb" class="pw-post-body-paragraph ln lo it lp b lq mk ju ls lt ml jx lv lw mm ly lz ma mn mc md me mo mg mh mi im bi translated">与随机森林模型一样，训练集和测试集的准确性得分之间的差异表明可能存在一些过度拟合。同样，这里可能有更多的超参数调整空间来进一步改进模型——但是我没有另外 14 个半小时的空闲时间。</p><h1 id="ac59" class="kv kw it bd kx ky kz la lb lc ld le lf jz lg ka lh kc li kd lj kf lk kg ll lm bi translated">模型评估</h1><p id="366b" class="pw-post-body-paragraph ln lo it lp b lq lr ju ls lt lu jx lv lw lx ly lz ma mb mc md me mf mg mh mi im bi translated">在参数调整之后，每个模型能够实现大约<strong class="lp iu"> 70% </strong>的精度。虽然达到这一精度水平相对容易，但参数调整只能少量提高精度水平。可能只有两类中的每一类都有相当大的数据量，这意味着即使是相对简单的模型(如具有默认设置的逻辑回归)也有足够的数据来达到良好的验证准确度。</p><p id="7332" class="pw-post-body-paragraph ln lo it lp b lq mk ju ls lt ml jx lv lw mm ly lz ma mn mc md me mo mg mh mi im bi translated">创建的最佳随机森林和 XGBoost 模型仍然表现出一定程度的过度拟合。需要进一步调整参数来减少这种情况。</p><p id="da1e" class="pw-post-body-paragraph ln lo it lp b lq mk ju ls lt ml jx lv lw mm ly lz ma mn mc md me mo mg mh mi im bi translated">最终选择的模型是调整后的<strong class="lp iu">逻辑回归模型</strong>。这是因为，尽管每个模型都能够为测试集达到相似的精度水平，但这是唯一没有表现出过度拟合的模型。</p><p id="7242" class="pw-post-body-paragraph ln lo it lp b lq mk ju ls lt ml jx lv lw mm ly lz ma mn mc md me mo mg mh mi im bi translated">有趣的是，<strong class="lp iu">与成功相比，每个模型在预测失败方面表现更差</strong>，真实的否定率低于真实的肯定率。也就是说，它将相当多的失败项目归类为成功，而将相对较少的成功项目归类为失败。可能导致项目失败的因素更有可能超出数据的范围，例如营销不善、更新不足或没有回复潜在支持者的消息。</p><p id="6715" class="pw-post-body-paragraph ln lo it lp b lq mk ju ls lt ml jx lv lw mm ly lz ma mn mc md me mo mg mh mi im bi translated">假阳性和假阴性率意味着，如果一个新项目的数据通过模型来预测其成功或失败:</p><ul class=""><li id="d0ae" class="mt mu it lp b lq mk lt ml lw mv ma mw me mx mi my mz na nb bi translated">如果这个项目最终会成功，这个模型将会在大约 80%的情况下正确地预测它会成功</li><li id="ef75" class="mt mu it lp b lq nc lt nd lw ne ma nf me ng mi my mz na nb bi translated">如果项目以失败告终，模型只会在大约 60%的时间里正确地将其预测为失败(而其余的时间会错误地将其预测为成功)</li></ul><h1 id="773a" class="kv kw it bd kx ky kz la lb lc ld le lf jz lg ka lh kc li kd lj kf lk kg ll lm bi translated">对考虑 Kickstarter 的项目创建者的建议</h1><p id="9770" class="pw-post-body-paragraph ln lo it lp b lq lr ju ls lt lu jx lv lw lx ly lz ma mb mc md me mf mg mh mi im bi translated">对成功率和/或收到的资金数量产生<strong class="lp iu">积极影响</strong>的一些因素有:</p><p id="eec2" class="pw-post-body-paragraph ln lo it lp b lq mk ju ls lt ml jx lv lw mm ly lz ma mn mc md me mo mg mh mi im bi translated">最重要的是:</p><ul class=""><li id="8b9e" class="mt mu it lp b lq mk lt ml lw mv ma mw me mx mi my mz na nb bi translated">较小的项目目标</li><li id="a2ed" class="mt mu it lp b lq nc lt nd lw ne ma nf me ng mi my mz na nb bi translated">被选为员工选择(质量的衡量标准)</li><li id="3a29" class="mt mu it lp b lq nc lt nd lw ne ma nf me ng mi my mz na nb bi translated">漫画、舞蹈和游戏项目</li><li id="1c84" class="mt mu it lp b lq nc lt nd lw ne ma nf me ng mi my mz na nb bi translated">来自香港的项目</li></ul><p id="4002" class="pw-post-body-paragraph ln lo it lp b lq mk ju ls lt ml jx lv lw mm ly lz ma mn mc md me mo mg mh mi im bi translated">不太重要:</p><ul class=""><li id="7995" class="mt mu it lp b lq mk lt ml lw mv ma mw me mx mi my mz na nb bi translated">较短的活动</li><li id="708a" class="mt mu it lp b lq nc lt nd lw ne ma nf me ng mi my mz na nb bi translated">从创建到发布需要更长时间</li><li id="7879" class="mt mu it lp b lq nc lt nd lw ne ma nf me ng mi my mz na nb bi translated">电影、视频和音乐项目(网站上的热门类别，相当成功)</li><li id="f44a" class="mt mu it lp b lq nc lt nd lw ne ma nf me ng mi my mz na nb bi translated">周二发布(尽管这也是最常见的项目发布日，所以要小心竞争)</li><li id="8793" class="mt mu it lp b lq nc lt nd lw ne ma nf me ng mi my mz na nb bi translated">10 月发布</li><li id="8e4d" class="mt mu it lp b lq nc lt nd lw ne ma nf me ng mi my mz na nb bi translated">在 UTC 时间下午 12 点到下午 2 点之间发布(这当然与项目发布的国家有关，但请记住，支持者可能来自世界各地)</li></ul><p id="8da1" class="pw-post-body-paragraph ln lo it lp b lq mk ju ls lt ml jx lv lw mm ly lz ma mn mc md me mo mg mh mi im bi translated">对成功率和/或收到的金额有<strong class="lp iu">负面影响</strong>的因素有:</p><p id="e9f9" class="pw-post-body-paragraph ln lo it lp b lq mk ju ls lt ml jx lv lw mm ly lz ma mn mc md me mo mg mh mi im bi translated">最负面:</p><ul class=""><li id="96b5" class="mt mu it lp b lq mk lt ml lw mv ma mw me mx mi my mz na nb bi translated">大目标</li><li id="82b6" class="mt mu it lp b lq nc lt nd lw ne ma nf me ng mi my mz na nb bi translated">食品和新闻项目</li><li id="6b02" class="mt mu it lp b lq nc lt nd lw ne ma nf me ng mi my mz na nb bi translated">来自意大利的项目</li></ul><p id="ca0e" class="pw-post-body-paragraph ln lo it lp b lq mk ju ls lt ml jx lv lw mm ly lz ma mn mc md me mo mg mh mi im bi translated">负面影响较小:</p><ul class=""><li id="3a22" class="mt mu it lp b lq mk lt ml lw mv ma mw me mx mi my mz na nb bi translated">长期活动</li><li id="3675" class="mt mu it lp b lq nc lt nd lw ne ma nf me ng mi my mz na nb bi translated">在周末发布</li><li id="67fd" class="mt mu it lp b lq nc lt nd lw ne ma nf me ng mi my mz na nb bi translated">7 月或 12 月发布</li><li id="bffe" class="mt mu it lp b lq nc lt nd lw ne ma nf me ng mi my mz na nb bi translated">在世界协调时下午 6 点到凌晨 4 点之间发布</li></ul><p id="8f77" class="pw-post-body-paragraph ln lo it lp b lq mk ju ls lt ml jx lv lw mm ly lz ma mn mc md me mo mg mh mi im bi translated">总体而言，Kickstarter 非常适合小型、高质量的项目，尤其是漫画、舞蹈和游戏。它不太适合大型项目，尤其是食品(如餐馆)和新闻项目。</p></div><div class="ab cl pj pk hx pl" role="separator"><span class="pm bw bk pn po pp"/><span class="pm bw bk pn po pp"/><span class="pm bw bk pn po"/></div><div class="im in io ip iq"><p id="c475" class="pw-post-body-paragraph ln lo it lp b lq mk ju ls lt ml jx lv lw mm ly lz ma mn mc md me mo mg mh mi im bi translated">感谢您读到这里！如果您有任何想法、意见或建议，请在下面添加。</p></div></div>    
</body>
</html>