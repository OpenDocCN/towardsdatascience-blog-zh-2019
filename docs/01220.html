<html>
<head>
<title>Demystifying Maths of Gradient Boosting</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">揭开梯度推进数学的神秘面纱</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/demystifying-maths-of-gradient-boosting-bd5715e82b7c?source=collection_archive---------4-----------------------#2019-02-25">https://towardsdatascience.com/demystifying-maths-of-gradient-boosting-bd5715e82b7c?source=collection_archive---------4-----------------------#2019-02-25</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="4baa" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">本文讨论了梯度推进算法数学背后的概念</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/a62ece9469a3d9be999c3051d574423f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Lxa0ioMibcTreJNtKhtNDQ.jpeg"/></div></div></figure><h1 id="e819" class="ku kv it bd kw kx ky kz la lb lc ld le jz lf ka lg kc lh kd li kf lj kg lk ll bi translated">介绍</h1><p id="9f53" class="pw-post-body-paragraph lm ln it lo b lp lq ju lr ls lt jx lu lv lw lx ly lz ma mb mc md me mf mg mh im bi translated">Boosting 是一种集成学习技术。从概念上讲，这些技术包括:<strong class="lo iu"> 1。学习基础学习者；2.使用所有模型得出最终预测</strong>。集成学习技术有不同的类型，并且在它们如何为基础学习者实现学习过程，然后使用它们的输出给出最终结果方面都彼此不同。集成学习中使用的技术是自举聚合(也称为 Bagging)、Boosting、级联模型和堆叠集成模型。在本文中，我们将简要讨论 Bagging，然后继续讨论梯度推进，这是本文的重点。有很多资料解释了梯度推进算法中的步骤。但是，如果你试图找到一个来源，解释每一步真正做了什么，使整个算法工作，你可能会找到使用<em class="mi">平方误差</em>作为例子这样做的文章。这些解释非常好，但问题是它们太关注平方误差，以至于几乎无法传达一个<em class="mi">概括的</em>理念。梯度增强是一种通用模型，适用于任何可微分的损失函数，然而，仅看到它适用于<em class="mi">平方损失模型</em>并不能完全解释它在学习过程中的作用。在本文中，我打算通过一种更通用的方法来解释这个算法。</p><blockquote class="mj mk ml"><p id="4f23" class="lm ln mi lo b lp mm ju lr ls mn jx lu mo mp lx ly mq mr mb mc ms mt mf mg mh im bi translated"><strong class="lo iu">注:</strong>基础模型在文献中也被称为基础学习者。他们是同一个人。然而，我用术语“基础学习者”来表示基础模型，用“模型”来表示由基础学习者构成的函数。</p></blockquote><h1 id="7045" class="ku kv it bd kw kx ky kz la lb lc ld le jz lf ka lg kc lh kd li kf lj kg lk ll bi translated">制袋材料</h1><p id="1125" class="pw-post-body-paragraph lm ln it lo b lp lq ju lr ls lt jx lu lv lw lx ly lz ma mb mc md me mf mg mh im bi translated">装袋是两个后续步骤的结合:</p><p id="308b" class="pw-post-body-paragraph lm ln it lo b lp mm ju lr ls mn jx lu lv mp lx ly lz mr mb mc md mt mf mg mh im bi translated">I .数据集的自举采样，分成<em class="mi"> M 个</em>子集。这些<em class="mi"> M 个</em>子集中的每一个然后被用于学习模型。这些模型被称为基础学习者/模型。</p><p id="26d8" class="pw-post-body-paragraph lm ln it lo b lp mm ju lr ls mn jx lu lv mp lx ly lz mr mb mc md mt mf mg mh im bi translated">二。以多数票宣布最终预测值。</p><p id="c1e2" class="pw-post-body-paragraph lm ln it lo b lp mm ju lr ls mn jx lu lv mp lx ly lz mr mb mc md mt mf mg mh im bi translated">由于在 bagging 中，数据集的子集用于训练基础模型，每个基础学习者都可能过度适应(由于每个模型可学习的例子较少，它们可能不能很好地概括)。采用多数投票给出了一个模型，其方差是所有基础学习者方差的平均值(图 1)。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi mu"><img src="../Images/1ced8e55bffdb68976ac7a8558ed0708.png" data-original-src="https://miro.medium.com/v2/resize:fit:522/0*IbAEe3WKlDoIwX5a"/></div><figcaption class="mv mw gj gh gi mx my bd b be z dk">Fig. 1. Blue curve rerpesents the variance of the final model, all other curves are variances of the base learners (source: <a class="ae mz" href="https://www.quora.com/What-does-Bagging-reduces-the-variance-while-retaining-the-bias-mean" rel="noopener ugc nofollow" target="_blank">https://www.quora.com/What-does-Bagging-reduces-the-variance-while-retaining-the-bias-mean</a>)</figcaption></figure><p id="5faf" class="pw-post-body-paragraph lm ln it lo b lp mm ju lr ls mn jx lu lv mp lx ly lz mr mb mc md mt mf mg mh im bi translated">Boosting 与 Bagging 在训练基础学习者并利用他们给出最终结果的方法上有很大不同。Bagging 从独立引导的数据子集学习基础学习器，因此我们可以在并行环境中同时训练所有的基础学习器。另一方面，Boosting 按顺序训练基础学习者——一个接一个地训练模型。因此，并行培训基础学习者是不可能的。此外，在 Boosting 算法中，我们从高偏置模型开始。实际模型首先用常数值初始化。然后，通过添加基础学习者来逐渐减少偏差。我们将看到梯度推进是如何学习最终模型的，该模型在给定适当数量的基础学习者的情况下具有低得多的偏差。</p><h1 id="de9e" class="ku kv it bd kw kx ky kz la lb lc ld le jz lf ka lg kc lh kd li kf lj kg lk ll bi translated">梯度推进</h1><h2 id="b605" class="na kv it bd kw nb nc dn la nd ne dp le lv nf ng lg lz nh ni li md nj nk lk nl bi translated"><strong class="ak">加法建模的思想:</strong></h2><p id="7a8d" class="pw-post-body-paragraph lm ln it lo b lp lq ju lr ls lt jx lu lv lw lx ly lz ma mb mc md me mf mg mh im bi translated">加法建模是 Boosting 算法的基础。这个想法很简单——通过将一些简单的项相加形成一个复杂的函数。在梯度推进中，一些简单的模型被加在一起以给出一个复杂的最终模型。正如我们将看到的，梯度推进通过对适当数量的基础学习器进行加权求和来学习模型。</p><h2 id="9956" class="na kv it bd kw nb nc dn la nd ne dp le lv nf ng lg lz nh ni li md nj nk lk nl bi translated"><strong class="ak">梯度推进算法</strong></h2><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nm"><img src="../Images/1f4e91f57a27dbe886d2520b998f7a1e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*3iojqS-gGsJ4XI6vajl69A.png"/></div></div><figcaption class="mv mw gj gh gi mx my bd b be z dk">Source: <a class="ae mz" href="https://en.wikipedia.org/wiki/Gradient_boosting" rel="noopener ugc nofollow" target="_blank">https://en.wikipedia.org/wiki/Gradient_boosting</a></figcaption></figure><h2 id="e4e0" class="na kv it bd kw nb nc dn la nd ne dp le lv nf ng lg lz nh ni li md nj nk lk nl bi translated"><strong class="ak">伪残差</strong></h2><p id="691d" class="pw-post-body-paragraph lm ln it lo b lp lq ju lr ls lt jx lu lv lw lx ly lz ma mb mc md me mf mg mh im bi translated">在算法中，步骤 2(1)提到了计算“伪残差”。虽然几乎没有任何具体的伪剩余的概念定义，但是在数学上你如何定义它。不过，我感觉这个名字有点借用了差<em class="mi"> (y_actual - y_predicted) </em>的意思，也就是通常所说的<em class="mi">残差</em>，它是我们以为例，通过对<em class="mi">的预测值<strong class="lo iu"><em class="mi">【x _ I】</em></strong>对平方损失函数<strong class="lo iu"> <em class="mi"> L </em> </strong> w.r.t 进行求导得到的。</em></p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nn"><img src="../Images/4d37b69ac214cb9973704ec4c15c2d54.png" data-original-src="https://miro.medium.com/v2/resize:fit:676/format:webp/1*Hnvlc-hCUdynYUjbEogrjw.png"/></div><figcaption class="mv mw gj gh gi mx my bd b be z dk">Fig.2. Negative of Derivative of squared loss w.r.t. hypothesis function gives the residual for ith example</figcaption></figure><p id="0877" class="pw-post-body-paragraph lm ln it lo b lp mm ju lr ls mn jx lu lv mp lx ly lz mr mb mc md mt mf mg mh im bi translated">在优化问题中，附加到目标函数的常数不会影响最优点，所以如图 2 所示的<em class="mi">‘2’</em>的因子实际上并不重要，可以安全地去掉(仅当我们求解优化时)。可能没有损失函数微分给出残差，然而，在平方损失的情况下，其微分给出最接近<em class="mi">残差“视觉上”</em>的函数。可能这个名字就是借用了这个。尽管如此，<em class="mi">梯度提升与损失函数 w.r.t .假设的导数等于残差无关。</em></p><h2 id="eac1" class="na kv it bd kw nb nc dn la nd ne dp le lv nf ng lg lz nh ni li md nj nk lk nl bi translated"><strong class="ak">算法如何工作</strong></h2><p id="5993" class="pw-post-body-paragraph lm ln it lo b lp lq ju lr ls lt jx lu lv lw lx ly lz ma mb mc md me mf mg mh im bi translated">我们可能已经想到了梯度推进中的一件事——对损失函数和假设函数求导。不用说，损失函数必须相对于假设函数是可微的。正如算法所说，梯度提升将训练集和损失函数作为输入。我们用<strong class="lo iu"> <em class="mi"> F_M(x) </em> </strong>来表示在算法结束时我们将得到的最终模型。</p><blockquote class="mj mk ml"><p id="9678" class="lm ln mi lo b lp mm ju lr ls mn jx lu mo mp lx ly mq mr mb mc ms mt mf mg mh im bi translated"><strong class="lo iu">符号</strong></p></blockquote><p id="1039" class="pw-post-body-paragraph lm ln it lo b lp mm ju lr ls mn jx lu lv mp lx ly lz mr mb mc md mt mf mg mh im bi translated">算法中使用的一些符号取自维基百科(见上文)，有些不一致。所以，我会用我自己的符号来表示这些变量。</p><p id="9c11" class="pw-post-body-paragraph lm ln it lo b lp mm ju lr ls mn jx lu lv mp lx ly lz mr mb mc md mt mf mg mh im bi translated"><em class="mi"> F_M(x) </em>:通过对<em class="mi"> M </em>个基础学习器进行加权求和而学习的最终模型(加法建模)。</p><p id="6a05" class="pw-post-body-paragraph lm ln it lo b lp mm ju lr ls mn jx lu lv mp lx ly lz mr mb mc md mt mf mg mh im bi translated"><em class="mi"> F_m(x) </em>:将<em class="mi"> m (=1，2，…，m) </em>基学习器和<em class="mi"> F_M(x) </em>初始常数值相加得到的模型。</p><blockquote class="mj mk ml"><p id="3910" class="lm ln mi lo b lp mm ju lr ls mn jx lu mo mp lx ly mq mr mb mc ms mt mf mg mh im bi translated"><strong class="lo iu">第一步。</strong>用常数值初始化模型。</p></blockquote><p id="3786" class="pw-post-body-paragraph lm ln it lo b lp mm ju lr ls mn jx lu lv mp lx ly lz mr mb mc md mt mf mg mh im bi translated">我们找到一个常数模型<em class="mi"> F_0 = γ </em>来拟合实际的 y 值。为什么是常数模型？这就是助推的想法开始体现的地方——从高偏差到低偏差模型。我们从一个常数函数开始(没有其他函数比常数函数有更大的偏差，除非数据集非常枯燥，甚至常数模型也适合它)，然后通过许多步骤找到一个偏差相当低的函数。在一些文本中，你可能会发现用<em class="mi"> 0 </em>(零)来初始化模型。这也是一个常量函数，但是我们很可能从一个稍微好一点的选项开始。假设初始模型是一个常数函数<em class="mi"> γ。</em>常量函数的损失函数如下:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi no"><img src="../Images/0ef2c8e4e549304739e6bdf452e61eac.png" data-original-src="https://miro.medium.com/v2/resize:fit:306/format:webp/1*YtQa-pT-P-InaOp-z9ffWg.png"/></div></figure><p id="05cb" class="pw-post-body-paragraph lm ln it lo b lp mm ju lr ls mn jx lu lv mp lx ly lz mr mb mc md mt mf mg mh im bi translated">因此，<em class="mi"> γ_optimal </em>通过求解以下优化问题来确定:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi np"><img src="../Images/809a8e918fd8c19d17eef867b4b6bdf7.png" data-original-src="https://miro.medium.com/v2/resize:fit:798/format:webp/1*s2B0a-4o5KKHGL8Da4m3fg.png"/></div></figure><p id="b400" class="pw-post-body-paragraph lm ln it lo b lp mm ju lr ls mn jx lu lv mp lx ly lz mr mb mc md mt mf mg mh im bi translated">这肯定比用零初始化的模型好。尤其对于平方损失误差，<em class="mi"> F_0(x) </em>等于实际<em class="mi"> y 值</em>的平均值，即<em class="mi"> F_0(x) = y_mean </em>当<em class="mi"> </em>使用平方损失<em class="mi">时。</em></p><p id="9300" class="pw-post-body-paragraph lm ln it lo b lp mm ju lr ls mn jx lu lv mp lx ly lz mr mb mc md mt mf mg mh im bi translated">通常在文本中，该模型不被算作基础学习者之一，尽管最终模型将是从基础学习者获得的<em class="mi">加性模型</em>，并且该模型也将是加数之一。但是有一个不同之处——在文献中被称为基础学习器的所有模型都适合伪残差，而不是实际数据集的<em class="mi"> y 值</em>(我们将在步骤 2 中看到如何实现)。由于<em class="mi"> F_0(x) </em>拟合在<em class="mi"> y 值</em>上，可能这就是为什么它在文献中不被认为是基础学习器之一。</p><p id="068c" class="pw-post-body-paragraph lm ln it lo b lp mm ju lr ls mn jx lu lv mp lx ly lz mr mb mc md mt mf mg mh im bi translated">此时<strong class="lo iu"> <em class="mi"> F_M(x) = F_0(x)。然而，</em> </strong> <em class="mi"> F_M(x)，</em>会被更新，直到所有的<em class="mi"> M </em>基础学习者都以合适的权重被添加到其中。</p><blockquote class="mj mk ml"><p id="9e78" class="lm ln mi lo b lp mm ju lr ls mn jx lu mo mp lx ly mq mr mb mc ms mt mf mg mh im bi translated"><strong class="lo iu">步骤 2: </strong>从 m = 1 到 m=M，每个基础学习者都要遵循该步骤。注意，梯度推进一次添加一个模型，一个接一个。</p></blockquote><p id="96eb" class="pw-post-body-paragraph lm ln it lo b lp mm ju lr ls mn jx lu lv mp lx ly lz mr mb mc md mt mf mg mh im bi translated">在执行之前，必须用超参数<em class="mi"> M(基础学习者数量)</em>的合适值配置梯度增强算法。</p><blockquote class="mj mk ml"><p id="526f" class="lm ln mi lo b lp mm ju lr ls mn jx lu mo mp lx ly mq mr mb mc ms mt mf mg mh im bi translated">第 2.1 步。计算伪残差:</p></blockquote><p id="1fe5" class="pw-post-body-paragraph lm ln it lo b lp mm ju lr ls mn jx lu lv mp lx ly lz mr mb mc md mt mf mg mh im bi translated">使用训练示例为每个<em class="mi">计算伪残差:</em></p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nq"><img src="../Images/4eaa93b52f35f8625434f5f52876768b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1144/format:webp/1*OS_oGwfScS97bi9XtY7SUw.png"/></div></figure><p id="7b4c" class="pw-post-body-paragraph lm ln it lo b lp mm ju lr ls mn jx lu lv mp lx ly lz mr mb mc md mt mf mg mh im bi translated">注意<em class="mi"> F_m-1(x) </em>是将<em class="mi"> m-1 </em>加权基学习器和初始常数函数相加得到的模型。第<em class="mi">个基础学习者</em>还没有添加。与当前基学习器<em class="mi"> m </em>(其<strong class="lo iu">将在步骤 2.2 中被</strong>训练和添加)相对应的<em class="mi">与</em>训练<em class="mi"> </em>示例的每个残差计算<em class="mi"> r_im </em>是对从<em class="mi"> 1 到 m-1 </em> <strong class="lo iu">的基学习器和初始常数函数</strong>的加权和进行的(步骤 1)。回想一下，在步骤 1 之后，<em class="mi"> F_0(x) = </em> γ不包括对应于任何基础学习器的任何项(回想一下，<em class="mi"> F_0(x) </em>在文献中最常不被称为基础学习器。它仅被视为模型的初始值)。</p><p id="ee43" class="pw-post-body-paragraph lm ln it lo b lp mm ju lr ls mn jx lu lv mp lx ly lz mr mb mc md mt mf mg mh im bi translated">此时，我们已经计算了每个训练示例的伪残差值。</p><blockquote class="mj mk ml"><p id="9584" class="lm ln mi lo b lp mm ju lr ls mn jx lu mo mp lx ly mq mr mb mc ms mt mf mg mh im bi translated">步骤 2.2。在伪残差上拟合<strong class="lo iu">基础学习器</strong></p></blockquote><p id="1d16" class="pw-post-body-paragraph lm ln it lo b lp mm ju lr ls mn jx lu lv mp lx ly lz mr mb mc md mt mf mg mh im bi translated">对于这一步，从给定的数据集导出一个新的数据集。数据集<em class="mi"> D_modified </em>的定义如图 3 所示。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nr"><img src="../Images/acce6707bce25c45dd2dea7307ffaa5b.png" data-original-src="https://miro.medium.com/v2/resize:fit:950/format:webp/1*5GrC7HaskULAmbc73o2_Ag.png"/></div><figcaption class="mv mw gj gh gi mx my bd b be z dk">Fig. 3. Modified dataset</figcaption></figure><p id="21fb" class="pw-post-body-paragraph lm ln it lo b lp mm ju lr ls mn jx lu lv mp lx ly lz mr mb mc md mt mf mg mh im bi translated">一个基础学习器<em class="mi"> h_m(x) </em>在这个数据集上被训练和拟合。</p><p id="5d33" class="pw-post-body-paragraph lm ln it lo b lp mm ju lr ls mn jx lu lv mp lx ly lz mr mb mc md mt mf mg mh im bi translated">至此，我们已经具备了确定<em class="mi"> F_m(x) </em>所需的一切。我们是这样做的:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ns"><img src="../Images/97d3955fd26a164b5e996140ff4eae29.png" data-original-src="https://miro.medium.com/v2/resize:fit:934/format:webp/1*3tf3bap74lsDXHZAgzomrQ.png"/></div></figure><p id="2310" class="pw-post-body-paragraph lm ln it lo b lp mm ju lr ls mn jx lu lv mp lx ly lz mr mb mc md mt mf mg mh im bi translated"><strong class="lo iu">为什么这么做有意义？</strong></p><p id="acbd" class="pw-post-body-paragraph lm ln it lo b lp mm ju lr ls mn jx lu lv mp lx ly lz mr mb mc md mt mf mg mh im bi translated">如果我们将它与在<em class="mi">梯度下降</em>(图 4) <em class="mi">中完成的重量增加进行比较，就很容易明白为什么这个等式是有意义的。</em>梯度下降中的重量向损耗<em class="mi"> L </em>减少的方向移动。应该移动多少权重由α(学习速率)决定。类似地，函数<em class="mi"> h_m(x) </em>拟合到损耗变化率<em class="mi">L</em>w . r . t .<em class="mi">F _ m-1(x)</em>。函数<em class="mi"> h_m(x) </em>(期望适当地近似损失 w.r.t. <em class="mi"> F_m-1(x) </em>的导数的行为)代表<em class="mi">损失函数</em>减少 w.r.t. <em class="mi"> F_m-1(x) </em>的方向。γ对应于效用方面的超参数α(两者都决定了应该进行的更新量)。这类似于梯度下降中的权重更新方程，除了γ是可训练的，而α是超参数。我们将在步骤 2.3 中看到γ的最佳值是如何获得的。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nt"><img src="../Images/77cebe902bd261352c5b64616e4c20c3.png" data-original-src="https://miro.medium.com/v2/resize:fit:338/format:webp/1*WXi_GRASVILl02aGZfT74g.png"/></div><figcaption class="mv mw gj gh gi mx my bd b be z dk">Fig. 4. Weight updation in Gradient Descent</figcaption></figure><p id="93e3" class="pw-post-body-paragraph lm ln it lo b lp mm ju lr ls mn jx lu lv mp lx ly lz mr mb mc md mt mf mg mh im bi translated">注意，γ是唯一需要在原始数据集上优化的参数 w . r . t .<em class="mi">F _ m(x)</em>。然而，基础学习者在数据集<em class="mi"> D_modified </em>上学习更多的参数，因为它们是实际的函数，它们被加在一起以给出最终的模型。</p><p id="bdcc" class="pw-post-body-paragraph lm ln it lo b lp mm ju lr ls mn jx lu lv mp lx ly lz mr mb mc md mt mf mg mh im bi translated">此时，我们有一个模型<em class="mi"> F_m(x) </em>，它将在下一步中用于计算<em class="mi"> y_pred </em>值。</p><blockquote class="mj mk ml"><p id="432f" class="lm ln mi lo b lp mm ju lr ls mn jx lu mo mp lx ly mq mr mb mc ms mt mf mg mh im bi translated">第 2.3 步。找到最佳γ</p></blockquote><p id="c073" class="pw-post-body-paragraph lm ln it lo b lp mm ju lr ls mn jx lu lv mp lx ly lz mr mb mc md mt mf mg mh im bi translated">我们将获取原始数据集<em class="mi"> D </em>(图 5) <em class="mi">。</em></p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nu"><img src="../Images/49bd3a2f219abdae528047c217190d92.png" data-original-src="https://miro.medium.com/v2/resize:fit:802/format:webp/1*6mEPIzkxNlktXHFY6pzHJQ.png"/></div><figcaption class="mv mw gj gh gi mx my bd b be z dk">Fig. 5. Original dataset</figcaption></figure><p id="f6d4" class="pw-post-body-paragraph lm ln it lo b lp mm ju lr ls mn jx lu lv mp lx ly lz mr mb mc md mt mf mg mh im bi translated">我们对原始数据集<em class="mi"> D，</em>采用模型<em class="mi"> F_m(x) </em>，然后计算损失<em class="mi">l。</em>注意，该损失是<em class="mi"> γ的函数。</em></p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nv"><img src="../Images/54fc23237f5d432c64a74b664dcbd1a2.png" data-original-src="https://miro.medium.com/v2/resize:fit:378/format:webp/1*8PhIBuDtt-WN0_HzR-AKdg.png"/></div></figure><p id="c67d" class="pw-post-body-paragraph lm ln it lo b lp mm ju lr ls mn jx lu lv mp lx ly lz mr mb mc md mt mf mg mh im bi translated">我们应该找到<em class="mi"> γ_optimum </em>。这可以通过解决以下优化问题来实现，该优化问题使:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nw"><img src="../Images/0a48ce054794b2a7a5a38f5081132c1a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1340/format:webp/1*gVT41gPIynmADLHzHm_0ew.png"/></div></figure><p id="2a49" class="pw-post-body-paragraph lm ln it lo b lp mm ju lr ls mn jx lu lv mp lx ly lz mr mb mc md mt mf mg mh im bi translated">此时我们有了<em class="mi"> γ的最佳值。</em></p><blockquote class="mj mk ml"><p id="b4db" class="lm ln mi lo b lp mm ju lr ls mn jx lu mo mp lx ly mq mr mb mc ms mt mf mg mh im bi translated">第 2.4 步。模型更新</p></blockquote><p id="e883" class="pw-post-body-paragraph lm ln it lo b lp mm ju lr ls mn jx lu lv mp lx ly lz mr mb mc md mt mf mg mh im bi translated">因此，模型<em class="mi"> F_m(x) </em>被获得为:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nx"><img src="../Images/ac6b4d98cf856d7983b9472dc789e6ad.png" data-original-src="https://miro.medium.com/v2/resize:fit:910/format:webp/1*TxGDAKlB344Fcvd5FmkIXQ.png"/></div></figure><p id="ed06" class="pw-post-body-paragraph lm ln it lo b lp mm ju lr ls mn jx lu lv mp lx ly lz mr mb mc md mt mf mg mh im bi translated">在每次迭代数<em class="mi"> m 结束时，F_M(x) </em>被更新为<em class="mi"> F_m(x) </em>的值。</p><p id="14db" class="pw-post-body-paragraph lm ln it lo b lp mm ju lr ls mn jx lu lv mp lx ly lz mr mb mc md mt mf mg mh im bi translated"><strong class="lo iu">步骤三。</strong>对每个基本型号<em class="mi"> m = 1 到 M </em>运行步骤 2。在步骤 2 的<em class="mi"> M </em>次迭代之后，我们得到最终的模型<em class="mi"> F_M(x)。</em></p><h1 id="b093" class="ku kv it bd kw kx ky kz la lb lc ld le jz lf ka lg kc lh kd li kf lj kg lk ll bi translated">为什么叫“梯度推进”？</h1><p id="e936" class="pw-post-body-paragraph lm ln it lo b lp lq ju lr ls lt jx lu lv lw lx ly lz ma mb mc md me mf mg mh im bi translated">我们刚刚看到了“梯度”在这个算法中的作用——我们总是让一个基础学习者适应损失函数 w.r.t .的梯度，模型<em class="mi"> F_m-1(x) </em>。术语“提升”指的是这样一个事实，即一个在数据集上表现非常差的高偏差模型被提升，最终成为一个合理的分类器，并且可能是一个强分类器。一般来说，Boosting 是一个算法家族，其中多个<em class="mi">【弱分类器】</em>(错误率低于 0.5 的一个)基本学习器被组合起来以给出一个强分类器(错误率接近 0 的一个)。在梯度提升中，我们从常数模型开始(根据数据集，它可能是一个非常弱的分类器)。在学习一个基础学习器的第<em class="mi"> m 次</em>迭代结束时，我们得到一个弱学习器，但相对来说是一个更好的分类器<em class="mi"> F_m(x) </em>，它逐渐向强分类器发展。</p><h1 id="d740" class="ku kv it bd kw kx ky kz la lb lc ld le jz lf ka lg kc lh kd li kf lj kg lk ll bi translated">脚注</h1><p id="3478" class="pw-post-body-paragraph lm ln it lo b lp lq ju lr ls lt jx lu lv lw lx ly lz ma mb mc md me mf mg mh im bi translated">希望这篇文章有意义。我的目标不仅仅是写下一个算法，我打算揭开数学的神秘面纱(如标题所示),揭示数学方程之外的东西。因此，如果我没能在任何地方传达数学背后的概念，请发表评论，这将是非常值得的。</p><p id="df35" class="pw-post-body-paragraph lm ln it lo b lp mm ju lr ls mn jx lu lv mp lx ly lz mr mb mc md mt mf mg mh im bi translated">感谢您的阅读！</p></div></div>    
</body>
</html>