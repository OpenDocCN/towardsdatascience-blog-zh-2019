<html>
<head>
<title>Neural Style Transfer Using Tensorflow 2.0</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用 Tensorflow 2.0 进行神经风格转换</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/neural-style-transfer-23a3fb4c6a9e?source=collection_archive---------18-----------------------#2019-04-30">https://towardsdatascience.com/neural-style-transfer-23a3fb4c6a9e?source=collection_archive---------18-----------------------#2019-04-30</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><p id="7481" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">作为将预制的 Tensorflow 代码和算法串在一起的过渡，我通过尝试我在一篇论文中描述的算法的第一个实现，开始了成为一名熟练的 Tensorflow 编码器的旅程。</p><p id="3ae1" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">这个项目是我将深度学习融入学校工作的一种方式。最初的项目是我计算机科学选修课上的一个图像处理项目。该项目的约束包括为图像处理应用程序创建一个功能，该功能将增加应用程序的价值并增加功能。</p><p id="cb6a" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">在了解了这些要求后，我想到了神经类型转移，在 coursera 的 deep learning . ai DL specialization 中为我介绍了这一点。主意已定，我开始研究神经类型转移的数学。知道 Tensorflow 2.0 将会被急切地执行，我决定用它来编程算法，以便于扩大项目规模。</p><p id="bed7" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我的第一步是阅读向研究界介绍 NST 的论文。</p><h2 id="ec68" class="kl km iq bd kn ko kp dn kq kr ks dp kt jy ku kv kw kc kx ky kz kg la lb lc ld bi translated">论文摘要</h2><div class="le lf gp gr lg lh"><a href="https://arxiv.org/abs/1508.06576" rel="noopener  ugc nofollow" target="_blank"><div class="li ab fo"><div class="lj ab lk cl cj ll"><h2 class="bd ir gy z fp lm fr fs ln fu fw ip bi translated">艺术风格的神经算法</h2><div class="lo l"><h3 class="bd b gy z fp lm fr fs ln fu fw dk translated">在美术中，尤其是绘画，人类已经掌握了通过构图创造独特视觉体验的技巧</h3></div><div class="lp l"><p class="bd b dl z fp lm fr fs ln fu fw dk translated">arxiv.org</p></div></div></div></a></div><p id="df77" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">该论文的作者提出了一种算法，通过神经网络将一幅图像的风格转移到另一幅图像的内容上来创建艺术品。</p><p id="2012" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">总的来说，人类非常擅长识别图像的整体风格，那些精通艺术的人甚至可以按照其他更著名的艺术作品的风格来复制艺术作品。本文中介绍的算法试图对人类创作新艺术作品的能力进行建模。</p><p id="b02f" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">使用<a class="ae lq" href="https://arxiv.org/abs/1409.1556" rel="noopener ugc nofollow" target="_blank"> VGG19 </a>预训练权重中中间层的激活从内容和风格图像中提取信息，输出图像被优化以最小化 3 种类型的损失:</p><figure class="ls lt lu lv gt lw gh gi paragraph-image"><div class="gh gi lr"><img src="../Images/6303d7bd616bf2e7dea551cc76a3a268.png" data-original-src="https://miro.medium.com/v2/resize:fit:1276/0*OIqQ1TMApBb-9srk"/></div><figcaption class="lz ma gj gh gi mb mc bd b be z dk"><a class="ae lq" href="https://image.slidesharecdn.com/chainer-meetup-3-160702141033/95/realtime-style-transfer-16-638.jpg?cb=1467468854" rel="noopener ugc nofollow" target="_blank"><em class="md">Source</em></a></figcaption></figure><h2 id="4326" class="kl km iq bd kn ko kp dn kq kr ks dp kt jy ku kv kw kc kx ky kz kg la lb lc ld bi translated"><strong class="ak">内容丢失</strong></h2><p id="9e23" class="pw-post-body-paragraph jn jo iq jp b jq me js jt ju mf jw jx jy mg ka kb kc mh ke kf kg mi ki kj kk ij bi translated">损失函数的这一部分负责控制最终出现在优化输出图像中的内容图像的数量。内容丢失的主要挑战是找出一种方法，只提取图像的内容特征，而不是样式图像。如果内容丢失只是检查输出图像和内容图像之间的距离，那么内容和样式特征都将被转换到输出图像上。这是一个问题，因为我们不想要内容图像的样式，但想要样式图像的样式。</p><p id="6684" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">对此的解决方案是使用卷积神经网络的特征图。受过训练的神经网络学会表现图像的不同部分。作者发现，ConvNet 的初始层代表图像的粗略、基本模式，而后面的层代表更明显的特征。如下所示，ConvNet 的中间层可以在没有样式信息的情况下捕获图像的空间信息，这正是这里所需要的。</p><p id="7734" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">这是这篇论文的主要发现，意味着 ConvNets 能够分离图像的风格和内容特征，并且这些特征可以用于创建图像的复杂组合。</p><figure class="ls lt lu lv gt lw gh gi paragraph-image"><div role="button" tabindex="0" class="mk ml di mm bf mn"><div class="gh gi mj"><img src="../Images/081b17c98c23eed792747ee8a21583bf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*MdUpBqnvnUwjwHavq0QfVw.png"/></div></div><figcaption class="lz ma gj gh gi mb mc bd b be z dk">L. Gatys et Al</figcaption></figure><p id="82e0" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">定义为输出和内容特征映射之间的简单 L2 距离，它迫使优化器合并内容图像的基本内容。</p><h2 id="1bdc" class="kl km iq bd kn ko kp dn kq kr ks dp kt jy ku kv kw kc kx ky kz kg la lb lc ld bi translated"><strong class="ak">风格丧失</strong></h2><p id="5102" class="pw-post-body-paragraph jn jo iq jp b jq me js jt ju mf jw jx jy mg ka kb kc mh ke kf kg mi ki kj kk ij bi translated">风格损失负责将风格图像合并到最终输出中。虽然人类对风格的理解通常基于图像的经验和模糊特征，但本文提出使用 gram 矩阵来表示图像的风格。</p><p id="adfc" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">gram 矩阵是通过计算展平样式特征和它们自身的点积而得到的。</p><p id="1657" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">使用 gram 矩阵是因为图像的风格不依赖于像素值，而是依赖于像素值之间的关系；gram matrix 将关于样式图像的所有信息去本地化，例如纹理、形状和重量:到底什么是样式。</p><p id="1d65" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">为了简化和理解格拉姆矩阵所代表的内容，让我们以两个向量的点积为例。</p><figure class="ls lt lu lv gt lw gh gi paragraph-image"><div class="ab gu cl mo"><img src="../Images/09718c419e48d09e2d29a9e35f15f7a2.png" data-original-src="https://miro.medium.com/v2/format:webp/1*H1UW3bwrhqkRUJ11Xg6gGA.png"/></div><figcaption class="lz ma gj gh gi mb mc bd b be z dk"><a class="ae lq" rel="noopener" target="_blank" href="/neural-networks-intuitions-2-dot-product-gram-matrix-and-neural-style-transfer-5d39653e7916">Source</a></figcaption></figure><p id="45bd" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">点积也可以定义为 a 在 b 轴上的长度乘以 b 的长度。这意味着向量 a 和 b 之间的角度越小，它们之间的点积就越大。因此，两个向量的点积表示它们彼此有多相似。</p><p id="fad8" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">现在，让我们来看看扁平化风格特征中的 2 个特征。它们之间的点积越大，特征之间的相关性越强，点积越小，特征之间的差异越大。也就是说，乘积越小，这两个特征同时出现的次数越少，乘积越大，它们同时出现的次数越多。直观地说，这给出了关于图像的纹理和风格的信息，并丢弃了关于图像的所有空间信息。</p><p id="b7d7" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">一旦计算了 gram 矩阵，就使用相同的 L2 距离来计算输出图像的 gram 矩阵和样式图像的 gram 矩阵之间的差异。</p><h2 id="5c31" class="kl km iq bd kn ko kp dn kq kr ks dp kt jy ku kv kw kc kx ky kz kg la lb lc ld bi translated"><strong class="ak">优化</strong></h2><p id="bdc6" class="pw-post-body-paragraph jn jo iq jp b jq me js jt ju mf jw jx jy mg ka kb kc mh ke kf kg mi ki kj kk ij bi translated">这些损失在随机噪声图像上进行优化，该图像基于总损失的梯度而改变。</p><h1 id="5aa1" class="mp km iq bd kn mq mr ms kq mt mu mv kt mw mx my kw mz na nb kz nc nd ne lc nf bi translated">我的实现</h1><p id="b7c1" class="pw-post-body-paragraph jn jo iq jp b jq me js jt ju mf jw jx jy mg ka kb kc mh ke kf kg mi ki kj kk ij bi translated">我使用了论文中的上述细节来实现我自己的 NST 算法。我对基本算法做了一些修改，以便更容易在 Tensorflow 中实现，并提高输出图像质量。</p><h2 id="ffb4" class="kl km iq bd kn ko kp dn kq kr ks dp kt jy ku kv kw kc kx ky kz kg la lb lc ld bi translated"><strong class="ak">总变差损失</strong></h2><p id="a476" class="pw-post-body-paragraph jn jo iq jp b jq me js jt ju mf jw jx jy mg ka kb kc mh ke kf kg mi ki kj kk ij bi translated">在评估我实现的算法时，我做的第一个改变是减少图像的“颗粒感”。这是因为图像中存在相当多的噪声，并且沿着角落经常有颜色和色调的突然变化。</p><p id="040b" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">在考虑这个问题的解决方案时，我想到总变差是图像中噪声的一个很好的度量，并且它可以很容易地在 tensorflow 中实现。</p><p id="699c" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">事实证明，全变分是张量流中的内置函数。该函数对相邻像素值的绝对差值求和。</p><h2 id="57e4" class="kl km iq bd kn ko kp dn kq kr ks dp kt jy ku kv kw kc kx ky kz kg la lb lc ld bi translated"><strong class="ak">亚当优化器</strong></h2><p id="c9e3" class="pw-post-body-paragraph jn jo iq jp b jq me js jt ju mf jw jx jy mg ka kb kc mh ke kf kg mi ki kj kk ij bi translated">我在实现算法时做的另一个改变是使用亚当优化器代替 L-BFGS。让我们先来看看它们之间的区别。</p><p id="ca9e" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">L-BFGS 算法是估计参数空间曲率的真正的准牛顿方法。如果参数空间有大量的鞍点，这使得它优于 Adam。Adam 优化器是一种一阶方法，试图弥补它不能估计曲率的事实。L-BFGS 算法的缺点是计算量大，而亚当运行速度很快。</p><p id="f61c" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我选择使用 Adam 的主要原因是因为这种计算上的差异。另一个几乎同样重要的原因是，Tensorflow 没有 L-BFGS 实现，只有一种方法来合并 scipy 的优化器。不幸的是，我发现 scipy 的优化器非常慢，所以决定用 Adam 代替。</p><h1 id="80ed" class="mp km iq bd kn mq mr ms kq mt mu mv kt mw mx my kw mz na nb kz nc nd ne lc nf bi translated">密码</h1><p id="d443" class="pw-post-body-paragraph jn jo iq jp b jq me js jt ju mf jw jx jy mg ka kb kc mh ke kf kg mi ki kj kk ij bi translated">我用的是 Tensorflow 2.0，它内置了急切执行功能…</p><h2 id="33bb" class="kl km iq bd kn ko kp dn kq kr ks dp kt jy ku kv kw kc kx ky kz kg la lb lc ld bi translated">个人损失</h2><p id="38dd" class="pw-post-body-paragraph jn jo iq jp b jq me js jt ju mf jw jx jy mg ka kb kc mh ke kf kg mi ki kj kk ij bi translated"><script src="”&lt;a" class="ae lq" href="https://gist.github.com/tekotan/50f7786d4b52b107c1ad78ddd90ebcde.js" rel="noopener ugc nofollow" target="_blank">https://gist . github . com/teko tan/50f 7786 d4b 52 b 107 C1 ad 78 DDD 90 ebc de . js&lt;/a&gt;"&amp;gt;&amp;lt;/script&amp;gt;&lt;/root&gt;</script></p><h2 id="d938" class="kl km iq bd kn ko kp dn kq kr ks dp kt jy ku kv kw kc kx ky kz kg la lb lc ld bi translated">组合损失</h2><p id="2b56" class="pw-post-body-paragraph jn jo iq jp b jq me js jt ju mf jw jx jy mg ka kb kc mh ke kf kg mi ki kj kk ij bi translated">我对每张图片的每组特征图的损失进行了平均。这使我能够在不改变损失权重的情况下，更改用于获取要素地图的 conv 图层数量。</p><p id="5aa4" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><script src="”&lt;a" class="ae lq" href="https://gist.github.com/tekotan/8ceafdaacd0998a5d5ca55ca21bcf1e8.js" rel="noopener ugc nofollow" target="_blank">https://gist . github . com/teko tan/8 ceafdaacd 0998 a5 D5 ca 55 ca 21 bcf1e 8 . js&lt;/a&gt;&amp;gt;&amp;lt;/script&amp;gt;&lt;/root&gt;</script></p><h2 id="a448" class="kl km iq bd kn ko kp dn kq kr ks dp kt jy ku kv kw kc kx ky kz kg la lb lc ld bi translated">计算梯度</h2><p id="d0d4" class="pw-post-body-paragraph jn jo iq jp b jq me js jt ju mf jw jx jy mg ka kb kc mh ke kf kg mi ki kj kk ij bi translated">随着急切执行的增加，tensorflow 增加了一种创建计算图形的方法，通过该图形可以计算梯度。要做到这一点，您可以用 tf 将所有要做的计算包装在一个中。GradientTape()作为磁带结构，然后一旦在“with”之外，你就计算梯度。</p><p id="13a7" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><script src="”&lt;a" class="ae lq" href="https://gist.github.com/tekotan/e2b9f82093186dff6dfd058408a0256e.js" rel="noopener ugc nofollow" target="_blank">https://gist . github . com/teko tan/e2b9f 82093186 dff 6 DFD 058408 a 0256 e . js&lt;/a&gt;"&amp;gt;&amp;lt;/script&amp;gt;&lt;/root&gt;</script></p><h2 id="b6b0" class="kl km iq bd kn ko kp dn kq kr ks dp kt jy ku kv kw kc kx ky kz kg la lb lc ld bi translated">整体优化功能</h2><p id="47a4" class="pw-post-body-paragraph jn jo iq jp b jq me js jt ju mf jw jx jy mg ka kb kc mh ke kf kg mi ki kj kk ij bi translated">整个优化过程从将输出图像初始化为内容图像开始。这是对原始论文的第三次也是最后一次修改。我发现当输出图像作为内容图像开始时，模型会收敛得更快。这是因为该模型不必从随机初始化的图像中从头开始，只需改变内容图像的样式。</p><p id="f945" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><script src="”&lt;a" class="ae lq" href="https://gist.github.com/tekotan/790548c0282bc47989377924804de508.js" rel="noopener ugc nofollow" target="_blank">https://gist . github . com/teko tan/790548 c 0282 BC 47989377924804 de 508 . js&lt;/a&gt;&amp;gt;&amp;lt;/script&amp;gt;&lt;/root&gt;</script></p><h1 id="4cb0" class="mp km iq bd kn mq mr ms kq mt mu mv kt mw mx my kw mz na nb kz nc nd ne lc nf bi translated">结果</h1><p id="acee" class="pw-post-body-paragraph jn jo iq jp b jq me js jt ju mf jw jx jy mg ka kb kc mh ke kf kg mi ki kj kk ij bi translated">在对许多不同的图像和样式运行 NST 后，我发现具有统一和清晰样式的样式图像很容易被转换到内容图像上，并且具有清晰和明确的边缘和线条的内容图像也很容易被转换。</p><figure class="ls lt lu lv gt lw gh gi paragraph-image"><div role="button" tabindex="0" class="mk ml di mm bf mn"><div class="gh gi ng"><img src="../Images/f412f1437d50e68802ada82cea7f1b8c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*Qe0ZdEQapPdPmhCN"/></div></div></figure><figure class="ls lt lu lv gt lw gh gi paragraph-image"><div role="button" tabindex="0" class="mk ml di mm bf mn"><div class="gh gi nh"><img src="../Images/eaad099ec2aed99a28b97dc5fe5c053b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*Th7rNbDlnShANwA6"/></div></div></figure><figure class="ls lt lu lv gt lw gh gi paragraph-image"><div role="button" tabindex="0" class="mk ml di mm bf mn"><div class="gh gi ni"><img src="../Images/f15a2764f25685c41abb61f3c378823a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*URxuDORjX336KN7H"/></div></div></figure><figure class="ls lt lu lv gt lw gh gi paragraph-image"><div role="button" tabindex="0" class="mk ml di mm bf mn"><div class="gh gi nj"><img src="../Images/5255f4f52fbdc759742a923ff1bbd377.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*ExN3IO-wAPesKnJS"/></div></div></figure><p id="79f6" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">正如你所看到的，大部分的风格都转换得干净而准确。不太吸引人的图像的重复出现的模式是样式图像的样式不是很明确。</p><p id="8208" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">此外，出于时间考虑，所有图像的尺寸都调整为 512x512 像素。这也是为什么由于图像上的插值伪影，一些样式没有被完美地翻译。</p><p id="e866" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">产生的最佳图像是在没有对原始图像进行任何尺寸调整和任何更改的情况下创建的。</p><figure class="ls lt lu lv gt lw gh gi paragraph-image"><div role="button" tabindex="0" class="mk ml di mm bf mn"><div class="gh gi nk"><img src="../Images/0b2985f580a8045703cd64be97b20da1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Ne9Cx2Xz35o_J9o1RQEMww.png"/></div></div></figure><p id="d837" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">如上图所示，神奈川外巨浪的风格与图宾根内卡锋面的图片完美融合，产生了高分辨率和美丽的边缘和边界的图像。图像的内容保持清晰，而风格却完全和根本不同。</p><h1 id="08bd" class="mp km iq bd kn mq mr ms kq mt mu mv kt mw mx my kw mz na nb kz nc nd ne lc nf bi translated">结论/想法</h1><p id="9053" class="pw-post-body-paragraph jn jo iq jp b jq me js jt ju mf jw jx jy mg ka kb kc mh ke kf kg mi ki kj kk ij bi translated">这是一个很好的例子，说明了神经网络的代表性力量，以及看似神秘的层和算法是如何产生这种美感的。nst 算法证明了神经网络与我们自己对这个世界的理解是多么相似。</p><p id="9008" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我的信念是，如果对其他神经网络，如 RNNs 和 GANs，有了这样一个完整的理解，一些更不可思议的事情将成为可能。我觉得在课程和教程中，对神经网络的理解和获得直觉是不够强调的，这导致了在神经网络层周围形成了一个看似“黑箱”的东西。</p><p id="749e" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">由于这个项目，我对神经网络和卷积层的理解有了很大的增长，我学到并获得了许多我在其他项目中缺乏的直觉。我希望这种对 ConvNets 的经验主义理解能够帮助我从根本上理解深度学习中的条件 GANs 和其他更复杂的技术。</p><p id="c3ec" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">这个项目帮助我的另一件事是，它打破了我阅读论文的僵局。在这个项目之前，由于我对科学论文的复杂性和“声望”的误解，这是我不愿意甚至害怕的事情。通过这个项目，我学会了阅读和理解论文的核心技术，现在将它们应用到未来越来越多的研究中。</p><blockquote class="nl nm nn"><p id="9e73" class="jn jo no jp b jq jr js jt ju jv jw jx np jz ka kb nq kd ke kf nr kh ki kj kk ij bi translated">感谢阅读！该项目的完整代码和结果在<a class="ae lq" href="https://github.com/tekotan/csp-neural-style-transfer" rel="noopener ugc nofollow" target="_blank">https://github.com/tekotan/csp-neural-style-transfer</a>。</p></blockquote></div></div>    
</body>
</html>