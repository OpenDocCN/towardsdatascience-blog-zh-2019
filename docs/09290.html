<html>
<head>
<title>Real-time Object Tracking with TensorFlow, Raspberry Pi, and Pan-Tilt HAT</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用 TensorFlow、Raspberry Pi 和 Pan-Tilt HAT 进行实时对象跟踪</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/real-time-object-tracking-with-tensorflow-raspberry-pi-and-pan-tilt-hat-2aeaef47e134?source=collection_archive---------1-----------------------#2019-12-09">https://towardsdatascience.com/real-time-object-tracking-with-tensorflow-raspberry-pi-and-pan-tilt-hat-2aeaef47e134?source=collection_archive---------1-----------------------#2019-12-09</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><figure class="ip iq gp gr ir is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi io"><img src="../Images/739bc51e2df63637905da013ea719b82.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*xAs0SJR4gvvgcuuySdfmAw.jpeg"/></div></div><figcaption class="iz ja gj gh gi jb jc bd b be z dk">Pictured: Raspberry Pi 4GB, Pi Camera v2.1, Pimoroni Pan-Tilt HAT, Coral Edge TPU USB Accelerator</figcaption></figure><div class=""/><div class=""><h2 id="e48a" class="pw-subtitle-paragraph kc je jf bd b kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt dk translated">便携式计算机视觉和运动跟踪的预算。</h2></div><h1 id="24e0" class="ku kv jf bd kw kx ky kz la lb lc ld le kl lf km lg ko lh kp li kr lj ks lk ll bi translated">第 1 部分—简介👋</h1><p id="364b" class="pw-post-body-paragraph lm ln jf lo b lp lq kg lr ls lt kj lu lv lw lx ly lz ma mb mc md me mf mg mh ij bi translated">你是刚入门机器/深度学习，TensorFlow，还是 Raspberry Pi？太好了，这篇博文是给你的！我创建了<a class="ae mi" href="https://github.com/leigh-johnson/rpi-deep-pantilt" rel="noopener ugc nofollow" target="_blank"><strong class="lo jg">rpi-deep-pantilt</strong></a><strong class="lo jg"/>作为野外物体检测的交互演示。🦁</p><p id="56a6" class="pw-post-body-paragraph lm ln jf lo b lp mj kg lr ls mk kj lu lv ml lx ly lz mm mb mc md mn mf mg mh ij bi translated"><strong class="lo jg">更新— </strong>新增人脸检测和跟踪！</p><p id="f5f9" class="pw-post-body-paragraph lm ln jf lo b lp mj kg lr ls mk kj lu lv ml lx ly lz mm mb mc md mn mf mg mh ij bi translated">我将向您展示如何复制下面的视频，它描绘了一个摄像机平移和倾斜来跟踪我在房间中的移动。</p><figure class="mo mp mq mr gt is"><div class="bz fp l di"><div class="ms mt l"/></div></figure><p id="8e18" class="pw-post-body-paragraph lm ln jf lo b lp mj kg lr ls mk kj lu lv ml lx ly lz mm mb mc md mn mf mg mh ij bi translated">我将介绍以下内容:</p><ol class=""><li id="a3ac" class="mu mv jf lo b lp mj ls mk lv mw lz mx md my mh mz na nb nc bi translated">建筑材料和硬件组装说明。</li><li id="868e" class="mu mv jf lo b lp nd ls ne lv nf lz ng md nh mh mz na nb nc bi translated">将<strong class="lo jg"> TensorFlow Lite </strong>对象检测模型<strong class="lo jg"> (MobileNetV3-SSD) </strong>部署到<strong class="lo jg"> Raspberry Pi。</strong></li><li id="ec77" class="mu mv jf lo b lp nd ls ne lv nf lz ng md nh mh mz na nb nc bi translated">使用<strong class="lo jg">比例-积分-微分控制器(PID)控制器向平移/倾斜伺服电机发送跟踪指令。</strong></li><li id="ab95" class="mu mv jf lo b lp nd ls ne lv nf lz ng md nh mh mz na nb nc bi translated">使用<strong class="lo jg"> Coral 的 USB Edge TPU 加速器</strong>和<strong class="lo jg"> Edge TPU 编译器</strong>加速任何<strong class="lo jg"> TensorFlow Lite </strong>模型的推理。</li></ol></div><div class="ab cl ni nj hu nk" role="separator"><span class="nl bw bk nm nn no"/><span class="nl bw bk nm nn no"/><span class="nl bw bk nm nn"/></div><div class="ij ik il im in"><h1 id="7e68" class="ku kv jf bd kw kx np kz la lb nq ld le kl nr km lg ko ns kp li kr nt ks lk ll bi translated">术语和参考📚</h1><p id="7ef2" class="pw-post-body-paragraph lm ln jf lo b lp lq kg lr ls lt kj lu lv lw lx ly lz ma mb mc md me mf mg mh ij bi translated"><a class="ae mi" href="https://www.raspberrypi.org/" rel="noopener ugc nofollow" target="_blank"> <strong class="lo jg">树莓派</strong></a>——一款受教育者、硬件爱好者和机器人爱好者欢迎的小型平价电脑。🤖</p><p id="ba79" class="pw-post-body-paragraph lm ln jf lo b lp mj kg lr ls mk kj lu lv ml lx ly lz mm mb mc md mn mf mg mh ij bi translated"><a class="ae mi" href="https://www.raspberrypi.org/downloads/raspbian/" rel="noopener ugc nofollow" target="_blank"><strong class="lo jg">Raspbian</strong></a><strong class="lo jg">——</strong>树莓派基金会的官方操作系统为 Pi。Raspbian 源自 Debian Linux。</p><p id="f2a5" class="pw-post-body-paragraph lm ln jf lo b lp mj kg lr ls mk kj lu lv ml lx ly lz mm mb mc md mn mf mg mh ij bi translated"><a class="ae mi" href="https://www.tensorflow.org/" rel="noopener ugc nofollow" target="_blank"> <strong class="lo jg"> TensorFlow </strong> </a> —用于<a class="ae mi" href="https://en.wikipedia.org/wiki/Dataflow_programming" rel="noopener ugc nofollow" target="_blank">数据流</a>编程的开源框架，用于机器学习和深度神经学习。</p><p id="f7e9" class="pw-post-body-paragraph lm ln jf lo b lp mj kg lr ls mk kj lu lv ml lx ly lz mm mb mc md mn mf mg mh ij bi translated"><a class="ae mi" href="https://www.tensorflow.org/lite" rel="noopener ugc nofollow" target="_blank"><strong class="lo jg">tensor flow Lite</strong></a>—一个在移动和嵌入式设备上部署<strong class="lo jg"> TensorFlow </strong>模型的开源框架。</p><p id="9f84" class="pw-post-body-paragraph lm ln jf lo b lp mj kg lr ls mk kj lu lv ml lx ly lz mm mb mc md mn mf mg mh ij bi translated"><a class="ae mi" rel="noopener" target="_blank" href="/portable-computer-vision-tensorflow-2-0-on-a-raspberry-pi-part-1-of-2-84e318798ce9#e8cc"> <strong class="lo jg">卷积神经网络</strong></a><strong class="lo jg"/>——一种非常适合图像分类和对象检测任务的神经网络架构类型。</p><p id="f3fe" class="pw-post-body-paragraph lm ln jf lo b lp mj kg lr ls mk kj lu lv ml lx ly lz mm mb mc md mn mf mg mh ij bi translated"><a class="ae mi" rel="noopener" target="_blank" href="/review-ssd-single-shot-detector-object-detection-851a94607d11"><strong class="lo jg">【SSD】</strong></a>—一种<strong class="lo jg">卷积神经网络</strong> (CNN)架构，专门用于实时物体检测、分类、包围盒定位。</p><p id="eacb" class="pw-post-body-paragraph lm ln jf lo b lp mj kg lr ls mk kj lu lv ml lx ly lz mm mb mc md mn mf mg mh ij bi translated"><a class="ae mi" href="https://ai.googleblog.com/2018/04/mobilenetv2-next-generation-of-on.html" rel="noopener ugc nofollow" target="_blank"><strong class="lo jg">MobileNetV3</strong></a><strong class="lo jg">—</strong>一款最先进的计算机视觉模型，针对普通手机处理器的性能进行了优化。</p><p id="57e0" class="pw-post-body-paragraph lm ln jf lo b lp mj kg lr ls mk kj lu lv ml lx ly lz mm mb mc md mn mf mg mh ij bi translated"><a class="ae mi" href="https://github.com/tensorflow/models/tree/master/research/object_detection#nov-13th-2019" rel="noopener ugc nofollow" target="_blank"><strong class="lo jg">MobileNet v3-SSD</strong></a>—基于<strong class="lo jg"> MobileNet </strong>架构的<strong class="lo jg">单次探测器</strong>。本教程将使用通过<a class="ae mi" href="https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/detection_model_zoo.md" rel="noopener ugc nofollow" target="_blank"> TensorFlow 的对象检测模型 zoo 提供的<strong class="lo jg"> MobileNetV3-SSD </strong>模型。</a></p><figure class="mo mp mq mr gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi nu"><img src="../Images/779030e603a8af1d196fd36471115120.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*4g3BquE6qJQ7BhjhbBGxaQ.png"/></div></div><figcaption class="iz ja gj gh gi jb jc bd b be z dk">Comparison of computer vision neural networks. Image Credit and Paper: <a class="ae mi" href="https://arxiv.org/abs/1905.02244" rel="noopener ugc nofollow" target="_blank">Searching for MobileNetV3</a></figcaption></figure><p id="0ac3" class="pw-post-body-paragraph lm ln jf lo b lp mj kg lr ls mk kj lu lv ml lx ly lz mm mb mc md mn mf mg mh ij bi translated"><a class="ae mi" href="https://cloud.google.com/edge-tpu/" rel="noopener ugc nofollow" target="_blank"> <strong class="lo jg">边缘 TPU </strong> </a> —张量处理单元(TPU)是一个集成电路，用于加速<strong class="lo jg"> TensorFlow 执行的计算。</strong><strong class="lo jg">边缘 TPU </strong>是为“在边缘”的移动和嵌入式设备开发的，占地面积小</p><div class="mo mp mq mr gt ab cb"><figure class="nv is nw nx ny nz oa paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><img src="../Images/573c0bf7f8abc51233ec2bda31a56758.png" data-original-src="https://miro.medium.com/v2/resize:fit:704/format:webp/0*ZJMNLxtlPL9ED_Ur.jpeg"/></div></figure><figure class="nv is ob nx ny nz oa paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><img src="../Images/3ffe620423192541c7e207f914ef1011.png" data-original-src="https://miro.medium.com/v2/resize:fit:570/format:webp/0*qITzpDpM_O7osma6.jpeg"/></div></figure><figure class="nv is oc nx ny nz oa paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><img src="../Images/1a56ccd7eb04be701e97c6b1b340aef6.png" data-original-src="https://miro.medium.com/v2/resize:fit:728/format:webp/0*rw3z1B2ka-wncLy4.png"/></div><figcaption class="iz ja gj gh gi jb jc bd b be z dk od di oe of">Cloud TPUv1, TPUv2 (left, middle) at Google Cloud Next ’18. Cloud TPUs accelerate TensorFlow model training and inference. Edge TPUs on a United States penny (right). Edge TPUs accelerate inferences in mobile devices. Image credit: <a class="ae mi" href="https://cloud.google.com/edge-tpu/)" rel="noopener ugc nofollow" target="_blank">Google</a></figcaption></figure></div></div><div class="ab cl ni nj hu nk" role="separator"><span class="nl bw bk nm nn no"/><span class="nl bw bk nm nn no"/><span class="nl bw bk nm nn"/></div><div class="ij ik il im in"><h1 id="4e6d" class="ku kv jf bd kw kx np kz la lb nq ld le kl nr km lg ko ns kp li kr nt ks lk ll bi translated">第 2 部分—🛠构建列表</h1><h2 id="d5d9" class="og kv jf bd kw oh oi dn la oj ok dp le lv ol om lg lz on oo li md op oq lk or bi translated"><strong class="ak">基本</strong></h2><ul class=""><li id="5611" class="mu mv jf lo b lp lq ls lt lv os lz ot md ou mh ov na nb nc bi translated"><a class="ae mi" href="https://www.raspberrypi.org/products/raspberry-pi-4-model-b/" rel="noopener ugc nofollow" target="_blank">树莓 Pi 4(推荐 4GB)</a></li><li id="7bc7" class="mu mv jf lo b lp nd ls ne lv nf lz ng md nh mh ov na nb nc bi translated"><a class="ae mi" href="https://www.raspberrypi.org/products/camera-module-v2/" rel="noopener ugc nofollow" target="_blank">树莓派相机 V2 </a></li><li id="2438" class="mu mv jf lo b lp nd ls ne lv nf lz ng md nh mh ov na nb nc bi translated"><a class="ae mi" href="https://shop.pimoroni.com/products/pan-tilt-hat?variant=22408353287" rel="noopener ugc nofollow" target="_blank">皮莫尔尼云台套装</a></li><li id="2bb2" class="mu mv jf lo b lp nd ls ne lv nf lz ng md nh mh ov na nb nc bi translated">Micro SD 卡 16+ GB</li><li id="8b10" class="mu mv jf lo b lp nd ls ne lv nf lz ng md nh mh ov na nb nc bi translated">微型 HDMI 电缆</li></ul><h2 id="851f" class="og kv jf bd kw oh oi dn la oj ok dp le lv ol om lg lz on oo li md op oq lk or bi translated"><strong class="ak">可选</strong></h2><ul class=""><li id="0fc1" class="mu mv jf lo b lp lq ls lt lv os lz ot md ou mh ov na nb nc bi translated"><a class="ae mi" href="https://www.adafruit.com/product/1648" rel="noopener ugc nofollow" target="_blank"> 12 英寸 CSI/DSI 色带，用于 Raspberry Pi 摄像机</a>。<br/>Pi 摄像机的标准电缆对于云台帽子的全范围运动来说太短。</li><li id="5839" class="mu mv jf lo b lp nd ls ne lv nf lz ng md nh mh ov na nb nc bi translated"><a class="ae mi" href="https://www.adafruit.com/product/1426" rel="noopener ugc nofollow" target="_blank"> RGB NeoPixel Stick </a> <br/>这个组件为你的项目增加了一致的光源。</li><li id="3eda" class="mu mv jf lo b lp nd ls ne lv nf lz ng md nh mh ov na nb nc bi translated"><a class="ae mi" href="https://coral.withgoogle.com/products/accelerator" rel="noopener ugc nofollow" target="_blank">珊瑚缘 TPU USB 加速器</a> <br/>在树莓派上加速推断(预测)速度。你不需要这个来重现演示。</li></ul><blockquote class="ow ox oy"><p id="2abf" class="lm ln oz lo b lp mj kg lr ls mk kj lu pa ml lx ly pb mm mb mc pc mn mf mg mh ij bi translated">👋<strong class="lo jg">找一个动片少的项目</strong> s？</p><p id="b27b" class="lm ln oz lo b lp mj kg lr ls mk kj lu pa ml lx ly pb mm mb mc pc mn mf mg mh ij bi translated">查看<a class="ae mi" rel="noopener" target="_blank" href="/portable-computer-vision-tensorflow-2-0-on-a-raspberry-pi-part-1-of-2-84e318798ce9">便携式计算机视觉:树莓 Pi 上的 tensor flow 2.0</a>以创建手持图像分类器。✨</p></blockquote></div><div class="ab cl ni nj hu nk" role="separator"><span class="nl bw bk nm nn no"/><span class="nl bw bk nm nn no"/><span class="nl bw bk nm nn"/></div><div class="ij ik il im in"><h1 id="772e" class="ku kv jf bd kw kx np kz la lb nq ld le kl nr km lg ko ns kp li kr nt ks lk ll bi translated">第 3 部分— Raspberry Pi 设置</h1><p id="ec9f" class="pw-post-body-paragraph lm ln jf lo b lp lq kg lr ls lt kj lu lv lw lx ly lz ma mb mc md me mf mg mh ij bi translated">有两种方法可以将<strong class="lo jg"> Raspbian </strong>安装到您的 Micro SD 卡上:</p><ol class=""><li id="9d65" class="mu mv jf lo b lp mj ls mk lv mw lz mx md my mh mz na nb nc bi translated"><a class="ae mi" href="https://www.raspberrypi.org/documentation/installation/noobs.md" rel="noopener ugc nofollow" target="_blank"> NOOBS </a>(新的开箱即用软件)是一个 GUI 操作系统安装管理器。如果这是你的第一个 Raspberry Pi 项目，我建议从这里开始。</li><li id="48ab" class="mu mv jf lo b lp nd ls ne lv nf lz ng md nh mh mz na nb nc bi translated"><a class="ae mi" href="https://www.raspberrypi.org/documentation/installation/installing-images/README.md" rel="noopener ugc nofollow" target="_blank">将 Raspbian 图像写入 SD 卡</a>。</li></ol><p id="b0e2" class="pw-post-body-paragraph lm ln jf lo b lp mj kg lr ls mk kj lu lv ml lx ly lz mm mb mc md mn mf mg mh ij bi translated">本教程及配套软件使用<a class="ae mi" href="https://www.raspberrypi.org/documentation/installation/" rel="noopener ugc nofollow" target="_blank"><strong class="lo jg">R</strong></a><strong class="lo jg">aspbian(Buster)</strong>编写。如果您使用的是不同版本的 Raspbian 或另一个平台，您可能会经历一些痛苦。</p><p id="f933" class="pw-post-body-paragraph lm ln jf lo b lp mj kg lr ls mk kj lu lv ml lx ly lz mm mb mc md mn mf mg mh ij bi translated"><strong class="lo jg">在进行</strong>之前，您需要:</p><ul class=""><li id="6b1d" class="mu mv jf lo b lp mj ls mk lv mw lz mx md my mh ov na nb nc bi translated">将您的 Pi 连接到互联网(<a class="ae mi" href="https://projects.raspberrypi.org/en/projects/raspberry-pi-using/4" rel="noopener ugc nofollow" target="_blank"> doc </a></li><li id="790e" class="mu mv jf lo b lp nd ls ne lv nf lz ng md nh mh ov na nb nc bi translated">SSH 到您的树莓 Pi ( <a class="ae mi" href="https://www.raspberrypi.org/documentation/remote-access/ssh/" rel="noopener ugc nofollow" target="_blank"> doc </a>)</li></ul></div><div class="ab cl ni nj hu nk" role="separator"><span class="nl bw bk nm nn no"/><span class="nl bw bk nm nn no"/><span class="nl bw bk nm nn"/></div><div class="ij ik il im in"><h1 id="fd8e" class="ku kv jf bd kw kx np kz la lb nq ld le kl nr km lg ko ns kp li kr nt ks lk ll bi translated">第 4 部分—软件安装</h1><ol class=""><li id="9f2f" class="mu mv jf lo b lp lq ls lt lv os lz ot md ou mh mz na nb nc bi translated">安装系统依赖项</li></ol><pre class="mo mp mq mr gt pd pe pf pg aw ph bi"><span id="d468" class="og kv jf pe b gy pi pj l pk pl">$ sudo apt-get update &amp;&amp; sudo apt-get install -y python3-dev libjpeg-dev libatlas-base-dev raspi-gpio libhdf5-dev python3-smbus</span></pre><p id="c174" class="pw-post-body-paragraph lm ln jf lo b lp mj kg lr ls mk kj lu lv ml lx ly lz mm mb mc md mn mf mg mh ij bi translated">2.创建新的项目目录</p><pre class="mo mp mq mr gt pd pe pf pg aw ph bi"><span id="9f19" class="og kv jf pe b gy pi pj l pk pl">$ mkdir rpi-deep-pantilt &amp;&amp; cd rpi-deep-pantilt</span></pre><p id="82ad" class="pw-post-body-paragraph lm ln jf lo b lp mj kg lr ls mk kj lu lv ml lx ly lz mm mb mc md mn mf mg mh ij bi translated">3.创建新的虚拟环境</p><pre class="mo mp mq mr gt pd pe pf pg aw ph bi"><span id="0eb8" class="og kv jf pe b gy pi pj l pk pl">$ python3 -m venv .venv</span></pre><p id="9c54" class="pw-post-body-paragraph lm ln jf lo b lp mj kg lr ls mk kj lu lv ml lx ly lz mm mb mc md mn mf mg mh ij bi translated">4.激活虚拟环境</p><pre class="mo mp mq mr gt pd pe pf pg aw ph bi"><span id="d2b7" class="og kv jf pe b gy pi pj l pk pl">$ source .venv/bin/activate &amp;&amp; python3 -m pip install --upgrade pip</span></pre><p id="7256" class="pw-post-body-paragraph lm ln jf lo b lp mj kg lr ls mk kj lu lv ml lx ly lz mm mb mc md mn mf mg mh ij bi translated">5.从社区构建的轮子安装 TensorFlow 2.0。</p><pre class="mo mp mq mr gt pd pe pf pg aw ph bi"><span id="ff11" class="og kv jf pe b gy pi pj l pk pl">$ pip install <a class="ae mi" href="https://github.com/bitsy-ai/tensorflow-arm-bin/releases/download/v2.4.0/tensorflow-2.4.0-cp37-none-linux_armv7l.whl" rel="noopener ugc nofollow" target="_blank">https://github.com/bitsy-ai/tensorflow-arm-bin/releases/download/v2.4.0/tensorflow-2.4.0-cp37-none-linux_armv7l.whl</a></span></pre><p id="c4ad" class="pw-post-body-paragraph lm ln jf lo b lp mj kg lr ls mk kj lu lv ml lx ly lz mm mb mc md mn mf mg mh ij bi translated">6.安装<strong class="lo jg">rpi-deep-pantilt</strong>Python 包</p><pre class="mo mp mq mr gt pd pe pf pg aw ph bi"><span id="55a5" class="og kv jf pe b gy pi pj l pk pl">$ python3 -m pip install rpi-deep-pantilt</span></pre></div><div class="ab cl ni nj hu nk" role="separator"><span class="nl bw bk nm nn no"/><span class="nl bw bk nm nn no"/><span class="nl bw bk nm nn"/></div><div class="ij ik il im in"><h1 id="c910" class="ku kv jf bd kw kx np kz la lb nq ld le kl nr km lg ko ns kp li kr nt ks lk ll bi translated">第 5 部分—云台帽硬件组件</h1><p id="cfaf" class="pw-post-body-paragraph lm ln jf lo b lp lq kg lr ls lt kj lu lv lw lx ly lz ma mb mc md me mf mg mh ij bi translated">如果您购买了预组装的<strong class="lo jg">云台套件，您可以跳到下一部分。</strong></p><p id="71ca" class="pw-post-body-paragraph lm ln jf lo b lp mj kg lr ls mk kj lu lv ml lx ly lz mm mb mc md mn mf mg mh ij bi translated">否则，在继续之前，遵循<a class="ae mi" href="https://learn.pimoroni.com/tutorial/sandyj/assembling-pan-tilt-hat" rel="noopener ugc nofollow" target="_blank">装配云台</a>中的步骤。</p></div><div class="ab cl ni nj hu nk" role="separator"><span class="nl bw bk nm nn no"/><span class="nl bw bk nm nn no"/><span class="nl bw bk nm nn"/></div><div class="ij ik il im in"><h1 id="31d2" class="ku kv jf bd kw kx np kz la lb nq ld le kl nr km lg ko ns kp li kr nt ks lk ll bi translated">第 6 部分—连接 Pi 摄像机</h1><ol class=""><li id="a000" class="mu mv jf lo b lp lq ls lt lv os lz ot md ou mh mz na nb nc bi translated">关掉树莓派</li><li id="3634" class="mu mv jf lo b lp nd ls ne lv nf lz ng md nh mh mz na nb nc bi translated">找到 USB 模块和 HDMI 模块之间的摄像头模块。</li><li id="657e" class="mu mv jf lo b lp nd ls ne lv nf lz ng md nh mh mz na nb nc bi translated">向上(轻轻地)拉，打开黑色塑料夹</li><li id="b4c3" class="mu mv jf lo b lp nd ls ne lv nf lz ng md nh mh mz na nb nc bi translated">插入摄像头模块带状电缆(金属连接器<strong class="lo jg">朝向远离 Raspberry Pi 4 上以太网/ USB 端口的</strong>)</li><li id="bb8b" class="mu mv jf lo b lp nd ls ne lv nf lz ng md nh mh mz na nb nc bi translated">锁定黑色塑料夹</li></ol><figure class="mo mp mq mr gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi pm"><img src="../Images/53e4f8ab441624f8c30729729a0cbdbe.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/1*cdWRY2ldCqz-8hYnuiTfBw.gif"/></div></div><figcaption class="iz ja gj gh gi jb jc bd b be z dk">Image Credit: <a class="ae mi" href="https://projects.raspberrypi.org/en/projects/getting-started-with-picamera" rel="noopener ugc nofollow" target="_blank">Getting Started with the Pi Camera</a></figcaption></figure></div><div class="ab cl ni nj hu nk" role="separator"><span class="nl bw bk nm nn no"/><span class="nl bw bk nm nn no"/><span class="nl bw bk nm nn"/></div><div class="ij ik il im in"><h1 id="7a87" class="ku kv jf bd kw kx np kz la lb nq ld le kl nr km lg ko ns kp li kr nt ks lk ll bi translated">第 7 部分—启用 Pi 摄像机</h1><ol class=""><li id="0390" class="mu mv jf lo b lp lq ls lt lv os lz ot md ou mh mz na nb nc bi translated">打开树莓派</li><li id="c507" class="mu mv jf lo b lp nd ls ne lv nf lz ng md nh mh mz na nb nc bi translated">运行<code class="fe pn po pp pe b">sudo raspi-config</code>并从 Raspberry Pi 软件配置工具的主菜单中选择<code class="fe pn po pp pe b">Interfacing Options</code>。按回车键。</li></ol><figure class="mo mp mq mr gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi pq"><img src="../Images/58e3a83dc5b4c863485087f31b34cdb4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*7JGOPvfv4JwYEIm-.png"/></div></div></figure><p id="c699" class="pw-post-body-paragraph lm ln jf lo b lp mj kg lr ls mk kj lu lv ml lx ly lz mm mb mc md mn mf mg mh ij bi translated">3.选择<code class="fe pn po pp pe b">Enable Camera</code>菜单选项并按下回车键。</p><figure class="mo mp mq mr gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi pr"><img src="../Images/5aec9b4e34e2ec12d5c004abefcec6ec.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*dFmOlqyBkE98o6JiU0kp6Q.png"/></div></div></figure><p id="2ad8" class="pw-post-body-paragraph lm ln jf lo b lp mj kg lr ls mk kj lu lv ml lx ly lz mm mb mc md mn mf mg mh ij bi translated">4.在下一个菜单中，使用右箭头键高亮显示<code class="fe pn po pp pe b">ENABLE</code>并按 ENTER 键。</p><figure class="mo mp mq mr gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi ps"><img src="../Images/f4e5df7fbc6ea28fe8e88cdeb7b1f8da.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*09oxH02CQXrAUp7qmar6Lg.png"/></div></div></figure></div><div class="ab cl ni nj hu nk" role="separator"><span class="nl bw bk nm nn no"/><span class="nl bw bk nm nn no"/><span class="nl bw bk nm nn"/></div><div class="ij ik il im in"><h1 id="5592" class="ku kv jf bd kw kx np kz la lb nq ld le kl nr km lg ko ns kp li kr nt ks lk ll bi translated">第 8 部分—测试云台</h1><p id="c853" class="pw-post-body-paragraph lm ln jf lo b lp lq kg lr ls lt kj lu lv lw lx ly lz ma mb mc md me mf mg mh ij bi translated">接下来，测试 Pan-Tilt HAT 模块的安装和设置。</p><ol class=""><li id="6177" class="mu mv jf lo b lp mj ls mk lv mw lz mx md my mh mz na nb nc bi translated">嘘到你的树莓皮</li><li id="c61d" class="mu mv jf lo b lp nd ls ne lv nf lz ng md nh mh mz na nb nc bi translated">激活你的虚拟环境:<code class="fe pn po pp pe b">source .venv/bin/activate</code></li><li id="d4ba" class="mu mv jf lo b lp nd ls ne lv nf lz ng md nh mh mz na nb nc bi translated">运行以下命令:<code class="fe pn po pp pe b">rpi-deep-pantilt test pantilt</code></li><li id="9bb3" class="mu mv jf lo b lp nd ls ne lv nf lz ng md nh mh mz na nb nc bi translated">用 Ctrl+C 退出测试</li></ol><p id="e562" class="pw-post-body-paragraph lm ln jf lo b lp mj kg lr ls mk kj lu lv ml lx ly lz mm mb mc md mn mf mg mh ij bi translated">如果你安装了正确的帽子，你应该看到两个伺服移动在一个平稳的正弦运动，而测试正在运行。</p><figure class="mo mp mq mr gt is gh gi paragraph-image"><div class="gh gi pt"><img src="../Images/a8a3cc952c34164566992acb8a397e36.png" data-original-src="https://miro.medium.com/v2/resize:fit:1200/1*SOV1U1PAojGui2RohhhqPA.gif"/></div></figure></div><div class="ab cl ni nj hu nk" role="separator"><span class="nl bw bk nm nn no"/><span class="nl bw bk nm nn no"/><span class="nl bw bk nm nn"/></div><div class="ij ik il im in"><h1 id="ec6d" class="ku kv jf bd kw kx np kz la lb nq ld le kl nr km lg ko ns kp li kr nt ks lk ll bi translated">第 9 部分—测试 Pi 摄像机</h1><p id="d287" class="pw-post-body-paragraph lm ln jf lo b lp lq kg lr ls lt kj lu lv lw lx ly lz ma mb mc md me mf mg mh ij bi translated">接下来，通过启动摄像机的预览覆盖来验证 Pi 摄像机是否安装正确。叠加将在 Pi 的主显示器(HDMI)上呈现。</p><ol class=""><li id="ccd7" class="mu mv jf lo b lp mj ls mk lv mw lz mx md my mh mz na nb nc bi translated">将您的 Raspberry Pi 插入 HDMI 屏幕</li><li id="6b5c" class="mu mv jf lo b lp nd ls ne lv nf lz ng md nh mh mz na nb nc bi translated">嘘到你的树莓皮</li><li id="054b" class="mu mv jf lo b lp nd ls ne lv nf lz ng md nh mh mz na nb nc bi translated">激活你的虚拟环境:<code class="fe pn po pp pe b">$ source .venv/bin/activate</code></li><li id="fe77" class="mu mv jf lo b lp nd ls ne lv nf lz ng md nh mh mz na nb nc bi translated">运行以下命令:<code class="fe pn po pp pe b">$ rpi-deep-pantilt test camera</code></li><li id="2015" class="mu mv jf lo b lp nd ls ne lv nf lz ng md nh mh mz na nb nc bi translated">用 Ctrl+C 退出测试</li></ol><p id="cdf6" class="pw-post-body-paragraph lm ln jf lo b lp mj kg lr ls mk kj lu lv ml lx ly lz mm mb mc md mn mf mg mh ij bi translated">如果您正确安装了 Pi 摄像机，您应该会看到摄像机中的素材渲染到您的 HDMI 或复合显示器上。</p></div><div class="ab cl ni nj hu nk" role="separator"><span class="nl bw bk nm nn no"/><span class="nl bw bk nm nn no"/><span class="nl bw bk nm nn"/></div><div class="ij ik il im in"><h1 id="9ee9" class="ku kv jf bd kw kx np kz la lb nq ld le kl nr km lg ko ns kp li kr nt ks lk ll bi translated">第 10 部分—测试对象检测</h1><p id="585c" class="pw-post-body-paragraph lm ln jf lo b lp lq kg lr ls lt kj lu lv lw lx ly lz ma mb mc md me mf mg mh ij bi translated">接下来，验证您可以在您的 Raspberry Pi 上运行对象检测模型(<strong class="lo jg"> MobileNetV3-SSD </strong>)。</p><ol class=""><li id="35a6" class="mu mv jf lo b lp mj ls mk lv mw lz mx md my mh mz na nb nc bi translated">嘘到你的树莓皮</li><li id="d67a" class="mu mv jf lo b lp nd ls ne lv nf lz ng md nh mh mz na nb nc bi translated">激活你的虚拟环境:<code class="fe pn po pp pe b">$ source .venv/bin/activate</code></li><li id="94b8" class="mu mv jf lo b lp nd ls ne lv nf lz ng md nh mh mz na nb nc bi translated">运行以下命令:</li></ol><pre class="mo mp mq mr gt pd pe pf pg aw ph bi"><span id="470d" class="og kv jf pe b gy pi pj l pk pl">$ <!-- -->rpi-deep-pantilt detect</span></pre><p id="3bb3" class="pw-post-body-paragraph lm ln jf lo b lp mj kg lr ls mk kj lu lv ml lx ly lz mm mb mc md mn mf mg mh ij bi translated">您的 Raspberry Pi 应该检测对象，尝试对对象进行分类，并在其周围绘制一个边界框。</p><pre class="mo mp mq mr gt pd pe pf pg aw ph bi"><span id="30d6" class="og kv jf pe b gy pi pj l pk pl">$ <!-- -->rpi-deep-pantilt face-detect</span></pre><h2 id="9a4d" class="og kv jf bd kw oh oi dn la oj ok dp le lv ol om lg lz on oo li md op oq lk or bi translated"><strong class="ak">注意:</strong>使用默认的<strong class="ak"> MobileNetV3-SSD 模型，只能检测和跟踪以下对象。</strong></h2><pre class="mo mp mq mr gt pd pe pf pg aw ph bi"><span id="7630" class="og kv jf pe b gy pi pj l pk pl">$ rpi-deep-pantilt list-labels<br/>[‘person’, ‘bicycle’, ‘car’, ‘motorcycle’, ‘airplane’, ‘bus’, ‘train’, ‘truck’, ‘boat’, ‘traffic light’, ‘fire hydrant’, ‘stop sign’, ‘parking meter’, ‘bench’, ‘bird’, ‘cat’, ‘dog’, ‘horse’, ‘sheep’, ‘cow’, ‘elephant’, ‘bear’, ‘zebra’, ‘giraffe’, ‘backpack’, ‘umbrella’, ‘handbag’, ‘tie’, ‘suitcase’, ‘frisbee’, ‘skis’, ‘snowboard’, ‘sports ball’, ‘kite’, ‘baseball bat’, ‘baseball glove’, ‘skateboard’, ‘surfboard’, ‘tennis racket’, ‘bottle’, ‘wine glass’, ‘cup’, ‘fork’, ‘knife’, ‘spoon’, ‘bowl’, ‘banana’, ‘apple’, ‘sandwich’, ‘orange’, ‘broccoli’, ‘carrot’, ‘hot dog’, ‘pizza’, ‘donut’, ‘cake’, ‘chair’, ‘couch’, ‘potted plant’, ‘bed’, ‘dining table’, ‘toilet’, ‘tv’, ‘laptop’, ‘mouse’, ‘remote’, ‘keyboard’, ‘cell phone’, ‘microwave’, ‘oven’, ‘toaster’, ‘sink’, ‘refrigerator’, ‘book’, ‘clock’, ‘vase’, ‘scissors’, ‘teddy bear’, ‘hair drier’, ‘toothbrush’]</span></pre></div><div class="ab cl ni nj hu nk" role="separator"><span class="nl bw bk nm nn no"/><span class="nl bw bk nm nn no"/><span class="nl bw bk nm nn"/></div><div class="ij ik il im in"><h1 id="9f70" class="ku kv jf bd kw kx np kz la lb nq ld le kl nr km lg ko ns kp li kr nt ks lk ll bi translated">第 11 部分—以约 8 FPS 的速度跟踪物体</h1><p id="bd4f" class="pw-post-body-paragraph lm ln jf lo b lp lq kg lr ls lt kj lu lv lw lx ly lz ma mb mc md me mf mg mh ij bi translated">这是我们期待已久的时刻！采用以下步骤，使用云台以大约 8 帧/秒的速度跟踪物体。</p><ol class=""><li id="9379" class="mu mv jf lo b lp mj ls mk lv mw lz mx md my mh mz na nb nc bi translated">嘘到你的树莓皮</li><li id="18e9" class="mu mv jf lo b lp nd ls ne lv nf lz ng md nh mh mz na nb nc bi translated">激活你的虚拟环境:<code class="fe pn po pp pe b">$source .venv/bin/activate</code></li><li id="f825" class="mu mv jf lo b lp nd ls ne lv nf lz ng md nh mh mz na nb nc bi translated">运行以下命令:<code class="fe pn po pp pe b">$ rpi-deep-pantilt track</code></li></ol><p id="961e" class="pw-post-body-paragraph lm ln jf lo b lp mj kg lr ls mk kj lu lv ml lx ly lz mm mb mc md mn mf mg mh ij bi translated">默认情况下，这将跟踪标签为<code class="fe pn po pp pe b">person</code>的对象。您可以使用<code class="fe pn po pp pe b">--label</code>参数跟踪不同类型的物体。</p><p id="dcc9" class="pw-post-body-paragraph lm ln jf lo b lp mj kg lr ls mk kj lu lv ml lx ly lz mm mb mc md mn mf mg mh ij bi translated">例如，要跟踪一只香蕉，您需要运行:</p><p id="f5fa" class="pw-post-body-paragraph lm ln jf lo b lp mj kg lr ls mk kj lu lv ml lx ly lz mm mb mc md mn mf mg mh ij bi translated"><code class="fe pn po pp pe b">$ rpi-deep-pantilt track --label=banana</code></p><p id="72be" class="pw-post-body-paragraph lm ln jf lo b lp mj kg lr ls mk kj lu lv ml lx ly lz mm mb mc md mn mf mg mh ij bi translated">在一台<strong class="lo jg"> Raspberry Pi 4 (4 GB) </strong>上，我对我的模型进行了大约每秒 8 帧的基准测试。</p><pre class="mo mp mq mr gt pd pe pf pg aw ph bi"><span id="5f68" class="og kv jf pe b gy pi pj l pk pl">INFO:root:FPS: 8.100870481091935<br/>INFO:root:FPS: 8.130448201926173<br/>INFO:root:FPS: 7.6518234817241355<br/>INFO:root:FPS: 7.657477766009717<br/>INFO:root:FPS: 7.861758172395542<br/>INFO:root:FPS: 7.8549541944597<br/>INFO:root:FPS: 7.907857699044301</span></pre></div><div class="ab cl ni nj hu nk" role="separator"><span class="nl bw bk nm nn no"/><span class="nl bw bk nm nn no"/><span class="nl bw bk nm nn"/></div><div class="ij ik il im in"><h1 id="3344" class="ku kv jf bd kw kx np kz la lb nq ld le kl nr km lg ko ns kp li kr nt ks lk ll bi translated">第 12 部分—使用边缘 TPU 实时跟踪物体</h1><p id="9223" class="pw-post-body-paragraph lm ln jf lo b lp lq kg lr ls lt kj lu lv lw lx ly lz ma mb mc md me mf mg mh ij bi translated">我们可以用<a class="ae mi" href="https://coral.ai/products/accelerator/" rel="noopener ugc nofollow" target="_blank"> Coral 的 USB 加速器来加速<strong class="lo jg">模型推理速度</strong>。</a>USB 加速器包含一个 Edge TPU，它是一个专用于 TensorFlow Lite 操作的<a class="ae mi" href="https://en.wikipedia.org/wiki/Application-specific_integrated_circuit" rel="noopener ugc nofollow" target="_blank"> ASIC </a>芯片。欲了解更多信息，请查看<a class="ae mi" href="https://coral.ai/docs/accelerator/get-started/" rel="noopener ugc nofollow" target="_blank">开始使用 USB 加速器。</a></p><ol class=""><li id="8c97" class="mu mv jf lo b lp mj ls mk lv mw lz mx md my mh mz na nb nc bi translated">嘘到你的树莓皮</li><li id="2d90" class="mu mv jf lo b lp nd ls ne lv nf lz ng md nh mh mz na nb nc bi translated">安装边缘 TPU 运行时</li></ol><pre class="mo mp mq mr gt pd pe pf pg aw ph bi"><span id="1156" class="og kv jf pe b gy pi pj l pk pl">$ echo "deb https://packages.cloud.google.com/apt coral-edgetpu-stable main" | sudo tee /etc/apt/sources.list.d/coral-edgetpu.list<br/><br/>$ curl https://packages.cloud.google.com/apt/doc/apt-key.gpg | sudo apt-key add -<br/><br/>$ sudo apt-get update &amp;&amp; sudo apt-get install libedgetpu1-std</span></pre><p id="ae1a" class="pw-post-body-paragraph lm ln jf lo b lp mj kg lr ls mk kj lu lv ml lx ly lz mm mb mc md mn mf mg mh ij bi translated">3.插入 Edge TPU(最好是一个<strong class="lo jg"> USB 3.0 端口</strong>)。<strong class="lo jg"> </strong>如果您的 Edge TPU 已经插入，<strong class="lo jg">移除并重新插入</strong>，以便 udev 设备管理器可以检测到它。</p><p id="cfb6" class="pw-post-body-paragraph lm ln jf lo b lp mj kg lr ls mk kj lu lv ml lx ly lz mm mb mc md mn mf mg mh ij bi translated">4.使用<code class="fe pn po pp pe b">--edge-tpu</code>选项尝试<strong class="lo jg">检测命令</strong>。你应该能够实时检测物体！🎉</p><pre class="mo mp mq mr gt pd pe pf pg aw ph bi"><span id="d2a9" class="og kv jf pe b gy pi pj l pk pl">$ rpi-deep-pantilt detect --edge-tpu --loglevel=INFO</span></pre><p id="c0ec" class="pw-post-body-paragraph lm ln jf lo b lp mj kg lr ls mk kj lu lv ml lx ly lz mm mb mc md mn mf mg mh ij bi translated"><strong class="lo jg">注意:</strong> <code class="fe pn po pp pe b"><strong class="lo jg">loglevel=INFO</strong></code> <strong class="lo jg"> </strong>将向您显示检测对象和将边界框渲染到 Raspberry Pi 相机覆盖图的 FPS。</p><p id="ec85" class="pw-post-body-paragraph lm ln jf lo b lp mj kg lr ls mk kj lu lv ml lx ly lz mm mb mc md mn mf mg mh ij bi translated">您应该看到大约 24 FPS，这是帧从 Pi 相机采样到帧缓冲区的速率。</p><pre class="mo mp mq mr gt pd pe pf pg aw ph bi"><span id="426e" class="og kv jf pe b gy pi pj l pk pl">INFO:root:FPS: 24.716493958392558<br/>INFO:root:FPS: 24.836166606505206<br/>INFO:root:FPS: 23.031063233367547<br/>INFO:root:FPS: 25.467177106703623<br/>INFO:root:FPS: 27.480438524486594<br/>INFO:root:FPS: 25.41399952505432</span></pre><p id="0659" class="pw-post-body-paragraph lm ln jf lo b lp mj kg lr ls mk kj lu lv ml lx ly lz mm mb mc md mn mf mg mh ij bi translated">5.使用<code class="fe pn po pp pe b">--edge-tpu</code>选项尝试跟踪命令。</p><pre class="mo mp mq mr gt pd pe pf pg aw ph bi"><span id="997e" class="og kv jf pe b gy pi pj l pk pl">$ rpi-deep-pantilt track --edge-tpu</span></pre></div><div class="ab cl ni nj hu nk" role="separator"><span class="nl bw bk nm nn no"/><span class="nl bw bk nm nn no"/><span class="nl bw bk nm nn"/></div><div class="ij ik il im in"><h1 id="fa53" class="ku kv jf bd kw kx np kz la lb nq ld le kl nr km lg ko ns kp li kr nt ks lk ll bi translated">第 13 部分—检测和跟踪人脸(v1.1.x 中的新功能)</h1><p id="ec18" class="pw-post-body-paragraph lm ln jf lo b lp lq kg lr ls lt kj lu lv lw lx ly lz ma mb mc md me mf mg mh ij bi translated">我在<code class="fe pn po pp pe b">rpi-deep-pantilt</code>的<strong class="lo jg"> v1.1.x </strong>版本中添加了一个<strong class="lo jg">全新的</strong>人脸检测模型🎉</p><p id="94c9" class="pw-post-body-paragraph lm ln jf lo b lp mj kg lr ls mk kj lu lv ml lx ly lz mm mb mc md mn mf mg mh ij bi translated">该模型来源于 TensorFlow 的<a class="ae mi" href="https://github.com/tensorflow/models" rel="noopener ugc nofollow" target="_blank">研究模型 zoo </a>中的<strong class="lo jg">faces SD _ mobilenet _ v2 _ quantified _ 320 _ open _ image _ v4</strong>。</p><p id="37b7" class="pw-post-body-paragraph lm ln jf lo b lp mj kg lr ls mk kj lu lv ml lx ly lz mm mb mc md mn mf mg mh ij bi translated">新命令是<code class="fe pn po pp pe b">rpi-deep-pantilt face-detect</code>(检测所有人脸)和<code class="fe pn po pp pe b">rpi-deep-pantilt face-track</code>(戴着潘迪特帽子追踪人脸)。这两个命令都支持<code class="fe pn po pp pe b">--edge-tpu</code>选项，如果使用 Edge TPU USB 加速器，这将加速推理。</p><pre class="mo mp mq mr gt pd pe pf pg aw ph bi"><span id="b104" class="og kv jf pe b gy pi pj l pk pl">rpi-deep-pantilt face-detect --help<br/>Usage: cli.py face-detect [OPTIONS]<br/><br/>Options:<br/>  --loglevel TEXT  Run object detection without pan-tilt controls. Pass<br/>                   --loglevel=DEBUG to inspect FPS.<br/>  --edge-tpu       Accelerate inferences using Coral USB Edge TPU<br/>  --help           Show this message and exit.</span></pre></div><div class="ab cl ni nj hu nk" role="separator"><span class="nl bw bk nm nn no"/><span class="nl bw bk nm nn no"/><span class="nl bw bk nm nn"/></div><div class="ij ik il im in"><pre class="pd pe pf pg aw ph bi"><span id="962e" class="og kv jf pe b gy pu pv pw px py pj l pk pl">rpi-deep-pantilt face-track --help<br/>Usage: cli.py face-track [OPTIONS]<br/><br/>Options:<br/>  --loglevel TEXT  Run object detection without pan-tilt controls. Pass<br/>                   --loglevel=DEBUG to inspect FPS.<br/>  --edge-tpu       Accelerate inferences using Coral USB Edge TPU<br/>  --help           Show this message and exit.</span></pre></div><div class="ab cl ni nj hu nk" role="separator"><span class="nl bw bk nm nn no"/><span class="nl bw bk nm nn no"/><span class="nl bw bk nm nn"/></div><div class="ij ik il im in"><h1 id="2ee4" class="ku kv jf bd kw kx np kz la lb nq ld le kl nr km lg ko ns kp li kr nt ks lk ll bi translated">包扎🌻</h1><p id="ec50" class="pw-post-body-paragraph lm ln jf lo b lp lq kg lr ls lt kj lu lv lw lx ly lz ma mb mc md me mf mg mh ij bi translated">恭喜你！你现在自豪地拥有了一个 DIY 对象跟踪系统，该系统使用<strong class="lo jg">单次检测器</strong>(一种<strong class="lo jg">卷积神经网络</strong>)来分类和定位对象。</p><h2 id="2da4" class="og kv jf bd kw oh oi dn la oj ok dp le lv ol om lg lz on oo li md op oq lk or bi translated">PID 控制器</h2><p id="dc6b" class="pw-post-body-paragraph lm ln jf lo b lp lq kg lr ls lt kj lu lv lw lx ly lz ma mb mc md me mf mg mh ij bi translated">平移/倾斜跟踪系统使用<a class="ae mi" href="https://en.wikipedia.org/wiki/PID_controller" rel="noopener ugc nofollow" target="_blank"> <strong class="lo jg">比例-积分-微分控制器(PID)控制器</strong> </a> <strong class="lo jg"> </strong>来平滑地跟踪边界框的质心。</p><figure class="mo mp mq mr gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi pz"><img src="../Images/b2c2d9461c931db668fc1182aeda9386.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*9sQpP7SqMHrhAwySJBJffQ.png"/></div></div><figcaption class="iz ja gj gh gi jb jc bd b be z dk">PID Controller Architecture, Leigh Johnson 2019</figcaption></figure><h2 id="73b1" class="og kv jf bd kw oh oi dn la oj ok dp le lv ol om lg lz on oo li md op oq lk or bi translated">张量流模型动物园</h2><p id="edb0" class="pw-post-body-paragraph lm ln jf lo b lp lq kg lr ls lt kj lu lv lw lx ly lz ma mb mc md me mf mg mh ij bi translated">本教程中的模型来源于<a class="ae mi" href="https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/detection_model_zoo.md" rel="noopener ugc nofollow" target="_blank"> <strong class="lo jg"> TensorFlow 检测模型 Zoo </strong> </a> <strong class="lo jg">中的<a class="ae mi" href="http://download.tensorflow.org/models/object_detection/ssd_mobilenet_v3_small_coco_2019_08_14.tar.gz" rel="noopener ugc nofollow" target="_blank"><strong class="lo jg">SSD _ mobilenet _ v3 _ small _ coco</strong></a>和<strong class="lo jg">SSD _ mobilenet _ edge TPU _ coco</strong><strong class="lo jg"/>。🦁🦄🐼</strong></p><p id="e5d4" class="pw-post-body-paragraph lm ln jf lo b lp mj kg lr ls mk kj lu lv ml lx ly lz mm mb mc md mn mf mg mh ij bi translated">我的模型可以通过<a class="ae mi" href="https://github.com/leigh-johnson/rpi-deep-pantilt/releases/tag/v1.0.1" rel="noopener ugc nofollow" target="_blank"> Github 发布说明</a>@<a class="ae mi" href="https://github.com/leigh-johnson/rpi-deep-pantilt" rel="noopener ugc nofollow" target="_blank">Leigh-Johnson/rpi-deep-pantilt</a>下载。</p><p id="1df6" class="pw-post-body-paragraph lm ln jf lo b lp mj kg lr ls mk kj lu lv ml lx ly lz mm mb mc md mn mf mg mh ij bi translated">我添加了自定义的<strong class="lo jg">TF lite _ Detection _ PostProcess</strong>操作，它在模型输出上实现了<strong class="lo jg">非最大抑制(NMS) </strong>的变体。<strong class="lo jg">非最大抑制</strong>是使用<a class="ae mi" href="https://www.probabilitycourse.com/chapter1/1_2_2_set_operations.php" rel="noopener ugc nofollow" target="_blank"> <strong class="lo jg">集合操作</strong>过滤许多包围盒提议的技术。</a></p><figure class="mo mp mq mr gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi qa"><img src="../Images/8ab351e3e235b7fce7f0cfa768cbc6b5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*weFV951XGeWqehMc.png"/></div></div><figcaption class="iz ja gj gh gi jb jc bd b be z dk">Image Credit: <a class="ae mi" rel="noopener" target="_blank" href="/non-maximum-suppression-nms-93ce178e177c">Non-maximum Suppression (NMS)</a></figcaption></figure><h1 id="b2fb" class="ku kv jf bd kw kx ky kz la lb lc ld le kl lf km lg ko lh kp li kr lj ks lk ll bi translated">感谢您的阅读！</h1><p id="6b47" class="pw-post-body-paragraph lm ln jf lo b lp lq kg lr ls lt kj lu lv lw lx ly lz ma mb mc md me mf mg mh ij bi translated">寻找更多针对 Raspberry Pi 和其他小型设备的机器学习实践示例？<a class="ae mi" href="https://www.bitsy.ai/" rel="noopener ugc nofollow" target="_blank">报名我的简讯</a>！</p><p id="51c2" class="pw-post-body-paragraph lm ln jf lo b lp mj kg lr ls mk kj lu lv ml lx ly lz mm mb mc md mn mf mg mh ij bi translated">我发布了真实世界的 ML 应用程序的例子(带有完整的源代码)和漂亮的小技巧，如<a class="ae mi" href="https://www.bitsy.ai/automate-bounding-box-annotation-with-tensorflow-and-automl/" rel="noopener ugc nofollow" target="_blank">自动消除边框注释的痛苦</a>。</p><h1 id="80d3" class="ku kv jf bd kw kx ky kz la lb lc ld le kl lf km lg ko lh kp li kr lj ks lk ll bi translated">特别感谢和致谢🤗</h1><p id="a161" class="pw-post-body-paragraph lm ln jf lo b lp lq kg lr ls lt kj lu lv lw lx ly lz ma mb mc md me mf mg mh ij bi translated">撰稿人:熊云阳、、苏约格·古普塔、、加布里埃尔·本德、谭明星、伯金·阿金、、郭乐。</p><p id="ee1f" class="pw-post-body-paragraph lm ln jf lo b lp mj kg lr ls mk kj lu lv ml lx ly lz mm mb mc md mn mf mg mh ij bi translated"><strong class="lo jg"> MobileNetV3 SSDLite </strong>供稿人:、、Vivek Rathod、Jonathan Huang。</p><p id="ce39" class="pw-post-body-paragraph lm ln jf lo b lp mj kg lr ls mk kj lu lv ml lx ly lz mm mb mc md mn mf mg mh ij bi translated">特别感谢<strong class="lo jg"> Adrian Rosebrock </strong>用树莓 Pi 和 OpenCV<strong class="lo jg"/>编写了<a class="ae mi" href="https://www.pyimagesearch.com/2019/04/01/pan-tilt-face-tracking-with-a-raspberry-pi-and-opencv/" rel="noopener ugc nofollow" target="_blank"> <strong class="lo jg">云台人脸跟踪，这是整个项目的灵感来源！</strong></a></p><p id="b5c2" class="pw-post-body-paragraph lm ln jf lo b lp mj kg lr ls mk kj lu lv ml lx ly lz mm mb mc md mn mf mg mh ij bi translated">特别感谢<strong class="lo jg"> Jason Zaman </strong>审阅本文和提前发布候选人。💪</p></div></div>    
</body>
</html>