<html>
<head>
<title>Object Detection with YOLO | Bringing Vision to Self-Driving Cars</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">YOLO 物体检测|为自动驾驶汽车带来视觉</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/object-detection-with-yolo-bringing-vision-to-self-driving-cars-980295226830?source=collection_archive---------8-----------------------#2019-11-02">https://towardsdatascience.com/object-detection-with-yolo-bringing-vision-to-self-driving-cars-980295226830?source=collection_archive---------8-----------------------#2019-11-02</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="d691" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">解释和使用 YOLO(你只看一次)计算机视觉算法的对象检测</h2></div><blockquote class="ki kj kk"><p id="389b" class="kl km kn ko b kp kq ju kr ks kt jx ku kv kw kx ky kz la lb lc ld le lf lg lh im bi translated"><strong class="ko iu">编辑</strong>:写完这篇文章后不久，我制作了一个 YouTube 视频(VSauce Parody)来解释 YOLO。请随意查看！</p></blockquote><figure class="li lj lk ll gt lm"><div class="bz fp l di"><div class="ln lo l"/></div></figure><p id="e21d" class="pw-post-body-paragraph kl km it ko b kp kq ju kr ks kt jx ku lp kw kx ky lq la lb lc lr le lf lg lh im bi translated">我们都认为我们的愿景是理所当然的。它是数亿年进化的产物，从一片感光细胞进化成一种被称为人眼的复杂光学奇观。</p><p id="9fb2" class="pw-post-body-paragraph kl km it ko b kp kq ju kr ks kt jx ku lp kw kx ky lq la lb lc lr le lf lg lh im bi translated">纵观人类的生存历程，我们的生存依赖于我们理解和解释环境的能力。在我们漫游非洲平原的时候，原始人类需要立即识别威胁并做出反应。</p><figure class="li lj lk ll gt lm gh gi paragraph-image"><div role="button" tabindex="0" class="lt lu di lv bf lw"><div class="gh gi ls"><img src="../Images/d477f912bf64bd879db6ddb7547e6500.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*FgahInknq1uYBcrU_4c1Xg.png"/></div></div></figure><p id="f555" class="pw-post-body-paragraph kl km it ko b kp kq ju kr ks kt jx ku lp kw kx ky lq la lb lc lr le lf lg lh im bi translated">即使在今天，这种情况仍然存在。</p><figure class="li lj lk ll gt lm gh gi paragraph-image"><div role="button" tabindex="0" class="lt lu di lv bf lw"><div class="gh gi ls"><img src="../Images/6f2ead4a85e257ddfd31639090ecf2dd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*nI5zi3bmlaXXRFlUAUAJcw.png"/></div></div></figure><p id="5698" class="pw-post-body-paragraph kl km it ko b kp kq ju kr ks kt jx ku lp kw kx ky lq la lb lc lr le lf lg lh im bi translated">看到我们生活的世界的能力让克里斯托弗·哥伦布得以环游世界，让莱昂纳多·达·芬奇得以画出蒙娜丽莎，让小蒂米得以骑独轮车。干得好，提米。</p><figure class="li lj lk ll gt lm gh gi paragraph-image"><div role="button" tabindex="0" class="lt lu di lv bf lw"><div class="gh gi ls"><img src="../Images/c7506182e3186f73b4c72a38c077d9fa.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*qrk3UZzPsqZld9dQAqQ2Og.png"/></div></div></figure><p id="5c53" class="pw-post-body-paragraph kl km it ko b kp kq ju kr ks kt jx ku lp kw kx ky lq la lb lc lr le lf lg lh im bi translated">自从智人出现以来，人类拥有了最好的视觉。然而，这种情况不会持续太久。因为人类很懒。最初人类认为:</p><blockquote class="ki kj kk"><p id="d61a" class="kl km kn ko b kp kq ju kr ks kt jx ku kv kw kx ky kz la lb lc ld le lf lg lh im bi translated">"嘿，走路太累了，让我们驯养这些大的四足动物，然后骑着它们到处走."</p></blockquote><figure class="li lj lk ll gt lm gh gi paragraph-image"><div role="button" tabindex="0" class="lt lu di lv bf lw"><div class="gh gi ls"><img src="../Images/09f8c90757539bb35270038855d5b2b5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*tyHGhgZdjZW1lgn2R7_yeQ.png"/></div></div></figure><p id="3ad1" class="pw-post-body-paragraph kl km it ko b kp kq ju kr ks kt jx ku lp kw kx ky lq la lb lc lr le lf lg lh im bi translated">然后我们想:</p><blockquote class="ki kj kk"><p id="32d8" class="kl km kn ko b kp kq ju kr ks kt jx ku kv kw kx ky kz la lb lc ld le lf lg lh im bi translated">“喂，养这些马太费事了，让我们造这些大四轮车到处跑吧”</p></blockquote><figure class="li lj lk ll gt lm gh gi paragraph-image"><div role="button" tabindex="0" class="lt lu di lv bf lw"><div class="gh gi ls"><img src="../Images/957544cd054f014b071fa74c1800981a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*sss3x8ouk3KYO9ja89vR7w.png"/></div></div></figure><p id="1952" class="pw-post-body-paragraph kl km it ko b kp kq ju kr ks kt jx ku lp kw kx ky lq la lb lc lr le lf lg lh im bi translated">现在我们认为:</p><blockquote class="ki kj kk"><p id="1d57" class="kl km kn ko b kp kq ju kr ks kt jx ku kv kw kx ky kz la lb lc ld le lf lg lh im bi translated">“嘿，驾驶这些汽车太费力了，让我们建立复杂的人工智能算法来为我们做这件事”</p></blockquote><figure class="li lj lk ll gt lm gh gi paragraph-image"><div role="button" tabindex="0" class="lt lu di lv bf lw"><div class="gh gi ls"><img src="../Images/b4318dd9b8700ccb01dd70e4a1b3554b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*FzjaPg62k1RbaAp7DteW_g.png"/></div></div></figure><p id="e5e5" class="pw-post-body-paragraph kl km it ko b kp kq ju kr ks kt jx ku lp kw kx ky lq la lb lc lr le lf lg lh im bi translated">于是自动驾驶汽车诞生了——诞生于我们甚至连开车都懒得做的懒惰。</p><p id="1a19" class="pw-post-body-paragraph kl km it ko b kp kq ju kr ks kt jx ku lp kw kx ky lq la lb lc lr le lf lg lh im bi translated"><strong class="ko iu">但是我们到底是如何制造出一辆能够自动驾驶的汽车的呢？</strong>仅仅将一台带有摄像头的电脑连接到汽车上是不够的，因为电脑看图像的方式与我们不同。看一看:</p><div class="li lj lk ll gt ab cb"><figure class="lz lm ma mb mc md me paragraph-image"><img src="../Images/3d4f17c19372317c7038ff0f94acc77b.png" data-original-src="https://miro.medium.com/v2/resize:fit:440/format:webp/0*X93HxqBzSoP1XCaQ.jpg"/></figure><figure class="lz lm mf mb mc md me paragraph-image"><img src="../Images/b21465fa217e06be935c4dc487df338e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1408/format:webp/0*T5As5vGkKeQ6HCaW.png"/></figure></div><p id="6a21" class="pw-post-body-paragraph kl km it ko b kp kq ju kr ks kt jx ku lp kw kx ky lq la lb lc lr le lf lg lh im bi translated">对我们来说，我们看到精致的形状和边缘，我们的<strong class="ko iu">大脑</strong>可以拼凑出一张脸。但是对一台计算机来说，他们看到的是一组<strong class="ko iu">多</strong>T8】多 T10】的数字。</p><p id="68c3" class="pw-post-body-paragraph kl km it ko b kp kq ju kr ks kt jx ku lp kw kx ky lq la lb lc lr le lf lg lh im bi translated">这么长时间以来，人类一直不知道如何教会计算机看东西。请想一想:</p><blockquote class="ki kj kk"><p id="fea8" class="kl km kn ko b kp kq ju kr ks kt jx ku kv kw kx ky kz la lb lc ld le lf lg lh im bi translated">如果给你一个装满数字的格子，你会用它做什么？你怎么能看穿这个？</p></blockquote><figure class="li lj lk ll gt lm gh gi paragraph-image"><div role="button" tabindex="0" class="lt lu di lv bf lw"><div class="gh gi ls"><img src="../Images/e9f4d26723a1a49e0ad33acf6446850f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*CZmNt1Nw-tfrniZDrwE2cg.png"/></div></div></figure><p id="be5c" class="pw-post-body-paragraph kl km it ko b kp kq ju kr ks kt jx ku lp kw kx ky lq la lb lc lr le lf lg lh im bi translated">更不用说，我上面用的亚伯拉罕·林肯的照片是黑白的。正常的彩色图像是 RGB(红绿蓝)格式，有 3 个独立的颜色通道，而不是 1 个，这意味着图像不仅仅是一个二维数组，而是一个三维数组。计算机如何识别这些数字中的模式来观察物体？这次，仅仅有一堆 if-else 语句是不够的。</p><p id="8a62" class="pw-post-body-paragraph kl km it ko b kp kq ju kr ks kt jx ku lp kw kx ky lq la lb lc lr le lf lg lh im bi translated"><strong class="ko iu">进入神经网络。</strong></p><figure class="li lj lk ll gt lm gh gi paragraph-image"><div role="button" tabindex="0" class="lt lu di lv bf lw"><div class="gh gi ls"><img src="../Images/00f1531a6545c0a60dfe47be24011356.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*yr6FpCrvDQOkjKvOgQ5Ilw.png"/></div></div></figure><p id="db15" class="pw-post-body-paragraph kl km it ko b kp kq ju kr ks kt jx ku lp kw kx ky lq la lb lc lr le lf lg lh im bi translated">神经网络受人脑工作方式的启发，由许多层相互连接的神经元组成，这些神经元共同工作。毕竟，如果我们的大脑能学会看东西，为什么人工大脑不能做到呢？神经网络允许计算机自学识别它希望完成的特定任务所需的复杂模式。在这种情况下，目标是教计算机看到并理解它所处的环境。</p><p id="f96c" class="pw-post-body-paragraph kl km it ko b kp kq ju kr ks kt jx ku lp kw kx ky lq la lb lc lr le lf lg lh im bi translated">教汽车看东西的最好方法是使用一种特殊类型的神经网络，称为<strong class="ko iu">卷积神经网络</strong>。</p><figure class="li lj lk ll gt lm gh gi paragraph-image"><div role="button" tabindex="0" class="lt lu di lv bf lw"><div class="gh gi ls"><img src="../Images/66cc3d72fe04163ee4f1c660aee5a68e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*oIDm45BTfqYF-VcE1vWmTA.png"/></div></div></figure><p id="b724" class="pw-post-body-paragraph kl km it ko b kp kq ju kr ks kt jx ku lp kw kx ky lq la lb lc lr le lf lg lh im bi translated"><strong class="ko iu">卷积神经网络</strong>(<strong class="ko iu">CNN</strong>)因其理解空间信息的惊人能力而被用于计算机视觉。这意味着如果我有一张人的照片，即使我旋转它，移动它，挤压和拉伸它，CNN 仍然会识别出它是一个人。</p><p id="dfb3" class="pw-post-body-paragraph kl km it ko b kp kq ju kr ks kt jx ku lp kw kx ky lq la lb lc lr le lf lg lh im bi translated">CNN 强大背后的关键是他们使用了一种叫做<strong class="ko iu">卷积层</strong>的特殊层，从图像中提取特征。初始卷积层识别边缘和拐角等低级特征。随着特征通过更多的卷积层，检测到的特征变得复杂得多。例如，用于检测人的卷积层可能会从边缘到形状到四肢再到人的整体。你可以在这篇<a class="ae mg" rel="noopener" target="_blank" href="/classifying-skin-lesions-with-convolutional-neural-networks-fc1302c60d54"> <strong class="ko iu">文章</strong> </a>中阅读更多关于卷积神经网络的内容。</p><div class="li lj lk ll gt ab cb"><figure class="lz lm mh mb mc md me paragraph-image"><div role="button" tabindex="0" class="lt lu di lv bf lw"><img src="../Images/a42bb47d9f61cd5f85cd57a8a6e65aff.png" data-original-src="https://miro.medium.com/v2/resize:fit:636/1*y2dCQAi4KR7D_nLdVf9xcQ.gif"/></div></figure><figure class="lz lm mi mb mc md me paragraph-image"><div role="button" tabindex="0" class="lt lu di lv bf lw"><img src="../Images/00800f8775b14a088341db39f79a7e95.png" data-original-src="https://miro.medium.com/v2/resize:fit:1366/format:webp/0*w35fVhUL_MUsAZf5.jpeg"/></div><figcaption class="mj mk gj gh gi ml mm bd b be z dk mn di mo mp">The architecture of Convolutional Neural Networks</figcaption></figure></div><p id="32df" class="pw-post-body-paragraph kl km it ko b kp kq ju kr ks kt jx ku lp kw kx ky lq la lb lc lr le lf lg lh im bi translated">卷积神经网络本身主要用于图像分类:给定一幅图像，网络将准确地指定给定的类别。例如，使用在皮肤病变数据集上训练的 CNN，它可以学习从给定的图像中诊断不同的皮肤癌。</p><figure class="li lj lk ll gt lm gh gi paragraph-image"><div role="button" tabindex="0" class="lt lu di lv bf lw"><div class="gh gi ls"><img src="../Images/d5d5eeefb00d9db3edcca57869abcaa5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ULdFRyiWR-Ktnxaz1awBcQ.png"/></div></div></figure><p id="0184" class="pw-post-body-paragraph kl km it ko b kp kq ju kr ks kt jx ku lp kw kx ky lq la lb lc lr le lf lg lh im bi translated">但是，如果我想知道的不仅仅是图像是否属于某个类，更具体地说，对象的确切位置是什么呢？此外，如果一个图像中有多个不同类别的对象，该怎么办？自动驾驶汽车不能只知道该区域有 5 辆车和 20 个人，它需要知道他们相对于自己的位置<strong class="ko iu">，以便安全导航</strong>。</p><figure class="li lj lk ll gt lm gh gi paragraph-image"><div role="button" tabindex="0" class="lt lu di lv bf lw"><div class="gh gi mq"><img src="../Images/f5fd22c34e92ed3cdf81dfc293872a4f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*7hj1o9-D8YO7opYn.jpg"/></div></div></figure><p id="82f1" class="pw-post-body-paragraph kl km it ko b kp kq ju kr ks kt jx ku lp kw kx ky lq la lb lc lr le lf lg lh im bi translated">这就是<strong class="ko iu">物体检测</strong>的用武之地。通过增强我们的卷积神经网络，我们可以重新利用其惊人的分类属性来定位图像中的类别。我们可以通过一种叫做<strong class="ko iu"> YOLO(你只看一次)</strong>的算法来做到这一点，这种算法可以进行实时物体检测，非常适合自动驾驶汽车。YOLO 非常快，使用 24 个卷积层，每秒可以处理高达 155 帧。这使得它很容易实现成为一辆<strong class="ko iu">自动驾驶汽车</strong>。那么它是如何工作的呢？</p><h1 id="e31a" class="mr ms it bd mt mu mv mw mx my mz na nb jz nc ka nd kc ne kd nf kf ng kg nh ni bi translated">#YOLO 解释道</h1><p id="fd64" class="pw-post-body-paragraph kl km it ko b kp nj ju kr ks nk jx ku lp nl kx ky lq nm lb lc lr nn lf lg lh im bi translated">正如研究论文所述，YOLO:</p><blockquote class="ki kj kk"><p id="df93" class="kl km kn ko b kp kq ju kr ks kt jx ku kv kw kx ky kz la lb lc ld le lf lg lh im bi translated">单个卷积神经网络同时预测多个<strong class="ko iu">边界框</strong>和这些框的<strong class="ko iu">类概率</strong></p></blockquote><p id="294a" class="pw-post-body-paragraph kl km it ko b kp kq ju kr ks kt jx ku lp kw kx ky lq la lb lc lr le lf lg lh im bi translated">YOLO 使用整个图像的特征来预测每个边界框和它们的类别，它同时进行<strong class="ko iu"/>。与人类相似，YOLO 几乎可以立即识别出给定图像中的物体位置和内容。</p><p id="9159" class="pw-post-body-paragraph kl km it ko b kp kq ju kr ks kt jx ku lp kw kx ky lq la lb lc lr le lf lg lh im bi translated">在运行一幅图像时，YOLO 首先将图像分成一个由 S 组成的网格。</p><figure class="li lj lk ll gt lm gh gi paragraph-image"><div role="button" tabindex="0" class="lt lu di lv bf lw"><div class="gh gi no"><img src="../Images/8d81443b35854d98021424bc88c3538d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*VaCtInm3Gb1dqmD-.jpeg"/></div></div></figure><p id="b32c" class="pw-post-body-paragraph kl km it ko b kp kq ju kr ks kt jx ku lp kw kx ky lq la lb lc lr le lf lg lh im bi translated">在每个网格单元内，YOLO 将预测预定数量的<strong class="ko iu">边界框</strong>的<strong class="ko iu">位置</strong>、<strong class="ko iu">大小</strong>和<strong class="ko iu">置信度得分</strong>——本质上是预测一个物体可能存在的类别和潜在位置。如果对象的中心落在网格单元中，则该网格单元的边界框负责准确定位和预测该对象。</p><figure class="li lj lk ll gt lm gh gi paragraph-image"><div class="gh gi np"><img src="../Images/dbb7c80de4f6577a660c68bdbb4e9e5f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1200/format:webp/0*syNYsUjxx79mY5LT.jpg"/></div><figcaption class="mj mk gj gh gi ml mm bd b be z dk">YOLO bounding boxes in action</figcaption></figure><p id="e246" class="pw-post-body-paragraph kl km it ko b kp kq ju kr ks kt jx ku lp kw kx ky lq la lb lc lr le lf lg lh im bi translated">每个边界框将有 5 个预测:x 坐标、y 坐标、宽度、高度和<strong class="ko iu">置信度</strong>。计算出的<strong class="ko iu">置信度得分</strong>表明模型认为在边界框内存在一个类的置信度，以及它认为该类适合该框的准确度，该框使用一种称为交集/并集的度量。</p><p id="16d2" class="pw-post-body-paragraph kl km it ko b kp kq ju kr ks kt jx ku lp kw kx ky lq la lb lc lr le lf lg lh im bi translated"><strong class="ko iu">并集上的交集</strong>用于对象检测，因为它将地面真实边界框与预测边界框进行比较。通过将重叠面积除以并集面积，我们得到一个函数，即<strong class="ko iu">奖励严重重叠</strong>而<strong class="ko iu">惩罚不准确的边界框预测</strong>。边界框的目标是最终尽可能精确地将对象限制在图像内，IoU 是确定这一点的一个很好的度量。</p><div class="li lj lk ll gt ab cb"><figure class="lz lm nq mb mc md me paragraph-image"><div role="button" tabindex="0" class="lt lu di lv bf lw"><img src="../Images/744698d4d38be93ba44a6f8861011928.png" data-original-src="https://miro.medium.com/v2/resize:fit:694/format:webp/0*K9w7rubmQzybVeii.png"/></div></figure><figure class="lz lm nr mb mc md me paragraph-image"><img src="../Images/6f1fe2b417c203971a419083f5589b49.png" data-original-src="https://miro.medium.com/v2/resize:fit:1200/format:webp/0*qHiINbzTkNhc5Jt7.png"/></figure></div><p id="5e80" class="pw-post-body-paragraph kl km it ko b kp kq ju kr ks kt jx ku lp kw kx ky lq la lb lc lr le lf lg lh im bi translated">在图像通过 YOLO 后，它输出 S x S x (B * 5 + C)张量中的预测，其中<strong class="ko iu">每个网格单元预测 C 个类别中 B 个边界框的位置和置信度得分</strong>。最终，我们得到了很多边界框——其中大部分与<strong class="ko iu">无关。</strong></p><p id="b111" class="pw-post-body-paragraph kl km it ko b kp kq ju kr ks kt jx ku lp kw kx ky lq la lb lc lr le lf lg lh im bi translated">为了过滤出正确的框，具有满足特定置信度分数的预测类的边界框将被保留。这允许我们隔离图像中的所有相关对象。</p><figure class="li lj lk ll gt lm gh gi paragraph-image"><div role="button" tabindex="0" class="lt lu di lv bf lw"><div class="gh gi no"><img src="../Images/1dec9e035a88749d8cb0dd725234e8b1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*UJ7DiL9NAWt0QwyT"/></div></div></figure><p id="cae9" class="pw-post-body-paragraph kl km it ko b kp kq ju kr ks kt jx ku lp kw kx ky lq la lb lc lr le lf lg lh im bi translated">本质上，YOLO 定位和分类图像/视频中的对象。<strong class="ko iu">像 YOLO 这样的物体检测</strong>算法，结合像 Li-Dar 这样的自动驾驶汽车上的许多其他传感器，使我们能够建造完全自动驾驶的汽车，比任何人都更快、更安全、更好。如果你有兴趣深入研究自动驾驶汽车，我强烈推荐你阅读<a class="ae mg" href="https://medium.com/@w.law/an-introduction-to-autonomous-vehicles-91d61ff81a40" rel="noopener"> <strong class="ko iu">这篇文章</strong> </a>。</p><p id="9792" class="pw-post-body-paragraph kl km it ko b kp kq ju kr ks kt jx ku lp kw kx ky lq la lb lc lr le lf lg lh im bi translated">既然你已经理解了 YOLO 的工作，<strong class="ko iu">让我们看看它是如何工作的</strong>。</p><h1 id="5134" class="mr ms it bd mt mu mv mw mx my mz na nb jz nc ka nd kc ne kd nf kf ng kg nh ni bi translated"><strong class="ak">奔跑的 YOLO </strong></h1><p id="61b3" class="pw-post-body-paragraph kl km it ko b kp nj ju kr ks nk jx ku lp nl kx ky lq nm lb lc lr nn lf lg lh im bi translated">要在您自己的计算机上试用 YOLO，<strong class="ko iu">将我的 GitHub 库克隆到您的计算机上。</strong></p><div class="ns nt gp gr nu nv"><a href="https://github.com/Sigil-Wen/YOLO" rel="noopener  ugc nofollow" target="_blank"><div class="nw ab fo"><div class="nx ab ny cl cj nz"><h2 class="bd iu gy z fp oa fr fs ob fu fw is bi translated">西吉尔-文/YOLO</h2><div class="oc l"><h3 class="bd b gy z fp oa fr fs ob fu fw dk translated">用 YOLO 检测物体(你只看一次)。要跑 YOLO，首先，下载链接的预训练重量…</h3></div><div class="od l"><p class="bd b dl z fp oa fr fs ob fu fw dk translated">github.com</p></div></div></div></a></div><p id="c1d1" class="pw-post-body-paragraph kl km it ko b kp kq ju kr ks kt jx ku lp kw kx ky lq la lb lc lr le lf lg lh im bi translated">然后从这个<a class="ae mg" href="https://drive.google.com/file/d/1sbrSFwp4lAgVVDKijGf7hlIzcDbu7Eu_/view" rel="noopener ugc nofollow" target="_blank"> <strong class="ko iu">链接</strong> </a> <strong class="ko iu"> </strong>下载预先训练好的重量，并将重量移动到名为<strong class="ko iu"> yolo-coco </strong>的文件夹中</p><figure class="li lj lk ll gt lm gh gi paragraph-image"><div class="gh gi oe"><img src="../Images/9c67bd9e725f9f2d0e8de0c6ea9de2cf.png" data-original-src="https://miro.medium.com/v2/resize:fit:832/format:webp/1*uVv12X1imfBuWINqkZ0WvA.png"/></div></figure><p id="f34e" class="pw-post-body-paragraph kl km it ko b kp kq ju kr ks kt jx ku lp kw kx ky lq la lb lc lr le lf lg lh im bi translated">在您的命令终端中，找到克隆的存储库，导入所需的依赖项和库，并输入以下命令在任何视频上运行 YOLO。</p><blockquote class="ki kj kk"><p id="0ebf" class="kl km kn ko b kp kq ju kr ks kt jx ku kv kw kx ky kz la lb lc ld le lf lg lh im bi translated">python yolo_video.py —输入<input path=""/> —输出<output path=""> — yolo yolo-coco</output></p></blockquote><figure class="li lj lk ll gt lm gh gi paragraph-image"><div role="button" tabindex="0" class="lt lu di lv bf lw"><div class="gh gi of"><img src="../Images/263bd2a2e1a68f4770a17c5e870c96ee.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*UrGlAL-VwCPAnyxzvvs2AA.png"/></div></div><figcaption class="mj mk gj gh gi ml mm bd b be z dk">Terminal Window</figcaption></figure><p id="f046" class="pw-post-body-paragraph kl km it ko b kp kq ju kr ks kt jx ku lp kw kx ky lq la lb lc lr le lf lg lh im bi translated">运行该命令后，YOLO 将在输入视频上运行，最终产品将出现在输出路径中。下面是我在 YOLO 看到的一些东西:</p><figure class="li lj lk ll gt lm"><div class="bz fp l di"><div class="ln lo l"/></div></figure><p id="49b7" class="pw-post-body-paragraph kl km it ko b kp kq ju kr ks kt jx ku lp kw kx ky lq la lb lc lr le lf lg lh im bi translated"><a class="ae mg" href="https://www.youtube.com/watch?v=AxhBu2uK86I&amp;" rel="noopener ugc nofollow" target="_blank">https://www.youtube.com/watch?v=AxhBu2uK86I&amp;T31】</a></p><p id="4264" class="pw-post-body-paragraph kl km it ko b kp kq ju kr ks kt jx ku lp kw kx ky lq la lb lc lr le lf lg lh im bi translated">这就对了。你理解并运行了一个物体检测算法！令人难以置信的是，我们距离一个由人工智能司机主导的世界有多近。</p><ul class=""><li id="b9dd" class="og oh it ko b kp kq ks kt lp oi lq oj lr ok lh ol om on oo bi translated">对跟随我的旅程感兴趣并想要更多这样的内容？跟着我上<strong class="ko iu">媒</strong>👇或者订阅我的<a class="ae mg" href="https://www.youtube.com/channel/UC68dN9l5fEaefElL728K6bA?sub_confirmation=1" rel="noopener ugc nofollow" target="_blank"> <strong class="ko iu"> YouTube 频道</strong> </a></li><li id="5234" class="og oh it ko b kp op ks oq lp or lq os lr ot lh ol om on oo bi translated">你可以在<a class="ae mg" href="https://www.linkedin.com/in/sigil-wen-081774163/" rel="noopener ugc nofollow" target="_blank"> <strong class="ko iu"> LinkedIn </strong> </a>和我联系，或者在 sigil.w3n@gmail.com 给我发邮件</li><li id="3898" class="og oh it ko b kp op ks oq lp or lq os lr ot lh ol om on oo bi translated">查看我的<a class="ae mg" href="https://sigilwen.ca" rel="noopener ugc nofollow" target="_blank"> <strong class="ko iu">个人网站</strong> </a>和<a class="ae mg" href="https://tks.life/profile/sigil.wen" rel="noopener ugc nofollow" target="_blank"> <strong class="ko iu">作品集</strong> </a></li><li id="b483" class="og oh it ko b kp op ks oq lp or lq os lr ot lh ol om on oo bi translated">看看我对 YOLO 的恶搞吧:<a class="ae mg" href="https://www.youtube.com/watch?v=AxhBu2uK86I&amp;" rel="noopener ugc nofollow" target="_blank">https://www.youtube.com/watch?v=AxhBu2uK86I&amp;T15】</a></li></ul></div></div>    
</body>
</html>