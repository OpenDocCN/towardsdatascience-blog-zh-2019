<html>
<head>
<title>XGBoost: An Intuitive Explanation</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">XGBoost:直观的解释</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/xgboost-an-intuitive-explanation-88eb32a48eff?source=collection_archive---------23-----------------------#2019-12-17">https://towardsdatascience.com/xgboost-an-intuitive-explanation-88eb32a48eff?source=collection_archive---------23-----------------------#2019-12-17</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/></div><div class="ab cl jq jr hx js" role="separator"><span class="jt bw bk ju jv jw"/><span class="jt bw bk ju jv jw"/><span class="jt bw bk ju jv"/></div><div class="im in io ip iq"><p id="de77" class="pw-post-body-paragraph jx jy it jz b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku im bi translated">我们都知道 XGBoost 是如何凭借性能和速度在 Kaggle 比赛中称霸的。这个博客是关于理解 XGBoost 是如何工作的(试着解释一下研究论文)。这篇博客不是关于如何编码/实现 XGboost 或者如何调优它的超参数。</p><p id="0796" class="pw-post-body-paragraph jx jy it jz b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku im bi translated">XGBoost 代表 e<strong class="jz iu">X</strong>treme<strong class="jz iu">G</strong>radient<strong class="jz iu">Boost</strong>ing。首先，回顾一下图 1 中的装袋和增压。它解释了 bagging(引导聚合)和 boosting(自适应 Boosting)。更准确地说，助推是如何添加到装袋的想法。在装袋过程中，随机选择不同袋子的数据点，并以相等的概率进行替换。在 boosting 中，基于迄今为止的模型性能来选择数据点。当创建一个新的包时，表现为<strong class="jz iu">差</strong>的数据点被赋予更多的权重。基于该重量，拾取数据点(轮盘赌类型选择)。XGBoost 基于类似的 boosting 思想(非随机地构造新的树)。</p><figure class="kw kx ky kz gt la gh gi paragraph-image"><div role="button" tabindex="0" class="lb lc di ld bf le"><div class="gh gi kv"><img src="../Images/ef68bec585cb4af9aadc1353179c8430.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*REinrEWZyRV_bszFjp4Q1g.png"/></div></div><figcaption class="lh li gj gh gi lj lk bd b be z dk">Figure 1. Bagging vs Boosting</figcaption></figure><p id="313a" class="pw-post-body-paragraph jx jy it jz b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku im bi translated">类似于 boosting，我们在 XGBoost 中基于模型到目前为止的性能构建一个新的树。图 2 给出了构建新树背后的符号和数学。</p><figure class="kw kx ky kz gt la gh gi paragraph-image"><div role="button" tabindex="0" class="lb lc di ld bf le"><div class="gh gi ll"><img src="../Images/c0983dc183d1e5603fd1feb20305f4bd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*aCKicSNWNuqNtZvfQ4AoEQ.png"/></div></div><figcaption class="lh li gj gh gi lj lk bd b be z dk">Figure 2. Building a new Tree in XGBoost</figcaption></figure><p id="acf2" class="pw-post-body-paragraph jx jy it jz b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku im bi translated">上面的步骤显示了当树按顺序构建时(像在 boosting 中)，如何计算新的<strong class="jz iu">树的权重。如果我们知道树的结构<em class="lm"> q </em>，我们就可以在方程(3)中获得根的权重和得分函数。<strong class="jz iu">但是我们不知道<em class="lm"> q </em> </strong>并且不可能枚举和尝试每一个树形结构。在寻找树的过程中，在树性能和计算工作量之间有一个折衷(取决于算法)。论文中提到的算法的要点如图 3 所示。</strong></p><figure class="kw kx ky kz gt la gh gi paragraph-image"><div role="button" tabindex="0" class="lb lc di ld bf le"><div class="gh gi ll"><img src="../Images/8800908b9e539128aa7c710e4a002096.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*kSU360yge1SeUBmek_CyWQ.png"/></div></div><figcaption class="lh li gj gh gi lj lk bd b be z dk">Figure 3. Finding the tree structure <strong class="bd ln">q</strong></figcaption></figure><p id="db28" class="pw-post-body-paragraph jx jy it jz b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku im bi translated">这是本文的前三部分。第 4 节涉及系统设计(更多的是从数据工程师的角度，我个人没有这方面的专业知识)。第 5 节讨论以前的工作，第 6 节显示 XGBoost 性能评估。</p><p id="d990" class="pw-post-body-paragraph jx jy it jz b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku im bi translated">XGBoost 的开发者做了大量的工作<strong class="jz iu">超越了</strong>仅仅是开发一个新的算法来构建树。其中包括:</p><ol class=""><li id="b40f" class="lo lp it jz b ka kb ke kf ki lq km lr kq ls ku lt lu lv lw bi translated">他们使它们在计算上高效(这使得扩展 XGBoost 和在非花哨的计算设备上实现成为可能)。</li><li id="a5ab" class="lo lp it jz b ka lx ke ly ki lz km ma kq mb ku lt lu lv lw bi translated">XGBoost 可以处理缺失和稀疏的数据</li><li id="ac02" class="lo lp it jz b ka lx ke ly ki lz km ma kq mb ku lt lu lv lw bi translated">它基于并行和分布式计算(可以在短时间内处理数百万个数据点，允许快速的模型探索)</li></ol><p id="4503" class="pw-post-body-paragraph jx jy it jz b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku im bi translated"><strong class="jz iu">参考文献:</strong> <br/> <a class="ae mc" href="http://dmlc.cs.washington.edu/xgboost.html" rel="noopener ugc nofollow" target="_blank"> XGBoost:一个可扩展的树提升系统</a>(原文)<br/> <a class="ae mc" href="https://machinelearningmastery.com/gentle-introduction-xgboost-applied-machine-learning/" rel="noopener ugc nofollow" target="_blank">机器学习掌握</a>(解释 XGBoost 的优点)<br/> <a class="ae mc" href="https://www.youtube.com/watch?v=Vly8xGnNiWs&amp;feature=emb_logo" rel="noopener ugc nofollow" target="_blank">谈 XGBoost 陈</a>(XGBoost 的主要作者)<br/> <a class="ae mc" href="https://www.youtube.com/watch?v=2Mg8QD0F1dQ" rel="noopener ugc nofollow" target="_blank">打包</a> (Udacity 视频)<br/> <a class="ae mc" href="https://www.youtube.com/watch?v=GM3CDQfQ4sw" rel="noopener ugc nofollow" target="_blank">提升</a> (Udacity 视频)</p><p id="aa8a" class="pw-post-body-paragraph jx jy it jz b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku im bi translated">我希望这篇博客对理解 XGBoost 背后的逻辑有所帮助。如果有错误或不清楚的地方，请写信给 ucdavis.edu 的 ashnayak</p></div><div class="ab cl jq jr hx js" role="separator"><span class="jt bw bk ju jv jw"/><span class="jt bw bk ju jv jw"/><span class="jt bw bk ju jv"/></div><div class="im in io ip iq"><p id="a2a5" class="pw-post-body-paragraph jx jy it jz b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku im bi translated"><em class="lm">原载于 2019 年 12 月 17 日 https://medium.com</em><em class="lm">的</em><a class="ae mc" href="https://medium.com/@ashutoshnayakkgp/xgboost-an-intuitive-explanation-9843b4ac4509" rel="noopener">T22。</a></p></div></div>    
</body>
</html>