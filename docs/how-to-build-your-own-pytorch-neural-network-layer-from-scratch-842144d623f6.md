# å¦‚ä½•ä»é›¶å¼€å§‹æ„å»ºè‡ªå·±çš„ PyTorch ç¥ç»ç½‘ç»œå±‚

> åŸæ–‡ï¼š<https://towardsdatascience.com/how-to-build-your-own-pytorch-neural-network-layer-from-scratch-842144d623f6?source=collection_archive---------7----------------------->

## å¹¶äº†è§£ä¸€äº›å…³äºæƒé‡åˆå§‹åŒ–çš„çŸ¥è¯†

![](img/4fc2d2bffd247d756fdd4f0645d164c0.png)

è¿™å®é™…ä¸Šæ˜¯æ°ç‘ç±³Â·éœåå¾·ç¬¬äº”è¯¾çš„ä½œä¸šã€‚æˆ‘å·²ç»å±•ç¤ºäº†ä½¿ç”¨ PyTorch ä»é›¶å¼€å§‹æ„å»ºå·ç§¯ç¥ç»ç½‘ç»œæ˜¯å¤šä¹ˆå®¹æ˜“ã€‚ä»Šå¤©ï¼Œè®©æˆ‘ä»¬è¯•ç€æ›´æ·±å…¥åœ°ç ”ç©¶ä¸€ä¸‹ï¼Œçœ‹çœ‹æˆ‘ä»¬æ˜¯å¦å¯ä»¥ç¼–å†™è‡ªå·±çš„`nn.Linear`æ¨¡å—ã€‚æ—¢ç„¶è„¸ä¹¦çš„å¼€å‘äººå‘˜å·²ç»å†™å¥½äº† PyTorch æ¨¡å—ï¼Œä¸ºä»€ä¹ˆè¿˜è¦æµªè´¹æ—¶é—´å†™è‡ªå·±çš„å‘¢ï¼Ÿ

å—¯ï¼Œé¦–å…ˆï¼Œä½ ä¼šå¯¹æ‰€æœ‰çš„éƒ¨åˆ†æ˜¯å¦‚ä½•ç»„åˆåœ¨ä¸€èµ·çš„æœ‰æ›´æ·±çš„ç†è§£ã€‚é€šè¿‡å°†æ‚¨çš„ä»£ç ä¸ PyTorch ä»£ç è¿›è¡Œæ¯”è¾ƒï¼Œæ‚¨å°†äº†è§£ä¸ºä»€ä¹ˆä»¥åŠå¦‚ä½•å¼€å‘è¿™äº›åº“ã€‚

æ­¤å¤–ï¼Œä¸€æ—¦ä½ å®Œæˆäº†ï¼Œä½ å°†å¯¹å®ç°å’Œä½¿ç”¨æ‰€æœ‰è¿™äº›åº“æ›´æœ‰ä¿¡å¿ƒï¼ŒçŸ¥é“äº‹æƒ…æ˜¯å¦‚ä½•å·¥ä½œçš„ã€‚å¯¹ä½ æ¥è¯´ä¸ä¼šæœ‰ç¥è¯ã€‚

æœ€åä½†åŒæ ·é‡è¦çš„æ˜¯ï¼Œå¦‚æœæƒ…å†µéœ€è¦ï¼Œæ‚¨å°†èƒ½å¤Ÿä¿®æ”¹/è°ƒæ•´è¿™äº›æ¨¡å—ã€‚è¿™å°±æ˜¯ noob å’Œ pro çš„åŒºåˆ«ã€‚

å¥½äº†ï¼ŒåŠ¨æœºå¤Ÿäº†ï¼Œè®©æˆ‘ä»¬å¼€å§‹å§ã€‚

## ç®€å•çš„ MNIST ä¸€å±‚ NN ä½œä¸ºèƒŒæ™¯

é¦–å…ˆï¼Œæˆ‘ä»¬éœ€è¦ä¸€äº›â€œèƒŒæ™¯â€ä»£ç æ¥æµ‹è¯•æˆ‘ä»¬çš„æ¨¡å—æ˜¯å¦æ‰§è¡Œä»¥åŠæ‰§è¡Œå¾—æœ‰å¤šå¥½ã€‚è®©æˆ‘ä»¬å»ºç«‹ä¸€ä¸ªéå¸¸ç®€å•çš„å•å±‚ç¥ç»ç½‘ç»œæ¥æ±‚è§£å¤è€çš„ MNIST æ•°æ®é›†ã€‚ä¸‹é¢çš„ä»£ç ç‰‡æ®µ(åœ¨ Jupyter ç¬”è®°æœ¬ä¸­è¿è¡Œ):

```
# We'll use fast.ai to showcase how to build your own 'nn.Linear' module
%matplotlib inline
from fastai.basics import *
import sys

# create and download/prepare our MNIST dataset
path = Config().data_path()/'mnist'
path.mkdir(parents=True)
!wget http://deeplearning.net/data/mnist/mnist.pkl.gz -P {path}

# Get the images downloaded into data set
with gzip.open(path/'mnist.pkl.gz', 'rb') as f:
    ((x_train, y_train), (x_valid, y_valid), _) = pickle.load(f, encoding='latin-1')

# Have a look at the images and shape
plt.imshow(x_train[0].reshape((28,28)), cmap="gray")
x_train.shape

# convert numpy into PyTorch tensor
x_train,y_train,x_valid,y_valid = map(torch.tensor, (x_train,y_train,x_valid,y_valid))
n,c = x_train.shape
x_train.shape, y_train.min(), y_train.max()

# prepare dataset and create fast.ai DataBunch for training
bs=64
train_ds = TensorDataset(x_train, y_train)
valid_ds = TensorDataset(x_valid, y_valid)
data = DataBunch.create(train_ds, valid_ds, bs=bs)

# create a simple MNIST logistic model with only one Linear layer
class Mnist_Logistic(nn.Module):
    def __init__(self):
        super().__init__()
        self.lin = nn.Linear(784, 10, bias=True)

    def forward(self, xb): return self.lin(xb)

model =Mnist_Logistic()

lr=2e-2
loss_func = nn.CrossEntropyLoss()

# define update function with weight decay
def update(x,y,lr):
    wd = 1e-5
    y_hat = model(x)
    # weight decay
    w2 = 0.
    for p in model.parameters(): w2 += (p**2).sum()
    # add to regular loss
    loss = loss_func(y_hat, y) + w2*wd
    loss.requres_grad = True

    loss.backward()
    with torch.no_grad():
        for p in model.parameters():
            p.sub_(lr * p.grad)
            p.grad.zero_()
    return loss.item()

# iterate through one epoch and plot losses
losses = [update(x,y,lr) for x,y in data.train_dl]
plt.plot(losses);
```

![](img/87118bc3c56d37b557aa66ccdec73a38.png)

è¿™äº›ä»£ç å¾ˆå®¹æ˜“ç†è§£ã€‚æˆ‘ä»¬åœ¨è¿™ä¸ªé¡¹ç›®ä¸­ä½¿ç”¨äº† [fast.ai](https://github.com/fastai) åº“ã€‚ä¸‹è½½ MNIST pickle æ–‡ä»¶å¹¶è§£å‹ç¼©ï¼Œå°†å…¶è½¬æ¢ä¸º PyTorch å¼ é‡ï¼Œç„¶åå°†å…¶å¡«å……åˆ° fast.ai DataBunch å¯¹è±¡ä¸­ï¼Œä»¥ä¾¿è¿›ä¸€æ­¥è®­ç»ƒã€‚ç„¶åæˆ‘ä»¬åˆ›å»ºäº†ä¸€ä¸ªåªæœ‰ä¸€ä¸ª`Linear`å±‚çš„ç®€å•ç¥ç»ç½‘ç»œã€‚æˆ‘ä»¬è¿˜ç¼–å†™äº†è‡ªå·±çš„`update`å‡½æ•°ï¼Œè€Œä¸æ˜¯ä½¿ç”¨`torch.optim`ä¼˜åŒ–å™¨ï¼Œå› ä¸ºæˆ‘ä»¬å¯ä»¥ä»å¤´å¼€å§‹ç¼–å†™è‡ªå·±çš„ä¼˜åŒ–å™¨ï¼Œä½œä¸º PyTorch å­¦ä¹ ä¹‹æ—…çš„ä¸‹ä¸€æ­¥ã€‚æœ€åï¼Œæˆ‘ä»¬éå†æ•°æ®é›†å¹¶ç»˜åˆ¶æŸå¤±å›¾ï¼Œä»¥æŸ¥çœ‹å®ƒæ˜¯å¦æœ‰æ•ˆä»¥åŠæ•ˆæœå¦‚ä½•ã€‚

## ç¬¬ä¸€æ¬¡è¿­ä»£:è®©å®ƒå·¥ä½œ

æ‰€æœ‰ PyTorch æ¨¡å—/å±‚éƒ½æ˜¯ä»`torch.nn.Module`æ‰©å±•è€Œæ¥ã€‚

```
class myLinear(nn.Module):
```

åœ¨è¿™ä¸ªç±»ä¸­ï¼Œæˆ‘ä»¬éœ€è¦ä¸€ä¸ª`__init__` dunder å‡½æ•°æ¥åˆå§‹åŒ–æˆ‘ä»¬çš„çº¿æ€§å±‚ï¼Œå¹¶éœ€è¦ä¸€ä¸ª`forward`å‡½æ•°æ¥è¿›è¡Œæ­£å‘è®¡ç®—ã€‚è®©æˆ‘ä»¬å…ˆæ¥çœ‹çœ‹`__init__`å‡½æ•°ã€‚

æˆ‘ä»¬å°†ä½¿ç”¨ PyTorch å®˜æ–¹æ–‡æ¡£ä½œä¸ºæ„å»ºæ¨¡å—çš„æŒ‡å—ã€‚ä»æ–‡æ¡£ä¸­å¯ä»¥çœ‹å‡ºï¼Œ`nn.Linear`æ¨¡å—å…·æœ‰ä»¥ä¸‹å±æ€§:

[![](img/b4ec4e8cd4a40df76e806dffba33d0a3.png)](https://pytorch.org/docs/stable/nn.html#linear)

å› æ­¤ï¼Œæˆ‘ä»¬å°†è·å¾—è¿™ä¸‰ä¸ªå±æ€§:

```
def __init__(self, **in_features, out_features, bias=True**):
        super().__init__()
       ** self.in_features = in_features
        self.out_features = out_features
        self.bias = bias**
```

è¯¥ç±»è¿˜éœ€è¦ä¿å­˜é‡é‡å’Œåå·®å‚æ•°ï¼Œä»¥ä¾¿è¿›è¡Œè®­ç»ƒã€‚æˆ‘ä»¬ä¹Ÿåˆå§‹åŒ–é‚£äº›ã€‚

![](img/8f25b7ddfc61ec19951380c54192835f.png)

```
 ** self.weight** = torch.nn.Parameter(torch.randn(out_features, in_features))
       ** self.bias** = torch.nn.Parameter(torch.randn(out_features))
```

è¿™é‡Œæˆ‘ä»¬ç”¨`torch.nn.Parameter`æ¥è®¾ç½®æˆ‘ä»¬çš„`weight`å’Œ`bias`ï¼Œå¦åˆ™ï¼Œå®ƒä¸ä¼šè®­ç»ƒã€‚

å¦å¤–ï¼Œè¯·æ³¨æ„ï¼Œæˆ‘ä»¬ä½¿ç”¨äº†`[torch.rand](https://pytorch.org/docs/stable/torch.html#torch.randn)n`è€Œä¸æ˜¯æ–‡æ¡£ä¸­æè¿°çš„æ¥åˆå§‹åŒ–å‚æ•°ã€‚è¿™ä¸æ˜¯æƒé‡åˆå§‹åŒ–çš„æœ€ä½³æ–¹å¼ï¼Œä½†æˆ‘ä»¬çš„ç›®çš„æ˜¯è®©å®ƒå…ˆå·¥ä½œï¼Œæˆ‘ä»¬å°†åœ¨ä¸‹ä¸€æ¬¡è¿­ä»£ä¸­è°ƒæ•´å®ƒã€‚

å¥½äº†ï¼Œç°åœ¨`__init__`éƒ¨åˆ†å®Œæˆäº†ï¼Œè®©æˆ‘ä»¬ç»§ç»­`forward`åŠŸèƒ½ã€‚è¿™å®é™…ä¸Šæ˜¯æœ€ç®€å•çš„éƒ¨åˆ†:

```
def forward(self, input):
        _, y = input.shape
        if y != self.in_features:
            sys.exit(f'Wrong Input Features. Please use tensor with {self.in_features} Input Features')
        **output = input @ self.weight.t() + self.bias
        return output**
```

æˆ‘ä»¬é¦–å…ˆè·å¾—è¾“å…¥çš„å½¢çŠ¶ï¼Œè®¡ç®—å‡ºè¾“å…¥ä¸­æœ‰å¤šå°‘åˆ—ï¼Œç„¶åæ£€æŸ¥è¾“å…¥å¤§å°æ˜¯å¦åŒ¹é…ã€‚ç„¶åæˆ‘ä»¬åšçŸ©é˜µä¹˜æ³•(æ³¨æ„æˆ‘ä»¬åœ¨è¿™é‡Œåšäº†è½¬ç½®æ¥è°ƒæ•´æƒé‡)å¹¶è¿”å›ç»“æœã€‚æˆ‘ä»¬å¯ä»¥é€šè¿‡ç»™å®ƒä¸€äº›æ•°æ®æ¥æµ‹è¯•å®ƒæ˜¯å¦æœ‰æ•ˆ:

```
my = myLinear(20,10)
a = torch.randn(5,20)
my(a)
```

æˆ‘ä»¬æœ‰ä¸€ä¸ª 5x20 çš„è¾“å…¥ï¼Œå®ƒé€šè¿‡æˆ‘ä»¬çš„å±‚ï¼Œå¾—åˆ°ä¸€ä¸ª 5x10 çš„è¾“å‡ºã€‚æ‚¨åº”è¯¥ä¼šå¾—åˆ°è¿™æ ·çš„ç»“æœ:

![](img/43f920d9c13ef78c6b8d4960099481ed.png)

å¥½ï¼Œç°åœ¨å›åˆ°æˆ‘ä»¬çš„ç¥ç»ç½‘ç»œä»£ç ï¼Œæ‰¾åˆ°`Mnist_Logistic`ç±»ï¼Œå°†`self.lin = nn.Linear(784,10, bias=True)`æ”¹ä¸º`self.lin = myLinear(784, 10, bias=True)`ã€‚è¿è¡Œä»£ç ï¼Œæ‚¨åº”è¯¥ä¼šçœ‹åˆ°ç±»ä¼¼è¿™æ ·çš„å›¾:

![](img/3f8165786fd3813b281e1c5eb84c436b.png)

å¦‚ä½ æ‰€è§ï¼Œå®ƒæ²¡æœ‰å¾ˆå¥½åœ°æ”¶æ•›(ä¸€ä¸ªæ—¶æœŸå¤§çº¦ 2.5 æ¬¡æŸå¤±)ã€‚é‚£å¾ˆå¯èƒ½æ˜¯å› ä¸ºæˆ‘ä»¬åˆå§‹åŒ–ä¸å¥½ã€‚å¦å¤–ï¼Œæˆ‘ä»¬æ²¡æœ‰æ³¨æ„åˆ°`bias`éƒ¨åˆ†ã€‚è®©æˆ‘ä»¬åœ¨ä¸‹ä¸€æ¬¡è¿­ä»£ä¸­è§£å†³è¿™ä¸ªé—®é¢˜ã€‚ç¬¬ä¸€æ¬¡è¿­ä»£çš„æœ€ç»ˆä»£ç å¦‚ä¸‹æ‰€ç¤º:

```
class myLinear(nn.Module):
    def __init__(self, in_features, out_features, bias=True):
        super().__init__()
        self.in_features = in_features
        self.out_features = out_features
        self.bias = bias
        self.weight = torch.nn.Parameter(torch.randn(out_features, in_features))
        self.bias = torch.nn.Parameter(torch.randn(out_features))

    def forward(self, input):
        x, y = input.shape
        if y != self.in_features:
            sys.exit(f'Wrong Input Features. Please use tensor with {self.in_features} Input Features')
        output = input @ self.weight.t() + self.bias
        return output
```

## ç¬¬äºŒæ¬¡è¿­ä»£:æ­£ç¡®çš„æƒé‡åˆå§‹åŒ–å’Œåå·®å¤„ç†

æˆ‘ä»¬å·²ç»å¤„ç†äº†`__init__`å’Œ`forward`ï¼Œä½†æ˜¯è®°ä½æˆ‘ä»¬è¿˜æœ‰ä¸€ä¸ª`bias`å±æ€§ï¼Œå¦‚æœ`False`ï¼Œå°†ä¸ä¼šå­¦ä¹ åŠ æ³•åå·®ã€‚æˆ‘ä»¬è¿˜æ²¡æœ‰å®æ–½ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬ä½¿ç”¨`torch.nn.randn`æ¥åˆå§‹åŒ–æƒé‡å’Œåå·®ï¼Œè¿™ä¸æ˜¯æœ€ä½³çš„ã€‚è®©æˆ‘ä»¬è§£å†³è¿™ä¸ªé—®é¢˜ã€‚æ›´æ–°åçš„`__init__`å‡½æ•°å¦‚ä¸‹:

```
def __init__(self, in_features, out_features, bias=True):
        super().__init__()
        self.in_features = in_features
        self.out_features = out_features
        self.bias = bias
        **self.weight = torch.nn.Parameter(torch.Tensor(out_features, in_features))
        if bias:
            self.bias = torch.nn.Parameter(torch.Tensor(out_features))
        else:
            self.register_parameter('bias', None)** **self.reset_parameters()**
```

é¦–å…ˆï¼Œå½“æˆ‘ä»¬åˆ›å»º`weight`å’Œ`bias`å‚æ•°æ—¶ï¼Œæˆ‘ä»¬æ²¡æœ‰å°†å®ƒä»¬åˆå§‹åŒ–ä¸ºæœ€åä¸€æ¬¡è¿­ä»£ã€‚æˆ‘ä»¬åªæ˜¯ç»™å®ƒåˆ†é…ä¸€ä¸ªè§„åˆ™çš„å¼ é‡å¯¹è±¡ã€‚å®é™…çš„åˆå§‹åŒ–åœ¨å¦ä¸€ä¸ªå‡½æ•°`reset_parameters`ä¸­å®Œæˆ(*å°†åœ¨åé¢è§£é‡Š*)ã€‚

å¯¹äº`bias`ï¼Œæˆ‘ä»¬å¢åŠ äº†ä¸€ä¸ªæ¡ä»¶ï¼Œå¦‚æœ`True`ï¼Œåšæˆ‘ä»¬ä¸Šä¸€æ¬¡è¿­ä»£åšçš„äº‹æƒ…ï¼Œä½†æ˜¯å¦‚æœ`False`ï¼Œå°†ä½¿ç”¨`register_parameter(â€˜biasâ€™, None)`ç»™å®ƒ`None`å€¼ã€‚ç°åœ¨å¯¹äº`reset_parameter`åŠŸèƒ½ï¼Œå®ƒçœ‹èµ·æ¥æ˜¯è¿™æ ·çš„:

```
def reset_parameters(self):
        **torch.nn.init.kaiming_uniform_(self.weight, a=math.sqrt(5))**
        if self.bias is not None:
            **fan_in, _ torch.nn.init._calculate_fan_in_and_fan_out(self.weight)
            bound = 1 / math.sqrt(fan_in)
            torch.nn.init.uniform_(self.bias, -bound, bound)**
```

ä»¥ä¸Šä»£ç ç›´æ¥å–è‡ª PyTorch æºä»£ç ã€‚PyTorch å¯¹æƒé‡åˆå§‹åŒ–æ‰€åšçš„ç§°ä¸º`kaiming_uniform_`ã€‚å®ƒæ¥è‡ªä¸€ç¯‡è®ºæ–‡[æ·±å…¥ç ”ç©¶æ•´æµå™¨:åœ¨ ImageNet åˆ†ç±»ä¸Šè¶…è¶Šäººç±»æ°´å¹³çš„æ€§èƒ½â€”â€”ä½•ï¼Œk .ç­‰äºº(2015)](https://arxiv.org/pdf/1502.01852.pdf) ã€‚

![](img/6886e67fa7fd0d400f96a6562a6376eb.png)

å®ƒå®é™…ä¸Šæ‰€åšçš„æ˜¯é€šè¿‡ç”¨å‡å€¼ä¸º 0 ä¸”æ–¹å·®ä¸º T16 çš„æ­£æ€åˆ†å¸ƒ**åˆå§‹åŒ–æƒé‡ï¼Œå®ƒé¿å…äº†**æ¶ˆå¤±/çˆ†ç‚¸æ¢¯åº¦**çš„é—®é¢˜(*å°½ç®¡æˆ‘ä»¬åœ¨è¿™é‡Œåªæœ‰ä¸€å±‚ï¼Œå½“ç¼–å†™çº¿æ€§ç±»æ—¶ï¼Œæˆ‘ä»¬ä»ç„¶åº”è¯¥è®°ä½ MLN*)ã€‚**

è¯·æ³¨æ„ï¼Œå¯¹äº`self.weight`ï¼Œæˆ‘ä»¬å®é™…ä¸Šç»™äº†`a`ä¸€ä¸ªå€¼`math.sqrt(5)`è€Œä¸æ˜¯`math.sqrt(fan_in)`ï¼Œè¿™åœ¨ PyTorch repo çš„ [this GitHub issue](https://github.com/pytorch/pytorch/issues/15314) ä¸­æœ‰æ‰€è§£é‡Šï¼Œå¯èƒ½æœ‰äººå¯¹æ­¤æ„Ÿå…´è¶£ã€‚

åŒæ ·ï¼Œæˆ‘ä»¬å¯ä»¥åœ¨æ¨¡å‹ä¸­æ·»åŠ ä¸€äº›`extra_repr`å­—ç¬¦ä¸²:

```
def extra_repr(self):
        return 'in_features={}, out_features={}, bias={}'.format(
            self.in_features, self.out_features, self.bias is not None
        )
```

æœ€ç»ˆçš„æ¨¡å‹å¦‚ä¸‹æ‰€ç¤º:

```
class myLinear(nn.Module):
    def __init__(self, in_features, out_features, bias=True):
        super().__init__()
        self.in_features = in_features
        self.out_features = out_features
        self.bias = bias
        self.weight = torch.nn.Parameter(torch.Tensor(out_features, in_features))
        if bias:
            self.bias = torch.nn.Parameter(torch.Tensor(out_features))
        else:
            self.register_parameter('bias', None)
        self.reset_parameters()

    def reset_parameters(self):
        torch.nn.init.kaiming_uniform_(self.weight, a=math.sqrt(5))
        if self.bias is not None:
            fan_in, _ = torch.nn.init._calculate_fan_in_and_fan_out(self.weight)
            bound = 1 / math.sqrt(fan_in)
            torch.nn.init.uniform_(self.bias, -bound, bound)

    def forward(self, input):
        x, y = input.shape
        if y != self.in_features:
            print(f'Wrong Input Features. Please use tensor with {self.in_features} Input Features')
            return 0
        output = input.matmul(weight.t())
        if bias is not None:
            output += bias
        ret = output
        return ret

    def extra_repr(self):
        return 'in_features={}, out_features={}, bias={}'.format(
            self.in_features, self.out_features, self.bias is not None
        )
```

é‡æ–°è¿è¡Œä»£ç ï¼Œæ‚¨åº”è¯¥èƒ½å¤Ÿçœ‹åˆ°è¿™ä¸ªå›¾:

![](img/d515b224aa298e7ae0654cdba9dcbad2.png)

æˆ‘ä»¬å¯ä»¥çœ‹åˆ°ï¼Œå®ƒåœ¨ä¸€ä¸ªæ—¶æœŸå†…æ”¶æ•›åˆ° 0.5 çš„æŸè€—è¦å¿«å¾—å¤šã€‚

## ç»“è®º

æˆ‘å¸Œæœ›è¿™èƒ½å¸®ä½ é©±æ•£è¿™äº› PyTorch `nn.modules`ä¸Šçš„é˜´éœ¾ã€‚è¿™å¯èƒ½çœ‹èµ·æ¥å¾ˆæ— èŠå’Œå¤šä½™ï¼Œä½†æœ‰æ—¶æœ€å¿«(ä¹Ÿæ˜¯æœ€çŸ­)çš„æ–¹æ³•å°±æ˜¯â€œæ— èŠâ€çš„æ–¹æ³•ã€‚ä¸€æ—¦ä½ æ·±ç©¶æ­¤äº‹ï¼Œé‚£ç§çŸ¥é“æ²¡æœ‰ä»€ä¹ˆâ€œæ›´å¤šâ€çš„æ„Ÿè§‰æ˜¯æ— ä»·çš„ã€‚ä½ ä¼šæ„è¯†åˆ°:

> åœ¨ PyTorch ä¸‹é¢ï¼Œæ²¡æœ‰æŠ€å·§ï¼Œæ²¡æœ‰ç¥è¯ï¼Œæ²¡æœ‰é™·é˜±ï¼Œåªæœ‰åšå¦‚ç£çŸ³çš„ Python ä»£ç ã€‚

æ­¤å¤–ï¼Œé€šè¿‡ç¼–å†™è‡ªå·±çš„ä»£ç ï¼Œç„¶åä¸å®˜æ–¹æºä»£ç è¿›è¡Œæ¯”è¾ƒï¼Œæ‚¨å°†èƒ½å¤Ÿçœ‹åˆ°ä¸åŒä¹‹å¤„ï¼Œå¹¶å‘è¡Œä¸šä¸­çš„ä½¼ä½¼è€…å­¦ä¹ ã€‚å¤šé…·å•Šã€‚

è§‰å¾—è¿™ç¯‡æ–‡ç« æœ‰ç”¨ï¼Ÿåœ¨ Medium ä¸Šå…³æ³¨æˆ‘([æç«‹ä¼Ÿ](https://medium.com/u/72c98619a048?source=post_page-----dbe7106145f5----------------------))æˆ–è€…ä½ å¯ä»¥åœ¨ Twitter [@lymenlee](https://twitter.com/lymenlee) æˆ–è€…æˆ‘çš„åšå®¢ç½‘ç«™[wayofnumbers.com](https://wayofnumbers.com/)ä¸Šæ‰¾åˆ°æˆ‘ã€‚ä½ ä¹Ÿå¯ä»¥çœ‹çœ‹æˆ‘ä¸‹é¢æœ€å—æ¬¢è¿çš„æ–‡ç« ï¼

[](/this-is-cs50-a-pleasant-way-to-kick-off-your-data-science-education-d6075a6e761a) [## â€œè¿™æ˜¯ CS50â€:å¼€å§‹æ•°æ®ç§‘å­¦æ•™è‚²çš„æ„‰å¿«æ–¹å¼

### ä¸ºä»€ä¹ˆ CS50 ç‰¹åˆ«é€‚åˆå·©å›ºä½ çš„è½¯ä»¶å·¥ç¨‹åŸºç¡€

towardsdatascience.com](/this-is-cs50-a-pleasant-way-to-kick-off-your-data-science-education-d6075a6e761a) [](/two-sides-of-the-same-coin-fast-ai-vs-deeplearning-ai-b67e9ec32133) [## ä¸€æšç¡¬å¸çš„ä¸¤é¢:æ°ç‘ç±³Â·éœåå¾·çš„ fast.ai vs å´æ©è¾¾çš„ deeplearning.ai

### å¦‚ä½•ä¸é€šè¿‡åŒæ—¶å‚åŠ  fast.ai å’Œ deeplearning.ai è¯¾ç¨‹æ¥â€œè¿‡åº¦é€‚åº”â€ä½ çš„äººå·¥æ™ºèƒ½å­¦ä¹ 

towardsdatascience.com](/two-sides-of-the-same-coin-fast-ai-vs-deeplearning-ai-b67e9ec32133) [](/what-you-need-to-know-about-netflixs-jupyter-killer-polynote-dbe7106145f5) [## ä½ éœ€è¦äº†è§£ç½‘é£çš„â€œæœ±åº‡ç‰¹é»‘ä»”â€:å†°ç©´ğŸ“–

### æ˜¯æ—¶å€™è®© Jupyter ç¬”è®°æœ¬æœ‰ä¸ªæœ‰ä»·å€¼çš„ç«äº‰å¯¹æ‰‹äº†

towardsdatascience.com](/what-you-need-to-know-about-netflixs-jupyter-killer-polynote-dbe7106145f5)