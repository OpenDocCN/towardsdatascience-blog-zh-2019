<html>
<head>
<title>Residual Networks: Implementing ResNet in Pytorch</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">å‰©ä½™ç½‘ç»œ:åœ¨ Pytorch ä¸­å®ç° ResNet</h1>
<blockquote>åŸæ–‡ï¼š<a href="https://towardsdatascience.com/residual-network-implementing-resnet-a7da63c7b278?source=collection_archive---------1-----------------------#2019-07-03">https://towardsdatascience.com/residual-network-implementing-resnet-a7da63c7b278?source=collection_archive---------1-----------------------#2019-07-03</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><figure class="is it gp gr iu iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi ir"><img src="../Images/a476c54194e79e53c6dd27d6f9f6b646.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*1JCuiYW2fTqbQVrjMXAFUA.png"/></div></div><figcaption class="jc jd gj gh gi je jf bd b be z dk">Image by the Author</figcaption></figure><div class=""/><p id="d1e5" class="pw-post-body-paragraph kf kg ji kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated"><strong class="kh jj"> <em class="ld">æˆ‘åœ¨</em></strong><a class="ae le" href="https://www.linkedin.com/in/francesco-saverio-zuppichini-94659a150/?originalSubdomain=ch" rel="noopener ugc nofollow" target="_blank"><strong class="kh jj"><em class="ld">LinkedIn</em></strong></a><strong class="kh jj"><em class="ld">ï¼Œå¿«æ¥æ‰“ä¸ªæ‹›å‘¼</em> </strong>ğŸ‘‹</p><p id="c9db" class="pw-post-body-paragraph kf kg ji kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">ä»Šå¤©æˆ‘ä»¬å°†åœ¨<a class="ae le" href="https://pytorch.org/" rel="noopener ugc nofollow" target="_blank"> Pytorch </a>ä¸­å®ç°ä½•ç­‰äºº(å¾®è½¯ç ”ç©¶é™¢)è‘—åçš„ ResNetã€‚å®ƒåœ¨ ILSVRC 2015 åˆ†ç±»ä»»åŠ¡ä¸­è·å¾—ç¬¬ä¸€åã€‚</p><p id="5df0" class="pw-post-body-paragraph kf kg ji kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated"><strong class="kh jj"> ResNet åŠå…¶æ‰€æœ‰å˜ç§å·²ç»åœ¨æˆ‘çš„åº“ä¸­å®ç°</strong> <a class="ae le" href="https://github.com/FrancescoSaverioZuppichini/glasses" rel="noopener ugc nofollow" target="_blank"> <strong class="kh jj">çœ¼é•œ</strong> </a></p><p id="0404" class="pw-post-body-paragraph kf kg ji kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">ä»£ç æ˜¯<a class="ae le" href="https://github.com/FrancescoSaverioZuppichini/ResNet" rel="noopener ugc nofollow" target="_blank">è¿™é‡Œ</a>ï¼Œè¿™ç¯‡æ–‡ç« çš„äº’åŠ¨ç‰ˆå¯ä»¥åœ¨<a class="ae le" href="https://github.com/FrancescoSaverioZuppichini/ResNet/blob/master/ResNet.ipynb" rel="noopener ugc nofollow" target="_blank">è¿™é‡Œä¸‹è½½</a>åŸæ–‡å¯ä»¥ä»<a class="ae le" href="https://arxiv.org/abs/1512.03385" rel="noopener ugc nofollow" target="_blank">è¿™é‡Œé˜…è¯»</a>(å¾ˆå®¹æ˜“ç†è§£)é™„åŠ ææ–™å¯ä»¥åœ¨è¿™ä¸ª<a class="ae le" href="https://www.quora.com/" rel="noopener ugc nofollow" target="_blank"> quora ç­”æ¡ˆ</a>ä¸­æ‰¾åˆ°</p><figure class="lg lh li lj gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi lf"><img src="../Images/bd90dfc8a364eb8cdb7ff9e44356f967.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*uhZbfvWvZVjn8GRoTCj2GA.png"/></div></div></figure><h1 id="842f" class="lk ll ji bd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh bi translated">ä»‹ç»</h1><p id="f748" class="pw-post-body-paragraph kf kg ji kh b ki mi kk kl km mj ko kp kq mk ks kt ku ml kw kx ky mm la lb lc im bi translated">è¿™ä¸æ˜¯ä¸€ç¯‡æŠ€æœ¯æ–‡ç« ï¼Œæˆ‘ä¹Ÿæ²¡æœ‰èªæ˜åˆ°æ¯”åŸä½œè€…æ›´å¥½åœ°è§£é‡Šå‰©ä½™è¿æ¥ã€‚å› æ­¤æˆ‘ä»¬å°†ä»…é™äºå¿«é€Ÿæ¦‚è¿°ã€‚</p><p id="ff46" class="pw-post-body-paragraph kf kg ji kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated"><em class="ld">è¶Šæ·±çš„ç¥ç»ç½‘ç»œè¶Šéš¾è®­ç»ƒã€‚</em>ä¸ºä»€ä¹ˆï¼Ÿæ·±å±‚ç½‘ç»œçš„ä¸€ä¸ªå¤§é—®é¢˜æ˜¯æ¶ˆå¤±æ¢¯åº¦é—®é¢˜ã€‚åŸºæœ¬ä¸Šæ˜¯è¶Šæ·±è¶Šéš¾ç»ƒã€‚</p><p id="c488" class="pw-post-body-paragraph kf kg ji kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">ä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œä½œè€…å»ºè®®ä½¿ç”¨å¯¹å‰ä¸€å±‚çš„å¼•ç”¨æ¥è®¡ç®—ç»™å®šå±‚çš„è¾“å‡ºã€‚åœ¨ ResNet ä¸­ï¼Œä¸Šä¸€å±‚çš„è¾“å‡º(ç§°ä¸ºæ®‹å·®)è¢«æ·»åŠ åˆ°å½“å‰å±‚çš„è¾“å‡ºä¸­ã€‚ä¸‹å›¾æ˜¾ç¤ºäº†è¿™ä¸€æ“ä½œ</p><p id="d34a" class="pw-post-body-paragraph kf kg ji kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">æˆ‘ä»¬å°†ä½¿ç”¨å¤§å¤šæ•°æ•°æ®ç§‘å­¦å®¶éƒ½ä¸çŸ¥é“çš„ä¸œè¥¿:é¢å‘å¯¹è±¡ç¼–ç¨‹ï¼Œä½¿æˆ‘ä»¬çš„å®ç°å°½å¯èƒ½å…·æœ‰å¯ä¼¸ç¼©æ€§</p><h1 id="3d04" class="lk ll ji bd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh bi translated">åŸºæœ¬å—</h1><p id="04de" class="pw-post-body-paragraph kf kg ji kh b ki mi kk kl km mj ko kp kq mk ks kt ku ml kw kx ky mm la lb lc im bi translated">å¥½çš„ï¼Œé¦–å…ˆè¦è€ƒè™‘æˆ‘ä»¬éœ€è¦ä»€ä¹ˆã€‚é¦–å…ˆï¼Œæˆ‘ä»¬å¿…é¡»æœ‰ä¸€ä¸ªå·ç§¯å±‚ï¼Œå› ä¸º PyTorch åœ¨ Conv2d ä¸­æ²¡æœ‰â€œè‡ªåŠ¨â€å¡«å……ï¼Œæˆ‘ä»¬å¿…é¡»è‡ªå·±ç¼–ç ï¼</p><figure class="lg lh li lj gt iv"><div class="bz fp l di"><div class="mn mo l"/></div></figure><figure class="lg lh li lj gt iv"><div class="bz fp l di"><div class="mn mo l"/></div></figure><pre class="lg lh li lj gt mp mq mr ms aw mt bi"><span id="d886" class="mu ll ji mq b gy mv mw l mx my">Conv2dAuto(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)</span></pre><p id="1eb8" class="pw-post-body-paragraph kf kg ji kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬ä½¿ç”¨<code class="fe mz na nb mq b">ModuleDict</code>åˆ›å»ºä¸€ä¸ªå…·æœ‰ä¸åŒæ¿€æ´»åŠŸèƒ½çš„å­—å…¸ï¼Œè¿™åœ¨ä»¥åä¼šå¾ˆæ–¹ä¾¿ã€‚</p><figure class="lg lh li lj gt iv"><div class="bz fp l di"><div class="mn mo l"/></div></figure><p id="7215" class="pw-post-body-paragraph kf kg ji kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">å¦‚æœä½ å¯¹<code class="fe mz na nb mq b">ModuleDict</code>ä¸ç†Ÿæ‚‰ï¼Œæˆ‘å»ºè®®é˜…è¯»æˆ‘ä»¥å‰çš„æ–‡ç« <a class="ae le" rel="noopener" target="_blank" href="/pytorch-how-and-when-to-use-module-sequential-modulelist-and-moduledict-7a54597b5f17"> Pytorch:å¦‚ä½•ä»¥åŠä½•æ—¶ä½¿ç”¨æ¨¡å—ã€é¡ºåºã€æ¨¡å—åˆ—è¡¨å’Œæ¨¡å—æŒ‡ä»¤</a></p><h1 id="765e" class="lk ll ji bd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh bi translated">æ®‹ä½™å—</h1><p id="f20a" class="pw-post-body-paragraph kf kg ji kh b ki mi kk kl km mj ko kp kq mk ks kt ku ml kw kx ky mm la lb lc im bi translated">åˆ›å»ºå¹²å‡€çš„ä»£ç å¿…é¡»è€ƒè™‘åº”ç”¨ç¨‹åºçš„ä¸»è¦æ„ä»¶ï¼Œæˆ–è€…åœ¨æˆ‘ä»¬çš„ä¾‹å­ä¸­æ˜¯ç½‘ç»œçš„ä¸»è¦æ„ä»¶ã€‚æ®‹å·®å—é‡‡ç”¨å¸¦æœ‰<code class="fe mz na nb mq b">in_channels</code>çš„è¾“å…¥ï¼Œåº”ç”¨å·ç§¯å±‚çš„ä¸€äº›å—å°†å…¶å‡å°‘åˆ°<code class="fe mz na nb mq b">out_channels</code>ï¼Œå¹¶å°†å…¶åŠ èµ·æ¥ä½œä¸ºåŸå§‹è¾“å…¥ã€‚å¦‚æœå®ƒä»¬çš„å¤§å°ä¸åŒ¹é…ï¼Œé‚£ä¹ˆè¾“å…¥è¿›å…¥<code class="fe mz na nb mq b">identity</code>ã€‚æˆ‘ä»¬å¯ä»¥æŠ½è±¡è¿™ä¸ªè¿‡ç¨‹ï¼Œå¹¶åˆ›å»ºä¸€ä¸ªå¯æ‰©å±•çš„æ¥å£ã€‚</p><figure class="lg lh li lj gt iv"><div class="bz fp l di"><div class="mn mo l"/></div></figure><figure class="lg lh li lj gt iv"><div class="bz fp l di"><div class="mn mo l"/></div></figure><pre class="lg lh li lj gt mp mq mr ms aw mt bi"><span id="dad0" class="mu ll ji mq b gy mv mw l mx my">ResidualBlock(<br/>  (blocks): Identity()<br/>  (activate): ReLU(inplace)<br/>  (shortcut): Identity()<br/>)</span></pre><p id="b23b" class="pw-post-body-paragraph kf kg ji kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">è®©æˆ‘ä»¬ç”¨ä¸€ä¸ª 1 çš„è™šæ‹Ÿå‘é‡æ¥æµ‹è¯•å®ƒï¼Œæˆ‘ä»¬åº”è¯¥å¾—åˆ°ä¸€ä¸ª 2 çš„å‘é‡</p><figure class="lg lh li lj gt iv"><div class="bz fp l di"><div class="mn mo l"/></div></figure><pre class="lg lh li lj gt mp mq mr ms aw mt bi"><span id="bfe8" class="mu ll ji mq b gy mv mw l mx my">tensor([[[[2.]]]])</span></pre><p id="22f7" class="pw-post-body-paragraph kf kg ji kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">åœ¨ ResNet ä¸­ï¼Œæ¯ä¸ªå—éƒ½æœ‰ä¸€ä¸ªæ‰©å±•å‚æ•°ï¼Œä»¥ä¾¿åœ¨éœ€è¦æ—¶å¢åŠ <code class="fe mz na nb mq b">out_channels</code>ã€‚åŒæ ·ï¼Œèº«ä»½è¢«å®šä¹‰ä¸ºä¸€ä¸ªå·ç§¯ï¼Œåè·Ÿä¸€ä¸ª BatchNorm å±‚ï¼Œè¿™è¢«ç§°ä¸º<code class="fe mz na nb mq b">shortcut</code>ã€‚ç„¶åï¼Œæˆ‘ä»¬å¯ä»¥æ‰©å±•<code class="fe mz na nb mq b">ResidualBlock</code>å¹¶å®šä¹‰<code class="fe mz na nb mq b">shortcut</code>å‡½æ•°ã€‚</p><figure class="lg lh li lj gt iv"><div class="bz fp l di"><div class="mn mo l"/></div></figure><figure class="lg lh li lj gt iv"><div class="bz fp l di"><div class="mn mo l"/></div></figure><pre class="lg lh li lj gt mp mq mr ms aw mt bi"><span id="da8e" class="mu ll ji mq b gy mv mw l mx my">ResNetResidualBlock(<br/>  (blocks): Identity()<br/>  (activate): ReLU(inplace)<br/>  (shortcut): Sequential(<br/>    (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)<br/>    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)<br/>  )<br/>)</span></pre><h1 id="80ab" class="lk ll ji bd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh bi translated">åŸºæœ¬å—</h1><p id="d51c" class="pw-post-body-paragraph kf kg ji kh b ki mi kk kl km mj ko kp kq mk ks kt ku ml kw kx ky mm la lb lc im bi translated">ä¸€ä¸ªåŸºæœ¬çš„ ResNet å—ç”±ä¸¤å±‚<code class="fe mz na nb mq b">3x3</code> conv/batchnorm/relu ç»„æˆã€‚å›¾ä¸­ï¼Œçº¿æ¡ä»£è¡¨å‰©ä½™è¿ç®—ã€‚è™šçº¿è¡¨ç¤ºåº”ç”¨äº†å¿«æ·æ–¹å¼æ¥åŒ¹é…è¾“å…¥å’Œè¾“å‡ºç»´åº¦ã€‚</p><figure class="lg lh li lj gt iv gh gi paragraph-image"><div class="gh gi nc"><img src="../Images/e6b778594d916d25df48c9a86e8c0f66.png" data-original-src="https://miro.medium.com/v2/resize:fit:470/format:webp/1*E6ptpDYIVmdlJO6hC-KzCQ.png"/></div><figcaption class="jc jd gj gh gi je jf bd b be z dk">Basic ResNet Block</figcaption></figure><p id="6e94" class="pw-post-body-paragraph kf kg ji kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">è®©æˆ‘ä»¬é¦–å…ˆåˆ›å»ºä¸€ä¸ªæ–¹ä¾¿çš„å‡½æ•°æ¥å †å ä¸€ä¸ª conv å’Œ batchnorm å±‚</p><figure class="lg lh li lj gt iv"><div class="bz fp l di"><div class="mn mo l"/></div></figure><figure class="lg lh li lj gt iv"><div class="bz fp l di"><div class="mn mo l"/></div></figure><figure class="lg lh li lj gt iv"><div class="bz fp l di"><div class="mn mo l"/></div></figure><pre class="lg lh li lj gt mp mq mr ms aw mt bi"><span id="0ecf" class="mu ll ji mq b gy mv mw l mx my">ResNetBasicBlock(<br/>  (blocks): Sequential(<br/>    (0): Sequential(<br/>      (0): Conv2dAuto(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)<br/>      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)<br/>    )<br/>    (1): ReLU(inplace)<br/>    (2): Sequential(<br/>      (0): Conv2dAuto(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)<br/>      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)<br/>    )<br/>  )<br/>  (activate): ReLU(inplace)<br/>  (shortcut): Sequential(<br/>    (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)<br/>    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)<br/>  )<br/>)</span></pre><h1 id="6e95" class="lk ll ji bd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh bi translated">ç“¶é¢ˆ</h1><p id="d499" class="pw-post-body-paragraph kf kg ji kh b ki mi kk kl km mj ko kp kq mk ks kt ku ml kw kx ky mm la lb lc im bi translated">ä¸ºäº†å¢åŠ ç½‘ç»œæ·±åº¦ï¼ŒåŒæ—¶ä¿æŒå‚æ•°å¤§å°å°½å¯èƒ½ä½ï¼Œä½œè€…å®šä¹‰äº†ä¸€ä¸ªç“¶é¢ˆå—ï¼Œå³â€œä¸‰å±‚æ˜¯ 1x1ã€3x3 å’Œ 1x1 å·ç§¯ï¼Œå…¶ä¸­ 1Ã—1 å±‚è´Ÿè´£å‡å°‘ç„¶åå¢åŠ (æ¢å¤)ç»´åº¦ï¼Œè€Œ 3Ã—3 å±‚æ˜¯å…·æœ‰è¾ƒå°è¾“å…¥/è¾“å‡ºç»´åº¦çš„ç“¶é¢ˆã€‚â€æˆ‘ä»¬å¯ä»¥æ‰©å±•<code class="fe mz na nb mq b">ResNetResidualBlock</code>å¹¶åˆ›å»ºè¿™äº›å—ã€‚</p><figure class="lg lh li lj gt iv"><div class="bz fp l di"><div class="mn mo l"/></div></figure><figure class="lg lh li lj gt iv"><div class="bz fp l di"><div class="mn mo l"/></div></figure><pre class="lg lh li lj gt mp mq mr ms aw mt bi"><span id="8ef9" class="mu ll ji mq b gy mv mw l mx my">ResNetBottleNeckBlock(<br/>  (blocks): Sequential(<br/>    (0): Sequential(<br/>      (0): Conv2dAuto(32, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)<br/>      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)<br/>    )<br/>    (1): ReLU(inplace)<br/>    (2): Sequential(<br/>      (0): Conv2dAuto(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)<br/>      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)<br/>    )<br/>    (3): ReLU(inplace)<br/>    (4): Sequential(<br/>      (0): Conv2dAuto(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)<br/>      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)<br/>    )<br/>  )<br/>  (activate): ReLU(inplace)<br/>  (shortcut): Sequential(<br/>    (0): Conv2d(32, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)<br/>    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)<br/>  )<br/>)</span></pre><h1 id="f50f" class="lk ll ji bd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh bi translated">å±‚</h1><p id="c4e9" class="pw-post-body-paragraph kf kg ji kh b ki mi kk kl km mj ko kp kq mk ks kt ku ml kw kx ky mm la lb lc im bi translated">ResNet çš„å±‚ç”±ä¸€ä¸ªæ¥ä¸€ä¸ªå †å çš„ç›¸åŒå—ç»„æˆã€‚</p><figure class="lg lh li lj gt iv gh gi paragraph-image"><div class="gh gi nc"><img src="../Images/fb543a9524e6be4f3fa5211d23feedf4.png" data-original-src="https://miro.medium.com/v2/resize:fit:470/format:webp/1*6_ex5WTe7ziTK-A5ix1HOQ.png"/></div><figcaption class="jc jd gj gh gi je jf bd b be z dk">ResNet Layer</figcaption></figure><p id="3934" class="pw-post-body-paragraph kf kg ji kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">æˆ‘ä»¬å¯ä»¥é€šè¿‡ä¸€ä¸ªæ¥ä¸€ä¸ªåœ°ç²˜è´´<code class="fe mz na nb mq b">n</code>å—æ¥è½»æ¾å®šä¹‰å®ƒï¼Œåªéœ€è®°ä½ç¬¬ä¸€ä¸ªå·ç§¯å—çš„æ­¥é•¿ä¸º 2ï¼Œå› ä¸ºâ€œæˆ‘ä»¬é€šè¿‡æ­¥é•¿ä¸º 2 çš„å·ç§¯å±‚ç›´æ¥æ‰§è¡Œä¸‹é‡‡æ ·â€ã€‚</p><figure class="lg lh li lj gt iv"><div class="bz fp l di"><div class="mn mo l"/></div></figure><figure class="lg lh li lj gt iv"><div class="bz fp l di"><div class="mn mo l"/></div></figure><pre class="lg lh li lj gt mp mq mr ms aw mt bi"><span id="f355" class="mu ll ji mq b gy mv mw l mx my">torch.Size([1, 128, 24, 24])</span></pre><h1 id="01f4" class="lk ll ji bd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh bi translated">ç¼–ç å™¨</h1><p id="b18d" class="pw-post-body-paragraph kf kg ji kh b ki mi kk kl km mj ko kp kq mk ks kt ku ml kw kx ky mm la lb lc im bi translated">ç±»ä¼¼åœ°ï¼Œç¼–ç å™¨ç”±ç‰¹å¾å°ºå¯¸é€æ¸å¢åŠ çš„å¤šå±‚ç»„æˆã€‚</p><figure class="lg lh li lj gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi nd"><img src="../Images/a2ece30661ab2c61d7092da7e8f84de9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*QEVnqrWM2ydj29QTPcugiA.png"/></div></div><figcaption class="jc jd gj gh gi je jf bd b be z dk">ResNet Encoder</figcaption></figure><figure class="lg lh li lj gt iv"><div class="bz fp l di"><div class="mn mo l"/></div></figure><h1 id="0dc4" class="lk ll ji bd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh bi translated">è§£ç å™¨</h1><p id="5983" class="pw-post-body-paragraph kf kg ji kh b ki mi kk kl km mj ko kp kq mk ks kt ku ml kw kx ky mm la lb lc im bi translated">è§£ç å™¨æ˜¯æˆ‘ä»¬åˆ›å»ºå®Œæ•´ç½‘ç»œæ‰€éœ€çš„æœ€åä¸€å—ã€‚å®ƒæ˜¯ä¸€ä¸ªå®Œå…¨è¿æ¥çš„å±‚ï¼Œå°†ç½‘ç»œå­¦ä¹ åˆ°çš„ç‰¹å¾æ˜ å°„åˆ°å®ƒä»¬å„è‡ªçš„ç±»ã€‚å¾ˆå®¹æ˜“ï¼Œæˆ‘ä»¬å¯ä»¥å°†å…¶å®šä¹‰ä¸º:</p><figure class="lg lh li lj gt iv"><div class="bz fp l di"><div class="mn mo l"/></div></figure><h1 id="b49f" class="lk ll ji bd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh bi translated">é›·æ–¯å†…ç‰¹</h1><p id="9fed" class="pw-post-body-paragraph kf kg ji kh b ki mi kk kl km mj ko kp kq mk ks kt ku ml kw kx ky mm la lb lc im bi translated">æœ€åï¼Œæˆ‘ä»¬å¯ä»¥å°†æ‰€æœ‰çš„éƒ¨åˆ†æ”¾åœ¨ä¸€èµ·ï¼Œåˆ›å»ºæœ€ç»ˆçš„æ¨¡å‹ã€‚</p><figure class="lg lh li lj gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi lf"><img src="../Images/bd90dfc8a364eb8cdb7ff9e44356f967.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*uhZbfvWvZVjn8GRoTCj2GA.png"/></div></div><figcaption class="jc jd gj gh gi je jf bd b be z dk">ResNet34</figcaption></figure><figure class="lg lh li lj gt iv"><div class="bz fp l di"><div class="mn mo l"/></div></figure><p id="0bc4" class="pw-post-body-paragraph kf kg ji kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">æˆ‘ä»¬ç°åœ¨å¯ä»¥å®šä¹‰ä½œè€…æå‡ºçš„äº”ä¸ªæ¨¡å‹ï¼Œ<code class="fe mz na nb mq b">resnet18,34,50,101,152</code></p><figure class="lg lh li lj gt iv"><div class="bz fp l di"><div class="mn mo l"/></div></figure><p id="1a85" class="pw-post-body-paragraph kf kg ji kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">è®©æˆ‘ä»¬ç”¨<a class="ae le" href="https://github.com/sksq96/pytorch-summary" rel="noopener ugc nofollow" target="_blank">ç«ç‚¬æ¦‚è¦</a>æ¥æµ‹è¯•è¿™ä¸ªæ¨¡å‹</p><figure class="lg lh li lj gt iv"><div class="bz fp l di"><div class="mn mo l"/></div></figure><pre class="lg lh li lj gt mp mq mr ms aw mt bi"><span id="bb98" class="mu ll ji mq b gy mv mw l mx my">----------------------------------------------------------------<br/>        Layer (type)               Output Shape         Param #<br/>================================================================<br/>            Conv2d-1         [-1, 64, 112, 112]           9,408<br/>       BatchNorm2d-2         [-1, 64, 112, 112]             128<br/>              ReLU-3         [-1, 64, 112, 112]               0<br/>         MaxPool2d-4           [-1, 64, 56, 56]               0<br/>        Conv2dAuto-5           [-1, 64, 56, 56]          36,864<br/>       BatchNorm2d-6           [-1, 64, 56, 56]             128<br/>              ReLU-7           [-1, 64, 56, 56]               0<br/>        Conv2dAuto-8           [-1, 64, 56, 56]          36,864<br/>       BatchNorm2d-9           [-1, 64, 56, 56]             128<br/>             ReLU-10           [-1, 64, 56, 56]               0<br/> ResNetBasicBlock-11           [-1, 64, 56, 56]               0<br/>       Conv2dAuto-12           [-1, 64, 56, 56]          36,864<br/>      BatchNorm2d-13           [-1, 64, 56, 56]             128<br/>             ReLU-14           [-1, 64, 56, 56]               0<br/>       Conv2dAuto-15           [-1, 64, 56, 56]          36,864<br/>      BatchNorm2d-16           [-1, 64, 56, 56]             128<br/>             ReLU-17           [-1, 64, 56, 56]               0<br/> ResNetBasicBlock-18           [-1, 64, 56, 56]               0<br/>      ResNetLayer-19           [-1, 64, 56, 56]               0<br/>           Conv2d-20          [-1, 128, 28, 28]           8,192<br/>      BatchNorm2d-21          [-1, 128, 28, 28]             256<br/>       Conv2dAuto-22          [-1, 128, 28, 28]          73,728<br/>      BatchNorm2d-23          [-1, 128, 28, 28]             256<br/>             ReLU-24          [-1, 128, 28, 28]               0<br/>       Conv2dAuto-25          [-1, 128, 28, 28]         147,456<br/>      BatchNorm2d-26          [-1, 128, 28, 28]             256<br/>             ReLU-27          [-1, 128, 28, 28]               0<br/> ResNetBasicBlock-28          [-1, 128, 28, 28]               0<br/>       Conv2dAuto-29          [-1, 128, 28, 28]         147,456<br/>      BatchNorm2d-30          [-1, 128, 28, 28]             256<br/>             ReLU-31          [-1, 128, 28, 28]               0<br/>       Conv2dAuto-32          [-1, 128, 28, 28]         147,456<br/>      BatchNorm2d-33          [-1, 128, 28, 28]             256<br/>             ReLU-34          [-1, 128, 28, 28]               0<br/> ResNetBasicBlock-35          [-1, 128, 28, 28]               0<br/>      ResNetLayer-36          [-1, 128, 28, 28]               0<br/>           Conv2d-37          [-1, 256, 14, 14]          32,768<br/>      BatchNorm2d-38          [-1, 256, 14, 14]             512<br/>       Conv2dAuto-39          [-1, 256, 14, 14]         294,912<br/>      BatchNorm2d-40          [-1, 256, 14, 14]             512<br/>             ReLU-41          [-1, 256, 14, 14]               0<br/>       Conv2dAuto-42          [-1, 256, 14, 14]         589,824<br/>      BatchNorm2d-43          [-1, 256, 14, 14]             512<br/>             ReLU-44          [-1, 256, 14, 14]               0<br/> ResNetBasicBlock-45          [-1, 256, 14, 14]               0<br/>       Conv2dAuto-46          [-1, 256, 14, 14]         589,824<br/>      BatchNorm2d-47          [-1, 256, 14, 14]             512<br/>             ReLU-48          [-1, 256, 14, 14]               0<br/>       Conv2dAuto-49          [-1, 256, 14, 14]         589,824<br/>      BatchNorm2d-50          [-1, 256, 14, 14]             512<br/>             ReLU-51          [-1, 256, 14, 14]               0<br/> ResNetBasicBlock-52          [-1, 256, 14, 14]               0<br/>      ResNetLayer-53          [-1, 256, 14, 14]               0<br/>           Conv2d-54            [-1, 512, 7, 7]         131,072<br/>      BatchNorm2d-55            [-1, 512, 7, 7]           1,024<br/>       Conv2dAuto-56            [-1, 512, 7, 7]       1,179,648<br/>      BatchNorm2d-57            [-1, 512, 7, 7]           1,024<br/>             ReLU-58            [-1, 512, 7, 7]               0<br/>       Conv2dAuto-59            [-1, 512, 7, 7]       2,359,296<br/>      BatchNorm2d-60            [-1, 512, 7, 7]           1,024<br/>             ReLU-61            [-1, 512, 7, 7]               0<br/> ResNetBasicBlock-62            [-1, 512, 7, 7]               0<br/>       Conv2dAuto-63            [-1, 512, 7, 7]       2,359,296<br/>      BatchNorm2d-64            [-1, 512, 7, 7]           1,024<br/>             ReLU-65            [-1, 512, 7, 7]               0<br/>       Conv2dAuto-66            [-1, 512, 7, 7]       2,359,296<br/>      BatchNorm2d-67            [-1, 512, 7, 7]           1,024<br/>             ReLU-68            [-1, 512, 7, 7]               0<br/> ResNetBasicBlock-69            [-1, 512, 7, 7]               0<br/>      ResNetLayer-70            [-1, 512, 7, 7]               0<br/>    ResNetEncoder-71            [-1, 512, 7, 7]               0<br/>AdaptiveAvgPool2d-72            [-1, 512, 1, 1]               0<br/>           Linear-73                 [-1, 1000]         513,000<br/>    ResnetDecoder-74                 [-1, 1000]               0<br/>================================================================<br/>Total params: 11,689,512<br/>Trainable params: 11,689,512<br/>Non-trainable params: 0<br/>----------------------------------------------------------------<br/>Input size (MB): 0.57<br/>Forward/backward pass size (MB): 65.86<br/>Params size (MB): 44.59<br/>Estimated Total Size (MB): 111.03<br/>----------------------------------------------------------------</span></pre><p id="cbce" class="pw-post-body-paragraph kf kg ji kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">ä¸ºäº†æ£€æŸ¥æ­£ç¡®æ€§ï¼Œè®©æˆ‘ä»¬çœ‹çœ‹åŸå§‹å®ç°çš„å‚æ•°æ•°é‡</p><figure class="lg lh li lj gt iv"><div class="bz fp l di"><div class="mn mo l"/></div></figure><pre class="lg lh li lj gt mp mq mr ms aw mt bi"><span id="3685" class="mu ll ji mq b gy mv mw l mx my">----------------------------------------------------------------<br/>        Layer (type)               Output Shape         Param #<br/>================================================================<br/>            Conv2d-1         [-1, 64, 112, 112]           9,408<br/>       BatchNorm2d-2         [-1, 64, 112, 112]             128<br/>              ReLU-3         [-1, 64, 112, 112]               0<br/>         MaxPool2d-4           [-1, 64, 56, 56]               0<br/>            Conv2d-5           [-1, 64, 56, 56]          36,864<br/>       BatchNorm2d-6           [-1, 64, 56, 56]             128<br/>              ReLU-7           [-1, 64, 56, 56]               0<br/>            Conv2d-8           [-1, 64, 56, 56]          36,864<br/>       BatchNorm2d-9           [-1, 64, 56, 56]             128<br/>             ReLU-10           [-1, 64, 56, 56]               0<br/>       BasicBlock-11           [-1, 64, 56, 56]               0<br/>           Conv2d-12           [-1, 64, 56, 56]          36,864<br/>      BatchNorm2d-13           [-1, 64, 56, 56]             128<br/>             ReLU-14           [-1, 64, 56, 56]               0<br/>           Conv2d-15           [-1, 64, 56, 56]          36,864<br/>      BatchNorm2d-16           [-1, 64, 56, 56]             128<br/>             ReLU-17           [-1, 64, 56, 56]               0<br/>       BasicBlock-18           [-1, 64, 56, 56]               0<br/>           Conv2d-19          [-1, 128, 28, 28]          73,728<br/>      BatchNorm2d-20          [-1, 128, 28, 28]             256<br/>             ReLU-21          [-1, 128, 28, 28]               0<br/>           Conv2d-22          [-1, 128, 28, 28]         147,456<br/>      BatchNorm2d-23          [-1, 128, 28, 28]             256<br/>           Conv2d-24          [-1, 128, 28, 28]           8,192<br/>      BatchNorm2d-25          [-1, 128, 28, 28]             256<br/>             ReLU-26          [-1, 128, 28, 28]               0<br/>       BasicBlock-27          [-1, 128, 28, 28]               0<br/>           Conv2d-28          [-1, 128, 28, 28]         147,456<br/>      BatchNorm2d-29          [-1, 128, 28, 28]             256<br/>             ReLU-30          [-1, 128, 28, 28]               0<br/>           Conv2d-31          [-1, 128, 28, 28]         147,456<br/>      BatchNorm2d-32          [-1, 128, 28, 28]             256<br/>             ReLU-33          [-1, 128, 28, 28]               0<br/>       BasicBlock-34          [-1, 128, 28, 28]               0<br/>           Conv2d-35          [-1, 256, 14, 14]         294,912<br/>      BatchNorm2d-36          [-1, 256, 14, 14]             512<br/>             ReLU-37          [-1, 256, 14, 14]               0<br/>           Conv2d-38          [-1, 256, 14, 14]         589,824<br/>      BatchNorm2d-39          [-1, 256, 14, 14]             512<br/>           Conv2d-40          [-1, 256, 14, 14]          32,768<br/>      BatchNorm2d-41          [-1, 256, 14, 14]             512<br/>             ReLU-42          [-1, 256, 14, 14]               0<br/>       BasicBlock-43          [-1, 256, 14, 14]               0<br/>           Conv2d-44          [-1, 256, 14, 14]         589,824<br/>      BatchNorm2d-45          [-1, 256, 14, 14]             512<br/>             ReLU-46          [-1, 256, 14, 14]               0<br/>           Conv2d-47          [-1, 256, 14, 14]         589,824<br/>      BatchNorm2d-48          [-1, 256, 14, 14]             512<br/>             ReLU-49          [-1, 256, 14, 14]               0<br/>       BasicBlock-50          [-1, 256, 14, 14]               0<br/>           Conv2d-51            [-1, 512, 7, 7]       1,179,648<br/>      BatchNorm2d-52            [-1, 512, 7, 7]           1,024<br/>             ReLU-53            [-1, 512, 7, 7]               0<br/>           Conv2d-54            [-1, 512, 7, 7]       2,359,296<br/>      BatchNorm2d-55            [-1, 512, 7, 7]           1,024<br/>           Conv2d-56            [-1, 512, 7, 7]         131,072<br/>      BatchNorm2d-57            [-1, 512, 7, 7]           1,024<br/>             ReLU-58            [-1, 512, 7, 7]               0<br/>       BasicBlock-59            [-1, 512, 7, 7]               0<br/>           Conv2d-60            [-1, 512, 7, 7]       2,359,296<br/>      BatchNorm2d-61            [-1, 512, 7, 7]           1,024<br/>             ReLU-62            [-1, 512, 7, 7]               0<br/>           Conv2d-63            [-1, 512, 7, 7]       2,359,296<br/>      BatchNorm2d-64            [-1, 512, 7, 7]           1,024<br/>             ReLU-65            [-1, 512, 7, 7]               0<br/>       BasicBlock-66            [-1, 512, 7, 7]               0<br/>AdaptiveAvgPool2d-67            [-1, 512, 1, 1]               0<br/>           Linear-68                 [-1, 1000]         513,000<br/>================================================================<br/>Total params: 11,689,512<br/>Trainable params: 11,689,512<br/>Non-trainable params: 0<br/>----------------------------------------------------------------<br/>Input size (MB): 0.57<br/>Forward/backward pass size (MB): 62.79<br/>Params size (MB): 44.59<br/>Estimated Total Size (MB): 107.96<br/>----------------------------------------------------------------</span></pre><p id="f66b" class="pw-post-body-paragraph kf kg ji kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">æ˜¯ä¸€æ ·çš„ï¼</p><h1 id="54db" class="lk ll ji bd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh bi translated">ç”¨æˆ·åŒ–</h1><p id="6c87" class="pw-post-body-paragraph kf kg ji kh b ki mi kk kl km mj ko kp kq mk ks kt ku ml kw kx ky mm la lb lc im bi translated">é¢å‘å¯¹è±¡ç¼–ç¨‹çš„ä¸€ä¸ªä¼˜ç‚¹æ˜¯æˆ‘ä»¬å¯ä»¥å¾ˆå®¹æ˜“åœ°å®šåˆ¶æˆ‘ä»¬çš„ç½‘ç»œã€‚</p><h1 id="fc66" class="lk ll ji bd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh bi translated">æ”¹å˜è¡—åŒº</h1><p id="7a47" class="pw-post-body-paragraph kf kg ji kh b ki mi kk kl km mj ko kp kq mk ks kt ku ml kw kx ky mm la lb lc im bi translated">å¦‚æœæˆ‘ä»¬æƒ³ä½¿ç”¨ä¸åŒçš„åŸºæœ¬å—å‘¢ï¼Ÿä¹Ÿè®¸æˆ‘ä»¬åªæƒ³è¦ä¸€ä¸ª 3x3 çš„ convï¼Œä¹Ÿè®¸è¿˜è¦é€€å­¦ï¼Ÿã€‚åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œæˆ‘ä»¬å¯ä»¥å­ç±»åŒ–<code class="fe mz na nb mq b">ResNetResidualBlock</code>å¹¶æ”¹å˜<code class="fe mz na nb mq b">.blocks</code>å­—æ®µï¼</p><figure class="lg lh li lj gt iv"><div class="bz fp l di"><div class="mn mo l"/></div></figure><p id="5969" class="pw-post-body-paragraph kf kg ji kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">è®©æˆ‘ä»¬æŠŠè¿™ä¸ªæ–°çš„åŒºå—äº¤ç»™<code class="fe mz na nb mq b">resnet18</code>ï¼Œåˆ›å»ºä¸€ä¸ªæ–°çš„æ¶æ„ï¼</p><figure class="lg lh li lj gt iv"><div class="bz fp l di"><div class="mn mo l"/></div></figure><pre class="lg lh li lj gt mp mq mr ms aw mt bi"><span id="ccb9" class="mu ll ji mq b gy mv mw l mx my">----------------------------------------------------------------<br/>        Layer (type)               Output Shape         Param #<br/>================================================================<br/>            Conv2d-1         [-1, 64, 112, 112]           9,408<br/>       BatchNorm2d-2         [-1, 64, 112, 112]             128<br/>              ReLU-3         [-1, 64, 112, 112]               0<br/>         MaxPool2d-4           [-1, 64, 56, 56]               0<br/>        Conv2dAuto-5           [-1, 64, 56, 56]          36,864<br/>         Dropout2d-6           [-1, 64, 56, 56]               0<br/>              ReLU-7           [-1, 64, 56, 56]               0<br/>              ReLU-8           [-1, 64, 56, 56]               0<br/>AnOtherResNetBlock-9           [-1, 64, 56, 56]               0<br/>       Conv2dAuto-10           [-1, 64, 56, 56]          36,864<br/>        Dropout2d-11           [-1, 64, 56, 56]               0<br/>             ReLU-12           [-1, 64, 56, 56]               0<br/>             ReLU-13           [-1, 64, 56, 56]               0<br/>AnOtherResNetBlock-14           [-1, 64, 56, 56]               0<br/>      ResNetLayer-15           [-1, 64, 56, 56]               0<br/>           Conv2d-16          [-1, 128, 28, 28]           8,192<br/>      BatchNorm2d-17          [-1, 128, 28, 28]             256<br/>       Conv2dAuto-18          [-1, 128, 28, 28]          73,728<br/>        Dropout2d-19          [-1, 128, 28, 28]               0<br/>             ReLU-20          [-1, 128, 28, 28]               0<br/>             ReLU-21          [-1, 128, 28, 28]               0<br/>AnOtherResNetBlock-22          [-1, 128, 28, 28]               0<br/>       Conv2dAuto-23          [-1, 128, 28, 28]         147,456<br/>        Dropout2d-24          [-1, 128, 28, 28]               0<br/>             ReLU-25          [-1, 128, 28, 28]               0<br/>             ReLU-26          [-1, 128, 28, 28]               0<br/>AnOtherResNetBlock-27          [-1, 128, 28, 28]               0<br/>      ResNetLayer-28          [-1, 128, 28, 28]               0<br/>           Conv2d-29          [-1, 256, 14, 14]          32,768<br/>      BatchNorm2d-30          [-1, 256, 14, 14]             512<br/>       Conv2dAuto-31          [-1, 256, 14, 14]         294,912<br/>        Dropout2d-32          [-1, 256, 14, 14]               0<br/>             ReLU-33          [-1, 256, 14, 14]               0<br/>             ReLU-34          [-1, 256, 14, 14]               0<br/>AnOtherResNetBlock-35          [-1, 256, 14, 14]               0<br/>       Conv2dAuto-36          [-1, 256, 14, 14]         589,824<br/>        Dropout2d-37          [-1, 256, 14, 14]               0<br/>             ReLU-38          [-1, 256, 14, 14]               0<br/>             ReLU-39          [-1, 256, 14, 14]               0<br/>AnOtherResNetBlock-40          [-1, 256, 14, 14]               0<br/>      ResNetLayer-41          [-1, 256, 14, 14]               0<br/>           Conv2d-42            [-1, 512, 7, 7]         131,072<br/>      BatchNorm2d-43            [-1, 512, 7, 7]           1,024<br/>       Conv2dAuto-44            [-1, 512, 7, 7]       1,179,648<br/>        Dropout2d-45            [-1, 512, 7, 7]               0<br/>             ReLU-46            [-1, 512, 7, 7]               0<br/>             ReLU-47            [-1, 512, 7, 7]               0<br/>AnOtherResNetBlock-48            [-1, 512, 7, 7]               0<br/>       Conv2dAuto-49            [-1, 512, 7, 7]       2,359,296<br/>        Dropout2d-50            [-1, 512, 7, 7]               0<br/>             ReLU-51            [-1, 512, 7, 7]               0<br/>             ReLU-52            [-1, 512, 7, 7]               0<br/>AnOtherResNetBlock-53            [-1, 512, 7, 7]               0<br/>      ResNetLayer-54            [-1, 512, 7, 7]               0<br/>    ResNetEncoder-55            [-1, 512, 7, 7]               0<br/>AdaptiveAvgPool2d-56            [-1, 512, 1, 1]               0<br/>           Linear-57                 [-1, 1000]         513,000<br/>    ResnetDecoder-58                 [-1, 1000]               0<br/>================================================================<br/>Total params: 5,414,952<br/>Trainable params: 5,414,952<br/>Non-trainable params: 0<br/>----------------------------------------------------------------<br/>Input size (MB): 0.57<br/>Forward/backward pass size (MB): 54.38<br/>Params size (MB): 20.66<br/>Estimated Total Size (MB): 75.61<br/>----------------------------------------------------------------</span></pre><h1 id="a99e" class="lk ll ji bd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh bi translated">æ”¹å˜æ¿€æ´»åŠŸèƒ½</h1><p id="7f33" class="pw-post-body-paragraph kf kg ji kh b ki mi kk kl km mj ko kp kq mk ks kt ku ml kw kx ky mm la lb lc im bi translated">å®¹æ˜“çš„äº‹</p><figure class="lg lh li lj gt iv"><div class="bz fp l di"><div class="mn mo l"/></div></figure><pre class="lg lh li lj gt mp mq mr ms aw mt bi"><span id="4bd4" class="mu ll ji mq b gy mv mw l mx my">----------------------------------------------------------------<br/>        Layer (type)               Output Shape         Param #<br/>================================================================<br/>            Conv2d-1         [-1, 64, 112, 112]           9,408<br/>       BatchNorm2d-2         [-1, 64, 112, 112]             128<br/>         LeakyReLU-3         [-1, 64, 112, 112]               0<br/>         MaxPool2d-4           [-1, 64, 56, 56]               0<br/>        Conv2dAuto-5           [-1, 64, 56, 56]          36,864<br/>       BatchNorm2d-6           [-1, 64, 56, 56]             128<br/>         LeakyReLU-7           [-1, 64, 56, 56]               0<br/>        Conv2dAuto-8           [-1, 64, 56, 56]          36,864<br/>       BatchNorm2d-9           [-1, 64, 56, 56]             128<br/>        LeakyReLU-10           [-1, 64, 56, 56]               0<br/> ResNetBasicBlock-11           [-1, 64, 56, 56]               0<br/>       Conv2dAuto-12           [-1, 64, 56, 56]          36,864<br/>      BatchNorm2d-13           [-1, 64, 56, 56]             128<br/>        LeakyReLU-14           [-1, 64, 56, 56]               0<br/>       Conv2dAuto-15           [-1, 64, 56, 56]          36,864<br/>      BatchNorm2d-16           [-1, 64, 56, 56]             128<br/>        LeakyReLU-17           [-1, 64, 56, 56]               0<br/> ResNetBasicBlock-18           [-1, 64, 56, 56]               0<br/>      ResNetLayer-19           [-1, 64, 56, 56]               0<br/>           Conv2d-20          [-1, 128, 28, 28]           8,192<br/>      BatchNorm2d-21          [-1, 128, 28, 28]             256<br/>       Conv2dAuto-22          [-1, 128, 28, 28]          73,728<br/>      BatchNorm2d-23          [-1, 128, 28, 28]             256<br/>        LeakyReLU-24          [-1, 128, 28, 28]               0<br/>       Conv2dAuto-25          [-1, 128, 28, 28]         147,456<br/>      BatchNorm2d-26          [-1, 128, 28, 28]             256<br/>        LeakyReLU-27          [-1, 128, 28, 28]               0<br/> ResNetBasicBlock-28          [-1, 128, 28, 28]               0<br/>       Conv2dAuto-29          [-1, 128, 28, 28]         147,456<br/>      BatchNorm2d-30          [-1, 128, 28, 28]             256<br/>        LeakyReLU-31          [-1, 128, 28, 28]               0<br/>       Conv2dAuto-32          [-1, 128, 28, 28]         147,456<br/>      BatchNorm2d-33          [-1, 128, 28, 28]             256<br/>        LeakyReLU-34          [-1, 128, 28, 28]               0<br/> ResNetBasicBlock-35          [-1, 128, 28, 28]               0<br/>      ResNetLayer-36          [-1, 128, 28, 28]               0<br/>           Conv2d-37          [-1, 256, 14, 14]          32,768<br/>      BatchNorm2d-38          [-1, 256, 14, 14]             512<br/>       Conv2dAuto-39          [-1, 256, 14, 14]         294,912<br/>      BatchNorm2d-40          [-1, 256, 14, 14]             512<br/>        LeakyReLU-41          [-1, 256, 14, 14]               0<br/>       Conv2dAuto-42          [-1, 256, 14, 14]         589,824<br/>      BatchNorm2d-43          [-1, 256, 14, 14]             512<br/>        LeakyReLU-44          [-1, 256, 14, 14]               0<br/> ResNetBasicBlock-45          [-1, 256, 14, 14]               0<br/>       Conv2dAuto-46          [-1, 256, 14, 14]         589,824<br/>      BatchNorm2d-47          [-1, 256, 14, 14]             512<br/>        LeakyReLU-48          [-1, 256, 14, 14]               0<br/>       Conv2dAuto-49          [-1, 256, 14, 14]         589,824<br/>      BatchNorm2d-50          [-1, 256, 14, 14]             512<br/>        LeakyReLU-51          [-1, 256, 14, 14]               0<br/> ResNetBasicBlock-52          [-1, 256, 14, 14]               0<br/>      ResNetLayer-53          [-1, 256, 14, 14]               0<br/>           Conv2d-54            [-1, 512, 7, 7]         131,072<br/>      BatchNorm2d-55            [-1, 512, 7, 7]           1,024<br/>       Conv2dAuto-56            [-1, 512, 7, 7]       1,179,648<br/>      BatchNorm2d-57            [-1, 512, 7, 7]           1,024<br/>        LeakyReLU-58            [-1, 512, 7, 7]               0<br/>       Conv2dAuto-59            [-1, 512, 7, 7]       2,359,296<br/>      BatchNorm2d-60            [-1, 512, 7, 7]           1,024<br/>        LeakyReLU-61            [-1, 512, 7, 7]               0<br/> ResNetBasicBlock-62            [-1, 512, 7, 7]               0<br/>       Conv2dAuto-63            [-1, 512, 7, 7]       2,359,296<br/>      BatchNorm2d-64            [-1, 512, 7, 7]           1,024<br/>        LeakyReLU-65            [-1, 512, 7, 7]               0<br/>       Conv2dAuto-66            [-1, 512, 7, 7]       2,359,296<br/>      BatchNorm2d-67            [-1, 512, 7, 7]           1,024<br/>        LeakyReLU-68            [-1, 512, 7, 7]               0<br/> ResNetBasicBlock-69            [-1, 512, 7, 7]               0<br/>      ResNetLayer-70            [-1, 512, 7, 7]               0<br/>    ResNetEncoder-71            [-1, 512, 7, 7]               0<br/>AdaptiveAvgPool2d-72            [-1, 512, 1, 1]               0<br/>           Linear-73                 [-1, 1000]         513,000<br/>    ResnetDecoder-74                 [-1, 1000]               0<br/>================================================================<br/>Total params: 11,689,512<br/>Trainable params: 11,689,512<br/>Non-trainable params: 0<br/>----------------------------------------------------------------<br/>Input size (MB): 0.57<br/>Forward/backward pass size (MB): 65.86<br/>Params size (MB): 44.59<br/>Estimated Total Size (MB): 111.03<br/>----------------------------------------------------------------</span></pre><h1 id="21ad" class="lk ll ji bd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh bi translated">ç»“è®º</h1><p id="1274" class="pw-post-body-paragraph kf kg ji kh b ki mi kk kl km mj ko kp kq mk ks kt ku ml kw kx ky mm la lb lc im bi translated">åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬çœ‹åˆ°äº†å¦‚ä½•ä»¥ä¸€ç§è‰¯å¥½çš„ã€å¯ä¼¸ç¼©çš„å’Œå¯å®šåˆ¶çš„æ–¹å¼å®ç° ResNetã€‚åœ¨ä¸‹ä¸€ç¯‡æ–‡ç« ä¸­ï¼Œæˆ‘ä»¬å°†è¿›ä¸€æ­¥æ‰©å±•è¿™ä¸ªæ¶æ„ï¼Œè®­ç»ƒå®ƒå¹¶ä½¿ç”¨å¦å¤–ä¸¤ä¸ªæŠ€å·§:é¢„æ¿€æ´»å’ŒæŒ¤å‹å’Œæ¿€åŠ±ã€‚</p><p id="fa49" class="pw-post-body-paragraph kf kg ji kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">è¿™é‡Œæ‰€æœ‰çš„ä»£ç éƒ½æ˜¯<a class="ae le" href="https://github.com/FrancescoSaverioZuppichini/ResNet" rel="noopener ugc nofollow" target="_blank">è¿™é‡Œæ˜¯</a></p><p id="bd9c" class="pw-post-body-paragraph kf kg ji kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">å¦‚æœä½ å¯¹ç†è§£æ›´å¥½çš„ç¥ç»ç½‘ç»œæ„Ÿå…´è¶£ï¼Œæˆ‘å»ºè®®ä½ è¯»ä¸€è¯»æˆ‘å†™çš„å¦ä¸€ç¯‡æ–‡ç« </p><div class="is it gp gr iu ne"><a rel="noopener follow" target="_blank" href="/a-journey-into-convolutional-neural-network-visualization-1abc71605209"><div class="nf ab fo"><div class="ng ab nh cl cj ni"><h2 class="bd jj gy z fp nj fr fs nk fu fw jh bi translated">å·ç§¯ç¥ç»ç½‘ç»œå¯è§†åŒ–ä¹‹æ—…</h2><div class="nl l"><h3 class="bd b gy z fp nj fr fs nk fu fw dk translated">å¼—æœ—è¥¿æ–¯ç§‘Â·è¨ç»´é‡Œå¥¥Â·ç¥–çš®å¥‡å°¼</h3></div><div class="nm l"><p class="bd b dl z fp nj fr fs nk fu fw dk translated">towardsdatascience.com</p></div></div><div class="nn l"><div class="no l np nq nr nn ns ja ne"/></div></div></a></div><p id="c0eb" class="pw-post-body-paragraph kf kg ji kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">æƒ³çŸ¥é“å¦‚ä½•å®ç° RepVGGï¼ŸResNet çš„æ›´å¥½ç‰ˆæœ¬ï¼Ÿ</p><div class="is it gp gr iu ne"><a rel="noopener follow" target="_blank" href="/implementing-repvgg-in-pytorch-fc8562be58f9"><div class="nf ab fo"><div class="ng ab nh cl cj ni"><h2 class="bd jj gy z fp nj fr fs nk fu fw jh bi translated">åœ¨ PyTorch ä¸­å®ç° RepVGG</h2><div class="nl l"><h3 class="bd b gy z fp nj fr fs nk fu fw dk translated">è®©æ‚¨çš„ CNN é€Ÿåº¦å¿« 100 å€ä»¥ä¸Š</h3></div><div class="nm l"><p class="bd b dl z fp nj fr fs nk fu fw dk translated">towardsdatascience.com</p></div></div><div class="nn l"><div class="nt l np nq nr nn ns ja ne"/></div></div></a></div><p id="f735" class="pw-post-body-paragraph kf kg ji kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">äº†è§£ PyTorch ä¸­çš„éæœ€å¤§æŠ‘åˆ¶</p><div class="is it gp gr iu ne"><a href="https://medium.com/@FrancescoZ/non-max-suppression-nms-in-pytorch-35f77397a0aa" rel="noopener follow" target="_blank"><div class="nf ab fo"><div class="ng ab nh cl cj ni"><h2 class="bd jj gy z fp nj fr fs nk fu fw jh bi translated">PyTorch ä¸­çš„éæœ€å¤§æŠ‘åˆ¶(NMS)</h2><div class="nl l"><h3 class="bd b gy z fp nj fr fs nk fu fw dk translated">åœ¨ PyTorch ä¸­å®ç°éæœ€å¤§æŠ‘åˆ¶</h3></div><div class="nm l"><p class="bd b dl z fp nj fr fs nk fu fw dk translated">medium.com</p></div></div><div class="nn l"><div class="nu l np nq nr nn ns ja ne"/></div></div></a></div><p id="a9f4" class="pw-post-body-paragraph kf kg ji kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">æ„Ÿè°¢æ‚¨çš„é˜…è¯»</p><p id="d2cf" class="pw-post-body-paragraph kf kg ji kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">å¼—æœ—è¥¿æ–¯ç§‘Â·è¨ç»´é‡Œå¥¥Â·ç¥–çš®å¥‡å°¼</p></div></div>    
</body>
</html>