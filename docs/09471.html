<html>
<head>
<title>Identifying Competitors Using Word Vectorization &amp; K-Means Clustering</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用单词矢量化和 K-Means 聚类识别竞争对手</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/identifying-competitors-using-word-vectorization-k-nearest-neighbors-412f1cea2506?source=collection_archive---------29-----------------------#2019-12-13">https://towardsdatascience.com/identifying-competitors-using-word-vectorization-k-nearest-neighbors-412f1cea2506?source=collection_archive---------29-----------------------#2019-12-13</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><h2 id="5907" class="ir is it bd b dl iu iv iw ix iy iz dk ja translated" aria-label="kicker paragraph">面向小型企业的数据科学</h2><div class=""/><div class=""><h2 id="7b76" class="pw-subtitle-paragraph jz jc it bd b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq dk translated">构建一种算法来帮助小企业利用 Yelp 数据。</h2></div><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi kr"><img src="../Images/9ff5e2a58e63bcb2303800c14ecec807.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*wJZbLHQ7kgyh92dtkj9B6Q.png"/></div></div></figure><p id="ec30" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">Yelp 为企业提供了丰富的信息来源，在分析相对于竞争对手的销售和服务表现时可以加以利用。利用这些数据是完全不同的事情。我想创造一种算法，让小企业相对容易地做到这一点。</p><p id="88cc" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">在本帖中，我们将探讨如何使用分类标签，通过词汇矢量化和 k-means 聚类来确定企业最相关的竞争对手。为了便于说明，我们将使用纽约市我最喜欢的当地餐馆之一:<a class="ae lz" href="https://www.yelp.com/biz/chanos-cantina-astoria" rel="noopener ugc nofollow" target="_blank"> Chano's Cantina </a>。使用<a class="ae lz" rel="noopener" target="_blank" href="/getting-started-with-the-yelp-api-ac30915a77ae"> Yelp API </a>，我获得了阿斯托里亚<em class="ma">墨西哥餐馆&amp;酒吧</em>的前 50 个搜索结果，并将它们保存到 dataframe 中。</p><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="mb mc l"/></div></figure><p id="6a30" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">我们的目标是确定 Chano's 与其竞争对手相比如何，确定餐厅做得好的地方和有待改进的地方。然而，试图将一家餐厅与 49 家潜在竞争对手进行比较可能会引入太多噪音，以至于很难提取出任何有意义的结果。相反，我们想找出 5-10 个在价格和产品供应方面与 Chano 最相似的竞争对手。我们如何找出哪些餐厅在这方面最相似？k-均值聚类！</p><h2 id="1ca1" class="md me it bd mf mg mh dn mi mj mk dp ml lm mm mn mo lq mp mq mr lu ms mt mu iz bi translated">数据选择</h2><p id="bdb8" class="pw-post-body-paragraph ld le it lf b lg mv kd li lj mw kg ll lm mx lo lp lq my ls lt lu mz lw lx ly im bi translated">让我们看看 Chano 的 Yelp 页面，看看哪些信息可能最适合手头的任务。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi na"><img src="../Images/5977dcb384d28aa7fe9be06bf5a2a4ad.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*KNta-uZBqZiWS5uydBl52w.png"/></div></div><figcaption class="nb nc gj gh gi nd ne bd b be z dk"><a class="ae lz" href="https://www.yelp.com/biz/chanos-cantina-astoria" rel="noopener ugc nofollow" target="_blank">https://www.yelp.com/biz/chanos-cantina-astoria</a></figcaption></figure><p id="e841" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">从上面，我们看到了一个带有两个美元符号的价格估计，以及几个关于<em class="ma">鸡尾酒吧</em>和<em class="ma">新墨西哥美食的标签。</em>很自然，我们希望将 Chano's 与类似的餐厅进行比较，因此我们希望找到标签和价格范围相同的餐厅。问题是大多数餐馆不会完全匹配，所以我们想尽可能接近。</p><p id="79cf" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">如果我们回顾我们的 API 结果，我们会看到相关信息在列<em class="ma">类别</em>和<em class="ma">价格中。</em>请注意，我们没有使用<em class="ma">评级</em>变量，因为这将是我们以后的目标。让我们清除一些混乱，以便更好地理解我们正在处理的内容。</p><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="mb mc l"/></div></figure><h2 id="dccb" class="md me it bd mf mg mh dn mi mj mk dp ml lm mm mn mo lq mp mq mr lu ms mt mu iz bi translated">预处理</h2><p id="c22c" class="pw-post-body-paragraph ld le it lf b lg mv kd li lj mw kg ll lm mx lo lp lq my ls lt lu mz lw lx ly im bi translated">这里我们有 50 条记录，我们希望使用类别和价格数据将其减少到不到 10 条。两个问题:</p><ul class=""><li id="c51a" class="nf ng it lf b lg lh lj lk lm nh lq ni lu nj ly nk nl nm nn bi translated"><strong class="lf jd">类别</strong>是以字符串形式保存在内存中的字典列表。</li><li id="4e80" class="nf ng it lf b lg no lj np lm nq lq nr lu ns ly nk nl nm nn bi translated">用美元符号表示的价格，不容易被机器解释。</li></ul><p id="479c" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">价格是更容易处理的问题:我们可以用一个表示美元符号数量的整数来代替这个值。然后我们可以用四舍五入到零位的平均价格来填充空值。</p><pre class="ks kt ku kv gt nt nu nv nw aw nx bi"><span id="9a91" class="md me it nu b gy ny nz l oa ob">df.price.replace(to_replace = ['$', '$$', '$$$', '$$$$'], <br/>                 value = [1, 2, 3, 4], <br/>                 inplace = True)</span><span id="d1d3" class="md me it nu b gy oc nz l oa ob">df.price.fillna(np.round(df.price.mean(), 0), inplace = True)</span></pre><p id="2164" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">关于分类标签，我们需要 Python 将每个企业的字符串值作为代码读取，这样我们就可以分离出我们需要的信息。例如，Chano's Cantina 的类别保存为:</p><pre class="ks kt ku kv gt nt nu nv nw aw nx bi"><span id="1ff8" class="md me it nu b gy ny nz l oa ob">"[{'alias': 'cocktailbars', 'title': 'Cocktail Bars'}, {'alias': 'newmexican', 'title': 'New Mexican Cuisine'}]"</span></pre><p id="4d5a" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">我们希望 Python 将这个字符串解释为字典列表，而不是将其作为字符串读取。幸运的是，通过使用<a class="ae lz" href="https://docs.python.org/3/library/ast.html" rel="noopener ugc nofollow" target="_blank">抽象语法树</a>库并调用<em class="ma"> literal_eval </em>方法，然后将结果保存为变量，我们可以很容易地做到这一点。从这里开始，只需遍历每条记录，获取标题单词，删除标点符号，并将所有单词转换为小写。我们可以将这些结果与价格值结合起来，并将结果保存到一个名为<em class="ma">标签的列中。</em>代码以及 Chano 的相关输出如下。</p><pre class="ks kt ku kv gt nt nu nv nw aw nx bi"><span id="6a31" class="md me it nu b gy ny nz l oa ob">import ast<br/>import re</span><span id="afe5" class="md me it nu b gy oc nz l oa ob">df['tags'] = ''</span><span id="a730" class="md me it nu b gy oc nz l oa ob">for ix in df.index:<br/><em class="ma">    # Evaluate categories as code<br/></em>    cat = ast.literal_eval(df['categories'][ix])<br/>    <br/><em class="ma">    # Save tags as single string<br/></em>    words = ''<br/>    for tag in cat:<br/>        words += f"{tag['title']} "<br/>    <br/><em class="ma">    # Remove punctuation<br/></em>    words = re.sub(r'[^\w\s]', ' ', words)</span><span id="1623" class="md me it nu b gy oc nz l oa ob">df.loc[ix, 'tags'] = ' '.join([words.lower(), str(int(df.loc[ix, 'price']))])</span><span id="9a08" class="md me it nu b gy oc nz l oa ob">OUTPUT:<br/>'cocktail bars new mexican cuisine 2'</span></pre><p id="844b" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">我们可以使用自然语言工具包(NLTK)将这些输出转换成单词标记列表。</p><pre class="ks kt ku kv gt nt nu nv nw aw nx bi"><span id="6754" class="md me it nu b gy ny nz l oa ob">from nltk import word_tokenize<br/>df['tags'] = df['tags'].map(word_tokenize).values</span><span id="5079" class="md me it nu b gy oc nz l oa ob">OUTPUT:<br/>['cocktail', 'bars', 'new', 'mexican', 'cuisine', '2']</span></pre><p id="8f62" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">您可能会问自己，为什么我们不为类别创建虚拟变量。这种方法<em class="ma">会是一种更直接的方式；然而，这也将导致对类别的解释是独特的离散。这种方法的问题是，诸如“墨西哥”和“新墨西哥美食”的标签非常相似。通过使用虚拟变量，我们会错过这种细微差别。为此，我们将使用单词表示的<a class="ae lz" href="https://nlp.stanford.edu/projects/glove/" rel="noopener ugc nofollow" target="_blank">全局向量</a> (GloVe)来解释分类标签。</em></p><h2 id="813f" class="md me it bd mf mg mh dn mi mj mk dp ml lm mm mn mo lq mp mq mr lu ms mt mu iz bi translated">单词矢量化</h2><p id="aa03" class="pw-post-body-paragraph ld le it lf b lg mv kd li lj mw kg ll lm mx lo lp lq my ls lt lu mz lw lx ly im bi translated">如果你不熟悉的话，单词矢量化是一种在高维空间中用数字表示单词的方法。那是什么意思？好吧，假设我们想根据动物的毛绒绒程度和友好程度来比较它们，我们把它们放在 1-10 的范围内。一只博美犬可能因为非常蓬松而得到 10 分，因为非常友好而得到 9 分。(我妻子告诉我博美犬不是特别友好，但让我们假装它们是！)</p><p id="a399" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">另一方面，一只短吻鳄可能在两个评分中都得到 1 分。我们可以用图表直观地表示这些单词:</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi od"><img src="../Images/105e0f62af5a6764063f7fa18780546b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*KrD7Jvhgl4nvWeq97Qm1YQ.png"/></div></div></figure><p id="80f8" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">使用这些维度，我们可以将每种动物表示为一个向量，第一个值表示蓬松度，第二个值表示友好度。更重要的是，我们可以想象在这条线上的不同点可能存在其他动物。你能想到一种比短吻鳄更蓬松、更友好，但没有博美犬蓬松、友好的动物吗？狒狒怎么样？如果我们计算这两个向量的平均值，我们就能算出狒狒在图上的位置。我们可以用算法将这一过程表示如下:</p><pre class="ks kt ku kv gt nt nu nv nw aw nx bi"><span id="6230" class="md me it nu b gy ny nz l oa ob">pomeranian = np.array([10, 9])<br/>alligator = np.array([1, 1])</span><span id="7df8" class="md me it nu b gy oc nz l oa ob">baboon = (pomeranian + alligator) / 2<br/>baboon</span><span id="e64f" class="md me it nu b gy oc nz l oa ob">OUTPUT:<br/>array([5.5, 5.])</span></pre><p id="71fa" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">输出表示在图表上放置狒狒的坐标。我们可以无限地扩展这个概念来描述各种各样的词，并理解它们之间的关系。面对如此无限的可能性，我们该从哪里开始呢？幸运的是，我们不必回答这个问题，因为斯坦福大学已经建立了一个模型，包含英语中 60 亿个单词的单词向量:这是 GloVe。每个单词都被表示为一个 50-300 维的向量，并且可以免费访问以用于您自己的模型。可以<a class="ae lz" href="http://nlp.stanford.edu/data/glove.6B.zip" rel="noopener ugc nofollow" target="_blank">这里下载</a>；请记住，该文件高达 822 兆字节。</p><h2 id="3d9c" class="md me it bd mf mg mh dn mi mj mk dp ml lm mm mn mo lq mp mq mr lu ms mt mu iz bi translated">用手套来代表单词</h2><p id="c1df" class="pw-post-body-paragraph ld le it lf b lg mv kd li lj mw kg ll lm mx lo lp lq my ls lt lu mz lw lx ly im bi translated">zip 文件包含四个以 UTF 8 格式编码的文本文件。每个文件包含相同的单词库，每行代表该单词的向量。文件之间的区别在于维数:50、100、200 和 300。出于我们的目的，我们将使用 50 个维度，因此我们首先将文件<em class="ma"> glove.6B.50d.txt </em>保存到与 Jupyter 笔记本相同的路径。</p><p id="d5e7" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">将向量分配给唯一单词的过程非常简单。</p><ol class=""><li id="41e7" class="nf ng it lf b lg lh lj lk lm nh lq ni lu nj ly oe nl nm nn bi translated">创建一个在我们新创建的<em class="ma">标签</em>栏中使用的独特词汇列表。</li><li id="3546" class="nf ng it lf b lg no lj np lm nq lq nr lu ns ly oe nl nm nn bi translated">从 GloVe 中获取代表每个单词的向量。</li><li id="43e3" class="nf ng it lf b lg no lj np lm nq lq nr lu ns ly oe nl nm nn bi translated">将结果保存为字典，使用单词作为键，向量作为值。</li></ol><pre class="ks kt ku kv gt nt nu nv nw aw nx bi"><span id="2aaf" class="md me it nu b gy ny nz l oa ob"><em class="ma"># Get unique words<br/></em>total_vocabulary = set(word.lower() for tag in df['tags'] for word in tag)</span><span id="b16d" class="md me it nu b gy oc nz l oa ob">def get_vectors(vocabulary):<br/>    <em class="ma"># Function to get vectors for words in vocabulary</em><br/>    glove = {}<br/>    with open('glove.6B.50d.txt', 'rb') as f:<br/>        for line in f:<br/>            parts = line.split()<br/>            word = parts[0].decode('utf-8')<br/>            if word in vocabulary:<br/>                vector = np.array(parts[1:], dtype=np.float32)<br/>                glove[word] = vector<br/>                <br/>    return glove</span><span id="04b7" class="md me it nu b gy oc nz l oa ob">glove = get_vectors(total_vocabulary)</span></pre><p id="73c2" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">有了我们的相关向量字典，我们现在想将它们应用到每个企业的特定标签集，获得每个公司的平均向量。我们可以创建一个类来完成这项工作，使用 map 函数将它应用到 tags 列。</p><pre class="ks kt ku kv gt nt nu nv nw aw nx bi"><span id="1cbe" class="md me it nu b gy ny nz l oa ob">class W2vVectorizer(object):<br/>    <br/>    def __init__(self, w2v):<br/>        <em class="ma"># Takes in a dictionary of words and vectors as input</em><br/>        self.w2v = w2v<br/>        if len(w2v) == 0:<br/>            self.dimensions = 0<br/>        else:<br/>            self.dimensions = len(w2v[next(iter(glove))])<br/>    <br/>    def fit(self, X, y):<br/>        return self<br/>            <br/>    def transform(self, X):<br/>        <em class="ma"># Get mean value of vectors from a list of words</em><br/>        return np.array([<br/>            np.mean([self.w2v[w] for w in words if w in self.w2v]<br/>                    or [np.zeros(self.dimensions)], axis=0) <br/>                    for words in X])</span></pre><p id="baca" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">该类接受单词和向量的字典，并通过调用 transform 方法为任何单词列表提供平均向量。</p><h2 id="db59" class="md me it bd mf mg mh dn mi mj mk dp ml lm mm mn mo lq mp mq mr lu ms mt mu iz bi translated">不戴手套的话</h2><p id="f14b" class="pw-post-body-paragraph ld le it lf b lg mv kd li lj mw kg ll lm mx lo lp lq my ls lt lu mz lw lx ly im bi translated">超过 40 万个单词有 60 亿个代币，很难想象一个单词不会在手套中找到。然而，在这个例子中我们确实遇到了一种:腹足类。有趣的是，这个单词的单数形式是存在的，所以使用<a class="ae lz" href="http://www.nltk.org/api/nltk.stem.html" rel="noopener ugc nofollow" target="_blank">词干和词汇化</a>是这个问题的第一个潜在解决方案。然而，在 NLTK 库中也没有找到这个单词。是时候发挥创造力了！</p><p id="84fa" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">我的下一个想法是使用韦氏词典查找音节，但是没有。最简单的解决方案是为丢失的单词插入零向量，或者从所有标签中删除它，但是我不想丢失信息。相反，我们可以从韦氏词典获得<a class="ae lz" href="https://www.merriam-webster.com/dictionary/gastropubs" rel="noopener ugc nofollow" target="_blank">字典定义</a>，并应用与上面类似的方法获得单词定义的平均向量。</p><p id="76a4" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">这个任务从使用<a class="ae lz" href="https://www.crummy.com/software/BeautifulSoup/bs4/doc/" rel="noopener ugc nofollow" target="_blank">美汤</a>的一些网页抓取开始。作为下一篇文章的一部分，我们将更详细地讨论网络抓取这个话题，所以，现在，我将只向您展示从韦氏词典的网站上获取任何单词的定义的代码。</p><pre class="ks kt ku kv gt nt nu nv nw aw nx bi"><span id="918d" class="md me it nu b gy ny nz l oa ob">from nltk import word_tokenize<br/>import requests<br/>from bs4 import BeautifulSoup as bs</span><span id="5832" class="md me it nu b gy oc nz l oa ob">def get_definition(word):<br/><em class="ma">    # Get webpage data for word definition<br/></em>    url = f'https://www.merriam-webster.com/dictionary/{word}'<br/>    r = requests.get(url)<br/>    <br/><em class="ma">    # Parse html<br/></em>    soup = bs(r.content, 'lxml')<br/>    definition = soup.find("span", {"class" : "dt"})<br/>    tag = definition.findChild()<br/>    definition = tag.find('strong').next_sibling.strip()<br/>    <br/><em class="ma">    # Clean text &amp; return tokenized definition<br/></em>    clean_def = re.sub(r'[^\w\s]', ' ', definition)<br/>    return word_tokenize(clean_def)</span></pre><p id="f14f" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">有了这个函数，我们就可以搜索 GloVe 中没有的单词，获得标记化的定义，然后使用我们的 vector 类获得相关单词的近似向量。</p><pre class="ks kt ku kv gt nt nu nv nw aw nx bi"><span id="fb0e" class="md me it nu b gy ny nz l oa ob"><em class="ma"># Get tokenized definitions for words not in Glove<br/></em>no_vectors = {}<br/>for word in total_vocabulary:<br/>    if word not in glove.keys():<br/>        no_vectors[word] = get_definition(word)</span><span id="e416" class="md me it nu b gy oc nz l oa ob"><em class="ma"># Add unique words from tokenized definitions to glove dictionary<br/></em>for key in no_vectors.keys():<br/>    words_to_add = []<br/>    for word in no_vectors[key]:<br/>        if word not in list(glove.keys()):<br/>            words_to_add.append(word)<br/>            <br/>    words_to_add = list(set(words_to_add))<br/>    new_vects = get_vectors(words_to_add)<br/>    glove.update(new_vects)</span><span id="ec9f" class="md me it nu b gy oc nz l oa ob"><em class="ma"># Calculate vectors for missing words to glove<br/></em>vectors = W2vVectorizer(glove)<br/>for key in no_vectors.keys():<br/>    vect = vectors.transform(no_vectors[key])<br/><strong class="nu jd">    glove[key] = np.average(vect, axis=0)<br/></strong>    <br/>print(sorted(list(glove.keys())))</span><span id="c728" class="md me it nu b gy oc nz l oa ob">OUTPUT:<br/>['1', '2', '3', 'a', 'american', 'bar', 'bars', 'beer', 'breakfast', 'brunch', 'chicken', 'cocktail', 'coffee', 'cuisine', 'event', 'gastropubs', 'grocery', 'high', 'irish', 'italian', 'latin', 'lounges', 'meals', 'mex', 'mexican', 'new', 'of', 'offers', 'or', 'peruvian', 'plates', 'pub', 'pubs', 'quality', 'seafood', 'small', 'southern', 'spaces', 'spirits', 'sports', 'tacos', 'tapas', 'tavern', 'tea', 'tex', 'that', 'traditional', 'venues', 'wine', 'wings']</span></pre><p id="f4a4" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">需要记住的一点是，向量的平均值返回高维空间中的值。但是，我们希望返回一个与所有其他单词形状相同的值，这由加粗的代码行处理。</p><p id="1ee2" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">随着我们所有的标签被正确地矢量化，我们现在可以继续进行聚类，以确定 Chano 的最直接的竞争对手。</p><h2 id="724f" class="md me it bd mf mg mh dn mi mj mk dp ml lm mm mn mo lq mp mq mr lu ms mt mu iz bi translated">k 均值聚类</h2><p id="452b" class="pw-post-body-paragraph ld le it lf b lg mv kd li lj mw kg ll lm mx lo lp lq my ls lt lu mz lw lx ly im bi translated">有很多博客文章详细介绍了 k-means 聚类的无监督学习机制，所以我在这里不打算全部重复。主要要知道的是，k-means 聚类是一种无监督的学习方法，它根据数据点的相似程度对它们进行分组。</p><p id="cc04" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">为了说明这一点，让我们回到短吻鳄和博美犬的比较。这一次，我们将在图表中添加一些其他动物。k-均值聚类的目的是识别一组随机动物的适当分组。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi of"><img src="../Images/b06d001247d1f47d719bd3ae294a9cc2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ctGYDffl-i_YmPc9t8I3eQ.png"/></div></div></figure><p id="293b" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">在这里，我们可以看到青蛙比鳄鱼友好一点，但一点也不蓬松。哈巴狗不如博美犬蓬松，但它更友好一些。然后还有蜜獾和狼蛛，有点蓬松，但不是特别友好。基于他们的分数，k-means 聚类旨在找出如何最好地对他们进行分组。</p><p id="ec0f" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">这个任务看起来很简单，但是如果我告诉你有必要把这些分成两组而不是三组呢？或者改为四组怎么样？我们可以想象，如果不知道最佳的组数，任务会变得更加复杂。</p><p id="e063" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">我们的目标是根据他们的 Yelp 标签和价格估计，找出 5-10 个与 Chano 最相似的竞争对手。对于本分析的其余部分，我们将重点关注 k-means 聚类的实现。尽管如此，如果你不熟悉算法的机制，我还是建议你看一看甲骨文的这篇简介。</p><h2 id="03e5" class="md me it bd mf mg mh dn mi mj mk dp ml lm mm mn mo lq mp mq mr lu ms mt mu iz bi translated">寻找最佳的聚类数</h2><p id="d8dc" class="pw-post-body-paragraph ld le it lf b lg mv kd li lj mw kg ll lm mx lo lp lq my ls lt lu mz lw lx ly im bi translated">有两种传统的方法来为 k-means 算法找到最佳的聚类数:</p><ol class=""><li id="81d8" class="nf ng it lf b lg lh lj lk lm nh lq ni lu nj ly oe nl nm nn bi translated">肘法</li><li id="c0df" class="nf ng it lf b lg no lj np lm nq lq nr lu ns ly oe nl nm nn bi translated">剪影法</li></ol><p id="eebc" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">对于每种方法，我们为一组组构建多个 k 均值算法，组的数量由字母<em class="ma"> k </em>表示。在这种情况下，我们将设置 2 到 10 个组或集群。使用肘方法，该算法估计每个分类的中心，然后测量分类中每个点离中心的平均距离。取这些距离的平均值得到了<strong class="lf jd"><em class="ma"/></strong><em class="ma">误差平方的组内和(WCSS)。随着星团数量的增加，我们可以绘制 WCSS，寻找 WCSS 趋于平稳的点。</em></p><p id="a0ac" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">为了说明这一点，我们随机生成一组点来代表 100 种不同的[理论上的]动物，并绘制在下面。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi og"><img src="../Images/1e836613a4ce59c68385793598d5ea31.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*pbvAjrJFAkPk99Xg1nshdQ.png"/></div></div></figure><p id="90d0" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">我们可以看到有三个不同的集群。让我们为 2–10 个集群构建 k-means 算法，看看 WCSS 会发生什么。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi oh"><img src="../Images/5c316f54fc1f3b4f1e050c0cae0ace86.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*yND12bwcb5eelCVJL0YBWA.png"/></div></div></figure><p id="1dc1" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">我们可以看到，在 3 个星团中，WCSS 到达了一个山谷。直觉上这是有道理的，但是区别并不总是清晰的，使得解释有些主观。更重要的是，我们不希望每次运行算法时都必须进行视觉检查。相反，我们将使用剪影法。</p><h2 id="fb64" class="md me it bd mf mg mh dn mi mj mk dp ml lm mm mn mo lq mp mq mr lu ms mt mu iz bi translated">剪影法</h2><p id="6ff2" class="pw-post-body-paragraph ld le it lf b lg mv kd li lj mw kg ll lm mx lo lp lq my ls lt lu mz lw lx ly im bi translated">使用剪影方法，我们查看一个簇中的点之间的平均距离，这被称为<strong class="lf jd">内聚</strong>。这个数字与组间的平均距离进行比较，这是对<strong class="lf jd">间距</strong>的测量。用非常简单的术语来说，我们寻找分离和内聚之间的差异最大化的簇的数量。和肘法一样，我们可以画出这些点。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi oi"><img src="../Images/66e3116e8bf9dd7e0b4198f27c882aa3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*tHnUTCRys-ffwvK4NUj9Nw.png"/></div></div></figure><p id="d09e" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">同样，我们可以看到最佳聚类数是 3，因为这是轮廓得分最大化的地方。然而，与 Elbow 方法不同，我们得到了一个清晰的最大值，可以很容易地通过编程来识别。</p><h2 id="8e14" class="md me it bd mf mg mh dn mi mj mk dp ml lm mm mn mo lq mp mq mr lu ms mt mu iz bi translated">把所有的放在一起</h2><p id="b3ae" class="pw-post-body-paragraph ld le it lf b lg mv kd li lj mw kg ll lm mx lo lp lq my ls lt lu mz lw lx ly im bi translated">有了手套向量和寻找最佳聚类数的方法，我们现在可以确定与 Chano 最相似的竞争对手。您可能已经从上面推断出，我们将需要多次实现该算法。幸运的是，这是这个过程中最简单的部分。</p><p id="7322" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">第一步:导入 K 均值算法。</p><pre class="ks kt ku kv gt nt nu nv nw aw nx bi"><span id="2e2f" class="md me it nu b gy ny nz l oa ob">from sklearn.cluster import KMeans</span></pre><p id="2be1" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">步骤 2:将标签转换为向量。</p><pre class="ks kt ku kv gt nt nu nv nw aw nx bi"><span id="448b" class="md me it nu b gy ny nz l oa ob">vectors = W2vVectorizer(glove)<br/>X = vectors.transform(df['tags'])</span></pre><p id="0064" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">第三步:找到最佳的聚类数。</p><pre class="ks kt ku kv gt nt nu nv nw aw nx bi"><span id="d23d" class="md me it nu b gy ny nz l oa ob">sil = []<br/>kmax = 10</span><span id="7377" class="md me it nu b gy oc nz l oa ob">for k in range(2, kmax+1):<br/>   kmeans = KMeans(n_clusters = k).fit(X)<br/>   labels = kmeans.labels_<br/>   sil.append(silhouette_score(X, labels, metric = 'euclidean'))<br/>        <br/>maxpos = sil.index(max(sil))<br/>n_clusters = maxpos + 2</span></pre><p id="7d1e" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">步骤 4:分配组标签并保存到数据帧。</p><pre class="ks kt ku kv gt nt nu nv nw aw nx bi"><span id="6291" class="md me it nu b gy ny nz l oa ob"><em class="ma"># Divide into k groups using k-mean clustering<br/></em>model = KMeans(n_clusters=n_clusters, init='k-means++',<br/>               max_iter=300, n_init=100)<br/>model.fit(X)<br/>    <br/><em class="ma"># Create group label column<br/></em>df['group'] = list(model.labels_)</span></pre><p id="a28e" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">第五步:筛选与 Chano 不在一个组的企业。</p><pre class="ks kt ku kv gt nt nu nv nw aw nx bi"><span id="088f" class="md me it nu b gy ny nz l oa ob">group = df[df['name'] == "Chano's Cantina"]['group'].values[0]<br/>new_df = df[df['group'] == group].reset_index(drop=True)</span></pre><p id="1cc5" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">步骤 6:对新的数据帧重复步骤 2 到 5，直到记录数少于 10。</p><p id="7e81" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">结果:下面，我们可以看到 Chano's 及其主要竞争对手的基本数据。</p><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="mb mc l"/></div></figure><h2 id="082c" class="md me it bd mf mg mh dn mi mj mk dp ml lm mm mn mo lq mp mq mr lu ms mt mu iz bi translated">后续步骤</h2><p id="9e26" class="pw-post-body-paragraph ld le it lf b lg mv kd li lj mw kg ll lm mx lo lp lq my ls lt lu mz lw lx ly im bi translated">既然我们已经正确地确定了 Chano 的主要竞争对手，我们就可以开始深入评论了。查看<em class="ma"> review_count </em>列，我们可以看到我们有近 1000 条评论要解析，但是 Yelp API 对可以访问的评论数量有严格限制。要绕过这一点，需要使用漂亮的汤进行一些繁重的网络抓取，但这是另一天的主题。</p></div></div>    
</body>
</html>