<html>
<head>
<title>The Complete Guide to Linear Regression in Python</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">Python 线性回归完全指南</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/the-complete-guide-to-linear-regression-in-python-3d3f8f06bf8?source=collection_archive---------0-----------------------#2019-06-18">https://towardsdatascience.com/the-complete-guide-to-linear-regression-in-python-3d3f8f06bf8?source=collection_archive---------0-----------------------#2019-06-18</a></blockquote><div><div class="fc ij ik il im in"/><div class="io ip iq ir is"><div class=""/><div class=""><h2 id="4c4f" class="pw-subtitle-paragraph js iu iv bd b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj dk translated">从理论到实践，学习线性回归的基本原理，并编写代码在数据集上实现它。</h2></div><figure class="kl km kn ko gt kp gh gi paragraph-image"><div role="button" tabindex="0" class="kq kr di ks bf kt"><div class="gh gi kk"><img src="../Images/93593b1496898b0b0f23984dff1c3185.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*guak1sQTh5sAf46NMzbQig.jpeg"/></div></div></figure><h1 id="4807" class="kw kx iv bd ky kz la lb lc ld le lf lg kb lh kc li ke lj kf lk kh ll ki lm ln bi translated">介绍</h1><p id="5445" class="pw-post-body-paragraph lo lp iv lq b lr ls jw lt lu lv jz lw lx ly lz ma mb mc md me mf mg mh mi mj io bi translated">本文试图成为您在理解和执行线性回归时需要的参考。虽然算法很简单，但只有少数人真正理解其中的基本原理。</p><p id="1de5" class="pw-post-body-paragraph lo lp iv lq b lr mk jw lt lu ml jz lw lx mm lz ma mb mn md me mf mo mh mi mj io bi translated">首先，我们将深入挖掘线性回归理论，以了解其内部工作原理。然后，我们将在 Python 中实现该算法来建模一个业务问题。</p><p id="0440" class="pw-post-body-paragraph lo lp iv lq b lr mk jw lt lu ml jz lw lx mm lz ma mb mn md me mf mo mh mi mj io bi translated">我希望这篇文章能找到你的书签！现在，让我们开始吧！</p><blockquote class="mp"><p id="996f" class="mq mr iv bd ms mt mu mv mw mx my mj dk translated">关于机器学习、深度学习和人工智能的实践视频教程，请查看我的<a class="ae mz" href="https://www.youtube.com/channel/UC-0lpiwlftqwC7znCcF83qg?view_as=subscriber" rel="noopener ugc nofollow" target="_blank"> YouTube 频道</a>。</p></blockquote><h1 id="23e8" class="kw kx iv bd ky kz la lb lc ld le lf lg kb na kc li ke nb kf lk kh nc ki lm ln bi translated">该理论</h1><figure class="kl km kn ko gt kp"><div class="bz fp l di"><div class="nd ne l"/></div><figcaption class="nf ng gj gh gi nh ni bd b be z dk">How you’ll feel studying linear regression</figcaption></figure><p id="6ab4" class="pw-post-body-paragraph lo lp iv lq b lr mk jw lt lu ml jz lw lx mm lz ma mb mn md me mf mo mh mi mj io bi translated">线性回归可能是统计学习最简单的方法。对于更高级的方法来说，这是一个很好的起点，事实上，许多新奇的统计学习技术可以被视为线性回归的扩展。因此，在进入更复杂的方法之前，理解这个简单的模型将建立一个良好的基础。</p><p id="5282" class="pw-post-body-paragraph lo lp iv lq b lr mk jw lt lu ml jz lw lx mm lz ma mb mn md me mf mo mh mi mj io bi translated">线性回归很好地回答了以下问题:</p><ul class=""><li id="489f" class="nj nk iv lq b lr mk lu ml lx nl mb nm mf nn mj no np nq nr bi translated">两个变量之间有关系吗？</li><li id="9a20" class="nj nk iv lq b lr ns lu nt lx nu mb nv mf nw mj no np nq nr bi translated">关系有多牢固？</li><li id="4a26" class="nj nk iv lq b lr ns lu nt lx nu mb nv mf nw mj no np nq nr bi translated">哪个变量的贡献最大？</li><li id="054f" class="nj nk iv lq b lr ns lu nt lx nu mb nv mf nw mj no np nq nr bi translated">我们能多精确地估计每个变量的影响？</li><li id="be58" class="nj nk iv lq b lr ns lu nt lx nu mb nv mf nw mj no np nq nr bi translated">我们能多精确地预测目标？</li><li id="e6a1" class="nj nk iv lq b lr ns lu nt lx nu mb nv mf nw mj no np nq nr bi translated">关系是线性的吗？(咄)</li><li id="608e" class="nj nk iv lq b lr ns lu nt lx nu mb nv mf nw mj no np nq nr bi translated">有交互作用吗？</li></ul><h2 id="a777" class="nx kx iv bd ky ny nz dn lc oa ob dp lg lx oc od li mb oe of lk mf og oh lm oi bi translated">估计系数</h2><p id="4167" class="pw-post-body-paragraph lo lp iv lq b lr ls jw lt lu lv jz lw lx ly lz ma mb mc md me mf mg mh mi mj io bi translated">假设我们只有一个变量和一个目标。然后，线性回归表示为:</p><figure class="kl km kn ko gt kp gh gi paragraph-image"><div role="button" tabindex="0" class="kq kr di ks bf kt"><div class="gh gi oj"><img src="../Images/9be7ae8ee9d11fe85b83cacf3605fa53.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*6ShYjDy-LBv3wQ26sZF8sQ@2x.png"/></div></div><figcaption class="nf ng gj gh gi nh ni bd b be z dk">Equation for a linear model with 1 variable and 1 target</figcaption></figure><p id="2c31" class="pw-post-body-paragraph lo lp iv lq b lr mk jw lt lu ml jz lw lx mm lz ma mb mn md me mf mo mh mi mj io bi translated">在上面的等式中，<em class="ok">β</em>是系数。这些系数是我们用模型进行预测所需要的。</p><p id="3fa5" class="pw-post-body-paragraph lo lp iv lq b lr mk jw lt lu ml jz lw lx mm lz ma mb mn md me mf mo mh mi mj io bi translated">那么我们如何找到这些参数呢？</p><p id="15c1" class="pw-post-body-paragraph lo lp iv lq b lr mk jw lt lu ml jz lw lx mm lz ma mb mn md me mf mo mh mi mj io bi translated">为了找到参数，我们需要最小化<strong class="lq iw">最小平方</strong>或<strong class="lq iw">误差平方和</strong>。当然，线性模型并不完美，它不会准确预测所有数据，这意味着实际值和预测值之间存在差异。误差很容易通过下式计算:</p><figure class="kl km kn ko gt kp gh gi paragraph-image"><div class="gh gi ol"><img src="../Images/eb6867c3e1afeb96533798af26290388.png" data-original-src="https://miro.medium.com/v2/resize:fit:1322/format:webp/1*hYt2F9dXepXYwqE0koXX_A@2x.png"/></div><figcaption class="nf ng gj gh gi nh ni bd b be z dk">Subtract the prediction from the true value</figcaption></figure><p id="7444" class="pw-post-body-paragraph lo lp iv lq b lr mk jw lt lu ml jz lw lx mm lz ma mb mn md me mf mo mh mi mj io bi translated">但是为什么误差是平方的呢？</p><p id="a33a" class="pw-post-body-paragraph lo lp iv lq b lr mk jw lt lu ml jz lw lx mm lz ma mb mn md me mf mo mh mi mj io bi translated">我们平方误差，因为预测可以高于或低于真实值，分别导致负的或正的差异。如果我们不对误差进行平方，误差的总和可能会因为负差异而减少，而不是因为模型非常适合。</p><p id="c4dd" class="pw-post-body-paragraph lo lp iv lq b lr mk jw lt lu ml jz lw lx mm lz ma mb mn md me mf mo mh mi mj io bi translated">此外，平方误差不利于较大的差异，因此最小化平方误差“保证”更好的模型。</p><p id="902a" class="pw-post-body-paragraph lo lp iv lq b lr mk jw lt lu ml jz lw lx mm lz ma mb mn md me mf mo mh mi mj io bi translated">让我们来看一个图表，以便更好地理解。</p><figure class="kl km kn ko gt kp gh gi paragraph-image"><div role="button" tabindex="0" class="kq kr di ks bf kt"><div class="gh gi om"><img src="../Images/925f74175baf8b72ea7c11f19308545d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ZC9jOzQPCsio3xqtK4aM2Q@2x.png"/></div></div><figcaption class="nf ng gj gh gi nh ni bd b be z dk">Linear fit to a data set</figcaption></figure><p id="7e7c" class="pw-post-body-paragraph lo lp iv lq b lr mk jw lt lu ml jz lw lx mm lz ma mb mn md me mf mo mh mi mj io bi translated">在上图中，红点是真实数据，蓝线是线性模型。灰色线条表示预测值和真实值之间的误差。因此，蓝线是使灰线的平方长度之和最小的线。</p><p id="bb97" class="pw-post-body-paragraph lo lp iv lq b lr mk jw lt lu ml jz lw lx mm lz ma mb mn md me mf mo mh mi mj io bi translated">经过一些对本文来说过于繁琐的数学计算后，您最终可以用下面的等式来估计系数:</p><figure class="kl km kn ko gt kp gh gi paragraph-image"><div class="gh gi on"><img src="../Images/f22960f727b78556e2210a508a995295.png" data-original-src="https://miro.medium.com/v2/resize:fit:1116/format:webp/1*oVnFCTLwxmlOGCtjMNYQqQ@2x.png"/></div></figure><figure class="kl km kn ko gt kp gh gi paragraph-image"><div class="gh gi oo"><img src="../Images/680d5eefd22fc33e2856690bdec59623.png" data-original-src="https://miro.medium.com/v2/resize:fit:616/format:webp/1*n48CcucPaBBIzza1ZFVQHw@2x.png"/></div></figure><p id="4ad2" class="pw-post-body-paragraph lo lp iv lq b lr mk jw lt lu ml jz lw lx mm lz ma mb mn md me mf mo mh mi mj io bi translated">其中<em class="ok"> x 条</em>和<em class="ok"> y 条</em>代表平均值。</p><h2 id="e4d6" class="nx kx iv bd ky ny nz dn lc oa ob dp lg lx oc od li mb oe of lk mf og oh lm oi bi translated">估计系数的相关性</h2><p id="98de" class="pw-post-body-paragraph lo lp iv lq b lr ls jw lt lu lv jz lw lx ly lz ma mb mc md me mf mg mh mi mj io bi translated">现在你有了系数，你如何知道它们是否与预测你的目标相关？</p><p id="8020" class="pw-post-body-paragraph lo lp iv lq b lr mk jw lt lu ml jz lw lx mm lz ma mb mn md me mf mo mh mi mj io bi translated">最好的方法是找到<em class="ok"> p 值。</em><em class="ok">p 值</em>用于量化统计显著性；它允许判断是否要拒绝零假设。</p><p id="af05" class="pw-post-body-paragraph lo lp iv lq b lr mk jw lt lu ml jz lw lx mm lz ma mb mn md me mf mo mh mi mj io bi translated">无效假设？</p><p id="39e7" class="pw-post-body-paragraph lo lp iv lq b lr mk jw lt lu ml jz lw lx mm lz ma mb mn md me mf mo mh mi mj io bi translated">对于任何建模任务，假设在特征和目标之间有某种关联。因此，零假设是相反的:<strong class="lq iw">在特征和目标之间没有相关性</strong>。</p><p id="3889" class="pw-post-body-paragraph lo lp iv lq b lr mk jw lt lu ml jz lw lx mm lz ma mb mn md me mf mo mh mi mj io bi translated">因此，找到每个系数的<em class="ok"> p 值</em>将会知道该变量对于预测目标是否具有统计显著性。根据一般经验，如果<em class="ok"> p 值</em>小于<strong class="lq iw">0.05</strong>:变量和目标之间有很强的关系。</p><h2 id="02db" class="nx kx iv bd ky ny nz dn lc oa ob dp lg lx oc od li mb oe of lk mf og oh lm oi bi translated">评估模型的准确性</h2><p id="a8e3" class="pw-post-body-paragraph lo lp iv lq b lr ls jw lt lu lv jz lw lx ly lz ma mb mc md me mf mg mh mi mj io bi translated">通过寻找变量的<em class="ok"> p 值</em>，您发现您的变量具有统计显著性。太好了！</p><p id="4590" class="pw-post-body-paragraph lo lp iv lq b lr mk jw lt lu ml jz lw lx mm lz ma mb mn md me mf mo mh mi mj io bi translated">现在，你怎么知道你的线性模型是好的呢？</p><p id="a84e" class="pw-post-body-paragraph lo lp iv lq b lr mk jw lt lu ml jz lw lx mm lz ma mb mn md me mf mo mh mi mj io bi translated">为了进行评估，我们通常使用 RSE(剩余标准误差)和 R 统计量。</p><figure class="kl km kn ko gt kp gh gi paragraph-image"><div role="button" tabindex="0" class="kq kr di ks bf kt"><div class="gh gi op"><img src="../Images/b425407f08c8ff3274c43981339f8570.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*F9g6XenPJN2AffG8yIzq8Q@2x.png"/></div></div><figcaption class="nf ng gj gh gi nh ni bd b be z dk">RSE formula</figcaption></figure><figure class="kl km kn ko gt kp gh gi paragraph-image"><div role="button" tabindex="0" class="kq kr di ks bf kt"><div class="gh gi oq"><img src="../Images/e1add1668b63d9e7c15ee73e57a222ea.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*nJ2zMf6Qxb3XfWa6n2Heag@2x.png"/></div></div><figcaption class="nf ng gj gh gi nh ni bd b be z dk">R² formula</figcaption></figure><p id="d23c" class="pw-post-body-paragraph lo lp iv lq b lr mk jw lt lu ml jz lw lx mm lz ma mb mn md me mf mo mh mi mj io bi translated">第一个误差指标很容易理解:残差越低，模型就越符合数据(在这种情况下，数据越接近线性关系)。</p><p id="863c" class="pw-post-body-paragraph lo lp iv lq b lr mk jw lt lu ml jz lw lx mm lz ma mb mn md me mf mo mh mi mj io bi translated">至于 R 度量，它测量目标中可以用特征 X 解释的<strong class="lq iw">可变性比例。所以假设线性关系，如果特征 X 能解释(预测)目标，那么比例高，R 值会接近 1。如果相反，R 值则更接近于 0。</strong></p><h1 id="39c1" class="kw kx iv bd ky kz la lb lc ld le lf lg kb lh kc li ke lj kf lk kh ll ki lm ln bi translated">多元线性回归理论</h1><p id="9061" class="pw-post-body-paragraph lo lp iv lq b lr ls jw lt lu lv jz lw lx ly lz ma mb mc md me mf mg mh mi mj io bi translated">在现实生活中，永远不会有单一的特征来预测目标。那么，我们一次对一个特征进行线性回归吗？当然不是。我们简单地执行多元线性回归。</p><p id="d171" class="pw-post-body-paragraph lo lp iv lq b lr mk jw lt lu ml jz lw lx mm lz ma mb mn md me mf mo mh mi mj io bi translated">该方程非常类似于简单的线性回归；简单地将预测值的数量和它们相应的系数相加:</p><figure class="kl km kn ko gt kp gh gi paragraph-image"><div class="gh gi or"><img src="../Images/8cc2ed14d32ae167ed11595445900aee.png" data-original-src="https://miro.medium.com/v2/resize:fit:1362/format:webp/1*CbYHku07Tjd50a50jttu2A@2x.png"/></div><figcaption class="nf ng gj gh gi nh ni bd b be z dk">Multiple linear regression equation. <strong class="bd os">p</strong> is the number of predictors</figcaption></figure><h2 id="8ab5" class="nx kx iv bd ky ny nz dn lc oa ob dp lg lx oc od li mb oe of lk mf og oh lm oi bi translated">评估预测值的相关性</h2><p id="b028" class="pw-post-body-paragraph lo lp iv lq b lr ls jw lt lu lv jz lw lx ly lz ma mb mc md me mf mg mh mi mj io bi translated">以前，在简单的线性回归中，我们通过寻找特征的<em class="ok"> p 值</em>来评估特征的相关性。</p><p id="bb26" class="pw-post-body-paragraph lo lp iv lq b lr mk jw lt lu ml jz lw lx mm lz ma mb mn md me mf mo mh mi mj io bi translated">在多元线性回归的情况下，我们使用另一个指标:F 统计量。</p><figure class="kl km kn ko gt kp gh gi paragraph-image"><div role="button" tabindex="0" class="kq kr di ks bf kt"><div class="gh gi ot"><img src="../Images/9a9a1d96d64cc15ff2fb46dc8b9c0b7c.png" data-original-src="https://miro.medium.com/v2/resize:fit:732/format:webp/1*W37Z8hscDevXdgvI3grGQw@2x.png"/></div></div><figcaption class="nf ng gj gh gi nh ni bd b be z dk">F-statistic formula. <strong class="bd os">n</strong> is the number of data points and <strong class="bd os">p</strong> is the number of predictors</figcaption></figure><p id="0a43" class="pw-post-body-paragraph lo lp iv lq b lr mk jw lt lu ml jz lw lx mm lz ma mb mn md me mf mo mh mi mj io bi translated">这里，F 统计量是针对整个模型计算的，而<em class="ok"> p 值</em>是针对每个预测值的。如果有强关系，那么 F 会远大于 1。否则，它将近似等于 1。</p><p id="accc" class="pw-post-body-paragraph lo lp iv lq b lr mk jw lt lu ml jz lw lx mm lz ma mb mn md me mf mo mh mi mj io bi translated">如何使<em class="ok">比</em>大<em class="ok">比 1 </em>足够大？</p><p id="c03d" class="pw-post-body-paragraph lo lp iv lq b lr mk jw lt lu ml jz lw lx mm lz ma mb mn md me mf mo mh mi mj io bi translated">这个很难回答。通常，如果有大量的数据点，F 可能略大于 1，表明有很强的关系。对于小数据集，F 值必须远大于 1，以表明强相关关系。</p><p id="ab5c" class="pw-post-body-paragraph lo lp iv lq b lr mk jw lt lu ml jz lw lx mm lz ma mb mn md me mf mo mh mi mj io bi translated">为什么我们不能在这种情况下使用<em class="ok"> p 值</em>？</p><p id="e08f" class="pw-post-body-paragraph lo lp iv lq b lr mk jw lt lu ml jz lw lx mm lz ma mb mn md me mf mo mh mi mj io bi translated">由于我们正在拟合许多预测值，因此我们需要考虑有许多特征的情况(<em class="ok"> p </em>很大)。对于非常大量的预测值，总有大约 5%的预测值偶然具有非常小的<em class="ok"> p 值</em> <strong class="lq iw"> <em class="ok">甚至</em> </strong> <em class="ok"> </em> <strong class="lq iw"> <em class="ok">，尽管它们在统计上不显著。因此，我们使用 F 统计量来避免将不重要的预测因子视为重要的预测因子。</em></strong></p><h2 id="84c4" class="nx kx iv bd ky ny nz dn lc oa ob dp lg lx oc od li mb oe of lk mf og oh lm oi bi translated">评估模型的准确性</h2><p id="2feb" class="pw-post-body-paragraph lo lp iv lq b lr ls jw lt lu lv jz lw lx ly lz ma mb mc md me mf mg mh mi mj io bi translated">就像简单的线性回归一样，R 可以用于多元线性回归。但是，要知道添加更多的预测值总是会增加 R 值，因为模型必然会更好地拟合训练数据。</p><p id="3ea8" class="pw-post-body-paragraph lo lp iv lq b lr mk jw lt lu ml jz lw lx mm lz ma mb mn md me mf mo mh mi mj io bi translated">然而，这并不意味着它将在测试数据上表现良好(对未知数据点进行预测)。</p><h2 id="81fe" class="nx kx iv bd ky ny nz dn lc oa ob dp lg lx oc od li mb oe of lk mf og oh lm oi bi translated">添加交互</h2><p id="f23b" class="pw-post-body-paragraph lo lp iv lq b lr ls jw lt lu lv jz lw lx ly lz ma mb mc md me mf mg mh mi mj io bi translated">一个线性模型中有多个预测因子意味着一些预测因子可能会对其他预测因子产生影响。</p><p id="5466" class="pw-post-body-paragraph lo lp iv lq b lr mk jw lt lu ml jz lw lx mm lz ma mb mn md me mf mo mh mi mj io bi translated">例如，你想预测一个人的工资，知道她的年龄和上学的年数。当然，一个人越老，他在学校度过的时间就越多。那么我们如何对这种互动效应建模呢？</p><p id="4178" class="pw-post-body-paragraph lo lp iv lq b lr mk jw lt lu ml jz lw lx mm lz ma mb mn md me mf mo mh mi mj io bi translated">考虑这个非常简单的例子，有两个预测值:</p><figure class="kl km kn ko gt kp gh gi paragraph-image"><div role="button" tabindex="0" class="kq kr di ks bf kt"><div class="gh gi ou"><img src="../Images/bf0c23f09636d9bc4d24d84916e92650.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*enACSDDH4l3sK2YrYJjgVA@2x.png"/></div></div><figcaption class="nf ng gj gh gi nh ni bd b be z dk">Interaction effect in multiple linear regression</figcaption></figure><p id="0ddb" class="pw-post-body-paragraph lo lp iv lq b lr mk jw lt lu ml jz lw lx mm lz ma mb mn md me mf mo mh mi mj io bi translated">如你所见，我们简单地将两个预测因子相乘，并关联一个新的系数。简化公式，我们现在看到系数受另一个特征的值的影响。</p><p id="6154" class="pw-post-body-paragraph lo lp iv lq b lr mk jw lt lu ml jz lw lx mm lz ma mb mn md me mf mo mh mi mj io bi translated">作为一般规则，如果我们包括交互模型，我们应该包括特征的个体效应，即使它的<em class="ok"> p 值</em>不显著。这就是所谓的<strong class="lq iw">等级原则</strong>。这背后的基本原理是，如果两个预测者相互作用，那么包括他们各自的贡献将对模型产生很小的影响。</p></div><div class="ab cl ov ow hz ox" role="separator"><span class="oy bw bk oz pa pb"/><span class="oy bw bk oz pa pb"/><span class="oy bw bk oz pa"/></div><div class="io ip iq ir is"><p id="7d61" class="pw-post-body-paragraph lo lp iv lq b lr mk jw lt lu ml jz lw lx mm lz ma mb mn md me mf mo mh mi mj io bi translated">好吧！现在我们知道了它是如何工作的，让我们让它工作吧！我们将通过 Python 中的简单和多元线性回归来工作，我将展示如何在这两种情况下评估参数和整体模型的质量。</p><p id="db93" class="pw-post-body-paragraph lo lp iv lq b lr mk jw lt lu ml jz lw lx mm lz ma mb mn md me mf mo mh mi mj io bi translated">你可以在这里抓取代码和数据<a class="ae mz" href="https://github.com/marcopeix/ISL-linear-regression" rel="noopener ugc nofollow" target="_blank">。</a></p><p id="2980" class="pw-post-body-paragraph lo lp iv lq b lr mk jw lt lu ml jz lw lx mm lz ma mb mn md me mf mo mh mi mj io bi translated">我强烈建议您在自己的 Jupyter 笔记本中遵循并重新创建这些步骤，以充分利用本教程。</p><p id="5d8e" class="pw-post-body-paragraph lo lp iv lq b lr mk jw lt lu ml jz lw lx mm lz ma mb mn md me mf mo mh mi mj io bi translated">我们开始吧！</p><figure class="kl km kn ko gt kp"><div class="bz fp l di"><div class="pc ne l"/></div><figcaption class="nf ng gj gh gi nh ni bd b be z dk">We all code like this, right?</figcaption></figure><h2 id="6931" class="nx kx iv bd ky ny nz dn lc oa ob dp lg lx oc od li mb oe of lk mf og oh lm oi bi translated">介绍</h2><p id="19fc" class="pw-post-body-paragraph lo lp iv lq b lr ls jw lt lu lv jz lw lx ly lz ma mb mc md me mf mg mh mi mj io bi translated">数据集包含关于花费在广告上的钱及其产生的销售额的信息。钱花在了电视、广播和报纸广告上。</p><p id="d33d" class="pw-post-body-paragraph lo lp iv lq b lr mk jw lt lu ml jz lw lx mm lz ma mb mn md me mf mo mh mi mj io bi translated"><strong class="lq iw">目标是使用线性回归来了解广告支出如何影响销售。</strong></p><h2 id="10be" class="nx kx iv bd ky ny nz dn lc oa ob dp lg lx oc od li mb oe of lk mf og oh lm oi bi translated">导入库</h2><p id="1ba8" class="pw-post-body-paragraph lo lp iv lq b lr ls jw lt lu lv jz lw lx ly lz ma mb mc md me mf mg mh mi mj io bi translated">使用 Python 的优势在于，我们可以访问许多库，这些库允许我们快速读取数据、绘制数据并执行线性回归。</p><p id="4875" class="pw-post-body-paragraph lo lp iv lq b lr mk jw lt lu ml jz lw lx mm lz ma mb mn md me mf mo mh mi mj io bi translated">我喜欢在笔记本顶部导入所有必要的库，以保持一切井然有序。导入以下内容:</p><pre class="kl km kn ko gt pd pe pf pg aw ph bi"><span id="a74e" class="nx kx iv pe b gy pi pj l pk pl">import pandas as pd<br/>import numpy as np</span><span id="a2a8" class="nx kx iv pe b gy pm pj l pk pl">import matplotlib.pyplot as plt</span><span id="5c5a" class="nx kx iv pe b gy pm pj l pk pl">from sklearn.linear_model import LinearRegression<br/>from sklearn.metrics import r2_score</span><span id="9504" class="nx kx iv pe b gy pm pj l pk pl">import statsmodels.api as sm</span></pre><h2 id="3c13" class="nx kx iv bd ky ny nz dn lc oa ob dp lg lx oc od li mb oe of lk mf og oh lm oi bi translated">读取数据</h2><p id="be35" class="pw-post-body-paragraph lo lp iv lq b lr ls jw lt lu lv jz lw lx ly lz ma mb mc md me mf mg mh mi mj io bi translated">假设您下载了数据集，将它放在项目文件夹内的一个<code class="fe pn po pp pe b">data</code>目录中。然后，像这样读取数据:</p><pre class="kl km kn ko gt pd pe pf pg aw ph bi"><span id="b794" class="nx kx iv pe b gy pi pj l pk pl">data = pd.read_csv("data/Advertising.csv")</span></pre><p id="f139" class="pw-post-body-paragraph lo lp iv lq b lr mk jw lt lu ml jz lw lx mm lz ma mb mn md me mf mo mh mi mj io bi translated">为了查看数据的样子，我们执行以下操作:</p><pre class="kl km kn ko gt pd pe pf pg aw ph bi"><span id="5307" class="nx kx iv pe b gy pi pj l pk pl">data.head()</span></pre><p id="f228" class="pw-post-body-paragraph lo lp iv lq b lr mk jw lt lu ml jz lw lx mm lz ma mb mn md me mf mo mh mi mj io bi translated">你应该看看这个:</p><figure class="kl km kn ko gt kp gh gi paragraph-image"><div class="gh gi pq"><img src="../Images/b2476d1299c6fcf14047cf587e85ffb7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1326/format:webp/1*FNfhnv-r5ZzHd56XBTpp6A@2x.png"/></div></figure><p id="fed2" class="pw-post-body-paragraph lo lp iv lq b lr mk jw lt lu ml jz lw lx mm lz ma mb mn md me mf mo mh mi mj io bi translated">如您所见，列<code class="fe pn po pp pe b">Unnamed: 0</code>是多余的。因此，我们删除它。</p><pre class="kl km kn ko gt pd pe pf pg aw ph bi"><span id="0cec" class="nx kx iv pe b gy pi pj l pk pl">data.drop(['Unnamed: 0'], axis=1)</span></pre><p id="e443" class="pw-post-body-paragraph lo lp iv lq b lr mk jw lt lu ml jz lw lx mm lz ma mb mn md me mf mo mh mi mj io bi translated">好了，我们的数据是干净的，可以进行线性回归了！</p><h1 id="c1f2" class="kw kx iv bd ky kz la lb lc ld le lf lg kb lh kc li ke lj kf lk kh ll ki lm ln bi translated">简单线性回归</h1><h2 id="9128" class="nx kx iv bd ky ny nz dn lc oa ob dp lg lx oc od li mb oe of lk mf og oh lm oi bi translated">系统模型化</h2><p id="3f68" class="pw-post-body-paragraph lo lp iv lq b lr ls jw lt lu lv jz lw lx ly lz ma mb mc md me mf mg mh mi mj io bi translated">对于简单的线性回归，我们只考虑电视广告对销售的影响。在开始建模之前，让我们看一下数据是什么样子的。</p><p id="5bd9" class="pw-post-body-paragraph lo lp iv lq b lr mk jw lt lu ml jz lw lx mm lz ma mb mn md me mf mo mh mi mj io bi translated">我们使用<code class="fe pn po pp pe b">matplotlib</code>，一个流行的 Python 绘图库来制作散点图。</p><pre class="kl km kn ko gt pd pe pf pg aw ph bi"><span id="2616" class="nx kx iv pe b gy pi pj l pk pl">plt.figure(figsize=(16, 8))<br/>plt.scatter(<br/>    data['TV'],<br/>    data['sales'],<br/>    c='black'<br/>)<br/>plt.xlabel("Money spent on TV ads ($)")<br/>plt.ylabel("Sales ($)")<br/>plt.show()</span></pre><p id="de8d" class="pw-post-body-paragraph lo lp iv lq b lr mk jw lt lu ml jz lw lx mm lz ma mb mn md me mf mo mh mi mj io bi translated">运行这个代码单元，您应该会看到这个图形:</p><figure class="kl km kn ko gt kp gh gi paragraph-image"><div role="button" tabindex="0" class="kq kr di ks bf kt"><div class="gh gi pr"><img src="../Images/5120c6a8f2df5c187fb679a07f3820e7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*adZn_xDeZ9nGKy309G6laQ@2x.png"/></div></div><figcaption class="nf ng gj gh gi nh ni bd b be z dk">Scatter plot of money spent on TV ads and sales</figcaption></figure><p id="bff3" class="pw-post-body-paragraph lo lp iv lq b lr mk jw lt lu ml jz lw lx mm lz ma mb mn md me mf mo mh mi mj io bi translated">正如你所看到的，在电视广告上的花费和销售额之间有着明显的关系。</p><p id="fc0c" class="pw-post-body-paragraph lo lp iv lq b lr mk jw lt lu ml jz lw lx mm lz ma mb mn md me mf mo mh mi mj io bi translated">让我们看看如何生成该数据的线性近似值。</p><pre class="kl km kn ko gt pd pe pf pg aw ph bi"><span id="513b" class="nx kx iv pe b gy pi pj l pk pl">X = data['TV'].values.reshape(-1,1)<br/>y = data['sales'].values.reshape(-1,1)</span><span id="5f32" class="nx kx iv pe b gy pm pj l pk pl">reg = LinearRegression()<br/>reg.fit(X, y)</span><span id="1d0d" class="nx kx iv pe b gy pm pj l pk pl">print("The linear model is: Y = {:.5} + {:.5}X".format(reg.intercept_[0], reg.coef_[0][0]))</span></pre><p id="cb7e" class="pw-post-body-paragraph lo lp iv lq b lr mk jw lt lu ml jz lw lx mm lz ma mb mn md me mf mo mh mi mj io bi translated">就这样？</p><p id="d047" class="pw-post-body-paragraph lo lp iv lq b lr mk jw lt lu ml jz lw lx mm lz ma mb mn md me mf mo mh mi mj io bi translated">是啊！对数据集拟合一条直线并查看方程的参数就是这么简单。在这种情况下，我们有</p><figure class="kl km kn ko gt kp gh gi paragraph-image"><div class="gh gi ps"><img src="../Images/b041214cb8ad9aa9b7a7c83454f87c97.png" data-original-src="https://miro.medium.com/v2/resize:fit:1386/format:webp/1*AEtxZoIxzs5S3WKqtjpjiw@2x.png"/></div><figcaption class="nf ng gj gh gi nh ni bd b be z dk">Simple linear regression equation</figcaption></figure><p id="d6ad" class="pw-post-body-paragraph lo lp iv lq b lr mk jw lt lu ml jz lw lx mm lz ma mb mn md me mf mo mh mi mj io bi translated">让我们想象一下这条线是如何拟合数据的。</p><pre class="kl km kn ko gt pd pe pf pg aw ph bi"><span id="7fae" class="nx kx iv pe b gy pi pj l pk pl">predictions = reg.predict(X)</span><span id="5ead" class="nx kx iv pe b gy pm pj l pk pl">plt.figure(figsize=(16, 8))<br/>plt.scatter(<br/>    data['TV'],<br/>    data['sales'],<br/>    c='black'<br/>)<br/>plt.plot(<br/>    data['TV'],<br/>    predictions,<br/>    c='blue',<br/>    linewidth=2<br/>)<br/>plt.xlabel("Money spent on TV ads ($)")<br/>plt.ylabel("Sales ($)")<br/>plt.show()</span></pre><p id="c8a4" class="pw-post-body-paragraph lo lp iv lq b lr mk jw lt lu ml jz lw lx mm lz ma mb mn md me mf mo mh mi mj io bi translated">现在，你看:</p><figure class="kl km kn ko gt kp gh gi paragraph-image"><div role="button" tabindex="0" class="kq kr di ks bf kt"><div class="gh gi pr"><img src="../Images/cb44033bd238be3f07c1c48121ba4013.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*GUFp-JY-VInBPEEtTpOmDA@2x.png"/></div></div><figcaption class="nf ng gj gh gi nh ni bd b be z dk">Linear fit</figcaption></figure><p id="099f" class="pw-post-body-paragraph lo lp iv lq b lr mk jw lt lu ml jz lw lx mm lz ma mb mn md me mf mo mh mi mj io bi translated">从上图来看，似乎一个简单的线性回归可以解释电视广告支出和销售额的总体影响。</p><h2 id="7629" class="nx kx iv bd ky ny nz dn lc oa ob dp lg lx oc od li mb oe of lk mf og oh lm oi bi translated">评估模型的相关性</h2><p id="7e29" class="pw-post-body-paragraph lo lp iv lq b lr ls jw lt lu lv jz lw lx ly lz ma mb mc md me mf mg mh mi mj io bi translated">现在，如果你还记得这篇<a class="ae mz" rel="noopener" target="_blank" href="/linear-regression-understanding-the-theory-7e53ac2831b5">文章</a>中的内容，为了看看这个模型是否好，我们需要看看每个系数的 R 值和 p 值<em class="ok"/>。</p><p id="7434" class="pw-post-body-paragraph lo lp iv lq b lr mk jw lt lu ml jz lw lx mm lz ma mb mn md me mf mo mh mi mj io bi translated">我们是这样做的:</p><pre class="kl km kn ko gt pd pe pf pg aw ph bi"><span id="5a7e" class="nx kx iv pe b gy pi pj l pk pl">X = data['TV']<br/>y = data['sales']</span><span id="a223" class="nx kx iv pe b gy pm pj l pk pl">X2 = sm.add_constant(X)<br/>est = sm.OLS(y, X2)<br/>est2 = est.fit()<br/>print(est2.summary())</span></pre><p id="faf0" class="pw-post-body-paragraph lo lp iv lq b lr mk jw lt lu ml jz lw lx mm lz ma mb mn md me mf mo mh mi mj io bi translated">这给了你这个可爱的输出:</p><figure class="kl km kn ko gt kp gh gi paragraph-image"><div role="button" tabindex="0" class="kq kr di ks bf kt"><div class="gh gi pt"><img src="../Images/24841a1db1c1e6daafd91056bc9566d3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*rt3Bs49UnXPcQlBHSYGE_Q@2x.png"/></div></div><figcaption class="nf ng gj gh gi nh ni bd b be z dk">R² and p-value</figcaption></figure><p id="26e0" class="pw-post-body-paragraph lo lp iv lq b lr mk jw lt lu ml jz lw lx mm lz ma mb mn md me mf mo mh mi mj io bi translated">查看这两个系数，我们有一个非常低的<em class="ok"> p 值</em>(尽管它可能不完全是 0)。这意味着这些系数和目标(销售额)之间有很强的相关性。</p><p id="45a7" class="pw-post-body-paragraph lo lp iv lq b lr mk jw lt lu ml jz lw lx mm lz ma mb mn md me mf mo mh mi mj io bi translated">然后，看 R 值，我们有 0.612。因此，<strong class="lq iw">大约 60%的销售变化可以用花在电视广告上的金额来解释</strong>。这没问题，但肯定不是我们能准确预测销售的最好方法。当然，在报纸和广播广告上的花费肯定会对销售产生一定的影响。</p><p id="a56b" class="pw-post-body-paragraph lo lp iv lq b lr mk jw lt lu ml jz lw lx mm lz ma mb mn md me mf mo mh mi mj io bi translated">让我们看看多元线性回归是否会表现得更好。</p><h1 id="c28a" class="kw kx iv bd ky kz la lb lc ld le lf lg kb lh kc li ke lj kf lk kh ll ki lm ln bi translated">多元线性回归</h1><h2 id="5454" class="nx kx iv bd ky ny nz dn lc oa ob dp lg lx oc od li mb oe of lk mf og oh lm oi bi translated">系统模型化</h2><p id="7ef1" class="pw-post-body-paragraph lo lp iv lq b lr ls jw lt lu lv jz lw lx ly lz ma mb mc md me mf mg mh mi mj io bi translated">就像简单的线性回归一样，我们将定义我们的特性和目标变量，并使用<em class="ok"> scikit-learn </em>库来执行线性回归。</p><pre class="kl km kn ko gt pd pe pf pg aw ph bi"><span id="b22b" class="nx kx iv pe b gy pi pj l pk pl">Xs = data.drop(['sales', 'Unnamed: 0'], axis=1)<br/>y = data['sales'].reshape(-1,1)</span><span id="47c7" class="nx kx iv pe b gy pm pj l pk pl">reg = LinearRegression()<br/>reg.fit(Xs, y)</span><span id="da70" class="nx kx iv pe b gy pm pj l pk pl">print("The linear model is: Y = {:.5} + {:.5}*TV + {:.5}*radio + {:.5}*newspaper".format(reg.intercept_[0], reg.coef_[0][0], reg.coef_[0][1], reg.coef_[0][2]))</span></pre><p id="9630" class="pw-post-body-paragraph lo lp iv lq b lr mk jw lt lu ml jz lw lx mm lz ma mb mn md me mf mo mh mi mj io bi translated">仅此而已！从这个代码单元，我们得到下面的等式:</p><figure class="kl km kn ko gt kp gh gi paragraph-image"><div role="button" tabindex="0" class="kq kr di ks bf kt"><div class="gh gi pr"><img src="../Images/8b546e5c706b4b79ddd28eeb656d2d2c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*HtaOtinBig3X_UZQZmE-SQ@2x.png"/></div></div><figcaption class="nf ng gj gh gi nh ni bd b be z dk">Multiple linear regression equation</figcaption></figure><p id="ac71" class="pw-post-body-paragraph lo lp iv lq b lr mk jw lt lu ml jz lw lx mm lz ma mb mn md me mf mo mh mi mj io bi translated">当然，我们无法想象所有三种媒体对销售的影响，因为它总共有四个维度。</p><p id="fdc1" class="pw-post-body-paragraph lo lp iv lq b lr mk jw lt lu ml jz lw lx mm lz ma mb mn md me mf mo mh mi mj io bi translated">请注意，报纸的系数是负的，但也相当小。与我们的模型相关吗？让我们通过计算每个系数的 F 统计量、R 值和<em class="ok"> p 值</em>来看看。</p><h2 id="60ea" class="nx kx iv bd ky ny nz dn lc oa ob dp lg lx oc od li mb oe of lk mf og oh lm oi bi translated">评估模型的相关性</h2><p id="a4c0" class="pw-post-body-paragraph lo lp iv lq b lr ls jw lt lu lv jz lw lx ly lz ma mb mc md me mf mg mh mi mj io bi translated">正如您所料，这里的过程与我们在简单线性回归中所做的非常相似。</p><pre class="kl km kn ko gt pd pe pf pg aw ph bi"><span id="58dc" class="nx kx iv pe b gy pi pj l pk pl">X = np.column_stack((data['TV'], data['radio'], data['newspaper']))<br/>y = data['sales']</span><span id="3c1b" class="nx kx iv pe b gy pm pj l pk pl">X2 = sm.add_constant(X)<br/>est = sm.OLS(y, X2)<br/>est2 = est.fit()<br/>print(est2.summary())</span></pre><p id="8b4f" class="pw-post-body-paragraph lo lp iv lq b lr mk jw lt lu ml jz lw lx mm lz ma mb mn md me mf mo mh mi mj io bi translated">您会得到以下结果:</p><figure class="kl km kn ko gt kp gh gi paragraph-image"><div role="button" tabindex="0" class="kq kr di ks bf kt"><div class="gh gi pu"><img src="../Images/0126fd677754c2248450e6bc9b1bc252.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*E2B-td65Q1s2tVGGr1imsg@2x.png"/></div></div><figcaption class="nf ng gj gh gi nh ni bd b be z dk">R², p-value and F-statistic</figcaption></figure><p id="b742" class="pw-post-body-paragraph lo lp iv lq b lr mk jw lt lu ml jz lw lx mm lz ma mb mn md me mf mo mh mi mj io bi translated">可以看到，R 远高于简单线性回归，其值为<strong class="lq iw"> 0.897 </strong>！</p><p id="21b6" class="pw-post-body-paragraph lo lp iv lq b lr mk jw lt lu ml jz lw lx mm lz ma mb mn md me mf mo mh mi mj io bi translated">还有，F 统计量是<strong class="lq iw"> 570.3 </strong>。这比 1 大得多，而且由于我们的数据集相当小(只有 200 个数据点)，它<strong class="lq iw">表明广告支出和销售</strong>之间有很强的关系。</p><p id="cb39" class="pw-post-body-paragraph lo lp iv lq b lr mk jw lt lu ml jz lw lx mm lz ma mb mn md me mf mo mh mi mj io bi translated">最后，因为我们只有三个预测值，所以我们可以考虑它们的<em class="ok"> p 值</em>来确定它们是否与模型相关。当然，您会注意到第三个系数(报纸的系数)有一个很大的<em class="ok"> p 值</em>。因此，报纸上的广告支出<strong class="lq iw">在统计上并不显著</strong>。移除那个预测因子会稍微降低 R 值，但我们可能会做出更好的预测。</p></div><div class="ab cl ov ow hz ox" role="separator"><span class="oy bw bk oz pa pb"/><span class="oy bw bk oz pa pb"/><span class="oy bw bk oz pa"/></div><div class="io ip iq ir is"><p id="bb6c" class="pw-post-body-paragraph lo lp iv lq b lr mk jw lt lu ml jz lw lx mm lz ma mb mn md me mf mo mh mi mj io bi translated">你真棒🤘。祝贺你坚持到最后，你现在是线性回归的大师了！</p><p id="cb3a" class="pw-post-body-paragraph lo lp iv lq b lr mk jw lt lu ml jz lw lx mm lz ma mb mn md me mf mo mh mi mj io bi translated">如上所述，这可能不是性能最好的算法，但对理解线性回归很重要，因为它是更复杂的统计学习方法的基础。</p><p id="425a" class="pw-post-body-paragraph lo lp iv lq b lr mk jw lt lu ml jz lw lx mm lz ma mb mn md me mf mo mh mi mj io bi translated">我希望你有时间会回头参考这篇文章。</p><p id="87b1" class="pw-post-body-paragraph lo lp iv lq b lr mk jw lt lu ml jz lw lx mm lz ma mb mn md me mf mo mh mi mj io bi translated">干杯！</p></div></div>    
</body>
</html>