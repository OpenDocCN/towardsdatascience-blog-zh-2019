<html>
<head>
<title>The Martian Chronicles — When Deep Learning meets Global Collaboration</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">火星编年史——当深度学习遇到全球协作</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/the-martian-chronicles-when-deep-learning-meets-global-collaboration-872425ba2787?source=collection_archive---------18-----------------------#2019-08-13">https://towardsdatascience.com/the-martian-chronicles-when-deep-learning-meets-global-collaboration-872425ba2787?source=collection_archive---------18-----------------------#2019-08-13</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><figure class="gl gn jr js jt ju gh gi paragraph-image"><div class="gh gi jq"><img src="../Images/67d5dba3673a71601ab22a2e1da248e0.png" data-original-src="https://miro.medium.com/v2/resize:fit:956/format:webp/1*FIpB5q_Qvhk6TonaWQ-l3w.png"/></div></figure><p id="7cb0" class="pw-post-body-paragraph jx jy it jz b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku im bi translated">上面你看到的是两张火星表面的灰度照片，是在勇气号着陆点附近拍摄的，勇气号是由美国宇航局建造的机器人漫游车，在 2004 年至 2010 年期间活动。如果你仔细观察，你会发现箭头右边的图像与左边的图像完全相同，只是陨石坑被神经网络用白色高亮显示了。</p><p id="a5d9" class="pw-post-body-paragraph jx jy it jz b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku im bi translated">如果你想知道这个非凡的结果是如何实现的，不要再想了，让我告诉你一个你从未听说过的故事——在这个故事中，你会发现来自地球各个角落的一群人，拥有不同的技能<em class="kv">(与火星相关或无关)</em>，他们如何远程合作，创建了一个能够自动下载和分析火星表面原始图像的完整管道。</p><p id="cb10" class="pw-post-body-paragraph jx jy it jz b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku im bi translated">我将这整个 2 个月的“太空之旅”分成 6 个阶段，并冒昧地对每个阶段做一个简要的概述。</p><figure class="kx ky kz la gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="lb lc di ld bf le"><div class="gh gi kw"><img src="../Images/ca69186e8436bddb9d64e4c30f827679.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Vo5huzdrYAMnHLr3Q71lwQ.png"/></div></div><figcaption class="lf lg gj gh gi lh li bd b be z dk">The entire space-trip of 2 months, broken up into 6 stages</figcaption></figure><h1 id="c96a" class="lj lk it bd ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg bi translated">起源故事</h1><p id="4537" class="pw-post-body-paragraph jx jy it jz b ka mh kc kd ke mi kg kh ki mj kk kl km mk ko kp kq ml ks kt ku im bi translated">这一切都始于<strong class="jz iu"> <em class="kv">火星</em>，</strong>当然还有<strong class="jz iu"> <em class="kv"> — </em> </strong>太阳系中第二小的行星，由稀薄的大气层组成，其表面特征让人想起月球的撞击坑以及地球的山谷、沙漠和极地冰盖。</p><figure class="kx ky kz la gt ju gh gi paragraph-image"><div class="gh gi mm"><img src="../Images/b6f625c39c3d4b38703089445bd04bb9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1166/format:webp/1*g0A223RPAEI-cnwxt_Y0BQ.png"/></div><figcaption class="lf lg gj gh gi lh li bd b be z dk">Examples of the Mars’ diverse surface</figcaption></figure><p id="aa18" class="pw-post-body-paragraph jx jy it jz b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku im bi translated">最近，寻找技术签名——为过去或现在的外星技术提供科学证据的可测量属性——获得了新的兴趣。</p><figure class="kx ky kz la gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="lb lc di ld bf le"><div class="gh gi ca"><img src="../Images/f433e7b02fbc36879407c3d6ed155120.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*-J9WE8xkKf_UuWWRCOTxmg.png"/></div></div></figure><p id="50dd" class="pw-post-body-paragraph jx jy it jz b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku im bi translated">会见 Omdena——这是一个全球合作平台，汇集了来自 18 个国家的 36 名地球人，为期 2 个月，以确定火星表面的异常情况，这将有助于发现技术签名和着陆点。当我在浏览我的媒体新闻时，我偶然发现了这颗宝石，并无意中发现了下面这篇改变人生的文章:</p><div class="mn mo gp gr mp mq"><a href="https://medium.com/omdena/learn-ai-through-collaboration-not-through-competition-f3b13f7f3f21" rel="noopener follow" target="_blank"><div class="mr ab fo"><div class="ms ab mt cl cj mu"><h2 class="bd iu gy z fp mv fr fs mw fu fw is bi translated">通过协作学习 AI，而不是通过竞争。</h2><div class="mx l"><h3 class="bd b gy z fp mv fr fs mw fu fw dk translated">与他人一起学习，获得真实世界的经验，成为全球社区的一员。</h3></div><div class="my l"><p class="bd b dl z fp mv fr fs mw fu fw dk translated">medium.com</p></div></div><div class="mz l"><div class="na l nb nc nd mz ne jv mq"/></div></div></a></div><p id="b1cc" class="pw-post-body-paragraph jx jy it jz b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku im bi translated">这篇文章出现的正是时候，当时我已经在诸如<strong class="jz iu"> Udacity、fast.ai、Coursera </strong>等平台上完成了相当多的 ML 课程。，并在寻找全新的项目来应用我新获得的技能。我没有浪费时间申请，几天后，经过简短的面试，我非常兴奋地收到一封电子邮件，确认我在这个项目中的 ML 工程师的角色。</p><p id="6142" class="pw-post-body-paragraph jx jy it jz b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku im bi translated">如果没有出色的在线协作工具，未来两个月的协作是不可能的，例如:</p><ul class=""><li id="82d5" class="nf ng it jz b ka kb ke kf ki nh km ni kq nj ku nk nl nm nn bi translated"><strong class="jz iu"> Slack </strong>，我们曾经在名副其实的#channels 的帮助下，用它来相互交流和集思广益。</li><li id="8cfd" class="nf ng it jz b ka no ke np ki nq km nr kq ns ku nk nl nm nn bi translated"><strong class="jz iu"> Zoom </strong>，我们用它来举行每周同步视频会议，所有参与者每周都可以分享他们的进步和学习。</li><li id="7e9c" class="nf ng it jz b ka no ke np ki nq km nr kq ns ku nk nl nm nn bi translated"><strong class="jz iu"> GitHub </strong>，我们用来贡献和分享所有开发代码的。</li><li id="9dfc" class="nf ng it jz b ka no ke np ki nq km nr kq ns ku nk nl nm nn bi translated"><strong class="jz iu">谷歌合作实验室</strong>，免费提供支持 GPU 的 Jupyter 笔记本电脑，以试验不同的模型。</li><li id="8b9f" class="nf ng it jz b ka no ke np ki nq km nr kq ns ku nk nl nm nn bi translated"><strong class="jz iu"> Google Drive、Google Docs 和 Google Slides </strong>，帮助我们以一种易于阅读的格式记录我们所有的数据和知识，并将它们呈现给其他人。</li></ul><h1 id="57d3" class="lj lk it bd ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg bi translated">接近</h1><p id="83d7" class="pw-post-body-paragraph jx jy it jz b ka mh kc kd ke mi kg kh ki mj kk kl km mk ko kp kq ml ks kt ku im bi translated">在我们自己的 Python 包——mars-ode-data-access——诞生之前，我们花了两周时间分析需求。对于那些试图访问和下载火星表面图像的人来说，这让生活变得更加容易。关于它的用法的所有信息都可以在这里找到—<a class="ae nt" href="https://github.com/samiriff/mars-ode-data-access" rel="noopener ugc nofollow" target="_blank">https://github.com/samiriff/mars-ode-data-access</a>。</p><figure class="kx ky kz la gt ju gh gi paragraph-image"><div class="gh gi nu"><img src="../Images/c1116bf5f9377a07381c00e6a09d5fe9.png" data-original-src="https://miro.medium.com/v2/resize:fit:994/format:webp/1*BW0Btus66YKaQBRnqF-MlQ.png"/></div><figcaption class="lf lg gj gh gi lh li bd b be z dk">Sample usage of the mars-ode-data-access Python package</figcaption></figure><p id="15a7" class="pw-post-body-paragraph jx jy it jz b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku im bi translated">数据是如何从火星一路传回我们的 Jupyter 笔记本的？长话短说，由美国宇航局建造的火星探测轨道器<em class="kv"> (MRO) </em>，使用高分辨率成像科学实验<em class="kv"> (HiRISE) </em>相机捕捉火星表面的高分辨率照片，并通过深空网络<em class="kv"> (DSN) </em>传回地球。像我们这样的普通用户通过在我们的浏览器中打开火星轨道数据浏览器<em class="kv"> (ODE) </em>网站来访问所有这些数据，或者更好的是，通过使用我们自己的 python 包以编程方式访问这些数据。</p><p id="94ed" class="pw-post-body-paragraph jx jy it jz b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku im bi translated">如果你想更深入地了解这一旅程的细节，请阅读下面的文章了解更多信息:</p><div class="mn mo gp gr mp mq"><a href="https://medium.com/omdena/a-journey-from-martian-orbiters-to-terrestrial-neural-networks-93541169f665" rel="noopener follow" target="_blank"><div class="mr ab fo"><div class="ms ab mt cl cj mu"><h2 class="bd iu gy z fp mv fr fs mw fu fw is bi translated">从火星轨道飞行器到陆地神经网络的旅程</h2><div class="mx l"><h3 class="bd b gy z fp mv fr fs mw fu fw dk translated">引入 Python 包来高效处理来自火星的数据</h3></div><div class="my l"><p class="bd b dl z fp mv fr fs mw fu fw dk translated">medium.com</p></div></div><div class="mz l"><div class="nv l nb nc nd mz ne jv mq"/></div></div></a></div><h1 id="f26e" class="lj lk it bd ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg bi translated">数据</h1><p id="02e1" class="pw-post-body-paragraph jx jy it jz b ka mh kc kd ke mi kg kh ki mj kk kl km mk ko kp kq ml ks kt ku im bi translated">一旦我们获得了数据，我们需要理解我们正在寻找的异常。基于<a class="ae nt" href="https://zenodo.org/record/2538136" rel="noopener ugc nofollow" target="_blank">芝诺多数据集</a>，我们能够识别 7 种不同的异常，即<strong class="jz iu">陨石坑、黑色沙丘、斜坡条纹、明亮沙丘、撞击喷出物、蜘蛛和瑞士奶酪。</strong></p><figure class="kx ky kz la gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="lb lc di ld bf le"><div class="gh gi nw"><img src="../Images/0960914653db829b7a5ab93fdef0d1a5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*cJpD72aDpO-4_l2v1feESg.png"/></div></div></figure><p id="544d" class="pw-post-body-paragraph jx jy it jz b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku im bi translated">除此之外，我们还从火星任务的不同着陆点识别出了<strong class="jz iu">技术特征</strong>，比如美国宇航局的好奇号探测器的降落伞。</p><p id="1a9e" class="pw-post-body-paragraph jx jy it jz b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku im bi translated">此外，我们创建了<strong class="jz iu">预处理实用程序</strong>来对齐、裁剪、平移、旋转、缩放和转换下载的数据。</p><figure class="kx ky kz la gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="lb lc di ld bf le"><div class="gh gi nx"><img src="../Images/9570a85afff885b10fc4ba2d12c54fa2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*kAUBmxnua4kBDWosgYI9iw.png"/></div></div></figure><p id="7def" class="pw-post-body-paragraph jx jy it jz b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku im bi translated">你可以在下面这篇由 Sebastian Laverde 撰写的文章中找到关于这些工具的更多细节:</p><div class="mn mo gp gr mp mq"><a href="https://medium.com/omdena/marsian-omaly-detection-through-deep-adversarial-training-4dbb10744ce8" rel="noopener follow" target="_blank"><div class="mr ab fo"><div class="ms ab mt cl cj mu"><h2 class="bd iu gy z fp mv fr fs mw fu fw is bi translated">通过深度对抗训练进行马氏检测</h2><div class="mx l"><h3 class="bd b gy z fp mv fr fs mw fu fw dk translated">“通过每一个发现的裂缝，一些看似不正常的东西从黑暗中掉了出来，落下来，作为进入……</h3></div><div class="my l"><p class="bd b dl z fp mv fr fs mw fu fw dk translated">medium.com</p></div></div><div class="mz l"><div class="ny l nb nc nd mz ne jv mq"/></div></div></a></div><h1 id="6897" class="lj lk it bd ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg bi translated">标签</h1><p id="7e69" class="pw-post-body-paragraph jx jy it jz b ka mh kc kd ke mi kg kh ki mj kk kl km mk ko kp kq ml ks kt ku im bi translated">所有数据就绪后，我们必须手动标记所有图像。简单图像分类的日子已经一去不复返了。我们现在生活在一个对象检测和语义分割的世界，有各种各样的注释工具和标签格式！糟糕的是没有一个单一的标准，这就是为什么我们有多个参与者使用不同的注释工具来标记不同的图像。贴标签是一项相当劳动密集型的任务，这是我们证明我们在数量上的优势的时候，我们平均在一周多一点的时间里，通过贴标签 300-400 张图片，完成了这项看似艰巨的任务。</p><p id="5264" class="pw-post-body-paragraph jx jy it jz b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku im bi translated">我们开始使用<a class="ae nt" href="https://github.com/tzutalin/labelImg" rel="noopener ugc nofollow" target="_blank">label img</a>——一种开源注释工具，在感兴趣的异常周围绘制矩形框，还创建了一个实用程序，用于在<a class="ae nt" href="http://host.robots.ox.ac.uk/pascal/VOC/" rel="noopener ugc nofollow" target="_blank"> PASCAL VOC </a>和<a class="ae nt" href="https://github.com/AlexeyAB/Yolo_mark/issues/60" rel="noopener ugc nofollow" target="_blank"> YOLO </a>格式之间自动转换。</p><figure class="kx ky kz la gt ju gh gi paragraph-image"><div class="gh gi nz"><img src="../Images/6c6731f3d42ca750ef783ca2bb74906f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1232/format:webp/1*uyPflG51GAixVrgX6lhVsw.png"/></div><figcaption class="lf lg gj gh gi lh li bd b be z dk">Drawing bounding boxes over craters with the LabelImg Tool</figcaption></figure><p id="9c46" class="pw-post-body-paragraph jx jy it jz b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku im bi translated">然后，我们使用<a class="ae nt" href="http://www.robots.ox.ac.uk/~vgg/software/via/" rel="noopener ugc nofollow" target="_blank"> VGG 图像注释器(VIA) </a>工具在感兴趣的异常周围绘制多边形。</p><figure class="kx ky kz la gt ju gh gi paragraph-image"><div class="gh gi oa"><img src="../Images/af9a3aa88cf3edb308a238d8bada48d9.png" data-original-src="https://miro.medium.com/v2/resize:fit:634/format:webp/1*3P3-42H7UC-O2rnRZhEqxQ.png"/></div><figcaption class="lf lg gj gh gi lh li bd b be z dk">Drawing Polygons around Bright Dunes with the VIA tool</figcaption></figure><p id="9981" class="pw-post-body-paragraph jx jy it jz b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku im bi translated">最后但同样重要的是，我们创建了一个工具——<a class="ae nt" href="https://github.com/samiriff/image-annotation-converter" rel="noopener ugc nofollow" target="_blank">https://github.com/samiriff/image-annotation-converter</a>——能够在 LabelMe 工具的帮助下，自动将来自 VIA 工具的多边形注释转换为分段遮罩。</p><figure class="kx ky kz la gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="lb lc di ld bf le"><div class="gh gi ob"><img src="../Images/f83cdc409f708073d685324f8db0441c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*sFzRgmSIUfXHIOeDeto7mw.png"/></div></div><figcaption class="lf lg gj gh gi lh li bd b be z dk">Segmentation masks of craters obtained from an image annotated with the VIA tool</figcaption></figure><h1 id="4da4" class="lj lk it bd ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg bi translated">模型</h1><p id="e64c" class="pw-post-body-paragraph jx jy it jz b ka mh kc kd ke mi kg kh ki mj kk kl km mk ko kp kq ml ks kt ku im bi translated">终于，经过如此精心的准备，我们到了大家期待已久的阶段——模特选拔和培训！</p><p id="febc" class="pw-post-body-paragraph jx jy it jz b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku im bi translated">我们尝试了监督和非监督模型，但为了保持这个故事的简洁，我将展示 3 个监督模型<em class="kv"> (SSD，Mask R-CNN 和 U-Net) </em>和 1 个非监督模型<em class="kv"> (Ano-GAN) </em>。所有实验都在谷歌实验室进行。</p><h2 id="e311" class="oc lk it bd ll od oe dn lp of og dp lt ki oh oi lx km oj ok mb kq ol om mf on bi translated">单触发多盒探测器(SSD)</h2><p id="9f3b" class="pw-post-body-paragraph jx jy it jz b ka mh kc kd ke mi kg kh ki mj kk kl km mk ko kp kq ml ks kt ku im bi translated">利用由 1674 个训练样本、350 个验证样本和多种类型的图像转换组成的<strong class="jz iu"> LabelImg 注释数据集</strong>，由预训练 Resnet34 模型支持的单次多盒检测机通过 1 周期学习率调度器被训练 30 个时期。选择焦点损失作为损失函数，并通过 Adam 优化器在 6.5 分钟内将其最小化，从而产生下图中显示的预测，异常周围有边界框。</p><figure class="kx ky kz la gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="lb lc di ld bf le"><div class="gh gi oo"><img src="../Images/6935e3cdd306dbb8c40a1edd7fd36653.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*xOSmhhaSOdyfyxSqRJ7uNA.png"/></div></div><figcaption class="lf lg gj gh gi lh li bd b be z dk">Parameter Values, Model Architecture and Sample Predictions for an SSD Model</figcaption></figure><h2 id="6281" class="oc lk it bd ll od oe dn lp of og dp lt ki oh oi lx km oj ok mb kq ol om mf on bi translated">屏蔽 R-CNN</h2><p id="54ca" class="pw-post-body-paragraph jx jy it jz b ka mh kc kd ke mi kg kh ki mj kk kl km mk ko kp kq ml ks kt ku im bi translated">利用<strong class="jz iu"> VIA 注释数据集</strong>和 1024 x 1024 像素的更高输入分辨率，由预训练的 Resnet101 主干支持的掩模 R-CNN 模型被训练 30 个时期。损失函数由边界框和掩膜损失的组合组成，由 SGD 优化器在大约 3 小时内最小化，从而产生下图中显示的预测，异常以不同颜色突出显示。</p><figure class="kx ky kz la gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="lb lc di ld bf le"><div class="gh gi op"><img src="../Images/dafb879c083263af7549bab85f97494a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*1Fox2KvY0cjikVgMUgV7qg.png"/></div></div><figcaption class="lf lg gj gh gi lh li bd b be z dk">Parameter Values, Model Architecture and Sample Predictions for a Mask R-CNN model</figcaption></figure><h2 id="875d" class="oc lk it bd ll od oe dn lp of og dp lt ki oh oi lx km oj ok mb kq ol om mf on bi translated">优信网</h2><p id="b075" class="pw-post-body-paragraph jx jy it jz b ka mh kc kd ke mi kg kh ki mj kk kl km mk ko kp kq ml ks kt ku im bi translated">利用<strong class="jz iu">分割掩码</strong>的数据集，由 Resnet18 模型支持的 U-Net 模型利用 1 周期学习率调度器，使用学习率和权重衰减的不同组合，被训练 47 个时期。Adam 优化器在大约 2 小时内将交叉熵损失函数的平坦损失最小化，从而产生了下图中的预测，异常以白色突出显示。</p><figure class="kx ky kz la gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="lb lc di ld bf le"><div class="gh gi oq"><img src="../Images/225ffe40e0f8f7d5eb791cd130e8d57e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*7YtY44HeZOkrt2nh_ZSRdg.png"/></div></div><figcaption class="lf lg gj gh gi lh li bd b be z dk">Parameter Values, Model Architecture and Sample Predictions for a U-Net Model</figcaption></figure><h2 id="2db2" class="oc lk it bd ll od oe dn lp of og dp lt ki oh oi lx km oj ok mb kq ol om mf on bi translated">阿诺-甘</h2><p id="c35e" class="pw-post-body-paragraph jx jy it jz b ka mh kc kd ke mi kg kh ki mj kk kl km mk ko kp kq ml ks kt ku im bi translated">最后但并非最不重要的是，利用 10000 幅图像的完全未标记数据集，对 200 个时代训练了一个生成性对抗网络。Adam 优化器在大约 6 小时内将 L1 重建损失降至最低，从而产生了显示在右侧的预测。探测到了隔热板、降落伞、坠机地点和好奇号火星车等技术特征。</p><figure class="kx ky kz la gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="lb lc di ld bf le"><div class="gh gi or"><img src="../Images/920f8f8533f7ab5bfadd7d2c1ab8abd9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*sKrdbftyZQfaxFOA3rzuzg.png"/></div></div><figcaption class="lf lg gj gh gi lh li bd b be z dk">Parameter Values, Model Architecture and Sample Predictions for an Ano-GAN model</figcaption></figure><p id="1ecf" class="pw-post-body-paragraph jx jy it jz b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku im bi translated">在这篇由<a class="ae nt" href="https://in.linkedin.com/in/smurli" rel="noopener ugc nofollow" target="_blank"> Murli Sivashanmugam </a>撰写的文章中，阅读更多关于这种模型的架构以及它是如何被训练的:</p><div class="mn mo gp gr mp mq"><a href="https://medium.com/omdena/anomaly-detection-in-martian-surface-searching-for-needles-in-a-haystack-169fb0246da7" rel="noopener follow" target="_blank"><div class="mr ab fo"><div class="ms ab mt cl cj mu"><h2 class="bd iu gy z fp mv fr fs mw fu fw is bi translated">火星表面的异常探测——大海捞针！</h2><div class="mx l"><h3 class="bd b gy z fp mv fr fs mw fu fw dk translated">我们如何克服数据挑战，并使用深度卷积网络和社区协作来检测…</h3></div><div class="my l"><p class="bd b dl z fp mv fr fs mw fu fw dk translated">medium.com</p></div></div><div class="mz l"><div class="os l nb nc nd mz ne jv mq"/></div></div></a></div><p id="9268" class="pw-post-body-paragraph jx jy it jz b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku im bi translated">在继续之前，我想花一点时间感谢<strong class="jz iu">杰瑞米·霍华德</strong>和<strong class="jz iu"> fast.ai </strong>背后的人们，他们创建了这样一个奇妙的图书馆和令人惊叹的视频讲座，这使我们更容易理解 SSD、U-Net 和 GAN 模型的内部工作原理。如果你之前没看过这个课程，我强烈建议你立刻访问<a class="ae nt" href="https://course.fast.ai/" rel="noopener ugc nofollow" target="_blank"> https://course.fast.ai </a>。</p><h1 id="3141" class="lj lk it bd ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg bi translated">结果</h1><figure class="kx ky kz la gt ju gh gi paragraph-image"><div class="gh gi ot"><img src="../Images/4a5a3dcf0e67fa9e2b309d3d774f65b0.png" data-original-src="https://miro.medium.com/v2/resize:fit:946/format:webp/1*zG2dD06CqZFbbWHq7F4OAg.png"/></div><figcaption class="lf lg gj gh gi lh li bd b be z dk">Precision, Recall, and F1-Scores for all label classes</figcaption></figure><p id="a46d" class="pw-post-body-paragraph jx jy it jz b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku im bi translated">发现 U-Net 模型产生了最好的分数。所有异常的精确度分数都在 90%以上，但是在技术签名、斜坡条纹和蜘蛛的召回分数方面仍有改进的空间。</p><p id="e6d9" class="pw-post-body-paragraph jx jy it jz b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku im bi translated">基于交集超过并集<em class="kv"> (IOU) </em>分数的混淆矩阵如下所示:</p><figure class="kx ky kz la gt ju gh gi paragraph-image"><div class="gh gi ou"><img src="../Images/e0552ca14140d153621dc11bd6e06368.png" data-original-src="https://miro.medium.com/v2/resize:fit:952/format:webp/1*Wj-8ud0qOZ81Hiibk-Ic9Q.png"/></div></figure><p id="992c" class="pw-post-body-paragraph jx jy it jz b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku im bi translated">等等！这个故事还没有结束。在我结束之前，让我向您展示一个用户友好的应用程序，它是通过将所有这 6 个部分结合在一起创建的，以创建一个端到端的管道，能够直接从火星轨道数据探测器下载图像，并使用我们训练有素的 U-Net 模型进行分析<em class="kv">(确保您在支持 GPU 的环境中运行此笔记本)</em>:</p><div class="mn mo gp gr mp mq"><a href="https://colab.research.google.com/drive/1snboX3JG9USKmbCAGf3XtCZkSjayMgM2" rel="noopener  ugc nofollow" target="_blank"><div class="mr ab fo"><div class="ms ab mt cl cj mu"><h2 class="bd iu gy z fp mv fr fs mw fu fw is bi translated">谷歌联合实验室</h2><div class="mx l"><h3 class="bd b gy z fp mv fr fs mw fu fw dk translated">用户友好的 Mars ODE + U-Net 管道</h3></div><div class="my l"><p class="bd b dl z fp mv fr fs mw fu fw dk translated">colab.research.google.com</p></div></div><div class="mz l"><div class="ov l nb nc nd mz ne jv mq"/></div></div></a></div><p id="0d8f" class="pw-post-body-paragraph jx jy it jz b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku im bi translated">如果你想看我们所有的实验或者也有所贡献，请访问<a class="ae nt" href="https://github.com/cienciaydatos/ai-challenge-mars" rel="noopener ugc nofollow" target="_blank">https://github.com/cienciaydatos/ai-challenge-mars</a>。</p><h1 id="4dd0" class="lj lk it bd ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg bi translated">结论</h1><p id="cfb9" class="pw-post-body-paragraph jx jy it jz b ka mh kc kd ke mi kg kh ki mj kk kl km mk ko kp kq ml ks kt ku im bi translated">好了，这就是我们过去两个月的旅程。我希望你喜欢阅读我们的项目，就像我们喜欢做它一样。</p><blockquote class="ow ox oy"><p id="6002" class="jx jy kv jz b ka kb kc kd ke kf kg kh oz kj kk kl pa kn ko kp pb kr ks kt ku im bi translated"><strong class="jz iu">在这个项目中合作工作类似于训练一个神经网络，在项目开始时，事情是混乱的，随机的陌生人加入了一个新创建的合作环境<em class="it">(类似于神经网络中的权重和偏差在创建过程中是如何随机初始化的)</em>随着时间的推移，我们逐渐了解并相互学习。 通过不断迭代<em class="it">(类似于神经网络如何在多个时期逐渐调整其权重以最小化成本函数)</em>来精炼我们的理解并变得不那么混乱，直到我们实现我们的目标或接近它<em class="it">(类似于神经网络最终产生预期结果的方式)。 </em>T9】</strong></p></blockquote><p id="46cb" class="pw-post-body-paragraph jx jy it jz b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku im bi translated">我们非常感激 Rudradeb Mitra 把我们聚集在一起并指导我们；<strong class="jz iu">丹尼尔·安格豪森</strong>和<strong class="jz iu">帕特里西奥·韦塞拉</strong>为我们提供问题陈述指导；<strong class="jz iu">迈克尔·布哈特</strong>宣传我们的媒体文章，并让我们了解奥姆德纳的最新动态；<strong class="jz iu">法维奥·瓦兹奎</strong>帮助我们开始使用 GitHub 上的开源库。</p><p id="746c" class="pw-post-body-paragraph jx jy it jz b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku im bi translated">在一个被贪婪、仇恨和偏狭所困扰的世界里，奥姆德纳为消除国家壁垒带来了一股新鲜空气。这个项目证明了这样一个事实，即把一群来自地球不同角落的陌生人聚集在一起，他们以前从未见过面；超越地理边界和时区，共同努力解决引人入胜的社会问题；虽然每天都互相学习和启发，但这不仅仅是一个白日梦，<strong class="jz iu">感谢在线教育、协作工具和 Omdena </strong>这样的平台！</p><p id="aad0" class="pw-post-body-paragraph jx jy it jz b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku im bi translated">如果您希望了解更多关于 Omdena 的信息，并将您的技能应用于新的合作挑战，请访问<a class="ae nt" href="https://omdena.com/" rel="noopener ugc nofollow" target="_blank">https://omdena.com</a>。</p><figure class="kx ky kz la gt ju gh gi paragraph-image"><div class="gh gi pc"><img src="../Images/def47f2dbe551dbbadb4fef8061ab9f9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*sul-DzvlQAlJ96dl.png"/></div></figure><p id="2435" class="pw-post-body-paragraph jx jy it jz b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku im bi translated">地面控制呼叫汤姆少校。通话完毕……</p><h2 id="ba95" class="oc lk it bd ll od oe dn lp of og dp lt ki oh oi lx km oj ok mb kq ol om mf on bi translated">参考</h2><p id="69d4" class="pw-post-body-paragraph jx jy it jz b ka mh kc kd ke mi kg kh ki mj kk kl km mk ko kp kq ml ks kt ku im bi translated">[1]<a class="ae nt" href="http://course18.fast.ai/lessons/lesson9.html" rel="noopener ugc nofollow" target="_blank">http://course 18 . fast . ai</a><br/>【2】<a class="ae nt" href="https://zenodo.org/record/2538136#.XTHh3OgzbIV" rel="noopener ugc nofollow" target="_blank">https://zenodo.org/record/2538136#.XTHh3OgzbIV</a><br/>【3】<a class="ae nt" href="https://medium.com/omdena/a-journey-from-martian-orbiters-to-terrestrial-neural-networks-93541169f665" rel="noopener">https://medium . com/om dena/a-journey-from-mars-orbiters-to-terrestrial-neural-networks-93541169 f 665</a><br/>【4】<a class="ae nt" href="https://github.com/cienciaydatos/ai-challenge-mars" rel="noopener ugc nofollow" target="_blank">https://github.com/cienciaydatos/ai-challenge-mars</a><br/>【5】<a class="ae nt" href="https://medium.com/omdena/marsian-omaly-detection-through-deep-adversarial-training-4dbb10744ce8" rel="noopener">https://medium . com/om dena/pushing-the-the</a></p></div></div>    
</body>
</html>