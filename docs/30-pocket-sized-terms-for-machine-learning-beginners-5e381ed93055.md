# 机器学习初学者的 30 个袖珍术语

> 原文：<https://towardsdatascience.com/30-pocket-sized-terms-for-machine-learning-beginners-5e381ed93055?source=collection_archive---------33----------------------->

![](img/fff64174770a0f00c6ee38aba2f2793f.png)

我先声明一下这篇文章**不是**是什么，然后我再提一下这篇文章能为**你**做什么。

这篇文章并不是你必须知道的机器学习术语的全面列表。这篇文章并没有充斥着伴随着数学符号和公式的教科书定义。现在这个问题已经解决了。往好的方面想。

这篇文章**是**一个以简单方式定义的术语列表，便于回忆。在你去面试的路上，可以随意使用这个列表来更新关键词和定义。或者，也许你已经是一名血统数据科学家或机器学习专家，但你想重温你的基础。或者你想打发时间。

与任何需要这篇文章的人分享这篇文章。还有，**在评论区多加一些定义，帮助别人，炫耀自己的技能。**

**神经元**:在深度学习和机器学习的世界中，神经元可以被描述为一个处理单元，它是神经网络的基本构建模块之一。

**权重:**这些是神经元间连接的强度。它们是神经网络中存储知识的关键元素。

**神经网络**:神经元(处理单元)的集合，能够保持知识。它们也可以被描述为并行分布式处理器。

**机器学习:**是实现计算机算法或指令的科学，这些算法或指令被编排成从数据中学习，其中算法被用于与它从其学习的数据相关的任务。

**深度学习:**这是机器学习的一个领域，算法利用几层神经网络从输入数据中提取更丰富的特征。深度学习技术的例子是卷积神经网络(CNN)和递归神经网络(RNN)

**监督学习:**这是用标注了标签的数据来训练机器学习算法。数据的注释通常由专家系统提供，例如人或外部系统。分类任务是监督学习任务的一个例子。

**无监督学习:**为处理这种类型的学习而设计的算法具有内置的自组织特性。这些算法根据在数据中检测到的模式自我组织数据，而不需要专家系统的参与。

**半监督学习:**半监督的机器学习算法由未标记和标记的训练数据组成。与未标记的训练数据相比，在训练数据集的分布中标记数据的频率通常在较小的规模上。

**强化学习:**这是一种机器学习技术，涉及被称为代理的已定义程序。这些代理人被放置在一个环境中，并受通过与环境的相互作用来增加奖励这一概念的支配。代理的目的是尽可能积累奖励。还有负面奖励或惩罚的形式。代理人的任务是改善其管理系统，随着时间的推移收集奖励，并避免处罚。

**批量学习:**这是一种向机器学习算法的网络呈现训练数据的方法。累积的训练数据被一次全部馈送到机器学习算法，并且一旦所有训练数据被前馈，就对被训练的网络的偏差和权重进行改变。

**在线学习:**这种向网络呈现训练数据的方法是以增量方式进行的。训练数据被分成称为小批量的组，并且一旦小批量已经通过网络馈送，就对网络的权重和偏差进行更新，然后向前馈送另一个小批量。重复该过程，直到所有小批量通过网络。

**一般化:**机器学习算法和模型可以基于对它们在看不见的数据上的性能的测量来分类。

**模型**:这可以描述为在数据集中观察到的一般化模式的数学表示。

**基于实例的学习(基于记忆的学习):**机器学习系统可以基于对在训练阶段呈现给算法的训练数据内的模式的观察来进行归纳。这些模式(实例)可用于通过基于在测试期间呈现的新实例计算一些相似性度量分数来提高机器学习算法的泛化能力，其中新实例用于训练。据说该算法可以根据训练过程中以前的观察实例对新实例进行预测。

**基于模型的学习:**与基于实例的学习相反，实现可以概括的系统的另一种方法是使用基于数据集生成模型，并使用该模型来处理诸如预测之类的任务。

**数据集:**这是包含相关元素的信息集合，机器学习算法可以将这些相关元素视为单个单元。

**特征:**这是一个对象、观察或数据集的可测量的决定性特征。

**训练数据集**:这是我们用来直接训练神经网络的数据集组。在使用卷积神经网络进行分类的任务中，网络将学习训练集数据的图像和标签关系。这些是网络在训练中看到的数据集组。

**验证数据集**:这是我们的一组数据集，在训练期间用来评估我们的网络在训练期间各个阶段的性能。这组数据集是必不可少的，因为它是网络模型过拟合和欠拟合等问题的指示器。

**测试数据集**:在训练阶段完成后，我们利用这组数据集来评估我们网络的性能。

**欠拟合:**当机器学习算法无法学习数据集中的模式时，就会出现这种情况。可以通过使用更适合该任务的更好的算法或模型来修复欠拟合。还可以通过识别数据中的更多特征并将其呈现给算法来调整欠拟合。

**过拟合:**这个问题涉及算法预测呈现给它的模式的新实例，过于基于**它在训练期间观察到的模式的实例。这可能导致机器学习算法无法准确地推广到看不见的数据。如果训练数据没有准确地表示测试数据的分布，则会发生过度拟合。可以通过减少训练数据中的特征数量以及通过各种技术降低网络的复杂性来修复过拟合。**

**正则化**:在机器学习中，正则化是一种通过使网络的权重仅取小值或具有小数量级的值来降低网络复杂性(从而防止过度拟合)的技术。通过对网络中权值的限制，我们可以使网络更简单，从而降低复杂性。在权重值高于某个数字的情况下，通过将成本/惩罚应用于损失函数，在网络内实现正则化。我们通过应用正则化来减少大值权重对网络的贡献，这可以减轻过拟合。

**超参数**:这些是在网络训练开始之前定义的值；它们被初始化以帮助引导网络达到积极的训练结果。它们的作用在机器/深度学习算法上，但不受算法影响。他们的价值观在训练中不会改变。超参数的例子是正则化值、学习率、层数等。

**网络参数**:这些是我们网络的组件，不是手动初始化的。它们是嵌入的网络值，由网络直接操纵。网络参数的一个例子是网络内部的权重。

**地面实况:**这是一个数据集内的元素，通过观察进行注释。在机器学习中，通过比较算法提供的推理结果和基本事实中包含的观察结果，基本事实数据被用于测量算法预测的准确性。

**混淆矩阵(误差矩阵):**提供了对分类器结果的基本事实注释的匹配或不匹配数量的可视化说明。混淆矩阵通常以表格形式构造，其中行用来自地面实况的观察结果填充，列用来自分类器的推断结果填充。

**Precision-Recall:** 这些是用于评估分类算法、视觉搜索系统等的性能指标。以评估可视化搜索系统(基于查询图像查找相似图像)为例，precision 捕获返回的相关结果的数量，而 recall 捕获数据集中返回的相关结果的数量。再读一遍。

**采样偏差**:这可能发生在数据采集过程中。抽样偏倚可以描述为在一个数据集中特定成员或子群的有限代表性的出现。数据集可以说是以一个子集在数量上对另一个子集有意义的方式分布的。随机抽样技术可以防止抽样偏差。

**反向传播:**一种算法，其目的是通过有效地计算使网络成本函数最小化的梯度，在神经网络内实现学习能力。

阅读这篇[文章](/introduction-to-computer-vision-b44bb4c495ab)了解计算机视觉的介绍。