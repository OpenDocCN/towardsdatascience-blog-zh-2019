# çº¿æ€§å›å½’

> åŸæ–‡ï¼š<https://towardsdatascience.com/apache-spark-mllib-tutorial-ec6f1cb336a9?source=collection_archive---------8----------------------->

## Apache Spark ML æ•™ç¨‹

## ä»‹ç» Spark ML ä»¥åŠå¦‚ä½•ä½¿ç”¨å®ƒæ¥è®­ç»ƒçº¿æ€§å›å½’æ¨¡å‹

æ³¨æ„:æœ¬æ–‡æ˜¯ç³»åˆ—æ–‡ç« çš„ä¸€éƒ¨åˆ†ã€‚æŸ¥çœ‹å®Œæ•´ç³»åˆ—: ***ç¬¬ 1 éƒ¨åˆ†:å›å½’*** *ï¼Œ* [*ç¬¬ 2 éƒ¨åˆ†:ç‰¹å¾è½¬åŒ–*](https://medium.com/@alimasri1991/apache-spark-mllib-tutorial-7aba8a1dce6e) *ï¼Œ* [*ç¬¬ 3 éƒ¨åˆ†:åˆ†ç±»*](/apache-spark-mllib-tutorial-part-3-complete-classification-workflow-a1eb430ad069) *ï¼Œç¬¬ 4 éƒ¨åˆ†åŠä»¥ä¸Šå³å°†æ¨å‡ºã€‚*

![](img/8e34dd2c2ec7b8a9b3700ae441a6250c.png)

æœ¬ç³»åˆ—çš„ç›®æ ‡æ˜¯å¸®åŠ©æ‚¨å¼€å§‹ä½¿ç”¨ Apache Spark çš„ ML åº“ã€‚æˆ‘ä»¬å°†ä¸€èµ·æ¢ç´¢å¦‚ä½•ä»¥ä¸€ç§ç»“æ„è‰¯å¥½çš„æ–¹å¼è§£å†³å„ç§æœ‰è¶£çš„æœºå™¨å­¦ä¹ ç”¨ä¾‹ã€‚æœ€åï¼Œæ‚¨å°†èƒ½å¤Ÿæ»¡æ€€ä¿¡å¿ƒåœ°ä½¿ç”¨ Spark MLï¼Œå¹¶å­¦ä¼šä¸ºæ‚¨æœªæ¥çš„é¡¹ç›®å®ç°ä¸€ä¸ªæœ‰ç»„ç»‡ä¸”æ˜“äºç»´æŠ¤çš„å·¥ä½œæµ

åœ¨æœ¬ç³»åˆ—çš„ç¬¬ä¸€éƒ¨åˆ†ï¼Œæˆ‘ä»¬å°†é‡ç‚¹å…³æ³¨ Spark ML çš„åŸºç¡€çŸ¥è¯†ã€‚æˆ‘ä»¬å°†ä»‹ç»åˆ›å»ºå›å½’æ¨¡å‹æ¥é¢„æµ‹æˆ¿ä»·çš„å¿…è¦æ­¥éª¤ã€‚æ›´å¤æ‚çš„ Spark ML ç‰¹æ€§å’ŒåŠŸèƒ½å°†åœ¨æœ¬ç³»åˆ—çš„åç»­æ–‡ç« ä¸­å‘å¸ƒã€‚

åœ¨è¿›ä¸€æ­¥è®¨è®ºä¹‹å‰ï¼Œè®©æˆ‘ä»¬ä»ä¸€äº›å®šä¹‰å¼€å§‹ã€‚

# å®šä¹‰

## é˜¿å¸•å¥‡ç«èŠ±

Apache Spark æ˜¯ä¸€ä¸ªå¼€æºçš„é›†ç¾¤è®¡ç®—æ¡†æ¶ã€‚Spark ä»£ç åº“æœ€åˆæ˜¯ç”±åŠ å·å¤§å­¦ä¼¯å…‹åˆ©åˆ†æ ¡çš„ AMPLab å¼€å‘çš„ï¼Œåæ¥è¢«æèµ ç»™äº† Apache Software Foundationï¼Œè¯¥åŸºé‡‘ä¼šä¸€ç›´ç»´æŠ¤ç€å®ƒã€‚Spark æä¾›äº†ä¸€ä¸ªæ¥å£ï¼Œé€šè¿‡éšå¼æ•°æ®å¹¶è¡Œå’Œå®¹é”™å¯¹æ•´ä¸ªé›†ç¾¤è¿›è¡Œç¼–ç¨‹ã€‚

## ç«èŠ±æ¯«å‡

[Apache Spark](https://spark.apache.org/mllib/) ML æ˜¯ç”±å¸¸ç”¨å­¦ä¹ ç®—æ³•å’Œå®ç”¨ç¨‹åºç»„æˆçš„æœºå™¨å­¦ä¹ åº“ï¼ŒåŒ…æ‹¬åˆ†ç±»ã€å›å½’ã€èšç±»ã€ååŒè¿‡æ»¤ã€é™ç»´ä»¥åŠåº•å±‚ä¼˜åŒ–åŸè¯­ã€‚

## ä¸ºä»€ä¹ˆé€‰æ‹© Spark MLï¼Ÿ

è¿ˆå‘å¤§æ•°æ®æ—¶ä»£éœ€è¦å¯¹éå¸¸å¤§çš„æ•°æ®é›†è¿›è¡Œå¤§é‡è¿­ä»£è®¡ç®—ã€‚æœºå™¨å­¦ä¹ ç®—æ³•çš„æ ‡å‡†å®ç°éœ€è¦éå¸¸å¼ºå¤§çš„æœºå™¨æ‰èƒ½è¿è¡Œã€‚ä¾èµ–é«˜ç«¯æœºå™¨å¹¶ä¸æœ‰åˆ©ï¼Œå› ä¸ºå®ƒä»¬ä»·æ ¼é«˜æ˜‚ï¼Œè€Œä¸”ä¸é€‚åˆæ‰©å¤§è§„æ¨¡ã€‚ä½¿ç”¨åˆ†å¸ƒå¼è®¡ç®—å¼•æ“çš„æƒ³æ³•æ˜¯å°†è®¡ç®—åˆ†å¸ƒåˆ°å¤šä¸ªä½ç«¯æœºå™¨(å•†ç”¨ç¡¬ä»¶)ï¼Œè€Œä¸æ˜¯ä¸€ä¸ªé«˜ç«¯æœºå™¨ã€‚è¿™æ— ç–‘åŠ é€Ÿäº†å­¦ä¹ é˜¶æ®µï¼Œå¹¶å…è®¸æˆ‘ä»¬åˆ›å»ºæ›´å¥½çš„æ¨¡å‹ã€‚

# è½¯ä»¶è¦æ±‚

ä¸ºäº†ç»§ç»­å­¦ä¹ æœ¬æ•™ç¨‹ï¼Œæ‚¨å¿…é¡»å®‰è£…ä»¥ä¸‹è½¯ä»¶:

*   è®¡ç®—æœºç¼–ç¨‹è¯­è¨€
*   é˜¿å¸•å¥‡ç«èŠ±
*   findspark åº“
*   Numpy
*   æœ±çš®ç‰¹

## é˜¿å¸•å¥‡ç«èŠ±

å®‰è£… Apache Spark æ˜¯å¦‚æ­¤ç®€å•ã€‚ä½ åªè¦ä»[å®˜ç½‘](https://spark.apache.org/downloads.html)ä¸‹è½½åŒ…å°±å¯ä»¥äº†ã€‚

è¦æµ‹è¯•æ‚¨çš„å®ç°:

1.  è§£å‹ç¼©æ–‡ä»¶
2.  è½¬åˆ° ***bin*** ç›®å½•
3.  è¿è¡Œä»¥ä¸‹å‘½ä»¤

```
% ./pyspark --version
```

è¾“å‡ºåº”è¯¥å¦‚ä¸‹æ‰€ç¤º:

![](img/905d722cccec35725cff9f5b9ec259ef.png)

Testing Apache Spark version

## findspark åº“

ä¸ºäº†æ›´å®¹æ˜“åˆ°è¾¾ Apache Sparkï¼Œæˆ‘ä»¬å°†ä½¿ç”¨ [findspark](https://github.com/minrk/findspark) ã€‚è¿™æ˜¯ä¸€ä¸ªéå¸¸ç®€å•çš„åº“ï¼Œå¯ä»¥è‡ªåŠ¨è®¾ç½®å¼€å‘ç¯å¢ƒæ¥å¯¼å…¥ Apache Spark åº“ã€‚

è¦å®‰è£… findsparkï¼Œè¯·åœ¨ shell ä¸­è¿è¡Œä»¥ä¸‹å‘½ä»¤:

```
% pip install findspark
```

## Numpy

Numpy æ˜¯ Python ä¸­è‘—åçš„æ•°å€¼è®¡ç®—åº“ã€‚Spark ML åœ¨å†…éƒ¨ä½¿ç”¨å®ƒè¿›è¡Œè®¡ç®—ã€‚

ä½¿ç”¨ä»¥ä¸‹å‘½ä»¤å®‰è£…å®ƒ:

```
% pip install numpy
```

**Jupyter**

[Jupyter Notebook](https://jupyter.org)æ˜¯ä¸€ä¸ªå¼€æºçš„ç½‘ç»œåº”ç”¨ç¨‹åºï¼Œå…è®¸ä½ åˆ›å»ºå’Œå…±äº«åŒ…å«å®æ—¶ä»£ç ã€å…¬å¼ã€å¯è§†åŒ–å’Œå™è¿°æ€§æ–‡æœ¬çš„æ–‡æ¡£ã€‚ç”¨é€”åŒ…æ‹¬:æ•°æ®æ¸…ç†å’Œè½¬æ¢ã€æ•°å€¼æ¨¡æ‹Ÿã€ç»Ÿè®¡å»ºæ¨¡ã€æ•°æ®å¯è§†åŒ–ã€æœºå™¨å­¦ä¹ ç­‰ç­‰ã€‚

è¦å®‰è£… Jupyter:

```
% pip install jupyter
```

# é—®é¢˜å®šä¹‰

è¿™ä¸ªç³»åˆ—çš„ç¬¬ä¸€ä¸ªé—®é¢˜æ˜¯ ***å›å½’*** ã€‚æˆ‘ä»¬å°†è®­ç»ƒä¸€ä¸ªæ¨¡å‹æ¥é¢„æµ‹è‘—åçš„ [*æ³¢å£«é¡¿æˆ¿å±‹*](https://www.cs.toronto.edu/~delve/data/boston/bostonDetail.html) æ•°æ®é›†(ä»[è¿™é‡Œä¸‹è½½](https://drive.google.com/open?id=1-zxrKH1T0fM1Oi1mZzCWNtzHzeM4OsKt))ã€‚

è¯¥æ•°æ®é›†åŒ…å«ç”±ç¾å›½äººå£æ™®æŸ¥å±€æ”¶é›†çš„æœ‰å…³é©¬è¨è¯¸å¡å·æ³¢å£«é¡¿åœ°åŒºä½æˆ¿çš„ä¿¡æ¯ã€‚å®ƒæ˜¯ä» [StatLib æ¡£æ¡ˆ](http://lib.stat.cmu.edu/datasets/boston)ä¸­è·å¾—çš„ï¼Œå¹¶åœ¨æ•´ä¸ªæ–‡çŒ®ä¸­è¢«å¹¿æ³›ç”¨äºåŸºå‡†ç®—æ³•ã€‚

æ•°æ®é›†å¾ˆå°ï¼Œåªæœ‰ 506 ä¸ªæ¡ˆä¾‹ã€‚å®ƒåŒ…å« 14 ä¸ªç‰¹å¾ï¼Œæè¿°å¦‚ä¸‹:

1.  CRIM:åŸé•‡äººå‡çŠ¯ç½ªç‡
2.  ZN:é¢ç§¯è¶…è¿‡ 25ï¼Œ000 å¹³æ–¹è‹±å°ºçš„ä½å®…ç”¨åœ°æ¯”ä¾‹
3.  å°åº¦æ²³æµåŸŸ:æ¯ä¸ªåŸé•‡éé›¶å”®å•†ä¸šè‹±äº©æ•°çš„æ¯”ä¾‹ã€‚
4.  CHAS: Charles River è™šæ‹Ÿå˜é‡(å¦‚æœåŒºåŸŸè¾¹ç•Œä¸ºæ²³æµï¼Œåˆ™ä¸º 1ï¼›å¦åˆ™ä¸º 0)
5.  NOX:æ°®æ°§åŒ–ç‰©æµ“åº¦(ç™¾ä¸‡åˆ†ä¹‹ä¸€)
6.  RM:æ¯ä¸ªä½å®…çš„å¹³å‡æˆ¿é—´æ•°
7.  å¹´é¾„:1940 å¹´ä»¥å‰å»ºé€ çš„è‡ªæœ‰ä½æˆ¿çš„æ¯”ä¾‹
8.  DIS:åˆ°äº”ä¸ªæ³¢å£«é¡¿å°±ä¸šä¸­å¿ƒçš„åŠ æƒè·ç¦»
9.  RAD:æ”¾å°„çŠ¶å…¬è·¯å¯è¾¾æ€§æŒ‡æ•°
10.  ç¨æ”¶:æ¯ 1 ä¸‡ç¾å…ƒçš„å…¨ä»·å€¼è´¢äº§ç¨ç¨ç‡
11.  PTRATIO:æŒ‰åŸé•‡åˆ†åˆ—çš„å¸ˆç”Ÿæ¯”ç‡
12.  B: 1000(Bk â€” 0.63)ï¼Œå…¶ä¸­ Bk æ˜¯æŒ‰åŸé•‡åˆ’åˆ†çš„é»‘äººæ¯”ä¾‹
13.  LSTAT: %äººå£çš„è¾ƒä½åœ°ä½
14.  MEDV:ä»¥åƒç¾å…ƒä¸ºå•ä½çš„è‡ªæœ‰ä½æˆ¿ä¸­å€¼

**ç›®æ ‡æ˜¯ä½¿ç”¨è¿™ 13 ä¸ªç‰¹å¾æ¥é¢„æµ‹ MEDV çš„ä»·å€¼(ä»£è¡¨æˆ¿ä»·)ã€‚**

æ˜¯æ—¶å€™æŠŠæ‰‹å¼„è„äº†ã€‚è®©æˆ‘ä»¬è·³è·ƒåˆ°ç«èŠ±å’Œç«èŠ±ä¸­ã€‚

# å±¥è¡Œ

## è®¾ç½® Apache Spark

å‡†å¤‡å¥½ä½ çš„å¼€å‘ç¯å¢ƒåˆé¤ ***Jupyter*** å¹¶åˆ›å»ºä¸€ä¸ªæ–°çš„ç¬”è®°æœ¬ã€‚

```
% jupyter notebook
```

æˆ‘ä»¬é¦–å…ˆå¯¼å…¥ ***findspark*** åº“ï¼Œå¹¶é€šè¿‡ä¼ é€’ Apache Spark æ–‡ä»¶å¤¹çš„è·¯å¾„æ¥åˆå§‹åŒ–å®ƒã€‚

```
import findspark
findspark.init('/opt/spark')
```

æ¯ä¸ª Spark åº”ç”¨ç¨‹åºéƒ½éœ€è¦ä¸€ä¸ª ***SparkSession*** ã€‚

ä¸ºäº†åˆ›å»ºä¸€ä¸ª ***SparkSession*** æˆ‘ä»¬å†™:

```
from pyspark.sql import SparkSession
spark = SparkSession.builder.getOrCreate()
```

## åŠ è½½æ•°æ®

```
data = spark.read.csv('./boston_housing.csv', header=True, inferSchema=True)
```

*   header=True è¡¨ç¤ºç¬¬ä¸€è¡ŒåŒ…å«æ ‡é¢˜
*   inferSchema=True å¯ç”¨åº•å±‚æ•°æ®æ¨¡å¼çš„è‡ªåŠ¨æ£€æµ‹

è¦æ˜¾ç¤ºæ•°æ®:

```
data.show()
```

![](img/263122cff36c02ec4c013586421bbfe1.png)

Top 20 rows of the data

## è®¾ç½®åŠŸèƒ½

ç°åœ¨æ˜¯æœ‰è¶£çš„éƒ¨åˆ†â€¦ Spark ML çš„ç®—æ³•æœŸæœ›æ•°æ®ä»¥ä¸¤åˆ—è¡¨ç¤º:**ç‰¹å¾**å’Œ**æ ‡ç­¾**ã€‚Features æ˜¯ç”¨äºé¢„æµ‹çš„æ‰€æœ‰ç‰¹å¾çš„æ•°æ®ç‚¹æ•°ç»„ã€‚æ ‡ç­¾åŒ…å«æ¯ä¸ªæ•°æ®ç‚¹çš„è¾“å‡ºæ ‡ç­¾ã€‚

åœ¨æˆ‘ä»¬çš„ä¾‹å­ä¸­ï¼Œç‰¹æ€§æ˜¯ä» 1 â†’ 13 çš„åˆ—ï¼Œæ ‡ç­¾æ˜¯åŒ…å«ä»·æ ¼çš„ *MEDV* åˆ—ã€‚

> ç›®æ ‡æ˜¯ä»ç‰¹å¾ä¸­é¢„æµ‹æ ‡ç­¾ã€‚

åˆ›å»ºç‰¹å¾æ•°ç»„éå¸¸ç®€å•ã€‚æ‚¨åªéœ€å¯¼å…¥***vector assembler***ç±»ï¼Œå¹¶ä¼ å…¥ä¸€ä¸ªç‰¹æ€§åˆ—ååˆ—è¡¨ã€‚

```
feature_columns = data.columns[:-1] # here we omit the final columnfrom pyspark.ml.feature import VectorAssemblerassembler = VectorAssembler(inputCols=feature_columns,outputCol="features")
```

*   outputCol="features "å®šä¹‰ç»„åˆæ‰€æœ‰å€¼çš„è¾“å‡ºå‘é‡çš„åç§°

ç°åœ¨æˆ‘ä»¬ä½¿ç”¨æ±‡ç¼–ç¨‹åºæ¥åˆ›å»ºç‰¹æ€§åˆ—:

```
data_2 = assembler.transform(data)
```

å°±æ˜¯è¿™æ ·ï¼å¦‚æœæ‰“å° data_2 çš„å€¼ï¼Œæ‚¨ä¼šæ³¨æ„åˆ°ä¸€ä¸ªåä¸ºâ€œfeaturesâ€çš„æ–°åˆ—ï¼Œå®ƒåŒ…å«æ‰€æœ‰ç»„åˆåœ¨ä¸€ä¸ªåˆ—è¡¨ä¸­çš„å€¼:

```
data_2.show()
```

![](img/775dbc4a6fa05f40ff8ea61208228e9b.png)

Data after VectorAssembler

## è®­ç»ƒ\æµ‹è¯•åˆ†å‰²

æ­£å¦‚åœ¨ä»»ä½•æœºå™¨å­¦ä¹ å·¥ä½œæµç¨‹ä¸­ä¸€æ ·ï¼Œæˆ‘ä»¬å°†æ•°æ®åˆ†ä¸ºè®­ç»ƒé›†å’Œæµ‹è¯•é›†ã€‚è¿™é‡Œæˆ‘ä»¬æŠŠå®ƒåˆ†æˆ 70%çš„è®­ç»ƒæ ·æœ¬å’Œ 30%çš„æµ‹è¯•æ ·æœ¬ã€‚

```
train, test = data_2.randomSplit([0.7, 0.3])
```

## è®­ç»ƒæœºå™¨å­¦ä¹ ç®—æ³•

æˆ‘ä»¬è½¬åˆ°å¦ä¸€ä¸ªæœ‰è¶£çš„éƒ¨åˆ†ï¼Œè®©æˆ‘ä»¬æ ¹æ®æˆ‘ä»¬çš„æ•°æ®è®­ç»ƒä¸€ä¸ªç®€å•çš„ ***çº¿æ€§å›å½’*** æ¨¡å‹ã€‚é¦–å…ˆï¼Œæˆ‘ä»¬å¯¼å…¥å¿…è¦çš„ç±»ã€‚

```
from pyspark.ml.regression import LinearRegression
```

æ¥ä¸‹æ¥æˆ‘ä»¬å®šä¹‰ ***ç®—æ³•*** å˜é‡ã€‚æˆ‘ä»¬éœ€è¦æŒ‡å®šç‰¹æ€§åˆ—å’Œæ ‡ç­¾åˆ—çš„åç§°ã€‚

```
algo = LinearRegression(featuresCol="features", labelCol="medv")
```

è®­ç»ƒæ—¶é—´â€¦æˆ‘ä»¬è°ƒç”¨ ***fit*** æ–¹æ³•ï¼Œå¼€å§‹åœ¨è®­ç»ƒé›†ä¸Šè®­ç»ƒæˆ‘ä»¬çš„æ¨¡å‹ã€‚

```
model = algo.fit(train)
```

ç§å•Šã€‚æ‚¨å·²ç»ä½¿ç”¨ Spark ML è®­ç»ƒäº†æ‚¨çš„ç¬¬ä¸€ä¸ªæ¨¡å‹ï¼

## è¯„ä¼°æ¨¡å‹æ€§èƒ½

å®ŒæˆåŸ¹è®­é˜¶æ®µæ˜¯ä¸å¤Ÿçš„ã€‚æˆ‘ä»¬å¿…é¡»è®¡ç®—æˆ‘ä»¬çš„æ¨¡å‹æœ‰å¤šå¥½ã€‚å¹¸å¥½æ¨¡å‹å¯¹è±¡æœ‰ä¸€ä¸ª ***æ±‚å€¼*** çš„æ–¹æ³•:

```
evaluation_summary = model.evaluate(test)
```

ä½¿ç”¨***evaluation _ summary***å¯¹è±¡è®¿é—®å¤§é‡æŒ‡æ ‡:

```
evaluation_summary.meanAbsoluteError
# Output: 3.39
evaluation_summary.rootMeanSquaredError
# Output: 5.16
evaluation_summary.r2
# Output: 0.58
```

å—¯ï¼Œå¯¹äºä¸€ä¸ªç®€å•çš„æ¨¡å‹æ¥è¯´è¿˜ä¸é”™ã€‚

## é¢„æµ‹å€¼

ä¸ºäº†é¢„æµ‹æœªæ ‡è®°æ•°æ®çš„è¾“å‡ºï¼Œåœ¨ä¼ é€’ DataFrame æ—¶è°ƒç”¨***model . transform***å‡½æ•°ã€‚

ä¾‹å¦‚ï¼Œè®©æˆ‘ä»¬ä»æµ‹è¯•é›†ä¸­é¢„æµ‹å€¼:

```
predictions = model.transform(test)
```

***é¢„æµ‹*** æ˜¯ä¸€ä¸ªæ•°æ®å¸§ï¼ŒåŒ…å«:æ¨¡å‹ç”Ÿæˆçš„åŸå§‹åˆ—ã€ç‰¹å¾åˆ—å’Œé¢„æµ‹åˆ—ã€‚

```
predictions.select(predictions.columns[13:]).show() # here I am filtering out some columns just for the figure to fit
```

![](img/9c503806cb21385bd9527461c5ebfc10.png)

Predictions

# å®Œæ•´ä»£ç 

Full Code

# æœ€åçš„æƒ³æ³•

æˆ‘çŸ¥é“è¿™æ˜¯ä¸€ç¯‡å¾ˆé•¿çš„æ–‡ç« ï¼Œä½†æˆ‘å¸Œæœ›å®ƒå€¼å¾—ä½ èŠ±æ—¶é—´ã€‚æˆ‘ä»¬ä»‹ç»äº† Apache Spark åŠå…¶ä»¤äººæƒŠå¹çš„ ML åº“ã€‚æˆ‘ä»¬åœ¨ä¸€ä¸ªå›å½’é—®é¢˜ä¸Šä½¿ç”¨äº† Spark ML æ¥é¢„æµ‹æˆ¿ä»·ã€‚æ¥ä¸‹æ¥ï¼Œæˆ‘å°†ä»‹ç»å…¶ä»–ç”¨ä¾‹çš„æ›´å¤šç‰¹æ€§ã€‚æ•¬è¯·å…³æ³¨â€¦

å¦‚æœä½ å–œæ¬¢è¿™ç¯‡æ–‡ç« ï¼Œè¯·ç‚¹å‡»â€œé¼“æŒâ€æŒ‰é’®ï¼Œæˆ‘å°†ä¸èƒœæ„Ÿæ¿€ğŸ‘æ‰€ä»¥å¯èƒ½ä¼šä¼ æŸ“ç»™ä»–äººã€‚ä¹Ÿå¯ä»¥åœ¨ [*æ¨ç‰¹*](https://twitter.com/alimasri1991) *ï¼Œ* [*è„¸ä¹¦*](https://www.facebook.com/alimasri91) *ï¼Œ* [*ä¸Šå…³æ³¨æˆ‘ç›´æ¥å‘é‚®ä»¶ç»™æˆ‘*](mailto:alimasri1991@gmail.com) *æˆ–è€…åœ¨*[*LinkedIn*](https://www.linkedin.com/in/alimasri/)*ä¸Šæ‰¾æˆ‘ã€‚*