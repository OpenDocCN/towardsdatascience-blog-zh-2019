<html>
<head>
<title>CelebA Attribute Prediction and Clustering with Keras</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">用 Keras 进行 CelebA 属性预测和聚类</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/celeba-attribute-prediction-and-clustering-with-keras-3d148063098d?source=collection_archive---------11-----------------------#2019-09-05">https://towardsdatascience.com/celeba-attribute-prediction-and-clustering-with-keras-3d148063098d?source=collection_archive---------11-----------------------#2019-09-05</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="8348" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">关于如何使用高效的基于 MobileNetV2 的模型检测和聚类多达 40 个面部属性的完整指南。</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/021ed21b63d2f5125dbe8397be24ef83.png" data-original-src="https://miro.medium.com/v2/resize:fit:784/format:webp/1*uBA1Y74j925n6Sz7jcbrRQ.png"/></div></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk">A synthetic face obtained from images of young smiling brown-haired women</figcaption></figure><p id="53f7" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">在本文中，我们讨论面部属性预测。我们将检查数据集并指出它的弱点。此外，我们将构建和训练一个深度模型，并最终讨论总体结果。</p><h1 id="75c9" class="lu lv it bd lw lx ly lz ma mb mc md me jz mf ka mg kc mh kd mi kf mj kg mk ml bi translated">介绍</h1><p id="e2fa" class="pw-post-body-paragraph ky kz it la b lb mm ju ld le mn jx lg lh mo lj lk ll mp ln lo lp mq lr ls lt im bi translated"><strong class="la iu">面部属性预测</strong>是一项关于推断面部属性集的计算机视觉(CV)任务。示例属性有<em class="mr">头发的颜色</em>、<em class="mr">发型</em>、<em class="mr">年龄</em>、<em class="mr">性别</em>等。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ms"><img src="../Images/145c2478aa300fd93083f9925f3ed5d0.png" data-original-src="https://miro.medium.com/v2/resize:fit:680/format:webp/0*6O-ThX64j_8P5lTY.png"/></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk">Some facial Attributes. <a class="ae mt" href="https://www.groundai.com/project/multi-task-learning-of-cascaded-cnn-for-facial-attribute-classification/" rel="noopener ugc nofollow" target="_blank">Source</a>.</figcaption></figure><p id="1c85" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">一般来说，面部属性预测是一项具有挑战性的任务:它首先涉及面部定位，然后是属性预测。此外，人脸由于其复杂的外观而固有地难以分析。通过<strong class="la iu">面部变化</strong>，面部的外观可以被改变，变得更加复杂。面部变化最常见的形式如下:</p><ul class=""><li id="3a20" class="mu mv it la b lb lc le lf lh mw ll mx lp my lt mz na nb nc bi translated"><strong class="la iu">遮挡:</strong> <em class="mr">发型</em>、<em class="mr">妆容</em>、<em class="mr">眼镜</em>(尤其是太阳镜)、<em class="mr">帽子</em>等种类的<em class="mr">物体</em>可以隐藏模型检测人脸及其属性所需的有意义的像素。在极度遮挡的情况下，模型可能根本无法定位人脸！</li><li id="66ed" class="mu mv it la b lb nd le ne lh nf ll ng lp nh lt mz na nb nc bi translated"><strong class="la iu">光照:</strong>极端<em class="mr">闪电</em>或极端<em class="mr">阴影</em>会让检测算法的工作变得更加困难(如果不是不可能的话)，就像遮挡一样。</li><li id="bc9e" class="mu mv it la b lb nd le ne lh nf ll ng lp nh lt mz na nb nc bi translated"><strong class="la iu">表情:</strong> <em class="mr">情绪</em>可以改变一张脸正常出现的方式。如果检测系统在训练期间从未见过受情绪影响的人脸，它可能无法正确检测到它们。</li><li id="fe08" class="mu mv it la b lb nd le ne lh nf ll ng lp nh lt mz na nb nc bi translated"><strong class="la iu">姿态:</strong>根据<em class="mr">滚动</em> (x 轴)<em class="mr">偏转</em> (z 轴)<em class="mr"> </em> e <em class="mr">俯仰</em> (y 轴)的高度旋转最终可以改变人脸的外观，并隐藏其面部特征。</li></ul><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ni"><img src="../Images/c274f30a8756a0d4b0b440bf6173a659.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*upPv05irph2U7iNSnhz3FA.jpeg"/></div></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk">Examples of challenging face variations.</figcaption></figure><p id="dcb6" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">因此，卷积模型在困难的人脸样本上进行训练非常重要，以便很好地推广到在野外捕获的<em class="mr">人脸</em>(在任何条件下捕获的人脸)。</p><p id="455c" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">面部属性预测不仅是一项学术挑战，也是改进现有应用的一种方法。例如，照片应用程序可以检测“微笑”属性，以便在给定的序列中确定哪张照片是最好的。</p></div><div class="ab cl nj nk hx nl" role="separator"><span class="nm bw bk nn no np"/><span class="nm bw bk nn no np"/><span class="nm bw bk nn no"/></div><div class="im in io ip iq"><h1 id="8557" class="lu lv it bd lw lx nq lz ma mb nr md me jz ns ka mg kc nt kd mi kf nu kg mk ml bi translated">数据探索</h1><p id="d7ba" class="pw-post-body-paragraph ky kz it la b lb mm ju ld le mn jx lg lh mo lj lk ll mp ln lo lp mq lr ls lt im bi translated">一个很好的、广泛的、多样化的数据集是<a class="ae mt" href="http://mmlab.ie.cuhk.edu.hk/projects/CelebA.html" rel="noopener ugc nofollow" target="_blank"> <strong class="la iu"> CelebA 数据集</strong> </a> <strong class="la iu">。</strong>它是一个大规模的人脸属性数据集，拥有超过<strong class="la iu"> 20 万张</strong>名人图片，涵盖了大量的变化，每张图片都有<strong class="la iu"> 40 个属性</strong>标注。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nv"><img src="../Images/be14aa4829893d91d409e972cd6109fe.png" data-original-src="https://miro.medium.com/v2/resize:fit:1046/format:webp/1*kZJR8CzdxQig6pI9y1P-tg.png"/></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk">The complete list of facial attributes provided by CelebA.</figcaption></figure><p id="9dc0" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">所以，首先要做的是下载数据集。通过在终端中执行以下代码，可以在或 Kaggle 上找到<a class="ae mt" href="http://mmlab.ie.cuhk.edu.hk/projects/CelebA.html" rel="noopener ugc nofollow" target="_blank">:</a></p><pre class="kj kk kl km gt nw nx ny nz aw oa bi"><span id="c87c" class="ob lv it nx b gy oc od l oe of"># install kaggle first: <br/>$&gt;<strong class="nx iu"> pip install kaggle</strong></span><span id="f2f9" class="ob lv it nx b gy og od l oe of"># set your Kaggle API key:<br/><strong class="nx iu">os.</strong>environ['<strong class="nx iu">KAGGLE_USERNAME</strong>'] = "YOUR_USERNAME"                       <strong class="nx iu">os.</strong>environ['<strong class="nx iu">KAGGLE_KEY</strong>'] = "YOUR_API_KEY"</span><span id="20e3" class="ob lv it nx b gy og od l oe of"># then download: <br/>$&gt; <strong class="nx iu">kaggle datasets download -d jessicali9530/celeba-dataset</strong></span></pre><p id="e091" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">下载并<strong class="la iu">解压</strong>之后，我们可以将它加载到我们的 Python 环境或 Jupyter 笔记本中。为此，我准备了完成所有枯燥工作的<code class="fe oh oi oj nx b">CelebA</code>类，将数据集加载到一个漂亮的熊猫<code class="fe oh oi oj nx b">DataFrame</code>:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="ok ol l"/></div></figure><p id="50bd" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">现在，<strong class="la iu">加载</strong>数据集(我假设它的路径是<code class="fe oh oi oj nx b">celeba-dataset\</code>)并最终选择面部属性的子集是小菜一碟。在示例代码中，我们删除了三个特性。</p><pre class="kj kk kl km gt nw nx ny nz aw oa bi"><span id="0bf4" class="ob lv it nx b gy oc od l oe of"># load the dataset with 37 out of 40 features:<br/>celeba = <strong class="nx iu">CelebA</strong>(drop_features=<strong class="nx iu">[</strong><br/>    '<strong class="nx iu">Attractive</strong>',<br/>    '<strong class="nx iu">Pale_Skin</strong>',<br/>    '<strong class="nx iu">Blurry</strong>',<br/><strong class="nx iu">]</strong>)</span></pre><p id="9bbf" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">之后，我们可以展示一些随机样本来理解<code class="fe oh oi oj nx b">celeba</code>数据帧的结构。</p><pre class="kj kk kl km gt nw nx ny nz aw oa bi"><span id="02e3" class="ob lv it nx b gy oc od l oe of"># shows five random samples<br/>celeba.attributes.<strong class="nx iu">sample</strong>(5)</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi om"><img src="../Images/5634e1a1335cfa6464cbd36045d8523e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*eIOF7-_5oCEY1T7YtJ4GeQ.png"/></div></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk">Random samples. Every attribute is binary: 0 means absent, 1 means present.</figcaption></figure><p id="2cb4" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">现在我们知道每个例子都关联到一个二进制标签的<strong class="la iu">向量，其中每个属性可以是<strong class="la iu"> 0 </strong>或<strong class="la iu"> 1 </strong>。因此，知道一个属性属于多少个面是非常有用的(我省略了这一点，但是数据集的每个图像都描绘了一个面)。通过统计某个属性出现 1 的次数，就可以计算出它的<strong class="la iu">绝对频率</strong>(甚至是<strong class="la iu"> <em class="mr">相对频率</em> </strong>除以样本总数)。</strong></p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi on"><img src="../Images/7d89fe2edbe6e15e5d080025550cbe8f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*XcNyZvn2jWIcCPsI2vsE7w.png"/></div></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk">The relative frequency of every attribute.</figcaption></figure><p id="ad87" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">在这里，我们可以清楚地观察到一个<strong class="la iu">数据不平衡问题</strong>。面部属性的频率变化很大，而不是彼此大致相等。出现频率在 10%以下的有<strong class="la iu">稀有属性</strong> ( <code class="fe oh oi oj nx b">Bald</code>、<code class="fe oh oi oj nx b">Mustache</code>、<code class="fe oh oi oj nx b">Double_Chin</code>等)，出现频率在 70%以上的有几个非常<strong class="la iu">常见属性</strong> ( <code class="fe oh oi oj nx b">No_Beard</code>、<code class="fe oh oi oj nx b">Young</code>)。</p><blockquote class="oo"><p id="0214" class="op oq it bd or os ot ou ov ow ox lt dk translated">这展示了另一个问题:数据集对年轻人和没有胡子的人有偏见。</p></blockquote><p id="183a" class="pw-post-body-paragraph ky kz it la b lb oy ju ld le oz jx lg lh pa lj lk ll pb ln lo lp pc lr ls lt im bi translated">当数据不平衡时，模型很容易<strong class="la iu">过拟合</strong>数据点。在这种情况下，它可以学习对每个常见属性总是输出一个<strong class="la iu"> 1 </strong>，对稀有属性总是输出一个<strong class="la iu"> 0 </strong>:模型发现这个策略(预测 0 和 1)是好的(这是不成立的，因为它不学习模式)。按照这种方式，模型的输出预测将看起来像<code class="fe oh oi oj nx b">[1, 0, ..., 0, 1]</code>向量，对每张图像都一样。</p><blockquote class="pd pe pf"><p id="10ed" class="ky kz mr la b lb lc ju ld le lf jx lg pg li lj lk ph lm ln lo pi lq lr ls lt im bi translated">如果发生这种情况，产生的模型是相当愚蠢的:它只会浪费计算资源，因为它可以被简单的代码(例如，随机猜测，或一个常量值)所取代。</p></blockquote><p id="e52b" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">好消息是，可以通过使用适当的损失函数来缓解这个问题(下一节将详细介绍)。</p><p id="e6d1" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">最后，上图展示了一些摄自 CelebA 的图片:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pj"><img src="../Images/700939a4c2f7676920b9c26529f5c8ad.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*h7dzaTDUOLyKna9z.png"/></div></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk">Source: <a class="ae mt" href="http://mmlab.ie.cuhk.edu.hk/projects/CelebA.html" rel="noopener ugc nofollow" target="_blank">CelebA</a>.</figcaption></figure></div><div class="ab cl nj nk hx nl" role="separator"><span class="nm bw bk nn no np"/><span class="nm bw bk nn no np"/><span class="nm bw bk nn no"/></div><div class="im in io ip iq"><h1 id="c098" class="lu lv it bd lw lx nq lz ma mb nr md me jz ns ka mg kc nt kd mi kf nu kg mk ml bi translated">模型</h1><p id="c51a" class="pw-post-body-paragraph ky kz it la b lb mm ju ld le mn jx lg lh mo lj lk ll mp ln lo lp mq lr ls lt im bi translated">我们将要构建的模型主要基于 MobileNetV2 架构，基本上是相同的模型，但是没有顶级分类层(MobileNetV2 构建为输出 1000 个类别概率)。</p><p id="5510" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">首先，该模型一次获取一个图像(3 个通道，大小为 224×224)作为<strong class="la iu">输入</strong>，并输出一个大小为<em class="mr"> n </em>的概率向量(通常，大小根据您想要检测的属性的多少而变化)。向量的第<em class="mr"> i </em>个元素是一个介于<strong class="la iu"> 0 </strong>(属性<em class="mr"> i </em>不存在)和<strong class="la iu"> 1 </strong>(属性<em class="mr"> i </em>存在)之间的实数。</p><blockquote class="pd pe pf"><p id="3275" class="ky kz mr la b lb lc ju ld le lf jx lg pg li lj lk ph lm ln lo pi lq lr ls lt im bi translated">请注意，输出向量可以包含多个非零元素，这意味着多个属性可以属于一个面。</p></blockquote><h2 id="c4b7" class="ob lv it bd lw pk pl dn ma pm pn dp me lh po pp mg ll pq pr mi lp ps pt mk pu bi translated">模型架构</h2><p id="ce0b" class="pw-post-body-paragraph ky kz it la b lb mm ju ld le mn jx lg lh mo lj lk ll mp ln lo lp mq lr ls lt im bi translated">为了定义模型架构，我们必须加载没有顶层的<strong class="la iu"> MobileNetV2 </strong>架构，将输入大小设置为 224×224，并添加新的顶层。以下代码实现了所有需要的操作:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="ok ol l"/></div></figure><p id="af9f" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">然后，要创建模型并显示其摘要(层、参数数量等)，请运行以下代码:</p><pre class="kj kk kl km gt nw nx ny nz aw oa bi"><span id="979a" class="ob lv it nx b gy oc od l oe of">model = <strong class="nx iu">build_model</strong>(num_features=<strong class="nx iu">celeba.num_features</strong>)<br/>model.summary()</span></pre><p id="9802" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">如您所见，创建模型很简单。在这里，我们将回顾新添加的顶层:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi pv"><img src="../Images/a53dfda4c788337f2bce777eb9b74411.png" data-original-src="https://miro.medium.com/v2/resize:fit:436/format:webp/1*uBSzkr599J_3dfpqL0Wkcw.png"/></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk">The model’s top layers. Image created with <a class="ae mt" href="https://github.com/lutzroeder/netron" rel="noopener ugc nofollow" target="_blank">Netron</a>.</figcaption></figure><ul class=""><li id="e0c5" class="mu mv it la b lb lc le lf lh mw ll mx lp my lt mz na nb nc bi translated"><strong class="la iu">globaveragepool2d:</strong>使用内核 big 作为最后卷积层的内核来产生 1×1 特征图。因此，如果最后的卷积层输出<em class="mr"> n </em>个特征图，每个都是宽<em class="mr"> w </em>和高<em class="mr"> h </em>，全局<em class="mr">T9】平均池层将对每个特征图应用一个核(<em class="mr"> w </em>，<em class="mr"> h </em>，以获得<em class="mr"> n </em> <strong class="la iu">置信度得分</strong>。当核与特征图一样大时，结果是一个标量，或者等价地，一个 1×1 的特征图。这样做可以减少全连接(密集)层的数量(通常至少为 2 层，由于 GlobalAveragePooling，只需要一层)，从而减少参数数量、训练时间和加速推理。GlobalAveragePooling 层是 GoogleLeNet 模型的关键创新之一。</em></li></ul><blockquote class="pd pe pf"><p id="d331" class="ky kz mr la b lb lc ju ld le lf jx lg pg li lj lk ph lm ln lo pi lq lr ls lt im bi translated">请注意，如果没有 GlobalAveragePooling 图层，则需要一个展平图层。展平(w，h，n)要素地图会生成一个具有 w×h×n 个单位的图层，而不是通过应用全局平均池生成的 n 个单位(因此，参数的数量要少得多)。</p></blockquote><ul class=""><li id="ef12" class="mu mv it la b lb lc le lf lh mw ll mx lp my lt mz na nb nc bi translated"><strong class="la iu">密集:</strong>之后，我们使用一个激活了 1536 个单元<strong class="la iu"> ReLU </strong>的密集层，来执行置信度得分的非线性组合(这增加了模型的容量及其辨别能力)。</li><li id="949b" class="mu mv it la b lb nd le ne lh nf ll ng lp nh lt mz na nb nc bi translated"><strong class="la iu"> BatchNormalization: </strong>模型基于非常深的架构，有几百层。为了加速训练并减少渐变消失或爆炸的机会，我们应用批量归一化，即<strong class="la iu"> <em class="mr">归一化</em> </strong>、<strong class="la iu"> <em class="mr">缩放</em> </strong>、<strong class="la iu"> <em class="mr">在应用激活函数之前移动</em> </strong>输入。批处理规范化通过学习四个附加参数来实现这一点。在某些情况下，批处理规范化具有正则化效果。</li><li id="1143" class="mu mv it la b lb nd le ne lh nf ll ng lp nh lt mz na nb nc bi translated"><strong class="la iu">退出:</strong>根据一个概率<em class="mr"> p </em>在训练中随机停用单位。以这种方式，一个神经元(单元)较少依赖于它的相邻单元。这迫使模型更好地概括。此外，dropout 可以被视为一种简单有效(但近似)的方法来训练许多神经网络的集合:在每次迭代中，不同的神经元被停用，从而产生不同的网络。当训练结束时，得到的网络大致表现为对训练期间获得的所有不同网络进行平均。</li><li id="6843" class="mu mv it la b lb nd le ne lh nf ll ng lp nh lt mz na nb nc bi translated"><strong class="la iu">密集:</strong>这是网络的<strong class="la iu">输出层</strong>。这里我们使用<strong class="la iu"> sigmoid </strong>作为激活函数，因为它允许具有不互斥的类(属性)(对于 softmax 层，只有一个输出元素可以是 1)，更重要的是，直接估计每个属性的概率。</li></ul><p id="c924" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">最后，该模型创建起来非常简单，甚至很小:它只有 4.3M 的参数，重量轻，速度快，也适合移动和网络应用。</p><h1 id="0ffc" class="lu lv it bd lw lx ly lz ma mb mc md me jz mf ka mg kc mh kd mi kf mj kg mk ml bi translated">培养</h1><p id="2c50" class="pw-post-body-paragraph ky kz it la b lb mm ju ld le mn jx lg lh mo lj lk ll mp ln lo lp mq lr ls lt im bi translated">有时，训练神经网络来解决给定数据集的某个任务，可以被视为试图使网络<strong class="la iu">符合生成数据集和真实世界数据的真实底层概率分布</strong>(数据集只是整个数据的一部分)。通常，真实的概率分布是未知的，并且由于在训练期间使用了数据集，因此只能<strong class="la iu">部分估计</strong>。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pw"><img src="../Images/97ed585ab0b5c734a009ab91dcea0eef.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*JuhIOBXQ2vlGF6UbTnEk2A.png"/></div></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk">Trying to capture the data distribution through training-data. <a class="ae mt" href="http://introtodeeplearning.com/materials/2019_6S191_L6.pdf" rel="noopener ugc nofollow" target="_blank">Source</a>.</figcaption></figure><p id="a7d7" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">训练数据的数量直接影响我们试图训练的网络的泛化能力。简而言之，<strong class="la iu">泛化误差</strong>随着训练数据量的增加而下降。</p><p id="ae4b" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">坏消息是，通常，训练数据不能捕获整个概率分布，因为不可能有覆盖分布的特定情况的例子。</p><p id="64a4" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">实际上，我们可以做的是稍微“<strong class="la iu">编辑</strong>”训练数据，以便有意引入一些变化(例如，旋转、移位……)—我们假设真实世界的数据可能会有这样的变化。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi px"><img src="../Images/0b64be242a3fec7c23932ca2be045381.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*3F25xg7yulPmx-sLBbAGNg.png"/></div></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk">Example of image augmentations.</figcaption></figure><h2 id="35a0" class="ob lv it bd lw pk pl dn ma pm pn dp me lh po pp mg ll pq pr mi lp ps pt mk pu bi translated">数据扩充</h2><p id="37f3" class="pw-post-body-paragraph ky kz it la b lb mm ju ld le mn jx lg lh mo lj lk ll mp ln lo lp mq lr ls lt im bi translated"><strong class="la iu">数据扩充</strong>的实践是增加训练集规模的有效方法。增加训练示例允许网络在训练期间“看到”更多样化但仍有代表性的数据点。</p><p id="49d3" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">下面的代码为训练集定义了一组扩展:<em class="mr">旋转</em>、<em class="mr">移动</em>、<em class="mr">剪切</em>、<em class="mr">翻转</em>和<em class="mr">缩放</em>。</p><blockquote class="pd pe pf"><p id="dc8c" class="ky kz mr la b lb lc ju ld le lf jx lg pg li lj lk ph lm ln lo pi lq lr ls lt im bi translated">请注意，验证集和测试集都不能增加。</p></blockquote><p id="ac9a" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">然后我们定义两个数据生成器:一个用于训练数据，另一个用于验证数据。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="ok ol l"/></div></figure><p id="8a7e" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">当我们处理不适合内存的大数据集时，我们必须找到一种方法只加载实际需要的数据。</p><p id="cc52" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">一个<strong class="la iu">数据生成器</strong>能够直接从源文件夹中加载所需数量的数据(一个小批量的图像)，将它们转换成<em class="mr">训练数据</em>(馈送给模型)和<em class="mr">训练目标</em>(一个属性向量——监督信号)。</p><blockquote class="pd pe pf"><p id="6129" class="ky kz mr la b lb lc ju ld le lf jx lg pg li lj lk ph lm ln lo pi lq lr ls lt im bi translated">对于我的实验，我通常设置<code class="fe oh oi oj nx b">batch_size = 80</code>。一般来说，介于 64 和 128 之间的值应该可以。通常，您希望根据计算资源和模型性能来增加/减少批量大小。</p></blockquote><h2 id="db39" class="ob lv it bd lw pk pl dn ma pm pn dp me lh po pp mg ll pq pr mi lp ps pt mk pu bi translated">优化器、损失函数和指标</h2><p id="78ca" class="pw-post-body-paragraph ky kz it la b lb mm ju ld le mn jx lg lh mo lj lk ll mp ln lo lp mq lr ls lt im bi translated">此时，我们选择具有默认值的<code class="fe oh oi oj nx b">adadelta</code>优化器(adam 优化器也很好，但它的性能似乎稍差一些):与 adam 一样，adadelta 是一个几乎不需要调整的优化器，因为它能够<strong class="la iu">自动调整学习速率</strong>(当出现问题时速度会变慢，或者朝着有希望的方向移动得更快)。</p><p id="2974" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">下一步，选择<strong class="la iu">损失函数:</strong>负责监控模型的性能并指导优化过程。</p><p id="d3a7" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">我发现一个<strong class="la iu">好的</strong>属性预测任务的损失函数，是一个能够区分属性向量的单个元素的函数，而不是将整个向量视为单个对象。我的意思是损耗一定要明白，向量<code class="fe oh oi oj nx b">[0, 1, 1, 0]</code>和这个向量<code class="fe oh oi oj nx b">[1, 0, 0, 1]</code>差很多(损耗要高)；有意义的是 1 和 0 的<strong class="la iu">数量</strong>，以及输入向量中单个元素的<strong class="la iu">精确位置</strong>。</p><p id="d556" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">像平均绝对误差(MAE)、均方误差(MSE)或均方根误差(RMSE)这样的损失函数不能进行这种区分:直觉上，它们只是对向量上的 1 进行计数，并对它们求平均值，因此丢失了关于位置的信息。</p><p id="1b37" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">相反，像<strong class="la iu">二元交叉熵</strong>和<strong class="la iu">余弦接近度</strong>这样的损失函数是理想的选择<strong class="la iu">。从经验上看，后者似乎表现稍好。</strong></p><p id="609b" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">最后一步，是选择我们的目标绩效指标。在这种情况下，我们关心的是最大化模型预测的二进制精度。</p><p id="41ed" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">最后，我们可以<strong class="la iu">编译</strong>我们的模型:</p><pre class="kj kk kl km gt nw nx ny nz aw oa bi"><span id="fee2" class="ob lv it nx b gy oc od l oe of">model<strong class="nx iu">.compile</strong>(loss='<strong class="nx iu">cosine_proximity</strong>',<br/>              optimizer='<strong class="nx iu">adadelta',<br/></strong>              metrics='<strong class="nx iu">binary_accuracy</strong>')</span></pre><h2 id="beab" class="ob lv it bd lw pk pl dn ma pm pn dp me lh po pp mg ll pq pr mi lp ps pt mk pu bi translated">适合的</h2><p id="6b5a" class="pw-post-body-paragraph ky kz it la b lb mm ju ld le mn jx lg lh mo lj lk ll mp ln lo lp mq lr ls lt im bi translated">在训练之前，模型有助于定义一个或多个<strong class="la iu">回调</strong>。挺好用的一个，有:<code class="fe oh oi oj nx b">ModelCheckpoint</code>和<code class="fe oh oi oj nx b">EarlyStopping</code>。</p><ul class=""><li id="26fa" class="mu mv it la b lb lc le lf lh mw ll mx lp my lt mz na nb nc bi translated"><strong class="la iu"> ModelCheckpoint: </strong>当训练需要大量时间来达到一个好的结果时，通常需要多次迭代(或者一些代价高昂的迭代)。在这种情况下，最好只在改进度量的时期结束时保存最佳执行模型的<strong class="la iu">副本</strong>。</li><li id="cbc4" class="mu mv it la b lb nd le ne lh nf ll ng lp nh lt mz na nb nc bi translated"><strong class="la iu">提前停止:</strong>有时，在训练期间，我们可以注意到<strong class="la iu">泛化差距</strong>(即训练和验证误差之间的差异)开始增加，而不是减少。这是<strong class="la iu">过拟合</strong>的症状，可以用很多方法解决(<em class="mr">减少模型容量</em>、<em class="mr">增加训练数据</em>、<em class="mr">数据增加</em>、<em class="mr">正则化</em>、<em class="mr">退出</em>等)。通常，一个实用有效的解决方案是当泛化差距越来越大时<strong class="la iu">停止训练</strong>。</li></ul><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi py"><img src="../Images/a6e5b2db782b74c007578185247fc2eb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*mt_hhxthEUOJg-6M8QwqLA.png"/></div></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk"><strong class="bd pz">Early stopping</strong>. <a class="ae mt" href="http://introtodeeplearning.com/materials/2019_6S191_L1.pdf" rel="noopener ugc nofollow" target="_blank">Source</a>.</figcaption></figure><p id="52a3" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">实际上，我只使用了 ModelCheckpoint 回调，因为不需要使用提前停止。无论如何，如果您想通过改变模型架构、超参数、损失和优化器来玩游戏，建议使用早期停止。</p><p id="9ea3" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">下面的代码将开始训练，将拟合信息收集到提供两条学习曲线的<code class="fe oh oi oj nx b">history</code>变量中:一条是损失曲线，另一条是准确度曲线；两者都可以被绘制出来。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="ok ol l"/></div></figure><p id="a1cb" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">通常我把<code class="fe oh oi oj nx b">num_epochs</code>设置在<strong class="la iu"> 10 </strong>和<strong class="la iu"> 20 </strong>之间。注意，该模型在前两个时期达到大约 89%的准确度。但是需要更长的训练来保持在大约 91%的精确度(至少这是我得到的最大精确度)。</p><blockquote class="pd pe pf"><p id="abd8" class="ky kz mr la b lb lc ju ld le lf jx lg pg li lj lk ph lm ln lo pi lq lr ls lt im bi translated">注意:每个<strong class="la iu">历元</strong>花费大约<strong class="la iu"> 40 分钟来完成</strong>(在 Google Colab GPU 上)。</p></blockquote><h2 id="4f1f" class="ob lv it bd lw pk pl dn ma pm pn dp me lh po pp mg ll pq pr mi lp ps pt mk pu bi translated">估价</h2><p id="7de1" class="pw-post-body-paragraph ky kz it la b lb mm ju ld le mn jx lg lh mo lj lk ll mp ln lo lp mq lr ls lt im bi translated">为了评估数据集的<strong class="la iu">测试分区</strong>上的模型，我们必须设置测试数据生成器，并让模型对每个测试数据进行预测:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="ok ol l"/></div></figure><p id="e693" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">我得到的测试精度大约是<strong class="la iu"> 90.95% </strong>。具体而言，每个面部属性以以下准确度被检测:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi qa"><img src="../Images/77f0d99c87f45473e6bb3d1e899bf34f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*KPnmMEk11cvZ0XkgqrdiCg.png"/></div></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk">Accuracy of each facial attribute. The model presented here is compared to a SOTA approach, which uses a combination of two kind of networks: LNet and ANet (more details <a class="ae mt" href="https://openaccess.thecvf.com/content_iccv_2015/papers/Liu_Deep_Learning_Face_ICCV_2015_paper.pdf" rel="noopener ugc nofollow" target="_blank">here</a>).</figcaption></figure></div><div class="ab cl nj nk hx nl" role="separator"><span class="nm bw bk nn no np"/><span class="nm bw bk nn no np"/><span class="nm bw bk nn no"/></div><div class="im in io ip iq"><h1 id="677f" class="lu lv it bd lw lx nq lz ma mb nr md me jz ns ka mg kc nt kd mi kf nu kg mk ml bi translated">聚类和结果</h1><p id="98a9" class="pw-post-body-paragraph ky kz it la b lb mm ju ld le mn jx lg lh mo lj lk ll mp ln lo lp mq lr ls lt im bi translated">一旦我们有了一个工作模型，我们就可以做类似<strong class="la iu">集群</strong>这样的事情。对于此任务，聚类的目标是将图像分组为聚类，其中每个聚类在其包含的图像中共享最大可能数量的面部属性。</p><p id="9534" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">换句话说，我们希望对面部属性相似的图像进行分组，比如有一个<strong class="la iu"> <em class="mr">金发女郎群</em></strong><strong class="la iu"><em class="mr">戴着帽子和眼镜的家伙</em> </strong>等。</p><p id="7ff8" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">例如，如果我们要对以下十个属性进行聚类:</p><pre class="kj kk kl km gt nw nx ny nz aw oa bi"><span id="ae8f" class="ob lv it nx b gy oc od l oe of">'Wearing_Lipstick'<br/>'Smiling'<br/>'No_Beard'             <br/>'Heavy_Makeup'<br/>'Bald'<br/>'Male'           <br/>'Young'<br/>'Eyeglasses'<br/>'Blond_Hair'<br/>'Wearing_Hat'</span></pre><p id="7771" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">我们可能会得到这些集群:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi qb"><img src="../Images/1df261751d22fcd47f332de399f686be.png" data-original-src="https://miro.medium.com/v2/resize:fit:1360/format:webp/1*VVWiGgTZsg6QLcFRvFf-RQ.png"/></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk"><strong class="bd pz">Top left: “</strong>smiling” cluster. <strong class="bd pz">Top right:</strong> “blonde” cluster. <strong class="bd pz">Bottom left:</strong> “hat” cluster. <strong class="bd pz">Bottom right:</strong> “eyeglasses” cluster.</figcaption></figure><p id="7743" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">在这里，我们可以看到每个聚类在我们选择的属性中捕获了一个或多个面部属性。</p><blockquote class="pd pe pf"><p id="a75f" class="ky kz mr la b lb lc ju ld le lf jx lg pg li lj lk ph lm ln lo pi lq lr ls lt im bi translated">注意:以上聚类是通过对模型的预测运行标准聚类算法(如 K-Means)获得的。</p></blockquote><p id="cbd2" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">为了更好地理解集群捕获的属性，我们可以<strong class="la iu">总结</strong>它，并观察集群的总结。</p><p id="9eab" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">一个聚类可以通过提取其<em class="mr">【区别特征】</em>来概括。这可以通过计算描述集群的主成分(例如使用 PCA)来完成。在这种情况下，我们有脸的集群，所以我们可以尝试计算每个集群的<strong class="la iu">特征脸</strong>，看看它看起来像什么…</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi qc"><img src="../Images/a26c2b69a18c8f2c20dcda693da7b8e2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*5Fgvm6h-Jf0wH3qsNYvaYQ.png"/></div></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk"><strong class="bd pz">Left: </strong>clusters. <strong class="bd pz">Right: </strong>eigenfaces of the corresponding clusters.</figcaption></figure><p id="aef0" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">令人惊讶的是，一个聚类的特征脸能够通过产生一个<strong class="la iu">合成脸</strong>(不属于该聚类)来概括整个聚类，该合成脸的面部属性是该聚类所捕获的。</p><p id="9118" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">这样，我们就能一眼看出一组图像中有哪些<strong class="la iu">突出的面部属性</strong>，分组到同一个聚类中。</p></div><div class="ab cl nj nk hx nl" role="separator"><span class="nm bw bk nn no np"/><span class="nm bw bk nn no np"/><span class="nm bw bk nn no"/></div><div class="im in io ip iq"><h1 id="33af" class="lu lv it bd lw lx nq lz ma mb nr md me jz ns ka mg kc nt kd mi kf nu kg mk ml bi translated">结论</h1><p id="63d5" class="pw-post-body-paragraph ky kz it la b lb mm ju ld le mn jx lg lh mo lj lk ll mp ln lo lp mq lr ls lt im bi translated">总之，像 MobileNetV2(或 Inception 和 Resnet 模型)这样设计良好的通用模型，使得构建有效的特定于任务的模型成为可能。</p><p id="4f7f" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">为了理解数据集的结构、数据和最终的缺陷，分析数据集并观察它的一些样本总是一个好的做法。</p><p id="bde6" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">属性预测是一项可以改进许多现有应用和领域(例如，安全、摄影等)的任务。</p><p id="ac92" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">我省略了关于集群的代码，因为它有点长且复杂。无论如何，你可以在这个<a class="ae mt" href="https://github.com/Luca96/face-clustering" rel="noopener ugc nofollow" target="_blank">仓库</a>找到所有的代码。</p><p id="c3a1" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">我推荐使用 Jupyter 笔记本版本的代码进行实验。</p><p id="c77f" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">希望你喜欢它，并感谢阅读它！</p></div><div class="ab cl nj nk hx nl" role="separator"><span class="nm bw bk nn no np"/><span class="nm bw bk nn no np"/><span class="nm bw bk nn no"/></div><div class="im in io ip iq"><h1 id="4dd4" class="lu lv it bd lw lx nq lz ma mb nr md me jz ns ka mg kc nt kd mi kf nu kg mk ml bi translated">参考</h1><ul class=""><li id="3b18" class="mu mv it la b lb mm le mn lh qd ll qe lp qf lt mz na nb nc bi translated">面部属性预测和聚类的迁移学习。<em class="mr">智慧城市与信息化国际会议</em>。2019 年，新加坡施普林格。</li><li id="e79a" class="mu mv it la b lb nd le ne lh nf ll ng lp nh lt mz na nb nc bi translated">刘，，等，“野外深度学习人脸属性”IEEE 计算机视觉国际会议论文集<em class="mr">。2015.</em></li><li id="192c" class="mu mv it la b lb nd le ne lh nf ll ng lp nh lt mz na nb nc bi translated"><a class="ae mt" href="https://www.google.com/url?sa=t&amp;rct=j&amp;q=&amp;esrc=s&amp;source=web&amp;cd=2&amp;cad=rja&amp;uact=8&amp;ved=2ahUKEwil44qR4rLkAhXBzaQKHUcRAuUQFjABegQIARAB&amp;url=http%3A%2F%2Fintrotodeeplearning.com%2F&amp;usg=AOvVaw0pc46QlF-SLjGePsq0gDPA" rel="noopener ugc nofollow" target="_blank">麻省理工 6。S191:深度学习介绍</a></li><li id="6b72" class="mu mv it la b lb nd le ne lh nf ll ng lp nh lt mz na nb nc bi translated">古德菲勒、伊恩、约舒阿·本吉奥和亚伦·库维尔。<em class="mr">深度学习</em>。麻省理工学院出版社，2016 年。</li><li id="5082" class="mu mv it la b lb nd le ne lh nf ll ng lp nh lt mz na nb nc bi translated">克里斯蒂安·塞格迪等着《用回旋深化》IEEE 计算机视觉和模式识别会议论文集。2015.</li></ul></div></div>    
</body>
</html>