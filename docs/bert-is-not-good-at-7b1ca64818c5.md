# 伯特不擅长 ____。

> 原文：<https://towardsdatascience.com/bert-is-not-good-at-7b1ca64818c5?source=collection_archive---------20----------------------->

查看 BERT 语言模型的一些缺点

![](img/88bfed12c09aeb5d06c7f968d12ee435.png)

[CC](https://www.flickr.com/photos/30624156@N00/4066177576)

如果你对 NLP 感兴趣，我毫不怀疑你已经广泛阅读了关于 BERT 的内容。谷歌的一组研究人员于去年年底首次推出了这种新的语言模型，看到这种新语言模型的性能并思考其潜力，这是非常了不起的。它已经为一些语言任务设定了新的标准，并且在 Medium 上不缺少教程，这些教程提供了许多可以用 BERT 完成的语言建模项目的见解。对于这个领域来说，这是令人着迷的一年，至少可以说有了这样的发展。

在所有的赞扬中，我一直对伯特可能没有击中要害的地方感兴趣。Allyson Ettinger 有一篇有趣的论文叫做[“伯特不是什么:来自一套新的语言模型心理语言学诊断的教训”](https://arxiv.org/abs/1907.13528v1)测试了一些语言失误。我强烈推荐阅读整篇论文，因为她对自己的过程和结果有一些非常好的解释，但这里只是提到了 BERT 不足之处的一些见解:

## 常识与语用推理

> 他抱怨说，在她吻了他之后，他无法去掉脸上的红色。他最后只是要求她不要再穿那件 ____。

阅读上面的句子，你可能很容易推断出缺少的单词是“口红”。你可能没有意识到你正在做的是“口红”这个词之前没有被提及，你只是从之前的句子中推断出它，而没有直接提及它是如何使用的。有一个读者可以理解的语用推理。

在她的研究中，Ettinger 发现 BERT 在这样的测试中可以做得很好，但是很少成功。伯特能够更喜欢好的完成(“口红”)而不是差的完成(“睫毛膏”)，但没有压倒性的信心。她发现，研究结果表明，它对常识性场景中的答案不像人那样敏感。它未能在很大程度上把握前一句话提供的上下文。

## 否认

> 柯基犬不是 _____。

因此，如果你问“柯基犬是 ____”，你可能会有一百万个选项，比如“一只狗”或“一只宠物”，但它不是什么？你肯定可以想出一个答案(“一只猫”、“一把椅子”)，但是当你这样做的时候，你可以看到这些是如何需要一点独特的创造力，什么是最合适的取决于你所谈论的更大的背景。

艾丁格发现，尽管伯特非常擅长正面(“是”)，但肯定会与负面(“不是”)作斗争。它能够将名词与相近的直接描述词联系起来，但不能处理肯定或否定的措辞。这是论文中的一个例子:

**知更鸟是一种 ____**

*伯特大预言:鸟、知更鸟、人、猎人、鸽子*

**知更鸟不是 ____**

*伯特大型预测:鸟，知更鸟，人，猎人，鸽子*

你看到的不是 double，它预测了两个相同的名词！虽然表现出很强的联想能力，但它显然没有处理否定。这是一个看起来很简单的概念对 BERT 来说并不简单的领域。

还有一个问题没有在这里详细说明，我不会破坏伯特在句子中角色互换的斗争，所以如果你觉得这些见解有趣，一定要深入研究这篇论文。