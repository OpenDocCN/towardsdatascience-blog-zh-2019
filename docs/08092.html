<html>
<head>
<title>How Deep Neural Networks Look for Features in Images? With Keras and Google Colab</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">神经网络在图像中寻找特征有多深？有了 Keras 和 Google Colab</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/how-deep-neural-network-look-for-features-in-images-with-keras-and-google-colab-28209d57f771?source=collection_archive---------15-----------------------#2019-11-06">https://towardsdatascience.com/how-deep-neural-network-look-for-features-in-images-with-keras-and-google-colab-28209d57f771?source=collection_archive---------15-----------------------#2019-11-06</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="9307" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">从隐藏图层中提取 Conv 图层输出</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/dc6ab06bd3a49e1fa7f8298605496642.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*tBm_Wcu56A9CwEG2N_IxIw.jpeg"/></div></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk">What’s in the net? (<a class="ae ky" href="https://pixabay.com/users/mac231-5473271/" rel="noopener ugc nofollow" target="_blank">Source: Pixabay</a>)</figcaption></figure><p id="2f89" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">当我第一次开始从学习标准的机器算法(如逻辑回归、支持向量机)走向深度学习和神经网络时，我常常着迷于网络中的深层是一种“黑盒”。后来，这种错误的理解消失了，一旦我学会绘制中间卷积层的输出，随机选择图像并查看每一层中发生的事情几乎成了一种痴迷。今天，我想一步一步地描述你如何从隐藏的 conv 中提取特征。使用 Keras 的层(运行在 TensorFlow 之上)。为了简单起见，我采用了<a class="ae ky" href="https://www.kaggle.com/c/dogs-vs-cats" rel="noopener ugc nofollow" target="_blank">狗与猫的数据集</a>，我将构建一个类似 VGG16 的模型，因此，这个问题本质上归结为一个二进制分类问题。</p><p id="2b8e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">你可以从这篇文章中学到什么—</p><ul class=""><li id="45e6" class="lv lw it lb b lc ld lf lg li lx lm ly lq lz lu ma mb mc md bi translated">学会使用<a class="ae ky" href="https://colab.research.google.com/notebooks/welcome.ipynb" rel="noopener ugc nofollow" target="_blank">谷歌 Colab </a>部署你的深度学习模型。我发现这非常有用，因为你可以免费使用云 GPU，12.72 GB 内存和 350 GB 磁盘空间。</li><li id="f60e" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated">提取隐藏的 conv。使用 Keras 的图层输出。</li><li id="0690" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated">两种不同的方法平铺这些输出以形成紧凑的图像。</li></ul><p id="f9e0" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">因此，让我们立即开始吧！</p></div><div class="ab cl mj mk hx ml" role="separator"><span class="mm bw bk mn mo mp"/><span class="mm bw bk mn mo mp"/><span class="mm bw bk mn mo"/></div><div class="im in io ip iq"><h1 id="cd73" class="mq mr it bd ms mt mu mv mw mx my mz na jz nb ka nc kc nd kd ne kf nf kg ng nh bi translated">设置 Google Colab 环境:</h1><p id="e069" class="pw-post-body-paragraph kz la it lb b lc ni ju le lf nj jx lh li nk lk ll lm nl lo lp lq nm ls lt lu im bi translated">如果你没有 GPU 和大量的 CPU 资源，Google Colab 可以帮助你训练中度到重度的深度网络。目前，Colab 提供 12 GB Nvidia Tesla GPU，可以连续使用长达 12 小时。如果你习惯于在 Jupyter 环境下工作，你可以很容易地适应 Google Colab。查看 Google 提供的关于使用 Colab 的详细教程，在这里，我描述了完成教程的两个必要步骤。</p><ol class=""><li id="2273" class="lv lw it lb b lc ld lf lg li lx lm ly lq lz lu nn mb mc md bi translated"><em class="no">使用 GPU: </em>要访问 GPU，您需要更改运行时类型。下图显示了 Colab 环境。</li></ol><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi np"><img src="../Images/9a018b6a7cce120ae9efaf43672fa244.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*MhNGsU0AOcR1dphqgv5WCQ.png"/></div></div></figure><p id="ac2f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">2.安装你的硬盘:你需要安装你的谷歌硬盘来访问硬盘上的文件。为此，您需要运行以下命令—</p><pre class="kj kk kl km gt nq nr ns nt aw nu bi"><span id="a8f7" class="nv mr it nr b gy nw nx l ny nz">from google.colab import drive<br/>drive.mount('/content/gdrive')</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oa"><img src="../Images/76e90770aab0fecafaefd0e6189cadc6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*dxA6klDgqWlFS0eRM2tUyw.png"/></div></div></figure><p id="fa45" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">URL 将为您提供一次性授权码，将其复制并粘贴到下面的框中，然后按 enter 键。你会得到确认——</p><pre class="kj kk kl km gt nq nr ns nt aw nu bi"><span id="b4bd" class="nv mr it nr b gy nw nx l ny nz">Mounted at /content/gdrive. </span></pre><p id="825c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">之后，您就可以直接使用驱动器中的文件和文件夹了。现在让我们深入教程。</p></div><div class="ab cl mj mk hx ml" role="separator"><span class="mm bw bk mn mo mp"/><span class="mm bw bk mn mo mp"/><span class="mm bw bk mn mo"/></div><div class="im in io ip iq"><h1 id="1179" class="mq mr it bd ms mt mu mv mw mx my mz na jz nb ka nc kc nd kd ne kf nf kg ng nh bi translated">用 Colab 内部的 Keras 训练深度神经网络</h1><p id="1e38" class="pw-post-body-paragraph kz la it lb b lc ni ju le lf nj jx lh li nk lk ll lm nl lo lp lq nm ls lt lu im bi translated">让我们使用<a class="ae ky" href="https://keras.io/models/sequential/" rel="noopener ugc nofollow" target="_blank"> Keras Sequential </a>来构建我们的模型</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ob"><img src="../Images/78b5d995cac0fb07edc5cdb528e114f7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*v0owCExj8DdMCEOixXJNoA.png"/></div></div></figure><p id="4531" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">为了更快地完成训练，我使用了一个更像迷你版 VGG16 架构(2 层 conv)的模型。层，后跟一个池层)，输入大小设置为(160，160)。让我们检查一下模型摘要—</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oc"><img src="../Images/55293c49dcf85a0ee09776cd40bbdfae.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*6NKzQd5V72tBHlFh_PHVGg.png"/></div></div></figure><p id="7bf1" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我猜你们大多数人都知道计算参数。但是让我们先来回顾一下前几层。对于第一层，输入图像大小为(160，160)3 个通道<em class="no"> (n_c) </em>。滤波器尺寸<em class="no"> (f) </em>为(3，3)，滤波器数量<em class="no"> (n_f) </em>为 16。所以总重量数(f× f × n_f × n_c) = 432。偏差数= n_f = 16。参数总数= 448。同样，对于第二层，权重= (3× 3 × 16 × 16) = 2304，偏差= 16，因此，参数总数= 2320，依此类推…</p><p id="79ab" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><em class="no">数据预处理:</em>在使用<a class="ae ky" href="https://keras.io/preprocessing/image/" rel="noopener ugc nofollow" target="_blank"><em class="no">Keras imagedata generator</em></a>类之前，我们要记住这里我们会直接从 google drive 中使用文件和文件夹。所以我们必须精确文件路径。让我们看看修改后的代码块—</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi od"><img src="../Images/192c53553064ef93b5c03706a083758a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*1Wbo0JLOZzQQj32KVZub9g.png"/></div></div></figure><p id="7a57" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">为了节省时间，我只用了 2800 张图片进行训练，用了 600 张图片进行验证。接下来不可避免的是编译和拟合模型——</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oe"><img src="../Images/4997d25ea7719b3854b9e17786922cdc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*J8GmbRy4wA7TIoI8XnAFQw.png"/></div></div></figure><p id="ae28" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我使用了 100 个历元，通过参数设置，在训练和验证数据上实现了 89%和 83%的准确度。在使用 GPU 的 Google Colab 中，训练这个模型大约需要 75-80 分钟。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi of"><img src="../Images/525e70d748d653df00d92f2e493df2e6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*OWIr2tdAu4O8USxBtq-cyA.png"/></div></div></figure><p id="81d6" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我试着预测从互联网上下载的一些随机图片上的类别标签</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi og"><img src="../Images/0631f01e2585364d63cc615913aa9569.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*iJKjKKhE7xEZNtIuMJtyhA.png"/></div></div></figure><p id="10c2" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我看到 3 张图片包括一只愤怒的猫被预测为狗。我们的重点不是提高精确度，而是检查隐藏 conv 的输出。层，并了解层中的不同滤镜如何试图在图像中找到不同的特征。让我们这样做</p></div><div class="ab cl mj mk hx ml" role="separator"><span class="mm bw bk mn mo mp"/><span class="mm bw bk mn mo mp"/><span class="mm bw bk mn mo"/></div><div class="im in io ip iq"><h2 id="a63b" class="nv mr it bd ms oh oi dn mw oj ok dp na li ol om nc lm on oo ne lq op oq ng or bi translated">可视化 Conv 图层输出:</h2><p id="5142" class="pw-post-body-paragraph kz la it lb b lc ni ju le lf nj jx lh li nk lk ll lm nl lo lp lq nm ls lt lu im bi translated">我将描述两种可视化 conv 的方法。图层输出，它们非常相似，但是平铺图像的过程不同。你可以根据你的喜好来选择…</p><p id="29d8" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><em class="no">第一种方法:水平叠加层输出</em></p><p id="08f3" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">让我们检查图层名称:</p><pre class="kj kk kl km gt nq nr ns nt aw nu bi"><span id="5dfd" class="nv mr it nr b gy nw nx l ny nz">from keras.preprocessing.image import load img_to_array, load_img<br/>import random </span><span id="4053" class="nv mr it nr b gy os nx l ny nz">layer_names_list = [layr.name for layr in model.layers]<br/>print ("layer names list: ", layer_names_list)  </span><span id="3bf5" class="nv mr it nr b gy os nx l ny nz">&gt;&gt;&gt; layer names list: ['conv2d_1', 'block0_conv2', 'block0_pool1', 'block1_conv1', 'block1_conv2', 'block1_pool1', 'block2_conv1', 'block2_conv2', 'block2_pool1', 'block3_conv1', 'block3_pool', 'flatten_1', 'dense_2', 'Dropout_1', 'dense_3']</span></pre><p id="2867" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我会选择几个 conv。我希望看到输出的图层，</p><pre class="kj kk kl km gt nq nr ns nt aw nu bi"><span id="f066" class="nv mr it nr b gy nw nx l ny nz">selected_layers = [‘block0_conv2’, ‘block2_conv1’, ‘block2_conv2’]</span><span id="177e" class="nv mr it nr b gy os nx l ny nz">matched_indices = [i for i, item in enumerate(layer_names_list) if item in selected_layers]</span><span id="c26e" class="nv mr it nr b gy os nx l ny nz">print (matched_indices)</span><span id="453f" class="nv mr it nr b gy os nx l ny nz">&gt;&gt;&gt; [1, 6, 7]</span></pre><p id="2330" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">为了从选定的层中获得输出，我们将使用<a class="ae ky" href="https://keras.io/layers/about-keras-layers/" rel="noopener ugc nofollow" target="_blank"><em class="no">Keras layer . output</em></a>方法。然后将输出附加到一个列表上，让我们看看:</p><pre class="kj kk kl km gt nq nr ns nt aw nu bi"><span id="2642" class="nv mr it nr b gy nw nx l ny nz">selected_layers_outputs = []</span><span id="fb4c" class="nv mr it nr b gy os nx l ny nz">for lr in range(len(matched_indices)):</span><span id="d692" class="nv mr it nr b gy os nx l ny nz">   outputs = model.layers[matched_indices[lr]].output <br/>   #output from selected layers</span><span id="1743" class="nv mr it nr b gy os nx l ny nz">   selected_layers_outputs.append(outputs)</span></pre><p id="e64e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">下一步是重要的，因为我们将实例化一个新的模型，它将采取一个随机的图像(猫或狗)作为输入，输出将是选定的 conv。层输出。查看<a class="ae ky" href="https://keras.io/models/model/" rel="noopener ugc nofollow" target="_blank"> Keras 模型 API </a>了解更多详情。</p><pre class="kj kk kl km gt nq nr ns nt aw nu bi"><span id="55a1" class="nv mr it nr b gy nw nx l ny nz">visual_model = keras.models.Model(inputs = model.input, outputs = selected_layers_outputs)</span></pre><p id="6c7e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">如果你记得我们的原始模型(VGG 喜欢)的输入，它是输入大小(无，160，160，3)的图像批次。我们将选择相同的输入尺寸维度，但是因为我们只想一次只处理 1 个随机选择的图像，所以我们的批量大小将是 1。首先，让我们随机选择一个图像，我们将使用<a class="ae ky" href="https://docs.python.org/3/library/random.html" rel="noopener ugc nofollow" target="_blank"> random.choice，</a>从非空序列中返回一个随机元素。</p><pre class="kj kk kl km gt nq nr ns nt aw nu bi"><span id="c6ab" class="nv mr it nr b gy nw nx l ny nz">dog_files = [os.path.join(dog_train_dir, f) for f in dog_train_images]</span><span id="056e" class="nv mr it nr b gy os nx l ny nz">cat_files = [os.path.join(cat_train_dir, g) for g in cat_train_images]</span><span id="fc2e" class="nv mr it nr b gy os nx l ny nz">random_cat_dog = random.choice(dog_files + cat_files)</span><span id="d154" class="nv mr it nr b gy os nx l ny nz">print (“random file name: “, random_cat_dog)</span></pre><p id="2ca5" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在下一步中，我们希望调整这个图像的大小，并将这个图像转换为一个 numpy 数组，最后，将其重新整形为一致的格式(批量大小、高度、宽度、通道)。让我们使用<a class="ae ky" href="https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image/load_img" rel="noopener ugc nofollow" target="_blank"> Keras load_img、</a> Keras <a class="ae ky" href="https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image/img_to_array" rel="noopener ugc nofollow" target="_blank"> img_to_array </a>和 numpy 模块来实现。</p><pre class="kj kk kl km gt nq nr ns nt aw nu bi"><span id="bc41" class="nv mr it nr b gy nw nx l ny nz">rand_img = load_img(random_cat_dog, target_size=(160, 160))</span><span id="a663" class="nv mr it nr b gy os nx l ny nz">rand_img_arr = img_to_array(rand_img)</span><span id="3f33" class="nv mr it nr b gy os nx l ny nz">print ("shape of selected image :", rand_img_arr.shape)</span><span id="e948" class="nv mr it nr b gy os nx l ny nz">x_in = np.reshape(rand_img_arr, (1, 160, 160, 3)) # batch size 1</span><span id="d4b9" class="nv mr it nr b gy os nx l ny nz">&gt;&gt;&gt; shape of selected image : (160, 160, 3)</span></pre><p id="d018" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">一旦我们以适合作为模型输入的格式处理了图像，让我们从模型中为所选层生成预测。</p><pre class="kj kk kl km gt nq nr ns nt aw nu bi"><span id="369b" class="nv mr it nr b gy nw nx l ny nz">selected_feature_maps = visual_model.predict(x_in)</span></pre><p id="d2f4" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">现在是以这种方式安排这些预测的部分，这样就有可能可视化每个过滤器对那些选定层的影响。这部分有点棘手，我们需要用 numpy 来释放我们的游戏性。让我简单介绍一下我们如何进行。如果你回头看 model.summary()，那么你将得到形状的概述，元组的最后一个元素是过滤器的数量，元组的第一/第二个元素是图像的高度/宽度。首先，我们创建具有形状(高度，高度*过滤器数量)的零网格，以便稍后我们可以水平堆叠输出。接下来，我们对过滤器的数量进行循环。我们需要记住，批量大小为 1，因此，要从选定的层中选择特定的滤波器输出，我们需要这样做(稍后查看详细代码)—</p><pre class="kj kk kl km gt nq nr ns nt aw nu bi"><span id="3693" class="nv mr it nr b gy nw nx l ny nz">for i in range(n_filters):<br/>  y = feat_map [0, :, :, i]</span></pre><p id="cbfb" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">然后，我们对过滤器的输出进行标准化和后处理，使其在视觉上可识别。最后，我们将过滤器输出堆叠在我们之前创建的显示网格中(零网格)。使用<a class="ae ky" href="https://matplotlib.org/3.1.1/api/_as_gen/matplotlib.pyplot.imshow.html" rel="noopener ugc nofollow" target="_blank"><em class="no">matplotlib imshow</em></a>，我们可以将图像并排堆叠的特定图层上的每个滤镜的效果可视化。如下图所示。我发现了一个关于<a class="ae ky" href="https://stackoverflow.com/questions/49434754/how-does-the-pyplot-imshow-function-work" rel="noopener ugc nofollow" target="_blank">如何使用<em class="no"> imshow </em>方法</a>的非常详细的答案；请检查一下，以便更好地理解下面代码中第二个 for 循环的最后一行发生了什么。</p><pre class="kj kk kl km gt nq nr ns nt aw nu bi"><span id="df4b" class="nv mr it nr b gy nw nx l ny nz">for lr_name, feat_map in zip(selected_layers, selected_feature_maps):</span><span id="194b" class="nv mr it nr b gy os nx l ny nz">  n_filters = feat_map.shape[-1]</span><span id="e89a" class="nv mr it nr b gy os nx l ny nz">  n_size = feat_map.shape[1]</span><span id="f05e" class="nv mr it nr b gy os nx l ny nz">  display_grid = np.zeros((n_size, n_size * n_filters))</span><span id="5a31" class="nv mr it nr b gy os nx l ny nz">  for i in range(n_filters):</span><span id="3f3e" class="nv mr it nr b gy os nx l ny nz">    y = feat_map[0, :, :, i]</span><span id="fd0a" class="nv mr it nr b gy os nx l ny nz">    y = y - y.mean()</span><span id="c07a" class="nv mr it nr b gy os nx l ny nz">    y = y/y.std()</span><span id="386f" class="nv mr it nr b gy os nx l ny nz">    y = y*64</span><span id="2406" class="nv mr it nr b gy os nx l ny nz">    y = y + 128</span><span id="697c" class="nv mr it nr b gy os nx l ny nz">    y = np.clip(y, 0, 255).astype('uint8')# value only between 0, 255. </span><span id="c439" class="nv mr it nr b gy os nx l ny nz">    display_grid[:, i * n_size : (i+1) * n_size] = y</span><span id="9c0d" class="nv mr it nr b gy os nx l ny nz">  scale = 20./n_filters</span><span id="7dcc" class="nv mr it nr b gy os nx l ny nz">  plt.figure(figsize=(scale * n_filters * 1.4, scale * 2))</span><span id="9cb7" class="nv mr it nr b gy os nx l ny nz">  plt.title(lr_name, fontsize=16)</span><span id="a612" class="nv mr it nr b gy os nx l ny nz">  plt.grid(False)</span><span id="d6c7" class="nv mr it nr b gy os nx l ny nz">plt.imshow(display_grid, aspect='auto', cmap='plasma')</span><span id="c453" class="nv mr it nr b gy os nx l ny nz">plt.savefig('/content/gdrive/My Drive/Colab Notebooks/cat_dog_visual_%s.png'%(lr_name), dpi=300)</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ot"><img src="../Images/944f78507870531eff39a61e97e50bfa.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*a7vjvZPpqiwOLkeD-5oARg.png"/></div></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk">Figure 1: Stacking output from each filter horizontally from 3 different convolutional layers.</figcaption></figure><p id="54b6" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在这里，我们可以看到模型的第二层<em class="no"> (block0_conv2) </em>中的滤波器看到完整的输入(160，160)，主要是寻找一些基本的边缘。但是，<em class="no">随着我们深入</em>输入尺寸减小，例如在<em class="no"> block2_conv2 </em>层中，图像的形状是(40，40)，这里视觉信息几乎无法识别，但是与图像类别相关的<em class="no">特征被过滤器捕获。</em>您还可以看到，随着我们深入网络，稀疏过滤器的数量也在增加，因为随着每层中过滤器数量的增加，前一层过滤器编码的模式在当前层中看不到。这就是为什么几乎总是你会看到，在第一层所有的过滤器被激活，但从第二层稀疏性增加。</p><p id="5606" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我发现前面的水平堆叠输出的方法很合理，但在视觉上并不引人注目，所以我给出了我在 Francois Chollet 的书<a class="ae ky" href="https://www.amazon.co.jp/Deep-Learning-Python-Francois-Chollet/dp/1617294438" rel="noopener ugc nofollow" target="_blank">用 Python 进行深度学习</a>中找到的第二种方法。这与第一个非常相似，但我们不是水平堆叠所有过滤器的输出，而是将它们放在一个数组中。这里的主要概念是确定阵列的形状，并像前面一样堆叠滤波器输出。</p><p id="4d63" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><em class="no">第二种方法:</em>这里我们从每层中使用的过滤器数量中获益，即它们都是 16 的倍数。因此，每个网格的列数将是 16，行数将取决于所选卷积层中使用的滤波器数量。因此，列数(ncols)由=滤波器数/16 给出。这里，我们的零网格将有形状(高*ncols，16 *宽)。考虑图像的高度和宽度在每一层中都是相同的。</p><pre class="kj kk kl km gt nq nr ns nt aw nu bi"><span id="4eb4" class="nv mr it nr b gy nw nx l ny nz">images_per_row = 16</span><span id="089a" class="nv mr it nr b gy os nx l ny nz">for lr_name1, feat_map1 in zip(selected_layers1, selected_feature_maps1):</span><span id="6a79" class="nv mr it nr b gy os nx l ny nz">  n_filters1 = feat_map1.shape[-1]</span><span id="663f" class="nv mr it nr b gy os nx l ny nz">  n_size1 = feat_map1.shape[1]</span><span id="a3a3" class="nv mr it nr b gy os nx l ny nz">  n_cols = n_filters1 // images_per_row</span><span id="490c" class="nv mr it nr b gy os nx l ny nz">  display_grid1 = np.zeros((n_size1 * n_cols, images_per_row * n_size1))</span><span id="a644" class="nv mr it nr b gy os nx l ny nz">  for col in range(n_cols):</span><span id="2dc3" class="nv mr it nr b gy os nx l ny nz">    for row in range(images_per_row):</span><span id="4910" class="nv mr it nr b gy os nx l ny nz">      chan_img = feat_map1[0, :, :, col*images_per_row + row]</span><span id="6cc8" class="nv mr it nr b gy os nx l ny nz">      chan_img = chan_img — chan_img.mean()</span><span id="0916" class="nv mr it nr b gy os nx l ny nz">      chan_img = chan_img / chan_img.std()</span><span id="cc3f" class="nv mr it nr b gy os nx l ny nz">      chan_img = chan_img * 64</span><span id="154d" class="nv mr it nr b gy os nx l ny nz">      chan_img = chan_img + 128</span><span id="558a" class="nv mr it nr b gy os nx l ny nz">      chan_img = np.clip(chan_img, 0, 255).astype(‘uint8’)</span><span id="1d51" class="nv mr it nr b gy os nx l ny nz">      display_grid1[col * n_size1 : (col+1) * n_size1, row * n_size1 : (row+1) * n_size1] = chan_img</span><span id="dec9" class="nv mr it nr b gy os nx l ny nz">  scale1 = 1./n_size1</span><span id="8905" class="nv mr it nr b gy os nx l ny nz">  plt.figure(figsize=(scale1 * display_grid1.shape[1]*1.4, scale1 * display_grid1.shape[0] * 2.))</span><span id="a55e" class="nv mr it nr b gy os nx l ny nz">  plt.title(lr_name1)</span><span id="8484" class="nv mr it nr b gy os nx l ny nz">  plt.grid(False)</span><span id="6df5" class="nv mr it nr b gy os nx l ny nz">  plt.imshow(display_grid1, aspect=’auto’, cmap=’viridis’)</span><span id="6c44" class="nv mr it nr b gy os nx l ny nz">  plt.savefig(‘/content/gdrive/My Drive/Colab Notebooks/cat_dog_visual2_%s.png’%(lr_name1), dpi=300)</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ou"><img src="../Images/9352d9c7df2706c6f6bc0b1db747fc8b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*hcjLpv-JzsRY5r6Ox0t9vA.png"/></div></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk">Figure 2: Arranging the same images as in Figure 1 more cleanly so that they are easy to interpret and understand.</figcaption></figure><p id="3423" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">有了这个表示，你可以清楚地看到我们的模型中更深层的过滤器如何集中在猫的特定特征上，如眼睛、鼻子、眉毛区域等的形状。</p></div><div class="ab cl mj mk hx ml" role="separator"><span class="mm bw bk mn mo mp"/><span class="mm bw bk mn mo mp"/><span class="mm bw bk mn mo"/></div><div class="im in io ip iq"><p id="1102" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在这篇文章中，我们看到了如何使用 Google Colab 来构建和训练你的相当大的深度学习网络。我们的主要焦点是通过深层神经网络的几个层来可视化图像的旅程，我们已经学会了两种方法来做到这一点。此外，可视化应该帮助我们更好地看透和理解它们，而不是将深层视为黑盒。</p></div><div class="ab cl mj mk hx ml" role="separator"><span class="mm bw bk mn mo mp"/><span class="mm bw bk mn mo mp"/><span class="mm bw bk mn mo"/></div><div class="im in io ip iq"><h2 id="f065" class="nv mr it bd ms oh oi dn mw oj ok dp na li ol om nc lm on oo ne lq op oq ng or bi translated">参考资料:</h2><p id="c664" class="pw-post-body-paragraph kz la it lb b lc ni ju le lf nj jx lh li nk lk ll lm nl lo lp lq nm ls lt lu im bi translated">[1] <a class="ae ky" href="https://arxiv.org/pdf/1409.1556.pdf" rel="noopener ugc nofollow" target="_blank">用于大规模图像识别的极深卷积网络</a>；k .西蒙扬 a .齐塞曼。</p><p id="aa87" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">[2] <a class="ae ky" href="https://colab.research.google.com/notebooks/welcome.ipynb" rel="noopener ugc nofollow" target="_blank">谷歌的 Colab 教程</a>。</p><p id="0f8a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">[3] <a class="ae ky" href="https://www.deeplearning.ai/tensorflow-in-practice/" rel="noopener ugc nofollow" target="_blank"> Tensorflow 专业化课程:深度学习. ai </a></p><p id="bfb0" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">【4】<a class="ae ky" href="https://www.amazon.co.jp/Deep-Learning-Python-Francois-Chollet/dp/1617294438" rel="noopener ugc nofollow" target="_blank">用 Python 进行深度学习；</a>弗朗索瓦·乔莱。第 160-177 页。</p><p id="d3df" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">[5]<a class="ae ky" href="https://neptune.ai/blog/google-colab-dealing-with-files" rel="noopener ugc nofollow" target="_blank">Colab 中处理文件的资源</a> : Neptune.ai</p><p id="6e0f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">[6] <a class="ae ky" href="https://github.com/suvoooo/Learn-TensorFlow/blob/master/Transfer_Learning/building_VGG16_visualization.ipynb" rel="noopener ugc nofollow" target="_blank">链接到本帖使用的笔记本！</a></p></div></div>    
</body>
</html>