<html>
<head>
<title>Resampling Methods for Unbalanced Datasets — Fraudulent Transactions</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">不平衡数据集的重采样方法-欺诈交易</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/https-towardsdatascience-com-resampling-methods-for-unbalanced-datasets-5b565d0a247d?source=collection_archive---------14-----------------------#2019-11-14">https://towardsdatascience.com/https-towardsdatascience-com-resampling-methods-for-unbalanced-datasets-5b565d0a247d?source=collection_archive---------14-----------------------#2019-11-14</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><p id="8562" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">假设你的任务是开发一个简单的机器学习算法，无论是有监督的(有明确的目标变量)还是无监督的(没有预定义的结果变量)。但是看你的数据，好像是一个阶级统治了另一个阶级。在这种情况下，您的模型将很难从您的数据中学习来预测未来的类。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi ko"><img src="../Images/550f3ef7ff7c45f0acf2bcaa36b038a0.png" data-original-src="https://miro.medium.com/v2/resize:fit:800/format:webp/1*fsN7QeV8B9qbGUlSHoBG1w.jpeg"/></div><figcaption class="kw kx gj gh gi ky kz bd b be z dk">Data Sampling <a class="ae la" href="https://ssix-project.eu/data-sampling/" rel="noopener ugc nofollow" target="_blank">Source</a></figcaption></figure><p id="d196" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">仍然不确定这里的问题是什么？让我们看一个恰当的例子。</p><p id="5df0" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu">可视化不平衡数据集</strong></p><p id="2c50" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">让我们看看不平衡数据在实践中是什么样子的。出于本文的目的，以及即将发布的一系列专注于检测欺诈者的文章，我从 Kaggle 挑选了<a class="ae la" href="https://www.kaggle.com/mlg-ulb/creditcardfraud" rel="noopener ugc nofollow" target="_blank">信用卡欺诈数据集</a>。<br/>该数据集是大约 28.5k 信用卡交易的集合，其中维度是从 V1 到 V28 的一组理论特征，不包括交易金额，以及后者是否是欺诈交易，以分类变量的形式表示(当没有欺诈时，Class == 0，否则，Class == 1)。</p><pre class="kp kq kr ks gt lb lc ld le aw lf bi"><span id="19f0" class="lg lh it lc b gy li lj l lk ll">#Import libraries &amp; Read Data<br/>import pandas as pd<br/>import numpy as np<br/>import matplotlib.pyplot as plt</span><span id="3fad" class="lg lh it lc b gy lm lj l lk ll">df = pd.read_csv("creditcard.csv")</span></pre><p id="22f2" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">现在让我们来数一数欺诈案件相对于非欺诈案件出现的次数。</p><pre class="kp kq kr ks gt lb lc ld le aw lf bi"><span id="98b4" class="lg lh it lc b gy li lj l lk ll">occ = df['Class'].value_counts()<br/>print(occ)</span><span id="c124" class="lg lh it lc b gy lm lj l lk ll">Output:<br/>#0    284315<br/>#1       492 </span></pre><p id="9617" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">因此，在总共 284807 笔信用卡交易中，我们总共发现了 492 起欺诈案件。</p><pre class="kp kq kr ks gt lb lc ld le aw lf bi"><span id="42e1" class="lg lh it lc b gy li lj l lk ll">print(occ / df.shape[0])</span></pre><p id="6c7f" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">这只占所有病例的 0.17%。对于训练我们的模型来说，这可以说是相当微不足道的欺诈性数据，这就是我们所说的<em class="ln">类不平衡问题。</em></p><p id="cdb2" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">在我们做出任何更改之前，让我们先直观地看一下。</p><p id="f9f1" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">首先，让我们定义一个函数来创建数据和标签的散点图。</p><pre class="kp kq kr ks gt lb lc ld le aw lf bi"><span id="f5bc" class="lg lh it lc b gy li lj l lk ll">def plot_data(X, y):<br/> plt.scatter(X[y == 0, 0], X[y == 0, 1], label="Class #0", alpha=0.5, linewidth=0.15)<br/> plt.scatter(X[y == 1, 0], X[y == 1, 1], label="Class #1", alpha=0.5, linewidth=0.15, c='r')<br/> plt.legend()<br/> return plt.show()</span></pre><p id="ca3b" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">我们希望在我们的图表上尽可能避免噪音和维度。因此，我们将创建一个将所有特性放在一起的<em class="ln">向量 X </em>，以及一个包含目标变量(类变量)的<em class="ln">向量 y </em>。<br/>我们将为此定义一个附加函数。</p><pre class="kp kq kr ks gt lb lc ld le aw lf bi"><span id="d799" class="lg lh it lc b gy li lj l lk ll">def prep_data(df):<br/>        X = df.iloc[:, 1:29].values<br/>        X = np.array(X).astype(np.float)<br/>        y = df.iloc[:, 30].values<br/>        y=np.array(y).astype(np.float)<br/>        return X,y</span></pre><p id="8ea6" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">我们现在定义变量 X 和 y:</p><pre class="kp kq kr ks gt lb lc ld le aw lf bi"><span id="8b88" class="lg lh it lc b gy li lj l lk ll">X, y = prep_data(df)</span></pre><p id="9558" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">准备好了吗？我们走吧:</p><pre class="kp kq kr ks gt lb lc ld le aw lf bi"><span id="c6a9" class="lg lh it lc b gy li lj l lk ll">plot_data(X, y)</span></pre><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi lo"><img src="../Images/8ed631c13db2e598443c22cd9a6f8aa9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1280/format:webp/1*mEDWkz-ZBsKa-BQ-adam8g.png"/></div><figcaption class="kw kx gj gh gi ky kz bd b be z dk">Visualization of Class Imbalance</figcaption></figure><p id="ce62" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">您可以很容易地看到，红色的欺诈案例明显多于蓝色的非欺诈案例。在这种情况下，机器学习算法解释的主要是非欺诈事件。当成功训练我们的模型时，这将被证明是具有挑战性的，因为当数据集保持原样时，它很可能会产生假阴性。</p><p id="478f" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">那么我们能做些什么呢？这就是重采样派上用场的地方，作为一种提高欺诈与非欺诈比率的方法。</p><p id="4aa6" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu">什么是重采样&amp;什么时候用？<br/> </strong>重采样是从原始数据集中抽取重复样本的过程。重采样方法背后的直觉是，它为我们的数据类创建“相似”案例，以便呈现代表我们希望调查的人群的数据，并因此向算法提供足够的数据以输出<em class="ln">更准确的结果(当数据不够时)。</em></p><p id="d4e4" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu">有哪些类型的重采样方法？</strong></p><ul class=""><li id="5fe6" class="lp lq it js b jt ju jx jy kb lr kf ls kj lt kn lu lv lw lx bi translated">欠采样多数类</li><li id="c9c4" class="lp lq it js b jt ly jx lz kb ma kf mb kj mc kn lu lv lw lx bi translated">对少数民族阶层进行过度采样</li><li id="32ba" class="lp lq it js b jt ly jx lz kb ma kf mb kj mc kn lu lv lw lx bi translated">合成少数过采样技术(SMOTE)</li></ul><p id="a886" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">显然有更多的重采样方法(例如，自举、交叉验证等。)但在本文中，我们将重点定义以上三种。</p><p id="e0fe" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu">欠采样多数类</strong>(在这种情况下，非欺诈情况)从数据集中随机抽取主要类，以匹配非主要类的数量。一般来说，这通常是最不可取的方法，因为它会导致我们丢弃一些有价值的数据，但是当您有一个大型数据集时，欠采样<em class="ln">在计算上可能会更好(除非您同时煮咖啡)。</em></p><p id="29fc" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu">过采样少数类</strong>则相反。与前面的方法不同，我们随机抽取非支配类，并创建“假”副本来匹配支配类中的案例数量。在这种情况下，我们实际上是在创建数据的副本，并在此基础上训练我们的模型。当我们的非支配类没有分散在数据集中时，这可能不是一个理想的方法。复制只会有效地再造相似的实例，而没有“合成的”种类。</p><p id="822b" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">这就引出了第三个也是最后一个方法！</p><p id="2b3f" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu">合成少数过采样技术(SMOTE) </strong>是另一种类型的少数过采样技术，只是这种技术考虑了非支配类的现有情况的特征，并以“最近邻居”的方式创建合成副本<em class="ln">(无法控制自己来自东南亚的说法:相同，但不同！).</em></p><blockquote class="md me mf"><p id="f8ce" class="jq jr ln js b jt ju jv jw jx jy jz ka mg kc kd ke mh kg kh ki mi kk kl km kn im bi translated">对于这三种方法，一个经验法则是只对你的训练数据进行重采样！</p></blockquote><p id="9408" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu">重采样不平衡类—击杀方式<br/> </strong> <em class="ln">(看我在那里做了什么？永远不要错过任何插上一句双关语的机会)</em></p><pre class="kp kq kr ks gt lb lc ld le aw lf bi"><span id="3feb" class="lg lh it lc b gy li lj l lk ll">!pip install imblearn<br/>from imblearn.over_sampling import SMOTE</span><span id="1e90" class="lg lh it lc b gy lm lj l lk ll">method = SMOTE(kind='regular')</span></pre><p id="2c7f" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">让我们将该方法应用于我们的特性&amp;目标变量。</p><pre class="kp kq kr ks gt lb lc ld le aw lf bi"><span id="ca9f" class="lg lh it lc b gy li lj l lk ll">X_resampled, y_resampled = method.fit_sample(X, y)</span></pre><p id="522f" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">现在让我们来看看我们新的平衡数据集:</p><pre class="kp kq kr ks gt lb lc ld le aw lf bi"><span id="57a5" class="lg lh it lc b gy li lj l lk ll">plot_data(X_resampled, y_resampled)</span></pre><p id="b312" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">瞧啊！</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi lo"><img src="../Images/aaa607efa640ac17b6e20d233770c649.png" data-original-src="https://miro.medium.com/v2/resize:fit:1280/format:webp/1*pq56Tf4m65DTlz_ZCRqBcg.png"/></div><figcaption class="kw kx gj gh gi ky kz bd b be z dk">Balanced Dataset — using SMOTE Technique</figcaption></figure><p id="3459" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu">结论</strong></p><p id="187f" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">正如你所看到的，我们的非主导类(红色的欺诈案例)在数据上更加明显。如果我们运行一个快速的数字检查，我们会看到<em class="ln"> y </em>和<em class="ln">y _ 重采样</em>的计数现在是相似的。<br/> SMOTE 已经在 imblearn 软件包中预定义的特征空间中有效地合成了新的欺诈案例(对于更倾向于数学的人来说，对 K-最近邻和欧几里德空间的理解在这一点上可能会派上用场)。</p><p id="6817" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">不过，尽管如此，还是要记住一些限制，因为最近的邻居可能并不总是欺诈案例。将 SMOTE 方法与其他一些基于规则的系统结合起来以获得更高的准确性将是一个明智的决定，但这取决于手头的任务和数据。</p><p id="4019" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu">玩得开心！<br/> </strong>现在，可以说你已经准备好继续使用你的预测模型了(别忘了只在训练集上应用 SMOTE)！</p><p id="cbcb" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><em class="ln">这是我关于检测信用卡欺诈的系列文章中的第一篇(因此选择了这里的数据集)。如果您有兴趣了解更多信息并尝试一下，请订阅我的频道，不要犹豫，请在下面留下您的反馈:)谢谢！</em></p></div></div>    
</body>
</html>