<html>
<head>
<title>Getting started on Deep Learning for Audio Data</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">音频数据深度学习入门</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/getting-started-on-deep-learning-for-audio-data-667d9aa76a33?source=collection_archive---------11-----------------------#2019-09-25">https://towardsdatascience.com/getting-started-on-deep-learning-for-audio-data-667d9aa76a33?source=collection_archive---------11-----------------------#2019-09-25</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><p id="180f" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">尽管随着梯度推进方法的兴起，传统的机器学习算法仍然在结构化数据上取得了胜利，但在处理非结构化数据方面，没有什么比深度学习更好了。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi ko"><img src="../Images/02fc85d06e5c1f1760495cf73c85ed92.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*poGcUrMDWDyqfXzI"/></div></div><figcaption class="la lb gj gh gi lc ld bd b be z dk">Photo by <a class="ae le" href="https://unsplash.com/@hiteshchoudhary?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Hitesh Choudhary</a> on <a class="ae le" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><p id="5f81" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">让我们回到标题。</p><p id="97d0" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><em class="lf">音频数据，你确定？</em></p><p id="01f4" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">好吧，不管是不是有意的，我想我们大多数人已经在基于音频的深度学习系统中尝试了一些解决方案。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi lg"><img src="../Images/e3166d80b55930e0b8275ee8a3dbe121.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*qesuIULIA1AFYH6OJ8oHoA.png"/></div><figcaption class="la lb gj gh gi lc ld bd b be z dk"><a class="ae le" href="https://techcrunch.com/2016/06/29/ok-google-tea-earl-grey-hot/" rel="noopener ugc nofollow" target="_blank">Ok, Google!</a></figcaption></figure><p id="adb2" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">我可以肯定地假设我们大多数人都尝试过这个东西。</p><p id="6cdd" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><em class="lf">你有没有想过那个功能是怎么建立的？</em></p><h1 id="33a0" class="lh li it bd lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me bi translated">非结构化数据的深度学习</h1><p id="fc3c" class="pw-post-body-paragraph jq jr it js b jt mf jv jw jx mg jz ka kb mh kd ke kf mi kh ki kj mj kl km kn im bi translated">是的，非结构化数据是迄今为止最适合深度学习的数据。虽然你也可以在结构化数据上使用它，但传统的机器学习可以在中等数量的数据上轻松击败性能。</p><p id="afc8" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">像自动驾驶汽车、人脸识别或几个月前传播开来的臭名昭著的 FaceApp 这样的东西，都是图像数据深度学习系统的副产品。</p><p id="b7a1" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu"> <em class="lf">图像数据=像素颜色=非结构化数据</em> </strong></p><p id="d5bb" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">基本上，非结构化数据意味着一堆数据点，没有对它们进行统计分析的手段。你不能在像素上使用任何形式的标准差，所以图像是非结构化的。</p><p id="85f2" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">文本和音频也是如此。</p><p id="5a0f" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">音频数据是一串一个接一个排序的波形信号。你不可能分析均值对模型的影响。</p><h1 id="1ed4" class="lh li it bd lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me bi translated">我们去找音频数据</h1><p id="8d72" class="pw-post-body-paragraph jq jr it js b jt mf jv jw jx mg jz ka kb mh kd ke kf mi kh ki kj mj kl km kn im bi translated">你知道非结构化数据的概念。现在，你想知道“好吧，谷歌！”正在建造的东西。</p><p id="e853" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">通俗地说，流程应该是这样的:</p><p id="82ae" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu">你的手机听周围的话→有人说关键词“好的，谷歌！”→助手应用程序激活。</strong></p><p id="348b" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">什么！</p><p id="5357" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><em class="lf">我手机每次都听我的？那不是侵犯隐私吗？</em></p><p id="0837" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">嗯，这篇文章我不想谈那个问题。让我们继续第 2 步和第 3 步。</p><p id="7411" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu">如果你的手机听到关键词，它会打开应用程序。</strong></p><p id="fdc5" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">因此，在这个特别的教程中，我想分享你如何建立一个算法，能够区分关键词和其他声音。</p><h1 id="6832" class="lh li it bd lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me bi translated">音频数据深度学习教程</h1><p id="b1ba" class="pw-post-body-paragraph jq jr it js b jt mf jv jw jx mg jz ka kb mh kd ke kf mi kh ki kj mj kl km kn im bi translated">让我们来看看<a class="ae le" href="http://www.kaggle.com" rel="noopener ugc nofollow" target="_blank"> Kaggle </a>，</p><p id="2a43" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">有一个关于如何区分火鸡(动物)的声音和其他声音的比赛。为什么是土耳其？我不知道。至少，它符合我们的需求。<strong class="js iu">关键词不一定要人声吧？Lol。</strong></p><p id="3e3d" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">下载数据，可以看到训练数据(train.json)</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi mk"><img src="../Images/186f5cf8f9e14c57fad79413d4719016.png" data-original-src="https://miro.medium.com/v2/resize:fit:670/format:webp/1*qbFU_DfSfVIbSFmQ1gpvtg.jpeg"/></div><figcaption class="la lb gj gh gi lc ld bd b be z dk">train.json data</figcaption></figure><p id="9b3c" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">您将看到一个包含 1195 个项目的 JSON 列表，这意味着您有 1995 个项目作为训练数据。</p><p id="3638" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">每个项目将有 5 个属性，</p><ol class=""><li id="ffe9" class="ml mm it js b jt ju jx jy kb mn kf mo kj mp kn mq mr ms mt bi translated">视频 id，即来自 YouTube 的视频的 ID</li><li id="dd44" class="ml mm it js b jt mu jx mv kb mw kf mx kj my kn mq mr ms mt bi translated">剪辑的开始时间</li><li id="add9" class="ml mm it js b jt mu jx mv kb mw kf mx kj my kn mq mr ms mt bi translated">剪辑的结束时间(因此，没有使用所有视频，只有 10 秒的视频)</li><li id="ca25" class="ml mm it js b jt mu jx mv kb mw kf mx kj my kn mq mr ms mt bi translated">是火鸡，确定那是不是火鸡</li><li id="0bb7" class="ml mm it js b jt mu jx mv kb mw kf mx kj my kn mq mr ms mt bi translated">音频嵌入，这是从音频嵌入的 10 秒钟。他们使用<a class="ae le" href="https://github.com/tensorflow/models/tree/master/research/audioset" rel="noopener ugc nofollow" target="_blank">https://github . com/tensor flow/models/tree/master/research/audioset</a>中的脚本将音频波转换成数字。我们可以只使用处理后的结果。</li></ol><p id="d4c6" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">例如，你可以看这个超赞的火鸡视频，</p><p id="8ce8" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">美味的火鸡</p><p id="bb88" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">从第 30 秒到第 40 秒观看。你知道有火鸡，尽管背景音乐扰乱了宁静。</p><h1 id="bde1" class="lh li it bd lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me bi translated">准备工作</h1><p id="1aac" class="pw-post-body-paragraph jq jr it js b jt mf jv jw jx mg jz ka kb mh kd ke kf mi kh ki kj mj kl km kn im bi translated"><em class="lf">等等</em>，我有点不知所措了。</p><p id="fd5e" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">看起来很复杂。我想从头说起。我不懂深度学习，连火鸡都不懂。</p><p id="41de" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">你可以在网上找到很多资源，从书籍、讲座到课程。去谷歌一下。</p><p id="6da0" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">或者你可以从我之前策划的<a class="ae le" href="https://thedatamage.com/best-course-for-ai-2019-updated/" rel="noopener ugc nofollow" target="_blank">开始。</a></p><p id="8827" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">所以，现在你已经熟悉了术语和其他种类的东西，你已经准备好了。</p><h1 id="a405" class="lh li it bd lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me bi translated">Python 和包</h1><p id="013c" class="pw-post-body-paragraph jq jr it js b jt mf jv jw jx mg jz ka kb mh kd ke kf mi kh ki kj mj kl km kn im bi translated">当然，Python。需要先从<a class="ae le" href="https://www.python.org/downloads/" rel="noopener ugc nofollow" target="_blank"> Python 官网</a>安装。您需要安装 3.6+版以保持库的最新状态。</p><p id="fb16" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">并从终端安装其他东西，</p><pre class="kp kq kr ks gt mz na nb nc aw nd bi"><span id="7727" class="ne li it na b gy nf ng l nh ni">pip install numpy<br/>pip install pandas<br/>pip install seaborn<br/>pip install matplotlib<br/>pip install tensorflow<br/>pip install keras<br/>pip install jupyter</span></pre><p id="5866" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">让我们从终端键入<em class="lf"> jupyter notebook </em>，我们就可以开始了！</p><pre class="kp kq kr ks gt mz na nb nc aw nd bi"><span id="da28" class="ne li it na b gy nf ng l nh ni">import numpy as np<br/>import pandas as pd <br/>import os<br/>import seaborn as sns<br/>import matplotlib.pyplot as plt<br/>import seaborn as sns<br/>plt.style.use('fivethirtyeight')<br/>from tqdm import tqdm<br/>print(os.listdir("../input"))</span></pre><p id="4237" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">准备好库，您可以看到输出</p><pre class="kp kq kr ks gt mz na nb nc aw nd bi"><span id="0182" class="ne li it na b gy nf ng l nh ni">['train.json', 'sample_submission.csv', 'test.json']</span></pre><p id="e5c4" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">导入您需要的 Keras 包</p><pre class="kp kq kr ks gt mz na nb nc aw nd bi"><span id="e716" class="ne li it na b gy nf ng l nh ni">from keras import Sequential<br/>from keras import optimizers<br/>from keras.preprocessing.sequence import pad_sequences<br/>from keras.models import Sequential,Model<br/>from keras.layers import LSTM, Dense, Bidirectional, Input,Dropout,BatchNormalization,CuDNNLSTM, GRU, CuDNNGRU, Embedding, GlobalMaxPooling1D, GlobalAveragePooling1D, Flatten<br/>from keras import backend as K<br/>from keras.engine.topology import Layer<br/>from keras import initializers, regularizers, constraints<br/>from sklearn.model_selection import KFold, cross_val_score, train_test_split</span></pre><p id="eb4d" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">当然，还要准备好你的数据</p><pre class="kp kq kr ks gt mz na nb nc aw nd bi"><span id="61be" class="ne li it na b gy nf ng l nh ni">train = pd.read_json('../input/train.json')<br/>display(train.shape)</span></pre><p id="8586" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">它会显示</p><pre class="kp kq kr ks gt mz na nb nc aw nd bi"><span id="1127" class="ne li it na b gy nf ng l nh ni">(1195, 5)</span></pre><p id="1cfa" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">是的，你有 1195 个数据要处理。</p><p id="8c25" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">让我们看看数据的内部</p><pre class="kp kq kr ks gt mz na nb nc aw nd bi"><span id="feec" class="ne li it na b gy nf ng l nh ni">train.head()</span></pre><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi nj"><img src="../Images/fee5e47698fad48395e109b18b41fe19.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*i58i4JLOlNmKXfHfgVb6ww.jpeg"/></div></div></figure><p id="51d7" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">让我们为训练准备数据。您需要拆分其中的一些进行验证，这样您就可以确保模型能够很好地处理看不见的数据。</p><pre class="kp kq kr ks gt mz na nb nc aw nd bi"><span id="1397" class="ne li it na b gy nf ng l nh ni">train_train, train_val = train_test_split(train, random_state = 42)<br/>xtrain = [k for k in train_train['audio_embedding']]<br/>ytrain = train_train['is_turkey'].values</span><span id="9484" class="ne li it na b gy nk ng l nh ni">xval = [k for k in train_val['audio_embedding']]<br/>yval = train_val['is_turkey'].values</span></pre><p id="a4d0" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">train_test_split 方法默认情况下，将数据按 3:1 分割意味着 75%的数据进入定型集，而剩余的 25%进入验证集。</p><p id="6d0a" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">为了在数据上创建一个标准，让我们用零填充所有音频嵌入，直到它们都具有相同的 10 秒长度。</p><pre class="kp kq kr ks gt mz na nb nc aw nd bi"><span id="1313" class="ne li it na b gy nf ng l nh ni"># Pad the audio features so that all are "10 seconds" long<br/>x_train = pad_sequences(xtrain, maxlen=10)<br/>x_val = pad_sequences(xval, maxlen=10)</span><span id="dd8b" class="ne li it na b gy nk ng l nh ni">y_train = np.asarray(ytrain)<br/>y_val = np.asarray(yval)</span></pre><h1 id="dda6" class="lh li it bd lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me bi translated">让我们创建模型！</h1><pre class="kp kq kr ks gt mz na nb nc aw nd bi"><span id="2cab" class="ne li it na b gy nf ng l nh ni">model = Sequential()<br/>model.add(BatchNormalization(momentum=0.98,input_shape=(10, 128)))<br/>model.add(Bidirectional(CuDNNGRU(128, return_sequences = True)))<br/>model.add(Flatten())<br/>model.add(Dense(1,activation='sigmoid'))<br/>model.compile(loss='binary_crossentropy', optimizer = optimizers.Nadam(lr=0.001), metrics=['accuracy'])<br/>print(model.summary())</span></pre><p id="1806" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">详细情况如下:</p><pre class="kp kq kr ks gt mz na nb nc aw nd bi"><span id="e9dd" class="ne li it na b gy nf ng l nh ni">_________________________________________________________________<br/>Layer (type)                 Output Shape              Param #   <br/>=================================================================<br/>batch_normalization_7 (Batch (None, 10, 128)           512       <br/>_________________________________________________________________<br/>bidirectional_7 (Bidirection (None, 10, 256)           198144    <br/>_________________________________________________________________<br/>flatten_2 (Flatten)          (None, 2560)              0         <br/>_________________________________________________________________<br/>dense_7 (Dense)              (None, 1)                 2561      <br/>=================================================================<br/>Total params: 201,217<br/>Trainable params: 200,961<br/>Non-trainable params: 256<br/>_________________________________________________________________</span></pre><p id="284a" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">看一下这段代码</p><pre class="kp kq kr ks gt mz na nb nc aw nd bi"><span id="a892" class="ne li it na b gy nf ng l nh ni">model.add(Bidirectional(CuDNNGRU(128, return_sequences = True)))</span></pre><p id="d0ed" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">那是什么鬼东西？</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi nl"><img src="../Images/a95c98012d47bec629d2455df939d559.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*tlMuoalz_V0C-k-V"/></div></div><figcaption class="la lb gj gh gi lc ld bd b be z dk">Photo by <a class="ae le" href="https://unsplash.com/@seantookthese?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Sean O.</a> on <a class="ae le" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><p id="1a7f" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">在继续之前，让我们看看美丽的日出。当然也能提神醒脑。哈哈</p><h1 id="7479" class="lh li it bd lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me bi translated">处理音频数据</h1><p id="c25d" class="pw-post-body-paragraph jq jr it js b jt mf jv jw jx mg jz ka kb mh kd ke kf mi kh ki kj mj kl km kn im bi translated">这是你必须知道的事情。音频数据是一系列声波。将一个连接到另一个。</p><p id="c2d0" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">有了这个属性，音频数据基本上就是一个数字序列。</p><p id="da41" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">当然，对于数字，你可以用格鲁的 LSTM</p><p id="92bc" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">这两种算法都非常擅长处理数列。基本上，他们可以保存他们“阅读”的内容，并在处理下一个数字时使用该信息。<strong class="js iu">这种“短期记忆”让他们比其他算法更有优势。</strong></p><p id="8e4c" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">在这个教程中，我用了 GRU</p><p id="6c94" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">让我们回到代码上来</p><pre class="kp kq kr ks gt mz na nb nc aw nd bi"><span id="0b0c" class="ne li it na b gy nf ng l nh ni">model = Sequential()<br/>model.add(BatchNormalization(momentum=0.98,input_shape=(10, 128)))<br/>model.add(Bidirectional(CuDNNGRU(128, return_sequences = True)))<br/>model.add(Flatten())<br/>model.add(Dense(1,activation='sigmoid'))</span></pre><p id="37fe" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">我在 Keras 上创建了一个简单的模型，</p><ol class=""><li id="c989" class="ml mm it js b jt ju jx jy kb mn kf mo kj mp kn mq mr ms mt bi translated">添加 BatchNorm 层以标准化输入数字(音频输入尚未标准化)</li><li id="25df" class="ml mm it js b jt mu jx mv kb mw kf mx kj my kn mq mr ms mt bi translated">添加双向 GRU 来处理输入</li><li id="096c" class="ml mm it js b jt mu jx mv kb mw kf mx kj my kn mq mr ms mt bi translated">拉平结果</li><li id="1ade" class="ml mm it js b jt mu jx mv kb mw kf mx kj my kn mq mr ms mt bi translated">为“对-错”或二元问题创建一个 sigmoid 密集层。</li></ol><h1 id="1d8e" class="lh li it bd lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me bi translated"><strong class="ak">训练时间！</strong></h1><pre class="kp kq kr ks gt mz na nb nc aw nd bi"><span id="3cc0" class="ne li it na b gy nf ng l nh ni">#fit on a portion of the training data, and validate on the rest<br/>from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau</span><span id="7d1b" class="ne li it na b gy nk ng l nh ni">reduce_lr = ReduceLROnPlateau(monitor='val_acc', factor=0.1, patience=2, verbose=1, min_lr=1e-8)</span><span id="be21" class="ne li it na b gy nk ng l nh ni">early_stop = EarlyStopping(monitor='val_loss', verbose=1, patience=20,  restore_best_weights=True)</span><span id="0886" class="ne li it na b gy nk ng l nh ni">history = model.fit(x_train, y_train,batch_size=512, epochs=16,validation_data=[x_val, y_val],verbose = 2,callbacks=[reduce_lr,early_stop])</span></pre><p id="a22d" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">它会显示这个结果</p><pre class="kp kq kr ks gt mz na nb nc aw nd bi"><span id="5683" class="ne li it na b gy nf ng l nh ni">Epoch 16/16<br/> - 0s - loss: 0.1037 - acc: 0.9710 - val_loss: 0.1694 - val_acc: 0.9231</span></pre><p id="65fa" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">它在验证测试中有 92.31%的准确率！厉害！</p><p id="14bd" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">让我们绘制培训历史</p><pre class="kp kq kr ks gt mz na nb nc aw nd bi"><span id="3518" class="ne li it na b gy nf ng l nh ni">def eva_plot(History):<br/>    plt.figure(figsize=(20,10))<br/>    sns.lineplot(range(1, 16+1), History.history['acc'], label='Train Accuracy')<br/>    sns.lineplot(range(1, 16+1), History.history['val_acc'], label='Test Accuracy')<br/>    plt.legend(['train', 'validaiton'], loc='upper left')<br/>    plt.ylabel('accuracy')<br/>    plt.xlabel('epoch')<br/>    plt.show()<br/>    plt.figure(figsize=(20,10))<br/>    sns.lineplot(range(1, 16+1), History.history['loss'], label='Train loss')<br/>    sns.lineplot(range(1, 16+1), History.history['val_loss'], label='Test loss')<br/>    plt.legend(['train', 'validaiton'], loc='upper left')<br/>    plt.ylabel('loss')<br/>    plt.xlabel('epoch')<br/>    plt.show()</span><span id="0668" class="ne li it na b gy nk ng l nh ni">eva_plot(history)</span></pre><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi nm"><img src="../Images/b61d95cea59f0dcf3e33401eae3766ab.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*fwiXha_NUli_pvl_zelFPA.png"/></div></div></figure><p id="250b" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">这个简单的模型实际上可以做一些伟大的事情。我们甚至没有对它做任何优化。</p><p id="d448" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">好吧，如果你想优化，欢迎你来做。</p><p id="bea5" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">虽然，我想做另一种形式的优化。不知道结果如何，何乐而不为。</p><h1 id="8f16" class="lh li it bd lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me bi translated">求关注！</h1><p id="b7c0" class="pw-post-body-paragraph jq jr it js b jt mf jv jw jx mg jz ka kb mh kd ke kf mi kh ki kj mj kl km kn im bi translated">不，我是说，注意力机制。看看下面的图片</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi nn"><img src="../Images/d0f5442844aaa54b5b073e65305a0358.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*9kUOMAPfanClcPFI"/></div></div><figcaption class="la lb gj gh gi lc ld bd b be z dk">Photo by <a class="ae le" href="https://unsplash.com/@zmachacek?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Zdeněk Macháček</a> on <a class="ae le" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><p id="21fb" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">你看到了什么？</p><p id="b820" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">当然，<strong class="js iu">那只鸟</strong></p><p id="34b7" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">而不是图像中的绿色背景。</p><p id="c0c6" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">这就是人类的感知方式。我们想在机器上模拟这个机制。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi no"><img src="../Images/188995c223d8bfc91eb91d055e9e394f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*LMxtoaou2EAkehmdyJjxaA.png"/></div></div><figcaption class="la lb gj gh gi lc ld bd b be z dk"><a class="ae le" href="https://lilianweng.github.io/lil-log/2018/06/24/attention-attention.html" rel="noopener ugc nofollow" target="_blank">Attention! Attention!</a></figcaption></figure><p id="e8b1" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">上图向你展示了注意力机制。这是一种机制，它迫使网络在处理新事物的同时关注某些事物。</p><p id="6ece" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">每一行都意味着一步一步的处理。<strong class="js iu">红色的</strong>字是当前正在处理的字。而蓝色的，越蓝意味着越多的机器关注这个词。</p><p id="b017" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">这将使机器与上下文保持一致。</p><h1 id="058f" class="lh li it bd lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me bi translated">实施</h1><p id="a730" class="pw-post-body-paragraph jq jr it js b jt mf jv jw jx mg jz ka kb mh kd ke kf mi kh ki kj mj kl km kn im bi translated">感谢我们在<a class="ae le" href="https://www.kaggle.com/qqgeogor/keras-lstm-attention-glove840b-lb-0-043" rel="noopener ugc nofollow" target="_blank"> kaggle </a>的朋友，我们可以使用这个令人敬畏的类，</p><pre class="kp kq kr ks gt mz na nb nc aw nd bi"><span id="0c80" class="ne li it na b gy nf ng l nh ni">class Attention(Layer):<br/>    def __init__(self, step_dim,<br/>                 W_regularizer=None, b_regularizer=None,<br/>                 W_constraint=None, b_constraint=None,<br/>                 bias=True, **kwargs):<br/>        self.supports_masking = True<br/>        self.init = initializers.get('glorot_uniform')</span><span id="fe3d" class="ne li it na b gy nk ng l nh ni">self.W_regularizer = regularizers.get(W_regularizer)<br/>        self.b_regularizer = regularizers.get(b_regularizer)</span><span id="42e4" class="ne li it na b gy nk ng l nh ni">self.W_constraint = constraints.get(W_constraint)<br/>        self.b_constraint = constraints.get(b_constraint)</span><span id="5a24" class="ne li it na b gy nk ng l nh ni">self.bias = bias<br/>        self.step_dim = step_dim<br/>        self.features_dim = 0<br/>        super(Attention, self).__init__(**kwargs)</span><span id="c23b" class="ne li it na b gy nk ng l nh ni">    def build(self, input_shape):<br/>        assert len(input_shape) == 3</span><span id="3006" class="ne li it na b gy nk ng l nh ni">        self.W = self.add_weight((input_shape[-1],),<br/>                                 initializer=self.init,<br/>                                 name='{}_W'.format(self.name),<br/>                                 regularizer=self.W_regularizer,<br/>                                 constraint=self.W_constraint)<br/>        self.features_dim = input_shape[-1]</span><span id="8b90" class="ne li it na b gy nk ng l nh ni">        if self.bias:<br/>            self.b = self.add_weight((input_shape[1],),<br/>                                     initializer='zero',<br/>                                     name='{}_b'.format(self.name),<br/>                                     regularizer=self.b_regularizer,<br/>                                     constraint=self.b_constraint)<br/>        else:<br/>            self.b = None</span><span id="2103" class="ne li it na b gy nk ng l nh ni">        self.built = True</span><span id="612f" class="ne li it na b gy nk ng l nh ni">    def compute_mask(self, input, input_mask=None):<br/>        return None</span><span id="a79c" class="ne li it na b gy nk ng l nh ni">    def call(self, x, mask=None):<br/>        features_dim = self.features_dim<br/>        step_dim = self.step_dim</span><span id="b3a9" class="ne li it na b gy nk ng l nh ni">        eij = K.reshape(K.dot(K.reshape(x, (-1, features_dim)),<br/>                        K.reshape(self.W, (features_dim, 1))), (-1, step_dim))</span><span id="49cb" class="ne li it na b gy nk ng l nh ni">        if self.bias:<br/>            eij += self.b</span><span id="139b" class="ne li it na b gy nk ng l nh ni">        eij = K.tanh(eij)</span><span id="bee7" class="ne li it na b gy nk ng l nh ni">        a = K.exp(eij)</span><span id="f0fc" class="ne li it na b gy nk ng l nh ni">        if mask is not None:<br/>            a *= K.cast(mask, K.floatx())</span><span id="639a" class="ne li it na b gy nk ng l nh ni">        a /= K.cast(K.sum(a, axis=1, keepdims=True) + K.epsilon(), K.floatx())</span><span id="8e14" class="ne li it na b gy nk ng l nh ni">        a = K.expand_dims(a)<br/>        weighted_input = x * a<br/>        return K.sum(weighted_input, axis=1)</span><span id="8e8c" class="ne li it na b gy nk ng l nh ni">    def compute_output_shape(self, input_shape):<br/>        return input_shape[0],  self.features_dim</span></pre><p id="9a34" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">不要强迫自己去理解这件事。让我们只是改变我们的模型</p><pre class="kp kq kr ks gt mz na nb nc aw nd bi"><span id="ba4d" class="ne li it na b gy nf ng l nh ni">model = Sequential()<br/>model.add(BatchNormalization(momentum=0.98,input_shape=(10, 128)))<br/>model.add(Bidirectional(CuDNNGRU(128, return_sequences = True)))<br/>model.add(Attention(10))<br/>model.add(Dense(1,activation='sigmoid'))<br/>model.compile(loss='binary_crossentropy', optimizer = optimizers.Nadam(lr=0.001), metrics=['accuracy'])<br/>print(model.summary())</span></pre><p id="20ae" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">改变扁平化层注意。你会看到</p><pre class="kp kq kr ks gt mz na nb nc aw nd bi"><span id="cee6" class="ne li it na b gy nf ng l nh ni">_________________________________________________________________<br/>Layer (type)                 Output Shape              Param #   <br/>=================================================================<br/>batch_normalization_6 (Batch (None, 10, 128)           512       <br/>_________________________________________________________________<br/>bidirectional_6 (Bidirection (None, 10, 256)           198144    <br/>_________________________________________________________________<br/>attention_2 (Attention)      (None, 256)               266       <br/>_________________________________________________________________<br/>dense_6 (Dense)              (None, 1)                 257       <br/>=================================================================<br/>Total params: 199,179<br/>Trainable params: 198,923<br/>Non-trainable params: 256<br/>_________________________________________________________________</span></pre><p id="f4b5" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">它减少了大约 2000 个可训练参数。嗯，这是好事。让我们试试训练</p><h1 id="31d7" class="lh li it bd lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me bi translated">培训 v2</h1><pre class="kp kq kr ks gt mz na nb nc aw nd bi"><span id="841c" class="ne li it na b gy nf ng l nh ni">early_stop = EarlyStopping(monitor='val_loss', verbose=1, patience=20,  restore_best_weights=True)</span><span id="9107" class="ne li it na b gy nk ng l nh ni">model.fit(x_train, y_train,batch_size=512, epochs=16,validation_data=[x_val, y_val],verbose = 2,callbacks=[reduce_lr,early_stop])</span></pre><p id="a8f2" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">现在你得到了:</p><pre class="kp kq kr ks gt mz na nb nc aw nd bi"><span id="92ef" class="ne li it na b gy nf ng l nh ni">Epoch 16/16<br/> - 0s - loss: 0.1037 - acc: 0.9710 - val_loss: 0.1680 - val_acc: 0.9331</span></pre><p id="9bf7" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">耶！1%增长到<strong class="js iu"> 93.31% </strong></p><p id="89f9" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">不多，但肯定是增加了！</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi np"><img src="../Images/e2bf0694fb4c153a640bc8f2b62fc69c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*hjgC-1M8uofYe-FE"/></div></div><figcaption class="la lb gj gh gi lc ld bd b be z dk">Photo by <a class="ae le" href="https://unsplash.com/@wflwong?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Warren Wong</a> on <a class="ae le" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><h1 id="0f87" class="lh li it bd lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me bi translated">结论</h1><p id="8e69" class="pw-post-body-paragraph jq jr it js b jt mf jv jw jx mg jz ka kb mh kd ke kf mi kh ki kj mj kl km kn im bi translated">创建音频数据的深度学习系统非常容易。</p><p id="f4bb" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">你只需要知道怎么做。变得更好，以创造真正的“好吧，谷歌！”。</p><p id="9650" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">去试试吧。当然，你可以尝试教程，并改变你想要的参数或网络。</p><p id="992a" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">祝你好运！</p></div></div>    
</body>
</html>