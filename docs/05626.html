<html>
<head>
<title>MachineX: Data Cleaning with NumPy and Pandas</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">MachineX:使用 NumPy 和 Pandas 进行数据清理</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/machinex-data-cleaning-in-python-ad6fa5ca109e?source=collection_archive---------11-----------------------#2019-08-18">https://towardsdatascience.com/machinex-data-cleaning-in-python-ad6fa5ca109e?source=collection_archive---------11-----------------------#2019-08-18</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><figure class="gl gn jr js jt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi jq"><img src="../Images/c905026c37637c843ffcd65a0546ec21.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*-npohGOGe898vm3a"/></div></div></figure><p id="b0af" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">在这篇博客中，我们将学习如何用 NumPy 和 Pandas 进行<strong class="kd iu">数据清理。</strong></p><p id="f167" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">大多数数据科学家仅将 20%的时间用于实际数据分析，80%的时间用于查找、清理和重组海量数据，这是一种低效的数据策略。</p><p id="6935" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">数据科学家最初被雇佣的原因是开发算法和建立机器学习模型，而这些通常是他们最喜欢的工作部分。然而，在当今的大多数公司中，数据科学家 80%的宝贵时间都花在了查找、清理和重新组织海量数据上。</p><p id="839b" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">如果你刚刚进入这个领域或者计划在这个领域发展你的职业生涯，能够处理杂乱的数据是很重要的，无论这意味着缺少值、不一致的格式、畸形的记录还是无意义的离群值。</p><p id="2d35" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">在本教程中，我们将使用 python 的 NumPy 和 Pandas 库来清理数据，并看看我们可以在多少方面使用它们。</p><p id="0341" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated"><strong class="kd iu">数据集</strong></p><p id="0486" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">我们正在使用一些常见的数据集来探索我们的知识，每个数据集都符合我们正在使用的清洗技术，因此您也可以下载自己的数据集并按照说明进行操作。</p><p id="eefc" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">以下是我们将使用的不同数据集，您可以通过以下链接下载这些数据集，也可以从<a class="ae kz" href="https://github.com/shubham769/Python-data-cleaning" rel="noopener ugc nofollow" target="_blank"> githubRepo </a>直接下载:</p><ul class=""><li id="3f0b" class="la lb it kd b ke kf ki kj km lc kq ld ku le ky lf lg lh li bi translated">BL-Flickr-Images-Book.csv  —包含大英图书馆书籍信息的 csv 文件</li><li id="b359" class="la lb it kd b ke lj ki lk km ll kq lm ku ln ky lf lg lh li bi translated"><a class="ae kz" href="https://github.com/shubham769/Python-data-cleaning/blob/master/olympics.csv" rel="noopener ugc nofollow" target="_blank"> university_towns.txt </a> —包含美国各州大学城名称的文本文件</li><li id="4933" class="la lb it kd b ke lj ki lk km ll kq lm ku ln ky lf lg lh li bi translated"><a class="ae kz" href="https://github.com/shubham769/Python-data-cleaning/blob/master/university_towns.txt" rel="noopener ugc nofollow" target="_blank"> olympics.csv </a> —总结所有国家参加夏季和冬季奥运会的 csv 文件</li></ul><p id="a216" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated"><strong class="kd iu">注意</strong>:我正在使用 Jupyter 笔记本，推荐使用。</p><p id="6123" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">让我们导入所需的模块并开始吧！</p><pre class="lo lp lq lr gt ls lt lu lv aw lw bi"><span id="ac0d" class="lx ly it lt b gy lz ma l mb mc">&gt;&gt;&gt; import pandas as pd<br/>&gt;&gt;&gt; import numpy as np</span></pre><p id="40c6" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">现在，让我们在这两个模块的帮助下开始清理数据。我们导入这两个模块，并指定 pd 和 np 作为对象来使用它们。</p><p id="1638" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated"><strong class="kd iu">删除数据帧中不需要的列</strong></p><p id="4aef" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">为了从数据帧中删除列，Pandas 使用了“<a class="ae kz" href="https://pandas.pydata.org/pandas-docs/version/0.21/generated/pandas.DataFrame.drop.html" rel="noopener ugc nofollow" target="_blank"> drop </a>”函数。Pandas 提供了一种使用<code class="fe md me mf lt b"><a class="ae kz" href="https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.drop.html" rel="noopener ugc nofollow" target="_blank">drop()</a></code>函数从<code class="fe md me mf lt b">DataFrame</code>中删除不需要的列或行的简便方法。让我们看一个简单的例子，我们从一个<code class="fe md me mf lt b">DataFrame</code>中删除了一些列。让我们从 CSV 文件“BL-Flickr-Images-Book.csv”中创建一个<code class="fe md me mf lt b">DataFrame</code>。在下面的例子中，我们传递了一个到<code class="fe md me mf lt b">pd.read_csv</code>的相对路径，这意味着所有的数据集都在我们当前工作目录中名为<code class="fe md me mf lt b">Datasets</code>的文件夹中:</p><pre class="lo lp lq lr gt ls lt lu lv aw lw bi"><span id="f1ac" class="lx ly it lt b gy lz ma l mb mc">&gt;&gt;&gt; dataF = pd.read_csv('Datasets/BL-Flickr-Images-Book.csv')<br/>&gt;&gt;&gt; dataF.head()</span><span id="f215" class="lx ly it lt b gy mg ma l mb mc">Identifier             Edition Statement      Place of Publication  \<br/>0         206                           NaN                    London<br/>1         216                           NaN  London; Virtue &amp; Yorston<br/>2         218                           NaN                    London<br/>3         472                           NaN                    London<br/>4         480  A new edition, revised, etc.                    London</span><span id="5e9c" class="lx ly it lt b gy mg ma l mb mc">Date of Publication              Publisher  \<br/>0         1879 [1878]       S. Tinsley &amp; Co.<br/>1                1868           Virtue &amp; Co.<br/>2                1869  Bradbury, Evans &amp; Co.<br/>3                1851          James Darling<br/>4                1857   Wertheim &amp; Macintosh</span><span id="e58d" class="lx ly it lt b gy mg ma l mb mc">Title     Author  \<br/>0                  Walter Forbes. [A novel.] By A. A      A. A.<br/>1  All for Greed. [A novel. The dedication signed...  A., A. A.<br/>2  Love the Avenger. By the author of “All for Gr...  A., A. A.<br/>3  Welsh Sketches, chiefly ecclesiastical, to the...  A., E. S.<br/>4  [The World in which I live, and my place in it...  A., E. S.</span><span id="4fa1" class="lx ly it lt b gy mg ma l mb mc">Contributors  Corporate Author  \<br/>0                               FORBES, Walter.               NaN<br/>1  BLAZE DE BURY, Marie Pauline Rose - Baroness               NaN<br/>2  BLAZE DE BURY, Marie Pauline Rose - Baroness               NaN<br/>3                   Appleyard, Ernest Silvanus.               NaN<br/>4                           BROOME, John Henry.               NaN</span><span id="6497" class="lx ly it lt b gy mg ma l mb mc">Corporate Contributors Former owner  Engraver Issuance type  \<br/>0                     NaN          NaN       NaN   monographic<br/>1                     NaN          NaN       NaN   monographic<br/>2                     NaN          NaN       NaN   monographic<br/>3                     NaN          NaN       NaN   monographic<br/>4                     NaN          NaN       NaN   monographic</span><span id="4701" class="lx ly it lt b gy mg ma l mb mc">Flickr URL  \<br/>0  http://www.flickr.com/photos/britishlibrary/ta...<br/>1  http://www.flickr.com/photos/britishlibrary/ta...<br/>2  http://www.flickr.com/photos/britishlibrary/ta...<br/>3  http://www.flickr.com/photos/britishlibrary/ta...<br/>4  <a class="ae kz" href="http://www.flickr.com/photos/britishlibrary/ta..." rel="noopener ugc nofollow" target="_blank">http://www.flickr.com/photos/britishlibrary/ta...</a></span><span id="3956" class="lx ly it lt b gy mg ma l mb mc">Shelfmarks<br/>0    British Library HMNTS 12641.b.30.<br/>1    British Library HMNTS 12626.cc.2.<br/>2    British Library HMNTS 12625.dd.1.<br/>3    British Library HMNTS 10369.bbb.15.<br/>4    British Library HMNTS 9007.d.28.</span></pre><p id="376a" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">当我们使用该方法查看前五个条目时，<code class="fe md me mf lt b">head()</code>我们可以看到一些列提供了对图书馆有帮助的辅助信息，但并没有很好地描述书籍本身:<code class="fe md me mf lt b">Edition StatementCorporate Author</code>、<code class="fe md me mf lt b">Corporate Contributors</code>、<code class="fe md me mf lt b">Former owner</code>、<code class="fe md me mf lt b">Engraver</code>、<code class="fe md me mf lt b">Issuance type</code>和<code class="fe md me mf lt b">Shelfmarks</code>。</p><h2 id="679a" class="lx ly it bd mh mi mj dn mk ml mm dp mn km mo mp mq kq mr ms mt ku mu mv mw mx bi translated">删除列</h2><p id="4846" class="pw-post-body-paragraph kb kc it kd b ke my kg kh ki mz kk kl km na ko kp kq nb ks kt ku nc kw kx ky im bi translated">我们可以通过以下方式删除这些列:</p><pre class="lo lp lq lr gt ls lt lu lv aw lw bi"><span id="cd3b" class="lx ly it lt b gy lz ma l mb mc">&gt;&gt;&gt; data_to_drop = ['Edition Statement',<br/>...            'Corporate Author',<br/>...            'Corporate Contributors',<br/>...            'Former owner',<br/>...            'Engraver',<br/>...            'Contributors',<br/>...            'Issuance type',<br/>...            'Shelfmarks']</span><span id="bf2f" class="lx ly it lt b gy mg ma l mb mc">&gt;&gt;&gt; dataF.drop(data_to_drop, inplace=True, axis=1)</span></pre><p id="b62c" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">上面，我们定义了一个列表，其中包含了我们想要删除的所有列的名称。接下来，我们调用对象上的<code class="fe md me mf lt b">drop()</code>函数，将<code class="fe md me mf lt b">inplace</code>参数作为<code class="fe md me mf lt b">True</code>传入，将<code class="fe md me mf lt b">axis</code>参数作为<code class="fe md me mf lt b">1</code>传入。这告诉 Pandas 我们希望直接在我们的对象中进行更改，并且它应该在对象的列中寻找要删除的值。</p><p id="45d6" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">当我们再次检查<code class="fe md me mf lt b">DataFrame</code>时，我们会看到不需要的列已被删除:</p><pre class="lo lp lq lr gt ls lt lu lv aw lw bi"><span id="0dc2" class="lx ly it lt b gy lz ma l mb mc">&gt;&gt;&gt; dataF.head()<br/>   Identifier      Place of Publication Date of Publication  \<br/>0         206                    London         1879 [1878]<br/>1         216  London; Virtue &amp; Yorston                1868<br/>2         218                    London                1869<br/>3         472                    London                1851<br/>4         480                    London                1857</span><span id="210d" class="lx ly it lt b gy mg ma l mb mc">Publisher                                              Title  \<br/>0       S. Tinsley &amp; Co.                  Walter Forbes. [A novel.] By A. A<br/>1           Virtue &amp; Co.  All for Greed. [A novel. The dedication signed...<br/>2  Bradbury, Evans &amp; Co.  Love the Avenger. By the author of “All for Gr...<br/>3          James Darling  Welsh Sketches, chiefly ecclesiastical, to the...<br/>4   Wertheim &amp; Macintosh  [The World in which I live, and my place in it...</span><span id="1641" class="lx ly it lt b gy mg ma l mb mc">Author                                         Flickr URL<br/>0      A. A.  http://www.flickr.com/photos/britishlibrary/ta...<br/>1  A., A. A.  http://www.flickr.com/photos/britishlibrary/ta...<br/>2  A., A. A.  http://www.flickr.com/photos/britishlibrary/ta...<br/>3  A., E. S.  http://www.flickr.com/photos/britishlibrary/ta...<br/>4  A., E. S.  <a class="ae kz" href="http://www.flickr.com/photos/britishlibrary/ta..." rel="noopener ugc nofollow" target="_blank">http://www.flickr.com/photos/britishlibrary/ta...</a></span></pre><h1 id="6f37" class="nd ly it bd mh ne nf ng mk nh ni nj mn nk nl nm mq nn no np mt nq nr ns mw nt bi translated">更改数据帧的索引</h1><p id="0615" class="pw-post-body-paragraph kb kc it kd b ke my kg kh ki mz kk kl km na ko kp kq nb ks kt ku nc kw kx ky im bi translated">Pandas <code class="fe md me mf lt b">Index</code>扩展了 NumPy 数组的功能，允许更多的切片和标记。在许多情况下，使用数据的唯一值标识字段作为索引是很有帮助的。</p><p id="a4ab" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">例如，在上一节使用的数据集中，可以预计当图书管理员搜索记录时，他们可能会输入一本书的唯一标识符(值在<code class="fe md me mf lt b">Identifier</code>列中):</p><pre class="lo lp lq lr gt ls lt lu lv aw lw bi"><span id="2132" class="lx ly it lt b gy lz ma l mb mc">&gt;&gt;&gt; dataF['Identifier'].is_unique<br/>True</span></pre><p id="9a24" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">让我们使用<code class="fe md me mf lt b">set_index</code>用这个列替换现有的索引:</p><pre class="lo lp lq lr gt ls lt lu lv aw lw bi"><span id="de9a" class="lx ly it lt b gy lz ma l mb mc">&gt;&gt;&gt; dataF = dataF.set_index('Identifier')<br/>&gt;&gt;&gt; dataF.head()<br/>                Place of Publication Date of Publication  \<br/>206                           London         1879 [1878]<br/>216         London; Virtue &amp; Yorston                1868<br/>218                           London                1869<br/>472                           London                1851<br/>480                           London                1857</span><span id="6f1a" class="lx ly it lt b gy mg ma l mb mc">Publisher  \<br/>206              S. Tinsley &amp; Co.<br/>216                  Virtue &amp; Co.<br/>218         Bradbury, Evans &amp; Co.<br/>472                 James Darling<br/>480          Wertheim &amp; Macintosh</span><span id="3295" class="lx ly it lt b gy mg ma l mb mc">Title     Author  \<br/>206                         Walter Forbes. [A novel.] By A. A      A. A.<br/>216         All for Greed. [A novel. The dedication signed...  A., A. A.<br/>218         Love the Avenger. By the author of “All for Gr...  A., A. A.<br/>472         Welsh Sketches, chiefly ecclesiastical, to the...  A., E. S.<br/>480         [The World in which I live, and my place in it...  A., E. S.</span><span id="5d47" class="lx ly it lt b gy mg ma l mb mc">Flickr URL<br/>206         http://www.flickr.com/photos/britishlibrary/ta...<br/>216         http://www.flickr.com/photos/britishlibrary/ta...<br/>218         http://www.flickr.com/photos/britishlibrary/ta...<br/>472         http://www.flickr.com/photos/britishlibrary/ta...<br/>480         <a class="ae kz" href="http://www.flickr.com/photos/britishlibrary/ta..." rel="noopener ugc nofollow" target="_blank">http://www.flickr.com/photos/britishlibrary/ta...</a></span></pre><p id="e91b" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">每个记录都可以用<code class="fe md me mf lt b">loc[]</code>访问，它允许我们做<em class="nu">基于标签的索引</em>，这是一个行或记录的标签，不考虑它的位置:</p><pre class="lo lp lq lr gt ls lt lu lv aw lw bi"><span id="2840" class="lx ly it lt b gy lz ma l mb mc">&gt;&gt;&gt; dataF.loc[206]<br/>Place of Publication                                               London<br/>Date of Publication                                           1879 [1878]<br/>Publisher                                                S. Tinsley &amp; Co.<br/>Title                                   Walter Forbes. [A novel.] By A. A<br/>Author                                                              A. A.<br/>Flickr URL              http://www.flickr.com/photos/britishlibrary/ta...<br/>Name: 206, dtype: object</span></pre><p id="6d43" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">换句话说，206 是索引的第一个标签。要通过<em class="nu">位置</em>访问它，我们可以使用<code class="fe md me mf lt b">iloc[0]</code>，它执行基于位置的索引。</p><h1 id="d548" class="nd ly it bd mh ne nf ng mk nh ni nj mn nk nl nm mq nn no np mt nq nr ns mw nt bi translated">整理数据中的字段</h1><p id="c329" class="pw-post-body-paragraph kb kc it kd b ke my kg kh ki mz kk kl km na ko kp kq nb ks kt ku nc kw kx ky im bi translated">到目前为止，我们已经删除了不必要的列，并将<code class="fe md me mf lt b">DataFrame</code>的索引改为更合理的内容。在这一节中，我们将清理特定的列，并将它们转换为统一的格式，以便更好地理解数据集并增强一致性。特别是，我们将清洁<code class="fe md me mf lt b">Date of Publication</code>和<code class="fe md me mf lt b">Place of Publication</code>。</p><p id="b24a" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">经检查，目前所有的数据类型都是<code class="fe md me mf lt b">object</code> <a class="ae kz" href="http://pandas.pydata.org/pandas-docs/stable/basics.html#dtypes" rel="noopener ugc nofollow" target="_blank"> dtype </a>，这大致类似于原生 Python 中的<code class="fe md me mf lt b">str</code>。</p><p id="101e" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">它封装了任何不能作为数字或分类数据的字段。这是有意义的，因为我们处理的数据最初是一堆杂乱的字符串:</p><pre class="lo lp lq lr gt ls lt lu lv aw lw bi"><span id="6585" class="lx ly it lt b gy lz ma l mb mc">&gt;&gt;&gt; dataF.get_dtype_counts() <br/>object    6</span></pre><p id="f944" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">强制使用数字值有意义的一个字段是出版日期，这样我们可以在以后进行计算:</p><pre class="lo lp lq lr gt ls lt lu lv aw lw bi"><span id="b622" class="lx ly it lt b gy lz ma l mb mc">&gt;&gt;&gt; dataF.loc[1905:, 'Date of Publication'].head(10) <br/>Identifier <br/>1905           1888 <br/>1929    1839, 38-54 <br/>2836        [1897?] <br/>2854           1865 <br/>2956        1860-63 <br/>2957           1873 <br/>3017           1866 <br/>3131           1899 <br/>4598           1814 <br/>4884           1820 <br/>Name: Date of Publication, dtype: object</span></pre><p id="215d" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">一本书只能有一个出版日期。因此，我们需要做到以下几点:</p><ul class=""><li id="e1b4" class="la lb it kd b ke kf ki kj km lc kq ld ku le ky lf lg lh li bi translated">删除方括号中的多余日期:1879 [1878]</li><li id="0899" class="la lb it kd b ke lj ki lk km ll kq lm ku ln ky lf lg lh li bi translated">将日期范围转换为它们的“开始日期”，如果有的话:1860–63；1839, 38–54</li><li id="9b7d" class="la lb it kd b ke lj ki lk km ll kq lm ku ln ky lf lg lh li bi translated">完全去掉我们不确定的日期，用 NumPy 的<code class="fe md me mf lt b">NaN</code>:【1897？]</li><li id="be36" class="la lb it kd b ke lj ki lk km ll kq lm ku ln ky lf lg lh li bi translated">将字符串<code class="fe md me mf lt b">nan</code>转换为 NumPy 的<code class="fe md me mf lt b">NaN</code>值</li></ul><p id="3ecf" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">综合这些模式，我们实际上可以利用一个正则表达式来提取出版年份:</p><pre class="lo lp lq lr gt ls lt lu lv aw lw bi"><span id="8ba9" class="lx ly it lt b gy lz ma l mb mc">regex = r'^(\d{4})'</span></pre><p id="c541" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">上面的正则表达式是查找一个字符串开头的任意四位数字。上面是一个<em class="nu">原始字符串</em>(意味着反斜杠不再是转义字符)，这是正则表达式的标准做法。</p><p id="d0b5" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated"><code class="fe md me mf lt b">\d</code>代表任意数字，<code class="fe md me mf lt b">{4}</code>重复此规则四次。<code class="fe md me mf lt b">^</code>字符匹配一个字符串的开头，圆括号表示一个捕获组，这向 Pandas 发出信号，表明我们想要提取正则表达式的这一部分。(我们希望<code class="fe md me mf lt b">^</code>避免<code class="fe md me mf lt b">[</code>从管柱开始的情况。)</p><p id="3fe7" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">让我们看看在数据集上运行这个正则表达式会发生什么:</p><pre class="lo lp lq lr gt ls lt lu lv aw lw bi"><span id="5a03" class="lx ly it lt b gy lz ma l mb mc">&gt;&gt;&gt; extr = dataF['Date of Publication'].str.extract(r'^(\d{4})', expand=False) <br/>&gt;&gt;&gt; extr.head() <br/>Identifier <br/>206    1879 <br/>216    1868 <br/>218    1869 <br/>472    1851 <br/>480    1857 <br/>Name: Date of Publication, dtype: object</span></pre><p id="1bb4" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">不熟悉 regex？你可以在 regex101.com<a class="ae kz" href="https://regex101.com/r/3AJ1Pv/1" rel="noopener ugc nofollow" target="_blank">查看上面</a>的表达式，并在 Python 正则表达式<a class="ae kz" href="https://docs.python.org/3.6/howto/regex.html" rel="noopener ugc nofollow" target="_blank"> HOWTOMakeExpressions </a>阅读更多内容。</p><p id="dabe" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">从技术上讲，这个列仍然有<code class="fe md me mf lt b">object</code> dtype，但是我们可以很容易地用<code class="fe md me mf lt b">pd.to_numeric</code>得到它的数字版本:</p><pre class="lo lp lq lr gt ls lt lu lv aw lw bi"><span id="72a3" class="lx ly it lt b gy lz ma l mb mc">&gt;&gt;&gt; dataF['Date of Publication'] = pd.to_numeric(extr) <br/>&gt;&gt;&gt; dataF['Date of Publication'].dtype dtype('float64')</span></pre><p id="3966" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">这导致大约十分之一的值丢失，对于现在能够对剩余的有效值进行计算来说，这是一个很小的代价:</p><pre class="lo lp lq lr gt ls lt lu lv aw lw bi"><span id="bf8d" class="lx ly it lt b gy lz ma l mb mc">&gt;&gt;&gt; dataF['Date of Publication'].isnull().sum() / len(dataF) 0.11717147339205986</span></pre><p id="e78a" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">太好了！搞定了。！！！</p><h1 id="dabf" class="nd ly it bd mh ne nf ng mk nh ni nj mn nk nl nm mq nn no np mt nq nr ns mw nt bi translated">使用 applymap 函数清理整个数据集</h1><p id="e34b" class="pw-post-body-paragraph kb kc it kd b ke my kg kh ki mz kk kl km na ko kp kq nb ks kt ku nc kw kx ky im bi translated">在某些情况下，将定制函数应用于数据帧的每个单元格或元素会很有帮助。Pandas <code class="fe md me mf lt b">.applymap()</code>方法类似于内置的<code class="fe md me mf lt b">map()</code>函数，只是将一个函数应用于<code class="fe md me mf lt b">DataFrame</code>中的所有元素。</p><p id="34dc" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">我们将从“university_towns.txt”文件中创建一个<code class="fe md me mf lt b">DataFrame</code>:</p><pre class="lo lp lq lr gt ls lt lu lv aw lw bi"><span id="18ce" class="lx ly it lt b gy lz ma l mb mc">&gt;&gt;&gt; head Datasets/univerisity_towns.txt<br/>Alabama[edit]<br/>Auburn (Auburn University)[1]<br/>Florence (University of North Alabama)<br/>Jacksonville (Jacksonville State University)[2]<br/>Livingston (University of West Alabama)[2]<br/>Montevallo (University of Montevallo)[2]<br/>Troy (Troy University)[2]<br/>Tuscaloosa (University of Alabama, Stillman College, Shelton State)[3][4]<br/>Tuskegee (Tuskegee University)[5]<br/>Alaska[edit]</span></pre><p id="7512" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">我们看到，我们有周期性的州名，后跟该州的大学城:<code class="fe md me mf lt b">StateA TownA1 TownA2 StateB TownB1 TownB2...</code>。如果我们观察状态名在文件中的书写方式，我们会发现所有的状态名中都有“[edit]”子字符串。</p><p id="547b" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">我们可以通过创建一个 <code class="fe md me mf lt b"><em class="nu">(state, city)</em></code> <em class="nu">元组</em>的<em class="nu">列表并将该列表包装在<code class="fe md me mf lt b">DataFrame</code>中来利用这种模式</em></p><pre class="lo lp lq lr gt ls lt lu lv aw lw bi"><span id="8b02" class="lx ly it lt b gy lz ma l mb mc">&gt;&gt;&gt; university_towns = []<br/>&gt;&gt;&gt; with open('Datasets/university_towns.txt') as file:<br/>...     for line in file:<br/>...         if '[edit]' in line:<br/>...             # Remember this `state` until the next is found<br/>...             state = line<br/>...         else:<br/>...             # Otherwise, we have a city; keep `state` as last-seen<br/>...             university_towns.append((state, line))</span><span id="b190" class="lx ly it lt b gy mg ma l mb mc">&gt;&gt;&gt; university_towns[:5]<br/>[('Alabama[edit]\n', 'Auburn (Auburn University)[1]\n'),<br/> ('Alabama[edit]\n', 'Florence (University of North Alabama)\n'),<br/> ('Alabama[edit]\n', 'Jacksonville (Jacksonville State University)[2]\n'),<br/> ('Alabama[edit]\n', 'Livingston (University of West Alabama)[2]\n'),<br/> ('Alabama[edit]\n', 'Montevallo (University of Montevallo)[2]\n')]</span></pre><p id="a7f8" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">我们可以将这个列表包装在一个 DataFrame 中，并将列设置为“State”和“RegionName”。Pandas 将获取列表中的每个元素，并将<code class="fe md me mf lt b">State</code>设置为左边的值，将<code class="fe md me mf lt b">RegionName</code>设置为右边的值。</p><pre class="lo lp lq lr gt ls lt lu lv aw lw bi"><span id="a523" class="lx ly it lt b gy lz ma l mb mc">&gt;&gt;&gt; towns_dataF = pd.DataFrame(university_towns,<br/>...                         columns=['State', 'RegionName'])</span><span id="a724" class="lx ly it lt b gy mg ma l mb mc">&gt;&gt;&gt; towns_dataF.head()<br/> State                                         RegionName<br/>0  Alabama[edit]\n                    Auburn (Auburn University)[1]\n<br/>1  Alabama[edit]\n           Florence (University of North Alabama)\n<br/>2  Alabama[edit]\n  Jacksonville (Jacksonville State University)[2]\n<br/>3  Alabama[edit]\n       Livingston (University of West Alabama)[2]\n<br/>4  Alabama[edit]\n         Montevallo (University of Montevallo)[2]\n</span></pre><h1 id="96fe" class="nd ly it bd mh ne nf ng mk nh ni nj mn nk nl nm mq nn no np mt nq nr ns mw nt bi translated"><code class="fe md me mf lt b">applymap()</code></h1><p id="0b18" class="pw-post-body-paragraph kb kc it kd b ke my kg kh ki mz kk kl km na ko kp kq nb ks kt ku nc kw kx ky im bi translated">虽然我们可以在上面的 for 循环中清理这些字符串，但 Pandas 让它变得很容易。我们只需要州名和镇名，其他的都可以去掉。虽然我们可以在这里再次使用 Pandas 的<code class="fe md me mf lt b">.str()</code>方法，但是我们也可以使用<code class="fe md me mf lt b">applymap()</code>将 Python callable 映射到 DataFrame 的每个元素。</p><p id="c19e" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">我们一直在使用术语<em class="nu">元素</em>，但是它到底是什么意思呢？考虑以下“玩具”数据帧:</p><pre class="lo lp lq lr gt ls lt lu lv aw lw bi"><span id="d946" class="lx ly it lt b gy lz ma l mb mc">0           1<br/>0    Mock     Dataset<br/>1  Python     Pandas<br/>2    Real     Python<br/>3   NumPy     Clean</span></pre><p id="97fc" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">在这个例子中，每个单元格(' Mock '，' Dataset '，' Python '，' Pandas '等)。)是一个元素。因此，<code class="fe md me mf lt b">applymap()</code>将独立地对其中的每一个应用一个函数。让我们来定义这个函数:</p><pre class="lo lp lq lr gt ls lt lu lv aw lw bi"><span id="2388" class="lx ly it lt b gy lz ma l mb mc">&gt;&gt;&gt; def get_citystate(item): <br/>...     if ' (' in item: <br/>...         return item[:item.find(' (')] <br/>...     elif '[' in item: <br/>...         return item[:item.find('[')] <br/>...     else: <br/>...         return item</span></pre><p id="b733" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">Pandas 的<code class="fe md me mf lt b">.applymap()</code>只有一个参数，它是应该应用于每个元素的函数(可调用的):</p><pre class="lo lp lq lr gt ls lt lu lv aw lw bi"><span id="e197" class="lx ly it lt b gy lz ma l mb mc">&gt;&gt;&gt; towns_dataF =  towns_dataF.applymap(get_citystate)</span></pre><p id="5338" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">首先，我们定义一个 Python 函数，它将来自<code class="fe md me mf lt b">DataFrame</code>的一个元素作为它的参数。在函数内部，执行检查以确定元素中是否有<code class="fe md me mf lt b">(</code>或<code class="fe md me mf lt b">[</code>。</p><p id="cff7" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">函数根据检查相应地返回值。最后，在我们的对象上调用<code class="fe md me mf lt b">applymap()</code>函数。现在数据框架更加整洁了:</p><pre class="lo lp lq lr gt ls lt lu lv aw lw bi"><span id="7929" class="lx ly it lt b gy lz ma l mb mc">&gt;&gt;&gt; towns_dataF.head()      <br/>State    RegionName <br/>0  Alabama        Auburn <br/>1  Alabama      Florence <br/>2  Alabama  Jacksonville <br/>3  Alabama    Livingston <br/>4  Alabama    Montevallo</span></pre><p id="38e5" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">方法<code class="fe md me mf lt b">applymap()</code>从 DataFrame 中取出每个元素，将其传递给函数，原始值被返回值替换。就这么简单！</p><p id="1f0f" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">快乐学习！！！！！！！！！</p><p id="48b9" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">请查看下面的链接，找到对您的 Python 数据科学之旅有所帮助的其他资源:</p><ul class=""><li id="67ad" class="la lb it kd b ke kf ki kj km lc kq ld ku le ky lf lg lh li bi translated">熊猫<a class="ae kz" href="https://pandas.pydata.org/pandas-docs/stable/index.html" rel="noopener ugc nofollow" target="_blank">文档</a></li><li id="2d57" class="la lb it kd b ke lj ki lk km ll kq lm ku ln ky lf lg lh li bi translated">NumPy <a class="ae kz" href="https://docs.scipy.org/doc/numpy/reference/" rel="noopener ugc nofollow" target="_blank">文档</a></li><li id="48a9" class="la lb it kd b ke lj ki lk km ll kq lm ku ln ky lf lg lh li bi translated">熊猫的创造者韦斯·麦金尼<a class="ae kz" href="https://realpython.com/asins/1491957662/" rel="noopener ugc nofollow" target="_blank">用于数据分析的 Python</a></li><li id="6ec2" class="la lb it kd b ke lj ki lk km ll kq lm ku ln ky lf lg lh li bi translated"><a class="ae kz" href="https://realpython.com/asins/B06W2LXLQK/" rel="noopener ugc nofollow" target="_blank">数据科学培训师兼顾问 Ted Petrou 撰写的熊猫食谱</a></li></ul><p id="a804" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated"><strong class="kd iu">参考资料:</strong><br/><a class="ae kz" href="https://realpython.com/python-data-cleaning-numpy-pandas/#tidying-up-fields-in-the-data" rel="noopener ugc nofollow" target="_blank">realPython.com</a><br/><a class="ae kz" href="https://www.dataquest.io/blog/data-cleaning-with-python/" rel="noopener ugc nofollow" target="_blank">data quest . io</a></p><p id="d497" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated"><strong class="kd iu">注</strong>:原发布于-&gt;<a class="ae kz" href="https://blog.knoldus.com/machine-x-data-cleaning-in-python/" rel="noopener ugc nofollow" target="_blank">https://blog.knoldus.com/machine-x-data-cleaning-in-python/</a></p></div></div>    
</body>
</html>