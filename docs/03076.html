<html>
<head>
<title>An Inutitive Understanding to Fader Networks</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">对衰减器网络的虚拟理解</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/an-inutitive-understanding-to-fader-networks-a8fb7c7901a4?source=collection_archive---------15-----------------------#2019-05-17">https://towardsdatascience.com/an-inutitive-understanding-to-fader-networks-a8fb7c7901a4?source=collection_archive---------15-----------------------#2019-05-17</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="66c1" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">推子网络是一种神经网络，可以让您控制数据项的一组属性</h2></div><p id="66db" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在这篇博客中，我们将讨论控制图像属性的推子网络，因为它们是最容易理解的。</p><div class="le lf gp gr lg lh"><a href="https://arxiv.org/abs/1706.00409" rel="noopener  ugc nofollow" target="_blank"><div class="li ab fo"><div class="lj ab lk cl cj ll"><h2 class="bd iu gy z fp lm fr fs ln fu fw is bi translated">推子网络:通过滑动属性操纵图像</h2><div class="lo l"><h3 class="bd b gy z fp lm fr fs ln fu fw dk translated">本文介绍了一种新的编码器-解码器结构，它通过对图像进行解纠缠来重建图像</h3></div><div class="lp l"><p class="bd b dl z fp lm fr fs ln fu fw dk translated">arxiv.org</p></div></div></div></a></div><figure class="lr ls lt lu gt lv gh gi paragraph-image"><div role="button" tabindex="0" class="lw lx di ly bf lz"><div class="gh gi lq"><img src="../Images/20d2d69bf3d9efcb9d4f556942d87d3d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*fzNMKDu6z_tRkjq4pnillA.png"/></div></div><figcaption class="mc md gj gh gi me mf bd b be z dk">The left images are the originals. Here we are controlling for the binary attributes of “age (young/old)” and “gender (male/female)”. Image from the <a class="ae mg" href="https://arxiv.org/abs/1706.00409" rel="noopener ugc nofollow" target="_blank">fader network paper</a>.</figcaption></figure><blockquote class="mh mi mj"><p id="1813" class="ki kj mk kk b kl km ju kn ko kp jx kq ml ks kt ku mm kw kx ky mn la lb lc ld im bi translated">我们假设你对神经网络有基本的了解</p></blockquote><h2 id="3440" class="mo mp it bd mq mr ms dn mt mu mv dp mw kr mx my mz kv na nb nc kz nd ne nf ng bi translated">衰减器网络是自动编码器的变体</h2><p id="0f41" class="pw-post-body-paragraph ki kj it kk b kl nh ju kn ko ni jx kq kr nj kt ku kv nk kx ky kz nl lb lc ld im bi translated">为了理解推子网络，我们将简要介绍一下自动编码器。</p><blockquote class="nm"><p id="1e7b" class="nn no it bd np nq nr ns nt nu nv ld dk translated">自动编码器(AE)是一种神经网络，用于在更小的维度空间中表示数据</p></blockquote><figure class="nx ny nz oa ob lv gh gi paragraph-image"><div class="gh gi nw"><img src="../Images/665ad2f814e509349cfa8851f0425d8b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1354/format:webp/1*wKE69-fX180Q_gkzYzGbwg.png"/></div><figcaption class="mc md gj gh gi me mf bd b be z dk">An autoencoder is a neural network that learns how to compress data into a smaller space. Source: <a class="ae mg" href="https://en.wikipedia.org/wiki/Autoencoder" rel="noopener ugc nofollow" target="_blank">Wikipedia</a></figcaption></figure><p id="d6ce" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">自动编码器由两个主要部分组成，<strong class="kk iu">编码器</strong>和<strong class="kk iu">解码器</strong>。</p><ul class=""><li id="4977" class="oc od it kk b kl km ko kp kr oe kv of kz og ld oh oi oj ok bi translated"><em class="mk">编码器</em>是一个神经网络，它学习将图像映射到一个更小的维度空间，称为<strong class="kk iu">潜在空间</strong>(在上图中，他们称之为代码)。一个图像在潜在空间中的点被称为它的潜在表示。</li><li id="203b" class="oc od it kk b kl ol ko om kr on kv oo kz op ld oh oi oj ok bi translated"><em class="mk">解码器</em>通过仅从潜在空间获取对应点来学习重建原始图像。</li><li id="8571" class="oc od it kk b kl ol ko om kr on kv oo kz op ld oh oi oj ok bi translated">自动编码器的<em class="mk">损失函数</em>就是重建误差(即像素值的均方误差)</li></ul><p id="b998" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">关于自动编码器的更详细的解释，请看这个<a class="ae mg" rel="noopener" target="_blank" href="/applied-deep-learning-part-3-autoencoders-1c083af4d798">博客</a>。</p><h2 id="3452" class="mo mp it bd mq mr ms dn mt mu mv dp mw kr mx my mz kv na nb nc kz nd ne nf ng bi translated">推子网络是如何修改自动编码器的</h2><p id="14ae" class="pw-post-body-paragraph ki kj it kk b kl nh ju kn ko ni jx kq kr nj kt ku kv nk kx ky kz nl lb lc ld im bi translated">为了理解推子网络，让我们使用在人脸数据集上训练的自动编码器，<a class="ae mg" href="http://mmlab.ie.cuhk.edu.hk/projects/CelebA.html" rel="noopener ugc nofollow" target="_blank"> CelebA </a>，其潜在空间维度为 2。我们想要控制性别属性。假设 0 表示男性，1 表示女性。训练之后，我们可以期望编码器像这样映射人脸。</p><figure class="lr ls lt lu gt lv gh gi paragraph-image"><div role="button" tabindex="0" class="lw lx di ly bf lz"><div class="gh gi oq"><img src="../Images/d6ad10670d5b6a7ed929d6059d20c32d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*0IUXa3mInX7NFHYs0w5isg.png"/></div></div><figcaption class="mc md gj gh gi me mf bd b be z dk">An autoencoder with a 2-dimensional latent space on faces. We can expect the encoder to map the males and females to disjoint regions of the latent space so that the decoder can correctly reconstruct their genders</figcaption></figure><p id="f82a" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在高层次上，每个性别占据了潜在空间的一个不相交的区域，使得解码器可以容易地学习用正确的性别重建面部。</p><p id="44e4" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">这是推子网络的不同之处。</p><figure class="lr ls lt lu gt lv gh gi paragraph-image"><div role="button" tabindex="0" class="lw lx di ly bf lz"><div class="gh gi or"><img src="../Images/f98b83317840b2b32d07192a64b7d3d0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*CGSbkVHoqcxG6Aw-TZhCLA.png"/></div></div><figcaption class="mc md gj gh gi me mf bd b be z dk">A fader network is jut like an autoencoder except that the decoder takes in some attributes and the discriminator penalizes for any encodings of those attributes in the latent space</figcaption></figure><blockquote class="nm"><p id="5909" class="nn no it bd np nq os ot ou ov ow ld dk translated">我们强制衰减器网络的解码器使用图像的给定属性，以及潜在表示来重建图像</p></blockquote><p id="7b47" class="pw-post-body-paragraph ki kj it kk b kl ox ju kn ko oy jx kq kr oz kt ku kv pa kx ky kz pb lb lc ld im bi translated">推子网络是一个自动编码器，除了我们馈入解码器，不仅是潜在的表现，还有我们想要控制的图像属性。</p><blockquote class="nm"><p id="4f3c" class="nn no it bd np nq nr ns nt nu nv ld dk translated">为了迫使解码器使用给定的属性进行重构，我们必须破坏潜在空间中关于属性的所有信息。</p></blockquote><p id="a158" class="pw-post-body-paragraph ki kj it kk b kl ox ju kn ko oy jx kq kr oz kt ku kv pa kx ky kz pb lb lc ld im bi translated">在我们的例子中，给定了潜在空间中的一个点，我不应该能够说出这张脸的性别。通过破坏潜在空间中关于性别的任何信息，解码器被迫使用我们提供给它的给定属性来重建具有正确性别的图像。</p><p id="6b06" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">为了破坏潜在空间中的属性，衰减器网络在其潜在空间上引入了鉴别器。这种鉴别器试图仅从图像的潜在表示中学习图像的属性。在我们的例子中，鉴别者试图从 2-D 潜在空间中学习图像的性别。在它被训练之后，通过惩罚潜在空间中属性的任何编码，它充当自动编码器的损失函数。</p><p id="6e97" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">经过大量的训练后，我们希望看到鉴别器的表现不比随机猜测好，因为这表明我们已经成功地销毁了潜在空间中关于属性的所有信息。</p><p id="0d07" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">通过完全训练的衰减器网络，我们可以通过改变属性值来控制重建图像的属性。在我们的例子中，我们可以在 0 和 1(男性和女性)之间滑动我们的性别属性，我们将看到男性和女性之间的人脸插值。</p><p id="b342" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我们可以训练推子网络来控制多个属性，但随着我们想要控制的属性数量的增加，我们得到的重建和真实感质量会降低。</p><figure class="lr ls lt lu gt lv gh gi paragraph-image"><div role="button" tabindex="0" class="lw lx di ly bf lz"><div class="gh gi pc"><img src="../Images/a52378ee3b0a1c65ba1a97ca46d04797.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*T8sPOJlFA9atOaeLflEsPQ.png"/></div></div><figcaption class="mc md gj gh gi me mf bd b be z dk">The left images are the originals. Here we are simultaneously controlling for the binary attributes of “opened eyes”, “glasses”, and “gender”. Image from the <a class="ae mg" href="https://arxiv.org/abs/1706.00409" rel="noopener ugc nofollow" target="_blank">fader network paper</a></figcaption></figure><h2 id="ed84" class="mo mp it bd mq mr ms dn mt mu mv dp mw kr mx my mz kv na nb nc kz nd ne nf ng bi translated">高级训练算法</h2><p id="eb18" class="pw-post-body-paragraph ki kj it kk b kl nh ju kn ko ni jx kq kr nj kt ku kv nk kx ky kz nl lb lc ld im bi translated">回想一下，自动编码器的损失函数就是重建损失。在衰减器网络中，<strong class="kk iu">总损失函数</strong>是重构损失<em class="mk">和</em>鉴别器损失的加权和(鉴别器损失的较高值表明鉴别器可以容易地从潜在空间辨别属性)。</p><p id="ac33" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">正如在大多数 ML 培训课程中一样，可以使用随机梯度下降来优化推子网络。</p><p id="b2e1" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><em class="mk">开始时，将鉴别器损失的权重设置为 0，这样自动编码器可以首先获得良好的重建效果</em></p><p id="45cc" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">对于给定的一批图像…</p><figure class="lr ls lt lu gt lv gh gi paragraph-image"><div role="button" tabindex="0" class="lw lx di ly bf lz"><div class="gh gi pd"><img src="../Images/5b4ae07d46f88fe9a0b938feb4056919.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Z78Ws6cZwMn8-oRCCPRlRQ.png"/></div></div><figcaption class="mc md gj gh gi me mf bd b be z dk">We alternatively train the discriminator and autoencoder within a batch of data. When we train the autoencoder, we are optimizing over a weighted sum of the discriminator loss (cross entopy) and the reconstruction loss (MSE). Overtime, we increase the weight of the discriminator loss to encourage disentaglement of the attributes from the latent space.</figcaption></figure><ol class=""><li id="cfc6" class="oc od it kk b kl km ko kp kr oe kv of kz og ld pe oi oj ok bi translated">通过编码器输入批次，并在此潜在表示上优化鉴别器</li><li id="4d32" class="oc od it kk b kl ol ko om kr on kv oo kz op ld pe oi oj ok bi translated">将批次通过自动编码器和新优化的鉴别器，并计算总损耗(鉴别器损耗和重建损耗的加权和)。针对这一总损失优化自动编码器(编码器和解码器)</li><li id="e61b" class="oc od it kk b kl ol ko om kr on kv oo kz op ld pe oi oj ok bi translated">重复第 1 步和第 2 步，同时缓慢增加总损失函数中鉴频器损失的权重。</li></ol><p id="cee4" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">随着我们增加鉴别器损失的权重，性别属性开始越来越多地从潜在空间中消失，这逐渐迫使鉴别器在重建期间使用给定的性别属性。</p><h2 id="32fe" class="mo mp it bd mq mr ms dn mt mu mv dp mw kr mx my mz kv na nb nc kz nd ne nf ng bi translated">履行</h2><blockquote class="nm"><p id="43a9" class="nn no it bd np nq nr ns nt nu nv ld dk translated"><a class="ae mg" href="https://colab.research.google.com/drive/1o6iHyHisEwD-rV1UXaWx7FR1KjxKv0L-" rel="noopener ugc nofollow" target="_blank"> MNIST 推子网络笔记本</a></p></blockquote><figure class="nx ny nz oa ob lv gh gi paragraph-image"><div class="gh gi pf"><img src="../Images/e64fbd22b60be91c6ae7f1e81d644cf1.png" data-original-src="https://miro.medium.com/v2/resize:fit:744/format:webp/1*RRBgrdk18pDogQMmbrxBEA.png"/></div></figure><figure class="lr ls lt lu gt lv gh gi paragraph-image"><div class="gh gi pf"><img src="../Images/9807457b272739eb9fc51561fcc4b16f.png" data-original-src="https://miro.medium.com/v2/resize:fit:744/format:webp/1*zPEP5LCmM59OvM_ItOQdzw.png"/></div></figure><figure class="lr ls lt lu gt lv gh gi paragraph-image"><div class="gh gi pf"><img src="../Images/6372e081f615d3b6bf24955583f683e1.png" data-original-src="https://miro.medium.com/v2/resize:fit:744/format:webp/1*eD_c-XCYPNk-EJm_20F2yA.png"/></div></figure><figure class="lr ls lt lu gt lv gh gi paragraph-image"><div class="gh gi pg"><img src="../Images/12c4ca40f1b98e90b249b3e031ff808a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1098/format:webp/1*R_rwFlleBqUqERX2DZpDvw.png"/></div></figure><p id="2a26" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我在手写数字数据集 MNIST 上使用 Google Colab 实现了一个推子网络。我们控制的属性是图像的数字值。编码器和解码器分别是卷积和反卷积神经网络。鉴别器是一个简单的多层感知器，它为数字值输出一个 10 维概率向量。我们将鉴频器损耗计算为鉴频器输出和数字值的一键编码之间的交叉熵。重建损失是像素值之间的均方误差。回想一下，总损耗是重建损耗和鉴别器损耗的加权和。重建损失的权重总是 1。鉴别器损耗的权重从 0 开始，在每个时期后增加 3，在 15 结束。训练 50 个纪元大概需要 10 分钟。训练后，我们演示了一个渐变到另一个随机选择的数字。</p></div></div>    
</body>
</html>