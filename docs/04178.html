<html>
<head>
<title>Feature Elimination Using SVM Weights</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用 SVM 权重的特征消除</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/feature-elimination-using-svm-weights-c287c16a5151?source=collection_archive---------23-----------------------#2019-06-30">https://towardsdatascience.com/feature-elimination-using-svm-weights-c287c16a5151?source=collection_archive---------23-----------------------#2019-06-30</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="26e2" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">特别是对于 SVMLight，但是这种特征消除方法可以用于任何线性 SVM。</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ki"><img src="../Images/cfb32f2baee215226dd37128a26e90fd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1054/format:webp/1*P2yQCnQNh9Lw7RQvEb0aoA.png"/></div><figcaption class="kq kr gj gh gi ks kt bd b be z dk">Figure 1: a random example of accuracy based on the number of SVM features used.</figcaption></figure><p id="1b54" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">大约在 2005 年至 2007 年，我在写硕士论文时，不得不根据 SVM 模型计算特征权重。这是在 2007 年开始的 SKlearn 之前。这个想法是基于算法认为影响最小的特征来迭代地删除冗余特征，看看我们可以在不牺牲性能的情况下删除多少。今天，您可以在 SKlearn 和其他包中轻松地选择这些类型的特性，但是，如果您坚持使用 SVMLight，您可以使用下面的代码。总的来说，这种方法今天仍然有效。</p><p id="e414" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">当时我们有两个选择，SVMLight 或者 LibSVM。我选择了 SMLight。Thorsten Joachims 发布了一个 Perl 脚本来计算 SVM 重量，但我使用的是 python，我用 Python 重写了他的脚本，他还在他的网站上放了一个<a class="ae lq" href="http://www.cs.cornell.edu/people/tj/svm_light/svm2weight.py.txt" rel="noopener ugc nofollow" target="_blank">下载链接</a>。</p><p id="b5ca" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">可以在这里找到 Perl 脚本原文:<a class="ae lq" href="http://www.cs.cornell.edu/people/tj/svm_light/svm_light_faq.html" rel="noopener ugc nofollow" target="_blank">http://www . cs . Cornell . edu/people/TJ/SVM _ light/SVM _ light _ FAQ . html<br/></a>和 Python 脚本:<a class="ae lq" href="http://www.cs.cornell.edu/people/tj/svm_light/svm2weight.py.txt" rel="noopener ugc nofollow" target="_blank">http://www . cs . Cornell . edu/people/TJ/SVM _ light/SVM 2 weight . py . txt</a></p><p id="aa25" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">使用该脚本将获得所有要素的权重。这在以后非常有用，正如您在下面的伪代码中看到的，您可以系统地消除功能:</p><ol class=""><li id="419d" class="lr ls it kw b kx ky la lb ld lt lh lu ll lv lp lw lx ly lz bi translated">K = 50%</li><li id="efe6" class="lr ls it kw b kx ma la mb ld mc lh md ll me lp lw lx ly lz bi translated">在对所有当前特征进行训练之后，选择具有最高 SVM 权重 s 的 K 个特征和具有最低(最负)SVM 权重的 K 个特征</li><li id="4bb2" class="lr ls it kw b kx ma la mb ld mc lh md ll me lp lw lx ly lz bi translated">再培训</li><li id="f31e" class="lr ls it kw b kx ma la mb ld mc lh md ll me lp lw lx ly lz bi translated">基于看不见的数据集测量准确性</li><li id="4348" class="lr ls it kw b kx ma la mb ld mc lh md ll me lp lw lx ly lz bi translated">迭代:转到 2。当没有更多功能可供选择时停止。</li><li id="7da8" class="lr ls it kw b kx ma la mb ld mc lh md ll me lp lw lx ly lz bi translated">选择如图 1 所示的最佳“弯头”。在本例中，重点是 128 个特征允许您获得与所有特征相同的精度。</li></ol><p id="6474" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated"><strong class="kw iu">您会注意到，仅使用您的特征子集就可以获得更高的预测结果。这是特征选择的本质。</strong></p><pre class="kj kk kl km gt mf mg mh mi aw mj bi"><span id="2544" class="mk ml it mg b gy mm mn l mo mp"># Compute the weight vector of linear SVM based on the model file<br/># Original Perl Author: Thorsten Joachims (thorsten@joachims.org)<br/># Python Version: Dr. Ori Cohen (orioric@gmail.com)<br/># Call: python svm2weights.py svm_model</span><span id="8351" class="mk ml it mg b gy mq mn l mo mp">import sys<br/>from operator import itemgetter</span><span id="f5e2" class="mk ml it mg b gy mq mn l mo mp">try:<br/>    import psyco<br/>    psyco.full()<br/>except ImportError:<br/>    print 'Psyco not installed, the program will just run slower'</span><span id="d739" class="mk ml it mg b gy mq mn l mo mp">def sortbyvalue(d,reverse=True):<br/>    ''' proposed in PEP 265, using  the itemgetter this function sorts a dictionary'''<br/>    return sorted(d.iteritems(), key=itemgetter(1), reverse=True)</span><span id="c159" class="mk ml it mg b gy mq mn l mo mp">def sortbykey(d,reverse=True):<br/>    ''' proposed in PEP 265, using  the itemgetter this function sorts a dictionary'''<br/>    return sorted(d.iteritems(), key=itemgetter(0), reverse=False)</span><span id="2444" class="mk ml it mg b gy mq mn l mo mp">def get_file():<br/>    """<br/>    Tries to extract a filename from the command line.  If none is present, it<br/>    assumes file to be svm_model (default svmLight output).  If the file<br/>    exists, it returns it, otherwise it prints an error message and ends<br/>    execution.<br/>    """<br/>    # Get the name of the data file and load it into<br/>    if len(sys.argv) &lt; 2:<br/>        # assume file to be svm_model (default svmLight output)<br/>        print "Assuming file as svm_model"<br/>        filename = 'svm_model'<br/>        #filename = sys.stdin.readline().strip()<br/>    else:<br/>        filename = sys.argv[1]</span><span id="3a5d" class="mk ml it mg b gy mq mn l mo mp">    try:<br/>        f = open(filename, "r")<br/>    except IOError:<br/>        print "Error: The file '%s' was not found on this system." % filename<br/>        sys.exit(0)</span><span id="cd69" class="mk ml it mg b gy mq mn l mo mp">    return f</span><span id="eca7" class="mk ml it mg b gy mq mn l mo mp">if __name__ == "__main__":<br/>    f = get_file()<br/>    i=0<br/>    lines = f.readlines()<br/>    printOutput = True<br/>    w = {}<br/>    for line in lines:<br/>        if i&gt;10:<br/>            features = line[:line.find('#')-1]<br/>            comments = line[line.find('#'):]<br/>            alpha = features[:features.find(' ')]<br/>            feat = features[features.find(' ')+1:]<br/>            for p in feat.split(' '): # Changed the code here.<br/>                a,v = p.split(':')<br/>                if not (int(a) in w):<br/>                    w[int(a)] = 0<br/>            for p in feat.split(' '):<br/>                a,v = p.split(':')<br/>                w[int(a)] +=float(alpha)*float(v)<br/>        elif i==1:<br/>            if line.find('0')==-1:<br/>                print 'Not linear Kernel!\n'<br/>                printOutput = False<br/>                break<br/>        elif i==10:<br/>            if line.find('threshold b')==-1:<br/>                print "Parsing error!\n"<br/>                printOutput = False<br/>                break</span><span id="92ce" class="mk ml it mg b gy mq mn l mo mp">        i+=1<br/>    f.close()</span><span id="22d2" class="mk ml it mg b gy mq mn l mo mp">    #if you need to sort the features by value and not by feature ID then use this line intead:<br/>    #ws = sortbyvalue(w) </span><span id="f97d" class="mk ml it mg b gy mq mn l mo mp">    ws = sortbykey(w)<br/>    if printOutput == True:<br/>        for (i,j) in ws:<br/>            print i,':',j<br/>            i+=1</span></pre></div><div class="ab cl mr ms hx mt" role="separator"><span class="mu bw bk mv mw mx"/><span class="mu bw bk mv mw mx"/><span class="mu bw bk mv mw"/></div><div class="im in io ip iq"><p id="540d" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">Ori Cohen 博士拥有计算机科学博士学位，专注于机器学习。他领导着 Zencity.io 的研究团队，试图积极影响市民的生活。</p></div></div>    
</body>
</html>