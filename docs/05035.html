<html>
<head>
<title>Illustrated: 10 CNN Architectures</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">插图:10 个 CNN 架构</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/illustrated-10-cnn-architectures-95d78ace614d?source=collection_archive---------0-----------------------#2019-07-29">https://towardsdatascience.com/illustrated-10-cnn-architectures-95d78ace614d?source=collection_archive---------0-----------------------#2019-07-29</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><figure class="is it gp gr iu iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi ir"><img src="../Images/a52201c7dd30736bc7ede00f64cf1fe0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*zbDxCB-0QDAc4oUGVtg3xw.png"/></div></div><figcaption class="jc jd gj gh gi je jf bd b be z dk">What architecture is this? 🤔</figcaption></figure><h2 id="ee69" class="jg jh ji bd b dl jj jk jl jm jn jo dk jp translated" aria-label="kicker paragraph"><a class="ae ep" href="https://medium.com/towards-data-science/inside-ai/home?source=post_page---------------------------" rel="noopener"> <strong class="ak">里面的艾</strong> </a></h2><div class=""/><div class=""><h2 id="488c" class="pw-subtitle-paragraph ko jr ji bd b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf dk translated">普通卷积神经网络的编译可视化</h2></div><p id="2437" class="pw-post-body-paragraph lg lh ji li b lj lk ks ll lm ln kv lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated"><em class="mc">(TL；DR —此处跳转到插图</em><a class="ae md" href="#bca5" rel="noopener ugc nofollow"><em class="mc"/></a><em class="mc">)</em></p><p id="658a" class="pw-post-body-paragraph lg lh ji li b lj lk ks ll lm ln kv lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated"><em class="mc">变更日志:<br/>2022 年 1 月 5 日—修复错别字并提高清晰度<br/>2020 年 11 月 28 日—更新了每个 CNN 的“最新消息”<br/>2020 年 11 月 17 日—编辑了从 4096 到 1000 的 Inceptionv1 的最后一个密集层的层数<br/>2020 年 9 月 24 日—编辑了 ResNeXt-50 的“最新消息”部分</em></p><p id="2097" class="pw-post-body-paragraph lg lh ji li b lj lk ks ll lm ln kv lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi me translated">你是如何跟上不同的卷积神经网络(CNN)的？近年来，我们见证了无数 CNN 的诞生。这些网络已经变得如此之深，以至于很难想象整个模型。我们不再跟踪他们，把他们当作黑箱模型。</p><p id="33b9" class="pw-post-body-paragraph lg lh ji li b lj lk ks ll lm ln kv lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">好吧，也许你不知道。但如果你也有罪，那么嘿，你来对地方了！这篇文章是 10 个常见的 CNN 架构的可视化，由你的忠实读者亲自挑选。这些插图提供了整个模型的更紧凑的视图，而不必为了查看 softmax 层而向下滚动几次。除了这些图像，我还写了一些笔记，说明它们是如何随着时间的推移而“演变”的——从 5 到 50 个卷积层，从普通卷积层到模块，从 2-3 个塔到 32 个塔，从 7⨉7 到 5⨉5—，但后面会有更多内容。</p><blockquote class="mn mo mp"><p id="35ed" class="lg lh mc li b lj lk ks ll lm ln kv lo mq lq lr ls mr lu lv lw ms ly lz ma mb im bi translated"><em class="ji">我说的‘常见’，是指那些预先训练好的权重通常被深度学习库(如 TensorFlow、Keras、PyTorch)共享给用户使用的模型，以及通常在课堂上教授的模型。这些模型中的一些已经在类似于</em> <a class="ae md" href="http://image-net.org/challenges/LSVRC/2016/index" rel="noopener ugc nofollow" target="_blank"> <em class="ji"> ImageNet 大规模视觉识别挑战赛</em> </a> <em class="ji"> (ILSVRC)的比赛中取得了成功。</em></p></blockquote><figure class="mu mv mw mx gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi mt"><img src="../Images/d1bad419ae0ff06934b9066778606853.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*dc07I4_N_IWDJVb6cM-KsQ.png"/></div></div><figcaption class="jc jd gj gh gi je jf bd b be z dk">The 10 architectures that will be discussed and the year their papers were published.</figcaption></figure><figure class="mu mv mw mx gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi my"><img src="../Images/4dcc6da3d5d601a747df64df04f55572.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*IPBwL5yb04_hc_zX08C-Rg.png"/></div></div><figcaption class="jc jd gj gh gi je jf bd b be z dk">Pre-trained weights are available in Keras for 6 of the architectures that we will talk about. Adapted from a table in the <a class="ae md" href="https://keras.io/applications/" rel="noopener ugc nofollow" target="_blank">Keras documentation</a>.</figcaption></figure><p id="a05c" class="pw-post-body-paragraph lg lh ji li b lj lk ks ll lm ln kv lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">写这篇文章的动机是，没有很多博客和文章有这些紧凑的可视化(如果你知道任何，请与我分享)。所以我决定写一个给大家参考。为了这个目的，我阅读了论文和代码(大部分来自 TensorFlow 和 Keras ),提出了这些 vizzes。</p><p id="eb95" class="pw-post-body-paragraph lg lh ji li b lj lk ks ll lm ln kv lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">这里我想补充一点，我们在野外看到的过多的 CNN 架构是许多事情的结果——改进的计算机硬件、ImageNet 竞争、解决特定任务、新想法等等。谷歌的研究员克里斯蒂安·塞格迪曾经提到</p><blockquote class="mz"><p id="a342" class="na nb ji bd nc nd ne nf ng nh ni mb dk translated">“这些进步不仅仅是更强大的硬件、更大的数据集和更大的模型的结果，更主要的是新思想、算法和改进的网络架构的结果。”(Szegedy 等人，2014 年)</p></blockquote><p id="4efa" class="pw-post-body-paragraph lg lh ji li b lj nj ks ll lm nk kv lo lp nl lr ls lt nm lv lw lx nn lz ma mb im bi translated">现在，让我们继续研究这些野兽，观察网络架构如何随着时间的推移而改进！</p><blockquote class="mn mo mp"><p id="fd4c" class="lg lh mc li b lj lk ks ll lm ln kv lo mq lq lr ls mr lu lv lw ms ly lz ma mb im bi translated"><strong class="li js"> <em class="ji">关于可视化的说明</em> </strong> <em class="ji"> <br/>注意，我已经排除了插图中卷积滤波器、填充、步幅、漏失和展平操作的数量。</em></p></blockquote></div><div class="ab cl no np hx nq" role="separator"><span class="nr bw bk ns nt nu"/><span class="nr bw bk ns nt nu"/><span class="nr bw bk ns nt"/></div><div class="im in io ip iq"><h2 id="7490" class="nv nw ji bd nx ny nz dn oa ob oc dp od lp oe of og lt oh oi oj lx ok ol om jo bi translated">目录(按出版年份排序)</h2><ol class=""><li id="e82e" class="on oo ji li b lj op lm oq lp or lt os lx ot mb ou ov ow ox bi translated"><a class="ae md" href="#e276" rel="noopener ugc nofollow"> LeNet-5 </a></li><li id="e2c9" class="on oo ji li b lj oy lm oz lp pa lt pb lx pc mb ou ov ow ox bi translated"><a class="ae md" href="#e971" rel="noopener ugc nofollow"> AlexNet </a></li><li id="fa1e" class="on oo ji li b lj oy lm oz lp pa lt pb lx pc mb ou ov ow ox bi translated"><a class="ae md" href="#c5a6" rel="noopener ugc nofollow"> VGG-16 </a></li><li id="47be" class="on oo ji li b lj oy lm oz lp pa lt pb lx pc mb ou ov ow ox bi translated"><a class="ae md" href="#81e0" rel="noopener ugc nofollow">盗梦空间-v1 </a></li><li id="1f58" class="on oo ji li b lj oy lm oz lp pa lt pb lx pc mb ou ov ow ox bi translated"><a class="ae md" href="#6872" rel="noopener ugc nofollow">盗梦空间-v3 </a></li><li id="6519" class="on oo ji li b lj oy lm oz lp pa lt pb lx pc mb ou ov ow ox bi translated"><a class="ae md" href="#e4b1" rel="noopener ugc nofollow"> ResNet-50 </a></li><li id="7a99" class="on oo ji li b lj oy lm oz lp pa lt pb lx pc mb ou ov ow ox bi translated"><a class="ae md" href="#d27e" rel="noopener ugc nofollow">异常</a></li><li id="598f" class="on oo ji li b lj oy lm oz lp pa lt pb lx pc mb ou ov ow ox bi translated"><a class="ae md" href="#b4ed" rel="noopener ugc nofollow">盗梦空间-v4 </a></li><li id="9971" class="on oo ji li b lj oy lm oz lp pa lt pb lx pc mb ou ov ow ox bi translated"><a class="ae md" href="#643c" rel="noopener ugc nofollow">盗梦空间</a></li><li id="2d85" class="on oo ji li b lj oy lm oz lp pa lt pb lx pc mb ou ov ow ox bi translated"><a class="ae md" href="#676b" rel="noopener ugc nofollow"> ResNeXt-50 </a></li></ol><h2 id="3c09" class="nv nw ji bd nx ny nz dn oa ob oc dp od lp oe of og lt oh oi oj lx ok ol om jo bi translated">神话；传奇</h2><figure class="mu mv mw mx gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi pd"><img src="../Images/74c36342fd60f37366ac81591eec6088.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*lzhgPYmx4epf7IbsEe584A.png"/></div></div></figure></div><div class="ab cl no np hx nq" role="separator"><span class="nr bw bk ns nt nu"/><span class="nr bw bk ns nt nu"/><span class="nr bw bk ns nt"/></div><div class="im in io ip iq"><h2 id="e276" class="nv nw ji bd nx ny nz dn oa ob oc dp od lp oe of og lt oh oi oj lx ok ol om jo bi translated">1.LeNet-5 (1998 年)</h2><figure class="mu mv mw mx gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi pe"><img src="../Images/b019f8ef994a397316d4a019affad8d2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*aQA7LuLJ2YfozSJa0pAO2Q.png"/></div></div><figcaption class="jc jd gj gh gi je jf bd b be z dk">Fig. 1: LeNet-5 architecture, based on their <a class="ae md" href="http://yann.lecun.com/exdb/publis/index.html#lecun-98" rel="noopener ugc nofollow" target="_blank">paper</a></figcaption></figure><p id="909f" class="pw-post-body-paragraph lg lh ji li b lj lk ks ll lm ln kv lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">LeNet-5 是最简单的架构之一。它有 2 个卷积层和 3 个全连接层(因此是“5”——神经网络的名称通常来自它们拥有的<em class="mc">卷积层</em>和<em class="mc">全连接层</em>)。我们现在知道的平均池层被称为<em class="mc">子采样层</em>，它具有可训练的权重(这不是当今设计 CNN 的当前实践)。这个架构大约有<strong class="li js">60000 个参数</strong>。</p><p id="05a3" class="pw-post-body-paragraph lg lh ji li b lj lk ks ll lm ln kv lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated"><strong class="li js"> ⭐️What's 小说？</strong></p><p id="2049" class="pw-post-body-paragraph lg lh ji li b lj lk ks ll lm ln kv lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">这种架构已经成为标准的“模板”:堆叠具有激活功能的卷积，汇集层，并以一个或多个完全连接的层结束网络。</p><p id="ca8d" class="pw-post-body-paragraph lg lh ji li b lj lk ks ll lm ln kv lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated"><strong class="li js">📝出版物</strong></p><ul class=""><li id="3d78" class="on oo ji li b lj lk lm ln lp pf lt pg lx ph mb pi ov ow ox bi translated">论文:<a class="ae md" href="http://yann.lecun.com/exdb/publis/index.html#lecun-98" rel="noopener ugc nofollow" target="_blank">基于梯度的学习应用于文档识别</a></li><li id="67c2" class="on oo ji li b lj oy lm oz lp pa lt pb lx pc mb pi ov ow ox bi translated">作者:Yann LeCun，Léon Bottou，Yoshua Bengio 和 Patrick Haffner</li><li id="e971" class="on oo ji li b lj oy lm oz lp pa lt pb lx pc mb pi ov ow ox bi translated"><strong class="li js">发表于:</strong>IEEE 会议录(1998)</li></ul><h2 id="f090" class="nv nw ji bd nx ny nz dn oa ob oc dp od lp oe of og lt oh oi oj lx ok ol om jo bi translated">2.AlexNet (2012 年)</h2><figure class="mu mv mw mx gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi pj"><img src="../Images/4407fbf3741cd65bc8e741a654449004.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*2DT1bjmvC-U-lrL7tpj6wg.png"/></div></div><figcaption class="jc jd gj gh gi je jf bd b be z dk">Fig. 2: AlexNet architecture, based on their <a class="ae md" href="https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks" rel="noopener ugc nofollow" target="_blank">paper</a>.</figcaption></figure><p id="72c0" class="pw-post-body-paragraph lg lh ji li b lj lk ks ll lm ln kv lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">有了<strong class="li js"> 60M 参数</strong>，AlexNet 有 8 层——5 层卷积，3 层全连接。AlexNet 刚刚在 LeNet-5 上又堆了几层。在发表时，作者指出，他们的架构是“迄今为止 ImageNet 子集上最大的卷积神经网络之一。”</p><p id="afc7" class="pw-post-body-paragraph lg lh ji li b lj lk ks ll lm ln kv lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated"><strong class="li js"> ⭐️What's 小说？</strong></p><ol class=""><li id="97a4" class="on oo ji li b lj lk lm ln lp pf lt pg lx ph mb ou ov ow ox bi translated">他们首先实现了作为激活函数的整流线性单元(ReLUs)。</li><li id="1fa6" class="on oo ji li b lj oy lm oz lp pa lt pb lx pc mb ou ov ow ox bi translated">辍学。</li></ol><p id="8199" class="pw-post-body-paragraph lg lh ji li b lj lk ks ll lm ln kv lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated"><strong class="li js">📝出版物</strong></p><ul class=""><li id="a166" class="on oo ji li b lj lk lm ln lp pf lt pg lx ph mb pi ov ow ox bi translated">论文:<a class="ae md" href="https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks" rel="noopener ugc nofollow" target="_blank"> ImageNet 深度卷积神经网络分类</a></li><li id="e843" class="on oo ji li b lj oy lm oz lp pa lt pb lx pc mb pi ov ow ox bi translated">作者:亚历克斯·克里热夫斯基，伊利亚·苏茨基弗，杰弗里·辛顿。加拿大多伦多大学。</li><li id="4e96" class="on oo ji li b lj oy lm oz lp pa lt pb lx pc mb pi ov ow ox bi translated">发表于:NeurIPS 2012 年</li></ul><h2 id="c5a6" class="nv nw ji bd nx ny nz dn oa ob oc dp od lp oe of og lt oh oi oj lx ok ol om jo bi translated">3.VGG-16 (2014 年)</h2><figure class="mu mv mw mx gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi pk"><img src="../Images/3928872236e557ac7e88cb82c8c6b70d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_vGloND6yyxFeFH5UyCDVg.png"/></div></div><figcaption class="jc jd gj gh gi je jf bd b be z dk">Fig. 3: VGG-16 architecture, based on their <a class="ae md" href="https://arxiv.org/abs/1409.1556" rel="noopener ugc nofollow" target="_blank">paper</a>.</figcaption></figure><p id="3183" class="pw-post-body-paragraph lg lh ji li b lj lk ks ll lm ln kv lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">到现在为止，你可能已经注意到 CNN 开始越来越深入。这是因为提高深度神经网络性能的最直接的方法是增加它们的大小(Szegedy 等人。al)。视觉几何小组(VGG)的人发明了 VGG-16，它有 13 个卷积层和 3 个全连接层，带有来自 AlexNet 的 ReLU 传统。该网络在 AlexNet 上堆叠更多层，并使用较小尺寸的过滤器(2×2 和 3×3)。它由<strong class="li js">138m</strong>T6】参数组成，占用大约 500MB 的存储空间😱。他们还设计了一种更深的变体，VGG-19。</p><p id="4f0b" class="pw-post-body-paragraph lg lh ji li b lj lk ks ll lm ln kv lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated"><strong class="li js"> ⭐️What's 小说？</strong></p><ol class=""><li id="eb36" class="on oo ji li b lj lk lm ln lp pf lt pg lx ph mb ou ov ow ox bi translated">正如他们在摘要中提到的，这篇论文的贡献是设计了更深层次的网络(大约是 AlexNet 的两倍)。这是通过堆积均匀的回旋来实现的。</li></ol><p id="f940" class="pw-post-body-paragraph lg lh ji li b lj lk ks ll lm ln kv lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated"><strong class="li js">📝出版物</strong></p><ul class=""><li id="4e70" class="on oo ji li b lj lk lm ln lp pf lt pg lx ph mb pi ov ow ox bi translated">论文:<a class="ae md" href="https://arxiv.org/abs/1409.1556" rel="noopener ugc nofollow" target="_blank">用于大规模图像识别的极深度卷积网络</a></li><li id="84c5" class="on oo ji li b lj oy lm oz lp pa lt pb lx pc mb pi ov ow ox bi translated">作者:卡伦·西蒙扬，安德鲁齐塞曼。英国牛津大学。</li><li id="680a" class="on oo ji li b lj oy lm oz lp pa lt pb lx pc mb pi ov ow ox bi translated">arXiv 预印本，2014 年</li></ul><h2 id="81e0" class="nv nw ji bd nx ny nz dn oa ob oc dp od lp oe of og lt oh oi oj lx ok ol om jo bi translated">4.《盗梦空间》第一版(2014 年)</h2><figure class="mu mv mw mx gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi pl"><img src="../Images/dfadfed6cadf91468f350ef82f56bb06.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*KnTe9YGNopUMiRjlEr3b8w.png"/></div></div><figcaption class="jc jd gj gh gi je jf bd b be z dk">Fig. 4: Inception-v1 architecture. This CNN has two auxiliary networks (which are discarded at inference time). Architecture is based on Figure 3 in the <a class="ae md" href="https://arxiv.org/abs/1409.4842" rel="noopener ugc nofollow" target="_blank">paper</a>.</figcaption></figure><p id="1a2b" class="pw-post-body-paragraph lg lh ji li b lj lk ks ll lm ln kv lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">这个拥有<strong class="li js"> 5M </strong>参数的 22 层架构被称为 Inception-v1。这里，网络中的网络(参见<a class="ae md" href="#a253" rel="noopener ugc nofollow">附录</a>)方法被大量使用，如论文中所述。网络中的网络通过<em class="mc">初始模块</em>实现。一个初始模块的架构设计是对近似稀疏结构进行研究的产物(更多信息请阅读本文！).每个模块提出 3 个想法:</p><ol class=""><li id="2db5" class="on oo ji li b lj lk lm ln lp pf lt pg lx ph mb ou ov ow ox bi translated">让<strong class="li js">并行塔</strong>的卷积具有不同的滤波器，然后级联，在 1×1、3×3 和 5×5 捕获不同的特征，从而“聚集”它们。这一想法是由 Arora 等人在论文<em class="mc">中提出的，论文</em>提出了一种逐层结构，在这种结构中，应该分析最后一层的相关性统计数据，并将它们聚类到具有高相关性的单元组中。</li><li id="1e38" class="on oo ji li b lj oy lm oz lp pa lt pb lx pc mb ou ov ow ox bi translated">1×1 卷积用于降维以消除计算瓶颈。</li><li id="ca6e" class="on oo ji li b lj oy lm oz lp pa lt pb lx pc mb ou ov ow ox bi translated">由于来自 1×1 卷积的激活函数，其加法也增加了非线性。这个想法是基于网络论文中的网络。此处见附录<a class="ae md" href="#a253" rel="noopener ugc nofollow">。</a></li><li id="6e83" class="on oo ji li b lj oy lm oz lp pa lt pb lx pc mb ou ov ow ox bi translated">作者还引入了<strong class="li js"> </strong>和两个<strong class="li js">辅助分类器</strong>，以鼓励在分类器的较低阶段进行区分，增加传播回来的梯度信号，并提供额外的正则化。<strong class="li js">辅助网络</strong>(连接到辅助分类器的分支)在推理时被丢弃。</li></ol><p id="aa5e" class="pw-post-body-paragraph lg lh ji li b lj lk ks ll lm ln kv lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">值得注意的是，“这种架构的主要特点是提高了网络内部计算资源的利用率。”</p><blockquote class="mn mo mp"><p id="a00e" class="lg lh mc li b lj lk ks ll lm ln kv lo mq lq lr ls mr lu lv lw ms ly lz ma mb im bi translated"><strong class="li js"> <em class="ji">注:</em> </strong> <em class="ji"> <br/>模块的名称(Stem 和 Inception)在这个版本的 Inception 中没有使用，直到后来的版本，即 Inception-v4 和 Inception-ResNets。为了便于比较，我在这里添加了它们。</em></p></blockquote><p id="d048" class="pw-post-body-paragraph lg lh ji li b lj lk ks ll lm ln kv lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated"><strong class="li js"> ⭐️What's 小说？</strong></p><ol class=""><li id="e64e" class="on oo ji li b lj lk lm ln lp pf lt pg lx ph mb ou ov ow ox bi translated">使用模块/块构建网络。我们不是堆叠卷积层，而是堆叠模块或块，模块或块内是卷积层。因此得名《盗梦空间》(参照 2010 年由莱昂纳多·迪卡普里奥主演的科幻电影《盗梦空间》)。</li></ol><p id="1189" class="pw-post-body-paragraph lg lh ji li b lj lk ks ll lm ln kv lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated"><strong class="li js">📝出版物</strong></p><ul class=""><li id="0421" class="on oo ji li b lj lk lm ln lp pf lt pg lx ph mb pi ov ow ox bi translated">论文:<a class="ae md" href="https://arxiv.org/abs/1409.4842" rel="noopener ugc nofollow" target="_blank">用卷积深化</a></li><li id="7318" class="on oo ji li b lj oy lm oz lp pa lt pb lx pc mb pi ov ow ox bi translated">作者:克里斯蒂安·塞格迪、、贾、Pierre Sermanet、Scott Reed、Dragomir Anguelov、Dumitru Erhan、Vincent Vanhoucke、Andrew Rabinovich。谷歌、密歇根大学、北卡罗来纳大学</li><li id="9bef" class="on oo ji li b lj oy lm oz lp pa lt pb lx pc mb pi ov ow ox bi translated">发表于:2015 年 IEEE 计算机视觉和模式识别会议(CVPR)</li></ul><h2 id="6872" class="nv nw ji bd nx ny nz dn oa ob oc dp od lp oe of og lt oh oi oj lx ok ol om jo bi translated">5.《盗梦空间》第三版(2015 年)</h2><figure class="mu mv mw mx gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi pm"><img src="../Images/d714c66f8e5abd852c256ac8e96d571d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ooVUXW6BIcoRdsF7kzkMwQ.png"/></div></div><figcaption class="jc jd gj gh gi je jf bd b be z dk">Fig. 5: Inception-v3 architecture. This CNN has an auxiliary network (which is discarded at inference time). *Note: All convolutional layers are followed by batch norm and ReLU activation. Architecture is based on their GitHub <a class="ae md" href="https://github.com/tensorflow/models/blob/master/research/slim/nets/inception_v1.py" rel="noopener ugc nofollow" target="_blank">code</a>.</figcaption></figure><p id="79af" class="pw-post-body-paragraph lg lh ji li b lj lk ks ll lm ln kv lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">Inception-v3 是 Inception-v1 的后继版本，有<strong class="li js"> 24M </strong>参数。等等，盗梦空间 v2 在哪里？不用担心——它是 v3 的早期原型，因此它与 v3 非常相似，但不常用。当作者推出 Inception-v2 时，他们在上面运行了许多实验，并记录了一些成功的调整。Inception-v3 是结合了这些调整的网络(对优化器、损失函数的调整以及对辅助网络中的辅助层添加批量归一化)。</p><p id="60e6" class="pw-post-body-paragraph lg lh ji li b lj lk ks ll lm ln kv lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">Inception-v2 和 Inception-v3 的动机是避免<em class="mc">表示瓶颈</em>(这意味着极大地减少下一层的输入维度)，并通过使用因式分解方法进行更有效的计算。</p><blockquote class="mn mo mp"><p id="4e87" class="lg lh mc li b lj lk ks ll lm ln kv lo mq lq lr ls mr lu lv lw ms ly lz ma mb im bi translated"><strong class="li js"> <em class="ji">注:</em> </strong> <em class="ji"> <br/>模块名称(Stem，Inception-A，Inception-B 等。)直到它的更高版本，即 Inception-v4 和 Inception-ResNets，才被用于这个版本的 Inception。为了便于比较，我在这里添加了它们。</em></p></blockquote><p id="eac4" class="pw-post-body-paragraph lg lh ji li b lj lk ks ll lm ln kv lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated"><strong class="li js"> ⭐️What's 小说？</strong></p><ol class=""><li id="7598" class="on oo ji li b lj lk lm ln lp pf lt pg lx ph mb ou ov ow ox bi translated">首批使用批量标准化的设计者之一(为简单起见，上图中没有反映)。</li></ol><p id="f0b8" class="pw-post-body-paragraph lg lh ji li b lj lk ks ll lm ln kv lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated"><strong class="li js"> ✨What's 改进自上一版本，</strong> <a class="ae md" href="#81e0" rel="noopener ugc nofollow"> <strong class="li js">盗梦空间-v1 </strong> </a> <strong class="li js">？</strong></p><ol class=""><li id="cda5" class="on oo ji li b lj lk lm ln lp pf lt pg lx ph mb ou ov ow ox bi translated">将<em class="mc"> n </em> × <em class="mc"> n </em>卷积分解为非对称卷积:1×n 和<em class="mc"> n </em> ×1 <em class="mc">和</em>卷积</li><li id="9d91" class="on oo ji li b lj oy lm oz lp pa lt pb lx pc mb ou ov ow ox bi translated">将 5×5 卷积分解为两个 3×3 卷积运算</li><li id="8115" class="on oo ji li b lj oy lm oz lp pa lt pb lx pc mb ou ov ow ox bi translated">用一系列 3×3 卷积替换 7×7</li></ol><p id="74ac" class="pw-post-body-paragraph lg lh ji li b lj lk ks ll lm ln kv lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated"><strong class="li js">📝出版物</strong></p><ul class=""><li id="63b2" class="on oo ji li b lj lk lm ln lp pf lt pg lx ph mb pi ov ow ox bi translated">论文:<a class="ae md" href="https://arxiv.org/abs/1512.00567" rel="noopener ugc nofollow" target="_blank">反思计算机视觉的初始架构</a></li><li id="a3a6" class="on oo ji li b lj oy lm oz lp pa lt pb lx pc mb pi ov ow ox bi translated">作者:克里斯蒂安·塞格迪，文森特·范霍克，谢尔盖·约菲，黄邦贤·施伦斯，兹比格涅夫·沃伊纳。谷歌，伦敦大学学院</li><li id="e4b1" class="on oo ji li b lj oy lm oz lp pa lt pb lx pc mb pi ov ow ox bi translated">发表于:2016 年 IEEE 计算机视觉与模式识别会议(CVPR)</li></ul><h2 id="afbd" class="nv nw ji bd nx ny nz dn oa ob oc dp od lp oe of og lt oh oi oj lx ok ol om jo bi translated">6.ResNet-50 (2015 年)</h2><figure class="mu mv mw mx gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi ir"><img src="../Images/a52201c7dd30736bc7ede00f64cf1fe0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*zbDxCB-0QDAc4oUGVtg3xw.png"/></div></div><figcaption class="jc jd gj gh gi je jf bd b be z dk">Fig. 6: ResNet-50 architecture, based on the GitHub <a class="ae md" href="https://github.com/keras-team/keras-applications/blob/master/keras_applications/resnet_common.py" rel="noopener ugc nofollow" target="_blank">code</a> from keras-team.</figcaption></figure><p id="6427" class="pw-post-body-paragraph lg lh ji li b lj lk ks ll lm ln kv lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">没错，就是你在文章上方看到的问题的答案<a class="ae md" href="#71ae" rel="noopener ugc nofollow">这里</a>(“这是什么架构？”).</p><p id="e9e6" class="pw-post-body-paragraph lg lh ji li b lj lk ks ll lm ln kv lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">从过去的几个 CNN 中，我们只看到设计中的层数越来越多，性能越来越好。但是“随着网络深度的增加，精确度会饱和(这并不奇怪)，然后迅速下降。”微软研究院的人用 ResNet 解决了这个问题——在构建更深层次的模型时使用跳过连接(也称为快捷连接，残差)。</p><p id="9236" class="pw-post-body-paragraph lg lh ji li b lj lk ks ll lm ln kv lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">ResNet 是批量标准化的早期采用者之一(Ioffe 和 Szegedy 撰写的批量标准化论文已于 2015 年提交给 ICML)。上图是 ResNet-50，参数<strong class="li js"> 26M </strong>。</p><p id="80f8" class="pw-post-body-paragraph lg lh ji li b lj lk ks ll lm ln kv lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">ResNets 的基本构造块是 conv 和标识块。因为它们看起来很像，你可能会把 ResNet-50 简化成这样(这个不要引用我的话！):</p><figure class="mu mv mw mx gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi pn"><img src="../Images/02c7cd8485cf78fa86251bc0ca0a8d79.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*eE1Oaewvqmlnb6V27byjtA.png"/></div></div></figure><p id="f18f" class="pw-post-body-paragraph lg lh ji li b lj lk ks ll lm ln kv lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated"><strong class="li js"> ⭐️有什么小说？</strong></p><ol class=""><li id="8117" class="on oo ji li b lj lk lm ln lp pf lt pg lx ph mb ou ov ow ox bi translated"><em class="mc">普及</em>跳过连接(他们不是第一个使用跳过连接的)。</li><li id="b0cf" class="on oo ji li b lj oy lm oz lp pa lt pb lx pc mb ou ov ow ox bi translated">设计更深层次的 CNN(多达 152 层),而不影响模型的泛化能力</li><li id="11cb" class="on oo ji li b lj oy lm oz lp pa lt pb lx pc mb ou ov ow ox bi translated">首批使用批量标准化的公司之一。</li></ol><p id="84bb" class="pw-post-body-paragraph lg lh ji li b lj lk ks ll lm ln kv lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated"><strong class="li js">📝出版物</strong></p><ul class=""><li id="0a2f" class="on oo ji li b lj lk lm ln lp pf lt pg lx ph mb pi ov ow ox bi translated">论文:<a class="ae md" href="https://arxiv.org/abs/1512.03385" rel="noopener ugc nofollow" target="_blank">用于图像识别的深度残差学习</a></li><li id="eda8" class="on oo ji li b lj oy lm oz lp pa lt pb lx pc mb pi ov ow ox bi translated">作者:，何，，，任，。微软</li><li id="d27e" class="on oo ji li b lj oy lm oz lp pa lt pb lx pc mb pi ov ow ox bi translated">发表于:2016 年 IEEE 计算机视觉与模式识别会议(CVPR)</li></ul><h2 id="579b" class="nv nw ji bd nx ny nz dn oa ob oc dp od lp oe of og lt oh oi oj lx ok ol om jo bi translated">7.例外(2016 年)</h2><figure class="mu mv mw mx gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi po"><img src="../Images/63d3dcae9735a8776168c5d792c02e49.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*NNsznNjzULwqvSER8k5eDg.png"/></div></div><figcaption class="jc jd gj gh gi je jf bd b be z dk">Fig. 7: Xception architecture, based on the GitHub <a class="ae md" href="https://github.com/keras-team/keras-applications/blob/master/keras_applications/xception.py" rel="noopener ugc nofollow" target="_blank">code</a> from keras-team. Depthwise separable convolutions are denoted by ‘conv sep.’</figcaption></figure><p id="2268" class="pw-post-body-paragraph lg lh ji li b lj lk ks ll lm ln kv lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">例外是对 Inception 的改编，其中 Inception 模块已经被深度方向可分离的卷积所取代。它还拥有与 Inception-v1 大致相同数量的参数(<strong class="li js"> 23M </strong>)。</p><p id="9724" class="pw-post-body-paragraph lg lh ji li b lj lk ks ll lm ln kv lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">Xception 将盗梦假设发挥到了极致<em class="mc"/>(因此得名)。什么是盗梦空间假说？谢天谢地，这篇论文明确而简洁地提到了这一点(谢谢弗朗索瓦！).</p><ul class=""><li id="24e1" class="on oo ji li b lj lk lm ln lp pf lt pg lx ph mb pi ov ow ox bi translated">首先，通过 1×1 卷积获得跨通道(或跨特征图)相关性。</li><li id="9b86" class="on oo ji li b lj oy lm oz lp pa lt pb lx pc mb pi ov ow ox bi translated">因此，每个通道内的空间相关性通过常规的 3×3 或 5×5 卷积来捕获。</li></ul><p id="e9c4" class="pw-post-body-paragraph lg lh ji li b lj lk ks ll lm ln kv lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">将这一想法发挥到极致意味着每个通道执行 1×1 到<em class="mc">，然后每个</em>通道执行 3×3 到<em class="mc">的输出。这等同于用深度方向可分离的卷积替换初始模块。</em></p><p id="fed6" class="pw-post-body-paragraph lg lh ji li b lj lk ks ll lm ln kv lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated"><strong class="li js"> ⭐️What's 小说？</strong></p><ol class=""><li id="1e99" class="on oo ji li b lj lk lm ln lp pf lt pg lx ph mb ou ov ow ox bi translated">介绍了完全基于深度方向可分离卷积层的 CNN。</li></ol><p id="5373" class="pw-post-body-paragraph lg lh ji li b lj lk ks ll lm ln kv lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated"><strong class="li js">📝出版物</strong></p><ul class=""><li id="4a16" class="on oo ji li b lj lk lm ln lp pf lt pg lx ph mb pi ov ow ox bi translated">论文:<a class="ae md" href="https://arxiv.org/abs/1610.02357" rel="noopener ugc nofollow" target="_blank">例外:深度可分卷积深度学习</a></li><li id="da27" class="on oo ji li b lj oy lm oz lp pa lt pb lx pc mb pi ov ow ox bi translated">作者:弗朗索瓦·乔莱。谷歌。</li><li id="5900" class="on oo ji li b lj oy lm oz lp pa lt pb lx pc mb pi ov ow ox bi translated">发表于:2017 年 IEEE 计算机视觉与模式识别会议(CVPR)</li></ul><h2 id="b4ed" class="nv nw ji bd nx ny nz dn oa ob oc dp od lp oe of og lt oh oi oj lx ok ol om jo bi translated">8.《盗梦空间》第 4 版(2016 年)</h2><figure class="mu mv mw mx gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi pp"><img src="../Images/238a2becbfdc5db3c106461c340d8dba.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*15sIUNOxqVyDPmGGqefyVw.png"/></div></div><figcaption class="jc jd gj gh gi je jf bd b be z dk">Fig. 8: Inception-v4 architecture. This CNN has an auxiliary network (which is discarded at inference time). *Note: All convolutional layers are followed by batch norm and ReLU activation. Architecture is based on their GitHub <a class="ae md" href="https://github.com/tensorflow/models/blob/master/research/slim/nets/inception_v4.py" rel="noopener ugc nofollow" target="_blank">code</a>.</figcaption></figure><p id="ec59" class="pw-post-body-paragraph lg lh ji li b lj lk ks ll lm ln kv lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">谷歌的人又用 Inception-v4，<strong class="li js"> 43M </strong>参数罢工了。同样，这是对 Inception-v3 的改进。主要区别是 Stem 组和 Inception-C 模块中的一些小变化。作者还“为每个网格大小的初始块做了统一的选择。”他们还提到，拥有“剩余连接可以显著提高训练速度。”</p><p id="c827" class="pw-post-body-paragraph lg lh ji li b lj lk ks ll lm ln kv lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">总之，请注意，它提到了 Inception-v4 工作得更好，因为增加了模型大小。</p><p id="0750" class="pw-post-body-paragraph lg lh ji li b lj lk ks ll lm ln kv lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated"><strong class="li js"> ✨What's 改进自上一版本，</strong> <a class="ae md" href="#6872" rel="noopener ugc nofollow"> <strong class="li js">盗梦空间-v3 </strong> </a> <strong class="li js">？</strong></p><ol class=""><li id="5ac8" class="on oo ji li b lj lk lm ln lp pf lt pg lx ph mb ou ov ow ox bi translated">阀杆模块的变化。</li><li id="5011" class="on oo ji li b lj oy lm oz lp pa lt pb lx pc mb ou ov ow ox bi translated">添加更多的初始模块。</li><li id="3d17" class="on oo ji li b lj oy lm oz lp pa lt pb lx pc mb ou ov ow ox bi translated">Inception-v3 模块的统一选择，意味着对每个模块使用相同数量的过滤器。</li></ol><p id="f0ed" class="pw-post-body-paragraph lg lh ji li b lj lk ks ll lm ln kv lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated"><strong class="li js">📝出版物</strong></p><ul class=""><li id="36e3" class="on oo ji li b lj lk lm ln lp pf lt pg lx ph mb pi ov ow ox bi translated">论文:<a class="ae md" href="https://arxiv.org/abs/1602.07261" rel="noopener ugc nofollow" target="_blank"> Inception-v4，Inception-ResNet 和剩余连接对学习的影响</a></li><li id="aec3" class="on oo ji li b lj oy lm oz lp pa lt pb lx pc mb pi ov ow ox bi translated">作者:克里斯蒂安·塞格迪，谢尔盖·约菲，文森特·万霍克，亚历克斯·阿莱米。谷歌。</li><li id="41a3" class="on oo ji li b lj oy lm oz lp pa lt pb lx pc mb pi ov ow ox bi translated">发表于:第三十一届 AAAI 人工智能会议记录</li></ul><h2 id="643c" class="nv nw ji bd nx ny nz dn oa ob oc dp od lp oe of og lt oh oi oj lx ok ol om jo bi translated">9.《盗梦空间》-ResNet-V2 (2016 年)</h2><figure class="mu mv mw mx gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi pq"><img src="../Images/c17d4b7e071037559ca1a8b4e8023f9e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*xpb6QFQ4IknSmxmgai8w-Q.png"/></div></div><figcaption class="jc jd gj gh gi je jf bd b be z dk">Fig. 9: Inception-ResNet-V2 architecture. *Note: All convolutional layers are followed by batch norm and ReLU activation. Architecture is based on their GitHub <a class="ae md" href="https://github.com/tensorflow/models/blob/master/research/slim/nets/inception_resnet_v2.py" rel="noopener ugc nofollow" target="_blank">code</a>.</figcaption></figure><p id="7400" class="pw-post-body-paragraph lg lh ji li b lj lk ks ll lm ln kv lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">在与 Inception-v4 相同的论文中，相同的作者还介绍了 Inception-ResNet——Inception-ResNet-v1 和 Inception-ResNet-v2 的家族。家族的后一个成员有<strong class="li js"> 56M </strong>参数。</p><p id="e334" class="pw-post-body-paragraph lg lh ji li b lj lk ks ll lm ln kv lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated"><strong class="li js"> ✨What's 改进自上一版本，</strong> <a class="ae md" href="#6872" rel="noopener ugc nofollow"> <strong class="li js">《盗梦空间》-v3 </strong> </a> <strong class="li js">？</strong></p><ol class=""><li id="0cf9" class="on oo ji li b lj lk lm ln lp pf lt pg lx ph mb ou ov ow ox bi translated">将初始模块转换成<em class="mc">剩余初始块。</em></li><li id="8717" class="on oo ji li b lj oy lm oz lp pa lt pb lx pc mb ou ov ow ox bi translated">添加更多的初始模块。</li><li id="9a62" class="on oo ji li b lj oy lm oz lp pa lt pb lx pc mb ou ov ow ox bi translated">在 Stem 模块之后添加一个新类型的初始模块(Inception-A)。</li></ol><p id="b124" class="pw-post-body-paragraph lg lh ji li b lj lk ks ll lm ln kv lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated"><strong class="li js">📝出版物</strong></p><ul class=""><li id="900e" class="on oo ji li b lj lk lm ln lp pf lt pg lx ph mb pi ov ow ox bi translated">论文:<a class="ae md" href="https://arxiv.org/abs/1602.07261" rel="noopener ugc nofollow" target="_blank"> Inception-v4，Inception-ResNet 和剩余连接对学习的影响</a></li><li id="1686" class="on oo ji li b lj oy lm oz lp pa lt pb lx pc mb pi ov ow ox bi translated">作者:克里斯蒂安·塞格迪，谢尔盖·约菲，文森特·万霍克，亚历克斯·阿莱米。谷歌</li><li id="4b05" class="on oo ji li b lj oy lm oz lp pa lt pb lx pc mb pi ov ow ox bi translated">发表于:第三十一届 AAAI 人工智能会议记录</li></ul><h2 id="676b" class="nv nw ji bd nx ny nz dn oa ob oc dp od lp oe of og lt oh oi oj lx ok ol om jo bi translated">10.ResNeXt-50 (2017 年)</h2><figure class="mu mv mw mx gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi pr"><img src="../Images/38b616609e1e5dd411f3a0fbee3150ae.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*HelCJiQZEuwuKakRwDdGPw.png"/></div></div><figcaption class="jc jd gj gh gi je jf bd b be z dk">Fig. 10: ResNeXt architecture, based on their paper.</figcaption></figure><p id="e18f" class="pw-post-body-paragraph lg lh ji li b lj lk ks ll lm ln kv lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">如果你在想 ResNets，是的，它们是相关的。ResNeXt-50 有<strong class="li js"> 25M </strong>参数(ResNet-50 有 25.5M)。ResNeXts 的不同之处在于在每个模块中添加了并行的塔/分支/路径，如上面“总共 32 个塔”所示</p><p id="d399" class="pw-post-body-paragraph lg lh ji li b lj lk ks ll lm ln kv lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated"><strong class="li js"> ⭐️有什么小说？</strong></p><ol class=""><li id="1d23" class="on oo ji li b lj lk lm ln lp pf lt pg lx ph mb ou ov ow ox bi translated">扩大一个模块中并行塔的数量(“基数”)(我的意思是这已经被 Inception network 探索过了，除了这些塔是在这里添加的)</li></ol><p id="7a2b" class="pw-post-body-paragraph lg lh ji li b lj lk ks ll lm ln kv lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated"><strong class="li js">📝出版物</strong></p><ul class=""><li id="0b37" class="on oo ji li b lj lk lm ln lp pf lt pg lx ph mb pi ov ow ox bi translated">论文:<a class="ae md" href="https://arxiv.org/abs/1611.05431" rel="noopener ugc nofollow" target="_blank">深度神经网络的聚合残差变换</a></li><li id="490b" class="on oo ji li b lj oy lm oz lp pa lt pb lx pc mb pi ov ow ox bi translated">作者:谢赛宁，罗斯·吉斯克，彼得·多拉尔，涂，何。加州大学圣地亚哥分校脸书研究所</li><li id="fabf" class="on oo ji li b lj oy lm oz lp pa lt pb lx pc mb pi ov ow ox bi translated">发表于:2017 年 IEEE 计算机视觉与模式识别会议(CVPR)</li></ul><h2 id="a253" class="nv nw ji bd nx ny nz dn oa ob oc dp od lp oe of og lt oh oi oj lx ok ol om jo bi translated"><strong class="ak">附录:网络中的网络(2014) </strong></h2><p id="b7e9" class="pw-post-body-paragraph lg lh ji li b lj op ks ll lm oq kv lo lp ps lr ls lt pt lv lw lx pu lz ma mb im bi translated">回想一下，在卷积中，像素值是过滤器和当前滑动窗口中权重的线性组合。作者建议用一个带有一个隐藏层的迷你神经网络来代替这种线性组合。这就是他们创造的 Mlpconv。因此，我们在这里处理的是(卷积神经)网络中的(简单的 1 个隐藏层)网络。</p><p id="e219" class="pw-post-body-paragraph lg lh ji li b lj lk ks ll lm ln kv lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">Mlpconv 的这种思想被比作 1×1 卷积，后来成为初始架构的主要特征。</p><p id="c717" class="pw-post-body-paragraph lg lh ji li b lj lk ks ll lm ln kv lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated"><strong class="li js"> ⭐️What's 小说？</strong></p><ol class=""><li id="79e7" class="on oo ji li b lj lk lm ln lp pf lt pg lx ph mb ou ov ow ox bi translated">MLP 卷积层，1×1 卷积</li><li id="9e7f" class="on oo ji li b lj oy lm oz lp pa lt pb lx pc mb ou ov ow ox bi translated">全局平均池(取每个特征地图的平均值，并将结果向量送入 softmax 层)</li></ol><p id="7ff4" class="pw-post-body-paragraph lg lh ji li b lj lk ks ll lm ln kv lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated"><strong class="li js">📝出版物</strong></p><ul class=""><li id="7b08" class="on oo ji li b lj lk lm ln lp pf lt pg lx ph mb pi ov ow ox bi translated">论文:<a class="ae md" href="https://arxiv.org/abs/1312.4400" rel="noopener ugc nofollow" target="_blank">网络中的网络</a></li><li id="429e" class="on oo ji li b lj oy lm oz lp pa lt pb lx pc mb pi ov ow ox bi translated">作者:，，水城颜。新加坡国立大学</li><li id="f155" class="on oo ji li b lj oy lm oz lp pa lt pb lx pc mb pi ov ow ox bi translated">arXiv 预印本，2013 年</li></ul></div><div class="ab cl no np hx nq" role="separator"><span class="nr bw bk ns nt nu"/><span class="nr bw bk ns nt nu"/><span class="nr bw bk ns nt"/></div><div class="im in io ip iq"><p id="bca5" class="pw-post-body-paragraph lg lh ji li b lj lk ks ll lm ln kv lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">为了便于参考，我们在这里再展示一次:</p><h2 id="04ce" class="nv nw ji bd nx ny nz dn oa ob oc dp od lp oe of og lt oh oi oj lx ok ol om jo bi translated">LeNet-5</h2><figure class="mu mv mw mx gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi pe"><img src="../Images/b019f8ef994a397316d4a019affad8d2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*aQA7LuLJ2YfozSJa0pAO2Q.png"/></div></div></figure><h2 id="1f3f" class="nv nw ji bd nx ny nz dn oa ob oc dp od lp oe of og lt oh oi oj lx ok ol om jo bi translated">AlexNet</h2><figure class="mu mv mw mx gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi pj"><img src="../Images/4407fbf3741cd65bc8e741a654449004.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*2DT1bjmvC-U-lrL7tpj6wg.png"/></div></div></figure><h2 id="aa0b" class="nv nw ji bd nx ny nz dn oa ob oc dp od lp oe of og lt oh oi oj lx ok ol om jo bi translated">VGG-16</h2><figure class="mu mv mw mx gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi pk"><img src="../Images/3928872236e557ac7e88cb82c8c6b70d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_vGloND6yyxFeFH5UyCDVg.png"/></div></div></figure><h2 id="f594" class="nv nw ji bd nx ny nz dn oa ob oc dp od lp oe of og lt oh oi oj lx ok ol om jo bi translated">盗梦空间-第一版</h2><figure class="mu mv mw mx gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi pl"><img src="../Images/7cfcd40f8a97cc8cfecb51de54d1d541.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*53uKkbeyzJcdo8PE5TQqqw.png"/></div></div></figure><h2 id="2e6c" class="nv nw ji bd nx ny nz dn oa ob oc dp od lp oe of og lt oh oi oj lx ok ol om jo bi translated">盗梦空间-第三版</h2><figure class="mu mv mw mx gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi pm"><img src="../Images/d714c66f8e5abd852c256ac8e96d571d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ooVUXW6BIcoRdsF7kzkMwQ.png"/></div></div></figure><h2 id="cecf" class="nv nw ji bd nx ny nz dn oa ob oc dp od lp oe of og lt oh oi oj lx ok ol om jo bi translated">盗梦空间-第 4 版</h2><figure class="mu mv mw mx gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi pp"><img src="../Images/238a2becbfdc5db3c106461c340d8dba.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*15sIUNOxqVyDPmGGqefyVw.png"/></div></div></figure><h2 id="726d" class="nv nw ji bd nx ny nz dn oa ob oc dp od lp oe of og lt oh oi oj lx ok ol om jo bi translated">盗梦空间-ResNet-V2</h2><figure class="mu mv mw mx gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi pq"><img src="../Images/c17d4b7e071037559ca1a8b4e8023f9e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*xpb6QFQ4IknSmxmgai8w-Q.png"/></div></div></figure><h2 id="8daf" class="nv nw ji bd nx ny nz dn oa ob oc dp od lp oe of og lt oh oi oj lx ok ol om jo bi translated">例外</h2><figure class="mu mv mw mx gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi po"><img src="../Images/63d3dcae9735a8776168c5d792c02e49.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*NNsznNjzULwqvSER8k5eDg.png"/></div></div></figure><h2 id="409d" class="nv nw ji bd nx ny nz dn oa ob oc dp od lp oe of og lt oh oi oj lx ok ol om jo bi translated">ResNet-50</h2><figure class="mu mv mw mx gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi ir"><img src="../Images/a52201c7dd30736bc7ede00f64cf1fe0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*zbDxCB-0QDAc4oUGVtg3xw.png"/></div></div></figure><h2 id="1cad" class="nv nw ji bd nx ny nz dn oa ob oc dp od lp oe of og lt oh oi oj lx ok ol om jo bi translated">ResNeXt-50</h2><figure class="mu mv mw mx gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi pr"><img src="../Images/38b616609e1e5dd411f3a0fbee3150ae.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*HelCJiQZEuwuKakRwDdGPw.png"/></div></div></figure></div><div class="ab cl no np hx nq" role="separator"><span class="nr bw bk ns nt nu"/><span class="nr bw bk ns nt nu"/><span class="nr bw bk ns nt"/></div><div class="im in io ip iq"><h2 id="ecc2" class="nv nw ji bd nx ny nz dn oa ob oc dp od lp oe of og lt oh oi oj lx ok ol om jo bi translated">神经网络可视化资源</h2><p id="b833" class="pw-post-body-paragraph lg lh ji li b lj op ks ll lm oq kv lo lp ps lr ls lt pt lv lw lx pu lz ma mb im bi translated">这里有一些资源供你想象你的神经网络:</p><ul class=""><li id="fcf0" class="on oo ji li b lj lk lm ln lp pf lt pg lx ph mb pi ov ow ox bi translated">Netron 😍</li><li id="3391" class="on oo ji li b lj oy lm oz lp pa lt pb lx pc mb pi ov ow ox bi translated"><a class="ae md" href="https://www.tensorflow.org/tensorboard/r1/overview" rel="noopener ugc nofollow" target="_blank">tensor flow 提供的 TensorBoard API </a></li><li id="6d58" class="on oo ji li b lj oy lm oz lp pa lt pb lx pc mb pi ov ow ox bi translated">Keras 的<code class="fe pv pw px py b"><a class="ae md" href="https://keras.io/visualization/" rel="noopener ugc nofollow" target="_blank">plot_model</a></code> <a class="ae md" href="https://keras.io/visualization/" rel="noopener ugc nofollow" target="_blank"> API </a></li><li id="ccf5" class="on oo ji li b lj oy lm oz lp pa lt pb lx pc mb pi ov ow ox bi translated"><code class="fe pv pw px py b"><a class="ae md" href="https://github.com/szagoruyko/pytorchviz" rel="noopener ugc nofollow" target="_blank">pytorchviz</a></code> <a class="ae md" href="https://github.com/szagoruyko/pytorchviz" rel="noopener ugc nofollow" target="_blank">包</a></li></ul><h2 id="2215" class="nv nw ji bd nx ny nz dn oa ob oc dp od lp oe of og lt oh oi oj lx ok ol om jo bi translated">类似文章</h2><p id="2acc" class="pw-post-body-paragraph lg lh ji li b lj op ks ll lm oq kv lo lp ps lr ls lt pt lv lw lx pu lz ma mb im bi translated">CNN 架构:LeNet、AlexNet、VGG、GoogLeNet、ResNet 等等。</p><p id="432b" class="pw-post-body-paragraph lg lh ji li b lj lk ks ll lm ln kv lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated"><a class="ae md" rel="noopener" target="_blank" href="/a-simple-guide-to-the-versions-of-the-inception-network-7fc52b863202">盗梦空间网络版本的简单指南</a></p><h2 id="fe1a" class="nv nw ji bd nx ny nz dn oa ob oc dp od lp oe of og lt oh oi oj lx ok ol om jo bi translated">参考</h2><p id="8d43" class="pw-post-body-paragraph lg lh ji li b lj op ks ll lm oq kv lo lp ps lr ls lt pt lv lw lx pu lz ma mb im bi translated">我参考了上面提到的产生这些架构的论文。除此之外，下面是我在本文中使用的一些其他方法:</p><p id="d08b" class="pw-post-body-paragraph lg lh ji li b lj lk ks ll lm ln kv lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated"><a class="ae md" href="https://github.com/tensorflow/models/tree/master/research/slim/nets" rel="noopener ugc nofollow" target="_blank">https://github . com/tensor flow/models/tree/master/research/slim/nets</a>(github.com/tensorflow)</p><p id="0397" class="pw-post-body-paragraph lg lh ji li b lj lk ks ll lm ln kv lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated"><a class="ae md" href="https://github.com/keras-team/keras-applications/tree/master/keras_applications" rel="noopener ugc nofollow" target="_blank">Keras 团队深度学习模型的实现</a>(github.com/keras-team)</p><p id="a136" class="pw-post-body-paragraph lg lh ji li b lj lk ks ll lm ln kv lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated"><a class="ae md" href="http://slazebni.cs.illinois.edu/spring17/lec01_cnn_architectures.pdf" rel="noopener ugc nofollow" target="_blank">卷积神经网络架构讲义:从 LeNet 到 ResNet</a>(slazebni.cs.illinois.edu)</p><p id="430f" class="pw-post-body-paragraph lg lh ji li b lj lk ks ll lm ln kv lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated"><a class="ae md" rel="noopener" target="_blank" href="/review-nin-network-in-network-image-classification-69e271e499ee">回顾:NIN —网络中的网络(图像分类)</a>(towardsdatascience.com)</p><p id="4298" class="pw-post-body-paragraph lg lh ji li b lj lk ks ll lm ln kv lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">你在观想中注意到什么错误了吗？你觉得我还应该包括什么吗？在下面给我留言吧！</p></div><div class="ab cl no np hx nq" role="separator"><span class="nr bw bk ns nt nu"/><span class="nr bw bk ns nt nu"/><span class="nr bw bk ns nt"/></div><div class="im in io ip iq"><p id="185f" class="pw-post-body-paragraph lg lh ji li b lj lk ks ll lm ln kv lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">如果你喜欢我的内容并且还没有订阅 Medium，请通过我的推荐链接 <a class="ae md" href="https://medium.com/@remykarem/membership" rel="noopener"> <em class="mc">这里</em> </a> <em class="mc">订阅！注意:你的会员费的一部分将作为介绍费分配给我。</em></p><p id="866c" class="pw-post-body-paragraph lg lh ji li b lj lk ks ll lm ln kv lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">特别感谢狄强、齐威、任杰、傅楠、希尔琳和德里克审阅本文。</p><p id="6458" class="pw-post-body-paragraph lg lh ji li b lj lk ks ll lm ln kv lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated"><em class="mc">关注我上</em> <a class="ae md" href="https://www.twitter.com/remykarem" rel="noopener ugc nofollow" target="_blank"> <em class="mc">推特</em> </a> <em class="mc"> @remykarem 或者</em><a class="ae md" href="http://www.linkedin.com/in/raimibkarim" rel="noopener ugc nofollow" target="_blank"><em class="mc">LinkedIn</em></a><em class="mc">。你也可以通过 raimi.bkarim@gmail.com 联系我。欢迎访问我的网站</em><a class="ae md" href="https://remykarem.github.io/" rel="noopener ugc nofollow" target="_blank"><em class="mc">remykarem . github . io</em></a><em class="mc">。</em></p></div></div>    
</body>
</html>