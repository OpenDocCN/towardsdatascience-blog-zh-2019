<html>
<head>
<title>Image recommendation engine with Keras</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">带有 Keras 的图像推荐引擎</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/image-recommendation-engine-with-keras-d227b0996667?source=collection_archive---------25-----------------------#2019-10-17">https://towardsdatascience.com/image-recommendation-engine-with-keras-d227b0996667?source=collection_archive---------25-----------------------#2019-10-17</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="c54a" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">建立一个 CNN 分类器，把它变成一个推荐引擎。</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/22f9666b2511e31e0647981260d3ee55.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Z9103ES8wytmq7H4_ykY1A.png"/></div></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk"><a class="ae ky" href="https://www.cleanpng.com/png-convolutional-neural-network-natural-language-proc-3083964/" rel="noopener ugc nofollow" target="_blank">https://www.cleanpng.com/png-convolutional-neural-network-natural-language-proc-3083964/</a></figcaption></figure></div><div class="ab cl kz la hx lb" role="separator"><span class="lc bw bk ld le lf"/><span class="lc bw bk ld le lf"/><span class="lc bw bk ld le"/></div><div class="im in io ip iq"><p id="086f" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">我有一些漫画数据，我甚至写了一篇文章，以便你可以收集这些数据集(有一些修改)见:<a class="ae ky" rel="noopener" target="_blank" href="/scrape-multiple-pages-with-scrapy-ea8edfa4318">https://towards data science . com/scrape-multiple-pages-with-scrapy-ea 8 EDFA 4318</a></p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="ab gu cl mc"><img src="../Images/11332c3776552659eca689bdc57d8612.png" data-original-src="https://miro.medium.com/v2/format:webp/1*_V00ZAzRA2uLmDfnOGFSYw.png"/></div></figure><p id="5cf2" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">对于每一部漫画，我都在海报栏里找到了他的照片的网址。我将在此基础上建立我的图像语料库</p><pre class="kj kk kl km gt md me mf mg aw mh bi"><span id="1086" class="mi mj it me b gy mk ml l mm mn">import requests</span><span id="47d8" class="mi mj it me b gy mo ml l mm mn">manga["title"] = manga["title"].replace({"%" : ""}, regex=True)<br/>manga= manga[(manga["title"] != "") &amp; (manga["title"].notnull()) &amp; (manga["poster"].notnull())]</span><span id="cf51" class="mi mj it me b gy mo ml l mm mn">import requests<br/>from tqdm import tqdm</span><span id="7193" class="mi mj it me b gy mo ml l mm mn">keep_in_memory = []</span><span id="d91f" class="mi mj it me b gy mo ml l mm mn">for url, title in tqdm(zip(manga["poster"], manga["title"])) : <br/>    str_name = "/home/jupyter/Untitled Folder/%s.jpg" %title<br/>    str_name = str_name.strip()<br/>    keep_in_memory.append(str_name)<br/>    with open(str_name, 'wb') as f:<br/>        f.write(requests.get(url).content)<br/>        <br/>manga["pics_ref"] = keep_in_memory</span></pre><p id="fb8e" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">我将使用性别列作为我的图像分类器的标签。但是我之前需要做一点清理，因为我有大约 3000 个独特的标签，我会清理我的标签并减少它们。</p><pre class="kj kk kl km gt md me mf mg aw mh bi"><span id="803d" class="mi mj it me b gy mk ml l mm mn">manga["genre"] = manga["genre"].str.strip()<br/>manga["genre"] = manga["genre"] +  " ,"</span><span id="367a" class="mi mj it me b gy mo ml l mm mn">import re</span><span id="5755" class="mi mj it me b gy mo ml l mm mn">def clean(genre, string_to_filter) :<br/>    return re.sub('(?&lt;={})(.*\n?)(?=,)'.format(string_to_filter), '', genre)</span><span id="4fa0" class="mi mj it me b gy mo ml l mm mn">manga["genre"] = manga["genre"].apply(lambda  x : clean(str(x), 'Comic'))<br/>manga["genre"] = manga["genre"].apply(lambda  x : clean(str(x), 'Action'))<br/>manga["genre"] = manga["genre"].apply(lambda  x : clean(str(x), 'Josei'))<br/>manga["genre"] = manga["genre"].apply(lambda  x : clean(str(x), 'Shoujo'))<br/>manga["genre"] = manga["genre"].apply(lambda  x : clean(str(x), 'Shounen'))<br/>manga["genre"] = manga["genre"].apply(lambda  x : clean(str(x), 'Horror'))</span><span id="9c47" class="mi mj it me b gy mo ml l mm mn">manga['genre'] = [list(map(str.strip, y)) for y in [x.split(',') for x in manga['genre']]]</span><span id="b56c" class="mi mj it me b gy mo ml l mm mn">manga['genre'] =[','.join(x) for x in manga['genre']]</span><span id="7bd8" class="mi mj it me b gy mo ml l mm mn">my_cat = ['Action', 'Adventure', 'Comedy', 'Hentai',<br/>          'Harem', 'Fantasy', 'Drama', 'Horror', 'Romance','Josei',<br/>          'Fantasy', 'Seinen', 'Sci-Fi', 'Slice of Life', 'Mecha', 'Yaoi',<br/>          'Yuri', 'Thriller', 'Comic']</span><span id="00ae" class="mi mj it me b gy mo ml l mm mn">manga["genre"] = manga["genre"].apply(lambda z : [x for x in my_cat if x in z])<br/>manga['genre'] =[','.join(x) for x in manga['genre']]</span><span id="cb98" class="mi mj it me b gy mo ml l mm mn">genre = manga["genre"].str.get_dummies(',')<br/>manga = pd.concat([manga, genre], axis = 1)</span></pre><p id="8e6e" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">我现在有 18 个标签，我把它们编码成每个标签的二进制矩阵。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi mp"><img src="../Images/8a235b7a38d210f3f6389aeec7cc0214.png" data-original-src="https://miro.medium.com/v2/resize:fit:546/format:webp/1*6idKbJTNdEXDCxwk-ls1MQ.png"/></div></figure><p id="0b32" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">我还有另一个问题:我的标签是不平衡的，所以我们将定义一个类权重，稍后我将在我的模型中传递它。</p><pre class="kj kk kl km gt md me mf mg aw mh bi"><span id="b612" class="mi mj it me b gy mk ml l mm mn">label_cnt = [(columns, manga[columns].sum()) for columns in manga.columns[8:]]<br/>tot = sum([x[1] for x in label_cnt])<br/>class_weight = dict(zip([x[0] for x in label_cnt], [x[1]/tot for x in label_cnt]))</span></pre><p id="a0ee" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">最后，我们将建立我们的输入矩阵。</p><pre class="kj kk kl km gt md me mf mg aw mh bi"><span id="a9e8" class="mi mj it me b gy mk ml l mm mn">train_image = []<br/>index_to_drop = []<br/>for i, png in tqdm(list(enumerate(manga["pics_ref"]))):<br/>    try : <br/>        img = image.load_img(png,target_size=(256,256,3))<br/>        img = image.img_to_array(img)<br/>        img = img/255<br/>        train_image.append(img)<br/>    except OSError : <br/>        index_to_drop.append(i)</span><span id="940f" class="mi mj it me b gy mo ml l mm mn">manga = manga.drop(manga.index[index_to_drop])<br/>    <br/>X = np.array(train_image)<br/>y = np.array(manga[manga.columns[8:].tolist()])</span><span id="8d2a" class="mi mj it me b gy mo ml l mm mn">from sklearn.model_selection import train_test_split<br/>X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 777)</span></pre><p id="c314" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">然后，我们将定义我们的模型。不管结构如何，这里有一点很重要，即我们的预测必须通过 sigmoid 函数激活，而不是 softmax，因为否则我们将有属于这样一个标签的累积概率，或者我们想要属于一个标签的独立概率。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="mq mr l"/></div></figure><p id="502d" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">最后，使用 ImageDataGenerator 模块增加数据，该模块将通过更改 RGB 通道、缩放、翻转图像等方式生成新照片…..</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="mq mr l"/></div></figure><p id="dea9" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">我们的模型拟合得非常准确，但它不是这项任务的完美指标。我们试试吧，省省吧。</p><pre class="kj kk kl km gt md me mf mg aw mh bi"><span id="28e9" class="mi mj it me b gy mk ml l mm mn">randint = np.random.randint(1, manga.shape[0], 1)[0]<br/>poster = manga["pics_ref"].iloc[randint]<br/>img = image.load_img(poster, target_size=(256,256,3))<br/>img = image.img_to_array(img)<br/>img = img/255</span><span id="453c" class="mi mj it me b gy mo ml l mm mn">classes = np.array(manga.columns[8:])<br/>proba = model.predict(img.reshape(1,256,256,3))<br/>top_3 = np.argsort(proba[0])[:-4:-1]<br/>for i in range(3):<br/>    print("{}".format(classes[top_3[i]])+" ({:.3})".format(proba[0][top_3[i]]))<br/>plt.imshow(img)</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ms"><img src="../Images/db3840d2b21b03dca8fb5dfea78a10cb.png" data-original-src="https://miro.medium.com/v2/resize:fit:828/format:webp/1*g2n8DMB1CKV7CBazqHTjLw.png"/></div></figure><pre class="kj kk kl km gt md me mf mg aw mh bi"><span id="d838" class="mi mj it me b gy mk ml l mm mn">from keras.models import model_from_json</span><span id="0bb3" class="mi mj it me b gy mo ml l mm mn"># serialize model to JSON<br/>model_json = model.to_json()<br/>with open("model.json", "w") as json_file:<br/>    json_file.write(model_json)<br/># serialize weights to HDF5<br/>model.save_weights("model.h5")<br/>print("Saved model to disk")<br/># load json and create model<br/>json_file = open('model.json', 'r')<br/>loaded_model_json = json_file.read()<br/>json_file.close()<br/>'''<br/>loaded_model = model_from_json(loaded_model_json)<br/>loaded_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])<br/>'''</span></pre><p id="b3ed" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">无论如何，我们对分类器的准确性不感兴趣，而是对训练产生的特征感兴趣，这将允许我们建立我们的推荐！首先，我们将通过删除最后一个预测层，用我们的预训练模型重建一个模型。</p><pre class="kj kk kl km gt md me mf mg aw mh bi"><span id="8f7b" class="mi mj it me b gy mk ml l mm mn">image_features_extractor = Model(inputs=model.input,  outputs=model.layers[-2].output)</span><span id="c4c9" class="mi mj it me b gy mo ml l mm mn">img_features = image_features_extractor.predict(X)</span><span id="a4ee" class="mi mj it me b gy mo ml l mm mn">cosSimilarities = cosine_similarity(img_features)</span><span id="b23c" class="mi mj it me b gy mo ml l mm mn">cos_similarities_df = pd.DataFrame(cosSimilarities,<br/>                                   columns=manga["title"],<br/>                                   index=manga["title"])</span></pre><p id="c043" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">最后，我们得到与给定海报最相似的海报。</p><pre class="kj kk kl km gt md me mf mg aw mh bi"><span id="0d07" class="mi mj it me b gy mk ml l mm mn">def most_similar_to(given_img, nb_closest_images = 5):</span><span id="f539" class="mi mj it me b gy mo ml l mm mn">print("-----------------------------------------------------------------------")<br/>    print("original manga:")</span><span id="dbd6" class="mi mj it me b gy mo ml l mm mn">original = load_img(given_img, target_size=(256,256,3))<br/>    plt.imshow(original)<br/>    plt.show()</span><span id="8303" class="mi mj it me b gy mo ml l mm mn">print("-----------------------------------------------------------------------")<br/>    print("most similar manga:")</span><span id="6492" class="mi mj it me b gy mo ml l mm mn">closest_imgs = cos_similarities_df[given_img].sort_values(ascending=False)[1:nb_closest_images+1].index<br/>    closest_imgs_scores = cos_similarities_df[given_img].sort_values(ascending=False)[1:nb_closest_images+1]</span><span id="5b7e" class="mi mj it me b gy mo ml l mm mn">for i in range(0,len(closest_imgs)):<br/>        img = image.load_img(closest_imgs[i], target_size=(256,256,3))<br/>        plt.imshow(img)<br/>        plt.show()<br/>        print("similarity score : ",closest_imgs_scores[i])</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi mt"><img src="../Images/655933de8b6ff3878d735aec9c0f5d9f.png" data-original-src="https://miro.medium.com/v2/resize:fit:584/format:webp/1*dNyERlQij_C5sh4IjqCm9A.png"/></div></figure><ul class=""><li id="b8e8" class="mu mv it li b lj lk lm ln lp mw lt mx lx my mb mz na nb nc bi translated">推荐</li></ul><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nd"><img src="../Images/a1644f0493013e57580ef072494cba7f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1298/format:webp/1*S6Z8DLNoGUI4iQ3Cl_aSYA.png"/></div></figure><p id="486a" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">看起来不错！但是还可以更好！</p><h1 id="3a6e" class="ne mj it bd nf ng nh ni nj nk nl nm nn jz no ka np kc nq kd nr kf ns kg nt nu bi translated">最后</h1><p id="16e0" class="pw-post-body-paragraph lg lh it li b lj nv ju ll lm nw jx lo lp nx lr ls lt ny lv lw lx nz lz ma mb im bi translated">我们编写了一个卷积神经网络来对我们的漫画进行分类，然后我们检索了训练过程中产生的变量，使其成为一个推荐系统。同一个模型的几种用法相当不错不是吗！<br/>谢谢，代码在这里:<a class="ae ky" href="https://github.com/AlexWarembourg/Medium" rel="noopener ugc nofollow" target="_blank">https://github.com/AlexWarembourg/Medium</a></p></div></div>    
</body>
</html>