<html>
<head>
<title>Training Yolo for Object Detection in PyTorch with Your Custom Dataset — The Simple Way</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用您的自定义数据集在 PyTorch 中训练 Yolo 进行对象检测——简单的方法</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/training-yolo-for-object-detection-in-pytorch-with-your-custom-dataset-the-simple-way-1aa6f56cf7d9?source=collection_archive---------2-----------------------#2019-10-09">https://towardsdatascience.com/training-yolo-for-object-detection-in-pytorch-with-your-custom-dataset-the-simple-way-1aa6f56cf7d9?source=collection_archive---------2-----------------------#2019-10-09</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><p id="24c2" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">在之前的故事中，我展示了如何使用预先训练好的 Yolo 网络进行<a class="ae kl" rel="noopener" target="_blank" href="/object-detection-and-tracking-in-pytorch-b3cf1a696a98"> <strong class="jp ir">物体检测和跟踪</strong> </a>。现在，我想向您展示如何使用由您自己的图像组成的自定义数据集来重新训练 Yolo。</p><p id="5470" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">对于这个故事，我将使用我自己为<a class="ae kl" href="http://www.cynet.ai/subt" rel="noopener ugc nofollow" target="_blank"> DARPA SubT 挑战</a>训练物体探测器的例子。挑战包括在隧道网络中检测 9 个不同的对象——它们是非常具体的对象，而不是标准 Yolo 模型中包含的常规对象。对于这个例子，我假设只有 3 个对象类。</p><p id="7957" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">有几种方法可以做到这一点，根据官方规范，您可以在培训脚本中定义图像、配置、注释和其他数据文件的位置，但这里有一种更简单且组织良好的方法，仍然遵循 Yolo 的最佳实践。</p><p id="4e2f" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">文件夹结构</strong></p><p id="672b" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">首先，您需要将所有的训练图像放在一起，使用这个文件夹结构(文件夹名称用<em class="km">斜体</em>)来表示:</p><pre class="kn ko kp kq gt kr ks kt ku aw kv bi"><span id="7d1b" class="kw kx iq ks b gy ky kz l la lb"><em class="km">Main Folder</em><br/>--- <em class="km">data</em><br/>    --- <em class="km">dataset name</em><br/>        --- <em class="km">images</em><br/>            --- img1.jpg<br/>            --- img2.jpg<br/>            ..........<br/>        --- <em class="km">labels</em><br/>            --- img1.txt<br/>            --- img2.txt<br/>            ..........<br/>        --- train.txt<br/>        --- val.txt</span></pre><p id="a4b3" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">现在让我们看看这些文件应该是什么样子的(除了那些显而易见的图像文件)。</p><p id="18f6" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">首先，注释文件。你需要一个。每个图像的 txt 文件(相同的名称，不同的扩展名，单独的文件夹)。每个文件只包含一行，格式如下:</p><pre class="kn ko kp kq gt kr ks kt ku aw kv bi"><span id="c3f3" class="kw kx iq ks b gy ky kz l la lb">class x y width height</span></pre><p id="0073" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">例如，一个文件(用于类 1)可以是:</p><pre class="kn ko kp kq gt kr ks kt ku aw kv bi"><span id="cb22" class="kw kx iq ks b gy ky kz l la lb">1 0.351466 0.427083 0.367168 0.570486</span></pre><p id="43f9" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">请注意，坐标和大小是整个图像大小的一部分。例如，如果文件是 600x600px，坐标(200，300)将表示为(0.333333，0.5)。</p><p id="520c" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir"> <em class="km"> train.txt </em> </strong>和<strong class="jp ir"> <em class="km"> val.txt </em> </strong>包含训练和验证图像列表，每行一个，路径完整。例如，在我的系统上，这样一个文件的前两行是:</p><pre class="kn ko kp kq gt kr ks kt ku aw kv bi"><span id="f691" class="kw kx iq ks b gy ky kz l la lb">/datadrive/Alphapilot/data/alpha/images/IMG_6723.JPG<br/>/datadrive/Alphapilot/data/alpha/images/IMG_6682.JPG</span></pre><p id="ce19" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我使用下面的<a class="ae kl" href="https://github.com/cfotache/pytorch_custom_yolo_training/blob/master/createlist.py" rel="noopener ugc nofollow" target="_blank">程序</a>生成 2 个文件，基于 90%训练/ 10%验证分割:</p><pre class="kn ko kp kq gt kr ks kt ku aw kv bi"><span id="65e7" class="kw kx iq ks b gy ky kz l la lb">import glob<br/>import os<br/>import numpy as np<br/>import sys</span><span id="cddf" class="kw kx iq ks b gy lc kz l la lb">current_dir = "./data/artifacts/images"<br/>split_pct = 10  # 10% validation set<br/>file_train = open("data/artifacts/train.txt", "w")  <br/>file_val = open("data/artifacts/val.txt", "w")  <br/>counter = 1  <br/>index_test = round(100 / split_pct)  <br/>for fullpath in glob.iglob(os.path.join(current_dir, "*.JPG")):  <br/>  title, ext = os.path.splitext(os.path.basename(fullpath))<br/>  if counter == index_test:<br/>    counter = 1<br/>    file_val.write(current_dir + "/" + title + '.JPG' + "\n")<br/>  else:<br/>    file_train.write(current_dir + "/" + title + '.JPG' + "\n")<br/>    counter = counter + 1<br/>file_train.close()<br/>file_val.close()</span></pre><p id="afb6" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">创建注释文件</strong></p><p id="eabe" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">现在你会问如何得到？txt 注释文件。嗯，我使用的是修改版的<strong class="jp ir"> BBOX </strong>工具，它包含在<a class="ae kl" href="https://github.com/cfotache/pytorch_custom_yolo_training/blob/master/bbox.py" rel="noopener ugc nofollow" target="_blank"> Github repo </a>中。它的工作方式是这样的:你将训练图像放在每个班级的不同文件夹中。查看 LoadDir 函数下的文件夹结构(或者根据您的情况进行修改)——在我的示例中，我有两个文件夹，“forboxing”用于图像，而“newlabels”用于生成的注释，在“forboxing”下有每个类的子文件夹(“0”、“1”等)。您必须修改文件顶部的<code class="fe ld le lf ks b">self.imgclass</code>属性，并为每个类单独运行它。这一程序使一切都快了一点。使用工具本身是非常直观的——你只需在每一帧中的对象周围画一个方框，然后转到下一帧。</p><figure class="kn ko kp kq gt lh gh gi paragraph-image"><div role="button" tabindex="0" class="li lj di lk bf ll"><div class="gh gi lg"><img src="../Images/e9a8d330a2a96d13bbfb512861bb50f1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*i0PZe3PFzyLSlRQmPpr7CQ.png"/></div></div></figure><p id="de96" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">配置文件</strong></p><p id="991a" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">现在来看看<em class="km"> config/ </em>文件夹中的配置文件。首先，<strong class="jp ir"> <em class="km"> coco.data </em> </strong>会是这样的:</p><pre class="kn ko kp kq gt kr ks kt ku aw kv bi"><span id="305d" class="kw kx iq ks b gy ky kz l la lb">classes = 3<br/>train=data/alpha/train.txt<br/>valid=data/alpha/val.txt<br/>names=config/coco.names<br/>backup=backup/</span></pre><p id="c7bc" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我认为这是不言自明的。backup 参数没有使用，但似乎是必需的。这个<strong class="jp ir"> <em class="km"> coco.names </em> </strong>文件非常简单，它应该列出类的名称，每行一个(对于注释文件，第一个对应于 0，第二个对应于 1，依此类推)。在我的例子中，文件包含三个类:</p><pre class="kn ko kp kq gt kr ks kt ku aw kv bi"><span id="f851" class="kw kx iq ks b gy ky kz l la lb">DRILL<br/>EXTINGUISHER<br/>RANDY</span></pre><p id="a9d3" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">现在，配置文件中最重要的是<strong class="jp ir"> <em class="km"> yolov3.cfg </em> </strong>。这是一个很大的文件，但以下是您必须更改的主要内容:</p><p id="ca5f" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">在第一个<code class="fe ld le lf ks b">[net]</code>部分，调整<code class="fe ld le lf ks b">batch</code>值和<code class="fe ld le lf ks b">subdivisions</code>以适合您的 GPU 内存。批量越大，训练越好，越快，但占用的内存也越多。对于一个 11Gb 内存的 Nvidia GPU 来说，一批 16 和 1 细分就不错了。也可以在这里调整<code class="fe ld le lf ks b">learning_rate</code>。</p><p id="7cbe" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">现在，最重要的是<code class="fe ld le lf ks b">classes</code>和最后一层<code class="fe ld le lf ks b">filters</code>的值(因为如果设置不正确，你的训练计划将会失败)。而且你要在<strong class="jp ir">文件中的三个</strong>不同的地方做。如果你搜索这个文件，你会发现 3 个<code class="fe ld le lf ks b">[yolo]</code>部分。在这个部分中，将<code class="fe ld le lf ks b">classes</code>设置为模型中的类的数量。您还必须更改[yolo]正上方的[卷积]部分中的<code class="fe ld le lf ks b">filters</code>值。该值等于:</p><pre class="kn ko kp kq gt kr ks kt ku aw kv bi"><span id="a704" class="kw kx iq ks b gy ky kz l la lb">filters = (classes + 5) x 3</span></pre><p id="0da6" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">所以对于我的 3 个类，有 24 个过滤器。注意，这只适用于 Yolo V3。V2 有一个不同的公式。</p><p id="b62c" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">运行培训脚本</strong></p><p id="116d" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">现在你已经为真正的训练做好了准备！训练程序(来自<a class="ae kl" href="https://github.com/cfotache/pytorch_custom_yolo_training/blob/master/train.py" rel="noopener ugc nofollow" target="_blank"> Github repo </a>)是标准的 Yolo 脚本。在 config 部分，设置所需的 epochs 数，确保文件夹路径正确，然后运行。根据训练图像的数量和您的硬件，这可能需要几个小时到一天以上的时间。</p><p id="c8ef" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">该脚本将在每个纪元后保存…抓取最后一个文件并将其放回您的配置文件夹中，然后它就可以在您的自定义数据集上进行对象检测了！关于如何运行检测功能的细节在前面的故事中有介绍，PyTorch 中的<a class="ae kl" rel="noopener" target="_blank" href="/object-detection-and-tracking-in-pytorch-b3cf1a696a98">对象检测和跟踪。</a></p><p id="7208" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">这个故事中引用的所有代码都可以在我的<a class="ae kl" href="https://github.com/cfotache/pytorch_custom_yolo_training" rel="noopener ugc nofollow" target="_blank"> Github repo </a>中获得。</p><p id="9610" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">Chris Fotache 是一名人工智能研究员，在新泽西州工作。他涵盖了与我们生活中的人工智能、Python 编程、机器学习、计算机视觉、自然语言处理、机器人等相关的主题。</p></div></div>    
</body>
</html>