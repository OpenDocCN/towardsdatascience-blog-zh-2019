<html>
<head>
<title>Uncertainty Sampling Cheatsheet</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">不确定性采样备忘单</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/uncertainty-sampling-cheatsheet-ec57bc067c0b?source=collection_archive---------12-----------------------#2019-07-29">https://towardsdatascience.com/uncertainty-sampling-cheatsheet-ec57bc067c0b?source=collection_archive---------12-----------------------#2019-07-29</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><p id="5914" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">当有监督的机器学习模型做出预测时，它通常会给出该预测的置信度。如果模型是不确定的(低置信度)，那么人类的反馈可以有所帮助。当一个模型不确定时，获得人类的反馈是一种被称为<em class="kl">不确定性采样</em>的<em class="kl">主动学习</em>。</p><p id="cb68" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">备忘单中涵盖的四种不确定性采样类型是:</p><ol class=""><li id="d822" class="km kn iq jp b jq jr ju jv jy ko kc kp kg kq kk kr ks kt ku bi translated"><strong class="jp ir">最不自信:</strong>最自信预测和 100%自信之间的差异</li><li id="5ae6" class="km kn iq jp b jq kv ju kw jy kx kc ky kg kz kk kr ks kt ku bi translated"><strong class="jp ir">置信区间:</strong>两个最有把握的预测之间的差异</li><li id="7678" class="km kn iq jp b jq kv ju kw jy kx kc ky kg kz kk kr ks kt ku bi translated"><strong class="jp ir">置信度:</strong>最有把握的两个预测之间的比率</li><li id="1fad" class="km kn iq jp b jq kv ju kw jy kx kc ky kg kz kk kr ks kt ku bi translated"><strong class="jp ir">熵:</strong>所有预测之间的差异，由信息论定义</li></ol><p id="1b2b" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">本文分享了这四种计算不确定性的常用方法的备忘单，包括示例、等式和 python 代码。下次你需要决定如何计算你的模型的置信度时，把它作为一个参考！</p><p id="65c0" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">数据科学家通常使用不确定性采样来对项目进行采样，以便进行人工审查。例如，想象一下，你负责一个机器学习模型来帮助自动驾驶汽车理解交通。你可能有数百万张从汽车前部摄像头拍摄的未标记图像，但你只有时间或预算来标记 1000 张。如果你随机采样，你可能会得到大部分来自高速公路驾驶的图像，自动驾驶汽车已经很自信，不需要额外的训练。因此，您将使用不确定性采样来查找 1，000 个最“不确定”的图像，其中您的模型最混乱。</p><figure class="lb lc ld le gt lf gh gi paragraph-image"><div role="button" tabindex="0" class="lg lh di li bf lj"><div class="gh gi la"><img src="../Images/a769342204151e4fcfcd76450b717965.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*X4c7GE0f_mEunzHjpViAow.jpeg"/></div></div><figcaption class="lm ln gj gh gi lo lp bd b be z dk">Confusing traffic lights</figcaption></figure><p id="209f" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">当您使用新标记的示例更新您的模型时，它应该会变得更智能、更快。</p><figure class="lb lc ld le gt lf gh gi paragraph-image"><div role="button" tabindex="0" class="lg lh di li bf lj"><div class="gh gi lq"><img src="../Images/93e2fbcd6f7a9e5fc8b226c2c8dba372.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*IKSzkO6I-9_Rg4lY0MaRpQ.png"/></div></div><figcaption class="lm ln gj gh gi lo lp bd b be z dk">An uncertain robot</figcaption></figure><figure class="lb lc ld le gt lf gh gi paragraph-image"><div role="button" tabindex="0" class="lg lh di li bf lj"><div class="gh gi lr"><img src="../Images/74806a38f4a822e324856dd077d22367.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*mOn7B41azPE-ClV9E3fdyg.png"/></div></div></figure><p id="2a2e" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">这篇备忘单摘自我的书《人在回路中的机器学习:<a class="ae ls" href="https://www.manning.com/books/human-in-the-loop-machine-learning#ref" rel="noopener ugc nofollow" target="_blank">https://www . manning . com/books/人在回路中的机器学习</a></p><p id="b52e" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">有关每种方法的更多细节和比标记更复杂的问题，如预测文本序列和图像的语义分割，请参见这本书。不确定度的原理是一样的，但是不确定度的计算会不一样。</p><p id="f94c" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">这本书还涵盖了其他主动学习策略，如多样性抽样，以及解释你的模型概率分布的最佳方式(<em class="kl">提示:</em>你可能无法相信你的模型的可信度)。</p><h1 id="1a83" class="lt lu iq bd lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk ml mm mn mo mp mq bi translated">下载代码和备忘单:</h1><p id="6def" class="pw-post-body-paragraph jn jo iq jp b jq mr js jt ju ms jw jx jy mt ka kb kc mu ke kf kg mv ki kj kk ij bi translated">您可以从这里下载代码:</p><div class="mw mx gp gr my mz"><a href="https://github.com/rmunro/uncertainty_sampling_numpy" rel="noopener  ugc nofollow" target="_blank"><div class="na ab fo"><div class="nb ab nc cl cj nd"><h2 class="bd ir gy z fp ne fr fs nf fu fw ip bi translated">RM unro/不确定性 _ 采样 _ 数字</h2><div class="ng l"><h3 class="bd b gy z fp ne fr fs nf fu fw dk translated">针对不确定性的常见主动学习策略的 NumPy 实现对四种不确定性进行采样…</h3></div><div class="nh l"><p class="bd b dl z fp ne fr fs nf fu fw dk translated">github.com</p></div></div><div class="ni l"><div class="nj l nk nl nm ni nn lk mz"/></div></div></a></div><p id="faf1" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">您可以在此下载 PDF 版本的备忘单:</p><figure class="lb lc ld le gt lf"><div class="bz fp l di"><div class="no np l"/></div></figure><p id="dfca" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我还将在以后发布 PyTorch 中的代码，以及更多种类的算法。</p><p id="bedf" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><em class="kl">编辑:PyTorch 版本的备忘单现已发布:</em><a class="ae ls" href="http://robertmunro.com/Uncertainty_Sampling_Cheatsheet_PyTorch.pdf" rel="noopener ugc nofollow" target="_blank">http://robertmunro . com/Uncertainty _ Sampling _ cheat sheet _ py torch . pdf</a></p><h1 id="d94b" class="lt lu iq bd lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk ml mm mn mo mp mq bi translated">进一步阅读</h1><p id="677d" class="pw-post-body-paragraph jn jo iq jp b jq mr js jt ju ms jw jx jy mt ka kb kc mu ke kf kg mv ki kj kk ij bi translated">不确定性抽样已经存在很长时间了，有很多好的文献。一篇关于最不自信的优秀早期论文是:</p><p id="4f95" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">阿伦·库洛塔和安德鲁·麦卡勒姆。2005.减少结构化预测任务的标记工作。<em class="kl"> AAAI </em>。<a class="ae ls" href="https://people.cs.umass.edu/~mccallum/papers/multichoice-aaai05.pdf" rel="noopener ugc nofollow" target="_blank">https://people . cs . umass . edu/~ McCallum/papers/multi choice-aaai 05 . pdf</a></p><p id="e7b7" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">一篇关于置信区间的优秀早期论文是:</p><p id="18cc" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">托拜厄斯·谢弗，克里斯蒂安·德科曼和斯特凡·弗罗贝尔。2001.用于信息抽取的主动隐马尔可夫模型。<em class="kl">伊达</em>。<a class="ae ls" href="https://link.springer.com/content/pdf/10.1007/3-540-44816-0_31.pdf" rel="noopener ugc nofollow" target="_blank">https://link . springer . com/content/pdf/10.1007/3-540-44816-0 _ 31 . pdf</a></p><p id="36ba" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">将信息论用于基于熵的采样的一篇好的早期论文是:</p><p id="d2c9" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">伊多·达甘和肖恩·p·恩格尔森。1995.用于训练概率分类器的基于委员会的采样。<em class="kl">95 年的 ICML。</em><a class="ae ls" href="http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.30.6148" rel="noopener ugc nofollow" target="_blank">http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.30.6148 </a></p><p id="d738" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">更一般地说，不确定性采样的基础文件是:</p><p id="fe6e" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">戴维·刘易斯和威廉·盖尔。1994.一种训练文本分类器的顺序算法。<em class="kl">94 年的 SIGIR。</em><a class="ae ls" href="https://arxiv.org/pdf/cmp-lg/9407020.pdf" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/pdf/cmp-lg/9407020.pdf</a></p><p id="e7f5" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">要获得更多关于不确定性抽样的学术论文，请查找引用上述论文的被广泛引用的近期工作。</p><p id="24ca" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">这些例子在我自己的文章中也有涉及:</p><p id="220c" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">罗伯特·芒罗。2020 年(预计)。人在回路中的机器学习。曼宁出版公司。https://www . manning . com/books/human-in-the-loop-machine-learning</p><p id="ee3c" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我文本中的章节是按照他们所写的内容出版的——不确定性抽样章节现在已经出版，多样性抽样章节将是下一个。我会边走边分享摘录，就像我最近在机器学习知识象限中做的那样:</p><div class="mw mx gp gr my mz"><a rel="noopener follow" target="_blank" href="/knowledge-quadrant-for-machine-learning-5f82ff979890"><div class="na ab fo"><div class="nb ab nc cl cj nd"><h2 class="bd ir gy z fp ne fr fs nf fu fw ip bi translated">机器学习的知识象限</h2><div class="ng l"><h3 class="bd b gy z fp ne fr fs nf fu fw dk translated">迁移学习、不确定性采样和多样性采样来改进您的机器学习模型。</h3></div><div class="nh l"><p class="bd b dl z fp ne fr fs nf fu fw dk translated">towardsdatascience.com</p></div></div><div class="ni l"><div class="nq l nk nl nm ni nn lk mz"/></div></div></a></div><h1 id="aacb" class="lt lu iq bd lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk ml mm mn mo mp mq bi translated">实施不确定性采样</h1><p id="1a64" class="pw-post-body-paragraph jn jo iq jp b jq mr js jt ju ms jw jx jy mt ka kb kc mu ke kf kg mv ki kj kk ij bi translated">备忘单中的所有方程返回[0，1]范围内的不确定性分数，其中 1 是最不确定的。许多学术论文没有对分数进行标准化，所以你可能会在上面的论文中看到不同的方程。但是，我建议您为任何用于非研究目的的代码实现规范化的[0–1]等式:[ 0–1]范围使下游处理、单元测试和抽查结果更容易。</p><p id="12da" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">本文和 GitHub 库中共享的代码都是开源的，所以请使用它来入门！</p><p id="43f6" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">罗伯特·芒罗</p><p id="371e" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">2019 年 7 月</p></div></div>    
</body>
</html>