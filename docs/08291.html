<html>
<head>
<title>A Simple Guide to Using Keras Pretrained Models</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用 Keras 预训练模型的简单指南</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/step-by-step-guide-to-using-pretrained-models-in-keras-c9097b647b29?source=collection_archive---------5-----------------------#2019-11-12">https://towardsdatascience.com/step-by-step-guide-to-using-pretrained-models-in-keras-c9097b647b29?source=collection_archive---------5-----------------------#2019-11-12</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><figure class="gl gn jr js jt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi jq"><img src="../Images/832aefb7c17a7c512e081f9b8e5f8541.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*T6cln2B2hWqwiCudGyUzYQ.jpeg"/></div></div><figcaption class="kb kc gj gh gi kd ke bd b be z dk">Image by <a class="ae kf" href="https://www.pexels.com/photo/brown-book-page-1112048/" rel="noopener ugc nofollow" target="_blank">Wendy</a></figcaption></figure><p id="654c" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">Keras 包含 10 个用于图像分类的预训练模型，这些模型是在<a class="ae kf" href="http://www.image-net.org/" rel="noopener ugc nofollow" target="_blank"> <strong class="ki iu"> Imagenet </strong> </a>数据上训练的。Imagenet 是一个包含 1000 种图像的大型图像数据集合。这些预训练的模型能够对落入这 1000 个图像类别中的任何图像进行分类。</p><p id="644d" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">本指南将涵盖以下概念。</p><ul class=""><li id="56b6" class="le lf it ki b kj kk kn ko kr lg kv lh kz li ld lj lk ll lm bi translated"><strong class="ki iu">图像分类</strong>车型。</li><li id="8e9b" class="le lf it ki b kj ln kn lo kr lp kv lq kz lr ld lj lk ll lm bi translated">在 Keras 中使用经过预训练的<strong class="ki iu">型号。</strong></li><li id="a486" class="le lf it ki b kj ln kn lo kr lp kv lq kz lr ld lj lk ll lm bi translated">将我们自己的<strong class="ki iu">分类器</strong>附加到预训练的模型上。</li><li id="7465" class="le lf it ki b kj ln kn lo kr lp kv lq kz lr ld lj lk ll lm bi translated"><strong class="ki iu">预训练模型中的输入形状</strong>。</li><li id="6098" class="le lf it ki b kj ln kn lo kr lp kv lq kz lr ld lj lk ll lm bi translated">使用<strong class="ki iu">池化</strong>。</li><li id="3753" class="le lf it ki b kj ln kn lo kr lp kv lq kz lr ld lj lk ll lm bi translated"><strong class="ki iu">冻结预应变模型中的</strong>层。</li><li id="7ff1" class="le lf it ki b kj ln kn lo kr lp kv lq kz lr ld lj lk ll lm bi translated">使用<strong class="ki iu">预训练模型的特定</strong>层。</li></ul><h1 id="1054" class="ls lt it bd lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk ml mm mn mo mp bi translated">图像分类模型</h1><p id="73b3" class="pw-post-body-paragraph kg kh it ki b kj mq kl km kn mr kp kq kr ms kt ku kv mt kx ky kz mu lb lc ld im bi translated">简单来说，图像分类模型如下所示。</p><figure class="mw mx my mz gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi mv"><img src="../Images/ccfdc3086ee52f303a109d830f5e57b7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*aoNqrxNzIWnMe0-LdVQ_RQ.png"/></div></div><figcaption class="kb kc gj gh gi kd ke bd b be z dk">Pretrained Model</figcaption></figure><p id="b9e5" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">其包含<strong class="ki iu">卷积</strong>层，随后是<strong class="ki iu">全连接</strong>层。卷积层从图像中提取特征，全连接层使用提取的特征对图像进行分类。</p><p id="f5fb" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">当我们在图像数据上训练一个<strong class="ki iu"> CNN </strong>时，可以看到网络的顶层学会从图像中提取<strong class="ki iu">一般</strong>特征，如边缘、颜色分布等。随着我们在网络中不断深入，各层往往会提取更多的特定特征。</p><p id="a768" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">现在，我们可以使用这些已经知道如何提取特征的预训练模型，避免从头开始训练。这个概念被称为<strong class="ki iu">迁移学习</strong>。</p></div><div class="ab cl na nb hx nc" role="separator"><span class="nd bw bk ne nf ng"/><span class="nd bw bk ne nf ng"/><span class="nd bw bk ne nf"/></div><div class="im in io ip iq"><h1 id="feed" class="ls lt it bd lu lv nh lx ly lz ni mb mc md nj mf mg mh nk mj mk ml nl mn mo mp bi translated">使用预训练模型</h1><p id="1486" class="pw-post-body-paragraph kg kh it ki b kj mq kl km kn mr kp kq kr ms kt ku kv mt kx ky kz mu lb lc ld im bi translated">在 Keras 中有两种创建模型的方法。一个是<strong class="ki iu">顺序</strong>模型，另一个是<strong class="ki iu">功能 API </strong>。顺序模型是层的线性堆叠。您可以通过调用<code class="fe nm nn no np b">add</code>方法简单地在顺序模型中添加层。另一个是 functional API，它允许您创建可能包含多个输入和输出的更复杂的模型。</p><p id="daa7" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在本指南中，我将使用<strong class="ki iu"> VGG16 </strong>预训练模型的例子。我们可以类似地使用其他预训练模型。</p><p id="3ced" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">Keras 的<strong class="ki iu">应用</strong>模块中提供了所有预训练模型。首先，我们必须导入预训练的模型，如下所示。</p><pre class="mw mx my mz gt nq np nr ns aw nt bi"><span id="6b4a" class="nu lt it np b gy nv nw l nx ny">from keras.applications.vgg16 import VGG16</span></pre><p id="696d" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">然后我们可以像下面这样添加预训练的模型，或者在<strong class="ki iu">顺序</strong>模型或者<strong class="ki iu">功能 API </strong>中。</p><figure class="mw mx my mz gt ju gh gi paragraph-image"><div class="gh gi nz"><img src="../Images/1c0f927dca6c117312b9d2045c5df9f6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1126/format:webp/1*_Oexibuc-cNf4YSKhv5HsQ.png"/></div><figcaption class="kb kc gj gh gi kd ke bd b be z dk">VGG in Sequential Model</figcaption></figure><figure class="mw mx my mz gt ju gh gi paragraph-image"><div class="gh gi oa"><img src="../Images/790bf7d8c07f6363e81d23a6e1c1cf3d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1118/format:webp/1*jsUOUiOoay-Lsyh6f2W4Hg.png"/></div><figcaption class="kb kc gj gh gi kd ke bd b be z dk">VGG in Functional API</figcaption></figure><p id="0b99" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">要使用预训练的权重，我们必须将参数<code class="fe nm nn no np b">weights</code>设置为<code class="fe nm nn no np b">imagenet</code>。默认值也被设置为<code class="fe nm nn no np b">imagenet</code>。但是如果我们想从头开始训练模型，我们可以将<code class="fe nm nn no np b">weights</code>参数设置为<code class="fe nm nn no np b">None</code>。这将在网络中随机初始化权重。</p></div><div class="ab cl na nb hx nc" role="separator"><span class="nd bw bk ne nf ng"/><span class="nd bw bk ne nf ng"/><span class="nd bw bk ne nf"/></div><div class="im in io ip iq"><h1 id="09a5" class="ls lt it bd lu lv nh lx ly lz ni mb mc md nj mf mg mh nk mj mk ml nl mn mo mp bi translated">附加我们自己的分类器</h1><p id="d97a" class="pw-post-body-paragraph kg kh it ki b kj mq kl km kn mr kp kq kr ms kt ku kv mt kx ky kz mu lb lc ld im bi translated">我们可以移除默认分类器，并在预训练模型中附加我们自己的分类器。为了排除默认分类器，我们必须将参数<code class="fe nm nn no np b">include_top</code>设置为<code class="fe nm nn no np b">false</code>。</p><p id="4274" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在下面的例子中，我从 VGG 移除默认分类器，然后附加我自己的分类器，这只是一个<code class="fe nm nn no np b">dense</code>层。我们还必须在添加一个<code class="fe nm nn no np b">dense</code>层之前添加一个<code class="fe nm nn no np b">flatten</code>层，将卷积层的 4D 输出转换为 2D，因为<code class="fe nm nn no np b">dense</code>层接受 2D 输入。</p><figure class="mw mx my mz gt ju gh gi paragraph-image"><div class="gh gi ob"><img src="../Images/4a9cb954f446190f205976469205a4db.png" data-original-src="https://miro.medium.com/v2/resize:fit:1136/format:webp/1*fsnYeOLGsvnY3YEqG5JoWg.png"/></div><figcaption class="kb kc gj gh gi kd ke bd b be z dk">Attaching a Classifier</figcaption></figure></div><div class="ab cl na nb hx nc" role="separator"><span class="nd bw bk ne nf ng"/><span class="nd bw bk ne nf ng"/><span class="nd bw bk ne nf"/></div><div class="im in io ip iq"><h1 id="449e" class="ls lt it bd lu lv nh lx ly lz ni mb mc md nj mf mg mh nk mj mk ml nl mn mo mp bi translated">输入形状</h1><p id="7a19" class="pw-post-body-paragraph kg kh it ki b kj mq kl km kn mr kp kq kr ms kt ku kv mt kx ky kz mu lb lc ld im bi translated">VGG16 在大小为<code class="fe nm nn no np b">(224, 224)</code>的 RGB 图像上训练，这是网络的默认输入大小。我们也可以输入默认尺寸以外的图像。但是图像的高度和宽度应该超过 32 像素。当我们从网络中排除默认分类器时，我们只能馈送其他大小的图像。以下是显示<code class="fe nm nn no np b">(32, 64, 3)</code>输入尺寸的示例。最后一个维度是 3，表示颜色通道的数量。</p><figure class="mw mx my mz gt ju gh gi paragraph-image"><div class="gh gi ob"><img src="../Images/b95b6f843d23098c94e8a30281b92a8e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1136/format:webp/1*5OduD87Tu1s-lUhpHqwV4w.png"/></div><figcaption class="kb kc gj gh gi kd ke bd b be z dk">Changing input shape</figcaption></figure><p id="e371" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我们也可以通过提供<strong class="ki iu">输入张量</strong>来定义输入形状，如下例所示。</p><figure class="mw mx my mz gt ju gh gi paragraph-image"><div class="gh gi nz"><img src="../Images/d2b87c95837ed529e47744c6d4ef5002.png" data-original-src="https://miro.medium.com/v2/resize:fit:1126/format:webp/1*0cNxzy_MNVfGjYCX0YU6NQ.png"/></div><figcaption class="kb kc gj gh gi kd ke bd b be z dk">Input Tensor</figcaption></figure><p id="f3c0" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我们可以注意到，当我们提供有意义的较小尺寸的图像时，输出维度也被压缩。</p></div><div class="ab cl na nb hx nc" role="separator"><span class="nd bw bk ne nf ng"/><span class="nd bw bk ne nf ng"/><span class="nd bw bk ne nf"/></div><div class="im in io ip iq"><h1 id="0495" class="ls lt it bd lu lv nh lx ly lz ni mb mc md nj mf mg mh nk mj mk ml nl mn mo mp bi translated">联营</h1><p id="c774" class="pw-post-body-paragraph kg kh it ki b kj mq kl km kn mr kp kq kr ms kt ku kv mt kx ky kz mu lb lc ld im bi translated">我们可以对卷积层的最终输出应用两种类型的池。<strong class="ki iu">全球平均统筹</strong>和<strong class="ki iu">全球最高统筹</strong>。</p><p id="5cc3" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在全局最大池中，我们在张量的每张幻灯片上选择一个最大值，如下图所示。</p><figure class="mw mx my mz gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi oc"><img src="../Images/66e0d73a27aa2a89f866342c18078996.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*lcZTSrV3s3KRxCpwi2WJrQ.png"/></div></div><figcaption class="kb kc gj gh gi kd ke bd b be z dk">Global Maximum Pooling</figcaption></figure><p id="329d" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">假设卷积层的输出张量具有形状<code class="fe nm nn no np b">(7, 7, 512)</code>。如果我们应用全局最大池，我们从每张<code class="fe nm nn no np b">(7, 7)</code>幻灯片中选择一个最大数字，这样我们总共有 512 个数字。平均池做同样的事情，除了取平均值而不是最大值。</p><p id="b60f" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">为了使用池，我们必须将参数<code class="fe nm nn no np b">pooling</code>设置为<code class="fe nm nn no np b">max</code>或<code class="fe nm nn no np b">avg</code>来使用这 2 个池。在下面的例子中，我使用的是全局平均池。</p><figure class="mw mx my mz gt ju gh gi paragraph-image"><div class="gh gi od"><img src="../Images/f7e0f30b83ba69e2507c5c1c3b90dc1c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1288/format:webp/1*e18Op4fkELhOpPQCVjaAfg.png"/></div><figcaption class="kb kc gj gh gi kd ke bd b be z dk">Global Average Pooling</figcaption></figure><p id="809c" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">当我们有一个<strong class="ki iu">可变</strong>大小的输入图像时，全局池是有用的。假设我们从不同大小的图像中得到 2 个不同大小的输出张量。输出张量的形状是<code class="fe nm nn no np b">(3, 3, 512)</code>和<code class="fe nm nn no np b">(7, 7, 512)</code>。在对这些张量中的任何一个应用全局池后，我们将得到一个长度为 512 的固定大小的向量。因此，在应用全局池后，可变大小图像的最终输出仍然是固定大小的向量。</p></div><div class="ab cl na nb hx nc" role="separator"><span class="nd bw bk ne nf ng"/><span class="nd bw bk ne nf ng"/><span class="nd bw bk ne nf"/></div><div class="im in io ip iq"><h1 id="5ecc" class="ls lt it bd lu lv nh lx ly lz ni mb mc md nj mf mg mh nk mj mk ml nl mn mo mp bi translated">冻结层</h1><p id="9d0e" class="pw-post-body-paragraph kg kh it ki b kj mq kl km kn mr kp kq kr ms kt ku kv mt kx ky kz mu lb lc ld im bi translated">在训练网络之前，你可能想根据任务冻结一些层。一旦层被冻结，其权重在训练时不会更新。</p><p id="2f3d" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在下面的例子中，我冻结了网络的前 10 层。我已经打印了网络中的所有层，以及它们是否可训练。我们可以看到只有前 10 层是不可训练的。</p><figure class="mw mx my mz gt ju gh gi paragraph-image"><div class="gh gi oe"><img src="../Images/464b093c9a60c857614b384bc5f079a5.png" data-original-src="https://miro.medium.com/v2/resize:fit:974/format:webp/1*kkwnw5jw7V7NkYCegeMTBQ.png"/></div><figcaption class="kb kc gj gh gi kd ke bd b be z dk">Freezing top 10 layers</figcaption></figure><p id="5941" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">如果当前数据集与训练这些网络的数据集相似，则最好冻结所有图层，因为两个数据集中的影像具有相似的要素。但是如果数据集不同，那么我们应该只冻结顶层并训练底层，因为顶层提取一般特征。数据集越相似，我们应该冻结的层就越多。</p></div><div class="ab cl na nb hx nc" role="separator"><span class="nd bw bk ne nf ng"/><span class="nd bw bk ne nf ng"/><span class="nd bw bk ne nf"/></div><div class="im in io ip iq"><h1 id="e230" class="ls lt it bd lu lv nh lx ly lz ni mb mc md nj mf mg mh nk mj mk ml nl mn mo mp bi translated">使用特定层</h1><p id="c00d" class="pw-post-body-paragraph kg kh it ki b kj mq kl km kn mr kp kq kr ms kt ku kv mt kx ky kz mu lb lc ld im bi translated">在上面的例子中，我们可以看到模型包含的所有层。我们也可以单独选择这些层中的任何一个，并在我们的模型中使用它们。</p><p id="8f8a" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在下面的例子中，我将第三层预训练模型<code class="fe nm nn no np b">(block1_conv2)</code>添加到顺序模型中。</p><figure class="mw mx my mz gt ju gh gi paragraph-image"><div class="gh gi of"><img src="../Images/68dd9ebd8286f6046316e0292e4ad7da.png" data-original-src="https://miro.medium.com/v2/resize:fit:1174/format:webp/1*C1xID5AySiZoIwK-2P8eSw.png"/></div><figcaption class="kb kc gj gh gi kd ke bd b be z dk">Adding a specific layer</figcaption></figure></div><div class="ab cl na nb hx nc" role="separator"><span class="nd bw bk ne nf ng"/><span class="nd bw bk ne nf ng"/><span class="nd bw bk ne nf"/></div><div class="im in io ip iq"><p id="cbd4" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">这几乎涵盖了在 Keras 中使用预训练模型时需要了解的所有用例。谢谢你的时间。</p></div></div>    
</body>
</html>