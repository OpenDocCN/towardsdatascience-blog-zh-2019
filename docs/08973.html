<html>
<head>
<title>Eigenvectors and Eigenvalues — All you need to know</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">特征向量和特征值——你需要知道的一切</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/eigenvectors-and-eigenvalues-all-you-need-to-know-df92780c591f?source=collection_archive---------1-----------------------#2019-11-30">https://towardsdatascience.com/eigenvectors-and-eigenvalues-all-you-need-to-know-df92780c591f?source=collection_archive---------1-----------------------#2019-11-30</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><figure class="gl gn jr js jt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi jq"><img src="../Images/1658b6cd265ff565500fb8bd2e72dfc0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*UdLhNthp1kQvLoSUTdpzmg.png"/></div></div><figcaption class="kb kc gj gh gi kd ke bd b be z dk">Image by joiom - <a class="ae kf" href="https://pixabay.com/illustrations/seamless-pattern-background-seamless-1822616/" rel="noopener ugc nofollow" target="_blank">https://pixabay.com/illustrations/seamless-pattern-background-seamless-1822616/</a></figcaption></figure><h1 id="bfee" class="kg kh it bd ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld bi translated">“Eigen”——词的起源</h1><p id="2894" class="pw-post-body-paragraph le lf it lg b lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">"<a class="ae kf" href="https://www.dictionary.com/browse/eigen-" rel="noopener ugc nofollow" target="_blank"> Eigen </a>"是一个德语单词，意思是“自己的”、“合适的”或“有特点的”。</p><h1 id="12a6" class="kg kh it bd ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld bi translated">什么是特征向量和特征值？</h1><p id="415e" class="pw-post-body-paragraph le lf it lg b lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">让我们看看<a class="ae kf" href="https://en.wikipedia.org/wiki/Eigenvalues_and_eigenvectors" rel="noopener ugc nofollow" target="_blank">维基百科</a>对特征向量和特征值有什么说法:</p><blockquote class="mc md me"><p id="147d" class="le lf mf lg b lh mg lj lk ll mh ln lo mi mj lr ls mk ml lv lw mm mn lz ma mb im bi translated">如果<em class="it"> T </em>是从向量空间<em class="it"> V </em>经过<a class="ae kf" href="https://en.wikipedia.org/wiki/Field_(mathematics)" rel="noopener ugc nofollow" target="_blank">域</a> <em class="it"> F </em>到自身的线性变换并且<strong class="lg iu"> v </strong>是<em class="it"> V </em>中不是<a class="ae kf" href="https://en.wikipedia.org/wiki/Zero_vector" rel="noopener ugc nofollow" target="_blank">零向量</a>的向量，那么<strong class="lg iu"> v </strong>是<em class="it"> T </em>的<strong class="lg iu">特征向量</strong>如果<em class="it">T</em>(这个条件可以写成如下等式</p><p id="296b" class="le lf mf lg b lh mg lj lk ll mh ln lo mi mj lr ls mk ml lv lw mm mn lz ma mb im bi translated"><strong class="lg iu"> T ( v ) = λ v </strong></p><p id="3039" class="le lf mf lg b lh mg lj lk ll mh ln lo mi mj lr ls mk ml lv lw mm mn lz ma mb im bi translated">其中<em class="it"> λ </em>是<em class="it"> F </em>域中的标量，称为<strong class="lg iu">特征值</strong>、<strong class="lg iu">特征值</strong>，或者与特征向量<strong class="lg iu"> v </strong>相关联的<strong class="lg iu">特征根</strong>。</p></blockquote><p id="7810" class="pw-post-body-paragraph le lf it lg b lh mg lj lk ll mh ln lo lp mj lr ls lt ml lv lw lx mn lz ma mb im bi translated">看起来很困惑，对吧？我们先分解一下，了解什么是线性变换。</p><h1 id="014b" class="kg kh it bd ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld bi translated">线性变换</h1><p id="d3fa" class="pw-post-body-paragraph le lf it lg b lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">假设 A 是一个 m×n 大小的矩阵。给定一个向量</p><figure class="mp mq mr ms gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi mo"><img src="../Images/02a6f941241ca2229e4d19b308b5f171.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*VwMy5RfeGyFx7hlsXFnJhQ.png"/></div></div></figure><p id="3f15" class="pw-post-body-paragraph le lf it lg b lh mg lj lk ll mh ln lo lp mj lr ls lt ml lv lw lx mn lz ma mb im bi translated">那么 t 是从 R^n 到 R^m 的线性变换</p><p id="93f6" class="pw-post-body-paragraph le lf it lg b lh mg lj lk ll mh ln lo lp mj lr ls lt ml lv lw lx mn lz ma mb im bi translated">这是怎么用的？假设您想要沿 x 轴将 2d 向量缩放 2 倍，沿 y 轴缩放 3 倍。假设向量 v 是[1，4]，那么在缩放之后它应该是[2，12]。这可以通过以下方式完成:</p><figure class="mp mq mr ms gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi mt"><img src="../Images/cedc44b9dcf74107a111d12a41e1ce11.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*CaXRoB4sy64Sv56mcnchBQ.png"/></div></div></figure><p id="d0dd" class="pw-post-body-paragraph le lf it lg b lh mg lj lk ll mh ln lo lp mj lr ls lt ml lv lw lx mn lz ma mb im bi translated">对于一个向量来说，这可能看起来微不足道。但是假设您有 n 个想要缩放的 2d 向量，您可以通过一次矩阵乘法操作一次转换所有这些向量。线性变换广泛应用于计算机图形学、游戏引擎、统计学等领域。</p><p id="0e57" class="pw-post-body-paragraph le lf it lg b lh mg lj lk ll mh ln lo lp mj lr ls lt ml lv lw lx mn lz ma mb im bi translated">这种操作不仅仅限于缩放，我们还可以将线性变换矩阵用于翻转矢量、旋转矢量、剪切矢量等。如果你对这个话题感到不舒服，我推荐你看一下 3Blue1Brown 关于线性变换的教程。</p><figure class="mp mq mr ms gt ju"><div class="bz fp l di"><div class="mu mv l"/></div></figure><h1 id="4c18" class="kg kh it bd ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld bi translated"><strong class="ak">回到特征向量和特征值</strong></h1><p id="1119" class="pw-post-body-paragraph le lf it lg b lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">假设我们在 2d 空间中有一个正方形，正方形上的每个点都是一个向量，我将只使用 3 个向量，如下所示。</p><figure class="mp mq mr ms gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi mw"><img src="../Images/d5a9efc59b57b22b0028576b5f21c746.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*bBg6jb4QbHe_VoW18LOFhA.png"/></div></div></figure><p id="a964" class="pw-post-body-paragraph le lf it lg b lh mg lj lk ll mh ln lo lp mj lr ls lt ml lv lw lx mn lz ma mb im bi translated">假设我们沿着 y 轴将正方形缩放 2 倍，如下所示</p><figure class="mp mq mr ms gt ju gh gi paragraph-image"><div class="gh gi mx"><img src="../Images/6c6dd9dd2b36d91cbddd37901f9fc5b0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1280/1*ds77YP-cwWDk8CapcRpBXg.gif"/></div><figcaption class="kb kc gj gh gi kd ke bd b be z dk">Scaling by a factor of 2 along y-axis</figcaption></figure><p id="244d" class="pw-post-body-paragraph le lf it lg b lh mg lj lk ll mh ln lo lp mj lr ls lt ml lv lw lx mn lz ma mb im bi translated">如果你注意到<em class="mf">红色</em> <em class="mf">矢量</em>在线性变换后具有相同的比例和方向。<em class="mf">绿色矢量</em>的比例发生变化，但方向仍然相同。而<em class="mf">黄色向量</em>既没有相同的比例，也增加了与 x 轴的角度，因此其方向也改变了。如果我们仔细观察，除了红色矢量<em class="mf">和绿色矢量<em class="mf">之外，其他所有矢量的方向都改变了。因此我们可以说红色和绿色向量是特殊的，它们是这个线性变换的<strong class="lg iu">特征</strong> <strong class="lg iu">。这些向量被称为该线性变换的<strong class="lg iu">特征向量</strong>。并且它们由于变换而在尺度上的变化被称为它们的<strong class="lg iu">特征值</strong>。其中对于<em class="mf">红色矢量</em>的特征值是 1，因为它的比例在变换前后是恒定的，而对于<em class="mf">绿色矢量</em>，它的特征值是 2，因为它放大了 2 倍。</strong></em></em></p><p id="60bf" class="pw-post-body-paragraph le lf it lg b lh mg lj lk ll mh ln lo lp mj lr ls lt ml lv lw lx mn lz ma mb im bi translated">让我们看看另一个线性变换，我们沿着 x 轴剪切正方形。</p><figure class="mp mq mr ms gt ju gh gi paragraph-image"><div class="gh gi mx"><img src="../Images/e5abb5fcbc361cf560b0e070992a77ec.png" data-original-src="https://miro.medium.com/v2/resize:fit:1280/1*h3qLWqnEJCKdb3mj30V3tQ.gif"/></div><figcaption class="kb kc gj gh gi kd ke bd b be z dk">Shear along x-axis</figcaption></figure><p id="38ee" class="pw-post-body-paragraph le lf it lg b lh mg lj lk ll mh ln lo lp mj lr ls lt ml lv lw lx mn lz ma mb im bi translated">如果你猜红色向量是本征向量，你猜对了，它的本征值是 1。</p><p id="4cdb" class="pw-post-body-paragraph le lf it lg b lh mg lj lk ll mh ln lo lp mj lr ls lt ml lv lw lx mn lz ma mb im bi translated">如果我们顺时针旋转这个正方形 90 度。</p><figure class="mp mq mr ms gt ju gh gi paragraph-image"><div class="gh gi mx"><img src="../Images/ac73c71d1270f5bbcc645c21037f90ef.png" data-original-src="https://miro.medium.com/v2/resize:fit:1280/1*2UJ_HfJkbj5gaYmiprYQ9A.gif"/></div><figcaption class="kb kc gj gh gi kd ke bd b be z dk">Rotate by 90 degrees clockwise</figcaption></figure><p id="6ac1" class="pw-post-body-paragraph le lf it lg b lh mg lj lk ll mh ln lo lp mj lr ls lt ml lv lw lx mn lz ma mb im bi translated">这里没有特征向量(学术人士会认为这种情况下有复杂的特征向量，但这已经超出了本文的范围，所以为了简单起见，我们还是坚持没有特征向量的情况)。如果我们把正方形旋转 180 度，而不是 90 度。</p><figure class="mp mq mr ms gt ju gh gi paragraph-image"><div class="gh gi mx"><img src="../Images/93daa4d98073a4c8f6cb9092d0570289.png" data-original-src="https://miro.medium.com/v2/resize:fit:1280/1*WYbLuVWJC_72SrCxWysbdQ.gif"/></div><figcaption class="kb kc gj gh gi kd ke bd b be z dk">Rotate by 180 degrees clockwise</figcaption></figure><p id="08c8" class="pw-post-body-paragraph le lf it lg b lh mg lj lk ll mh ln lo lp mj lr ls lt ml lv lw lx mn lz ma mb im bi translated">这里所有的向量和三个彩色向量都是特征值为-1 的特征向量。</p><p id="badd" class="pw-post-body-paragraph le lf it lg b lh mg lj lk ll mh ln lo lp mj lr ls lt ml lv lw lx mn lz ma mb im bi translated">让我们来看一个特例，我们沿着 x 轴和 y 轴相等地缩放正方形。</p><figure class="mp mq mr ms gt ju gh gi paragraph-image"><div class="gh gi mx"><img src="../Images/ad6cc59b77b98384cece54bd102a8ba2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1280/1*dRU7gtiFJe2gWlCl8HBIEA.gif"/></div><figcaption class="kb kc gj gh gi kd ke bd b be z dk">Scaling equally along x and y axis</figcaption></figure><p id="1ac9" class="pw-post-body-paragraph le lf it lg b lh mg lj lk ll mh ln lo lp mj lr ls lt ml lv lw lx mn lz ma mb im bi translated">这里所有的向量都是特征向量，它们的特征值就是比例因子。</p><p id="3fec" class="pw-post-body-paragraph le lf it lg b lh mg lj lk ll mh ln lo lp mj lr ls lt ml lv lw lx mn lz ma mb im bi translated">现在让我们回到<a class="ae kf" href="https://en.wikipedia.org/wiki/Eigenvalues_and_eigenvectors" rel="noopener ugc nofollow" target="_blank">维基百科对特征向量和特征值的</a>定义:</p><blockquote class="mc md me"><p id="d6ed" class="le lf mf lg b lh mg lj lk ll mh ln lo mi mj lr ls mk ml lv lw mm mn lz ma mb im bi translated">如果<em class="it"> T </em>是从向量空间<em class="it"> V </em>经过<a class="ae kf" href="https://en.wikipedia.org/wiki/Field_(mathematics)" rel="noopener ugc nofollow" target="_blank">域</a>F 到自身的线性变换，并且<strong class="lg iu"> v </strong>是<em class="it"> V </em>中不是<a class="ae kf" href="https://en.wikipedia.org/wiki/Zero_vector" rel="noopener ugc nofollow" target="_blank">零向量</a>的向量，那么<strong class="lg iu"> v </strong>是<em class="it"> T </em>的<strong class="lg iu">特征向量</strong>如果<em class="it"> T </em>这个条件可以写成如下等式</p><p id="f928" class="le lf mf lg b lh mg lj lk ll mh ln lo mi mj lr ls mk ml lv lw mm mn lz ma mb im bi translated"><strong class="lg iu"> T ( v ) = λ v </strong></p><p id="4158" class="le lf mf lg b lh mg lj lk ll mh ln lo mi mj lr ls mk ml lv lw mm mn lz ma mb im bi translated">其中<em class="it"> λ </em>是域<em class="it"> F </em>中的标量，称为与特征向量<strong class="lg iu"> v </strong>相关联的<strong class="lg iu">特征值</strong>、<strong class="lg iu">特征值</strong>或<strong class="lg iu">特征根</strong>。</p></blockquote><p id="b4af" class="pw-post-body-paragraph le lf it lg b lh mg lj lk ll mh ln lo lp mj lr ls lt ml lv lw lx mn lz ma mb im bi translated">让我们看看这个等式是如何工作的，在第一种情况下，我们沿着 y 轴将一个正方形缩放了 2 倍，其中<em class="mf">红色向量</em>和<em class="mf">绿色向量是</em>特征向量。</p><figure class="mp mq mr ms gt ju gh gi paragraph-image"><div class="gh gi mx"><img src="../Images/6c6dd9dd2b36d91cbddd37901f9fc5b0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1280/1*ds77YP-cwWDk8CapcRpBXg.gif"/></div><figcaption class="kb kc gj gh gi kd ke bd b be z dk">Scaling by a factor of 2 along y axis</figcaption></figure><p id="a5c1" class="pw-post-body-paragraph le lf it lg b lh mg lj lk ll mh ln lo lp mj lr ls lt ml lv lw lx mn lz ma mb im bi translated">线性变换前:</p><figure class="mp mq mr ms gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi my"><img src="../Images/018e8d6e2ceb23bfff3e6794c3b36b44.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*mICZqG4NMORY3byK5kyUDw.png"/></div></div></figure><p id="4d66" class="pw-post-body-paragraph le lf it lg b lh mg lj lk ll mh ln lo lp mj lr ls lt ml lv lw lx mn lz ma mb im bi translated">线性变换后:</p><figure class="mp mq mr ms gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi mz"><img src="../Images/c6b53bb2e595e681268c29db732f938c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Fdz5fIJ8htvZFE8Avp9MDg.png"/></div></div></figure><p id="3352" class="pw-post-body-paragraph le lf it lg b lh mg lj lk ll mh ln lo lp mj lr ls lt ml lv lw lx mn lz ma mb im bi translated">我们可以使用下面的等式显示线性变换后的结果:</p><figure class="mp mq mr ms gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi na"><img src="../Images/ca6a5ca53c272364a9b5bbd4c36c7d87.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*oGgXLGKNPkWjyWnZzlRoJw.png"/></div></div></figure><figure class="mp mq mr ms gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi nb"><img src="../Images/7696920df1237883c02d99b392e5f057.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*FYJqbGoxHDrjmnDMjyksNg.png"/></div></div></figure><figure class="mp mq mr ms gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi nc"><img src="../Images/973387bf9226c2b76e4f5848cada692a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*YKfEn3etYCe-IIfsnu0IJg.png"/></div></div></figure><p id="0737" class="pw-post-body-paragraph le lf it lg b lh mg lj lk ll mh ln lo lp mj lr ls lt ml lv lw lx mn lz ma mb im bi translated">让我们把这个问题扩大到三维。假设我们沿着 z 轴旋转一个立方体，那么沿着 z 轴的向量就是特征值为 1 的特征向量。</p><p id="f703" class="pw-post-body-paragraph le lf it lg b lh mg lj lk ll mh ln lo lp mj lr ls lt ml lv lw lx mn lz ma mb im bi translated">如果我们超过 3 维，就很难想象和计算出特征向量。即使在 2d 或 3d 中的某些情况下，也不是那么容易。那么我们如何计算特征向量呢？</p><p id="daa4" class="pw-post-body-paragraph le lf it lg b lh mg lj lk ll mh ln lo lp mj lr ls lt ml lv lw lx mn lz ma mb im bi translated">我们知道对于任何特征向量 v，</p><figure class="mp mq mr ms gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi na"><img src="../Images/ca6a5ca53c272364a9b5bbd4c36c7d87.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*oGgXLGKNPkWjyWnZzlRoJw.png"/></div></div></figure><p id="b1c5" class="pw-post-body-paragraph le lf it lg b lh mg lj lk ll mh ln lo lp mj lr ls lt ml lv lw lx mn lz ma mb im bi translated">假设变换矩阵是 a。因此，</p><figure class="mp mq mr ms gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi nd"><img src="../Images/a7774d180d381a23b38c0d186edc0c56.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*w_7MdlwzOP7wzIlp0tGXhA.png"/></div></div></figure><p id="d6ee" class="pw-post-body-paragraph le lf it lg b lh mg lj lk ll mh ln lo lp mj lr ls lt ml lv lw lx mn lz ma mb im bi translated">从以上两个等式我们可以推断出，</p><figure class="mp mq mr ms gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi ne"><img src="../Images/65b82d8022d1bec12257b655c1c7451d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*CqcxnuEbIkg2mpbNxs-rWA.png"/></div></div></figure><p id="2ea4" class="pw-post-body-paragraph le lf it lg b lh mg lj lk ll mh ln lo lp mj lr ls lt ml lv lw lx mn lz ma mb im bi translated">将这些术语放在一起，</p><figure class="mp mq mr ms gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi nf"><img src="../Images/4191d3c56518d7a649bafd9058cc9800.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*fDRrXfrtQvqiH79q-8YMHw.png"/></div></div></figure><p id="bddb" class="pw-post-body-paragraph le lf it lg b lh mg lj lk ll mh ln lo lp mj lr ls lt ml lv lw lx mn lz ma mb im bi translated">现在λ只是一个标量。因为 A 是一个矩阵，如果我们能把它转换成一个矩阵，我们就可以把 v 作为一个公式化。为此，我们可以将λ乘以单位矩阵 I。因此，</p><figure class="mp mq mr ms gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi ng"><img src="../Images/a094d32d6650dab24405c314b6211f73.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*T9AWjAuFNZlKqwJ2hretpA.png"/></div></div></figure><p id="9153" class="pw-post-body-paragraph le lf it lg b lh mg lj lk ll mh ln lo lp mj lr ls lt ml lv lw lx mn lz ma mb im bi translated">现在，对于右侧的 0，要么(A-λI)应该是 0，要么/和 v 应该是 0。但是如果你还记得特征向量的定义，它是非零向量。所以(A-λI)应该总是 0，v 才是特征向量。我们可以通过计算矩阵的行列式来计算矩阵运算是否为 0。</p><p id="3098" class="pw-post-body-paragraph le lf it lg b lh mg lj lk ll mh ln lo lp mj lr ls lt ml lv lw lx mn lz ma mb im bi translated">因此，</p><figure class="mp mq mr ms gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi nh"><img src="../Images/c42eebd77e6e0433b57d33279c42b6ae.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*uZOnRolRurIwWydyrJtyhA.png"/></div></div></figure><p id="f2ea" class="pw-post-body-paragraph le lf it lg b lh mg lj lk ll mh ln lo lp mj lr ls lt ml lv lw lx mn lz ma mb im bi translated">让我们用同样的例子来看看这是否可行，即沿着 y 轴将一个正方形缩放 2 倍。</p><p id="344a" class="pw-post-body-paragraph le lf it lg b lh mg lj lk ll mh ln lo lp mj lr ls lt ml lv lw lx mn lz ma mb im bi translated">这里，变换矩阵 A 可以表示为:</p><figure class="mp mq mr ms gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi ni"><img src="../Images/8815e9fbe5613595d4da8684376f81c0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*6rLiWifgyhtAocokh7ehfw.png"/></div></div></figure><p id="6516" class="pw-post-body-paragraph le lf it lg b lh mg lj lk ll mh ln lo lp mj lr ls lt ml lv lw lx mn lz ma mb im bi translated">现在我们知道了，</p><figure class="mp mq mr ms gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi nj"><img src="../Images/8494ac644d5bca1fa23dd01ef55c0a82.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*6QQaDGZsEXghmrA-niobKg.png"/></div></div></figure><p id="0236" class="pw-post-body-paragraph le lf it lg b lh mg lj lk ll mh ln lo lp mj lr ls lt ml lv lw lx mn lz ma mb im bi translated">输入 A 的值并进一步求解:</p><figure class="mp mq mr ms gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi nk"><img src="../Images/e990929492ed3f7836b26ce428b54920.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*OqaM96kJd-drMr6aNSqg3w.png"/></div></div></figure><p id="9d7c" class="pw-post-body-paragraph le lf it lg b lh mg lj lk ll mh ln lo lp mj lr ls lt ml lv lw lx mn lz ma mb im bi translated">我们知道，</p><figure class="mp mq mr ms gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi nl"><img src="../Images/ea11d4d0663293b388d297af498a91e8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*c83loED-Yw3v0zpYSd8xzA.png"/></div></div></figure><p id="e96b" class="pw-post-body-paragraph le lf it lg b lh mg lj lk ll mh ln lo lp mj lr ls lt ml lv lw lx mn lz ma mb im bi translated">求解λ = 1，我们得到:</p><figure class="mp mq mr ms gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi nm"><img src="../Images/484c96b199c92e8f0c4f8ba748caa2b2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*7E4es9UnJz4tU5mcVdExRw.png"/></div></div></figure><p id="c2b7" class="pw-post-body-paragraph le lf it lg b lh mg lj lk ll mh ln lo lp mj lr ls lt ml lv lw lx mn lz ma mb im bi translated">这意味着对于 v2=0 任何向量，该向量是特征值为 1 的特征向量。对于任何垂直矢量都是如此，在我们的例子中是红色矢量。</p><p id="7276" class="pw-post-body-paragraph le lf it lg b lh mg lj lk ll mh ln lo lp mj lr ls lt ml lv lw lx mn lz ma mb im bi translated">求解λ = 2，我们得到:</p><figure class="mp mq mr ms gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi nn"><img src="../Images/239d7bfb4e019d6ec2523d1eca7563e2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*tKbFSMSNiwJ_wrS-j-0-Qg.png"/></div></div></figure><p id="d87c" class="pw-post-body-paragraph le lf it lg b lh mg lj lk ll mh ln lo lp mj lr ls lt ml lv lw lx mn lz ma mb im bi translated">这意味着对于 v1=0 任何向量，该向量是特征值为 2 的特征向量。对于任何垂直矢量都是如此，在我们的例子中就是<em class="mf">绿色矢量。</em></p><h1 id="770e" class="kg kh it bd ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld bi translated">特征向量的重要性</h1><p id="b674" class="pw-post-body-paragraph le lf it lg b lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">特征值在数学中如此重要的原因太多了。以下是我现在想到的一些应用:</p><ul class=""><li id="454e" class="no np it lg b lh mg ll mh lp nq lt nr lx ns mb nt nu nv nw bi translated">主成分分析在降维和目标/图像识别中的应用。(参见<a class="ae kf" href="https://en.wikipedia.org/wiki/Principal_component_analysis" rel="noopener ugc nofollow" target="_blank"> PCA </a></li><li id="7a81" class="no np it lg b lh nx ll ny lp nz lt oa lx ob mb nt nu nv nw bi translated">通过计算图像的特征向量进行人脸识别(见<a class="ae kf" href="http://en.wikipedia.org/wiki/Eigenface" rel="noopener ugc nofollow" target="_blank">特征脸</a>)。</li><li id="d57c" class="no np it lg b lh nx ll ny lp nz lt oa lx ob mb nt nu nv nw bi translated">物理学——稳定性分析，旋转体的物理学(见<a class="ae kf" href="https://en.wikipedia.org/wiki/Stability_theory" rel="noopener ugc nofollow" target="_blank">稳定性理论</a>)。</li><li id="2fc6" class="no np it lg b lh nx ll ny lp nz lt oa lx ob mb nt nu nv nw bi translated">谷歌用它来为你的搜索结果排名页面<a class="ae kf" href="http://en.wikipedia.org/wiki/PageRank" rel="noopener ugc nofollow" target="_blank">(见 PageRank </a>)。</li></ul><h1 id="bda6" class="kg kh it bd ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld bi translated">实际的失误</h1><p id="240e" class="pw-post-body-paragraph le lf it lg b lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">华盛顿州的<a class="ae kf" href="https://en.wikipedia.org/wiki/Tacoma_Narrows_Bridge" rel="noopener ugc nofollow" target="_blank">塔科马海峡大桥</a>在建造了 4 个月后于 1940 年倒塌。这被拍成电影，后来被戏称为“盖尔平”。</p><figure class="mp mq mr ms gt ju"><div class="bz fp l di"><div class="oc mv l"/></div></figure><p id="9040" class="pw-post-body-paragraph le lf it lg b lh mg lj lk ll mh ln lo lp mj lr ls lt ml lv lw lx mn lz ma mb im bi translated">它的崩溃可以用特征值来解释。在许多大学物理教科书中，该事件被描述为基本强迫共振的例子，风提供了与自然结构频率相匹配的外部周期频率，即使桥梁故障的真正原因是气动弹性颤振，而不是共振。不要进入辩论，坚持这个博客的目的是解释特征向量和特征值，这个自然频率可以用最小幅度的特征值来表征。</p><p id="20e3" class="pw-post-body-paragraph le lf it lg b lh mg lj lk ll mh ln lo lp mj lr ls lt ml lv lw lx mn lz ma mb im bi translated">我希望你现在理解了特征向量和特征值背后的理论。如果你想获得更多关于特征向量的直觉，我推荐这个视频教程</p><figure class="mp mq mr ms gt ju"><div class="bz fp l di"><div class="mu mv l"/></div></figure></div></div>    
</body>
</html>