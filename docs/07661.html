<html>
<head>
<title>Text Data Augmentation makes your model stronger</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">文本数据扩充使您的模型更强大</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/text-data-augmentation-makes-your-model-stronger-7232bd23704?source=collection_archive---------18-----------------------#2019-10-24">https://towardsdatascience.com/text-data-augmentation-makes-your-model-stronger-7232bd23704?source=collection_archive---------18-----------------------#2019-10-24</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="a71d" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">使用马尔可夫链生成文本数据，以提高模型性能</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/5db4c7d856bc23780f1e2d8d5c76f261.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*DBce-yi56w1ymdTF"/></div></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk">Photo by <a class="ae ky" href="https://unsplash.com/@julsssy?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Julienne Erika Alviar</a> on <a class="ae ky" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><p id="8745" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">文本分类算法对训练中存在的多样性极其敏感。一个健壮的 NLP 流水线必须考虑到低质量数据存在的可能性，并试图以最好的方式解决这个问题。</p><p id="a5df" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">处理图像时，加强分类算法和引入多样性的标准方法是操作数据扩充。现在有很多漂亮和聪明的技术来操作自动图像增强。在自然语言处理任务中，文本数据扩充的方法并不常见，结果也不明确。</p><p id="5a16" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在这篇文章中，我将展示一个简单直观的技术来执行文本数据生成。使用马尔可夫链规则，我们将能够生成新的文本样本来填充我们的模型并测试其性能。</p><h1 id="8489" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">数据集</h1><p id="aac0" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">我从卡格尔那里得到了我们实验的数据。<a class="ae ky" href="https://www.kaggle.com/purvank/uber-rider-reviews-dataset" rel="noopener ugc nofollow" target="_blank">优步骑行评论数据集</a>是 2014-2017 年期间发布的骑行评论集，从网上搜集而来。在里面，我们可以找到原始的文字评论、用户给出的乘坐评级(1-5)和乘坐感受(如果评级高于 3:感受为 1，否则为 0)。如你所见，这是一个不平衡的分类问题，骑行评论的分布偏向于正面评价。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ms"><img src="../Images/666904efcf1be97f15428f3b1b83fae4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ViuEnwq5KKgFInYU12jirw.png"/></div></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk">Label Distributions: the reviews with ‘3 stars Ride Rating’ are excluded from the analysis</figcaption></figure><p id="3bb4" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">首先，我们的目标是预测适合和尝试不同架构的评论的情绪。最有趣的一点发生在第二阶段，我们想给我们的模型施加压力；即我们让他们预测一些用马尔可夫链随机产生的虚假数据。我们想测试我们的模型是否足够稳定，以实现来自列车的足够的性能预测数据(在添加一些噪声之后)。如果一切正常，我们的模型应该不会有问题，在这个假数据上产生良好的结果，并有望提高测试性能，相反，我们需要重新审视训练过程。</p><h1 id="8f7e" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">文本数据扩充</h1><p id="d5a6" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">在开始训练程序之前，我们必须生成我们的假数据。都开始研究火车上复习长度的分布。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi mt"><img src="../Images/e3921b87a219259d31460c24c9283e1b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1070/format:webp/1*fbjrKJ8HflIXuX8yGAx-vQ.png"/></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk">Review Length Distribution</figcaption></figure><p id="86e2" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们必须存储这些信息，因为我们的新评论将有类似的长度分布。生成过程由两个阶段组成。第一种，我们“构建链”，即，我们接收文本集合(在我们的情况下是训练语料库)作为输入，并自动为每个单词记录语料库中存在的每个可能的后续单词。在第二阶段，我们可以简单地基于之前的链创建新的评论…我们从起始语料库的整个词汇中随机选择一个词(我们评论的开始)，并随机选择下面的新词进入其链。在这个决定的最后，我们准备从新选择的单词重新开始这个过程。一般来说，我们在模拟一个马尔可夫链过程，在这个过程中，为了建立一个新的评论，一个词的选择仅仅基于前一个词。</p><p id="28a6" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我在一个独特的函数(<em class="mu">生成器</em>)中集合了这两个阶段。该函数接收文本评论作为输入，带有相关标签，以及要生成的新实例的期望前缀数量(针对每个类)。原始长度分布是有用的，因为我们可以从中抽取评论的合理长度。</p><pre class="kj kk kl km gt mv mw mx my aw mz bi"><span id="dcc0" class="na lw it mw b gy nb nc l nd ne">def <strong class="mw iu">build_chain</strong>(texts):<br/>    <br/>    index = 1<br/>    chain = {}<br/>    <br/>    for text in texts:<br/>        <br/>        text = text.split()<br/>        for word in text[index:]:<br/>            key = text[index-1]<br/>            if key in chain:<br/>                chain[key].append(word)<br/>            else:<br/>                chain[key] = [word]<br/>            index += 1<br/>        <br/>        index = 1<br/>    <br/>    return chain</span><span id="709a" class="na lw it mw b gy nf nc l nd ne">def <strong class="mw iu">create_sentence</strong>(chain, lenght):<br/>    <br/>    start = random.choice(list(chain.keys()))<br/>    text = [start]</span><span id="3719" class="na lw it mw b gy nf nc l nd ne">    while len(text) &lt; lenght:<br/>        try:<br/>            after = random.choice(chain[start])<br/>            start = after<br/>            text.append(after)<br/>        except: #end of the sentence<br/>            #text.append('.')<br/>            start = random.choice(list(chain.keys()))<br/>    <br/>    return ' '.join(text)</span><span id="7602" class="na lw it mw b gy nf nc l nd ne">def <strong class="mw iu">Generator</strong>(x_train, y_train, rep, concat=False, seed=33):<br/>    <br/>    np.random.seed(seed)<br/>    <br/>    new_corpus, new_labels = [], []<br/>    <br/>    for i,lab in enumerate(np.unique(y_train)):</span><span id="b1c6" class="na lw it mw b gy nf nc l nd ne">        selected = x_train[y_train == lab]<br/>        chain = build_chain(selected)</span><span id="2511" class="na lw it mw b gy nf nc l nd ne">        sentences = []<br/>        for i in range(rep):<br/>            lenght = int(np.random.choice(lenghts, 1, p=freq))<br/>            sentences.append(create_sentence(chain, lenght))</span><span id="2f27" class="na lw it mw b gy nf nc l nd ne">        new_corpus.extend(sentences)<br/>        new_labels.extend([lab]*rep)<br/>    <br/>    if concat:<br/>        return list(x_train)+new_corpus, list(y_train)+new_labels<br/>    <br/>    return new_corpus, new_labels</span></pre><p id="29e1" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们需要带标签的文本作为输入，因为我们将生成过程分成不同的子过程:来自特定类的评论被选择来为同一类生成新的评论；因此，我们需要区分构建链和采样过程，以便为我们的预测模型生成真实的样本。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ng"><img src="../Images/f896fa7bbfe0b7e49b623e326a9e3677.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*t_xmvJ415hqBmc5e-2TCmA.png"/></div></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk">Example of randomly generated reviews. Don’t care about their literally meaning</figcaption></figure><h1 id="2ccf" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">模特们</h1><p id="8622" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">我们在训练和测试中分割初始数据集。我们用火车作为语料库来支持我们的生成器，并创建新的评论。我们生成 200 个(每个类 100 个)评论以形成新的独立测试集，并生成 600 个(每个类 300 个)评论以加强我们的训练集。我们的模型库由一个层感知器神经网络、一个逻辑回归和一个随机森林组成。培训过程分为两个阶段。首先，我们用原始训练拟合所有模型，并分别在测试和伪测试数据上检查性能。我们期望所有的模型都优于假测试数据，因为它们是从训练中生成的。其次，我们用强化训练重复我们的模型的拟合，并在我们的测试集上检查性能。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nh"><img src="../Images/b598c7a7bc59656a8b5e9db5b76bd2db.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*uiSP5iOlervA6m_8IhoBlg.png"/></div></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk">Performace report on the true test set</figcaption></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nh"><img src="../Images/ecef4a55b1ea4d816d3c9cf79178a54c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*jzvrolQkjSh_93CyGgXjXA.png"/></div></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk">Performace report on the fake test set</figcaption></figure><p id="522f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在第一阶段，测试数据的最佳模型是神经网络(AUC、precision、recall 和 f1 被报告为性能指标)，但令人惊讶的是，逻辑回归和随机森林在假测试中失败了！这表明我们的模型不太合适。我们再次尝试拟合模型，但这次我们使用强化训练集。在这一点上，所有模型在原始测试中的性能都有所提高，现在它们也开始在假数据上进行很好的推广。</p><h1 id="193c" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">摘要</h1><p id="9a40" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">在这篇文章中，我组装了一个简单的程序来生成假文本数据。当我们安装一个 NLP 分类器并想测试它的强度时，这种技术对我们很有用。如果我们的模型不能很好地分类来自训练的虚假数据，那么重新访问训练过程、调整超参数或直接在训练中添加这些数据是合适的。</p></div><div class="ab cl ni nj hx nk" role="separator"><span class="nl bw bk nm nn no"/><span class="nl bw bk nm nn no"/><span class="nl bw bk nm nn"/></div><div class="im in io ip iq"><p id="6bc3" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><a class="ae ky" href="https://github.com/cerlymarco/MEDIUM_NoteBook" rel="noopener ugc nofollow" target="_blank"> <strong class="lb iu">查看我的 GITHUB 回购</strong> </a></p><p id="37bf" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">保持联系:<a class="ae ky" href="https://www.linkedin.com/in/marco-cerliani-b0bba714b/" rel="noopener ugc nofollow" target="_blank"> Linkedin </a></p></div></div>    
</body>
</html>