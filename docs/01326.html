<html>
<head>
<title>Review: CRF-RNN — Conditional Random Fields as Recurrent Neural Networks (Semantic Segmentation)</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">综述:条件随机场-RNN——作为递归神经网络(语义分割)</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/review-crf-rnn-conditional-random-fields-as-recurrent-neural-networks-semantic-segmentation-a11eb6e40c8c?source=collection_archive---------3-----------------------#2019-03-03">https://towardsdatascience.com/review-crf-rnn-conditional-random-fields-as-recurrent-neural-networks-semantic-segmentation-a11eb6e40c8c?source=collection_archive---------3-----------------------#2019-03-03</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="da98" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">一种将 CRF 集成到端到端深度学习解决方案中的方法</h2></div><p id="ed9f" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi lb translated"><span class="l lc ld le bm lf lg lh li lj di">在</span>这个故事中，<strong class="kh ir"> CRF-RNN </strong>，<strong class="kh ir">条件随机场作为递归神经网络</strong>，由<strong class="kh ir">牛津大学</strong>，<strong class="kh ir">斯坦福大学</strong>，<strong class="kh ir">百度</strong>进行综述。CRF 是计算机视觉中最成功的图形模型之一。发现全卷积网络(<a class="ae lk" rel="noopener" target="_blank" href="/review-fcn-semantic-segmentation-eb8c9b50d2d1"> FCN </a>)输出的分割结果非常粗糙。因此，许多方法使用 CRF 作为后处理步骤来细化从网络获得的输出语义分割图，例如<a class="ae lk" rel="noopener" target="_blank" href="/review-deeplabv1-deeplabv2-atrous-convolution-semantic-segmentation-b51c5fbde92d">deeplab v1&amp;deeplab v2</a>，以具有更细粒度的分割结果。但是，CRF 的参数不与<a class="ae lk" rel="noopener" target="_blank" href="/review-fcn-semantic-segmentation-eb8c9b50d2d1"> FCN </a>一起训练。换句话说，<a class="ae lk" rel="noopener" target="_blank" href="/review-fcn-semantic-segmentation-eb8c9b50d2d1"> FCN </a>在训练中并不知道慢性肾衰竭。这可能会限制网络能力。</p><p id="ac88" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir">在 CRF-RNN 中，作者提出将 CRF 表述为 RNN，以便与</strong><a class="ae lk" rel="noopener" target="_blank" href="/review-fcn-semantic-segmentation-eb8c9b50d2d1"><strong class="kh ir">【FCN】</strong></a><strong class="kh ir">集成，以端到端的方式训练整个网络，以获得更好的结果</strong>。这是一篇<strong class="kh ir"> 2015 年 ICCV </strong>论文，引用超过<strong class="kh ir"> 1300 次</strong>。(<a class="ll lm ep" href="https://medium.com/u/aff72a0c1243?source=post_page-----a11eb6e40c8c--------------------------------" rel="noopener" target="_blank"> Sik-Ho Tsang </a> @中)</p></div><div class="ab cl ln lo hu lp" role="separator"><span class="lq bw bk lr ls lt"/><span class="lq bw bk lr ls lt"/><span class="lq bw bk lr ls"/></div><div class="ij ik il im in"><h1 id="8a6d" class="lu lv iq bd lw lx ly lz ma mb mc md me jw mf jx mg jz mh ka mi kc mj kd mk ml bi translated">CRF-RNN 现场演示</h1><p id="0ecb" class="pw-post-body-paragraph kf kg iq kh b ki mm jr kk kl mn ju kn ko mo kq kr ks mp ku kv kw mq ky kz la ij bi translated">作者们还为此制作了一个现场演示:</p><pre class="mr ms mt mu gt mv mw mx my aw mz bi"><span id="1e32" class="na lv iq mw b gy nb nc l nd ne"><a class="ae lk" href="http://www.robots.ox.ac.uk/~szheng/crfasrnndemo" rel="noopener ugc nofollow" target="_blank">http://www.robots.ox.ac.uk/~szheng/crfasrnndemo</a></span></pre><figure class="mr ms mt mu gt ng gh gi paragraph-image"><div role="button" tabindex="0" class="nh ni di nj bf nk"><div class="gh gi nf"><img src="../Images/bf7ae74abf512f8ac988ba6aa2e72a47.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*BUMq4jppl-OAtQiXCzf4Cg.png"/></div></div><figcaption class="nn no gj gh gi np nq bd b be z dk"><strong class="bd nr">We can try our own image from internet or upload our own</strong></figcaption></figure><p id="a4c1" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">以下是我的试验，这很有趣:</p><h2 id="347d" class="na lv iq bd lw ns nt dn ma nu nv dp me ko nw nx mg ks ny nz mi kw oa ob mk oc bi translated">奇迹</h2><figure class="mr ms mt mu gt ng gh gi paragraph-image"><div role="button" tabindex="0" class="nh ni di nj bf nk"><div class="gh gi od"><img src="../Images/dd037d3cf22983aac31a013f847c2873.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*a3oRyr_uu6oOA4ySkwWpyA.png"/></div></div><figcaption class="nn no gj gh gi np nq bd b be z dk"><strong class="bd nr">Marvel</strong></figcaption></figure><h2 id="11bf" class="na lv iq bd lw ns nt dn ma nu nv dp me ko nw nx mg ks ny nz mi kw oa ob mk oc bi translated">城市景观数据集</h2><figure class="mr ms mt mu gt ng gh gi paragraph-image"><div role="button" tabindex="0" class="nh ni di nj bf nk"><div class="gh gi oe"><img src="../Images/7bbe27be7e1a1fae73ad110746968a20.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*8eak6LLhvVOO3FwOLAUNpA.png"/></div></div><figcaption class="nn no gj gh gi np nq bd b be z dk"><strong class="bd nr">Cityscape Dataset</strong></figcaption></figure><h2 id="7ecc" class="na lv iq bd lw ns nt dn ma nu nv dp me ko nw nx mg ks ny nz mi kw oa ob mk oc bi translated">船和人</h2><figure class="mr ms mt mu gt ng gh gi paragraph-image"><div role="button" tabindex="0" class="nh ni di nj bf nk"><div class="gh gi of"><img src="../Images/8340c813122cbab8136cff54fe162c07.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*zKcyfLuSfJCMr8BREdnSSA.png"/></div></div><figcaption class="nn no gj gh gi np nq bd b be z dk"><strong class="bd nr">Boats &amp; Persons</strong></figcaption></figure><p id="619e" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这是相当准确的，当然，我也尝试了一些 CRF-RNN 不能工作。</p></div><div class="ab cl ln lo hu lp" role="separator"><span class="lq bw bk lr ls lt"/><span class="lq bw bk lr ls lt"/><span class="lq bw bk lr ls"/></div><div class="ij ik il im in"><h1 id="7146" class="lu lv iq bd lw lx ly lz ma mb mc md me jw mf jx mg jz mh ka mi kc mj kd mk ml bi translated">概述</h1><ol class=""><li id="8b86" class="og oh iq kh b ki mm kl mn ko oi ks oj kw ok la ol om on oo bi translated"><strong class="kh ir">条件随机场</strong></li><li id="1a3e" class="og oh iq kh b ki op kl oq ko or ks os kw ot la ol om on oo bi translated"><strong class="kh ir"> CRF 作为 CNN 进行一次迭代</strong></li><li id="ff39" class="og oh iq kh b ki op kl oq ko or ks os kw ot la ol om on oo bi translated"><strong class="kh ir"> CRF 为多次迭代的 RNN</strong></li><li id="0a32" class="og oh iq kh b ki op kl oq ko or ks os kw ot la ol om on oo bi translated"><strong class="kh ir">结果</strong></li></ol></div><div class="ab cl ln lo hu lp" role="separator"><span class="lq bw bk lr ls lt"/><span class="lq bw bk lr ls lt"/><span class="lq bw bk lr ls"/></div><div class="ij ik il im in"><h1 id="61ac" class="lu lv iq bd lw lx ly lz ma mb mc md me jw mf jx mg jz mh ka mi kc mj kd mk ml bi translated"><strong class="ak"> 1。条件随机场</strong></h1><figure class="mr ms mt mu gt ng gh gi paragraph-image"><div role="button" tabindex="0" class="nh ni di nj bf nk"><div class="gh gi ou"><img src="../Images/30ce07e814ddccb38798b05184bba8dd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*-lgwBj7KTh8His-4zMa17Q.png"/></div></div></figure><ul class=""><li id="feff" class="og oh iq kh b ki kj kl km ko ov ks ow kw ox la oy om on oo bi translated">CRF 的目的是基于每个位置本身的标签以及相邻位置的标签和位置来细化粗略输出。</li><li id="d2c0" class="og oh iq kh b ki op kl oq ko or ks os kw ot la oy om on oo bi translated"><strong class="kh ir">考虑全连通的成对 CRF </strong>。完全连接意味着所有位置都已连接，如上图中间所示。成对意味着连接成对连接。</li><li id="b4f8" class="og oh iq kh b ki op kl oq ko or ks os kw ot la oy om on oo bi translated">当我们讨论 CRF 时，我们在讨论如何最小化一个能量函数。这里，我们需要最小化标签分配的能量。我只是把能量当作一种成本函数。通过将最可能的标签分配给每个位置，我们可以获得更低的能量，即更低的成本，从而获得更高的精度。</li><li id="d485" class="og oh iq kh b ki op kl oq ko or ks os kw ot la oy om on oo bi translated">CRF 的特征在于以下形式的吉布斯分布:</li></ul><figure class="mr ms mt mu gt ng gh gi paragraph-image"><div class="gh gi oz"><img src="../Images/ec6ca77036e91ff25f72941f9090f40e.png" data-original-src="https://miro.medium.com/v2/resize:fit:642/format:webp/1*3UUPkagsiaxLx2yDn2FM2g.png"/></div></figure><ul class=""><li id="1ad9" class="og oh iq kh b ki kj kl km ko ov ks ow kw ox la oy om on oo bi translated">其中<em class="pa"> I </em>是输入。<em class="pa"> Xi </em>是位置<em class="pa"> i </em>处的随机变量，代表分配的标签。<em class="pa"> I </em>为简单起见被丢弃。<em class="pa"> E </em> ( <em class="pa"> x </em>)是能量函数，<em class="pa"> Z </em> ( <em class="pa"> I </em>)是配分函数，就是所有 exp(- <em class="pa"> E </em> ( <em class="pa"> x </em>)的和。</li><li id="1acd" class="og oh iq kh b ki op kl oq ko or ks os kw ot la oy om on oo bi translated">这个 CRF 分布<em class="pa"> P </em> ( <em class="pa"> X </em>)近似为<em class="pa"> Q </em> ( <em class="pa"> X </em>)，是独立<em class="pa">齐</em> ( <em class="pa"> Xi </em>)的乘积:</li></ul><figure class="mr ms mt mu gt ng gh gi paragraph-image"><div class="gh gi pb"><img src="../Images/48569c3edc8531262c18d17b0f7e5ffe.png" data-original-src="https://miro.medium.com/v2/resize:fit:378/format:webp/1*Z7SAtoDKfQTp-ssEuRl5QQ.png"/></div></figure><ul class=""><li id="e4c3" class="og oh iq kh b ki kj kl km ko ov ks ow kw ox la oy om on oo bi translated">在论文中，作者提到他们遵循[29]。(如有兴趣，请访问[29]。这是 2011 年 NIPS 的一篇论文，名为“在具有高斯边缘势的全连接 CRF 中的<a class="ae lk" href="https://arxiv.org/pdf/1210.5644.pdf" rel="noopener ugc nofollow" target="_blank">有效推断</a>”。)能量函数:</li></ul><figure class="mr ms mt mu gt ng gh gi paragraph-image"><div class="gh gi pc"><img src="../Images/61cd0b6f88dad128ab1645fc52a63d4f.png" data-original-src="https://miro.medium.com/v2/resize:fit:696/format:webp/1*Wv1GoeDKC9mWcF4n8JCMRQ.png"/></div></figure><ul class=""><li id="56da" class="og oh iq kh b ki kj kl km ko ov ks ow kw ox la oy om on oo bi translated"><strong class="kh ir">第一项，一元能量<em class="pa">ψu</em>(<em class="pa">Xi</em>)</strong>:<strong class="kh ir">如果标签分配与初始分类器不一致，则测量成本。</strong>一元表示每次只考虑单个位置的标签。</li><li id="e5eb" class="og oh iq kh b ki op kl oq ko or ks os kw ot la oy om on oo bi translated"><strong class="kh ir">第二项，成对能量<em class="pa">ψ</em>p(<em class="pa">Xi</em>，<em class="pa"> xj </em>):如果两个相似像素(例如相邻像素或具有相似颜色的像素)采用不同的标签，则测量成本:</strong></li></ul><figure class="mr ms mt mu gt ng gh gi paragraph-image"><div class="gh gi pd"><img src="../Images/def5b2b52495212519a29be1a2f2a881.png" data-original-src="https://miro.medium.com/v2/resize:fit:832/format:webp/1*AMTCPKabFp57JooCNocm6A.png"/></div></figure><ul class=""><li id="8b13" class="og oh iq kh b ki kj kl km ko ov ks ow kw ox la oy om on oo bi translated">其中<strong class="kh ir"> <em class="pa"> kG </em>是应用于特征向量的</strong> <strong class="kh ir">高斯核</strong>。特征向量可以是空间位置和 RGB 值，例如高斯滤波器和双边滤波器。</li><li id="ccf2" class="og oh iq kh b ki op kl oq ko or ks os kw ot la oy om on oo bi translated">并且<strong class="kh ir"> μ是标签兼容性函数</strong>，其在标签不同时分配惩罚。</li></ul><figure class="mr ms mt mu gt ng gh gi paragraph-image"><div class="gh gi pe"><img src="../Images/c63f840dc728f5662560dbaaf5f45566.png" data-original-src="https://miro.medium.com/v2/resize:fit:1100/format:webp/1*KVg99RSO_1w44zIA-bGAvw.png"/></div><figcaption class="nn no gj gh gi np nq bd b be z dk"><strong class="bd nr">End-to-end Trainable CRF-RNN</strong></figcaption></figure><ul class=""><li id="e386" class="og oh iq kh b ki kj kl km ko ov ks ow kw ox la oy om on oo bi translated">CRF 是一种非常强大的统计建模方法，应用于各种模式识别任务，如文本序列分类。我只能以非常简要的方式介绍本文中提到的通用报告格式。</li><li id="6c65" class="og oh iq kh b ki op kl oq ko or ks os kw ot la oy om on oo bi translated">简而言之，输入图像将通过<a class="ae lk" rel="noopener" target="_blank" href="/review-fcn-semantic-segmentation-eb8c9b50d2d1"> FCN </a>然后是 CRF。该 CRF 将考虑一元能量项和成对能量项，然后输出更精确的分割图。</li><li id="0052" class="og oh iq kh b ki op kl oq ko or ks os kw ot la oy om on oo bi translated">这个 CRF 是作为 CNN 的一个栈实现的，如下所示。</li></ul></div><div class="ab cl ln lo hu lp" role="separator"><span class="lq bw bk lr ls lt"/><span class="lq bw bk lr ls lt"/><span class="lq bw bk lr ls"/></div><div class="ij ik il im in"><h1 id="4890" class="lu lv iq bd lw lx ly lz ma mb mc md me jw mf jx mg jz mh ka mi kc mj kd mk ml bi translated"><strong class="ak"> 2。</strong> CRF 作为 CNN 进行一次迭代</h1><figure class="mr ms mt mu gt ng gh gi paragraph-image"><div class="gh gi pf"><img src="../Images/bb3f346cb892c38a510387e1f89f1285.png" data-original-src="https://miro.medium.com/v2/resize:fit:1068/format:webp/1*YjZKyG4k4Qwyv3ftcKljrQ.png"/></div></figure><h2 id="4d78" class="na lv iq bd lw ns nt dn ma nu nv dp me ko nw nx mg ks ny nz mi kw oa ob mk oc bi translated">初始化</h2><ul class=""><li id="7b63" class="og oh iq kh b ki mm kl mn ko oi ks oj kw ok la oy om on oo bi translated"><em class="pa"> Ui </em> ( <em class="pa"> l </em>)是基于<a class="ae lk" href="https://medium.com/coinmonks/paper-review-of-vggnet-1st-runner-up-of-ilsvlc-2014-image-classification-d02355543a11" rel="noopener"> VGG-16 </a>的 <a class="ae lk" rel="noopener" target="_blank" href="/review-fcn-semantic-segmentation-eb8c9b50d2d1"> <strong class="kh ir"> FCN-8s </strong> </a>提供的<strong class="kh ir">一元电位。</strong></li><li id="e3a1" class="og oh iq kh b ki op kl oq ko or ks os kw ot la oy om on oo bi translated">使用<strong class="kh ir"> softmax </strong>获得<em class="pa"> Qi </em> ( <em class="pa"> l </em>)。</li><li id="30fd" class="og oh iq kh b ki op kl oq ko or ks os kw ot la oy om on oo bi translated">初始化之后，将会有一系列流程的迭代(while 循环)。</li></ul><h2 id="6477" class="na lv iq bd lw ns nt dn ma nu nv dp me ko nw nx mg ks ny nz mi kw oa ob mk oc bi translated">信息传递</h2><ul class=""><li id="d600" class="og oh iq kh b ki mm kl mn ko oi ks oj kw ok la oy om on oo bi translated">使用 M 个高斯滤波器。</li><li id="b77c" class="og oh iq kh b ki op kl oq ko or ks os kw ot la oy om on oo bi translated">在[29]之后，<strong class="kh ir">使用两个高斯核</strong>，<strong class="kh ir">一个空间核和一个双边核</strong>。</li></ul><h2 id="8ebb" class="na lv iq bd lw ns nt dn ma nu nv dp me ko nw nx mg ks ny nz mi kw oa ob mk oc bi translated">加权滤波器输出</h2><ul class=""><li id="8dac" class="og oh iq kh b ki mm kl mn ko oi ks oj kw ok la oy om on oo bi translated">对于每个类别标签<em class="pa"> l </em>，上一步的<em class="pa"> M </em>滤波器输出的加权和。</li><li id="4ae6" class="og oh iq kh b ki op kl oq ko or ks os kw ot la oy om on oo bi translated">当每个标签被单独考虑时，它可以被视为具有<em class="pa"> M 个</em>输入通道和一个输出通道的<strong class="kh ir"> 1×1 卷积</strong>。</li><li id="6152" class="og oh iq kh b ki op kl oq ko or ks os kw ot la oy om on oo bi translated">与[29]相反，每个类标签使用单独的核权重。</li></ul><h2 id="a4a9" class="na lv iq bd lw ns nt dn ma nu nv dp me ko nw nx mg ks ny nz mi kw oa ob mk oc bi translated">兼容性转换</h2><ul class=""><li id="7ede" class="og oh iq kh b ki mm kl mn ko oi ks oj kw ok la oy om on oo bi translated">当分配不同的标签时，会分配一个罚分。</li><li id="661d" class="og oh iq kh b ki op kl oq ko or ks os kw ot la oy om on oo bi translated">例如:将标签“人”和“自行车”分配给附近的像素应该具有比分配标签“天空”和“自行车”更小的惩罚。</li><li id="0ff2" class="og oh iq kh b ki op kl oq ko or ks os kw ot la oy om on oo bi translated">这样，<strong class="kh ir"> <em class="pa"> μ </em> ( <em class="pa"> l </em>，<em class="pa">l’</em>)从数据</strong>中学习。</li></ul><h2 id="aded" class="na lv iq bd lw ns nt dn ma nu nv dp me ko nw nx mg ks ny nz mi kw oa ob mk oc bi translated">添加一元位势</h2><ul class=""><li id="9e46" class="og oh iq kh b ki mm kl mn ko oi ks oj kw ok la oy om on oo bi translated">兼容性转换步骤的输出是从一元输入<em class="pa">U</em>T45】中按元素减去<strong class="kh ir">。</strong></li></ul><h2 id="1f0c" class="na lv iq bd lw ns nt dn ma nu nv dp me ko nw nx mg ks ny nz mi kw oa ob mk oc bi translated">正常化</h2><ul class=""><li id="82c4" class="og oh iq kh b ki mm kl mn ko oi ks oj kw ok la oy om on oo bi translated">另一个<strong class="kh ir"> softmax </strong>操作。</li></ul><figure class="mr ms mt mu gt ng gh gi paragraph-image"><div role="button" tabindex="0" class="nh ni di nj bf nk"><div class="gh gi pg"><img src="../Images/9df409daf5ad989d7850b5e25b05e176.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*--nPlr7NVAt-AdqYER2SkQ.png"/></div></div><figcaption class="nn no gj gh gi np nq bd b be z dk"><strong class="bd nr">Fully connected CRFs as a CNN for one mean-field iteration</strong></figcaption></figure><ul class=""><li id="7bd7" class="og oh iq kh b ki kj kl km ko ov ks ow kw ox la oy om on oo bi translated">以上是一次平均场迭代的概述。</li><li id="1adc" class="og oh iq kh b ki op kl oq ko or ks os kw ot la oy om on oo bi translated">通过重复上述模块，我们可以进行多次平均场迭代。</li></ul></div><div class="ab cl ln lo hu lp" role="separator"><span class="lq bw bk lr ls lt"/><span class="lq bw bk lr ls lt"/><span class="lq bw bk lr ls"/></div><div class="ij ik il im in"><h1 id="db88" class="lu lv iq bd lw lx ly lz ma mb mc md me jw mf jx mg jz mh ka mi kc mj kd mk ml bi translated"><strong class="ak"> 3。将 CRF 作为多次迭代的 RNN</strong></h1><figure class="mr ms mt mu gt ng gh gi paragraph-image"><div role="button" tabindex="0" class="nh ni di nj bf nk"><div class="gh gi ph"><img src="../Images/895165277923510ef012d1ce872cac7e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*baA7Ymdj1cn0VrwgOmc0qw.png"/></div></div><figcaption class="nn no gj gh gi np nq bd b be z dk"><strong class="bd nr">CRF as RNN for Multiple Iterations</strong></figcaption></figure><ul class=""><li id="f753" class="og oh iq kh b ki kj kl km ko ov ks ow kw ox la oy om on oo bi translated"><em class="pa">我</em>就是形象。<em class="pa"> U </em>是来自<a class="ae lk" rel="noopener" target="_blank" href="/review-fcn-semantic-segmentation-eb8c9b50d2d1"> FCN </a>的一元电位。<em class="pa"> T </em>为总迭代次数。</li><li id="e820" class="og oh iq kh b ki op kl oq ko or ks os kw ot la oy om on oo bi translated"><strong class="kh ir"> <em class="pa"> fθ(U，H </em> 1( <em class="pa"> t </em>)，<em class="pa"> I </em>)是上一节所述的平均场迭代</strong>，其中<em class="pa"> θ </em>是上一节所述的 CRF 参数，即<em class="pa"> w </em>，<em class="pa"> μ </em>，<em class="pa"> m </em>，</li><li id="2f68" class="og oh iq kh b ki op kl oq ko or ks os kw ot la oy om on oo bi translated"><strong class="kh ir">在 t = 0 </strong>时，第一次迭代，<strong class="kh ir"><em class="pa">H</em>1(<em class="pa">t</em>)= soft max(<em class="pa">U</em>)</strong>，<strong class="kh ir">否则<em class="pa"> H </em> 1( <em class="pa"> t </em>)是前一次平均场迭代的输出，<strong class="kh ir"><em class="pa">H</em>2(<em class="pa">t</em>-1)</strong>。</strong></li><li id="5bc4" class="og oh iq kh b ki op kl oq ko or ks os kw ot la oy om on oo bi translated"><strong class="kh ir"><em class="pa">H</em>2(<em class="pa">t</em>)</strong>是平均场迭代 <em class="pa"> fθ(U，H</em>1(<em class="pa">t</em>)<em class="pa">I</em>)的<strong class="kh ir">输出。</strong></li><li id="c5b8" class="og oh iq kh b ki op kl oq ko or ks os kw ot la oy om on oo bi translated"><strong class="kh ir">最终输出，<em class="pa">Y</em>(<em class="pa">T</em>)=<em class="pa">H</em>2(<em class="pa">T</em>)当<em class="pa"> t </em> = <em class="pa"> T </em> </strong>时，即最后一次迭代结束时。</li><li id="d900" class="og oh iq kh b ki op kl oq ko or ks os kw ot la oy om on oo bi translated"><strong class="kh ir">使用递归神经网络(RNN) </strong>设置，即这里的<strong class="kh ir">参数在所有迭代</strong>中共享。</li><li id="dd65" class="og oh iq kh b ki op kl oq ko or ks os kw ot la oy om on oo bi translated">在<strong class="kh ir">训练</strong>时，<strong class="kh ir"> <em class="pa"> T </em> =5 </strong>用于避免消失/爆炸渐变问题。</li><li id="4b2e" class="og oh iq kh b ki op kl oq ko or ks os kw ot la oy om on oo bi translated">在<strong class="kh ir">测试</strong>期间，<strong class="kh ir"> <em class="pa"> T </em> =10 </strong>。</li></ul></div><div class="ab cl ln lo hu lp" role="separator"><span class="lq bw bk lr ls lt"/><span class="lq bw bk lr ls lt"/><span class="lq bw bk lr ls"/></div><div class="ij ik il im in"><h1 id="cd8e" class="lu lv iq bd lw lx ly lz ma mb mc md me jw mf jx mg jz mh ka mi kc mj kd mk ml bi translated">4.结果</h1><h2 id="6022" class="na lv iq bd lw ns nt dn ma nu nv dp me ko nw nx mg ks ny nz mi kw oa ob mk oc bi translated">4.1.帕斯卡 VOC</h2><figure class="mr ms mt mu gt ng gh gi paragraph-image"><div class="gh gi pi"><img src="../Images/eee9811ad21ba4561afb1ed7417040e1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1136/format:webp/1*6GcySdFD4PWl8qeqlX1DUA.png"/></div><figcaption class="nn no gj gh gi np nq bd b be z dk"><strong class="bd nr">Mean IU Accuracy on PASCAL VOC 2012 Validation Set</strong></figcaption></figure><ul class=""><li id="e1ae" class="og oh iq kh b ki kj kl km ko ov ks ow kw ox la oy om on oo bi translated">有/没有 COCO:模特是否也由 COCO 训练。</li><li id="4ebf" class="og oh iq kh b ki op kl oq ko or ks os kw ot la oy om on oo bi translated"><strong class="kh ir">平原</strong> <a class="ae lk" rel="noopener" target="_blank" href="/review-fcn-semantic-segmentation-eb8c9b50d2d1"> <strong class="kh ir"> FCN-8s </strong> </a>:平均 IU 精度最低。</li><li id="7581" class="og oh iq kh b ki op kl oq ko or ks os kw ot la oy om on oo bi translated"><strong class="kh ir">带 CRF 但断开</strong>:这意味着 CRF 不用<a class="ae lk" rel="noopener" target="_blank" href="/review-fcn-semantic-segmentation-eb8c9b50d2d1"> FCN </a>以端到端的方式训练，获得更高的平均 IU 精度</li><li id="7122" class="og oh iq kh b ki op kl oq ko or ks os kw ot la oy om on oo bi translated">端到端 CRF-RNN :获得了最高的平均 IU 精度，这意味着端到端<a class="ae lk" rel="noopener" target="_blank" href="/review-fcn-semantic-segmentation-eb8c9b50d2d1"> FCN </a> +CRF 是最佳解决方案。</li></ul><figure class="mr ms mt mu gt ng gh gi paragraph-image"><div class="gh gi pj"><img src="../Images/1f97adfeacbc4d654fa0930c345a3190.png" data-original-src="https://miro.medium.com/v2/resize:fit:1096/format:webp/1*6ySVRVqIUziE2GE9sQhaKw.png"/></div><figcaption class="nn no gj gh gi np nq bd b be z dk"><strong class="bd nr">Mean IU Accuracy on PASCAL VOC 2010, 2011, 2012 Test Set</strong></figcaption></figure><ul class=""><li id="5435" class="og oh iq kh b ki kj kl km ko ov ks ow kw ox la oy om on oo bi translated"><strong class="kh ir"> CRF-RNN w/o COCO </strong>:性能优于<a class="ae lk" rel="noopener" target="_blank" href="/review-fcn-semantic-segmentation-eb8c9b50d2d1"> FCN-8s </a>和<a class="ae lk" rel="noopener" target="_blank" href="/review-deeplabv1-deeplabv2-atrous-convolution-semantic-segmentation-b51c5fbde92d"> DeepLab-v1 </a>。</li><li id="5bdb" class="og oh iq kh b ki op kl oq ko or ks os kw ot la oy om on oo bi translated">有 COCO 的 CRF-RNN:效果更好。</li></ul><h2 id="d841" class="na lv iq bd lw ns nt dn ma nu nv dp me ko nw nx mg ks ny nz mi kw oa ob mk oc bi translated">4.2.PASCAL 上下文</h2><figure class="mr ms mt mu gt ng gh gi paragraph-image"><div class="gh gi pk"><img src="../Images/c7a1354c9d35943b1cf4c7010b3c34d3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1080/format:webp/1*tJ7LcOZl5iKSV9WE2OsXWA.png"/></div><figcaption class="nn no gj gh gi np nq bd b be z dk"><strong class="bd nr">Mean IU Accuracy on PASCAL Context Validation Set</strong></figcaption></figure><ul class=""><li id="b3a3" class="og oh iq kh b ki kj kl km ko ov ks ow kw ox la oy om on oo bi translated"><strong class="kh ir"> CRF-RNN </strong>:比<a class="ae lk" rel="noopener" target="_blank" href="/review-fcn-semantic-segmentation-eb8c9b50d2d1"> FCN-8s </a>更高的平均 IU 精度。</li></ul><h2 id="e6d3" class="na lv iq bd lw ns nt dn ma nu nv dp me ko nw nx mg ks ny nz mi kw oa ob mk oc bi translated">4.3.进一步分析</h2><ul class=""><li id="ca51" class="og oh iq kh b ki mm kl mn ko oi ks oj kw ok la oy om on oo bi translated">在 PASCAL VOC 2012 验证集上进行附加实验。</li><li id="cf86" class="og oh iq kh b ki op kl oq ko or ks os kw ot la oy om on oo bi translated">对不同等级使用不同的权重<em class="pa"> w </em>会增加 1.8%的平均 IU。</li><li id="d34a" class="og oh iq kh b ki op kl oq ko or ks os kw ot la oy om on oo bi translated">在训练和测试期间，T  =10 导致 0.7%的下降，这表明存在消失梯度效应。</li><li id="f06f" class="og oh iq kh b ki op kl oq ko or ks os kw ot la oy om on oo bi translated">每次迭代的独立参数而不是共享参数，仅获得 70.9%的平均 IU 准确度，这表明递归结构是重要的。</li></ul><h2 id="d1e7" class="na lv iq bd lw ns nt dn ma nu nv dp me ko nw nx mg ks ny nz mi kw oa ob mk oc bi translated">4.4.定性结果</h2><figure class="mr ms mt mu gt ng gh gi paragraph-image"><div role="button" tabindex="0" class="nh ni di nj bf nk"><div class="gh gi pl"><img src="../Images/bbf6d661f5855d2fdaa30a957dfe0b18.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*U51N_rd0El5M_-0TV2IKwA.png"/></div></div><figcaption class="nn no gj gh gi np nq bd b be z dk"><strong class="bd nr">Some Good Results on PASCAL VOC 2012</strong></figcaption></figure><figure class="mr ms mt mu gt ng gh gi paragraph-image"><div role="button" tabindex="0" class="nh ni di nj bf nk"><div class="gh gi pm"><img src="../Images/ccc22296e0b6e6c6c16543bef55d5caf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*avtul3X3SNMqFuMH7vkHSg.png"/></div></div><figcaption class="nn no gj gh gi np nq bd b be z dk"><strong class="bd nr">Comparison with State-of-the-art Approaches</strong></figcaption></figure></div><div class="ab cl ln lo hu lp" role="separator"><span class="lq bw bk lr ls lt"/><span class="lq bw bk lr ls lt"/><span class="lq bw bk lr ls"/></div><div class="ij ik il im in"><p id="0cc2" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">虽然 CRF-RNN 是在 2015 年发表的，但这篇论文向我介绍了一个重要的概念/逻辑，即把一个传统的/非深度学习的方法转换/近似为基于深度学习的方法，并把它变成一个端到端的解决方案。</p></div><div class="ab cl ln lo hu lp" role="separator"><span class="lq bw bk lr ls lt"/><span class="lq bw bk lr ls lt"/><span class="lq bw bk lr ls"/></div><div class="ij ik il im in"><h2 id="8832" class="na lv iq bd lw ns nt dn ma nu nv dp me ko nw nx mg ks ny nz mi kw oa ob mk oc bi translated">参考</h2><p id="d411" class="pw-post-body-paragraph kf kg iq kh b ki mm jr kk kl mn ju kn ko mo kq kr ks mp ku kv kw mq ky kz la ij bi translated">【2015 ICCV】【CRF-RNN】<br/><a class="ae lk" href="https://arxiv.org/abs/1502.03240" rel="noopener ugc nofollow" target="_blank">条件随机场作为递归神经网络</a></p><h2 id="c573" class="na lv iq bd lw ns nt dn ma nu nv dp me ko nw nx mg ks ny nz mi kw oa ob mk oc bi translated">我以前的评论</h2><p id="4da9" class="pw-post-body-paragraph kf kg iq kh b ki mm jr kk kl mn ju kn ko mo kq kr ks mp ku kv kw mq ky kz la ij bi translated">)(我)(们)(都)(不)(想)(到)(这)(些)(人)(,)(我)(们)(都)(不)(想)(要)(到)(这)(些)(人)(,)(但)(是)(这)(些)(人)(还)(不)(想)(到)(这)(些)(人)(,)(我)(们)(还)(没)(想)(到)(这)(些)(事)(,)(我)(们)(就)(想)(到)(了)(这)(些)(人)(们)(,)(我)(们)(们)(都)(不)(想)(要)(到)(这)(些)(人)(,)(但)(我)(们)(还)(没)(想)(到)(这)(些)(事)(,)(我)(们)(还)(没)(想)(想)(到)(这)(些)(事)(,)(我)(们)(还)(没)(想)(到)(这)(里)(去)(。 )(他)(们)(都)(不)(在)(这)(些)(事)(上)(,)(她)(们)(还)(不)(在)(这)(些)(事)(上)(有)(什)(么)(情)(况)(呢)(?)(她)(们)(都)(不)(在)(这)(些)(情)(况)(下)(,)(她)(们)(还)(是)(不)(在)(这)(些)(事)(上)(有)(什)(么)(情)(况)(吗)(?)(她)(们)(都)(不)(在)(这)(些)(事)(上)(,)(她)(们)(们)(还)(不)(在)(这)(些)(事)(上)(,)(她)(们)(们)(还)(不)(在)(这)(些)(事)(上)(有)(什)(么)(好)(的)(情)(情)(情)(况)(。</p><p id="8b77" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir">物体检测<br/></strong><a class="ae lk" href="https://medium.com/coinmonks/review-of-overfeat-winner-of-ilsvrc-2013-localization-task-object-detection-a6f8b9044754" rel="noopener">过食</a><a class="ae lk" href="https://medium.com/coinmonks/review-r-cnn-object-detection-b476aba290d1" rel="noopener">R-CNN</a><a class="ae lk" href="https://medium.com/coinmonks/review-fast-r-cnn-object-detection-a82e172e87ba" rel="noopener">快 R-CNN</a><a class="ae lk" rel="noopener" target="_blank" href="/review-faster-r-cnn-object-detection-f5685cb30202">快 R-CNN</a><a class="ae lk" rel="noopener" target="_blank" href="/review-deepid-net-def-pooling-layer-object-detection-f72486f1a0f6">DeepID-Net</a>】<a class="ae lk" rel="noopener" target="_blank" href="/review-craft-cascade-region-proposal-network-and-fast-r-cnn-object-detection-2ce987361858">CRAFT</a><a class="ae lk" rel="noopener" target="_blank" href="/review-r-fcn-positive-sensitive-score-maps-object-detection-91cd2389345c">R-FCN</a><a class="ae lk" rel="noopener" target="_blank" href="/review-ion-inside-outside-net-2nd-runner-up-in-2015-coco-detection-object-detection-da19993f4766">ION</a><a class="ae lk" rel="noopener" target="_blank" href="/review-multipath-mpn-1st-runner-up-in-2015-coco-detection-segmentation-object-detection-ea9741e7c413">multipath Net</a>【T21 [ <a class="ae lk" rel="noopener" target="_blank" href="/yolov1-you-only-look-once-object-detection-e1f3ffec8a89">约洛夫 1 </a> ] [ <a class="ae lk" rel="noopener" target="_blank" href="/review-yolov2-yolo9000-you-only-look-once-object-detection-7883d2b02a65">约洛夫 2 /约洛 9000 </a> ] [ <a class="ae lk" rel="noopener" target="_blank" href="/review-yolov3-you-only-look-once-object-detection-eab75d7a1ba6">约洛夫 3 </a> ] [ <a class="ae lk" rel="noopener" target="_blank" href="/review-fpn-feature-pyramid-network-object-detection-262fc7482610"> FPN </a> ] [ <a class="ae lk" rel="noopener" target="_blank" href="/review-retinanet-focal-loss-object-detection-38fba6afabe4">视网膜网</a> ] [ <a class="ae lk" rel="noopener" target="_blank" href="/review-dcn-deformable-convolutional-networks-2nd-runner-up-in-2017-coco-detection-object-14e488efce44"> DCN </a> ]</p><p id="6582" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir">语义切分<br/></strong><a class="ae lk" rel="noopener" target="_blank" href="/review-fcn-semantic-segmentation-eb8c9b50d2d1">FCN</a><a class="ae lk" rel="noopener" target="_blank" href="/review-deconvnet-unpooling-layer-semantic-segmentation-55cf8a6e380e">de convnet</a><a class="ae lk" rel="noopener" target="_blank" href="/review-deeplabv1-deeplabv2-atrous-convolution-semantic-segmentation-b51c5fbde92d">deeplab v1&amp;deeplab v2</a><a class="ae lk" rel="noopener" target="_blank" href="/review-segnet-semantic-segmentation-e66f2e30fb96">SegNet</a>】【parse net<a class="ae lk" rel="noopener" target="_blank" href="/review-dilated-convolution-semantic-segmentation-9d5a5bd768f5">dilated net</a><a class="ae lk" rel="noopener" target="_blank" href="/review-pspnet-winner-in-ilsvrc-2016-semantic-segmentation-scene-parsing-e089e5df177d">PSP net</a><a class="ae lk" rel="noopener" target="_blank" href="/review-deeplabv3-atrous-convolution-semantic-segmentation-6d818bfd1d74">deeplab v3</a><a class="ae lk" rel="noopener" target="_blank" href="/review-drn-dilated-residual-networks-image-classification-semantic-segmentation-d527e1a8fb5">DRN</a></p><p id="fc65" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir">生物医学图像分割<br/></strong><a class="ae lk" href="https://medium.com/datadriveninvestor/review-cumedvision1-fully-convolutional-network-biomedical-image-segmentation-5434280d6e6" rel="noopener">cumed vision 1</a><a class="ae lk" href="https://medium.com/datadriveninvestor/review-cumedvision2-dcan-winner-of-2015-miccai-gland-segmentation-challenge-contest-biomedical-878b5a443560" rel="noopener">cumed vision 2/DCAN</a><a class="ae lk" rel="noopener" target="_blank" href="/review-u-net-biomedical-image-segmentation-d02bf06ca760">U-Net</a><a class="ae lk" href="https://medium.com/datadriveninvestor/review-cfs-fcn-biomedical-image-segmentation-ae4c9c75bea6" rel="noopener">CFS-FCN</a><a class="ae lk" href="https://medium.com/datadriveninvestor/review-u-net-resnet-the-importance-of-long-short-skip-connections-biomedical-image-ccbf8061ff43" rel="noopener">U-Net+ResNet</a><a class="ae lk" rel="noopener" target="_blank" href="/review-multichannel-segment-colon-histology-images-biomedical-image-segmentation-d7e57902fbfc">多通道</a></p><p id="3134" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir"> 实例分段 <br/> </strong> <a class="ae lk" rel="noopener" target="_blank" href="/review-deepmask-instance-segmentation-30327a072339"> DeepMask </a> <a class="ae lk" rel="noopener" target="_blank" href="/review-sharpmask-instance-segmentation-6509f7401a61"> SharpMask </a> <a class="ae lk" rel="noopener" target="_blank" href="/review-multipath-mpn-1st-runner-up-in-2015-coco-detection-segmentation-object-detection-ea9741e7c413"> MultiPathNet </a> <a class="ae lk" rel="noopener" target="_blank" href="/review-mnc-multi-task-network-cascade-winner-in-2015-coco-segmentation-instance-segmentation-42a9334e6a34"> MNC </a> <a class="ae lk" rel="noopener" target="_blank" href="/review-instancefcn-instance-sensitive-score-maps-instance-segmentation-dbfe67d4ee92"> InstanceFCN </a> <a class="ae lk" rel="noopener" target="_blank" href="/review-fcis-winner-in-2016-coco-segmentation-instance-segmentation-ee2d61f465e2"> FCIS </a>】</p><p id="58de" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">)(我)(们)(都)(不)(知)(道)(,)(我)(们)(还)(是)(不)(知)(道)(,)(我)(们)(还)(是)(不)(知)(道)(,)(我)(们)(还)(是)(不)(知)(道)(,)(我)(们)(还)(是)(不)(知)(道)(,)(我)(们)(还)(是)(不)(知)(道)(,)(我)(们)(还)(是)(不)(知)(道)(。</p></div></div>    
</body>
</html>