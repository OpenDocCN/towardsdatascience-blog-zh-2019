<html>
<head>
<title>Multicollinearity — How does it create a problem?</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">多重共线性-它是如何产生问题的？</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/https-towardsdatascience-com-multicollinearity-how-does-it-create-a-problem-72956a49058?source=collection_archive---------11-----------------------#2019-08-09">https://towardsdatascience.com/https-towardsdatascience-com-multicollinearity-how-does-it-create-a-problem-72956a49058?source=collection_archive---------11-----------------------#2019-08-09</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="50d8" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">深入了解多重共线性如何影响模型的性能</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/0d03568e3ebb5ba4da3db4a0ac53b7e4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*y9rN9LBOp3fDp_LyuJWiKQ.jpeg"/></div></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk">Photo by <a class="ae kv" href="https://unsplash.com/@lukechesser?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank">Luke Chesser</a> on <a class="ae kv" href="https://unsplash.com/search/photos/stats?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><p id="be8a" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在回归分析过程中，我们在实际执行回归之前检查许多东西。我们检查独立值是否相关，我们检查我们选择的特征是否重要，以及是否有任何缺失值，如果是，那么如何处理它们。</p><p id="13b0" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">首先，让我们了解什么是因变量和自变量—</p><ol class=""><li id="a516" class="ls lt iq ky b kz la lc ld lf lu lj lv ln lw lr lx ly lz ma bi translated">因变量，回归过程中必须预测的值。也称为目标值。</li><li id="b6d8" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr lx ly lz ma bi translated">自变量，我们用来预测目标值或因变量的值。也被称为预测器。</li></ol><p id="aa77" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">如果我们有这样一个等式</p><pre class="kg kh ki kj gt mg mh mi mj aw mk bi"><span id="9485" class="ml mm iq mh b gy mn mo l mp mq">y = w*x</span></pre><p id="0af2" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这里，y 是因变量，w 是自变量。</p><p id="c28c" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我们稍后会看到它是如何被检测到的，但首先，让我们看看如果变量是相关的，会有什么问题。</p><h2 id="490c" class="ml mm iq bd mr ms mt dn mu mv mw dp mx lf my mz na lj nb nc nd ln ne nf ng nh bi translated">从概念上理解—</h2><p id="2b43" class="pw-post-body-paragraph kw kx iq ky b kz ni jr lb lc nj ju le lf nk lh li lj nl ll lm ln nm lp lq lr ij bi translated">想象你去观看一个摇滚乐队的音乐会。有两名歌手，一名鼓手，一名键盘手和两名吉他手。你很容易区分歌手的声音，因为一个是男性，另一个是女性，但你似乎很难分辨谁弹得更好。</p><p id="3da7" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">两个吉他手都以相同的音调、音高和速度演奏。如果你能去掉其中一个，那就不成问题了，因为两者几乎一样。</p><p id="6e0f" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">去掉一个吉他手的好处是降低成本，减少团队成员。在机器学习中，训练的特征越少，模型就越简单。</p><p id="4ac6" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这里两个吉他手共线。如果一个人弹吉他很慢，那么另一个吉他手也会弹得很慢。如果一个人弹得快，那么另一个人也弹得快。</p><p id="f0e7" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">如果两个变量共线，这意味着如果一个变量增加，那么另一个也增加，反之亦然。</p><h2 id="4f88" class="ml mm iq bd mr ms mt dn mu mv mw dp mx lf my mz na lj nb nc nd ln ne nf ng nh bi translated">数学上的理解—</h2><p id="f12a" class="pw-post-body-paragraph kw kx iq ky b kz ni jr lb lc nj ju le lf nk lh li lj nl ll lm ln nm lp lq lr ij bi translated">让我们考虑这个等式</p><p id="d8e9" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">考虑 A 和 B 是高度相关的。</p><pre class="kg kh ki kj gt mg mh mi mj aw mk bi"><span id="1ff6" class="ml mm iq mh b gy mn mo l mp mq">y = w1*A + w2*B</span></pre><p id="fe4a" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">系数 w1 是在保持 B 不变的情况下，A 每增加一个单位 y 的增加量。但是实际上这是不可能的，因为 A 和 B 是相关的，如果 A 增加一个单位，那么 B 也增加一个单位。因此，我们不能检查 A 或 b 的个人贡献。解决方案是删除他们中的任何一个。</p><h2 id="f4de" class="ml mm iq bd mr ms mt dn mu mv mw dp mx lf my mz na lj nb nc nd ln ne nf ng nh bi translated">检查多重共线性—</h2><p id="6f90" class="pw-post-body-paragraph kw kx iq ky b kz ni jr lb lc nj ju le lf nk lh li lj nl ll lm ln nm lp lq lr ij bi translated">通常有两种方法来检查多重共线性</p><ol class=""><li id="f3bb" class="ls lt iq ky b kz la lc ld lf lu lj lv ln lw lr lx ly lz ma bi translated">相关矩阵</li><li id="7969" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr lx ly lz ma bi translated">差异通货膨胀系数(VIF)</li></ol><p id="81f8" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir">相关矩阵—</strong><strong class="ky ir">相关矩阵</strong>是显示变量间<strong class="ky ir">相关</strong>系数的表格。</p><p id="281e" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我们不打算讨论相关矩阵是如何计算的。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nn no l"/></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk">create_correlation_matrix</figcaption></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi np"><img src="../Images/3169445c3a244d4bc299c230c76230db.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*ydSnOHeCMyuu91Ch.png"/></div></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk"><a class="ae kv" href="https://www.google.co.in/url?sa=i&amp;source=images&amp;cd=&amp;cad=rja&amp;uact=8&amp;ved=2ahUKEwi2rcf-jfTjAhXFbCsKHSTSCHYQjB16BAgBEAM&amp;url=http%3A%2F%2Fwww.sthda.com%2Fenglish%2Fwiki%2Fggplot2-quick-correlation-matrix-heatmap-r-software-and-data-visualization&amp;psig=AOvVaw2dwHr4ilqUXUzygcdOfSJz&amp;ust=1565382389179020" rel="noopener ugc nofollow" target="_blank">source</a></figcaption></figure><blockquote class="nq nr ns"><p id="5552" class="kw kx nt ky b kz la jr lb lc ld ju le nu lg lh li nv lk ll lm nw lo lp lq lr ij bi translated">我认为高于 0.75 的值是高度相关的。</p></blockquote><p id="170e" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir">方差膨胀因子— </strong>方差膨胀因子(VIF)是多项模型中的方差与单项模型中的方差之比。它量化了普通最小二乘回归分析中多重共线性的严重程度。VIF 值可以解释为</p><ol class=""><li id="c05c" class="ls lt iq ky b kz la lc ld lf lu lj lv ln lw lr lx ly lz ma bi translated">1(非共线)</li><li id="c68b" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr lx ly lz ma bi translated">1–5(中等共线)</li><li id="5ccd" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr lx ly lz ma bi translated">&gt; 5(高度共线)</li></ol><p id="0cb8" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">移除 VIF 值大于 5 的值。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nn no l"/></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk">VIF Python</figcaption></figure><h2 id="4c2f" class="ml mm iq bd mr ms mt dn mu mv mw dp mx lf my mz na lj nb nc nd ln ne nf ng nh bi translated">结论—</h2><p id="5204" class="pw-post-body-paragraph kw kx iq ky b kz ni jr lb lc nj ju le lf nk lh li lj nl ll lm ln nm lp lq lr ij bi translated">多重共线性会显著降低模型的性能，而我们可能不知道这一点。这是特征选择过程中非常重要的一步。移除多重共线性还可以减少要素，这最终会降低模型的复杂性，并且存储这些要素的开销也会减少。</p><p id="ef31" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">确保在执行任何回归分析之前运行多重共线性测试。</p></div></div>    
</body>
</html>