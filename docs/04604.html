<html>
<head>
<title>Linear Regression in 3 Steps</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">三步线性回归</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/machine-learning-in-python-numpy-part-2-linear-regression-in-3-steps-cad77bd92717?source=collection_archive---------26-----------------------#2019-07-14">https://towardsdatascience.com/machine-learning-in-python-numpy-part-2-linear-regression-in-3-steps-cad77bd92717?source=collection_archive---------26-----------------------#2019-07-14</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="c226" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">引入梯度下降</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/f2bc2391e15eb2565365f7450a197dc0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*EsB6177T5QNuioLi"/></div></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk">Photo by <a class="ae ky" href="https://unsplash.com/@charliefoster?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Charlie Foster</a> on <a class="ae ky" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><h1 id="92b4" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">动机</h1><p id="8eca" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">我们在本系列的第一部分<a class="ae ky" rel="noopener" target="_blank" href="/machine-learning-in-python-numpy-neural-network-in-9-steps-eafd0db25906"><strong class="lt iu"/></a>中的<strong class="lt iu"> <em class="mn"> 9 步</em> </strong>中演示了如何使用 Python NumPy 构建神经网络，但是对于初学者来说可能太难理解了。在这种情况下，我们将使用 NumPy 库来实现最简单的机器学习模型之一的<strong class="lt iu">线性回归</strong>。最好对微积分和 Python 语法有基本的了解(但不是必须的，因为你可以随时学习)。</p><p id="765d" class="pw-post-body-paragraph lr ls it lt b lu mo ju lw lx mp jx lz ma mq mc md me mr mg mh mi ms mk ml mm im bi translated"><em class="mn">代码在</em><a class="ae ky" href="https://github.com/edenau/ML-in-NumPy/blob/master/linear-regression.ipynb" rel="noopener ugc nofollow" target="_blank"><em class="mn">GitHub</em></a><em class="mn">上有。最初发布于</em><a class="ae ky" href="https://edenau.github.io/" rel="noopener ugc nofollow" target="_blank"><em class="mn">edenau . github . io</em></a><em class="mn">。</em></p></div><div class="ab cl mt mu hx mv" role="separator"><span class="mw bw bk mx my mz"/><span class="mw bw bk mx my mz"/><span class="mw bw bk mx my"/></div><div class="im in io ip iq"><h1 id="c4b3" class="kz la it bd lb lc na le lf lg nb li lj jz nc ka ll kc nd kd ln kf ne kg lp lq bi translated">1.初始化</h1><p id="60d5" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">第一步。导入 NumPy。说真的。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nf ng l"/></div></figure></div><div class="ab cl mt mu hx mv" role="separator"><span class="mw bw bk mx my mz"/><span class="mw bw bk mx my mz"/><span class="mw bw bk mx my"/></div><div class="im in io ip iq"><h1 id="707c" class="kz la it bd lb lc na le lf lg nb li lj jz nc ka ll kc nd kd ln kf ne kg lp lq bi translated">2.生成数据</h1><p id="800d" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">我们为标量输入<code class="fe nh ni nj nk b">X</code>及其对应的高斯<code class="fe nh ni nj nk b">noise</code>生成一万个点，这样对于一些固定的斜率<code class="fe nh ni nj nk b">w_true=7.6</code>和截距<code class="fe nh ni nj nk b">b_true=-3.3</code>，我们可以通过下面的线性关系生成<code class="fe nh ni nj nk b">y</code>。<code class="fe nh ni nj nk b">w_true</code>和<code class="fe nh ni nj nk b">b_true</code>的值完全是任意的。</p><pre class="kj kk kl km gt nl nk nm nn aw no bi"><span id="5d96" class="np la it nk b gy nq nr l ns nt">y = w_true * X + b_true + noise</span></pre><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nf ng l"/></div></figure><p id="7a84" class="pw-post-body-paragraph lr ls it lt b lu mo ju lw lx mp jx lz ma mq mc md me mr mg mh mi ms mk ml mm im bi translated">添加零均值高斯噪声使我们的数据更加真实。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nu"><img src="../Images/4c61722bc24cee200af8398f65a631a1.png" data-original-src="https://miro.medium.com/v2/resize:fit:760/format:webp/1*zoPjaoNFYFLlkWEZiXIb8w.png"/></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk">Data points (blue) and linear relationship without noise (red)</figcaption></figure></div><div class="ab cl mt mu hx mv" role="separator"><span class="mw bw bk mx my mz"/><span class="mw bw bk mx my mz"/><span class="mw bw bk mx my"/></div><div class="im in io ip iq"><h1 id="8484" class="kz la it bd lb lc na le lf lg nb li lj jz nc ka ll kc nd kd ln kf ne kg lp lq bi translated">3.梯度下降</h1><p id="1a96" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">实际上，我们不知道线性函数参数<code class="fe nh ni nj nk b">w</code>和<code class="fe nh ni nj nk b">b</code>的值，这就是梯度下降的由来。我们将误差函数<code class="fe nh ni nj nk b">e</code>定义为某些<code class="fe nh ni nj nk b">(w,b)</code>的实际<code class="fe nh ni nj nk b">y</code>和预测<code class="fe nh ni nj nk b">y=wx+b</code>之间的平方差的和<strong class="lt iu">。</strong></p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nv"><img src="../Images/8353b963ecad0b5875daa2a3c37df81a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*4owoDvUr2p7fs3dtjt4EGg@2x.png"/></div></div></figure><p id="eca1" class="pw-post-body-paragraph lr ls it lt b lu mo ju lw lx mp jx lz ma mq mc md me mr mg mh mi ms mk ml mm im bi translated">该误差函数惩罚实际值和预测值<code class="fe nh ni nj nk b">y</code>之间的不匹配。使用平方差代替绝对差<code class="fe nh ni nj nk b">||.||</code>，这样我们可以解析地计算<strong class="lt iu"> ∂e/∂w </strong>和<strong class="lt iu"> ∂e/∂b </strong>，这留给读者作为练习。<strong class="lt iu"> <em class="mn">这些渐变分别代表了</em> </strong> <code class="fe nh ni nj nk b"><strong class="lt iu"><em class="mn">w</em></strong></code> <strong class="lt iu"> <em class="mn">和</em> </strong> <code class="fe nh ni nj nk b"><strong class="lt iu"><em class="mn">b</em></strong></code> <strong class="lt iu"> <em class="mn">增加的方向。</em> </strong>因此，如果我们想<strong class="lt iu"> <em class="mn">减少</em> </strong>的误差<code class="fe nh ni nj nk b">e</code>，我们应该通过去导数的<strong class="lt iu"> <em class="mn">负方向</em> </strong>来更新参数。这可以表示为</p><pre class="kj kk kl km gt nl nk nm nn aw no bi"><span id="b1bb" class="np la it nk b gy nq nr l ns nt">w ← w - learning_rate * ∂e/∂w<br/>b ← b - learning_rate * ∂e/∂b<br/># The key is the minus signs</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nw"><img src="../Images/97f952687227beb3ab4ff9c55e52cf12.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*vKvXK4VWNN8vnXUu"/></div></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk">Photo by <a class="ae ky" href="https://unsplash.com/@bernardhermant?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Bernard Hermant</a> on <a class="ae ky" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><p id="973b" class="pw-post-body-paragraph lr ls it lt b lu mo ju lw lx mp jx lz ma mq mc md me mr mg mh mi ms mk ml mm im bi translated">如果我们迭代地进行这些更新，直到<code class="fe nh ni nj nk b">(w,b)</code>收敛，我们将得到一组最佳的参数，可以表示<code class="fe nh ni nj nk b">X</code>和<code class="fe nh ni nj nk b">y</code>之间的线性关系。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nf ng l"/></div></figure><h1 id="c939" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">外卖</h1><p id="c046" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">这是在<strong class="lt iu"> <em class="mn"> 3 步</em> </strong>中使用 NumPy 库的线性回归算法的最小实现。如果你想测试你对线性回归的理解，以下是你可能想尝试的事情:</p><ul class=""><li id="d604" class="nx ny it lt b lu mo lx mp ma nz me oa mi ob mm oc od oe of bi translated">使用其他库实现线性回归(在<a class="ae ky" href="https://github.com/edenau/ML-in-NumPy/blob/master/linear-regression.ipynb" rel="noopener ugc nofollow" target="_blank"> GitHub </a>和<em class="mn">上)</em></li><li id="36ce" class="nx ny it lt b lu og lx oh ma oi me oj mi ok mm oc od oe of bi translated">训练测试数据集拆分</li><li id="b994" class="nx ny it lt b lu og lx oh ma oi me oj mi ok mm oc od oe of bi translated">多输入特征</li><li id="9010" class="nx ny it lt b lu og lx oh ma oi me oj mi ok mm oc od oe of bi translated">非高斯分布噪声</li><li id="6d93" class="nx ny it lt b lu og lx oh ma oi me oj mi ok mm oc od oe of bi translated">不同的误差函数</li></ul><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ol"><img src="../Images/b5d5976694afd9844e25bb7a7d8e1859.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*ydIe6aYg9KjDufVj"/></div></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk">Photo by <a class="ae ky" href="https://unsplash.com/@ameenfahmy_?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Ameen Fahmy</a> on <a class="ae ky" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><p id="3ba2" class="pw-post-body-paragraph lr ls it lt b lu mo ju lw lx mp jx lz ma mq mc md me mr mg mh mi ms mk ml mm im bi translated">代码可在<a class="ae ky" href="https://github.com/edenau/ML-in-NumPy/blob/master/neural-net.ipynb" rel="noopener ugc nofollow" target="_blank"> Github </a>上获得。编码快乐！</p><h2 id="7a90" class="np la it bd lb om on dn lf oo op dp lj ma oq or ll me os ot ln mi ou ov lp ow bi translated">相关文章</h2><p id="5dd0" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">感谢您的阅读！如果您对机器学习或 Python 感兴趣，请查看以下文章:</p><div class="ox oy gp gr oz pa"><a rel="noopener follow" target="_blank" href="/5-python-features-i-wish-i-had-known-earlier-bc16e4a13bf4"><div class="pb ab fo"><div class="pc ab pd cl cj pe"><h2 class="bd iu gy z fp pf fr fs pg fu fw is bi translated">我希望我能早点知道的 5 个 Python 特性</h2><div class="ph l"><h3 class="bd b gy z fp pf fr fs pg fu fw dk translated">超越 lambda、map 和 filter 的 Python 技巧</h3></div><div class="pi l"><p class="bd b dl z fp pf fr fs pg fu fw dk translated">towardsdatascience.com</p></div></div><div class="pj l"><div class="pk l pl pm pn pj po ks pa"/></div></div></a></div><div class="ox oy gp gr oz pa"><a rel="noopener follow" target="_blank" href="/visualizing-bike-mobility-in-london-using-interactive-maps-for-absolute-beginners-3b9f55ccb59"><div class="pb ab fo"><div class="pc ab pd cl cj pe"><h2 class="bd iu gy z fp pf fr fs pg fu fw is bi translated">使用交互式地图和动画可视化伦敦的自行车移动性</h2><div class="ph l"><h3 class="bd b gy z fp pf fr fs pg fu fw dk translated">探索 Python 中的数据可视化工具</h3></div><div class="pi l"><p class="bd b dl z fp pf fr fs pg fu fw dk translated">towardsdatascience.com</p></div></div><div class="pj l"><div class="pp l pl pm pn pj po ks pa"/></div></div></a></div><div class="ox oy gp gr oz pa"><a rel="noopener follow" target="_blank" href="/machine-learning-in-python-numpy-neural-network-in-9-steps-eafd0db25906"><div class="pb ab fo"><div class="pc ab pd cl cj pe"><h2 class="bd iu gy z fp pf fr fs pg fu fw is bi translated">Python NumPy 中的机器学习(第 1 部分):9 步神经网络</h2><div class="ph l"><h3 class="bd b gy z fp pf fr fs pg fu fw dk translated">通过编码理解神经网络</h3></div><div class="pi l"><p class="bd b dl z fp pf fr fs pg fu fw dk translated">towardsdatascience.com</p></div></div><div class="pj l"><div class="pq l pl pm pn pj po ks pa"/></div></div></a></div><p id="c8a0" class="pw-post-body-paragraph lr ls it lt b lu mo ju lw lx mp jx lz ma mq mc md me mr mg mh mi ms mk ml mm im bi translated"><em class="mn">最初发表于</em><a class="ae ky" href="https://edenau.github.io/" rel="noopener ugc nofollow" target="_blank"><em class="mn">edenau . github . io</em></a><em class="mn">。</em></p></div></div>    
</body>
</html>