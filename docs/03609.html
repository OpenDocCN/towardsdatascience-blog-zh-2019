<html>
<head>
<title>Wasserstein GAN in Swift for TensorFlow</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">Wasserstein GAN 在 Swift for TensorFlow</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/wasserstein-gan-in-swift-for-tensorflow-61b557bd8c63?source=collection_archive---------12-----------------------#2019-06-08">https://towardsdatascience.com/wasserstein-gan-in-swift-for-tensorflow-61b557bd8c63?source=collection_archive---------12-----------------------#2019-06-08</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><figure class="gl gn jo jp jq jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi jn"><img src="../Images/2e8dbaafe1d0cd6b74c69ddd65886d88.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*W9CeWXlKZ2EUaWsFUvmqhw.jpeg"/></div></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk">Vanilla Generative Adversarial Network (GAN) as explained by <a class="ae kc" href="https://en.wikipedia.org/wiki/Ian_Goodfellow" rel="noopener ugc nofollow" target="_blank">Ian Goodfellow</a> in <a class="ae kc" href="https://papers.nips.cc/paper/5423-generative-adversarial-nets.pdf" rel="noopener ugc nofollow" target="_blank">original paper</a>.</figcaption></figure><p id="a400" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我是<a class="ae kc" href="https://swift.org/" rel="noopener ugc nofollow" target="_blank">苹果 Swift </a>和<a class="ae kc" href="https://en.wikipedia.org/wiki/Deep_learning" rel="noopener ugc nofollow" target="_blank">深度神经网络</a>的<em class="lb">大粉丝</em>。而最近即将推出的深度学习框架是 TensorFlow 的<a class="ae kc" href="https://www.tensorflow.org/swift/" rel="noopener ugc nofollow" target="_blank">Swift</a>。所以，很明显，我必须马上投入进去！我已经在 TensorFlow 或 PyTorch 中写过 Wasserstein GAN 和其他 GAN，但这个 Swift for TensorFlow 的东西超级酷。在后端，从编译器的角度来看，这是使 Swift 成为机器学习语言的最终努力。在本帖中，我将分享我在 Swift 为 TensorFlow 编写和培训 Wasserstein GAN 的工作。代码在 GitHub 上是开源的，现在就可以在 Google Colab 上运行！</p><h1 id="7ecb" class="lc ld iq bd le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz bi translated">生成对抗网的历史</h1><p id="11ad" class="pw-post-body-paragraph kd ke iq kf b kg ma ki kj kk mb km kn ko mc kq kr ks md ku kv kw me ky kz la ij bi mf translated"><span class="l mg mh mi bm mj mk ml mm mn di"> G </span>生成对抗网络(GAN)是由<a class="ae kc" href="https://en.wikipedia.org/wiki/Ian_Goodfellow" rel="noopener ugc nofollow" target="_blank"> Ian Goodfellow </a>在 2014 年发明的。GAN 通常有两个神经网络，即生成器<strong class="kf ir"> G </strong>和评价器<strong class="kf ir"> C </strong>。唯一可用的数据是真实世界&amp;实值数据(来自自然)的未标记集合，可以是图像、音频等。GANs 是为改进真实数据建模而设计的，这样当模型被要求生成图像时，它应该能够这样做，这就是<strong class="kf ir"> G </strong>的用途。这里，<strong class="kf ir"> C </strong>帮助<strong class="kf ir"> G </strong>学习生成更真实的数据，自己学习预测<strong class="kf ir"> G </strong>生成的图像是假的。它也接受真实的图像，并学会称之为真实的图像。这是一个迭代过程，它提高了<strong class="kf ir"> C </strong>预测虚假和真实数据的能力，并反过来帮助<strong class="kf ir"> G </strong>调整其参数，从而生成更真实的数据。</p><p id="73c1" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这些香草甘不产生非常好的图像质量。因此，提高图像生成质量的工作仍在继续，该子领域中最重要的方向之一是将 Critic 网络约束在函数空间的 1-Lipschitz 集合中，并最小化<strong class="kf ir"> G </strong>分布(假)和<strong class="kf ir"> P </strong>分布(真)之间的 Wasserstein 距离。查看<a class="ae kc" href="https://en.wikipedia.org/wiki/Lipschitz_continuity" rel="noopener ugc nofollow" target="_blank">维基百科页面</a>了解 Lipschitz 连续性。现在我们继续用 Swift 为 TensorFlow 编码 WGAN！</p><h1 id="4429" class="lc ld iq bd le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz bi translated">数据</h1><p id="c655" class="pw-post-body-paragraph kd ke iq kf b kg ma ki kj kk mb km kn ko mc kq kr ks md ku kv kw me ky kz la ij bi translated">数据是神经网络学习的第一步。因此，我使用了 CIFAR-10 数据集，它包含以下 10 个类别的图像:</p><ul class=""><li id="4baa" class="mo mp iq kf b kg kh kk kl ko mq ks mr kw ms la mt mu mv mw bi translated">飞机</li><li id="b9bb" class="mo mp iq kf b kg mx kk my ko mz ks na kw nb la mt mu mv mw bi translated">汽车</li><li id="4e22" class="mo mp iq kf b kg mx kk my ko mz ks na kw nb la mt mu mv mw bi translated">伯德</li><li id="d142" class="mo mp iq kf b kg mx kk my ko mz ks na kw nb la mt mu mv mw bi translated">猫</li><li id="0ade" class="mo mp iq kf b kg mx kk my ko mz ks na kw nb la mt mu mv mw bi translated">鹿</li><li id="9e24" class="mo mp iq kf b kg mx kk my ko mz ks na kw nb la mt mu mv mw bi translated">狗</li><li id="f26c" class="mo mp iq kf b kg mx kk my ko mz ks na kw nb la mt mu mv mw bi translated">青蛙</li><li id="630f" class="mo mp iq kf b kg mx kk my ko mz ks na kw nb la mt mu mv mw bi translated">马</li><li id="08a9" class="mo mp iq kf b kg mx kk my ko mz ks na kw nb la mt mu mv mw bi translated">船</li><li id="3b48" class="mo mp iq kf b kg mx kk my ko mz ks na kw nb la mt mu mv mw bi translated">卡车</li></ul><p id="c5ba" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">每个图像都是一个<code class="fe nc nd ne nf b">32x32</code>大小的 RGB 图像。大约有 50k 的训练图像和 10k 的测试图像。哇，我从来没有注意到图像类的数量接近 MNIST 数据集中的数量🤔。总之，我用这些数据来训练我的 Wasserstein GAN 生成这样的图像。</p><pre class="ng nh ni nj gt nk nf nl nm aw nn bi"><span id="4953" class="no ld iq nf b gy np nq l nr ns">import TensorFlow<br/>import Python<br/>PythonLibrary.useVersion(3)</span><span id="74e6" class="no ld iq nf b gy nt nq l nr ns">// Import some Python libraries<br/>let plt = Python.import("atplotlib.pyplot")</span></pre><figure class="ng nh ni nj gt jr"><div class="bz fp l di"><div class="nu nv l"/></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk">Data downloading and loading</figcaption></figure><p id="ea53" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">首先使用 Swift for TensorFlow toolchain 导入 TensorFlow 和 Python(3 . x 版)。然后通过 Python 互用性特性导入 Python 库！现在定义一些 CIFAR-10 下载、加载和预处理函数。最后，加载数据集。</p><h2 id="42ec" class="no ld iq bd le nw nx dn li ny nz dp lm ko oa ob lq ks oc od lu kw oe of ly og bi translated">配置</h2><p id="b017" class="pw-post-body-paragraph kd ke iq kf b kg ma ki kj kk mb km kn ko mc kq kr ks md ku kv kw me ky kz la ij bi translated">为了训练网络，需要设置一些重要的配置。我尽量保持配置与<a class="ae kc" href="https://arxiv.org/abs/1701.07875" rel="noopener ugc nofollow" target="_blank"> WGAN 纸</a>相似。因此，我将批量大小设置为 64，图像大小调整为 64x64，通道数(RGB)为 3。WGAN 被训练了 5 个纪元(如 PyTorch 教程中所建议的)。<strong class="kf ir"> G </strong>的潜在空间被设定为 128 维。每个<strong class="kf ir"> G </strong>的<strong class="kf ir"> C </strong>的迭代次数被设置为 5，这是为了很好地近似 1-Lipschitz 函数，如论文中所建议的。另外，<strong class="kf ir"> C </strong>的可训练参数值必须限制在极限值[-0.01，0.01]。</p><figure class="ng nh ni nj gt jr"><div class="bz fp l di"><div class="nu nv l"/></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk">Configurations</figcaption></figure><h1 id="f9c9" class="lc ld iq bd le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz bi translated">瓦瑟斯坦生成对抗网络</h1><p id="d354" class="pw-post-body-paragraph kd ke iq kf b kg ma ki kj kk mb km kn ko mc kq kr ks md ku kv kw me ky kz la ij bi translated">如上所述，WGAN 的模型包含一个<strong class="kf ir"> C </strong>和<strong class="kf ir"> G </strong>网络。<strong class="kf ir"> C </strong>包含多个卷积层，而<strong class="kf ir"> G </strong>由顺序转置卷积层组成，这些卷积层有时也被错误地称为反卷积层。</p><h2 id="fbe5" class="no ld iq bd le nw nx dn li ny nz dp lm ko oa ob lq ks oc od lu kw oe of ly og bi translated">自定义图层</h2><p id="f00f" class="pw-post-body-paragraph kd ke iq kf b kg ma ki kj kk mb km kn ko mc kq kr ks md ku kv kw me ky kz la ij bi translated">在 Swift 中为 TensorFlow 定制神经层，使你的结构符合<code class="fe nc nd ne nf b"><a class="ae kc" href="https://www.tensorflow.org/swift/api_docs/Protocols/Layer" rel="noopener ugc nofollow" target="_blank">Layer</a></code>协议。Swift 中 TensorFlow 的参数是通过使您的神经结构符合<code class="fe nc nd ne nf b"><a class="ae kc" href="https://www.tensorflow.org/swift/api_docs/Protocols/KeyPathIterable.html" rel="noopener ugc nofollow" target="_blank">KeyPathIterable</a></code>协议来访问的，这是默认的，但我写它是为了记住 Swift 中类型属性的迭代是如何发生的。目前，用于 TensorFlow 的 Swift 中的<code class="fe nc nd ne nf b"><a class="ae kc" href="https://www.tensorflow.org/swift/api_docs/Structs/TransposedConv2D" rel="noopener ugc nofollow" target="_blank">TransposedConv2D</a></code>实现工作不太好，所以我决定按照<a class="ae kc" href="https://distill.pub/2016/deconv-checkerboard/" rel="noopener ugc nofollow" target="_blank"> Odena 等人 2016 </a>建议的方式，在<code class="fe nc nd ne nf b">Conv2D</code>层之后使用<code class="fe nc nd ne nf b"><a class="ae kc" href="https://www.tensorflow.org/swift/api_docs/Structs/UpSampling2D" rel="noopener ugc nofollow" target="_blank">UpSampling2D</a></code> op。使用<code class="fe nc nd ne nf b"><a class="ae kc" href="https://www.tensorflow.org/swift/api_docs/Structs/Conv2D" rel="noopener ugc nofollow" target="_blank">Conv2D</a></code>结构，因为它跟随<code class="fe nc nd ne nf b"><a class="ae kc" href="https://www.tensorflow.org/swift/api_docs/Structs/BatchNorm" rel="noopener ugc nofollow" target="_blank">BatchNorm</a></code> op，该 op 也在连续的<code class="fe nc nd ne nf b">UpSampling2D</code>和<code class="fe nc nd ne nf b">Conv2D</code>操作之后使用，代替<code class="fe nc nd ne nf b">TranposedConv2D</code>。我写的这些自定义层用 Swift 代码显示如下。</p><figure class="ng nh ni nj gt jr"><div class="bz fp l di"><div class="nu nv l"/></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk">Custom neural layers</figcaption></figure><h2 id="43e8" class="no ld iq bd le nw nx dn li ny nz dp lm ko oa ob lq ks oc od lu kw oe of ly og bi translated">WGAN 架构</h2><p id="2ca4" class="pw-post-body-paragraph kd ke iq kf b kg ma ki kj kk mb km kn ko mc kq kr ks md ku kv kw me ky kz la ij bi translated"><strong class="kf ir"> G </strong>网络从高斯分布中取形状为【128】的随机向量。这将在<code class="fe nc nd ne nf b">BatchNorm</code>和<code class="fe nc nd ne nf b">relu</code>激活功能之后通过一个密集(全连接)层。产生的转换输出被重新整形，使得它可以通过一系列的<code class="fe nc nd ne nf b">UpSampling2D</code>、<code class="fe nc nd ne nf b">Conv2D</code>、<code class="fe nc nd ne nf b">BatchNorm</code>层和<code class="fe nc nd ne nf b">relu</code>激活。最后的层块简单地对卷积层和<code class="fe nc nd ne nf b">tanh</code>激活函数之后的输出进行上采样。</p><p id="61c1" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">网络<strong class="kf ir"> C </strong>的架构是这样的，它有 4 个块<code class="fe nc nd ne nf b">Conv2D</code>，后面跟着<code class="fe nc nd ne nf b">BatchNorm</code>。每个块后面都有一个负斜率为 0.2 的<code class="fe nc nd ne nf b">leakyReLU</code>激活函数。在撰写本文时，<code class="fe nc nd ne nf b">leakyReLU</code>功能尚未在 Swift for TensorFlow 中实现，因此我通过使其可区分来实现自己的功能。最后，输出被展平，并通过产生[1]维输出的密集层，以给出图像是真/假的概率。</p><figure class="ng nh ni nj gt jr"><div class="bz fp l di"><div class="nu nv l"/></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk">Wasserstein GAN architecture</figcaption></figure><p id="2396" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">请注意，在<strong class="kf ir"> G </strong>和<strong class="kf ir"> C </strong>中，步幅为(2，2)，填充设置为相同。两者中的内核大小都被设置为(4，4)大小。在上面的两个网络中，<code class="fe nc nd ne nf b">call(_:)</code>函数使用<code class="fe nc nd ne nf b">@differentiable</code>属性变得可微。用类似的方法创建可微的 LeakyReLU 激活函数。</p><figure class="ng nh ni nj gt jr"><div class="bz fp l di"><div class="nu nv l"/></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk">Differentiable Leaky ReLU</figcaption></figure><h1 id="623a" class="lc ld iq bd le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz bi translated">培养</h1><p id="c365" class="pw-post-body-paragraph kd ke iq kf b kg ma ki kj kk mb km kn ko mc kq kr ks md ku kv kw me ky kz la ij bi translated">网络被训练 5 个时期。在每次迭代中,<strong class="kf ir"> C </strong>比<strong class="kf ir"> G </strong>的单个训练步长多训练 5 次。每个网络使用的批次大小为 64。我使用 RMSProp 优化器，两个网络的学习率都是 0.00005。<strong class="kf ir"> G </strong>的<code class="fe nc nd ne nf b">zInput</code>取自均匀分布。我还记录了 1 个纪元的训练时间，对我来说大约是 12 分钟。使用<a class="ae kc" href="https://matplotlib.org" rel="noopener ugc nofollow" target="_blank"> Matplotlib </a>还绘制了 Wasserstein 距离和几个损失(如<strong class="kf ir"> G </strong>损失&amp;T21C 损失)的图表，这是因为 Swift for TensorFlow 支持 Python 互操作性。关于 TensorFlow 的 Swift，我学到的另一件事是，您可以迭代任何任意类型的属性，这些属性符合在<a class="ae kc" href="https://github.com/apple/swift" rel="noopener ugc nofollow" target="_blank"> apple/swift </a>的<a class="ae kc" href="https://github.com/tensorflow/swift" rel="noopener ugc nofollow" target="_blank"> tensorflow/swift </a> fork 中实现的<a class="ae kc" href="https://www.tensorflow.org/swift/api_docs/Protocols/KeyPathIterable" rel="noopener ugc nofollow" target="_blank">keypathiable</a>协议。这是一个超级酷的想法，但许多工作仍然需要做，如访问特定层的参数和修改需要应用每层激活。</p><p id="c7e9" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">不管怎样，下面是一个更深入的自我解释的 Swift 代码，用于训练我的 Wasserstein GAN！</p><figure class="ng nh ni nj gt jr"><div class="bz fp l di"><div class="nu nv l"/></div></figure><p id="6b4b" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">注意，需要通过下面几行代码来设置训练/推理模式。</p><pre class="ng nh ni nj gt nk nf nl nm aw nn bi"><span id="ce5c" class="no ld iq nf b gy np nq l nr ns">// For setting to training mode<br/>Context.local.learningPhase = .training<br/>// If you want to perform only inference<br/>Context.local.learningPhase = .inference</span></pre><h1 id="3f6f" class="lc ld iq bd le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz bi translated">讨论</h1><p id="872e" class="pw-post-body-paragraph kd ke iq kf b kg ma ki kj kk mb km kn ko mc kq kr ks md ku kv kw me ky kz la ij bi translated">用 Swift 语言接触深度神经网络是一种很好的体验。我认为 Swift for TensorFlow 将成长为一个新的主流机器学习框架，很可能取代 PyTorch 的大部分功能，就像 PyTorch 过去对 vanilla TensorFlow 所做的那样。我真的很喜欢它支持作为默认行为的急切执行，而且我不必手动设置设备进行训练&amp;我还可以在 Google Colab 中使用云 TPU。很高兴看到 TensorFlow 社区通过提供基于 Jupyter 的 Swift 环境，努力使 Swift for TensorFlow 可在 Colab 上使用。也可以使用<code class="fe nc nd ne nf b">Raw</code>类型的名称空间(我想它更像结构，因为 Swift 中不存在名称空间的概念)来访问一些基本的操作，如<code class="fe nc nd ne nf b">mul(_:_:)</code>、<code class="fe nc nd ne nf b">add(_:_:)</code>等。在 Swift for TensorFlow。这是谷歌 TensorFlow 团队<a class="ae kc" href="https://en.wikipedia.org/wiki/Chris_Lattner" rel="noopener ugc nofollow" target="_blank">克里斯·拉特纳</a> &amp;斯威夫特的一项令人敬畏的努力。</p><p id="5477" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">以下是我对 Swift for TensorFlow 目前在研究原型方面提供灵活性的方式的部分担忧。</p><h2 id="8579" class="no ld iq bd le nw nx dn li ny nz dp lm ko oa ob lq ks oc od lu kw oe of ly og bi translated">访问每层的参数</h2><p id="c8c5" class="pw-post-body-paragraph kd ke iq kf b kg ma ki kj kk mb km kn ko mc kq kr ks md ku kv kw me ky kz la ij bi translated">Swift for TensorFlow 采用了一种新颖的方法来访问一种类型的属性以进行修改。这是访问和更新神经网络参数所必需的。该设备提供给符合<a class="ae kc" href="https://www.tensorflow.org/swift/api_docs/Protocols/KeyPathIterable" rel="noopener ugc nofollow" target="_blank">按键可变</a>协议的类型。默认情况下，符合<a class="ae kc" href="https://www.tensorflow.org/swift/api_docs/Protocols/Layer" rel="noopener ugc nofollow" target="_blank">层</a>协议的神经网络结构存在这种行为。所以，你不必一遍又一遍地写，因为很可能你会想要访问神经网络的属性。这工作得很好，正如我在 Wasserstein GAN 代码中所做的那样，但我仍然不能灵活地访问每一层的参数，但我只是迭代一次所有属性，而不知道它们当前属于哪一层。这实际上不是我的要求，但在其他情况下，比如你想进行迁移学习时，这可能是一个要求。它需要访问特定的层来更新参数。希望 Swift 能很快为 TensorFlow 提供这种灵活性。</p><h2 id="bbea" class="no ld iq bd le nw nx dn li ny nz dp lm ko oa ob lq ks oc od lu kw oe of ly og bi translated">每层激活函数</h2><p id="7e8a" class="pw-post-body-paragraph kd ke iq kf b kg ma ki kj kk mb km kn ko mc kq kr ks md ku kv kw me ky kz la ij bi translated">我认为谷歌将会并且可能需要改变激活应用到每一层的方式(这是我不用的，因为 LeakyReLU 不能那样应用)。它类似于<code class="fe nc nd ne nf b">Conv2D(…, activation: relu)</code>，其中 relu 也可以被线性激活代替，但 LeakyReLU 不太适合这种设计，因为它没有给定的斜率值。这里，函数没有被调用，它只是一个作为参数传递给 Conv2D 层或任何其他层的函数。我能想到的最好的解决方案是使用枚举而不是像<code class="fe nc nd ne nf b">Conv2D(…, activation: .relu)</code>那样传递函数，或者对 LeakyReLU 做类似<code class="fe nc nd ne nf b">Conv2D(…, activation: .leakyrelu(0.2))</code>的事情，其中 0.2 是激活函数的枚举情况<code class="fe nc nd ne nf b">leakyrelu</code>的关联值。</p><p id="22fd" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><em class="lb">我希望你喜欢这本书。如果你真的喜欢我的文章，请与你的朋友分享，关注我吧！除了写文章，我还积极地在推特上发关于机器学习、区块链、量子计算的微博</em><a class="ae kc" href="https://twitter.com/Rahul_Bhalley" rel="noopener ugc nofollow" target="_blank"><strong class="kf ir"><em class="lb">@ Rahul _ Bhalley</em></strong></a><em class="lb">！</em></p></div></div>    
</body>
</html>