<html>
<head>
<title>Principal Component Analysis — Math and Intuition (Post 1)</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">主成分分析—数学和直觉(后 1)</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/principal-component-analysis-math-and-intuition-post-1-d44bf32844f3?source=collection_archive---------19-----------------------#2019-04-04">https://towardsdatascience.com/principal-component-analysis-math-and-intuition-post-1-d44bf32844f3?source=collection_archive---------19-----------------------#2019-04-04</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><figure class="gl gn jr js jt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi jq"><img src="../Images/2077b1b815c98f080656ebbb6a369eb8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*c-ZYbjLfhsSHaiup-vhbpQ.jpeg"/></div></div></figure><p id="d061" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">主成分分析(PCA)是现代数据分析中广泛使用的工具，不容忽视。不幸的是，许多人仍然对它知之甚少，因为它建立在坚实的数学基础上。PCA 的“是什么”相当简单；然而，好奇的人会渴望知道“如何”，这就是事情开始变得复杂的地方。这个 3 部分系列的目标是建立一个线性代数概念的框架，从而对 PCA 形成一个坚实的直觉。这个话题非常广泛，无法在一篇文章中得到证实。因此，我将其细分如下:</p><ol class=""><li id="1263" class="kz la it kd b ke kf ki kj km lb kq lc ku ld ky le lf lg lh bi translated"><strong class="kd iu"><em class="li">PCA 介绍</em> </strong>:真实世界的例子，直观解释 PCA</li></ol><p id="c6af" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">2.<a class="ae lj" rel="noopener" target="_blank" href="/principal-component-analysis-math-and-intuition-post-2-1849090e6b7a"><strong class="kd iu"><em class="li">PCA 数学背后的数学</em></strong></a><strong class="kd iu"><em class="li">:</em></strong>中级<strong class="kd iu"> <em class="li"> </em> </strong>线性代数(与 PCA 相关)</p><p id="b8b3" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">3.<strong class="kd iu"> <em class="li">点点滴滴联系起来理解 PCA: </em> </strong>用扎实的数学概念重温岗位 1 所掌握的直觉</p><p id="b028" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">那么，什么是 PCA？</p><p id="ee19" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">考虑一个例子，您被分配了一项任务，设计一个模型来预测城市居民的社会经济状况。市议会收集的数据集包括 70 多个特征，如年度个人收入、年度家庭收入、受抚养人数量、资产数量、房屋位置、房间、卧室、浴室、汽车数量、儿童数量、学校类型(公立/私立)、学费、替代收入来源、就业部门、教育水平、配偶就业、配偶教育、病史等等。整个数据集可以被视为一个 m(行)x n(列)矩阵；其中行代表居民，而每列代表一个特征或一个<em class="li">维度</em>。通常，计算的数量随着每个维度以二次比例增加，这使得计算要求很高。</p><p id="ef67" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">快速浏览一下特性列表，你会发现大多数特性都是相互关联的，它们只是潜在信号的指示器，并没有被直接观察到。例如，<em class="li">孩子数</em>和<em class="li">学费</em>是一个潜在信号的指标<em class="li">每个孩子的教育费用</em>。<em class="li">房间、卧室、浴室的数量</em>是房屋<em class="li">大小</em>的指标。两个或更多特征之间的这种直接关联使得它们是冗余的，并且可以减少特征空间或数据集的维度。PCA 是一种算法方法，用于降低数据集的维数，使其在计算上可以处理。</p><p id="9d4e" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">需要注意的是，PCA 不执行特征消除。直观地说，它提取原始数据集中所有特征的有效位，并创建较少数量的<em class="li">新特征</em>或<em class="li">主成分。</em>从技术上来说，维数减少会造成信息损失，但这种损失会被边缘化，并通过优化计算能力得到很大补偿。</p><p id="bd05" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">现在，您已经了解了什么是 PCA，您知道当应用 PCA 时，它会对您的数据集产生多大的影响。因此，有必要对它的功能有一个坚实的理解，我希望你有足够的兴趣和动力来进一步投入你的努力并继续<a class="ae lj" rel="noopener" target="_blank" href="/principal-component-analysis-math-and-intuition-post-2-1849090e6b7a"> Post 2 </a>。</p></div></div>    
</body>
</html>