<html>
<head>
<title>Dealing with Categorical Data fast — an example</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">快速处理分类数据—一个例子</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/dealing-with-categorical-data-fast-an-example-d4329b44253d?source=collection_archive---------4-----------------------#2019-02-07">https://towardsdatascience.com/dealing-with-categorical-data-fast-an-example-d4329b44253d?source=collection_archive---------4-----------------------#2019-02-07</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><figure class="ip iq gp gr ir is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi io"><img src="../Images/4cdd8ec74acb328dfac61b5870c74083.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*JaGNeDxS196rIz9Bsimgsg.jpeg"/></div></div></figure><div class=""/><p id="8983" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">早上 9 点你在办公室。你的老板进来，给了你一些数据，并要求你在中午 12 点之前创建一个模型。将召开一次会议，会上将展示这个模型。你是做什么的？</p><p id="8a38" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">我们将查看来自私人 Kaggle 竞赛的示例数据集，创建一些快速模型并选择一个。完整的 github 库在这里是<a class="ae kw" href="https://github.com/samirgadkari/Predict_Functional_Water_Pumps_Tanzania_Kaggle" rel="noopener ugc nofollow" target="_blank"/>。</p><p id="016a" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">我们得到了训练数据集(特征和目标)。我们还获得了测试特性数据集，并被要求预测测试目标。为了测试您的预测，您创建了一个预测文件并将其上传到 Kaggle。然后 Kaggle 会给你一个分数(数值从 0 到 1)。值越高，你的预测就越好。我们将重点关注准确度分数，因为这是 Kaggle 将在本次比赛中测试的分数。</p><p id="0e78" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">在 Jupyter 笔记本中首先导入您需要的课程。保持这个块是独立的，因为您可以向它添加更多的库并单独执行它。</p><pre class="kx ky kz la gt lb lc ld le aw lf bi"><span id="73ed" class="lg lh jb lc b gy li lj l lk ll">import numpy as np<br/>import pandas as pd</span><span id="9bdc" class="lg lh jb lc b gy lm lj l lk ll">from sklearn.metrics import accuracy_score<br/>from sklearn.model_selection import train_test_split<br/>from sklearn.model_selection import cross_val_score, GridSearchCV<br/>from sklearn.linear_model import LogisticRegression<br/>from sklearn.tree import DecisionTreeClassifier<br/>from sklearn.ensemble import RandomForestClassifier</span><span id="d926" class="lg lh jb lc b gy lm lj l lk ll">pd.set_option('display.max_columns', None)  # Unlimited columns.<br/>pd.options.mode.use_inf_as_na = True        # Any inf or -inf is <br/>                                            # treated as NA.</span></pre><p id="373c" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">读入训练特征数据:</p><pre class="kx ky kz la gt lb lc ld le aw lf bi"><span id="0e1d" class="lg lh jb lc b gy li lj l lk ll">X_train_original = pd.read_csv('./train_features.csv', <br/>                               header = [0],  # Top row is header.<br/>                               index_col = 0) # First col is index.<br/>X_train_original.head()</span></pre><figure class="kx ky kz la gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi ln"><img src="../Images/8221b290e8c438f821528a8c1603774c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*DRADsYU3p89x8Pr7hWy1vQ.png"/></div></div></figure><p id="ee2e" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">读入训练目标数据:</p><pre class="kx ky kz la gt lb lc ld le aw lf bi"><span id="02be" class="lg lh jb lc b gy li lj l lk ll">y_train_original = pd.read_csv('./train_labels.csv', <br/>                               header = [0],  # Top row is header.<br/>                               index_col = 0) # First col is index.<br/>y_train_original.head()</span></pre><figure class="kx ky kz la gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi lo"><img src="../Images/8e7e476f15e336359f817ca4fafe56aa.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*HX0gnwFYQ3SQevRbXDUyFQ.png"/></div></div></figure><p id="9c1c" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">你的目标很明确。让我们看看它有多少个类别:</p><pre class="kx ky kz la gt lb lc ld le aw lf bi"><span id="033e" class="lg lh jb lc b gy li lj l lk ll">pd.value_counts(y_train_original.status_group, normalize = True)</span></pre><figure class="kx ky kz la gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi lo"><img src="../Images/00a6797e8de90a717cbc0647091bc863.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ms3km64XWJF8_XEFY_DqFQ.png"/></div></div></figure><p id="eea8" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">由于一半以上只是一个类别，我们可以预测我们所有的目标值都是“功能性的”。这将在训练数据集上给我们 0.54 的准确度。让我们看看它在测试数据集上做了什么。</p><h1 id="4866" class="lp lh jb bd lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk ml bi translated">多数类预测</h1><p id="bc5f" class="pw-post-body-paragraph jy jz jb ka b kb mm kd ke kf mn kh ki kj mo kl km kn mp kp kq kr mq kt ku kv ij bi translated">我们进行多数类预测的原因是为了衡量我们未来的预测分数应该有多好。这给了我们一个基线，我们希望在下一个模型中跨越它。</p><p id="913b" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">让我们先来看看测试特性:</p><pre class="kx ky kz la gt lb lc ld le aw lf bi"><span id="6447" class="lg lh jb lc b gy li lj l lk ll">X_test_original = pd.read_csv('./test_features.csv', <br/>                              header = [0], <br/>                              index_col = 0)<br/>X_test_original.shape</span></pre><p id="c199" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi">(14358, 39)</p><p id="4119" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">此形状显示我们在预测输出中需要 14358 个值(输入的每行一个)。因此，我们创建了一个具有所需行数的数组，值为“functional”:</p><pre class="kx ky kz la gt lb lc ld le aw lf bi"><span id="6071" class="lg lh jb lc b gy li lj l lk ll">y_pred = ['functional'] * len(X_test_original)<br/>y_pred = pd.DataFrame(data = y_pred,<br/>                      index = X_test_original.index.values,<br/>                      columns = ['status_group'])<br/>y_pred.head()</span></pre><figure class="kx ky kz la gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi lo"><img src="../Images/d7d2506f918d4ed23c7a404cc74feec9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*cbtEJcANw3lVRmax4hGHKA.png"/></div></div></figure><p id="f783" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">然后我们把它写到一个文件中，并导入到 Kaggle 中。Kaggle 的准确率为 0.53(这和我们的预期差不多)。区别只是因为测试数据集不包含与训练数据集完全相同的目标类值比例。</p><h1 id="410a" class="lp lh jb bd lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk ml bi translated">仅使用数字特征进行预测</h1><pre class="kx ky kz la gt lb lc ld le aw lf bi"><span id="9b51" class="lg lh jb lc b gy li lj l lk ll">X_train_numerical = X_train_original.select_dtypes(<br/>                         include = np.number).copy()</span></pre><p id="3609" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">将“日期 _ 记录”字段转换为“天数 _ 自 _ 纪元”。在计算机编程中，对于 unix 计算机，纪元被认为是 1970 年 1 月 1 日。这只是一个通常使用的惯例——我们可以在这里的任何一天使用。对于机器学习，我们只关心值的相对比例是否相同。</p><pre class="kx ky kz la gt lb lc ld le aw lf bi"><span id="d097" class="lg lh jb lc b gy li lj l lk ll">days_since_epoch = \<br/>        pd.to_datetime(X_train_original['date_recorded']) \           <br/>            - pd.datetime(1970, 1, 1)<br/>X_train_numerical['days_since_epoch'] = days_since_epoch.dt.days<br/>X_train_numerical.head()</span></pre><figure class="kx ky kz la gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi mr"><img src="../Images/537005cc5f5b5a5e8f1af23aeced60ff.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*APsYmKC1EXlfCnOaLq3cgQ.png"/></div></div></figure><pre class="kx ky kz la gt lb lc ld le aw lf bi"><span id="2e76" class="lg lh jb lc b gy li lj l lk ll">X_train_numerical_indices = X_train_numerical.index.values<br/>y_train_numerical = y_train_original[y_train_original.index. \<br/>                                    isin(X_train_numerical_indices)]</span></pre><h2 id="ba73" class="lg lh jb bd lq ms mt dn lu mu mv dp ly kj mw mx mc kn my mz mg kr na nb mk nc bi translated">逻辑回归</h2><p id="6306" class="pw-post-body-paragraph jy jz jb ka b kb mm kd ke kf mn kh ki kj mo kl km kn mp kp kq kr mq kt ku kv ij bi translated">让我们尝试一个逻辑回归分类器:</p><pre class="kx ky kz la gt lb lc ld le aw lf bi"><span id="69ef" class="lg lh jb lc b gy li lj l lk ll">cv_score = cross_val_score(LogisticRegression(), <br/>                            X_train_numerical, y_train_numerical,<br/>                            scoring = 'accuracy',<br/>                            cv = 3,<br/>                            n_jobs = -1,<br/>                            verbose = 1)<br/>cv_score</span></pre><p id="2e9f" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">逻辑回归给我们的分数是 0.55。与多数班级模式没有太大区别。</p><h2 id="ecf4" class="lg lh jb bd lq ms mt dn lu mu mv dp ly kj mw mx mc kn my mz mg kr na nb mk nc bi translated">决策图表</h2><p id="7fc0" class="pw-post-body-paragraph jy jz jb ka b kb mm kd ke kf mn kh ki kj mo kl km kn mp kp kq kr mq kt ku kv ij bi translated">决策树分类器怎么样:</p><pre class="kx ky kz la gt lb lc ld le aw lf bi"><span id="fc8f" class="lg lh jb lc b gy li lj l lk ll">clf = DecisionTreeClassifier()<br/>cv_score = cross_val_score(clf, <br/>                            X_train_numerical, y_train_numerical,<br/>                            scoring = 'accuracy',<br/>                            cv = 3,<br/>                            n_jobs = -1,<br/>                            verbose = 1)<br/>cv_score</span></pre><p id="9529" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">这个分数在 0.65 就好多了。让我们获得测试数据集的预测，并将其写出到文件中。然后我们可以提交给 Kaggle:</p><pre class="kx ky kz la gt lb lc ld le aw lf bi"><span id="2198" class="lg lh jb lc b gy li lj l lk ll">clf.fit(X_train_numerical, y_train_numerical)<br/>X_test_numerical = X_test_original.select_dtypes(include = \ <br/>                                                 np.number).copy()<br/>days_since_epoch = pd.to_datetime(X_test_original['date_recorded']) <br/>                      - pd.datetime(1970, 1, 1)<br/>X_test_numerical['days_since_epoch'] = days_since_epoch.dt.days</span><span id="17be" class="lg lh jb lc b gy lm lj l lk ll">y_pred = clf.predict(X_test_numerical)</span><span id="6a1c" class="lg lh jb lc b gy lm lj l lk ll">y_pred = pd.DataFrame(data = y_pred, <br/>                      index = X_test_numerical.index.values,<br/>                      columns = ['status_group'])</span><span id="85ce" class="lg lh jb lc b gy lm lj l lk ll">y_pred.to_csv('./decision_tree_pred.csv', <br/>              header = ['status_group'],<br/>              index = True,<br/>              index_label = 'id')</span></pre><h1 id="fbb8" class="lp lh jb bd lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk ml bi translated">检查数据中是否有缺失值或异常值</h1><pre class="kx ky kz la gt lb lc ld le aw lf bi"><span id="9f99" class="lg lh jb lc b gy li lj l lk ll">X_train_original.isnull().sum()</span></pre><p id="2e3c" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">39 个要素中有 7 个要素的值为空。让我们放弃这些功能:</p><pre class="kx ky kz la gt lb lc ld le aw lf bi"><span id="a2d5" class="lg lh jb lc b gy li lj l lk ll">X_non_nulls = X_train_original.dropna(axis = 1)</span></pre><p id="3a6e" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">让我们找出每个特征中有多少个唯一值:</p><pre class="kx ky kz la gt lb lc ld le aw lf bi"><span id="0f34" class="lg lh jb lc b gy li lj l lk ll">X_non_nulls.nunique().sort_values(ascending = True)</span></pre><p id="0ad9" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">根据<a class="ae kw" href="https://medium.com/data-design/visiting-categorical-features-and-encoding-in-decision-trees-53400fa65931" rel="noopener">这篇文章</a>，当分类值编码为数字或二进制时，决策树分类器更快。<br/>让我们对具有&lt; 50 个唯一值的非空列进行编码，将数字列添加到数据帧中，并运行不同深度的决策树分类器。</p><pre class="kx ky kz la gt lb lc ld le aw lf bi"><span id="e01c" class="lg lh jb lc b gy li lj l lk ll">X_selected = X_non_nulls.loc[:, X_non_nulls.nunique().sort_values()\<br/>                             &lt; 50]<br/>cat_cols = list(X_selected.select_dtypes(['object']).columns.values)</span><span id="f84e" class="lg lh jb lc b gy lm lj l lk ll">X_categorical = X_selected[cat_cols]. \<br/>                  apply(lambda x: x.astype('category').cat.codes)<br/>X_train_selected = X_train_numerical.join(X_categorical)</span><span id="3ba0" class="lg lh jb lc b gy lm lj l lk ll">clf = DecisionTreeClassifier()<br/>cv_score = cross_val_score(clf, <br/>                            X_train_selected, y_train_original,<br/>                            scoring = 'accuracy',<br/>                            cv = 3,<br/>                            n_jobs = -1,<br/>                            verbose = 1)<br/>cv_score</span></pre><p id="1174" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">这给了我们 0.75 分。这是训练分数，所以我们应该将相同的分类器应用于测试数据，并请 Kaggle 评估其准确性:</p><pre class="kx ky kz la gt lb lc ld le aw lf bi"><span id="2778" class="lg lh jb lc b gy li lj l lk ll">clf.fit(X_train_selected, y_train_original)</span><span id="0a0b" class="lg lh jb lc b gy lm lj l lk ll">X_test_non_nulls = X_test_original.dropna(axis = 1)<br/>X_test_selected = X_test_non_nulls.loc[:, \<br/>                      X_test_non_nulls.nunique().sort_values() &lt; 50]</span><span id="8aba" class="lg lh jb lc b gy lm lj l lk ll">cat_cols = list(X_test_selected.select_dtypes(['object']). \<br/>              columns.values)<br/>X_test_categorical = X_test_selected[cat_cols]. \<br/>                        apply(lambda x: \ <br/>                                  x.astype('category').cat.codes)</span><span id="a551" class="lg lh jb lc b gy lm lj l lk ll">X_test_selected = X_test_numerical.join(X_test_categorical)</span><span id="89da" class="lg lh jb lc b gy lm lj l lk ll">y_pred = clf.predict(X_test_selected)<br/>y_pred = pd.DataFrame(data = y_pred, <br/>                      index = X_test_selected.index.values,<br/>                      columns = ['status_group'])</span></pre><p id="af4b" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">测试数据集给我们的分数是 0.76，这个分数更高，因为我们的模型对测试数据集的拟合程度肯定比训练数据集好一点。仍然在相同的值左右，这是意料之中的。</p><h1 id="cbad" class="lp lh jb bd lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk ml bi translated">既然我们的决策树给了我们一个好的结果，让我们试试随机森林分类器</h1><p id="20b6" class="pw-post-body-paragraph jy jz jb ka b kb mm kd ke kf mn kh ki kj mo kl km kn mp kp kq kr mq kt ku kv ij bi translated">随机森林分类器适用于多项目标(具有多个分类值的目标)。该分类器从训练数据集中随机抽取样本，因此不需要对其进行交叉验证。我们可能会做 GridSearchCV 来尝试不同的 n_estimators 和 max_depth(如果我们的分数不是很好的话)。</p><p id="6f13" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">随机森林分类器由许多决策树组成。通过从整个特征列表中随机选择树的每个节点处的特征来创建每个树。与单个决策树分类器相比，树的数量给予随机森林分类器更少的偏差。</p><pre class="kx ky kz la gt lb lc ld le aw lf bi"><span id="e2e8" class="lg lh jb lc b gy li lj l lk ll">X_train, X_test, y_train, y_test = train_test_split(<br/>    X_train_selected, y_train_original, test_size=0.2)</span><span id="b607" class="lg lh jb lc b gy lm lj l lk ll">clf = RandomForestClassifier()<br/>clf.fit(X_train, y_train)<br/>clf.score(X_test, y_test)</span></pre><p id="4cb2" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">决策树分类器给我们的分数是 0.79。很好，但是没有以前跳得高。这是我们通常会发现的情况——早期的模型通常得分较低，可以很容易地被击败，但后期的模型很难被击败。我们还没完呢。我们将使用网格搜索来搜索最佳随机森林分类器:</p><pre class="kx ky kz la gt lb lc ld le aw lf bi"><span id="b2d6" class="lg lh jb lc b gy li lj l lk ll">param_grid = {<br/>    'n_estimators': [10, 20, 30],<br/>    'max_depth': [6, 10, 20, 30]<br/>}</span><span id="36fb" class="lg lh jb lc b gy lm lj l lk ll">gridsearch = GridSearchCV(RandomForestClassifier(n_jobs = -1), <br/>                          param_grid=param_grid, <br/>                          scoring='accuracy', cv=3, <br/>                          return_train_score=True, verbose=10)</span><span id="888c" class="lg lh jb lc b gy lm lj l lk ll">gridsearch.fit(X_train, y_train)</span></pre><figure class="kx ky kz la gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi nd"><img src="../Images/497a09067fb69e95270ecc31a24876b2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*iRwvKgtMVOnVuvQ-EGb0gg.png"/></div></div></figure><p id="f160" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">param_grid 是分类器所需参数的字典。如果您不确定在这个字典中放入什么，可以使用这个函数调用，它会给出您可以使用的参数列表:</p><pre class="kx ky kz la gt lb lc ld le aw lf bi"><span id="0edc" class="lg lh jb lc b gy li lj l lk ll">RandomForestClassifier().get_params().keys()</span></pre><p id="38eb" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">在 GridSearchCV 函数内部，我们用 n_jobs = -1 创建了一个 RandomForestClassifier 对象。这将允许我们使用机器上的所有内核，从而使这个作业运行得更快。</p><p id="6fda" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">变量“cv”给出了该网格搜索应该使用的交叉验证折叠数。cv = 3 会将我们的数据分成 3 个相等的部分，然后使用其中的两个部分来训练 RandomForest 分类器，并使用剩余的数据进行测试。它会一直这样做，直到所有的组合都用完为止。</p><p id="b746" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">verbose 值将告诉 grid search 要打印多少信息。值越大，打印的信息越多。值为 10 时，您将会看到在 param_grid 字典中指定的变量值的每个组合与测试/训练分割的迭代编号一起打印出来。您还将看到在数据的测试部分获得的分数。您不必阅读所有内容，我们会打印出一份更易于阅读的摘要:</p><pre class="kx ky kz la gt lb lc ld le aw lf bi"><span id="1369" class="lg lh jb lc b gy li lj l lk ll">pd.DataFrame(gridsearch.cv_results_).sort_values( \<br/>                                         by='rank_test_score')</span></pre><figure class="kx ky kz la gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi ne"><img src="../Images/fb999eedcf9bbd379b0a1a701977dbfc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*bmWFTC9ifxiaHUtxAbflrg.png"/></div></div></figure><p id="ff66" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">此数据帧的顶行显示了 param_grid 选项，这些选项在数据的测试部分给出了最好的分数。这显示在 mean_test_score 列中，我们的分数是 0.79。这与决策树分类器相同。</p><p id="7487" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">让我们在 Kaggle 测试集上运行这个:</p><pre class="kx ky kz la gt lb lc ld le aw lf bi"><span id="f0e1" class="lg lh jb lc b gy li lj l lk ll">clf = RandomForestClassifier(max_depth = 20, <br/>                             n_estimators = 30, <br/>                             n_jobs = -1)<br/>clf.fit(X_train, y_train)<br/>clf.score(X_test, y_test)</span></pre><p id="44ac" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">我们得到了 0.81 分。这与决策树分类器得分 0.79 没有太大的不同。不同的是决策树有偏差，而随机森林没有。如果你在多组新的测试数据上测试这个随机森林分类器，你会发现它比决策树分类器做得更好。</p><h1 id="a84e" class="lp lh jb bd lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk ml bi translated">结论</h1><p id="4871" class="pw-post-body-paragraph jy jz jb ka b kb mm kd ke kf mn kh ki kj mo kl km kn mp kp kq kr mq kt ku kv ij bi translated">既然你知道随机森林比决策树更好，也许你可以使用以下步骤更快地找到解决方案:</p><ol class=""><li id="ac41" class="nf ng jb ka b kb kc kf kg kj nh kn ni kr nj kv nk nl nm nn bi translated">永远，永远，先做个快速预测。对于像这样的分类问题，如果目标中有一个多数类，多数类预测将是一个好的开始。</li><li id="3de6" class="nf ng jb ka b kb no kf np kj nq kn nr kr ns kv nk nl nm nn bi translated">如果有很少的空值(或者如果它们只存在于某些特征中)，则丢弃观察值/特征。</li><li id="caef" class="nf ng jb ka b kb no kf np kj nq kn nr kr ns kv nk nl nm nn bi translated">删除具有大量值的分类要素。他们可能不会做出好的特写。此外，删除具有单一值的要素，因为它们无法区分不同的类。</li><li id="1dd7" class="nf ng jb ka b kb no kf np kj nq kn nr kr ns kv nk nl nm nn bi translated">将日期转换为天或秒(为了更精确)。大多数分类器都是和数字一起工作的，所以最好都给它们数字。将分类列转换为数字。</li><li id="ea85" class="nf ng jb ka b kb no kf np kj nq kn nr kr ns kv nk nl nm nn bi translated">不要运行决策树分类器，因为它是有偏见的，只需用随机森林分类器运行网格搜索。</li></ol></div></div>    
</body>
</html>