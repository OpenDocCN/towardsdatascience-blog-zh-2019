# 人工智能专家:是时候让守护者保护我们自己了

> 原文：<https://towardsdatascience.com/time-to-program-guardians-to-protect-ourselves-ai-experts-6af06bbcae36?source=collection_archive---------42----------------------->

## 计算机越来越多地使用我们的数据来对我们做出决定，但我们能信任它们吗？

每天，在你不知情的情况下，计算机算法会利用你的数据来预测你的习惯、偏好和行为。

他们认为你喜欢 YouTube 上的猫视频意味着你会收到胡须广告的垃圾邮件，或者你的披头士下载意味着你想听保罗·麦卡特尼的第 100 首单曲。

如果你喜欢被推荐的音乐，或者不觉得广告反映了你令人毛骨悚然的网络浏览，那么你可能不会介意。

但是通过算法做出决策要更进一步。

算法正在决定谁能通过护照检查，谁能收到债务催收通知、房屋贷款和保险，甚至谁会成为警察的目标以及他们的刑期有多长。

最近，[透露了](https://mashable.com/article/flo-period-tracking-app-will-stop-sharing-data-with-facebook/#ewBHMwVaqsqr)算法告诉经期跟踪应用程序通知脸书你可能怀孕了。

算法基本上是计算机如何处理它接收到的数据的一组指令。

随着越来越多的系统变得自动化和个性化，这些输入越来越成为我们的个人数据:手机位置、社交媒体或应用程序使用习惯、网页浏览历史，甚至健康信息。

问题在于，你永远不知道一种算法是如何处理你的数据并做出决定的:你的抵押贷款申请被拒绝是基于你的未付账单历史还是你头发的颜色。

事实上，你对决策过程没有任何意见，你可以保证你的利益将永远支持那些开发应用程序的人。

![](img/5bb5ca4260cf0be5ea973043f993b874.png)

Your trail of mobile and other data is being monetised daily

一群领先的计算机科学家最近一直在讨论在这个新兴系统中更好地保护我们自己的必要性。

[他们说](https://ieeexplore.ieee.org/document/8371566)如果不采取行动，我们将失去对个人数据的控制，也失去对我们决策的透明度。

RMIT 大学副教授 Flora Salim、UNSW 大学教授 Salil Kanhere 和迪肯大学教授 Seng Loke 提出的解决方案之一是编写我们自己的算法监护人。

# 什么是“算法守护者”？

[算法守护者](https://ieeexplore.ieee.org/document/8371566/)将会是个人助理机器人，甚至是伴随我们到任何地方的全息图，并提醒我们在线幕后发生的事情。

这些守护者本身就是算法，但它们只为我们工作，被编程为根据我们的个人偏好管理我们与社交平台和应用程序的数字交互。

它们可以根据我们的意愿改变我们的数字身份，对不同的服务应用不同的设置，甚至在我们选择的时候让我们变得可识别或匿名。

我们的监护人可以确保我们的备份和密码是安全的，并允许我们决定在我们的在线存在中记住什么和忘记什么。

实际上，算法监护人将:

*   如果我们的位置、在线活动或对话被监控或跟踪，提醒我们，并给我们选择消失
*   当我们注册在线服务时，请帮助我们理解冗长繁琐的条款和条件的相关要点
*   当我们不明白我们的电脑、电话记录和手机后台运行的数十个应用程序之间的数据发生了什么变化时，请给我们一个简单的解释
*   如果有应用程序将我们手机中的数据发送给第三方，请通知我们，并让我们选择实时阻止它
*   请告诉我们，我们的数据是否被第三方货币化，以及用途是什么。

算法守护者被设想为当前个人助理(如 Siri、Alexa 或 Watson)的下一代。

他们不需要像人类一样聪明，只要与他们居住的环境相关就行——识别其他算法并解释他们在做什么。

如果没有这种责任感，我们生活中的关键时刻将越来越多地被未知的、看不见的和任意的算法所影响。

算法监护人将承担沟通和解释这些决定的重要角色。

可解释的机器学习是人工智能研究中越来越感兴趣和活跃的一个领域，它试图提供对算法如何做出最终决定的洞察。

既然算法已经渗透到日常生活中，可解释性不再是一种选择，而是一个迫切需要进一步关注的领域。

# 算法守护者何时到来？

就在我们说话的时候，实现算法守护者的技术正在出现，滞后的是我们需要它们的普遍意识。

你可以在存储和管理密码的数字保险库中，以及在让我们对如何使用我们的数据进行一些控制的软件设置中，看到算法守护者技术的原始版本。但是在普适计算时代，需要更全面的东西。

该团队表示，我们需要在未来几年内开发特定的算法监护人模型，为未来十年的开放算法系统奠定基础。

需求肯定是存在的，是吗？

在过去的十年里，隐私的概念发生了根本性的变化。

有没有可能在下一个十年里，我们甚至不会在乎每个系统都知道我们的一切，并利用这些信息为所欲为，因为大多数情况下，它都工作得很好？

*本文改编自《对话》中出现的* [*一片*](https://theconversation.com/your-period-tracking-app-could-tell-facebook-when-youre-pregnant-an-algorithmic-guardian-could-stop-it-111815) *，作者为萨利姆、坎 here 和洛克。*

迈克尔·奎恩