<html>
<head>
<title>Real time face recognition with CPU</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">CPU 实时人脸识别</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/real-time-face-recognition-with-cpu-983d35cc3ec5?source=collection_archive---------1-----------------------#2019-10-31">https://towardsdatascience.com/real-time-face-recognition-with-cpu-983d35cc3ec5?source=collection_archive---------1-----------------------#2019-10-31</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="9f7f" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated"><strong class="ak">看完这篇文章，你就会明白如何利用预先训练好的模型，用 CPU </strong>构建实时人脸识别系统。</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/5f043a4a3169470e1d8b4a065ceb56f3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*BSeQNbpsxs3_U6sM15N_Aw.jpeg"/></div></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk">Static face recognition with system described in this post</figcaption></figure><p id="936d" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">学术和工业领域都投入了巨大的努力来开发既快速又准确的人脸识别算法和模型。由于这些努力，现在可以用 CPU 完成多张人脸的准确、实时的人脸识别。</p><p id="5a56" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">在这篇文章中，我们将使用林扎尔<a class="ae lr" href="https://github.com/Linzaer/Ultra-Light-Fast-Generic-Face-Detector-1MB/blob/master/README_EN.md" rel="noopener ugc nofollow" target="_blank">和 MobileFaceNet 的超轻型人脸检测器构建一个实时人脸识别系统。</a></p><h1 id="08db" class="ls lt iq bd lu lv lw lx ly lz ma mb mc jw md jx me jz mf ka mg kc mh kd mi mj bi translated">人脸检测</h1><p id="9ac9" class="pw-post-body-paragraph kv kw iq kx b ky mk jr la lb ml ju ld le mm lg lh li mn lk ll lm mo lo lp lq ij bi translated">为了识别人脸，我们首先需要从图像中检测人脸。有许多方法可以做到这一点。</p><p id="430c" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">我已经探索了多种面部检测器。其中包括<a class="ae lr" href="https://github.com/ageitgey/face_recognition" rel="noopener ugc nofollow" target="_blank">人脸识别</a>包(包含方向梯度直方图(HOG)和卷积神经网络(CNN)检测器)<a class="ae lr" href="https://pypi.org/project/mtcnn/" rel="noopener ugc nofollow" target="_blank"> MTCNN </a>、<a class="ae lr" href="https://github.com/sthanhng/yoloface" rel="noopener ugc nofollow" target="_blank"> Yoloface </a>、<a class="ae lr" rel="noopener" target="_blank" href="/faced-cpu-real-time-face-detection-using-deep-learning-1488681c1602"> Faced </a>，以及最近发布的超轻人脸检测器。</p><p id="6676" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">我发现，虽然 Yoloface 具有最高的准确性和最一致的执行时间，但超轻人脸检测器在速度方面是无与伦比的，并产生了相对较好的准确性。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi mp"><img src="../Images/b11b7ba89373173189f1ea86f60ec4b4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*dKXQ8okYEwZxObABTBeVZA.png"/></div></div></figure><p id="cd02" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">在这篇文章中，我们将使用超轻型探测器。但是如果你有兴趣应用提到的任何其他检测方法，你可以在这里参考我的 Github 库<a class="ae lr" href="https://github.com/fyr91/face_detection/tree/master" rel="noopener ugc nofollow" target="_blank">。</a></p><p id="5ba6" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">要使用超轻模型，需要以下 python(python 3.6 版)包:</p><p id="9b20" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated"><code class="fe mq mr ms mt b">onnx==1.6.0</code><code class="fe mq mr ms mt b">onnx-tf==1.3.0</code><code class="fe mq mr ms mt b">onnxruntime==0.5.0</code><code class="fe mq mr ms mt b">opencv-python==4.1.1.26</code>T4】</p><p id="a9a8" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">使用<code class="fe mq mr ms mt b">pip install</code>安装所有的依赖项。</p><p id="6018" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">准备好环境后，我们可以通过以下代码使用 OpenCV 库从我们的网络摄像头获取帧馈送:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mu mv l"/></div></figure><p id="9422" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">对于我们获取的每个帧，我们需要在模型训练阶段遵循精确的预处理流水线，以实现预期的性能。</p><p id="d9c3" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">由于我们将使用预训练的<code class="fe mq mr ms mt b"><a class="ae lr" href="https://drive.google.com/open?id=1EDOJtWE_rnotlHZBRoYvPotRHr9PghxY" rel="noopener ugc nofollow" target="_blank">ultra_light_640.onnx</a></code>模型，我们必须将输入图像的大小调整为 640x480。如果您使用的是 320 型号，请相应地重新设置。</p><p id="48e0" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">代码如下所示:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mu mv l"/></div></figure><p id="3e0a" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">在预处理图像之后，我们将必须准备 ONNX 模型并创建一个 ONNX 推理会话。想了解更多关于模型推断的内容，可以查看这里的<a class="ae lr" href="https://blogs.nvidia.com/blog/2016/08/22/difference-deep-learning-training-inference-ai/" rel="noopener ugc nofollow" target="_blank">链接</a>。</p><p id="1e12" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">准备模型和创建推理会话的代码如下所示:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mu mv l"/></div></figure><p id="792f" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">现在是时候用下面的代码检测一些人脸了:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mu mv l"/></div></figure><p id="020a" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">变量<code class="fe mq mr ms mt b">confidences</code>包含了<code class="fe mq mr ms mt b">boxes</code>变量中每个框的置信水平列表。一个置信度对的第一和第二值分别指示包含背景和人脸的概率。</p><p id="1345" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">由于<code class="fe mq mr ms mt b">boxes</code>值包含了所有生成的盒子，我们将不得不根据相应的 Jaccard 索引(也称为 Union 上的交集)来识别具有包含面部的高概率的盒子并移除重复的盒子。</p><p id="fc74" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">获得正确框的代码如下所示:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mu mv l"/></div></figure><p id="fccd" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated"><code class="fe mq mr ms mt b">predict</code>函数将接受一个盒子数组，以及每个标签对应的置信度。然后，将执行置信度过滤，以保留所有包含人脸的概率较高的框。</p><p id="6147" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">之后，计算每个剩余盒子的交集(IOU)值。最后，使用具有硬 IOU 阈值的非最大抑制来过滤方框，以移除相似的方框。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mu mv l"/></div></figure><p id="8958" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">一旦我们有了过滤框，我们就可以在视频流中绘制和显示:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mu mv l"/></div></figure><p id="aad5" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">英特尔酷睿 i7–8550 u CPU @ 1.80 GHz 笔记本电脑网络摄像头的结果:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi mw"><img src="../Images/4ade8c6818d8b75245ac87817f0808f8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1200/1*8upkqz6HVTYH4AIRvt87-Q.gif"/></div></figure><p id="45be" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">检测部分的完整代码可以在<a class="ae lr" href="https://gist.github.com/fyr91/79aaf4b6d679814406ee4028bd03b7aa" rel="noopener ugc nofollow" target="_blank">这里</a>找到。</p><h1 id="035e" class="ls lt iq bd lu lv lw lx ly lz ma mb mc jw md jx me jz mf ka mg kc mh kd mi mj bi translated">人脸识别</h1><p id="89e7" class="pw-post-body-paragraph kv kw iq kx b ky mk jr la lb ml ju ld le mm lg lh li mn lk ll lm mo lo lp lq ij bi translated">检测到人脸后，下一步是识别它们。面部识别的技术有很多，包括<a class="ae lr" href="https://github.com/cmusatyalab/openface" rel="noopener ugc nofollow" target="_blank"> OpenFace </a>、<a class="ae lr" href="https://github.com/davidsandberg/facenet" rel="noopener ugc nofollow" target="_blank"> FaceNet </a>、<a class="ae lr" href="https://github.com/ox-vgg/vgg_face2" rel="noopener ugc nofollow" target="_blank"> VGGFace2 </a>、<a class="ae lr" href="https://github.com/xiaochus/MobileNetV2" rel="noopener ugc nofollow" target="_blank"> MobileNetV2 </a>等。本文中我们将使用的模型是 MobileFaceNet，它的灵感来自于 MobileNetV2。这个网络架构的细节以及如何训练可以在<a class="ae lr" href="https://arxiv.org/abs/1804.07573" rel="noopener ugc nofollow" target="_blank">这里</a>找到。</p><p id="8a93" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">一般来说，识别一张人脸需要三个步骤:(1)数据预处理，(2)人脸特征提取，以及(3)比较目标人脸和数据库中人脸的特征。</p><h2 id="e0f1" class="mx lt iq bd lu my mz dn ly na nb dp mc le nc nd me li ne nf mg lm ng nh mi ni bi translated">预处理</h2><p id="def4" class="pw-post-body-paragraph kv kw iq kx b ky mk jr la lb ml ju ld le mm lg lh li mn lk ll lm mo lo lp lq ij bi translated">我们将使用的数据是吉米·基梅尔采访詹妮弗·安妮斯顿的视频剪辑。我们将拍摄视频片段并提取詹妮弗·安妮斯顿的面部。您可以在相应的文件夹中添加自己的培训数据。</p><p id="ef38" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">文件结构如下所示:</p><pre class="kg kh ki kj gt nj mt nk nl aw nm bi"><span id="4d0a" class="mx lt iq mt b gy nn no l np nq">train.py<br/>faces<br/>  --training<br/>    --rachel<br/>      --rachel.mp4<br/>    --...<br/>  --temp<br/>  --embeddings</span></pre><p id="ff26" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">一旦训练数据就绪，我们就可以使用下面的代码对视频剪辑执行人脸提取:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mu mv l"/></div></figure><p id="405b" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">在<code class="fe mq mr ms mt b">boxes</code>里面抓拍人脸。现在，我们可以从人脸预处理开始。</p><p id="600d" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">我们将确定五个面部标志，通过适当的变换对齐面部，并将它们的大小调整为 112x112。</p><p id="ab43" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">我们将使用<code class="fe mq mr ms mt b">dlib</code>和<code class="fe mq mr ms mt b">imutils</code>来完成这些子任务。如果您还没有安装这两个软件包，请使用<code class="fe mq mr ms mt b">pip install</code>进行安装。</p><p id="5bdc" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">满足要求后，我们需要用下面的代码启动<code class="fe mq mr ms mt b">shape_predictor</code>(用于面部标志预测)和<code class="fe mq mr ms mt b">FaceAligner</code>:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mu mv l"/></div></figure><p id="92bd" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated"><code class="fe mq mr ms mt b">shape_predictor_5_landmarks.dat</code>用过的可以在这里下载<a class="ae lr" href="https://drive.google.com/open?id=1lAFZBh93lbzXEuDWgg6HPv2X0U61e6P9" rel="noopener ugc nofollow" target="_blank">。<code class="fe mq mr ms mt b">desiredLeftEye</code>指定你想要提取的人脸的大小。通常该值的范围是从 0.2 到 0.4。值越小，脸就越大。</a></p><p id="1d28" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">下面的代码说明了如何在提取的所有面上应用面对齐并写入文件:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mu mv l"/></div></figure><p id="6323" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">结果:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nr"><img src="../Images/f64ce2cbee76637b8ae8a1ab23b58c88.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*u7BAzFppCG6ta3ICt5rctw.jpeg"/></div></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk">Eyes are aligned and faces are of similar sizes.</figcaption></figure><p id="f24c" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">为了使用 MobileFaceNet 模型，需要进一步的预处理。我们必须用 127.5 减去对齐的面，然后用 128 除结果，如论文中所述。</p><p id="641c" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">用于如上所述的更多预处理的代码:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mu mv l"/></div></figure><h2 id="e856" class="mx lt iq bd lu my mz dn ly na nb dp mc le nc nd me li ne nf mg lm ng nh mi ni bi translated">计算面部嵌入</h2><p id="c62f" class="pw-post-body-paragraph kv kw iq kx b ky mk jr la lb ml ju ld le mm lg lh li mn lk ll lm mo lo lp lq ij bi translated">是时候从预处理过的人脸中获取面部特征了。我们将从加载张量流<a class="ae lr" href="https://drive.google.com/drive/folders/1J5NFwdeiamiPofeJsCpcmm46rgdrs5NW?usp=sharing" rel="noopener ugc nofollow" target="_blank">模型</a>开始:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mu mv l"/></div></figure><p id="a12a" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">接下来，我们将定义网络输入，获取嵌入并保存到 pickle 文件:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mu mv l"/></div></figure><h2 id="bee1" class="mx lt iq bd lu my mz dn ly na nb dp mc le nc nd me li ne nf mg lm ng nh mi ni bi translated">认出一张脸</h2><p id="a970" class="pw-post-body-paragraph kv kw iq kx b ky mk jr la lb ml ju ld le mm lg lh li mn lk ll lm mo lo lp lq ij bi translated">要识别人脸，只需加载带有相应标签的嵌入数据集。然后使用欧几里德距离和阈值来确定每个检测到的人脸属于谁。</p><p id="b783" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">代码如下所示:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mu mv l"/></div></figure><h2 id="58b4" class="mx lt iq bd lu my mz dn ly na nb dp mc le nc nd me li ne nf mg lm ng nh mi ni bi translated">最后</h2><p id="3511" class="pw-post-body-paragraph kv kw iq kx b ky mk jr la lb ml ju ld le mm lg lh li mn lk ll lm mo lo lp lq ij bi translated">让我们看看我们的结果:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi mw"><img src="../Images/e36566d365bdc7eb89c2961eb41c9bac.png" data-original-src="https://miro.medium.com/v2/resize:fit:1200/1*334GoqXS7V74ESygNSt9rQ.gif"/></div></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk">Embeddings acquired for six main characters from Friends series</figcaption></figure><p id="5e09" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">同样，你可以在这里找到完整的代码<a class="ae lr" href="https://github.com/fyr91/Face-Reco" rel="noopener ugc nofollow" target="_blank"/>。</p><h1 id="1e51" class="ls lt iq bd lu lv lw lx ly lz ma mb mc jw md jx me jz mf ka mg kc mh kd mi mj bi translated">摘要</h1><p id="34f4" class="pw-post-body-paragraph kv kw iq kx b ky mk jr la lb ml ju ld le mm lg lh li mn lk ll lm mo lo lp lq ij bi translated">据此，我们创建了一个可以用 CPU 进行实时人脸识别的系统。虽然它的运行速度只有大约 13 FPS，但它比使用复杂的 CNN 要快得多。</p><p id="7cb6" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">然而，我们仍然可以做很多事情来提高这个系统的性能(精度和速度)。潜在地，我们可以应用知识提取来压缩当前模型，并使用低位量化来进一步减小模型大小。此外，我们可以使用其他机器学习分类方法来提高嵌入的准确率。</p><p id="a5e6" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">感谢您的阅读！希望这对您有所帮助。</p><p id="ff2b" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">敬请期待，再见~</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi ns"><img src="../Images/19fe60b5436a215d06983a72ef2d41fb.png" data-original-src="https://miro.medium.com/v2/resize:fit:960/1*35Rj6G_OhvmO1ND578ITxw.gif"/></div></figure><h2 id="586e" class="mx lt iq bd lu my mz dn ly na nb dp mc le nc nd me li ne nf mg lm ng nh mi ni bi translated">参考</h2><p id="268a" class="pw-post-body-paragraph kv kw iq kx b ky mk jr la lb ml ju ld le mm lg lh li mn lk ll lm mo lo lp lq ij bi translated"><em class="nt"> [1]:陈，盛，等，“移动人脸识别网:在移动设备上实现准确实时人脸识别的高效细胞神经网络”中国生物识别会议。施普林格，查姆，2018。</em></p><p id="1c72" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated"><em class="nt">【2】:桑德勒、马克等《Mobilenetv2:反向残差与线性瓶颈》。IEEE 计算机视觉和模式识别会议录。2018 年</em></p></div></div>    
</body>
</html>