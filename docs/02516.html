<html>
<head>
<title>Properly Setting the Random Seed in Machine Learning Experiments</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">机器学习实验中随机种子的合理设置</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/properly-setting-the-random-seed-in-machine-learning-experiments-7da298d1320b?source=collection_archive---------18-----------------------#2019-04-24">https://towardsdatascience.com/properly-setting-the-random-seed-in-machine-learning-experiments-7da298d1320b?source=collection_archive---------18-----------------------#2019-04-24</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="7a0c" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">你能在机器学习实验中利用随机性，同时仍然获得可重复的结果吗？</h2></div></div><div class="ab cl kf kg hu kh" role="separator"><span class="ki bw bk kj kk kl"/><span class="ki bw bk kj kk kl"/><span class="ki bw bk kj kk"/></div><div class="ij ik il im in"><p id="dd1e" class="pw-post-body-paragraph km kn iq ko b kp kq jr kr ks kt ju ku kv kw kx ky kz la lb lc ld le lf lg lh ij bi translated"><a class="ae li" href="https://opendatascience.com/machine-learning-guide-20-free-odsc-resources-to-learn-machine-learning/" rel="noopener ugc nofollow" target="_blank">机器学习</a>模型以显而易见和意想不到的方式利用随机性。<strong class="ko ir">在概念层面</strong>，这种不确定性可能会影响你的模型的收敛速度、结果的稳定性以及网络的最终质量。</p><p id="7258" class="pw-post-body-paragraph km kn iq ko b kp kq jr kr ks kt ju ku kv kw kx ky kz la lb lc ld le lf lg lh ij bi translated"><strong class="ko ir">在实际层面上</strong>，这意味着你可能很难为你的模型重复运行相同的结果——即使你对相同的训练数据运行相同的脚本。这也可能导致在确定性能变化是由于实际模型或数据修改，还是仅仅是新的随机样本的结果方面的挑战。</p><p id="a514" class="pw-post-body-paragraph km kn iq ko b kp kq jr kr ks kt ju ku kv kw kx ky kz la lb lc ld le lf lg lh ij bi translated">为了解决这些变异的来源，一个关键的起点是<strong class="ko ir">全面了解数据、模型代码和参数，以及导致特定结果的环境细节</strong>。这种水平的再现性将减少您运行中的意外变化，并帮助您<a class="ae li" rel="noopener" target="_blank" href="/checklist-for-debugging-neural-networks-d8b2a9434f21">调试机器学习实验</a>。</p><p id="70db" class="pw-post-body-paragraph km kn iq ko b kp kq jr kr ks kt ju ku kv kw kx ky kz la lb lc ld le lf lg lh ij bi translated">在这篇文章中，我们探索了机器学习中出现随机性的领域，以及如何通过使用<a class="ae li" href="http://bit.ly/2JxjXN4" rel="noopener ugc nofollow" target="_blank"> Comet.ml </a>的示例仔细设置随机种子来实现可重复、确定性和更一般化的结果。</p><h1 id="9c0d" class="lj lk iq bd ll lm ln lo lp lq lr ls lt jw lu jx lv jz lw ka lx kc ly kd lz ma bi translated">随机性为什么重要？</h1><p id="991d" class="pw-post-body-paragraph km kn iq ko b kp mb jr kr ks mc ju ku kv md kx ky kz me lb lc ld mf lf lg lh ij bi translated">很明显，机器学习中的<a class="ae li" href="https://www.comet.ml/about" rel="noopener ugc nofollow" target="_blank">再现性</a>很重要，但是我们如何平衡这一点和随机性的需要呢？随机性既有实际的好处，也有迫使我们使用随机性的约束。</p><p id="0e84" class="pw-post-body-paragraph km kn iq ko b kp kq jr kr ks kt ju ku kv kw kx ky kz la lb lc ld le lf lg lh ij bi translated">实际上，内存和时间的限制也迫使我们“依赖”随机性。<a class="ae li" href="http://cs231n.github.io/neural-networks-3/" rel="noopener ugc nofollow" target="_blank">梯度下降</a>是用于训练机器学习模型的最流行和最广泛使用的算法之一，然而，基于整个数据集计算梯度步长对于大型数据集和模型是不可行的。随机梯度下降(SGD)仅使用从训练集中随机选取的一个或一小批<em class="mg"/>训练样本在特定迭代中对参数进行更新。</p><p id="9bac" class="pw-post-body-paragraph km kn iq ko b kp kq jr kr ks kt ju ku kv kw kx ky kz la lb lc ld le lf lg lh ij bi translated">虽然 SGD 可能导致梯度估计中的噪声误差，但这种噪声实际上可以鼓励勘探更容易地避开浅层局部极小值。你可以用<a class="ae li" href="https://iamaaditya.github.io/2012/10/why-simulated-annealing-works/" rel="noopener ugc nofollow" target="_blank">模拟退火</a>更进一步，这是 SGD 的扩展，模型有目的地采取随机步骤以寻求更好的状态。</p><figure class="mh mi mj mk gt ml gh gi paragraph-image"><div class="ab gu cl mm"><img src="../Images/62161071317ef0fe35cd2c2a9ea13c3c.png" data-original-src="https://miro.medium.com/v2/format:webp/0*wW-R9MukpZajCOoZ.png"/></div><figcaption class="mp mq gj gh gi mr ms bd b be z dk">Escaping shallow local minima encountered earlier on using stochastic gradient descent (SGD). Image source here</figcaption></figure><p id="ddde" class="pw-post-body-paragraph km kn iq ko b kp kq jr kr ks kt ju ku kv kw kx ky kz la lb lc ld le lf lg lh ij bi translated">随机性还可以通过一种叫做<a class="ae li" href="https://en.wikipedia.org/wiki/Bootstrap_aggregating" rel="noopener ugc nofollow" target="_blank">引导聚合</a> (bagging)的技术帮助你从更小的数据集获得更多的里程。最常见于随机森林，bagging 在重叠的随机选择的数据子集上训练多个模型</p><h1 id="60a9" class="lj lk iq bd ll lm ln lo lp lq lr ls lt jw lu jx lv jz lw ka lx kc ly kd lz ma bi translated">随机性出现在哪里？</h1><p id="4e06" class="pw-post-body-paragraph km kn iq ko b kp mb jr kr ks mc ju ku kv md kx ky kz me lb lc ld mf lf lg lh ij bi translated">既然我们理解了随机性在机器学习中的重要作用，我们就可以深入研究引入随机性的特定任务、功能和建模决策。</p><p id="21b3" class="pw-post-body-paragraph km kn iq ko b kp kq jr kr ks kt ju ku kv kw kx ky kz la lb lc ld le lf lg lh ij bi translated">以下是机器学习工作流程中出现随机性的一些重要部分:</p><p id="2354" class="pw-post-body-paragraph km kn iq ko b kp kq jr kr ks kt ju ku kv kw kx ky kz la lb lc ld le lf lg lh ij bi translated"><strong class="ko ir"> 1。数据准备</strong>-在神经网络的情况下，混洗的批次将导致不同运行的损失值。这意味着您的梯度值在运行中会有所不同，并且您可能会收敛到不同的局部最小值。对于特定类型的数据，如时间序列、音频或文本数据，以及特定类型的模型，如 LSTMs 和 RNNs，您的数据的输入顺序会极大地影响模型性能。</p><p id="c69f" class="pw-post-body-paragraph km kn iq ko b kp kq jr kr ks kt ju ku kv kw kx ky kz la lb lc ld le lf lg lh ij bi translated"><strong class="ko ir"> 2。数据预处理</strong> — <a class="ae li" href="https://chrisalbon.com/machine_learning/preprocessing_structured_data/handling_imbalanced_classes_with_upsampling/" rel="noopener ugc nofollow" target="_blank">对数据</a>进行过采样或上采样，以解决类别不平衡问题，这包括从具有替换的少数类别中随机选择一个观察值。向上采样会导致过度拟合，因为您会多次显示同一示例的模型。</p><p id="3742" class="pw-post-body-paragraph km kn iq ko b kp kq jr kr ks kt ju ku kv kw kx ky kz la lb lc ld le lf lg lh ij bi translated"><strong class="ko ir"> 3。交叉验证</strong>—<a class="ae li" rel="noopener" target="_blank" href="/train-test-split-and-cross-validation-in-python-80b61beca4b6">K-fold 和留一个交叉验证(LOOCV) </a>都涉及随机分割数据，以便<a class="ae li" href="https://medium.com/comet-ml/building-reliable-machine-learning-models-with-cross-validation-20b2c3e32f3e" rel="noopener">评估模型的泛化性能</a></p><p id="0f8e" class="pw-post-body-paragraph km kn iq ko b kp kq jr kr ks kt ju ku kv kw kx ky kz la lb lc ld le lf lg lh ij bi translated"><strong class="ko ir"> 4。权重初始化</strong> —机器学习模型的初始权重值通常被设置为小的随机数(通常在[-1，1]或[0，1]的范围内)。深度学习框架提供了多种初始化方法，从用零初始化到从正态分布初始化(参见<a class="ae li" href="https://keras.io/initializers/" rel="noopener ugc nofollow" target="_blank">Keras initializer 文档</a>作为例子加上<a class="ae li" href="https://intoli.com/blog/neural-network-initialization/" rel="noopener ugc nofollow" target="_blank">这个优秀的资源</a>)。</p><p id="b0d3" class="pw-post-body-paragraph km kn iq ko b kp kq jr kr ks kt ju ku kv kw kx ky kz la lb lc ld le lf lg lh ij bi translated"><strong class="ko ir"> 5。网络中的隐藏层</strong> — <a class="ae li" href="https://medium.com/@amarbudhiraja/https-medium-com-amarbudhiraja-learning-less-to-learn-better-dropout-in-deep-machine-learning-74334da4bfc5" rel="noopener">丢弃层</a>将在特定的向前或向后传递期间随机忽略节点的子集(每个节点都有被丢弃的概率，1- <em class="mg"> p </em>)。即使使用相同的输入，这也会导致层激活的差异。</p><p id="126d" class="pw-post-body-paragraph km kn iq ko b kp kq jr kr ks kt ju ku kv kw kx ky kz la lb lc ld le lf lg lh ij bi translated"><strong class="ko ir"> 6。算法本身</strong>——一些模型，如随机森林，自然依赖于随机性，而另一些则使用随机性作为探索空间的一种方式。</p><h1 id="8c87" class="lj lk iq bd ll lm ln lo lp lq lr ls lt jw lu jx lv jz lw ka lx kc ly kd lz ma bi translated">实现再现性</h1><p id="c972" class="pw-post-body-paragraph km kn iq ko b kp mb jr kr ks mc ju ku kv md kx ky kz me lb lc ld mf lf lg lh ij bi translated">这些因素都会导致运行之间的差异，即使您使用相同的模型代码和训练数据，也很难再现。控制实验过程中的不确定性和可见性是至关重要的。</p><p id="e6d1" class="pw-post-body-paragraph km kn iq ko b kp kq jr kr ks kt ju ku kv kw kx ky kz la lb lc ld le lf lg lh ij bi translated"><strong class="ko ir">好消息是，通过仔细设置管道中的随机种子，您可以实现可重复性。</strong>“种子”是序列的起点，其保证是，如果您从同一种子开始，您将获得相同的数字序列。<strong class="ko ir">也就是说，您还想跨不同的种子值来测试您的实验。</strong></p><p id="2df7" class="pw-post-body-paragraph km kn iq ko b kp kq jr kr ks kt ju ku kv kw kx ky kz la lb lc ld le lf lg lh ij bi translated">我们建议采取几个步骤来实现这两个目标:</p><p id="c414" class="pw-post-body-paragraph km kn iq ko b kp kq jr kr ks kt ju ku kv kw kx ky kz la lb lc ld le lf lg lh ij bi translated">1.使用一个实验追踪系统，比如<a class="ae li" href="http://bit.ly/2JxjXN4" rel="noopener ugc nofollow" target="_blank"> Comet.ml </a>。假设随机性在实验中是一种可取的属性，那么您只是希望能够尽可能地再现随机性。</p><p id="ac54" class="pw-post-body-paragraph km kn iq ko b kp kq jr kr ks kt ju ku kv kw kx ky kz la lb lc ld le lf lg lh ij bi translated">2.定义一个包含静态随机种子的变量，并在整个管道中使用它:</p><pre class="mh mi mj mk gt mt mu mv mw aw mx bi"><span id="edf0" class="my lk iq mu b gy mz na l nb nc">seed_value<!-- --> = 12321 # some number that you manually pick</span></pre><p id="b91a" class="pw-post-body-paragraph km kn iq ko b kp kq jr kr ks kt ju ku kv kw kx ky kz la lb lc ld le lf lg lh ij bi translated">3.向你的实验追踪系统报告这个数字。</p><pre class="mh mi mj mk gt mt mu mv mw aw mx bi"><span id="db67" class="my lk iq mu b gy mz na l nb nc">experiment = Experiment(project_name="Classification model") experiment.log_other("random seed",<!-- -->seed_value<!-- -->)</span></pre><p id="9ce1" class="pw-post-body-paragraph km kn iq ko b kp kq jr kr ks kt ju ku kv kw kx ky kz la lb lc ld le lf lg lh ij bi translated">4.仔细地为所有框架设置种子变量:</p><pre class="mh mi mj mk gt mt mu mv mw aw mx bi"><span id="f10f" class="my lk iq mu b gy mz na l nb nc"># Set a seed value: <br/>seed_value= <!-- -->12321 <!-- --> </span><span id="0ddd" class="my lk iq mu b gy nd na l nb nc"># 1. Set `PYTHONHASHSEED` environment variable at a fixed value: import os os.environ['PYTHONHASHSEED']=str(seed_value) </span><span id="3882" class="my lk iq mu b gy nd na l nb nc"># 2. Set `python` built-in pseudo-random generator at a fixed value: import random random.seed(seed_value) </span><span id="135a" class="my lk iq mu b gy nd na l nb nc"># 3. Set `numpy` pseudo-random generator at a fixed value:<br/>import numpy as np np.random.seed(seed_value) </span><span id="6dfa" class="my lk iq mu b gy nd na l nb nc"># 4. Set `tensorflow` pseudo-random generator at a fixed value: import tensorflow as tf tf.set_random_seed(seed_value)</span><span id="d0f8" class="my lk iq mu b gy nd na l nb nc"># 5. For layers that introduce randomness like dropout, make sure to set seed values:<br/>model.add(Dropout(0.25, seed=seed_value))</span><span id="9b17" class="my lk iq mu b gy nd na l nb nc">#6 Configure a new global `tensorflow` session: </span><span id="aa4b" class="my lk iq mu b gy nd na l nb nc">from keras import backend as K <br/>session_conf = tf.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1) <br/>sess = tf.Session(graph=tf.get_default_graph(), config=session_conf)<br/>K.set_session(sess)</span></pre><p id="3c7d" class="pw-post-body-paragraph km kn iq ko b kp kq jr kr ks kt ju ku kv kw kx ky kz la lb lc ld le lf lg lh ij bi translated">采取这些战术措施会让你在一定程度上实现可重复性，但是为了全面了解你的实验，你需要对你的实验进行更详细的记录。</p><p id="0273" class="pw-post-body-paragraph km kn iq ko b kp kq jr kr ks kt ju ku kv kw kx ky kz la lb lc ld le lf lg lh ij bi translated">正如 Matthew Rahtz 在他的博客文章'<a class="ae li" href="http://amid.fish/reproducing-deep-rl" rel="noopener ugc nofollow" target="_blank">中描述的，经验教训再现深度强化学习论文</a>:</p><blockquote class="ne nf ng"><p id="0a38" class="km kn mg ko b kp kq jr kr ks kt ju ku nh kw kx ky ni la lb lc nj le lf lg lh ij bi translated">当每一个进程花费的时间少于几个小时时，没有日志的工作是很好的，但是如果超过这个时间，你很容易忘记你到目前为止所做的努力，最终只是在原地打转。</p></blockquote><p id="ce48" class="pw-post-body-paragraph km kn iq ko b kp kq jr kr ks kt ju ku kv kw kx ky kz la lb lc ld le lf lg lh ij bi translated"><a class="ae li" href="http://bit.ly/2JxjXN4" rel="noopener ugc nofollow" target="_blank"> <strong class="ko ir"> Comet.ml </strong> </a> <strong class="ko ir">帮助您的团队自动跟踪数据集、代码变更、实验历史和生产模型，从而提高效率、透明度和重现性。</strong></p><h1 id="a69d" class="lj lk iq bd ll lm ln lo lp lq lr ls lt jw lu jx lv jz lw ka lx kc ly kd lz ma bi translated">浏览一个例子</h1><p id="8827" class="pw-post-body-paragraph km kn iq ko b kp mb jr kr ks mc ju ku kv md kx ky kz me lb lc ld mf lf lg lh ij bi translated">我们可以用 Comet.ml 测试种子，使用这个例子<a class="ae li" href="https://github.com/comet-ml/comet-examples/blob/master/keras/comet-keras-cnn-lstm-example.py" rel="noopener ugc nofollow" target="_blank">和 Keras CNN LSTM 对来自 IMDB 数据集的评论进行分类。如果你现在想看完整的实验列表，</a><a class="ae li" href="https://www.comet.ml/ceceshao1/determinism" rel="noopener ugc nofollow" target="_blank">点击这里</a>。</p><p id="5e85" class="pw-post-body-paragraph km kn iq ko b kp kq jr kr ks kt ju ku kv kw kx ky kz la lb lc ld le lf lg lh ij bi translated"><strong class="ko ir">第一轮:</strong>在同一台机器上使用相同的模型<code class="fe nk nl nm mu b">py</code>文件和相同的 IMDB 训练数据，我们运行我们的前两个实验，并获得两个不同的验证准确度(0.82099 对 0.81835)和验证损失值(1.34898 对 1.43609)。</p><figure class="mh mi mj mk gt ml gh gi paragraph-image"><div role="button" tabindex="0" class="no np di nq bf nr"><div class="gh gi nn"><img src="../Images/5bcb4c1b2b6c7ef8caf33148b105b449.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*xPoWpKHDMIyfRKsAWkcYUg.png"/></div></div><figcaption class="mp mq gj gh gi mr ms bd b be z dk">The Comet.ml Experiment Table gives you an organized view of your experiment’s metrics, parameters, and more. See the full example project <a class="ae li" href="https://www.comet.ml/ceceshao1/determinism" rel="noopener ugc nofollow" target="_blank">here</a></figcaption></figure><p id="6927" class="pw-post-body-paragraph km kn iq ko b kp kq jr kr ks kt ju ku kv kw kx ky kz la lb lc ld le lf lg lh ij bi translated"><strong class="ko ir">第二轮:</strong>这一次，我们为数据集训练/测试分割设置种子值</p><pre class="mh mi mj mk gt mt mu mv mw aw mx bi"><span id="9496" class="my lk iq mu b gy mz na l nb nc">(x_train, y_train), (x_test, y_test) = imdb.load_data( num_words=max_features, skip_top=50, seed=seed_value)</span></pre><p id="400b" class="pw-post-body-paragraph km kn iq ko b kp kq jr kr ks kt ju ku kv kw kx ky kz la lb lc ld le lf lg lh ij bi translated">即使我们的验证准确度值更接近，两个实验之间仍有一些差异(参见下表中的<code class="fe nk nl nm mu b">val_acc</code>和<code class="fe nk nl nm mu b">val_loss</code>列)</p><figure class="mh mi mj mk gt ml gh gi paragraph-image"><div role="button" tabindex="0" class="no np di nq bf nr"><div class="gh gi ns"><img src="../Images/a3701d5567543695b7eb5327efac641e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*hseK9izD2X5vj8KI2o98UA.png"/></div></div></figure><p id="c108" class="pw-post-body-paragraph km kn iq ko b kp kq jr kr ks kt ju ku kv kw kx ky kz la lb lc ld le lf lg lh ij bi translated"><strong class="ko ir">第三轮:</strong>除了为数据集训练/测试分割设置种子值之外，我们还将为我们在步骤 3 中记录的所有区域添加种子变量(如上所述，但为了方便起见在此复制)。</p><pre class="mh mi mj mk gt mt mu mv mw aw mx bi"><span id="adf8" class="my lk iq mu b gy mz na l nb nc"># Set seed value seed_value = 56 <br/>import os os.environ['PYTHONHASHSEED']=str(seed_value) </span><span id="50aa" class="my lk iq mu b gy nd na l nb nc"># 2. Set `python` built-in pseudo-random generator at a fixed value import random random.seed(seed_value) </span><span id="9c89" class="my lk iq mu b gy nd na l nb nc"># 3. Set `numpy` pseudo-random generator at a fixed value <br/>import numpy as np np.random.seed(seed_value) </span><span id="75f7" class="my lk iq mu b gy nd na l nb nc">from comet_ml import Experiment </span><span id="3fa5" class="my lk iq mu b gy nd na l nb nc"># 4. Set `tensorflow` pseudo-random generator at a fixed value import tensorflow as tf tf.set_random_seed(seed_value) </span><span id="c013" class="my lk iq mu b gy nd na l nb nc"># 5. Configure a new global `tensorflow` session <br/>from keras import backend as K <br/>session_conf = tf.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1) <br/>sess = tf.Session(graph=tf.get_default_graph(), config=session_conf)<br/>K.set_session(sess)</span></pre><p id="b6b6" class="pw-post-body-paragraph km kn iq ko b kp kq jr kr ks kt ju ku kv kw kx ky kz la lb lc ld le lf lg lh ij bi translated">现在我们已经添加了种子变量并配置了一个新的会话，我们的实验结果终于可以一致地重现了！</p><figure class="mh mi mj mk gt ml gh gi paragraph-image"><div role="button" tabindex="0" class="no np di nq bf nr"><div class="gh gi nt"><img src="../Images/ab2786f3013c0bae3d9dd3f17bc2476e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*dwwum0MGE5_C34qb64w9LQ.png"/></div></div></figure><p id="8965" class="pw-post-body-paragraph km kn iq ko b kp kq jr kr ks kt ju ku kv kw kx ky kz la lb lc ld le lf lg lh ij bi translated">使用 Comet.ml，您可以随着训练的进行，对几次跑步进行可视化的实时比较:</p><figure class="mh mi mj mk gt ml gh gi paragraph-image"><div role="button" tabindex="0" class="no np di nq bf nr"><div class="gh gi nu"><img src="../Images/8a02be973e2386badac47cdee3d8b526.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*pNDZXgr2qxI1ND_jweSBgw.png"/></div></div></figure><p id="6902" class="pw-post-body-paragraph km kn iq ko b kp kq jr kr ks kt ju ku kv kw kx ky kz la lb lc ld le lf lg lh ij bi translated">Comet.ml 帮助您挖掘可能导致观察到的性能变化的参数、种子或数据的差异。</p><p id="3969" class="pw-post-body-paragraph km kn iq ko b kp kq jr kr ks kt ju ku kv kw kx ky kz la lb lc ld le lf lg lh ij bi translated">您可以在下面看到我们第 3 轮的一个实验如何指定了<code class="fe nk nl nm mu b">random seed</code>值，而我们第 1 轮的一个实验却没有指定。根据您的需要，将像<code class="fe nk nl nm mu b">random seed</code>这样的信息记录到 Comet 是灵活的。</p><figure class="mh mi mj mk gt ml gh gi paragraph-image"><div role="button" tabindex="0" class="no np di nq bf nr"><div class="gh gi nv"><img src="../Images/24b980dcc96bb2fb5d04ebcc259b9e34.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*vI5ZmoQg3LNF9qMdVrVK7w.png"/></div></div></figure><p id="5bab" class="pw-post-body-paragraph km kn iq ko b kp kq jr kr ks kt ju ku kv kw kx ky kz la lb lc ld le lf lg lh ij bi translated">您甚至可以检查两个实验之间的代码差异，并查看我们在第 3 轮实验中设置<code class="fe nk nl nm mu b">seed_value</code>的不同区域:</p><figure class="mh mi mj mk gt ml gh gi paragraph-image"><div role="button" tabindex="0" class="no np di nq bf nr"><div class="gh gi nw"><img src="../Images/dfad9655faa4f2e876494b3f45e8acad.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/1*WVHRxHFxJdOscfwlZGXKPw.gif"/></div></div></figure><p id="74ce" class="pw-post-body-paragraph km kn iq ko b kp kq jr kr ks kt ju ku kv kw kx ky kz la lb lc ld le lf lg lh ij bi translated">使用 Comet.ml 正确跟踪这些实验的细节后，您可以开始测试不同的种子值，以查看这些性能指标是否特定于某个种子值，或者您的模型是否真正具有普遍性。</p><figure class="mh mi mj mk gt ml gh gi paragraph-image"><div role="button" tabindex="0" class="no np di nq bf nr"><div class="gh gi nx"><img src="../Images/265ff64160133eed0e5d019b08c651fd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*SYGuJ6ZhIdEJ3ig9"/></div></div><figcaption class="mp mq gj gh gi mr ms bd b be z dk">Never fear cells being run out of order or duplicating work again. See our notebook examples <a class="ae li" href="https://github.com/comet-ml/comet-examples/tree/master/notebooks" rel="noopener ugc nofollow" target="_blank">here</a></figcaption></figure><p id="6a30" class="pw-post-body-paragraph km kn iq ko b kp kq jr kr ks kt ju ku kv kw kx ky kz la lb lc ld le lf lg lh ij bi translated">现在你知道如何在你的机器学习实验中通过设置种子来拥抱和控制随机性了！</p><h2 id="a822" class="my lk iq bd ll ny nz dn lp oa ob dp lt kv oc od lv kz oe of lx ld og oh lz oi bi translated">如果您有兴趣了解 Comet 如何帮助您的数据科学团队提高工作效率，<a class="ae li" href="http://bit.ly/2JxjXN4" rel="noopener ugc nofollow" target="_blank">请点击这里</a>了解更多信息。</h2></div></div>    
</body>
</html>