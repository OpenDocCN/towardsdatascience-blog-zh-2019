<html>
<head>
<title>PySpark in Google Colab</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">谷歌可乐中的 PySpark</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/pyspark-in-google-colab-6821c2faf41c?source=collection_archive---------2-----------------------#2019-02-09">https://towardsdatascience.com/pyspark-in-google-colab-6821c2faf41c?source=collection_archive---------2-----------------------#2019-02-09</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="9186" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">在 Colab 中使用 PySpark 创建简单的线性回归模型</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/caacd658ab835349d1b36ab9400a4048.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*67yx2NlYj7zMyT-WILujIA.jpeg"/></div></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk">Photo by <a class="ae ky" href="https://unsplash.com/photos/Kw_zQBAChws?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank">Ashim D’Silva</a> on <a class="ae ky" href="https://unsplash.com/search/photos/ai?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><p id="83da" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">随着数据池来源的拓宽，大数据主题在过去几年中受到了越来越多的关注。除了处理各种类型和形状的巨大数据之外，大数据的分析部分的目标周转时间也大大减少了。这种速度和效率不仅有助于大数据的<strong class="lb iu"> </strong>即时分析，也有助于识别<strong class="lb iu"> </strong>新机会。这反过来又导致<strong class="lb iu"> </strong>采取更明智的商业行动，更高效的运营，更高的利润和更满意的客户。</p><p id="6a23" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">Apache Spark 旨在以更快的速度分析大数据。Apache Spark 提供的一个重要特性是能够在内存中运行计算。对于在磁盘上运行的复杂应用程序，它也被认为比 MapReduce 更高效。</p><p id="3c1b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">Spark 被设计成高度可访问的，提供了 Python、Java、Scala 和 SQL 的简单 API，以及丰富的内置库。它还与其他大数据工具紧密集成。特别是 Spark 可以在 Hadoop 集群中运行，可以访问任何 Hadoop 数据源，包括 Cassandra。</p><p id="a8df" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">PySpark 是使用 Python 编程语言访问 Spark 的接口。PySpark 是用 python 开发的 API，用于 Spark 编程和用 Python 风格编写 spark 应用程序，尽管底层执行模型对于所有 API 语言都是相同的。</p><p id="2f44" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在本教程中，我们将主要处理 PySpark 机器学习库 Mllib，该库可用于导入线性回归模型或其他机器学习模型。</p><h2 id="7509" class="lv lw it bd lx ly lz dn ma mb mc dp md li me mf mg lm mh mi mj lq mk ml mm mn bi translated">是的，但是为什么是 Google Colab 呢？</h2><p id="9e45" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">Google 的 Colab 基于 Jupyter Notebook，这是一个非常强大的工具，利用了 google docs 的功能。由于它运行在谷歌服务器上，我们不需要在我们的系统中本地安装任何东西，无论是 Spark 还是深度学习模型。Colab 最吸引人的特性是免费的 GPU 和 TPU 支持！由于 GPU 支持运行在谷歌自己的服务器上，事实上，它比一些商用 GPU(如 Nvidia 1050Ti)更快。分配给用户的一条常规系统信息如下所示:</p><pre class="kj kk kl km gt mt mu mv mw aw mx bi"><span id="f8a5" class="lv lw it mu b gy my mz l na nb">Gen RAM Free: 11.6 GB  | Proc size: 666.0 MB<br/>GPU RAM Free: 11439MB | Used: 0MB | Util  0% | Total 11439MB</span></pre><p id="31a4" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">如果你有兴趣了解更多关于 Colab 的信息，Anna Bonner<a class="ae ky" href="https://towardsdatascience.com/@annebonner" rel="noopener" target="_blank">的这篇</a><a class="ae ky" rel="noopener" target="_blank" href="/getting-started-with-google-colab-f2fff97f594c">文章</a>指出了使用 Colab 的一些显著好处。</p><p id="24cd" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">闲聊到此为止。让我们用 Google Colab 中的 PySpark 创建一个简单的线性回归模型。</p><p id="aedf" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">要打开 Colab Jupyter 笔记本，请点击此<a class="ae ky" href="http://colab.research.google.com" rel="noopener ugc nofollow" target="_blank">链接</a>。</p><h2 id="0682" class="lv lw it bd lx ly lz dn ma mb mc dp md li me mf mg lm mh mi mj lq mk ml mm mn bi translated">在 Colab 运行 Pyspark</h2><p id="5146" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">要在 Colab 中运行 spark，首先我们需要在 Colab 环境中安装所有依赖项，如 Apache Spark 2.3.2 with hadoop 2.7、Java 8 和 Findspark，以便在系统中定位 Spark。工具安装可以在 Colab 的 Jupyter 笔记本内进行。</p><p id="d5ae" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">按照以下步骤安装依赖项:</p><pre class="kj kk kl km gt mt mu mv mw aw mx bi"><span id="0c6c" class="lv lw it mu b gy my mz l na nb">!apt-get install openjdk-8-jdk-headless -qq &gt; /dev/null<br/>!wget -q <a class="ae ky" href="https://www-us.apache.org/dist/spark/spark-2.4.1/spark-2.4.1-bin-hadoop2.7.tgz" rel="noopener ugc nofollow" target="_blank">https://www-us.apache.org/dist/spark/spark-2.4.1/spark-2.4.1-bin-hadoop2.7.tgz</a><br/>!tar xf spark-2.4.1-bin-hadoop2.7.tgz<br/>!pip install -q findspark</span></pre><p id="4c68" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">既然我们已经在 Colab 中安装了 Spark 和 Java，现在是时候设置环境路径，使我们能够在我们的 Colab 环境中运行 PySpark。通过运行以下代码设置 Java 和 Spark 的位置:</p><pre class="kj kk kl km gt mt mu mv mw aw mx bi"><span id="0083" class="lv lw it mu b gy my mz l na nb">import os<br/>os.environ["JAVA_HOME"] = "/usr/lib/jvm/java-8-openjdk-amd64"<br/>os.environ["SPARK_HOME"] = "/content/spark-2.3.2-bin-hadoop2.7"</span></pre><p id="5422" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们可以运行一个本地 spark 会话来测试我们的安装:</p><pre class="kj kk kl km gt mt mu mv mw aw mx bi"><span id="431a" class="lv lw it mu b gy my mz l na nb">import findspark<br/>findspark.init()<br/>from pyspark.sql import SparkSession<br/>spark = SparkSession.builder.master("local[*]").getOrCreate()</span></pre><p id="41be" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们的实验室可以运行 PySpark 了。让我们建立一个简单的线性回归模型。</p><h2 id="3d0d" class="lv lw it bd lx ly lz dn ma mb mc dp md li me mf mg lm mh mi mj lq mk ml mm mn bi translated">线性回归模型</h2><p id="4952" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">线性回归模型是一种最古老和广泛使用的机器学习方法，它假设因变量和自变量之间存在关系。例如，建模者可能希望根据湿度比来预测降雨。线性回归由穿过图上分散点的最佳拟合线组成，最佳拟合线称为回归线。关于线性回归的详细内容可以在这里找到<a class="ae ky" href="http://onlinestatbook.com/2/regression/intro.html" rel="noopener ugc nofollow" target="_blank">。</a></p><p id="6ad2" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">为了从 Colab 中的 Pyspark 开始并保持简单，我们将使用著名的波士顿住房数据集。这个数据集的完整描述可以在这个<a class="ae ky" href="https://www.cs.toronto.edu/~delve/data/boston/bostonDetail.html" rel="noopener ugc nofollow" target="_blank">链接</a>中找到。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nc"><img src="../Images/371716b580f8026ade5a8239a0e98257.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*wkAWKdXrPbsRzJX0gO4SUg.png"/></div></div></figure><p id="d1db" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">本练习的目标是根据给定的特征预测房价。让我们通过将 MEDV 作为目标变量，将所有其他变量作为输入要素来预测 Boston Housing 数据集的价格。</p><p id="4f88" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们可以从这个<a class="ae ky" href="https://github.com/asifahmed90/pyspark-ML-in-Colab/blob/master/BostonHousing.csv" rel="noopener ugc nofollow" target="_blank">链接</a>下载数据集，并将它保存在本地驱动器中的某个可访问的地方。可以在同一驱动器上使用以下命令将数据集加载到 Colab 目录中。</p><pre class="kj kk kl km gt mt mu mv mw aw mx bi"><span id="a88d" class="lv lw it mu b gy my mz l na nb">from google.colab import files<br/>files.upload()</span></pre><p id="b1af" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们现在可以检查 Colab 的目录内容</p><pre class="kj kk kl km gt mt mu mv mw aw mx bi"><span id="46e4" class="lv lw it mu b gy my mz l na nb">!ls</span></pre><p id="46c9" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们应该看到一个名为 BostonHousing.csv 的文件被保存。现在我们已经成功上传了数据集，我们可以开始分析了。</p><p id="5273" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">对于我们的线性回归模型，我们需要从 PySpark API 导入<a class="ae ky" href="https://spark.apache.org/docs/2.2.0/ml-features.html" rel="noopener ugc nofollow" target="_blank">向量汇编器</a>和<a class="ae ky" href="https://spark.apache.org/docs/2.1.1/ml-classification-regression.html" rel="noopener ugc nofollow" target="_blank">线性回归</a>模块。Vector Assembler 是一个转换工具，它将包含 type <a class="ae ky" href="https://en.wikipedia.org/wiki/Double-precision_floating-point_format" rel="noopener ugc nofollow" target="_blank"> double </a>的多个列中的所有特征组合成一个向量。我们<em class="nd">应该使用</em> ( <strong class="lb iu">必须使用</strong> ) <a class="ae ky" href="https://spark.rstudio.com/reference/ft_string_indexer/" rel="noopener ugc nofollow" target="_blank"> StringIndexer </a>如果我们的任何列包含字符串值，就将其转换为数值。幸运的是，BostonHousing 数据集只包含 double 类型，所以我们现在可以跳过<a class="ae ky" href="https://spark.rstudio.com/reference/ft_string_indexer/" rel="noopener ugc nofollow" target="_blank"> StringIndexer </a>。</p><pre class="kj kk kl km gt mt mu mv mw aw mx bi"><span id="7749" class="lv lw it mu b gy my mz l na nb">from pyspark.ml.feature import VectorAssembler<br/>from pyspark.ml.regression import LinearRegression</span><span id="f0a2" class="lv lw it mu b gy ne mz l na nb">dataset = spark.read.csv('BostonHousing.csv',inferSchema=True, header =True)</span></pre><p id="7d4b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">注意，我们在 read.csv()中使用了 InferSchema。InferSchema 自动为每一列推断不同的数据类型。</p><p id="37e7" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">让我们查看数据集，看看每一列的数据类型:</p><pre class="kj kk kl km gt mt mu mv mw aw mx bi"><span id="5704" class="lv lw it mu b gy my mz l na nb">dataset.printSchema()</span></pre><p id="cda7" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">它应该打印如下数据类型:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nf"><img src="../Images/71a7ecdb33b7f7577268d33a44d6e44f.png" data-original-src="https://miro.medium.com/v2/resize:fit:870/format:webp/1*Neqj_aYzx6COj-XwZIbCYg.png"/></div></figure><p id="e18e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在下一步中，我们将把不同列中的所有特征转换成一个单独的列，我们可以在 outputCol 中将这个新的向量列称为“属性”。</p><pre class="kj kk kl km gt mt mu mv mw aw mx bi"><span id="339d" class="lv lw it mu b gy my mz l na nb">#Input all the features in one vector column<br/>assembler = VectorAssembler(inputCols=['crim', 'zn', 'indus', 'chas', 'nox', 'rm', 'age', 'dis', 'rad', 'tax', 'ptratio', 'b', 'lstat'], outputCol = 'Attributes')</span><span id="7999" class="lv lw it mu b gy ne mz l na nb">output = assembler.transform(dataset)</span><span id="c8e5" class="lv lw it mu b gy ne mz l na nb">#Input vs Output<br/>finalized_data = output.select("Attributes","medv")</span><span id="8694" class="lv lw it mu b gy ne mz l na nb">finalized_data.show()</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ng"><img src="../Images/c4c30d9daf88352e6dbb0cb83f943974.png" data-original-src="https://miro.medium.com/v2/resize:fit:686/format:webp/1*jK3mCz1oQypBKMJirJBGOw.png"/></div></figure><p id="c851" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这里，“属性”是所有列的输入特征，“medv”是目标列。</p><p id="fec2" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">接下来，我们应该根据我们的数据集拆分训练和测试数据(在本例中为 0.8 和 0.2)。</p><pre class="kj kk kl km gt mt mu mv mw aw mx bi"><span id="91f5" class="lv lw it mu b gy my mz l na nb">#Split training and testing data<br/>train_data,test_data = finalized_data.randomSplit([0.8,0.2])</span><span id="535e" class="lv lw it mu b gy ne mz l na nb">regressor = LinearRegression(featuresCol = 'Attributes', labelCol = 'medv')</span><span id="cd91" class="lv lw it mu b gy ne mz l na nb">#Learn to fit the model from training set<br/>regressor = regressor.fit(train_data)</span><span id="2381" class="lv lw it mu b gy ne mz l na nb">#To predict the prices on testing set<br/>pred = regressor.evaluate(test_data)</span><span id="89fe" class="lv lw it mu b gy ne mz l na nb">#Predict the model<br/>pred.predictions.show()</span></pre><p id="e7aa" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">预测列中的预测得分作为输出:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nh"><img src="../Images/f37ba1425a4b750037746eeb6fd82514.png" data-original-src="https://miro.medium.com/v2/resize:fit:1068/format:webp/1*uTb3prZNYtkh2oAtxdIhZw.png"/></div></figure><p id="a9ab" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们还可以使用以下命令打印回归模型的系数和截距:</p><pre class="kj kk kl km gt mt mu mv mw aw mx bi"><span id="8e27" class="lv lw it mu b gy my mz l na nb">#coefficient of the regression model<br/>coeff = regressor.coefficients</span><span id="4ec9" class="lv lw it mu b gy ne mz l na nb">#X and Y intercept<br/>intr = regressor.intercept</span><span id="9665" class="lv lw it mu b gy ne mz l na nb">print ("The coefficient of the model is : %a" %coeff)<br/>print ("The Intercept of the model is : %f" %intr)</span></pre><p id="bb21" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">完成基本的线性回归操作后，我们可以进一步从 Pyspark 导入<a class="ae ky" href="https://jaceklaskowski.gitbooks.io/mastering-apache-spark/spark-mllib/spark-mllib-RegressionEvaluator.html" rel="noopener ugc nofollow" target="_blank"> RegressionEvaluator </a>模块，对我们的模型进行统计分析。</p><pre class="kj kk kl km gt mt mu mv mw aw mx bi"><span id="5d3e" class="lv lw it mu b gy my mz l na nb">from pyspark.ml.evaluation import RegressionEvaluator<br/>eval = RegressionEvaluator(labelCol="medv", predictionCol="prediction", metricName="rmse")</span><span id="67fd" class="lv lw it mu b gy ne mz l na nb"># Root Mean Square Error<br/>rmse = eval.evaluate(pred.predictions)<br/>print("RMSE: %.3f" % rmse)</span><span id="b026" class="lv lw it mu b gy ne mz l na nb"># Mean Square Error<br/>mse = eval.evaluate(pred.predictions, {eval.metricName: "mse"})<br/>print("MSE: %.3f" % mse)</span><span id="cf49" class="lv lw it mu b gy ne mz l na nb"># Mean Absolute Error<br/>mae = eval.evaluate(pred.predictions, {eval.metricName: "mae"})<br/>print("MAE: %.3f" % mae)</span><span id="1b5d" class="lv lw it mu b gy ne mz l na nb"># r2 - coefficient of determination<br/>r2 = eval.evaluate(pred.predictions, {eval.metricName: "r2"})<br/>print("r2: %.3f" %r2)</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ni"><img src="../Images/fcea3bd85da5f784272d7da72a35ee07.png" data-original-src="https://miro.medium.com/v2/resize:fit:360/format:webp/1*E37E5OIO1XFPP-RXHQH67Q.png"/></div></div></figure><p id="4403" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">就是这样。你已经在 Google Colab 中使用 Pyspark 创建了你的第一个机器学习模型。</p><p id="cbcd" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">你可以从 github 的<a class="ae ky" href="https://github.com/asifahmed90/pyspark-ML-in-Colab/blob/master/PySpark_Regression_Analysis.ipynb" rel="noopener ugc nofollow" target="_blank">这里</a>获得完整的代码。</p><p id="4df5" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">请让我知道，如果你遇到任何其他的新手问题，我也许可以帮助你。如果可以的话，我很乐意帮助你！</p></div></div>    
</body>
</html>