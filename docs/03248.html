<html>
<head>
<title>Segmenting Credit Card Customers with Machine Learning</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">利用机器学习细分信用卡客户</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/segmenting-credit-card-customers-with-machine-learning-ed4dbcea009c?source=collection_archive---------14-----------------------#2019-05-24">https://towardsdatascience.com/segmenting-credit-card-customers-with-machine-learning-ed4dbcea009c?source=collection_archive---------14-----------------------#2019-05-24</a></blockquote><div><div class="fc if ig ih ii ij"/><div class="ik il im in io"><div class=""/><div class=""><h2 id="d287" class="pw-subtitle-paragraph jo iq ir bd b jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf dk translated">利用无监督机器学习识别可销售细分市场</h2></div><figure class="kh ki kj kk gu kl gi gj paragraph-image"><div role="button" tabindex="0" class="km kn di ko bf kp"><div class="gi gj kg"><img src="../Images/9476bdd186a7b0aa45fe993f3c046aec.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Jo5Km_GgbPvQ5IliG9iFdA.jpeg"/></div></div><figcaption class="ks kt gk gi gj ku kv bd b be z dk">Photo by <a class="ae kw" href="https://unsplash.com/photos/x8i6FfaZAbs?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank">Ryan Born</a> on <a class="ae kw" href="https://unsplash.com/search/photos/credit-card?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><p id="a025" class="pw-post-body-paragraph kx ky ir kz b la lb js lc ld le jv lf lg lh li lj lk ll lm ln lo lp lq lr ls ik bi translated"><em class="lt">市场营销中的细分是一种技术，用于根据行为或人口统计等属性将客户或其他实体分成不同的群体。确定可能以类似方式对特定营销技术(如电子邮件主题行或展示广告)做出反应的客户群非常有用。因为它使企业能够定制营销消息和时机，以产生更好的响应率并提供改善的消费者体验。</em></p><p id="28d4" class="pw-post-body-paragraph kx ky ir kz b la lb js lc ld le jv lf lg lh li lj lk ll lm ln lo lp lq lr ls ik bi translated">在接下来的文章中，我将使用一个包含信用卡客户行为属性的数据集。数据集可以从 Kaggle <a class="ae kw" href="https://www.kaggle.com/arjunbhasin2013/ccdata" rel="noopener ugc nofollow" target="_blank">网站</a>下载。我将使用<a class="ae kw" href="https://scikit-learn.org/stable/modules/clustering.html" rel="noopener ugc nofollow" target="_blank"> scikit-learn </a> python 机器学习库来应用一种称为聚类的无监督机器学习技术，以识别人类认知可能不会立即显现的片段。</p><p id="057a" class="pw-post-body-paragraph kx ky ir kz b la lb js lc ld le jv lf lg lh li lj lk ll lm ln lo lp lq lr ls ik bi translated">该数据集由 18 个信用卡客户行为特征组成。这些变量包括当前卡上的余额、账户上的购物次数、信用额度等。完整的<a class="ae kw" href="https://www.kaggle.com/arjunbhasin2013/ccdata/discussion/91399" rel="noopener ugc nofollow" target="_blank">数据字典</a>可在数据下载页面找到。</p><p id="7a9d" class="pw-post-body-paragraph kx ky ir kz b la lb js lc ld le jv lf lg lh li lj lk ll lm ln lo lp lq lr ls ik bi translated"><strong class="kz is">设置</strong></p><p id="fac9" class="pw-post-body-paragraph kx ky ir kz b la lb js lc ld le jv lf lg lh li lj lk ll lm ln lo lp lq lr ls ik bi translated"><em class="lt">我在</em><a class="ae kw" href="https://blog.jupyter.org/jupyterlab-is-ready-for-users-5a6f039b8906" rel="noopener ugc nofollow" target="_blank"><em class="lt">JupyterLab</em></a><em class="lt">中运行以下代码。我正在使用</em><a class="ae kw" href="https://github.com/rasbt/watermark" rel="noopener ugc nofollow" target="_blank"><em class="lt">iPython magic</em></a><em class="lt">扩展水印来记录我正在运行的工具的版本。如果您在运行代码时遇到任何问题，其输出如下所示。库导入也显示在下面。</em></p><pre class="kh ki kj kk gu lu lv lw lx aw ly bi"><span id="65cb" class="lz ma ir lv b gz mb mc l md me">%load_ext watermark<br/>%watermark -d -m -v -p numpy,matplotlib,sklearn,seaborn,pandas -g</span></pre><figure class="kh ki kj kk gu kl gi gj paragraph-image"><div class="gi gj mf"><img src="../Images/df94732ac254357e9187c1c3be439c35.png" data-original-src="https://miro.medium.com/v2/resize:fit:536/format:webp/1*2xybBuICE13A4l1jh2OYSQ.png"/></div></figure><pre class="kh ki kj kk gu lu lv lw lx aw ly bi"><span id="33f2" class="lz ma ir lv b gz mb mc l md me">import pandas as pd<br/>import numpy as np</span><span id="e054" class="lz ma ir lv b gz mg mc l md me">from sklearn.cluster import KMeans<br/>from sklearn import preprocessing</span><span id="c091" class="lz ma ir lv b gz mg mc l md me">import matplotlib.pyplot as plt<br/>%matplotlib inline<br/>import seaborn as sns</span></pre><h2 id="3aa7" class="lz ma ir bd mh mi mj dn mk ml mm dp mn lg mo mp mq lk mr ms mt lo mu mv mw mx bi translated">数据清理</h2><p id="1493" class="pw-post-body-paragraph kx ky ir kz b la my js lc ld mz jv lf lg na li lj lk nb lm ln lo nc lq lr ls ik bi translated">首先，我们需要检查数据，找出可能需要的清理和转换。scikit-learn 库要求所有数据都没有空值，并且所有值都必须是数字。</p><p id="7d2a" class="pw-post-body-paragraph kx ky ir kz b la lb js lc ld le jv lf lg lh li lj lk ll lm ln lo lp lq lr ls ik bi translated">首先，我已经阅读了下载的 csv 文件。</p><pre class="kh ki kj kk gu lu lv lw lx aw ly bi"><span id="2c28" class="lz ma ir lv b gz mb mc l md me">TRAIN_FILE = 'CC GENERAL.csv'<br/>train_data = pd.read_csv(TRAIN_FILE)</span></pre><p id="0e94" class="pw-post-body-paragraph kx ky ir kz b la lb js lc ld le jv lf lg lh li lj lk ll lm ln lo lp lq lr ls ik bi translated">首先，我运行下面的代码来检查数据类型，看看是否有需要转换的分类变量。从结果中我们可以看到，除了<code class="fe nd ne nf lv b">CUST_ID</code>以外，所有的特征都是数字。但是因为我们不需要这个特性来训练模型，所以我们不需要在这里做任何转换。</p><pre class="kh ki kj kk gu lu lv lw lx aw ly bi"><span id="6e93" class="lz ma ir lv b gz mb mc l md me">print("Data Types:", train_data.dtypes)</span><span id="ce4f" class="lz ma ir lv b gz mg mc l md me">output:<br/>Data Types: CUST_ID                              object<br/>BALANCE                             float64<br/>BALANCE_FREQUENCY                   float64<br/>PURCHASES                           float64<br/>ONEOFF_PURCHASES                    float64<br/>INSTALLMENTS_PURCHASES              float64<br/>CASH_ADVANCE                        float64<br/>PURCHASES_FREQUENCY                 float64<br/>ONEOFF_PURCHASES_FREQUENCY          float64<br/>PURCHASES_INSTALLMENTS_FREQUENCY    float64<br/>CASH_ADVANCE_FREQUENCY              float64<br/>CASH_ADVANCE_TRX                      int64<br/>PURCHASES_TRX                         int64<br/>CREDIT_LIMIT                        float64<br/>PAYMENTS                            float64<br/>MINIMUM_PAYMENTS                    float64<br/>PRC_FULL_PAYMENT                    float64<br/>TENURE                                int64</span></pre><p id="c6af" class="pw-post-body-paragraph kx ky ir kz b la lb js lc ld le jv lf lg lh li lj lk ll lm ln lo lp lq lr ls ik bi translated">运行下面的代码告诉我，只有两个特性具有空值“CREDIT_LIMIT”和“MINIMUM_PAYMENTS”。此外，每列中只有不到 5%的部分为空。这意味着我们应该可以用合理的替换值来填充它们，并且应该仍然能够使用该特性。</p><pre class="kh ki kj kk gu lu lv lw lx aw ly bi"><span id="5878" class="lz ma ir lv b gz mb mc l md me">train_data.apply(lambda x: sum(x.isnull()/len(train_data)))</span><span id="6b05" class="lz ma ir lv b gz mg mc l md me">Output:<br/>CUST_ID                             0.000000<br/>BALANCE                             0.000000<br/>BALANCE_FREQUENCY                   0.000000<br/>PURCHASES                           0.000000<br/>ONEOFF_PURCHASES                    0.000000<br/>INSTALLMENTS_PURCHASES              0.000000<br/>CASH_ADVANCE                        0.000000<br/>PURCHASES_FREQUENCY                 0.000000<br/>ONEOFF_PURCHASES_FREQUENCY          0.000000<br/>PURCHASES_INSTALLMENTS_FREQUENCY    0.000000<br/>CASH_ADVANCE_FREQUENCY              0.000000<br/>CASH_ADVANCE_TRX                    0.000000<br/>PURCHASES_TRX                       0.000000<br/>CREDIT_LIMIT                        0.000112<br/>PAYMENTS                            0.000000<br/>MINIMUM_PAYMENTS                    0.034972<br/>PRC_FULL_PAYMENT                    0.000000<br/>TENURE                              0.000000</span></pre><p id="0fa9" class="pw-post-body-paragraph kx ky ir kz b la lb js lc ld le jv lf lg lh li lj lk ll lm ln lo lp lq lr ls ik bi translated">下面的代码用列中最常出现的值填充缺少的值。我们同样可以使用均值或中值，或者其他方法，但如果需要，我们将从这里开始迭代。</p><pre class="kh ki kj kk gu lu lv lw lx aw ly bi"><span id="e85b" class="lz ma ir lv b gz mb mc l md me">train_clean = train_data.apply(lambda x:x.fillna(x.value_counts().index[0]))</span></pre><p id="eb68" class="pw-post-body-paragraph kx ky ir kz b la lb js lc ld le jv lf lg lh li lj lk ll lm ln lo lp lq lr ls ik bi translated">我还将删除<code class="fe nd ne nf lv b">CUST_ID</code>列，因为我们在培训中不需要它。</p><pre class="kh ki kj kk gu lu lv lw lx aw ly bi"><span id="9777" class="lz ma ir lv b gz mb mc l md me">cols_to_drop = 'CUST_ID'<br/>train_clean = train_clean.drop([cols_to_drop], axis=1)</span></pre><h2 id="727c" class="lz ma ir bd mh mi mj dn mk ml mm dp mn lg mo mp mq lk mr ms mt lo mu mv mw mx bi translated">特征缩放</h2><p id="0d36" class="pw-post-body-paragraph kx ky ir kz b la my js lc ld mz jv lf lg na li lj lk nb lm ln lo nc lq lr ls ik bi translated">在训练模型之前，我要做的最后一项处理是缩放特征。</p><p id="8b91" class="pw-post-body-paragraph kx ky ir kz b la lb js lc ld le jv lf lg lh li lj lk ll lm ln lo lp lq lr ls ik bi translated">我在这篇文章中使用的聚类模型是 K-Means。简单来说，下面是该算法的工作原理:</p><ol class=""><li id="35ef" class="ng nh ir kz b la lb ld le lg ni lk nj lo nk ls nl nm nn no bi translated">取预定数量的簇。</li><li id="1fd5" class="ng nh ir kz b la np ld nq lg nr lk ns lo nt ls nl nm nn no bi translated">找到每个聚类的质心，实质上就是平均值。</li><li id="5b32" class="ng nh ir kz b la np ld nq lg nr lk ns lo nt ls nl nm nn no bi translated">根据平方欧几里得距离将每个数据点分配给其最近的聚类。</li><li id="1e26" class="ng nh ir kz b la np ld nq lg nr lk ns lo nt ls nl nm nn no bi translated">一旦训练了新的看不见的数据点的聚类，就可以基于欧几里德距离来识别。</li></ol><p id="7b53" class="pw-post-body-paragraph kx ky ir kz b la lb js lc ld le jv lf lg lh li lj lk ll lm ln lo lp lq lr ls ik bi translated">因为它依赖于这种距离度量特征，所以缩放是一个非常重要的考虑因素。在我使用的数据集的例子中，让我们取两个特征<code class="fe nd ne nf lv b">PURCHASES_FREQUENCY</code>和<code class="fe nd ne nf lv b">BALANCE</code>。特征<code class="fe nd ne nf lv b">PURCHASES_FREQUENCY</code>是一个介于 0 和 1 之间的数字，而<code class="fe nd ne nf lv b">BALANCE</code>在这个数据集中是一个介于 0 和 19，043 之间的货币值。这些特征具有非常不同的尺度，这意味着如果我们不对它们进行标准化，使它们处于相同的尺度上。可能存在算法将给予一个变量更多权重的情况。</p><p id="3dc8" class="pw-post-body-paragraph kx ky ir kz b la lb js lc ld le jv lf lg lh li lj lk ll lm ln lo lp lq lr ls ik bi translated">以下代码缩放数据框中的所有要素。我在第一次迭代中使用了 min_max_scaler。不同的缩放技术可能会产生不同的结果。</p><pre class="kh ki kj kk gu lu lv lw lx aw ly bi"><span id="49df" class="lz ma ir lv b gz mb mc l md me">x = train_clean.values<br/>min_max_scaler = preprocessing.MinMaxScaler()<br/>x_scaled = min_max_scaler.fit_transform(x)<br/>train_clean = pd.DataFrame(x_scaled,columns=train_clean.columns)</span></pre><p id="0c62" class="pw-post-body-paragraph kx ky ir kz b la lb js lc ld le jv lf lg lh li lj lk ll lm ln lo lp lq lr ls ik bi translated">为了说明这一点，这里是缩放前的<code class="fe nd ne nf lv b">PURCHASES_FREQUENCY</code>和<code class="fe nd ne nf lv b">BALANCE </code>列。</p><figure class="kh ki kj kk gu kl gi gj paragraph-image"><div class="gi gj nu"><img src="../Images/6041d678137429136bc0fe0e58933249.png" data-original-src="https://miro.medium.com/v2/resize:fit:548/format:webp/1*pKN-PAZ8DH3Zt8f84botQA.png"/></div></figure><p id="4ad8" class="pw-post-body-paragraph kx ky ir kz b la lb js lc ld le jv lf lg lh li lj lk ll lm ln lo lp lq lr ls ik bi translated">缩放后。</p><figure class="kh ki kj kk gu kl gi gj paragraph-image"><div class="gi gj nv"><img src="../Images/f8d585814fd579c141e757e406c22c08.png" data-original-src="https://miro.medium.com/v2/resize:fit:532/format:webp/1*BLWgWZD_CK5wXVwCvSqeTw.png"/></div></figure><h2 id="d694" class="lz ma ir bd mh mi mj dn mk ml mm dp mn lg mo mp mq lk mr ms mt lo mu mv mw mx bi translated">有多少个集群？</h2><p id="f65d" class="pw-post-body-paragraph kx ky ir kz b la my js lc ld mz jv lf lg na li lj lk nb lm ln lo nc lq lr ls ik bi translated">我之前提到过，我们需要告诉 K-Means 算法它应该使用的聚类数。有许多技术可以用来找到最佳数量。对于这个例子，我将使用<a class="ae kw" href="https://en.wikipedia.org/wiki/Elbow_method_(clustering)" rel="noopener ugc nofollow" target="_blank">肘方法</a>,这样命名是因为它产生的图表在形状上类似于肘的曲线。此方法计算聚类 k 的距离平方和。随着使用的聚类越来越多，方差将会减少，直到达到某个点，在该点上增加聚类不再会产生更好的模型。从这篇<a class="ae kw" href="https://blog.cambridgespark.com/how-to-determine-the-optimal-number-of-clusters-for-k-means-clustering-14f27070048f" rel="noopener ugc nofollow" target="_blank">文章</a>中借用的代码说明了这一点。谢谢<a class="ae kw" href="https://blog.cambridgespark.com/@tolaalade_48082" rel="noopener ugc nofollow" target="_blank">托拉孙心怡</a>！</p><pre class="kh ki kj kk gu lu lv lw lx aw ly bi"><span id="5afd" class="lz ma ir lv b gz mb mc l md me">Sum_of_squared_distances = []<br/>K = range(1,15)<br/>for k in K:<br/>    km = KMeans(n_clusters=k)<br/>    km = km.fit(train_clean)<br/>    Sum_of_squared_distances.append(km.inertia_)</span><span id="0b20" class="lz ma ir lv b gz mg mc l md me">plt.plot(K, Sum_of_squared_distances, 'bx-')<br/>plt.xlabel('k')<br/>plt.ylabel('Sum_of_squared_distances')<br/>plt.title('Elbow Method For Optimal k')<br/>plt.show()</span></pre><figure class="kh ki kj kk gu kl gi gj paragraph-image"><div class="gi gj nw"><img src="../Images/b5b8caca9f5e93f11141e5896b38f23a.png" data-original-src="https://miro.medium.com/v2/resize:fit:812/format:webp/1*SJwdAkRhcIbiHZx988q8_Q.png"/></div></figure><p id="68f2" class="pw-post-body-paragraph kx ky ir kz b la lb js lc ld le jv lf lg lh li lj lk ll lm ln lo lp lq lr ls ik bi translated">您可以看到，在 8 个集群之后，添加更多集群对模型的好处微乎其微。因此，我将使用 8 个聚类来训练我的模型。</p><h2 id="0f9c" class="lz ma ir bd mh mi mj dn mk ml mm dp mn lg mo mp mq lk mr ms mt lo mu mv mw mx bi translated">培养</h2><p id="e8ad" class="pw-post-body-paragraph kx ky ir kz b la my js lc ld mz jv lf lg na li lj lk nb lm ln lo nc lq lr ls ik bi translated">在训练之前，我将把数据集分为训练集和测试集。下面的代码划分数据，保留 20%用于测试。</p><pre class="kh ki kj kk gu lu lv lw lx aw ly bi"><span id="b5c0" class="lz ma ir lv b gz mb mc l md me">np.random.seed(0)<br/>msk = np.random.rand(len(train_clean)) &lt; 0.8<br/>train = train_clean[msk]<br/>test = train_clean[~msk]</span></pre><p id="eaf3" class="pw-post-body-paragraph kx ky ir kz b la lb js lc ld le jv lf lg lh li lj lk ll lm ln lo lp lq lr ls ik bi translated">然后，我将训练集和测试集都转换成 numpy 数组。</p><pre class="kh ki kj kk gu lu lv lw lx aw ly bi"><span id="fdcc" class="lz ma ir lv b gz mb mc l md me">X = np.array(train)<br/>X_test = np.array(test)</span></pre><p id="b682" class="pw-post-body-paragraph kx ky ir kz b la lb js lc ld le jv lf lg lh li lj lk ll lm ln lo lp lq lr ls ik bi translated">接下来，我使用 8 个集群调用 KMeans fit 方法。</p><pre class="kh ki kj kk gu lu lv lw lx aw ly bi"><span id="3d85" class="lz ma ir lv b gz mb mc l md me">kmeans = KMeans(n_clusters=8, random_state=0).fit(X)</span></pre><p id="540d" class="pw-post-body-paragraph kx ky ir kz b la lb js lc ld le jv lf lg lh li lj lk ll lm ln lo lp lq lr ls ik bi translated">使用训练好的模型，我现在将预测测试集上的聚类。</p><pre class="kh ki kj kk gu lu lv lw lx aw ly bi"><span id="92a0" class="lz ma ir lv b gz mb mc l md me">y_k = kmeans.predict(X_test)</span></pre><p id="5ccc" class="pw-post-body-paragraph kx ky ir kz b la lb js lc ld le jv lf lg lh li lj lk ll lm ln lo lp lq lr ls ik bi translated">现在，我将把预测指定为原始测试数据框上的一个新列，以分析结果。</p><pre class="kh ki kj kk gu lu lv lw lx aw ly bi"><span id="9b68" class="lz ma ir lv b gz mb mc l md me">test['PREDICTED_CLUSTER'] = y_k</span></pre><h2 id="8f3e" class="lz ma ir bd mh mi mj dn mk ml mm dp mn lg mo mp mq lk mr ms mt lo mu mv mw mx bi translated">分析集群</h2><p id="4ce6" class="pw-post-body-paragraph kx ky ir kz b la my js lc ld mz jv lf lg na li lj lk nb lm ln lo nc lq lr ls ik bi translated">我将使用 pandas groupby 函数来分析聚类的一些选定特征，以了解模型是否成功识别了独特的片段。</p><pre class="kh ki kj kk gu lu lv lw lx aw ly bi"><span id="dffc" class="lz ma ir lv b gz mb mc l md me">train_summary = test.groupby(by='PREDICTED_CLUSTER').mean()<br/>train_summary = train_summary[['BALANCE', 'PURCHASES', <br/>                               'PURCHASES_FREQUENCY','CREDIT_LIMIT', <br/>                               'ONEOFF_PURCHASES_FREQUENCY', <br/>                              'MINIMUM_PAYMENTS','PRC_FULL_PAYMENT', <br/>                               'PAYMENTS']]<br/>train_summary</span></pre><p id="c74d" class="pw-post-body-paragraph kx ky ir kz b la lb js lc ld le jv lf lg lh li lj lk ll lm ln lo lp lq lr ls ik bi translated">这给出了以下输出。</p><figure class="kh ki kj kk gu kl gi gj paragraph-image"><div role="button" tabindex="0" class="km kn di ko bf kp"><div class="gi gj nx"><img src="../Images/e71aa3fcc8a95c1c8bc788224696352c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*9AbBXwtu0fqWDCgvsTSKFA.png"/></div></div></figure><p id="9ecd" class="pw-post-body-paragraph kx ky ir kz b la lb js lc ld le jv lf lg lh li lj lk ll lm ln lo lp lq lr ls ik bi translated">只需查看“PURCHASES_FREQUENCY ”,我们就可以看到该模型已经识别出一些高频购买细分市场，即集群 2 和集群 3。让我们了解这两个部分之间的差异，以进一步确定它们为什么在不同的群集中。我们可以看到，集群 3 的总购买次数更多，信用额度更高，他们经常进行一次性购买，更有可能全额支付。我们可以得出结论，这些都是高价值的客户，因此几乎可以肯定的是，你如何向这些客户营销会有所不同。</p><p id="a726" class="pw-post-body-paragraph kx ky ir kz b la lb js lc ld le jv lf lg lh li lj lk ll lm ln lo lp lq lr ls ik bi translated">作为模型的第一次迭代，这似乎是识别一些有用的部分。我们可以通过多种方式调整模型，包括替代数据清理方法、特征工程、删除高相关性特征和超参数优化。然而，出于这篇文章的目的，我想给出一个关于如何启动一个执行无监督聚类的机器学习模型的高级端到端视图。</p></div></div>    
</body>
</html>