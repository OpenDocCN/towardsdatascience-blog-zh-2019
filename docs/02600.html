<html>
<head>
<title>Analyzing CNET’s Headlines</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">分析 CNET 的标题</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/analyzing-cnets-headlines-3f350bb97cd4?source=collection_archive---------17-----------------------#2019-04-28">https://towardsdatascience.com/analyzing-cnets-headlines-3f350bb97cd4?source=collection_archive---------17-----------------------#2019-04-28</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="5580" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">使用 Python 和熊猫探索 CNET 上发布的新闻</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/7e656f7b0d4d1b5464d6eed8997af1ca.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*cGuruaul8ki2Ou1n"/></div></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk">Photo by <a class="ae kv" href="https://unsplash.com/@m_b_m?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">M. B. M.</a> on <a class="ae kv" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><p id="072c" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我写了一个爬虫从 CNET 的网站地图中抓取新闻标题，并决定对其进行一些探索性分析。在这篇文章中，我将向你介绍我的发现、一些异常现象和一些有趣的见解。如果你想直接进入，你可以在找到代码<a class="ae kv" href="https://github.com/sagunsh/cnet_analysis" rel="noopener ugc nofollow" target="_blank">。</a></p><p id="16b6" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir">履带</strong></p><p id="0e15" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">爬虫使用<a class="ae kv" href="https://scrapy.org/" rel="noopener ugc nofollow" target="_blank"> Scrapy </a>编写，这是一个用 Python 编写的开源网络爬行框架。有一个选项可以将数据转储到 csv 或 json 文件中，只需对命令稍作修改。你可以在我的<a class="ae kv" href="https://github.com/sagunsh/cnet_analysis" rel="noopener ugc nofollow" target="_blank"> GitHub repo </a>中找到代码和命令。是时候深入分析了。</p><p id="8091" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir">装载和清洗数据</strong></p><p id="3007" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">第一步是加载数据，然后清理数据，为分析做好准备。</p><pre class="kg kh ki kj gt ls lt lu lv aw lw bi"><span id="4c82" class="lx ly iq lt b gy lz ma l mb mc">import numpy as np<br/>import pandas as pd<br/>import matplotlib.pyplot as plt<br/>%matplotlib inline</span><span id="9720" class="lx ly iq lt b gy md ma l mb mc">df = pd.read_csv('cnet_data.csv')</span><span id="9c8e" class="lx ly iq lt b gy md ma l mb mc">df.head()</span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi me"><img src="../Images/e84e2c5048465aec11d7e207d9b0911e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*TaHynS4ugbrsMBLFrP1xsw.png"/></div></div></figure><p id="d5c4" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">df.head()只输出数据帧的前 5 行。这里我们有 3 列:标题，链接和日期。这里明智的做法是将 date 列中的值转换为 datetime 对象。这将使访问年，月，日，工作日更容易。</p><pre class="kg kh ki kj gt ls lt lu lv aw lw bi"><span id="8c57" class="lx ly iq lt b gy lz ma l mb mc">df['date'] = pd.to_datetime(df.date, format='%Y-%m-%d')</span></pre><p id="9cb6" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">注意:df.date 与 df['date']相同。只要列名是有效的变量名，就可以使用点(.)，否则您将需要使用 df['列名']</p><p id="707f" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">数据集最常见的问题之一是空值。让我们从数据帧中删除标题为空的行。</p><pre class="kg kh ki kj gt ls lt lu lv aw lw bi"><span id="3b56" class="lx ly iq lt b gy lz ma l mb mc">df = df[pd.notnull(df['title'])]</span></pre><p id="0a9f" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">现在我们可以开始分析了。</p><p id="944d" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir">分析</strong></p><p id="fee1" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">让我们按日期分析文章发表的频率。</p><pre class="kg kh ki kj gt ls lt lu lv aw lw bi"><span id="8cf0" class="lx ly iq lt b gy lz ma l mb mc">ax = df.groupby(df.date.dt.year)['title'].count().plot(kind='bar', figsize=(12, 6))</span><span id="88c0" class="lx ly iq lt b gy md ma l mb mc">ax.set(xlabel='Year', ylabel='Number of Articles', title="Articles Published Every Year")</span><span id="d246" class="lx ly iq lt b gy md ma l mb mc">plt.show()</span></pre><p id="b1e1" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">上面几行代码按年份对记录进行分组，并绘制计数。代码中的一切似乎都是不言自明的。我们可以将<code class="fe mf mg mh lt b">kind</code>参数设置为其他值，如 line 表示线图，barh 表示水平条。查看<a class="ae kv" href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.plot.html" rel="noopener ugc nofollow" target="_blank">文档</a>了解更多详情。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi mi"><img src="../Images/08b0a05af6cc9e56def1be0191ca64c0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*i02Iohk--jVrzWK8jqI-lQ.png"/></div></div></figure><p id="5c14" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我们可以为月份和工作日绘制类似的图表。</p><pre class="kg kh ki kj gt ls lt lu lv aw lw bi"><span id="7bec" class="lx ly iq lt b gy lz ma l mb mc">ax = df.groupby(df.date.dt.month)['title'].count().plot(kind='bar')<br/>months = ['JAN',  'FEB', 'MAR', 'APR', 'MAY', 'JUN', 'JUL', 'AUG', 'SEP', 'OCT', 'NOV', 'DEC']</span><span id="b5c2" class="lx ly iq lt b gy md ma l mb mc">ax.set_xticklabels(months)<br/>ax.set(xlabel='Month', ylabel='Number of Articles', title="Articles Published Every Month")</span><span id="9f35" class="lx ly iq lt b gy md ma l mb mc">plt.show()</span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi mj"><img src="../Images/4e5146c9a25249ab7679bac98fb70ee6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*uCrr-vzTQwV9rhO9JweA7Q.png"/></div></div></figure><pre class="kg kh ki kj gt ls lt lu lv aw lw bi"><span id="1e95" class="lx ly iq lt b gy lz ma l mb mc">ax = df.groupby(df.date.dt.weekday)['title'].count().plot(kind='bar')</span><span id="6e84" class="lx ly iq lt b gy md ma l mb mc">days_of_week = ['MON', 'TUE', 'WED', 'THU', 'FRI', 'SAT', 'SUN']<br/>ax.set_xticklabels(days_of_week)<br/>ax.set(xlabel='Day of Week', ylabel='Number of Articles', title="Articles Published Every WeekDay")</span><span id="f529" class="lx ly iq lt b gy md ma l mb mc">plt.show()</span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi mj"><img src="../Images/1ef8c29197f7925d340c97ded70992fb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*chopaGVESozS4vGJ1qsPcA.png"/></div></div></figure><ul class=""><li id="ce72" class="mk ml iq ky b kz la lc ld lf mm lj mn ln mo lr mp mq mr ms bi translated">2009 年发表的文章数量最多，1995 年最少。</li><li id="c945" class="mk ml iq ky b kz mt lc mu lf mv lj mw ln mx lr mp mq mr ms bi translated">九月份发表的文章数量最多。</li><li id="4127" class="mk ml iq ky b kz mt lc mu lf mv lj mw ln mx lr mp mq mr ms bi translated">除了九月，其他月份发表的文章数量几乎相同。</li><li id="65b3" class="mk ml iq ky b kz mt lc mu lf mv lj mw ln mx lr mp mq mr ms bi translated">星期三是一周中最忙的一天。</li><li id="ae33" class="mk ml iq ky b kz mt lc mu lf mv lj mw ln mx lr mp mq mr ms bi translated">不出所料，周末发表的文章数量很少。</li></ul><pre class="kg kh ki kj gt ls lt lu lv aw lw bi"><span id="10bb" class="lx ly iq lt b gy lz ma l mb mc">df['date'].value_counts().head(10)</span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi my"><img src="../Images/7bab02455ca5d76c1058381a9c149a18.png" data-original-src="https://miro.medium.com/v2/resize:fit:718/format:webp/1*qyIN8kl0I_y3GmIvJvkqbQ.png"/></div></figure><p id="7c38" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">有趣的是，2009 年 9 月 2 日有 15000 多篇文章，前一天有 35000 多篇。这可能是为什么我们在之前的图表中看到 9 月和 2009 年以相当大的优势赢得比赛的原因。</p><p id="3a00" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">让我们忽略前 5 个结果，绘制一个图表来显示按日期发布的文章的分布。</p><pre class="kg kh ki kj gt ls lt lu lv aw lw bi"><span id="e787" class="lx ly iq lt b gy lz ma l mb mc">ax = df['date'].value_counts()[5:].plot(color='red', figsize=(12,6))<br/>ax.set(xlabel='Date', ylabel='Number of Articles')<br/>plt.show()</span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi mz"><img src="../Images/0cd410676206260581920e1a785282d8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*xf9kQuTsPcSTHdwc_Ku1gA.png"/></div></div></figure><p id="b2a6" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我仍然很好奇 2009 年 9 月 2 日发生了什么，导致如此大量的文章被发表。我们来看看当天出现在头条上的主导关键词。</p><pre class="kg kh ki kj gt ls lt lu lv aw lw bi"><span id="66b1" class="lx ly iq lt b gy lz ma l mb mc">from wordcloud import WordCloud<br/>stopwords = set(open('stopwords.txt').read().split(','))<br/>wc = WordCloud(stopwords=stopwords)<br/>wordcloud = wc.generate(' '.join(df[df.date=='2009-09-02']['title'].apply(str)))</span><span id="f2a9" class="lx ly iq lt b gy md ma l mb mc">plt.imshow(wordcloud, interpolation='bilinear')<br/>plt.axis('off')<br/>plt.show()</span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi na"><img src="../Images/e89abd810bd5512e08bb4c813c77c8e2.png" data-original-src="https://miro.medium.com/v2/resize:fit:770/format:webp/1*9N1j4ivj_9wRD5dyJIwCoA.png"/></div></figure><p id="deeb" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">苹果似乎在当天的新闻中占据主导地位。我们可以在词云中看到 Mac，Apple，iTunes 这样的关键词。</p><pre class="kg kh ki kj gt ls lt lu lv aw lw bi"><span id="8872" class="lx ly iq lt b gy lz ma l mb mc">wordcloud = wc.generate(' '.join(df['title'].apply(str)))<br/>plt.imshow(wordcloud, interpolation='bilinear')<br/>plt.axis('off')<br/>plt.show()</span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi na"><img src="../Images/0dccce8e7a74424366b6f5428dadd1a7.png" data-original-src="https://miro.medium.com/v2/resize:fit:770/format:webp/1*6j9CekEeTQ0rWVARxPw_LA.png"/></div></figure><p id="b430" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">纵观整个数据框架，头条新闻被谷歌、苹果、微软和脸书占据，这是意料之中的。</p><p id="6fcb" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我们还可以统计一些热门关键词在头条中的出现次数。</p><pre class="kg kh ki kj gt ls lt lu lv aw lw bi"><span id="0338" class="lx ly iq lt b gy lz ma l mb mc">keywords = ['microsoft', 'apple', 'facebook', 'google', 'amazon', <br/>            'twitter', 'ibm', 'iphone', 'android', 'window', 'ios']</span><span id="5f10" class="lx ly iq lt b gy md ma l mb mc">for kw in keywords:<br/>    count = df[df['title'].str.contains(kw, case=False)].title.count()<br/>    print('{} found {} times'.format(kw, count))</span><span id="5362" class="lx ly iq lt b gy md ma l mb mc">microsoft found 12918 times<br/>apple found 17762 times<br/>facebook found 6342 times<br/>google found 13409 times<br/>amazon found 4162 times<br/>twitter found 3340 times<br/>ibm found 3178 times<br/>iphone found 11543 times<br/>android found 5801 times<br/>window found 6063 times<br/>ios found 3199 times</span></pre><p id="8839" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这是对 CNET 头条新闻的基本分析。你可以在我的<a class="ae kv" href="https://github.com/sagunsh/cnet_analysis" rel="noopener ugc nofollow" target="_blank"> github repo 这里</a>找到笔记本和数据。</p><p id="1c1b" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">随便玩玩，看看能不能在数据里找到什么有趣的东西，如果我漏掉了什么，就告诉我。</p><p id="02b9" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">喜欢这篇文章吗？在我分享类似内容的<a class="ae kv" href="https://twitter.com/sagunsh" rel="noopener ugc nofollow" target="_blank"> Twitter </a>上找到我。</p></div></div>    
</body>
</html>