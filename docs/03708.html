<html>
<head>
<title>Do GANs Dream of Fake Images?</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">甘人会梦到假图像吗？</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/do-gans-dream-of-fake-images-4372b0777a2d?source=collection_archive---------10-----------------------#2019-06-12">https://towardsdatascience.com/do-gans-dream-of-fake-images-4372b0777a2d?source=collection_archive---------10-----------------------#2019-06-12</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="4084" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">深入研究图像取证:区分真实图像和伪造图像的努力</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi kf"><img src="../Images/186af0b15b97d91d60eb74dcf529e99a.png" data-original-src="https://miro.medium.com/v2/resize:fit:888/1*DJ-H_9kmeZQEmSeQnYkNlA.gif"/></div><figcaption class="kn ko gj gh gi kp kq bd b be z dk">Barack Obama is one of the most popular characters for puppeteering</figcaption></figure><p id="3822" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">众所周知，现在很难区分真实媒体和虚假媒体。可能是文本、音频、视频或图像。</p><p id="0459" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">每种媒体都有自己的伪造方法。虽然伪造文本(仍然)主要是以传统方式进行的，但伪造图像和视频已经向前迈出了一大步。我们有些人甚至觉得再也分不清什么是真的什么是假的了。如果说两年前，<a class="ae ln" href="https://www.reddit.com/r/photoshopbattles/" rel="noopener ugc nofollow" target="_blank"> <strong class="kt ir"> photoshop 之战</strong> </a> sub-reddit 是伪造图像的艺术状态，photoshop 专家是这一领域的奇才，那么新技术已经改变了很多事情。</p><p id="5966" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">你可能听说过一些尖端的伪造方法，它们严重威胁着我们对什么是真什么是假的感知:<a class="ae ln" href="https://www.youtube.com/watch?v=gLoI9hAX9dw" rel="noopener ugc nofollow" target="_blank"> <strong class="kt ir">深度伪造</strong> </a>技术允许在每个视频中种植每张脸，不同的<strong class="kt ir">re</strong><a class="ae ln" href="https://www.youtube.com/watch?v=p1b5aiTrGzY" rel="noopener ugc nofollow" target="_blank"><strong class="kt ir">——制定</strong> </a>技术允许随心所欲地移动每张脸:做出表情、说话等。而这仅仅是开始。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi lo"><img src="../Images/b16d681cdff77a9d4aff074c8daa4bce.png" data-original-src="https://miro.medium.com/v2/resize:fit:878/0*e3aBVRUGi_9At_ht"/></div><figcaption class="kn ko gj gh gi kp kq bd b be z dk">Deep fake — planting Hillary Clinton on her impersonator</figcaption></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="lq lr di ls bf lt"><div class="gh gi lp"><img src="../Images/19af7fbc51f863691f64ed55aa61c633.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*W6WeAmIlOOcL5jlzblD7mw.png"/></div></div><figcaption class="kn ko gj gh gi kp kq bd b be z dk">Re-enactment — making a face talk</figcaption></figure><p id="3d01" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">最近，我非常投入这个领域:我已经开始与一家名为<a class="ae ln" href="https://www.cyabra.com/" rel="noopener ugc nofollow" target="_blank"> <strong class="kt ir"> Cyabra </strong> </a>的伟大初创公司合作。Cyabra 是一家反假新闻和反机器人的初创公司，因此，它的任务之一是将假图像与真图像进行分类，专业术语是<strong class="kt ir">图像取证</strong>。</p><p id="8797" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">如你所料，这是一项具有挑战性的任务。正如许多网络安全/欺诈检测任务一样，保护者似乎总是比伪造者落后一步。在图像伪造中，情况甚至更复杂，因为新的伪造技术每天都在出现。</p><p id="9e8d" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">那么解决 hits 任务的正确方法是什么呢？在每一项安全任务中，保护者都必须考虑所有可能的已知的 T21 威胁，此外还有攻击者意想不到的未知威胁。</p><p id="3612" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">让我们考虑一下防止窃贼入室:你知道窃贼可以破门而入，打破窗户、后门等。所以你把所有的入口都锁上了。但是你也应该放一个运动探测器，以防窃贼从一个未知的缺口进入，你仍然可以发现他。</p><p id="4b7c" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">在网络安全领域，特别是在数字图像取证领域，这意味着你必须以最高的准确性解决所有已知的伪造方法，以及一些通用的异常检测方法。由于如上所述，图像伪造技术正在经历一种繁荣，后一种方法变得更加重要。</p><h1 id="1888" class="lu lv iq bd lw lx ly lz ma mb mc md me jw mf jx mg jz mh ka mi kc mj kd mk ml bi translated">有哪些图像篡改技术？</h1><p id="cd0f" class="pw-post-body-paragraph kr ks iq kt b ku mm jr kw kx mn ju kz la mo lc ld le mp lg lh li mq lk ll lm ij bi translated">首先，让我们讨论一下我们在处理什么。</p><p id="c784" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">摄影锻造几乎和摄影本身一样古老。在下面的图片中，你可以看到一张被篡改的 19 世纪的照片:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="lq lr di ls bf lt"><div class="gh gi mr"><img src="../Images/fb98c1f037cf0c7eb4e1371e9a0040d1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*JnfyuCi6QCoAXMxe"/></div></div></figure><p id="3f95" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">更多的例子可以在哈尼·法里德的数字取证<strong class="kt ir">圣经</strong>——<a class="ae ln" href="https://www.amazon.com/Photo-Forensics-Press-Hany-Farid/dp/0262035340" rel="noopener ugc nofollow" target="_blank">书</a>中找到。</p><h2 id="019a" class="ms lv iq bd lw mt mu dn ma mv mw dp me la mx my mg le mz na mi li nb nc mk nd bi translated">“手动”伪造—Photoshop</h2><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi ne"><img src="../Images/22398cf38eb05b73ee95e0277cf7a88a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1358/format:webp/1*SaDCfiUa9ED3ZOVMSsj2cQ.png"/></div></figure><p id="a625" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">随着数码摄影的出现，图像篡改变得越来越容易和常见:最常见的一种被称为“<strong class="kt ir">拼接</strong>”和“<strong class="kt ir">复制-移动</strong>”，或大多数人所说的“<strong class="kt ir">Photoshop</strong>”。</p><p id="32f3" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">这些方法包括将一幅图像的一部分移植到另一幅图像中。为了让它看起来更真实，伪造者还会做一些数字修饰。这些技术的结果可能很难用肉眼区分。</p><p id="87a6" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">修图本身也是一种篡改方式，尤其是在时尚照中。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi nf"><img src="../Images/06091f7ccea4eebc730c8ac4e39c9e4d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*gltnzyYl23QAX4vw"/></div></figure><p id="9a9e" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">如前所述，photoshopping 并不总是容易辨别，但使用一些方法，将在稍后讨论，研究人员在事情的顶部。然而，技术让事情变得更难(或者更容易，取决于你站在哪一边)。具有讽刺意味的是，深度学习成为图像分类的主要方法，也允许一种新的、开创性的伪造物——生成模型。</p><h2 id="2e05" class="ms lv iq bd lw mt mu dn ma mv mw dp me la mx my mg le mz na mi li nb nc mk nd bi translated">基于生成模型的方法</h2><p id="db5a" class="pw-post-body-paragraph kr ks iq kt b ku mm jr kw kx mn ju kz la mo lc ld le mp lg lh li mq lk ll lm ij bi translated">自 2014 年出现一般敌对网络以来，很明显，图像伪造将永远不会相同。一个算法从字面上从零开始创造一个图像(例如一张脸)的能力既令人惊讶又令人恐惧。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="lq lr di ls bf lt"><div class="gh gi ng"><img src="../Images/c9a05752f2e36e13f2dfe097485f85a9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*4znkWqfMHPKZ8f-R"/></div></div><figcaption class="kn ko gj gh gi kp kq bd b be z dk">GANs results throughout the years (none of the above is a real person)</figcaption></figure><p id="4095" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">在他 2014 年的开创性工作中，Ian Goodfellow 从概念上展示了在小规模(28 X 28)下创建逼真的人脸是可能的。这一概念很快成为现实，2018 年底，Nvidia 研究人员推出了能够以高分辨率创建超现实人脸的<a class="ae ln" href="https://arxiv.org/abs/1812.04948" rel="noopener ugc nofollow" target="_blank"><strong class="kt ir"/></a><strong class="kt ir"/>。但这远不是对 GAN 的唯一研究:令人印象深刻的是，研究人员做了不同的调整，创造了新的假图像。我们只能想象这种技术的未来，但同时，让我们看看其他变体的一个不完全详尽的列表:</p><h2 id="dbaf" class="ms lv iq bd lw mt mu dn ma mv mw dp me la mx my mg le mz na mi li nb nc mk nd bi translated">CycleGan</h2><p id="8fb5" class="pw-post-body-paragraph kr ks iq kt b ku mm jr kw kx mn ju kz la mo lc ld le mp lg lh li mq lk ll lm ij bi translated">2017 年，2 部令人惊艳的作品出自<a class="ae ln" href="https://people.eecs.berkeley.edu/~efros/" rel="noopener ugc nofollow" target="_blank">阿列克谢·埃夫罗斯</a>实验室— <a class="ae ln" href="https://phillipi.github.io/pix2pix/" rel="noopener ugc nofollow" target="_blank"> <em class="nh"> pix2pix </em> </a>和<a class="ae ln" href="https://junyanz.github.io/CycleGAN/" rel="noopener ugc nofollow" target="_blank"> <em class="nh"> CycleGan </em> </a>。你可以在我之前的<a class="ae ln" rel="noopener" target="_blank" href="/a-different-kind-of-deep-learning-part-2-b447ff469255">帖子中读到它们。</a></p><p id="1cad" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">这两个作品都允许将图像从一个领域“复制”到另一个领域:将马转换成斑马，将狗转换成猫等等。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi ni"><img src="../Images/5ed8f5a14db35cffa99ab4c15b0cc2c1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1016/0*x6jznbnjm3OadGkP"/></div></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi nj"><img src="../Images/bea6bd36fe061aae188bd3344a210369.png" data-original-src="https://miro.medium.com/v2/resize:fit:728/0*E6pS1C3uLIeGpgvL"/></div></figure><h2 id="ce3d" class="ms lv iq bd lw mt mu dn ma mv mw dp me la mx my mg le mz na mi li nb nc mk nd bi translated">假视频——重现</h2><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi nk"><img src="../Images/02cbcec5bec7ca2065c471e9245adfa9.png" data-original-src="https://miro.medium.com/v2/resize:fit:742/format:webp/1*KtqhS7WT0CrB4EJ2v2sabw.png"/></div><figcaption class="kn ko gj gh gi kp kq bd b be z dk">Nicholas Cage as Marlon Brando as The Godfather</figcaption></figure><p id="dec0" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">除了创建假图像，深度学习技术更进一步，允许创建假视频。</p><p id="08ea" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">这个领域的真正转折点(和许多其他场合一样)不是技术，而是文化。2018 年 1 月左右，Reddit 上开始出现高质量的假视频。他们中的许多人将尼古拉斯·凯奇的脸植入不同的场景，但并不是所有人都是 SFW。这立即引发了媒体对这一领域的关注(以及世界末日的预言)。</p><p id="d016" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">但深度伪装并不孤单:最近这种技术激增，它们在真实性和易于训练方面变得越来越先进。从玩具“换脸”app 开始，通过<a class="ae ln" href="http://openaccess.thecvf.com/content_cvpr_2016/html/Thies_Face2Face_Real-Time_Face_CVPR_2016_paper.html" rel="noopener ugc nofollow" target="_blank"> face2face </a>、<a class="ae ln" href="https://www.youtube.com/watch?v=gLoI9hAX9dw" rel="noopener ugc nofollow" target="_blank">深度造假</a>、<a class="ae ln" href="https://grail.cs.washington.edu/projects/AudioToObama/siggraph17_obama.pdf" rel="noopener ugc nofollow" target="_blank">综合奥巴马</a>、<strong class="kt ir">、</strong>到最近三星的<a class="ae ln" href="https://arxiv.org/pdf/1905.08233.pdf" rel="noopener ugc nofollow" target="_blank">少数镜头说话头像</a>。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi nl"><img src="../Images/b862eaddfa440cfa6be12ad78cd26f09.png" data-original-src="https://miro.medium.com/v2/resize:fit:874/format:webp/1*u1iUeN_1RZULiHV8LxbI8A.png"/></div></figure><p id="e31f" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">目前在这个领域最令人印象深刻的工作(目前，事情进展很快)是<strong class="kt ir">深度视频肖像— </strong>在这个<a class="ae ln" href="https://web.stanford.edu/~zollhoef/papers/SG2018_DeepVideo/paper.pdf" rel="noopener ugc nofollow" target="_blank">工作</a>中，研究人员使用了一种多步骤的方法，来“操纵”一张全脸。他们首先从源视频和目标视频中提取面部特征，如姿势、表情、眼睛坐标等，然后使用编码器-解码器生成一个假视频，不仅可以控制嘴部运动和面部表情，还可以控制头部运动。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi nm"><img src="../Images/8d574e19fbc4ae12874df3767a15c2d7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1312/format:webp/1*hb_FVlUJWGK6NHsf2a9i4w.png"/></div><figcaption class="kn ko gj gh gi kp kq bd b be z dk">Deep video portrait</figcaption></figure><h1 id="e3d1" class="lu lv iq bd lw lx ly lz ma mb mc md me jw mf jx mg jz mh ka mi kc mj kd mk ml bi translated">数字取证</h1><p id="b7c8" class="pw-post-body-paragraph kr ks iq kt b ku mm jr kw kx mn ju kz la mo lc ld le mp lg lh li mq lk ll lm ij bi translated">因为这个帖子不是关于图像生成，而是关于我们如何检测它们，在看到一些伪造技术后，我们想检查一下防守团队提供了什么。如前所述，数字取证方法可以分为三种。良好的检测操作应结合使用以下各项:</p><ol class=""><li id="39b8" class="nn no iq kt b ku kv kx ky la np le nq li nr lm ns nt nu nv bi translated"><strong class="kt ir">基于特征的</strong> —在某一类(或多类)伪造品中存在一种伪造品的情况下——大多适用于经典方法。</li><li id="5e36" class="nn no iq kt b ku nw kx nx la ny le nz li oa lm ns nt nu nv bi translated"><strong class="kt ir">监督学习</strong> —使用深度学习分类器(主要是 CNN)来学习某些类型的伪图像—适用于经典方法以及生成模型，例如 GANs。</li><li id="7f18" class="nn no iq kt b ku nw kx nx la ny le nz li oa lm ns nt nu nv bi translated"><strong class="kt ir">无监督/通用</strong>——试图捕捉真实图像的一些本质，以检测新类型的伪造(模型以前没有见过)。这可以看作是一种异常检测。</li></ol><p id="015a" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">所有上述方法都有其优点和缺点，但由于生成方法变得更加现实，2 和 3 变得更加突出。</p><p id="5ee6" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">我们在上一部分中目睹的篡改技术全部(或大部分)都是由深度学习社区提供的公开可用的。然而，它不必永远保持这种状态:在随后的几年里，不同的公司和政权将有自己的秘密技术，这是非常合理的。</p><h1 id="f11e" class="lu lv iq bd lw lx ly lz ma mb mc md me jw mf jx mg jz mh ka mi kc mj kd mk ml bi translated">基于特征的</h1><p id="15de" class="pw-post-body-paragraph kr ks iq kt b ku mm jr kw kx mn ju kz la mo lc ld le mp lg lh li mq lk ll lm ij bi translated">2004 年，<strong class="kt ir">哈尼·法里德</strong>和<strong class="kt ir">阿林</strong> <strong class="kt ir">波佩斯库</strong>发表了第一篇关于使用数字文物识别假图像的作品。数码相机具有不同的伪像，这些伪像源自摄影硬件、软件或特定于图像的压缩技术。因此，发现这些假照片的数字方法的出现只是时间问题。法里德和波佩斯库使用了一种特殊的相机过滤器(CFA)来识别图像的虚假部分。</p><p id="db56" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">从那以后，出现了更多的手工制作技术:</p><h2 id="275d" class="ms lv iq bd lw mt mu dn ma mv mw dp me la mx my mg le mz na mi li nb nc mk nd bi translated">使用 JPEG“签名”</h2><p id="6d0b" class="pw-post-body-paragraph kr ks iq kt b ku mm jr kw kx mn ju kz la mo lc ld le mp lg lh li mq lk ll lm ij bi translated">JPEG 是数字媒体中最常见的图像压缩协议。你可以在这里阅读它的细节<a class="ae ln" href="https://parametric.press/issue-01/unraveling-the-jpeg/" rel="noopener ugc nofollow" target="_blank">。简而言之，每个图像都有自己的编码方式来优化文件大小。可以利用不同图像的编码差异来检测伪造图像(拼接)。这里有一个</a><a class="ae ln" href="https://www.cs.dartmouth.edu/farid/downloads/publications/wifs17.pdf" rel="noopener ugc nofollow" target="_blank">这样工作的例子</a>。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi ob"><img src="../Images/8e5bb9165e508bf42a78d2a46b135803.png" data-original-src="https://miro.medium.com/v2/resize:fit:1014/format:webp/1*6Y-tHRLm5JH16WMX1N6bvQ.png"/></div><figcaption class="kn ko gj gh gi kp kq bd b be z dk">Splicing artifacts caused by JPEG compression</figcaption></figure><h2 id="3c92" class="ms lv iq bd lw mt mu dn ma mv mw dp me la mx my mg le mz na mi li nb nc mk nd bi translated">相机伪影</h2><p id="5b99" class="pw-post-body-paragraph kr ks iq kt b ku mm jr kw kx mn ju kz la mo lc ld le mp lg lh li mq lk ll lm ij bi translated">如前所述，数码相机在硬件或软件中也有其制品、结构。每个相机制造商、型号或软件版本都可能有自己的签名。比较图像不同部分的这些特征或<a class="ae ln" href="http://www.cs.albany.edu/~lsw/papers/ijcv14.pdf" rel="noopener ugc nofollow" target="_blank">相机噪声</a>可能会产生一个好的分类器。</p><h2 id="3786" class="ms lv iq bd lw mt mu dn ma mv mw dp me la mx my mg le mz na mi li nb nc mk nd bi translated">摄影艺术品</h2><p id="2f4f" class="pw-post-body-paragraph kr ks iq kt b ku mm jr kw kx mn ju kz la mo lc ld le mp lg lh li mq lk ll lm ij bi translated">与上面的逻辑相同，篡改图像可能会扭曲照片的自然条件。使用这种特征的数字测量(例如<a class="ae ln" href="https://www.ijcaonline.org/archives/volume177/number1/manthale-2017-ijca-915436.pdf" rel="noopener ugc nofollow" target="_blank">照明</a>、“<a class="ae ln" href="http://cs.haifa.ac.il/hagit/papers/IJCV_11_ImageForgery.pdf" rel="noopener ugc nofollow" target="_blank">像差</a>”)在伪造检测中也是有用的。</p><h2 id="19df" class="ms lv iq bd lw mt mu dn ma mv mw dp me la mx my mg le mz na mi li nb nc mk nd bi translated">生成模型工件</h2><p id="4ba2" class="pw-post-body-paragraph kr ks iq kt b ku mm jr kw kx mn ju kz la mo lc ld le mp lg lh li mq lk ll lm ij bi translated">当前的生成模型也遭受已知的伪像，有些甚至是可见的，如不同的不对称，奇怪的嘴的形状，不对称的眼睛等等。这些人工制品在这个<a class="ae ln" href="https://faui1-files.cs.fau.de/public/mmsec/pub/matern_ivfws_2019_face_artifacts.pdf" rel="noopener ugc nofollow" target="_blank">作品</a>中被利用，使用经典的计算机视觉将假图像与真图像分开。然而，考虑到生成模型的进步，这些人工制品不一定存在于明天的赝品中。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi oc"><img src="../Images/bdc8e150e508f345b6b444d1c61ebec1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1230/format:webp/1*-mUYcUpr1_FyE9415Z7yYA.png"/></div><figcaption class="kn ko gj gh gi kp kq bd b be z dk">Asymmetric eyes in GAN face</figcaption></figure><p id="3171" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">所有上述方法都是伟大和聪明的，但是一旦暴露，他们就可以被伪造者所穿透。这就是机器学习的用武之地:它有点像一个黑匣子，可以在伪造者不知道其细节的情况下学习假图像。</p><h1 id="701d" class="lu lv iq bd lw lx ly lz ma mb mc md me jw mf jx mg jz mh ka mi kc mj kd mk ml bi translated">监督深度学习</h1><p id="7a9d" class="pw-post-body-paragraph kr ks iq kt b ku mm jr kw kx mn ju kz la mo lc ld le mp lg lh li mq lk ll lm ij bi translated">随着深度学习的兴起，研究人员开始使用深度网络来检测虚假图像是很自然的。</p><p id="ee94" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">直观上，很容易从不同类型的伪造类中获取图像，并开始训练分类器和检测器。让我们来看看一些备受瞩目的作品。</p><h2 id="6406" class="ms lv iq bd lw mt mu dn ma mv mw dp me la mx my mg le mz na mi li nb nc mk nd bi translated">使用新 conv 层的通用图像处理检测</h2><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi od"><img src="../Images/8fcb52b0cbe21d648b78fd161172fde2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1022/format:webp/1*QejRD3XUCey3-xUay7ekiA.png"/></div></figure><p id="5bd6" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">在这项<a class="ae ln" href="http://ece.drexel.edu/stamm/papers/Bayar_IHMMSec_2016.pdf" rel="noopener ugc nofollow" target="_blank">工作</a>中，研究人员设计了一个特殊的卷积层，它通过对过滤器施加约束，旨在捕捉<em class="nh">操作</em>，而不是图像<em class="nh">语义内容</em>。经过对中值滤波、高斯模糊等不同修图方法的测试，该方法达到了&gt; 95%的准确率。这项工作的目的是通用的，然而，据称它的设计仅限于 photoshopping 和篡改，而不是 GANs 之类的。</p><h2 id="d3c1" class="ms lv iq bd lw mt mu dn ma mv mw dp me la mx my mg le mz na mi li nb nc mk nd bi translated">Mesonet</h2><p id="fd21" class="pw-post-body-paragraph kr ks iq kt b ku mm jr kw kx mn ju kz la mo lc ld le mp lg lh li mq lk ll lm ij bi translated">Mesonet 是一部专注于也许是最痛苦的问题的作品:篡改视频中的人脸。具体来说就是 face2face 和 deep fakes(见上图)。由于视频(特别是数字化的)本质上是一系列图像，研究人员使用深度网络解决这项任务，并使用非常标准的网络获得了良好的结果。总之，这项工作除了是最早解决这项任务的工作之一之外，并没有什么特别之处。</p><h2 id="7ef2" class="ms lv iq bd lw mt mu dn ma mv mw dp me la mx my mg le mz na mi li nb nc mk nd bi translated">甘实验</h2><p id="483a" class="pw-post-body-paragraph kr ks iq kt b ku mm jr kw kx mn ju kz la mo lc ld le mp lg lh li mq lk ll lm ij bi translated">正如我们前面所看到的，甘人只是不断出现。训练一个模型来区分真实图像和特定的 GAN 并不困难。但是为<em class="nh">每</em>根训练一个模型也是不切实际的。</p><p id="2ece" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated"><a class="ae ln" href="https://arxiv.org/abs/1902.11153" rel="noopener ugc nofollow" target="_blank">一些研究人员</a>非常乐观，试图将一个分类模型推广到不同的 GANs，这些 GANs 与他们所接受的训练不同。换句话说，他们在一种 GAN(<a class="ae ln" href="https://arxiv.org/abs/1710.10196" rel="noopener ugc nofollow" target="_blank">PG-GAN</a>—style GAN 的前身)上训练了一个深度网络，并试图在另一种 GAN(DC-GAN，WGAN)上进行推断。</p><p id="0d19" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">正如预期的那样，结果表明，即使研究人员进行了预处理，也没有任何普遍性。</p><p id="c8ce" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">还有很多类似的方法，但概括起来——意思是，识别从未见过的伪造品，学习研究需要开始变得更有创造性。</p><h1 id="9060" class="lu lv iq bd lw lx ly lz ma mb mc md me jw mf jx mg jz mh ka mi kc mj kd mk ml bi translated">通用方法</h1><p id="ae24" class="pw-post-body-paragraph kr ks iq kt b ku mm jr kw kx mn ju kz la mo lc ld le mp lg lh li mq lk ll lm ij bi translated">我们知道，深度学习不仅仅局限于朴素的分类器。有许多种 un/<a class="ae ln" rel="noopener" target="_blank" href="/a-different-kind-of-deep-learning-part-1-90fe6c52f1ab">self</a>/semi-supervised 模型可以处理少量数据、n 次拍摄和其他任务。</p><p id="88ca" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">让我们来看看用什么样的思路来解决“万能假像”的问题。</p><h2 id="d4d3" class="ms lv iq bd lw mt mu dn ma mv mw dp me la mx my mg le mz na mi li nb nc mk nd bi translated">自洽性</h2><p id="39d5" class="pw-post-body-paragraph kr ks iq kt b ku mm jr kw kx mn ju kz la mo lc ld le mp lg lh li mq lk ll lm ij bi translated">这种方法的一个很好的例子可以在作品<a class="ae ln" href="https://arxiv.org/abs/1805.04096" rel="noopener ugc nofollow" target="_blank"> <strong class="kt ir">打击假新闻:通过学习自洽的图像拼接检测</strong> </a> <strong class="kt ir">中找到。</strong>这篇文章来自<strong class="kt ir">阿列克谢·埃夫罗斯</strong>的工作坊，大部分人都知道他在<a class="ae ln" rel="noopener" target="_blank" href="/a-different-kind-of-deep-learning-part-1-90fe6c52f1ab">自我监督</a>技术方面的工作。这部作品与他早期的作品有一些相同之处。研究人员整合了一个 4 步工作流程，其中他们:</p><ol class=""><li id="6421" class="nn no iq kt b ku kv kx ky la np le nq li nr lm ns nt nu nv bi translated">学习预测图像的 EXIF*元数据。</li><li id="c935" class="nn no iq kt b ku nw kx nx la ny le nz li oa lm ns nt nu nv bi translated">将图像分割成许多小块，比较每一对的预测 EXIF 值。</li><li id="7079" class="nn no iq kt b ku nw kx nx la ny le nz li oa lm ns nt nu nv bi translated">看起来具有不匹配的 EXIF 值的切片将被分类为取自不同的图像，因此该图像将是假的。</li><li id="d3c4" class="nn no iq kt b ku nw kx nx la ny le nz li oa lm ns nt nu nv bi translated">分类将用于提供移植区域的热图。</li></ol><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="lq lr di ls bf lt"><div class="gh gi oe"><img src="../Images/39ff3924196b4883f82f4b7ea4a572f0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*fE3KpSBAdyBmItF_"/></div></div><figcaption class="kn ko gj gh gi kp kq bd b be z dk">A detection of “spliced” Keanu Reeves</figcaption></figure><p id="837f" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">但是什么是 EXIF 呢？在数字媒体中，图像(和一些声音文件也是如此)，EXIF，<strong class="kt ir">可交换图像文件格式，</strong>是一种元数据签名的文件。图像的 EXIF 应该包括相机(或扫描仪)型号、原始图像大小、照片属性(闪光灯、快门打开时间)等等。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi of"><img src="../Images/62ab6ed1dc0d3b1f44fb9d0555553205.png" data-original-src="https://miro.medium.com/v2/resize:fit:554/0*RUOMf1NI7YhxLDsr"/></div></figure><p id="f2b0" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">显然，并不是所有的网上照片都有完整的 EXIF，尤其是那些造假的照片。这正是研究人员参与预测每个图像/补丁的 EXIF 的原因。现在你可以看到，这项任务在某种程度上是无人监管的，因为有大量的在线图像和现成的 EXIF 可供学习。更准确地说，使用了 40 万张图像来训练这个模型。</p><p id="0bec" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">该模型在 photoshopped 图像上取得了良好的结果，但令人惊讶的是，它在 GaN 生成的图像上也取得了一些成功。</p><h2 id="d270" class="ms lv iq bd lw mt mu dn ma mv mw dp me la mx my mg le mz na mi li nb nc mk nd bi translated">法医转移</h2><p id="34e6" class="pw-post-body-paragraph kr ks iq kt b ku mm jr kw kx mn ju kz la mo lc ld le mp lg lh li mq lk ll lm ij bi translated">Luisa Verdoliva 是一名意大利研究人员，她和她的团队拍摄了一些有趣的照片来推广图像取证。在这个<a class="ae ln" href="https://arxiv.org/pdf/1812.02510.pdf" rel="noopener ugc nofollow" target="_blank">作品</a>中，他们训练了一个有点不同的模型，这将有望更具普遍性。他们所做的是使用自动编码器，这是一种旨在将图像“收缩”成向量，然后重建它的网络。这个向量被训练成<strong class="kt ir">分类器</strong>来确定图像是真是假:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi og"><img src="../Images/7aa4ddc63a9f69ff255674188f7bf39d.png" data-original-src="https://miro.medium.com/v2/resize:fit:942/format:webp/1*pgwv4nfsZj3Kcoa-8882Nw.png"/></div><figcaption class="kn ko gj gh gi kp kq bd b be z dk">A scheme of the forensic transfer autoEncoder</figcaption></figure><p id="40ca" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">他们还尝试迁移学习:在数据集 A 上训练他们的网络，用数据集 B 的一个小子集重新训练它，并尝试在数据集 B 上进行推断。</p><p id="fe0a" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">他们在几个数据集上来来回回地做这项工作，并得到合理的结果(75-85%的准确率)。这些结果优于其他网络(其中一些在上面的<strong class="kt ir">监督学习</strong>部分讨论过)</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi oh"><img src="../Images/78b52038e2e79a74ba1d132b19df21e3.png" data-original-src="https://miro.medium.com/v2/resize:fit:896/format:webp/1*uClcZZtlVA0ehzct0ADzpQ.png"/></div><figcaption class="kn ko gj gh gi kp kq bd b be z dk">ForensicTransfer — an example transfer learning results</figcaption></figure><h2 id="4708" class="ms lv iq bd lw mt mu dn ma mv mw dp me la mx my mg le mz na mi li nb nc mk nd bi translated">噪声印迹</h2><p id="d6b1" class="pw-post-body-paragraph kr ks iq kt b ku mm jr kw kx mn ju kz la mo lc ld le mp lg lh li mq lk ll lm ij bi translated">来自上述团队的另一种无人监督的<a class="ae ln" href="https://arxiv.org/pdf/1808.08396.pdf" rel="noopener ugc nofollow" target="_blank">方法</a>，类似于自洽，试图预测图像碎片之间的 PRNU 噪声(一种特定类型的相机噪声)。它报告了多个数据集的最新结果(平均马修斯相关度为 0.4，而自洽度为 0.33)。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="lq lr di ls bf lt"><div class="gh gi oi"><img src="../Images/a1b555d4db5c6d45439f1218bb43867d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*AlT57bDIzvn9S3Uq"/></div></div><figcaption class="kn ko gj gh gi kp kq bd b be z dk">A set of predictions: noise print on the right. EXIF-SC is self-consistency.</figcaption></figure><h1 id="fda4" class="lu lv iq bd lw lx ly lz ma mb mc md me jw mf jx mg jz mh ka mi kc mj kd mk ml bi translated">深度假动作旋转</h1><p id="00db" class="pw-post-body-paragraph kr ks iq kt b ku mm jr kw kx mn ju kz la mo lc ld le mp lg lh li mq lk ll lm ij bi translated">考虑到以上所有情况，似乎通用方法必须更积极地解决生成性伪问题。他们确实做到了:一些研究人员抓住机会，试图创造出某种甘将军猎人。这意味着能够识别 GAN 生成的图像，而无需对其种类进行专门培训。让我们来看看其中的几个:</p><h2 id="8194" class="ms lv iq bd lw mt mu dn ma mv mw dp me la mx my mg le mz na mi li nb nc mk nd bi translated">学习在野外检测假的人脸图像</h2><p id="e871" class="pw-post-body-paragraph kr ks iq kt b ku mm jr kw kx mn ju kz la mo lc ld le mp lg lh li mq lk ll lm ij bi translated">在一篇有点仓促的<a class="ae ln" href="https://arxiv.org/pdf/1809.08754.pdf" rel="noopener ugc nofollow" target="_blank">文章</a>(只有 4 页)中，研究人员使用非耦合的图像对来训练一个深度网络，以对相同/不同的图像进行分类(真实和真实，假的和假的，真实和假的),这种有点天真的结果在不同的 GANs 上得到了合理的结果，尽管对所有的 GANs 都进行了训练。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi oj"><img src="../Images/a46325eb470d43aa0fd53c9ae819ddd3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1218/format:webp/1*oZ8KhC7bNOK1YssdCWFJyQ.png"/></div></figure><h2 id="dcc9" class="ms lv iq bd lw mt mu dn ma mv mw dp me la mx my mg le mz na mi li nb nc mk nd bi translated">GANs 会留下人工指纹吗？</h2><p id="30a4" class="pw-post-body-paragraph kr ks iq kt b ku mm jr kw kx mn ju kz la mo lc ld le mp lg lh li mq lk ll lm ij bi translated">在本文中，<strong class="kt ir">Luisa verdolva</strong>使用她最喜欢的噪声图(PRNU)，用不同的训练数据集来尝试和表征几种不同的 GAN 模型(PG-GAN，cycle-GAN)。他们的成功表明，实际上每个 GAN(达到训练集水平)都有自己的噪声指纹，类似于相机的噪声指纹。不幸的是，这种方法对检测假图像的帮助主要是理论上的，至少目前是这样。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi ok"><img src="../Images/09b1b14719bbf22f7c70f0f36e057f6a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1094/format:webp/1*4kmrd5lxogpneEqOnJqTiA.png"/></div></figure><h1 id="ed40" class="lu lv iq bd lw lx ly lz ma mb mc md me jw mf jx mg jz mh ka mi kc mj kd mk ml bi translated">作品分类</h1><p id="d15a" class="pw-post-body-paragraph kr ks iq kt b ku mm jr kw kx mn ju kz la mo lc ld le mp lg lh li mq lk ll lm ij bi translated">最终，我们可以交叉生产<em class="nh">锻造</em>和<em class="nh">检测</em>方法，并将大多数方法放入一个(或多个)盒子中:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="lq lr di ls bf lt"><div class="gh gi ol"><img src="../Images/cb7cba377465f12d783c016249e2455a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*nlpFzb_D_1Amn5a28M8SVA.png"/></div></div></figure><p id="6385" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">在我们在 Cyabra 的工作中，我们面临许多上述挑战，因此我们采用类似的策略:使用监督方法来检测已知的伪造品，同时进行调整和测试，希望能推广到其他伪造品。</p><p id="94f1" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">不知何故，也许令人惊讶的是，我们已经发现一些通用或半通用的方法可能出乎意料地有效。例如，发现自洽工作，(通过一些调整)可能是有效的分类 GAN 创建的图像。</p><h1 id="4e48" class="lu lv iq bd lw lx ly lz ma mb mc md me jw mf jx mg jz mh ka mi kc mj kd mk ml bi translated">摘要</h1><p id="725b" class="pw-post-body-paragraph kr ks iq kt b ku mm jr kw kx mn ju kz la mo lc ld le mp lg lh li mq lk ll lm ij bi translated">这就是了，如果你已经到达这里，你就成功地穿越了图像和视频取证的泡沫领域。</p><p id="c6a2" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">正如我们在上面看到的，大部分工作都集中在对特定篡改进行分类的方法上。然而，一般的方法是新的，仍然是稀疏的。</p><p id="1aab" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">很明显，这个领域很快将不再是研究人员和爱好者的狭窄领域，而是开始涉及普通人——他们希望重新获得辨别真假的能力。</p><p id="7d24" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">军备竞赛不会很快停止，但我们应该期待看到法医们齐心协力，想出一些更好的方法来反击伪造者。</p><p id="085d" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated"><em class="nh"> *值得注意的作品</em> <a class="ae ln" href="https://arxiv.org/abs/1901.08971" rel="noopener ugc nofollow" target="_blank"> <em class="nh">监督</em> </a> <em class="nh"> </em> <a class="ae ln" href="https://arxiv.org/abs/1703.04615" rel="noopener ugc nofollow" target="_blank"> <em class="nh">学习</em> </a> <em class="nh">。</em></p><p id="b411" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi om translated">我希望你喜欢阅读这篇评论！欢迎随时 <a class="ae ln" href="https://twitter.com/shgidi" rel="noopener ugc nofollow" target="_blank"> <strong class="kt ir"> <em class="nh">关注</em> </strong> </a> <em class="nh">我，并查看我的网站—</em><a class="ae ln" href="https://www.shibumi-ai.com/" rel="noopener ugc nofollow" target="_blank"><strong class="kt ir"><em class="nh">www.shibumi-ai.com</em></strong></a></p></div></div>    
</body>
</html>