# 不要急于编码。企业人工智能项目的 4 个原则。

> 原文：<https://towardsdatascience.com/do-not-rush-to-code-4-principles-for-ai-projects-in-enterprise-20cfeb32af3d?source=collection_archive---------20----------------------->

![](img/daf2c91d2527d8faaf225dca82c815a7.png)

Think together before doing alone, an ant principle.

不，人工智能自己不能理解。不，数据科学不是自动的。敏捷方法并不意味着混乱。一句话，不，这不是魔法。在匆忙编码之前需要做什么？在这里，我与你分享我从职业和个人项目中学到的 4 条原则。

# 尽可能清晰地制定业务目标

做数据科学是一个绝对的趋势，虽然是一个强大的工具，但有时会被过度使用和不适应。这就是为什么在开始任何一行代码之前，我们必须确定我们在寻找什么来证明/改进，以及我们有什么样的数据来实现这个目标。在编码之前定义一个清晰的业务目标，是企业中一个重要的关键特性，然后这个定义将被用来定义我们的解决方案的评估指标。

# 必须准备好数据

大多数数据科学项目都是为了确保我们拥有数据。然后，我们必须确保数据准备好用于我们的模型。缺失值和异常值是我们必须处理的事情，以便我们的模型具有良好的数据质量。数据准备所需时间常常被低估。这不是机器学习中最性感的部分，但通过 EDA 过程准备和了解你的数据，可以让我们挑战我们试图帮助的工作专家，然后对主要问题有更好的理解(有时会发现之前需要解决的其他问题)。

# 精确定义交付

任何数据科学家的主要目标都是让一个模型在评估指标上表现良好。但是，我们必须确定我们正在寻找的最终交付是什么，以及在开发开始时，这种交付将如何在技术上集成到全球解决方案中。我们是在寻找一个 MVP 吗？这是一个 shell 脚本执行吗？Web 执行？我们想要什么样的动态？我们想要什么样的硬编码？这只是演示还是一个生产项目？所有这些问题都必须在编码前回答。

# 没有黑盒效应

机器学习将被应用到越来越多的行业的各个层面。从这个假设出发，我们必须确保所有人都能够很好地理解机器预测什么以及为什么，机器学习的可解释性是关键。伦理问题在我们的社区中越来越受到重视，我坚信“无黑箱效应”将允许我们通过预测人工智能在未来可能面临的伦理问题来提供解决方案。我强烈建议任何数据科学家在其基础数据科学管道中添加一个 ML 可解释性部分，就像我们对功能工程或度量评估所做的那样。

有什么建议吗？

请在评论区分享你自己的建议。:)