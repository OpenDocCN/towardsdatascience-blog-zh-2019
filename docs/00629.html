<html>
<head>
<title>Scaling Machine Learning from 0 to millions of users — part 1</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">从 0 到数百万用户扩展机器学习—第 1 部分</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/scaling-machine-learning-from-0-to-millions-of-users-part-1-a2d36a5e849?source=collection_archive---------3-----------------------#2019-01-29">https://towardsdatascience.com/scaling-machine-learning-from-0-to-millions-of-users-part-1-a2d36a5e849?source=collection_archive---------3-----------------------#2019-01-29</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="29c3" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">突破笔记本电脑</h2></div><p id="8eca" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我认为大多数机器学习(ML)模型都是在白板或餐巾纸上构思出来的，诞生于笔记本电脑上。当这些羽翼未丰的生物开始咿咿呀呀地说出它们的第一个预言时，我们充满了自豪，并对它们未来的能力寄予厚望。唉，我们内心深处知道，并非所有人都会成功，远非如此。</p><p id="1a62" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">当我们建造它们时，一小部分很快就让我们失望了。其他的看起来很有希望，并显示出一定程度的预测能力。然后，我们面临着在生产环境中部署它们的严峻挑战，在生产环境中，它们要么证明自己传奇的勇气，要么不光彩地死去。</p><figure class="lc ld le lf gt lg gh gi paragraph-image"><div role="button" tabindex="0" class="lh li di lj bf lk"><div class="gh gi lb"><img src="../Images/2df04d74b8943c90661030c40417f710.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*at743M34p8AdMI8S.jpg"/></div></div><figcaption class="ln lo gj gh gi lp lq bd b be z dk">One day, your models will rule the world… if you read all these posts and pay attention ;)</figcaption></figure><p id="5949" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在这一系列观点鲜明的帖子中，我们将讨论<strong class="kh ir">如何训练 ML 模型并将其部署到生产中，从卑微的开始到统治世界</strong>。在这一过程中，我们将努力采取公正合理的措施，与过度设计、炒作驱动的开发以及“为什么不直接用 XYZ 呢？”的邪恶势力作斗争。</p><blockquote class="lr"><p id="c4f5" class="ls lt iq bd lu lv lw lx ly lz ma la dk translated">尽可能享受您的数据科学沙盒的安全舒适，并为寒冷、严酷的生产世界做好准备。</p></blockquote><h1 id="7260" class="mb mc iq bd md me mf mg mh mi mj mk ml jw mm jx mn jz mo ka mp kc mq kd mr ms bi translated"><strong class="ak">第 0 天</strong></h1><p id="afd8" class="pw-post-body-paragraph kf kg iq kh b ki mt jr kk kl mu ju kn ko mv kq kr ks mw ku kv kw mx ky kz la ij bi translated">所以你想建立一个 ML 模型。嗯。让我们停下来想一想:</p><ul class=""><li id="c0f3" class="my mz iq kh b ki kj kl km ko na ks nb kw nc la nd ne nf ng bi translated">你的业务问题能否由<strong class="kh ir">的高级 AWS 服务</strong>解决，比如<a class="ae nh" href="http://aws.amazon.com/rekognition" rel="noopener ugc nofollow" target="_blank">亚马逊认证</a>、<a class="ae nh" href="http://aws.amazon.com/rekognition" rel="noopener ugc nofollow" target="_blank">亚马逊 Polly </a>等。？</li><li id="cabe" class="my mz iq kh b ki ni kl nj ko nk ks nl kw nm la nd ne nf ng bi translated">还是通过嵌入在其他 AWS 服务中的<a class="ae nh" href="https://medium.com/@julsimon/applying-machine-learning-to-aws-services-9768f926f11f" rel="noopener">不断增长的应用 ML 特性列表</a>？</li></ul><p id="aeb3" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">不要对此置之不理:<strong class="kh ir">没有机器学习比没有机器学习更容易管理</strong>。找到一种使用高级服务的方法可以为你节省几周甚至几个月的时间。</p><h2 id="a08e" class="nn mc iq bd md no np dn mh nq nr dp ml ko ns nt mn ks nu nv mp kw nw nx mr ny bi translated">如果答案是“是”</h2><p id="914a" class="pw-post-body-paragraph kf kg iq kh b ki mt jr kk kl mu ju kn ko mv kq kr ks mw ku kv kw mx ky kz la ij bi translated">请扪心自问:</p><ul class=""><li id="7e89" class="my mz iq kh b ki kj kl km ko na ks nb kw nc la nd ne nf ng bi translated">为什么您要费尽周折构建一个冗余的定制解决方案呢？</li><li id="a8c6" class="my mz iq kh b ki ni kl nj ko nk ks nl kw nm la nd ne nf ng bi translated">你真的是“<em class="nz">缺失功能</em>”吗？什么是<strong class="kh ir">真正的</strong>业务影响？</li><li id="3394" class="my mz iq kh b ki ni kl nj ko nk ks nl kw nm la nd ne nf ng bi translated">你真的需要“<em class="nz">更高的精确度</em>”你怎么知道<strong class="kh ir">你</strong>能达到呢？</li></ul><p id="8a4f" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">如果你不确定，为什么不用你自己的数据进行一次快速概念验证呢？这些服务是完全托管的(不需要…更多…服务器),并且非常容易集成到任何应用程序中。弄清楚它们不需要花太多时间，然后你就会有可靠的数据来做出有根据的决定，决定你是否真的需要训练你自己的模型。</p><blockquote class="oa ob oc"><p id="a400" class="kf kg nz kh b ki kj jr kk kl km ju kn od kp kq kr oe kt ku kv of kx ky kz la ij bi translated">如果这些服务对你来说足够好，那么恭喜你，你基本上完成了！如果你决定建造，我希望听到你的反馈。请保持联系。</p></blockquote><h2 id="4cf6" class="nn mc iq bd md no np dn mh nq nr dp ml ko ns nt mn ks nu nv mp kw nw nx mr ny bi translated"><strong class="ak">如果这个答案是“否”</strong></h2><p id="69c4" class="pw-post-body-paragraph kf kg iq kh b ki mt jr kk kl mu ju kn ko mv kq kr ks mw ku kv kw mx ky kz la ij bi translated">请再问自己一次这个问题！我们大多数人都有扭曲现实和欺骗自己的惊人能力:)如果诚实的答案真的是“不”，那么我仍然建议考虑一下您可以使用高级服务的<strong class="kh ir">子流程</strong>，例如:</p><ul class=""><li id="7176" class="my mz iq kh b ki kj kl km ko na ks nb kw nc la nd ne nf ng bi translated">使用<a class="ae nh" href="http://aws.amazon.com/translate" rel="noopener ugc nofollow" target="_blank"> Amazon 翻译</a>支持的语言对，并使用您自己的解决方案来翻译其余的语言对。</li><li id="2f73" class="my mz iq kh b ki ni kl nj ko nk ks nl kw nm la nd ne nf ng bi translated">在将人脸输入到你的模型之前，使用亚马逊的识别功能来检测人脸，</li><li id="147b" class="my mz iq kh b ki ni kl nj ko nk ks nl kw nm la nd ne nf ng bi translated">使用<a class="ae nh" href="http://aws.amazon.com/textract" rel="noopener ugc nofollow" target="_blank"> Amazon Textract </a>来提取文本，然后将其提供给 NLP 模型。</li></ul><p id="3885" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这不是推销 AWS 服务(我看起来像销售人员吗？).我只是<strong class="kh ir">想让你免于重新发明轮子</strong>(或轮子的部件):你真的应该<strong class="kh ir">专注于手头的业务问题</strong>，而不是建造你在博客帖子中读到的或在会议上看到的卡片房子。是的，它在你的简历上可能看起来很棒，这个轮子最初是一个有趣的旋转木马…然后，它变成了<strong class="kh ir">痛苦之轮，你被拴在它上面，别人拿着鞭子</strong>。</p><figure class="lc ld le lf gt lg gh gi paragraph-image"><div role="button" tabindex="0" class="lh li di lj bf lk"><div class="gh gi og"><img src="../Images/78d62a263d7211429e72c16d29cdef64.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*MK8gZmjzXiAIkTee.png"/></div></div><figcaption class="ln lo gj gh gi lp lq bd b be z dk">Why did I blindly trust that meetup talk? Crom! Help me escape and bash that guy’s skull with his laptop.</figcaption></figure><p id="9e54" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">反正消极够了:)你确实需要一个模型，我们继续吧。</p><h1 id="0adf" class="mb mc iq bd md me mf mg mh mi mj mk ml jw oh jx mn jz oi ka mp kc oj kd mr ms bi translated">第一天:一个用户(你)</h1><p id="06ad" class="pw-post-body-paragraph kf kg iq kh b ki mt jr kk kl mu ju kn ko mv kq kr ks mw ku kv kw mx ky kz la ij bi translated">我们将从您在本地机器(或本地开发服务器)上训练模型的阶段开始我们的旅程，使用流行的开源库，如<a class="ae nh" href="https://scikit-learn.org" rel="noopener ugc nofollow" target="_blank"> scikit-learn </a>、<a class="ae nh" href="https://www.tensorflow.org" rel="noopener ugc nofollow" target="_blank"> TensorFlow </a>或<a class="ae nh" href="https://mxnet.incubator.apache.org" rel="noopener ugc nofollow" target="_blank"> Apache MXNet </a>。也许你甚至已经实现了自己的算法(数据科学家，你们这些魔鬼)。</p><p id="2766" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">您已经使用测试集测量了模型的准确性，情况看起来不错。现在您想要将模型部署到生产中，以便检查它的实际行为，运行 A/B 测试，等等。从哪里开始？</p><h2 id="e3c4" class="nn mc iq bd md no np dn mh nq nr dp ml ko ns nt mn ks nu nv mp kw nw nx mr ny bi translated">批量预测还是实时预测？</h2><p id="bee5" class="pw-post-body-paragraph kf kg iq kh b ki mt jr kk kl mu ju kn ko mv kq kr ks mw ku kv kw mx ky kz la ij bi translated">首先，您应该弄清楚您的应用程序是否需要<strong class="kh ir">批量预测</strong>(即收集大量数据点，定期处理它们并将结果存储在某个地方)，或者<strong class="kh ir">实时预测</strong>(即向 web 服务发送一个数据点并接收一个即时预测)。我之所以提前提出这一点，是因为它对部署复杂性有很大的影响。</p><p id="bd97" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">乍一看，实时预测听起来更有吸引力(因为…实时，耶！)，但它也带来了 web 服务固有的更强的需求:高可用性、处理流量突发的能力等。批处理更加轻松，因为它只需要时不时地运行:只要不丢失数据，没有人会看到它是否在中间被破坏了；)</p><p id="9357" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">缩放现在不是一个问题:您关心的只是部署您的模型、测试轮胎、运行一些性能测试等等。从我的经验来看，<strong class="kh ir">您可能选择了最短的路线，将所有东西部署到一个 Amazon EC2 实例</strong>。每个人都知道一点 Linux CLI，你在某处读到过使用“IaaS 将保护你免受邪恶的供应商锁定”。哈！那就 EC2 吧！</p><blockquote class="oa ob oc"><p id="49ea" class="kf kg nz kh b ki kj jr kk kl km ju kn od kp kq kr oe kt ku kv of kx ky kz la ij bi translated">我听到 AWS 时空连续体中充满恐惧和怀疑的尖叫声，也许还有一些类似“哦，这太愚蠢了，没有人真的这么做！”。嗯，我敢打赌，到目前为止，大多数人都是这样开始的。如果你没有，恭喜你，但是请让我告诉这些好人，在他们真正伤害自己之前，哪条路是出路；)</p></blockquote><p id="f8c6" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">所以，盯着我的魔镜，我看到…</p><h2 id="75f3" class="nn mc iq bd md no np dn mh nq nr dp ml ko ns nt mn ks nu nv mp kw nw nx mr ny bi translated">批量预测</h2><p id="bff1" class="pw-post-body-paragraph kf kg iq kh b ki mt jr kk kl mu ju kn ko mv kq kr ks mw ku kv kw mx ky kz la ij bi translated">您已经将模型、批处理脚本和应用程序复制到 EC2 实例中。您的批处理脚本作为 cron 作业定期运行，并将预测数据保存到本地存储。您的应用程序在启动时加载模型和初始预测数据，并使用它来做任何它必须做的事情。它还会定期检查更新的预测，并在它们可用时加载它们。</p><h2 id="b9cb" class="nn mc iq bd md no np dn mh nq nr dp ml ko ns nt mn ks nu nv mp kw nw nx mr ny bi translated">实时预测</h2><p id="3b3d" class="pw-post-body-paragraph kf kg iq kh b ki mt jr kk kl mu ju kn ko mv kq kr ks mw ku kv kw mx ky kz la ij bi translated">您已经将模型嵌入到应用程序中，在启动时加载它，并使用各种数据(用户输入、文件、API 等)提供预测。).</p><p id="6938" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">不管怎样，你现在正在云中运行预测，生活是美好的。你用一品脱黑啤酒来庆祝…或者可能是无麸质、公平交易的有机豆奶拿铁，因为毕竟是 2019 年了。</p><h1 id="a128" class="mb mc iq bd md me mf mg mh mi mj mk ml jw oh jx mn jz oi ka mp kc oj kd mr ms bi translated">第一周:一个抱歉的用户(你)</h1><p id="eac3" class="pw-post-body-paragraph kf kg iq kh b ki mt jr kk kl mu ju kn ko mv kq kr ks mw ku kv kw mx ky kz la ij bi translated">该模型预测得很好，并且您希望投入更多时间来收集更多数据和添加功能。不幸的是，没过多久事情就变糟了，你现在<strong class="kh ir">陷入了各种各样的问题</strong>(下面是不完整的列表):</p><ul class=""><li id="8262" class="my mz iq kh b ki kj kl km ko na ks nb kw nc la nd ne nf ng bi translated">在您的笔记本电脑上进行培训并手动部署到云是一件痛苦且容易出错的事情。</li><li id="9249" class="my mz iq kh b ki ni kl nj ko nk ks nl kw nm la nd ne nf ng bi translated">您意外地终止了 EC2 实例，不得不从头开始重新安装。</li><li id="a64c" class="my mz iq kh b ki ni kl nj ko nk ks nl kw nm la nd ne nf ng bi translated">你'<em class="nz"> pip 安装了</em>-Python 库，现在你的 EC2 实例全乱了。</li><li id="83ef" class="my mz iq kh b ki ni kl nj ko nk ks nl kw nm la nd ne nf ng bi translated">您必须为您的同事手动安装另外两个实例，现在您真的不能确定你们都在使用相同的环境。</li><li id="59c4" class="my mz iq kh b ki ni kl nj ko nk ks nl kw nm la nd ne nf ng bi translated">您的第一个负载测试失败了，但是您不确定应该归咎于什么:应用程序？模特？阴间的古人巫师？</li><li id="a93b" class="my mz iq kh b ki ni kl nj ko nk ks nl kw nm la nd ne nf ng bi translated">您希望在 TensorFlow 中实现相同的算法，也许在 Apache MXNet 中也是如此:更多的环境，更多的部署。没时间了。</li><li id="c3a8" class="my mz iq kh b ki ni kl nj ko nk ks nl kw nm la nd ne nf ng bi translated">当然还有大家的最爱:销售听说“你的产品现在有 AI 能力了”。你害怕他们会把它卖给一个客户，然后让你下周去大规模现场。</li></ul><p id="ebb5" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这样的例子不胜枚举。如果不是真的会很搞笑(欢迎在评论里补充自己的例子)。突然之间，这个 ML 的冒险听起来不那么令人兴奋了，不是吗？<strong class="kh ir">你将大部分时间花在救火上，而不是建立最好的模型上</strong>。不能这样下去了！</p><figure class="lc ld le lf gt lg gh gi paragraph-image"><div role="button" tabindex="0" class="lh li di lj bf lk"><div class="gh gi og"><img src="../Images/257de239613454bf842737a8b3d2fef8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*e2Y4pLSeeGOT0tKv"/></div></div><figcaption class="ln lo gj gh gi lp lq bd b be z dk">I’ve revoked your IAM credentials on ‘<em class="ok">TerminateInstances</em>’. Yes, even in the dev account. Any questions?</figcaption></figure><h1 id="2343" class="mb mc iq bd md me mf mg mh mi mj mk ml jw oh jx mn jz oi ka mp kc oj kd mr ms bi translated">第 2 周:反击</h1><p id="fede" class="pw-post-body-paragraph kf kg iq kh b ki mt jr kk kl mu ju kn ko mv kq kr ks mw ku kv kw mx ky kz la ij bi translated">团队中有人观看了这个非常酷的 AWS 视频，其中展示了一个名为<a class="ae nh" href="http://aws.amazon.com/sagemaker" rel="noopener ugc nofollow" target="_blank">亚马逊 SageMaker </a>的新 ML 服务。您记住了这一点，但是现在，没有时间重新构建一切:销售人员正紧盯着您，几天后您有一个客户演示，您需要强化现有的解决方案。</p><p id="03fb" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">很有可能，你还没有堆积如山的数据:训练可以等等。你需要专注于让预测变得可靠。这里有一些可靠的技术措施，实施起来不会超过几天。</p><h2 id="c5d0" class="nn mc iq bd md no np dn mh nq nr dp ml ko ns nt mn ks nu nv mp kw nw nx mr ny bi translated">使用深度学习 AMI</h2><p id="d4f3" class="pw-post-body-paragraph kf kg iq kh b ki mt jr kk kl mu ju kn ko mv kq kr ks mw ku kv kw mx ky kz la ij bi translated">由 AWS 维护的这个<a class="ae nh" href="https://aws.amazon.com/machine-learning/amis/" rel="noopener ugc nofollow" target="_blank">亚马逊机器映像</a>带有<strong class="kh ir">预装的</strong>许多你可能需要的工具和库:开源、NVIDIA 驱动程序等。不必管理它们将为您节省大量时间，并且还将保证您的多个实例以相同的设置运行。</p><p id="33ce" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">AMI 还附带了<a class="ae nh" href="https://conda.io/en/latest/" rel="noopener ugc nofollow" target="_blank"> Conda </a> <strong class="kh ir">依赖和环境管理器</strong>，它可以让您快速轻松地创建许多隔离的环境:这是一个用不同的 Python 版本或不同的库测试您的代码的好方法，而不会意外地破坏一切。</p><p id="114a" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">最后但同样重要的是，这个 AMI 是<strong class="kh ir">免费的</strong>，就像任何其他 AMI 一样，如果你*真的*有必要，你可以定制。</p><h2 id="38de" class="nn mc iq bd md no np dn mh nq nr dp ml ko ns nt mn ks nu nv mp kw nw nx mr ny bi translated">打破巨石</h2><p id="8b5e" class="pw-post-body-paragraph kf kg iq kh b ki mt jr kk kl mu ju kn ko mv kq kr ks mw ku kv kw mx ky kz la ij bi translated">您的应用程序代码和您的预测代码有<strong class="kh ir">不同的需求</strong>。除非你有令人信服的理由这样做(超低延迟可能是一个)，否则它们不应该生活在同一个屋檐下。让我们来看一些原因:</p><ul class=""><li id="7372" class="my mz iq kh b ki kj kl km ko na ks nb kw nc la nd ne nf ng bi translated"><strong class="kh ir">部署</strong>:每次更新模型都要重启或者更新 app 吗？或者 ping 你的应用程序重新加载它或其他什么？不不不，保持简单:说到解耦，没有什么比构建独立的服务更好的了。</li><li id="7674" class="my mz iq kh b ki ni kl nj ko nk ks nl kw nm la nd ne nf ng bi translated"><strong class="kh ir">性能</strong>:如果您的应用程序代码在内存密集型实例上运行得最好，而您的 ML 模型需要 GPU，该怎么办？你将如何处理这种权衡？你为什么会偏爱其中一个？将它们分开让你<strong class="kh ir">为每个用例</strong>挑选最佳的实例类型。</li><li id="3df6" class="my mz iq kh b ki ni kl nj ko nk ks nl kw nm la nd ne nf ng bi translated"><strong class="kh ir">可伸缩性</strong>:如果您的应用程序代码和您的模型具有不同的可伸缩性配置文件，那该怎么办？在 GPU 实例上横向扩展是一种耻辱，因为您的一小部分应用程序代码正在热运行…同样，最好将事情分开，这将有助于采取最<strong class="kh ir">适当的扩展决策</strong>以及降低成本。</li></ul><p id="f5da" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">那么，预处理/后处理代码呢，也就是说，你需要在预测之前和之后对数据采取的行动。它该何去何从？很难给出一个明确的答案:我会说<strong class="kh ir">独立于模型的动作</strong>(格式化、日志记录等)。)应该留在应用程序中，而<strong class="kh ir">依赖于模型的动作</strong>(特征工程)应该靠近模型以避免部署不一致。</p><h2 id="238c" class="nn mc iq bd md no np dn mh nq nr dp ml ko ns nt mn ks nu nv mp kw nw nx mr ny bi translated">构建预测服务</h2><p id="d274" class="pw-post-body-paragraph kf kg iq kh b ki mt jr kk kl mu ju kn ko mv kq kr ks mw ku kv kw mx ky kz la ij bi translated">将预测代码从应用程序代码中分离出来并不一定很痛苦，您可以重用<strong class="kh ir">可靠的、可扩展的工具</strong>来构建预测服务。让我们来看看一些选项:</p><ul class=""><li id="ba89" class="my mz iq kh b ki kj kl km ko na ks nb kw nc la nd ne nf ng bi translated"><strong class="kh ir"> Scikit-learn </strong>:说到用 Python 构建 web 服务，我是<a class="ae nh" href="http://flask.pocoo.org" rel="noopener ugc nofollow" target="_blank"> Flask </a>的忠实粉丝。它整洁、简单并且可伸缩性好。不用再找了。你的代码应该是这样的。</li></ul><pre class="lc ld le lf gt ol om on oo aw op bi"><span id="9f64" class="nn mc iq om b gy oq or l os ot"># My awesome API<br/>from flask import Flask<br/>import pickle</span><span id="c1a2" class="nn mc iq om b gy ou or l os ot">app = Flask(__name__)<br/>model = pickle.load(open("my_awesome_model.sav", 'rb'))<br/>...<br/>@app.route('/predict', methods=['POST'])<br/>def predict():<br/>    # Grab data from the HTTP request<br/>    ...<br/>    model.predict(...)<br/>    ...</span></pre><ul class=""><li id="1225" class="my mz iq kh b ki kj kl km ko na ks nb kw nc la nd ne nf ng bi translated"><strong class="kh ir">张量流</strong>:不需要编码！您可以使用<a class="ae nh" href="https://www.tensorflow.org/serving/" rel="noopener ugc nofollow" target="_blank"><strong class="kh ir">tensor flow Serving</strong></a>来提供大规模预测。一旦训练好模型并将其保存为正确的格式，为预测服务所需要做的就是:</li></ul><pre class="lc ld le lf gt ol om on oo aw op bi"><span id="34b5" class="nn mc iq om b gy oq or l os ot">docker run -p 8500:8500 \<br/>--mount type=bind,source=/tmp/myModel,target=/models/myModel \<br/>-e MODEL_NAME=myModel -t tensorflow/serving &amp;</span></pre><ul class=""><li id="2b60" class="my mz iq kh b ki kj kl km ko na ks nb kw nc la nd ne nf ng bi translated"><strong class="kh ir"> Apache MXNet </strong>:同样的，Apache MXNet 提供了一个<a class="ae nh" href="https://github.com/awslabs/mxnet-model-server" rel="noopener ugc nofollow" target="_blank"> <strong class="kh ir">模型服务器</strong>，</a>能够服务 MXNet 和<a class="ae nh" href="https://onnx.ai/" rel="noopener ugc nofollow" target="_blank"> <strong class="kh ir"> ONNX </strong> </a>模型(后者是 PyTorch、Caffe2 等支持的常用格式)。它既可以作为独立的应用程序运行，也可以在 Docker 容器中运行<a class="ae nh" href="https://github.com/awslabs/mxnet-model-server/blob/master/docker/README.md" rel="noopener ugc nofollow" target="_blank">。</a></li></ul><p id="5ab6" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">两个模型服务器都预装在<strong class="kh ir">深度学习 AMI: </strong>这是使用它的另一个原因。为了简单起见，您可以将您的前/后处理留在应用程序中，并调用由模型服务器部署的模型。但是，有一个警告:这些模型服务器既不实现认证也不实现节流，所以请确保不要将它们直接暴露给互联网流量。</p><ul class=""><li id="0e66" class="my mz iq kh b ki kj kl km ko na ks nb kw nc la nd ne nf ng bi translated"><strong class="kh ir">还有什么</strong>:如果你正在使用另一个环境(比如定制代码)或者非 web 架构(比如消息传递)，同样的模式应该适用:构建一个可以独立<strong class="kh ir">部署和扩展的独立服务</strong>。</li></ul><h2 id="0d4e" class="nn mc iq bd md no np dn mh nq nr dp ml ko ns nt mn ks nu nv mp kw nw nx mr ny bi translated">(可选)容器化您的应用程序</h2><p id="77ca" class="pw-post-body-paragraph kf kg iq kh b ki mt jr kk kl mu ju kn ko mv kq kr ks mw ku kv kw mx ky kz la ij bi translated">既然你已经决定拆分你的代码，我强烈建议你利用这个机会将不同的部分打包到 Docker 容器中:一个用于<strong class="kh ir">训练</strong>，一个用于<strong class="kh ir">预测</strong>，一个(或多个)用于<strong class="kh ir">应用</strong>。这个阶段严格来说没有必要，但是如果你能抽出时间，我相信过早的投资是值得的。</p><blockquote class="oa ob oc"><p id="4746" class="kf kg nz kh b ki kj jr kk kl km ju kn od kp kq kr oe kt ku kv of kx ky kz la ij bi translated">如果<!-- -->你一直生活在岩石下，或者从未真正关注过容器，现在可能是赶上的时候了:)我强烈推荐运行<a class="ae nh" href="https://docs.docker.com/get-started/" rel="noopener ugc nofollow" target="_blank"> Docker 教程</a>，它将教你为了我们的目的需要知道的一切。</p></blockquote><p id="fa9c" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">容器使得跨不同环境(开发、测试、生产等)移动代码变得容易。)和实例。它们解决了各种依赖问题，即使您只管理少量实例，这些问题也会突然出现。随后，容器也将成为 Docker clusters 或 Amazon SageMaker 等大型解决方案的先决条件。</p><h1 id="2d30" class="mb mc iq bd md me mf mg mh mi mj mk ml jw oh jx mn jz oi ka mp kc oj kd mr ms bi translated">第二周结束</h1><p id="a52d" class="pw-post-body-paragraph kf kg iq kh b ki mt jr kk kl mu ju kn ko mv kq kr ks mw ku kv kw mx ky kz la ij bi translated">经过一个艰难的开始，事情正在好转！</p><ul class=""><li id="7da4" class="my mz iq kh b ki kj kl km ko na ks nb kw nc la nd ne nf ng bi translated">深度学习 AMI 提供了一个稳定的、维护良好的基础。</li><li id="47a3" class="my mz iq kh b ki ni kl nj ko nk ks nl kw nm la nd ne nf ng bi translated">容器帮助您移动和部署您的应用程序，比以前少了很多基础设施。</li><li id="98b1" class="my mz iq kh b ki ni kl nj ko nk ks nl kw nm la nd ne nf ng bi translated">预测现在存在于您的应用程序之外，使得测试、部署和扩展更加简单。</li><li id="4c6a" class="my mz iq kh b ki ni kl nj ko nk ks nl kw nm la nd ne nf ng bi translated">如果您可以使用它们，模型服务器将为您省去编写预测服务的大部分麻烦。</li></ul><p id="de8a" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">不过，不要太激动。是的，我们回到了正轨，并准备好做更大的事情，但仍有大量的工作要做。那么<strong class="kh ir">对多个实例的伸缩预测、</strong> <strong class="kh ir">高可用性</strong>、<strong class="kh ir">管理成本</strong>等呢？当堆积如山的训练数据开始堆积时，我们该怎么办？面对现实吧，我们仅仅触及了表面。</p><p id="e815" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">“<em class="nz">老傻瓜！负载平衡器！自动缩放！自动化！</em>“我听到你的哭声。哦，你是说你又急着管理基础设施了？我以为你们想要机器学习。)</p><p id="c500" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这个重磅炸弹，是时候收工了。<a class="ae nh" href="https://medium.com/@julsimon/scaling-machine-learning-from-0-to-millions-of-users-part-2-80b0d1d7fc61" rel="noopener">在下一篇</a>中，我们将开始比较和挑战更大规模 ML 培训的选项:<strong class="kh ir">EC2</strong>vs<strong class="kh ir">ECS/EKS</strong>vs<strong class="kh ir">SageMaker</strong>。一场史诗般的战斗，毫无疑问。</p><p id="614c" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">感谢阅读。同意吗？不同意？太好了！乐于在此讨论或在<a class="ae nh" href="https://twitter.com/julsimon" rel="noopener ugc nofollow" target="_blank"> Twitter </a>上讨论。</p></div><div class="ab cl ov ow hu ox" role="separator"><span class="oy bw bk oz pa pb"/><span class="oy bw bk oz pa pb"/><span class="oy bw bk oz pa"/></div><div class="ij ik il im in"><p id="edb2" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">有史以来最佳电影配乐。是的，魔戒团契只排第二:)</p><figure class="lc ld le lf gt lg"><div class="bz fp l di"><div class="pc pd l"/></div></figure></div></div>    
</body>
</html>