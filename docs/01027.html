<html>
<head>
<title>Facial attribute detection using Deep learning</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用深度学习的人脸属性检测</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/real-time-multi-facial-attribute-detection-using-transfer-learning-and-haar-cascades-with-fastai-47ff59e36df0?source=collection_archive---------11-----------------------#2019-02-17">https://towardsdatascience.com/real-time-multi-facial-attribute-detection-using-transfer-learning-and-haar-cascades-with-fastai-47ff59e36df0?source=collection_archive---------11-----------------------#2019-02-17</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="2b46" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">一个快速的 4 部分演练，通过使用深度学习进行实时多面部属性检测(ResNet50 与 FastAI &amp; Pytorch)，使用 Haar 级联进行面部检测和定位(OpenCV)。</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi kf"><img src="../Images/0dd1b45737f82e404d7d57d73b489293.png" data-original-src="https://miro.medium.com/v2/resize:fit:1200/1*w6BrQtmkxhXh3cskNHXqMw.gif"/></div><figcaption class="kn ko gj gh gi kp kq bd b be z dk">The final output of the multi facial attribute detection project.</figcaption></figure><p id="855d" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">在这篇文章中，我们试图达到上述结果。这篇文章用一个端到端的过程来指导我如何构建它。复制项目的全部代码都在我的<a class="ae ln" href="https://github.com/aayushmnit/Deep_learning_explorations/tree/master/7_Facial_attributes_fastai_opencv" rel="noopener ugc nofollow" target="_blank"> GitHub 库</a>中。</p><h1 id="a878" class="lo lp iq bd lq lr ls lt lu lv lw lx ly jw lz jx ma jz mb ka mc kc md kd me mf bi translated">第 1 部分—数据采集和理解</h1><p id="4f09" class="pw-post-body-paragraph kr ks iq kt b ku mg jr kw kx mh ju kz la mi lc ld le mj lg lh li mk lk ll lm ij bi translated">对于任何深度学习模型来说，要给出合理的准确率，我们都需要依赖大量的标注数据。我发现大多数关于面部特征检测的报告都只集中在多类分类上，如情感检测、微笑检测等。我在寻找一个带有多个标签的面部图像数据集，这样我就可以实现一个<a class="ae ln" href="https://cloud.google.com/vision/" rel="noopener ugc nofollow" target="_blank">谷歌视觉 API </a>实现的东西，如下所示—</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="mm mn di mo bf mp"><div class="gh gi ml"><img src="../Images/6c180fe9968693858b9885e9237ec3fa.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*3Hyqvaog_-eNJFWO7VaVBQ.png"/></div></div><figcaption class="kn ko gj gh gi kp kq bd b be z dk">Example of a facial detection output from Google vision API</figcaption></figure><p id="149d" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">为此，我在<a class="ae ln" href="https://www.kaggle.com/datasets" rel="noopener ugc nofollow" target="_blank"> Kaggle 数据集网站</a>上找到了一个名为<a class="ae ln" href="https://www.kaggle.com/jessicali9530/celeba-dataset" rel="noopener ugc nofollow" target="_blank">CelebA 属性(CelebA)数据集</a>的数据集，其中包含-</p><ul class=""><li id="3b6b" class="mq mr iq kt b ku kv kx ky la ms le mt li mu lm mv mw mx my bi translated">202，599 个各种名人的面部图像</li><li id="af89" class="mq mr iq kt b ku mz kx na la nb le nc li nd lm mv mw mx my bi translated">10，177 个独特的身份，但没有给出名人的名字</li><li id="bd4e" class="mq mr iq kt b ku mz kx na la nb le nc li nd lm mv mw mx my bi translated">每个图像 40 个二元属性注释</li><li id="5a19" class="mq mr iq kt b ku mz kx na la nb le nc li nd lm mv mw mx my bi translated">5 个地标位置</li></ul><p id="f672" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">对于处理计算机视觉中的各种令人兴奋的问题来说，这是一个相当不错的数据集，因为我只对面部图像和这些图像的 40 个二进制属性注释感兴趣。这里列出了 40 个二元属性(是/否)——5 点钟形阴影、拱形眉毛、迷人、眼袋、秃头、刘海、大嘴唇、大鼻子、黑发、金发、模糊、棕色头发、浓密的眉毛、胖乎乎的、双下巴、眼镜、山羊胡、灰色头发、浓妆、高颧骨、男性、嘴巴微张、小胡子、窄眼睛、无胡须、椭圆形脸、苍白的皮肤、尖鼻子、后移的发际线这里有一个例子-</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="mm mn di mo bf mp"><div class="gh gi ne"><img src="../Images/38a81c1cbdf55663e24395ab4bf11c19.png" data-original-src="https://miro.medium.com/v2/resize:fit:356/format:webp/1*-cd08kLHxS-hEp2hrE452Q.png"/></div></div><figcaption class="kn ko gj gh gi kp kq bd b be z dk">Example from CelbeA dataset</figcaption></figure><p id="a7e3" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">上面的图片标注了这些特征——拱形眉毛，迷人，大嘴唇，浓妆，窄眼睛，没有胡子，尖鼻子，涂着口红，年轻。因为雄旗是假的，我们可以说标签是雌的。</p><h1 id="f8fd" class="lo lp iq bd lq lr ls lt lu lv lw lx ly jw lz jx ma jz mb ka mc kc md kd me mf bi translated">第 2 部分—数据预处理</h1><p id="edae" class="pw-post-body-paragraph kr ks iq kt b ku mg jr kw kx mh ju kz la mi lc ld le mj lg lh li mk lk ll lm ij bi translated">数据预处理的全部代码都在<a class="ae ln" href="https://github.com/aayushmnit/Deep_learning_explorations/blob/master/7_Facial_attributes_fastai_opencv/Data_prepration.ipynb" rel="noopener ugc nofollow" target="_blank">这个笔记本</a>里。</p><p id="2d47" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated"><strong class="kt ir"> 2.1)在图像上- </strong></p><p id="a9c0" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">当我为 CelebA 数据集进行数据处理时，我的主要想法是考虑如何使用建立在真实视频/网络摄像头流/图像上的模型。CelebA 数据紧密地裁剪在脸部周围，但是在视频/网络摄像头/图像中，脸部可以在任何地方，并且必须首先被检测到。有许多预先构建的工具可以在图像中定位人脸，例如<a class="ae ln" href="https://github.com/ageitgey/face_recognition" rel="noopener ugc nofollow" target="_blank">人脸识别</a>，它使用深度学习网络来检测人脸。我想保持这一步简单，所以我使用了<a class="ae ln" href="https://docs.opencv.org/3.3.0/d7/d8b/tutorial_py_face_detection.html" rel="noopener ugc nofollow" target="_blank">哈尔级联</a>，这是一种传统的计算机视觉方法来检测物体。Haar cascade 返回检测到人脸的图像上的边界框坐标，下面是使用 Haar cascade 的输出示例</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="ab gu cl nf"><img src="../Images/e5f485fd2daebcb57f38c1ec7e5fcaa9.png" data-original-src="https://miro.medium.com/v2/format:webp/1*1WEz_nmsV4L9RqyIV0x25w.png"/></div><figcaption class="kn ko gj gh gi kp kq bd b be z dk">An example of Haar Cascade output.</figcaption></figure><p id="369f" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">要了解更多关于哈尔瀑布的信息，请参考<a class="ae ln" rel="noopener" target="_blank" href="/face-detection-for-beginners-e58e8f21aad9">这篇博客</a>。<a class="ae ln" href="https://docs.opencv.org/3.3.0/index.html" rel="noopener ugc nofollow" target="_blank"> OpenCV </a>中有<a class="ae ln" href="https://github.com/opencv/opencv/tree/master/data/haarcascades" rel="noopener ugc nofollow" target="_blank">预置的 haar 级联</a>滤镜。我用其中一个进行正面人脸检测。因此，一旦决定了人脸检测的方法，下一步就是在 CelebA 数据集上应用相同的方法来检测人脸，并只裁剪图像的面部区域(增加一些边距)，这一步将有助于确保</p><ul class=""><li id="799c" class="mq mr iq kt b ku kv kx ky la ms le mt li mu lm mv mw mx my bi translated">我们使用 Haar 级联来移除正面人脸未被检测到的任何人脸，例如人侧脸的情况</li><li id="3f3b" class="mq mr iq kt b ku mz kx na la nb le nc li nd lm mv mw mx my bi translated">这将确保我们的训练图像符合模型的实际使用</li></ul><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi ng"><img src="../Images/aa10f78fc6f6bc8004d3dc2723753577.png" data-original-src="https://miro.medium.com/v2/resize:fit:1190/format:webp/1*u6WqKEaGQ4zu87yqCq79gw.png"/></div><figcaption class="kn ko gj gh gi kp kq bd b be z dk">Example of Haar cascade processing on CelebA dataset</figcaption></figure><p id="bbf3" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">请注意，在上面的例子中，在哈尔级联裁剪后，左边的图片被转换为右边的图片(看起来更放大了)。我们还从 202，599 张图像过滤到 175，640 张图像，因为过滤后的图像不包含正面人脸。过滤后的图像示例如下-</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="mm mn di mo bf mp"><div class="gh gi ne"><img src="../Images/b8ea3e09f43706ece8d4d63e9952f8b3.png" data-original-src="https://miro.medium.com/v2/resize:fit:356/format:webp/1*v4FMM3wu3D_XPw_9EbOdqA.png"/></div></div><figcaption class="kn ko gj gh gi kp kq bd b be z dk">Example of a filtered image.</figcaption></figure><p id="444f" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated"><strong class="kt ir"> 2.2)在标签文件上- </strong></p><p id="d9d1" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">除了对图像进行预处理，我们还需要创建我们的标签文件，供 FastAI 数据集加载器使用。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="mm mn di mo bf mp"><div class="gh gi nh"><img src="../Images/b2e0a12809fb6c5343d79a82ecf98fd6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*lnRT4qCyM-aLNTsoAW9jng.png"/></div></div><figcaption class="kn ko gj gh gi kp kq bd b be z dk">Original label file</figcaption></figure><p id="7a2f" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">在原始标签文件中，多属性标签每 40 个属性包含 1 /-1 个值，其中 1 表示该特征是否存在，而-1 表示该特征不存在。我只是写了一个简单的函数来转换这个文件，这样我们只有一个标签列，用空格分隔标签(如下图)</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="mm mn di mo bf mp"><div class="gh gi ni"><img src="../Images/d1e1a80217d02156d48cb61e59a7bbed.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*72yW7IsU3xZ9PEYEJ7P44A.png"/></div></div><figcaption class="kn ko gj gh gi kp kq bd b be z dk">Modified Label file</figcaption></figure><h1 id="79db" class="lo lp iq bd lq lr ls lt lu lv lw lx ly jw lz jx ma jz mb ka mc kc md kd me mf bi translated">第 3 部分—模型培训</h1><p id="d1d1" class="pw-post-body-paragraph kr ks iq kt b ku mg jr kw kx mh ju kz la mi lc ld le mj lg lh li mk lk ll lm ij bi translated">一旦我们预处理了我们的数据，下一步是建立一个模型，它可以检测给定面部图像的 40+个属性。为此，我们将使用由<a class="ae ln" href="https://pytorch.org/" rel="noopener ugc nofollow" target="_blank"> Pytorch 1.0 </a>编写的<a class="ae ln" href="https://docs.fast.ai/" rel="noopener ugc nofollow" target="_blank"> FastAI </a> v1 库。模特训练笔记本可以在我的<a class="ae ln" href="https://github.com/aayushmnit/Deep_learning_explorations/blob/master/7_Facial_attributes_fastai_opencv/MultiClass%20classification%20on%20CelebA%20dataset%20using%20FastAI.ipynb" rel="noopener ugc nofollow" target="_blank"> Github 这里</a>找到。我根据对图像编号的建议划分，从 1–182637(用于训练)到 182638(用于验证)对训练和验证集中的数据进行了划分。在 FastAI 库中用几行代码训练世界级的模型是不可思议的容易，所以让我们来看看代码-</p><p id="0017" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated"><strong class="kt ir">锅炉钢板库导入命令— </strong></p><pre class="kg kh ki kj gt nj nk nl nm aw nn bi"><span id="34f5" class="no lp iq nk b gy np nq l nr ns"><strong class="nk ir">import</strong> <strong class="nk ir">pandas</strong> <strong class="nk ir">as</strong> <strong class="nk ir">pd</strong><br/><strong class="nk ir">import</strong> <strong class="nk ir">numpy</strong> <strong class="nk ir">as</strong> <strong class="nk ir">np</strong><br/><strong class="nk ir">from</strong> <strong class="nk ir">fastai.vision</strong> <strong class="nk ir">import</strong> *<br/><strong class="nk ir">import</strong> <strong class="nk ir">matplotlib.pyplot</strong> <strong class="nk ir">as</strong> <strong class="nk ir">plt</strong></span></pre><p id="d9b5" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated"><strong class="kt ir">数据集加载</strong></p><pre class="kg kh ki kj gt nj nk nl nm aw nn bi"><span id="e99a" class="no lp iq nk b gy np nq l nr ns">path = Path('../data/celeba/faces/')<br/><em class="nt">## Function to filter validation samples</em><br/><strong class="nk ir">def</strong> validation_func(x):<br/>    <strong class="nk ir">return</strong> 'validation' <strong class="nk ir">in</strong> x</span><span id="f60a" class="no lp iq nk b gy nu nq l nr ns">tfms = get_transforms(do_flip=<strong class="nk ir">False</strong>, flip_vert=<strong class="nk ir">False</strong>, max_rotate=30, max_lighting=0.3)</span><span id="73c7" class="no lp iq nk b gy nu nq l nr ns">src = (ImageItemList.from_csv(path, csv_name='labels.csv')<br/>       .split_by_valid_func(validation_func)<br/>       .label_from_df(cols='tags',label_delim=' '))</span><span id="f6e1" class="no lp iq nk b gy nu nq l nr ns">data = (src.transform(tfms, size=128)<br/>       .databunch(bs=256).normalize(imagenet_stats))</span></pre><p id="885b" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated"><em class="nt">第 1 行</em> —定义数据集文件夹的路径。</p><p id="7054" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated"><em class="nt">第 2–4 行</em> —定义我们将如何找到训练和验证图像。</p><p id="7224" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated"><em class="nt">第 6–7 行</em> —定义我们想要对数据进行的变换，例如将图像随机旋转最大 30 度，以及最大 0.3 的光照调整。</p><p id="845c" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated"><em class="nt">第 8 行</em> —将图像定义为标签 CSV 中的项目列表</p><p id="30b9" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated"><em class="nt">第 9 行</em> —使用第 2–4 行的验证函数拆分训练和验证中的数据</p><p id="9450" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated"><em class="nt">第 10 行</em> —帮助我们从 labels.csv 的 tags 列获取标签，并帮助我们定义它是一个多标签列，其中用空格分隔标签。</p><p id="5117" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated"><em class="nt">第 12 行</em> —传递第 6–7 行的转换函数，将图像大小调整为 3*128*128</p><p id="03c1" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated"><em class="nt">第 13 行</em> —定义 256 张图像的批量大小，并使用 ImageNet 平均值对数据进行标准化</p><p id="970f" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">请注意，我们使用较小的图像大小进行模型的初始训练，稍后我们将图像大小增加到 3*256*256。这个技巧通过允许更大的批量帮助我们更快地训练我们的模型，并且更快地试验什么模型配置有效。</p><p id="905f" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated"><strong class="kt ir">模型定义— </strong></p><p id="31cb" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">在本次建模练习中，我们将使用预先训练好的 ResNet 50 模型进行迁移学习。</p><pre class="kg kh ki kj gt nj nk nl nm aw nn bi"><span id="7067" class="no lp iq nk b gy np nq l nr ns">arch = models.resnet50<br/>acc_02 = partial(accuracy_thresh, thresh=0.2)<br/>acc_03 = partial(accuracy_thresh, thresh=0.3)<br/>acc_04 = partial(accuracy_thresh, thresh=0.4)<br/>acc_05 = partial(accuracy_thresh, thresh=0.5)<br/>f_score = partial(fbeta, thresh=0.2)<br/>learn = create_cnn(data, arch, metrics=[acc_02, acc_03, acc_04, acc_05, f_score])</span></pre><p id="daa3" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated"><em class="nt"> Line1 </em> —下载预训练的 Resnet 50 模型</p><p id="3b5c" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated"><em class="nt">第 2–6 行</em> —在 FastAI 中，我们可以跟踪尽可能多的验证数据的准确性度量；这些指标仅用于监控，不用于训练模型。我们使用部分函数来定义不同阈值的准确性，并跟踪阈值为 0.2 时的 F 值</p><p id="ab1b" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated"><em class="nt">第 7 行</em> —通过使用 ResNet 50 模型的预训练卷积部分并在顶部添加两个新的全连接层，帮助创建 CNN 架构。</p><p id="4b98" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">FastAI 的好处是，它通过为特定的兴趣练习找到理想的学习速度，节省了大量的训练时间。</p><pre class="kg kh ki kj gt nj nk nl nm aw nn bi"><span id="2379" class="no lp iq nk b gy np nq l nr ns">learn.lr_find()<br/>learn.recorder.plot()</span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi nv"><img src="../Images/6686bac7c7f40ddc56b41803106f580c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1026/format:webp/1*S5ODHYM2GLdpOvZUWEPMfA.png"/></div><figcaption class="kn ko gj gh gi kp kq bd b be z dk">Learning rate finder from FastAI</figcaption></figure><p id="68d6" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated"><em class="nt">第 1 行——通过在数据样本上尝试多个学习率来找到理想的学习率</em></p><p id="c589" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated"><em class="nt">第 2 行— </em>让我们画出不同学习速率下的损失。</p><p id="ac48" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">我们需要在上面的函数中选择一个斜率最大的学习率。在这种情况下，它是 1e-2。</p><pre class="kg kh ki kj gt nj nk nl nm aw nn bi"><span id="6394" class="no lp iq nk b gy np nq l nr ns">lr = 1e-2<br/>learn.fit_one_cycle(4, slice(lr))</span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="mm mn di mo bf mp"><div class="gh gi nw"><img src="../Images/012a5fec551fb4a8500900286baf9182.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*JEwv2EmwIE7D0sNJvVWi1w.png"/></div></div><figcaption class="kn ko gj gh gi kp kq bd b be z dk">Training snapshot</figcaption></figure><p id="8687" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">现在我们已经训练了最后一个全连接层。让我们解冻所有的层，并训练完整的模型。我们将使用学习率查找器再次确定理想的学习率。</p><pre class="kg kh ki kj gt nj nk nl nm aw nn bi"><span id="251e" class="no lp iq nk b gy np nq l nr ns">learn.unfreeze()<br/>learn.lr_find()<br/>learn.recorder.plot()</span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi nx"><img src="../Images/627815ee7fbf8062ce3a46fe6d9aeb6a.png" data-original-src="https://miro.medium.com/v2/resize:fit:990/format:webp/1*GfjdBMBi-0KUrN4B9B1XnQ.png"/></div><figcaption class="kn ko gj gh gi kp kq bd b be z dk">Snapshot of learning rate finder in FastAI</figcaption></figure><p id="ae45" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated"><em class="nt">线 1 </em> —解冻所有层</p><p id="b55e" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated"><em class="nt">第 2–3 行</em> —帮助我们找到理想的学习速度。</p><p id="2107" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">现在，我们将对模型中的每一层使用不同的学习速率，方法是当我们回到各层时，按指数规律衰减学习速率。</p><pre class="kg kh ki kj gt nj nk nl nm aw nn bi"><span id="12e8" class="no lp iq nk b gy np nq l nr ns">learn.fit_one_cycle(5, slice(1e-5, lr/5))<br/>learn.save('ff_stage-2-rn50')</span></pre><p id="8262" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated"><em class="nt">第 1 行</em> —以可变学习率使用一个周期学习</p><p id="0f5e" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated"><em class="nt">第 2 行</em> —用指定的名称保存我们的模型。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="mm mn di mo bf mp"><div class="gh gi ny"><img src="../Images/87e80a94d8d725fd6f47e08d8bf2b2c9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*TZUX2mtl3VCoD0eKmwmYDQ.png"/></div></div><figcaption class="kn ko gj gh gi kp kq bd b be z dk">Training snapshot</figcaption></figure><p id="7fba" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">现在，我们可以将输入图像大小增加到 3*256*256，并在上面训练的模型上使用迁移学习来适应新的输入图像大小。</p><pre class="kg kh ki kj gt nj nk nl nm aw nn bi"><span id="5aa5" class="no lp iq nk b gy np nq l nr ns">data = (src.transform(tfms, size=256)<br/>       .databunch(bs=64).normalize(imagenet_stats))</span><span id="6588" class="no lp iq nk b gy nu nq l nr ns">acc_05 = partial(accuracy_thresh, thresh=0.5)<br/>f_score = partial(fbeta, thresh=0.5)<br/>learn = create_cnn(data, models.resnet50, pretrained=<strong class="nk ir">False</strong>,metrics=[acc_05, f_score])</span><span id="1c7b" class="no lp iq nk b gy nu nq l nr ns">learn.load("ff_stage-2-rn50")</span></pre><p id="ab50" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated"><em class="nt">第 1–2 行</em> —创建一个新的数据加载器，将图像大小调整为 3*256*256，并将批量大小减少到 64。</p><p id="ea9f" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated"><em class="nt">第 4–6 行</em> —定义我们需要跟踪的指标，并创建一个与之前模型相似的 ResNet 50 模型。</p><p id="4b73" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated"><em class="nt">第 8 行</em> —将权重从我们之前训练的模型加载到新创建的模型中。</p><p id="a445" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">现在，我们可以按照上面提到的类似步骤对模型进行更多的训练。培训笔记本还提供了可视化中间层激活的代码，以帮助理解图像的哪一部分驱动模型的最终结果。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi nz"><img src="../Images/debb402ac9f6f9198064fdb42cdb7424.png" data-original-src="https://miro.medium.com/v2/resize:fit:570/format:webp/1*pJwxROPt0BZQl_Ipwt3olw.png"/></div><figcaption class="kn ko gj gh gi kp kq bd b be z dk">Models Intermediate Activation layers heatmap over the actual image.</figcaption></figure><p id="27da" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">正如我们可以从上面的图像中看到的，该模型在图像中人脸所在的位置最活跃，这正是我们想要的，因为它是一个面部特征检测模型。</p><h1 id="489e" class="lo lp iq bd lq lr ls lt lu lv lw lx ly jw lz jx ma jz mb ka mc kc md kd me mf bi translated">第 4 部分—组合一切</h1><p id="62dc" class="pw-post-body-paragraph kr ks iq kt b ku mg jr kw kx mh ju kz la mi lc ld le mj lg lh li mk lk ll lm ij bi translated">现在我们已经训练好了我们的模型，让我们写一个可以进行面部属性检测的脚本，最后一部分是把它们放在一起。这部分的代码在我的<a class="ae ln" href="https://github.com/aayushmnit/Deep_learning_explorations/blob/master/7_Facial_attributes_fastai_opencv/detect_features.py" rel="noopener ugc nofollow" target="_blank"> Github 这里</a>。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="mm mn di mo bf mp"><div class="gh gi oa"><img src="../Images/c8fdfd6c9ed28c8a1c0dc6f35a332c91.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*WBPRilhDFbP9Py5veN1Q1g.png"/></div></div><figcaption class="kn ko gj gh gi kp kq bd b be z dk">Detection script process flow</figcaption></figure><p id="5b66" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">该脚本执行以下任务-</p><ol class=""><li id="abbd" class="mq mr iq kt b ku kv kx ky la ms le mt li mu lm ob mw mx my bi translated">使用 OpenCV 访问网络摄像头拍摄输入视频并转换成一系列图像帧。</li><li id="9442" class="mq mr iq kt b ku mz kx na la nb le nc li nd lm ob mw mx my bi translated">对于每一帧，我们从 OpenCV 运行 Haar 级联模型来定位面部并将其从帧中裁剪出来。</li><li id="44d5" class="mq mr iq kt b ku mz kx na la nb le nc li nd lm ob mw mx my bi translated">将这些裁剪出来的检测到的人脸帧传递到我们训练过的模型中，以找到相关的面部特征</li><li id="1c2f" class="mq mr iq kt b ku mz kx na la nb le nc li nd lm ob mw mx my bi translated">运行脚本时，显示边界框以及在帧上检测到的所有特征</li><li id="570c" class="mq mr iq kt b ku mz kx na la nb le nc li nd lm ob mw mx my bi translated">可选地保存视频流</li></ol><h1 id="92c0" class="lo lp iq bd lq lr ls lt lu lv lw lx ly jw lz jx ma jz mb ka mc kc md kd me mf bi translated">结论</h1><p id="cf8a" class="pw-post-body-paragraph kr ks iq kt b ku mg jr kw kx mh ju kz la mi lc ld le mj lg lh li mk lk ll lm ij bi translated">在上面的博客中，我们看到了如何通过将从传统机器视觉到深度学习的各种技术结合在一起，来完成端到端的面部属性检测问题。</p><p id="4184" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">我希望你喜欢阅读，并随时使用我在<a class="ae ln" href="https://github.com/aayushmnit/Deep_learning_explorations/tree/master/7_Facial_attributes_fastai_opencv" rel="noopener ugc nofollow" target="_blank"> Github </a>上的代码来为你的目的进行试验。此外，如果对代码或博客有任何反馈，请随时联系 aayushmnit@gmail.com 的<a class="ae ln" href="https://www.linkedin.com/in/aayushmnit/" rel="noopener ugc nofollow" target="_blank"> LinkedIn </a>或给我发电子邮件。您也可以在 Medium 和 Github 上关注我，了解我将来可能会写的博客文章和探索项目代码。</p></div></div>    
</body>
</html>