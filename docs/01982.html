<html>
<head>
<title>Easy Image Classification with TensorFlow 2.0</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用 TensorFlow 2.0 轻松进行图像分类</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/easy-image-classification-with-tensorflow-2-0-f734fee52d13?source=collection_archive---------2-----------------------#2019-04-02">https://towardsdatascience.com/easy-image-classification-with-tensorflow-2-0-f734fee52d13?source=collection_archive---------2-----------------------#2019-04-02</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="4933" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated"><span class="l kf kg kh bm ki kj kk kl km di"> G </span> etting 从 TensorFlow 2.0 alpha 的改进高级 API 开始</h2></div><figure class="ko kp kq kr gt ks gh gi paragraph-image"><div role="button" tabindex="0" class="kt ku di kv bf kw"><div class="gh gi kn"><img src="../Images/98050328fea161885f066e9d5d9f8818.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Ni9QTN23XU2K5LjtzdObew.png"/></div></div></figure><h1 id="995b" class="kz la iq bd lb lc ld le lf lg lh li lj jw lk jx ll jz lm ka ln kc lo kd lp lq bi translated">具有重大优势的主要版本</h1><p id="cd04" class="pw-post-body-paragraph lr ls iq lt b lu lv jr lw lx ly ju lz ma mb mc md me mf mg mh mi mj mk ml mm ij bi translated">在 2019 年 TensorFlow Dev 峰会上，谷歌推出了 TensorFlow 2.0 的 alpha 版本。从历史上看，TensorFlow 被认为是机器学习框架的“工业车床”:一个强大的工具，具有令人生畏的复杂性和陡峭的学习曲线。如果你过去用过 TensorFlow 1.x，你就知道我在说什么。这个 2.0 版本代表了为提高 TensorFlow 的可用性、清晰性和灵活性所做的共同努力。以下是一些亮点:</p><ul class=""><li id="99e7" class="mn mo iq lt b lu mp lx mq ma mr me ms mi mt mm mu mv mw mx bi translated">默认情况下，会启用急切执行，而不会牺牲基于图形的执行的性能优化。</li><li id="c022" class="mn mo iq lt b lu my lx mz ma na me nb mi nc mm mu mv mw mx bi translated">API 更干净，更一致，冗余更少。</li><li id="43ee" class="mn mo iq lt b lu my lx mz ma na me nb mi nc mm mu mv mw mx bi translated">作为高级 API 的更紧密的 Keras 集成。</li><li id="9c8b" class="mn mo iq lt b lu my lx mz ma na me nb mi nc mm mu mv mw mx bi translated"><a class="ae nd" href="https://www.tensorflow.org/community/roadmap" rel="noopener ugc nofollow" target="_blank">还有更</a></li></ul><p id="1682" class="pw-post-body-paragraph lr ls iq lt b lu mp jr lw lx mq ju lz ma ne mc md me nf mg mh mi ng mk ml mm ij bi translated">因此，TensorFlow 2.0 更加 Pythonic 化，学习起来不那么令人畏惧，同时保留了较低级别的定制和复杂性(如果需要的话)。让我们从 TensorFlow 2.0 开始，探索如何在经典图像分类设置中应用其高级 API。</p><h1 id="d466" class="kz la iq bd lb lc ld le lf lg lh li lj jw lk jx ll jz lm ka ln kc lo kd lp lq bi translated">在 Colab 上安装 TensorFlow 2.0 alpha</h1><p id="4fd1" class="pw-post-body-paragraph lr ls iq lt b lu lv jr lw lx ly ju lz ma mb mc md me mf mg mh mi mj mk ml mm ij bi translated"><a class="ae nd" href="https://colab.research.google.com" rel="noopener ugc nofollow" target="_blank">谷歌合作实验室</a>让在云中设置 Python 笔记本变得非常容易。由于每次可以免费访问 GPU 长达 12 小时，Colab 很快成为我进行机器学习实验的首选平台。</p><p id="230a" class="pw-post-body-paragraph lr ls iq lt b lu mp jr lw lx mq ju lz ma ne mc md me nf mg mh mi ng mk ml mm ij bi translated">让我们通过 pip 在一台 Colab 笔记本上安装 TensorFlow 2.0 alpha 版本(GPU 版)。</p><pre class="ko kp kq kr gt nh ni nj nk aw nl bi"><span id="2cf5" class="nm la iq ni b gy nn no l np nq">!pip install tensorflow-gpu==2.0.0-alpha0</span></pre><p id="6e62" class="pw-post-body-paragraph lr ls iq lt b lu mp jr lw lx mq ju lz ma ne mc md me nf mg mh mi ng mk ml mm ij bi translated">要验证其安装是否正确:</p><pre class="ko kp kq kr gt nh ni nj nk aw nl bi"><span id="eeff" class="nm la iq ni b gy nn no l np nq">import tensorflow as tf<br/>print(tf.__version)</span><span id="d111" class="nm la iq ni b gy nr no l np nq"># Output: 2.0.0-alpha0</span></pre><p id="80dd" class="pw-post-body-paragraph lr ls iq lt b lu mp jr lw lx mq ju lz ma ne mc md me nf mg mh mi ng mk ml mm ij bi translated">你应该可以走了！如果您遇到问题，请在“编辑”&gt;“笔记本设置”中仔细检查您的 Colab 运行时是否将“GPU”作为运行时加速器。</p><h1 id="98dc" class="kz la iq bd lb lc ld le lf lg lh li lj jw lk jx ll jz lm ka ln kc lo kd lp lq bi translated">使用 tf.data.Dataset 加载数据</h1><p id="5d5d" class="pw-post-body-paragraph lr ls iq lt b lu lv jr lw lx ly ju lz ma mb mc md me mf mg mh mi mj mk ml mm ij bi translated">让我们使用 Kaggle 上的<a class="ae nd" href="https://www.kaggle.com/c/aerial-cactus-identification" rel="noopener ugc nofollow" target="_blank">空中仙人掌识别</a>比赛的数据集。我们的任务是建立一个分类器，能够确定一个航拍图像是否包含柱状仙人掌。该数据集是 Cactus 航空照片数据集[1]的修改版本(Kaggle 将每个图像的大小调整为 32x32 像素)。</p><figure class="ko kp kq kr gt ks gh gi paragraph-image"><div class="gh gi ns"><img src="../Images/98bfae45497f1e9e86e417178a0ec184.png" data-original-src="https://miro.medium.com/v2/resize:fit:232/format:webp/1*7jQjRGXeVvKrLCHyIMrC0w.jpeg"/></div><figcaption class="nt nu gj gh gi nv nw bd b be z dk">Example image with cactus</figcaption></figure><figure class="ko kp kq kr gt ks gh gi paragraph-image"><div class="gh gi nx"><img src="../Images/4c668f66f876d5ea9024a8632bb95e36.png" data-original-src="https://miro.medium.com/v2/resize:fit:256/format:webp/1*Co0dk3PmgQA0dAg81AnQuA.png"/></div><figcaption class="nt nu gj gh gi nv nw bd b be z dk">Example image with no cactus (upscaled 4x)</figcaption></figure><p id="659f" class="pw-post-body-paragraph lr ls iq lt b lu mp jr lw lx mq ju lz ma ne mc md me nf mg mh mi ng mk ml mm ij bi translated">例如从 Kaggle 下载/解压缩数据集的代码，请参见<a class="ae nd" href="https://github.com/cameroncruz/notebooks/blob/master/Easy_Image_Classification_with_TF_2.ipynb" rel="noopener ugc nofollow" target="_blank">完整笔记本，此处为</a>。</p><p id="e236" class="pw-post-body-paragraph lr ls iq lt b lu mp jr lw lx mq ju lz ma ne mc md me nf mg mh mi ng mk ml mm ij bi translated">让我们使用 pandas 将图像文件路径及其相应的标签加载到列表中，然后使用 sklearn.model_selection 创建一个 90–10 的训练验证分割。</p><pre class="ko kp kq kr gt nh ni nj nk aw nl bi"><span id="aebc" class="nm la iq ni b gy nn no l np nq">train_csv = pd.read_csv('data/train.csv')</span><span id="bd2b" class="nm la iq ni b gy nr no l np nq"># Prepend image filenames in train/ with relative path<br/>filenames = ['train/' + fname for fname in train_csv['id'].tolist()]<br/>labels = train_csv['has_cactus'].tolist()</span><span id="029b" class="nm la iq ni b gy nr no l np nq">train_filenames, val_filenames, train_labels, val_labels = <br/>  train_test_split(filenames,<br/>                 labels,<br/>                 train_size=0.9,<br/>                 random_state=42)</span></pre><p id="a24f" class="pw-post-body-paragraph lr ls iq lt b lu mp jr lw lx mq ju lz ma ne mc md me nf mg mh mi ng mk ml mm ij bi translated">现在我们已经将图像文件名和标签分成了训练集和验证集，我们可以创建各自的 tf.data.Dataset 对象。</p><pre class="ko kp kq kr gt nh ni nj nk aw nl bi"><span id="e8de" class="nm la iq ni b gy nn no l np nq">train_data = tf.data.Dataset.from_tensor_slices(<br/>  (tf.constant(train_filenames), tf.constant(train_labels))<br/>)</span><span id="c60c" class="nm la iq ni b gy nr no l np nq">val_data = tf.data.Dataset.from_tensor_slices(<br/>  (tf.constant(val_filenames), tf.constant(val_labels))<br/>)</span></pre><p id="05a3" class="pw-post-body-paragraph lr ls iq lt b lu mp jr lw lx mq ju lz ma ne mc md me nf mg mh mi ng mk ml mm ij bi translated">然而，我们的数据集仍然只包含图像文件名，而不是实际的图像。我们需要定义一个函数，可以从文件中加载图像，并执行任何必要的预处理。当我们这样做的时候，让我们也对数据集进行洗牌和批处理。</p><pre class="ko kp kq kr gt nh ni nj nk aw nl bi"><span id="937c" class="nm la iq ni b gy nn no l np nq">IMAGE_SIZE = 96 # Minimum image size for use with MobileNetV2</span><span id="ccfa" class="nm la iq ni b gy nr no l np nq">BATCH_SIZE = 32</span><span id="d4d5" class="nm la iq ni b gy nr no l np nq"># Function to load and preprocess each image<br/>def _parse_fn(filename, label):<br/>    img = tf.io.read_file(img)<br/>    img = tf.image.decode_jpeg(img)<br/>    img = (tf.cast(img, tf.float32)/127.5) - 1<br/>    img = tf.image.resize(img, (IMAGE_SIZE, IMAGE_SIZE))<br/>    return img, label<br/></span><span id="1b99" class="nm la iq ni b gy nr no l np nq"># Run _parse_fn over each example in train and val datasets<br/># Also shuffle and create batches</span><span id="a2dd" class="nm la iq ni b gy nr no l np nq">train_data = (train_data.map(_parse_fn)<br/>             .shuffle(buffer_size=10000)<br/>             .batch(BATCH_SIZE)<br/>             )</span><span id="0193" class="nm la iq ni b gy nr no l np nq">val_data = (val_data.map(_parse_fn)<br/>           .shuffle(buffer_size=10000)<br/>           .batch(BATCH_SIZE)<br/>           )</span></pre><h1 id="491e" class="kz la iq bd lb lc ld le lf lg lh li lj jw lk jx ll jz lm ka ln kc lo kd lp lq bi translated">构建迁移学习模型</h1><p id="b143" class="pw-post-body-paragraph lr ls iq lt b lu lv jr lw lx ly ju lz ma mb mc md me mf mg mh mi mj mk ml mm ij bi translated">迁移学习通过使我们能够重复使用现有的预训练图像分类模型来加速训练，只需要重新训练网络的顶层来确定图像可以属于的类别[2]。</p><figure class="ko kp kq kr gt ks gh gi paragraph-image"><div role="button" tabindex="0" class="kt ku di kv bf kw"><div class="gh gi ny"><img src="../Images/1b850db312edfc22399a96cfd8703743.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*5F4b6ggZY7hlvGHxbrhTyA.png"/></div></div><figcaption class="nt nu gj gh gi nv nw bd b be z dk">Diagram illustrating transfer learning</figcaption></figure><p id="e0d7" class="pw-post-body-paragraph lr ls iq lt b lu mp jr lw lx mq ju lz ma ne mc md me nf mg mh mi ng mk ml mm ij bi translated">让我们使用 TensorFlow 2.0 的高级 Keras API 来快速构建我们的图像分类模型。对于迁移学习，我们可以使用预训练的 MobileNetV2 模型作为特征检测器。MobileNetV2 是由 Google 发布的 MobileNet 的第二个迭代，目标是比 ResNet 和 Inception 等模型更小、更轻量级，以便在移动设备上运行[3]。让我们加载在 ImageNet 上预训练的没有顶层的 MobileNetV2 模型，冻结其权重，并添加新的分类头。</p><pre class="ko kp kq kr gt nh ni nj nk aw nl bi"><span id="43fd" class="nm la iq ni b gy nn no l np nq">IMG_SHAPE = (IMAGE_SIZE, IMAGE_SIZE, 3)</span><span id="83f7" class="nm la iq ni b gy nr no l np nq"># Pre-trained model with MobileNetV2<br/>base_model = tf.keras.applications.MobileNetV2(<br/>    input_shape=IMG_SHAPE,<br/>    include_top=False,<br/>    weights='imagenet'<br/>)</span><span id="ed84" class="nm la iq ni b gy nr no l np nq"># Freeze the pre-trained model weights<br/>base_model.trainable = False</span><span id="f11c" class="nm la iq ni b gy nr no l np nq"># Trainable classification head<br/>maxpool_layer = tf.keras.layers.GlobalMaxPooling2D()<br/>prediction_layer = tf.keras.layers.Dense(1, activation='sigmoid')</span><span id="1f55" class="nm la iq ni b gy nr no l np nq"># Layer classification head with feature detector<br/>model = tf.keras.Sequential([<br/>    base_model,<br/>    maxpool_layer,<br/>    prediction_layer<br/>])</span><span id="980d" class="nm la iq ni b gy nr no l np nq">learning_rate = 0.0001</span><span id="0721" class="nm la iq ni b gy nr no l np nq"># Compile the model<br/>model.compile(optimizer=tf.keras.optimizers.Adam(lr=learning_rate), <br/>              loss='binary_crossentropy',<br/>              metrics=['accuracy']<br/>)</span></pre><p id="7dd3" class="pw-post-body-paragraph lr ls iq lt b lu mp jr lw lx mq ju lz ma ne mc md me nf mg mh mi ng mk ml mm ij bi translated">注意，建议使用 TensorFlow 优化器训练<code class="fe nz oa ob ni b">tf.keras</code>模型。在 TensorFlow 2.0 中，之前<code class="fe nz oa ob ni b">tf.train</code>和<code class="fe nz oa ob ni b">tf.keras.optimizers</code>API 中的优化器已经统一在<code class="fe nz oa ob ni b">tf.keras.optimizers</code>下，其中原来的<code class="fe nz oa ob ni b">tf.keras</code>优化器已经被升级后的 TensorFlow 优化器所取代【4】。因此，应用 TensorFlow 优化器现在是一种更简单、更一致的体验，完全支持使用<code class="fe nz oa ob ni b">tf.keras</code> API，并且不会牺牲性能。</p><h1 id="778b" class="kz la iq bd lb lc ld le lf lg lh li lj jw lk jx ll jz lm ka ln kc lo kd lp lq bi translated">训练模型</h1><p id="90d9" class="pw-post-body-paragraph lr ls iq lt b lu lv jr lw lx ly ju lz ma mb mc md me mf mg mh mi mj mk ml mm ij bi translated">TensorFlow 2.0 中的<code class="fe nz oa ob ni b">tf.keras</code> API 现在已经完全支持<code class="fe nz oa ob ni b">tf.data</code> API，因此我们可以在训练模型时轻松使用我们的<code class="fe nz oa ob ni b">tf.data.Dataset</code>对象[5]。同样，现在默认情况下，训练会被急切地执行，而不会牺牲基于图形的执行的性能优势。</p><pre class="ko kp kq kr gt nh ni nj nk aw nl bi"><span id="7a01" class="nm la iq ni b gy nn no l np nq">num_epochs = 30<br/>steps_per_epoch = round(num_train)//BATCH_SIZE<br/>val_steps = 20</span><span id="689f" class="nm la iq ni b gy nr no l np nq">model.fit(train_data.repeat(),<br/>          epochs=num_epochs,<br/>          steps_per_epoch = steps_per_epoch,<br/>          validation_data=val_data.repeat(), <br/>          validation_steps=val_steps)</span></pre><p id="f49c" class="pw-post-body-paragraph lr ls iq lt b lu mp jr lw lx mq ju lz ma ne mc md me nf mg mh mi ng mk ml mm ij bi translated">经过 30 个时期后，模型的验证精度从大约 0.63 提高到 0.94。</p><figure class="ko kp kq kr gt ks gh gi paragraph-image"><div class="gh gi oc"><img src="../Images/ff1d5a494328029560cf6e40924fe32d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1002/format:webp/1*gNv90Sy4mmeuEpG_IuAlYQ.png"/></div><figcaption class="nt nu gj gh gi nv nw bd b be z dk">Accuracy and loss over 30 epochs of transfer learning</figcaption></figure><h1 id="152f" class="kz la iq bd lb lc ld le lf lg lh li lj jw lk jx ll jz lm ka ln kc lo kd lp lq bi translated">微调模型</h1><p id="bd11" class="pw-post-body-paragraph lr ls iq lt b lu lv jr lw lx ly ju lz ma mb mc md me mf mg mh mi mj mk ml mm ij bi translated">让我们试着进一步提高我们模型的准确性。当我们应用迁移学习时，我们只训练模型的新分类头，冻结来自 MobileNetV2 的权重。如果我们最初不冻结这些权重，模型将“忘记”它开始时的所有知识，因为新的分类头是随机初始化的[2]。然而，现在我们已经首先训练了分类头，我们可以在预训练的模型中解冻层，以在这个特定的数据集上进行微调。</p><pre class="ko kp kq kr gt nh ni nj nk aw nl bi"><span id="e5db" class="nm la iq ni b gy nn no l np nq"><em class="od"># Unfreeze all layers of MobileNetV2</em><br/>base_model.trainable = <strong class="ni ir">True</strong><br/><br/><em class="od"># Refreeze layers until the layers we want to fine-tune</em><br/><strong class="ni ir">for</strong> layer <strong class="ni ir">in</strong> base_model.layers[:100]:<br/>  layer.trainable =  <strong class="ni ir">False</strong></span><span id="2f7a" class="nm la iq ni b gy nr no l np nq"># Use a lower learning rate<br/>lr_finetune = learning_rate / 10</span><span id="a13d" class="nm la iq ni b gy nr no l np nq"># Recompile the model<br/>model.compile(loss='binary_crossentropy',<br/>              optimizer = tf.keras.optimizers.Adam(lr=lr_finetune),<br/>              metrics=['accuracy'])</span><span id="4ebf" class="nm la iq ni b gy nr no l np nq"># Increase training epochs for fine-tuning<br/>fine_tune_epochs = 30<br/>total_epochs =  num_epochs + fine_tune_epochs<br/></span><span id="43d7" class="nm la iq ni b gy nr no l np nq"># Fine-tune model<br/># Note: Set initial_epoch to begin training after epoch 30 since we<br/># previously trained for 30 epochs.</span><span id="6685" class="nm la iq ni b gy nr no l np nq">model.fit(train_data.repeat(), <br/>          steps_per_epoch = steps_per_epoch,<br/>          epochs=total_epochs, <br/>          initial_epoch = num_epochs,<br/>          validation_data=val_data.repeat(), <br/>          validation_steps=val_steps)</span></pre><p id="f9ba" class="pw-post-body-paragraph lr ls iq lt b lu mp jr lw lx mq ju lz ma ne mc md me nf mg mh mi ng mk ml mm ij bi translated">在另外 30 个时期的微调后，该模型达到了 0.986 的验证精度。基于准确度和损失图，更多的时期可能导致更大的改进。</p><figure class="ko kp kq kr gt ks gh gi paragraph-image"><div class="gh gi oe"><img src="../Images/2f20f84249a8f95c181e570a22056f8e.png" data-original-src="https://miro.medium.com/v2/resize:fit:962/format:webp/1*9Ez7YXASQSsGbnvvQ2k1eA.png"/></div><figcaption class="nt nu gj gh gi nv nw bd b be z dk">Accuracy and loss with additional 30 epochs of fine-tuning</figcaption></figure><h1 id="60de" class="kz la iq bd lb lc ld le lf lg lh li lj jw lk jx ll jz lm ka ln kc lo kd lp lq bi translated">摘要</h1><p id="c894" class="pw-post-body-paragraph lr ls iq lt b lu lv jr lw lx ly ju lz ma mb mc md me mf mg mh mi mj mk ml mm ij bi translated">在这篇文章中，我们了解了 TensorFlow 2.0 对可用性、清晰度和灵活性的关注如何使 TensorFlow 在机器学习实验中的入门变得不那么令人生畏。热切的执行和改进的高级 API 抽象出了 TensorFlow 通常的复杂性，使其更容易快速实施和运行典型的图像分类实验。</p><p id="b83e" class="pw-post-body-paragraph lr ls iq lt b lu mp jr lw lx mq ju lz ma ne mc md me nf mg mh mi ng mk ml mm ij bi translated">在撰写本文时，这只是 TensorFlow 2.0 的 alpha 版本，最终版本预计将在今年晚些时候发布。显然，TensorFlow 团队正在打造一个更加直观的 TensorFlow 迭代。这可能会全面提高机器学习工程师的生产率，降低通常的复杂性，同时为那些需要的人保留较低层次的控制。此外，虽然 TensorFlow 已经是机器学习专家的热门选择，但更平滑的学习曲线也使其对初学者更具吸引力。</p><p id="9025" class="pw-post-body-paragraph lr ls iq lt b lu mp jr lw lx mq ju lz ma ne mc md me nf mg mh mi ng mk ml mm ij bi translated">请在评论中告诉我你对 TensorFlow 2.0 目前为止的看法！另外，<strong class="lt ir">如果你对本教程的完整代码感兴趣，</strong> <a class="ae nd" href="https://github.com/cameroncruz/notebooks/blob/master/Easy_Image_Classification_with_TF_2.ipynb" rel="noopener ugc nofollow" target="_blank"> <strong class="lt ir">参见笔记本这里的</strong> </a>。如果你有任何问题，也不要犹豫，在评论区提问。</p><h1 id="2ea1" class="kz la iq bd lb lc ld le lf lg lh li lj jw lk jx ll jz lm ka ln kc lo kd lp lq bi translated">参考</h1><p id="3ec0" class="pw-post-body-paragraph lr ls iq lt b lu lv jr lw lx ly ju lz ma mb mc md me mf mg mh mi mj mk ml mm ij bi translated">本教程的灵感来自于使用 TensorFlow.org 的预训练网络进行迁移学习。阅读教程原文，见<a class="ae nd" href="https://www.tensorflow.org/alpha/tutorials/images/transfer_learning" rel="noopener ugc nofollow" target="_blank">此处</a>。</p><p id="27a0" class="pw-post-body-paragraph lr ls iq lt b lu mp jr lw lx mq ju lz ma ne mc md me nf mg mh mi ng mk ml mm ij bi translated">[1]Kaggle.com j .瓦斯奎兹-戈麦斯<a class="ae nd" href="https://www.kaggle.com/irvingvasquez/cactus-aerial-photos" rel="noopener ugc nofollow" target="_blank">仙人掌航拍照片</a> (2019)</p><p id="76b0" class="pw-post-body-paragraph lr ls iq lt b lu mp jr lw lx mq ju lz ma ne mc md me nf mg mh mi ng mk ml mm ij bi translated">[2] <a class="ae nd" href="https://www.tensorflow.org/alpha/tutorials/images/transfer_learning" rel="noopener ugc nofollow" target="_blank">利用预训练的 ConvNets 进行迁移学习</a> (2019)，TensorFlow.org</p><p id="6299" class="pw-post-body-paragraph lr ls iq lt b lu mp jr lw lx mq ju lz ma ne mc md me nf mg mh mi ng mk ml mm ij bi translated">[3] M. Sandler，A. Howard，m . Zhmonginov，L. C. Chen，<a class="ae nd" href="https://arxiv.org/pdf/1801.04381.pdf" rel="noopener ugc nofollow" target="_blank"> MobileNetV2:反向残差和线性瓶颈</a> (2019)，谷歌公司。</p><p id="941f" class="pw-post-body-paragraph lr ls iq lt b lu mp jr lw lx mq ju lz ma ne mc md me nf mg mh mi ng mk ml mm ij bi translated">[4] F. Chollet，<a class="ae nd" href="https://github.com/tensorflow/community/blob/master/rfcs/20181016-optimizer-unification.md" rel="noopener ugc nofollow" target="_blank"> TensorFlow 2.0:优化器统一</a> (2018)，TensorFlow GitHub</p><p id="7f7d" class="pw-post-body-paragraph lr ls iq lt b lu mp jr lw lx mq ju lz ma ne mc md me nf mg mh mi ng mk ml mm ij bi translated">[5] <a class="ae nd" href="https://www.tensorflow.org/community/roadmap" rel="noopener ugc nofollow" target="_blank">路线图</a> (2019)，TensorFlow.org</p></div></div>    
</body>
</html>