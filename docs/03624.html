<html>
<head>
<title>Unsupervised Extractive Summarization: A Comparative Study</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">无监督抽取摘要:一项比较研究</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/unsupervised-extractive-summarization-a-comparative-study-ca6ac2181d54?source=collection_archive---------7-----------------------#2019-06-09">https://towardsdatascience.com/unsupervised-extractive-summarization-a-comparative-study-ca6ac2181d54?source=collection_archive---------7-----------------------#2019-06-09</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="3ecf" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">Laurent El Ghaoui 和 Tanya Roosta。</h2></div><p id="9b2e" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi lc translated"><span class="l ld le lf bm lg lh li lj lk di"> T </span>他的文章涉及摘要，目标是提取几个句子，很好地概括一个给定的文档或一组文档。有监督的方法寻求学习基于大量的例子提取哪些句子；它们在实践中的应用和部署可能具有挑战性，因为它们需要大型、高质量的训练集。无监督的方法不需要任何训练集，并且仅与语料库一起工作以进行总结。在这里，我们探索如何非监督的方法可以与最先进的，监督提取摘要方法竞争。</p></div><div class="ab cl ll lm hu ln" role="separator"><span class="lo bw bk lp lq lr"/><span class="lo bw bk lp lq lr"/><span class="lo bw bk lp lq"/></div><div class="ij ik il im in"><p id="f460" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi lc translated"><span class="l ld le lf bm lg lh li lj lk di"> B </span> <strong class="ki ir">背景。</strong>抽取方法通过直接从源文本中选择重要的现有单词、短语或句子的子集来生成摘要。关于这个主题有大量的科学文献；最近的调查有(<a class="ae kf" href="https://hal.archives-ouvertes.fr/hal-00782442/document" rel="noopener ugc nofollow" target="_blank">萨基奥<em class="ls">等人</em>，2016 </a>，<a class="ae kf" href="https://link.springer.com/article/10.1007/s10462-016-9475-9" rel="noopener ugc nofollow" target="_blank">甘比尔<em class="ls">等人，</em> 2017 </a>，<a class="ae kf" href="https://arxiv.org/abs/1904.00688" rel="noopener ugc nofollow" target="_blank">白羊座<em class="ls">等人</em>，2019 </a>，<a class="ae kf" href="https://arxiv.org/pdf/1905.05044.pdf" rel="noopener ugc nofollow" target="_blank">帕帕吉安诺普卢<em class="ls">等人，</em> 2019 </a>)。</p><p id="61a9" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated">抽象概括可以与抽象概括形成对比，抽象概括与抽象概括的不同之处在于它试图从零开始生成新的句子，而不是从源文档中提取句子。把提取摘要想象成一支荧光笔，把抽象摘要想象成一个人类作家。抽象方法通常更难开发，因为它们需要高性能的自然语言生成技术，这本身就是一个活跃的研究领域，参见例如(<a class="ae kf" href="https://arxiv.org/abs/1905.01975" rel="noopener ugc nofollow" target="_blank"> Boutkan <em class="ls">等人，</em>2019</a>；<a class="ae kf" href="https://arxiv.org/abs/1611.03382" rel="noopener ugc nofollow" target="_blank">曾<em class="ls">等，</em> 2019 </a> <em class="ls"> ) </em>及其引用文献。最近还提出了结合抽取和抽象方法的混合策略，例如参见(<a class="ae kf" href="https://arxiv.org/abs/1904.04428" rel="noopener ugc nofollow" target="_blank">彭<em class="ls">等</em>)。，2019 </a>)。</p><p id="786e" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated">迄今为止，最先进的有监督的纯提取摘要技术依赖于神经网络体系结构；summary runner(<a class="ae kf" href="https://www.aaai.org/ocs/index.php/AAAI/AAAI17/paper/viewPaper/14636" rel="noopener ugc nofollow" target="_blank">Nallapati<em class="ls">et al .</em>，2018 </a> <em class="ls"> ) </em>它采用了一种“递归神经网络”，是该类别的最佳模型代表之一。</p><p id="05e9" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated">如(<a class="ae kf" href="https://arxiv.org/abs/1804.11283'" rel="noopener ugc nofollow" target="_blank">格鲁斯基<em class="ls">等人</em>所述。，2018 </a>)在新闻数据集上，非常简单的(无监督的)基线，比如选取一篇新闻文章的前几个句子，仍然能够击败这些高级的监督模型。这可能是通常用于评估的数据集的一个产物:新闻文章倾向于以这样一种方式写作，即前几个句子给出文章的主旨，这在新闻编辑室的说法中被称为“导语”；但这也指出了一个事实，即无人监管的方法仍有可能战胜有人监管的方法。</p><p id="703f" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated">先前在无监督提取摘要方面的工作集中在统计的、基于图的和基于优化的方法上。统计方法(<a class="ae kf" href="https://hal.archives-ouvertes.fr/hal-00782442/document" rel="noopener ugc nofollow" target="_blank"> Saggio <em class="ls"> et al. </em>，2016 </a>)以 TF-IDF 评分等简单统计为核心。基于图的方法(<a class="ae kf" href="https://arxiv.org/abs/1602.03606" rel="noopener ugc nofollow" target="_blank"> Barrios et al .，2016 </a>)将文本表示为链接句子的网络，并使用基于图的排序方法生成摘要；基于优化的方法(<a class="ae kf" href="https://arxiv.org/abs/1603.08887" rel="noopener ugc nofollow" target="_blank"> Durrett et al .，2016 </a>)使用稀疏优化、整数线性规划和约束优化等技术。</p></div><div class="ab cl ll lm hu ln" role="separator"><span class="lo bw bk lp lq lr"/><span class="lo bw bk lp lq lr"/><span class="lo bw bk lp lq"/></div><div class="ij ik il im in"><p id="eed2" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi lc translated"><span class="l ld le lf bm lg lh li lj lk di">D</span>T20】数据集合。为了比较摘要算法，最好有包含“黄金”或参考摘要的数据集。在我们的比较中，我们使用了标准和不太标准的数据集。</p><p id="6644" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated">数据集<em class="ls"> CNN </em>和<em class="ls">每日邮报</em> (DM)，在<a class="ae kf" href="https://cs.nyu.edu/~kcho/DMQA/" rel="noopener ugc nofollow" target="_blank">这里</a>可用，都包含新闻文章，通常有 1 或 2 页长，通常只有几个句子长的“黄金”摘要是手工编写的。</p><p id="2f07" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated">对于这些标准数据集，我们开源了<a class="ae kf" href="https://github.com/SumUpAnalytics/goldsum" rel="noopener ugc nofollow" target="_blank">这里</a>两个有用的新数据集，因为它们包含更长的文档:</p><ul class=""><li id="b5e9" class="lt lu iq ki b kj kk km kn kp lv kt lw kx lx lb ly lz ma mb bi translated"><em class="ls"> 2019 金融展望</em> (FO)数据集包含来自多家大型金融机构的 10 份公开发布的金融报告。每份报告从 10 页到 144 页不等，平均长度为 33 页。没有黄金总结<em class="ls">本身</em>。我们选择将黄金摘要定义为句子的集合，或句子的一部分，在内容中以粗体显示；或者，在内容中突出显示为插页的任何句子。</li><li id="cb85" class="lt lu iq ki b kj mc km md kp me kt mf kx mg lb ly lz ma mb bi translated"><em class="ls">古典文学书籍(CL) </em>数据集包含 11 本英文古典书籍，范围从 53 页到 1139 页，中值长度为 198 页。这本书每章的黄金摘要通常有 20 页长，从<a class="ae kf" href="http://wikisum.com/w/Main_Page" rel="noopener ugc nofollow" target="_blank"> WikiSummary </a>中获取。</li></ul></div><div class="ab cl ll lm hu ln" role="separator"><span class="lo bw bk lp lq lr"/><span class="lo bw bk lp lq lr"/><span class="lo bw bk lp lq"/></div><div class="ij ik il im in"><p id="2211" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi lc translated"><span class="l ld le lf bm lg lh li lj lk di"> E </span>摘要领域中使用的评估指标通常基于所谓的<a class="ae kf" href="https://www.aclweb.org/anthology/W04-1013" rel="noopener ugc nofollow" target="_blank"> ROUGE scores </a>，其测量提取的句子与其参考对应物之间的词汇重叠，例如，与参考摘要共享的字数。许多作者注意到这种纯词汇测量的缺点，特别是当参考文献摘要使用的语言在意义上相似，但在词的选择上不同。这促使研究人员提出更多基于语义的方法，主要是为了更好地处理同义词。</p><p id="8eb6" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated">(<a class="ae kf" href="https://aclweb.org/anthology/D15-1222" rel="noopener ugc nofollow" target="_blank"> Ng <em class="ls"> et al. </em>，2015 </a>)的论文通过所谓的<a class="ae kf" href="https://openreview.net/forum?id=SyK00v5xx" rel="noopener ugc nofollow" target="_blank">句子嵌入</a>来测量提取的句子和参考摘要之间的相似性，从而解决同义性问题；其他方法，如 ROUGE 2.0 基于固定的同义词列表和/或主题的使用。</p></div><div class="ab cl ll lm hu ln" role="separator"><span class="lo bw bk lp lq lr"/><span class="lo bw bk lp lq lr"/><span class="lo bw bk lp lq"/></div><div class="ij ik il im in"><p id="fe19" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi lc translated"><span class="l ld le lf bm lg lh li lj lk di">R</span>T22】结果。我们比较了四种不同的方法:</p><ul class=""><li id="acb2" class="lt lu iq ki b kj kk km kn kp lv kt lw kx lx lb ly lz ma mb bi translated"><a class="ae kf" href="https://arxiv.org/pdf/1804.11283.pdf" rel="noopener ugc nofollow" target="_blank"><em class="ls">Lede-3</em></a><em class="ls">:</em>使用前 3 个句子的简单基线。</li><li id="c5fd" class="lt lu iq ki b kj mc km md kp me kt mf kx mg lb ly lz ma mb bi translated"><a class="ae kf" href="https://www.aclweb.org/anthology/W04-3252" rel="noopener ugc nofollow" target="_blank"> <em class="ls">文本排名</em> </a> <em class="ls"> : </em>一种基于图的无监督方法。</li><li id="4bf5" class="lt lu iq ki b kj mc km md kp me kt mf kx mg lb ly lz ma mb bi translated"><a class="ae kf" href="https://www.aaai.org/ocs/index.php/AAAI/AAAI17/paper/viewPaper/14636" rel="noopener ugc nofollow" target="_blank"><em class="ls">sum runner</em></a><em class="ls">:</em>上面提到的有监督的提取摘要神经网络算法。</li><li id="c12e" class="lt lu iq ki b kj mc km md kp me kt mf kx mg lb ly lz ma mb bi translated"><a class="ae kf" href="https://www.sumup.ai/#/nucleus" rel="noopener ugc nofollow" target="_blank"><em class="ls">Nucleus</em></a><em class="ls">:</em>是指<a class="ae kf" href="https://www.sumup.ai" rel="noopener ugc nofollow" target="_blank"> sumup.ai </a>开发并商业化的专有文本包中的无监督的、提取的摘要器。</li></ul><p id="b35e" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated">下表显示了与词汇模糊度量相对应的分数，显示了 95%的置信区间。(所示的度量对应于召回和精度测量的调和平均值；它不应与分类中典型的 F1 分数相混淆；对于汇总重叠度量，这些数字通常要低得多。)</p><figure class="mi mj mk ml gt mm gh gi paragraph-image"><div class="gh gi mh"><img src="../Images/5a87199b7389eb0b1bd708fd4d21927d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1182/format:webp/1*4PFWVhdn1-AoTvtSugJKyw.png"/></div><figcaption class="mp mq gj gh gi mr ms bd b be z dk">Average performance (ROUGE-1 F score) for four extractive summarization methods evaluated on three kinds data sets: News (averaged over CNN and Daily Mail datasets), reports on 2019 Financial Outlooks and classical literature books.</figcaption></figure><p id="234f" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated">我们观察到，当数据包含较短的文档(CNN 和 DM，<em class="ls">即</em> news)时，SummaRunner 似乎更受青睐；但是在这种情况下，简单基线(Lede-3)几乎做得一样好。面对更长的文档，如报告和文献，基线和基于图表的方法都被其他两种模型所主导，相差甚远。在不同的数据集上，非监督方法 Nucleus 与复杂的监督模型不相上下。</p><p id="98ce" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated">其他词汇度量，如 ROUGE-*，以及测量，如精度、召回率等。，或使用语义胭脂度量，指向相同的结论。</p></div></div>    
</body>
</html>