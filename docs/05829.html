<html>
<head>
<title>Understanding the Different Types of Machine Learning Models</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">了解不同类型的机器学习模型</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/understanding-the-different-types-of-machine-learning-models-9c47350bb68a?source=collection_archive---------8-----------------------#2019-08-25">https://towardsdatascience.com/understanding-the-different-types-of-machine-learning-models-9c47350bb68a?source=collection_archive---------8-----------------------#2019-08-25</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="3c9f" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">监督、半监督和非监督机器学习方法</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/4b146ae40bb16f9be89036a6809bea20.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*-NT0owBMakmZ7G_a"/></div></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk">Photo by <a class="ae ky" href="https://unsplash.com/@franckinjapan?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Franck V.</a> on <a class="ae ky" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><h1 id="e8ae" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">概观</h1><p id="5178" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">在机器学习领域，有三种主要类型的任务:监督的、半监督的和无监督的。</p><p id="5f59" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">这些类型之间的主要区别在于<strong class="lt iu">地面实况</strong>数据的可用性水平，即对于给定的输入，模型的输出应该是什么的先验知识。</p><p id="7f56" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated"><strong class="lt iu">监督学习</strong>旨在学习一个函数，在给定数据样本和期望输出的情况下，近似一个将输入映射到输出的函数。</p><p id="941c" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated"><strong class="lt iu">半监督学习</strong>旨在利用从少量已标记数据点学习到的知识来标记未标记数据点。</p><p id="b5ae" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated"><strong class="lt iu">无监督学习</strong>没有(或不需要)任何标记输出，所以它的目标是推断一组数据点中存在的自然结构。</p></div><div class="ab cl ms mt hx mu" role="separator"><span class="mv bw bk mw mx my"/><span class="mv bw bk mw mx my"/><span class="mv bw bk mw mx"/></div><div class="im in io ip iq"><h1 id="ac02" class="kz la it bd lb lc mz le lf lg na li lj jz nb ka ll kc nc kd ln kf nd kg lp lq bi translated">监督学习</h1><blockquote class="ne"><p id="5a21" class="nf ng it bd nh ni nj nk nl nm nn mm dk translated">监督学习模型将输入映射到输出。</p></blockquote><h2 id="7ae0" class="no la it bd lb np nq dn lf nr ns dp lj ma nt nu ll me nv nw ln mi nx ny lp nz bi translated">概观</h2><p id="8804" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">当我们想要将输入映射到输出标签时，监督学习通常在<strong class="lt iu">分类</strong>的上下文中完成，或者当我们想要将输入映射到连续输出时，监督学习通常在<strong class="lt iu">回归</strong>的上下文中完成。监督学习中的常见算法包括逻辑回归、朴素贝叶斯、支持向量机、人工神经网络和随机森林。在回归和分类中，目标是在输入数据中找到特定的关系或结构，使我们能够有效地产生正确的输出数据。</p><p id="001e" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">请注意,“正确的”输出完全是由训练数据决定的，因此，虽然我们确实有一个我们的模型将假设为正确的基本事实，但这并不是说数据标签在现实世界中总是正确的。嘈杂或不正确的数据标签将明显降低模型的有效性。</p><h2 id="3156" class="no la it bd lb np oa dn lf nr ob dp lj ma oc nu ll me od nw ln mi oe ny lp nz bi translated"><strong class="ak">复杂性</strong></h2><p id="62f8" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">模型复杂性指的是您试图学习的函数的复杂性，类似于多项式的次数。模型复杂性的适当级别通常由训练数据的性质决定。</p><p id="d811" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">如果您有少量的数据，或者如果您的数据没有均匀地分布在不同的可能场景中，那么您应该选择低复杂度的模型。这是因为如果在少量数据点上使用，高复杂性模型会<strong class="lt iu">过度拟合</strong>。</p><p id="52ba" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">过度拟合指的是学习一个非常适合你的训练数据的函数，但不<strong class="lt iu">将</strong>推广到其他数据点——换句话说，你严格地学习产生你的训练数据，而没有学习导致这个输出的数据中的实际趋势或结构。想象一下试图拟合两点之间的曲线。理论上，你可以使用任何次数的函数，但在实践中，你会吝啬地增加复杂性，并使用线性函数。</p><h2 id="3d7e" class="no la it bd lb np oa dn lf nr ob dp lj ma oc nu ll me od nw ln mi oe ny lp nz bi translated">偏差-方差权衡</h2><p id="6078" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">偏差-方差权衡也与模型泛化有关。在任何模型中，在作为恒定误差项的<strong class="lt iu">偏差</strong>和作为不同数据集之间误差变化量的<strong class="lt iu">方差</strong>之间存在平衡。因此，高偏差和低方差的模型在 20%的时间里都是错误的，而低偏差和高方差的模型在 5%-50%的时间里都是错误的，这取决于用来训练它的数据。</p><p id="091b" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">请注意，偏差和方差通常彼此反向移动；增加偏差通常会导致较低的方差，反之亦然。在制作模型时，您的具体问题和数据的性质应该允许您在偏差-方差谱的哪个位置做出明智的决定。</p><p id="0df6" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">通常，增加偏差(和减少方差)会导致模型具有相对保证的基线性能水平，这在某些任务中可能是至关重要的。此外，为了生成具有良好泛化能力的模型，模型的方差应该随训练数据的大小和复杂程度而变化。小而简单的数据集通常应该用低方差模型来学习，而大而复杂的数据集通常需要高方差模型来全面学习数据的结构。</p></div><div class="ab cl ms mt hx mu" role="separator"><span class="mv bw bk mw mx my"/><span class="mv bw bk mw mx my"/><span class="mv bw bk mw mx"/></div><div class="im in io ip iq"><h1 id="1deb" class="kz la it bd lb lc mz le lf lg na li lj jz nb ka ll kc nc kd ln kf nd kg lp lq bi translated">半监督学习</h1><blockquote class="ne"><p id="ca56" class="nf ng it bd nh ni nj nk nl nm nn mm dk translated">利用未标记和标记的数据点进行学习。</p></blockquote><h2 id="9597" class="no la it bd lb np nq dn lf nr ns dp lj ma nt nu ll me nv nw ln mi nx ny lp nz bi translated">概观</h2><p id="6844" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">半监督学习介于监督学习和非监督学习之间。半监督模型旨在使用少量已标记的训练数据以及大量未标记的训练数据。这种情况经常发生在现实世界中，在现实世界中，标注数据非常昂贵，并且/或者您有稳定的数据流。</p><p id="98bd" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">例如，如果我们试图在社交网络中检测不适当的消息，就没有办法获得每条消息的手工标记信息，因为消息太多了，成本太高。相反，我们可以手动标记其中的一个子集，并利用半监督技术来使用这个小的标记数据集来帮助我们理解其余的消息内容。</p><p id="f7a6" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">一些常见的半监督方法是直推式支持向量机和基于图的方法，如标签传播。</p><h2 id="9e45" class="no la it bd lb np oa dn lf nr ob dp lj ma oc nu ll me od nw ln mi oe ny lp nz bi translated">假设</h2><p id="e289" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">半监督方法必须对数据做出<em class="of">一些</em>假设，以证明使用一小组标记数据来对未标记数据点做出结论是合理的。这些可以分为三类。</p><p id="3320" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">第一个是<strong class="lt iu">连续性假设</strong>。这假设彼此“接近”的数据点更有可能具有共同的标签。</p><p id="3f86" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">第二个是<strong class="lt iu">集群假设</strong>。这假设数据自然地形成离散的聚类，并且同一聚类中的点更有可能共享一个标签。</p><p id="0723" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">第三个是<strong class="lt iu">流形假设</strong>。这假设数据大致位于比输入空间更低维度的空间(或流形)中。当一个不可观察或难以观察的具有少量参数的系统产生高维可观察输出时，这种情况是相关的。</p></div><div class="ab cl ms mt hx mu" role="separator"><span class="mv bw bk mw mx my"/><span class="mv bw bk mw mx my"/><span class="mv bw bk mw mx"/></div><div class="im in io ip iq"><h1 id="c16e" class="kz la it bd lb lc mz le lf lg na li lj jz nb ka ll kc nc kd ln kf nd kg lp lq bi translated">无监督学习</h1><blockquote class="ne"><p id="50bd" class="nf ng it bd nh ni nj nk nl nm nn mm dk translated">无监督模型发现数据中的固有模式。</p></blockquote><h2 id="bee6" class="no la it bd lb np nq dn lf nr ns dp lj ma nt nu ll me nv nw ln mi nx ny lp nz bi translated">概观</h2><p id="6a7a" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">无监督学习中最常见的任务是聚类、表示学习和密度估计。在所有这些情况下，我们希望了解数据的内在结构，而不使用显式提供的标签。一些常见的算法包括 k 均值聚类、主成分分析和自动编码器。由于没有提供标签，所以在大多数无监督学习方法中，没有特定的方法来比较模型性能。</p><h2 id="fce3" class="no la it bd lb np oa dn lf nr ob dp lj ma oc nu ll me od nw ln mi oe ny lp nz bi translated">探索性数据分析</h2><p id="112f" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">无监督学习在探索性分析中非常有用，因为它可以自动识别数据中的结构。例如，如果分析师试图对消费者进行细分，无监督聚类方法将是他们分析的一个很好的起点。在人类不可能或不切实际地提出数据趋势的情况下，无监督学习可以提供最初的见解，然后可以用于测试个人假设。</p><h2 id="48b7" class="no la it bd lb np oa dn lf nr ob dp lj ma oc nu ll me od nw ln mi oe ny lp nz bi translated">降维</h2><p id="cf07" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">降维是指使用较少的列或特征来表示数据的方法，可以通过无监督的方法来实现。在<strong class="lt iu">表征学习</strong>中，我们希望学习个体特征之间的关系，允许我们使用与初始特征相关的潜在特征来表示我们的数据。这种稀疏潜在结构通常使用比我们开始时少得多的特征来表示，因此它可以使进一步的数据处理不那么密集，并且可以消除冗余特征。在其他情况下，降维可用于将数据从一种模态转换为另一种模态。例如，可以使用循环自动编码器将序列转换为固定长度的表示形式。</p></div></div>    
</body>
</html>