<html>
<head>
<title>Searching for ET using AI on GCP</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">在 GCP 上用人工智能搜索外星人</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/searching-for-et-using-ai-on-gcp-b45b07ba5b6?source=collection_archive---------26-----------------------#2019-07-09">https://towardsdatascience.com/searching-for-et-using-ai-on-gcp-b45b07ba5b6?source=collection_archive---------26-----------------------#2019-07-09</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><figure class="ip iq gp gr ir is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi io"><img src="../Images/24c39699d5e78fd26fe023424f165541.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*23ezUVvzbJ_mTWK5ulzO7Q.jpeg"/></div></div><figcaption class="iz ja gj gh gi jb jc bd b be z dk">Photo by <a class="ae jd" href="https://unsplash.com/@semajjat?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank">Austin Johnson</a> on <a class="ae jd" href="https://unsplash.com/search/photos/aliens?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><div class=""/><p id="1a19" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><em class="lb">一个使用 SETI 开放数据的项目</em></p><p id="16d1" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">他们说学习数据科学的最好方法是创造一些东西。</p><p id="2272" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">一旦你使用教科书、博客文章，当然还有 MOOCs(大规模开放在线课程)覆盖了数据处理、编码和统计的基础知识，接下来要做的就是做一个你感兴趣的项目。通过这种方式，您可以使用您所学的各种工具和技术，另外，您可以以一种现实而有意义的方式进行数据科学研究，因为您必须实际找到数据，为分析做好准备，最重要的是，您必须提出要问的问题。</p><p id="9be5" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">对我来说，这就是我最近花了几年时间学习无数在线课程的地方。我已经达到了 MOOC 疲劳的暂时状态，我想做一些长期而深入的工作。我开始四处寻找有趣的数据，最终偶然发现了来自<a class="ae jd" href="https://www.seti.org/" rel="noopener ugc nofollow" target="_blank"> SETI 研究所</a>(搜寻外星智能)的各种文件和 GitHub 知识库。</p><p id="7f48" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">最初，看起来我需要的所有数据和代码都是可用的，包括 IBM 托管的一些大数据集，加上一些分析代码。然后我意识到，相当一部分是来自已经停止的项目，留给我许多零碎的东西，但没有具体的东西。</p><p id="f2d1" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">令人欣慰的是，在收到几封邮件后，SETI 的人热心地帮助我，并明确表示，让“公民科学家”参与进来是他们希望在未来做得更多的事情。我加入了他们的 Slack 频道，打了一个 Skype 电话，并获得了几个额外数据集的链接。这是一种惊人的、令人耳目一新的接触数据爱好者的方法，我以前从未遇到过。</p><p id="93d6" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">满怀热情的我接着回顾了 SETI 过去和现在的所有公众参与项目，以便找到我的项目想法。</p><h1 id="1aed" class="lc ld jg bd le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz bi translated"><strong class="ak"> SETI 和公民科学</strong></h1><p id="f4bf" class="pw-post-body-paragraph kd ke jg kf b kg ma ki kj kk mb km kn ko mc kq kr ks md ku kv kw me ky kz la ij bi translated">2016 年 1 月，伯克利大学伯克利 SETI 研究中心启动了一项名为<a class="ae jd" href="https://en.wikipedia.org/wiki/Breakthrough_Listen" rel="noopener ugc nofollow" target="_blank">突破倾听</a>的计划，被描述为“<em class="lb">迄今为止最全面的外星通讯搜索</em>”。无线电数据目前由西弗吉尼亚州的<a class="ae jd" href="https://greenbankobservatory.org/" rel="noopener ugc nofollow" target="_blank">格林班克天文台</a>和新南威尔士的<a class="ae jd" href="https://en.wikipedia.org/wiki/Parkes_Observatory" rel="noopener ugc nofollow" target="_blank">巴夏礼天文台</a>收集，光学数据由加利福尼亚州的<a class="ae jd" href="https://en.wikipedia.org/wiki/Automated_Planet_Finder" rel="noopener ugc nofollow" target="_blank">自动行星探测器</a>收集。</p><p id="a42f" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">为了吸引公众，Breakthrough listen 的主要方法是一种名为<a class="ae jd" href="https://setiathome.berkeley.edu/" rel="noopener ugc nofollow" target="_blank"> SETI@Home </a>的东西，可以下载并安装一个程序，空闲时可以用你的电脑下载数据包并对其进行各种分析。</p><p id="b717" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">除此之外，他们还共享了一些启动脚本和一些数据。脚本可以在 GitHub <a class="ae jd" href="https://github.com/UCBerkeleySETI/breakthrough/tree/master/GBT" rel="noopener ugc nofollow" target="_blank">这里</a>找到，数据存档可以在<a class="ae jd" href="http://breakthroughinitiatives.org/opendatasearch" rel="noopener ugc nofollow" target="_blank">这里</a>找到(虽然大部分是“基带”格式，与我一直使用的“滤波器库”格式相比，这是一种更原始的格式)。请注意，来自自动行星探测器的光学数据也是一种不同的格式，称为“FITS”文件。</p><p id="d1d0" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">SETI 让公众参与的第二个举措是 2016 年 9 月启动的<a class="ae jd" href="https://developer.ibm.com/clouddataservices/2016/09/29/seti-data-on-ibm-cloud/" rel="noopener ugc nofollow" target="_blank"> SETI@IBMCloud </a>项目。这为公众提供了通过 IBM 云平台访问大量数据的机会。这个项目也附带了一个优秀的启动脚本集合，这个集合仍然可以在 GitHub <a class="ae jd" href="https://github.com/ibm-watson-data-lab/seti_at_ibm" rel="noopener ugc nofollow" target="_blank">这里</a>找到。不幸的是，在编写本报告时，该项目被搁置，数据无法访问。</p><h1 id="db77" class="lc ld jg bd le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz bi translated">SETI 对深度学习的运用</h1><p id="37cd" class="pw-post-body-paragraph kd ke jg kf b kg ma ki kj kk mb km kn ko mc kq kr ks md ku kv kw me ky kz la ij bi translated">SETI 还有一些其他的在线数据来源。2017 年夏天，他们举办了一场机器学习挑战，向参与者提供了各种大小的模拟数据集以及盲测集。获胜团队使用卷积神经网络实现了 94.7%的分类准确率。这项挑战的目的是尝试一种新的信号检测方法，即超越传统的信号分析方法，在将信号转换为<a class="ae jd" href="https://en.wikipedia.org/wiki/Spectrogram" rel="noopener ugc nofollow" target="_blank">光谱图</a>后，将问题转化为图像分类任务。</p><figure class="mg mh mi mj gt is gh gi paragraph-image"><div class="gh gi mf"><img src="../Images/f96297617056f215d12ad910117fffd5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1024/format:webp/1*zVU76JPnFbIHwwxvb2u0ZA.png"/></div><figcaption class="iz ja gj gh gi jb jc bd b be z dk">A squiggly signal in simualated SETI data</figcaption></figure><p id="703d" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">主要训练数据已被删除，但数据的“基本”、“小型”和“中型”版本仍在<a class="ae jd" href="https://github.com/setiQuest/ML4SETI" rel="noopener ugc nofollow" target="_blank"> GitHub 页面</a>上。这些信号的详细性质以及更详细的挑战描述可以在<a class="ae jd" href="https://medium.com/ibm-watson-data-lab/using-artificial-intelligence-to-search-for-extraterrestrial-intelligence-ec19169e01af" rel="noopener">这里</a>找到。</p><p id="0946" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">注意，许多由 SETI 编写的托管在 Github 上的脚本使用了一个名为<strong class="kf jh"> ibmseti </strong>的非标准 Python 包。</p><p id="a75d" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">SETI 在机器学习方面的工作最近成为头条新闻，当时一种深度学习算法被应用于来自绿色银行望远镜的大量数据，这些数据与一个名为<a class="ae jd" href="https://www.seti.org/frb-121102-radio-calling-cards-distant-civilization" rel="noopener ugc nofollow" target="_blank"> FRB 121102 </a>的射电源有关。被认为来自 30 亿光年外的一个矮星系，一些神秘的信号被发现，让媒体陷入外星人引发的狂热。然而，这些信号的一些细节，如它们的极化，表明它们已经通过了一个极其强大的磁场，导致了它们来自一颗中子星的假设，也许是在一个大质量黑洞附近。</p><p id="4001" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">进一步的细节可以在张，格里等人的论文“快速无线电突发 121102 脉冲检测和周期性:机器学习方法”中找到<em class="lb">天体物理学报</em> 866.2 (2018): 149。</p><p id="e388" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这项工作的所有数据和相应论文的链接可以在<a class="ae jd" href="http://seti.berkeley.edu/frb-machine/" rel="noopener ugc nofollow" target="_blank">这里</a>找到。</p><h1 id="59fc" class="lc ld jg bd le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz bi translated"><strong class="ak">ABACAD 寻找 ET 的方法</strong></h1><p id="1ac7" class="pw-post-body-paragraph kd ke jg kf b kg ma ki kj kk mb km kn ko mc kq kr ks md ku kv kw me ky kz la ij bi translated">一些 SETI 数据寻找非常快速的信号，即在很宽的频率范围内存在很短时间的信号。来自上述快速射电爆发论文的数据使用了这样的数据。另一种 SETI 数据被用来做相反的事情，即信号在很窄的频率窗口在较长的时间帧。这类数据从一开始就让我更感兴趣，因为它似乎更有可能包含任何有目的的外星信号。</p><p id="5f11" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">然后我看到了下面这篇文章:对智慧生命的突破性监听搜索:对 692 颗邻近恒星的 1.1-1.9 GHz 观测。<em class="lb">天体物理学报</em> 849.2 (2017): 104。</p><p id="9cb8" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在其中，使用非机器学习技术分析了来自 692 颗恒星的此类数据，其中许多基础数据是共享的(从现在起我将把这项工作称为“突破 692”论文/项目)。使用的一种技术被称为“ABACAD”方法。思路如下:从目标恒星(第一个“A”)收集数据，然后将望远镜移动到不同的目标(“B”)。然后，回到 A，然后是另一个目标 C，再次回到 A，然后是最后一个不同的目标 d。这个想法是，如果信号来自主要目标恒星，它将出现在所有 3 A 扫描中。然而，如果一个信号来自陆地，它可能会在所有 6 次扫描中出现。</p><p id="add9" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这篇论文让我产生了将这些数据用于机器学习的想法。我找到了我的项目！</p><h1 id="0531" class="lc ld jg bd le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz bi translated"><strong class="ak">我的项目</strong></h1><p id="214e" class="pw-post-body-paragraph kd ke jg kf b kg ma ki kj kk mb km kn ko mc kq kr ks md ku kv kw me ky kz la ij bi translated">最初，我开始玩 2017 年 SETI 夏季机器学习挑战的模拟数据。起初我在本地这样做(即使用我的家用台式电脑)，然后很快转移到在<a class="ae jd" href="https://www.kaggle.com/" rel="noopener ugc nofollow" target="_blank"> Kaggle </a>上工作，这要感谢他们免费的数据托管和 GPU 支持。我创建了一个笔记本(在 Kaggle 上称为“内核”)，介绍了典型的 SETI 数据和 filterbank 文件格式，随后是一个使用深度学习区分不同类型模拟数据的笔记本(根据夏季挑战)。</p><p id="6d0e" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">然后，我转向突破性的 692 数据，并决定尝试使用云计算来实现这一点，因为我知道，在 ABACAD 搜索中生成的大量 filterbank 文件中翻腾将受益于云平台提供的缩放能力。不幸的是，我对这个主题知之甚少，所以我暂停了这个项目，直到我在 Coursera 上完成了出色的<a class="ae jd" href="https://www.coursera.org/specializations/gcp-data-machine-learning" rel="noopener ugc nofollow" target="_blank">谷歌云平台专业化数据工程。</a></p><p id="fb7d" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">一旦完成，我就开始在 GCP 数据实验室(谷歌的云版 Jupyter 笔记本)上整理代码。我把这个问题分成 4 个部分，</p><ol class=""><li id="b117" class="mk ml jg kf b kg kh kk kl ko mm ks mn kw mo la mp mq mr ms bi translated"><strong class="kf jh">创建谱图图像</strong>——将滤波器组数据转换成谱图图像文件</li><li id="44e4" class="mk ml jg kf b kg mt kk mu ko mv ks mw kw mx la mp mq mr ms bi translated"><strong class="kf jh">模拟数据</strong> —这必须与 ABACAD 搜索得出的数据类型相似，与夏季挑战赛的模拟数据截然不同</li><li id="790b" class="mk ml jg kf b kg mt kk mu ko mv ks mw kw mx la mp mq mr ms bi translated"><strong class="kf jh">构建深度学习模型</strong> —使用模拟数据创建和评估模型</li><li id="8803" class="mk ml jg kf b kg mt kk mu ko mv ks mw kw mx la mp mq mr ms bi translated"><strong class="kf jh">从 ABACAD filterbank 文件中进行预测</strong> —使用模型发现信号，不仅仅是每个图像，还包括 ABACAD 扫描技术的背景</li></ol><h1 id="c44e" class="lc ld jg bd le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz bi translated"><strong class="ak">模拟数据</strong></h1><p id="8c91" class="pw-post-body-paragraph kd ke jg kf b kg ma ki kj kk mb km kn ko mc kq kr ks md ku kv kw me ky kz la ij bi translated">为了模拟数据，我想出了一些类别(部分基于夏季挑战类别，部分基于我在突破 692 结果中看到的)。这些是:<em class="lb">噪音、线条、断续线、抖动</em>和<em class="lb">曲线</em>。我试图确保信号水平和背景噪声水平的种类，以及像素的数量，与突破 692 项目中看到的数据种类相匹配。下面是每种方法的一些例子，</p><p id="87e8" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kf jh">线</strong></p><figure class="mg mh mi mj gt is gh gi paragraph-image"><div class="gh gi my"><img src="../Images/b8dd27f3bf1395780ac848982e28f8db.png" data-original-src="https://miro.medium.com/v2/resize:fit:1206/format:webp/1*_rwSAW-PrcyZ7o7W-ScYMQ.png"/></div></figure><p id="d051" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kf jh">维布尔</strong></p><figure class="mg mh mi mj gt is gh gi paragraph-image"><div class="gh gi my"><img src="../Images/d6ffd760d8f42a5111ee0ff7ceff35bc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1206/format:webp/1*tYIfjf4xZZfPZDrtHDA0oA.png"/></div></figure><p id="23bb" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kf jh">斩线</strong></p><figure class="mg mh mi mj gt is gh gi paragraph-image"><div class="gh gi my"><img src="../Images/37af60c368c9513d83a812b90f74f728.png" data-original-src="https://miro.medium.com/v2/resize:fit:1206/format:webp/1*kkwpVK1wNgnv0I8YZDvU3A.png"/></div></figure><p id="9ef6" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kf jh">曲线</strong></p><figure class="mg mh mi mj gt is gh gi paragraph-image"><div class="gh gi my"><img src="../Images/fd2aaae36dd13f07c78f8641d01a0afc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1206/format:webp/1*xZL5y0XslPB_gcUgqyYUsg.png"/></div></figure><p id="dbc8" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kf jh">噪音</strong></p><figure class="mg mh mi mj gt is gh gi paragraph-image"><div class="gh gi my"><img src="../Images/1cb329f713de0b95637bc29bce20466d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1206/format:webp/1*-dSHISSnWHXB2mZ0lqihBA.png"/></div></figure><p id="95b9" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">该代码有一个变量列表，它可以取某个范围内的任何值。这些包括数值变量，例如背景噪声水平、信号强度、线的梯度、截断线中间隙的大小等。这些是每次随机选择的，允许批量创建每个图像类别的变体。还有一些更多的实验变量，如一个叫做“幽灵”的变量，其中信号的副本被复制到主信号的左侧和右侧。然而，我还没有探究它的影响。</p><h1 id="0401" class="lc ld jg bd le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz bi translated"><strong class="ak">构建深度学习模型</strong></h1><p id="df80" class="pw-post-body-paragraph kd ke jg kf b kg ma ki kj kk mb km kn ko mc kq kr ks md ku kv kw me ky kz la ij bi translated">对于这个项目的深度学习方面，我最初使用了 VGG19 和 InceptionNet 等预构建模型。然而，我后来得出结论，对于这个应用程序来说，这些可能过于复杂，所以最终使用 Keras 框架来构建一个简单的模型架构(受我读过的一些 Keras 博客帖子的启发)。我使用的模型总结如下:</p><pre class="mg mh mi mj gt mz na nb nc aw nd bi"><span id="d578" class="ne ld jg na b gy nf ng l nh ni">_________________________________________________________________<br/>Layer (type)                 Output Shape              Param #   <br/>=================================================================<br/>conv2d_1 (Conv2D)            (None, 188, 188, 32)      9632      <br/>_________________________________________________________________<br/>activation_1 (Activation)    (None, 188, 188, 32)      0         <br/>_________________________________________________________________<br/>max_pooling2d_1 (MaxPooling2 (None, 94, 94, 32)        0         <br/>_________________________________________________________________<br/>dropout_1 (Dropout)          (None, 94, 94, 32)        0         <br/>_________________________________________________________________<br/>conv2d_2 (Conv2D)            (None, 90, 90, 32)        25632     <br/>_________________________________________________________________<br/>activation_2 (Activation)    (None, 90, 90, 32)        0         <br/>_________________________________________________________________<br/>max_pooling2d_2 (MaxPooling2 (None, 45, 45, 32)        0         <br/>_________________________________________________________________<br/>dropout_2 (Dropout)          (None, 45, 45, 32)        0         <br/>_________________________________________________________________<br/>conv2d_3 (Conv2D)            (None, 43, 43, 64)        18496     <br/>_________________________________________________________________<br/>activation_3 (Activation)    (None, 43, 43, 64)        0         <br/>_________________________________________________________________<br/>max_pooling2d_3 (MaxPooling2 (None, 21, 21, 64)        0         <br/>_________________________________________________________________<br/>dropout_3 (Dropout)          (None, 21, 21, 64)        0         <br/>_________________________________________________________________<br/>flatten_1 (Flatten)          (None, 28224)             0         <br/>_________________________________________________________________<br/>dense_1 (Dense)              (None, 197)               5560325   <br/>_________________________________________________________________<br/>dropout_4 (Dropout)          (None, 197)               0         <br/>_________________________________________________________________<br/>dense_2 (Dense)              (None, 5)                 990</span></pre><p id="e16c" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">然后，我使用<a class="ae jd" rel="noopener" target="_blank" href="/a-look-at-gradient-descent-and-rmsprop-optimizers-f77d483ef08b"> RMSprop 优化器</a>对其进行了 100 多个时期的训练，给出了以下准确度和损耗图。</p><figure class="mg mh mi mj gt is gh gi paragraph-image"><div class="gh gi nj"><img src="../Images/7fda4a6007ddc642ad87e0f9128a29e4.png" data-original-src="https://miro.medium.com/v2/resize:fit:796/format:webp/1*k8vIXHpFCc2sSJiHRF9BgQ.png"/></div></figure><p id="77ac" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这实现了大约 84%的测试数据准确性。下面是测试阶段的混淆矩阵，</p><figure class="mg mh mi mj gt is gh gi paragraph-image"><div class="gh gi nk"><img src="../Images/edb3e2a80cd8a48545a3b9a91456a240.png" data-original-src="https://miro.medium.com/v2/resize:fit:804/format:webp/1*W_TdbgCix6Vbj3Stn4a58w.png"/></div></figure><h1 id="274b" class="lc ld jg bd le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz bi translated"><strong class="ak">单幅图像预测</strong></h1><p id="1974" class="pw-post-body-paragraph kd ke jg kf b kg ma ki kj kk mb km kn ko mc kq kr ks md ku kv kw me ky kz la ij bi translated">一旦模型被创建，我需要一些图像来测试。我从突破 692 论文里取了一些，看看模型给出了什么。下面是几张来自<a class="ae jd" href="https://en.wikipedia.org/wiki/Mu_Andromedae" rel="noopener ugc nofollow" target="_blank"> HIP4436 </a>的图片，第一张是噪点，</p><figure class="mg mh mi mj gt is gh gi paragraph-image"><div class="gh gi nl"><img src="../Images/340172f87f01dc5fdfda6ba5d8985106.png" data-original-src="https://miro.medium.com/v2/resize:fit:664/format:webp/1*IN0IDqeHp6cKjGBrcJ8vaw.png"/></div></figure><p id="0ca6" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这是模型的预测，</p><figure class="mg mh mi mj gt is gh gi paragraph-image"><div class="gh gi nm"><img src="../Images/5b77fe34b8d06687639cbcfc208b32aa.png" data-original-src="https://miro.medium.com/v2/resize:fit:844/format:webp/1*gOpjsyPLL7nm7PwskYWIgQ.png"/></div></figure><p id="5d41" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">如你所见，它正确地将其归类为噪声。接下来，有信号存在的图像，</p><figure class="mg mh mi mj gt is gh gi paragraph-image"><div class="gh gi nl"><img src="../Images/f631a563b064c57b82e2ce7fcc634225.png" data-original-src="https://miro.medium.com/v2/resize:fit:664/format:webp/1*KM6e5qxreX642xBMz7837Q.png"/></div></figure><p id="75e2" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这个预测，</p><figure class="mg mh mi mj gt is gh gi paragraph-image"><div class="gh gi nm"><img src="../Images/bce7c8ea84b4a1a7db1291c26af77b68.png" data-original-src="https://miro.medium.com/v2/resize:fit:844/format:webp/1*8YVkIQGb7XdK0C8JJC097w.png"/></div></figure><p id="1f53" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">“line”类是明显的赢家。</p><h1 id="01ea" class="lc ld jg bd le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz bi translated"><strong class="ak">根据 ABACAD 过滤器库文件进行预测</strong></h1><p id="95b1" class="pw-post-body-paragraph kd ke jg kf b kg ma ki kj kk mb km kn ko mc kq kr ks md ku kv kw me ky kz la ij bi translated">从 filterbank 文件中提取一部分并对其进行分类是很好的，但正如前面提到的，SETI 使用 ABACAD 搜索技术来决定目标是否是感兴趣的。为此，我编写了一个“评分函数”(我在代码中实际上称之为“外星人探测器”，因为这样听起来更酷)，对 6 幅图像进行预测，对应于 6 个 filterbank 文件的相同频率范围，然后应用一些简单的规则，通过分配点数来决定整体模式是否令人感兴趣。评分工作如下，</p><figure class="mg mh mi mj gt is gh gi paragraph-image"><div class="gh gi nn"><img src="../Images/8b0efbbcafa1628ee671d413fa87f991.png" data-original-src="https://miro.medium.com/v2/resize:fit:440/format:webp/1*ZDwASrfyehMp-uL0U6ePQA.png"/></div></figure><p id="61e1" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">例如，6 个“噪音”结果得零分。事实上，6 手任何一个相同的信号都不得分(例如线-线-线-线-线)。一个或多个 A 扫描中的一种信号类型与 B、C 和 D 扫描中的不同类型得到<em class="lb">一些</em>点，最大值分配给 3 A 扫描中的一种信号类型，B、C 和 D 为噪声(例如<em class="lb">wibble-noise-wibble-noise-wibble-noise</em>)。</p><p id="bc33" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这似乎工作得很好。例如，在 Breakthrough 692 论文中，使用非 ML 信号检测方法将以下标记为可能的候选者(HIP65352 ),</p><figure class="mg mh mi mj gt is gh gi paragraph-image"><div class="gh gi no"><img src="../Images/5d059ef49600539895a5a3a1038d8b88.png" data-original-src="https://miro.medium.com/v2/resize:fit:1134/format:webp/1*thBa-0LsZP1MYSZkF0iVgQ.png"/></div></figure><p id="1596" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">使用深度学习，这得到一个很低的分数，因为 B 扫描(倒数第二个)，你可以<em class="lb">仅仅</em>用眼睛看到有一条微弱的线存在，<em class="lb">被</em>检测到。</p><p id="499f" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">回到前面使用的 HIP4436 示例，我们有以下图像集合，</p><figure class="mg mh mi mj gt is gh gi paragraph-image"><div class="gh gi np"><img src="../Images/3c2fc6078636313b588612be35a68fe2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1138/format:webp/1*PMDZzPiMgs_nf1WL7vHl2A.png"/></div></figure><p id="b851" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">用深度学习模型给出以下预测:<em class="lb">‘线’，‘噪声’，‘线’，‘噪声’，‘线’，‘噪声’，</em>，如预期。这得到最高分。</p><h1 id="8998" class="lc ld jg bd le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz bi translated">新建数据</h1><p id="b869" class="pw-post-body-paragraph kd ke jg kf b kg ma ki kj kk mb km kn ko mc kq kr ks md ku kv kw me ky kz la ij bi translated">上面的例子使用了从突破 692 论文中共享的<a class="ae jd" href="https://seti.berkeley.edu/lband2017/landing.html" rel="noopener ugc nofollow" target="_blank">小数据文件。然而，SETI 向公众公开了大量未经处理的数据。分析单个目标所需的 x6 filterbank 文件高达令人瞠目的 100GB。我将这些文件用于 HIP4436，并将这 6 个文件中的前 3000 个频率片转换成 PNG 图像文件。</a></p><p id="5b6d" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这些然后通过深度学习模型发送，然后通过评分功能，最后结果被保存到 csv 文件中。对于如此少量的频率，这将产生一个微小且易于使用的文件，但如果处理整个滤波器组范围，产生的 csv 文件将有 50 万个条目(尽管您总是只能保存“命中”，这将少得多)。</p><p id="710b" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">为了将结果转换成更加“云友好”的格式，我测试了从结果中创建一个 BigQuery 数据库。这非常简单，并且可以作为处理管道的一部分来完成，然后允许感兴趣的团体搜索高分目标。举个例子，</p><p id="7ae9" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kf jh"><em class="lb">SELECT *<br/>FROM ` SETI _ results . SETI _ results _ table `<br/>其中分数&gt; 0 <br/>按分数排序 DESC </em> </strong></p><p id="b190" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">给出最高得分目标。</p><h1 id="073f" class="lc ld jg bd le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz bi translated"><strong class="ak">整体流程</strong></h1><p id="7c7e" class="pw-post-body-paragraph kd ke jg kf b kg ma ki kj kk mb km kn ko mc kq kr ks md ku kv kw me ky kz la ij bi translated">下图显示了如何将此流程放入一个简单的管道中，不同的流交错排列，以显示扫描完成后可以立即开始处理 A1 数据(在所有流完成并输入评分功能后，结果将与其他 5 个流合并)。</p><p id="cc84" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这些独立的流甚至可以由 6 个不同的 GCP 实例来处理，从而大大加快速度。</p><figure class="mg mh mi mj gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi nq"><img src="../Images/479fc5b0b4b8b7795b5595d7396ec8bc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Q4b4tM6Wc3xv17xdAi7jug.png"/></div></div></figure><h1 id="0e5d" class="lc ld jg bd le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz bi translated">时间就是金钱</h1><p id="a538" class="pw-post-body-paragraph kd ke jg kf b kg ma ki kj kk mb km kn ko mc kq kr ks md ku kv kw me ky kz la ij bi translated">据我所知，SETI 数据的一个问题似乎是它的剪切比例。单个 filterbank 文件是 17GB，我们每个目标处理 6 个。在每个单独图像的频率分辨率下，每个滤波器组生成 500，000 个图像。因此，每个目标都需要通过深度学习模型处理惊人的 300 万张图像。</p><p id="d20a" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我在一个 GCP 实例上测试了一些东西，具体来说，是一个带有 1 个 NVIDIA Tesla K80 GPU 的<strong class="kf jh"> n1-standard-8 </strong> (8 个 vCPUs，30 GB 内存)。利用这一点，我能够对每次扫描的 2999 幅图像做出预测，或者在大约 187 秒内总共 17，994 幅图像。基于此，300 万次预测需要大约 8 个小时。</p><p id="cafa" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们可以从下面的成本计算器中看到，如果我永久保留这个实例，成本将是每天 15 美元左右。因此，使用这种方法可以处理全套 6 个滤波器组文件，费用约为 5 美元。</p><figure class="mg mh mi mj gt is gh gi paragraph-image"><div class="gh gi nm"><img src="../Images/1e786fbcd6b8d265f89c0bbd40b087a7.png" data-original-src="https://miro.medium.com/v2/resize:fit:844/format:webp/1*rXXUNg3SfhFQ-YKicjEQoQ.png"/></div></figure><p id="19e0" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">因为这是云计算，如果可以承受更高的成本水平，这个价格可以降低以节省资金，或者分析一组 filterbank 文件的时间可以减少(甚至大大减少)。</p><h1 id="e5eb" class="lc ld jg bd le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz bi translated"><strong class="ak">下一步去哪里？</strong></h1><p id="d7e0" class="pw-post-body-paragraph kd ke jg kf b kg ma ki kj kk mb km kn ko mc kq kr ks md ku kv kw me ky kz la ij bi translated">由于我不是 SETI 的专业研究人员，毫无疑问，上述所有方面都可以改进，包括:</p><ol class=""><li id="77ae" class="mk ml jg kf b kg kh kk kl ko mm ks mn kw mo la mp mq mr ms bi translated"><strong class="kf jh">数据模拟</strong> —改善信号类别(信号形状、信号电平、信号噪声等)。在给定图像中包括不止一个信号(例如几行而不是一行)。我最初生成了一个名为“brightpixel”的图像类，用于夏季 ML 挑战赛。然而，这似乎破坏了我的模型。这可以进一步调查</li><li id="bc3e" class="mk ml jg kf b kg mt kk mu ko mv ks mw kw mx la mp mq mr ms bi translated"><strong class="kf jh">深度学习模型</strong> —尝试不同的模型配置、不同的超参数、不同的预处理方法等。针对更多数据和更多时期进行训练</li><li id="97d3" class="mk ml jg kf b kg mt kk mu ko mv ks mw kw mx la mp mq mr ms bi translated"><strong class="kf jh"> ABACAD 评分</strong> —为决定 ABACAD 功能的结果设计一个更好的评分系统</li><li id="be1f" class="mk ml jg kf b kg mt kk mu ko mv ks mw kw mx la mp mq mr ms bi translated"><strong class="kf jh">大规模模型部署</strong> —使用 GCP 允许过滤器库集合(来自 ABACAD 搜索的 x6)通过部署的模型自动运行</li><li id="e0de" class="mk ml jg kf b kg mt kk mu ko mv ks mw kw mx la mp mq mr ms bi translated"><strong class="kf jh">代码优化</strong> —通过提高代码效率来加速预测</li></ol><p id="2cb3" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">欢迎专业人士的任何意见或建议。</p><p id="e7c5" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这个项目的代码可以在<a class="ae jd" href="https://github.com/RobHarrand/SETI_GCP" rel="noopener ugc nofollow" target="_blank">这里</a>找到。</p><p id="2e7f" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">感谢 Emilio Enriquez、Andrew Siemion 和 Steve Croft 在这方面的帮助，以及 SETI 对让公民科学家研究这些迷人数据的普遍开放态度。</p></div></div>    
</body>
</html>