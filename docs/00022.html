<html>
<head>
<title>Dice, Polls &amp; Dirichlet Multinomials</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">骰子、民意测验和狄利克雷多项式</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/calogica-com-dice-polls-dirichlet-multinomials-eca987e6ec3f?source=collection_archive---------11-----------------------#2019-01-02">https://towardsdatascience.com/calogica-com-dice-polls-dirichlet-multinomials-eca987e6ec3f?source=collection_archive---------11-----------------------#2019-01-02</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="4f0e" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">概率规划在贝叶斯统计中的一些应用</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/ff66a64809c3c07057ffbe0f6ebd3af7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*4rY6GVqMP1Sgt5MHTwcl4Q.png"/></div></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk">Photo by <a class="ae kv" href="https://unsplash.com/photos/a6N685qLsHQ?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank">Jonathan Petersson</a> on <a class="ae kv" href="https://unsplash.com/search/photos/dice?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><p id="f69f" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">作为学习贝叶斯统计的长期项目的一部分，我目前正在阅读安德鲁·吉尔曼、约翰·卡林、哈尔·斯特恩、大卫·邓森、阿基·维赫塔里和唐纳德·鲁宾撰写的<a class="ae kv" href="http://www.stat.columbia.edu/~gelman/book/" rel="noopener ugc nofollow" target="_blank">贝叶斯数据分析，第三版</a>，通常被称为<strong class="ky ir"> BDA3 </strong>。虽然在过去一年左右的项目中，我一直在使用贝叶斯统计和概率编程语言，如<a class="ae kv" href="https://docs.pymc.io/" rel="noopener ugc nofollow" target="_blank"> PyMC3 </a>，但这本书迫使我超越纯粹的从业者建模方法，同时仍然提供非常实用的价值。</p><p id="49dd" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">以下是我觉得有趣的本书前几章的一些摘录。他们的目的是希望激励其他人学习贝叶斯统计，而不是试图对数学过于正式。如果有些东西在房间里受过训练的数学家看来不是 100%，请让我知道，或者只是稍微眯着眼睛看一下。；)</p><p id="c5db" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我们将涵盖:</p><ul class=""><li id="c7c7" class="ls lt iq ky b kz la lc ld lf lu lj lv ln lw lr lx ly lz ma bi translated">一些常见的<strong class="ky ir">共轭分布</strong></li><li id="a01d" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr lx ly lz ma bi translated">使用掷骰子的<strong class="ky ir">狄利克雷多项式</strong>分布示例</li><li id="c659" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr lx ly lz ma bi translated">涉及<strong class="ky ir">轮询来自 BDA3 的数据</strong>的两个示例</li></ul><h1 id="f690" class="mg mh iq bd mi mj mk ml mm mn mo mp mq jw mr jx ms jz mt ka mu kc mv kd mw mx bi translated">共轭分布</h1><p id="1bfd" class="pw-post-body-paragraph kw kx iq ky b kz my jr lb lc mz ju le lf na lh li lj nb ll lm ln nc lp lq lr ij bi translated">在本书的第 2 章中，作者介绍了先验概率分布的几种选择，以及第 2.4 节中的<strong class="ky ir">共轭分布</strong>的概念。</p><p id="bd4f" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">来自<a class="ae kv" href="https://en.wikipedia.org/wiki/Conjugate_prior" rel="noopener ugc nofollow" target="_blank">维基百科</a></p><blockquote class="nd ne nf"><p id="d2c2" class="kw kx ng ky b kz la jr lb lc ld ju le nh lg lh li ni lk ll lm nj lo lp lq lr ij bi translated"><em class="iq">在贝叶斯概率理论中，如果后验分布 p(θ | x)与先验概率分布 p(θ)在同一个概率分布族中，则先验和后验称为共轭分布，先验称为似然函数的共轭先验。</em></p></blockquote><p id="e5b2" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">约翰·库克在他的<a class="ae kv" href="https://www.johndcook.com/blog/conjugate_prior_diagram/" rel="noopener ugc nofollow" target="_blank">网站</a>上有一张有用的图表，展示了一些常见的共轭分布族:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi nk"><img src="../Images/cdbc43ac56751f6ce506774057068373.png" data-original-src="https://miro.medium.com/v2/resize:fit:768/format:webp/1*rggtyrv_8pUGoHORc_vKgQ.png"/></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk">Conjugate Priors</figcaption></figure><p id="268c" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">共轭分布在概率论中是一个非常重要的概念，这在很大程度上是由于一些很好的数学性质使得计算后验概率更容易处理。即使有越来越好的计算工具，如 MCMC，基于共轭分布的模型也是有优势的。</p><h1 id="4d04" class="mg mh iq bd mi mj mk ml mm mn mo mp mq jw mr jx ms jz mt ka mu kc mv kd mw mx bi translated">贝塔二项式</h1><p id="ed91" class="pw-post-body-paragraph kw kx iq ky b kz my jr lb lc mz ju le lf na lh li lj nb ll lm ln nc lp lq lr ij bi translated">共轭分布的一个更广为人知的例子是<a class="ae kv" href="https://www.statisticshowto.datasciencecentral.com/beta-binomial-distribution/" rel="noopener ugc nofollow" target="_blank">Beta-二项式</a>分布，它通常用于模拟一系列的硬币投掷(这是关于概率的帖子中一直存在的话题)。</p><p id="9346" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><em class="ng">二项式</em>分布代表一系列伯努利试验的成功概率，而<em class="ng">贝塔</em>分布则代表每次试验成功概率的先验概率分布。</p><p id="a5f0" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">因此，硬币落在<em class="ng">头</em>上的概率<strong class="ky ir"> p </strong>被建模为<em class="ng">β</em>分布(参数为α和β)，而<em class="ng">头</em>和<em class="ng">尾</em>的概率被假设为遵循<em class="ng">二项式</em>分布，参数为<strong class="ky ir"> n </strong>(代表翻转次数)和<em class="ng">β</em>分布<strong class="ky ir"> p </strong>，因此</p><blockquote class="nl"><p id="9adf" class="nm nn iq bd no np nq nr ns nt nu lr dk translated">p∞β(α，β)</p><p id="24cb" class="nm nn iq bd no np nq nr ns nt nu lr dk translated">y∞二项式(n，p)</p></blockquote><h1 id="f4a2" class="mg mh iq bd mi mj mk ml mm mn mo mp mq jw nv jx ms jz nw ka mu kc nx kd mw mx bi translated">伽马泊松</h1><p id="f5f0" class="pw-post-body-paragraph kw kx iq ky b kz my jr lb lc mz ju le lf na lh li lj nb ll lm ln nc lp lq lr ij bi translated">另一种常用的共轭分布是<em class="ng">伽马-泊松</em>分布，这样命名是因为参数化<em class="ng">泊松</em>分布的速率参数λ被建模为<em class="ng">伽马</em>分布:</p><blockquote class="nl"><p id="2aa7" class="nm nn iq bd no np nq nr ns nt nu lr dk translated">λ∞伽马(k，θ)</p><p id="a69f" class="nm nn iq bd no np nq nr ns nt nu lr dk translated">y∞泊松(λ)</p></blockquote><p id="7d94" class="pw-post-body-paragraph kw kx iq ky b kz ny jr lb lc nz ju le lf oa lh li lj ob ll lm ln oc lp lq lr ij bi translated">虽然离散的<em class="ng">泊松</em>分布通常用于计数数据的应用，例如商店顾客、电子商务订单、网站访问，但是<em class="ng">伽马</em>分布用作建模这些事件发生率(λ)的有用分布，因为<em class="ng">伽马</em>分布仅建模正的连续值，但是在其他方面其参数化相当灵活:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi od"><img src="../Images/405c1c2acb74d885795172221542eac0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*rYlGJ2lN4jJ9GeVQdJ-I-g.png"/></div></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk">Gamma Distributions</figcaption></figure><p id="415a" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这种分布也被称为<a class="ae kv" href="https://en.wikipedia.org/wiki/Negative_binomial_distribution#Gamma%E2%80%93Poisson_mixture" rel="noopener ugc nofollow" target="_blank">负二项分布</a>，我们可以将其视为泊松分布的<em class="ng">混合</em>。</p><p id="c7ab" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">如果你觉得这很困惑，你并不孤单，也许你会开始理解为什么我们经常试图用好的旧的正态分布来近似事物…</p><h1 id="903f" class="mg mh iq bd mi mj mk ml mm mn mo mp mq jw mr jx ms jz mt ka mu kc mv kd mw mx bi translated">狄利克雷多项式</h1><p id="19da" class="pw-post-body-paragraph kw kx iq ky b kz my jr lb lc mz ju le lf na lh li lj nb ll lm ln nc lp lq lr ij bi translated">一个或许更有趣但似乎很少被提及的共轭分布的例子是 BDA3 第 3 章中介绍的<a class="ae kv" href="https://en.wikipedia.org/wiki/Dirichlet-multinomial_distribution" rel="noopener ugc nofollow" target="_blank">狄利克雷多项式</a>分布。</p><p id="028c" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">思考<em class="ng">狄利克雷-多项式</em>分布的一种方式是，<em class="ng">多项式</em>(即多项选择)分布是<em class="ng">二项式</em>分布(即二元选择)的推广，<em class="ng">狄利克雷</em>分布是<em class="ng">贝塔</em>分布的推广。也就是说，<em class="ng"> Beta </em>分布模拟单个<em class="ng">概率</em>p<strong class="ky ir">概率</strong>的概率，而<em class="ng"> Dirichlet </em>模拟多个互斥选择的概率，由 a 参数化，a 被称为<em class="ng">浓度</em>参数，代表每个选择的权重(我们将在后面看到更多)。</p><p id="0684" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">换句话说，把<strong class="ky ir">硬币</strong>想象成<em class="ng">贝塔二项式</em>分布，把<strong class="ky ir">骰子</strong>想象成<em class="ng">狄利克雷多项式</em>分布。</p><blockquote class="nl"><p id="271e" class="nm nn iq bd no np nq nr ns nt nu lr dk translated">θ∞狄利克雷(a)</p><p id="3e49" class="nm nn iq bd no np nq nr ns nt nu lr dk translated">y∞多项式(n，θ)</p></blockquote><p id="6665" class="pw-post-body-paragraph kw kx iq ky b kz ny jr lb lc nz ju le lf oa lh li lj ob ll lm ln oc lp lq lr ij bi translated">在野外，我们可能会遇到<em class="ng">狄利克雷</em>分布，这些天经常出现在自然语言处理中的主题建模上下文中，它通常被用作<a class="ae kv" href="https://en.wikipedia.org/wiki/Latent_Dirichlet_allocation" rel="noopener ugc nofollow" target="_blank">潜在狄利克雷分配</a>(或 LDA)模型的一部分，这是一种奇特的方式，即我们试图计算出一篇文章属于给定内容的某个主题的概率。</p><p id="9a97" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">然而，为了我们的目的，让我们在简单的多项选择的背景下看一下<em class="ng">狄利克雷多项式</em>，让我们从投掷骰子作为激励的例子开始。</p><h1 id="461d" class="mg mh iq bd mi mj mk ml mm mn mo mp mq jw mr jx ms jz mt ka mu kc mv kd mw mx bi translated">扔骰子</h1><p id="d95e" class="pw-post-body-paragraph kw kx iq ky b kz my jr lb lc mz ju le lf na lh li lj nb ll lm ln nc lp lq lr ij bi translated">(如果您想尝试这里的代码片段，您需要首先导入相关的 Python 库。或者您可以跟随本文附带的<a class="ae kv" href="https://nbviewer.jupyter.org/github/clausherther/public/blob/master/probabilistic_programming/Dirichlet%20Multinomial%20Example.ipynb" rel="noopener ugc nofollow" target="_blank"> Jupyter 笔记本</a>。)</p><pre class="kg kh ki kj gt oe of og oh aw oi bi"><span id="4892" class="oj mh iq of b gy ok ol l om on">import numpy as np<br/>from scipy import stats<br/>import pandas as pd<br/><br/>import matplotlib.pyplot as plt<br/>import seaborn as sns<br/><br/>import pymc3 as pm</span></pre><p id="4089" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">让我们首先创建一些表示 122 个六面骰子的数据，其中<strong class="ky ir"> p </strong>表示公平骰子每一面的预期概率，即 1/6。</p><pre class="kg kh ki kj gt oe of og oh aw oi bi"><span id="68d7" class="oj mh iq of b gy ok ol l om on">y = np.asarray([20,  21, 17, 19, 17, 28])<br/>k = len(y)<br/>p = 1/k<br/>n = y.sum()</span><span id="fd5a" class="oj mh iq of b gy oo ol l om on">print(n, p)</span><span id="9ee5" class="oj mh iq of b gy oo ol l om on"><strong class="of ir">(122, 0.16666666666666666)</strong></span></pre><p id="e0bb" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">仅仅看一个简单的数据柱状图，我们就怀疑我们可能处理的不是一个公平的死亡！</p><pre class="kg kh ki kj gt oe of og oh aw oi bi"><span id="82c6" class="oj mh iq of b gy ok ol l om on">sns.barplot(x=np.arange(1, k+1), y=y);</span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi op"><img src="../Images/3faf7db9d0ec82c98241ed6d63414a83.png" data-original-src="https://miro.medium.com/v2/resize:fit:744/format:webp/1*-7JbSEm7cemJ-xWz116ufQ.png"/></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk">Barplot of rolls of six-sided die</figcaption></figure><p id="058e" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">然而，我们是贝叶斯统计的学生，我们想更进一步，量化我们在骰子的公平性方面的不确定性，并计算有人向我们扔骰子的概率。</p><p id="96f5" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">让我们在 PyMC3 中建立一个简单的模型，它不仅可以计算 theta 的后验概率(即骰子每边的概率)，还可以估计骰子返回 6 的偏差。为此，除了未观察到的(<code class="fe oq or os of b">theta</code>)和观察到的(<code class="fe oq or os of b">results</code>)随机变量之外，我们还将使用 PyMC3 <code class="fe oq or os of b">Deterministic</code>变量。</p><p id="3910" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">对于θ上的先验，我们将假设非信息性的<em class="ng">均匀</em>分布，通过用参数<code class="fe oq or os of b">a</code>的一系列 1 初始化<em class="ng">狄利克雷</em>先验，一个 1 对应一个<code class="fe oq or os of b">k</code>可能的结果。这类似于将一个<em class="ng"> Beta </em>分布初始化为<em class="ng"> Beta(1，1) </em>，它对应于<em class="ng">均匀</em>分布(关于这个<a class="ae kv" href="https://en.wikipedia.org/wiki/Beta_distribution#Bayes'_prior_probability_(Beta(1,1))" rel="noopener ugc nofollow" target="_blank">的更多信息在这里</a>)。</p><pre class="kg kh ki kj gt oe of og oh aw oi bi"><span id="2d4f" class="oj mh iq of b gy ok ol l om on">with pm.Model() as dice_model:<br/>    <br/>    # initializes the Dirichlet distribution with a uniform prior:<br/>    a = np.ones(k) <br/>    <br/>    theta = pm.Dirichlet("theta", a=a)<br/>    <br/>    # Since theta[5] will hold the posterior probability <br/>    # of rolling a 6 we'll compare this to the <br/>    # reference value p = 1/6 to determine the amount of bias<br/>    # in the die<!-- --> <br/>    six_bias = pm.Deterministic("six_bias", theta[k-1] - p)<br/>    <br/>    results = pm.Multinomial("results", n=n, p=theta, observed=y)</span></pre><p id="e586" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">从 3.5 版开始，PyMC3 包含了一个方便的函数，可以用平板符号绘制模型:</p><pre class="kg kh ki kj gt oe of og oh aw oi bi"><span id="ac72" class="oj mh iq of b gy ok ol l om on">pm.model_to_graphviz(dice_model)</span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ot"><img src="../Images/c1577b8a7a022ab149ec0f0f9449be9c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*4DxF-dkDy5HF4HgKLg5_rQ.png"/></div></div></figure><p id="2c69" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">让我们使用默认的 NUTS 采样器从关节后部抽取 1000 个样本:</p><pre class="kg kh ki kj gt oe of og oh aw oi bi"><span id="3731" class="oj mh iq of b gy ok ol l om on">with dice_model:<br/>    dice_trace = pm.sample(draws=1000)<!-- --> </span><span id="a4d4" class="oj mh iq of b gy oo ol l om on"><em class="ng">Auto-assigning NUTS sampler...<br/>Initializing NUTS using jitter+adapt_diag...<br/>Multiprocess sampling (4 chains in 4 jobs)<br/>NUTS: [theta]<br/>Sampling 4 chains: 100%|██████████| 6000/6000 [00:01&lt;00:00, 3822.31draws/s]</em></span></pre><p id="0cc9" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">从跟踪图中，我们已经可以看到其中一个θ后验概率与其余的不一致:</p><pre class="kg kh ki kj gt oe of og oh aw oi bi"><span id="fbd7" class="oj mh iq of b gy ok ol l om on">with dice_model:<br/>    pm.traceplot(dice_trace, combined=True, lines={"theta": p})</span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ou"><img src="../Images/b32cb0d729ae4d647820b8e86fd98459.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*DNC_9KBsQfwMunqvKktchg.png"/></div></div></figure><p id="6230" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我们将绘制每个θ的后验分布，并将其与我们的参考值<strong class="ky ir"> p </strong>进行比较，以查看 95% HPD(最高后验密度)区间是否包括<strong class="ky ir"> p=1/6 </strong>。</p><pre class="kg kh ki kj gt oe of og oh aw oi bi"><span id="e092" class="oj mh iq of b gy ok ol l om on">axes = pm.plot_posterior(dice_trace, <br/>                          varnames=["theta"], <br/>                          ref_val=np.round(p, 3))</span><span id="e3f8" class="oj mh iq of b gy oo ol l om on">for i, ax in enumerate(axes):<br/>    ax.set_title(f"{i+1}")</span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ou"><img src="../Images/18eb89999c546792aca119c8f5951371.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*E-wIixk91wpEvaraCyDKfg.png"/></div></div></figure><p id="d671" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我们可以清楚地看到，掷出 6 的后验概率的 HPD 几乎不包括我们对公平骰子的期望值。</p><p id="1339" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">更准确地说，通过比较θ[Six]和<strong class="ky ir"> p </strong>，让我们画出骰子偏向 6 的概率。</p><pre class="kg kh ki kj gt oe of og oh aw oi bi"><span id="4301" class="oj mh iq of b gy ok ol l om on">ax = pm.plot_posterior(dice_trace, <br/>                        varnames=["six_bias"], <br/>                        ref_val=[0])</span><span id="5cf9" class="oj mh iq of b gy oo ol l om on">ax.set_title(f"P(Theta[Six] - {p:.2%})");</span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi ov"><img src="../Images/03164c3912a7a37fd90bc69e938d3389.png" data-original-src="https://miro.medium.com/v2/resize:fit:846/format:webp/1*zNo392m__7es34rzbD8xVg.png"/></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk">P(Theta[Six])</figcaption></figure><p id="ce94" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">最后，我们可以通过计算参考线右侧 0:</p><pre class="kg kh ki kj gt oe of og oh aw oi bi"><span id="42c8" class="oj mh iq of b gy ok ol l om on">six_bias = dice_trace["six_bias"]<br/>six_bias_perc = len(six_bias[six_bias&gt;0])/len(six_bias)<br/>      <br/>print(f'P(Six is biased) = {six_bias_perc:.2%}')</span><span id="5722" class="oj mh iq of b gy oo ol l om on"><strong class="of ir">P(Six is biased) = 95.25%</strong></span></pre><p id="36f5" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">因此，我们的骰子有超过 95%的可能性偏向 6。最好买些新骰子…！</p><h1 id="bb78" class="mg mh iq bd mi mj mk ml mm mn mo mp mq jw mr jx ms jz mt ka mu kc mv kd mw mx bi translated">投票#1</h1><p id="1237" class="pw-post-body-paragraph kw kx iq ky b kz my jr lb lc mz ju le lf na lh li lj nb ll lm ln nc lp lq lr ij bi translated">让我们把狄利克雷多项式分布的回顾转向另一个例子，关于轮询数据。</p><p id="963e" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在 BDA3 关于多变量模型的第 3.4 节，特别是关于分类数据的多项模型的第<em class="ng">节</em>中，作者引用了 1988 年老布什和迈克尔·杜卡基斯总统竞选中的一个不太成熟的投票数据示例。</p><p id="edd9" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">对于那些当时不关注政治的人来说:布什以巨大优势获胜。自 1988 年以来，没有一位总统候选人能在选举人票或普选中获得与布什相同或更高的票数。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi ow"><img src="../Images/8ee9f603d6c3bf75a8029052372ae292.png" data-original-src="https://miro.medium.com/v2/resize:fit:1358/format:webp/1*facOwEYT7g4dbSFBs73vbA.png"/></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk">(Image credit: <a class="ae kv" href="https://commons.wikimedia.org/wiki/File:ElectoralCollege1988-Large.png)" rel="noopener ugc nofollow" target="_blank">https://commons.wikimedia.org/wiki/File:ElectoralCollege1988-Large.png)</a></figcaption></figure><p id="0271" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">反正回到数据问题！设置如下:</p><ul class=""><li id="8b91" class="ls lt iq ky b kz la lc ld lf lu lj lv ln lw lr lx ly lz ma bi translated">1，447 名可能的选民接受了关于他们在即将到来的总统选举中的偏好的调查</li><li id="4584" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr lx ly lz ma bi translated">他们的回答是:<br/>T5 布什:727 <br/>杜卡基斯:583 <br/>其他:137 </li><li id="ab84" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr lx ly lz ma bi translated">更多人投票给布什而不是杜卡基斯的概率有多大？即两个主要候选人的支持率有什么不同？</li></ul><p id="36ce" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我们设置了数据，其中<code class="fe oq or os of b">k</code>代表受访者的选择数量:</p><pre class="kg kh ki kj gt oe of og oh aw oi bi"><span id="d762" class="oj mh iq of b gy ok ol l om on">y = np.asarray([727, 583, 137])<br/>n = y.sum()<br/>k = len(y)</span></pre><p id="b8d2" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我们再次建立了一个简单的狄利克雷多项式模型，并加入了一个<code class="fe oq or os of b">Deterministic</code>变量来计算兴趣值——布什和杜卡基斯的受访者概率之差。</p><pre class="kg kh ki kj gt oe of og oh aw oi bi"><span id="6247" class="oj mh iq of b gy ok ol l om on">with pm.Model() as polling_model:<br/>    <br/>    # initializes the Dirichlet distribution with a uniform prior:<br/>    a = np.ones(k) <br/>    <br/>    theta = pm.Dirichlet("theta", a=a)<br/>    <br/>    bush_dukakis_diff = pm.Deterministic("bush_dukakis_diff",<br/>                                          theta[0] - theta[1])<br/>    <br/>    likelihood = pm.Multinomial("likelihood", <br/>                                 n=n, <br/>                                 p=theta, <br/>                                 observed=y)</span><span id="d173" class="oj mh iq of b gy oo ol l om on">pm.model_to_graphviz(polling_model)</span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ox"><img src="../Images/d85d8c409c3e7ded13a4958bd17ddb45.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*8cX25S6A7XIlqr6LFYudrQ.png"/></div></div></figure><pre class="kg kh ki kj gt oe of og oh aw oi bi"><span id="7803" class="oj mh iq of b gy ok ol l om on">with polling_model:<br/>    polling_trace = pm.sample(draws=1000)</span></pre><p id="09ca" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">看看布什和杜卡基斯的受访者之间的%差异，我们可以看到大部分的密度是<strong class="ky ir">大于 0% </strong>，这表明布什在这次民意调查中有很大的优势。<br/>我们还通过<code class="fe oq or os of b">scipy.stats</code>将<em class="ng"> Beta </em>分布拟合到该数据，我们可以看到，2θ值的差值的后验非常好地拟合了<em class="ng"> Beta </em>分布(鉴于狄利克雷分布作为<em class="ng"> Beta </em>分布的多元推广的特性，这是可以预料的)。</p><pre class="kg kh ki kj gt oe of og oh aw oi bi"><span id="b065" class="oj mh iq of b gy ok ol l om on">_, ax = plt.subplots(1,1, figsize=(10, 6))<br/>sns.distplot(polling_trace["bush_dukakis_diff"], <br/>     bins=20, ax=ax, kde=False, fit=stats.beta)</span><span id="aeae" class="oj mh iq of b gy oo ol l om on">ax.axvline(0, c='g', linestyle='dotted')<br/>ax.set_title("% Difference Bush vs Dukakis")<br/>ax.set_xlabel("% Difference");</span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi oy"><img src="../Images/6bb219a1c1f574486463e26a2816bc92.png" data-original-src="https://miro.medium.com/v2/resize:fit:1190/format:webp/1*s87wUsEowEPZM5apo0xQsA.png"/></div></figure><p id="b68a" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">带有<code class="fe oq or os of b">bush_dukakis_diff &gt; 0</code>的样本百分比:</p><pre class="kg kh ki kj gt oe of og oh aw oi bi"><span id="db11" class="oj mh iq of b gy ok ol l om on">diff = polling_trace["bush_dukakis_diff"]<br/>bush_dukakis_diff_perc = len(diff[diff&gt;0])/len(diff)<br/>      <br/>print(f'P(More Responses for Bush) = {bush_dukakis_diff_perc:.0%}')</span><span id="bf86" class="oj mh iq of b gy oo ol l om on"><strong class="of ir">P(More Responses for Bush) = 100%</strong></span></pre><h1 id="18bc" class="mg mh iq bd mi mj mk ml mm mn mo mp mq jw mr jx ms jz mt ka mu kc mv kd mw mx bi translated">投票#2</h1><p id="dbba" class="pw-post-body-paragraph kw kx iq ky b kz my jr lb lc mz ju le lf na lh li lj nb ll lm ln nc lp lq lr ij bi translated">作为对前一个模型的扩展，BDA 的作者在第 3.10 章中包括了一个练习(练习 2)，为我们提供了 1988 年总统竞选的民调数据，在辩论之一的之前取<em class="ng">，在</em>之后取<em class="ng">。</em></p><blockquote class="nd ne nf"><p id="600b" class="kw kx ng ky b kz la jr lb lc ld ju le nh lg lh li ni lk ll lm nj lo lp lq lr ij bi translated"><em class="iq">两个多项观察值的比较:1988 年 9 月 25 日，一场总统竞选辩论的当晚，ABC 新闻对美国注册选民进行了一项调查；辩论前对 639 人进行了民意测验，辩论后对 639 名不同的人进行了民意测验。结果如表 3.2 所示。假设调查是从注册选民人口中随机抽取的独立样本。用两种不同的多项式分布对数据建模。对于</em> j=1，2 <em class="iq">，设</em> αj <em class="iq">为在调查</em> j <em class="iq">时偏好布什或杜卡基斯的选民中，偏好布什的比例。绘制</em>α2-α1<em class="iq">的后验密度直方图。转向布什的后验概率是多少？</em></p></blockquote><p id="cbd4" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">让我们复制练习中的数据，将问题建模为概率模型，同样使用 PyMC3:</p><pre class="kg kh ki kj gt oe of og oh aw oi bi"><span id="b990" class="oj mh iq of b gy ok ol l om on">data = pd.DataFrame([<br/>        {"candidate": "bush", "pre": 294, "post": 288},<br/>        {"candidate": "dukakis", "pre": 307, "post": 332},<br/>        {"candidate": "other", "pre": 38, "post": 10}<br/>       ], columns=["candidate", "pre", "post"])</span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi oz"><img src="../Images/2c905a874b61ef4f1d3d3d40089e5cc8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*xQMfyqDj0rtCTY7lhtDVTA.png"/></div></div></figure><p id="1c18" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">转换为 2x3 阵列:</p><pre class="kg kh ki kj gt oe of og oh aw oi bi"><span id="3c72" class="oj mh iq of b gy ok ol l om on">y = data[["pre", "post"]].T.values</span><span id="f92b" class="oj mh iq of b gy oo ol l om on">print(y)<!-- --> </span><span id="df1c" class="oj mh iq of b gy oo ol l om on"><strong class="of ir">array([[294, 307,  38],<br/>       [288, 332,  10]])</strong></span></pre><p id="42a0" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">每次调查的受访者人数:</p><pre class="kg kh ki kj gt oe of og oh aw oi bi"><span id="e9f1" class="oj mh iq of b gy ok ol l om on">n = y.sum(axis=1) <br/>print(n)</span><span id="194e" class="oj mh iq of b gy oo ol l om on"><strong class="of ir">array([639, 630])</strong></span></pre><p id="c8a1" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">每次调查中两个主要候选人的受访者人数:</p><pre class="kg kh ki kj gt oe of og oh aw oi bi"><span id="75e3" class="oj mh iq of b gy ok ol l om on">m = y[:, :2].sum(axis=1) <br/>print(m)<!-- --> </span><span id="8331" class="oj mh iq of b gy oo ol l om on"><strong class="of ir">array([601, 620])</strong></span></pre><p id="2010" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">对于这个模型，我们需要稍微不同地设置先验。我们需要 2 套，而不是 1 套<em class="ng">theta</em>，每个调查一套(辩论前/辩论后)。要做到这一点而不创建每个变量的特定前/后版本，我们将利用 PyMC3 的<code class="fe oq or os of b">shape</code>参数，该参数可用于大多数(所有？)分布。</p><p id="c41f" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在这种情况下，我们需要一个二维形状参数，代表辩论的数量<code class="fe oq or os of b">n_debates</code>和候选人的选择数量<code class="fe oq or os of b">n_candidates</code></p><pre class="kg kh ki kj gt oe of og oh aw oi bi"><span id="9738" class="oj mh iq of b gy ok ol l om on">n_debates, n_candidates = y.shape<br/>print(n_debates, n_candidates)<!-- --> </span><span id="da13" class="oj mh iq of b gy oo ol l om on"><strong class="of ir">(2, 3)</strong></span></pre><p id="4b80" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">因此，我们需要用形状<code class="fe oq or os of b">(2,3)</code>初始化 Dirichlet 分布，然后在需要的地方通过索引引用相关参数。</p><pre class="kg kh ki kj gt oe of og oh aw oi bi"><span id="0478" class="oj mh iq of b gy ok ol l om on">with pm.Model() as polling_model_debates:<br/>    <br/>    # initializes the Dirichlet distribution with a uniform prior:</span><span id="0921" class="oj mh iq of b gy oo ol l om on">    shape = (n_debates, n_candidates)<br/>    a = np.ones(shape)<br/>    <br/>    # This creates a separate Dirichlet distribution for each debate<br/>    # where sum of probabilities across candidates = 100% <br/>    # for each debate</span><span id="08a9" class="oj mh iq of b gy oo ol l om on">    theta = pm.Dirichlet("theta", a=a, shape=shape)<br/>    <br/>    # get the "Bush" theta for each debate, at index=0<br/>    # and normalize across supporters for the 2 major candidates</span><span id="26ae" class="oj mh iq of b gy oo ol l om on">    bush_pref = pm.Deterministic("bush_pref", theta[:, 0] * n / m)<br/>    <br/>    # to calculate probability that support for Bush <br/>    # shifted from debate 1 [0] to 2 [1]</span><span id="e50a" class="oj mh iq of b gy oo ol l om on">    bush_shift = pm.Deterministic("bush_shift", <br/>        bush_pref[1]-bush_pref[0])<br/>    <br/>    # because of the shapes of the inputs, <br/>    # this essentially creates 2 multinomials, <br/>    # one for each debate</span><span id="4372" class="oj mh iq of b gy oo ol l om on">    responses = pm.Multinomial("responses", <br/>        n=n, p=theta, observed=y)</span></pre><p id="dc03" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">对于具有多维形状的模型，最好在采样前检查各种参数的形状:</p><pre class="kg kh ki kj gt oe of og oh aw oi bi"><span id="7782" class="oj mh iq of b gy ok ol l om on">for v in polling_model_debates.unobserved_RVs:<br/>    print(v, v.tag.test_value.shape)</span><span id="f15f" class="oj mh iq of b gy oo ol l om on"><strong class="of ir">theta_stickbreaking__ (2, 2)<br/><em class="ng">theta (2, 3)<br/></em>bush_pref (2,)<br/>bush_shift ()</strong><strong class="of ir"> </strong></span></pre><p id="cbb9" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">标牌视觉效果也有所帮助:</p><pre class="kg kh ki kj gt oe of og oh aw oi bi"><span id="f249" class="oj mh iq of b gy ok ol l om on">pm.model_to_graphviz(polling_model_debates)</span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi pa"><img src="../Images/5727dd9095bd4b36a266ca7901303f1f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*HWMg_etKXRwa6xfZrYb8RQ.png"/></div></div></figure><p id="000a" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">让我们以稍微多一点的抽取次数和调谐步骤进行采样:</p><pre class="kg kh ki kj gt oe of og oh aw oi bi"><span id="e481" class="oj mh iq of b gy ok ol l om on">with polling_model_debates:<br/>    polling_trace_debates = pm.sample(draws=3000, tune=1500)</span></pre><p id="0e31" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">快速查看 traceplot 以确保模型平滑收敛:</p><pre class="kg kh ki kj gt oe of og oh aw oi bi"><span id="3fd3" class="oj mh iq of b gy ok ol l om on">with polling_model_debates:<br/>    pm.traceplot(polling_trace_debates, combined=True)</span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ou"><img src="../Images/6f17db4e13d44790feb04fdcdc24495f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*6qefkM7A33IhKo0nsWFq0A.png"/></div></div></figure><p id="9917" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">让我们来看一下<code class="fe oq or os of b">theta</code>的后验概率的平均值，表明辩论前&amp;后每位候选人的支持率百分比:</p><pre class="kg kh ki kj gt oe of og oh aw oi bi"><span id="6d05" class="oj mh iq of b gy ok ol l om on">s = ["pre", "post"]<br/>candidates = data["candidate"].values</span><span id="a2fd" class="oj mh iq of b gy oo ol l om on">pd.DataFrame(polling_trace_debates["theta"].mean(axis=0), <br/>    index=s, <br/>    columns=candidates)</span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi oz"><img src="../Images/2881b1ec9967d8e11ccb0120e4572e79.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*-LntfdUX7b8aMFVGcLIWAw.png"/></div></div></figure><p id="6ac3" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">仅从平均值来看，我们可以看到布什的支持者人数可能<strong class="ky ir">在辩论后从 48.8%下降到 46.3%(作为两大候选人支持者的百分比):</strong></p><pre class="kg kh ki kj gt oe of og oh aw oi bi"><span id="417c" class="oj mh iq of b gy ok ol l om on">pd.DataFrame(polling_trace_debates["bush_pref"].mean(axis=0),  <br/>    index=s, columns=["bush_pref"])</span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi pb"><img src="../Images/014e115fe233b7b739e1bbd1c402c4ba.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*WkPbuIUnGyjoT_lUrAIQRg.png"/></div></div></figure><p id="886e" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">让我们通过绘制布什%回应的辩论前/后值的后验分布和布什支持者辩论前/后差异的后验分布来直观地比较结果:</p><pre class="kg kh ki kj gt oe of og oh aw oi bi"><span id="cb1c" class="oj mh iq of b gy ok ol l om on">_, ax = plt.subplots(2,1, figsize=(10, 10))</span><span id="2b74" class="oj mh iq of b gy oo ol l om on">sns.distplot(polling_trace_debates["bush_pref"][:,0], <br/>    hist=False, ax=ax[0], label="Pre-Debate")</span><span id="3d04" class="oj mh iq of b gy oo ol l om on">sns.distplot(polling_trace_debates["bush_pref"][:,1], <br/>    hist=False, ax=ax[0], label="Post-Debate")</span><span id="42f6" class="oj mh iq of b gy oo ol l om on">ax[0].set_title("% Responses for Bush vs Dukakis")<br/>ax[0].set_xlabel("% Responses");</span><span id="d634" class="oj mh iq of b gy oo ol l om on">sns.distplot(polling_trace_debates["bush_shift"], <br/>    hist=True, ax=ax[1], label="P(Bush Shift)")</span><span id="f58d" class="oj mh iq of b gy oo ol l om on">ax[1].axvline(0, c='g', linestyle='dotted')<br/>ax[1].set_title("% Shift Pre/Prior Debate")<br/>ax[1].set_xlabel("% Shift");</span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi pc"><img src="../Images/41abad3fb10f9e6b564d7e8479f86c6f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1210/format:webp/1*EsY_reZwKt4xiLgtvxpOVg.png"/></div></figure><p id="bc08" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">从第二个图中，我们已经可以看到很大一部分后验密度低于 0，但让我们精确地实际计算一下辩论后支持从<em class="ng">转向</em>布什的概率:</p><pre class="kg kh ki kj gt oe of og oh aw oi bi"><span id="5b2a" class="oj mh iq of b gy ok ol l om on">bush_shift = polling_trace_debates["bush_shift"]<br/>perc_shift = (<br/>              len(bush_shift[bush_shift &gt; 0])<br/>              /len(bush_shift)<br/>             )<br/>print(f'P(Shift Towards Bush) = {perc_shift:.1%}')</span><span id="57eb" class="oj mh iq of b gy oo ol l om on"><strong class="of ir">P(Shift Towards Bush) = 19.9%</strong></span></pre><p id="a1f4" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">虽然这是一种迂回的方式来表明布什在 9 月的辩论中失去了支持，但希望这说明了概率模型(和 PyMC3)的灵活性和稳健性。</p><p id="17f8" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">如果你对这篇文章有任何想法或反馈，请告诉我！</p><p id="d900" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">(这个帖子在 Github 上也有<a class="ae kv" href="https://nbviewer.jupyter.org/github/clausherther/public/blob/master/Dirichlet%20Multinomial%20Example.ipynb" rel="noopener ugc nofollow" target="_blank"> Jupyter 笔记本。)</a></p></div></div>    
</body>
</html>