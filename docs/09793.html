<html>
<head>
<title>A Beginner’s Guide to Preprocessing Text Data Using NLP</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用 NLP 预处理文本数据的初学者指南</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/a-beginners-guide-to-preprocessing-text-data-using-nlp-tools-5cb52a8d3cd?source=collection_archive---------17-----------------------#2019-12-23">https://towardsdatascience.com/a-beginners-guide-to-preprocessing-text-data-using-nlp-tools-5cb52a8d3cd?source=collection_archive---------17-----------------------#2019-12-23</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="d212" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">用于预处理从 Twitter 获得的推文的代码</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/80c661fc6f7d71ee547418fb7e1b0a99.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*h0mO4PdZaQKtbwWJW40FKQ.jpeg"/></div></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk">Source: <a class="ae ky" href="https://www.blumeglobal.com/learning/natural-language-processing/" rel="noopener ugc nofollow" target="_blank">https://www.blumeglobal.com/learning/natural-language-processing/</a></figcaption></figure><p id="5b6f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">下面我概述了我用来预处理自然语言处理项目的代码。这个代码主要用于分类者从 Twitter 上获得的 tweets。我希望本指南能够帮助有抱负的数据科学家和机器学习工程师，让他们熟悉一些非常有用的自然语言处理工具和步骤。</p><h2 id="8c4f" class="lv lw it bd lx ly lz dn ma mb mc dp md li me mf mg lm mh mi mj lq mk ml mm mn bi translated">要导入的包</h2><pre class="kj kk kl km gt mo mp mq mr aw ms bi"><span id="4625" class="lv lw it mp b gy mt mu l mv mw">from nltk.stem import LancasterStemmer, SnowballStemmer, RegexpStemmer, WordNetLemmatizer <br/>#this was part of the NLP notebook</span><span id="ee9e" class="lv lw it mp b gy mx mu l mv mw">import nltk<br/>nltk.download('punkt')</span><span id="3b52" class="lv lw it mp b gy mx mu l mv mw">#import sentence tokenizer<br/>from nltk import sent_tokenize</span><span id="0bcc" class="lv lw it mp b gy mx mu l mv mw">#import word tokenizer<br/>from nltk import word_tokenize</span><span id="d59f" class="lv lw it mp b gy mx mu l mv mw">#list of stopwords<br/>from nltk.corpus import stopwords</span><span id="41cf" class="lv lw it mp b gy mx mu l mv mw">import string</span></pre><h2 id="f224" class="lv lw it bd lx ly lz dn ma mb mc dp md li me mf mg lm mh mi mj lq mk ml mm mn bi translated">处理表情符号</h2><pre class="kj kk kl km gt mo mp mq mr aw ms bi"><span id="55ae" class="lv lw it mp b gy mt mu l mv mw">import emoji</span><span id="f10c" class="lv lw it mp b gy mx mu l mv mw">#checking if a character is an emoji<br/>def char_is_emoji(character):<br/>    return character in emoji.UNICODE_EMOJI</span><span id="e6cf" class="lv lw it mp b gy mx mu l mv mw">#does the text contain an emoji?<br/>def text_has_emoji(text):<br/>    for character in text:<br/>        if character in emoji.UNICODE_EMOJI:<br/>            return True<br/>    return False</span><span id="4fed" class="lv lw it mp b gy mx mu l mv mw">#remove the emoji<br/>def deEmojify(inputString):<br/>    return inputString.encode('ascii', 'ignore').decode('ascii')</span></pre><h2 id="e6a1" class="lv lw it bd lx ly lz dn ma mb mc dp md li me mf mg lm mh mi mj lq mk ml mm mn bi translated">删除标点符号</h2><pre class="kj kk kl km gt mo mp mq mr aw ms bi"><span id="226a" class="lv lw it mp b gy mt mu l mv mw">punct =[]<br/>punct += list(string.punctuation)<br/>punct += '’'<br/>punct.remove("'")</span><span id="9ee7" class="lv lw it mp b gy mx mu l mv mw">def remove_punctuations(text):<br/>    for punctuation in punct:<br/>        text = text.replace(punctuation, ' ')<br/>    return text</span></pre><p id="847d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">下面的函数被用来为我工作的分类器项目对 tweets 进行大量的预处理。这应该同样适用于您可能正在从事的其他 NLP 项目。上面的功能会在下面辅助。</p><h2 id="cade" class="lv lw it bd lx ly lz dn ma mb mc dp md li me mf mg lm mh mi mj lq mk ml mm mn bi translated">函数完成了大部分预处理工作，为了便于理解，已经将其注释掉了</h2><pre class="kj kk kl km gt mo mp mq mr aw ms bi"><span id="52eb" class="lv lw it mp b gy mt mu l mv mw">def nlp(df):<br/>    # lowercase everything<br/>    # get rid of '\n' from whitespace<br/>    # regex remove hyperlinks<br/>    # removing '&amp;gt;'<br/>    # check for emojis<br/>    # remove emojis<br/>    # remove punctuation<br/>    # remove ' s ' from removing punctuation</span><span id="c9d6" class="lv lw it mp b gy mx mu l mv mw">  <br/>    # lowercase everything<br/>    df['token'] = df['tweet'].apply(lambda x: x.lower())<br/>    # get rid of '\n' from whitespace <br/>    df['token'] = df['token'].apply(lambda x: x.replace('\n', ' '))<br/>    # regex remove hyperlinks<br/>    df['token'] = df['token'].str.replace('http\S+|<a class="ae ky" href="http://www.\S+'" rel="noopener ugc nofollow" target="_blank">www.\S+'</a>, '', case=False)<br/>    # removing '&amp;gt;'<br/>    df['token'] = df['token'].apply(lambda x: x.replace('&amp;gt;', ''))<br/>    # Checking if emoji in tokens column, use for EDA purposes otherwise not necessary to keep this column<br/>    df['emoji'] = df['token'].apply(lambda x: text_has_emoji(x))<br/>    # Removing Emojis from tokens<br/>    df['token'] = df['token'].apply(lambda x: deEmojify(x))<br/>    # remove punctuations<br/>    df['token'] = df['token'].apply(remove_punctuations)<br/>    # remove ' s ' that was created after removing punctuations<br/>    df['token'] = df['token'].apply(lambda x: str(x).replace(" s ", " "))</span><span id="e732" class="lv lw it mp b gy mx mu l mv mw">    return df</span></pre><h1 id="732e" class="my lw it bd lx mz na nb ma nc nd ne md jz nf ka mg kc ng kd mj kf nh kg mm ni bi translated">使用空间的词汇化</h1><pre class="kj kk kl km gt mo mp mq mr aw ms bi"><span id="7336" class="lv lw it mp b gy mt mu l mv mw">import spacy<br/>from spacy.lemmatizer import Lemmatizer<br/>from spacy.lookups import Lookups</span><span id="9ed2" class="lv lw it mp b gy mx mu l mv mw">sp = spacy.load('en')<br/>lookups = Lookups()<br/>lemm = Lemmatizer(lookups)</span></pre><h2 id="3dbf" class="lv lw it bd lx ly lz dn ma mb mc dp md li me mf mg lm mh mi mj lq mk ml mm mn bi translated">创建和执行一个引理函数</h2><pre class="kj kk kl km gt mo mp mq mr aw ms bi"><span id="116d" class="lv lw it mp b gy mt mu l mv mw">def lemma_function(text):<br/>    dummy = []<br/>    #this is just a test to see if it works<br/>    for word in sp(text):<br/>        dummy.append(word.lemma_)</span><span id="1961" class="lv lw it mp b gy mx mu l mv mw">    return ' '.join(dummy)</span><span id="cb3b" class="lv lw it mp b gy mx mu l mv mw">df['lemmatized'] = df['token'].apply(lambda x: lemma_function(x))</span></pre><p id="bd9a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在对推文进行词汇化后，我发现“-PRON-”出现在我的文本中，这是在你使用 spacy 对代词进行词汇化后出现的“短语”。这对于通知我一条推文的内容并不重要，所以我也删除了这个“-PRON-”短语。</p><pre class="kj kk kl km gt mo mp mq mr aw ms bi"><span id="e54b" class="lv lw it mp b gy mt mu l mv mw">df['lemmatized'] = df['lemmatized'].apply(lambda x: x.replace('-PRON-', ' '))</span></pre><h2 id="da6d" class="lv lw it bd lx ly lz dn ma mb mc dp md li me mf mg lm mh mi mj lq mk ml mm mn bi translated">标记我的数据</h2><pre class="kj kk kl km gt mo mp mq mr aw ms bi"><span id="aea8" class="lv lw it mp b gy mt mu l mv mw">df['final_text'] = df['lemmatized'].apply(word_tokenize)</span></pre><h2 id="b191" class="lv lw it bd lx ly lz dn ma mb mc dp md li me mf mg lm mh mi mj lq mk ml mm mn bi translated">从我的令牌中删除停用字词</h2><pre class="kj kk kl km gt mo mp mq mr aw ms bi"><span id="c967" class="lv lw it mp b gy mt mu l mv mw">from nltk.corpus import stopwords<br/>my_stopwords = set(stopwords.words('english'))</span><span id="8950" class="lv lw it mp b gy mx mu l mv mw">df['final_text'] = df['final_text'].apply(lambda text_list: [x for x in text_list if x not in stopwords.words('english')])</span></pre><h2 id="a99d" class="lv lw it bd lx ly lz dn ma mb mc dp md li me mf mg lm mh mi mj lq mk ml mm mn bi translated">从我的标记化文本数据中移除数字</h2><pre class="kj kk kl km gt mo mp mq mr aw ms bi"><span id="1ada" class="lv lw it mp b gy mt mu l mv mw">df['final_text'] = df['final_text'].apply(lambda list_data: [x for x in list_data if x.isalpha()])</span></pre><p id="dcd8" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">既然你的 tweet 数据已经被预处理了，你的数据现在应该更干净了。除了上述内容之外，您还有更广泛的考虑事项。在我的分类器项目中，我还使用了<strong class="lb iu"> TextBlob </strong>来自动更正我的语料库中的任何拼写错误。但是请注意，TextBlob 的计算开销很大。此外，一旦您对数据进行了充分的预处理，并准备好创建单词包(计数矢量器)或 TF-IDF 矢量器，您就可以调整参数，以满足您对机器学习问题的要求。</p><p id="5a3c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我希望这篇指南能加速你的下一个 NLP 项目的文本数据的预处理。请随意留下任何想法和见解。</p></div></div>    
</body>
</html>