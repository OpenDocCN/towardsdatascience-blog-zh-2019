<html>
<head>
<title>Fast data augmentation in PyTorch using Nvidia DALI</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用 Nvidia DALI 在 PyTorch 中快速增强数据</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/fast-data-augmentation-in-pytorch-using-nvidia-dali-68f5432e1f5f?source=collection_archive---------18-----------------------#2019-07-03">https://towardsdatascience.com/fast-data-augmentation-in-pytorch-using-nvidia-dali-68f5432e1f5f?source=collection_archive---------18-----------------------#2019-07-03</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><p id="7085" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">原帖:<a class="ae ko" href="https://www.basicml.com/performance/2019/04/16/pytorch-data-augmentation-with-nvidia-dali" rel="noopener ugc nofollow" target="_blank">https://www . basic ml . com/performance/2019/04/16/py torch-data-augmentation-with-NVIDIA-Dali</a></p><p id="c76f" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">在我工作的新项目中，我必须为多标签多类别分类任务处理一组足够大的图像数据。尽管 GPU 利用率接近 100%，但运行超过 200 万张图像的单个训练时段需要近 3.5 小时。如果您正在进行基线实验，并且想要快速得到结果，这是一个大问题。我首先想到的是，由于我在处理原始大小的图像，每个图像至少有几兆字节，所以瓶颈是磁盘 I/O。我使用<a class="ae ko" href="https://imagemagick.org/script/mogrify.php" rel="noopener ugc nofollow" target="_blank"> Imagemagick mogrify </a>来调整所有 200 万张图像的大小，这花了很长时间。令我惊讶的是，调整图片大小根本没有减少训练时间！嗯，不明显。因此，我仔细检查了代码，发现主要的瓶颈是 PyTorch 中的图像增强操作。</p><figure class="kp kq kr ks gt kt"><div class="bz fp l di"><div class="ku kv l"/></div></figure><p id="c645" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">在偶然发现 Github 的时候，我发现在 Nvidia 工作的人最近发布了一个库——<a class="ae ko" href="https://github.com/NVIDIA/DALI" rel="noopener ugc nofollow" target="_blank">DALI</a>，据说就是为了解决这个问题。该库仍在积极开发中，并支持所有主要 ML 开发库的快速数据扩充— <a class="ae ko" href="https://pytorch.org/" rel="noopener ugc nofollow" target="_blank"> PyTorch </a>，<a class="ae ko" href="https://www.tensorflow.org/" rel="noopener ugc nofollow" target="_blank"> Tensorflow </a>，<a class="ae ko" href="https://mxnet.apache.org/" rel="noopener ugc nofollow" target="_blank"> MXNet </a>。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi kw"><img src="../Images/ea74fbd81d9d11cd4500060716da86f2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*00PmRDHTyGWf6j8wKUa3-A.png"/></div></div><figcaption class="ld le gj gh gi lf lg bd b be z dk">Fig 1: A typical data augmentation pipeline</figcaption></figure><p id="9954" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">使用 Nvidia DALI，可以通过将适当的<a class="ae ko" href="https://docs.nvidia.com/deeplearning/sdk/dali-developer-guide/docs/supported_ops.html" rel="noopener ugc nofollow" target="_blank">操作</a>移到 GPU 来优化上述数据流水线。使用 DALI 后，管道看起来像这样-</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi lh"><img src="../Images/ffffc59e4b973df80ee58d28d69bd721.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*t3O2Rpm-YYfdUW8sUpsPMA.png"/></div></div><figcaption class="ld le gj gh gi lf lg bd b be z dk">Fig 2: Fig 2: An Nvidia DALI pipeline</figcaption></figure><p id="4971" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">有关 DALI 功能的更多细节，请参见这篇由 Nvidia 开发人员撰写的初学者友好帖子，标题为<a class="ae ko" href="https://devblogs.nvidia.com/fast-ai-data-preprocessing-with-nvidia-dali/" rel="noopener ugc nofollow" target="_blank">使用 NVIDIA DALI 进行快速 AI 数据预处理</a>。在这篇文章的剩余部分，我将展示如何将 Nvidia DALI 合并到 PyTorch 代码中。欢迎读者对下面的代码提供可能的改进。</p><p id="0397" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">我们从安装所需的依赖项开始。</p><figure class="kp kq kr ks gt kt"><div class="bz fp l di"><div class="ku kv l"/></div></figure><p id="0f2d" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">到目前为止，您已经完成了“nvidia-dali”的安装，我们现在将把它集成到我们的 PyTorch 代码中。为了创建虚拟数据集，我们下载了由<a class="ae ko" href="https://www.udacity.com/course/deep-learning-pytorch--ud188" rel="noopener ugc nofollow" target="_blank"> Udacity </a>提供的花卉分类数据。数据集包含两个文件夹——“训练”和“有效”。我们使用“train”文件夹中的图像，并展平目录，该目录组织为一个分层文件夹，包含按标签排列的图像，每个标签有一个子文件夹。我们不使用提供的标签，而是生成虚拟标签进行演示。</p><figure class="kp kq kr ks gt kt"><div class="bz fp l di"><div class="ku kv l"/></div></figure><p id="8a02" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">接下来，我们创建一个空格分隔的文件，它符合 Nvidia DALI 官方文档页面上给出的示例。</p><figure class="kp kq kr ks gt kt"><div class="bz fp l di"><div class="ku kv l"/></div></figure><p id="b1b7" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">接下来，我们创建一个“ExternalInputIterator ”,它对我们的数据进行批处理，并由 DALI <a class="ae ko" href="https://docs.nvidia.com/deeplearning/sdk/dali-master-branch-user-guide/docs/examples/getting%20started.html#Pipeline" rel="noopener ugc nofollow" target="_blank">管道</a>用来输入数据，并将其馈送给相应的设备进行处理。下面的代码改编自官方代码<a class="ae ko" href="https://docs.nvidia.com/deeplearning/sdk/dali-developer-guide/docs/examples/external_input.html" rel="noopener ugc nofollow" target="_blank">这里</a>为多个标签工作。感谢<a class="li lj ep" href="https://medium.com/u/43ce294a7ce?source=post_page-----68f5432e1f5f--------------------------------" rel="noopener" target="_blank">悉达多甘居</a>指向官方教程。</p><figure class="kp kq kr ks gt kt"><div class="bz fp l di"><div class="ku kv l"/></div></figure><p id="2d44" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">接下来，我们实例化该迭代器，并将其作为输入提供给‘externalsourcepipeline ’,该‘externalsourcepipeline’扩展了‘pipeline’类，并将数据提供给相应的设备用于增强操作。</p><figure class="kp kq kr ks gt kt"><div class="bz fp l di"><div class="ku kv l"/></div></figure><p id="f992" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">我们差不多完成了，现在我们实例化一个“DALIGenericIterator ”,它帮助我们迭代数据集，就像我们在 PyTorch 中通常做的那样。</p><figure class="kp kq kr ks gt kt"><div class="bz fp l di"><div class="ku kv l"/></div></figure><p id="235f" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">谷歌 Colab: <a class="ae ko" href="http://tiny.cc/nvidia-dali" rel="noopener ugc nofollow" target="_blank">笔记本</a></p><p id="d52f" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">我还没有在我的代码中对 DALI 进行基准测试，一旦有了结果，我会更新这篇文章。</p><p id="2e57" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">保持优雅。</p><p id="0a71" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu">链接:</strong></p><p id="0d92" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">-达利 Github <a class="ae ko" href="https://github.com/NVIDIA/DALI" rel="noopener ugc nofollow" target="_blank">回购</a></p><p id="6a1b" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">-大理官方<a class="ae ko" href="https://devblogs.nvidia.com/fast-ai-data-preprocessing-with-nvidia-dali/" rel="noopener ugc nofollow" target="_blank">博客文章</a></p></div></div>    
</body>
</html>