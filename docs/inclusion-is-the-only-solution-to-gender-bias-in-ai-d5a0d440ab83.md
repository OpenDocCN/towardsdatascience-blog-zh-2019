# 包容是人工智能性别偏见的唯一解决方案

> 原文：<https://towardsdatascience.com/inclusion-is-the-only-solution-to-gender-bias-in-ai-d5a0d440ab83?source=collection_archive---------45----------------------->

![](img/f8d141ce277a20b61ef5600538906585.png)

人工智能中的性别话题正日益成为主流。我知道这一点是因为在完成关于这个主题的硕士论文后，我的许多朋友和家人会给我发他们在这个主题上看到的文章，所以我每周至少会收到一篇。

今天发给我的这篇文章来自 [ICT Works](https://www.ictworks.org/siri-gender-equal-technology-solutions/#.XcLnSejYqUl) ，在我看来，它代表了许多关于这个主题的主流文章的做法——强调了一些相对众所周知的关于女性在技术领域缺乏的观点，并提出我们只需要让更多女性进入 STEM 教育。任务完成。

不幸的是，这个问题/解决方案框架过于简单，尽管这是一个非常普遍的分析，它表明*问题*(人工智能中的偏见=没有足够的女性开发技术)可以通过增加女性在技术领域的人数*来解决*。不要误解我。我们当然需要鼓励和支持，但是教育者和学生要让两性都参与 STEM。但我坚信，除非教育、工作和社会系统具有包容性，否则这不可能通过强制性别多样化来实现。

扩展标准“人工智能中的性别问题可以通过让更多女性进入技术领域来解决”论点的五个复杂性:

1/ *为什么选择了*女声，至少根据我的分析，远比 CS 发展中的男性主导问题复杂。既有“硬编码”(即我们对听到女性和男性声音的方式的生物倾向)，也有更多的“软编码”(即设定我们对女性/男性声音及其对我们的意义的观点的社会学条件)。我的[中帖](https://medium.com/voice-tech-podcast/siri-alexa-cortana-and-why-all-boats-are-a-she-e4fb71b6a9f7)对此有更深入的探讨。

2/为了进一步补充这一点，我们不能忘记的是 Siri、Alexa、Cortana 都是纯粹为了盈利的商业产品(苹果并不真正关心社会学影响)。他们知道第一点，因为他们已经测试过了:例如:在英国，Siri 实际上是默认的男性声音，但在德国，司机拒绝在他们的宝马里使用女性声音，因为它不够“权威”。在我们的后现代主义世界中，公司对社会的影响可能比反过来更大，这意味着我们在这个“恶性循环”中有一个次要的复杂因素，即我们继续犯下社会偏见和刻板印象。

让更多的女孩接受 STEM 教育和工作远比坐在教室的椅子上要复杂得多。有证据表明，计算机科学的整个教学都是重男轻女的(也就是说，计算机科学的整个语言及其教学方式更倾向于男性对女性的“认知方式”，这实际上可能是为什么我们在技术领域没有更多女性的根源。[《人工认识》](https://www.amazon.com/Artificial-Knowing-Gender-Thinking-Machine/dp/041512963X)这本书是对这个话题非常优秀的考查。

4/榜样。尽管该领域目前存在性别失衡，但在主流的科技历史记录中，不可否认的是[忽略了女性榜样](https://www.researchgate.net/publication/46513426_Feminist_theories_of_technology)，尽管她们对该领域做出了许多贡献。迄今为止，600 个诺贝尔科学奖中只有 [20 个授予了女性](https://www.pri.org/stories/2019-10-09/only-20-nobels-sciences-have-gone-women-why)——2019 年的获奖者都是男性。在媒体和现实世界中看到杰出的女性成为 STEM 领导者，将是打破当前技术仅仅是男性努力的刻板印象的关键因素。

5/最后，关注“管道”问题(例如，没有足够的女性候选人)是“指责系统”的好方法，然而，它模糊了一个更大的偏见问题(有意识和无意识的)，即在招聘、薪酬和留住女性方面。对超过 98 项实证研究的回顾表明，劳动力中存在系统性问题，导致女性被不成比例地排除在晋升、权威角色和高薪职位之外。此外，从某些方面来看，微妙性别歧视的险峻“男性文化”在今天的科技公司以及 Siri、Alexa 和 Cortana 的开发者中非常猖獗。

对抗多样性的最佳方式不是强迫它，而是创造和培养更具包容性的教育、社会和工作环境，在这样的环境中，每个人的声音都是同等有效的。那是一件不可能的事情——直到我们都相信它是值得的。