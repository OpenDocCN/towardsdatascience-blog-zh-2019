<html>
<head>
<title>[NLP] Performance of Different Word Embeddings on Text Classification</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">[NLP]不同单词嵌入对文本分类的性能</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/nlp-performance-of-different-word-embeddings-on-text-classification-de648c6262b?source=collection_archive---------3-----------------------#2019-07-10">https://towardsdatascience.com/nlp-performance-of-different-word-embeddings-on-text-classification-de648c6262b?source=collection_archive---------3-----------------------#2019-07-10</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><figure class="is it gp gr iu iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi ir"><img src="../Images/dff25694bc33adc3626878b20bf81109.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*mKx0t_8b7PiNtv2l"/></div></div><figcaption class="jc jd gj gh gi je jf bd b be z dk">Photo by <a class="ae jg" href="https://unsplash.com/@kstonematheson?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Kate Stone Matheson</a> on <a class="ae jg" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><div class=""/><div class=""><h2 id="2c82" class="pw-subtitle-paragraph kg ji jj bd b kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx dk translated">在 word2vec、TF-IDF 加权、GloVe 和 doc2vec 之间进行比较</h2></div><h1 id="b803" class="ky kz jj bd la lb lc ld le lf lg lh li kp lj kq lk ks ll kt lm kv ln kw lo lp bi translated">诱因</h1><p id="acf0" class="pw-post-body-paragraph lq lr jj ls b lt lu kk lv lw lx kn ly lz ma mb mc md me mf mg mh mi mj mk ml im bi translated">已经有一段时间不能写新帖了，很难过，但现在我终于又回来分享我刚刚获得的一些知识。这次是关于 NLP 的。</p><p id="4be5" class="pw-post-body-paragraph lq lr jj ls b lt mm kk lv lw mn kn ly lz mo mb mc md mp mf mg mh mq mj mk ml im bi translated">作为 NLP 的新手，我想尝试一下，测试一下创建文档向量的不同方法在文本分类上的表现。这篇文章将高度关注特征工程方面，即单词矢量化，而不是建模。因此，没有进一步的原因，让我们开始吧。</p><h2 id="bb99" class="mr kz jj bd la ms mt dn le mu mv dp li lz mw mx lk md my mz lm mh na nb lo nc bi translated">简介</h2><p id="ed62" class="pw-post-body-paragraph lq lr jj ls b lt lu kk lv lw lx kn ly lz ma mb mc md me mf mg mh mi mj mk ml im bi translated">这里研究的单词嵌入是 word2vec、TF-IDF 加权 word2vec、训练前手套 word2vec 和 doc2vec。需要的软件包是 Gensim、Spacy 和 Scikit-Learn。Spacy 用于文档预处理，包括停用词去除和基于其词性的自定义标记选择。Gensim 主要用于训练 word2vec 和 doc2vec，最后，Scikit-Learn 用于分类器构建和训练。</p><h2 id="3052" class="mr kz jj bd la ms mt dn le mu mv dp li lz mw mx lk md my mz lm mh na nb lo nc bi translated">快速小结</h2><p id="c15b" class="pw-post-body-paragraph lq lr jj ls b lt lu kk lv lw lx kn ly lz ma mb mc md me mf mg mh mi mj mk ml im bi translated">在对不同的单词嵌入/平均方法进行一系列比较后，结果表明<strong class="ls jk">定制训练单词嵌入</strong>及其平均方法，无论是简单均值还是 TF-IDF 加权都具有最佳性能，而相反，手套单词嵌入或定制训练 Doc2vec 的性能略差于前者。</p><p id="fd05" class="pw-post-body-paragraph lq lr jj ls b lt mm kk lv lw mn kn ly lz mo mb mc md mp mf mg mh mq mj mk ml im bi translated">此外，即使我们试图将 word2vec 和 doc2vec 连接成一个完整的特性集，它的性能与只使用平均单词嵌入是一样的。换句话说，不需要同时使用 word2vec 和 doc2vec。</p><h2 id="edbe" class="mr kz jj bd la ms mt dn le mu mv dp li lz mw mx lk md my mz lm mh na nb lo nc bi translated">特别鸣谢以下帖子和作者</h2><p id="1d42" class="pw-post-body-paragraph lq lr jj ls b lt lu kk lv lw lx kn ly lz ma mb mc md me mf mg mh mi mj mk ml im bi translated">在创建我的用于文本预处理的<strong class="ls jk"> python 类对象</strong>时，我参考了这些写得很好的帖子。</p><ul class=""><li id="c2bc" class="nd ne jj ls b lt mm lw mn lz nf md ng mh nh ml ni nj nk nl bi translated">nadbor 的文章<a class="ae jg" href="http://nadbordrozd.github.io/blog/2016/05/20/text-classification-with-word2vec/" rel="noopener ugc nofollow" target="_blank">“使用 Word2vec 的文本分类”</a>演示了如何编写自己的类来计算 doc 的平均单词嵌入，无论是简单平均还是 TF-IDF 加权。</li><li id="cf3f" class="nd ne jj ls b lt nm lw nn lz no md np mh nq ml ni nj nk nl bi translated"><a class="ae jg" rel="noopener" target="_blank" href="/multi-class-text-classification-model-comparison-and-selection-5eb066197568">《多类文本分类模型比较与选择》Susan Li</a>教我如何写出漂亮的平均函数用于单词嵌入。</li><li id="68d9" class="nd ne jj ls b lt nm lw nn lz no md np mh nq ml ni nj nk nl bi translated">本教程<a class="ae jg" href="https://github.com/RaRe-Technologies/gensim/blob/3c3506d51a2caf6b890de3b1b32a8b85f7566ca5/docs/notebooks/doc2vec-IMDB.ipynb" rel="noopener ugc nofollow" target="_blank">“关于 IMDB 情感数据集的 Gensim Doc2vec 教程”</a>对如何通过 Gensim 创建 Doc2vec 进行了逐步指导。</li><li id="27e5" class="nd ne jj ls b lt nm lw nn lz no md np mh nq ml ni nj nk nl bi translated"><a class="ae jg" href="https://blog.acolyer.org/2016/06/01/distributed-representations-of-sentences-and-documents/" rel="noopener ugc nofollow" target="_blank"/>Le&amp;的《句子和文档的分布式表示》Mikolov 对 doc2vec 下发生的事情做了清晰易懂的解释。</li></ul></div><div class="ab cl nr ns hx nt" role="separator"><span class="nu bw bk nv nw nx"/><span class="nu bw bk nv nw nx"/><span class="nu bw bk nv nw"/></div><div class="im in io ip iq"><h1 id="969c" class="ky kz jj bd la lb ny ld le lf nz lh li kp oa kq lk ks ob kt lm kv oc kw lo lp bi translated">数据准备</h1><p id="1ef1" class="pw-post-body-paragraph lq lr jj ls b lt lu kk lv lw lx kn ly lz ma mb mc md me mf mg mh mi mj mk ml im bi translated">我将在这里使用的数据集是帖子[1]中提到的关于金融产品/服务的消费者投诉数据集。数据集由<a class="ae jg" href="https://catalog.data.gov/dataset/consumer-complaint-database" rel="noopener ugc nofollow" target="_blank">美国州长 CFPB </a>收集并发布，同时我们也可以从<a class="ae jg" href="https://www.kaggle.com/cfpb/us-consumer-finance-complaints" rel="noopener ugc nofollow" target="_blank"> Kaggle </a>下载数据集。</p><p id="e488" class="pw-post-body-paragraph lq lr jj ls b lt mm kk lv lw mn kn ly lz mo mb mc md mp mf mg mh mq mj mk ml im bi translated">原始数据集包含 50 多万条记录，列包括<em class="od">产品、子产品、问题、消费者投诉、公司回应消费者等..</em>我们将使用<strong class="ls jk">产品</strong>作为文本标签，使用<strong class="ls jk">消费者 _ 投诉 _ 叙述</strong>作为文本本身。在删除了消费者投诉中的几行缺失值后，我们只剩下大约 6 万条记录。为了减轻计算压力，我将只对前 25000 条记录进行实验。</p><p id="bbea" class="pw-post-body-paragraph lq lr jj ls b lt mm kk lv lw mn kn ly lz mo mb mc md mp mf mg mh mq mj mk ml im bi translated">现在，让我们看看频率是如何在每个标签中分布的。</p><figure class="of og oh oi gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi oe"><img src="../Images/541e2288ba1d708b86e52d524a4271ef.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*YQRZcvPM2iBXVNFx60S6Ug.png"/></div></div><figcaption class="jc jd gj gh gi je jf bd b be z dk">Distribution of Each Label in the Dataset</figcaption></figure><p id="6e65" class="pw-post-body-paragraph lq lr jj ls b lt mm kk lv lw mn kn ly lz mo mb mc md mp mf mg mh mq mj mk ml im bi translated">我们可以看出，这是一个高度不平衡的数据集，其中<strong class="ls jk">讨债和抵押</strong>占总记录的一半，而最稀缺的类别<strong class="ls jk">预付卡和其他金融服务</strong>在数据集中仅占不到 1%。</p><p id="5a89" class="pw-post-body-paragraph lq lr jj ls b lt mm kk lv lw mn kn ly lz mo mb mc md mp mf mg mh mq mj mk ml im bi translated">以下是(标签、文本)示例的演示。</p><figure class="of og oh oi gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi oj"><img src="../Images/4e8f05da5f5b365a78fb474bea16e94d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*L9ncrYHsfQBktOY775OADA.png"/></div></div><figcaption class="jc jd gj gh gi je jf bd b be z dk">Demo of Product(Label), Consumer Complaints(Text)</figcaption></figure></div><div class="ab cl nr ns hx nt" role="separator"><span class="nu bw bk nv nw nx"/><span class="nu bw bk nv nw nx"/><span class="nu bw bk nv nw"/></div><div class="im in io ip iq"><h1 id="3e7f" class="ky kz jj bd la lb ny ld le lf nz lh li kp oa kq lk ks ob kt lm kv oc kw lo lp bi translated">文档预处理</h1><p id="88a2" class="pw-post-body-paragraph lq lr jj ls b lt lu kk lv lw lx kn ly lz ma mb mc md me mf mg mh mi mj mk ml im bi translated">现在是第一步——文档预处理。在我们基于输入文本创建自己的单词嵌入之前，我们需要对文本进行预处理，使其符合 Gensim 要求的输入格式。它包括从单词标记化、二元语法检测、词条化等开始的多个步骤..</p><p id="30a9" class="pw-post-body-paragraph lq lr jj ls b lt mm kk lv lw mn kn ly lz mo mb mc md mp mf mg mh mq mj mk ml im bi translated">在这里，我写了一个名为<strong class="ls jk"> DocProcess </strong>的 python 类。这个类为我们实现了上面提到的所有底层工作，例如:</p><ol class=""><li id="993b" class="nd ne jj ls b lt mm lw mn lz nf md ng mh nh ml ok nj nk nl bi translated">首先，该类接收一系列文本，然后标记文本并删除所有标点符号。</li><li id="d8b6" class="nd ne jj ls b lt nm lw nn lz no md np mh nq ml ok nj nk nl bi translated">它有一个选项<code class="fe ol om on oo b">build_bi</code>，表示是否建立二元语法，函数采用 Gensim。默认值为 False，如果选项<code class="fe ol om on oo b">build_bi</code>设置为 True，那么该类将训练一个双字母检测器并为文本创建双字母单词。</li><li id="c2b9" class="nd ne jj ls b lt nm lw nn lz no md np mh nq ml ok nj nk nl bi translated">现在，所有经过处理的标记被连接起来，再次形成一个句子。</li><li id="46d5" class="nd ne jj ls b lt nm lw nn lz no md np mh nq ml ok nj nk nl bi translated">文本再次被标记化，但这一次，文本中不允许的<strong class="ls jk">停用词</strong>和<strong class="ls jk">词性</strong>都将被移除，所有标记都将被<strong class="ls jk">符号化</strong>。这些标记存储为<code class="fe ol om on oo b">self.doc_words</code> —每个文本的标记列表(doc)。</li><li id="a108" class="nd ne jj ls b lt nm lw nn lz no md np mh nq ml ok nj nk nl bi translated">最后，这些<code class="fe ol om on oo b">self.doc_words</code>被打包成<strong class="ls jk"> TaggedDocument </strong>，这是 Gensim 中的一个对象类型，供以后在 doc2vec 训练中使用。它存放在<code class="fe ol om on oo b">self.tagdocs</code></li></ol><figure class="of og oh oi gt iv"><div class="bz fp l di"><div class="op oq l"/></div><figcaption class="jc jd gj gh gi je jf bd b be z dk">Snippet of Class “DocPreprocess”</figcaption></figure><p id="d438" class="pw-post-body-paragraph lq lr jj ls b lt mm kk lv lw mn kn ly lz mo mb mc md mp mf mg mh mq mj mk ml im bi translated">有了这个类，我只需一行代码就可以轻松实现文档预处理。</p><pre class="of og oh oi gt or oo os ot aw ou bi"><span id="fd48" class="mr kz jj oo b gy ov ow l ox oy">from UtilWordEmbedding import DocPreprocess<br/>import spacy</span><span id="a5ba" class="mr kz jj oo b gy oz ow l ox oy">nlp = spacy.load('en_core_web_md')<br/>stop_words = spacy.lang.en.stop_words.STOP_WORDS</span><span id="ee3a" class="mr kz jj oo b gy oz ow l ox oy">all_docs = DocPreprocess(nlp, stop_words, df['consumer_complaint_narrative'], df['product'])</span></pre><p id="c5da" class="pw-post-body-paragraph lq lr jj ls b lt mm kk lv lw mn kn ly lz mo mb mc md mp mf mg mh mq mj mk ml im bi translated">现在我们来看看 doc 预处理的输出是什么样的。</p><figure class="of og oh oi gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi pa"><img src="../Images/18ef45aa83af9c077b69d409508e6b6c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*72f7tcLoBS9sFIP7OFqCEg.png"/></div></div><figcaption class="jc jd gj gh gi je jf bd b be z dk">The Content Stored in DocPreprocess Class</figcaption></figure><p id="b30c" class="pw-post-body-paragraph lq lr jj ls b lt mm kk lv lw mn kn ly lz mo mb mc md mp mf mg mh mq mj mk ml im bi translated">从上面我们可以看出，这个类已经存储了标记化的单词、标签和标记文档，这些都可以在以后使用。</p></div><div class="ab cl nr ns hx nt" role="separator"><span class="nu bw bk nv nw nx"/><span class="nu bw bk nv nw nx"/><span class="nu bw bk nv nw"/></div><div class="im in io ip iq"><h1 id="2584" class="ky kz jj bd la lb ny ld le lf nz lh li kp oa kq lk ks ob kt lm kv oc kw lo lp bi translated">单词模型— Word2vec 培训</h1><p id="a95d" class="pw-post-body-paragraph lq lr jj ls b lt lu kk lv lw lx kn ly lz ma mb mc md me mf mg mh mi mj mk ml im bi translated">由于文本被正确处理，我们准备通过 Gensim 训练我们的 word2vec。在这里，我为每个单词的嵌入选择了尺寸 100，窗口尺寸为 5。训练迭代 100 次。</p><pre class="of og oh oi gt or oo os ot aw ou bi"><span id="8305" class="mr kz jj oo b gy ov ow l ox oy">word_model = Word2Vec(all_docs.doc_words, min_count=2, size=100, window=5, workers=workers, iter=100)</span></pre><figure class="of og oh oi gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi pb"><img src="../Images/eadb8c6790342d06400c52de5bdb5886.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*Hs3CQiblxcv0Kj0z"/></div></div><figcaption class="jc jd gj gh gi je jf bd b be z dk">Photo by <a class="ae jg" href="https://unsplash.com/@epicantus?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Daria Nepriakhina</a> on <a class="ae jg" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><blockquote class="pc"><p id="afda" class="pd pe jj bd pf pg ph pi pj pk pl ml dk translated">现在是休息时间，很快，让我们继续…</p></blockquote><h1 id="2af4" class="ky kz jj bd la lb lc ld le lf lg lh li kp pm kq lk ks pn kt lm kv po kw lo lp bi translated">每个文档的平均单词嵌入</h1><p id="efde" class="pw-post-body-paragraph lq lr jj ls b lt lu kk lv lw lx kn ly lz ma mb mc md me mf mg mh mi mj mk ml im bi translated">好吧！现在我们手头有了单词嵌入，我们将使用单词嵌入来计算整个文本的代表向量。然后作为文本分类模型的特征输入。有多种方法可以得出 doc vector。首先，我们从简单的开始。</p><h2 id="3616" class="mr kz jj bd la ms mt dn le mu mv dp li lz mw mx lk md my mz lm mh na nb lo nc bi translated">(1)对单词嵌入的简单平均</h2><p id="3d3b" class="pw-post-body-paragraph lq lr jj ls b lt lu kk lv lw lx kn ly lz ma mb mc md me mf mg mh mi mj mk ml im bi translated">这是一个相当简单的方法。它直接对文本中出现的所有单词嵌入进行平均。在这里，我改编了这两篇文章[2][3]中的代码，并创建了类<strong class="ls jk">meanwodembedding vectorizer</strong>。</p><figure class="of og oh oi gt iv"><div class="bz fp l di"><div class="op oq l"/></div><figcaption class="jc jd gj gh gi je jf bd b be z dk">Class of MeanWordEmbeddingVectorizer</figcaption></figure><p id="3cd7" class="pw-post-body-paragraph lq lr jj ls b lt mm kk lv lw mn kn ly lz mo mb mc md mp mf mg mh mq mj mk ml im bi translated">它有<code class="fe ol om on oo b">self.fit()</code>和<code class="fe ol om on oo b">self.transform()</code>方法，以便与 scikit-learn 中的其他功能兼容。这个类做的事情相当简单。使用单词模型(训练单词嵌入)初始化该类，然后它可以将文本中的所有标记转换为向量，并进行平均以得出代表性的 doc 向量。如果 doc 没有标记，那么它将返回一个零向量。</p><p id="fcbb" class="pw-post-body-paragraph lq lr jj ls b lt mm kk lv lw mn kn ly lz mo mb mc md mp mf mg mh mq mj mk ml im bi translated">只是提醒一下，<code class="fe ol om on oo b">self.transform()</code>的输入必须是文档标记列表，而不是文档文本本身。</p><pre class="of og oh oi gt or oo os ot aw ou bi"><span id="7f65" class="mr kz jj oo b gy ov ow l ox oy">from UtilWordEmbedding import MeanEmbeddingVectorizer</span><span id="c268" class="mr kz jj oo b gy oz ow l ox oy">mean_vec_tr = MeanEmbeddingVectorizer(word_model)<br/>doc_vec = mean_vec_tr.transform(all_docs.doc_words)</span></pre><h2 id="e81e" class="mr kz jj bd la ms mt dn le mu mv dp li lz mw mx lk md my mz lm mh na nb lo nc bi translated">(2)单词嵌入的 TF-IDF 加权平均</h2><p id="e08c" class="pw-post-body-paragraph lq lr jj ls b lt lu kk lv lw lx kn ly lz ma mb mc md me mf mg mh mi mj mk ml im bi translated">不仅仅满足于简单的平均？我们可以进一步采用 TF-IDF 作为每个单词嵌入的权重。这将放大有效词在计算文档向量中的作用。这里，整个过程是在类<strong class="ls jk">TfidfEmbeddingVectorizer</strong>下实现的。同样，代码改编自相同的帖子源。</p><p id="159e" class="pw-post-body-paragraph lq lr jj ls b lt mm kk lv lw mn kn ly lz mo mb mc md mp mf mg mh mq mj mk ml im bi translated">值得注意的一点是，我们在对文本进行平均时已经考虑到了<strong class="ls jk">词频</strong>，而没有考虑到<strong class="ls jk">逆文档频率</strong>，因此权重字面上就是 IDF，默认设置中未看到的词被赋予最大 IDF。代码片段可以在<a class="ae jg" href="https://gist.github.com/TomLin/30244bcccb7e4f94d191a878a697f698" rel="noopener ugc nofollow" target="_blank"> this gist </a>中查看。</p><p id="ce68" class="pw-post-body-paragraph lq lr jj ls b lt mm kk lv lw mn kn ly lz mo mb mc md mp mf mg mh mq mj mk ml im bi translated">另一件要注意的事情是，我们需要先用标记来<strong class="ls jk">拟合类，因为它必须事先遍历所有单词，以便计算 IDF。</strong></p><pre class="of og oh oi gt or oo os ot aw ou bi"><span id="d618" class="mr kz jj oo b gy ov ow l ox oy">from UtilWordEmbedding import TfidfEmbeddingVectorizer</span><span id="ee7d" class="mr kz jj oo b gy oz ow l ox oy">tfidf_vec_tr = TfidfEmbeddingVectorizer(word_model)<br/>tfidf_vec_tr.fit(all_docs.doc_words)  # fit tfidf model first<br/>tfidf_doc_vec = tfidf_vec_tr.transform(all_docs.doc_words)</span></pre><h2 id="4f90" class="mr kz jj bd la ms mt dn le mu mv dp li lz mw mx lk md my mz lm mh na nb lo nc bi translated">(3)利用预训练手套单词嵌入</h2><p id="bac8" class="pw-post-body-paragraph lq lr jj ls b lt lu kk lv lw lx kn ly lz ma mb mc md me mf mg mh mi mj mk ml im bi translated">让我们包括另一个选项—利用现有的预训练单词嵌入，看看它在文本分类中的表现如何。在这里，我按照<a class="ae jg" href="http://web.stanford.edu/class/cs224n/materials/Gensim%20word%20vector%20visualization.html" rel="noopener ugc nofollow" target="_blank">斯坦福大学自然语言处理课程(CS224N)笔记本</a>的说明，将 GloVe word embedding 导入 Gensim 进行计算，以计算文本上的平均单词嵌入。</p><p id="d385" class="pw-post-body-paragraph lq lr jj ls b lt mm kk lv lw mn kn ly lz mo mb mc md mp mf mg mh mq mj mk ml im bi translated">顺便说一句，我还尝试对手套向量应用 TF-IDF 加权方法，但发现结果与 Tf-IDF 加权平均 doc 向量的结果基本相同。因此，我省略了演示，这里只包括手套字向量的简单平均。</p><pre class="of og oh oi gt or oo os ot aw ou bi"><span id="e3ee" class="mr kz jj oo b gy ov ow l ox oy"># Apply word averaging on GloVe word vector.<br/>glove_mean_vec_tr = MeanEmbeddingVectorizer(glove_word_model)<br/>glove_doc_vec = glove_mean_vec_tr.transform(all_docs.doc_words)</span></pre><h2 id="1c05" class="mr kz jj bd la ms mt dn le mu mv dp li lz mw mx lk md my mz lm mh na nb lo nc bi translated">(4)直接应用 Doc2vec 培训</h2><p id="56cd" class="pw-post-body-paragraph lq lr jj ls b lt lu kk lv lw lx kn ly lz ma mb mc md me mf mg mh mi mj mk ml im bi translated">最后但同样重要的是，我们还有一个选择—直接训练 doc2vec，不需要对所有单词嵌入进行平均。这里我选择了<strong class="ls jk"> PV-DM 型号</strong>来训练我的 doc2vec。</p><p id="ef63" class="pw-post-body-paragraph lq lr jj ls b lt mm kk lv lw mn kn ly lz mo mb mc md mp mf mg mh mq mj mk ml im bi translated">该脚本主要参考自 Gensim 教程[4]。同样，为了节省所有的劳动，我为它创建了一个类<strong class="ls jk"> DocModel </strong>。这个类只需要接受<strong class="ls jk"> TaggedDocument </strong>然后我们调用<code class="fe ol om on oo b">self.custom_train()</code>方法，doc 模型会自己训练。</p><figure class="of og oh oi gt iv"><div class="bz fp l di"><div class="op oq l"/></div><figcaption class="jc jd gj gh gi je jf bd b be z dk">Class of DocModel</figcaption></figure><p id="51dc" class="pw-post-body-paragraph lq lr jj ls b lt mm kk lv lw mn kn ly lz mo mb mc md mp mf mg mh mq mj mk ml im bi translated">注意到<code class="fe ol om on oo b">self.custom_train()</code>可以选择使用<em class="od">固定学习率</em>。据说固定的学习速率达到更好的效果[5]如这里所引用的，</p><blockquote class="pp pq pr"><p id="45a6" class="lq lr od ls b lt mm kk lv lw mn kn ly ps mo mb mc pt mp mf mg pu mq mj mk ml im bi translated">1.随机化输入句子的顺序，或者</p><p id="b928" class="lq lr od ls b lt mm kk lv lw mn kn ly ps mo mb mc pt mp mf mg pu mq mj mk ml im bi translated">2.在几次迭代过程中手动控制学习速率。</p></blockquote><p id="e67b" class="pw-post-body-paragraph lq lr jj ls b lt mm kk lv lw mn kn ly lz mo mb mc md mp mf mg mh mq mj mk ml im bi translated">但这并没有发生在我的实验中。当我手动降低学习率时(下面的代码)，我发现 doc2vec 模型不能正确推断最相似的 doc。也就是说，如果我输入来自同一个文档的<em class="od">文档向量</em>,<code class="fe ol om on oo b">self.test_orig_doc_infer()</code>不会返回与最相似文档相同的文档，尽管它应该这样做。</p><p id="a3c9" class="pw-post-body-paragraph lq lr jj ls b lt mm kk lv lw mn kn ly lz mo mb mc md mp mf mg mh mq mj mk ml im bi translated">顺便提一下，<code class="fe ol om on oo b">self.test_orig_doc_infer()</code>方法用于测试给定来自原始文档的<em class="od">文档向量</em>的预测文档是否确实返回与最相似文档相同的文档。如果是这样，我们可以公平地判断该模型成功地捕捉了整个文档的隐含意义，从而给出了具有代表性的文档向量。</p><pre class="of og oh oi gt or oo os ot aw ou bi"><span id="53bc" class="mr kz jj oo b gy ov ow l ox oy"># Failed Attempt (Not achieving better result.)<br/>for _ in range(fixed_lr_epochs):<br/>   self.model.train(utils.shuffle([x for x in self.docs]),<br/>                total_examples=len(self.docs),<br/>                epochs=1)<br/>   self.model.alpha -= 0.002<br/>   self.model.min_alpha = self.model.alpha  # fixed learning rate</span></pre><p id="8834" class="pw-post-body-paragraph lq lr jj ls b lt mm kk lv lw mn kn ly lz mo mb mc md mp mf mg mh mq mj mk ml im bi translated">因此，相反，只保留默认设置就足以达到更好的效果。这里，学习率被设置为 0.025，训练时期为 100，并且应用负采样。</p><pre class="of og oh oi gt or oo os ot aw ou bi"><span id="3ad5" class="mr kz jj oo b gy ov ow l ox oy">from UtilWordEmbedding import DocModel</span><span id="53ad" class="mr kz jj oo b gy oz ow l ox oy"># Configure keyed arguments for Doc2Vec model.<br/>dm_args = {<br/>    'dm': 1,<br/>    'dm_mean': 1,<br/>    'vector_size': 100,<br/>    'window': 5,<br/>    'negative': 5,<br/>    'hs': 0,<br/>    'min_count': 2,<br/>    'sample': 0,<br/>    'workers': workers,<br/>    'alpha': 0.025,<br/>    'min_alpha': 0.025,<br/>    'epochs': 100,<br/>    'comment': 'alpha=0.025'<br/>}</span><span id="c273" class="mr kz jj oo b gy oz ow l ox oy"># Instantiate a pv-dm model.<br/>dm = DocModel(docs=all_docs.tagdocs, **dm_args)</span><span id="2cee" class="mr kz jj oo b gy oz ow l ox oy">dm.custom_train()</span></pre><h2 id="8baa" class="mr kz jj bd la ms mt dn le mu mv dp li lz mw mx lk md my mz lm mh na nb lo nc bi translated">(5)标签</h2><p id="832c" class="pw-post-body-paragraph lq lr jj ls b lt lu kk lv lw lx kn ly lz ma mb mc md me mf mg mh mi mj mk ml im bi translated">最后，不要忘记标签！！！</p><pre class="of og oh oi gt or oo os ot aw ou bi"><span id="9cf0" class="mr kz jj oo b gy ov ow l ox oy">target_labels = all_docs.labels</span></pre></div><div class="ab cl nr ns hx nt" role="separator"><span class="nu bw bk nv nw nx"/><span class="nu bw bk nv nw nx"/><span class="nu bw bk nv nw"/></div><div class="im in io ip iq"><h1 id="7e84" class="ky kz jj bd la lb ny ld le lf nz lh li kp oa kq lk ks ob kt lm kv oc kw lo lp bi translated">准备分类模型</h1><p id="0e70" class="pw-post-body-paragraph lq lr jj ls b lt lu kk lv lw lx kn ly lz ma mb mc md me mf mg mh mi mj mk ml im bi translated">现在，我们已经准备好了所有必要的材料——不同类型的功能。让我们通过实验来观察它们对分类性能的影响。在这里，我将使用<strong class="ls jk">基本逻辑模型</strong>作为基础模型，并加入之前创建的不同类型的特征。因此，要比较它们的有效性。</p><p id="1404" class="pw-post-body-paragraph lq lr jj ls b lt mm kk lv lw mn kn ly lz mo mb mc md mp mf mg mh mq mj mk ml im bi translated">除了比较每种单词嵌入平均方法的效果，我还尝试将 word2vec 和 doc2vec 连接在一起，看看它是否能进一步提升性能。</p><p id="298d" class="pw-post-body-paragraph lq lr jj ls b lt mm kk lv lw mn kn ly lz mo mb mc md mp mf mg mh mq mj mk ml im bi translated">我一起用了 TF-IDF 加权词嵌入和 PV-DM doc2vec。结果表明，它提高了训练数据集的准确性(也许是过拟合的标志？)，但与单独使用 TF-IDF word2vec 相比，在测试数据集上没有显著改善。</p><h1 id="dc39" class="ky kz jj bd la lb lc ld le lf lg lh li kp lj kq lk ks ll kt lm kv ln kw lo lp bi translated">反光</h1><p id="daba" class="pw-post-body-paragraph lq lr jj ls b lt lu kk lv lw lx kn ly lz ma mb mc md me mf mg mh mi mj mk ml im bi translated">我们来考察一下哪个单词嵌入的表现最差。令人惊讶的是，预训练手套单词嵌入和 doc2vec 在文本分类上的表现相对较差，准确率分别为 0.73 和 0.78，其他都在 0.8 以上。也许，这是因为定制训练的 word2vec 特别适合这个数据集，因此为手头的文档提供了最相关的信息。</p><p id="361a" class="pw-post-body-paragraph lq lr jj ls b lt mm kk lv lw mn kn ly lz mo mb mc md mp mf mg mh mq mj mk ml im bi translated">这并不一定意味着我们不应该再使用 GloVe word embedding 或 doc2vec，因为在推理阶段，我们可能会遇到单词模型中没有单词嵌入的新单词。在这种情况下，手套单词嵌入将对其在宽词汇量上的覆盖有很大帮助。</p><p id="c780" class="pw-post-body-paragraph lq lr jj ls b lt mm kk lv lw mn kn ly lz mo mb mc md mp mf mg mh mq mj mk ml im bi translated">至于 doc2vec，我们可以说它可以帮助训练好的单词嵌入来进一步提高文本分类模型的性能，尽管它很小，也很适合选择退出。</p><figure class="of og oh oi gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi pv"><img src="../Images/a7384b7a48e684069ada5477febe8312.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*O4SNyLs1gti3phbveo3Llw.png"/></div></div><figcaption class="jc jd gj gh gi je jf bd b be z dk">Table of Classification Performance over Different Word Embedding</figcaption></figure><p id="1c9e" class="pw-post-body-paragraph lq lr jj ls b lt mm kk lv lw mn kn ly lz mo mb mc md mp mf mg mh mq mj mk ml im bi translated">完整的 jupyter 笔记本可以在<a class="ae jg" href="https://github.com/TomLin/Playground/blob/master/04-Model-Comparison-Word2vec-Doc2vec-TfIdfWeighted.ipynb" rel="noopener ugc nofollow" target="_blank">这个链接</a>下找到。</p></div><div class="ab cl nr ns hx nt" role="separator"><span class="nu bw bk nv nw nx"/><span class="nu bw bk nv nw nx"/><span class="nu bw bk nv nw"/></div><div class="im in io ip iq"><h2 id="09c5" class="mr kz jj bd la ms mt dn le mu mv dp li lz mw mx lk md my mz lm mh na nb lo nc bi translated">参考</h2><p id="c9b9" class="pw-post-body-paragraph lq lr jj ls b lt lu kk lv lw lx kn ly lz ma mb mc md me mf mg mh mi mj mk ml im bi translated">[1] Susan Li，<a class="ae jg" rel="noopener" target="_blank" href="/multi-class-text-classification-with-doc2vec-logistic-regression-9da9947b43f4">用 Doc2Vec 进行多类文本分类&amp; Logistic 回归</a> (2018)，<em class="od">走向数据科学</em></p><p id="a08c" class="pw-post-body-paragraph lq lr jj ls b lt mm kk lv lw mn kn ly lz mo mb mc md mp mf mg mh mq mj mk ml im bi translated">[2]纳德博尔，<a class="ae jg" href="http://nadbordrozd.github.io/blog/2016/05/20/text-classification-with-word2vec/" rel="noopener ugc nofollow" target="_blank">文字分类用 Word2Vec </a> (2016)，<em class="od"> DS 绝杀</em></p><p id="4e9f" class="pw-post-body-paragraph lq lr jj ls b lt mm kk lv lw mn kn ly lz mo mb mc md mp mf mg mh mq mj mk ml im bi translated">[3]苏珊·李，<a class="ae jg" rel="noopener" target="_blank" href="/multi-class-text-classification-model-comparison-and-selection-5eb066197568">多类文本分类模型比较与选择</a> (2018)，<em class="od">走向数据科学</em></p><p id="850b" class="pw-post-body-paragraph lq lr jj ls b lt mm kk lv lw mn kn ly lz mo mb mc md mp mf mg mh mq mj mk ml im bi translated">[4] <a class="ae jg" href="https://github.com/RaRe-Technologies/gensim/blob/3c3506d51a2caf6b890de3b1b32a8b85f7566ca5/docs/notebooks/doc2vec-IMDB.ipynb" rel="noopener ugc nofollow" target="_blank"> Gensim Doc2Vec 关于 IMDB 情感数据集的教程</a>(2018)<em class="od">github</em></p><p id="3e10" class="pw-post-body-paragraph lq lr jj ls b lt mm kk lv lw mn kn ly lz mo mb mc md mp mf mg mh mq mj mk ml im bi translated">[5]雷迪姆·řehůřek's，<a class="ae jg" href="https://rare-technologies.com/doc2vec-tutorial/" rel="noopener ugc nofollow" target="_blank"> Doc2vec 教程</a> (2014)，<em class="od">稀有技术</em></p></div></div>    
</body>
</html>