<html>
<head>
<title>Multivariable time series forecasting using Stateless Neural Networks</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用无状态神经网络的多变量时间序列预测</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/multivariable-time-series-forecasting-using-stateless-neural-networks-e88afdd5cd82?source=collection_archive---------9-----------------------#2019-08-27">https://towardsdatascience.com/multivariable-time-series-forecasting-using-stateless-neural-networks-e88afdd5cd82?source=collection_archive---------9-----------------------#2019-08-27</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><p id="f5ff" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">用无状态深度学习辅助目标变量的多变量预测。</p></div><div class="ab cl ko kp hx kq" role="separator"><span class="kr bw bk ks kt ku"/><span class="kr bw bk ks kt ku"/><span class="kr bw bk ks kt"/></div><div class="im in io ip iq"><figure class="kw kx ky kz gt la gh gi paragraph-image"><div role="button" tabindex="0" class="lb lc di ld bf le"><div class="gh gi kv"><img src="../Images/bd0fb771b5f75f1e416cb7c763a30cf9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*ClAOhtPIWe5gTk3M"/></div></div><figcaption class="lh li gj gh gi lj lk bd b be z dk">Photo by <a class="ae ll" href="https://unsplash.com/@jontyson?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Jon Tyson</a> on <a class="ae ll" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><h1 id="6283" class="lm ln it bd lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj bi translated">有辅助变量的时间序列预测</h1><p id="4a9f" class="pw-post-body-paragraph jq jr it js b jt mk jv jw jx ml jz ka kb mm kd ke kf mn kh ki kj mo kl km kn im bi mp translated">输入法系列。带有时间元素的数据集。这样的数据允许我们思考时间序列的<strong class="js iu"> <em class="my"> 2 </em> </strong> <em class="my">属性</em>的组合:</p><ol class=""><li id="949b" class="mz na it js b jt ju jx jy kb nb kf nc kj nd kn ne nf ng nh bi translated"><strong class="js iu">季节性</strong> —在特定时间长度内倾向于反复重复的数据模式。</li><li id="6c36" class="mz na it js b jt ni jx nj kb nk kf nl kj nm kn ne nf ng nh bi translated"><strong class="js iu">趋势</strong> —这类似于回归，我们正在捕捉系列的全局模式。</li><li id="81c5" class="mz na it js b jt ni jx nj kb nk kf nl kj nm kn ne nf ng nh bi translated">数据的相关性趋向于<em class="my">以</em> <em class="my">当前时间为中心，</em>表示过去，接近当前时间的数据影响更大，越接近当前数据未来预测的准确性越好(熵<em class="my">原理</em>)。</li></ol><figure class="kw kx ky kz gt la gh gi paragraph-image"><div class="gh gi nn"><img src="../Images/0ea35617cb94df9f5fb8f0cf755c6b59.png" data-original-src="https://miro.medium.com/v2/resize:fit:1340/format:webp/1*ciU5nqeSKJtTJ0PtBBU3Mw.png"/></div></figure><p id="9ba4" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi mp translated">这样的组合使得时间序列变得特别。某一时间点的数据取决于之前的数据。直觉上，这是事件的<em class="my">因果</em>本质，比如你正在阅读的单词基于之前的单词有意义。</p><p id="98c0" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">通常情况下，机器学习只捕捉趋势，这使得训练时间序列上的典型机器学习模型非常昂贵。</p></div><div class="ab cl ko kp hx kq" role="separator"><span class="kr bw bk ks kt ku"/><span class="kr bw bk ks kt ku"/><span class="kr bw bk ks kt"/></div><div class="im in io ip iq"><h1 id="06f5" class="lm ln it bd lo lp no lr ls lt np lv lw lx nq lz ma mb nr md me mf ns mh mi mj bi translated">用支持变量预测单个变量</h1><p id="ec51" class="pw-post-body-paragraph jq jr it js b jt mk jv jw jx ml jz ka kb mm kd ke kf mn kh ki kj mo kl km kn im bi mp translated"><span class="l mq mr ms bm mt mu mv mw mx di"> N </span>通常预测一个<em class="my">单变量</em>需要创建一个模型，该模型是以前时间数据的函数。这就是所谓的<em class="my">单变量自回归。</em></p><figure class="kw kx ky kz gt la gh gi paragraph-image"><div class="gh gi nt"><img src="../Images/8076a0a6f1c46b9f7bfdad1ed645de02.png" data-original-src="https://miro.medium.com/v2/resize:fit:306/format:webp/1*HltwJpgMUFSiUi0yBFl_0w.png"/></div><figcaption class="lh li gj gh gi lj lk bd b be z dk">[1]Autoregression formula. (Wikipedia)</figcaption></figure><p id="0a0f" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">上图是一个自回归公式的例子。[1]</p><p id="ec2c" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">我们不会深入研究公式的细节，但请注意 ff 变量:</p><figure class="kw kx ky kz gt la gh gi paragraph-image"><div class="gh gi nu"><img src="../Images/726b2becb06f29180b466de5b2614a5b.png" data-original-src="https://miro.medium.com/v2/resize:fit:144/format:webp/1*hFuE2LmHzqTp9wg4V5GRIg.png"/></div></figure><p id="bfaa" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">→ <strong class="js iu">因变量</strong>。目前数据的价值。</p><figure class="kw kx ky kz gt la gh gi paragraph-image"><div class="gh gi nu"><img src="../Images/236614f964af33932ca95cfee1a17ebd.png" data-original-src="https://miro.medium.com/v2/resize:fit:144/format:webp/1*ahEL06MssH3N73drWqN6sg.png"/></div></figure><p id="4760" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">→ <strong class="js iu">自变量</strong>。注意<em class="my">之前的数据</em>是变量的给定值。</p><p id="a34a" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">其余的是提高模型精确度的附加参数和变量。</p><p id="6ef1" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">但是如果我们有额外的与目标变量相关的假设变量呢？这些可以通过适当的建模提高我们需要的目标变量的准确性。</p></div><div class="ab cl ko kp hx kq" role="separator"><span class="kr bw bk ks kt ku"/><span class="kr bw bk ks kt ku"/><span class="kr bw bk ks kt"/></div><div class="im in io ip iq"><h1 id="ad47" class="lm ln it bd lo lp no lr ls lt np lv lw lx nq lz ma mb nr md me mf ns mh mi mj bi translated">算法和模型</h1><p id="88df" class="pw-post-body-paragraph jq jr it js b jt mk jv jw jx ml jz ka kb mm kd ke kf mn kh ki kj mo kl km kn im bi mp translated"><span class="l mq mr ms bm mt mu mv mw mx di"> W </span>一想到时间序列，马上想到 LSTMs、GRUs 等<em class="my">递归神经网络</em>。但是在这种情况下，我们拒绝这样做，而是依靠<em class="my">前馈神经网络</em>。为什么呢？让我们举例说明这两者以及我为什么选择后者:</p><ol class=""><li id="8865" class="mz na it js b jt ju jx jy kb nb kf nc kj nd kn ne nf ng nh bi translated"><strong class="js iu">递归神经网络— </strong>这些图的输出反馈到输入。随着推理的进行，网络的输出被存储为状态，准备在下一个时间步进行推理。</li></ol><figure class="kw kx ky kz gt la gh gi paragraph-image"><div role="button" tabindex="0" class="lb lc di ld bf le"><div class="gh gi nv"><img src="../Images/63500d02f2284f5eabbe91a255975dfa.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*fDV9INjZlKJeFkU5OUsRSw.png"/></div></div><figcaption class="lh li gj gh gi lj lk bd b be z dk">RNN and its states through time. Source: <a class="ae ll" href="https://upload.wikimedia.org/wikipedia/commons/e/ee/Unfold_through_time.png" rel="noopener ugc nofollow" target="_blank">https://upload.wikimedia.org/wikipedia/commons/e/ee/Unfold_through_time.png</a></figcaption></figure><p id="6d39" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">循环网络试图通过以下方式预测下一个时间步长:</p><ol class=""><li id="6995" class="mz na it js b jt ju jx jy kb nb kf nc kj nd kn ne nf ng nh bi translated"><em class="my">在</em> →实际输入值在<em class="my">时刻</em></li><li id="878d" class="mz na it js b jt ni jx nj kb nk kf nl kj nm kn ne nf ng nh bi translated"><em class="my">Xt</em>→RNN 或模型预测的先前状态</li></ol><p id="3874" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">利用上述变量，网络通过最小化<em class="my">建模数据</em>和<em class="my">实际数据之间的误差来实现其预测能力。</em>但是，请注意，随着 RNN 穿过不同的时态数据，预测模型的误差会增加。</p><figure class="kw kx ky kz gt la gh gi paragraph-image"><div role="button" tabindex="0" class="lb lc di ld bf le"><div class="gh gi nw"><img src="../Images/e39fdc1dcfe9aeebbb4023cf80390e9d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*7BE1dq9G55dA1Nt0MxalLg.png"/></div></div><figcaption class="lh li gj gh gi lj lk bd b be z dk">Continuous state transformation worsens the transformation through time.</figcaption></figure><p id="505a" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">LSTMs 和 GRUs 似乎解决了这个问题，因为它包含接受或忘记被认为不相关的先前数据的门。然而，这些门和数据转换不能具体控制到时序分析的一个关键方面:各种<em class="my">时间状态</em>如何相互关联。</p><p id="66c0" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">在下图中，时间步长变成了一个带有激活函数的单元格的向量。因此，捕获的时间步长与目标未来步长之间的关系。</p><figure class="kw kx ky kz gt la gh gi paragraph-image"><div class="gh gi nx"><img src="../Images/30a0cdc10504cba8d337eaa7180164be.png" data-original-src="https://miro.medium.com/v2/resize:fit:1260/format:webp/1*Quj2tPSm2dt5LM-coa8I2Q.png"/></div><figcaption class="lh li gj gh gi lj lk bd b be z dk">Feedforward network that relates various timesteps vs the next timestep</figcaption></figure><p id="20a7" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">然后，我们可以针对管道和设计的模型的具体细节，进行适当的实现。</p></div><div class="ab cl ko kp hx kq" role="separator"><span class="kr bw bk ks kt ku"/><span class="kr bw bk ks kt ku"/><span class="kr bw bk ks kt"/></div><div class="im in io ip iq"><h1 id="6508" class="lm ln it bd lo lp no lr ls lt np lv lw lx nq lz ma mb nr md me mf ns mh mi mj bi translated"><strong class="ak">实施</strong></h1><p id="f7ce" class="pw-post-body-paragraph jq jr it js b jt mk jv jw jx ml jz ka kb mm kd ke kf mn kh ki kj mo kl km kn im bi translated">完整的代码实现位于 https://github.com/arjay55/time_series_stateless.git<a class="ae ll" href="https://github.com/arjay55/time_series_stateless.git" rel="noopener ugc nofollow" target="_blank">的 Github 上</a></p><p id="5212" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu">一、图书馆</strong></p><p id="78eb" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">这些库主要包括 ff:</p><ol class=""><li id="1204" class="mz na it js b jt ju jx jy kb nb kf nc kj nd kn ne nf ng nh bi translated"><strong class="js iu">熊猫→ </strong>进行数据准备</li><li id="9170" class="mz na it js b jt ni jx nj kb nk kf nl kj nm kn ne nf ng nh bi translated"><strong class="js iu"> Scikit-learn (sklearn)和 scipy </strong> →用于外部损失功能和缩放</li><li id="2645" class="mz na it js b jt ni jx nj kb nk kf nl kj nm kn ne nf ng nh bi translated"><strong class="js iu"> seaborn → </strong>用于热图可视化</li><li id="dfc1" class="mz na it js b jt ni jx nj kb nk kf nl kj nm kn ne nf ng nh bi translated"><strong class="js iu"> skopt </strong> →包含贝叶斯优化的优化模块。我们将在训练中使用它进行超参数调整。</li><li id="10df" class="mz na it js b jt ni jx nj kb nk kf nl kj nm kn ne nf ng nh bi translated"><strong class="js iu"> TensorFlow </strong> →深度学习开源库。我们用的是最新版本，<em class="my"> tensorflow-beta1。</em></li></ol></div><div class="ab cl ko kp hx kq" role="separator"><span class="kr bw bk ks kt ku"/><span class="kr bw bk ks kt ku"/><span class="kr bw bk ks kt"/></div><div class="im in io ip iq"><p id="3c4a" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu">二。数据准备</strong></p><p id="4086" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">出于数据隐私的考虑，我们将只加载规范化的数据集。</p><p id="1105" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">首先，我们加载规范化的数据集。</p><figure class="kw kx ky kz gt la"><div class="bz fp l di"><div class="ny nz l"/></div></figure><figure class="kw kx ky kz gt la gh gi paragraph-image"><div class="gh gi oa"><img src="../Images/f44ae7e0fa46622328b9276a3c0e909c.png" data-original-src="https://miro.medium.com/v2/resize:fit:832/format:webp/1*1ms5uXdi0_LeMMSRJubycA.png"/></div><figcaption class="lh li gj gh gi lj lk bd b be z dk">Snip of the Dataframe. Note the missing data on <strong class="bd ob"><em class="oc">inflation </em></strong>column</figcaption></figure><p id="0931" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">检查数据帧后，我们有 3 列<br/> 1。<strong class="js iu"> mutual_unit </strong> →这是信托基金单位，可兑换为投资货币。它的价值越高，你的投资回报就越多。<br/> 2。这是一个公司中不同公司股票价格的综合指数。<br/> 3。<strong class="js iu">通货膨胀</strong> →特定国家的通货膨胀率。</p><p id="0ac5" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">选择这些变量是因为它们代表了一个特定国家的财政状况。</p><p id="dfe2" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">请注意，<em class="my">通货膨胀</em>列有许多空值或空值。一种技术是用假设值填充数据:<br/> 1。数据集的最高和最低索引中的线性插值。<br/> 2。超越最远指数的 ARIMA 外推。为什么？仅使用 2 个预测步骤来模拟外部部分更容易。</p><figure class="kw kx ky kz gt la"><div class="bz fp l di"><div class="ny nz l"/></div></figure><p id="827d" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">我们将文件保存到一个 csv 文件中，以供另一种编程语言 r 使用。我选择使用它，因为它的<em class="my">“auto-ARIMA”</em>函数与 Python 的同类函数相比更流行、更成熟。</p><p id="1355" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">我们将有 2 个输出:<br/> 1。倒排[2]值到<strong class="js iu"> <em class="my"> x </em> </strong>步骤→“<em class="my">倒排</em>”表示向后预测，或者简单地反转时间序列并执行预测。<br/> 2。预测值→y<strong class="js iu"><em class="my"/></strong>步骤→平时预测。</p><p id="9840" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><em class="my"> x </em>和<em class="my"> y </em>值由函数<strong class="js iu"> get_outernan </strong>确定，而<strong class="js iu"> fill_data </strong>用假定值填充缺失数据。</p><figure class="kw kx ky kz gt la"><div class="bz fp l di"><div class="ny nz l"/></div></figure><p id="b307" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">在<em class="my"> Rstudio </em>中，我们加载插值膨胀数据集并执行简单的 ARIMA:</p><figure class="kw kx ky kz gt la"><div class="bz fp l di"><div class="ny nz l"/></div></figure><ul class=""><li id="1a67" class="mz na it js b jt ju jx jy kb nb kf nc kj nd kn od nf ng nh bi translated">在<em class="my">预报中，</em>常规 ARIMA 已经完成</li><li id="fe06" class="mz na it js b jt ni jx nj kb nk kf nl kj nm kn od nf ng nh bi translated">在<em class="my">“回显”中，</em>注意在时间序列<em class="my"> ts() </em>函数之前使用<em class="my"> rev() </em>函数将数据转换为时间序列。</li><li id="accf" class="mz na it js b jt ni jx nj kb nk kf nl kj nm kn od nf ng nh bi translated">get <strong class="js iu"> get_outernan </strong>函数返回值<em class="my"> (6，15)，</em>，其中分别是<em class="my">回测</em>和<em class="my">预测</em>的步数。</li></ul></div><div class="ab cl ko kp hx kq" role="separator"><span class="kr bw bk ks kt ku"/><span class="kr bw bk ks kt ku"/><span class="kr bw bk ks kt"/></div><div class="im in io ip iq"><p id="7153" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu">三世。数据探索</strong></p><p id="ed14" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">既然我们已经准备好了用于分析的数据，我们就可以开始研究它们，以检查其数据质量，并使用领域专业知识简化数据。</p><p id="ebcf" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">首先，让我们细化我们的目标。请记住，我们打算预测一个单一的变量。那个变量就是<strong class="js iu"> mutual_unit </strong>。我们有 3 个变量</p><p id="abda" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">我们的目的是<em class="my">借助<em class="my">辅助变量</em>预测</em> <strong class="js iu"> <em class="my">共同 _ 单位</em> </strong> <em class="my">变量</em>，即<em class="my">股票 _ 交易所</em>和<em class="my">通货膨胀。</em></p><p id="789c" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">让我们画出三个变量:</p><figure class="kw kx ky kz gt la gh gi paragraph-image"><div class="gh gi oe"><img src="../Images/052fb96756a35427f0be0a31c8ef6b0e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1206/format:webp/1*lWrI8Bck4bmyq5ZRvGz2bg.png"/></div><figcaption class="lh li gj gh gi lj lk bd b be z dk">Line plots of the three variables</figcaption></figure><p id="a042" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">在检查图表时，在互助单位和股票交易所之间可能存在一些相关性。对于通货膨胀，数值有一个支点，从<em class="my">上升</em>到<em class="my">下降</em>。</p><p id="1e3d" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">作为附加分析，让我们执行时间步长与时间步长<em class="my">相关性分析。</em>我们将使用<em class="my">热图</em>来查看相关性。</p><figure class="kw kx ky kz gt la"><div class="bz fp l di"><div class="ny nz l"/></div></figure><p id="48c7" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">在第一次剪切(<em class="my"> correl.py </em>)时，它生成一个热图。</p><figure class="kw kx ky kz gt la gh gi paragraph-image"><div class="gh gi of"><img src="../Images/5589225a31ae0527a759bb62faeac215.png" data-original-src="https://miro.medium.com/v2/resize:fit:856/format:webp/1*_9eyFt-XxgPIzR528YykDQ.png"/></div></figure></div><div class="ab cl ko kp hx kq" role="separator"><span class="kr bw bk ks kt ku"/><span class="kr bw bk ks kt ku"/><span class="kr bw bk ks kt"/></div><div class="im in io ip iq"><p id="8267" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">我们可以看到<em class="my"> mutual_unit </em>具有高度的相关性:</p><figure class="kw kx ky kz gt la gh gi paragraph-image"><div class="gh gi og"><img src="../Images/14c6fc0f7d3c0d326f93bb787405fd3d.png" data-original-src="https://miro.medium.com/v2/resize:fit:754/format:webp/1*VDMiGSzjw6Q11PI4FG5quw.png"/></div><figcaption class="lh li gj gh gi lj lk bd b be z dk">Correlation of mutual_unit to other variables</figcaption></figure><p id="288f" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><em class="my">注:</em>在撰写本文时，<em class="my">通货膨胀</em>似乎与<em class="my">互助单位负相关。</em>这可能是该股走高，以从通胀上升中复苏。您可以尝试减少感兴趣的时间窗口，这可能会提高模型的准确性。</p><p id="8357" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">在我们的模型中，我们需要指定变量的权重。这是代码的第二部分(<em class="my"> correl2 </em>)。由于我们使用<em class="my">股票交易</em>和<em class="my">通货膨胀</em>作为辅助变量，它们的权重将产生以下影响:</p><ol class=""><li id="e50c" class="mz na it js b jt ju jx jy kb nb kf nc kj nd kn ne nf ng nh bi translated"><em class="my">较高的权重</em>意味着与目标变量的相关性较高。</li><li id="5e9f" class="mz na it js b jt ni jx nj kb nk kf nl kj nm kn ne nf ng nh bi translated"><em class="my">降低重量</em>与上述相反。如果指定了更高的权重，那么变量的噪声将会过拟合或使目标变量不太准确。</li></ol><p id="04c1" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">作为我们模型的权重。相关性的标度如下:</p><p id="6efc" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">ABS(变量)/SUM(ABS(变量))</p><p id="b822" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">其中 VARIABLEx 是相关系数。除以变量的相关系数之和。注意<em class="my">绝对值</em>是在其他计算之前获取的。</p><figure class="kw kx ky kz gt la gh gi paragraph-image"><div class="gh gi oh"><img src="../Images/066bdf1a887bf2c77f92f6bb073cdbf9.png" data-original-src="https://miro.medium.com/v2/resize:fit:718/format:webp/1*8Qf6kiN2f2CXbBc-mwJNgw.png"/></div><figcaption class="lh li gj gh gi lj lk bd b be z dk">computed initial weights of the variables</figcaption></figure><p id="6e5f" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">请注意，这三者的比例大致相同，因为它们与 mutual_unit 具有相关性。</p></div><div class="ab cl ko kp hx kq" role="separator"><span class="kr bw bk ks kt ku"/><span class="kr bw bk ks kt ku"/><span class="kr bw bk ks kt"/></div><div class="im in io ip iq"><h1 id="2925" class="lm ln it bd lo lp no lr ls lt np lv lw lx nq lz ma mb nr md me mf ns mh mi mj bi translated"><strong class="ak">四。预测管道</strong></h1><p id="44d2" class="pw-post-body-paragraph jq jr it js b jt mk jv jw jx ml jz ka kb mm kd ke kf mn kh ki kj mo kl km kn im bi translated">这是我们应用机器学习进行预测的部分！当然，这并不神奇，这个过程仍然是随机的和数学的。正是它的信息处理技术使得它的预测令人印象深刻。</p><p id="fd99" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">我们进行的预测类型是<strong class="js iu">回归</strong>，我们预测的是连续值。在<em class="my">回归</em>中，我们建模<em class="my">连续值</em>。在<em class="my">分类</em>中，我们对离散值进行建模。在下图中，某个指标以两种类型表示。在离散或<em class="my">分类</em>中，数值为<em class="my">轻度</em>、<em class="my">中度</em>或<em class="my">重度</em>。在右轴中，指标表示为连续的值。</p><figure class="kw kx ky kz gt la gh gi paragraph-image"><div role="button" tabindex="0" class="lb lc di ld bf le"><div class="gh gi oi"><img src="../Images/ec87528630000191fd96454e5494d8a1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*CUSD4JUf1QUCNCfw1X5W3w.png"/></div></div><figcaption class="lh li gj gh gi lj lk bd b be z dk">Comparison between regression and classification.</figcaption></figure></div><div class="ab cl ko kp hx kq" role="separator"><span class="kr bw bk ks kt ku"/><span class="kr bw bk ks kt ku"/><span class="kr bw bk ks kt"/></div><div class="im in io ip iq"><h1 id="8444" class="lm ln it bd lo lp no lr ls lt np lv lw lx nq lz ma mb nr md me mf ns mh mi mj bi translated">数据集的时间处理</h1><p id="3d02" class="pw-post-body-paragraph jq jr it js b jt mk jv jw jx ml jz ka kb mm kd ke kf mn kh ki kj mo kl km kn im bi translated">我们的数据是一个时间序列，因此，除了它的特征值，还有一个向前移动的时间。虽然我们的数据集包含趋势和季节性，但将数据集截断到滚动窗口中是很重要的。为什么？因为使用整个历史可能会使模型过拟合。</p><p id="9585" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">在我们的案例中，<em class="my"> 1 个月的窗口期可能就足够了，或者 4 个工作周</em>。这种假设意味着可以使用该窗口对大多数属性进行建模。</p><p id="70cd" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi mp translated"><span class="l mq mr ms bm mt mu mv mw mx di"> N </span> <em class="my">注:从这一点上，我将提到在下面的实现中使用的函数。</em></p><p id="24f2" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">我们还需要定义滚动窗口的<em class="my">范围。在我们的例子中，我们将假设<em class="my"> 3 个月的训练数据</em>来表征模型。</em></p><figure class="kw kx ky kz gt la gh gi paragraph-image"><div role="button" tabindex="0" class="lb lc di ld bf le"><div class="gh gi oj"><img src="../Images/45a60a19ada8c8c82d00d61a0949101b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*WfXaGvoBOiyBe-9j3E_XrA.png"/></div></div><figcaption class="lh li gj gh gi lj lk bd b be z dk">Illustration period of training scope and model scope. The right side of the illustration is the recommended dataset.</figcaption></figure><figure class="kw kx ky kz gt la gh gi paragraph-image"><div class="gh gi ok"><img src="../Images/b88d889176aa417095a9e78a779b51f8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1008/format:webp/1*sh60bhp1ClyOhWZGzJ7utQ.png"/></div><figcaption class="lh li gj gh gi lj lk bd b be z dk">Dataset creation using rolling window. Photo credit and source from <a class="ae ll" href="https://www.researchgate.net/profile/Huaiqing_Wang" rel="noopener ugc nofollow" target="_blank">Huaiqing Wang</a>, <a class="ae ll" href="https://www.researchgate.net/figure/Diagram-of-building-up-the-dataset-Stock-time-series-segmentation-is-made-by-20-width_fig2_276890244" rel="noopener ugc nofollow" target="_blank">Diagram of building up the dataset</a></figcaption></figure><p id="2162" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">我们现在将分割训练和测试数据集:</p><figure class="kw kx ky kz gt la"><div class="bz fp l di"><div class="ny nz l"/></div></figure><p id="bd55" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">上面的代码显示了<em class="my">训练</em>和<em class="my">测试数据集</em>的创建。结果是一个已经创建了滚动窗口数据集的<em class="my">时间序列生成器</em>。</p><p id="ca68" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">我们将训练/测试数据集分成 80%/20%。请注意，测试数据的批量大小只有 1，正如我们稍后将会遇到的，测试集将会 1 个<em class="my">与 1 个</em>进行比较，以形成<em class="my">验证错误。</em></p><p id="a69a" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">训练窗口大小为<strong class="js iu"> 20 </strong>。</p></div><div class="ab cl ko kp hx kq" role="separator"><span class="kr bw bk ks kt ku"/><span class="kr bw bk ks kt ku"/><span class="kr bw bk ks kt"/></div><div class="im in io ip iq"><h1 id="3516" class="lm ln it bd lo lp no lr ls lt np lv lw lx nq lz ma mb nr md me mf ns mh mi mj bi translated"><strong class="ak">模型架构</strong></h1><p id="47b7" class="pw-post-body-paragraph jq jr it js b jt mk jv jw jx ml jz ka kb mm kd ke kf mn kh ki kj mo kl km kn im bi translated">该模型本质上是<em class="my">顺序</em>的，意味着各层堆叠成一个<em class="my">单输入/单输出</em>而没有任何分支。</p><figure class="kw kx ky kz gt la gh gi paragraph-image"><div class="gh gi ol"><img src="../Images/d83f4613b59f58e18e34e8f8006dbafd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1380/format:webp/1*Q3U0YY3HALA06Q7Rp1nfxQ.png"/></div><figcaption class="lh li gj gh gi lj lk bd b be z dk">Model architecture from <strong class="bd ob">TensorBoard</strong></figcaption></figure><p id="be14" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">模型从<em class="my">“密集”</em>开始，到<em class="my">“密集 _ 2”</em>层结束。</p><ol class=""><li id="66d8" class="mz na it js b jt ju jx jy kb nb kf nc kj nd kn ne nf ng nh bi translated">第 1 层(<em class="my">“dense”</em>)简单来说就是一个<em class="my">点乘</em>，相当于线性<em class="my">向量自回归</em> (VAR)，参数个数可调，增加了复杂度。它不包含随机参数。</li><li id="090e" class="mz na it js b jt ni jx nj kb nk kf nl kj nm kn ne nf ng nh bi translated">第二层(<em class="my">“dense _ 1”</em>)是学习进一步非线性的附加层。</li><li id="bb64" class="mz na it js b jt ni jx nj kb nk kf nl kj nm kn ne nf ng nh bi translated">接下来的几层分别是，<br/> <em class="my"> a. Dropout </em>层——训练时随机断开某些权重的层。这有助于网络学习逻辑形式的非线性，同时减少过拟合。<em class="my"> <br/> b .展平</em>层——将<em class="my">先前的隐藏层</em>置换为<em class="my">输出</em>层的层。<em class="my">输出尺寸</em>等于<em class="my">目标变量的尺寸</em>。</li></ol><pre class="kw kx ky kz gt om on oo op aw oq bi"><span id="c03e" class="or ln it on b gy os ot l ou ov">Function: train_evaluate()</span></pre><figure class="kw kx ky kz gt la gh gi paragraph-image"><div class="gh gi nx"><img src="../Images/b1f5de5c52ea92c63c6d60f3502e6142.png" data-original-src="https://miro.medium.com/v2/resize:fit:1260/format:webp/1*gangHck1d6H780CqqbZK-w.png"/></div><figcaption class="lh li gj gh gi lj lk bd b be z dk">Dropout illustration. Source: Srivastava Nitish, et. al, Dropout: <a class="ae ll" href="http://jmlr.org/papers/volume15/srivastava14a.old/srivastava14a.pdf" rel="noopener ugc nofollow" target="_blank">A Simple Way to Prevent Neural Networks from Overfitting</a> (2014), Journal of Machine Learning Research 15</figcaption></figure></div><div class="ab cl ko kp hx kq" role="separator"><span class="kr bw bk ks kt ku"/><span class="kr bw bk ks kt ku"/><span class="kr bw bk ks kt"/></div><div class="im in io ip iq"><h1 id="f77f" class="lm ln it bd lo lp no lr ls lt np lv lw lx nq lz ma mb nr md me mf ns mh mi mj bi translated">在输入图层上添加时态训练技术</h1><p id="a646" class="pw-post-body-paragraph jq jr it js b jt mk jv jw jx ml jz ka kb mm kd ke kf mn kh ki kj mo kl km kn im bi translated">回想一下<em class="my">递归网络</em>仅模拟当前和下一个时间步。如果我们只想要一个<em class="my">自回归模型</em>来描述<em class="my">下一个时间步</em>与前一个时间步的特征呢？(见上图，“将不同时间步长与下一个时间步长相关联的<em class="my">前馈网络”)。然后我们将一个无状态网络，因为它简化了模型。</em></p><p id="8af5" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">另一个重要特征是<em class="my">输入屏蔽</em>。回想一下，我们的输入形状有 20 个时间步长。我们将<em class="my">不使用这些</em>形状作为输入层形状:</p><ol class=""><li id="4587" class="mz na it js b jt ju jx jy kb nb kf nc kj nd kn ne nf ng nh bi translated">使用所有时间步长可能会导致过度拟合。</li><li id="1cde" class="mz na it js b jt ni jx nj kb nk kf nl kj nm kn ne nf ng nh bi translated">由于我们正在训练<em class="my">滚动窗口</em>来捕捉季节性，我们将使用输入跳跃来捕捉不同尺度的季节性。</li><li id="f539" class="mz na it js b jt ni jx nj kb nk kf nl kj nm kn ne nf ng nh bi translated">更远的时间步长与现值的相关性更小。</li></ol><figure class="kw kx ky kz gt la gh gi paragraph-image"><div class="gh gi ow"><img src="../Images/c83ca051e1d699f8e5099aed535ac41c.png" data-original-src="https://miro.medium.com/v2/resize:fit:596/format:webp/1*R1kNuRdr-fUOqs25xMpDmg.png"/></div><figcaption class="lh li gj gh gi lj lk bd b be z dk">Masking the inputs. The timesteps highlighted as <strong class="bd ob">gray </strong>are masked.</figcaption></figure><p id="975d" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">有了这些，我们在输入层只有<em class="my"> 11 个输入</em>。可以尝试不同的组合来面膜。</p><figure class="kw kx ky kz gt la"><div class="bz fp l di"><div class="ny nz l"/></div><figcaption class="lh li gj gh gi lj lk bd b be z dk">Code snip for code on masking. For full code, you can refer to <strong class="ak">train_evaluate() </strong>function.</figcaption></figure></div><div class="ab cl ko kp hx kq" role="separator"><span class="kr bw bk ks kt ku"/><span class="kr bw bk ks kt ku"/><span class="kr bw bk ks kt"/></div><div class="im in io ip iq"><h1 id="f926" class="lm ln it bd lo lp no lr ls lt np lv lw lx nq lz ma mb nr md me mf ns mh mi mj bi translated">超参数调谐</h1><p id="caf4" class="pw-post-body-paragraph jq jr it js b jt mk jv jw jx ml jz ka kb mm kd ke kf mn kh ki kj mo kl km kn im bi translated"><em class="my">超参数</em>主要是实例化或训练模型时的可调参数。</p><p id="6f00" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">作为一个例子，上面的要点实例化了一个<em class="my">“密集”</em>层。那些属于<em class="my"> kwargs </em>字典的是超参数:</p><ol class=""><li id="6491" class="mz na it js b jt ju jx jy kb nb kf nc kj nd kn ne nf ng nh bi translated"><em class="my">‘输入层’</em>是创建的神经元数量。调整这些将直接影响模型适应非线性(欠拟合或过拟合)的能力。</li><li id="5c71" class="mz na it js b jt ni jx nj kb nk kf nl kj nm kn ne nf ng nh bi translated">'<em class="my"> uni_reg' </em>将 L1 正则化应用于该层。参数值越高，调整速度越慢，降低了<em class="my">过拟合</em>的风险。</li></ol><p id="40bb" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">以下是模型的超参数:</p><figure class="kw kx ky kz gt la"><div class="bz fp l di"><div class="ny nz l"/></div></figure><p id="2025" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">上面的要点是使用名为“<em class="my"> skopt.space </em>”的库创建的，您可以在其中指定要优化的范围和类别。</p><p id="4fe1" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">之后，我们将整个管道封装到一个函数中，并运行优化函数命令。这就是我们创建一个名为</p><pre class="kw kx ky kz gt om on oo op aw oq bi"><span id="a4ed" class="or ln it on b gy os ot l ou ov">train_evaluate(normalized_data, est_period,loss_func,param_record, **kwargs)</span></pre><p id="bb41" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">它包含模型创建、验证过程等。你可以随意研究。</p><p id="15ab" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">现在，到超参数优化命令。</p><figure class="kw kx ky kz gt la"><div class="bz fp l di"><div class="ny nz l"/></div></figure><p id="3c19" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">我们正在使用<em class="my">高斯概率贝叶斯优化</em>来优化参数。它本质上映射了优化空间的一个<em class="my">概率模型</em>。关于<em class="my">开采</em>(疑似值)和<em class="my">勘探</em>(创建真实数据点)之间的导航空间的假设[4]</p><figure class="kw kx ky kz gt la gh gi paragraph-image"><div class="gh gi ox"><img src="../Images/89f35ccda144888c8ce62d3ed3299f0a.png" data-original-src="https://miro.medium.com/v2/resize:fit:990/format:webp/1*a-pPzw9C8dVx4Jh1KohQdQ.png"/></div><figcaption class="lh li gj gh gi lj lk bd b be z dk">Continuous improvement using Bayesian optimization. Source: Gilles Louppe, Manoj Kumar, <a class="ae ll" href="https://scikit-optimize.github.io/notebooks/bayesian-optimization.html" rel="noopener ugc nofollow" target="_blank">Bayesian optimization with </a><code class="fe oy oz pa on b"><a class="ae ll" href="https://scikit-optimize.github.io/notebooks/bayesian-optimization.html" rel="noopener ugc nofollow" target="_blank">skopt</a> (2016)</code></figcaption></figure></div><div class="ab cl ko kp hx kq" role="separator"><span class="kr bw bk ks kt ku"/><span class="kr bw bk ks kt ku"/><span class="kr bw bk ks kt"/></div><div class="im in io ip iq"><h1 id="2fcb" class="lm ln it bd lo lp no lr ls lt np lv lw lx nq lz ma mb nr md me mf ns mh mi mj bi translated">测试/验证</h1><p id="9511" class="pw-post-body-paragraph jq jr it js b jt mk jv jw jx ml jz ka kb mm kd ke kf mn kh ki kj mo kl km kn im bi translated">测试这个自回归问题有很多组成部分:</p><ol class=""><li id="1de8" class="mz na it js b jt ju jx jy kb nb kf nc kj nd kn ne nf ng nh bi translated"><em class="my">训练期间的测试集</em></li></ol><ul class=""><li id="ff35" class="mz na it js b jt ju jx jy kb nb kf nc kj nd kn od nf ng nh bi translated">这些是预测 X(t+1)处特征的测试值</li></ul><p id="a740" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">2.<em class="my">多步预测的迭代预测</em></p><p id="c6fa" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">首先，让我们提醒自己我们的目标变量，<strong class="js iu"><em class="my">mutual _ unit</em></strong><em class="my">。</em></p><p id="badf" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">为了验证这个变量，需要在 X(t+1)预测这 3 个变量。输入数据被推到左边，然后最新的时间步长数据被替换为预测数据。该过程被迭代以实现在<em class="my">多步骤的迭代。</em></p><figure class="kw kx ky kz gt la gh gi paragraph-image"><div class="gh gi pb"><img src="../Images/b1e1b73078fc95e6ebf93df59328f276.png" data-original-src="https://miro.medium.com/v2/resize:fit:1036/format:webp/1*Ce-tHYE0F-ib_JPjkLkfow.png"/></div><figcaption class="lh li gj gh gi lj lk bd b be z dk">Process on how the model forecasts in multi-steps. <strong class="bd ob">Xn</strong> is real data point where <strong class="bd ob">Hn</strong> is a predicted value</figcaption></figure><p id="5d4e" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">做到这一点的功能是</p><pre class="kw kx ky kz gt om on oo op aw oq bi"><span id="f7b6" class="or ln it on b gy os ot l ou ov"><strong class="on iu">validation()</strong></span></pre><p id="62ba" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><em class="my">验证</em>函数进行迭代预测，并与相应的测试数据进行比较。注意，只有<em class="my"> mutual_unit </em>才被拿出来比较。</p><figure class="kw kx ky kz gt la"><div class="bz fp l di"><div class="ny nz l"/></div><figcaption class="lh li gj gh gi lj lk bd b be z dk">A code snip on comparing the predicted(y_pred) and actual values(y_true).</figcaption></figure><p id="2b00" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">现在，向量<em class="my"> y_pred </em>和<em class="my"> y_true </em>是未来值。随着时间步长的进一步预测，熵或不可预测性增加。因此，我们将为这些值引入一个<em class="my">折现因子</em>。在我们的应用中，贴现因子是<em class="my"> 0.9。</em></p><figure class="kw kx ky kz gt la"><div class="bz fp l di"><div class="ny nz l"/></div><figcaption class="lh li gj gh gi lj lk bd b be z dk">Code to create the coefficients for multiplying into future data.</figcaption></figure><p id="a44e" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">此后，计算<em class="my">平均绝对误差</em><em class="my">。</em>这将是衡量模型性能的主要验证指标。</p><p id="eed5" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">这个<em class="my"> MAE </em>将作为<em class="my">提前停止</em>的度量。</p><p id="759c" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">早期停止应用于我们的验证指标(<em class="my"> MAE </em>)以减轻<em class="my">过度拟合的风险。</em>一旦验证误差开始<em class="my">增加</em>时停止。然而，由于验证值被假定为<em class="my">凸</em>，它具有不完全达到完全最优的风险，因为一旦发现误差的拐点，训练就停止。</p><figure class="kw kx ky kz gt la gh gi paragraph-image"><div class="gh gi pc"><img src="../Images/301df7f5a78cd497157f022c30e56170.png" data-original-src="https://miro.medium.com/v2/resize:fit:624/format:webp/1*9Fo_BKE5JjkkJBQbbUTiaA.png"/></div><figcaption class="lh li gj gh gi lj lk bd b be z dk">Early stopping illustration. Source: Shubham Jain, <a class="ae ll" href="https://www.analyticsvidhya.com/blog/2018/04/fundamentals-deep-learning-regularization-techniques/" rel="noopener ugc nofollow" target="_blank">An Overview of Regularization Techniques in Deep Learning (with Python code)</a> (2018),</figcaption></figure><p id="be79" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">我使用了手动编码的早期停止器，而不是 TensorFlow 的 API，这是因为定制的验证计算加上它更容易编码，而不是找到合适的 API。对象名称是</p><pre class="kw kx ky kz gt om on oo op aw oq bi"><span id="b9d7" class="or ln it on b gy os ot l ou ov">class CustomEarlyStopper:<br/>	def __init__(self, patience=3, delta=1e-4):<br/>	...</span></pre><p id="75c4" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">它具有类似的参数，如<em class="my">耐心</em>和<em class="my">增量，</em>作为验证误差增加的容限。</p><p id="deea" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">让我们来看看预测值和实际值之间的关系。请注意，预测值在预测值之上有一个正偏移。</p><figure class="kw kx ky kz gt la gh gi paragraph-image"><div class="gh gi pd"><img src="../Images/37954ddc50c05b46bda2bf78bc8511c1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1192/format:webp/1*k3EptW3dPP_HummSR6U_pg.png"/></div><figcaption class="lh li gj gh gi lj lk bd b be z dk">Comparison between the predicted(‘mutual_unit_forecast’) and actual(‘mutual_unit’)</figcaption></figure></div><div class="ab cl ko kp hx kq" role="separator"><span class="kr bw bk ks kt ku"/><span class="kr bw bk ks kt ku"/><span class="kr bw bk ks kt"/></div><div class="im in io ip iq"><h1 id="1c5a" class="lm ln it bd lo lp no lr ls lt np lv lw lx nq lz ma mb nr md me mf ns mh mi mj bi translated">定稿</h1><p id="d810" class="pw-post-body-paragraph jq jr it js b jt mk jv jw jx ml jz ka kb mm kd ke kf mn kh ki kj mo kl km kn im bi translated">我们现在正在准备用于推理的模型。</p><ol class=""><li id="8afb" class="mz na it js b jt ju jx jy kb nb kf nc kj nd kn ne nf ng nh bi translated">使用最终参数，我们重新优化模型，以在超参数调整期间达到相同的验证误差。这些可以通过加载优化对象来获得。</li></ol><figure class="kw kx ky kz gt la"><div class="bz fp l di"><div class="ny nz l"/></div></figure><p id="21bc" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">在笔记本中，你可以注意到<em class="my"> jump() </em>和<em class="my"> load() </em>这两个函数使<em class="my">持久化</em>(保存到磁盘)。放置这些函数是为了便于在系统中断时使用对象。</p><p id="972d" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><em class="my">注意:您可以重构代码，以便用最佳超参数优化的模型成为持久的(用户),从而避免如上所述的重新训练。</em></p><p id="b2a4" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">2.在此之后，捕捉最后一次最优训练的最后一次<em class="my">训练损失</em>。请注意，这是要应用的<strong class="js iu">培训损失</strong>，而不是验证损失。这种技术也可以重构。</p><p id="7482" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">3.最后，我们必须使用整个数据集来训练模型。为了降低过度拟合的风险，我们将从最后训练的模型中获得<em class="my">先前训练损失</em>。一旦达到目标训练损失，我们将<em class="my">停止</em>模型训练。</p><figure class="kw kx ky kz gt la gh gi paragraph-image"><div class="gh gi pe"><img src="../Images/58b934a7834acd4444f97fdc5888a2ac.png" data-original-src="https://miro.medium.com/v2/resize:fit:996/format:webp/1*sWuNPP-w_94M0SHYJD5AKw.png"/></div></figure></div><div class="ab cl ko kp hx kq" role="separator"><span class="kr bw bk ks kt ku"/><span class="kr bw bk ks kt ku"/><span class="kr bw bk ks kt"/></div><div class="im in io ip iq"><h1 id="62c8" class="lm ln it bd lo lp no lr ls lt np lv lw lx nq lz ma mb nr md me mf ns mh mi mj bi translated">结束语</h1><p id="4c13" class="pw-post-body-paragraph jq jr it js b jt mk jv jw jx ml jz ka kb mm kd ke kf mn kh ki kj mo kl km kn im bi translated">感谢您的阅读，希望您了解了时间序列预测的基础知识，从数据准备到建模。我很高兴分享这一经历，就像在简单的时间序列预测中学习、发现和应用深度学习一样有趣。</p><h1 id="2f7c" class="lm ln it bd lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj bi translated">参考</h1><p id="b657" class="pw-post-body-paragraph jq jr it js b jt mk jv jw jx ml jz ka kb mm kd ke kf mn kh ki kj mo kl km kn im bi translated">[1] <a class="ae ll" href="https://en.wikipedia.org/wiki/Autoregressive_model#Characteristic_polynomial" rel="noopener ugc nofollow" target="_blank">自回归模型</a>，维基百科</p><p id="3a80" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">[2]“罗布·J·海德曼”，<a class="ae ll" href="https://robjhyndman.com/hyndsight/backcasting/" rel="noopener ugc nofollow" target="_blank">回播于 R (2014) </a></p><p id="2ddc" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">[3] <a class="ae ll" href="https://en.wikipedia.org/wiki/Vector_autoregression" rel="noopener ugc nofollow" target="_blank">向量自回归</a>，维基百科</p><p id="92bf" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">[4]吉勒·卢佩，马诺奇·库马尔，<a class="ae ll" href="https://scikit-optimize.github.io/notebooks/bayesian-optimization.html" rel="noopener ugc nofollow" target="_blank">贝叶斯优化与</a> <code class="fe oy oz pa on b"><a class="ae ll" href="https://scikit-optimize.github.io/notebooks/bayesian-optimization.html" rel="noopener ugc nofollow" target="_blank">skopt</a> (2016)</code></p></div></div>    
</body>
</html>