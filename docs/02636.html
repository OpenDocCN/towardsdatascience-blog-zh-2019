<html>
<head>
<title>Everything You Need to Know About Autoencoders in TensorFlow</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">关于 TensorFlow 中的自动编码器，您需要了解的一切</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/everything-you-need-to-know-about-autoencoders-in-tensorflow-b6a63e8255f0?source=collection_archive---------11-----------------------#2019-04-30">https://towardsdatascience.com/everything-you-need-to-know-about-autoencoders-in-tensorflow-b6a63e8255f0?source=collection_archive---------11-----------------------#2019-04-30</a></blockquote><div><div class="fc ij ik il im in"/><div class="io ip iq ir is"><div class=""/><div class=""><h2 id="3d7c" class="pw-subtitle-paragraph js iu iv bd b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj dk translated">在 TensorFlow 中从理论到实现</h2></div><figure class="kl km kn ko gt kp gh gi paragraph-image"><div role="button" tabindex="0" class="kq kr di ks bf kt"><div class="gh gi kk"><img src="../Images/a2223d4f0f5c8e40db69d8f5d495eeb9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*DHi2oJYHpBaXycyi"/></div></div><figcaption class="kw kx gj gh gi ky kz bd b be z dk">Photo by <a class="ae la" href="https://unsplash.com/@killerfvith?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Alex wong</a> on <a class="ae la" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><p id="fc10" class="pw-post-body-paragraph lb lc iv ld b le lf jw lg lh li jz lj lk ll lm ln lo lp lq lr ls lt lu lv lw io bi translated">自动编码器是人工神经网络，可以从未标记的训练集中学习。这可能被戏称为<em class="lx">无监督深度学习</em>。它们既可以用于降维，也可以作为<strong class="ld iw">生成模型</strong>，这意味着它们可以从输入数据中生成新数据。</p><p id="7128" class="pw-post-body-paragraph lb lc iv ld b le lf jw lg lh li jz lj lk ll lm ln lo lp lq lr ls lt lu lv lw io bi translated">在本帖中，将介绍不同类型的自动编码器及其应用，并使用 TensorFlow 实现。</p><p id="7fce" class="pw-post-body-paragraph lb lc iv ld b le lf jw lg lh li jz lj lk ll lm ln lo lp lq lr ls lt lu lv lw io bi translated">所有代码都可以在 Github <a class="ae la" href="https://github.com/marcopeix/Neural_Networkds_and_Deep_Learning/blob/master/Autoencoders.ipynb" rel="noopener ugc nofollow" target="_blank">回购</a>中获得。</p><p id="9ac9" class="pw-post-body-paragraph lb lc iv ld b le lf jw lg lh li jz lj lk ll lm ln lo lp lq lr ls lt lu lv lw io bi translated">点燃你的笔记本，让我们开始吧！</p><blockquote class="ly"><p id="20f6" class="lz ma iv bd mb mc md me mf mg mh lw dk translated">关于机器学习、深度学习和人工智能的实践视频教程，请查看我的<a class="ae la" href="https://www.youtube.com/channel/UC-0lpiwlftqwC7znCcF83qg?view_as=subscriber" rel="noopener ugc nofollow" target="_blank"> YouTube 频道</a>。</p></blockquote><figure class="mi mj mk ml mm kp"><div class="bz fp l di"><div class="mn mo l"/></div><figcaption class="kw kx gj gh gi ky kz bd b be z dk">Technically, we can generate new “faces” with autoencoders!</figcaption></figure><h1 id="0f50" class="mp mq iv bd mr ms mt mu mv mw mx my mz kb na kc nb ke nc kf nd kh ne ki nf ng bi translated">自动编码器如何工作</h1><p id="a4b2" class="pw-post-body-paragraph lb lc iv ld b le nh jw lg lh ni jz lj lk nj lm ln lo nk lq lr ls nl lu lv lw io bi translated">自动编码器将数据作为输入，将其转换为有效的内部表示，并输出看起来像输入的数据。</p><p id="9833" class="pw-post-body-paragraph lb lc iv ld b le lf jw lg lh li jz lj lk ll lm ln lo lp lq lr ls lt lu lv lw io bi translated">换句话说，它在输入中寻找模式，以生成新的东西，但非常接近输入数据。</p><p id="da3c" class="pw-post-body-paragraph lb lc iv ld b le lf jw lg lh li jz lj lk ll lm ln lo lp lq lr ls lt lu lv lw io bi translated">自动编码器总是由两部分组成:</p><ul class=""><li id="fbed" class="nm nn iv ld b le lf lh li lk no lo np ls nq lw nr ns nt nu bi translated">一个<strong class="ld iw">编码器</strong>或<strong class="ld iw">识别网络</strong></li><li id="b01e" class="nm nn iv ld b le nv lh nw lk nx lo ny ls nz lw nr ns nt nu bi translated">一个<strong class="ld iw">解码器</strong>或<strong class="ld iw">生成网络</strong></li></ul><p id="ed73" class="pw-post-body-paragraph lb lc iv ld b le lf jw lg lh li jz lj lk ll lm ln lo lp lq lr ls lt lu lv lw io bi translated">当然，编码器将输入转换成更简单的内部表示，解码器负责从内部表示产生输出。</p><figure class="kl km kn ko gt kp gh gi paragraph-image"><div class="gh gi oa"><img src="../Images/e9b20e8c264dac2a7b1883733d496673.png" data-original-src="https://miro.medium.com/v2/resize:fit:700/format:webp/1*6NpAVwuN_nf8s4Ggz0MYVg.png"/></div><figcaption class="kw kx gj gh gi ky kz bd b be z dk">Schema of an autoencoder. Note that the internal representation is also termed “code”. <a class="ae la" href="https://en.wikipedia.org/wiki/Autoencoder" rel="noopener ugc nofollow" target="_blank">Source</a></figcaption></figure><p id="324c" class="pw-post-body-paragraph lb lc iv ld b le lf jw lg lh li jz lj lk ll lm ln lo lp lq lr ls lt lu lv lw io bi translated">注意，自动编码器在输入和输出层具有相同数量的神经元。为了迫使网络学习数据中最重要的特征，隐藏层必须具有较少的神经元。这样，它就不能简单地将输入复制到输出。由于隐藏层的维数比输出低，自动编码器被称为<em class="lx">欠完成。</em></p><h1 id="0cc5" class="mp mq iv bd mr ms mt mu mv mw mx my mz kb na kc nb ke nc kf nd kh ne ki nf ng bi translated">带自动编码器的 PCA</h1><p id="df4a" class="pw-post-body-paragraph lb lc iv ld b le nh jw lg lh ni jz lj lk nj lm ln lo nk lq lr ls nl lu lv lw io bi translated">作为降维的一个例子，如果 PCA 仅使用线性激活函数，并且如果成本函数被设置为均方误差(MSE ),则可以用自动编码器来执行 PCA。</p><p id="0d3a" class="pw-post-body-paragraph lb lc iv ld b le lf jw lg lh li jz lj lk ll lm ln lo lp lq lr ls lt lu lv lw io bi translated">让我们看看如何实现这一点。</p><p id="9b7e" class="pw-post-body-paragraph lb lc iv ld b le lf jw lg lh li jz lj lk ll lm ln lo lp lq lr ls lt lu lv lw io bi translated">首先，我们创建一个虚拟 3D 数据集:</p><figure class="kl km kn ko gt kp gh gi paragraph-image"><div role="button" tabindex="0" class="kq kr di ks bf kt"><div class="gh gi ob"><img src="../Images/663542bf0699bd4ae0a36c0cf951c8e7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_OBcPTuvoIdOX9SVjGsrDw.png"/></div></div></figure><p id="c967" class="pw-post-body-paragraph lb lc iv ld b le lf jw lg lh li jz lj lk ll lm ln lo lp lq lr ls lt lu lv lw io bi translated">绘制数据集，我们得到:</p><figure class="kl km kn ko gt kp gh gi paragraph-image"><div class="gh gi oc"><img src="../Images/6409a9830fb7c0c893d32540f6356e36.png" data-original-src="https://miro.medium.com/v2/resize:fit:1076/format:webp/1*cf8-Y4kOzuwNkUAOQp9ayw.png"/></div></figure><figure class="kl km kn ko gt kp gh gi paragraph-image"><div role="button" tabindex="0" class="kq kr di ks bf kt"><div class="gh gi od"><img src="../Images/51e38bdb9a07db0d6062f006fab14627.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*qcFvrYq5kIQw_jsaYyWbhQ.png"/></div></div><figcaption class="kw kx gj gh gi ky kz bd b be z dk">Generated 3D dataset</figcaption></figure><p id="191e" class="pw-post-body-paragraph lb lc iv ld b le lf jw lg lh li jz lj lk ll lm ln lo lp lq lr ls lt lu lv lw io bi translated">厉害！现在，我们准备编码和训练一个自动编码器来执行 PCA:</p><figure class="kl km kn ko gt kp gh gi paragraph-image"><div class="gh gi oe"><img src="../Images/1c984f27692cf0dfd4078cc457e0cf6d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1210/format:webp/1*l3xW9jtzweNHW9o-Gy3MGg.png"/></div></figure><p id="fd28" class="pw-post-body-paragraph lb lc iv ld b le lf jw lg lh li jz lj lk ll lm ln lo lp lq lr ls lt lu lv lw io bi translated">现在，我们可以像这样绘制结果:</p><figure class="kl km kn ko gt kp gh gi paragraph-image"><div class="gh gi of"><img src="../Images/547de9858dcc6118a12ddff7343459b3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1160/format:webp/1*lMW4OSbppFbI503IHU5EWg.png"/></div></figure><p id="5955" class="pw-post-body-paragraph lb lc iv ld b le lf jw lg lh li jz lj lk ll lm ln lo lp lq lr ls lt lu lv lw io bi translated">您应该会看到:</p><figure class="kl km kn ko gt kp gh gi paragraph-image"><div role="button" tabindex="0" class="kq kr di ks bf kt"><div class="gh gi og"><img src="../Images/c95a3cb21e8531dc4031dc1c31caddca.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*4YJPvUio7WLZdcYVB7TrLQ.png"/></div></div><figcaption class="kw kx gj gh gi ky kz bd b be z dk">Result of PCA with an autoencoder</figcaption></figure><p id="8a30" class="pw-post-body-paragraph lb lc iv ld b le lf jw lg lh li jz lj lk ll lm ln lo lp lq lr ls lt lu lv lw io bi translated">太好了！如您所见，自动编码器通过保持原始数据集的方差有效地执行了 PCA，但是是在 2D 平面上。</p><h1 id="df92" class="mp mq iv bd mr ms mt mu mv mw mx my mz kb na kc nb ke nc kf nd kh ne ki nf ng bi translated">堆叠自动编码器</h1><p id="b519" class="pw-post-body-paragraph lb lc iv ld b le nh jw lg lh ni jz lj lk nj lm ln lo nk lq lr ls nl lu lv lw io bi translated">就像其他神经网络一样，自动编码器可以有多个隐藏层。它们被称为<em class="lx">堆叠式自动编码器</em>。更多的隐藏层将允许网络学习更复杂的特征。然而，过多的隐藏层可能会使输入过拟合，并且自动编码器将不能很好地概括。</p><p id="b207" class="pw-post-body-paragraph lb lc iv ld b le lf jw lg lh li jz lj lk ll lm ln lo lp lq lr ls lt lu lv lw io bi translated">堆叠式自动编码器的架构是关于<em class="lx">编码</em>层(中间隐藏层)对称的，如下图所示。</p><figure class="kl km kn ko gt kp gh gi paragraph-image"><div role="button" tabindex="0" class="kq kr di ks bf kt"><div class="gh gi oh"><img src="../Images/8d58f7553cd50e63c43e4a99ffcd00be.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*7H9VQlN94-wv7Ianqt6GZg.png"/></div></div><figcaption class="kw kx gj gh gi ky kz bd b be z dk">Schema of a stacked autoencoder</figcaption></figure><h2 id="c23c" class="oi mq iv bd mr oj ok dn mv ol om dp mz lk on oo nb lo op oq nd ls or os nf ot bi translated">MNIST 的实施情况</h2><p id="da18" class="pw-post-body-paragraph lb lc iv ld b le nh jw lg lh ni jz lj lk nj lm ln lo nk lq lr ls nl lu lv lw io bi translated">让我们使用 MNIST 数据集来训练堆栈式自动编码器。</p><p id="391e" class="pw-post-body-paragraph lb lc iv ld b le lf jw lg lh li jz lj lk ll lm ln lo lp lq lr ls lt lu lv lw io bi translated">首先，我们导入 MNIST 数据集:</p><figure class="kl km kn ko gt kp gh gi paragraph-image"><div class="gh gi ou"><img src="../Images/f0765f1448c0b6ac62c4c348546cb7d3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1278/format:webp/1*wf854PVqf7Ha3mGA8eWSwQ.png"/></div></figure><p id="e70e" class="pw-post-body-paragraph lb lc iv ld b le lf jw lg lh li jz lj lk ll lm ln lo lp lq lr ls lt lu lv lw io bi translated">然后，我们构建堆栈式自动编码器:</p><figure class="kl km kn ko gt kp gh gi paragraph-image"><div role="button" tabindex="0" class="kq kr di ks bf kt"><div class="gh gi ov"><img src="../Images/e5197fec3663c75ae98aca31ac7de8b7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*XLpcViNlH4zyjfIvodTPVA.png"/></div></div></figure><p id="26ca" class="pw-post-body-paragraph lb lc iv ld b le lf jw lg lh li jz lj lk ll lm ln lo lp lq lr ls lt lu lv lw io bi translated">我们运行它:</p><figure class="kl km kn ko gt kp gh gi paragraph-image"><div role="button" tabindex="0" class="kq kr di ks bf kt"><div class="gh gi ow"><img src="../Images/4e6128db950e27ddfea358d07985277e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Y0mB6JAw5Jd6yaVRpnAlzA.png"/></div></div></figure><p id="d6b0" class="pw-post-body-paragraph lb lc iv ld b le lf jw lg lh li jz lj lk ll lm ln lo lp lq lr ls lt lu lv lw io bi translated">最后，我们可以看到自动编码器是如何重建数字的:</p><figure class="kl km kn ko gt kp gh gi paragraph-image"><div role="button" tabindex="0" class="kq kr di ks bf kt"><div class="gh gi ox"><img src="../Images/f39ef0d786fb875655f975eb07434ed0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*g0_za6lS3VqnI4ZIPzmRGw.png"/></div></div></figure><p id="3d84" class="pw-post-body-paragraph lb lc iv ld b le lf jw lg lh li jz lj lk ll lm ln lo lp lq lr ls lt lu lv lw io bi translated">您应该会看到:</p><figure class="kl km kn ko gt kp gh gi paragraph-image"><div class="gh gi oy"><img src="../Images/9bd85551979c0f060ce7271402d7b3ba.png" data-original-src="https://miro.medium.com/v2/resize:fit:1128/format:webp/1*rgQpTnw43qpN7Awu8s4ong.png"/></div><figcaption class="kw kx gj gh gi ky kz bd b be z dk">Reconstructed digits with a stacked autoencoder. <strong class="bd oz">Left</strong>: original digits. <strong class="bd oz">Right</strong>: reconstructed digits.</figcaption></figure><h1 id="d1c1" class="mp mq iv bd mr ms mt mu mv mw mx my mz kb na kc nb ke nc kf nd kh ne ki nf ng bi translated">用可变自动编码器生成数字</h1><p id="06ab" class="pw-post-body-paragraph lb lc iv ld b le nh jw lg lh ni jz lj lk nj lm ln lo nk lq lr ls nl lu lv lw io bi translated">2014 年推出的自动编码器的一个重要类别:变型自动编码器。它们在两个方面不同于传统的自动编码器:</p><ul class=""><li id="6fbc" class="nm nn iv ld b le lf lh li lk no lo np ls nq lw nr ns nt nu bi translated">它们是概率自动编码器，这意味着输出部分是偶然的，即使在训练之后</li><li id="1933" class="nm nn iv ld b le nv lh nw lk nx lo ny ls nz lw nr ns nt nu bi translated">它们是生成式自动编码器；他们可以生成看起来像输入的新数据实例</li></ul><p id="3ba0" class="pw-post-body-paragraph lb lc iv ld b le lf jw lg lh li jz lj lk ll lm ln lo lp lq lr ls lt lu lv lw io bi translated">变分自动编码器的结构与传统自动编码器的结构非常相似。但是，如下图，有一个小小的转折。</p><figure class="kl km kn ko gt kp gh gi paragraph-image"><div role="button" tabindex="0" class="kq kr di ks bf kt"><div class="gh gi pa"><img src="../Images/cd8309896d8c08262ba7f6c47c5cae52.png" data-original-src="https://miro.medium.com/v2/resize:fit:1314/format:webp/1*lU0_hEUFZ_QNdYVWAGvWKw.png"/></div></div><figcaption class="kw kx gj gh gi ky kz bd b be z dk">Schema of a variational autoencoder</figcaption></figure><p id="3869" class="pw-post-body-paragraph lb lc iv ld b le lf jw lg lh li jz lj lk ll lm ln lo lp lq lr ls lt lu lv lw io bi translated">这里，自动编码器产生了一个<em class="lx">均值</em>编码(<em class="lx">μ</em>)和一个标准差(<em class="lx">σ</em>)。然后，从具有相同均值<em class="lx">μ</em>和标准差<em class="lx">σ</em>的高斯分布中随机采样实际编码。然后，它被正常解码以产生输出。</p><p id="6bba" class="pw-post-body-paragraph lb lc iv ld b le lf jw lg lh li jz lj lk ll lm ln lo lp lq lr ls lt lu lv lw io bi translated">此外，成本函数还有第二部分，称为<em class="lx">潜在损失</em>。这确保了自动编码器的编码看起来像是从简单的高斯分布中采样的。</p><p id="c2ab" class="pw-post-body-paragraph lb lc iv ld b le lf jw lg lh li jz lj lk ll lm ln lo lp lq lr ls lt lu lv lw io bi translated">让我们看看如何构建一个可变的自动编码器来生成新的手写数字。</p><p id="e494" class="pw-post-body-paragraph lb lc iv ld b le lf jw lg lh li jz lj lk ll lm ln lo lp lq lr ls lt lu lv lw io bi translated">至于前面的自动编码器，我们从定义架构和构建张量流图开始。您会注意到它与以前的自动编码器非常相似，但是我们添加了几个隐藏层来产生用于输出采样的平均值和标准偏差。</p><figure class="kl km kn ko gt kp gh gi paragraph-image"><div role="button" tabindex="0" class="kq kr di ks bf kt"><div class="gh gi pb"><img src="../Images/efd0e8d7c67622ecbbd3e3017cc98ec2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*HNZfTU8rujQ3iNiS0oq3Fg.png"/></div></div></figure><p id="841e" class="pw-post-body-paragraph lb lc iv ld b le lf jw lg lh li jz lj lk ll lm ln lo lp lq lr ls lt lu lv lw io bi translated">然后，我们可以通过从 MNIST 数据集学习来训练模型生成新的数字:</p><figure class="kl km kn ko gt kp gh gi paragraph-image"><div role="button" tabindex="0" class="kq kr di ks bf kt"><div class="gh gi pb"><img src="../Images/2bd62e26714670aa64c085f0327e7ff8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*QpqDFESW2fWc_gduZgvZCg.png"/></div></div></figure><p id="3e5c" class="pw-post-body-paragraph lb lc iv ld b le lf jw lg lh li jz lj lk ll lm ln lo lp lq lr ls lt lu lv lw io bi translated">输出结果时，您应该看到:</p><figure class="kl km kn ko gt kp gh gi paragraph-image"><div class="gh gi pc"><img src="../Images/160a1a280eaef5e648784cac2c56af56.png" data-original-src="https://miro.medium.com/v2/resize:fit:1042/format:webp/1*LqlFPopSKg7Xv8wnF4wI_Q.png"/></div></figure><figure class="kl km kn ko gt kp gh gi paragraph-image"><div role="button" tabindex="0" class="kq kr di ks bf kt"><div class="gh gi pd"><img src="../Images/7b3b20d5feceb1f5ecb15f8c02775549.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*baBZSv5Jv4fIj46jA-x05g.png"/></div></div><figcaption class="kw kx gj gh gi ky kz bd b be z dk">Generated digits from a variational autoencoder</figcaption></figure><p id="8654" class="pw-post-body-paragraph lb lc iv ld b le lf jw lg lh li jz lj lk ll lm ln lo lp lq lr ls lt lu lv lw io bi translated">正如你所看到的，数字非常接近 MNIST 数据集，我们的变分自动编码器成功地学习了关于输入的最重要的特征。</p></div><div class="ab cl pe pf hz pg" role="separator"><span class="ph bw bk pi pj pk"/><span class="ph bw bk pi pj pk"/><span class="ph bw bk pi pj"/></div><div class="io ip iq ir is"><p id="d033" class="pw-post-body-paragraph lb lc iv ld b le lf jw lg lh li jz lj lk ll lm ln lo lp lq lr ls lt lu lv lw io bi translated">干得好，坚持到了最后！在这篇文章中，我们了解了自动编码器如何工作，以及它们如何用于降维、无监督学习和作为生成模型。</p><p id="b362" class="pw-post-body-paragraph lb lc iv ld b le lf jw lg lh li jz lj lk ll lm ln lo lp lq lr ls lt lu lv lw io bi translated">参考:使用 Scikit-Learn 和 tensor flow-aurélien géRon 进行机器实践学习</p></div></div>    
</body>
</html>