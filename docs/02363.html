<html>
<head>
<title>How a team of deep learning newbies came 3rd place in a kaggle contest</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">深度学习新手团队如何在 kaggle 竞赛中获得第三名</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/how-a-team-of-deep-learning-newbies-came-3rd-place-in-a-kaggle-contest-644adcc143c8?source=collection_archive---------6-----------------------#2019-04-18">https://towardsdatascience.com/how-a-team-of-deep-learning-newbies-came-3rd-place-in-a-kaggle-contest-644adcc143c8?source=collection_archive---------6-----------------------#2019-04-18</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="494c" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">利用 fast.ai 对油棕林图像进行分类</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/b633615eaeb51bcd102047de4601c72f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*8PPe56WHT1miCF9p"/></div></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk">Photo by <a class="ae kv" href="https://unsplash.com/@alexandernaglestad?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Alexander Naglestad</a> on <a class="ae kv" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><p id="a53d" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">数据科学领域的妇女与其合作伙伴共同发起了 WiDS 数据马拉松。面临的挑战是创建一个模型来预测卫星图像中油棕种植园的存在。<em class="ls">行星</em>和<em class="ls">八字</em>慷慨地提供了一组由<em class="ls">行星的</em>卫星最近拍摄的卫星图像的注释数据集。数据集影像的空间分辨率为 3 米，每个影像都根据影像中是否存在油棕种植园进行标注(0 表示无种植园，1 表示有种植园)。任务是训练一个模型，该模型将卫星图像作为输入，并输出图像包含油棕榈种植园的可能性预测。<a class="ae kv" href="https://www.widsconference.org/datathon.html" rel="noopener ugc nofollow" target="_blank">竞赛创建者</a>为模型开发提供了带标签的训练和测试数据集。更多<strong class="ky ir"> </strong> <a class="ae kv" href="https://www.kaggle.com/c/widsdatathon2019" rel="noopener ugc nofollow" target="_blank"> <strong class="ky ir">此处</strong> </a>阅读。</p><p id="2997" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我和我的队友(<a class="lt lu ep" href="https://medium.com/u/d4284ce02aec?source=post_page-----644adcc143c8--------------------------------" rel="noopener" target="_blank">阿卜迪沙库尔</a>、<a class="ae kv" href="https://www.linkedin.com/in/halimah-oladosu-50680385/" rel="noopener ugc nofollow" target="_blank">哈利玛</a>和<a class="lt lu ep" href="https://medium.com/u/2f29addd85ff?source=post_page-----644adcc143c8--------------------------------" rel="noopener" target="_blank">伊欧马·奥科</a>)在这次挑战中使用了<a class="ae kv" href="https://www.fast.ai/" rel="noopener ugc nofollow" target="_blank"> fast.ai </a>框架。非常感谢托马斯·卡佩勒🤗对于他在<a class="ae kv" href="https://www.kaggle.com/tcapelle" rel="noopener ugc nofollow" target="_blank"> kaggle </a>上的入门内核，它提供了关于如何解决这个问题的如此多的见解，也为 fast.ai 团队创造了一个令人惊叹的<a class="ae kv" href="https://course.fast.ai/" rel="noopener ugc nofollow" target="_blank">深度学习课程</a>，简化了许多困难的深度学习概念。深度学习的初学者现在可以赢得游戏比赛😁。</p></div><div class="ab cl lv lw hu lx" role="separator"><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma"/></div><div class="ij ik il im in"><h2 id="6ed4" class="mc md iq bd me mf mg dn mh mi mj dp mk lf ml mm mn lj mo mp mq ln mr ms mt mu bi translated">让我们开始吧:一个简单易用的深度学习教程</h2><p id="9a2a" class="pw-post-body-paragraph kw kx iq ky b kz mv jr lb lc mw ju le lf mx lh li lj my ll lm ln mz lp lq lr ij bi translated">不要担心理解所有的东西，这需要大量的练习。这个教程就是想让你看看 fast.ai 对于初学深度学习的人来说有多酷。我假设你了解一些 python，并且对 ML 有所涉猎。如果那是你；那我们就走上正轨了。</p><blockquote class="na nb nc"><p id="6657" class="kw kx ls ky b kz la jr lb lc ld ju le nd lg lh li ne lk ll lm nf lo lp lq lr ij bi translated">这里显示的所有代码都可以在<a class="ae kv" href="https://colab.research.google.com/notebooks/welcome.ipynb" rel="noopener ugc nofollow" target="_blank">谷歌合作实验室</a>获得；一个免费的 Jupyter 笔记本环境，不需要设置，完全在云中运行。借助 Colaboratory，您可以编写和执行代码、保存和共享您的分析，以及访问强大的计算资源，所有这些都可以从浏览器中免费获得。点击<a class="ae kv" href="https://colab.research.google.com/drive/1PVaRPY1XZuPLtm01V2XxIWqhLrz3_rgX" rel="noopener ugc nofollow" target="_blank">这里</a>访问我们将要使用的代码。</p></blockquote></div><div class="ab cl lv lw hu lx" role="separator"><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma"/></div><div class="ij ik il im in"><h2 id="dcff" class="mc md iq bd me mf mg dn mh mi mj dp mk lf ml mm mn lj mo mp mq ln mr ms mt mu bi translated">导入 fast.ai 和我们将使用的其他库</h2><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="ng nh l"/></div></figure><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="ng nh l"/></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk">Import libraries</figcaption></figure><h2 id="96ff" class="mc md iq bd me mf mg dn mh mi mj dp mk lf ml mm mn lj mo mp mq ln mr ms mt mu bi translated">获取比赛<a class="ae kv" href="https://www.kaggle.com/c/widsdatathon2019/data" rel="noopener ugc nofollow" target="_blank">数据</a></h2><p id="794e" class="pw-post-body-paragraph kw kx iq ky b kz mv jr lb lc mw ju le lf mx lh li lj my ll lm ln mz lp lq lr ij bi translated">为了尽可能直截了当，阿卜迪沙库尔上传了比赛数据文件给 dropbox.com。你可以在比赛网页<a class="ae kv" href="https://www.kaggle.com/c/widsdatathon2019/data" rel="noopener ugc nofollow" target="_blank">这里</a>找到它们。你需要接受比赛规则并加入才能访问数据。</p><pre class="kg kh ki kj gt ni nj nk nl aw nm bi"><span id="2e7f" class="mc md iq nj b gy nn no l np nq"># Get the data from dropbox link<br/>!wget <a class="ae kv" href="https://www.dropbox.com/s/6kltw0kqynlijxv/widsdatathon2019.zip" rel="noopener ugc nofollow" target="_blank">https://www.dropbox.com/s/6kltw0kqynlijxv/widsdatathon2019.zip</a><br/>  <br/># The downloaded competition data is zipped, let us unzip it<br/>!unzip widsdatathon2019.zip</span><span id="a1ad" class="mc md iq nj b gy nr no l np nq"># The training and testing data have already been seperated, Unzip them as well<br/>!unzip train_images.zip<br/>!unzip leaderboard_holdout_data.zip<br/>!unzip leaderboard_test_data.zip</span></pre><h2 id="56bb" class="mc md iq bd me mf mg dn mh mi mj dp mk lf ml mm mn lj mo mp mq ln mr ms mt mu bi translated">看着这些数据</h2><p id="4d3a" class="pw-post-body-paragraph kw kx iq ky b kz mv jr lb lc mw ju le lf mx lh li lj my ll lm ln mz lp lq lr ij bi translated">当我们着手解决一个问题时，首先要做的是看一看现有的数据。我们需要了解问题和数据是什么样的，然后才能找到解决方法。查看数据意味着了解数据目录的结构，标签是什么，以及一些示例图像是什么样子。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="ng nh l"/></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk">Use the pandas library to read the data</figcaption></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi ns"><img src="../Images/67c4650676e77addd62a02cbabb30e54.png" data-original-src="https://miro.medium.com/v2/resize:fit:1332/format:webp/1*QqEDQh2JqtmmlFT2cXG_-Q.png"/></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk">The labels of the data we’ll use to train our models</figcaption></figure><p id="19d0" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">处理影像分类数据集和表格数据集的主要区别在于标注的存储方式。这里的标签指的是图像中的内容。在这个特定的数据集中，标签存储在 CSV 文件中。</p><p id="ecc2" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">要了解更多关于如何计算<strong class="ky ir">分数</strong>栏的信息，请点击<a class="ae kv" href="https://success.figure-eight.com/hc/en-us/articles/201855939-How-to-Calculate-a-Confidence-Score" rel="noopener ugc nofollow" target="_blank"> <strong class="ky ir">此处</strong> </a>。</p><p id="98ca" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我们将使用 seaborn 的<code class="fe nt nu nv nj b">countplot </code>函数来查看我们的训练数据的分布。从该图中，我们可以看到大约 14，300 幅图像中没有油棕榈种植园，而只有 942 幅图像中有。这被称为<a class="ae kv" rel="noopener" target="_blank" href="/deep-learning-unbalanced-training-data-solve-it-like-this-6c528e9efea6">不平衡数据集</a>，这是一个深度学习问题，我们不打算在这里讨论；目前我们正在慢慢地走👶🏽。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="ng nh l"/></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk">Count of the two classes</figcaption></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi nw"><img src="../Images/474c4b2c57400277505a6310aea6a5ff.png" data-original-src="https://miro.medium.com/v2/resize:fit:796/format:webp/1*hD465Xp7BsrHg01jygcb1Q.png"/></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk">Distribution of the training dataset</figcaption></figure><h1 id="deb4" class="nx md iq bd me ny nz oa mh ob oc od mk jw oe jx mn jz of ka mq kc og kd mt oh bi translated">准备数据</h1><p id="5353" class="pw-post-body-paragraph kw kx iq ky b kz mv jr lb lc mw ju le lf mx lh li lj my ll lm ln mz lp lq lr ij bi translated">提供的测试数据位于两个独立的文件夹中，分别是<em class="ls">排行榜维持数据、</em>和<em class="ls">排行榜测试数据。</em>我们将把两者结合起来，因为比赛要求提交对两者的预测。我们组合了<code class="fe nt nu nv nj b">6534</code>个图像。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="ng nh l"/></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk">Combine <em class="oi">leaderboard holdout data </em>and <em class="oi">leaderboard test data</em></figcaption></figure><p id="3ae7" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我们将使用 fast.ai 的<a class="ae kv" href="https://github.com/fastai/fastai/blob/master/docs_src/data_block.ipynb" rel="noopener ugc nofollow" target="_blank">数据块 API </a>来构建数据，这是一种将数据集呈现给模型的便捷方式。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="ng nh l"/></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk">Creating an ImageList to hold the data</figcaption></figure><ul class=""><li id="5960" class="oj ok iq ky b kz la lc ld lf ol lj om ln on lr oo op oq or bi translated">我们将使用一个<code class="fe nt nu nv nj b">ImageList</code>来保存我们的训练数据，并使用<code class="fe nt nu nv nj b">from_df</code>方法。我们这样做是因为我们将关于训练集的信息存储在一个名为<code class="fe nt nu nv nj b">df</code>的数据帧中。我们告诉它在哪里可以找到我们的训练图像，<code class="fe nt nu nv nj b">path</code>以及保存图像的文件夹的名称，<code class="fe nt nu nv nj b">train_images</code>。</li><li id="ec5a" class="oj ok iq ky b kz os lc ot lf ou lj ov ln ow lr oo op oq or bi translated">接下来，我们使用随机拆分来拆分我们的训练集。我们希望留出 20%的数据来监控模型在训练期间的表现。我们选择了一个种子，以确保我们再次检查时得到相同的结果。我们需要知道什么可行，什么不可行。</li><li id="701c" class="oj ok iq ky b kz os lc ot lf ou lj ov ln ow lr oo op oq or bi translated">我们告诉<code class="fe nt nu nv nj b">ImageList</code>在哪里可以找到我们训练集中数据的标签，<code class="fe nt nu nv nj b">has_oilpalm</code>并添加我们刚刚合并的数据作为测试数据。</li><li id="7fec" class="oj ok iq ky b kz os lc ot lf ou lj ov ln ow lr oo op oq or bi translated">最后，我们对数据执行转换。用<code class="fe nt nu nv nj b">flip_vert = True</code>翻转图像有助于模型识别图像，不管它们的方向如何。我们将使用<code class="fe nt nu nv nj b">imagenet_stats</code>来标准化图像。<strong class="ky ir"> <em class="ls">注意:这是一种迁移学习技巧，为了尽可能简单起见，这就是我要说的。</em>🤐</strong></li></ul><h1 id="ea07" class="nx md iq bd me ny nz oa mh ob oc od mk jw oe jx mn jz of ka mq kc og kd mt oh bi translated">图像预览</h1><p id="119c" class="pw-post-body-paragraph kw kx iq ky b kz mv jr lb lc mw ju le lf mx lh li lj my ll lm ln mz lp lq lr ij bi translated">以下是有或没有油棕榈种植园的卫星图像:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="ng nh l"/></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk">Show 2 batches of images</figcaption></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi ox"><img src="../Images/9f08b6be91f8493eadd52c34d72a05bc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1118/format:webp/1*zcCcK6BgMTp4-Bx-1hksNg.png"/></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk">Images with oil palms are labeled 1, those without are 0</figcaption></figure><h1 id="e5d2" class="nx md iq bd me ny nz oa mh ob oc od mk jw oe jx mn jz of ka mq kc og kd mt oh bi translated">训练我们的模型</h1><p id="8b27" class="pw-post-body-paragraph kw kx iq ky b kz mv jr lb lc mw ju le lf mx lh li lj my ll lm ln mz lp lq lr ij bi translated">现在我们训练我们的模型。我们将使用一个<a class="ae kv" href="http://cs231n.github.io/convolutional-networks/" rel="noopener ugc nofollow" target="_blank">卷积神经网络</a>主干，并使用来自 resnet 模型的预训练权重，该模型已被训练用于对各种图像进行分类。不要管这具体是什么意思。目前，我们正在建立一个模型，该模型以卫星图像为输入，输出两个类别的预测概率。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="ng nh l"/></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk">Convolutional neural network</figcaption></figure></div><div class="ab cl lv lw hu lx" role="separator"><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma"/></div><div class="ij ik il im in"><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="ng nh l"/></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk">Find an optimal model learning rate</figcaption></figure><p id="2efe" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">接下来，我们使用<code class="fe nt nu nv nj b">lr_find()</code>找到一个理想的学习率，并使用<code class="fe nt nu nv nj b">recorder.plot()</code>将其可视化。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi oy"><img src="../Images/716ec73d27cf84a74d77b47ef74fdec2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*a6y2MmMqwj3iChOQuTDwwA.png"/></div></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk">Find an optimal model learning rate</figcaption></figure><p id="8104" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我们将选择一个接近斜率最陡的学习率，在我们的例子中是<code class="fe nt nu nv nj b">1e-2</code>。</p></div><div class="ab cl lv lw hu lx" role="separator"><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma"/></div><div class="ij ik il im in"><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="ng nh l"/></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk">Train model for 5 cycles with learning rate = 1e-2</figcaption></figure><p id="b893" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我们将使用<code class="fe nt nu nv nj b">fit_one_cycle</code>函数为我们的模型训练 5 个时期(通过所有数据的 5 个周期)。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi oz"><img src="../Images/d27e4f8eb9178eb9ed01a7533a97488d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1256/format:webp/1*kOtQopDMSFYG5s6ORxnTFw.png"/></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk">Training and validation losses</figcaption></figure><p id="73bd" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">注意显示的<code class="fe nt nu nv nj b">metrics</code>即<code class="fe nt nu nv nj b">training_loss</code>和<code class="fe nt nu nv nj b">valid_loss</code>？我们用它们来监控模型随时间的改进。</p><p id="f532" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我们最好的模型是在第四纪元获得的。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi pa"><img src="../Images/ec3479bbc2f184bacbc246baafa40042.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*AtnWInBLodhr2L1a2TDI4g.png"/></div></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk">The output of training our model; the progression of training and validation losses</figcaption></figure><p id="d38f" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">当你运行训练和验证数据集时，fast.ai 在内部只挑选和保存你的最佳模型。</p><h1 id="3085" class="nx md iq bd me ny nz oa mh ob oc od mk jw oe jx mn jz of ka mq kc og kd mt oh bi translated">评估我们的模型</h1><p id="e569" class="pw-post-body-paragraph kw kx iq ky b kz mv jr lb lc mw ju le lf mx lh li lj my ll lm ln mz lp lq lr ij bi translated">根据预测概率和观察目标<code class="fe nt nu nv nj b">has_oilpalm</code>之间的接收器工作特性曲线下的面积，对提交的竞赛进行评估。在这个<a class="ae kv" href="https://developers.google.com/machine-learning/crash-course/classification/roc-and-auc" rel="noopener ugc nofollow" target="_blank">开发者速成班</a>、这个<a class="ae kv" href="https://www.dataschool.io/roc-curves-and-auc-explained/" rel="noopener ugc nofollow" target="_blank">视频</a>或这个<a class="ae kv" href="https://www.kaggle.com/learn-forum/53782" rel="noopener ugc nofollow" target="_blank"> Kaggle 学习论坛</a>帖子中了解更多关于 AUC 的信息。Fast.ai 默认情况下没有这个指标，所以我们将使用 scikit-learn 库。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="ng nh l"/></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk">Print out validation metrics</figcaption></figure><p id="9091" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">使用预训练模型和 fast.ai 的好处在于，你可以获得非常好的预测精度，<code class="fe nt nu nv nj b">99.44%</code>在我们的情况下，无需做最多的事情。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi pb"><img src="../Images/b6d97ce1ef0f230f5444363d7ffcacad.png" data-original-src="https://miro.medium.com/v2/resize:fit:864/format:webp/1*ONxS6xsqEXLr4_bhWeF8JQ.png"/></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk">The metrics for the first stage of training</figcaption></figure><p id="08aa" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">让我们保存我们的模型，并绘制一个关于预测的混淆矩阵。</p><pre class="kg kh ki kj gt ni nj nk nl aw nm bi"><span id="1b43" class="mc md iq nj b gy nn no l np nq">learn.save('resnet50-stg1')</span></pre><h1 id="7b6e" class="nx md iq bd me ny nz oa mh ob oc od mk jw oe jx mn jz of ka mq kc og kd mt oh bi translated">使用混淆矩阵查看结果</h1><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="ng nh l"/></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk">Plot confusion matrix</figcaption></figure><p id="cf4c" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">混淆矩阵是查看模型准确或不准确预测的图像数量的图形方式。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi pc"><img src="../Images/e533943403f645efc8216ab4c58f0831.png" data-original-src="https://miro.medium.com/v2/resize:fit:932/format:webp/1*G9juDWONQuFpA_O3WrDMcw.png"/></div></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk">Confusion matrix for the first stage of training</figcaption></figure><p id="85e0" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">从该图中，我们可以看到，该模型准确预测了 2，863 幅图像中没有油棕榈种植园，168 幅图像中有油棕榈种植园被正确分类。包含油棕种植园的 10 幅图像被分类为没有，而不包含油棕种植园的 7 幅图像被分类为有。</p><p id="982e" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">对于一个简单的模型🥳.来说还不错</p><p id="7e99" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">接下来，我们为这个训练迭代找到一个理想的学习率。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="ng nh l"/></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk">Find an ideal learning rate</figcaption></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi pd"><img src="../Images/94feb5c4745dab4e15f23ef07098ef80.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*UIFYAIFfOmYfYpcpYPb2oA.png"/></div></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk">We choose a learning rate that’s between <code class="fe nt nu nv nj b">1e-6</code> and <code class="fe nt nu nv nj b">1e-4</code></figcaption></figure><p id="ae26" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">使用 7 个时期内<code class="fe nt nu nv nj b">1e-6</code>和<code class="fe nt nu nv nj b">1e-4</code>之间的最大学习速率来拟合模型。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="ng nh l"/></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk">Train model for 7 cycles, the learning rate shouldn’t exceed the range of 1e-6 and 1e-4</figcaption></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi ns"><img src="../Images/3308dbbaaab76df3ad4db1e25b031af3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1332/format:webp/1*mokJC4j8lge6oSRtwXT91Q.png"/></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk">Training and validation losses</figcaption></figure><p id="b2fd" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">以图形方式观察训练指标，以在每个训练周期后监控模型的性能。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi pe"><img src="../Images/4359184c02a2b3af069499fe4f28a5d4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Dy6VutYWum8xQa_VPW0wkg.png"/></div></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk">The output of training our model; the progression of training and validation losses</figcaption></figure><p id="587b" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">省去第二阶段的模型训练。</p><pre class="kg kh ki kj gt ni nj nk nl aw nm bi"><span id="f324" class="mc md iq nj b gy nn no l np nq">learn.save('resnet50-stg2')</span></pre><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="ng nh l"/></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk">Accuracy, error rate and AUC score</figcaption></figure><p id="1e18" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">打印出模型的精确度、误差率和曲线下面积。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi pf"><img src="../Images/0aed8e4657276dd6f1f6c878f2498ac4.png" data-original-src="https://miro.medium.com/v2/resize:fit:900/format:webp/1*ZLk_RrjIHJrKPvH3S13e2w.png"/></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk">The metrics for the second stage of training</figcaption></figure><p id="abc1" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">你会注意到模型的精确度从<code class="fe nt nu nv nj b">99.44%</code>提高到<code class="fe nt nu nv nj b">99.48%</code>。错误率从<code class="fe nt nu nv nj b">0.0056</code>降低到<code class="fe nt nu nv nj b">0.0052</code>。AUC 也有所改善，从<code class="fe nt nu nv nj b">99.82%</code>到<code class="fe nt nu nv nj b">99.87%.</code></p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="ng nh l"/></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk">Plot confusion matrix</figcaption></figure><p id="6cb7" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">与我们绘制的上一个混淆矩阵相比，你会注意到这个模型做出了更好的预测。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi pc"><img src="../Images/74a49ac139ba39d95aea771e3c3584f4.png" data-original-src="https://miro.medium.com/v2/resize:fit:932/format:webp/1*JunKQo_4IYQE7lswkmi8UA.png"/></div></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk">Confusion matrix for the second stage of training</figcaption></figure><p id="7b15" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">以前 7 张没有油棕榈种植园的图片被错误分类，现在我们减少到 3 张。这就是进步。</p><p id="ca13" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">你会注意到我们在训练中一直遵循一个模式，并在这个过程中调整了一些参数。我们一直在做的叫做调谐。大多数深度学习实验都遵循类似的迭代模式。</p></div><div class="ab cl lv lw hu lx" role="separator"><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma"/></div><div class="ij ik il im in"><h2 id="b3c3" class="mc md iq bd me mf mg dn mh mi mj dp mk lf ml mm mn lj mo mp mq ln mr ms mt mu bi translated">图像转换</h2><p id="bcb9" class="pw-post-body-paragraph kw kx iq ky b kz mv jr lb lc mw ju le lf mx lh li lj my ll lm ln mz lp lq lr ij bi translated">我们将对数据执行更多的图像转换。这应该会改进我们的模型。每个转换的详细描述可以在 fast.ai <a class="ae kv" href="https://docs.fast.ai/vision.transform.html" rel="noopener ugc nofollow" target="_blank">文档</a>中找到:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="ng nh l"/></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk">Applying different transforms to improve our model</figcaption></figure><ul class=""><li id="5a49" class="oj ok iq ky b kz la lc ld lf ol lj om ln on lr oo op oq or bi translated"><code class="fe nt nu nv nj b">max_lighting</code>:如果不是<code class="fe nt nu nv nj b">None</code>，则以概率 p_lighting 应用由 max_lighting 控制的随机闪电和对比度变化</li><li id="b75a" class="oj ok iq ky b kz os lc ot lf ou lj ov ln ow lr oo op oq or bi translated"><code class="fe nt nu nv nj b">max_zoom</code>:如果不是<code class="fe nt nu nv nj b">1.</code>或更小，则以概率 p_affine 应用<code class="fe nt nu nv nj b">1.</code>和 max_zoom 之间的随机缩放</li><li id="5a24" class="oj ok iq ky b kz os lc ot lf ou lj ov ln ow lr oo op oq or bi translated"><code class="fe nt nu nv nj b">max_warp</code>:如果不是<code class="fe nt nu nv nj b">None</code>，则以概率 p_affine 应用在<code class="fe nt nu nv nj b">-max_warp</code>和<code class="fe nt nu nv nj b">max_warp</code>之间的大小的随机对称扭曲</li></ul></div><div class="ab cl lv lw hu lx" role="separator"><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma"/></div><div class="ij ik il im in"><p id="f23d" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我们又找到了一个最优学习率。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="ng nh l"/></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk">Find an ideal learning rate</figcaption></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi pg"><img src="../Images/6df98bfa697ea88e0b3322ef0fc57809.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*QrjNAK5eCFHECmqPUZRKoA.png"/></div></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk">We chose a learning rate of 1e-6</figcaption></figure><p id="51df" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">5 个周期的训练模型。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="ng nh l"/></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk">Train for 5 cycles</figcaption></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi ph"><img src="../Images/1b81a88b093ee913d6f2d5682c574e3e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1260/format:webp/1*jxIuEMos7TvhrqsmwcFk6Q.png"/></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk">Training and validation losses</figcaption></figure><p id="b4c9" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">比较培训指标，并与过去的指标进行比较。我们的模型在这次迭代中<code class="fe nt nu nv nj b">0.0169</code>比<code class="fe nt nu nv nj b">0.0163</code>稍差。不要绝望。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi pe"><img src="../Images/2d4d12bf99b010243010f1abeab336e2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*8vmj3XkrwdUGhFdFPKjhvg.png"/></div></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk">The output of training our model; the best model is at epoch 3</figcaption></figure></div><div class="ab cl lv lw hu lx" role="separator"><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma"/></div><div class="ij ik il im in"><p id="caa3" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">保存模型培训的第三阶段，并打印出指标。你会注意到，模型的精度现在是<code class="fe nt nu nv nj b">99.38%</code>，在前一阶段是<code class="fe nt nu nv nj b">99.48%</code>。AUC 得分从<code class="fe nt nu nv nj b">99.87%</code>提高到<code class="fe nt nu nv nj b">99.91%</code>，这是对竞争进行评级的指标。</p><pre class="kg kh ki kj gt ni nj nk nl aw nm bi"><span id="4f80" class="mc md iq nj b gy nn no l np nq">learn.save('resnet50-stg3')</span></pre><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="ng nh l"/></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk">Accuracy, error rate and AUC score</figcaption></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi pi"><img src="../Images/00c925b93fc63c543886fee6fd8f2821.png" data-original-src="https://miro.medium.com/v2/resize:fit:880/format:webp/1*u3eICUlY-r5_7YUqqVzuqg.png"/></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk">The metrics for the third stage of training</figcaption></figure><h1 id="659a" class="nx md iq bd me ny nz oa mh ob oc od mk jw oe jx mn jz of ka mq kc og kd mt oh bi translated">最终培训阶段</h1><p id="9136" class="pw-post-body-paragraph kw kx iq ky b kz mv jr lb lc mw ju le lf mx lh li lj my ll lm ln mz lp lq lr ij bi translated">如果你注意到我们从有<code class="fe nt nu nv nj b">size = 164</code>的图像开始，我们逐渐建立，直到我们到达下面的<code class="fe nt nu nv nj b">size = 256</code>。我们这样做是为了利用 fast.ai 的渐进式图像大小调整进行分类，即在训练开始时使用小图像，并随着训练的进行逐渐增加大小。这样，当模型在早期非常不准确时，它可以快速看到大量图像并取得快速进展，然后在训练中，它可以看到更大的图像以了解更精细的区别。点击<a class="ae kv" href="https://www.fast.ai/2018/08/10/fastai-diu-imagenet/" rel="noopener ugc nofollow" target="_blank">这里</a>阅读更多相关内容。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="ng nh l"/></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk">Applying different transforms to improve model, increased image sizes to 256</figcaption></figure><p id="4dbd" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我们又找到了一个最优学习率。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="ng nh l"/></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk">Find an ideal learning rate</figcaption></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi pj"><img src="../Images/3f091fa3e5ab60186ffde7e8109880cc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*oJ_0B04K9iMyh4YJ-XiOUw.png"/></div></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk">Find an ideal learning rate</figcaption></figure><p id="d3bd" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">使用 5 个时期的学习率<code class="fe nt nu nv nj b">1e-4</code>拟合模型。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="ng nh l"/></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk">Train model for 5 cycles, the learning rate is set to 1e-4</figcaption></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi pk"><img src="../Images/6b8b57733e6e1ae680aeb1c393b83c93.png" data-original-src="https://miro.medium.com/v2/resize:fit:1328/format:webp/1*XHr86rkhyskZZCU5xfkcJg.png"/></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk">Training and validation losses</figcaption></figure><p id="4600" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">观察培训指标，并与过去的指标进行比较。我们的模型做了一点改进，从<code class="fe nt nu nv nj b">0.0169</code>到<code class="fe nt nu nv nj b">0.0168</code>。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi pl"><img src="../Images/fa80b83cf398e4103d8e501f3efcb519.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_4zGbp1LevXlqP1151ZhTA.png"/></div></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk">The output of training our model; the best model is at epoch 2</figcaption></figure><p id="ccda" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">保存模型训练的最后阶段并打印出指标。</p><pre class="kg kh ki kj gt ni nj nk nl aw nm bi"><span id="f0fe" class="mc md iq nj b gy nn no l np nq">learn.save('resnet50-stg4')</span></pre><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="ng nh l"/></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk">Accuracy, error rate and AUC score</figcaption></figure><p id="02f0" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">正如你所注意到的，模型的精度现在是<code class="fe nt nu nv nj b">99.44%</code>，这比上次训练阶段<code class="fe nt nu nv nj b">99.38%</code>有所提高。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi pm"><img src="../Images/10cb7d8aef6c0615a04a1fc4f8474326.png" data-original-src="https://miro.medium.com/v2/resize:fit:924/format:webp/1*aIwOWP2S3Qyk7HncZgsYhg.png"/></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk">The metrics for the fourth stage of training</figcaption></figure><h1 id="4c66" class="nx md iq bd me ny nz oa mh ob oc od mk jw oe jx mn jz of ka mq kc og kd mt oh bi translated">准备竞赛提交文件</h1><p id="6275" class="pw-post-body-paragraph kw kx iq ky b kz mv jr lb lc mw ju le lf mx lh li lj my ll lm ln mz lp lq lr ij bi translated">现在我们可以看到我们的模型对尚未看到的数据的预测有多好。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="ng nh l"/></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk">Prepare a CSV submission file</figcaption></figure><h1 id="fb43" class="nx md iq bd me ny nz oa mh ob oc od mk jw oe jx mn jz of ka mq kc og kd mt oh bi translated">向 WiDS Datathon 提交一份材料</h1><p id="e76e" class="pw-post-body-paragraph kw kx iq ky b kz mv jr lb lc mw ju le lf mx lh li lj my ll lm ln mz lp lq lr ij bi translated">您仍然可以参加 WiDS 竞赛，并提交一份迟交的材料。为此，请点击进入竞赛页面<a class="ae kv" href="https://www.kaggle.com/c/widsdatathon2019" rel="noopener ugc nofollow" target="_blank">，点击<strong class="ky ir">加入竞赛</strong>并接受竞赛规则。现在你可以提交一份申请，看看如果你参加的话，你的排名会是多少。</a></p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi pn"><img src="../Images/07c1ccb15cf5884080ce31c40336e2b1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*yjTei2AcfdAgruGU6v3ICA.png"/></div></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk">Private and Public Scores for the submission I made from our model’s predictions.</figcaption></figure><p id="132c" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">声明:文章中的说明不会像我们一样把你放在第三位，我想尽可能保持简单。要弄清楚这一点，请查看<a class="lt lu ep" href="https://medium.com/u/d4284ce02aec?source=post_page-----644adcc143c8--------------------------------" rel="noopener" target="_blank"> Abdishakur </a>关于它的帖子<a class="ae kv" href="https://www.kaggle.com/c/widsdatathon2019/discussion/82252" rel="noopener ugc nofollow" target="_blank">这里</a>。</p><p id="ebbb" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">好奇想了解更多？看看这个由杰瑞米·霍华德和 fast.ai 团队策划的惊人的 7 部分系列讲座。</p></div></div>    
</body>
</html>