<html>
<head>
<title>K-Means Clustering Chardonnay Reviews using Scikit-Learn &amp; NLTK</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">K-Means 使用 Scikit-Learn &amp; NLTK 对 Chardonnay 评论进行聚类</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/k-means-clustering-chardonnay-reviews-using-scikit-learn-nltk-9df3c59527f3?source=collection_archive---------17-----------------------#2019-11-05">https://towardsdatascience.com/k-means-clustering-chardonnay-reviews-using-scikit-learn-nltk-9df3c59527f3?source=collection_archive---------17-----------------------#2019-11-05</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><figure class="is it gp gr iu iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi ir"><img src="../Images/169d3cdbd249cf34be9f728e89a8f93b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*KmlxewrKZ991xI3w06iRRA.png"/></div></div></figure><div class=""/><p id="5aed" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">霞多丽是世界上最受欢迎的白葡萄酒。这种葡萄很容易种植，它以复杂和适应不同的技术和口味而闻名。例如，昨晚我尝了一种甜味的未发酵的夏敦埃酒。霞多丽到底有多受欢迎？正如<a class="ae kz" href="https://www.nass.usda.gov/Statistics_by_State/California/Publications/Specialty_and_Other_Releases/Grapes/Acreage/2019/201904grpacSUMMARY2018Crop.pdf" rel="noopener ugc nofollow" target="_blank"> 2018 年加州葡萄种植面积报告</a>所述，在 176，092 英亩专用于白葡萄酒的总面积中，霞多丽消耗了一半以上，为 93，148 英亩！下一个最高的品种是法国科隆巴德，消耗 18246 英亩；相比之下微不足道。那是许多葡萄！</p><figure class="lb lc ld le gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi la"><img src="../Images/f6d24e8765eb648965eede6dea7341b5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*rZKe4oOmwb4RA-BnPD505w.png"/></div></div></figure></div><div class="ab cl lf lg hx lh" role="separator"><span class="li bw bk lj lk ll"/><span class="li bw bk lj lk ll"/><span class="li bw bk lj lk"/></div><div class="im in io ip iq"><p id="d34a" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi lm translated"><span class="l ln lo lp bm lq lr ls lt lu di"> S </span>因为我熟悉 kaggle 上的<a class="ae kz" href="https://www.kaggle.com/zynicide/wine-reviews" rel="noopener ugc nofollow" target="_blank">葡萄酒评论数据集，所以我决定加载一个笔记本来分析夏敦埃酒。</a></p><blockquote class="lv lw lx"><p id="b6ab" class="kb kc ly kd b ke kf kg kh ki kj kk kl lz kn ko kp ma kr ks kt mb kv kw kx ky im bi translated">聚类能帮助我们确定描述和评级之间的关系吗？</p></blockquote><p id="55cf" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">在本文中，我将展示如何使用<a class="ae kz" href="https://scikit-learn.org/stable/" rel="noopener ugc nofollow" target="_blank"> Scikit-Learn </a>和<a class="ae kz" href="https://www.nltk.org/" rel="noopener ugc nofollow" target="_blank">自然语言工具包</a>来处理、分析和聚类 Chardonnay 数据。通过使用这些技术，我希望能看到评分高于平均水平的葡萄酒评论和评分低于平均水平的葡萄酒评论在主题或话题上是否有所不同。</p><h1 id="530f" class="mc md je bd me mf mg mh mi mj mk ml mm mn mo mp mq mr ms mt mu mv mw mx my mz bi translated">导入依赖项和数据</h1><p id="5a14" class="pw-post-body-paragraph kb kc je kd b ke na kg kh ki nb kk kl km nc ko kp kq nd ks kt ku ne kw kx ky im bi translated">因为这篇文章结合了几种技术来分析 Chardonnay 评论，所以我们有相当多的东西要导入。此外，<a class="ae kz" rel="noopener" target="_blank" href="/generating-wine-recommendations-using-the-universal-sentence-encoder-d086edd13d00">我对数据集</a>做了一些初步清理，删除了重复和空值，并将其存储在 SQLite 数据库中:</p><pre class="lb lc ld le gt nf ng nh ni aw nj bi"><span id="ab59" class="nk md je ng b gy nl nm l nn no">#import dependencies<br/>import pandas as pd<br/>import numpy as np<br/>import matplotlib.pyplot as plt<br/>import seaborn as sns<br/>import re</span><span id="f0a5" class="nk md je ng b gy np nm l nn no">from sklearn import preprocessing, decomposition, model_selection, metrics, pipeline<br/>from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer<br/>from sklearn.cluster import KMeans</span><span id="44af" class="nk md je ng b gy np nm l nn no">import nltk<br/>from nltk.stem.wordnet import WordNetLemmatizer<br/>from nltk.corpus import stopwords</span><span id="1760" class="nk md je ng b gy np nm l nn no">import sqlite3<br/>from sqlite3 import Error</span><span id="af1f" class="nk md je ng b gy np nm l nn no">#force output to display the full description<br/>pd.set_option('display.max_colwidth', -1)</span><span id="015f" class="nk md je ng b gy np nm l nn no">#connect to database file<br/>conn = sqlite3.connect('db\wine_data.sqlite')<br/>c = conn.cursor()</span><span id="8227" class="nk md je ng b gy np nm l nn no">#create dataframe from sql query<br/>df = pd.read_sql("Select country, description, rating, price, title, variety from wine_data where variety = 'Chardonnay'", conn)</span><span id="18ab" class="nk md je ng b gy np nm l nn no">#display the top 3 rows<br/>df.head(3)</span></pre><figure class="lb lc ld le gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi nq"><img src="../Images/db20bdaf08c88dae6f130a2584cac887.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*oxXW4g-yA7wVXqIWOPCFJQ.png"/></div></div></figure><h1 id="d004" class="mc md je bd me mf mg mh mi mj mk ml mm mn mo mp mq mr ms mt mu mv mw mx my mz bi translated">特征工程和分析</h1><p id="387f" class="pw-post-body-paragraph kb kc je kd b ke na kg kh ki nb kk kl km nc ko kp kq nd ks kt ku ne kw kx ky im bi translated">从一开始，我就知道我想添加几个特性:首先，我将添加字数统计列来存储每个描述中的字数。其次，我将添加一个二进制字段来表示葡萄酒的评级是否高于平均水平。在我添加这些功能之前，我需要做一些分析来找到平均评级。</p><h2 id="44d2" class="nk md je bd me nr ns dn mi nt nu dp mm km nv nw mq kq nx ny mu ku nz oa my ob bi translated">分析字数</h2><p id="9a82" class="pw-post-body-paragraph kb kc je kd b ke na kg kh ki nb kk kl km nc ko kp kq nd ks kt ku ne kw kx ky im bi translated">分析字数可以帮助您决定是否要缩减数据集。例如，查看数据，我们看到一篇葡萄酒评论的最小字数是 3 个词。查看少于 15 个单词的评论，平均评分是 82 分，范围是 80-100 分。这告诉我，简短的评论可能与较低的评级有关。同样，当我观察分布的另一端时，我注意到较长的评论可能与较高的评级相关。</p><blockquote class="oc"><p id="c29d" class="od oe je bd of og oh oi oj ok ol ky dk translated">简短的评论可能与较低的评级相关联。更长的评论可能与更高的评级相关联。</p></blockquote><pre class="om on oo op oq nf ng nh ni aw nj bi"><span id="737c" class="nk md je ng b gy nl nm l nn no">#add a column for the word count<br/>df['word_count'] = df['description'].apply(lambda x: len(str(x).split(" ")))</span><span id="9e1b" class="nk md je ng b gy np nm l nn no">print("Word Count Median: " + str(df['word_count'].median()))<br/>print(df['word_count'].describe())</span><span id="32e2" class="nk md je ng b gy np nm l nn no">x = df['word_count']<br/>n_bins = 95</span><span id="3cbc" class="nk md je ng b gy np nm l nn no">plt.hist(x, bins=n_bins)<br/>plt.xlabel('Number of Words in Description')<br/>plt.ylabel('Frequency')<br/>plt.show()</span></pre><figure class="lb lc ld le gt iv gh gi paragraph-image"><div class="gh gi or"><img src="../Images/53869c18bb39e3c04dbbdbda0e3e6cb2.png" data-original-src="https://miro.medium.com/v2/resize:fit:888/format:webp/1*dCZ4JpATvUQvN-X9vDh2jQ.png"/></div></figure><pre class="lb lc ld le gt nf ng nh ni aw nj bi"><span id="11de" class="nk md je ng b gy nl nm l nn no">#word counts less than 15<br/>wc15 = df.loc[df['word_count'] &lt; 15]<br/>print(wc15.rating.median())<br/>print(wc15.rating.describe())</span><span id="4b5e" class="nk md je ng b gy np nm l nn no">#word counts greater than 70<br/>wc70 = df.loc[df['word_count'] &gt; 70]<br/>print(wc70.rating.median())<br/>print(wc70.rating.describe())</span><span id="0a8e" class="nk md je ng b gy np nm l nn no">#plot the counts<br/>plt.figure(figsize=(14,4))<br/>sns.countplot(x ='rating', data = wc70).set_title("Rating Counts")</span></pre><p id="f467" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">数据可以可视化，帮助我们看到字数和评分之间的关系。</p><figure class="lb lc ld le gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi os"><img src="../Images/d072b63b986e552d6ea11d6afae9f6b2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*vmNtZ6icpjYbaEsNkOFehg.png"/></div></div><figcaption class="ot ou gj gh gi ov ow bd b be z dk">Rating Counts where Word_Count &lt; 15</figcaption></figure><figure class="lb lc ld le gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi ox"><img src="../Images/06f8232929708cc1d2c4dae207f3c053.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*rNT3rOT7L_hd1F-SW62g8g.png"/></div></div><figcaption class="ot ou gj gh gi ov ow bd b be z dk">Rating Counts where Word_Count &gt; 70</figcaption></figure></div><div class="ab cl lf lg hx lh" role="separator"><span class="li bw bk lj lk ll"/><span class="li bw bk lj lk ll"/><span class="li bw bk lj lk"/></div><div class="im in io ip iq"><h2 id="ce6c" class="nk md je bd me nr ns dn mi nt nu dp mm km nv nw mq kq nx ny mu ku nz oa my ob bi translated">分析评级</h2><p id="6044" class="pw-post-body-paragraph kb kc je kd b ke na kg kh ki nb kk kl km nc ko kp kq nd ks kt ku ne kw kx ky im bi translated">因为我想看看描述是否可以用来区分葡萄酒是否高于平均评级，所以我必须找到平均评级。熊猫<em class="ly">描述</em>功能使统计数据的查找变得简单。看数据，我们得到的平均评分是 88。使用 list comprehension 很容易将二进制值列添加到数据框中。如果评分大于 88，我们的新列将为 1。如果等级为 88 或更低，值将为 0，因为葡萄酒并不比平均水平好。</p><blockquote class="oc"><p id="bd2d" class="od oe je bd of og oh oi oj ok ol ky dk translated">如果评分大于 88，我们的新列将为 1。如果等级为 88 或更低，值将为 0，因为葡萄酒并不比平均水平好。</p></blockquote><pre class="om on oo op oq nf ng nh ni aw nj bi"><span id="5a43" class="nk md je ng b gy nl nm l nn no">print("Number of Unique Ratings: " + str(len(df['rating'].unique())))</span><span id="a652" class="nk md je ng b gy np nm l nn no">print("Rating Median: " + str(df['rating'].median()))<br/>print(df['rating'].describe())</span><span id="2a15" class="nk md je ng b gy np nm l nn no">plt.figure(figsize=(14,4))<br/>sns.countplot(x='rating', data=df).set_title("Rating Counts")<br/>plt.show()</span><span id="39c7" class="nk md je ng b gy np nm l nn no">#add column to flag records with rating greater than 88<br/>df['above_avg'] = [1 if rating &gt; 88 else 0 for rating in df['rating']]</span></pre><figure class="lb lc ld le gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi oy"><img src="../Images/4011930ae97d2adf1db302e23bee4a60.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*o0rAiijoXQLKWLlax79JMg.png"/></div></div><figcaption class="ot ou gj gh gi ov ow bd b be z dk">Distribution of Chardonnay Ratings</figcaption></figure></div><div class="ab cl lf lg hx lh" role="separator"><span class="li bw bk lj lk ll"/><span class="li bw bk lj lk ll"/><span class="li bw bk lj lk"/></div><div class="im in io ip iq"><h1 id="65f8" class="mc md je bd me mf oz mh mi mj pa ml mm mn pb mp mq mr pc mt mu mv pd mx my mz bi translated">自然语言处理</h1><p id="cb3b" class="pw-post-body-paragraph kb kc je kd b ke na kg kh ki nb kk kl km nc ko kp kq nd ks kt ku ne kw kx ky im bi translated">在对数据进行聚类之前，我使用了几种 NLP 技术，比如删除停用词、标点符号和特殊字符，以及对文本进行规范化。处理完文本后，我将使用<a class="ae kz" href="https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html" rel="noopener ugc nofollow" target="_blank"> Scikit-Learn tf-idf 矢量器</a>对文本进行矢量化。</p><h2 id="2988" class="nk md je bd me nr ns dn mi nt nu dp mm km nv nw mq kq nx ny mu ku nz oa my ob bi translated">清理文本</h2><p id="0f9f" class="pw-post-body-paragraph kb kc je kd b ke na kg kh ki nb kk kl km nc ko kp kq nd ks kt ku ne kw kx ky im bi translated">在聚类之前，我想删除停用词。停用词是常见的词，如“the”和“of”将它们从描述中移除可以突出更相关的常用词。我通过词频来判断是否应该将额外的词添加到停用词表中。此外，我使用<a class="ae kz" href="https://en.wikipedia.org/wiki/Regular_expression" rel="noopener ugc nofollow" target="_blank">正则表达式</a>清理描述，删除标点符号、标签和特殊字符，然后对单词进行词汇化，将单词简化为词根形式，同时保持它是一个真实的单词。词条满足是一种规范化文本的技术:</p><pre class="lb lc ld le gt nf ng nh ni aw nj bi"><span id="ca73" class="nk md je ng b gy nl nm l nn no">#create a list of stop words<br/>stop_words = set(stopwords.words("english"))</span><span id="8515" class="nk md je ng b gy np nm l nn no">#show how many words are in the list of stop words<br/>print(len(stop_words))<br/>#179</span><span id="5639" class="nk md je ng b gy np nm l nn no">#construct a new list to store the cleaned text<br/>clean_desc = []<br/>for w in range(len(df.description)):<br/>    desc = df['description'][w].lower()<br/>    <br/>    #remove punctuation<br/>    desc = re.sub('[^a-zA-Z]', ' ', desc)<br/>    <br/>    #remove tags<br/>    desc = re.sub("&amp;lt;/?.*?&amp;gt;"," &amp;lt;&amp;gt; ",desc)<br/>    <br/>    #remove special characters and digits<br/>    desc = re.sub("(\\d|\\W)+"," ",desc)<br/>    <br/>    split_text = desc.split()<br/>    <br/>    #Lemmatisation<br/>    lem = WordNetLemmatizer()<br/>    split_text = [lem.lemmatize(word) for word in split_text if not word in stop_words and len(word) &gt;2] <br/>    split_text = " ".join(split_text)<br/>    clean_desc.append(split_text)</span></pre></div><div class="ab cl lf lg hx lh" role="separator"><span class="li bw bk lj lk ll"/><span class="li bw bk lj lk ll"/><span class="li bw bk lj lk"/></div><div class="im in io ip iq"><h2 id="899b" class="nk md je bd me nr ns dn mi nt nu dp mm km nv nw mq kq nx ny mu ku nz oa my ob bi translated">使用 TF-IDF 对文本进行矢量化</h2><p id="03de" class="pw-post-body-paragraph kb kc je kd b ke na kg kh ki nb kk kl km nc ko kp kq nd ks kt ku ne kw kx ky im bi translated">tfidf vector 将文本转换成一个<a class="ae kz" href="https://en.wikipedia.org/wiki/Vector_space_model" rel="noopener ugc nofollow" target="_blank">向量空间</a>。为了简化概念，假设你有两个句子:</p><blockquote class="lv lw lx"><p id="d092" class="kb kc ly kd b ke kf kg kh ki kj kk kl lz kn ko kp ma kr ks kt mb kv kw kx ky im bi translated">狗是白色的，猫是黑色的</p></blockquote><p id="ed53" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">将句子转换为向量空间模型会以这样的方式转换它们，即查看所有句子中的单词，然后用数字表示句子中的单词。例如，如果单词在句子中，它就是 1。如果该单词不在句子中，则用 0 表示:</p><blockquote class="lv lw lx"><p id="4992" class="kb kc ly kd b ke kf kg kh ki kj kk kl lz kn ko kp ma kr ks kt mb kv kw kx ky im bi translated">狗是白色的猫是黑色的狗是白色的猫是黑色的</p></blockquote><p id="e1b5" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated"><a class="ae kz" href="https://en.wikipedia.org/wiki/Tf%E2%80%93idf" rel="noopener ugc nofollow" target="_blank"> TF-IDF </a>代表<strong class="kd jf">词频-逆文档频率</strong>。这是一种对单词值进行加权而不是简单计数的方法。它用于确定一个单词对集合文档中的文本有多重要。该功能对于搜索引擎和文本挖掘等信息检索非常有用。Scikit-Learn 中的<a class="ae kz" href="https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html" rel="noopener ugc nofollow" target="_blank">tfidf 矢量器将一组原始文档转换成 TF-IDF 特征矩阵。它使用<em class="ly"> fit_transform </em>方法返回矩阵。</a></p><pre class="lb lc ld le gt nf ng nh ni aw nj bi"><span id="ee06" class="nk md je ng b gy nl nm l nn no">#TF-IDF vectorizer<br/>tfv = TfidfVectorizer(stop_words = stop_words, ngram_range = (1,1))</span><span id="4364" class="nk md je ng b gy np nm l nn no">#transform<br/>vec_text = tfv.fit_transform(clean_desc)</span><span id="ffdb" class="nk md je ng b gy np nm l nn no">#returns a list of words.<br/>words = tfv.get_feature_names()</span></pre></div><div class="ab cl lf lg hx lh" role="separator"><span class="li bw bk lj lk ll"/><span class="li bw bk lj lk ll"/><span class="li bw bk lj lk"/></div><div class="im in io ip iq"><h2 id="80e8" class="nk md je bd me nr ns dn mi nt nu dp mm km nv nw mq kq nx ny mu ku nz oa my ob bi translated">基于 K-均值聚类的主题抽取</h2><p id="ea02" class="pw-post-body-paragraph kb kc je kd b ke na kg kh ki nb kk kl km nc ko kp kq nd ks kt ku ne kw kx ky im bi translated"><a class="ae kz" href="https://en.wikipedia.org/wiki/K-means_clustering" rel="noopener ugc nofollow" target="_blank"> K-means 聚类</a>是一种流行的无监督学习算法，可用于通过将相似的评论分组在一起并产生常用词列表来提取主题。我将试着把数据分成 21 组(n_clusters = 21 ),看看我是否能发现在高评分中常见的主题和在低评分中常见的主题。<a class="ae kz" href="https://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html#sklearn.cluster.KMeans" rel="noopener ugc nofollow" target="_blank"> Scikit-Learn 使 k-means 的应用变得简单</a>。</p><pre class="lb lc ld le gt nf ng nh ni aw nj bi"><span id="506c" class="nk md je ng b gy nl nm l nn no">#setup kmeans clustering<br/>kmeans = KMeans(n_clusters = 21, n_init = 17, n_jobs = -1, tol = 0.01, max_iter = 200)</span><span id="a3b0" class="nk md je ng b gy np nm l nn no">#fit the data <br/>kmeans.fit(vec_text)</span><span id="6641" class="nk md je ng b gy np nm l nn no">#this loop transforms the numbers back into words<br/>common_words = kmeans.cluster_centers_.argsort()[:,-1:-11:-1]<br/>for num, centroid in enumerate(common_words):<br/>    print(str(num) + ' : ' + ', '.join(words[word] for word in centroid))</span></pre><figure class="lb lc ld le gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi pe"><img src="../Images/dec45311a7916a95b24231e99939cb34.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*BwPHPowzVitzKZdkYfUtMQ.png"/></div></div></figure></div><div class="ab cl lf lg hx lh" role="separator"><span class="li bw bk lj lk ll"/><span class="li bw bk lj lk ll"/><span class="li bw bk lj lk"/></div><div class="im in io ip iq"><h1 id="7c1d" class="mc md je bd me mf oz mh mi mj pa ml mm mn pb mp mq mr pc mt mu mv pd mx my mz bi translated">将结果可视化</h1><p id="7d3e" class="pw-post-body-paragraph kb kc je kd b ke na kg kh ki nb kk kl km nc ko kp kq nd ks kt ku ne kw kx ky im bi translated">使用热图，我可以看到评级是如何聚集的。我还可以看到高于平均水平的评级与低于平均水平或低于平均水平的评级相比是否聚集在一起。</p><pre class="lb lc ld le gt nf ng nh ni aw nj bi"><span id="1bbb" class="nk md je ng b gy nl nm l nn no">#add the cluster label to the data frame<br/>df['cluster'] = kmeans.labels_</span><span id="bb22" class="nk md je ng b gy np nm l nn no">clusters = df.groupby(['cluster', 'rating']).size()</span><span id="3dc9" class="nk md je ng b gy np nm l nn no">fig, ax1 = plt.subplots(figsize = (26, 15))<br/>sns.heatmap(clusters.unstack(level = 'rating'), ax = ax1, cmap = 'Reds')</span><span id="743e" class="nk md je ng b gy np nm l nn no">ax1.set_xlabel('rating').set_size(18)<br/>ax1.set_ylabel('cluster').set_size(18)</span><span id="3c06" class="nk md je ng b gy np nm l nn no">clusters = df.groupby(['cluster', 'above_avg']).size()<br/>fig2, ax2 = plt.subplots(figsize = (30, 15))<br/>sns.heatmap(clusters.unstack(level = 'above_avg'), ax = ax2, cmap="Reds")</span><span id="2ba2" class="nk md je ng b gy np nm l nn no">ax2.set_xlabel('Above Average Rating').set_size(18)<br/>ax2.set_ylabel('Cluster').set_size(18)</span></pre><figure class="lb lc ld le gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi pf"><img src="../Images/2da9ecbb821e5051245137cd5b518ba0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*MDJsLiR5zG0OoZC_lQBDyA.png"/></div></div></figure><figure class="lb lc ld le gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi pg"><img src="../Images/91e1f22918bd30394c11185f48e45a73.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*qxdRs2Zl8pmxHS8LwRclRg.png"/></div></div></figure></div><div class="ab cl lf lg hx lh" role="separator"><span class="li bw bk lj lk ll"/><span class="li bw bk lj lk ll"/><span class="li bw bk lj lk"/></div><div class="im in io ip iq"><p id="7af1" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">我可以通过分割数据框和绘制聚类数来查看分布情况！</p><pre class="lb lc ld le gt nf ng nh ni aw nj bi"><span id="363e" class="nk md je ng b gy nl nm l nn no">#create dataframe of reviews not above average<br/>not_above = df.loc[df['above_avg'] == 0]<br/>not_above.describe()</span><span id="2e8d" class="nk md je ng b gy np nm l nn no">#create data frame of reviews above average<br/>above_avg = df.loc[df['above_avg'] == 1]<br/>above_avg.describe()</span><span id="537f" class="nk md je ng b gy np nm l nn no">#plot the counts<br/>plt.figure(figsize=(14,4))<br/>sns.countplot(x='cluster', data=not_above).set_title("Rating Counts")<br/>plt.show()</span><span id="feff" class="nk md je ng b gy np nm l nn no">plt.figure(figsize=(14,4))<br/>sns.countplot(x='cluster', data=above_avg).set_title("Rating Counts")<br/>plt.show()</span></pre><figure class="lb lc ld le gt iv gh gi paragraph-image"><div class="gh gi ph"><img src="../Images/f0ed25d83e12729102a05bbdf8d1961b.png" data-original-src="https://miro.medium.com/v2/resize:fit:616/format:webp/1*-uvVJlgS8SJXqGPFdxOHZg.png"/></div><figcaption class="ot ou gj gh gi ov ow bd b be z dk">Not Above stats v.s. Above Average stats</figcaption></figure><figure class="lb lc ld le gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi pi"><img src="../Images/22793378af21b7693618f94eda4010c4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*6pNJWdvesomcbSjYJ0vxPg.png"/></div></div></figure><figure class="lb lc ld le gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi pj"><img src="../Images/8ce859bda0208d0307bacbb4a8f407fa.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*OKBsDngSljBfquKRR_tu8A.png"/></div></div></figure></div><div class="ab cl lf lg hx lh" role="separator"><span class="li bw bk lj lk ll"/><span class="li bw bk lj lk ll"/><span class="li bw bk lj lk"/></div><div class="im in io ip iq"><h1 id="f1ae" class="mc md je bd me mf oz mh mi mj pa ml mm mn pb mp mq mr pc mt mu mv pd mx my mz bi translated">最后的想法和笔记本</h1><p id="e14a" class="pw-post-body-paragraph kb kc je kd b ke na kg kh ki nb kk kl km nc ko kp kq nd ks kt ku ne kw kx ky im bi translated">观察可视化结果，他们显示高于平均水平的评分更多地集中在 5、6 和 12。这意味着这些聚类中的单词在高于平均评级的葡萄酒评论中被普遍使用。需要更深入地查看聚类中的单词，因为仅查看前 10 个单词时很难区分显著差异。例如,“苹果”、“香气”和“味道”等词出现在几个分组中，这使得人们很难理解不同的主题。此外，有不同的算法可能在主题建模方面表现更好。</p><p id="ffbb" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated"><a class="ae kz" href="https://en.wikipedia.org/wiki/Latent_Dirichlet_allocation" rel="noopener ugc nofollow" target="_blank">潜在狄利克雷分配(LDA) </a>是另一种流行的无监督学习算法，用于主题建模，其性能优于 K-means。希望我能有机会探索 LDA 并比较我的结果。</p><p id="6e6f" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">你可以从我的 github repo 下载我的笔记本:</p><div class="is it gp gr iu pk"><a href="https://github.com/bendgame/kmeansChardonnay" rel="noopener  ugc nofollow" target="_blank"><div class="pl ab fo"><div class="pm ab pn cl cj po"><h2 class="bd jf gy z fp pp fr fs pq fu fw jd bi translated">bendgame/kmeansChardonnay</h2><div class="pr l"><h3 class="bd b gy z fp pp fr fs pq fu fw dk translated">此时您不能执行该操作。您已使用另一个标签页或窗口登录。您已在另一个选项卡中注销，或者…</h3></div><div class="ps l"><p class="bd b dl z fp pp fr fs pq fu fw dk translated">github.com</p></div></div><div class="pt l"><div class="pu l pv pw px pt py ja pk"/></div></div></a></div><h1 id="8e10" class="mc md je bd me mf mg mh mi mj mk ml mm mn mo mp mq mr ms mt mu mv mw mx my mz bi translated">谢谢大家！</h1><ul class=""><li id="c1ab" class="pz qa je kd b ke na ki nb km qb kq qc ku qd ky qe qf qg qh bi translated"><em class="ly">如果你喜欢这个，</em> <a class="ae kz" href="https://medium.com/@erickleppen" rel="noopener"> <em class="ly">跟我上 Medium </em> </a> <em class="ly">了解更多</em></li><li id="f8d5" class="pz qa je kd b ke qi ki qj km qk kq ql ku qm ky qe qf qg qh bi translated"><a class="ae kz" href="https://erickleppen.medium.com/membership" rel="noopener"> <em class="ly">通过订阅</em> </a>获得完全访问权限并帮助支持我的内容</li><li id="6317" class="pz qa je kd b ke qi ki qj km qk kq ql ku qm ky qe qf qg qh bi translated"><em class="ly">我们来连线一下</em><a class="ae kz" href="https://www.linkedin.com/in/erickleppen01/" rel="noopener ugc nofollow" target="_blank"><em class="ly">LinkedIn</em></a></li><li id="668a" class="pz qa je kd b ke qi ki qj km qk kq ql ku qm ky qe qf qg qh bi translated"><em class="ly">用 Python 分析数据？查看我的</em> <a class="ae kz" href="https://pythondashboards.com/" rel="noopener ugc nofollow" target="_blank"> <em class="ly">网站</em> </a></li></ul><p id="7bc9" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated"><a class="ae kz" href="http://pythondashboards.com/" rel="noopener ugc nofollow" target="_blank"> <strong class="kd jf"> —埃里克·克莱本</strong> </a></p></div></div>    
</body>
</html>