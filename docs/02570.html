<html>
<head>
<title>R-CNN for object detection</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">用于目标检测的 R-CNN</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/r-cnn-for-object-detection-a-technical-summary-9e7bfa8a557c?source=collection_archive---------3-----------------------#2019-04-27">https://towardsdatascience.com/r-cnn-for-object-detection-a-technical-summary-9e7bfa8a557c?source=collection_archive---------3-----------------------#2019-04-27</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="62ca" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">技术论文摘要</h2></div><p id="3533" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在快速发展的深度学习领域，这是一系列了解出版物的一部分，这些出版物是当今对象检测的基础。</p><p id="61aa" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">原始论文“精确对象检测和语义分割的丰富特征层次”[1]阐述了在对象检测系统中使用 CNN 的第一个突破，称为“R-CNN”或“带 CNN 的区域”，其对象检测性能比当时其他流行的方法高得多。</p><h1 id="cb41" class="lb lc iq bd ld le lf lg lh li lj lk ll jw lm jx ln jz lo ka lp kc lq kd lr ls bi translated">区域提议</h1><p id="77b2" class="pw-post-body-paragraph kf kg iq kh b ki lt jr kk kl lu ju kn ko lv kq kr ks lw ku kv kw lx ky kz la ij bi translated">R-CNN 管道的第一阶段是在图像中生成“区域提议”或区域，这些区域<em class="ly">可能</em>属于特定对象。作者使用选择性搜索算法。选择性搜索算法[2]的工作原理是根据颜色、纹理、大小和形状生成可能属于一个对象的图像的子分割，并迭代地组合相似的区域以形成对象。这就产生了不同规模的“目标提议”。注意，R-CNN 管道对于区域提议算法是不可知的。作者使用选择性搜索算法<strong class="kh ir">为每个单独的图像生成 2000 个类别独立区域提议</strong>(通常由矩形区域或‘边界框’)<strong class="kh ir">。</strong></p><figure class="ma mb mc md gt me gh gi paragraph-image"><div role="button" tabindex="0" class="mf mg di mh bf mi"><div class="gh gi lz"><img src="../Images/a7370779c1be1c2355a1d3c2a4e2a24f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*g4izhFRwaDAi9vLB.png"/></div></div><figcaption class="ml mm gj gh gi mn mo bd b be z dk">Figure 1: How the selective search algorithm iteratively obtains “region proposals”</figcaption></figure><h1 id="8051" class="lb lc iq bd ld le lf lg lh li lj lk ll jw lm jx ln jz lo ka lp kc lq kd lr ls bi translated">阶段 1:从区域建议中提取特征</h1><p id="2e83" class="pw-post-body-paragraph kf kg iq kh b ki lt jr kk kl lu ju kn ko lv kq kr ks lw ku kv kw lx ky kz la ij bi translated">在流水线的这一阶段结束时，作者使用卷积神经网络(CNN)从每个图像的 2000 个区域提议中的每一个生成 4096 维特征向量。训练 CNN 的细节如下。</p><p id="daa3" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir">监督预训练:</strong>Krizhevsky 等人[3]描述的 CNN，现在被普遍称为“AlexNet”，具有 5 个卷积层和 2 个全连接层。CNN 首先在 ILSVRC2012 <em class="ly">分类</em>数据集上进行训练，用于具有大量图像的 1000 路图像分类任务，以便卷积层可以学习基本图像特征。</p><p id="9931" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir">特定于域的微调:</strong>现在，需要对网络进行微调，以学习 a)新类型图像的视觉特征-失真区域提议，以及 b)用于检测任务的较小数据集的特定目标类别。我们微调分类网络以从区域提议中识别属于检测任务的类别。</p><ul class=""><li id="7fe1" class="mp mq iq kh b ki kj kl km ko mr ks ms kw mt la mu mv mw mx bi translated">来自预训练的 CNN 的最终 1000 路分类层被用于 N 个对象类和检测任务的一般背景类的随机初始化的(N+1)路 softmax 分类层所取代。</li><li id="2aa9" class="mp mq iq kh b ki my kl mz ko na ks nb kw nc la mu mv mw mx bi translated"><strong class="kh ir">输入:</strong> <em class="ly"> </em>从每个图像生成的 2000 个区域建议中的每一个(使用选择性搜索算法)通过简单的变形被转换成大小为 227×227 的固定输入，而不考虑大小或纵横比，以使它们能够用于微调 CNN(我们需要固定大小的输入，而不考虑馈送到 CNN 的实际尺寸)。一个额外的参数，<em class="ly"> p </em>被用于指示原始边界框的可能扩展量，以包括来自其周围区域的一些上下文。</li><li id="6c71" class="mp mq iq kh b ki my kl mz ko na ks nb kw nc la mu mv mw mx bi translated"><strong class="kh ir">用于训练的标签:</strong>作者将每个对象提议映射到与其具有最大 IoU 重叠的<strong class="kh ir">基础事实实例，并且如果 IoU 至少为 0.5，则将其标记为<strong class="kh ir"> <em class="ly">正</em> </strong> <em class="ly"> </em>(用于匹配的基础事实类)。其余的框被视为<strong class="kh ir"> <em class="ly">背景</em> </strong>类(对所有类为负)。</strong></li><li id="3b81" class="mp mq iq kh b ki my kl mz ko na ks nb kw nc la mu mv mw mx bi translated"><strong class="kh ir">训练管道:</strong>作者使用 SGD 以初始训练前学习率的(1/10)训练网络。在每次迭代中，他们对所有类别中的 32 个正窗口和属于背景类别的 96 个窗口进行采样，以形成 128 个小批量，从而确保在训练期间有来自正类别的足够的代表性。</li></ul><figure class="ma mb mc md gt me gh gi paragraph-image"><div role="button" tabindex="0" class="mf mg di mh bf mi"><div class="gh gi nd"><img src="../Images/f66a376b568d402af693ca30eebcf40c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Xxm2czX19Fcxd-yLZvfodg.png"/></div></div><figcaption class="ml mm gj gh gi mn mo bd b be z dk">Figure 2: The CNN training pipeline taking in a batch of region proposals and giving a classification label (at train time)</figcaption></figure><p id="af6b" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir"> <em class="ly">阶段 1 的最终输出:</em> </strong> <em class="ly">在训练之后，最终分类层被移除，并且对于 2000 个区域提议中的每一个(对于每一幅图像)，从 CNN 的倒数第二层获得 4096 维特征向量。参考上图。</em></p><h1 id="95d4" class="lb lc iq bd ld le lf lg lh li lj lk ll jw lm jx ln jz lo ka lp kc lq kd lr ls bi translated">第 2 阶段:用于物体分类的 SVM</h1><p id="833e" class="pw-post-body-paragraph kf kg iq kh b ki lt jr kk kl lu ju kn ko lv kq kr ks lw ku kv kw lx ky kz la ij bi translated">这个阶段包括为每个类别学习一个<strong class="kh ir">单独的</strong>线性 SVM(支持向量机)分类器，该分类器检测属于特定类别的对象的存在或不存在。</p><ul class=""><li id="0bb0" class="mp mq iq kh b ki kj kl km ko mr ks ms kw mt la mu mv mw mx bi translated"><strong class="kh ir">输入:</strong>4096-<em class="ly">d</em>每个区域建议的特征向量。</li><li id="e5e6" class="mp mq iq kh b ki my kl mz ko na ks nb kw nc la mu mv mw mx bi translated"><strong class="kh ir">用于训练的标签:</strong>在训练期间，与地面真实边界框具有小于 0.3 的 IoU 重叠的所有区域提议的特征被认为是该类的<em class="ly">否定</em> <strong class="kh ir"> <em class="ly"> </em> </strong>。该类的<em class="ly">阳性</em>仅仅是来自地面真实边界框本身的特征。出于训练 SVM 的目的，所有其他提议(IoU 重叠大于 0.3，但不是地面真实边界框)被<em class="ly">忽略。</em></li><li id="8a0e" class="mp mq iq kh b ki my kl mz ko na ks nb kw nc la mu mv mw mx bi translated"><strong class="kh ir">测试单幅图像的时间推断:</strong>将特征和 SVM 权重之间的类特定点积合并为一幅图像的单个矩阵-矩阵积(如下图 3 所示)。也就是说，对于每个图像，生成一个 2000×4096 的特征矩阵(对于所有 2000 个区域提议，CNN 的 4096- <em class="ly"> d </em>特征)。SVM 权重矩阵是 4096×N，其中 N 是类的数量。</li></ul><figure class="ma mb mc md gt me gh gi paragraph-image"><div role="button" tabindex="0" class="mf mg di mh bf mi"><div class="gh gi ne"><img src="../Images/c684c7a298985d88000d13c850c8ba6b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*cmgaF4K6A_Ql-AyqYH3ZXQ.png"/></div></div><figcaption class="ml mm gj gh gi mn mo bd b be z dk">Figure 3: Final consolidated test time SVM computation</figcaption></figure><p id="3c03" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir"> <em class="ly">阶段 2 的最终输出:</em> </strong> <em class="ly">在训练了 SVM 之后，阶段 2 的最终输出是每一类的一组正面物体提议，来自 2000 个区域提议(每个图像的)的 CNN 特征。</em></p><h1 id="134a" class="lb lc iq bd ld le lf lg lh li lj lk ll jw lm jx ln jz lo ka lp kc lq kd lr ls bi translated">阶段 3:包围盒回归</h1><p id="6471" class="pw-post-body-paragraph kf kg iq kh b ki lt jr kk kl lu ju kn ko lv kq kr ks lw ku kv kw lx ky kz la ij bi translated">为了提高定位性能，作者包括一个包围盒回归步骤，以学习预测包围盒位置和大小的校正。</p><figure class="ma mb mc md gt me gh gi paragraph-image"><div role="button" tabindex="0" class="mf mg di mh bf mi"><div class="gh gi nf"><img src="../Images/e46dfe84f986b6e482d8f04bdcae30ee.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*PUJocoWsZIHZltbQeXsqaw.png"/></div></div><figcaption class="ml mm gj gh gi mn mo bd b be z dk">Figure 4: The equations for bounding box regression stages explained below.</figcaption></figure><ul class=""><li id="ddc9" class="mp mq iq kh b ki kj kl km ko mr ks ms kw mt la mu mv mw mx bi translated">等式 1:该任务的目的是学习我们的预测建议<em class="ly"> P </em>和目标建议<em class="ly"> G </em>之间的目标<strong class="kh ir">变换</strong>。变量<em class="ly"> x，y，w，</em>和<em class="ly"> h </em>代表建议书的中心<em class="ly"> (x，y) </em>和宽度<em class="ly"> w </em>和高度<em class="ly"> h </em>的坐标。</li><li id="42cb" class="mp mq iq kh b ki my kl mz ko na ks nb kw nc la mu mv mw mx bi translated">等式 2:等式 2 中显示了需要学习的<strong class="kh ir">地面真实变换</strong>。前两个变换指定了<em class="ly"> P — x </em>和<em class="ly"> y </em>的中心的比例不变平移，后两个指定了宽度<em class="ly"> w </em>和高度<em class="ly"> h </em>的对数空间变换。</li><li id="2160" class="mp mq iq kh b ki my kl mz ko na ks nb kw nc la mu mv mw mx bi translated">等式 3: <em class="ly"> d </em> ₖ <em class="ly"> (P) </em>其中ₖ可以属于<em class="ly"> (x，y，h 或 w) </em>为<strong class="kh ir">预测变换</strong>。ĝ表示使用原始预测框<em class="ly"> P </em>和预测变换<em class="ly"> d </em> ₖ <em class="ly"> (P) </em>计算的校正预测框。</li><li id="4c0a" class="mp mq iq kh b ki my kl mz ko na ks nb kw nc la mu mv mw mx bi translated">等式 4:预测的变换<em class="ly"> d </em> ₖ(P)被建模为图 2)中的 pool₅(shown 特征的线性函数—<em class="ly">φ₅</em>。<br/>因此，<em class="ly">dₖ(p)=wₖᵀφ₅(p)</em>其中<strong class="kh ir"> <em class="ly"> wₖ </em>是可学习模型参数的向量。</strong>注意，φ₅依赖于实际的图像特征。<strong class="kh ir"> <em class="ly"> wₖ </em>通过优化等式 4 的第二行所示的正则化最小二乘目标函数来学习。</strong></li><li id="93a5" class="mp mq iq kh b ki my kl mz ko na ks nb kw nc la mu mv mw mx bi translated">其他注释:如果预测的盒子<em class="ly"> P </em>靠近至少一个地面实况盒子，则该算法仅从该盒子中学习。每个预测框<em class="ly"> P </em>通过选择与它具有最大重叠的基础事实框(假设它具有至少 0.6 的 IoU 重叠)被映射到它的基础事实。<strong class="kh ir">为检测任务的每一类学习单独的变换。</strong></li></ul><p id="c6dd" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir"> <em class="ly">阶段 3 的最终输出:</em> </strong> <em class="ly">对于从 SVM 预测的每一类的所有正区域提议，我们具有围绕对象的精确的、校正的边界框。</em></p><h1 id="5ffc" class="lb lc iq bd ld le lf lg lh li lj lk ll jw lm jx ln jz lo ka lp kc lq kd lr ls bi translated">其他捐款</h1><ul class=""><li id="f124" class="mp mq iq kh b ki lt kl lu ko ng ks nh kw ni la mu mv mw mx bi translated">在其发表时，R-CNN 在 PASCAL VOC 2010 上获得了 54%的 mAP，在 ILSVRC 检测上获得了 31%的 mAP，远远高于其竞争算法。</li><li id="1dcd" class="mp mq iq kh b ki my kl mz ko na ks nb kw nc la mu mv mw mx bi translated">这篇论文的另一个主要贡献是，有确凿的证据表明，对于类似的任务，有监督的预训练比无监督的预训练更能提高表现。</li><li id="3903" class="mp mq iq kh b ki my kl mz ko na ks nb kw nc la mu mv mw mx bi translated">在对 CNN 进行了全面分析后，作者发现，在没有对检测任务进行微调的情况下，移除了完全连接层的网络能够检测到物体提议以及附加了完全连接层的网络——即使前者(pool₅)特征仅使用网络参数的 6%来计算。微调后，最大的性能提升发生在网络中，包括 FC 层。这表明，卷积层比全连接层包含更多的概化特征，全连接层包含特定任务的信息。</li><li id="d891" class="mp mq iq kh b ki my kl mz ko na ks nb kw nc la mu mv mw mx bi translated">作者假设，需要单独的 SVM 进行检测，而不是使用微调的 CNN 本身进行分类，这来自几个因素的组合，包括 a)微调中使用的正例定义不强调精确定位的事实，以及 b)微调中的 softmax 分类器是在随机采样的负例上训练的，而不是在用于 SVM 训练的“硬负”子集上训练的。</li></ul><p id="fd10" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这就是 R-CNN 论文的技术总结。希望你喜欢(理解)！欢迎在下面的评论中讨论或更正。</p><p id="fd0f" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">了解 R-CNN 热门接班人:<a class="ae nj" href="https://medium.com/@shilpa_47526/fast-r-cnn-for-object-detection-a-technical-summary-a0ff94faa022" rel="noopener">快 R-CNN </a>和<a class="ae nj" href="https://medium.com/@shilpa_47526/faster-r-cnn-for-object-detection-a-technical-summary-474c5b857b46" rel="noopener">更快 R-CNN </a>。</p><h2 id="5708" class="nk lc iq bd ld nl nm dn lh nn no dp ll ko np nq ln ks nr ns lp kw nt nu lr nv bi translated">参考资料:</h2><p id="d9ab" class="pw-post-body-paragraph kf kg iq kh b ki lt jr kk kl lu ju kn ko lv kq kr ks lw ku kv kw lx ky kz la ij bi translated">[1] Girshick，Ross 等人，“用于精确对象检测和语义分割的丰富特征层次。”2014 年 IEEE 计算机视觉与模式识别会议(2014)<br/>【2】Uijlings，J. R. R .等人《物体识别的选择性搜索》。国际计算机视觉杂志 104.2(2013)<br/>【3】Alex Krizhevsky，Ilya Sutskever，Geoffrey e . hint on“<a class="ae nj" href="https://www.semanticscholar.org/paper/ImageNet-Classification-with-Deep-Convolutional-Krizhevsky-Sutskever/6bca5ff6cfe3b473a1ae04c635404c3e4109fca3" rel="noopener ugc nofollow" target="_blank">使用深度卷积神经网络的 ImageNet 分类</a>”，发表于 NIPS 2012</p></div></div>    
</body>
</html>