<html>
<head>
<title>Unittesting Apache Spark Applications</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">单元测试 Apache Spark 应用程序</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/unittesting-apache-spark-applications-b9a46e319ce3?source=collection_archive---------13-----------------------#2019-10-13">https://towardsdatascience.com/unittesting-apache-spark-applications-b9a46e319ce3?source=collection_archive---------13-----------------------#2019-10-13</a></blockquote><div><div class="fc ii ij ik il im"/><div class="in io ip iq ir"><div class=""/><div class=""><h2 id="6ca3" class="pw-subtitle-paragraph jr it iu bd b js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki dk translated">PySpark 案件</h2></div><figure class="kk kl km kn gu ko gi gj paragraph-image"><div role="button" tabindex="0" class="kp kq di kr bf ks"><div class="gi gj kj"><img src="../Images/37114d6e5ded1d3bca1b5c5fd75ab0b0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ZQ-AAP7xX4pl1dk5qeWEZg.png"/></div></div></figure><p id="6e5f" class="pw-post-body-paragraph kv kw iu kx b ky kz jv la lb lc jy ld le lf lg lh li lj lk ll lm ln lo lp lq in bi translated">对 Spark 应用程序进行单元测试并不是那么简单。对于大多数情况，您可能需要一个活跃的 spark 会话，这意味着您的测试用例将需要很长时间来运行，并且可能我们正在所谓的单元测试的边界附近踮着脚尖。但是，这绝对值得去做。</p><p id="2bfd" class="pw-post-body-paragraph kv kw iu kx b ky kz jv la lb lc jy ld le lf lg lh li lj lk ll lm ln lo lp lq in bi translated"><em class="lr">那么，我应该吗？</em> <br/>嗯，<strong class="kx iv">是的</strong>！测试你的软件总是一件好事，它很可能会让你免除许多麻烦，此外，你将被迫把你的代码实现成更小的片断，这样更容易测试，从而获得可读性和简单性。</p><p id="a44a" class="pw-post-body-paragraph kv kw iu kx b ky kz jv la lb lc jy ld le lf lg lh li lj lk ll lm ln lo lp lq in bi translated">好的，那么我需要做些什么呢？嗯，我认为我们可以从<code class="fe ls lt lu lv b">pip install spark-testing-base</code>开始，然后从那里开始。为此，我们还需要<code class="fe ls lt lu lv b">pyspark</code>(当然)和<code class="fe ls lt lu lv b">unittest</code>(单元测试 2)和<code class="fe ls lt lu lv b">pytest</code>——尽管<code class="fe ls lt lu lv b">pytest</code>是个人偏好。</p><div class="lw lx gq gs ly lz"><a href="https://github.com/holdenk/spark-testing-base" rel="noopener  ugc nofollow" target="_blank"><div class="ma ab fp"><div class="mb ab mc cl cj md"><h2 class="bd iv gz z fq me fs ft mf fv fx it bi translated">霍尔登克/火花测试基地</h2><div class="mg l"><h3 class="bd b gz z fq me fs ft mf fv fx dk translated">用 Spark 编写测试时使用的基类。您已经在 Spark 中编写了一个很棒的程序，现在是时候编写了…</h3></div><div class="mh l"><p class="bd b dl z fq me fs ft mf fv fx dk translated">github.com</p></div></div><div class="mi l"><div class="mj l mk ml mm mi mn kt lz"/></div></div></a></div><p id="370d" class="pw-post-body-paragraph kv kw iu kx b ky kz jv la lb lc jy ld le lf lg lh li lj lk ll lm ln lo lp lq in bi translated">Spark testing base 是一个帮助 Spark 测试的基类集合。对于这个例子，我们将使用继承自<code class="fe ls lt lu lv b">SparkTestingBaseReuse</code>的基础<code class="fe ls lt lu lv b"><a class="ae mo" href="https://github.com/holdenk/spark-testing-base/blob/master/python/sparktestingbase/sqltestcase.py" rel="noopener ugc nofollow" target="_blank">SQLTestCase</a></code>，它创建并重用了一个 SparkContext。</p><p id="ac9c" class="pw-post-body-paragraph kv kw iu kx b ky kz jv la lb lc jy ld le lf lg lh li lj lk ll lm ln lo lp lq in bi translated">在<code class="fe ls lt lu lv b">SparkSession</code>和<code class="fe ls lt lu lv b">SparkContext</code>上:</p><div class="lw lx gq gs ly lz"><a href="https://medium.com/@achilleus/spark-session-10d0d66d1d24" rel="noopener follow" target="_blank"><div class="ma ab fp"><div class="mb ab mc cl cj md"><h2 class="bd iv gz z fq me fs ft mf fv fx it bi translated">火花会议和火花背景的故事</h2><div class="mg l"><h3 class="bd b gz z fq me fs ft mf fv fx dk translated">我已经有了 Spark 上下文、SQL 上下文、Hive 上下文！</h3></div><div class="mh l"><p class="bd b dl z fq me fs ft mf fv fx dk translated">medium.com</p></div></div><div class="mi l"><div class="mp l mk ml mm mi mn kt lz"/></div></div></a></div><p id="33ae" class="pw-post-body-paragraph kv kw iu kx b ky kz jv la lb lc jy ld le lf lg lh li lj lk ll lm ln lo lp lq in bi translated">从个人经验来说(使用目前最新的 spark 版本。+)，我发现我需要对<code class="fe ls lt lu lv b">SQLTestCase</code>做一些小的调整，这是我在当前项目中经常使用的一个测试用例。因此，这里有一个我为适应自己的需要而做的调整的例子:</p><figure class="kk kl km kn gu ko"><div class="bz fq l di"><div class="mq mr l"/></div><figcaption class="ms mt gk gi gj mu mv bd b be z dk">Example of a base spark test case, based on Spark testing base’ s SQLTestCase</figcaption></figure><p id="ee84" class="pw-post-body-paragraph kv kw iu kx b ky kz jv la lb lc jy ld le lf lg lh li lj lk ll lm ln lo lp lq in bi translated">总结一下我所做的改变:</p><ul class=""><li id="27fb" class="mw mx iu kx b ky kz lb lc le my li mz lm na lq nb nc nd ne bi translated">为了一致性，我添加了一个配置，将时区设置为<code class="fe ls lt lu lv b">UTC</code>。时区一致性是贯穿你的代码的一个非常基本的东西，所以请确保你总是设置<code class="fe ls lt lu lv b">spark.sql.session.timeZone</code></li><li id="cfe4" class="mw mx iu kx b ky nf lb ng le nh li ni lm nj lq nb nc nd ne bi translated">在配置中设置的另一个重要的事情是<code class="fe ls lt lu lv b">spark.sql.shuffle.partitions</code>对于将要运行测试的机器来说是合理的，比如<code class="fe ls lt lu lv b">&lt;= cores * 2</code>。如果我们不这样做，那么 spark 将使用默认值，即<strong class="kx iv"> 200 </strong>分区，这将不必要地、不可避免地减慢整个过程。<code class="fe ls lt lu lv b">&lt;= cores * 2</code>是一个普遍适用的好规则，不仅仅适用于测试。</li><li id="4e56" class="mw mx iu kx b ky nf lb ng le nh li ni lm nj lq nb nc nd ne bi translated">还添加了一种在比较之前对要比较的数据帧进行排序的方法。在一个基类中有一个<code class="fe ls lt lu lv b">compareRDDWithOrder</code>方法，但是我认为使用 dataframes 更容易。</li><li id="3f87" class="mw mx iu kx b ky nf lb ng le nh li ni lm nj lq nb nc nd ne bi translated"><code class="fe ls lt lu lv b">schema_nullable_helper</code>方法应该<strong class="kx iv">谨慎使用</strong>，因为它可能最终破坏你的测试用例，这取决于你需要测试什么。这种情况的用例是在没有指定模式的情况下创建数据帧(目前不推荐使用)，因为 spark 试图推断数据类型，有时要比较的两个数据帧之间的可空标志不一致，这取决于用于创建它们的数据。该方法将两个数据帧的模式之一更新为另一个的模式，该模式仅与<strong class="kx iv">可空值</strong>相关。</li><li id="688e" class="mw mx iu kx b ky nf lb ng le nh li ni lm nj lq nb nc nd ne bi translated">最后，我为<code class="fe ls lt lu lv b">appName</code>和<code class="fe ls lt lu lv b">config</code>添加了一个稍微调整过的版本。在最新的 pyspark 版本中,<code class="fe ls lt lu lv b">session</code>实例化也有所不同。(对于 2.2 的支持，有一个待定的版本。+和 2.3。+ spark 版本仍然开放<a class="ae mo" href="https://github.com/holdenk/spark-testing-base/pull/264" rel="noopener ugc nofollow" target="_blank">这里</a>和<a class="ae mo" href="https://github.com/holdenk/spark-testing-base/issues/268" rel="noopener ugc nofollow" target="_blank">这里</a>，所以，我们将子类化来解决这个问题)</li></ul><p id="fbbc" class="pw-post-body-paragraph kv kw iu kx b ky kz jv la lb lc jy ld le lf lg lh li lj lk ll lm ln lo lp lq in bi translated">注意<code class="fe ls lt lu lv b">getOrCreate()</code>将创建一次 spark 会话，然后在整个测试套件中重用它。</p></div><div class="ab cl nk nl hy nm" role="separator"><span class="nn bw bk no np nq"/><span class="nn bw bk no np nq"/><span class="nn bw bk no np"/></div><div class="in io ip iq ir"><p id="c5ea" class="pw-post-body-paragraph kv kw iu kx b ky kz jv la lb lc jy ld le lf lg lh li lj lk ll lm ln lo lp lq in bi translated">现在让我们创建一个要测试的简单特性:</p><figure class="kk kl km kn gu ko"><div class="bz fq l di"><div class="mq mr l"/></div><figcaption class="ms mt gk gi gj mu mv bd b be z dk">An example of a feature calculation class</figcaption></figure><p id="4414" class="pw-post-body-paragraph kv kw iu kx b ky kz jv la lb lc jy ld le lf lg lh li lj lk ll lm ln lo lp lq in bi translated">这个特性只是计算<code class="fe ls lt lu lv b">a/b</code>，其中<code class="fe ls lt lu lv b">a</code>和<code class="fe ls lt lu lv b">b</code>是输入数据帧中的列。非常简单明了。我在这里没有包括列检查，因为如果<code class="fe ls lt lu lv b">a</code>或<code class="fe ls lt lu lv b">b</code>丢失，我们需要计算过程失败到足以停止一切。但一般来说，这取决于您希望如何处理应用程序中的错误情况，以及这种计算对您的过程有多重要。</p><p id="ab2e" class="pw-post-body-paragraph kv kw iu kx b ky kz jv la lb lc jy ld le lf lg lh li lj lk ll lm ln lo lp lq in bi translated">这里需要注意的是:即使您模拟了对<code class="fe ls lt lu lv b">calculate</code> dataframe 的输入，spark 会话也是需要的，因为在我们特性的<code class="fe ls lt lu lv b">calculate</code>实现中，我们使用了像<code class="fe ls lt lu lv b">F.col('a')</code>这样的<code class="fe ls lt lu lv b">pyspark.sql.functions</code>，这需要您有一个活动的会话。如果我们没有会话，我们会得到这样的错误:</p><figure class="kk kl km kn gu ko gi gj paragraph-image"><div role="button" tabindex="0" class="kp kq di kr bf ks"><div class="gi gj nr"><img src="../Images/533bb1e6be995130a489620b2c0326e3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*8xAbn36Gs7kwl6p-n4dzJw.png"/></div></div><figcaption class="ms mt gk gi gj mu mv bd b be z dk">Attribute error when using pyspark sql functions without an active session</figcaption></figure><p id="6abc" class="pw-post-body-paragraph kv kw iu kx b ky kz jv la lb lc jy ld le lf lg lh li lj lk ll lm ln lo lp lq in bi translated">如果出于某种原因，我们需要在特性的<code class="fe ls lt lu lv b">__init__</code>体(构造函数)中声明计算，这就更明显了，例如:</p><pre class="kk kl km kn gu ns lv nt nu aw nv bi"><span id="6689" class="nw nx iu lv b gz ny nz l oa ob"><strong class="lv iv">class </strong>FeatureAToBRatio(object):<br/>    feature_name = <strong class="lv iv">'a_to_b_ratio'<br/>    </strong>default_value = 0.<br/><br/>    <strong class="lv iv">def </strong>__init__(self):<br/>        self.calculation = F.col(<strong class="lv iv">'a'</strong>).cast(<strong class="lv iv">'float'</strong>) / F.col(<strong class="lv iv">'b'</strong>).cast(<strong class="lv iv">'float'</strong>)</span></pre><p id="8662" class="pw-post-body-paragraph kv kw iu kx b ky kz jv la lb lc jy ld le lf lg lh li lj lk ll lm ln lo lp lq in bi translated">然后我们会在特性实例化期间得到错误<code class="fe ls lt lu lv b">feature = FeatureAToBRatio()</code>。</p></div><div class="ab cl nk nl hy nm" role="separator"><span class="nn bw bk no np nq"/><span class="nn bw bk no np nq"/><span class="nn bw bk no np"/></div><div class="in io ip iq ir"><p id="3a4e" class="pw-post-body-paragraph kv kw iu kx b ky kz jv la lb lc jy ld le lf lg lh li lj lk ll lm ln lo lp lq in bi translated">现在让我们继续添加一些测试用例。</p><figure class="kk kl km kn gu ko"><div class="bz fq l di"><div class="mq mr l"/></div><figcaption class="ms mt gk gi gj mu mv bd b be z dk">An example test suite for testing feature a to b ratio</figcaption></figure><p id="b307" class="pw-post-body-paragraph kv kw iu kx b ky kz jv la lb lc jy ld le lf lg lh li lj lk ll lm ln lo lp lq in bi translated">我们正在测试:</p><ul class=""><li id="0820" class="mw mx iu kx b ky kz lb lc le my li mz lm na lq nb nc nd ne bi translated">正常情况下，<code class="fe ls lt lu lv b">a</code>和<code class="fe ls lt lu lv b">b</code>存在，并有数值</li><li id="d511" class="mw mx iu kx b ky nf lb ng le nh li ni lm nj lq nb nc nd ne bi translated">其中一个例外，例如<code class="fe ls lt lu lv b">b</code>不存在于数据帧中</li><li id="b5b1" class="mw mx iu kx b ky nf lb ng le nh li ni lm nj lq nb nc nd ne bi translated">分母为 0 的情况。</li></ul><p id="f849" class="pw-post-body-paragraph kv kw iu kx b ky kz jv la lb lc jy ld le lf lg lh li lj lk ll lm ln lo lp lq in bi translated">这些只是<strong class="kx iv">人们可以为</strong>测试的一些基本测试用例。我想到了许多其他的例子，例如，如果<code class="fe ls lt lu lv b">a</code>为空或者不同类型的数据类型会发生什么，但是为了这个例子，让我们保持它简单明了。</p><p id="7817" class="pw-post-body-paragraph kv kw iu kx b ky kz jv la lb lc jy ld le lf lg lh li lj lk ll lm ln lo lp lq in bi translated">要运行测试套件:</p><pre class="kk kl km kn gu ns lv nt nu aw nv bi"><span id="0728" class="nw nx iu lv b gz ny nz l oa ob">python -m pytest test_feature_a_to_b_ratio.py</span></pre><figure class="kk kl km kn gu ko gi gj paragraph-image"><div role="button" tabindex="0" class="kp kq di kr bf ks"><div class="gi gj oc"><img src="../Images/df04c9f40beffb68922637d0af09b112.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*nkQsgvvmxHgvrE6HGLLSUg.png"/></div></div><figcaption class="ms mt gk gi gj mu mv bd b be z dk">Example output of tests execution</figcaption></figure><figure class="kk kl km kn gu ko gi gj paragraph-image"><div role="button" tabindex="0" class="kp kq di kr bf ks"><div class="gi gj od"><img src="../Images/c0f5fee3cc9bed3f881a12d2692ed260.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*FdoBGriNjQ2RhdJSEgnFiQ.png"/></div></div><figcaption class="ms mt gk gi gj mu mv bd b be z dk">Example output of tests execution — ran with PyCharm</figcaption></figure><p id="a102" class="pw-post-body-paragraph kv kw iu kx b ky kz jv la lb lc jy ld le lf lg lh li lj lk ll lm ln lo lp lq in bi translated">就是这样！请注意，它运行了 7.58 秒(当 shuffle 分区设置为默认的 200 时，运行了 14.72 秒)，这对于单元测试来说有点多，而且它只有 3 个测试用例—想象一下，有一个 CI/ CD 在每次合并或提交时运行测试套件…</p><p id="db25" class="pw-post-body-paragraph kv kw iu kx b ky kz jv la lb lc jy ld le lf lg lh li lj lk ll lm ln lo lp lq in bi translated">当然，spark / pyspark 还有很多复杂的测试要做，但我认为这是一个很好的基础。如果有更好的方法，请告诉我。</p><p id="9a71" class="pw-post-body-paragraph kv kw iu kx b ky kz jv la lb lc jy ld le lf lg lh li lj lk ll lm ln lo lp lq in bi translated">我希望这有所帮助。任何想法，问题，更正和建议都非常欢迎:)</p><p id="7a3b" class="pw-post-body-paragraph kv kw iu kx b ky kz jv la lb lc jy ld le lf lg lh li lj lk ll lm ln lo lp lq in bi translated">如果您想了解更多关于 Spark 的工作原理，请访问:</p><div class="lw lx gq gs ly lz"><a rel="noopener follow" target="_blank" href="/explaining-technical-stuff-in-a-non-techincal-way-apache-spark-274d6c9f70e9"><div class="ma ab fp"><div class="mb ab mc cl cj md"><h2 class="bd iv gz z fq me fs ft mf fv fx it bi translated">用非技术性的方式解释技术性的东西——Apache Spark</h2><div class="mg l"><h3 class="bd b gz z fq me fs ft mf fv fx dk translated">什么是 Spark 和 PySpark，我可以用它做什么？</h3></div><div class="mh l"><p class="bd b dl z fq me fs ft mf fv fx dk translated">towardsdatascience.com</p></div></div><div class="mi l"><div class="oe l mk ml mm mi mn kt lz"/></div></div></a></div><div class="lw lx gq gs ly lz"><a rel="noopener follow" target="_blank" href="/adding-sequential-ids-to-a-spark-dataframe-fa0df5566ff6"><div class="ma ab fp"><div class="mb ab mc cl cj md"><h2 class="bd iv gz z fq me fs ft mf fv fx it bi translated">向 Spark 数据帧添加顺序 id</h2><div class="mg l"><h3 class="bd b gz z fq me fs ft mf fv fx dk translated">怎么做，这是个好主意吗？</h3></div><div class="mh l"><p class="bd b dl z fq me fs ft mf fv fx dk translated">towardsdatascience.com</p></div></div><div class="mi l"><div class="of l mk ml mm mi mn kt lz"/></div></div></a></div></div></div>    
</body>
</html>