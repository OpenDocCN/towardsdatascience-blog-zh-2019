<html>
<head>
<title>Unsupervised Learning Project: Creating Customer Segments</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">无监督学习项目:创建客户群</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/unsupervised-learning-project-creating-customer-segments-17c4b4bbf925?source=collection_archive---------0-----------------------#2019-04-28">https://towardsdatascience.com/unsupervised-learning-project-creating-customer-segments-17c4b4bbf925?source=collection_archive---------0-----------------------#2019-04-28</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="a0ab" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">了解如何开发端到端聚类和降维项目！</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/1f29e7f0086ff962b381f5f06385cc77.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*-_0EwViz18k_3YGT"/></div></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk">Picture from <a class="ae ky" href="https://unsplash.com/photos/5fNmWej4tAA" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><h1 id="5a9d" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">介绍</h1><p id="bf4e" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">在整个项目中，我们将分析一些产品类别中几个客户的消费行为。该项目的主要目标是:</p><ul class=""><li id="7b9c" class="mn mo it lt b lu mp lx mq ma mr me ms mi mt mm mu mv mw mx bi translated">将具有相似消费特征的客户分组。</li><li id="c9ab" class="mn mo it lt b lu my lx mz ma na me nb mi nc mm mu mv mw mx bi translated">描述不同组内的差异，以便为每个组找到最佳的交付结构。</li></ul><p id="7daa" class="pw-post-body-paragraph lr ls it lt b lu mp ju lw lx mq jx lz ma nd mc md me ne mg mh mi nf mk ml mm im bi translated">为了执行这个项目，我们将使用可以在下面的<a class="ae ky" href="https://archive.ics.uci.edu/ml/datasets/Wholesale+customers" rel="noopener ugc nofollow" target="_blank"> UCI 机器学习知识库</a>中找到的数据集。</p><p id="1266" class="pw-post-body-paragraph lr ls it lt b lu mp ju lw lx mq jx lz ma nd mc md me ne mg mh mi nf mk ml mm im bi translated">你可以在我的<a class="ae ky" href="https://github.com/rromanss23/Machine_Leaning_Engineer_Udacity_NanoDegree/tree/master/projects/customer_segments" rel="noopener ugc nofollow" target="_blank"> GitHub 页面</a>上找到完整的项目、文档和数据集:</p><p id="d251" class="pw-post-body-paragraph lr ls it lt b lu mp ju lw lx mq jx lz ma nd mc md me ne mg mh mi nf mk ml mm im bi translated"><a class="ae ky" href="https://github.com/rromanss23/Machine_Leaning_Engineer_Udacity_NanoDegree/tree/master/projects/customer_segments" rel="noopener ugc nofollow" target="_blank">https://github . com/rromans 23/Machine _ learning _ Engineer _ uda city _ nano degree/tree/master/projects/customer _ segments</a></p><p id="2970" class="pw-post-body-paragraph lr ls it lt b lu mp ju lw lx mq jx lz ma nd mc md me ne mg mh mi nf mk ml mm im bi translated">我们将重点分析为客户记录的六个产品类别，不包括“渠道”和“地区”字段。</p><pre class="kj kk kl km gt ng nh ni nj aw nk bi"><span id="8342" class="nl la it nh b gy nm nn l no np"><strong class="nh iu"><em class="nq"># Import libraries necessary for this project</em></strong><br/>import numpy as np<br/>import pandas as pd<br/>from IPython.display import display <em class="nq"># Allows the use of display() for DataFrames</em><br/><br/><strong class="nh iu"><em class="nq"># Import supplementary visualizations code visuals.py</em></strong><br/>import visuals as vs<br/><br/><strong class="nh iu"><em class="nq"># Pretty display for notebooks</em></strong><br/>%matplotlib inline<br/><br/><strong class="nh iu"><em class="nq"># Load the wholesale customers dataset</em></strong><br/>try:<br/>    data = pd.read_csv("customers.csv")<br/>    data.drop(['Region', 'Channel'], axis = 1, inplace = True)<br/>    print("Wholesale customers dataset has {} samples with {} features each.".format(*data.shape))<br/>except:<br/>    print("Dataset could not be loaded. Is the dataset missing?")</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nr"><img src="../Images/e1a836e84ad60d4042b5f23a227e890e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1024/format:webp/1*8qrOYg3rJMZEc_kx9WSEHA.png"/></div></figure><h1 id="0723" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">数据探索</h1><p id="0882" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">现在，我们将通过可视化和代码来探索数据集，以了解要素之间的关系。此外，我们将计算数据集的统计描述，并考虑每个特征的整体相关性。</p><pre class="kj kk kl km gt ng nh ni nj aw nk bi"><span id="1cbc" class="nl la it nh b gy nm nn l no np"><strong class="nh iu"><em class="nq"># Display a description of the dataset</em></strong><br/>display(data.describe())</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ns"><img src="../Images/64d6f197cc7011d05bc0c03e886bc8a1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1380/format:webp/1*cvZ3pVLkGcUc0gZDh1odwQ.png"/></div></figure><pre class="kj kk kl km gt ng nh ni nj aw nk bi"><span id="4c8c" class="nl la it nh b gy nm nn l no np"><strong class="nh iu"><em class="nq"># Display the head of the dataset</em></strong><br/>data.head()</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nt"><img src="../Images/80db985876b1ec27b9a447fbecdb72c4.png" data-original-src="https://miro.medium.com/v2/resize:fit:922/format:webp/1*FfcVtr0EjsggqhFpQE9kkA.png"/></div></figure><h2 id="1bf0" class="nl la it bd lb nu nv dn lf nw nx dp lj ma ny nz ll me oa ob ln mi oc od lp oe bi translated">选择样本</h2><p id="bfab" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">为了更好地了解我们的数据集以及数据将如何通过分析进行转换，我们将选择几个样本点并详细研究它们。</p><pre class="kj kk kl km gt ng nh ni nj aw nk bi"><span id="7822" class="nl la it nh b gy nm nn l no np"><strong class="nh iu"><em class="nq"># Select three indices to sample from the dataset</em></strong><br/>indices = [85,181,338]<br/><br/><strong class="nh iu"><em class="nq"># Create a DataFrame of the chosen samples</em></strong><br/>samples = pd.DataFrame(data.loc[indices], columns = data.keys()).reset_index(drop = True)<br/>print("Chosen samples of wholesale customers dataset:")<br/>display(samples)</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi of"><img src="../Images/34c89b6352b2fe41f95d0f309005dcd0.png" data-original-src="https://miro.medium.com/v2/resize:fit:944/format:webp/1*G3Iycv3VuXO9cPKZbB_RVw.png"/></div></div></figure><h2 id="a232" class="nl la it bd lb nu nv dn lf nw nx dp lj ma ny nz ll me oa ob ln mi oc od lp oe bi translated">考虑</h2><p id="88ae" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">现在，让我们考虑每个产品类别的总购买成本，以及上述样本客户数据集的统计描述。如果我们必须预测三个样本中的每一个代表哪种机构(客户):</p><p id="8f29" class="pw-post-body-paragraph lr ls it lt b lu mp ju lw lx mq jx lz ma nd mc md me ne mg mh mi nf mk ml mm im bi translated">考虑平均值:</p><ul class=""><li id="fde4" class="mn mo it lt b lu mp lx mq ma mr me ms mi mt mm mu mv mw mx bi translated">新鲜度:12000.2977</li><li id="86e6" class="mn mo it lt b lu my lx mz ma na me nb mi nc mm mu mv mw mx bi translated">牛奶:5796.2</li><li id="8d34" class="mn mo it lt b lu my lx mz ma na me nb mi nc mm mu mv mw mx bi translated">杂货:3071.9</li><li id="6662" class="mn mo it lt b lu my lx mz ma na me nb mi nc mm mu mv mw mx bi translated">洗涤剂 _ 纸张:2881.4</li><li id="fb19" class="mn mo it lt b lu my lx mz ma na me nb mi nc mm mu mv mw mx bi translated">熟食店:1524.8</li></ul><p id="1ba2" class="pw-post-body-paragraph lr ls it lt b lu mp ju lw lx mq jx lz ma nd mc md me ne mg mh mi nf mk ml mm im bi translated">我们可以做出如下预测:</p><p id="7095" class="pw-post-body-paragraph lr ls it lt b lu mp ju lw lx mq jx lz ma nd mc md me ne mg mh mi nf mk ml mm im bi translated"><strong class="lt iu"> 1)指数 85:零售商:</strong></p><p id="e0e1" class="pw-post-body-paragraph lr ls it lt b lu mp ju lw lx mq jx lz ma nd mc md me ne mg mh mi nf mk ml mm im bi translated">-在洗涤剂、纸张和杂货上的支出最大，通常是家庭用品。</p><p id="cdf9" class="pw-post-body-paragraph lr ls it lt b lu mp ju lw lx mq jx lz ma nd mc md me ne mg mh mi nf mk ml mm im bi translated">-高于牛奶的平均支出。</p><p id="fa94" class="pw-post-body-paragraph lr ls it lt b lu mp ju lw lx mq jx lz ma nd mc md me ne mg mh mi nf mk ml mm im bi translated">-低于冷冻产品的平均支出。</p><p id="5928" class="pw-post-body-paragraph lr ls it lt b lu mp ju lw lx mq jx lz ma nd mc md me ne mg mh mi nf mk ml mm im bi translated"><strong class="lt iu"> 2)指数 181:大市场</strong></p><p id="f84e" class="pw-post-body-paragraph lr ls it lt b lu mp ju lw lx mq jx lz ma nd mc md me ne mg mh mi nf mk ml mm im bi translated">-几乎每个产品类别的高支出。</p><p id="eb93" class="pw-post-body-paragraph lr ls it lt b lu mp ju lw lx mq jx lz ma nd mc md me ne mg mh mi nf mk ml mm im bi translated">-在整个数据集的新鲜产品上花费最高。很可能是一个大市场。</p><p id="6c60" class="pw-post-body-paragraph lr ls it lt b lu mp ju lw lx mq jx lz ma nd mc md me ne mg mh mi nf mk ml mm im bi translated">-洗涤剂支出低。</p><p id="33cc" class="pw-post-body-paragraph lr ls it lt b lu mp ju lw lx mq jx lz ma nd mc md me ne mg mh mi nf mk ml mm im bi translated"><strong class="lt iu"> 3)索引 338:餐馆</strong></p><p id="2fae" class="pw-post-body-paragraph lr ls it lt b lu mp ju lw lx mq jx lz ma nd mc md me ne mg mh mi nf mk ml mm im bi translated">-每种产品的数量都显著低于前两个客户考虑的数量。</p><p id="c67f" class="pw-post-body-paragraph lr ls it lt b lu mp ju lw lx mq jx lz ma nd mc md me ne mg mh mi nf mk ml mm im bi translated">-生鲜产品支出是整个数据集中最低的。</p><p id="1177" class="pw-post-body-paragraph lr ls it lt b lu mp ju lw lx mq jx lz ma nd mc md me ne mg mh mi nf mk ml mm im bi translated">-在牛奶、清洁剂和纸张上的支出处于最低的四分之一。</p><ul class=""><li id="453a" class="mn mo it lt b lu mp lx mq ma mr me ms mi mt mm mu mv mw mx bi translated">它可能是一个小而便宜的餐馆，需要食品杂货和冷冻食品来提供食物。</li></ul><h2 id="2fc7" class="nl la it bd lb nu nv dn lf nw nx dp lj ma ny nz ll me oa ob ln mi oc od lp oe bi translated">特征相关性</h2><p id="e496" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">我们现在将分析这些特性的相关性，以了解顾客的购买行为。换句话说，确定购买某一类产品的某一数量的顾客是否一定会购买另一类产品的某一比例的数量。</p><p id="9b51" class="pw-post-body-paragraph lr ls it lt b lu mp ju lw lx mq jx lz ma nd mc md me ne mg mh mi nf mk ml mm im bi translated">我们将通过在删除一个特征的数据子集上训练一个监督回归学习器来研究这一点，然后对该模型预测删除特征的效果进行评分。</p><pre class="kj kk kl km gt ng nh ni nj aw nk bi"><span id="5a3f" class="nl la it nh b gy nm nn l no np"><strong class="nh iu"><em class="nq"># Display the head of the dataset</em></strong><br/>data.head(1)</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi og"><img src="../Images/e06374d64f0b419cb569a3a9f8ff8920.png" data-original-src="https://miro.medium.com/v2/resize:fit:916/format:webp/1*uatQYocvDj9M7Y7A7A5O-w.png"/></div></figure><pre class="kj kk kl km gt ng nh ni nj aw nk bi"><span id="88b5" class="nl la it nh b gy nm nn l no np"><strong class="nh iu"><em class="nq"># Make a copy of the DataFrame, using the 'drop' function to drop the given feature</em></strong><br/>new_data = data.drop('Grocery', axis=1)<br/><br/><strong class="nh iu"><em class="nq"># Split the data into training and testing sets(0.25) using the given feature as the target</em><br/><em class="nq"># Set a random state.</em></strong><br/>from sklearn.model_selection import train_test_split<br/><br/>X_train, X_test, y_train, y_test = train_test_split(new_data, data.Grocery, test_size=0.25, random_state=42)<br/><br/><strong class="nh iu"><em class="nq"># Create a decision tree regressor and fit it to the training set</em></strong><br/>from sklearn.tree import DecisionTreeRegressor<br/>regressor = DecisionTreeRegressor()<br/>regressor = regressor.fit(X_train, y_train)<br/>prediction = regressor.predict(X_test)<br/><br/><strong class="nh iu"><em class="nq"># Report the score of the prediction using the testing set</em></strong><br/>from sklearn.metrics import r2_score<br/>score = r2_score(y_test, prediction)<br/>print("Prediction score is: {}".format(score))</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi oh"><img src="../Images/b95550515b699cd8da272a7a7c6593f6.png" data-original-src="https://miro.medium.com/v2/resize:fit:626/format:webp/1*l5E-etVVhmJl9G0ZvL4sZQ.png"/></div></figure><ul class=""><li id="2a50" class="mn mo it lt b lu mp lx mq ma mr me ms mi mt mm mu mv mw mx bi translated">我们试图预测食品杂货的特点。</li><li id="a653" class="mn mo it lt b lu my lx mz ma na me nb mi nc mm mu mv mw mx bi translated">报道的预测得分为 67.25%。</li><li id="4aa8" class="mn mo it lt b lu my lx mz ma na me nb mi nc mm mu mv mw mx bi translated">由于我们获得了高分，这表明我们非常适合。因此，考虑到其他的消费习惯，这个特征是很容易预测的，因此，对于识别顾客的消费习惯来说不是很必要。</li></ul><h2 id="e1ee" class="nl la it bd lb nu nv dn lf nw nx dp lj ma ny nz ll me oa ob ln mi oc od lp oe bi translated">可视化特征分布</h2><p id="2944" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">为了更好地理解我们的数据集，我们将展示每个产品特性的散点图。</p><p id="8b2c" class="pw-post-body-paragraph lr ls it lt b lu mp ju lw lx mq jx lz ma nd mc md me ne mg mh mi nf mk ml mm im bi translated">散点图中显示相关性的产品特性将与预测其他特性相关。</p><pre class="kj kk kl km gt ng nh ni nj aw nk bi"><span id="ef87" class="nl la it nh b gy nm nn l no np"><strong class="nh iu"><em class="nq"># Produce a scatter matrix for each pair of features in the data</em></strong><br/>pd.scatter_matrix(data, alpha = 0.3, figsize = (14,8), diagonal = 'kde');</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oi"><img src="../Images/f095d80f779225d4d67356888f06e594.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*6wbmENmXMTFx-m3kVngIQw.png"/></div></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk">@</figcaption></figure><pre class="kj kk kl km gt ng nh ni nj aw nk bi"><span id="4053" class="nl la it nh b gy nm nn l no np"><strong class="nh iu"># Display a correlation matrix<br/>import seaborn as sns</strong><br/>sns.heatmap(data.corr())</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi oj"><img src="../Images/eb74164ed2b63fd1e74140520e9b6462.png" data-original-src="https://miro.medium.com/v2/resize:fit:908/format:webp/1*L94o_lXELcvM9sBzZQeEEQ.png"/></div></figure><p id="4286" class="pw-post-body-paragraph lr ls it lt b lu mp ju lw lx mq jx lz ma nd mc md me ne mg mh mi nf mk ml mm im bi translated">使用散布矩阵和相关矩阵作为参考，我们可以推断如下:</p><ul class=""><li id="0313" class="mn mo it lt b lu mp lx mq ma mr me ms mi mt mm mu mv mw mx bi translated">数据不是正态分布的，它是正偏态的，并且符合对数正态分布。</li><li id="c13d" class="mn mo it lt b lu my lx mz ma na me nb mi nc mm mu mv mw mx bi translated">在大多数图中，大多数数据点位于原点附近，这表明它们之间几乎没有相关性。</li><li id="b8f9" class="mn mo it lt b lu my lx mz ma na me nb mi nc mm mu mv mw mx bi translated">从散点图和相关热图中，我们可以看到“杂货店”和“洗涤剂 _ 纸”特征之间有很强的相关性。特征“食品杂货”和“牛奶”也显示了很好的相关性。</li><li id="f82b" class="mn mo it lt b lu my lx mz ma na me nb mi nc mm mu mv mw mx bi translated">这种相关性证实了我对“杂货”特征相关性的猜测，这可以通过“洗涤剂 _ 纸”特征来准确预测。因此，不是数据集中绝对必要的特征。</li></ul><h1 id="0834" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">数据预处理</h1><p id="4135" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">这一步是至关重要的，以确保获得的结果是重要的，有意义的，他们是优化的。我们将通过缩放数据和检测潜在的异常值来预处理数据。</p><h2 id="63b9" class="nl la it bd lb nu nv dn lf nw nx dp lj ma ny nz ll me oa ob ln mi oc od lp oe bi translated">特征缩放</h2><p id="6588" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">通常，当数据不是正态分布时，特别是如果平均值和中值变化很大(表明偏差很大)，最<a class="ae ky" href="http://econbrowser.com/archives/2014/02/use-of-logarithms-in-economics" rel="noopener ugc nofollow" target="_blank">通常最适合</a>应用非线性标度，尤其是对于金融数据。</p><p id="f01e" class="pw-post-body-paragraph lr ls it lt b lu mp ju lw lx mq jx lz ma nd mc md me ne mg mh mi nf mk ml mm im bi translated">实现这种缩放的一种方法是使用<a class="ae ky" href="http://scipy.github.io/devdocs/generated/scipy.stats.boxcox.html" rel="noopener ugc nofollow" target="_blank"> Box-Cox 测试</a>，该测试计算减少偏斜的数据的最佳幂变换。一种在大多数情况下都可行的更简单的方法是应用自然对数。</p><pre class="kj kk kl km gt ng nh ni nj aw nk bi"><span id="0c4c" class="nl la it nh b gy nm nn l no np"><strong class="nh iu"><em class="nq"># Scale the data using the natural logarithm</em> </strong><br/>log_data = np.log(data)  </span><span id="e473" class="nl la it nh b gy ok nn l no np"><strong class="nh iu"><em class="nq"># Scale the sample data using the natural logarithm</em> </strong><br/>log_samples = np.log(samples)  </span><span id="7063" class="nl la it nh b gy ok nn l no np"><strong class="nh iu"><em class="nq"># Produce a scatter matrix for each pair of newly-transformed features</em> </strong><br/>pd.scatter_matrix(log_data, alpha = 0.3, figsize = (14,8), diagonal = 'kde');</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ol"><img src="../Images/5ae9b77f35c8065e3debead54dbcbf57.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*LQE8q0sHxAwkGB2ZErrbcw.png"/></div></div></figure><h2 id="508e" class="nl la it bd lb nu nv dn lf nw nx dp lj ma ny nz ll me oa ob ln mi oc od lp oe bi translated">观察</h2><p id="3cc6" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">在对数据应用自然对数标度后，每个特征的分布看起来更加正常。对于我们之前识别为相关的任何特征对，我们在这里观察到相关性仍然存在(以及它现在比以前更强还是更弱)。</p><p id="21a4" class="pw-post-body-paragraph lr ls it lt b lu mp ju lw lx mq jx lz ma nd mc md me ne mg mh mi nf mk ml mm im bi translated">显示实际数据:</p><pre class="kj kk kl km gt ng nh ni nj aw nk bi"><span id="dd0c" class="nl la it nh b gy nm nn l no np"><strong class="nh iu"><em class="nq"># Display the log-transformed sample data</em></strong><br/>display(log_samples)</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi om"><img src="../Images/0b26727b429657c2e3998c9450839125.png" data-original-src="https://miro.medium.com/v2/resize:fit:1090/format:webp/1*yuy3DlzclV31J8GsvIExdA.png"/></div></figure><h2 id="4b5b" class="nl la it bd lb nu nv dn lf nw nx dp lj ma ny nz ll me oa ob ln mi oc od lp oe bi translated">离群点检测</h2><p id="34bf" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">在任何分析的数据预处理步骤中，检测数据中的异常值都是极其重要的。异常值的存在通常会扭曲考虑这些数据点的结果。</p><p id="ee1d" class="pw-post-body-paragraph lr ls it lt b lu mp ju lw lx mq jx lz ma nd mc md me ne mg mh mi nf mk ml mm im bi translated">这里，我们将使用<a class="ae ky" href="http://datapigtechnologies.com/blog/index.php/highlighting-outliers-in-your-data-with-the-tukey-method/" rel="noopener ugc nofollow" target="_blank">图基的方法来识别异常值</a>:一个<em class="nq">异常值步长</em>被计算为四分位间距(IQR)的 1.5 倍。具有超出该特征的 IQR 之外的异常值步长的特征的数据点被视为异常。</p><pre class="kj kk kl km gt ng nh ni nj aw nk bi"><span id="774c" class="nl la it nh b gy nm nn l no np">outliers = []<br/><br/><strong class="nh iu"><em class="nq"># For each feature find the data points with extreme high or low values</em></strong><br/>for feature in log_data.keys():<br/>    <br/>   <strong class="nh iu"><em class="nq"># Calculate Q1 (25th percentile of the data) for the given feature</em></strong><br/>    Q1 = np.percentile(log_data[feature],25)<br/>    <br/><strong class="nh iu">    <em class="nq"># Calculate Q3 (75th percentile of the data) for the given feature</em></strong><br/>    Q3 = np.percentile(log_data[feature],75)<br/>    <br/> <strong class="nh iu">   <em class="nq"># Use the interquartile range to calculate an outlier step (1.5 times the interquartile range)</em></strong><br/>    step = 1.5 * (Q3-Q1)<br/>    <br/>    <strong class="nh iu"><em class="nq"># Display the outliers</em></strong><br/>    print("Data points considered outliers for the feature '{}':".format(feature))<br/>    display(log_data[~((log_data[feature] &gt;= Q1 - step) &amp; (log_data[feature] &lt;= Q3 + step))])<br/>    lista = log_data[~((log_data[feature] &gt;= Q1 - step) &amp; (log_data[feature] &lt;= Q3 + step))].index.tolist()<br/>    outliers.append(lista)</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi on"><img src="../Images/a8a415c4aa3946d3753c21e656a62747.png" data-original-src="https://miro.medium.com/v2/resize:fit:1112/format:webp/1*qwW13iAhOkaDEnco5oaiXw.png"/></div></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi oo"><img src="../Images/e0759b07b61c06160df561d8b354b302.png" data-original-src="https://miro.medium.com/v2/resize:fit:1130/format:webp/1*kra3CeQovWnukS5o-sZ9DA.png"/></div></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi op"><img src="../Images/7f6f285c2bac70677e2b82ae70cdfcc9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1146/format:webp/1*AYjv0stL5kHRnIFPXKpXew.png"/></div></figure><pre class="kj kk kl km gt ng nh ni nj aw nk bi"><span id="4c41" class="nl la it nh b gy nm nn l no np">outliers </span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi oq"><img src="../Images/6a33068e3330a7f024d5f60150283708.png" data-original-src="https://miro.medium.com/v2/resize:fit:1204/format:webp/1*mnNCmYgw3eRWW84hzQ66NQ.png"/></div></figure><pre class="kj kk kl km gt ng nh ni nj aw nk bi"><span id="8e54" class="nl la it nh b gy nm nn l no np"><strong class="nh iu"># Detecting outliers that appear in more than one product</strong><br/>seen = {}<br/>dupes = []<br/><br/>for lista in outliers:<br/>    for index in lista:<br/>        if index not in seen:<br/>            seen[index] = 1<br/>        else:<br/>            if seen[index] == 1:<br/>                dupes.append(index)<br/>            seen[index] += 1<br/>dupes = sorted(dupes)<br/>dupes</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi or"><img src="../Images/4b037ce51f9bc1a0aa1db4e032a07f2e.png" data-original-src="https://miro.medium.com/v2/resize:fit:358/format:webp/1*XGMVRHS0uvghVb7eyTNw4g.png"/></div></figure><pre class="kj kk kl km gt ng nh ni nj aw nk bi"><span id="19ce" class="nl la it nh b gy nm nn l no np"><strong class="nh iu"><em class="nq"># Removing outliers</em> </strong> <br/>good_data = log_data.drop(dupes, axis=0).reset_index(drop=True)</span></pre><h2 id="a0d9" class="nl la it bd lb nu nv dn lf nw nx dp lj ma ny nz ll me oa ob ln mi oc od lp oe bi translated">观察</h2><ul class=""><li id="ca69" class="mn mo it lt b lu lv lx ly ma os me ot mi ou mm mu mv mw mx bi translated">存在于多个特征中的被视为异常值的数据点有:65、66、75、128、154。</li><li id="1489" class="mn mo it lt b lu my lx mz ma na me nb mi nc mm mu mv mw mx bi translated">K-Means 受异常值的影响很大，因为它们会显著增加算法试图最小化的损失函数。该损失函数是每个数据点到质心的距离的平方和，因此，如果异常值足够远，质心将被错误地定位。因此，离群值应该被去除。</li></ul><h1 id="eec0" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">特征转换</h1><p id="ae42" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">现在我们将使用主成分分析(PCA)来提取关于数据集的隐藏结构的结论。PCA 用于计算那些方差最大化的维度，因此我们将找到最能描述每个客户的特征组合。</p><h2 id="f6a9" class="nl la it bd lb nu nv dn lf nw nx dp lj ma ny nz ll me oa ob ln mi oc od lp oe bi translated">主成分分析</h2><p id="0d90" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">一旦数据被调整为正态分布，必要的异常值被移除，我们可以将 PCA 应用于<code class="fe ov ow ox nh b">good_data</code>以发现数据的哪些维度最大化了相关特征的方差。</p><p id="0feb" class="pw-post-body-paragraph lr ls it lt b lu mp ju lw lx mq jx lz ma nd mc md me ne mg mh mi nf mk ml mm im bi translated">除了找到这些维度，PCA 还将报告每个维度的<em class="nq">解释方差比率</em>—数据中有多少方差是由该维度单独解释的。</p><pre class="kj kk kl km gt ng nh ni nj aw nk bi"><span id="a3e5" class="nl la it nh b gy nm nn l no np"><strong class="nh iu"># Get the shape of the log_samples</strong><br/>log_samples.shape</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi oy"><img src="../Images/5e639a9d77a914012c9b2974a37b57ea.png" data-original-src="https://miro.medium.com/v2/resize:fit:102/format:webp/1*PuSuZ1mI_uQIKlXmz_0EXw.png"/></div></figure><pre class="kj kk kl km gt ng nh ni nj aw nk bi"><span id="4020" class="nl la it nh b gy nm nn l no np"><strong class="nh iu"><em class="nq"># Apply PCA by fitting the good data with the same number of dimensions as features</em></strong><br/>from sklearn.decomposition import PCA<br/>pca = PCA(n_components=good_data.shape[1])<br/>pca = pca.fit(good_data)<br/><br/><strong class="nh iu"><em class="nq"># Transform log_samples using the PCA fit above</em></strong><br/>pca_samples = pca.transform(log_samples)<br/><br/><strong class="nh iu"><em class="nq"># Generate PCA results plot</em></strong><br/>pca_results = vs.pca_results(good_data, pca)</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oz"><img src="../Images/bdef7bad68c5d643dbdf2a217a6b14bc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*cAdrW8H5AjnafmgHp9QQiA.png"/></div></div></figure><h2 id="de56" class="nl la it bd lb nu nv dn lf nw nx dp lj ma ny nz ll me oa ob ln mi oc od lp oe bi translated">观察</h2><ul class=""><li id="792c" class="mn mo it lt b lu lv lx ly ma os me ot mi ou mm mu mv mw mx bi translated">前两个主成分解释的方差占总方差的 70.68%。</li><li id="4c71" class="mn mo it lt b lu my lx mz ma na me nb mi nc mm mu mv mw mx bi translated">前三个主成分解释的方差占总方差的 93.11%。</li></ul><p id="c6fd" class="pw-post-body-paragraph lr ls it lt b lu mp ju lw lx mq jx lz ma nd mc md me ne mg mh mi nf mk ml mm im bi translated"><strong class="lt iu">尺寸讨论</strong></p><ul class=""><li id="863a" class="mn mo it lt b lu mp lx mq ma mr me ms mi mt mm mu mv mw mx bi translated">维度 1:根据负方差，该维度很好地代表了以下特征:洗涤剂 _ 纸、牛奶和杂货。主要是日常消费的公用事业。</li><li id="40a7" class="mn mo it lt b lu my lx mz ma na me nb mi nc mm mu mv mw mx bi translated">维度 2:这个维度很好地代表了负方差方面的以下特征:新鲜、冷冻和熟食。主要是消耗食物。</li><li id="3ff0" class="mn mo it lt b lu my lx mz ma na me nb mi nc mm mu mv mw mx bi translated">维度 3:这个维度很好地代表了，就正方差而言，熟食特征，就负方差而言，新鲜特征。当天要吃的食物。</li><li id="88d7" class="mn mo it lt b lu my lx mz ma na me nb mi nc mm mu mv mw mx bi translated">维度 4:这个维度很好地代表了正方差方面的冷冻特征，以及负方差方面的熟食特征。可以储存的食物。</li></ul><pre class="kj kk kl km gt ng nh ni nj aw nk bi"><span id="d799" class="nl la it nh b gy nm nn l no np"><strong class="nh iu"><em class="nq"># Display sample log-data after having a PCA transformation applied</em></strong><br/>display(pd.DataFrame(np.round(pca_samples, 4), columns = pca_results.index.values))</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi pa"><img src="../Images/eaec1df74971ee26998bec4cd4b421da.png" data-original-src="https://miro.medium.com/v2/resize:fit:1184/format:webp/1*tPPwOjD4SNVeiejRE_VT5g.png"/></div></figure><h2 id="71e8" class="nl la it bd lb nu nv dn lf nw nx dp lj ma ny nz ll me oa ob ln mi oc od lp oe bi translated">降维</h2><p id="2e56" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">当使用主成分分析时，主要目标之一是降低数据的维数。</p><p id="4c62" class="pw-post-body-paragraph lr ls it lt b lu mp ju lw lx mq jx lz ma nd mc md me ne mg mh mi nf mk ml mm im bi translated">维数减少是有代价的:使用的维数越少，意味着数据中被解释的总方差越少。正因为如此，<em class="nq">累计解释方差比</em>对于了解问题需要多少个维度极其重要。此外，如果大量的差异只能用二维或三维来解释，那么减少的数据可以在以后可视化。</p><pre class="kj kk kl km gt ng nh ni nj aw nk bi"><span id="6f77" class="nl la it nh b gy nm nn l no np"><strong class="nh iu"><em class="nq"># Apply PCA by fitting the good data with only two dimensions</em></strong><br/>pca = PCA(n_components=2).fit(good_data)<br/><br/><strong class="nh iu"><em class="nq"># Transform the good data using the PCA fit above</em></strong><br/>reduced_data = pca.transform(good_data)<br/><br/><strong class="nh iu"><em class="nq"># Transform log_samples using the PCA fit above</em></strong><br/>pca_samples = pca.transform(log_samples)<br/><br/><strong class="nh iu"><em class="nq"># Create a DataFrame for the reduced data</em></strong><br/>reduced_data = pd.DataFrame(reduced_data, columns = ['Dimension 1', 'Dimension 2'])</span></pre><p id="d343" class="pw-post-body-paragraph lr ls it lt b lu mp ju lw lx mq jx lz ma nd mc md me ne mg mh mi nf mk ml mm im bi translated">下面的单元格显示了对数变换后的样本数据在仅使用二维数据进行 PCA 变换后的变化。观察与六维中的 PCA 变换相比，前二维的值如何保持不变。</p><pre class="kj kk kl km gt ng nh ni nj aw nk bi"><span id="13da" class="nl la it nh b gy nm nn l no np"><strong class="nh iu"><em class="nq"># Display sample log-data after applying PCA transformation in two dimensions</em></strong><br/>display(pd.DataFrame(np.round(pca_samples, 4), columns = ['Dimension 1', 'Dimension 2']))</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi pb"><img src="../Images/f824ec03dc8a82d9eb4c476e5b170336.png" data-original-src="https://miro.medium.com/v2/resize:fit:430/format:webp/1*ZH05rJ4nhx9dhbUOTY9elw.png"/></div></figure><h2 id="8a26" class="nl la it bd lb nu nv dn lf nw nx dp lj ma ny nz ll me oa ob ln mi oc od lp oe bi translated">可视化双标图</h2><p id="a064" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">双标图是一种散点图，其中每个数据点都由其沿主成分的分数表示。轴是主要部件(在这种情况下是<code class="fe ov ow ox nh b">Dimension 1</code>和<code class="fe ov ow ox nh b">Dimension 2</code>)。</p><p id="63fb" class="pw-post-body-paragraph lr ls it lt b lu mp ju lw lx mq jx lz ma nd mc md me ne mg mh mi nf mk ml mm im bi translated">双绘图显示原始特征沿组件的投影。双标图可以帮助我们解释数据的降维，并发现主要成分和原始特征之间的关系。</p><pre class="kj kk kl km gt ng nh ni nj aw nk bi"><span id="69d0" class="nl la it nh b gy nm nn l no np"><strong class="nh iu"><em class="nq"># Create a biplot</em></strong><br/>vs.biplot(good_data, reduced_data, pca)</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pc"><img src="../Images/9a2e9d7506303f00de28eb2789920713.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*hR6dGSxtVaSgWKHGepcGSA.png"/></div></div></figure><p id="3548" class="pw-post-body-paragraph lr ls it lt b lu mp ju lw lx mq jx lz ma nd mc md me ne mg mh mi nf mk ml mm im bi translated">一旦我们有了原始特征投影(红色)，就更容易解释散点图中每个数据点的相对位置。</p><p id="14ff" class="pw-post-body-paragraph lr ls it lt b lu mp ju lw lx mq jx lz ma nd mc md me ne mg mh mi nf mk ml mm im bi translated">例如，图右下角的点可能对应于在<code class="fe ov ow ox nh b">'Milk'</code>、<code class="fe ov ow ox nh b">'Grocery'</code>和<code class="fe ov ow ox nh b">'Detergents_Paper'</code>上花费很多，但在其他产品类别上花费不多的客户。</p><h1 id="ccd7" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">使聚集</h1><p id="38c7" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">在本节中，我们将选择使用 K 均值聚类算法或高斯混合模型(GMM)聚类算法来识别隐藏在数据中的各种客户群。</p><p id="a1ea" class="pw-post-body-paragraph lr ls it lt b lu mp ju lw lx mq jx lz ma nd mc md me ne mg mh mi nf mk ml mm im bi translated">然后，我们将从集群中恢复特定的数据点，通过将它们转换回原始维度和规模来理解它们的重要性。</p><p id="5375" class="pw-post-body-paragraph lr ls it lt b lu mp ju lw lx mq jx lz ma nd mc md me ne mg mh mi nf mk ml mm im bi translated"><strong class="lt iu"> K 均值 vs GMM </strong></p><p id="b4dc" class="pw-post-body-paragraph lr ls it lt b lu mp ju lw lx mq jx lz ma nd mc md me ne mg mh mi nf mk ml mm im bi translated">1)使用 K-Means 作为聚类算法的主要优点是:</p><p id="3505" class="pw-post-body-paragraph lr ls it lt b lu mp ju lw lx mq jx lz ma nd mc md me ne mg mh mi nf mk ml mm im bi translated">——容易实现。</p><p id="f24c" class="pw-post-body-paragraph lr ls it lt b lu mp ju lw lx mq jx lz ma nd mc md me ne mg mh mi nf mk ml mm im bi translated">-对于大量变量，如果(K 很小)，它在计算上可能比分层聚类更快。</p><p id="1e36" class="pw-post-body-paragraph lr ls it lt b lu mp ju lw lx mq jx lz ma nd mc md me ne mg mh mi nf mk ml mm im bi translated">-一致且比例不变。</p><p id="842f" class="pw-post-body-paragraph lr ls it lt b lu mp ju lw lx mq jx lz ma nd mc md me ne mg mh mi nf mk ml mm im bi translated">-保证会收敛。</p><p id="719e" class="pw-post-body-paragraph lr ls it lt b lu mp ju lw lx mq jx lz ma nd mc md me ne mg mh mi nf mk ml mm im bi translated">2)使用高斯混合模型作为聚类算法的主要优点是:</p><p id="7398" class="pw-post-body-paragraph lr ls it lt b lu mp ju lw lx mq jx lz ma nd mc md me ne mg mh mi nf mk ml mm im bi translated">-它在聚类协方差方面更加灵活。这意味着每个聚类可以具有无约束的协方差结构。换句话说，K-means 假设每个簇都有球形结构，而 GMM 允许椭圆结构。</p><p id="d521" class="pw-post-body-paragraph lr ls it lt b lu mp ju lw lx mq jx lz ma nd mc md me ne mg mh mi nf mk ml mm im bi translated">-积分可以属于不同的集群，具有不同的成员级别。这个隶属级别是每个点属于每个聚类的概率。</p><p id="7fc0" class="pw-post-body-paragraph lr ls it lt b lu mp ju lw lx mq jx lz ma nd mc md me ne mg mh mi nf mk ml mm im bi translated">3)选择的算法:</p><ul class=""><li id="5222" class="mn mo it lt b lu mp lx mq ma mr me ms mi mt mm mu mv mw mx bi translated">选择的算法是高斯混合模型。因为数据没有被分割成清晰和不同的簇，所以我们不知道有多少簇。</li></ul><h2 id="8a68" class="nl la it bd lb nu nv dn lf nw nx dp lj ma ny nz ll me oa ob ln mi oc od lp oe bi translated">创建集群</h2><p id="ab6d" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">当事先不知道簇的数量<em class="nq"/>时，不能保证给定数量的簇最好地分割数据，因为不清楚数据中存在什么结构。</p><p id="c9c6" class="pw-post-body-paragraph lr ls it lt b lu mp ju lw lx mq jx lz ma nd mc md me ne mg mh mi nf mk ml mm im bi translated">然而，我们可以通过计算每个数据点的<em class="nq">轮廓系数</em>来量化一个聚类的“良好性”。一个数据点的<a class="ae ky" href="http://scikit-learn.org/stable/modules/generated/sklearn.metrics.silhouette_score.html" rel="noopener ugc nofollow" target="_blank">轮廓系数</a>从-1(不相似)到 1(相似)测量它与其分配的聚类有多相似。计算<em class="nq">平均值</em>轮廓系数提供了给定聚类的简单评分方法。</p><pre class="kj kk kl km gt ng nh ni nj aw nk bi"><span id="0522" class="nl la it nh b gy nm nn l no np"><strong class="nh iu"><em class="nq"># Import the necessary libraries</em></strong><br/>from sklearn.mixture import GaussianMixture<br/>from sklearn.metrics import silhouette_score<br/><br/>scores = {}<br/>for i in range(2,7):<br/>    <br/>    print('Number of clusters: ' + str(i))<br/>        <br/>    <strong class="nh iu"><em class="nq"># Apply your clustering algorithm of choice to the reduced data </em></strong><br/>    clusterer = GaussianMixture(random_state=42, n_components=i)<br/>    clusterer.fit(reduced_data)<br/><br/>  <strong class="nh iu">  <em class="nq"># Predict the cluster for each data point</em></strong><br/>    preds = clusterer.predict(reduced_data)<br/><br/>    <strong class="nh iu"><em class="nq"># Find the cluster centers</em></strong><br/>    centers = clusterer.means_<br/>    print('Cluster Center: ' + str(centers))<br/><br/>   <strong class="nh iu"> <em class="nq"># Predict the cluster for each transformed sample data point</em></strong><br/>    sample_preds = clusterer.predict(pca_samples)<br/>    print('Sample predictions: ' + str(sample_preds))<br/><br/>  <strong class="nh iu">  <em class="nq"># Calculate the mean silhouette coefficient for the number of clusters chosen</em></strong><br/>    score = silhouette_score(reduced_data, preds)<br/>    scores[i] = score<br/>    print('Silhouette score is: ' + str(score), '\n')<br/>    <br/>print('Scores: ' + str(scores))</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi pd"><img src="../Images/84d939f339a3dec43a357a606fbb2ee5.png" data-original-src="https://miro.medium.com/v2/resize:fit:692/format:webp/1*VvRKt9wgLOY7NJ71O74ksA.png"/></div></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pe"><img src="../Images/bd56073f5cfa43bf6f8bf21b7491dd6f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*0dHLpEQtKITzk2bH5xR9ow.png"/></div></div></figure><p id="5372" class="pw-post-body-paragraph lr ls it lt b lu mp ju lw lx mq jx lz ma nd mc md me ne mg mh mi nf mk ml mm im bi translated">轮廓得分最好的聚类数为 2，得分为 0.42。</p><h2 id="e66a" class="nl la it bd lb nu nv dn lf nw nx dp lj ma ny nz ll me oa ob ln mi oc od lp oe bi translated">集群可视化</h2><p id="47e8" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">一旦我们使用上面的评分标准为聚类算法选择了最佳的聚类数，我们现在可以在下面的代码块中可视化结果。</p><pre class="kj kk kl km gt ng nh ni nj aw nk bi"><span id="25cb" class="nl la it nh b gy nm nn l no np"><strong class="nh iu"><em class="nq"># Apply your clustering algorithm of choice to the reduced data </em></strong><br/>clusterer = GaussianMixture(random_state=42, n_components=2)<br/>clusterer.fit(reduced_data)<br/><br/><strong class="nh iu"><em class="nq"># Predict the cluster for each data point</em></strong><br/>preds = clusterer.predict(reduced_data)<br/><br/><strong class="nh iu"><em class="nq"># Find the cluster centers</em></strong><br/>centers = clusterer.means_<br/>print('Cluster Center: ' + str(centers))<br/><br/><strong class="nh iu"><em class="nq"># Predict the cluster for each transformed sample data point</em></strong><br/>sample_preds = clusterer.predict(pca_samples)<br/>print('Sample predictions: ' + str(sample_preds))<br/><br/><strong class="nh iu"><em class="nq"># Calculate the mean silhouette coefficient for the number of clusters chosen</em></strong><br/>score = silhouette_score(reduced_data, preds)<br/>scores[i] = score<br/>print('Silhouette score is: ' + str(score), '\n')</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi pf"><img src="../Images/59c7f0133636506bacdad1ae89571209.png" data-original-src="https://miro.medium.com/v2/resize:fit:664/format:webp/1*-g2ufku2ZxVUkKhBdRYM0w.png"/></div></figure><pre class="kj kk kl km gt ng nh ni nj aw nk bi"><span id="885c" class="nl la it nh b gy nm nn l no np"><strong class="nh iu"><em class="nq"># Display the results of the clustering from implementation</em></strong><br/>vs.cluster_results(reduced_data, preds, centers, pca_samples)</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pg"><img src="../Images/df937e1ad52f5cd22da0b0ed9a8a3e79.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Ehyk7g70ufiju7A4fT1yzQ.png"/></div></div></figure><h2 id="6763" class="nl la it bd lb nu nv dn lf nw nx dp lj ma ny nz ll me oa ob ln mi oc od lp oe bi translated">数据恢复</h2><p id="cff4" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">上图中的每个星团都有一个中心点。这些中心(或平均值)不是来自数据的特定数据点，而是在相应聚类中预测的所有数据点的<em class="nq">平均值</em>。</p><p id="ae71" class="pw-post-body-paragraph lr ls it lt b lu mp ju lw lx mq jx lz ma nd mc md me ne mg mh mi nf mk ml mm im bi translated">对于创建客户细分的问题，一个聚类的中心点对应于该细分的平均客户。由于数据目前已降维并按对数进行了缩放，我们可以通过应用逆变换从这些数据点中恢复代表性的客户支出。</p><pre class="kj kk kl km gt ng nh ni nj aw nk bi"><span id="fd1d" class="nl la it nh b gy nm nn l no np"><strong class="nh iu"><em class="nq"># Inverse transform the centers</em></strong><br/>log_centers = pca.inverse_transform(centers)<br/><br/><strong class="nh iu"><em class="nq"># Exponentiate the centers</em></strong><br/>true_centers = np.exp(log_centers)<br/><br/><strong class="nh iu"><em class="nq"># Display the true centers</em></strong><br/>segments = ['Segment <strong class="nh iu">{}</strong>'.format(i) <strong class="nh iu">for</strong> i <strong class="nh iu">in</strong> range(0,len(centers))]<br/>true_centers = pd.DataFrame(np.round(true_centers), columns = data.keys())<br/>true_centers.index = segments<br/>display(true_centers)</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ph"><img src="../Images/bd6fe8093924f85eb2d1795c140005dd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1086/format:webp/1*0VUnHCB5EUJ94oXi-eBWXg.png"/></div></figure><ul class=""><li id="f694" class="mn mo it lt b lu mp lx mq ma mr me ms mi mt mm mu mv mw mx bi translated">细分 0 可能代表新鲜食品市场，因为除了冷冻和新鲜，其他所有特征都低于中值。</li><li id="6f62" class="mn mo it lt b lu my lx mz ma na me nb mi nc mm mu mv mw mx bi translated">分段 1 可以代表超市，因为除了新鲜和冷冻之外的每个特征都高于中间值。</li></ul><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi pi"><img src="../Images/7b56fbadddd46e8ce9f4be0e73e27cd0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1388/format:webp/1*I1fIj0a9eLl56fqvk8LrVQ.png"/></div></figure><p id="d371" class="pw-post-body-paragraph lr ls it lt b lu mp ju lw lx mq jx lz ma nd mc md me ne mg mh mi nf mk ml mm im bi translated">下面的代码显示了每个样本点预计属于哪个库。</p><pre class="kj kk kl km gt ng nh ni nj aw nk bi"><span id="e102" class="nl la it nh b gy nm nn l no np"><strong class="nh iu"><em class="nq"># Display the predictions</em></strong><br/><strong class="nh iu">for</strong> i, pred <strong class="nh iu">in</strong> enumerate(sample_preds):<br/>    print("Sample point", i, "predicted to be in Cluster", pred)</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pj"><img src="../Images/8a4b8ccf9c396779549418e3e4de518a.png" data-original-src="https://miro.medium.com/v2/resize:fit:682/format:webp/1*yyOD33PEyVkc_4Q_zTslrw.png"/></div></div></figure><p id="3aa1" class="pw-post-body-paragraph lr ls it lt b lu mp ju lw lx mq jx lz ma nd mc md me ne mg mh mi nf mk ml mm im bi translated"><strong class="lt iu">观察结果</strong></p><ul class=""><li id="5837" class="mn mo it lt b lu mp lx mq ma mr me ms mi mt mm mu mv mw mx bi translated">样本点 0 →超市而最初的猜测是零售商。这种差异可能是因为集群的大小(相当大)</li><li id="9137" class="mn mo it lt b lu my lx mz ma na me nb mi nc mm mu mv mw mx bi translated">样本点 1 →超市与原猜测相同。</li><li id="8c79" class="mn mo it lt b lu my lx mz ma na me nb mi nc mm mu mv mw mx bi translated">样本点 2 →生鲜食品市场，最初的猜测是一家餐馆，考虑到该特征的消费金额，这是合理的。</li></ul><h1 id="76c5" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">结论</h1><p id="4c16" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated"><em class="nq">批发分销商如何仅使用估计的产品支出和</em> <strong class="lt iu"> <em class="nq">客户群</em> </strong> <em class="nq">数据来标记新客户？</em></p><p id="f166" class="pw-post-body-paragraph lr ls it lt b lu mp ju lw lx mq jx lz ma nd mc md me ne mg mh mi nf mk ml mm im bi translated">可以使用监督学习算法，将估计的产品支出作为属性，将客户群作为目标变量，使其成为一个分类问题(我们将有 2 个可能的标签)。由于客户细分和产品支出之间没有明确的数学关系，KNN 可能是一个很好的算法。</p><h2 id="f848" class="nl la it bd lb nu nv dn lf nw nx dp lj ma ny nz ll me oa ob ln mi oc od lp oe bi translated">可视化底层分布</h2><p id="6216" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">在本项目开始时，我们讨论过将<code class="fe ov ow ox nh b">'Channel'</code>和<code class="fe ov ow ox nh b">'Region'</code>特征从数据集中排除，以便在分析中强调客户产品类别。通过向数据集重新引入<code class="fe ov ow ox nh b">'Channel'</code>特征，当考虑先前应用于原始数据集的相同 PCA 降维时，一个有趣的结构出现了。</p><p id="ca46" class="pw-post-body-paragraph lr ls it lt b lu mp ju lw lx mq jx lz ma nd mc md me ne mg mh mi nf mk ml mm im bi translated">下面的代码块显示了每个数据点是如何被标记为<code class="fe ov ow ox nh b">'HoReCa'</code>(酒店/餐厅/咖啡馆)或<code class="fe ov ow ox nh b">'Retail'</code>缩减空间的。</p><pre class="kj kk kl km gt ng nh ni nj aw nk bi"><span id="635f" class="nl la it nh b gy nm nn l no np"><strong class="nh iu"><em class="nq"># Display the clustering results based on 'Channel' data</em></strong> vs.channel_results(reduced_data, preds, pca_samples)</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pk"><img src="../Images/6b60e902741cd60f3407a75a46732343.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*lCaAiiDwmWUKv7nG2m9rWw.png"/></div></div></figure><p id="8b8d" class="pw-post-body-paragraph lr ls it lt b lu mp ju lw lx mq jx lz ma nd mc md me ne mg mh mi nf mk ml mm im bi translated">我们可以观察到，聚类算法在将数据聚类到底层分布方面做得非常好，因为聚类 0 可以很好地与零售商相关联，聚类 1 可以很好地与 Ho/Re/Ca 相关联。</p><h1 id="3de6" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">最后的话</h1><p id="66aa" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">一如既往，我希望你<strong class="lt iu"> </strong>喜欢这篇文章，你现在是神经网络的专家了！</p><p id="6817" class="pw-post-body-paragraph lr ls it lt b lu mp ju lw lx mq jx lz ma nd mc md me ne mg mh mi nf mk ml mm im bi translated"><em class="nq">如果你想了解更多关于机器学习、数据科学和人工智能的知识</em> <strong class="lt iu"> <em class="nq">请在 Medium </em> </strong> <em class="nq">上关注我，敬请关注我的下一篇帖子！</em></p></div></div>    
</body>
</html>