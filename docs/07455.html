<html>
<head>
<title>Analyzing Wine Descriptions using the Natural Language Toolkit in Python</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用 Python 中的自然语言工具包分析葡萄酒描述</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/analyzing-wine-descriptions-using-the-natural-language-toolkit-in-python-497ac1e228d5?source=collection_archive---------23-----------------------#2019-10-18">https://towardsdatascience.com/analyzing-wine-descriptions-using-the-natural-language-toolkit-in-python-497ac1e228d5?source=collection_archive---------23-----------------------#2019-10-18</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><figure class="is it gp gr iu iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi ir"><img src="../Images/e6c27d8d6c076a8e7d76bc4335710471.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Wcfw4yWWOzPuJhLbE3_C1Q.png"/></div></div></figure><div class=""/><h1 id="856c" class="kb kc je bd kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky bi translated">为外行描述葡萄酒</h1><p id="75a9" class="pw-post-body-paragraph kz la je lb b lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw im bi translated">几个月前，我创建了一个<a class="ae lx" href="http://robotsdodream.com" rel="noopener ugc nofollow" target="_blank"> web 应用</a>，它允许用户输入一个查询，并根据语义相似度返回葡萄酒推荐。<a class="ae lx" rel="noopener" target="_blank" href="/generating-wine-recommendations-using-the-universal-sentence-encoder-d086edd13d00">它是使用 Tensorflow 实验室通用句子编码器</a>构建的。当我将该工具投入生产时，我添加了将用户输入写入数据库的代码，这样我就可以分析人们用来寻找葡萄酒的词语。根据我对目前记录的内容的分析，似乎大多数人都和我一样:我几乎没有评论葡萄酒的经验，我不知道在搜索葡萄酒时应该使用哪些词。我记录的大多数查询都是两三个简单的词，比如“容易喝”为了帮助我自己和我的用户，我正在钻研葡萄酒描述，看看我能从描述葡萄酒的语言中学到什么。滚动到文章底部，查看完整的代码。</p><figure class="lz ma mb mc gt iv gh gi paragraph-image"><div class="gh gi ly"><img src="../Images/2c645c4a63b6e89e405c14ef724f94b0.png" data-original-src="https://miro.medium.com/v2/resize:fit:932/format:webp/1*VO0ebvXRqCeqUpR_Zlxg6w.png"/></div></figure><h1 id="7cb5" class="kb kc je bd kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky bi translated">数据和依赖关系</h1><p id="2a81" class="pw-post-body-paragraph kz la je lb b lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw im bi translated">原始数据可以在<a class="ae lx" href="https://www.kaggle.com/zynicide/wine-reviews#winemag-data-130k-v2.csv" rel="noopener ugc nofollow" target="_blank"> Kaggle </a>上找到；然而，本文中的例子使用了我的工程数据。对于那些感兴趣的人，我在我的<a class="ae lx" rel="noopener" target="_blank" href="/generating-wine-recommendations-using-the-universal-sentence-encoder-d086edd13d00">原始文章</a>中讨论了一些数据工程。为了分析文本，我使用了<a class="ae lx" href="http://amueller.github.io/word_cloud/index.html" rel="noopener ugc nofollow" target="_blank"> WordCloud </a>和<a class="ae lx" href="https://www.nltk.org/" rel="noopener ugc nofollow" target="_blank"> nltk(自然语言工具包)</a> python 包。我从加载依赖项和检查数据开始:</p><pre class="lz ma mb mc gt md me mf mg aw mh bi"><span id="9235" class="mi kc je me b gy mj mk l ml mm">#dependencies<br/>import pandas as pd<br/>import sqlite3<br/>from sqlite3 import Error<br/>import re</span><span id="42d7" class="mi kc je me b gy mn mk l ml mm">from wordcloud import WordCloud<br/>import matplotlib.pyplot as plt</span><span id="0bb7" class="mi kc je me b gy mn mk l ml mm">import nltk<br/>from nltk.tokenize import RegexpTokenizer<br/>from nltk.stem.snowball import SnowballStemmer<br/>#nltk.download('wordnet')<br/>from nltk.stem.wordnet import WordNetLemmatizer</span><span id="4e02" class="mi kc je me b gy mn mk l ml mm">#nltk.download('stopwords')<br/>from nltk.corpus import stopwords</span><span id="7ca4" class="mi kc je me b gy mn mk l ml mm">from sklearn.feature_extraction.text import CountVectorizer</span><span id="8478" class="mi kc je me b gy mn mk l ml mm">#force output to display the full description<br/>pd.set_option('display.max_colwidth', -1)</span><span id="e9da" class="mi kc je me b gy mn mk l ml mm">#create connection to database<br/>conn = sqlite3.connect('db\wine_data.sqlite')<br/>c = conn.cursor()</span><span id="bd24" class="mi kc je me b gy mn mk l ml mm">#create the pandas data frame<br/>wine_df = pd.read_sql('Select title, description, rating, price, color from wine_data', conn)</span><span id="4f35" class="mi kc je me b gy mn mk l ml mm">#display the top 3 records from the data frame<br/>wine_df.head(3)</span></pre><figure class="lz ma mb mc gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi mo"><img src="../Images/810dfe183b8107a40da10526e5c9d792.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*B4poFjQ5Jysz4uUni0g8hg.png"/></div></div><figcaption class="mp mq gj gh gi mr ms bd b be z dk">Top 3 results from wine_df</figcaption></figure></div><div class="ab cl mt mu hx mv" role="separator"><span class="mw bw bk mx my mz"/><span class="mw bw bk mx my mz"/><span class="mw bw bk mx my"/></div><div class="im in io ip iq"><h1 id="45a7" class="kb kc je bd kd ke na kg kh ki nb kk kl km nc ko kp kq nd ks kt ku ne kw kx ky bi translated">字数和分布</h1><p id="304c" class="pw-post-body-paragraph kz la je lb b lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw im bi translated">从关于数据的一些基本信息开始，很容易向数据框添加一个字数统计列，并使用 pandas 的 describe 方法来处理一些基本统计数据:</p><pre class="lz ma mb mc gt md me mf mg aw mh bi"><span id="11d5" class="mi kc je me b gy mj mk l ml mm">#inline function to produce word count, splitting on spaces<br/>wine_df['word_count'] = wine_df['description'].apply(lambda x: len(str(x).split(" ")))</span><span id="3c8b" class="mi kc je me b gy mn mk l ml mm">wine_df.word_count.describe()</span></pre><figure class="lz ma mb mc gt iv gh gi paragraph-image"><div class="gh gi nf"><img src="../Images/8a84cfac1b0184f5d67a4e3b67394ba7.png" data-original-src="https://miro.medium.com/v2/resize:fit:646/format:webp/1*fT0UTD-hmfXMQSkqnn36YQ.png"/></div><figcaption class="mp mq gj gh gi mr ms bd b be z dk">wine_df.word_count.describe()</figcaption></figure><p id="bee6" class="pw-post-body-paragraph kz la je lb b lc ng le lf lg nh li lj lk ni lm ln lo nj lq lr ls nk lu lv lw im bi translated">使用 matplotlib 中的图可以很容易地直观显示字数的分布:</p><pre class="lz ma mb mc gt md me mf mg aw mh bi"><span id="6f19" class="mi kc je me b gy mj mk l ml mm">#set x for the histogram and set bins based on max<br/>x = wine_df['word_count']<br/>n_bins = 140</span><span id="8d4e" class="mi kc je me b gy mn mk l ml mm">#plot histogram<br/>plt.hist(x, bins=n_bins)<br/>plt.show()</span></pre><figure class="lz ma mb mc gt iv gh gi paragraph-image"><div class="gh gi nl"><img src="../Images/93994d3d95ee4c4369b03f2680ecbd8c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1022/format:webp/1*y9golfbcjCsjR7UWjowjjg.png"/></div><figcaption class="mp mq gj gh gi mr ms bd b be z dk">Distribution of description word count</figcaption></figure></div><div class="ab cl mt mu hx mv" role="separator"><span class="mw bw bk mx my mz"/><span class="mw bw bk mx my mz"/><span class="mw bw bk mx my"/></div><div class="im in io ip iq"><h1 id="eb22" class="kb kc je bd kd ke na kg kh ki nb kk kl km nc ko kp kq nd ks kt ku ne kw kx ky bi translated">停用词和频率</h1><p id="e239" class="pw-post-body-paragraph kz la je lb b lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw im bi translated">在依赖项中，我导入了 NLTK 库中包含的停用词列表。停用字词是最常见的字词列表，如“the”和“of”将它们从描述中移除可以突出更相关的常用词。我通过词频来判断是否应该将额外的词添加到停用词表中。在计算字数之前，我使用<a class="ae lx" href="https://en.wikipedia.org/wiki/Regular_expression" rel="noopener ugc nofollow" target="_blank">正则表达式</a>清除描述，删除标点符号、标签和特殊字符:</p><pre class="lz ma mb mc gt md me mf mg aw mh bi"><span id="2f19" class="mi kc je me b gy mj mk l ml mm">stop_words = set(stopwords.words("english"))</span><span id="b48a" class="mi kc je me b gy mn mk l ml mm">#show how many words are in the list of stop words<br/>print(len(stop_words))<br/>#179</span><span id="4ff1" class="mi kc je me b gy mn mk l ml mm">#loops through descriptions and cleans them<br/>clean_desc = []<br/>for w in range(len(wine_df.description)):<br/>    desc = wine_df['description'][w].lower()<br/>    <br/>    #remove punctuation<br/>    desc = re.sub('[^a-zA-Z]', ' ', desc)<br/>    <br/>    #remove tags<br/>    desc=re.sub("&amp;lt;/?.*?&amp;gt;"," &amp;lt;&amp;gt; ",desc)<br/>    <br/>    #remove digits and special chars<br/>    desc=re.sub("(\\d|\\W)+"," ",desc)<br/>    <br/>    clean_desc.append(desc)</span><span id="c07c" class="mi kc je me b gy mn mk l ml mm">#assign the cleaned descriptions to the data frame<br/>wine_df['clean_desc'] = clean_desc</span><span id="31c9" class="mi kc je me b gy mn mk l ml mm">#calculate the frequency<br/>word_frequency = pd.Series(' '.join(wine_df['clean_desc']).split()).value_counts()[:30]<br/>word_frequency</span></pre><figure class="lz ma mb mc gt iv gh gi paragraph-image"><div class="gh gi nm"><img src="../Images/e8dfdc92f5a349183c92dc78f985af88.png" data-original-src="https://miro.medium.com/v2/resize:fit:350/format:webp/1*vl5iRdmpg-OwZn_vp-ozpw.png"/></div><figcaption class="mp mq gj gh gi mr ms bd b be z dk">25 most frequent words</figcaption></figure><p id="f991" class="pw-post-body-paragraph kz la je lb b lc ng le lf lg nh li lj lk ni lm ln lo nj lq lr ls nk lu lv lw im bi translated">查看最常用单词的列表，我决定将“葡萄酒”和“饮料”添加到停用单词列表中，这样它们就不会显示在单词云中。</p><pre class="lz ma mb mc gt md me mf mg aw mh bi"><span id="c416" class="mi kc je me b gy mj mk l ml mm">#add single word to stoplist<br/>#stop_words.add("wine")</span><span id="2b35" class="mi kc je me b gy mn mk l ml mm">#add list of words to stoplist<br/>add_stopwords = ["wine", "drink"]<br/>stop_words = stop_words.union(add_stopwords)</span><span id="d4e9" class="mi kc je me b gy mn mk l ml mm">print(len(stop_words))<br/>#181</span></pre></div><div class="ab cl mt mu hx mv" role="separator"><span class="mw bw bk mx my mz"/><span class="mw bw bk mx my mz"/><span class="mw bw bk mx my"/></div><div class="im in io ip iq"><h1 id="16c1" class="kb kc je bd kd ke na kg kh ki nb kk kl km nc ko kp kq nd ks kt ku ne kw kx ky bi translated">词干化还是词干化？</h1><p id="cee7" class="pw-post-body-paragraph kz la je lb b lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw im bi translated">两者都是规范化语言的技术，但是变元化和词干化之间的主要区别在于变元化将单词简化为词根形式，同时保持它是一个真实的单词。词干化通过去除后缀将单词还原为词根形式，并将其转化为真实单词的表示形式。例如，词干“body”和“body”都会导致“bodi”我相信共识是，引理满足优于一些词干算法；然而，词干仍然是一项需要理解的重要技术。比较这两个词云:第一个用词干处理，第二个用词条解释:</p><figure class="lz ma mb mc gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi nn"><img src="../Images/3cbe942c9f958248fb587fd34f010b1b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*08nWsbZyeqzGR23gkabEpg.png"/></div></div><figcaption class="mp mq gj gh gi mr ms bd b be z dk">Stemming (left) v.s. Lemmatisation (right)</figcaption></figure><p id="178d" class="pw-post-body-paragraph kz la je lb b lc ng le lf lg nh li lj lk ni lm ln lo nj lq lr ls nk lu lv lw im bi translated">尽管大体相似，但请注意词干是如何影响单词后缀的。你可以看到包括“dri”、“complex”和“medium bodi”在内的几个词之间的明显区别</p><pre class="lz ma mb mc gt md me mf mg aw mh bi"><span id="52f6" class="mi kc je me b gy mj mk l ml mm">stem_desc = []<br/>for w in range(len(wine_df['clean_desc'])):</span><span id="ab70" class="mi kc je me b gy mn mk l ml mm">split_text = wine_df['clean_desc'][w].split()<br/>    <br/>    ##Stemming<br/>#     stm = SnowballStemmer("english")<br/>#     split_text = [stm.stem(word) for word in split_text if not word in stop_words] <br/>#     split_text = " ".join(split_text)<br/>#     stem_desc.append(split_text)<br/>    <br/>    #Lemmatisation<br/>    lem = WordNetLemmatizer()<br/>    split_text = [lem.lemmatize(word) for word in split_text if not word in stop_words] <br/>    split_text = " ".join(split_text)<br/>    stem_desc.append(split_text)<br/>stem_desc</span></pre></div><div class="ab cl mt mu hx mv" role="separator"><span class="mw bw bk mx my mz"/><span class="mw bw bk mx my mz"/><span class="mw bw bk mx my"/></div><div class="im in io ip iq"><h1 id="5663" class="kb kc je bd kd ke na kg kh ki nb kk kl km nc ko kp kq nd ks kt ku ne kw kx ky bi translated">生成单词云</h1><p id="68c2" class="pw-post-body-paragraph kz la je lb b lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw im bi translated">词云是可视化文本数据的一种有用方式，因为它们使理解词频变得更容易。在葡萄酒描述中出现频率更高的词在云中会显得更大。这是一种提取和可视化关键词的方法。</p><pre class="lz ma mb mc gt md me mf mg aw mh bi"><span id="c205" class="mi kc je me b gy mj mk l ml mm">#set the word cloud parameters<br/>wordcloud = WordCloud(width = 800, height = 800, background_color = 'black', stopwords = stop_words, max_words = 1000,                  min_font_size = 20).generate(str(stem_desc))<br/></span><span id="2e6c" class="mi kc je me b gy mn mk l ml mm">#plot the word cloud<br/>fig = plt.figure(figsize = (8,8), facecolor = None)<br/>plt.imshow(wordcloud)<br/>plt.axis('off')<br/>plt.show()<br/>#fig.savefig("wordcloud.png")</span></pre><figure class="lz ma mb mc gt iv gh gi paragraph-image"><div class="gh gi no"><img src="../Images/90c63a9bf2ec90185661d3e52a85a5c9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1118/format:webp/1*Pn3euRy_80CbzDh8IN4J3g.png"/></div><figcaption class="mp mq gj gh gi mr ms bd b be z dk">Word Cloud</figcaption></figure></div><div class="ab cl mt mu hx mv" role="separator"><span class="mw bw bk mx my mz"/><span class="mw bw bk mx my mz"/><span class="mw bw bk mx my"/></div><div class="im in io ip iq"><h1 id="b473" class="kb kc je bd kd ke na kg kh ki nb kk kl km nc ko kp kq nd ks kt ku ne kw kx ky bi translated">分析 n 元语法</h1><p id="eba7" class="pw-post-body-paragraph kz la je lb b lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw im bi translated">观察排名靠前的单词序列有助于理解描述葡萄酒的语言。三元模型分析三个单词的组合，可以让我们深入了解描述葡萄酒的常见方式，因为它保持了单词的顺序。通常，n-gram 模型用于帮助预测序列中的下一个项目，并帮助在文本分析期间维护上下文。</p><p id="4a73" class="pw-post-body-paragraph kz la je lb b lc ng le lf lg nh li lj lk ni lm ln lo nj lq lr ls nk lu lv lw im bi translated">因为目的是分析如何描述葡萄酒，所以我需要基于频率分析创建一个新的停用词列表。我使用 scikit-learn CountVectorizer 创建一个函数来生成三元模型，然后将它们放入一个数据框中，看看我的停用词列表是否需要调整。</p><pre class="lz ma mb mc gt md me mf mg aw mh bi"><span id="83e2" class="mi kc je me b gy mj mk l ml mm">def get_trigrams(descriptions, n=None):<br/>    <br/>    vec = CountVectorizer(ngram_range = (3,3), max_features = 20000).fit(descriptions)<br/>    bag_of_words = vec.transform(descriptions)<br/>    sum_words = bag_of_words.sum(axis = 0) <br/>    words_freq = [(word, sum_words[0, i]) for word, i in vec.vocabulary_.items()]<br/>    words_freq =sorted(words_freq, key = lambda x: x[1], reverse = True)<br/>   <br/>    return words_freq[:n]</span><span id="79b2" class="mi kc je me b gy mn mk l ml mm">#run the function on the processed descriptions<br/>trigrams = get_trigrams(clean_desc, n=15)</span><span id="b25b" class="mi kc je me b gy mn mk l ml mm">#create a trigram data frame<br/>trigram_df = pd.DataFrame(trigrams)<br/>trigram_df.columns=["Trigram", "Freq"]</span><span id="a747" class="mi kc je me b gy mn mk l ml mm">#output top 15 rows<br/>trigram_df.head(15)</span></pre><figure class="lz ma mb mc gt iv gh gi paragraph-image"><div class="gh gi np"><img src="../Images/9f466da78cd1327eb314cbd1f0e19d72.png" data-original-src="https://miro.medium.com/v2/resize:fit:370/format:webp/1*7UahEU267mxIaoVSVL0b5Q.png"/></div><figcaption class="mp mq gj gh gi mr ms bd b be z dk">top 15 trigrams</figcaption></figure><p id="7ddb" class="pw-post-body-paragraph kz la je lb b lc ng le lf lg nh li lj lk ni lm ln lo nj lq lr ls nk lu lv lw im bi translated">在分析了顶级三元模型之后，我决定使用一个定制的停用词表。我去掉了“葡萄酒”和“饮料”以及几个顶级品种，所以我只剩下 n_grams 来帮助我理解如何描述葡萄酒。</p><pre class="lz ma mb mc gt md me mf mg aw mh bi"><span id="de69" class="mi kc je me b gy mj mk l ml mm">stops = ['wine','the', 'drink', 'an', 'cabernet', 'sauvignon', 'black', 'cherry']</span><span id="7fc4" class="mi kc je me b gy mn mk l ml mm">stem_desc = []<br/>for w in range(len(wine_df['clean_desc'])):</span><span id="381a" class="mi kc je me b gy mn mk l ml mm">split_text = wine_df['clean_desc'][w].split()<br/>       <br/>    #Lemmatisation<br/>    #lem = WordNetLemmatizer()<br/>    split_text = [lem.lemmatize(word) for word in split_text if not word in stops] <br/>    split_text = " ".join(split_text)<br/>    stem_desc.append(split_text)</span><span id="d1e2" class="mi kc je me b gy mn mk l ml mm">trigrams = get_trigrams(clean_desc, n=15)</span><span id="1eb0" class="mi kc je me b gy mn mk l ml mm">#create a trigram data frame<br/>trigram_df = pd.DataFrame(trigrams)<br/>trigram_df.columns=["Trigram", "Freq"]</span><span id="1377" class="mi kc je me b gy mn mk l ml mm">#output top 15 rows<br/>trigram_df.head(15)</span></pre><p id="25da" class="pw-post-body-paragraph kz la je lb b lc ng le lf lg nh li lj lk ni lm ln lo nj lq lr ls nk lu lv lw im bi translated">可以使用条形图来可视化三元模型。</p><pre class="lz ma mb mc gt md me mf mg aw mh bi"><span id="ffd7" class="mi kc je me b gy mj mk l ml mm">fig = sns.set(rc = {'figure.figsize':(12,8)})<br/>bp = sns.barplot(x = "Trigram", y = "Freq", data = trigram_df)<br/>bp.set_xticklabels(bp.get_xticklabels(), rotation = 75)<br/>plt.show()</span></pre><figure class="lz ma mb mc gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi nq"><img src="../Images/710d46017cbbb4021c2e515a649fa8c8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*q4KuS3ygklrz_0-uBekRwA.png"/></div></div><figcaption class="mp mq gj gh gi mr ms bd b be z dk">Top 15 trigrams</figcaption></figure><p id="32ab" class="pw-post-body-paragraph kz la je lb b lc ng le lf lg nh li lj lk ni lm ln lo nj lq lr ls nk lu lv lw im bi translated">通过查看三元模型，我可以深入了解应该如何查询葡萄酒。例如，我可以看到描述中包含像“带有暗示”和“有点”这样的描述符是很常见的结合“云”这个词，我现在对关键词、顶级品种和用于描述葡萄酒的语言有了更好的理解。以下是所有代码:</p><pre class="lz ma mb mc gt md me mf mg aw mh bi"><span id="314a" class="mi kc je me b gy mj mk l ml mm">#dependencies<br/>import pandas as pd<br/>import sqlite3<br/>from sqlite3 import Error<br/>import re<br/>from wordcloud import WordCloud<br/>import matplotlib.pyplot as plt<br/>import nltk<br/>from nltk.tokenize import RegexpTokenizer<br/>from nltk.stem.snowball import SnowballStemmer<br/>#nltk.download('wordnet')<br/>from nltk.stem.wordnet import WordNetLemmatizer<br/>#nltk.download('stopwords')<br/>from nltk.corpus import stopwords<br/>from sklearn.feature_extraction.text import CountVectorizer<br/>#force output to display the full description<br/>pd.set_option('display.max_colwidth', -1)<br/>#create connection to database<br/>conn = sqlite3.connect('db\wine_data.sqlite')<br/>c = conn.cursor()</span><span id="2225" class="mi kc je me b gy mn mk l ml mm">#create the pandas data frame<br/>wine_df = pd.read_sql('Select title, description, rating, price, color from wine_data', conn)</span><span id="966f" class="mi kc je me b gy mn mk l ml mm">#display the top 3 records from the data frame<br/>wine_df.head(3)</span><span id="e83c" class="mi kc je me b gy mn mk l ml mm">#inline function to produce word count, splitting on spaces<br/>wine_df['word_count'] = wine_df['description'].apply(lambda x: len(str(x).split(" ")))</span><span id="c9b1" class="mi kc je me b gy mn mk l ml mm">wine_df.word_count.describe()</span><span id="981d" class="mi kc je me b gy mn mk l ml mm">#set x for the histogram and set bins based on max<br/>x = wine_df['word_count']<br/>n_bins = 140</span><span id="e96f" class="mi kc je me b gy mn mk l ml mm">#plot histogram<br/>plt.hist(x, bins=n_bins)<br/>plt.show()</span><span id="bbc6" class="mi kc je me b gy mn mk l ml mm">stop_words = set(stopwords.words("english"))</span><span id="e9e8" class="mi kc je me b gy mn mk l ml mm">#show how many words are in the list of stop words<br/>print(len(stop_words))<br/>#179</span><span id="e598" class="mi kc je me b gy mn mk l ml mm">#loops through descriptions and cleans them<br/>clean_desc = []<br/>for w in range(len(wine_df.description)):<br/>    desc = wine_df['description'][w].lower()<br/>    <br/>    #remove punctuation<br/>    desc = re.sub('[^a-zA-Z]', ' ', desc)<br/>    <br/>    #remove tags<br/>    desc=re.sub("&amp;lt;/?.*?&amp;gt;"," &amp;lt;&amp;gt; ",desc)<br/>    <br/>    #remove digits and special chars<br/>    desc=re.sub("(\\d|\\W)+"," ",desc)<br/>    <br/>    clean_desc.append(desc)</span><span id="c69a" class="mi kc je me b gy mn mk l ml mm">#assign the cleaned descriptions to the data frame<br/>wine_df['clean_desc'] = clean_desc</span><span id="580c" class="mi kc je me b gy mn mk l ml mm">#calculate the frequency<br/>word_frequency = pd.Series(' '.join(wine_df['clean_desc']).split()).value_counts()[:30]<br/>word_frequency</span><span id="13c1" class="mi kc je me b gy mn mk l ml mm">#add single word to stoplist<br/>#stop_words.add("wine")</span><span id="2ecb" class="mi kc je me b gy mn mk l ml mm">#add list of words to stoplist<br/>add_stopwords = ["wine", "drink"]<br/>stop_words = stop_words.union(add_stopwords)</span><span id="7ae6" class="mi kc je me b gy mn mk l ml mm">print(len(stop_words))<br/>#181</span><span id="6fc5" class="mi kc je me b gy mn mk l ml mm">stem_desc = []<br/>for w in range(len(wine_df['clean_desc'])):<br/>split_text = wine_df['clean_desc'][w].split()<br/>    <br/>    ##Stemming<br/>#     stm = SnowballStemmer("english")<br/>#     split_text = [stm.stem(word) for word in split_text if not word in stop_words] <br/>#     split_text = " ".join(split_text)<br/>#     stem_desc.append(split_text)<br/>    <br/>    #Lemmatisation<br/>    lem = WordNetLemmatizer()<br/>    split_text = [lem.lemmatize(word) for word in split_text if not word in stop_words] <br/>    split_text = " ".join(split_text)<br/>    stem_desc.append(split_text)<br/>stem_desc</span><span id="8a45" class="mi kc je me b gy mn mk l ml mm">#set the word cloud parameters<br/>wordcloud = WordCloud(width = 800, height = 800, background_color = 'black', stopwords = stop_words, max_words = 1000, min_font_size = 20).generate(str(stem_desc))</span><span id="c92f" class="mi kc je me b gy mn mk l ml mm">#plot the word cloud<br/>fig = plt.figure(figsize = (8,8), facecolor = None)<br/>plt.imshow(wordcloud)<br/>plt.axis('off')<br/>plt.show()<br/>#fig.savefig("wordcloud.png")</span><span id="18e5" class="mi kc je me b gy mn mk l ml mm">def get_trigrams(descriptions, n=None):<br/>    <br/>    vec = CountVectorizer(ngram_range = (3,3), max_features = 20000).fit(descriptions)<br/>    bag_of_words = vec.transform(descriptions)<br/>    sum_words = bag_of_words.sum(axis = 0) <br/>    words_freq = [(word, sum_words[0, i]) for word, i in vec.vocabulary_.items()]<br/>    words_freq =sorted(words_freq, key = lambda x: x[1], reverse = True)<br/>   <br/>    return words_freq[:n]</span><span id="2768" class="mi kc je me b gy mn mk l ml mm">stops = ['wine','the', 'drink', 'an', 'cabernet', 'sauvignon', 'black', 'cherry']<br/>stem_desc = []</span><span id="5bef" class="mi kc je me b gy mn mk l ml mm">for w in range(len(wine_df['clean_desc'])):<br/>split_text = wine_df['clean_desc'][w].split()<br/>       <br/>    #Lemmatisation<br/>    lem = WordNetLemmatizer()<br/>    split_text = [lem.lemmatize(word) for word in split_text if not word in stops] <br/>    split_text = " ".join(split_text)<br/>    stem_desc.append(split_text)</span><span id="a889" class="mi kc je me b gy mn mk l ml mm">trigrams = get_trigrams(clean_desc, n=15)</span><span id="4357" class="mi kc je me b gy mn mk l ml mm">#create a trigram data frame<br/>trigram_df = pd.DataFrame(trigrams)<br/>trigram_df.columns=["Trigram", "Freq"]</span><span id="9680" class="mi kc je me b gy mn mk l ml mm">#output top 15 rows<br/>trigram_df.head(15)</span><span id="a1ee" class="mi kc je me b gy mn mk l ml mm">fig = sns.set(rc = {'figure.figsize':(12,8)})<br/>bp = sns.barplot(x = "Trigram", y = "Freq", data = trigram_df)<br/>bp.set_xticklabels(bp.get_xticklabels(), rotation = 75)<br/>plt.show()</span></pre></div><div class="ab cl mt mu hx mv" role="separator"><span class="mw bw bk mx my mz"/><span class="mw bw bk mx my mz"/><span class="mw bw bk mx my"/></div><div class="im in io ip iq"><h1 id="dc7b" class="kb kc je bd kd ke na kg kh ki nb kk kl km nc ko kp kq nd ks kt ku ne kw kx ky bi translated">谢谢大家！</h1><ul class=""><li id="1183" class="nr ns je lb b lc ld lg lh lk nt lo nu ls nv lw nw nx ny nz bi translated"><em class="oa">如果你喜欢这个，</em> <a class="ae lx" href="https://medium.com/@erickleppen" rel="noopener"> <em class="oa">在 Medium 上关注我</em> </a> <em class="oa">获取更多</em></li><li id="ced8" class="nr ns je lb b lc ob lg oc lk od lo oe ls of lw nw nx ny nz bi translated"><a class="ae lx" href="https://erickleppen.medium.com/membership" rel="noopener"> <em class="oa">通过订阅</em> </a>获得对我的内容的完全访问和帮助支持</li><li id="b769" class="nr ns je lb b lc ob lg oc lk od lo oe ls of lw nw nx ny nz bi translated"><em class="oa">我们连线上</em> <a class="ae lx" href="https://www.linkedin.com/in/erickleppen01/" rel="noopener ugc nofollow" target="_blank"> <em class="oa"> LinkedIn </em> </a></li><li id="8714" class="nr ns je lb b lc ob lg oc lk od lo oe ls of lw nw nx ny nz bi translated"><em class="oa">用 Python 分析数据？查看我的</em> <a class="ae lx" href="https://pythondashboards.com/" rel="noopener ugc nofollow" target="_blank"> <em class="oa">网站</em> </a></li></ul><p id="0363" class="pw-post-body-paragraph kz la je lb b lc ng le lf lg nh li lj lk ni lm ln lo nj lq lr ls nk lu lv lw im bi translated"><a class="ae lx" href="http://pythondashboards.com/" rel="noopener ugc nofollow" target="_blank"> <strong class="lb jf"> —埃里克·克莱本</strong> </a></p><p id="1617" class="pw-post-body-paragraph kz la je lb b lc ng le lf lg nh li lj lk ni lm ln lo nj lq lr ls nk lu lv lw im bi translated">有关分析文本和自然语言处理的更多信息，请查看以下链接:</p><div class="is it gp gr iu og"><a href="https://www.nltk.org/" rel="noopener  ugc nofollow" target="_blank"><div class="oh ab fo"><div class="oi ab oj cl cj ok"><h2 class="bd jf gy z fp ol fr fs om fu fw jd bi translated">自然语言工具包- NLTK 3.4.5 文档</h2><div class="on l"><h3 class="bd b gy z fp ol fr fs om fu fw dk translated">NLTK 是构建 Python 程序来处理人类语言数据的领先平台。它提供了易于使用的…</h3></div><div class="oo l"><p class="bd b dl z fp ol fr fs om fu fw dk translated">www.nltk.org</p></div></div><div class="op l"><div class="oq l or os ot op ou ja og"/></div></div></a></div><div class="is it gp gr iu og"><a href="http://www.nltk.org/book/" rel="noopener  ugc nofollow" target="_blank"><div class="oh ab fo"><div class="oi ab oj cl cj ok"><h2 class="bd jf gy z fp ol fr fs om fu fw jd bi translated">NLTK 图书</h2><div class="on l"><h3 class="bd b gy z fp ol fr fs om fu fw dk translated">Steven Bird、Ewan Klein 和 Edward Loper 这本书的 NLTK 版本针对 Python 3 和 NLTK 3 进行了更新。第一个…</h3></div><div class="oo l"><p class="bd b dl z fp ol fr fs om fu fw dk translated">www.nltk.org</p></div></div></div></a></div><div class="is it gp gr iu og"><a href="https://medium.com/analytics-vidhya/automated-keyword-extraction-from-articles-using-nlp-bfd864f41b34" rel="noopener follow" target="_blank"><div class="oh ab fo"><div class="oi ab oj cl cj ok"><h2 class="bd jf gy z fp ol fr fs om fu fw jd bi translated">使用自然语言处理从文章中自动提取关键词</h2><div class="on l"><h3 class="bd b gy z fp ol fr fs om fu fw dk translated">背景</h3></div><div class="oo l"><p class="bd b dl z fp ol fr fs om fu fw dk translated">medium.com</p></div></div><div class="op l"><div class="ov l or os ot op ou ja og"/></div></div></a></div><p id="cad8" class="pw-post-body-paragraph kz la je lb b lc ng le lf lg nh li lj lk ni lm ln lo nj lq lr ls nk lu lv lw im bi translated"><a class="ae lx" href="http://robotsdodream.com" rel="noopener ugc nofollow" target="_blank">robotsdodream.com</a></p></div></div>    
</body>
</html>