<html>
<head>
<title>How to use NVIDIA GPUs for Machine Learning with the new Data Science PC from Maingear</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">如何通过 Maingear 的新数据科学 PC 使用 NVIDIA GPUs 进行机器学习</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/how-to-use-gpus-for-machine-learning-with-the-new-nvidia-data-science-workstation-64ef37460fa0?source=collection_archive---------3-----------------------#2019-10-28">https://towardsdatascience.com/how-to-use-gpus-for-machine-learning-with-the-new-nvidia-data-science-workstation-64ef37460fa0?source=collection_archive---------3-----------------------#2019-10-28</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="f4e9" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">是的，你没看错:是机器学习，不是深度学习</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/c1bcd498a079fd654fed8578cfecc05a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*qSsiZAuYqkxzVHC4AJV4lA.png"/></div></div></figure><p id="3cae" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">深度学习使我们能够执行许多类似人类的任务，但是如果你是一名数据科学家，并且你不在 T2 的 FAANG T3 公司工作(或者如果你没有开发下一个人工智能初创公司)，你很可能仍然使用好的和旧的(好的，也许不是 T4 的 T5 旧的)T6 机器学习 T7 来执行你的日常任务。</p><p id="ff7f" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">深度学习的一个特点是计算量非常大，所以所有主要的 DL 库都利用 GPU 来提高处理速度。但是，如果你曾经因为不从事深度学习而感到被排除在派对之外，那种日子已经过去了:现在有了<a class="ae lo" href="https://developer.nvidia.com/rapids" rel="noopener ugc nofollow" target="_blank"> RAPIDS </a>库套件，我们可以完全在 GPU 上运行我们的数据科学和分析管道<strong class="kt ir">。</strong></p><p id="92da" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">在本文中，我们将讨论其中的一些 RAPIDS 库，并进一步了解 Maingear 的新型<strong class="kt ir">数据科学 PC。</strong></p><h1 id="c722" class="lp lq iq bd lr ls lt lu lv lw lx ly lz jw ma jx mb jz mc ka md kc me kd mf mg bi translated">为什么人们会使用 GPU 呢？</h1><p id="51b3" class="pw-post-body-paragraph kr ks iq kt b ku mh jr kw kx mi ju kz la mj lc ld le mk lg lh li ml lk ll lm ij bi translated">一般来说，GPU 速度很快，因为它们有<strong class="kt ir">高带宽存储器</strong>和执行<strong class="kt ir">浮点运算</strong>的硬件，其速度明显高于传统 CPUs】。GPU 的主要任务是执行渲染 3D 计算机图形所需的计算。</p><p id="477c" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">但是在 2007 年，NVIDIA 创造了 CUDA。CUDA 是一个<strong class="kt ir">并行计算平台</strong>，为开发者提供 API，允许他们构建能够利用 GPU 进行<strong class="kt ir">通用处理</strong>的工具。</p><blockquote class="mm"><p id="6284" class="mn mo iq bd mp mq mr ms mt mu mv lm dk translated">GPU 已经发展成为高度并行的多核系统，可以非常高效地处理大块数据。在并行处理大块数据的情况下，这种设计比通用中央处理器(CPU)更有效</p></blockquote><p id="c209" class="pw-post-body-paragraph kr ks iq kt b ku mw jr kw kx mx ju kz la my lc ld le mz lg lh li na lk ll lm ij bi translated">处理大块数据基本上是机器学习做的事情，所以 GPU 对于 ML 任务来说就派上用场了。TensorFlow 和 Pytorch 是已经使用 GPU 的库的例子。现在有了 RAPIDS 库套件，我们还可以<strong class="kt ir">操纵数据帧，并在 GPU 上运行机器学习算法</strong>。</p><h1 id="fe1e" class="lp lq iq bd lr ls lt lu lv lw lx ly lz jw ma jx mb jz mc ka md kc me kd mf mg bi translated">湍流</h1><p id="b5d9" class="pw-post-body-paragraph kr ks iq kt b ku mh jr kw kx mi ju kz la mj lc ld le mk lg lh li ml lk ll lm ij bi translated">RAPIDS 是一套<strong class="kt ir">开源库</strong>，其中<strong class="kt ir">集成了流行的数据科学库和工作流</strong>来加速机器学习【3】。</p><p id="b748" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">一些 RAPIDS 项目包括<a class="ae lo" href="https://github.com/rapidsai/cudf" rel="noopener ugc nofollow" target="_blank"> cuDF </a>，一个类似<strong class="kt ir">熊猫的</strong>数据帧操作库；<a class="ae lo" href="https://github.com/rapidsai/cuml" rel="noopener ugc nofollow" target="_blank"> cuML </a>，一个机器学习库的集合，将提供<strong class="kt ir"> sciKit-learn </strong>中可用算法的 GPU 版本；cuGraph，一个类似 NetworkX 的加速图形分析库[4]。</p><p id="267a" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">Pandas 和 sciKit-learn 是两个主要的数据科学库，所以让我们了解更多关于<strong class="kt ir"> cuDF </strong>和<strong class="kt ir"> cuML </strong>的知识。</p><h2 id="fbb4" class="nb lq iq bd lr nc nd dn lv ne nf dp lz la ng nh mb le ni nj md li nk nl mf nm bi translated">cuDF:数据帧操作</h2><p id="583e" class="pw-post-body-paragraph kr ks iq kt b ku mh jr kw kx mi ju kz la mj lc ld le mk lg lh li ml lk ll lm ij bi translated">cuDF 为数据帧操作提供了一个类似 pandas 的 API，所以如果你知道如何使用 pandas，你就已经知道如何使用 cuDF。如果你想在多个 GPU 上分布你的工作流，还有 Dask-cuDF 库。</p><p id="2861" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">我们可以像熊猫一样创造系列和数据框架:</p><pre class="kg kh ki kj gt nn no np nq aw nr bi"><span id="852a" class="nb lq iq no b gy ns nt l nu nv">import numpy as np<br/><strong class="no ir">import cudf</strong></span><span id="335c" class="nb lq iq no b gy nw nt l nu nv">s = <strong class="no ir">cudf.Series(</strong>[1,2,3,None,4]<strong class="no ir">)</strong></span><span id="3c06" class="nb lq iq no b gy nw nt l nu nv">df = <strong class="no ir">cudf.DataFrame(</strong>[('a', list(range(20))),<br/>                     ('b', list(reversed(range(20)))),<br/>                     ('c', list(range(20)))]<strong class="no ir">)</strong></span></pre><p id="e6a4" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">也可以<strong class="kt ir">将 pandas 数据帧转换成 cuDF 数据帧</strong>(但是<em class="ln">不建议这样做</em>):</p><pre class="kg kh ki kj gt nn no np nq aw nr bi"><span id="bfbd" class="nb lq iq no b gy ns nt l nu nv">import pandas as pd<br/><strong class="no ir">import cudf</strong></span><span id="51b1" class="nb lq iq no b gy nw nt l nu nv">df = pd.DataFrame({'a': [0, 1, 2, 3],'b': [0.1, 0.2, None, 0.3]})<br/>gdf = <strong class="no ir">cudf.DataFrame.from_pandas(</strong>df<strong class="no ir">)</strong></span></pre><p id="8020" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">我们也可以做相反的事情，将 cuDF 数据帧转换成 pandas 数据帧。</p><pre class="kg kh ki kj gt nn no np nq aw nr bi"><span id="f981" class="nb lq iq no b gy ns nt l nu nv">import cudf</span><span id="f1ae" class="nb lq iq no b gy nw nt l nu nv">df = <strong class="no ir">cudf.DataFrame(</strong>[('a', list(range(20))),<br/>                     ('b', list(reversed(range(20)))),<br/>                     ('c', list(range(20)))]<strong class="no ir">)</strong></span><span id="c370" class="nb lq iq no b gy nw nt l nu nv">pandas_df = df.head().<strong class="no ir">to_pandas()</strong></span></pre><p id="ec6a" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">或者转换成<strong class="kt ir"> numpy </strong>数组:</p><pre class="kg kh ki kj gt nn no np nq aw nr bi"><span id="7b18" class="nb lq iq no b gy ns nt l nu nv">import cudf</span><span id="22d8" class="nb lq iq no b gy nw nt l nu nv">df = cudf.DataFrame([('a', list(range(20))),<br/>                     ('b', list(reversed(range(20)))),<br/>                     ('c', list(range(20)))])<strong class="no ir"><br/></strong>df.<strong class="no ir">as_matrix()</strong></span><span id="cf0c" class="nb lq iq no b gy nw nt l nu nv">df['a'].<strong class="no ir">to_array()</strong></span></pre><p id="5383" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">我们对数据帧所做的其他事情(查看数据、排序、选择、处理缺失值、处理 csv 文件等等)都是一样的:</p><pre class="kg kh ki kj gt nn no np nq aw nr bi"><span id="aab0" class="nb lq iq no b gy ns nt l nu nv">import cudf</span><span id="7d96" class="nb lq iq no b gy nw nt l nu nv">df = <strong class="no ir">cudf.DataFrame</strong>([('a', list(range(20))),<br/>                     ('b', list(reversed(range(20)))),<br/>                     ('c', list(range(20)))]<strong class="no ir">)</strong></span><span id="7bdb" class="nb lq iq no b gy nw nt l nu nv">df.<strong class="no ir">head</strong>(2)<br/>df.<strong class="no ir">sort_values</strong>(by='b')<br/>df['a']<br/>df.<strong class="no ir">loc</strong>[2:5, ['a', 'b']]</span><span id="ebc8" class="nb lq iq no b gy nw nt l nu nv">s = cudf.Series([1,2,3,None,4])<strong class="no ir"><br/></strong>s.fillna(999)</span><span id="a26a" class="nb lq iq no b gy nw nt l nu nv">df = cudf.<strong class="no ir">read_csv(</strong>'example_output/foo.csv'<strong class="no ir">)<br/></strong>df.<strong class="no ir">to_csv(</strong>'example_output/foo.csv', index=False<strong class="no ir">)</strong></span></pre><p id="09ce" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">关于性能，仅举一个例子，用熊猫加载一个 1gb 的 csv 文件需要 13 秒，用 cuDF 加载需要 2.53 秒。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nx"><img src="../Images/2a525dfaa41592287e8425e00ec56161.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*M-lroIJXoFW8iDyPm_fqHA.png"/></div></div><figcaption class="ny nz gj gh gi oa ob bd b be z dk">Loading a 1gb csv 5X faster with cuDF</figcaption></figure><h2 id="9d1d" class="nb lq iq bd lr nc nd dn lv ne nf dp lz la ng nh mb le ni nj md li nk nl mf nm bi translated">cuML:机器学习算法</h2><p id="8ba0" class="pw-post-body-paragraph kr ks iq kt b ku mh jr kw kx mi ju kz la mj lc ld le mk lg lh li ml lk ll lm ij bi translated">cuML 与其他 RAPIDS 项目集成实现了<strong class="kt ir">机器学习算法</strong>和<strong class="kt ir">数学原语函数</strong>。在大多数情况下，cuML 的 Python API 与来自<strong class="kt ir"> sciKit-learn </strong>的 API 相匹配。该项目仍然有一些限制(例如，目前 cuML RandomForestClassifier 的实例不能被腌制)，但他们有一个短暂的 6 周发布时间表，所以他们总是添加新的功能。</p><p id="9c8a" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">除了其他工具之外，还有对<a class="ae lo" href="https://rapidsai.github.io/projects/cuml/en/0.10.0/api.html#regression-and-classification" rel="noopener ugc nofollow" target="_blank">回归</a>、<a class="ae lo" href="https://rapidsai.github.io/projects/cuml/en/0.10.0/api.html#regression-and-classification" rel="noopener ugc nofollow" target="_blank">分类</a>、<a class="ae lo" href="https://rapidsai.github.io/projects/cuml/en/0.10.0/api.html#clustering" rel="noopener ugc nofollow" target="_blank">聚类</a>和<a class="ae lo" href="https://rapidsai.github.io/projects/cuml/en/0.10.0/api.html#dimensionality-reduction-and-manifold-learning" rel="noopener ugc nofollow" target="_blank">维度缩减</a>算法的实现。该 API 确实与 sciKit API 非常一致:</p><pre class="kg kh ki kj gt nn no np nq aw nr bi"><span id="c193" class="nb lq iq no b gy ns nt l nu nv">import cudf<br/>import numpy as np</span><span id="f2c5" class="nb lq iq no b gy nw nt l nu nv">from <strong class="no ir">cuml.linear_model</strong> import <strong class="no ir">LogisticRegression</strong><br/><br/>X = cudf.DataFrame()</span><span id="f3ed" class="nb lq iq no b gy nw nt l nu nv">X['col1'] = np.array([1,1,2,2], dtype = np.float32)<br/>X['col2'] = np.array([1,2,2,3], dtype = np.float32)</span><span id="1077" class="nb lq iq no b gy nw nt l nu nv">y = cudf.Series( np.array([0.0, 0.0, 1.0, 1.0], dtype = np.float32) )</span><span id="707a" class="nb lq iq no b gy nw nt l nu nv"># training</span><span id="e757" class="nb lq iq no b gy nw nt l nu nv">reg = <strong class="no ir">LogisticRegression()</strong><br/>reg.<strong class="no ir">fit(</strong>X,y<strong class="no ir">)</strong><br/><br/>print("Coefficients:")<br/>print(reg.coef_.copy_to_host())<br/>print("Intercept:")<br/>print(reg.intercept_.copy_to_host())</span><span id="caec" class="nb lq iq no b gy nw nt l nu nv"># making predictions</span><span id="3065" class="nb lq iq no b gy nw nt l nu nv">X_new = cudf.DataFrame()</span><span id="51af" class="nb lq iq no b gy nw nt l nu nv">X_new['col1'] = np.array([1,5], dtype = np.float32)<br/>X_new['col2'] = np.array([2,5], dtype = np.float32)<br/><br/>preds = reg.<strong class="no ir">predict(</strong>X_new<strong class="no ir">)</strong><br/><br/>print("Predictions:")<br/>print(preds)</span></pre><h1 id="5520" class="lp lq iq bd lr ls lt lu lv lw lx ly lz jw ma jx mb jz mc ka md kc me kd mf mg bi translated">Maingear 的数据科学电脑</h1><p id="2cab" class="pw-post-body-paragraph kr ks iq kt b ku mh jr kw kx mi ju kz la mj lc ld le mk lg lh li ml lk ll lm ij bi translated">这些都很棒，但是我们如何使用这些工具呢？嗯，首先你需要弄一个<strong class="kt ir"> NVIDIA GPU 卡</strong> <a class="ae lo" href="https://rapids.ai/start.html#prerequisites" rel="noopener ugc nofollow" target="_blank"> <strong class="kt ir">兼容 RAPIDS </strong> </a>。如果你不想花时间找出硬件规格的最佳选择，NVIDIA 将发布<strong class="kt ir">数据科学 PC </strong>。</p><p id="8e45" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">PC 自带软件栈，优化运行所有这些用于机器学习和深度学习的库。它带有 Ubuntu 18.04，你可以使用来自<a class="ae lo" href="https://ngc.nvidia.com/catalog/all" rel="noopener ugc nofollow" target="_blank"> NVIDIA GPU Cloud </a>的 docker 容器，或者使用原生的 conda 环境。PC 最大的好处之一就是你可以完全安装所有的库和软件。如果你曾经不得不在 Linux 发行版上安装 NVIDIA 驱动程序，或者不得不从源代码安装 TensorFlow，你就会知道这有多梦幻。这些是系统规格:</p><ul class=""><li id="6d8d" class="oc od iq kt b ku kv kx ky la oe le of li og lm oh oi oj ok bi translated"><strong class="kt ir"> GPU </strong></li></ul><p id="102e" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">配备 24 GB GPU 内存的 NVIDIA Titan RTX<strong class="kt ir"><em class="ln">或</em> </strong>双路 NVIDIA Titan RTX 通过 NVIDIA NVLink 连接，提供 48 GB GPU 内存</p><ul class=""><li id="ec4a" class="oc od iq kt b ku kv kx ky la oe le of li og lm oh oi oj ok bi translated"><strong class="kt ir"> CPU </strong></li></ul><p id="2e08" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">英特尔酷睿 i7 类 CPU <strong class="kt ir"> <em class="ln">或</em> </strong>更高</p><ul class=""><li id="389c" class="oc od iq kt b ku kv kx ky la oe le of li og lm oh oi oj ok bi translated"><strong class="kt ir">系统内存</strong></li></ul><p id="c91d" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">最少 48 GB DDR4 系统内存用于<strong class="kt ir">单 GPU 配置</strong>和<strong class="kt ir"> </strong>最少 48 GB DDR4 系统内存用于<strong class="kt ir">双 GPU 配置</strong></p><ul class=""><li id="d6c6" class="oc od iq kt b ku kv kx ky la oe le of li og lm oh oi oj ok bi translated"><strong class="kt ir">磁盘</strong></li></ul><p id="3761" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">最少 1 TB 固态硬盘</p><p id="ae51" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated"><a class="ae lo" href="https://maingear.com/nvidiadatascience/" rel="noopener ugc nofollow" target="_blank"> Maingear VYBE PRO 数据科学 PC </a>配备了多达两个双 NVIDIA TITAN RTX 24GB 卡，每台 PC 都是手工组装的<strong class="kt ir">。</strong></p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ol"><img src="../Images/6f58f9afa93db6e744f592a7b0bdc4d2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*VPj5cud_Tc445oBSRsybiw.png"/></div></div><figcaption class="ny nz gj gh gi oa ob bd b be z dk">A <a class="ae lo" href="https://maingear.com/nvidiadatascience/" rel="noopener ugc nofollow" target="_blank">VYBE PRO PC from Maingear</a> with two NVIDIA TITAN RTX cards (this thing is so beautiful I was afraid to turn it on)</figcaption></figure><p id="c960" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">使用具有 4，000，000 行和 1000 列的数据集在 VYBER PRO PC 上训练 XGBoost 模型(此数据帧使用大约。15 GB 内存)在 CPU 上占用<strong class="kt ir"> 1min 46s(内存增量为<strong class="kt ir">73325 MiB</strong>)<strong class="kt ir">T5】在 GPU</strong>上仅<strong class="kt ir"> 21.2s(内存增量为<strong class="kt ir"> 520 MiB </strong>)。</strong></strong></p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi om"><img src="../Images/d062925b8e7a2e23b6670f20f18358e3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/1*IGT4OOdhXw9qR-4dfaBT2g.gif"/></div></div><figcaption class="ny nz gj gh gi oa ob bd b be z dk">Training a XGBoost model 5X faster with GPUs</figcaption></figure><h1 id="d3b3" class="lp lq iq bd lr ls lt lu lv lw lx ly lz jw ma jx mb jz mc ka md kc me kd mf mg bi translated">结论</h1><p id="db36" class="pw-post-body-paragraph kr ks iq kt b ku mh jr kw kx mi ju kz la mj lc ld le mk lg lh li ml lk ll lm ij bi translated">对于数据科学，我们总是需要探索和尝试新事物。在使我们的工作流程变得困难的其他软件工程挑战中，计算我们的数据所需的大小和时间是两个瓶颈，它们阻止我们在运行我们的实验时达到<em class="ln">流状态</em>。拥有一台电脑和工具可以改善这一点，可以真正加快我们的工作，帮助我们更快地发现数据中有趣的模式。想象一下，获取一个 40 GB 的 csv 文件，然后简单地将其加载到内存中，看看它是关于什么的。</p><p id="9c0e" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">RAPIDS 工具为机器学习工程师带来了深度学习工程师已经熟悉的 GPU 处理速度提升。为了制造使用机器学习的产品，我们需要迭代并确保我们有可靠的端到端管道，使用 GPU 来执行它们将有望提高项目的输出。</p><h1 id="41f3" class="lp lq iq bd lr ls lt lu lv lw lx ly lz jw ma jx mb jz mc ka md kc me kd mf mg bi translated">参考</h1><p id="a8db" class="pw-post-body-paragraph kr ks iq kt b ku mh jr kw kx mi ju kz la mj lc ld le mk lg lh li ml lk ll lm ij bi translated">[1]<a class="ae lo" href="https://graphics.stanford.edu/papers/gpumatrixmult/gpumatrixmult.pdf" rel="noopener ugc nofollow" target="_blank">https://graphics . Stanford . edu/papers/gpumatrixmult/gpumatrixmult . pdf</a></p><p id="17b9" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated"><a class="ae lo" href="https://en.wikipedia.org/wiki/CUDA" rel="noopener ugc nofollow" target="_blank">https://en.wikipedia.org/wiki/CUDA</a></p><p id="1f4a" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">[3]<a class="ae lo" href="https://nvidianews.nvidia.com/news/nvidia-introduces-rapids-open-source-gpu-acceleration-platform-for-large-scale-data-analytics-and-machine-learning" rel="noopener ugc nofollow" target="_blank">https://NVIDIA news . NVIDIA . com/news/NVIDIA-introduces-rapids-open-source-GPU-acceleration-platform-for-large-scale-data-analytics-and-machine-learning</a></p><p id="1648" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated"><a class="ae lo" href="https://rapids.ai/about.html" rel="noopener ugc nofollow" target="_blank">https://rapids.ai/about.html</a></p><p id="7eb1" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">[5]<a class="ae lo" href="https://rapidsai.github.io/projects/cudf/en/0.10.0/10min.html#When-to-use-cuDF-and-Dask-cuDF" rel="noopener ugc nofollow" target="_blank">https://rapidsai . github . io/projects/cuDF/en/0 . 10 . 0/10min . html # When-to-use-cuDF-and-Dask-cuDF</a></p></div></div>    
</body>
</html>