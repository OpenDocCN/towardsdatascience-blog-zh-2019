<html>
<head>
<title>How can Artificial Intelligence become curious?</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">人工智能如何变得好奇？</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/artificial-curiosity-e1837e4ca2c9?source=collection_archive---------20-----------------------#2019-05-03">https://towardsdatascience.com/artificial-curiosity-e1837e4ca2c9?source=collection_archive---------20-----------------------#2019-05-03</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="ca7d" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">人工好奇心可能是机器学习和人工意识之间缺失的一环</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/8869cc11313251b57aeb19129ad8f2f8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*0o4Jaiyo4TGnrGUU"/></div></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk">Photo by <a class="ae kv" href="https://unsplash.com/@yulokchan?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Joseph Chan</a> on <a class="ae kv" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><p id="499d" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi ls translated">任何人都会因为书籍、电影和电视剧中出现的一些非凡情节而对机器学习(或更广泛的研究领域——人工智能)产生兴趣。研究和实现能够在解决许多任务方面专业化并超越人类的算法确实非常令人着迷。然而，当谈到我们通常处理的大多数问题时，感觉我们离阿齐莫夫故事和终结者电影中存在的智能实体很远。在现实中，没有公开的关于人工智能的信息，人工智能具有必要的复杂性，能够变得有意识，并能够自愿开始自己做事情。</p><p id="640b" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">那么，我们要达到那个人工智能水平，还缺什么呢？答案并不简单，但我会说大多数机器学习方法都过于依赖人类的监督。对于监督学习，必须提供带有人工分类示例的大数据集，而在强化学习中，代理高度依赖于奖励函数。从这个意义上说，这些算法与它们被编程来解决的任务紧密相关。</p><p id="7a03" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">但是，如何让一个系统在没有明确编程的情况下能够学习呢？一种选择是让这个系统对新奇的事物感到好奇。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi mb"><img src="../Images/8853b66f780232deadcd556d180f045f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*8-HVmSayGYX9x0y-"/></div></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk">Photo by <a class="ae kv" href="https://unsplash.com/@josephandjosephandjoseph?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Joseph Rosales</a> on <a class="ae kv" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><h2 id="bdbf" class="mc md iq bd me mf mg dn mh mi mj dp mk lf ml mm mn lj mo mp mq ln mr ms mt mu bi translated">什么是人工好奇心？</h2><p id="f4cb" class="pw-post-body-paragraph kw kx iq ky b kz mv jr lb lc mw ju le lf mx lh li lj my ll lm ln mz lp lq lr ij bi ls translated"><span class="l lt lu lv bm lw lx ly lz ma di">在</span>这个上下文中，好奇心被定义为一个智能体学习未知规律的兴趣。这个想法是奖励系统，如果它发现一些意想不到的东西。另一方面，当面对可预测或固有不可预测的模式时，这样的代理应该会感到厌烦。第二种说法可能听起来很奇怪，但是对于代理人来说，花费大量时间试图理解某个随机事件是如何工作的是不合理的。例如，来自无线电的静态噪声代表未知数据的连续流。然而，不可能从中提取有意义的信息。</p><p id="af7c" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">人工好奇心一词代表实现这一机制的算法。好奇心奖励被添加到代理学习过程中，与给定输入的预期结果和实际输出之间的差异成比例。如果这种差异很大，这意味着代理人“创建”的关于周围世界的模型不包括这一特定事件。收到好奇心奖励后，代理人被刺激去了解更多发生的事情。然而，对它了解得越多，预期/实际产出的差异(以及收到的回报)就会越小，导致兴趣降低。</p><p id="db72" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">当我们正确看待人类行为时，这种好奇心范式很有意义。当面对未知但可学习的情况时，我们有一种内在的动力去更好地理解它。然而，当解决一些太简单的任务，或者已经解决了很多次的任务(例如，重复的例程)，我们会感到无聊，好奇心不足以成为继续工作的动力。</p><h2 id="a7b6" class="mc md iq bd me mf mg dn mh mi mj dp mk lf ml mm mn lj mo mp mq ln mr ms mt mu bi translated">人工好奇心如何帮助解决问题？</h2><p id="8239" class="pw-post-body-paragraph kw kx iq ky b kz mv jr lb lc mw ju le lf mx lh li lj my ll lm ln mz lp lq lr ij bi ls translated">人工好奇心是探索的有力工具。这对于解决优化问题尤为重要。在这样的问题中，有时很难避免陷入次优解。在强化学习中，这通常是通过强迫代理在开始时探索来实现的。然而，定义一个好的勘探/开发比率并不容易。</p><p id="816b" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">对于好奇的代理人来说，探索是自然发生的。推动他们前进的动力是内在的:好奇心奖励是发现新事物的内在刺激。这可以很容易地与代理试图解决的任务相结合。结果是一个受两种不同动机影响的主体:外在动机(学习如何解决任务时获得奖励)和内在动机(发现新事物获得的奖励)。</p><p id="f007" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">例如，OpenAI 在使用好奇心驱动的代理人之后，只能在蒙特祖马的复仇上开发出超过人类平均表现的人工智能[1]。这是一款 Atari 游戏，具有特殊的机制，使得大多数机器学习方法很难学习。</p><h2 id="6ef5" class="mc md iq bd me mf mg dn mh mi mj dp mk lf ml mm mn lj mo mp mq ln mr ms mt mu bi translated">结论</h2><p id="1953" class="pw-post-body-paragraph kw kx iq ky b kz mv jr lb lc mw ju le lf mx lh li lj my ll lm ln mz lp lq lr ij bi ls translated"><span class="l lt lu lv bm lw lx ly lz ma di"> E </span>即使我们无法开发出能够实现诸如持续学习、人工意识和自我意识等范式的人工系统，但许多可以帮助我们实现这一目标的方法已经存在。</p><h2 id="e2a6" class="mc md iq bd me mf mg dn mh mi mj dp mk lf ml mm mn lj mo mp mq ln mr ms mt mu bi translated">参考</h2><p id="b2d1" class="pw-post-body-paragraph kw kx iq ky b kz mv jr lb lc mw ju le lf mx lh li lj my ll lm ln mz lp lq lr ij bi translated">[1]纽约州布尔达市、爱德华兹市、斯托尔基市和克里莫夫市(2018 年)。<strong class="ky ir">用随机网络蒸馏探索。</strong><em class="na">arXiv 预印本 arXiv:1810.12894 </em>。</p></div></div>    
</body>
</html>