<html>
<head>
<title>Random Forest In Python</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">Python 中的随机森林</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/random-forest-in-python-154d78aad254?source=collection_archive---------15-----------------------#2019-08-21">https://towardsdatascience.com/random-forest-in-python-154d78aad254?source=collection_archive---------15-----------------------#2019-08-21</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><figure class="is it gp gr iu iv gh gi paragraph-image"><div class="gh gi ir"><img src="../Images/d96de6e2f2dc6b5d84064a5ca75369f4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1280/0*3sDRsvZmCe-wBQHH"/></div><figcaption class="iy iz gj gh gi ja jb bd b be z dk"><a class="ae jc" href="https://commons.wikimedia.org/wiki/File:Randomforests_ensemble.gif" rel="noopener ugc nofollow" target="_blank">https://commons.wikimedia.org/wiki/File:Randomforests_ensemble.gif</a></figcaption></figure><div class=""/><p id="9de0" class="pw-post-body-paragraph kc kd jf ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz im bi translated">随机森林是最流行的机器学习算法之一。像决策树一样，随机森林可以应用于回归和分类问题。有些法律要求在发放贷款或保险时使用的模型所做出的决定是可以解释的。后者被称为模型可解释性，这也是我们看到随机森林模型在工业中被大量使用的原因之一。</p><h1 id="32b5" class="la lb jf bd lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx bi translated">算法</h1><p id="e99c" class="pw-post-body-paragraph kc kd jf ke b kf ly kh ki kj lz kl km kn ma kp kq kr mb kt ku kv mc kx ky kz im bi translated">随机森林算法通过聚合不同深度的多个决策树做出的预测来工作。林中的每个决策树都在称为引导数据集的数据集子集上进行训练。</p><figure class="me mf mg mh gt iv gh gi paragraph-image"><div class="gh gi md"><img src="../Images/c63e4c7b0744736f87e3a629534bf9ed.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*QqAlyTsX0HjdvBLM.png"/></div></figure><p id="4ff7" class="pw-post-body-paragraph kc kd jf ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz im bi translated">在构建森林中的每个决策树期间被遗漏的样本部分被称为出袋(OOB)数据集。我们将在后面看到，该模型将通过在森林中运行 OOB 数据集中的每个样本来自动评估其自身的性能。</p><figure class="me mf mg mh gt iv gh gi paragraph-image"><div class="gh gi md"><img src="../Images/64dee17bd1b7c5b4bd4d456a915b828e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*Vg56M8mYIeYK8n1F.png"/></div></figure><p id="e307" class="pw-post-body-paragraph kc kd jf ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz im bi translated">回想一下，在决定分割决策树的标准时，我们如何使用基尼指数或熵来测量每个特征产生的杂质。然而，在随机森林中，我们随机选择预定数量特征作为候选者。后者将导致包含相同特征(即与目标标签高度相关的特征)的树之间的更大差异。</p><figure class="me mf mg mh gt iv gh gi paragraph-image"><div class="gh gi md"><img src="../Images/a0278fd2b7aaded977c5f07086941a5a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*pf5AawTfs4YWyEym.png"/></div></figure><p id="f34d" class="pw-post-body-paragraph kc kd jf ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz im bi translated">当随机森林用于分类并呈现新样本时，通过取森林中每个单独决策树所做预测的<strong class="ke jg">多数</strong>来进行最终预测。在这种情况下，它被用于回归，并提供了一个新的样本，最终的预测是通过对森林中每个单独的决策树所做的预测取<strong class="ke jg">平均值</strong>来进行的。</p><figure class="me mf mg mh gt iv gh gi paragraph-image"><div class="gh gi md"><img src="../Images/231528f6b7eecccadb90b5281cea5f51.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*lIOUjg2Z6XWigUQL.png"/></div></figure><h1 id="3694" class="la lb jf bd lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx bi translated">Python 代码</h1><p id="e10b" class="pw-post-body-paragraph kc kd jf ke b kf ly kh ki kj lz kl km kn ma kp kq kr mb kt ku kv mc kx ky kz im bi translated">首先，我们导入以下库。</p><pre class="me mf mg mh gt mi mj mk ml aw mm bi"><span id="1239" class="mn lb jf mj b gy mo mp l mq mr">from sklearn.ensemble import RandomForestClassifier<br/>from sklearn.datasets import load_iris<br/>from sklearn.model_selection import train_test_split<br/>from sklearn.metrics import confusion_matrix<br/>import pandas as pd<br/>import numpy as np<br/>from sklearn.tree import export_graphviz<br/>from sklearn.externals.six import StringIO <br/>from IPython.display import Image <br/>from pydot import graph_from_dot_data</span></pre><p id="82ad" class="pw-post-body-paragraph kc kd jf ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz im bi translated">在接下来的部分，我们将尝试对不同种类的鸢尾进行分类。幸运的是，<code class="fe ms mt mu mj b">scikit-learn</code>库提供了一个包装器函数，用于将数据集导入我们的程序。</p><pre class="me mf mg mh gt mi mj mk ml aw mm bi"><span id="2f4b" class="mn lb jf mj b gy mo mp l mq mr">iris = load_iris()<br/>X = pd.DataFrame(iris.data, columns=iris.feature_names)<br/>y = pd.Categorical.from_codes(iris.target, iris.target_names)</span></pre><p id="b7b0" class="pw-post-body-paragraph kc kd jf ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz im bi translated"><code class="fe ms mt mu mj b">RandomForestClassifier</code>不能直接处理分类数据。因此，我们将每个物种编码为一个数字。</p><pre class="me mf mg mh gt mi mj mk ml aw mm bi"><span id="90f3" class="mn lb jf mj b gy mo mp l mq mr">y = pd.get_dummies(y)</span></pre><p id="9ce8" class="pw-post-body-paragraph kc kd jf ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz im bi translated">我们留出一部分数据用于测试。</p><pre class="me mf mg mh gt mi mj mk ml aw mm bi"><span id="4c59" class="mn lb jf mj b gy mo mp l mq mr">X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)</span></pre><p id="0f23" class="pw-post-body-paragraph kc kd jf ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz im bi translated">接下来，我们创建一个<code class="fe ms mt mu mj b">RandomForestClassifier</code>类的实例。</p><pre class="me mf mg mh gt mi mj mk ml aw mm bi"><span id="b84c" class="mn lb jf mj b gy mo mp l mq mr">rf = RandomForestClassifier(criterion='entropy', oob_score=True, random_state=1)</span></pre><p id="651d" class="pw-post-body-paragraph kc kd jf ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz im bi translated">为了增加趣味，这次我们将使用熵作为决策标准。这个过程与前一篇文章中使用的类似，除了我们使用下面的等式。</p><figure class="me mf mg mh gt iv gh gi paragraph-image"><div class="gh gi mv"><img src="../Images/00fcd6fddfbd74d8feeda6bc04d95eb3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1076/format:webp/1*kpEKnTp3I4fFsZGdI7BSeQ.png"/></div></figure><p id="d47e" class="pw-post-body-paragraph kc kd jf ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz im bi translated">节点本身的杂质等于左子节点中样本的分数加上右子节点中样本的分数。</p><figure class="me mf mg mh gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="mx my di mz bf na"><div class="gh gi mw"><img src="../Images/8bb402871b17e2be27b2b53d5595ca4d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*z1pz9VWBbVfXrwKTV1te_A.png"/></div></div></figure><p id="e87b" class="pw-post-body-paragraph kc kd jf ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz im bi translated">为了计算左叶的杂质，我们将已婚和未婚以及收入低于 5 万英镑的人口比例代入等式。</p><figure class="me mf mg mh gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="mx my di mz bf na"><div class="gh gi nb"><img src="../Images/bcbeccf737f5ba0ee822d4faa405939d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*1BR6rk_lYlU82QEuQmp2Pg.png"/></div></div></figure><p id="8af1" class="pw-post-body-paragraph kc kd jf ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz im bi translated">对于右叶的杂质，我们遵循同样的过程。</p><figure class="me mf mg mh gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="mx my di mz bf na"><div class="gh gi nc"><img src="../Images/2d98f3559d57e8bf0d06a1e01044bc02.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_kxuu6yJmQ83MMmaKYlIHw.png"/></div></div></figure><p id="cc05" class="pw-post-body-paragraph kc kd jf ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz im bi translated">信息增益(有熵)写如下。</p><figure class="me mf mg mh gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="mx my di mz bf na"><div class="gh gi nd"><img src="../Images/e2c895c43d3bdac3e2104be1c3af43c2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*T2SL9NIDLRL1Im07WiaNAw.png"/></div></div></figure><p id="06cb" class="pw-post-body-paragraph kc kd jf ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz im bi translated">然后对收入和性别重复这一过程。我们选择具有最大信息增益的分割。</p><figure class="me mf mg mh gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="mx my di mz bf na"><div class="gh gi ne"><img src="../Images/f534d2927079846fbe714374e3668a2c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*FDcwGLmAyo8TJmmdSO1eZQ.png"/></div></div></figure><p id="1538" class="pw-post-body-paragraph kc kd jf ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz im bi translated">接下来，我们训练我们的模型。</p><pre class="me mf mg mh gt mi mj mk ml aw mm bi"><span id="670b" class="mn lb jf mj b gy mo mp l mq mr">rf.fit(X_train, y_train)</span></pre><p id="d847" class="pw-post-body-paragraph kc kd jf ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz im bi translated">属性包含一个由组成森林的对象组成的数组。就像之前一样，我们可以运行下面的代码块来可视化一个给定的决策树。</p><pre class="me mf mg mh gt mi mj mk ml aw mm bi"><span id="fbb8" class="mn lb jf mj b gy mo mp l mq mr">dt = rf.estimators_[0]</span><span id="3a91" class="mn lb jf mj b gy nf mp l mq mr">dot_data = StringIO()</span><span id="39a2" class="mn lb jf mj b gy nf mp l mq mr">export_graphviz(dt, out_file=dot_data, feature_names=iris.feature_names)</span><span id="0dfc" class="mn lb jf mj b gy nf mp l mq mr">(graph, ) = graph_from_dot_data(dot_data.getvalue())</span><span id="0a9b" class="mn lb jf mj b gy nf mp l mq mr">Image(graph.create_png())</span></pre><figure class="me mf mg mh gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="mx my di mz bf na"><div class="gh gi ng"><img src="../Images/79574e66b1d55d056746b8fe7a363fcf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*I53L0SS5r8wryAiyO7-z9g.png"/></div></div></figure><p id="08ce" class="pw-post-body-paragraph kc kd jf ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz im bi translated">我们可以通过查看开箱得分来评估我们的随机森林模型的准确性。</p><pre class="me mf mg mh gt mi mj mk ml aw mm bi"><span id="a79e" class="mn lb jf mj b gy mo mp l mq mr">rf.oob_score_</span></pre><p id="f805" class="pw-post-body-paragraph kc kd jf ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz im bi translated">我们还可以检查我们的模型在测试集上的表现。考虑到这是一个分类问题，我们使用了混淆矩阵。</p><pre class="me mf mg mh gt mi mj mk ml aw mm bi"><span id="0b29" class="mn lb jf mj b gy mo mp l mq mr">y_pred = rf.predict(X_test)</span><span id="3f1b" class="mn lb jf mj b gy nf mp l mq mr">species = np.array(y_test).argmax(axis=1)<br/>predictions = np.array(y_pred).argmax(axis=1)</span><span id="81e4" class="mn lb jf mj b gy nf mp l mq mr">confusion_matrix(species, predictions)</span></pre><figure class="me mf mg mh gt iv gh gi paragraph-image"><div class="gh gi nh"><img src="../Images/436dc307dfb33b81257ecbaf94290046.png" data-original-src="https://miro.medium.com/v2/resize:fit:378/format:webp/1*icOqWE7eoa2M6Tct7dfo0w.png"/></div></figure></div></div>    
</body>
</html>