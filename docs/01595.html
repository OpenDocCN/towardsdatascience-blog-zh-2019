<html>
<head>
<title>Paper review: The power of choice in data-aware cluster scheduling</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">论文综述:数据感知集群调度中选择的力量</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/paper-review-the-power-of-choice-in-data-aware-cluster-scheduling-7292b13e10f5?source=collection_archive---------18-----------------------#2019-03-14">https://towardsdatascience.com/paper-review-the-power-of-choice-in-data-aware-cluster-scheduling-7292b13e10f5?source=collection_archive---------18-----------------------#2019-03-14</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><p id="2031" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">在本帖中，我们将介绍一个名为<a class="ae ko" href="https://www.usenix.org/system/files/conference/osdi14/osdi14-paper-venkataraman.pdf" rel="noopener ugc nofollow" target="_blank"> KMN </a>的调度器，该调度器旨在解决 Spark 或 MapReduce 等分布式计算框架中 I/O 密集型任务的调度问题。这个调度器不同于我们之前讨论的调度器，因为它强调数据感知调度，我们将在本文中讨论。</p><p id="729c" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu">背景</strong></p><p id="453c" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">在当今的批处理计算框架中，如 Hadoop 和 Spark，它们为每个构建成 DAG(有向无环图)依赖图的作业运行许多阶段和任务。如果我们假设这些任务中有很大一部分是 I/O 密集型的，那么调度器的任务就是尽量减少任务读取数据的时间。然而，在大型多租户集群中，具有数据局部性的完美节点可能经常不可用。</p><p id="d0ab" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">今天的数据应用程序和算法也可以选择只选择源数据的子集来逼近答案，而不是需要完整的数据集。</p><p id="1fe4" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">Spark &amp; MapReduce 框架通常有读取源数据的输入任务和将数据从输入任务转发到进一步处理的中间任务。对于任务调度器，它可以为输入任务优化的是尝试将任务放置在更靠近源数据的地方(位置)。对于中间任务，调度程序将进行优化，以最小化来自输入任务的网络传输。集群内网络带宽的一个主要瓶颈是跨机架链接饱和。作者模拟了使用过去的脸书跟踪实现网络争用和数据局部性的情况，并估计性能提高了 87.6%。</p><p id="c780" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu"> KMN 调度</strong></p><p id="2215" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">KMN 调度器在 Spark 中实现，它提供了一个应用程序接口，允许用户选择查询将选择的输入数据比率(1–100%)。</p><figure class="kq kr ks kt gt ku gh gi paragraph-image"><div class="gh gi kp"><img src="../Images/b363f26de418fd7a5b12e6e0cf6a30ca.png" data-original-src="https://miro.medium.com/v2/resize:fit:1146/0*-Qbxdc60AnHMLLvX"/></div></figure><p id="e338" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">KMN 调度程序将基于所有可用的 N 个输入和局部性选择，选择在具有内存局部性的 K 个可用块的随机样本上启动输入任务(一对一传输)。</p><figure class="kq kr ks kt gt ku gh gi paragraph-image"><div class="gh gi kx"><img src="../Images/2a71d9d81867ab050f8786da74fb5c39.png" data-original-src="https://miro.medium.com/v2/resize:fit:1144/0*4M4KdpZ7gsNxcwh0"/></div></figure><p id="04cb" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">对于进行多对一传输的中间任务，作者发现的主要见解是，避免跨机架网络带宽偏斜的关键是允许启动 K 个以上的输入任务(M 个任务)，因为这允许从下游任务传输数据的更多选择，从而可以避免偏斜。虽然找到任务的最佳机架位置是一个 NP-hard 问题，但作者建议，在他们的设置中，要么使用最适合小型任务的贪婪搜索，要么使用大型任务的循环调度的变体。</p><figure class="kq kr ks kt gt ku gh gi paragraph-image"><div role="button" tabindex="0" class="kz la di lb bf lc"><div class="gh gi ky"><img src="../Images/ec5587aa89961f8aadbb109401dc09cb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1256/0*mULzdlVNOkgsQQpD"/></div></div></figure><p id="35f4" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">这里一个重要的决定当然是我们应该启动多少额外的任务。过多的任务将导致更长的作业等待时间(也考虑到掉队者)，但是过少的额外任务可能会导致网络不平衡问题。找到平衡点可以让你最大化两者之间的平衡。这里的一个策略是，调度程序可以决定在启动下游任务之前，等待上游任务启动和完成的时间，因此当您遇到掉队的任务时，您不必等待样本中的所有任务都完成。</p><p id="7dc8" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu">思绪</strong></p><p id="ba52" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">当我与几家运营大型本地集群的公司聊天时，跨机架网络拥塞仍然是一个现实问题。虽然随着时间的推移，数据位置的重要性正在降低，这使得云中的<a class="ae ko" href="https://aws.amazon.com/blogs/aws/the-floodgates-are-open-increased-network-bandwidth-for-ec2-instances/" rel="noopener ugc nofollow" target="_blank">速度更快</a>，但我认为跨 AZ 和网络拥塞仍然是我看到的公司在云中经常遇到的问题。</p><p id="e4a9" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">当然，我们可以看到，在制定任务和分布决策时，所有分布式数据框架都开始意识到集群资源瓶颈。</p></div></div>    
</body>
</html>