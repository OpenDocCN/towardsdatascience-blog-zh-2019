<html>
<head>
<title>Data Engineering — How to Build a Gmail Data Pipeline on Apache Airflow</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">数据工程——如何在 Apache Airflow 上构建 Gmail 数据管道</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/data-engineering-how-to-build-a-gmail-data-pipeline-on-apache-airflow-ce2cfd1f9282?source=collection_archive---------12-----------------------#2019-07-08">https://towardsdatascience.com/data-engineering-how-to-build-a-gmail-data-pipeline-on-apache-airflow-ce2cfd1f9282?source=collection_archive---------12-----------------------#2019-07-08</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="bc40" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">黑掉你的 Gmail 收件箱。</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/15dde588c19e2468871d6deb436f8a1b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*AmNcNZJpgXUDQ4gMC0m1sA.png"/></div></div></figure><p id="1a32" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">我的读者朋友们，你们好。你今天过得怎么样？好吗？<br/>我将向你解释我是如何为我的公司制作了一个<br/> <strong class="kw iu"> Gmail 数据管道</strong>来让它变得更好。<br/>围拢过来。你不会想错过的。</p><p id="7223" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">那是什么？你说你为什么要在乎这个？<br/>嗯，考虑到谷歌通过整合大量技术(如 Google Drive、Google Photos、Google Calendar、Google Everything)在电子邮件服务提供商领域占据了主导地位，它也被许多评论网站评为顶级电子邮件服务提供商。这里有一个<a class="ae lq" href="https://www.toptenreviews.com/best-free-email-services" rel="noopener ugc nofollow" target="_blank">的例子。</a></p><p id="a54c" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">这也是大多数公司和临时用户的首选。我不会深究为什么 Gmail 是最好的。<br/>这里谁用雅虎邮箱？正是我的观点。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="lr ls l"/></div></figure><p id="8233" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">还不信服？<br/>只需看看谷歌趋势中电子邮件提供商之间的比较。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi lt"><img src="../Images/53456a4424c919bab9c122974d757758.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*fv8RFMExJY7PsaoLMPVx1g.png"/></div></div></figure><p id="17c8" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">结果不言自明。<br/>Github 上也有对 Gmail 相关代码的巨大支持。仅 Gmail 一项，Github 就有超过 16k 个知识库和 1.8 亿个代码。因此，任何你能想到的用 Gmail 实现的东西，可能已经有人做过类似的事情了。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi lt"><img src="../Images/35f97bcfd6603819362fd3c7bf2cd36d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*vmmwNrEvMVqcMa7CHPxCrg.png"/></div></div></figure><p id="a05d" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">话虽如此。你登上 Gmail 火车了吗？最好快点。在你告诉你的老板你能够从 Gmail 中自动提取、转换和加载数据到你的数据仓库后，他可能会立即大幅提升你到数据科学的领导位置。请给我捐点钱，我的银行账号是<br/> I-M-K-I-D-D-I-N-G，来自讽刺银行。让我们进入正题。</p><h1 id="faa1" class="lu lv it bd lw lx ly lz ma mb mc md me jz mf ka mg kc mh kd mi kf mj kg mk ml bi translated">Gmail 数据管道</h1><ul class=""><li id="4642" class="mm mn it kw b kx mo la mp ld mq lh mr ll ms lp mt mu mv mw bi translated">每天自动从您的 Gmail 收件箱提取、转换数据并将其加载到您的首选数据仓库中</li><li id="9d91" class="mm mn it kw b kx mx la my ld mz lh na ll nb lp mt mu mv mw bi translated">一个自动化系统，可以更好地将您的 Gmail 附件组织到您的数据库中。只保留你需要的，其余的都扔掉</li><li id="6bbc" class="mm mn it kw b kx mx la my ld mz lh na ll nb lp mt mu mv mw bi translated">易于使用，没有麻烦。停止下载附件并手动上传到数据仓库</li></ul><p id="5043" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">我将使用由 Google Cloud Composer 管理的 Apache Airflow 来执行管道。在我的公司里，我也使用 Google Bigquery 作为我的数据仓库。你可以使用任何你喜欢的 WMS 和数据仓库，无论如何 Google API 应该是可调用的。</p><p id="1c8c" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">我写过一篇如何从零到英雄操作阿帕奇气流的文章。<br/>你可以在这里找到:<a class="ae lq" rel="noopener" target="_blank" href="/data-engineering-basics-of-apache-airflow-build-your-first-pipeline-eefecb7f1bb9"> <em class="nc">阿帕奇气流基础</em> </a></p><h1 id="c24f" class="lu lv it bd lw lx ly lz ma mb mc md me jz mf ka mg kc mh kd mi kf mj kg mk ml bi translated">第一步。设置您的 Gmail 收件箱</h1><p id="d962" class="pw-post-body-paragraph ku kv it kw b kx mo ju kz la mp jx lc ld nd lf lg lh ne lj lk ll nf ln lo lp im bi translated">管道的第一步是设置要提取的标签收件箱。提取收件箱中的所有附件是可能的，但是请考虑一下。<br/>其中一些将是图片、文本文件、视频、pdf 等。我们只想要 csv 文件，因为数据通常是这样发送的。我们还想标准化每个管道的格式，这样我们就不会在未来遇到任何不一致的情况。<br/>例如，詹姆斯发给你的每周财务报告的数据和莫尼卡发给你的每周活动结果的数据是不同的。<br/>因此，我们需要通过添加标签来区分数据。</p><p id="d18f" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">进入您的 gmail 收件箱。在右上角，</p><p id="4971" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated"><strong class="kw iu">设置</strong> &gt; <strong class="kw iu">过滤器并屏蔽</strong> <strong class="kw iu">地址</strong> &gt; <strong class="kw iu">创建新过滤器</strong></p><p id="3b1c" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">设置标签的条件。例如，unknown@gmail.com 每周给我发一份产品性能报告。<br/>电子邮件的主题通常是“每周报告产品 A”</p><p id="2666" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">因此，我将从:unknown@gmail.com<br/><strong class="kw iu">主题</strong>:周报产品 A <br/>中设置<br/> <strong class="kw iu">，并勾选<strong class="kw iu">有附件</strong>框。</strong></p><p id="2ed9" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">选择<strong class="kw iu">创建过滤器</strong>，你会看到一堆复选框:<br/>重要的有</p><ul class=""><li id="c820" class="mm mn it kw b kx ky la lb ld ng lh nh ll ni lp mt mu mv mw bi translated"><strong class="kw iu">应用标签:选择一个标签</strong></li><li id="9501" class="mm mn it kw b kx mx la my ld mz lh na ll nb lp mt mu mv mw bi translated"><strong class="kw iu">还将过滤器应用于匹配对话</strong></li></ul><p id="2cb7" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">务必选中这两个框，并为这批特定的电子邮件创建一个新的标签名称。我通常也会勾选“跳过收件箱”,这样电子邮件就会被直接发送到标有“收件箱”的地方。让我们为我们正在使用的示例创建一个标签收件箱，命名为“<strong class="kw iu">每周报告产品收件箱</strong>”。</p><p id="c6bb" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">您现在应该会看到所有的电子邮件，包括关于产品 A 的周报告的现有邮件，这些邮件在<br/> <strong class="kw iu">周报告产品 A 收件箱</strong>中包含附件。<br/>祝贺您，您已经完成了这个流程中最简单的一步。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nj ls l"/></div></figure></div><div class="ab cl nk nl hx nm" role="separator"><span class="nn bw bk no np nq"/><span class="nn bw bk no np nq"/><span class="nn bw bk no np"/></div><div class="im in io ip iq"><h1 id="ba43" class="lu lv it bd lw lx nr lz ma mb ns md me jz nt ka mg kc nu kd mi kf nv kg mk ml bi translated">第二步。在 Apache Airflow 中创建 DAG 文件</h1><p id="4015" class="pw-post-body-paragraph ku kv it kw b kx mo ju kz la mp jx lc ld nd lf lg lh ne lj lk ll nf ln lo lp im bi translated">如果你现在迷失了，给自己两个耳光，集中注意力。我们即将进入本质，也就是代码。我假设您知道如何在 Apache Airflow 中创建 Dag 和操作符，如果您不知道，请节省一些时间，阅读我的文章<a class="ae lq" rel="noopener" target="_blank" href="/data-engineering-basics-of-apache-airflow-build-your-first-pipeline-eefecb7f1bb9">中关于如何创建 Dag 和操作符的内容。这样一来，打开你最喜欢的文本编辑器，开始编码。</a></p><h1 id="cdf7" class="lu lv it bd lw lx ly lz ma mb mc md me jz mf ka mg kc mh kd mi kf mj kg mk ml bi translated">进口</h1><pre class="kj kk kl km gt nw nx ny nz aw oa bi"><span id="ffda" class="ob lv it nx b gy oc od l oe of"># airflow related<br/>from airflow import models<br/>from airflow import DAG</span><span id="e9c6" class="ob lv it nx b gy og od l oe of"># other packages<br/>from datetime import datetime, timedelta</span></pre><h1 id="2d69" class="lu lv it bd lw lx ly lz ma mb mc md me jz mf ka mg kc mh kd mi kf mj kg mk ml bi translated">设置默认参数</h1><pre class="kj kk kl km gt nw nx ny nz aw oa bi"><span id="f0e0" class="ob lv it nx b gy oc od l oe of">default_dag_args = {<br/>    # Setting start date as yesterday starts the DAG immediately       when it is<br/>    # detected in the Cloud Storage bucket.<br/>    # set your start_date : airflow will run previous dags if dags #since startdate has not run<br/>#notify email is a python function that sends notification email upon failure    <br/>    'start_date': datetime(2019, 7, 1, 10),<br/>    'email_on_failure': True,<br/>    'email_on_retry': True,<br/>    'project_id' : 'your_project_name',<br/>    'retries': 1,<br/>    'on_failure_callback': notify_email,<br/>    'retry_delay': timedelta(minutes=5),<br/>}</span><span id="e8b8" class="ob lv it nx b gy og od l oe of">with models.DAG(<br/>    dag_id='your_dag_name',<br/>    # Continue to run DAG once per day<br/>    schedule_interval = timedelta(weeks=1),<br/>    catchup = True,<br/>    default_args=default_dag_args) as dag:</span></pre><p id="2bbb" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">我们将 DAG 设置为每周一上午 10 点运行<strong class="kw iu">。</strong>假设每周报告将在每周一上午 10 点前发送。如果在上午 10 点以后收到电子邮件，将不会有任何数据加载到数据仓库中。请记住，当你设置这个的时候，你总是想要设置一个你<strong class="kw iu">确定</strong>数据会出现在收件箱的时间。我选择每周一次的报告也没有特别的原因。如果您正在处理的是每日报告，只需将 schedule_interval 更改为 timedelta(days=1)。</p><h1 id="ddfb" class="lu lv it bd lw lx ly lz ma mb mc md me jz mf ka mg kc mh kd mi kf mj kg mk ml bi translated">定义我们的 DAG、任务和运算符</h1><p id="a2dc" class="pw-post-body-paragraph ku kv it kw b kx mo ju kz la mp jx lc ld nd lf lg lh ne lj lk ll nf ln lo lp im bi translated">让我们设计要在这个特定 DAG 中运行的任务。<br/>我的做法是:</p><ol class=""><li id="2c54" class="mm mn it kw b kx ky la lb ld ng lh nh ll ni lp oh mu mv mw bi translated">浏览 Gmail 收件箱并将所有附件下载到 GCS</li><li id="e08c" class="mm mn it kw b kx mx la my ld mz lh na ll nb lp oh mu mv mw bi translated">检查是否有要加载的附件</li><li id="b9a1" class="mm mn it kw b kx mx la my ld mz lh na ll nb lp oh mu mv mw bi translated">将所有附件加载到 Google Bigquery</li><li id="fe30" class="mm mn it kw b kx mx la my ld mz lh na ll nb lp oh mu mv mw bi translated">检查 Google Bigquery 中的任何重复加载</li><li id="ce11" class="mm mn it kw b kx mx la my ld mz lh na ll nb lp oh mu mv mw bi translated">写日志</li><li id="35e1" class="mm mn it kw b kx mx la my ld mz lh na ll nb lp oh mu mv mw bi translated">发送电子邮件</li></ol><p id="eb74" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">让我们为操作员编写执行这些任务的代码。<br/>不用担心。我将和你一起浏览所有重要的操作符。<br/>在文本编辑器中打开第二个窗口，开始<strong class="kw iu">编写操作符。</strong></p><h1 id="2739" class="lu lv it bd lw lx ly lz ma mb mc md me jz mf ka mg kc mh kd mi kf mj kg mk ml bi translated"><strong class="ak">操作员:给 GCS 发邮件</strong></h1><h1 id="7cb4" class="lu lv it bd lw lx ly lz ma mb mc md me jz mf ka mg kc mh kd mi kf mj kg mk ml bi translated">进口</h1><pre class="kj kk kl km gt nw nx ny nz aw oa bi"><span id="a80c" class="ob lv it nx b gy oc od l oe of"># airflow related<br/>from airflow.models import BaseOperator<br/>from airflow.utils.decorators import apply_defaults</span><span id="d716" class="ob lv it nx b gy og od l oe of"># other packages<br/>from datetime import datetime, timedelta<br/>from os import environ<br/>import csv<br/>import getpass, imaplib</span></pre><h1 id="3934" class="lu lv it bd lw lx ly lz ma mb mc md me jz mf ka mg kc mh kd mi kf mj kg mk ml bi translated">设计</h1><pre class="kj kk kl km gt nw nx ny nz aw oa bi"><span id="2186" class="ob lv it nx b gy oc od l oe of">class ExtractAttachment(BaseOperator):<br/>    """<br/>    Extract data from Gmail into GCS<br/>    """</span><span id="c129" class="ob lv it nx b gy og od l oe of"><a class="ae lq" href="http://twitter.com/apply_defaults" rel="noopener ugc nofollow" target="_blank">@apply_defaults</a><br/>def __init__(<br/>        self,<br/>        inbox_name,<br/>        *args, **kwargs):</span><span id="0953" class="ob lv it nx b gy og od l oe of">super(DataSourceToCsv, self).__init__(*args, **kwargs)<br/>        self.inbox_name = inbox_name<br/>        self.file_path = #filepath_to_save_CSV</span><span id="2329" class="ob lv it nx b gy og od l oe of">def __extract_email_attachment(self, execution_date):<br/>        userName = 'your_user_name'<br/>        passwd = 'your_password'</span><span id="bb20" class="ob lv it nx b gy og od l oe of">        imapSession = imaplib.IMAP4_SSL('imap.gmail.com')<br/>        typ, accountDetails = imapSession.login(userName, passwd)<br/>        if typ != 'OK':<br/>            print('Not able to sign in!')</span><span id="eaed" class="ob lv it nx b gy og od l oe of">        imapSession.select(self.inbox_name)<br/>        typ, data = imapSession.search(None, 'Unseen')<br/>        if typ != 'OK':<br/>            print('Error searching Inbox.')</span><span id="fff0" class="ob lv it nx b gy og od l oe of"># Iterating over all emails<br/>        for msgId in data[0].split():<br/>            typ, messageParts = imapSession.fetch(msgId, '(RFC822)')<br/>            if typ != 'OK':<br/>                print('Error fetching mail.')</span><span id="ab4e" class="ob lv it nx b gy og od l oe of">            raw_email = messageParts[0][1]<br/>            raw_email_string = raw_email.decode('utf-8')<br/>            email_message =  email.message_from_string(raw_email_string)<br/>            for part in email_message.walk():<br/>                if part.get_content_maintype() == 'multipart':<br/>                    # print part.as_string()<br/>                    continue<br/>                if part.get('Content-Disposition') is None:<br/>                    # print part.as_string()<br/>                    continue<br/>                fileName = part.get_filename()</span><span id="2dfe" class="ob lv it nx b gy og od l oe of">            if bool(fileName):<br/>                    filePath = self.file_path + fileName<br/>                    print(filePath)<br/>                    if not os.path.isfile(filePath) :<br/>                        print(fileName)<br/>                        fp = open(filePath, 'wb')<br/>                        fp.write(part.get_payload(decode=True))<br/>                        fp.close()<br/>            imapSession.uid('STORE',msgId, '+FLAGS', '\SEEN')<br/>        imapSession.close()<br/>        imapSession.logout()</span><span id="f9e0" class="ob lv it nx b gy og od l oe of">def execute(self, context):<br/>execution_date = (context.get('execution_date')<br/>self.__extract_email_attachment(execution_date)</span></pre><p id="8891" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">在这段代码中，我们:</p><ol class=""><li id="e8ee" class="mm mn it kw b kx ky la lb ld ng lh nh ll ni lp oh mu mv mw bi translated">定义数据所在的 Gmail 收件箱名称</li><li id="8db6" class="mm mn it kw b kx mx la my ld mz lh na ll nb lp oh mu mv mw bi translated">设置我们的 Gmail 用户名和密码(是的，不幸的是，任何查看代码的人都会看到)</li><li id="d4a5" class="mm mn it kw b kx mx la my ld mz lh na ll nb lp oh mu mv mw bi translated">设置 IMAP 会话，使用凭证登录</li><li id="ff1e" class="mm mn it kw b kx mx la my ld mz lh na ll nb lp oh mu mv mw bi translated">搜索名为<strong class="kw iu"> inbox_name </strong>参数的 Gmail 标签收件箱</li><li id="317b" class="mm mn it kw b kx mx la my ld mz lh na ll nb lp oh mu mv mw bi translated">只选择<strong class="kw iu">不可见的</strong>邮件，这很重要，因为我们不想两次加载相同的数据</li><li id="0c1f" class="mm mn it kw b kx mx la my ld mz lh na ll nb lp oh mu mv mw bi translated">提取这些邮件的附件并保存在由<strong class="kw iu"> file_path </strong>参数定义的文件路径中</li><li id="0359" class="mm mn it kw b kx mx la my ld mz lh na ll nb lp oh mu mv mw bi translated">提取后，将电子邮件标记为已读，这样下次就不会被提取了</li><li id="b45c" class="mm mn it kw b kx mx la my ld mz lh na ll nb lp oh mu mv mw bi translated">注销我们的 IMAP 会话</li></ol><p id="c40e" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">请记住，操作员只考虑那些<strong class="kw iu">未看到/未读的</strong>电子邮件。因此，如果您不小心点击了该邮件，它将自动标记为<strong class="kw iu">已读</strong>，完全忽略来自管道的邮件。如果你不希望这种情况发生，记得在阅读完邮件后，从 Gmail 用户界面将它标记为<strong class="kw iu">未看/未读</strong>。</p><p id="ec19" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">以下是操作符本身的完整代码:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="oi ls l"/></div></figure><p id="c136" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">这是完成的第一个操作符。继续前进。</p><h1 id="178b" class="lu lv it bd lw lx ly lz ma mb mc md me jz mf ka mg kc mh kd mi kf mj kg mk ml bi translated">操作员:短路操作员</h1><p id="d016" class="pw-post-body-paragraph ku kv it kw b kx mo ju kz la mp jx lc ld nd lf lg lh ne lj lk ll nf ln lo lp im bi translated">由于电子邮件可能会不可避免地丢失，DAG 有时会返回一个错误，因为没有数据加载到 BQ 中。对于这一部分，我们使用 ShortCircuit 操作符检查是否有任何文件要加载到 Google Bigquery 中。如果没有要加载的文件，则跳过该操作符的所有下游任务，DAG 成功完成。否则，DAG 照常进行。没有必要为此编写自定义操作符，我们将使用 Airflow 提供的默认操作符。跳过任务时，气流将显示粉色指示器。下面是一个例子。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oj"><img src="../Images/0c5b02d691d6f8f09ab29ef8079f5039.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*xYk7RBTU8sn0TPJE-TnBEw.png"/></div></div></figure><h1 id="070b" class="lu lv it bd lw lx ly lz ma mb mc md me jz mf ka mg kc mh kd mi kf mj kg mk ml bi translated">操作员:GCS 到 Google Bigquery</h1><h1 id="d13e" class="lu lv it bd lw lx ly lz ma mb mc md me jz mf ka mg kc mh kd mi kf mj kg mk ml bi translated">进口</h1><pre class="kj kk kl km gt nw nx ny nz aw oa bi"><span id="a102" class="ob lv it nx b gy oc od l oe of"># airflow related<br/>from airflow.models import BaseOperator<br/>from airflow.utils.decorators import apply_defaults</span><span id="e00b" class="ob lv it nx b gy og od l oe of"># other packages<br/>from datetime import datetime, timedelta<br/>from os import environ<br/>import csv<br/>from google.cloud import bigquery<br/>import pandas as pd<br/>import os</span></pre><h1 id="328a" class="lu lv it bd lw lx ly lz ma mb mc md me jz mf ka mg kc mh kd mi kf mj kg mk ml bi translated">设计</h1><pre class="kj kk kl km gt nw nx ny nz aw oa bi"><span id="d7b3" class="ob lv it nx b gy oc od l oe of">class StorageToBigQuery(BaseOperator):<br/>    """<br/>    Extract data from Google Cloud Storage to Google Bigquery<br/>    """</span><span id="83ac" class="ob lv it nx b gy og od l oe of"><a class="ae lq" href="http://twitter.com/apply_defaults" rel="noopener ugc nofollow" target="_blank">@apply_defaults</a><br/>def __init__(<br/>            self,<br/>            dataset_name,<br/>            bigquery_table_name,<br/>            write_mode,<br/>            *args, **kwargs):</span><span id="1af5" class="ob lv it nx b gy og od l oe of">super(StorageToBigQuery, self).__init__(*args, **kwargs)<br/>        self.dataset_name =  dataset_name<br/>        self.bigquery_table_name =  bigquery_table_name<br/>        self.write_mode = write_mode<br/>        self.local_path = 'File Path of CSV'</span><span id="df06" class="ob lv it nx b gy og od l oe of">def __StorageToBigQuery(self, execution_date):<br/>for file in os.listdir(self.local_path):<br/>        filename = self.local_path + file<br/>        df=pd.read_csv(filename,error_bad_lines=False)<br/>        #Using pandas to clean data<br/>        df.to_csv(self.local_path + 'cleaned_' + file,index=False)</span><span id="e929" class="ob lv it nx b gy og od l oe of">        file_path_to_load = self.local_path + 'cleaned_' + file<br/>            logging.info("FILE PATH TO LOAD : %s" % file_path_to_load)<br/>            print('loading_file_to_BQ')<br/>            client = bigquery.Client()<br/>            dataset_ref = client.dataset(self.dataset_name)<br/>            job_config = bigquery.LoadJobConfig()<br/>            job_config.autodetect = False<br/>            if(self.write_mode == 'overwrite'):<br/>                job_config.write_disposition = 'WRITE_TRUNCATE'<br/>            elif(self.write_mode == 'empty'):<br/>                job_config.write_disposition = 'WRITE_EMPTY'<br/>            else:<br/>                job_config.write_disposition = 'WRITE_APPEND'<br/>            job_config.skip_leading_rows = 1<br/>            job_config.field_delimiter = ','<br/>            job_config.quote = ''<br/>            job_config.allow_quoted_newlines = True<br/>            with open( file_path_to_load, 'rb' ) as source_file:<br/>                load_job = client.load_table_from_file(<br/>                        source_file,<br/>                        dataset_ref.table(self.bigquery_table_name),<br/>                        job_config=job_config)</span><span id="4a43" class="ob lv it nx b gy og od l oe of">        assert load_job.job_type == 'load'<br/>            load_job.result()<br/>            assert load_job.state == 'DONE'</span><span id="63f4" class="ob lv it nx b gy og od l oe of">def execute(self, context):<br/>execution_date = (context.get('execution_date')<br/>self.__StorageToBigQuery(execution_date)</span></pre><p id="3911" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated"><strong class="kw iu">重要提示</strong>:由于我默认使用 Google Cloud Composer，所以在调用 Google Bigquery API 时，我不需要通过任何身份验证。如果你正在使用香草气流，请在这里找到如何调用谷歌大查询 API<a class="ae lq" href="https://cloud.google.com/bigquery/docs/reference/libraries#client-libraries-usage-python" rel="noopener ugc nofollow" target="_blank"/>。在加载数据之前，您还需要在 Google BQ 中创建表格。</p><p id="4177" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">在这段代码中，我们:</p><ol class=""><li id="f4b1" class="mm mn it kw b kx ky la lb ld ng lh nh ll ni lp oh mu mv mw bi translated">在 BQ 中定义要加载到的数据集和表格</li><li id="0d75" class="mm mn it kw b kx mx la my ld mz lh na ll nb lp oh mu mv mw bi translated">浏览<strong class="kw iu"> local_path </strong>目录下的所有文件</li><li id="ab3d" class="mm mn it kw b kx mx la my ld mz lh na ll nb lp oh mu mv mw bi translated">用熊猫做一些清洁工作</li><li id="4eec" class="mm mn it kw b kx mx la my ld mz lh na ll nb lp oh mu mv mw bi translated">使用由<strong class="kw iu"> write_mode </strong>参数设置的写入模式，在清理的文件上启动到 BQ 的加载作业</li></ol><p id="fa62" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">用熊猫清洁是为了避免任何人为错误。但是，您可以在该部分进行某种转换，然后加载该文件。我还使用它来添加一个名为<strong class="kw iu">气流执行日期</strong>的列，将 DAG 的执行日期作为输入。这对以后删除重复项很有用。<br/>以下是操作员的完整代码:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="oi ls l"/></div></figure><p id="27fc" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">又一个倒下了，坚持住。</p><h1 id="6640" class="lu lv it bd lw lx ly lz ma mb mc md me jz mf ka mg kc mh kd mi kf mj kg mk ml bi translated">运算符:检查 Bigquery 中的重复项</h1><p id="b7e2" class="pw-post-body-paragraph ku kv it kw b kx mo ju kz la mp jx lc ld nd lf lg lh ne lj lk ll nf ln lo lp im bi translated">每当我们将数据加载(追加)到 BQ 中时，<br/>数据中可能会有重复。<br/>这可能是由以下几个原因造成的:</p><ul class=""><li id="3dcc" class="mm mn it kw b kx ky la lb ld ng lh nh ll ni lp mt mu mv mw bi translated">数据组有人启动了 DAG 两次</li><li id="317e" class="mm mn it kw b kx mx la my ld mz lh na ll nb lp mt mu mv mw bi translated">数据中有重复项(可以通过清除上一个运算符来删除)</li><li id="8607" class="mm mn it kw b kx mx la my ld mz lh na ll nb lp mt mu mv mw bi translated">有人中途停止了 DAG 并重新启动了它</li><li id="518b" class="mm mn it kw b kx mx la my ld mz lh na ll nb lp mt mu mv mw bi translated">代码中的缺陷</li><li id="3b95" class="mm mn it kw b kx mx la my ld mz lh na ll nb lp mt mu mv mw bi translated">许多其他原因</li></ul><p id="1c99" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">因此，为了确保万无一失，我们总是运行重复检查，以确保我们只加载数据一次。我们不想报告 2 倍的收入，只是为了发现这是重复加载，不是吗？</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="ok ls l"/></div></figure><h1 id="2c27" class="lu lv it bd lw lx ly lz ma mb mc md me jz mf ka mg kc mh kd mi kf mj kg mk ml bi translated">进口</h1><pre class="kj kk kl km gt nw nx ny nz aw oa bi"><span id="a98d" class="ob lv it nx b gy oc od l oe of"># airflow related<br/>from airflow.models import BaseOperator<br/>from airflow.utils.decorators import apply_defaults</span><span id="da10" class="ob lv it nx b gy og od l oe of"># other packages<br/>from datetime import datetime, timedelta<br/>from os import environ<br/>import csv<br/>from google.cloud import bigquery<br/>import pandas as pd<br/>import os</span></pre><h1 id="6da7" class="lu lv it bd lw lx ly lz ma mb mc md me jz mf ka mg kc mh kd mi kf mj kg mk ml bi translated">设计</h1><pre class="kj kk kl km gt nw nx ny nz aw oa bi"><span id="62e0" class="ob lv it nx b gy oc od l oe of">class CheckBQDuplication(BaseOperator):<br/>    """<br/>    Check if a specific table in BigQuery contains duplicated data after the load<br/>    """</span><span id="0946" class="ob lv it nx b gy og od l oe of"><a class="ae lq" href="http://twitter.com/apply_defaults" rel="noopener ugc nofollow" target="_blank">@apply_defaults</a><br/>def __init__(<br/>        self,<br/>        dataset_name,<br/>        bigquery_table_name,<br/>        bigquery_table_key,<br/>        date_column,<br/>        *args, **kwargs):</span><span id="7955" class="ob lv it nx b gy og od l oe of">super(CheckBQDuplication, self).__init__(*args, **kwargs)<br/>        self.dataset_name = dataset_name<br/>        self.bigquery_table_name = bigquery_table_name<br/>        self.bigquery_table_key = bigquery_table_key<br/>        self.date_column =  date_column<br/>        self.file_path = 'File Path of CSV'</span><span id="6552" class="ob lv it nx b gy og od l oe of">def __check_BQ_duplication(self, execution_date):<br/># Check if the table contains duplicated data</span><span id="852a" class="ob lv it nx b gy og od l oe of">        check_query = """<br/>            SELECT MAX(count) FROM (<br/>            SELECT $ID_COLUMN, COUNT(*) as count<br/>            FROM `$DATASET_NAME.$BIGQUERY_TABLE_NAME`<br/>            WHERE CAST($DATE_COLUMN AS DATE) = $EXECUTION_DATE<br/>            GROUP BY $ID_COLUMN)<br/>            """<br/>        check_query = check_query \<br/>          .replace("$ID_COLUMN", self.bigquery_table_key)\<br/>          .replace("$DATASET_NAME", self.dataset_name) \<br/>          .replace("$BIGQUERY_TABLE_NAME",self.bigquery_table_name)\<br/>          .replace("$EXECUTION_DATE", \<br/>           "'" + execution_date + "'") \<br/>          .replace("$DATE_COLUMN", self.date_column)<br/>        logging.info("CHECK QUERY : %s" % check_query)</span><span id="0f3a" class="ob lv it nx b gy og od l oe of">check_query_job = bigquery.Client().query(query = check_query)<br/>        logging.info("job state : %s at %s" % \(check_query_job.state, check_query_job.ended))</span><span id="0c05" class="ob lv it nx b gy og od l oe of">check_query_result = 0<br/>        for row in check_query_job:<br/>            check_query_result = int(row[0])<br/>            break<br/>    <br/>        if check_query_result &gt; 1:<br/>            logging.error('(ERROR): DUPLICATION EXISTS IN TABLE ' + self.bigquery_table_name)<br/> <br/>       # Duplication exists, proceed to delete the data in Big Query</span><span id="40ce" class="ob lv it nx b gy og od l oe of">            delete_query = """<br/>                DELETE FROM `$DATASET_NAME.$BIGQUERY_TABLE_NAME`<br/>                WHERE CAST($DATE_COLUMN AS DATE) = $EXECUTION_DATE<br/>                """<br/>            delete_query = delete_query \<br/>         .replace("$DATASET_NAME",self.dataset_name) \<br/>         .replace("$BIGQUERY_TABLE_NAME",self.bigquery_table_name)\<br/>         .replace("$EXECUTION_DATE", "'" +execution_date + "'")\<br/>         .replace("$DATE_COLUMN", self.date_column)<br/>            logging.info("DELETE QUERY : %s" % delete_query)</span><span id="a9b8" class="ob lv it nx b gy og od l oe of">delete_query_job = bigquery.Client().query(query=delete_query)<br/>            logging.info("job state : %s at %s" % (delete_query_job.state, delete_query_job.ended))</span><span id="7254" class="ob lv it nx b gy og od l oe of"># Reload the file from Cloud Storage<br/>            print('going through the folder')<br/>            for file in os.listdir(self.local_path):<br/>                file_path_to_load = self.local_path + 'cleaned_' + file</span><span id="aeb1" class="ob lv it nx b gy og od l oe of">logging.info("FULL FILE PATH TO LOAD : %s" % file_path_to_load)</span><span id="87fd" class="ob lv it nx b gy og od l oe of">            client = bigquery.Client()<br/>                dataset_ref = client.dataset(self.dataset_name)<br/>                job_config = bigquery.LoadJobConfig()<br/>                job_config.autodetect = False<br/>                job_config.write_disposition = 'WRITE_APPEND'<br/>                job_config.skip_leading_rows = 1<br/>                job_config.field_delimiter = ','<br/>                job_config.quote = ''<br/>                job_config.allow_quoted_newlines = True<br/>                with open( file_path_to_load, 'rb' ) as source_file:<br/>                    load_job = client.load_table_from_file(<br/>                       source_file,<br/>                       dataset_ref.table(self.bigquery_table_name),<br/>                       job_config=job_config)</span><span id="a716" class="ob lv it nx b gy og od l oe of">                assert load_job.job_type == 'load'<br/>                load_job.result()<br/>                assert load_job.state == 'DONE'</span><span id="63d5" class="ob lv it nx b gy og od l oe of">def execute(self, context):<br/>execution_date = (context.get('execution_date')<br/>self.__check_BQ_duplication(execution_date)</span></pre><p id="6836" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">在这段代码中，我们:</p><ol class=""><li id="5b72" class="mm mn it kw b kx ky la lb ld ng lh nh ll ni lp oh mu mv mw bi translated">定义查询以检查重复并在 BQ 中执行它</li><li id="c8bf" class="mm mn it kw b kx mx la my ld mz lh na ll nb lp oh mu mv mw bi translated">如有重复，删除 BQ 中所有数据，其中<br/><strong class="kw iu">date _ column</strong>=<strong class="kw iu">execution _ date</strong></li><li id="6e7f" class="mm mn it kw b kx mx la my ld mz lh na ll nb lp oh mu mv mw bi translated">从<strong class="kw iu"> file_path </strong>参数中重新加载所有<strong class="kw iu">清理过的</strong>文件</li></ol><p id="6042" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">考虑到机制，我们需要在表中有一个日期列。如果默认情况下没有，我们必须显式地创建一个。这就是为什么我在前一个操作符中创建了 Airflow 执行日期列。<br/>再一次，这里是操作员的完整代码:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="oi ls l"/></div></figure><p id="57e1" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">将您编写的所有操作符保存在 Airflow 可访问的文件夹中。对我来说，它是 DAG 文件夹中一个名为 Operators 的文件夹。最后两个操作符只是通知您作业的状态，并在 BQ 中写入日志。在 writing logs 操作符中还有一个部分删除了<strong class="kw iu"> file_path </strong>目录中的文件。我将不会进入最后 2 个运营商，因为我们已经可以实现我们想要的，直到这个阶段。我会写一篇写日志和发邮件的文章，因为它适合我所有的日志。这篇文章已经写了太久了。和我在一起。</p></div><div class="ab cl nk nl hx nm" role="separator"><span class="nn bw bk no np nq"/><span class="nn bw bk no np nq"/><span class="nn bw bk no np"/></div><div class="im in io ip iq"><h1 id="af28" class="lu lv it bd lw lx nr lz ma mb ns md me jz nt ka mg kc nu kd mi kf nv kg mk ml bi translated">第三步。最终确定 DAG</h1><p id="ba24" class="pw-post-body-paragraph ku kv it kw b kx mo ju kz la mp jx lc ld nd lf lg lh ne lj lk ll nf ln lo lp im bi translated">完成所有操作后，剩下的就是将它们调用到我们的 DAG 文件中。<br/>让我们回到 DAG 文件中。</p><h1 id="9c1c" class="lu lv it bd lw lx ly lz ma mb mc md me jz mf ka mg kc mh kd mi kf mj kg mk ml bi translated">导入运算符</h1><pre class="kj kk kl km gt nw nx ny nz aw oa bi"><span id="2cb6" class="ob lv it nx b gy oc od l oe of"># import operators from the 'operators' file<br/>from operators import GmailToGCS<br/>from operators import StorageToBQ<br/>from operators import CheckDupBQ<br/>from operators import WriteLogs<br/>from operators import SendEmail<br/>from airflow.operators import ShortCircuitOperator</span></pre><h1 id="3f85" class="lu lv it bd lw lx ly lz ma mb mc md me jz mf ka mg kc mh kd mi kf mj kg mk ml bi translated">呼叫短路接线员</h1><pre class="kj kk kl km gt nw nx ny nz aw oa bi"><span id="6f78" class="ob lv it nx b gy oc od l oe of">def checkforfile():<br/>    file_path = 'File Path to Load'<br/>    if os.listdir(file_path):<br/>        return True<br/>    else:    <br/>        return False</span><span id="696d" class="ob lv it nx b gy og od l oe of">checkforfile = ShortCircuitOperator(<br/>        task_id='checkforfile',<br/>        provide_context=False,<br/>        python_callable=checkforfile)</span></pre><p id="6899" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">ShortCircuit 操作符通过传递返回真或假输出的 python 函数来工作。如果输出为真，DAG 照常进行。否则，DAG 会跳过所有下游任务并继续完成。因此，我们编写一个函数来检查<strong class="kw iu">文件路径</strong>目录中的文件，如果文件存在，则返回 True。</p><p id="42e6" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">DAG 的完整代码:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="oi ls l"/></div></figure><p id="c8a1" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">注意，要传递给操作符的所有参数都是在 DAG 的顶部定义的。这样做是为了让 DAG 可以用作 Gmail 收件箱中其他<strong class="kw iu">标签</strong>的模板。这也更容易向你的同事解释，他们可能想使用它。</p></div><div class="ab cl nk nl hx nm" role="separator"><span class="nn bw bk no np nq"/><span class="nn bw bk no np nq"/><span class="nn bw bk no np"/></div><div class="im in io ip iq"><h1 id="0dc5" class="lu lv it bd lw lx nr lz ma mb ns md me jz nt ka mg kc nu kd mi kf nv kg mk ml bi translated">第四步。孩子身上的弹性</h1><p id="ec0c" class="pw-post-body-paragraph ku kv it kw b kx mo ju kz la mp jx lc ld nd lf lg lh ne lj lk ll nf ln lo lp im bi translated">放松点。没有更多的代码要读。<br/>将 DAG 文件弹出到 Airflow DAG 文件夹中，就可以了。<br/> <strong class="kw iu">恭喜</strong>，您已经成功构建了您的个人<br/> Gmail 数据管道。如何处理这些数据现在完全取决于你。你可以自动化仪表盘来显示报告，制作显示趋势的网页，甚至向你的机器学习模型提供数据。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="ol ls l"/></div></figure><p id="6945" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">所以，现在去吧，我的数据从业者伙伴们。传播消息。给自己一个鼓励..继续做下一个项目。至少这是我接下来要做的。</p><p id="e8d2" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">最后，让我引用一段话:</p><blockquote class="om on oo"><p id="2378" class="ku kv nc kw b kx ky ju kz la lb jx lc op le lf lg oq li lj lk or lm ln lo lp im bi translated">你可以有没有信息的数据，但你不能有没有数据的信息。—丹尼尔·凯斯·莫兰</p></blockquote></div><div class="ab cl nk nl hx nm" role="separator"><span class="nn bw bk no np nq"/><span class="nn bw bk no np nq"/><span class="nn bw bk no np"/></div><div class="im in io ip iq"><h2 id="8473" class="ob lv it bd lw os ot dn ma ou ov dp me ld ow ox mg lh oy oz mi ll pa pb mk pc bi translated">订阅我的时事通讯，保持联系。</h2><p id="2916" class="pw-post-body-paragraph ku kv it kw b kx mo ju kz la mp jx lc ld nd lf lg lh ne lj lk ll nf ln lo lp im bi translated"><strong class="kw iu"> <em class="nc">感谢</em> </strong> <em class="nc">的阅读！如果你想与我取得联系，请随时通过 nickmydata@gmail.com 或我的</em> <a class="ae lq" href="https://www.linkedin.com/in/nickefy/" rel="noopener ugc nofollow" target="_blank"> <em class="nc"> linkedIn 个人资料</em> </a> <em class="nc">联系我。也可以在我的</em><a class="ae lq" href="https://github.com/nickefy" rel="noopener ugc nofollow" target="_blank"><em class="nc">Github</em></a><em class="nc">中查看代码。</em></p></div></div>    
</body>
</html>