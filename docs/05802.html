<html>
<head>
<title>Anomaly Detection : Isolation Forest with Statistical Rules</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">异常检测:使用统计规则隔离森林</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/isolation-forest-with-statistical-rules-4dd27dad2da9?source=collection_archive---------5-----------------------#2019-08-24">https://towardsdatascience.com/isolation-forest-with-statistical-rules-4dd27dad2da9?source=collection_archive---------5-----------------------#2019-08-24</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><figure class="gl gn jo jp jq jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi jn"><img src="../Images/07d9095abee17cfaab4274970340f49d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*v4SX5LfW9Yf63ZYiWz1cYg.jpeg"/></div></div></figure><p id="dd73" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">这是一篇关于使用隔离林进行<strong class="ka ir">异常检测的后续文章。在上一篇文章中，我们看到了时间序列预测和分类的异常检测。对于隔离森林，我们必须处理<strong class="ka ir">污染参数</strong>，它将我们数据中的<strong class="ka ir">百分比点</strong>设置为异常。</strong></p><p id="2694" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">虽然这可能是看到初始结果的一个好的开始，但这将使您陷入一个问题，在任何点<strong class="ka ir"> x%的点将被异常返回</strong>。让我们来看看一种可能的方法来避免它。</p><p id="5624" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">现在，让我们从在数据集上直接实施隔离林开始，该数据集的值为时间戳和 cpu_utilization:</p><p id="2026" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">链接到数据集(<a class="ae kw" href="https://github.com/numenta/NAB/tree/master/data/realAWSCloudwatch" rel="noopener ugc nofollow" target="_blank">https://github . com/numenta/NAB/tree/master/data/realAWSCloudwatch</a>)</p><pre class="kx ky kz la gt lb lc ld le aw lf bi"><span id="93d6" class="lg lh iq lc b gy li lj l lk ll">import pandas as pd<br/>import numpy as np<br/>full_df=pd.read_csv('ec2_cpu_utilization_5f5533.csv')<br/>full_df.head()</span></pre><figure class="kx ky kz la gt jr gh gi paragraph-image"><div class="gh gi lm"><img src="../Images/730d8e2e95664ea5cdcabcb8377aae30.png" data-original-src="https://miro.medium.com/v2/resize:fit:554/format:webp/1*QSCadD-pL-T-8lNDF1WsWw.png"/></div></figure><p id="afa0" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">从 2 月 14 日到 2 月 28 日，我们在 5 分钟内有大约 4000 个数据点。</p><pre class="kx ky kz la gt lb lc ld le aw lf bi"><span id="c5d3" class="lg lh iq lc b gy li lj l lk ll">print(full_df['timestamp'].min())print(full_df['timestamp'].max())<br/>print(len(full_df['timestamp']))</span></pre><figure class="kx ky kz la gt jr gh gi paragraph-image"><div class="gh gi ln"><img src="../Images/6dd0b9c89f923fbc83bb98d4d8866a95.png" data-original-src="https://miro.medium.com/v2/resize:fit:418/format:webp/1*wZoHmNAQUlQaCLpiLK2apA.png"/></div><figcaption class="lo lp gj gh gi lq lr bd b be z dk">Min &amp; Max Timestamps with number of data points</figcaption></figure><p id="5625" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">将这些点可视化，以了解时间序列数据的概况:</p><pre class="kx ky kz la gt lb lc ld le aw lf bi"><span id="eff1" class="lg lh iq lc b gy li lj l lk ll"># Using graph_objects<br/>from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot<br/>import plotly.plotly as py<br/>import matplotlib.pyplot as plt<br/>from matplotlib import pyplot<br/>import plotly.graph_objs as go<br/>init_notebook_mode(connected=True)<br/>import plotly.graph_objs as go<br/>fig = go.Figure(data=[go.Scatter(x=full_df['timestamp'], y=full_df['value'])])<br/>iplot(fig)</span></pre><figure class="kx ky kz la gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi ls"><img src="../Images/10f6af1751109d612eb3c5c10a4b0698.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*8l_O-XdwJsYFHAGENxturg.png"/></div></div></figure><p id="b68c" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">我将筛选特定一天的数据，以便进行简单的可视化。2 月 24 日似乎是一个很好的选择，因为数据中有一个下降和显著的峰值。</p><pre class="kx ky kz la gt lb lc ld le aw lf bi"><span id="bf10" class="lg lh iq lc b gy li lj l lk ll">df=full_df.loc[(full_df[‘timestamp’]&gt;’2014–02–24 00:00:00')&amp;(full_df[‘timestamp’]&lt;’2014–02–24 23:59:59')]<br/>df.head()<br/>plot_data=go.Scatter(x=df['timestamp'], y=df['value'])<br/>fig=go.Figure(data=[plot_data])<br/>iplot(fig)</span></pre><figure class="kx ky kz la gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi lt"><img src="../Images/3e71a8666131f9142324b7e75e2612d0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*6sn8oIxWQkDMqYgqaq3ijA.png"/></div></div></figure><p id="78c1" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">现在，让我们开始将它与隔离森林模型进行拟合，根据我的直觉，将<strong class="ka ir">污染参数</strong>设置为 4%。</p><pre class="kx ky kz la gt lb lc ld le aw lf bi"><span id="b05e" class="lg lh iq lc b gy li lj l lk ll">from sklearn.ensemble import IsolationForest<br/>#to_model_column='value'<br/>clf=IsolationForest(n_estimators=10, max_samples='auto', contamination=float(.04), \<br/>                        max_features=1.0, bootstrap=False, n_jobs=-1, random_state=42, verbose=0,behaviour='new')<br/>clf.fit(df[['value']])<br/>df['scores']=clf.decision_function(df[['value']])<br/>df['anomaly']=clf.predict(df[['value']])<br/>df.head()df.loc[df['anomaly'] == 1,'anomaly'] = 0<br/>df.loc[df['anomaly'] == -1,'anomaly'] = 1<br/>df.value_counts()</span></pre><figure class="kx ky kz la gt jr gh gi paragraph-image"><div class="gh gi lu"><img src="../Images/17441991089eb2e9627283a6e61372a3.png" data-original-src="https://miro.medium.com/v2/resize:fit:568/format:webp/1*BaUPWKO_kk9--7a3ViFTQA.png"/></div></figure><pre class="kx ky kz la gt lb lc ld le aw lf bi"><span id="415b" class="lg lh iq lc b gy li lj l lk ll">def plot_anomaly(df,metric_name):<br/>    df.timestamp = pd.to_datetime(df['timestamp'].astype(str), format="%Y-%m-%d %H:%M:%S")<br/>    dates = df.timestamp<br/>    #identify the anomaly points and create a array of its values for plot<br/>    bool_array = (abs(df['anomaly']) &gt; 0)<br/>    actuals = df["value"][-len(bool_array):]<br/>    anomaly_points = bool_array * actuals<br/>    anomaly_points[anomaly_points == 0] = np.nan<br/>    #A dictionary for conditional format table based on anomaly<br/>    color_map = {0: "'rgba(228, 222, 249, 0.65)'", 1: "red"}</span><span id="32ac" class="lg lh iq lc b gy lv lj l lk ll">#Table which includes Date,Actuals,Change occured from previous point<br/>    table = go.Table(<br/>    domain=dict(x=[0, 1],<br/>                y=[0, 0.3]),<br/>    columnwidth=[1, 2],<br/>    # columnorder=[0, 1, 2,],<br/>    header=dict(height=20,<br/>                values=[['&lt;b&gt;Date&lt;/b&gt;'], ['&lt;b&gt;Actual Values &lt;/b&gt;'],<br/>                        ],<br/>                font=dict(color=['rgb(45, 45, 45)'] * 5, size=14),<br/>                fill=dict(color='#d562be')),<br/>    cells=dict(values=[df.round(3)[k].tolist() for k in ['timestamp', 'value']],<br/>               line=dict(color='#506784'),<br/>               align=['center'] * 5,<br/>               font=dict(color=['rgb(40, 40, 40)'] * 5, size=12),<br/>               # format = [None] + [",.4f"] + [',.4f'],<br/>               # suffix=[None] * 4,<br/>               suffix=[None] + [''] + [''] + ['%'] + [''],<br/>               height=27,<br/>               fill=dict(color=[df['anomaly'].map(color_map)],#map based on anomaly level from dictionary<br/>               )<br/>               ))<br/>    #Plot the actuals points<br/>    Actuals = go.Scatter(name='Actuals',<br/>                     x=dates,<br/>                     y=df['value'],<br/>                     xaxis='x1', yaxis='y1',<br/>                     mode='line',<br/>                     marker=dict(size=12,<br/>                                 line=dict(width=1),<br/>                                 color="blue"))<br/>    #Highlight the anomaly points<br/>    anomalies_map = go.Scatter(name="Anomaly",<br/>                               showlegend=True,<br/>                               x=dates,<br/>                               y=anomaly_points,<br/>                               mode='markers',<br/>                               xaxis='x1',<br/>                               yaxis='y1',<br/>                               marker=dict(color="red",<br/>                                           size=11,<br/>                                           line=dict(<br/>                                               color="red",<br/>                                               width=2)))<br/>    axis = dict(<br/>        showline=True,<br/>        zeroline=False,<br/>        showgrid=True,<br/>        mirror=True,<br/>        ticklen=4,<br/>        gridcolor='#ffffff',<br/>        tickfont=dict(size=10))<br/>    layout = dict(<br/>        width=1000,<br/>        height=865,<br/>        autosize=False,<br/>        title=metric_name,<br/>        margin=dict(t=75),<br/>        showlegend=True,<br/>        xaxis1=dict(axis, **dict(domain=[0, 1], anchor='y1', showticklabels=True)),<br/>        yaxis1=dict(axis, **dict(domain=[2 * 0.21 + 0.20, 1], anchor='x1', hoverformat='.2f')))<br/>    fig = go.Figure(data=[table, anomalies_map, Actuals], layout=layout)<br/>    iplot(fig)<br/>    pyplot.show()</span><span id="a17c" class="lg lh iq lc b gy lv lj l lk ll">plot_anomaly(df,'anomalies')</span></pre><figure class="kx ky kz la gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi lw"><img src="../Images/3e953ef88b97b9de4905482e93542274.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*bqqM1yVjtyNi3854WLCIJw.png"/></div></div></figure><pre class="kx ky kz la gt lb lc ld le aw lf bi"><span id="5df6" class="lg lh iq lc b gy li lj l lk ll">print("Percentage of anomalies in data: {:.2f}".format((len(df.loc[df['anomaly']==1])/len(df))*100))</span></pre><figure class="kx ky kz la gt jr gh gi paragraph-image"><div class="gh gi lx"><img src="../Images/cb7050a80e76a7946598b129f4cf6307.png" data-original-src="https://miro.medium.com/v2/resize:fit:616/format:webp/1*8xBXPsPJDPY-tmhQOMcKQQ.png"/></div></figure><p id="7ce9" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">看起来不错，有一些小的错误异常，因为我们的绘图显示，我们已经捕捉到了重大的尖峰和其他一些下降和尖峰。现在让我们看看污染参数的作用。</p><figure class="kx ky kz la gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi ly"><img src="../Images/ee470619592d3d9c07c18a0c06d18500.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*FFvvaGoU2b1CSma6AwulTA.png"/></div></div><figcaption class="lo lp gj gh gi lq lr bd b be z dk">Inliers occur together , it takes around 2 splits to separate x(i) whereas an outlier x(0) is separated in 4 splits</figcaption></figure><p id="6ead" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated"><strong class="ka ir">隔离森林将每个点</strong>从其他点中随机分离出来，并根据其分裂次数构建一棵树，每个点代表树中的一个节点。<strong class="ka ir">离群值出现在树中更靠近根的位置</strong>，而内嵌值出现在更深的位置。在隔离森林的情况下，基于<strong class="ka ir"> n_estimators 和 max_sample </strong>参数创建森林，并从中得出分数。</p><p id="3aae" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">可以使用<strong class="ka ir">score _ samples/decision _ function</strong>来获得每个点的归一化异常分数，这里越负，它就异常，基于 sklearn 计算。</p><p id="ab4c" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">直到这一步<strong class="ka ir">污染因素对分数</strong>没有影响。从这里开始，当我们应用 predict 以返回异常时，1/0 污染作为分数的临界值/百分点，并将前 x 个百分点的负分数作为异常返回。(例如:如果污染设定为 0.05/5%，那么负得分最高的 5%的点被标记为异常)</p><pre class="kx ky kz la gt lb lc ld le aw lf bi"><span id="bdd9" class="lg lh iq lc b gy li lj l lk ll">df['scores'].hist()</span></pre><figure class="kx ky kz la gt jr gh gi paragraph-image"><div class="gh gi lz"><img src="../Images/c776a5f2adc110a17ee3132ce418f0df.png" data-original-src="https://miro.medium.com/v2/resize:fit:1036/format:webp/1*8lwCjuyM9Tv6P1ylS8AC1A.png"/></div></figure><p id="60bb" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated"><strong class="ka ir">得分为正的内场球员在得分为正的右侧击球</strong>。分数为负的点是异常点。这是这个特定输入点的分数分布。一旦我们在此基础上最终确定了我们的模型，并预测了未来的点，那么我们的污染得分截止值可能会发生变化，给出 4%的异常点，但得分的分布可能会发生变化。为了克服硬编码的分数百分比总是被标记为异常而不考虑分数的变化，我们可以使用一些统计算法，如<strong class="ka ir"> Z-Score 或分数上的 IQR</strong>，来检测分数的变化并更好地对异常进行分类。</p><pre class="kx ky kz la gt lb lc ld le aw lf bi"><span id="c661" class="lg lh iq lc b gy li lj l lk ll">def iqr_bounds(scores,k=1.5):<br/>    q1 = scores.quantile(0.25)<br/>    q3 = scores.quantile(0.75)<br/>    iqr = q3 - q1<br/>    lower_bound=(q1 - k * iqr)<br/>    upper_bound=(q3 + k * iqr)<br/>    print("Lower bound:{} \nUpper bound:{}".format(lower_bound,upper_bound))<br/>    return lower_bound,upper_bound<br/>lower_bound,upper_bound=iqr_bounds(df['scores'],k=2)</span></pre><figure class="kx ky kz la gt jr gh gi paragraph-image"><div class="gh gi ma"><img src="../Images/cbc66a2ac0c74e9902c7dba6edcb9667.png" data-original-src="https://miro.medium.com/v2/resize:fit:646/format:webp/1*3636SXuWz9NUQO7xqELwiQ.png"/></div></figure><pre class="kx ky kz la gt lb lc ld le aw lf bi"><span id="b03d" class="lg lh iq lc b gy li lj l lk ll">df['anomaly']=0<br/>df['anomaly']=(df['scores'] &lt; lower_bound) |(df['scores'] &gt; upper_bound)<br/>df['anomaly']=df['anomaly'].astype(int)<br/>plot_anomaly(df,'iqr based')</span></pre><figure class="kx ky kz la gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi mb"><img src="../Images/e989ae5c3678d448e1af2e228000674e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*arN18cS_tTDN60TUwYzrqA.png"/></div></div></figure><figure class="kx ky kz la gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi mc"><img src="../Images/d02ffad36fa405d8781b4ef7f18efbf2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*kuylAZyV2iP4xhcaI0uhWw.png"/></div></div></figure><p id="b263" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">标记为异常的点的百分比在这里大约是 2%,在 IQR k 被设置为 2。</p><pre class="kx ky kz la gt lb lc ld le aw lf bi"><span id="e191" class="lg lh iq lc b gy li lj l lk ll">print("Percentage of anomalies in data: {:.2f}".format((len(df.loc[df['anomaly']==1])/len(df))*100))</span></pre><figure class="kx ky kz la gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi md"><img src="../Images/aa31ae490877e5d1e6baa047ee9d26dd.png" data-original-src="https://miro.medium.com/v2/resize:fit:766/format:webp/1*UO8gBCqMXaANrkVFuWrHDg.png"/></div></div></figure><p id="759d" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">现在让我们用另一个数据来验证这一点，考虑到同样的污染，以及 IQR 相同的 k 值:</p><pre class="kx ky kz la gt lb lc ld le aw lf bi"><span id="514e" class="lg lh iq lc b gy li lj l lk ll">df=full_df.loc[(full_df['timestamp']&gt;'2014-02-17 00:00:00')&amp;(full_df['timestamp']&lt;'2014-02-17 23:59:59')]<br/># Using graph_objects<br/>plot_data=go.Scatter(x=df['timestamp'], y=df['value'])<br/>fig=go.Figure(data=[plot_data])<br/>iplot(fig)</span></pre><figure class="kx ky kz la gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi me"><img src="../Images/29a0274d51da291d417c65541f6934f2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*usJ9VLQ6o5RmYVzPFgg2zQ.png"/></div></div></figure><p id="5cd5" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">通过查看这一天的曲线图，数据看起来不同，异常更少。</p><pre class="kx ky kz la gt lb lc ld le aw lf bi"><span id="e2bc" class="lg lh iq lc b gy li lj l lk ll">from sklearn.ensemble import IsolationForest<br/>#to_model_column='value'<br/>clf=IsolationForest(n_estimators=10, max_samples='auto', contamination=float(.04), \<br/>                        max_features=1.0, bootstrap=False, n_jobs=-1, random_state=42, verbose=0,behaviour='new')<br/>clf.fit(df[['value']])<br/>df['scores']=clf.decision_function(df[['value']])<br/>df['anomaly']=clf.predict(df[['value']])<br/>df.loc[df['anomaly'] == 1,'anomaly'] = 0<br/>df.loc[df['anomaly'] == -1,'anomaly'] = 1<br/>plot_anomaly(df,'anomalies')</span></pre><figure class="kx ky kz la gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi mf"><img src="../Images/e6d45e3af3354d4eee523a83517de368.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Yj7d3Vf41Ty66bZuaQpnFA.png"/></div></div></figure><pre class="kx ky kz la gt lb lc ld le aw lf bi"><span id="6593" class="lg lh iq lc b gy li lj l lk ll">print("Percentage of anomalies in data: {:.2f}".format((len(df.loc[df['anomaly']==1])/len(df))*100))</span></pre><figure class="kx ky kz la gt jr gh gi paragraph-image"><div class="gh gi lx"><img src="../Images/cb7050a80e76a7946598b129f4cf6307.png" data-original-src="https://miro.medium.com/v2/resize:fit:616/format:webp/1*8xBXPsPJDPY-tmhQOMcKQQ.png"/></div></figure><p id="270e" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">是的，这里我们从可视化中看到了更多的<strong class="ka ir">错误异常</strong>。这里的<strong class="ka ir">异常点百分比保持不变</strong>，因为我们对新时间帧的数据使用了相同的污染。</p><pre class="kx ky kz la gt lb lc ld le aw lf bi"><span id="6f88" class="lg lh iq lc b gy li lj l lk ll">df['scores'].hist()</span></pre><figure class="kx ky kz la gt jr gh gi paragraph-image"><div class="gh gi mg"><img src="../Images/e615effbd47dba0e34f9a3d0289d5b73.png" data-original-src="https://miro.medium.com/v2/resize:fit:986/format:webp/1*6o3Hzt9g5Y4L8Rw29pHApA.png"/></div></figure><pre class="kx ky kz la gt lb lc ld le aw lf bi"><span id="4072" class="lg lh iq lc b gy li lj l lk ll">lower_bound,upper_bound=iqr_bounds(df['scores'],k=2)<br/>df['anomaly']=0<br/>df['anomaly']=(df['scores'] &lt; lower_bound) |(df['scores'] &gt; upper_bound)<br/>df['anomaly']=df['anomaly'].astype(int)<br/>plot_anomaly(df,'iqr second case')</span></pre><figure class="kx ky kz la gt jr gh gi paragraph-image"><div class="gh gi mh"><img src="../Images/5fcf1cd97fd06050fba2d5257a8a2f92.png" data-original-src="https://miro.medium.com/v2/resize:fit:642/format:webp/1*czEnYkax_U2LUBH1REUBWA.png"/></div></figure><figure class="kx ky kz la gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi mi"><img src="../Images/7e8d9247d90eb97b745b5390927e9702.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*I6YWJPGxa5YJrCI4OswNew.png"/></div></div></figure><pre class="kx ky kz la gt lb lc ld le aw lf bi"><span id="1a06" class="lg lh iq lc b gy li lj l lk ll">print("Percentage of anomalies in data: {:.2f}".format((len(df.loc[df['anomaly']==1])/len(df))*100))</span></pre><figure class="kx ky kz la gt jr gh gi paragraph-image"><div class="gh gi mj"><img src="../Images/2fa5f032cb19548cdfd77937a4fe6c95.png" data-original-src="https://miro.medium.com/v2/resize:fit:598/format:webp/1*gC43V2UZwOJx4lDjprqmvQ.png"/></div></figure><p id="3ec4" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated"><strong class="ka ir">在这种情况下，异常值的百分比在这种方法中下降，因为分数中反映的数据分布已经改变。</strong></p><p id="00a9" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">在实时异常检测中，隔离森林上的统计规则组合会更好地工作，因为您会对未来的数据流进行建模、部署和预测，这些数据流的分布可能会随时间变化，并且新数据的<strong class="ka ir">分数会不同</strong>。</p><p id="fb78" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">此外，IQR 的这个<strong class="ka ir"> k 参数可以基于对检测到的异常的反馈进行调整。如果有假阳性，那么 k 应该减少，如果有假阴性，那么 k 应该减少以发现更多的异常。</strong></p><p id="e0d8" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">随后将介绍隔离林算法的一些细节，新增加的热启动和解释来自隔离林的结果。</p><p id="d3b8" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated"><strong class="ka ir"> <em class="mk">加在</em> </strong> <em class="mk">上:下面是一个多元的</em> <strong class="ka ir"> <em class="mk">异常 3d 可视化</em> </strong> <em class="mk">用</em> <strong class="ka ir"> <em class="mk">情节性地表达</em> </strong> <em class="mk">其中我发现很酷在所有 3 个维度上玩它，看看异常情况。</em></p><figure class="kx ky kz la gt jr"><div class="bz fp l di"><div class="ml mm l"/></div></figure></div></div>    
</body>
</html>