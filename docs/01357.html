<html>
<head>
<title>How to Build a Deep Neural Network Without a Framework</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">如何建立一个没有框架的深度神经网络</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/how-to-build-a-deep-neural-network-without-a-framework-5d46067754d5?source=collection_archive---------15-----------------------#2019-03-04">https://towardsdatascience.com/how-to-build-a-deep-neural-network-without-a-framework-5d46067754d5?source=collection_archive---------15-----------------------#2019-03-04</a></blockquote><div><div class="fc ij ik il im in"/><div class="io ip iq ir is"><div class=""/><div class=""><h2 id="4722" class="pw-subtitle-paragraph js iu iv bd b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj dk translated">了解如何使用<em class="kk"> NumPy </em>构建可扩展的深度神经网络，并将其用于图像分类</h2></div><figure class="km kn ko kp gt kq gh gi paragraph-image"><div role="button" tabindex="0" class="kr ks di kt bf ku"><div class="gh gi kl"><img src="../Images/6d04c238bddf5fff58cf7f5de10ffb6d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*77h8gBGmo62HG4EU"/></div></div><figcaption class="kx ky gj gh gi kz la bd b be z dk">Photo by <a class="ae lb" href="https://unsplash.com/@sneakyelbow?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Sneaky Elbow</a> on <a class="ae lb" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><h1 id="0bca" class="lc ld iv bd le lf lg lh li lj lk ll lm kb ln kc lo ke lp kf lq kh lr ki ls lt bi translated">介绍</h1><p id="6029" class="pw-post-body-paragraph lu lv iv lw b lx ly jw lz ma mb jz mc md me mf mg mh mi mj mk ml mm mn mo mp io bi translated"><a class="ae lb" rel="noopener" target="_blank" href="/step-by-step-guide-to-building-your-own-neural-network-from-scratch-df64b1c5ab6e">之前</a>，我们从零开始构建了一个非常简单的神经网络用于图像分类。尽管如此，我们还是获得了 70%的准确率。</p><p id="2567" class="pw-post-body-paragraph lu lv iv lw b lx mq jw lz ma mr jz mc md ms mf mg mh mt mj mk ml mu mn mo mp io bi translated">现在，我们将在不使用框架的情况下构建更深层次的神经网络。以下几段代码可扩展到任何神经网络架构。这意味着你可以使用不同数量的层和不同的<a class="ae lb" rel="noopener" target="_blank" href="/step-by-step-guide-to-building-your-own-neural-network-from-scratch-df64b1c5ab6e">激活</a>和<a class="ae lb" rel="noopener" target="_blank" href="/step-by-step-guide-to-building-your-own-neural-network-from-scratch-df64b1c5ab6e">成本函数</a>，只需对代码做最小的改动！</p><p id="239d" class="pw-post-body-paragraph lu lv iv lw b lx mq jw lz ma mr jz mc md ms mf mg mh mt mj mk ml mu mn mo mp io bi translated">你可以在 Github 上抓取总结代码的两个笔记本。第一个<a class="ae lb" href="https://github.com/marcopeix/Deep_Learning_AI/blob/master/1.Neural%20Networks%20and%20Deep%20Learning/4.Deep%20Neural%20Networks/Building%20a%20Deep%20Neural%20Network.ipynb" rel="noopener ugc nofollow" target="_blank">笔记本</a>构建必要的函数，第二个<a class="ae lb" href="https://github.com/marcopeix/Deep_Learning_AI/blob/master/1.Neural%20Networks%20and%20Deep%20Learning/4.Deep%20Neural%20Networks/Deep%20Neural%20Network%20-%20Application.ipynb" rel="noopener ugc nofollow" target="_blank">笔记本</a>应用它们进行图像分类。</p><p id="196a" class="pw-post-body-paragraph lu lv iv lw b lx mq jw lz ma mr jz mc md ms mf mg mh mt mj mk ml mu mn mo mp io bi translated">作为先决条件，我强烈推荐你阅读我的<a class="ae lb" href="https://github.com/marcopeix/Deep_Learning_AI/blob/master/1.Neural%20Networks%20and%20Deep%20Learning/4.Deep%20Neural%20Networks/Deep%20Neural%20Network%20-%20Application.ipynb" rel="noopener ugc nofollow" target="_blank">上一篇文章</a>，因为它包含了关于构建神经网络的不同步骤的详细解释。</p><p id="ad68" class="pw-post-body-paragraph lu lv iv lw b lx mq jw lz ma mr jz mc md ms mf mg mh mt mj mk ml mu mn mo mp io bi translated">现在，让我们开始编码吧！</p><blockquote class="mv"><p id="debd" class="mw mx iv bd my mz na nb nc nd ne mp dk translated">关于机器学习、深度学习和人工智能的实践视频教程，请查看我的<a class="ae lb" href="https://www.youtube.com/channel/UC-0lpiwlftqwC7znCcF83qg?view_as=subscriber" rel="noopener ugc nofollow" target="_blank"> YouTube 频道</a>。</p></blockquote><figure class="nf ng nh ni nj kq"><div class="bz fp l di"><div class="nk nl l"/></div><figcaption class="kx ky gj gh gi kz la bd b be z dk">The feeling you will get when you are done building the neural network!</figcaption></figure><h1 id="aed0" class="lc ld iv bd le lf lg lh li lj lk ll lm kb ln kc lo ke lp kf lq kh lr ki ls lt bi translated">构建神经网络</h1><h2 id="ad27" class="nm ld iv bd le nn no dn li np nq dp lm md nr ns lo mh nt nu lq ml nv nw ls nx bi translated">步骤 1:初始化权重和偏差</h2><p id="b511" class="pw-post-body-paragraph lu lv iv lw b lx ly jw lz ma mb jz mc md me mf mg mh mi mj mk ml mm mn mo mp io bi translated">像往常一样，构建神经网络的第一步是初始化权重矩阵和偏差矩阵。</p><p id="5fa5" class="pw-post-body-paragraph lu lv iv lw b lx mq jw lz ma mr jz mc md ms mf mg mh mt mj mk ml mu mn mo mp io bi translated">请记住，权重必须是随机的非零值，而偏差可以初始化为 0。</p><p id="709c" class="pw-post-body-paragraph lu lv iv lw b lx mq jw lz ma mr jz mc md ms mf mg mh mt mj mk ml mu mn mo mp io bi translated">对于这一步，函数非常简单:在神经网络的层数上循环，并为您的输入初始化每个权重和偏差。在代码中，应该是这样的:</p><figure class="km kn ko kp gt kq"><div class="bz fp l di"><div class="ny nl l"/></div></figure><h2 id="49f2" class="nm ld iv bd le nn no dn li np nq dp lm md nr ns lo mh nt nu lq ml nv nw ls nx bi translated">步骤 2:正向传播模块</h2><p id="be2c" class="pw-post-body-paragraph lu lv iv lw b lx ly jw lz ma mb jz mc md me mf mg mh mi mj mk ml mm mn mo mp io bi translated">现在，我们将构建正向传播模块。在前向传播中，我们需要将加权和提供给激活函数。</p><p id="0f8b" class="pw-post-body-paragraph lu lv iv lw b lx mq jw lz ma mr jz mc md ms mf mg mh mt mj mk ml mu mn mo mp io bi translated">该模块将分三步构建:</p><ul class=""><li id="26a2" class="nz oa iv lw b lx mq ma mr md ob mh oc ml od mp oe of og oh bi translated">为加权和写一个函数</li><li id="2d55" class="nz oa iv lw b lx oi ma oj md ok mh ol ml om mp oe of og oh bi translated">编写一个函数，将加权和提供给激活函数</li><li id="462a" class="nz oa iv lw b lx oi ma oj md ok mh ol ml om mp oe of og oh bi translated">编写一个函数，在最后一层使用 sigmoid 函数，在所有前面的层使用 ReLU</li></ul></div><div class="ab cl on oo hz op" role="separator"><span class="oq bw bk or os ot"/><span class="oq bw bk or os ot"/><span class="oq bw bk or os"/></div><div class="io ip iq ir is"><p id="3e13" class="pw-post-body-paragraph lu lv iv lw b lx mq jw lz ma mr jz mc md ms mf mg mh mt mj mk ml mu mn mo mp io bi translated"><strong class="lw iw">可选阅读:什么是 ReLU？</strong></p><p id="b2c7" class="pw-post-body-paragraph lu lv iv lw b lx mq jw lz ma mr jz mc md ms mf mg mh mt mj mk ml mu mn mo mp io bi translated"><strong class="lw iw"> ReLu </strong>代表<strong class="lw iw">Re</strong>ctived<strong class="lw iw">L</strong>linear<strong class="lw iw">U</strong>nit，表示为:</p><figure class="km kn ko kp gt kq gh gi paragraph-image"><div role="button" tabindex="0" class="kr ks di kt bf ku"><div class="gh gi ou"><img src="../Images/23693eddd90355bda5f2e6218a295fc2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Od4DEy4d6wstbL075Havcg.png"/></div></div><figcaption class="kx ky gj gh gi kz la bd b be z dk">ReLU function</figcaption></figure><p id="05b6" class="pw-post-body-paragraph lu lv iv lw b lx mq jw lz ma mr jz mc md ms mf mg mh mt mj mk ml mu mn mo mp io bi translated">看起来是这样的:</p><figure class="km kn ko kp gt kq gh gi paragraph-image"><div role="button" tabindex="0" class="kr ks di kt bf ku"><div class="gh gi ov"><img src="../Images/4f58377e6a5e0d92ba64fbcdc22c6969.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*QkZ5OYHJvCnYPigMJ2SIyg.png"/></div></div><figcaption class="kx ky gj gh gi kz la bd b be z dk">ReLU plot</figcaption></figure><p id="b579" class="pw-post-body-paragraph lu lv iv lw b lx mq jw lz ma mr jz mc md ms mf mg mh mt mj mk ml mu mn mo mp io bi translated">如你所见，正值的导数是 1，负值的导数是 0。请注意，函数在 0 处不可微。</p><p id="3303" class="pw-post-body-paragraph lu lv iv lw b lx mq jw lz ma mr jz mc md ms mf mg mh mt mj mk ml mu mn mo mp io bi translated">实际上，激活函数通常是正的，这意味着导数将大于 0。因此，参数将更新得更快，并且网络最终<em class="ow">通过 ReLU 学习得更快</em>。</p><p id="d797" class="pw-post-body-paragraph lu lv iv lw b lx mq jw lz ma mr jz mc md ms mf mg mh mt mj mk ml mu mn mo mp io bi translated">通常，如果您不确定使用什么激活函数，ReLU 是一个很好的默认函数，在大多数情况下都能很好地工作。</p></div><div class="ab cl on oo hz op" role="separator"><span class="oq bw bk or os ot"/><span class="oq bw bk or os ot"/><span class="oq bw bk or os"/></div><div class="io ip iq ir is"><p id="f8b0" class="pw-post-body-paragraph lu lv iv lw b lx mq jw lz ma mr jz mc md ms mf mg mh mt mj mk ml mu mn mo mp io bi translated">因此，对于加权和，函数很简单:</p><figure class="km kn ko kp gt kq"><div class="bz fp l di"><div class="ny nl l"/></div></figure><p id="ba31" class="pw-post-body-paragraph lu lv iv lw b lx mq jw lz ma mr jz mc md ms mf mg mh mt mj mk ml mu mn mo mp io bi translated">够简单！现在，我们构建一个函数来将结果提供给激活函数(ReLU 或 sigmoid):</p><figure class="km kn ko kp gt kq"><div class="bz fp l di"><div class="ny nl l"/></div></figure><p id="44f3" class="pw-post-body-paragraph lu lv iv lw b lx mq jw lz ma mr jz mc md ms mf mg mh mt mj mk ml mu mn mo mp io bi translated">现在，我们想在最后一层使用 sigmoid 函数，并依赖于所有先前的层。这是特定于该应用的，因为我们将执行二值图像分类，所以在最后一层使用 sigmoid 函数是有意义的。</p><figure class="km kn ko kp gt kq"><div class="bz fp l di"><div class="ny nl l"/></div></figure><p id="b573" class="pw-post-body-paragraph lu lv iv lw b lx mq jw lz ma mr jz mc md ms mf mg mh mt mj mk ml mu mn mo mp io bi translated">太好了！</p><h2 id="eb13" class="nm ld iv bd le nn no dn li np nq dp lm md nr ns lo mh nt nu lq ml nv nw ls nx bi translated">步骤 3:定义成本函数</h2><p id="fa6c" class="pw-post-body-paragraph lu lv iv lw b lx ly jw lz ma mb jz mc md me mf mg mh mi mj mk ml mm mn mo mp io bi translated">当然，我们现在需要定义一个成本函数。然后，该函数将被最小化，并且它将驱动对权重和偏差矩阵的更新。</p><p id="7d20" class="pw-post-body-paragraph lu lv iv lw b lx mq jw lz ma mr jz mc md ms mf mg mh mt mj mk ml mu mn mo mp io bi translated">为此，我们使用交叉熵损失表示为:</p><figure class="km kn ko kp gt kq gh gi paragraph-image"><div role="button" tabindex="0" class="kr ks di kt bf ku"><div class="gh gi ox"><img src="../Images/5496f02c95f3d7e581160e9572f0a59e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*jNAvW0EmSrqIlklNzksULQ.png"/></div></div><figcaption class="kx ky gj gh gi kz la bd b be z dk">Cross-entropy loss function</figcaption></figure><p id="fe40" class="pw-post-body-paragraph lu lv iv lw b lx mq jw lz ma mr jz mc md ms mf mg mh mt mj mk ml mu mn mo mp io bi translated">现在，我们用代码实现了一个矢量化版本:</p><figure class="km kn ko kp gt kq"><div class="bz fp l di"><div class="ny nl l"/></div></figure><p id="94a5" class="pw-post-body-paragraph lu lv iv lw b lx mq jw lz ma mr jz mc md ms mf mg mh mt mj mk ml mu mn mo mp io bi translated">成本函数到此为止！</p><h2 id="9e29" class="nm ld iv bd le nn no dn li np nq dp lm md nr ns lo mh nt nu lq ml nv nw ls nx bi translated">第四步:反向传播</h2><p id="6609" class="pw-post-body-paragraph lu lv iv lw b lx ly jw lz ma mb jz mc md me mf mg mh mi mj mk ml mm mn mo mp io bi translated">与正向传播类似，我们将分三步构建反向传播模块:</p><ul class=""><li id="42c3" class="nz oa iv lw b lx mq ma mr md ob mh oc ml od mp oe of og oh bi translated">计算重量和偏差的导数</li><li id="a1d4" class="nz oa iv lw b lx oi ma oj md ok mh ol ml om mp oe of og oh bi translated">计算激活函数的导数</li><li id="f17a" class="nz oa iv lw b lx oi ma oj md ok mh ol ml om mp oe of og oh bi translated">对整个网络执行反向传播</li></ul><p id="00f3" class="pw-post-body-paragraph lu lv iv lw b lx mq jw lz ma mr jz mc md ms mf mg mh mt mj mk ml mu mn mo mp io bi translated">首先，我们为权重和偏差的导数写一个函数:</p><figure class="km kn ko kp gt kq"><div class="bz fp l di"><div class="ny nl l"/></div></figure><p id="c8d8" class="pw-post-body-paragraph lu lv iv lw b lx mq jw lz ma mr jz mc md ms mf mg mh mt mj mk ml mu mn mo mp io bi translated">然后，我们找到激活函数的导数:</p><figure class="km kn ko kp gt kq"><div class="bz fp l di"><div class="ny nl l"/></div></figure><p id="f15c" class="pw-post-body-paragraph lu lv iv lw b lx mq jw lz ma mr jz mc md ms mf mg mh mt mj mk ml mu mn mo mp io bi translated">最后，我们编写一个函数在整个网络上执行反向传播:</p><figure class="km kn ko kp gt kq"><div class="bz fp l di"><div class="ny nl l"/></div></figure><p id="8041" class="pw-post-body-paragraph lu lv iv lw b lx mq jw lz ma mr jz mc md ms mf mg mh mt mj mk ml mu mn mo mp io bi translated">现在这已经完成了，我们需要更新我们的参数！</p><h2 id="3fe1" class="nm ld iv bd le nn no dn li np nq dp lm md nr ns lo mh nt nu lq ml nv nw ls nx bi translated">步骤 5:用梯度下降更新参数</h2><p id="8b0d" class="pw-post-body-paragraph lu lv iv lw b lx ly jw lz ma mb jz mc md me mf mg mh mi mj mk ml mm mn mo mp io bi translated">现在，我们简单地定义梯度下降来更新我们的参数，以便最小化交叉熵成本函数:</p><figure class="km kn ko kp gt kq"><div class="bz fp l di"><div class="ny nl l"/></div></figure><p id="3d56" class="pw-post-body-paragraph lu lv iv lw b lx mq jw lz ma mr jz mc md ms mf mg mh mt mj mk ml mu mn mo mp io bi translated">完美！我们现在准备在一个用于图像分类的神经网络中使用上述所有功能！</p><h1 id="99da" class="lc ld iv bd le lf lg lh li lj lk ll lm kb ln kc lo ke lp kf lq kh lr ki ls lt bi translated">使用神经网络</h1><p id="93d6" class="pw-post-body-paragraph lu lv iv lw b lx ly jw lz ma mb jz mc md me mf mg mh mi mj mk ml mm mn mo mp io bi translated">随着所有助手功能的建立，我们现在可以在深度神经网络中使用它们来识别它是否是一张猫图片，并看看我们是否可以在我们的<a class="ae lb" rel="noopener" target="_blank" href="/step-by-step-guide-to-building-your-own-neural-network-from-scratch-df64b1c5ab6e">以前的模型</a>上进行改进。</p><p id="c3d2" class="pw-post-body-paragraph lu lv iv lw b lx mq jw lz ma mr jz mc md ms mf mg mh mt mj mk ml mu mn mo mp io bi translated">查阅<a class="ae lb" href="https://github.com/marcopeix/Deep_Learning_AI/blob/master/1.Neural%20Networks%20and%20Deep%20Learning/4.Deep%20Neural%20Networks/Deep%20Neural%20Network%20-%20Application.ipynb" rel="noopener ugc nofollow" target="_blank">笔记本</a>导入合适的库并预处理数据。</p><p id="a2a7" class="pw-post-body-paragraph lu lv iv lw b lx mq jw lz ma mr jz mc md ms mf mg mh mt mj mk ml mu mn mo mp io bi translated">在这种情况下，我们将训练一个 5 层网络。我们定义每个维度的维度，并按如下方式训练模型:</p><figure class="km kn ko kp gt kq"><div class="bz fp l di"><div class="ny nl l"/></div></figure><p id="c6ad" class="pw-post-body-paragraph lu lv iv lw b lx mq jw lz ma mr jz mc md ms mf mg mh mt mj mk ml mu mn mo mp io bi translated">训练此模型需要几分钟时间。如果一切都做对了，你应该看到我们达到了 80%的测试准确率！这比我们以前的型号好多了！</p><p id="984c" class="pw-post-body-paragraph lu lv iv lw b lx mq jw lz ma mr jz mc md ms mf mg mh mt mj mk ml mu mn mo mp io bi translated">当然，您可以随意调整模型的参数和结构。上面代码的优点是完全灵活。你可以添加任意多的层，改变迭代次数，提高学习速度等等。</p></div><div class="ab cl on oo hz op" role="separator"><span class="oq bw bk or os ot"/><span class="oq bw bk or os ot"/><span class="oq bw bk or os"/></div><div class="io ip iq ir is"><p id="7961" class="pw-post-body-paragraph lu lv iv lw b lx mq jw lz ma mr jz mc md ms mf mg mh mt mj mk ml mu mn mo mp io bi translated">恭喜你构建了一个没有任何框架的深度神经网络！你现在已经有了深度学习的坚实基础，你甚至可以将上面的代码重用到任何神经网络结构中。</p><p id="4b12" class="pw-post-body-paragraph lu lv iv lw b lx mq jw lz ma mr jz mc md ms mf mg mh mt mj mk ml mu mn mo mp io bi translated">在接下来的文章中，我将教授不同的方法来改善你的神经网络，并取得更好的效果。</p><p id="fb77" class="pw-post-body-paragraph lu lv iv lw b lx mq jw lz ma mr jz mc md ms mf mg mh mt mj mk ml mu mn mo mp io bi translated">干杯！</p></div></div>    
</body>
</html>