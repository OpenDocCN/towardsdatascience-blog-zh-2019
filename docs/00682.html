<html>
<head>
<title>Doing meaningful work with Machine Learning — Classify Disaster Messages</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">用机器学习做有意义的工作——对灾难信息进行分类</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/doing-meaningful-work-with-machine-learning-classify-disaster-messages-436bfe9ec42?source=collection_archive---------23-----------------------#2019-01-31">https://towardsdatascience.com/doing-meaningful-work-with-machine-learning-classify-disaster-messages-436bfe9ec42?source=collection_archive---------23-----------------------#2019-01-31</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="65dc" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">建立模型，帮助救灾组织拯救人们的生命。</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/1977e9de175d4ad227632837d88a1c67.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Yfs8GpTY8-JaTxScxGY1ZA.jpeg"/></div></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk">I’m writing this post at 1am in Bucharest, Romania.</figcaption></figure><p id="455d" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">又见面了。欢迎来到我的第四篇关于机器学习的内容。我最近做了一个我认为对社会有意义的项目。我将简要概述这是怎么回事，然后马上深入代码:)</p><blockquote class="lr ls lt"><p id="bd27" class="kv kw lu kx b ky kz jr la lb lc ju ld lv lf lg lh lw lj lk ll lx ln lo lp lq ij bi translated">在这个项目中，我应用数据工程技术创建了一个 API(应用程序编程接口),将来自各种来源(Twitter，文本消息)的灾难消息分为 36 类。这种分类问题是一种受监督的机器学习，因为模型根据对提供给它的数据的学习来学习对结果进行分类。即信息与什么相关:水、食物、住所、金钱等。？原因是当灾难发生时，有数百万条消息被发送和推文告知。然而，灾难由不同的组织负责。食物供应可能由某个组织提供，而灭火则由另一个组织负责。因此，该应用程序的用途是将这些消息分类成各种类型，以便可以理解对于特定的灾难需要哪种类型的援助。</p></blockquote><h2 id="4452" class="ly lz iq bd ma mb mc dn md me mf dp mg le mh mi mj li mk ml mm lm mn mo mp mq bi translated">项目结构</h2><p id="25ca" class="pw-post-body-paragraph kv kw iq kx b ky mr jr la lb ms ju ld le mt lg lh li mu lk ll lm mv lo lp lq ij bi translated">该项目有三个部分:</p><ol class=""><li id="7af5" class="mw mx iq kx b ky kz lb lc le my li mz lm na lq nb nc nd ne bi translated"><strong class="kx ir"> ETL 管道</strong> <br/> <em class="lu">提取、转换、加载</em>数据。这与处理数据有关。也就是说，我加载、合并和清理了消息和类别数据集。我存储到 SQLite 数据库中，以便模型可以在下一步中使用它进行训练。</li><li id="c0f0" class="mw mx iq kx b ky nf lb ng le nh li ni lm nj lq nb nc nd ne bi translated"><strong class="kx ir"> ML 流水线</strong><br/><em class="lu">机器学习</em>流水线与训练模型和测试模型有关。管道包括一个文本处理部分，因为它处理开头提到的文本源。我还使用 GridSearchCV 进一步调优模型，并将其保存为 pickle 文件。</li><li id="7d3a" class="mw mx iq kx b ky nf lb ng le nh li ni lm nj lq nb nc nd ne bi translated"><strong class="kx ir">Flask Web App</strong><br/><code class="fe nk nl nm nn b">run.py</code><code class="fe nk nl nm nn b">process_data</code><code class="fe nk nl nm nn b">train_classifier</code>基本就是终端工作空间包含的 ETL 管道和 ML 管道，让 App 工作。</li></ol><h2 id="f489" class="ly lz iq bd ma mb mc dn md me mf dp mg le mh mi mj li mk ml mm lm mn mo mp mq bi translated">ETL 管道</h2><p id="20ad" class="pw-post-body-paragraph kv kw iq kx b ky mr jr la lb ms ju ld le mt lg lh li mu lk ll lm mv lo lp lq ij bi translated">在项目的第一部分，我的目的是提取我需要的数据，进行必要的转换，以便我可以在以后的算法构建中使用它。一旦我看到了我需要的两个数据集:T3 和 T4，我就使用公共 id 合并这两个数据集。</p><pre class="kg kh ki kj gt no nn np nq aw nr bi"><span id="4dd9" class="ly lz iq nn b gy ns nt l nu nv"><em class="lu"># merge data sets</em> <br/>df = messages.merge(categories, on = [‘id’]) <br/>df.head()</span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nw"><img src="../Images/6fa01fe7ca84d7c31994547a4fe03a4d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*u7aZC3efnOxV8osLFYHBQg.jpeg"/></div></div></figure><p id="0037" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">然后，我将类别分成单独的类别列，并为每一列指定了单独的类别名称。</p><pre class="kg kh ki kj gt no nn np nq aw nr bi"><span id="de9b" class="ly lz iq nn b gy ns nt l nu nv"><em class="lu"># create a dataframe of the 36 individual category columns</em><br/>categories = df['categories'].str.split(';', expand = <strong class="nn ir">True</strong>)</span><span id="a2b5" class="ly lz iq nn b gy nx nt l nu nv">row = categories.head(1)</span><span id="9602" class="ly lz iq nn b gy nx nt l nu nv">category_colnames = row.applymap(<strong class="nn ir">lambda</strong> x: x[:-2]).iloc[0, :].tolist()</span><span id="1dd9" class="ly lz iq nn b gy nx nt l nu nv"><em class="lu"># rename the columns of `categories`</em><br/>categories.columns = category_colnames<br/>categories.head()</span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ny"><img src="../Images/09e107921ee8964233c9fb682a093c16.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*HO87TL9GSQibmluzc5eGow.jpeg"/></div></div></figure><p id="4922" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">因为模型使用数字作为输入，所以我将类别值转换为数字 0 或 1。</p><pre class="kg kh ki kj gt no nn np nq aw nr bi"><span id="a16c" class="ly lz iq nn b gy ns nt l nu nv"><strong class="nn ir">for</strong> column <strong class="nn ir">in</strong> categories:<br/>    <em class="lu"># set each value to be the last character of the string</em><br/>    categories[column] = categories[column].astype(str).str[-1]<br/>    <br/>    <em class="lu"># convert column from string to numeric</em><br/>    categories[column] = categories[column].astype(int)<br/>categories.head()</span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nz"><img src="../Images/71e2dd3fa6b7437725998e67be945576.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*peM1TsIB8SNbUMCbI4CLZA.jpeg"/></div></div></figure><p id="5462" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">转换类别列后，我对数据框进行了更改。我用新的类别列替换了原来的类别列。</p><pre class="kg kh ki kj gt no nn np nq aw nr bi"><span id="82c6" class="ly lz iq nn b gy ns nt l nu nv"><em class="lu"># drop the original categories column from `df`</em><br/>df.drop('categories', axis = 1, inplace = <strong class="nn ir">True</strong>)</span><span id="7d86" class="ly lz iq nn b gy nx nt l nu nv"><em class="lu"># concatenate the original dataframe with the new `categories` dataframe</em> df = pd.concat([df, categories], axis = 1) </span><span id="834d" class="ly lz iq nn b gy nx nt l nu nv">df.head()</span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi oa"><img src="../Images/0ced3871c237a955f17dc11cf0a4ed19.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*OM41L2r2EWq7r-fDbEjumw.jpeg"/></div></div></figure><p id="c10b" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">在检查了数据中的重复项后，我删除了它们。</p><pre class="kg kh ki kj gt no nn np nq aw nr bi"><span id="329f" class="ly lz iq nn b gy ns nt l nu nv"><em class="lu"># check number of duplicates</em><br/>df[df.duplicated].shape</span><span id="d0de" class="ly lz iq nn b gy nx nt l nu nv">(170, 40)</span><span id="e3eb" class="ly lz iq nn b gy nx nt l nu nv"><em class="lu"># drop duplicates</em> <br/>df.drop_duplicates(inplace = <strong class="nn ir">True</strong>)</span><span id="b637" class="ly lz iq nn b gy nx nt l nu nv"><em class="lu"># check number of duplicates</em> <br/>df[df.duplicated].count()</span></pre><p id="7598" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">我最终将干净的数据集保存到 SQLite 数据库中。</p><pre class="kg kh ki kj gt no nn np nq aw nr bi"><span id="4596" class="ly lz iq nn b gy ns nt l nu nv"><em class="lu"># Save the clean dataset into a sqlite database.</em><br/>engine = create_engine('sqlite:///disaster.db')<br/>df.to_sql('messages_disaster', engine, index=<strong class="nn ir">False</strong>)</span></pre><h2 id="969c" class="ly lz iq bd ma mb mc dn md me mf dp mg le mh mi mj li mk ml mm lm mn mo mp mq bi translated">ML 管道</h2><p id="4ac6" class="pw-post-body-paragraph kv kw iq kx b ky mr jr la lb ms ju ld le mt lg lh li mu lk ll lm mv lo lp lq ij bi translated">在项目的第二部分，我创建了机器学习管道，用于将灾难信息分类成不同的类别。被称为“管道”的原因是因为这个建模工具由几个步骤组成，这些步骤处理输入以生成输出。在这种情况下，我使用<em class="lu">标记化</em>来处理文本数据。</p><pre class="kg kh ki kj gt no nn np nq aw nr bi"><span id="08ba" class="ly lz iq nn b gy ns nt l nu nv"><em class="lu"># load data from database</em><br/>engine = create_engine('sqlite:///disaster.db')<br/>df = pd.read_sql_table('messages_disaster', con = engine)</span><span id="92ca" class="ly lz iq nn b gy nx nt l nu nv">X = df['message']  <br/>Y = df.drop(['message', 'genre', 'id', 'original'], axis = 1)</span><span id="ef71" class="ly lz iq nn b gy nx nt l nu nv"><em class="lu"># Tokenization function to process text data.</em><br/><strong class="nn ir">def</strong> tokenize(text):<br/>    tokens = word_tokenize(text)<br/>    lemmatizer = WordNetLemmatizer()<br/>    clean_tokens = []<br/>    <strong class="nn ir">for</strong> tok <strong class="nn ir">in</strong> clean_tokens:<br/>        clean_tok = lemmatizer.lemmatize(tok).lower().strip()<br/>        clean_tokens.append(clean_tok)<br/>    <strong class="nn ir">return</strong> clean_tokens</span></pre><p id="c214" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">机器学习管道将在数据集中的 36 个类别上以<code class="fe nk nl nm nn b">message</code>列作为输入和输出分类。这是一个<em class="lu">自然语言处理的问题；</em>即对文本进行处理，从信息中提取含义。是不是很神奇？</p><pre class="kg kh ki kj gt no nn np nq aw nr bi"><span id="b6f8" class="ly lz iq nn b gy ns nt l nu nv">pipeline = Pipeline([<br/>    ('vect', CountVectorizer()),<br/>    ('tfidf', TfidfTransformer()),<br/>    ('clf', MultiOutputClassifier(RandomForestClassifier()))<br/>])</span></pre><p id="46b0" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">就像所有其他 ML 模型一样，我们必须有训练和测试集。原因是我们不希望我们的模型在训练集上表现得非常好，同时在看到新数据时不能正确地对我们的类别进行分类。因此，我们必须只使用数据的子集来训练它，并观察它在测试集上的表现。</p><pre class="kg kh ki kj gt no nn np nq aw nr bi"><span id="a92c" class="ly lz iq nn b gy ns nt l nu nv"><em class="lu"># Split data into train and test tests.</em><br/>X_train, X_test, y_train, y_test = train_test_split(X,Y, test_size = 0.2, random_state = 45)</span><span id="8e45" class="ly lz iq nn b gy nx nt l nu nv"><em class="lu"># Train the model.</em><br/>pipeline.fit(X_train, y_train)</span></pre><p id="2268" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">在测试我的模型时，我希望有一些客观的性能指标。即我会看<em class="lu"> f1 分数</em>，<em class="lu">精度和召回。</em></p><pre class="kg kh ki kj gt no nn np nq aw nr bi"><span id="e67c" class="ly lz iq nn b gy ns nt l nu nv"><em class="lu"># Test the model and print the classification report for each of the 36 categories.</em><br/><strong class="nn ir">def</strong> performance(model, X_test, y_test):<br/>    y_pred = model.predict(X_test)<br/>    <strong class="nn ir">for</strong> i, col <strong class="nn ir">in</strong> enumerate(y_test):<br/>        print(col)<br/>        print(classification_report(y_test[col], y_pred[:, i]))</span><span id="494d" class="ly lz iq nn b gy nx nt l nu nv">performance(pipeline, X_test, y_test)</span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi ob"><img src="../Images/7c4c37d71602ae69a1c4533a70bedbe7.png" data-original-src="https://miro.medium.com/v2/resize:fit:902/format:webp/1*VSShbmEKL1W9fjzKxErnuw.jpeg"/></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk">just a snapshot</figcaption></figure><p id="3079" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">在建立模型时，寻求改进总是一个好主意。尝试调整模型的参数以获得更好的结果。这就是我在这里尝试的。这是相同的过程，但有不同的管道。</p><pre class="kg kh ki kj gt no nn np nq aw nr bi"><span id="4422" class="ly lz iq nn b gy ns nt l nu nv"><em class="lu"># Improve the pipeline.</em><br/>pipeline2 = Pipeline([<br/>    ('vect', CountVectorizer()),<br/>    ('best', TruncatedSVD()),<br/>    ('tfidf', TfidfTransformer()),<br/>    ('clf', MultiOutputClassifier(AdaBoostClassifier()))<br/>])</span><span id="9ee1" class="ly lz iq nn b gy nx nt l nu nv"><em class="lu"># Train the adjusted pipeline.</em> <br/>pipeline2.fit(X_train, y_train)</span><span id="ef7b" class="ly lz iq nn b gy nx nt l nu nv"># Check the performance of the adjusted model.<br/>performance(pipeline2, X_test, y_test)</span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi oc"><img src="../Images/9936e3c59898b4aeefbc289f25f1848c.png" data-original-src="https://miro.medium.com/v2/resize:fit:906/format:webp/1*fcMfPIlfyxnrtuX5kbaM4Q.jpeg"/></div></figure><p id="a44c" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">我更进一步，使用了一组不同的参数和一定范围的值。在<em class="lu"> GridSearchCV </em>的帮助下，模型选择最佳参数。</p><pre class="kg kh ki kj gt no nn np nq aw nr bi"><span id="9d1a" class="ly lz iq nn b gy ns nt l nu nv">parameters2 = { <br/>              'tfidf__use_idf': (<strong class="nn ir">True</strong>, <strong class="nn ir">False</strong>), <br/>              'clf__estimator__n_estimators': [50, 100],<br/>              'clf__estimator__learning_rate': [1,2] }</span><span id="6731" class="ly lz iq nn b gy nx nt l nu nv">cv2 = GridSearchCV(pipeline2, param_grid=parameters2)</span><span id="4a4e" class="ly lz iq nn b gy nx nt l nu nv">cv2.fit(X_train, y_train)</span><span id="d2d9" class="ly lz iq nn b gy nx nt l nu nv">performance(cv2, X_test, y_test)</span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi od"><img src="../Images/f4eb22fc9f90a83f25c282e3d3930b6d.png" data-original-src="https://miro.medium.com/v2/resize:fit:960/format:webp/1*_zTraOfIWJjc9SW33fN0jA.jpeg"/></div></figure><h2 id="8bea" class="ly lz iq bd ma mb mc dn md me mf dp mg le mh mi mj li mk ml mm lm mn mo mp mq bi translated"><strong class="ak">构建 API </strong></h2><p id="67f6" class="pw-post-body-paragraph kv kw iq kx b ky mr jr la lb ms ju ld le mt lg lh li mu lk ll lm mv lo lp lq ij bi translated">最后，我以制作一个 API 来结束这个项目，这个 API 接收一条灾难消息，并将其分类为最可能的灾难类别。这样，我们可以帮助救灾组织更好地了解发生了什么类型的灾难，以及需要哪种援助。</p><h2 id="560b" class="ly lz iq bd ma mb mc dn md me mf dp mg le mh mi mj li mk ml mm lm mn mo mp mq bi translated"><strong class="ak">结束语</strong></h2><p id="75ba" class="pw-post-body-paragraph kv kw iq kx b ky mr jr la lb ms ju ld le mt lg lh li mu lk ll lm mv lo lp lq ij bi translated">如果你做到了这一步，非常感谢你的阅读！希望这能让你了解机器学习有多有用。以及它的应用范围有多广。通过了解如何处理文本数据和实现模型，我们可以真正挽救人们的生命。说到模型，这是我的<a class="ae oe" href="https://github.com/andreigalanciuc/RECOMMENDATION-SYSTEM-WITH-IBM" rel="noopener ugc nofollow" target="_blank"> <strong class="kx ir"> github </strong> </a>上的完整项目。</p><p id="33a7" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">祝你一切顺利，永远幸福:)</p><p id="6c32" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated"><strong class="kx ir">附:我们来连线一下</strong> <a class="ae oe" href="https://www.linkedin.com/in/andreigalanchuk/" rel="noopener ugc nofollow" target="_blank"> <strong class="kx ir"> Linkedin </strong> </a> <strong class="kx ir">！</strong></p></div></div>    
</body>
</html>