# ç”¨äºå“ç‰Œæå‡å’Œè¯é¢˜è·Ÿè¸ªçš„å®æ—¶ Twitter æƒ…æ„Ÿåˆ†æ(ç¬¬ 2/3 ç« )

> åŸæ–‡ï¼š<https://towardsdatascience.com/real-time-twitter-sentiment-analysis-for-brand-improvement-and-topic-tracking-chapter-2-3-1caf05346721?source=collection_archive---------6----------------------->

## è¡Œä¸šä¸­çš„æ•°æ®ç§‘å­¦

## ä½¿ç”¨ REã€TextBlobã€NLTK å’Œ Plotly è¿›è¡Œ Twitter æƒ…æ„Ÿåˆ†æå’Œäº¤äº’å¼æ•°æ®å¯è§†åŒ–

![](img/539cede38ac9d047756c6eb73bd50e28.png)

Photo by [Jonatan Pie](https://unsplash.com/@r3dmax?utm_source=medium&utm_medium=referral) on [Unsplash](https://unsplash.com?utm_source=medium&utm_medium=referral)

æ•™ç¨‹å°†æ•™ä½ å¦‚ä½•ä¸€æ­¥ä¸€æ­¥åœ°åœ¨ Twitter æ•°æ®ä¸Šåº”ç”¨ 1) **è‡ªç„¶è¯­è¨€å¤„ç†**å’Œ**æƒ…æ„Ÿåˆ†æ**ï¼Œ2)åˆ©ç”¨ **Plotly** æ„å»ºä¸€ä¸ª**äº¤äº’å¼æ•°æ®å¯è§†åŒ–**ã€‚

è¿™æ˜¯ä¸€ä¸ªç‹¬ç«‹çš„ç»„ä»¶ï¼Œç”¨äºæ‰§è¡Œæƒ…ç»ªåˆ†æå’Œè¯é¢˜è·Ÿè¸ªï¼Œå¹¶åœ¨ Jupiter Notebook ä¸Šæ„å»ºåˆ†æä»ªè¡¨æ¿ï¼Œå°½ç®¡å®ƒæ˜¯æˆ‘çš„ç»¼åˆå®æ—¶ Twitter ç›‘æ§ç³»ç»Ÿæ•™ç¨‹çš„ç¬¬äºŒéƒ¨åˆ†ã€‚åœ¨å‰ä¸€ç« ä¸­è§£é‡Šå¹¶å®ç°äº†æµ Twitter æ•°æ®æ”¶é›†ã€‚

*   [**ç¬¬ 1 ç« **](/real-time-twitter-sentiment-analysis-for-brand-improvement-and-topic-tracking-chapter-1-3-e02f7652d8ff) **:** ä½¿ç”¨ Tweepyã€MySQLã€& Python çš„æµ Twitter API æ”¶é›† Twitter æ•°æ®
*   **ç¬¬äºŒç« (ä½ æ¥äº†ï¼):**ä½¿ç”¨ REã€TextBlobã€NLTK å’Œ Plotly è¿›è¡Œ Twitter æƒ…æ„Ÿåˆ†æå’Œäº¤äº’å¼æ•°æ®å¯è§†åŒ–
*   [**ç¬¬ä¸‰ç« **](http://bit.ly/2msOUbR) **:** ä½¿ç”¨ Python ä¸­çš„ Dash & Plotly åœ¨ Heroku ä¸Šéƒ¨ç½²ä¸€ä¸ªå®æ—¶çš„ Twitter åˆ†æ Web App
*   **ç¬¬ 4 ç« **(å¯é€‰) **:** ä½¿ç”¨ Scalaã€Kafka å’Œ Spark Streaming å®ç°æµåª’ä½“ Twitter æƒ…æ„Ÿåˆ†æçš„å¹¶è¡ŒåŒ–

![](img/a36e56712db16599d87c4dbb3af76bea.png)

Data Visualization based on Plotly in this Chapter

ä¸Šé¢çš„[](https://nbviewer.jupyter.org/github/Chulong-Li/Real-time-Sentiment-Tracking-on-Twitter-for-Brand-Improvement-and-Trend-Recognition/blob/master/Trend_Analysis_Complex.ipynb)**åˆ†æä»ªè¡¨æ¿(å¸¦å®Œæ•´ä»£ç )å°±æ˜¯æˆ‘ä»¬ä»Šå¤©è¦åšçš„ï¼Œå®ƒä¸ºä¸‹ä¸€ç« çš„ [**å®æ—¶ Twitter ç›‘æ§ Web App**](http://bit.ly/30VS87a) å¥ å®šäº†åŸºç¡€ï¼Œå› ä¸º Dash(python framework for analytical Web apps)æ˜¯åœ¨ Plotly ä¹‹ä¸Šç¼–å†™çš„ã€‚æŸ¥çœ‹æˆ‘çš„ [**GitHub å›è´­**](http://bit.ly/33UKT12) äº†è§£æ›´å¤šè¯¦æƒ…ã€‚**

**![](img/31b488cada146cc088031ad457da5918.png)**

**Web App based on Dash-Plotly in next chapter**

****ç¬¬**ç« çš„æŠ€æœ¯æ ˆ:REï¼ŒNLTKï¼ŒTextBlobï¼ŒPlotlyï¼ŒMySQLï¼ŒPython (timeï¼Œdatetimeï¼Œmathï¼Œitertools)**

*   **[**RE**](https://docs.python.org/3.7/library/re.html) : **æ­£åˆ™è¡¨è¾¾å¼**è¯†åˆ«ç»™å®šå­—ç¬¦åºåˆ—ä¸­æ˜¯å¦å­˜åœ¨æ¨¡å¼çš„æ“ä½œ**
*   **[**NLTK**](https://www.nltk.org) : **è‡ªç„¶è¯­è¨€**å·¥å…·åŒ…ï¼Œæ„å»º Python ç¨‹åºå¤„ç†äººç±»è¯­è¨€æ•°æ®çš„é¢†å…ˆå¹³å°**
*   **[**TextBlob**](https://textblob.readthedocs.io/en/dev/) : **è‡ªç„¶è¯­è¨€å¤„ç†**åº“ï¼Œç”¨äºå¤„ç†æ–‡æœ¬æ•°æ®ï¼Œæä¾›ä¸€ä¸ª**ç®€å•çš„ API** ç”¨äºæ½œå…¥æ™®é€šçš„ NLPã€‚**
*   **[](https://plot.ly/python/)**:ä¸€ä¸ª**äº¤äº’å¼**ï¼Œå¼€æºçš„ï¼ŒåŸºäºæµè§ˆå™¨çš„**Python å›¾å½¢åº“******

## ****åŠ è½½å’Œå‡†å¤‡ Twitter æ•°æ®****

****é¦–å…ˆï¼Œæˆ‘ä»¬éœ€è¦ä»æ•°æ®æºä¸­æå– Twitter æ•°æ®ã€‚ç®€å•èµ·è§å¯ä»¥ç›´æ¥ä»`sample_data.csv`å¼€å§‹è¯»ã€‚****

```
**df = pd.read_csv("sample_data.csv")**
```

****æˆ–è€…ä»¥ä¸€ç§æ›´æ­£å¼çš„æ–¹å¼ï¼Œä»æˆ‘ä»¬çš„ MySQL æ•°æ®åº“ä¸­æå–æ•°æ®ï¼Œè¯¥æ•°æ®åº“å·²ç»åœ¨ç¬¬ 1 ç« ä¸­å»ºç«‹å¹¶å¡«å……äº†å®æ—¶ Twitter æ•°æ®ã€‚****

```
**db_connection = mysql.connector.connect(
    host="localhost",
    user="root",
    passwd="password",
    database="TwitterDB",
    charset = 'utf8'
 )
time_now = datetime.datetime.utcnow()
time_10mins_before = datetime.timedelta(hours=0,minutes=10)) \
    .strftime('%Y-%m-%d %H:%M:%S'
time_interval = time_now - time_10mins_before**
```

****è¯»å–è¿‡å» 30 åˆ†é’Ÿå†…å‘å¸ƒçš„æ•°æ®ï¼Œå¹¶é€šè¿‡ SQL æŸ¥è¯¢å°†å…¶åŠ è½½åˆ° Pandas DataFrame ä¸­ã€‚****

```
**query = "SELECT id_str, text, created_at, polarity,          \
         user_location FROM **{}** WHERE created_at >= '**{}**'"     \
        .format(settings.TABLE_NAME, time_interval)
df = pd.read_sql(query, con=db_connection)**
```

****ç„¶åæŠŠ DATETIME (MySQL æ•°æ®ç±»å‹)è½¬æ¢æˆ Datetime (Pandas æ•°æ®ç±»å‹)ã€‚****

```
***# UTC for date time at default*
df['created_at'] = pd.to_datetime(df['created_at'])**
```

## ****ä½¿ç”¨[æ–‡æœ¬å—](https://textblob.readthedocs.io/en/dev/)è¿›è¡Œæƒ…æ„Ÿåˆ†æ****

****æƒ…æ„Ÿåˆ†æçš„æ ¸å¿ƒæ˜¯ä½¿ç”¨ TextBlobï¼Œä»¥ä¾¿ä» tweet æ–‡æœ¬ä¸­æå–**ææ€§** & **ä¸»è§‚æ€§**ï¼Œè¿™å®é™…ä¸Šæ˜¯ä¸Šä¸€ç« ä¸ºäº†æ›´å¥½åœ°å­˜å‚¨æ•°æ®è€Œè¿›è¡Œçš„æ•°æ®é¢„å¤„ç†ã€‚è´Ÿé¢æ¨æ–‡ä»£è¡¨-1ï¼Œæ­£é¢æ¨æ–‡ä»£è¡¨+1ï¼Œä¸­æ€§æ¨æ–‡ä»£è¡¨ 0ã€‚****

```
**from **textblob** import TextBlob
sentiment = TextBlob(tweet_text).sentiment
polarity = sentiment.polarity
subjectivity = sentiment.subjectivity**
```

****å°†æ•´ä¸ªæ—¶é—´åºåˆ—è½¬æ¢ä¸º 2 ç§’ä¸€ç»„ï¼Œå¹¶è®¡ç®—æ¯ä¸ªæ—¶é—´é—´éš”ç»„ä¸­æ¯ç§ææ€§(ä¾‹å¦‚-1ã€0 å’Œ 1)çš„æƒ…ç»ªæ•°é‡ã€‚****

****åº”ç”¨**æ‹†æ ˆ**æŠ€æœ¯ä»¥ç¡®ä¿æ¯ç»„ä¸­çš„æ‰€æœ‰ç±»åˆ«éƒ½è¢«æ˜¾ç¤ºï¼Œå³ä½¿å…¶ä¸­ä¸€ä¸ªç±»åˆ«æ²¡æœ‰ä»»ä½•å€¼ã€‚å› ä¸ºæˆ‘ä»¬åªæ˜¾ç¤ºæœ€è¿‘ 30 åˆ†é’Ÿå†…å‘å¸ƒçš„å®æ—¶æ¨æ–‡ï¼Œæ‰€ä»¥åœ¨å®è·µä¸­ï¼Œ2 ç§’é—´éš”çš„ç»„æœ€å¥½æ˜¾ç¤ºåœ¨å±å¹•ä¸Šã€‚ä¹‹åï¼Œé‡å‘½åè¿™äº›åˆ—ï¼Œä½¿å®ƒä»¬èƒ½å¤Ÿè‡ªæˆ‘è§£é‡Šã€‚****

```
***# Clean and transform data to enable time series*
result = df.groupby(                                        \
      [pd.Grouper(key='created_at', freq='2s'), 'polarity'] \
    ).count().unstack(fill_value=0).stack().reset_index()

result = result.rename(columns=                             \
    { "id_str": "Num of '{}' mentions".format(TRACK_WORD),  \
      "created_at":"Time in UTC" })**
```

****ä»¥ 2 ç§’çš„é—´éš”è®°å½•æ—¶é—´åºåˆ—ï¼Œä»¥ä¾¿è¿›ä¸€æ­¥ä½¿ç”¨ç´¢å¼•ã€‚****

```
**time_series = result["Time in UTC"][result['polarity']==0]  \ 
    .reset_index(drop=**True**)**
```

****ä½¿ç”¨ç®€å•çš„[**Plotly Express**](https://plot.ly/python/plotly-express/)å¿«é€Ÿå¯è§†åŒ–æŠ˜çº¿å›¾ã€‚æ³¨æ„:Plotly Express æ˜¯ä¸€ä¸ªç®€æ´ã€ä¸€è‡´ã€é«˜çº§çš„`plotly.graph_objects`åŒ…è£…å™¨ï¼Œç”¨äºå¿«é€Ÿæ•°æ®æ¢ç´¢å’Œå›¾å½¢ç”Ÿæˆã€‚****

```
**import **plotly.express** as px
fig = px.line(result, x='Time in UTC',                      \
    y="Num of '{}' mentions".format(TRACK_WORD),            \
    color='polarity')
fig.show()**
```

****![](img/a65d5a03593583270743c7479da41d20.png)****

****Line Chart for Sentiment Analysis****

## ******ä½¿ç”¨ RE çš„è‡ªç„¶è¯­è¨€å¤„ç†çš„ä¸»é¢˜è·Ÿè¸ª& NLTK******

****ä¸ºäº†è·Ÿè¸ªæ¨æ–‡ä¸­æœ€çƒ­é—¨çš„è¯æˆ–æœ€å¸¸ç”¨çš„ç¬¦å·ï¼Œæˆ‘ä»¬åŠ å…¥æ‰€æœ‰æ¨æ–‡ï¼Œåˆ é™¤ URLï¼Œæ¸…é™¤â€œRTâ€å’Œâ€œT36â€(ä¹Ÿç§°ä¸ºâ€œT37â€)ampï¼›ã€‚)ç¬¦å·ï¼Œå¹¶å°†æ‰€æœ‰å­—ç¬¦è½¬æ¢æˆå°å†™ã€‚****

```
**content = ' '.join(df["text"])
content = re.sub(r"http\S+", "", content)
content = content.replace('RT ', ' ').replace('&amp;', 'and')
content = re.sub('[^A-Za-z0-9]+', ' ', content)
content = content.lower()**
```

****ç¬¬ä¸€æ¬¡ä½¿ç”¨ python è„šæœ¬ä» NLTK ä¸‹è½½è¿™ä¸¤ä¸ªæ–‡ä»¶ã€‚ [**Punkt å¥å­åˆ†è¯å™¨**](https://www.nltk.org/api/nltk.tokenize.html#module-nltk.tokenize.punkt) ç”¨äºé€šè¿‡ä½¿ç”¨æ— ç›‘ç£ç®—æ³•å°†æ–‡æœ¬åˆ†æˆä¸€ç³»åˆ—å¥å­ã€‚****

```
***import nltk
nltk.download('punkt')*
*nltk.download('stopwords')***
```

****ç„¶å**ä»æ‰€æœ‰æ¨æ–‡ä¸­å¯¹æ•´ä¸ªæ–‡æœ¬è¿›è¡Œ**åˆ†è¯ï¼Œä½¿ç”¨ [**åœç”¨è¯**](https://www.geeksforgeeks.org/removing-stop-words-nltk-python/) å»é™¤å¸¸ç”¨è¯ï¼Œå¹¶æå–æ‰€æœ‰è¯çš„ [**é¢‘ç‡åˆ†å¸ƒ**](http://www.nltk.org/api/nltk.html?highlight=freqdist#nltk.probability.FreqDist) ä¸­æœ€å¸¸è§çš„ 10 ä¸ªè¯ã€‚****

```
**from **nltk.probability** import FreqDist
from **nltk.tokenize** import word_tokenize
from **nltk.corpus** import stopwordstokenized_word = word_tokenize(content)
stop_words=set(stopwords.words("english"))
filtered_sent=[]
**for** w **in** tokenized_word:
    **if** w **not** **in** stop_words:
        filtered_sent.append(w)
fdist = FreqDist(filtered_sent)
fd = pd.DataFrame(fdist.most_common(10),                    \
    columns = ["Word","Frequency"]).drop([0]).reindex()**
```

****å†æ¬¡ä½¿ç”¨ç®€å•çš„ [**å›¾å½¢è¡¨è¾¾**](https://plot.ly/python/plotly-express/) å¿«é€Ÿå¯è§†åŒ–æ¡å½¢å›¾ã€‚****

```
**import **plotly.express** as px
fig = px.bar(fd, x="Word", y="Frequency")
fig.update_traces(marker_color='rgb(240,128,128)',          \
    marker_line_color='rgb(8,48,107)',                      \
    marker_line_width=1.5, opacity=0.8)
fig.show()**
```

****![](img/07d87ddeb6656721a8593ad008f0f852.png)****

****Bar Chart for Topic Tracking****

## ****æ–‡æœ¬å¤„ç†ä¸­çš„åœ°ç†åˆ†å‰²è¯†åˆ«****

****ä¸ºäº†æ¢ç´¢ç”¨æˆ·çš„åœ°ç†åˆ†å¸ƒï¼Œæˆ‘ä»¬éœ€è¦é€šè¿‡ä»–ä»¬çš„**ç”¨æˆ·èµ„æ–™**æ¥è¯†åˆ«ä»–ä»¬çš„**ä½ç½®**ï¼Œè€Œä¸æ˜¯é™„æœ‰æ¨æ–‡çš„ä½ç½®ï¼Œå› ä¸ºåªæœ‰ä¸åˆ° 1%çš„äººä¼šé™„ä¸Šä»–ä»¬çš„æ¨æ–‡ä½ç½®ã€‚ç„¶è€Œï¼Œæ ¹æ®ç”¨æˆ·ç®€æ¡£ä¸­çš„ä½ç½®ï¼Œå®ƒä»¬å¯èƒ½åŒ…æ‹¬ä¸€ä¸ªæˆ–å¤šä¸ªå¿ã€åŸå¸‚ã€å·ã€å›½å®¶æˆ–æ˜Ÿçƒã€‚å› æ­¤ï¼Œå°†è¿™äº›æ•°æ®è¿‡æ»¤æˆç¾å›½å·çº§ä½ç½®æ˜¯åœ°ç†åˆ†æ®µè¯†åˆ«çš„æ ¸å¿ƒã€‚****

****å°†æ‰€æœ‰**çŠ¶æ€å**åŠå…¶**ç¼©å†™**è®¾ç½®ä¸ºå¸¸é‡ï¼Œç”¨äºè¿›ä¸€æ­¥çš„ç¼©å†™-åç§°è½¬æ¢ã€‚****

```
**STATES = ['Alabama', 'AL', 'Alaska', 'AK',                    \ 
    ...... # Text hided for readability                       \
    'WV', 'Wisconsin', 'WI', 'Wyoming', 'WY']STATE_DICT = dict(itertools.zip_longest(*[iter(STATES)] * 2, fillvalue=""))
INV_STATE_DICT = dict((v,k) **for** k,v **in** STATE_DICT.items())**
```

****é€šè¿‡**è¿­ä»£**å·ååˆ—è¡¨å’Œç”¨æˆ·ä½ç½®åˆ—è¡¨ï¼Œä»ä»–ä»¬çš„ä½ç½®æå–å·ä¿¡æ¯ã€‚****

```
**is_in_US=[]
geo = df[['user_location']]
df = df.fillna(" ")
**for** x **in** df['user_location']:
    check = **False**
    **for** s **in** STATES:
        **if** s **in** x:
            is_in_US.append(STATE_DICT[s] **if** s **in** STATE_DICT **else** s)
            check = **True**
            **break**
    **if** **not** check:
        is_in_US.append(**None**)

geo_dist = pd.DataFrame(is_in_US, columns['State'])           \
    .dropna().reset_index()**
```

****ç»Ÿè®¡ç¾å›½å„å·å‘å¸ƒçš„æ¨æ–‡æ•°é‡ï¼Œç”¨**å¯¹æ•°**æ•°å­—é¿å¼€**æå€¼**(å¦‚åŠ å· 500+ï¼ŒåŒ—è¾¾ç§‘ä»–å· 3)æ›´å¥½çš„å¯è§†åŒ–ã€‚****

```
**geo_dist = geo_dist.groupby('State').count().                 \ 
    rename(columns={"index": "Number"}).sort_values(          \
    by=['Number'], ascending=**False**).reset_index()
geo_dist["Log Num"] = geo_dist["Number"]                      \
    .apply(**lambda** x: math.log(x, 2))**
```

****ä¸ºç¨åä»ªè¡¨æ¿ä¸Šçš„æ‚¬åœæ–‡æœ¬æ·»åŠ è¯´æ˜æ€§æ–‡æœ¬ä¿¡æ¯ã€‚****

```
**geo_dist['Full State Name'] = geo_dist['State']               \
    .apply(**lambda** x: INV_STATE_DICT[x])
geo_dist['text'] = geo_dist['Full State Name'] + '<br>' +     \
    'Num: ' + geo_dist['Number'].astype(str)**
```

****è¿™ä¸€æ¬¡ï¼Œæˆ‘ä»¬ä½¿ç”¨ **Plotly** (ä¸æ˜¯ Plotly Express)æ¥å¯è§†åŒ–ç¾å›½åœ°å›¾ã€‚****

******æ³¨** : `plotly.graph_objects`æ˜¯ Plotly åº“çš„æ ¸å¿ƒï¼ŒåŒ…å«æ›´å¤šé€šç”¨å‡½æ•°ï¼Œç”¨äºæ›´å¤æ‚çš„ç”¨é€”ã€‚`locationmode`æ˜¯â€œä»“ä½â€ä¸­ä»“ä½åŒ¹é…æ¡ç›®çš„é›†åˆã€‚`text`æ˜¯æ‚¬åœæ–‡æœ¬ã€‚`marker_line_color`æ˜¯çŠ¶æ€é—´çº¿æ¡æ ‡è®°çš„é¢œè‰²ã€‚è®¾ç½®`geo_scope`å°†åœ°å›¾èŒƒå›´é™åˆ¶åœ¨ç¾å›½ã€‚****

```
**import **plotly.graph_objects** as go
fig = go.Figure(data=go.Choropleth(
    locations=geo_dist['State'], *# Spatial coordinates*
    z = geo_dist['Log Num'].astype(float), *# Data to be color-coded*

    locationmode = 'USA-states', 
    colorscale = "Reds",
    text=geo_dist['text'],
    marker_line_color='white', *# line markers between states*
    colorbar_title = "Numbers in Log2"
))

fig.update_layout(
    geo_scope='usa', 
)

fig.show()**
```

****![](img/2af3ddfb23dfccef1bbff1c2c9ff097d.png)********![](img/6c5c7de27640af261e6cca0afff5afb0.png)****

****Photo by [Karsten WÃ¼rth (@karsten.wuerth)](https://unsplash.com/@karsten_wuerth?utm_source=medium&utm_medium=referral) on [Unsplash](https://unsplash.com?utm_source=medium&utm_medium=referral)****

## ****å¸¦æœ‰ [Plotly](https://plot.ly/python/) çš„äº¤äº’å¼åˆ†æä»ªè¡¨æ¿****

****ç°åœ¨æˆ‘ä»¬å¯ä»¥ä½¿ç”¨`Plotly.subplots`å°†æ‰€æœ‰æ•°æ®å¯è§†åŒ–éƒ¨åˆ†é›†æˆåˆ°ä¸€ä¸ª**ä»ªè¡¨æ¿**ä¸­ã€‚åŒæ—¶æ˜¾ç¤ºå¤šä¸ªå›¾å½¢å¯ä»¥å¤§å¤§æé«˜é˜…è¯»æ•ˆç‡ï¼Œå¢å¼ºå¤šä¸ªè§è§£ä¹‹é—´çš„å¯æ¯”æ€§ã€‚****

****![](img/9496ae5652530b37b788930157afef29.png)****

****é¦–å…ˆåˆ›å»ºä¸€ä¸ªåŒ…å« 2 ä¸ª **Ã—** 2 ä¸ª**æ”¯çº¿å‰§æƒ…**çš„**å‰§æƒ…å›¾**ï¼Œå·¦è¾¹æ˜¯**çº¿å›¾**ï¼Œå³ä¸Šè§’æ˜¯**è´´å›¾**ï¼Œå³ä¸‹è§’æ˜¯**æ¡å½¢å›¾**ã€‚****

```
**from **plotly.subplots** import make_subplots
fig = make_subplots(
        rows=2, cols=2,
        column_widths=[1, 0.4],
        row_heights=[0.6, 0.4],
        specs=[[{"type": "scatter", "rowspan": 2}, 
                {"type": "choropleth"}],
               [**None**, {"type": "bar"}]]
        )**
```

****ä½¿ç”¨`add_trace`å’Œ`go.Scatter`åœ¨ç¬¬ä¸€ä¸ªå­æƒ…èŠ‚ä¸­æ·»åŠ ä¸‰è¡Œ**è´Ÿç‰‡ã€ä¸­æ€§ç‰‡å’Œæ­£ç‰‡**ã€‚å¦å¤–ï¼Œ`row`å’Œ`col`ä»£è¡¨è¿™ä¸ªæ”¯çº¿å‰§æƒ…åœ¨å¤§å›¾ä¸­çš„ä½ç½®ã€‚****

```
**fig.add_trace(go.Scatter(
    x=time_series,
    y=result["Num of '**{}**' mentions"                     \
        .format(settings.TRACK_WORDS[0])]               \
        [result['polarity']==0].reset_index(drop=**True**), \
    name="Neural",
    opacity=0.8), row=1, col=1) fig.add_trace(go.Scatter(
    x=time_series,
    y=result["Num of '**{}**' mentions"                     \
        .format(settings.TRACK_WORDS[0])]               \ 
        [result['polarity']==-1].reset_index(drop=**True**),
    name="Negative",
    opacity=0.8), row=1, col=1)fig.add_trace(go.Scatter(
    x=time_series,
    y=result["Num of '**{}**' mentions"                     \
        .format(settings.TRACK_WORDS[0])]               \
        [result['polarity']==1].reset_index(drop=**True**), \
    name="Positive",
    opacity=0.8), row=1, col=1)**
```

****ä½¿ç”¨`add_trace`å’Œ`go.Bar`æ·»åŠ ä¸»é¢˜é¢‘ç‡åˆ†å¸ƒçš„**æ¡å½¢å›¾**ã€‚æ‚¨å¯ä»¥ä½¿ç”¨`rgb(xx,xx,xx)`æˆ–`rgba(xx,xx,xx,x)`æ”¹å˜å›¾ä¸­æŸäº›å…ƒç´ çš„é¢œè‰²ã€‚****

```
**fig.add_trace(go.Bar(x=fd["Word"], y=fd["Frequency"],       \
    name="Freq Dist"), row=2, col=2)

fig.update_traces(marker_color='rgb(59, 89, 152)',          \
    marker_line_color='rgb(8,48,107)',                      \
    marker_line_width=0.5, opacity=0.7, row=2, col=2)**
```

****ç„¶ååœ¨å³ä¸Šè§’æ’å…¥**åœ°å›¾**ï¼Œå¹¶è®¾ç½®ä½ç½®å’Œæ¯ä¸ªä½ç½®çš„ç¼–å·ã€‚****

```
**fig.add_trace(go.Choropleth(
    locations=geo_dist['State'], *# Spatial coordinates*
    z = geo_dist['Log Num'].astype(float), *# Data to be color-coded*
    locationmode = 'USA-states', 
    colorscale = "Blues",
    text=geo_dist['text'], *# hover text*
    showscale=**False**,
    geo = 'geo'
    ), row=1, col=2)**
```

****åœ¨æˆ‘ä»¬çš„å›¾çš„å¸ƒå±€ä¸­æ·»åŠ **æ ‡é¢˜**ï¼Œç¼©å°æˆ‘ä»¬åœ°å›¾çš„**åœ°ç†èŒƒå›´**ï¼Œå°†**æ¨¡æ¿ä¸»é¢˜**å˜ä¸ºæš—ï¼Œä½¿ç”¨`go.layout.Annotation`ä¸ºå¸ƒå±€æ·»åŠ  [**æ ‡æ³¨**](https://plot.ly/python/text-and-annotations/) ã€‚****

```
**fig.update_layout(
    title_text =                                            \
      "Real-time tracking '**{}**' mentions on Twitter **{}** UTC"  \
      .format(settings.TRACK_WORDS[0]        
        ,datetime.datetime.utcnow().strftime('%m-%d %H:%M') \
      ),
    geo = dict(
        scope='usa',
    ),
    template="plotly_dark",
    margin=dict(r=20, t=50, b=50, l=20),
    annotations=[
        go.layout.Annotation(
            text="Source: Twitter",
            showarrow=**False**,
            xref="paper",
            yref="paper",
            x=0,
            y=0)
    ],
    showlegend=**False**,
    xaxis_rangeslider_visible=**True** )**
```

****æœ€åï¼Œæ˜¾ç¤ºå•ä¸€å›¾å½¢ä¸­çš„æ‰€æœ‰æ”¯çº¿å‰§æƒ…ã€‚****

```
**fig.show()**
```

******ä½œè€…çš„è¯**:è¿™ä¸€ç« æœ‰ç‚¹å¤æ‚ï¼Œå› ä¸ºå®ƒä½¿ç”¨ NLP å’Œæƒ…æ„Ÿåˆ†ææ–¹æ³•å°†æ•°æ®ç‚¹è½¬åŒ–ä¸ºæ´å¯ŸåŠ›ã€‚é€šè¿‡ä½¿ç”¨å…ˆè¿›çš„è‡ªç„¶è¯­è¨€å¤„ç†æ–¹æ³•ï¼Œå¯ä»¥å®ç°å¯¹ä¸»é¢˜è·Ÿè¸ªçš„è¿›ä¸€æ­¥æ”¹è¿›ã€‚****

****ä¸‹ä¸€ç« å°†æ˜¯æœ€æ¿€åŠ¨äººå¿ƒçš„éƒ¨åˆ†ï¼Œä½¿ç”¨ Dash åœ¨ Heroku æœåŠ¡å™¨ä¸Šé›†æˆå’Œéƒ¨ç½²æ‰€æœ‰åŠŸèƒ½ã€‚ä¸€å¦‚æ—¢å¾€ï¼Œæˆ‘æ„Ÿè°¢æ‚¨çš„ä»»ä½•åé¦ˆï¼ğŸ˜ƒ****

******9 æœˆ 20 æ—¥æ›´æ–°:** [ç¬¬ä¸‰ç« ](http://bit.ly/2msOUbR)å·²å‡ºç‰ˆï¼****