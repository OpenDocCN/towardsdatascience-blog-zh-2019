<html>
<head>
<title>Indian Actors Classification using Deep Neural Networks</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用深度神经网络的印度演员分类</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/indian-actors-classification-using-deep-neural-networks-8552573f39aa?source=collection_archive---------22-----------------------#2019-05-06">https://towardsdatascience.com/indian-actors-classification-using-deep-neural-networks-8552573f39aa?source=collection_archive---------22-----------------------#2019-05-06</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><figure class="gl gn jo jp jq jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi jn"><img src="../Images/cef6f7e7b5694c9ed507819c7bb56f42.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*S_mvNp9jfontb4WoUN5lFQ.png"/></div></div></figure><p id="35d7" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">如果你需要使用深度网络对你最喜欢的演员进行分类，该怎么办？</p><p id="a4d3" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">在这篇文章中，我想演示使用神经网络的多类分类。</p><p id="bb02" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">对于数据集，我已经收集了印度演员的图像样本[萨尔曼·可汗(401 张图像)、沙鲁克·汗(411 张图像)和阿米尔·可汗(433 张图像)]到单独的文件夹中。]</p><p id="2809" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">我们的问题陈述包括使用深度神经网络将印度演员的样本图像分类到正确的标签中，并在测试数据集上训练模型和计算准确度。</p><p id="98b9" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">让我们开始练习吧</p><p id="c29e" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">1.首先导入要使用的必要库。对于神经网络，我使用了 Keras 以及 numpy、pandas、matplotlib、cv2 和 seaborn。</p><pre class="kw kx ky kz gt la lb lc ld aw le bi"><span id="d86a" class="lf lg iq lb b gy lh li l lj lk">import numpy as np<br/>import pandas as pd<br/>import seaborn as sns<br/>import matplotlib.pyplot as plt<br/>from keras.models import Sequential <br/>from keras.layers import Dense<br/>from keras.utils import to_categorical<br/>from keras.layers import Flatten,MaxPooling2D,Conv2D,LeakyReLU<br/>from keras import optimizers</span></pre><p id="ad91" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">2.数据集包括对应于每个印度演员的图像的命名文件夹。将文件夹中的图像加载到 numpy 数组中。此外，转换所有的图像大小为常数大小，即(64*64)或(128*128)和可视化的一类。</p><pre class="kw kx ky kz gt la lb lc ld aw le bi"><span id="215b" class="lf lg iq lb b gy lh li l lj lk">import cv2<br/>import os<br/>def load_images_from_folder(folder):<br/>    images = []<br/>    for filename in os.listdir(folder):<br/>        img = cv2.imread(os.path.join(folder,filename))<br/>        if img is not None:<br/>            img1=cv2.resize(img,(64,64))<br/>            images.append(img1)<br/>    return images</span><span id="392a" class="lf lg iq lb b gy ll li l lj lk"><strong class="lb ir">#Load the images </strong><br/>amir=load_images_from_folder('./AamirKhan/')<br/>salman=load_images_from_folder('./SalmanKhan/')<br/>shahruk=load_images_from_folder('./ShahrukhKhan/')</span><span id="b7e6" class="lf lg iq lb b gy ll li l lj lk">train_amir = np.array(amir)<br/>train_salman = np.array(salman)<br/>train_shahruk= np.array(shahruk)</span><span id="f07b" class="lf lg iq lb b gy ll li l lj lk"><strong class="lb ir">#Visualize the images </strong><br/>fig = plt.figure(figsize=(20,5))<br/>for i in range(36):<br/>    ax = fig.add_subplot(3, 12, i + 1, xticks=[], yticks=[])<br/>    ax.imshow(np.squeeze(salman[i]))</span></pre><figure class="kw kx ky kz gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi lm"><img src="../Images/c2dc48978ae5e83f300af879b5a22850.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*QGMNdtljyvKJLFy8sLDPlw.png"/></div></div></figure><p id="593d" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">3.下一步是为图像创建标签，因为每个印度演员都有对应的文件夹。我创建了一个 numpy 数组，其长度与特定的类[阿米尔·可汗]相同，并给定标签为零。类似地，萨尔曼·可汗为 1，沙鲁克·汗为 2。</p><pre class="kw kx ky kz gt la lb lc ld aw le bi"><span id="a9cc" class="lf lg iq lb b gy lh li l lj lk">train_amir_label=np.zeros(len(train_amir))<br/>train_salman_label=np.ones(len(train_salman))<br/>train_shahruk_label=np.full(len(train_shahruk),2)<br/><br/>print(train_amir.shape,train_amir_label.shape)<br/>print(train_salman.shape,train_salman_label.shape)<br/>print(train_shahruk.shape,train_shahruk_label.shape)</span></pre><figure class="kw kx ky kz gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi ln"><img src="../Images/e1c36d54887f2f367ba7c7737d748b29.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*bq5uO9uRTBlnYz8eRwnPjg.png"/></div></div></figure><p id="e746" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">4.将所有图像连接成 X，将所有相应的标签连接成 y。使用 keras.utils 的 to _ categorical 方法将 y 标签转换成一个热编码。使用训练测试拆分方法，将数据集拆分为 X_train、y_train、X_test 和 y_test，并对数据进行归一化处理。</p><pre class="kw kx ky kz gt la lb lc ld aw le bi"><span id="7f8c" class="lf lg iq lb b gy lh li l lj lk"><strong class="lb ir">#Concatenate </strong><br/>X=np.concatenate((train_amir,train_salman,train_shahruk))<br/>y=np.concatenate((train_amir_label,train_salman_label,train_shahruk_label))<br/>y_label =to_categorical(y)</span><span id="497a" class="lf lg iq lb b gy ll li l lj lk"><strong class="lb ir">#Train -Test Split</strong><br/>from sklearn.model_selection import train_test_split<br/>X_train, X_test, y_train, y_test = train_test_split(X, y_label, test_size=0.33, random_state=42,shuffle=True)</span><span id="f6dd" class="lf lg iq lb b gy ll li l lj lk"><strong class="lb ir">#Normalize the data</strong><br/>X_train=X_train.astype('float32')<br/>X_test=X_test.astype('float32')<br/>X_train=X_train/255<br/>X_test=X_test/255<br/>print("Training Data",X_train.shape)<br/>print("Testing Data",X_test.shape)</span></pre><figure class="kw kx ky kz gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi lo"><img src="../Images/692a7c9786a7f612a8020e3264bbf23f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*qgg6JnpvOgqmHMTKnS8OGA.png"/></div></div></figure><p id="b0f4" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">5.现在我定义多层神经网络。框图包括以下内容。基本架构是 Conv2d 层[3*3]，然后是 leaky Relu 激活，然后在其上应用 Max Pooling[2 * 2]层。有 3 个这样的分层网络[Conv2d-&gt;Leaky Relu-&gt;Max Pool]将尝试使网络更深，并将从这些层中提取特征地图。在后面的层中，我将 Conv2d 层的输出展平为 1 维，并应用了两个密集层，中间有 Leaky Relu，然后是 Softmax，以将最终输出转换为 3 类概率。使用的一些超参数如下</p><p id="9958" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">epochs =20，alpha =0.1，batch size =64，padding = same[这是为了保留与输入图像相同的大小]，optimizer = Adam，loss function = cross 熵。</p><pre class="kw kx ky kz gt la lb lc ld aw le bi"><span id="a9eb" class="lf lg iq lb b gy lh li l lj lk"><strong class="lb ir">#HyperParameters</strong><br/>batch_size = 64<br/>epochs = 20<br/>num_classes = 3<br/>input_shape=(64,64,3)<br/><strong class="lb ir">#Model Define<br/></strong>model = Sequential()<br/>model.add(Conv2D(32, kernel_size=(3,3),activation='linear',input_shape=input_shape,padding='same'))<br/>model.add(LeakyReLU(alpha=0.1))<br/>model.add(MaxPooling2D((2, 2),padding='same'))<br/>model.add(Conv2D(64, (3, 3), activation='linear',padding='same'))<br/>model.add(LeakyReLU(alpha=0.1))<br/>model.add(MaxPooling2D(pool_size=(2, 2),padding='same'))<br/>model.add(Conv2D(128, (3, 3), activation='linear',padding='same'))<br/>model.add(LeakyReLU(alpha=0.1))                  <br/>model.add(MaxPooling2D(pool_size=(2, 2),padding='same'))<br/>model.add(Flatten())<br/>model.add(Dense(128, activation='linear'))<br/>model.add(LeakyReLU(alpha=0.1))                  <br/>model.add(Dense(3, activation='softmax'))<br/>model.compile(loss='categorical_crossentropy', optimizer='Adam',metrics=['accuracy'])<br/>model.summary()</span></pre><figure class="kw kx ky kz gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi lp"><img src="../Images/9e83a18f50f1fb2edfc4bb04be27a50c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*bZ21yjCkjQZAz0SxZ6qDoA.png"/></div></div></figure><p id="27fb" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">6.在定义了模型之后，我传递了 X_train，y_train 数据以及验证数据(X_test，y_test ),并计算了精确度。对数据集的 834 个样本进行了训练，对数据集的 411 个样本进行了验证。准确率为- <strong class="ka ir"> 86.86% </strong></p><pre class="kw kx ky kz gt la lb lc ld aw le bi"><span id="21cb" class="lf lg iq lb b gy lh li l lj lk">np.random.seed(42)<br/>model_1=model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=epochs, batch_size=64,shuffle=True)<br/>scores = model.evaluate(X_test, y_test, verbose=0)<br/>print("Accuracy: %.2f%%" % (scores[1]*100))</span></pre><figure class="kw kx ky kz gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi lq"><img src="../Images/070bdbdea423a9efe407929ac5179560.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*K5nM4bDzI5wWUmi9VFC7Lw.png"/></div></div></figure><p id="26eb" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">7.我绘制了验证和训练曲线，并检查模型是否过拟合或欠拟合，或者它只是很好。这个模型既没有过拟合也没有过拟合。</p><pre class="kw kx ky kz gt la lb lc ld aw le bi"><span id="8229" class="lf lg iq lb b gy lh li l lj lk">test_eval = model.evaluate(X_test, y_test, verbose=0)<br/>print('Test loss:', test_eval[0])<br/>print('Test accuracy:', test_eval[1])</span><span id="873f" class="lf lg iq lb b gy ll li l lj lk">accuracy = model_1.history['acc']<br/>val_accuracy = model_1.history['val_acc']<br/>loss = model_1.history['loss']<br/>val_loss = model_1.history['val_loss']<br/>epochs = range(len(accuracy))<br/>plt.plot(epochs, accuracy, 'r', label='Training accuracy')<br/>plt.plot(epochs, val_accuracy, 'b', label='Validation accuracy')<br/>plt.title('Training and validation accuracy')<br/>plt.legend()<br/>plt.figure()<br/>plt.plot(epochs, loss, 'r', label='Training loss')<br/>plt.plot(epochs, val_loss, 'b', label='Validation loss')<br/>plt.title('Training and validation loss')</span></pre><figure class="kw kx ky kz gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi lp"><img src="../Images/d1d49251de174336c3e07e649444dfc5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*vsZ1DOhrB9JNVFfbVWZUVQ.png"/></div></div></figure><p id="9b47" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">8.我还想知道有多少样本被错误分类。为此，我计算了混淆矩阵，发现 149 个样本中有 123 个样本正确地将阿米尔·可汗归类为阿米尔·可汗。26 个样本被错误归类，109 个样本正确地将萨尔曼·可汗归类为萨尔曼汗，125 个样本将沙鲁克汗归类为沙鲁克汗。</p><pre class="kw kx ky kz gt la lb lc ld aw le bi"><span id="a7ed" class="lf lg iq lb b gy lh li l lj lk">from sklearn.metrics import confusion_matrix<br/>y_test_pred=model.predict(X_test)<br/>cnf_matrix = confusion_matrix(y_test.argmax(axis=1), y_test_pred.argmax(axis=1))<br/>cnf_matrix</span></pre><figure class="kw kx ky kz gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi lr"><img src="../Images/1dba8c37c4cfdc1534065446aacb1674.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*rtobRDkseX38QCxzZ_hdDA.png"/></div></div></figure><p id="8512" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">9.最后，我在看不见的数据上测试了模型，并可视化了样本。几乎所有的随机样本都给了我正确的预测。</p><pre class="kw kx ky kz gt la lb lc ld aw le bi"><span id="24c6" class="lf lg iq lb b gy lh li l lj lk">testdata= load_images_from_folder('../Q1_TestData/')<br/>testimages=np.array(testdata)<br/>predicted_classes = model.predict(testimages)<br/>predicted_classes1 = np.argmax(np.round(predicted_classes),axis=1)<br/><strong class="lb ir">#Visualize the test data</strong><br/>fig = plt.figure(figsize=(20,5))<br/>for i in range(36):<br/>    ax = fig.add_subplot(3, 12, i+1,xticks=[], yticks=[])<br/>    plt.imshow(testimages[i])<br/>    if (predicted_classes1[i]==0):<br/>        plt.xlabel('amir')<br/>    if (predicted_classes1[i]==1):<br/>        plt.xlabel('salman')<br/>    if (predicted_classes1[i]==2):<br/>        plt.xlabel('shahruk')    <br/>plt.show()</span></pre><figure class="kw kx ky kz gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi lp"><img src="../Images/192f31c7b02b7581ee514ed00ad3a4da.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Bfd__PiKU8HjULiMGkk_YA.png"/></div></div></figure><p id="cfcf" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">瞧啊。请点赞并分享..谢谢..你可以帮我联系@<a class="ae ls" href="https://www.linkedin.com/in/ashishbansal1/" rel="noopener ugc nofollow" target="_blank">https://www.linkedin.com/in/ashishbansal1/</a></p><figure class="kw kx ky kz gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi lt"><img src="../Images/1cd1ed66488aaf0f6e4a657de15553ef.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*oUKvKCDUiYcZF9v5gWd5Sw.jpeg"/></div></div></figure></div></div>    
</body>
</html>