<html>
<head>
<title>A Gentle Guide to Starting Your NLP Project with AllenNLP</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">用 AllenNLP 开始你的 NLP 项目的温和指南</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/allennlp-startup-guide-24ffd773cd5b?source=collection_archive---------11-----------------------#2019-06-10">https://towardsdatascience.com/allennlp-startup-guide-24ffd773cd5b?source=collection_archive---------11-----------------------#2019-06-10</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="5897" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">跟你乱七八糟的代码说再见吧！</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/5755fe014895631c2f09028e10f52896.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*xDD4Hw6cZYg7UEmzjOtSZw.jpeg"/></div></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk">Photo by <a class="ae ky" href="https://unsplash.com/@jamietempleton?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank">Jamie Templeton</a> on <a class="ae ky" href="https://unsplash.com/search/photos/sign?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><p id="4cd7" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">你知道图书馆吗？如果你从事自然语言处理(NLP)，你可能会听说过这个名字。不过，我估计有几个人真的在用。或者其他人以前尝试过，但不知道从哪里开始，因为有很多功能。对于那些不熟悉 AllenNLP 的人，我将简要介绍一下这个库，并让您了解将它集成到您的项目中的优势。</p><p id="4a42" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">AllenNLP 是 NLP 的深度学习库。<a class="ae ky" href="https://allenai.org/" rel="noopener ugc nofollow" target="_blank">艾伦人工智能研究所</a>，人工智能的领先研究组织之一，开发了这个基于<a class="ae ky" href="https://pytorch.org/" rel="noopener ugc nofollow" target="_blank"> PyTorch </a>的库。使用 AllenNLP 开发一个模型比 PyTorch 从头开始构建一个模型要容易得多。它不仅提供了更容易的开发，而且支持实验的管理和开发后的评估。<strong class="lb iu"> AllenNLP 的特点是专注于研发</strong>。更具体地说，有可能<strong class="lb iu">快速原型化模型</strong>，并使<strong class="lb iu">更容易管理具有许多不同参数的实验</strong>。此外，它还考虑使用可读的变量名。</p><p id="fb8a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们可能有过从零开始编码而得到混乱的代码或丢失重要实验结果的经历。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi lv"><img src="../Images/3a959e4034f15b4a2c046ccb2155838a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*hXca_IbqU7-FWevidZodGA.png"/></div></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk">When I’ve got to know AllenNLP</figcaption></figure><p id="4791" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在 AllenNLP 中，我们应该遵循下面的开发和实验流程。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi lw"><img src="../Images/a0e4396c980317a21b91382bbabd88f0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*6JbO66ixEgvWLgYxmzBIcw.png"/></div></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk">Comparison between the typical process and the process with AllenNLP</figcaption></figure><p id="3dba" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">根据你自己的研究项目，你只需要实现 DatasetReader 和 Model，然后用配置文件运行你的各种实验。基本上，我们需要了解以下三个特性，以便开始我们的 AllenNLP 项目</p><ol class=""><li id="bf28" class="lx ly it lb b lc ld lf lg li lz lm ma lq mb lu mc md me mf bi translated">定义 DatasetReader</li><li id="0a8e" class="lx ly it lb b lc mg lf mh li mi lm mj lq mk lu mc md me mf bi translated">定义您的模型</li><li id="8d56" class="lx ly it lb b lc mg lf mh li mi lm mj lq mk lu mc md me mf bi translated">设置您的配置文件</li></ol><p id="14c9" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">换句话说，一旦你理解了它，你就能够进行可伸缩的开发。在这篇文章中，我将通过处理情感分析任务来解释上述三个关键特征。此外，您可以在 post 中使用如下方式检查代码:</p><div class="ml mm gp gr mn mo"><a href="https://github.com/yasufumy/allennlp_imdb" rel="noopener  ugc nofollow" target="_blank"><div class="mp ab fo"><div class="mq ab mr cl cj ms"><h2 class="bd iu gy z fp mt fr fs mu fu fw is bi translated">yasufumy/allennlp_imdb</h2><div class="mv l"><h3 class="bd b gy z fp mt fr fs mu fu fw dk translated">最简单的 AllenNLP 食谱。在 GitHub 上创建一个帐户，为 yasufumy/allennlp_imdb 的开发做出贡献。</h3></div><div class="mw l"><p class="bd b dl z fp mt fr fs mu fu fw dk translated">github.com</p></div></div><div class="mx l"><div class="my l mz na nb mx nc ks mo"/></div></div></a></div><p id="7072" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们开始吧！</p><h1 id="0e01" class="nd ne it bd nf ng nh ni nj nk nl nm nn jz no ka np kc nq kd nr kf ns kg nt nu bi translated">0.快速回顾:情绪分析</h1><p id="0a42" class="pw-post-body-paragraph kz la it lb b lc nv ju le lf nw jx lh li nx lk ll lm ny lo lp lq nz ls lt lu im bi translated">在这里，我将为那些不熟悉的人解释情感分析任务的基础。所以如果你已经很了解它，请继续下一部分:1。定义 DatasetReader。</p><p id="557d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">情感分析是一项尝试对给定文档的极性(积极或消极)进行分类的任务。在本帖中，我们使用<a class="ae ky" href="https://www.imdb.com/" rel="noopener ugc nofollow" target="_blank"> IMDB </a>中的电影评论作为给定文档。例如，我们将在<a class="ae ky" href="https://www.imdb.com/title/tt4154796/reviews?ref_=tt_urv" rel="noopener ugc nofollow" target="_blank">复仇者联盟 4：终局之战的用户评论</a>中找到正面和负面评论。这一次，我们将使用下面链接中提供的数据集。</p><div class="ml mm gp gr mn mo"><a href="https://ai.stanford.edu/~amaas/data/sentiment/" rel="noopener  ugc nofollow" target="_blank"><div class="mp ab fo"><div class="mq ab mr cl cj ms"><h2 class="bd iu gy z fp mt fr fs mu fu fw is bi translated">情感分析</h2><div class="mv l"><h3 class="bd b gy z fp mt fr fs mu fu fw dk translated">这是一个用于二元情感分类的数据集，包含的数据比以前的基准测试多得多…</h3></div><div class="mw l"><p class="bd b dl z fp mt fr fs mu fu fw dk translated">ai.stanford.edu</p></div></div></div></a></div><p id="23e2" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们将构建模型，将文档(评论)作为输入，预测标签(极性)作为输出。我们应该准备文档和标签对作为数据集。</p><h1 id="d00d" class="nd ne it bd nf ng nh ni nj nk nl nm nn jz no ka np kc nq kd nr kf ns kg nt nu bi translated">1.定义 DatasetReader</h1><p id="05e4" class="pw-post-body-paragraph kz la it lb b lc nv ju le lf nw jx lh li nx lk ll lm ny lo lp lq nz ls lt lu im bi translated">下图显示了 AllenNLP 中的 DatasetReader 类。这个类主要处理任务中使用的数据。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi oa"><img src="../Images/4e327154ae1ea7e6c5016b1fb398bbc9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1228/format:webp/1*KtHAegi5mTQuNZKTHsLjZw.png"/></div></figure><p id="20da" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">DatasetReader 将原始数据集作为输入，并应用预处理，如小写、标记化等。最后，它输出实例对象的列表，该列表将预处理后的每个数据作为属性保存。在本文中，实例对象将文档和标签信息作为属性。</p><p id="8076" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">首先，我们应该继承 DatasetReader 类来创建自己的类。然后我们需要实现三个方法:<code class="fe ob oc od oe b">__init__</code>、<code class="fe ob oc od oe b">_read</code>和<code class="fe ob oc od oe b">text_to_instance</code>。所以让我们看看如何实现我们自己的 DatasetReader。我将跳过<code class="fe ob oc od oe b">read</code>方法的实现，因为它与 AllenNLP 的用法没有太大关系。但是如果你对它感兴趣，你可以参考这个链接。</p><p id="3d4f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">实现<code class="fe ob oc od oe b">__init__</code>将如下所示。我们可以通过配置文件控制这个方法的参数。</p><pre class="kj kk kl km gt of oe og oh aw oi bi"><span id="f707" class="oj ne it oe b gy ok ol l om on">@DatasetReader.register('imdb')<br/>ImdbDatasetReader(DatasetReaer):<br/>  def __init__(self, token_indexers, tokenizer):<br/>    self._tokenizer = tokenizer<br/>    self._token_indexers = token_indexers</span></pre><p id="84d7" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在这篇文章中，我将<code class="fe ob oc od oe b">token_indexers</code>和<code class="fe ob oc od oe b">tokenizer</code>设置为参数，因为我假设我们在实验中改变了索引或标记化的方式。<code class="fe ob oc od oe b">token_indexers</code>执行索引，<code class="fe ob oc od oe b">tokenizer</code>执行标记化。我实现的类有<a class="ae ky" href="https://docs.python.org/3/glossary.html#term-decorator" rel="noopener ugc nofollow" target="_blank">装饰器</a> ( <code class="fe ob oc od oe b">DatasetReader.register('imdb')</code>)，这使我们能够通过配置文件来控制它。</p><p id="bf3d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">实现<code class="fe ob oc od oe b">text_to_instance</code>将如下。这个方法是 DatasetReader 的主进程。<code class="fe ob oc od oe b">text_to_instance</code>将每个原始数据作为输入，应用一些预处理，并将每个原始数据作为一个<code class="fe ob oc od oe b">Instance</code>输出。在 IMDB 中，它将检查字符串和极性标签作为输入。</p><pre class="kj kk kl km gt of oe og oh aw oi bi"><span id="e67e" class="oj ne it oe b gy ok ol l om on">@DatasetReader.register('imdb')<br/>ImdbDatasetReader(DatasetReaer):<br/>    ...<br/>  def text_to_instance(self, string: str, label: int) -&gt; Instance:<br/>    fields = {}<br/>    tokens = self._tokenizer.tokenize(string)<br/>    fields['tokens'] = TextField(tokens, self._token_indexers)<br/>    fields['label'] = LabelField(label, skip_indexing=True)<br/>    return Instance(fields)</span></pre><p id="dc05" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在 AllenNLP 中，实例的属性对应于字段。我们可以从字段字典中创建实例。实例的属性代表每个数据，就像文档或标签一样。在 IMDB 中，实例散列两个属性:review 和 label。评论和标签分别对应于 TextField 和 LabelField。</p><p id="e61d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">上面提到的是定义我们的 DatasetReader 的方法。你可以从<a class="ae ky" href="https://github.com/yasufumy/allennlp_imdb/blob/master/allennlp_imdb/data/dataset_readers/imdb.py#L22" rel="noopener ugc nofollow" target="_blank">这个链接</a>查阅整个代码。</p><h1 id="a112" class="nd ne it bd nf ng nh ni nj nk nl nm nn jz no ka np kc nq kd nr kf ns kg nt nu bi translated">2.定义您的模型</h1><p id="baf8" class="pw-post-body-paragraph kz la it lb b lc nv ju le lf nw jx lh li nx lk ll lm ny lo lp lq nz ls lt lu im bi translated">下图显示了 AllenNLP 中的模型类。这个类主要是建立模型来解决任务。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi oo"><img src="../Images/c43e4c700a4e86ed251211501cdd6cc7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1078/format:webp/1*FN_zPQIcyTFE-cFiOqRb-Q.png"/></div></figure><p id="f63a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">该模型将数据作为输入，并将正向计算的结果和评估指标作为字典输出。</p><p id="a028" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">首先，我们应该继承模型类来创建我们自己的模型类。然后我们需要实现三个方法:<code class="fe ob oc od oe b">__init__</code>、<code class="fe ob oc od oe b">forward</code>和<code class="fe ob oc od oe b">get_metrics</code>。这里，我们使用递归神经网络(RNN)实现 IMDB 评论的极性分类模型。</p><p id="cc49" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">实施<code class="fe ob oc od oe b">__init__</code>将如下。我们可以通过与 DatasetReader 相同的配置文件来控制该方法的参数。</p><pre class="kj kk kl km gt of oe og oh aw oi bi"><span id="d8da" class="oj ne it oe b gy ok ol l om on">@Model.register('rnn_classifier')<br/>class RnnClassifier(Model):    <br/>def __init__(self, vocab, text_field_embedder,<br/>             seq2vec_encoder, label_namespace):<br/>  super().__init__(vocab)</span><span id="33e0" class="oj ne it oe b gy op ol l om on">self._text_field_embedder = text_field_embedder<br/>  self._seq2vec_encoder = seq2vec_encoder<br/>  self._classifier_input_dim = self._seq2vec_encoder.get_output_dim()<br/>  self._num_labels = vocab.get_vocab_size(namespace=label_namespace)</span><span id="72e1" class="oj ne it oe b gy op ol l om on">self._classification_layer = nn.Linear(self._classifier_input_dim, self._num_labels)<br/>  self._accuracy = CategoricalAccuracy()<br/>  self._loss = nn.CrossEntropyLoss()</span></pre><p id="2ddf" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在这篇文章中，我将<code class="fe ob oc od oe b">text_field_embedder</code>和<code class="fe ob oc od oe b">seq2vec_encoder</code>设为自变量，因为我假设我们在实验中改变了嵌入或 RNN 类型的方式。<code class="fe ob oc od oe b">text_field_embedder</code>将令牌作为向量嵌入，<code class="fe ob oc od oe b">seq2vec_encoder</code>用 RNN 对令牌序列进行编码(从技术上讲，除了 RNN，您可以使用其他类型)。我实现的类有装饰器(<code class="fe ob oc od oe b">Model.register('rnn_classifier')</code>)，这使我们能够通过配置文件来控制它。</p><p id="2768" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><code class="fe ob oc od oe b">forward</code>的实现如下。这种方法是建模的主要过程。<code class="fe ob oc od oe b">forward</code>将数据作为输入，通过正向计算进行计算，并将预测标签和评估指标的结果作为字典输出。大多数实现与 PyTorch 的方式相同。但是，请注意，我们应该将结果作为字典返回。</p><pre class="kj kk kl km gt of oe og oh aw oi bi"><span id="5116" class="oj ne it oe b gy ok ol l om on">def forward(self, tokens, label=None):<br/>  embedded_text = self._text_field_embedder(tokens)<br/>  mask = get_text_field_mask(tokens).float()</span><span id="5748" class="oj ne it oe b gy op ol l om on">encoded_text = self._dropout(self._seq2vec_encoder(embedded_text, mask=mask))</span><span id="fbfc" class="oj ne it oe b gy op ol l om on">logits = self._classification_layer(encoded_text)<br/>  probs = F.softmax(logits, dim=1)</span><span id="ba46" class="oj ne it oe b gy op ol l om on">output_dict = {'logits': logits, 'probs': probs}</span><span id="8664" class="oj ne it oe b gy op ol l om on">if label is not None:<br/>    loss = self._loss(logits, label.long().view(-1))<br/>    output_dict['loss'] = loss<br/>    self._accuracy(logits, label)</span><span id="01d2" class="oj ne it oe b gy op ol l om on">return output_dict</span></pre><p id="6af4" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">上面的实现计算极性、交叉熵损失和准确度的分类概率。我们通过 softmax 从 RNN 的输出计算分类概率。此外，如果标签给定，我们计算模型的分类精度。最后，它输出每个计算结果作为字典(<code class="fe ob oc od oe b">output_dict</code>)。</p><p id="eb0d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">实现<code class="fe ob oc od oe b">get_metrics</code>将如下所示。</p><pre class="kj kk kl km gt of oe og oh aw oi bi"><span id="3bc6" class="oj ne it oe b gy ok ol l om on">def get_metrics(self, reset=False):<br/>  return {'accuracy': self._accuracy.get_metric(reset)}</span></pre><p id="2d9f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">它将精度值作为字典返回。这是因为这次我们使用模型的准确性作为衡量标准。我们可以在<code class="fe ob oc od oe b">get_metrics</code>方法中使用多个值。</p><p id="c2c5" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">上面提到的是我们定义模型的方式。你可以从<a class="ae ky" href="https://github.com/yasufumy/allennlp_imdb/blob/master/allennlp_imdb/model/rnn_classifier.py" rel="noopener ugc nofollow" target="_blank">这个链接</a>查阅整个代码。</p><h1 id="dbc5" class="nd ne it bd nf ng nh ni nj nk nl nm nn jz no ka np kc nq kd nr kf ns kg nt nu bi translated">3.设置您的配置文件</h1><p id="cc02" class="pw-post-body-paragraph kz la it lb b lc nv ju le lf nw jx lh li nx lk ll lm ny lo lp lq nz ls lt lu im bi translated">下图显示了如何在 AllenNLP 中运行我们的实验。我们可以通过将配置文件传递给<code class="fe ob oc od oe b">allennlp train</code>命令来运行我们的实验。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi oo"><img src="../Images/ab5ca78595ecb032da7e62c8db581ef1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1078/format:webp/1*z7izkA8PEphaWXDaLI7UZQ.png"/></div></figure><p id="3a8d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我将解释如何制作配置文件来控制我们的实验。我们可以通过下面的命令用 GUI 界面制作配置文件。但是为了更好的理解，我将从头开始解释。</p><pre class="kj kk kl km gt of oe og oh aw oi bi"><span id="301b" class="oj ne it oe b gy ok ol l om on">allennlp configure --include-package allennlp_imdb</span></pre><p id="b96b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">配置文件主要由<code class="fe ob oc od oe b">dataset_reader</code>字段、<code class="fe ob oc od oe b">model</code>字段和<code class="fe ob oc od oe b">trainer</code>字段组成。</p><pre class="kj kk kl km gt of oe og oh aw oi bi"><span id="7f5b" class="oj ne it oe b gy ok ol l om on">{<br/>  "dataset_reader": {...},<br/>  "model": {...},<br/>  "trainer": {...}<br/>}</span></pre><p id="5af1" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><code class="fe ob oc od oe b">dataset_reader</code>字段和<code class="fe ob oc od oe b">model</code>字段分别指定 DatasetReader 的设置和我们到目前为止实现的模型。另外，<code class="fe ob oc od oe b">trainer</code>字段指定了优化器、时期数和设备(CPU/GPU)的设置。你可以从<a class="ae ky" href="https://github.com/yasufumy/allennlp_imdb/blob/master/training_config/base_cpu.jsonnet" rel="noopener ugc nofollow" target="_blank">这个链接</a>查阅整个配置文件。接下来，我将分别解释这三个字段的重要部分。</p><p id="beeb" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">DatasetReader 的设置如下。</p><pre class="kj kk kl km gt of oe og oh aw oi bi"><span id="514e" class="oj ne it oe b gy ok ol l om on">"dataset_reader": {<br/>  "type": "imdb",<br/>  "token_indexers": {<br/>    "tokens": {<br/>      "type": "single_id"<br/>    }<br/>  },<br/>  "tokenizer": {<br/>    "type": "word"<br/>  }<br/>}</span></pre><p id="36e2" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">首先，我们指定在<code class="fe ob oc od oe b">type</code>中使用哪个 DatasetReader。我们可以使用 ImdbDatasetReader 将<code class="fe ob oc od oe b">type</code>设置为<code class="fe ob oc od oe b">imdb</code>，因为它已经准备好供<code class="fe ob oc od oe b">@DatasetReader.register('imdb')</code>使用。AllenNLP 已经提供了许多流行的数据集。你可以从<a class="ae ky" href="https://allenai.github.io/allennlp-docs/api/allennlp.data.dataset_readers.html" rel="noopener ugc nofollow" target="_blank">文档</a>中查看这些。</p><p id="3292" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">然后，我们为<code class="fe ob oc od oe b">ImdbDatasetReader.__init__</code>方法指定参数。我们使用<code class="fe ob oc od oe b"><a class="ae ky" href="https://github.com/allenai/allennlp/blob/master/allennlp/data/token_indexers/single_id_token_indexer.py#L12" rel="noopener ugc nofollow" target="_blank">SingleIdTokenIndexer</a></code>表示<code class="fe ob oc od oe b">token_indexers</code>,因为我们希望令牌对应于单个 id。此外，我们使用<code class="fe ob oc od oe b"><a class="ae ky" href="https://github.com/allenai/allennlp/blob/master/allennlp/data/tokenizers/word_tokenizer.py#L12" rel="noopener ugc nofollow" target="_blank">WordTokenizer</a></code>来表示<code class="fe ob oc od oe b">tokenizer</code>，因为我们希望令牌是一个单词。</p><p id="be92" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">模型的设置如下。</p><pre class="kj kk kl km gt of oe og oh aw oi bi"><span id="eefa" class="oj ne it oe b gy ok ol l om on">"model": {<br/>  "type": "rnn_classifier",<br/>  "text_field_embedder": {<br/>    "token_embedders": {<br/>      "type": "embedding",<br/>      ...<br/>    }<br/>  },<br/>  "seq2vec_encoder": {<br/>    "type": "gru",<br/>    ...<br/>  }<br/>}</span></pre><p id="7846" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">首先，我们指定在<code class="fe ob oc od oe b">type</code>中使用哪个模型，与 DatasetReader 相同。我们可以使用 RnnClassifier 将<code class="fe ob oc od oe b">type</code>设置为<code class="fe ob oc od oe b">rnn_classifier</code>，因为它已经准备好供<code class="fe ob oc od oe b">@Model.register('rnn_classifier')</code>使用。</p><p id="93a8" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">然后，我们为<code class="fe ob oc od oe b">RnnClassifier.__init__</code>方法指定参数。我们使用<code class="fe ob oc od oe b"><a class="ae ky" href="https://allenai.github.io/allennlp-docs/api/allennlp.modules.token_embedders.html#embedding" rel="noopener ugc nofollow" target="_blank">Embedding</a></code>来表示<code class="fe ob oc od oe b">text_field_embedder</code>，因为我们希望将单词作为向量嵌入。此外，我们用<code class="fe ob oc od oe b"><a class="ae ky" href="https://allenai.github.io/allennlp-docs/api/allennlp.modules.seq2vec_encoders.html" rel="noopener ugc nofollow" target="_blank">GRU</a></code>代替<code class="fe ob oc od oe b">seq2vec_encoder</code>，因为我们想通过 GRU 对嵌入的单词序列进行编码。</p><p id="8c22" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">训练器的设置如下。</p><pre class="kj kk kl km gt of oe og oh aw oi bi"><span id="af1f" class="oj ne it oe b gy ok ol l om on">"trainer": {<br/>  "num_epochs": 10,<br/>  "optimizer": {<br/>    "type": "adam"<br/>  }<br/>}</span></pre><p id="4498" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><code class="fe ob oc od oe b">num_epochs</code>指定要训练的时期数。<code class="fe ob oc od oe b">optimizer</code>指定优化器更新参数，在这种情况下，我们选择使用<code class="fe ob oc od oe b">adam</code>。</p><p id="23cc" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">上面提到的是建立你的配置文件的方法。</p><p id="e840" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们可以通过执行以下命令来运行实验:</p><pre class="kj kk kl km gt of oe og oh aw oi bi"><span id="d103" class="oj ne it oe b gy ok ol l om on">allennlp train \<br/>    --include-package allennlp_imdb \<br/>    -s /path/to/storage \<br/>    -o '{"trainer": {"cuda_device": 0}} \<br/>    training_config/base_cpu.jsonnet</span></pre><p id="1411" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">当我们想改变实验设置时，我们需要创建新的配置文件。但是如果变化很小，我们可以通过下面的命令来改变设置。下面的命令将 GRU 更新为 LSTM。</p><pre class="kj kk kl km gt of oe og oh aw oi bi"><span id="60cc" class="oj ne it oe b gy ok ol l om on">allennlp train \<br/>    --include-package allennlp_imdb \<br/>    -s /path/to/storage \<br/>    -o '{"trainer": {"cuda_device": 0}} \<br/>    -o '{"model": {"seq2vec_encoder": {"type": "lstm"}}}' \<br/>    training_config/base_cpu.jsonnet</span></pre><p id="3b17" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">解释到此为止。谢谢你看我的帖子。我希望您了解如何在 AllenNLP 中构建您的数据加载器、建模和管理您的实验。</p></div></div>    
</body>
</html>