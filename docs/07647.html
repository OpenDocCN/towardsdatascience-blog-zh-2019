<html>
<head>
<title>A Quick Introduction to TensorFlow 2.0 for Deep Learning</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">深度学习 TensorFlow 2.0 快速入门</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/a-quick-introduction-to-tensorflow-2-0-for-deep-learning-e740ca2e974c?source=collection_archive---------4-----------------------#2019-10-24">https://towardsdatascience.com/a-quick-introduction-to-tensorflow-2-0-for-deep-learning-e740ca2e974c?source=collection_archive---------4-----------------------#2019-10-24</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><figure class="gl gn jr js jt ju gh gi paragraph-image"><div class="gh gi jq"><img src="../Images/fcc2baa8744bf4d8b36dc561c86b2085.png" data-original-src="https://miro.medium.com/v2/resize:fit:1200/format:webp/0*yz4OzmTYGW6M-UKV.jpg"/></div></figure><blockquote class="jx jy jz"><p id="e8b3" class="ka kb kc kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">想获得灵感？快来加入我的<a class="ae kz" href="https://www.superquotes.co/?utm_source=mediumtech&amp;utm_medium=web&amp;utm_campaign=sharing" rel="noopener ugc nofollow" target="_blank"> <strong class="kd iu">超级行情快讯</strong> </a>。😎</p></blockquote><p id="645f" class="pw-post-body-paragraph ka kb it kd b ke kf kg kh ki kj kk kl la kn ko kp lb kr ks kt lc kv kw kx ky im bi translated">经过大量的社区宣传和期待，<a class="ae kz" href="https://www.tensorflow.org/" rel="noopener ugc nofollow" target="_blank"> TensorFlow 2.0 </a>终于在 2019 年 9 月 30 日由 Google 发布<a class="ae kz" href="https://medium.com/tensorflow/tensorflow-2-0-is-now-available-57d706c2a9ab" rel="noopener">。</a></p><p id="8db7" class="pw-post-body-paragraph ka kb it kd b ke kf kg kh ki kj kk kl la kn ko kp lb kr ks kt lc kv kw kx ky im bi translated">TensorFlow 2.0 代表了图书馆发展的一个重要里程碑。在过去的几年里，TensorFlow 的主要弱点之一，也是许多人转而使用 PyTorch 的一个重要原因，就是它非常复杂的 API。</p><p id="a9d7" class="pw-post-body-paragraph ka kb it kd b ke kf kg kh ki kj kk kl la kn ko kp lb kr ks kt lc kv kw kx ky im bi translated">定义深度神经网络需要的工作比合理的要多得多。这导致了位于 TensorFlow 之上的几个高级 API 的开发，包括<a class="ae kz" href="https://github.com/tensorflow/models/tree/master/research/slim" rel="noopener ugc nofollow" target="_blank"> TF Slim </a>和<a class="ae kz" href="https://keras.io" rel="noopener ugc nofollow" target="_blank"> Keras </a>。</p><p id="5148" class="pw-post-body-paragraph ka kb it kd b ke kf kg kh ki kj kk kl la kn ko kp lb kr ks kt lc kv kw kx ky im bi translated">现在事情又回到了起点，Keras 将成为 TensorFlow 2.0 的官方 API。加载数据、定义模型、训练和评估现在都变得容易多了，Keras 风格的代码更干净，开发时间更快。</p><p id="e7f4" class="pw-post-body-paragraph ka kb it kd b ke kf kg kh ki kj kk kl la kn ko kp lb kr ks kt lc kv kw kx ky im bi translated">本文将快速介绍使用 Keras 进行深度学习的新 TensorFlow 2.0 方式。我们将经历加载数据集、定义模型、训练和评估的端到端流程，所有这些都使用新的 TensorFlow 2.0 API。如果你想自己运行全部代码，我已经设置了一个包含全部内容的<a class="ae kz" href="https://colab.research.google.com/drive/1KRi0k5XTJoKEuRGOMRy3xhaUU_txNCYm" rel="noopener ugc nofollow" target="_blank"> Google Colab 笔记本</a>！</p><h1 id="9fb2" class="ld le it bd lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma bi translated">导入和设置</h1><p id="aa4d" class="pw-post-body-paragraph ka kb it kd b ke mb kg kh ki mc kk kl la md ko kp lb me ks kt lc mf kw kx ky im bi translated">我们将从导入 TensorFlow、Keras 和 Matplotlib 开始。请注意我们如何使用<code class="fe mg mh mi mj b">tensorflow.keras</code>直接从 TensorFlow 中提取 Keras，因为它现在就捆绑在 tensor flow 中。我们还有一个<em class="kc"> if </em>语句来安装 2.0 版本，以防我们的笔记本运行的是旧版本。</p><figure class="mk ml mm mn gt ju"><div class="bz fp l di"><div class="mo mp l"/></div></figure><p id="f8c3" class="pw-post-body-paragraph ka kb it kd b ke kf kg kh ki kj kk kl la kn ko kp lb kr ks kt lc kv kw kx ky im bi translated">接下来，我们将加载数据集。对于本教程，我们将使用<a class="ae kz" href="https://en.wikipedia.org/wiki/MNIST_database" rel="noopener ugc nofollow" target="_blank"> MNIST 数据集</a>，它包含 60，000 张训练图像和 10，000 张数字从 0 到 9 的测试图像，大小为 28x28。这是一个非常基本的数据集，一直用于快速测试和概念验证。还有一些使用 Matplotlib 的可视化代码，因此我们可以查看数据。</p><figure class="mk ml mm mn gt ju"><div class="bz fp l di"><div class="mo mp l"/></div></figure><figure class="mk ml mm mn gt ju gh gi paragraph-image"><div class="gh gi mq"><img src="../Images/9d761621ef2b34cc0c1a120024e5bd03.png" data-original-src="https://miro.medium.com/v2/resize:fit:1152/format:webp/1*YVKBAbXQR7rcDMZ1HBGhGw.png"/></div><figcaption class="mr ms gj gh gi mt mu bd b be z dk">Visualizing MNIST digits</figcaption></figure><h1 id="34b2" class="ld le it bd lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma bi translated">创建用于图像分类的卷积神经网络</h1><p id="8e20" class="pw-post-body-paragraph ka kb it kd b ke mb kg kh ki mc kk kl la md ko kp lb me ks kt lc mf kw kx ky im bi translated">做图像分类最好的方法当然是用一个<a class="ae kz" href="http://cs231n.github.io/convolutional-networks/" rel="noopener ugc nofollow" target="_blank">卷积神经网络</a> (CNN)。API 将拥有我们构建这样一个网络所需的一切。由于 MNIST 非常小——图像大小为 28x28，只有 60，000 个训练图像——我们不需要超级庞大的网络，所以我们将保持简单。</p><p id="5a90" class="pw-post-body-paragraph ka kb it kd b ke kf kg kh ki kj kk kl la kn ko kp lb kr ks kt lc kv kw kx ky im bi translated">在过去的几年中，构建一个好的 CNN 的公式在很大程度上保持不变:堆叠卷积层(通常为 3×3 或 1×1 ),中间有非线性激活(通常为 ReLU ),添加几个完全连接的层，并在最后添加一个 Softmax 函数来获得类概率。我们已经在下面的网络定义中完成了所有这些工作。</p><figure class="mk ml mm mn gt ju"><div class="bz fp l di"><div class="mo mp l"/></div></figure><p id="6db2" class="pw-post-body-paragraph ka kb it kd b ke kf kg kh ki kj kk kl la kn ko kp lb kr ks kt lc kv kw kx ky im bi translated">我们的模型共有 6 个卷积层，每个卷积层之后都有一个 ReLU 激活。在卷积层之后，我们有一个 GlobalAveragePooling 来将我们的数据放入一个密集的向量中。我们完成了我们的全连接(密集)层，最后一个有 10 个 MNIST 的 10 类大小。</p><p id="9a8e" class="pw-post-body-paragraph ka kb it kd b ke kf kg kh ki kj kk kl la kn ko kp lb kr ks kt lc kv kw kx ky im bi translated">同样，请注意我们所有的模型层都来自于<code class="fe mg mh mi mj b">tensorflow.keras.layers</code>，并且我们使用的是 Keras 的功能 API。使用函数式 API，我们将模型构建为一系列顺序函数。第一层将输入图像作为输入变量。接下来，每个后续层都将前一层的输出作为其输入。我们的<code class="fe mg mh mi mj b">model.Model()</code>简单地连接了从输入到输出张量的“管道”。</p><p id="44e1" class="pw-post-body-paragraph ka kb it kd b ke kf kg kh ki kj kk kl la kn ko kp lb kr ks kt lc kv kw kx ky im bi translated">有关该模型的更详细描述，请查看下面<code class="fe mg mh mi mj b">model.summary()</code>的打印结果。</p><pre class="mk ml mm mn gt mv mj mw mx aw my bi"><span id="3ccb" class="mz le it mj b gy na nb l nc nd">Model: "model_1" _________________________________________________________________ Layer (type)                 Output Shape              Param #    ================================================================= input_3 (InputLayer)         [(None, 28, 28, 1)]       0          _________________________________________________________________ conv2d_12 (Conv2D)           (None, 28, 28, 32)        320        _________________________________________________________________ activation_16 (Activation)   (None, 28, 28, 32)        0          _________________________________________________________________ conv2d_13 (Conv2D)           (None, 14, 14, 32)        9248       _________________________________________________________________ activation_17 (Activation)   (None, 14, 14, 32)        0          _________________________________________________________________ conv2d_14 (Conv2D)           (None, 14, 14, 64)        18496      _________________________________________________________________ activation_18 (Activation)   (None, 14, 14, 64)        0          _________________________________________________________________ conv2d_15 (Conv2D)           (None, 7, 7, 64)          36928      _________________________________________________________________ activation_19 (Activation)   (None, 7, 7, 64)          0          _________________________________________________________________ conv2d_16 (Conv2D)           (None, 7, 7, 64)          36928      _________________________________________________________________ activation_20 (Activation)   (None, 7, 7, 64)          0          _________________________________________________________________ conv2d_17 (Conv2D)           (None, 7, 7, 64)          36928      _________________________________________________________________ activation_21 (Activation)   (None, 7, 7, 64)          0          _________________________________________________________________ global_average_pooling2d_2 ( (None, 64)                0          _________________________________________________________________ dense_4 (Dense)              (None, 32)                2080       _________________________________________________________________ activation_22 (Activation)   (None, 32)                0          _________________________________________________________________ dense_5 (Dense)              (None, 10)                330        _________________________________________________________________ activation_23 (Activation)   (None, 10)                0          ================================================================= Total params: 141,258 Trainable params: 141,258 Non-trainable params: 0 _________________________________________________________________</span></pre><h1 id="7303" class="ld le it bd lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma bi translated">培训和测试</h1><p id="6368" class="pw-post-body-paragraph ka kb it kd b ke mb kg kh ki mc kk kl la md ko kp lb me ks kt lc mf kw kx ky im bi translated">最精彩的部分来了:训练并获得实际效果！</p><p id="046a" class="pw-post-body-paragraph ka kb it kd b ke kf kg kh ki kj kk kl la kn ko kp lb kr ks kt lc kv kw kx ky im bi translated">首先，我们需要做一些数据预处理，以便为训练正确格式化数据。我们的训练图像需要在一个 4 维的阵列中，格式为:</p><p id="31e1" class="pw-post-body-paragraph ka kb it kd b ke kf kg kh ki kj kk kl la kn ko kp lb kr ks kt lc kv kw kx ky im bi translated"><strong class="kd iu">(批量 _ 尺寸，宽度，高度，通道)</strong></p><p id="8b87" class="pw-post-body-paragraph ka kb it kd b ke kf kg kh ki kj kk kl la kn ko kp lb kr ks kt lc kv kw kx ky im bi translated">我们将图像转换为类型为<em class="kc"> float32 </em>的图像，这是正确训练的一个要求，并进行归一化，使每个像素的值在 0.0 和 1.0 之间</p><p id="f510" class="pw-post-body-paragraph ka kb it kd b ke kf kg kh ki kj kk kl la kn ko kp lb kr ks kt lc kv kw kx ky im bi translated">至于标签，因为我们正在使用<a class="ae kz" href="https://en.wikipedia.org/wiki/Softmax_function" rel="noopener ugc nofollow" target="_blank"> Softmax </a>激活，我们希望我们的目标输出是一个热编码向量的形式。为此，我们使用了<code class="fe mg mh mi mj b">tf.keras.utils.to_categorical()</code>功能。函数中的第二个变量被设置为 10，因为我们有 10 个类。</p><figure class="mk ml mm mn gt ju"><div class="bz fp l di"><div class="mo mp l"/></div></figure><p id="6792" class="pw-post-body-paragraph ka kb it kd b ke kf kg kh ki kj kk kl la kn ko kp lb kr ks kt lc kv kw kx ky im bi translated">我们选择<a class="ae kz" rel="noopener" target="_blank" href="/adam-latest-trends-in-deep-learning-optimization-6be9a291375c">亚当</a>作为我们的优化器——它非常容易使用，开箱即用。我们将损失函数设置为<code class="fe mg mh mi mj b">categorical_crossentropy</code>，这与我们的 Softmax 兼容。训练 CNN 就像用我们的数据作为输入调用 Keras <code class="fe mg mh mi mj b">.fit()</code>函数一样简单！</p><p id="aca6" class="pw-post-body-paragraph ka kb it kd b ke kf kg kh ki kj kk kl la kn ko kp lb kr ks kt lc kv kw kx ky im bi translated">请注意，所有这些几乎都是纯粹的 Keras。真正唯一的区别是我们使用了 TensorFlow 的 Keras 库<em class="kc">，</em>，即<code class="fe mg mh mi mj b">tensorflow.keras</code>。它非常方便，因为它包含在一个漂亮的包中 TensorFlow 的强大功能和 Keras 的易用性。太棒了。</p><figure class="mk ml mm mn gt ju"><div class="bz fp l di"><div class="mo mp l"/></div></figure><p id="d92e" class="pw-post-body-paragraph ka kb it kd b ke kf kg kh ki kj kk kl la kn ko kp lb kr ks kt lc kv kw kx ky im bi translated">MNIST 是一个简单的数据集，所以我们的 CNN 应该很快达到高精度。在我自己的实验中，它在 5 个时期内达到了大约 97%。</p><p id="f404" class="pw-post-body-paragraph ka kb it kd b ke kf kg kh ki kj kk kl la kn ko kp lb kr ks kt lc kv kw kx ky im bi translated">一旦训练完成，我们可以绘制损失和准确性的历史。我们再次使用纯 Keras 代码从历史中提取损失和准确性信息。Matplotlib 用于轻松绘图。</p><figure class="mk ml mm mn gt ju"><div class="bz fp l di"><div class="mo mp l"/></div></figure><div class="mk ml mm mn gt ab cb"><figure class="ne ju nf ng nh ni nj paragraph-image"><img src="../Images/1187792d9f01d95112d031738cc5b54d.png" data-original-src="https://miro.medium.com/v2/resize:fit:790/format:webp/1*sfgwR_WkxeyEougFGIbFMg.png"/></figure><figure class="ne ju nk ng nh ni nj paragraph-image"><img src="../Images/6517be2a118572255535a5eb2921763d.png" data-original-src="https://miro.medium.com/v2/resize:fit:778/format:webp/1*brKKDMYK3xQnJe2fCrbvjQ.png"/><figcaption class="mr ms gj gh gi mt mu bd b be z dk nl di nm nn">Accuracy (left) and loss (right) results from our CNN on MNIST</figcaption></figure></div><p id="c569" class="pw-post-body-paragraph ka kb it kd b ke kf kg kh ki kj kk kl la kn ko kp lb kr ks kt lc kv kw kx ky im bi translated">要评估我们的网络，我们可以使用…你猜对了，Keras <code class="fe mg mh mi mj b">.evaluate()</code>功能！我们将应用它，然后打印出精度。</p><figure class="mk ml mm mn gt ju"><div class="bz fp l di"><div class="mo mp l"/></div></figure><p id="5cdc" class="pw-post-body-paragraph ka kb it kd b ke kf kg kh ki kj kk kl la kn ko kp lb kr ks kt lc kv kw kx ky im bi translated">我们的 CNN 模型在测试集上达到了 98.52%的准确率。</p></div><div class="ab cl no np hx nq" role="separator"><span class="nr bw bk ns nt nu"/><span class="nr bw bk ns nt nu"/><span class="nr bw bk ns nt"/></div><div class="im in io ip iq"><h1 id="b8a6" class="ld le it bd lf lg nv li lj lk nw lm ln lo nx lq lr ls ny lu lv lw nz ly lz ma bi translated">喜欢学习？</h1><p id="ebef" class="pw-post-body-paragraph ka kb it kd b ke mb kg kh ki mc kk kl la md ko kp lb me ks kt lc mf kw kx ky im bi translated">在推特<a class="ae kz" href="https://twitter.com/GeorgeSeif94" rel="noopener ugc nofollow" target="_blank">上关注我，在那里我会发布所有最新最棒的人工智能、技术和科学！也在 LinkedIn </a>上与我联系！</p></div></div>    
</body>
</html>