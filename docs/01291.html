<html>
<head>
<title>Skin cancer classification with machine learning</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">基于机器学习的皮肤癌分类</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/skin-cancer-classification-with-machine-learning-c9d3445b2163?source=collection_archive---------14-----------------------#2019-02-28">https://towardsdatascience.com/skin-cancer-classification-with-machine-learning-c9d3445b2163?source=collection_archive---------14-----------------------#2019-02-28</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><p id="60d7" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">皮肤癌是美国最常见的皮肤癌。美国每年诊断出 400 多万例皮肤癌。</p><p id="e94c" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">这是巨大的！每年可能有 400 万人死于皮肤癌。想想这有多疯狂。</p><p id="19da" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">现在那些人都快死了，但是你猜怎么着！这些人中大约有一半，也许更多，甚至在可以预防的早期阶段不去看医生。</p><p id="c02f" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">即使人们出现了症状，他们仍然不想去看医生。这太疯狂了。特别是因为皮肤癌在早期阶段更容易治疗，而且它生长得超级快。</p><p id="6df2" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">现在我不能神奇地让人去看医生。或者我可以…</p><figure class="km kn ko kp gt kq gh gi paragraph-image"><div role="button" tabindex="0" class="kr ks di kt bf ku"><div class="gh gi kl"><img src="../Images/4c95f5b185d8ae968117021230bec0c0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*gXVu59qYJaIq62tgeWm8QA.jpeg"/></div></div><figcaption class="kx ky gj gh gi kz la bd b be z dk">Is this me?</figcaption></figure><p id="f4b0" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">不，你抓住我了。我不是巫师。但是我能做的是让人们在家自己检测皮肤癌。你所需要的只是一台笔记本电脑和几行代码。</p><h1 id="83cb" class="lb lc iq bd ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly bi translated">皮肤癌分类</h1><p id="09ec" class="pw-post-body-paragraph jn jo iq jp b jq lz js jt ju ma jw jx jy mb ka kb kc mc ke kf kg md ki kj kk ij bi translated">正如我所说，皮肤癌是美国乃至全世界的一大杀手。但问题是，在早期这是可以预防的，但人们只是不想去看医生。</p><p id="96dc" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">所以，我用机器学习想出了一种方法，让人们能够在自己家里舒适地检查自己是否患有皮肤癌。</p><h1 id="0e28" class="lb lc iq bd ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly bi translated">我是如何做到的</h1><p id="dac7" class="pw-post-body-paragraph jn jo iq jp b jq lz js jt ju ma jw jx jy mb ka kb kc mc ke kf kg md ki kj kk ij bi translated"><strong class="jp ir">数据集:</strong></p><p id="0bc5" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我用 PyTorch 编码了这个。首先，你需要<strong class="jp ir">导入数据集。</strong></p><p id="6afd" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">对于这一部分，我使用了这个<a class="ae me" href="https://www.kaggle.com/kmader/dermatology-mnist-loading-and-processing" rel="noopener ugc nofollow" target="_blank">内核</a>中的一些代码，里面有所有的数据。</p><pre class="km kn ko kp gt mf mg mh mi aw mj bi"><span id="6649" class="mk lc iq mg b gy ml mm l mn mo">base_skin_dir = os.path.join('..', 'input')<br/><br/>imageid_path_dict = {os.path.splitext(os.path.basename(x))[0]: x<br/>                     for x <strong class="mg ir">in</strong> glob(os.path.join(base_skin_dir, '*', '*.jpg'))}<br/><br/>lesion_type_dict = {<br/>    'nv': 'Melanocytic nevi',<br/>    'mel': 'dermatofibroma',<br/>    'bkl': 'Benign keratosis-like lesions ',<br/>    'bcc': 'Basal cell carcinoma',<br/>    'akiec': 'Actinic keratoses',<br/>    'vasc': 'Vascular lesions',<br/>    'df': 'Dermatofibroma'</span><span id="8dc3" class="mk lc iq mg b gy mp mm l mn mo">tile_df = pd.read_csv(os.path.join(base_skin_dir, 'HAM10000_metadata.csv'))<br/>tile_df['path'] = tile_df['image_id'].map(imageid_path_dict.get)<br/>tile_df['cell_type'] = tile_df['dx'].map(lesion_type_dict.get) <br/>tile_df['cell_type_idx'] = pd.Categorical(tile_df['cell_type']).codes</span><span id="de5d" class="mk lc iq mg b gy mp mm l mn mo">tile_df[['cell_type_idx', 'cell_type']].sort_values('cell_type_idx').drop_duplicates()</span></pre><figure class="km kn ko kp gt kq gh gi paragraph-image"><div class="gh gi mq"><img src="../Images/53689211cc44bb4160c575c4ffe719b5.png" data-original-src="https://miro.medium.com/v2/resize:fit:580/format:webp/1*4RPLUbZUqLVMnmsnQVoa7w.png"/></div></figure><p id="f372" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">那么您应该得到如下所示的输出。正如你所看到的，我们对地面实况数据有一个很好的概述。我们唯一需要的部分是“cell_type_idx”列，因为这些数据是我们进行模型定型所需要的。</p><p id="ba21" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">尽管只有一列是我们真正需要的，但了解每一列的含义仍然是一个好主意。所以让我们快速看一下我们表格中的其他肿瘤在数据集中出现的频率。</p><pre class="km kn ko kp gt mf mg mh mi aw mj bi"><span id="419c" class="mk lc iq mg b gy ml mm l mn mo">tile_df['cell_type'].value_counts()</span></pre><p id="e078" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">输入该代码后，您应该会得到如下所示的输出:</p><figure class="km kn ko kp gt kq gh gi paragraph-image"><div class="gh gi mr"><img src="../Images/2baf778ee4a145b5234009a88587cbb3.png" data-original-src="https://miro.medium.com/v2/resize:fit:680/format:webp/1*9yLGVQMgijBCfjv4wN-6ww.png"/></div></figure><p id="7f75" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">如你所见，黑色素细胞痣的发生率是皮肤纤维瘤的 58 倍。可能发生的是，与皮肤纤维瘤相比，黑色素细胞痣在预测中是优选的。一种解决方案是在培训中更多地显示不太频繁的课程。但这不是一个需要马上解决的大问题，没有它我们也能做得很好。</p><p id="e4d1" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">让我们看一下完整的表格:</p><pre class="km kn ko kp gt mf mg mh mi aw mj bi"><span id="044d" class="mk lc iq mg b gy ml mm l mn mo">tile_df.sample(3)</span></pre><figure class="km kn ko kp gt kq gh gi paragraph-image"><div role="button" tabindex="0" class="kr ks di kt bf ku"><div class="gh gi ms"><img src="../Images/40a25c574d7748e3fc4612c581a29ff7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*nq-LNOKdeADP1KruqcVYOg.png"/></div></div></figure><figure class="km kn ko kp gt kq gh gi paragraph-image"><div class="gh gi mt"><img src="../Images/3ad3391c57aa24f577cbe4c98e4f41ff.png" data-original-src="https://miro.medium.com/v2/resize:fit:426/format:webp/1*NCXKciJpiN1_Ogy6WmUBwA.png"/></div></figure><p id="c3c8" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">上表可用于通过路径获取输入数据。对应的基本事实标签已经由列“cell_type_idx”在同一行中给出。稍后，我们将创建几个已加载图像的输入批次 X 和由相应地面实况标签给出的相应地面实况值 y。</p><p id="4376" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">但是，在此之前，我们需要先做些别的事情。<strong class="jp ir">选择型号。</strong></p><h1 id="75c3" class="lb lc iq bd ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly bi translated">选择培训模型</h1><p id="9669" class="pw-post-body-paragraph jn jo iq jp b jq lz js jt ju ma jw jx jy mb ka kb kc mc ke kf kg md ki kj kk ij bi translated">PyTorch 有一个特性，它有成熟的模型。这些模型可选地已经在 ImageNet 数据集上被训练，使得训练时间通常更短。</p><p id="69e7" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">所以，我们加载一个预训练的 ResNet50，稍微调整一下最后一层。</p><pre class="km kn ko kp gt mf mg mh mi aw mj bi"><span id="1605" class="mk lc iq mg b gy ml mm l mn mo">import torchvision.models as models<br/>model_conv = models.resnet50(pretrained=True) <br/>        Downloading: "https://download.pytorch.org/models/resnet50-          <br/>        19c8e357.pth" to /tmp/.torch/models/resnet50-19c8e357.pth 100%<br/>       ██████████| 102502400/102502400 [00:01&lt;00:00, 83469977.65it/s]</span><span id="0554" class="mk lc iq mg b gy mp mm l mn mo">print(model_conv)<br/>     ResNet(<br/>  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)<br/>  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)<br/>  (relu): ReLU(inplace)<br/>  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)<br/>  (layer1): Sequential(<br/>    (0): Bottleneck(<br/>      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)<br/>      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)<br/>      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)<br/>      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)<br/>      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)<br/>      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)<br/>      (relu): ReLU(inplace)<br/>      (downsample): Sequential(<br/>        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)<br/>        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)<br/>      )<br/>    )<br/>    (1): Bottleneck(<br/>      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)<br/>      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)<br/>      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)<br/>      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)<br/>      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)<br/>      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)<br/>      (relu): ReLU(inplace)<br/>    )<br/>    (2): Bottleneck(<br/>      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)<br/>      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)<br/>      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)<br/>      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)<br/>      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)<br/>      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)<br/>      (relu): ReLU(inplace)<br/>    )<br/>  )<br/>  (layer2): Sequential(<br/>    (0): Bottleneck(<br/>      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)<br/>      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)<br/>      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)<br/>      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)<br/>      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)<br/>      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)<br/>      (relu): ReLU(inplace)<br/>      (downsample): Sequential(<br/>        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)<br/>        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)<br/>      )<br/>    )<br/>    (1): Bottleneck(<br/>      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)<br/>      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)<br/>      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)<br/>      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)<br/>      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)<br/>      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)<br/>      (relu): ReLU(inplace)<br/>    )<br/>    (2): Bottleneck(<br/>      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)<br/>      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)<br/>      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)<br/>      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)<br/>      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)<br/>      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)<br/>      (relu): ReLU(inplace)<br/>    )<br/>    (3): Bottleneck(<br/>      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)<br/>      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)<br/>      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)<br/>      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)<br/>      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)<br/>      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)<br/>      (relu): ReLU(inplace)<br/>    )<br/>  )<br/>  (layer3): Sequential(<br/>    (0): Bottleneck(<br/>      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)<br/>      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)<br/>      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)<br/>      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)<br/>      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)<br/>      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)<br/>      (relu): ReLU(inplace)<br/>      (downsample): Sequential(<br/>        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)<br/>        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)<br/>      )<br/>    )<br/>    (1): Bottleneck(<br/>      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)<br/>      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)<br/>      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)<br/>      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)<br/>      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)<br/>      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)<br/>      (relu): ReLU(inplace)<br/>    )<br/>    (2): Bottleneck(<br/>      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)<br/>      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)<br/>      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)<br/>      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)<br/>      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)<br/>      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)<br/>      (relu): ReLU(inplace)<br/>    )<br/>    (3): Bottleneck(<br/>      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)<br/>      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)<br/>      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)<br/>      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)<br/>      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)<br/>      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)<br/>      (relu): ReLU(inplace)<br/>    )<br/>    (4): Bottleneck(<br/>      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)<br/>      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)<br/>      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)<br/>      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)<br/>      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)<br/>      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)<br/>      (relu): ReLU(inplace)<br/>    )<br/>    (5): Bottleneck(<br/>      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)<br/>      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)<br/>      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)<br/>      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)<br/>      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)<br/>      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)<br/>      (relu): ReLU(inplace)<br/>    )<br/>  )<br/>  (layer4): Sequential(<br/>    (0): Bottleneck(<br/>      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)<br/>      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)<br/>      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)<br/>      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)<br/>      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)<br/>      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)<br/>      (relu): ReLU(inplace)<br/>      (downsample): Sequential(<br/>        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)<br/>        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)<br/>      )<br/>    )<br/>    (1): Bottleneck(<br/>      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)<br/>      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)<br/>      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)<br/>      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)<br/>      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)<br/>      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)<br/>      (relu): ReLU(inplace)<br/>    )<br/>    (2): Bottleneck(<br/>      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)<br/>      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)<br/>      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)<br/>      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)<br/>      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)<br/>      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)<br/>      (relu): ReLU(inplace)<br/>    )<br/>  )<br/>  (avgpool): AvgPool2d(kernel_size=7, stride=1, padding=0)<br/>  (fc): Linear(in_features=2048, out_features=1000, bias=True)<br/>)</span><span id="c5fc" class="mk lc iq mg b gy mp mm l mn mo">print(model_conv.fc)<br/>      Linear(in_features=2048, out_features=1000, bias=True)</span></pre><p id="c467" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">所以我们要调整的是最后一层(FC)。最后一层是线性层，具有 2048 个输入神经元和 1000 个输出神经元。如果你有 1000 个不同的类，这很有用。然而，我们只需要处理 7 个不同的类别——7 种不同的肿瘤类型——所以我们需要改变最后一层。</p><pre class="km kn ko kp gt mf mg mh mi aw mj bi"><span id="ac16" class="mk lc iq mg b gy ml mm l mn mo">num_ftrs = model_conv.fc.in_features<br/>model_conv.fc = torch.nn.Linear(num_ftrs, 7)<br/></span><span id="1043" class="mk lc iq mg b gy mp mm l mn mo">print(model_conv.fc)<br/>Linear(in_features=2048, out_features=7, bias=True)</span></pre><p id="3673" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">因此，现在在调整之后，我们需要将模型移动到 GPU，因为模型最终将在那里进行训练。</p><h1 id="0e9c" class="lb lc iq bd ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly bi translated">回到数据</h1><p id="04cf" class="pw-post-body-paragraph jn jo iq jp b jq lz js jt ju ma jw jx jy mb ka kb kc mc ke kf kg md ki kj kk ij bi translated"><strong class="jp ir">训练和验证集</strong></p><pre class="km kn ko kp gt mf mg mh mi aw mj bi"><span id="f905" class="mk lc iq mg b gy ml mm l mn mo">from sklearn.model_selection import train_test_split<br/><br/>train_df, test_df = train_test_split(tile_df, test_size=0.1)</span><span id="3d56" class="mk lc iq mg b gy mp mm l mn mo"><em class="mu"># We can split the test set again in a validation set and a true test set:</em><br/>validation_df, test_df = train_test_split(test_df, test_size=0.5)</span><span id="21f9" class="mk lc iq mg b gy mp mm l mn mo">train_df = train_df.reset_index()<br/>validation_df = validation_df.reset_index()<br/>test_df = test_df.reset_index()</span></pre><p id="b010" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">创建一个类‘数据集’</strong></p><p id="451f" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">dataset 类将允许我们在多个 CPU 上轻松地在后台加载和转换批量数据。</p><pre class="km kn ko kp gt mf mg mh mi aw mj bi"><span id="5601" class="mk lc iq mg b gy ml mm l mn mo">class <strong class="mg ir">Dataset</strong>(data.Dataset):<br/>    'Characterizes a dataset for PyTorch'<br/>    def __init__(self, df, transform=None):<br/>        'Initialization'<br/>        self.df = df<br/>        self.transform = transform<br/><br/>    def __len__(self):<br/>        'Denotes the total number of samples'<br/>        return len(self.df)<br/><br/>    def __getitem__(self, index):<br/>        'Generates one sample of data'<br/>        <em class="mu"># Load data and get label</em><br/>        X = Image.open(self.df['path'][index])<br/>        y = torch.tensor(int(self.df['cell_type_idx'][index]))<br/><br/>        if self.transform:<br/>            X = self.transform(X)<br/><br/>        return X, y</span><span id="365f" class="mk lc iq mg b gy mp mm l mn mo"><em class="mu"># Define the parameters for the dataloader</em><br/>params = {'batch_size': 4,<br/>          'shuffle': True,<br/>          'num_workers': 6}</span></pre><p id="1e4f" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">使用 dataset 类的另一个好处是，我们可以轻松地执行数据的预处理和/或数据扩充。</p><p id="9378" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">在本例中，我们只执行镜像(RandomHorizontalFlip，RandomVerticalFlip)，将图像裁剪到黑色素瘤最常出现的图像中心(CenterCrop)，从图像中心随机裁剪(RandomCrop)，并根据预训练模型的需要对图像进行归一化(normalize)。然后，我们使用将图像转换为张量，这是使用 PyTorch 进行学习所必需的，具有函数 ToTensor:</p><pre class="km kn ko kp gt mf mg mh mi aw mj bi"><span id="3711" class="mk lc iq mg b gy ml mm l mn mo"><em class="mu">define the transformation of the images.</em><br/>import torchvision.transforms as trf<br/>composed = trf.Compose([trf.RandomHorizontalFlip(), trf.RandomVerticalFlip(), trf.CenterCrop(256), trf.RandomCrop(224),  trf.ToTensor(),<br/>                        trf.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])])</span><span id="afb0" class="mk lc iq mg b gy mp mm l mn mo"><em class="mu"><br/># Define the trainingsset using the table train_df and using our defined transitions (composed)</em><br/>training_set = Dataset(train_df, transform=composed)<br/>training_generator = data.DataLoader(training_set, **params)<br/><br/><em class="mu"># Same for the validation set:</em><br/>validation_set = Dataset(validation_df, transform=composed)<br/>validation_generator = data.DataLoader(validation_set, **params)</span></pre><p id="deb3" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">现在我们必须定义我们想要使用的优化器。在这种情况下，它将是一个学习率为 1e 61e 6 的 Adam 优化器。</p><p id="ec45" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我们将使用的损失函数是 CrossEntropyLoss。这是为多类分类问题选择的典型方法。</p><pre class="km kn ko kp gt mf mg mh mi aw mj bi"><span id="6e0c" class="mk lc iq mg b gy ml mm l mn mo">optimizer = torch.optim.Adam(model.parameters(), lr=1e-6)<br/>criterion = torch.nn.CrossEntropyLoss()</span></pre><p id="d5bf" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">现在，我们有了一个用于训练集中数据的数据加载器，一个用于验证集中数据的数据加载器，并且我们已经定义了优化器和标准。我们现在可以开始训练和测试模型了。</p><h1 id="2040" class="lb lc iq bd ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly bi translated">训练和测试模型</h1><p id="7ab1" class="pw-post-body-paragraph jn jo iq jp b jq lz js jt ju ma jw jx jy mb ka kb kc mc ke kf kg md ki kj kk ij bi translated">训练和测试模型是机器学习的主要部分，在我看来也是最好的部分。这是真正的事情发生的地方。所有的数据准备和数据收集工作都很重要，这是有趣的部分，也是非常重要的。</p><p id="1957" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">要训练模型，只需输入以下代码:</p><pre class="km kn ko kp gt mf mg mh mi aw mj bi"><span id="ea2f" class="mk lc iq mg b gy ml mm l mn mo">max_epochs = 20<br/>trainings_error = []<br/>validation_error = []<br/>for epoch <strong class="mg ir">in</strong> range(max_epochs):<br/>    print('epoch:', epoch)<br/>    count_train = 0<br/>    trainings_error_tmp = []<br/>    model.train()<br/>    for data_sample, y <strong class="mg ir">in</strong> training_generator:<br/>        data_gpu = data_sample.to(device)<br/>        y_gpu = y.to(device)<br/>        output = model(data_gpu)<br/>        err = criterion(output, y_gpu)<br/>        err.backward()<br/>        optimizer.step()<br/>        trainings_error_tmp.append(err.item())<br/>        count_train += 1<br/>        if count_train &gt;= 100:<br/>            count_train = 0<br/>            mean_trainings_error = np.mean(trainings_error_tmp)<br/>            trainings_error.append(mean_trainings_error)<br/>            print('trainings error:', mean_trainings_error)<br/>            break<br/>    with torch.set_grad_enabled(False):<br/>        validation_error_tmp = []<br/>        count_val = 0<br/>        model.eval()<br/>        for data_sample, y <strong class="mg ir">in</strong> validation_generator:<br/>            data_gpu = data_sample.to(device)<br/>            y_gpu = y.to(device)<br/>            output = model(data_gpu)<br/>            err = criterion(output, y_gpu)<br/>            validation_error_tmp.append(err.item())<br/>            count_val += 1<br/>            if count_val &gt;= 10:<br/>                count_val = 0<br/>                mean_val_error = np.mean(validation_error_tmp)<br/>                validation_error.append(mean_val_error)<br/>                print('validation error:', mean_val_error)<br/>                break</span><span id="b1f9" class="mk lc iq mg b gy mp mm l mn mo">plt.plot(trainings_error, label = 'training error')<br/>plt.plot(validation_error, label = 'validation error')<br/>plt.legend()<br/>plt.show()</span></pre><p id="c45c" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">测试模型:</strong></p><p id="24f6" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">要测试模型的实际能力，请导入以下代码:</p><pre class="km kn ko kp gt mf mg mh mi aw mj bi"><span id="6338" class="mk lc iq mg b gy ml mm l mn mo">model.eval()<br/>test_set = Dataset(validation_df, transform=composed)<br/>test_generator = data.SequentialSampler(validation_set)</span><span id="1974" class="mk lc iq mg b gy mp mm l mn mo">result_array = []<br/>gt_array = []<br/>for i <strong class="mg ir">in</strong> test_generator:<br/>    data_sample, y = validation_set.__getitem__(i)<br/>    data_gpu = data_sample.unsqueeze(0).to(device)<br/>    output = model(data_gpu)<br/>    result = torch.argmax(output)<br/>    result_array.append(result.item())<br/>    gt_array.append(y.item())</span><span id="2743" class="mk lc iq mg b gy mp mm l mn mo">correct_results = np.array(result_array)==np.array(gt_array)</span><span id="31ec" class="mk lc iq mg b gy mp mm l mn mo">sum_correct = np.sum(correct_results)</span><span id="bda1" class="mk lc iq mg b gy mp mm l mn mo">accuracy = sum_correct/test_generator.__len__()</span><span id="73d6" class="mk lc iq mg b gy mp mm l mn mo">print(accuracy)<br/>0.8403193612774451</span></pre><p id="5318" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">现在你可以看到，我们的精度相当高，但并不完美。这个模型也不会是 100%完美的，但它肯定很接近，很快就会实现。</p><p id="5d9a" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">现在有了这个，人们不必每次出现皮肤癌的症状都去看医生，只需在自己家里舒适地进行测试。现在人们不会因为不想去看医生而死于皮肤癌。</p><p id="623c" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">如果你有任何问题，请在下面的评论中留下，别忘了鼓掌！</p></div></div>    
</body>
</html>