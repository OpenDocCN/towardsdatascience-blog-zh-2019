<html>
<head>
<title>Finding Donors: Classification Project With PySpark</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">寻找捐赠者:PySpark 分类项目</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/finding-donors-classification-project-with-pyspark-485fb3c94e5e?source=collection_archive---------19-----------------------#2019-06-19">https://towardsdatascience.com/finding-donors-classification-project-with-pyspark-485fb3c94e5e?source=collection_archive---------19-----------------------#2019-06-19</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="af38" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">了解如何使用 Apache PySpark 来增强您的分类预测</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/6756e3d0338155353eb89b24f8f91518.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*0V6esVMFsm9V61_m"/></div></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk">Picture from <a class="ae ky" href="https://unsplash.com/photos/Wpnoqo2plFA" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><h1 id="af8a" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">介绍</h1><p id="2a16" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">本文的目的是对机器学习中的分类问题做一个温和的介绍，并通过一个全面的指南来成功地使用 PySpark 开发一个类预测。</p><p id="ad12" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">所以没有进一步的行动，让我们投入进去吧！</p><h1 id="4437" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">分类</h1><p id="1c8c" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">如果你想深入了解分类问题、它的主要算法以及如何使用机器学习技术来处理它们，我强烈建议你去看看下面这篇文章，在这篇文章中，我详细地解释了这个概念。</p><div class="ms mt gp gr mu mv"><a rel="noopener follow" target="_blank" href="/supervised-learning-basics-of-classification-and-main-algorithms-c16b06806cd3"><div class="mw ab fo"><div class="mx ab my cl cj mz"><h2 class="bd iu gy z fp na fr fs nb fu fw is bi translated">监督学习:分类基础和主要算法</h2><div class="nc l"><h3 class="bd b gy z fp na fr fs nb fu fw dk translated">了解机器如何分类</h3></div><div class="nd l"><p class="bd b dl z fp na fr fs nb fu fw dk translated">towardsdatascience.com</p></div></div><div class="ne l"><div class="nf l ng nh ni ne nj ks mv"/></div></div></a></div><h2 id="74e4" class="nk la it bd lb nl nm dn lf nn no dp lj ma np nq ll me nr ns ln mi nt nu lp nv bi translated">什么是分类？</h2><p id="3ca4" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">分类是监督学习的一个子类，其目标是基于过去的观察来预测新实例的分类类别标签(离散的、无序的值、组成员)。</p><p id="462d" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">分类问题主要有两种类型:</p><ul class=""><li id="a955" class="nw nx it lt b lu mn lx mo ma ny me nz mi oa mm ob oc od oe bi translated">二元分类:典型的例子是邮件垃圾邮件检测，其中每封邮件都是垃圾邮件→ 1 封垃圾邮件；或者不是→ 0。</li><li id="031a" class="nw nx it lt b lu of lx og ma oh me oi mi oj mm ob oc od oe bi translated">多类分类:像手写字符识别(类从 0 到 9)。</li></ul><p id="648a" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">下面的例子很有代表性地解释了二元分类法:</p><p id="2b88" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">有两个类别，圆和十字，以及两个特征，X1 和 X2。该模型能够找到每个数据点的特征与其类别之间的关系，并在它们之间设置边界线，因此当提供新数据时，它可以估计其所属的类别，给定其特征。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="ab gu cl ok"><img src="../Images/72e63ec35c59e4adf7116d3dafb3ba5a.png" data-original-src="https://miro.medium.com/v2/format:webp/1*fBjniQPOKigqxYSKEumXoA.png"/></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk">Figure by Author</figcaption></figure><p id="83eb" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">在这种情况下，新数据点落入圆形子空间，因此，模型将预测其类别为圆形。</p><h2 id="2315" class="nk la it bd lb nl nm dn lf nn no dp lj ma np nq ll me nr ns ln mi nt nu lp nv bi translated">分类主要算法</h2><p id="e81b" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">为了预测某些样本的类别，可以使用几种分类算法。事实上，在开发我们的机器学习模型时，我们会对其中的一定数量进行训练和评估，我们会保留那些预测性能更好的模型。</p><p id="742f" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">一些最常用的算法的非穷尽列表如下:</p><ul class=""><li id="3e26" class="nw nx it lt b lu mn lx mo ma ny me nz mi oa mm ob oc od oe bi translated">逻辑回归</li><li id="56e3" class="nw nx it lt b lu of lx og ma oh me oi mi oj mm ob oc od oe bi translated">决策树</li><li id="29dc" class="nw nx it lt b lu of lx og ma oh me oi mi oj mm ob oc od oe bi translated">随机森林</li><li id="b1c7" class="nw nx it lt b lu of lx og ma oh me oi mi oj mm ob oc od oe bi translated">支持向量机</li><li id="932b" class="nw nx it lt b lu of lx og ma oh me oi mi oj mm ob oc od oe bi translated">k-最近邻(KNN)</li></ul><h2 id="fabd" class="nk la it bd lb nl nm dn lf nn no dp lj ma np nq ll me nr ns ln mi nt nu lp nv bi translated">分类评估指标</h2><p id="52a8" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">当对事件进行预测时，我们可以得到四种结果:</p><ul class=""><li id="aa3d" class="nw nx it lt b lu mn lx mo ma ny me nz mi oa mm ob oc od oe bi translated">真阳性:TP</li><li id="501e" class="nw nx it lt b lu of lx og ma oh me oi mi oj mm ob oc od oe bi translated">真阴性:TN</li><li id="0c83" class="nw nx it lt b lu of lx og ma oh me oi mi oj mm ob oc od oe bi translated">误报:FP</li><li id="6cc0" class="nw nx it lt b lu of lx og ma oh me oi mi oj mm ob oc od oe bi translated">假阴性:FN</li></ul><p id="fda7" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">所有这些都在下面的分类矩阵中表示:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ol"><img src="../Images/df97bbef7edb6133253d4e0264918f3f.png" data-original-src="https://miro.medium.com/v2/resize:fit:664/format:webp/0*ryvmZJ40k8yVnlr_.png"/></div></figure><p id="a15c" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated"><strong class="lt iu">准确性</strong>衡量分类器做出正确预测的频率。它是正确预测的数量与预测总数(测试数据点的数量)的比率。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi om"><img src="../Images/234c01f04e1ac99234c203e70ecb066f.png" data-original-src="https://miro.medium.com/v2/resize:fit:678/format:webp/1*_WCAZ2LmAYT3FJS59kFiJQ.png"/></div></figure><p id="041d" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated"><strong class="lt iu"> Precision </strong>告诉我们我们归类为某一类的事件的比例，实际上是那个类。它是真阳性与所有阳性的比率。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi on"><img src="../Images/5a4c5b810ef94da02c9e5fdbe9cb4c00.png" data-original-src="https://miro.medium.com/v2/resize:fit:508/format:webp/1*vIeuuORD9gXKdroLoIbC0Q.png"/></div></figure><p id="031f" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">回忆(敏感度)告诉我们实际上属于某一类别的事件中有多少被我们归类为该类别。它是真阳性与所有阳性的比率。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi oo"><img src="../Images/2c3ff40172f228b3c2543a4e6ad59a6c.png" data-original-src="https://miro.medium.com/v2/resize:fit:478/format:webp/1*0jS_lWQ3q0shAorbCivZ6w.png"/></div></figure><p id="f664" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated"><strong class="lt iu">特异性</strong>是被正确识别为阴性的类别占阴性类别总数的比例。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi op"><img src="../Images/c3bc6e90250df36da26b3e1ae38e561a.png" data-original-src="https://miro.medium.com/v2/resize:fit:504/format:webp/1*NOQAxQMiup_AyK_XS0OyHw.png"/></div></figure><p id="742d" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">对于分类分布有偏差的分类问题，准确性本身并不是一个合适的度量。反而精度和召回率更有代表性。</p><p id="d9ac" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">这两个指标可以结合起来得到<strong class="lt iu"> F1 分数</strong>，它是精确度和召回分数的加权平均值(调和平均值)。这个分数的范围从 0 到 1，1 是可能的最佳 F1 分数(我们在处理比率时采用调和平均值)。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi oq"><img src="../Images/6599e3f35dfc0c1cdb4bd0c7c5a4a7c0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1100/format:webp/1*SaP3n4_vtVbSo3o9r_wDcQ.png"/></div></figure><h2 id="baca" class="nk la it bd lb nl nm dn lf nn no dp lj ma np nq ll me nr ns ln mi nt nu lp nv bi translated">皇家对空观察队</h2><p id="bc11" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">最后，我们将在项目中使用的指标是<strong class="lt iu">接收机操作特性或 ROC </strong>。</p><p id="cfe2" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">ROC 曲线告诉我们该模型区分两个类别的能力有多强。它可以得到从 0 到 1 的值(€[0，1])。模型越好，越接近 1 值。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi or"><img src="../Images/bb9993a22c4e0819d2f65fbe7d4ead7c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_Ew6vT0cd2LrAPJEc5vJsg.png"/></div></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk">Figure by Author</figcaption></figure><p id="38e8" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">从上图中可以看出，我们的分类模型将在类别和之间绘制一个分离边界:</p><ul class=""><li id="4262" class="nw nx it lt b lu mn lx mo ma ny me nz mi oa mm ob oc od oe bi translated">落在阈值左边的每个样本将被归类为负类。</li><li id="4949" class="nw nx it lt b lu of lx og ma oh me oi mi oj mm ob oc od oe bi translated">落在阈值右边的每个样本将被分类为阳性类别，</li></ul><p id="d2ac" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">预测的分布如下:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi os"><img src="../Images/f50e3afb7c03ce4126b46801a3070f21.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*mKqmwaGX_YuPKVNofGxKKQ.png"/></div></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk">Figure by Author</figcaption></figure><p id="8702" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated"><strong class="lt iu">灵敏度&amp;特异性</strong>之间的权衡</p><p id="9630" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">当我们降低阈值时，我们最终会预测更多的正值，并提高灵敏度。因此，特异性降低。</p><p id="c37d" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">当我们提高阈值时，我们最终会预测更多的负值并提高特异性。因此降低了灵敏度。</p><p id="8889" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">如<strong class="lt iu">敏感性</strong> ⬇️ <strong class="lt iu">特异性</strong> ⬆️</p><p id="59f0" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">如<strong class="lt iu">特异性</strong> ⬇️ <strong class="lt iu">敏感性</strong> ⬆️</p><p id="c713" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">为了优化分类性能，我们考虑(1-特异性)而不是特异性。所以，当敏感性增加时，(1-特异性)也会增加。这就是我们计算 ROC 的方法。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ot"><img src="../Images/d1ab7154ee47ccc99e4fc165dfa8319e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*4rV4lK_IS9jkliiebTiYhA.png"/></div></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk">Figure by Author</figcaption></figure><h2 id="7a63" class="nk la it bd lb nl nm dn lf nn no dp lj ma np nq ll me nr ns ln mi nt nu lp nv bi translated">性能示例</h2><p id="2106" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">如前所述，赋值器越接近 1，模型的预测性能就越好，类之间的重叠区域就越小。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ou"><img src="../Images/e95ae96f37218318e9450eb641b75cf5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*5XLCjZxQwzfiez1Ofk9keg.png"/></div></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk">Figure by Author</figcaption></figure><h1 id="1394" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">寻找捐助者项目</h1><p id="7cfe" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">可以在以下文章中找到该项目的完整介绍:</p><div class="ms mt gp gr mu mv"><a rel="noopener follow" target="_blank" href="/classification-project-finding-donors-853db66fbb8c"><div class="mw ab fo"><div class="mx ab my cl cj mz"><h2 class="bd iu gy z fp na fr fs nb fu fw is bi translated">机器学习分类项目:寻找捐赠者</h2><div class="nc l"><h3 class="bd b gy z fp na fr fs nb fu fw dk translated">使用此分类模型查找并预测谁将向慈善机构捐款！</h3></div><div class="nd l"><p class="bd b dl z fp na fr fs nb fu fw dk translated">towardsdatascience.com</p></div></div><div class="ne l"><div class="ov l ng nh ni ne nj ks mv"/></div></div></a></div><p id="ba3d" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">在本文中，我们将关注该项目的 PySpark 实现。</p><p id="c754" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">总之，在整个项目中，我们将使用许多不同的监督算法，使用从 1994 年美国人口普查中收集的数据来精确预测个人收入。</p><p id="7072" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">然后，我们将从初步结果中选择最佳候选算法，并进一步优化该算法以最佳地模拟数据。</p><p id="0480" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">我们实现的目标是构建一个模型，准确预测个人收入是否超过 50，000 美元。根据我们之前的研究，我们发现最有可能向慈善机构捐款的人是那些年收入超过 5 万美元的人。</p><p id="f502" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">因此，我们面临着一个二元分类问题，我们想确定一个人的年收入是否超过 5 万美元(第 1 类)或没有(第 0 类)。</p><p id="f504" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">这个项目的数据集来源于<a class="ae ky" href="https://archive.ics.uci.edu/ml/datasets/Census+Income" rel="noopener ugc nofollow" target="_blank"> UCI 机器学习知识库</a>。</p><h2 id="3c2e" class="nk la it bd lb nl nm dn lf nn no dp lj ma np nq ll me nr ns ln mi nt nu lp nv bi translated">数据</h2><p id="54d0" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">人口普查数据集由大约 45222 个数据点组成，每个数据点有 13 个特征。</p><p id="1e13" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated"><strong class="lt iu">特性</strong></p><ul class=""><li id="d25a" class="nw nx it lt b lu mn lx mo ma ny me nz mi oa mm ob oc od oe bi translated"><code class="fe ow ox oy oz b">age</code>:年龄</li><li id="94c7" class="nw nx it lt b lu of lx og ma oh me oi mi oj mm ob oc od oe bi translated"><code class="fe ow ox oy oz b">workclass</code>:工人阶级(私营、自营企业、自营企业、联邦政府、地方政府、州政府、无薪、从未工作)</li><li id="4383" class="nw nx it lt b lu of lx og ma oh me oi mi oj mm ob oc od oe bi translated"><code class="fe ow ox oy oz b">education_level</code>:教育水平(学士、专科学校、11 年级、高级研究生、专业学校、acdm 协会、voc 协会、9 年级、7-8 年级、12 年级、硕士、1-4 年级、10 年级、博士、5-6 年级、学前班)</li><li id="b1ca" class="nw nx it lt b lu of lx og ma oh me oi mi oj mm ob oc od oe bi translated"><code class="fe ow ox oy oz b">education-num</code>:完成的教育年数</li><li id="d073" class="nw nx it lt b lu of lx og ma oh me oi mi oj mm ob oc od oe bi translated"><code class="fe ow ox oy oz b">marital-status</code>:婚姻状况(已婚-未婚-配偶、离婚、未婚、分居、丧偶、已婚-配偶不在、已婚-配偶)</li><li id="4d8f" class="nw nx it lt b lu of lx og ma oh me oi mi oj mm ob oc od oe bi translated"><code class="fe ow ox oy oz b">occupation</code>:工作职业(技术支持、工艺维修、其他服务、销售、行政管理、专业教授、搬运工人、清洁工、机器操作员、行政文员、农业渔业、运输搬运、私人服务、保安服务、武装部队)</li><li id="0454" class="nw nx it lt b lu of lx og ma oh me oi mi oj mm ob oc od oe bi translated"><code class="fe ow ox oy oz b">relationship</code>:关系状态(妻子、亲生子女、丈夫、非家庭成员、其他亲属、未婚)</li><li id="93ca" class="nw nx it lt b lu of lx og ma oh me oi mi oj mm ob oc od oe bi translated">种族(白人、亚洲太平洋岛民、美洲印第安爱斯基摩人、其他人、黑人)</li><li id="c57e" class="nw nx it lt b lu of lx og ma oh me oi mi oj mm ob oc od oe bi translated"><code class="fe ow ox oy oz b">sex</code>:性别(女，男)</li><li id="9162" class="nw nx it lt b lu of lx og ma oh me oi mi oj mm ob oc od oe bi translated"><code class="fe ow ox oy oz b">capital-gain</code>:货币资本收益</li><li id="0e7a" class="nw nx it lt b lu of lx og ma oh me oi mi oj mm ob oc od oe bi translated"><code class="fe ow ox oy oz b">capital-loss</code>:货币资本损失</li><li id="432e" class="nw nx it lt b lu of lx og ma oh me oi mi oj mm ob oc od oe bi translated"><code class="fe ow ox oy oz b">hours-per-week</code>:每周平均工作时间</li><li id="6597" class="nw nx it lt b lu of lx og ma oh me oi mi oj mm ob oc od oe bi translated"><code class="fe ow ox oy oz b">native-country</code>:本土国家(美国、柬埔寨、英国、波多黎各、加拿大、德国、美国外围地区(关岛-USVI 等)、印度、日本、希腊、中国、古巴、伊朗、洪都拉斯、菲律宾、意大利、波兰、牙买加、越南、墨西哥、葡萄牙、爱尔兰、法国、多米尼加共和国、老挝、厄瓜多尔、台湾、海地、哥伦比亚、匈牙利、危地马拉、尼加拉瓜、苏格兰、泰国、南斯拉夫、萨尔瓦多、特立尼达和多巴哥&amp;多巴哥、秘鲁、香港、荷兰)</li></ul><p id="0d0c" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated"><strong class="lt iu">目标变量</strong></p><ul class=""><li id="b2ae" class="nw nx it lt b lu mn lx mo ma ny me nz mi oa mm ob oc od oe bi translated"><code class="fe ow ox oy oz b">income</code>:收入阶层(&lt; =50K，&gt; 50K)</li></ul><h2 id="ca05" class="nk la it bd lb nl nm dn lf nn no dp lj ma np nq ll me nr ns ln mi nt nu lp nv bi translated">导入数据和探索性数据分析(EDA)</h2><p id="541a" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">我们将从导入数据集并显示数据的前几行开始，以对探索性数据分析进行初步近似。</p><pre class="kj kk kl km gt pa oz pb pc aw pd bi"><span id="6c64" class="nk la it oz b gy pe pf l pg ph"><strong class="oz iu"># File location and type</strong><br/>file_location = "/FileStore/tables/census.csv"<br/>file_type = "csv"</span><span id="df11" class="nk la it oz b gy pi pf l pg ph"><strong class="oz iu"># CSV options</strong><br/>infer_schema = "true"<br/>first_row_is_header = "true"<br/>delimiter = ","</span><span id="1775" class="nk la it oz b gy pi pf l pg ph"><strong class="oz iu"># The applied options are for CSV files. For other file types, these will be ignored.</strong><br/>df = spark.read.format(file_type) \<br/>  .option("inferSchema", infer_schema) \<br/>  .option("header", first_row_is_header) \<br/>  .option("sep", delimiter) \<br/>  .load(file_location)</span><span id="eb4c" class="nk la it oz b gy pi pf l pg ph">display(df)</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pj"><img src="../Images/1d2602bd67f61c92b868a4ceb9721b88.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*v_zdy6nvX2SbKkdIXAkomw.png"/></div></div></figure><p id="edf9" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">我们现在将通过使用。describe()方法。</p><pre class="kj kk kl km gt pa oz pb pc aw pd bi"><span id="a3e4" class="nk la it oz b gy pe pf l pg ph"><strong class="oz iu"># Display Dataset's Summary</strong><br/>display(df.describe())</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pj"><img src="../Images/4abb67759eca582a9d0aceddeb15d2a7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*rFi8aV8op0ZYpqdGCTHI0A.png"/></div></div></figure><p id="0de8" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">让我们也找出数据集的模式。</p><pre class="kj kk kl km gt pa oz pb pc aw pd bi"><span id="9bbe" class="nk la it oz b gy pe pf l pg ph"><strong class="oz iu"># Display Dataset's Schema</strong><br/>display(df.describe())</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi pk"><img src="../Images/471c484ba1d02c5241d1535e0125b481.png" data-original-src="https://miro.medium.com/v2/resize:fit:754/format:webp/1*lWxJl4ej72dLPPmsY_L5ww.png"/></div></figure><h2 id="6714" class="nk la it bd lb nl nm dn lf nn no dp lj ma np nq ll me nr ns ln mi nt nu lp nv bi translated">准备数据</h2><p id="7c38" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">因为我们想预测个人年收入是否超过 50K 美元，我们将把标签“收入”替换为“&gt; 50K”。</p><p id="c154" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">为此，我们将创建一个新列，根据个人年收入是否超过 5 万美元，该列的值将为 1 或 0。然后我们将删除收入栏。</p><pre class="kj kk kl km gt pa oz pb pc aw pd bi"><span id="b624" class="nk la it oz b gy pe pf l pg ph"><strong class="oz iu"># Import pyspark functions</strong><br/>from pyspark.sql import functions as F</span><span id="29ba" class="nk la it oz b gy pi pf l pg ph"><strong class="oz iu"># Create add new column to the dataset</strong><br/>df = df.withColumn('&gt;50K', F.when(df.income == '&lt;=50K', 0).otherwise(1))</span><span id="f85e" class="nk la it oz b gy pi pf l pg ph"><strong class="oz iu"># Drop the Income label</strong><br/>df = df.drop('income')</span><span id="e0f3" class="nk la it oz b gy pi pf l pg ph"><strong class="oz iu"># Show dataset's columns<br/></strong>df.columns</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi pl"><img src="../Images/80c6d607a96b7b3b0815cf899b59e29e.png" data-original-src="https://miro.medium.com/v2/resize:fit:302/format:webp/1*50edwX-aZFNsCELj5mHlBw.png"/></div></figure><h2 id="c1d4" class="nk la it bd lb nl nm dn lf nn no dp lj ma np nq ll me nr ns ln mi nt nu lp nv bi translated">向量化数字特征和一次性编码分类特征</h2><p id="1f4e" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">为了对模型的训练进行处理，Apache Spark 中的特征必须被转换成向量。这个过程将使用我们现在将要探索的某些类来完成。</p><p id="7347" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">首先，我们将导入相关的库和方法。</p><pre class="kj kk kl km gt pa oz pb pc aw pd bi"><span id="55e1" class="nk la it oz b gy pe pf l pg ph">from pyspark.ml import Pipeline<br/>from pyspark.ml.feature import StringIndexer, OneHotEncoder, VectorAssembler<br/>from pyspark.ml.classification import (DecisionTreeClassifier, GBTClassifier, RandomForestClassifier, LogisticRegression)<br/>from pyspark.ml.evaluation import BinaryClassificationEvaluator</span></pre><p id="5dac" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">现在，我们将选择分类特征。</p><pre class="kj kk kl km gt pa oz pb pc aw pd bi"><span id="989e" class="nk la it oz b gy pe pf l pg ph"><strong class="oz iu"># Selecting categorical features</strong><br/>categorical_columns = [<br/> 'workclass',<br/> 'education_level',<br/> 'marital-status',<br/> 'occupation',<br/> 'relationship',<br/> 'race',<br/> 'sex',<br/> 'hours-per-week',<br/> 'native-country',<br/> ]</span></pre><p id="e08b" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">为了对这种分类特征进行一次性编码，我们将首先将它们通过索引器，然后传递给编码器。</p><pre class="kj kk kl km gt pa oz pb pc aw pd bi"><span id="59d1" class="nk la it oz b gy pe pf l pg ph"><strong class="oz iu"># The index of string values multiple columns</strong><br/>indexers = [<br/>    StringIndexer(inputCol=c, outputCol="{0}_indexed".format(c))<br/>    for c in categorical_columns]</span><span id="e816" class="nk la it oz b gy pi pf l pg ph"><strong class="oz iu"># The encode of indexed values multiple columns</strong><br/>encoders = [OneHotEncoder(dropLast=False,inputCol=indexer.getOutputCol(),<br/>            outputCol="{0}_encoded".format(indexer.getOutputCol())) <br/>    for indexer in indexers]</span></pre><p id="463f" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">现在，我们将把分类编码的特征与数字特征结合起来，并用它们两者构成一个向量。</p><pre class="kj kk kl km gt pa oz pb pc aw pd bi"><span id="5f3d" class="nk la it oz b gy pe pf l pg ph"><strong class="oz iu"># Vectorizing encoded values</strong><br/>categorical_encoded = [encoder.getOutputCol() for encoder in encoders]<br/>numerical_columns = ['age', 'education-num', 'capital-gain', 'capital-loss']<br/>inputcols = categorical_encoded + numerical_columns<br/>assembler = VectorAssembler(inputCols=inputcols, outputCol="features")</span></pre><p id="9d10" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">现在，我们将建立一个管道来自动化这个阶段。</p><pre class="kj kk kl km gt pa oz pb pc aw pd bi"><span id="5234" class="nk la it oz b gy pe pf l pg ph">pipeline = Pipeline(stages=indexers + encoders+[assembler])<br/>model = pipeline.fit(df)</span><span id="aed8" class="nk la it oz b gy pi pf l pg ph"><strong class="oz iu"># Transform data</strong><br/>transformed = model.transform(df)<br/>display(transformed)</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pm"><img src="../Images/d1c3d98deae8899f227b55a3fbf5ff54.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*0Dclf51k9v1L1mNGoc_dZw.png"/></div></div></figure><p id="69f5" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">最后，我们将只选择具有相关特征的数据集。</p><pre class="kj kk kl km gt pa oz pb pc aw pd bi"><span id="4df8" class="nk la it oz b gy pe pf l pg ph"><strong class="oz iu"># Transform data</strong><br/>final_data = transformed.select('features', '&gt;50K')</span></pre><h2 id="b114" class="nk la it bd lb nl nm dn lf nn no dp lj ma np nq ll me nr ns ln mi nt nu lp nv bi translated">初始化模型</h2><p id="00b4" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">对于这个项目，我们将研究三种不同分类算法的预测性能:</p><ul class=""><li id="2af8" class="nw nx it lt b lu mn lx mo ma ny me nz mi oa mm ob oc od oe bi translated">决策树</li><li id="ea34" class="nw nx it lt b lu of lx og ma oh me oi mi oj mm ob oc od oe bi translated">随机森林</li><li id="1426" class="nw nx it lt b lu of lx og ma oh me oi mi oj mm ob oc od oe bi translated">梯度增强树</li></ul><pre class="kj kk kl km gt pa oz pb pc aw pd bi"><span id="83b4" class="nk la it oz b gy pe pf l pg ph"><strong class="oz iu"># Initialize the classification models</strong><br/>dtc = DecisionTreeClassifier(labelCol='&gt;50K', featuresCol='features')<br/>rfc = RandomForestClassifier(numTrees=150, labelCol='&gt;50K', featuresCol='features')<br/>gbt = GBTClassifier(labelCol='&gt;50K', featuresCol='features', maxIter=10)</span></pre><h2 id="0a2d" class="nk la it bd lb nl nm dn lf nn no dp lj ma np nq ll me nr ns ln mi nt nu lp nv bi translated">拆分数据</h2><p id="7e89" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">我们将在训练和测试数据之间执行经典的 80/20 拆分。</p><pre class="kj kk kl km gt pa oz pb pc aw pd bi"><span id="152c" class="nk la it oz b gy pe pf l pg ph">train_data, test_data = final_data.randomSplit([0.8,0.2])</span></pre><h2 id="d28f" class="nk la it bd lb nl nm dn lf nn no dp lj ma np nq ll me nr ns ln mi nt nu lp nv bi translated">训练模型</h2><pre class="kj kk kl km gt pa oz pb pc aw pd bi"><span id="9e6e" class="nk la it oz b gy pe pf l pg ph">dtc_model = dtc.fit(train_data)<br/>rfc_model = rfc.fit(train_data)<br/>gbt_model = gbt.fit(train_data)</span></pre><p id="7fcd" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated"><strong class="lt iu">获得预测</strong></p><pre class="kj kk kl km gt pa oz pb pc aw pd bi"><span id="fe04" class="nk la it oz b gy pe pf l pg ph">dtc_preds = dtc_model.transform(test_data)<br/>rfc_preds = rfc_model.transform(test_data)<br/>gbt_preds = gbt_model.transform(test_data)</span></pre><h2 id="1293" class="nk la it bd lb nl nm dn lf nn no dp lj ma np nq ll me nr ns ln mi nt nu lp nv bi translated">评估模型的性能</h2><p id="8911" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">如前所述，我们的评估者将是中华民国。我们将初始化它的类，并将预测值传递给它，以便获得值。</p><pre class="kj kk kl km gt pa oz pb pc aw pd bi"><span id="c05d" class="nk la it oz b gy pe pf l pg ph">my_eval = BinaryClassificationEvaluator(labelCol='&gt;50K')</span><span id="e886" class="nk la it oz b gy pi pf l pg ph"><strong class="oz iu"># Display Decision Tree evaluation metric</strong><br/>print('DTC')<br/>print(my_eval.evaluate(dtc_preds))</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi pn"><img src="../Images/3b0e93de63fc327f495d3a95ee7c3709.png" data-original-src="https://miro.medium.com/v2/resize:fit:312/format:webp/1*_sEPstSoPjSqAfUbV4rCWw.png"/></div></figure><pre class="kj kk kl km gt pa oz pb pc aw pd bi"><span id="1595" class="nk la it oz b gy pe pf l pg ph"><strong class="oz iu"># Display Random Forest evaluation metric</strong><br/>print('RFC')<br/>print(my_eval.evaluate(rfc_preds))</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi po"><img src="../Images/fe0e8dd274920613d5ce2c142357bde8.png" data-original-src="https://miro.medium.com/v2/resize:fit:290/format:webp/1*GflbTj69iOH0oUcv54Uh4w.png"/></div></figure><pre class="kj kk kl km gt pa oz pb pc aw pd bi"><span id="d76b" class="nk la it oz b gy pe pf l pg ph"><strong class="oz iu"># Display Gradien Boosting Tree evaluation metric</strong><br/>print('GBT')<br/>print(my_eval.evaluate(gbt_preds))</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi pp"><img src="../Images/738f4614c1c0808415981e9acd727337.png" data-original-src="https://miro.medium.com/v2/resize:fit:314/format:webp/1*VhGz7TKUSQP4TMwVcGc74Q.png"/></div></figure><p id="0467" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">最佳预测器是梯度提升树。实际上，0.911 是一个非常好的值，当显示其预测值时，我们将看到以下内容:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pj"><img src="../Images/244d16e4b80674eda545ff4ae232cb24.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*v4fnxip5xJXuD1EhpdZzcg.png"/></div></div></figure><h2 id="a3dc" class="nk la it bd lb nl nm dn lf nn no dp lj ma np nq ll me nr ns ln mi nt nu lp nv bi translated">提高模型性能</h2><p id="666a" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">我们将尝试通过执行网格搜索交叉验证技术来做到这一点。有了它，我们将使用先前超参数值集的不同组合来评估模型的性能。</p><p id="6180" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">我们将调整的超参数有:</p><ul class=""><li id="4eca" class="nw nx it lt b lu mn lx mo ma ny me nz mi oa mm ob oc od oe bi translated">最大深度</li><li id="1f2e" class="nw nx it lt b lu of lx og ma oh me oi mi oj mm ob oc od oe bi translated">最大箱数</li><li id="940c" class="nw nx it lt b lu of lx og ma oh me oi mi oj mm ob oc od oe bi translated">最大迭代次数</li></ul><pre class="kj kk kl km gt pa oz pb pc aw pd bi"><span id="2b0f" class="nk la it oz b gy pe pf l pg ph"><strong class="oz iu"># Import libraries</strong><br/>from pyspark.ml.tuning import ParamGridBuilder, CrossValidator</span><span id="496e" class="nk la it oz b gy pi pf l pg ph"><strong class="oz iu"># Set the Parameters grid</strong><br/>paramGrid = (ParamGridBuilder()<br/>             .addGrid(gbt.maxDepth, [2, 4, 6])<br/>             .addGrid(gbt.maxBins, [20, 60])<br/>             .addGrid(gbt.maxIter, [10, 20])<br/>             .build())</span><span id="7936" class="nk la it oz b gy pi pf l pg ph"><strong class="oz iu"># Iinitializing the cross validator class</strong><br/>cv = CrossValidator(estimator=gbt, estimatorParamMaps=paramGrid, evaluator=my_eval, numFolds=5)</span><span id="5eed" class="nk la it oz b gy pi pf l pg ph"><strong class="oz iu"># Run cross validations.  This can take about 6 minutes since it is training over 20 trees</strong><br/>cvModel = cv.fit(train_data)<br/>gbt_predictions_2 = cvModel.transform(test_data)<br/>my_eval.evaluate(gbt_predictions_2)</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi pq"><img src="../Images/6b2eb3f6cbbe228b33beb312008b8cd3.png" data-original-src="https://miro.medium.com/v2/resize:fit:482/format:webp/1*7Sd5DIoL6MVj4e-wO9Zzpg.png"/></div></figure><p id="4767" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">我们在预测性能上获得了微小的改进。而计算时间，几乎到了 20 分钟。因此，在这些情况下，我们应该分析这种改进是否值得努力。</p><h1 id="756e" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">结论</h1><p id="07a1" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">在整篇文章中，我们做了一个端到端的机器学习分类项目。我们还学习并获得了一些关于分类模型的见解，以及使用 PySpark、其方法和实现来开发一个具有良好性能的分类模型的关键。</p><p id="cb21" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">我们还学会了一旦识别出一个性能良好的模型，如何调整我们的算法。</p><p id="e97e" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">在接下来的文章中，我们将学习如何在 PySpark 中开发回归模型。所以，如果你对这个话题感兴趣，我强烈建议你继续关注！</p><p id="3658" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated"><em class="pr">如果你喜欢这篇文章，那么你可以看看我关于数据科学和机器学习的其他文章</em> <a class="ae ky" href="https://medium.com/@rromanss23" rel="noopener"> <em class="pr">这里</em> </a> <em class="pr">。</em></p><p id="034f" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated"><em class="pr">如果你想了解更多关于机器学习、数据科学和人工智能的知识</em> <strong class="lt iu"> <em class="pr">请在 Medium </em> </strong> <em class="pr">上关注我，敬请关注我的下一篇帖子！</em></p></div></div>    
</body>
</html>