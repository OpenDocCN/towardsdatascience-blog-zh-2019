# 模型解释和现实世界中的因果关系

> 原文：<https://towardsdatascience.com/causality-in-model-explanations-and-in-the-real-world-9f57e17a9138?source=collection_archive---------26----------------------->

## 你不能总是改变一个人的输入来看输出。

在 Fiddler Labs，我们非常重视忠实于模型行为的模型解释。理想情况下，特征重要性解释应该浮出水面，并适当地量化所有且仅是那些对预测有因果关系的因素。如果我们希望解释符合法律规定，这一点尤为重要(例如， [GDPR，第 13 条第 2f 款](https://gdpr-info.eu/art-22-gdpr/)，人们有权*'【了解】是否存在自动决策，包括特征分析)..和..关于所涉及的逻辑的有意义的信息'*)，以及可操作的。即使在做出人类可以理解的后处理解释时，我们也必须保持对模型的忠实。

我们如何区分与结果相关的特征和导致结果的特征？换句话说，**我们如何看待一个特性对一个模型输出或者一个现实世界任务的因果关系？让我们一个一个来。**

![](img/08667d090127aaa28fd5d96b77834fba.png)

# 解释模型中的因果关系很难

在解释模型预测时，我们希望量化每个(因果)特征对预测的贡献。

例如，在信用风险模型中，我们可能想知道收入或邮政编码对预测有多重要。

请注意，邮政编码可能是模型预测的因果关系(即，更改邮政编码可能会更改模型预测)，即使它可能不是基础任务的因果关系(即，更改邮政编码可能不会更改是否发放贷款的决策)。然而，如果在现实世界的决策过程中使用该模型的输出，这两件事可能是相关的。

好消息是，因为我们可以访问模型的输入输出，所以我们可以用任意的输入来探测它。这允许检查**反事实**，不同于正在解释的预测的输入。这些反事实可能在数据集中的其他地方，也可能不在。

[Shapley 值](https://en.wikipedia.org/wiki/Shapley_value)(博弈论的经典结果)提供了一种优雅的、公理化的方法来量化特征贡献。

一个挑战是，他们依赖于对大量反事实的探测，这些反事实大到无法计算。因此，有几篇关于近似 Shapley 值的论文，特别是对于特定类别的模型函数。

然而，一个更基本的挑战是，当特征相关时，并不是所有的反事实都是真实的。在如何解决这个问题上没有明确的共识，现有的方法在要考虑的一组确切的反事实上有所不同。

为了克服这些挑战，依靠观测数据是很有诱惑力的。例如，使用观察到的数据来定义应用 Shapley 值的反事实。或者更简单地说，用一个可解释的模型来模拟主模型的预测，然后用可解释的模型代替主模型进行解释。但是，这可能是危险的。

考虑一个信用风险模型，其特征包括申请人的收入和邮政编码。假设该模型在内部仅依赖于邮政编码(即 it [红线](https://en.wikipedia.org/wiki/Redlining)申请人)。基于观察数据的解释可能会揭示，由于申请人的收入与邮政编码相关，因此可以预测模型的输出。这可能会误导我们用申请人的收入来解释模型的输出。事实上，一个简单的解释算法会在两个完全相关的特征之间平分属性。

要了解更多，可以介入特性。一个改变邮政编码而不是收入的反事实将揭示邮政编码导致模型的预测改变。第二个反事实是改变收入但不改变邮政编码，它将揭示收入不变。这两个因素加在一起将使我们得出结论，邮政编码是模型预测的因果关系，而收入不是。

解释因果关系需要正确的反事实。

# 解释现实世界中的因果关系更加困难

上面我们概述了一种试图解释模型中因果关系的方法:研究当特征改变时会发生什么。要在现实世界中做到这一点，你必须能够应用干预。这通常被称为“[随机对照试验](https://en.wikipedia.org/wiki/Randomized_controlled_trial)”(当有两个变体时，也称为“ [A/B 测试](https://en.wikipedia.org/wiki/A/B_testing))，尤其是在科技行业)。你将人群随机分成两组或更多组，并对每组应用不同的干预措施。随机化确保各组之间的唯一差异是您的干预。因此，你可以得出结论，你的干预导致了群体中可测量的差异。

将这种方法应用于现实任务的挑战在于，并非所有的干预措施都是可行的。你不能从道德上要求某人开始吸烟。在现实世界中，您可能无法获得正确检查因果关系所需的数据。

我们可以随意探测模型，但不能探测人。

自然实验可以为我们提供一个机会来研究我们通常不会干预的情况，比如流行病学和经济学。然而，这些为我们提供了一个有限的工具包，留下了这些领域的许多问题供讨论。

有一些关于[和其他理论](https://en.wikipedia.org/wiki/Causality#Theories)的提议，允许我们使用领域知识来区分相关性和因果关系。这些都是正在进行的辩论和研究的主题。

现在你知道为什么在模型中解释因果关系很难，而在现实世界中解释更难了。

要了解更多关于解释模型的信息，请发邮件至 [info@fiddler.ai](mailto:info@fiddler.ai) 。(图片鸣谢: [pixabay](https://pixabay.com/illustrations/mikado-domino-stones-pay-steinchen-1013877/) 。)这篇文章是与 Ankur Taly 共同撰写的。

*原载于 2019 年 7 月 31 日*[*https://blog . fiddler . ai*](https://blog.fiddler.ai/2019/07/causality-in-model-explanations-and-in-the-real-world/)*。*