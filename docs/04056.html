<html>
<head>
<title>The Complete Guide to Classification in Python</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">Python 分类完全指南</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/the-complete-guide-to-classification-in-python-b0e34c92e455?source=collection_archive---------4-----------------------#2019-06-26">https://towardsdatascience.com/the-complete-guide-to-classification-in-python-b0e34c92e455?source=collection_archive---------4-----------------------#2019-06-26</a></blockquote><div><div class="fc ij ik il im in"/><div class="io ip iq ir is"><div class=""/><div class=""><h2 id="8e3e" class="pw-subtitle-paragraph js iu iv bd b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj dk translated">深入探究逻辑回归、LDA 和 QDA 的内部工作原理，并在项目环境中实现每个算法。</h2></div><figure class="kl km kn ko gt kp gh gi paragraph-image"><div class="gh gi kk"><img src="../Images/8e7221aada4ffaa52e1cd479d0e67cc5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*TqEHFKv0IuQfnjqtWy-81Q.jpeg"/></div></figure><h1 id="c23f" class="ks kt iv bd ku kv kw kx ky kz la lb lc kb ld kc le ke lf kf lg kh lh ki li lj bi translated">介绍</h1><p id="ab7d" class="pw-post-body-paragraph lk ll iv lm b ln lo jw lp lq lr jz ls lt lu lv lw lx ly lz ma mb mc md me mf io bi translated">本文可作为简单和复杂分类问题的参考。通过“简单”,我们指定一个二元分类问题，其中两个类别之间存在一个清晰的线性边界。更复杂的分类问题可能涉及两个以上的类别，或者边界是非线性的。</p><p id="9593" class="pw-post-body-paragraph lk ll iv lm b ln mg jw lp lq mh jz ls lt mi lv lw lx mj lz ma mb mk md me mf io bi translated">对于此类问题，<strong class="lm iw">逻辑回归</strong>、<strong class="lm iw">线性判别分析</strong> (LDA)和<strong class="lm iw">二次判别分析</strong> (QDA)等技术是应用最广泛的算法。</p><p id="d2dc" class="pw-post-body-paragraph lk ll iv lm b ln mg jw lp lq mh jz ls lt mi lv lw lx mj lz ma mb mk md me mf io bi translated">在本文中，我们将首先解释回归和分类问题之间的区别。然后，我们将深入研究逻辑回归、LDA 和 QDA 的理论。最后，我们将使用真实数据集在 Python 中实现每个算法。</p><p id="b95c" class="pw-post-body-paragraph lk ll iv lm b ln mg jw lp lq mh jz ls lt mi lv lw lx mj lz ma mb mk md me mf io bi translated">我希望这篇文章对你有用，并且你可以回头参考它！我们开始吧！</p><blockquote class="ml"><p id="3d7f" class="mm mn iv bd mo mp mq mr ms mt mu mf dk translated">关于机器学习、深度学习和人工智能的实践视频教程，请查看我的<a class="ae mv" href="https://www.youtube.com/channel/UC-0lpiwlftqwC7znCcF83qg?view_as=subscriber" rel="noopener ugc nofollow" target="_blank"> YouTube 频道</a>。</p></blockquote><figure class="mw mx my mz na kp"><div class="bz fp l di"><div class="nb nc l"/></div></figure><h1 id="abcc" class="ks kt iv bd ku kv kw kx ky kz la lb lc kb ld kc le ke lf kf lg kh lh ki li lj bi translated">回归与分类问题</h1><p id="8420" class="pw-post-body-paragraph lk ll iv lm b ln lo jw lp lq lr jz ls lt lu lv lw lx ly lz ma mb mc md me mf io bi translated">之前，我们看到<a class="ae mv" rel="noopener" target="_blank" href="/the-complete-guide-to-linear-regression-in-python-3d3f8f06bf8">线性回归</a>假设响应变量是定量的。然而，在许多情况下，反应实际上是定性的，就像眼睛的颜色。这种类型的反应被称为<strong class="lm iw">分类反应。</strong></p><p id="f465" class="pw-post-body-paragraph lk ll iv lm b ln mg jw lp lq mh jz ls lt mi lv lw lx mj lz ma mb mk md me mf io bi translated">分类是预测定性反应的过程。用于分类的方法通常预测定性变量的每个类别的概率，作为进行分类的基础。在某种程度上，它们的行为类似于回归方法。</p><p id="9f66" class="pw-post-body-paragraph lk ll iv lm b ln mg jw lp lq mh jz ls lt mi lv lw lx mj lz ma mb mk md me mf io bi translated">通过分类，我们可以回答如下问题:</p><ul class=""><li id="4aa7" class="nd ne iv lm b ln mg lq mh lt nf lx ng mb nh mf ni nj nk nl bi translated">一个人有一系列症状，这些症状可以归因于三种医学状况中的一种。哪一个？</li><li id="09d9" class="nd ne iv lm b ln nm lq nn lt no lx np mb nq mf ni nj nk nl bi translated">一笔交易是不是欺诈？</li></ul><p id="f065" class="pw-post-body-paragraph lk ll iv lm b ln mg jw lp lq mh jz ls lt mi lv lw lx mj lz ma mb mk md me mf io bi translated">分类回答通常用词来表达。当然，我们不能用文字作为传统统计方法的输入数据。当我们实现算法的时候，我们会看到如何处理这个问题。</p><p id="2436" class="pw-post-body-paragraph lk ll iv lm b ln mg jw lp lq mh jz ls lt mi lv lw lx mj lz ma mb mk md me mf io bi translated">现在，让我们看看逻辑回归是如何工作的。</p><h1 id="3dff" class="ks kt iv bd ku kv kw kx ky kz la lb lc kb ld kc le ke lf kf lg kh lh ki li lj bi translated">逻辑回归</h1><p id="2ffa" class="pw-post-body-paragraph lk ll iv lm b ln lo jw lp lq lr jz ls lt lu lv lw lx ly lz ma mb mc md me mf io bi translated">当涉及到分类时，我们要确定一个观察值是否属于某一类的概率。因此，我们希望用 0 到 1 之间的值来表示概率。</p><p id="ec7e" class="pw-post-body-paragraph lk ll iv lm b ln mg jw lp lq mh jz ls lt mi lv lw lx mj lz ma mb mk md me mf io bi translated">接近 1 的概率意味着观察结果<strong class="lm iw">很可能</strong>属于该类别。</p><p id="826f" class="pw-post-body-paragraph lk ll iv lm b ln mg jw lp lq mh jz ls lt mi lv lw lx mj lz ma mb mk md me mf io bi translated">为了生成介于 0 和 1 之间的值，我们使用以下等式来表示概率:</p><figure class="kl km kn ko gt kp gh gi paragraph-image"><div class="gh gi nr"><img src="../Images/2b92f7b52ada4b2f97d12182e9b2000e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1138/format:webp/1*16pvfuKHKmt444j3A0JMaQ.png"/></div><figcaption class="ns nt gj gh gi nu nv bd b be z dk">Sigmoid function</figcaption></figure><p id="23a0" class="pw-post-body-paragraph lk ll iv lm b ln mg jw lp lq mh jz ls lt mi lv lw lx mj lz ma mb mk md me mf io bi translated">上面的等式被定义为<strong class="lm iw"> sigmoid 函数。</strong></p><p id="2081" class="pw-post-body-paragraph lk ll iv lm b ln mg jw lp lq mh jz ls lt mi lv lw lx mj lz ma mb mk md me mf io bi translated">画出这个方程，你会发现这个方程总是产生一个介于 0 和 1 之间的 S 形曲线。</p><figure class="kl km kn ko gt kp gh gi paragraph-image"><div role="button" tabindex="0" class="nx ny di nz bf oa"><div class="gh gi nw"><img src="../Images/4e6f08f12007fb3aa1d3aaf852c9e765.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*d82VwmBN3YGn3rzMUTluJg.png"/></div></div><figcaption class="ns nt gj gh gi nu nv bd b be z dk">Logistic regression curve</figcaption></figure><p id="505d" class="pw-post-body-paragraph lk ll iv lm b ln mg jw lp lq mh jz ls lt mi lv lw lx mj lz ma mb mk md me mf io bi translated">对上面的等式进行一些操作后，您会发现:</p><figure class="kl km kn ko gt kp gh gi paragraph-image"><div class="gh gi ob"><img src="../Images/6c4d4ac4127958c37d66cd80235d62ba.png" data-original-src="https://miro.medium.com/v2/resize:fit:1136/format:webp/1*UHGn0QlV5Ifybot8RirOaA.png"/></div></figure><p id="bf51" class="pw-post-body-paragraph lk ll iv lm b ln mg jw lp lq mh jz ls lt mi lv lw lx mj lz ma mb mk md me mf io bi translated">拿起<em class="oc">两边的圆木</em>；</p><figure class="kl km kn ko gt kp gh gi paragraph-image"><div class="gh gi od"><img src="../Images/da59415e20f8acdccfdfc796aa0fc3bc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1168/format:webp/1*6pnEwGy2Z5z73NasEmC9MQ.png"/></div></figure><p id="b003" class="pw-post-body-paragraph lk ll iv lm b ln mg jw lp lq mh jz ls lt mi lv lw lx mj lz ma mb mk md me mf io bi translated">上面的等式被称为<em class="oc">对数</em>。可以看到，它在<em class="oc"> X </em>是线性的。这里，如果系数是正的，那么<em class="oc"> X </em>的增加将导致更高的概率。</p><h2 id="c4f2" class="oe kt iv bd ku of og dn ky oh oi dp lc lt oj ok le lx ol om lg mb on oo li op bi translated">估计系数</h2><p id="0133" class="pw-post-body-paragraph lk ll iv lm b ln lo jw lp lq lr jz ls lt lu lv lw lx ly lz ma mb mc md me mf io bi translated">与线性回归一样，我们需要一种方法来估计系数。为此，我们<strong class="lm iw">最大化</strong>的<em class="oc">似然函数</em>:</p><figure class="kl km kn ko gt kp gh gi paragraph-image"><div class="gh gi oq"><img src="../Images/fe9b7da0c6c9ef17607f78d6b3ff2dbb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1236/format:webp/1*IDgIv1rCstBxoAD2E5SWIA.png"/></div><figcaption class="ns nt gj gh gi nu nv bd b be z dk">Likelihood function</figcaption></figure><p id="2af2" class="pw-post-body-paragraph lk ll iv lm b ln mg jw lp lq mh jz ls lt mi lv lw lx mj lz ma mb mk md me mf io bi translated">这里的直觉是，我们希望系数使得预测的概率(在上面的等式中用撇号表示)尽可能接近观察到的状态。</p><p id="3fc4" class="pw-post-body-paragraph lk ll iv lm b ln mg jw lp lq mh jz ls lt mi lv lw lx mj lz ma mb mk md me mf io bi translated">与线性回归类似，我们使用<em class="oc"> p 值</em>来确定是否拒绝零假设。</p><p id="00c3" class="pw-post-body-paragraph lk ll iv lm b ln mg jw lp lq mh jz ls lt mi lv lw lx mj lz ma mb mk md me mf io bi translated"><em class="oc"> Z 统计</em>也被广泛使用。大的绝对 Z 统计量意味着零假设被拒绝。</p><p id="8ec8" class="pw-post-body-paragraph lk ll iv lm b ln mg jw lp lq mh jz ls lt mi lv lw lx mj lz ma mb mk md me mf io bi translated">请记住，零假设声明:特征和目标之间没有相关性。</p><h2 id="71df" class="oe kt iv bd ku of og dn ky oh oi dp lc lt oj ok le lx ol om lg mb on oo li op bi translated">多元逻辑回归</h2><p id="5653" class="pw-post-body-paragraph lk ll iv lm b ln lo jw lp lq lr jz ls lt lu lv lw lx ly lz ma mb mc md me mf io bi translated">当然，逻辑回归可以很容易地扩展到容纳一个以上的预测因子:</p><figure class="kl km kn ko gt kp gh gi paragraph-image"><div class="gh gi or"><img src="../Images/e29a7fec4a5aab3c90857900e998ae2d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1216/format:webp/1*WswbXWnjjzP2pglpBp0PnQ.png"/></div><figcaption class="ns nt gj gh gi nu nv bd b be z dk">Multiple logistic regression</figcaption></figure><p id="3f4d" class="pw-post-body-paragraph lk ll iv lm b ln mg jw lp lq mh jz ls lt mi lv lw lx mj lz ma mb mk md me mf io bi translated">请注意，使用多元逻辑回归可能会给出更好的结果，因为它可以考虑预测因素之间的相关性，这种现象被称为<em class="oc">混淆</em>。此外，很少仅有一个预测器就足以建立准确的预测模型。</p><h1 id="ef6c" class="ks kt iv bd ku kv kw kx ky kz la lb lc kb ld kc le ke lf kf lg kh lh ki li lj bi translated">线性判别分析</h1><p id="a8df" class="pw-post-body-paragraph lk ll iv lm b ln lo jw lp lq lr jz ls lt lu lv lw lx ly lz ma mb mc md me mf io bi translated">现在，我们明白了逻辑回归是如何工作的，但是像任何模型一样，它也存在一些缺陷:</p><ul class=""><li id="527f" class="nd ne iv lm b ln mg lq mh lt nf lx ng mb nh mf ni nj nk nl bi translated">当类被很好地分开时，从逻辑回归估计的参数往往是不稳定的</li><li id="e684" class="nd ne iv lm b ln nm lq nn lt no lx np mb nq mf ni nj nk nl bi translated">当数据集很小时，逻辑回归也是不稳定的</li><li id="42d7" class="nd ne iv lm b ln nm lq nn lt no lx np mb nq mf ni nj nk nl bi translated">最好不要预测两个以上的类</li></ul><p id="eb25" class="pw-post-body-paragraph lk ll iv lm b ln mg jw lp lq mh jz ls lt mi lv lw lx mj lz ma mb mk md me mf io bi translated">这就是线性判别分析(LDA)派上用场的地方。它比逻辑回归更稳定，广泛用于预测两个以上的类别。</p><p id="1af5" class="pw-post-body-paragraph lk ll iv lm b ln mg jw lp lq mh jz ls lt mi lv lw lx mj lz ma mb mk md me mf io bi translated">LDA 的特殊性在于，它分别对每个响应类别中预测值的分布进行建模，然后使用贝叶斯定理来估计概率。</p><figure class="kl km kn ko gt kp"><div class="bz fp l di"><div class="os nc l"/></div></figure><p id="39a2" class="pw-post-body-paragraph lk ll iv lm b ln mg jw lp lq mh jz ls lt mi lv lw lx mj lz ma mb mk md me mf io bi translated">好吧，这有点难以理解。我们来分解一下。</p><h2 id="cbb5" class="oe kt iv bd ku of og dn ky oh oi dp lc lt oj ok le lx ol om lg mb on oo li op bi translated">贝叶斯分类定理</h2><p id="b106" class="pw-post-body-paragraph lk ll iv lm b ln lo jw lp lq lr jz ls lt lu lv lw lx ly lz ma mb mc md me mf io bi translated"><em class="oc">(抱歉，Medium 不支持数学方程。我尽了最大努力，尽可能的明确)。</em></p><p id="b095" class="pw-post-body-paragraph lk ll iv lm b ln mg jw lp lq mh jz ls lt mi lv lw lx mj lz ma mb mk md me mf io bi translated">假设我们想要将一个观察值分类到<em class="oc"> K </em>类中的一个，其中<em class="oc"> K </em>大于或等于 2。然后，让<em class="oc"> pi-k </em>成为一个观察值关联到第<em class="oc">个</em>类的总概率。然后，让<em class="oc"> f_k(X) </em>表示<em class="oc"> X </em>的密度函数，用于来自<em class="oc">第 k 个</em>类的观察。这意味着如果来自第<em class="oc">第 k 个</em>类的观测值具有 X = x 的概率，则<em class="oc"> f_k(X) </em>是大的。然后，贝叶斯定理陈述:</p><figure class="kl km kn ko gt kp gh gi paragraph-image"><div role="button" tabindex="0" class="nx ny di nz bf oa"><div class="gh gi ot"><img src="../Images/8d926810b82bace2969c746be224514a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*NcxRpOttYmE7_xNaYPJY3A.png"/></div></div><figcaption class="ns nt gj gh gi nu nv bd b be z dk">Bayes’ theorem for classification</figcaption></figure><p id="29bd" class="pw-post-body-paragraph lk ll iv lm b ln mg jw lp lq mh jz ls lt mi lv lw lx mj lz ma mb mk md me mf io bi translated">上面的等式可以简单地缩写为:</p><figure class="kl km kn ko gt kp gh gi paragraph-image"><div class="gh gi ou"><img src="../Images/99fe7de58b205720d8604b771e9e5a74.png" data-original-src="https://miro.medium.com/v2/resize:fit:1322/format:webp/1*CG0Qv2fGlfxMJdJ4-6fJZg.png"/></div><figcaption class="ns nt gj gh gi nu nv bd b be z dk">Abbreviated Bayes’ theorem for classification</figcaption></figure><p id="7cf4" class="pw-post-body-paragraph lk ll iv lm b ln mg jw lp lq mh jz ls lt mi lv lw lx mj lz ma mb mk md me mf io bi translated">希望这有一定的意义！</p><p id="6e40" class="pw-post-body-paragraph lk ll iv lm b ln mg jw lp lq mh jz ls lt mi lv lw lx mj lz ma mb mk md me mf io bi translated">这里的挑战是估计密度函数。理论上，贝叶斯的分类错误率最低。因此，我们的分类器需要估计密度函数，以逼近贝叶斯分类器。</p><h2 id="a7d9" class="oe kt iv bd ku of og dn ky oh oi dp lc lt oj ok le lx ol om lg mb on oo li op bi translated">一个预测器的 LDA</h2><p id="2b1c" class="pw-post-body-paragraph lk ll iv lm b ln lo jw lp lq lr jz ls lt lu lv lw lx ly lz ma mb mc md me mf io bi translated">假设我们只有一个预测值，并且密度函数是正态的。然后，您可以将密度函数表示为:</p><figure class="kl km kn ko gt kp gh gi paragraph-image"><div role="button" tabindex="0" class="nx ny di nz bf oa"><div class="gh gi ov"><img src="../Images/83627df82ffdd989eaea46c114edf28e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*MMP0tIKRK-jtKK0eH3Nt0g.png"/></div></div><figcaption class="ns nt gj gh gi nu nv bd b be z dk">Normal distribution function</figcaption></figure><p id="4a76" class="pw-post-body-paragraph lk ll iv lm b ln mg jw lp lq mh jz ls lt mi lv lw lx mj lz ma mb mk md me mf io bi translated">现在，我们要指定一个观察值<em class="oc"> X = x </em>，对于这个观察值<em class="oc"> P_k(X) </em>最大。如果你在<em class="oc"> P_k(X) </em>中插入密度函数，取<em class="oc">对数</em>，你会发现你希望最大化:</p><figure class="kl km kn ko gt kp gh gi paragraph-image"><div role="button" tabindex="0" class="nx ny di nz bf oa"><div class="gh gi ow"><img src="../Images/4bb3f76ad375a92a4729065196e48091.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ZTlK7kePOQIQPJQ9fEQz5A.png"/></div></div><figcaption class="ns nt gj gh gi nu nv bd b be z dk">Discriminant equation</figcaption></figure><p id="caeb" class="pw-post-body-paragraph lk ll iv lm b ln mg jw lp lq mh jz ls lt mi lv lw lx mj lz ma mb mk md me mf io bi translated">上面的等式被称为<strong class="lm iw">判别式。</strong>如你所见，这是一个线性方程。因此得名:<strong class="lm iw">线性判别分析</strong>！</p><p id="73c3" class="pw-post-body-paragraph lk ll iv lm b ln mg jw lp lq mh jz ls lt mi lv lw lx mj lz ma mb mk md me mf io bi translated">现在，假设只有两个具有相等分布的类，您会发现:</p><figure class="kl km kn ko gt kp gh gi paragraph-image"><div role="button" tabindex="0" class="nx ny di nz bf oa"><div class="gh gi ox"><img src="../Images/2a6bfda7e458a505807aabc59f320463.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*KFffe_Sbr40PwYLvwfO2PA.png"/></div></div><figcaption class="ns nt gj gh gi nu nv bd b be z dk">Boundary equation</figcaption></figure><p id="f477" class="pw-post-body-paragraph lk ll iv lm b ln mg jw lp lq mh jz ls lt mi lv lw lx mj lz ma mb mk md me mf io bi translated">这是边界方程。下图显示了图示。</p><figure class="kl km kn ko gt kp gh gi paragraph-image"><div class="gh gi oy"><img src="../Images/ffe69e5db11a49d70659bfe4942a65ff.png" data-original-src="https://miro.medium.com/v2/resize:fit:1356/format:webp/1*CDviUGNenbTAF4CK4HLdyg.png"/></div><figcaption class="ns nt gj gh gi nu nv bd b be z dk">Boundary line to separate 2 classes using LDA</figcaption></figure><p id="f427" class="pw-post-body-paragraph lk ll iv lm b ln mg jw lp lq mh jz ls lt mi lv lw lx mj lz ma mb mk md me mf io bi translated">当然，这代表了一种理想的解决方案。事实上，我们无法精确计算边界线。</p><p id="e3e3" class="pw-post-body-paragraph lk ll iv lm b ln mg jw lp lq mh jz ls lt mi lv lw lx mj lz ma mb mk md me mf io bi translated">因此，LDA 利用以下近似:</p><ul class=""><li id="85d2" class="nd ne iv lm b ln mg lq mh lt nf lx ng mb nh mf ni nj nk nl bi translated">对于所有训练观察的平均值</li></ul><figure class="kl km kn ko gt kp gh gi paragraph-image"><div class="gh gi oz"><img src="../Images/e72c60e61ce4dca18c8226f64cbb4c64.png" data-original-src="https://miro.medium.com/v2/resize:fit:1038/format:webp/1*sXg0dhjsM8rnWKOvjitNDA.png"/></div><figcaption class="ns nt gj gh gi nu nv bd b be z dk">Average of all training observations</figcaption></figure><ul class=""><li id="3f49" class="nd ne iv lm b ln mg lq mh lt nf lx ng mb nh mf ni nj nk nl bi translated">对于每类样本方差的加权平均值</li></ul><figure class="kl km kn ko gt kp gh gi paragraph-image"><div role="button" tabindex="0" class="nx ny di nz bf oa"><div class="gh gi pa"><img src="../Images/368090a325b230584b871ae1a68dc8ca.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*si02aMPhNrabyr06mq4_kA.png"/></div></div><figcaption class="ns nt gj gh gi nu nv bd b be z dk">Weighted average of sample variances for each class</figcaption></figure><p id="1623" class="pw-post-body-paragraph lk ll iv lm b ln mg jw lp lq mh jz ls lt mi lv lw lx mj lz ma mb mk md me mf io bi translated">其中<em class="oc"> n </em>是观察次数。</p><p id="1e7c" class="pw-post-body-paragraph lk ll iv lm b ln mg jw lp lq mh jz ls lt mi lv lw lx mj lz ma mb mk md me mf io bi translated">重要的是要知道 LDA 假设每个类别的<strong class="lm iw">正态分布</strong>，特定类别的<strong class="lm iw">均值</strong>，以及<strong class="lm iw">共同方差</strong>。</p><h2 id="80f7" class="oe kt iv bd ku of og dn ky oh oi dp lc lt oj ok le lx ol om lg mb on oo li op bi translated">多个预测值的 LDA</h2><p id="7980" class="pw-post-body-paragraph lk ll iv lm b ln lo jw lp lq lr jz ls lt lu lv lw lx ly lz ma mb mc md me mf io bi translated">现在扩展到多个预测值，我们必须假设<em class="oc"> X </em>是从<strong class="lm iw">多元高斯分布</strong>中提取的，具有特定类别的均值向量和公共协方差矩阵。</p><p id="5a74" class="pw-post-body-paragraph lk ll iv lm b ln mg jw lp lq mh jz ls lt mi lv lw lx mj lz ma mb mk md me mf io bi translated">相关和不相关高斯分布的示例如下所示。</p><figure class="kl km kn ko gt kp gh gi paragraph-image"><div role="button" tabindex="0" class="nx ny di nz bf oa"><div class="gh gi pb"><img src="../Images/08dc756c5e3a44c38ff49c63266ead04.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*GrPryIQQntXoZ0UIWPh4LA.png"/></div></div><figcaption class="ns nt gj gh gi nu nv bd b be z dk">Left: Uncorrelated normal distribution. Right: correlated normal distribution</figcaption></figure><p id="02d9" class="pw-post-body-paragraph lk ll iv lm b ln mg jw lp lq mh jz ls lt mi lv lw lx mj lz ma mb mk md me mf io bi translated">现在，用向量符号表示判别方程，我们得到:</p><figure class="kl km kn ko gt kp gh gi paragraph-image"><div role="button" tabindex="0" class="nx ny di nz bf oa"><div class="gh gi pc"><img src="../Images/cbcab3a712d6404dd44f7d7c6712ec4e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*4JBGR-vPiJpu2so9LYr3PA.png"/></div></div><figcaption class="ns nt gj gh gi nu nv bd b be z dk">Discriminant equation with matrix notation</figcaption></figure><p id="3358" class="pw-post-body-paragraph lk ll iv lm b ln mg jw lp lq mh jz ls lt mi lv lw lx mj lz ma mb mk md me mf io bi translated">如你所见，等式保持不变。只是这一次，我们使用向量符号来容纳许多预测值。</p><h2 id="2f38" class="oe kt iv bd ku of og dn ky oh oi dp lc lt oj ok le lx ol om lg mb on oo li op bi translated">如何评估模型的性能</h2><p id="f374" class="pw-post-body-paragraph lk ll iv lm b ln lo jw lp lq lr jz ls lt lu lv lw lx ly lz ma mb mc md me mf io bi translated">对于分类，有时使用准确性来评估模型的性能是不相关的。</p><p id="18e0" class="pw-post-body-paragraph lk ll iv lm b ln mg jw lp lq mh jz ls lt mi lv lw lx mj lz ma mb mk md me mf io bi translated">考虑分析一个高度不平衡的数据集。例如，您试图确定一项交易是否是欺诈性的，但您的数据集只有 0.5%包含欺诈性交易。然后，您可以预测没有任何交易是欺诈性的，并有 99.5%的准确率得分！当然，这是一种非常幼稚的方法，无助于检测欺诈交易。</p><p id="57e3" class="pw-post-body-paragraph lk ll iv lm b ln mg jw lp lq mh jz ls lt mi lv lw lx mj lz ma mb mk md me mf io bi translated">那么我们用什么呢？</p><p id="5e17" class="pw-post-body-paragraph lk ll iv lm b ln mg jw lp lq mh jz ls lt mi lv lw lx mj lz ma mb mk md me mf io bi translated">通常，我们用<strong class="lm iw">灵敏度</strong>和<strong class="lm iw">特异性</strong>。</p><p id="8783" class="pw-post-body-paragraph lk ll iv lm b ln mg jw lp lq mh jz ls lt mi lv lw lx mj lz ma mb mk md me mf io bi translated"><strong class="lm iw">灵敏度</strong>是真正的阳性率:正确识别的实际阳性的比例。</p><p id="c735" class="pw-post-body-paragraph lk ll iv lm b ln mg jw lp lq mh jz ls lt mi lv lw lx mj lz ma mb mk md me mf io bi translated"><strong class="lm iw">特异性</strong>是真阴性率:实际阴性被正确识别的比例。</p><p id="8eb9" class="pw-post-body-paragraph lk ll iv lm b ln mg jw lp lq mh jz ls lt mi lv lw lx mj lz ma mb mk md me mf io bi translated">让我们给出一些背景来更好地理解。使用欺诈检测问题，<strong class="lm iw">敏感度</strong>是被识别为欺诈的欺诈交易的比例。<strong class="lm iw">特异性</strong>是被识别为非欺诈的非欺诈交易的比例。</p><p id="aed2" class="pw-post-body-paragraph lk ll iv lm b ln mg jw lp lq mh jz ls lt mi lv lw lx mj lz ma mb mk md me mf io bi translated">因此，在理想情况下，我们需要高灵敏度和高特异性，尽管这可能会因环境而异。例如，银行可能希望优先考虑较高的敏感性而不是特异性，以确保识别欺诈性交易。</p><p id="9de8" class="pw-post-body-paragraph lk ll iv lm b ln mg jw lp lq mh jz ls lt mi lv lw lx mj lz ma mb mk md me mf io bi translated"><strong class="lm iw"> ROC 曲线</strong>(接收器工作特性)可以很好地显示上述两种误差指标。分类器的总体性能由 ROC 曲线下的面积给出(<strong class="lm iw"> AUC </strong>)。理想情况下，它应该紧挨着图形的左上角，并且面积接近 1。</p><figure class="kl km kn ko gt kp gh gi paragraph-image"><div role="button" tabindex="0" class="nx ny di nz bf oa"><div class="gh gi pd"><img src="../Images/70a6ba90afd16cf93ba43751747c9107.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*s40QXq6Ia3xP7iBju4NyoA.png"/></div></div><figcaption class="ns nt gj gh gi nu nv bd b be z dk">Example of a ROC curve. The straight line is a base model</figcaption></figure><h1 id="040d" class="ks kt iv bd ku kv kw kx ky kz la lb lc kb ld kc le ke lf kf lg kh lh ki li lj bi translated">二次判别分析(QDA)</h1><p id="9449" class="pw-post-body-paragraph lk ll iv lm b ln lo jw lp lq lr jz ls lt lu lv lw lx ly lz ma mb mc md me mf io bi translated">这里，我们保持与 LDA 相同的假设，但是现在，来自第<em class="oc">个</em>类的每个观察值都有自己的协方差矩阵。</p><p id="f1fb" class="pw-post-body-paragraph lk ll iv lm b ln mg jw lp lq mh jz ls lt mi lv lw lx mj lz ma mb mk md me mf io bi translated">对于 QDA，判别式表示为:</p><figure class="kl km kn ko gt kp gh gi paragraph-image"><div role="button" tabindex="0" class="nx ny di nz bf oa"><div class="gh gi pe"><img src="../Images/ae6647a2eb116829c38300c5e2bbeb4c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*hM7ZhQC8jSa4EK1aXTcpbg.png"/></div></div><figcaption class="ns nt gj gh gi nu nv bd b be z dk">Discriminant equation for QDA</figcaption></figure><p id="c356" class="pw-post-body-paragraph lk ll iv lm b ln mg jw lp lq mh jz ls lt mi lv lw lx mj lz ma mb mk md me mf io bi translated">毫无疑问，你会注意到这个方程现在是二次方程了。</p><p id="da4d" class="pw-post-body-paragraph lk ll iv lm b ln mg jw lp lq mh jz ls lt mi lv lw lx mj lz ma mb mk md me mf io bi translated">但是，为什么选择 QDA 而不是 LDA？</p><p id="6a36" class="pw-post-body-paragraph lk ll iv lm b ln mg jw lp lq mh jz ls lt mi lv lw lx mj lz ma mb mk md me mf io bi translated">对于大型数据集，QDA 是更好的选择，因为它倾向于具有更低的偏差和更高的方差。</p><p id="300f" class="pw-post-body-paragraph lk ll iv lm b ln mg jw lp lq mh jz ls lt mi lv lw lx mj lz ma mb mk md me mf io bi translated">另一方面，LDA 更适合于较小的数据集，它有较高的偏倚和较低的方差。</p><h1 id="29f1" class="ks kt iv bd ku kv kw kx ky kz la lb lc kb ld kc le ke lf kf lg kh lh ki li lj bi translated">项目</h1><p id="087a" class="pw-post-body-paragraph lk ll iv lm b ln lo jw lp lq lr jz ls lt lu lv lw lx ly lz ma mb mc md me mf io bi translated">太好了！既然我们已经深刻理解了逻辑回归、LDA 和 QDA 的工作原理，让我们应用每种算法来解决一个分类问题。</p><h2 id="ff52" class="oe kt iv bd ku of og dn ky oh oi dp lc lt oj ok le lx ol om lg mb on oo li op bi translated">动机</h2><p id="f105" class="pw-post-body-paragraph lk ll iv lm b ln lo jw lp lq lr jz ls lt lu lv lw lx ly lz ma mb mc md me mf io bi translated">蘑菇味道好极了！但是，仅在北美就有超过 10 000 种蘑菇，我们怎么知道哪些是可以食用的呢？</p><p id="64c7" class="pw-post-body-paragraph lk ll iv lm b ln mg jw lp lq mh jz ls lt mi lv lw lx mj lz ma mb mk md me mf io bi translated">这是这个项目的目标。我们将构建一个分类器来确定某种蘑菇是可食用的还是有毒的。</p><p id="a78d" class="pw-post-body-paragraph lk ll iv lm b ln mg jw lp lq mh jz ls lt mi lv lw lx mj lz ma mb mk md me mf io bi translated">我建议你抓住<a class="ae mv" href="https://www.kaggle.com/uciml/mushroom-classification" rel="noopener ugc nofollow" target="_blank">数据集</a>并继续。如果您曾经被卡住，请随意查阅<a class="ae mv" href="https://github.com/marcopeix/ISL-classification" rel="noopener ugc nofollow" target="_blank">完整的笔记本</a>。</p><p id="6bfd" class="pw-post-body-paragraph lk ll iv lm b ln mg jw lp lq mh jz ls lt mi lv lw lx mj lz ma mb mk md me mf io bi translated">我们开始吧！</p><figure class="kl km kn ko gt kp"><div class="bz fp l di"><div class="pf nc l"/></div><figcaption class="ns nt gj gh gi nu nv bd b be z dk">A GIF of a coding mushroom… What are the odds of finding that!</figcaption></figure><h2 id="7a12" class="oe kt iv bd ku of og dn ky oh oi dp lc lt oj ok le lx ol om lg mb on oo li op bi translated">探索性数据分析</h2><p id="0c1a" class="pw-post-body-paragraph lk ll iv lm b ln lo jw lp lq lr jz ls lt lu lv lw lx ly lz ma mb mc md me mf io bi translated">我们将使用的<a class="ae mv" href="https://www.kaggle.com/uciml/mushroom-classification" rel="noopener ugc nofollow" target="_blank">数据集</a>包含具有 22 个特征的 8124 个蘑菇实例。其中，我们发现蘑菇的帽形、帽色、鳃色、面纱类型等。当然，它也告诉我们蘑菇是可食用的还是有毒的。</p><p id="8b40" class="pw-post-body-paragraph lk ll iv lm b ln mg jw lp lq mh jz ls lt mi lv lw lx mj lz ma mb mk md me mf io bi translated">让我们导入一些库，这些库将帮助我们导入和操作数据。在您的笔记本中，运行以下代码:</p><figure class="kl km kn ko gt kp gh gi paragraph-image"><div role="button" tabindex="0" class="nx ny di nz bf oa"><div class="gh gi pb"><img src="../Images/864b6b26310eef1f68f38192793a4dd7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*zMHgsHxpABe62I51j6SYOQ.png"/></div></div></figure><p id="f977" class="pw-post-body-paragraph lk ll iv lm b ln mg jw lp lq mh jz ls lt mi lv lw lx mj lz ma mb mk md me mf io bi translated">数据科学项目的常见第一步是执行<strong class="lm iw">探索性数据分析</strong> (EDA)。这一步通常包括了解更多您正在处理的数据。您可能想知道数据集的<strong class="lm iw">形状</strong>(有多少行和列)、空值的数量以及数据的可视化部分，以更好地理解要素和目标之间的相关性。</p><p id="f5d1" class="pw-post-body-paragraph lk ll iv lm b ln mg jw lp lq mh jz ls lt mi lv lw lx mj lz ma mb mk md me mf io bi translated">导入数据，并使用以下代码查看前五列:</p><figure class="kl km kn ko gt kp gh gi paragraph-image"><div role="button" tabindex="0" class="nx ny di nz bf oa"><div class="gh gi pb"><img src="../Images/c590f07a79ecd7e637d57181dc2bffde.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*087gMOJE_SVfGworrwbyCw.png"/></div></div></figure><p id="ff90" class="pw-post-body-paragraph lk ll iv lm b ln mg jw lp lq mh jz ls lt mi lv lw lx mj lz ma mb mk md me mf io bi translated">将数据集放在项目目录中的<em class="oc"> data </em>文件夹中总是很好的。此外，我们将文件路径存储在一个变量中，这样，如果路径发生变化，我们只需要改变变量分配。</p><p id="94c1" class="pw-post-body-paragraph lk ll iv lm b ln mg jw lp lq mh jz ls lt mi lv lw lx mj lz ma mb mk md me mf io bi translated">运行此代码单元格后，您应该会看到前五行。您会注意到，每个特征都是分类的，并且用一个字母来定义某个值。当然，分类器不能接受字母作为输入，所以我们最终必须改变它。</p><p id="2864" class="pw-post-body-paragraph lk ll iv lm b ln mg jw lp lq mh jz ls lt mi lv lw lx mj lz ma mb mk md me mf io bi translated">现在，让我们看看我们的数据集是否<strong class="lm iw">不平衡。</strong>不平衡数据集是指<strong class="lm iw">一个类比另一个类</strong>多得多。理想情况下，在分类的上下文中，我们希望每个类的实例数量相等。否则，需要采用先进的采样方法，如<strong class="lm iw">少数过采样。</strong></p><p id="f787" class="pw-post-body-paragraph lk ll iv lm b ln mg jw lp lq mh jz ls lt mi lv lw lx mj lz ma mb mk md me mf io bi translated">就我们的情况而言，我们想看看数据集中是否有同等数量的有毒和可食用蘑菇。我们可以这样绘制每个类别的频率:</p><figure class="kl km kn ko gt kp gh gi paragraph-image"><div role="button" tabindex="0" class="nx ny di nz bf oa"><div class="gh gi pb"><img src="../Images/44fc1ddf1f3a6aa5fd9ee6a223a9ba7f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*MEi1Jv8OPKXb0omVXhKsjg.png"/></div></div></figure><p id="f6ac" class="pw-post-body-paragraph lk ll iv lm b ln mg jw lp lq mh jz ls lt mi lv lw lx mj lz ma mb mk md me mf io bi translated">你会得到下图:</p><figure class="kl km kn ko gt kp gh gi paragraph-image"><div class="gh gi pg"><img src="../Images/35b55f4073edd33af850ca408d6dacbe.png" data-original-src="https://miro.medium.com/v2/resize:fit:1394/format:webp/1*OI4IpjZlwcBogDgCWEVx_Q.png"/></div><figcaption class="ns nt gj gh gi nu nv bd b be z dk">Count of each class</figcaption></figure><p id="dcd0" class="pw-post-body-paragraph lk ll iv lm b ln mg jw lp lq mh jz ls lt mi lv lw lx mj lz ma mb mk md me mf io bi translated">太棒了。它看起来像一个相当平衡的数据集，有几乎相等数量的有毒和可食用的蘑菇。</p><p id="23df" class="pw-post-body-paragraph lk ll iv lm b ln mg jw lp lq mh jz ls lt mi lv lw lx mj lz ma mb mk md me mf io bi translated">现在，我想看看每个功能是如何影响目标的。为了做到这一点，对于每一个特征，我制作了一个由蘑菇类分隔的所有可能值的条形图。对所有 22 个特性手动操作是没有意义的，所以我们构建了这个助手函数:</p><figure class="kl km kn ko gt kp gh gi paragraph-image"><div role="button" tabindex="0" class="nx ny di nz bf oa"><div class="gh gi pb"><img src="../Images/32027fc3c16706836c88d14749924b0b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*p8ZBPwVLlPOAfcpX1QYDrA.png"/></div></div></figure><p id="bca9" class="pw-post-body-paragraph lk ll iv lm b ln mg jw lp lq mh jz ls lt mi lv lw lx mj lz ma mb mk md me mf io bi translated"><em class="oc">色调</em>会给有毒和可食用类一个颜色代码。<em class="oc">数据</em>参数将包含除蘑菇类之外的所有特征。运行下面的单元代码:</p><figure class="kl km kn ko gt kp gh gi paragraph-image"><div role="button" tabindex="0" class="nx ny di nz bf oa"><div class="gh gi pb"><img src="../Images/dd8d69cee0765a7554a5474905a83eff.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*LIeWt4ave1WlKa4_VPs3mQ.png"/></div></div></figure><p id="49ba" class="pw-post-body-paragraph lk ll iv lm b ln mg jw lp lq mh jz ls lt mi lv lw lx mj lz ma mb mk md me mf io bi translated">您应该会得到一个包含 22 个地块的列表。下面是一个输出示例:</p><figure class="kl km kn ko gt kp gh gi paragraph-image"><div role="button" tabindex="0" class="nx ny di nz bf oa"><div class="gh gi ph"><img src="../Images/db322ecb75d6e14c81b6ff7121a1025b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*qfXbUC9EihVKV-azuuqvbQ.png"/></div></div><figcaption class="ns nt gj gh gi nu nv bd b be z dk">Cap surface</figcaption></figure><p id="1151" class="pw-post-body-paragraph lk ll iv lm b ln mg jw lp lq mh jz ls lt mi lv lw lx mj lz ma mb mk md me mf io bi translated">花些时间浏览所有的情节。</p><p id="62c2" class="pw-post-body-paragraph lk ll iv lm b ln mg jw lp lq mh jz ls lt mi lv lw lx mj lz ma mb mk md me mf io bi translated">现在，让我们看看是否有丢失的值。运行这段代码:</p><figure class="kl km kn ko gt kp gh gi paragraph-image"><div role="button" tabindex="0" class="nx ny di nz bf oa"><div class="gh gi pb"><img src="../Images/077735967f06d4599023802b2867ac67.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*JZPAYdk1UzyblI64_2E_tQ.png"/></div></div></figure><p id="d430" class="pw-post-body-paragraph lk ll iv lm b ln mg jw lp lq mh jz ls lt mi lv lw lx mj lz ma mb mk md me mf io bi translated">您应该看到每一列都有缺失值的数量。幸运的是，我们有一个没有缺失值的数据集。这很不常见，但我们不会抱怨。</p><h2 id="223f" class="oe kt iv bd ku of og dn ky oh oi dp lc lt oj ok le lx ol om lg mb on oo li op bi translated">为建模做准备</h2><p id="a01d" class="pw-post-body-paragraph lk ll iv lm b ln lo jw lp lq lr jz ls lt lu lv lw lx ly lz ma mb mc md me mf io bi translated">现在我们已经熟悉了数据，是时候为建模做准备了。如前所述，特性用字母来表示不同的可能值，但是我们需要将它们转换成数字。</p><p id="3944" class="pw-post-body-paragraph lk ll iv lm b ln mg jw lp lq mh jz ls lt mi lv lw lx mj lz ma mb mk md me mf io bi translated">为了实现这一点，我们将使用<strong class="lm iw">标签编码</strong>和<strong class="lm iw">一键编码。</strong></p><p id="0afb" class="pw-post-body-paragraph lk ll iv lm b ln mg jw lp lq mh jz ls lt mi lv lw lx mj lz ma mb mk md me mf io bi translated">让我们首先在目标列上使用标签编码。运行以下代码:</p><figure class="kl km kn ko gt kp gh gi paragraph-image"><div role="button" tabindex="0" class="nx ny di nz bf oa"><div class="gh gi pb"><img src="../Images/b3f5408a948004008c9cfdf5035531bb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*iPbzOAj0xTBaQdM199ey-g.png"/></div></div></figure><p id="5ff1" class="pw-post-body-paragraph lk ll iv lm b ln mg jw lp lq mh jz ls lt mi lv lw lx mj lz ma mb mk md me mf io bi translated">您会注意到现在该列包含 1 和 0。</p><figure class="kl km kn ko gt kp gh gi paragraph-image"><div role="button" tabindex="0" class="nx ny di nz bf oa"><div class="gh gi pi"><img src="../Images/7f583d51dd75dede4dc793299b3f0c11.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*tX5a8e64PmaeQ1z4lwjkgg.png"/></div></div><figcaption class="ns nt gj gh gi nu nv bd b be z dk">Result of label encoding the ‘class’ column</figcaption></figure><p id="3201" class="pw-post-body-paragraph lk ll iv lm b ln mg jw lp lq mh jz ls lt mi lv lw lx mj lz ma mb mk md me mf io bi translated">现在，有毒的用 1 表示，可食用的用 0 表示。现在，我们可以把我们的分类器想成“有毒与否”。毒蘑菇得 1(真)，食用菌得 0(假)。</p><p id="82b0" class="pw-post-body-paragraph lk ll iv lm b ln mg jw lp lq mh jz ls lt mi lv lw lx mj lz ma mb mk md me mf io bi translated">因此，<strong class="lm iw">标签编码</strong>会将分类特征转化为数字特征。但是，当有两个以上的可能值时，不建议使用标签编码。</p><p id="ff87" class="pw-post-body-paragraph lk ll iv lm b ln mg jw lp lq mh jz ls lt mi lv lw lx mj lz ma mb mk md me mf io bi translated">为什么？</p><p id="6c8e" class="pw-post-body-paragraph lk ll iv lm b ln mg jw lp lq mh jz ls lt mi lv lw lx mj lz ma mb mk md me mf io bi translated">因为它会将每个值赋给 0、1 或 2。这是一个问题，因为“2”可能被认为是更重要的<em class="oc"/>，并且可能由此得出错误的相关性。</p><p id="4d90" class="pw-post-body-paragraph lk ll iv lm b ln mg jw lp lq mh jz ls lt mi lv lw lx mj lz ma mb mk md me mf io bi translated">为了避免这个问题，我们在其他特性上使用<strong class="lm iw">一键编码</strong>。为了理解它的作用，让我们考虑一下第一个入口点的帽形。你可以看到它的值为“x ”,代表一个凸帽形状。然而，在数据集中总共记录了六种不同的帽形状。如果我们对特征进行一次性编码，我们应该得到:</p><figure class="kl km kn ko gt kp gh gi paragraph-image"><div role="button" tabindex="0" class="nx ny di nz bf oa"><div class="gh gi pb"><img src="../Images/e8f0cf1ef58ca8d63603fd5b70f40248.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*lX3IblxDBB1hsQa_kYjTrA.png"/></div></div><figcaption class="ns nt gj gh gi nu nv bd b be z dk">One-hot encoding the “cap-shape” feature</figcaption></figure><p id="3de4" class="pw-post-body-paragraph lk ll iv lm b ln mg jw lp lq mh jz ls lt mi lv lw lx mj lz ma mb mk md me mf io bi translated">如您所见，帽子形状现在是一个矢量。1 表示数据集中条目的实际帽形状值，其余部分用 0 填充。还是那句话，你可以把 1 想成<em class="oc">真</em>，把 0 想成<em class="oc">假。</em></p><p id="fe5a" class="pw-post-body-paragraph lk ll iv lm b ln mg jw lp lq mh jz ls lt mi lv lw lx mj lz ma mb mk md me mf io bi translated">一键编码的缺点是它向数据集引入了更多的列。在帽形的情况下，我们从一列到六列。对于非常大的数据集，这可能是一个问题，但是在我们的例子中，额外的列应该是可以管理的。</p><p id="b84f" class="pw-post-body-paragraph lk ll iv lm b ln mg jw lp lq mh jz ls lt mi lv lw lx mj lz ma mb mk md me mf io bi translated">让我们继续对其余的功能进行一次性编码:</p><figure class="kl km kn ko gt kp gh gi paragraph-image"><div role="button" tabindex="0" class="nx ny di nz bf oa"><div class="gh gi pb"><img src="../Images/33136b55890783c901265993df28540d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*5f1xtLJ21ujGk3rpxYwh8g.png"/></div></div></figure><p id="5e61" class="pw-post-body-paragraph lk ll iv lm b ln mg jw lp lq mh jz ls lt mi lv lw lx mj lz ma mb mk md me mf io bi translated">现在您应该可以看到:</p><figure class="kl km kn ko gt kp gh gi paragraph-image"><div role="button" tabindex="0" class="nx ny di nz bf oa"><div class="gh gi pb"><img src="../Images/b309089bb8d4bf68854492beb79f9c9a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*7mYzIOow8qrFYFpKrCTJWQ.png"/></div></div><figcaption class="ns nt gj gh gi nu nv bd b be z dk">One-hot encoded data set</figcaption></figure><p id="9d53" class="pw-post-body-paragraph lk ll iv lm b ln mg jw lp lq mh jz ls lt mi lv lw lx mj lz ma mb mk md me mf io bi translated">你注意到我们从 23 列增加到 118 列。这是五倍的增长，但这个数字还不足以导致计算机内存问题。</p><p id="b683" class="pw-post-body-paragraph lk ll iv lm b ln mg jw lp lq mh jz ls lt mi lv lw lx mj lz ma mb mk md me mf io bi translated">既然我们的数据集只包含数字数据，我们就可以开始建模和预测了！</p><h2 id="987c" class="oe kt iv bd ku of og dn ky oh oi dp lc lt oj ok le lx ol om lg mb on oo li op bi translated">训练/测试分割</h2><p id="c7a5" class="pw-post-body-paragraph lk ll iv lm b ln lo jw lp lq lr jz ls lt lu lv lw lx ly lz ma mb mc md me mf io bi translated">在深入建模和进行预测之前，我们需要将数据集分成训练集和测试集。这样，我们可以在训练集上训练算法，并在测试集上进行预测。这种方式的误差度量将更加相关，因为该算法将对以前没有见过的数据进行预测。</p><p id="13ee" class="pw-post-body-paragraph lk ll iv lm b ln mg jw lp lq mh jz ls lt mi lv lw lx mj lz ma mb mk md me mf io bi translated">我们可以像这样轻松地分割数据集:</p><figure class="kl km kn ko gt kp gh gi paragraph-image"><div role="button" tabindex="0" class="nx ny di nz bf oa"><div class="gh gi pb"><img src="../Images/4d0e3125ba48cccc09de0cf5ef05aa77.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Dz4efFPLSpsDZBnAqIDRyQ.png"/></div></div></figure><p id="e4f8" class="pw-post-body-paragraph lk ll iv lm b ln mg jw lp lq mh jz ls lt mi lv lw lx mj lz ma mb mk md me mf io bi translated">这里，<em class="oc"> y </em>就是单纯的目标(有毒或可食用)。那么，<em class="oc"> X </em>就是简单的所有特征的数据集。最后，我们使用<em class="oc"> train_test_split </em>函数。<em class="oc"> test_size </em>参数对应于将用于测试的数据集部分。通常，我们使用 20%。然后，<em class="oc"> random_state </em>参数用于再现性。它可以设置为任何数字，但它将确保每次代码运行时，数据集将被相同地分割。如果没有提供<em class="oc"> random_state </em>，那么训练集和测试集将会不同，因为函数会随机分割它。</p><p id="b8a6" class="pw-post-body-paragraph lk ll iv lm b ln mg jw lp lq mh jz ls lt mi lv lw lx mj lz ma mb mk md me mf io bi translated">好了，我们正式准备好开始建模和预测了！</p><h2 id="9a58" class="oe kt iv bd ku of og dn ky oh oi dp lc lt oj ok le lx ol om lg mb on oo li op bi translated">逻辑回归</h2><p id="9c0b" class="pw-post-body-paragraph lk ll iv lm b ln lo jw lp lq lr jz ls lt lu lv lw lx ly lz ma mb mc md me mf io bi translated">我们将首先使用逻辑回归。在接下来的步骤中，我们将使用 ROC 曲线下的面积和混淆矩阵作为误差度量。</p><p id="1ed7" class="pw-post-body-paragraph lk ll iv lm b ln mg jw lp lq mh jz ls lt mi lv lw lx mj lz ma mb mk md me mf io bi translated">让我们先导入我们需要的所有内容:</p><figure class="kl km kn ko gt kp gh gi paragraph-image"><div role="button" tabindex="0" class="nx ny di nz bf oa"><div class="gh gi pb"><img src="../Images/9b36f4331e383f7672beacf04abd6897.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*VhlZa4w-t4aexK2VWGf__Q.png"/></div></div></figure><p id="5374" class="pw-post-body-paragraph lk ll iv lm b ln mg jw lp lq mh jz ls lt mi lv lw lx mj lz ma mb mk md me mf io bi translated">然后，我们创建一个<em class="oc"> LogisticRegression </em>对象的实例，并使模型适合训练集:</p><figure class="kl km kn ko gt kp gh gi paragraph-image"><div role="button" tabindex="0" class="nx ny di nz bf oa"><div class="gh gi pb"><img src="../Images/6a1dea5cb52989185c1b059ba3fee5c7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*rb8bnyYacFoRrfIeF3vxOg.png"/></div></div></figure><p id="498f" class="pw-post-body-paragraph lk ll iv lm b ln mg jw lp lq mh jz ls lt mi lv lw lx mj lz ma mb mk md me mf io bi translated">然后，我们预测蘑菇有毒的概率。记住，我们认为蘑菇有毒或无毒。</p><p id="de51" class="pw-post-body-paragraph lk ll iv lm b ln mg jw lp lq mh jz ls lt mi lv lw lx mj lz ma mb mk md me mf io bi translated">此外，必须提醒您，逻辑回归会返回一个概率。现在，让我们将阈值设置为 0.5，这样，如果概率大于 0.5，蘑菇将被分类为有毒。当然，如果概率小于阈值，蘑菇被分类为可食用。</p><p id="bf0d" class="pw-post-body-paragraph lk ll iv lm b ln mg jw lp lq mh jz ls lt mi lv lw lx mj lz ma mb mk md me mf io bi translated">这正是下面代码单元格中发生的情况:</p><figure class="kl km kn ko gt kp gh gi paragraph-image"><div role="button" tabindex="0" class="nx ny di nz bf oa"><div class="gh gi pb"><img src="../Images/c655431dfc22f25ccf90fd3a604d4a9e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*60X-JZ_ql93e-WaWG2mh6Q.png"/></div></div></figure><p id="bee3" class="pw-post-body-paragraph lk ll iv lm b ln mg jw lp lq mh jz ls lt mi lv lw lx mj lz ma mb mk md me mf io bi translated">注意，我们是在测试集上计算概率的。</p><p id="7ce0" class="pw-post-body-paragraph lk ll iv lm b ln mg jw lp lq mh jz ls lt mi lv lw lx mj lz ma mb mk md me mf io bi translated">现在，让我们看看<strong class="lm iw">混淆矩阵。</strong>这将显示真实阳性率、真实阴性率、假阳性率和假阴性率。</p><figure class="kl km kn ko gt kp gh gi paragraph-image"><div class="gh gi pj"><img src="../Images/011ee3d97d11b162641d9c4fdd960c7f.png" data-original-src="https://miro.medium.com/v2/resize:fit:576/format:webp/1*iGCc-GJHfpkyHQxNjK3_GA.png"/></div><figcaption class="ns nt gj gh gi nu nv bd b be z dk">Example of a confusion matrix</figcaption></figure><p id="3af6" class="pw-post-body-paragraph lk ll iv lm b ln mg jw lp lq mh jz ls lt mi lv lw lx mj lz ma mb mk md me mf io bi translated">我们像这样输出我们的混淆矩阵:</p><figure class="kl km kn ko gt kp gh gi paragraph-image"><div role="button" tabindex="0" class="nx ny di nz bf oa"><div class="gh gi pb"><img src="../Images/e22b33ecab4d9bdb66bb96d453f940ad.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*6Va4Ot2hEH6GsXa5b7MQsA.png"/></div></div></figure><p id="0527" class="pw-post-body-paragraph lk ll iv lm b ln mg jw lp lq mh jz ls lt mi lv lw lx mj lz ma mb mk md me mf io bi translated">您应该得到:</p><figure class="kl km kn ko gt kp gh gi paragraph-image"><div role="button" tabindex="0" class="nx ny di nz bf oa"><div class="gh gi pk"><img src="../Images/c2a1c65429ba9c79ad1b8eedf2006693.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*IwqU8DDJ-knFnaGsCATbug.png"/></div></div></figure><p id="d355" class="pw-post-body-paragraph lk ll iv lm b ln mg jw lp lq mh jz ls lt mi lv lw lx mj lz ma mb mk md me mf io bi translated">太神奇了！我们的分类器是完美的！从上面的混淆矩阵中，你可以看到我们的假阳性和假阴性率是 0，这意味着所有的蘑菇都被正确地分类为有毒或可食用！</p><p id="34ee" class="pw-post-body-paragraph lk ll iv lm b ln mg jw lp lq mh jz ls lt mi lv lw lx mj lz ma mb mk md me mf io bi translated">让我们打印 ROC 曲线下的面积。如你所知，对于一个完美的分类器，它应该等于 1。</p><figure class="kl km kn ko gt kp gh gi paragraph-image"><div role="button" tabindex="0" class="nx ny di nz bf oa"><div class="gh gi pb"><img src="../Images/35c1c2dc48fd7e6f9a97abc78e09be78.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Cd-BQbhSq0G5a-ht_0xIwg.png"/></div></div></figure><p id="31e6" class="pw-post-body-paragraph lk ll iv lm b ln mg jw lp lq mh jz ls lt mi lv lw lx mj lz ma mb mk md me mf io bi translated">的确，上面的代码块输出 1！我们可以制作自己的函数来可视化 ROC 曲线:</p><figure class="kl km kn ko gt kp gh gi paragraph-image"><div role="button" tabindex="0" class="nx ny di nz bf oa"><div class="gh gi pb"><img src="../Images/383525c1b07216661e3dad6332d1ba33.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*KfcRn47UCoYkTDgShA7DqA.png"/></div></div></figure><p id="0e6f" class="pw-post-body-paragraph lk ll iv lm b ln mg jw lp lq mh jz ls lt mi lv lw lx mj lz ma mb mk md me mf io bi translated">您应该会看到:</p><figure class="kl km kn ko gt kp gh gi paragraph-image"><div role="button" tabindex="0" class="nx ny di nz bf oa"><div class="gh gi pl"><img src="../Images/a354c11e01f3d90479525c96fad4fa1d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Bg9emKDvbv5JdqX_vc74qw.png"/></div></div><figcaption class="ns nt gj gh gi nu nv bd b be z dk">ROC curve</figcaption></figure><p id="cc45" class="pw-post-body-paragraph lk ll iv lm b ln mg jw lp lq mh jz ls lt mi lv lw lx mj lz ma mb mk md me mf io bi translated">恭喜你！你用一个基本的逻辑回归模型建立了一个完美的分类器。</p><p id="531c" class="pw-post-body-paragraph lk ll iv lm b ln mg jw lp lq mh jz ls lt mi lv lw lx mj lz ma mb mk md me mf io bi translated">然而，为了获得更多的经验，让我们使用 ld a 和 QDA 建立一个分类器，看看我们是否得到类似的结果。</p><h2 id="106b" class="oe kt iv bd ku of og dn ky oh oi dp lc lt oj ok le lx ol om lg mb on oo li op bi translated">LDA 分类器</h2><p id="0d97" class="pw-post-body-paragraph lk ll iv lm b ln lo jw lp lq lr jz ls lt lu lv lw lx ly lz ma mb mc md me mf io bi translated">遵循逻辑回归概述的相同步骤:</p><figure class="kl km kn ko gt kp gh gi paragraph-image"><div role="button" tabindex="0" class="nx ny di nz bf oa"><div class="gh gi pb"><img src="../Images/b6a702c3d1cc7e89b51c0eed7cbc78a3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*IVky3NwthaUlGo-v14YlwA.png"/></div></div></figure><p id="9a3d" class="pw-post-body-paragraph lk ll iv lm b ln mg jw lp lq mh jz ls lt mi lv lw lx mj lz ma mb mk md me mf io bi translated">如果您运行上面的代码，您应该看到我们再次获得了一个完美的分类器，其结果与使用逻辑回归的分类器相同。</p><h2 id="f7a0" class="oe kt iv bd ku of og dn ky oh oi dp lc lt oj ok le lx ol om lg mb on oo li op bi translated">QDA 分类器</h2><p id="4562" class="pw-post-body-paragraph lk ll iv lm b ln lo jw lp lq lr jz ls lt lu lv lw lx ly lz ma mb mc md me mf io bi translated">现在，我们重复这个过程，但是使用 QDA:</p><figure class="kl km kn ko gt kp gh gi paragraph-image"><div role="button" tabindex="0" class="nx ny di nz bf oa"><div class="gh gi pb"><img src="../Images/6580b38f7618a4512bce5cd2cd40b294.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*yKiwQaP1zy1UN_wP5dwgQA.png"/></div></div></figure><p id="e31d" class="pw-post-body-paragraph lk ll iv lm b ln mg jw lp lq mh jz ls lt mi lv lw lx mj lz ma mb mk md me mf io bi translated">同样，结果是一样的！</p></div><div class="ab cl pm pn hz po" role="separator"><span class="pp bw bk pq pr ps"/><span class="pp bw bk pq pr ps"/><span class="pp bw bk pq pr"/></div><div class="io ip iq ir is"><p id="8806" class="pw-post-body-paragraph lk ll iv lm b ln mg jw lp lq mh jz ls lt mi lv lw lx mj lz ma mb mk md me mf io bi translated">在本文中，您了解了用于分类的逻辑回归、LDA 和 QDA 的内部工作原理。</p><p id="07b0" class="pw-post-body-paragraph lk ll iv lm b ln mg jw lp lq mh jz ls lt mi lv lw lx mj lz ma mb mk md me mf io bi translated">您还学习了如何用 Python 实现每个算法来解决分类问题。您经历了一个典型的分类工作流，其中必须对类进行编码，并且必须检查数据集是否不平衡。</p><p id="02d2" class="pw-post-body-paragraph lk ll iv lm b ln mg jw lp lq mh jz ls lt mi lv lw lx mj lz ma mb mk md me mf io bi translated">我希望这篇文章对你有用。当你需要的时候，请随时查阅它！</p><p id="bf4d" class="pw-post-body-paragraph lk ll iv lm b ln mg jw lp lq mh jz ls lt mi lv lw lx mj lz ma mb mk md me mf io bi translated">干杯！</p></div></div>    
</body>
</html>