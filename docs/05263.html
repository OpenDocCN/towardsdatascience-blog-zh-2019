<html>
<head>
<title>Python Libraries for Interpretable Machine Learning</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">用于可解释机器学习的 Python 库</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/python-libraries-for-interpretable-machine-learning-c476a08ed2c7?source=collection_archive---------8-----------------------#2019-08-06">https://towardsdatascience.com/python-libraries-for-interpretable-machine-learning-c476a08ed2c7?source=collection_archive---------8-----------------------#2019-08-06</a></blockquote><div><div class="fc ii ij ik il im"/><div class="in io ip iq ir"><div class=""/><div class=""><h2 id="d99e" class="pw-subtitle-paragraph jr it iu bd b js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki dk translated">4 个用于更好地可视化、解释和诠释模型的库</h2></div><figure class="kk kl km kn gu ko gi gj paragraph-image"><div class="gi gj kj"><img src="../Images/3eade71f71721c5a02027ffc129cab23.png" data-original-src="https://miro.medium.com/v2/resize:fit:1162/format:webp/1*YJdpqylxxACYYttLeQZfMg.png"/></div></figure><p id="29ba" class="pw-post-body-paragraph kr ks iu kt b ku kv jv kw kx ky jy kz la lb lc ld le lf lg lh li lj lk ll lm in bi translated">随着对人工智能偏见的担忧变得越来越突出，企业能够解释他们的模型产生的预测以及模型本身如何工作变得越来越重要。幸运的是，正在开发越来越多的 python 库来尝试解决这个问题。在下面的帖子中，我将简要介绍四个最常用的解释和说明机器学习模型的软件包。</p><p id="4a6b" class="pw-post-body-paragraph kr ks iu kt b ku kv jv kw kx ky jy kz la lb lc ld le lf lg lh li lj lk ll lm in bi translated">下面的库都是 pip 可安装的，带有很好的文档，并且强调可视化解释。</p><h2 id="981a" class="lo lp iu bd lq lr ls dn lt lu lv dp lw la lx ly lz le ma mb mc li md me mf mg bi translated"><a class="ae ln" href="https://www.scikit-yb.org/en/latest/quickstart.html" rel="noopener ugc nofollow" target="_blank">黄砖</a></h2><p id="3c6f" class="pw-post-body-paragraph kr ks iu kt b ku mh jv kw kx mi jy kz la mj lc ld le mk lg lh li ml lk ll lm in bi translated">这个库本质上是 scikit-learn 库的扩展，为机器学习模型提供了一些非常有用和漂亮的可视化。visualiser 对象，核心接口，是 scikit-learn 评估器，所以如果你习惯于使用 scikit-learn，工作流程应该很熟悉。</p><p id="8dd1" class="pw-post-body-paragraph kr ks iu kt b ku kv jv kw kx ky jy kz la lb lc ld le lf lg lh li lj lk ll lm in bi translated">可以呈现的可视化包括模型选择、特征重要性和模型性能分析。</p><p id="bd61" class="pw-post-body-paragraph kr ks iu kt b ku kv jv kw kx ky jy kz la lb lc ld le lf lg lh li lj lk ll lm in bi translated">让我们看几个简单的例子。</p><p id="acad" class="pw-post-body-paragraph kr ks iu kt b ku kv jv kw kx ky jy kz la lb lc ld le lf lg lh li lj lk ll lm in bi translated">该库可以通过 pip 安装。</p><pre class="kk kl km kn gu mm mn mo mp aw mq bi"><span id="fd77" class="lo lp iu mn b gz mr ms l mt mu">pip install yellowbrick</span></pre><p id="f85b" class="pw-post-body-paragraph kr ks iu kt b ku kv jv kw kx ky jy kz la lb lc ld le lf lg lh li lj lk ll lm in bi translated">为了说明一些特性，我将使用一个名为<a class="ae ln" href="https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_wine.html#sklearn.datasets.load_wine" rel="noopener ugc nofollow" target="_blank">葡萄酒识别</a>集的 scikit-learn 数据集。该数据集有 13 个特征和 3 个目标类，可以直接从 scikit-learn 库中加载。在下面的代码中，我导入数据集并将其转换为数据框。数据可以在分类器中使用，无需任何额外的预处理。</p><pre class="kk kl km kn gu mm mn mo mp aw mq bi"><span id="5109" class="lo lp iu mn b gz mr ms l mt mu">import pandas as pd<br/>from sklearn import datasets</span><span id="70ec" class="lo lp iu mn b gz mv ms l mt mu">wine_data = datasets.load_wine()<br/>df_wine = pd.DataFrame(wine_data.data,columns=wine_data.feature_names)<br/>df_wine['target'] = pd.Series(wine_data.target)</span></pre><p id="92b7" class="pw-post-body-paragraph kr ks iu kt b ku kv jv kw kx ky jy kz la lb lc ld le lf lg lh li lj lk ll lm in bi translated">我还使用 scikit-learn 将数据集进一步分为测试和训练。</p><pre class="kk kl km kn gu mm mn mo mp aw mq bi"><span id="ed18" class="lo lp iu mn b gz mr ms l mt mu">from sklearn.model_selection import train_test_split</span><span id="2a30" class="lo lp iu mn b gz mv ms l mt mu">X = df_wine.drop(['target'], axis=1)<br/>y = df_wine['target']</span><span id="b4c6" class="lo lp iu mn b gz mv ms l mt mu">X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)</span></pre><p id="10be" class="pw-post-body-paragraph kr ks iu kt b ku kv jv kw kx ky jy kz la lb lc ld le lf lg lh li lj lk ll lm in bi translated">接下来，让我们使用 Yellowbricks visualiser 来查看数据集中特征之间的相关性。</p><pre class="kk kl km kn gu mm mn mo mp aw mq bi"><span id="970b" class="lo lp iu mn b gz mr ms l mt mu">from yellowbrick.features import Rank2D<br/>import matplotlib.pyplot as plt</span><span id="5b03" class="lo lp iu mn b gz mv ms l mt mu">visualizer = Rank2D(algorithm="pearson",  size=(1080, 720))<br/>visualizer.fit_transform(X_train)<br/>visualizer.poof()</span></pre><figure class="kk kl km kn gu ko gi gj paragraph-image"><div role="button" tabindex="0" class="mx my di mz bf na"><div class="gi gj mw"><img src="../Images/87b7f4a58020311ed3e63d63e9eee390.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*AU4IhBUQe4EgXxiphrNI4g.png"/></div></div></figure><p id="c27a" class="pw-post-body-paragraph kr ks iu kt b ku kv jv kw kx ky jy kz la lb lc ld le lf lg lh li lj lk ll lm in bi translated">现在让我们安装一个 RandomForestClassifier 并使用另一个可视化工具评估性能。</p><pre class="kk kl km kn gu mm mn mo mp aw mq bi"><span id="7048" class="lo lp iu mn b gz mr ms l mt mu">from yellowbrick.classifier import ClassificationReport<br/>from sklearn.ensemble import RandomForestClassifier</span><span id="cad3" class="lo lp iu mn b gz mv ms l mt mu">model =  RandomForestClassifier()<br/>visualizer = ClassificationReport(model, size=(1080, 720))</span><span id="a37b" class="lo lp iu mn b gz mv ms l mt mu">visualizer.fit(X_train, y_train)<br/>visualizer.score(X_test, y_test)<br/>visualizer.poof()</span></pre><figure class="kk kl km kn gu ko gi gj paragraph-image"><div role="button" tabindex="0" class="mx my di mz bf na"><div class="gi gj nb"><img src="../Images/963486652a6c916147bc9158cf3e629c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*kK_QYZt_fXr_Ylz_mHTDbg.png"/></div></div></figure><h2 id="06ec" class="lo lp iu bd lq lr ls dn lt lu lv dp lw la lx ly lz le ma mb mc li md me mf mg bi translated"><a class="ae ln" href="https://eli5.readthedocs.io/en/latest/" rel="noopener ugc nofollow" target="_blank"> ELI5 </a></h2><p id="4c9a" class="pw-post-body-paragraph kr ks iu kt b ku mh jv kw kx mi jy kz la mj lc ld le mk lg lh li ml lk ll lm in bi translated">ELI5 是另一个可视化库，用于调试机器学习模型并解释它们产生的预测。它可以与最常见的 python 机器学习库一起工作，包括 scikit-learn、XGBoost 和 Keras。</p><p id="33dc" class="pw-post-body-paragraph kr ks iu kt b ku kv jv kw kx ky jy kz la lb lc ld le lf lg lh li lj lk ll lm in bi translated">让我们使用 ELI5 来检查我们上面训练的模型的特征重要性。</p><pre class="kk kl km kn gu mm mn mo mp aw mq bi"><span id="bf96" class="lo lp iu mn b gz mr ms l mt mu">import eli5</span><span id="6cbe" class="lo lp iu mn b gz mv ms l mt mu">eli5.show_weights(model, feature_names = X.columns.tolist())</span></pre><figure class="kk kl km kn gu ko gi gj paragraph-image"><div class="gi gj nc"><img src="../Images/df4dcfb6ed311d47eb82f710c5de40c9.png" data-original-src="https://miro.medium.com/v2/resize:fit:642/format:webp/1*2kiqFsUm103ddqPdJ7d3nw.png"/></div></figure><p id="723e" class="pw-post-body-paragraph kr ks iu kt b ku kv jv kw kx ky jy kz la lb lc ld le lf lg lh li lj lk ll lm in bi translated">默认情况下，<code class="fe nd ne nf mn b">show_weights</code>方法使用<code class="fe nd ne nf mn b">gain</code>来计算权重，但是您可以通过添加<code class="fe nd ne nf mn b">importance_type</code>参数来指定其他类型。</p><p id="bb1c" class="pw-post-body-paragraph kr ks iu kt b ku kv jv kw kx ky jy kz la lb lc ld le lf lg lh li lj lk ll lm in bi translated">也可以用<code class="fe nd ne nf mn b">show_prediction</code>来考察个别预测的原因。</p><pre class="kk kl km kn gu mm mn mo mp aw mq bi"><span id="61bd" class="lo lp iu mn b gz mr ms l mt mu">from eli5 import show_prediction</span><span id="9103" class="lo lp iu mn b gz mv ms l mt mu">show_prediction(model, X_train.iloc[1], feature_names = X.columns.tolist(), <br/>                show_feature_values=True)</span></pre><figure class="kk kl km kn gu ko gi gj paragraph-image"><div role="button" tabindex="0" class="mx my di mz bf na"><div class="gi gj ng"><img src="../Images/f48530f657ad18298c4fa67f34041596.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Awd5HIOdq7IsrHCqc_lk5g.png"/></div></div></figure><h2 id="69c0" class="lo lp iu bd lq lr ls dn lt lu lv dp lw la lx ly lz le ma mb mc li md me mf mg bi translated"><a class="ae ln" href="https://github.com/marcotcr/lime" rel="noopener ugc nofollow" target="_blank">石灰</a></h2><p id="fccb" class="pw-post-body-paragraph kr ks iu kt b ku mh jv kw kx mi jy kz la mj lc ld le mk lg lh li ml lk ll lm in bi translated">LIME(本地可解释模型不可知解释)是一个用于解释机器学习算法所做预测的包。Lime 支持对来自各种分类器的单个预测的解释，并且内置了对 scikit-learn 的支持。</p><p id="fdf3" class="pw-post-body-paragraph kr ks iu kt b ku kv jv kw kx ky jy kz la lb lc ld le lf lg lh li lj lk ll lm in bi translated">让我们使用 Lime 来解释我们之前训练的模型的一些预测。</p><p id="81d8" class="pw-post-body-paragraph kr ks iu kt b ku kv jv kw kx ky jy kz la lb lc ld le lf lg lh li lj lk ll lm in bi translated">石灰可以通过 pip 安装。</p><pre class="kk kl km kn gu mm mn mo mp aw mq bi"><span id="a1c3" class="lo lp iu mn b gz mr ms l mt mu">pip install lime</span></pre><p id="ae38" class="pw-post-body-paragraph kr ks iu kt b ku kv jv kw kx ky jy kz la lb lc ld le lf lg lh li lj lk ll lm in bi translated">首先，我们构建解释器。这将训练数据集作为一个数组，模型中使用的功能的名称和目标变量中的类的名称。</p><pre class="kk kl km kn gu mm mn mo mp aw mq bi"><span id="0a06" class="lo lp iu mn b gz mr ms l mt mu">import lime.lime_tabular</span><span id="d87f" class="lo lp iu mn b gz mv ms l mt mu">explainer = lime.lime_tabular.LimeTabularExplainer(X_train.values,                                            feature_names=X_train.columns.values.tolist(),                                        class_names=y_train.unique())</span></pre><p id="1368" class="pw-post-body-paragraph kr ks iu kt b ku kv jv kw kx ky jy kz la lb lc ld le lf lg lh li lj lk ll lm in bi translated">接下来，我们创建一个 lambda 函数，使用该模型对数据样本进行预测。这是借用这个优秀的，更深入的，关于石灰的<a class="ae ln" href="https://www.guru99.com/scikit-learn-tutorial.html" rel="noopener ugc nofollow" target="_blank">教程</a>。</p><pre class="kk kl km kn gu mm mn mo mp aw mq bi"><span id="0bfe" class="lo lp iu mn b gz mr ms l mt mu">predict_fn = lambda x: model.predict_proba(x).astype(float)</span></pre><p id="3f36" class="pw-post-body-paragraph kr ks iu kt b ku kv jv kw kx ky jy kz la lb lc ld le lf lg lh li lj lk ll lm in bi translated">然后，我们使用解释器来解释一个选定例子的预测。结果如下所示。Lime 产生了一个可视化效果，显示了这些特征是如何促成这一特定预测的。</p><pre class="kk kl km kn gu mm mn mo mp aw mq bi"><span id="b221" class="lo lp iu mn b gz mr ms l mt mu">exp = explainer.explain_instance(X_test.values[0], predict_fn, num_features=6)<br/>exp.show_in_notebook(show_all=False)</span></pre><figure class="kk kl km kn gu ko gi gj paragraph-image"><div role="button" tabindex="0" class="mx my di mz bf na"><div class="gi gj nh"><img src="../Images/e3e7c9c9329b81c0fcfac204358a003f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*vNbER-mCdNQsHOztRMdnBA.png"/></div></div></figure><h2 id="12af" class="lo lp iu bd lq lr ls dn lt lu lv dp lw la lx ly lz le ma mb mc li md me mf mg bi translated"><a class="ae ln" href="http://rasbt.github.io/mlxtend/" rel="noopener ugc nofollow" target="_blank"> MLxtend </a></h2><p id="76a4" class="pw-post-body-paragraph kr ks iu kt b ku mh jv kw kx mi jy kz la mj lc ld le mk lg lh li ml lk ll lm in bi translated">这个库包含了许多机器学习的辅助函数。这涵盖了像堆叠和投票分类器，模型评估，特征提取和工程和绘图。除了文档之外，这篇<a class="ae ln" href="https://sebastianraschka.com/pdf/software/mlxtend-latest.pdf" rel="noopener ugc nofollow" target="_blank">文章</a>也是一个很好的资源，有助于更详细地理解这个包。</p><p id="c003" class="pw-post-body-paragraph kr ks iu kt b ku kv jv kw kx ky jy kz la lb lc ld le lf lg lh li lj lk ll lm in bi translated">让我们使用 MLxtend 来比较投票分类器与其组成分类器的决策边界。</p><p id="0f0a" class="pw-post-body-paragraph kr ks iu kt b ku kv jv kw kx ky jy kz la lb lc ld le lf lg lh li lj lk ll lm in bi translated">同样，它可以通过 pip 安装。</p><pre class="kk kl km kn gu mm mn mo mp aw mq bi"><span id="9e29" class="lo lp iu mn b gz mr ms l mt mu">pip install mlxtend</span></pre><p id="dd59" class="pw-post-body-paragraph kr ks iu kt b ku kv jv kw kx ky jy kz la lb lc ld le lf lg lh li lj lk ll lm in bi translated">我使用的导入如下所示。</p><pre class="kk kl km kn gu mm mn mo mp aw mq bi"><span id="29f1" class="lo lp iu mn b gz mr ms l mt mu">from mlxtend.plotting import plot_decision_regions<br/>from mlxtend.classifier import EnsembleVoteClassifier<br/>import matplotlib.gridspec as gridspec<br/>import itertools</span><span id="db68" class="lo lp iu mn b gz mv ms l mt mu">from sklearn import model_selection<br/>from sklearn.linear_model import LogisticRegression<br/>from sklearn.naive_bayes import GaussianNB<br/>from sklearn.ensemble import RandomForestClassifier</span></pre><p id="5910" class="pw-post-body-paragraph kr ks iu kt b ku kv jv kw kx ky jy kz la lb lc ld le lf lg lh li lj lk ll lm in bi translated">下面的可视化一次只能处理两个特征，所以我们将首先创建一个包含特征<code class="fe nd ne nf mn b">proline</code>和<code class="fe nd ne nf mn b">color_intensity</code>的数组。我选择这些是因为它们在我们之前使用 ELI5 检查的所有特性中权重最高。</p><pre class="kk kl km kn gu mm mn mo mp aw mq bi"><span id="6b91" class="lo lp iu mn b gz mr ms l mt mu">X_train_ml = X_train[['proline', 'color_intensity']].values<br/>y_train_ml = y_train.values</span></pre><p id="c7c4" class="pw-post-body-paragraph kr ks iu kt b ku kv jv kw kx ky jy kz la lb lc ld le lf lg lh li lj lk ll lm in bi translated">接下来，我们创建分类器，使它们适合训练数据，并使用 MLxtend 可视化决策边界。输出显示在代码下方。</p><pre class="kk kl km kn gu mm mn mo mp aw mq bi"><span id="8946" class="lo lp iu mn b gz mr ms l mt mu">clf1 = LogisticRegression(random_state=1)<br/>clf2 = RandomForestClassifier(random_state=1)<br/>clf3 = GaussianNB()<br/>eclf = EnsembleVoteClassifier(clfs=[clf1, clf2, clf3], weights=[1,1,1])</span><span id="3b07" class="lo lp iu mn b gz mv ms l mt mu">value=1.5<br/>width=0.75</span><span id="c73a" class="lo lp iu mn b gz mv ms l mt mu">gs = gridspec.GridSpec(2,2)</span><span id="7a93" class="lo lp iu mn b gz mv ms l mt mu">fig = plt.figure(figsize=(10,8))</span><span id="5ecf" class="lo lp iu mn b gz mv ms l mt mu">labels = ['Logistic Regression', 'Random Forest', 'Naive Bayes', 'Ensemble']</span><span id="eeb2" class="lo lp iu mn b gz mv ms l mt mu">for clf, lab, grd in zip([clf1, clf2, clf3, eclf],<br/>                         labels,<br/>                         itertools.product([0, 1], repeat=2)):<br/>                         <br/>    clf.fit(X_train_ml, y_train_ml)<br/>    ax = plt.subplot(gs[grd[0], grd[1]])<br/>    fig = plot_decision_regions(X=X_train_ml, y=y_train_ml, clf=clf)<br/>    plt.title(lab)</span></pre><figure class="kk kl km kn gu ko gi gj paragraph-image"><div class="gi gj kj"><img src="../Images/3eade71f71721c5a02027ffc129cab23.png" data-original-src="https://miro.medium.com/v2/resize:fit:1162/format:webp/1*YJdpqylxxACYYttLeQZfMg.png"/></div></figure><p id="b3ce" class="pw-post-body-paragraph kr ks iu kt b ku kv jv kw kx ky jy kz la lb lc ld le lf lg lh li lj lk ll lm in bi translated">这绝不是一个用于解释、可视化和解释机器学习模型的详尽的库列表。这篇优秀的<a class="ae ln" href="https://skymind.ai/wiki/python-ai" rel="noopener ugc nofollow" target="_blank">帖子</a>包含了一长串其他有用的库供您尝试。</p><p id="030e" class="pw-post-body-paragraph kr ks iu kt b ku kv jv kw kx ky jy kz la lb lc ld le lf lg lh li lj lk ll lm in bi translated">感谢阅读！</p></div></div>    
</body>
</html>