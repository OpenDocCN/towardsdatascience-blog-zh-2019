<html>
<head>
<title>Generate Anime Style Face Using DCGAN and Explore Its Latent Feature Representation</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用 DCGAN 生成动漫风格人脸并探索其潜在特征表示</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/generate-anime-style-face-using-dcgan-and-explore-its-latent-feature-representation-ae0e905f3974?source=collection_archive---------1-----------------------#2019-04-13">https://towardsdatascience.com/generate-anime-style-face-using-dcgan-and-explore-its-latent-feature-representation-ae0e905f3974?source=collection_archive---------1-----------------------#2019-04-13</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="0bd1" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">逐步试验 DCGAN 并可视化其结果</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/991cb253e8d8d300269f794a217b2376.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*jKZK-liwSn2ozdon-5wupw.png"/></div></div></figure><p id="b778" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi ln translated">各位，好久不见了！今天，我想写一下我学习和实验另一种深度学习技术的结果，这种技术是生成对抗网络(GAN)。最近研究了解了一下。我想如果把我的实验分享给每个人会很好。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi lw"><img src="../Images/afcbd18057807051be78afbb374d6149.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*rdyGiu2aaXlrLPch"/></div></div><figcaption class="lx ly gj gh gi lz ma bd b be z dk">Photo by <a class="ae mb" href="https://unsplash.com/@hiteshchoudhary?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Hitesh Choudhary</a> on <a class="ae mb" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><p id="440e" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">“干”主要是指产生某种东西。在这篇文章中，我想分享关于生成动漫人物面部的实验。不仅仅是生成，我还实验了图像可以通过潜在变量(一个用于生成人脸的向量)的线性代数运算来操作。我还看到生成的人脸遵循统计分布，这真的很棒。</p><p id="7012" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">这篇文章将集中在教程如何做 GAN 的每个步骤解释(与源代码)。它将针对任何对人工智能感兴趣的人，特别是想练习使用深度学习的人。它也针对每个人谁想学习如何做甘第一次。我会尽可能简单易懂地写这篇文章。我希望读者通过阅读这篇文章，了解甘将军是如何工作的。</p><p id="b50f" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">如果你想在阅读这篇文章时有更好的理解，我建议你至少了解神经网络和卷积神经网络(CNN)。</p><p id="5995" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">如果您想了解完整的源代码，本文末尾有一个 GitHub 链接。现在，我将给出存储库中的 python 笔记本和协作链接。</p><p id="0462" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated"><strong class="kt ir">图片 0 </strong>是生成的动漫人物脸之一，我们将使用模型形成的图片来创建。左起第一张和第二张图由 GAN 生成。第三是第一面和第二面的相加(你可以称之为第一面和第二面的融合)。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi mc"><img src="../Images/200b395e65ba9665b7c4003effb2fe75.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*h5wxkHfbNfwQG1cTR4NO0g.png"/></div></div><figcaption class="lx ly gj gh gi lz ma bd b be z dk">Images 0 : Example of generated faces and the fusion of their face. G + D = GAN</figcaption></figure><h1 id="3787" class="md me iq bd mf mg mh mi mj mk ml mm mn jw mo jx mp jz mq ka mr kc ms kd mt mu bi translated">概述</h1><ol class=""><li id="26df" class="mv mw iq kt b ku mx kx my la mz le na li nb lm nc nd ne nf bi translated">技术</li><li id="460e" class="mv mw iq kt b ku ng kx nh la ni le nj li nk lm nc nd ne nf bi translated">介绍</li><li id="93c9" class="mv mw iq kt b ku ng kx nh la ni le nj li nk lm nc nd ne nf bi translated">甘简介</li><li id="d939" class="mv mw iq kt b ku ng kx nh la ni le nj li nk lm nc nd ne nf bi translated">履行</li><li id="0550" class="mv mw iq kt b ku ng kx nh la ni le nj li nk lm nc nd ne nf bi translated">结果</li><li id="a31e" class="mv mw iq kt b ku ng kx nh la ni le nj li nk lm nc nd ne nf bi translated">吸取的教训</li><li id="59b4" class="mv mw iq kt b ku ng kx nh la ni le nj li nk lm nc nd ne nf bi translated">结论</li><li id="9c06" class="mv mw iq kt b ku ng kx nh la ni le nj li nk lm nc nd ne nf bi translated">编后记</li><li id="6413" class="mv mw iq kt b ku ng kx nh la ni le nj li nk lm nc nd ne nf bi translated">贮藏室ˌ仓库</li><li id="5c35" class="mv mw iq kt b ku ng kx nh la ni le nj li nk lm nc nd ne nf bi translated">来源</li></ol><h1 id="dee6" class="md me iq bd mf mg mh mi mj mk ml mm mn jw mo jx mp jz mq ka mr kc ms kd mt mu bi translated">技术和数据</h1><ol class=""><li id="0097" class="mv mw iq kt b ku mx kx my la mz le na li nb lm nc nd ne nf bi translated">Python 3.7</li><li id="e7d1" class="mv mw iq kt b ku ng kx nh la ni le nj li nk lm nc nd ne nf bi translated">合作实验室:免费的 Jupyter 笔记本环境，无需设置，完全在云中运行。有 GPU 特斯拉 K80 甚至 TPU！遗憾的是，在撰写本文时，Tensorflow v2.0 alpha 仍不支持 TPU。遗憾的是，DCGAN 不能通过 TPU 训练。</li><li id="477b" class="mv mw iq kt b ku ng kx nh la ni le nj li nk lm nc nd ne nf bi translated">Keras:用于深度学习的 Python 库。</li><li id="d8e8" class="mv mw iq kt b ku ng kx nh la ni le nj li nk lm nc nd ne nf bi translated">数据取自<a class="ae mb" href="https://github.com/Mckinsey666/Anime-Face-Dataset" rel="noopener ugc nofollow" target="_blank">这里</a></li></ol><h1 id="d778" class="md me iq bd mf mg mh mi mj mk ml mm mn jw mo jx mp jz mq ka mr kc ms kd mt mu bi translated">介绍</h1><p id="9d44" class="pw-post-body-paragraph kr ks iq kt b ku mx jr kw kx my ju kz la nl lc ld le nm lg lh li nn lk ll lm ij bi translated">深度学习领域的研究热点之一是生成对抗网络。由<a class="ae mb" href="https://papers.nips.cc/paper/5423-generative-adversarial-nets.pdf" rel="noopener ugc nofollow" target="_blank"> Ian Goodfellow 等人</a>介绍。，它可以在无人监督的情况下从零开始生成东西。在计算机视觉领域。有许多研究人员在研究和改进它。例如，NVIDIA 通过使用 GAN 创建了<a class="ae mb" href="https://medium.com/syncedreview/gan-2-0-nvidias-hyperrealistic-face-generator-e3439d33ebaf" rel="noopener">逼真的人脸生成器。音乐领域也有一些关于</a><a class="ae mb" href="https://magenta.tensorflow.org/research" rel="noopener ugc nofollow" target="_blank">使用甘</a>的研究。我之前的一篇文章展示了如何使用 GAN 来生成音乐。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi no"><img src="../Images/6a63d398d607d395d47688bd53612f84.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*6wU6RkA2Rr_amVnsggCrEA.png"/></div></div><figcaption class="lx ly gj gh gi lz ma bd b be z dk">Image 1 : HoloGAN paper</figcaption></figure><p id="38ae" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">研究人员开发了许多不同类型的氮化镓。最新的一个(在我写这篇文章的时候)是可以从自然图像生成 3D 表示的<a class="ae mb" href="https://arxiv.org/pdf/1904.01326v1.pdf" rel="noopener ugc nofollow" target="_blank"> HoloGAN </a>。如果你看看它是如何做到的，它真的很神奇。实际上，这些高级 GAN 遵循 GAN 工作的基本原理。每个 GAN 都有两个代理作为它的学习器、鉴别器和生成器(我们将在后面深入讨论这些术语)。要了解更多高级 GAN 技术，必须了解基本 GAN 的工作原理。</p><p id="7662" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">本文将重点介绍深度卷积 GAN (DCGAN)的实现，它是拉德福德等人提出的 GAN 的变体之一。基本上就是一个有很多卷积层的 GAN。它是流行的 GAN 神经网络之一。我们将构建一个与他们论文中提出的架构不同的架构。尽管有所不同，但它仍然产生了一些好结果。</p><p id="a75c" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">关于 GAN 的一个有趣的事情是，它将建立它的潜在变量(一个长度为任何长度的一维向量),可以用线性代数运算。<strong class="kt ir">图像 0 </strong>上的例子就是其中之一。第一个面的向量(从左边开始)被添加到第二个面的向量。然后，它产生了第三张脸。</p><p id="2069" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">它还产生了一些有趣数据分布。分布中的每一点都有不同的面。例如，以平均值-0.7 为中心的数据将具有黄色头发的脸。</p><p id="4a06" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">我们将从了解一个关于甘的简要描述开始。</p><h1 id="791b" class="md me iq bd mf mg mh mi mj mk ml mm mn jw mo jx mp jz mq ka mr kc ms kd mt mu bi translated"><strong class="ak">简介</strong>甘</h1><h2 id="51b2" class="np me iq bd mf nq nr dn mj ns nt dp mn la nu nv mp le nw nx mr li ny nz mt oa bi translated">那么，甘是什么呢？</h2><p id="03d5" class="pw-post-body-paragraph kr ks iq kt b ku mx jr kw kx my ju kz la nl lc ld le nm lg lh li nn lk ll lm ij bi translated">更简单地说，这是一种用于从头生成一些新数据的深度学习技术。它以无人监管的方式运行，这意味着它可以在没有人为标记的情况下运行。它会根据学习到的模式生成数据。</p><p id="5fb9" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">甘是一个生成性的模型，他有以下几个方面的特点:</p><ul class=""><li id="22b7" class="mv mw iq kt b ku kv kx ky la ob le oc li od lm oe nd ne nf bi translated">学习联合概率<strong class="kt ir"> P(x，y) </strong>其中<strong class="kt ir"> x </strong>是输入，<strong class="kt ir"> y </strong>是输出。它将基于<strong class="kt ir"> P(x|y) </strong>进行推断，给定输出<strong class="kt ir"> y，</strong>它将推断出<strong class="kt ir"> x. </strong>你可以说<strong class="kt ir"> y </strong>是 GAN 中的真实数据。</li><li id="e25d" class="mv mw iq kt b ku ng kx nh la ni le nj li nk lm oe nd ne nf bi translated">当模型被给予训练真实数据<strong class="kt ir"> y </strong>时，它将学习真实数据的特征。它将通过识别真实数据<strong class="kt ir">潜在特征表示变量</strong>来学习。更简单地说，它学习真实数据中图像的基本构造函数特性。例如，模型可以学习由眼睛和头发的颜色构成的脸。这两个将是产生面的基础之一。通过调整它的变量，它也可以改变生成的面。比如提高眼睛的变量，眼睛会更黑。降低它将产生相反的结果。</li><li id="0cf9" class="mv mw iq kt b ku ng kx nh la ni le nj li nk lm oe nd ne nf bi translated">它可以建立概率分布，例如正态分布，其可以用于避免异常值<strong class="kt ir"/>。由于<strong class="kt ir">异常值</strong>通常在分布中非常罕见，所以生成它的几率将非常小。因此，GAN 在有异常值的真实数据上运行良好。</li></ul><h2 id="17db" class="np me iq bd mf nq nr dn mj ns nt dp mn la nu nv mp le nw nx mr li ny nz mt oa bi translated">那么，它是如何工作的呢？</h2><p id="3ec0" class="pw-post-body-paragraph kr ks iq kt b ku mx jr kw kx my ju kz la nl lc ld le nm lg lh li nn lk ll lm ij bi translated">GAN 组成两个神经网络，<strong class="kt ir">鉴别器</strong>和<strong class="kt ir">发生器</strong>。甘将使这两个网络在一个零和博弈框架(博弈论)上相互争斗。这是这些代理(网络)之间的游戏。《甘》中的<strong class="kt ir">反</strong>名就来源于这个概念。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi of"><img src="../Images/d7f3c46cbd740b182db4ad7c2cc9386c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1278/format:webp/1*aaP0cSWKyX_bZukKw5QApg.png"/></div><figcaption class="lx ly gj gh gi lz ma bd b be z dk">Image 2 : Illustration of Discriminator vs Generator . Image modified and taken from <a class="ae mb" href="https://yugioh.fandom.com/wiki/Yu-Gi-Oh!_-_Episode_129" rel="noopener ugc nofollow" target="_blank">here</a></figcaption></figure><p id="ad0a" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated"><strong class="kt ir">发生器</strong>将产生一些假数据，而<strong class="kt ir">鉴别器</strong>将识别出几个数据，这些数据包含由<strong class="kt ir">发生器</strong>产生的假数据和从真实数据中采样的数据。<strong class="kt ir">发生器</strong>的目的主要是产生一些与真实数据相似的虚假数据，并欺骗<strong class="kt ir">鉴别器</strong>识别哪些数据是真实的，哪些是虚假的。<strong class="kt ir">鉴别器</strong>的目的是让它更智能地识别真假数据。每个代理将交替移动。通过与这些代理决斗，我们希望这些代理会变得更强，尤其是<strong class="kt ir">发电机。</strong></p><blockquote class="og oh oi"><p id="3a6c" class="kr ks oj kt b ku kv jr kw kx ky ju kz ok lb lc ld ol lf lg lh om lj lk ll lm ij bi translated">你可以说他们是命中注定的对手。主角是<strong class="kt ir">发电机，它通过从对手的战斗中学习，力求更好地实现我们的目标。</strong></p></blockquote><p id="2682" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">好的，换句话说，<strong class="kt ir">发生器</strong>将通过对学习到的分布进行采样来模拟真实数据，并打算与真实数据相同的分布。它会训练自己的神经网络来生成它。鉴于此，<strong class="kt ir">鉴别器</strong>将在监督技术中训练其神经网络来检测虚假和真实数据。每个网络将交替训练其网络。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi on"><img src="../Images/d7933bae7efd01e358192b05f38af571.png" data-original-src="https://miro.medium.com/v2/resize:fit:1370/format:webp/1*15QzlRAF4xSdAnw5ANR1gA.png"/></div></div><figcaption class="lx ly gj gh gi lz ma bd b be z dk">Image 3 : Illustration GAN on learning data distribution. Picture taken from <a class="ae mb" href="https://www.slideshare.net/thinkingfactory/variants-of-gans-jaejun-yoo" rel="noopener ugc nofollow" target="_blank">here</a>.</figcaption></figure><p id="b74c" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">以下是 GAN 工作原理的大致步骤:</p><ol class=""><li id="87ee" class="mv mw iq kt b ku kv kx ky la ob le oc li od lm nc nd ne nf bi translated">以概率分布如正态分布产生随机噪声。</li><li id="a507" class="mv mw iq kt b ku ng kx nh la ni le nj li nk lm nc nd ne nf bi translated">将其作为发电机神经网络的输入。它将输出生成的<strong class="kt ir"> <em class="oj">假数据</em> </strong>。这些步骤也意味着我们从生成器学习的分布中抽取一些数据。我们将噪声记为<code class="fe oo op oq or b"><strong class="kt ir">z_n</strong></code>，生成的数据记为<code class="fe oo op oq or b"><strong class="kt ir">G(z_n</strong>)</code>。<code class="fe oo op oq or b"><strong class="kt ir">G(z_n)</strong></code>指发电机<strong class="kt ir"> G </strong>处理噪声的结果。</li><li id="fa56" class="mv mw iq kt b ku ng kx nh la ni le nj li nk lm nc nd ne nf bi translated">我们将生成的假数据与从数据集采样的数据(真实数据)结合起来。使它们成为我们的<strong class="kt ir">鉴别器的输入。我们将其记为 D. </strong>鉴别器将通过预测数据是否为假来尝试学习。通过前向传递和后向传播来训练神经网络。更新<strong class="kt ir"> D </strong>权重。</li><li id="3649" class="mv mw iq kt b ku ng kx nh la ni le nj li nk lm nc nd ne nf bi translated">然后，我们需要训练<strong class="kt ir">发电机</strong>。我们需要将<code class="fe oo op oq or b"><strong class="kt ir">G(z_n)</strong></code>或者随机噪声产生的伪数据作为<strong class="kt ir"> D 的输入</strong>注意，这个步骤只是将伪数据输入到<strong class="kt ir">鉴别器</strong>中。正向传递<strong class="kt ir">【d】</strong>中的<strong class="kt ir"> </strong> <code class="fe oo op oq or b"><strong class="kt ir">G(z_n)</strong></code> <strong class="kt ir"> </strong>通过使用鉴别器神经网络，在做正向传递时，预测假数据是否为假数据<code class="fe oo op oq or b"><strong class="kt ir">(D(G(z_n)))</strong></code>。然后进行反向传播，我们将只更新<strong class="kt ir"> G </strong>权重。</li><li id="cefd" class="mv mw iq kt b ku ng kx nh la ni le nj li nk lm nc nd ne nf bi translated">重复这些步骤，直到我们可以看到生成器提供良好的伪数据或者已经达到最大迭代。</li></ol><p id="af3d" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">图示如下:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi os"><img src="../Images/f230fd9a06a1e0a5a3964da080ba4653.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*vcQmX9LqQAUf9YOVc3IXvw.png"/></div></div><figcaption class="lx ly gj gh gi lz ma bd b be z dk">Image 4 : How GAN Works. Picture taken from <a class="ae mb" href="http://Image 3 : Illustration GAN on learning data distribution. Picture taken from here." rel="noopener ugc nofollow" target="_blank">here</a>.</figcaption></figure><p id="d38b" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">通过更新生成器的分布来匹配鉴别器。这和最小化 JS 散度是一样的。要了解更多信息，您可以阅读<a class="ae mb" href="https://lilianweng.github.io/lil-log/2017/08/20/from-GAN-to-WGAN.html" rel="noopener ugc nofollow" target="_blank">这篇</a>文章。</p><p id="4407" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">为了让我们的代理学习，一定要让<strong class="kt ir">鉴别器</strong>和<strong class="kt ir">发生器</strong>互相支配。使它们尽可能平衡，并使<strong class="kt ir">鉴别器</strong>和<strong class="kt ir">发生器</strong>同时学习。当<strong class="kt ir">鉴别器</strong>太强(能 100%区分真假)时，<strong class="kt ir">发生器</strong>变得什么也学不会。如果在训练过程中我们达到这一点，最好结束它。在<strong class="kt ir">发生器</strong>比鉴别器强的情况下，相反的情况也有影响。它会导致模式崩溃，我们的模型对任何随机噪声都会预测相同的结果。这是 GAN 中最难和最难的部分之一，它会让人感到沮丧。</p><p id="e8b7" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">如果你想了解更多，我建议看一看这篇很棒的<a class="ae mb" href="https://medium.com/@jonathan_hui/gan-dcgan-deep-convolutional-generative-adversarial-networks-df855c438f" rel="noopener">文章</a>。</p><h1 id="5962" class="md me iq bd mf mg mh mi mj mk ml mm mn jw mo jx mp jz mq ka mr kc ms kd mt mu bi translated">履行</h1><h2 id="e5ad" class="np me iq bd mf nq nr dn mj ns nt dp mn la nu nv mp le nw nx mr li ny nz mt oa bi translated">那么，鉴别器和生成器的架构如何呢？</h2><p id="de3f" class="pw-post-body-paragraph kr ks iq kt b ku mx jr kw kx my ju kz la nl lc ld le nm lg lh li nn lk ll lm ij bi translated">这取决于我们将开发的 GAN 的变体。由于我们将使用 DCGAN，我们将使用一系列的 CNN 层。</p><p id="ed5e" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">我们将使用不同于原始论文的自定义架构。我沿用了《用 Python 进行深度学习》一书中使用的架构<em class="oj"/><a class="ae mb" href="https://www.amazon.com/Deep-Learning-Python-Francois-Chollet/dp/1617294438" rel="noopener ugc nofollow" target="_blank"/><em class="oj">。</em></p><p id="9baa" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">我们用于构建 DCGAN 的配置如下:</p><pre class="kg kh ki kj gt ot or ou ov aw ow bi"><span id="1d68" class="np me iq or b gy ox oy l oz pa">latent_dim = 64<br/>height = 64<br/>width = 64<br/>channels = 3</span></pre><p id="3be2" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">这意味着我们将有一个 64 维的潜在变量。我们的图像的高度和宽度是 64。每个图像有 3 个通道(R，G，B)</p><p id="7660" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">以下是导入的库以及如何准备数据:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="pb pc l"/></div></figure><p id="9b15" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">这里是架构:</p><h2 id="677a" class="np me iq bd mf nq nr dn mj ns nt dp mn la nu nv mp le nw nx mr li ny nz mt oa bi translated"><strong class="ak">发电机</strong></h2><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi pd"><img src="../Images/ac6911f7b2cee070979c7db1bb63cd69.png" data-original-src="https://miro.medium.com/v2/resize:fit:1198/format:webp/1*GgkMwiFL_h1CukJnaraCXw.png"/></div></figure><p id="deac" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">它由卷积层组成，其中一层是卷积转置层。为了增加图像<code class="fe oo op oq or b">(32 -&gt; 62)</code>的大小，我们将在卷积层中使用步长参数。这样做是为了避免 GAN 的不稳定训练。</p><p id="f642" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated"><strong class="kt ir">代码</strong></p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="pb pc l"/></div></figure><h2 id="adc5" class="np me iq bd mf nq nr dn mj ns nt dp mn la nu nv mp le nw nx mr li ny nz mt oa bi translated"><strong class="ak">鉴别器</strong></h2><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi pe"><img src="../Images/6049ae7b00823412a6a29b8df7cdb8c6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1022/format:webp/1*d-hE60aCl6oj4us8GR8ucw.png"/></div></figure><p id="0076" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">它还由卷积层组成，我们使用步长进行缩减采样。</p><p id="c13b" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated"><strong class="kt ir">代码</strong></p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="pb pc l"/></div></figure><h2 id="8c3a" class="np me iq bd mf nq nr dn mj ns nt dp mn la nu nv mp le nw nx mr li ny nz mt oa bi translated">开始</h2><p id="efa0" class="pw-post-body-paragraph kr ks iq kt b ku mx jr kw kx my ju kz la nl lc ld le nm lg lh li nn lk ll lm ij bi translated">为了使生成器的反向传播成为可能，我们在 Keras 中创建新的网络，它是<strong class="kt ir">生成器</strong>后跟<strong class="kt ir">鉴别器。在这个网络中，我们冻结了所有的权重，这样它的权重就不会改变。</strong></p><p id="98e4" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated"><strong class="kt ir">这是网络:</strong></p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi pf"><img src="../Images/1eb66ff9442d891c4319bd06a9caeec4.png" data-original-src="https://miro.medium.com/v2/resize:fit:790/format:webp/1*KeBfpw_YPydLEG0Dn4Uo2w.png"/></div></figure><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="pb pc l"/></div></figure><h1 id="2c77" class="md me iq bd mf mg mh mi mj mk ml mm mn jw mo jx mp jz mq ka mr kc ms kd mt mu bi translated">培养</h1><p id="4531" class="pw-post-body-paragraph kr ks iq kt b ku mx jr kw kx my ju kz la nl lc ld le nm lg lh li nn lk ll lm ij bi translated">培训的配置如下:</p><pre class="kg kh ki kj gt ot or ou ov aw ow bi"><span id="2e69" class="np me iq or b gy ox oy l oz pa">iterations = 15000 <br/>batch_size = 32</span></pre><p id="d201" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">该配置意味着我们将进行 15000 次迭代。每次迭代我们处理 32 批真实数据和虚假数据(总共 64 批用于训练鉴别器)。</p><p id="263f" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">按照我上面解释的粗略步骤，下面是我们如何一步一步地训练 DCGAN:</p><ol class=""><li id="b8c8" class="mv mw iq kt b ku kv kx ky la ob le oc li od lm nc nd ne nf bi translated"><strong class="kt ir">重复以下步骤直到最大迭代次数</strong></li></ol><pre class="kg kh ki kj gt ot or ou ov aw ow bi"><span id="60e0" class="np me iq or b gy ox oy l oz pa">for step in tqdm_notebook(range(iterations)):</span></pre><p id="795c" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated"><strong class="kt ir"> 2。以概率分布如正态分布产生随机噪声。</strong></p><pre class="kg kh ki kj gt ot or ou ov aw ow bi"><span id="7824" class="np me iq or b gy ox oy l oz pa">random_latent_vectors = np.random.normal(size = (batch_size, latent_dim))<br/>generated_images = generator.predict(random_latent_vectors)</span></pre><p id="d0a7" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated"><strong class="kt ir"> 3。将生成的假数据与从数据集中采样的数据结合起来。</strong></p><pre class="kg kh ki kj gt ot or ou ov aw ow bi"><span id="e831" class="np me iq or b gy ox oy l oz pa">stop = start + batch_size<br/>real_images = x_train[start: stop]<br/>combined_images = np.concatenate([generated_images, real_images])<br/>labels = np.concatenate([np.ones((batch_size,1)), <br/>                                    np.zeros((batch_size, 1))])</span></pre><p id="39ab" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">请注意，我们使用顺序采样器，每个数据将被顺序采样，直到数据结束。将被抽样的数量等于批量大小。</p><p id="164d" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated"><strong class="kt ir"> 4。向输入标签添加噪声</strong></p><pre class="kg kh ki kj gt ot or ou ov aw ow bi"><span id="a3e4" class="np me iq or b gy ox oy l oz pa">labels += 0.05 * np.random.random(labels.shape)</span></pre><p id="aad2" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">这是训练甘的重要一招。</p><p id="2987" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated"><strong class="kt ir"> 5。训练鉴别器</strong></p><pre class="kg kh ki kj gt ot or ou ov aw ow bi"><span id="5fa2" class="np me iq or b gy ox oy l oz pa">d_loss = discriminator.train_on_batch(combined_images, labels)</span></pre><p id="f1ef" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated"><strong class="kt ir"> 6。训练发电机</strong></p><pre class="kg kh ki kj gt ot or ou ov aw ow bi"><span id="d450" class="np me iq or b gy ox oy l oz pa">random_latent_vectors = np.random.normal(size=(batch_size, <br/>                                                 latent_dim))<br/>misleading_targets = np.zeros((batch_size, 1))<br/>a_loss = gan.train_on_batch(random_latent_vectors, <br/>                              misleading_targets)</span></pre><p id="e29f" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">注意，我们创建了一个新的潜在向量。别忘了我们需要交换标签。请记住，我们要尽量减少因鉴别者未能预测到假货而造成的损失。<code class="fe oo op oq or b">misleading_targets</code>的标签应该是 1。</p><p id="2321" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated"><strong class="kt ir"> 7。更新真实数据集的起始索引</strong></p><pre class="kg kh ki kj gt ot or ou ov aw ow bi"><span id="f5c1" class="np me iq or b gy ox oy l oz pa">start += batch_size<br/>  <br/>  if start &gt; len(x_train) - batch_size:<br/>    start = 0</span></pre><p id="b086" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">就这样，下面是训练 DCGAN 的完整代码:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="pb pc l"/></div></figure><h1 id="0df9" class="md me iq bd mf mg mh mi mj mk ml mm mn jw mo jx mp jz mq ka mr kc ms kd mt mu bi translated">结果</h1><p id="c8ce" class="pw-post-body-paragraph kr ks iq kt b ku mx jr kw kx my ju kz la nl lc ld le nm lg lh li nn lk ll lm ij bi translated">好了，好戏开始了！我们将开始在不同的平均点上可视化生成的图像。在我们这样做之前，让我告诉你，这是上述模型的结果，该模型训练了 20000 步(迭代)和 30000 步。该模型被训练大约 7 小时(大约每小时 4300 步)。我将较少步骤的模型命名为<strong class="kt ir">模型-A </strong>，另一个命名为<strong class="kt ir">模型-B </strong>。</p><p id="2a05" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">开始了。</p><blockquote class="og oh oi"><p id="49a3" class="kr ks oj kt b ku kv jr kw kx ky ju kz ok lb lc ld ol lf lg lh om lj lk ll lm ij bi translated"><strong class="kt ir">如何阅读</strong></p><p id="f44e" class="kr ks oj kt b ku kv jr kw kx ky ju kz ok lb lc ld ol lf lg lh om lj lk ll lm ij bi translated"><strong class="kt ir"> N ~ (x，y) </strong>:遵循正态分布随机生成的潜在向量，具有均值<strong class="kt ir"> x </strong>和标准差<strong class="kt ir"> y </strong></p></blockquote><p id="7879" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated"><strong class="kt ir">模型-A </strong>上<strong class="kt ir"> N ~ (0，0.4) </strong>的潜在向量结果:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi pg"><img src="../Images/ee43d98f4d72efa9139554a285a1f65c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1202/format:webp/1*KfG5y9EHFedrdDHjCkXf7Q.png"/></div><figcaption class="lx ly gj gh gi lz ma bd b be z dk">Image 5 : Generated Face Model-A N ~ (0, 0.4)</figcaption></figure><p id="379b" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">不错吧，虽然有一些照片中的人有不对称的脸。</p><p id="2efb" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated"><strong class="kt ir">模型-A </strong>上<strong class="kt ir"> N ~ (0，1) </strong>的潜在向量结果:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi ph"><img src="../Images/b7e47e7eb6c3ff67da05f6236e51ea20.png" data-original-src="https://miro.medium.com/v2/resize:fit:1216/format:webp/1*0rD_eQtxl2W0Gq80nH0j5A.png"/></div><figcaption class="lx ly gj gh gi lz ma bd b be z dk">Image 6 : Generated Face Model-A N ~ (0, 1)</figcaption></figure><p id="6404" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">看看它..这个模型产生了一些令人厌恶的面孔。事实证明，这个模型并没有真正掌握真实数据的分布。当标准差较低时，它可以做得更好。我训练的 DCGAN 还没有掌握如何表示不太接近均值点的数据点。我认为，它需要更多的训练或更强大的架构。</p><p id="f425" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">让我们将架构更改为<strong class="kt ir">模型-B </strong></p><p id="0155" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated"><strong class="kt ir">模型 B: </strong>上<strong class="kt ir"> N ~ (0，0.4) </strong>的潜在向量结果</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi pd"><img src="../Images/d34bfe82e516209cd573bebacf8c3960.png" data-original-src="https://miro.medium.com/v2/resize:fit:1198/format:webp/1*nvNm4689qSswy4lORnnmZA.png"/></div><figcaption class="lx ly gj gh gi lz ma bd b be z dk">Image 7 : Generated Face Model-B N ~ (0, 0.4)</figcaption></figure><p id="e91f" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">还好，但是脸变得更黑了。我想知道发电机怎么了。</p><p id="a023" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">在<strong class="kt ir">模型-B </strong>上的<strong class="kt ir"> N ~ (0，1) </strong>上的潜在向量结果:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi pi"><img src="../Images/69dd414c268f95d0a615a01b817c2df0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1206/format:webp/1*rROMSJfQeFUdh_Gom5H0-Q.png"/></div><figcaption class="lx ly gj gh gi lz ma bd b be z dk">Image 8 : Generated Face Model-A N ~ (0, 1)</figcaption></figure><p id="0901" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">嗯，好吧..其中大部分仍然包含着<strong class="kt ir">可憎的</strong>面孔。他们中的一些人表情很好。质量还是和 a 型差不多。好的..对于下一批图像，让我们尽可能地改变标准偏差。0.4 最好。</p><p id="7452" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">让我们检查一下，我们的潜在向量是否是使用相同的标准偏差，以-0.3 和 0.3 为中心平均值生成的。</p><p id="2778" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated"><strong class="kt ir">模型-A </strong>上<strong class="kt ir"> N ~ (-0.3，0.4) </strong>的潜在向量结果:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi pj"><img src="../Images/e07e9d8c7a509ffdb784ec1928ccc568.png" data-original-src="https://miro.medium.com/v2/resize:fit:1186/format:webp/1*5sEqCyjcNdEy8Y4V-fvH2w.png"/></div><figcaption class="lx ly gj gh gi lz ma bd b be z dk">Image 9 : Generated Face Model-A N ~ (0.3, 0.4)</figcaption></figure><p id="3420" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated"><strong class="kt ir">模型-A </strong>上<strong class="kt ir"> N ~ (0.3，0.4) </strong>的潜在向量结果:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi pk"><img src="../Images/d1b955ecec259538267b9186d7e52572.png" data-original-src="https://miro.medium.com/v2/resize:fit:1240/format:webp/1*sDa84r2EEPoD7onUGESE0w.png"/></div><figcaption class="lx ly gj gh gi lz ma bd b be z dk">Image 10: Generated Face Model-A N ~ (-0.3, 0.4)</figcaption></figure><p id="89f6" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated"><strong class="kt ir">B 型</strong>上<strong class="kt ir"> N ~ (-0.3，0.4) </strong>的潜在向量结果:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi pl"><img src="../Images/e3f6353c911557b54662b372f392acb3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1222/format:webp/1*tjdjU5Xpl22ysMK_neDNFQ.png"/></div><figcaption class="lx ly gj gh gi lz ma bd b be z dk">Image 11: Generated Face Model-B N ~ (-0.3, 0.4)</figcaption></figure><p id="53ec" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">在<strong class="kt ir"> Model-B </strong>上<strong class="kt ir"> N ~ (0.3，0.4) </strong>上的潜在向量结果:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi pm"><img src="../Images/22b8f55850d58537410038f7489ed33b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1234/format:webp/1*zatCDzE7RJWqgSs7GKOyYA.png"/></div><figcaption class="lx ly gj gh gi lz ma bd b be z dk">Image 12: Generated Face Model-B N ~ (0.3, 0.4)</figcaption></figure><p id="44b4" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated"><strong class="kt ir">看出区别了吗？</strong></p><p id="dbb6" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">是的，看他们的头发。平均值为 0.3 时，头发大部分是黑色的(其中一些是棕色的)。相反，在平均值为-0.3 时，毛发大多是黄色的。是的，我们的模型可以把脸放在相应的点上。模型 B 也生成比 a 更暗的面。</p><p id="b487" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">从上面我们所做的，我们可以直观地了解我们的模型是如何学习数据分布的。</p><p id="4050" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">让我们绘制它:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi pn"><img src="../Images/c44872dc46c192c55cfbbb8e68992ccf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*v7ki0B8YkA963J7ieBkcjQ.png"/></div></div><figcaption class="lx ly gj gh gi lz ma bd b be z dk">Image 13: Data distribution of the generator</figcaption></figure><p id="48f5" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">从上面显示的结果来看，我认为潜在向量越小，脸的头发越亮，潜在向量越大，脸的头发越红。</p><p id="709d" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">为了确定这一点，让我们来看看每个平均点中的平均面:</p><p id="8ea6" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">我们画出这些潜在向量，它们的平均值是:</p><pre class="kg kh ki kj gt ot or ou ov aw ow bi"><span id="4514" class="np me iq or b gy ox oy l oz pa">[-1, -0.8, -0.6, -0.4, -0.2, 0, 0.2 0.4, 0.6, 0.8 ]</span></pre><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="pb pc l"/></div></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi po"><img src="../Images/bd984fbb150dad71f58af1d7201fcba1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*0jHOtFK3EX3ARZvpPzNClg.png"/></div></div><figcaption class="lx ly gj gh gi lz ma bd b be z dk">Image 14: Average faces from different mean points</figcaption></figure><p id="2e20" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">第一行是模型 A，第二行是模型 b。通过处理潜在向量的平均值，我们可以看到它在该点生成的脸。我们可以看到:</p><ul class=""><li id="f3c1" class="mv mw iq kt b ku kv kx ky la ob le oc li od lm oe nd ne nf bi translated">向量的点越低，头发越黄。</li><li id="32d7" class="mv mw iq kt b ku ng kx nh la ni le nj li nk lm oe nd ne nf bi translated">它的脸中间比较黑。这意味着数据集中的平均人脸具有这些风格。</li><li id="186b" class="mv mw iq kt b ku ng kx nh la ni le nj li nk lm oe nd ne nf bi translated">向量的点越正，头发越蓝。正面潜在向量在微笑上也有更多的开口。</li></ul><h2 id="ed30" class="np me iq bd mf nq nr dn mj ns nt dp mn la nu nv mp le nw nx mr li ny nz mt oa bi translated">基本线性代数运算</h2><p id="e37e" class="pw-post-body-paragraph kr ks iq kt b ku mx jr kw kx my ju kz la nl lc ld le nm lg lh li nn lk ll lm ij bi translated">很神奇吧？</p><p id="1e68" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">还没有，我们可以对潜向量做线性代数运算。方程的结果也可以生成，并有有趣的结果。在介绍部分之前，从我们的第一张面孔中提取一个结果:</p><p id="1def" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated"><strong class="kt ir"> G + D </strong></p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi mc"><img src="../Images/200b395e65ba9665b7c4003effb2fe75.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*h5wxkHfbNfwQG1cTR4NO0g.png"/></div></div><figcaption class="lx ly gj gh gi lz ma bd b be z dk">Images 15 : G + D = GAN</figcaption></figure><p id="e689" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">甘脸是 G 和 d 相加的结果。你可以看到头发变得有点棕色。右边的头发是 D 型，左边的是 G 型。</p><p id="58f5" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">以下是其他人操作的结果:</p><p id="57a0" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated"><strong class="kt ir"> G — D(绝对)</strong></p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi pp"><img src="../Images/5f199ae3521c3ef26fae8cd780c0958e.png" data-original-src="https://miro.medium.com/v2/resize:fit:380/format:webp/1*dYCMTsordy2H0S9Xw0eAVg.png"/></div><figcaption class="lx ly gj gh gi lz ma bd b be z dk">Images 16 : G-D</figcaption></figure><p id="fdea" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated"><strong class="kt ir">按分量相乘(G，D) </strong></p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi pp"><img src="../Images/a2886905bd9fddffb47a734d41a8fe85.png" data-original-src="https://miro.medium.com/v2/resize:fit:380/format:webp/1*6NysKHDNv6UT14XJmsmE7g.png"/></div><figcaption class="lx ly gj gh gi lz ma bd b be z dk">Images 17 :<strong class="bd pq"> </strong>Component-Wise multiplied (G, D)</figcaption></figure><h2 id="2a4e" class="np me iq bd mf nq nr dn mj ns nt dp mn la nu nv mp le nw nx mr li ny nz mt oa bi translated">操纵潜在向量</h2><p id="1446" class="pw-post-body-paragraph kr ks iq kt b ku mx jr kw kx my ju kz la nl lc ld le nm lg lh li nn lk ll lm ij bi translated">如果我们在潜向量中操作一个维度，我们将会看到生成的图像是怎样的。正如我前面所说，模型将学习潜在的特征表示。所以，潜在向量中的每一个元素都有生成图像的目的。</p><p id="04f8" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">为了进行可视化，我们将冻结 vectors 中的所有元素，并更改要检查的所选维度。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi pr"><img src="../Images/eae11faf01b1e3377daf663bfaaab45d.png" data-original-src="https://miro.medium.com/v2/resize:fit:992/format:webp/1*ck2n-F38r_RsogsEXPf7iQ.png"/></div><figcaption class="lx ly gj gh gi lz ma bd b be z dk">Images 18 : Illustration on what we do in this section</figcaption></figure><p id="0b6e" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">例如，我们想要检查潜在向量中的第一个元素，我们改变该维度并保持其他维度不变。</p><p id="226a" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">我们将生成一些具有以下意义的面:</p><pre class="kg kh ki kj gt ot or ou ov aw ow bi"><span id="e86f" class="np me iq or b gy ox oy l oz pa">[-0.6, -0.3, 0.1, 0.3, 0.6]</span></pre><p id="ba56" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">对于每个平均点，我们将生成其潜在向量中的维度随着这些值迭代地改变的面:</p><pre class="kg kh ki kj gt ot or ou ov aw ow bi"><span id="9ce1" class="np me iq or b gy ox oy l oz pa">[-1.08031934, -0.69714143, -0.39691713, -0.12927146,  0.12927146, 0.39691713,  0.69714143,  1.08031934]</span></pre><p id="d4a9" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">让我们在选择的维度上可视化: (本节将只使用模型-A)</p><p id="2850" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated"><strong class="kt ir">第 28 次元</strong>:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi ps"><img src="../Images/12fb90dc7b7531217608bb6253e6d0c3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1244/format:webp/1*IB5aY8G6Mz_HyPhKKaUqCg.png"/></div><figcaption class="lx ly gj gh gi lz ma bd b be z dk">Image 19 : Result on Changing 28th latent variable in different mean points.</figcaption></figure><p id="e2a9" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">第 28 个潜变量的目的是什么？</p><p id="5f46" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">我认为，它使头发变得更亮，改变左眼的形状，也改变右眼的小变化。由于它将特征压缩成 64 长度的潜在向量，一个维度可以有多种用途。</p><p id="0a01" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">让我们看另一个！</p><p id="9c74" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated"><strong class="kt ir">第五维度</strong></p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi pt"><img src="../Images/21b426d16618faf85ab8926b86fe8da0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1190/format:webp/1*vLQBj54qZLNXZ-Aqmd6fvQ.png"/></div><figcaption class="lx ly gj gh gi lz ma bd b be z dk">Image 20 : Result on changing 5th latent variables in different means</figcaption></figure><p id="2b29" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">这个潜在变量的目的是什么？</p><p id="37f8" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">我认为这与左眼有关，尽管每个穴位对左眼的治疗不同。它也使头发颜色变深。你怎么想呢?</p><p id="0dba" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated"><strong class="kt ir">第 11 维</strong></p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi pu"><img src="../Images/3adac32656bee9222a39f87057528cde.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*1wEBfNOXaAb9cQlBX525yg.png"/></div></div><figcaption class="lx ly gj gh gi lz ma bd b be z dk">Image 21 : Result on changing the 11th latent variables in different means</figcaption></figure><p id="ebd4" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">我想，这个维度关心的是嘴巴和右眼。</p><p id="3464" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">另一个例子是通过调整一个潜在变量从一个平均点生成的面:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi pv"><img src="../Images/67597a35ad3f834dc1703f60635b2176.png" data-original-src="https://miro.medium.com/v2/resize:fit:978/format:webp/1*kye2MH1rixL_aEL_xm4ZrQ.png"/></div><figcaption class="lx ly gj gh gi lz ma bd b be z dk">Image 22 : Result on faces by changing a latent variable</figcaption></figure><p id="2428" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">就是这样。我们可以画出潜在向量的任何维度，看看它的目的是什么。尽管有时很难看出潜在变量的目的是什么。</p><h2 id="62cb" class="np me iq bd mf nq nr dn mj ns nt dp mn la nu nv mp le nw nx mr li ny nz mt oa bi translated">与真实数据比较</h2><p id="f78d" class="pw-post-body-paragraph kr ks iq kt b ku mx jr kw kx my ju kz la nl lc ld le nm lg lh li nn lk ll lm ij bi translated">让我们从数据集中抽取 8 个真实的人脸样本:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi pw"><img src="../Images/da70e2e335422c09e64a85b13cd90a74.png" data-original-src="https://miro.medium.com/v2/resize:fit:974/format:webp/1*SRxaJlDs0Fi5jffPXozpAQ.png"/></div><figcaption class="lx ly gj gh gi lz ma bd b be z dk">Image 22 : Real Faces from dataset</figcaption></figure><p id="d573" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">型号 A 和 B 的发电机<code class="fe oo op oq or b"> N ~ (0,1)</code>的样本 8:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi px"><img src="../Images/8e121d675063b6becaa3b832777799fc.png" data-original-src="https://miro.medium.com/v2/resize:fit:396/format:webp/1*zei9SGLRMUIWgEcvoG7CAQ.png"/></div></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi py"><img src="../Images/524793702be8189fc0d26c1b9fd06db3.png" data-original-src="https://miro.medium.com/v2/resize:fit:408/format:webp/1*TjYzsBCwhzQ6qu1geDeP5w.png"/></div><figcaption class="lx ly gj gh gi lz ma bd b be z dk">Image 23 : Fake faces generated by generator</figcaption></figure><p id="1e21" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">那么，如果我们充当鉴别者，我们能区分真脸和假脸吗？</p><p id="56fb" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">毫无疑问，我们仍然可以区分哪些面孔是假的，哪些是真的。这种模式需要更多训练或强大的架构来实现。即便如此，我们的模型仍然可以生成动漫风格的人脸形状，这很棒。</p><h1 id="284c" class="md me iq bd mf mg mh mi mj mk ml mm mn jw mo jx mp jz mq ka mr kc ms kd mt mu bi translated">吸取的教训</h1><p id="9245" class="pw-post-body-paragraph kr ks iq kt b ku mx jr kw kx my ju kz la nl lc ld le nm lg lh li nn lk ll lm ij bi translated">以下是我研究 DCGAN 后学到的经验:</p><ul class=""><li id="0a33" class="mv mw iq kt b ku kv kx ky la ob le oc li od lm oe nd ne nf bi translated">训练甘很难。如果没有经验者的提示和技巧，很难做出一个稳定的架构。尤其是在平衡鉴频器和发生器的功率方面。使 GAN 不崩溃也是一个挑战。</li></ul><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi pz"><img src="../Images/157f23992513463d3159d66d3e72c764.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*F4M36wJfRuWnPYC7"/></div></div><figcaption class="lx ly gj gh gi lz ma bd b be z dk">Photo by <a class="ae mb" href="https://unsplash.com/@pablomerchanm?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Pablo Merchán Montes</a> on <a class="ae mb" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><ul class=""><li id="2c41" class="mv mw iq kt b ku kv kx ky la ob le oc li od lm oe nd ne nf bi translated">实际上，这些模型仍然不擅长生成假图像。然而，它可以建立一些好的面孔，虽然没有真正的好。我们仍然可以区分假图像和真实图像。这是因为模型还没有掌握真实数据的数据分布。</li><li id="4685" class="mv mw iq kt b ku ng kx nh la ni le nj li nk lm oe nd ne nf bi translated">该模型在 26000 步左右降低其质量。在我的实验中，这是发电机变弱的地方。这是 GAN 中的不稳定性。我需要寻找一个更好的架构来做这件事。我们可以看到模型 B 上的结果变得更暗。</li><li id="51a9" class="mv mw iq kt b ku ng kx nh la ni le nj li nk lm oe nd ne nf bi translated">因此，我开发了另一个具有批处理规范化甚至是丢弃层的架构。你猜怎么着？在调整架构的过程中，我有两个结果。模型崩溃和鉴别器优势。我猜开发 GAN 架构并不容易。</li><li id="b9c6" class="mv mw iq kt b ku ng kx nh la ni le nj li nk lm oe nd ne nf bi translated">然而，有许多关于开发一个好的 GAN 的提示和技巧我还没有实现。也许遵循这些提示可以减少模型的不稳定性。</li><li id="a377" class="mv mw iq kt b ku ng kx nh la ni le nj li nk lm oe nd ne nf bi translated">有许多更稳定 GAN 变体，例如 WGAN-DC 和 DRAGAN，以及 SAGAN。我需要使用可能比 DCGAN 做得更好的不同架构。</li></ul><h1 id="f535" class="md me iq bd mf mg mh mi mj mk ml mm mn jw mo jx mp jz mq ka mr kc ms kd mt mu bi translated">结论</h1><p id="0ab5" class="pw-post-body-paragraph kr ks iq kt b ku mx jr kw kx my ju kz la nl lc ld le nm lg lh li nn lk ll lm ij bi translated">这篇文章告诉了我们甘在做什么，并一步一步地告诉我们如何去做。之后，它告诉我们一个有趣的特征，它的潜在向量显示了数据分布的发电机学习。它向我们展示了它可以形成一个数据分布。</p><p id="077b" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">潜在向量可以进行线性代数运算。它可以向我们展示一些有趣的事情，例如两个潜在向量的相加将组合这些面孔中每一个的特征。它还可以被操纵以基于潜在向量中的改变的元素来改变面部。</p><p id="fef8" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">即便如此，我们的模型仍然无法做出一张能让我们怀疑那张脸是不是假的脸。它仍然可以形成一个动漫风格的面孔。</p><h1 id="4b9f" class="md me iq bd mf mg mh mi mj mk ml mm mn jw mo jx mp jz mq ka mr kc ms kd mt mu bi translated">编后记</h1><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi qa"><img src="../Images/7f2e593a78b2c2e529132cafc157fe35.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*37vP2Orv8aasZcPM"/></div></div><figcaption class="lx ly gj gh gi lz ma bd b be z dk">Photo by <a class="ae mb" href="https://unsplash.com/@lemuelbutler?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Lemuel Butler</a> on <a class="ae mb" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><p id="52b9" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">就是这样，我第一次做 GAN 的经验。我越来越了解甘在做什么。我也想探究一下我对甘到底学到了什么的好奇心。它们就在那里，它实际上做的事情真的很神奇。生成器可以将正常随机噪声生成的随机向量映射到数据分布中。它将人脸聚集成指定的数据点。</p><p id="f95d" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">在做甘，我实际上运行几个模型，我手工制作的。好吧，他们悲惨地失败了。有一次，我认为模型可以成功，但它进入模式崩溃(预测的脸将是相同的，不管潜在向量)。我找到了关于 DCGAN 的<em class="oj"> fchollet </em>存储库，并遵循了它的架构。</p><p id="4f27" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">由于这是我第一次设计 GAN，我希望每个人都对此有很多反馈。请指出我犯的错误，因为这是我第一次做。如果结果没那么好请见谅。我只想分享我做甘的兴奋。并分享如何做到。</p><p id="8481" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">即便如此，这真的很有趣，我想尝试另一种 GAN 变体，如 WGAN-GP、DRAGAN 或 SAGAN。我只是略读了一点，并想尝试一下。期待一篇做这些实验的文章😃。</p><p id="3545" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">这个迷因实际上描绘了这个实验😆。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi qb"><img src="../Images/3604dff5368d1ed12667b96ef116fb45.png" data-original-src="https://miro.medium.com/v2/resize:fit:1386/format:webp/1*R6uFWqh6Y1iSmg1E-de-sg.png"/></div><figcaption class="lx ly gj gh gi lz ma bd b be z dk">Images 24 : Image taken from <a class="ae mb" href="https://www.instagram.com/neuralnetmemes/" rel="noopener ugc nofollow" target="_blank">neuralnetmemes </a>Instagram</figcaption></figure><blockquote class="og oh oi"><p id="2dbc" class="kr ks oj kt b ku kv jr kw kx ky ju kz ok lb lc ld ol lf lg lh om lj lk ll lm ij bi translated">我欢迎任何可以提高我自己和这篇文章的反馈。我正在学习写作和深度学习。我感谢能让我变得更好的反馈。确保以适当的方式给出反馈😄。</p></blockquote><p id="9da5" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">在我的下一篇文章中再见！</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="ab gu cl qc"><img src="../Images/0ce8ad0f37089b73b9fdfdcf06435689.png" data-original-src="https://miro.medium.com/v2/format:webp/0*9IUYoChZToK82eAh.png"/></div><figcaption class="lx ly gj gh gi lz ma bd b be z dk">Source : <a class="ae mb" href="https://cdn.pixabay.com/photo/2017/07/10/16/07/thank-you-2490552_1280.png" rel="noopener ugc nofollow" target="_blank">https://cdn.pixabay.com/photo/2017/07/10/16/07/thank-you-2490552_1280.png</a></figcaption></figure><h1 id="7f14" class="md me iq bd mf mg mh mi mj mk ml mm mn jw mo jx mp jz mq ka mr kc ms kd mt mu bi translated">贮藏室ˌ仓库</h1><p id="28ee" class="pw-post-body-paragraph kr ks iq kt b ku mx jr kw kx my ju kz la nl lc ld le nm lg lh li nn lk ll lm ij bi translated">查看这个 GitHub 资源库:</p><div class="qd qe gp gr qf qg"><a href="https://github.com/haryoa/DCGAN-Anime" rel="noopener  ugc nofollow" target="_blank"><div class="qh ab fo"><div class="qi ab qj cl cj qk"><h2 class="bd ir gy z fp ql fr fs qm fu fw ip bi translated">haryoa/DCGAN-Anime</h2><div class="qn l"><h3 class="bd b gy z fp ql fr fs qm fu fw dk translated">使用 DCGAN 制作动漫脸的个人项目。通过在…上创建一个帐户，为哈里亚海/DCGAN-Anime 的发展做出贡献</h3></div><div class="qo l"><p class="bd b dl z fp ql fr fs qm fu fw dk translated">github.com</p></div></div><div class="qp l"><div class="qq l qr qs qt qp qu kp qg"/></div></div></a></div><p id="fea6" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">目前，我只提供 IPython 笔记本来从头开始训练 GAN。请注意，如果模型在大约 200 次迭代后没有输出人脸形状的图像，请重新开始训练(从“<strong class="kt ir">创建模型</strong>部分开始运行)。</p><p id="08d5" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">稍后，我将创建一个操场笔记本来实验操纵潜在变量。</p><h1 id="a684" class="md me iq bd mf mg mh mi mj mk ml mm mn jw mo jx mp jz mq ka mr kc ms kd mt mu bi translated">来源</h1><div class="qd qe gp gr qf qg"><a href="https://medium.com/datadriveninvestor/deep-learning-generative-adversarial-network-gan-34abb43c0644" rel="noopener follow" target="_blank"><div class="qh ab fo"><div class="qi ab qj cl cj qk"><h2 class="bd ir gy z fp ql fr fs qm fu fw ip bi translated">深度学习——生成对抗网络</h2><div class="qn l"><h3 class="bd b gy z fp ql fr fs qm fu fw dk translated">在这篇文章中，我们将了解生成性敌对网络(GAN)。我们将比较生成性和辨别力…</h3></div><div class="qo l"><p class="bd b dl z fp ql fr fs qm fu fw dk translated">medium.com</p></div></div><div class="qp l"><div class="qv l qr qs qt qp qu kp qg"/></div></div></a></div><p id="b913" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">感谢<a class="qw qx ep" href="https://medium.com/u/31b07253bc35?source=post_page-----ae0e905f3974--------------------------------" rel="noopener" target="_blank">雷努·汉德尔瓦尔</a>的精彩文章。</p><p id="65c0" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated"><a class="ae mb" href="https://www.cs.toronto.edu/~duvenaud/courses/csc2541/slides/gan-foundations.pdf" rel="noopener ugc nofollow" target="_blank">https://www . cs . Toronto . edu/~ duvenaud/courses/CSC 2541/slides/gan-foundations . pdf</a></p><p id="294d" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated"><a class="ae mb" href="https://github.com/fchollet/deep-learning-with-python-notebooks" rel="noopener ugc nofollow" target="_blank">https://github . com/fchollet/用 python 深度学习笔记本</a></p><div class="qd qe gp gr qf qg"><a href="https://lilianweng.github.io/lil-log/2017/08/20/from-GAN-to-WGAN.html" rel="noopener  ugc nofollow" target="_blank"><div class="qh ab fo"><div class="qi ab qj cl cj qk"><h2 class="bd ir gy z fp ql fr fs qm fu fw ip bi translated">从 GAN 到 WGAN</h2><div class="qn l"><h3 class="bd b gy z fp ql fr fs qm fu fw dk translated">这篇文章解释了生成性对抗网络(GAN)模型背后的数学原理，以及为什么它很难被训练…</h3></div><div class="qo l"><p class="bd b dl z fp ql fr fs qm fu fw dk translated">lilianweng.github.io</p></div></div><div class="qp l"><div class="qy l qr qs qt qp qu kp qg"/></div></div></a></div><p id="7be1" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated"><a class="ae mb" href="https://arxiv.org/pdf/1511.06434.pdf" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/pdf/1511.06434.pdf</a></p><div class="qd qe gp gr qf qg"><a href="https://medium.com/@jonathan_hui/gan-why-it-is-so-hard-to-train-generative-advisory-networks-819a86b3750b" rel="noopener follow" target="_blank"><div class="qh ab fo"><div class="qi ab qj cl cj qk"><h2 class="bd ir gy z fp ql fr fs qm fu fw ip bi translated">甘——为什么生成性对抗网络这么难训练！</h2><div class="qn l"><h3 class="bd b gy z fp ql fr fs qm fu fw dk translated">认出莫奈的画比画一幅容易。生成模型(创建数据)被认为是非常…</h3></div><div class="qo l"><p class="bd b dl z fp ql fr fs qm fu fw dk translated">medium.com</p></div></div><div class="qp l"><div class="qz l qr qs qt qp qu kp qg"/></div></div></a></div><p id="2526" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">感谢 Jonathan Hui 的精彩文章。</p></div></div>    
</body>
</html>