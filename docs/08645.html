<html>
<head>
<title>Text Preprocessing in Natural Language Processing</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">自然语言处理中的文本预处理</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/text-preprocessing-in-natural-language-processing-using-python-6113ff5decd8?source=collection_archive---------1-----------------------#2019-11-21">https://towardsdatascience.com/text-preprocessing-in-natural-language-processing-using-python-6113ff5decd8?source=collection_archive---------1-----------------------#2019-11-21</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="37ed" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">文本预处理在模型性能中的意义。</h2></div><p id="27d8" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">数据预处理是建立机器学习模型的必要步骤，取决于数据预处理的好坏；结果是看到的。</p><p id="a8ef" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在自然语言处理中，文本预处理是建立模型的第一步。</p><p id="3f07" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">各种文本预处理步骤是:</p><ol class=""><li id="4073" class="le lf it kk b kl km ko kp kr lg kv lh kz li ld lj lk ll lm bi translated">标记化</li><li id="f208" class="le lf it kk b kl ln ko lo kr lp kv lq kz lr ld lj lk ll lm bi translated">下部外壳</li><li id="2f77" class="le lf it kk b kl ln ko lo kr lp kv lq kz lr ld lj lk ll lm bi translated">停止单词删除</li><li id="91d6" class="le lf it kk b kl ln ko lo kr lp kv lq kz lr ld lj lk ll lm bi translated">堵塞物</li><li id="0f22" class="le lf it kk b kl ln ko lo kr lp kv lq kz lr ld lj lk ll lm bi translated">词汇化</li></ol><p id="af9d" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">这些不同的文本预处理步骤被广泛用于降维。</p><p id="9146" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在向量空间模型中，每个单词/术语是一个轴/维度。文本/文档被表示为多维空间中的向量。<br/>唯一字的数量就是维度的数量。</p><figure class="lt lu lv lw gt lx gh gi paragraph-image"><div role="button" tabindex="0" class="ly lz di ma bf mb"><div class="gh gi ls"><img src="../Images/833592dccf4fe410c7a30a3856407157.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*b06OA4v3x3yhQiFNNzbzow.png"/></div></div></figure><p id="c252" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">安装:我将用来实现文本预处理任务的 python 库是<strong class="kk iu"> nltk </strong></p><pre class="lt lu lv lw gt me mf mg mh aw mi bi"><span id="8dc0" class="mj mk it mf b gy ml mm l mn mo">pip install nltk==3.4.5</span></pre><p id="ca76" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="kk iu">标记化</strong>:将句子拆分成单词。</p><figure class="lt lu lv lw gt lx"><div class="bz fp l di"><div class="mp mq l"/></div></figure><pre class="lt lu lv lw gt me mf mg mh aw mi bi"><span id="7680" class="mj mk it mf b gy ml mm l mn mo"><strong class="mf iu">Output: </strong>['Books', 'are', 'on', 'the', 'table'] </span></pre><p id="2cc3" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="kk iu">小写:</strong>将单词转换成小写(NLP - &gt; nlp)。<br/>像<em class="mr"> Book </em>和<em class="mr"> book </em>这样的单词意思相同，但是当不转换成小写时，这两个单词在向量空间模型中表示为两个不同的单词(导致更多的维度)。</p><figure class="lt lu lv lw gt lx"><div class="bz fp l di"><div class="mp mq l"/></div></figure><pre class="lt lu lv lw gt me mf mg mh aw mi bi"><span id="6d9d" class="mj mk it mf b gy ml mm l mn mo"><strong class="mf iu">Output: </strong>books are on the table.</span></pre><p id="88a9" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="kk iu">停用词去除:</strong>停用词是非常常用的词(a、an、the 等。)在文档中。这些词实际上并不表示任何重要性，因为它们无助于区分两个文档。</p><figure class="lt lu lv lw gt lx"><div class="bz fp l di"><div class="mp mq l"/></div></figure><pre class="lt lu lv lw gt me mf mg mh aw mi bi"><span id="bd13" class="mj mk it mf b gy ml mm l mn mo"><strong class="mf iu">Output</strong>: ['Machine', 'Learning', 'cool', '!']<br/><strong class="mf iu">Explanation</strong>: Stop word ‘is’ has been removed</span></pre><p id="ae24" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="kk iu">词干化</strong>:是将一个单词转化为其词根形式的过程。</p><figure class="lt lu lv lw gt lx"><div class="bz fp l di"><div class="mp mq l"/></div></figure><pre class="lt lu lv lw gt me mf mg mh aw mi bi"><span id="762f" class="mj mk it mf b gy ml mm l mn mo"><strong class="mf iu">Output</strong>: machin, learn, is, cool<br/><strong class="mf iu">Explanation</strong>: The word 'machine' has its suffix 'e' chopped off. The stem does not make sense as it is not a word in English. This is a disadvantage of stemming.</span></pre><p id="ded4" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="kk iu">词汇化</strong>:与词干化不同，词汇化将单词简化为语言中存在的单词。</p><p id="0154" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">词干化或词汇化都可以使用。像<strong class="kk iu"> nltk </strong>和<strong class="kk iu"> spaCy </strong>这样的库已经实现了词干分析器和词条分类器。这些都是基于基于规则的方法构建的。</p><blockquote class="ms mt mu"><p id="1d18" class="ki kj mr kk b kl km ju kn ko kp jx kq mv ks kt ku mw kw kx ky mx la lb lc ld im bi translated">斯特梅尔比词条解释器更容易构建，因为后者在构建词典时需要深厚的语言学知识来查找单词的词条。</p></blockquote><p id="c3f0" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">对于将单词解析为其词条的词条化，需要单词的词性。这有助于将单词转换成合适的词根形式。然而，要做到这一点，它需要额外的计算语言学能力，如词性标注器。</p><p id="3911" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">有关 python 中词汇化的更多示例，请查看这个<a class="ae my" href="https://www.machinelearningplus.com/nlp/lemmatization-examples-python/" rel="noopener ugc nofollow" target="_blank">博客</a>，有关词干化和词汇化之间差异的详细解释，请查看这个<a class="ae my" href="https://blog.bitext.com/what-is-the-difference-between-stemming-and-lemmatization/" rel="noopener ugc nofollow" target="_blank">博客</a></p><blockquote class="ms mt mu"><p id="3872" class="ki kj mr kk b kl km ju kn ko kp jx kq mv ks kt ku mw kw kx ky mx la lb lc ld im bi translated">变元化优于词干化，因为变元化对单词进行词法分析。</p></blockquote><figure class="lt lu lv lw gt lx"><div class="bz fp l di"><div class="mp mq l"/></div></figure><pre class="lt lu lv lw gt me mf mg mh aw mi bi"><span id="8f40" class="mj mk it mf b gy ml mm l mn mo"><strong class="mf iu">Output</strong>: machine, care<br/><strong class="mf iu">Explanation</strong>: The word Machine transforms to lowercase and retains the same word unlike Stemming. Also, the word caring is transformed to its lemma 'care' as the parts of speech variable (pos) is verb(v)</span></pre><p id="a553" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">总之，这些是自然语言处理中的文本预处理步骤。可以使用各种 python 库，如<a class="ae my" href="https://www.nltk.org/" rel="noopener ugc nofollow" target="_blank"> nltk </a>、<a class="ae my" href="https://spacy.io/" rel="noopener ugc nofollow" target="_blank"> spaCy </a>和<a class="ae my" href="https://textblob.readthedocs.io/en/dev/" rel="noopener ugc nofollow" target="_blank"> TextBlob </a>。请参考他们的文档并试用它们。</p><p id="07da" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="kk iu">关于我</strong> <br/>我对位于湾区的数据科学充满热情。我的重点是学习自然语言处理的最新技术。请随时在 LinkedIn 上与我联系</p><p id="6288" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">参考资料:</p><p id="ab52" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">[1]<a class="ae my" href="https://www.coursera.org/lecture/language-processing/text-preprocessing-SCd4G" rel="noopener ugc nofollow" target="_blank">https://www . coursera . org/lecture/language-processing/text-预处理-SCd4G</a><br/>【2】<a class="ae my" href="https://www.nltk.org/" rel="noopener ugc nofollow" target="_blank">https://www.nltk.org/</a></p></div></div>    
</body>
</html>