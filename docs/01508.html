<html>
<head>
<title>StarGAN — Image-to-Image Translation</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">StarGAN —图像到图像的翻译</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/stargan-image-to-image-translation-44d4230fbb48?source=collection_archive---------10-----------------------#2019-03-10">https://towardsdatascience.com/stargan-image-to-image-translation-44d4230fbb48?source=collection_archive---------10-----------------------#2019-03-10</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><figure class="gl gn jn jo jp jq gh gi paragraph-image"><div class="ab gu cl jr"><img src="../Images/39e334ce866648942067d0181abfd800.png" data-original-src="https://miro.medium.com/v2/format:webp/1*LTyklTEl4CjCQWD252w1Jw.png"/></div></figure><h1 id="0baf" class="ju jv iq bd jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr bi translated">星际之门是用来做什么的？</h1><p id="11cd" class="pw-post-body-paragraph ks kt iq ku b kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp ij bi translated">给定来自两个不同领域的训练数据，这些<br/>模型学习将图像从<strong class="ku ir">一个领域翻译到<br/>另一个领域。</strong></p><p id="97ac" class="pw-post-body-paragraph ks kt iq ku b kv lq kx ky kz lr lb lc ld ls lf lg lh lt lj lk ll lu ln lo lp ij bi translated">比如——将一个人的<strong class="ku ir">发色</strong>(属性)从<strong class="ku ir">黑色</strong>(属性值)改为<strong class="ku ir">金色</strong>(属性<strong class="ku ir"> </strong>值)。</p><p id="a111" class="pw-post-body-paragraph ks kt iq ku b kv lq kx ky kz lr lb lc ld ls lf lg lh lt lj lk ll lu ln lo lp ij bi translated">我们将域表示为共享相同属性值的一组图像。黑发人是一个领域，金发人是另一个领域。</p><h1 id="8c36" class="ju jv iq bd jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr bi translated">斯塔根</h1><figure class="lv lw lx ly gt jq gh gi paragraph-image"><div class="ab gu cl jr"><img src="../Images/92717948ac59f320d9f59cac3514ad60.png" data-original-src="https://miro.medium.com/v2/format:webp/1*xbYvTbqRDXRU_aEAyZzv-Q.png"/></div></figure><ol class=""><li id="04de" class="lz ma iq ku b kv lq kz lr ld mb lh mc ll md lp me mf mg mh bi translated">g 将<strong class="ku ir">图像</strong>和<strong class="ku ir">目标域</strong> <strong class="ku ir">标签</strong>作为输入，并生成假图像。(二)</li><li id="1d16" class="lz ma iq ku b kv mi kz mj ld mk lh ml ll mm lp me mf mg mh bi translated">g 试图从给定原始域标签的<strong class="ku ir">伪图像</strong>中重建<strong class="ku ir">原始图像</strong>。</li><li id="164a" class="lz ma iq ku b kv mi kz mj ld mk lh ml ll mm lp me mf mg mh bi translated">这里，鉴别器不仅告诉我们<strong class="ku ir">伪造性</strong>，而且将图像分类到其<strong class="ku ir">对应的域</strong>，从而 G 试图生成<strong class="ku ir">与真实图像</strong>无法区分并且<strong class="ku ir">可被 D </strong>分类为目标域的图像。即最终将学会生成对应于给定目标域的真实图像。(四)</li></ol><h1 id="ece0" class="ju jv iq bd jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr bi translated">歧视者的目标</h1><p id="745b" class="pw-post-body-paragraph ks kt iq ku b kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp ij bi translated">这里，鉴别器有两件事要做，</p><ol class=""><li id="b8e8" class="lz ma iq ku b kv lq kz lr ld mb lh mc ll md lp me mf mg mh bi translated">它应该能够识别一个图像是不是假的。</li><li id="573c" class="lz ma iq ku b kv mi kz mj ld mk lh ml ll mm lp me mf mg mh bi translated">在 D 之上的<strong class="ku ir">辅助分类器的帮助下，鉴别器还可以预测作为输入给 D 的图像的域。</strong></li></ol><h2 id="8dce" class="mn jv iq bd jw mo mp dn ka mq mr dp ke ld ms mt ki lh mu mv km ll mw mx kq my bi translated"><strong class="ak">辅助分类器有什么用？</strong></h2><p id="30fe" class="pw-post-body-paragraph ks kt iq ku b kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp ij bi translated">利用辅助分类器，D 从数据集中学习原始图像及其对应域的映射。当 G 生成以目标域 c(比如金发)为条件的新图像时，D 可以预测生成图像的域，因此 G 将生成新图像，直到 D 将其预测为目标域 c(金发)。</p><figure class="lv lw lx ly gt jq gh gi paragraph-image"><div class="gh gi mz"><img src="../Images/90349663bf6673f98689f3aaa1a25a7f.png" data-original-src="https://miro.medium.com/v2/resize:fit:668/format:webp/1*Yrxiaj6SUMp5xeIb7_Vb2A.png"/></div><figcaption class="na nb gj gh gi nc nd bd b be z dk">Loss function of Discriminator</figcaption></figure><h1 id="2646" class="ju jv iq bd jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr bi translated">生成器的目标</h1><p id="f0a8" class="pw-post-body-paragraph ks kt iq ku b kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp ij bi translated">发电机有三个用途—</p><ol class=""><li id="ebae" class="lz ma iq ku b kv lq kz lr ld mb lh mc ll md lp me mf mg mh bi translated">调整发生器权重，以使生成的图像逼真。</li><li id="83af" class="lz ma iq ku b kv mi kz mj ld mk lh ml ll mm lp me mf mg mh bi translated">调整生成器权重，使得生成的图像可由 d 分类为目标域。</li><li id="99e5" class="lz ma iq ku b kv mi kz mj ld mk lh ml ll mm lp me mf mg mh bi translated">g 尝试从给定原始域标签的伪图像重建原始图像。我们使用单个生成器两次，首先将<br/>原始图像转换成目标域中的图像，然后从转换后的<br/>图像重建原始图像。</li></ol><figure class="lv lw lx ly gt jq gh gi paragraph-image"><div class="gh gi ne"><img src="../Images/7246afffc18f79995b7c8d4cfd0f1307.png" data-original-src="https://miro.medium.com/v2/resize:fit:912/format:webp/1*1sejE4uJGe3zjLcBdKYlzg.png"/></div><figcaption class="na nb gj gh gi nc nd bd b be z dk">Loss function of Generator</figcaption></figure><h1 id="6910" class="ju jv iq bd jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr bi translated"><strong class="ak">数据集</strong></h1><p id="3f21" class="pw-post-body-paragraph ks kt iq ku b kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp ij bi translated">CelebA。名人面孔属性(CelebA)数据集<br/>包含 202，599 个名人的面部图像，每个图像都有 40 个二元属性的注释<br/>。</p><p id="b2af" class="pw-post-body-paragraph ks kt iq ku b kv lq kx ky kz lr lb lc ld ls lf lg lh lt lj lk ll lu ln lo lp ij bi translated">Radboud 人脸数据库(RaFD)由从 67 名参与者收集的 4824 张图片组成。每个参与者<br/>在三个不同的凝视<br/>方向上做出八个面部表情，这些表情是从三个不同的角度拍摄的。</p><h1 id="a213" class="ju jv iq bd jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr bi translated">参考</h1><p id="8975" class="pw-post-body-paragraph ks kt iq ku b kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp ij bi translated">StarGAN:用于多领域图像到图像翻译的统一生成对抗网络</p></div></div>    
</body>
</html>