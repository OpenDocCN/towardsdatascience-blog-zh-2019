<html>
<head>
<title>ML Approaches for Time Series</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">时间序列的 ML 方法</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/ml-approaches-for-time-series-4d44722e48fe?source=collection_archive---------0-----------------------#2019-05-19">https://towardsdatascience.com/ml-approaches-for-time-series-4d44722e48fe?source=collection_archive---------0-----------------------#2019-05-19</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><h2 id="7601" class="io ip iq bd b dl ir is it iu iv iw dk ix translated" aria-label="kicker paragraph"><a class="ae ep" href="https://towardsdatascience.com/tagged/ML-Time-Series" rel="noopener" target="_blank">时间序列数据的机器学习方法</a></h2><div class=""/><p id="ffe9" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">用非常规模型模拟时间序列</p><figure class="kv kw kx ky gt kz gh gi paragraph-image"><div role="button" tabindex="0" class="la lb di lc bf ld"><div class="gh gi ku"><img src="../Images/58476cb955aee59e995c3e9341b93f79.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*MQPTUReZ0RQq4BtT.png"/></div></div></figure><p id="73bd" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">在这篇文章中，我尝试了一些机器学习技术来分析时间序列数据，并探索它们在这种情况下的潜在用途。</p><p id="6cc3" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">在这第一篇文章中，只开发了索引的第一点。其余的有一个单独的帖子，可以从索引中访问。</p><p id="f560" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated"><strong class="jy ja">注意:</strong>这项工作是在 2017 年初完成的，所以很可能有些库已经更新了。</p><h1 id="8032" class="lg lh iq bd li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md bi translated">索引</h1><p id="dc45" class="pw-post-body-paragraph jw jx iq jy b jz me kb kc kd mf kf kg kh mg kj kk kl mh kn ko kp mi kr ks kt ij bi translated">1 —数据创建、窗口和基线模型<br/> 2 —遗传编程:符号回归<br/> 3 —极限学习机<br/> 4 —高斯过程<br/>5—卷积神经网络</p><h1 id="76b1" class="lg lh iq bd li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md bi translated">1 —数据创建、窗口和基线模型</h1><h2 id="c3df" class="mj lh iq bd li mk ml dn lm mm mn dp lq kh mo mp lu kl mq mr ly kp ms mt mc iw bi translated">1.1 —数据创建</h2><p id="aac5" class="pw-post-body-paragraph jw jx iq jy b jz me kb kc kd mf kf kg kh mg kj kk kl mh kn ko kp mi kr ks kt ij bi translated">在这项工作中，我们将对<strong class="jy ja">非均匀间隔时间序列</strong>数据进行分析。我们将创建 3 个随机变量<em class="mu"> x1 </em>、<em class="mu"> x2 </em>和<em class="mu"> x3 </em>的合成数据，并向这些变量的一些滞后的线性组合添加一些噪声，我们将确定 y，即响应。</p><p id="804e" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">这样，我们可以确保函数不是 100%可预测的，响应取决于预测器，并且存在由预测器的先前<strong class="jy ja">滞后对响应的影响引起的<strong class="jy ja">时间依赖性</strong>。</strong></p><p id="690b" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">该 python 脚本将在给定时间序列数据的情况下创建窗口，以便以一种我们可以为模型提供尽可能完整的信息的方式来构建问题。</p><p id="a384" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">让我们看看，首先，我们有哪些数据，我们将采用什么样的治疗方法。</p><pre class="kv kw kx ky gt mv mw mx my aw mz bi"><span id="58e7" class="mj lh iq mw b gy na nb l nc nd">N = 600<br/><br/>t = np.arange(0, N, 1).reshape(-1,1)<br/>t = np.array([t[i] + np.random.rand(1)/4 <strong class="mw ja">for</strong> i <strong class="mw ja">in</strong> range(len(t))])<br/>t = np.array([t[i] - np.random.rand(1)/7 <strong class="mw ja">for</strong> i <strong class="mw ja">in</strong> range(len(t))])<br/>t = np.array(np.round(t, 2))<br/><br/>x1 = np.round((np.random.random(N) * 5).reshape(-1,1), 2)<br/>x2 = np.round((np.random.random(N) * 5).reshape(-1,1), 2)<br/>x3 = np.round((np.random.random(N) * 5).reshape(-1,1), 2)<br/><br/>n = np.round((np.random.random(N) * 2).reshape(-1,1), 2)<br/><br/>y = np.array([((np.log(np.abs(2 + x1[t])) - x2[t-1]**2) + 0.02*x3[t-3]*np.exp(x1[t-1])) <strong class="mw ja">for</strong> t <strong class="mw ja">in</strong> range(len(t))])<br/>y = np.round(y+n, 2)</span></pre><figure class="kv kw kx ky gt kz gh gi paragraph-image"><div role="button" tabindex="0" class="la lb di lc bf ld"><div class="gh gi ne"><img src="../Images/cc1bc7561a80db043ff9aa9e2a1a34a7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*6-KYP5TTCOULI2xRXD9pOw.png"/></div></div></figure><p id="2fcc" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">然后，我们有一个函数 y，它是 3 个独立随机变量的响应，并带有一个附加噪声。此外，响应与独立变量的滞后直接<strong class="jy ja">相关，而不仅仅是与它们在给定点的值相关。这样我们确保了<strong class="jy ja">时间依赖性</strong>，并且我们强制我们的模型能够识别这种行为。</strong></p><p id="b720" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">此外，时间戳的间隔<strong class="jy ja">也不均匀</strong>。通过这种方式，我们强化了这样一个想法，即我们希望我们的模型能够理解时间依赖性，因为它们不能仅仅根据观察值(行)的数量来处理序列。</p><p id="207e" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">我们包含了指数和对数运算符，目的是<strong class="jy ja">在数据中引入高度非线性</strong>。</p><h2 id="7a3a" class="mj lh iq bd li mk ml dn lm mm mn dp lq kh mo mp lu kl mq mr ly kp ms mt mc iw bi translated">1.2 —窗户框架</h2><p id="1aae" class="pw-post-body-paragraph jw jx iq jy b jz me kb kc kd mf kf kg kh mg kj kk kl mh kn ko kp mi kr ks kt ij bi translated">这项工作的所有模型所遵循的方法是通过固定的窗口来重塑我们所拥有的信息，这些窗口将在给定的时间点从最近的过去给模型提供尽可能最完整的信息，以便实现准确的预测。此外，我们将检查将响应本身的先前值作为独立变量如何影响模型。</p><p id="d9ba" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">让我们看看我们将如何去做:</p><figure class="kv kw kx ky gt kz gh gi paragraph-image"><div role="button" tabindex="0" class="la lb di lc bf ld"><div class="gh gi nf"><img src="../Images/566f292e26a293624e45258698049457.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*hBQil1TD1T8Un9B5.png"/></div></div></figure><p id="b263" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">图中只显示了时间轴和响应。记住，在我们的例子中，还有 3 个变量负责<em class="mu"> t </em>的值。</p><p id="2d31" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">顶部的图片显示了一个选定(固定)尺寸 w 的窗口，在本例中为 4。这意味着，模型将映射包含在该窗口中的信息，预测点在<em class="mu"> t+1 </em>。响应的大小中有一个 r，因为我们可能想要预测过去的几个时间步长。这将是一种<strong class="jy ja">多对多</strong>关系。为了简单和更容易可视化，我们将使用<code class="fe ng nh ni mw b">r=1</code>。</p><p id="7ff7" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">我们现在可以看到<strong class="jy ja">滑动窗口</strong>的效果。通过将窗口移动一个时间步到未来，并像我们在上一步中所做的那样继续，获得模型将具有的用于找到映射函数的下一对输入-输出。</p><p id="cdab" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">那好吧。我们如何将它应用到当前的数据集？让我们看看我们需要什么，并建立我们的助手功能。<br/>但是首先，我们不希望时间是绝对值，我们更感兴趣的是知道哪一个是观察之间的<strong class="jy ja">经过时间</strong>(记住数据不是均匀分布的！).因此，我们创建一个 t，看看我们的数据。</p><pre class="kv kw kx ky gt mv mw mx my aw mz bi"><span id="9571" class="mj lh iq mw b gy na nb l nc nd">dataset = pd.DataFrame(np.concatenate((t, x1, x2, x3, y), axis=1), <br/>                       columns=['t', 'x1', 'x2', 'x3', 'y'])<br/><br/>deltaT = np.array([(dataset.t[i + 1] - dataset.t[i]) <strong class="mw ja">for</strong> i <strong class="mw ja">in</strong> range(len(dataset)-1)])<br/>deltaT = np.concatenate((np.array([0]), deltaT))<br/><br/>dataset.insert(1, '∆t', deltaT)<br/>dataset.head(3)</span></pre><figure class="kv kw kx ky gt kz gh gi paragraph-image"><div role="button" tabindex="0" class="la lb di lc bf ld"><div class="gh gi nj"><img src="../Images/16bd8fec62bbba49e1c5dcd6de26674d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*1tvk62AM_8vI1zoq4M0oHA.png"/></div></div></figure><p id="caa2" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">现在我们知道了数据集的样子，让我们重新创建我们希望我们的帮助函数在一个表的方案上做什么。</p><p id="7d72" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">对于尺寸为 4 的窗户:</p><figure class="kv kw kx ky gt kz gh gi paragraph-image"><div role="button" tabindex="0" class="la lb di lc bf ld"><div class="gh gi nk"><img src="../Images/5c7096172d441cdcf990af73f2544d93.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*uh9YZ9iuLmHCAiV_pquLYQ.png"/></div></div></figure><p id="415c" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">我们的函数要做的是展平窗口中包含的所有信息，即 W 窗口中的所有值，以及我们希望进行预测的时间戳。</p><p id="29e6" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">这样，我们可以有两个不同的方程来模拟我们的系统，这取决于我们是否包括以前的响应值作为新的预测值。</p><p id="7eb1" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">该函数必须返回的结果应该如下所示:</p><figure class="kv kw kx ky gt kz gh gi paragraph-image"><div role="button" tabindex="0" class="la lb di lc bf ld"><div class="gh gi nl"><img src="../Images/6485be791f8b28098ea225770bdbbba9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*6i7hhkTLOHMj3mGoOnt3nA.png"/></div></div></figure><p id="b448" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">我们将能够创建<code class="fe ng nh ni mw b">l = n - (w+r) +1</code>窗口，因为我们丢失了第一行，因为我们没有关于<em class="mu"> Y(0) </em>的第一个值的先前信息。</p><p id="c127" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">我们提到的所有滞后就像模型的新预测器(在这个可视化中，不包括先前的值<em class="mu"> Y </em>，它们将遵循与<em class="mu"> Xi </em>相同的值)。然后，我们希望进行预测的时间戳(经过的时间)<em class="mu">∏t(4)</em>，以及预测应该是什么的对应值<em class="mu"> Y(4) </em>。请注意，所有第一个<em class="mu">∏t(0)</em>都被初始化为<em class="mu"> 0 </em>，因为我们希望将每个窗口标准化为相同的范围。</p><p id="09f1" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">下面是为实现这一过程而创建的代码。有一个函数 WindowSlider，通过它我们可以创建对象来构造不同的窗口，改变参数。</p><figure class="kv kw kx ky gt kz"><div class="bz fp l di"><div class="nm nn l"/></div></figure></div><div class="ab cl no np hu nq" role="separator"><span class="nr bw bk ns nt nu"/><span class="nr bw bk ns nt nu"/><span class="nr bw bk ns nt"/></div><div class="ij ik il im in"><h2 id="cd07" class="mj lh iq bd li mk ml dn lm mm mn dp lq kh mo mp lu kl mq mr ly kp ms mt mc iw bi translated">3 —基线模型</h2><blockquote class="nv nw nx"><p id="609a" class="jw jx mu jy b jz ka kb kc kd ke kf kg ny ki kj kk nz km kn ko oa kq kr ks kt ij bi translated">“总是先做简单的事情。只在需要的时候运用智慧”——萨德·斯塔纳</p></blockquote><p id="fc4f" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated"><strong class="jy ja">创建窗口</strong></p><pre class="kv kw kx ky gt mv mw mx my aw mz bi"><span id="9f87" class="mj lh iq mw b gy na nb l nc nd">w = 5<br/>train_constructor = WindowSlider()<br/>train_windows = train_constructor.collect_windows(trainset.iloc[:,1:], <br/>                                                  previous_y=<strong class="mw ja">False</strong>)<br/><br/>test_constructor = WindowSlider()<br/>test_windows = test_constructor.collect_windows(testset.iloc[:,1:],<br/>                                                previous_y=<strong class="mw ja">False</strong>)<br/><br/>train_constructor_y_inc = WindowSlider()<br/>train_windows_y_inc = train_constructor_y_inc.collect_windows(trainset.iloc[:,1:], <br/>                                                  previous_y=<strong class="mw ja">True</strong>)<br/><br/>test_constructor_y_inc = WindowSlider()<br/>test_windows_y_inc = test_constructor_y_inc.collect_windows(testset.iloc[:,1:],<br/>                                                previous_y=<strong class="mw ja">True</strong>)<br/><br/>train_windows.head(3)</span></pre><figure class="kv kw kx ky gt kz gh gi paragraph-image"><div role="button" tabindex="0" class="la lb di lc bf ld"><div class="gh gi ob"><img src="../Images/2a56ad25e47b4a11860bf43e7e4b3937.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*IbHmFA2RE1RIAk713YIjlg.png"/></div></div></figure><p id="4286" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">我们可以看到窗口是如何为每个预测带来的，剩余变量过去(window_length)时间步长的记录，以及<em class="mu">∏t</em>的累加和。</p><p id="7f16" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated"><strong class="jy ja">预测=当前</strong></p><p id="1eac" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">我们将首先从一个简单的模型开始，该模型将给出最后一个值(每个预测点的当前值)作为下一个时间戳的预测。</p><pre class="kv kw kx ky gt mv mw mx my aw mz bi"><span id="b2ab" class="mj lh iq mw b gy na nb l nc nd"><em class="mu"># ________________ Y_pred = current Y ________________ </em><br/>bl_trainset = cp.deepcopy(trainset)<br/>bl_testset = cp.deepcopy(testset)<br/><br/>bl_y = pd.DataFrame(bl_testset['y'])<br/>bl_y_pred = bl_y.shift(periods=1)<br/><br/>bl_residuals = bl_y_pred - bl_y<br/>bl_rmse = np.sqrt(np.sum(np.power(bl_residuals,2)) / len(bl_residuals))<br/>print('RMSE = <strong class="mw ja">%.2f</strong>' % bl_rmse)<br/>print('Time to train = <strong class="mw ja">0</strong> seconds')</span><span id="e145" class="mj lh iq mw b gy oc nb l nc nd">## RMSE = 11.28</span></pre><figure class="kv kw kx ky gt kz gh gi paragraph-image"><div role="button" tabindex="0" class="la lb di lc bf ld"><div class="gh gi od"><img src="../Images/87a689c14023353c43be6ca312789cd6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*lYYfxsi7VDRd4tVeMvHyTw.png"/></div></div></figure><p id="c32d" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated"><strong class="jy ja">结论</strong>我们已经有了一个值，可以与即将得出的结果进行比较。我们应用了给定我的当前值作为预测的简单规则。对于响应值更稳定(即平稳)的时间序列，这种方法有时比最大似然算法表现得更好。在这种情况下，数据的曲折是众所周知的，导致预测能力很差。</p><h2 id="6cff" class="mj lh iq bd li mk ml dn lm mm mn dp lq kh mo mp lu kl mq mr ly kp ms mt mc iw bi translated"><strong class="ak">多元线性回归</strong></h2><p id="962a" class="pw-post-body-paragraph jw jx iq jy b jz me kb kc kd mf kf kg kh mg kj kk kl mh kn ko kp mi kr ks kt ij bi translated">我们的下一个方法是建立一个多元线性回归模型</p><pre class="kv kw kx ky gt mv mw mx my aw mz bi"><span id="a8bf" class="mj lh iq mw b gy na nb l nc nd"><em class="mu"># ______________ MULTIPLE LINEAR REGRESSION ______________ #</em></span><span id="1b47" class="mj lh iq mw b gy oc nb l nc nd"><strong class="mw ja">from</strong> <strong class="mw ja">sklearn.linear_model</strong> <strong class="mw ja">import</strong> LinearRegression<br/>lr_model = LinearRegression()<br/>lr_model.fit(trainset.iloc[:,:-1], trainset.iloc[:,-1])<br/><br/>t0 = time.time()<br/>lr_y = testset['y'].values<br/>lr_y_fit = lr_model.predict(trainset.iloc[:,:-1])<br/>lr_y_pred = lr_model.predict(testset.iloc[:,:-1])<br/>tF = time.time()<br/><br/>lr_residuals = lr_y_pred - lr_y<br/>lr_rmse = np.sqrt(np.sum(np.power(lr_residuals,2)) / len(lr_residuals))<br/>print('RMSE = <strong class="mw ja">%.2f</strong>' % lr_rmse)<br/>print('Time to train = <strong class="mw ja">%.2f</strong> seconds' % (tF - t0))</span><span id="c7ac" class="mj lh iq mw b gy oc nb l nc nd">## RMSE = 8.61 <br/>## Time to train = 0.00 seconds</span></pre><figure class="kv kw kx ky gt kz gh gi paragraph-image"><div role="button" tabindex="0" class="la lb di lc bf ld"><div class="gh gi od"><img src="../Images/d26cca7d196c02b45789cc1fdd392e5d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*nSYBJ5g6JRF0obLnSXdVew.png"/></div></div></figure><p id="d6eb" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated"><strong class="jy ja">结论</strong></p><p id="cfff" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">我们可以看到多元线性回归模型是如何无法捕捉到反应行为的。这可能是因为响应和独立变量之间的非线性关系。此外，正是这些变量的滞后影响了给定时间的响应。因此，对于找不到映射此关系的模型，这些值位于不同的行中。</p><p id="01a6" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">我很想检查一下我们在解释窗户结构时所做的假设。我们说过，我们希望为每个预测点建立一个完整的信息集。因此，预测能力应该增加后，建设的窗口…让我们去吧！</p><h2 id="a3c2" class="mj lh iq bd li mk ml dn lm mm mn dp lq kh mo mp lu kl mq mr ly kp ms mt mc iw bi translated"><strong class="ak">带窗口的 MLR</strong></h2><pre class="kv kw kx ky gt mv mw mx my aw mz bi"><span id="0efe" class="mj lh iq mw b gy na nb l nc nd"><em class="mu"># ___________ MULTIPLE LINEAR REGRESSION ON WINDOWS ___________ </em></span><span id="ebdd" class="mj lh iq mw b gy oc nb l nc nd"><strong class="mw ja">from</strong> <strong class="mw ja">sklearn.linear_model</strong> <strong class="mw ja">import</strong> LinearRegression<br/>lr_model = LinearRegression()<br/>lr_model.fit(train_windows.iloc[:,:-1], train_windows.iloc[:,-1])<br/><br/>t0 = time.time()<br/>lr_y = test_windows['y'].values<br/>lr_y_fit = lr_model.predict(train_windows.iloc[:,:-1])<br/>lr_y_pred = lr_model.predict(test_windows.iloc[:,:-1])<br/>tF = time.time()<br/><br/>lr_residuals = lr_y_pred - lr_y<br/>lr_rmse = np.sqrt(np.sum(np.power(lr_residuals,2)) / len(lr_residuals))<br/>print('RMSE = <strong class="mw ja">%.2f</strong>' % lr_rmse)<br/>print('Time to train = <strong class="mw ja">%.2f</strong> seconds' % (tF - t0))</span><span id="1a47" class="mj lh iq mw b gy oc nb l nc nd">## RMSE = 3.84<br/>## Time to train = 0.00 seconds</span></pre><figure class="kv kw kx ky gt kz gh gi paragraph-image"><div role="button" tabindex="0" class="la lb di lc bf ld"><div class="gh gi ne"><img src="../Images/0d46ebb88af1e6a07fce81983cb0e4ef.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*kOM4NNkeICRoGQmM5uY0LQ.png"/></div></div></figure><p id="abaa" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated"><strong class="jy ja">哇！这绝对是一大进步。现在我们有一个非常强大的模型要打败。似乎有了新的窗口，模型能够找到整个窗口信息和响应之间的关系。</strong></p></div><div class="ab cl no np hu nq" role="separator"><span class="nr bw bk ns nt nu"/><span class="nr bw bk ns nt nu"/><span class="nr bw bk ns nt"/></div><div class="ij ik il im in"><h1 id="78a7" class="lg lh iq bd li lj oe ll lm ln of lp lq lr og lt lu lv oh lx ly lz oi mb mc md bi translated">2 —符号回归</h1><figure class="kv kw kx ky gt kz gh gi paragraph-image"><div class="gh gi oj"><img src="../Images/dc49d00648c0a1ba014137dd4ff6f94e.png" data-original-src="https://miro.medium.com/v2/resize:fit:596/format:webp/0*L_W2QQ9sgwA7SvOI.png"/></div></figure><p id="747a" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated"><a class="ae ok" href="https://en.wikipedia.org/wiki/Symbolic_regression" rel="noopener ugc nofollow" target="_blank">符号回归</a>是一种回归分析，它搜索数学表达式的<strong class="jy ja">空间，以找到最适合给定数据集的模型。</strong></p><p id="4ad8" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">符号回归的基础是<a class="ae ok" href="https://en.wikipedia.org/wiki/Genetic_programming" rel="noopener ugc nofollow" target="_blank"> <strong class="jy ja">遗传规划</strong> </a>，因此，它是一种<a class="ae ok" href="https://en.wikipedia.org/wiki/Genetic_algorithm" rel="noopener ugc nofollow" target="_blank">进化算法</a>(又名遗传算法——GA)</p><p id="d218" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">简单总结一下算法是如何工作的，首先我们需要理解一个数学表达式可以表示为一个<strong class="jy ja">树形结构</strong>，如上图所示。</p><p id="6f19" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">这样，算法将从第一代的大量树木开始，根据<strong class="jy ja">适应度</strong>函数来测量，在我们的例子中是 RMSE。然后，每一代中最好的个体在它们之间进行交叉<strong class="jy ja"/>,并且应用一些<strong class="jy ja">突变</strong>,以包括探索和随机性。当满足停止标准时，该迭代算法结束。</p><p id="83ac" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">这个视频是对基因编程的精彩解释。</p><h2 id="dfff" class="mj lh iq bd li mk ml dn lm mm mn dp lq kh mo mp lu kl mq mr ly kp ms mt mc iw bi translated"><strong class="ak">型号</strong></h2><figure class="kv kw kx ky gt kz"><div class="bz fp l di"><div class="nm nn l"/></div></figure><figure class="kv kw kx ky gt kz gh gi paragraph-image"><div role="button" tabindex="0" class="la lb di lc bf ld"><div class="gh gi ol"><img src="../Images/1eea25852f4439a06fad772d62f1d96a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*udrzVH7V-pAN_3M4MLQ6gw.png"/></div></div></figure><figure class="kv kw kx ky gt kz gh gi paragraph-image"><div role="button" tabindex="0" class="la lb di lc bf ld"><div class="gh gi od"><img src="../Images/a20e2f12a8feb3fcedee3673a11fe49c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*OkvK_M6bYiyxCYGGIR2KOQ.png"/></div></div></figure><figure class="kv kw kx ky gt kz"><div class="bz fp l di"><div class="nm nn l"/></div></figure><figure class="kv kw kx ky gt kz gh gi paragraph-image"><div role="button" tabindex="0" class="la lb di lc bf ld"><div class="gh gi om"><img src="../Images/b5521d7cfb2b47532733a5d1c4f6aeac.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*q4CVNNzzrnKXgz6J0Na47A.png"/></div></div></figure><figure class="kv kw kx ky gt kz gh gi paragraph-image"><div role="button" tabindex="0" class="la lb di lc bf ld"><div class="gh gi on"><img src="../Images/d0f6c7dc9a51b1ff45d3ae648f914b9a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Jgxoj2iyRO1hX4hLTgX53g.png"/></div></div></figure><h2 id="6105" class="mj lh iq bd li mk ml dn lm mm mn dp lq kh mo mp lu kl mq mr ly kp ms mt mc iw bi translated">结论</h2><p id="658c" class="pw-post-body-paragraph jw jx iq jy b jz me kb kc kd mf kf kg kh mg kj kk kl mh kn ko kp mi kr ks kt ij bi translated">我们已经看到，符号回归表现出令人难以置信的好，几乎完美地符合验证数据。</p><p id="2522" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">令人惊讶的是，我通过只包含四个最简单的操作符(加、减、乘、除)获得了最好的准确性，缺点是需要更多的训练时间。</p><p id="f24b" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">我鼓励你尝试模型的不同参数并改进结果！</p></div><div class="ab cl no np hu nq" role="separator"><span class="nr bw bk ns nt nu"/><span class="nr bw bk ns nt nu"/><span class="nr bw bk ns nt"/></div><div class="ij ik il im in"><h1 id="771e" class="lg lh iq bd li lj oe ll lm ln of lp lq lr og lt lu lv oh lx ly lz oi mb mc md bi translated">3 —极限学习机</h1><figure class="kv kw kx ky gt kz gh gi paragraph-image"><div class="gh gi oo"><img src="../Images/6f19f823dc34b0a7ed0f3d599c8c3da4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1092/format:webp/0*EtuHy09wTnfpyB_I.png"/></div></figure><p id="5f14" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">极端学习机是一种重要的涌现机器学习技术。这些技术的主要方面是它们不需要学习过程来计算模型的参数。</p><p id="c148" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">本质上，EML 是一个单层前馈神经网络<a class="ae ok" href="https://en.wikipedia.org/wiki/Feedforward_neural_network" rel="noopener ugc nofollow" target="_blank"> (SLFN) </a>。ELM 理论表明，该隐藏层的权重值不需要调整，因此与训练数据无关。</p><p id="140c" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated"><a class="ae ok" href="https://en.wikipedia.org/wiki/Universal_approximation_theorem" rel="noopener ugc nofollow" target="_blank"> <strong class="jy ja">通用逼近属性</strong> </a>意味着，如果 EML 有足够的隐藏神经元和训练数据来学习所有隐藏神经元的参数，它可以以期望的精度解决任何回归问题。</p><p id="5d94" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">EML 还受益于模型结构和正则化，这减少了随机初始化和过度拟合的负面影响。</p><p id="0158" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">给定一组 N 个训练样本<code class="fe ng nh ni mw b">(x, t)</code>。具有 L 个隐藏神经元输出的 SLFN 是:</p><figure class="kv kw kx ky gt kz gh gi paragraph-image"><div role="button" tabindex="0" class="la lb di lc bf ld"><div class="gh gi op"><img src="../Images/a854f68eed1a6ebba8eec8e06ca25911.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*I9R1j1lxIAjCk0ziWXXaXA.png"/></div></div></figure><p id="884c" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">目标与网络的输入和输出之间的关系是:</p><figure class="kv kw kx ky gt kz gh gi paragraph-image"><div role="button" tabindex="0" class="la lb di lc bf ld"><div class="gh gi oq"><img src="../Images/9ec92c66be8829b50873d9252b4b0088.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*T3OWs4Srtz8AZ-Lp3DhnCw.png"/></div></div></figure><p id="c30b" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">隐藏的神经元分两步将输入数据转换成不同的表示。首先，通过输入层的权重和偏差将数据投影到隐藏层，然后对结果应用非线性激活函数。</p><p id="81c5" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">实际上，ELMs 是以矩阵形式作为普通神经网络来求解的。矩阵形式如下所示:</p><figure class="kv kw kx ky gt kz gh gi paragraph-image"><div role="button" tabindex="0" class="la lb di lc bf ld"><div class="gh gi or"><img src="../Images/122de1a8d4cfc2a3093300a344314a00.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*UhXqUS-nm4CB6kr2b_qmoA.png"/></div></div></figure><p id="200d" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">这就是这个方法的重要部分。给定 T 是我们想要达到的目标，使用<strong class="jy ja">摩尔-彭罗斯广义逆</strong>可以找到具有最小平方误差的系统的唯一解。因此，我们可以在一个单独的操作中计算隐藏层的权重值，这将导致预测目标 t 的误差最小的解决方案</p><figure class="kv kw kx ky gt kz gh gi paragraph-image"><div role="button" tabindex="0" class="la lb di lc bf ld"><div class="gh gi os"><img src="../Images/851d09be86101d66759d0e1d1b5e1a1d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*qbny4fz7VaS1XwPDZzo7Fw.png"/></div></div></figure><p id="8450" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">使用<a class="ae ok" href="https://en.wikipedia.org/wiki/Singular-value_decomposition" rel="noopener ugc nofollow" target="_blank">奇异值分解</a>计算这个伪逆</p><p id="13af" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">在<a class="ae ok" href="http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7140733" rel="noopener ugc nofollow" target="_blank">这篇文章</a>中，有一个关于 EML 如何工作的详细描述，以及一个用于 EML 的高性能工具箱的包，以及在 MATLAB 和 Python 中的实现。</p><h2 id="86d9" class="mj lh iq bd li mk ml dn lm mm mn dp lq kh mo mp lu kl mq mr ly kp ms mt mc iw bi translated">模型</h2><figure class="kv kw kx ky gt kz"><div class="bz fp l di"><div class="nm nn l"/></div></figure><p id="baa8" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">不考虑 y 的先前值作为特征</p><figure class="kv kw kx ky gt kz"><div class="bz fp l di"><div class="nm nn l"/></div></figure><pre class="kv kw kx ky gt mv mw mx my aw mz bi"><span id="cb96" class="mj lh iq mw b gy na nb l nc nd">RMSE = 3.77<br/>Time to train 0.12</span></pre><figure class="kv kw kx ky gt kz gh gi paragraph-image"><div role="button" tabindex="0" class="la lb di lc bf ld"><div class="gh gi od"><img src="../Images/2e47f4babfa15752c76501a3a1182a4e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*XAQ29A9slbe_P9ribeeM2Q.png"/></div></div></figure><p id="17e7" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">考虑 y 的先前值作为特征</p><figure class="kv kw kx ky gt kz"><div class="bz fp l di"><div class="nm nn l"/></div></figure><pre class="kv kw kx ky gt mv mw mx my aw mz bi"><span id="f0ac" class="mj lh iq mw b gy na nb l nc nd">RMSE = 6.37<br/>Time to train 0.00</span></pre><figure class="kv kw kx ky gt kz gh gi paragraph-image"><div role="button" tabindex="0" class="la lb di lc bf ld"><div class="gh gi od"><img src="../Images/42385dc68755f8b6b14703762ef82f15.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*DSeTfCcoRl4k5U_jq4A6fw.png"/></div></div></figure><h2 id="f54a" class="mj lh iq bd li mk ml dn lm mm mn dp lq kh mo mp lu kl mq mr ly kp ms mt mc iw bi translated">结论</h2><p id="fe87" class="pw-post-body-paragraph jw jx iq jy b jz me kb kc kd mf kf kg kh mg kj kk kl mh kn ko kp mi kr ks kt ij bi translated">我们可以看到 EML 对我们的数据有很强的预测能力。此外，如果我们把以前的反应值作为预测值，结果会更糟。</p><p id="088a" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">毫无疑问，EML 是需要继续探索的模型，这是一个快速的实现，已经显示了它们的强大功能，它们能够通过简单的矩阵求逆和很少的运算来计算精度。</p><p id="2581" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated"><strong class="jy ja">在线学习</strong></p><p id="5230" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">EMLs 最大的优势在于，对于实现在线模型来说，它们在计算上非常便宜。在<a class="ae ok" href="http://pabloruizruiz10.com/resources/Time-Series-Analysis/Extreme-Learning-Machines.html" rel="noopener ugc nofollow" target="_blank">这篇文章</a>中有更多关于更新和 downdate 操作的信息。</p><p id="8cf7" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">在几行中，我们可以说模型变得自适应，并且如果预测误差超过一个稳定的阈值，这个特定的数据点被合并到 SVD 中，因此模型不需要昂贵的完全再训练。这样，模型可以适应过程中可能发生的变化，并从中学习。</p></div><div class="ab cl no np hu nq" role="separator"><span class="nr bw bk ns nt nu"/><span class="nr bw bk ns nt nu"/><span class="nr bw bk ns nt"/></div><div class="ij ik il im in"><h1 id="52c3" class="lg lh iq bd li lj oe ll lm ln of lp lq lr og lt lu lv oh lx ly lz oi mb mc md bi translated">4 —高斯过程</h1><p id="1a2e" class="pw-post-body-paragraph jw jx iq jy b jz me kb kc kd mf kf kg kh mg kj kk kl mh kn ko kp mi kr ks kt ij bi translated">这篇文章是一系列文章的一部分。首发哨车发现<a class="ae ok" href="https://medium.com/@pabloruizruiz/ml-approaches-for-time-series-4d44722e48fe" rel="noopener">在这里</a></p><p id="1392" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated"><a class="ae ok" href="https://en.wikipedia.org/wiki/Gaussian_process" rel="noopener ugc nofollow" target="_blank">高斯过程</a>是随机变量的集合，使得这些随机变量的每个有限集合都具有多元正态分布，这意味着它们的每个可能的线性组合都是正态分布的。(高斯过程可以看作多元正态分布的无限维推广)。</p><p id="2ac3" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">GP 的分布是所有那些随机变量的<a class="ae ok" href="https://en.wikipedia.org/wiki/Joint_distribution" rel="noopener ugc nofollow" target="_blank"> <strong class="jy ja">联合分布</strong> </a>。简而言之，GPs 使用确定点之间相似性的<strong class="jy ja">核函数</strong>来预测一个看不见的点的值。</p><p id="a97c" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated"><a class="ae ok" href="https://www.youtube.com/watch?v=UpsV1y6wMQ8&amp;t=3578s" rel="noopener ugc nofollow" target="_blank">这个视频</a>是预测二氧化碳水平的高斯过程的精彩快速介绍。<br/> <a class="ae ok" href="http://www.gaussianprocess.org/gpml/chapters/RW.pdf" rel="noopener ugc nofollow" target="_blank">这本书</a>是高斯过程的主要指南。</p><p id="e8b2" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">GP 的一个明显的<strong class="jy ja">优势</strong>是，我们在每次预测时都获得一个<strong class="jy ja">标准偏差</strong>，这可以很容易地用来计算预测的置信区间。</p><h2 id="8e8f" class="mj lh iq bd li mk ml dn lm mm mn dp lq kh mo mp lu kl mq mr ly kp ms mt mc iw bi translated">模型</h2><p id="78e9" class="pw-post-body-paragraph jw jx iq jy b jz me kb kc kd mf kf kg kh mg kj kk kl mh kn ko kp mi kr ks kt ij bi translated">一个非常简单的 CNN 游戏:</p><figure class="kv kw kx ky gt kz"><div class="bz fp l di"><div class="nm nn l"/></div></figure><p id="3a46" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">不考虑 y 的先前值作为特征</p><figure class="kv kw kx ky gt kz"><div class="bz fp l di"><div class="nm nn l"/></div></figure><pre class="kv kw kx ky gt mv mw mx my aw mz bi"><span id="1c9e" class="mj lh iq mw b gy na nb l nc nd">RMSE = 2.320005<br/>Time to train 4.17</span></pre><figure class="kv kw kx ky gt kz gh gi paragraph-image"><div role="button" tabindex="0" class="la lb di lc bf ld"><div class="gh gi od"><img src="../Images/106690340051397960037ed6d4d9fabf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*mHpxos2mLGppPtlMq6LI9g.png"/></div></div></figure><p id="d6af" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">考虑 y 的先前值作为特征</p><figure class="kv kw kx ky gt kz"><div class="bz fp l di"><div class="nm nn l"/></div></figure><figure class="kv kw kx ky gt kz gh gi paragraph-image"><div role="button" tabindex="0" class="la lb di lc bf ld"><div class="gh gi od"><img src="../Images/fa9755677400f7813a410865a474785f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*DNPHzwYEV2uY4tEml61Yrw.png"/></div></div></figure><p id="4b7f" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">如果我们不向模型显示响应的先前值，那么验证的性能要差得多。</p><p id="14b1" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated"><strong class="jy ja">结论</strong></p><p id="38dd" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">我们已经看到高斯过程是另一种具有高预测能力的奇妙方法。该模型在引入以前的响应值作为预测值时也得到更差的结果。</p><p id="075f" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">主要的一点是，我们可以通过调整内核的几乎无限组合来寻找随机变量的组合，它们的联合分布更好地符合我们的模型。我鼓励您尝试您自己的内核并改进这些结果！</p></div><div class="ab cl no np hu nq" role="separator"><span class="nr bw bk ns nt nu"/><span class="nr bw bk ns nt nu"/><span class="nr bw bk ns nt"/></div><div class="ij ik il im in"><h1 id="3e94" class="lg lh iq bd li lj oe ll lm ln of lp lq lr og lt lu lv oh lx ly lz oi mb mc md bi translated">5-卷积神经网络</h1><p id="7377" class="pw-post-body-paragraph jw jx iq jy b jz me kb kc kd mf kf kg kh mg kj kk kl mh kn ko kp mi kr ks kt ij bi translated">这个想法是，窗口的前一个值定义为一个<strong class="jy ja"> <em class="mu">画面</em> </strong>在给定时间过程的状态。</p><p id="9598" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">因此，我们对<em class="mu">图像识别</em>使用并行性，因为我们希望找到将“图片”映射到响应值的模式。我们在<code class="fe ng nh ni mw b">timeseries.py</code>中包含了一个新函数<code class="fe ng nh ni mw b">WindowsToPictures()</code>。</p><p id="f5f7" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">该函数将我们一直使用的窗口作为输入，并为响应中的每个值创建一个图片，该图片包含所有列的<em class="mu">窗口长度</em>的所有先前值。</p><p id="5774" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">如果我们还记得第一章中对窗户的改造，这一次，窗户不会变平。相反，它们将被堆叠在 3D 张量的第三维中，其中每个<em class="mu">切片</em>将是用唯一响应值映射的图片。下面是一个例子:</p><figure class="kv kw kx ky gt kz gh gi paragraph-image"><div role="button" tabindex="0" class="la lb di lc bf ld"><div class="gh gi ot"><img src="../Images/4ebf5bb6e800abb0d8a929b721ef5ead.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*nEVqle3f3RdesRpv.png"/></div></div></figure><h2 id="fa6a" class="mj lh iq bd li mk ml dn lm mm mn dp lq kh mo mp lu kl mq mr ly kp ms mt mc iw bi translated">模型</h2><figure class="kv kw kx ky gt kz"><div class="bz fp l di"><div class="nm nn l"/></div></figure><p id="93ac" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">不考虑 y 的先前值作为特征</p><figure class="kv kw kx ky gt kz gh gi paragraph-image"><div role="button" tabindex="0" class="la lb di lc bf ld"><div class="gh gi ou"><img src="../Images/aa5607960a856c54cc699209b5124501.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*VzxIfxwf8mMLqZmWBHxrxw.png"/></div></div></figure><pre class="kv kw kx ky gt mv mw mx my aw mz bi"><span id="d623" class="mj lh iq mw b gy na nb l nc nd">RMSE = 4.21</span></pre><figure class="kv kw kx ky gt kz gh gi paragraph-image"><div role="button" tabindex="0" class="la lb di lc bf ld"><div class="gh gi ov"><img src="../Images/7146db090868edf375a225f98edcca0d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*MbBj7YFQoINNFUhtC_EQFw.png"/></div></div></figure><p id="5b4b" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">考虑 y 的先前值作为特征</p><figure class="kv kw kx ky gt kz gh gi paragraph-image"><div role="button" tabindex="0" class="la lb di lc bf ld"><div class="gh gi ow"><img src="../Images/df4357d95f8a386e5ae973b8af9c9ce8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*StZvdaIuPvSIuMFwMOC54A.png"/></div></div></figure><pre class="kv kw kx ky gt mv mw mx my aw mz bi"><span id="cf0c" class="mj lh iq mw b gy na nb l nc nd">RMSE = 3.59</span></pre><figure class="kv kw kx ky gt kz gh gi paragraph-image"><div role="button" tabindex="0" class="la lb di lc bf ld"><div class="gh gi ox"><img src="../Images/c80e32e16277d6dfc90366cad2b0bc7e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*-IBj2SJdENtmnhBqBmVnVg.png"/></div></div></figure><h2 id="e6d2" class="mj lh iq bd li mk ml dn lm mm mn dp lq kh mo mp lu kl mq mr ly kp ms mt mc iw bi translated">结论</h2><p id="eff1" class="pw-post-body-paragraph jw jx iq jy b jz me kb kc kd mf kf kg kh mg kj kk kl mh kn ko kp mi kr ks kt ij bi translated">对于多变量时间序列预测，将过程的先前状态作为每个时间步的过程图似乎是一种合理的方法。</p><p id="9cb1" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">这种方法允许将问题构建成任何类型的问题，例如金融时间序列预测、温度/天气预测、过程变量监控…</p><p id="ec1c" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">我仍然想考虑创建窗口和图片的新方法来改善结果，但对我来说，它看起来像一个防止过度拟合的健壮模块，正如我们在峰值中看到的那样，它从来没有超过实际值。</p><p id="f019" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">我很想知道你想出什么来改善它！</p></div></div>    
</body>
</html>