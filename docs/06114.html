<html>
<head>
<title>What does RMSE really mean?</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">RMSE 到底是什么意思？</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/what-does-rmse-really-mean-806b65f2e48e?source=collection_archive---------0-----------------------#2019-09-05">https://towardsdatascience.com/what-does-rmse-really-mean-806b65f2e48e?source=collection_archive---------0-----------------------#2019-09-05</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><p id="f1ad" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">均方根误差(RMSE)是衡量模型在预测定量数据时的误差的标准方法。正式定义如下:</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi ko"><img src="../Images/1745c4a763256d431519ce429b6a87d1.png" data-original-src="https://miro.medium.com/v2/resize:fit:966/format:webp/1*lqDsPkfXPGen32Uem1PTNg.png"/></div></figure><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi kw"><img src="../Images/7ba721d91936c035709dc98b7fddb9a1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1210/format:webp/1*NupCRCord7W0whzSOttnxQ.png"/></div></figure><p id="6175" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">让我们试着从数学的角度来探索为什么这个误差的度量是有意义的。忽略平方根下 n 的除法，我们首先注意到的是类似于ℝⁿ:中两个向量之间的欧几里德距离公式</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi ky"><img src="../Images/6d18d959b5a5a4a57698020e7f1c2f3a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1176/format:webp/1*IBJLV0KIfrOyZAnd_136zw.png"/></div></figure><p id="f44d" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">这启发性地告诉我们，RMSE 可以被认为是预测值向量和观测值向量之间的某种(归一化)距离。</p><p id="4171" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">但是为什么我们在平方根下面除以 n 呢？如果我们保持 n(观察次数)不变，它所做的只是将欧几里德距离重新缩放一个因子√(1/n)。很难看出为什么这是正确的做法，所以让我们更深入地研究一下。</p><p id="635a" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">假设我们的观测值是通过给每个预测值加上随机“误差”来确定的，如下所示:</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="la lb di lc bf ld"><div class="gh gi kz"><img src="../Images/f44c8e7825de103f4d57e05b40681557.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*0YnRuB5VuzZoVZhd4pcA5g.png"/></div></div></figure><p id="aea8" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">这些误差被认为是随机变量，可能具有均值为μ、标准差为σ的高斯分布，但任何其他平方可积 PDF ( <em class="le">概率密度函数</em>)分布也适用。我们想把 ŷᵢ看作一个潜在的物理量，比如在某个特定的时间点从火星到太阳的确切距离。我们观测到的 yᵢ量将是我们测量时从火星到太阳的距离<em class="le"/>，其中一些误差来自我们望远镜的误校准和大气干扰的测量噪声。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="la lb di lc bf ld"><div class="gh gi lf"><img src="../Images/c23e3cea86d0cb1fc02b31c4c7572bb0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*mr1fjGIeMQaQWlk2GJ5WWg.jpeg"/></div></div><figcaption class="lg lh gj gh gi li lj bd b be z dk">(NOT TO SCALE)</figcaption></figure><p id="8657" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">误差分布的均值μ对应于来自误校准的持续偏差，而标准差σ对应于测量噪声量。想象一下，现在我们确切地知道了误差分布的均值μ，并且想要估计标准差σ。我们可以通过一点计算看出:</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi lk"><img src="../Images/d51b147f600788a46ad32051d057a22a.png" data-original-src="https://miro.medium.com/v2/resize:fit:684/format:webp/1*IlDRC69jbvpoDA8CEVhfDA.png"/></div></figure><p id="684b" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">这里<strong class="js iu"> E </strong> […]是期望，Var(…)是方差。我们可以用第四行的<strong class="js iu">e</strong>【ε】代替第三行的期望值<strong class="js iu"> E[ </strong> εᵢ ]的平均值，其中ε是与每个εᵢ具有相同分布的变量，因为误差εᵢ是同分布的，因此它们的平方都具有相同的期望值。</p><p id="8d87" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">请记住，我们假设我们已经确切地知道μ。也就是说，我们仪器中的持续偏差是已知偏差，而不是未知偏差。因此，我们不妨通过从所有原始观测值中减去μ来立即校正这种偏差。也就是说，我们不妨假设我们的误差已经以均值μ = 0 分布。将这个代入上面的等式，取两边的平方根，得到:</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi ll"><img src="../Images/b29704907b7b37ffc845ea70b73b52a2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1398/format:webp/1*T5d8WZYEIc16wk2fKO7SHw.png"/></div></figure><p id="d18c" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">注意左手边看起来很熟悉！如果我们从平方根中去掉期望 E，这就是我们之前的 RMSE 公式。中心极限定理告诉我们，随着 n 变大，σᵢ(ŷᵢ—yᵢ)/n =σᵢ(εᵢ)/n 这个量的方差应该收敛到零。事实上，中心极限定理的一个更清晰的形式告诉我们，它的方差应该像 1/n 一样渐近地收敛到 0。这告诉我们，σᵢ(ŷᵢ—yᵢ)/n 是对<strong class="js iu">e</strong>[σᵢ(ŷᵢ—yᵢ)/n]=σ的一个很好的估计。但是 RMSE 是我们误差分布的标准差σ的一个很好的估计量！</p><p id="e01a" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">我们现在还应该有一个在 RMSE 平方根下除以 n 的解释:它允许我们估计典型的<em class="le">单次</em>观测的误差的标准偏差σ，而不是某种“总误差”。通过除以 n，当我们从小的观测值集合移动到更大的集合时，我们保持这种误差测量一致(随着我们增加观测值的数量，它变得更加精确)。换句话说，RMSE 是回答这个问题的一个很好的方式:“我们应该期望我们的模型在下一次预测中有多远？”</p><p id="cd72" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">总结我们的讨论，假设我们的观测数据可以分解为:</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="la lb di lc bf ld"><div class="gh gi lm"><img src="../Images/9f08188a65631949ad2ee3647df58c86.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*gpH4l09b1_RYRaPcLQaRXQ.png"/></div></div></figure><p id="ea1d" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">这里的随机噪声可以是我们的模型没有捕捉到的任何东西(例如，可能影响观察值的未知变量)。如果噪音很小，正如 RMSE 估计的那样，这通常意味着我们的模型擅长预测我们观察到的数据，如果 RMSE 很大，这通常意味着我们的模型无法解释我们数据背后的重要特征。</p><h2 id="c6a2" class="ln lo it bd lp lq lr dn ls lt lu dp lv kb lw lx ly kf lz ma mb kj mc md me mf bi translated">数据科学中的 RMSE:使用 RMSE 的微妙之处</h2><p id="77de" class="pw-post-body-paragraph jq jr it js b jt mg jv jw jx mh jz ka kb mi kd ke kf mj kh ki kj mk kl km kn im bi translated">在数据科学中，RMSE 有双重目的:</p><ul class=""><li id="2d82" class="ml mm it js b jt ju jx jy kb mn kf mo kj mp kn mq mr ms mt bi translated">作为训练模型的启发</li><li id="3ed2" class="ml mm it js b jt mu jx mv kb mw kf mx kj my kn mq mr ms mt bi translated">评估训练模型的有用性/准确性</li></ul><p id="5dad" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">这就提出了一个重要的问题:<strong class="js iu">RMSE 的“小”意味着什么？</strong></p><p id="3083" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">我们首先要注意的是,“小”取决于我们选择的单位，以及我们希望的具体应用。在建筑设计中，100 英寸是一个很大的误差，但 100 纳米不是。另一方面，100 纳米在制造冰块托盘时是一个小误差，但在制造集成电路时可能是一个大误差。</p><p id="1d0f" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">对于训练模型，我们使用什么单位并不重要，因为在训练过程中我们所关心的是有一个启发式方法来帮助我们减少每次迭代的错误。我们只关心从一步到下一步的相对误差大小，而不是误差的绝对大小。</p><p id="0da0" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">但是，在评估数据科学中经过训练的模型的有用性/准确性时，我们确实关心单位，因为我们不仅仅是想看看我们是否比上一次做得更好:我们想知道我们的模型是否能真正帮助我们解决实际问题。这里的微妙之处在于，评估 RMSE 是否足够小，将取决于我们对给定应用的模型精度要求。这永远不会有一个数学公式，因为它依赖于人的意图(“你打算用这个模型做什么？”)，风险厌恶(“如果这个模型做了一个不好的预测，会造成多大的伤害？”)，等等。</p><p id="4d71" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">除了单位之外，还有另一个考虑因素:“小”也需要相对于正在使用的模型的类型、数据点的数量以及在评估模型的准确性之前模型经历的训练历史来度量。起初，这听起来可能违反直觉，但当你想起<strong class="js iu">过度装配</strong>的问题时，就不会了。</p><p id="296c" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">每当模型中的参数数量相对于您拥有的数据点数量较大时，就有过度拟合的风险。例如，如果我们试图预测一个实数<strong class="js iu"> y </strong>作为另一个实数<strong class="js iu"> x </strong>的函数，并且我们的观测值是(xᵢ，yᵢ)与 x₁ &lt; x₂ &lt; x₃ …，一个通用插值定理告诉我们，对于 i = 1，…，n，存在某个次数最多为 n+1 的多项式 f(x)=yᵢ。这意味着如果我们选择我们的模型为 n+1 次多项式， 通过调整我们模型的参数(多项式的系数)，我们将能够把 RMSE 一直降到 0。 不管我们的 y 值是多少，这都是正确的。在这种情况下，RMSE 并没有真正告诉我们任何关于我们的基础模型的准确性:我们被保证能够调整参数，以获得 RMSE = 0，正如在我们现有的数据点上测量的那样，不管这两个真实量之间是否有任何关系。</p><p id="c330" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">但是不仅仅是当参数的数量超过数据点的数量时，我们可能会遇到问题。即使我们没有过多的参数，一般的数学原理和对我们数据的温和背景假设也能保证我们很有可能通过调整模型中的参数，使 RMSE 低于某个阈值。如果我们处于这种情况，那么 RMSE 低于这一阈值可能对我们模型的预测能力没有任何意义。</p><p id="46fc" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">如果我们想像统计学家一样思考，我们会问的问题不是“我们训练的模型的 RMSE 小吗？”而是，“我们训练过的模型在如此这般的一组观察值上的 RMSE 随机变得如此之小的概率是多少？”</p><p id="bdd6" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">这类问题变得有点复杂(你实际上必须做统计)，但希望你们都明白为什么“足够小的 RMSE”没有预先确定的阈值，因为这将使我们的生活变得简单。</p></div></div>    
</body>
</html>