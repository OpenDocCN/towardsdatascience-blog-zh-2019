<html>
<head>
<title>Neural Style Transfer Series : Part 2</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">神经风格转移系列:第二部分</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/neural-style-transfer-series-part-2-91baad306b24?source=collection_archive---------18-----------------------#2019-03-25">https://towardsdatascience.com/neural-style-transfer-series-part-2-91baad306b24?source=collection_archive---------18-----------------------#2019-03-25</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="65b1" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">神经类型转换的 TensorFlow 和 pyTorch 实现</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/77585b65d2e05b5604c2f961ead8084a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*2XNrOZisIvpc3BGgDv1Mhw.png"/></div></div></figure><p id="54f5" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi ln translated">他的文章来自我们在第一篇文章中讨论的内容。虽然我们谈到了直觉和神经类型转移如何工作的理论，但我们现在将继续实现最初的论文。如果这是你阅读这个系列的第一篇文章，我恳求你阅读下面给出的前一篇文章。我们已经深入解释了 neural style 是如何工作的，这篇文章主要是关于如何实现它。理解理论上的细微差别也有助于理解实现。</p><p id="03dc" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated"><a class="ae lw" rel="noopener" target="_blank" href="/neural-style-transfer-tutorial-part-1-f5cd3315fa7f">神经风格迁移教程—第一部分:神经风格迁移理论</a></p><p id="cad1" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">在解释整个代码之前，我将先浏览一下实现它们的框架。然后进入实现阶段。</p><p id="7001" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">实现的代码可以在这里找到。[ <a class="ae lw" href="https://github.com/Shashi456/Neural-Style/blob/master/Neural%20Style%20Transfer/train_Pytorch.py" rel="noopener ugc nofollow" target="_blank"> Pytorch </a>，<a class="ae lw" href="https://github.com/Shashi456/Neural-Style/blob/master/Neural%20Style%20Transfer/train_TensorFlow.py" rel="noopener ugc nofollow" target="_blank"> Tensorflow </a></p><p id="3e31" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">注意:你一定注意到了，不是将代码模块化成一组损失，网络创建和培训文件。我们刚刚创建了两个名为 train_Pytorch.py 和 train_TensorFlow.py 的文件，我们可能会在未来的代码中更改此工作流。</p><p id="809b" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">在我们深入研究代码实现之前，现在让我们试着对深度学习框架有一个整体的看法。由于我们将使用 Python，我将坚持使用 Pytorch 和 Tensorflow 等主流框架。这将是一个非常全面的库视图，我们可以写另一篇文章，专门讨论不同的可用框架及其优缺点。您可能想看看其他几个框架，包括但不限于 Dynet、Chainer 和 Julia language 最近发布的框架 flux。另一件要注意的事情是，尽管这些是用于构建模型的框架，但还有更高级别的抽象，如 fastai、spacy 和 keras。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi lx"><img src="../Images/50e637fa5f47350ef1af06fa5efd664a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1124/format:webp/1*qaeiDmtPiDv6FLedyM9ItQ.png"/></div><figcaption class="ly lz gj gh gi ma mb bd b be z dk">A computational graph</figcaption></figure><p id="1557" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">Pytorch 是由脸书借鉴 Lua 中的 torch 并在 caffe2 上构建而成的，而 Tensorflow 是由 google 创建的。Tensorflow 仍然是大多数人当前选择的框架，但 Pytorch 正在迅速加快速度，据说在某些方面更好。Pytorch 和 Tensorflow 都创建了被称为计算图的东西，两者的主要区别在于它们如何创建这些计算图。Pytorch 创建动态图，Tensorflow 创建静态图。这意味着，在 Pytorch 中，您可以随时操作您的图形，而在 Tensorflow 中，您必须事先完全定义它。Tensorflow2.0 正在尝试将动态图以急切执行的形式融入到语言中。Pytorch 更 pythonic 化，因此学习起来更直观，而 Tensorflow 有许多好的特性，如 Tensorboard(模型的可视化平台)，也更容易投入生产。</p><p id="bcc9" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">现在回到我们的文章，在这个代码解释中，我希望给出一些关于计算图的概述，并看到框架中的一些差异和相似之处。我想恳求你先理解代码，运行它，然后执行它，而不要看代码，如果有任何错误。我不会讨论为该程序编写的实用程序，因为它们只是数据加载函数，本质上大多是琐碎的。</p><p id="47ff" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">首先要注意的是“内容层”和“风格层”，你可以用任何你想要的方式来尝试不同的表现。正如在原始文章中所解释的，这两个数组用于表示您将从中获取要素制图表达的图层。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mc md l"/></div></figure><p id="c11c" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">在 pyTorch 中，创建网络的方法是重载 nn.Module。它通常有两个部分，首先是初始化所有层的<em class="me"> __init__ </em>方法，然后是<em class="me"> forward </em>方法，forward 方法用于通过网络实际传递数据并获得输出。在这段代码中，我选择编写我自己的 VGG19 网络，但是也有一些方法可以导入内置的模型并加载权重。我选择以一种特殊的方式做的一些事情是保持平均池层，你也可以使用最大池层。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mc md l"/></div></figure><p id="e85c" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">如果你想知道<em class="me">变换</em>变量的用途是什么，它基本上是为了变换你的输入图像而存在的，无论原始分辨率是多少，都可以将其转换成可以馈入 VGG 网络的东西。我们对图像进行归一化处理，以便更详细地描述图像网络的含义。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mc md l"/></div></figure><p id="0d3a" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">在复制论文或制作模型时，框架内需要注意的一件事是，通常我们在 cpu 上有数据，但神经网络模型的效率训练是在 GPU 上进行的，因此正如你所见，我们使用了<em class="me">。cuda() </em>函数将我们的样式和内容图像等对象传输到 gpu 上。我们将预训练的 VGG 权重加载到模型上，这些预训练的权重来自在 Imagenet 上训练的 VGG。保存的重量文件的扩展名为<em class="me">。pth </em>需要注意的一件事是，当你编写你的网络并保存权重并尝试在我的网络上运行时，它可能不会工作虽然我们都在训练 vgg 网络，但不同的层名称等细节可能会或选择 max 而不是 average pooling 等层可能会在加载权重时引发错误。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mc md l"/></div></figure><p id="ba1f" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">谈到损失函数，首先我们有 gram 矩阵类。如前一篇文章所述，我们使用 Gram 矩阵提取特征层，即<em class="me">。bmm() </em>代表批量矩阵乘法。在批量矩阵乘法中，最后 2 个维度用于矩阵乘法，而其余维度被视为批量。我在变量后面的注释中写了一个例子来给出矩阵维数的概念。样式损失的计算方法是，首先传递图层以获取其 gram 矩阵表示，然后获取表示和目标之间的均方误差。一步一步地检查其余部分，我们从 VGG 网络中分离层，并将它们添加到各自的目标层。然后，我们开始定义损失、目标和损失层。最后，我们有风格权重和内容权重，你可以用任何你想要的方式进行实验，该文件建议 1000 和 5 是一个很好的开始方式，你的内容权重越高，你就越保留你的原始图像，你的风格权重越高，你会发现风格变得越来越突出，而内容退居其次。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mc md l"/></div></figure><p id="c1fe" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">最后是训练循环，训练循环是各种深度学习模型建立的关键部分。为了勾勒出一个通用的框架，我们在任何训练循环中做三件事，我们决定优化器，计算损失，然后反向推进。在上面的例子中，我们使用了 LBFGS 优化器。我们可以看到我们称之为<em class="me">。zero_grad() </em>函数这是因为，pytorch 默认情况下会累积梯度，所以我们需要每次在计算梯度之前将梯度设置为零。然后通过遍历所有的样式和内容层来累积总损失，之后是<em class="me">。backward() </em>函数用于计算梯度和<em class="me">。步骤()</em>用于更新权重。我们将损失函数传递给<em class="me">步骤()</em>的原因是，在 LBFGS 的情况下，需要多次计算损失。</p><p id="ff41" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">现在，我将尝试指出主要的区别，而不是完整地浏览 Tensorflow 代码，因为代码的其余部分与 pyTorch 非常相似。其中一个基本区别是在<em class="me"> run_style_transfer() </em>中，我们可以观察到一个会话变量正在被创建，这就引出了一个事实，即由于 tensorflow 创建静态图，我们需要首先定义一个会话，然后在这个会话中训练模型。Adam 优化器用于训练模型，而不是 LBGFS。在训练循环中，会话是通过将优化器传递给相同的。并且只有在当前损失好于(即小于)先前损失的情况下，才更新损失。预加载重量的 VGG 模型是从 keras 导入的，而不是从头开始编写的。训练模型时，可能需要一段时间，因为如果本地没有权重，tensorflow 将下载权重。</p><p id="c704" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">好了，你已经成功地看到了神经类型转换的代码。接下来要做的是，运行代码并亲自查看输出。我们将继续快速神经风格转移系列，简单介绍一下，当你训练网络时，你可能会观察到，对于每种风格，你都需要重复训练整个网络。解决这个问题的一个更好的方法可能是学习样式权重，保存它们，然后随时加载您想要的任何内容图像。这可能听起来令人困惑，所以期待深入的文章。</p><p id="04d8" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">非常感谢等待这篇文章。</p><p id="9252" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">感谢<a class="ae lw" href="https://medium.com/@vamshikdshetty" rel="noopener">瓦姆西克·谢蒂</a>与我共同创作了这个系列。</p><p id="81e9" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">您可以在这个<a class="ae lw" href="https://github.com/Shashi456/Neural-Style" rel="noopener ugc nofollow" target="_blank">资源库</a>中找到代码，在这里我们也将有本系列未来文章的代码。</p></div></div>    
</body>
</html>