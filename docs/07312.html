<html>
<head>
<title>BLEU-BERT-y: Comparing sentence scores</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">比较句子得分</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/bleu-bert-y-comparing-sentence-scores-307e0975994d?source=collection_archive---------16-----------------------#2019-10-14">https://towardsdatascience.com/bleu-bert-y-comparing-sentence-scores-307e0975994d?source=collection_archive---------16-----------------------#2019-10-14</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><figure class="gl gn jo jp jq jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi jn"><img src="../Images/339afe7e7f77a35044ee67d397c5f1a0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Oa50sYP2_kCCuuTO8Lj6OA.jpeg"/></div></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk">Blueberries — Photo by <a class="ae kc" href="https://unsplash.com/@joannakosinska?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank">Joanna Kosinska</a> on <a class="ae kc" href="https://unsplash.com/s/photos/blueberry?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><p id="5402" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">本故事的目标是理解 BLEU，因为它是 MT 模型的一种广泛使用的测量方法，并研究它与 BERT 的关系。</p><p id="54f1" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这是我的项目的第一个故事，我尝试在神经机器翻译(NMT)问题中使用 BERT 情境化嵌入向量。我对机器翻译比较陌生，因此，欢迎任何建议。</p><h1 id="d8cc" class="lb lc iq bd ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly bi translated">句子相似度</h1><p id="7bc6" class="pw-post-body-paragraph kd ke iq kf b kg lz ki kj kk ma km kn ko mb kq kr ks mc ku kv kw md ky kz la ij bi translated">当涉及到机器翻译或其他自然语言处理(NLP)问题时，过程的输出是文本，测量结果的正确性并不简单。</p><p id="000d" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">评估机器翻译算法我们要问的问题是“这个翻译有多好？”或者“目标语言中的句子和源语言中的句子有多接近？”</p><p id="a234" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">为了理解这个问题，在这里我们将看看它的一个更简单的版本:“在<em class="me">同一种语言</em>中的两个句子有多相似？”</p><p id="97c5" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在这个故事中，让我们使用以下袖珍句子:<br/> <code class="fe mf mg mh mi b">s0: James Cook was a very good man and a loving husband. <br/>s1: James Cook was a very nice man and a loving husband.<br/>s2: James Cook was a bad man and a terrible husband.<br/>s3: James Cook was a nice person and a good husband.<br/>s4: The sky is blue today and learning history is important.</code></p><p id="8f31" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我想建议大家花一分钟思考一下句子之间的相似性，它们与第一个句子有多接近！</p><h1 id="1c9c" class="lb lc iq bd ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly bi translated">蓝色</h1><p id="95e6" class="pw-post-body-paragraph kd ke iq kf b kg lz ki kj kk ma km kn ko mb kq kr ks mc ku kv kw md ky kz la ij bi translated">BLEU:双语评价替角提供评分比较句子[1]。最初，它是为翻译开发的，使用参考翻译来评估预测的翻译，然而，它也可以用于句子相似性。<a class="ae kc" href="https://machinelearningmastery.com/calculate-bleu-score-for-text-python/" rel="noopener ugc nofollow" target="_blank">这里</a>很好的介绍了 BLEU(或者阅读原文)。</p><p id="2c82" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">BLEU 背后的想法是统计句子中匹配的<em class="me"> n-grams </em>。一元词是一个单词(token)，二元词是一对两个单词，以此类推。在这种情况下，单词的顺序无关紧要。</p><p id="5b6c" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">为了消除错误的分数(例如，“the the the the”给“猫吃鸟”一个相对较好的分数)，引入了这个计数的修改版本。这个<em class="me">修改的单字精度</em>惩罚了在参考文本中多次使用同一个单词。</p><p id="5dc6" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">BLEU 不能处理单词同义词，但是，它是一种快速、廉价的算法，与语言无关，并且与人类评估相关。</p><h1 id="7fba" class="lb lc iq bd ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly bi translated">伯特</h1><p id="8fd4" class="pw-post-body-paragraph kd ke iq kf b kg lz ki kj kk ma km kn ko mb kq kr ks mc ku kv kw md ky kz la ij bi translated">BERT:来自变压器的双向编码器表示是一个上下文化的单词嵌入(以及更多)[2]。<a class="ae kc" href="http://jalammar.github.io/illustrated-bert/" rel="noopener ugc nofollow" target="_blank">这里</a>是对 BERT 的一个很棒的总结(或者阅读原文)。</p><p id="1bfb" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">单词嵌入是映射到单词的向量，以帮助计算机理解单词。虽然“猫”或“狗”对计算机来说很难处理，但它们的矢量表示更适合。对嵌入映射的一个期望是相似的单词必须彼此靠近。</p><p id="6b3e" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">根据上下文，上下文化单词嵌入向量对于相同的单词具有不同的嵌入。BERT 嵌入的一个技巧是，它是用分隔符<code class="fe mf mg mh mi b">CLS</code>和<code class="fe mf mg mh mi b">SEP</code>训练的，这些分隔符也有上下文相关的嵌入向量。原论文中建议这些嵌入可以作为句子级嵌入。这里，我们将使用每个句子的<code class="fe mf mg mh mi b">CLS</code>分隔符的嵌入向量作为句子的嵌入。<code class="fe mf mg mh mi b">[CLS] This is a sentence with separators . [SEP]</code></p><h1 id="0941" class="lb lc iq bd ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly bi translated">向量距离</h1><p id="4bba" class="pw-post-body-paragraph kd ke iq kf b kg lz ki kj kk ma km kn ko mb kq kr ks mc ku kv kw md ky kz la ij bi translated">这里，我们将使用相应的<code class="fe mf mg mh mi b">CLS</code>句子级嵌入的欧几里德距离和余弦相似度来计算句子之间的相似度。</p><figure class="mk ml mm mn gt jr gh gi paragraph-image"><div class="gh gi mj"><img src="../Images/e50b1a3bca3e047e449dba1504689cfc.png" data-original-src="https://miro.medium.com/v2/resize:fit:330/format:webp/1*tk8Es1ItbwqEE3geKrak6Q.png"/></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk">Euclidean distance</figcaption></figure><figure class="mk ml mm mn gt jr gh gi paragraph-image"><div class="gh gi mo"><img src="../Images/ccdf1dd4936b8f62f6f38f18c6e53ccc.png" data-original-src="https://miro.medium.com/v2/resize:fit:750/format:webp/1*iAiRbXj3s7T1aJqrHSOYHA.png"/></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk">Cosine similarity</figcaption></figure><p id="eec1" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">欧几里德距离的范围是[0，∞)，因此，为了匹配其他分数，让我们使用函数 f(x)=(1/1.2)^x 来获得(0，1)分数。该函数产生相对接近于 BLEU 的分数。余弦相似度具有正确的范围，但是，它与 BLEU 分数没有可比性。为了评估结果，我们必须调查句子之间的相对分数，而不是其他分数。</p><h1 id="31db" class="lb lc iq bd ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly bi translated">相似性得分</h1><p id="6b58" class="pw-post-body-paragraph kd ke iq kf b kg lz ki kj kk ma km kn ko mb kq kr ks mc ku kv kw md ky kz la ij bi translated">这是一个使用 BLEU 的分数表。正如我们所看到的，BLEU 认为第二个句子与第一个句子很接近(只有一个单词发生了变化)，但是它不能处理第四个句子的同义词。还有一个完全不同的句子得分比较高。</p><p id="0b80" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">具有平滑功能的 BLEU 解决了后一个问题。</p><p id="7f26" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">具有欧几里德距离的 BERT 获得了与 BLEU 相对相似的分数，但是它也处理同义词。BERT 向量的余弦相似性具有与空间相似性得分相似的得分。</p><p id="e5e3" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">Spacy 是一个工业级的自然语言处理工具。Spacy 使用嵌入向量的单词，句子的向量是其标记向量的平均值。更多关于空间相似性<a class="ae kc" href="https://spacy.io/usage/vectors-similarity" rel="noopener ugc nofollow" target="_blank">这里</a>。</p><figure class="mk ml mm mn gt jr"><div class="bz fp l di"><div class="mp mq l"/></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk">BLEU and BERT scores of the pocket sentences, similarity to the first sentence</figcaption></figure><h1 id="6808" class="lb lc iq bd ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly bi translated">贝特斯科尔</h1><p id="f5c3" class="pw-post-body-paragraph kd ke iq kf b kg lz ki kj kk ma km kn ko mb kq kr ks mc ku kv kw md ky kz la ij bi translated"><em class="me">(2019 年 11 月 6 日更新)</em></p><p id="2c7f" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这是一个更新，因为我最近发现了一篇文章，其想法是使用 BERT 来评估机器翻译系统[4]。作者表明，与之前的分数(如 BLUE)相比，BERTScore 与人类判断的相关性更好。</p><p id="1304" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">BERTScore 与这里介绍的相似，但是，BERTScore 使用标记级 BERT 嵌入向量的相似性，而我们使用句子级嵌入。</p><h1 id="ab64" class="lb lc iq bd ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly bi translated">摘要</h1><p id="c503" class="pw-post-body-paragraph kd ke iq kf b kg lz ki kj kk ma km kn ko mb kq kr ks mc ku kv kw md ky kz la ij bi translated">这个故事介绍了评估句子相似性的 BLEU 分数，并将其与 BERT 向量距离进行了比较。这些例子试图说明定义一个相似的句子意味着什么是多么困难，这两种方法显示了定量测量某种相似性的可能答案。附在这个故事上的代码提供了 BLEU 和 BERT 以及 Spacy 的基本用法。对于详细的介绍，提供了额外的链接。</p><p id="8e1c" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><a class="ae kc" href="https://colab.research.google.com/drive/11I3Zu1QX0KOZprVLF8ac_5vsN44hOj7r" rel="noopener ugc nofollow" target="_blank">相应的代码</a>在 Google Colab 中有。</p><h1 id="3e48" class="lb lc iq bd ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly bi translated">参考</h1><p id="47af" class="pw-post-body-paragraph kd ke iq kf b kg lz ki kj kk ma km kn ko mb kq kr ks mc ku kv kw md ky kz la ij bi translated">[1]帕皮尼，k .，鲁科斯，s .，沃德，t .，，朱，W. J. (2002 年 7 月).<a class="ae kc" href="https://dl.acm.org/citation.cfm?id=1073135" rel="noopener ugc nofollow" target="_blank"> BLEU:一种自动评估机器翻译的方法。</a>见<em class="me">计算语言学协会第 40 届年会论文集</em>(第 311-318 页)。计算语言学协会。</p><p id="f591" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">[2] Devlin，j .，Chang，M. W .，Lee，k .，&amp; Toutanova，K. (2018 年)。<a class="ae kc" href="https://arxiv.org/abs/1810.04805" rel="noopener ugc nofollow" target="_blank"> Bert:用于语言理解的深度双向转换器的预训练。</a> <em class="me"> arXiv 预印本 arXiv:1810.04805 </em>。</p><p id="6aa5" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">[3]林春燕，吴凤珍(2004 年 7 月).<a class="ae kc" href="https://dl.acm.org/citation.cfm?id=1219032" rel="noopener ugc nofollow" target="_blank">使用最长公共子序列和 skip-bigram 统计自动评估机器翻译质量。</a>见<em class="me">第 42 届计算语言学协会年会论文集</em>(第 605 页)。计算语言学协会。</p><p id="21d5" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">[4]张，t .，基肖尔，v .，吴，f .，温伯格，K. Q .，&amp;阿奇，Y. (2019)。<a class="ae kc" href="https://arxiv.org/abs/1904.09675" rel="noopener ugc nofollow" target="_blank"> BERTScore:用 BERT </a>评估文本生成。<em class="me"> arXiv 预印本 arXiv:1904.09675 </em>。</p><h1 id="3d51" class="lb lc iq bd ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly bi translated">用伯特的故事学习 NMT</h1><ol class=""><li id="fa35" class="mr ms iq kf b kg lz kk ma ko mt ks mu kw mv la mw mx my mz bi translated"><a class="ae kc" href="https://medium.com/@neged.ng/bleu-bert-y-comparing-sentence-scores-307e0975994d" rel="noopener"> BLEU-BERT-y:比较句子得分</a></li><li id="faa5" class="mr ms iq kf b kg na kk nb ko nc ks nd kw ne la mw mx my mz bi translated">嵌入关系的可视化(word2vec，BERT) </li><li id="0086" class="mr ms iq kf b kg na kk nb ko nc ks nd kw ne la mw mx my mz bi translated"><a class="ae kc" rel="noopener" target="_blank" href="/machine-translation-a-short-overview-91343ff39c9f">机器翻译:简要概述</a></li><li id="31a2" class="mr ms iq kf b kg na kk nb ko nc ks nd kw ne la mw mx my mz bi translated"><a class="ae kc" rel="noopener" target="_blank" href="/identifying-the-right-meaning-of-the-words-using-bert-817eef2ac1f0">使用 BERT 识别单词的正确含义</a></li><li id="14c3" class="mr ms iq kf b kg na kk nb ko nc ks nd kw ne la mw mx my mz bi translated">机器翻译:与 SOTA 相比</li><li id="0c92" class="mr ms iq kf b kg na kk nb ko nc ks nd kw ne la mw mx my mz bi translated"><a class="ae kc" rel="noopener" target="_blank" href="/simple-bert-using-tensorflow-2-0-132cb19e9b22">使用 TensorFlow 2.0 的简单 BERT】</a></li></ol></div></div>    
</body>
</html>