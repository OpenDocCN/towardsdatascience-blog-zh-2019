<html>
<head>
<title>Measures of Proximity in Data Mining &amp; Machine Learning</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">数据挖掘和机器学习中的相似性度量</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/measures-of-proximity-in-data-mining-machine-learning-e9baaed1aafb?source=collection_archive---------0-----------------------#2019-08-18">https://towardsdatascience.com/measures-of-proximity-in-data-mining-machine-learning-e9baaed1aafb?source=collection_archive---------0-----------------------#2019-08-18</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="deb5" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">在分析过程中执行数据转换</h2></div><figure class="ki kj kk kl gt km"><div class="bz fp l di"><div class="kn ko l"/></div><figcaption class="kp kq gj gh gi kr ks bd b be z dk">Video version of the story, if you are into that sort of thing</figcaption></figure><p id="039f" class="pw-post-body-paragraph kt ku it kv b kw kx ju ky kz la jx lb lc ld le lf lg lh li lj lk ll lm ln lo im bi lp translated"><span class="l lq lr ls bm lt lu lv lw lx di">在</span> <a class="ae ly" rel="noopener" target="_blank" href="/assessing-the-quality-of-data-e5e996a1681b"> <em class="lz">我之前的一个帖子</em> </a>里，我讲过<strong class="kv iu"> <em class="lz">评估数据挖掘的数据质量&amp;机器学习算法</em> </strong>。这个就继续那个，如果还没看的话，这里看一下<a class="ae ly" rel="noopener" target="_blank" href="/assessing-the-quality-of-data-e5e996a1681b"><strong class="kv iu"><em class="lz"/></strong></a><strong class="kv iu"><em class="lz"/></strong>以便对我在文章中要讲的话题和概念有一个恰当的把握。</p></div><div class="ab cl ma mb hx mc" role="separator"><span class="md bw bk me mf mg"/><span class="md bw bk me mf mg"/><span class="md bw bk me mf"/></div><div class="im in io ip iq"><p id="6f8f" class="pw-post-body-paragraph kt ku it kv b kw kx ju ky kz la jx lb lc ld le lf lg lh li lj lk ll lm ln lo im bi lp translated">两个对象之间的接近度是两个对象的相应属性之间的接近度的函数。接近度是指<strong class="kv iu">相似度和相异度</strong>。相似性和不相似性很重要，因为它们被许多数据挖掘技术使用，如聚类、最近邻分类和异常检测。</p><p id="469e" class="pw-post-body-paragraph kt ku it kv b kw kx ju ky kz la jx lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">我们将从高级定义开始讨论，并探索它们之间的关系。然后，我们继续讨论具有一个简单属性的两个数据对象中的<strong class="kv iu">接近度</strong>，并继续讨论具有多个属性的对象。</p><blockquote class="mh"><p id="27f1" class="mi mj it bd mk ml mm mn mo mp mq lo dk translated">请容忍我的概念部分，我知道这可能有点无聊，但如果你有强大的基础，那么没有什么可以阻止你成为一名伟大的数据科学家或机器学习工程师。</p></blockquote></div><div class="ab cl ma mb hx mc" role="separator"><span class="md bw bk me mf mg"/><span class="md bw bk me mf mg"/><span class="md bw bk me mf"/></div><div class="im in io ip iq"><blockquote class="mr ms mt"><p id="75a1" class="kt ku lz kv b kw kx ju ky kz la jx lb mu ld le lf mv lh li lj mw ll lm ln lo im bi translated"><strong class="kv iu">什么是相似性？</strong></p></blockquote><p id="3228" class="pw-post-body-paragraph kt ku it kv b kw kx ju ky kz la jx lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">→这是两个对象相似程度的数字度量。</p><p id="e479" class="pw-post-body-paragraph kt ku it kv b kw kx ju ky kz la jx lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">→对于更相似的一对对象，该值更高。</p><p id="388b" class="pw-post-body-paragraph kt ku it kv b kw kx ju ky kz la jx lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">→通常为非负值，介于 0 和 1 之间。</p><blockquote class="mh"><p id="bde3" class="mi mj it bd mk ml mm mn mo mp mq lo dk translated">0 ~没有相似性，1 ~完全相似</p></blockquote><blockquote class="mr ms mt"><p id="ce7f" class="kt ku lz kv b kw mx ju ky kz my jx lb mu mz le lf mv na li lj mw nb lm ln lo im bi translated">什么是不同？</p></blockquote><p id="c412" class="pw-post-body-paragraph kt ku it kv b kw kx ju ky kz la jx lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">→它是两个对象不同程度的数值度量。</p><p id="a787" class="pw-post-body-paragraph kt ku it kv b kw kx ju ky kz la jx lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">→对于更相似的一对对象，较低。</p><p id="7229" class="pw-post-body-paragraph kt ku it kv b kw kx ju ky kz la jx lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">→范围 0 至<em class="lz">无穷大</em>。</p></div><div class="ab cl ma mb hx mc" role="separator"><span class="md bw bk me mf mg"/><span class="md bw bk me mf mg"/><span class="md bw bk me mf"/></div><div class="im in io ip iq"><h2 id="7a1f" class="nc nd it bd ne nf ng dn nh ni nj dp nk lc nl nm nn lg no np nq lk nr ns nt nu bi translated">变换函数</h2><p id="15fa" class="pw-post-body-paragraph kt ku it kv b kw nv ju ky kz nw jx lb lc nx le lf lg ny li lj lk nz lm ln lo im bi translated">这是一个函数，用于将相似性转换为不相似性，反之亦然，或者将接近度转换为特定范围。例如:</p><blockquote class="mh"><p id="0784" class="mi mj it bd mk ml mm mn mo mp mq lo dk translated">s' = (s-min(s)) / max(s)-min(s))</p></blockquote><p id="dffb" class="pw-post-body-paragraph kt ku it kv b kw mx ju ky kz my jx lb lc mz le lf lg na li lj lk nb lm ln lo im bi translated">在哪里，</p><p id="451a" class="pw-post-body-paragraph kt ku it kv b kw kx ju ky kz la jx lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated"><em class="lz">s’</em>=新转换的邻近测量值，</p><p id="2227" class="pw-post-body-paragraph kt ku it kv b kw kx ju ky kz la jx lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated"><em class="lz"> s </em> =当前接近度测量值，</p><p id="767e" class="pw-post-body-paragraph kt ku it kv b kw kx ju ky kz la jx lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated"><em class="lz">最小值</em> =邻近测量值的最小值，</p><p id="4678" class="pw-post-body-paragraph kt ku it kv b kw kx ju ky kz la jx lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated"><em class="lz">最大值</em> =最大接近度测量值</p><p id="4e94" class="pw-post-body-paragraph kt ku it kv b kw kx ju ky kz la jx lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">这个转换函数只是所有可用选项中的一个例子。</p></div><div class="ab cl ma mb hx mc" role="separator"><span class="md bw bk me mf mg"/><span class="md bw bk me mf mg"/><span class="md bw bk me mf"/></div><div class="im in io ip iq"><h2 id="8ec5" class="nc nd it bd ne nf ng dn nh ni nj dp nk lc nl nm nn lg no np nq lk nr ns nt nu bi translated">简单属性之间的相似和相异</h2><p id="d65b" class="pw-post-body-paragraph kt ku it kv b kw nv ju ky kz nw jx lb lc nx le lf lg ny li lj lk nz lm ln lo im bi lp translated">具有多个属性的对象的接近度通常通过组合单个属性的接近度来定义，因此，我们首先讨论具有单个属性的对象之间的接近度。</p><figure class="ki kj kk kl gt km gh gi paragraph-image"><div role="button" tabindex="0" class="ob oc di od bf oe"><div class="gh gi oa"><img src="../Images/624dbad72c6d802eadc7a1316224c0b5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*tKlgcYb4VHRvsCywxCTzlA.png"/></div></div><figcaption class="kp kq gj gh gi kr ks bd b be z dk">Introduction to Data Mining — Pang-Ning Tan, Michael Steinbach, Vipin Kumar</figcaption></figure><p id="5f2b" class="pw-post-body-paragraph kt ku it kv b kw kx ju ky kz la jx lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">为了更好地理解它，让我们看一些例子。</p><ul class=""><li id="6c3f" class="oh oi it kv b kw kx kz la lc oj lg ok lk ol lo om on oo op bi translated">考虑由一个<strong class="kv iu">名义</strong>属性描述的对象。如何像这样比较两个物体的相似度？名义属性只告诉我们对象的独特性。因此，在这种情况下，如果属性值匹配，则相似性被定义为 1，否则，相反定义的相似性为 0。</li><li id="0601" class="oh oi it kv b kw oq kz or lc os lg ot lk ou lo om on oo op bi translated">对于具有单个<strong class="kv iu">序数</strong>属性的对象，情况更复杂，因为需要考虑关于顺序的信息。考虑一个衡量产品质量的属性，等级为{差、一般、好、好、极好}。我们有三个产品 P1，P2，&amp; P3，质量分别为极好，良好，&amp;还行。为了比较有序的数量，它们被映射到连续的整数。在这种情况下，如果刻度分别映射到{0，1，2，3，4}。那么，不同(P1，P2)= 4–3 = 1。</li><li id="2906" class="oh oi it kv b kw oq kz or lc os lg ot lk ou lo om on oo op bi translated">对于<strong class="kv iu">区间或比率</strong>属性，两个对象之间相异度的自然度量是它们值的绝对差值。例如，我们可以通过说“我重了十磅”来比较我们现在的体重和一年前的体重</li></ul><p id="c29f" class="pw-post-body-paragraph kt ku it kv b kw kx ju ky kz la jx lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">如果你不知道不同的属性类型，即<strong class="kv iu">名义的、序数的、区间的和比率的</strong>，那么让<a class="ae ly" rel="noopener" target="_blank" href="/journey-into-data-mining-3b5ccfa5343">阅读我以前的关于属性</a>到不同类型的分布的文章。</p><div class="ov ow gp gr ox oy"><a rel="noopener follow" target="_blank" href="/journey-into-data-mining-3b5ccfa5343"><div class="oz ab fo"><div class="pa ab pb cl cj pc"><h2 class="bd iu gy z fp pd fr fs pe fu fw is bi translated">数据挖掘之旅</h2><div class="pf l"><h3 class="bd b gy z fp pd fr fs pe fu fw dk translated">数据导论</h3></div><div class="pg l"><p class="bd b dl z fp pd fr fs pe fu fw dk translated">towardsdatascience.com</p></div></div><div class="ph l"><div class="pi l pj pk pl ph pm of oy"/></div></div></a></div></div><div class="ab cl ma mb hx mc" role="separator"><span class="md bw bk me mf mg"/><span class="md bw bk me mf mg"/><span class="md bw bk me mf"/></div><div class="im in io ip iq"><p id="2aea" class="pw-post-body-paragraph kt ku it kv b kw kx ju ky kz la jx lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">接下来，我们将分别讨论数据对象之间的相似性和不相似性。事不宜迟，让我们开始吧。</p><h2 id="7dda" class="nc nd it bd ne nf ng dn nh ni nj dp nk lc nl nm nn lg no np nq lk nr ns nt nu bi translated">数据对象之间的差异</h2><p id="b4e8" class="pw-post-body-paragraph kt ku it kv b kw nv ju ky kz nw jx lb lc nx le lf lg ny li lj lk nz lm ln lo im bi translated">我们从讨论距离开始，距离具有不同的性质。</p><blockquote class="mr ms mt"><p id="65df" class="kt ku lz kv b kw kx ju ky kz la jx lb mu ld le lf mv lh li lj mw ll lm ln lo im bi translated"><strong class="kv iu">欧几里德距离</strong></p></blockquote><p id="5b85" class="pw-post-body-paragraph kt ku it kv b kw kx ju ky kz la jx lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">在一维、二维、三维或更高维空间中，两点 x 和 y 之间的欧几里德距离 d 由以下公式给出:</p><figure class="ki kj kk kl gt km gh gi paragraph-image"><div class="gh gi pn"><img src="../Images/ff1deb68667e46807587c3c3b14d13ee.png" data-original-src="https://miro.medium.com/v2/resize:fit:936/format:webp/1*iCKP8Pi8k8qBrAITdxCV_Q.png"/></div><figcaption class="kp kq gj gh gi kr ks bd b be z dk">Introduction to Data Mining — Pang-Ning Tan, Michael Steinbach, Vipin Kumar</figcaption></figure><p id="f91a" class="pw-post-body-paragraph kt ku it kv b kw kx ju ky kz la jx lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">其中 n 是维数，<em class="lz"> x(k) </em>和<em class="lz"> y(k) </em>分别是<em class="lz"> x </em>和<em class="lz"> y </em>的<em class="lz">k</em>属性(组件)。</p><p id="ee44" class="pw-post-body-paragraph kt ku it kv b kw kx ju ky kz la jx lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated"><strong class="kv iu"> <em class="lz">举例:</em> </strong></p><figure class="ki kj kk kl gt km gh gi paragraph-image"><div role="button" tabindex="0" class="ob oc di od bf oe"><div class="gh gi po"><img src="../Images/d01858ea96574985c30d19de57373a88.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*1Ecv4mGPvbk0o2_ejPK2mQ.png"/></div></div><figcaption class="kp kq gj gh gi kr ks bd b be z dk">Introduction to Data Mining — Pang-Ning Tan, Michael Steinbach, Vipin Kumar</figcaption></figure><blockquote class="mr ms mt"><p id="51d8" class="kt ku lz kv b kw kx ju ky kz la jx lb mu ld le lf mv lh li lj mw ll lm ln lo im bi translated"><strong class="kv iu">闵可夫斯基距离</strong></p></blockquote><p id="a781" class="pw-post-body-paragraph kt ku it kv b kw kx ju ky kz la jx lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">它是欧几里得距离的推广。它由以下公式给出:</p><figure class="ki kj kk kl gt km gh gi paragraph-image"><div class="gh gi pp"><img src="../Images/014c91f3666f5b7feff7b99db3e8666f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1056/format:webp/1*G0OfSFbEtJBPPaP6fvGh4g.png"/></div></figure><p id="6c54" class="pw-post-body-paragraph kt ku it kv b kw kx ju ky kz la jx lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">其中<em class="lz"> r </em>是一个参数。以下是闵可夫斯基距离的三个最常见的例子。</p><p id="9d18" class="pw-post-body-paragraph kt ku it kv b kw kx ju ky kz la jx lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">→ <em class="lz"> r = 1 </em>。城市街区(曼哈顿、出租车、<em class="lz">、L1 定额</em>)距离。一个常见的例子是<strong class="kv iu">汉明距离</strong>，它是仅具有二进制属性的两个对象之间，即两个二进制向量之间不同的位数。</p><p id="318e" class="pw-post-body-paragraph kt ku it kv b kw kx ju ky kz la jx lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">→ <em class="lz"> r = 2 </em>。欧几里德距离(<em class="lz"> L2 范数</em>)。</p><p id="a8f6" class="pw-post-body-paragraph kt ku it kv b kw kx ju ky kz la jx lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">→ <em class="lz"> r =无穷大</em>。上确界(<em class="lz"> L(最大)，或 L(无穷大)范数</em>)距离。这是对象的任何属性之间的最大差异。这由以下公式定义:</p><figure class="ki kj kk kl gt km gh gi paragraph-image"><div class="gh gi pq"><img src="../Images/31ea60129839dbd3661e307017faf64b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1180/format:webp/1*oajJMv_E76d608UYBn4ckQ.png"/></div></figure><p id="3b13" class="pw-post-body-paragraph kt ku it kv b kw kx ju ky kz la jx lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated"><strong class="kv iu"> <em class="lz">举例:</em> </strong></p><figure class="ki kj kk kl gt km gh gi paragraph-image"><div role="button" tabindex="0" class="ob oc di od bf oe"><div class="gh gi pr"><img src="../Images/fa8e8c773ac1fb90830fe0b1ca8ba092.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*eVgHi8vGe9zYX9aspPk5YQ.png"/></div></div><figcaption class="kp kq gj gh gi kr ks bd b be z dk">Introduction to Data Mining — Pang-Ning Tan, Michael Steinbach, Vipin Kumar</figcaption></figure><p id="b5d5" class="pw-post-body-paragraph kt ku it kv b kw kx ju ky kz la jx lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">距离，如欧几里德距离，有一些众所周知的性质。如果<em class="lz"> d(x，y) </em>是两点之间的距离，<em class="lz"> x </em>和<em class="lz"> y </em>，那么以下性质成立。</p><ol class=""><li id="c155" class="oh oi it kv b kw kx kz la lc oj lg ok lk ol lo ps on oo op bi translated"><strong class="kv iu">积极性</strong></li></ol><p id="58b0" class="pw-post-body-paragraph kt ku it kv b kw kx ju ky kz la jx lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">a) <em class="lz"> d(x，y) &gt; 0 </em>对于所有<em class="lz"> x </em>和<em class="lz"> y </em>，</p><p id="5814" class="pw-post-body-paragraph kt ku it kv b kw kx ju ky kz la jx lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">b) <em class="lz"> d(x，y) = 0 </em>仅当<em class="lz"> x = y </em></p><p id="a8ba" class="pw-post-body-paragraph kt ku it kv b kw kx ju ky kz la jx lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">2.<strong class="kv iu">对称</strong> <br/> <em class="lz"> d(x，y) = d(y，x) </em>对于所有<em class="lz"> x </em>和<em class="lz"> y </em></p><p id="8cce" class="pw-post-body-paragraph kt ku it kv b kw kx ju ky kz la jx lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">3.<strong class="kv iu">三角形不等式</strong></p><p id="5d21" class="pw-post-body-paragraph kt ku it kv b kw kx ju ky kz la jx lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated"><em class="lz"> d(x，z) ≤ d(x，y) + d(y，z) </em>对于所有点<em class="lz"> x，y </em>和<em class="lz"> z </em></p><p id="7312" class="pw-post-body-paragraph kt ku it kv b kw kx ju ky kz la jx lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">满足所有这三个属性的度量被称为<strong class="kv iu">度量。</strong></p></div><div class="ab cl ma mb hx mc" role="separator"><span class="md bw bk me mf mg"/><span class="md bw bk me mf mg"/><span class="md bw bk me mf"/></div><div class="im in io ip iq"><h2 id="e5c2" class="nc nd it bd ne nf ng dn nh ni nj dp nk lc nl nm nn lg no np nq lk nr ns nt nu bi translated">数据对象之间的相似性</h2><p id="4a51" class="pw-post-body-paragraph kt ku it kv b kw nv ju ky kz nw jx lb lc nx le lf lg ny li lj lk nz lm ln lo im bi translated">对于相似性，三角形不等式通常不成立，但对称性和正性通常成立。明确地说，如果<em class="lz"> s(x，y) </em>是点<em class="lz"> x </em>和<em class="lz"> y </em>之间的相似性，那么相似性的典型性质如下:</p><ol class=""><li id="c2d0" class="oh oi it kv b kw kx kz la lc oj lg ok lk ol lo ps on oo op bi translated"><em class="lz"> s(x，y) = 1 </em>仅当<em class="lz"> x = y </em>时。(0 ≤ <em class="lz"> s </em> ≤ 1)</li><li id="55c4" class="oh oi it kv b kw oq kz or lc os lg ot lk ou lo ps on oo op bi translated"><em class="lz"> s(x，y) = s(y，x) </em>对于所有<em class="lz"> x </em>和<em class="lz"> y </em>。(对称)</li></ol><p id="0c78" class="pw-post-body-paragraph kt ku it kv b kw kx ju ky kz la jx lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">对于相似性度量，没有三角形不等式的一般模拟。</p><p id="616d" class="pw-post-body-paragraph kt ku it kv b kw kx ju ky kz la jx lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated"><strong class="kv iu">二进制数据</strong>的相似性度量被称为<strong class="kv iu">相似性系数</strong>，其值通常在 0 和 1 之间。两个二进制对象之间的比较使用以下四个量来完成:</p><figure class="ki kj kk kl gt km gh gi paragraph-image"><div role="button" tabindex="0" class="ob oc di od bf oe"><div class="gh gi pt"><img src="../Images/e7d9a964c43a7104f06cc44f2d6b242d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*4zYyrzTqxjq7JgSU_oeuLA.png"/></div></div><figcaption class="kp kq gj gh gi kr ks bd b be z dk">Introduction to Data Mining — Pang-Ning Tan, Michael Steinbach, Vipin Kumar</figcaption></figure><blockquote class="mr ms mt"><p id="5a12" class="kt ku lz kv b kw kx ju ky kz la jx lb mu ld le lf mv lh li lj mw ll lm ln lo im bi translated"><strong class="kv iu">简单匹配系数</strong></p></blockquote><p id="4ec4" class="pw-post-body-paragraph kt ku it kv b kw kx ju ky kz la jx lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">其定义如下:</p><figure class="ki kj kk kl gt km gh gi paragraph-image"><div role="button" tabindex="0" class="ob oc di od bf oe"><div class="gh gi pu"><img src="../Images/6aee84d487d586c5007e731e671fa858.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*0wZRXimRtxsID7XFkwrVfQ.png"/></div></div><figcaption class="kp kq gj gh gi kr ks bd b be z dk">Introduction to Data Mining — Pang-Ning Tan, Michael Steinbach, Vipin Kumar</figcaption></figure><blockquote class="mr ms mt"><p id="1a67" class="kt ku lz kv b kw kx ju ky kz la jx lb mu ld le lf mv lh li lj mw ll lm ln lo im bi translated"><strong class="kv iu">雅克卡系数</strong></p></blockquote><p id="2e9a" class="pw-post-body-paragraph kt ku it kv b kw kx ju ky kz la jx lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">其定义如下:</p><figure class="ki kj kk kl gt km gh gi paragraph-image"><div role="button" tabindex="0" class="ob oc di od bf oe"><div class="gh gi pv"><img src="../Images/b36420d7d93fbae6d181c99731ff49d8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Q7lyrZILGe432f1o0c2omQ.png"/></div></div><figcaption class="kp kq gj gh gi kr ks bd b be z dk">Introduction to Data Mining — Pang-Ning Tan, Michael Steinbach, Vipin Kumar</figcaption></figure><p id="9752" class="pw-post-body-paragraph kt ku it kv b kw kx ju ky kz la jx lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">比较这两种相似性方法的示例:</p><figure class="ki kj kk kl gt km gh gi paragraph-image"><div role="button" tabindex="0" class="ob oc di od bf oe"><div class="gh gi pw"><img src="../Images/72628bb8794b1f7d30b79a2f01c43b4b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ZGPWIvdnrNdA7x12uPImfw.png"/></div></div><figcaption class="kp kq gj gh gi kr ks bd b be z dk">Introduction to Data Mining — Pang-Ning Tan, Michael Steinbach, Vipin Kumar</figcaption></figure><blockquote class="mr ms mt"><p id="3128" class="kt ku lz kv b kw kx ju ky kz la jx lb mu ld le lf mv lh li lj mw ll lm ln lo im bi translated"><strong class="kv iu">余弦相似度</strong></p></blockquote><p id="ee8b" class="pw-post-body-paragraph kt ku it kv b kw kx ju ky kz la jx lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">文档通常表示为向量，其中每个属性表示特定术语(单词)在文档中出现的频率。<strong class="kv iu">余弦相似度</strong>，是一种最常见的度量文档相似度的方法。如果<em class="lz"> x </em>和<em class="lz"> y </em>是两个文档向量，那么</p><figure class="ki kj kk kl gt km gh gi paragraph-image"><div class="gh gi px"><img src="../Images/090bc131896063c0594698ac006048cc.png" data-original-src="https://miro.medium.com/v2/resize:fit:676/format:webp/1*L5C-ATHBkRUVbC2GiBNWmg.png"/></div><figcaption class="kp kq gj gh gi kr ks bd b be z dk">Introduction to Data Mining — Pang-Ning Tan, Michael Steinbach, Vipin Kumar</figcaption></figure><p id="0b61" class="pw-post-body-paragraph kt ku it kv b kw kx ju ky kz la jx lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">在哪里？表示<em class="lz">点积</em>和<em class="lz"> ||x|| </em>定义向量<em class="lz"> x </em>的长度。</p><p id="f775" class="pw-post-body-paragraph kt ku it kv b kw kx ju ky kz la jx lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated"><strong class="kv iu">余弦相似度</strong>度量的一个例子如下:</p><figure class="ki kj kk kl gt km gh gi paragraph-image"><div role="button" tabindex="0" class="ob oc di od bf oe"><div class="gh gi py"><img src="../Images/69f049b9d4f1c05a49d9d4b2effc1738.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*FjnZqDvVKaeICVeyI9xkXA.png"/></div></div><figcaption class="kp kq gj gh gi kr ks bd b be z dk">Introduction to Data Mining — Pang-Ning Tan, Michael Steinbach, Vipin Kumar</figcaption></figure><blockquote class="mr ms mt"><p id="6f5b" class="kt ku lz kv b kw kx ju ky kz la jx lb mu ld le lf mv lh li lj mw ll lm ln lo im bi translated"><strong class="kv iu">相关性</strong></p></blockquote><p id="ce6c" class="pw-post-body-paragraph kt ku it kv b kw kx ju ky kz la jx lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">它是对具有二元或连续变量的对象的属性之间的线性关系的度量。<strong class="kv iu">两个对象<em class="lz"> x </em>和<em class="lz"> y </em>之间的相关性</strong>定义如下:</p><figure class="ki kj kk kl gt km gh gi paragraph-image"><div role="button" tabindex="0" class="ob oc di od bf oe"><div class="gh gi pz"><img src="../Images/c63bb2242f068fd1a309bab2d05f52b4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*LcVWIMQFctgAc_NXUX9WqQ.png"/></div></div><figcaption class="kp kq gj gh gi kr ks bd b be z dk">Introduction to Data Mining — Pang-Ning Tan, Michael Steinbach, Vipin Kumar</figcaption></figure><p id="0e48" class="pw-post-body-paragraph kt ku it kv b kw kx ju ky kz la jx lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">其中使用的符号在标准中定义为:</p><figure class="ki kj kk kl gt km gh gi paragraph-image"><div role="button" tabindex="0" class="ob oc di od bf oe"><div class="gh gi qa"><img src="../Images/7cbfadda45d00d2cf4571bd268422b93.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*wGno-JwJf374ghm5EaNOTw.png"/></div></div><figcaption class="kp kq gj gh gi kr ks bd b be z dk">Introduction to Data Mining — Pang-Ning Tan, Michael Steinbach, Vipin Kumar</figcaption></figure></div><div class="ab cl ma mb hx mc" role="separator"><span class="md bw bk me mf mg"/><span class="md bw bk me mf mg"/><span class="md bw bk me mf"/></div><div class="im in io ip iq"><p id="47a4" class="pw-post-body-paragraph kt ku it kv b kw kx ju ky kz la jx lb lc ld le lf lg lh li lj lk ll lm ln lo im bi lp translated">直到现在我们已经定义并理解了数据对象之间的相似性和不相似性度量。现在，让我们讨论一下邻近计算面临的问题。</p><blockquote class="mr ms mt"><p id="0dd7" class="kt ku lz kv b kw kx ju ky kz la jx lb mu ld le lf mv lh li lj mw ll lm ln lo im bi translated"><strong class="kv iu">邻近度计算中的问题</strong></p></blockquote><ol class=""><li id="a58b" class="oh oi it kv b kw kx kz la lc oj lg ok lk ol lo ps on oo op bi translated">如何处理具有不同尺度和/或相关属性的酪蛋白，</li><li id="13bd" class="oh oi it kv b kw oq kz or lc os lg ot lk ou lo ps on oo op bi translated">如何计算由不同类型的属性(例如，定量和定性属性)组成的对象之间的接近度，以及</li><li id="fc17" class="oh oi it kv b kw oq kz or lc os lg ot lk ou lo ps on oo op bi translated">当属性具有不同的权重时，即当并非所有属性对对象的邻近性的贡献相等时，如何处理邻近性计算。</li></ol></div><div class="ab cl ma mb hx mc" role="separator"><span class="md bw bk me mf mg"/><span class="md bw bk me mf mg"/><span class="md bw bk me mf"/></div><div class="im in io ip iq"><h2 id="3cdc" class="nc nd it bd ne nf ng dn nh ni nj dp nk lc nl nm nn lg no np nq lk nr ns nt nu bi translated">选择正确的邻近测量</h2><p id="5369" class="pw-post-body-paragraph kt ku it kv b kw nv ju ky kz nw jx lb lc nx le lf lg ny li lj lk nz lm ln lo im bi translated">以下是一些可能有帮助的一般观察。首先，邻近度量的类型应该适合数据的类型。对于许多类型的密集、连续数据，通常使用公制距离度量，如<strong class="kv iu">欧几里德距离</strong>。</p><p id="a67b" class="pw-post-body-paragraph kt ku it kv b kw kx ju ky kz la jx lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">连续属性之间的接近度通常用<strong class="kv iu">差异</strong>来表示，而<strong class="kv iu">距离</strong>度量提供了一种将这些差异组合成整体接近度的明确方法。</p><p id="4a74" class="pw-post-body-paragraph kt ku it kv b kw kx ju ky kz la jx lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">对于通常由不对称属性组成的稀疏数据，我们通常采用忽略 0–0 匹配的相似性度量。从概念上讲，这反映了这样一个事实:对于一对复杂的对象来说，相似性取决于它们共有的特征的数量，而不是它们都缺少的特征的数量。对于这类数据，可以使用<strong class="kv iu">余弦相似度</strong>或<strong class="kv iu">雅克卡系数</strong>。</p><p id="37c0" class="pw-post-body-paragraph kt ku it kv b kw kx ju ky kz la jx lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">以上只是一些需要坚持或者可以遵循的建议。它们没有涵盖所有类型的现有<a class="ae ly" rel="noopener" target="_blank" href="/types-of-data-sets-in-data-science-data-mining-machine-learning-eb47c80af7a">数据集</a>。<strong class="kv iu">接近度测量</strong>的最终确定取决于问题。</p><p id="dca9" class="pw-post-body-paragraph kt ku it kv b kw kx ju ky kz la jx lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">我们对邻近度的讨论到此结束。</p><p id="e2d0" class="pw-post-body-paragraph kt ku it kv b kw kx ju ky kz la jx lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">这个帖子的后续是<a class="ae ly" rel="noopener" target="_blank" href="/data-preprocessing-in-data-mining-machine-learning-79a9662e2eb">这里</a>。</p><div class="ov ow gp gr ox oy"><a rel="noopener follow" target="_blank" href="/data-preprocessing-in-data-mining-machine-learning-79a9662e2eb"><div class="oz ab fo"><div class="pa ab pb cl cj pc"><h2 class="bd iu gy z fp pd fr fs pe fu fw is bi translated">数据挖掘和机器学习中的数据预处理</h2><div class="pf l"><h3 class="bd b gy z fp pd fr fs pe fu fw dk translated">有了详细的概念…</h3></div><div class="pg l"><p class="bd b dl z fp pd fr fs pe fu fw dk translated">towardsdatascience.com</p></div></div><div class="ph l"><div class="qb l pj pk pl ph pm of oy"/></div></div></a></div></div><div class="ab cl ma mb hx mc" role="separator"><span class="md bw bk me mf mg"/><span class="md bw bk me mf mg"/><span class="md bw bk me mf"/></div><div class="im in io ip iq"><p id="e56c" class="pw-post-body-paragraph kt ku it kv b kw kx ju ky kz la jx lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">我将免费赠送一本关于一致性的电子书。在这里获得你的免费电子书。</p></div><div class="ab cl ma mb hx mc" role="separator"><span class="md bw bk me mf mg"/><span class="md bw bk me mf mg"/><span class="md bw bk me mf"/></div><div class="im in io ip iq"><p id="189a" class="pw-post-body-paragraph kt ku it kv b kw kx ju ky kz la jx lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">如果你喜欢阅读这样的故事，那么你应该<a class="ae ly" href="https://tarun-gupta.medium.com/subscribe" rel="noopener"> <strong class="kv iu">在你的收件箱</strong> </a>中收到我的帖子，如果你想支持我成为一名作家，考虑<a class="ae ly" href="https://tarun-gupta.medium.com/membership" rel="noopener">注册成为一名媒体成员</a>。每月 5 美元，你可以无限制地阅读媒体上的故事。如果你注册使用我的链接，我会赚一小笔佣金，不需要你额外付费。</p><div class="ov ow gp gr ox oy"><a href="https://tarun-gupta.medium.com/membership" rel="noopener follow" target="_blank"><div class="oz ab fo"><div class="pa ab pb cl cj pc"><h2 class="bd iu gy z fp pd fr fs pe fu fw is bi translated">加入我的推荐链接-塔伦古普塔</h2><div class="pf l"><h3 class="bd b gy z fp pd fr fs pe fu fw dk translated">作为一个媒体会员，你的会员费的一部分会给你阅读的作家，你可以完全接触到每一个故事…</h3></div><div class="pg l"><p class="bd b dl z fp pd fr fs pe fu fw dk translated">tarun-gupta.medium.com</p></div></div><div class="ph l"><div class="qc l pj pk pl ph pm of oy"/></div></div></a></div><p id="fb5f" class="pw-post-body-paragraph kt ku it kv b kw kx ju ky kz la jx lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">感谢阅读。如果你喜欢这个，去看看我在这个索引中的其他文章。</p><div class="ov ow gp gr ox oy"><a href="https://tarun-gupta.medium.com/thank-you-for-visiting-my-profile-9f708062c75e" rel="noopener follow" target="_blank"><div class="oz ab fo"><div class="pa ab pb cl cj pc"><h2 class="bd iu gy z fp pd fr fs pe fu fw is bi translated">标记故事列表的快速链接—感谢您的访问</h2><div class="pf l"><h3 class="bd b gy z fp pd fr fs pe fu fw dk translated">我也有一份以快节奏出版为目标的出版物。读书成为作家。</h3></div><div class="pg l"><p class="bd b dl z fp pd fr fs pe fu fw dk translated">tarun-gupta.medium.com</p></div></div></div></a></div></div></div>    
</body>
</html>