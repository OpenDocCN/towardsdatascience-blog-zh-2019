# 我用遗传算法代替深度学习反向传播(SGD)的实验

> 原文：<https://towardsdatascience.com/my-experiments-in-replacing-deep-learning-backpropagation-sgd-with-a-genetic-algorithm-c6e308382926?source=collection_archive---------19----------------------->

本文描述了我用遗传算法(GA)取代深度学习模型中的随机梯度下降(SGD)和反向传播的实验。

作为一个剧透，让我说，这些早期的实验并没有表现出接近 SGD。然而，我在结论中对此说得更多。

## 语境

出于本文的目的，我将使用下图来提供今天在训练深度学习模型时使用的突出流程。

![](img/7f7a3549ca8f1e1ab2396ba8890aec59.png)

成本函数通过比较训练结果和预期结果(基本事实)来计算误差量( ***E*** )。反过来，SGD 将更改应用于模型参数，以改进下一个训练结果。值得注意的是，模型中使用的函数必须是可微的，以便 SGD 搜索最优解。

参数更新循环继续，直到达到所需的精度(图中未显示)。

我将用 ***W*** 来表示模型参数集。深度学习模型可以轻松包含数千万(如果不是数亿)的参数。训练完成后， ***W*** 将形成训练好的模型的基础。

## 遗传算法方法概述

下图显示了 SGD 被 GA 替换，单个的 ***W*** 被群体 ***W*** 替换，我将用**[*W***来表示。

![](img/6e02fef4f04c96df7326af93f1c38754.png)

成本函数被移除，并由精度函数代替，该精度函数在 GA 术语中提供适应度函数。适合度值是给定一些标准的群体成员的适合度。适合度是一个 0 到 1 的值，0 表示最适合。我用【T24【F】来代表 **[ *W* ]每个成员的适合度。**

注意，在 GA 方法中，模型函数不必是可微的，因为 GA 不会使用函数导数来收敛于解。

## 遗传算法概述

有许多关于 GAs 的学术性和详细的书籍，例如，Goldberg 的“搜索、优化和机器学习中的遗传算法”。在这里，我会停留在(非常)高的水平。

给定一个种群 **[ *W* ]** ，以及种群中每个成员的适应度值 **[ *F* ]** ，GA 将决定下一代种群的构成。

***W***下一个=***GA***(***W****当前*，***F****当前*)

一个简单的遗传算法可以描述为:

1.  选择——将适应度作为一个偏差来配对成员
2.  组合(combination )-组合所选对以创建下一代。这也被称为交叉，父母的基因在下一代中交叉。
3.  突变——在释放新群体之前，应用(少量)随机突变

## 实验

我最初从一个简单的 XOR 问题开始，测试 GA 的流程。GA 确实相对较快地收敛于一个解决方案。然而，对于这篇文章，我将描述一个更实质性的问题。

该实验基于 TensorFlow MNIST 深度示例(mnist _ Deep . py as found the tensor flow GitHub repos)。这是一个用于识别 MNIST 手写数字数据集的深度卷积神经网络。该模型包含数千万个参数；我认为这将是一个很好的非玩具的例子。

我将所有的模型参数(权重和偏差)外化到 TensorFlow 变量中，这样就可以很容易地操纵 TensorFlow 张量之外的值。使用“feed_dict”将参数 ***W*** 载入 TensorFlow 模型图。

人口规模参数化为 ***N*** 。使用`numpy.random.randn`(平均值为 0 且方差为 1 的高斯分布)初始化*N 个起始模型中的每一个。*

*然后，对于 **[ *W* ]** 中的每个 ***W*** ，计算适应度值。要运行的代数是 ***G*** (或者直到解收敛)。*

```
*for generation = 1 to G
   for index = 1 to N
       F[index] = session.run(accuracy, feed_dict = W[index])*
```

*计算下一代***W***的过程是:*

```
*Random pairing of [W], biased towards fitter membersCrossover of each pair in [W]Random mutation of each member of [W]*
```

## *交叉*

*每个 ***W*** 由一组矩阵形成，其中每个矩阵代表机器学习模型的一部分(权重和偏差)。给定一对中的两个成员:*

```
*Wa -> [a1, a2, a3, ...] # where each a is a matrix
Wb -> [b1, b2, b3, ...] # where each b is a matrix* 
```

*有许多方法可以跨越 Wa 和 Wb。在这个实验中，我选择随机交叉相应矩阵中的元素。例如:*

```
*mask = random 0 or 1 in shape of a1
mask_inv = opposite of masknew_a1 = a1 * mask + b1 * mask_inv
new_b1 = b1 * mask + a1 * mask_invand so on for (a2,b2), (a3, b3), etc.*
```

## *变化*

*作为 GA 超参数，有一个“变异量”，但变异量本身根据当前解收敛的远近而变化。最终，我发现理解和应用突变是一个挑战。*

## *结果*

*第一张图显示了 300 代 200 人的种群规模。*

*![](img/63e0d13f3733c8e75797533f927d740e.png)*

*上图显示了每一代的最佳结果(橙色)。回想一下，MNIST 数据有 10 位数字，因此在上述范围内随机选择 0.9。随着跑步的进行，有一个明显的拉平。对于每一代，最好的模型也是根据验证数据运行的(数据放在一边，不被视为训练的一部分)。*

*尽管精确度显然不是最先进的，但在某种程度上，遗传算法能够筛选数百万个参数，并随着时间的推移创建更好的模型；都没有反向传播。*

*在同一次运行中，下图描绘了每代中最佳模型的 100 个数值。图表显示了最初的波动性和随后的稳定值:*

*![](img/4f1fd95d8c26567fd9b22e4d93117c07.png)*

*挑战在于早期的稳定会导致性能的上限，但是不稳定会导致在解决方案空间中的随机行走和没有收敛。突变的程度应该是达到平衡的一个因素。*

*下图显示了将人口规模增加到 1000 的效果。验证精度从 0.65 提高到大约 0.5。然而，验证准确性似乎在训练准确性之前趋于平稳。*

*![](img/cb7a5bd64b80b65633c58493cd8b8127.png)*

## *结论和讨论*

*公平地说，200 人甚至 1000 人的人口规模可能太小，不足以取得有意义的结果。也许人口数量应该以百万计。*

*除了人口规模，还有其他几个超参数可以考虑。一些例子是:*

1.  *排名和成对选择。有多少偏向于更适合的成员？在我的实验中，我提升了表现最好的人，这样他们的影响力就超过了严格意义上的健康水平。*
2.  *突变。变异有多大？如何应用？是否随收敛而变化？*
3.  *交叉。两个模型如何交叉？我选择在矩阵粒度上均匀交叉。两者中较强的一方应该保留更多的价值观吗？矩阵应该被分割然后连接吗？交叉是否应该定义在整个矩阵的交换上？*
4.  *批量大小。我尝试了各种批量大小，最终确定为 64。*
5.  *过度拟合。看一看 1000 人的运行，可以看到训练结果可能正在改善，而验证结果已经稳定在更高的值。*

*对我来说，接下来的步骤还没有确定，因为验证收敛的平稳化一直是一个难以克服的障碍(至少在我的计算机能力范围内，MacBook Pro 2018)。*

*如果你已经做到这一步，感谢你的关注和时间，我希望你喜欢这篇文章！*