<html>
<head>
<title>Why do Neural Networks Need an Activation Function?</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">为什么神经网络需要激活函数？</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/why-do-neural-networks-need-an-activation-function-3a5f6a5f00a?source=collection_archive---------19-----------------------#2019-07-01">https://towardsdatascience.com/why-do-neural-networks-need-an-activation-function-3a5f6a5f00a?source=collection_archive---------19-----------------------#2019-07-01</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><figure class="gl gn jo jp jq jr gh gi paragraph-image"><div class="gh gi jn"><img src="../Images/77f9133f48355c390dde7d12fe56da09.png" data-original-src="https://miro.medium.com/v2/resize:fit:1280/format:webp/0*BpLK0UQUQGjqctt5.jpg"/></div></figure><p id="63c6" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">为什么神经网络需要激活函数？每当你第一次看到一个神经网络的架构，你首先会注意到的一件事是它们有许多相互连接的层。</p><p id="44cb" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated"><strong class="jw ir">神经网络中的每一层都有一个激活函数，但为什么它们是必要的呢？为什么它们如此重要？在这里了解答案。</strong></p><h1 id="c157" class="ks kt iq bd ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp bi translated">什么是激活功能？</h1><p id="52f9" class="pw-post-body-paragraph ju jv iq jw b jx lq jz ka kb lr kd ke kf ls kh ki kj lt kl km kn lu kp kq kr ij bi translated">要回答什么是激活函数的问题，我们先退一步，回答一个更大的问题:什么是神经网络？</p><h1 id="0d09" class="ks kt iq bd ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp bi translated">什么是神经网络？</h1><p id="b253" class="pw-post-body-paragraph ju jv iq jw b jx lq jz ka kb lr kd ke kf ls kh ki kj lt kl km kn lu kp kq kr ij bi translated">神经网络是一种机器学习模型，在给定某些输入和输出向量的情况下，它会尝试将输出“拟合”到输入。</p><p id="0d0b" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">这意味着，给定一组具有我们希望预测的某些值的观察实例，以及我们关于每个实例的一些数据，它将尝试概括这些数据，以便它可以正确预测问题的新实例的值。</p><p id="df4b" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">作为一个例子，我们可能正在设计一个图像分类器(通常使用一个<a class="ae lv" href="http://www.datastuff.tech/machine-learning/convolutional-neural-networks-an-introduction-tensorflow-eager/" rel="noopener ugc nofollow" target="_blank">卷积神经网络</a>)。这里，输入是一个像素向量。输出可以是数字类别标签(例如，1 代表狗，0 代表猫)。</p><p id="95e7" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">这将训练一个神经网络来预测一幅图像是包含一只猫还是一只狗。</p><p id="910a" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">但是，给定一组像素，如果它们对应于狗的图像，则返回 1，如果对应于猫的图像，则返回 0，这是什么数学函数呢？</p><p id="a69e" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">想出一个手动的数学函数是不可能的。<strong class="jw ir">对人类来说</strong>。</p><p id="f244" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">所以我们所做的是发明一种机器来为我们找到那个功能。</p><p id="8a8a" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">它看起来像这样:</p><figure class="lx ly lz ma gt jr gh gi paragraph-image"><div class="gh gi lw"><img src="../Images/22b990c0fcee1f4386c4b226ee9ea683.png" data-original-src="https://miro.medium.com/v2/resize:fit:790/format:webp/0*jRmjehyeDenFkVOT.png"/></div><figcaption class="mb mc gj gh gi md me bd b be z dk">Single hidden layer Neural Network. <a class="ae lv" href="https://docs.opencv.org/2.4/modules/ml/doc/neural_networks.html" rel="noopener ugc nofollow" target="_blank">Source</a>.</figcaption></figure><p id="55a4" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">但是你可能已经看过这张图很多次了，认出它是为了一个神经网络，仍然不知道它到底代表了什么。</p><p id="cc75" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">在这里，每个圆圈代表我们神经网络中的一个神经元，垂直排列的神经元代表每一层。</p><h1 id="3a21" class="ks kt iq bd ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp bi translated">神经网络是如何工作的？</h1><p id="2d7e" class="pw-post-body-paragraph ju jv iq jw b jx lq jz ka kb lr kd ke kf ls kh ki kj lt kl km kn lu kp kq kr ij bi translated">神经元只是一个数学函数，它接受输入(指向它的神经元的输出)，然后<strong class="jw ir">返回输出</strong>。</p><p id="dc01" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">这些输出作为下一层的输入，以此类推，直到我们到达最终的输出层，这是我们返回的实际值。</p><p id="98b7" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">有一个输入层，其中每个神经元将简单地返回输入向量中的相应值。</p><p id="5e15" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">对于每组输入，神经网络的目标是使其每个输出<strong class="jw ir">尽可能接近实际期望值</strong>。</p><p id="e1f3" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">再次回想一下图像分类器的例子。</p><p id="ec47" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">如果我们将动物的 100x100px 图片作为输入，那么我们的输入层将有 30000 个神经元。所有像素都是 10000，乘以 3，因为一个像素已经是一个三元向量(RGB 值)。</p><p id="9f01" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">然后，我们将通过每一层运行输入。我们得到一个<strong class="jw ir">新向量作为每层的输出，将其作为输入</strong>提供给下一层，以此类推。</p><p id="f868" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">层中的每个神经元将返回单个值，因此层的输出向量将具有与层中的神经元一样多的维度。</p><p id="63bf" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">那么，给定一些输入，神经元会返回哪个值呢？</p><h1 id="c57f" class="ks kt iq bd ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp bi translated">神经元做什么？</h1><p id="c89c" class="pw-post-body-paragraph ju jv iq jw b jx lq jz ka kb lr kd ke kf ls kh ki kj lt kl km kn lu kp kq kr ij bi translated">一个神经元接受一个输入向量，并对它做三件事:</p><ul class=""><li id="1647" class="mf mg iq jw b jx jy kb kc kf mh kj mi kn mj kr mk ml mm mn bi translated">乘以一个权重向量。</li><li id="94aa" class="mf mg iq jw b jx mo kb mp kf mq kj mr kn ms kr mk ml mm mn bi translated">给乘积加上一个偏差值。</li><li id="d047" class="mf mg iq jw b jx mo kb mp kf mq kj mr kn ms kr mk ml mm mn bi translated">将<strong class="jw ir">激活函数</strong>应用于该值。</li></ul><p id="ee15" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">我们终于找到了我们业务的核心:这就是激活函数的作用。</p><p id="777e" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">我们通常使用<strong class="jw ir">非线性函数作为激活函数</strong>。这是因为线性部分已经由先前应用的乘积和加法处理。</p><h1 id="3249" class="ks kt iq bd ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp bi translated">最常用的激活功能有哪些？</h1><p id="aa90" class="pw-post-body-paragraph ju jv iq jw b jx lq jz ka kb lr kd ke kf ls kh ki kj lt kl km kn lu kp kq kr ij bi translated">我说的是非线性函数，这听起来很符合逻辑，但是什么是典型的、常用的激活函数呢？</p><p id="0ac8" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">让我们看一些例子。</p><h1 id="2cd5" class="ks kt iq bd ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp bi translated">热卢</h1><p id="adfa" class="pw-post-body-paragraph ju jv iq jw b jx lq jz ka kb lr kd ke kf ls kh ki kj lt kl km kn lu kp kq kr ij bi translated">ReLU 代表“校正线性单位”。</p><p id="c1d6" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">在所有激活函数中，这是<strong class="jw ir">最类似于线性函数</strong>的一个:</p><ul class=""><li id="7eff" class="mf mg iq jw b jx jy kb kc kf mh kj mi kn mj kr mk ml mm mn bi translated">对于非负值，它只应用标识。</li><li id="3994" class="mf mg iq jw b jx mo kb mp kf mq kj mr kn ms kr mk ml mm mn bi translated">对于负值，它返回 0。</li></ul><p id="d9e7" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">用数学术语来说，</p><figure class="lx ly lz ma gt jr gh gi paragraph-image"><div class="gh gi mt"><img src="../Images/371d135783a0935f9c787bcd71a5ffbf.png" data-original-src="https://miro.medium.com/v2/resize:fit:266/format:webp/0*_HZ9xRVv9WeUP7HA.png"/></div></figure><p id="7e21" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">这意味着所有负值都将变为 0，而其余值保持不变。</p><figure class="lx ly lz ma gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="mv mw di mx bf my"><div class="gh gi mu"><img src="../Images/f00aa1bb2032062387bda00641c3f787.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*n9edLWjCUcRb-a3v.png"/></div></div></figure><p id="97bb" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">这是一个受生物启发的功能，因为大脑中的神经元要么“激发”(返回正值)，要么不激发(返回 0)。</p><p id="48a7" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">注意如何与偏差结合，这实际上<strong class="jw ir">过滤掉低于某个阈值</strong>的任何值。</p><p id="620f" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">假设我们的偏差的值为-b。任何低于 b 的输入值，在加上偏差后将变成负值。在对其应用 ReLU 后，它变为 0。</p><h1 id="757c" class="ks kt iq bd ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp bi translated">乙状结肠的</h1><p id="c65f" class="pw-post-body-paragraph ju jv iq jw b jx lq jz ka kb lr kd ke kf ls kh ki kj lt kl km kn lu kp kq kr ij bi translated">sigmoid 函数将任意实数作为输入，<strong class="jw ir">返回 0 和 1 </strong>之间的值。由于它是连续的，它有效地"<strong class="jw ir"> smushes </strong>"值:</p><p id="8bc4" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">如果你把 sigmoid 应用于 3，你会得到 0.95。将它应用到 10，你得到 0.999…它会一直接近 1，但永远不会达到 1。</p><p id="b0b1" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">同样的情况发生在负方向，除了它收敛到 0。</p><p id="b9c5" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">这是 sigmoid 函数的数学公式。</p><figure class="lx ly lz ma gt jr gh gi paragraph-image"><div class="gh gi mz"><img src="../Images/8ae4b5e7e91ec1539069d1491b031625.png" data-original-src="https://miro.medium.com/v2/resize:fit:238/format:webp/0*cFjqP1ztAkAz8B4A.png"/></div></figure><p id="0eae" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">如你所见，当 x 趋近于无穷大时，它趋近于 1，当 x 趋近于负无穷大时，它趋近于 0。</p><p id="3a6d" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">它也是对称的，当其输入为 0 时，其值为 1/2。</p><figure class="lx ly lz ma gt jr gh gi paragraph-image"><div class="gh gi na"><img src="../Images/86fb90d0ba82828ea4c66f1d9ecefba1.png" data-original-src="https://miro.medium.com/v2/resize:fit:640/format:webp/0*xW3Mc8rvAvWFrYB_.png"/></div></figure><p id="9206" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">因为它取 0 到 1 之间的值，所以如果您想对概率建模，这个函数作为输出是非常有用的。</p><p id="d25a" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">如果你希望应用一个“过滤器”来部分保留某个值(就像在一个<a class="ae lv" href="http://www.datastuff.tech/machine-learning/lstm-how-to-train-neural-networks-to-write-like-lovecraft/" rel="noopener ugc nofollow" target="_blank"> LSTM 的遗忘之门</a>中)，这也是有帮助的。</p><h1 id="f185" class="ks kt iq bd ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp bi translated">为什么神经网络需要激活函数？</h1><p id="80a1" class="pw-post-body-paragraph ju jv iq jw b jx lq jz ka kb lr kd ke kf ls kh ki kj lt kl km kn lu kp kq kr ij bi translated">我们已经讨论了一些不同激活函数在不同情况下的应用。</p><p id="61af" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">一些让信号通过或阻挡它，另一些过滤它的强度。甚至还有<a class="ae lv" href="https://en.wikipedia.org/wiki/Hyperbolic_function" rel="noopener ugc nofollow" target="_blank"> tanh </a>激活函数:它不是过滤，而是将输入变成负值或正值。</p><p id="2aae" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">但是为什么我们的神经网络需要激活功能呢？<strong class="jw ir">如果我们不用它们会怎么样</strong>？</p><p id="0abd" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">我在 Yoshua Bengio 的令人敬畏的<a class="ae lv" href="https://amzn.to/305g2MF" rel="noopener ugc nofollow" target="_blank">深度学习书籍</a>中找到了这个问题的解释，我认为它在那里得到了完美的解释。</p><p id="7e0f" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">我们可以让每个神经元简单地返回它们的结果，而不是用非线性函数组合我们的线性变换(实际上是用同一性组合它们)。</p><p id="0314" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">但是，我们所有的层将简单地堆叠一个又一个仿射(乘积加加法)变换。每一层只需在前一层的基础上增加一个矢量积和矢量加法。</p><p id="d65e" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">可以证明(你甚至可以说服自己，如果你在白板上用一个小向量来计算)，这个仿射变换的组合，等价于一个单独的仿射变换。</p><p id="234f" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">实际上，整个“神经网络”中所有的激活函数都被恒等式所取代，这个“神经网络”只不过是一个矢量积和一个偏差加法。</p><p id="fdc4" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">有许多问题是线性变换无法解决的，所以我们实际上是在<strong class="jw ir">减少我们的模型能够估计的函数的数量。</strong></p><p id="6c72" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">作为一个非常简单但却惊天动地的例子，考虑 XOR 运算符。</p><figure class="lx ly lz ma gt jr gh gi paragraph-image"><div class="ab gu cl nb"><img src="../Images/638a3c38c46c5f772a331a943cf240ca.png" data-original-src="https://miro.medium.com/v2/format:webp/1*FDAAQeaaE8s_Il8K9llr8w.png"/></div></figure><p id="3c65" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">试着找一个二元向量，加上一个可以取 x1 和 x2 的 bias，把它们变成 x1 XOR x2。去吧，我等着。</p><p id="9149" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi">…</p><p id="e597" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">没错，你不能。没人能。然而，考虑一下</p><figure class="lx ly lz ma gt jr gh gi paragraph-image"><div class="gh gi nc"><img src="../Images/e6227b6bad7163b72233b60a8372cddf.png" data-original-src="https://miro.medium.com/v2/resize:fit:614/format:webp/0*_Vh988l6o4Jto5Vr.png"/></div></figure><p id="6d7d" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">如果你计算一下，你会看到对于 1 和 0 的每个可能的组合都有期望的输出。</p><p id="eed5" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">恭喜你！你刚刚训练了你的第一个神经网络！</p><p id="819b" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">它学会了一个线性模型永远学不会的问题。</p><h1 id="e70b" class="ks kt iq bd ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp bi translated">结论</h1><p id="8d76" class="pw-post-body-paragraph ju jv iq jw b jx lq jz ka kb lr kd ke kf ls kh ki kj lt kl km kn lu kp kq kr ij bi translated">我希望在这个解释之后，你现在能更好地理解为什么神经网络需要一个激活函数。</p><p id="221b" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">在以后的文章中，我可能会涉及其他激活函数及其用途，比如 SoftMax 和有争议的 Cos。</p><p id="298c" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">你觉得怎么样？你从这篇文章中学到什么了吗？你觉得有趣吗？数学关了吗？</p><p id="54ab" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">如果你想对我说什么或问什么，请随时在<a class="ae lv" href="http://www.twitter.com/strikingloo" rel="noopener ugc nofollow" target="_blank"> Twitter </a>、<a class="ae lv" href="http://www.medium.com/@strikingloo" rel="noopener"> Medium </a>或<a class="ae lv" href="http://www.dev.to/strikingloo" rel="noopener ugc nofollow" target="_blank"> dev.to </a>上联系我！</p><p id="ed2e" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated"><em class="nd">如果你想成为一名数据科学家，可以看看我的</em> <a class="ae lv" href="http://www.datastuff.tech/data-science/3-machine-learning-books-that-helped-me-level-up-as-a-data-scientist/" rel="noopener ugc nofollow" target="_blank"> <em class="nd">最佳机器学习书籍</em> </a> <em class="nd">清单和我的</em> <a class="ae lv" href="http://www.datastuff.tech/programming/terminal-tutorial-more-productive/" rel="noopener ugc nofollow" target="_blank"> <em class="nd"> Bash 教程</em> </a> <em class="nd">。</em></p></div><div class="ab cl ne nf hu ng" role="separator"><span class="nh bw bk ni nj nk"/><span class="nh bw bk ni nj nk"/><span class="nh bw bk ni nj"/></div><div class="ij ik il im in"><p id="bf31" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated"><em class="nd">原载于 2019 年 7 月 1 日</em><a class="ae lv" href="http://www.datastuff.tech/machine-learning/why-do-neural-networks-need-an-activation-function/" rel="noopener ugc nofollow" target="_blank"><em class="nd">http://www . data stuff . tech</em></a><em class="nd">。</em></p></div></div>    
</body>
</html>