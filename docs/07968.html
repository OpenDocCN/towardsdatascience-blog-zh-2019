<html>
<head>
<title>Cityscape Image Segmentation With TensorFlow 2.0</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">基于 TensorFlow 2.0 的城市景观图像分割</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/cityscape-segmentation-with-tensorflow-2-0-b320b6605cbf?source=collection_archive---------7-----------------------#2019-11-03">https://towardsdatascience.com/cityscape-segmentation-with-tensorflow-2-0-b320b6605cbf?source=collection_archive---------7-----------------------#2019-11-03</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><h2 id="42f1" class="ir is it bd b dl iu iv iw ix iy iz dk ja translated" aria-label="kicker paragraph">🤖<a class="ae ep" href="https://equipintelligence.medium.com/list/deep-learning-techniques-methods-and-how-tos-01015cf5f917" rel="noopener">深度学习</a></h2><div class=""/><div class=""><h2 id="3500" class="pw-subtitle-paragraph jz jc it bd b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq dk translated">基于 UNet 架构的图像分割。</h2></div><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi kr"><img src="../Images/37ee08f21e89f339cc301fa86542bfb7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*HbaHvX8syDfkB2PX"/></div></div><figcaption class="ld le gj gh gi lf lg bd b be z dk">Photo by <a class="ae lh" href="https://unsplash.com/@andreacau?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Andrea Cau</a> on <a class="ae lh" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><p id="27f6" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">图像分割是在各种计算机视觉应用中使用的检测技术。我们实际上“分割”了图像中我们感兴趣的部分。在这个故事中，我们将为<a class="ae lh" href="https://www.analyticsvidhya.com/blog/2019/02/tutorial-semantic-segmentation-google-deeplab/" rel="noopener ugc nofollow" target="_blank">语义分割</a>创建一个<a class="ae lh" href="https://arxiv.org/abs/1505.04597" rel="noopener ugc nofollow" target="_blank"> UNet </a>模型(不要与实例分割混淆😕 ).</p><p id="5a64" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">你可以在这里查看这个故事的实现--&gt;</p><div class="mf mg gp gr mh mi"><a href="https://colab.research.google.com/drive/1i-7Vn_9hGdOvMjkYNedK5nsonNizhe0o#scrollTo=l8WavclxY7ec&amp;forceEdit=true&amp;sandboxMode=true" rel="noopener  ugc nofollow" target="_blank"><div class="mj ab fo"><div class="mk ab ml cl cj mm"><h2 class="bd jd gy z fp mn fr fs mo fu fw jc bi translated">城市景观 _ 图像 _ 分割</h2><div class="mp l"><p class="bd b dl z fp mn fr fs mo fu fw dk translated">colab.research.google.com</p></div></div><div class="mq l"><div class="mr l ms mt mu mq mv lb mi"/></div></div></a></div><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="mw mx l"/></div></figure><h1 id="c07d" class="my mz it bd na nb nc nd ne nf ng nh ni ki nj kj nk kl nl km nm ko nn kp no np bi translated">UNet 的架构怎么样？</h1><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="nq mx l"/></div><figcaption class="ld le gj gh gi lf lg bd b be z dk">😴 Implementing Faster RCNN from scratch! ( For me at least… )</figcaption></figure><p id="a636" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">如果您使用 TensorFlow Keras 或 PyTorch，实现 UNet 可能会更容易一些。简单来说，</p><blockquote class="nr"><p id="d849" class="ns nt it bd nu nv nw nx ny nz oa md dk translated">UNet 具有编码器-解码器类型的结构。编码器接收图像，对图像执行各种卷积和最大池操作，并构建图像的潜在表示。现在，解码器获取这种表示，并对图像进行上采样(在跳过连接的帮助下)，最终为我们提供分段掩码。</p></blockquote><p id="6b89" class="pw-post-body-paragraph li lj it lk b ll ob kd ln lo oc kg lq lr od lt lu lv oe lx ly lz of mb mc md im bi translated">UNet 与卷积自动编码器的不同之处在于它有<strong class="lk jd">跳跃连接😎</strong>。跳过连接顾名思义(<em class="me">也许；-) </em>)为解码器保存空间信息。通常，编码器将图像分解成高维张量(如形状<em class="me">【8，8，256】</em>)。这可能会导致一些重要功能的丢失。当我们把图像输入编码器时。在每次最大池操作(在编码器中)之后，我们存储操作的结果。现在，当我们在解码器中执行转置卷积时，我们将之前的输出(来自解码器)和之前存储在编码器部分的相应张量连接起来。解码器接收原始图像的一些元数据来构造遮罩。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi kr"><img src="../Images/f9dedf133a092c48565ad4b6f9541088.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*3FGS0kEAS55XmqxIXkp0mQ.png"/></div></div><figcaption class="ld le gj gh gi lf lg bd b be z dk">A <strong class="bd og">creepy</strong> 👽 drawing of a UNet!</figcaption></figure><p id="9e4b" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">在 Keras，我们有<code class="fe oh oi oj ok b">Con2D</code>、<code class="fe oh oi oj ok b">Con2DTranspose</code>、<code class="fe oh oi oj ok b">MaxPooling2D</code>和<code class="fe oh oi oj ok b">UpSampling2D</code>层，让您的生活更轻松。但是我们将使用原始的 TensorFlow 2.0 APIs 来创建模型。</p><blockquote class="nr"><p id="b713" class="ns nt it bd nu nv nw nx ny nz oa md dk translated">也许这个模型被命名为“UNet ”,是因为使用跳跃连接得到了一些 U 形。让我们把这留给发明家吧！😅</p></blockquote><h1 id="ff8d" class="my mz it bd na nb nc nd ne nf ng nh ni ki ol kj nk kl om km nm ko on kp no np bi translated">讨论数据</h1><p id="694b" class="pw-post-body-paragraph li lj it lk b ll oo kd ln lo op kg lq lr oq lt lu lv or lx ly lz os mb mc md im bi translated">我们的数据集来自于<a class="ae lh" href="https://www.kaggle.com/" rel="noopener ugc nofollow" target="_blank"> Kaggle </a>上<a class="ae lh" href="https://www.kaggle.com/dansbecker" rel="noopener ugc nofollow" target="_blank"> DanB </a>的<a class="ae lh" href="https://www.kaggle.com/dansbecker/cityscapes-image-pairs" rel="noopener ugc nofollow" target="_blank">城市景观图像对</a>。这些图像看起来像，</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi ot"><img src="../Images/1f10635d76fd098a6e667f5b590f99dd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*BqXYDyuuTzQQcdn058gsgQ.png"/></div></div><figcaption class="ld le gj gh gi lf lg bd b be z dk">Sample images from the dataset.</figcaption></figure><p id="3010" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">右边部分是遮罩，左边部分是实际图像。我们将使用 Pillow 用<code class="fe oh oi oj ok b">ImageOps</code>分割这些图像。</p><p id="b6c3" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">数据集具有不同类别的多个掩膜，它们具有各自的颜色。为了简单起见，我们只尝试分割图像中的“道路”。请注意，道路的 RGB 颜色为(128，63，126)。我们的模型将输出一个二进制掩码，只包含 1 和 0。我们的输入图像将是(128，128，3)形状的图像，目标将是(128，128，1)形状的遮罩。因此，RGB 值为(128，63，126)的像素在目标蒙版中将具有值 1。所有其他像素将保持值 0。</p><h1 id="e1aa" class="my mz it bd na nb nc nd ne nf ng nh ni ki nj kj nk kl nl km nm ko nn kp no np bi translated">准备行动！</h1><p id="41fc" class="pw-post-body-paragraph li lj it lk b ll oo kd ln lo op kg lq lr oq lt lu lv or lx ly lz os mb mc md im bi translated">我们将为四个操作定义方法:</p><ol class=""><li id="26df" class="ou ov it lk b ll lm lo lp lr ow lv ox lz oy md oz pa pb pc bi translated"><code class="fe oh oi oj ok b">conv2d_down</code>:常规卷积和泄漏 ReLU 激活。</li><li id="b8e7" class="ou ov it lk b ll pd lo pe lr pf lv pg lz ph md oz pa pb pc bi translated"><code class="fe oh oi oj ok b">maxpool_down</code>:有效填充的最大池操作。</li><li id="c368" class="ou ov it lk b ll pd lo pe lr pf lv pg lz ph md oz pa pb pc bi translated"><code class="fe oh oi oj ok b">conv2d_up</code>:对图像进行上采样的转置卷积。</li><li id="c696" class="ou ov it lk b ll pd lo pe lr pf lv pg lz ph md oz pa pb pc bi translated"><code class="fe oh oi oj ok b">maxpool_up</code>:像<code class="fe oh oi oj ok b">UpSampling2D</code> Keras 图层一样对输入进行上采样。</li></ol><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="mw mx l"/></div><figcaption class="ld le gj gh gi lf lg bd b be z dk">Snippet 1</figcaption></figure><p id="95cd" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">我们将使用<a class="ae lh" href="https://www.tensorflow.org/api_docs/python/tf/keras/initializers/GlorotUniform" rel="noopener ugc nofollow" target="_blank"> Glorot 统一初始化器</a>为我们的 UNet 创建一些权重，</p><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="mw mx l"/></div><figcaption class="ld le gj gh gi lf lg bd b be z dk">Snippet 2</figcaption></figure><p id="e046" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">我们现在准备组装最终模型。</p><h1 id="a67e" class="my mz it bd na nb nc nd ne nf ng nh ni ki nj kj nk kl nl km nm ko nn kp no np bi translated">制作 UNet 模型</h1><p id="6f41" class="pw-post-body-paragraph li lj it lk b ll oo kd ln lo op kg lq lr oq lt lu lv or lx ly lz os mb mc md im bi translated">用我们之前创建的所有操作组装 UNet 模型。</p><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="mw mx l"/></div><figcaption class="ld le gj gh gi lf lg bd b be z dk">Snippet 3</figcaption></figure><p id="7ecf" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">注意到<code class="fe oh oi oj ok b">tf.concat()</code>操作了吗？这是我们实际连接上一层(解码器)和跳过连接(编码器)输出的地方。</p><p id="9683" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated"><code class="fe oh oi oj ok b">model()</code>接收输入，将其通过 UNet，并返回 sigmoid 激活的输出。🆒</p><h1 id="aeea" class="my mz it bd na nb nc nd ne nf ng nh ni ki nj kj nk kl nl km nm ko nn kp no np bi translated">培训和优化</h1><p id="2969" class="pw-post-body-paragraph li lj it lk b ll oo kd ln lo op kg lq lr oq lt lu lv or lx ly lz os mb mc md im bi translated">我们使用<a class="ae lh" href="https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/Adam" rel="noopener ugc nofollow" target="_blank"> Adam optimizer </a>和<a class="ae lh" href="https://www.tensorflow.org/api_docs/python/tf/keras/losses/BinaryCrossentropy" rel="noopener ugc nofollow" target="_blank">二元交叉熵</a>损失函数来优化我们的模型(还记得最后一层的 sigmoid 激活吗？).</p><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="mw mx l"/></div><figcaption class="ld le gj gh gi lf lg bd b be z dk">Snippet 4</figcaption></figure><p id="e997" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">我们现在准备训练模型。我们将为我们在数据集中创建的每个批处理调用<code class="fe oh oi oj ok b">train()</code>方法。</p><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="mw mx l"/></div><figcaption class="ld le gj gh gi lf lg bd b be z dk">Snippet 5</figcaption></figure><p id="9e1f" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">您将找到一个代码单元来为笔记本中的图像生成遮罩。经过 25 个时期的训练，结果😂是来验证数据集的。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi pi"><img src="../Images/1fc10236e9849466ad1b6c61a9219cdc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*6br5LS4IC2c0RpPe10lWvQ.png"/></div></div><figcaption class="ld le gj gh gi lf lg bd b be z dk">The Results!</figcaption></figure><h1 id="1753" class="my mz it bd na nb nc nd ne nf ng nh ni ki nj kj nk kl nl km nm ko nn kp no np bi translated">还有呢！</h1><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="mw mx l"/></div></figure><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="mw mx l"/></div></figure><h1 id="8627" class="my mz it bd na nb nc nd ne nf ng nh ni ki nj kj nk kl nl km nm ko nn kp no np bi translated">仅此而已！</h1><p id="3249" class="pw-post-body-paragraph li lj it lk b ll oo kd ln lo op kg lq lr oq lt lu lv or lx ly lz os mb mc md im bi translated">希望这很有趣。机器学习快乐！</p></div></div>    
</body>
</html>