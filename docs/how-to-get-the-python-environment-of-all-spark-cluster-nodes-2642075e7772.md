# 如何获取所有 Spark 集群节点的 Python 环境

> 原文：<https://towardsdatascience.com/how-to-get-the-python-environment-of-all-spark-cluster-nodes-2642075e7772?source=collection_archive---------28----------------------->

![](img/3feb5525dbcb760b2a161f054cf0a7ac.png)

我们在 [Invenium](https://invenium.io/) 对匿名手机位置数据进行分析时，使用了 Apache Spark **等工具。**在我们的应用程序中，我们直接使用 Java API 和 Python API `pyspark`进行接口。最近，我们注意到在运行我们的算法时出现了不寻常的性能下降。

在确保我们没有对代码进行任何可能导致性能变化的更改后，我们给集群维护人员发了电子邮件，检查他们那边是否有任何更改。据他们说，除了增加几个新节点外，没有任何变化。然后，我们开始检查调度程序，发现一些节点以正常速度处理任务，而其他节点则慢得令人痛苦。这使我们对新增加的工人产生了怀疑。可能它们的某些配置与现有基础架构不同。

## 但是如何调试不可访问的节点呢？

由于只能直接访问边缘节点，而不能访问工作节点，因此我们想出了一个能够在工作节点上自省 Python 环境的简短脚本:

Code to query print the environment on worker nodes

据我们所知，没有安全的方法来确保脚本在所有节点上运行，因为这依赖于调度程序。作为一种变通方法，下面的代码在`NUMBER_OF_PARTITIONS = 10_000`分区中启动`NUMBER_OF_OPERATIONS = 100_000`操作，这些操作通常应该(假设集群上没有太多其他负载)平均分布在工作节点中。根据集群大小和当前负载，您可以尝试增加这些值和/或多次运行脚本，以确保它在每个工作线程上至少执行一次。

## 我们发现的窃听器

我们发现所有节点上都安装了相同的软件包，但是，在较新的节点上，一些软件包的版本有所不同。即使情况不应该是这样——您会希望在相同的集群节点上有不同的版本吗？—只要主要版本保持不变，这通常不是问题。但是你永远不应该抛开墨菲定律。不幸的是，包含一个性能错误的`pyproj`的最新版本恰好在补丁发布前几天安装，导致转换慢得多，从而导致观察到的性能下降。

我们希望这可以帮助其他人调试不可访问的集群基础设施。