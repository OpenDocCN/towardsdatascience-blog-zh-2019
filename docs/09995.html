<html>
<head>
<title>Training on batch: how do you split the data?</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">批量训练:如何拆分数据？</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/training-on-batch-how-to-split-data-effectively-3234f3918b07?source=collection_archive---------39-----------------------#2019-12-30">https://towardsdatascience.com/training-on-batch-how-to-split-data-effectively-3234f3918b07?source=collection_archive---------39-----------------------#2019-12-30</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><p id="81a7" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><em class="ko">三种将你的数据分割成批的方法，比较时间&amp;内存效率和代码质量。</em></p><h1 id="e906" class="kp kq it bd kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm bi translated">介绍</h1><p id="a9f9" class="pw-post-body-paragraph jq jr it js b jt ln jv jw jx lo jz ka kb lp kd ke kf lq kh ki kj lr kl km kn im bi translated">随着数据量的增加，训练机器学习模型的一种常见方法是对批处理应用所谓的<em class="ko">训练。这种方法包括将数据集分割成一系列较小的数据块，一次一个地传递给模型。</em></p><p id="a5f1" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">在本帖中，我们将提出<strong class="js iu">三个想法</strong>来拆分批量数据集:</p><ul class=""><li id="933d" class="ls lt it js b jt ju jx jy kb lu kf lv kj lw kn lx ly lz ma bi translated">创造了一个“大”张量，</li><li id="e321" class="ls lt it js b jt mb jx mc kb md kf me kj mf kn lx ly lz ma bi translated">用 HDF5 加载部分数据，</li><li id="3655" class="ls lt it js b jt mb jx mc kb md kf me kj mf kn lx ly lz ma bi translated">python 生成器。</li></ul><p id="c924" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">出于说明的目的，我们将假设该模型是一个基于声音的检测器，但本文中的分析是通用的。尽管这个例子是作为一种特殊情况来设计的，但这里讨论的步骤本质上是对数据进行<strong class="js iu">分割、预处理</strong>和<strong class="js iu">迭代</strong>。它符合普通程序。不管图像文件、来自 SQL 查询的表或 HTTP 响应的数据是什么，我们主要关心的是过程。</p><p id="7512" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">具体来说，我们将从以下几个方面比较我们的方法:</p><ul class=""><li id="1c54" class="ls lt it js b jt ju jx jy kb lu kf lv kj lw kn lx ly lz ma bi translated">代码质量，</li><li id="127e" class="ls lt it js b jt mb jx mc kb md kf me kj mf kn lx ly lz ma bi translated">内存占用，</li><li id="c1b4" class="ls lt it js b jt mb jx mc kb md kf me kj mf kn lx ly lz ma bi translated">时间效率。</li></ul><h1 id="f713" class="kp kq it bd kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm bi translated">什么是批？</h1><p id="e5de" class="pw-post-body-paragraph jq jr it js b jt ln jv jw jx lo jz ka kb lp kd ke kf lq kh ki kj lr kl km kn im bi translated">形式上，批处理被理解为输入输出对<code class="fe mg mh mi mj b">(X[i], y[i])</code>，是数据的子集。由于我们的模型是一个基于声音的检测器，它期望一个经过<em class="ko">处理的</em>音频序列作为输入，并返回某个事件发生的概率。很自然，在我们的例子中，该批次包括:</p><ul class=""><li id="1775" class="ls lt it js b jt ju jx jy kb lu kf lv kj lw kn lx ly lz ma bi translated"><code class="fe mg mh mi mj b">X[t]</code> -表示在时间窗口内采样的处理过的音轨的矩阵，以及</li><li id="96dd" class="ls lt it js b jt mb jx mc kb md kf me kj mf kn lx ly lz ma bi translated"><code class="fe mg mh mi mj b">y[t]</code> -表示事件存在的二元标签，</li></ul><p id="0e61" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">其中<code class="fe mg mh mi mj b">t</code>表示时间窗(图 1。).</p><figure class="ml mm mn mo gt mp gh gi paragraph-image"><div role="button" tabindex="0" class="mq mr di ms bf mt"><div class="gh gi mk"><img src="../Images/f19373a6ca55d63b00de1fcf23e133f4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*g3ewdAOXBO5-OquQ.png"/></div></div><figcaption class="mw mx gj gh gi my mz bd b be z dk">Figure 1. An example of data input. Top: simple binary label (random), middle: raw audio channel (mono), bottom: spectrogram represented as naural logarithm of the spectrum. The vertical lines represent slicing of the sequence into batches of 1 second length.</figcaption></figure><h1 id="2241" class="kp kq it bd kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm bi translated">光谱图</h1><p id="98f8" class="pw-post-body-paragraph jq jr it js b jt ln jv jw jx lo jz ka kb lp kd ke kf lq kh ki kj lr kl km kn im bi translated">至于声谱图，你可以把它看作是一种描述每首“曲子”在音轨中所占比重的方式。例如，当演奏低音吉他时，声谱图会显示更集中在频谱较低一侧的高强度。相反，对于女高音歌手，我们会观察到相反的情况。通过这种“编码”，谱图自然地代表了模型的有用特征。</p><h1 id="d0a4" class="kp kq it bd kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm bi translated">比较想法</h1><p id="6f10" class="pw-post-body-paragraph jq jr it js b jt ln jv jw jx lo jz ka kb lp kd ke kf lq kh ki kj lr kl km kn im bi translated">作为我们比较的一个共同前提，让我们简单定义以下导入和常量。</p><pre class="ml mm mn mo gt na mj nb nc aw nd bi"><span id="3861" class="ne kq it mj b gy nf ng l nh ni">from scipy.signal import spectrogram<br/>from os.path import join<br/>from math import ceil<br/>import numpy as np<br/><br/><br/>FILENAME = 'test'<br/>FILEPATH = 'data'<br/>CHANNEL  = 0        # mono track only<br/>SAMPLING = 8000     # sampling rate (audio at 8k samples per s)<br/>NFREQS   = 512      # 512 frequencies for the spectrogram<br/>NTIMES   = 400      # 400 time-points for the spectrogram<br/>SLEN     = 1        # 1 second of audio for a batch<br/><br/>N = lambda x: (x - x.mean())/x.std() # normalization<br/><br/>filename = join(FILEPATH, FILENAME)</span></pre><p id="d76d" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">这里的数字有些随意。我们决定采用最低采样率(其他常见值为 16k 和 22.4k fps)，并让每个<code class="fe mg mh mi mj b">X</code>组块成为 512 个频率通道的频谱图，该频谱图是使用沿时间轴的 400 个数据点从 1 的非重叠音频序列计算的。换句话说，每一批将是一对一个<strong class="js iu"> 512 乘 400 的矩阵</strong>，加上一个二进制标签。</p><h1 id="3f08" class="kp kq it bd kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm bi translated">想法 1——一个“大”张量</h1><p id="8226" class="pw-post-body-paragraph jq jr it js b jt ln jv jw jx lo jz ka kb lp kd ke kf lq kh ki kj lr kl km kn im bi translated">模型的输入是一个二维张量。由于最后一步涉及批次的迭代，因此<em class="ko">增加张量的秩</em>并为批次计数保留第三维是有意义的。因此，整个过程可以概括如下:</p><ol class=""><li id="10da" class="ls lt it js b jt ju jx jy kb lu kf lv kj lw kn nj ly lz ma bi translated">加载<code class="fe mg mh mi mj b">x</code>-数据。</li><li id="3ff3" class="ls lt it js b jt mb jx mc kb md kf me kj mf kn nj ly lz ma bi translated">加载<code class="fe mg mh mi mj b">y</code>标签。</li><li id="5dc1" class="ls lt it js b jt mb jx mc kb md kf me kj mf kn nj ly lz ma bi translated">将<code class="fe mg mh mi mj b">X</code>和<code class="fe mg mh mi mj b">y</code>分批切片。</li><li id="8014" class="ls lt it js b jt mb jx mc kb md kf me kj mf kn nj ly lz ma bi translated">提取每一批的特征(这里是谱图)。</li><li id="aa25" class="ls lt it js b jt mb jx mc kb md kf me kj mf kn nj ly lz ma bi translated">将<code class="fe mg mh mi mj b">X[t]</code>和<code class="fe mg mh mi mj b">y[t]</code>放在一起。</li></ol><p id="5d6b" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">为什么这不是个好主意？让我们看一个实现的例子。</p><pre class="ml mm mn mo gt na mj nb nc aw nd bi"><span id="2d63" class="ne kq it mj b gy nf ng l nh ni">def create_X_tensor(audio, fs, slen=SLEN, bsize=(NFREQS, NTIMES)):<br/>    X = np.zeros((n_batches, bsize[0], bsize[1]))<br/><br/>    for bn in range(n_batches):<br/>        aslice = slice(bn*slen*fs, (bn + 1)*slen*fs)<br/>        *_, spec = spectrogram(<br/>                N(audio(aslice)), <br/>                fs       = fs, <br/>                nperseg  = int(fs/bsize[1]),<br/>                noverlap = 0,<br/>                nfft     = bsize[0])<br/>        X[bn, :, :spec.shape[1]] = spec<br/>    return np.log(X + 1e-6) # to avoid -Inf<br/><br/>def get_batch(X, y, bn):<br/>    return X[bn, :, :], y[bn]<br/><br/><br/>if __name__ == '__main__':<br/>    audio = np.load(filename + '.npy')[:, CHANNEL]<br/>    label = np.load(filename + '-lbl.npy')<br/><br/>    X = create_X_tensor(audio, SAMPLING)<br/>    for t in range(X.shape[0]):<br/>        batch = get_batch(X, y, t)<br/>        print ('Batch #{}, shape={}, label={}'.format(<br/>            t, X.shape, y[i]))</span></pre><p id="9ccb" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">这种方法的本质可以被描述为<strong class="js iu">现在全部加载，以后再担心。</strong></p><p id="d82f" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">虽然创建<code class="fe mg mh mi mj b">X</code>一个自包含的数据块可以被视为一个优点，但这种方法也有<em class="ko">缺点</em>:</p><ol class=""><li id="43ee" class="ls lt it js b jt ju jx jy kb lu kf lv kj lw kn nj ly lz ma bi translated">我们将所有数据导入 RAM，不管 RAM 是否能存储这些数据。</li><li id="617d" class="ls lt it js b jt mb jx mc kb md kf me kj mf kn nj ly lz ma bi translated">我们使用第一维度<code class="fe mg mh mi mj b">X</code>进行批次计数。然而，这仅仅是基于一个<em class="ko">惯例</em>。如果下一次有人决定应该是最后一次呢？</li><li id="a19c" class="ls lt it js b jt mb jx mc kb md kf me kj mf kn nj ly lz ma bi translated">尽管<code class="fe mg mh mi mj b">X.shape[0]</code>准确地告诉我们有多少批次，我们仍然需要创建一个辅助变量<code class="fe mg mh mi mj b">t</code>来帮助我们跟踪批次。这个设计强制模型训练代码遵守这个决定。</li><li id="4ec8" class="ls lt it js b jt mb jx mc kb md kf me kj mf kn nj ly lz ma bi translated">最后，它要求定义<code class="fe mg mh mi mj b">get_batch</code>函数。其唯一目的是选择<code class="fe mg mh mi mj b">X</code>和<code class="fe mg mh mi mj b">y</code>的子集，并将它们整理在一起。它看起来充其量是不受欢迎的。</li></ol><h1 id="f29d" class="kp kq it bd kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm bi translated">想法 2——使用 HDF5 加载批次</h1><p id="894b" class="pw-post-body-paragraph jq jr it js b jt ln jv jw jx lo jz ka kb lp kd ke kf lq kh ki kj lr kl km kn im bi translated">让我们从消除最可怕的问题开始，即将所有数据加载到 RAM 中。如果数据来自一个文件，那么只加载它的一部分并对这些部分进行操作是有意义的。</p><p id="c1a7" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">使用来自<a class="ae nk" href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_csv.html" rel="noopener ugc nofollow" target="_blank">熊猫的</a> <code class="fe mg mh mi mj b"><a class="ae nk" href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_csv.html" rel="noopener ugc nofollow" target="_blank">read_csv</a></code>的<code class="fe mg mh mi mj b">skiprows</code>和<code class="fe mg mh mi mj b">nrows</code>参数，可以加载. csv 文件的片段。然而，由于 CSV 格式对于存储声音数据来说相当不切实际，<a class="ae nk" href="https://support.hdfgroup.org/HDF5/" rel="noopener ugc nofollow" target="_blank">分层数据格式(HDF5) </a>是更好的选择。这种格式允许我们存储多个类似 numpy 的数组，并以类似 numpy 的方式访问它们。</p><p id="2d33" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">这里，我们假设文件包含名为<code class="fe mg mh mi mj b">'audio'</code>和<code class="fe mg mh mi mj b">'label'</code>的固有数据集。更多信息请查看 Python <a class="ae nk" href="https://docs.h5py.org/en/stable/" rel="noopener ugc nofollow" target="_blank"> h5py </a>库。</p><pre class="ml mm mn mo gt na mj nb nc aw nd bi"><span id="a732" class="ne kq it mj b gy nf ng l nh ni">def get_batch(filepath, t, slen=SLEN, bsize=(NFREQS, NTIMES)):<br/>    with h5.File(filepath + '.h5', 'r') as f:<br/>        fs    = f['audio'].attrs['sampling_rate']<br/>        audio = f['audio'][t*slen*fs:(t + 1)*slen*fs, CHANNEL]<br/>        label = f['label'][t]<br/><br/>    *_, spec = spectrogram(<br/>            N(audio),<br/>            fs          = fs,<br/>            nperseg     = int(fs/bsize[1]),<br/>            noverlap    = 0,<br/>            nfft        = bsize[0])<br/>    X = np.zeros((bsize[0] // 2 + 1, bsize[1]))<br/>    X[:, :spec.shape[1]] = spec<br/>    return np.log(X + 1e-6), label<br/><br/>def get_number_of_batches(filepath):<br/>    with h5.File(filepath + '.h5', 'r') as f:<br/>        fs = f['audio'].attrs['sampling_rate']<br/>        sp = f['audio'].shape[0]<br/>    return ceil(sp/fs)<br/>    <br/><br/>if __name__ == '__main__':<br/>    n_batches = get_number_of_batches(filename)<br/>    for t in range(n_batches):<br/>        batch = get_batch(filename, t)<br/>        print ('Batch #{}, shape={}, label={}'.format(<br/>            i, batch[0].shape, batch[1]))</span></pre><p id="a7ec" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">希望我们的数据现在是可管理的(如果以前不是的话)！此外，在整体质量方面，我们也取得了一些进步:</p><ol class=""><li id="a352" class="ls lt it js b jt ju jx jy kb lu kf lv kj lw kn nj ly lz ma bi translated">我们去掉了之前的<code class="fe mg mh mi mj b">get_batch</code>函数，用一个更有意义的函数取而代之。它计算什么是必要的，并传递数据。简单。</li><li id="3cea" class="ls lt it js b jt mb jx mc kb md kf me kj mf kn nj ly lz ma bi translated">我们的<code class="fe mg mh mi mj b">X</code>张量不再需要人为修改。</li><li id="3a17" class="ls lt it js b jt mb jx mc kb md kf me kj mf kn nj ly lz ma bi translated">事实上，通过将<code class="fe mg mh mi mj b">get_batch(X, y, t)</code>改为<code class="fe mg mh mi mj b">get_batch(filename, t)</code>，我们抽象出了对数据集的访问，并从名称空间中移除了<code class="fe mg mh mi mj b">X</code>和<code class="fe mg mh mi mj b">y</code>。</li><li id="6734" class="ls lt it js b jt mb jx mc kb md kf me kj mf kn nj ly lz ma bi translated">数据集也变成了一个单独的文件。我们不需要从两个不同的文件中获取数据和标签。</li><li id="71a2" class="ls lt it js b jt mb jx mc kb md kf me kj mf kn nj ly lz ma bi translated">我们不需要提供<code class="fe mg mh mi mj b">fs</code>(采样率)参数。得益于 HDF5 中所谓的<em class="ko">属性</em>，它可以成为数据集文件的一部分。</li></ol><p id="1cef" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">尽管有这些优点，我们仍然有两个…不便之处。</p><p id="114c" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">因为新的<code class="fe mg mh mi mj b">get_batch</code>不记得<em class="ko">状态</em>。我们必须像以前一样使用循环来控制<code class="fe mg mh mi mj b">t</code>。然而，由于<code class="fe mg mh mi mj b">get_batch</code>中没有机制来告诉循环需要多大(除了添加第三个输出参数，这很奇怪)，我们需要事先检查数据的大小。除了向<code class="fe mg mh mi mj b">get_batch</code>添加第三个输出(这会使这个函数变得很奇怪)之外，它还要求我们创建第二个函数:<code class="fe mg mh mi mj b">get_number_of_batches</code>。</p><p id="4ec4" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">不幸的是，它并没有使解决方案尽可能优雅。如果我们只是将<code class="fe mg mh mi mj b">get_batch</code>转换成一种能够保持状态的形式，我们可以做得更好。</p><h1 id="5319" class="kp kq it bd kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm bi translated">想法 3——发电机</h1><p id="e626" class="pw-post-body-paragraph jq jr it js b jt ln jv jw jx lo jz ka kb lp kd ke kf lq kh ki kj lr kl km kn im bi translated">让我们来识别模式。我们只对一个接一个地访问、处理和传递数据片段感兴趣。我们不需要一下子全部用完。</p><p id="7a17" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">对于这些机会，Python 有一个特殊的构造，即<em class="ko">生成器</em>。生成器是返回<em class="ko">生成器迭代器</em>的函数，迭代器不是急切地执行计算，而是在那时传递一点结果，等待被要求继续。完美，对吧？</p><p id="0cd4" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">生成器迭代器可以通过三种方式构建:</p><ul class=""><li id="3a47" class="ls lt it js b jt ju jx jy kb lu kf lv kj lw kn lx ly lz ma bi translated">通过类似于列表理解的表达:例如<code class="fe mg mh mi mj b">(i for i in iterable)</code>，但是使用<code class="fe mg mh mi mj b">()</code>而不是<code class="fe mg mh mi mj b">[]</code>，</li><li id="9636" class="ls lt it js b jt mb jx mc kb md kf me kj mf kn lx ly lz ma bi translated">发电机功能——用<code class="fe mg mh mi mj b">yield</code>代替<code class="fe mg mh mi mj b">return</code>,或</li><li id="7a1d" class="ls lt it js b jt mb jx mc kb md kf me kj mf kn lx ly lz ma bi translated">来自定义自定义<code class="fe mg mh mi mj b">__iter__</code>(或<code class="fe mg mh mi mj b">__getitem__</code>)和<code class="fe mg mh mi mj b">__next__</code>方法的类对象(见<a class="ae nk" href="https://docs.python.org/3/library/stdtypes.html#generator-types" rel="noopener ugc nofollow" target="_blank">文档</a>)。</li></ul><p id="959b" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">在这里，使用<code class="fe mg mh mi mj b">yield</code>自然符合我们需要做的事情。</p><pre class="ml mm mn mo gt na mj nb nc aw nd bi"><span id="1996" class="ne kq it mj b gy nf ng l nh ni">def get_batches(filepath, slen=SLEN, bsize=(NFREQS, NTIMES)):<br/>    with h5.File(filepath + '.h5', 'r') as f:<br/>        fs = f['audio'].attrs['sampling_rate']<br/>        n_batches = ceil(f['audio'].shape[0]/fs)<br/><br/>        for t in range(n_batches):<br/>            audio = f['audio'][t*slen*fs:(t + 1)*slen*fs, CHANNEL]<br/>            label = f['label'][t]<br/>            *_, spec = spectrogram(<br/>                    N(audio),<br/>                    fs          = fs,<br/>                    nperseg     = int(fs/bsize[1]),<br/>                    noverlap    = 0,<br/>                    nfft        = bsize[0])<br/>            X = np.zeros((bsize[0] // 2 + 1, bsize[1]))<br/>            X[:, :spec.shape[1]] = spec<br/>            yield np.log(X + 1e-6), label<br/><br/><br/>if __name__ == '__main__':<br/>    for b in get_batches(filename):<br/>        print ('shape={}, label={}'.format(b[0].shape, b[1]))</span></pre><p id="4b74" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">该循环现在位于函数内部。由于有了<code class="fe mg mh mi mj b">yield</code>语句，只有在<code class="fe mg mh mi mj b">get_batches</code>被调用<code class="fe mg mh mi mj b">t - 1</code>次后才会返回<code class="fe mg mh mi mj b">(X[t], y[t])</code>对。模型训练代码不需要管理循环的状态。该函数会记住调用之间的状态，允许用户迭代批处理，而不是使用一些人工的批处理索引。</p><p id="8b43" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">将生成器迭代器比作包含数据的容器是很有用的。随着每一次迭代中批次的删除，容器在某个时候变空了。因此，索引和停止条件都不是必需的。数据被消耗，直到不再有数据，过程停止。</p><h1 id="18fa" class="kp kq it bd kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm bi translated">性能:时间和记忆</h1><p id="aba1" class="pw-post-body-paragraph jq jr it js b jt ln jv jw jx lo jz ka kb lp kd ke kf lq kh ki kj lr kl km kn im bi translated">我们有意从讨论代码质量开始，因为它与我们的解决方案的发展方式紧密相关。然而，考虑资源限制同样重要，尤其是当数据量增长时。</p><p id="66e0" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">图二。显示使用上述三种不同方法交付批次所需的时间。如我们所见，处理和移交数据所需的时间几乎相同。无论我们是加载所有要处理的数据，然后对其进行切片，还是从头开始一点一点地加载和处理，获得解决方案的总时间几乎是相等的。当然，这可能是拥有 SSD 的结果，SSD 允许更快地访问数据。尽管如此，所选择的策略似乎对整体时间性能没有什么影响。</p><figure class="ml mm mn mo gt mp gh gi paragraph-image"><div role="button" tabindex="0" class="mq mr di ms bf mt"><div class="gh gi nl"><img src="../Images/4fa671bdecbe4f3a3241140c84dd2637.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*DJUpgKuxZjnEH0xJ.png"/></div></div><figcaption class="mw mx gj gh gi my mz bd b be z dk">Figure 2. Time performance comparison. The red-solid line refers to timing both loading the data to the memory and performing the computation. The red-dotted line times only the loop, where slices are delivered, assuming that data was precomputed. The green-dotted line refers to loading batches from HDF5 file and the blue-dashed-dotted line implements a generator. Comparing the red lines, we can see that just accessing of the data once it is in the RAM is almost for free. When data is local, the differences between the other cases are minimal, anyway.</figcaption></figure><p id="9892" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">当查看图 3 时，可以观察到更多的差异。考虑到第一种方法，它是所有方法中对内存需求最大的，会产生长达 1 小时的音频样本。相反，当分块加载数据时，分配的 RAM 由批处理大小决定，使我们安全地低于限制。</p><figure class="ml mm mn mo gt mp gh gi paragraph-image"><div role="button" tabindex="0" class="mq mr di ms bf mt"><div class="gh gi nl"><img src="../Images/b5bf22a295b37b9f68d774710a29bb7b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*BVoBLxPhYOIqazvz.png"/></div></div><figcaption class="mw mx gj gh gi my mz bd b be z dk">Figure 3. Memory consumption comparison, expressed in terms of the percentage of the available RAM being consumed by the python script, evaluated using: <code class="fe mg mh mi mj b">(env)$ python idea.py &amp; top -b -n 10 &gt; capture.log; cat capture.log | egrep python &gt; analysis.log</code>, and post-processed.</figcaption></figure><p id="62f2" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">令人惊讶的是(或者不是)，第二种和第三种方法之间没有明显的区别。该图告诉我们，选择或不选择实现生成器迭代器对我们的解决方案的内存占用没有影响。</p><p id="0a48" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">这是很重要的一点。通常鼓励使用生成器作为更有效的解决方案，以节省时间和内存。相反，该图显示，就资源而言，生成器本身并不能提供更好的解决方案。重要的是我们访问资源的速度有多快，我们一次能处理多少数据。</p><p id="574c" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">使用 HDF5 文件被证明是有效的，因为我们可以非常快速地访问数据，并且足够灵活，我们不需要一次加载所有数据。同时，生成器的实现提高了代码的可读性和质量。虽然我们也可以将第一种方法构建成生成器的形式，但这没有任何意义，因为如果不能加载少量数据，生成器只会改进语法。因此，最好的方法似乎是同时使用加载部分数据和生成器，这由第三种方法表示。</p><h1 id="ab94" class="kp kq it bd kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm bi translated">结束语</h1><p id="9228" class="pw-post-body-paragraph jq jr it js b jt ln jv jw jx lo jz ka kb lp kd ke kf lq kh ki kj lr kl km kn im bi translated">在这篇文章中，我们介绍了三种不同的方法来分割和处理我们的数据。我们比较了每种方法的性能和整体代码质量。我们也说过，生成器本身并不能提高代码的效率。最终的性能由时间和内存约束决定，但是，生成器可以使解决方案更加优雅。</p><p id="5ab0" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">你觉得哪个解决方案最有吸引力？</p><h1 id="48e0" class="kp kq it bd kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm bi translated">还会有更多…</h1><p id="f1b4" class="pw-post-body-paragraph jq jr it js b jt ln jv jw jx lo jz ka kb lp kd ke kf lq kh ki kj lr kl km kn im bi translated">我计划把文章带到下一个层次，并提供简短的视频教程。</p><p id="b613" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">如果您想了解关于视频和未来文章的更新，<strong class="js iu">订阅我的</strong> <a class="ae nk" href="https://landing.mailerlite.com/webforms/landing/j5y2q1" rel="noopener ugc nofollow" target="_blank"> <strong class="js iu">简讯</strong> </a> <strong class="js iu">。你也可以通过填写<a class="ae nk" href="https://forms.gle/bNpf9aqZJGLgaU589" rel="noopener ugc nofollow" target="_blank">表格</a>让我知道你的期望。回头见！</strong></p></div><div class="ab cl nm nn hx no" role="separator"><span class="np bw bk nq nr ns"/><span class="np bw bk nq nr ns"/><span class="np bw bk nq nr"/></div><div class="im in io ip iq"><p id="13c5" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><em class="ko">原载于</em><a class="ae nk" href="https://zerowithdot.com/splitting-to-batches/" rel="noopener ugc nofollow" target="_blank"><em class="ko">https://zerowithdot.com</em></a><em class="ko">。</em></p></div></div>    
</body>
</html>