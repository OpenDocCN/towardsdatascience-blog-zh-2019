<html>
<head>
<title>Network Analysis of the Romance of Three Kingdoms</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">《三国演义》的网络分析</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/network-analysis-of-the-romance-of-three-kingdoms-5b1c1b84601d?source=collection_archive---------28-----------------------#2019-11-06">https://towardsdatascience.com/network-analysis-of-the-romance-of-three-kingdoms-5b1c1b84601d?source=collection_archive---------28-----------------------#2019-11-06</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><figure class="is it gp gr iu iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi ir"><img src="../Images/55a39cb7595d43f64b3b1351e2a9c558.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*6HNw_EWBtzouxniufNqpYA.jpeg"/></div></div></figure><div class=""/><p id="26e1" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">最近，我发表了一篇关于 14 世纪小说《三国演义》的社交网络的文章。在文章中，我讨论了在分析小说人物的互动时出现的社会网络。此外，通过使用中心性测量，我确定了谁是最有影响力的人物。这篇文章是非技术性的，我的分析中的一些细节被省略了。</p><p id="1d59" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">在这里，我提出了分析背后的代码，并进一步讨论了小说的社会网络的技术细节。此外，这段代码可以(稍加修改)用于对其他小说或文本进行类似的分析。</p><p id="d4cb" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">我的分析受到了 Andrew Beveridge 和 Jie Shan 对《权力的游戏》的<a class="ae kz" href="https://networkofthrones.wordpress.com/" rel="noopener ugc nofollow" target="_blank">网络分析的启发。两部文学作品都有错综复杂的情节和大量的人物。这使得《三国演义》成为这种分析的一个很好的候选。</a></p><h1 id="19de" class="la lb je bd lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx bi translated">预处理</h1><p id="bd4a" class="pw-post-body-paragraph kb kc je kd b ke ly kg kh ki lz kk kl km ma ko kp kq mb ks kt ku mc kw kx ky im bi translated">在开始分析《三国演义》之前，我必须做出一些初步的决定。</p><ul class=""><li id="45f5" class="md me je kd b ke kf ki kj km mf kq mg ku mh ky mi mj mk ml bi translated">第一个决定是在我的分析中包含哪些字符。这部小说中出现了一千多个人物。为了让读者能够更密切地跟踪这些角色，只选择了 70 个角色。为了选择字符，我使用了以下步骤。首先，我选择了名字在整部小说中出现次数最多的 100 个角色。然后，我列出了在关于这部小说的网站和文章中出现最多的人物，在系列中出现的人物，甚至一些我个人认为重要的人物。我比较了这些列表，手动选择了哪些字符将保留在我的最终列表中。</li><li id="323d" class="md me je kd b ke mm ki mn km mo kq mp ku mq ky mi mj mk ml bi translated">我做的另一个决定是分章节分析这部小说。这部小说的篇幅很大。它包括 120 个章节，英语翻译版本包含超过 50 万字。我决定，为了更好地跟踪人物的互动，在分析全文之前，我应该把小说分成几组章节，并分别分析每一组。由于章节长度相似，我决定创建 30 个章节的组，总共 4 个组。最后，我还处理了整部小说，得到了所有人物的宏大网络。</li></ul><p id="5446" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">通过使用 bash 脚本，我将 30 个一组的章节连接到单独的文件中，再加上一个包含全文的文件。接下来，我创建了 python 脚本，它将一个文本文件作为输入，并生成一个图形对象作为输出。然后，我可以用像<a class="ae kz" href="https://gephi.org/" rel="noopener ugc nofollow" target="_blank"> Gephi </a>这样的工具进一步处理图形，以创建漂亮的网络可视化。</p><figure class="ms mt mu mv gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi mr"><img src="../Images/be6e2e9f6880b84e2b58cf8e80980b43.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*43rJTUr_w6bZ6Q6E8UHDwA.png"/></div></div><figcaption class="mw mx gj gh gi my mz bd b be z dk">The network for chapters 1–30</figcaption></figure><p id="e07a" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">我们首先导入文件并删除所有特殊字符，因为初始文本中有很多特殊字符</p><pre class="ms mt mu mv gt na nb nc nd aw ne bi"><span id="7e4c" class="nf lb je nb b gy ng nh l ni nj">import re</span><span id="1063" class="nf lb je nb b gy nk nh l ni nj">with open(infile, 'r') as file:<br/>    data = file.read().replace('\n', ' ')</span><span id="a1cd" class="nf lb je nb b gy nk nh l ni nj">text = re.sub('[^A-Za-z0–9]+', ' ', data)</span></pre><p id="75d1" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">接下来，我们需要从文本中创建一个标记列表。Python 的<code class="fe nl nm nn nb b">nltk</code>库可以很容易地为我们做到这一点。此外，我们从令牌中删除了停用词</p><pre class="ms mt mu mv gt na nb nc nd aw ne bi"><span id="9884" class="nf lb je nb b gy ng nh l ni nj">import nltk</span><span id="3981" class="nf lb je nb b gy nk nh l ni nj">stopWords = nltk.corpus.stopwords.words('english')</span><span id="38bb" class="nf lb je nb b gy nk nh l ni nj">def wordTokens(text, stop_words):<br/> <br/>    wtokens = nltk.word_tokenize(text.lower())<br/>    wtokens = [w for w in wtokens if w not in stop_words]</span><span id="a323" class="nf lb je nb b gy nk nh l ni nj">return wtokens</span></pre><p id="4e6a" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">因为我们在文本中寻找的名字都由两个单词组成，所以我们想要创建二元模型。在<code class="fe nl nm nn nb b">nltk</code>的帮助下，这又变得非常简单</p><pre class="ms mt mu mv gt na nb nc nd aw ne bi"><span id="cf52" class="nf lb je nb b gy ng nh l ni nj">bigrm = nltk.bigrams(tokens)<br/>bigrms = list(bigrm)</span></pre><p id="4a59" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">如果有一个单词的名字或两个以上单词的名字，我们可以通过包含初始标记以及三元模型或任何其他 n 元模型来概括代码。</p><p id="61bf" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">最后，我们从字符列表中创建元组，以便直接与二元模型进行比较</p><pre class="ms mt mu mv gt na nb nc nd aw ne bi"><span id="4d0d" class="nf lb je nb b gy ng nh l ni nj">def char_tuple_f(chars_list):<br/>    char_tuples_list = []<br/>    for char in chars:<br/>        tup = tuple(char.split(" "))<br/>        char_tuples_list.append(tup)</span><span id="626c" class="nf lb je nb b gy nk nh l ni nj">return char_tuples_list</span></pre><figure class="ms mt mu mv gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi no"><img src="../Images/7332f5a61fda226c891c89d90c969d76.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*M31xFKBQbI9k_Q9xDk4nSA.png"/></div></div><figcaption class="mw mx gj gh gi my mz bd b be z dk">The network for chapters 31–60</figcaption></figure><h1 id="5a52" class="la lb je bd lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx bi translated">计数交互</h1><p id="26b4" class="pw-post-body-paragraph kb kc je kd b ke ly kg kh ki lz kk kl km ma ko kp kq mb ks kt ku mc kw kx ky im bi translated">我们的最终目标是分析角色之间的互动。但是什么才算互动呢？在这里，我跟踪贝弗里奇和山，统计了两个角色的名字出现在小说中时，彼此之间的 15 个单词以内的互动。实际上，单词的数量，即字符的“单词距离”，本身也是一个变量。在对不同的值进行试验后，15 似乎是一个产生良好结果的值。</p><p id="62a3" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">我们用字符的名字作为关键字创建一个字典。每个键的值都是一个所有索引的<code class="fe nl nm nn nb b">numpy</code>数组，其中人物的名字出现在二元模型列表中。</p><pre class="ms mt mu mv gt na nb nc nd aw ne bi"><span id="8f98" class="nf lb je nb b gy ng nh l ni nj">def indices_dic(char_tuples, bigr):<br/>    dic = {}<br/>    for tup in char_tuples:<br/>        char_name = " ".join(tup)<br/>        indices = [i for i, x in enumerate(bigr) if x == tup]<br/>        dic[char_name] = np.array(indices)<br/>    <br/>    return dic</span></pre><p id="9c28" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">然后，对于上述字典中的每个字符，我们取该字符的索引与其他字符索引的差。如果这种差异低于某个阈值(通常是 15)，我们就认为这是角色之间的一次交互。这里，<code class="fe nl nm nn nb b">numpy</code>的向量化显著加快了代码的速度。最后，我们将每个角色的所有交互添加到一个字典中。</p><p id="d662" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">我们只考虑有 3 次以上互动的角色。这样做的原因如下。有时候，一个段落/行尾的人物名字和下一个段落/行首的人物名字可能会出现在我们的阈值内，即使这些人物之间并没有真正的互动。这种情况通常随机发生，并且对于相同的字符，它们发生三次以上的概率很低。另一方面，如果两个角色真正地相互作用，他们将有超过 3 次的相互作用</p><pre class="ms mt mu mv gt na nb nc nd aw ne bi"><span id="92e3" class="nf lb je nb b gy ng nh l ni nj">def links_dic_f(indices_dic, threshold):<br/>    <br/>    link_dic = {}<br/>    for first_char, ind_arr1 in indices_dic.items():<br/>        dic = {}<br/>        for second_char, ind_arr2 in indices_dic.items():<br/>            if first_char == second_char:<br/>                continue</span><span id="e670" class="nf lb je nb b gy nk nh l ni nj">matr = np.abs(ind_arr1[np.newaxis].T - <br/>                         ind_arr2) &lt;= threshold<br/>            s = np.sum(matr)<br/>            if s &gt; 3:<br/>                dic[second_char] = s<br/>        link_dic[first_char] = dic<br/>    <br/>    return link_dic</span></pre><p id="a0b4" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">这部分代码可能还可以进一步优化。然而，对于我所分析的文本的大小，代码几乎是即时运行的，我不觉得需要进一步优化。</p><figure class="ms mt mu mv gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi np"><img src="../Images/8f03d055392a03a915901029e13f510e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*vhZiIiCfGGRe8OY8Y5_sWw.png"/></div></div><figcaption class="mw mx gj gh gi my mz bd b be z dk">The network for chapters 61–90</figcaption></figure><p id="d6da" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">因为我们在小说的所有部分都使用了相同的角色列表，所以在某些部分，一些角色可能没有出现，或者没有与任何人互动。这已经在交互字典中考虑到了，但是我们也想把它们从字符列表中删除。这样，我们的图中就不会出现没有边的孤立节点。</p><pre class="ms mt mu mv gt na nb nc nd aw ne bi"><span id="8017" class="nf lb je nb b gy ng nh l ni nj">def remove_zero_link_chars(inter_dic, chars_list):<br/>    rem_set = set()<br/>    for key in inter_dic:<br/>        if inter_dic[key] == {}:<br/>            rem_set.add(key)<br/> <br/>    fin_list = [char for char in chars_list if char not in rem_set]<br/>    return fin_list</span></pre><h1 id="a910" class="la lb je bd lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx bi translated">创建图表</h1><p id="f4ec" class="pw-post-body-paragraph kb kc je kd b ke ly kg kh ki lz kk kl km ma ko kp kq mb ks kt ku mc kw kx ky im bi translated">现在我们有了一个包含所有角色互动次数的字典，我们准备创建一个代表角色网络的图。我们将使用<code class="fe nl nm nn nb b">networkx</code>库来创建图表。<code class="fe nl nm nn nb b">networkx</code>期望图的节点作为一个列表。我们已经有了，这是我们的角色列表。此外，它期望图的边作为两个节点的元组加上边的权重值给出。我们如下创建这些元组</p><pre class="ms mt mu mv gt na nb nc nd aw ne bi"><span id="d37d" class="nf lb je nb b gy ng nh l ni nj">def edge_tuples_f(link_dic):<br/>    edges_tuples = []<br/>    for key in link_dic:<br/>        for item, value in link_dic[key].items():<br/>            tup = (key.title(), item.title(), value)<br/>            edges_tuples.append(tup)</span><span id="99d0" class="nf lb je nb b gy nk nh l ni nj">return edges_tuples</span></pre><p id="b79f" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">当我们有两个列表时，用<code class="fe nl nm nn nb b">networkx</code>创建图表是非常简单的</p><pre class="ms mt mu mv gt na nb nc nd aw ne bi"><span id="21c1" class="nf lb je nb b gy ng nh l ni nj">import networkx as nx</span><span id="b27c" class="nf lb je nb b gy nk nh l ni nj">G = nx.Graph()<br/>G.add_nodes_from(node_chars)<br/>G.add_weighted_edges_from(edges_tuples)</span></pre><p id="af84" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">最后，我们想要检测存在于我们的图中的社区。社区是我们的图的子集，其成员相互之间的交互多于与其他社区成员的交互。社区检测背后的算法超出了本文的范围。尽管如此，我们想要展示 python 模块<code class="fe nl nm nn nb b">community</code>可以只用一行代码就完成这一点。我们将这个分区作为属性添加到图的节点中。Gephi 稍后可以使用它来对节点进行分组。</p><pre class="ms mt mu mv gt na nb nc nd aw ne bi"><span id="ce4a" class="nf lb je nb b gy ng nh l ni nj">import community</span><span id="de8a" class="nf lb je nb b gy nk nh l ni nj">partition = community.best_partition(G)<br/>nx.set_node_attributes(G, partition, ‘group’)</span></pre><p id="6d5a" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">我们将图表导出为一个<code class="fe nl nm nn nb b">.gexf</code>文件</p><pre class="ms mt mu mv gt na nb nc nd aw ne bi"><span id="3bf2" class="nf lb je nb b gy ng nh l ni nj">nx.write_gexf(G, outfile)</span></pre><p id="57ed" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">使用 Gephi，我们可以生成图形的美丽可视化。在 Gephi 中创建网络的要点是我使用了 Force Atlas 布局。此外，我使用社区组的节点颜色和边的数量来确定节点的大小。</p><figure class="ms mt mu mv gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi nq"><img src="../Images/c10031b9252112eff3bc9f42f01ab258.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ijkhXrmwvCRuM1PhjbjbxQ.png"/></div></div><figcaption class="mw mx gj gh gi my mz bd b be z dk">The network of the full text</figcaption></figure><h1 id="4b42" class="la lb je bd lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx bi translated">中心性</h1><p id="d6c0" class="pw-post-body-paragraph kb kc je kd b ke ly kg kh ki lz kk kl km ma ko kp kq mb ks kt ku mc kw kx ky im bi translated">为了找到小说中最有影响力的人物，我们研究了中心性测量。我们计算了三种不同的中心性。</p><ul class=""><li id="df66" class="md me je kd b ke kf ki kj km mf kq mg ku mh ky mi mj mk ml bi translated"><strong class="kd jf">度中心性</strong>定义为每个节点的边数。一个节点，或者在我们的例子中的一个字符，有更多的边，被认为更有影响力</li><li id="94b3" class="md me je kd b ke mm ki mn km mo kq mp ku mq ky mi mj mk ml bi translated"><strong class="kd jf">中间中心性</strong>显示一个节点在两个其他节点的最短路径内被发现的次数。实际上，它确定了角色</li><li id="57aa" class="md me je kd b ke mm ki mn km mo kq mp ku mq ky mi mj mk ml bi translated"><strong class="kd jf">特征向量中心性</strong>根据节点的连接来衡量节点的重要性，但与其他重要节点的连接比与不重要节点的连接贡献更大。它识别与强大角色交互的角色。</li></ul><p id="7cb3" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">我们使用这三个中心来计算一个角色的重要性。由于我们不能直接比较不同的中心性，最终，我们的断言将是定性的。然而，对于小说中的人物，我们认为与重要人物有联系的人比与次要人物有联系的人更有影响力。因此，我们认为特征向量中心性比其他两个中心性更能决定一个字符的重要性。此外，在我们的计算中，特征向量中心性考虑了边的权重。</p><p id="b232" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated"><code class="fe nl nm nn nb b">networkx</code>库包括计算所有三个中心性的算法。我们用每个节点的中心性创建一个<code class="fe nl nm nn nb b">pandas</code>数据帧。</p><pre class="ms mt mu mv gt na nb nc nd aw ne bi"><span id="2bfc" class="nf lb je nb b gy ng nh l ni nj">def calc_centralities(graph):<br/>    <br/>    dgc = nx.degree_centrality(graph)<br/>    dgc = pd.DataFrame.from_dict(dgc, orient='index', columns=["DGC"])<br/>    btc = nx.betweenness_centrality(graph)<br/>    btc = pd.DataFrame.from_dict(btc, orient='index', columns=["BTC"])<br/>    evc = nx.eigenvector_centrality(graph, weight='weight')<br/>    evc = pd.DataFrame.from_dict(evc, orient='index', columns=["EVC"])</span><span id="7397" class="nf lb je nb b gy nk nh l ni nj">df = pd.concat([dgc, btc, evc], axis=1)<br/>    <br/>    return df</span><span id="b4c7" class="nf lb je nb b gy nk nh l ni nj">df = calc_centralities(G)</span></pre><p id="756a" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">最后，我们为所有三个中心创建了一个包含前 10 个角色的图</p><pre class="ms mt mu mv gt na nb nc nd aw ne bi"><span id="0b8f" class="nf lb je nb b gy ng nh l ni nj">import matplotlib.pyplot as plt</span><span id="b786" class="nf lb je nb b gy nk nh l ni nj">def plot_centrality(centr, df, title, n, col_list):<br/>    <br/>    ax = plt.subplot(1, 3, n)<br/>    s = df.sort_values(centr, ascending=False)[:10]<br/>    x = list(s[centr].index)[::-1]<br/>    y = list(s[centr])[::-1]<br/>    <br/>    for i, v in enumerate(y):<br/>        bars = plt.barh(x[i], v, color=col_list[n-1])<br/>    <br/>    plt.title(title, size=22)<br/>    ax.get_xaxis().set_visible(False)<br/>    ax.spines['top'].set_visible(False)<br/>    ax.spines['bottom'].set_visible(False)<br/>    ax.spines['right'].set_visible(False)<br/>    ax.spines['left'].set_visible(False)<br/>    ax.tick_params(axis='y', length = 0, labelsize=14)</span><span id="89fd" class="nf lb je nb b gy nk nh l ni nj">col_list = ["peachpuff", "plum", "orange"]<br/>fig, ax = plt.subplots(1,3, figsize=(15, 10))<br/>plot_centrality("DGC", df, 'Degree Centrality', 1, col_list)<br/>plot_centrality("BTC", df, 'Betweeness Centrality', 2, col_list)<br/>plot_centrality("EVC", df, 'Eigenvector Centrality', 3, col_list)</span><span id="e804" class="nf lb je nb b gy nk nh l ni nj">plt.savefig(figfile_centr, dpi=300)</span></pre><p id="2cb4" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">当然，对于图中的一种颜色，我们使用“桃子色”，这让我想起了<a class="ae kz" href="https://en.wikipedia.org/wiki/Oath_of_the_Peach_Garden" rel="noopener ugc nofollow" target="_blank">在桃花源</a>的誓言。</p><figure class="ms mt mu mv gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi nr"><img src="../Images/6b8b51b359c1f26b0281ca651ff55e1a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*37jX5rMeIfjAXlTsrWXZOQ.png"/></div></div><figcaption class="mw mx gj gh gi my mz bd b be z dk">Centrality measures for the full text of the novel</figcaption></figure><p id="452b" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">完整的<code class="fe nl nm nn nb b">jupyter</code>笔记本可以在<a class="ae kz" href="https://github.com/dmanolidis/three-kingdoms" rel="noopener ugc nofollow" target="_blank">这里</a>找到。分析的结果可以在这篇<a class="ae kz" rel="noopener" target="_blank" href="/the-network-of-three-kingdoms-df6f8f8a1263">文章</a>中找到。</p></div></div>    
</body>
</html>