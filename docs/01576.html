<html>
<head>
<title>Person Search</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">人员搜索</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/person-search-1f207af28bec?source=collection_archive---------17-----------------------#2019-03-13">https://towardsdatascience.com/person-search-1f207af28bec?source=collection_archive---------17-----------------------#2019-03-13</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><h1 id="0ebc" class="jn jo iq bd jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk bi translated">什么是人肉搜索</h1><p id="8485" class="pw-post-body-paragraph kl km iq kn b ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">人物搜索是一项任务，其目的是在没有边界框注释的情况下在图库的图像中搜索相应的实例。相关联的数据类似于个人重新识别中的数据。关键的区别在于边界框在此任务中不可用。实际上，可以将行人检测和人员识别结合起来视为一项任务。</p><h1 id="19f9" class="jn jo iq bd jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk bi translated">论文评论</h1><p id="abfc" class="pw-post-body-paragraph kl km iq kn b ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated"><code class="fe lj lk ll lm b">Joint Detection and Identification Feature Learning for Person Search(CVPR 2017)</code></p><p id="92e4" class="pw-post-body-paragraph kl km iq kn b ko ln kq kr ks lo ku kv kw lp ky kz la lq lc ld le lr lg lh li ij bi translated"><a class="ae ls" href="https://arxiv.org/pdf/1604.01850v3.pdf" rel="noopener ugc nofollow" target="_blank">论文/ </a> <a class="ae ls" href="https://github.com/ShuangLI59/person_search/" rel="noopener ugc nofollow" target="_blank">代码/ </a> <a class="ae ls" href="https://www.semanticscholar.org/paper/Joint-Detection-and-Identification-Feature-Learning-Xiao-Li/0c769c19d894e0dbd6eb314781dc1db3c626df57?navId=featured-content" rel="noopener ugc nofollow" target="_blank">语义书生</a></p><figure class="lu lv lw lx gt ly gh gi paragraph-image"><div class="gh gi lt"><img src="../Images/1d9edce265bf518a7f03f80dafd35f00.png" data-original-src="https://miro.medium.com/v2/resize:fit:1312/format:webp/0*TuBatJ4Ny9wWso0X.png"/></div></figure><blockquote class="mb mc md"><p id="d1d9" class="kl km me kn b ko ln kq kr ks lo ku kv mf lp ky kz mg lq lc ld mh lr lg lh li ij bi translated"><em class="iq">图取自论文</em></p></blockquote><p id="2cb4" class="pw-post-body-paragraph kl km iq kn b ko ln kq kr ks lo ku kv kw lp ky kz la lq lc ld le lr lg lh li ij bi translated">人员搜索问题设置更接近真实世界的应用，并且比人员重新识别更具挑战性，因为检测行人将不可避免地产生错误警报、错误检测和错位。本文没有将人员搜索问题分解为两个独立的任务——行人检测和人员重新识别，而是在单个卷积神经网络中联合处理这两个方面。提出了一种在线实例匹配(OIM)损失函数来有效地训练网络，该函数可扩展到具有大量身份的数据集。</p><figure class="lu lv lw lx gt ly gh gi paragraph-image"><div role="button" tabindex="0" class="mj mk di ml bf mm"><div class="gh gi mi"><img src="../Images/b50520b61e2d3731f6d7045c6084152b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*DJXTdAfbsRubwE9o.png"/></div></div></figure><blockquote class="mb mc md"><p id="aac7" class="kl km me kn b ko ln kq kr ks lo ku kv mf lp ky kz mg lq lc ld mh lr lg lh li ij bi translated"><em class="iq">提议的框架(图取自论文)</em></p></blockquote><p id="1e9f" class="pw-post-body-paragraph kl km iq kn b ko ln kq kr ks lo ku kv kw lp ky kz la lq lc ld le lr lg lh li ij bi translated">行人提议网络生成候选人的包围盒，将其送入识别网络进行特征提取。该特征被投影到 L2 归一化的 256 维子空间，并且用提议的在线实例匹配损失来训练。行人建议网和识别网共享基础卷积特征图。</p><figure class="lu lv lw lx gt ly gh gi paragraph-image"><div role="button" tabindex="0" class="mj mk di ml bf mm"><div class="gh gi mn"><img src="../Images/118c147c7ba7a219f7017c6875688482.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*RmEltkbqiBl-eJfF.png"/></div></div></figure><p id="382d" class="pw-post-body-paragraph kl km iq kn b ko ln kq kr ks lo ku kv kw lp ky kz la lq lc ld le lr lg lh li ij bi translated">在线实例匹配(图取自论文)</p><p id="d9fe" class="pw-post-body-paragraph kl km iq kn b ko ln kq kr ks lo ku kv kw lp ky kz la lq lc ld le lr lg lh li ij bi translated">左边部分显示了图像中已标记(蓝色)和未标记(橙色)的身份建议。我们维护一个查找表(LUT)和一个循环队列(CQ)来存储特性。转发时，每个标记的身份与所有存储的特征相匹配。向后时，我们根据 id 更新 LUT，将新功能推送到 CQ，并弹出过时的功能。注意，这两种数据结构都是外部存储器，而不是 CNN 的参数。</p><p id="cd1e" class="pw-post-body-paragraph kl km iq kn b ko ln kq kr ks lo ku kv kw lp ky kz la lq lc ld le lr lg lh li ij bi translated"><code class="fe lj lk ll lm b">Person Search in Videos with One Portrait Through Visual and Temporal Links(ECCV 2018)</code></p><p id="d7b1" class="pw-post-body-paragraph kl km iq kn b ko ln kq kr ks lo ku kv kw lp ky kz la lq lc ld le lr lg lh li ij bi translated"><a class="ae ls" href="https://arxiv.org/pdf/1807.10510.pdf" rel="noopener ugc nofollow" target="_blank">论文/ </a> <a class="ae ls" href="http://qqhuang.cn/projects/eccv18-person-search/" rel="noopener ugc nofollow" target="_blank">项目/ </a> <a class="ae ls" href="https://github.com/hqqasw/person-search-PPCC" rel="noopener ugc nofollow" target="_blank">代号/ </a> <a class="ae ls" href="https://www.semanticscholar.org/paper/Person-Search-in-Videos-with-One-Portrait-Through-Huang-Liu/c97a5f2241cc6cd99ef0c4527ea507a50841f60b" rel="noopener ugc nofollow" target="_blank">语义书生</a></p><p id="b531" class="pw-post-body-paragraph kl km iq kn b ko ln kq kr ks lo ku kv kw lp ky kz la lq lc ld le lr lg lh li ij bi translated">在一些现实世界的应用中，人们需要从长视频中通过少量的肖像来搜索特定的人。与人的重新识别相比，这是一个非常困难的问题，因为环境可能非常多。为了解决这一挑战性问题，作者提出了一种通过视觉和时间链接的标签传播策略，其中视觉链接由视觉外观特征之间的相似性定义，而时间链接由轨迹生成。使用经由竞争共识技术的渐进传播来提高传播过程的可靠性。</p><figure class="lu lv lw lx gt ly gh gi paragraph-image"><div role="button" tabindex="0" class="mj mk di ml bf mm"><div class="gh gi mo"><img src="../Images/3baf6d724e11063833503fd1a5ee5f44.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*Xjiote4OuWk63yXs.png"/></div></div></figure><blockquote class="mb mc md"><p id="0e92" class="kl km me kn b ko ln kq kr ks lo ku kv mf lp ky kz mg lq lc ld mh lr lg lh li ij bi translated"><em class="iq">图形中的视觉链接和时间链接(黄庆秋等，2018) </em></p></blockquote><p id="08bc" class="pw-post-body-paragraph kl km iq kn b ko ln kq kr ks lo ku kv kw lp ky kz la lq lc ld le lr lg lh li ij bi translated">在图中执行身份传播，其中节点由检测到的人定义。该图包含两种链接，视觉链接和时间链接(这两种链接都是稀疏的，以提高图的鲁棒性)。</p><figure class="lu lv lw lx gt ly gh gi paragraph-image"><div role="button" tabindex="0" class="mj mk di ml bf mm"><div class="gh gi mp"><img src="../Images/b8a0dba4a1b11ff9d050761d8feca1ae.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*H6pGu3-nzbVNv74Q.png"/></div></div></figure><p id="6d89" class="pw-post-body-paragraph kl km iq kn b ko ln kq kr ks lo ku kv kw lp ky kz la lq lc ld le lr lg lh li ij bi translated">竞争性共识与线性扩散的比较(黄庆秋等，2018)</p><p id="8e4e" class="pw-post-body-paragraph kl km iq kn b ko ln kq kr ks lo ku kv kw lp ky kz la lq lc ld le lr lg lh li ij bi translated">以防止在标签传播期间身份信息被噪声链路污染。使用竞争一致性模型，目标节点的邻居在传播期间相互竞争，并且仅保留最大的同一性元素。</p></div><div class="ab cl mq mr hu ms" role="separator"><span class="mt bw bk mu mv mw"/><span class="mt bw bk mu mv mw"/><span class="mt bw bk mu mv"/></div><div class="ij ik il im in"><p id="464b" class="pw-post-body-paragraph kl km iq kn b ko ln kq kr ks lo ku kv kw lp ky kz la lq lc ld le lr lg lh li ij bi translated"><em class="me">最初发布于</em><a class="ae ls" href="https://amberer.gitlab.io/papers_in_ai/person-search.html" rel="noopener ugc nofollow" target="_blank"><em class="me">amberer . git lab . io</em></a><em class="me">。</em></p></div></div>    
</body>
</html>