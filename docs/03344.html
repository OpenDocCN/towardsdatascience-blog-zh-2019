<html>
<head>
<title>The Million-Dollar Neural Network, Part II: Machine Learning Intuition</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">百万美元的神经网络，第二部分:机器学习直觉</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/the-million-dollar-neural-network-part-ii-machine-learning-intuition-a84650185e44?source=collection_archive---------25-----------------------#2019-05-28">https://towardsdatascience.com/the-million-dollar-neural-network-part-ii-machine-learning-intuition-a84650185e44?source=collection_archive---------25-----------------------#2019-05-28</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="336e" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">了解如何建立一个神经网络，并在这个由 3 部分组成的系列中赢得 165 万美元的 CMS 人工智能健康成果挑战赛</h2></div><p id="9941" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><em class="le">作者注:在</em> <a class="ae lf" rel="noopener" target="_blank" href="/the-million-dollar-neural-network-part-i-understanding-the-biological-basis-6920910a7cf9"> <em class="le">第一部分</em> </a> <em class="le">中，我们讨论了价值 165 万美元的 CMS 人工智能健康成果挑战、擅长数据科学需要什么，以及神经网络的生物学基础。如果你还没有，读一读(大约 6 分钟。)在这里继续之前。</em></p><p id="aa87" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">这个系列的这个特殊部分变得相当长。因此，我将分为 2(这部分)和 2A。然后在第 3 部分，我们将按照最初的计划实际构建我们的神经网络。</p><p id="4385" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">所以，现在你已经对人工神经网络(ann)的生物学对应部分有了牢固的理解，是时候进入 ann 本身了。</p><p id="b367" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">以下是我们将涉及的主题的简要概述:</p><ul class=""><li id="8e4c" class="lg lh it kk b kl km ko kp kr li kv lj kz lk ld ll lm ln lo bi translated">从生物学到计算机科学:神经元到节点</li><li id="9270" class="lg lh it kk b kl lp ko lq kr lr kv ls kz lt ld ll lm ln lo bi translated">神经网络结构:输入、隐藏和输出层</li><li id="926a" class="lg lh it kk b kl lp ko lq kr lr kv ls kz lt ld ll lm ln lo bi translated">分配和更新权重:神经网络如何学习</li><li id="4b3f" class="lg lh it kk b kl lp ko lq kr lr kv ls kz lt ld ll lm ln lo bi translated">将输入转换为输出:激活功能</li></ul><p id="7701" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">现在，事不宜迟，让我们开始吧。</p><h1 id="92fd" class="lu lv it bd lw lx ly lz ma mb mc md me jz mf ka mg kc mh kd mi kf mj kg mk ml bi translated">从生物学到计算机科学:神经元到节点</h1><p id="3434" class="pw-post-body-paragraph ki kj it kk b kl mm ju kn ko mn jx kq kr mo kt ku kv mp kx ky kz mq lb lc ld im bi translated">正如我们在<a class="ae lf" rel="noopener" target="_blank" href="/the-million-dollar-neural-network-part-i-understanding-the-biological-basis-6920910a7cf9">第一部分</a>中所讨论的，生物神经元接收来自其他神经元的大量输入(通过<strong class="kk iu">树突</strong>)。</p><p id="9332" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">这些输入被相加(在<strong class="kk iu">体细胞</strong>中),如果相加的输入达到或超过该神经元的指定阈值，则信号(通过<strong class="kk iu">动作电位</strong>沿<strong class="kk iu">轴突</strong>的长度向下传输。</p><p id="76dc" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">这个输出然后通过<strong class="kk iu">突触</strong>(通过化学信号)从<strong class="kk iu">突触前神经元</strong>的<strong class="kk iu">轴突末端</strong>传递到<strong class="kk iu">突触后神经元</strong>的树突。</p><p id="c4c3" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">就像它们的生物对应物一样，人工神经元(或者通常被称为<strong class="kk iu">节点</strong>)从网络中的其他神经元接收大量输入，并传递输出。</p><h2 id="1c4d" class="mr lv it bd lw ms mt dn ma mu mv dp me kr mw mx mg kv my mz mi kz na nb mk nc bi translated">神经网络结构:输入、隐藏和输出层</h2><p id="3e9b" class="pw-post-body-paragraph ki kj it kk b kl mm ju kn ko mn jx kq kr mo kt ku kv mp kx ky kz mq lb lc ld im bi translated">在人工神经网络中，节点(如下图圆圈所示)属于三个不同的<strong class="kk iu">层</strong>中的一个:输入层<strong class="kk iu">输入层</strong>、隐藏层<strong class="kk iu">隐藏层</strong>或输出层<strong class="kk iu">输出层</strong>，它们都由<strong class="kk iu">突触</strong>连接(如下图箭头所示)。</p><figure class="ne nf ng nh gt ni gh gi paragraph-image"><div role="button" tabindex="0" class="nj nk di nl bf nm"><div class="gh gi nd"><img src="../Images/c2975a37c20ff5c154f5bb0a4c28e4d9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*kaxFfBnq9MvXQQ_b8alIxA.png"/></div></div></figure><p id="e68f" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">正如您可能猜到的那样，<strong class="kk iu">输入层</strong>从数据集的一行数据中接收输入。给定输入集中的每个输入来自不同的数据元素，<strong class="kk iu">都来自同一行</strong>。</p><p id="ad65" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">例如，让我们看看下面的数据集。想象一下，你和我一起经营一家大型国际公司。现在想象一下，我们正面临一个员工流动率很高的问题。我们想做的是尝试并预测我们不同的员工中哪些人最有可能离开，这样我们就可以围绕提高员工保留率设计有效的计划。</p><p id="bd4c" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">假设我们已经使用我们的员工数据训练了我们的神经网络，我们现在使用以下数据进行一些预测。</p><figure class="ne nf ng nh gt ni gh gi paragraph-image"><div role="button" tabindex="0" class="nj nk di nl bf nm"><div class="gh gi np"><img src="../Images/571f91eff9a2be996d66cebc068161f7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*oAoNDbgOjnkSeVo9ZJnoog.png"/></div></div></figure><p id="b829" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我们神经网络的输入将是<em class="le">姓名</em>、<em class="le">职位、办公室、年龄、开始日期</em>和<em class="le">薪水</em>。因此，给定的一组输入将全部来自同一行，可能如下所示:</p><pre class="ne nf ng nh gt nq nr ns nt aw nu bi"><span id="c015" class="mr lv it nr b gy nv nw l nx ny">Sonya Frost; Software Engineer; Edinburgh; 23; 2008/12/13; $103,600</span></pre><p id="0286" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">或者重新使用我们之前基本神经网络的图像:</p><figure class="ne nf ng nh gt ni gh gi paragraph-image"><div role="button" tabindex="0" class="nj nk di nl bf nm"><div class="gh gi nd"><img src="../Images/a7b8f83d7d139c9796a82e9c2d1bf064.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*E_x_O623aFhoXn7HHhj6Fw.png"/></div></div></figure><p id="3879" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">现在需要注意的是，输入层没有应用任何计算(或<strong class="kk iu">激活函数</strong>)——没有输入求和，没有达到或超过阈值。其目的仅仅是向<strong class="kk iu">隐藏层</strong>节点传递信息。</p><p id="cc53" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="kk iu">隐藏层节点</strong>从输入层接收输入，执行计算，并将输出传递给<strong class="kk iu">输出节点。</strong>输出节点执行最终计算并给出答案。这个最终输出是对来自同一行的<strong class="kk iu">数据的响应——在我们的例子中，这可能代表 Sonya 辞职的可能性，比方说在 0 到 1 的范围内可能是 0.6。</strong></p><p id="8958" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">这个最终输出可以是<strong class="kk iu">连续的、二进制的、</strong>或<strong class="kk iu">分类的</strong>；您需要的输出类型将取决于您的特定用例/问题。</p><p id="b62e" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在我们的例子中，概率分数将是最有帮助的，所以我们将在输出层中使用一个<strong class="kk iu"> sigmoid 函数</strong>。如果你在这个阶段不确定这意味着什么，不要担心——我们一会儿就会讲到<strong class="kk iu">激活功能</strong>:)。</p><p id="7452" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">该过程实质上对下一行数据重复进行。再次使用我们的示例数据集，这将是:</p><pre class="ne nf ng nh gt nq nr ns nt aw nu bi"><span id="aa52" class="mr lv it nr b gy nv nw l nx ny">Doris Wilder; Sales Assistant; Sidney; 23; 2010/09/20; $85,600</span></pre><p id="0b43" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在更复杂的神经网络的情况下，也称为<strong class="kk iu">深度神经网络，其中<strong class="kk iu"> </strong>是<strong class="kk iu">多个隐藏层</strong>，隐藏层的节点从前一个隐藏层的节点接收输入，直到最后一个隐藏层将其输出发送到输出层。</strong></p><p id="ae22" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">这样想一想:</p><p id="dcee" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">回到第一部分中的示例，假设从数据集接收数据的输入图层等同于您的眼睛接收视觉刺激，即强烈的阳光。输出层的最终输出相当于控制你眼睑点火的肌肉，使你闭上眼睛。隐藏层是中间的所有复杂步骤，使它看起来像魔术一样。</p><h1 id="0c1d" class="lu lv it bd lw lx ly lz ma mb mc md me jz mf ka mg kc mh kd mi kf mj kg mk ml bi translated">分配和更新权重—神经网络如何学习</h1><p id="caa5" class="pw-post-body-paragraph ki kj it kk b kl mm ju kn ko mn jx kq kr mo kt ku kv mp kx ky kz mq lb lc ld im bi translated">那么还记得在<a class="ae lf" rel="noopener" target="_blank" href="/the-million-dollar-neural-network-part-i-understanding-the-biological-basis-6920910a7cf9">第一部分</a>中，我们如何说理解<strong class="kk iu">动作电位</strong>将有助于理解<strong class="kk iu">激活功能</strong>吗？这就是最终派上用场的地方。</p><p id="3cf9" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">节点间的<strong class="kk iu">突触</strong>或连接被赋予随机强度，也称为<strong class="kk iu">权重</strong>。</p><p id="3d53" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">神经网络通过更新这些权重来学习，增加一些节点之间的连接强度，削弱甚至消除(或<strong class="kk iu">修剪</strong>)其他节点之间的连接。</p><p id="c382" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">这正是人类大脑的工作方式——加强一些联系，删减一些。</p><p id="c557" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">那么在各个节点内部发生了什么呢？</p><p id="8fea" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">暂时回到生物神经元:在生物神经元的<strong class="kk iu">胞体</strong>(细胞体)中，所有的输入都加在一起。如果总和超过特定神经元的给定阈值，则触发<strong class="kk iu">动作电位</strong>。</p><p id="74f7" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在人工神经元(节点)中，节点的所有输入都乘以各自连接的权重，并求和在一起，产生<strong class="kk iu">加权和</strong>。</p><h2 id="8fa8" class="mr lv it bd lw ms mt dn ma mu mv dp me kr mw mx mg kv my mz mi kz na nb mk nc bi translated">将输入转换为输出:激活功能</h2><p id="5942" class="pw-post-body-paragraph ki kj it kk b kl mm ju kn ko mn jx kq kr mo kt ku kv mp kx ky kz mq lb lc ld im bi translated">因此，一旦我们有了加权和，就应用一个<strong class="kk iu">激活函数</strong>将这些输入转换成输出，这决定了什么样的信号被传递(或不传递)到下一个节点。激活函数引入了<strong class="kk iu">非线性</strong>并使神经网络能够分析图像、音频和视频等复杂数据。</p><p id="ef2d" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">有许多类型的激活函数，其中一些更适合用于隐藏层(例如 ReLU)，而另一些更适合用于输出层(例如 sigmoid):</p><ul class=""><li id="72d3" class="lg lh it kk b kl km ko kp kr li kv lj kz lk ld ll lm ln lo bi translated"><strong class="kk iu">二进制步骤</strong> →产生 1 或 0 输出；当你需要一个简单的是/否预测时，这是很棒的</li></ul><figure class="ne nf ng nh gt ni gh gi paragraph-image"><div class="gh gi nz"><img src="../Images/9af6d46cb3c9f6ed0e1f984cb2d334d2.png" data-original-src="https://miro.medium.com/v2/resize:fit:780/format:webp/1*Ajrl6nD1hd6FmS07aYJg5g.png"/></div><figcaption class="oa ob gj gh gi oc od bd b be z dk">Binary Step Function</figcaption></figure><ul class=""><li id="32c2" class="lg lh it kk b kl km ko kp kr li kv lj kz lk ld ll lm ln lo bi translated"><strong class="kk iu"> Sigmoid 函数</strong> →在输出层预测概率时非常有用，因为每个概率都在 0 和 1 之间</li></ul><figure class="ne nf ng nh gt ni gh gi paragraph-image"><div class="gh gi oe"><img src="../Images/036f6f6cfc00b8e970510326a875a963.png" data-original-src="https://miro.medium.com/v2/resize:fit:792/format:webp/1*POC9MPPkCWqRirP77eS5fA.png"/></div><figcaption class="oa ob gj gh gi oc od bd b be z dk">Sigmoid Function</figcaption></figure><ul class=""><li id="52b3" class="lg lh it kk b kl km ko kp kr li kv lj kz lk ld ll lm ln lo bi translated"><strong class="kk iu">双曲正切</strong>(又名<strong class="kk iu">双曲正切</strong>)及其变体(LeCun 的双曲正切，硬双曲正切)→本质上是范围从-1 到 1 的缩放的 sigmoid 函数</li></ul><figure class="ne nf ng nh gt ni gh gi paragraph-image"><div class="gh gi of"><img src="../Images/152998155aa1b234608172918cbab0da.png" data-original-src="https://miro.medium.com/v2/resize:fit:808/format:webp/1*HBpNfZvy2CKtcz-IgZhVsw.png"/></div><figcaption class="oa ob gj gh gi oc od bd b be z dk">Tanh function</figcaption></figure><ul class=""><li id="fc29" class="lg lh it kk b kl km ko kp kr li kv lj kz lk ld ll lm ln lo bi translated"><strong class="kk iu"> ReLU(整流线性单元)</strong>及其变种(<strong class="kk iu">漏 ReLU </strong>，PReLU，eLU 等。)→至今仍是神经网络中最常用的函数之一。使计算变得简单而有效。Leaky ReLU 变体解决了传统 ReLU 常见的“死亡神经元”问题。</li></ul><div class="ne nf ng nh gt ab cb"><figure class="og ni oh oi oj ok ol paragraph-image"><img src="../Images/18979629e7d41f7d1e770d956edade06.png" data-original-src="https://miro.medium.com/v2/resize:fit:774/format:webp/1*hNIacIFmn3U9uQES7m5rcg.png"/></figure><figure class="og ni om oi oj ok ol paragraph-image"><img src="../Images/2cc09b442a06fb17c240ec2689115307.png" data-original-src="https://miro.medium.com/v2/resize:fit:782/format:webp/1*YQSeZ4T0fHVMo_2bma8U0g.png"/><figcaption class="oa ob gj gh gi oc od bd b be z dk on di oo op">ReLU vs Leaky ReLU</figcaption></figure></div><ul class=""><li id="9244" class="lg lh it kk b kl km ko kp kr li kv lj kz lk ld ll lm ln lo bi translated"><strong class="kk iu"> SoftMax → </strong>一种 sigmoid 函数，最适用于多类别分类问题的输出层(例如，输入是一个神奇宝贝的图像，输出是特定神奇宝贝是火、草或水类型的概率)</li></ul><figure class="ne nf ng nh gt ni gh gi paragraph-image"><div class="gh gi oq"><img src="../Images/af70d804c11f993c79c8f0a0b1c93f69.png" data-original-src="https://miro.medium.com/v2/resize:fit:804/format:webp/1*SSshUNP3NZaJ8PbWFD268g.png"/></div><figcaption class="oa ob gj gh gi oc od bd b be z dk">SoftMax function</figcaption></figure><h1 id="d212" class="lu lv it bd lw lx ly lz ma mb mc md me jz mf ka mg kc mh kd mi kf mj kg mk ml bi translated">让我们回顾一下</h1><p id="ca3d" class="pw-post-body-paragraph ki kj it kk b kl mm ju kn ko mn jx kq kr mo kt ku kv mp kx ky kz mq lb lc ld im bi translated">所以回到第一部分，我们讨论了人工神经网络的生物学基础——人脑。重要的是，当神经元从其他神经元接收输入时，这些输入在<strong class="kk iu">细胞体</strong>(细胞体)中相加。<strong class="kk iu"> </strong>如果这些输入的总和达到或超过特定神经元的给定阈值，则<strong class="kk iu">动作电位</strong>被触发，信号沿着<strong class="kk iu">轴突</strong>传播，并穿过<strong class="kk iu">突触</strong>到达下一个神经元。</p><p id="da21" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在第二部分中，我们已经讨论了这如何转化为机器学习环境。<strong class="kk iu">节点</strong>，或者人工神经网络中的单个神经元，通过<strong class="kk iu">突触</strong>相互连接。神经网络由三个独立的层组成:输入层<strong class="kk iu">输入层</strong>(传递来自数据集的数据)、隐藏层<strong class="kk iu">隐藏层</strong>(神经网络的真正魔力发生在这里)，以及输出层<strong class="kk iu"/>(在给出最终答案之前应用最终计算或激活函数)。</p><p id="71f1" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">初始输入是来自数据集的数据元素，<em class="le">都来自同一行或观察</em>(按照我们之前的例子，开始日期、薪水和办公室位置)。最后的输出也是针对同一行的(根据我们前面的例子，雇员离开组织的概率)。在该行/观察的数据元素通过神经网络运行之后，该过程在下一行/观察中再次重复。</p><p id="380a" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">突触具有不同的<strong class="kk iu">权重</strong>或强度，当神经网络学习时，这些权重或强度会更新(加强或削弱)。给定节点的输入乘以它们的权重并求和以给出一个<strong class="kk iu">加权和</strong>。</p><p id="9285" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">那么，这些节点如何知道应该传递什么样的信号呢？该节点取其输入的加权和，并应用一个<strong class="kk iu">激活函数。</strong>有几种激活函数，有些更适合用于隐藏层，如<strong class="kk iu"> ReLU 函数</strong>，或用于输出层，如<strong class="kk iu"> sigmoid 函数</strong>。</p><p id="dacc" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">输出层使用的激活函数很大程度上取决于你需要什么样的答案。例如，sigmoid 函数在 0 到 1 的范围内给出了一个很好的概率。如果您需要将概率分配给多个类别，那么使用<strong class="kk iu"> SoftMax 函数可能会更好。</strong></p></div><div class="ab cl or os hx ot" role="separator"><span class="ou bw bk ov ow ox"/><span class="ou bw bk ov ow ox"/><span class="ou bw bk ov ow"/></div><div class="im in io ip iq"><p id="dce1" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><em class="le">不幸的是，第二部分很长，所以我们将在 2A 的一部分完成我们的机器学习直觉，我们将讨论隐藏层的重要性，最小化成本函数，梯度下降和反向传播。然后在第 3 部分，我们将最终进入实际建设我们的神经网络！</em></p></div><div class="ab cl or os hx ot" role="separator"><span class="ou bw bk ov ow ox"/><span class="ou bw bk ov ow ox"/><span class="ou bw bk ov ow"/></div><div class="im in io ip iq"><p id="1d7e" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><em class="le">对使用机器学习在医疗保健领域产生实际影响感兴趣？了解我们如何</em> <a class="ae lf" href="https://medcitynews.com/2019/04/orderly-health-provider-data-accuracy/" rel="noopener ugc nofollow" target="_blank"> <em class="le">解决医生数据</em> </a> <em class="le">不准确的问题，并访问我们的网站</em><a class="ae lf" href="http://orderlyhealth.com" rel="noopener ugc nofollow" target="_blank"><em class="le">orderlyhealth.com</em></a><em class="le">。</em></p></div></div>    
</body>
</html>