<html>
<head>
<title>AI-powered Indian license plate detector.</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">人工智能驱动的印度车牌检测器。</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/ai-based-indian-license-plate-detector-de9d48ca8951?source=collection_archive---------5-----------------------#2019-09-07">https://towardsdatascience.com/ai-based-indian-license-plate-detector-de9d48ca8951?source=collection_archive---------5-----------------------#2019-09-07</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><figure class="is it gp gr iu iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi ir"><img src="../Images/a75cb8dcad6763a4fbdaa57a6ee9f0c1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Fh9BMaEwSRsCFOFvQnC2ww.jpeg"/></div></div></figure><div class=""/></div><div class="ab cl kb kc hx kd" role="separator"><span class="ke bw bk kf kg kh"/><span class="ke bw bk kf kg kh"/><span class="ke bw bk kf kg"/></div><div class="im in io ip iq"><blockquote class="ki kj kk"><p id="caba" class="kl km kn ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj im bi translated">灵感:撞了我的车还逍遥法外的家伙！</p><p id="fed6" class="kl km kn ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj im bi translated"><strong class="ko jf">背景故事:</strong>在和朋友度过了一个难忘的夜晚后，当我们准备回家时，有一件事让那个夜晚更加难忘，我的汽车前保险杠上有一个巨大的凹痕，似乎是被另一辆车撞了，但这该怪谁呢？周围没有人会目睹那件事。我能做些什么呢？<br/>我会告诉你我到底做了什么。<br/>我利用我的机器学习和编程技能，决定制作一个基于人工智能的印度车牌检测器，它能够通过检测周围车辆的车牌来监视车辆，在这篇博客中，我将带你们了解我是如何做到这一点的！</p><p id="69a5" class="kl km kn ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj im bi translated"><strong class="ko jf">首先:</strong>总有即兴发挥的余地，所以如果你对这个项目有更好的想法或疑问，请使用下面的回复部分。</p></blockquote><h1 id="b2b1" class="lk ll je bd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh bi translated">方法:</h1><h2 id="1557" class="mi ll je bd lm mj mk dn lq ml mm dp lu mn mo mp ly mq mr ms mc mt mu mv mg mw bi translated">我们需要建立一个系统，能够-</h2><ul class=""><li id="8c1b" class="mx my je ko b kp mz kt na mn nb mq nc mt nd lj ne nf ng nh bi translated">从周围获取图像/视频(一系列图像):<br/>在硬件端，我们需要一台 pc(或 raspberry pi)和一个摄像头，在软件端，我们需要一个库来捕获和处理数据(图像)。我在这个项目中使用了 OpenCV (4.1.0)和 Python (3.6.7)。</li><li id="6f57" class="mx my je ko b kp ni kt nj mn nk mq nl mt nm lj ne nf ng nh bi translated">在图像中寻找车牌:<br/>要从图像中检测一个物体(车牌)，我们需要另一个工具来识别印度车牌，为此我使用了 Haar cascade，它是在印度车牌上预先训练的(将很快更新到 YOLO v3)。</li><li id="4e8d" class="mx my je ko b kp ni kt nj mn nk mq nl mt nm lj ne nf ng nh bi translated">对车牌进行分析和执行一些图像处理:<br/>使用 OpenCV 的灰度、阈值、腐蚀、扩张、轮廓检测，并通过一些参数调整，我们可以很容易地生成足够多的关于车牌的信息，以决定这些数据是否足够有用，可以传递给进一步的处理(有时如果图像非常失真或不正确，我们可能只能得到假设的 10 个字符中的 8 个， 然后，没有必要将数据传递到管道中，而是忽略它并查看下一帧的板)，此外，在将图像传递到下一个过程之前，我们需要确保它没有噪声并经过处理。</li><li id="2ad0" class="mx my je ko b kp ni kt nj mn nk mq nl mt nm lj ne nf ng nh bi translated">从车牌中分割出字母数字字符:<br/>如果上述步骤一切正常，我们应该准备好从车牌中提取字符，这可以通过巧妙地对图像进行阈值处理、腐蚀、扩张和模糊来完成，这样最终我们得到的图像几乎没有噪声，并且易于进一步的功能处理。我们现在再次使用轮廓检测和一些参数调整来提取字符。</li><li id="405b" class="mx my je ko b kp ni kt nj mn nk mq nl mt nm lj ne nf ng nh bi translated">逐个考虑字符，识别字符，将结果串联起来并以字符串形式给出车牌号码:<br/>现在有趣的部分来了！因为我们有所有的字符，所以我们需要将字符一个接一个地传递到我们训练好的模型中，它应该能够识别字符，瞧！我们将使用 Keras 作为我们的卷积神经网络模型。</li></ul><h1 id="fdcd" class="lk ll je bd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh bi translated">先决条件:</h1><ul class=""><li id="3350" class="mx my je ko b kp mz kt na mn nb mq nc mt nd lj ne nf ng nh bi translated">OpenCV  : OpenCV 是一个编程函数库，主要针对实时计算机视觉，加上它的开源性，使用起来很有趣，也是我个人的最爱。这个项目我用的是 4.1.0 版本。</li><li id="0cbf" class="mx my je ko b kp ni kt nj mn nk mq nl mt nm lj ne nf ng nh bi translated"><strong class="ko jf"> Python </strong>:又名编码的瑞士军刀。我这里用的是 3.6.7 版本。</li><li id="a695" class="mx my je ko b kp ni kt nj mn nk mq nl mt nm lj ne nf ng nh bi translated">IDE: 我将在这里使用 Jupyter。</li><li id="198d" class="mx my je ko b kp ni kt nj mn nk mq nl mt nm lj ne nf ng nh bi translated"><strong class="ko jf"> Haar cascade </strong>:这是一种机器学习对象检测算法，用于识别图像或视频中的对象，基于 Paul Viola 和 Michael Jones 在 2001 年的论文“使用简单特征的增强级联进行快速对象检测”中提出的<strong class="ko jf"> </strong>特征概念。<a class="ae nn" href="https://en.wikipedia.org/wiki/Viola%E2%80%93Jones_object_detection_framework" rel="noopener ugc nofollow" target="_blank">更多信息</a></li><li id="4fe6" class="mx my je ko b kp ni kt nj mn nk mq nl mt nm lj ne nf ng nh bi translated"><strong class="ko jf">Keras</strong>:Keras 易于使用并得到广泛支持，它让深度学习变得尽可能简单。</li><li id="0831" class="mx my je ko b kp ni kt nj mn nk mq nl mt nm lj ne nf ng nh bi translated"><strong class="ko jf">Scikit-Learn:</strong>It<strong class="ko jf"/>是一个免费的 Python 编程语言的软件机器学习库。</li><li id="7864" class="mx my je ko b kp ni kt nj mn nk mq nl mt nm lj ne nf ng nh bi translated">当然，不要忘记<strong class="ko jf">咖啡</strong>！</li></ul><h1 id="8dea" class="lk ll je bd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh bi translated">第一步</h1><blockquote class="ki kj kk"><p id="181c" class="kl km kn ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj im bi translated"><strong class="ko jf">创建工作空间。</strong></p></blockquote><p id="9eed" class="pw-post-body-paragraph kl km je ko b kp kq kr ks kt ku kv kw mn ky kz la mq lc ld le mt lg lh li lj im bi translated">我推荐创建一个 conda 环境，因为它使项目管理更加容易。请按照此<a class="ae nn" href="https://docs.conda.io/projects/conda/en/latest/user-guide/install/" rel="noopener ugc nofollow" target="_blank">链接</a>中的说明安装 miniconda。安装完成后，打开 cmd/terminal 并使用以下命令创建一个环境</p><pre class="no np nq nr gt ns nt nu nv aw nw bi"><span id="f9c6" class="mi ll je nt b gy nx ny l nz oa">&gt;conda create -n 'name_of_the_environment' python=3.6.7</span></pre><p id="b18e" class="pw-post-body-paragraph kl km je ko b kp kq kr ks kt ku kv kw mn ky kz la mq lc ld le mt lg lh li lj im bi translated">现在让我们激活环境:</p><pre class="no np nq nr gt ns nt nu nv aw nw bi"><span id="8ec4" class="mi ll je nt b gy nx ny l nz oa">&gt;conda activate 'name_of_the_environment'</span></pre><p id="194b" class="pw-post-body-paragraph kl km je ko b kp kq kr ks kt ku kv kw mn ky kz la mq lc ld le mt lg lh li lj im bi translated">这应该让我们进入虚拟环境。是时候安装一些库了-</p><pre class="no np nq nr gt ns nt nu nv aw nw bi"><span id="d33b" class="mi ll je nt b gy nx ny l nz oa"># installing OpenCV<br/>&gt;pip install opencv-python==4.1.0</span><span id="1377" class="mi ll je nt b gy ob ny l nz oa"># Installing Keras<br/>&gt;pip install keras</span><span id="b3ca" class="mi ll je nt b gy ob ny l nz oa"># Installing Jupyter<br/>&gt;pip install jupyter</span><span id="8fa8" class="mi ll je nt b gy ob ny l nz oa">#Installing Scikit-Learn<br/>&gt;pip install <!-- -->scikit-learn</span></pre><h1 id="183a" class="lk ll je bd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh bi translated">第二步</h1><blockquote class="ki kj kk"><p id="d1c4" class="kl km kn ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj im bi translated"><strong class="ko jf">设置环境！</strong></p></blockquote><p id="a459" class="pw-post-body-paragraph kl km je ko b kp kq kr ks kt ku kv kw mn ky kz la mq lc ld le mt lg lh li lj im bi translated">我们将从运行 jupyter notebook 开始，然后在我们的例子中导入必要的库 OpenCV、Keras 和 sklearn。</p><pre class="no np nq nr gt ns nt nu nv aw nw bi"><span id="a593" class="mi ll je nt b gy nx ny l nz oa"># in your conda environment run<br/>&gt;jupyter notebook</span></pre><p id="ead3" class="pw-post-body-paragraph kl km je ko b kp kq kr ks kt ku kv kw mn ky kz la mq lc ld le mt lg lh li lj im bi translated">这将在默认的网络浏览器中打开 Jupyter 笔记本。一旦打开，让我们导入库</p><pre class="no np nq nr gt ns nt nu nv aw nw bi"><span id="cd91" class="mi ll je nt b gy nx ny l nz oa">#importing openCV<br/>&gt;import cv2</span><span id="8960" class="mi ll je nt b gy ob ny l nz oa">#importing numpy<br/>&gt;import numpy as np</span><span id="5558" class="mi ll je nt b gy ob ny l nz oa">#importing pandas to read the CSV file containing our data<br/>&gt;import pandas as pd</span><span id="e7c4" class="mi ll je nt b gy ob ny l nz oa">#importing keras and sub-libraries<br/>&gt;from keras.models import Sequential<br/>&gt;from keras.layers import Dense<br/>&gt;from keras.layers import Dropout<br/>&gt;from keras.layers import Flatten, MaxPool2D<br/>&gt;from keras.layers.convolutional import Conv2D<br/>&gt;from keras.layers.convolutional import MaxPooling2D<br/>&gt;from keras import backend as K<br/>&gt;from keras.utils import np_utils<br/>&gt;from sklearn.model_selection import train_test_split</span></pre><h1 id="81ac" class="lk ll je bd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh bi translated">第三步</h1><blockquote class="ki kj kk"><p id="935d" class="kl km kn ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj im bi translated"><strong class="ko jf">号牌检测:</strong></p></blockquote><p id="7d41" class="pw-post-body-paragraph kl km je ko b kp kq kr ks kt ku kv kw mn ky kz la mq lc ld le mt lg lh li lj im bi translated">让我们简单地从导入一个带有牌照的汽车样本图像开始，并定义一些函数:</p><figure class="no np nq nr gt iv"><div class="bz fp l di"><div class="oc od l"/></div></figure><p id="d889" class="pw-post-body-paragraph kl km je ko b kp kq kr ks kt ku kv kw mn ky kz la mq lc ld le mt lg lh li lj im bi translated">上述函数的工作方式是将图像作为输入，然后应用预先训练好的“haar cascade”来检测印度车牌，这里的参数 scaleFactor 代表一个值，通过该值可以缩放输入图像，以便更好地检测车牌(<a class="ae nn" href="https://sites.google.com/site/5kk73gpu2012/assignment/viola-jones-face-detection#TOC-Image-Pyramid" rel="noopener ugc nofollow" target="_blank">了解更多信息</a>)。minNeighbors 只是一个减少误报的参数，如果这个值很低，算法可能更容易给出一个误识别的输出。(您可以从我的<a class="ae nn" href="https://github.com/SarthakV7/AI-based-indian-license-plate-detection" rel="noopener ugc nofollow" target="_blank"> github </a>个人资料中下载名为“indian_license_plate.xml”的 haar cascade 文件。)</p><figure class="no np nq nr gt iv gh gi paragraph-image"><div class="gh gi oe"><img src="../Images/269331735970c2908ca599227fdc4956.png" data-original-src="https://miro.medium.com/v2/resize:fit:650/format:webp/1*RFqmJj0alAKWAqyBuihosw.jpeg"/></div><figcaption class="of og gj gh gi oh oi bd b be z dk">input image</figcaption></figure><figure class="no np nq nr gt iv gh gi paragraph-image"><div class="gh gi oe"><img src="../Images/2e197a2880ea37ba683ebf342df7aaf4.png" data-original-src="https://miro.medium.com/v2/resize:fit:650/format:webp/1*S8bTK6q1LUuChQ2Fet6yfQ.jpeg"/></div><figcaption class="of og gj gh gi oh oi bd b be z dk">output image with detected plate highlighted</figcaption></figure><figure class="no np nq nr gt iv gh gi paragraph-image"><div class="gh gi oj"><img src="../Images/a4d9fc51b733b2235e258ef4a20a22b1.png" data-original-src="https://miro.medium.com/v2/resize:fit:292/format:webp/1*w_LVI7pA6CehL0P5t6LhGQ.png"/></div><figcaption class="of og gj gh gi oh oi bd b be z dk">output image of detected license plate</figcaption></figure><h1 id="bdaa" class="lk ll je bd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh bi translated">第四步</h1><blockquote class="ki kj kk"><p id="2cb8" class="kl km kn ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj im bi translated"><strong class="ko jf">对车牌进行一些图像处理。</strong></p></blockquote><p id="1b3b" class="pw-post-body-paragraph kl km je ko b kp kq kr ks kt ku kv kw mn ky kz la mq lc ld le mt lg lh li lj im bi translated">现在让我们进一步处理这个图像，使字符提取过程变得容易。我们将从定义更多的函数开始。</p><figure class="no np nq nr gt iv"><div class="bz fp l di"><div class="oc od l"/></div></figure><p id="a0fe" class="pw-post-body-paragraph kl km je ko b kp kq kr ks kt ku kv kw mn ky kz la mq lc ld le mt lg lh li lj im bi translated">上述函数接收图像作为输入，并对其执行以下操作-</p><ul class=""><li id="0b53" class="mx my je ko b kp kq kt ku mn ok mq ol mt om lj ne nf ng nh bi translated">将它调整到一个尺寸，这样所有的字符看起来都清晰明了</li><li id="8f5f" class="mx my je ko b kp ni kt nj mn nk mq nl mt nm lj ne nf ng nh bi translated">将彩色图像转换为灰度图像，即图像只有一个 8 位通道，取值范围为 0-255，0 对应黑色，255 对应白色，而不是 3 通道(BGR)。我们这样做是为下一个过程准备图像。</li><li id="0b4c" class="mx my je ko b kp ni kt nj mn nk mq nl mt nm lj ne nf ng nh bi translated">现在阈值函数将灰度图像转换为二进制图像，即每个像素现在将具有 0 或 1 的值，其中 0 对应于黑色，1 对应于白色。这是通过应用具有 0 到 255 之间的值的阈值来完成的，这里的值是 200，这意味着在灰度图像中，对于具有大于 200 的值的像素，在新的二进制图像中，该像素将被赋予值 1。并且对于值低于 200 的像素，在新的二进制图像中，该像素将被赋予值 0。</li><li id="9618" class="mx my je ko b kp ni kt nj mn nk mq nl mt nm lj ne nf ng nh bi translated">图像现在是二进制形式，为下一个腐蚀过程做准备。<br/>侵蚀是一个简单的过程，用于从对象的边界移除不想要的像素，即值应该为 0 但却为 1 的像素。它的工作原理是逐个考虑图像中的每个像素，然后考虑像素的邻居(邻居的数量取决于内核大小)，只有当它的所有邻居像素都是 1 时，该像素才被赋予值 1，否则被赋予值 0。</li><li id="99ac" class="mx my je ko b kp ni kt nj mn nk mq nl mt nm lj ne nf ng nh bi translated">图像现在是干净的，没有边界噪声，我们现在将放大图像以填充缺少的像素，即应该具有值 1 但具有值 0 的像素。该函数的工作方式类似于侵蚀，但有一点不同，它的工作方式是逐个考虑图像中的每个像素，然后考虑像素的邻居(邻居的数量取决于内核大小)，如果像素的至少一个相邻像素为 1，则该像素的值为 1。</li><li id="fbd0" class="mx my je ko b kp ni kt nj mn nk mq nl mt nm lj ne nf ng nh bi translated">下一步是将图像的边界变成白色。这是为了移除帧外的任何像素(如果它存在的话)。</li><li id="b841" class="mx my je ko b kp ni kt nj mn nk mq nl mt nm lj ne nf ng nh bi translated">接下来，我们定义一个包含 4 个值的维度列表，我们将用它来比较字符的维度，以筛选出所需的字符。</li><li id="1fc8" class="mx my je ko b kp ni kt nj mn nk mq nl mt nm lj ne nf ng nh bi translated">通过上面的过程，我们已经将我们的图像减少到一个处理过的二进制图像，并且我们已经准备好传递这个图像用于字符提取。</li></ul><h1 id="4d86" class="lk ll je bd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh bi translated">第五步</h1><blockquote class="ki kj kk"><p id="e409" class="kl km kn ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj im bi translated">从车牌中分割出字母数字字符。</p></blockquote><figure class="no np nq nr gt iv"><div class="bz fp l di"><div class="oc od l"/></div></figure><p id="2eb0" class="pw-post-body-paragraph kl km je ko b kp kq kr ks kt ku kv kw mn ky kz la mq lc ld le mt lg lh li lj im bi translated">在第 4 步之后，我们应该有一个干净的二进制图像。在这一步中，我们将应用更多的图像处理来从牌照中提取单个字符。涉及的步骤将是-</p><ul class=""><li id="d00f" class="mx my je ko b kp kq kt ku mn ok mq ol mt om lj ne nf ng nh bi translated">找到输入图像中的所有轮廓。函数 cv2.findContours 返回它在图像中找到的所有轮廓。轮廓可以简单地解释为连接所有连续点(沿边界)的曲线，具有相同的颜色或强度。</li></ul><figure class="no np nq nr gt iv gh gi paragraph-image"><div class="gh gi on"><img src="../Images/299743a5d489ca1ec562506b2bf271d6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1150/format:webp/1*I1-aZ-szf-SqrxueEtB-Tg.png"/></div><figcaption class="of og gj gh gi oh oi bd b be z dk"><a class="ae nn" href="https://www.oipapio.com/static-img/4698620190220123940948.jpg" rel="noopener ugc nofollow" target="_blank">https://www.oipapio.com/static-img/4698620190220123940948.jpg</a></figcaption></figure><figure class="no np nq nr gt iv gh gi paragraph-image"><div class="gh gi oo"><img src="../Images/4572d765553e8f50abdcbc3de215d09f.png" data-original-src="https://miro.medium.com/v2/resize:fit:682/format:webp/1*8blZEtiXo9vxriC3yp1EDA.png"/></div><figcaption class="of og gj gh gi oh oi bd b be z dk">plate with contours drawn in green</figcaption></figure><ul class=""><li id="4be1" class="mx my je ko b kp kq kt ku mn ok mq ol mt om lj ne nf ng nh bi translated">找到所有轮廓后，我们逐个考虑它们，并计算它们各自的边界矩形的尺寸。现在考虑边界矩形是可能包含轮廓的最小矩形。让我通过在这里为每个字符画出边界矩形来说明它们。</li></ul><figure class="no np nq nr gt iv gh gi paragraph-image"><div class="gh gi oo"><img src="../Images/2b7f3a8d8de56e9a996862f63203c9a2.png" data-original-src="https://miro.medium.com/v2/resize:fit:682/format:webp/1*0l5qoklROE2bdIq4JkXfuA.png"/></div></figure><ul class=""><li id="a657" class="mx my je ko b kp kq kt ku mn ok mq ol mt om lj ne nf ng nh bi translated">因为我们有了这些边界矩形的尺寸，所以我们需要做的就是做一些参数调整，并过滤出包含所需字符的所需矩形。为此，我们将通过只接受宽度在 0，(pic 的长度)/(字符数)和长度在(pic 的宽度)/2，4 *(pic 的宽度)/5 范围内的那些矩形来执行一些维度比较。如果一切顺利，我们应该有所有的字符提取为二进制图像。</li></ul><figure class="no np nq nr gt iv gh gi paragraph-image"><div class="gh gi op"><img src="../Images/954f065e3404d1dad86bff46ef88ef66.png" data-original-src="https://miro.medium.com/v2/resize:fit:690/format:webp/1*PVdInfmQoYIxyYyp81Kx1w.png"/></div><figcaption class="of og gj gh gi oh oi bd b be z dk">The binary images of 10 extracted characters.</figcaption></figure><ul class=""><li id="4795" class="mx my je ko b kp kq kt ku mn ok mq ol mt om lj ne nf ng nh bi translated">字符可能是无序的，但不要担心，代码的最后几行会处理好这一点。它根据字符的边界矩形相对于盘子左边界的位置对字符进行排序。</li></ul><h1 id="04fa" class="lk ll je bd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh bi translated">第六步</h1><blockquote class="ki kj kk"><p id="044e" class="kl km kn ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj im bi translated"><strong class="ko jf">创造一个机器学习模型，并为角色训练它。</strong></p></blockquote><ul class=""><li id="c088" class="mx my je ko b kp kq kt ku mn ok mq ol mt om lj ne nf ng nh bi translated">数据都是干净的，准备好了，现在是时候创建一个足够智能的神经网络来识别训练后的字符。</li></ul><figure class="no np nq nr gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi oq"><img src="../Images/0ac4212e2e66023e66d98188d9ba2a92.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*KhUiEJdZy42JfkCfwm7jjg.jpeg"/></div></div><figcaption class="of og gj gh gi oh oi bd b be z dk"><a class="ae nn" href="https://mesin-belajar.blogspot.com/2016/05/topological-visualisation-of.html" rel="noopener ugc nofollow" target="_blank">https://mesin-belajar.blogspot.com/2016/05/topological-visualisation-of.html</a></figcaption></figure><ul class=""><li id="5d09" class="mx my je ko b kp kq kt ku mn ok mq ol mt om lj ne nf ng nh bi translated">为了建模，我们将使用具有 3 层的卷积神经网络。</li></ul><pre class="no np nq nr gt ns nt nu nv aw nw bi"><span id="6cc3" class="mi ll je nt b gy nx ny l nz oa">## create model<br/>&gt;model = Sequential()<br/>&gt;model.add(Conv2D(filters=32, kernel_size=(5,5), input_shape=(28, 28, 1), activation='relu'))<br/>&gt;model.add(MaxPooling2D(pool_size=(2, 2)))<br/>&gt;model.add(Dropout(rate=0.4))<br/>&gt;model.add(Flatten())<br/>&gt;model.add(Dense(units=128, activation='relu'))<br/>&gt;model.add(Dense(units=36, activation='softmax'))</span></pre><figure class="no np nq nr gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi or"><img src="../Images/fee83072cbdb774732ffa8f8d64b4d9e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*FAMyA1skMbdXYQlmUM6Kfw.png"/></div></div></figure><ul class=""><li id="90ae" class="mx my je ko b kp kq kt ku mn ok mq ol mt om lj ne nf ng nh bi translated">为了保持模型简单，我们将从创建一个顺序对象开始。</li><li id="599e" class="mx my je ko b kp ni kt nj mn nk mq nl mt nm lj ne nf ng nh bi translated">第一层将是具有 32 个输出滤波器、大小为(5，5)的卷积窗口和作为激活函数的‘Relu’的卷积层。</li></ul><figure class="no np nq nr gt iv gh gi paragraph-image"><div class="gh gi os"><img src="../Images/61feb87faaae38518f47d08b8658e26c.png" data-original-src="https://miro.medium.com/v2/resize:fit:714/format:webp/1*njuH4XVXf-l9pR_RorUOrA.png"/></div></figure><figure class="no np nq nr gt iv gh gi paragraph-image"><div class="gh gi ot"><img src="../Images/a311e9cc462b5fb63526371ba6ee5c8b.png" data-original-src="https://miro.medium.com/v2/resize:fit:772/format:webp/1*iUxZ6ZNaizs2DzhDvTWDgg.png"/></div></figure><ul class=""><li id="ca4b" class="mx my je ko b kp kq kt ku mn ok mq ol mt om lj ne nf ng nh bi translated">接下来，我们将添加一个窗口大小为(2，2)的 max-pooling 层。<br/> <strong class="ko jf"> Max pooling </strong>是一个基于样本的离散化过程。目标是对输入表示(图像、隐藏层<strong class="ko jf">和输出矩阵</strong>等)进行下采样。)，减少其维数，并允许对包含在被装仓的子区域中的特征进行假设。</li></ul><figure class="no np nq nr gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi ou"><img src="../Images/96ea8e54beea6c8756dd422582dc6966.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*cEpnL1pqYe45cBZIfOxASw.png"/></div></div><figcaption class="of og gj gh gi oh oi bd b be z dk">max-pooling layer</figcaption></figure><ul class=""><li id="b60a" class="mx my je ko b kp kq kt ku mn ok mq ol mt om lj ne nf ng nh bi translated">现在，我们将增加一些辍学率，以照顾过度拟合。<br/> <strong class="ko jf"> Dropout </strong>是一个正则化超参数，被初始化以防止神经网络过拟合。Dropout 是一种在训练过程中忽略随机选择的神经元的技术。他们是“<strong class="ko jf">掉</strong> - <strong class="ko jf">掉</strong>”随机产生的。我们选择了 0.4 的丢弃率，这意味着将保留 60%的节点。</li><li id="688e" class="mx my je ko b kp ni kt nj mn nk mq nl mt nm lj ne nf ng nh bi translated">现在是展平节点数据的时候了，所以我们添加了一个展平层。展平层从上一层获取数据，并在一维中表示它。</li></ul><figure class="no np nq nr gt iv gh gi paragraph-image"><div class="gh gi ov"><img src="../Images/312a4852d3c0b829fbfbd4afcb214e5f.png" data-original-src="https://miro.medium.com/v2/resize:fit:684/format:webp/1*BLP5zEDWc6kwBpThM5jFjQ.png"/></div></figure><ul class=""><li id="3fba" class="mx my je ko b kp kq kt ku mn ok mq ol mt om lj ne nf ng nh bi translated">最后，我们将添加两个密集层，一个输出空间的维数为 128，激活函数='relu ',另一个，我们的最后一层有 36 个输出，用于对 26 个字母(A-Z) + 10 个数字(0–9)和激活函数=' softmax '进行分类</li></ul><figure class="no np nq nr gt iv gh gi paragraph-image"><div class="gh gi ow"><img src="../Images/e339821764849f033b5abda3ea99beff.png" data-original-src="https://miro.medium.com/v2/resize:fit:508/format:webp/1*_uXiq8n5QvQzlJLNjZRLSg.png"/></div></figure><h1 id="6c51" class="lk ll je bd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh bi translated">第七步</h1><blockquote class="ki kj kk"><p id="fe4c" class="kl km kn ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj im bi translated"><strong class="ko jf">训练我们的 CNN 模型。</strong></p></blockquote><ul class=""><li id="dbca" class="mx my je ko b kp kq kt ku mn ok mq ol mt om lj ne nf ng nh bi translated">我们将使用的数据包含大小为 28x28 的字母(A-Z)和数字(0-9)的图像，并且数据是平衡的，因此我们不必在这里进行任何类型的数据调整。</li><li id="abdb" class="mx my je ko b kp ni kt nj mn nk mq nl mt nm lj ne nf ng nh bi translated">我已经创建了一个<a class="ae nn" href="https://github.com/SarthakV7/AI-based-indian-license-plate-detection/blob/master/data.zip" rel="noopener ugc nofollow" target="_blank"> zip 文件</a>，其中包含按照下面的目录结构的数据，训练测试分割为 80:20</li></ul><figure class="no np nq nr gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi ox"><img src="../Images/c804eaef67408e56e684e35651386034.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*uXcMknHKArBw3f5J.jpeg"/></div></div><figcaption class="of og gj gh gi oh oi bd b be z dk"><a class="ae nn" href="https://medium.com/@vijayabhaskar96/tutorial-image-classification-with-keras-flow-from-directory-and-generators-95f75ebe5720" rel="noopener">https://medium.com/@vijayabhaskar96/tutorial-image-classification-with-keras-flow-from-directory-and-generators-95f75ebe5720</a></figcaption></figure><ul class=""><li id="c746" class="mx my je ko b kp kq kt ku mn ok mq ol mt om lj ne nf ng nh bi translated">我们将使用 keras 中可用的 ImageDataGenerator 类，使用宽度移动、高度移动等图像增强技术来生成更多的数据。要了解更多关于 ImageDataGenerator 的信息，请查看<a class="ae nn" href="https://medium.com/@vijayabhaskar96/tutorial-image-classification-with-keras-flow-from-directory-and-generators-95f75ebe5720" rel="noopener">这篇</a>不错的博客。</li><li id="d808" class="mx my je ko b kp ni kt nj mn nk mq nl mt nm lj ne nf ng nh bi translated">Width shift:接受一个浮点值，表示图像将向左和向右移动的百分比。<br/> Height shift:接受一个浮点值，表示图像上下移动的比例。</li></ul><figure class="no np nq nr gt iv"><div class="bz fp l di"><div class="oc od l"/></div></figure><ul class=""><li id="bcf4" class="mx my je ko b kp kq kt ku mn ok mq ol mt om lj ne nf ng nh bi translated">现在该训练我们的模特了！<br/>我们将使用“分类 _ 交叉熵”作为损失函数，“亚当”作为优化函数，“准确度”作为误差矩阵。</li></ul><figure class="no np nq nr gt iv"><div class="bz fp l di"><div class="oc od l"/></div></figure><ul class=""><li id="ac5d" class="mx my je ko b kp kq kt ku mn ok mq ol mt om lj ne nf ng nh bi translated">经过 23 个历元的训练，模型达到了 99.54%的准确率。</li></ul><figure class="no np nq nr gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi oy"><img src="../Images/91615264c607ec3495f2b0d5ff143163.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*HAA_UPvZRihw3i17aYLvVA.png"/></div></div></figure><figure class="no np nq nr gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi oz"><img src="../Images/0463059a1843acd2e54d4a2bd4f4e819.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*o9wFBmX69Nm44RbMngw6dA.png"/></div></div></figure><h1 id="bc43" class="lk ll je bd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh bi translated">第八步</h1><blockquote class="ki kj kk"><p id="6c2c" class="kl km kn ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj im bi translated"><strong class="ko jf">输出。</strong></p></blockquote><p id="275f" class="pw-post-body-paragraph kl km je ko b kp kq kr ks kt ku kv kw mn ky kz la mq lc ld le mt lg lh li lj im bi translated">最后，是时候测试我们的模型了，还记得从车牌中提取字符的二值图像吗？让我们把图像输入到我们的模型中！</p><figure class="no np nq nr gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi pa"><img src="../Images/81f5b7b375cccb1cc7dfb668042804e1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*esXDwU6Brah9mL42BY0M-A.png"/></div></div></figure><p id="c262" class="pw-post-body-paragraph kl km je ko b kp kq kr ks kt ku kv kw mn ky kz la mq lc ld le mt lg lh li lj im bi translated">输出-</p><figure class="no np nq nr gt iv gh gi paragraph-image"><div class="gh gi pb"><img src="../Images/47aaad48090d61e821882a9a0ec2eb94.png" data-original-src="https://miro.medium.com/v2/resize:fit:1230/format:webp/1*9OWCIVp8wZvYbgajn_mC-w.png"/></div></figure><blockquote class="ki kj kk"><p id="171d" class="kl km kn ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj im bi translated"><strong class="ko jf">最终意见</strong></p></blockquote><p id="022b" class="pw-post-body-paragraph kl km je ko b kp kq kr ks kt ku kv kw mn ky kz la mq lc ld le mt lg lh li lj im bi translated">感谢你们阅读这个博客，希望这个项目对那些有志于做 OCR、图像处理、机器学习、物联网项目的人有用。</p><p id="cb8f" class="pw-post-body-paragraph kl km je ko b kp kq kr ks kt ku kv kw mn ky kz la mq lc ld le mt lg lh li lj im bi translated">如果你对这个项目有任何疑问，请在回复部分留下评论。</p><p id="ba87" class="pw-post-body-paragraph kl km je ko b kp kq kr ks kt ku kv kw mn ky kz la mq lc ld le mt lg lh li lj im bi translated">完整的项目可以在我的 Github 上找到:<br/><a class="ae nn" href="https://github.com/SarthakV7/AI-based-indian-license-plate-detection" rel="noopener ugc nofollow" target="_blank">https://Github . com/SarthakV7/AI-based-Indian-license-plate-detection</a></p><p id="472e" class="pw-post-body-paragraph kl km je ko b kp kq kr ks kt ku kv kw mn ky kz la mq lc ld le mt lg lh li lj im bi translated">在 LinkedIn 上找到我:<a class="ae nn" href="http://www.linkedin.com/in/sarthak-vajpayee" rel="noopener ugc nofollow" target="_blank">www.linkedin.com/in/sarthak-vajpayee</a></p></div></div>    
</body>
</html>