<html>
<head>
<title>How to Build Your Own PyTorch Neural Network Layer from Scratch</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">å¦‚ä½•ä»é›¶å¼€å§‹æ„å»ºè‡ªå·±çš„ PyTorch ç¥ç»ç½‘ç»œå±‚</h1>
<blockquote>åŸæ–‡ï¼š<a href="https://towardsdatascience.com/how-to-build-your-own-pytorch-neural-network-layer-from-scratch-842144d623f6?source=collection_archive---------7-----------------------#2019-11-01">https://towardsdatascience.com/how-to-build-your-own-pytorch-neural-network-layer-from-scratch-842144d623f6?source=collection_archive---------7-----------------------#2019-11-01</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="b42f" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">å¹¶äº†è§£ä¸€äº›å…³äºæƒé‡åˆå§‹åŒ–çš„çŸ¥è¯†</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/4fc2d2bffd247d756fdd4f0645d164c0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*oLcN6Vlpa-PrxnRYJGnXDQ.png"/></div></div></figure><p id="4acc" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi lq translated">è¿™å®é™…ä¸Šæ˜¯æ°ç‘ç±³Â·éœåå¾·ç¬¬äº”è¯¾çš„ä½œä¸šã€‚æˆ‘å·²ç»å±•ç¤ºäº†ä½¿ç”¨ PyTorch ä»é›¶å¼€å§‹æ„å»ºå·ç§¯ç¥ç»ç½‘ç»œæ˜¯å¤šä¹ˆå®¹æ˜“ã€‚ä»Šå¤©ï¼Œè®©æˆ‘ä»¬è¯•ç€æ›´æ·±å…¥åœ°ç ”ç©¶ä¸€ä¸‹ï¼Œçœ‹çœ‹æˆ‘ä»¬æ˜¯å¦å¯ä»¥ç¼–å†™è‡ªå·±çš„<code class="fe mc md me mf b">nn.Linear</code>æ¨¡å—ã€‚æ—¢ç„¶è„¸ä¹¦çš„å¼€å‘äººå‘˜å·²ç»å†™å¥½äº† PyTorch æ¨¡å—ï¼Œä¸ºä»€ä¹ˆè¿˜è¦æµªè´¹æ—¶é—´å†™è‡ªå·±çš„å‘¢ï¼Ÿ</p><p id="8e02" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">å—¯ï¼Œé¦–å…ˆï¼Œä½ ä¼šå¯¹æ‰€æœ‰çš„éƒ¨åˆ†æ˜¯å¦‚ä½•ç»„åˆåœ¨ä¸€èµ·çš„æœ‰æ›´æ·±çš„ç†è§£ã€‚é€šè¿‡å°†æ‚¨çš„ä»£ç ä¸ PyTorch ä»£ç è¿›è¡Œæ¯”è¾ƒï¼Œæ‚¨å°†äº†è§£ä¸ºä»€ä¹ˆä»¥åŠå¦‚ä½•å¼€å‘è¿™äº›åº“ã€‚</p><p id="6fad" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">æ­¤å¤–ï¼Œä¸€æ—¦ä½ å®Œæˆäº†ï¼Œä½ å°†å¯¹å®ç°å’Œä½¿ç”¨æ‰€æœ‰è¿™äº›åº“æ›´æœ‰ä¿¡å¿ƒï¼ŒçŸ¥é“äº‹æƒ…æ˜¯å¦‚ä½•å·¥ä½œçš„ã€‚å¯¹ä½ æ¥è¯´ä¸ä¼šæœ‰ç¥è¯ã€‚</p><p id="3f0b" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">æœ€åä½†åŒæ ·é‡è¦çš„æ˜¯ï¼Œå¦‚æœæƒ…å†µéœ€è¦ï¼Œæ‚¨å°†èƒ½å¤Ÿä¿®æ”¹/è°ƒæ•´è¿™äº›æ¨¡å—ã€‚è¿™å°±æ˜¯ noob å’Œ pro çš„åŒºåˆ«ã€‚</p><p id="17c9" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">å¥½äº†ï¼ŒåŠ¨æœºå¤Ÿäº†ï¼Œè®©æˆ‘ä»¬å¼€å§‹å§ã€‚</p></div><div class="ab cl mg mh hx mi" role="separator"><span class="mj bw bk mk ml mm"/><span class="mj bw bk mk ml mm"/><span class="mj bw bk mk ml"/></div><div class="im in io ip iq"><h2 id="4293" class="mn mo it bd mp mq mr dn ms mt mu dp mv ld mw mx my lh mz na nb ll nc nd ne nf bi translated">ç®€å•çš„ MNIST ä¸€å±‚ NN ä½œä¸ºèƒŒæ™¯</h2><p id="81fd" class="pw-post-body-paragraph ku kv it kw b kx ng ju kz la nh jx lc ld ni lf lg lh nj lj lk ll nk ln lo lp im bi lq translated">é¦–å…ˆï¼Œæˆ‘ä»¬éœ€è¦ä¸€äº›â€œèƒŒæ™¯â€ä»£ç æ¥æµ‹è¯•æˆ‘ä»¬çš„æ¨¡å—æ˜¯å¦æ‰§è¡Œä»¥åŠæ‰§è¡Œå¾—æœ‰å¤šå¥½ã€‚è®©æˆ‘ä»¬å»ºç«‹ä¸€ä¸ªéå¸¸ç®€å•çš„å•å±‚ç¥ç»ç½‘ç»œæ¥æ±‚è§£å¤è€çš„ MNIST æ•°æ®é›†ã€‚ä¸‹é¢çš„ä»£ç ç‰‡æ®µ(åœ¨ Jupyter ç¬”è®°æœ¬ä¸­è¿è¡Œ):</p><pre class="kj kk kl km gt nl mf nm nn aw no bi"><span id="7069" class="mn mo it mf b gy np nq l nr ns"># We'll use fast.ai to showcase how to build your own 'nn.Linear' module<br/>%matplotlib inline<br/>from fastai.basics import *<br/>import sys<br/><br/># create and download/prepare our MNIST dataset<br/>path = Config().data_path()/'mnist'<br/>path.mkdir(parents=True)<br/>!wget http://deeplearning.net/data/mnist/mnist.pkl.gz -P {path}<br/>  <br/># Get the images downloaded into data set<br/>with gzip.open(path/'mnist.pkl.gz', 'rb') as f:<br/>    ((x_train, y_train), (x_valid, y_valid), _) = pickle.load(f, encoding='latin-1')<br/><br/># Have a look at the images and shape<br/>plt.imshow(x_train[0].reshape((28,28)), cmap="gray")<br/>x_train.shape<br/><br/># convert numpy into PyTorch tensor<br/>x_train,y_train,x_valid,y_valid = map(torch.tensor, (x_train,y_train,x_valid,y_valid))<br/>n,c = x_train.shape<br/>x_train.shape, y_train.min(), y_train.max()<br/><br/># prepare dataset and create fast.ai DataBunch for training<br/>bs=64<br/>train_ds = TensorDataset(x_train, y_train)<br/>valid_ds = TensorDataset(x_valid, y_valid)<br/>data = DataBunch.create(train_ds, valid_ds, bs=bs)<br/><br/># create a simple MNIST logistic model with only one Linear layer<br/>class Mnist_Logistic(nn.Module):<br/>    def __init__(self):<br/>        super().__init__()<br/>        self.lin = nn.Linear(784, 10, bias=True)<br/><br/>    def forward(self, xb): return self.lin(xb)<br/><br/>model =Mnist_Logistic()<br/><br/>lr=2e-2<br/>loss_func = nn.CrossEntropyLoss()<br/><br/># define update function with weight decay<br/>def update(x,y,lr):<br/>    wd = 1e-5<br/>    y_hat = model(x)<br/>    # weight decay<br/>    w2 = 0.<br/>    for p in model.parameters(): w2 += (p**2).sum()<br/>    # add to regular loss<br/>    loss = loss_func(y_hat, y) + w2*wd<br/>    loss.requres_grad = True<br/>   <br/>    loss.backward()<br/>    with torch.no_grad():<br/>        for p in model.parameters():<br/>            p.sub_(lr * p.grad)<br/>            p.grad.zero_()<br/>    return loss.item()<br/><br/># iterate through one epoch and plot losses<br/>losses = [update(x,y,lr) for x,y in data.train_dl]<br/>plt.plot(losses);</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nt"><img src="../Images/87118bc3c56d37b557aa66ccdec73a38.png" data-original-src="https://miro.medium.com/v2/resize:fit:764/format:webp/1*p2sKZABskEsunz6WcZdf7A.png"/></div></figure><p id="484b" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">è¿™äº›ä»£ç å¾ˆå®¹æ˜“ç†è§£ã€‚æˆ‘ä»¬åœ¨è¿™ä¸ªé¡¹ç›®ä¸­ä½¿ç”¨äº†<a class="ae mb" href="https://github.com/fastai" rel="noopener ugc nofollow" target="_blank"> fast.ai </a>åº“ã€‚ä¸‹è½½ MNIST pickle æ–‡ä»¶å¹¶è§£å‹ç¼©ï¼Œå°†å…¶è½¬æ¢ä¸º PyTorch å¼ é‡ï¼Œç„¶åå°†å…¶å¡«å……åˆ° fast.ai DataBunch å¯¹è±¡ä¸­ï¼Œä»¥ä¾¿è¿›ä¸€æ­¥è®­ç»ƒã€‚ç„¶åæˆ‘ä»¬åˆ›å»ºäº†ä¸€ä¸ªåªæœ‰ä¸€ä¸ª<code class="fe mc md me mf b">Linear</code>å±‚çš„ç®€å•ç¥ç»ç½‘ç»œã€‚æˆ‘ä»¬è¿˜ç¼–å†™äº†è‡ªå·±çš„<code class="fe mc md me mf b">update</code>å‡½æ•°ï¼Œè€Œä¸æ˜¯ä½¿ç”¨<code class="fe mc md me mf b">torch.optim</code>ä¼˜åŒ–å™¨ï¼Œå› ä¸ºæˆ‘ä»¬å¯ä»¥ä»å¤´å¼€å§‹ç¼–å†™è‡ªå·±çš„ä¼˜åŒ–å™¨ï¼Œä½œä¸º PyTorch å­¦ä¹ ä¹‹æ—…çš„ä¸‹ä¸€æ­¥ã€‚æœ€åï¼Œæˆ‘ä»¬éå†æ•°æ®é›†å¹¶ç»˜åˆ¶æŸå¤±å›¾ï¼Œä»¥æŸ¥çœ‹å®ƒæ˜¯å¦æœ‰æ•ˆä»¥åŠæ•ˆæœå¦‚ä½•ã€‚</p></div><div class="ab cl mg mh hx mi" role="separator"><span class="mj bw bk mk ml mm"/><span class="mj bw bk mk ml mm"/><span class="mj bw bk mk ml"/></div><div class="im in io ip iq"><h2 id="fb23" class="mn mo it bd mp mq mr dn ms mt mu dp mv ld mw mx my lh mz na nb ll nc nd ne nf bi translated">ç¬¬ä¸€æ¬¡è¿­ä»£:è®©å®ƒå·¥ä½œ</h2><p id="0d93" class="pw-post-body-paragraph ku kv it kw b kx ng ju kz la nh jx lc ld ni lf lg lh nj lj lk ll nk ln lo lp im bi translated">æ‰€æœ‰ PyTorch æ¨¡å—/å±‚éƒ½æ˜¯ä»<code class="fe mc md me mf b">torch.nn.Module</code>æ‰©å±•è€Œæ¥ã€‚</p><pre class="kj kk kl km gt nl mf nm nn aw no bi"><span id="d6e0" class="mn mo it mf b gy np nq l nr ns">class myLinear(nn.Module):</span></pre><p id="554e" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">åœ¨è¿™ä¸ªç±»ä¸­ï¼Œæˆ‘ä»¬éœ€è¦ä¸€ä¸ª<code class="fe mc md me mf b">__init__</code> dunder å‡½æ•°æ¥åˆå§‹åŒ–æˆ‘ä»¬çš„çº¿æ€§å±‚ï¼Œå¹¶éœ€è¦ä¸€ä¸ª<code class="fe mc md me mf b">forward</code>å‡½æ•°æ¥è¿›è¡Œæ­£å‘è®¡ç®—ã€‚è®©æˆ‘ä»¬å…ˆæ¥çœ‹çœ‹<code class="fe mc md me mf b">__init__</code>å‡½æ•°ã€‚</p><p id="088b" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">æˆ‘ä»¬å°†ä½¿ç”¨ PyTorch å®˜æ–¹æ–‡æ¡£ä½œä¸ºæ„å»ºæ¨¡å—çš„æŒ‡å—ã€‚ä»æ–‡æ¡£ä¸­å¯ä»¥çœ‹å‡ºï¼Œ<code class="fe mc md me mf b">nn.Linear</code>æ¨¡å—å…·æœ‰ä»¥ä¸‹å±æ€§:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><a href="https://pytorch.org/docs/stable/nn.html#linear"><div class="gh gi nu"><img src="../Images/b4ec4e8cd4a40df76e806dffba33d0a3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*eDRvelSa-3eugiKZ2X_fdw.png"/></div></a></figure><p id="89fa" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">å› æ­¤ï¼Œæˆ‘ä»¬å°†è·å¾—è¿™ä¸‰ä¸ªå±æ€§:</p><pre class="kj kk kl km gt nl mf nm nn aw no bi"><span id="0192" class="mn mo it mf b gy np nq l nr ns">def __init__(self, <strong class="mf iu">in_features, out_features, bias=True</strong>):<br/>        super().__init__()<br/>       <strong class="mf iu"> self.in_features = in_features<br/>        self.out_features = out_features<br/>        self.bias = bias</strong></span></pre><p id="4a98" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">è¯¥ç±»è¿˜éœ€è¦ä¿å­˜é‡é‡å’Œåå·®å‚æ•°ï¼Œä»¥ä¾¿è¿›è¡Œè®­ç»ƒã€‚æˆ‘ä»¬ä¹Ÿåˆå§‹åŒ–é‚£äº›ã€‚</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nv"><img src="../Images/8f25b7ddfc61ec19951380c54192835f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*bxuSixoCvOkpt9HijP_4Mg.png"/></div></div></figure><pre class="kj kk kl km gt nl mf nm nn aw no bi"><span id="2269" class="mn mo it mf b gy np nq l nr ns">       <strong class="mf iu"> self.weight</strong> = torch.nn.Parameter(torch.randn(out_features, in_features))<br/>       <strong class="mf iu"> self.bias</strong> = torch.nn.Parameter(torch.randn(out_features))</span></pre><p id="e563" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">è¿™é‡Œæˆ‘ä»¬ç”¨<code class="fe mc md me mf b">torch.nn.Parameter</code>æ¥è®¾ç½®æˆ‘ä»¬çš„<code class="fe mc md me mf b">weight</code>å’Œ<code class="fe mc md me mf b">bias</code>ï¼Œå¦åˆ™ï¼Œå®ƒä¸ä¼šè®­ç»ƒã€‚</p><p id="d431" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">å¦å¤–ï¼Œè¯·æ³¨æ„ï¼Œæˆ‘ä»¬ä½¿ç”¨äº†<code class="fe mc md me mf b"><a class="ae mb" href="https://pytorch.org/docs/stable/torch.html#torch.randn" rel="noopener ugc nofollow" target="_blank">torch.rand</a>n</code>è€Œä¸æ˜¯æ–‡æ¡£ä¸­æè¿°çš„æ¥åˆå§‹åŒ–å‚æ•°ã€‚è¿™ä¸æ˜¯æƒé‡åˆå§‹åŒ–çš„æœ€ä½³æ–¹å¼ï¼Œä½†æˆ‘ä»¬çš„ç›®çš„æ˜¯è®©å®ƒå…ˆå·¥ä½œï¼Œæˆ‘ä»¬å°†åœ¨ä¸‹ä¸€æ¬¡è¿­ä»£ä¸­è°ƒæ•´å®ƒã€‚</p><p id="10d3" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">å¥½äº†ï¼Œç°åœ¨<code class="fe mc md me mf b">__init__</code>éƒ¨åˆ†å®Œæˆäº†ï¼Œè®©æˆ‘ä»¬ç»§ç»­<code class="fe mc md me mf b">forward</code>åŠŸèƒ½ã€‚è¿™å®é™…ä¸Šæ˜¯æœ€ç®€å•çš„éƒ¨åˆ†:</p><pre class="kj kk kl km gt nl mf nm nn aw no bi"><span id="3889" class="mn mo it mf b gy np nq l nr ns">def forward(self, input):<br/>        _, y = input.shape<br/>        if y != self.in_features:<br/>            sys.exit(f'Wrong Input Features. Please use tensor with {self.in_features} Input Features')<br/>        <strong class="mf iu">output = input @ self.weight.t() + self.bias<br/>        return output</strong></span></pre><p id="371a" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">æˆ‘ä»¬é¦–å…ˆè·å¾—è¾“å…¥çš„å½¢çŠ¶ï¼Œè®¡ç®—å‡ºè¾“å…¥ä¸­æœ‰å¤šå°‘åˆ—ï¼Œç„¶åæ£€æŸ¥è¾“å…¥å¤§å°æ˜¯å¦åŒ¹é…ã€‚ç„¶åæˆ‘ä»¬åšçŸ©é˜µä¹˜æ³•(æ³¨æ„æˆ‘ä»¬åœ¨è¿™é‡Œåšäº†è½¬ç½®æ¥è°ƒæ•´æƒé‡)å¹¶è¿”å›ç»“æœã€‚æˆ‘ä»¬å¯ä»¥é€šè¿‡ç»™å®ƒä¸€äº›æ•°æ®æ¥æµ‹è¯•å®ƒæ˜¯å¦æœ‰æ•ˆ:</p><pre class="kj kk kl km gt nl mf nm nn aw no bi"><span id="2707" class="mn mo it mf b gy np nq l nr ns">my = myLinear(20,10)<br/>a = torch.randn(5,20)<br/>my(a)</span></pre><p id="172f" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">æˆ‘ä»¬æœ‰ä¸€ä¸ª 5x20 çš„è¾“å…¥ï¼Œå®ƒé€šè¿‡æˆ‘ä»¬çš„å±‚ï¼Œå¾—åˆ°ä¸€ä¸ª 5x10 çš„è¾“å‡ºã€‚æ‚¨åº”è¯¥ä¼šå¾—åˆ°è¿™æ ·çš„ç»“æœ:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nw"><img src="../Images/43f920d9c13ef78c6b8d4960099481ed.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*uz_Hb4rul6pYs0bMIcTEBQ.png"/></div></div></figure><p id="a691" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">å¥½ï¼Œç°åœ¨å›åˆ°æˆ‘ä»¬çš„ç¥ç»ç½‘ç»œä»£ç ï¼Œæ‰¾åˆ°<code class="fe mc md me mf b">Mnist_Logistic</code>ç±»ï¼Œå°†<code class="fe mc md me mf b">self.lin = nn.Linear(784,10, bias=True)</code>æ”¹ä¸º<code class="fe mc md me mf b">self.lin = myLinear(784, 10, bias=True)</code>ã€‚è¿è¡Œä»£ç ï¼Œæ‚¨åº”è¯¥ä¼šçœ‹åˆ°ç±»ä¼¼è¿™æ ·çš„å›¾:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nt"><img src="../Images/3f8165786fd3813b281e1c5eb84c436b.png" data-original-src="https://miro.medium.com/v2/resize:fit:764/format:webp/1*IdvjAdDwEwhgLw0hRi2zwg.png"/></div></figure><p id="527b" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">å¦‚ä½ æ‰€è§ï¼Œå®ƒæ²¡æœ‰å¾ˆå¥½åœ°æ”¶æ•›(ä¸€ä¸ªæ—¶æœŸå¤§çº¦ 2.5 æ¬¡æŸå¤±)ã€‚é‚£å¾ˆå¯èƒ½æ˜¯å› ä¸ºæˆ‘ä»¬åˆå§‹åŒ–ä¸å¥½ã€‚å¦å¤–ï¼Œæˆ‘ä»¬æ²¡æœ‰æ³¨æ„åˆ°<code class="fe mc md me mf b">bias</code>éƒ¨åˆ†ã€‚è®©æˆ‘ä»¬åœ¨ä¸‹ä¸€æ¬¡è¿­ä»£ä¸­è§£å†³è¿™ä¸ªé—®é¢˜ã€‚ç¬¬ä¸€æ¬¡è¿­ä»£çš„æœ€ç»ˆä»£ç å¦‚ä¸‹æ‰€ç¤º:</p><pre class="kj kk kl km gt nl mf nm nn aw no bi"><span id="c7bb" class="mn mo it mf b gy np nq l nr ns">class myLinear(nn.Module):<br/>    def __init__(self, in_features, out_features, bias=True):<br/>        super().__init__()<br/>        self.in_features = in_features<br/>        self.out_features = out_features<br/>        self.bias = bias<br/>        self.weight = torch.nn.Parameter(torch.randn(out_features, in_features))<br/>        self.bias = torch.nn.Parameter(torch.randn(out_features))<br/>       <br/>        <br/>    def forward(self, input):<br/>        x, y = input.shape<br/>        if y != self.in_features:<br/>            sys.exit(f'Wrong Input Features. Please use tensor with {self.in_features} Input Features')<br/>        output = input @ self.weight.t() + self.bias<br/>        return output</span></pre></div><div class="ab cl mg mh hx mi" role="separator"><span class="mj bw bk mk ml mm"/><span class="mj bw bk mk ml mm"/><span class="mj bw bk mk ml"/></div><div class="im in io ip iq"><h2 id="c1a8" class="mn mo it bd mp mq mr dn ms mt mu dp mv ld mw mx my lh mz na nb ll nc nd ne nf bi translated">ç¬¬äºŒæ¬¡è¿­ä»£:æ­£ç¡®çš„æƒé‡åˆå§‹åŒ–å’Œåå·®å¤„ç†</h2><p id="38c6" class="pw-post-body-paragraph ku kv it kw b kx ng ju kz la nh jx lc ld ni lf lg lh nj lj lk ll nk ln lo lp im bi translated">æˆ‘ä»¬å·²ç»å¤„ç†äº†<code class="fe mc md me mf b">__init__</code>å’Œ<code class="fe mc md me mf b">forward</code>ï¼Œä½†æ˜¯è®°ä½æˆ‘ä»¬è¿˜æœ‰ä¸€ä¸ª<code class="fe mc md me mf b">bias</code>å±æ€§ï¼Œå¦‚æœ<code class="fe mc md me mf b">False</code>ï¼Œå°†ä¸ä¼šå­¦ä¹ åŠ æ³•åå·®ã€‚æˆ‘ä»¬è¿˜æ²¡æœ‰å®æ–½ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬ä½¿ç”¨<code class="fe mc md me mf b">torch.nn.randn</code>æ¥åˆå§‹åŒ–æƒé‡å’Œåå·®ï¼Œè¿™ä¸æ˜¯æœ€ä½³çš„ã€‚è®©æˆ‘ä»¬è§£å†³è¿™ä¸ªé—®é¢˜ã€‚æ›´æ–°åçš„<code class="fe mc md me mf b">__init__</code>å‡½æ•°å¦‚ä¸‹:</p><pre class="kj kk kl km gt nl mf nm nn aw no bi"><span id="ae3c" class="mn mo it mf b gy np nq l nr ns">def __init__(self, in_features, out_features, bias=True):<br/>        super().__init__()<br/>        self.in_features = in_features<br/>        self.out_features = out_features<br/>        self.bias = bias<br/>        <strong class="mf iu">self.weight = torch.nn.Parameter(torch.Tensor(out_features, in_features))<br/>        if bias:<br/>            self.bias = torch.nn.Parameter(torch.Tensor(out_features))<br/>        else:<br/>            self.register_parameter('bias', None)</strong></span><span id="fd2a" class="mn mo it mf b gy nx nq l nr ns"><strong class="mf iu">        self.reset_parameters()</strong></span></pre><p id="c225" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">é¦–å…ˆï¼Œå½“æˆ‘ä»¬åˆ›å»º<code class="fe mc md me mf b">weight</code>å’Œ<code class="fe mc md me mf b">bias</code>å‚æ•°æ—¶ï¼Œæˆ‘ä»¬æ²¡æœ‰å°†å®ƒä»¬åˆå§‹åŒ–ä¸ºæœ€åä¸€æ¬¡è¿­ä»£ã€‚æˆ‘ä»¬åªæ˜¯ç»™å®ƒåˆ†é…ä¸€ä¸ªè§„åˆ™çš„å¼ é‡å¯¹è±¡ã€‚å®é™…çš„åˆå§‹åŒ–åœ¨å¦ä¸€ä¸ªå‡½æ•°<code class="fe mc md me mf b">reset_parameters</code>ä¸­å®Œæˆ(<em class="ny">å°†åœ¨åé¢è§£é‡Š</em>)ã€‚</p><p id="10bd" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">å¯¹äº<code class="fe mc md me mf b">bias</code>ï¼Œæˆ‘ä»¬å¢åŠ äº†ä¸€ä¸ªæ¡ä»¶ï¼Œå¦‚æœ<code class="fe mc md me mf b">True</code>ï¼Œåšæˆ‘ä»¬ä¸Šä¸€æ¬¡è¿­ä»£åšçš„äº‹æƒ…ï¼Œä½†æ˜¯å¦‚æœ<code class="fe mc md me mf b">False</code>ï¼Œå°†ä½¿ç”¨<code class="fe mc md me mf b">register_parameter(â€˜biasâ€™, None)</code>ç»™å®ƒ<code class="fe mc md me mf b">None</code>å€¼ã€‚ç°åœ¨å¯¹äº<code class="fe mc md me mf b">reset_parameter</code>åŠŸèƒ½ï¼Œå®ƒçœ‹èµ·æ¥æ˜¯è¿™æ ·çš„:</p><pre class="kj kk kl km gt nl mf nm nn aw no bi"><span id="7e7e" class="mn mo it mf b gy np nq l nr ns">def reset_parameters(self):<br/>        <strong class="mf iu">torch.nn.init.kaiming_uniform_(self.weight, a=math.sqrt(5))</strong><br/>        if self.bias is not None:<br/>            <strong class="mf iu">fan_in, _ torch.nn.init._calculate_fan_in_and_fan_out(self.weight)<br/>            bound = 1 / math.sqrt(fan_in)<br/>            torch.nn.init.uniform_(self.bias, -bound, bound)</strong></span></pre><p id="800c" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">ä»¥ä¸Šä»£ç ç›´æ¥å–è‡ª PyTorch æºä»£ç ã€‚PyTorch å¯¹æƒé‡åˆå§‹åŒ–æ‰€åšçš„ç§°ä¸º<code class="fe mc md me mf b">kaiming_uniform_</code>ã€‚å®ƒæ¥è‡ªä¸€ç¯‡è®ºæ–‡<a class="ae mb" href="https://arxiv.org/pdf/1502.01852.pdf" rel="noopener ugc nofollow" target="_blank">æ·±å…¥ç ”ç©¶æ•´æµå™¨:åœ¨ ImageNet åˆ†ç±»ä¸Šè¶…è¶Šäººç±»æ°´å¹³çš„æ€§èƒ½â€”â€”ä½•ï¼Œk .ç­‰äºº(2015) </a>ã€‚</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nz"><img src="../Images/6886e67fa7fd0d400f96a6562a6376eb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1372/format:webp/1*cq0NDktwlKPtWQ2OrhL67Q.png"/></div></figure><p id="7448" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">å®ƒå®é™…ä¸Šæ‰€åšçš„æ˜¯é€šè¿‡ç”¨å‡å€¼ä¸º 0 ä¸”æ–¹å·®ä¸º T16 çš„æ­£æ€åˆ†å¸ƒ<strong class="kw iu">åˆå§‹åŒ–æƒé‡ï¼Œå®ƒé¿å…äº†<strong class="kw iu">æ¶ˆå¤±/çˆ†ç‚¸æ¢¯åº¦</strong>çš„é—®é¢˜(<em class="ny">å°½ç®¡æˆ‘ä»¬åœ¨è¿™é‡Œåªæœ‰ä¸€å±‚ï¼Œå½“ç¼–å†™çº¿æ€§ç±»æ—¶ï¼Œæˆ‘ä»¬ä»ç„¶åº”è¯¥è®°ä½ MLN</em>)ã€‚</strong></p><p id="b30f" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">è¯·æ³¨æ„ï¼Œå¯¹äº<code class="fe mc md me mf b">self.weight</code>ï¼Œæˆ‘ä»¬å®é™…ä¸Šç»™äº†<code class="fe mc md me mf b">a</code>ä¸€ä¸ªå€¼<code class="fe mc md me mf b">math.sqrt(5)</code>è€Œä¸æ˜¯<code class="fe mc md me mf b">math.sqrt(fan_in)</code>ï¼Œè¿™åœ¨ PyTorch repo çš„<a class="ae mb" href="https://github.com/pytorch/pytorch/issues/15314" rel="noopener ugc nofollow" target="_blank"> this GitHub issue </a>ä¸­æœ‰æ‰€è§£é‡Šï¼Œå¯èƒ½æœ‰äººå¯¹æ­¤æ„Ÿå…´è¶£ã€‚</p><p id="c908" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">åŒæ ·ï¼Œæˆ‘ä»¬å¯ä»¥åœ¨æ¨¡å‹ä¸­æ·»åŠ ä¸€äº›<code class="fe mc md me mf b">extra_repr</code>å­—ç¬¦ä¸²:</p><pre class="kj kk kl km gt nl mf nm nn aw no bi"><span id="a325" class="mn mo it mf b gy np nq l nr ns">def extra_repr(self):<br/>        return 'in_features={}, out_features={}, bias={}'.format(<br/>            self.in_features, self.out_features, self.bias is not None<br/>        )</span></pre><p id="70ca" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">æœ€ç»ˆçš„æ¨¡å‹å¦‚ä¸‹æ‰€ç¤º:</p><pre class="kj kk kl km gt nl mf nm nn aw no bi"><span id="6890" class="mn mo it mf b gy np nq l nr ns">class myLinear(nn.Module):<br/>    def __init__(self, in_features, out_features, bias=True):<br/>        super().__init__()<br/>        self.in_features = in_features<br/>        self.out_features = out_features<br/>        self.bias = bias<br/>        self.weight = torch.nn.Parameter(torch.Tensor(out_features, in_features))<br/>        if bias:<br/>            self.bias = torch.nn.Parameter(torch.Tensor(out_features))<br/>        else:<br/>            self.register_parameter('bias', None)<br/>        self.reset_parameters()<br/>        <br/>    def reset_parameters(self):<br/>        torch.nn.init.kaiming_uniform_(self.weight, a=math.sqrt(5))<br/>        if self.bias is not None:<br/>            fan_in, _ = torch.nn.init._calculate_fan_in_and_fan_out(self.weight)<br/>            bound = 1 / math.sqrt(fan_in)<br/>            torch.nn.init.uniform_(self.bias, -bound, bound)<br/>        <br/>    def forward(self, input):<br/>        x, y = input.shape<br/>        if y != self.in_features:<br/>            print(f'Wrong Input Features. Please use tensor with {self.in_features} Input Features')<br/>            return 0<br/>        output = input.matmul(weight.t())<br/>        if bias is not None:<br/>            output += bias<br/>        ret = output<br/>        return ret<br/>    <br/>    def extra_repr(self):<br/>        return 'in_features={}, out_features={}, bias={}'.format(<br/>            self.in_features, self.out_features, self.bias is not None<br/>        )</span></pre><p id="05e2" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">é‡æ–°è¿è¡Œä»£ç ï¼Œæ‚¨åº”è¯¥èƒ½å¤Ÿçœ‹åˆ°è¿™ä¸ªå›¾:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nt"><img src="../Images/d515b224aa298e7ae0654cdba9dcbad2.png" data-original-src="https://miro.medium.com/v2/resize:fit:764/format:webp/1*6nUlBO7nIt9t2E0xrfgP-w.png"/></div></figure><p id="7683" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">æˆ‘ä»¬å¯ä»¥çœ‹åˆ°ï¼Œå®ƒåœ¨ä¸€ä¸ªæ—¶æœŸå†…æ”¶æ•›åˆ° 0.5 çš„æŸè€—è¦å¿«å¾—å¤šã€‚</p></div><div class="ab cl mg mh hx mi" role="separator"><span class="mj bw bk mk ml mm"/><span class="mj bw bk mk ml mm"/><span class="mj bw bk mk ml"/></div><div class="im in io ip iq"><h2 id="dd5b" class="mn mo it bd mp mq mr dn ms mt mu dp mv ld mw mx my lh mz na nb ll nc nd ne nf bi translated">ç»“è®º</h2><p id="8159" class="pw-post-body-paragraph ku kv it kw b kx ng ju kz la nh jx lc ld ni lf lg lh nj lj lk ll nk ln lo lp im bi translated">æˆ‘å¸Œæœ›è¿™èƒ½å¸®ä½ é©±æ•£è¿™äº› PyTorch <code class="fe mc md me mf b">nn.modules</code>ä¸Šçš„é˜´éœ¾ã€‚è¿™å¯èƒ½çœ‹èµ·æ¥å¾ˆæ— èŠå’Œå¤šä½™ï¼Œä½†æœ‰æ—¶æœ€å¿«(ä¹Ÿæ˜¯æœ€çŸ­)çš„æ–¹æ³•å°±æ˜¯â€œæ— èŠâ€çš„æ–¹æ³•ã€‚ä¸€æ—¦ä½ æ·±ç©¶æ­¤äº‹ï¼Œé‚£ç§çŸ¥é“æ²¡æœ‰ä»€ä¹ˆâ€œæ›´å¤šâ€çš„æ„Ÿè§‰æ˜¯æ— ä»·çš„ã€‚ä½ ä¼šæ„è¯†åˆ°:</p><blockquote class="oa"><p id="55b6" class="ob oc it bd od oe of og oh oi oj lp dk translated">åœ¨ PyTorch ä¸‹é¢ï¼Œæ²¡æœ‰æŠ€å·§ï¼Œæ²¡æœ‰ç¥è¯ï¼Œæ²¡æœ‰é™·é˜±ï¼Œåªæœ‰åšå¦‚ç£çŸ³çš„ Python ä»£ç ã€‚</p></blockquote><p id="45ff" class="pw-post-body-paragraph ku kv it kw b kx ok ju kz la ol jx lc ld om lf lg lh on lj lk ll oo ln lo lp im bi translated">æ­¤å¤–ï¼Œé€šè¿‡ç¼–å†™è‡ªå·±çš„ä»£ç ï¼Œç„¶åä¸å®˜æ–¹æºä»£ç è¿›è¡Œæ¯”è¾ƒï¼Œæ‚¨å°†èƒ½å¤Ÿçœ‹åˆ°ä¸åŒä¹‹å¤„ï¼Œå¹¶å‘è¡Œä¸šä¸­çš„ä½¼ä½¼è€…å­¦ä¹ ã€‚å¤šé…·å•Šã€‚</p></div><div class="ab cl mg mh hx mi" role="separator"><span class="mj bw bk mk ml mm"/><span class="mj bw bk mk ml mm"/><span class="mj bw bk mk ml"/></div><div class="im in io ip iq"><p id="7ac5" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">è§‰å¾—è¿™ç¯‡æ–‡ç« æœ‰ç”¨ï¼Ÿåœ¨ Medium ä¸Šå…³æ³¨æˆ‘(<a class="ae mb" href="https://medium.com/u/72c98619a048?source=post_page-----dbe7106145f5----------------------" rel="noopener">æç«‹ä¼Ÿ</a>)æˆ–è€…ä½ å¯ä»¥åœ¨ Twitter <a class="ae mb" href="https://twitter.com/lymenlee" rel="noopener ugc nofollow" target="_blank"> @lymenlee </a>æˆ–è€…æˆ‘çš„åšå®¢ç½‘ç«™<a class="ae mb" href="https://wayofnumbers.com/" rel="noopener ugc nofollow" target="_blank">wayofnumbers.com</a>ä¸Šæ‰¾åˆ°æˆ‘ã€‚ä½ ä¹Ÿå¯ä»¥çœ‹çœ‹æˆ‘ä¸‹é¢æœ€å—æ¬¢è¿çš„æ–‡ç« ï¼</p><div class="op oq gp gr or os"><a rel="noopener follow" target="_blank" href="/this-is-cs50-a-pleasant-way-to-kick-off-your-data-science-education-d6075a6e761a"><div class="ot ab fo"><div class="ou ab ov cl cj ow"><h2 class="bd iu gy z fp ox fr fs oy fu fw is bi translated">â€œè¿™æ˜¯ CS50â€:å¼€å§‹æ•°æ®ç§‘å­¦æ•™è‚²çš„æ„‰å¿«æ–¹å¼</h2><div class="oz l"><h3 class="bd b gy z fp ox fr fs oy fu fw dk translated">ä¸ºä»€ä¹ˆ CS50 ç‰¹åˆ«é€‚åˆå·©å›ºä½ çš„è½¯ä»¶å·¥ç¨‹åŸºç¡€</h3></div><div class="pa l"><p class="bd b dl z fp ox fr fs oy fu fw dk translated">towardsdatascience.com</p></div></div><div class="pb l"><div class="pc l pd pe pf pb pg ks os"/></div></div></a></div><div class="op oq gp gr or os"><a rel="noopener follow" target="_blank" href="/two-sides-of-the-same-coin-fast-ai-vs-deeplearning-ai-b67e9ec32133"><div class="ot ab fo"><div class="ou ab ov cl cj ow"><h2 class="bd iu gy z fp ox fr fs oy fu fw is bi translated">ä¸€æšç¡¬å¸çš„ä¸¤é¢:æ°ç‘ç±³Â·éœåå¾·çš„ fast.ai vs å´æ©è¾¾çš„ deeplearning.ai</h2><div class="oz l"><h3 class="bd b gy z fp ox fr fs oy fu fw dk translated">å¦‚ä½•ä¸é€šè¿‡åŒæ—¶å‚åŠ  fast.ai å’Œ deeplearning.ai è¯¾ç¨‹æ¥â€œè¿‡åº¦é€‚åº”â€ä½ çš„äººå·¥æ™ºèƒ½å­¦ä¹ </h3></div><div class="pa l"><p class="bd b dl z fp ox fr fs oy fu fw dk translated">towardsdatascience.com</p></div></div><div class="pb l"><div class="ph l pd pe pf pb pg ks os"/></div></div></a></div><div class="op oq gp gr or os"><a rel="noopener follow" target="_blank" href="/what-you-need-to-know-about-netflixs-jupyter-killer-polynote-dbe7106145f5"><div class="ot ab fo"><div class="ou ab ov cl cj ow"><h2 class="bd iu gy z fp ox fr fs oy fu fw is bi translated">ä½ éœ€è¦äº†è§£ç½‘é£çš„â€œæœ±åº‡ç‰¹é»‘ä»”â€:å†°ç©´ğŸ“–</h2><div class="oz l"><h3 class="bd b gy z fp ox fr fs oy fu fw dk translated">æ˜¯æ—¶å€™è®© Jupyter ç¬”è®°æœ¬æœ‰ä¸ªæœ‰ä»·å€¼çš„ç«äº‰å¯¹æ‰‹äº†</h3></div><div class="pa l"><p class="bd b dl z fp ox fr fs oy fu fw dk translated">towardsdatascience.com</p></div></div><div class="pb l"><div class="pi l pd pe pf pb pg ks os"/></div></div></a></div></div></div>    
</body>
</html>