# 积分级训练/测试分裂的危险

> 原文：<https://towardsdatascience.com/the-perils-of-point-level-train-test-splits-f4eec67668ab?source=collection_archive---------40----------------------->

将你的数据拆分成 Train/Valid/Test 并不像`from sklearn.model_selection import train_test_split`那么简单。当你有一些数据点和其他数据点真的很接近的时候，用幼稚的方式随机拆分你的例子，会让你觉得你的模型比实际更准确。让我给你举几个亲身经历的例子。

示例 1:法律文档上的命名实体识别

我为一家公司(http://atrium.co)工作，该公司有来自几百个客户的几千份文件，我们想要一个模型，它可以提取文件并找出投资者是谁。使用了一个 [CRF](https://en.wikipedia.org/wiki/Conditional_random_field) 。

该模型的早期迭代的验证和“测试”准确度在 80%左右，但在新客户的新文档中低于 50%。出了什么事？*

您可能希望模型查看类似 PREVIOUS_WORD2=='Investor '或 NEXT_WORD2=='Purchase '的功能。但当我们查看该模型考虑的权重最大的因素时，排在首位的都是类似 WORD _ IDENTITY =[特定投资者名称]这样的东西。标准的过度拟合问题，可以通过增加一个单词在模型认为它是一个真正的单词之前必须出现在文档中的百分比来解决，而不仅仅是把它扔进<unk>堆。但有趣的是，就我们的训练/测试分割而言，*并没有*过度拟合，因为【特定投资者名称】也出现在测试集中！</unk>

为了更准确地评估模型的性能，关键是在客户级别而不是在文档级别进行拆分。如果我们有一堆客户 A 的文档，投资者 B 给了他们钱，它们要么都在训练集中，要么都在测试集中。这样做使我们的测试准确度和我们实际的真实测试准确度一致。

示例 2:蛋白质

蛋白质由氨基酸组成。大约有 20 种氨基酸，所以每种蛋白质都是由 20 个字符的字母表组成的一个单词，或者如果你喜欢，也可以是由 20 个单词的字典组成的一个句子。

你可能还记得最近一篇名为[“使用深度学习来注释蛋白质宇宙”](https://www.biorxiv.org/content/10.1101/626507v1.full)的谷歌论文/公告，其中他们让 CNN 的狗来研究这些单词/句子，并学习预测世界上的每一个属性。

这篇论文在 5 月份得到了预印，但尚未在任何地方发表，这些 Twitter 用户提出了一个可能的原因:如果你检查他们的“严格基准数据集”部分，他们将序列分成训练和随机测试，但数据集中有一些序列与其他序列非常接近，如果它们在训练和测试之间分开，那么模型可以说“看不见的”测试序列与它确实看到的超级相似的训练序列具有相同的属性。

[我不是在批评那些看起来很酷的论文作者//支持他们调查的广泛的财产//我可能对他们的方法有些误解。]

我在研究一个模型时遇到了类似的问题，该模型旨在预测一种蛋白质作为攻城锤突破细胞壁并运送它碰巧携带的任何珍贵货物的能力。我们有一份 1000 种蛋白质的清单，这些蛋白质是从不同科学家进行的实验中收集来的。但是很多时候实验者会研究一个主题的一堆变体，看看哪一个效果最好。因此，分割训练/测试数据的正确方法不是按蛋白质，而是按“主题”，我们通过基于您最喜欢的氨基酸序列之间的距离度量的分层聚类来建模。

总之，不要简单地分割你的数据。分层前批准。劈开之前先怀孕。如果你以前遇到过这种事情，请告诉我，我正在收集例子。

*   人们说“什么给”，所以我想我会去一个过去式的版本。

[原发于[https://zswitten . github . io/2019/11/03/train-test-splitting . html](https://zswitten.github.io/2019/11/03/train-test-splitting.html)]