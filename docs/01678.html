<html>
<head>
<title>Introducing Mercury-ML: an open-source “messenger of the machine learning gods”</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">介绍 Mercury-ML:一个开源的“机器学习之神的使者”</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/introducing-mercury-ml-an-open-source-messenger-of-the-machine-learning-gods-c571f90e6b36?source=collection_archive---------27-----------------------#2019-03-18">https://towardsdatascience.com/introducing-mercury-ml-an-open-source-messenger-of-the-machine-learning-gods-c571f90e6b36?source=collection_archive---------27-----------------------#2019-03-18</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><figure class="gl gn js jt ju jv gh gi paragraph-image"><div role="button" tabindex="0" class="jw jx di jy bf jz"><div class="gh gi jr"><img src="../Images/b2707d9f441cde603404932455ee7f71.png" data-original-src="https://miro.medium.com/v2/resize:fit:1200/format:webp/1*9Yrw8GHnOSMZvjufBFWhWQ.jpeg"/></div></div></figure><p id="6c8f" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">在古罗马神话中，墨丘利神被称为“众神的使者”。他穿着带翼的鞋子，戴着带翼的帽子，在奥林匹斯山和人类王国之间飞奔，确保众神的意志被知晓。他不是众神中最强壮、最聪明、最受尊敬或最令人畏惧的，但他脚步敏捷、狡猾，可以依靠他来引导事情朝着他们想要的结果发展。没有他，珀尔修斯不可能打败美杜莎；奥德修斯可能会中了喀尔刻的魔咒；而赫拉克勒斯也不可能将冥府之神地狱犬从冥府中拖出来，从而完成他 12 项神话般的劳动中的最后一项…</p><p id="1c27" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">在这篇文章中，我想介绍一个名为<a class="ae la" href="https://github.com/mercury-ml-team/mercury-ml" rel="noopener ugc nofollow" target="_blank"> Mercury-ML </a>的新项目，以及开源的“机器学习之神的使者”。</p><p id="f8df" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated"><strong class="ke ir">机器学习工作流程看似简单，却依赖于多种工具和技术的复杂组合</strong></p><p id="fd03" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">机器学习和数据处理工具的最新发展导致了无数的开源库，其中每个库都提供了开发良好的透明 API，并且每个库都在构建健壮的机器学习工作流时发挥作用。经常使用的机器学习库，如 TensorFlow、PyTorch、Keras 或 SciKit-Learn，通常会形成这种工作流的主干，但仍然有来自不同库的无数功能，通常需要串在一起才能完成工作流。</p><p id="c7dc" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">例如，考虑一个图像识别工作流，您需要从 HDFS 获取图像；在这些图像上拟合 Keras 模型；使用 SciKit-Learn 评估模型；在 AWS 上将训练好的模型保存到 S3；在 MongoDB 中存储训练运行的元数据；并最终使用 TensorFlow 服务来服务模型。你如何建立这样的工作流程？</p><p id="b62d" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">此外，如果您的需求在项目中途发生变化，以至于您需要从其他地方获取数据，或者需要使用不同的机器学习引擎，该怎么办？你将如何拔掉这些组件中的一个并用另一个替换它？您需要引入多少新代码(和测试！)才能让这个正常工作？</p></div><div class="ab cl lb lc hu ld" role="separator"><span class="le bw bk lf lg lh"/><span class="le bw bk lf lg lh"/><span class="le bw bk lf lg"/></div><div class="ij ik il im in"><p id="0195" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated"><strong class="ke ir">机器学习工作流程的上帝使者</strong></p><figure class="lj lk ll lm gt jv gh gi paragraph-image"><div class="gh gi li"><img src="../Images/92194f7530b5efdbb90589d8a61e4067.png" data-original-src="https://miro.medium.com/v2/resize:fit:600/format:webp/1*Hvk5BfohZLCk2eyspCG2xw.jpeg"/></div></figure><p id="2bab" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">这些是我们在<a class="ae la" href="https://www.alexanderthamm.com/en/" rel="noopener ugc nofollow" target="_blank"> Alexander Thamm </a>为客户开发机器学习解决方案时经常面临的一些非常现实的问题。</p><p id="67e3" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">最近，我们很清楚，我们需要一个能够将机器学习项目分解成典型组件(如读取数据、转换数据、拟合模型、评估模型、服务模型等)的库。)足够模块化和通用，允许我们根据需要插入不同的技术。</p><p id="c364" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">最初是一个帮助我们更好地完成自己工作的内部项目，现在已经发展成为我们认为值得作为开源库提供给更广泛的社区的东西。因此，我们决定让 Mercury-ML——我们内部开发的“机器学习之神的使者”——在 MIT 许可下在 GitHub 上可用<a class="ae la" href="https://github.com/mercury-ml-team/mercury-ml" rel="noopener ugc nofollow" target="_blank">。</a></p><p id="4bfb" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">最新的稳定版本也将始终在<a class="ae la" href="https://pypi.org/project/mercury-ml/" rel="noopener ugc nofollow" target="_blank"> PyPi </a>上提供，并且可以使用“pip install mercury-ml”进行安装</p><p id="3a9c" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">(注意，尽管这个库已经有了丰富的特性，但它还远远没有达到特性的完备。我们暂时将它标记为“预发布”，这意味着一些大范围的变化仍然可能发生。</p><p id="1401" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated"><strong class="ke ir">工作原理</strong></p><p id="7feb" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">Mercury-ML 旨在提供对不同抽象层次功能的简化访问。</p><p id="d128" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">作为这种工作方式的一个简单例子，让我们看看通常构成机器学习工作流一部分的两个小组件:保存拟合的模型，然后将保存的对象存储在远程位置(以后可以从该位置提供服务)。为此，我们将考察四个抽象层次:</p><ol class=""><li id="b665" class="ln lo iq ke b kf kg kj kk kn lp kr lq kv lr kz ls lt lu lv bi translated">不使用 Mercury-ML(即直接使用底层依赖关系)</li><li id="4b8d" class="ln lo iq ke b kf lw kj lx kn ly kr lz kv ma kz ls lt lu lv bi translated">使用提供者 API</li><li id="fc78" class="ln lo iq ke b kf lw kj lx kn ly kr lz kv ma kz ls lt lu lv bi translated">使用容器 API</li><li id="877a" class="ln lo iq ke b kf lw kj lx kn ly kr lz kv ma kz ls lt lu lv bi translated">使用任务 API(结合容器 API)</li></ol><p id="4e6d" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">这些方法中的每一种都是完全有效的，尽管在某些情况下一种可能比另一种更有意义。让我们来看看:</p><p id="4fba" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated"><strong class="ke ir">参数化:</strong></p><p id="396a" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">对于这个例子，我们将保存一个 Keras 模型，并将其存储到 AWS 上的 S3 存储桶中。假设我们有以下输入:</p><pre class="lj lk ll lm gt mb jq mc md aw me bi"><span id="3608" class="mf mg iq jq b gy mh mi l mj mk">model = … # assume a fitted Keras model fetched here<br/>filename = “my_model”<br/>local_dir = “./local_models”<br/>extension = “.h5”<br/>remote_dir = “my-bucket/remote-model”</span></pre><p id="8f3d" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated"><strong class="ke ir"> 1。通过直接访问底层库(即不使用 Mercury-ML)的示例</strong></p><p id="6595" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">当您希望最大限度地灵活配置如何使用这些库时，使用底层库而不是使用 Mercury-ML API 是有意义的。下面是一个典型的脚本，你可以把它放在一起。</p><pre class="lj lk ll lm gt mb jq mc md aw me bi"><span id="0c38" class="mf mg iq jq b gy mh mi l mj mk">import os</span><span id="7b8d" class="mf mg iq jq b gy ml mi l mj mk"><strong class="jq ir"># save model</strong><br/>if not os.path.exists(local_dir):<br/>os.makedirs(local_dir)</span><span id="2e0a" class="mf mg iq jq b gy ml mi l mj mk">filename = filename + extension<br/>local_path = os.path.join(local_dir + "/" + filename)<br/>model.save(local_path)</span><span id="43e2" class="mf mg iq jq b gy ml mi l mj mk"><strong class="jq ir"># copy to s3</strong><br/>import boto3<br/>session = boto3.Session() #assuming connection parameters are implicit<br/>s3 = session.resource("s3")</span><span id="f175" class="mf mg iq jq b gy ml mi l mj mk">s3_bucket, s3_partial_key = remote_dir.split("/", 1)<br/>s3_key = s3_partial_key + "/" + filename + extension<br/>s3.Object(s3_bucket, s3_key).put(Body=open(local_path, "rb"))</span></pre><p id="c1d9" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">这里没有什么特别复杂的东西，但是有许多小步骤需要正确执行。您需要手动检查您希望在本地保存您的模型的目录是否存在(并且必须注意 Keras 不会为您这样做)。您必须知道，Keras 将其模型对象保存为 HDF5 文件，扩展名为“. h5”。您必须知道如何打开一个 S3 连接，并且知道保存到 S3 位置的函数调用需要“桶”和“键”输入(这两个输入放在一起可以简化为“路径”)。要做到这一点，你必须处理大量连接和分离字符串路径的调用。</p><p id="48c7" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">(例如，如果您决定将您的模型对象存储在 Google 云存储中，您将需要再次这样做)。</p><p id="5248" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated"><strong class="ke ir"> 2。供应商示例</strong></p><p id="e1e5" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">Mercury-ML 中的提供者旨在将大部分内容抽象出来，并在公开一个简单的(但也是高度可配置的)API 的同时处理好细节。</p><pre class="lj lk ll lm gt mb jq mc md aw me bi"><span id="ab8d" class="mf mg iq jq b gy mh mi l mj mk">from mercury_ml.keras.providers import model_saving<br/>from mercury_ml.common.providers.artifact_copying import from_disk<br/>import os</span><span id="0d91" class="mf mg iq jq b gy ml mi l mj mk"><strong class="jq ir"># save model</strong><br/>path = model_saving.save_keras_hdf5(<br/>    model=model,<br/>    filename=filename,<br/>    local_dir=local_dir, <br/>    extension=extension<br/>)</span><span id="72f2" class="mf mg iq jq b gy ml mi l mj mk"><strong class="jq ir"># copy to s3</strong><br/>from_disk.copy_from_disk_to_s3(<br/>    source_dir=local_dir, <br/>    target_dir=remote_dir, <br/>    filename=os.path.basename(path)<br/>)</span></pre><p id="d566" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">如果您想要硬编码您想要使用的提供者，使用提供者 API(而不是任务 API 的容器)是最有意义的。例如在上面的代码片段中，你只能使用<strong class="ke ir">model _ saving . save _ keras _ HD F5</strong>和<strong class="ke ir">from _ disk . copy _ from _ disk _ to _ S3</strong>。</p><p id="e459" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">如果您想要以不同的格式保存模型，或者将它复制到不同的存储中，那么您必须更改您的代码来做到这一点。例如，要存储到 Google 云存储中，您可以将<strong class="ke ir">from _ disk . copy _ from _ disk _ to _ S3</strong>替换为<strong class="ke ir">from _ disk . copy _ from _ disk _ to _ GCS。</strong></p><p id="5a9b" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated"><strong class="ke ir"> 3。通过容器的示例</strong></p><p id="ab17" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">当您希望通过配置文件来控制工作流时，使用容器 API 是最有意义的。</p><p id="98c1" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">容器只是轻量级的类，允许您从一个位置访问各种类似的提供者。例如，上面使用的函数<strong class="ke ir">model _ saving . save _ keras _ HD F5</strong>也可以通过容器<strong class="ke ir"> ModelSavers.save_hdf5 </strong>来访问。使用<strong class="ke ir"> getattr </strong>函数，这也可以作为<strong class="ke ir"> getattr(ModelSavers，" save_hdf5") </strong>访问，使我们可以在配置中轻松地对其进行参数化。</p><pre class="lj lk ll lm gt mb jq mc md aw me bi"><span id="cef7" class="mf mg iq jq b gy mh mi l mj mk">from mercury_ml.keras.containers import ModelSavers<br/>from mercury_ml.common.containers import ArtifactCopiers<br/>import os</span><span id="ea55" class="mf mg iq jq b gy ml mi l mj mk">config = {<br/>    "save_model": "save_hdf5",<br/>    "copy_model": "copy_from_disk_to_s3"<br/>}</span><span id="ce38" class="mf mg iq jq b gy ml mi l mj mk">save_model = getattr(ModelSavers, config["save_model"])</span><span id="09de" class="mf mg iq jq b gy ml mi l mj mk">copy_from_local_to_remote = getattr(<br/>    ArtifactCopiers, <br/>    config["copy_model"]<br/>)</span><span id="b6d1" class="mf mg iq jq b gy ml mi l mj mk"><strong class="jq ir"># save model</strong><br/>path = save_model(<br/>    model=model,<br/>    filename=filename,<br/>    local_dir=local_dir,<br/>    extension=extension<br/>)</span><span id="7461" class="mf mg iq jq b gy ml mi l mj mk"><strong class="jq ir"># copy to s3</strong><br/>copy_from_local_to_remote(<br/>    source_dir=local_dir,<br/>    target_dir=remote_dir,<br/>    filename=os.path.basename(path)<br/>)</span></pre><p id="2f48" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">想要将模型保存为张量流图吗？而想将其存储在谷歌云存储中？只需更改配置:</p><pre class="lj lk ll lm gt mb jq mc md aw me bi"><span id="da6e" class="mf mg iq jq b gy mh mi l mj mk">config = {<br/>    "save_model": "save_tensorflow_graph",<br/>    "copy_model": "copy_from_disk_to_gcs"<br/>}</span></pre><p id="ecc8" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated"><strong class="ke ir"> 4。示例通过任务(与容器一起)</strong></p><p id="fccc" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">当您想要使用单个函数来定义涉及多个提供者并需要多个步骤的小型工作流时，使用 tasks API 是有意义的。例如，下面的<strong class="ke ir"> store_model </strong>任务被注入了一个<strong class="ke ir"> save_model </strong>和一个<strong class="ke ir">copy _ from _ local _ to _ remote</strong>提供程序，并继续使用这些提供程序首先在本地保存模型，然后将其复制到远程位置。</p><pre class="lj lk ll lm gt mb jq mc md aw me bi"><span id="f090" class="mf mg iq jq b gy mh mi l mj mk">from mercury_ml.keras.containers import ModelSaversfrom mercury_ml.common.containers import ArtifactCopiers<br/>from mercury_ml.common.tasks import store_model</span><span id="eeeb" class="mf mg iq jq b gy ml mi l mj mk">save_model = getattr(ModelSavers, config["save_model"])<br/>copy_from_local_to_remote = getattr(<br/>    ArtifactCopiers, <br/>    config["copy_model"]<br/>)</span><span id="d7d6" class="mf mg iq jq b gy ml mi l mj mk"><strong class="jq ir"># save model and copy to s3</strong><br/>store_model(<br/>    save_model=save_model,<br/>    copy_from_local_to_remote=copy_from_local_to_remote,<br/>    model=model,<br/>    filename=filename,<br/>    local_dir=local_dir,<br/>    remote_dir=local_dir,<br/>    extension=extension<br/>)</span></pre><p id="f924" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">tasks API 比其他任何东西都更方便，但是对于经常一起出现的小块工作流来说非常有用。</p><p id="4eac" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated"><strong class="ke ir">了解更多信息</strong></p><p id="6a73" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">以上只是一个小例子。完全成熟的示例工作流可以在<a class="ae la" href="https://github.com/mercury-ml-team/mercury-ml/tree/master/examples" rel="noopener ugc nofollow" target="_blank">这里</a>找到。</p><p id="615c" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">Mercury-ML 能够促进工作流的一个关键因素也与它在机器学习管道的各个阶段处理数据的方式有关。Mercury-ML 将数据包装成通用的 DataWrapper 对象(例如“特征”和“目标”)，并将它们排列成数据集(例如“训练”、“有效”和“测试”)，并最终排列成数据组。你可以在这里找到更多关于如何做的信息<a class="ae la" href="https://github.com/mercury-ml-team/mercury-ml/blob/master/README.md#data-in-mercury-ml" rel="noopener ugc nofollow" target="_blank">。</a></p><p id="b5b1" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated"><strong class="ke ir">成为投稿人！</strong></p><p id="5657" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">这也是对任何对使用 Mercury-ML 感兴趣的开发人员的公开邀请。告诉我们您需要什么功能，让我们知道哪些功能不起作用，或者贡献您自己的更改或添加内容！</p></div></div>    
</body>
</html>