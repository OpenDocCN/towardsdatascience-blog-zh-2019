<html>
<head>
<title>How to scale training on multiple GPUs</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">如何在多个 GPU 上扩展训练</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/how-to-scale-training-on-multiple-gpus-dae1041f49d2?source=collection_archive---------1-----------------------#2019-12-22">https://towardsdatascience.com/how-to-scale-training-on-multiple-gpus-dae1041f49d2?source=collection_archive---------1-----------------------#2019-12-22</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><figure class="ip iq gp gr ir is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi io"><img src="../Images/3f2ccbb474b23640e51e249e3723e380.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*SV7m7LlmyAdRwdestUdd8w.jpeg"/></div></div></figure><div class=""/><div class=""><h2 id="f7db" class="pw-subtitle-paragraph jy ja jb bd b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp dk translated">如何在多个 GPU 中训练 PyTorch 模型</h2></div><p id="46b7" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">深度学习模型的最大问题之一是，它们变得太大，无法在单个 GPU 中训练。如果在单个 GPU 中训练当前的模型，它们将花费太长时间。为了及时地训练模型，有必要用多个 GPU 来训练它们。</p><p id="21d6" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">我们<a class="ae lm" href="https://medium.com/south-park-commons/scaling-transformer-xl-to-128-gpus-85849508ec35" rel="noopener">需要</a>来缩放训练方法，以使用 100 个甚至 1000 个 GPU。例如，一位<a class="ae lm" href="https://medium.com/south-park-commons/scaling-transformer-xl-to-128-gpus-85849508ec35" rel="noopener">著名研究员</a>能够将 ImageNet 的训练时间从 2 周减少到 18 分钟，或者在 2 周内训练出最大和最先进的 Transformer-XL，而不是 4 年。他使用了 100 个 GPU 来完成这个任务。</p><p id="9cc8" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">我们非常关心我们的训练迭代速度。因此，为了提高我们的迭代速度，我们必须将我们的训练扩展到多个 GPU。在这篇博文中，我将介绍如何用 PyTorch 扩大训练规模。我们已经在 TensorFlow ( &lt;2.0) and scaled our training, using <a class="ae lm" href="https://github.com/horovod/horovod" rel="noopener ugc nofollow" target="_blank"> Horovod </a>)中有了一些模型，这是优步工程团队开发的一个工具。如果你走这条路，我们建议使用他们的<a class="ae lm" href="https://github.com/horovod/horovod/blob/master/docs/docker.rst" rel="noopener ugc nofollow" target="_blank"> Docker 镜像</a>来安装它。</p><p id="a816" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">我们发现 PyTorch 在易用性和控制性之间取得了最好的平衡，<a class="ae lm" href="https://medium.com/huggingface/benchmarking-transformers-pytorch-and-tensorflow-e2917fb891c2" rel="noopener">同时又不牺牲性能</a>。PyTorch 构建了两种方法来在多个 GPU 中实现分布式训练:<code class="fe ln lo lp lq b">nn.DataParalllel</code>和<code class="fe ln lo lp lq b">nn.DistributedParalllel</code>。它们是包装和更改代码以及在多个 GPU 中增加训练网络的能力的简单方法。</p><p id="d464" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated"><code class="fe ln lo lp lq b">nn.DataParallel</code>更容易使用，但要求只能在一台机器上使用。<code class="fe ln lo lp lq b">nn.DataParalllel</code>仅使用一个进程来计算模型权重，并在每批中将其分配给每个 GPU。</p><p id="c254" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">在这篇博文中，我将详细介绍<code class="fe ln lo lp lq b">nn.DataParallel</code>和<code class="fe ln lo lp lq b">nn.DistributedDataParalllel</code>是如何工作的。我将介绍两者之间的主要区别，以及在多个 GPU 中进行训练的工作原理。我将首先解释训练神经网络是如何工作的。</p><h1 id="b946" class="lr ls jb bd lt lu lv lw lx ly lz ma mb kh mc ki md kk me kl mf kn mg ko mh mi bi translated">训练循环</h1><p id="e4cd" class="pw-post-body-paragraph kq kr jb ks b kt mj kc kv kw mk kf ky kz ml lb lc ld mm lf lg lh mn lj lk ll ij bi translated">首先，让我们回顾一下训练神经网络通常是如何工作的。为此，我们将使用由<a class="ae lm" href="https://huggingface.co/" rel="noopener ugc nofollow" target="_blank"> HuggingFace </a>创建的一些图像:</p><figure class="mp mq mr ms gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi mo"><img src="../Images/56839040dae9dd9e4f5616d57e801ff7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/1*v2cEppSrjkkvIzrUi0hFCw.gif"/></div></div></figure><p id="8985" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">训练神经网络时，每个循环都有四个主要步骤:</p><ol class=""><li id="154d" class="mt mu jb ks b kt ku kw kx kz mv ld mw lh mx ll my mz na nb bi translated">正向传递，由神经网络处理输入</li><li id="bf93" class="mt mu jb ks b kt nc kw nd kz ne ld nf lh ng ll my mz na nb bi translated">计算损失函数，比较预测标签和地面实况标签</li><li id="dcc5" class="mt mu jb ks b kt nc kw nd kz ne ld nf lh ng ll my mz na nb bi translated">进行反向传递，根据损耗计算每个参数的梯度(使用反向传播)</li><li id="92de" class="mt mu jb ks b kt nc kw nd kz ne ld nf lh ng ll my mz na nb bi translated">使用梯度更新参数</li></ol><p id="8276" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">对于大于 1 的批量大小，我们可能希望批量规范化训练。关于批处理规范化的深入解释，我推荐阅读这篇博文:</p><div class="ip iq gp gr ir nh"><a href="https://kratzert.github.io/2016/02/12/understanding-the-gradient-flow-through-the-batch-normalization-layer.html" rel="noopener  ugc nofollow" target="_blank"><div class="ni ab fo"><div class="nj ab nk cl cj nl"><h2 class="bd jc gy z fp nm fr fs nn fu fw ja bi translated">了解反向传递批处理规范化层</h2><div class="no l"><h3 class="bd b gy z fp nm fr fs nn fu fw dk translated">目前在斯坦福大学有一门很棒的课程，叫做 CS231n -卷积神经…</h3></div><div class="np l"><p class="bd b dl z fp nm fr fs nn fu fw dk translated">kratzert.github.io</p></div></div><div class="nq l"><div class="nr l ns nt nu nq nv ix nh"/></div></div></a></div><h1 id="9101" class="lr ls jb bd lt lu lv lw lx ly lz ma mb kh mc ki md kk me kl mf kn mg ko mh mi bi translated">数据并行</h1><p id="e365" class="pw-post-body-paragraph kq kr jb ks b kt mj kc kv kw mk kf ky kz ml lb lc ld mm lf lg lh mn lj lk ll ij bi translated">DataParallel 有助于将训练分布到单台机器的多个 GPU 中。让我们详细了解一下 DataParallel 是如何工作的。每当使用数据并行训练神经网络时，都会发生几个步骤:</p><figure class="mp mq mr ms gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi nw"><img src="../Images/bc9f1dbe595d35daf6c13835e61cbfe9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*IA3JaoSzp10SHSCYRZ1IfQ.png"/></div></div><figcaption class="nx ny gj gh gi nz oa bd b be z dk">Image created by <a class="ae lm" href="https://huggingface.co/" rel="noopener ugc nofollow" target="_blank">HuggingFace</a></figcaption></figure><ol class=""><li id="9130" class="mt mu jb ks b kt ku kw kx kz mv ld mw lh mx ll my mz na nb bi translated">小批量在 GPU 上拆分:0</li><li id="f0df" class="mt mu jb ks b kt nc kw nd kz ne ld nf lh ng ll my mz na nb bi translated">将小批量分割并移动到所有不同的 GPU</li><li id="3f17" class="mt mu jb ks b kt nc kw nd kz ne ld nf lh ng ll my mz na nb bi translated">将模型复制到 GPU</li><li id="6c28" class="mt mu jb ks b kt nc kw nd kz ne ld nf lh ng ll my mz na nb bi translated">正向传递发生在所有不同的 GPU 中</li><li id="fe48" class="mt mu jb ks b kt nc kw nd kz ne ld nf lh ng ll my mz na nb bi translated">计算与 GPU:0 上的网络输出相关的损耗，并将损耗返回给不同的 GPU。计算每个 GPU 上的梯度</li><li id="9a77" class="mt mu jb ks b kt nc kw nd kz ne ld nf lh ng ll my mz na nb bi translated">对 GPU:0 上的梯度求和，并使用优化器更新 GPU:0 上的模型</li></ol><h2 id="0d38" class="ob ls jb bd lt oc od dn lx oe of dp mb kz og oh md ld oi oj mf lh ok ol mh om bi translated">简单的例子</h2><p id="0e63" class="pw-post-body-paragraph kq kr jb ks b kt mj kc kv kw mk kf ky kz ml lb lc ld mm lf lg lh mn lj lk ll ij bi translated">让我们把这个编码起来。首先，让我们进口我们需要的一切</p><figure class="mp mq mr ms gt is"><div class="bz fp l di"><div class="on oo l"/></div></figure><p id="cecb" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">我们定义一个非常简单的卷积模型来预测 MNIST</p><figure class="mp mq mr ms gt is"><div class="bz fp l di"><div class="on oo l"/></div></figure><p id="7e55" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">第 4–14 行:我们正在定义这个神经网络的层次。</p><p id="da3f" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">第 16–21 行:我们定义了向前传球</p><p id="d4e2" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">main()函数将接受一些参数并运行训练函数:</p><figure class="mp mq mr ms gt is"><div class="bz fp l di"><div class="on oo l"/></div></figure><p id="2430" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">第 2–6 行:我们实例化模型并将其设置为在指定的 GPU 中运行，并通过使用<code class="fe ln lo lp lq b">DataParallel</code>在多个 GPU 中并行运行我们的操作。</p><p id="70b0" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">第 9–23 行:我们定义损失函数(标准)，和<a class="ae lm" rel="noopener" target="_blank" href="/types-of-optimization-algorithms-used-in-neural-networks-and-ways-to-optimize-gradient-95ae5d39529f">优化器</a>(在这种情况下，我们使用 SGD)。我们定义了训练数据集(MNIST)和数据加载器。</p><p id="d2b4" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">第 24–45 行:这就是训练神经网络的循环发生的地方。我们加载输入和预期输出。我们运行向前传递和向后传递以及优化器。</p><p id="c808" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">这里肯定有一些额外的东西(例如，GPU 和节点的数量)我们还不需要，但将整个框架放在适当的位置是有帮助的。</p><h1 id="64e7" class="lr ls jb bd lt lu lv lw lx ly lz ma mb kh mc ki md kk me kl mf kn mg ko mh mi bi translated">分布式数据并行</h1><p id="ce5f" class="pw-post-body-paragraph kq kr jb ks b kt mj kc kv kw mk kf ky kz ml lb lc ld mm lf lg lh mn lj lk ll ij bi translated">为了 nn。' DistributedDataParallel '，机器每个 GPU 有一个进程，每个模型由每个进程控制。GPU 可以都在同一个节点上，也可以跨多个节点。只有渐变在进程/GPU 之间传递。</p><figure class="mp mq mr ms gt is gh gi paragraph-image"><div class="gh gi op"><img src="../Images/b006ae9ad501376107bf0992295e5ec5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1056/format:webp/1*ZXoCZTUmxtD_srJEwDMziA.png"/></div></figure><p id="4a66" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">在训练过程中，每个进程从磁盘加载自己的小批量，并将其传递给 GPU。每个 GPU 执行其正向传递，然后梯度在 GPU 之间全部降低。每层的梯度不依赖于先前的层，因此梯度 all-reduce 与向后传递同时计算，以进一步缓解网络瓶颈。在反向过程结束时，每个节点都有平均梯度，确保模型权重保持同步。</p><h2 id="51c6" class="ob ls jb bd lt oc od dn lx oe of dp mb kz og oh md ld oi oj mf lh ok ol mh om bi translated">辅导的</h2><p id="7b09" class="pw-post-body-paragraph kq kr jb ks b kt mj kc kv kw mk kf ky kz ml lb lc ld mm lf lg lh mn lj lk ll ij bi translated">为了用多重处理来做到这一点，我们需要一个脚本来为每个 GPU 启动一个进程。每个进程都需要知道使用哪个 GPU，以及它在所有正在运行的进程中的排名。我们需要在每个节点上运行脚本。</p><p id="d652" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">让我们来看看每个函数的变化。我已经把新代码隔离开来，以便于查找。</p><figure class="mp mq mr ms gt is"><div class="bz fp l di"><div class="on oo l"/></div></figure><p id="7df7" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">让我们回顾一下主函数的参数:</p><ul class=""><li id="4854" class="mt mu jb ks b kt ku kw kx kz mv ld mw lh mx ll oq mz na nb bi translated"><code class="fe ln lo lp lq b">args.nodes</code>是我们正在使用的节点总数(机器数量)。</li><li id="cac3" class="mt mu jb ks b kt nc kw nd kz ne ld nf lh ng ll oq mz na nb bi translated"><code class="fe ln lo lp lq b">args.gpus</code>是每个节点(每台机器上)的 GPU 数量。</li><li id="f685" class="mt mu jb ks b kt nc kw nd kz ne ld nf lh ng ll oq mz na nb bi translated"><code class="fe ln lo lp lq b">args.nr</code>是当前节点(机器)在所有节点(机器)中的排名，从 0 到<code class="fe ln lo lp lq b">args.nodes</code> - 1。</li></ul><p id="ce38" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">让我们一行一行地看看新的变化:</p><p id="bc0d" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">第 12 行:根据节点数和每个节点的 GPU 数，我们可以计算出<code class="fe ln lo lp lq b">world_size</code>，或者要运行的进程总数，它等于 GPU 总数乘以节点数。</p><p id="3fe2" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">第 13 行:这告诉多处理模块为进程 0 寻找什么 IP 地址。它需要这样做，以便所有的进程可以同步开始。这需要在所有节点上保持一致。</p><p id="9c4a" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">第 14 行:同样，这是查找进程 0 时使用的端口。</p><p id="77b7" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">第 15 行:现在，不再运行一次 train 函数，我们将产生<code class="fe ln lo lp lq b">args.gpus</code>进程，每个进程运行<code class="fe ln lo lp lq b">train(i, args)</code>，其中<code class="fe ln lo lp lq b">i</code>从 0 到<code class="fe ln lo lp lq b">args.gpus</code> - 1。记住，我们在每个节点上运行<code class="fe ln lo lp lq b">main()</code>函数，这样总共会有<code class="fe ln lo lp lq b">args.nodes</code> * <code class="fe ln lo lp lq b">args.gpus</code> = <code class="fe ln lo lp lq b">args.world_size</code>个进程。</p><p id="1c0f" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">我可以在终端中运行<code class="fe ln lo lp lq b">export MASTER_ADDR=10.57.23.164</code>和<code class="fe ln lo lp lq b">export MASTER_PORT=8888</code>，而不是第 13 和 14 行。</p><p id="e532" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">接下来，让我们看看对<code class="fe ln lo lp lq b">train</code>的修改。我会再把新线路围起来。</p><figure class="mp mq mr ms gt is"><div class="bz fp l di"><div class="on oo l"/></div></figure><p id="dfe1" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">我已经删除了一些代码，并用<code class="fe ln lo lp lq b">...</code>代替，以使本教程更容易阅读，但如果你想要完整的脚本，这里是<a class="ae lm" href="https://github.com/yangkky/distributed_tutorial/blob/master/src/mnist-distributed.py" rel="noopener ugc nofollow" target="_blank"/>。</p><p id="eff3" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">第 3 行:这是该流程在所有流程中的全局排名。我们将在第 6 行使用这个。</p><p id="1857" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">第 4–6 行:初始化流程并与其他流程连接。这是“阻塞”，意味着在所有进程都加入之前，没有进程会继续。我用的是<code class="fe ln lo lp lq b">NCCL</code>，因为它是最快的..<code class="fe ln lo lp lq b">init_method</code>告诉进程组在哪里寻找一些设置。在这种情况下，它在查看<code class="fe ln lo lp lq b">MASTER_ADDR</code>和<code class="fe ln lo lp lq b">MASTER_PORT</code>的环境变量，我们在<code class="fe ln lo lp lq b">main</code>中设置了这些变量。这就是为什么我们把它设置为<code class="fe ln lo lp lq b">env://</code>。我们可以在那里设置<code class="fe ln lo lp lq b">world_size</code>和<code class="fe ln lo lp lq b">WORLD_SIZE.</code></p><p id="2f3f" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">第 23 行:将模型包装成一个<code class="fe ln lo lp lq b"><a class="ae lm" href="https://pytorch.org/docs/stable/nn.html#distributeddataparallel" rel="noopener ugc nofollow" target="_blank">DistributedDataParallel</a></code>模型。这将模型复制到每个 GPU 上。</p><p id="1a24" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">第 35–39 行:<code class="fe ln lo lp lq b"><a class="ae lm" href="https://pytorch.org/docs/stable/_modules/torch/utils/data/distributed.html" rel="noopener ugc nofollow" target="_blank">nn.utils.data.DistributedSampler</a></code>确保每次加载数据时，每个进程都获得不同的训练数据片段。如果您想要调试并验证每个 GPU 都加载了正确的数据，您可以计算加载到每个 GPU 中的张量的 sha。</p><p id="c15b" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">第 46 行和第 51 行:使用<code class="fe ln lo lp lq b">nn.utils.data.DistributedSampler</code>而不是通常的洗牌方式。这就是为什么我们将 shuffle 设置为 false。</p><p id="40a0" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">比方说，要在 4 个各有 8 个 GPU 的节点上运行，我们需要 4 个终端(每个节点一个)。在节点 0 上(由<code class="fe ln lo lp lq b">main</code>中的第 13 行设置):</p><figure class="mp mq mr ms gt is"><div class="bz fp l di"><div class="on oo l"/></div></figure><p id="2d08" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">然后，在其他节点上:</p><figure class="mp mq mr ms gt is"><div class="bz fp l di"><div class="on oo l"/></div></figure><p id="c46a" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">对于 i∈1，2，3。换句话说，我们在每个节点上运行这个脚本，告诉它在训练开始之前启动彼此同步的<code class="fe ln lo lp lq b">args.gpus</code>进程。</p><p id="61b6" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">请注意，有效的 batch_size 现在是每 GPU batch_size(脚本中的值)* GPU 总数(全局大小)。</p><h2 id="c980" class="ob ls jb bd lt oc od dn lx oe of dp mb kz og oh md ld oi oj mf lh ok ol mh om bi translated">问题</h2><p id="2b63" class="pw-post-body-paragraph kq kr jb ks b kt mj kc kv kw mk kf ky kz ml lb lc ld mm lf lg lh mn lj lk ll ij bi translated">当在几个 GPU 而不是一个 GPU 中运行同一模型时，可能会出现一些问题。可能出现的最大问题是主 GPU 可能会耗尽内存。这样做的原因是因为第一个 GPU 将为不同的 GPU 保存所有不同的输出以计算损失。</p><figure class="mp mq mr ms gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi ca"><img src="../Images/13c301206a72464d57060acd5bd2eeda.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*MgnfS0jIHfyi5LhxgBfCfw.png"/></div></div></figure><p id="4b21" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">每当您训练网络时，以下信息将显示在控制台上:<code class="fe ln lo lp lq b">ran out of memory trying to allocate 2.59GiB</code></p><p id="1a38" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">为了解决这个问题，并减少内存使用量，我们使用两种技术:</p><ol class=""><li id="a4ea" class="mt mu jb ks b kt ku kw kx kz mv ld mw lh mx ll my mz na nb bi translated">减少批量大小</li><li id="9f25" class="mt mu jb ks b kt nc kw nd kz ne ld nf lh ng ll my mz na nb bi translated">将 Apex 用于混合精度</li></ol><p id="9449" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">第一种技术非常简单，通常只需要改变一个超参数。</p><p id="a71c" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">第二种技术意味着我们将降低神经网络中使用的权重的精度，因此使用更少的内存。混合精度意味着对某些事情使用 16 位，但对权重等事情保持 32 位。要了解更多关于混合精度的信息，我推荐阅读这篇博文:</p><div class="ip iq gp gr ir nh"><a href="https://www.quora.com/What-is-the-difference-between-FP16-and-FP32-when-doing-deep-learning" rel="noopener  ugc nofollow" target="_blank"><div class="ni ab fo"><div class="nj ab nk cl cj nl"><h2 class="bd jc gy z fp nm fr fs nn fu fw ja bi translated">做深度学习的时候 FP16 和 FP32 有什么区别？</h2><div class="no l"><h3 class="bd b gy z fp nm fr fs nn fu fw dk translated">回答(第 1 题，共 3 题):这是一个适时的问题，因为我们上周五刚刚给 Horovod 添加了 FP16 支持。所以很自然，我…</h3></div><div class="np l"><p class="bd b dl z fp nm fr fs nn fu fw dk translated">www.quora.com</p></div></div><div class="nq l"><div class="or l ns nt nu nq nv ix nh"/></div></div></a></div><h1 id="98c5" class="lr ls jb bd lt lu lv lw lx ly lz ma mb kh mc ki md kk me kl mf kn mg ko mh mi bi translated">混合精度的顶点</h1><p id="3b62" class="pw-post-body-paragraph kq kr jb ks b kt mj kc kv kw mk kf ky kz ml lb lc ld mm lf lg lh mn lj lk ll ij bi translated">为了解决内存不足的问题，我们建议使用较低精度的数字。这使我们能够使用更大的批量，并利用 NVIDIA Tensor 内核加快计算速度。</p><p id="c3dc" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">为了让 APEX 工作，我们需要更改代码的 2 个部分。第一个是在代码库中的<code class="fe ln lo lp lq b">train</code>循环中:</p><h2 id="a96b" class="ob ls jb bd lt oc od dn lx oe of dp mb kz og oh md ld oi oj mf lh ok ol mh om bi translated">训练步骤</h2><figure class="mp mq mr ms gt is"><div class="bz fp l di"><div class="on oo l"/></div></figure><p id="8819" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">第 18 行:<code class="fe ln lo lp lq b"><a class="ae lm" href="https://nvidia.github.io/apex/amp.html#unified-api" rel="noopener ugc nofollow" target="_blank">amp.initialize</a></code>包装混合精度训练的模型和优化器。注意，在调用<code class="fe ln lo lp lq b">amp.initialize</code>之前，模型必须已经在正确的 GPU 上。<code class="fe ln lo lp lq b">opt_level</code>从使用所有浮点的<code class="fe ln lo lp lq b">O0</code>到使用半精度的<code class="fe ln lo lp lq b">O3</code>。<code class="fe ln lo lp lq b">O1</code>和<code class="fe ln lo lp lq b">O2</code>是不同程度的混合精度，其细节可以在 Apex <a class="ae lm" href="https://nvidia.github.io/apex/amp.html#opt-levels-and-properties" rel="noopener ugc nofollow" target="_blank">文档</a>中找到。</p><p id="f652" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">第 20 行:<code class="fe ln lo lp lq b"><a class="ae lm" href="https://nvidia.github.io/apex/parallel.html" rel="noopener ugc nofollow" target="_blank">apex.parallel.DistributedDataParallel</a></code>是<code class="fe ln lo lp lq b">nn.DistributedDataParallel</code>的替代产品。我们不再需要指定 GPU，因为 Apex 只允许每个进程使用一个 GPU。它还假设脚本在将模型移动到 GPU 之前调用了<code class="fe ln lo lp lq b">torch.cuda.set_device(local_rank)</code>(第 10 行)。</p><p id="f37c" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">第 37–38 行:混合精度训练要求损失被<a class="ae lm" href="https://devblogs.nvidia.com/mixed-precision-training-deep-neural-networks/" rel="noopener ugc nofollow" target="_blank">缩放</a>，以防止梯度下溢。Apex 会自动执行此操作。</p><p id="be7f" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">确保无论何时初始化 AMP，你都设置了<code class="fe ln lo lp lq b">opt_level=O1</code>，因为它的实现有一个<a class="ae lm" href="https://github.com/NVIDIA/apex/issues/250" rel="noopener ugc nofollow" target="_blank">错误</a></p><h2 id="cb65" class="ob ls jb bd lt oc od dn lx oe of dp mb kz og oh md ld oi oj mf lh ok ol mh om bi translated">检查站</h2><p id="4cf7" class="pw-post-body-paragraph kq kr jb ks b kt mj kc kv kw mk kf ky kz ml lb lc ld mm lf lg lh mn lj lk ll ij bi translated">每当使用 Apex 时，我们需要改变我们保存和加载模型的方式，请参见下面的<a class="ae lm" href="https://github.com/NVIDIA/apex/issues/250" rel="noopener ugc nofollow" target="_blank">问题</a>。我们需要改变保存检查点并将其加载到模型中的方式:</p><figure class="mp mq mr ms gt is"><div class="bz fp l di"><div class="on oo l"/></div></figure><p id="9aec" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">第 5 行:我们将<code class="fe ln lo lp lq b">amp.state_dict</code>添加到检查点</p><p id="fef2" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">第 19 行:我们在这里加载<code class="fe ln lo lp lq b">state_dict</code>到 amp。</p><h1 id="b309" class="lr ls jb bd lt lu lv lw lx ly lz ma mb kh mc ki md kk me kl mf kn mg ko mh mi bi translated">结论</h1><p id="d3bf" class="pw-post-body-paragraph kq kr jb ks b kt mj kc kv kw mk kf ky kz ml lb lc ld mm lf lg lh mn lj lk ll ij bi translated">有了所有这些，您应该能够开始在多个 GPU 中训练您的模型。我们建议在尝试将训练扩展到多个 GPU 之前，先在一个 GPU 中训练一个小模型。但是，如果有必要进行规模化训练，本教程可能会有所帮助。</p><h1 id="f5f6" class="lr ls jb bd lt lu lv lw lx ly lz ma mb kh mc ki md kk me kl mf kn mg ko mh mi bi translated">链接和参考:</h1><p id="a347" class="pw-post-body-paragraph kq kr jb ks b kt mj kc kv kw mk kf ky kz ml lb lc ld mm lf lg lh mn lj lk ll ij bi translated"><a class="ae lm" href="https://lambdalabs.com/blog/introduction-multi-gpu-multi-node-distributed-training-nccl-2-0/" rel="noopener ugc nofollow" target="_blank">https://lambda labs . com/blog/introduction-multi-GPU-multi-node-distributed-training-nccl-2-0/</a></p><p id="bdd9" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated"><a class="ae lm" href="https://medium.com/intel-student-ambassadors/distributed-training-of-deep-learning-models-with-pytorch-1123fa538848" rel="noopener">https://medium . com/Intel-student-ambassadors/distributed-training-of-deep-learning-models-with-py torch-1123 fa 538848</a></p><p id="fe5a" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated"><a class="ae lm" rel="noopener" target="_blank" href="/visual-intuition-on-ring-allreduce-for-distributed-deep-learning-d1f34b4911da">https://towards data science . com/visual-intuition-on-ring-all reduce-for-distributed-deep-learning-d1f 34 b 4911 da</a></p><p id="4b1e" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated"><a class="ae lm" href="https://medium.com/huggingface/training-larger-batches-practical-tips-on-1-gpu-multi-gpu-distributed-setups-ec88c3e51255" rel="noopener">https://medium . com/hugging face/training-large-batches-practical-tips-on-1-GPU-multi-GPU-distributed-settings-EC 88 C3 e 51255</a></p><p id="bec1" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated"><a class="ae lm" href="https://medium.com/south-park-commons/scaling-transformer-xl-to-128-gpus-85849508ec35" rel="noopener">https://medium . com/south-park-commons/scaling-transformer-XL-to-128-GPU-85849508 EC 35</a></p><p id="30c6" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated"><a class="ae lm" href="https://yangkky.github.io/2019/07/08/distributed-pytorch-tutorial.html" rel="noopener ugc nofollow" target="_blank">https://yang kky . github . io/2019/07/08/distributed-py torch-tutorial . html</a></p></div></div>    
</body>
</html>