<html>
<head>
<title>Machine learning on categorical variables</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">分类变量上的机器学习</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/machine-learning-on-categorical-variables-3b76ffe4a7cb?source=collection_archive---------4-----------------------#2019-08-16">https://towardsdatascience.com/machine-learning-on-categorical-variables-3b76ffe4a7cb?source=collection_archive---------4-----------------------#2019-08-16</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="223d" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated"><strong class="ak">如何正确运行和评估模型</strong></h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/2208d882fc62c64b4402de6aee721fda.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*57AdDO-xH97k3N7n"/></div></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk">Photo by <a class="ae ky" href="https://unsplash.com/@v2osk?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">v2osk</a> on <a class="ae ky" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><p id="0e58" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi lv translated"><span class="l lw lx ly bm lz ma mb mc md di">乍一看，分类变量和数字变量没什么不同。但是，一旦你开始深入挖掘，并在代码中实现你的机器学习(和预处理)思想，你就会每分钟都停下来问一些问题，比如“我在训练集和测试集上都做特征工程吗？”或者“我听说了一些关于<a class="ae ky" href="https://stackoverflow.com/questions/10164608/how-do-you-count-cardinality-of-very-large-datasets-efficiently-in-python" rel="noopener ugc nofollow" target="_blank">基数</a>的事情——那是什么，我应该用谷歌搜索更多相关信息吗？”</span></p><p id="9751" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">让我们看看我们是否可以通过一个行动计划来澄清这一点，即如何处理具有许多分类变量的数据集并训练几个模型。</p><p id="1b78" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">Kaggle 将作为我们的数据源:它有一个<a class="ae ky" href="https://www.kaggle.com/c/house-prices-advanced-regression-techniques" rel="noopener ugc nofollow" target="_blank">优秀的房价数据集</a>。准备花些时间浏览<a class="ae ky" href="https://storage.googleapis.com/kaggle-competitions-data/kaggle/5407/205873/data_description.txt?GoogleAccessId=web-data@kaggle-161607.iam.gserviceaccount.com&amp;Expires=1564839056&amp;Signature=f5rA1N%2B30QoGsRGpUq8B4PuRuAPXgwHDtJ34IkFb4NGCjxoBvsUnmKuDFTqtK3SJ0JOS31A%2BZmmBlw5aKBoRu6Zjd5870t4LhPYT0SAbUPvfCmEJEPkLyjH55AUfFcP%2BzbcdihTDX47q1NdjDg%2FfBx%2FK2%2FNqd2QthD4J2AXX3BIm0Foxi0bYBUCU%2FQd4jw9yN6grKjRgDWU9eePGciBC%2FDPvqBQEFiqVgZuBW%2BMxOMoy3ElgIVJgs7PyxoACeywYutFtRV01uU5JlwYYsLumJI6M5W4o7hlXWOgZXSxZ0WUGWvacdhqmjqJWyY3ZA7JmHSk%2FSxXRfWNXhqn9J2teOw%3D%3D" rel="noopener ugc nofollow" target="_blank">提供的数据字典</a>。您可以在单独的浏览器窗口中打开它。我们还会将其加载到 Jupyter 笔记本中。在本练习中，我们将根据房屋的各种参数预测列<em class="me"> SalePrice </em>中的值。</p><p id="08a0" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">和往常一样，所有代码都可以在<a class="ae ky" href="https://github.com/nastyh/Feature-Engineering--House-Prices" rel="noopener ugc nofollow" target="_blank"> GitHub </a>上获得(你需要工作簿<a class="ae ky" href="https://github.com/nastyh/Feature-Engineering--House-Prices/blob/master/Features_for_MLOps.ipynb" rel="noopener ugc nofollow" target="_blank">Features _ for _ mlops . ipynb</a>)。它还有一些额外的图表，我们在这里没有涉及，但对于更好地理解这个过程是有用的。</p><p id="f2ba" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">让我们加载依赖项和数据:</p><pre class="kj kk kl km gt mf mg mh mi aw mj bi"><span id="4a40" class="mk ml it mg b gy mm mn l mo mp"># Loading necessary packages<br/>import pandas as pd<br/>import numpy as np<br/>import matplotlib.pyplot as plt<br/>import scipy.stats as st<br/>import seaborn as sns<br/>import pandas_profiling<br/>import requests <br/>%matplotlib inline</span><span id="2869" class="mk ml it mg b gy mq mn l mo mp">train = pd.read_csv(r'train.csv')<br/>test = pd.read_csv(r'test.csv')</span></pre><p id="5c04" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">如果您想在 GUI 中有一个数据字典:</p><pre class="kj kk kl km gt mf mg mh mi aw mj bi"><span id="f3f5" class="mk ml it mg b gy mm mn l mo mp">response = requests.get('<a class="ae ky" href="https://storage.googleapis.com/kaggle-competitions-data/kaggle/5407/205873/data_description.txt?GoogleAccessId=web-data@kaggle-161607.iam.gserviceaccount.com&amp;Expires=1564407075&amp;Signature=Iduf4UDvx2Cei5S9B7A%2B%2Fz3u%2Ff8GG0RxvpfMu5IHRtJOFBsjq806B2sSr6zucZBwJeBNSOuIpOssfa4i%2BYS8ybrJgaHnA%2Fqkcox6ZsD8BLIl3yTHjwmfkie2ohGSI0bdZLiXblBWps8xJ8sGZPnmTegLYLhFgrA7O0BEF5dIXrFVYufTcndkOeOyYm3fopGjTablaxWOUyhmd43WfOxADJInaMqUk37SBzVD4jD1bj%2F%2B%2FJkK7OeTvUIBJOR3EXij97rhVqcZNdxTttF91t0W3HFcqJrRhrw5%2BKvZmHNzsT5AO164QSjlFqT5kU3dZWoZqxdDOxImVvr%2Fw2m4IRZGCw%3D%3D'" rel="noopener ugc nofollow" target="_blank">https://storage.googleapis.com/kaggle-competitions-data/kaggle/5407/205873/data_description.txt?GoogleAccessId=web-data@kaggle-161607.iam.gserviceaccount.com&amp;Expires=1564407075&amp;Signature=Iduf4UDvx2Cei5S9B7A%2B%2Fz3u%2Ff8GG0RxvpfMu5IHRtJOFBsjq806B2sSr6zucZBwJeBNSOuIpOssfa4i%2BYS8ybrJgaHnA%2Fqkcox6ZsD8BLIl3yTHjwmfkie2ohGSI0bdZLiXblBWps8xJ8sGZPnmTegLYLhFgrA7O0BEF5dIXrFVYufTcndkOeOyYm3fopGjTablaxWOUyhmd43WfOxADJInaMqUk37SBzVD4jD1bj%2F%2B%2FJkK7OeTvUIBJOR3EXij97rhVqcZNdxTttF91t0W3HFcqJrRhrw5%2BKvZmHNzsT5AO164QSjlFqT5kU3dZWoZqxdDOxImVvr%2Fw2m4IRZGCw%3D%3D'</a>)<br/>dict = response.text<br/>print(dict)</span></pre><p id="91ce" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们现在可以进行快速数据分析:</p><pre class="kj kk kl km gt mf mg mh mi aw mj bi"><span id="702f" class="mk ml it mg b gy mm mn l mo mp">train.describe().T<br/>test.describe().T</span></pre><p id="85a0" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">和往常一样，我推荐<a class="ae ky" href="https://github.com/pandas-profiling/pandas-profiling" rel="noopener ugc nofollow" target="_blank">熊猫简介包</a>。</p><pre class="kj kk kl km gt mf mg mh mi aw mj bi"><span id="641b" class="mk ml it mg b gy mm mn l mo mp">pandas_profiling.ProfileReport(train)</span></pre><p id="b540" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">有很多缺失的值。除了逐一检查每个特性并决定如何处理它们之外，没有什么灵丹妙药可以解决这个问题。我们用以下方式清洁它们:</p><pre class="kj kk kl km gt mf mg mh mi aw mj bi"><span id="6875" class="mk ml it mg b gy mm mn l mo mp">dr = ['Alley','Fence','FireplaceQu','MiscFeature','PoolQC']<br/>train.drop(labels = dr, axis = 1, inplace = True)<br/>test.drop(labels = dr, axis = 1, inplace = True)</span><span id="91cb" class="mk ml it mg b gy mq mn l mo mp">train['LotFrontage'].fillna(train['LotFrontage'].mean(), inplace = True)<br/>train['GarageQual'].fillna('NA', inplace = True)<br/>train['GarageFinish'].fillna('NA', inplace = True)<br/>train['GarageCond'].fillna('NA', inplace = True)<br/>train['GarageYrBlt'].fillna(train['GarageYrBlt'].mean(), inplace = True)<br/>train['GarageType'].fillna('NA', inplace = True)<br/>train['MasVnrType'].fillna('None', inplace = True)<br/>train['MasVnrArea'].fillna(train['MasVnrArea'].mean(), inplace = True)<br/>train['BsmtQual'].fillna('NA', inplace = True)<br/>train['BsmtCond'].fillna('NA', inplace = True)<br/>train['BsmtExposure'].fillna('NA', inplace = True)<br/>train['BsmtFinType1'].fillna('NA', inplace = True)<br/>train['BsmtFinType2'].fillna('NA', inplace = True)<br/>train['Electrical'].fillna('SBrkr', inplace = True) # substituting with the majority class</span><span id="9e47" class="mk ml it mg b gy mq mn l mo mp"># and for the test set</span><span id="f8d9" class="mk ml it mg b gy mq mn l mo mp">test['LotFrontage'].fillna(train['LotFrontage'].mean(), inplace = True)<br/>test['GarageQual'].fillna('NA', inplace = True)<br/>test['GarageFinish'].fillna('NA', inplace = True)<br/>test['GarageCond'].fillna('NA', inplace = True)<br/>test['GarageYrBlt'].fillna(train['GarageYrBlt'].mean(), inplace = True)<br/>test['GarageType'].fillna('NA', inplace = True)<br/>test['MasVnrType'].fillna('None', inplace = True)<br/>test['MasVnrArea'].fillna(train['MasVnrArea'].mean(), inplace = True)<br/>test['BsmtQual'].fillna('NA', inplace = True)<br/>test['BsmtCond'].fillna('NA', inplace = True)<br/>test['BsmtExposure'].fillna('NA', inplace = True)<br/>test['BsmtFinType1'].fillna('NA', inplace = True)<br/>test['BsmtFinType2'].fillna('NA', inplace = True)<br/>test['Electrical'].fillna('SBrkr', inplace = True) # substituting with the majority class</span></pre><p id="0625" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">有趣的是，测试集有缺失值，而训练集没有。这意味着我们需要做额外的清洁工作:</p><pre class="kj kk kl km gt mf mg mh mi aw mj bi"><span id="cb77" class="mk ml it mg b gy mm mn l mo mp">test['MSZoning'].fillna('RL', inplace = True)<br/>test['Utilities'].dropna(inplace = True)<br/>test['Exterior1st'].dropna(inplace = True)<br/>test['Exterior2nd'].dropna(inplace = True)<br/>test['BsmtFinSF1'].fillna(test['BsmtFinSF1'].mean(), inplace = True)<br/>test['BsmtFinSF2'].fillna(test['BsmtFinSF2'].mean(), inplace = True)<br/>test['BsmtUnfSF'].fillna(test['BsmtUnfSF'].mean(), inplace = True)<br/>test['TotalBsmtSF'].fillna(test['TotalBsmtSF'].mean(), inplace = True)<br/>test['BsmtFullBath'].fillna(test['BsmtFullBath'].mean(), inplace = True)<br/>test['BsmtHalfBath'].fillna(test['BsmtHalfBath'].mean(), inplace = True)<br/>test['KitchenQual'].dropna(inplace = True)<br/>test['Functional'].dropna(inplace = True)<br/>test['GarageCars'].fillna(round(float(test['GarageCars'].mean()),1), inplace = True)<br/>test['GarageArea'].fillna(test['GarageArea'].mean(), inplace = True)<br/>test['SaleType'].dropna(inplace = True)</span><span id="7ede" class="mk ml it mg b gy mq mn l mo mp">test.drop(test.index[[95,45,485,756,1013,1029]], inplace = True)<br/>test.drop(test.index[[455,691]], inplace = True)<br/>test.drop(test.loc[test['Id']==1916].index, inplace = True)<br/>test.drop(test.loc[test['Id']==2152].index, inplace = True)</span></pre><p id="217d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在这个过程之后，没有 nan 留下:</p><pre class="kj kk kl km gt mf mg mh mi aw mj bi"><span id="93ac" class="mk ml it mg b gy mm mn l mo mp">train.columns[train.isna().any()].tolist()</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi mr"><img src="../Images/cb66dd78237139fff27507dccaa2d175.png" data-original-src="https://miro.medium.com/v2/resize:fit:88/format:webp/1*E6Or9Ap2GI5HeMcTBygLSw.png"/></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk">It’s an empty list that would have had columns with NaNs if there were any</figcaption></figure><pre class="kj kk kl km gt mf mg mh mi aw mj bi"><span id="ade1" class="mk ml it mg b gy mm mn l mo mp">test[test.isna().any(axis=1)]</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ms"><img src="../Images/f40d2ec49942a97d40ad16319e6ebe36.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*JawmlKYWUpOnPea7eWrrZw.png"/></div></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk">The Test set is also good to go</figcaption></figure><h1 id="42d5" class="mt ml it bd mu mv mw mx my mz na nb nc jz nd ka ne kc nf kd ng kf nh kg ni nj bi translated">分类变量的未来工程</h1><p id="ef94" class="pw-post-body-paragraph kz la it lb b lc nk ju le lf nl jx lh li nm lk ll lm nn lo lp lq no ls lt lu im bi translated">这就是你在这里的原因。这是我们将遵循的清单:</p><ul class=""><li id="10c0" class="np nq it lb b lc ld lf lg li nr lm ns lq nt lu nu nv nw nx bi translated">确保分类变量被如此对待。这同样适用于数字变量</li><li id="6733" class="np nq it lb b lc ny lf nz li oa lm ob lq oc lu nu nv nw nx bi translated">检查分类要素的基数</li><li id="273e" class="np nq it lb b lc ny lf nz li oa lm ob lq oc lu nu nv nw nx bi translated">查看“可疑”列如何与目标变量交互</li><li id="360d" class="np nq it lb b lc ny lf nz li oa lm ob lq oc lu nu nv nw nx bi translated">查看是否有任何高度相关的要素可以删除</li><li id="1da6" class="np nq it lb b lc ny lf nz li oa lm ob lq oc lu nu nv nw nx bi translated">看看有没有可以组合的功能</li><li id="f129" class="np nq it lb b lc ny lf nz li oa lm ob lq oc lu nu nv nw nx bi translated">考虑基数，对分类变量进行一次性编码或频率编码</li></ul><h2 id="14a4" class="mk ml it bd mu od oe dn my of og dp nc li oh oi ne lm oj ok ng lq ol om ni on bi translated">分类变量的类型为“类别”</h2><p id="1e2c" class="pw-post-body-paragraph kz la it lb b lc nk ju le lf nl jx lh li nm lk ll lm nn lo lp lq no ls lt lu im bi translated">如果您查看一些列，如<em class="me"> MSSubClass </em>，您会意识到，虽然它们包含数值(在本例中为 20、30 等。)，它们实际上是分类变量。从数据字典中可以清楚地看出:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oo"><img src="../Images/a1e7288e601af6acc8636ce56a9af2b4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*8Vg2uF1VT1RhRmMFtDXjWw.png"/></div></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk">Numbers don’t always mean numbers</figcaption></figure><p id="448d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们怀疑这样的柱子不止一根。我们来确认一下:</p><pre class="kj kk kl km gt mf mg mh mi aw mj bi"><span id="961f" class="mk ml it mg b gy mm mn l mo mp">[col for col in train.columns.tolist() if train[col].dtype not in ['object']]</span></pre><p id="acf2" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">它返回非对象列的列表。在阅读了对它们每一个的描述后，我们决定进行以下转换:</p><pre class="kj kk kl km gt mf mg mh mi aw mj bi"><span id="1aff" class="mk ml it mg b gy mm mn l mo mp">train['Id'] = train['Id'].astype('category') <br/>train['MSSubClass'] = train['MSSubClass'].astype('category')<br/># train['YearBuilt'] = train['YearBuilt'].astype('category')<br/># train['YrSold'] = train['YrSold'].astype('category')<br/># train['YearRemodAdd'] = train['YearRemodAdd'].astype('category')<br/>train['GarageYrBlt'] = train['GarageYrBlt'].astype('category')<br/>train['Fence'] = train['Fence'].astype('category')<br/>train['MiscFeature'] = train['MiscFeature'].astype('category')<br/>train['MiscVal'] = train['MiscVal'].astype('category')</span></pre><p id="febb" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">您将很快看到为什么三个与年份相关的列还没有被转换。</p><h2 id="d03a" class="mk ml it bd mu od oe dn my of og dp nc li oh oi ne lm oj ok ng lq ol om ni on bi translated">基数</h2><p id="ddbd" class="pw-post-body-paragraph kz la it lb b lc nk ju le lf nl jx lh li nm lk ll lm nn lo lp lq no ls lt lu im bi translated">如果您有显示高基数的分类要素，您可能会面临某些问题。最有可能的情况是，您将使用一键编码器，您的数据集可能会突然变得非常宽和稀疏。这不利于计算(尤其是当列数接近观察数时)，不利于任何基于树的方法(很可能，树会向一个方向生长)，并且可能导致过度拟合和数据泄漏。</p><p id="4777" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">你可以从概念上<strong class="lb iu">或者技术上<strong class="lb iu">来解决这个问题。</strong></strong></p><p id="e409" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">概念方法</strong>:检查每一个变量，对它们进行<em class="me"> value_counts() </em>运算，决定是否可以牺牲一些不常用的值，将它们放在“其他”项下。</p><pre class="kj kk kl km gt mf mg mh mi aw mj bi"><span id="1e83" class="mk ml it mg b gy mm mn l mo mp">top = test['GarageType'].isin(test['GarageType'].value_counts().index[:5])<br/>test.loc[~top, 'GarageType'] = "other"</span></pre><p id="5d12" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们刚刚在这里做的:<em class="me"> index() </em>返回给定元素在列表中的位置。在我们的例子中，该列中所有不在频率前五位的<strong class="lb iu">值现在都在“其他”中。理想情况下，您希望对每一列都这样做。之后，你做一个热编码。然而，如果你对自己的时间很吝啬，你可能会用一种纯粹的<strong class="lb iu">技术</strong>方法。最有可能的是，你的计算机将能够处理一个非常广泛的数据集，并相对快速地处理它。所以只要调用 get_dummies()就可以了，希望一切顺利。你可能需要忘记<a class="ae ky" href="https://roamanalytics.com/2016/10/28/are-categorical-variables-getting-lost-in-your-random-forests/" rel="noopener ugc nofollow" target="_blank">基于森林的</a>或者降维方法，但是，在大多数情况下，你可以忍受它。Sklearn 的<em class="me"> OneHotEncoder() </em>在这里提供了一些<a class="ae ky" href="https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html" rel="noopener ugc nofollow" target="_blank">额外的功能</a>可能会有用。它有一个参数<em class="me"> n_values() </em>，您可以用它来指定每一列可以保留的值的最大数量。</strong></p><p id="126f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在这个特定的数据集中，我们首先调查了训练列和测试列是否具有不同的基数:</p><pre class="kj kk kl km gt mf mg mh mi aw mj bi"><span id="3649" class="mk ml it mg b gy mm mn l mo mp">for col in train.columns:<br/>    if train[col].dtype == "object":<br/>        print("For column {} cardinality in Train minus cardinality in Test equals: {}".format(col, train[col].nunique()-test[col].nunique()))<br/></span></pre><p id="3785" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">然后决定通过研究条形图来研究这些信息:</p><pre class="kj kk kl km gt mf mg mh mi aw mj bi"><span id="2e06" class="mk ml it mg b gy mm mn l mo mp"># Gathering columns for which cardinality isn't the same into a list in order to make charts<br/>cols_list = []<br/>for col in train.columns:<br/>     if train[col].dtype == "object" and (train[col].nunique()-test[col].nunique()) != 0:<br/>        cols_list.append(col)<br/>        <br/># looking at values in these columns<br/>for l in cols_list:<br/>    sns.catplot(x=l, hue='Status', kind='count', data=combo)<br/>    plt.xticks(rotation=45)</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi op"><img src="../Images/5417a982c2c0e5a430fc16d8835df71d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1360/format:webp/1*39UJpxTb7rr81Y63aLfkTw.png"/></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk">Example of a variable’s values in the train and test datasets</figcaption></figure><p id="c9d2" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">幸运的是，一般来说，没有一个列有很多不同的分类值，测试集和训练集也没有表现出很高的基数。正因为如此，我们能够继续进行一个普通的独热编码。</p><h2 id="b498" class="mk ml it bd mu od oe dn my of og dp nc li oh oi ne lm oj ok ng lq ol om ni on bi translated">“可疑”栏</h2><p id="169e" class="pw-post-body-paragraph kz la it lb b lc nk ju le lf nl jx lh li nm lk ll lm nn lo lp lq no ls lt lu im bi translated">正如我们上面所说的，高基数的情况没有那么糟糕，只适用于相应列中的较小值。因此，我们将保持原样。不过，我们仍然可以检查它们是如何影响销售价格的。</p><p id="6b71" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们将构建盒子图<em class="me">(可能需要一些时间来渲染)</em>:</p><pre class="kj kk kl km gt mf mg mh mi aw mj bi"><span id="79d5" class="mk ml it mg b gy mm mn l mo mp"># list w/ categorical variables<br/>cater_cols = train.select_dtypes(include='category').columns.to_list()</span><span id="5d1d" class="mk ml it mg b gy mq mn l mo mp">for cols in cater_cols:<br/>    plt.figure()<br/>    sns.boxplot(x = cols, y = 'SalePrice', data = train)</span></pre><p id="c418" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">一个好主意是在以下情况后关闭图表:</p><pre class="kj kk kl km gt mf mg mh mi aw mj bi"><span id="b69f" class="mk ml it mg b gy mm mn l mo mp">plt.clf()<br/>plt.close()</span></pre><p id="6bf5" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">无法检测到任何可见的异常值。</p><h2 id="4306" class="mk ml it bd mu od oe dn my of og dp nc li oh oi ne lm oj ok ng lq ol om ni on bi translated">相关</h2><p id="48b9" class="pw-post-body-paragraph kz la it lb b lc nk ju le lf nl jx lh li nm lk ll lm nn lo lp lq no ls lt lu im bi translated">我们将把数字特征与<em class="me">销售价格</em>联系起来，希望了解哪些可以删除，哪些可以合并。查看每个特性可能不是一个好主意，所以让我们关注前 15 个(但是您可以在下面的代码中将这个数字更改为任何其他值)最相关的变量:</p><pre class="kj kk kl km gt mf mg mh mi aw mj bi"><span id="9114" class="mk ml it mg b gy mm mn l mo mp">corrmat = train.corr()<br/>plt.figure(figsize=(20,10))<br/>k = 15 #number of variables for heatmap<br/>cols = corrmat.nlargest(k, 'SalePrice')['SalePrice'].index<br/>cm = np.corrcoef(train[cols].values.T)<br/>sns.set(font_scale=1.25)<br/>hm = sns.heatmap(cm, cbar=True, annot=True, square=True, fmt='.2f', annot_kws={'size': 10}, yticklabels=cols.values, xticklabels=cols.values)<br/>plt.show()</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oq"><img src="../Images/cd31d1a6bd7b53d4e5855803ad4e12b2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*n4WOcGbhiMEosNYMvRz6Hw.png"/></div></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk">Top categories affecting <em class="or">SalePrice</em></figcaption></figure><p id="e8b3" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">同样，你需要运用一些常识。例如，<em class="me"> GarageCars </em>和<em class="me"> GarageArea </em>都在讲述一个关于你停放车辆的地方有多大的故事。关于平方英尺的信息分布在不同的列中，并且可能被汇总。平方英尺的浴池可以跟随诉讼。一个时代的房子和他们何时被改造也应该齐头并进。让我们来实现它:</p><pre class="kj kk kl km gt mf mg mh mi aw mj bi"><span id="a839" class="mk ml it mg b gy mm mn l mo mp">train['Remodeled Y/N'] = np.where(train['YearRemodAdd'] ==train['YearBuilt'], 'No', 'Yes')<br/>train['Age when Sold'] = train['YrSold'] - train['YearRemodAdd']<br/>train['Remodeled Y/N'] = train['Remodeled Y/N'].astype('category')</span><span id="afff" class="mk ml it mg b gy mq mn l mo mp">train['totSqFt'] = train['TotalBsmtSF'] + train['GrLivArea'] + train['1stFlrSF'] + train['2ndFlrSF']</span><span id="d151" class="mk ml it mg b gy mq mn l mo mp">train['totBath'] = train['FullBath'] + 0.5*train['HalfBath'] + train['BsmtFullBath'] + 0.5*train['BsmtHalfBath']</span></pre><p id="e9b7" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们刚刚创建了一个新列，<em class="me"> totSqFt </em>，它合并了三个现有的值。我们可以检查它是否可以作为一个正确的近似:</p><pre class="kj kk kl km gt mf mg mh mi aw mj bi"><span id="fc5f" class="mk ml it mg b gy mm mn l mo mp">fig = plt.figure(figsize=(20,10))<br/>ax1 = fig.add_subplot(121)<br/>ax2 = fig.add_subplot(122)</span><span id="d3ca" class="mk ml it mg b gy mq mn l mo mp">ax1.scatter(train['totSqFt'],train['SalePrice'], color = 'crimson', label = 'totSqFt')</span><span id="490c" class="mk ml it mg b gy mq mn l mo mp">ax2.scatter(train['GrLivArea'],train['SalePrice'], color = 'teal', alpha = 0.3, label ='GrLivArea')<br/>ax2.scatter(train['TotalBsmtSF'],train['SalePrice'], color = 'midnightblue', label = 'TotalBsmtSF')<br/>ax2.scatter(train['1stFlrSF'],train['SalePrice'], color = 'coral', alpha = 0.4, label = '1stFlrSF')</span><span id="e346" class="mk ml it mg b gy mq mn l mo mp">ax1.legend()<br/>ax2.legend()<br/>plt.show()</span></pre><p id="2c20" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">看起来很准确:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi os"><img src="../Images/ade8e349e547402474d68da30fc8374a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*obM_lUZZpZMam1piSDXqaA.png"/></div></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk">Sum of three columns on the left; original features on the right</figcaption></figure><p id="3d70" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">完成后，我们可以删除进入新变量的列:</p><pre class="kj kk kl km gt mf mg mh mi aw mj bi"><span id="9323" class="mk ml it mg b gy mm mn l mo mp"># Remove variables that were used to create new features<br/>cols_2_remove = ['GrLivArea','TotalBsmtSF','1stFlrSF','YearRemodAdd','YearBuilt','YrSold','Id','2ndFlrSF',<br/>                'FullBath','HalfBath','BsmtFullBath','BsmtHalfBath','GarageYrBlt']<br/>train_rem = train.copy()<br/>train_rem.drop(cols_2_remove, axis = 1, inplace = True)</span></pre><p id="2c36" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们有独立变量，情况很好，但是让我们再看看<em class="me">销售价格</em>。</p><pre class="kj kk kl km gt mf mg mh mi aw mj bi"><span id="1936" class="mk ml it mg b gy mm mn l mo mp"># Building normality plots<br/>from statsmodels.graphics.gofplots import qqplot<br/>from matplotlib import pyplot</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ot"><img src="../Images/5a8997b8526817e814cd4665c374f251.png" data-original-src="https://miro.medium.com/v2/resize:fit:1356/format:webp/1*qdp4-EyOhT5fBZknwy7a4A.png"/></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk">Normality plot for SalePrice</figcaption></figure><p id="3805" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这张<a class="ae ky" href="https://data.library.virginia.edu/understanding-q-q-plots/" rel="noopener ugc nofollow" target="_blank"> q-q 图</a>显示，非常便宜和非常昂贵的房子并不真正遵循正态分布。对<em class="me"> totSqFt </em>的额外检查证实了这一点:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ou"><img src="../Images/6e77d2e23b702e99e07109ef983eb7bb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1276/format:webp/1*CIq9SUQY7qV7xdnsa_Zl-g.png"/></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk">q-q plot for totSqFt</figcaption></figure><p id="3cd7" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">你可以探索这些又大又贵(或者又小又便宜)的房子:</p><pre class="kj kk kl km gt mf mg mh mi aw mj bi"><span id="ad8d" class="mk ml it mg b gy mm mn l mo mp">train_rem[train_rem['totSqFt']&gt;10000]<br/>train_rem[train_rem['SalePrice']&gt;700000]</span></pre><p id="328e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">它们没有什么特别的，所以我们应该对从集合中移除它们感到相对安全:</p><pre class="kj kk kl km gt mf mg mh mi aw mj bi"><span id="643d" class="mk ml it mg b gy mm mn l mo mp">train_rem.drop(train_rem[train_rem.totSqFt&gt;10000].index, inplace = True)<br/>train_rem.drop(train_rem[train_rem.SalePrice&gt;700000].index, inplace = True)</span></pre><p id="2b1a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">之后，q-q 图看起来更正常。</p><p id="13bf" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这是有效处理具有大量分类特征的数据集的方法。我们已经做了大量的数据探索和预处理，这将在 ML 阶段有所帮助。</p><p id="ec14" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">现在这里最重要的部分:<strong class="lb iu">你必须对合并的数据集进行任何编码！</strong>为什么？假设您有一个列“颜色”，它在训练集中的值为“蓝色”、“绿色”和“黑色”。同时测试也有“黄色”和“红色”您的编码器必须看到所有可能的值，才能充分利用它们。</p><p id="f497" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">操作的顺序是:</p><ul class=""><li id="e82a" class="np nq it lb b lc ld lf lg li nr lm ns lq nt lu nu nv nw nx bi translated">在新列<em class="me">状态</em>中分别标记训练集和测试集</li><li id="016d" class="np nq it lb b lc ny lf nz li oa lm ob lq oc lu nu nv nw nx bi translated">组合列车和测试装置，从列车部分移除<em class="me">销售价格</em></li><li id="3a0d" class="np nq it lb b lc ny lf nz li oa lm ob lq oc lu nu nv nw nx bi translated">对分类特征进行一次性编码(但不包括<em class="me">状态</em></li><li id="ca8a" class="np nq it lb b lc ny lf nz li oa lm ob lq oc lu nu nv nw nx bi translated">使用<em class="me">状态</em>将接头组拆分回列车并测试</li></ul><p id="0764" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">没有理由保留分类列的<em class="me">对象</em>类型。让我们把它们变成<a class="ae ky" href="https://pandas.pydata.org/pandas-docs/stable/user_guide/categorical.html" rel="noopener ugc nofollow" target="_blank"> <em class="me">类别</em> </a>。</p><pre class="kj kk kl km gt mf mg mh mi aw mj bi"><span id="327b" class="mk ml it mg b gy mm mn l mo mp"># turning object columns into category columns<br/>for i in train.select_dtypes(include='object').columns.to_list():<br/>    train[i] = train[i].astype('category')</span></pre><p id="ebd2" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">和主要部分:</p><pre class="kj kk kl km gt mf mg mh mi aw mj bi"><span id="ce5a" class="mk ml it mg b gy mm mn l mo mp"># list w/ categorical variables<br/>cater_cols = train.select_dtypes(include='category').columns.to_list()</span><span id="698f" class="mk ml it mg b gy mq mn l mo mp">#Add new column Status to both sets to differentiate between the two<br/>train_1 = train_rem.copy()<br/>train_1.drop(labels = 'SalePrice', axis = 1, inplace = True)<br/>train_1['Status'] = 'Train Set' # adding a column Status to differentiate between Train and Test in the combined set<br/>test_1 = test_rem.copy()<br/>test_1['Status'] = 'Test Set'<br/>combo = train_1.copy()<br/>combo = combo.append(test_1)</span></pre><p id="75d8" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">确保每件事都做对的一个好方法是不断检查你的数据帧的形状:</p><pre class="kj kk kl km gt mf mg mh mi aw mj bi"><span id="a29b" class="mk ml it mg b gy mm mn l mo mp">train_1.shape<br/>test_1.shape<br/>combo.shape</span></pre><p id="6865" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这里我们单独保存了<em class="me">状态</em>并从 X:</p><pre class="kj kk kl km gt mf mg mh mi aw mj bi"><span id="fe9d" class="mk ml it mg b gy mm mn l mo mp">X = combo.copy()<br/>St = X['Status']<br/>X.drop('Status', axis = 1, inplace = True)</span></pre><p id="fd2d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">以及编码:</p><pre class="kj kk kl km gt mf mg mh mi aw mj bi"><span id="2724" class="mk ml it mg b gy mm mn l mo mp">X_cat = X.select_dtypes(include=['category'])<br/>X_num = X.select_dtypes(exclude=['category'])<br/>X_encoded = pd.get_dummies(X_cat)</span></pre><p id="e777" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">现在我们有三块:<em class="me"> X_encoded </em>(编码后的分类变量)<em class="me"> X_num </em>(没变的数值变量)<em class="me"> St </em>(就一列，<em class="me">状态</em>)。</p><p id="45e8" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">检查它们的大小是否匹配:</p><pre class="kj kk kl km gt mf mg mh mi aw mj bi"><span id="0ab7" class="mk ml it mg b gy mm mn l mo mp">print("X_encoded = {}\nX_num = {}\nSt = {}".format(X_encoded.shape,X_num.shape, St.shape))</span></pre><p id="5434" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">将它们组合在一起(并进行最终尺寸检查):</p><pre class="kj kk kl km gt mf mg mh mi aw mj bi"><span id="b184" class="mk ml it mg b gy mm mn l mo mp">frames = [X_encoded, X_num, St]<br/>combo_enc = pd.concat(frames, axis = 1)</span><span id="6307" class="mk ml it mg b gy mq mn l mo mp">print('Combined set is {}'.format(combo_enc.shape))</span></pre><p id="8681" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">现在，我们可以将组合集分为训练集和测试集，并继续机器学习:</p><pre class="kj kk kl km gt mf mg mh mi aw mj bi"><span id="d30e" class="mk ml it mg b gy mm mn l mo mp">train_enc = combo_enc.loc[combo_enc['Status']=='Train Set']<br/>test_enc = combo_enc.loc[combo_enc['Status']=='Test Set']</span><span id="aa00" class="mk ml it mg b gy mq mn l mo mp">print('Encoded Train set is {}\nEncoded Test set is {}'.format(train_enc.shape,test_enc.shape))</span></pre><p id="b68f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这种事实上的方法是透明的，在各种文章和书籍中都有描述。然而，让我们避免使我们的数据集太宽。怎么会？通过频率编码。</p><h2 id="91fc" class="mk ml it bd mu od oe dn my of og dp nc li oh oi ne lm oj ok ng lq ol om ni on bi translated">频率编码</h2><pre class="kj kk kl km gt mf mg mh mi aw mj bi"><span id="8bb9" class="mk ml it mg b gy mm mn l mo mp">X_cat_freq = X_cat.copy()</span><span id="b486" class="mk ml it mg b gy mq mn l mo mp">for c in X_cat_freq.columns.to_list():<br/>    X_cat_freq[c] = X_cat_freq.groupby(c).transform('count')/len(X_cat_freq[c])</span></pre><p id="66e3" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">频率编码并不难理解或实现。我们计算一列中不同值的数量，然后除以该列的总长度。结果，我们得到了每一个值的“份额”,这些值在任何 ML 算法中都能很好地发挥作用。</p><p id="674e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">下面的代码看起来应该很熟悉:我们需要区分训练集和测试集，然后将它们合并在一起，</p><pre class="kj kk kl km gt mf mg mh mi aw mj bi"><span id="9886" class="mk ml it mg b gy mm mn l mo mp">frames_freq = [X_cat_freq, X_num, St]<br/>combo_enc_freq = pd.concat(frames_freq, axis = 1)</span><span id="7d00" class="mk ml it mg b gy mq mn l mo mp">combo_enc_freq.shape<br/># All features and Status are together</span><span id="5298" class="mk ml it mg b gy mq mn l mo mp">#cut combo_enc_freq by Train and Test. Add SalePrice back to the Train portion<br/>train_freq = combo_enc_freq.loc[combo_enc_freq['Status']=='Train Set']<br/>test_freq = combo_enc_freq.loc[combo_enc_freq['Status']=='Test Set']</span><span id="ee86" class="mk ml it mg b gy mq mn l mo mp"># adding SalePrice to Encoded Train set<br/>fr = [train_freq, sp]<br/>train_freq = pd.concat(fr, axis = 1)</span><span id="5321" class="mk ml it mg b gy mq mn l mo mp"># Checking sizes <br/>print("Respective sizes of the train set: {}\nOf the test set: {}\nOf the prices array:{}".format(train_freq.shape,<br/>                                                                                                 test_freq.shape,<br/>                                                                                                 sp.shape))</span></pre><p id="ae51" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">为了便于您比较哪种编码类型会产生更好的结果，我们创建了使用频率和一键编码方法编码的数据帧:</p><pre class="kj kk kl km gt mf mg mh mi aw mj bi"><span id="4ce6" class="mk ml it mg b gy mm mn l mo mp">features_freq = train_freq.drop(['SalePrice','Status'], axis = 1)<br/>result_freq = np.exp(train_freq['SalePrice'])</span><span id="b499" class="mk ml it mg b gy mq mn l mo mp">X_train_freq, X_test_freq, y_train_freq, y_test_freq = train_test_split(features_freq, result_freq, test_size = 0.2, random_state = 12)</span><span id="6df2" class="mk ml it mg b gy mq mn l mo mp">features = train_enc.drop(['SalePrice','Status'], axis = 1)<br/>result = train_enc['SalePrice']</span><span id="5ffd" class="mk ml it mg b gy mq mn l mo mp">X_train, X_test, y_train, y_test = train_test_split(features, result, test_size = 0.2, random_state = 12)</span></pre><h1 id="3fdf" class="mt ml it bd mu mv mw mx my mz na nb nc jz nd ka ne kc nf kd ng kf nh kg ni nj bi translated">机器学习</h1><p id="fff6" class="pw-post-body-paragraph kz la it lb b lc nk ju le lf nl jx lh li nm lk ll lm nn lo lp lq no ls lt lu im bi translated">这一部分在其他资料中有详细解释；此外，GitHub 上的工作簿包含了几个不同模型的实现:从使用 one-hot 编码数据集的回归到 Lasso 和 XGBoost。下面我们将探讨线性回归和 XGBoost，我们在经过频率编码的集合上运行。</p><pre class="kj kk kl km gt mf mg mh mi aw mj bi"><span id="2f13" class="mk ml it mg b gy mm mn l mo mp">import xgboost as xgb<br/>from sklearn.linear_model import LinearRegression<br/>from sklearn.model_selection import StratifiedKFold<br/>import math</span></pre><p id="f484" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">加载完依赖项后，我们可以开始建模了。</p><pre class="kj kk kl km gt mf mg mh mi aw mj bi"><span id="e8a9" class="mk ml it mg b gy mm mn l mo mp">regr_freq = LinearRegression()<br/>regr_freq.fit(X_train_freq, y_train_freq)</span><span id="0ac4" class="mk ml it mg b gy mq mn l mo mp">print("RMSE is: {:.2f}\nR_squared is {:.2f}%".format(math.sqrt(np.mean((regr_freq.predict(X_test_freq) - y_test_freq) ** 2)),<br/>                                                   regr_freq.score(X_test_freq,y_test_freq)*100))</span></pre><p id="f4b8" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">回归给了我们:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ov"><img src="../Images/f9501fa033ed0e0711edf0a8f6c4c7a7.png" data-original-src="https://miro.medium.com/v2/resize:fit:454/format:webp/1*mcbuhRPqdk5l3bZ_Ksu3MQ.png"/></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk">Not bad for the simplest method possible</figcaption></figure><p id="972d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">和 XGBoost:</p><pre class="kj kk kl km gt mf mg mh mi aw mj bi"><span id="a6a7" class="mk ml it mg b gy mm mn l mo mp">xgb_freq = xgb.XGBRegressor(n_estimators=100, learning_rate=0.08, gamma=0, subsample=0.75,<br/>                           colsample_bytree=1, max_depth=7)</span><span id="d2fe" class="mk ml it mg b gy mq mn l mo mp">xgb_freq.fit(X_train_freq,y_train_freq)<br/>predictions_xgb_freq = xgb_freq.predict(X_test_freq)<br/>print(explained_variance_score(predictions_xgb_freq,y_test_freq))</span></pre><p id="02c7" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">现成的结果几乎与回归结果一致:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ow"><img src="../Images/78dc09e3748795346ede8c55af94bcae.png" data-original-src="https://miro.medium.com/v2/resize:fit:668/format:webp/1*XlO8sPwmjbZIjmJvqDDZGg.png"/></div></figure><p id="bc8b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">如果我们优化参数，会有帮助吗？运行以下代码需要几分钟时间:</p><pre class="kj kk kl km gt mf mg mh mi aw mj bi"><span id="8864" class="mk ml it mg b gy mm mn l mo mp"># TAKES TIME<br/>n_estimators = [80, 100, 120, 140, 160]<br/>max_depth = [4, 5, 6, 7, 8, 9, 10]<br/>learning_rate = [0.0001, 0.001, 0.005, 0.01, 0.1, 0.2, 0.3, 0.04]<br/>param_grid = dict(max_depth = max_depth, n_estimators = n_estimators, learning_rate=learning_rate)<br/>kfold = StratifiedKFold(n_splits = 10, shuffle = True, random_state = 10)<br/>grid_search_xg_freq = GridSearchCV(xgb_freq, param_grid, scoring = 'r2', n_jobs = -1, cv=kfold, verbose = 1)<br/>result_gcv_xgb_freq = grid_search_xg_freq.fit(X_train_freq, y_train_freq.astype(int))</span><span id="c0d2" class="mk ml it mg b gy mq mn l mo mp">print("Best score: %f using %s" % (result_gcv_xgb_freq.best_score_, result_gcv_xgb_freq.best_params_))<br/>means = result_gcv_xgb_freq.cv_results_['mean_test_score']<br/>stds = result_gcv_xgb_freq.cv_results_['std_test_score']<br/>params = result_gcv_xgb_freq.cv_results_['params']</span></pre><p id="c92e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">让我们使用最佳参数:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ox"><img src="../Images/779d5e8a19467e9cc1b1ccb1bdd6a3ce.png" data-original-src="https://miro.medium.com/v2/resize:fit:1294/format:webp/1*8eEpnEY7sAXCnVvnRfD3ow.png"/></div></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk">Results of GridSearchCV</figcaption></figure><pre class="kj kk kl km gt mf mg mh mi aw mj bi"><span id="0303" class="mk ml it mg b gy mm mn l mo mp"># Rebuilding using the best parameters:<br/>xgb_freq = xgb.XGBRegressor(n_estimators=110, learning_rate=0.1, gamma=0, subsample=0.75,<br/>                           colsample_bytree=1, max_depth=5)</span><span id="d9bc" class="mk ml it mg b gy mq mn l mo mp">xgb_freq.fit(X_train_freq,y_train_freq)<br/>predictions_xgb_freq = xgb_freq.predict(X_test_freq)<br/>print("R squared is {}".format(explained_variance_score(predictions_xgb_freq,y_test_freq)))</span></pre><p id="f5d9" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们可以进一步调整模型，但这不是主要的学习成果。主要的一点是，通过以明智和准确的方式对待分类特征，我们可以在没有非常花哨的机器学习方法或过度计算能力的情况下获得体面的结果。</p></div></div>    
</body>
</html>