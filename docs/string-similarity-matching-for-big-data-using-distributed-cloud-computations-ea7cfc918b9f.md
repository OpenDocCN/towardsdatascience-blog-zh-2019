# 基于分布式云计算的大数据字符串相似性匹配

> 原文：<https://towardsdatascience.com/string-similarity-matching-for-big-data-using-distributed-cloud-computations-ea7cfc918b9f?source=collection_archive---------18----------------------->

## 将 BigQuery、Python 的 Scikit-Learn & Dask(分布式)和 Kubernetes 组合在一个项目中。

![](img/497260c56c925d1021fb5d4324e85c45.png)

Photo by [daveynin](https://www.flickr.com/photos/daveynin/) on [flickr](https://www.flickr.com)

# e̶x̶i̶s̶t̶e̶n̶t̶i̶a̶l̶问题设置

像大多数故事一样，我们的故事始于一项雄心勃勃的事业！我们得到了两个大型数据集(来自 BigQuery 中的两个表)。一个包括来自 Google Play 和 iOS 应用商店的所有应用名称——大约 1400 万个条目——我们称之为“干净的”应用名称。另一个包含大约 5K 个“脏”应用程序名称。*肮脏*是指遗漏的单词、某些单词的拼写错误、涉及操作系统或其他信息的附加单词等。可以通过查看“将所有东西放在一起并运行它”一节来找到例子。

![](img/5c907178a0ba1a2dad2e91c0d6f351a4.png)

Choose wisely — Photo by [W.carter](https://commons.wikimedia.org/wiki/User:W.carter) on [Wikimedia Commons](https://commons.wikimedia.org)

除了数据集，我们还为[提供了蓝色和红色药丸](https://en.wikipedia.org/wiki/Red_pill_and_blue_pill)。我们认为自己足够勇敢，决定服用红色药丸，接受挑战，寻求残酷的真相。

请求是将“脏”数据集中的条目与“干净”数据集中的条目进行匹配，然后将结果存储为查找表。

# 旅程——测试和失败

在成为男人和面对 t̶h̶e̶ ̶r̶e̶a̶l̶ ̶w̶o̶r̶l̶d̶制作之前，一个男孩需要在操场上发展他的技能。一个奇特的例子是[谷歌合作实验室](https://colab.research.google.com/)，这是一个托管在云上的 Jupyter 笔记本电脑，提供免费的强大计算资源(包括 GPU/TPU)，这是第一次测试运行的地方。

计算机科学家会把我们的问题归类为近似字符串匹配问题。这些问题的传统解决方案使用不同的字符串度量来得出两个给定字符序列之间的**距离**。例如[Jaro-Winkler 距离](https://en.wikipedia.org/wiki/Jaro%E2%80%93Winkler_distance)和 [Levenshtein 距离](https://en.wikipedia.org/wiki/Levenshtein_distance)。

我们的第一个尝试是使用 [fuzzy wuzzy](https://github.com/seatgeek/fuzzywuzzy) ，一个实现 Levenshtein 距离的 Python 库。(请保留下面的粗略数字，而不是适当的基准。最终的差异如此显著，以至于完美的精度并不重要。)Fuzzy wuzzy 需要大约 15 分钟来计算来自“脏”数据集的单个条目和来自“干净”数据集的所有条目之间的距离。重复这个过程 5K 次相当于大约 52 天，这比我们希望的每天至少运行一次的过程稍微多了*。如果时间就是金钱，我们早就破产了！*

# *最终(目前)算法*

*为了避免严重的贷款和破产，采用了一种略有不同的方法:通过数字的力量提高业绩。基于[**TF–IDF**](https://en.wikipedia.org/wiki/Tf%E2%80%93idf)**将字符串数据集转换成向量，以便使用余弦相似度。该算法的核心之前已经用于类似的问题[这里](/fuzzy-matching-at-scale-84f2bfd0c536)，这里[这里](https://bergvca.github.io/2017/10/14/super-fast-string-matching.html)和这里[这里](/fuzzy-matching-at-scale-84f2bfd0c536)。为了进一步提高性能，本文引入了一些修改，以支持在云 [Dask](https://dask.org/) 客户端上运行分布式计算。***

> ***为什么是达斯克？Dask 是什么？***

***Dask 是一个库，它提供了在本地扩展 Pandas、Scikit-Learn 和 Numpy 工作流的方法，只需最少的重写。因此，普通的 Python 操作可以在不同的节点/CPU 内核之间分布/并行化。它也可以(但不是必须)在分布式集群上运行。也就是说，Dask 只不过是提供基础设施来将数据(如 Pandas 数据帧)分割成不同的节点，然后使用多个内核执行操作，并确保分割数据之间的通信。***

## ***设置事物***

****注:下面的* ***干净*** *和* ***脏*** *命名约定分别用于基线和待匹配数据集。****

***下面是这个项目使用的基本库的列表:***

## ***从 BigQuery 导入数据***

***为了从 BigQuery 获取数据，我们使用了 Python 的 [BigQuery 客户端库。客户端将数据加载到 Pandas 数据帧中，该数据帧立即转换为 Dask 数据帧。Dask 数据帧只不过是分布在许多分区( *npartitions* )上的 Pandas 数据帧的组合，具体取决于 CPU 架构。](https://cloud.google.com/bigquery/docs/reference/libraries#using_the_client_library)***

## ***转换为向量***

***使用 tf-idf 将数据帧从字符串转换为向量实际上需要 3 行代码:***

***使用 Scikit-Learn 中的`TfidfVectorizer`函数并通过定义分析器函数来初始化矢量化函数(参见下面的信息)。干净的数据帧用于定义特征向量(基于分析器)，同时计算干净的 tf-idf 矩阵(`fit_transform`)，然后计算脏的 tf-idf 矩阵(`transform`)。***

***分析器是用于将每个应用程序名称(字符串)分割成较小部分的功能。从干净数据帧的所有条目中收集所有这些较小的比特定义了特征向量。如果一个特定的应用程序名称包含这一位，那么当转换为向量时，它将在相应的位置获得一个浮点值——如果不是 0。浮点值取决于该位在应用程序名称中出现的次数，并且该值被修改，使得该应用程序名称的向量被归一化(向量范数等于 1 个单位)。举个例子:如果分析仪定义如下***

***干净的数据帧简单如下，***

***![](img/17785e427217cd144554369ceaa3d75a.png)***

***那么特征向量具有这样的形式:***

```
***['ACE',
 'AGR',
 'BOO',
 'CEB',
 'EBO',
 'FAC',
 'GRA',
 'INS',
 'NST',
 'OOK',
 'RAM',
 'STA',
 'TAG']***
```

***干净的数据帧被转换成下面的向量矩阵(输出矩阵以稀疏矩阵(CSR)格式给出，但在这里显示为数组)***

```
***[[0.40824829 0\.         0.40824829 0.40824829 0.40824829 0.40824829
  0\.         0\.         0\.         0.40824829 0\.         0.
  0\.        ]
 [0\.         0.37796447 0\.         0\.         0\.         0.
  0.37796447 0.37796447 0.37796447 0\.         0.37796447 0.37796447
  0.37796447]]***
```

## ***余弦相似性***

***一旦干净和脏数据集处于向量模式，我们就可以继续获得余弦相似性得分矩阵。在干净和脏的矢量化矩阵之间执行点积足以给出余弦值，因为向量是归一化的。即，点积与余弦(相似性)一致。***

***![](img/bb42f7bd403c4fbc8c966c5367e86556.png)***

***为此，使用了以下代码:***

***这里使用了 [sparse_dot_topn](https://github.com/ing-bank/sparse_dot_topn) 包，它提供了一种快速的方法来执行稀疏矩阵乘法，然后使用 [Cython](https://cython.org/) 进行 top-n 乘法结果选择。余弦相似性将以稀疏矩阵形式给出，其中行对应于脏数据集，列对应于干净数据集。***

***使用这个相似性矩阵，我们可以提取在 ***干净*** 和 ***脏*** 之间匹配的条目以及它们的相似性分数，使用:***

## ***上传到 BigQuery***

***最后但同样重要的是，我们需要将匹配过程的结果作为查找表上传回 BiqQuery。这样做的代码如下所示:***

***比起算法的千言万语，你会更喜欢一张图片吗？这是它的简图:***

***![](img/9c59b59d4b3bc0917cdd9c332af97cfb.png)***

# ***部署(在 Kubernetes)***

****节由* [*盖亚尔*](https://medium.com/u/f1ffe8077e95?source=post_page-----ea7cfc918b9f--------------------------------) 撰写***

***Dask 是一个如此通用的工具，甚至通过使用其内置的 Pandas API 支持在本地运行它也能让您受益。然而，当它在分布式系统上运行时——也就是集群——显示了它的全部能力。通过与 DevOps 工程师的合作，我们可以访问部署在谷歌云平台(GCP)上的托管 Kubernetes (k8s)集群。在大多数情况下，在获得对集群的访问权后，可以使用 helm package manager 通过运行以下命令在 k8s 上轻松部署 Dask:***

```
***helm install —name my-dask stable/dask***
```

***过一会儿，你会部署 5 个吊舱:***

*   ***调度程序—主 Dask 任务管理器***
*   ***3 名工作人员—处理数据和应用操作***
*   ***Jupyter 舱——一个预先设置的 Jupiter 实验室舱，是与 Dask 互动的好方法***

***为了获得部署后的 pod 列表，我们创建了一个简单的 shell 脚本。运行它，它将显示所有新创建的 pod 的 IP 地址列表:***

***如果你不再需要它，或者你弄坏了什么东西，想要一个新的开始，你可以跑:***

```
***helm delete dask —purge***
```

***是不是看起来太容易不真实了？你说得对；通用的解决方案很少奏效。***

***![](img/f290fba918f8efec524404120f2b3d16.png)***

***Made with [imgflip.com](https://imgflip.com)***

***这里有一点定制，使它为我们的需要工作。***

***在最初的测试之后，我们已经发现了**几个在使用 Dask helm 时的问题**。***

1.  ***它有几个 bug。幸运的是，所有的修复都在官方回购中作为未决的拉请求(PRs) [存在，但是没有被合并。](https://github.com/helm/helm)***
2.  ***我们需要的一些软件包缺少默认图像。***
3.  ***一个包在 pip 中没有二进制版本，并且在`pip install ...`部分失败。***
4.  ***默认的 pod 配置不足以处理我们的大型数据帧。***

***继续讨论**解决方案**:***

*****1。头盔配置中的错误**
幸运的是，这些错误已经通过待定的 PRs 在官方回购中修复了。要应用它们，我们必须制作一个 repo 的本地克隆，并将所有 PRs 与解决方案合并为补丁。这当然不是理想的解决方案，但却是一种快速有效的方法。
另一个问题是回购协议中定义的 Jupyter Lab 版本有一些 UI 问题。为了克服它们，必须通过指定包版本来升级。方法包含在第二个问题的解决方案中。***

*****2。由于我们的数据管道是基于 GCP 的，我们需要包含 SDK 包和一些其他的库。幸运的是，Dask helm chart 支持使用 YAML 配置文件。因此，可以指定包含哪个`pip`或`conda`包，分配给工人多少 RAM 以及更多。
在我们的例子中，我们添加了以下内容:*****

***大多数软件包将通过`conda`使用`conda-forge`和`gaiar`通道安装(见下文为什么也需要这个通道)。其余通过`pip`安装。***

*****3。缺少二进制包版本**
为了加速稀疏矩阵乘法，我们使用的是`sparse_dot_topn`，在算法部分提到过，它依赖于 Cython。像这样的包通常以两种方式提供:或者作为二进制预编译包，或者当库在安装主机上编译它的一部分时。在我们的例子中，我们遗漏了二进制发行版，这意味着我们应该在已经“不那么轻”的映像中添加编译工具。相反，我们选择了另一种方式。我已经有了在自己的渠道中构建和维护 conda 包的经验。conda 的一个显著优势是它以二进制方式发送包，这正是我们所需要的。
根据 pip 分布使用 conda 配方定义 YAML 文件相对容易:***

***有了这个配方，您就可以运行`conda build`命令并将包上传到您可以访问的频道。然后，可以用`conda -c CHANNEL_NAME PACKAGE_NAME`或者在我们的例子中用`conda -c gaiar sparse_dot_topn`来安装这个包。我准备了两个版本——一个用于 Linux，另一个用于 MacOS(因为它在安装上也有一些问题)。***

*****4。吊舱的有限资源**
这部分是具体情况，取决于 Dask 正在运行的任务类型和约束条件。在我们的例子中，我们需要更多的 RAM，并希望定义每个 pod 可以消耗的内存上限。这通过配置 YAML 文件再次完成:***

***也就是说:每个员工的最低限额是 3G，但是如果需要的话，可以申请 6G。***

***下面是 Dask 在 GCP k8s 上工作的简单演示:***

***![](img/1a32933e32bbc65384ba960be810a0a5.png)***

# ***把所有东西放在一起并运行它***

***结合上述算法和部署，我们的代码在大约 20-30 分钟内执行匹配过程；与最初的 52 天相比，速度大大加快了。😆***

***这是我们一次运行的输出表中的一小部分:***

***这张表和获取它所需的执行时间表明，红色药丸可能是这次更明智的决定。***

# ***编后记***

***让我们试着用一句话来说:部署在 Kubernetes 中的 Tf-idf 矢量化和余弦相似性结合高效的稀疏矩阵计算和并行执行操作使用 Dask 的分布功能，被证明是处理大规模字符串相似性问题的非常有效的方法。***

****特别感谢* [*盖亚尔·白木拉托夫*](https://medium.com/u/f1ffe8077e95?source=post_page-----ea7cfc918b9f--------------------------------) *做出部署并撰写相应章节。****