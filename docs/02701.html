<html>
<head>
<title>Zalando Dress Recommendation and Tagging</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">Zalando 服装推荐和标签</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/zalando-dress-recomendation-and-tagging-f38e1cbfc4a9?source=collection_archive---------16-----------------------#2019-05-02">https://towardsdatascience.com/zalando-dress-recomendation-and-tagging-f38e1cbfc4a9?source=collection_archive---------16-----------------------#2019-05-02</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="5a5e" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">利用图像和文字描述来建议和标记产品</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/609b6d49271d009b03b2f26cc375f652.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*nhB8_Q738WWX4SU2"/></div></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk">Photo by <a class="ae ky" href="https://unsplash.com/@beccamchaffie?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Becca McHaffie</a> on <a class="ae ky" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><p id="c47e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在人工智能领域，计算机视觉技术被大量应用。一个很好的应用领域(我最喜欢的领域之一)是时装业。原始图像方面的资源可用性允许开发有趣的用例。Zalando 知道这一点(我建议看看他们的<a class="ae ky" href="https://github.com/zalandoresearch" rel="noopener ugc nofollow" target="_blank"> GitHub 知识库</a>)并经常开发令人惊叹的 AI 解决方案，或发表 juicy ML 研究报告。</p><p id="df5b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在 AI 社区中，Zalando 研究团队还因发布 Fashion-MNIST 而闻名，这是 Zalando 文章图像的数据集，旨在取代机器学习研究中的传统 MNIST 数据集。最近他们发布了另一个有趣的数据集:<a class="ae ky" href="https://github.com/zalandoresearch/feidegger" rel="noopener ugc nofollow" target="_blank"><strong class="lb iu"/></a>。由服装图像和相关文本描述组成的数据集。和前一个一样，Zalando 将这些数据捐赠给了研究社区，以试验各种文本图像任务，如字幕和图像检索。</p><p id="0b45" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在这篇文章中，我利用这些数据来构建:</p><ul class=""><li id="d4e0" class="lv lw it lb b lc ld lf lg li lx lm ly lq lz lu ma mb mc md bi translated">基于图像相似度的<strong class="lb iu">服装推荐系统</strong>；</li><li id="7e6c" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated">仅基于文本描述的<strong class="lb iu">服装标签系统</strong>。</li></ul><h1 id="9346" class="mj mk it bd ml mm mn mo mp mq mr ms mt jz mu ka mv kc mw kd mx kf my kg mz na bi translated">数据集</h1><blockquote class="nb nc nd"><p id="4054" class="kz la ne lb b lc ld ju le lf lg jx lh nf lj lk ll ng ln lo lp nh lr ls lt lu im bi translated">该数据集本身由 8732 幅高分辨率图像组成，每幅图像都描绘了 Zalando 商店出售的一件白色背景的裙子。为每张图片提供了五个德语文本注释，每个注释都是由单独的用户生成的。下面的例子显示了一件衣服的 5 个描述中的 2 个(英文翻译仅用于说明，但不是数据集的一部分)。</p></blockquote><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ni"><img src="../Images/74073b6402ee82ab5cbfcb61db0ed65e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*vmrVMvXAxhYGJrDAfLvY5g.png"/></div></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk">source <a class="ae ky" href="https://github.com/zalandoresearch/feidegger" rel="noopener ugc nofollow" target="_blank">Zalando</a></figcaption></figure><p id="b6da" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在开始时，数据集为每个单一描述存储相关图像(以 URL 格式):我们为单一服装加上条目。我们开始合并同一件衣服的描述，以方便操作图像并减少重复。</p><pre class="kj kk kl km gt nj nk nl nm aw nn bi"><span id="87e4" class="no mk it nk b gy np nq l nr ns">data = pd.read_csv('./FEIDEGGER.csv').fillna(' ')<br/>newdata = data.groupby('Image URL')['Description'].apply(lambda x: x.str.cat(sep=' ')).reset_index()</span></pre><h1 id="ac8c" class="mj mk it bd ml mm mn mo mp mq mr ms mt jz mu ka mv kc mw kd mx kf my kg mz na bi translated">服装推荐系统</h1><p id="caca" class="pw-post-body-paragraph kz la it lb b lc nt ju le lf nu jx lh li nv lk ll lm nw lo lp lq nx ls lt lu im bi translated">为了建立我们的服装推荐系统，我们利用了迁移学习。具体来说，我们利用预训练的 VGG16 从我们的服装图像中提取相关特征，并在其上建立相似性得分。</p><pre class="kj kk kl km gt nj nk nl nm aw nn bi"><span id="12f7" class="no mk it nk b gy np nq l nr ns">vgg_model = vgg16.VGG16(weights='imagenet')<br/>feat_extractor = Model(inputs=vgg_model.input, outputs=vgg_model.get_layer("fc2").output)</span></pre><p id="f095" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们在倒数第二层“切割”VGG，因此我们为每一幅图像获得一个维度为 1x4096 的向量。在此过程结束时，我们可以在 2D 空间中绘制我们的所有特征:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ny"><img src="../Images/25911fbef0e53fb97059a6d954a384c3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*11x96WrEgqzMiWoOEiaVxA.png"/></div></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk">TSNE on VGG features</figcaption></figure><p id="e44a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">为了测试我们系统的良好性，我们保留了一部分衣服(大约 10%)。其余部分用于构建相似性得分矩阵。我们选择余弦相似度作为相似度得分。每次我们向系统传递一幅服装图像时，我们都会计算所有存储在“train”中的服装的相似度，然后选择最相似的(相似度得分最高的)。</p><pre class="kj kk kl km gt nj nk nl nm aw nn bi"><span id="7854" class="no mk it nk b gy np nq l nr ns">sim = cosine_similarity(train, test[test_id].reshape(1,-1))</span></pre><p id="d73e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在这里，我报告一些例子，其中“原始”图像是来自测试集的服装图像。右边的服装是 5 件最相似的，指的是我们之前看过的“原始”服装。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nz"><img src="../Images/095d8f2d078d24cb5dd92d4bbc247007.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*NKkk3VEoSTkMYJYbyRjT7w.png"/></div></div></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nz"><img src="../Images/97838436419a6ba849a6be5cb9f2ab83.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*EqSbKL2utiAb9UGniRcARQ.png"/></div></div></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nz"><img src="../Images/a9e78f7d525fc8cbf0522aa46de0d109.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*smrBNkXZjbFA34cu0LY9lw.png"/></div></div></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nz"><img src="../Images/350563094e4cb8f9cd6d93ce891f3799.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*D8AlF2DjS5uwKFgXxn5aKQ.png"/></div></div></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nz"><img src="../Images/2337c93b2a4775d8cb890d6b8f7f4560.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*B2Rr0j8AcDlfppdFf32ugQ.png"/></div></div></figure><p id="4199" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">还不错！VGG 是非常强大的，做得非常好！</p><h1 id="d900" class="mj mk it bd ml mm mn mo mp mq mr ms mt jz mu ka mv kc mw kd mx kf my kg mz na bi translated">服装标签系统</h1><p id="9c04" class="pw-post-body-paragraph kz la it lb b lc nt ju le lf nu jx lh li nv lk ll lm nw lo lp lq nx ls lt lu im bi translated">我们开发服装标签系统所遵循的方法不同于前面的服装相似性方法。这个场景也不同于传统的标签问题，在传统的标签问题中，我们有图像和单个单词形式的相关标签。这里我们只有服装的文字描述，我们必须从中提取信息。这有点棘手，因为我们必须分析人类写的自由文本。我们的想法是从描述中提取最重要的词，以便将它们用作图像的标签。</p><p id="4774" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">下图总结了我们的工作流程:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oa"><img src="../Images/d4a18ec80adbb7d27751c9e8afc5201b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Tg_8cqot4ebZvMQeZQ6__g.png"/></div></div></figure><p id="bd4a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">图像描述是用基本的德语写的……<em class="ne">Zum GLüCK spreche Ich wenig Deutsch</em>(希望我会说一点德语)，所以我决定用德语工作，如果有困难，请谷歌翻译。</p><p id="6335" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们的想法是开发两种不同的模型；一个是名词，另一个是形容词。为了进行这种分离，我们首先在原始数据集的图像描述上进行词性标注。</p><pre class="kj kk kl km gt nj nk nl nm aw nn bi"><span id="8535" class="no mk it nk b gy np nq l nr ns">tokenizer = nltk.tokenize.RegexpTokenizer(r'[a-zA-ZäöüßÄÖÜ]+')<br/>nlp = spacy.load('de_core_news_sm')</span><span id="e160" class="no mk it nk b gy ob nq l nr ns">def clean(txt):<br/>    text = tokenizer.tokenize(txt)<br/>    text = nlp(" ".join(text))<br/>    adj, noun = [], []<br/>    for token in text:<br/>        if token.pos_ == 'ADJ' and len(token)&gt;2:<br/>            adj.append(token.lemma_)<br/>        elif token.pos_ in ['NOUN','PROPN'] and len(token)&gt;2: <br/>            noun.append(token.lemma_)            <br/>    return " ".join(adj).lower(), " ".join(noun).lower()</span><span id="a399" class="no mk it nk b gy ob nq l nr ns">adj, noun = zip(*map(clean,tqdm(data['Description'])))</span></pre><p id="4a29" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们把所有的形容词组合起来后，指的是同一个意象(名词也是如此)。</p><pre class="kj kk kl km gt nj nk nl nm aw nn bi"><span id="5102" class="no mk it nk b gy np nq l nr ns">newdata = data.groupby(‘Image URL’)[‘adj_Description’].apply(lambda x: x.str.cat(sep=’ XXX ‘)).reset_index()</span></pre><p id="ddf5" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在这一点上，为了提取每个图像的有意义的标签，我们应用 TFIDF 并基于这个分数获得最重要的形容词/名词(我们已经选择了 3 个最好的形容词/名词。如果没有找到单词，则返回一系列‘XXX’只是为了提高效率)。我还计算出一系列要排除的模糊形容词/名词。</p><pre class="kj kk kl km gt nj nk nl nm aw nn bi"><span id="021a" class="no mk it nk b gy np nq l nr ns">def tagging(comments, remove=None, n_word=3):<br/>    <br/>    comments = comments.split('XXX')<br/>    try:<br/>        counter = TfidfVectorizer(min_df=2, analyzer='word', stop_words=remove)<br/>        counter.fit(comments)<br/>        score = counter.transform(comments).toarray().sum(axis=0)<br/>        word = counter.get_feature_names()<br/>        vocab = pd.DataFrame({'w':word,'s':score}).sort_values('s').tail(n_word)['w'].values<br/>        return  " ".join(list(vocab)+['xxx']*(n_word-len(vocab)))<br/>    except:<br/>        return  " ".join(['xxx']*n_word)</span></pre><p id="624a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">对于每件衣服，我们最终最多有 3 个形容词和 3 个名词…我们已经准备好建立我们的模型了！</p><p id="2287" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">为了填充我们的模型，我们利用了以前使用的特征，这些特征是用 VGG 提取的。在我们的例子中，每件衣服最多出现 3 次，最多有 3 个不同的标签(指 3 个不同的形容词/名词)。我们使用的模型非常简单，具有相同的结构，如下所示:</p><pre class="kj kk kl km gt nj nk nl nm aw nn bi"><span id="d2ea" class="no mk it nk b gy np nq l nr ns">inp = Input(shape=(4096, ))<br/>dense1 = Dense(256, activation='relu')(inp)<br/>dense2 = Dense(128, activation='relu')(dense1)<br/>drop = Dropout(0.5)(dense2)<br/>dense3 = Dense(64, activation='relu')(drop)<br/>out = Dense(y.shape[1], activation='softmax')(dense3)</span><span id="2c7e" class="no mk it nk b gy ob nq l nr ns">model = Model(inputs=inp, outputs=out)<br/>model.compile(optimizer='adam', loss='categorical_crossentropy')</span></pre><p id="4296" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">来看看成果吧！</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oc"><img src="../Images/b70ee71b8dc44e073af2cbb9801657e2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*K_PnDat6AB319yOMFBl92w.png"/></div></div></figure><p id="4c3e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们在以前的相同服装上测试我们的模型，并绘制出前两个概率最高的标签，用于形容词和名词(我也提供翻译)。成绩很棒！总的来说，我们的模特能够很好地描述图片中的服装。</p><h1 id="8c2d" class="mj mk it bd ml mm mn mo mp mq mr ms mt jz mu ka mv kc mw kd mx kf my kg mz na bi translated">摘要</h1><p id="e4da" class="pw-post-body-paragraph kz la it lb b lc nt ju le lf nu jx lh li nv lk ll lm nw lo lp lq nx ls lt lu im bi translated">在这篇文章中，我们利用迁移学习直接开发了一个基于内容的推荐系统。在第二阶段，我们尝试标记服装，仅从文本描述中提取信息。取得的效果非常漂亮，易于观察，还能为你更新衣柜提供建议。</p></div><div class="ab cl od oe hx of" role="separator"><span class="og bw bk oh oi oj"/><span class="og bw bk oh oi oj"/><span class="og bw bk oh oi"/></div><div class="im in io ip iq"><p id="7caf" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><a class="ae ky" href="https://github.com/cerlymarco/MEDIUM_NoteBook" rel="noopener ugc nofollow" target="_blank"> <strong class="lb iu">查看我的 GITHUB 回购</strong> </a></p><p id="6604" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">保持联系:<a class="ae ky" href="https://www.linkedin.com/in/marco-cerliani-b0bba714b/" rel="noopener ugc nofollow" target="_blank"> Linkedin </a></p></div></div>    
</body>
</html>