<html>
<head>
<title>Probabilistic tools for Privacy in Data Analysis</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">数据分析中隐私的概率工具</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/probabilistic-tools-for-privacy-in-data-analysis-a715ec5ac25c?source=collection_archive---------35-----------------------#2019-07-30">https://towardsdatascience.com/probabilistic-tools-for-privacy-in-data-analysis-a715ec5ac25c?source=collection_archive---------35-----------------------#2019-07-30</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><figure class="ip iq gp gr ir is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi io"><img src="../Images/ce30c720287b549b869e26eced812701.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*acUYm6Xmr6BMi45g"/></div></div><figcaption class="iz ja gj gh gi jb jc bd b be z dk">Photo by <a class="ae jd" href="https://unsplash.com/@srd844?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Stephen Dawson</a> on <a class="ae jd" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><div class=""/><div class=""><h2 id="1a8b" class="pw-subtitle-paragraph kd jf jg bd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku dk translated">我们将继续我们的旅程来学习差分私有算法，这一次探索更多的概率工具。</h2></div><p id="1220" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">在上一篇文章中，我们学习了如何使用大数理论和概率来设计差分私有算法。</p><p id="1820" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">我鼓励您在继续学习之前查看一下，以便更好地理解本教程的范围。</p><div class="ip iq gp gr ir lr"><a rel="noopener follow" target="_blank" href="/a-coin-some-smokers-and-privacy-in-data-analysis-1339b83ede74"><div class="ls ab fo"><div class="lt ab lu cl cj lv"><h2 class="bd jh gy z fp lw fr fs lx fu fw jf bi translated">一枚硬币、一些吸烟者和数据分析中的隐私</h2><div class="ly l"><h3 class="bd b gy z fp lw fr fs lx fu fw dk translated">我们将继续探索学习隐私保护数据分析的技术，更深入地挖掘…</h3></div><div class="lz l"><p class="bd b dl z fp lw fr fs lx fu fw dk translated">towardsdatascience.com</p></div></div><div class="ma l"><div class="mb l mc md me ma mf ix lr"/></div></div></a></div><p id="6765" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">如果您阅读了本系列的上一篇文章，您已经知道任何随机化算法 M 都可以是(<strong class="kx jh"> ε，δ)差分私有算法，</strong>，如果它满足这样的性质。</p><p id="ddff" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">这种方法的核心特性之一是在进行任何分析之前，甚至在将数据放入数据库之前，向数据本身注入噪声。像这样给数据引入随机性在隐私保护数据分析中相当常见，事实上它有一个专门的名字叫做<strong class="kx jh">局部差分隐私。</strong></p><figure class="mh mi mj mk gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi mg"><img src="../Images/82d37c66c5583daaa1cc064340dd5df9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*EOG9BJVDo93f4MwR"/></div></div><figcaption class="iz ja gj gh gi jb jc bd b be z dk">Photo by <a class="ae jd" href="https://unsplash.com/@franki?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Franki Chamaki</a> on <a class="ae jd" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><blockquote class="ml mm mn"><p id="447a" class="kv kw mo kx b ky kz kh la lb lc kk ld mp lf lg lh mq lj lk ll mr ln lo lp lq ij bi translated">然而，仅仅为了防止数据被对手窃取而破坏我们的数据的想法听起来非常妥协。一定有别的办法。</p></blockquote><p id="96f9" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">此时我们应该想到的两个问题是:</p><ul class=""><li id="41c5" class="ms mt jg kx b ky kz lb lc le mu li mv lm mw lq mx my mz na bi translated">本地差分隐私是防止隐私数据泄露的唯一方法吗，有什么方法可以在不损坏我们数据的情况下提供隐私？</li><li id="907d" class="ms mt jg kx b ky nb lb nc le nd li ne lm nf lq mx my mz na bi translated">除了随机化回答，还有其他算法可以解决这个保护隐私的数据分析问题吗？</li></ul><p id="f34d" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">我们将在本文中尝试解决这两个问题。</p></div><div class="ab cl ng nh hu ni" role="separator"><span class="nj bw bk nk nl nm"/><span class="nj bw bk nk nl nm"/><span class="nj bw bk nk nl"/></div><div class="ij ik il im in"><h1 id="ed89" class="nn no jg bd np nq nr ns nt nu nv nw nx km ny kn nz kp oa kq ob ks oc kt od oe bi translated">全球差异隐私—简介:</h1><p id="0bf1" class="pw-post-body-paragraph kv kw jg kx b ky of kh la lb og kk ld le oh lg lh li oi lk ll lm oj lo lp lq ij bi translated">我们已经知道，在局部差分隐私的情况下，我们向输入数据点添加噪声。因此，每个人都可以向自己的数据中添加噪声，从而完全消除了信任数据所有者或管理者的需要。<strong class="kx jh">我们可以说，在这种环境下，个人隐私得到了最大程度的保护。</strong></p><p id="e22a" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated"><strong class="kx jh">另一方面，全局差分隐私</strong>给数据库的查询输出增加了<strong class="kx jh">噪声。因此，在这种情况下，我们有一个包含所有敏感信息的数据库，但是对该数据库的任何查询都不一定会生成真实的结果，因为这些结果是错误的。</strong></p><blockquote class="ok"><p id="131b" class="ol om jg bd on oo op oq or os ot lq dk translated">但是，如果局部差异隐私更能保护个人隐私信息，为什么还要使用全局差异隐私呢？</p></blockquote><p id="a66e" class="pw-post-body-paragraph kv kw jg kx b ky ou kh la lb ov kk ld le ow lg lh li ox lk ll lm oy lo lp lq ij bi translated">如果你还记得上一篇文章，你应该知道，准确性和隐私之间总是有一个权衡。因此，如果你的目标是更多的隐私，它会来找你，但代价是失去一些准确性。考虑到这一点，本地和全局差异隐私的唯一区别在于:</p><blockquote class="ml mm mn"><p id="ceaa" class="kv kw mo kx b ky kz kh la lb lc kk ld mp lf lg lh mq lj lk ll mr ln lo lp lq ij bi translated"><strong class="kx jh">如果数据所有者值得信任，那么对于相同级别的隐私保护，全局差异隐私会产生更准确的结果。</strong></p></blockquote><p id="4170" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated"><strong class="kx jh">一个重要的问题是要有一个值得信赖的所有者或管理者，</strong>如果找到了，我们就可以在相同的隐私级别上有更好的准确性，因为在全球差异隐私的设置中，我们不再破坏我们的数据，而是将所需的噪声添加到我们对该数据库的查询的输出中。</p><figure class="mh mi mj mk gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi oz"><img src="../Images/5db740913e01eba91d0fc1a7accbecb2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*uC8yzu_fMja8GLJW_Kg3hw.png"/></div></div><figcaption class="iz ja gj gh gi jb jc bd b be z dk">Difference b/w Local and Global Privacy Settings</figcaption></figure><p id="4aad" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">上面给出的图表毫不费力地解释了这一点。然而，我们现有的保护隐私的方法没有为应用全局差分隐私提供空间，因此我们需要设计一种不同的算法来做到这一点。</p><h1 id="a697" class="nn no jg bd np nq pa ns nt nu pb nw nx km pc kn nz kp pd kq ob ks pe kt od oe bi translated">保护隐私的拉普拉斯机制:</h1><p id="a8ec" class="pw-post-body-paragraph kv kw jg kx b ky of kh la lb og kk ld le oh lg lh li oi lk ll lm oj lo lp lq ij bi translated">在上一篇文章中，我们了解了一种实现差分隐私的技术，我们设计的算法给了数据生成器一种<strong class="kx jh"> <em class="mo">似是而非的可否认性</em> </strong>的感觉，从而允许它们向数据中添加噪声。</p><p id="be40" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">在这里，我们将了解一个更常用的工具，它为我们提供差分隐私，<strong class="kx jh">拉普拉斯机制，</strong>，它为实(向量)值查询提供差分隐私。这些查询将数据库映射到一些实数，而不是整数值。</p><p id="f66c" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated"><strong class="kx jh"> ℓ1-敏感度</strong>可以再次用于确定我们可以多准确地回答数据库的查询，因此，直观地，我们必须引入响应中的不确定性以隐藏单个个体的参与。因此，拉普拉斯机制帮助我们在全局差分隐私的设置下保护隐私。</p><figure class="mh mi mj mk gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi pf"><img src="../Images/3be5e15e6dc18a9033880b82ca152949.png" data-original-src="https://miro.medium.com/v2/resize:fit:1270/format:webp/1*CSpLTJmgzNOkNi9Ew-envg.png"/></div></div></figure><p id="239f" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">函数(查询)的敏感度也告诉我们，为了保护隐私，我们必须对其输出进行多大程度的扰动，它为我们提供了查询输出中最大可能变化的度量。拉普拉斯机制将简单地计算<strong class="kx jh"> func </strong>，并用从拉普拉斯分布中提取的噪声扰动每个坐标。噪声的标度将被校准到<strong class="kx jh"> func </strong>的灵敏度(除以<strong class="kx jh"> ε </strong>，这被称为<strong class="kx jh">β。</strong></p><p id="6dbf" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated"><strong class="kx jh">β= Lap(δf/ε)</strong></p><figure class="mh mi mj mk gt is gh gi paragraph-image"><div class="gh gi pg"><img src="../Images/711778c9efa577969813116c2cd3922d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1238/format:webp/1*79EPd2KHzxfPe9rxaDvJLQ.png"/></div><figcaption class="iz ja gj gh gi jb jc bd b be z dk">From the Algorithmic Foundation of Diff. Privacy</figcaption></figure><figure class="mh mi mj mk gt is gh gi paragraph-image"><div class="gh gi ph"><img src="../Images/ea41de5ce9349591f25b25b1d0e4296c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1234/format:webp/1*4cHv4nxx09fzT-aJC2fYhA.png"/></div><figcaption class="iz ja gj gh gi jb jc bd b be z dk">Formalizing Laplace mechanism</figcaption></figure><blockquote class="ml mm mn"><p id="62b2" class="kv kw mo kx b ky kz kh la lb lc kk ld mp lf lg lh mq lj lk ll mr ln lo lp lq ij bi translated"><strong class="kx jh"> <em class="jg">因此，在拉普拉斯机制的情况下，不是在查询之前将噪声添加到数据，而是将该噪声添加到对数据库的查询的输出。拉普拉斯机制只是简单地把对称连续分布的噪声加到真答案上，如上图所示。</em>T25】</strong></p></blockquote><figure class="mh mi mj mk gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi pi"><img src="../Images/98d4c56ffe95960fcfca1cc14daba02c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*1FB4JONwuZXqf-p3"/></div></div><figcaption class="iz ja gj gh gi jb jc bd b be z dk">Photo by <a class="ae jd" href="https://unsplash.com/@markusspiske?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Markus Spiske</a> on <a class="ae jd" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><p id="1cff" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">这里需要理解的重要一点是，在拉普拉斯机制的情况下，这种对称连续分布以零为中心。</p><p id="fb08" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">辛西娅·德沃克(Cynthia Dwork)的《差分隐私算法基础》( algorithm Foundation of Differential Privacy)中提供了为什么拉普拉斯机制是(<strong class="kx jh"> ε，0)差分隐私算法</strong>的有力证明。</p></div><div class="ab cl ng nh hu ni" role="separator"><span class="nj bw bk nk nl nm"/><span class="nj bw bk nk nl nm"/><span class="nj bw bk nk nl"/></div><div class="ij ik il im in"><h1 id="b2ea" class="nn no jg bd np nq nr ns nt nu nv nw nx km ny kn nz kp oa kq ob ks oc kt od oe bi translated">总结:</h1><p id="eb93" class="pw-post-body-paragraph kv kw jg kx b ky of kh la lb og kk ld le oh lg lh li oi lk ll lm oj lo lp lq ij bi translated">在本文中，我们了解了局部和全局差分隐私之间的差异，并介绍了一种使用后者的设置来实现差分隐私的算法。</p><p id="ce64" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">本系列接下来的几篇文章将更侧重于使用差分隐私进行深度学习。</p><p id="37b3" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">敬请关注。暂时快乐学习。</p><p id="1288" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">PS。这是我关于媒体的第三篇文章，所以欢迎任何反馈和建议。</p><p id="f034" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated"><strong class="kx jh">资源:</strong></p><ol class=""><li id="4b3f" class="ms mt jg kx b ky kz lb lc le mu li mv lm mw lq pj my mz na bi translated">https://www.cis.upenn.edu/~aaroth/Papers/privacybook.pdf<a class="ae jd" href="https://www.cis.upenn.edu/~aaroth/Papers/privacybook.pdf?source=post_page---------------------------" rel="noopener ugc nofollow" target="_blank"/></li><li id="24b9" class="ms mt jg kx b ky nb lb nc le nd li ne lm nf lq pj my mz na bi translated">【http://www.cis.upenn.edu/~ahae/papers/epsilon-csf2014.pdf T4】</li><li id="9fcd" class="ms mt jg kx b ky nb lb nc le nd li ne lm nf lq pj my mz na bi translated"><a class="ae jd" href="http://dimacs.rutgers.edu/~graham/pubs/slides/privdb-tutorial.pdf" rel="noopener ugc nofollow" target="_blank">http://dimacs . Rutgers . edu/~ Graham/pubs/slides/priv db-tutorial . pdf</a></li><li id="ee14" class="ms mt jg kx b ky nb lb nc le nd li ne lm nf lq pj my mz na bi translated"><a class="ae jd" href="https://arxiv.org/pdf/1808.10410.pdf" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/pdf/1808.10410.pdf</a></li><li id="6b71" class="ms mt jg kx b ky nb lb nc le nd li ne lm nf lq pj my mz na bi translated"><a class="ae jd" rel="noopener" target="_blank" href="/understanding-differential-privacy-85ce191e198a">https://towards data science . com/understanding-differential-privacy-85ce 191 e 198 a</a></li><li id="a951" class="ms mt jg kx b ky nb lb nc le nd li ne lm nf lq pj my mz na bi translated"><a class="ae jd" rel="noopener" target="_blank" href="/a-coin-some-smokers-and-privacy-in-data-analysis-1339b83ede74">https://towards data science . com/a-coin-some-smokers-and-privacy-in-data-analysis-1339 b 83 ede 74</a></li><li id="00b9" class="ms mt jg kx b ky nb lb nc le nd li ne lm nf lq pj my mz na bi translated"><a class="ae jd" rel="noopener" target="_blank" href="/mr-x-netflix-and-privacy-in-data-analysis-f59227d50f45">https://towards data science . com/Mr-x-网飞和数据分析隐私-f59227d50f45 </a></li></ol></div></div>    
</body>
</html>