# åˆ†ç±»

> åŸæ–‡ï¼š<https://towardsdatascience.com/apache-spark-mllib-tutorial-part-3-complete-classification-workflow-a1eb430ad069?source=collection_archive---------15----------------------->

## Apache Spark ML æ•™ç¨‹

## æ„å»ºå®Œæ•´çš„åˆ†ç±»å·¥ä½œæµç¨‹

æ³¨æ„:æœ¬æ–‡æ˜¯ç³»åˆ—æ–‡ç« çš„ä¸€éƒ¨åˆ†ã€‚æŸ¥çœ‹å®Œæ•´ç³»åˆ—: [*ç¬¬ 1 éƒ¨åˆ†:å›å½’*](/apache-spark-mllib-tutorial-ec6f1cb336a9) *ï¼Œ* [*ç¬¬ 2 éƒ¨åˆ†:ç‰¹å¾è½¬åŒ–*](/apache-spark-mllib-tutorial-7aba8a1dce6e) *ï¼Œ* ***ç¬¬ 3 éƒ¨åˆ†:åˆ†ç±»*** *ï¼Œç¬¬ 4 éƒ¨åˆ†åŠä»¥ä¸Šå³å°†æ¨å‡ºã€‚*

![](img/41b76e34e040b64dca853e6d41434b7a.png)

Image by [pixel2013](https://pixabay.com/users/pixel2013-2364555/?utm_source=link-attribution&utm_medium=referral&utm_campaign=image&utm_content=3401500) from [Pixabay](https://pixabay.com/)

# ä»‹ç»

åœ¨è¿™ä¸ªç³»åˆ—çš„è¿™ä¸€éƒ¨åˆ†ä¸­ï¼Œæˆ‘ä»¬å°†æŠŠæˆ‘ä»¬æ‰€å­¦çš„ä¸€åˆ‡æ”¾åœ¨ä¸€èµ·è®­ç»ƒä¸€ä¸ª**åˆ†ç±»æ¨¡å‹**ã€‚ç›®æ ‡æ˜¯å­¦ä¹ å¦‚ä½•ä»å¤´åˆ°å°¾å»ºç«‹ä¸€ä¸ªå®Œæ•´çš„åˆ†ç±»å·¥ä½œæµç¨‹ã€‚

# é—®é¢˜å®šä¹‰

æˆ‘ä»¬è¦è§£å†³çš„é—®é¢˜æ˜¯è‡­åæ˜­è‘—çš„ [*æ³°å¦å°¼å…‹å·ç”Ÿå­˜é—®é¢˜*](https://www.kaggle.com/c/titanic) ã€‚æˆ‘ä»¬è¢«è¦æ±‚å»ºç«‹ä¸€ä¸ªæœºå™¨å­¦ä¹ æ¨¡å‹ï¼Œè¯¥æ¨¡å‹è·å–ä¹˜å®¢ä¿¡æ¯ï¼Œå¹¶é¢„æµ‹ä»–/å¥¹æ˜¯å¦å¹¸å­˜ã€‚æ•°æ®é›†åŒ…å« 12 åˆ—ï¼Œæè¿°å¦‚ä¸‹:[ä»[è¿™é‡Œ](https://drive.google.com/open?id=1wI5UtWvoE_n9bvX8nMSp3v6tWr4NRb22)ä¸‹è½½]

![](img/26cc29f5158acbf40d2655f5c6006069.png)

# å‡†å¤‡å¼€å‘ç¯å¢ƒ

ä½ ç°åœ¨åº”è¯¥å¾ˆç†Ÿæ‚‰è¿™ä¸€æ­¥äº†ã€‚æˆ‘ä»¬å°†æ‰“å¼€ä¸€ä¸ªæ–°çš„ *Jyputer ç¬”è®°æœ¬*ï¼Œå¯¼å…¥å¹¶åˆå§‹åŒ– *findspark* ï¼Œåˆ›å»º *spark ä¼šè¯*ï¼Œæœ€å*åŠ è½½*æ•°æ®ã€‚

```
import findspark
findspark.init('/opt/spark')
from pyspark.sql import SparkSession
spark = SparkSession.builder.getOrCreate()
data = spark.read.csv('./datasets/titanic.csv', inferSchema=True, header=True)
```

è®©æˆ‘ä»¬çœ‹çœ‹æ•°æ®åŠå…¶ç»Ÿè®¡:

![](img/9be7d1a5a217d67c8e98f94218944d41.png)

Top 20 rows of the dataset

![](img/cc98c146c3e663d64f336a75bb3c0e6a.png)

Statistics

ä¸‹é¢æ˜¯ä¸€ä¸ªå…³äºæŸäººå¦‚ä½•é€šè¿‡åˆ†æä¸Šè¿°è¡¨æ ¼æ¥é€‰æ‹©/æ›´æ–°å…¶ç‰¹å¾çš„ç¤ºä¾‹:

*   åŒ…å«ä¸€äº›åŠŸèƒ½æ˜¯æ²¡æœ‰æ„ä¹‰çš„ï¼Œä¾‹å¦‚:*ä¹˜å®¢ ID* ã€*å§“å*å’Œ*è½¦ç¥¨* â†’æˆ‘ä»¬å°†åˆ é™¤å®ƒä»¬
*   *å°å±‹*æœ‰å¾ˆå¤šç©ºå€¼â†’æˆ‘ä»¬ä¹Ÿä¼šåˆ é™¤å®ƒ
*   ä¹Ÿè®¸*ç™»ä¸Š*æŸ±ä¸ç”Ÿå­˜æ— å…³â†’è®©æˆ‘ä»¬ç§»é™¤å®ƒ
*   æˆ‘ä»¬åœ¨*å¹´é¾„*åˆ—ä¸­ç¼ºå°‘ 177 ä¸ªå€¼â†’ *å¹´é¾„*å¾ˆé‡è¦ï¼Œæˆ‘ä»¬éœ€è¦æ‰¾åˆ°ä¸€ç§æ–¹æ³•æ¥å¤„ç†ç¼ºå°‘çš„å€¼
*   *æ€§åˆ«*æœ‰æ ‡ç§°å€¼â†’éœ€è¦ç¼–ç 

è®©æˆ‘ä»¬è¿‡æ»¤æ‰ä¸éœ€è¦çš„åˆ—:

```
data = data.select(['Survived', 'Pclass', 'Gender', 'Age', 'SibSp', 'Parch', 'Fare'])
```

# ç‰¹å¾è½¬æ¢

æˆ‘ä»¬å°†é€ä¸ªå¤„ç†è½¬æ¢ã€‚åœ¨ä»¥åçš„æ–‡ç« ä¸­ï¼Œæˆ‘å°†è®¨è®ºå¦‚ä½•ä½¿ç”¨**ç®¡é“æ¥æ”¹è¿›è¿™ä¸ªè¿‡ç¨‹ã€‚ä½†æ˜¯è®©æˆ‘ä»¬å…ˆç”¨æ— èŠçš„æ–¹æ³•æ¥åšã€‚**

## è®¡ç®—å¹´é¾„ç¼ºå¤±å€¼

*å¹´é¾„*æ˜¯é‡è¦ç‰¹å¾ï¼›å› ä¸ºä¸€äº›ç¼ºå¤±çš„å€¼è€Œä¸¢å¼ƒå®ƒæ˜¯ä¸æ˜æ™ºçš„ã€‚æˆ‘ä»¬èƒ½åšçš„æ˜¯åœ¨ç°æœ‰ä»·å€¼çš„å¸®åŠ©ä¸‹å¡«è¡¥ç¼ºå¤±çš„ä»·å€¼ã€‚è¿™ä¸ªè¿‡ç¨‹è¢«ç§°ä¸º**æ•°æ®æ’è¡¥**ã€‚æœ‰è®¸å¤šå¯ç”¨çš„ç­–ç•¥ï¼Œä½†æˆ‘ä»¬å°†éµå¾ªä¸€ä¸ªç®€å•çš„ç­–ç•¥ï¼Œç”¨ä»æ ·æœ¬ä¸­è®¡ç®—å‡ºçš„*å¹³å‡å€¼*æ¥å¡«å……ç¼ºå¤±å€¼ã€‚

ä½¿ç”¨**ä¼°ç®—å™¨**ç±»ï¼ŒSpark ML ä½¿è¿™é¡¹å·¥ä½œå˜å¾—ç®€å•ã€‚é¦–å…ˆï¼Œæˆ‘ä»¬å®šä¹‰ä¼°è®¡é‡ï¼Œä½¿å…¶é€‚åˆæ¨¡å‹ï¼Œç„¶åæˆ‘ä»¬å¯¹æ•°æ®åº”ç”¨è½¬æ¢å™¨ã€‚

```
from pyspark.ml.feature import Imputer
imputer = Imputer(strategy='mean', inputCols=['Age'], outputCols=['AgeImputed'])
imputer_model = imputer.fit(data)
data = imputer_model.transform(data)
```

![](img/a625e97a6be9612649cd7544b70e6cdc.png)

ä¸å†æœ‰ç¼ºå¤±å€¼ï¼è®©æˆ‘ä»¬ç»§ç»­ä¸‹ä¸€æ­¥â€¦

## æ€§åˆ«ä»·å€¼è§‚ç¼–ç 

æˆ‘ä»¬äº†è§£åˆ°æœºå™¨å­¦ä¹ ç®—æ³•æ— æ³•å¤„ç†åˆ†ç±»ç‰¹å¾ã€‚æ‰€ä»¥ï¼Œæˆ‘ä»¬éœ€è¦ç´¢å¼•*æ€§åˆ«*å€¼:

```
from pyspark.ml.feature import StringIndexer
gender_indexer = StringIndexer(inputCol='Gender', outputCol='GenderIndexed')
gender_indexer_model = gender_indexer.fit(data)
data = gender_indexer_model.transform(data)
```

![](img/836a1473f59aa6dabd56520f358f5ba4.png)

æ²¡æœ‰æ›´å¤šçš„åˆ†ç±»å€¼â€¦æ³¨æ„ï¼Œæˆ‘ä»¬ä¸éœ€è¦å¯¹ç´¢å¼•å€¼è¿›è¡Œä¸€æ¬¡çƒ­ç¼–ç ï¼Œå®ƒä»¬è‡ªç„¶æ˜¯ç”¨ 0 å’Œ 1 å€¼è¿›è¡ŒäºŒè¿›åˆ¶ç¼–ç çš„ã€‚

## åˆ›å»ºç‰¹å¾å‘é‡

æˆ‘ä»¬ä¹‹å‰äº†è§£åˆ° *Spark ML* æœŸæœ›æ•°æ®åœ¨ä¸¤åˆ—ä¸­è¡¨ç¤º:ä¸€ä¸ª*ç‰¹å¾å‘é‡*å’Œä¸€ä¸ª*æ ‡ç­¾åˆ—*ã€‚æˆ‘ä»¬å·²ç»å‡†å¤‡å¥½äº†*æ ‡ç­¾*åˆ—(*å¹¸å­˜*ï¼Œæ‰€ä»¥è®©æˆ‘ä»¬å‡†å¤‡*ç‰¹å¾å‘é‡*ã€‚

**æ³¨æ„ï¼Œæˆ‘ä»¬æ·»åŠ äº†*å¹´é¾„ä¼°ç®—*å’Œ*æ€§åˆ«ç´¢å¼•*ï¼Œè€Œä¸æ˜¯*å¹´é¾„*å’Œ*æ€§åˆ«*ã€‚**

```
from pyspark.ml.feature import VectorAssembler
assembler = VectorAssembler(inputCols=['Pclass', 'SibSp', 'Parch', 'Fare', 'AgeImputed', 'GenderIndexed'], outputCol='features')
data = assembler.transform(data)
```

![](img/ee6c9d4cae03598687ea39b376dbdb51.png)

æˆ‘ä»¬å‡†å¤‡å‡ºå‘äº†ï¼æœºå™¨å­¦ä¹ æ—¶é—´åˆ°äº†â€¦

# è®­ç»ƒæ¨¡å‹

å¯¹äºè¿™ä¸ªé—®é¢˜ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨ä¸€ä¸ª**éšæœºæ£®æ—åˆ†ç±»å™¨**ã€‚æ‚¨å¯ä»¥è‡ªç”±é€‰æ‹©ä»»ä½•å…¶ä»–æ‚¨è®¤ä¸ºåˆé€‚çš„åˆ†ç±»å™¨ã€‚

æ­¥éª¤:

1.  åˆ›å»ºè¯„ä¼°è€…
2.  æŒ‡å®šè¦ç´ åˆ—å’Œæ ‡æ³¨åˆ—çš„åç§°
3.  ç¬¦åˆæ¨¡å‹

```
from pyspark.ml.classification import RandomForestClassifier
algo = RandomForestClassifier(featuresCol='features', labelCol='Survived')
model = algo.fit(data)
```

æå®šäº†ã€‚

# ç”Ÿæˆé¢„æµ‹

æˆ‘ä»¬è°ƒç”¨æ¨¡å‹çš„å˜æ¢æ–¹æ³•æ¥è·å¾—æˆ‘ä»¬çš„é¢„æµ‹:

```
predictions = model.transform(data)
```

è®©æˆ‘ä»¬æ£€æŸ¥ä¸€ä¸‹é¢„æµ‹å€¼:

```
predictions.select(['Survived','prediction', 'probability']).show()
```

![](img/9a31044aa1c7be9b7f24e5c0243e6ae5.png)

åˆ°ç›®å‰ä¸ºæ­¢ä¸€åˆ‡é¡ºåˆ©ï¼Œä½†æ˜¯ä»”ç»†æ£€æŸ¥è®°å½•å¹¶é€ä¸€éªŒè¯è¿™äº›è®°å½•ä¸ç¬¦åˆé€»è¾‘ã€‚æˆ‘ä»¬éœ€è¦è®¡ç®—ä¸€äº›æŒ‡æ ‡æ¥è·å¾—æ¨¡å‹çš„æ•´ä½“æ€§èƒ½ã€‚**è¯„ä¼°æ—¶é—´â€¦**

# æ¨¡å‹è¯„ä¼°

æˆ‘ä»¬å°†ä½¿ç”¨ä¸€ä¸ª**binary classification evaluator**æ¥è¯„ä¼°æˆ‘ä»¬çš„æ¨¡å‹ã€‚å®ƒéœ€è¦çŸ¥é“*æ ‡ç­¾åˆ—çš„åç§°*å’Œ*å…¬åˆ¶åç§°*ã€‚è¿™é‡Œæˆ‘ä»¬å°†ä½¿ç”¨ ROC æ›²çº¿ ä¸‹çš„ [*åŒºåŸŸã€‚*](https://en.wikipedia.org/wiki/Receiver_operating_characteristic)

```
from pyspark.ml.evaluation import BinaryClassificationEvaluator
evaluator = BinaryClassificationEvaluator(labelCol='Survived', metricName='areaUnderROC')
```

è°ƒç”¨ evaluate æ–¹æ³•è·å¾—ç»“æœ:

```
evaluator.evaluate(predictions)
```

é€šè¿‡ä½¿ç”¨ä¸Šè¿°è®¾ç½®ï¼Œæˆ‘çš„è¯„ä¼°å™¨è¿”å›: **0.90**

é‰´äºæˆ‘ä»¬æ²¡æœ‰é…ç½®*é¢„å¤„ç†ç¨‹åº*ï¼Œæœ€åˆçš„ç»“æœæ˜¯æœ‰å¸Œæœ›çš„ã€‚æˆ‘çŸ¥é“æˆ‘æ²¡æœ‰æ ¹æ®æµ‹è¯•æ•°æ®è¿›è¡Œè¯„ä¼°ï¼Œä½†æˆ‘ç›¸ä¿¡ä½ èƒ½åšåˆ°ã€‚

# ä½¿ç”¨ SciKit-Learn è¿›è¡Œæ¨¡å‹è¯„ä¼°

å¦‚æœæ‚¨æƒ³ç”Ÿæˆå…¶ä»–è¯„ä¼°ï¼Œå¦‚æ··æ·†çŸ©é˜µæˆ–åˆ†ç±»æŠ¥å‘Šï¼Œæ‚¨æ€»æ˜¯å¯ä»¥ä½¿ç”¨ [scikit-learn åº“](https://scikit-learn.org)ã€‚

ä½ åªéœ€è¦ä»ä½ çš„æ•°æ®å¸§ä¸­æå– *y_true* å’Œ *y_pred* ã€‚åˆ«æ‹…å¿ƒï¼Œæˆ‘ä¼šå‘Šè¯‰ä½ æ€ä¹ˆåš:

```
y_true = predictions.select(['Survived']).collect()
y_pred = predictions.select(['prediction']).collect()
```

å¯¼å…¥æ‚¨çš„æŒ‡æ ‡:

```
from sklearn.metrics import classification_report, confusion_matrix
```

é€šè¿‡ä¼ é€’ *y_true* å’Œ *y_pred* è°ƒç”¨å‡½æ•°:

```
print(classification_report(y_true, y_pred))
```

![](img/78ceab2936f48497a92089831ed28892.png)

```
print(confusion_matrix(y_true, y_pred))
```

![](img/32a2a536a1b672c086fa85638667a841.png)

# æœ€åçš„æƒ³æ³•

æ­å–œä½ ã€‚æ‚¨å·²ç»æˆåŠŸå®Œæˆäº†å¦ä¸€ä¸ªæ•™ç¨‹ã€‚ä½ ç°åœ¨åº”è¯¥å¯¹è‡ªå·±çš„ *Spark ML* æŠ€èƒ½æ›´æœ‰ä¿¡å¿ƒäº†ã€‚åœ¨æœªæ¥çš„æ•™ç¨‹ä¸­ï¼Œæˆ‘ä»¬å°†é€šè¿‡ä½¿ç”¨ ***ç®¡é“*** æ¥æ”¹è¿›é¢„å¤„ç†é˜¶æ®µï¼Œæˆ‘å°†å‘æ‚¨å±•ç¤ºæ›´å¤šä»¤äººå…´å¥‹çš„ *Spark ML* ç‰¹æ€§ã€‚æ•¬è¯·å…³æ³¨â€¦

å¦‚æœä½ å–œæ¬¢è¿™ç¯‡æ–‡ç« ï¼Œè¯·ç‚¹å‡»â€œé¼“æŒâ€æŒ‰é’®ï¼Œæˆ‘å°†ä¸èƒœæ„Ÿæ¿€ğŸ‘æ‰€ä»¥å¯èƒ½ä¼šä¼ æŸ“ç»™ä»–äººã€‚ä¹Ÿå¯ä»¥åœ¨ [*æ¨ç‰¹*](https://twitter.com/alimasri1991) *ï¼Œ* [*è„¸ä¹¦*](https://www.facebook.com/alimasri91) *ï¼Œ* [*ä¸Šå…³æ³¨æˆ‘ç›´æ¥å‘é‚®ä»¶ç»™æˆ‘*](mailto:alimasri1991@gmail.com) *æˆ–è€…åœ¨*[*LinkedIn*](https://www.linkedin.com/in/alimasri/)*ä¸Šæ‰¾æˆ‘ã€‚*