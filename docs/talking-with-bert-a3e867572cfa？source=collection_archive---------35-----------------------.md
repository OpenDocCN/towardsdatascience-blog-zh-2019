# 与伯特交谈

> 原文：<https://towardsdatascience.com/talking-with-bert-a3e867572cfa?source=collection_archive---------35----------------------->

## 改进提示以更好地理解语言模型

![](img/875a2cf21b9836eef1f9d575bfe36172.png)

Photo Mashup w/ [Anna Vander Stel](https://unsplash.com/@ann_van_?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText) X [Rock’n Roll Monkey](https://unsplash.com/@rocknrollmonkey?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)

在过去的几年中，围绕语言模型的知识和研究的增长是惊人的。特别是对 BERT 来说，我们已经看到了这种大规模预训练语言模型在文本分类、预测和问题回答等任务中的一些令人难以置信的用途。[我最近写了](/bert-is-not-good-at-7b1ca64818c5)关于一些人如何研究 BERT 在执行某些语言任务时的局限性。此外，我自己做了一些测试，用[创建了一个问答系统](/bert-is-not-good-at-7b1ca64818c5)，来感受一下如何使用它。在实践中看到并尝试语言模型的许多功能是非常棒的。

当你认真对待它时，这些模型显然有很多关于单词和想法之间关系的信息，但很难真正检查它知道什么。我最近探索了一篇名为[的有趣论文，我们如何才能知道语言模型知道什么？](https://arxiv.org/abs/1911.12543)看看我们如何向语言模型提问。像任何语言一样，这不仅仅是你问什么的问题，而是你如何问的问题。

研究团队工作的主要目标是研究我们如何有效地从语言模型中提取知识。当我们想探究一个语言模型可能包含什么关系信息时，我们使用提示，比如“*柯基是一种 __”。类似这样的提示通常可以手动创建。他们的实验测试了创建不同的提示，并在 BERT 上进行测试，看看是否可以通过改变提示的措辞方法来提高性能。*

让我们开玩笑说，我们用来自[wookiepedia](https://starwars.fandom.com/wiki/Main_Page)的所有重要信息创建了一个语言模型(你没看错，这是一个关于《星球大战》所有内容的维基，真的令人印象深刻)。类似这样的提示:

> "卢克·天行者认为 ____ 是他的出生地"

是一种效率较低的提问方式:

> "卢克·天行者出生于 ____ "

既然如此，我们就知道，如果我们想知道其他人的起源，最好像第二个那样来组织我们的提示。研究小组根据他们的成功特别注意到了两种主要的方法来形成提示以改善结果:

## 基于挖掘的方法

正如他们在论文中提到的，这种方法是对先前问答系统研究中提到的基于模板的方法的一种尝试。这种方法基于这样一种思想，即在大型语料库中，文本通常被结构化为**主题** > **特定关系** > **对象**。他们从维基百科语料库中挖掘所有使用这种格式的句子，以创建一组更灵活的提示，例如:

> (主语)出生于(宾语)

正如您所想象的，使用语料库中更具体的关系措辞会使语言模型更容易得出符合事实的答案。虽然您可以手动给出类似的提示，但是它们的表现不如这种方法。

在我的 Wookiepedia 语言模型的例子中，我可以在语料库中挖掘类似的格式，也许我会找到短语“皮耶特拥有海军上将军衔”，我可以推断为 *(x)拥有(y)* 的军衔，这可能会帮助我制定更有效的方法来检查其他帝国军官的军衔。

## 基于释义的方法

所以我们有一个挖掘的提示，就像我们的 *(x)有一个(y)* 的秩，但这显然只是陈述关系的一种方式。转述是为了提高用来表达这种关系的词语的多样性，但不要偏离提示。这可以手动完成，但研究小组使用了反向翻译方法，将提示翻译成不同的语言，然后再翻译回来。他们工作中的一个例子是:

> x 与 y > x 有共同的边界，x 与 y 相邻

## 外卖食品

总的来说，这项研究指出了一种比手动提示更好的查询语言模型的方法。从本质上来说，在某种程度上，说一种类似于模型的语言可以改善它理解你的问题的方式是有意义的。我很想知道，如果你有一个纯粹根据人们自然说话的文字记录训练的语言模型，这样的东西会是什么样子。表现最好的提示类型是手动的还是挖掘的？只是一些疯狂的想法！我强烈推荐阅读这篇论文，这是一个非常有趣的研究。