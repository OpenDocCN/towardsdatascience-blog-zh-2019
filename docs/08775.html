<html>
<head>
<title>Classification Model Building and Tracking in Tensorflow 2.0</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">Tensorflow 2.0 中的分类模型构建和跟踪</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/classification-model-building-and-tracking-in-tensorflow-2-0-398f5fca8fcf?source=collection_archive---------24-----------------------#2019-11-24">https://towardsdatascience.com/classification-model-building-and-tracking-in-tensorflow-2-0-398f5fca8fcf?source=collection_archive---------24-----------------------#2019-11-24</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><figure class="ip iq gp gr ir is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi io"><img src="../Images/f4a70cd9f47d53fc92af01a2a7857aaf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*78KMHVVecnTzkLbN7xW0tQ.png"/></div></div></figure><div class=""/><p id="7e36" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">上个月发布了 Tensorflow 2，通过紧密集成高级 keras、清除冗余 API、将急切执行保留为默认、移除全局和使用函数而不是会话，使模型开发和部署更加容易。</p><p id="635e" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">在本文中，我们将使用 Tensorflow 2.0 为 MNIST 数据集构建一个 CNN 分类器，并使用 Tensorboard 跟踪模型性能，同时牢记所有最佳实践。</p><p id="8486" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">第一步是安装 Tensorflow 2.0。建议的方法是安装在虚拟环境或 docker 中。要通过虚拟环境安装，你可以按照这个<a class="ae kw" href="https://medium.com/@sambit9238/python-development-environment-set-up-with-virtual-environment-be26b1e96188." rel="noopener">链接</a>。</p><p id="8735" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">现在我们将文章分成两部分:</p><ol class=""><li id="6668" class="kx ky jb ka b kb kc kf kg kj kz kn la kr lb kv lc ld le lf bi translated">CNN 模型大楼。</li><li id="4e7c" class="kx ky jb ka b kb lg kf lh kj li kn lj kr lk kv lc ld le lf bi translated">用张量板跟踪模型。</li></ol><h1 id="d67c" class="ll lm jb bd ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi bi translated">CNN 模型构建</h1><p id="6988" class="pw-post-body-paragraph jy jz jb ka b kb mj kd ke kf mk kh ki kj ml kl km kn mm kp kq kr mn kt ku kv ij bi translated">首先，我们需要导入所需的库。</p><pre class="mo mp mq mr gt ms mt mu mv aw mw bi"><span id="5a09" class="mx lm jb mt b gy my mz l na nb">from tensorflow.keras import Model</span><span id="9e83" class="mx lm jb mt b gy nc mz l na nb">from tensorflow.keras.layers import Dense, Flatten, Conv2D</span><span id="a772" class="mx lm jb mt b gy nc mz l na nb">import tensorflow as tf</span></pre><blockquote class="nd ne nf"><p id="bfd5" class="jy jz ng ka b kb kc kd ke kf kg kh ki nh kk kl km ni ko kp kq nj ks kt ku kv ij bi translated">确保您已经安装了 numpy 版本 1.16.4，否则会出现如下用户警告:</p><p id="b2a5" class="jy jz ng ka b kb kc kd ke kf kg kh ki nh kk kl km ni ko kp kq nj ks kt ku kv ij bi translated">FutureWarning:不赞成将(type，1)或“1type”作为类型的同义词进行传递。在 numpy 的未来版本中，它将被理解为(type，(1，))/ '(1，)type '。NP _ resource = NP . dtype((" resource "，np.ubyte，1)) s</p></blockquote><p id="0868" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">现在，我们将从 tf.keras API 中获取可用的<a class="ae kw" href="https://www.tensorflow.org/api_docs/python/tf/keras/datasets" rel="noopener ugc nofollow" target="_blank"> mnist 手写数字数据集。</a>训练集和测试集分别有 6 万幅和 1 万幅图像。每张图片都是尺寸为 28*28 的黑白图片。然后，我们将样本从整数转换为浮点数，以提供给模型。</p><pre class="mo mp mq mr gt ms mt mu mv aw mw bi"><span id="d97c" class="mx lm jb mt b gy my mz l na nb">mnist = tf.keras.datasets.mnist</span><span id="73a6" class="mx lm jb mt b gy nc mz l na nb">(x_train, y_train), (x_test, y_test) = mnist.load_data()</span><span id="62ae" class="mx lm jb mt b gy nc mz l na nb">x_train, x_test = x_train / 255.0, x_test / 255.0</span><span id="b244" class="mx lm jb mt b gy nc mz l na nb">print(x_train.shape)<br/>#  (60000, 28, 28)</span></pre><p id="d6fa" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">因为我们要将输入馈送给 CNN，所以输入形状必须是特定的格式。对于 Tensorflow，格式应为(批次、高度、宽度、通道)。因此，我们将添加一个新的轴来格式化 CNN 的输入。</p><pre class="mo mp mq mr gt ms mt mu mv aw mw bi"><span id="622c" class="mx lm jb mt b gy my mz l na nb"># Add a channels dimension<br/>x_train = x_train[..., tf.newaxis]<br/>x_test = x_test[..., tf.newaxis]</span><span id="36bf" class="mx lm jb mt b gy nc mz l na nb">print(x_train.shape)<br/># (60000, 28, 28, 1)</span></pre><p id="0861" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">然后我们将使用 tf.data API 对数据集进行洗牌和批处理。这是一个非常方便的 API，可以设计到生产模型的输入数据管道。对于洗牌，我们将使用。来自 tf.data.Dataset API 的 shuffle()。它通过用<code class="fe nk nl nm mt b">buffer_size</code>元素填充一个缓冲区来随机打乱所提供的数据集的元素，然后从这个缓冲区中随机抽取元素，用新元素替换所选的元素。考虑到机器的内存限制，我们使用了大小为 10000 的缓冲区。</p><pre class="mo mp mq mr gt ms mt mu mv aw mw bi"><span id="6d62" class="mx lm jb mt b gy my mz l na nb">#tf.data to batch and shuffle the dataset</span><span id="869a" class="mx lm jb mt b gy nc mz l na nb">train_ds = tf.data.Dataset.from_tensor_slices((x_train,y_train))\<br/>                                        .shuffle(10000).batch(32)</span><span id="5ec6" class="mx lm jb mt b gy nc mz l na nb">test_ds =  tf.data.Dataset.from_tensor_slices((x_test,y_test))\<br/>                                        .batch(32)</span><span id="ff6c" class="mx lm jb mt b gy nc mz l na nb">print(train_ds.element_spec)</span><span id="5001" class="mx lm jb mt b gy nc mz l na nb">#(TensorSpec(shape=(None, 28, 28, 1), dtype=tf.float64, name=None), TensorSpec(shape=(None,), dtype=tf.uint8, name=None))</span></pre><p id="c1eb" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">因为我们是以 32 为一批，所以最后一批将少于 32 个元素，如果你愿意，可以通过将<code class="fe nk nl nm mt b">drop_remainder=True</code>传递给。批处理()</p><p id="32a8" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">现在我们有了数据，是时候定义模型架构了。为此，我们将使用 Keras <a class="ae kw" href="https://www.tensorflow.org/guide/keras#model_subclassing" rel="noopener ugc nofollow" target="_blank">模型子类 API </a>。另一种方法是使用 keras functional API，尽管子类化 API 更适合生产。</p><pre class="mo mp mq mr gt ms mt mu mv aw mw bi"><span id="2d23" class="mx lm jb mt b gy my mz l na nb">class MyModel(Model):<br/>        def __init__(self):<br/>                super(MyModel, self).__init__()<br/>                self.conv1 = tf.keras.layers.Conv2D(32, 3, padding='same', activation='relu')<br/>                self.pool = tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=2, padding='same')<br/>                self.flatten = tf.keras.layers.Flatten()<br/>                self.d1 = tf.keras.layers.Dense(256, activation='relu')<br/>                self.d2 = tf.keras.layers.Dense(128, activation='relu')<br/>                self.d3 = tf.keras.layers.Dense(10, activation='softmax')</span><span id="0c41" class="mx lm jb mt b gy nc mz l na nb">        def call(self, x):<br/>                x = self.conv1(x)<br/>                x = self.pool(x)<br/>                x = self.flatten(x)<br/>                x = self.d1(x)<br/>                x = self.d2(x)<br/>                x = self.d3(x)<br/>                return x</span></pre><p id="9cb1" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">现在，我们需要一个优化器和损失函数来训练模型。</p><pre class="mo mp mq mr gt ms mt mu mv aw mw bi"><span id="dd73" class="mx lm jb mt b gy my mz l na nb"># optimizer and loss function to train<br/>loss_object = tf.keras.losses.SparseCategoricalCrossentropy()<br/>optimizer = tf.keras.optimizers.Adam()</span></pre><blockquote class="nd ne nf"><p id="517e" class="jy jz ng ka b kb kc kd ke kf kg kh ki nh kk kl km ni ko kp kq nj ks kt ku kv ij bi translated">因为我们将标签作为整数提供，所以我们将使用稀疏分类交叉熵作为损失函数。</p></blockquote><p id="f51b" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">我们还将在每个时期后跟踪训练和测试数据的损失和准确性。</p><pre class="mo mp mq mr gt ms mt mu mv aw mw bi"><span id="a17b" class="mx lm jb mt b gy my mz l na nb"># metrics to measure the loss and the accuracy of the model</span><span id="8307" class="mx lm jb mt b gy nc mz l na nb">train_loss = tf.keras.metrics.Mean(name='train_loss')<br/>train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(<br/>                            name='train_accuracy')</span><span id="79a3" class="mx lm jb mt b gy nc mz l na nb">test_loss = tf.keras.metrics.Mean(name='test_loss')<br/>test_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(<br/>                            name='test_accuracy')</span></pre><p id="3f0e" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">现在，我们需要定义训练和测试方法来开始模型构建。</p><pre class="mo mp mq mr gt ms mt mu mv aw mw bi"><span id="b5fd" class="mx lm jb mt b gy my mz l na nb">@tf.function<br/>def train_step(model, optimizer, images, labels):<br/>         with tf.GradientTape() as tape:<br/>                  predictions = model(images)<br/>                  loss = loss_object(labels, predictions)<br/>         gradients = tape.gradient(loss, model.trainable_variables)<br/>         optimizer.apply_gradients(zip(gradients,                   model.trainable_variables))<br/>         train_loss(loss)<br/>         train_accuracy(labels, predictions)</span><span id="ce5b" class="mx lm jb mt b gy nc mz l na nb">@tf.function<br/>def test_step(model, images, labels):<br/>         predictions = model(images)<br/>         t_loss = loss_object(labels, predictions)<br/>         test_loss(t_loss)<br/>         test_accuracy(labels, predictions)</span></pre><p id="729d" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">在上面的代码中，有很多来自 Tensorflow 1 次的不同内容。</p><p id="f62b" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">首先关于 tf.function，</p><blockquote class="nd ne nf"><p id="38f6" class="jy jz ng ka b kb kc kd ke kf kg kh ki nh kk kl km ni ko kp kq nj ks kt ku kv ij bi translated">在 TensorFlow 2.0 中，默认情况下会打开急切执行。用户界面直观而灵活(运行一次性操作更容易、更快)，但这会以牺牲性能和可部署性为代价。</p><p id="98c3" class="jy jz ng ka b kb kc kd ke kf kg kh ki nh kk kl km ni ko kp kq nj ks kt ku kv ij bi translated"><code class="fe nk nl nm mt b">tf.function</code>构造一个 callable，它执行一个通过跟踪<code class="fe nk nl nm mt b">func</code>中的张量流操作创建的张量流图(<code class="fe nk nl nm mt b"><a class="ae kw" href="https://www.tensorflow.org/api_docs/python/tf/Graph" rel="noopener ugc nofollow" target="_blank">tf.Graph</a></code>)。这允许 TensorFlow 运行时在由<code class="fe nk nl nm mt b">func</code>定义的计算中应用优化和利用并行性。所以，建议用于生产。</p></blockquote><p id="3ca2" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">第二件事是 tf。GradientTape()，</p><blockquote class="nd ne nf"><p id="0961" class="jy jz ng ka b kb kc kd ke kf kg kh ki nh kk kl km ni ko kp kq nj ks kt ku kv ij bi translated">启用快速执行后，为了反向传播错误，您必须跟踪计算的梯度，然后将这些梯度应用到优化器。</p><p id="b081" class="jy jz ng ka b kb kc kd ke kf kg kh ki nh kk kl km ni ko kp kq nj ks kt ku kv ij bi translated">显然，Tensorflow 可以跟踪每个 tf.Variable 上的每个计算的每个梯度。然而，这可能是一个巨大的性能瓶颈。它们公开了一个渐变带，以便您可以控制代码的哪些区域需要渐变信息。</p></blockquote><p id="3c99" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">现在，我们必须实例化一个模型对象并输入数据来训练模型。我们必须跟踪测试数据的损失和准确性来评估模型。出于演示目的，我们在此仅使用了 5 个时期。</p><pre class="mo mp mq mr gt ms mt mu mv aw mw bi"><span id="3d67" class="mx lm jb mt b gy my mz l na nb">EPOCHS = 5</span><span id="3f1b" class="mx lm jb mt b gy nc mz l na nb"># Create an instance of the model<br/>model = MyModel()<br/>for epoch in range(EPOCHS):<br/>        for images, labels in train_ds:<br/>                train_step(model, optimizer, images, labels)</span><span id="0e32" class="mx lm jb mt b gy nc mz l na nb">        for test_images, test_labels in test_ds:<br/>                test_step(model, test_images, test_labels)</span><span id="bdd8" class="mx lm jb mt b gy nc mz l na nb">        template = 'Epoch {}, Loss: {}, Accuracy: {}, Test Loss: {}, Test Accuracy: {}'<br/>        print(template.format(epoch+1, train_loss.result(),<br/>                              train_accuracy.result()*100,<br/>                              test_loss.result(),<br/>                              test_accuracy.result()*100))</span><span id="efd5" class="mx lm jb mt b gy nc mz l na nb">#output<br/>Epoch 1, Loss: 0.14411139488220215, Accuracy: 95.71333312988281, Test Loss: 0.04969984292984009, Test Accuracy: 98.44999694824219<br/>2019-11-24 18:54:43.808050: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 376320000 exceeds 10% of system memory.<br/>Epoch 2, Loss: 0.04587719216942787, Accuracy: 98.59500122070312, Test Loss: 0.06183547526597977, Test Accuracy: 98.04000091552734<br/>Epoch 3, Loss: 0.029635081067681313, Accuracy: 99.05333709716797, Test Loss: 0.04673100262880325, Test Accuracy: 98.54000091552734<br/>Epoch 4, Loss: 0.020683910697698593, Accuracy: 99.32167053222656, Test Loss: 0.04771297425031662, Test Accuracy: 98.6199951171875<br/>Epoch 5, Loss: 0.01358255185186863, Accuracy: 99.57833099365234, Test Loss: 0.05094970762729645, Test Accuracy: 98.58000183105469</span></pre><p id="957b" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">如果我们看到 5 个时期，它得到了大约 98%以上的准确性。</p><h1 id="9f1c" class="ll lm jb bd ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi bi translated">用张量板跟踪模型</h1><p id="018e" class="pw-post-body-paragraph jy jz jb ka b kb mj kd ke kf mk kh ki kj ml kl km kn mm kp kq kr mn kt ku kv ij bi translated">Tensorboard 是一个非常方便的图形可视化工具，可以实时跟踪模型训练进度。它可以用于多种用途，从检查模型架构到跟踪模型训练中超参数的行为。这里，我们将通过一个简短的例子来检查模型在训练时的准确性和损失。</p><p id="79a1" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">我们需要首先启动一个 Tensorboard 实例来显示数据。</p><pre class="mo mp mq mr gt ms mt mu mv aw mw bi"><span id="f4cc" class="mx lm jb mt b gy my mz l na nb">import datetime<br/>from tensorboard import program</span><span id="44b9" class="mx lm jb mt b gy nc mz l na nb">tb = program.TensorBoard()<br/>tb.configure(argv=[None, ‘ — logdir’, “.”])<br/>url = tb.launch()<br/>print(“tensorboard url: “, url)</span><span id="deaf" class="mx lm jb mt b gy nc mz l na nb">#tensorboard url:  <a class="ae kw" href="http://localhost:6006/" rel="noopener ugc nofollow" target="_blank">http://localhost:6007/</a></span></pre><p id="8ebe" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">现在可以在<a class="ae kw" href="http://localhost:6006/" rel="noopener ugc nofollow" target="_blank"> http://localhost:6007/ </a>查看 Tensorboard。如果你去那里，你会看到一个像这样的屏幕:</p><figure class="mo mp mq mr gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi nn"><img src="../Images/4e44538926423b1c30347aa8072cb05e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_brT5L0iN9TFtv9dNFtgLw.png"/></div></div></figure><p id="65c2" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">这是因为 Tensorboard 通过读取所提供位置的日志目录来显示数据。在 tb.configure 中，我们已经提供了当前的工作目录。所以它会创建一个日志目录，并写入要在 Tensorboard 上显示的数据。因此，我们将首先为培训和测试创建一个日志记录器</p><pre class="mo mp mq mr gt ms mt mu mv aw mw bi"><span id="91eb" class="mx lm jb mt b gy my mz l na nb">current_time = datetime.datetime.now().strftime("%Y%m%d-%H%M%S")<br/>train_log_dir = 'logs/gradient_tape/' + current_time + '/train'<br/>test_log_dir = 'logs/gradient_tape/' + current_time + '/test'<br/>train_summary_writer = tf.summary.create_file_writer(train_log_dir)<br/>test_summary_writer = tf.summary.create_file_writer(test_log_dir)</span></pre><p id="af9d" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">然后，我们必须将每个 epoch 结果写入训练和测试中，以使它们可视化。</p><pre class="mo mp mq mr gt ms mt mu mv aw mw bi"><span id="867e" class="mx lm jb mt b gy my mz l na nb">for images, labels in train_ds:<br/>        for images, labels in train_ds:<br/>                train_step(model, optimizer, images, labels)<br/>        with train_summary_writer.as_default():<br/>                tf.summary.scalar('loss', train_loss.result(), step=epoch)<br/>                tf.summary.scalar('accuracy', train_accuracy.result(), step=epoch)</span><span id="18e9" class="mx lm jb mt b gy nc mz l na nb">        for test_images, test_labels in test_ds:<br/>                test_step(model, test_images, test_labels)<br/>        with test_summary_writer.as_default():<br/>                tf.summary.scalar('loss', test_loss.result(), step=epoch)<br/>                tf.summary.scalar('accuracy', test_accuracy.result(), step=epoch)</span></pre><p id="9007" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">现在，当训练正在进行时，如果您想查看结果，只需访问 Tensorboard url，屏幕将如下所示:</p><figure class="mo mp mq mr gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi no"><img src="../Images/e030ff9306e120704f244a7410802172.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*WllH1EvXYCzJa9pli2X7bw.png"/></div></div></figure><p id="d551" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">在 Tensorboard 中可以看到许多关于模型的东西，这不是本文的一部分。</p><p id="39f9" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">本文的代码可以在以下位置找到:</p><div class="ip iq gp gr ir np"><a href="https://github.com/sambit9238/Deep-Learning/blob/master/mnist.py" rel="noopener  ugc nofollow" target="_blank"><div class="nq ab fo"><div class="nr ab ns cl cj nt"><h2 class="bd jc gy z fp nu fr fs nv fu fw ja bi translated">sambit 9238/深度学习</h2><div class="nw l"><h3 class="bd b gy z fp nu fr fs nv fu fw dk translated">此时您不能执行该操作。您已使用另一个标签页或窗口登录。您已在另一个选项卡中注销，或者…</h3></div><div class="nx l"><p class="bd b dl z fp nu fr fs nv fu fw dk translated">github.com</p></div></div><div class="ny l"><div class="nz l oa ob oc ny od ix np"/></div></div></a></div><h2 id="db88" class="mx lm jb bd ln oe of dn lr og oh dp lv kj oi oj lz kn ok ol md kr om on mh oo bi translated">参考资料:</h2><div class="ip iq gp gr ir np"><a href="https://www.tensorflow.org/tutorials/quickstart/advanced" rel="noopener  ugc nofollow" target="_blank"><div class="nq ab fo"><div class="nr ab ns cl cj nt"><h2 class="bd jc gy z fp nu fr fs nv fu fw ja bi translated">面向专家的 TensorFlow 2 快速入门| TensorFlow 核心</h2><div class="nw l"><h3 class="bd b gy z fp nu fr fs nv fu fw dk translated">这是一个谷歌合作的笔记本文件。Python 程序直接在浏览器中运行——这是学习和研究的好方法</h3></div><div class="nx l"><p class="bd b dl z fp nu fr fs nv fu fw dk translated">www.tensorflow.org</p></div></div></div></a></div><div class="ip iq gp gr ir np"><a href="https://pgaleone.eu/tensorflow/tf.function/2019/03/21/dissecting-tf-function-part-1/" rel="noopener  ugc nofollow" target="_blank"><div class="nq ab fo"><div class="nr ab ns cl cj nt"><h2 class="bd jc gy z fp nu fr fs nv fu fw ja bi translated">分析 tf.function 以发现签名的优势和微妙之处——第 1 部分</h2><div class="nw l"><h3 class="bd b gy z fp nu fr fs nv fu fw dk translated">AutoGraph 是 Tensorflow 2.0 最激动人心的新特性之一:它允许转换 Python 语法的子集…</h3></div><div class="nx l"><p class="bd b dl z fp nu fr fs nv fu fw dk translated">pgaleone.eu</p></div></div><div class="ny l"><div class="op l oa ob oc ny od ix np"/></div></div></a></div></div></div>    
</body>
</html>