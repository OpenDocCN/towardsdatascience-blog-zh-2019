<html>
<head>
<title>MNIST Handwritten Digits Classification using a Convolutional Neural Network (CNN)</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">基于卷积神经网络的 MNIST 手写数字分类</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/mnist-handwritten-digits-classification-using-a-convolutional-neural-network-cnn-af5fafbc35e9?source=collection_archive---------4-----------------------#2019-09-07">https://towardsdatascience.com/mnist-handwritten-digits-classification-using-a-convolutional-neural-network-cnn-af5fafbc35e9?source=collection_archive---------4-----------------------#2019-09-07</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><figure class="gl gn jr js jt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi jq"><img src="../Images/776e109cdee400c27beb419655300447.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*SGPGG7oeSvVlV5sOSQ2iZw.png"/></div></div></figure><p id="bb60" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">这篇文章的目标是使用 PyTorch 实现一个 CNN 来分类 MNIST 手写数字图像。</p><p id="4e5d" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">这篇文章是关于卷积神经网络(CNN)介绍的 2 部分系列文章的一部分。</p><p id="6d5b" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated"><a class="ae kz" href="https://medium.com/@krutpatel/convolution-neural-networks-a-beginners-guide-implementing-a-mnist-hand-written-digit-8aa60330d022" rel="noopener"> <strong class="kd iu">第一部分——围绕 CNN 的基本概念</strong> </a></p><p id="577a" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated"><a class="ae kz" href="https://medium.com/@krutpatel/mnist-handwritten-digits-classification-using-a-convolutional-neural-network-cnn-af5fafbc35e9" rel="noopener"> <strong class="kd iu">第二部分— Pytorch 实现 CNN 对 MNIST 手写数字进行分类</strong> </a></p><p id="ff0e" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">本帖没有详细解释<strong class="kd iu">卷积层</strong>、<strong class="kd iu">最大池层</strong>、<strong class="kd iu">全连接层</strong>、<strong class="kd iu">脱落层</strong>等概念的工作原理。如果不熟悉，请阅读<a class="ae kz" href="https://medium.com/@krutpatel/convolution-neural-networks-a-beginners-guide-implementing-a-mnist-hand-written-digit-8aa60330d022" rel="noopener">第 1 部分</a>。</p><p id="f469" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">你可以在这里找到代码—<a class="ae kz" href="https://github.com/KrutPatel2257/MNIST_handwriting_classification" rel="noopener ugc nofollow" target="_blank">https://github.com/iamkrut/MNIST_handwriting_classification</a></p><p id="0f15" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">从这个<a class="ae kz" href="http://yann.lecun.com/exdb/mnist/" rel="noopener ugc nofollow" target="_blank">页面</a>可以得到 MNIST 手写数字数据库，它有 60，000 个样本的训练集和 10，000 个样本的测试集。这是从 NIST 可获得的更大集合的子集。数字已经过大小标准化，并在固定大小的图像中居中。</p><p id="980c" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">对于那些希望了解现实世界数据的各种模式识别方法，同时花费最少的精力进行预处理和格式化的人来说，这是一个很好的数据库。</p><h1 id="85ec" class="la lb it bd lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx bi translated">获取 MNIST 数据集并准备训练、验证和测试数据加载器</h1><figure class="ly lz ma mb gt ju"><div class="bz fp l di"><div class="mc md l"/></div></figure><p id="bf15" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">我们可以从 NIST 网站下载数据集，但使用 PyTorch 提供的<code class="fe me mf mg mh b">torchvision</code>下的<code class="fe me mf mg mh b">dataset</code> <strong class="kd iu"> </strong> API 更方便，它直接获取 MNIST 数据。</p><p id="db99" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">我们获取 NIST 提供的训练集和测试集。为了获取训练集，我们将参数<code class="fe me mf mg mh b">train</code>设置为<code class="fe me mf mg mh b">True</code>，而为了获取测试集，我们将其设置为<code class="fe me mf mg mh b">False</code>。<code class="fe me mf mg mh b">dataset</code> <strong class="kd iu"> </strong> API 还允许我们处理我们想要应用于数据的任何转换。我们设置<code class="fe me mf mg mh b">transform=transforms.Compose([transforms.ToTensor()]))</code>将图像数据转换成张量。</p><pre class="ly lz ma mb gt mi mh mj mk aw ml bi"><span id="06b0" class="mm lb it mh b gy mn mo l mp mq">mnist_trainset = datasets.MNIST(root='./data', train=True, download=True, <br/>transform=transforms.Compose([transforms.ToTensor()]))</span><span id="0b31" class="mm lb it mh b gy mr mo l mp mq">mnist_testset = datasets.MNIST(root='./data', train=False, download=True, transform=transforms.Compose([transforms.ToTensor()]))</span></pre><p id="ac5b" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated"><code class="fe me mf mg mh b">mnist_trainset</code>的尺寸为 60000，<code class="fe me mf mg mh b">mnist_testset</code>的尺寸为 10000</p><p id="669a" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">然后，我们将测试数据集分成两组，一组用于验证，另一组用于测试。我们做 90%–10%的测试，即 9000 次用于验证，1000 次用于测试。我们使用<code class="fe me mf mg mh b">torch.utils.data.random_split()</code>函数来完成这项工作。</p><pre class="ly lz ma mb gt mi mh mj mk aw ml bi"><span id="ab39" class="mm lb it mh b gy mn mo l mp mq">mnist_valset, mnist_testset = torch.utils.data.random_split(mnist_testset, [int(0.9 *    len(mnist_testset)), int(0.1 * len(mnist_testset))])</span></pre><p id="1032" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">之后，我们为所有三个集合准备数据加载器。DataLoader 基本上将数据集和采样器结合起来，并在给定的数据集上提供一个 iterable。</p><p id="5b8d" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">它还允许我们选择批量大小。<strong class="kd iu">批次大小</strong>是一个超参数，它定义了模型在更新内部模型参数之前查看的样本数量。这个概念被称为<strong class="kd iu">小批量梯度下降</strong>，因为模型对小批量数据进行处理以计算梯度，并根据梯度修改模型参数。我们选择<code class="fe me mf mg mh b">train_dataloader</code>的批量为 64，<code class="fe me mf mg mh b">val_dataloader</code>和<code class="fe me mf mg mh b">test_dataloader</code>的批量为 32。</p><pre class="ly lz ma mb gt mi mh mj mk aw ml bi"><span id="fedc" class="mm lb it mh b gy mn mo l mp mq">train_dataloader = torch.utils.data.DataLoader(mnist_trainset, batch_size=64, shuffle=True)<br/>val_dataloader = torch.utils.data.DataLoader(mnist_valset, batch_size=32, shuffle=False)<br/>test_dataloader = torch.utils.data.DataLoader(mnist_testset, batch_size=32, shuffle=False)</span></pre><h1 id="380a" class="la lb it bd lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx bi translated">可视化数据</h1><p id="96a9" class="pw-post-body-paragraph kb kc it kd b ke ms kg kh ki mt kk kl km mu ko kp kq mv ks kt ku mw kw kx ky im bi translated">开发深度学习模型的第一步是可视化数据。因此，让我们从列车组中绘制一些图像。</p><figure class="ly lz ma mb gt ju"><div class="bz fp l di"><div class="mc md l"/></div></figure><p id="7e79" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">该图显示了数字图像及其顶部的标签。如果你把图像数据打印出来，你可以看到数值在 0 和 1 之间。所以不需要对图像数据进行归一化。</p><figure class="ly lz ma mb gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi mx"><img src="../Images/56de26240a46d78f233dddd88728a8d2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*-SKNUhV8DploiNUvNmh3HQ.png"/></div></div></figure><h1 id="7be3" class="la lb it bd lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx bi translated">定义模型</h1><p id="e649" class="pw-post-body-paragraph kb kc it kd b ke ms kg kh ki mt kk kl km mu ko kp kq mv ks kt ku mw kw kx ky im bi translated">我们将定义一个简单的卷积神经网络，它有两个卷积层，后面是两个完全连接的层。</p><p id="b97c" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">下面是我们将用于 CNN 的模型架构。</p><figure class="ly lz ma mb gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi jq"><img src="../Images/776e109cdee400c27beb419655300447.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*SGPGG7oeSvVlV5sOSQ2iZw.png"/></div></div><figcaption class="my mz gj gh gi na nb bd b be z dk">Model Architecture</figcaption></figure><figure class="ly lz ma mb gt ju"><div class="bz fp l di"><div class="mc md l"/></div></figure><p id="ec9d" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">我们用 RelU 激活函数和 max-pool 层跟踪每个卷积层。RelU 引入了非线性，max-pooling 有助于消除噪声。</p><p id="e136" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">第一卷积层<code class="fe me mf mg mh b">self.conv_1</code>接收维度为 1 的通道，因为图像是灰度的。内核大小被选择为 3×3，步长为 1。该卷积的输出被设置为 32 个通道，这意味着它将使用 32 个核来提取 32 个特征图。我们用填充大小 1 填充图像，这样输入和输出维度是相同的。该层的<strong class="kd iu">输出尺寸</strong>将为<strong class="kd iu">32×28×28</strong>。</p><p id="12a1" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">这就是我们如何定义<code class="fe me mf mg mh b">self.conv_1</code>层:</p><pre class="ly lz ma mb gt mi mh mj mk aw ml bi"><span id="db3b" class="mm lb it mh b gy mn mo l mp mq">self.conv_1 = torch.nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3, stride=1, padding=1)</span></pre><p id="750f" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">我们对其应用 RelU 激活，然后是内核大小为 2、步距为 2 的最大池层。这将特征图向下采样到尺寸<strong class="kd iu"> 32 x 14 x 14 </strong>。</p><p id="f7d3" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">这就是我们如何定义<code class="fe me mf mg mh b">self.relu</code>层:</p><pre class="ly lz ma mb gt mi mh mj mk aw ml bi"><span id="e230" class="mm lb it mh b gy mn mo l mp mq">self.relu = torch.nn.ReLU()</span></pre><p id="773a" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">这就是我们如何定义<code class="fe me mf mg mh b">self.max_pool2d</code>层:</p><pre class="ly lz ma mb gt mi mh mj mk aw ml bi"><span id="b798" class="mm lb it mh b gy mn mo l mp mq">self.max_pool2d = torch.nn.MaxPool2d(kernel_size=2, stride=2)</span></pre><p id="dbe1" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">第二卷积层<code class="fe me mf mg mh b">self.conv_2</code>将具有 32 的输入通道尺寸。我们选择输出通道大小为 64，这意味着它将提取 64 个特征图。这一层的内核大小为 3，步幅为 1。我们再次使用填充大小 1，以便输入和输出维度保持相同。该层的输出尺寸将为<strong class="kd iu"> 64 x 7 x 7 </strong>。</p><p id="f7be" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">这就是我们如何定义<code class="fe me mf mg mh b">self.conv_2</code>层:</p><pre class="ly lz ma mb gt mi mh mj mk aw ml bi"><span id="a491" class="mm lb it mh b gy mn mo l mp mq">self.conv_2 = torch.nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=1)</span></pre><p id="a60f" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">然后，我们用一个 RelU 激活和一个内核大小为 2、步幅为 2 的 max-pooling 层来跟进。下采样的特征图将具有尺寸<strong class="kd iu">64×7×7</strong>。</p><p id="f0b6" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">我们对此使用相同的定义<code class="fe me mf mg mh b">self.relu</code>和<code class="fe me mf mg mh b">self.max_pool2d</code>，因为<code class="fe me mf mg mh b">self.relu</code>是相同的操作，定义它两次没有意义。类似地<code class="fe me mf mg mh b">self.max_pool2d</code>也是相同的操作，因为它们使用相同的内核大小和步数。</p><p id="79cd" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">最后，使用两个完全连接的层<code class="fe me mf mg mh b">self.linear_1</code>和<code class="fe me mf mg mh b">self.linear_2</code>。我们将把特征地图的展平版本传递给第一个完全连接的层。因此，它的尺寸必须是 64×7×7，等于 3136 个节点。该层将连接到另一个具有<strong class="kd iu"> 128 个节点</strong>的全连接层。这将是我们的最后一层，所以输出的维度应该与总类相匹配，即<strong class="kd iu"> 10 </strong>。因此，我们有两个完全连接的层，大小为<strong class="kd iu"> 3136 x 128 </strong>，后面是<strong class="kd iu"> 128 x 10 </strong>。</p><p id="5171" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">该层<code class="fe me mf mg mh b">self.linear_1</code>和<code class="fe me mf mg mh b">self.linear_2</code>定义如下:</p><pre class="ly lz ma mb gt mi mh mj mk aw ml bi"><span id="757e" class="mm lb it mh b gy mn mo l mp mq">self.linear_1 = torch.nn.Linear(7 * 7 * 64, 128)<br/>self.linear_2 = torch.nn.Linear(128, 10</span></pre><p id="ee61" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">由于我们想要丢弃两个线性层之间的连接以减少过拟合，我们定义<code class="fe me mf mg mh b">self.dropout</code>的连接丢弃概率为 0.5，如下所示:</p><pre class="ly lz ma mb gt mi mh mj mk aw ml bi"><span id="1893" class="mm lb it mh b gy mn mo l mp mq">self.dropout = torch.nn.Dropout(p=0.5)</span></pre><p id="873f" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">以上所有的层和操作都是在类<code class="fe me mf mg mh b">torch.nn.Module</code>的 overridern <code class="fe me mf mg mh b">__init__</code>方法下定义的</p><pre class="ly lz ma mb gt mi mh mj mk aw ml bi"><span id="2e87" class="mm lb it mh b gy mn mo l mp mq">def __init__(self):<br/>    super(Model, self).__init__()<br/>    self.conv_1 = torch.nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3, stride=1, padding=1)<br/>    self.conv_2 = torch.nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=1)<br/>    self.max_pool2d = torch.nn.MaxPool2d(kernel_size=2, stride=2)<br/>    self.linear_1 = torch.nn.Linear(7 * 7 * 64, 128)<br/>    self.linear_2 = torch.nn.Linear(128, 10)<br/>    self.dropout = torch.nn.Dropout(p=0.5)<br/>    self.relu = torch.nn.ReLU()</span></pre><p id="3784" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">接下来，我们通过覆盖类<code class="fe me mf mg mh b">torch.nn.Module</code>的<code class="fe me mf mg mh b">forward</code>方法来定义我们希望数据如何流经这些层</p><pre class="ly lz ma mb gt mi mh mj mk aw ml bi"><span id="7696" class="mm lb it mh b gy mn mo l mp mq">def forward(self, x):<br/>    x = self.conv_1(x)<br/>    x = self.relu(x)<br/>    x = self.max_pool2d(x)<br/>    x = self.conv_2(x)<br/>    x = self.relu(x)<br/>    x = self.max_pool2d(x)<br/>    x = x.reshape(x.size(0), -1)<br/>    x = self.linear_1(x)<br/>    x = self.relu(x)<br/>    x = self.dropout(x)<br/>    pred = self.linear_2(x)<br/><br/>    return pred</span></pre><h1 id="0a56" class="la lb it bd lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx bi translated">定义模型对象、损失函数和优化器</h1><p id="6e83" class="pw-post-body-paragraph kb kc it kd b ke ms kg kh ki mt kk kl km mu ko kp kq mv ks kt ku mw kw kx ky im bi translated">我们定义了一个<code class="fe me mf mg mh b">Model()</code>类的实例，并将其命名为<code class="fe me mf mg mh b">model</code></p><pre class="ly lz ma mb gt mi mh mj mk aw ml bi"><span id="4739" class="mm lb it mh b gy mn mo l mp mq">model = Model()</span></pre><p id="43f4" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated"><strong class="kd iu">损失标准:</strong>损失函数告诉我们模型预测的好坏。由于我们正在处理多类分类，我们选择交叉熵作为我们的损失函数。我们使用结合了 softmax 函数<code class="fe me mf mg mh b">nn.LogSoftmax()</code>和<code class="fe me mf mg mh b">nn.NLLLoss()</code>损失函数的<code class="fe me mf mg mh b">torch.nn.CrossEntropyLoss</code>。</p><pre class="ly lz ma mb gt mi mh mj mk aw ml bi"><span id="10e3" class="mm lb it mh b gy mn mo l mp mq">criterion = torch.nn.CrossEntropyLoss()</span></pre><p id="5581" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated"><strong class="kd iu">优化器:</strong>优化器通过响应损失标准的输出更新模型，将损失函数和模型参数联系在一起。我们将使用 Adam 作为优化器，其<strong class="kd iu">学习率</strong>为<strong class="kd iu"> 0.001 </strong>。</p><pre class="ly lz ma mb gt mi mh mj mk aw ml bi"><span id="60e2" class="mm lb it mh b gy mn mo l mp mq">optimizer = torch.optim.Adam(model.parameters(), lr=0.001)</span></pre><figure class="ly lz ma mb gt ju"><div class="bz fp l di"><div class="mc md l"/></div></figure><h1 id="ffb2" class="la lb it bd lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx bi translated">培训和评估</h1><figure class="ly lz ma mb gt ju"><div class="bz fp l di"><div class="mc md l"/></div></figure><p id="1e7b" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">我们将训练 100 个时期的模型，并挑选验证损失最低的模型。</p><h2 id="6d42" class="mm lb it bd lc nc nd dn lg ne nf dp lk km ng nh lo kq ni nj ls ku nk nl lw nm bi translated">训练循环</h2><p id="6154" class="pw-post-body-paragraph kb kc it kd b ke ms kg kh ki mt kk kl km mu ko kp kq mv ks kt ku mw kw kx ky im bi translated">对于每个时期，我们使用 train_dataloader 上的枚举函数迭代通过 train_dataset 的批次。</p><p id="0071" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">首先，我们将模型设置为训练模式。这使我们能够启用 dropout 层，并在训练模式下设置模型。</p><pre class="ly lz ma mb gt mi mh mj mk aw ml bi"><span id="b72d" class="mm lb it mh b gy mn mo l mp mq">model.train()</span></pre><p id="ea8a" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">对于每一批，我们将该批图像张量传递到模型中，该模型将返回一个具有该批预测的张量。</p><pre class="ly lz ma mb gt mi mh mj mk aw ml bi"><span id="0785" class="mm lb it mh b gy mn mo l mp mq">pred = model(image)</span></pre><p id="fa0e" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">得到预测后，我们将它们与它们的实际标签一起传递到交叉熵损失标准中，并计算损失。</p><pre class="ly lz ma mb gt mi mh mj mk aw ml bi"><span id="2bcc" class="mm lb it mh b gy mn mo l mp mq">loss = criterion(pred, label)</span></pre><p id="6d92" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">我们使用这个损失值进行反向传递，并使用 Adam optimizer 来修改模型参数。</p><pre class="ly lz ma mb gt mi mh mj mk aw ml bi"><span id="554d" class="mm lb it mh b gy mn mo l mp mq">loss.backward()<br/>optimizer.step()</span></pre><p id="71f4" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">在每次迭代之前，我们需要将优化器梯度归零。</p><pre class="ly lz ma mb gt mi mh mj mk aw ml bi"><span id="2367" class="mm lb it mh b gy mn mo l mp mq">optimizer.zero_grad()</span></pre><p id="36bb" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">我们通过将每批迭代的所有损失相加，并通过迭代计数对其进行平均，来获得整个时期的训练损失。除此之外，我们还通过将损失值存储在列表<code class="fe me mf mg mh b">train_loss</code>中来跟踪每个时期的训练损失</p><p id="332a" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">这是整个循环的样子:</p><pre class="ly lz ma mb gt mi mh mj mk aw ml bi"><span id="ee08" class="mm lb it mh b gy mn mo l mp mq">model.train()<br/># training<br/>for itr, (image, label) in enumerate(train_dataloader):<br/><br/>    if (torch.cuda.is_available()):<br/>        image = image.cuda()<br/>        label = label.cuda()<br/><br/>    optimizer.zero_grad()<br/><br/>    pred = model(image)<br/><br/>    loss = criterion(pred, label)<br/>    total_train_loss += loss.item()<br/><br/>    loss.backward()<br/>    optimizer.step()<br/><br/>total_train_loss = total_train_loss / (itr + 1)<br/>train_loss.append(total_train_loss)</span></pre><h2 id="7f32" class="mm lb it bd lc nc nd dn lg ne nf dp lk km ng nh lo kq ni nj ls ku nk nl lw nm bi translated">验证循环</h2><p id="72b3" class="pw-post-body-paragraph kb kc it kd b ke ms kg kh ki mt kk kl km mu ko kp kq mv ks kt ku mw kw kx ky im bi translated">对于训练循环之后的每个时期，我们进行验证循环，以查看该模型在验证集上的表现。</p><p id="b70f" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">首先，我们将模型设置为评估模式</p><pre class="ly lz ma mb gt mi mh mj mk aw ml bi"><span id="bdea" class="mm lb it mh b gy mn mo l mp mq">model.eval()</span></pre><p id="f40e" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">然后，我们使用 enumerate 函数迭代验证数据加载器中的每个批次。我们采取了与训练相似的步骤，但我们不会将失败反向传播。之后，我们将模型的预测与实际标签进行比较，并计算模型的准确性。与训练阶段类似，我们通过将每批迭代的所有损失相加，并通过迭代计数对其进行平均，来获得该时期的验证损失。我们通过将每个时期的损失值存储在<code class="fe me mf mg mh b">val_loss</code>中来跟踪每个时期的确认损失</p><p id="ca4d" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">整个循环如下所示:</p><pre class="ly lz ma mb gt mi mh mj mk aw ml bi"><span id="6a87" class="mm lb it mh b gy mn mo l mp mq">for itr, (image, label) in enumerate(val_dataloader):<br/>    pred = model(image)</span><span id="4504" class="mm lb it mh b gy mr mo l mp mq">    loss = criterion(pred, label)<br/>    total_val_loss += loss.item()<br/><br/>    pred = torch.nn.functional.softmax(pred, dim=1)<br/>    for i, p in enumerate(pred):<br/>        if label[i] == torch.max(p.data, 0)[1]:<br/>            total = total + 1<br/><br/>accuracy = total / len(mnist_valset)<br/><br/>total_val_loss = total_val_loss / (itr + 1)</span></pre><p id="8f84" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">我们绘制了每个时期的训练和验证损失，它们分别存储在列表<code class="fe me mf mg mh b">train_loss</code>和<code class="fe me mf mg mh b">val_loss</code>下。</p><pre class="ly lz ma mb gt mi mh mj mk aw ml bi"><span id="5b25" class="mm lb it mh b gy mn mo l mp mq">fig=plt.figure(figsize=(20, 10))<br/>plt.plot(np.arange(1, no_epochs+1), train_loss, label="Train loss")<br/>plt.plot(np.arange(1, no_epochs+1), val_loss, label="Validation loss")<br/>plt.xlabel('Loss')<br/>plt.ylabel('Epochs')<br/>plt.title("Loss Plots")<br/>plt.legend(loc='upper right')<br/>plt.show()</span></pre><p id="a9c7" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">下面是训练和验证损失图</p><figure class="ly lz ma mb gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi nn"><img src="../Images/cd6ad47be07f9e2b9bb41a02d700f8c1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*JMdv-1vZoY_JLmRJo1ZMTQ.png"/></div></div><figcaption class="my mz gj gh gi na nb bd b be z dk">Loss plot</figcaption></figure><p id="68eb" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">如所见，第 12 个时期具有最低的验证损失 0.02092566 和精度 0.99388889，之后模型开始过拟合并且验证损失激增。</p><p id="6705" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">培训日志如下所示:</p><pre class="ly lz ma mb gt mi mh mj mk aw ml bi"><span id="9385" class="mm lb it mh b gy mn mo l mp mq">Training dataset size:  60000<br/>Validation dataset size:  9000<br/>Testing dataset size:  1000</span><span id="664b" class="mm lb it mh b gy mr mo l mp mq">Epoch: 1/100, Train Loss: 0.27790789, Val Loss: 0.04998713, Val Accuracy: 0.98311111<br/>Saving the model state dictionary for Epoch: 1 with Validation loss: 0.04998713</span><span id="4d14" class="mm lb it mh b gy mr mo l mp mq">Epoch: 2/100, Train Loss: 0.09957011, Val Loss: 0.04592616, Val Accuracy: 0.98533333<br/>Saving the model state dictionary for Epoch: 2 with Validation loss: 0.04592616</span><span id="1f50" class="mm lb it mh b gy mr mo l mp mq">Epoch: 3/100, Train Loss: 0.07494711, Val Loss: 0.03318010, Val Accuracy: 0.98900000<br/>Saving the model state dictionary for Epoch: 3 with Validation loss: 0.03318010</span><span id="1462" class="mm lb it mh b gy mr mo l mp mq">Epoch: 4/100, Train Loss: 0.06168462, Val Loss: 0.02777057, Val Accuracy: 0.99033333<br/>Saving the model state dictionary for Epoch: 4 with Validation loss: 0.02777057</span><span id="f1eb" class="mm lb it mh b gy mr mo l mp mq">Epoch: 5/100, Train Loss: 0.05156403, Val Loss: 0.02722912, Val Accuracy: 0.99100000<br/>Saving the model state dictionary for Epoch: 5 with Validation loss: 0.02722912</span><span id="7fb5" class="mm lb it mh b gy mr mo l mp mq">Epoch: 6/100, Train Loss: 0.04502778, Val Loss: 0.02404975, Val Accuracy: 0.99233333<br/>Saving the model state dictionary for Epoch: 6 with Validation loss: 0.02404975</span><span id="99a3" class="mm lb it mh b gy mr mo l mp mq">Epoch: 7/100, Train Loss: 0.03968575, Val Loss: 0.02311387, Val Accuracy: 0.99211111<br/>Saving the model state dictionary for Epoch: 7 with Validation loss: 0.02311387</span><span id="03e5" class="mm lb it mh b gy mr mo l mp mq">Epoch: 8/100, Train Loss: 0.03550077, Val Loss: 0.02516144, Val Accuracy: 0.99188889</span><span id="2583" class="mm lb it mh b gy mr mo l mp mq">Epoch: 9/100, Train Loss: 0.02957717, Val Loss: 0.02641086, Val Accuracy: 0.99144444</span><span id="13e4" class="mm lb it mh b gy mr mo l mp mq">Epoch: 10/100, Train Loss: 0.02666702, Val Loss: 0.02112512, Val Accuracy: 0.99344444<br/>Saving the model state dictionary for Epoch: 10 with Validation loss: 0.02112512</span><span id="60a3" class="mm lb it mh b gy mr mo l mp mq">Epoch: 11/100, Train Loss: 0.02564372, Val Loss: 0.02457329, Val Accuracy: 0.99266667</span><span id="1157" class="mm lb it mh b gy mr mo l mp mq">Epoch: 12/100, Train Loss: 0.02233217, Val Loss: 0.02092566, Val Accuracy: 0.99388889<br/>Saving the model state dictionary for Epoch: 12 with Validation loss: 0.02092566</span><span id="b394" class="mm lb it mh b gy mr mo l mp mq">Epoch: 13/100, Train Loss: 0.02011606, Val Loss: 0.02414113, Val Accuracy: 0.99322222</span><span id="63e9" class="mm lb it mh b gy mr mo l mp mq">Epoch: 14/100, Train Loss: 0.02053968, Val Loss: 0.02243329, Val Accuracy: 0.99388889</span><span id="90f3" class="mm lb it mh b gy mr mo l mp mq">.<br/>.<br/>.</span><span id="b8c8" class="mm lb it mh b gy mr mo l mp mq">Epoch: 99/100, Train Loss: 0.00538922, Val Loss: 0.05434694, Val Accuracy: 0.99366667</span><span id="fb2e" class="mm lb it mh b gy mr mo l mp mq">Epoch: 100/100, Train Loss: 0.00425748, Val Loss: 0.06263806, Val Accuracy: 0.99288889</span></pre><h1 id="02e9" class="la lb it bd lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx bi translated">测试和可视化结果</h1><figure class="ly lz ma mb gt ju"><div class="bz fp l di"><div class="mc md l"/></div></figure><p id="e3ad" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">我们为具有最低验证损失的模型获取保存的模型状态字典，并将其加载到我们的模型中。接下来，我们将模型设置为评估模式。</p><pre class="ly lz ma mb gt mi mh mj mk aw ml bi"><span id="4ac8" class="mm lb it mh b gy mn mo l mp mq">model.load_state_dict(torch.load("model.dth"))<br/>model.eval()</span></pre><p id="976d" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">我们通过测试数据加载器进行枚举，并以与验证循环相同的方式计算模型的准确性。我们还将结果存储在“结果”列表中。使用这个模型，我在测试集上获得了 0.99300000 的准确度。</p><pre class="ly lz ma mb gt mi mh mj mk aw ml bi"><span id="9c2e" class="mm lb it mh b gy mn mo l mp mq">results = list()<br/>total = 0<br/>for itr, (image, label) in enumerate(test_dataloader):<br/>    pred = model(image)<br/>    pred = torch.nn.functional.softmax(pred, dim=1)<br/><br/>    for i, p in enumerate(pred):<br/>        if label[i] == torch.max(p.data, 0)[1]:<br/>            total = total + 1<br/>            results.append((image, torch.max(p.data, 0)[1]))</span></pre><p id="f040" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">然后我们画出结果。</p><pre class="ly lz ma mb gt mi mh mj mk aw ml bi"><span id="01cf" class="mm lb it mh b gy mn mo l mp mq"># visualize results<br/>fig=plt.figure(figsize=(20, 10))<br/>for i in range(1, 11):<br/>    img = transforms.ToPILImage(mode='L')(results[i]             [0].squeeze(0).detach().cpu())<br/>    fig.add_subplot(2, 5, i)<br/>    plt.title(results[i][1].item())<br/>    plt.imshow(img)<br/>plt.show()</span></pre><p id="c3e3" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">预测标签显示在每个图像的上方。从结果可以看出，我们的模型预测得很好。</p><figure class="ly lz ma mb gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi no"><img src="../Images/a288a8b8f5d4141e77352e30cf5b2e9d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*26W2Yk3cu2uz_R8BuSb_SA.png"/></div></div></figure><h1 id="fad6" class="la lb it bd lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx bi translated">放弃</h1><p id="387b" class="pw-post-body-paragraph kb kc it kd b ke ms kg kh ki mt kk kl km mu ko kp kq mv ks kt ku mw kw kx ky im bi translated">虽然这篇文章介绍了用 pytorch 实现 CNN 模型对 MNIST 手写数字进行分类，但这绝不是最好的实现。使用数据扩充、调整漏层、正则化、批量归一化、超参数调整可以进一步提高性能。等等。它的目标是那些试图进入计算机视觉领域并希望从某个地方开始的初学者。</p></div></div>    
</body>
</html>