<html>
<head>
<title>How to use NLP to Analyze WhatsApp Messages</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">如何使用 NLP 分析 WhatsApp 消息</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/how-to-use-nlp-to-analyze-whatsapp-messages-1adf0e85907c?source=collection_archive---------8-----------------------#2019-06-27">https://towardsdatascience.com/how-to-use-nlp-to-analyze-whatsapp-messages-1adf0e85907c?source=collection_archive---------8-----------------------#2019-06-27</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><h2 id="1927" class="ir is it bd b dl iu iv iw ix iy iz dk ja translated" aria-label="kicker paragraph">NLP-WhatsApp</h2><div class=""/><div class=""><h2 id="476f" class="pw-subtitle-paragraph jz jc it bd b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq dk translated">使用 NLP 分析我和妻子之间的 WhatsApp 消息</h2></div><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi kr"><img src="../Images/11e360f3ff3149bbd8761680850587e4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ZTzL0HlOgeEM8hPw1ElMCQ.jpeg"/></div></div></figure><p id="3b4f" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">2018 年 8 月 17 日，我和我梦想中的女人结婚了，想在婚礼前一天送她一份礼物给她一个惊喜。当然，作为一名数据科学家，我必须通过<strong class="lf jd">数据</strong>进行交流！</p><p id="cc06" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">我们的<strong class="lf jd"> WhatsApp messages </strong>似乎是一个很好的信息来源。我使用 NLP 来分析消息，并创建了一个小的 python 包，名为<a class="ae lz" href="https://github.com/MaartenGr/soan" rel="noopener ugc nofollow" target="_blank"><strong class="lf jd">【SOAN】</strong></a>，它允许你这样做。</p><p id="998e" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">在这篇文章中，我将指导你完成我所做的分析，以及你将如何使用我创建的包。点击<a class="ae lz" href="https://faq.whatsapp.com/en/wp/22548236" rel="noopener ugc nofollow" target="_blank">此</a>链接，获取将 WhatsApp 文本下载为. txt 的说明。</p></div><div class="ab cl ma mb hx mc" role="separator"><span class="md bw bk me mf mg"/><span class="md bw bk me mf mg"/><span class="md bw bk me mf"/></div><div class="im in io ip iq"><h1 id="0f2b" class="mh mi it bd mj mk ml mm mn mo mp mq mr ki ms kj mt kl mu km mv ko mw kp mx my bi translated"><strong class="ak">预处理数据</strong></h1><p id="1577" class="pw-post-body-paragraph ld le it lf b lg mz kd li lj na kg ll lm nb lo lp lq nc ls lt lu nd lw lx ly im bi translated">该包允许您预处理。txt 文件作为特定的格式是进行分析所必需的。只需导入 helper 函数来导入数据和处理数据。<em class="ne"> import_data </em>用于导入数据，而<em class="ne"> preprocess_data </em>用于准备数据，以备分析。</p><pre class="ks kt ku kv gt nf ng nh ni aw nj bi"><span id="0dd2" class="nk mi it ng b gy nl nm l nn no">from soan.whatsapp import helper      # Helper to prepare the data<br/>from soan.whatsapp import general     # General statistics<br/>from soan.whatsapp import tf_idf      # Calculate uniqueness<br/>from soan.whatsapp import emoji       # Analyse use of emoji<br/>from soan.whatsapp import topic       # Topic modeling<br/>from soan.whatsapp import sentiment   # Sentiment analyses<br/>from soan.whatsapp import wordcloud   # Sentiment-based Word Clouds</span><span id="fab1" class="nk mi it ng b gy np nm l nn no">%matplotlib inline<br/>df = helper.import_data('Whatsapp.txt')<br/>df = helper.preprocess_data(df)</span></pre><p id="8531" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">在对数据进行预处理后，您将得到几个列:Message_Raw、Message_Clean、Message_Only_Text、User、Date、Hour、Day_of_Week。Message_Raw 包含原始消息，Message_Clean 仅包含消息本身，不包含用户或日期，Message_Only_Text 仅保留小写文本并删除任何非字母数字字符:</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi nq"><img src="../Images/55bbd4039ba56e6f24ce63f4f0663971.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*P43atvD73qGE-RUs4ekGwg.png"/></div></div><figcaption class="nr ns gj gh gi nt nu bd b be z dk">The first row of our cleaned messages. It is in Dutch but basically states if I made it home alright :-P</figcaption></figure></div><div class="ab cl ma mb hx mc" role="separator"><span class="md bw bk me mf mg"/><span class="md bw bk me mf mg"/><span class="md bw bk me mf"/></div><div class="im in io ip iq"><h1 id="172b" class="mh mi it bd mj mk ml mm mn mo mp mq mr ki ms kj mt kl mu km mv ko mw kp mx my bi translated"><strong class="ak">探索性数据分析(EDA) </strong></h1><p id="7d64" class="pw-post-body-paragraph ld le it lf b lg mz kd li lj na kg ll lm nb lo lp lq nc ls lt lu nd lw lx ly im bi translated">既然已经对数据进行了预处理，就可以根据消息的频率创建一些初始图。调用<em class="ne"> plot_messages </em>绘制每周的信息频率:</p><pre class="ks kt ku kv gt nf ng nh ni aw nj bi"><span id="c991" class="nk mi it ng b gy nl nm l nn no">general.plot_messages(df, colors=None, trendline=False, savefig=False, dpi=100)</span></pre><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi nv"><img src="../Images/455002fda5e722eeaf2717efcc81c466.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*a-KiFt0Xt6JABp1zLOQJWg.png"/></div></div><figcaption class="nr ns gj gh gi nt nu bd b be z dk">Weekly count of the number of messages over time.</figcaption></figure><p id="47bf" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">有趣的是，这表明在 2016 年 12 月左右，消息似乎出现了明显的下降。那时我们搬到了一起住在 T21，这解释了为什么我们不需要给对方发那么多短信。</p><p id="2944" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">我还对我和妻子之间每天的信息频率感兴趣。从 Github 借鉴了一些灵感来创建一个日历情节(使用修改版的<a class="ae lz" href="https://pythonhosted.org/calmap/" rel="noopener ugc nofollow" target="_blank"> CalMap </a>):</p><pre class="ks kt ku kv gt nf ng nh ni aw nj bi"><span id="9466" class="nk mi it ng b gy nl nm l nn no">general.calendar_plot(df, year=2017, how='count', column='index')</span></pre><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi nw"><img src="../Images/ad4c38c8c9cd3a3799a1e98a6b9d0473.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*u9YWhKGtnv9bMp8jc9lsmA.png"/></div></div><figcaption class="nr ns gj gh gi nt nu bd b be z dk">The frequency of messages (darker = more often)</figcaption></figure><p id="d4f1" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">有一段时间，我们发短信的频率更高，但这似乎不是一种视觉上可以观察到的模式。让我们和 TF-IDF 一起更深入的探讨一下！</p><h1 id="7b9c" class="mh mi it bd mj mk nx mm mn mo ny mq mr ki nz kj mt kl oa km mv ko ob kp mx my bi translated"><strong class="ak">独特的文字(TF-IDF) </strong></h1><p id="f5ae" class="pw-post-body-paragraph ld le it lf b lg mz kd li lj na kg ll lm nb lo lp lq nc ls lt lu nd lw lx ly im bi translated">我想展示一些对我们来说独一无二但也经常使用的单词。例如，单词“Hi”可能对我来说是唯一的(因为她总是使用单词“Hello”)，但如果我在数百条消息中只使用一次，它就不会那么有趣了。为了对此建模，我使用了一种流行的算法，称为 TF-IDF(即，术语频率-逆文档频率)。它获取文档中单词的频率，并计算这些单词在语料库中的反比:</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi oc"><img src="../Images/3af75704ea1c28497ac056952b14ceaf.png" data-original-src="https://miro.medium.com/v2/resize:fit:950/format:webp/1*IzOiFMSONYnAhlJcMfENUA.png"/></div><figcaption class="nr ns gj gh gi nt nu bd b be z dk">TF-IDF slightly adjusted to work with text messages</figcaption></figure><p id="e8b0" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">基本上，它会告诉你哪些单词重要，哪些不重要。例如，像“the”、“I”和“an”这样的词出现在大多数文本中，通常并不那么有趣。</p><p id="8f36" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">你在上面看到的 TF-IDF 版本略有调整，因为我关注的是一个人发短信的字数，而不是文本的数量。</p><p id="791a" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">下一步是通过简单地划分每个人的 TF-IDF 分数来计算每个人的独特性分数:</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi od"><img src="../Images/3fbbf45e8ad325c875bde79add7a181f.png" data-original-src="https://miro.medium.com/v2/resize:fit:428/format:webp/1*sGOejpjlX42pm-2FEtUudA.png"/></div><figcaption class="nr ns gj gh gi nt nu bd b be z dk">Uniqueness score for each person.</figcaption></figure><p id="6c80" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">正如你在上面的公式中看到的，它考虑了聊天中每个人的 TF-IDF 分数。因此，它也适用于<strong class="lf jd">群组</strong>聊天。</p><p id="fb23" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">从事数据科学的一件重要事情是以清晰、有趣和吸引人的方式交流结果。因为我的观众是我的妻子，我必须确保我的视觉效果是清晰的。我决定使用一个水平直方图来显示最独特的单词和它们的分数。水平直方图中的单词通常更容易阅读。为了使它在视觉上更有趣，您可以使用条形作为您想要包含的任何图像的遮罩。出于演示的目的，我用了一张我婚礼的照片:</p><pre class="ks kt ku kv gt nf ng nh ni aw nj bi"><span id="e9f0" class="nk mi it ng b gy nl nm l nn no">unique_words = tf_idf.get_unique_words(counts, df, version = 'C')<br/>tf_idf.plot_unique_words(unique_words, user='Me', <br/>                         image_path='histogram.jpg', image_url=None,<br/>                         title="Me", title_color="white", <br/>                         title_background='#AAAAAA', width=400,<br/>                         height=500)</span></pre><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi oe"><img src="../Images/19cdccf8331b057f4348ed5136eab8e4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1248/format:webp/1*CwD9M3vSiOmK8xEHx4JN8w.png"/></div><figcaption class="nr ns gj gh gi nt nu bd b be z dk">My top 10 most unique words used in our text messages.</figcaption></figure><h1 id="57b5" class="mh mi it bd mj mk nx mm mn mo ny mq mr ki nz kj mt kl oa km mv ko ob kp mx my bi translated"><strong class="ak">表情符号和情感分析</strong></h1><p id="d3ba" class="pw-post-body-paragraph ld le it lf b lg mz kd li lj na kg ll lm nb lo lp lq nc ls lt lu nd lw lx ly im bi translated">我们使用的表情符号在一定程度上可以描述我们的感受。我觉得将你之前看到的公式(即 TF-IDF +独特词汇)应用于<strong class="lf jd">表情符号</strong>会很有趣。换句话说，哪些表情符号是谁独有的，但也经常使用？</p><p id="9d87" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">我可以简单地获取原始信息并提取表情符号。然后，这是一种简单的方式来计算表情符号的数量并应用公式:</p><pre class="ks kt ku kv gt nf ng nh ni aw nj bi"><span id="85bb" class="nk mi it ng b gy nl nm l nn no">emoji.print_stats(unique_emoji, counts)</span></pre><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi of"><img src="../Images/62089f56886ecbb53e541db93b6f4a40.png" data-original-src="https://miro.medium.com/v2/resize:fit:502/format:webp/1*oj7vEdrilFQHTreWHP0LuA.png"/></div><figcaption class="nr ns gj gh gi nt nu bd b be z dk">Unique and frequently emojis per person.</figcaption></figure><p id="5fab" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">显然，我独特的表情符号更积极，而她的表情符号似乎是消极的。这并不一定意味着我使用更多积极的表情符号。这仅仅意味着她独特的表情符号倾向于更加消极。</p><p id="16c2" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">这些分析的自然结果是<strong class="lf jd">情绪</strong>。从我们的信息中可以看出我们之间的关系是否有所下降？首先，我们需要提取积极的信息。请确保通过以下方式创建一个包含情感得分的新列:</p><pre class="ks kt ku kv gt nf ng nh ni aw nj bi"><span id="848c" class="nk mi it ng b gy nl nm l nn no">from pattern.nl import sentiment  as sentiment_nl<br/>df['Sentiment'] = df.apply(lambda row: <br/>                           sentiment_nl(row.Message_Clean)[0], 1)</span></pre><p id="7b80" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">我决定不把情感步骤放在包里，因为有很多方法(和语言)来创造情感。也许你想使用不同的方法，而不是基于词典的方法。然后，我们可以计算平均每周情绪，并绘制结果:</p><pre class="ks kt ku kv gt nf ng nh ni aw nj bi"><span id="e6ff" class="nk mi it ng b gy nl nm l nn no">sentiment.plot_sentiment(df, colors=[‘#EAAA69’,’#5361A5'],     <br/>                         savefig=False)</span></pre><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi og"><img src="../Images/102396c05e29b104fd7d06c05f229953.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*e-VmbIsyBrtjD0Miq2kPbg.png"/></div></div><figcaption class="nr ns gj gh gi nt nu bd b be z dk">Our sentiment over time. The y-axis shows how happy or sad we communicated in that period.</figcaption></figure><p id="f84d" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">2018 年 1 月，我遭遇了一场事故，这解释了那段时间信息的负面性。</p><h1 id="cc82" class="mh mi it bd mj mk nx mm mn mo ny mq mr ki nz kj mt kl oa km mv ko ob kp mx my bi translated"><strong class="ak">基于情感的词云</strong></h1><p id="2fd0" class="pw-post-body-paragraph ld le it lf b lg mz kd li lj na kg ll lm nb lo lp lq nc ls lt lu nd lw lx ly im bi translated">词云通常用于演示哪些词在文档中频繁出现。经常出现的词比只出现几次的词大。</p><p id="c167" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">为了让云彩更有趣，我用情感将它们分开。积极的词语和消极的词语有着不同的含义:</p><pre class="ks kt ku kv gt nf ng nh ni aw nj bi"><span id="5bab" class="nk mi it ng b gy nl nm l nn no">(positive, <br/>negative) = wordcloud.extract_sentiment_count(counts, <br/>                                              user = "Me")</span><span id="fd6f" class="nk mi it ng b gy np nm l nn no">wordcloud.create_wordcloud(data=positive, cmap='Greens', <br/>                           mask='mask.jpg', <br/>                           stopwords='stopwords_dutch.txt',     <br/>                           random_state=42, max_words=1000,  <br/>                           max_font_size=50, scale=1.5, <br/>                           normalize_plurals=False,  <br/>                           relative_scaling=0.5)</span><span id="b844" class="nk mi it ng b gy np nm l nn no">wordcloud.create_wordcloud(data=negative, cmap='Reds', <br/>                           mask='mask.jpg', <br/>                           stopwords='stopwords_dutch.txt',     <br/>                           random_state=42, max_words=1000,  <br/>                           max_font_size=50, scale=1.5, <br/>                           normalize_plurals=False,  <br/>                           relative_scaling=0.5)</span></pre><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi oh"><img src="../Images/66d1a597f14036ebce2fb6edede64671.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*y-q_VJ8_BFGl_lHLO7uhHA.png"/></div></div><figcaption class="nr ns gj gh gi nt nu bd b be z dk">Sentiment-based Word Clouds for my messages.</figcaption></figure><p id="3bfc" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">这些单词是基于<em class="ne">模式</em>包中的现有词典选择的。我们通常使用的正面词汇是<em class="ne"> goed </em>(好)和<em class="ne"> super </em>(超级)。负面词有<em class="ne"> laat </em>(后期)和<em class="ne"> verschrikkelijk </em>(恐怖)。有趣的是，我发现有些词被贴上了负面标签，而我并没有这样使用它们。例如，我通常使用<em class="ne">waanzining</em>(疯狂)作为<em class="ne"> very </em>来强调某些单词。</p><h1 id="fe48" class="mh mi it bd mj mk nx mm mn mo ny mq mr ki nz kj mt kl oa km mv ko ob kp mx my bi translated"><strong class="ak">主题建模</strong></h1><p id="5d76" class="pw-post-body-paragraph ld le it lf b lg mz kd li lj na kg ll lm nb lo lp lq nc ls lt lu nd lw lx ly im bi translated">主题建模是一种试图从文本文档中提取主题的工具。一组文档可能包含用户可能感兴趣的多个主题。一个主题由一组单词表示。例如，一个主题可能包含单词<em class="ne">狗</em>、<em class="ne">猫</em>和<em class="ne">马。</em>根据这些话，好像题目是关于动物的。</p><p id="9cca" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">我在 SOAN 实现了两个创建主题的算法，即 LDA(潜在狄利克雷分配)和 NMF(非负矩阵分解)。NMF 使用线性代数来创建主题，而 LDA 基于概率建模。查看<a class="ae lz" href="https://medium.com/ml2vec/topic-modeling-is-an-unsupervised-learning-approach-to-clustering-documents-to-discover-topics-fdfbf30e27df" rel="noopener">这篇</a>帖子，获取对模型的深入解释。</p><p id="7ee2" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">我决定删除对两个模型的参数进行工作的选项，因为它旨在给出可能的主题的快速概述。它为每个用户分别运行模型:</p><pre class="ks kt ku kv gt nf ng nh ni aw nj bi"><span id="ddf9" class="nk mi it ng b gy nl nm l nn no">topic.topics(df, model='lda', stopwords='stopwords_dutch.txt')<br/>topic.topics(df, model='nmf', stopwords='stopwords_dutch.txt')</span></pre><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi oi"><img src="../Images/886b5685b560159d8c4e2a4da30da45f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*4Sxn7H4D86_nvtjLksC3Ww.png"/></div></div><figcaption class="nr ns gj gh gi nt nu bd b be z dk">Topics generated per person using LDA and NMF</figcaption></figure><p id="265d" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">在生成的主题中你能看到的(如果你能读懂荷兰语)是可以找到描述做杂货的主题。也有相当多的话题在某种程度上描述了第二天见面或说晚安。这是有意义的，因为我们大部分的信息都是在我们不住在一起的时候发出的。</p><p id="3e50" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">使用主题建模的缺点是用户需要自己解释主题。它还可能需要调整参数来找到高质量的主题。</p></div><div class="ab cl ma mb hx mc" role="separator"><span class="md bw bk me mf mg"/><span class="md bw bk me mf mg"/><span class="md bw bk me mf"/></div><div class="im in io ip iq"><h1 id="02b4" class="mh mi it bd mj mk ml mm mn mo mp mq mr ki ms kj mt kl mu km mv ko mw kp mx my bi translated">感谢您的阅读！</h1><p id="fedd" class="pw-post-body-paragraph ld le it lf b lg mz kd li lj na kg ll lm nb lo lp lq nc ls lt lu nd lw lx ly im bi translated">如果你和我一样，对人工智能、数据科学或心理学充满热情，请随时在<a class="ae lz" href="https://www.linkedin.com/in/mgrootendorst/" rel="noopener ugc nofollow" target="_blank"> LinkedIn </a>上添加我，或者在<a class="ae lz" href="https://twitter.com/MaartenGr" rel="noopener ugc nofollow" target="_blank"> Twitter </a>上关注我。</p><p id="a6a4" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">如果您想全面了解代码，请务必访问<a class="ae lz" href="https://github.com/MaartenGr/soan/blob/master/soan.ipynb" rel="noopener ugc nofollow" target="_blank">笔记本</a>！你可以通过这个链接简单地获取代码并添加你自己的 WhatsApp.txt 文件。</p></div></div>    
</body>
</html>