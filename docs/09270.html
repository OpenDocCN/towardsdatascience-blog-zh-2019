<html>
<head>
<title>Visualizing the Fundamentals of Convolutional Neural Networks</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">可视化卷积神经网络的基础</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/visualizing-the-fundamentals-of-convolutional-neural-networks-6021e5b07f69?source=collection_archive---------7-----------------------#2019-12-08">https://towardsdatascience.com/visualizing-the-fundamentals-of-convolutional-neural-networks-6021e5b07f69?source=collection_archive---------7-----------------------#2019-12-08</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><figure class="ip iq gp gr ir is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi io"><img src="../Images/ca3c500e0678b2a2811f70a0869a28b0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*GKLAU4BFmXE87F1rDjV5dA.jpeg"/></div></div><figcaption class="iz ja gj gh gi jb jc bd b be z dk">Photo by <a class="ae jd" href="https://unsplash.com/@pactovisual?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank">Pacto Visual</a> on <a class="ae jd" href="https://unsplash.com/?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><div class=""/><div class=""><h2 id="36e3" class="pw-subtitle-paragraph kd jf jg bd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku dk translated">通过可视化示例理解卷积神经网络背后的主要概念</h2></div><h1 id="4366" class="kv kw jg bd kx ky kz la lb lc ld le lf km lg kn lh kp li kq lj ks lk kt ll lm bi translated">什么是卷积神经网络？</h1><p id="6317" class="pw-post-body-paragraph ln lo jg lp b lq lr kh ls lt lu kk lv lw lx ly lz ma mb mc md me mf mg mh mi ij bi translated">卷积神经网络(CNN)是人工神经网络(ann)的一个子类型，主要用于图像分类。CNN 遵循能够识别模式的结构复制的生物学原理，以识别不同位置的这些模式。它的灵感来自于诺贝尔奖获得者 Hubel 和 Wiesel 在 1962 年发表的“<a class="ae jd" href="https://www.ncbi.nlm.nih.gov/pubmed/14449617" rel="noopener ugc nofollow" target="_blank">猫的视觉皮层</a>中的感受野、双目互动和功能结构”中提出的猫的视觉系统模型。运用这一灵感的作品之一是 1980 年福岛的<a class="ae jd" href="https://www.rctn.org/bruno/public/papers/Fukushima1980.pdf" rel="noopener ugc nofollow" target="_blank">新认知图</a>，尽管当时没有使用<strong class="lp jh">卷积</strong>这个词。所以，CNN 在图像识别上非常成功，不是巧合。然而，它们在处理时间数据方面也表现出了良好的效果，例如<a class="ae jd" href="https://arxiv.org/pdf/1703.04691.pdf" rel="noopener ugc nofollow" target="_blank">时间序列</a>和<a class="ae jd" href="https://ieeexplore.ieee.org/document/6857341?reload=true" rel="noopener ugc nofollow" target="_blank">语音识别</a>，甚至在应用于<a class="ae jd" rel="noopener" target="_blank" href="/how-to-do-deep-learning-on-graphs-with-graph-convolutional-networks-7d2250723780">图形</a>时也是如此。<br/><br/>CNN 在以大约 10%的优势赢得 2012 年比赛<a class="ae jd" href="http://www.image-net.org/challenges/LSVRC/" rel="noopener ugc nofollow" target="_blank"> Imagenet 大规模视觉识别挑战赛</a>后变得非常受欢迎。<a class="ae jd" href="https://qz.com/1307091/the-inside-story-of-how-ai-got-good-enough-to-dominate-silicon-valley/" rel="noopener ugc nofollow" target="_blank"> Alex Krizhevsky </a>和 Ilya Sutskever 在<a class="ae jd" href="https://en.wikipedia.org/wiki/Geoffrey_Hinton" rel="noopener ugc nofollow" target="_blank"> Geoffrey Hinton </a>的指导下，提交了以“AlexNet”为名而成名的 CNN 架构。当时，杰弗里·辛顿已经在人工神经网络领域做出了重大的科学贡献。他是 1986 年<a class="ae jd" href="https://web.stanford.edu/class/psych209a/ReadingsByDate/02_06/PDPVolIChapter8.pdf" rel="noopener ugc nofollow" target="_blank">反向传播</a>算法和 1983 年玻尔兹曼机器的贡献者之一。这些就是杰弗里·辛顿被公认为深度学习之父的部分原因。</p><h1 id="2b4f" class="kv kw jg bd kx ky kz la lb lc ld le lf km lg kn lh kp li kq lj ks lk kt ll lm bi translated">卷积或互相关</h1><p id="8183" class="pw-post-body-paragraph ln lo jg lp b lq lr kh ls lt lu kk lv lw lx ly lz ma mb mc md me mf mg mh mi ij bi translated">典型的 CNN 由一系列充当特征提取器的卷积层组成，后面是一个分类器，通常是一个<a class="ae jd" href="https://deepai.org/machine-learning-glossary-and-terms/multilayer-perceptron" rel="noopener ugc nofollow" target="_blank">多层感知器(MLP) </a>，也称为全连接层(FC 层)，如图 1 所示。</p><figure class="mk ml mm mn gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi mj"><img src="../Images/3f46eb6ca0a542dac02b6fbd6a4557c3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Vior6yy6_qN5rBv5Os0kGA.png"/></div></div><figcaption class="iz ja gj gh gi jb jc bd b be z dk"><strong class="bd mo">Figure 1</strong> — Architecture of a basic Convolutional Neural Network.</figcaption></figure><p id="f27d" class="pw-post-body-paragraph ln lo jg lp b lq mp kh ls lt mq kk lv lw mr ly lz ma ms mc md me mt mg mh mi ij bi translated">第一层接收用三个颜色通道(RGB 通道)表示的输入图像。然后，第一层用多个核执行输入图像的卷积，产生第一层的一组<strong class="lp jh">特征图</strong>。每个特征图确定特定特征的强度和位置。由卷积层提取的特征图可以被提交给称为汇集的下采样操作。汇集操作是可选的，因此它可能不会遵循每个卷积层。合并图层的结果是另一组要素地图，地图数量相同，但分辨率降低。下面的卷积层使用来自前一层的特征图来执行更多的卷积并生成新的特征图。来自最后层的特征图是分类器，FC 层的输入。</p><p id="d31c" class="pw-post-body-paragraph ln lo jg lp b lq mp kh ls lt mq kk lv lw mr ly lz ma ms mc md me mt mg mh mi ij bi translated">用星号表示的卷积运算可以描述为:</p><figure class="mk ml mm mn gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi mu"><img src="../Images/a55c3e0bd75ef74da835bd828ee20565.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*MV9gJnxrLjDxaWzHvMA74w@2x.png"/></div></div></figure><p id="66a1" class="pw-post-body-paragraph ln lo jg lp b lq mp kh ls lt mq kk lv lw mr ly lz ma ms mc md me mt mg mh mi ij bi translated">被𝑥某种类型的输入，如传感器信号，𝑡给定的时间，和𝑘的内核应用。</p><p id="80b7" class="pw-post-body-paragraph ln lo jg lp b lq mp kh ls lt mq kk lv lw mr ly lz ma ms mc md me mt mg mh mi ij bi translated">卷积运算的一个重要性质是它是可交换的，这意味着(𝑥∗ 𝑘)=( 𝑘∗𝑥)如下:</p><figure class="mk ml mm mn gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi mu"><img src="../Images/6a8590b30e732bc3b8603e62f20eb624.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*vFZg3C8KqYAcaspMeYwf7A@2x.png"/></div></div></figure><p id="05a7" class="pw-post-body-paragraph ln lo jg lp b lq mp kh ls lt mq kk lv lw mr ly lz ma ms mc md me mt mg mh mi ij bi translated">另一方面，由⋆(五角星)表示的互相关运算是不可交换的，可以描述为:</p><figure class="mk ml mm mn gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi mu"><img src="../Images/2f6ab16cc3874cc9c53efa0a69a90669.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*hf43MOEKYX1g5rd4nLhR-Q@2x.png"/></div></div></figure><p id="9bc2" class="pw-post-body-paragraph ln lo jg lp b lq mp kh ls lt mq kk lv lw mr ly lz ma ms mc md me mt mg mh mi ij bi translated">卷积的可交换性来自于内核相对于输入翻转的事实。这种翻转是索引操作的结果。请注意，输入𝑥的索引是𝑎，内核的索引是𝑡−𝑎.尽管可交换性对于编写数学证明是一个有价值的属性，但它与神经网络实现并不相关。事实上，许多机器学习库实现了互相关而不是卷积，并将这两种操作都称为卷积。因此，在训练期间学习的内核与实际实现如等式 1 所述的卷积的库相比将被翻转。在本文中，我们将遵循同样的惯例，称之为互相关卷积。</p><p id="0eff" class="pw-post-body-paragraph ln lo jg lp b lq mp kh ls lt mq kk lv lw mr ly lz ma ms mc md me mt mg mh mi ij bi translated">我们可以将等式 3 用于与 2D 数据(例如灰度图像)的卷积:</p><figure class="mk ml mm mn gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi mu"><img src="../Images/521c4181ceb60ac63f6e670ec2eecd6b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*SZV8-C3QSMEpZMtvm-h9ng@2x.png"/></div></div></figure><p id="825b" class="pw-post-body-paragraph ln lo jg lp b lq mp kh ls lt mq kk lv lw mr ly lz ma ms mc md me mt mg mh mi ij bi translated">是𝑟[𝑖,𝑗]卷积的离散输出，ℎ是核的高度，𝑤是核的宽度，𝑥[𝑎,𝑏]是灰度图像的补片，而𝑘[𝑖+𝑎，𝑗+𝑏]是核。</p><p id="85d4" class="pw-post-body-paragraph ln lo jg lp b lq mp kh ls lt mq kk lv lw mr ly lz ma ms mc md me mt mg mh mi ij bi translated">换句话说，卷积运算从图像中提取多个像素片，然后乘以内核。内核基本上是一个权重矩阵。从图像中提取的像素块通常被称为<strong class="lp jh">感受野</strong>——在生物学中，感受野是刺激神经元的感觉区域。感受野和内核之间的乘法包括每个像素和内核的相应元素之间的逐元素乘法。在乘法之后，结果被相加以形成特征图的一个元素，由𝑟[𝑖,𝑗].在等式 4 中定义</p><p id="7844" class="pw-post-body-paragraph ln lo jg lp b lq mp kh ls lt mq kk lv lw mr ly lz ma ms mc md me mt mg mh mi ij bi translated">以下动画显示了 5x5 灰度图像和 3x3 内核之间的卷积运算。感受野用红色方块突出显示。该卷积的输出是 3×3 特征图。</p><figure class="mk ml mm mn gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi mv"><img src="../Images/73f1df8d973ee6cd70b762ff4ad3e5ff.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/1*cfO8kMdUGG-X33TZa2h-vQ.gif"/></div></div><figcaption class="iz ja gj gh gi jb jc bd b be z dk"><strong class="bd mo">Figure 2</strong> — Step-by-step of the convolution of a 5x5 image with a 3x3 kernel.</figcaption></figure><p id="0f95" class="pw-post-body-paragraph ln lo jg lp b lq mp kh ls lt mq kk lv lw mr ly lz ma ms mc md me mt mg mh mi ij bi translated">动画中使用的实际图像可以在下面的图 3 中看到。内核和特征图中的值被重新缩放以适合 0 到 255 之间的区间，从而被表示为灰度像素。图像中较亮的像素代表卷积的较高值，而较暗的像素代表较低值。</p><figure class="mk ml mm mn gt is gh gi paragraph-image"><div class="gh gi mw"><img src="../Images/b3a36138f12d8277a3b7a1706ac99a7c.png" data-original-src="https://miro.medium.com/v2/resize:fit:776/format:webp/1*VGwtxUdUFOPjgv0kqRhxxw.png"/></div><figcaption class="iz ja gj gh gi jb jc bd b be z dk"><strong class="bd mo">Figure 3</strong> — Convolution of a 5x5 input with a 3x3 kernel.</figcaption></figure><p id="397b" class="pw-post-body-paragraph ln lo jg lp b lq mp kh ls lt mq kk lv lw mr ly lz ma ms mc md me mt mg mh mi ij bi translated">上面的卷积使用核 3x3，因此，在输入中有九个可能的感受野，每个大小为 3x3。注意，主要由白色像素组成的感受野或主要由暗像素组成的感受野在卷积后会产生非常暗的像素。另一方面，由左边的三个亮像素、中间的中间像素和右边的暗像素组成的感受域在卷积后产生最亮的像素。这是因为这种类型的内核有助于突出显示边缘，特别是从左侧亮区域过渡到右侧暗区域的边缘。</p><p id="3059" class="pw-post-body-paragraph ln lo jg lp b lq mp kh ls lt mq kk lv lw mr ly lz ma ms mc md me mt mg mh mi ij bi translated">现在，看看当我们将相同的内核应用到一个也包含相反过渡的图像时会发生什么，从左边的暗区域到右边的亮区域。在图 4 中，感受野呈现从暗到亮的过渡，导致最暗的像素。请注意，之前的过渡(从亮到暗)仍然会产生更亮的像素。这意味着该内核不仅检测从亮到暗转变的边缘，还检测相反的从暗到亮的边缘。一种类型的边产生最大的正值，而另一种类型的边产生最大的负值。</p><figure class="mk ml mm mn gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi mx"><img src="../Images/0aab54600bbabe5b527ba2d38e5bd26a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*y3xS3tge7sPQxZvSQLABTw.png"/></div></div><figcaption class="iz ja gj gh gi jb jc bd b be z dk"><strong class="bd mo">Figure 4</strong> — Convolution of an image 17x17 with an edge detector kernel 3x3.</figcaption></figure><p id="1be7" class="pw-post-body-paragraph ln lo jg lp b lq mp kh ls lt mq kk lv lw mr ly lz ma ms mc md me mt mg mh mi ij bi translated">RGB 图像的卷积与灰度图像非常相似。等式 4 可以适用于 RGB 图像，增加另一个循环来迭代 RGB 通道，如下所示:</p><figure class="mk ml mm mn gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi mu"><img src="../Images/7f17e4f1826a6e18c8ac05f4175ac37f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*iz3LHOPbRMIKv3QUXkYQ_g@2x.png"/></div></div></figure><p id="68a9" class="pw-post-body-paragraph ln lo jg lp b lq mp kh ls lt mq kk lv lw mr ly lz ma ms mc md me mt mg mh mi ij bi translated">可变𝑐上的附加循环允许在信道 RBG 上迭代。结果，求和是在三维数据上完成的，而不是在二维数据上，并且仍然产生每个三维感受野和核的单个值。</p><h1 id="7f3b" class="kv kw jg bd kx ky kz la lb lc ld le lf km lg kn lh kp li kq lj ks lk kt ll lm bi translated">特征抽出</h1><p id="9c49" class="pw-post-body-paragraph ln lo jg lp b lq lr kh ls lt lu kk lv lw lx ly lz ma mb mc md me mf mg mh mi ij bi translated">让我们从一个实际的例子开始这个话题。请看图 5 中下面三个卷积的结果。为了说明卷积的结果，以下示例中的三个核中的每一个都由从图像中提取的小块组成。</p><figure class="mk ml mm mn gt is gh gi paragraph-image"><div class="gh gi my"><img src="../Images/7435e5e400115c0d28d34afadccffdda.png" data-original-src="https://miro.medium.com/v2/resize:fit:1226/format:webp/1*VfO7MkIaFC9vPIlj6P6uXQ.png"/></div></figure><figure class="mk ml mm mn gt is gh gi paragraph-image"><div class="gh gi my"><img src="../Images/c4b177c06ba732587f365197ee83ba5b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1226/format:webp/1*TEVKDVl-cTMfF2mWvfCtzg.png"/></div></figure><figure class="mk ml mm mn gt is gh gi paragraph-image"><div class="gh gi my"><img src="../Images/daa4856d4f0794de8223f2f00c16e55e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1226/format:webp/1*yS7kngwne2hoNe-qdb0Wug.png"/></div><figcaption class="iz ja gj gh gi jb jc bd b be z dk"><strong class="bd mo">Figure 5 — </strong>Examples of convolutions.</figcaption></figure><p id="556f" class="pw-post-body-paragraph ln lo jg lp b lq mp kh ls lt mq kk lv lw mr ly lz ma ms mc md me mt mg mh mi ij bi translated">在第一个例子中，组成内核的面片包括带有白色数字 6 的平面区域。右边的灰度图像本质上是内核和图像之间卷积的结果。最暗的像素代表感受野和内核之间操作的最小结果，另一方面，最亮的像素代表感受野和内核之间操作的最高值。</p><p id="089e" class="pw-post-body-paragraph ln lo jg lp b lq mp kh ls lt mq kk lv lw mr ly lz ma ms mc md me mt mg mh mi ij bi translated">在第二个例子中，内核由形成飞机轮子的像素片组成。在第三个例子中，内核由从飞机尾部复制的一片黄色像素组成。</p><p id="ff32" class="pw-post-body-paragraph ln lo jg lp b lq mp kh ls lt mq kk lv lw mr ly lz ma ms mc md me mt mg mh mi ij bi translated">请注意，每个结果图像中最亮的像素对应于产生每个内核的位置。在第一个示例中，它对应于数字 6 的位置。在第二个例子中，它对应于轮子的位置。尽管内核是其中一个轮子的副本，另一个轮子非常相似，也产生了明亮的像素。在第三个例子中，最亮的像素对应于平面的所有黄色区域。</p><h2 id="9ddc" class="mz kw jg bd kx na nb dn lb nc nd dp lf lw ne nf lh ma ng nh lj me ni nj ll nk bi translated">进展</h2><p id="3ce0" class="pw-post-body-paragraph ln lo jg lp b lq lr kh ls lt lu kk lv lw lx ly lz ma mb mc md me mf mg mh mi ij bi translated">步幅是每个感受野之间的距离。到目前为止，我们展示的所有例子都使用了一个步长。采用如此小的步幅导致感受野之间的大重叠。结果，许多信息在相邻的感受野重复出现，如图 6 所示。</p><figure class="mk ml mm mn gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi nl"><img src="../Images/b086364fff00bc3b78258bb9776d4768.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*xHeKopE35qOILX4XaveTbQ.png"/></div></div><figcaption class="iz ja gj gh gi jb jc bd b be z dk"><strong class="bd mo">Figure 6</strong> –Receptive fields with stride 1.</figcaption></figure><p id="1c40" class="pw-post-body-paragraph ln lo jg lp b lq mp kh ls lt mq kk lv lw mr ly lz ma ms mc md me mt mg mh mi ij bi translated">在 3×3 大小的核的情况下，步长为 2 的采用导致一列或一行与相邻感受野重叠。这种重叠是为了保证步幅不会跳过重要信息。</p><p id="1c38" class="pw-post-body-paragraph ln lo jg lp b lq mp kh ls lt mq kk lv lw mr ly lz ma ms mc md me mt mg mh mi ij bi translated">增加步距将减少卷积的计算成本。如果我们将步距从 1 改为 2，计算成本的减少大约是 4。这是因为步幅影响了二维感受野之间的距离。类似地，如果我们将步幅增加三倍，我们可以预期计算成本降低大约九倍。计算成本降低，因为步幅的增加减少了从输入中提取的感受野的数量，因此，输出的维度也减少了。</p><p id="47ce" class="pw-post-body-paragraph ln lo jg lp b lq mp kh ls lt mq kk lv lw mr ly lz ma ms mc md me mt mg mh mi ij bi translated">图 7 显示了步长为 2、4、8 和 16 的四种卷积结果。卷积中使用的内核大小是 70x70。请注意，将步幅增加两倍，执行时间会减少近四倍。</p><figure class="mk ml mm mn gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi nm"><img src="../Images/67b4c07082e33cef24ed1b8f05527c2a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*dXGr3nt7ZRDLg1HWYQE_IA.png"/></div></div></figure><figure class="mk ml mm mn gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi nm"><img src="../Images/9156ef2fb6b924c820d2a97b0c5f19c4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*sMyAv0ELBhoIW5AKtN6XQQ.png"/></div></div><figcaption class="iz ja gj gh gi jb jc bd b be z dk"><strong class="bd mo">Figure 7</strong> — Examples of stride 2, 4, 8, and 16. The receptive field dimension is 70x70.</figcaption></figure><p id="06e8" class="pw-post-body-paragraph ln lo jg lp b lq mp kh ls lt mq kk lv lw mr ly lz ma ms mc md me mt mg mh mi ij bi translated">在图 7 中，步长为 16 的卷积结果比步长为 8 的卷积结果少 4 倍的像素。注意，采用 16 的步幅导致 54 行或列的重叠，因为感受野大小是 70×70。步长为 16 时，仍有可能通过平面轮中最亮的像素来识别卷积的最高值。</p><h1 id="a83a" class="kv kw jg bd kx ky kz la lb lc ld le lf km lg kn lh kp li kq lj ks lk kt ll lm bi translated">正向传播</h1><p id="1ce4" class="pw-post-body-paragraph ln lo jg lp b lq lr kh ls lt lu kk lv lw lx ly lz ma mb mc md me mf mg mh mi ij bi translated">在本节中，我们将研究前向传播在卷积层中的工作原理。为此，我们将了解单个卷积层是如何工作的，然后了解多个卷积层是如何协同工作的。在这项研究中，我们将学习两个新概念:非线性激活和池操作。</p><h2 id="aa21" class="mz kw jg bd kx na nb dn lb nc nd dp lf lw ne nf lh ma ng nh lj me ni nj ll nk bi translated">在卷积层中</h2><p id="a5b0" class="pw-post-body-paragraph ln lo jg lp b lq lr kh ls lt lu kk lv lw lx ly lz ma mb mc md me mf mg mh mi ij bi translated">图 8 显示了典型卷积层中的前向传播，它包括三个阶段:卷积、非线性激活和池化。卷积运算已经在第一节中讨论过了。现在，我们将看到其他两个操作。</p><figure class="mk ml mm mn gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi nn"><img src="../Images/83b7a5b940b36ac236908d0befdcc996.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*68-rxF2WEDMCwXtw3U2Hqg.png"/></div></div><figcaption class="iz ja gj gh gi jb jc bd b be z dk"><strong class="bd mo">Figure 8</strong> — The three stages of a convolutional layer.</figcaption></figure><p id="5b21" class="pw-post-body-paragraph ln lo jg lp b lq mp kh ls lt mq kk lv lw mr ly lz ma ms mc md me mt mg mh mi ij bi translated">非线性激活也被称为检测器阶段。在这个阶段，卷积和偏差的结果被提交给非线性激活，例如 ReLU 函数。非线性激活不会改变特征图的尺寸，它只会调整其中的值。</p><h2 id="f0a0" class="mz kw jg bd kx na nb dn lb nc nd dp lf lw ne nf lh ma ng nh lj me ni nj ll nk bi translated">非线性激活</h2><p id="85b6" class="pw-post-body-paragraph ln lo jg lp b lq lr kh ls lt lu kk lv lw lx ly lz ma mb mc md me mf mg mh mi ij bi translated">一、什么是线性激活？线性激活是遵循规则 f(x)=ax 的函数，其中 a 是常数，x 是变量。它的图形是一条穿过原点(0，0)的直线。意味着形状 f(x)=ax + b 中的函数，其中 a 和 b 是常数，<a class="ae jd" href="https://mathinsight.org/linear_function_one_variable" rel="noopener ugc nofollow" target="_blank">不是线性的</a>。两者都是仿射函数，但只有一个常数乘以变量的函数是线性函数。</p><p id="33c5" class="pw-post-body-paragraph ln lo jg lp b lq mp kh ls lt mq kk lv lw mr ly lz ma ms mc md me mt mg mh mi ij bi translated">对于一个线性函数，当我们把输入乘以一个常数𝛼时，我们也应该看到输出乘以同一个常数𝛼.这意味着:</p><figure class="mk ml mm mn gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi mu"><img src="../Images/663a672e8e90d629bafbc1dc20e5457c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*YKLUnOQw8fMzPnjTv28bMA@2x.png"/></div></div></figure><p id="3650" class="pw-post-body-paragraph ln lo jg lp b lq mp kh ls lt mq kk lv lw mr ly lz ma ms mc md me mt mg mh mi ij bi translated">另一个要求是，当我们在线性函数中应用两个输入的和时，我们应该得到分别应用于该函数的两个变量的和的输出当量:</p><figure class="mk ml mm mn gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi no"><img src="../Images/50bc3e1edd2da019768fa208123aac57.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*mARvgq7arxRZJLUBQLdhBw@2x.png"/></div></div></figure><p id="55c2" class="pw-post-body-paragraph ln lo jg lp b lq mp kh ls lt mq kk lv lw mr ly lz ma ms mc md me mt mg mh mi ij bi translated">那么，我们为什么要使用非线性激活呢？因为当我们在线性函数中应用线性组合(加法或乘法)时，结果也是线性的。尽管许多模型可以用线性模型粗略地近似，但在人工神经网络中使用非线性使得它能够表示线性和非线性模型。换句话说，非线性使人工神经网络成为更强大的函数逼近器。</p><p id="b5bb" class="pw-post-body-paragraph ln lo jg lp b lq mp kh ls lt mq kk lv lw mr ly lz ma ms mc md me mt mg mh mi ij bi translated">深度学习中最常用的非线性激活之一是 ReLU 函数，它代表整流线性单元。该函数由下式给出:</p><figure class="mk ml mm mn gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi mu"><img src="../Images/b78f2af996d18b83c861b4ca3a0f31c0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*FI_BCs0gsYW4bFfc73XdoQ@2x.png"/></div></div></figure><p id="0d93" class="pw-post-body-paragraph ln lo jg lp b lq mp kh ls lt mq kk lv lw mr ly lz ma ms mc md me mt mg mh mi ij bi translated">该函数在有偏置的情况下，会产生如图 9 所示的图形。</p><figure class="mk ml mm mn gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi np"><img src="../Images/8e4442c604c64e7b527defd0a61e325d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*g6hN0KVDEpnSuY387jUAbg.png"/></div></div><figcaption class="iz ja gj gh gi jb jc bd b be z dk">Figure 9 — The graph of ReLU function.</figcaption></figure><p id="ac6b" class="pw-post-body-paragraph ln lo jg lp b lq mp kh ls lt mq kk lv lw mr ly lz ma ms mc md me mt mg mh mi ij bi translated">图 10 显示了 ReLU 如何调制卷积的结果。这里，来自图 2 的相同结果被用于应用 ReLU 函数。</p><figure class="mk ml mm mn gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi nq"><img src="../Images/a229363e68ae52226f574ca349ef0e0d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*6NBF_T7DTqLepRfgmVVHCg.png"/></div></div><figcaption class="iz ja gj gh gi jb jc bd b be z dk"><strong class="bd mo">Figure 10 </strong>— ReLU function applied after the convolution.</figcaption></figure><p id="4142" class="pw-post-body-paragraph ln lo jg lp b lq mp kh ls lt mq kk lv lw mr ly lz ma ms mc md me mt mg mh mi ij bi translated">上例中使用的 ReLU 函数的等效图像如图 11 所示。请注意，一些中间值被涂黑，突出显示了最亮的三个像素。</p><figure class="mk ml mm mn gt is gh gi paragraph-image"><div class="gh gi nr"><img src="../Images/a007f3e05452fe2c1062d28786fa64cc.png" data-original-src="https://miro.medium.com/v2/resize:fit:914/format:webp/1*RQccJVQpNwQDv-PAHVNMxA.png"/></div><figcaption class="iz ja gj gh gi jb jc bd b be z dk"><strong class="bd mo">Figure 11</strong> — Visual representation of the ReLU function applied after the convolution.</figcaption></figure><p id="26d1" class="pw-post-body-paragraph ln lo jg lp b lq mp kh ls lt mq kk lv lw mr ly lz ma ms mc md me mt mg mh mi ij bi translated">接下来，在图 12 中，您可以看到 ReLU 函数中的一些偏置选项。该函数将平面与包含车轮的图像面片的卷积结果作为输入。请注意，偏差就像一个阈值，决定显示什么和不显示什么。</p><figure class="mk ml mm mn gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi nm"><img src="../Images/0698046718fbec11484802b980904921.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*d84G-pRg2RKbt8WGVCM15w.png"/></div></div></figure><figure class="mk ml mm mn gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi nm"><img src="../Images/151c5bc5ce6041d189470f6539c009bc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*dSN-SKdsOOkd-2ixS3q1CQ.png"/></div></div><figcaption class="iz ja gj gh gi jb jc bd b be z dk"><strong class="bd mo">Figure 12 </strong>— Different values of bias applied to the same result of the convolution between the plane and a patch of the image containing the wheel.</figcaption></figure><p id="8112" class="pw-post-body-paragraph ln lo jg lp b lq mp kh ls lt mq kk lv lw mr ly lz ma ms mc md me mt mg mh mi ij bi translated">图 12 中描绘的阈值行为类似于生物神经元，当它接收到低于某个阈值的刺激时<a class="ae jd" href="https://www.britannica.com/science/nervous-system/The-neuronal-membrane" rel="noopener ugc nofollow" target="_blank">不会触发。如果刺激超过阈值，神经元就开始放电，并且随着刺激的增加，放电频率也会增加。在图 12 中，当偏差为 500 时，它有助于人工神经元的活动。然而，如果我们将偏差定义为-1000，人工神经元只会在最强的刺激下激发。</a></p><p id="7266" class="pw-post-body-paragraph ln lo jg lp b lq mp kh ls lt mq kk lv lw mr ly lz ma ms mc md me mt mg mh mi ij bi translated">总之，ReLU 功能就像一个人工神经元。这就是为什么这个阶段被称为检测阶段。ReLU 函数负责检测由内核提取的特征的存在。因此，每个内核都有一个偏差，因为每个特性需要不同的阈值。</p><h2 id="aa83" class="mz kw jg bd kx na nb dn lb nc nd dp lf lw ne nf lh ma ng nh lj me ni nj ll nk bi translated">联营</h2><p id="a7a0" class="pw-post-body-paragraph ln lo jg lp b lq lr kh ls lt lu kk lv lw lx ly lz ma mb mc md me mf mg mh mi ij bi translated">最后，但不是最不重要的，池操作。它是对每个特征地图执行的缩减采样操作。它从特征图中提取感受野并用单个值替换它。这个单一值可以通过不同的聚集标准获得，例如根据距感受野中心的距离的最大值、平均值或加权平均值。</p><p id="3ef0" class="pw-post-body-paragraph ln lo jg lp b lq mp kh ls lt mq kk lv lw mr ly lz ma ms mc md me mt mg mh mi ij bi translated">除了聚集标准之外，在汇集操作中还有另外两个超参数，感受野的大小和步幅。</p><p id="589b" class="pw-post-body-paragraph ln lo jg lp b lq mp kh ls lt mq kk lv lw mr ly lz ma ms mc md me mt mg mh mi ij bi translated">与 stride 类似，池化操作导致卷积处理的数据更少。一个区别是，汇集操作不是跳过数据，而是试图将感受域总结成一个值。另一个不同之处在于，跨距是在卷积之前应用的，而池是在卷积的结果上应用的，从而减少了下一层的数据量。此外，汇集操作的感受域是二维的，因为它被单独应用于每个特征图，而卷积的感受域是三维的，包括一层中所有特征图的一部分。</p><p id="109f" class="pw-post-body-paragraph ln lo jg lp b lq mp kh ls lt mq kk lv lw mr ly lz ma ms mc md me mt mg mh mi ij bi translated">汇集操作的一个期望的副作用是<a class="ae jd" href="https://www.di.ens.fr/willow/pdfs/icml2010b.pdf" rel="noopener ugc nofollow" target="_blank">增加了网络对输入的平移</a>的不变性。随着更多卷积层之后是汇集层，这种效应被放大。</p><p id="8ba0" class="pw-post-body-paragraph ln lo jg lp b lq mp kh ls lt mq kk lv lw mr ly lz ma ms mc md me mt mg mh mi ij bi translated">图 13 显示了值通过两个池层的传播，池大小为 3x3，跨距为 2。在输入要素地图的蓝色区域中的任何激活都会影响池 1 结果中的蓝色区域。类似地，在汇集 1 的结果中被蓝色覆盖的区域中的激活影响在汇集 2 的结果中被蓝色覆盖的区域。绿色区域之间的关系也是如此。</p><figure class="mk ml mm mn gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi ns"><img src="../Images/725ac13fb61dc17425a5df05e64b85a7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*vUYHAlcURCBK9horaqBoTA.png"/></div></div><figcaption class="iz ja gj gh gi jb jc bd b be z dk"><strong class="bd mo">Figure 13</strong>–Propagation of values through pooling layers with pooling size 3x3 and stride of 2. In this example, the convolutional layers were omitted for clarity.</figcaption></figure><p id="5d96" class="pw-post-body-paragraph ln lo jg lp b lq mp kh ls lt mq kk lv lw mr ly lz ma ms mc md me mt mg mh mi ij bi translated">考虑到图 13 中的池是最大池，最高值出现在输入特征图中蓝色区域的哪个位置并不重要，因为它将以同样的方式传播到结果池 2 中的蓝色激活。这就是合并图层增强平移不变性的原因，输入中的小平移不会改变输出中的值。</p><p id="6d08" class="pw-post-body-paragraph ln lo jg lp b lq mp kh ls lt mq kk lv lw mr ly lz ma ms mc md me mt mg mh mi ij bi translated">图 14 显示了卷积步长、ReLU 函数偏差、合并大小和合并步长的不同组合的效果。在左边，有三个步幅的例子:2、9 和 16。对于步幅的每个选项，有三个偏差示例:500、-250 和-1000。对于每种偏差，有三个汇集大小和步幅的示例:汇集大小为 3×3，步幅为 2，汇集大小为 5×5，步幅为 3，汇集大小为 7×7，步幅为 4×4。</p><figure class="mk ml mm mn gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi nt"><img src="../Images/3a03834a79f428b7a33cba4e288e1794.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*pj-erX7mbHFG0x30kIinHg.png"/></div></div><figcaption class="iz ja gj gh gi jb jc bd b be z dk"><strong class="bd mo">Figure 14</strong>–Effects of different hyperparameters in convolution, ReLU and max pooling.</figcaption></figure><p id="8ad2" class="pw-post-body-paragraph ln lo jg lp b lq mp kh ls lt mq kk lv lw mr ly lz ma ms mc md me mt mg mh mi ij bi translated">卷积中的步幅和最大池中的步幅的效果是累积的。当我们在卷积和最大池中使用步长 2 时，最终结果是特征图的宽度和高度大约减少了四倍。</p><p id="dc74" class="pw-post-body-paragraph ln lo jg lp b lq mp kh ls lt mq kk lv lw mr ly lz ma ms mc md me mt mg mh mi ij bi translated">卷积中的步幅值为 16，最大池中的步幅值为 4，这是不常见的。它们被故意夸大以说明它们对卷积层最终结果的影响。生成的特征图只有 100 个元素(10 x 10)，比具有 37636 个元素的特征图(194 x 194)小得多。</p><h1 id="fd66" class="kv kw jg bd kx ky kz la lb lc ld le lf km lg kn lh kp li kq lj ks lk kt ll lm bi translated">将碎片拼在一起</h1><p id="f01b" class="pw-post-body-paragraph ln lo jg lp b lq lr kh ls lt lu kk lv lw lx ly lz ma mb mc md me mf mg mh mi ij bi translated">我们将回到 AlexNet，第一个著名的 CNN 架构。这是一个很好的实际例子，可以理解 CNN 的组件是如何一起工作的。AlexNet 的构建模块如图 14 所示。虚线金字塔表示使用来自输入的感受野或来自前一层的特征图执行卷积。大方框代表特征图，特征图内的小方框是感受野。这个 CNN 可以将物体分为 1000 种不同的类别。</p><figure class="mk ml mm mn gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi nu"><img src="../Images/64c34f8c58c85240a2d6fff6b6b36969.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*UItPkoIvPZR5iXgzVgap6g.png"/></div></div><figcaption class="iz ja gj gh gi jb jc bd b be z dk"><strong class="bd mo">Figure 15 </strong>— Architecture of AlexNet CNN.</figcaption></figure><p id="ecc8" class="pw-post-body-paragraph ln lo jg lp b lq mp kh ls lt mq kk lv lw mr ly lz ma ms mc md me mt mg mh mi ij bi translated">这种架构的一个特点是它使用两个 GPU 进行训练。图 15 顶部的元素分配在一个 GPU 中，而底部的元素分配在另一个 GPU 中。</p><p id="38fb" class="pw-post-body-paragraph ln lo jg lp b lq mp kh ls lt mq kk lv lw mr ly lz ma ms mc md me mt mg mh mi ij bi translated">你可以在一些框架中得到 CNN 的训练，比如 PyTorch。比较好用。您还可以使用迁移学习将此架构应用于其他影像数据集。这需要一些数据处理来标准化和重新缩放图像，以符合 AlexNet 的要求，但值得一试。大概是这样的:</p><pre class="mk ml mm mn gt nv nw nx ny aw nz bi"><span id="ffff" class="mz kw jg nw b gy oa ob l oc od">from torchvision import transforms</span><span id="d337" class="mz kw jg nw b gy oe ob l oc od">pre_transforms = transforms.Compose([<br/>transforms.RandomResizedCrop(224),<br/>transforms.ToTensor(),<br/>transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])<br/>])</span></pre><p id="87c5" class="pw-post-body-paragraph ln lo jg lp b lq mp kh ls lt mq kk lv lw mr ly lz ma ms mc md me mt mg mh mi ij bi translated">您可以在 PyTorch 中导入模型，如下所示:</p><pre class="mk ml mm mn gt nv nw nx ny aw nz bi"><span id="6654" class="mz kw jg nw b gy oa ob l oc od">from torchvision import models</span><span id="ae8a" class="mz kw jg nw b gy oe ob l oc od">model = models.alexnet(pretrained=True)</span></pre><p id="ddcd" class="pw-post-body-paragraph ln lo jg lp b lq mp kh ls lt mq kk lv lw mr ly lz ma ms mc md me mt mg mh mi ij bi translated">您可以禁用卷积层的训练，并创建自己的分类器来覆盖原始的 AlexNet 全连接层:</p><pre class="mk ml mm mn gt nv nw nx ny aw nz bi"><span id="93df" class="mz kw jg nw b gy oa ob l oc od">from torch import nn</span><span id="cff3" class="mz kw jg nw b gy oe ob l oc od">for param in model.parameters():<br/>    param.requires_grad = False # disable training</span><span id="1a2d" class="mz kw jg nw b gy oe ob l oc od">fcLayersDict = OrderedDict([('fc1', nn.Linear(9216, 1024)),<br/>                   ('relu1', nn.ReLU()),<br/>                   ('fc2', nn.Linear(1024, 102)),<br/>                   ('output', nn.LogSoftmax(dim=1))<br/>                           ])<br/>model.fcLayersDict = fcLayersDict<br/>fc = nn.Sequential(fcLayersDict)<br/>model.classifier = fc</span></pre><p id="e2cb" class="pw-post-body-paragraph ln lo jg lp b lq mp kh ls lt mq kk lv lw mr ly lz ma ms mc md me mt mg mh mi ij bi translated">除了 AlexNet，PyTorch 中还有其他模型可以用来对您自己的图像数据集进行分类，只要进行必要的定制。真的建议测试这些模型，甚至从零开始建立自己的 CNN，了解 CNN 是如何工作的。</p></div><div class="ab cl of og hu oh" role="separator"><span class="oi bw bk oj ok ol"/><span class="oi bw bk oj ok ol"/><span class="oi bw bk oj ok"/></div><div class="ij ik il im in"><p id="4dbb" class="pw-post-body-paragraph ln lo jg lp b lq mp kh ls lt mq kk lv lw mr ly lz ma ms mc md me mt mg mh mi ij bi translated">即使您已经熟悉这里介绍的概念，我希望您至少可以从另一个角度来看它们。CNN 还有其他一些概念没有在这里讨论。如果你对 CNN 的某个方面感到好奇或不确定，请告诉我。</p></div></div>    
</body>
</html>