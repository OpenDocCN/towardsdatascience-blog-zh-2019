<html>
<head>
<title>Airplanes Detection for Satellite using Faster RCNN</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">基于快速 RCNN 的卫星飞机检测</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/airplanes-detection-for-satellite-using-faster-rcnn-d307d58353f1?source=collection_archive---------6-----------------------#2019-06-20">https://towardsdatascience.com/airplanes-detection-for-satellite-using-faster-rcnn-d307d58353f1?source=collection_archive---------6-----------------------#2019-06-20</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="5871" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">对象检测、更快的 RCNN、数据增强、飞机、卫星图像等等…</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/d6fe6a24b5d9e080a156799842533585.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*UW9sYLP6qxXAfbkVMwiM7w.png"/></div></div></figure><h1 id="9ca9" class="kr ks iq bd kt ku kv kw kx ky kz la lb jw lc jx ld jz le ka lf kc lg kd lh li bi translated">介绍</h1><p id="fde7" class="pw-post-body-paragraph lj lk iq ll b lm ln jr lo lp lq ju lr ls lt lu lv lw lx ly lz ma mb mc md me ij bi translated"><strong class="ll ir">物体检测</strong>是一项与计算机视觉和图像处理相关的计算机技术，处理在数字图像和视频中检测某类语义<strong class="ll ir">物体</strong>的<strong class="ll ir">实例</strong>。</p><p id="7ae2" class="pw-post-body-paragraph lj lk iq ll b lm mf jr lo lp mg ju lr ls mh lu lv lw mi ly lz ma mj mc md me ij bi translated">目标检测是已经取得巨大成功的领域之一。它被用于许多领域，如人脸检测(脸书用于识别人)、肿瘤检测(用于医学领域)等。</p><p id="efe9" class="pw-post-body-paragraph lj lk iq ll b lm mf jr lo lp mg ju lr ls mh lu lv lw mi ly lz ma mj mc md me ij bi translated">自从计算机视觉中的深度学习出现以来，像物体检测这样的任务已经变得相对容易和有效。<br/>深度学习模型比早期的计算机视觉方法提供了更好的准确性、更少的时间消耗、更低的复杂性和更好的整体性能。<br/>深度学习为对象检测提供了优于传统计算机视觉方法的出色结果，导致了深度学习模型的广泛使用。</p><p id="2737" class="pw-post-body-paragraph lj lk iq ll b lm mf jr lo lp mg ju lr ls mh lu lv lw mi ly lz ma mj mc md me ij bi translated">其中表现最好的物体检测(深度学习)算法包括:<br/> 1。RCNN(基于区域卷积神经网络)<br/> 2。快速 RCNN <br/> 3。更快的 RCNN <br/> 4。SSD(单次多盒探测器)<br/> 5。YOLO(你只看一眼)</p><p id="c0e9" class="pw-post-body-paragraph lj lk iq ll b lm mf jr lo lp mg ju lr ls mh lu lv lw mi ly lz ma mj mc md me ij bi translated">在本文中，我将使用更快的 RCNN(FRCNN)来演示对象检测的突出用途。</p><h1 id="741d" class="kr ks iq bd kt ku kv kw kx ky kz la lb jw lc jx ld jz le ka lf kc lg kd lh li bi translated">数据</h1><p id="4a31" class="pw-post-body-paragraph lj lk iq ll b lm ln jr lo lp lq ju lr ls lt lu lv lw lx ly lz ma mb mc md me ij bi translated">数据集取自 kaggle，你可以在这里找到它<a class="ae mk" href="https://www.kaggle.com/aceofspades914/cgi-planes-in-satellite-imagery-w-bboxes" rel="noopener ugc nofollow" target="_blank"/><br/>它包含 400 张训练图像和 100 张测试图像。边界框保存在 XML 和 CSV 文件中。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ml"><img src="../Images/bf5dce6774659af915a27058fdeed5d4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*0eyyrum6OUejBNMEdAel2w.png"/></div></div><figcaption class="mm mn gj gh gi mo mp bd b be z dk">An image from the training set</figcaption></figure><p id="03c5" class="pw-post-body-paragraph lj lk iq ll b lm mf jr lo lp mg ju lr ls mh lu lv lw mi ly lz ma mj mc md me ij bi translated">数据集包含计算机生成的飞机卫星图像。</p><p id="cc92" class="pw-post-body-paragraph lj lk iq ll b lm mf jr lo lp mg ju lr ls mh lu lv lw mi ly lz ma mj mc md me ij bi translated">从数据集可以看出，一些图像不包含与背景高度可区分的对象(飞机)，即飞机在颜色、纹理和外观方面与背景有些相似。<br/>例如，考虑以下图像:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi mq"><img src="../Images/0e5d3ae37c1208ab1b5af4b185819dd4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*VQ-lpk0zPbtOdmbo_Y6dHw.png"/></div></div></figure><p id="46a3" class="pw-post-body-paragraph lj lk iq ll b lm mf jr lo lp mg ju lr ls mh lu lv lw mi ly lz ma mj mc md me ij bi translated">你能看见多少架飞机？？你能看见一架飞机吗？？？！！<br/>嗯，这是来自训练集的图像，你可以看到在图像中找出飞机是多么困难(即使对一个人来说)。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi mr"><img src="../Images/95376c6eba2252c345c7ca658207f02f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*MfkGMFCQlcFILfCYFOUrBQ.png"/></div></div></figure><p id="1bc1" class="pw-post-body-paragraph lj lk iq ll b lm mf jr lo lp mg ju lr ls mh lu lv lw mi ly lz ma mj mc md me ij bi translated">顺便说一下，这是带有边框的图像，显示有两架飞机。(你想通了吗？？)</p><p id="46d0" class="pw-post-body-paragraph lj lk iq ll b lm mf jr lo lp mg ju lr ls mh lu lv lw mi ly lz ma mj mc md me ij bi translated">但是，这种很难区分背景和对象的图像会对模型性能产生影响吗？<br/>如果你有很强的计算机视觉背景，那么你一定知道物体检测的初始方法首先将图像转换为灰度，然后寻找边缘或梯度变化……<br/>所有这些都会受到图像中物体外观的很大影响。如果图像和物体非常相似(如上图所示)，那么这些方法将会失败。这种情况称为杂乱回波，在这种情况下，很难区分对象和背景。<br/>但是它也会影响深度学习模型吗？？？<br/>这些神经网络在寻找的是如何将物体从背景中区分出来(识别)，从而将其包围在一个包围盒中(定位)。这些被称为负责对象检测的特征。<br/>如果物体和背景之间的差异较小，很难发现这样的特征。<br/>因此，这个数据集是一个很好的例子，用于测试深度学习模型-FRCNN 的性能。</p><h1 id="e265" class="kr ks iq bd kt ku kv kw kx ky kz la lb jw lc jx ld jz le ka lf kc lg kd lh li bi translated">方法</h1><p id="ff17" class="pw-post-body-paragraph lj lk iq ll b lm ln jr lo lp lq ju lr ls lt lu lv lw lx ly lz ma mb mc md me ij bi translated">你可以在这里找到这个问题的 python 代码<a class="ae mk" href="https://github.com/ShubhankarRawat/Airplane-Detection-for-Satellites" rel="noopener ugc nofollow" target="_blank"/></p><p id="bdbf" class="pw-post-body-paragraph lj lk iq ll b lm mf jr lo lp mg ju lr ls mh lu lv lw mi ly lz ma mj mc md me ij bi translated">首先，400 张图片没有用武之地。为了让深度学习模型发挥最佳性能，我们需要大量数据。</p><p id="4f24" class="pw-post-body-paragraph lj lk iq ll b lm mf jr lo lp mg ju lr ls mh lu lv lw mi ly lz ma mj mc md me ij bi translated">深度学习模型的性能与训练数据量成正比是众所周知的事实。数据越多，性能越好。<br/>像 FRCNN 这样的模型需要大量的训练数据才能产生好的结果。然而，很少有(如果不是没有的话)用于对象检测的数据集具有充足的训练数据。<br/>在这个数据集中，我们也只有 400 张图像，这不足以产生好的结果。<br/>因此，要解决这一数据增强问题，就要出手相救。<br/>这个数据集再次成为一个很好的例子，展示了数据增强对于深度学习模型如何产生良好结果是至关重要的。</p><h2 id="a5b9" class="ms ks iq bd kt mt mu dn kx mv mw dp lb ls mx my ld lw mz na lf ma nb nc lh nd bi translated">数据扩充</h2><p id="2ed2" class="pw-post-body-paragraph lj lk iq ll b lm ln jr lo lp lq ju lr ls lt lu lv lw lx ly lz ma mb mc md me ij bi translated"><strong class="ll ir">数据扩充</strong>是从现有的训练<strong class="ll ir">数据中人工创建新的训练<strong class="ll ir">数据</strong>的技术。<br/> </strong>如果你一直在研究计算机视觉的深度学习模型(无论是图像分类、定位还是检测等)，那么你一定遇到过数据增强这个术语，并意识到它的重要性。</p><p id="d41f" class="pw-post-body-paragraph lj lk iq ll b lm mf jr lo lp mg ju lr ls mh lu lv lw mi ly lz ma mj mc md me ij bi translated">数据扩充生成用于训练的新图像，从而提高模型性能。<br/>数据增强为什么有效？？<br/>现代深度学习算法，如卷积神经网络，或 CNN，可以学习对图像中的位置不变的特征。然而，增强可以进一步帮助这种变换不变的学习方法，并且可以帮助模型学习对于诸如从左到右到从上到下排序、照片中的亮度等变换也不变的特征。</p><p id="a811" class="pw-post-body-paragraph lj lk iq ll b lm mf jr lo lp mg ju lr ls mh lu lv lw mi ly lz ma mj mc md me ij bi translated">有各种各样的数据增强技术，以下是在这种方法中使用的:<br/> 1。水平翻转<br/> 2。缩放比例<br/> 3。翻译<br/> 4。旋转<br/> 5。剪切<br/> 6。以上的各种组合</p><p id="4647" class="pw-post-body-paragraph lj lk iq ll b lm mf jr lo lp mg ju lr ls mh lu lv lw mi ly lz ma mj mc md me ij bi translated">与图像分类相比，数据扩充对于对象检测是不同的。在图像分类中，您只需要相应地改变图像，但是在对象检测中，您还需要改变和调整边界框。例如，如果您水平翻转图像，那么您也需要翻转边界框。</p><p id="a84c" class="pw-post-body-paragraph lj lk iq ll b lm mf jr lo lp mg ju lr ls mh lu lv lw mi ly lz ma mj mc md me ij bi translated">牢记边界框约束，我实现了数据扩充，总共生成了 4400 张图像。<br/>图像数量仍然不多，但是因为只有 100 个图像要测试，并且只有一个类别要检测，所以这么多就够了。<br/>但我强烈建议在不创建不必要数据的情况下，尽可能地增加训练数据(这种情况在数据扩充过程中经常发生)。</p><p id="a38c" class="pw-post-body-paragraph lj lk iq ll b lm mf jr lo lp mg ju lr ls mh lu lv lw mi ly lz ma mj mc md me ij bi translated">现在我们已经有了一些可以训练的数据，让我们来实现这个模型。</p><h2 id="76a6" class="ms ks iq bd kt mt mu dn kx mv mw dp lb ls mx my ld lw mz na lf ma nb nc lh nd bi translated">FRCNN</h2><p id="ae9e" class="pw-post-body-paragraph lj lk iq ll b lm ln jr lo lp lq ju lr ls lt lu lv lw lx ly lz ma mb mc md me ij bi translated">我建议您从上面提到的 GitHub 资源库下载代码文件，以充分利用本文。</p><p id="dbd0" class="pw-post-body-paragraph lj lk iq ll b lm mf jr lo lp mg ju lr ls mh lu lv lw mi ly lz ma mj mc md me ij bi translated">更快的 RCNN 是一个非常棒的深度学习模型，表现极其出色，这一点我们即将搞清楚。</p><p id="a0ce" class="pw-post-body-paragraph lj lk iq ll b lm mf jr lo lp mg ju lr ls mh lu lv lw mi ly lz ma mj mc md me ij bi translated">首先，组织数据。<br/>训练集图像被移至名为<em class="ne"> train_images </em>的文件夹，测试集图像被移至文件夹<em class="ne"> test_images。<br/> </em>一个空文件夹<em class="ne">结果</em> <em class="ne"> _imgs </em>被创建，该文件夹将包含所有带有边界框的输出图像。</p><p id="5674" class="pw-post-body-paragraph lj lk iq ll b lm mf jr lo lp mg ju lr ls mh lu lv lw mi ly lz ma mj mc md me ij bi translated">通过在命令提示符下执行下面一行，安装了所有需要的库和包(将当前文件夹作为工作目录):</p><pre class="kg kh ki kj gt nf ng nh ni aw nj bi"><span id="badd" class="ms ks iq ng b gy nk nl l nm nn">pip install -r requirements.txt</span></pre><p id="d96e" class="pw-post-body-paragraph lj lk iq ll b lm mf jr lo lp mg ju lr ls mh lu lv lw mi ly lz ma mj mc md me ij bi translated">批注文件(annotate.txt)已创建，看起来像:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi no"><img src="../Images/9c10bc2ba80603f65741991546f569be.png" data-original-src="https://miro.medium.com/v2/resize:fit:1014/format:webp/1*CgX8Q3yBAy3psDpFyxCLXw.png"/></div><figcaption class="mm mn gj gh gi mo mp bd b be z dk">annotate.txt</figcaption></figure><p id="aa5e" class="pw-post-body-paragraph lj lk iq ll b lm mf jr lo lp mg ju lr ls mh lu lv lw mi ly lz ma mj mc md me ij bi translated">它包含训练集图像的文件夹名称、图像名称和边界框坐标以及对象的类别。<br/>注意，边界框坐标的顺序为:xmin、ymin、xmax 和 ymax。</p><p id="0a68" class="pw-post-body-paragraph lj lk iq ll b lm mf jr lo lp mg ju lr ls mh lu lv lw mi ly lz ma mj mc md me ij bi translated">注释文件中的条目将根据数据扩充的实现方式而变化。</p><p id="56ad" class="pw-post-body-paragraph lj lk iq ll b lm mf jr lo lp mg ju lr ls mh lu lv lw mi ly lz ma mj mc md me ij bi translated">通过在命令提示符下执行以下行来运行该模型:</p><pre class="kg kh ki kj gt nf ng nh ni aw nj bi"><span id="53f7" class="ms ks iq ng b gy nk nl l nm nn">python train_frcnn.py -o simple -p annotate.txt</span></pre><p id="edfe" class="pw-post-body-paragraph lj lk iq ll b lm mf jr lo lp mg ju lr ls mh lu lv lw mi ly lz ma mj mc md me ij bi translated">我已经运行了 800 个时期的代码，每个时期有 20 次迭代，人们可以改变这些数字以获得更好的准确性，比如增加时期的数量。</p><p id="0c82" class="pw-post-body-paragraph lj lk iq ll b lm mf jr lo lp mg ju lr ls mh lu lv lw mi ly lz ma mj mc md me ij bi translated">强烈建议使用 GPU 来运行上述代码，因为训练可能需要很多时间，尤其是对于大量的历元。</p><p id="ce49" class="pw-post-body-paragraph lj lk iq ll b lm mf jr lo lp mg ju lr ls mh lu lv lw mi ly lz ma mj mc md me ij bi translated">培训完成后，是时候测试模型了。<br/>为了得到输出图像，执行以下命令:</p><pre class="kg kh ki kj gt nf ng nh ni aw nj bi"><span id="a5a2" class="ms ks iq ng b gy nk nl l nm nn">python test_frcnn.py -p test_images</span></pre><p id="79d8" class="pw-post-body-paragraph lj lk iq ll b lm mf jr lo lp mg ju lr ls mh lu lv lw mi ly lz ma mj mc md me ij bi translated">执行该命令时，可以看到输出图像，其边界框保存在<em class="ne"> results_imgs </em>文件夹中。</p><p id="2e28" class="pw-post-body-paragraph lj lk iq ll b lm mf jr lo lp mg ju lr ls mh lu lv lw mi ly lz ma mj mc md me ij bi translated">以下是我获得的一些结果:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi mq"><img src="../Images/80a34d1513422ab35a1f9e39381a9d23.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*EGsTirXh9a03lUbahaINMg.png"/></div></div></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi mq"><img src="../Images/04ba9695276bcd740c8056533c1566c6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*b_zcdJUolykVCWwhQe-G4w.png"/></div></div></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi mq"><img src="../Images/65612082d62a458dc22ae8b412863a0f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*4qcgLjf2m7WJqQstgU8L0w.png"/></div></div></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi mq"><img src="../Images/6afb7ef422ca05ce7d9bebfaee5913e2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*c8RTvJFKjZLDQaZDg0aNEQ.png"/></div></div></figure><p id="d2d0" class="pw-post-body-paragraph lj lk iq ll b lm mf jr lo lp mg ju lr ls mh lu lv lw mi ly lz ma mj mc md me ij bi translated">上面的图像显示了 FRCNN 在目标检测方面的出色表现。<br/>通过使用数据扩充生成更高质量的图像并增加历元数，可以增强模型性能。</p><p id="0590" class="pw-post-body-paragraph lj lk iq ll b lm mf jr lo lp mg ju lr ls mh lu lv lw mi ly lz ma mj mc md me ij bi translated">现在，让我们看看在没有进行数据扩充的情况下获得的结果，保持历元和迭代的数量不变。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi mq"><img src="../Images/c8df3991b3bbcdc5ed392176c5a4e1d8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*wYcg4WKqt9P9-w2wVgI8Mg.png"/></div></div></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi mq"><img src="../Images/69dd14a6ea30b515e026364b95eb5619.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*rwAwk0S3PgUnhQiplzIiKQ.png"/></div></div></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi mq"><img src="../Images/05df01ede61dcfa3ac773f851efd4cf9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*jHLSv4weNcXXp15otUAApQ.png"/></div></div></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi mq"><img src="../Images/2aa1aa4b7c0179907e4a3051bd340289.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ZUJWZHO1s1YIPPRml6P1OA.png"/></div></div></figure><p id="baf1" class="pw-post-body-paragraph lj lk iq ll b lm mf jr lo lp mg ju lr ls mh lu lv lw mi ly lz ma mj mc md me ij bi translated">可以看出，结果不如先前的结果好，在先前的结果中实现了数据扩充。<br/>该模型未能正确识别飞机，而是将非飞机物体识别为飞机。即假阳性和假阴性的数量很高。</p><p id="1dff" class="pw-post-body-paragraph lj lk iq ll b lm mf jr lo lp mg ju lr ls mh lu lv lw mi ly lz ma mj mc md me ij bi translated">这表明了数据增强如何有助于减少错误并提高深度学习模型的性能。</p><h2 id="95b8" class="ms ks iq bd kt mt mu dn kx mv mw dp lb ls mx my ld lw mz na lf ma nb nc lh nd bi translated">结束注释</h2><p id="11c2" class="pw-post-body-paragraph lj lk iq ll b lm ln jr lo lp lq ju lr ls lt lu lv lw lx ly lz ma mb mc md me ij bi translated">物体检测是一个很好的探索领域。<br/>我见过许多用于各种场合的物体检测模型，例如用于自动驾驶汽车、手机、安全等，但将其用于卫星对我来说有些陌生。</p><p id="4c4d" class="pw-post-body-paragraph lj lk iq ll b lm mf jr lo lp mg ju lr ls mh lu lv lw mi ly lz ma mj mc md me ij bi translated">此外，更快的 RCNN 名副其实，并产生很大的结果。</p><p id="9147" class="pw-post-body-paragraph lj lk iq ll b lm mf jr lo lp mg ju lr ls mh lu lv lw mi ly lz ma mj mc md me ij bi translated">我在这篇文章中的唯一目的是分享使用更快的 RCNN，而不是如何实现它，所以如果您在运行上述代码时遇到任何错误或有任何疑问，请随时在评论部分提问。</p></div></div>    
</body>
</html>