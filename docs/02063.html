<html>
<head>
<title>Computer Vision for Beginners: Part 3</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">初学者的计算机视觉:第 3 部分</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/computer-vision-for-beginners-part-3-79de62dbeef7?source=collection_archive---------8-----------------------#2019-04-05">https://towardsdatascience.com/computer-vision-for-beginners-part-3-79de62dbeef7?source=collection_archive---------8-----------------------#2019-04-05</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="7da4" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">从特征检测到人脸检测</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/eb7dbfcd2a390335ea6ea0c5dc9f00af.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*WcLE09IeZoRZcBJ7"/></div></div></figure><p id="0fe3" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">检测任务是计算机视觉的主要任务之一，我们有许多方法可以利用这项技术。识别出现时可能是关键的错误，但人眼无法识别。探测不安全和危险的动作或时刻以拯救生命。为自动驾驶汽车感知空间信息。使用物体检测的例子数不胜数，让这些任务自动化将给我们带来安全和效率。</p><p id="159c" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">这是 OpenCV 初学者教程的第三部分，完整系列如下:</p><ol class=""><li id="42f8" class="lq lr it kw b kx ky la lb ld ls lh lt ll lu lp lv lw lx ly bi translated"><a class="ae lz" rel="noopener" target="_blank" href="/computer-vision-for-beginners-part-1-7cca775f58ef">理解颜色模型并在图像上绘制图形</a></li><li id="3972" class="lq lr it kw b kx ma la mb ld mc lh md ll me lp lv lw lx ly bi translated"><a class="ae lz" rel="noopener" target="_blank" href="/computer-vision-for-beginners-part-2-29b3f9151874">带滤波的图像处理基础知识</a></li><li id="c30b" class="lq lr it kw b kx ma la mb ld mc lh md ll me lp lv lw lx ly bi translated"><strong class="kw iu"> <em class="mf">从特征检测到人脸检测</em> </strong></li><li id="507b" class="lq lr it kw b kx ma la mb ld mc lh md ll me lp lv lw lx ly bi translated"><a class="ae lz" rel="noopener" target="_blank" href="/computer-vision-for-beginners-part-4-64a8d9856208">轮廓检测和享受一点乐趣</a></li></ol><p id="7f24" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">我们已经讨论了几种颜色模式以及如何在图像上绘制图形，例如矩形和圆形。然后在第 2 部分，我们谈到了图像处理的概念，如模糊，梯度，腐蚀，膨胀等。今天，我们将应用这些概念来检测图像的特征，并在最后进行人脸检测。</p><p id="de31" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">本文假设您已经遵循了前面的步骤，或者您已经知道这些概念。但如果不是这样，请查看本系列前面的部分。本教程的完整代码可在<a class="ae lz" href="https://github.com/jjone36/vision_4_beginners/blob/master/part3_object_detection.ipynb" rel="noopener ugc nofollow" target="_blank"> <strong class="kw iu"> Github </strong> </a>上获得。现在让我们开始吧！</p><h1 id="1f87" class="mg mh it bd mi mj mk ml mm mn mo mp mq jz mr ka ms kc mt kd mu kf mv kg mw mx bi translated">边缘检测</h1><p id="e776" class="pw-post-body-paragraph ku kv it kw b kx my ju kz la mz jx lc ld na lf lg lh nb lj lk ll nc ln lo lp im bi translated"><a class="ae lz" href="https://en.wikipedia.org/wiki/Edge_detection" rel="noopener ugc nofollow" target="_blank"> <strong class="kw iu">边缘检测</strong> </a>是指识别图像中亮度变化剧烈或不连续的点。我们可以用那些点画线段，这些线段叫做<strong class="kw iu"> <em class="mf">边</em> </strong>。实际上，我们上次已经学习了一种边缘检测技术。你还记得吗？用索贝尔和拉普拉斯运算进行梯度滤波。通过计算给定方向上像素值的导数，梯度滤波可以描绘图像的边缘。</p><p id="9dcf" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated"><a class="ae lz" href="https://en.wikipedia.org/wiki/Canny_edge_detector" rel="noopener ugc nofollow" target="_blank"> <strong class="kw iu"> Canny 检测</strong> </a>是另一种边缘检测技术。这是最流行的边缘检测算法之一，分四步进行:<strong class="kw iu"> <em class="mf">降噪，寻找梯度及其方向，非最大抑制</em> </strong>和<strong class="kw iu"> <em class="mf">滞后阈值</em> </strong>。</p><p id="d131" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">该算法从高斯模糊开始，我想我们已经知道去除图像中噪声的原因。然后用 Sobel 核寻找图像的亮度梯度。利用导出的梯度和方向，检查每个像素的某个点是否是其周围点的局部最大值。如果不是，这一点被抑制为零(完全不存在，黑色)。这叫做<strong class="kw iu"> <em class="mf">非最大抑制</em> </strong>。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nd"><img src="../Images/7b72ad36ed44d643a81df061855dc65a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*geOqlrXjkodWq0WPjYRklg.png"/></div></div></figure><p id="35c3" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">如果该点被认为是局部最大值，则进入下一阶段。最后一个阶段是最后一个决定阶段，决定前面步骤中的边是否真的是边。这被称为<strong class="kw iu"> <em class="mf">滞后阈值</em> </strong>，这里我们需要两个阈值。</p><p id="ad75" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">给定两个不同的阈值，我们得到三个范围的值。因此，如果一个点的强度梯度高于上限阈值，它将被认为是“确定边缘”如果一个点的梯度低于下限阈值，该点将被丢弃。在梯度处于两个阈值中间的情况下，我们看到它与其他“确定边缘”点的连通性。如果没有联系，它也会被丢弃。</p><pre class="kj kk kl km gt ne nf ng nh aw ni bi"><span id="0fcb" class="nj mh it nf b gy nk nl l nm nn">img = cv2.imread('images/giraffe.jpg')<br/>img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)</span><span id="bae5" class="nj mh it nf b gy no nl l nm nn"># Canny detection without blurring<br/>edges = <strong class="nf iu">cv2.Canny(</strong>image=img, threshold1=127, threshold2=127<strong class="nf iu">)</strong></span><span id="eee7" class="nj mh it nf b gy no nl l nm nn">plt.figure(figsize = (20, 20))<br/>plt.subplot(1, 2, 1); plt.imshow(img)<br/>plt.axis('off')<br/>plt.subplot(1, 2, 2); plt.imshow(edges)<br/>plt.axis('off')</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi np"><img src="../Images/63d7fb2c75b35df2df64b4806c565f31.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Rf9VDRWDGQX2zPtOnrM6MQ.png"/></div></div></figure><p id="d04c" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">我只是在没有模糊的情况下使用了两个阈值的中间值，结果并不理想。现在让我们这次尝试不同的阈值。</p><pre class="kj kk kl km gt ne nf ng nh aw ni bi"><span id="fe74" class="nj mh it nf b gy nk nl l nm nn"># Set the lower and upper threshold<br/>med_val = np.median(img)</span><span id="7452" class="nj mh it nf b gy no nl l nm nn">lower = int(max(0, .7*med_val))<br/>upper = int(min(255, 1.3*med_val))</span></pre><p id="75cf" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">为了了解模糊如何改变结果，我将应用两种不同大小的内核，(5x5)和(9x9)。我将尝试通过增加 100 来更改上限阈值。因此，我们有 4 种类型的处理图像，如下所示:</p><pre class="kj kk kl km gt ne nf ng nh aw ni bi"><span id="c92e" class="nj mh it nf b gy nk nl l nm nn"># Blurring with ksize = 5 <br/>img_k5 = cv2.blur(img, ksize = (5, 5))</span><span id="cae1" class="nj mh it nf b gy no nl l nm nn"># Canny detection with different thresholds<br/>edges_k5 = cv2.Canny(img_k5, threshold1 = lower, threshold2 = upper)<br/>edges_k5_2 = cv2.Canny(img_k5, lower, upper+100)</span><span id="5c9f" class="nj mh it nf b gy no nl l nm nn"># Blurring with ksize = 9 <br/>img_k9 = cv2.blur(img, ksize = (9, 9))</span><span id="437e" class="nj mh it nf b gy no nl l nm nn"># Canny detection with different thresholds<br/>edges_k9 = cv2.Canny(img_k9, lower, upper)<br/>edges_k9_2 = cv2.Canny(img_k9, lower, upper+100)</span><span id="6edb" class="nj mh it nf b gy no nl l nm nn"># Plot the images<br/>images = [edges_k5, edges_k5_2, edges_k9, edges_k9_2]<br/>plt.figure(figsize = (20, 15))<br/>for i in range(4):<br/>    plt.subplot(2, 2, i+1)<br/>    plt.imshow(images[i])<br/>    plt.axis('off')<br/>plt.show()</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nq"><img src="../Images/4ce5705172bf1e36aa63bdaebb863b3d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*8iz2t7A8zN7nzyqJEO1Gvw.png"/></div></div></figure><p id="08e6" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">正如你在上面看到的，模糊有助于去除噪声，我们用(9x9)大小的内核得到了更好的结果。此外，阈值上限越高，我们得到的结果越好。</p><h1 id="0d89" class="mg mh it bd mi mj mk ml mm mn mo mp mq jz mr ka ms kc mt kd mu kf mv kg mw mx bi translated">角点检测</h1><p id="9183" class="pw-post-body-paragraph ku kv it kw b kx my ju kz la mz jx lc ld na lf lg lh nb lj lk ll nc ln lo lp im bi translated">角点检测是另一种广泛应用于目标检测、运动检测、视频跟踪等领域的检测算法。什么是图像处理中的角点？怎样才能用像素定义一个角呢？我们把角看作是边相交的地方。那我们怎么找到他们？首先找到所有的边，然后定位它们相互交叉的点？其实我们还有另外一种让事情更有效率的方法，那就是<strong class="kw iu"> <em class="mf">哈里斯</em> </strong>和<strong class="kw iu"> <em class="mf">石&amp;托马西</em> </strong>。</p><p id="643f" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">这些算法工作如下。我们检测各个方向上强度值有相当大变化的点。然后我们构造一个矩阵从中提取特征值。这些特征值是为了得分来决定它是否是一个角。数学表达式如下所示。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nr"><img src="../Images/f79cc7ebf074e25558be566e41e41ce9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*M7v6-iD-P26Mc_4fOwBd8w.png"/></div></div></figure><p id="82a5" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">现在让我们看看如何用代码实现这些。我们首先需要将图像转换成灰度。<a class="ae lz" href="https://docs.opencv.org/3.0-beta/doc/py_tutorials/py_feature2d/py_features_harris/py_features_harris.html" rel="noopener ugc nofollow" target="_blank"> <strong class="kw iu">哈里斯角点检测</strong> </a>可以用 OpenCV 中的函数<code class="fe ns nt nu nf b">cv2.cornerHarris()</code>进行。</p><pre class="kj kk kl km gt ne nf ng nh aw ni bi"><span id="7339" class="nj mh it nf b gy nk nl l nm nn">img = cv2.imread('images/desk.jpg')<br/>img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)<br/>img_gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)</span><span id="b082" class="nj mh it nf b gy no nl l nm nn"># Apply Harris corner detection<br/>dst = <strong class="nf iu">cv2.cornerHarris(</strong>img_gray, blockSize = 2, ksize = 3, k = .04<strong class="nf iu">)</strong></span></pre><p id="7814" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">参数<code class="fe ns nt nu nf b">blockSize</code>是被认为是邻域的窗口的大小，而<code class="fe ns nt nu nf b">k</code>是哈里斯检测器自由参数，如上面的等式所示。结果是分数 R，我们将使用它来检测角点。</p><pre class="kj kk kl km gt ne nf ng nh aw ni bi"><span id="4629" class="nj mh it nf b gy nk nl l nm nn"># Spot the detected corners<br/>img_2 = img.copy()<br/>img_2[dst&gt;0.01*dst.max()]=[255,0,0]</span><span id="8050" class="nj mh it nf b gy no nl l nm nn"># Plot the image<br/>plt.figure(figsize = (20, 20))<br/>plt.subplot(1, 2, 1); plt.imshow(img)<br/>plt.axis('off')<br/>plt.subplot(1, 2, 2); plt.imshow(img_2)<br/>plt.axis('off')</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nv"><img src="../Images/9aadcc705e38e2dcc67a3ddf1fefdd3a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*GMyjPviRSkRzUdqjuDV0fA.png"/></div></div></figure><p id="420a" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">这次我们试试<strong class="kw iu"> Shi-Tomasi 角点检测</strong>。我们可以用函数<code class="fe ns nt nu nf b">cv2.goodFeaturesToTrack()</code>来使用它。我们按照最大可能性(<code class="fe ns nt nu nf b">maxCorners</code>)设置最大数量的角点。我们还指定了最小距离(<code class="fe ns nt nu nf b">minDistance</code>)和最小质量等级(<code class="fe ns nt nu nf b">qualityLevel</code>)，它们被认为是角点。在我们得到检测到的角点后，我们将用圆圈标记这些点，如下所示。</p><pre class="kj kk kl km gt ne nf ng nh aw ni bi"><span id="6c1c" class="nj mh it nf b gy nk nl l nm nn"># Apply Shi-Tomasi corner detection<br/>corners = <strong class="nf iu">cv2.goodFeaturesToTrack(</strong>img_gray, maxCorners = 50, <br/>                                  qualityLevel = 0.01, <br/>                                  minDistance = 10<strong class="nf iu">)</strong><br/>corners = np.int0(corners)</span><span id="6d1c" class="nj mh it nf b gy no nl l nm nn"># Spot the detected corners<br/>img_2 = img.copy()<br/>for i in corners:<br/>    x,y = i.ravel()<br/>    cv2.circle(img_2, center = (x, y), <br/>               radius = 5, color = 255, thickness = -1)</span><span id="d41e" class="nj mh it nf b gy no nl l nm nn"># Plot the image<br/>plt.figure(figsize = (20, 20))<br/>plt.subplot(1, 2, 1); plt.imshow(img)<br/>plt.axis('off')<br/>plt.subplot(1, 2, 2); plt.imshow(img_2)<br/>plt.axis('off')</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nw"><img src="../Images/50b942125fd1ba1afbecdeea144402e1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*zIbJm4M8YOvsYEpE2SSlgg.png"/></div></div></figure><h1 id="5c58" class="mg mh it bd mi mj mk ml mm mn mo mp mq jz mr ka ms kc mt kd mu kf mv kg mw mx bi translated">人脸检测</h1><p id="d0ae" class="pw-post-body-paragraph ku kv it kw b kx my ju kz la mz jx lc ld na lf lg lh nb lj lk ll nc ln lo lp im bi translated">我们要看的最后一个特征是一张脸。<a class="ae lz" href="https://en.wikipedia.org/wiki/Face_detection" rel="noopener ugc nofollow" target="_blank"> <strong class="kw iu">人脸检测</strong> </a> <strong class="kw iu"> </strong>是一种识别数字图像中人脸的存在和位置的技术。我要你把人脸检测和人脸识别  <strong class="kw iu"> </strong>区分开来，人脸识别是指通过人脸来检测一个人的身份。所以人脸检测并不能告诉我们检测到的人脸属于谁。</p><p id="afdd" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">人脸检测基本上是一个分类任务，因此它被训练来分类是否有目标对象。而<strong class="kw iu"> <em class="mf">基于 Haar 特征的级联分类器</em> </strong>是 OpenCV 中可用的人脸检测模型之一。这是一个预训练模型，这意味着它已经完成了数千张图像的训练。理解该算法的 4 个要点是<strong class="kw iu"> <em class="mf">哈尔特征提取、积分图像、Adaboost </em> </strong>和<strong class="kw iu"> <em class="mf">级联分类器</em> </strong>。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nx"><img src="../Images/7d2b04fbae3e5da2a562ee32d1c57a57.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ELoJu38cHKMb8e3_IVz_eA.png"/></div></div></figure><p id="eb56" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated"><a class="ae lz" href="https://en.wikipedia.org/wiki/Haar-like_feature" rel="noopener ugc nofollow" target="_blank"> <strong class="kw iu"> <em class="mf">类哈尔特征</em> </strong> </a> <strong class="kw iu"> <em class="mf"> </em> </strong>是用于物体检测的图像滤波器或图像核，示例如上。它们的名字源于它们与最初由 Alfréd Haar 提出的 Haar 小波的直觉相似性。在检测过程中，我们通过图像上的窗口，用过滤器进行卷积运算，以查看图像中是否有我们要寻找的特征。这里是<a class="ae lz" href="https://vimeo.com/12774628" rel="noopener ugc nofollow" target="_blank"> <strong class="kw iu">视频</strong> </a> <strong class="kw iu"> </strong>，它可视化了检测是如何工作的。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ny"><img src="../Images/bb87f59e6e7ce6e2653b645b2a557e47.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*84KZtk275LK9PYv81lG9yQ.png"/></div></div></figure><p id="617c" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">那么我们如何决定在一个给定的区域中是否有一个想要的特性呢？我们来看看上图。我们有一个内核，它的上半部分是深色的，下半部分是浅色的。然后，我们得到每个区域的像素值的平均值，并减去两者之间的差距。如果结果高于一个阈值，比如说 0.5，那么我们得出结论，这就是我们正在检测的特征。我们对每个内核重复这个过程，同时在图像上滑动窗口。</p><p id="1074" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">虽然这不是一个复杂的计算，但当我们在整个图像中考虑它时，总计算量变得巨大。如果你看过上面提到的视频，你会对所涉及的计算量有直觉。而这正是一个<a class="ae lz" href="https://en.wikipedia.org/wiki/Summed-area_table" rel="noopener ugc nofollow" target="_blank"> <strong class="kw iu"> <em class="mf">积分图</em> </strong> </a>发挥作用的地方。积分图像是一种图像表示方式，是为了使特征评价更快、更有效而衍生出来的。</p><p id="f6f0" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">如下图所示，左边是一幅图像的像素，右边是一幅完整的图像。从左上角开始，它计算给定矩形区域下像素的累积和。在积分图像上，虚线框内的像素之和写在右边框的右下点。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nz"><img src="../Images/bacc706e1dac4487e768260d928ca102.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*yu4aq8LBUJkdI2-75i6m3g.png"/></div></div></figure><p id="42b5" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">有了这个预先计算的表，我们可以通过子矩形(红色、橙色、蓝色和紫色的方框)的值简单地得到某个区域的总和值。</p><p id="d542" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">所以我们用积分图像解决了计算量。但是我们还没完。想象一下，当检测窗口处于没有物体或人脸的空白背景时。如果在这样的部分执行相同的过程，仍然是浪费时间。还有一个让这个探测器更快的因素。实现<strong class="kw iu"> <em class="mf">一个</em> </strong> <a class="ae lz" href="https://en.wikipedia.org/wiki/Cascading_classifiers" rel="noopener ugc nofollow" target="_blank"> <strong class="kw iu"> <em class="mf">级联分类器</em></strong></a><strong class="kw iu"><em class="mf"/></strong>与 Adaboost！</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oa"><img src="../Images/d1a5cd99898f3cee637095a18ce5dd3b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*MOD1SWG_WGoVo3VyAPlX8Q.png"/></div></div></figure><p id="11b1" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">级联分类器构建逐步的阶段，并给出类哈尔特征之间的顺序。功能的基本形式在早期阶段实现，而更复杂的功能仅适用于那些有希望的区域。并且在每个阶段，Adaboost 模型将通过集合弱学习者来训练。如果一个子部分或子窗口在前一阶段被归类为“非人脸区域”，它将被拒绝进入下一步。这样做，我们只能考虑幸存的，并实现更高的速度。</p><h1 id="6e2f" class="mg mh it bd mi mj mk ml mm mn mo mp mq jz mr ka ms kc mt kd mu kf mv kg mw mx bi translated">我们的英雄在哪里？</h1><p id="c1dc" class="pw-post-body-paragraph ku kv it kw b kx my ju kz la mz jx lc ld na lf lg lh nb lj lk ll nc ln lo lp im bi translated">为了让这个教程更有趣，我想实现这个级联分类器来检测我们的漫威英雄的脸。(机器学习应该很好玩，你说呢？😃😃)让我们有请漫威上尉作为我们的第一位客人。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ob"><img src="../Images/0138606cb5efe4536089085f7e2a63f4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1054/format:webp/1*TT9i-deWvAczE2-DuudBBg.png"/></div></figure><p id="1eb3" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">我们将只使用这张图片的一部分。所以让我们先得到她脸部周围的感兴趣区域，然后将图像转换成灰度。只使用一个通道的原因是因为我们只对特征的光强度变化感兴趣。</p><pre class="kj kk kl km gt ne nf ng nh aw ni bi"><span id="b2ad" class="nj mh it nf b gy nk nl l nm nn">cap_mavl = cv2.imread('images/captin_marvel.jpg')</span><span id="ec6c" class="nj mh it nf b gy no nl l nm nn"># Find the region of interest<br/>roi = cap_mavl[50:350, 200:550]<br/>roi = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY)<br/>plt.imshow(roi, cmap = 'gray')</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi oc"><img src="../Images/116ea4aa6487920da5f4fb74ba533079.png" data-original-src="https://miro.medium.com/v2/resize:fit:832/format:webp/1*fdnKOp9jxIKx_wV7242ShQ.png"/></div></figure><p id="0b40" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">Haar 级联分类器文件基本上是 OpenCV 附带的。你可以在你电脑上的 OpenCV 文件夹中找到它们。或者你可以简单的在这里 下载文件<a class="ae lz" href="https://github.com/jjone36/vision_4_beginners/tree/master/haarcascades" rel="noopener ugc nofollow" target="_blank"> <strong class="kw iu">。</strong></a></p><pre class="kj kk kl km gt ne nf ng nh aw ni bi"><span id="2b56" class="nj mh it nf b gy nk nl l nm nn"># Load Cascade filter <br/>face_cascade = cv2.CascadeClassifier('haarcascades/<strong class="nf iu">haarcascade_frontalface_default.xml</strong>')</span></pre><p id="6aff" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">接下来，我们将创建一个函数来检测一张脸，并在其周围绘制一个矩形。为了检测面部，我们可以使用上面加载的分类器<code class="fe ns nt nu nf b">face_cascade</code>的方法<code class="fe ns nt nu nf b">.detectMulitiScale()</code>。它返回识别区域的四个点，所以我们将在那个位置画一个矩形。<code class="fe ns nt nu nf b">scaleFactor</code>是每个图像尺度下图像尺寸减小多少的参数，而<code class="fe ns nt nu nf b">minNeighbors</code>是每个候选矩形应该训练多少个邻居的参数。现在让我们把这个函数应用到图像上，看看结果。</p><pre class="kj kk kl km gt ne nf ng nh aw ni bi"><span id="750d" class="nj mh it nf b gy nk nl l nm nn"># Create the face detecting function <br/><strong class="nf iu">def </strong>detect_face(img)<strong class="nf iu">:</strong><br/>    <br/>    img_2 = img.copy()<br/>    face_rects = <strong class="nf iu">face_cascade.detectMultiScale(</strong>img_copy, <br/>                                               scaleFactor = 1.1,<br/>                                               minNeighbors = 3<strong class="nf iu">)<br/>    <br/>    for </strong>(x, y, w, h) <strong class="nf iu">in </strong>face_rects:<br/>        cv2.rectangle(img_2, (x, y), (x+w, y+h), (255, 255, 255), 3)<br/>        <br/>    <strong class="nf iu">return</strong> img_2</span><span id="4cac" class="nj mh it nf b gy no nl l nm nn"># Detect the face<br/>roi_detected = detect_face(roi)<br/>plt.imshow(roi_detected, cmap = 'gray')<br/>plt.axis('off')</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi od"><img src="../Images/b18af3d34fb16464946403198b7c939c.png" data-original-src="https://miro.medium.com/v2/resize:fit:850/format:webp/1*g_lzYa62hA2fkmlW6FEMAA.png"/></div></figure><p id="e044" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">太好了！我觉得这个还是比较满意的。这次为什么不干脆叫其他英雄？我们也可以对有多张脸的图像实现这个分类器。</p><pre class="kj kk kl km gt ne nf ng nh aw ni bi"><span id="628e" class="nj mh it nf b gy nk nl l nm nn"># Load the image file and convert the color mode<br/>avengers = cv2.imread('images/avengers.jpg')<br/>avengers = cv2.cvtColor(avengers, cv2.COLOR_BGR2GRAY)</span><span id="6e4e" class="nj mh it nf b gy no nl l nm nn"># Detect the face and plot the result<br/>detected_avengers = detect_face(avengers)<br/>display(detected_avengers, cmap = 'gray')</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oe"><img src="../Images/7a724e3e9682ed4c76319e81572cd3a5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ftXCUABE2HUr7mY2MgdmQA.png"/></div></div></figure><p id="ff3a" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">是的，有时捕捉“非人脸”对象或错过“真实人脸”会导致失败。有趣的是，它成功地发现了蜘蛛侠，却把美国队长和黑寡妇的手误认为眼睛。我们通常会得到更好的结果，一张脸看着前方，清楚地显示出额头和眼睛。</p><h1 id="8cfc" class="mg mh it bd mi mj mk ml mm mn mo mp mq jz mr ka ms kc mt kd mu kf mv kg mw mx bi translated">想试试你的吗？</h1><p id="2fa1" class="pw-post-body-paragraph ku kv it kw b kx my ju kz la mz jx lc ld na lf lg lh nb lj lk ll nc ln lo lp im bi translated">你想试试你的网络摄像头吗？我们可以应用同样的过程。将下面的代码脚本保存为一个文件，并将其导入到您的终端上。如果你要使用 Jupyter 笔记本，把代码放在一个单元格中并执行。你可以按 ESC 键关闭窗口。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="of og l"/></div></figure><p id="35fe" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">它成功检测到你的脸了吗？希望它不会选择你的鼻孔做眼睛。😅</p><h1 id="ee21" class="mg mh it bd mi mj mk ml mm mn mo mp mq jz mr ka ms kc mt kd mu kf mv kg mw mx bi translated">下一步是什么？</h1><p id="a450" class="pw-post-body-paragraph ku kv it kw b kx my ju kz la mz jx lc ld na lf lg lh nb lj lk ll nc ln lo lp im bi translated">你喜欢这个故事吗？除了正面人脸分类器，还有眼睛、上半身、下半身等各种模型。你也可以试试检测俄罗斯车牌的模型。所以我建议你也玩玩它。你想测试你对图像处理的理解吗？试试这个<a class="ae lz" href="https://www.analyticsvidhya.com/blog/2017/10/image-skilltest/" rel="noopener ugc nofollow" target="_blank"> <strong class="kw iu"> <em class="mf"> 25 题图像处理</em> </strong> </a>。这里有一些很棒的文章，为你应该检查的问题提供了详细的解释。</p><div class="oh oi gp gr oj ok"><a rel="noopener follow" target="_blank" href="/my-take-on-25-questions-to-test-a-data-scientist-on-image-processing-with-interactive-code-part-1-a6196f535008"><div class="ol ab fo"><div class="om ab on cl cj oo"><h2 class="bd iu gy z fp op fr fs oq fu fw is bi translated">我用 25 个问题来测试一个数据科学家关于交互式代码的图像处理-第 1 部分</h2><div class="or l"><h3 class="bd b gy z fp op fr fs oq fu fw dk translated">所以我找到了这个神奇的博客作者 Faizan Shaikh，他的博客上有一些神奇的东西！所以请检查他…</h3></div><div class="os l"><p class="bd b dl z fp op fr fs oq fu fw dk translated">towardsdatascience.com</p></div></div><div class="ot l"><div class="ou l ov ow ox ot oy ks ok"/></div></div></a></div><div class="oh oi gp gr oj ok"><a rel="noopener follow" target="_blank" href="/my-take-on-25-questions-to-test-a-data-scientist-on-image-processing-with-interactive-code-part-2-77eacfd96cf9"><div class="ol ab fo"><div class="om ab on cl cj oo"><h2 class="bd iu gy z fp op fr fs oq fu fw is bi translated">我用 25 个问题来测试一个数据科学家对交互式代码的图像处理-第 2 部分</h2><div class="or l"><h3 class="bd b gy z fp op fr fs oq fu fw dk translated">所以我找到了这个神奇的博客作者 Faizan Shaikh，他的博客上有一些神奇的东西！所以请检查他…</h3></div><div class="os l"><p class="bd b dl z fp op fr fs oq fu fw dk translated">towardsdatascience.com</p></div></div><div class="ot l"><div class="oz l ov ow ox ot oy ks ok"/></div></div></a></div><p id="5c82" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">有你想改正的错误吗？请与我们分享您的见解。我总是乐于交谈，所以请在下面留下评论，分享你的想法。我还在<a class="ae lz" href="https://www.linkedin.com/in/jiwon-jeong/" rel="noopener ugc nofollow" target="_blank"> <strong class="kw iu"> LinkedIn </strong> </a>上分享有趣且有用的资源，欢迎随时关注并联系我。我将带来另一个有趣的计算机视觉故事。敬请关注！</p></div></div>    
</body>
</html>