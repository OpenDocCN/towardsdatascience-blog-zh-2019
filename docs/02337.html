<html>
<head>
<title>Scalable Jaccard similarity using MinHash and Spark</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用 MinHash 和 Spark 的可扩展 Jaccard 相似性</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/scalable-jaccard-similarity-using-minhash-and-spark-85d00a007c5e?source=collection_archive---------7-----------------------#2019-04-17">https://towardsdatascience.com/scalable-jaccard-similarity-using-minhash-and-spark-85d00a007c5e?source=collection_archive---------7-----------------------#2019-04-17</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="3a20" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">一个简单的算法使得大规模计算相似矩阵变得容易得多。</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/4e1c86130a290f83f8322ca471e29ac5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*0ub-Xnpjc3W2-IddxJKZqw.jpeg"/></div></div></figure><p id="231d" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">不久前我想到，除了算术平均值之外，Jaccard 相似系数在我的作品中出现的次数可能比其他任何统计都多。如果你有两组事物(词、词的一部分、属性、类别或其他)，你可以用集合交集中的事物数除以集合并集中的事物数。由此产生的度量是一个有意义的相似性度量，其额外的优点是非常容易向非技术人员解释。</p><p id="5e02" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">Jaccard 相似性在规模上直接计算有点困难。如果您有一个非常大的实体-属性对列表，并且您想要一个逐个实体的相似性矩阵，您基本上必须执行一个内部连接，按实体分组并计数，然后执行一个外部连接，按实体分组并计数，然后将两个连接的结果连接在一起。如果你的工作流程使用 Spark，就像我的一样，那就是一大堆混乱。它是昂贵的。</p><p id="9899" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">不久前，一位同事给我指出了一件我觉得我应该知道但却不知道的事情:<a class="ae ln" href="https://en.wikipedia.org/wiki/MinHash#Jaccard_similarity_and_minimum_hash_values" rel="noopener ugc nofollow" target="_blank"> MinHash </a>。对于每个实体，随机排列属性，然后散列它们(将它们转换成整数)，然后取最小值。这样做很多次，然后计算两个实体的相同绘制的最小灰度匹配的百分比。我们可以用解释这两个实体属性集之间的 Jaccard 相似性的方式来解释这个度量。所以它把问题从大量的属性归结为少量的散列；但是更好的是，它带来的问题从可变数量的属性——伴随着<a class="ae ln" href="https://coxautomotivedatasolutions.github.io/datadriven/spark/data%20skew/joins/data_skew/" rel="noopener ugc nofollow" target="_blank">键偏斜</a>的所有痛苦——到所有实体中相同数量的最小散列。</p><p id="a3e3" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">以下代码片段中从第 36 行到第 52 行的大部分内容都来自 Patrick Nicholson，他是我的同事，告诉我 MinHash 的事情，他改编了 Spark 的<code class="fe lo lp lq lr b">spark.ml.feature.MinHashLSH</code>实现中的散列算法。我构建了连接逻辑，将 MinHash 结果转化为实际的 Jaccard 相似性，并将整个过程包装在一个函数中，使其更具可移植性。</p><p id="b90e" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">该函数需要一个 Spark 数据帧，一个指示数据帧中包含节点标签的列的字符串(我们希望在它们之间找到相似性的实体)，以及包含边的列(我们将散列的属性)。该函数输出一个包含两列节点标签的数据框——每列都有一个由<code class="fe lo lp lq lr b">suffixes</code>关键字参数指定的后缀——以及 Jaccard 相似性。</p><p id="f81a" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">随着抽牌次数的增加，Jaccard 的相似性变得更加精确。一百次绘制(下面代码中的默认值)给出的精度最高为 0.01。500 次抽奖的精确度高达 0.005。1000 次绘制的精度最高可达 0.001。你明白了。</p><p id="65a9" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">在过去的几个月里，这个小东西为我节省了很多时间和麻烦。我觉得值得分享一下。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="ls lt l"/></div></figure></div></div>    
</body>
</html>