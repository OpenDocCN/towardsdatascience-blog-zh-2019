<html>
<head>
<title>Defining User Restrictions for GPUs</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">为 GPU 定义用户限制</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/defining-user-restrictions-for-gpus-6971a658a9ce?source=collection_archive---------28-----------------------#2019-12-09">https://towardsdatascience.com/defining-user-restrictions-for-gpus-6971a658a9ce?source=collection_archive---------28-----------------------#2019-12-09</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="1598" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">如何在用户之间共享多个 GPU 而不出现 OOM 错误？</h2></div><p id="2b2a" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们正在南加州大学使用λ实验室的 4-GPU 工作站。由于多个用户可以同时在服务器上运行作业，处理内存不足(OOM)错误和公平性有点困难。我们可以在网上找到的解决方案如下:</p><ol class=""><li id="8cb7" class="lc ld iq kh b ki kj kl km ko le ks lf kw lg la lh li lj lk bi translated"><a class="ae lb" href="https://docs.nvidia.com/grid/latest/grid-vgpu-user-guide/index.html" rel="noopener ugc nofollow" target="_blank">英伟达的 GPU 虚拟化软件</a>，可以添加到虚拟化管理程序之上。不过，目前仅支持<a class="ae lb" href="https://www.nvidia.com/en-us/design-visualization/technologies/turing-architecture/" rel="noopener ugc nofollow" target="_blank">NVIDIA Turing</a>、<a class="ae lb" href="https://www.nvidia.com/en-us/data-center/volta-gpu-architecture/" rel="noopener ugc nofollow" target="_blank">Volta</a>、<a class="ae lb" href="https://www.nvidia.com/en-us/data-center/pascal-gpu-architecture/" rel="noopener ugc nofollow" target="_blank">Pascal</a>和<a class="ae lb" href="https://developer.nvidia.com/maxwell-compute-architecture" rel="noopener ugc nofollow" target="_blank">Maxwell</a>GPU 架构。</li></ol><figure class="lm ln lo lp gt lq gh gi paragraph-image"><div class="gh gi ll"><img src="../Images/248f2349ac2a7f50d6ff1bb34c01a5e2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1344/format:webp/1*9F8c0yoKGl2C1EVpP-tj4A.png"/></div><figcaption class="lt lu gj gh gi lv lw bd b be z dk">NVIDIA’s GPU virtualization stack. [<a class="ae lb" href="https://blogs.nvidia.com/blog/2018/06/11/what-is-a-virtual-gpu/" rel="noopener ugc nofollow" target="_blank">Source</a>]</figcaption></figure><p id="f5a7" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">2.Slurm 是一个开源的、高度可伸缩的作业调度系统，适用于大型和小型 Linux 集群。它支持 GPU 资源调度。对于大型团队来说似乎是一个非常合适的选择。它还支持每 GPU 内存分配，如果有足够的内存和未充分利用的计算单元，则可以在单个 GPU 上运行多个进程。</p><figure class="lm ln lo lp gt lq gh gi paragraph-image"><div class="gh gi lx"><img src="../Images/d676a8b3cefb2829bb74da767fffa628.png" data-original-src="https://miro.medium.com/v2/resize:fit:400/format:webp/1*3B86Z3qq0EAJBZc3rFeUXg.png"/></div><figcaption class="lt lu gj gh gi lv lw bd b be z dk">Slurm workload manager [<a class="ae lb" href="https://en.wikipedia.org/wiki/Slurm_Workload_Manager" rel="noopener ugc nofollow" target="_blank">Source</a>]</figcaption></figure><p id="071a" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在本文的其余部分，我们将解释我们为在用户之间共享多个 GPU 所做的工作。在多 GPU 工作站中，为每个 GPU 驱动程序文件创建用户组允许我们授予特定用户使用特定 GPU 的权限。现在，只有指定的 GPU 对用户可见。我们解释了在 4 GPU 工作站上创建 GPU 用户限制所需的命令。</p><p id="8e3e" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir">步骤 1: </strong>创建组，并将用户添加到组中。我们需要创建 4 个组，因为我们有 4 个 GPU:</p><pre class="lm ln lo lp gt ly lz ma mb aw mc bi"><span id="65fc" class="md me iq lz b gy mf mg l mh mi"># Adding groups<br/>sudo groupadd nvidia0<br/>sudo groupadd nvidia1<br/>sudo groupadd nvidia2<br/>sudo groupadd nvidia3</span><span id="9a7f" class="md me iq lz b gy mj mg l mh mi"># Adding users to the groups<br/>sudo usermod -a -G nvidia0 olivia<br/>sudo usermod -a -G nvidia1 peter</span></pre><p id="29e0" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir">第二步:</strong>在<em class="mk">/etc/modprob . d/NVIDIA . conf</em>创建一个配置文件，内容如下:</p><pre class="lm ln lo lp gt ly lz ma mb aw mc bi"><span id="bcb5" class="md me iq lz b gy mf mg l mh mi">#!/bin/bash<br/>options nvidia NVreg_DeviceFileUID=0 NVreg_DeviceFileGID=0 NVreg_DeviceFileMode=0777 NVreg_ModifyDeviceFiles=0</span></pre><p id="a8b6" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这个配置文件将把 4 个 NVIDIA 的驱动参数加载到 Linux 的内核中。NVIDIA 的驱动程序文件的一个问题是，它们在每次会话后都会重新生成，这破坏了我们将要在驱动程序文件上设置的用户访问限制。<em class="mk"> NVreg_ModifyDeviceFiles </em>保证驱动文件一次生成，以后不会更改。其他参数是设置具有 777 访问权限的默认用户和组 id。如果在<em class="mk"> /etc/modprob.d/，</em>已经有一个 NVIDIA 配置文件，你可以保留它的备份，并用我们提供的脚本替换它的内容。</p><p id="9180" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir">第三步:</strong>在<em class="mk"> /etc/init.d/gpu-restriction 创建一个脚本来加载 NVIDIA 的驱动。</em></p><pre class="lm ln lo lp gt ly lz ma mb aw mc bi"><span id="d3c2" class="md me iq lz b gy mf mg l mh mi">#!/bin/bash<br/>### BEGIN INIT INFO<br/># Provides:          gpu-restriction<br/># Required-Start:    $all<br/># Required-Stop:<br/># Default-Start:     2 3 4 5<br/># Default-Stop:<br/># Short-Description: Start daemon at boot time<br/># Description:       Enable service provided by daemon.<br/>#  permissions if needed.<br/>### END INIT INFO</span><span id="68a2" class="md me iq lz b gy mj mg l mh mi">set -e</span><span id="7a52" class="md me iq lz b gy mj mg l mh mi">start() {<br/>/sbin/modprobe --ignore-install nvidia; /sbin/modprobe nvidia_uvm; test -c /dev/nvidia-uvm || mknod -m 777 /dev/nvidia-uvm c $(cat /proc/devices | while read major device; do if [ "$device" == "nvidia-uvm" ]; then echo $major; break; fi ; done) 0 &amp;&amp; chown :root /dev/nvidia-uvm; test -c /dev/nvidiactl || mknod -m 777 /dev/nvidiactl c 195 255 &amp;&amp; chown :root /dev/nvidiactl; devid=-1; for dev in $(ls -d /sys/bus/pci/devices/*); do vendorid=$(cat $dev/vendor); if [ "$vendorid" == "0x10de" ]; then class=$(cat $dev/class); classid=${class%%00}; if [ "$classid" == "0x0300" -o "$classid" == "0x0302" ]; then devid=$((devid+1)); test -c /dev/nvidia${devid} || mknod -m 660 /dev/nvidia${devid} c 195 ${devid} &amp;&amp; chown :nvidia${devid} /dev/nvidia${devid}; fi; fi; done<br/>}</span><span id="8b49" class="md me iq lz b gy mj mg l mh mi">stop() {<br/>:<br/>}</span><span id="7a9b" class="md me iq lz b gy mj mg l mh mi">case "$1" in<br/>    start)<br/>       start<br/>       ;;<br/>    stop)<br/>       stop<br/>       ;;<br/>    restart)<br/>       stop<br/>       start<br/>       ;;<br/>    status)<br/>       # code to check status of app comes here <br/>       # example: status program_name<br/>       ;;<br/>    *)<br/>       echo "Usage: $0 {start|stop|status|restart}"<br/>esac</span><span id="78a7" class="md me iq lz b gy mj mg l mh mi">exit 0</span></pre><p id="4b86" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">然后，输入以下命令，该命令将告诉 Linux 在重新启动后加载脚本:</p><pre class="lm ln lo lp gt ly lz ma mb aw mc bi"><span id="5d7d" class="md me iq lz b gy mf mg l mh mi">sudo update-rc.d gpu-restriction defaults<br/>sudo update-rc.d gpu-restriction enable</span></pre><p id="1632" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">现在，我们有了一个 Linux 服务，可以通过以下命令启动它:</p><pre class="lm ln lo lp gt ly lz ma mb aw mc bi"><span id="dd1e" class="md me iq lz b gy mf mg l mh mi">sudo service gpu-restriction start</span></pre><p id="1dda" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">重启机器。您现在一切就绪！</p><p id="8dc6" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir">检查脚本:</strong></p><p id="9bb4" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">加载 NVIDIA 驱动程序的脚本的核心部分是:</p><pre class="lm ln lo lp gt ly lz ma mb aw mc bi"><span id="2e27" class="md me iq lz b gy mf mg l mh mi">/sbin/modprobe --ignore-install nvidia;<br/>/sbin/modprobe nvidia_uvm;<br/>test -c /dev/nvidia-uvm || mknod -m 777 /dev/nvidia-uvm c $(cat /proc/devices | while read major device; do if [ "$device" == "nvidia-uvm" ]; then echo $major; break; fi ; done) 0 &amp;&amp; chown :root /dev/nvidia-uvm; test -c /dev/nvidiactl || mknod -m 777 /dev/nvidiactl c 195 255 &amp;&amp; chown :root /dev/nvidiactl; devid=-1; for dev in $(ls -d /sys/bus/pci/devices/*); do vendorid=$(cat $dev/vendor); if [ "$vendorid" == "0x10de" ]; then class=$(cat $dev/class); classid=${class%%00}; if [ "$classid" == "0x0300" -o "$classid" == "0x0302" ]; then devid=$((devid+1)); test -c /dev/nvidia${devid} || mknod -m 660 /dev/nvidia${devid} c 195 ${devid} &amp;&amp; chown :nvidia${devid} /dev/nvidia${devid}; fi; fi; done</span></pre><p id="7b42" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">上面的脚本首先会加载 NVIDIA 模块<em class="mk"> nvidia </em>和<em class="mk"> nvidia_uvm。</em>为了设置用户访问限制，在所有 PCI express 设备的循环中，我们发现它们的供应商和类别 id 是否与 NVIDIA GPU 卡匹配。之后，我们创建每个 GPU 的驱动程序文件，然后我们在它们上面设置组和访问限制(660)。驱动文件位于<em class="mk"> /dev/nvidia0 </em>，…，<em class="mk"> /dev/nvidia3 </em>设置<em class="mk">。</em></p><p id="e295" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们建议首先在一个可执行文件中运行上述脚本，以测试它是否工作正常。如果您在教程中发现任何问题，请告诉我，我将不胜感激。</p></div></div>    
</body>
</html>