# 甘人会梦到假图像吗？

> 原文：<https://towardsdatascience.com/do-gans-dream-of-fake-images-4372b0777a2d?source=collection_archive---------10----------------------->

## 深入研究图像取证:区分真实图像和伪造图像的努力

![](img/186af0b15b97d91d60eb74dcf529e99a.png)

Barack Obama is one of the most popular characters for puppeteering

众所周知，现在很难区分真实媒体和虚假媒体。可能是文本、音频、视频或图像。

每种媒体都有自己的伪造方法。虽然伪造文本(仍然)主要是以传统方式进行的，但伪造图像和视频已经向前迈出了一大步。我们有些人甚至觉得再也分不清什么是真的什么是假的了。如果说两年前， [**photoshop 之战**](https://www.reddit.com/r/photoshopbattles/) sub-reddit 是伪造图像的艺术状态，photoshop 专家是这一领域的奇才，那么新技术已经改变了很多事情。

你可能听说过一些尖端的伪造方法，它们严重威胁着我们对什么是真什么是假的感知: [**深度伪造**](https://www.youtube.com/watch?v=gLoI9hAX9dw) 技术允许在每个视频中种植每张脸，不同的**re**[**——制定**](https://www.youtube.com/watch?v=p1b5aiTrGzY) 技术允许随心所欲地移动每张脸:做出表情、说话等。而这仅仅是开始。

![](img/b16d681cdff77a9d4aff074c8daa4bce.png)

Deep fake — planting Hillary Clinton on her impersonator

![](img/19af7fbc51f863691f64ed55aa61c633.png)

Re-enactment — making a face talk

最近，我非常投入这个领域:我已经开始与一家名为 [**Cyabra**](https://www.cyabra.com/) 的伟大初创公司合作。Cyabra 是一家反假新闻和反机器人的初创公司，因此，它的任务之一是将假图像与真图像进行分类，专业术语是**图像取证**。

如你所料，这是一项具有挑战性的任务。正如许多网络安全/欺诈检测任务一样，保护者似乎总是比伪造者落后一步。在图像伪造中，情况甚至更复杂，因为新的伪造技术每天都在出现。

那么解决 hits 任务的正确方法是什么呢？在每一项安全任务中，保护者都必须考虑所有可能的已知的 T21 威胁，此外还有攻击者意想不到的未知威胁。

让我们考虑一下防止窃贼入室:你知道窃贼可以破门而入，打破窗户、后门等。所以你把所有的入口都锁上了。但是你也应该放一个运动探测器，以防窃贼从一个未知的缺口进入，你仍然可以发现他。

在网络安全领域，特别是在数字图像取证领域，这意味着你必须以最高的准确性解决所有已知的伪造方法，以及一些通用的异常检测方法。由于如上所述，图像伪造技术正在经历一种繁荣，后一种方法变得更加重要。

# 有哪些图像篡改技术？

首先，让我们讨论一下我们在处理什么。

摄影锻造几乎和摄影本身一样古老。在下面的图片中，你可以看到一张被篡改的 19 世纪的照片:

![](img/fb98c1f037cf0c7eb4e1371e9a0040d1.png)

更多的例子可以在哈尼·法里德的数字取证**圣经**——[书](https://www.amazon.com/Photo-Forensics-Press-Hany-Farid/dp/0262035340)中找到。

## “手动”伪造—Photoshop

![](img/22398cf38eb05b73ee95e0277cf7a88a.png)

随着数码摄影的出现，图像篡改变得越来越容易和常见:最常见的一种被称为“**拼接**”和“**复制-移动**”，或大多数人所说的“**Photoshop**”。

这些方法包括将一幅图像的一部分移植到另一幅图像中。为了让它看起来更真实，伪造者还会做一些数字修饰。这些技术的结果可能很难用肉眼区分。

修图本身也是一种篡改方式，尤其是在时尚照中。

![](img/06091f7ccea4eebc730c8ac4e39c9e4d.png)

如前所述，photoshopping 并不总是容易辨别，但使用一些方法，将在稍后讨论，研究人员在事情的顶部。然而，技术让事情变得更难(或者更容易，取决于你站在哪一边)。具有讽刺意味的是，深度学习成为图像分类的主要方法，也允许一种新的、开创性的伪造物——生成模型。

## 基于生成模型的方法

自 2014 年出现一般敌对网络以来，很明显，图像伪造将永远不会相同。一个算法从字面上从零开始创造一个图像(例如一张脸)的能力既令人惊讶又令人恐惧。

![](img/c9a05752f2e36e13f2dfe097485f85a9.png)

GANs results throughout the years (none of the above is a real person)

在他 2014 年的开创性工作中，Ian Goodfellow 从概念上展示了在小规模(28 X 28)下创建逼真的人脸是可能的。这一概念很快成为现实，2018 年底，Nvidia 研究人员推出了能够以高分辨率创建超现实人脸的[](https://arxiv.org/abs/1812.04948)****。但这远不是对 GAN 的唯一研究:令人印象深刻的是，研究人员做了不同的调整，创造了新的假图像。我们只能想象这种技术的未来，但同时，让我们看看其他变体的一个不完全详尽的列表:****

## ****CycleGan****

****2017 年，2 部令人惊艳的作品出自[阿列克谢·埃夫罗斯](https://people.eecs.berkeley.edu/~efros/)实验室— [*pix2pix*](https://phillipi.github.io/pix2pix/) 和 [*CycleGan*](https://junyanz.github.io/CycleGAN/) 。你可以在我之前的[帖子中读到它们。](/a-different-kind-of-deep-learning-part-2-b447ff469255)****

****这两个作品都允许将图像从一个领域“复制”到另一个领域:将马转换成斑马，将狗转换成猫等等。****

****![](img/5ed8f5a14db35cffa99ab4c15b0cc2c1.png)********![](img/bea6bd36fe061aae188bd3344a210369.png)****

## ****假视频——重现****

****![](img/02cbcec5bec7ca2065c471e9245adfa9.png)****

****Nicholas Cage as Marlon Brando as The Godfather****

****除了创建假图像，深度学习技术更进一步，允许创建假视频。****

****这个领域的真正转折点(和许多其他场合一样)不是技术，而是文化。2018 年 1 月左右，Reddit 上开始出现高质量的假视频。他们中的许多人将尼古拉斯·凯奇的脸植入不同的场景，但并不是所有人都是 SFW。这立即引发了媒体对这一领域的关注(以及世界末日的预言)。****

****但深度伪装并不孤单:最近这种技术激增，它们在真实性和易于训练方面变得越来越先进。从玩具“换脸”app 开始，通过 [face2face](http://openaccess.thecvf.com/content_cvpr_2016/html/Thies_Face2Face_Real-Time_Face_CVPR_2016_paper.html) 、[深度造假](https://www.youtube.com/watch?v=gLoI9hAX9dw)、[综合奥巴马](https://grail.cs.washington.edu/projects/AudioToObama/siggraph17_obama.pdf)、**、**到最近三星的[少数镜头说话头像](https://arxiv.org/pdf/1905.08233.pdf)。****

****![](img/b862eaddfa440cfa6be12ad78cd26f09.png)****

****目前在这个领域最令人印象深刻的工作(目前，事情进展很快)是**深度视频肖像—** 在这个[工作](https://web.stanford.edu/~zollhoef/papers/SG2018_DeepVideo/paper.pdf)中，研究人员使用了一种多步骤的方法，来“操纵”一张全脸。他们首先从源视频和目标视频中提取面部特征，如姿势、表情、眼睛坐标等，然后使用编码器-解码器生成一个假视频，不仅可以控制嘴部运动和面部表情，还可以控制头部运动。****

****![](img/8d574e19fbc4ae12874df3767a15c2d7.png)****

****Deep video portrait****

# ****数字取证****

****因为这个帖子不是关于图像生成，而是关于我们如何检测它们，在看到一些伪造技术后，我们想检查一下防守团队提供了什么。如前所述，数字取证方法可以分为三种。良好的检测操作应结合使用以下各项:****

1.  ******基于特征的** —在某一类(或多类)伪造品中存在一种伪造品的情况下——大多适用于经典方法。****
2.  ******监督学习** —使用深度学习分类器(主要是 CNN)来学习某些类型的伪图像—适用于经典方法以及生成模型，例如 GANs。****
3.  ******无监督/通用**——试图捕捉真实图像的一些本质，以检测新类型的伪造(模型以前没有见过)。这可以看作是一种异常检测。****

****所有上述方法都有其优点和缺点，但由于生成方法变得更加现实，2 和 3 变得更加突出。****

****我们在上一部分中目睹的篡改技术全部(或大部分)都是由深度学习社区提供的公开可用的。然而，它不必永远保持这种状态:在随后的几年里，不同的公司和政权将有自己的秘密技术，这是非常合理的。****

# ****基于特征的****

****2004 年，**哈尼·法里德**和**阿林** **波佩斯库**发表了第一篇关于使用数字文物识别假图像的作品。数码相机具有不同的伪像，这些伪像源自摄影硬件、软件或特定于图像的压缩技术。因此，发现这些假照片的数字方法的出现只是时间问题。法里德和波佩斯库使用了一种特殊的相机过滤器(CFA)来识别图像的虚假部分。****

****从那以后，出现了更多的手工制作技术:****

## ****使用 JPEG“签名”****

****JPEG 是数字媒体中最常见的图像压缩协议。你可以在这里阅读它的细节[。简而言之，每个图像都有自己的编码方式来优化文件大小。可以利用不同图像的编码差异来检测伪造图像(拼接)。这里有一个](https://parametric.press/issue-01/unraveling-the-jpeg/)[这样工作的例子](https://www.cs.dartmouth.edu/farid/downloads/publications/wifs17.pdf)。****

****![](img/8e5bb9165e508bf42a78d2a46b135803.png)****

****Splicing artifacts caused by JPEG compression****

## ****相机伪影****

****如前所述，数码相机在硬件或软件中也有其制品、结构。每个相机制造商、型号或软件版本都可能有自己的签名。比较图像不同部分的这些特征或[相机噪声](http://www.cs.albany.edu/~lsw/papers/ijcv14.pdf)可能会产生一个好的分类器。****

## ****摄影艺术品****

****与上面的逻辑相同，篡改图像可能会扭曲照片的自然条件。使用这种特征的数字测量(例如[照明](https://www.ijcaonline.org/archives/volume177/number1/manthale-2017-ijca-915436.pdf)、“[像差](http://cs.haifa.ac.il/hagit/papers/IJCV_11_ImageForgery.pdf)”)在伪造检测中也是有用的。****

## ****生成模型工件****

****当前的生成模型也遭受已知的伪像，有些甚至是可见的，如不同的不对称，奇怪的嘴的形状，不对称的眼睛等等。这些人工制品在这个[作品](https://faui1-files.cs.fau.de/public/mmsec/pub/matern_ivfws_2019_face_artifacts.pdf)中被利用，使用经典的计算机视觉将假图像与真图像分开。然而，考虑到生成模型的进步，这些人工制品不一定存在于明天的赝品中。****

****![](img/bdc8e150e508f345b6b444d1c61ebec1.png)****

****Asymmetric eyes in GAN face****

****所有上述方法都是伟大和聪明的，但是一旦暴露，他们就可以被伪造者所穿透。这就是机器学习的用武之地:它有点像一个黑匣子，可以在伪造者不知道其细节的情况下学习假图像。****

# ****监督深度学习****

****随着深度学习的兴起，研究人员开始使用深度网络来检测虚假图像是很自然的。****

****直观上，很容易从不同类型的伪造类中获取图像，并开始训练分类器和检测器。让我们来看看一些备受瞩目的作品。****

## ****使用新 conv 层的通用图像处理检测****

****![](img/8fcb52b0cbe21d648b78fd161172fde2.png)****

****在这项[工作](http://ece.drexel.edu/stamm/papers/Bayar_IHMMSec_2016.pdf)中，研究人员设计了一个特殊的卷积层，它通过对过滤器施加约束，旨在捕捉*操作*，而不是图像*语义内容*。经过对中值滤波、高斯模糊等不同修图方法的测试，该方法达到了> 95%的准确率。这项工作的目的是通用的，然而，据称它的设计仅限于 photoshopping 和篡改，而不是 GANs 之类的。****

## ****Mesonet****

****Mesonet 是一部专注于也许是最痛苦的问题的作品:篡改视频中的人脸。具体来说就是 face2face 和 deep fakes(见上图)。由于视频(特别是数字化的)本质上是一系列图像，研究人员使用深度网络解决这项任务，并使用非常标准的网络获得了良好的结果。总之，这项工作除了是最早解决这项任务的工作之一之外，并没有什么特别之处。****

## ****甘实验****

****正如我们前面所看到的，甘人只是不断出现。训练一个模型来区分真实图像和特定的 GAN 并不困难。但是为*每*根训练一个模型也是不切实际的。****

****[一些研究人员](https://arxiv.org/abs/1902.11153)非常乐观，试图将一个分类模型推广到不同的 GANs，这些 GANs 与他们所接受的训练不同。换句话说，他们在一种 GAN([PG-GAN](https://arxiv.org/abs/1710.10196)—style GAN 的前身)上训练了一个深度网络，并试图在另一种 GAN(DC-GAN，WGAN)上进行推断。****

****正如预期的那样，结果表明，即使研究人员进行了预处理，也没有任何普遍性。****

****还有很多类似的方法，但概括起来——意思是，识别从未见过的伪造品，学习研究需要开始变得更有创造性。****

# ****通用方法****

****我们知道，深度学习不仅仅局限于朴素的分类器。有许多种 un/[self](/a-different-kind-of-deep-learning-part-1-90fe6c52f1ab)/semi-supervised 模型可以处理少量数据、n 次拍摄和其他任务。****

****让我们来看看用什么样的思路来解决“万能假像”的问题。****

## ****自洽性****

****这种方法的一个很好的例子可以在作品 [**打击假新闻:通过学习自洽的图像拼接检测**](https://arxiv.org/abs/1805.04096) **中找到。**这篇文章来自**阿列克谢·埃夫罗斯**的工作坊，大部分人都知道他在[自我监督](/a-different-kind-of-deep-learning-part-1-90fe6c52f1ab)技术方面的工作。这部作品与他早期的作品有一些相同之处。研究人员整合了一个 4 步工作流程，其中他们:****

1.  ****学习预测图像的 EXIF*元数据。****
2.  ****将图像分割成许多小块，比较每一对的预测 EXIF 值。****
3.  ****看起来具有不匹配的 EXIF 值的切片将被分类为取自不同的图像，因此该图像将是假的。****
4.  ****分类将用于提供移植区域的热图。****

****![](img/39ff3924196b4883f82f4b7ea4a572f0.png)****

****A detection of “spliced” Keanu Reeves****

****但是什么是 EXIF 呢？在数字媒体中，图像(和一些声音文件也是如此)，EXIF，**可交换图像文件格式，**是一种元数据签名的文件。图像的 EXIF 应该包括相机(或扫描仪)型号、原始图像大小、照片属性(闪光灯、快门打开时间)等等。****

****![](img/62ab6ed1dc0d3b1f44fb9d0555553205.png)****

****显然，并不是所有的网上照片都有完整的 EXIF，尤其是那些造假的照片。这正是研究人员参与预测每个图像/补丁的 EXIF 的原因。现在你可以看到，这项任务在某种程度上是无人监管的，因为有大量的在线图像和现成的 EXIF 可供学习。更准确地说，使用了 40 万张图像来训练这个模型。****

****该模型在 photoshopped 图像上取得了良好的结果，但令人惊讶的是，它在 GaN 生成的图像上也取得了一些成功。****

## ****法医转移****

****Luisa Verdoliva 是一名意大利研究人员，她和她的团队拍摄了一些有趣的照片来推广图像取证。在这个[作品](https://arxiv.org/pdf/1812.02510.pdf)中，他们训练了一个有点不同的模型，这将有望更具普遍性。他们所做的是使用自动编码器，这是一种旨在将图像“收缩”成向量，然后重建它的网络。这个向量被训练成**分类器**来确定图像是真是假:****

****![](img/7aa4ddc63a9f69ff255674188f7bf39d.png)****

****A scheme of the forensic transfer autoEncoder****

****他们还尝试迁移学习:在数据集 A 上训练他们的网络，用数据集 B 的一个小子集重新训练它，并尝试在数据集 B 上进行推断。****

****他们在几个数据集上来来回回地做这项工作，并得到合理的结果(75-85%的准确率)。这些结果优于其他网络(其中一些在上面的**监督学习**部分讨论过)****

****![](img/78b52038e2e79a74ba1d132b19df21e3.png)****

****ForensicTransfer — an example transfer learning results****

## ****噪声印迹****

****来自上述团队的另一种无人监督的[方法](https://arxiv.org/pdf/1808.08396.pdf)，类似于自洽，试图预测图像碎片之间的 PRNU 噪声(一种特定类型的相机噪声)。它报告了多个数据集的最新结果(平均马修斯相关度为 0.4，而自洽度为 0.33)。****

****![](img/a1b555d4db5c6d45439f1218bb43867d.png)****

****A set of predictions: noise print on the right. EXIF-SC is self-consistency.****

# ****深度假动作旋转****

****考虑到以上所有情况，似乎通用方法必须更积极地解决生成性伪问题。他们确实做到了:一些研究人员抓住机会，试图创造出某种甘将军猎人。这意味着能够识别 GAN 生成的图像，而无需对其种类进行专门培训。让我们来看看其中的几个:****

## ****学习在野外检测假的人脸图像****

****在一篇有点仓促的[文章](https://arxiv.org/pdf/1809.08754.pdf)(只有 4 页)中，研究人员使用非耦合的图像对来训练一个深度网络，以对相同/不同的图像进行分类(真实和真实，假的和假的，真实和假的),这种有点天真的结果在不同的 GANs 上得到了合理的结果，尽管对所有的 GANs 都进行了训练。****

****![](img/a46325eb470d43aa0fd53c9ae819ddd3.png)****

## ****GANs 会留下人工指纹吗？****

****在本文中，**Luisa verdolva**使用她最喜欢的噪声图(PRNU)，用不同的训练数据集来尝试和表征几种不同的 GAN 模型(PG-GAN，cycle-GAN)。他们的成功表明，实际上每个 GAN(达到训练集水平)都有自己的噪声指纹，类似于相机的噪声指纹。不幸的是，这种方法对检测假图像的帮助主要是理论上的，至少目前是这样。****

****![](img/09b1b14719bbf22f7c70f0f36e057f6a.png)****

# ****作品分类****

****最终，我们可以交叉生产*锻造*和*检测*方法，并将大多数方法放入一个(或多个)盒子中:****

****![](img/cb7cba377465f12d783c016249e2455a.png)****

****在我们在 Cyabra 的工作中，我们面临许多上述挑战，因此我们采用类似的策略:使用监督方法来检测已知的伪造品，同时进行调整和测试，希望能推广到其他伪造品。****

****不知何故，也许令人惊讶的是，我们已经发现一些通用或半通用的方法可能出乎意料地有效。例如，发现自洽工作，(通过一些调整)可能是有效的分类 GAN 创建的图像。****

# ****摘要****

****这就是了，如果你已经到达这里，你就成功地穿越了图像和视频取证的泡沫领域。****

****正如我们在上面看到的，大部分工作都集中在对特定篡改进行分类的方法上。然而，一般的方法是新的，仍然是稀疏的。****

****很明显，这个领域很快将不再是研究人员和爱好者的狭窄领域，而是开始涉及普通人——他们希望重新获得辨别真假的能力。****

****军备竞赛不会很快停止，但我们应该期待看到法医们齐心协力，想出一些更好的方法来反击伪造者。****

******值得注意的作品* [*监督*](https://arxiv.org/abs/1901.08971) [*学习*](https://arxiv.org/abs/1703.04615) *。*****

****我希望你喜欢阅读这篇评论！欢迎随时 [***关注***](https://twitter.com/shgidi) *我，并查看我的网站—*[***www.shibumi-ai.com***](https://www.shibumi-ai.com/)****