<html>
<head>
<title>Finding r in R</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">在 R 中寻找 R</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/finding-r-in-r-455fb7de5d80?source=collection_archive---------16-----------------------#2019-11-28">https://towardsdatascience.com/finding-r-in-r-455fb7de5d80?source=collection_archive---------16-----------------------#2019-11-28</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><figure class="gl gn jr js jt ju gh gi paragraph-image"><div class="gh gi jq"><img src="../Images/0fb5174ac1170b2c2c1cc3075e1409f5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1146/format:webp/1*nGKRexhAemU3nJ3s6yeWCg.png"/></div></figure><p id="7685" class="pw-post-body-paragraph jx jy it jz b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku im bi kv translated">相关系数(R)、回归的相关系数(R)和编程语言 R 都是数据科学的三个标志性 R。相关系数(r)是一个非常著名的统计测试，在机器学习模型中非常常用。回归的相关系数可以确定斜率与相关值的一致程度，是回归目标预测的重要指标。r 是一种函数式语言，它植根于语言 S，是数据科学家非常流行的选择。</p><blockquote class="le"><p id="bbd6" class="lf lg it bd lh li lj lk ll lm ln ku dk translated">是的，我们在 R 中找到 R，因为我觉得这很有趣。</p></blockquote><p id="1fd9" class="pw-post-body-paragraph jx jy it jz b ka lo kc kd ke lp kg kh ki lq kk kl km lr ko kp kq ls ks kt ku im bi translated"><a class="ae lt" href="https://github.com/emmettgb/Emmetts-DS-NoteBooks/blob/master/R/r%20in%20R.ipynb" rel="noopener ugc nofollow" target="_blank">这里有<em class="lu">笔记本。</em> </a></p></div><div class="ab cl lv lw hx lx" role="separator"><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma"/></div><div class="im in io ip iq"><figure class="md me mf mg gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="mh mi di mj bf mk"><div class="gh gi mc"><img src="../Images/d076c567a812799927c8ebd14f681928.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*XuMcVejVKwC7rk9sV4FTEw.png"/></div></div></figure><p id="9593" class="pw-post-body-paragraph jx jy it jz b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku im bi translated">r 是一种函数式语言，其历史和计算一样悠久。虽然这有时是一种优势，但 R 也一直是一种较小的语言。重要的是要记住，尽管 R 对于数据科学家来说的确是一件大事，并且是一门伟大的语言；r 将不会像 Python 或 C 语言那样拥有广泛的支持。当然，Python 和 C 也有其局限性，Julia 和 Scala 也是如此。总的来说，虽然我发现自己使用 R 的次数比 Python、Julia 甚至 Scala 少得多，但我仍然认为 R 是一个很棒的工具，我甚至比现在更想使用它。</p></div><div class="ab cl lv lw hx lx" role="separator"><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma"/></div><div class="im in io ip iq"><h1 id="8db2" class="ml mm it bd mn mo mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne nf ng nh ni bi translated">为什么？</h1><p id="4510" class="pw-post-body-paragraph jx jy it jz b ka nj kc kd ke nk kg kh ki nl kk kl km nm ko kp kq nn ks kt ku im bi translated">我喜欢低级的数据科学，也喜欢高级的。令人惊讶的是，经常会遇到那些对相关系数、模型等非常熟悉的人。在更大的范围内。但是了解一个模型的内部运作，或者至少了解一个模型如何与统计数据一起工作来证明一个更准确的结果是有价值的信息。</p><p id="aa57" class="pw-post-body-paragraph jx jy it jz b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku im bi translated">在不使用库的情况下设计自己的算法肯定会让你在面试中成为众矢之的，并让你在你的领域中与众不同。这是因为为了开发复杂的算法，可能需要大量的计算机科学技能。我不想详细说明，但是 CS 技能经常会成为工作中非常重要的一部分。</p><blockquote class="le"><p id="9c1d" class="lf lg it bd lh li lj lk ll lm ln ku dk translated">除了正当理由，它的乐趣！</p></blockquote></div><div class="ab cl lv lw hx lx" role="separator"><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma"/></div><div class="im in io ip iq"><h1 id="be55" class="ml mm it bd mn mo mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne nf ng nh ni bi translated">函数公式</h1><figure class="md me mf mg gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="mh mi di mj bf mk"><div class="gh gi no"><img src="../Images/b53515a82463a7538c5adf65ee280b17.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/1*LKHbm_e4XNMtpvitEPGwRQ.gif"/></div></div><figcaption class="np nq gj gh gi nr ns bd b be z dk">formula for the correlation coefficient</figcaption></figure><p id="c44a" class="pw-post-body-paragraph jx jy it jz b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku im bi kv translated"><span class="l kw kx ky bm kz la lb lc ld di">在</span>首先，这个计算似乎相当全面和困难。当游戏中的每个部分都被分解成小块时，这个公式就变得简单多了。</p><ul class=""><li id="eae4" class="nt nu it jz b ka kb ke kf ki nv km nw kq nx ku ny nz oa ob bi translated">n —样本量。</li><li id="27c0" class="nt nu it jz b ka oc ke od ki oe km of kq og ku ny nz oa ob bi translated">σxy——x 和 y 的点积之和。</li><li id="789d" class="nt nu it jz b ka oc ke od ki oe km of kq og ku ny nz oa ob bi translated">σx——x 的总和。</li><li id="5e19" class="nt nu it jz b ka oc ke od ki oe km of kq og ku ny nz oa ob bi translated">σy——y 的总和。</li><li id="4ce1" class="nt nu it jz b ka oc ke od ki oe km of kq og ku ny nz oa ob bi translated">σx——x 的点平方之和。</li><li id="dae0" class="nt nu it jz b ka oc ke od ki oe km of kq og ku ny nz oa ob bi translated">(σx)—x 的二次幂之和。</li><li id="cc46" class="nt nu it jz b ka oc ke od ki oe km of kq og ku ny nz oa ob bi translated">σy——y 的点平方之和。</li><li id="44dc" class="nt nu it jz b ka oc ke od ki oe km of kq og ku ny nz oa ob bi translated">(σy)—y 的二次幂之和。</li></ul><p id="6682" class="pw-post-body-paragraph jx jy it jz b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku im bi translated">分解方程后，显然我们需要计算每个单独的部分。幸运的是，R 是在考虑线性代数的情况下构建的。R 中几乎所有的操作数都可以用于线性代数。</p><ul class=""><li id="6c9c" class="nt nu it jz b ka kb ke kf ki nv km nw kq nx ku ny nz oa ob bi translated">n —我们可以使用 R 的基函数“length”来计算 n</li><li id="e9c2" class="nt nu it jz b ka oc ke od ki oe km of kq og ku ny nz oa ob bi translated">xy——我们首先需要 x 和 y 的乘积，幸运的是，我们可以使用*操作数来乘以数组。</li><li id="1945" class="nt nu it jz b ka oc ke od ki oe km of kq og ku ny nz oa ob bi translated">σ()基本适马可以使用 sum()函数来计算。</li></ul><pre class="md me mf mg gt oh oi oj ok aw ol bi"><span id="e78f" class="om mm it oi b gy on oo l op oq">    n = length(x)<br/>    xy = x * y<br/>    Σx = sum(x)<br/>    Σy = sum(y)<br/>    Σxy = sum(xy)</span></pre><blockquote class="le"><p id="4f33" class="lf lg it bd lh li or os ot ou ov ku dk translated">很简单，对吧？</p></blockquote><p id="c120" class="pw-post-body-paragraph jx jy it jz b ka lo kc kd ke lp kg kh ki lq kk kl km lr ko kp kq ls ks kt ku im bi translated">现在我们只缺少 x 和 y 的点指数的和，以及 x 的平方的和。</p><blockquote class="ow ox oy"><p id="09aa" class="jx jy lu jz b ka kb kc kd ke kf kg kh oz kj kk kl pa kn ko kp pb kr ks kt ku im bi translated">x 的和与 x 的和…..</p></blockquote><pre class="md me mf mg gt oh oi oj ok aw ol bi"><span id="e8dc" class="om mm it oi b gy on oo l op oq">    x2 = x ^ 2<br/>    y2 = y ^ 2<br/>    sx2 = sum(x2)<br/>    sy2 = sum(y2)</span></pre><p id="447e" class="pw-post-body-paragraph jx jy it jz b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku im bi translated">注意σx 和(σx)之间的区别，它们可能读起来一样，但是<em class="lu">它们不是同一个</em>。</p><h1 id="170e" class="ml mm it bd mn mo pc mq mr ms pd mu mv mw pe my mz na pf nc nd ne pg ng nh ni bi translated">编写我们的函数</h1><p id="872d" class="pw-post-body-paragraph jx jy it jz b ka nj kc kd ke nk kg kh ki nl kk kl km nm ko kp kq nn ks kt ku im bi translated">结合上面所有的数学，我们可以得到我们的值，然后把它们代入 R 函数的公式中，就像这样:</p><pre class="md me mf mg gt oh oi oj ok aw ol bi"><span id="002c" class="om mm it oi b gy on oo l op oq">correlationcoeff &lt;- function(x,y){<br/>    n = length(x)<br/>    yl = length(y)<br/>    xy = x * y<br/>    sx = sum(x)<br/>    sy = sum(y)<br/>    sxy = sum(xy)<br/>    x2 = x ^ 2<br/>    y2 = y ^ 2<br/>    sx2 = sum(x2)<br/>    sy2 = sum(y2)<br/>    r = ((n*sxy) - (sx * sy)) / (sqrt((((n*sx2)-(sx^2)) * ((n*sy2)-(sy^2)))))<br/>    return(r)<br/>}</span></pre><p id="e0be" class="pw-post-body-paragraph jx jy it jz b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku im bi translated">不用说，<strong class="jz iu">挺酷的</strong>！但是让我们更进一步，多做一点，只是说我们做到了。</p><h1 id="e6fd" class="ml mm it bd mn mo pc mq mr ms pd mu mv mw pe my mz na pf nc nd ne pg ng nh ni bi translated">相关系数…的平方</h1><p id="c181" class="pw-post-body-paragraph jx jy it jz b ka nj kc kd ke nk kg kh ki nl kk kl km nm ko kp kq nn ks kt ku im bi translated">回归的相关系数(相关系数的平方)也是一个非常酷的概念，您应该非常熟悉。r 分数因其用作连续模型回归度量而众所周知。r 通常以百分比形式计算，表示回归相似性或差异(对于机器学习来说，与训练集相似是件好事。)</p><figure class="md me mf mg gt ju gh gi paragraph-image"><div class="gh gi ph"><img src="../Images/ec188e1b30bb7fc92a8e69059b7dc365.png" data-original-src="https://miro.medium.com/v2/resize:fit:800/format:webp/1*VUwNP8T4ut-4FnR0W22IMQ.png"/></div></figure><p id="8b43" class="pw-post-body-paragraph jx jy it jz b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku im bi translated">好消息是，我们可以循环使用之前的函数，以获得与平方(r)的相关系数</p><pre class="md me mf mg gt oh oi oj ok aw ol bi"><span id="7c3c" class="om mm it oi b gy on oo l op oq">r2 &lt;- function(x,y){<br/>    r = correlationcoeff(x,y)<br/>    r2 = r ^ 2<br/>    return(r2)<br/>}</span></pre><blockquote class="le"><p id="732d" class="lf lg it bd lh li or os ot ou ov ku dk translated">简单，简单，柠檬榨汁机</p></blockquote><h1 id="2610" class="ml mm it bd mn mo pc mq mr ms pd mu mv mw pi my mz na pj nc nd ne pk ng nh ni bi translated">创建回归模型</h1><p id="98a3" class="pw-post-body-paragraph jx jy it jz b ka nj kc kd ke nk kg kh ki nl kk kl km nm ko kp kq nn ks kt ku im bi translated">使用我们用于特征选择的相关系数(r ),以及我们的相关决定系数(r ),我们现在可以着手编写一些重要的加权推理模型。让我们使用线性最小二乘回归方程！如果再正式一点的话，我们会创建一个可以放入预测函数的构造函数，这通常是处理模型时的一个好习惯，因为它们被视为对象类型，而不是一个单一的数学函数(可能是因为拟合变换)。)幸运的是，这个函数不是我的作品集，也不是任何形式的专利，所以我们只是将 x 和 y 放入参数中！</p><pre class="md me mf mg gt oh oi oj ok aw ol bi"><span id="aa75" class="om mm it oi b gy on oo l op oq">pred_linearleastsquare <strong class="oi iu">&lt;-</strong> <strong class="oi iu">function</strong>(x,y,xt){</span><span id="5a29" class="om mm it oi b gy pl oo l op oq"><em class="lu"># Summatation of x*y</em></span><span id="22f8" class="om mm it oi b gy pl oo l op oq">xy <strong class="oi iu">=</strong> x <strong class="oi iu">*</strong> y</span><span id="7be4" class="om mm it oi b gy pl oo l op oq">sxy <strong class="oi iu">=</strong> sum(xy)</span><span id="6b99" class="om mm it oi b gy pl oo l op oq"><em class="lu"># N</em></span><span id="4337" class="om mm it oi b gy pl oo l op oq">n <strong class="oi iu">=</strong> length(x)</span><span id="d39f" class="om mm it oi b gy pl oo l op oq"><em class="lu"># Summatation of x^2</em></span><span id="49ad" class="om mm it oi b gy pl oo l op oq">x2 <strong class="oi iu">=</strong> x <strong class="oi iu">^</strong> 2</span><span id="9124" class="om mm it oi b gy pl oo l op oq">sx2 <strong class="oi iu">=</strong> sum(x2)</span><span id="cbb7" class="om mm it oi b gy pl oo l op oq"><em class="lu"># Summatation of x and y</em></span><span id="c00b" class="om mm it oi b gy pl oo l op oq">sx <strong class="oi iu">=</strong> sum(x)</span><span id="fc92" class="om mm it oi b gy pl oo l op oq">sy <strong class="oi iu">=</strong> sum(y)</span><span id="3cd9" class="om mm it oi b gy pl oo l op oq"><em class="lu"># Calculate the slope:</em></span><span id="f259" class="om mm it oi b gy pl oo l op oq">slope <strong class="oi iu">=</strong> ((n<strong class="oi iu">*</strong>sxy) <strong class="oi iu">-</strong> (sx <strong class="oi iu">*</strong> sy)) <strong class="oi iu">/</strong> ((n <strong class="oi iu">*</strong> sx2) <strong class="oi iu">-</strong> (sx)<strong class="oi iu">^</strong>2)</span><span id="5699" class="om mm it oi b gy pl oo l op oq"><em class="lu"># Calculate the y intercept</em></span><span id="71e0" class="om mm it oi b gy pl oo l op oq">b <strong class="oi iu">=</strong> (sy <strong class="oi iu">-</strong> (slope<strong class="oi iu">*</strong>sx)) <strong class="oi iu">/</strong> n</span><span id="bb5e" class="om mm it oi b gy pl oo l op oq"><em class="lu"># Empty prediction list:</em></span><span id="dee4" class="om mm it oi b gy pl oo l op oq">y_pred <strong class="oi iu">=</strong> c()</span><span id="fb69" class="om mm it oi b gy pl oo l op oq"><strong class="oi iu">for</strong> (i <strong class="oi iu">in</strong> xt)</span><span id="6d0f" class="om mm it oi b gy pl oo l op oq">{</span><span id="5bad" class="om mm it oi b gy pl oo l op oq">pred <strong class="oi iu">=</strong> (slope<strong class="oi iu">*</strong>i)<strong class="oi iu">+</strong>b</span><span id="a3ca" class="om mm it oi b gy pl oo l op oq">y_pred <strong class="oi iu">=</strong> append(y_pred,pred)</span><span id="0392" class="om mm it oi b gy pl oo l op oq">}</span><span id="1c53" class="om mm it oi b gy pl oo l op oq">return(y_pred)</span><span id="9808" class="om mm it oi b gy pl oo l op oq">}</span></pre><blockquote class="le"><p id="d318" class="lf lg it bd lh li or os ot ou ov ku dk translated">让我们做一些数据</p></blockquote><figure class="pn po pp pq pr ju gh gi paragraph-image"><div role="button" tabindex="0" class="mh mi di mj bf mk"><div class="gh gi pm"><img src="../Images/7fa096b59dccccbd5ff710c953c553d5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ifhG5mL5go2NvRB9zK3xrA.png"/></div></div></figure><p id="3470" class="pw-post-body-paragraph jx jy it jz b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku im bi translated">显然，随机数据并不代表真实世界的情况，但是不必篡改数据清理来测试功能无疑是避免使用真实世界数据的一个可行的借口。</p></div><div class="ab cl lv lw hx lx" role="separator"><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma"/></div><div class="im in io ip iq"><h1 id="2f4d" class="ml mm it bd mn mo mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne nf ng nh ni bi translated">使用我们的功能</h1><p id="6533" class="pw-post-body-paragraph jx jy it jz b ka nj kc kd ke nk kg kh ki nl kk kl km nm ko kp kq nn ks kt ku im bi translated">首先，让我们从预测线性最小二乘函数开始:</p><pre class="md me mf mg gt oh oi oj ok aw ol bi"><span id="e3a9" class="om mm it oi b gy on oo l op oq">y_pred = pred_linearleastsquare(trainX,trainy,testX)</span></pre><p id="9f02" class="pw-post-body-paragraph jx jy it jz b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku im bi translated">然后我们可以使用 r2 来验证我们的模型做得有多好。</p><figure class="md me mf mg gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="mh mi di mj bf mk"><div class="gh gi ps"><img src="../Images/a8bd1b3eeff5257305aa3693bab1544c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*UowSu0Csm4imwNzkCwOsgw.png"/></div></div></figure><h1 id="b04b" class="ml mm it bd mn mo pc mq mr ms pd mu mv mw pe my mz na pf nc nd ne pg ng nh ni bi translated">但是 r 呢？</h1><p id="ac97" class="pw-post-body-paragraph jx jy it jz b ka nj kc kd ke nk kg kh ki nl kk kl km nm ko kp kq nn ks kt ku im bi translated">相关系数可以非常有效地提供两个不同特征之间的相关性信息，或者更好地提供特征和目标之间的相关性信息。我确实在条件模型中看到了很多 r 的使用，尤其是那些关于连续目标的模型。</p><p id="17f9" class="pw-post-body-paragraph jx jy it jz b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku im bi translated">所以，不用说，R，R 和 R 都是统计学和数据科学中非常酷和重要的概念。期待看到未来几年 R 的位置，以及其他语言的位置。</p></div></div>    
</body>
</html>