<html>
<head>
<title>Annotator Bias and Incomplete Annotations for Named Entity Recognition(NER)</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">命名实体识别中的标注者偏差和不完整标注(NER)</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/annotator-bias-and-incomplete-annotations-for-named-entity-recognition-ner-84819af730?source=collection_archive---------32-----------------------#2019-09-30">https://towardsdatascience.com/annotator-bias-and-incomplete-annotations-for-named-entity-recognition-ner-84819af730?source=collection_archive---------32-----------------------#2019-09-30</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="6a24" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">介绍 2019 年发表的两篇论文，涉及命名实体识别的不完全标注(NER)</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/2b306d6ea820253177c8fb2c68dc050b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*2yKpI-DmLmNlSi2SdAZGww.jpeg"/></div></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk">Photo by <a class="ae ky" href="https://unsplash.com/@alvaroreyes?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank">Alvaro Reyes</a> on <a class="ae ky" href="https://unsplash.com/collections/3550997/hist-gd-ux-presentation?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><p id="b2ca" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们知道深度学习(DL)的兴起离不开带注释的数据。换句话说，正是那些注释者让 DL 发展的如此之快。但他们也是人，他们有自己的注释习惯，也会犯错误。在本帖中，我将介绍一些有趣的论文。一篇论文是关于注释者的偏见，两篇论文是关于命名实体识别的不完整注释(NER)。</p><h1 id="9a88" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">em NLP-2019/11-我们是对任务建模还是对注释器建模？自然语言理解数据集中标注者偏差的研究</h1><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi mn"><img src="../Images/3cf6f17a2e2234d4134b6130962f6fc3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*mWUtA7DuJBA2Cug5CRWZwQ.png"/></div></div></figure><p id="2110" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这篇文章的出发点相当有趣。外包标注任务在业内很常见。我们可能关注注释的质量，但是很少关注<strong class="lb iu">注释者的偏见。注释者偏差</strong>意味着每个注释者都有自己标记数据的习惯，他们会给数据带来这样的偏差。本文表明<strong class="lb iu">注释者的偏见会影响模型的性能</strong>。如果在训练期间输入注释者标识符作为特征，模型将学习注释者的习惯并训练一个更健壮的模型。另一个有趣的发现是，模型不能很好地概括来自对训练集没有贡献的注释者的例子。具体来说，如果模型不能从训练集中学习注释者的习惯，它就不能很好地推广到测试集中。一个建议是，当我们注释数据集时，一个注释器应该同时注释训练集和测试集。</p><h1 id="70c6" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">NAACL-2019/06-对命名实体识别的不完整注释进行更好的建模</h1><h2 id="4523" class="mo lw it bd lx mp mq dn mb mr ms dp mf li mt mu mh lm mv mw mj lq mx my ml mz bi translated">注释者也是人，人也会犯错。注释数据不可能总是完美的。对于这种情况，我们必须找出如何更好地学习不完善的标注数据。这两篇论文是为 NER 任务学习这样的数据。</h2><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi na"><img src="../Images/a08143a182a7436be3c492ca53d8e8f2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*cL1kFNiu8ZTQ15bRHludhw.png"/></div></div></figure><p id="5cb0" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">上图显示了不完整的注释示例。为了更好地对不完整标注建模，作者提出了一种新的损失函数。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nb"><img src="../Images/13a779632f8374915ec5c042e0560a6c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*7ioe5aL0cfhi0-p0BJp6CA.png"/></div></div></figure><p id="274d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">为了对不完全标注建模，作者引入了一种新的概率分布<em class="nc"> q </em>来表示所有可能的标注。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi mn"><img src="../Images/7f69885d260efbf118f873182b4cd07b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*aq5UFKTkeCObp8km.png"/></div></div></figure><p id="11dd" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这个想法在上图的右下角。通过引入<em class="nc"> q </em>分布，该模型可以考虑不完整标签的所有可能路径。</p><p id="f12a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">如何学习<em class="nc"> q </em>分配？</p><p id="5228" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">作者提出了两种方法，硬方法和软方法。在硬方法中，所得的<em class="nc"> q </em>分布是将概率 1 分配给单个完整标签序列的折叠分布，而在软方法中，每个可能的标签序列将得到某个概率分数。</p><h1 id="24c0" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">EMNLP-2019/11-CrossWeigh:从不完善的注释中训练命名实体标记器</h1><p id="5791" class="pw-post-body-paragraph kz la it lb b lc nd ju le lf ne jx lh li nf lk ll lm ng lo lp lq nh ls lt lu im bi translated">NER 存在两种标签错误:(1)测试集中的错误会干扰评估结果，甚至导致对模型性能的不准确评估；以及(2)训练集中的错误会损害 NER 模型训练。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ni"><img src="../Images/bcb10359663b9ede0bdb932cfbf44eaa.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*jRaA5S9R8xHJDMxXy2d-dA.png"/></div></div></figure><p id="b559" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">来解决第一个问题。在本文中，他们纠正了测试集中的错误，以形成更清晰的基准，并开发了一个新颖的框架来处理训练集中的错误。他们纠正了 CoNLL03 NER 数据集的 5.38%标签错误测试句子。它表明，模型性能在更干净的测试数据集上有所提高。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nj"><img src="../Images/20a630525ae052de736464a17d32c821.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*6MLbFM1xDuxqLBNylugxTg.png"/></div></div></figure><p id="c9be" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">为了解决第二个问题，他们提出了一个交叉权重框架来更好地处理标签错误。这个框架包含两个部分。</p><ul class=""><li id="02e1" class="nk nl it lb b lc ld lf lg li nm lm nn lq no lu np nq nr ns bi translated">错误估计:通过交叉检查过程识别训练数据<br/>中潜在的标签错误。</li><li id="db21" class="nk nl it lb b lc nt lf nu li nv lm nw lq nx lu np nq nr ns bi translated">错误重新加权:在最终 NER 模型的训练过程中，它降低了这些实例的权重。交叉校验过程受 k 重交叉验证的启发；不同的是，在每个文件夹的训练数据中，它会删除包含该文件夹中出现的任何实体的数据。</li></ul><blockquote class="ny nz oa"><p id="2572" class="kz la nc lb b lc ld ju le lf lg jx lh ob lj lk ll oc ln lo lp od lr ls lt lu im bi translated"><strong class="lb iu"> <em class="it">查看我的其他帖子</em> </strong> <a class="ae ky" href="https://medium.com/@bramblexu" rel="noopener"> <strong class="lb iu"> <em class="it">中</em> </strong> </a> <strong class="lb iu"> <em class="it">同</em> </strong> <a class="ae ky" href="https://bramblexu.com/posts/eb7bd472/" rel="noopener ugc nofollow" target="_blank"> <strong class="lb iu"> <em class="it">一分类查看</em> </strong> </a> <strong class="lb iu"> <em class="it">！<br/>GitHub:</em></strong><a class="ae ky" href="https://github.com/BrambleXu" rel="noopener ugc nofollow" target="_blank"><strong class="lb iu"><em class="it">bramble Xu</em></strong></a><strong class="lb iu"><em class="it"><br/>LinkedIn:</em></strong><a class="ae ky" href="https://www.linkedin.com/in/xu-liang-99356891/" rel="noopener ugc nofollow" target="_blank"><strong class="lb iu"><em class="it">徐亮</em> </strong> </a> <strong class="lb iu"> <em class="it"> <br/>博客:</em></strong><a class="ae ky" href="https://bramblexu.com" rel="noopener ugc nofollow" target="_blank"><strong class="lb iu"><em class="it">bramble Xu</em></strong></a></p></blockquote><h1 id="2dcd" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">参考</h1><ul class=""><li id="44d6" class="nk nl it lb b lc nd lf ne li oe lm of lq og lu np nq nr ns bi translated"><a class="ae ky" href="https://arxiv.org/pdf/1908.07898.pdf" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/pdf/1908.07898.pdf</a></li><li id="1c65" class="nk nl it lb b lc nt lf nu li nv lm nw lq nx lu np nq nr ns bi translated"><a class="ae ky" href="https://www.aclweb.org/anthology/N19-1079" rel="noopener ugc nofollow" target="_blank">https://www.aclweb.org/anthology/N19-1079</a></li><li id="c7ec" class="nk nl it lb b lc nt lf nu li nv lm nw lq nx lu np nq nr ns bi translated"><a class="ae ky" href="https://arxiv.org/pdf/1909.01441.pdf" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/pdf/1909.01441.pdf</a></li></ul></div></div>    
</body>
</html>