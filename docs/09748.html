<html>
<head>
<title>Step by Step: Build Your Custom Real-Time Object Detector</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">一步一步:构建您的自定义实时对象检测器</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/detailed-tutorial-build-your-custom-real-time-object-detector-5ade1017fd2d?source=collection_archive---------0-----------------------#2019-12-22">https://towardsdatascience.com/detailed-tutorial-build-your-custom-real-time-object-detector-5ade1017fd2d?source=collection_archive---------0-----------------------#2019-12-22</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="fd6b" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">附有详细的笔记本:使用 Tensorflow API、Google Colab 和 GDrive 从现场摄像机中检测枪支。</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/7012386056f802e0554bcddf99bf31c8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*y2qKoh3IGljS5BQOSntEqg.png"/></div></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk">Model Inference on the <a class="ae ky" href="https://www.google.com/search?sxsrf=ACYBGNQ1tnoKUwuqjnhSn9w4bPdjP-UCSw%3A1577040012760&amp;ei=jLj_Xbz-LY_K_QajzZZQ&amp;q=Equilibrium+2002&amp;oq=Equilibrium+2002&amp;gs_l=psy-ab.3..35i39j0i67l2j0l7.1835.1835..2009...0.2..0.64.64.1......0....1..gws-wiz.......0i71.oHYYez4zbOo&amp;ved=0ahUKEwi89Ibu88nmAhUPZd8KHaOmBQoQ4dUDCAs&amp;uact=5" rel="noopener ugc nofollow" target="_blank">Equilibrium</a>, 2002 <a class="ae ky" href="https://www.youtube.com/watch?v=4weEXyoXZKs" rel="noopener ugc nofollow" target="_blank">Video Clip</a></figcaption></figure><p id="b2f3" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi lv translated">当事故发生时，政策响应时间非常关键。在美国，警察的平均反应时间约为 18 分钟。<a class="ae ky" href="http://1. https://www.policemag.com/341042/quicker-response-to-active-shooters" rel="noopener ugc nofollow" target="_blank"> </a> <br/>在我的上一个项目中，我试图通过在现场闭路电视摄像机中检测武器来最大限度地缩短警方的反应时间，作为一种一旦检测到枪支就向他们发出警报的方法。这个项目的主要动机是因为美国校园枪击事件越来越多</p><p id="9166" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在本教程中，我们将:</p><ul class=""><li id="8e68" class="me mf it lb b lc ld lf lg li mg lm mh lq mi lu mj mk ml mm bi translated">使用 Tensorflow 对象检测 API 对自定义图像执行对象检测</li><li id="a5d2" class="me mf it lb b lc mn lf mo li mp lm mq lq mr lu mj mk ml mm bi translated">使用<strong class="lb iu"> Google Colab </strong>免费的<strong class="lb iu"> GPU </strong>进行训练，使用<strong class="lb iu"> Google Drive </strong>保持一切同步。</li><li id="cc91" class="me mf it lb b lc mn lf mo li mp lm mq lq mr lu mj mk ml mm bi translated">使用本地网络摄像头调整、训练、监控和使用模型进行推理的详细步骤。</li></ul><p id="ef18" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">如果你想开始探索，我已经创建了这个<a class="ae ky" href="https://colab.research.google.com/github/AlaaSenjab/-Tutorial-Tensorflow_Object_Detection_API_On_Custom_Dataset/blob/master/weapon_detection_BL.ipynb" rel="noopener ugc nofollow" target="_blank"> <strong class="lb iu"> Colab 笔记本</strong> </a>。它有一些这里没有提到的步骤和注意事项。建议看完这个教程再看<em class="ms">。</em></p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="mt mu l"/></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk">Model Inference on the <a class="ae ky" href="https://www.google.com/search?sxsrf=ACYBGNQ1tnoKUwuqjnhSn9w4bPdjP-UCSw%3A1577040012760&amp;ei=jLj_Xbz-LY_K_QajzZZQ&amp;q=Equilibrium+2002&amp;oq=Equilibrium+2002&amp;gs_l=psy-ab.3..35i39j0i67l2j0l7.1835.1835..2009...0.2..0.64.64.1......0....1..gws-wiz.......0i71.oHYYez4zbOo&amp;ved=0ahUKEwi89Ibu88nmAhUPZd8KHaOmBQoQ4dUDCAs&amp;uact=5" rel="noopener ugc nofollow" target="_blank">Equilibrium</a>, 2002 <a class="ae ky" href="https://www.youtube.com/watch?v=4weEXyoXZKs" rel="noopener ugc nofollow" target="_blank">Video Clip</a></figcaption></figure><p id="0ee3" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们开始吧，好吗？</p><h2 id="e9ef" class="mv mw it bd mx my mz dn na nb nc dp nd li ne nf ng lm nh ni nj lq nk nl nm nn bi translated">路线图:</h2><p id="e755" class="pw-post-body-paragraph kz la it lb b lc no ju le lf np jx lh li nq lk ll lm nr lo lp lq ns ls lt lu im bi translated">1.<a class="ae ky" href="#862a" rel="noopener ugc nofollow">采集图像和标签</a>。<br/> 2。建立环境。<br/> 3。<a class="ae ky" href="#7b1a" rel="noopener ugc nofollow">导入并安装所需的软件包</a>。<br/> 4。<a class="ae ky" href="#30ac" rel="noopener ugc nofollow">预处理图像和标签</a>。<br/> 5。<a class="ae ky" href="#ae83" rel="noopener ugc nofollow">下载<strong class="lb iu"> Tensorflow </strong>模型</a>。<br/> 6。<a class="ae ky" href="#afd3" rel="noopener ugc nofollow">生成<strong class="lb iu">TF records</strong>T37】。<br/> 7。</a><a class="ae ky" href="#d582" rel="noopener ugc nofollow">选择并下载预先训练好的模型</a>。<br/> 8。<a class="ae ky" href="#e41c" rel="noopener ugc nofollow">配置培训管道</a>。<br/> 9。<a class="ae ky" href="#78cd" rel="noopener ugc nofollow">张量板</a>。<br/> 10。<a class="ae ky" href="#5f34" rel="noopener ugc nofollow">训练</a>。<br/> 11。<a class="ae ky" href="#b948" rel="noopener ugc nofollow">导出训练好的模型</a>。<br/> 12。<a class="ae ky" href="#695b" rel="noopener ugc nofollow">网络摄像头推断</a>。</p></div><div class="ab cl nt nu hx nv" role="separator"><span class="nw bw bk nx ny nz"/><span class="nw bw bk nx ny nz"/><span class="nw bw bk nx ny"/></div><div class="im in io ip iq"><h1 id="862a" class="oa mw it bd mx ob oc od na oe of og nd jz oh ka ng kc oi kd nj kf oj kg nm ok bi translated">1.收集图像和标签。</h1><p id="a62a" class="pw-post-body-paragraph kz la it lb b lc no ju le lf np jx lh li nq lk ll lm nr lo lp lq ns ls lt lu im bi translated">我会用手枪的照片。<a class="ae ky" href="https://sci2s.ugr.es/weapons-detection" rel="noopener ugc nofollow" target="_blank">原始数据集</a>由西班牙<a class="ae ky" href="https://www.ugr.es/en/" rel="noopener ugc nofollow" target="_blank">格拉纳达</a>大学收集并标记。该数据集包含 3000 张不同位置、旋转、背景等的枪支照片。枪也已经贴好标签了(不是最好的)。你可以使用你自己的图片或者我在这里使用的数据集！</p><h2 id="4721" class="mv mw it bd mx my mz dn na nb nc dp nd li ne nf ng lm nh ni nj lq nk nl nm nn bi translated">➊.收集图像:</h2><p id="b22d" class="pw-post-body-paragraph kz la it lb b lc no ju le lf np jx lh li nq lk ll lm nr lo lp lq ns ls lt lu im bi translated">如果你已经收集了你的图片，那太好了！如果没有，根据你的问题，你可以从手机拍照或从谷歌上搜索图片。</p><p id="03e9" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">记住</strong>:垃圾进=垃圾出。选择图片是最重要的部分！<br/>以下是收集图像时可能会有所帮助的一些提示:</p><ol class=""><li id="bf42" class="me mf it lb b lc ld lf lg li mg lm mh lq mi lu ol mk ml mm bi translated">每节课至少 50 张图片。越多越好！如果您只检测一个类，甚至可以获得更多。</li><li id="f285" class="me mf it lb b lc mn lf mo li mp lm mq lq mr lu ol mk ml mm bi translated">背景中有随机对象的图像。</li><li id="52ea" class="me mf it lb b lc mn lf mo li mp lm mq lq mr lu ol mk ml mm bi translated">各种背景条件；黑暗、明亮、室内/室外等。</li></ol><p id="419b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">收集图片最简单的方法之一就是使用<a class="ae ky" href="https://github.com/hardikvasa/google-images-download" rel="noopener ugc nofollow" target="_blank"> <strong class="lb iu">谷歌-图片-下载</strong> </a> <strong class="lb iu">。</strong>您也可以使用<strong class="lb iu"> </strong> <a class="ae ky" href="https://www.pyimagesearch.com/2017/12/04/how-to-create-a-deep-learning-dataset-using-google-images/" rel="noopener ugc nofollow" target="_blank">下载图片。本</a>教程提供了多种从谷歌收集图片的方法。</p><p id="04d3" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">将您的图像保存在名为<code class="fe om on oo op b">images</code>的文件夹中</p><p id="db6c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu"> <em class="ms">注意</em> </strong> <em class="ms">:确保所有图像都是</em> <strong class="lb iu"> <em class="ms">。jpg </em> </strong> <em class="ms">，如果图像在不同的扩展名中，您可能会在训练时出错。</em></p><h2 id="d846" class="mv mw it bd mx my mz dn na nb nc dp nd li ne nf ng lm nh ni nj lq nk nl nm nn bi translated">➋.标记图像:</h2><p id="f169" class="pw-post-body-paragraph kz la it lb b lc no ju le lf np jx lh li nq lk ll lm nr lo lp lq ns ls lt lu im bi translated">一旦你收集了你的图片，是时候给它们贴上标签了。有许多工具可以帮助你标记你的图像。也许，<a class="ae ky" href="https://github.com/tzutalin/labelImg" rel="noopener ugc nofollow" target="_blank"> <strong class="lb iu"> LabelImg </strong> </a>是最受欢迎也是最容易使用的。使用 github repo 中的说明，下载并安装到您的本地机器上。</p><p id="e674" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">使用<strong class="lb iu">标签</strong>很简单，只要记住:</p><ol class=""><li id="287a" class="me mf it lb b lc ld lf lg li mg lm mh lq mi lu ol mk ml mm bi translated">为标签创建一个新目录，我将其命名为<code class="fe om on oo op b">annotations</code></li><li id="99f8" class="me mf it lb b lc mn lf mo li mp lm mq lq mr lu ol mk ml mm bi translated">在<strong class="lb iu">标签框</strong>中，点击<strong class="lb iu">更改保存目录</strong>并选择<code class="fe om on oo op b">annotations</code>文件夹。这是保存标签/注释的位置。</li><li id="6902" class="me mf it lb b lc mn lf mo li mp lm mq lq mr lu ol mk ml mm bi translated">点击<strong class="lb iu">打开目录</strong>并选择图像文件夹。</li><li id="9fbf" class="me mf it lb b lc mn lf mo li mp lm mq lq mr lu ol mk ml mm bi translated">使用快捷方式可以加快速度。</li></ol><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oq"><img src="../Images/6b4cfef0bd9c101effc79506ea5d60d1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/1*GUyV6ecnz3JeLRaVMo134A.gif"/></div></div></figure><pre class="kj kk kl km gt or op os ot aw ou bi"><span id="08c8" class="mv mw it op b gy ov ow l ox oy">Shortcuts for MacOS:<br/>_____<br/>| CMD + s | Save the label<br/>_<br/>|    w    | Create a box<br/>_<br/>|    d    | Next image<br/>|    a    | Previous image<br/>_<br/>| CMD + + | Zoom in<br/>| CMD + - | Zoom out<br/>_____</span></pre><p id="6a7e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">默认情况下，标签将采用 PascalVOC 格式。每个图像将有一个<strong class="lb iu">。有标签的 xml </strong>文件。如果一幅图像中有不止一个类或一个标签，那<strong class="lb iu">。xml </strong>文件将包括它们全部。</p></div><div class="ab cl nt nu hx nv" role="separator"><span class="nw bw bk nx ny nz"/><span class="nw bw bk nx ny nz"/><span class="nw bw bk nx ny"/></div><div class="im in io ip iq"><h1 id="4418" class="oa mw it bd mx ob oc od na oe of og nd jz oh ka ng kc oi kd nj kf oj kg nm ok bi translated">2.设置环境。</h1><h2 id="8875" class="mv mw it bd mx my mz dn na nb nc dp nd li ne nf ng lm nh ni nj lq nk nl nm nn bi translated">➊.设置 Google Colab 笔记本:</h2><ol class=""><li id="f479" class="me mf it lb b lc no lf np li oz lm pa lq pb lu ol mk ml mm bi translated">创建一个<a class="ae ky" href="https://colab.research.google.com/notebook#create=true&amp;language=python3" rel="noopener ugc nofollow" target="_blank">新的</a>笔记本。</li><li id="9a0a" class="me mf it lb b lc mn lf mo li mp lm mq lq mr lu ol mk ml mm bi translated">从左上角菜单:进入<strong class="lb iu">运行时</strong> &gt; <strong class="lb iu">更改运行时类型</strong> &gt;从<strong class="lb iu">硬件加速器中选择<strong class="lb iu"> GPU </strong>。一些预训练的模型支持 TPU。我们在这个项目中选择的预训练模型只支持 GPU。</strong></li><li id="97ef" class="me mf it lb b lc mn lf mo li mp lm mq lq mr lu ol mk ml mm bi translated">(强烈推荐)将 Google Drive 安装到 Colab <strong class="lb iu"> </strong>笔记本上:</li></ol><p id="db21" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">当训练开始时，将创建检查点、日志和许多其他重要文件。当内核断开连接时，如果这些文件没有保存在你的 Google Drive 或其他地方，它们和其他所有文件都会被删除。在你的电脑睡眠后或使用 Colab GPU 12 小时后，内核会立即断开连接。如果训练的模型没有被保存，则需要从零重新开始训练。我也高度推荐下载谷歌备份和同步应用程序，这样移动和编辑文件就更容易了，也能让一切保持同步。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pc"><img src="../Images/19241a6647ba9c7d93984e39daf3b2dd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*T1YcTFmU-T7eNC-tVAs7kw.png"/></div></div></figure><ul class=""><li id="d238" class="me mf it lb b lc ld lf lg li mg lm mh lq mi lu mj mk ml mm bi translated">打开你的<a class="ae ky" href="https://drive.google.com/" rel="noopener ugc nofollow" target="_blank">谷歌硬盘</a>，创建一个名为<code class="fe om on oo op b">object_detection</code>的文件夹</li><li id="5bc1" class="me mf it lb b lc mn lf mo li mp lm mq lq mr lu mj mk ml mm bi translated">在本地机器上打开谷歌备份和同步应用程序，选择<code class="fe om on oo op b">object_detection</code>文件夹，</li></ul><p id="070a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">注意:这种方法很大程度上取决于你的网络连接速度。</p><p id="73c6" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi">.</p><p id="e5ab" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在 Colab 笔记本上，挂载 gdrive 并导航到项目的文件夹，会要求您输入授权代码:</p><pre class="kj kk kl km gt or op os ot aw ou bi"><span id="7eaa" class="mv mw it op b gy ov ow l ox oy">from google.colab import drive<br/> <br/>drive.mount('/gdrive')</span><span id="9a26" class="mv mw it op b gy pd ow l ox oy"># the project's folder<br/>%cd /gdrive/'My Drive'/<!-- -->object_detection</span></pre><h2 id="52d2" class="mv mw it bd mx my mz dn na nb nc dp nd li ne nf ng lm nh ni nj lq nk nl nm nn bi translated">➋.上传您的图像和标签:</h2><p id="a2a8" class="pw-post-body-paragraph kz la it lb b lc no ju le lf np jx lh li nq lk ll lm nr lo lp lq ns ls lt lu im bi translated">在<code class="fe om on oo op b">object_detection</code>文件夹中，创建一个包含图像和标签的文件夹<code class="fe om on oo op b">data</code>。选择以下方法之一上传您的数据。</p><ol class=""><li id="301d" class="me mf it lb b lc ld lf lg li mg lm mh lq mi lu ol mk ml mm bi translated">使用谷歌备份和同步应用程序:</li></ol><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pe"><img src="../Images/6486aabe18b1fbc034f162d519207522.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*XhOEi_rszTQFex5DglXCKA.png"/></div></div></figure><p id="05f8" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">上传<code class="fe om on oo op b">images</code>和<code class="fe om on oo op b">annotations</code>文件夹很容易；只需将它们从您的计算机移动到<code class="fe om on oo op b">data/object_detection </code>文件夹中。</p><p id="7486" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi">.</p><p id="092d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi">.</p><p id="ebac" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">2.直接从笔记本上传:</p><p id="58d9" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu"> <em class="ms">注</em> </strong> <em class="ms">:这种方法最慢。</em></p><p id="fd77" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">使用以下内容直接上传到笔记本。你必须压缩<code class="fe om on oo op b">images</code>文件夹或者单独上传它们(不支持上传文件夹到 Google Colab)。组织和拥有相同的文件结构非常重要。</p><pre class="kj kk kl km gt or op os ot aw ou bi"><span id="d289" class="mv mw it op b gy ov ow l ox oy">from google.colab import files</span><span id="b325" class="mv mw it op b gy pd ow l ox oy">uploaded = files.upload()</span></pre><p id="c6c7" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">3.直接从来源上传:</p><p id="6aa1" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">您也可以使用<code class="fe om on oo op b">curl</code>或<code class="fe om on oo op b">wget</code>直接从信号源下载</p><p id="0eca" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">到目前为止的工作目录:</strong></p><pre class="kj kk kl km gt or op os ot aw ou bi"><span id="1564" class="mv mw it op b gy ov ow l ox oy">object_detection<br/>             └── data<br/>                   ├── images<br/>                   │      ├── image_1.jpg<br/>                   │      ├── image_2.jpg<br/>                   │      └── ...<br/>                   │<br/>                   └── <!-- -->annotations<br/>                          ├── image_1.xml<br/>                          ├── image_2.xml<br/>                          └── ...</span></pre><p id="ff56" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">提示</strong>:你可以在<strong class="lb iu"> Google Colab </strong>笔记本上查看完整的工作目录，方法是:点击左上角的箭头打开左侧面板。或者使用<strong class="lb iu">⌘</strong>/<strong class="lb iu">ctrl</strong>+<strong class="lb iu">alt</strong>+<strong class="lb iu">p<br/></strong>然后点击左上角菜单中的<strong class="lb iu">文件</strong>。</p><h2 id="6cce" class="mv mw it bd mx my mz dn na nb nc dp nd li ne nf ng lm nh ni nj lq nk nl nm nn bi translated">➌.将图像分为训练和测试:</h2><p id="53f6" class="pw-post-body-paragraph kz la it lb b lc no ju le lf np jx lh li nq lk ll lm nr lo lp lq ns ls lt lu im bi translated">根据数据集的大小，您可能需要手动分割数据。如果你有很多图片，你可能想用这样的东西来随机分割你的数据。</p><p id="7912" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu"> <em class="ms">注意:</em></strong><em class="ms"/><code class="fe om on oo op b"><em class="ms">images</em></code><em class="ms">里面的图像不需要拆分，只需要</em> <strong class="lb iu"> <em class="ms">。xml </em> </strong> <em class="ms">文件。</em></p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="pf mu l"/></div></figure><p id="181d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">此时的工作目录:</strong></p><pre class="kj kk kl km gt or op os ot aw ou bi"><span id="ae67" class="mv mw it op b gy ov ow l ox oy">object_detection<br/>             └── data<br/>                   ├── images<br/>                   │      ├── image_1.jpg<br/>                   │      └── ...<br/>                   │<br/>                   ├── <!-- -->annotations<br/>                   │      ├── image_1.xml<br/>                   │      └── ...<br/>                   │<br/>                   ├── train_labels <!-- -->//contains the labels only<br/>                   │      ├── image_1.xml<br/>                   │      └── ...<br/>                   │<br/>                   └── <!-- -->test_labels //contains the labels only <br/>                          ├── image_50.xml<br/>                          └── ...</span></pre></div><div class="ab cl nt nu hx nv" role="separator"><span class="nw bw bk nx ny nz"/><span class="nw bw bk nx ny nz"/><span class="nw bw bk nx ny"/></div><div class="im in io ip iq"><h1 id="7b1a" class="oa mw it bd mx ob oc od na oe of og nd jz oh ka ng kc oi kd nj kf oj kg nm ok bi translated">3.导入和安装所需的软件包。</h1><h2 id="36fd" class="mv mw it bd mx my mz dn na nb nc dp nd li ne nf ng lm nh ni nj lq nk nl nm nn bi translated">➊.安装所需的软件包:</h2><p id="47c5" class="pw-post-body-paragraph kz la it lb b lc no ju le lf np jx lh li nq lk ll lm nr lo lp lq ns ls lt lu im bi translated">Google Colab 已经预装了大部分软件包；Python，Tensorflow，熊猫等。</p><p id="fb3e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这些是我们需要的软件包，默认情况下不会预装。通过运行以下命令来安装它们:</p><pre class="kj kk kl km gt or op os ot aw ou bi"><span id="6dfb" class="mv mw it op b gy ov ow l ox oy">!apt-get install -qq protobuf-compiler python-pil python-lxml python-tk</span><span id="75cb" class="mv mw it op b gy pd ow l ox oy">!pip install -qq Cython contextlib2 pillow lxml matplotlib pycocotools</span></pre><h2 id="2d52" class="mv mw it bd mx my mz dn na nb nc dp nd li ne nf ng lm nh ni nj lq nk nl nm nn bi translated">➋.导入库:</h2><p id="0abf" class="pw-post-body-paragraph kz la it lb b lc no ju le lf np jx lh li nq lk ll lm nr lo lp lq ns ls lt lu im bi translated">其他导入将在以后需要时完成。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="pf mu l"/></div></figure><p id="3891" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们需要 Tensorflow 版本 1.15.0。通过运行以下命令检查 Tensorflow 版本:</p><pre class="kj kk kl km gt or op os ot aw ou bi"><span id="e8bc" class="mv mw it op b gy ov ow l ox oy">print(tf.__version__)</span></pre></div><div class="ab cl nt nu hx nv" role="separator"><span class="nw bw bk nx ny nz"/><span class="nw bw bk nx ny nz"/><span class="nw bw bk nx ny"/></div><div class="im in io ip iq"><h1 id="30ac" class="oa mw it bd mx ob oc od na oe of og nd jz oh ka ng kc oi kd nj kf oj kg nm ok bi translated">4.预处理图像和标签。</h1><p id="5715" class="pw-post-body-paragraph kz la it lb b lc no ju le lf np jx lh li nq lk ll lm nr lo lp lq ns ls lt lu im bi translated">我们需要为创建两个<strong class="lb iu"> csv </strong>文件。<strong class="lb iu"> xml </strong>文件中的每一个<code class="fe om on oo op b">train_labels/</code>和<code class="fe om on oo op b">test_labels/</code></p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pg"><img src="../Images/a5630afacb52fbeeba1b087ac368cab7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ZOsFZj-lmJXmWxwAI_V06w.png"/></div></div></figure><p id="d7ab" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这两个<strong class="lb iu"> csv </strong>文件将包含每个图像的文件名、标签/盒子位置等。此外，如果同一张图片有多个类别或标签，则会为其创建多个行。</p><p id="5e77" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">除了<strong class="lb iu"> CSV </strong> s，我们还需要创建一个<strong class="lb iu"> pbtxt </strong>文件来包含每个类的标签映射。这个文件将通过定义类名到类 ID 号的映射来告诉模型每个对象是什么。</p><p id="f8c6" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">您不必手动执行这些操作，下面的操作会将<strong class="lb iu"> xml </strong>文件转换成两个<strong class="lb iu"> csv </strong>文件，并创建<code class="fe om on oo op b">.pbtxt</code>文件。只要确保:</p><ul class=""><li id="ab73" class="me mf it lb b lc ld lf lg li mg lm mh lq mi lu mj mk ml mm bi translated">匹配<strong class="lb iu"> xml </strong>所在的相同文件夹的名称:<code class="fe om on oo op b">train_labels/</code>和<code class="fe om on oo op b">test_labels/</code>(或者更改为下面的代码)</li><li id="dda0" class="me mf it lb b lc mn lf mo li mp lm mq lq mr lu mj mk ml mm bi translated">当前目录是<code class="fe om on oo op b">object_detection/data/</code></li><li id="f061" class="me mf it lb b lc mn lf mo li mp lm mq lq mr lu mj mk ml mm bi translated">图像在<strong class="lb iu">。jpg </strong>格式</li></ul><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="pf mu l"/></div></figure><p id="4f11" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">此时的工作目录:</strong></p><pre class="kj kk kl km gt or op os ot aw ou bi"><span id="60a6" class="mv mw it op b gy ov ow l ox oy">object_detection/<br/>             └── data/<br/>                   ├── images/<br/>                   │      └── ...<br/>                   ├── <!-- -->annotations/<br/>                   │      └── ...<br/>                   ├── train_labels/<br/>                   │      └── ...<br/>                   ├── <!-- -->test_labels/<br/>                   │    └── ...<br/>                   │<br/>                   ├── label_map.pbtxt<br/>                   │<br/>                   ├── test_labels.csv<br/>                   │<br/>                   └── train_labels.csv</span></pre></div><div class="ab cl nt nu hx nv" role="separator"><span class="nw bw bk nx ny nz"/><span class="nw bw bk nx ny nz"/><span class="nw bw bk nx ny"/></div><div class="im in io ip iq"><h1 id="ae83" class="oa mw it bd mx ob oc od na oe of og nd jz oh ka ng kc oi kd nj kf oj kg nm ok bi translated">5.正在下载张量流模型。</h1><p id="7a69" class="pw-post-body-paragraph kz la it lb b lc no ju le lf np jx lh li nq lk ll lm nr lo lp lq ns ls lt lu im bi translated">Tensorflow 模型包含了我们感兴趣的对象检测 API。我们会从<a class="ae ky" href="https://github.com/tensorflow/models" rel="noopener ugc nofollow" target="_blank">官方回购</a>中得到。</p><ul class=""><li id="1fdc" class="me mf it lb b lc ld lf lg li mg lm mh lq mi lu mj mk ml mm bi translated">导航到<code class="fe om on oo op b">object_detection/</code>目录，然后:</li></ul><pre class="kj kk kl km gt or op os ot aw ou bi"><span id="6be9" class="mv mw it op b gy ov ow l ox oy"># downloads the models<br/>!git clone --q <a class="ae ky" href="https://github.com/tensorflow/models.git" rel="noopener ugc nofollow" target="_blank">https://github.com/tensorflow/models.git</a></span></pre><p id="bcd3" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">接下来，我们需要编译 proto buffers——理解这个项目并不重要，但是你可以在这里了解更多。此外，PATH var 应该添加以下目录:<code class="fe om on oo op b">models/research/</code>和<code class="fe om on oo op b">models/research/slim/</code></p><ul class=""><li id="dec9" class="me mf it lb b lc ld lf lg li mg lm mh lq mi lu mj mk ml mm bi translated">导航至<code class="fe om on oo op b">object_detection/models/research/</code>目录，然后:</li></ul><pre class="kj kk kl km gt or op os ot aw ou bi"><span id="2051" class="mv mw it op b gy ov ow l ox oy"># compils the proto buffers<br/>!protoc object_detection/protos/*.proto --python_out=.</span><span id="93b2" class="mv mw it op b gy pd ow l ox oy"># exports PYTHONPATH environment var with research and slim paths<br/>os.environ['PYTHONPATH'] += ':./:./slim/'</span></pre><p id="9e11" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">最后，运行一个快速测试来确认模型构建器工作正常:</p><pre class="kj kk kl km gt or op os ot aw ou bi"><span id="300b" class="mv mw it op b gy ov ow l ox oy"># testing the model builder<br/>!python3 object_detection/builders/model_builder_test.py</span></pre><p id="ca41" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">如果你在测试结束时看到一个<code class="fe om on oo op b">OK</code>，那么一切都很好！</p></div><div class="ab cl nt nu hx nv" role="separator"><span class="nw bw bk nx ny nz"/><span class="nw bw bk nx ny nz"/><span class="nw bw bk nx ny"/></div><div class="im in io ip iq"><h1 id="afd3" class="oa mw it bd mx ob oc od na oe of og nd jz oh ka ng kc oi kd nj kf oj kg nm ok bi translated">6.正在生成 TFRecords。</h1><p id="df32" class="pw-post-body-paragraph kz la it lb b lc no ju le lf np jx lh li nq lk ll lm nr lo lp lq ns ls lt lu im bi translated">Tensorflow 接受数据作为 TFRecords <code class="fe om on oo op b">data.record</code>。TFRecord 是一个二进制文件，运行速度快，内存使用率低。它在一个文件中包含所有的图像和标签。点击阅读更多相关信息<a class="ae ky" href="https://www.skcript.com/svr/why-every-tensorflow-developer-should-know-about-tfrecord/" rel="noopener ugc nofollow" target="_blank">。</a></p><p id="05eb" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在我们的例子中，我们将有两个 TFRecords 一个用于测试，另一个用于培训。要做到这一点，我们需要确保:</p><ul class=""><li id="21f4" class="me mf it lb b lc ld lf lg li mg lm mh lq mi lu mj mk ml mm bi translated">匹配<strong class="lb iu"> CSV </strong> s 文件名:<code class="fe om on oo op b">train_labels.csv</code>和<code class="fe om on oo op b">test_labels.csv</code>(或者在下面的代码中更改)</li><li id="e266" class="me mf it lb b lc mn lf mo li mp lm mq lq mr lu mj mk ml mm bi translated">当前目录是<code class="fe om on oo op b">object_detection/models/research</code></li><li id="f227" class="me mf it lb b lc mn lf mo li mp lm mq lq mr lu mj mk ml mm bi translated">通过改变<code class="fe om on oo op b">row_label</code>变量，在下面的函数<code class="fe om on oo op b">class_text_to_int</code>中添加您的自定义对象文本(这是将出现在被检测对象上的文本)。如果有多个对象，请添加更多标签。</li><li id="78a4" class="me mf it lb b lc mn lf mo li mp lm mq lq mr lu mj mk ml mm bi translated">检查到<code class="fe om on oo op b">data/</code>目录的路径是否与下面的<code class="fe om on oo op b">data_base_url</code>相同。</li></ul><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="pf mu l"/></div></figure></div><div class="ab cl nt nu hx nv" role="separator"><span class="nw bw bk nx ny nz"/><span class="nw bw bk nx ny nz"/><span class="nw bw bk nx ny"/></div><div class="im in io ip iq"><h1 id="d582" class="oa mw it bd mx ob oc od na oe of og nd jz oh ka ng kc oi kd nj kf oj kg nm ok bi translated">7.选择和下载预先训练的模型。</h1><h2 id="4de6" class="mv mw it bd mx my mz dn na nb nc dp nd li ne nf ng lm nh ni nj lq nk nl nm nn bi translated">➊.选择预先训练的模型:</h2><p id="165e" class="pw-post-body-paragraph kz la it lb b lc no ju le lf np jx lh li nq lk ll lm nr lo lp lq ns ls lt lu im bi translated">预训练模型仅仅意味着它已经在另一个数据集上被训练过。这个模型已经看到了成千上万的图像和物体。<br/> <a class="ae ky" href="http://cocodataset.org/#home" rel="noopener ugc nofollow" target="_blank"> COCO </a>(上下文中的常见对象)是一个包含 33 万幅图像的数据集，其中包含 80 个不同类别的 150 万个对象。比如，狗，猫，车，香蕉，…在这里勾选所有类别<a class="ae ky" href="https://gist.github.com/AruniRC/7b3dadd004da04c80198557db5da4bda" rel="noopener ugc nofollow" target="_blank">。</a></p><p id="4f3c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">从头开始训练一个模型是极其耗时的；完成训练可能需要几天或几周的时间。一个预先训练好的模型已经看到了大量的物体，并且知道如何对它们进行分类。所以，为什么不直接用它呢！</p><p id="055a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">因为我们的兴趣是干扰实时视频，我们将选择一个具有低<strong class="lb iu"> ms </strong>推理速度和相对高<strong class="lb iu">地图</strong>的模型。</p><p id="965a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">本项目使用的型号为<strong class="lb iu"> ssd_mobilenet_v2_coco </strong>。从<a class="ae ky" href="https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/detection_model_zoo.md#coco-trained-models" rel="noopener ugc nofollow" target="_blank">到<strong class="lb iu">此处</strong>到</a>查看其他型号。你可以使用任何你喜欢的预先训练的模型，但我建议先用<strong class="lb iu">SSD’</strong>single shot detector’模型进行实验，因为它们在实时视频<a class="ae ky" href="http://4. https://towardsdatascience.com/review-ssd-single-shot-detector-object-detection-851a94607d11" rel="noopener ugc nofollow" target="_blank"> ⁴ </a>上的表现比任何类型的 RCNN 都要快。</p><p id="7ae9" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">解释对象检测技术之间的区别超出了本教程的范围。你可以从<a class="ae ky" href="https://heartbeat.fritz.ai/a-2019-guide-to-object-detection-9509987954c3" rel="noopener ugc nofollow" target="_blank">这篇</a>博客文章中读到更多关于它们的信息，或者从<a class="ae ky" href="https://heartbeat.fritz.ai/a-2019-guide-to-object-detection-9509987954c3" rel="noopener ugc nofollow" target="_blank">这里</a>了解它们的速度和准确性。</p><p id="26b7" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">让我们从选择一个预训练模型开始:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="pf mu l"/></div></figure><p id="8a50" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们将下载选定的模型。我创建了这两个模型配置来使它更容易。这里选择的是<strong class="lb iu"> ssd_mobilenet_v2 </strong>，如果你愿意的话，可以稍后尝试使用<strong class="lb iu">faster _ rcnn _ inception _ v2</strong><strong class="lb iu"/>。只需改变上面的<code class="fe om on oo op b">selected_model</code>。</p><h2 id="47f1" class="mv mw it bd mx my mz dn na nb nc dp nd li ne nf ng lm nh ni nj lq nk nl nm nn bi translated">➋.下载预训练模型:</h2><ul class=""><li id="fdc7" class="me mf it lb b lc no lf np li oz lm pa lq pb lu mj mk ml mm bi translated">导航至<code class="fe om on oo op b">models/research/</code></li><li id="bce0" class="me mf it lb b lc mn lf mo li mp lm mq lq mr lu mj mk ml mm bi translated"><code class="fe om on oo op b">DEST_DIR</code>是下载模型的地方。如果您有不同的工作目录，请更改它。</li></ul><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="pf mu l"/></div></figure><p id="cc0a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在训练时，默认情况下，模型会每 600 秒自动保存一次。日志和图形，如<strong class="lb iu">图</strong>、<strong class="lb iu">损失</strong>和<strong class="lb iu"> AR、</strong>也会不断保存。让我们为它们创建一个文件夹，以便在培训期间保存:</p><ul class=""><li id="6603" class="me mf it lb b lc ld lf lg li mg lm mh lq mi lu mj mk ml mm bi translated">在<code class="fe om on oo op b">object_detection/model/research/</code>里面创建一个名为<code class="fe om on oo op b">training</code>的文件夹</li></ul><p id="2965" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">此时的工作目录:</strong></p><pre class="kj kk kl km gt or op os ot aw ou bi"><span id="e0f3" class="mv mw it op b gy ov ow l ox oy">object_detection/<br/>           ├── data/<br/>           │    ├── images/<br/>           │    │      └── ...<br/>           │    ├── <!-- -->annotations/<br/>           │    │      └── ...<br/>           │    ├── train_labels/<br/>           │    │      └── ...<br/>           │    ├── <!-- -->test_labels/<br/>           │    │      └── ...<br/>           │    ├── label_map.pbtxt<br/>           │    ├── test_labels.csv<br/>           │    ├── train_labels.csv<br/>           │    ├── test_labels.records<br/>           │    └── train_labels.records<br/>           │<br/>           └── models/           <br/>                ├── research/<br/>                │      ├── training/<br/>                │      │      <!-- -->└── ...<br/>                │      <!-- -->├── pretrained_model/<br/>                <br/>                │      ├── frozen_inference_graph.pb<br/>                │      └── ...<br/>                └── ...</span></pre></div><div class="ab cl nt nu hx nv" role="separator"><span class="nw bw bk nx ny nz"/><span class="nw bw bk nx ny nz"/><span class="nw bw bk nx ny"/></div><div class="im in io ip iq"><h1 id="e41c" class="oa mw it bd mx ob oc od na oe of og nd jz oh ka ng kc oi kd nj kf oj kg nm ok bi translated">8.配置培训渠道。</h1><p id="9c29" class="pw-post-body-paragraph kz la it lb b lc no ju le lf np jx lh li nq lk ll lm nr lo lp lq ns ls lt lu im bi translated">这是开始训练模型前的最后一步，终于！也许，在这一步，您可能会花一些时间来调整模型。</p><p id="30bb" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们下载的 Tensorflow 对象检测 API 模型附带了许多示例配置文件。对于每个型号，都有一个“几乎”可以使用的配置文件。</p><p id="afcc" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">配置文件位于以下位置:</p><pre class="kj kk kl km gt or op os ot aw ou bi"><span id="3c4c" class="mv mw it op b gy ov ow l ox oy">object_detection/models/research/object_detection/samples/configs/</span></pre><p id="c9f2" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">SSD _ mobilenet _ v2 _ coco . config</strong>是我们正在使用的预训练模型的配置文件。<strong class="lb iu">T22 如果你选择了另一个型号，你需要使用&amp;编辑相应的配置文件。</strong></p><p id="8eb2" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">因为我们可能必须不断地调整配置，所以我建议执行以下操作:</p><ul class=""><li id="d2bb" class="me mf it lb b lc ld lf lg li mg lm mh lq mi lu mj mk ml mm bi translated">通过运行以下命令查看示例配置文件的内容:</li></ul><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="pf mu l"/></div></figure><ul class=""><li id="0a3d" class="me mf it lb b lc ld lf lg li mg lm mh lq mi lu mj mk ml mm bi translated">复制配置文件的内容</li><li id="76bd" class="me mf it lb b lc mn lf mo li mp lm mq lq mr lu mj mk ml mm bi translated">使用以下命令编辑它</li></ul><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="pf mu l"/></div></figure><p id="5bd1" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">或者，如果您使用任何文本编辑器同步了所有内容，您可以直接从本地机器打开并编辑配置文件。</p><p id="81cc" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">以下是示例配置文件中需要更改的必要编辑，以及一些用于提高模型性能的建议编辑。</p><p id="99f4" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">➊ <strong class="lb iu">需要对配置文件进行的编辑:</strong></p><ol class=""><li id="976a" class="me mf it lb b lc ld lf lg li mg lm mh lq mi lu ol mk ml mm bi translated"><strong class="lb iu">型号{} </strong> &gt; <strong class="lb iu"> ssd {} </strong>:把<code class="fe om on oo op b">num_classes</code>改成你拥有的班级数。</li></ol><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="pf mu l"/></div></figure><p id="8795" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">2.<strong class="lb iu"> train_config {} </strong>:将<code class="fe om on oo op b">fine_tune_checkpoint</code>改为检查点文件路径。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="pf mu l"/></div></figure><p id="135b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">注</strong>:确切的文件名<code class="fe om on oo op b">model.ckpt</code>不存在。这是模型在训练期间将被保存的地方。这是它的相对路径:</p><pre class="kj kk kl km gt or op os ot aw ou bi"><span id="ae11" class="mv mw it op b gy ov ow l ox oy">/object_detection/models/research/pretrained_model/model.ckpt</span></pre><p id="ced8" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">3.<strong class="lb iu"> train_input_reader {} </strong>:设置<code class="fe om on oo op b">train_labels.record</code>和标签映射<code class="fe om on oo op b">pbtxt</code>文件的路径。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="pf mu l"/></div></figure><p id="a5f5" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">4.<strong class="lb iu"> eval_input_reader {}: </strong>设置<code class="fe om on oo op b">test_labels.record</code>和标签映射<code class="fe om on oo op b">pbtxt</code>文件的路径。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="pf mu l"/></div></figure><p id="bfbc" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">就是这样！您可以跳过可选的编辑，直接参加培训！</p><p id="4537" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">➋ <strong class="lb iu">。建议</strong> <strong class="lb iu">编辑配置文件:</strong></p><p id="b60b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">首先，您可能想开始训练模型，看看它做得有多好。如果你过拟合，那么你可能想做一些更多的图像放大。</p><ul class=""><li id="dd78" class="me mf it lb b lc ld lf lg li mg lm mh lq mi lu mj mk ml mm bi translated">在示例配置文件中:默认添加<code class="fe om on oo op b">random_horizontal_flip</code> &amp; <code class="fe om on oo op b">ssd_random_crop</code>。您也可以尝试添加以下内容:</li></ul><p id="87bb" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">来自<strong class="lb iu">列车配置{}: </strong></p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="pf mu l"/></div></figure><p id="5fa0" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu"> <em class="ms">注意</em> </strong> <em class="ms">:每一次图像放大都会大幅增加训练时间。</em></p><p id="8575" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">您可以添加许多数据扩充选项。从官方代码<a class="ae ky" href="https://github.com/tensorflow/models/blob/master/research/object_detection/protos/preprocessor.proto" rel="noopener ugc nofollow" target="_blank">点击</a>查看完整列表。</p><ul class=""><li id="d6a8" class="me mf it lb b lc ld lf lg li mg lm mh lq mi lu mj mk ml mm bi translated">在<strong class="lb iu">模型{ }&gt;SSD { }&gt;box _ predictor { }:</strong>设置<strong class="lb iu"> </strong> <code class="fe om on oo op b">use_dropout</code>为<code class="fe om on oo op b">true</code>这将有助于对抗过拟合。</li><li id="e529" class="me mf it lb b lc mn lf mo li mp lm mq lq mr lu mj mk ml mm bi translated">在<strong class="lb iu"> eval_config : {} </strong>设置<code class="fe om on oo op b">num_examples</code>中的<strong class="lb iu">测试</strong>图像的数量，并移除<code class="fe om on oo op b">max_eval</code>以无限期评估</li></ul><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="pf mu l"/></div></figure><p id="ce0d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu"> <em class="ms">注</em> </strong> <em class="ms">:提供的笔记本解释了更多关于调整配置文件的内容。</em> <a class="ae ky" href="https://colab.research.google.com/github/AlaaSenjab/-Tutorial-Tensorflow_Object_Detection_API_On_Custom_Dataset/blob/master/weapon_detection_BL.ipynb" rel="noopener ugc nofollow" target="_blank"> <em class="ms">检查一下</em> </a> <em class="ms">！</em></p><p id="7dfe" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">完整的工作目录:<br/> </strong>(包括后面会创建和使用的一些文件/文件夹)</p><pre class="kj kk kl km gt or op os ot aw ou bi"><span id="aa3d" class="mv mw it op b gy ov ow l ox oy">object_detection/<br/>      ├── data/<br/>      │    ├── images/<br/>      │    │      └── ...<br/>      │    ├── <!-- -->annotations/<br/>      │    │      └── ...<br/>      │    ├── train_labels/<br/>      │    │      └── ...<br/>      │    ├── <!-- -->test_labels/<br/>      │    │      └── ...<br/>      │    ├── label_map.pbtxt<br/>      │    ├── test_labels.csv<br/>      │    ├── train_labels.csv<br/>      │    ├── test_labels.records<br/>      │    └── train_labels.records<br/>      │<br/>      └── models/           <br/>           ├─ research/<br/>           │    ├── fine_tuned_model/<br/>           │    │      ├── frozen_inference_graph.pb<br/>           │    │      └── ...<br/>           │    │         <br/>           │    ├── pretrained_model/<br/>           │    │      ├── frozen_inference_graph.pb<br/>           │    │      └── ...<br/>           │    │         <br/>           │    ├── object_detection/<br/>           │    │      ├── utils/<br/>           │    │      ├── samples/<br/>           │    │      │     ├── configs/             <br/>           │    │      │     │     ├── <!-- -->ssd_mobilenet_v2_coco.con<!-- -->fig<br/>           │    │      │     │     ├── <!-- -->rfcn_resnet101_pets.config<br/>           <!-- -->│    │      │     │     └── ... <br/>           │    │      │     └── ...                                <br/>           │    │      ├── export_inference_graph.py<br/>           │    │      ├── model_main.py<br/>           │    │      └── ...<br/>           │    │         <br/>           │    ├── training/<br/>           │    │      ├── events.out.tfevents.xxxxx<br/>           │    │      └── ...               <br/>           │    └── ...<br/>           └── ...</span></pre><h1 id="78cd" class="oa mw it bd mx ob ph od na oe pi og nd jz pj ka ng kc pk kd nj kf pl kg nm ok bi translated">9.张量板。</h1><p id="26fe" class="pw-post-body-paragraph kz la it lb b lc no ju le lf np jx lh li nq lk ll lm nr lo lp lq ns ls lt lu im bi translated">Tensorboard 是我们可以想象训练中发生的一切的地方。您可以监控<code class="fe om on oo op b">loss</code>、<code class="fe om on oo op b">mAP</code>、<code class="fe om on oo op b">AR</code>等等。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oq"><img src="../Images/474d7788849e1f8e34b598b101aeafd5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/1*9DQUOKB2whTii20vGRxQgg.gif"/></div></div></figure><p id="4113" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">你也可以在训练中监控图片和注释。在每一次评估<code class="fe om on oo op b">step</code>中，你可以看到你的模型在探测物体方面有多好。<br/> <strong class="lb iu">注意</strong>:还记得我们上面设置<code class="fe om on oo op b">num_visualizations: 20</code>的时候吗？Tensorboard 将在这里显示大量测试图像的图片。</p><p id="a61e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">要在 Colab 上使用 Tensorboard，我们需要通过<a class="ae ky" href="https://ngrok.com/" rel="noopener ugc nofollow" target="_blank"> ngrok </a>来使用。通过运行以下命令获得:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="pf mu l"/></div></figure><p id="938e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">接下来，我们指定日志文件的存储位置，并配置一个链接来查看 Tensorboard:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="pf mu l"/></div></figure><p id="c598" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">当您运行上面的代码时，在输出的最后会有一个 url，您可以通过它访问 Tensorboard。</p><p id="9ac5" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">注意事项</strong>:</p><ol class=""><li id="155e" class="me mf it lb b lc ld lf lg li mg lm mh lq mi lu ol mk ml mm bi translated">运行上述代码时，您可能不会得到 url，而是得到一个错误。只需再次运行上面的单元格。不需要重新安装 ngrok。</li><li id="d1f8" class="me mf it lb b lc mn lf mo li mp lm mq lq mr lu ol mk ml mm bi translated">在训练开始之前，Tensorboard 不会记录任何文件。</li><li id="377c" class="me mf it lb b lc mn lf mo li mp lm mq lq mr lu ol mk ml mm bi translated">使用 ngrok 时，每分钟最多允许 20 个连接，当模型正在登录时，您将无法访问 tensorboard。(经常发生)</li></ol><p id="8f6c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">如果您将项目同步到本地机器，您将能够不受任何限制地查看 Tensorboard。</p><p id="447e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">转到本地机器上的<strong class="lb iu">终端</strong>并运行:</p><pre class="kj kk kl km gt or op os ot aw ou bi"><span id="f12d" class="mv mw it op b gy ov ow l ox oy">$ pip install tensorboard</span></pre><p id="6139" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">运行它并指定日志目录的位置:</p><pre class="kj kk kl km gt or op os ot aw ou bi"><span id="9482" class="mv mw it op b gy ov ow l ox oy"># in my case, the path to the training folder is:<br/>tensorboard --logdir=/Users/alaasenjab/Google\ Drive/object_detection/models/research/training</span></pre><h1 id="5f34" class="oa mw it bd mx ob ph od na oe pi og nd jz pj ka ng kc pk kd nj kf pl kg nm ok bi translated">10.训练…终于！</h1><p id="e2c5" class="pw-post-body-paragraph kz la it lb b lc no ju le lf np jx lh li nq lk ll lm nr lo lp lq ns ls lt lu im bi translated">训练模型就像运行下面的代码一样简单。我们只需要给它:</p><ul class=""><li id="aed8" class="me mf it lb b lc ld lf lg li mg lm mh lq mi lu mj mk ml mm bi translated">运行培训流程的</li><li id="cca4" class="me mf it lb b lc mn lf mo li mp lm mq lq mr lu mj mk ml mm bi translated"><strong class="lb iu">管道 _ 配置 _ 路径</strong>=路径/至/配置/文件/模型.配置</li><li id="dbd9" class="me mf it lb b lc mn lf mo li mp lm mq lq mr lu mj mk ml mm bi translated"><strong class="lb iu">型号 _ 目录</strong> =路径/至/培训/</li></ul><p id="cad4" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">注意事项</strong>:</p><ol class=""><li id="8b57" class="me mf it lb b lc ld lf lg li mg lm mh lq mi lu ol mk ml mm bi translated">如果内核死亡，训练将从最后一个检查点恢复。除非你没有把<code class="fe om on oo op b">training/</code>目录保存在某个地方，比如:GDrive。</li><li id="a81d" class="me mf it lb b lc mn lf mo li mp lm mq lq mr lu ol mk ml mm bi translated">如果您正在更改以下路径，请确保等号<code class="fe om on oo op b">=</code>和路径之间没有空格。</li></ol><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="pf mu l"/></div></figure><p id="7556" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">现在退后，在 Tensorboard 上观看你的火车模型。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="pm mu l"/></div></figure><h1 id="b948" class="oa mw it bd mx ob ph od na oe pi og nd jz pj ka ng kc pk kd nj kf pl kg nm ok bi translated">11.导出训练好的模型。</h1><p id="7e39" class="pw-post-body-paragraph kz la it lb b lc no ju le lf np jx lh li nq lk ll lm nr lo lp lq ns ls lt lu im bi translated">默认情况下，该模型将每 600 秒保存一个检查点，同时训练多达 5 个检查点。然后，随着新文件的创建，旧文件将被删除。</p><p id="8990" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">通过运行以下代码，我们可以找到最后一个定型的模型:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="pf mu l"/></div></figure><p id="8304" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">然后通过执行<code class="fe om on oo op b">export_inference_graph.py</code>将模型转换成一个冻结的模型<code class="fe om on oo op b">frozen_inference_graph.pb</code>，我们可以用它来进行推理。这个冰冻的模型不能用来恢复训练。然而，<code class="fe om on oo op b">saved_model.pb</code>也被导出，它可以用来恢复训练，因为它拥有所有的权重。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="pf mu l"/></div></figure><ul class=""><li id="267c" class="me mf it lb b lc ld lf lg li mg lm mh lq mi lu mj mk ml mm bi translated"><strong class="lb iu">管道 _ 配置 _ 路径</strong>=路径/至/配置/文件/模型.配置</li><li id="192c" class="me mf it lb b lc mn lf mo li mp lm mq lq mr lu mj mk ml mm bi translated"><strong class="lb iu">输出目录</strong> =保存模型的位置</li><li id="b6c4" class="me mf it lb b lc mn lf mo li mp lm mq lq mr lu mj mk ml mm bi translated"><strong class="lb iu">trained _ check point _ prefix</strong>=路径/到/a/检查点</li></ul><p id="696b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">您可以从该目录访问所有导出的文件:</p><pre class="kj kk kl km gt or op os ot aw ou bi"><span id="95ea" class="mv mw it op b gy ov ow l ox oy">/gdrive/My Drive/object_detection/models/research/pretrained_model/</span></pre><p id="9428" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">或者，你可以直接从 Google Colab 下载推理所需的冻结图:</p><pre class="kj kk kl km gt or op os ot aw ou bi"><span id="2ca2" class="mv mw it op b gy ov ow l ox oy">#downloads the frozen model that is needed for inference<br/># output_directory = 'fine_tuned_model' dir specified above.</span><span id="d957" class="mv mw it op b gy pd ow l ox oy">files.download(output_directory + '/frozen_inference_graph.pb')</span></pre><p id="0865" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们还需要标签图<code class="fe om on oo op b">.pbtxt</code>文件:</p><pre class="kj kk kl km gt or op os ot aw ou bi"><span id="ecb7" class="mv mw it op b gy ov ow l ox oy">#downlaod the label map<br/># we specified '<!-- -->data_base_url' above. It directs to<br/># '<!-- -->object_detection/data/'<!-- --> folder.</span><span id="f38e" class="mv mw it op b gy pd ow l ox oy">files.download(data_base_url + '/label_map.pbtxt')</span></pre><h1 id="695b" class="oa mw it bd mx ob ph od na oe pi og nd jz pj ka ng kc pk kd nj kf pl kg nm ok bi translated">12。网络摄像头推断。</h1><p id="a60e" class="pw-post-body-paragraph kz la it lb b lc no ju le lf np jx lh li nq lk ll lm nr lo lp lq ns ls lt lu im bi translated">要在本地机器上使用您的网络摄像头来推断型号，您需要安装以下软件:</p><pre class="kj kk kl km gt or op os ot aw ou bi"><span id="34b0" class="mv mw it op b gy ov ow l ox oy">Tensorflow = 1.15.0<br/>cv2 = 4.1.2</span></pre><p id="f3d8" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">您还需要在本地机器上下载 Tensorflow 模型(上面的步骤 5 ),或者如果您在本地机器上同步了 GDrive，您可以跳过这一步并导航到模型。</p><ul class=""><li id="6b93" class="me mf it lb b lc ld lf lg li mg lm mh lq mi lu mj mk ml mm bi translated">转到本地机器上的终端并导航到<code class="fe om on oo op b">models/research/object_detection</code></li></ul><p id="e390" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在我的例子中，我导航到 GDrive 中的文件夹。</p><pre class="kj kk kl km gt or op os ot aw ou bi"><span id="2e50" class="mv mw it op b gy ov ow l ox oy">$ cd /Users/alaasenjab/Google\ Drive/object_detection/models/research/object_detection</span></pre><p id="a7eb" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">您可以从 jupyter 笔记本或通过创建一个<code class="fe om on oo op b">.py</code>文件来运行以下内容。但是，更改<code class="fe om on oo op b">PATH_TO_FROZEN_GRAPH</code>、<code class="fe om on oo op b">PATH_TO_LABEL_MAP</code>和<code class="fe om on oo op b">NUM_CLASSES</code></p><p id="66fc" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">运行代码微笑:)</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="pf mu l"/></div></figure></div><div class="ab cl nt nu hx nv" role="separator"><span class="nw bw bk nx ny nz"/><span class="nw bw bk nx ny nz"/><span class="nw bw bk nx ny"/></div><div class="im in io ip iq"><h1 id="33cb" class="oa mw it bd mx ob oc od na oe of og nd jz oh ka ng kc oi kd nj kf oj kg nm ok bi translated">结论:</h1><p id="36f8" class="pw-post-body-paragraph kz la it lb b lc no ju le lf np jx lh li nq lk ll lm nr lo lp lq ns ls lt lu im bi translated">从图像和视频中检测物体比实时检测要简单一些。当我们有一个视频或图像，我们想从其中检测对象时，我们不太关心模型检测对象可能需要的推理时间。在实时对象检测中，我们可能希望牺牲一些精度来获得更快的推理时间。<br/>在检测枪支以通知警方的情况下，我们并不太关心检测枪支的确切位置。相反，我们可能会对这两种情况进行优化:<br/> <strong class="lb iu">假阴性:</strong>当有枪时没有检测到枪。<br/> <strong class="lb iu">真否定:</strong>没有枪的时候检测到枪。</p><p id="a7cd" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我希望你觉得这篇关于如何使用 Tensorflow 检测自定义对象的教程简单而有用。别忘了查看<a class="ae ky" href="https://colab.research.google.com/github/AlaaSenjab/-Tutorial-Tensorflow_Object_Detection_API_On_Custom_Dataset/blob/master/weapon_detection_BL.ipynb" rel="noopener ugc nofollow" target="_blank"> Colab 笔记本</a>了解更多详情。</p><p id="9a95" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">如果你有任何问题，请告诉我，我会尽力帮助你的！</p><h2 id="e1f4" class="mv mw it bd mx my mz dn na nb nc dp nd li ne nf ng lm nh ni nj lq nk nl nm nn bi translated">资源:</h2><p id="1f44" class="pw-post-body-paragraph kz la it lb b lc no ju le lf np jx lh li nq lk ll lm nr lo lp lq ns ls lt lu im bi translated"><em class="ms"> ⋆ Tensorflow 对象检测 API。by:</em><a class="ae ky" href="https://github.com/tensorflow/models/tree/master/research/object_detection" rel="noopener ugc nofollow" target="_blank"><em class="ms">tensor flow</em></a><em class="ms">。</em> <br/> <em class="ms"> ⋆的灵感来自:免费火车物体检测。由:</em> <a class="ae ky" href="https://www.dlology.com/blog/how-to-train-an-object-detection-model-easy-for-free/" rel="noopener ugc nofollow" target="_blank"> <em class="ms">程维</em> </a> <em class="ms">。<br/> ⋆浣熊探测器数据集。by:</em><a class="ae ky" href="https://github.com/datitran/raccoon_dataset" rel="noopener ugc nofollow" target="_blank"><em class="ms">Dat Tran</em></a><em class="ms">。<br/> ⋆使用 Colab 训练 Yolov3。作者:</em> <a class="ae ky" href="http://blog.ibanyez.info/blogs/coding/20190410-run-a-google-colab-notebook-to-train-yolov3-using-darknet-in/" rel="noopener ugc nofollow" target="_blank"> <em class="ms">大卫·伊瓦涅斯</em> </a> <em class="ms">。</em></p></div></div>    
</body>
</html>