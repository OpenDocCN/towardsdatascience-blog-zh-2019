<html>
<head>
<title>State of the Art Audio Data Augmentation with Google Brain’s SpecAugment and Pytorch</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用 Google Brain 的 SpecAugment 和 Pytorch 增强最先进的音频数据</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/state-of-the-art-audio-data-augmentation-with-google-brains-specaugment-and-pytorch-d3d1a3ce291e?source=collection_archive---------15-----------------------#2019-05-01">https://towardsdatascience.com/state-of-the-art-audio-data-augmentation-with-google-brains-specaugment-and-pytorch-d3d1a3ce291e?source=collection_archive---------15-----------------------#2019-05-01</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><figure class="is it gp gr iu iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi ir"><img src="../Images/01a8431622d7bcb6f7aaa94f6af547f3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*jejyDqBj4mj2BylbP0UD7Q.jpeg"/></div></div><figcaption class="jc jd gj gh gi je jf bd b be z dk">Photo by <a class="ae jg" href="https://unsplash.com/photos/wt2tFjoTRcw?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank">Steve Harvey</a> on <a class="ae jg" href="https://unsplash.com/search/photos/audio?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><div class=""/><div class=""><h2 id="6692" class="pw-subtitle-paragraph kg ji jj bd b kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx dk translated">使用 Pytorch 和 TorchAudio 实现 SpecAugment</h2></div><p id="b6b0" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">谷歌大脑最近发布了<a class="ae jg" href="http://ai.googleblog.com/2019/04/specaugment-new-data-augmentation.html" rel="noopener ugc nofollow" target="_blank"> SpecAugment:一种用于自动语音识别的新数据增强方法</a>，它在各种语音识别任务上取得了最先进的结果。</p><p id="9ecb" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">不幸的是，谷歌大脑没有发布代码，似乎他们在 TensorFlow 中编写了他们的版本。对于喜欢 Pytorch 的从业者，我已经发布了使用 Pytorch 的伟大伙伴库<a class="ae jg" href="https://pytorch.org/audio/" rel="noopener ugc nofollow" target="_blank"> torchaudio </a>和一些从与其他 FastAI 学生的持续合作中借来的功能<a class="ae jg" href="https://github.com/zcaceres/fastai-audio" rel="noopener ugc nofollow" target="_blank"> fastai-audio </a>的 SpecAugment 的实现<a class="ae jg" href="https://github.com/zcaceres/spec_augment" rel="noopener ugc nofollow" target="_blank">。</a></p><h2 id="3871" class="lu lv jj bd lw lx ly dn lz ma mb dp mc lh md me mf ll mg mh mi lp mj mk ml mm bi translated">SpecAugment 基础</h2><p id="178c" class="pw-post-body-paragraph ky kz jj la b lb mn kk ld le mo kn lg lh mp lj lk ll mq ln lo lp mr lr ls lt im bi translated">在语音识别中，原始音频通常被转换成基于图像的表示。这些图像是典型的<a class="ae jg" href="https://en.wikipedia.org/wiki/Spectrogram" rel="noopener ugc nofollow" target="_blank">频谱图</a>，它以一种许多模型都觉得更容易学习的格式对声音的属性进行编码。</p><p id="d4e1" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">SpecAugment 没有对原始音频信号进行数据增强，而是借鉴了计算机视觉的思想，对频谱图进行操作。SpecAugment 工程。<a class="ae jg" href="https://arxiv.org/abs/1904.08779" rel="noopener ugc nofollow" target="_blank">谷歌大脑报告了奇妙的结果</a>:</p><div class="ms mt mu mv gt ab cb"><figure class="mw iv mx my mz na nb paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><img src="../Images/c61ec5be3f553556179448522d311958.png" data-original-src="https://miro.medium.com/v2/resize:fit:1012/format:webp/1*SdNVSOdw7qHQ6qqlCfWGKQ.png"/></div></figure><figure class="mw iv nc my mz na nb paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><img src="../Images/819708c6fc8f510bb1238228511ed1e1.png" data-original-src="https://miro.medium.com/v2/resize:fit:990/format:webp/1*-o5rvdhQ6FLIiwnqtXYoUw.png"/></div><figcaption class="jc jd gj gh gi je jf bd b be z dk nd di ne nf">SOTA results using SpecAugment</figcaption></figure></div><p id="cf1b" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">SpecAugment 有三个增强功能。</p><h2 id="8353" class="lu lv jj bd lw lx ly dn lz ma mb dp mc lh md me mf ll mg mh mi lp mj mk ml mm bi translated">时间隧道</h2><figure class="ms mt mu mv gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi ng"><img src="../Images/2e4a8323b67bf26e694e77d807c2a8f7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_MEaHwOXnbT0Db26k8A6aA.png"/></div></div><figcaption class="jc jd gj gh gi je jf bd b be z dk">time warping a spectrogram</figcaption></figure><p id="9248" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">简而言之，时间扭曲通过使用插值技术在随机选择的方向上挤压和拉伸数据来及时移动频谱图。</p><p id="0056" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">时间扭曲是 SpecAugment 最复杂、计算量最大的增强。深度学习工程师<a class="ae jg" href="https://www.linkedin.com/in/caijenny/" rel="noopener ugc nofollow" target="_blank"> Jenny Cai </a>和我一起完成了 Tensorflow 的<code class="fe nh ni nj nk b"><a class="ae jg" href="https://www.tensorflow.org/versions/r1.9/api_docs/python/tf/contrib/image/sparse_image_warp?hl=en" rel="noopener ugc nofollow" target="_blank">sparse_image_warp</a> </code>功能，直到我们有了 Pytorch 的支持。</p><p id="1b55" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">如果你对细节感兴趣，你可以查看<a class="ae jg" href="https://github.com/zcaceres/spec_augment" rel="noopener ugc nofollow" target="_blank">回购</a>中的<code class="fe nh ni nj nk b">SparseImageWarp.ipynb</code>。谷歌大脑的研究表明，时间扭曲是最无效的增强，所以，如果性能是一个问题，你可能会考虑先放弃这个。</p><h2 id="ac61" class="lu lv jj bd lw lx ly dn lz ma mb dp mc lh md me mf ll mg mh mi lp mj mk ml mm bi translated">频率和时间掩蔽</h2><p id="5192" class="pw-post-body-paragraph ky kz jj la b lb mn kk ld le mo kn lg lh mp lj lk ll mq ln lo lp mr lr ls lt im bi translated">频率屏蔽和时间屏蔽类似于计算机视觉中常用的<a class="ae jg" href="https://arxiv.org/abs/1708.04552" rel="noopener ugc nofollow" target="_blank">剪切数据增强技术</a>。</p><p id="fc02" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">简而言之，我们用频谱图的平均值，或者，如果你喜欢，零，来屏蔽随机选择的频带或时间步长。</p><p id="31ed" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">X 轴为时间，Y 轴为频段，时间屏蔽如下所示:</p><figure class="ms mt mu mv gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi nl"><img src="../Images/ad129be6e7ee4309dacd8bd75537d893.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*tnR0w_sLgKkkfE-C9RiDUA.png"/></div></div><figcaption class="jc jd gj gh gi je jf bd b be z dk">time masking a spectrogram</figcaption></figure><p id="3ab6" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">这是频率掩蔽:</p><figure class="ms mt mu mv gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi nm"><img src="../Images/23c2472acfff04b4cbe136331c19ff93.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*k60IY6j0yK6r9qQQ7FwOyQ.png"/></div></div><figcaption class="jc jd gj gh gi je jf bd b be z dk">frequency masking a spectrogram</figcaption></figure><p id="b50d" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">自然，您可以在一个声谱图上应用所有三种增强:</p><figure class="ms mt mu mv gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi nn"><img src="../Images/fd68ffb2ffc02660845128ab5e6b23fc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*FpZUDoo6YzgMm7DSNy6UfQ.png"/></div></div><figcaption class="jc jd gj gh gi je jf bd b be z dk">All three augmentations combined on a single spectrogram</figcaption></figure><p id="f41c" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">希望这些新的 Pytorch 函数将在您的深度学习工作流程中证明有用。感谢阅读！</p></div></div>    
</body>
</html>