<html>
<head>
<title>Latent Dirichlet Allocation</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">潜在狄利克雷分配</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/latent-dirichlet-allocation-15800c852699?source=collection_archive---------14-----------------------#2019-01-14">https://towardsdatascience.com/latent-dirichlet-allocation-15800c852699?source=collection_archive---------14-----------------------#2019-01-14</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><p id="4ce4" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">潜在狄利克雷分配</strong> (LDA)是由零件组成的复合物集合的“生成概率模型”。就主题建模而言，组合是文档，部分是单词和/或短语(n 元语法)。但是你可以将 LDA 应用于 DNA 和核苷酸，比萨饼和配料，分子和原子，雇员和技能，或者键盘和面包屑。</p><figure class="km kn ko kp gt kq gh gi paragraph-image"><div class="gh gi kl"><img src="../Images/122acfcf99e66b7616ed7bfc2185fdf5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1276/format:webp/0*Sj65xR38wDwuxhtr.jpg"/></div><figcaption class="kt ku gj gh gi kv kw bd b be z dk"><a class="ae kx" href="http://nlpx.net/wp/wp-content/uploads/2016/01/LDA_image2.jpg" rel="noopener ugc nofollow" target="_blank">Source</a></figcaption></figure><p id="d048" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">潜在狄利克雷分配(LDA)是一种自动发现这些文档包含的主题的技术。</p><figure class="km kn ko kp gt kq gh gi paragraph-image"><div role="button" tabindex="0" class="ky kz di la bf lb"><div class="gh gi gj"><img src="../Images/e44c85cfc1eba38e3aa02ab3bfca8cb2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*sQ43HX2UufHhE5Tt"/></div></div></figure><p id="a7be" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">假设你有下面这组句子:</p><figure class="km kn ko kp gt kq gh gi paragraph-image"><div class="gh gi lc"><img src="../Images/d9493a45fbebc2947e57d9fd0bc5145b.png" data-original-src="https://miro.medium.com/v2/resize:fit:584/format:webp/1*k9VIpwVdMby3406OomATiw.png"/></div></figure><p id="eb5a" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">根据上面的句子，LDA 可能会将红色单词归类到主题 F 下，我们可以将其标记为“食物”。类似地，蓝色单词可能被归类到一个单独的主题 P 下，我们可以将其标记为“宠物”。LDA 将每个主题定义为一个单词包，你必须按照你认为合适的方式给主题贴上标签。</p><p id="8d96" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">LDA 在单词级别定义主题有两个好处:</p><p id="99da" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">1)我们可以通过字数来推断每个句子的内容传播:</p><p id="67f7" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">第一句</strong> : 100%话题 F<br/>T5】第二句 : 100%话题 P<br/>T8】第三句 : 33%话题 P 和 67%话题 F</p><p id="3d20" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">2)我们可以推导出每个单词在给定主题中所占的比例。例如，主题 F 可能包含以下比例的单词:40%吃，40%鱼，20%蔬菜，…</p><p id="c818" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">LDA 分三步实现上述结果。</p><p id="bdc9" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">为了说明这些步骤，假设您现在正在文档中发现主题，而不是句子。假设您有两个包含以下单词的文档:</p><figure class="km kn ko kp gt kq gh gi paragraph-image"><div class="gh gi ld"><img src="../Images/9863f9689368fbd929bc01d80c0a6c9d.png" data-original-src="https://miro.medium.com/v2/resize:fit:600/0*wfj5NoObW0dZgeUP"/></div></figure><p id="ae0e" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">第一步<br/> <strong class="jp ir">你告诉算法你认为有多少个题目。</strong>您可以使用可靠的估计(例如之前分析的结果)，也可以简单地试错。在尝试不同的估计时，你可以选择一个产生你想要的可解释性水平的话题，或者一个产生最高统计确定性(即对数可能性)的话题。在上面的例子中，主题的数量可以通过目测文档来推断。</p><p id="bdcb" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">步骤 2 <br/> <strong class="jp ir">算法会将每个单词分配给一个临时主题</strong>。主题分配是临时的，因为它们将在步骤 3 中更新。临时主题以半随机的方式(确切地说，根据狄利克雷分布)被分配给每个单词。这也意味着，如果一个词出现两次，每个词可能被分配到不同的主题。注意，在分析实际文档时，功能词(例如“the”、“and”、“my”)被移除，并且不被分配给任何主题。</p><p id="35ef" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">步骤 3(迭代)<br/> <strong class="jp ir">该算法将检查并更新主题分配</strong>，遍历每个文档中的每个单词。对于每个单词，其主题分配基于两个标准进行更新:</p><ul class=""><li id="cb7b" class="le lf iq jp b jq jr ju jv jy lg kc lh kg li kk lj lk ll lm bi translated">这个词在各种话题中有多普遍？</li><li id="0b29" class="le lf iq jp b jq ln ju lo jy lp kc lq kg lr kk lj lk ll lm bi translated">文档中的主题有多普遍？</li></ul><p id="a309" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">为了理解这两个标准是如何工作的，假设我们现在正在检查文档 Y 中单词“fish”的主题分配:</p><figure class="km kn ko kp gt kq gh gi paragraph-image"><div class="gh gi ld"><img src="../Images/719367a8121ff05500ab4c5bc546b953.png" data-original-src="https://miro.medium.com/v2/resize:fit:600/0*dU2xriqeLlPecAVC"/></div></figure><ul class=""><li id="e83b" class="le lf iq jp b jq jr ju jv jy lg kc lh kg li kk lj lk ll lm bi translated">这个词在各种话题中有多普遍？由于两个文档中的“鱼”字包括几乎一半的剩余主题 F 字，但是 0%的剩余主题 P 字，所以随机挑选的“鱼”字更可能是关于主题 F 的</li></ul><figure class="km kn ko kp gt kq gh gi paragraph-image"><div class="gh gi ld"><img src="../Images/9cb88b721a84113a1ec8480f52efaa6b.png" data-original-src="https://miro.medium.com/v2/resize:fit:600/0*bN-Iznrrutoyv0vp"/></div></figure><ul class=""><li id="b8b7" class="le lf iq jp b jq jr ju jv jy lg kc lh kg li kk lj lk ll lm bi translated">文档中的主题有多普遍？因为文档 Y 中的单词以 50:50 的比例分配给主题 F 和主题 P，所以剩余的“鱼”单词似乎同样可能与任一主题有关。</li></ul><figure class="km kn ko kp gt kq gh gi paragraph-image"><div class="gh gi ld"><img src="../Images/b9f56083c78a5cd25229ecb522b2bb51.png" data-original-src="https://miro.medium.com/v2/resize:fit:600/0*DzVUsl_9JpvfbPPq"/></div></figure><p id="f9a8" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">权衡两个标准得出的结论，我们将把 Doc Y 的“鱼”字分配给 Topic f。Doc Y 可能是一个关于喂小猫什么的文档。</p><p id="8a2d" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">对每个文档中的每个单词重复检查主题分配的过程，在整个文档集合中循环多次。这种迭代更新是 LDA 的关键特征，它生成具有连贯主题的最终解决方案。</p></div></div>    
</body>
</html>