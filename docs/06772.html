<html>
<head>
<title>Kernel Regression — with example and code</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">内核回归—示例和代码</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/kernel-regression-made-easy-to-understand-86caf2d2b844?source=collection_archive---------2-----------------------#2019-09-27">https://towardsdatascience.com/kernel-regression-made-easy-to-understand-86caf2d2b844?source=collection_archive---------2-----------------------#2019-09-27</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><figure class="is it gp gr iu iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi ir"><img src="../Images/4d2471cf3b83ee8bebfeca883fd8acee.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*taSid1ez-2Jt_o162fyHCQ.jpeg"/></div></div><figcaption class="jc jd gj gh gi je jf bd b be z dk">Photo by <a class="ae jg" href="https://unsplash.com/@markusspiske?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank">Markus Spiske</a> on <a class="ae jg" href="https://unsplash.com/s/photos/stacking?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><div class=""/><p id="9767" class="pw-post-body-paragraph kg kh jj ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">本文讨论了如何利用核函数作为权函数来建立非参数回归模型。在文章的开始，简要讨论了核函数的性质和围绕数据点构建核的步骤。</p><h2 id="f902" class="le lf jj bd lg lh li dn lj lk ll dp lm kr ln lo lp kv lq lr ls kz lt lu lv lw bi translated">核函数</h2><p id="bbfa" class="pw-post-body-paragraph kg kh jj ki b kj lx kl km kn ly kp kq kr lz kt ku kv ma kx ky kz mb lb lc ld im bi translated">在非参数统计中，核是满足以下性质的加权函数。</p><ol class=""><li id="5f7e" class="mc md jj ki b kj kk kn ko kr me kv mf kz mg ld mh mi mj mk bi translated">一个核函数必须<strong class="ki jk">对称</strong>。从数学上讲，这种性质可以表示为 K (-u) = K (+u)。核函数的对称性质使其最大值(<em class="ml"> max(K(u) </em>)位于曲线的中间。</li></ol><figure class="mn mo mp mq gt iv gh gi paragraph-image"><div class="gh gi mm"><img src="../Images/2331e9fdb9668db277cbfc0fefb23685.png" data-original-src="https://miro.medium.com/v2/resize:fit:656/format:webp/0*o3YUAXs5JEcLoZ61.png"/></div><figcaption class="jc jd gj gh gi je jf bd b be z dk">An illustration of Gaussian kernel function</figcaption></figure><p id="fe8f" class="pw-post-body-paragraph kg kh jj ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">2.函数曲线下的面积必须是<strong class="ki jk">等于 1</strong>。从数学上来说，该属性表示为:</p><figure class="mn mo mp mq gt iv gh gi paragraph-image"><div class="gh gi mr"><img src="../Images/28618275bb3b08d54200d70ff1c342c9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1130/format:webp/0*oZ0CPRC0upk0T5RX.png"/></div></figure><p id="8f0a" class="pw-post-body-paragraph kg kh jj ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">3.核函数<strong class="ki jk">的值不能为负，即</strong>K(u)≥0 for all-&lt;u&lt;∞。</p><h1 id="59a5" class="ms lf jj bd lg mt mu mv lj mw mx my lm mz na nb lp nc nd ne ls nf ng nh lv ni bi translated">核估计</h1><p id="de55" class="pw-post-body-paragraph kg kh jj ki b kj lx kl km kn ly kp kq kr lz kt ku kv ma kx ky kz mb lb lc ld im bi translated">在本文中，高斯核函数用于计算数据点的核。高斯核的等式是:</p><figure class="mn mo mp mq gt iv gh gi paragraph-image"><div class="gh gi mr"><img src="../Images/7610b3dda43b9dbb852813c731e31fe0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1130/format:webp/0*4N1Vqb9usMZRKJU_.png"/></div></figure><p id="ec1d" class="pw-post-body-paragraph kg kh jj ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">其中<strong class="ki jk"> <em class="ml"> xi </em> </strong>为观察数据点。<strong class="ki jk"> <em class="ml"> x </em> </strong>是计算核函数的值，<strong class="ki jk"> <em class="ml"> h </em> </strong>称为带宽。核回归中的带宽被称为平滑参数，因为它控制输出中的方差和偏差。本文稍后将讨论带宽值对模型预测的影响。</p><h2 id="3174" class="le lf jj bd lg lh li dn lj lk ll dp lm kr ln lo lp kv lq lr ls kz lt lu lv lw bi translated">例子</h2><p id="1090" class="pw-post-body-paragraph kg kh jj ki b kj lx kl km kn ly kp kq kr lz kt ku kv ma kx ky kz mb lb lc ld im bi translated">假设有六个数据点，每个数据点显示单个学生在某一科目中获得的分数。使用高斯核函数在每个数据点构建核的步骤如下所述。</p><p id="3014" class="pw-post-body-paragraph kg kh jj ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="ki jk"><em class="ml">【Xi】</em></strong>= { 65，75，67，79，81，91}其中<strong class="ki jk"> <em class="ml"> x1 </em> </strong> = 65，<strong class="ki jk"><em class="ml">x2</em></strong>= 75…<em class="ml"/><strong class="ki jk"><em class="ml">X6</em></strong>= 91。</p><p id="6363" class="pw-post-body-paragraph kg kh jj ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">需要三个输入来构建围绕数据点的核心曲线。</p><blockquote class="nj nk nl"><p id="00eb" class="kg kh ml ki b kj kk kl km kn ko kp kq nm ks kt ku nn kw kx ky no la lb lc ld im bi translated">一.观察数据点，<strong class="ki jk"><em class="jj"/></strong></p><p id="2a81" class="kg kh ml ki b kj kk kl km kn ko kp kq nm ks kt ku nn kw kx ky no la lb lc ld im bi translated">二。<strong class="ki jk">的值<em class="jj"> h </em>的值</strong></p><p id="0576" class="kg kh ml ki b kj kk kl km kn ko kp kq nm ks kt ku nn kw kx ky no la lb lc ld im bi translated">三。线性间隔的数据点系列，包括需要估计<em class="jj"> K </em>值的观察数据点。如:<strong class="ki jk"> <em class="jj"> Xj </em> </strong> = {50，51，52 …99}</p></blockquote><p id="c77b" class="pw-post-body-paragraph kg kh jj ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">对于给定的<strong class="ki jk"><em class="ml"/></strong><strong class="ki jk"><em class="ml"/></strong>h 值，计算<strong class="ki jk"/>K 值<em class="ml">【Xj】</em>值的步骤如下表所示，其中<strong class="ki jk"><em class="ml">【Xi】</em></strong>= 65、<em class="ml"/><strong class="ki jk"><em class="ml">h</em></strong>= 5.5。表格中的最后一列显示了内核的纵坐标为<strong class="ki jk"><em class="ml"/></strong>= 65。</p><figure class="mn mo mp mq gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi np"><img src="../Images/d85cd370ce05c59abc182e9cdb6c3803.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*bIue9eqFeBJJB3a-.png"/></div></div></figure><p id="e905" class="pw-post-body-paragraph kg kh jj ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">下面绘制<strong class="ki jk"> <em class="ml"> Xj </em> </strong>和<strong class="ki jk"> <em class="ml"> K </em> </strong>来可视化内核。注意图中的<em class="ml"> x 轴</em>是<strong class="ki jk"> <em class="ml"> Xj </em> </strong>，在其上构建内核曲线，在高斯分布的情况下，以<strong class="ki jk"><em class="ml">【Xi】</em></strong>为均值，<strong class="ki jk"><em class="ml">【h】</em></strong>为标准差。</p><figure class="mn mo mp mq gt iv gh gi paragraph-image"><div class="gh gi nq"><img src="../Images/ce33a7aebade3b0c2025da0558c9f770.png" data-original-src="https://miro.medium.com/v2/resize:fit:1110/format:webp/0*GHrYzp_W0zDhtcXa.png"/></div></figure><p id="b21b" class="pw-post-body-paragraph kg kh jj ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">类似地，在所有六个观察到的数据点，内核值被估计并绘制如下。据观察，<strong class="ki jk"><em class="ml">【Xj】</em></strong>与<strong class="ki jk"><em class="ml">【Xi】</em></strong>相差甚远的<strong class="ki jk"> <em class="ml"> K </em> </strong>的值接近 0。例如，<strong class="ki jk"><em class="ml">Xj</em></strong><em class="ml"/>= 99 的内核值对于<strong class="ki jk"><em class="ml"/></strong>= 65 是零。</p><figure class="mn mo mp mq gt iv gh gi paragraph-image"><div class="gh gi nr"><img src="../Images/44c6b841443b5ae316a1857da3a44dcd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1136/format:webp/0*dOmKIIp8Z75ip0yF.png"/></div><figcaption class="jc jd gj gh gi je jf bd b be z dk">Kernels plotted for all <strong class="bd ns">xi</strong></figcaption></figure><h1 id="6e63" class="ms lf jj bd lg mt mu mv lj mw mx my lm mz na nb lp nc nd ne ls nf ng nh lv ni bi translated">核回归</h1><p id="31e7" class="pw-post-body-paragraph kg kh jj ki b kj lx kl km kn ly kp kq kr lz kt ku kv ma kx ky kz mb lb lc ld im bi translated">在本节中，内核值用于从给定的输入导出权重以预测输出。计算权重并最终将其用于预测输出变量所涉及的步骤，预测变量中的<strong class="ki jk"> <em class="ml"> y </em> </strong>，<strong class="ki jk"> <em class="ml"> x </em> </strong>将在以下章节中详细说明。让我们从一个例子开始，清楚地理解内核回归是如何工作的。</p><h2 id="f5c8" class="le lf jj bd lg lh li dn lj lk ll dp lm kr ln lo lp kv lq lr ls kz lt lu lv lw bi translated"><strong class="ak">例子</strong></h2><p id="5d30" class="pw-post-body-paragraph kg kh jj ki b kj lx kl km kn ly kp kq kr lz kt ku kv ma kx ky kz mb lb lc ld im bi translated">在本例中，开发了一个核心回归模型来预测集水区的河流流量。如下图所示，集水面积(平方英里)和河流流量(立方英尺/秒)之间存在非线性关系。在本例中，<strong class="ki jk"> <em class="ml"> y </em> </strong>为河流流量，x  为流域面积。</p><figure class="mn mo mp mq gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi nt"><img src="../Images/38be3fc31c499145fa8c0a1d657084d4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ZbTBdDTma2OnMAFIyJ0BBw.png"/></div></div><figcaption class="jc jd gj gh gi je jf bd b be z dk">Example data set to build kernel regression</figcaption></figure><h2 id="96a5" class="le lf jj bd lg lh li dn lj lk ll dp lm kr ln lo lp kv lq lr ls kz lt lu lv lw bi translated">作为加权函数的核</h2><p id="8729" class="pw-post-body-paragraph kg kh jj ki b kj lx kl km kn ly kp kq kr lz kt ku kv ma kx ky kz mb lb lc ld im bi translated">最初，如前几节所述，使用所有输入的带宽值来估计核。然后用它们来计算重量。在本例中，带宽值 10 用于解释内核回归。然而，带宽值需要优化以适当地适应数据。在不同的<strong class="ki jk"> <em class="ml"> x </em> </strong>值下绘制的内核如下图所示。</p><blockquote class="nu"><p id="d1af" class="nv nw jj bd nx ny nz oa ob oc od ld dk translated">重要的是要理解，内核是在所有的<em class="oe"> xi </em>值下开发的。内核回归背后的基本计算是针对给定的<em class="oe">预测值 xi，估计所有观察到的<em class="oe"> y </em>值的加权和。</em>权重只不过是内核值，范围在 0 和 1 之间，在给定的 xi 与垂直于 x 轴的线相交(如下图所示)。</p></blockquote><figure class="og oh oi oj ok iv gh gi paragraph-image"><div class="gh gi of"><img src="../Images/652b0820605cad47922a582329fe054c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1198/format:webp/1*TNrri3WZ6qhOHyYyUHMvfw.png"/></div><figcaption class="jc jd gj gh gi je jf bd b be z dk">Scattered plot showing input-output data (above) and kernels at all inputs using a bandwidth of 10 (below)</figcaption></figure><figure class="mn mo mp mq gt iv gh gi paragraph-image"><div class="gh gi ol"><img src="../Images/081338b7d368086bff27aeb4c317f307.png" data-original-src="https://miro.medium.com/v2/resize:fit:860/format:webp/1*IZiXwqqFL8-4rLa6IKpK3g.png"/></div><figcaption class="jc jd gj gh gi je jf bd b be z dk">Intersection of predictor variable, area = 50 with surrounding kernels</figcaption></figure><p id="7be9" class="pw-post-body-paragraph kg kh jj ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">上面的星形标记显示了交叉点及其相应的内核值。内核值在 0 和 1 之间缩放，以将其用作权重。以下等式用于在 0 和 1 之间缩放内核值。</p><figure class="mn mo mp mq gt iv gh gi paragraph-image"><div class="gh gi om"><img src="../Images/e3d8be4d14665e41895f49d8036eb993.png" data-original-src="https://miro.medium.com/v2/resize:fit:454/format:webp/1*eFcC_SGOptY0sHd0FqAIvA.png"/></div></figure><p id="2964" class="pw-post-body-paragraph kg kh jj ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">其中<strong class="ki jk"> <em class="ml"> wi </em> </strong>为输入的权重<strong class="ki jk"><em class="ml">I</em></strong><strong class="ki jk"><em class="ml">n</em></strong>为数据点总数。<strong class="ki jk"> <em class="ml"> x </em> </strong> = 50 的输出<strong class="ki jk"> <em class="ml"> y </em> </strong>计算为所有观察到的<strong class="ki jk"> <em class="ml"> y </em> </strong>值的加权和，如下式所示。</p><figure class="mn mo mp mq gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi on"><img src="../Images/31b1d6a2c1385c7b6b26525e8c089408.png" data-original-src="https://miro.medium.com/v2/resize:fit:1230/format:webp/1*HYbe_RcXwQxAleuHKHMYnA.png"/></div></div></figure><p id="1814" class="pw-post-body-paragraph kg kh jj ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">其中<strong class="ki jk"> <em class="ml"> y11 </em> </strong>是<em class="ml">面积= 11 </em>的河流流量，<strong class="ki jk"> <em class="ml"> w11 </em> </strong>是相应的重量，等式中的其他项也是如此。</p><p id="fcc8" class="pw-post-body-paragraph kg kh jj ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">下表显示了从输入<strong class="ki jk"> <em class="ml"> x </em> </strong> = 50 的内核值<strong class="ki jk"> <em class="ml"> </em> </strong>计算权重所涉及的步骤。表中的最后一列提供了最终输出，即 50 平方英里区域的计算河流流量。</p><figure class="mn mo mp mq gt iv gh gi paragraph-image"><div class="gh gi oo"><img src="../Images/c8221c41958c04f2938e2b48e03fb6f9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1348/format:webp/1*TVw9Idj4orrXD1cHckXMAw.png"/></div></figure><p id="456e" class="pw-post-body-paragraph kg kh jj ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">同样，对于<strong class="ki jk"> <em class="ml"> x、</em> </strong>的所有值，权重如上表所述进行估算，并用于计算相应的<strong class="ki jk"> <em class="ml"> y </em> </strong>值。下表和下图显示了不同区域输入的预测河流流量值。</p><figure class="mn mo mp mq gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi op"><img src="../Images/8b3655e5527b867843440c3916fe8a77.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*IRq35hcXcXASsnx2qeSoQg.png"/></div></div><figcaption class="jc jd gj gh gi je jf bd b be z dk">Computed river flow from kernel regression</figcaption></figure><h2 id="2b62" class="le lf jj bd lg lh li dn lj lk ll dp lm kr ln lo lp kv lq lr ls kz lt lu lv lw bi translated">带宽灵敏度</h2><p id="232b" class="pw-post-body-paragraph kg kh jj ki b kj lx kl km kn ly kp kq kr lz kt ku kv ma kx ky kz mb lb lc ld im bi translated">以上计算基于带宽值 10。内核带宽对预测的影响很大，如下图所示。</p><figure class="mn mo mp mq gt iv gh gi paragraph-image"><div class="gh gi oq"><img src="../Images/1202e43f0560240a59f2620e3f4564ae.png" data-original-src="https://miro.medium.com/v2/resize:fit:1224/format:webp/1*rodHVOMVVNDh6S4cbbnRVw.png"/></div><figcaption class="jc jd gj gh gi je jf bd b be z dk">Kernel regression output for bandwidth value = 5</figcaption></figure><figure class="mn mo mp mq gt iv gh gi paragraph-image"><div class="gh gi oq"><img src="../Images/7483dc678fac033345ad424ab46f4e73.png" data-original-src="https://miro.medium.com/v2/resize:fit:1224/format:webp/1*tgm2enIAO_gX4xAnBBTnhQ.png"/></div><figcaption class="jc jd gj gh gi je jf bd b be z dk">Kernel regression output for bandwidth value = 10</figcaption></figure><figure class="mn mo mp mq gt iv gh gi paragraph-image"><div class="gh gi or"><img src="../Images/65a0b025cc7b454d4893286c5eac5e18.png" data-original-src="https://miro.medium.com/v2/resize:fit:1218/format:webp/1*FPN8HI3pM_unWPrk6AbvJQ.png"/></div><figcaption class="jc jd gj gh gi je jf bd b be z dk">Kernel regression output for bandwidth value = 15</figcaption></figure><p id="9f94" class="pw-post-body-paragraph kg kh jj ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在为<strong class="ki jk"><em class="ml"/></strong>预测时，由于较窄的内核对训练数据集中的“<strong class="ki jk"><em class="ml">【Xi】</em></strong>”的<em class="ml">【易】</em> 赋予较高的权重，因此较小的带宽值过拟合数据。低带宽会在输出中产生大量看起来不真实的变化，而高带宽值会使输出过于平滑，无法揭示输入和输出之间的真实关系。因此，为了达到偏差-方差的平衡，应该在核回归中优化带宽。</p><h2 id="d10b" class="le lf jj bd lg lh li dn lj lk ll dp lm kr ln lo lp kv lq lr ls kz lt lu lv lw bi translated">核回归的 r 代码</h2><pre class="mn mo mp mq gt os ot ou ov aw ow bi"><span id="64ca" class="le lf jj ot b gy ox oy l oz pa">#Kernel regression<br/>data &lt;- data.frame(Area = c(11,22,33,44,50,56,67,70,78,89,90,100),        RiverFlow = c(2337,2750,2301,2500,1700,2100,1100,1750,1000,1642, 2000,1932))                                 <br/><br/>x &lt;- data$Area<br/>y &lt;- data$RiverFlow</span><span id="2f72" class="le lf jj ot b gy pb oy l oz pa">#function to calculate Gaussian kernel<br/>gausinKernel &lt;- function(x,b){<br/>  K &lt;- (1/((sqrt(2*pi))))*exp(-0.5 *(x/b)^2)<br/>  return(K)<br/>}</span><span id="b6f1" class="le lf jj ot b gy pb oy l oz pa">b &lt;- 10 #bandwidth<br/>kdeEstimateyX &lt;- seq(5,110,1)<br/>ykernel &lt;- NULL<br/>for(xesti in kdeEstimateyX){<br/>  xx &lt;-  xesti - x<br/>  K &lt;-gausinKernel(xx,b)<br/>  Ksum &lt;- sum(K)<br/>  weight &lt;- K/Ksum<br/>  yk &lt;- sum(weight*y)<br/>  xkyk &lt;- c(xesti,yk)<br/>  ykernel &lt;- rbind(ykernel,xkyk)<br/>}<br/>plot(x,y,xlab = "Area", ylab = "Flow", col = 'blue', cex = 2)<br/>lines(ykernel[,1],ykernel[,2], col = 'red', lwd = 2)</span></pre><h1 id="59d8" class="ms lf jj bd lg mt mu mv lj mw mx my lm mz na nb lp nc nd ne ls nf ng nh lv ni bi translated">参考</h1><p id="e017" class="pw-post-body-paragraph kg kh jj ki b kj lx kl km kn ly kp kq kr lz kt ku kv ma kx ky kz mb lb lc ld im bi translated">R.蒂布拉尼和 l .乏色曼，非参数回归，统计机器学习(2015)——卡耐基梅隆大学讲稿</p></div></div>    
</body>
</html>