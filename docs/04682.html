<html>
<head>
<title>Thoughts on the Two Cultures of Statistical Modeling</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">关于统计建模两种文化的思考</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/thoughts-on-the-two-cultures-of-statistical-modeling-72d75a9e06c2?source=collection_archive---------7-----------------------#2019-07-17">https://towardsdatascience.com/thoughts-on-the-two-cultures-of-statistical-modeling-72d75a9e06c2?source=collection_archive---------7-----------------------#2019-07-17</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><figure class="ip iq gp gr ir is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi io"><img src="../Images/bf6c5667044bdb144ebb87724c9211f3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*eQ6K5MUVFiDg_bSN6xn1Ng.jpeg"/></div></div><figcaption class="iz ja gj gh gi jb jc bd b be z dk"><a class="ae jd" href="https://www.pexels.com/photo/background-beautiful-blossom-calm-waters-268533/" rel="noopener ugc nofollow" target="_blank">(Source)</a></figcaption></figure><div class=""/><div class=""><h2 id="d16a" class="pw-subtitle-paragraph kd jf jg bd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku dk translated">准确性胜过可解释性和其他来自 Leo Breiman 的《统计建模:两种文化》的内容</h2></div><p id="8651" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">在论文中:<a class="ae jd" href="http://www2.math.uu.se/~thulin/mm/breiman.pdf" rel="noopener ugc nofollow" target="_blank">“统计建模:两种文化”</a>，<a class="ae jd" href="https://scholar.google.com/citations?user=mXSv_1UAAAAJ&amp;hl=en" rel="noopener ugc nofollow" target="_blank">利奥·布雷曼</a>—<a class="ae jd" href="https://www.stat.berkeley.edu/~breiman/randomforest2001.pdf" rel="noopener ugc nofollow" target="_blank">随机森林</a>以及<a class="ae jd" href="https://www.stat.berkeley.edu/~breiman/bagging.pdf" rel="noopener ugc nofollow" target="_blank">装袋</a>和<a class="ae jd" href="https://pdfs.semanticscholar.org/814c/f172298d11db0ac9b839440ed8f3db93e438.pdf" rel="noopener ugc nofollow" target="_blank">助推</a>集合的开发者——描述了两种截然不同的统计建模方法:</p><ol class=""><li id="0a97" class="lr ls jg kx b ky kz lb lc le lt li lu lm lv lq lw lx ly lz bi translated"><strong class="kx jh">数据建模:</strong>根据对数据生成机制的直觉，选择一个简单的(线性)模型。重点是模型的可解释性和验证，如果要做的话，是通过拟合优度来完成的。</li><li id="7426" class="lr ls jg kx b ky ma lb mb le mc li md lm me lq lw lx ly lz bi translated"><strong class="kx jh">算法建模:</strong>选择预测验证准确率最高的模型，不考虑模型的可解释性。</li></ol><p id="712d" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">在 2001 年撰写本文时，Breiman 估计 98%的统计学家属于数据建模团队，而 2%(包括他自己)属于算法建模文化。这篇论文旨在呼吁统计学家停止仅仅依赖数据建模——这会导致“误导性结论”和“无关理论”——并采用算法建模来解决大规模数据集产生的新的现实世界问题。Breiman 是一名学者，在 Berkely 做了 21 年的统计学家，但他之前做过 13 年的自由顾问，这让他对统计如何在工业中有用有了很好的看法。</p><p id="cf28" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">布雷曼感到沮丧，因为他知道数据模型无法解决大规模数据收集带来的新挑战，他觉得学术统计学由于拒绝采用新工具而变得无关紧要:预测性能高但可解释性低的复杂算法。虽然自这篇论文发表以来的 18 年里，机器学习和统计学已经发生了变化(我不知道 98/2 的分裂是否仍然成立)，但提出的几个有趣的观点仍然与今天实践机器学习有关，特别是对于那些从学术界向工业界过渡的人。这些要点包括:</p><ol class=""><li id="6cab" class="lr ls jg kx b ky kz lb lc le lt li lu lm lv lq lw lx ly lz bi translated"><strong class="kx jh">具有不同特征的模型通常产生相似的预测准确度。</strong></li><li id="1114" class="lr ls jg kx b ky ma lb mb le mc li md lm me lq lw lx ly lz bi translated"><strong class="kx jh">在机器学习中，模型可解释性和性能之间存在权衡。</strong></li><li id="4742" class="lr ls jg kx b ky ma lb mb le mc li md lm me lq lw lx ly lz bi translated">更多的特性可以提高复杂算法模型的性能。</li><li id="1185" class="lr ls jg kx b ky ma lb mb le mc li md lm me lq lw lx ly lz bi translated"><strong class="kx jh">随着我们收集更多关于世界的信息，科学从简单模型发展到复杂模型。</strong></li></ol><p id="e413" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">这篇论文的总体经验与我在工业中应用机器学习所学到的一致(在<a class="ae jd" href="https://cortexintel.com" rel="noopener ugc nofollow" target="_blank">Cortex Building Intelligence</a>):<strong class="kx jh">首先关注模型的准确性，只有在建立了高性能模型之后，才考虑解释它。</strong>一个无法完全解释的高度复杂、精确的模型比一个我们完全理解的没有预测精度的简单线性模型更有价值。</p><p id="9b52" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">以下是我对 Breiman 论文的一些想法。请记住，这些都是基于比 Breiman 撰写的经验少得多的经验——在学术环境中的 1 年(2018 年)和在行业中的 1 年多一点(2018 年至今)。我建议<a class="ae jd" href="http://www2.math.uu.se/~thulin/mm/breiman.pdf" rel="noopener ugc nofollow" target="_blank">阅读文章</a>(以及其中包含的批评)来形成自己的观点。请随意将关于论文或机器学习相关主题的评论或经验添加到本文中。尽管机器学习似乎发展得令人难以置信地快，<em class="mf">仍然可以从旧的论文和书籍中学习到有价值的信息</em>，尤其是那些由 Breiman 这样的人物撰写的，他在塑造该领域方面发挥了关键作用。</p></div><div class="ab cl mg mh hu mi" role="separator"><span class="mj bw bk mk ml mm"/><span class="mj bw bk mk ml mm"/><span class="mj bw bk mk ml"/></div><div class="ij ik il im in"><h1 id="3af8" class="mn mo jg bd mp mq mr ms mt mu mv mw mx km my kn mz kp na kq nb ks nc kt nd ne bi translated">统计建模的两种方法</h1><p id="7ba1" class="pw-post-body-paragraph kv kw jg kx b ky nf kh la lb ng kk ld le nh lg lh li ni lk ll lm nj lo lp lq ij bi translated">在我们讨论什么是好的模型之前，我们必须理解<a class="ae jd" href="https://www.ibm.com/support/knowledgecenter/en/SS3RA7_17.0.0/clementine/nodes_statisticalmodels.html" rel="noopener ugc nofollow" target="_blank">建模</a>的两个目标:</p><ol class=""><li id="120c" class="lr ls jg kx b ky kz lb lc le lt li lu lm lv lq lw lx ly lz bi translated"><strong class="kx jh">预测:</strong>根据一组新的独立变量(特征)估计结果(目标)</li><li id="329d" class="lr ls jg kx b ky ma lb mb le mc li md lm me lq lw lx ly lz bi translated"><strong class="kx jh">信息:</strong>了解一些关于自然(数据生成)过程的知识</li></ol><p id="a470" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">这两个目标的精确平衡取决于具体情况:如果你试图预测股票，你可能只关心模型是否准确。在医疗环境中，了解疾病的原因可能是建立模型的主要焦点。Breiman 认为，对于这两个目标，算法方法实际上比数据建模方法占了上风。</p><h2 id="d67a" class="nk mo jg bd mp nl nm dn mt nn no dp mx le np nq mz li nr ns nb lm nt nu nd nv bi translated">数据建模</h2><p id="982d" class="pw-post-body-paragraph kv kw jg kx b ky nf kh la lb ng kk ld le nh lg lh li ni lk ll lm nj lo lp lq ij bi translated">使用数据建模方法(Breiman 认为数据模型是用于回归的线性回归和用于分类的判别分析或逻辑回归)的研究人员首先构建一个关于数据如何生成的合理机制。也就是说，研究人员根据直觉、经验或领域知识，想出一个将自变量(特征)与因变量(目标)联系起来的线性方程。</p><p id="3c93" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">模型中的系数(特征权重)是通过将其拟合到数据集而得到的。由此产生的线性方程代表了实际的数据生成机制——自然通过这个黑盒生成因变量和自变量的值。系数被用作变量重要性的度量，显示特征对响应的影响。</p><p id="64c7" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">数据建模中的验证(如果发生的话)是通过拟合优度度量(如 R 或残差分析)来完成的，这两种度量都是在训练数据集上进行的。很少考虑预测的准确性。相反，重点是模型如何解释正在研究的现象。如果系数上的 p 值足够低，那么它们是“显著的”,用 Breiman 的话来说，该模型“成为真理”,从该模型得出的任何结论都是可靠的。整个过程由直觉和主观决定引导:研究人员没有让数据说话，而是通过选择，如使用哪些特征和哪些数据点作为异常值丢弃，来强加他们自己的个人理论。</p><p id="26cf" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">Breiman 引用了 Mosteller 和 Tukey 的一本教科书来总结他对数据建模的失望:“指导回归的整个领域充满了智力、统计、计算和主题方面的困难。”换句话说，用简单的线性模型和直觉进行数据建模并不是从数据中学习的客观方式。然而，根据 Breiman 的调查，这是 98%的学术统计学家采用的方法！难怪他对自己的领域感到沮丧。</p><h2 id="0901" class="nk mo jg bd mp nl nm dn mt nn no dp mx le np nq mz li nr ns nb lm nt nu nd nv bi translated">算法建模</h2><p id="6181" class="pw-post-body-paragraph kv kw jg kx b ky nf kh la lb ng kk ld le nh lg lh li ni lk ll lm nj lo lp lq ij bi translated">算法建模方法围绕着一个问题:模型在验证数据上的表现如何？在选择模型时，不考虑模型是否代表生成数据的潜在机制，只考虑模型是否能够对新的(或持续的)观察值做出可靠的估计。Breiman 将算法文化的兴起归功于新算法的发明，如随机森林(他自己的工作)、支持向量机和神经网络。至少在当时，这些模型在理论上还没有得到很好的理解，但却产生了非凡的预测准确性，特别是在大型数据集上。</p><p id="c247" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">算法社区的一个中心思想是，自然是一个黑箱，我们的模型也是一个黑箱，尽管它可以根据新的观察结果给我们预测。试图解释一个不准确的模型是没有用的，所以在集中精力从模型中学到任何关于自然的东西之前，首先要集中精力建立一个具有最佳性能的模型。一个精确的模型，不管有多复杂，对预测(清晰地)和信息收集都更有用，因为一个简单的、可解释的低精度模型不能捕捉到任何关于问题的有用信息。</p><p id="1f4f" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">算法文化不是从学术统计中发展出来的，而是来自“年轻的计算机科学家、物理学家和工程师加上一些年老的统计学家。”换句话说，那些不怕采用甚至发明新技术来解决新问题的人。这些是实践者而不是理论家，他们使用神经网络和随机森林来解决从医学到基因组学到股票市场到天文学等领域的问题。</p><p id="32dc" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">作为一名顾问，Breiman 看到了算法建模的价值，采用最好的工具来解决问题。他开始将计算机视为一种无价的工具，因为它们能够将复杂的技术应用于大量的数据。回到学术界后，他对依赖数据模型和不重视预测准确性感到失望。即使你的主要目标是通过建模提取关于自然的信息，首要任务也应该是准确性。一个复杂、精确的模型可以告诉我们问题域，因为它一定已经捕获了特征和目标之间的关系的某个部分。此外，算法建模社区通过解决问题已经有了一些有趣的发现。</p></div><div class="ab cl mg mh hu mi" role="separator"><span class="mj bw bk mk ml mm"/><span class="mj bw bk mk ml mm"/><span class="mj bw bk mk ml"/></div><div class="ij ik il im in"><h2 id="299e" class="nk mo jg bd mp nl nm dn mt nn no dp mx le np nq mz li nr ns nb lm nt nu nd nv bi translated">1.模型的多样性:许多具有不同特征集的模型具有几乎相同的预测准确性</h2><p id="d174" class="pw-post-body-paragraph kv kw jg kx b ky nf kh la lb ng kk ld le nh lg lh li ni lk ll lm nj lo lp lq ij bi translated">我在工作中建立的最初几个模型，我被一个重复出现的模式所困扰。我试图通过测量验证分数来选择“最佳”特性，但是，每次我尝试不同的子集时，总的验证分数几乎保持不变。这令人困惑，但却反复发生:改变特性，甚至尝试不同的超参数值都会产生相似的性能。Breiman 说这没什么可担心的:对于大多数问题，当使用复杂模型时，有许多特征和超参数给出大致相同的性能。换句话说，单一最佳模型的想法是虚构的，所以我们不应该担心找到它。</p><p id="8055" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">虽然这不应该是算法模型的问题，但它给任何依赖数据模型的人带来了令人不安的问题。因为简单的线性模型不能很好地处理许多特征，它们需要广泛的特征选择，通常是通过直觉和形式方法的结合。从特征到目标的映射是通过选择特征和通过拟合计算系数来创建的，假设该映射代表地面实况，即数据生成过程。然而，如果实际上有许多组特征将给出相同的性能，那么仅仅一组特征怎么可能是事实的最终来源呢？在现实中，有许多同样好的模型，所以只选择一个并不能准确地代表问题。</p><p id="dce1" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">是什么导致了模型的多样性？我自己建立模型的经验告诉我，这是由于相关的特征(当两个变量一起增加或减少时，它们正相关)。尽管线性回归假设输入变量是独立的，但在现实世界的数据集中，几乎所有要素都有一定程度的相关性，通常非常高。因此，一个特征可以替代模型中的另一个特征，而不会降低精度。构建一个单一的数据模型，并将其称为事实的来源，会忽略所有其他同样有效的模型。算法建模者不应该担心选择特征:只需将它们全部交给你的随机森林，让它来决定哪些是重要的。训练后，认识到拟合模型只是从特征到目标的映射的一种可能的表示。</p></div><div class="ab cl mg mh hu mi" role="separator"><span class="mj bw bk mk ml mm"/><span class="mj bw bk mk ml mm"/><span class="mj bw bk mk ml"/></div><div class="ij ik il im in"><h2 id="7903" class="nk mo jg bd mp nl nm dn mt nn no dp mx le np nq mz li nr ns nb lm nt nu nd nv bi translated">2.机器学习的权衡:简单性和准确性</h2><p id="4205" class="pw-post-body-paragraph kv kw jg kx b ky nf kh la lb ng kk ld le nh lg lh li ni lk ll lm nj lo lp lq ij bi translated">这是该论文(也是从 2001 年开始)显示其年龄的一个领域。Breiman 提出了一个共同的主张，即更复杂的机器学习模型是完全无法解释的(特别是随机森林和神经网络)。当选择一个模型时，他说我们总是需要用可解释性来换取更高的准确性。然而，过去几年在解释复杂模型方面取得了重大进展，特别是<a class="ae jd" href="https://github.com/slundberg/shap/tree/master/shap" rel="noopener ugc nofollow" target="_blank"> SHAP 值</a>和<a class="ae jd" href="https://github.com/marcotcr/lime" rel="noopener ugc nofollow" target="_blank">局部可解释模型不可知解释(LIME) </a>。这些操作的一般原则是建立一个复杂的模型，然后使用一个简单的模型(如线性回归)来解释它的一小部分(局部)。</p><p id="78f6" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">(关于可解释机器学习的课程，参见 Kaggle 的<a class="ae jd" href="https://www.kaggle.com/learn/machine-learning-explainability" rel="noopener ugc nofollow" target="_blank">机器学习可解释性)。</a></p><p id="0f34" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">这些模型解释技术可以与任何模型一起工作，从随机森林到神经网络，并为单个模型预测提供合理的解释。在 Cortex，我们使用 SHAP 值来解释我们对建筑物启动 HVAC(供暖或空调)的理想时间的估计。我们的建议被广泛采纳，部分原因在于这些简单易懂的解释。</p><p id="9068" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">Breiman 对缺乏可解释性的担忧是有道理的，但是，正如新算法被发明来处理更大的数据集一样，新技术也被开发来窥视复杂的黑盒机器学习模型。这是一个算法发展速度比解释快得多的问题。这是有道理的——在试图解释算法之前，我们需要确保算法是准确的。解释一个不准确模型的预测是没有什么意义的。现在，模型解释技术已经赶上了算法，我们可以同时拥有预测背后的推理和高预测准确性。</p><p id="5026" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">当我们谈到解释的时候，我们应该提到人类在解释他们的决定方面是很糟糕的。我们确实给出了个人选择的原因，但这些原因不可能包含环境、遗传、处境、情绪、神经递质等的全部组合。真正影响决策。当我们问别人为什么上班迟到时，他们告诉我们“因为我走了不同的地铁路线”，我们接受这个事实，通常就此打住。我们没有深究其中的原因，也没有询问详细的后续问题，这将导致更多的后续问题。我们需要知道一个人的整个生活史来完整地解释他们做出的一个选择，所以很明显我们无法从人类那里得到完整的解释。</p><p id="9de0" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">我发现人们想要任何解释，不管多么站不住脚，而不是没有解释。即使这是一个<a class="ae jd" href="https://en.wikipedia.org/wiki/Tautology_(language)" rel="noopener ugc nofollow" target="_blank">同义反复</a>(男孩就是男孩)或者<a class="ae jd" href="https://en.wikipedia.org/wiki/Circular_reasoning" rel="noopener ugc nofollow" target="_blank">循环推理</a>(我犯了很多拼写错误，因为我的拼写很差)人们也会接受任何一种理由。与人为原因相比，机器学习模型输出的 SHAP 值更全面，显示了分配给与单个预测相关联的每个变量的准确权重。在这一点上，我更喜欢这些模型解释技术得出的数字，而不是人类给出的误导性理由。</p><p id="7b2b" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">与其担心模型的可解释性，也许我们应该处理更困难的问题，弄清楚人类的决策！我们在解释机器学习输出方面取得了更多进展，而不是在找出个人特定行为背后复杂的影响网络方面。(我有点掉以轻心了。我认为<a class="ae jd" href="https://christophm.github.io/interpretable-ml-book/" rel="noopener ugc nofollow" target="_blank">模型解释</a>是机器学习中最有前途的领域之一，我对向非技术观众解释机器学习的新工具感到兴奋。我的主要观点是，自论文发表以来，我们在解释模型方面已经走了很长的路。)</p></div><div class="ab cl mg mh hu mi" role="separator"><span class="mj bw bk mk ml mm"/><span class="mj bw bk mk ml mm"/><span class="mj bw bk mk ml"/></div><div class="ij ik il im in"><p id="ea5f" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated"><strong class="kx jh"> 3。有了算法模型，更多的特性可以提高性能</strong></p><p id="0c96" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">在研究生数据科学建模课上，我的教授们花了大量时间使用像<a class="ae jd" href="https://www.statisticshowto.datasciencecentral.com/variance-inflation-factor/" rel="noopener ugc nofollow" target="_blank">方差膨胀因子</a>或<a class="ae jd" href="https://en.wikipedia.org/wiki/Mutual_information" rel="noopener ugc nofollow" target="_blank">互信息</a>这样的技术进行特征选择。在实验室中，我看到了大量的功能选择，几乎总是由直觉而不是标准化的程序来指导。原因可能是合理的:线性模型往往不能很好地处理许多要素，因为它们没有足够的能力对来自要素的所有信息进行建模-但所使用的方法往往是主观的，导致模型更多地由人驱动，而不是由数据驱动。</p><p id="c79a" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">相比之下，算法模型可以从更多的特征中获益。Breiman 指出，更多的变量意味着更多的信息，一个有效的模型应该能够从噪音中挑选出信号。像随机森林这样的 ML 方法可以提供具有许多特征的准确预测，即使当变量的数量超过数据点的数量时，正如在基因组数据集中经常发生的那样。我们可以给算法模型所有的特征，让它找出与任务最相关的特征，而不是花费时间试图凭直觉留下重要的特征。此外，我们可能实际上想要创建<em class="mf">附加特性</em>，从现有变量中设计它们，以帮助模型提取更多信息。</p><p id="a786" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">直觉在算法建模文化中没有位置，不像在数据模型中，它可能通知进入模型的特征。如果我们真的想从数据中学习，那么我们必须相信数据，而不是我们的主观意见。算法建模不需要我们执行任何任意的特性选择:相反，我们保留所有的特性，甚至添加更多，并以更少的努力获得更好的性能。</p></div><div class="ab cl mg mh hu mi" role="separator"><span class="mj bw bk mk ml mm"/><span class="mj bw bk mk ml mm"/><span class="mj bw bk mk ml"/></div><div class="ij ik il im in"><h2 id="e3e8" class="nk mo jg bd mp nl nm dn mt nn no dp mx le np nq mz li nr ns nb lm nt nu nd nv bi translated">4.科学从简单到复杂</h2><p id="0e57" class="pw-post-body-paragraph kv kw jg kx b ky nf kh la lb ng kk ld le nh lg lh li ni lk ll lm nj lo lp lq ij bi translated">最后一个要点实际上来自布雷曼对批评的回应(见下文)，但这是至关重要的一点。随着我们对世界的认识不断进步，我们需要更复杂的模型来预测和学习信息。</p><p id="457b" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">早期的宇宙模型将地球置于中心，然后在确定我们当前的观点之前，将太阳置于中心，银河系只是巨大(可能是无限)宇宙中数十亿个星系中的一个。在每一步，模型都变得更加复杂，因为我们收集了更多不符合现有模型的信息。牛顿的万有引力定律在数百年间一直运行良好，直到进一步的观察揭示了它的局限性。现在，我们需要爱因斯坦的相对论(狭义和广义)来确保我们的卫星不会从天上掉下来，因此我们的 GPS 系统仍然准确。</p><p id="7a9e" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">随着其他领域开发出更复杂的模型来应对新的困难(原子的<a class="ae jd" href="https://www.compoundchem.com/2016/10/13/atomicmodels/" rel="noopener ugc nofollow" target="_blank">模型是另一个例子)，当旧的线性模型不再有用时，统计学应该抛弃它们。数据模型适用于一小部分问题，但是我们现在在数据科学中面临的挑战要大得多。用于解决它们的技术应该相应地扩展。如果科学的其他部分正在走向更大的</a><a class="ae jd" href="https://en.wikipedia.org/wiki/Complexity" rel="noopener ugc nofollow" target="_blank">复杂性</a>，我们为什么要假设统计学可以继续在最简单的模型中运行？有很多令人兴奋的问题，开发和解决它们需要使用任何最合适的工具，甚至发明新的技术来应对新的障碍。</p></div><div class="ab cl mg mh hu mi" role="separator"><span class="mj bw bk mk ml mm"/><span class="mj bw bk mk ml mm"/><span class="mj bw bk mk ml"/></div><div class="ij ik il im in"><h1 id="46e8" class="mn mo jg bd mp mq mr ms mt mu mv mw mx km my kn mz kp na kq nb ks nc kt nd ne bi translated">批评</h1><p id="9c94" class="pw-post-body-paragraph kv kw jg kx b ky nf kh la lb ng kk ld le nh lg lh li ni lk ll lm nj lo lp lq ij bi translated">按照最好的科学传统，Breiman 将 4 位统计学家的大量批评作为论文的附录，然后对反馈做出回应。通读批评和观察来回(民事)争论是值得的。科学通过公开讨论而进步，因为没有一个人有所有正确的答案。正是通过一个反复的过程，提出一个想法，对其进行批评，作为回应改进想法，收集更多的数据，并展开更多的讨论，科学才取得了巨大的成功。以下是一些阻力。</p><h2 id="8053" class="nk mo jg bd mp nl nm dn mt nn no dp mx le np nq mz li nr ns nb lm nt nu nd nv bi translated">1.简单的模型仍然有用</h2><p id="29c3" class="pw-post-body-paragraph kv kw jg kx b ky nf kh la lb ng kk ld le nh lg lh li ni lk ll lm nj lo lp lq ij bi translated">这是 Breiman 愿意承认的一点:在某些情况下，线性模型可能是合适的。例如，如果我们将距离建模为速率的函数，那么这是一个线性关系:距离=速率*时间。然而，自然界中很少有现象遵循如此好的机制(甚至上面的例子在现实世界中也几乎不成立。)线性模型可以在具有很少特征的非常小的数据集的情况下工作，但是当在诸如天文学、气候变化、股票市场预测、自然语言处理等领域中处理较新的问题时很快就过时了。其中数据集很大并且包含成千上万或更多的变量。</p><p id="88d4" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">算法文化不是放弃数据模型，而是在任何情况下使用最合适的模型。如果线性模型在数据集上记录了最高的预测准确性，则选择该模型。Breiman 的观点是，我们不应该提前假设哪个模型是正确的。算法建模是一种以上的建模方法。</p><h2 id="8917" class="nk mo jg bd mp nl nm dn mt nn no dp mx le np nq mz li nr ns nb lm nt nu nd nv bi translated">2.过度适应验证数据</h2><p id="bfb1" class="pw-post-body-paragraph kv kw jg kx b ky nf kh la lb ng kk ld le nh lg lh li ni lk ll lm nj lo lp lq ij bi translated">过拟合是机器学习中的一个基本问题:参数总是在一些数据集上学习，这并不表示该问题的所有数据。通过选择具有最佳验证分数的模型，我们可能会无意中选择一个对未来数据概括较差的模型。这不是算法模型独有的问题(尽管用更复杂的模型可能更容易过度拟合，因为它有更多的自由参数要训练)。</p><p id="a0e2" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">解决方案不是回到更简单的模型，而是使用更健壮的验证。我更喜欢交叉验证，使用多个训练/测试子集，这样性能就不会因为一个随机选择而有所偏差。该模型可能仍然是过度拟合的(这应该被称为 Kaggle 效应，因为它几乎在每个比赛中都发生)，但是一个健壮的验证设置应该在新数据上给出一个体面的性能指标。监控模型在生产中的持续性能也很重要。定期检查模型的准确性没有下降，这将允许您捕捉模型或数据漂移。一旦发生这种情况，你需要建立一个新的模型，收集更多的数据，或者重新开始解决问题。过度拟合是一个严重的问题，但可以通过正确的方法解决。</p><h2 id="2436" class="nk mo jg bd mp nl nm dn mt nn no dp mx le np nq mz li nr ns nb lm nt nu nd nv bi translated">3.特征重要性</h2><p id="4231" class="pw-post-body-paragraph kv kw jg kx b ky nf kh la lb ng kk ld le nh lg lh li ni lk ll lm nj lo lp lq ij bi translated">Breiman 关于从复杂模型中提取信息的大部分观点依赖于特征重要性的思想。这在实际的论文中没有定义，但在 Breiman 对批评的回应中有所涉及。他的定义建立在准确性的基础上。一个特性的重要性是通过这个问题来衡量的:在模型中包含这个特性能提高性能吗？</p><p id="e354" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">传统上，变量重要性是由线性模型的系数决定的。然而，我们已经看到，多个特征可以产生相同的性能，因此使用学习到的权重作为重要性的度量并不能捕捉任何单一的基本事实。</p><p id="5f8f" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">重要性可变的领域仍未解决。当变量共线(高度相关)时会出现问题，因为要素重要性可能会在要素之间分割。目前还没有一种令人满意的方法来确定哪些变量是最重要的，但基于准确性的方法比基于权重的方法更不主观。SHAP 值还提供了可变重要性的预测测量，使我们可以通过观察输出来了解每个特征值的确切影响。预测特征重要性可能不是某个特征在本质上的“真实”相关性，但它可以给我们变量之间的相对比较。</p><h2 id="70cc" class="nk mo jg bd mp nl nm dn mt nn no dp mx le np nq mz li nr ns nb lm nt nu nd nv bi translated">4.建模的目标</h2><p id="922f" class="pw-post-body-paragraph kv kw jg kx b ky nf kh la lb ng kk ld le nh lg lh li ni lk ll lm nj lo lp lq ij bi translated">一些统计学家瞄准了建模的目标是预测的想法，主张更加重视信息收集。我的回答是一个没有预测准确性的模型不能提供任何关于这个问题的有用信息。它可能会提供模型权重，但如果它们不能导致准确的预测，我们为什么要试图从中学习呢？相反，我们应该首先关注准确性——这样我们就知道我们的模型学到了一些有用的东西——然后试图弄清楚模型是如何运行的。一个模型必须准确，才能给我们有用的信息！</p><p id="9f71" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">试图理解一个无法超越简单的无机器学习基线的线性模型是没有意义的。以准确性为目标，然后花尽可能多的时间解释模型。一个没有解释的精确模型要比一个产生废话但给出清晰解释的模型好得多。</p></div><div class="ab cl mg mh hu mi" role="separator"><span class="mj bw bk mk ml mm"/><span class="mj bw bk mk ml mm"/><span class="mj bw bk mk ml"/></div><div class="ij ik il im in"><h1 id="1413" class="mn mo jg bd mp mq mr ms mt mu mv mw mx km my kn mz kp na kq nb ks nc kt nd ne bi translated">结论</h1><p id="bb2b" class="pw-post-body-paragraph kv kw jg kx b ky nf kh la lb ng kk ld le nh lg lh li ni lk ll lm nj lo lp lq ij bi translated">这篇文章对我从学术数据科学环境转向工业环境是有用的。最初，我花了很多时间试图理解模型背后的理论或通过直觉解决问题，而不是以准确性为目标，让数据决定模型。最终，我通过经验了解到了这篇论文最重要的一点:先关注准确性，再关注解释。一个模型在值得用于知识提取之前必须具有高预测性能。</p><p id="34a3" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">这在实践中意味着什么(特别是对那些在工业中的人来说)很简单:集中精力建立一个健壮的验证方案，并找到表现最好的模型。不要花太多时间担心模型背后的理论，直到你知道它是可行的。此外，经验表明，许多模型可以通过不同的特征集产生相同的准确性，附加特征可以提高复杂算法的性能，并且在模型可解释性和准确性之间存在平衡，尽管新技术已经在很大程度上缩小了差距。</p><p id="4eb0" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">当我们看到一个预测或决定时，我们都希望得到解释。然而，我们必须承认，当我们的知识和大脑限制我们时:我们根本无法处理我们现在面临的数据量，我们必须依靠机器来为我们进行大部分推理。机器学习是一种用来解决数据问题的工具，我们应该尽可能使用最好的工具。统计学是一个古老的领域，但这并不意味着它必须停留在过去:通过采用最新的算法，统计学家，甚至是学术界的统计学家，可以解决建模中出现的具有挑战性的新问题。</p></div><div class="ab cl mg mh hu mi" role="separator"><span class="mj bw bk mk ml mm"/><span class="mj bw bk mk ml mm"/><span class="mj bw bk mk ml"/></div><div class="ij ik il im in"><p id="dd74" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">一如既往，我欢迎任何反馈和建设性的批评。可以通过 Twitter <a class="ae jd" href="http://twitter.com/@koehrsen_will" rel="noopener ugc nofollow" target="_blank"> @koehrsen_will </a>找到我。</p></div></div>    
</body>
</html>