# 移动 ML 的强大臂膀

> 原文：<https://towardsdatascience.com/the-strong-arm-of-mobile-ml-5d44713072f4?source=collection_archive---------34----------------------->

![](img/508e5448a9a60806bccce1944ce924aa.png)

2009 年，我正忙于为英国情报机构和美国国防部(DoD)构建一个 skunkworks 指挥和控制项目。这个项目外包给了我自己的技术咨询公司，所以我有一个相当开放的领域，从概念到交付。

该项目需要实时接收和处理来自内部和外部的大量不同来源的数据。最终的结果是一个基于 ESRI 地理信息系统(GIS)设计的反应灵敏的仪表盘。

到目前为止，我已经花了大约 3 年的时间来构建神经网络，从麻省理工学院的一个研究项目开始，利用现有的技术尽可能地深入研究。这些神经网络大多是用运行在 Windows 上的低级 C++构建的。本质上，我所钻研的机器学习是实验性和学术性的。

随着我现在能够从指挥和控制项目中获得大量数据，我开始设计神经网络来分析社会联系和地理数据，以发现行为模式。当 OpenCL(开放计算语言)登陆时，我将一个基于 AMD 的裸机神经网络引擎放在一起，以测试我在研究中通过各种笔记本勾画出的神经网络概念的可能性(和响应性)。这是我第一次介绍嵌入式神经网络的开发。不用说，时代变了。

多年来，我一直在我能找到的每个平台上研究神经网络，包括从英伟达的 [CUDA](https://developer.nvidia.com/cuda-zone) (亚马逊的云平台)到谷歌的 [TPU](https://cloud.google.com/tpu/) 的硬件。为从汽车、无人机和机器人到服务器集群和高产出数据平台的所有领域开发解决方案。

# 库达&马里的统治

十年后，嵌入式神经网络的前景已经完全改变，通过融合硬件设计影响云计算。在过去的几年里，我通过自己的企业与 ARM 合作过几次，包括嵌入式和 HPC 部门。

ARM 的设计现在渗透到智能手机、物联网和可穿戴设备市场，以及许多其他行业。他们的 HPC 设计正在服务器和云行业快速扩张，谷歌是他们最大的客户，此前他们将对谷歌云平台的投资从英特尔分散到 AMD，然后是 ARM。从苹果到三星，甚至像华为这样的中国主要制造商，ARM 都在不断地为我们的日常设备提供动力。

![](img/ba601aeaf94673614e5f14ce2320e39c.png)

NVIDIA has leveraged the power of their GPUs for large scale deep learning

因此，当 ARM 发布了 Mali GPU ASIC 设计时，我又开始用 C++试验嵌入式神经网络。在 2013 年，这仍然是一项艰巨的工作，但改进的结果是显著的。将雾计算平台中基于 Mali 的神经网络与亚马逊上基于 CUDA 的集群相结合，为我正在钻研的从农业到经济的各种项目提供了昂贵但令人印象深刻的解决方案。在 ARM 和 NVIDIA 基本控制市场的情况下，高效 GPU 硬件的可用性是机器学习领域的一个重大改变。

# 手机上的机器学习

这些解决方案随着现在可用的开发工具的不断改进而不断发展，包括 [TensorFlow Lite](https://www.tensorflow.org/lite/) 、 [ML Kit](https://developers.google.com/ml-kit/) 和 [Core ML](https://developer.apple.com/machine-learning/core-ml/) 。后两者对于移动开发者社区尤为重要，他们越来越多地转向机器学习来增强移动应用体验。

这些框架的工具——以及在移动应用中有效使用它们的途径——差别很大，这本身就是一个迷人的主题。最近我一直在想，主要设备制造商之间的硬件实际上是如何影响开发者体验的。我最近支持了一个计算机视觉项目，其中一名 Android 开发人员发现谷歌 Pixel 3 上的 TensorFlow Lite (ML Kit / Firebase)模型的性能不足，不得不用三星 S10 进行原型开发。

![](img/fe684304c65dce0ed92ef765ef53e635.png)

我考虑这是否意味着两个最强大的智能手机之间的移动应用体验可能会有很大的不同，从而改变客户对质量的看法。因此，我一头扎进硬件，看看为什么最新的手机在如此短的时间内在性能方面取得了飞跃，以便更好地了解在构建智能手机体验时需要考虑哪些设计因素。

最初，关于谷歌 Pixel 3 为什么比三星 S10 慢这么多的具体答案很快就出来了。高通的骁龙 855 是新 S10 的核心，因为 Pixel 3 使用了旧的骁龙 845。不仅如此，S10 还有 [Mali-G76](https://www.arm.com/products/silicon-ip-multimedia/gpu/mali-g76) ，其中-因为 Pixel 3 使用了高通 Adreno 630。我不会在这里进入智能手机拆卸领域，人们会很快指出，S10 也有一个 Adreno 640 作为骁龙 855 的一部分，而不是在马里。无论如何，芯片设计的微小变化可以在机器学习模型和推理的计算能力方面产生巨大差异。

我在 iPhone 11 Pro 上使用了苹果的 [A13 Bionic](https://en.wikipedia.org/wiki/Apple_A13) ，并在索尼的 Xperia 5 上测试了相同的 TensorFlow Lite 计算机视觉模型。该模型是我在 2016 年开发的，只是更新了依赖关系并进行重新训练。同样，我不会在这里对智能手机的性能进行基准测试，但在这些设备之间移动并看到性能变化的体验提出了一个问题，即开发人员在将他们的机器学习项目交付给消费者之前，可以在多大程度上测试他们的项目。

> 如果性能差异如此之大，用户体验设计应该考虑响应能力的潜在差异。我们不要忘记，改进不仅仅是在延迟方面，还包括热量和能源使用方面。这些是终端用户体验的关键要素。

# 神经处理单元

所有这些设备制造商都在通过他们定制的基于 ARM 的芯片构建特定于设备的功能，如摄影增强和生物识别。最近，智能手机神经网络行业的武器化迈出了重要的一步，这可能会对智能手机开发商的竞争力产生巨大影响。例如，苹果、谷歌和华为现在已经为他们最新的旗舰手机构建了定制的神经处理单元(npu)，使机器学习对应用程序开发人员来说更加强大，但也意味着这些设备制造商可以独特地访问他们想要在这些设备上运行的操作类型。

![](img/c307a0e7f4771f89bca0d877c7183040.png)

> 在 npu 之前，开发人员构建的模型将针对 GPU(通常基于 Mali)进行优化，因为 GPU 的计算设计用于矩阵乘法和卷积，最初旨在渲染复杂的图形。在 GPU 出现之前，CPU 必须满足所有的处理需求。npu 松散地基于 GPU，没有图形处理所需的任何开销，这使得它们对于机器学习和深度学习任务非常有效。由于深度学习是一项计算量很大的任务，因此这是向前迈出的重要一步。

距离 ARM [宣布他们自己的一系列名为 Ethos](https://developer.arm.com/ip-products/processors/machine-learning/arm-ethos-n) 的 npu 还不到一周，这些 npu 是以 [ARM NN](https://developer.arm.com/ip-products/processors/machine-learning/arm-nn) 为理念打造的。这真的让我很兴奋:基于 ARM 的神经处理单元的想法将在未来 18 个月内开始登陆智能手机，更有趣的是，开始在边缘计算(想想物联网)和云计算中使用。这通常是英伟达的 CUDA 硬件和谷歌 TPU 的强项，但就效率和性能而言，ARM 无疑是这些公司所在市场的领导者，因此它们的 npu 可能会大幅进入这些领域。

ARM 的 Mali 几乎是最高性能智能手机唯一可用的 GPU 架构，它一直是移动设备上现有神经网络性能的主要来源。如果 ARM 采用了 Mali 的最佳部分，并将 Ethos 设计为神经网络的下一步，那么这可能是性能的重大转变。GPU 是一个有用的权宜之计，但从来没有打算做 npu 现在能够做的事情。

# 云中的风暴

一些最知名和最常用的神经网络库已经针对 Ethos 进行了优化，包括 [Caffe2](https://caffe2.ai) (本身是一个面向移动的库) [MXNet](https://mxnet.incubator.apache.org) 、 [PyTorch](https://pytorch.org) 和 [TensorFlow](https://www.tensorflow.org) 。随着谷歌在其谷歌云平台上拥有自己的 TPU(Google NPU 和首批上市的产品之一)的性能优势，我设想亚马逊和微软会考虑 ARM 的 Ethos 计划，并看看他们如何利用这些计划将 AWS 和 Azure 分别带回与谷歌云平台的竞争中，用于深度学习项目。

![](img/3048350ba0e7d3a0726aab8b4af4c714.png)

数据平台架构中的现有概念已经发生了广泛的变化，npu 在以多种方式优化数据平台方面创造了无数的可能性，这可能会使过去 15 年中占主导地位的数据平台架构像现在的 N 层架构一样冗余。

我最近与苹果、谷歌和英特尔谈论了机器学习的开发者工具链以及它与网络生态系统的关系。他们目前的视野是 10 年的硬件开发，这越来越适合神经网络操作的优化。流行的神经网络库已经包含 10，000 个运算，TensorFlow 同比增长 25%。这使得这些 10 年路线图无法坚持软件行业的发展。

相反，更高级的工具需要能够在编译器级别提供优化，这在目前还不是标准。Python 是最流行的机器学习语言，由于其执行模型，在运行时的优化有限。由于[多级中间表示](https://medium.com/tensorflow/mlir-a-new-intermediate-representation-and-compiler-framework-beba999ed18d)和【TensorFlow 的 Swift】是这种工具链优化如何有效工作的一个很好的例子，这种情况正在改变。优化硬件只是这个快速变化的生态系统的一部分。

# 开放，但不自由

看到 npu 的成熟和普及令人兴奋，但也令人担忧。对开发人员生态系统的硬件控制是一种把关的方法，增加了开发人员的工具费用。为机器学习生产和分发开源软件看起来仁慈而慷慨，但如果这些工具是由开源项目的赞助人针对特定 NPU 严格优化的，那么它就不再是一个开放的生态系统。这种担忧不仅与智能手机市场相关，也与云基础架构和 HPC 市场相关。

尽管如此，npu 可能对隐私优先的机器学习架构和安全性产生巨大的积极影响，无疑将刺激许多机器学习智能手机应用的用户体验。

当然，这里涵盖的大部分内容都是比大多数开发人员看到的更低的抽象层次。虽然我很喜欢 ARMv8 解决方案的开发，但开发人员甚至不会直接接触 ARM-NN SDK。这些组件都是像 TensorFlow 这样的高级神经网络在部署应用程序时如何工作的关键。了解我们所构建的基础对于进一步做出决策至关重要。

最后，重要的是从建立越来越多的智能神经网络的热情中退一步，并记住建立越来越大和复杂的计算解决方案的生态成本。考虑到这些项目的影响，关注如何让开发人员从我们丰富的工具中获得最大的影响是很重要的。