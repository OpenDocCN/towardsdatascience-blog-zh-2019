<html>
<head>
<title>Looking for the Perfect Words? Generate Them</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">寻找完美的词语？生成它们</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/looking-for-the-perfect-words-generate-them-b28b818c2f24?source=collection_archive---------48-----------------------#2019-12-02">https://towardsdatascience.com/looking-for-the-perfect-words-generate-them-b28b818c2f24?source=collection_archive---------48-----------------------#2019-12-02</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="5ae8" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">使用 LSTM 模型生成诗歌。</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/5f90c262d2904d8748a0fd4f378ccfb5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*kvy_G-Y6YHmEubCe"/></div></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk">Photo by <a class="ae kv" href="https://unsplash.com/@thoughtcatalog?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Thought Catalog</a> on <a class="ae kv" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Unsplash</a>.</figcaption></figure><h1 id="65f4" class="kw kx iq bd ky kz la lb lc ld le lf lg jw lh jx li jz lj ka lk kc ll kd lm ln bi translated">动机</h1><p id="1cdb" class="pw-post-body-paragraph lo lp iq lq b lr ls jr lt lu lv ju lw lx ly lz ma mb mc md me mf mg mh mi mj ij bi translated">有没有试着找到合适的词来描述你的感受？想在一首诗中向你的另一半表白你的爱吗？你为什么不根据成千上万首著名的诗来生成一首呢？这就是我们试图用长短期记忆(LSTM)模型来做的事情。</p><h1 id="26af" class="kw kx iq bd ky kz la lb lc ld le lf lg jw lh jx li jz lj ka lk kc ll kd lm ln bi translated">什么是 LSTM 模型？</h1><p id="d717" class="pw-post-body-paragraph lo lp iq lq b lr ls jr lt lu lv ju lw lx ly lz ma mb mc md me mf mg mh mi mj ij bi translated">LSTM 模型具有人工递归神经网络(RNN)架构。既然是递归网络，就意味着模型有反馈连接。此外，它可以处理整个数据序列，如句子或视频。LSTM 通常用于手写识别和语音识别。它擅长处理这类问题，因为它有选择性的记忆模式。典型的 LSTM 单元由一个单元、一个输入门、一个输出门和一个遗忘门组成。当信息进入这个单元时，它要么被遗忘，要么被输入到单元的其他部分，要么被汇总并输出。</p><p id="51c9" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated"><strong class="lq ir"> <em class="mp">遗忘门</em> </strong>通过滤波器的乘法运算从细胞中移除信息(见上面最左边的 sigmoid 函数，乘法符号的箭头)。</p><p id="6030" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated"><strong class="lq ir"> <em class="mp">输入门</em> </strong>是如何将新信息添加到单元格中的。这分三步进行。首先，sigmoid 函数充当过滤器，决定需要添加哪些值。接下来，tanh 函数创建一个包含所有可能相加的值的向量。输出向量将在-1 到 1 的范围内。最后，sigmoid 滤波器和 tanh 函数的值相乘，然后相加到单元格中。</p><p id="ebf5" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated"><strong class="lq ir"> <em class="mp">输出门</em> </strong>从单元状态中选择有用的信息并显示为输出。这也分三步进行。首先，应用双曲正切函数得到-1 和 1 之间的值。同样，我们将使用 sigmoid 函数作为过滤器。为了完成这一步，tanh 函数创建的向量与过滤器相乘，并将其作为输出发送到下一个隐藏单元格。</p><p id="805d" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">总之，所有这些门使得 LSTM 模型在序列预测方面比典型的卷积前馈网络或 RNN 好得多。这就是为什么我们选择使用 LSTM 模型来生成诗歌。</p><h1 id="f4f7" class="kw kx iq bd ky kz la lb lc ld le lf lg jw lh jx li jz lj ka lk kc ll kd lm ln bi translated">我们的数据</h1><p id="ee71" class="pw-post-body-paragraph lo lp iq lq b lr ls jr lt lu lv ju lw lx ly lz ma mb mc md me mf mg mh mi mj ij bi translated">用于训练我们的用于诗歌生成的 LSTM 模型的数据来自于《PoetryFoundation.com 诗集》。数据可以在 Kaggle 上的<a class="ae kv" href="https://www.kaggle.com/tgdivy/poetry-foundation-poems" rel="noopener ugc nofollow" target="_blank">处找到。每个诗歌条目包含几个描述诗歌的标签。我们决定把重点放在三类诗歌上:爱情、自然和悲伤。为了获得正确的数据，我们需要从数据集中提取具有特定标签的诗歌。我们决定将每首诗的字符数限制在 1000 个以内(我们用了更多的字符)，因为这样我们就包含了足够多的诗，并且不会给我们的计算机带来太大的压力。在下面的代码中，您可以看到我们是如何获得数据的。</a></p><pre class="kg kh ki kj gt mq mr ms mt aw mu bi"><span id="c131" class="mv kx iq mr b gy mw mx l my mz"><strong class="mr ir"># include 1000 characters from each poem</strong><br/>pd.options.display.max_colwidth = 1000 </span><span id="318c" class="mv kx iq mr b gy na mx l my mz"><strong class="mr ir"># load dataset from poetryfoundation.com dataset</strong><br/>df = pd.read_csv('PoetryFoundationData.csv') </span><span id="9a8e" class="mv kx iq mr b gy na mx l my mz"><strong class="mr ir"># dropping any entries with no tags</strong><br/>df = df.dropna()</span></pre><p id="c8eb" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">这是原始数据的一个例子。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nb"><img src="../Images/0ec166285b98b0ec594c130423f1ed34.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Q1hOx1nL4skPJ4ZNPtX0fA.png"/></div></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk">Raw poem data from Kaggle dataset. Photo by author.</figcaption></figure><p id="7f4c" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">正如你在上面的原始数据中看到的，有几个标签。为了这篇博文的目的，我们将只向您展示我们是如何提取带有标签“爱”的诗歌的(参见下面的代码)。我们还使用其他标签生成了诗歌，你可以在这篇文章的结尾看到。</p><pre class="kg kh ki kj gt mq mr ms mt aw mu bi"><span id="4f90" class="mv kx iq mr b gy mw mx l my mz">poems = df[‘Poem’]</span><span id="5b96" class="mv kx iq mr b gy na mx l my mz"><strong class="mr ir"># you can add additional tags to searchfor if you want more poems</strong><br/>searchfor = [‘Love’]<br/>lovePoems = poems.loc[df[‘Tags’].str.contains(‘|’.join(searchfor))] <br/>lovePoems = lovePoems.to_string()</span></pre><h1 id="5468" class="kw kx iq bd ky kz la lb lc ld le lf lg jw lh jx li jz lj ka lk kc ll kd lm ln bi translated">训练模型</h1><p id="b050" class="pw-post-body-paragraph lo lp iq lq b lr ls jr lt lu lv ju lw lx ly lz ma mb mc md me mf mg mh mi mj ij bi translated">一旦我们收集了我们需要的诗歌，我们就能够创建训练和测试数据。在下面的代码中，我们创建了训练数据。首先，我们必须将字符映射到索引，反之亦然。</p><pre class="kg kh ki kj gt mq mr ms mt aw mu bi"><span id="2924" class="mv kx iq mr b gy mw mx l my mz">chars = sorted(list(set(lovePoems)))<br/>char_indices = dict((c, i) for i, c in enumerate(chars))<br/>indices_char = dict((i, c) for i, c in enumerate(chars))</span></pre><p id="144b" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">接下来，我们必须为训练创建 X 和 Y 数据集。这个过程将一大串诗歌分割成长度为 50 个字符的序列。</p><pre class="kg kh ki kj gt mq mr ms mt aw mu bi"><span id="02fe" class="mv kx iq mr b gy mw mx l my mz"><strong class="mr ir"># process the dataset</strong><br/>seqlen = 50<br/>step = seqlen</span><span id="d1ad" class="mv kx iq mr b gy na mx l my mz">data_X = []<br/>data_y = []</span><span id="456d" class="mv kx iq mr b gy na mx l my mz">poemLines = []</span><span id="cc22" class="mv kx iq mr b gy na mx l my mz"><strong class="mr ir"># creates poem lines </strong><br/>for i in range(0, len(lovePoems) — seqlen — 1, step):<br/> poemLines.append(lovePoems[i: i + seqlen + 1])<br/> <br/><strong class="mr ir"># creating x and y data</strong><br/>data_X = np.zeros((len(poemLines), seqlen, len(chars)), dtype=np.bool)<br/>data_Y = np.zeros((len(poemLines), seqlen, len(chars)), dtype=np.bool)</span><span id="49f2" class="mv kx iq mr b gy na mx l my mz">for i, poemLines in enumerate(poemLines):<br/> for t, (char_in, char_out) in enumerate(zip(poemLines[:-1], poemLines[1:])):<br/> data_X[i, t, char_indices[char_in]] = 1<br/> data_Y[i, t, char_indices[char_out]] = 1</span></pre><p id="3be6" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">生成数据后，我们建立了模型。其架构中有一个 LSTM 层和一个密集层。我们将在下面讨论，但我们玩了 LSTM 层的隐藏单位的数量。此外，我们尝试了一个具有 2 个 LSTM 层和 3 个 LSTM 层的模型。保持所有变量不变，当改变层数时，我们没有看到模型性能的差异。</p><pre class="kg kh ki kj gt mq mr ms mt aw mu bi"><span id="4989" class="mv kx iq mr b gy mw mx l my mz"><strong class="mr ir"># create the model</strong><br/>model = Sequential()<br/>model.add(LSTM(80, input_shape=(seqlen, len(chars)), return_sequences=True))<br/>model.add(Dense(len(chars), activation='softmax'))</span><span id="5a64" class="mv kx iq mr b gy na mx l my mz">model.compile(loss='categorical_crossentropy', optimizer=RMSprop(learning_rate=0.01), metrics=['categorical_crossentropy', 'accuracy'])<br/>model.summary()</span></pre><h1 id="8c7d" class="kw kx iq bd ky kz la lb lc ld le lf lg jw lh jx li jz lj ka lk kc ll kd lm ln bi translated">评估模型</h1><p id="15f8" class="pw-post-body-paragraph lo lp iq lq b lr ls jr lt lu lv ju lw lx ly lz ma mb mc md me mf mg mh mi mj ij bi translated">然后，我们准备好安装我们的模型。经过 128 个批次和 10 个时期的训练，我们达到了 0.68 的准确率。</p><pre class="kg kh ki kj gt mq mr ms mt aw mu bi"><span id="8309" class="mv kx iq mr b gy mw mx l my mz"><strong class="mr ir"># evaluate the model on validation set and visualize <br/></strong>history = model.fit(data_X, data_Y, validation_split = .33, batch_size=128, epochs=10)</span></pre><p id="7bba" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">我们还在验证数据集上评估了该模型，并可视化了结果。下图显示了 LSTM 层有 128 个隐藏单元时的训练和验证损失。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi nc"><img src="../Images/86f4405edb6ddfc0ec7658e10be28607.png" data-original-src="https://miro.medium.com/v2/resize:fit:796/format:webp/1*x3xnOStUyWhHltNrorY5zw.png"/></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk">Visualization of model training and validation loss when LSTM layer had 128 hidden units. Photo by author.</figcaption></figure><p id="1e2e" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">然而，当我们用 80 个隐藏单元为 LSTM 层拟合我们的模型时，我们看到了下图。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi nd"><img src="../Images/d559cfc88ed7717b8927fa69843fa4ea.png" data-original-src="https://miro.medium.com/v2/resize:fit:772/format:webp/1*5p8ycKL7wGuIO0r5uUyDQg.png"/></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk">Visualization of model training and validation loss when LSTM layer had 80 hidden units. Photo by author.</figcaption></figure><p id="c977" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">当比较这两个图时，我们可以看到 LSTM 层中具有 80 个隐藏单元的模型比具有 128 个隐藏单元的模型具有更好的拟合。具有 128 个隐藏单元的模型显示了我们在研究中读到的过度拟合模式。随着时间的推移，训练和验证数据会出现分歧，这不是我们想要的。然而，对于 80 个隐藏单元，训练和验证损失一起减少，表明模型拟合良好。</p><p id="5118" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">我们也意识到，我们的精确度本来可以更高。我们尝试用数据集中每首诗的 3000 个字符来训练我们的模型。这增加了我们拥有的数据量，我们能够将模型的准确性提高到 78%，增加了 10%。如果我们有更多的时间和更多的计算能力，我们可以使用更多的数据。我们使用的数据量比我们能获得的要少，因为训练时间太长了。</p><h1 id="3076" class="kw kx iq bd ky kz la lb lc ld le lf lg jw lh jx li jz lj ka lk kc ll kd lm ln bi translated">生成诗歌</h1><p id="c09e" class="pw-post-body-paragraph lo lp iq lq b lr ls jr lt lu lv ju lw lx ly lz ma mb mc md me mf mg mh mi mj ij bi translated">在确定了模型的架构之后，我们使用下面的代码生成了一些诗歌。</p><pre class="kg kh ki kj gt mq mr ms mt aw mu bi"><span id="c0df" class="mv kx iq mr b gy mw mx l my mz"><strong class="mr ir"># helper function that samples an index from probability array<br/></strong>def sample(preds, temperature=1.0):<br/>    preds = np.asarray(preds).astype('float64')<br/>    preds = np.exp(np.log(preds) / temperature)  # softmax<br/>    preds = preds / np.sum(preds)                <br/>    probas = np.random.multinomial(1, preds, 1)  # sample index<br/>    return np.argmax(probas)</span><span id="eb1d" class="mv kx iq mr b gy na mx l my mz"><strong class="mr ir"># generate poem<br/></strong>def generating_poem(poem_length, start_index, diversity, _):<br/>    start_index = start_index<br/>    diversity = diversity</span><span id="0fc5" class="mv kx iq mr b gy na mx l my mz">generated = ''<br/>    poemLines = lovePoems[start_index: start_index + seqlen]<br/>    generated += poemLines<br/>    print('----- Generating with seed: "' + poemLines + '"')<br/>    sys.stdout.write(generated)</span><span id="99dc" class="mv kx iq mr b gy na mx l my mz">for i in range(poem_length):<br/>        x_pred = np.zeros((1, seqlen, len(chars)))<br/>        for t, char in enumerate(poemLines):<br/>            x_pred[0, t, char_indices[char]] = 1.<br/>            <br/>        preds = model.predict(x_pred, verbose=0)<br/>        next_index = sample(preds[0, -1], diversity)<br/>        next_char = indices_char[next_index]</span><span id="fb50" class="mv kx iq mr b gy na mx l my mz">poemLines = poemLines[1:] + next_char</span><span id="d9ad" class="mv kx iq mr b gy na mx l my mz">sys.stdout.write(next_char)<br/>        sys.stdout.flush()<br/>    print()</span></pre><p id="548d" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">下面，我们生成了一首诗，长度为 500 个字符，一个开始索引(这是来自原始文本的序列长度的字符串)，多样性为 0.5。分集输入改变了采样概率。经过几次尝试，我们发现 0.5 的多样性给了我们最好的诗。多样性为 0.1 会使诗歌过于重复，多样性为 1 会使诗歌缺乏意义。</p><pre class="kg kh ki kj gt mq mr ms mt aw mu bi"><span id="7cef" class="mv kx iq mr b gy mw mx l my mz"><strong class="mr ir"># input desired poem length, start index, diversity</strong><br/>generating_poem(500, 60, .5, _) </span></pre><p id="354e" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">下面是上面代码运行的输出:</p><pre class="kg kh ki kj gt mq mr ms mt aw mu bi"><span id="e35a" class="mv kx iq mr b gy mw mx l my mz">----- Generating with seed: "n\r\r\n\r\r\n\r\r\nAnd it won’t be multiple choice"<br/>n\r\r\n\r\r\n\r\r\nAnd it won’t be multiple choiced in the sky love and made the back between the forest and the from the black and sky feet promised which her desire. I could come before the point to the collation.\r\r\nI am a dear the shadows and which stare of the father, the cheek and boxasted seeman that the confecting the can sweating while I moved me can don’t know you want to still watch the stater and we can see a poem who deep of bene to the didn’t were been on the breaks dark in the tongue and blood from the color in the morning on t</span></pre><p id="fbbc" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">如您所见，输出包括新的线条指示器(\r\r\n)。我们尝试从训练字符串中删除这些字符，但是我们认为保留这些字符可以让我们的模型像真正的诗歌一样构建我们生成的诗歌。下面，我们展示了一些我们生成的、格式很好的诗歌。</p><p id="3c80" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated"><strong class="lq ir">爱情诗#1: </strong></p><pre class="kg kh ki kj gt mq mr ms mt aw mu bi"><span id="c249" class="mv kx iq mr b gy mw mx l my mz">Roy and Glen</span><span id="4c4a" class="mv kx iq mr b gy na mx l my mz">lost themselves</span><span id="3ad9" class="mv kx iq mr b gy na mx l my mz">is the world the prides or story in the starting the discapive to the stranged start us the wind. The down the stucky strange and the last the sky</span><span id="3d1a" class="mv kx iq mr b gy na mx l my mz">each an all the spon and carry me heart and set, and the bright have so sand for the stranged of the stranger. I see we between my leaves stranged the skies in the annt, sweet of at the same shade to heart, and the can don’t grape in not so self</span></pre><p id="8916" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated"><strong class="lq ir">爱情诗#2: </strong></p><pre class="kg kh ki kj gt mq mr ms mt aw mu bi"><span id="a10a" class="mv kx iq mr b gy mw mx l my mz">The woman carried the bucket</span><span id="326e" class="mv kx iq mr b gy na mx l my mz">and the man with sing are fingers the soft in this do, and of the conficial from the strangering to my slight which the sky stead between the body of a sation under there is the spring became and prices air strange of me to mouth have at his blossoms the sands in the trangs of the stared a paration in the man spring of carvant</span></pre><p id="5f22" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated"><strong class="lq ir">悲伤的诗#1: </strong></p><pre class="kg kh ki kj gt mq mr ms mt aw mu bi"><span id="71b1" class="mv kx iq mr b gy mw mx l my mz">Among these in this place my father lay</span><span id="62d6" class="mv kx iq mr b gy na mx l my mz">At the end of everything</span><span id="285b" class="mv kx iq mr b gy na mx l my mz">In the curked the pather she have years with the single to the mander,</span><span id="242d" class="mv kx iq mr b gy na mx l my mz">as mance of the should the wordder the stear the procked the goor in hone the searther the marmer.</span><span id="c75b" class="mv kx iq mr b gy na mx l my mz">I was a sinder the pourth of the say and word the same the see we life, geser and he was down the all dading morned with the stead of the sleet on the surion, not liver, a mone the mardens colling to me see she seeple of the sead of the becausion the spean.</span><span id="d3a0" class="mv kx iq mr b gy na mx l my mz">Lone the bood the swear the looked wor a man her beants of the rom</span></pre><p id="44bb" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated"><strong class="lq ir">悲伤的诗#2: </strong></p><pre class="kg kh ki kj gt mq mr ms mt aw mu bi"><span id="1a87" class="mv kx iq mr b gy mw mx l my mz">tooed with red…</span><span id="af2d" class="mv kx iq mr b gy na mx l my mz">Imagine half your face</span><span id="db43" class="mv kx iq mr b gy na mx l my mz">rubbed out yet</span><span id="36ec" class="mv kx iq mr b gy na mx l my mz">you are suited up</span><span id="5209" class="mv kx iq mr b gy na mx l my mz">where were souned a reared semerit</span><span id="3f03" class="mv kx iq mr b gy na mx l my mz">a manding words and the did read to mister the flown the stone are where dristed were the san land a come was the son like word the light of the wise to belend</span><span id="346a" class="mv kx iq mr b gy na mx l my mz">and she teather, you been a die and lacken the wanted from the cores and the mand of Comples, never a come your mone the mone of the she she park of hall that like the sard of the she was the pleared in the say back the meed the say with to be the ray.</span><span id="0986" class="mv kx iq mr b gy na mx l my mz">A dried be sun to carr take in th</span></pre><p id="3d6c" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated"><strong class="lq ir">自然诗#1: </strong></p><pre class="kg kh ki kj gt mq mr ms mt aw mu bi"><span id="5fa2" class="mv kx iq mr b gy mw mx l my mz">Soon the fish will learn to walk. Then humans will come ashore and paint dreams on the wall distant when the rain she who water the world of mean the flower </span><span id="b4e5" class="mv kx iq mr b gy na mx l my mz">the flowers the flacks the ancent of my walls and shadows the river and stars them like the sung and flue</span><span id="b020" class="mv kx iq mr b gy na mx l my mz">the sea when the bodge his not behind the streets of the remement and she to the sings in the screen, the name the stars of the days on the the sounds the dark skin the mother the same and this pity, the clouds have a state is sings and someone land, and at my shell stars</span><span id="c6dd" class="mv kx iq mr b gy na mx l my mz">as the little still make a way t</span></pre><p id="a186" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated"><strong class="lq ir">自然诗#2: </strong></p><pre class="kg kh ki kj gt mq mr ms mt aw mu bi"><span id="2d1e" class="mv kx iq mr b gy mw mx l my mz">e; it is obvious) and everything about him is beautiful. His hand swells from the bite [spread?] of the sky in the more the will condine her the distant green the forms, the wind my bear the side the roots where a merch her cold of high a constiled in the charged the body the stars in the wind sauter be. The cold with the world from the remember, and he stream and sting for the season the men rain</span><span id="100d" class="mv kx iq mr b gy na mx l my mz">a wood with the was in the silence and men the world it roses where the cattent the capt and seas the dark and still as the grass</span><span id="ad56" class="mv kx iq mr b gy na mx l my mz">where he the stars and past of the the color the beats head</span></pre><h1 id="7459" class="kw kx iq bd ky kz la lb lc ld le lf lg jw lh jx li jz lj ka lk kc ll kd lm ln bi translated">生成诗述评</h1><p id="fe71" class="pw-post-body-paragraph lo lp iq lq b lr ls jr lt lu lv ju lw lx ly lz ma mb mc md me mf mg mh mi mj ij bi translated">总的来说，我们的诗歌输出似乎生成了与数据集格式相似的诗歌。他们有相似数量的“\r\r\n”来表示间距，并且他们非常擅长造句。每个类别的总体情绪似乎也反映了它所来自的数据。然而，它们仍然很难符合逻辑，并且高度基于起始索引。起始索引在决定这首诗的结局方面起着很大的作用。起始种子中的单词经常在整首诗中重复出现。</p><p id="4ab3" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">在将来，为了提高这些诗的输出，我们可以将这些诗编入索引，这样每次的起始种子都从诗的开头开始，而不是从诗的中间或结尾开始。我们可以做些工作，让它在一首完整的诗上训练，这样它就不会随机开始和结束——创造一首更简洁的诗。</p><p id="3cfd" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">每个句子的逻辑感是另一个需要提高的地方。然而，这在诗歌中是一个巨大的挑战，因为诗歌是艺术的，不一定遵循传统的语法规则。我们也可以做更多的研究来让诗歌更连贯。</p><h1 id="61dd" class="kw kx iq bd ky kz la lb lc ld le lf lg jw lh jx li jz lj ka lk kc ll kd lm ln bi translated">反光</h1><p id="fb05" class="pw-post-body-paragraph lo lp iq lq b lr ls jr lt lu lv ju lw lx ly lz ma mb mc md me mf mg mh mi mj ij bi translated">当我们开始这个项目时，我们原本打算使用一个生成式对抗网络(GAN)，其中生成器是一个递归神经网络(RNN)。在做了一些研究之后，我们发现<a class="ae kv" href="https://becominghuman.ai/generative-adversarial-networks-for-text-generation-part-1-2b886c8cab10" rel="noopener ugc nofollow" target="_blank">有几篇文章</a>提到了在文本格式上使用 GAN 时的困难和不准确性。我们还看到有人推荐 LSTM 模型，所以我们改用了它。如果使用 GAN 就好了，因为我们可以组合数据的潜在空间，而不是为每种类型的诗歌创建一个新的模型。</p><p id="bcb7" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">我们可以尝试的另一件事是把这首诗按照时间周期分开。莎士比亚写的诗与现代诗有着非常不同的语言，这可能会给模型生成带来混乱的数据集。如果我们要添加到这个项目中，我们可以按时间段分开，这样用户可以选择他们希望他们的诗出来的风格。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/b74cbcd2da6d7af22c0f4f30b4ea5d2e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*nGmyPVyB_zeHwEy6"/></div></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk">Photo by <a class="ae kv" href="https://unsplash.com/@thoughtcatalog?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Thought Catalog</a> on <a class="ae kv" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><p id="0204" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">另一个可以添加到未来工作中的功能是诗歌标题。如果我们有更多的时间，我们可以格式化数据，将诗名和诗内容一起放入。然后，我们将根据匹配每首生成的诗歌的标签生成一个标题。然而，这可能会导致标题与实际的诗歌内容无关。</p><p id="c63d" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">总的来说，我们意识到有很多事情我们可以尝试改进模型的诗生成。然而，我们在诗歌生成方面有了一个良好的开端，并且已经了解了很多关于 LSTM 模型如何工作以及如何调整它们的知识。</p><h1 id="b03f" class="kw kx iq bd ky kz la lb lc ld le lf lg jw lh jx li jz lj ka lk kc ll kd lm ln bi translated">参考</h1><div class="ne nf gp gr ng nh"><a href="https://www.analyticsvidhya.com/blog/2017/12/fundamentals-of-deep-learning-introduction-to-lstm/" rel="noopener  ugc nofollow" target="_blank"><div class="ni ab fo"><div class="nj ab nk cl cj nl"><h2 class="bd ir gy z fp nm fr fs nn fu fw ip bi translated">深度学习精要:长短期记忆导论</h2><div class="no l"><h3 class="bd b gy z fp nm fr fs nn fu fw dk translated">引言序列预测问题由来已久。他们被认为是最难的…</h3></div><div class="np l"><p class="bd b dl z fp nm fr fs nn fu fw dk translated">www.analyticsvidhya.com</p></div></div><div class="nq l"><div class="nr l ns nt nu nq nv kp nh"/></div></div></a></div><div class="ne nf gp gr ng nh"><a rel="noopener follow" target="_blank" href="/ai-generates-taylor-swifts-song-lyrics-6fd92a03ef7e"><div class="ni ab fo"><div class="nj ab nk cl cj nl"><h2 class="bd ir gy z fp nm fr fs nn fu fw ip bi translated">人工智能生成泰勒·斯威夫特的歌词</h2><div class="no l"><h3 class="bd b gy z fp nm fr fs nn fu fw dk translated">泰勒斯威夫特歌词生成器</h3></div><div class="np l"><p class="bd b dl z fp nm fr fs nn fu fw dk translated">towardsdatascience.com</p></div></div><div class="nq l"><div class="nw l ns nt nu nq nv kp nh"/></div></div></a></div><div class="ne nf gp gr ng nh"><a href="https://machinelearningmastery.com/diagnose-overfitting-underfitting-lstm-models/" rel="noopener  ugc nofollow" target="_blank"><div class="ni ab fo"><div class="nj ab nk cl cj nl"><h2 class="bd ir gy z fp nm fr fs nn fu fw ip bi translated">如何诊断 LSTM 模型的过拟合和欠拟合</h2><div class="no l"><h3 class="bd b gy z fp nm fr fs nn fu fw dk translated">很难确定你的长短期记忆模型是否在你的序列中表现良好…</h3></div><div class="np l"><p class="bd b dl z fp nm fr fs nn fu fw dk translated">machinelearningmastery.com</p></div></div><div class="nq l"><div class="nx l ns nt nu nq nv kp nh"/></div></div></a></div><div class="ne nf gp gr ng nh"><a href="https://becominghuman.ai/generative-adversarial-networks-for-text-generation-part-1-2b886c8cab10" rel="noopener  ugc nofollow" target="_blank"><div class="ni ab fo"><div class="nj ab nk cl cj nl"><h2 class="bd ir gy z fp nm fr fs nn fu fw ip bi translated">文本生成的生成性对抗网络——第一部分</h2><div class="no l"><h3 class="bd b gy z fp nm fr fs nn fu fw dk translated">用于文本生成的 GANs 的问题以及解决这些问题的方法</h3></div><div class="np l"><p class="bd b dl z fp nm fr fs nn fu fw dk translated">becominghuman.ai</p></div></div><div class="nq l"><div class="ny l ns nt nu nq nv kp nh"/></div></div></a></div><div class="ne nf gp gr ng nh"><a href="https://medium.com/cindicator/music-generation-with-neural-networks-gan-of-the-week-b66d01e28200" rel="noopener follow" target="_blank"><div class="ni ab fo"><div class="nj ab nk cl cj nl"><h2 class="bd ir gy z fp nm fr fs nn fu fw ip bi translated">基于神经网络的音乐生成——本周 GAN</h2><div class="no l"><h3 class="bd b gy z fp nm fr fs nn fu fw dk translated">本周 GAN 是一系列关于生成模型的笔记，包括 GAN 和自动编码器。每周我都会复习一篇…</h3></div><div class="np l"><p class="bd b dl z fp nm fr fs nn fu fw dk translated">medium.com</p></div></div><div class="nq l"><div class="nz l ns nt nu nq nv kp nh"/></div></div></a></div><p id="f303" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated"><em class="mp">Emma Sheridan 和 Jessica Petersen 为人工神经网络课程完成的项目。这个项目的源代码可以在</em> <a class="ae kv" href="https://github.com/emmasheridan/ANNfinalproject\" rel="noopener ugc nofollow" target="_blank"> <em class="mp"> GitHub </em> </a> <em class="mp">上找到。</em></p></div></div>    
</body>
</html>