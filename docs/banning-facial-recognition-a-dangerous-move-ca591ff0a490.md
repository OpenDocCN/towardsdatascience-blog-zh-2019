# 禁止面部识别，这是一个危险的举动

> 原文：<https://towardsdatascience.com/banning-facial-recognition-a-dangerous-move-ca591ff0a490?source=collection_archive---------21----------------------->

![](img/5e3efb89787439f4b2e424acb891b928.png)

Wedjat Eye Amulet ca. 1070–664 B.C.

## 随着人们开始害怕面部识别，我们应该后退一步，重新评估这项技术和我们的选择。

> 为了透明起见，我认为我有责任声明我在计算机视觉行业工作。我不是用这篇文章来推动一家公司的议程或试图保住我的工作，而是为一个备受批评和误解的领域提供背景。

这是真的，谈论使用人工智能来调查城市会让人想起乔治·奥威尔警告过的反面乌托邦。知道某些政府如何利用这种技术并不能带来安慰。在过去的几个月里，人们一直在努力遏制计算机视觉的滥用。旧金山通过立法禁止市政当局使用面部识别技术。众议员奥卡西奥-科尔特斯在与算法正义联盟创始人的[听证会](https://www.huffpost.com/entry/ocasio-cortez-facial-recognition-technology_n_5ce5d3a3e4b0db9c29929f86)上指出了一些担忧。最近， [Buzzfeed 发布了一篇夸张的文章](https://www.buzzfeednews.com/article/evangreer/dont-regulate-facial-recognition-ban-it)，要求彻底禁止所有面部识别技术。

面部识别技术是一个难以置信的新生领域。第一篇描述面部识别工作方法的论文发表于 [1987 年](https://en.wikipedia.org/wiki/Eigenface)，而 celeritous detection 发表于 [2001 年](https://www.cs.cmu.edu/~efros/courses/LBMV07/Papers/viola-cvpr-01.pdf)。然而，这项技术在专利申请方面已经取得了长足的进步。Google 相册能够按照特定的人([和狗)对你的照片进行分类！](https://www.theverge.com/2017/10/16/16483542/google-photos-recognize-pets))。脸书最近的照片崩溃事件显示了它识别照片中的人和情感的能力。

虽然这可能看起来令人印象深刻，甚至具有威胁性，但认识到面部识别的依赖性和局限性很重要。此外，像许多技术一样，我们应该承认总会有人滥用技术。这并不意味着这项技术没有善意的应用。

任何人工智能、机器学习或其他可怕的技术术语都是数学的应用。面部识别也没什么不同。该主题实现了线性代数和统计，以实现特定的目标。有多种方法用于实现面部检测，但一种基本方法涉及拍摄大量面部图像并将其提供给“训练者”。培训师确定图像和化妆之间哪些特征是相似的，我们认为什么是脸。这些不是我们想象中的特征，比如鼻子、嘴巴、两只眼睛等等。计算机不知道鼻子是什么。不，这些要素由一组离散的边、线、点和空间组成。从一个足够大和多样化的数据集中，这个训练器可以创建一个数学表达式。该表达式可以基于已经提取的特征在新图像上产生置信度得分。然后，外部用户可以声明他们认为能够证明成功结果的置信度分数。

这是一种简单的方法，更快、更精确的方法已经被开发出来。然而，它们的基本前提是相同的。这些算法依赖于大量的数据才能成功，它们产生的是置信度得分，而不是绝对答案。

这种方法有一个明显的问题。如果使用的数据集有明显的偏差，那么异常值将会引起问题。偏差会影响整个系统。其次，如果出现对置信度得分的误解，单个病例可能会被错误地处理。

这正是刑事调查案件中发生的情况。算法的设计者并没有天生地构建系统来选择某些少数群体、肤色或性别。一个更可能的解释是在训练阶段使用了同质数据集。如果数据集中使用的大多数人脸是年龄在 20 到 30 岁之间的白人男性，那么任何其他人脸都将被视为异常值，并报告有缺陷的置信度得分。在繁重的工程期限内，可能很难积累一个稳健的数据集，其中包含人口的现实代表。

报告的分数是误差的第二个来源。引入了第二层人为错误。如果向用户报告的结果没有置信度得分，那么解释器就没有其他信息可以采取行动。从工程角度来看，这是一个糟糕的设计。或者，如果产生了置信度得分，用户可能不理解置信度得分是如何得到的。这两个问题很可能是由于工程师、项目经理、销售人员和营销人员之间的沟通不畅而引起的。在这个分销链的某个地方，细节被忽略，最终用户对此一无所知。

已经提出了解决这些问题的规则。数据政策中的一些人提议公布数据。如果一个算法使用未知信息来得出结论，也许它的用户应该了解先验信息。科技公司会抱怨这破坏了竞争优势。

另一个解决方案是建立信心报告的标准。可以实施这样的法律，即算法本身不能基于某些置信度做出决定。他们可以向用户报告指标，但仍然给人以权威。这类法规将为科技公司创造更高的标准。这些法律可能适用于高风险场景，如刑事和国防，但不应普遍适用。某些令人兴奋的技术，如自动驾驶汽车，是建立在基于信心得分做出决策的基础上的。

## 规范智能

综上所述，讨论一下为什么完全禁止这种新生技术是危险的是很重要的。在过去，我们在技术的早期阶段就将其妖魔化并加以惩罚，这是我们今天要付出的代价。核能就是一个最好的例子。核技术因其在武器上的应用而声名狼藉，这是理所当然的。切尔诺贝利和福岛事故也无济于事。然而，在当今时代，核能实际上可能是我们减少化石燃料消耗和扭转气候变化影响的最佳机会。不幸的是，提出这样的技术已经成为政治自杀，现在被忽视。

联邦对大麻的驱逐是另一个例子。在极少进行研究的情况下，该药物在美国被宣布为非法。我们现在正在了解该药物的一些健康益处，但合法化和进展遭到了怀疑的反对。

如果我们在面部识别技术上鲁莽行事，我们不知道我们正在摧毁哪个科学和研究领域。也许有一些医学应用将有助于识别面部瑕疵和异常值，否则无法检测出来。一些公司正在车内实施面部识别系统，以提高驾驶员的注意力和安全性。这个领域仍未被充分开发。

禁止一项技术不仅从科学好奇心的角度来看是危险的，从立法的角度来看也是危险的。当规章到位时，可以测试、检查实践，并且可以进一步编辑规章。可以发现并封闭循环孔。压迫性的限制可以重新评估。当一项彻底的禁令实施后，任何废除的企图都几乎是不可能的。