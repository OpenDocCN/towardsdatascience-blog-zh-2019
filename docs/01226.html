<html>
<head>
<title>Understand how your TensorFlow Model is Making Predictions</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">了解你的张量流模型是如何进行预测的</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/understand-how-your-tensorflow-model-is-making-predictions-d0b3c7e88500?source=collection_archive---------10-----------------------#2019-02-25">https://towardsdatascience.com/understand-how-your-tensorflow-model-is-making-predictions-d0b3c7e88500?source=collection_archive---------10-----------------------#2019-02-25</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="0429" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">与 SHAP 一起探索学生贷款数据</h2></div><h1 id="2edf" class="ki kj it bd kk kl km kn ko kp kq kr ks jz kt ka ku kc kv kd kw kf kx kg ky kz bi translated">介绍</h1><p id="bbad" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">机器学习可以比以往更快更准确地回答问题。随着机器学习在更多任务关键型应用中的使用，理解这些预测是如何得出的变得越来越重要。</p><p id="fd38" class="pw-post-body-paragraph la lb it lc b ld lw ju lf lg lx jx li lj ly ll lm ln lz lp lq lr ma lt lu lv im bi translated">在这篇博文中，我们将使用来自<a class="ae mb" href="https://www.tensorflow.org/" rel="noopener ugc nofollow" target="_blank"> TensorFlow </a>的 Keras API 构建一个神经网络模型，这是一个开源的机器学习框架。一旦我们的模型被训练，我们将把它与可解释性库<a class="ae mb" href="https://github.com/slundberg/shap" rel="noopener ugc nofollow" target="_blank"> SHAP </a>集成。我们将使用 SHAP 来了解哪些因素与模型预测相关。</p><figure class="md me mf mg gt mh gh gi paragraph-image"><div role="button" tabindex="0" class="mi mj di mk bf ml"><div class="gh gi mc"><img src="../Images/6ca0f6743b1ac62c95dcf5108842d3d8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*U8vytmtt9XKnNfv9keEFyg.jpeg"/></div></div></figure><h1 id="127a" class="ki kj it bd kk kl km kn ko kp kq kr ks jz kt ka ku kc kv kd kw kf kx kg ky kz bi translated">关于模型</h1><p id="7e15" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">我们的模型将预测大学毕业生相对于他们未来收入的毕业债务。这一债务收益比旨在作为一所大学投资回报(ROI)的粗略指标。这些数据来自美国教育部的<a class="ae mb" href="https://collegescorecard.ed.gov/" rel="noopener ugc nofollow" target="_blank">大学记分卡</a>，这是一个公开其数据的互动网站。</p><p id="3246" class="pw-post-body-paragraph la lb it lc b ld lw ju lf lg lx jx li lj ly ll lm ln lz lp lq lr ma lt lu lv im bi translated">下表列出了模型中的功能。关于数据集的更多细节可以在<a class="ae mb" href="https://collegescorecard.ed.gov/data/documentation/" rel="noopener ugc nofollow" target="_blank">数据文档</a>中找到。</p><pre class="md me mf mg gt mo mp mq mr aw ms bi"><span id="6a30" class="mt kj it mp b gy mu mv l mw mx">+-------------------------+--------------------------------------+<br/>|         Feature         |             Description              |<br/>+-------------------------+--------------------------------------+<br/>| ADM_RATE                | Admission rate                       |<br/>| SAT_AVG                 | SAT average                          |<br/>| TRANS_4                 | Transfer rate                        |<br/>| NPT4                    | Net price (list price - average aid) |<br/>| INC_N                   | Family income                        |<br/>| PUBLIC                  | Public institution                   |<br/>| UGDS                    | Number of undergraduate students     |<br/>| PPTUG_EF                | % part-time students                 |<br/>| FIRST_GEN               | % first-generation students          |<br/>| MD_INC_COMP_ORIG_YR4_RT | % completed within 4 years           |<br/>+-------------------------+--------------------------------------+</span></pre><p id="c1c0" class="pw-post-body-paragraph la lb it lc b ld lw ju lf lg lx jx li lj ly ll lm ln lz lp lq lr ma lt lu lv im bi translated">我们从数据集中可用的债务和收益数据中推导出目标变量(债务收益比)。具体来说，就是毕业时积累的债务中位数(<code class="fe my mz na mp b">MD_INC_DEBT_MDN</code>)，除以毕业后 6 年的平均收入(<code class="fe my mz na mp b">MN_EARN_WNE_INC2_P6</code>)。</p><p id="c6d0" class="pw-post-body-paragraph la lb it lc b ld lw ju lf lg lx jx li lj ly ll lm ln lz lp lq lr ma lt lu lv im bi translated">创建散点图是为了可视化每个特征与我们的目标变量的相关性。下面的每张图表在 X 轴上显示特征，在 Y 轴上显示债务/收益比率。</p><figure class="md me mf mg gt mh gh gi paragraph-image"><div role="button" tabindex="0" class="mi mj di mk bf ml"><div class="gh gi nb"><img src="../Images/49c0a8479453836d695c9bc2576522ad.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*09_dzS7KYE4W1SR-"/></div></div></figure><p id="16ab" class="pw-post-body-paragraph la lb it lc b ld lw ju lf lg lx jx li lj ly ll lm ln lz lp lq lr ma lt lu lv im bi translated">我们将使用一个<code class="fe my mz na mp b">Sequential</code>模型，有两个密集连接的隐藏层和一个 ReLU 激活函数:</p><pre class="md me mf mg gt mo mp mq mr aw ms bi"><span id="a149" class="mt kj it mp b gy mu mv l mw mx">model = keras.Sequential([<br/>    layers.Dense(16, activation=tf.nn.relu, input_shape=[len(df.keys())]),<br/>    layers.Dense(16, activation=tf.nn.relu),<br/>    layers.Dense(1)</span></pre><p id="a6d2" class="pw-post-body-paragraph la lb it lc b ld lw ju lf lg lx jx li lj ly ll lm ln lz lp lq lr ma lt lu lv im bi translated">下面我们看到一个训练过程的图表。训练误差和验证误差之间的差距越来越大，这表明有些过度拟合。过度拟合很可能是由于数据集中具有所有所需特征的样本数量有限(1，117 个)。尽管如此，考虑到平均债务收益比大约为 0.45，0.1 的平均绝对误差证明了一个有意义的预测。</p><figure class="md me mf mg gt mh gh gi paragraph-image"><div class="gh gi nc"><img src="../Images/f6aea6bc54faf476bd0d78688b7d8e3c.png" data-original-src="https://miro.medium.com/v2/resize:fit:790/format:webp/1*WUvp_cqvII2IH0FwXN1Yvg.png"/></div></figure><p id="6119" class="pw-post-body-paragraph la lb it lc b ld lw ju lf lg lx jx li lj ly ll lm ln lz lp lq lr ma lt lu lv im bi translated">要在浏览器中直接运行笔记本，您可以使用<a class="ae mb" href="https://colab.research.google.com/github/kweinmeister/notebooks/blob/master/tensorflow-shap-college-debt.ipynb" rel="noopener ugc nofollow" target="_blank"> Colab </a>。在<a class="ae mb" href="https://github.com/kweinmeister/notebooks/blob/master/tensorflow-shap-college-debt.ipynb" rel="noopener ugc nofollow" target="_blank"> Github </a>中也有。</p><h1 id="ed6d" class="ki kj it bd kk kl km kn ko kp kq kr ks jz kt ka ku kc kv kd kw kf kx kg ky kz bi translated">关于 ML 公平的一句话</h1><p id="d010" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">我们在这篇博文中调查的大学债务问题与更广泛的社会经济问题有着密切的联系。应该仔细评估任何模型及其训练数据，以确保它公平地服务于所有用户。例如，如果我们的训练数据主要包括来自高收入家庭的学生就读的学校，那么模型的预测将会歪曲那些学生通常有许多学生贷款的学校。</p><p id="e216" class="pw-post-body-paragraph la lb it lc b ld lw ju lf lg lx jx li lj ly ll lm ln lz lp lq lr ma lt lu lv im bi translated">在可能的情况下，对中等收入学生的数据值进行了过滤，以便对不同家庭收入水平的学生进行一致的分析。大学记分卡数据将中等收入阶层定义为家庭收入在 3 万美元至 7.5 万美元之间的学生。并非所有可用的数据都提供此过滤器，但它可用于净价、收益、债务和完成率等关键功能。</p><p id="682a" class="pw-post-body-paragraph la lb it lc b ld lw ju lf lg lx jx li lj ly ll lm ln lz lp lq lr ma lt lu lv im bi translated">记住这个思考过程，分析可以进一步扩展到数据集中的其他方面。同样值得注意的是，可解释性揭示了哪些特征对模型的预测贡献最大。它并不表明特征和预测之间是否存在因果关系。</p><h1 id="f701" class="ki kj it bd kk kl km kn ko kp kq kr ks jz kt ka ku kc kv kd kw kf kx kg ky kz bi translated">SHAP 简介</h1><p id="9eaa" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">可解释性本质上是理解模型中正在发生的事情的能力。通常在模型的准确性和可解释性之间有一个折衷。简单的线性模型易于理解，因为它们直接暴露了变量和系数。非线性模型，包括由神经网络或梯度增强树导出的模型，可能更难以解释。</p><p id="8455" class="pw-post-body-paragraph la lb it lc b ld lw ju lf lg lx jx li lj ly ll lm ln lz lp lq lr ma lt lu lv im bi translated">进入 SHAP。SHAP，或 SHapley Additive exPlanations，是由 Scott Lundberg 创建的 Python 库，可以解释许多机器学习框架的输出。它有助于解释单个预测或汇总更大人群的预测。</p><p id="8224" class="pw-post-body-paragraph la lb it lc b ld lw ju lf lg lx jx li lj ly ll lm ln lz lp lq lr ma lt lu lv im bi translated">SHAP 通过干扰输入数据来评估每个特征的影响。每个特征的贡献在所有可能的特征交互中被平均。这种方法是基于博弈论中 Shapley 值的概念。它提供了一种稳健的近似，相对于 LIME 等其他方法，这种近似在计算上可能更昂贵。关于 SHAP 理论的更多细节可以在图书馆作者的<a class="ae mb" href="http://papers.nips.cc/paper/7062-a-unified-approach-to-interpreting-model-predictions" rel="noopener ugc nofollow" target="_blank"> 2017 NeurIPS 论文</a>中找到。</p><h1 id="89f1" class="ki kj it bd kk kl km kn ko kp kq kr ks jz kt ka ku kc kv kd kw kf kx kg ky kz bi translated">将 SHAP 与张量流 Keras 模型结合使用</h1><p id="1de5" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">SHAP 提供了几个解释器类，它们使用不同的实现，但都利用了基于 Shapley 值的方法。在这篇博文中，我们将演示如何使用 KernelExplainer 和 DeepExplainer 类。KernelExplainer 与模型无关，因为它将模型预测和训练数据作为输入。DeepExplainer 针对深度学习框架(TensorFlow / Keras)进行了优化。</p><p id="9b05" class="pw-post-body-paragraph la lb it lc b ld lw ju lf lg lx jx li lj ly ll lm ln lz lp lq lr ma lt lu lv im bi translated">SHAP DeepExplainer 目前不支持急切执行模式或 TensorFlow 2.0。然而，KernelExplainer 将工作得很好，尽管它明显慢了很多。</p><p id="8db6" class="pw-post-body-paragraph la lb it lc b ld lw ju lf lg lx jx li lj ly ll lm ln lz lp lq lr ma lt lu lv im bi translated">让我们从使用 KernelExplainer 绘制模型的概要图开始。我们将首先把训练数据总结成<em class="nd"> n </em>个集群。这是一个可选但有用的步骤，因为生成 Shapley 值的时间会随着数据集的大小呈指数增长。</p><pre class="md me mf mg gt mo mp mq mr aw ms bi"><span id="1444" class="mt kj it mp b gy mu mv l mw mx"># Summarize the training set to accelerate analysis<br/>df_train_normed_summary = shap.kmeans(df_train_normed.values, 25)</span><span id="ba81" class="mt kj it mp b gy ne mv l mw mx"># Instantiate an explainer with the model predictions and training data summary<br/>explainer = shap.KernelExplainer(model.predict, df_train_normed_summary)</span><span id="d879" class="mt kj it mp b gy ne mv l mw mx"># Extract Shapley values from the explainer<br/>shap_values = explainer.shap_values(df_train_normed.values)</span><span id="fd30" class="mt kj it mp b gy ne mv l mw mx"># Summarize the Shapley values in a plot<br/>shap.summary_plot(shap_values[0], df_train_normed)</span></pre><p id="6dc6" class="pw-post-body-paragraph la lb it lc b ld lw ju lf lg lx jx li lj ly ll lm ln lz lp lq lr ma lt lu lv im bi translated">摘要图显示了每个要素的 Shapley 值分布。每个点的颜色在光谱上，该特征的最高值是红色，最低值是蓝色。通过 Shapley 值的绝对值之和对特征进行排序。</p><p id="ab48" class="pw-post-body-paragraph la lb it lc b ld lw ju lf lg lx jx li lj ly ll lm ln lz lp lq lr ma lt lu lv im bi translated">我们从剧情来看一些关系。贡献度最高的前三个特征分别是<strong class="lc iu">SAT 平均分</strong>、<strong class="lc iu"> %第一代学生</strong>、<strong class="lc iu"> %非全日制招生</strong>。请注意，这些特征中的每一个都在右侧有显著的蓝点(低特征值),这里有正 SHAP 值。这告诉我们，这些特征的低值导致我们的模型预测高 DTE 比率。列表中的第四个特性<strong class="lc iu">净价</strong>具有相反的关系，其中净价越高，DTE 比率越高。</p><figure class="md me mf mg gt mh gh gi paragraph-image"><div class="gh gi nf"><img src="../Images/5fc51bd4d41c202b6289041ea772f40e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1306/format:webp/1*94lWPlaBwxPG3qFGVHtQjg.png"/></div></figure><p id="3415" class="pw-post-body-paragraph la lb it lc b ld lw ju lf lg lx jx li lj ly ll lm ln lz lp lq lr ma lt lu lv im bi translated">也可以使用<code class="fe my mz na mp b">force_plot()</code>函数解释一个特定的实例:</p><pre class="md me mf mg gt mo mp mq mr aw ms bi"><span id="4663" class="mt kj it mp b gy mu mv l mw mx"># Plot the SHAP values for one instance<br/>INSTANCE_NUM = 0</span><span id="8616" class="mt kj it mp b gy ne mv l mw mx">shap.force_plot(explainer.expected_value[0], shap_values[0][INSTANCE_NUM], df_train.iloc[INSTANCE_NUM,:])</span></pre><figure class="md me mf mg gt mh gh gi paragraph-image"><div role="button" tabindex="0" class="mi mj di mk bf ml"><div class="gh gi ng"><img src="../Images/84f101fdef86e2b859050b165c773ae9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ChMOef0y68nNLNYggnFbIw.png"/></div></div></figure><p id="43b3" class="pw-post-body-paragraph la lb it lc b ld lw ju lf lg lx jx li lj ly ll lm ln lz lp lq lr ma lt lu lv im bi translated">在这个特殊的例子中，大学的 SAT 平均分对其 0.53 的 DTE 预测贡献最大，推动其值更高。完成率(<code class="fe my mz na mp b">MD_INC_COMP_ORIG_YR4_RT</code>)是第二重要的特征，将预测值推低。还可以查看整个数据集或一部分<em class="nd"> n </em>实例中显示的一系列 SHAP 值，如下所示:</p><pre class="md me mf mg gt mo mp mq mr aw ms bi"><span id="b45e" class="mt kj it mp b gy mu mv l mw mx"># Plot the SHAP values for multiple instances<br/>NUM_ROWS = 10<br/>shap.force_plot(explainer.expected_value[0], shap_values[0][0:NUM_ROWS], df_train.iloc[0:NUM_ROWS])</span></pre><figure class="md me mf mg gt mh gh gi paragraph-image"><div role="button" tabindex="0" class="mi mj di mk bf ml"><div class="gh gi nh"><img src="../Images/c992340b223c547be3748869adf703a1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*NofQnq9AVDiIzX4mxIB7aw.png"/></div></div></figure><h1 id="62af" class="ki kj it bd kk kl km kn ko kp kq kr ks jz kt ka ku kc kv kd kw kf kx kg ky kz bi translated">注意相关的特征</h1><p id="ea2e" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">SHAP 将在相关变量间分割特征贡献。在为模型选择特征和分析特征重要性时，记住这一点很重要。让我们计算相关矩阵，看看我们会发现什么:</p><pre class="md me mf mg gt mo mp mq mr aw ms bi"><span id="23bb" class="mt kj it mp b gy mu mv l mw mx">corr = df.corr()<br/>sns.heatmap(corr)</span></pre><figure class="md me mf mg gt mh gh gi paragraph-image"><div class="gh gi ni"><img src="../Images/348322f6cd4f7963c761523827e78a4c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1020/format:webp/1*zs-Bu2WxGzP9YcyHcrixrQ.png"/></div></figure><p id="24a1" class="pw-post-body-paragraph la lb it lc b ld lw ju lf lg lx jx li lj ly ll lm ln lz lp lq lr ma lt lu lv im bi translated">让我们用相关矩阵交叉引用总结图中的前三个特征，看看哪些特征可能会被拆分:</p><ul class=""><li id="a9da" class="nj nk it lc b ld lw lg lx lj nl ln nm lr nn lv no np nq nr bi translated"><strong class="lc iu"> SAT 平均分</strong>与<strong class="lc iu">完成率</strong>呈正相关，与<strong class="lc iu">录取率</strong>和<strong class="lc iu">一代比呈负相关。</strong></li><li id="95e0" class="nj nk it lc b ld ns lg nt lj nu ln nv lr nw lv no np nq nr bi translated"><strong class="lc iu">一代比</strong>与<strong class="lc iu">兼职比</strong>相关，与<strong class="lc iu">完成率</strong>负相关。</li></ul><p id="201e" class="pw-post-body-paragraph la lb it lc b ld lw ju lf lg lx jx li lj ly ll lm ln lz lp lq lr ma lt lu lv im bi translated">几个相关的特征被分组在摘要图列表的顶部。值得关注的是榜单中排名靠后的<strong class="lc iu">完成率</strong>和<strong class="lc iu">录取率</strong>。</p><p id="5254" class="pw-post-body-paragraph la lb it lc b ld lw ju lf lg lx jx li lj ly ll lm ln lz lp lq lr ma lt lu lv im bi translated">SHAP 有一个<code class="fe my mz na mp b">dependence_plot()</code>功能，可以帮助揭示更多细节。比如我们来看看<strong class="lc iu">一代比</strong>和<strong class="lc iu">兼职比</strong>的相互作用。正如我们在汇总图中观察到的，我们可以看到<strong class="lc iu">第一代</strong>比率与其 Shapley 值呈负相关。依赖图还向我们显示，当大学的兼职学生比例较低时，相关性更强。</p><pre class="md me mf mg gt mo mp mq mr aw ms bi"><span id="f19c" class="mt kj it mp b gy mu mv l mw mx">shap.dependence_plot('FIRST_GEN', shap_values[0], df_train, interaction_index='PPTUG_EF')</span></pre><figure class="md me mf mg gt mh gh gi paragraph-image"><div class="gh gi nx"><img src="../Images/a6f3efd3cae56c71c67b2bbeec48af47.png" data-original-src="https://miro.medium.com/v2/resize:fit:978/format:webp/1*k4xIuZPsTCDoPOlFGg93Wg.png"/></div></figure><h1 id="c704" class="ki kj it bd kk kl km kn ko kp kq kr ks jz kt ka ku kc kv kd kw kf kx kg ky kz bi translated">结论</h1><p id="b48f" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">在这篇博文中，我们展示了如何用 SHAP 解释 tf.keras 模型。我们还回顾了如何使用 SHAP API 和几个 SHAP 绘图类型。最后，为了完整和准确的描述，我们讨论了关于公平性和相关变量的考虑。现在，您拥有了更好地了解 TensorFlow Keras 模型中发生的事情的工具！</p><p id="6ca9" class="pw-post-body-paragraph la lb it lc b ld lw ju lf lg lx jx li lj ly ll lm ln lz lp lq lr ma lt lu lv im bi translated">要了解我在这里介绍的更多信息，请查看以下资源:</p><ul class=""><li id="1966" class="nj nk it lc b ld lw lg lx lj nl ln nm lr nn lv no np nq nr bi translated"><a class="ae mb" href="https://colab.research.google.com/github/kweinmeister/notebooks/blob/master/tensorflow-shap-college-debt.ipynb" rel="noopener ugc nofollow" target="_blank"> Colab 笔记本</a>从浏览器运行模型</li><li id="a5ab" class="nj nk it lc b ld ns lg nt lj nu ln nv lr nw lv no np nq nr bi translated"><a class="ae mb" href="https://github.com/kweinmeister/notebooks/blob/master/tensorflow-shap-college-debt.ipynb" rel="noopener ugc nofollow" target="_blank"> GitHub 储存库</a>带笔记本</li><li id="564d" class="nj nk it lc b ld ns lg nt lj nu ln nv lr nw lv no np nq nr bi translated">【tf.keras 入门</li><li id="fef7" class="nj nk it lc b ld ns lg nt lj nu ln nv lr nw lv no np nq nr bi translated"><a class="ae mb" href="https://github.com/slundberg/shap" rel="noopener ugc nofollow" target="_blank"> SHAP GitHub 库</a></li></ul><p id="2f9e" class="pw-post-body-paragraph la lb it lc b ld lw ju lf lg lx jx li lj ly ll lm ln lz lp lq lr ma lt lu lv im bi translated">在<a class="ae mb" href="https://twitter.com/kweinmeister" rel="noopener ugc nofollow" target="_blank">推特</a>上让我知道你的想法！</p></div></div>    
</body>
</html>