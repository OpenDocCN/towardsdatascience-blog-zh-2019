<html>
<head>
<title>The Ethical and Privacy Issues of Recommendation Engines on Media Platforms</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">媒体平台推荐引擎的伦理和隐私问题</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/the-ethical-and-privacy-issues-of-recommendation-engines-on-media-platforms-9bea7bcb0abc?source=collection_archive---------8-----------------------#2019-04-24">https://towardsdatascience.com/the-ethical-and-privacy-issues-of-recommendation-engines-on-media-platforms-9bea7bcb0abc?source=collection_archive---------8-----------------------#2019-04-24</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><figure class="is it gp gr iu iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi ir"><img src="../Images/5b38420bb5bfab0441292e269d1b1d51.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*uaNMz6gnpeUGb7Hc"/></div></div><figcaption class="jc jd gj gh gi je jf bd b be z dk">Photo by <a class="ae jg" href="https://unsplash.com/@jenskreuter?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Jens Kreuter</a> on <a class="ae jg" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><h2 id="c183" class="jh ji jj bd b dl jk jl jm jn jo jp dk jq translated" aria-label="kicker paragraph"><a class="ae ep" href="https://medium.com/towards-data-science/data-science-in-the-real-world/home" rel="noopener">现实世界中的数据科学</a></h2><div class=""/><div class=""><h2 id="f529" class="pw-subtitle-paragraph kp js jj bd b kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg dk translated">为什么我们应该更加关注提供内容的系统。</h2></div><p id="d0a5" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">媒体平台上的推荐引擎正在主导我们的媒体决策。不是让沙发冲浪的随机性决定我们的观看命运，而是在所有形式的数字媒体中为我们做出选择，包括 YouTube、脸书、Spotify 等。根据<a class="ae jg" href="https://www.mckinsey.com/industries/retail/our-insights/how-retailers-can-keep-up-with-consumers" rel="noopener ugc nofollow" target="_blank">麦肯锡的一份报告</a>，75%的网飞观看决定来自产品推荐。</p><p id="1b2d" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">虽然从表面上看，这等同于用户便利，因为系统推荐的东西与它收集的数据一致，以创建用户兴趣的简档，但实际上，推荐系统的统治掩盖了道德和隐私问题。</p><h1 id="6a09" class="md me jj bd mf mg mh mi mj mk ml mm mn ky mo kz mp lb mq lc mr le ms lf mt mu bi translated"><strong class="ak">伦理问题#1:成瘾</strong></h1><p id="5171" class="pw-post-body-paragraph lh li jj lj b lk mv kt lm ln mw kw lp lq mx ls lt lu my lw lx ly mz ma mb mc im bi translated">推荐系统中的一个伦理问题是，它们被创造出来是为了让人上瘾。他们的目的是在长时间内抓住并保持用户的兴趣。以 YouTube 和网飞上的自动播放功能为例。两者都提供根据你的资料定制的内容，并自动播放以吸引你。</p><p id="b86b" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">这有什么伦理上的两难呢？这难道不是在新的注意力经济中生存的一种方式吗？乍一看，也许是这样。但是，当这些全球性公司利用人类心理来创造一种令人上瘾的产品时，该怎么办呢，正如脸书创始人肖恩·帕克在接受 Axios 采访时承认的那样:</p><blockquote class="na nb nc"><p id="7380" class="lh li nd lj b lk ll kt lm ln lo kw lp ne lr ls lt nf lv lw lx ng lz ma mb mc im bi translated">“构建这些应用程序的思维过程，脸书是第一个，……都是关于:‘我们如何尽可能多地消耗你的时间和有意识的注意力。’"</p></blockquote><p id="12cd" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">斯坦福大学教授 Nir Eyal 写了一本关于设计成瘾产品的书，他呼吁建立新的道德标准。埃亚尔说，不同的说服技巧可能是合乎道德的，这取决于具体情况；例如，在 Duolingo 上使用“条纹”来鼓励人们学习一门新语言可能看起来可以接受，而 SnapChat 的“条纹”旨在让青少年强制检查该应用程序，这可能处于道德灰色地带，这使它成为一个复杂的问题。因此，他假设，如果平台让用户做他们不想做的事情，那就不再是简单的说服了，而是强迫。</p><p id="0725" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">虽然这可能是 SnapChat 和脸书等应用程序中的一个更大的问题，但这仍然与推荐引擎有关，因为它们通常是为了吸引和保持观众的注意力而构建的。网飞的《你还在看吗其他应用程序也应该使用该功能，比如 YouTube。</p><h1 id="7216" class="md me jj bd mf mg mh mi mj mk ml mm mn ky mo kz mp lb mq lc mr le ms lf mt mu bi translated"><strong class="ak">道德问题#2:极端内容=观众的注意力，但代价是什么</strong></h1><p id="24ae" class="pw-post-body-paragraph lh li jj lj b lk mv kt lm ln mw kw lp lq mx ls lt lu my lw lx ly mz ma mb mc im bi translated">吸引和保持用户注意力的斗争导致了另一个关于推荐引擎的关键道德问题:提供的内容可能实际上不符合用户的最佳利益，并导致两极分化。正如 Renee Diresta 在<a class="ae jg" href="https://www.wired.com/story/creating-ethical-recommendation-engines/" rel="noopener ugc nofollow" target="_blank">连线</a>中所说，推荐系统被“打破”并成为“伟大的票贩子”</p><p id="f014" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">例如，在 YouTube 上，该算法往往会提供越来越激进的内容，让你继续观看，以便谷歌可以从广告中赚更多的钱。正如 Zeynep Tufekci 在<a class="ae jg" href="https://www.nytimes.com/2018/03/10/opinion/sunday/youtube-politics-radical.html" rel="noopener ugc nofollow" target="_blank">纽约时报</a>中所说，</p><blockquote class="na nb nc"><p id="28ab" class="lh li nd lj b lk ll kt lm ln lo kw lp ne lr ls lt nf lv lw lx ng lz ma mb mc im bi translated">" YouTube 将观众引入极端主义的兔子洞，而谷歌则提升了广告销售额."</p></blockquote><p id="9484" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">Tufekci 发现，无论你开始观看稍微自由或保守的领先视频，YouTube 最终都会建议越来越激进的内容，包括至上主义和阴谋论视频。即使是非政治性的视频，比如关于素食主义的视频，也会引出关于素食主义的视频来吸引用户。</p><p id="fdbe" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">Tufekci 最终将 YouTube 与快餐店联系起来:提供大量含糖、含盐的食物，让我们即使已经吃饱了也想继续吃。</p><p id="65de" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">对于谷歌的工程师来说，这是一个道德问题，因为他们知道人们去 YouTube 获取各种主题的信息，而算法最终会让人们观看不正确、激进、极端的视频。</p><p id="191f" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">内容创作者也受到影响，<a class="ae jg" href="https://medium.com/@guillaumechaslot/how-algorithms-can-learn-to-discredit-the-media-d1360157c4fa" rel="noopener">Guillaume Chaslot</a>写道，他是前谷歌工程师，曾批评 YouTube 算法的道德。由于越来越激进的内容表现良好，创作者受到激励，创建煽动性的视频和帖子，以吸引眼球。</p><blockquote class="na nb nc"><p id="46f2" class="lh li nd lj b lk ll kt lm ln lo kw lp ne lr ls lt nf lv lw lx ng lz ma mb mc im bi translated">“人工智能本身还没有制造假新闻，并对媒体发动战争，但它正在激励内容创作者和公众人物这样做。”</p></blockquote><p id="f12f" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">推荐系统导致内容越来越激进的问题不仅限于 YouTube 的算法。据 BuzzFeed 新闻报道，脸书正在考虑改变其新闻推送推荐系统，以更多地推广脸书群体，这可能是一个错误，因为这些群体可能会变成极端主义的缩影。</p><p id="bfa8" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">安全研究员 Renne DiResta 告诉 BuzzFeed 新闻，团体已经成为坏人的目标:</p><blockquote class="na nb nc"><p id="f09b" class="lh li nd lj b lk ll kt lm ln lo kw lp ne lr ls lt nf lv lw lx ng lz ma mb mc im bi translated">“宣传者和垃圾邮件发送者需要聚集一批观众，而各种团体则为他们提供服务。如果你可以简单地加入相关团体并开始发帖，就没有必要进行广告宣传来寻找接受你信息的人。”</p></blockquote><p id="4895" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">脸书改变算法，更多地关注群体，而不是更少，这是一个道德灰色地带。一方面，人们更多地在群里发帖，因此，抓住更多人的注意力，对其平台的表现来说是有意义的。另一方面，知道坏演员经常专门利用群体——BuzzFeed 新闻也指出，俄罗斯黑客反复引用脸书群体作为焦点——表明脸书可能正在帮助用户更容易受到这些坏影响。</p><p id="bd4c" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">Diresta 提出了一些缓解这个问题的方法。第一个是创建一个推荐问题，将人们引向相反的方向——指向旨在消除观众激进情绪的内容。让用户对他们的算法过滤有更多的控制权是另一个选择。比如在 Twitter 上，你可以过滤掉低质量账号的内容。</p><p id="2a7d" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">另一个选择是让算法考虑内容质量的来源，这样低质量的内容就不会被推荐。这将“推动”用户转向更高质量的内容，Diresta 将其比作午餐食品系列中的苹果而不是薯片。</p><p id="42cf" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">据<a class="ae jg" href="https://www.nbcnews.com/tech/social-media/algorithms-take-over-youtube-s-recommendations-highlight-human-problem-n867596" rel="noopener ugc nofollow" target="_blank"> NBC 新闻</a>报道，YouTube 发言人表示，他们已经将算法转移到关注“满意度”而不是“观看时间”，因此评论、喜欢、不喜欢、分享和调查都被考虑在内。算法已被更改，以更多地包含视频源的权限。</p><h1 id="b48c" class="md me jj bd mf mg mh mi mj mk ml mm mn ky mo kz mp lb mq lc mr le ms lf mt mu bi translated"><strong class="ak">隐私问题:个人数据收集</strong></h1><p id="1ba5" class="pw-post-body-paragraph lh li jj lj b lk mv kt lm ln mw kw lp lq mx ls lt lu my lw lx ly mz ma mb mc im bi translated">个性化推荐通常需要收集个人数据进行分析，这可能会使用户容易受到隐私侵犯问题的影响。根据发表在 Engineering 上的一篇<a class="ae jg" href="https://www.sciencedirect.com/science/article/pii/S2095809917303855" rel="noopener ugc nofollow" target="_blank"> 2018 年研究论文，这些数据“不良地向推荐者披露了用户的个人兴趣。“此外，数据可以在未经用户同意的情况下出售给第三方。以脸书/剑桥分析公司丑闻为例。第三个隐私问题是，平台可能被黑客攻击，用户的个人数据可能被泄露，这已经在脸书(和其他平台)发生过几次。</a></p><p id="7f38" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">平台必须制定隐私保护措施，以避免此类侵权行为。2018 年的研究论文建议使用加密和随机化技术来保护和保存私人数据。与这些方法相呼应的是用户分组，它根据相似的特征对成员进行分组，并删除个人识别数据。这样，在不牺牲用户隐私的情况下，对平台和广告商来说重要的特征得以保留。</p><h1 id="7f16" class="md me jj bd mf mg mh mi mj mk ml mm mn ky mo kz mp lb mq lc mr le ms lf mt mu bi translated"><strong class="ak">推荐引擎:主宰媒体的未来</strong></h1><p id="5f57" class="pw-post-body-paragraph lh li jj lj b lk mv kt lm ln mw kw lp lq mx ls lt lu my lw lx ly mz ma mb mc im bi translated">随着媒体领域越来越被社交媒体和流媒体平台所主导，形成推荐系统的算法在人们观看的内容中发挥着巨大的作用。这些系统的创造者需要理解和减轻威胁消费者的道德和隐私问题。</p></div></div>    
</body>
</html>