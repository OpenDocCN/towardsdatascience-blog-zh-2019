<html>
<head>
<title>A Gold-Winning Solution Review of Kaggle Humpback Whale Identification Challenge</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">Kaggle 座头鲸识别挑战的金牌解决方案综述</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/a-gold-winning-solution-review-of-kaggle-humpback-whale-identification-challenge-53b0e3ba1e84?source=collection_archive---------14-----------------------#2019-03-04">https://towardsdatascience.com/a-gold-winning-solution-review-of-kaggle-humpback-whale-identification-challenge-53b0e3ba1e84?source=collection_archive---------14-----------------------#2019-03-04</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="d715" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">对最引人注目的方法的广泛而简单的回顾</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/ec4ef01dfbe8f8f7fc5539270c9d417d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*eX9ExTbkDCpEPFVG"/></div></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk">Photo by <a class="ae ky" href="https://unsplash.com/@seitamaaphotography?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Sandra Seitamaa</a> on <a class="ae ky" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><p id="f5c8" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">最近，我的团队参加了在 Kaggle 举办的<a class="ae ky" href="https://www.kaggle.com/c/humpback-whale-identification/leaderboard" rel="noopener ugc nofollow" target="_blank">座头鲸识别挑战赛</a>。我们赢得了一枚金牌，并在排行榜上(在 2131 支队伍中)名列第十。</p><p id="bb79" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在这篇博文中，我将总结我们解决方案的主要思想，并简要概述其他团队使用的有趣且吸引人的方法。</p></div><div class="ab cl lv lw hx lx" role="separator"><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma"/></div><div class="im in io ip iq"><h1 id="9760" class="mc md it bd me mf mg mh mi mj mk ml mm jz mn ka mo kc mp kd mq kf mr kg ms mt bi translated">问题描述</h1><p id="06b6" class="pw-post-body-paragraph kz la it lb b lc mu ju le lf mv jx lh li mw lk ll lm mx lo lp lq my ls lt lu im bi translated">主要目标是确定，给定的这张鲸侥幸的照片是属于 5004 种已知鲸鱼个体中的一种，还是一种以前从未观察到的<em class="mz">新鲸鱼</em>。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi na"><img src="../Images/bfc4ce747c3c3eb64f3640503a02952d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*c9JmA_7A7742kM777M2t7A.png"/></div></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk">Example of 9 photos of the same whale from the training data</figcaption></figure><p id="94ba" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这场竞赛令人困惑的一面是巨大的阶级不平衡。对于 2000 多个班级，只有一个训练样本<strong class="lb iu">，这使得很难使用开箱即用的分类方法。更重要的是，对鲸鱼是否是新品种进行分类是比赛的重要组成部分，这被证明是相当重要的。</strong></p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nb"><img src="../Images/e4eeda52459acd9588065046bfa2142c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*JlgQt4Hq3OtV7A5QrrGH6w.png"/></div></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk">Class Imbalance, from kernel by <br/><a class="ae ky" href="https://www.kaggle.com/kretes" rel="noopener ugc nofollow" target="_blank">Tomasz Bartczak</a></figcaption></figure><p id="db61" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">比赛的衡量标准是<a class="ae ky" href="https://medium.com/@jonathan_hui/map-mean-average-precision-for-object-detection-45c121a31173" rel="noopener"> mAP@5 </a>(平均精度为 5)，这允许我们为每张测试图像提交多达 5 个预测。我们在私有测试集上的最高成绩是<strong class="lb iu"> 0.959 </strong> mAP@5。</p><h1 id="baba" class="mc md it bd me mf nc mh mi mj nd ml mm jz ne ka mo kc nf kd mq kf ng kg ms mt bi translated">萨纳科耶乌，普莱斯科夫，沙克雷💪</h1><p id="9e4f" class="pw-post-body-paragraph kz la it lb b lc mu ju le lf mv jx lh li mw lk ll lm mx lo lp lq my ls lt lu im bi translated">该团队由海德堡大学博士生<a class="ae ky" href="https://www.linkedin.com/in/vladislav-shakhray-74b98315b/" rel="noopener ugc nofollow" target="_blank">弗拉迪斯拉夫·沙克雷</a>(我)<a class="ae ky" href="https://asanakoy.github.io" rel="noopener ugc nofollow" target="_blank">阿奇奥姆·萨纳科耶乌</a>和 Kaggle Top-5 特级大师<a class="ae ky" href="https://www.linkedin.com/in/ppleskov/" rel="noopener ugc nofollow" target="_blank">帕维尔·普莱斯科夫</a>组成。</p><p id="e954" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">为了加快实验速度，我们在比赛中途加入了 Artsiom，Pavel 在团队合并截止日期前一周加入了我们。</p><h1 id="4922" class="mc md it bd me mf nc mh mi mj nd ml mm jz ne ka mo kc nf kd mq kf ng kg ms mt bi translated">验证和初始设置</h1><p id="7c68" class="pw-post-body-paragraph kz la it lb b lc mu ju le lf mv jx lh li mw lk ll lm mx lo lp lq my ls lt lu im bi translated">在这场比赛的几个月前，同一场比赛的<a class="ae ky" href="https://www.kaggle.com/c/whale-categorization-playground" rel="noopener ugc nofollow" target="_blank">游乐场版本</a>在 Kaggle 上举办，但是，正如比赛主办方<a class="ae ky" href="https://www.kaggle.com/c/humpback-whale-identification/discussion/73208" rel="noopener ugc nofollow" target="_blank">提到的</a>，真实(非游乐场)版本的特点是更多的数据和更干净的标签。我们决定以多种方式利用之前比赛的知识和数据:</p><ol class=""><li id="4e84" class="nh ni it lb b lc ld lf lg li nj lm nk lq nl lu nm nn no np bi translated">利用之前比赛的数据，我们使用<a class="ae ky" href="https://jenssegers.com/61/perceptual-image-hashes" rel="noopener ugc nofollow" target="_blank">图像哈希</a>收集了【2000 多个验证样本。后来，当我们验证我们的套装时，这被证明是至关重要的。</li><li id="c2a0" class="nh ni it lb b lc nq lf nr li ns lm nt lq nu lu nm nn no np bi translated">我们从训练数据集中删除了<em class="mz"> new_whale </em>类，因为它的元素之间不共享任何逻辑图像特性。</li><li id="7a92" class="nh ni it lb b lc nq lf nr li ns lm nt lq nu lu nm nn no np bi translated">有些图像根本没有对齐。幸运的是，有一个公开可用的预先训练的<strong class="lb iu">边界框</strong>模型，用于操场竞赛的获胜解决方案。我们用它来检测鲸鱼爪周围的精确边界框，并相应地裁剪图像。</li><li id="5305" class="nh ni it lb b lc nq lf nr li ns lm nt lq nu lu nm nn no np bi translated">由于图像的颜色不同，所有数据在训练前都被转换为<strong class="lb iu">灰度</strong>。</li></ol><h1 id="c221" class="mc md it bd me mf nc mh mi mj nd ml mm jz ne ka mo kc nf kd mq kf ng kg ms mt bi translated">方法 1:连体网络(Vladislav)</h1><p id="9339" class="pw-post-body-paragraph kz la it lb b lc mu ju le lf mv jx lh li mw lk ll lm mx lo lp lq my ls lt lu im bi translated">我们的第一个架构是一个暹罗网络，有许多分支架构和客户损耗，由许多卷积层和密集层组成。我们使用的分支架构包括:</p><ul class=""><li id="3e8d" class="nh ni it lb b lc ld lf lg li nj lm nk lq nl lu nv nn no np bi translated">ResNet-18，ResNet-34，Resnet-50</li><li id="e998" class="nh ni it lb b lc nq lf nr li ns lm nt lq nu lu nv nn no np bi translated">SE-ResNeXt-50</li><li id="2550" class="nh ni it lb b lc nq lf nr li ns lm nt lq nu lu nv nn no np bi translated">马丁·皮奥特公开分享的类 ResNet<a class="ae ky" href="https://www.kaggle.com/martinpiotte/whale-recognition-model-with-score-0-78563" rel="noopener ugc nofollow" target="_blank">自定义分支</a></li></ul><p id="8557" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们使用<strong class="lb iu">硬负</strong>以及<strong class="lb iu">硬正</strong>挖掘，通过每 4 个时期对分数矩阵求解线性分配问题。为了简化训练过程，在矩阵中加入了少量的随机化。</p><p id="838d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">采用渐进式学习</strong>，分辨率策略 229 x229-&gt;384 x384-&gt;512 x512。也就是说，我们首先在 229x229 图像上训练我们的网络，几乎没有正则化，学习率更大。收敛后，我们重置学习率并增加正则化，从而在更高分辨率(例如 384x484)的图像上再次训练网络。</p><p id="e732" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">此外，由于数据的性质，使用了大量的增强，包括随机亮度、高斯噪声、随机裁剪和随机模糊。</p><p id="ed86" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">此外，我们追求智能翻转增强策略，这大大有助于创建更多的训练数据。具体来说，对于属于<strong class="lb iu">同一</strong>鲸鱼<code class="fe nw nx ny nz b">X, Y</code>的每对训练图像，我们多创建了一对训练图像<code class="fe nw nx ny nz b">flip(X), flip(Y)</code>。另一方面，对于每一对<strong class="lb iu">不同的</strong>鲸鱼，我们又创造了三个例子<code class="fe nw nx ny nz b">flip(X), Y</code>、<code class="fe nw nx ny nz b">Y, flip(X)</code>和<code class="fe nw nx ny nz b">flip(X), flip(Y)</code>。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oa"><img src="../Images/cc26899cc42c154302db0d4f50a1c214.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*h19maqe74iviYhKng5krIg.png"/></div></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk">An example showing that random flips strategy does not work with a pair of same-whale photos. Notice how the lower photos become different when we flip one of the images since we care about fluke orientation.</figcaption></figure><p id="1847" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">使用 Adam optimizer 对模型进行优化，初始学习率为 1e-4，在平稳状态下减少了 5 倍。批量大小被设置为 64。</p><p id="3ee0" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">模型的来源写在<a class="ae ky" href="https://keras.io" rel="noopener ugc nofollow" target="_blank"> Keras </a>上。在单个 2080Ti 上训练约 400-600 个历元的模型需要 2-3 天(取决于图像分辨率)。</p><p id="7002" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">拥有 ResNet-50 的表现最好的单一模型得分<strong class="lb iu"> 0.929 磅。</strong></p><h1 id="720f" class="mc md it bd me mf nc mh mi mj nd ml mm jz ne ka mo kc nf kd mq kf ng kg ms mt bi translated">方法 2:度量学习(Artsiom)</h1><p id="d27e" class="pw-post-body-paragraph kz la it lb b lc mu ju le lf mv jx lh li mw lk ll lm mx lo lp lq my ls lt lu im bi translated">我们使用的另一种方法是利用<a class="ae ky" href="https://arxiv.org/abs/1706.07567" rel="noopener ugc nofollow" target="_blank">利润损失</a>的度量学习。我们使用了许多 ImageNet 预训练的主干架构，包括:</p><ul class=""><li id="ff4f" class="nh ni it lb b lc ld lf lg li nj lm nk lq nl lu nv nn no np bi translated">ResNet-50，ResNet-101，ResNet-152</li><li id="ea67" class="nh ni it lb b lc nq lf nr li ns lm nt lq nu lu nv nn no np bi translated">DenseNet-121、DenseNet-169</li></ul><p id="9d81" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">网络主要使用 448×448-&gt; 672×672 策略逐步训练。</p><p id="24ec" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们使用 Adam 优化器，在 100 个时期后将学习率降低 10 倍。我们还在整个培训中使用了 96 的批量大小。</p><p id="6b46" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">最有趣的部分是什么让我们立即获得了 2%的提升。这是一种度量学习方法，由 Sanakoyeu，Tschernezki 等人开发，并在 2019 年 CVPR 上发表。它所做的是每隔<code class="fe nw nx ny nz b">n</code>个时期就将训练数据和嵌入层分成<code class="fe nw nx ny nz b">k</code>个簇。在建立了训练组块和学习者之间的双射之后，该模型在累积分支网络的梯度的同时单独训练它们。你可以在这篇论文发表的时候在<a class="ae ky" href="https://github.com/CompVis/metric-learning-divide-and-conquer" rel="noopener ugc nofollow" target="_blank">这里</a>查看它和代码。</p><blockquote class="ob oc od"><p id="83fc" class="kz la mz lb b lc ld ju le lf lg jx lh oe lj lk ll of ln lo lp og lr ls lt lu im bi translated">“分而治之，嵌入度量学习空间”，Artsiom Sanakoyeu，Vadim Tschernezki，Uta Büchler，bjrn Ommer，CVPR，2019 年</p></blockquote><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oh"><img src="../Images/c4c46ab9d1763a4ac5edde9462ca13ce.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*wD03M6Qp_Rsp8u3Y5ptqPw.png"/></div></div></figure><p id="0be1" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">由于巨大的阶级不平衡，大量的<strong class="lb iu">增强</strong>被使用，其中包括随机翻转，旋转，缩放，模糊，照明，对比度，饱和度变化。在推断期间，计算查询特征向量和训练图库特征向量之间的点积，并且选择具有最高点积值的类作为前 1 个预测。另一个有助于解决类别不平衡的技巧是对属于相同鲸鱼 id 的训练图像的特征向量进行平均。</p><p id="83f7" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这些模型是使用<a class="ae ky" href="https://pytorch.org" rel="noopener ugc nofollow" target="_blank"> PyTorch </a>实现的，在一台 Titan Xp 上训练需要 2-4 天(取决于图像分辨率)。值得一提的是，采用 DenseNet-169 主干的性能最佳的单一型号的得分为<strong class="lb iu"> 0.931 磅。</strong></p><h1 id="d229" class="mc md it bd me mf nc mh mi mj nd ml mm jz ne ka mo kc nf kd mq kf ng kg ms mt bi translated">方法 3:特征分类(Artsiom)</h1><p id="fb9d" class="pw-post-body-paragraph kz la it lb b lc mu ju le lf mv jx lh li mw lk ll lm mx lo lp lq my ls lt lu im bi translated">当我和 Artsiom 联手时，我们做的第一件事就是使用从我们所有模型中提取的特征训练分类模型，并连接在一起(当然是在应用 PCA 之后)。</p><p id="8002" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">分类头由两个致密层组成，中间有脱落物。该模型训练非常快，因为我们使用预先计算的特征。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oi"><img src="../Images/187b21112b7697e7ae053ca1b683fa6b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*wqpfSc-koOGaGCP6WFgD_w.png"/></div></div></figure><p id="c4bf" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这种方法让我们获得了 0.924 磅，并带来了更多的整体多样性。</p><h1 id="d158" class="mc md it bd me mf nc mh mi mj nd ml mm jz ne ka mo kc nf kd mq kf ng kg ms mt bi translated">方法 4:新的鲸鱼分类(Pavel)</h1><p id="fba6" class="pw-post-body-paragraph kz la it lb b lc mu ju le lf mv jx lh li mw lk ll lm mx lo lp lq my ls lt lu im bi translated">这场比赛最复杂的部分之一是正确地对新鲸鱼进行分类(因为大约 30%的图像属于<em class="mz">新鲸鱼</em>类)。</p><p id="6bee" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">处理这个问题的流行策略是使用一个简单的阈值。也就是说，如果给定图像 X 属于某个已知的鲸类的最大概率小于阈值，则它被分类为<em class="mz">新鲸类</em>。然而，我们认为可能有更好的办法来解决这个问题。</p><p id="97c3" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">对于每个表现最好的模型和集合，我们取其前 4 个预测，按降序排列。然后，对于<em class="mz">每隔一个</em>模型，我们取它们在所选的 4 个类别中的概率。目的是根据这些特征来预测鲸鱼是否是新的。</p><p id="1b9a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">Pavel 创建了一个非常强大的对数回归、SVM、几个 k-NN 模型和 LightGBM 的混合体。在交叉验证中，所有数据的组合为我们提供了 0.9655 的 ROC-AUC，并增加了 2%的 LB 分数。</p><h1 id="d400" class="mc md it bd me mf nc mh mi mj nd ml mm jz ne ka mo kc nf kd mq kf ng kg ms mt bi translated">组装</h1><p id="dec8" class="pw-post-body-paragraph kz la it lb b lc mu ju le lf mv jx lh li mw lk ll lm mx lo lp lq my ls lt lu im bi translated">从我们的模型中构建整体绝对不是一件容易的事。事实是，我的模型的输出是一个非标准化概率矩阵(从 0 到 1)，而 Artsiom 提供的输出矩阵由欧几里德距离组成(因此范围从 0 到无穷大)。</p><p id="adab" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们尝试了多种方法将 Artsiom 的矩阵转换为概率，其中包括:</p><ul class=""><li id="e40a" class="nh ni it lb b lc ld lf lg li nj lm nk lq nl lu nv nn no np bi translated">类 t-SNE 变换:</li></ul><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi oj"><img src="../Images/e28741d51675ab004c72bfa6de5a621b.png" data-original-src="https://miro.medium.com/v2/resize:fit:654/format:webp/1*ECKvwpFt47wYezLDAjswZQ.png"/></div></figure><ul class=""><li id="f640" class="nh ni it lb b lc ld lf lg li nj lm nk lq nl lu nv nn no np bi translated">Softmax</li><li id="5431" class="nh ni it lb b lc nq lf nr li ns lm nt lq nu lu nv nn no np bi translated">通过应用功能<code class="fe nw nx ny nz b">1 / (1 + distances)</code>简单地反转范围</li><li id="a22a" class="nh ni it lb b lc nq lf nr li ns lm nt lq nu lu nv nn no np bi translated">许多其他函数来反转矩阵的范围</li></ul><p id="7895" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">不幸的是，前两种方法根本不起作用，虽然大多数情况下使用任意函数将范围裁剪为[0，1]，但结果大致相同。我们最终选择了这个函数，在验证集上选择了一个具有最高 mAP@5 的函数。</p><p id="8f1d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">令人惊讶的是，最好的一个是<code class="fe nw nx ny nz b">1 / (1 + log(1 + log(1 + distances)))</code>。</p><h1 id="583d" class="mc md it bd me mf nc mh mi mj nd ml mm jz ne ka mo kc nf kd mq kf ng kg ms mt bi translated">其他团队使用的方法</h1><h2 id="ec38" class="ok md it bd me ol om dn mi on oo dp mm li op oq mo lm or os mq lq ot ou ms ov bi translated">基于 SIFT 的</h2><p id="99a8" class="pw-post-body-paragraph kz la it lb b lc mu ju le lf mv jx lh li mw lk ll lm mx lo lp lq my ls lt lu im bi translated">我想概述一个解决方案，在我看来，它是最漂亮的解决方案之一，同时也是不寻常的。</p><p id="acdb" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">现在是 Kaggle 特级大师(排名 12)的 David 在私人 LB 排名第四，并在 Kaggle 讨论论坛上以<a class="ae ky" href="https://www.kaggle.com/c/humpback-whale-identification/discussion/82356" rel="noopener ugc nofollow" target="_blank">帖子</a>的形式分享了他的解决方案。</p><p id="3be2" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">他处理全分辨率图像，使用传统的<strong class="lb iu">关键点匹配</strong>技术，利用 SIFT 和 ROOTSIFT。为了处理假阳性，大卫训练了一个 U-Net 从背景中分割出鲸鱼。有趣的是，他使用 smart <strong class="lb iu">后处理</strong>给只有一个训练示例的类更多的机会进入前 1 预测。</p><p id="65d2" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们也想过尝试基于 SIFT 的方法，但我们确信它的性能肯定比顶级的神经网络差。</p><p id="c7d7" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在我看来，我们永远不应该被深度学习的力量所蒙蔽，低估传统方法的能力。</p><h2 id="bc65" class="ok md it bd me ol om dn mi on oo dp mm li op oq mo lm or os mq lq ot ou ms ov bi translated">纯分类</h2><p id="ee22" class="pw-post-body-paragraph kz la it lb b lc mu ju le lf mv jx lh li mw lk ll lm mx lo lp lq my ls lt lu im bi translated">由<a class="ae ky" href="https://medium.com/@ducha.aiki" rel="noopener"> Dmytro Mishkin </a>、<a class="ae ky" href="https://medium.com/@anastasiya.mishchuk" rel="noopener"> Anastasiia Mishchuk </a>和<a class="ae ky" href="https://www.linkedin.com/in/igor-krashenyi-38b89b98/" rel="noopener ugc nofollow" target="_blank"> Igor Krashenyi </a>组成的团队<em class="mz"> Pure Magic thanks radek </em>(第 7 名)采用了一种结合了度量学习(三重缺失)和分类的方法，正如 Dmytro 在他的<a class="ae ky" href="https://medium.com/@ducha.aiki/thanks-radek-7th-place-solution-to-hwi-2019-competition-738624e4c885" rel="noopener">帖子</a>中所描述的那样。</p><p id="6c67" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在长时间训练分类模型时，他们尝试使用<a class="ae ky" href="https://ydwen.github.io/papers/WenECCV16.pdf" rel="noopener ugc nofollow" target="_blank">中心损失</a>来减少过拟合，并在应用 softmax 之前使用<a class="ae ky" href="https://arxiv.org/pdf/1706.04599.pdf" rel="noopener ugc nofollow" target="_blank">温度缩放</a>。在使用的众多主干架构中，最好的是 SE-ResNeXt-50，它能够达到<strong class="lb iu"> 0.955 LB。</strong></p><p id="9e8a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">他们的解决方案远不止这些，我强烈建议你参考最初的<a class="ae ky" href="https://medium.com/@ducha.aiki/thanks-radek-7th-place-solution-to-hwi-2019-competition-738624e4c885" rel="noopener">帖子</a>。</p><h2 id="a15e" class="ok md it bd me ol om dn mi on oo dp mm li op oq mo lm or os mq lq ot ou ms ov bi translated">圆脸，圆脸</h2><p id="0fc8" class="pw-post-body-paragraph kz la it lb b lc mu ju le lf mv jx lh li mw lk ll lm mx lo lp lq my ls lt lu im bi translated">正如<a class="ae ky" href="https://www.kaggle.com/sawseen" rel="noopener ugc nofollow" target="_blank"> Ivan Sosin </a>在<a class="ae ky" href="https://www.kaggle.com/c/humpback-whale-identification/discussion/82427" rel="noopener ugc nofollow" target="_blank">帖子</a>中提到的(他的团队<em class="mz"> BratanNet </em>在这次比赛中获得第 9 名)，他们使用了<a class="ae ky" href="https://arxiv.org/abs/1801.09414" rel="noopener ugc nofollow" target="_blank"> CosFace </a>和<a class="ae ky" href="https://arxiv.org/abs/1801.07698" rel="noopener ugc nofollow" target="_blank"> ArcFace </a>方法。来自原帖:</p><blockquote class="ob oc od"><p id="8ff3" class="kz la mz lb b lc ld ju le lf lg jx lh oe lj lk ll of ln lo lp og lr ls lt lu im bi translated">其中，Cosface 和 Arcface 作为新发现的人脸识别任务的 SOTA 脱颖而出。主要思想是在余弦相似性空间中使相同类的例子彼此靠近，并拉开不同的类。用 cosface 或 arcface 训练一般是分类，所以最后损失的是交叉熵。</p></blockquote><p id="df2a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">当使用像 InceptionV3 或 SE-ResNeXt-50 这样的较大主干时，他们注意到过度拟合，因此他们转向像 ResNet-34、BN-Inception 和 DenseNet-121 这样的较轻网络。</p><p id="8427" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">该团队还使用了精心挑选的增强功能和众多网络修改技术，如<a class="ae ky" href="https://arxiv.org/abs/1807.03247" rel="noopener ugc nofollow" target="_blank"> CoordConv </a>和<a class="ae ky" href="https://openreview.net/forum?id=ryl5khRcKm" rel="noopener ugc nofollow" target="_blank"> GapNet </a>。</p><p id="3c1a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">他们的方法中特别有趣的是他们处理<em class="mz">new _ whale</em>s . From the original post 的方式:</p><blockquote class="ob oc od"><p id="542b" class="kz la mz lb b lc ld ju le lf lg jx lh oe lj lk ll of ln lo lp og lr ls lt lu im bi translated">从一开始，我们就意识到有必要对新的鲸鱼做些什么，以便将它们纳入训练过程。简单的解决方法是给每条新鲸鱼分配一个概率，每类概率等于 1/5004。在加权抽样技术的帮助下，它给了我们一些帮助。但后来我们意识到，我们可以使用 softmax 预测来自训练集合的新鲸鱼。所以我们想出了<strong class="lb iu">蒸馏</strong>。我们选择蒸馏而不是伪标签，因为新鲸被认为具有与火车标签不同的标签。尽管这可能不是真的。</p><p id="cb78" class="kz la mz lb b lc ld ju le lf lg jx lh oe lj lk ll of ln lo lp og lr ls lt lu im bi translated">为了进一步提高模型能力，我们将带有伪标签的测试图像添加到训练数据集中。最终，我们的单个模型可以通过快照组装达到<strong class="lb iu"> 0.958 </strong>。不幸的是，以这种方式训练的 ensembling 并没有带来任何分数的提高。也许是因为伪标签和蒸馏导致的品种减少。</p></blockquote><h1 id="53cb" class="mc md it bd me mf nc mh mi mj nd ml mm jz ne ka mo kc nf kd mq kf ng kg ms mt bi translated">最后的想法</h1><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ow"><img src="../Images/3dfa896b6c3fe9120b5af9459755f3eb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*dChRM-kDfd_6eUX0IMR0ow.png"/></div></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk">Final Standings</figcaption></figure><p id="6e25" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">令人惊讶的是，尽管私有测试集贡献了所有测试数据集的近 80%,但最终几乎没有任何改变。我相信竞赛主持人很好地提供了一个非常有趣的问题，以及干净和经过处理的数据。</p><p id="8fe5" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这是我参加的第一次 Kaggle 比赛，它确实证明了 Kaggle 比赛是多么有趣、吸引人、激励和教育人。我想祝贺那些由于这次比赛而成为专家、大师和特级大师的人们。我还要感谢<a class="ae ky" href="http://ods.ai" rel="noopener ugc nofollow" target="_blank"> ODS.ai </a>社区令人惊叹的讨论和支持。</p><p id="c362" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">最后，我想再次特别感谢我的团队成员<a class="ae ky" href="https://asanakoy.github.io" rel="noopener ugc nofollow" target="_blank"> Artsiom Sanakoyeu </a>和<a class="ae ky" href="https://www.linkedin.com/in/ppleskov/" rel="noopener ugc nofollow" target="_blank"> Pavel Pleskov </a>给了我一次难忘的 Kaggle 比赛经历。</p></div></div>    
</body>
</html>