<html>
<head>
<title>Metrics and Python</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">度量和 Python</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/metrics-and-python-850b60710e0c?source=collection_archive---------12-----------------------#2019-11-24">https://towardsdatascience.com/metrics-and-python-850b60710e0c?source=collection_archive---------12-----------------------#2019-11-24</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="f752" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">在三篇系列文章中，我们将描述一组基本的统计概念和用于回归和分类的度量标准</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/eab75042f1ebbaa511eaf7fce6e76af3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*9xW9scKJDxkU-u8Y"/></div></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk">Photo by <a class="ae ky" href="https://unsplash.com/@christina?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Isabella Christina</a> on <a class="ae ky" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><p id="48ff" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">作为一名程序员，我缺乏对数学和统计概念的研究。现在有了更多的经验，我决定汇编并分享一些我遇到的不同问题的度量标准和概念。</p><p id="eeba" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在这一系列文章中，我们将简要回顾它们的用法、公式、示例以及在 Python 中的实现，这样我们就可以一起看到它们，并且在必要时手头有这个图表。<br/>这里是<strong class="lb iu">第一部分</strong>，指的是回归案例中最常用的指标。</p><h1 id="1c33" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">数据集和模型</h1><p id="b260" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">在本文中，我们使用了关于房价的 Kaggle 数据集，因为这是一个我们许多人都熟悉的回归的典型例子。<br/>基本的工程特征已经完成，能够呈现一个最低限度的合理模型，作为度量标准开发的范例。</p><pre class="kj kk kl km gt ms mt mu mv aw mw bi"><span id="0eff" class="mx lw it mt b gy my mz l na nb">from scipy.stats import boxcox_normmax<br/>from scipy.special import boxcox1p<br/>from sklearn.linear_model import LinearRegression</span><span id="f5de" class="mx lw it mt b gy nc mz l na nb">train = pd.read_csv('../input/home-data-for-ml-course/train.csv')<br/>y = train.SalePrice.reset_index(drop=True)</span><span id="6526" class="mx lw it mt b gy nc mz l na nb">features = train<br/>end_features = ['OverallQual','GrLivArea','GarageCars','GarageArea','TotalBsmtSF','1stFlrSF','FullBath','TotRmsAbvGrd','MSSubClass','MSZoning']<br/>features = features[end_features]</span><span id="7d10" class="mx lw it mt b gy nc mz l na nb">features['MSSubClass'] = features['MSSubClass'].apply(str)<br/>features['MSZoning'] = features.groupby('MSSubClass')['MSZoning'].transform(lambda x: x.fillna(x.mode()[0]))</span><span id="ab77" class="mx lw it mt b gy nc mz l na nb">objects = [col for col in features.columns if features[col].dtype == "object"]<br/>features.update(features[objects].fillna('None'))</span><span id="ec72" class="mx lw it mt b gy nc mz l na nb">numeric_dtypes = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']<br/>numerics = [col for col in features.columns if features[col].dtype in numeric_dtypes]<br/>features.update(features[numerics].fillna(0))</span><span id="6e9c" class="mx lw it mt b gy nc mz l na nb">for i in numerics:<br/>    features[i] = boxcox1p(features[i], boxcox_normmax(features[i] + 1))</span><span id="c962" class="mx lw it mt b gy nc mz l na nb">X = pd.get_dummies(features).reset_index(drop=True)</span><span id="a2b6" class="mx lw it mt b gy nc mz l na nb">#----------------- The model<br/>reg = LinearRegression().fit(X, y)<br/>y_pred = reg.predict(X)</span></pre><h1 id="3cc7" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">回归度量摘要</h1><p id="dac3" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">这是一个简单的表格，包含了我们将要描述的指标，表格的最后一列是我们模型的结果。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nd"><img src="../Images/424869b5627ee5561db11376d4d1a2aa.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*lke9jk2uY-ppHO0h0xytQw.png"/></div></div></figure><h1 id="4d39" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">平均绝对误差</h1><blockquote class="ne nf ng"><p id="9e31" class="kz la nh lb b lc ld ju le lf lg jx lh ni lj lk ll nj ln lo lp nk lr ls lt lu im bi translated">MAE 测量一组预测中误差的平均大小，不考虑它们的方向。它是预测和实际观察之间的绝对差异的测试样本的平均值，其中所有个体差异都具有相同的权重。</p></blockquote><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nl"><img src="../Images/c5fd51ed6df89e896b6e14c778f28f9c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*A4AwqjvFDZMYR40Z.jpg"/></div></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk"><a class="ae ky" href="https://www.dataquest.io/blog/understanding-regression-error-metrics/" rel="noopener ugc nofollow" target="_blank">https://www.dataquest.io/blog/understanding-regression-error-metrics/</a></figcaption></figure><p id="12f7" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">平均绝对误差使用与数据相同的标度。这被称为依赖于尺度的精度度量，因此不能用于使用不同尺度的系列之间的比较。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nm"><img src="../Images/3f08456600a70609305c067b7684e22e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*sA9a9MlNiZ1dI7so.jpg"/></div></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk"><a class="ae ky" href="https://www.dataquest.io/blog/understanding-regression-error-metrics/" rel="noopener ugc nofollow" target="_blank">https://www.dataquest.io/blog/understanding-regression-error-metrics/</a></figcaption></figure><pre class="kj kk kl km gt ms mt mu mv aw mw bi"><span id="36dd" class="mx lw it mt b gy my mz l na nb">from sklearn.metrics import mean_absolute_error<br/>print ('Sk MAE: ' + str(mean_absolute_error(y,y_pred)) )</span><span id="82c5" class="mx lw it mt b gy nc mz l na nb">def MAE(predict,target):<br/>    return (abs(predict-target)).mean()</span><span id="2c2a" class="mx lw it mt b gy nc mz l na nb">print ('My MAE: ' + str(MAE(y_pred,y)))</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nn"><img src="../Images/a473b860148fc463da5066a816a6899e.png" data-original-src="https://miro.medium.com/v2/resize:fit:426/format:webp/1*qc8rvM6qq3Zp6DQ5-CJhug.png"/></div></div></figure><h1 id="e2a8" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">MSE:均方差</h1><blockquote class="ne nf ng"><p id="0d37" class="kz la nh lb b lc ld ju le lf lg jx lh ni lj lk ll nj ln lo lp nk lr ls lt lu im bi translated">MSE 是一个<a class="ae ky" href="https://en.wikipedia.org/wiki/Risk_function" rel="noopener ugc nofollow" target="_blank">风险函数</a>，对应于平方误差损失的<a class="ae ky" href="https://en.wikipedia.org/wiki/Expected_value" rel="noopener ugc nofollow" target="_blank">期望值</a>。MSE 几乎总是严格为正(且不为零)的事实是因为<a class="ae ky" href="https://en.wikipedia.org/wiki/Randomness" rel="noopener ugc nofollow" target="_blank">随机性</a>或者因为估计器<a class="ae ky" href="https://en.wikipedia.org/wiki/Omitted-variable_bias" rel="noopener ugc nofollow" target="_blank">没有考虑到能够产生更精确估计的信息</a>。MSE 是对估计量质量的一种度量，它总是非负的，值越接近零越好。</p></blockquote><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi no"><img src="../Images/62c6ffa444eda204b42a2398e8b92d67.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*7RxO773DPeY8IYeD.png"/></div></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk"><a class="ae ky" href="https://www.geeksforgeeks.org/ml-mathematical-explanation-of-rmse-and-r-squared-error/" rel="noopener ugc nofollow" target="_blank">https://www.geeksforgeeks.org/ml-mathematical-explanation-of-rmse-and-r-squared-error/</a></figcaption></figure><p id="ba4b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">“最小化 MSE 是选择估值器的关键标准:见<a class="ae ky" href="https://en.wikipedia.org/wiki/Minimum_mean-square_error" rel="noopener ugc nofollow" target="_blank">最小均方误差</a>。在无偏估计量中，最小化 MSE 等价于最小化方差，而做这件事的估计量就是<a class="ae ky" href="https://en.wikipedia.org/wiki/Minimum_variance_unbiased_estimator" rel="noopener ugc nofollow" target="_blank">最小方差无偏估计量</a>。然而，有偏估计量可能具有较低的 MSE 参见<a class="ae ky" href="https://en.wikipedia.org/wiki/Estimator_bias" rel="noopener ugc nofollow" target="_blank">估计器偏差</a>。</p><p id="f99d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在<a class="ae ky" href="https://en.wikipedia.org/wiki/Statistical_modelling" rel="noopener ugc nofollow" target="_blank">统计建模</a>中，MSE 可以表示实际观测值和模型预测的观测值之间的差异。在这种情况下，它用于确定模型与数据的吻合程度，以及是否可以在不明显损害模型预测能力的情况下删除一些解释变量。"</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi np"><img src="../Images/bec0b509d5cb97b4fa131ef17d874587.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*9uUU5Fya4YMbl_7C.jpg"/></div></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk"><a class="ae ky" href="https://www.geeksforgeeks.org/ml-mathematical-explanation-of-rmse-and-r-squared-error/" rel="noopener ugc nofollow" target="_blank">https://www.geeksforgeeks.org/ml-mathematical-explanation-of-rmse-and-r-squared-error/</a></figcaption></figure><pre class="kj kk kl km gt ms mt mu mv aw mw bi"><span id="402d" class="mx lw it mt b gy my mz l na nb">from sklearn.metrics import mean_squared_error<br/>print ('Sk MSE: ' + str(mean_squared_error(y,y_pred)) )</span><span id="8621" class="mx lw it mt b gy nc mz l na nb">def MSE(predict,target):<br/>    return ((predict-target)**2).mean()<br/>print ('My MSE: ' + str(MSE(y_pred,y)) )</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nq"><img src="../Images/3be54ce5fbed8a343e9aa424bbb85c26.png" data-original-src="https://miro.medium.com/v2/resize:fit:440/format:webp/1*wpAi82rvvw_zfd0VWXrhOQ.png"/></div></figure><h1 id="0398" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">RMSE:均方根误差</h1><blockquote class="ne nf ng"><p id="8e4e" class="kz la nh lb b lc ld ju le lf lg jx lh ni lj lk ll nj ln lo lp nk lr ls lt lu im bi translated">RMSE 是一个二次评分规则，也衡量误差的平均幅度。它是预测值和实际观测值之间的平均平方差的平方根。</p></blockquote><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nr"><img src="../Images/6a6cc3427b807d45012e8f387b4500b2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1040/format:webp/0*at-j68ROeSmiruDE.png"/></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk"><a class="ae ky" href="https://www.includehelp.com/ml-ai/root-mean-square%20error-rmse.aspx" rel="noopener ugc nofollow" target="_blank">https://www.includehelp.com/ml-ai/root-mean-square%20error-rmse.aspx</a></figcaption></figure><p id="7630" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">RMSE 和梅的比较</p><p id="6bf4" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">相似之处</strong>:</p><ul class=""><li id="834f" class="ns nt it lb b lc ld lf lg li nu lm nv lq nw lu nx ny nz oa bi translated">用感兴趣变量的相同单位表示平均模型预测误差。</li><li id="9739" class="ns nt it lb b lc ob lf oc li od lm oe lq of lu nx ny nz oa bi translated">范围从 0 到∞并且与误差方向无关。</li><li id="0a9a" class="ns nt it lb b lc ob lf oc li od lm oe lq of lu nx ny nz oa bi translated">值越低越好。</li></ul><p id="fdae" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">差异</strong>:</p><ul class=""><li id="5bab" class="ns nt it lb b lc ld lf lg li nu lm nv lq nw lu nx ny nz oa bi translated">在求平均值之前求平方根，RMSE 给大误差一个相对较高的权重，所以当不希望有大误差时，RMSE 应该有用。</li></ul><pre class="kj kk kl km gt ms mt mu mv aw mw bi"><span id="ef0d" class="mx lw it mt b gy my mz l na nb">def RMSE(predict, target):<br/>    return np.sqrt(((predict - target) ** 2).mean())<br/>print ('My RMSE: ' + str(RMSE(y_pred,y)) )</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi og"><img src="../Images/ec03a47322362d440b2fa9bae40188d8.png" data-original-src="https://miro.medium.com/v2/resize:fit:446/format:webp/1*_aC9Cc28lXCJihComPsucg.png"/></div></figure><h1 id="645d" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">MAPE:平均绝对百分比误差</h1><blockquote class="ne nf ng"><p id="b53b" class="kz la nh lb b lc ld ju le lf lg jx lh ni lj lk ll nj ln lo lp nk lr ls lt lu im bi translated">在<a class="ae ky" href="https://en.wikipedia.org/wiki/Statistics" rel="noopener ugc nofollow" target="_blank">统计</a>中预测方法的预测精度的度量，例如在<a class="ae ky" href="https://en.wikipedia.org/wiki/Trend_estimation" rel="noopener ugc nofollow" target="_blank">趋势估计</a>中，也用作<a class="ae ky" href="https://en.wikipedia.org/wiki/Loss_function" rel="noopener ugc nofollow" target="_blank">机器学习</a>中回归问题的损失函数。它通常用百分比来表示准确度。</p></blockquote><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oh"><img src="../Images/f4355aa84ab9121c32d6f54cb84d895e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*N8USfmlDmXq7YuNy.png"/></div></div></figure><p id="90a7" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">虽然 MAPE 的概念听起来非常简单和令人信服，但它在实际应用中有重大缺陷<a class="ae ky" href="https://en.wikipedia.org/wiki/Mean_absolute_percentage_error#cite_note-tofallis2015-3" rel="noopener ugc nofollow" target="_blank"> [*] </a>，并且有许多来自 MAPE 的关于缺陷和误导性结果的研究</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nl"><img src="../Images/496e3c6d1a6e7376db82f1f469bc4eef.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*sB6BWioIO5PTBbt9.jpg"/></div></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk"><a class="ae ky" href="https://www.dataquest.io/blog/understanding-regression-error-metrics/" rel="noopener ugc nofollow" target="_blank">https://www.dataquest.io/blog/understanding-regression-error-metrics/</a></figcaption></figure><pre class="kj kk kl km gt ms mt mu mv aw mw bi"><span id="1ad8" class="mx lw it mt b gy my mz l na nb">def MAPE(predict,target):<br/>    return ( abs((target - predict) / target).mean()) * 100</span><span id="e7e0" class="mx lw it mt b gy nc mz l na nb">print ('My MAPE: ' + str(MAPE(y_pred,y)) )</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi oi"><img src="../Images/b94e1ad7c2d33ec43568e0d9e24eb991.png" data-original-src="https://miro.medium.com/v2/resize:fit:454/format:webp/1*XSFuU72NqZlxBHOe70GM1Q.png"/></div></figure><h1 id="e0d2" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">RMSLE:均方根对数误差</h1><blockquote class="ne nf ng"><p id="abf8" class="kz la nh lb b lc ld ju le lf lg jx lh ni lj lk ll nj ln lo lp nk lr ls lt lu im bi translated">在 RMSLE 的情况下，你取预测值和实际值的对数。所以基本上，改变的是你测量的方差。我相信，当预测值和真实值都是巨大的数字时，如果不想惩罚预测值和实际值之间的巨大差异，通常会使用 RMSLE。</p></blockquote><p id="0044" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">RMSLE 衡量实际和预测之间的比率。</p><p id="c79b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">对数(pi+1)对数(ai+1)对数(pi+1)对数(ai+1)</p><p id="0ee7" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">可以写成 log((pi+1)/(ai+1))log((pi+1)/(ai+1))</p><p id="bacc" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">当值是巨大的数字时，如果不想惩罚巨大的差异，可以使用它。</p><p id="394c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">此外，当您希望对低估的惩罚比对高估的惩罚更多时，也可以使用这种方法。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi oj"><img src="../Images/ccd20bb9ddc533e0609df804c17f6341.png" data-original-src="https://miro.medium.com/v2/resize:fit:936/format:webp/1*FqvDmgsC4OQ8PcSHRH3IVg.png"/></div></figure><p id="b887" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">让我们看看下面的例子</p><p id="e4ff" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">情况 a) : Pi = 600，Ai = 1000 — RMSE = 400，RMSLE = 0.5108</p><p id="0eef" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">情况 b) : Pi = 1400，Ai = 1000 — RMSE = 400，RMSLE = 0.3365</p><pre class="kj kk kl km gt ms mt mu mv aw mw bi"><span id="734b" class="mx lw it mt b gy my mz l na nb">import math</span><span id="4818" class="mx lw it mt b gy nc mz l na nb">def RMSLE(predict, target):<br/>    total = 0 <br/>    for k in range(len(predict)):<br/>        LPred= np.log1p(predict[k]+1)<br/>        LTarg = np.log1p(target[k] + 1)<br/>        if not (math.isnan(LPred)) and  not (math.isnan(LTarg)): <br/>            total = total + ((LPred-LTarg) **2)<br/>        <br/>    total = total / len(predict)        <br/>    return np.sqrt(total)</span><span id="2319" class="mx lw it mt b gy nc mz l na nb">print ('My RMSLE: ' + str(RMSLE(y_pred,y)) )</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ok"><img src="../Images/08e71a0118c17e5dd454b2ba82d5ea81.png" data-original-src="https://miro.medium.com/v2/resize:fit:456/format:webp/1*AYtFXD-trF5-8xplQa1piA.png"/></div></figure><h1 id="10bc" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">R and R 平方:决定系数</h1><blockquote class="ne nf ng"><p id="027b" class="kz la nh lb b lc ld ju le lf lg jx lh ni lj lk ll nj ln lo lp nk lr ls lt lu im bi translated">R and R 平方帮助我们了解我们的回归模型与一个非常简单的模型相比有多好，该模型仅预测来自作为预测的训练集的目标的平均值。</p></blockquote><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ol"><img src="../Images/0f618f9211b4fed561ef72671bb860d7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*-lBX506Imc6Hjqpu"/></div></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk"><a class="ae ky" href="https://www.datasciencecentral.com/profiles/blogs/r-squared-in-one-picture" rel="noopener ugc nofollow" target="_blank">https://www.datasciencecentral.com/profiles/blogs/r-squared-in-one-picture</a></figcaption></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi om"><img src="../Images/c1bbb2592f1b549e7c3919bf63c8e5e7.png" data-original-src="https://miro.medium.com/v2/resize:fit:540/0*ap7U_Ij6D7Z_XMnF.gif"/></div></figure><pre class="kj kk kl km gt ms mt mu mv aw mw bi"><span id="ce1a" class="mx lw it mt b gy my mz l na nb">def R2(predict, target):<br/>    return 1 - (MAE(predict,target) / MAE(target.mean(),target))</span><span id="be4e" class="mx lw it mt b gy nc mz l na nb">def R_SQR(predict, target):<br/>    r2 = R2(predict,target)<br/>    return np.sqrt(r2)</span><span id="da2a" class="mx lw it mt b gy nc mz l na nb">print ('My R2         : ' + str(R2(y_pred,y)) )<br/>print ('My R          : ' + str(R_SQR(y_pred,y)) )</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi on"><img src="../Images/a0ac2381948a4c06865cc531229e3c3d.png" data-original-src="https://miro.medium.com/v2/resize:fit:428/format:webp/1*h067I7RJGyv-dNqCxMdTfQ.png"/></div></figure><h1 id="de87" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">调整后 R</h1><blockquote class="ne nf ng"><p id="86ca" class="kz la nh lb b lc ld ju le lf lg jx lh ni lj lk ll nj ln lo lp nk lr ls lt lu im bi translated">表现等同于基线的模型会将 R 平方值设为 0。模型越好，r2 值越高。具有所有正确预测的最佳模型会给出 R 平方为 1。但是，在向模型中添加新要素时，R 平方值要么增加，要么保持不变。R-Squared 不会因添加对模型没有任何价值的要素而受到惩罚。因此，R 平方的改进版本是调整后的 R 平方</p></blockquote><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oo"><img src="../Images/dd83781bfd3710491d152fd71a011613.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*1jxDmwoJF8R4tOVq.png"/></div></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk"><a class="ae ky" href="http://www.haghish.com/statistics/stata-blog/stata-programming/adjusted_R_squared.php" rel="noopener ugc nofollow" target="_blank">http://www.haghish.com/statistics/stata-blog/stata-programming/adjusted_R_squared.php</a></figcaption></figure><pre class="kj kk kl km gt ms mt mu mv aw mw bi"><span id="0d88" class="mx lw it mt b gy my mz l na nb">def R2_ADJ(predict, target, k):<br/>    r2 = R2(predict,target)<br/>    n = len(target)<br/>    return (1 -  ( (1-r2) *  ( (n-1) / (n-(k+1)) ) ) )</span><span id="555c" class="mx lw it mt b gy nc mz l na nb">k= len(features.columns)<br/>print ('My R2 adjusted: ' + str(R2_ADJ(y_pred,y,k)) )</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi oi"><img src="../Images/dd28b98e7841765324f9ffc8e9c6cfac.png" data-original-src="https://miro.medium.com/v2/resize:fit:454/format:webp/1*tTKizNxplALd60P82TPmng.png"/></div></figure><h1 id="c13c" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">摘要</h1><p id="d52a" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">将主要的回归度量放在一个表中，并为它们中的每一个编写函数，这是一种极好的个人体验。在同一个练习中使用它们，因为这让我能够比较它们的用途，理解它们的公式，并在撰写文章时有一个完整的画面。<br/>希望这篇文章是有用的，欢迎任何评论或更正。</p><p id="9d65" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><em class="nh">下周我们将发表这个系列的第二部分，一篇关于分类度量的文章……</em></p><h1 id="8cef" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">来源</h1><div class="op oq gp gr or os"><a href="https://en.wikipedia.org/wiki/Mean_absolute_error" rel="noopener  ugc nofollow" target="_blank"><div class="ot ab fo"><div class="ou ab ov cl cj ow"><h2 class="bd iu gy z fp ox fr fs oy fu fw is bi translated">绝对平均误差</h2><div class="oz l"><h3 class="bd b gy z fp ox fr fs oy fu fw dk translated">在统计学中，平均绝对误差(MAE)是两个连续变量之间差异的度量。假设 X 和是…</h3></div><div class="pa l"><p class="bd b dl z fp ox fr fs oy fu fw dk translated">en.wikipedia.org</p></div></div><div class="pb l"><div class="pc l pd pe pf pb pg ks os"/></div></div></a></div><div class="op oq gp gr or os"><a href="https://medium.com/human-in-a-machine-world/mae-and-rmse-which-metric-is-better-e60ac3bde13d" rel="noopener follow" target="_blank"><div class="ot ab fo"><div class="ou ab ov cl cj ow"><h2 class="bd iu gy z fp ox fr fs oy fu fw is bi translated">梅和 RMSE——哪个指标更好？</h2><div class="oz l"><h3 class="bd b gy z fp ox fr fs oy fu fw dk translated">平均绝对误差与均方根误差</h3></div><div class="pa l"><p class="bd b dl z fp ox fr fs oy fu fw dk translated">medium.com</p></div></div><div class="pb l"><div class="ph l pd pe pf pb pg ks os"/></div></div></a></div><div class="op oq gp gr or os"><a href="https://www.dataquest.io/blog/understanding-regression-error-metrics/" rel="noopener  ugc nofollow" target="_blank"><div class="ot ab fo"><div class="ou ab ov cl cj ow"><h2 class="bd iu gy z fp ox fr fs oy fu fw is bi translated">教程:了解线性回归和回归误差度量</h2><div class="oz l"><h3 class="bd b gy z fp ox fr fs oy fu fw dk translated">人类大脑的构造是为了识别我们周围世界的模式。例如，我们观察到如果我们练习…</h3></div><div class="pa l"><p class="bd b dl z fp ox fr fs oy fu fw dk translated">www.dataquest.io</p></div></div><div class="pb l"><div class="pi l pd pe pf pb pg ks os"/></div></div></a></div><div class="op oq gp gr or os"><a href="https://www.geeksforgeeks.org/ml-mathematical-explanation-of-rmse-and-r-squared-error/" rel="noopener  ugc nofollow" target="_blank"><div class="ot ab fo"><div class="ou ab ov cl cj ow"><h2 class="bd iu gy z fp ox fr fs oy fu fw is bi translated">RMSE 和 R 平方误差的数学解释</h2><div class="oz l"><h3 class="bd b gy z fp ox fr fs oy fu fw dk translated">RMSE:均方根误差是回归线与数据点拟合程度的量度。RMSE 也可以是…</h3></div><div class="pa l"><p class="bd b dl z fp ox fr fs oy fu fw dk translated">www.geeksforgeeks.org</p></div></div><div class="pb l"><div class="pj l pd pe pf pb pg ks os"/></div></div></a></div><div class="op oq gp gr or os"><a href="https://en.wikipedia.org/wiki/Mean_squared_error" rel="noopener  ugc nofollow" target="_blank"><div class="ot ab fo"><div class="ou ab ov cl cj ow"><h2 class="bd iu gy z fp ox fr fs oy fu fw is bi translated">均方误差</h2><div class="oz l"><h3 class="bd b gy z fp ox fr fs oy fu fw dk translated">在统计学中，估计量的均方误差(MSE)或均方偏差(MSD)</h3></div><div class="pa l"><p class="bd b dl z fp ox fr fs oy fu fw dk translated">en.wikipedia.org</p></div></div></div></a></div><div class="op oq gp gr or os"><a href="https://www.includehelp.com/ml-ai/root-mean-square%20error-rmse.aspx" rel="noopener  ugc nofollow" target="_blank"><div class="ot ab fo"><div class="ou ab ov cl cj ow"><h2 class="bd iu gy z fp ox fr fs oy fu fw is bi translated">均方根误差(RMSE) |机器学习</h2><div class="oz l"><h3 class="bd b gy z fp ox fr fs oy fu fw dk translated">首页“机器学习/人工智能均方根误差(RMSE):在这篇文章中，我们将学习…</h3></div><div class="pa l"><p class="bd b dl z fp ox fr fs oy fu fw dk translated">www.includehelp.com</p></div></div><div class="pb l"><div class="pk l pd pe pf pb pg ks os"/></div></div></a></div><div class="op oq gp gr or os"><a href="https://en.wikipedia.org/wiki/Root-mean-square_deviation" rel="noopener  ugc nofollow" target="_blank"><div class="ot ab fo"><div class="ou ab ov cl cj ow"><h2 class="bd iu gy z fp ox fr fs oy fu fw is bi translated">均方根偏差</h2><div class="oz l"><h3 class="bd b gy z fp ox fr fs oy fu fw dk translated">均方根偏差(RMSD)或均方根误差(RMSE)(有时也称为均方根误差)是一个…</h3></div><div class="pa l"><p class="bd b dl z fp ox fr fs oy fu fw dk translated">en.wikipedia.org</p></div></div></div></a></div><div class="op oq gp gr or os"><a href="https://www.forecastpro.com/Trends/forecasting101August2011.html" rel="noopener  ugc nofollow" target="_blank"><div class="ot ab fo"><div class="ou ab ov cl cj ow"><h2 class="bd iu gy z fp ox fr fs oy fu fw is bi translated">欢迎使用销售预测、库存计划、需求计划、销售和运营预测软件</h2><div class="oz l"><h3 class="bd b gy z fp ox fr fs oy fu fw dk translated">预测 101:预测误差测量统计和如何使用它们的指南误差测量统计发挥…</h3></div><div class="pa l"><p class="bd b dl z fp ox fr fs oy fu fw dk translated">www.forecastpro.com</p></div></div><div class="pb l"><div class="pl l pd pe pf pb pg ks os"/></div></div></a></div><div class="op oq gp gr or os"><a href="https://en.wikipedia.org/wiki/Mean_absolute_percentage_error" rel="noopener  ugc nofollow" target="_blank"><div class="ot ab fo"><div class="ou ab ov cl cj ow"><h2 class="bd iu gy z fp ox fr fs oy fu fw is bi translated">平均绝对百分比误差</h2><div class="oz l"><h3 class="bd b gy z fp ox fr fs oy fu fw dk translated">平均绝对百分比误差(MAPE)，也称为平均绝对百分比偏差(MAPD)，是衡量…</h3></div><div class="pa l"><p class="bd b dl z fp ox fr fs oy fu fw dk translated">en.wikipedia.org</p></div></div></div></a></div><div class="op oq gp gr or os"><a href="https://www.quora.com/What-is-the-difference-between-an-RMSE-and-RMSLE-logarithmic-error-and-does-a-high-RMSE-imply-low-RMSLE" rel="noopener  ugc nofollow" target="_blank"><div class="ot ab fo"><div class="ou ab ov cl cj ow"><h2 class="bd iu gy z fp ox fr fs oy fu fw is bi translated">RMSE 和 RMSLE(对数误差)之间有什么区别，高 RMSE 是否意味着…</h2><div class="oz l"><h3 class="bd b gy z fp ox fr fs oy fu fw dk translated">回答(第 1 题，共 2 题):均方根误差(RMSE)和均方根对数误差(RMSLE)都是技术…</h3></div><div class="pa l"><p class="bd b dl z fp ox fr fs oy fu fw dk translated">www.quora.com</p></div></div><div class="pb l"><div class="pm l pd pe pf pb pg ks os"/></div></div></a></div><p id="cccd" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><a class="ae ky" href="https://en.wikipedia.org/wiki/Coefficient_of_determination" rel="noopener ugc nofollow" target="_blank">https://en.wikipedia.org/wiki/Coefficient_of_determination</a></p><div class="op oq gp gr or os"><a href="https://www.analyticsvidhya.com/blog/2019/08/11-important-model-evaluation-error-metrics/?utm_source=twitter.com&amp;utm_medium=social" rel="noopener  ugc nofollow" target="_blank"><div class="ot ab fo"><div class="ou ab ov cl cj ow"><h2 class="bd iu gy z fp ox fr fs oy fu fw is bi translated">每个人都应该知道的机器学习的 11 个重要模型评估指标</h2><div class="oz l"><h3 class="bd b gy z fp ox fr fs oy fu fw dk translated">概述评估模型是构建有效机器学习模型的核心部分，有几种评估方法…</h3></div><div class="pa l"><p class="bd b dl z fp ox fr fs oy fu fw dk translated">www.analyticsvidhya.com</p></div></div><div class="pb l"><div class="pn l pd pe pf pb pg ks os"/></div></div></a></div><div class="op oq gp gr or os"><a href="http://www.haghish.com/statistics/stata-blog/stata-programming/adjusted_R_squared.php" rel="noopener  ugc nofollow" target="_blank"><div class="ot ab fo"><div class="ou ab ov cl cj ow"><h2 class="bd iu gy z fp ox fr fs oy fu fw is bi translated">在 Stata 中计算调整后的 R 平方</h2><div class="oz l"><h3 class="bd b gy z fp ox fr fs oy fu fw dk translated">2014 年 11 月 23 日更新|快速提示| |简介| |算法| | r2_a 程序| |分析| |练习|…</h3></div><div class="pa l"><p class="bd b dl z fp ox fr fs oy fu fw dk translated">www.haghish.com</p></div></div></div></a></div><div class="op oq gp gr or os"><a href="https://en.wikipedia.org/wiki/Coefficient_of_determination" rel="noopener  ugc nofollow" target="_blank"><div class="ot ab fo"><div class="ou ab ov cl cj ow"><h2 class="bd iu gy z fp ox fr fs oy fu fw is bi translated">决定系数</h2><div class="oz l"><h3 class="bd b gy z fp ox fr fs oy fu fw dk translated">在统计学中，决定系数，表示为 R 2 或 r 2，读作“R 的平方”，是…</h3></div><div class="pa l"><p class="bd b dl z fp ox fr fs oy fu fw dk translated">en.wikipedia.org</p></div></div><div class="pb l"><div class="po l pd pe pf pb pg ks os"/></div></div></a></div></div></div>    
</body>
</html>