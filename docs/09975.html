<html>
<head>
<title>Logistic Regression from Scratch in R</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">R 中从头开始的逻辑回归</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/logistic-regression-from-scratch-in-r-b5b122fd8e83?source=collection_archive---------19-----------------------#2019-12-30">https://towardsdatascience.com/logistic-regression-from-scratch-in-r-b5b122fd8e83?source=collection_archive---------19-----------------------#2019-12-30</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/></div><div class="ab cl jn jo hu jp" role="separator"><span class="jq bw bk jr js jt"/><span class="jq bw bk jr js jt"/><span class="jq bw bk jr js"/></div><div class="ij ik il im in"><p id="e9ba" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated"><em class="ks">如果方程式没有出现，请点击“显示嵌入”来显示它们</em></p></div><div class="ab cl jn jo hu jp" role="separator"><span class="jq bw bk jr js jt"/><span class="jq bw bk jr js jt"/><span class="jq bw bk jr js"/></div><div class="ij ik il im in"><figure class="ku kv kw kx gt ky gh gi paragraph-image"><div class="gh gi kt"><img src="../Images/329b22fe4976ee7f0fad2d27e671fe52.png" data-original-src="https://miro.medium.com/v2/resize:fit:1344/format:webp/1*gduuc2YJAnufKioWyaPsGQ.png"/></div></figure><h1 id="7723" class="lb lc iq bd ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly bi translated">介绍</h1><p id="7703" class="pw-post-body-paragraph ju jv iq jw b jx lz jz ka kb ma kd ke kf mb kh ki kj mc kl km kn md kp kq kr ij bi translated">在统计学和数据科学中，逻辑回归用于预测某一类或某一事件的概率。通常，该模型是二项式的，但也可以扩展到多项式。对于许多应用程序来说，它可能是最简单但极其有用的模型之一，因为它实现速度快，易于解释。</p><p id="0bc4" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">这篇文章将关注二项式逻辑回归(可能会跟进多项式模型)。我将讨论逻辑回归的基础知识，它与线性回归的关系，以及如何使用简单的矩阵运算在<strong class="jw ir"> R </strong>中构建模型。仅使用数学和矩阵运算(而不是<strong class="jw ir"> R </strong>中的内置模型)将帮助我们理解幕后的逻辑回归。</p><p id="d5ad" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">最后，我将使用构建的模型对一些生成的数据进行分类，并显示决策边界。</p><h1 id="dbd3" class="lb lc iq bd ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly bi translated">逻辑回归</h1><p id="783b" class="pw-post-body-paragraph ju jv iq jw b jx lz jz ka kb ma kd ke kf mb kh ki kj mc kl km kn md kp kq kr ij bi translated">我们可以认为逻辑回归是一个广义线性模型，具有二项分布和 logit 连接函数。这种与线性回归的相似性将有助于我们构建模型。但是两种模型的区别在于:在线性回归中，预测值的范围是(<strong class="jw ir"> -∞，∞ </strong>)，而在逻辑回归中，是概率<strong class="jw ir"> <em class="ks"> p </em> </strong>范围[0，1]。这就是为什么我们需要使用 logit link 函数。</p><p id="3a7c" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">我们不是直接预测<strong class="jw ir"> <em class="ks"> p </em> </strong>，而是预测几率对数(<a class="ae me" href="https://en.wikipedia.org/wiki/Logit" rel="noopener ugc nofollow" target="_blank"> logit </a>):</p><figure class="ku kv kw kx gt ky"><div class="bz fp l di"><div class="mf mg l"/></div></figure><p id="5eab" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">其范围从<strong class="jw ir"> -∞ </strong>到<strong class="jw ir"> ∞ </strong>。当<strong class="jw ir"><em class="ks">p</em></strong>→<strong class="jw ir">0</strong>，<strong class="jw ir">logit(<em class="ks">p</em>)</strong>→<strong class="jw ir">-∞</strong>而当<strong class="jw ir"> p → 1 时，logit(<em class="ks">p</em>)</strong>→<strong class="jw ir">-∞。</strong>因此，logit 函数有效地将概率值从[0，1]映射到(<strong class="jw ir"> -∞，∞ </strong>)。现在线性关系是:</p><figure class="ku kv kw kx gt ky"><div class="bz fp l di"><div class="mf mg l"/></div></figure><p id="f199" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">其中上标表示第<strong class="jw ir"> <em class="ks"> i </em> </strong>个例子，下标表示特征或预测器<strong class="jw ir"> <em class="ks"> x </em> 1 </strong>，<strong class="jw ir"> <em class="ks"> x </em> 2 </strong>等(<strong class="jw ir"> <em class="ks"> x </em> 0 </strong>为<strong class="jw ir"> 1 </strong>作为偏差)。对于总共<strong class="jw ir"> m 个</strong>训练样本，预测矩阵<strong class="jw ir"> <em class="ks"> X </em> </strong>的形状将是<strong class="jw ir"> m×(D+1) </strong>，其中<strong class="jw ir"> D </strong>是预测变量<strong class="jw ir"> ( <em class="ks"> x </em> 1，<em class="ks"> x </em> 2，…，<em class="ks"> x </em> D) </strong>的维数。加 1 是为了包含偏置列<strong class="jw ir"> <em class="ks"> x </em> 0 </strong>。</p><p id="5239" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">而<strong class="jw ir"> ( <em class="ks"> θ </em> 0，<em class="ks"> θ </em> 1，…，<em class="ks"> θ </em> D) </strong>是一个<strong class="jw ir"> (D+1)×1 </strong>列向量。向量化计算，右手边(<strong class="jw ir"> RHS </strong>)可以写成<strong class="jw ir">转置</strong>(<strong class="jw ir"><em class="ks">θ</em></strong>)<strong class="jw ir"><em class="ks">⋅x</em></strong>或者<strong class="jw ir"> <em class="ks"> X⋅θ </em> </strong>。接下来的任务是找到<strong class="jw ir"> <em class="ks"> θ </em> </strong>，这最能代表<strong class="jw ir"> <em class="ks"> p </em> </strong>随<strong class="jw ir"><em class="ks"/></strong>X<strong class="jw ir"><em class="ks">【m</em></strong>训练示例的变化。</p><p id="68e1" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">为了找到<strong class="jw ir"> <em class="ks"> θ </em> </strong>，我们需要定义一个代价函数。成本函数是这样的，每一个不正确的预测(或离真实值更远的预测)都会增加它的值。在逻辑回归中，成本函数定义为:</p><figure class="ku kv kw kx gt ky"><div class="bz fp l di"><div class="mf mg l"/></div></figure><p id="d166" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">其中<strong class="jw ir"><em class="ks">h</em>(<em class="ks">x</em>)</strong>是 sigmoid 函数，logit 函数的反函数:</p><figure class="ku kv kw kx gt ky"><div class="bz fp l di"><div class="mf mg l"/></div></figure><p id="dcf9" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">对于每个例子，<strong class="jw ir"> <em class="ks"> y </em> </strong>是实际的类标签 0 或 1，<strong class="jw ir"> <em class="ks"> h </em> ( <em class="ks"> x </em> ) </strong>是得到值 1 的预测概率。如果<strong class="jw ir"> <em class="ks"> y </em> = 1 </strong>(第二项用<strong class="jw ir"> (1- <em class="ks"> y </em> ) </strong>将为 0)，<strong class="jw ir"><em class="ks">j</em>(<em class="ks">I</em>)=-<em class="ks">y⋅</em>log(<em class="ks">h</em>(<em class="ks">x</em>)。</strong>当<strong class="jw ir"><em class="ks">h</em>(<em class="ks">x</em>)→</strong>1、<strong class="jw ir">T38】J(<em class="ks">I</em>)→0</strong>自<strong class="jw ir">log(1)= 0</strong>；当<strong class="jw ir"><em class="ks">h</em>(<em class="ks">x</em>)</strong>→<strong class="jw ir">0</strong>，<strong class="jw ir"> <em class="ks"> J </em> ( <em class="ks"> i </em> ) → ∞时。</strong>如果<strong class="jw ir"> <em class="ks"> y </em> = 0，<em class="ks">J</em>(<em class="ks">I</em>)=-log(1-(<em class="ks">h</em>(<em class="ks">x</em>))。</strong>当<strong class="jw ir"><em class="ks">h</em>(<em class="ks">x</em>)</strong>→<strong class="jw ir">0</strong>，<strong class="jw ir"><em class="ks">J</em>(<em class="ks">I</em>)→0</strong>，当<strong class="jw ir"><em class="ks">h</em>(<em class="ks">x</em>)</strong>→1，<strong class="jw ir">T92【J】</strong>随着<strong class="jw ir"><em class="ks">h</em>(<em class="ks">x</em>)</strong>从<strong class="jw ir"> <em class="ks"> y </em> </strong>进一步发展，成本函数迅速增加。</p><p id="d167" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">这是构建模型的基本过程。令人惊讶的是，当我开始编码时，它比我想象的要简单。</p><h1 id="5318" class="lb lc iq bd ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly bi translated">R 中的模型构造</h1><p id="7bab" class="pw-post-body-paragraph ju jv iq jw b jx lz jz ka kb ma kd ke kf mb kh ki kj mc kl km kn md kp kq kr ij bi translated">现在我们已经有了数学部分，让我们建立我们的逻辑回归。首先我将定义辅助函数，如 sigmoid 函数、成本函数<strong class="jw ir"> <em class="ks"> J </em> </strong>和梯度函数<strong class="jw ir"> <em class="ks"> J </em> </strong>。注意<code class="fe mh mi mj mk b">%*%</code>是<strong class="jw ir"> R </strong>中的点积。以下所有函数都使用矢量化计算。</p><figure class="ku kv kw kx gt ky"><div class="bz fp l di"><div class="ml mg l"/></div></figure><p id="dd4c" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">接下来是逻辑回归函数，它将训练数据<strong class="jw ir"> <em class="ks"> X </em> </strong>，标签<strong class="jw ir"> <em class="ks"> y </em> </strong>作为输入。它返回一个列向量，该向量存储了<strong class="jw ir"> <em class="ks"> θ </em> </strong>中的系数。需要注意的一点是，输入的<strong class="jw ir"> <em class="ks"> X </em> </strong>通常没有偏置项，前导列向量为 1，所以我在函数中添加了这个列。</p><figure class="ku kv kw kx gt ky"><div class="bz fp l di"><div class="ml mg l"/></div></figure><p id="ba3d" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">最后我可以写两个预测函数:第一个以<strong class="jw ir"> <em class="ks"> X </em> </strong>和<strong class="jw ir"> <em class="ks"> θ </em> </strong>为输入预测概率<strong class="jw ir"> <em class="ks"> p </em> </strong>，第二个以<strong class="jw ir"> <em class="ks"> p </em> </strong>为输入返回<strong class="jw ir"> <em class="ks"> y </em> </strong> (1 或 0)。</p><figure class="ku kv kw kx gt ky"><div class="bz fp l di"><div class="ml mg l"/></div></figure><h1 id="5282" class="lb lc iq bd ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly bi translated">分类和决策边界</h1><p id="27ff" class="pw-post-body-paragraph ju jv iq jw b jx lz jz ka kb ma kd ke kf mb kh ki kj mc kl km kn md kp kq kr ij bi translated">生成训练数据，使得它具有两个类别(0，1)，两个预测值(<strong class="jw ir"> <em class="ks"> x </em> 1，<em class="ks"> x </em> 2 </strong>)，并且可以通过线性函数来分离。</p><figure class="ku kv kw kx gt ky"><div class="bz fp l di"><div class="ml mg l"/></div></figure><figure class="ku kv kw kx gt ky gh gi paragraph-image"><div class="gh gi mm"><img src="../Images/aa54f8b26eb919cbb5db78d2933d10ab.png" data-original-src="https://miro.medium.com/v2/resize:fit:1090/format:webp/1*0E2kkYMSR5kHjhEVf0oYnQ.png"/></div></figure><p id="8491" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">有一些轻微的重叠，所以没有这样的线将两个类完全分开。然而，我们的模型仍然能够找到最佳线路。</p><p id="99ff" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">现在我可以训练模型得到<strong class="jw ir"> <em class="ks"> θ </em> </strong>。</p><figure class="ku kv kw kx gt ky"><div class="bz fp l di"><div class="ml mg l"/></div></figure><p id="5d2e" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">还创建了一个网格，它可以被视为一个测试集。经过训练的模型将应用于此网格，并预测结果 z。这可用于创建决策边界。</p><figure class="ku kv kw kx gt ky"><div class="bz fp l di"><div class="ml mg l"/></div></figure><p id="5cac" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">在下面的图中，模型预测了将两个类的大部分分开的边界。一些数据点没有像预期的那样正确预测。但是，对训练数据进行 100%预测的模型在大多数情况下可能不是一个好模型，因为它会过度拟合数据。事实上，根据我生成数据的方式，解析解应该是<strong class="jw ir"><em class="ks">x</em>/3+<em class="ks">y</em>= 2</strong>。而我的决策边界非常接近这条分析线。</p><figure class="ku kv kw kx gt ky gh gi paragraph-image"><div class="gh gi mm"><img src="../Images/35170ebd1122c499694ea36110fcd7b2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1090/format:webp/1*MA0gJ7YGJcyqjnbunPUfxg.png"/></div></figure><h1 id="9a9a" class="lb lc iq bd ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly bi translated">结论</h1><p id="7fbc" class="pw-post-body-paragraph ju jv iq jw b jx lz jz ka kb ma kd ke kf mb kh ki kj mc kl km kn md kp kq kr ij bi translated">现在你知道了，从头开始建立回归模型对我们来说并不困难。如果你阅读了这篇文章，希望现在你已经对逻辑回归有了更好的理解。最后一点，虽然逻辑回归经常被认为是一个分类器，但它也可以用于回归:找到我们上面看到的概率。</p></div><div class="ab cl jn jo hu jp" role="separator"><span class="jq bw bk jr js jt"/><span class="jq bw bk jr js jt"/><span class="jq bw bk jr js"/></div><div class="ij ik il im in"><p id="f151" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated"><em class="ks">你可以在这里找到代码:</em><a class="ae me" href="https://github.com/JunWorks/Logistic-Regression-from-scratch-in-R" rel="noopener ugc nofollow" target="_blank">https://github . com/JunWorks/Logistic-Regression-from-scratch-in-R</a></p></div></div>    
</body>
</html>