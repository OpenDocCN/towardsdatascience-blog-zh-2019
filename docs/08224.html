<html>
<head>
<title>Using TF IDF to form descriptive chapter summaries via keyword extraction.</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用 TF IDF 通过关键词提取形成描述性章节摘要。</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/using-tf-idf-to-form-descriptive-chapter-summaries-via-keyword-extraction-4e6fd857d190?source=collection_archive---------11-----------------------#2019-11-10">https://towardsdatascience.com/using-tf-idf-to-form-descriptive-chapter-summaries-via-keyword-extraction-4e6fd857d190?source=collection_archive---------11-----------------------#2019-11-10</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><figure class="gl gn jr js jt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi jq"><img src="../Images/6f8ad3b61f972006778dcd9d1c93718c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*nZ5sCFdk7PVMlGfGvrnq5g.png"/></div></div><figcaption class="kb kc gj gh gi kd ke bd b be z dk">Source: <a class="ae kf" href="https://pixabay.com/photos/library-books-education-literature-869061/" rel="noopener ugc nofollow" target="_blank">https://pixabay.com/photos/library-books-education-literature-869061/</a></figcaption></figure><p id="6246" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">TF IDF 是一种自然语言处理技术，用于提取一组文档或章节中的重要关键字。首字母缩写代表“<em class="le">术语频率-逆文档频率”</em>并描述了该算法如何工作。</p><h2 id="7088" class="lf lg it bd lh li lj dn lk ll lm dp ln kr lo lp lq kv lr ls lt kz lu lv lw lx bi translated">数据集</h2><p id="b4d2" class="pw-post-body-paragraph kg kh it ki b kj ly kl km kn lz kp kq kr ma kt ku kv mb kx ky kz mc lb lc ld im bi translated">作为我们的数据集，我们将采用玛丽·雪莱的《弗兰肯斯坦》的脚本(由古腾堡项目<a class="ae kf" href="http://www.gutenberg.org/files/84/84-0.txt" rel="noopener ugc nofollow" target="_blank">提供)，并基于 TFIDF 算法的输出生成每章中事件的感觉。为了做到这一点，我们首先要理解为什么 TFIDF 算法如此成功:</a></p><h2 id="39b5" class="lf lg it bd lh li lj dn lk ll lm dp ln kr lo lp lq kv lr ls lt kz lu lv lw lx bi translated">TFIDF 算法</h2><p id="5b1e" class="pw-post-body-paragraph kg kh it ki b kj ly kl km kn lz kp kq kr ma kt ku kv mb kx ky kz mc lb lc ld im bi translated">该算法分两部分工作。首先，我们计算我们的“<strong class="ki iu">项频率</strong>”。这将根据每个单词在文档中出现的次数对其进行排序(加权)——我们重复的次数越多，它越重要的可能性就越大。</p><p id="3824" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">然后，这个术语通过除以整个组中的单词数而被标准化。这是因为出现在一小段中的单词，例如标题，比成千上万行中的同一个单词具有更大的权重。</p><p id="47cd" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">接下来，我们有'<strong class="ki iu">逆文档频率</strong>'部分。这很重要，因为它根据单词在特定文本片段中的个性对单词进行排序。在这里，我们将在文本的单个部分<em class="le">中频繁使用的单词与在各处</em>中频繁使用的单词分开。这意味着只有当前文档/章节的本地标识词被标记为重要。我们使用以下公式进行计算:</p><pre class="md me mf mg gt mh mi mj mk aw ml bi"><span id="6134" class="lf lg it mi b gy mm mn l mo mp"><em class="le">1 + log_exp ( number_documents / (document_frequency + 1))</em></span></pre><p id="7eb0" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">这两个术语结合起来提供了每个单词相对于其所在部分的重要性的权重。</p><h2 id="da13" class="lf lg it bd lh li lj dn lk ll lm dp ln kr lo lp lq kv lr ls lt kz lu lv lw lx bi translated">预处理</h2><p id="689d" class="pw-post-body-paragraph kg kh it ki b kj ly kl km kn lz kp kq kr ma kt ku kv mb kx ky kz mc lb lc ld im bi translated">与所有数据科学任务一样，我们需要为算法中使用的数据做好准备。将所需文本读入 python 后，我们可以用空格替换所有句点，并用 regex 模块(re)删除所有非单词字符:</p><pre class="md me mf mg gt mh mi mj mk aw ml bi"><span id="cdf6" class="lf lg it mi b gy mm mn l mo mp">text = text.replace('.',' ')<br/>text = re.sub(r'\s+',' ',re.sub(r'[^\w \s]','',text) ).lower()</span></pre><p id="5894" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">接下来，我们根据单词'<em class="le"> chapter </em> ' <em class="le"> (+一个数字)</em>分割数据集，尽管这可以是 LaTeX 中的<code class="fe mq mr ms mi b">\section{.*}</code>或您选择的任何其他分隔符。</p><pre class="md me mf mg gt mh mi mj mk aw ml bi"><span id="ba53" class="lf lg it mi b gy mm mn l mo mp">corpus = re.split('chapter \d+',text)</span></pre><h2 id="8b5a" class="lf lg it bd lh li lj dn lk ll lm dp ln kr lo lp lq kv lr ls lt kz lu lv lw lx bi translated">将数据输入算法</h2><p id="4a99" class="pw-post-body-paragraph kg kh it ki b kj ly kl km kn lz kp kq kr ma kt ku kv mb kx ky kz mc lb lc ld im bi translated">最简单的方法是使用 python 中的<a class="ae kf" href="https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html" rel="noopener ugc nofollow" target="_blank"> scikit-learn </a>包。在这里，我们可以直接输入我们的数据，并获得它来计算每个组的单词排名:</p><pre class="md me mf mg gt mh mi mj mk aw ml bi"><span id="b3d6" class="lf lg it mi b gy mm mn l mo mp">import pandas as pd<br/>from sklearn.feature_extraction.text import TfidfVectorizer</span><span id="d148" class="lf lg it mi b gy mt mn l mo mp">vectorizer = TfidfVectorizer()<br/>vectors = vectorizer.fit_transform(corpus)</span><span id="6526" class="lf lg it mi b gy mt mn l mo mp">names = vectorizer.get_feature_names()<br/>data = vectors.todense().tolist()</span><span id="4de7" class="lf lg it mi b gy mt mn l mo mp"># Create a dataframe with the results<br/>df = pd.DataFrame(data, columns=names)</span></pre><h2 id="aac4" class="lf lg it bd lh li lj dn lk ll lm dp ln kr lo lp lq kv lr ls lt kz lu lv lw lx bi translated">过滤掉停用词</h2><p id="a6c8" class="pw-post-body-paragraph kg kh it ki b kj ly kl km kn lz kp kq kr ma kt ku kv mb kx ky kz mc lb lc ld im bi translated">在自然语言处理中，停用词是一组对最终输出没有什么意义的词。这些通常是常用词，如<code class="fe mq mr ms mi b">I,a,all, any,and,the,them,it,dont,has</code>等。使用自然处理库<code class="fe mq mr ms mi b">nltk</code>,我们可以过滤掉包含这些的所有列。</p><pre class="md me mf mg gt mh mi mj mk aw ml bi"><span id="cf60" class="lf lg it mi b gy mm mn l mo mp">from nltk.corpus import stopwords<br/>nltk.download('stopwords')<br/>st = set(stopwords.words('english'))</span><span id="bdb9" class="lf lg it mi b gy mt mn l mo mp">#remove all columns containing a stop word from the resultant dataframe. </span><span id="1580" class="lf lg it mi b gy mt mn l mo mp">df = df[filter(lambda x: x not in list(st) , df.columns)]</span></pre><h2 id="8b45" class="lf lg it bd lh li lj dn lk ll lm dp ln kr lo lp lq kv lr ls lt kz lu lv lw lx bi translated">打印出每章排名前 N 位的单词</h2><p id="88f2" class="pw-post-body-paragraph kg kh it ki b kj ly kl km kn lz kp kq kr ma kt ku kv mb kx ky kz mc lb lc ld im bi translated">这是通过选择每一行/数据集来完成的——由于我们之前的选择，这些代表不同的章节，并在打印之前选择 N 个排名最高的列。</p><pre class="md me mf mg gt mh mi mj mk aw ml bi"><span id="9726" class="lf lg it mi b gy mm mn l mo mp">N = 10;</span><span id="6c28" class="lf lg it mi b gy mt mn l mo mp">for i in df.iterrows():<br/>    print(i[1].sort_values(ascending=False)[:N])</span></pre></div><div class="ab cl mu mv hx mw" role="separator"><span class="mx bw bk my mz na"/><span class="mx bw bk my mz na"/><span class="mx bw bk my mz"/></div><div class="im in io ip iq"><h2 id="1f9a" class="lf lg it bd lh li lj dn lk ll lm dp ln kr lo lp lq kv lr ls lt kz lu lv lw lx bi translated">解释结果</h2><p id="9418" class="pw-post-body-paragraph kg kh it ki b kj ly kl km kn lz kp kq kr ma kt ku kv mb kx ky kz mc lb lc ld im bi translated">现在，这就是我们看到我们的算法在预测关键词方面有多好的地方。因为有 25 个章节，我们在下面只展示了一些随机选择的章节。在该选择中，我们将章节提要与由 TFIDF 算法选择的排名最高的关键字进行比较，并决定它在描述现有事件方面的表现。</p></div><div class="ab cl mu mv hx mw" role="separator"><span class="mx bw bk my mz na"/><span class="mx bw bk my mz na"/><span class="mx bw bk my mz"/></div><div class="im in io ip iq"><p id="80bf" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="ki iu">第一章</strong>弗兰肯斯坦设定了场景，描述了他的母亲如何发现了被一个意大利家庭遗弃的伊丽莎白，并收养了她。</p><pre class="md me mf mg gt mh mi mj mk aw ml bi"><span id="2322" class="lf lg it mi b gy mm mn l mo mp">mother      0.084748<br/>beaufort    0.079967<br/>child       0.068566<br/>father      0.062509<br/>orphan      0.054138<br/>daughter    0.053630<br/>poverty     0.049939<br/>italy       0.047980<br/>infant      0.043612<br/>abode       0.043612<br/>Name: 1, dtype: float64</span></pre><p id="f5b6" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="ki iu">第 3 章</strong>维克多(弗兰肯斯坦)离开日内瓦去上大学。在这里，自然哲学教授 Krempe 说服他，他学习炼金术的时间是一种浪费。结果，他参加了沃尔德曼教授举办的化学讲座，教授说服他从事科学研究。</p><pre class="md me mf mg gt mh mi mj mk aw ml bi"><span id="2103" class="lf lg it mi b gy mm mn l mo mp">science       0.074137<br/>natural       0.071721<br/>professor     0.065336<br/>philosophy    0.059502<br/>modern        0.054772<br/>krempe        0.049489<br/>waldman       0.049489<br/>lecture       0.043557<br/>chemistry     0.043557<br/>principal     0.036860<br/>Name: 3, dtype: float64</span></pre><p id="c4e3" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">第 4 章维克托斯对他在理解生命科学方面的工作表现出极大的热情。以至于他对创造生命的迷恋成为他唯一的追求，这在很大程度上导致他忽视了生活中的朋友，并秘密进行令人讨厌的实验。</p><pre class="md me mf mg gt mh mi mj mk aw ml bi"><span id="e618" class="lf lg it mi b gy mm mn l mo mp">pursuit       0.053314<br/>study         0.050588<br/>life          0.046087<br/>one           0.040652<br/>corruption    0.039524<br/>would         0.036956<br/>science       0.036134<br/>eagerness     0.035029<br/>natural       0.034180<br/>secret        0.034180<br/>Name: 4, dtype: float64</span></pre><p id="6894" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">这个怪物一直在学习一个小茅屋里的居民的语言和历史。费利克斯最近在这里遇到了萨菲。萨菲的母亲是一名信奉基督教的阿拉伯人，在嫁给萨菲的父亲之前曾被土耳其人奴役。</p><pre class="md me mf mg gt mh mi mj mk aw ml bi"><span id="cc67" class="lf lg it mi b gy mm mn l mo mp">felix        0.164026<br/>safie        0.136081<br/>turk         0.112066<br/>paris        0.087163<br/>leghorn      0.084299<br/>daughter     0.083509<br/>deliverer    0.070249<br/>lacey        0.045272<br/>merchant     0.045272<br/>christian    0.042149<br/>Name: 14, dtype: float64</span></pre><p id="f18e" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">维克多和亨利穿越了英格兰和苏格兰，但是维克多开始迫不及待地想要开始他的工作，摆脱他和怪物的束缚。</p><pre class="md me mf mg gt mh mi mj mk aw ml bi"><span id="273f" class="lf lg it mi b gy mm mn l mo mp">oxford        0.060545<br/>city          0.058641<br/>edinburgh     0.048436<br/>lakes         0.042927<br/>scotland      0.042927<br/>might         0.038131<br/>visited       0.037911<br/>matlock       0.036327<br/>cumberland    0.036327<br/>clerval       0.034506<br/>Name: 19, dtype: float64</span></pre><p id="516c" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="ki iu">第二十三章</strong>伊丽莎白被怪物杀死。在未能说服裁判官让这个生物负责后，维克多·沃斯让他的生命去摧毁他的创造。</p><pre class="md me mf mg gt mh mi mj mk aw ml bi"><span id="c369" class="lf lg it mi b gy mm mn l mo mp">magistrate    0.048762<br/>room          0.047945<br/>exert         0.039379<br/>pistol        0.039379<br/>arms          0.036325<br/>punishment    0.034900<br/>rushed        0.034054<br/>might         0.033068<br/>elizabeth     0.032818<br/>wandered      0.032088<br/>Name: 23, dtype: float64</span></pre><p id="6f83" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">维克多失去了所有的家人，他追踪怪物来到北方的冰雪之地。在临终前，维克多讲述了他的故事，并恳求沃尔顿在他死后继续他的追求。</p><pre class="md me mf mg gt mh mi mj mk aw ml bi"><span id="7073" class="lf lg it mi b gy mm mn l mo mp">yet             0.051022<br/>ice             0.048866<br/>vengeance       0.037918<br/>shall           0.033370<br/>still           0.031682<br/>die             0.030744<br/>frankenstein    0.030744<br/>would           0.027350<br/>death           0.026679<br/>feel            0.026679<br/>Name: 24, dtype: float64</span></pre></div><div class="ab cl mu mv hx mw" role="separator"><span class="mx bw bk my mz na"/><span class="mx bw bk my mz na"/><span class="mx bw bk my mz"/></div><div class="im in io ip iq"><h2 id="8e4f" class="lf lg it bd lh li lj dn lk ll lm dp ln kr lo lp lq kv lr ls lt kz lu lv lw lx bi translated">结论</h2><p id="5abf" class="pw-post-body-paragraph kg kh it ki b kj ly kl km kn lz kp kq kr ma kt ku kv mb kx ky kz mc lb lc ld im bi translated">看起来，至少对于这本玛丽·谢利的小说来说，<em class="le">术语频率-逆文档频率</em>算法很容易使用，并作为提取每章描述性关键词的可靠方法。所以为什么不亲自尝试一下，看看你会有什么发现呢？</p></div><div class="ab cl mu mv hx mw" role="separator"><span class="mx bw bk my mz na"/><span class="mx bw bk my mz na"/><span class="mx bw bk my mz"/></div><div class="im in io ip iq"><h2 id="4bf6" class="lf lg it bd lh li lj dn lk ll lm dp ln kr lo lp lq kv lr ls lt kz lu lv lw lx bi translated">进一步的工作</h2><p id="b174" class="pw-post-body-paragraph kg kh it ki b kj ly kl km kn lz kp kq kr ma kt ku kv mb kx ky kz mc lb lc ld im bi translated">这种和平的延续:将情感和情绪分析应用于《弗兰肯斯坦》,可以使用下面的链接找到。</p><div class="nb nc gp gr nd ne"><a rel="noopener follow" target="_blank" href="/using-sentiment-analysis-to-explore-emotions-within-text-ae48e3e93999"><div class="nf ab fo"><div class="ng ab nh cl cj ni"><h2 class="bd iu gy z fp nj fr fs nk fu fw is bi translated">使用情感分析探索文本中的情感</h2><div class="nl l"><h3 class="bd b gy z fp nj fr fs nk fu fw dk translated">应用两种自然语言处理技术来比较玛丽·雪莱的《弗兰肯斯坦》中的情感和 TF-IDF 关键词分析…</h3></div><div class="nm l"><p class="bd b dl z fp nj fr fs nk fu fw dk translated">towardsdatascience.com</p></div></div><div class="nn l"><div class="no l np nq nr nn ns jz ne"/></div></div></a></div></div></div>    
</body>
</html>