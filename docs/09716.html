<html>
<head>
<title>Building a Video Search Engine using Computer Vision</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">利用计算机视觉构建视频搜索引擎</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/building-a-video-search-engine-b93305126b59?source=collection_archive---------22-----------------------#2019-12-20">https://towardsdatascience.com/building-a-video-search-engine-b93305126b59?source=collection_archive---------22-----------------------#2019-12-20</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="35bc" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">使用萨尔萨舞视频的案例研究</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/ec320e93e96ac41ef90484c7b59ccfe4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*vOouRnfyFxVhMwLRl3QurA.jpeg"/></div></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk"><a class="ae kv" href="https://artofdance.ca/wp-content/uploads/2015/06/flam_dance_slide1.jpg" rel="noopener ugc nofollow" target="_blank">Source</a></figcaption></figure><h1 id="712f" class="kw kx iq bd ky kz la lb lc ld le lf lg jw lh jx li jz lj ka lk kc ll kd lm ln bi translated">介绍</h1><p id="0ccd" class="pw-post-body-paragraph lo lp iq lq b lr ls jr lt lu lv ju lw lx ly lz ma mb mc md me mf mg mh mi mj ij bi translated">在图像分类任务取得前所未有的进展之后，计算机视觉领域的自然进展是朝着视频和视频理解的方向发展，尤其是它如何与识别人类对象和活动相关联。正在这一领域建立一些数据集和基准。</p><p id="04d1" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">与此同时，与 2D 图像相关的计算机视觉任务正在取得进一步进展，如细粒度分类、图像分割、3D 图像构建、机器人视觉、场景流量估计和<strong class="lq ir"> <em class="mp">人体姿态估计</em> </strong>。</p><p id="3f3a" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">作为我在 Metis bootcamp 的最终数据科学项目的一部分，我决定将这两个平行的领域结合起来——具体来说是视频和人体姿势估计——以创建一个基于内容的视频搜索引擎。由于将 2D 人体姿势估计应用于视频搜索是一个“没有概念证明”的新颖想法，所以我通过选择 Salsa 舞蹈视频的单个表演者、固定位置单个摄像机视频片段来简化我的方法。</p><h1 id="f28f" class="kw kx iq bd ky kz la lb lc ld le lf lg jw lh jx li jz lj ka lk kc ll kd lm ln bi translated">录像</h1><p id="70f5" class="pw-post-body-paragraph lo lp iq lq b lr ls jr lt lu lv ju lw lx ly lz ma mb mc md me mf mg mh mi mj ij bi translated">仅次于谷歌的第二大搜索引擎 YouTube 的用户每天观看超过 10 亿小时的视频。世界上最受欢迎的社交网站脸书的用户每天观看大约 1 亿小时的视频！！这些平台对向用户提供搜索和发现感兴趣的相关内容的工具感兴趣。</p><p id="537f" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">这些平台提供的搜索工具主要使用视频的元数据(位置、时间、内容创建者等。)、标题、描述、抄本(用户创建的或机器从音频生成的)、用户评级、用户评论等。检索“相似”的结果。这些搜索工具不会浏览视频本身的实际内容。对于搜索来说，视频是不可浏览或可索引的。</p><p id="f4c9" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">视频中的视觉特征太多了，索引它们的计算成本很高，检索起来又太慢。举个例子，如果你要搜索<em class="mp">展览 1 </em>中萨尔萨舞者的舞步，目前在 YoutTube 这样的平台上还没有可供用户使用的工具。salsa 步骤没有文本上下文来执行搜索。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mq mr l"/></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk"><em class="ms">Exhibit 1: Salsa Dance Video (Credit: World Salsa Summit 2016. Dancer: Valentino Sinatra, Italy)</em></figcaption></figure><p id="6b8b" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">作为我的 Metis 项目 5 的一部分，我构建的视频搜索引擎已经索引了来自 YouTube 的大约 70 分钟的萨尔萨舞视频，并将返回一个匹配，如下面的<em class="mp">图表</em>所示。Yeifren(中)和 Adriano(右)表演的萨尔萨舞步与 Valentino(左)相似。在这些片段中，表演者走回到舞台中央，并面向舞台左侧进行多次转身。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mq mr l"/></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk"><em class="ms">Exhibit 2: A search results from the Video Search Engine (Credit: World Salsa Summit 2016. Dancers: Valentino Sinatra, Italy; Yeifren Mata, Venezuela; Adriano Leropoli, Montreal)</em></figcaption></figure><p id="d4da" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">Valentino(左)和 Yiefren(中)之间的一个非常微妙的动作是，他们都触摸/撞击他们的膝盖/腿！！它在剪辑中的时间是关闭的，但模型拿起这个！！这些片段我看了好多天都没注意到！我认为这是一个迷人的结果。</p><h1 id="5989" class="kw kx iq bd ky kz la lb lc ld le lf lg jw lh jx li jz lj ka lk kc ll kd lm ln bi translated">方法学</h1><p id="e902" class="pw-post-body-paragraph lo lp iq lq b lr ls jr lt lu lv ju lw lx ly lz ma mb mc md me mf mg mh mi mj ij bi translated">建立视频搜索引擎有两个步骤。第一步是下载和处理视频素材，并通过 OpenPose 进行特征提取。OpenPose 是卡内基梅隆大学研究人员(曹哲等人)开发的一种人体姿态估计算法。更多关于 OpenPose 的内容将在后面的章节中介绍。第二步是模型构建和测试查询指标。使用矩阵分解方法(PCA，LSA，NMF)建立模型。欧几里德距离和余弦相似性作为查询度量被测试。作为第二步的一部分，还进行了特征工程/特征表示练习，测试了每一帧的展平特征和特征的 Hu 矩。</p><p id="7353" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">所获得的“特征表示/维数减少/查询度量”的最佳组合是通过使用具有 LSA 和余弦相似性的简单平坦姿态估计。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi mt"><img src="../Images/e08b566249cde8fe3162dd5768e10c2a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*GY-N8DhYAYLJjt6u.png"/></div></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk"><em class="ms">Exhibit 3: Methodology for building a video search engine</em></figcaption></figure><h2 id="0d14" class="mu kx iq bd ky mv mw dn lc mx my dp lg lx mz na li mb nb nc lk mf nd ne lm nf bi translated">数据</h2><p id="cabb" class="pw-post-body-paragraph lo lp iq lq b lr ls jr lt lu lv ju lw lx ly lz ma mb mc md me mf mg mh mi mj ij bi translated">这个项目的数据来自处理 YouTube 萨尔萨视频(链接如下)。</p><p id="0186" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated"><strong class="lq ir">为什么是莎莎？</strong></p><p id="7179" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">除了是一种具有挑战性的舞蹈形式，涉及微妙和快速的动作，YouTube 上的许多频道还提供了独舞者的视频。对于多人视频帧，用于我的项目的特征提取的 Zhe Cao 等人的姿态估计是快速和准确的，但是那些算法不能逐帧跟踪一个人。当视频中的人交换位置时，这就产生了一个问题——比如一对夫妇在做转体/托举等动作。为了避免这种情况并简化我的问题，我选择了独舞视频。</p><p id="6408" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">我考虑过的另一种舞蹈形式是芭蕾。然而，女舞者的服装(读芭蕾短裙！)会导致假阳性，如在芭蕾中常见的某些舞蹈姿势的膝盖。</p><p id="cc75" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">我收集的萨尔萨舞片段来自以下四个总时长为 160 分钟的视频。这个镜头被处理到 70 分钟，并被格式化成 3 秒钟的剪辑。处理后的视频由大约 30 名艺术家的大约 58 场表演组成。</p><p id="fa86" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">这些视频是:</p><ul class=""><li id="c263" class="ng nh iq lq b lr mk lu ml lx ni mb nj mf nk mj nl nm nn no bi translated">【https://www.youtube.com/watch?v=4nHElVbT3HY T4】</li><li id="efb8" class="ng nh iq lq b lr np lu nq lx nr mb ns mf nt mj nl nm nn no bi translated"><a class="ae kv" href="https://www.youtube.com/watch?v=ITNiqNcl6Mw" rel="noopener ugc nofollow" target="_blank">https://www.youtube.com/watch?v=ITNiqNcl6Mw</a></li><li id="fac8" class="ng nh iq lq b lr np lu nq lx nr mb ns mf nt mj nl nm nn no bi translated"><a class="ae kv" href="https://www.youtube.com/watch?v=L5mqL7ADEsY" rel="noopener ugc nofollow" target="_blank">https://www.youtube.com/watch?v=L5mqL7ADEsY</a></li><li id="3977" class="ng nh iq lq b lr np lu nq lx nr mb ns mf nt mj nl nm nn no bi translated"><a class="ae kv" href="https://www.youtube.com/watch?v=M_rPhEjym1o" rel="noopener ugc nofollow" target="_blank">https://www.youtube.com/watch?v=M_rPhEjym1o</a></li></ul><p id="28d7" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">总而言之，所用的视频包括:</p><ol class=""><li id="11b1" class="ng nh iq lq b lr mk lu ml lx ni mb nj mf nk mj nu nm nn no bi translated">单身舞者</li><li id="9705" class="ng nh iq lq b lr np lu nq lx nr mb ns mf nt mj nu nm nn no bi translated">固定位置的单个摄像机的镜头(没有移动的摄像机！).只有摄像机角度和缩放级别会反映在素材中。</li><li id="d11d" class="ng nh iq lq b lr np lu nq lx nr mb ns mf nt mj nu nm nn no bi translated">视频帧速率从原来的 24 帧/秒降低到 8 帧/秒。</li><li id="616e" class="ng nh iq lq b lr np lu nq lx nr mb ns mf nt mj nu nm nn no bi translated">固定屏幕分辨率为 640(宽)X 360(高)像素。</li><li id="5f62" class="ng nh iq lq b lr np lu nq lx nr mb ns mf nt mj nu nm nn no bi translated">大约 70 分钟的经过处理的镜头，并格式化为 3 秒钟的剪辑(超过 1，400 次观察)。</li></ol><p id="b2c1" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated"><strong class="lq ir"> OpenPose:实时 2D 多人姿态估计算法</strong></p><p id="4cb6" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">人体姿态估计是识别图像或视频中人体解剖“关键点”的计算机视觉问题。在过去的几年里，许多研究人员取得了令人难以置信的进展，并展示了实时性能⁴.卡内基梅隆大学机器人研究所的曹哲等人使用“自下而上”的方法赢得了首届 COCO 2016 关键点挑战。他们使用安装了 GPU 的笔记本电脑实现了实时速度。</p><p id="9751" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">姿态估计用于对图像/视频剪辑中的人类活动进行分类。它们主要应用于 2D 图像，但从未用于视频搜索目标。下面是 OpenPose 如何在 2D 图像中识别一个人的 18 个关键点的示例(为了简单起见，只显示了 14 个关键点)。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nv"><img src="../Images/7458ee207d900b4a8dacad06e55bb48b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*ZFP6Li6__Kcr_DZY.png"/></div></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk"><em class="ms">Exhibit 4: OpenPose on a 2D Image Identifying Keypoints</em></figcaption></figure><p id="5e65" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">当识别出视频中每一帧的关键点时，结果将如下面的<em class="mp">展示 5 &amp; 6 </em>所示。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mq mr l"/></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk"><em class="ms">Exhibit 5: OpenPose on a Salsa Dance Video Identifying Keypoints</em></figcaption></figure><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mq mr l"/></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk"><em class="ms">Exhibit 6: Spatio-temporal features extracted from OpenPose</em></figcaption></figure><h1 id="718b" class="kw kx iq bd ky kz la lb lc ld le lf lg jw lh jx li jz lj ka lk kc ll kd lm ln bi translated">结果</h1><p id="71ae" class="pw-post-body-paragraph lo lp iq lq b lr ls jr lt lu lv ju lw lx ly lz ma mb mc md me mf mg mh mi mj ij bi translated">下面显示了索引 salsa 视频并使用余弦相似度进行搜索的一些结果。右上方的视频是搜索片段，搜索结果要从左到右读，然后从上到下。</p><p id="f9b1" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">请注意，搜索引擎索引在检索舞者正走向他们的位置的视频剪辑时是充分有效的(<em class="mp">展示 7 </em>)。这本身就是一个有趣的结果，并展示了这种索引方法如何用于视频编辑。即使对于 2.5 小时的“小的”未处理的镜头，手动编辑这些剪辑也将花费数小时，而搜索引擎运行(后期索引)不到一秒钟，并且能够找到镜头中所有这种剪辑的时间戳。这使得视频编辑更加自动化和快速。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mq mr l"/></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk"><em class="ms">Exhibit 7: Search using a Clip of Dancers Making an Entry</em></figcaption></figure><h2 id="c0c7" class="mu kx iq bd ky mv mw dn lc mx my dp lg lx mz na li mb nb nc lk mf nd ne lm nf bi translated">更多的结果</h2><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mq mr l"/></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk"><em class="ms">Exhibit 8: Dancers Performing Turns</em></figcaption></figure><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mq mr l"/></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk"><em class="ms">Exhibit 9: Turn while bearing to the left (&amp; swoop down!)</em></figcaption></figure><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mq mr l"/></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk"><em class="ms">Exhibit 10: Moving to the left and a turn</em></figcaption></figure><h1 id="9e24" class="kw kx iq bd ky kz la lb lc ld le lf lg jw lh jx li jz lj ka lk kc ll kd lm ln bi translated">其他应用</h1><p id="3467" class="pw-post-body-paragraph lo lp iq lq b lr ls jr lt lu lv ju lw lx ly lz ma mb mc md me mf mg mh mi mj ij bi translated">像这样的视频搜索引擎有很多应用。下面列出了一些例子:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nw"><img src="../Images/a83a6fc531f192061d97d442d7bfc68b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*3qq_Kx73YuZBYJBw.png"/></div></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk"><em class="ms">Exhibit 8: Other Applications for Video Search Engine</em></figcaption></figure><p id="ecd2" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">对于像 YouTube 和脸书这样的平台如何在他们当前的网站上使用视频搜索，我有更多的想法。一些概念性的想法如下所示:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nv"><img src="../Images/cc890c2292794541edd686f7980d4169.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*t03GUWLvUxq8ktyn.png"/></div></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk"><em class="ms">Exhibit 9: A Conceptual Layout of Video Search on YouTube Salsa Videos</em></figcaption></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nv"><img src="../Images/1f4b0eb91387305e2c6cf73bbdf1a001.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*l9cRlcDdgiHJndvf.png"/></div></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk"><em class="ms">Exhibit 10: A Conceptual Layout of Video Search on YouTube Football Game Videos</em></figcaption></figure><h1 id="e04f" class="kw kx iq bd ky kz la lb lc ld le lf lg jw lh jx li jz lj ka lk kc ll kd lm ln bi translated">参考</h1><ol class=""><li id="1eb0" class="ng nh iq lq b lr ls lu lv lx nx mb ny mf nz mj nu nm nn no bi translated">南 Abu-El-Haija 等人<a class="ae kv" href="https://arxiv.org/pdf/1609.08675.pdf" rel="noopener ugc nofollow" target="_blank"> YouTube-8M:大规模视频分类基准</a>。<em class="mp"> arXiv:1609.08675be </em>，2016</li><li id="f1d8" class="ng nh iq lq b lr np lu nq lx nr mb ns mf nt mj nu nm nn no bi translated">曹哲等人，<a class="ae kv" href="https://arxiv.org/pdf/1611.08050.pdf" rel="noopener ugc nofollow" target="_blank">利用局部亲和场的实时多人 2D 姿态估计(2017) </a>，CVPR</li><li id="4c42" class="ng nh iq lq b lr np lu nq lx nr mb ns mf nt mj nu nm nn no bi translated">曹哲等，<a class="ae kv" href="https://github.com/ZheC/Realtime_Multi-Person_Pose_Estimation" rel="noopener ugc nofollow" target="_blank"> Github to OpenPose </a> (2017)</li><li id="d323" class="ng nh iq lq b lr np lu nq lx nr mb ns mf nt mj nu nm nn no bi translated">德里克·姆维蒂，<a class="ae kv" href="https://heartbeat.fritz.ai/a-2019-guide-to-human-pose-estimation-c10b79b64b73" rel="noopener ugc nofollow" target="_blank">2019 年人体姿势估计指南</a> (2019)，中等文章</li></ol></div><div class="ab cl oa ob hu oc" role="separator"><span class="od bw bk oe of og"/><span class="od bw bk oe of og"/><span class="od bw bk oe of"/></div><div class="ij ik il im in"><p id="b58a" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated"><em class="mp">最初发布于</em><a class="ae kv" href="https://mlbhanuyerra.github.io/2019-12-09-Video-Search-Engine-Salsa/" rel="noopener ugc nofollow" target="_blank"><em class="mp">https://mlbhanuyerra . github . io</em></a><em class="mp">。</em></p></div></div>    
</body>
</html>