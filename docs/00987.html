<html>
<head>
<title>Demystifying — Deep Image Prior</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">去神秘化——深度图像先验</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/demystifying-deep-image-prior-7076e777e5ba?source=collection_archive---------11-----------------------#2019-02-15">https://towardsdatascience.com/demystifying-deep-image-prior-7076e777e5ba?source=collection_archive---------11-----------------------#2019-02-15</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="6dab" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">使用深度图像先验的图像恢复介绍。</h2></div><p id="74e8" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在这篇文章中，我将主要关注图像恢复的任务，以及如何使用之前的<a class="ae lb" href="https://dmitryulyanov.github.io/deep_image_prior" rel="noopener ugc nofollow" target="_blank">深度图像来解决这个任务。</a></p><h1 id="050e" class="lc ld iq bd le lf lg lh li lj lk ll lm jw ln jx lo jz lp ka lq kc lr kd ls lt bi translated">图像恢复简介</h1><p id="0253" class="pw-post-body-paragraph kf kg iq kh b ki lu jr kk kl lv ju kn ko lw kq kr ks lx ku kv kw ly ky kz la ij bi translated">图像恢复是指从退化图像中恢复未知真实图像的任务。图像退化可能发生在图像形成、传输和存储过程中。这一任务在卫星成像、弱光摄影中具有广泛的应用范围，并且由于数字技术、计算和通信技术的进步，从退化图像中恢复干净图像是非常重要的，因此已经发展成为与图像处理、计算机视觉和计算成像交叉的研究领域。</p><p id="070a" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">图像恢复主要有三个任务:</p><h2 id="4e6e" class="lz ld iq bd le ma mb dn li mc md dp lm ko me mf lo ks mg mh lq kw mi mj ls mk bi translated"><strong class="ak">图像去噪:</strong></h2><p id="a592" class="pw-post-body-paragraph kf kg iq kh b ki lu jr kk kl lv ju kn ko lw kq kr ks lx ku kv kw ly ky kz la ij bi translated">图像去噪是指恢复被加性噪声污染的图像。这是图像恢复中最简单的任务，因此已经被几个技术团体广泛研究。</p><figure class="mm mn mo mp gt mq gh gi paragraph-image"><div role="button" tabindex="0" class="mr ms di mt bf mu"><div class="gh gi ml"><img src="../Images/d7ef517e4d203df7c6aea7dd24bd5027.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*BvkEVxCg7Egc2hslEwDsQg.png"/></div></div><figcaption class="mx my gj gh gi mz na bd b be z dk">Fig.1 (left)noise add image, (center)true image, (right)Gaussian noise</figcaption></figure><h2 id="f81e" class="lz ld iq bd le ma mb dn li mc md dp lm ko me mf lo ks mg mh lq kw mi mj ls mk bi translated">2.<strong class="ak">超分辨率:</strong></h2><p id="f23a" class="pw-post-body-paragraph kf kg iq kh b ki lu jr kk kl lv ju kn ko lw kq kr ks lx ku kv kw ly ky kz la ij bi translated">超分辨率是指从一组低分辨率图像产生高分辨率图像(或高分辨率图像序列)的过程。</p><figure class="mm mn mo mp gt mq gh gi paragraph-image"><div class="gh gi nb"><img src="../Images/b928b7c15c6a771b5919044e630642ac.png" data-original-src="https://miro.medium.com/v2/resize:fit:954/0*8YSRshYdby4VRZYI"/></div><figcaption class="mx my gj gh gi mz na bd b be z dk">Fig2. (left)low resolution image, (right)high resolution image</figcaption></figure><p id="5959" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir"> 3 </strong>。<strong class="kh ir">图像补绘:</strong> <br/>图像补绘是对图像中丢失或损坏的部分进行重建的过程。内画实际上是一种古老的艺术，需要人类来画出画中已经变质和丢失的部分。但是在今天的世界中，研究已经提出了许多方法来使用深度卷积网络来自动完成这项任务。</p><figure class="mm mn mo mp gt mq gh gi paragraph-image"><div class="gh gi nc"><img src="../Images/73265848527d43e2357276ea16b89f31.png" data-original-src="https://miro.medium.com/v2/resize:fit:1156/0*lZQmmVChFdv7ugDg"/></div><figcaption class="mx my gj gh gi mz na bd b be z dk">Fig. 3 (left) input, (right) output</figcaption></figure><h1 id="c48f" class="lc ld iq bd le lf lg lh li lj lk ll lm jw ln jx lo jz lp ka lq kc lr kd ls lt bi translated">什么是深度图像先验？</h1><p id="6c7d" class="pw-post-body-paragraph kf kg iq kh b ki lu jr kk kl lv ju kn ko lw kq kr ks lx ku kv kw ly ky kz la ij bi translated">随着 alexnet 在 2012 年 image-net 竞赛中的成功，卷积神经网络变得非常流行，已经用于每个计算机视觉和图像处理任务，并且已经广泛用于执行逆图像重建任务，并且已经实现了最先进的性能。<br/>深度卷积网络已经取得了成功，因为它们能够从大量图像数据集进行学习。Dmitry Ulyanov 的惊人论文“Deep Image Prior”表明，为了解决像图像恢复这样的逆问题，网络的结构是足够的，并且施加了强先验以从降级图像恢复原始图像。该论文强调，为了执行这些任务，不需要预先训练的网络或大型图像数据集，并且可以仅在考虑降质图像的情况下执行。</p><p id="93eb" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">为了完成图像恢复的任务，学习先验和显式先验是研究人员常用的两种方法。</p><p id="056f" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在学习-先验中是一种训练深度卷积网络的直接方法，以通过数据集学习世界，该数据集将有噪声的图像作为输入，将干净的图像作为期望的输出。<br/>另一方面，explicit-prior 或手工制作的 prior 方法，是我们在其中嵌入硬约束并教导什么类型的图像是自然的、人脸等。从合成数据中。像自然这样用数学表达约束是非常困难的。</p><p id="b967" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在深度图像先验中，作者试图通过使用卷积神经网络构造一个新的显式先验来弥补两种流行方法之间的差距。</p><h1 id="e00f" class="lc ld iq bd le lf lg lh li lj lk ll lm jw ln jx lo jz lp ka lq kc lr kd ls lt bi translated">让我们从技术角度出发...</h1><figure class="mm mn mo mp gt mq gh gi paragraph-image"><div role="button" tabindex="0" class="mr ms di mt bf mu"><div class="gh gi nd"><img src="../Images/43997967fe8ca522d06b99d2606f3c13.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*xL0uDxiwEoJD-etk-ZqTag.png"/></div></div><figcaption class="mx my gj gh gi mz na bd b be z dk">Fig.4. (left)clean image, (center)corrupted image, (left) restored image</figcaption></figure><p id="3d0e" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir"> <em class="ne"> x </em> </strong> → <em class="ne">干净图像<br/></em><strong class="kh ir"><em class="ne">ẋ</em></strong><em class="ne"/>→<em class="ne">退化图像<br/></em><strong class="kh ir"><em class="ne">x</em>*</strong>→<em class="ne">恢复图像</em></p><p id="e0d4" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们可以使用最大后验分布来估计经验数据中的未观测值</p><figure class="mm mn mo mp gt mq gh gi paragraph-image"><div role="button" tabindex="0" class="mr ms di mt bf mu"><div class="gh gi nf"><img src="../Images/70b84d850e6ea408b6d148cbc93b23d7.png" data-original-src="https://miro.medium.com/v2/resize:fit:678/format:webp/1*iPfmLB_y60FL2-cHDBfgOQ.png"/></div></div></figure><p id="c26f" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">使用贝叶斯规则，我们可以将其表示为<em class="ne">似然*先验。</em></p><figure class="mm mn mo mp gt mq gh gi paragraph-image"><div class="gh gi ng"><img src="../Images/c82b7c3a38c9b0a2d45494be794895dd.png" data-original-src="https://miro.medium.com/v2/resize:fit:906/format:webp/1*6ERRM0kRgaNY6f0i0jZ2Dg.png"/></div></figure><p id="d68a" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们可以通过对等式应用负算法，将等式公式化为优化问题，而不是分别处理分布。(1)</p><figure class="mm mn mo mp gt mq gh gi paragraph-image"><div class="gh gi nc"><img src="../Images/8463efaa242c1c067b1d6a54ad888f52.png" data-original-src="https://miro.medium.com/v2/resize:fit:1156/format:webp/1*wKyayNFE9tttAX1s4iv-Ig.png"/></div></figure><p id="442a" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">e(x；ẋ) <em class="ne"> </em>是作为似然负对数的数据项，R(x)是作为先验负对数的图像先验项。</p><p id="1aad" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">现在的任务是在图像<em class="ne"> x </em>上最小化等式(2)。传统的方法是用随机噪声初始化<em class="ne"> x </em>，然后计算函数相对于 x 的梯度，并遍历图像空间，直到我们收敛到某个点。</p><figure class="mm mn mo mp gt mq gh gi paragraph-image"><div role="button" tabindex="0" class="mr ms di mt bf mu"><div class="gh gi nh"><img src="../Images/0f69e79b10e03e2559e52b36a5c5d288.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*RW00udUCVSO97ngnck5S6w.png"/></div></div><figcaption class="mx my gj gh gi mz na bd b be z dk">Fig. 5 visualization of regular approach</figcaption></figure><p id="9a3e" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">另一种方法是构造一个函数<em class="ne"> g </em>，它用随机θ初始化，来自不同空间的输出可以映射到图像 x，并使用梯度下降更新θ，直到它收敛到某个点。因此，我们可以在θ上优化，而不是在图像空间上优化。</p><figure class="mm mn mo mp gt mq gh gi paragraph-image"><div class="gh gi ni"><img src="../Images/527a0c4404d1799dcd0a1fae31d4b379.png" data-original-src="https://miro.medium.com/v2/resize:fit:946/format:webp/1*S633mrGqye6GHRk5milh_Q.png"/></div></figure><figure class="mm mn mo mp gt mq gh gi paragraph-image"><div role="button" tabindex="0" class="mr ms di mt bf mu"><div class="gh gi nj"><img src="../Images/f8174f44c4467c8997b59d3ecb1663d6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*cd862SkDaQUIk8ap7E8_gQ.png"/></div></div><figcaption class="mx my gj gh gi mz na bd b be z dk">FIg. 6 Visualization of parameterized approach</figcaption></figure><p id="fcbf" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">但是，为什么这种方法是可能的，为什么我们应该使用它？。这是可能的，因为从理论上讲，如果 g 是满射的<strong class="kh ir"><em class="ne">g:θ</em>↦<em class="ne">x</em></strong>(如果至少有一个<em class="ne"> θ </em> <strong class="kh ir"> <em class="ne"> </em> </strong>映射到图像<em class="ne"> x </em>)那么这个优化问题是等价的，即它们有相同的解。但在实践中，<em class="ne"> g </em>在优化方法搜索图像空间的方式上发生了巨大的变化。我们实际上可以把<em class="ne"> g </em>作为超参数来对待，并对其进行调优。如果我们观察，g(θ)作为一个先验，有助于选择一个好的映射<em class="ne"> </em>，它给出一个期望的输出图像，并防止使用得到错误的图像。<br/>所以，与其优化两个分量之和。我们现在将只优化第一项。</p><p id="face" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">现在，Eq 2。可以表示为，</p><figure class="mm mn mo mp gt mq gh gi paragraph-image"><div class="gh gi nk"><img src="../Images/46c73915f1561b75b7902c3ec44c2e2c.png" data-original-src="https://miro.medium.com/v2/resize:fit:656/format:webp/1*2K4vwbcsFpHMdefin8gmdA.png"/></div></figure><p id="f80f" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">其中，<em class="ne"> z </em>是随机固定输入图像，θ是随机初始化的权重，其将使用梯度下降来更新，以获得期望的输出图像。</p><p id="0a6d" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">但是仍然不清楚为什么我们应该考虑这种参数化方法。理论上乍一看，它似乎会产生原始噪声图像。在论文中，作者进行了一项实验，该实验表明，当使用梯度下降来优化网络时，卷积神经网络不愿意噪声图像，并且更快和更容易地下降到看起来自然的图像。</p><figure class="mm mn mo mp gt mq gh gi paragraph-image"><div class="gh gi nl"><img src="../Images/e729738251b8c9b41c57dd8d7b97ad28.png" data-original-src="https://miro.medium.com/v2/resize:fit:876/format:webp/1*dtD74AtEgunTUdzMEZ2DRA.png"/></div><figcaption class="mx my gj gh gi mz na bd b be z dk">Fig. 7 Learning curves for the reconstruction task using: a natural image, the same plus i.i.d. noise, the same<br/>randomly scrambled, and white noise. Naturally-looking images result in much faster convergence, whereas noise is rejected.</figcaption></figure><h1 id="306e" class="lc ld iq bd le lf lg lh li lj lk ll lm jw ln jx lo jz lp ka lq kc lr kd ls lt bi translated">逐步深入图像先验</h1><p id="a753" class="pw-post-body-paragraph kf kg iq kh b ki lu jr kk kl lv ju kn ko lw kq kr ks lx ku kv kw ly ky kz la ij bi translated"><em class="ne"> ẋ =被破坏的图像</em>(被观察)<br/> <strong class="kh ir"> 1。初始化<em class="ne">z</em>T8<em class="ne">。</em>:用均匀噪声或任何其它随机图像填充输入<em class="ne"> z。</em></strong></p><p id="17ca" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir"> 2。使用基于梯度的方法求解</strong>并优化函数。</p><figure class="mm mn mo mp gt mq gh gi paragraph-image"><div class="gh gi nm"><img src="../Images/18d542de5090d6241f499126c6833b5f.png" data-original-src="https://miro.medium.com/v2/resize:fit:750/format:webp/1*Ho33drLF62gsFC_9svKrpQ.png"/></div></figure><p id="4024" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">3.最后，当我们找到最佳θ时，我们可以<strong class="kh ir">获得最佳图像</strong>，只需将固定输入<em class="ne"> z </em>正向传递给具有参数θ的网络。</p><figure class="mm mn mo mp gt mq gh gi paragraph-image"><div class="gh gi nn"><img src="../Images/e1e0a9d7ff8779779d8e0ec4c7c267cb.png" data-original-src="https://miro.medium.com/v2/resize:fit:370/format:webp/1*YW51yFjnjQtKrREJj4Qd7A.png"/></div></figure><figure class="mm mn mo mp gt mq gh gi paragraph-image"><div role="button" tabindex="0" class="mr ms di mt bf mu"><div class="gh gi no"><img src="../Images/1e62169c6af478dc84d2dff6f55cb6c1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*JZRn2y0LIKqP9vhcPf6nVA.png"/></div></div><figcaption class="mx my gj gh gi mz na bd b be z dk">Fig. 8: Image restoration using the deep image prior. Starting from a random weights θ 0 , we iteratively<br/>update them in order to minimize the data term eq. (2). At every iteration the weights θ are mapped to image<br/>x = f θ (z), where z is a fixed tensor and the mapping f is a neural network with parameters θ. The image x is<br/>used to compute the task-dependent loss E(x, x 0 ). The gradient of the loss w.r.t. the weights θ is then computed and used to update the parameters.</figcaption></figure><h1 id="ce0b" class="lc ld iq bd le lf lg lh li lj lk ll lm jw ln jx lo jz lp ka lq kc lr kd ls lt bi translated">结论</h1><p id="2331" class="pw-post-body-paragraph kf kg iq kh b ki lu jr kk kl lv ju kn ko lw kq kr ks lx ku kv kw ly ky kz la ij bi translated">该论文试图表明，在具有随机化权重的深度卷积神经网络结构内构造隐式先验的方法非常适合于图像恢复任务。该论文中显示的结果在很大程度上表明，适当手工制作的网络架构足以解决图像恢复任务。</p></div></div>    
</body>
</html>