<html>
<head>
<title>How least squares regression estimates are actually calculated</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">最小二乘回归估计实际上是如何计算的</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/how-least-squares-regression-estimates-are-actually-calculated-662d237a4d7e?source=collection_archive---------14-----------------------#2019-12-31">https://towardsdatascience.com/how-least-squares-regression-estimates-are-actually-calculated-662d237a4d7e?source=collection_archive---------14-----------------------#2019-12-31</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="62e7" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">理解模型输出是如何计算的，有助于理解它们的解释</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/d16d57edcf6bb9d375d2c8aee19943e3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*YwB7i65fbxLjFSABC0izow.jpeg"/></div></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk">FWStudio from Pexels</figcaption></figure><p id="1cd7" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">普通最小二乘法是线性回归用来获得参数估计的一种方法。这需要拟合一条线，使得从每个点到回归线的平方距离之和(残差)最小。让我们在下面的图表中想象一下，红线是回归线，蓝线是残差。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi lr"><img src="../Images/fe3b08a95679e65fc94b7e58f997631e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*tQkyTR9yxDcS1GKVFhdQQA.jpeg"/></div></div></figure><p id="84fc" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">下面，我将首先介绍一个例子，然后说明如何使用残差来估计线性模型的参数。然后，我将展示如何计算汇总输出中的每个值。总之，这将揭示普通最小二乘法的内部工作原理，并演示它们是如何结合在一起的。</p><h1 id="5e70" class="ls lt iq bd lu lv lw lx ly lz ma mb mc jw md jx me jz mf ka mg kc mh kd mi mj bi translated"><strong class="ak">根据 GPA 预测 ACT 成绩</strong></h1><p id="6960" class="pw-post-body-paragraph kv kw iq kx b ky mk jr la lb ml ju ld le mm lg lh li mn lk ll lm mo lo lp lq ij bi translated">目标是根据学生的 GPA 预测学生的 ACT 分数。我们首先制作一个包含 15 个 ACT 成绩和 GPA 的数据框架。然后，我们使用 lm 函数创建线性模型。</p><pre class="kg kh ki kj gt mp mq mr ms aw mt bi"><span id="ada3" class="mu lt iq mq b gy mv mw l mx my">gpa = c(2.931,3.682,3.113,3.910,2.568,<br/> 3.292,3.684,3.835,3.180,3.516,<br/> 3.358,2.801,2.729,3.989,2.679)<br/>act = c(28,31,26,36,27,31,28,34,29,32,28,24,30,33,26)<br/>df = data.frame(cbind(gpa,act))</span><span id="9c8e" class="mu lt iq mq b gy mz mw l mx my">mod = lm(act~gpa,data=df)<br/>summary(mod)</span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi na"><img src="../Images/42dcda2754ef024ee89baf9c83d16778.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ARFhX5jAYPW6usRRb9czNA.png"/></div></div></figure><p id="fbeb" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated"><em class="nb">act</em>= 11.877+5.376 *<em class="nb">GPA</em></p><p id="1c78" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">我们看到<em class="nb"> gpa </em>由低 p 值支持，这表明它是<em class="nb"> act </em>的强预测因子。估计是 5.376，这意味着 gpa 每增加 1.0，我们预计 ACT 会增加 5.376 个点。让我们看看汇总表中这些不同的值是从哪里来的。</p><h1 id="e01a" class="ls lt iq bd lu lv lw lx ly lz ma mb mc jw md jx me jz mf ka mg kc mh kd mi mj bi translated">平方和</h1><p id="53e6" class="pw-post-body-paragraph kv kw iq kx b ky mk jr la lb ml ju ld le mm lg lh li mn lk ll lm mo lo lp lq ij bi translated">下图中每个点是<em class="nb"> yᵢ，</em>每个预测值是<em class="nb"> ŷᵢ </em>，平均值是<em class="nb"> ȳ </em>。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nc"><img src="../Images/f7ec1c8a3fb43ac660fc13795a65a394.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Gl4TWXfooGAeW4cVI9bgUQ.png"/></div></div></figure><p id="4577" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated"><strong class="kx ir">残差平方和(RSS/SSE) </strong></p><blockquote class="nd ne nf"><p id="d8b6" class="kv kw nb kx b ky kz jr la lb lc ju ld ng lf lg lh nh lj lk ll ni ln lo lp lq ij bi translated">eᵢ = yᵢ - ŷᵢ</p></blockquote><p id="276b" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">第<em class="nb">个</em>残差是第<em class="nb">个</em>实际值和第<em class="nb">个</em>预测值之间的差值(蓝线)。<strong class="kx ir">各残差平方之和为 RSS。这是为了得到我们的 beta 估计而最小化的。</strong></p><blockquote class="nd ne nf"><p id="6937" class="kv kw nb kx b ky kz jr la lb lc ju ld ng lf lg lh nh lj lk ll ni ln lo lp lq ij bi translated">回想一下，ŷ = b₀ + b₁x</p><p id="5f2f" class="kv kw nb kx b ky kz jr la lb lc ju ld ng lf lg lh nh lj lk ll ni ln lo lp lq ij bi translated">因此，eᵢ = yᵢ - ŷᵢ = yᵢ - b₀ - b₁xᵢ</p><p id="d5c4" class="kv kw nb kx b ky kz jr la lb lc ju ld ng lf lg lh nh lj lk ll ni ln lo lp lq ij bi translated">RSS =σ(yᵢ-b₀-b₁xᵢ)</p></blockquote><p id="7b0d" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">我们首先对 RSS 取相对于<em class="nb"> b₀ </em>和<em class="nb"> b₁ </em>的偏导数，然后将它们设置为零。</p><blockquote class="nd ne nf"><p id="667a" class="kv kw nb kx b ky kz jr la lb lc ju ld ng lf lg lh nh lj lk ll ni ln lo lp lq ij bi translated">∂rss/∂b₀=-2σ(yᵢ-b₀-b₁xᵢ)</p><p id="d94f" class="kv kw nb kx b ky kz jr la lb lc ju ld ng lf lg lh nh lj lk ll ni ln lo lp lq ij bi translated">b₀ = ȳ - b₁x̄</p><p id="d452" class="kv kw nb kx b ky kz jr la lb lc ju ld ng lf lg lh nh lj lk ll ni ln lo lp lq ij bi translated">∂rss/∂b₁=-2σ(yᵢ-b₀-b₁xᵢ)xᵢ</p><p id="d6b2" class="kv kw nb kx b ky kz jr la lb lc ju ld ng lf lg lh nh lj lk ll ni ln lo lp lq ij bi translated">b₁=(σ(xᵢ-x̄)(yᵢ-ȳ))/σ(xᵢ-x̄)= sxy/sxx</p></blockquote><p id="2413" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">让我们用上面的公式看看结果，从<em class="nb"> b₁.开始</em></p><pre class="kg kh ki kj gt mp mq mr ms aw mt bi"><span id="0478" class="mu lt iq mq b gy mv mw l mx my">avg_act = mean(df$act)<br/>avg_gpa = mean(df$gpa)<br/>b1 = sum((df$gpa - avg_gpa)*(df$act - avg_act))/sum((df$gpa - avg_gpa)**2)</span></pre><p id="6956" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">这得出 5.376。请注意，这与 lm 估计的<em class="nb"> gpa </em>相匹配。太好了，让我们为 b₀.重复这个过程</p><pre class="kg kh ki kj gt mp mq mr ms aw mt bi"><span id="7373" class="mu lt iq mq b gy mv mw l mx my">b0 = avg_act - b1*(avg_gpa)</span></pre><p id="090f" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">这得到 11.877，与截距估计值相匹配。很好，我们已经展示了如何计算参数估计，但现在我们需要测试它们的重要性。让我们先来看看与 RSS 密切相关的另外两个值。</p><p id="8965" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated"><strong class="kx ir">平方和回归(SSReg) </strong></p><blockquote class="nd ne nf"><p id="e3c9" class="kv kw nb kx b ky kz jr la lb lc ju ld ng lf lg lh nh lj lk ll ni ln lo lp lq ij bi translated">σ(ŷᵢ-ȳ)</p></blockquote><p id="82aa" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">这将对预测值和平均值之间的平方差求和。换句话说，这衡量了回归线解释了多少平方和。回头参考前面的图来想象一下。</p><p id="bed8" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated"><strong class="kx ir">总平方和(SST) </strong></p><blockquote class="nd ne nf"><p id="8682" class="kv kw nb kx b ky kz jr la lb lc ju ld ng lf lg lh nh lj lk ll ni ln lo lp lq ij bi translated">σ(yᵢ-ȳ)</p><p id="51f5" class="kv kw nb kx b ky kz jr la lb lc ju ld ng lf lg lh nh lj lk ll ni ln lo lp lq ij bi translated">SST = RSS + SSReg</p></blockquote><p id="66e1" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">让我们检查一下这个等式对我们的例子是否成立。</p><pre class="kg kh ki kj gt mp mq mr ms aw mt bi"><span id="7532" class="mu lt iq mq b gy mv mw l mx my">rss = sum(((df$act - fitted.values(mod)))**2)<br/>ssreg = sum(((fitted.values(mod) - avg_act))**2)<br/>sst = sum(((df$act - avg_act))**2)<br/>all.equal((rss+ssreg),sst)</span></pre><h1 id="5572" class="ls lt iq bd lu lv lw lx ly lz ma mb mc jw md jx me jz mf ka mg kc mh kd mi mj bi translated">将 RSS、SSReg 和 SST 与摘要输出相关联</h1><p id="d4eb" class="pw-post-body-paragraph kv kw iq kx b ky mk jr la lb ml ju ld le mm lg lh li mn lk ll lm mo lo lp lq ij bi translated"><strong class="kx ir">残差标准误差</strong></p><p id="90d0" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">假设我们的误差是独立的，同方差的，正态分布，均值为 0，方差为σ。残差可用于创建误差方差的无偏估计。剩余标准误差是这个σ估计量的平方根。这让我们知道我们的点离回归线有多远。</p><pre class="kg kh ki kj gt mp mq mr ms aw mt bi"><span id="6f5b" class="mu lt iq mq b gy mv mw l mx my">n = nrow(df)<br/>p = 1<br/>rse = sqrt(rss/(n-p-1))</span></pre><p id="7efb" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">这里，p 是非截距预测值的数量。在我们的 SLR 例子中，我们只有一个预测器，所以分母变成 n-2。</p><p id="6c6a" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated"><strong class="kx ir">性病。(参数估计的)误差</strong></p><blockquote class="nd ne nf"><p id="9a2c" class="kv kw nb kx b ky kz jr la lb lc ju ld ng lf lg lh nh lj lk ll ni ln lo lp lq ij bi translated">var(<em class="iq">b₀</em>| x)=σ[(1/n)+(x̄/sxx)]</p></blockquote><pre class="kg kh ki kj gt mp mq mr ms aw mt bi"><span id="4a6d" class="mu lt iq mq b gy mv mw l mx my">sxx = sum((df$gpa - avg_gpa)**2)<br/>sigma_squared = rss/(n-p-1)</span><span id="7d05" class="mu lt iq mq b gy mz mw l mx my">var_b0 = sigma_squared*((1/n)+(avg_gpa**2/sxx))<br/>se_b0 = sqrt(var_b0)</span></pre><blockquote class="nd ne nf"><p id="4f73" class="kv kw nb kx b ky kz jr la lb lc ju ld ng lf lg lh nh lj lk ll ni ln lo lp lq ij bi translated">Var( <em class="iq"> b₁ </em> |X) = σ /SXX</p></blockquote><pre class="kg kh ki kj gt mp mq mr ms aw mt bi"><span id="c2c4" class="mu lt iq mq b gy mv mw l mx my">var_b1 = (rss/(n-p-1))/(sxx)<br/>se_b1 = sqrt(var_b1)</span></pre><p id="82b8" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated"><strong class="kx ir"> t 值</strong></p><p id="20d3" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">t 统计量的计算方法是将β估计值除以它们的标准误差。分子是标准的正态变量，分母是具有 n-p-1 个自由度的卡方变量的平方根。因此，这些统计数据遵循具有 n-p-1 个自由度的 t 分布。</p><pre class="kg kh ki kj gt mp mq mr ms aw mt bi"><span id="5342" class="mu lt iq mq b gy mv mw l mx my">t_b0 = b0/se_b0<br/>t_b1 = b1/se_b1<br/>2*pt(t_b0,n-p-1,lower.tail=F)<br/>2*pt(t_b1,n-p-1,lower.tail=F)</span></pre><p id="9d2f" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated"><strong class="kx ir">多重 R 平方</strong></p><blockquote class="nd ne nf"><p id="9657" class="kv kw nb kx b ky kz jr la lb lc ju ld ng lf lg lh nh lj lk ll ni ln lo lp lq ij bi translated">R = SSReg/SST = 1 - RSS/SST</p></blockquote><p id="5607" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">换句话说，R 是回归线(SSReg)对总方差(SST)解释的方差的度量。</p><p id="c749" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated"><strong class="kx ir">调整后的 R 平方</strong></p><blockquote class="nd ne nf"><p id="ac6b" class="kv kw nb kx b ky kz jr la lb lc ju ld ng lf lg lh nh lj lk ll ni ln lo lp lq ij bi translated">ᵃᵈʲ = 1 - (RSS/n-p-1)/(SST/n-1)</p></blockquote><p id="4bd3" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">重新排列调整后的 R 方程，分子中会留下 n-1，分母中会留下 n-p-1。因此，即使在简单的线性回归环境中，调整后的 R 也总是小于 R 的倍数。</p><p id="9631" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated"><strong class="kx ir"> F 统计量</strong></p><blockquote class="nd ne nf"><p id="8daf" class="kv kw nb kx b ky kz jr la lb lc ju ld ng lf lg lh nh lj lk ll ni ln lo lp lq ij bi translated">f = MSReg/MSE</p></blockquote><p id="1c9b" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">MS 指均方差。这些值的计算方法是将 SSReg 和 RSS 除以各自的自由度 1 和 n-p-1。因为这是两个卡方变量的比率，所以新的统计数据遵循具有 1 和 n-p-1 个自由度的 f 分布。</p><pre class="kg kh ki kj gt mp mq mr ms aw mt bi"><span id="d7f0" class="mu lt iq mq b gy mv mw l mx my">f = (ssreg/1)/(rss/(n-2))<br/>pf(f,1,n-p-1,lower.tail=F)</span></pre><h1 id="ce02" class="ls lt iq bd lu lv lw lx ly lz ma mb mc jw md jx me jz mf ka mg kc mh kd mi mj bi translated">结论</h1><p id="bb84" class="pw-post-body-paragraph kv kw iq kx b ky mk jr la lb ml ju ld le mm lg lh li mn lk ll lm mo lo lp lq ij bi translated">我们已经研究了普通的最小二乘法，以及如何用它来计算参数估计。此外，我们已经展示了如何使用与 RSS 相关的值来计算测试统计信息和诊断信息。</p></div></div>    
</body>
</html>