<html>
<head>
<title>Twitter Sentiment Analysis using fastText</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用 fastText 的 Twitter 情感分析</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/twitter-sentiment-analysis-using-fasttext-9ccd04465597?source=collection_archive---------6-----------------------#2019-03-05">https://towardsdatascience.com/twitter-sentiment-analysis-using-fasttext-9ccd04465597?source=collection_archive---------6-----------------------#2019-03-05</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><p id="1fd9" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">在这篇博客中，我们将使用一个快速文本库来分析各种推文的情绪，该库易于使用和快速训练。</p><figure class="km kn ko kp gt kq gh gi paragraph-image"><div role="button" tabindex="0" class="kr ks di kt bf ku"><div class="gh gi kl"><img src="../Images/0d22e011563ae0e3681bb4310df17f29.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*VT7AxioAGXplMe7RAEYfSA.png"/></div></div><figcaption class="kx ky gj gh gi kz la bd b be z dk">Twitter sentiment analysis</figcaption></figure><h1 id="c372" class="lb lc iq bd ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly bi translated">什么是 fastText？</h1><p id="63ce" class="pw-post-body-paragraph jn jo iq jp b jq lz js jt ju ma jw jx jy mb ka kb kc mc ke kf kg md ki kj kk ij bi translated">FastText 是由脸书人工智能开发的自然语言处理库。这是一个开源、免费、轻量级的库，允许用户学习文本表示和文本分类器。它在标准的通用硬件上工作。模型可以缩小尺寸，甚至适合移动设备。</p><h1 id="2ac3" class="lb lc iq bd ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly bi translated">为什么选择 fastText？</h1><p id="8b50" class="pw-post-body-paragraph jn jo iq jp b jq lz js jt ju ma jw jx jy mb ka kb kc mc ke kf kg md ki kj kk ij bi translated">深度神经网络模型的主要缺点是它们需要大量的时间来训练和测试。在这里，fastText 有一个优势，因为它只需要很少的时间来训练，并且可以在我们的家用电脑上高速训练。</p><p id="6298" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">根据 fastText 上的<a class="ae me" href="https://research.fb.com/fasttext/" rel="noopener ugc nofollow" target="_blank">脸书人工智能博客</a>的说法，这个库的准确性与深度神经网络相当，并且只需要很少的时间来训练。</p><figure class="km kn ko kp gt kq gh gi paragraph-image"><div role="button" tabindex="0" class="kr ks di kt bf ku"><div class="gh gi mf"><img src="../Images/e850ea29faffd15f2253108f5e19b65a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*2HEY4ZmzTbzFjqBdy4nwjw.png"/></div></div><figcaption class="kx ky gj gh gi kz la bd b be z dk">comparison between fastText and other deep learning based models</figcaption></figure><p id="6875" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">现在，我们知道了 fastText 以及我们为什么使用它，我们将看到如何使用这个库进行情感分析。</p><h1 id="e166" class="lb lc iq bd ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly bi translated">获取数据集</h1><p id="9f55" class="pw-post-body-paragraph jn jo iq jp b jq lz js jt ju ma jw jx jy mb ka kb kc mc ke kf kg md ki kj kk ij bi translated">我们将使用 betsentiment.com 的<a class="ae me" href="https://betsentiment.com/resources/dataset/english-tweets" rel="noopener ugc nofollow" target="_blank">上可用的数据集。推文有四个标签，分别是正值、负值、中性和混合型。我们会忽略所有带有混合标签的推文。</a></p><p id="5b4d" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我们将使用团队 tweet 数据集作为训练集，而球员数据集作为验证集。</p><h1 id="2651" class="lb lc iq bd ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly bi translated">清洗数据集</h1><p id="5359" class="pw-post-body-paragraph jn jo iq jp b jq lz js jt ju ma jw jx jy mb ka kb kc mc ke kf kg md ki kj kk ij bi translated">正如我们所知，在训练任何模型之前，我们需要清理数据，在这里也是如此。</p><h2 id="4aa7" class="mg lc iq bd ld mh mi dn lh mj mk dp ll jy ml mm lp kc mn mo lt kg mp mq lx mr bi translated">我们将根据这些规则清理推文:</h2><ol class=""><li id="1846" class="ms mt iq jp b jq lz ju ma jy mu kc mv kg mw kk mx my mz na bi translated">移除所有标签，因为标签不会影响情绪。</li><li id="106e" class="ms mt iq jp b jq nb ju nc jy nd kc ne kg nf kk mx my mz na bi translated">删除提及，因为它们在情感分析中也不重要。</li><li id="b25a" class="ms mt iq jp b jq nb ju nc jy nd kc ne kg nf kk mx my mz na bi translated">将任何表情符号替换为它们所代表的文本，作为表情符号或表情符号在代表一种情绪方面发挥着重要作用。</li><li id="891f" class="ms mt iq jp b jq nb ju nc jy nd kc ne kg nf kk mx my mz na bi translated">用完整的形式代替收缩。</li><li id="6b5e" class="ms mt iq jp b jq nb ju nc jy nd kc ne kg nf kk mx my mz na bi translated">删除推文中出现的任何 URL，因为它们在情感分析中并不重要。</li><li id="1d34" class="ms mt iq jp b jq nb ju nc jy nd kc ne kg nf kk mx my mz na bi translated">删除标点符号。</li><li id="e982" class="ms mt iq jp b jq nb ju nc jy nd kc ne kg nf kk mx my mz na bi translated">修复拼写错误的单词(非常基础，因为这是一个非常耗时的步骤)。</li><li id="c1c1" class="ms mt iq jp b jq nb ju nc jy nd kc ne kg nf kk mx my mz na bi translated">将所有内容转换为小写。</li><li id="eee2" class="ms mt iq jp b jq nb ju nc jy nd kc ne kg nf kk mx my mz na bi translated">删除 HTML 标签(如果有)。</li></ol><h2 id="fff2" class="mg lc iq bd ld mh mi dn lh mj mk dp ll jy ml mm lp kc mn mo lt kg mp mq lx mr bi translated">清理推文的规则:</h2><p id="784b" class="pw-post-body-paragraph jn jo iq jp b jq lz js jt ju ma jw jx jy mb ka kb kc mc ke kf kg md ki kj kk ij bi translated">我们将清理这条推文</p><pre class="km kn ko kp gt ng nh ni nj aw nk bi"><span id="18ba" class="mg lc iq nh b gy nl nm l nn no">tweet = '&lt;html&gt; bayer leverkusen goalkeeeeper bernd leno will not be #going to napoli. his agent uli ferber to bild: "I can confirm that there were negotiations with napoli, which we have broken off. napoli is not an option." Atletico madrid and Arsenal are the other strong rumours. #b04 #afc &lt;/html&gt;'</span></pre><h2 id="d812" class="mg lc iq bd ld mh mi dn lh mj mk dp ll jy ml mm lp kc mn mo lt kg mp mq lx mr bi translated">删除 HTML 标签</h2><p id="4f07" class="pw-post-body-paragraph jn jo iq jp b jq lz js jt ju ma jw jx jy mb ka kb kc mc ke kf kg md ki kj kk ij bi translated">有时 twitter 响应包含 HTML 标签，我们需要删除它。</p><p id="70b1" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">为此，我们将使用<code class="fe np nq nr nh b"><a class="ae me" href="https://www.crummy.com/software/BeautifulSoup/bs4/doc/" rel="noopener ugc nofollow" target="_blank">Beautifulsoup</a></code> <a class="ae me" href="https://www.crummy.com/software/BeautifulSoup/bs4/doc/" rel="noopener ugc nofollow" target="_blank">包</a>。</p><p id="4a05" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">如果没有 HTML 标签，那么它将返回相同的文本。</p><pre class="km kn ko kp gt ng nh ni nj aw nk bi"><span id="68c8" class="mg lc iq nh b gy nl nm l nn no">tweet = BeautifulSoup(tweet).get_text()</span><span id="0d7e" class="mg lc iq nh b gy ns nm l nn no">#output<br/>'bayer leverkusen goalkeeeeper bernd leno will not be #going to napoli. his agent uli ferber to bild: "I can confirm that there were negotiations with napoli, which we have broken off. napoli is not an option." Atletico madrid and Arsenal are the other strong rumours. #b04 #afc'</span></pre><p id="0a74" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我们将使用正则表达式来匹配要删除或要替换的表达式。为此，将使用<code class="fe np nq nr nh b"><a class="ae me" href="https://docs.python.org/3/library/re.html" rel="noopener ugc nofollow" target="_blank">re</a></code> <a class="ae me" href="https://docs.python.org/3/library/re.html" rel="noopener ugc nofollow" target="_blank">包</a>。</p><h2 id="40db" class="mg lc iq bd ld mh mi dn lh mj mk dp ll jy ml mm lp kc mn mo lt kg mp mq lx mr bi translated">移除标签</h2><p id="e81c" class="pw-post-body-paragraph jn jo iq jp b jq lz js jt ju ma jw jx jy mb ka kb kc mc ke kf kg md ki kj kk ij bi translated">Regex <code class="fe np nq nr nh b">@[A-Za-z0-9]+</code>代表提及次数，<code class="fe np nq nr nh b">#[A-Za-z0-9]+</code>代表标签。我们将用空格替换匹配这个正则表达式的每个单词。</p><pre class="km kn ko kp gt ng nh ni nj aw nk bi"><span id="7d23" class="mg lc iq nh b gy nl nm l nn no">tweet = ' '.join(re.sub("(@[A-Za-z0-9]+)|(#[A-Za-z0-9]+)", " ", tweet).split())</span><span id="268f" class="mg lc iq nh b gy ns nm l nn no">#output<br/>'bayer leverkusen goalkeeeeper bernd leno will not be to napoli. his agent uli ferber to bild: "I can confirm that there were negotiations with napoli, which we have broken off. napoli is not an option." Atletico madrid and Arsenal are the other strong rumours.'</span></pre><h2 id="f0d8" class="mg lc iq bd ld mh mi dn lh mj mk dp ll jy ml mm lp kc mn mo lt kg mp mq lx mr bi translated">删除 URL</h2><p id="dafc" class="pw-post-body-paragraph jn jo iq jp b jq lz js jt ju ma jw jx jy mb ka kb kc mc ke kf kg md ki kj kk ij bi translated">Regex <code class="fe np nq nr nh b">\w+:\/\/\S+</code>匹配所有以 http://或 https://开头并用空格替换的 URL。</p><pre class="km kn ko kp gt ng nh ni nj aw nk bi"><span id="7f5f" class="mg lc iq nh b gy nl nm l nn no">tweet = ' '.join(re.sub("(\w+:\/\/\S+)", " ", tweet).split())</span><span id="9e8d" class="mg lc iq nh b gy ns nm l nn no">#output<br/>'bayer leverkusen goalkeeeeper bernd leno will not be to napoli. his agent uli ferber to bild: "I can confirm that there were negotiations with napoli, which we have broken off. napoli is not an option." Atletico madrid and Arsenal are the other strong rumours.'</span></pre><h2 id="7794" class="mg lc iq bd ld mh mi dn lh mj mk dp ll jy ml mm lp kc mn mo lt kg mp mq lx mr bi translated">删除标点符号</h2><p id="f804" class="pw-post-body-paragraph jn jo iq jp b jq lz js jt ju ma jw jx jy mb ka kb kc mc ke kf kg md ki kj kk ij bi translated">用空格替换所有标点符号，如<code class="fe np nq nr nh b">.,!?:;-=</code>。</p><pre class="km kn ko kp gt ng nh ni nj aw nk bi"><span id="0b88" class="mg lc iq nh b gy nl nm l nn no">tweet = ' '.join(re.sub("[\.\,\!\?\:\;\-\=]", " ", tweet).split())</span><span id="6d86" class="mg lc iq nh b gy ns nm l nn no">#output <br/>'bayer leverkusen goalkeeeeper bernd leno will not be napoli his agent uli ferber to bild "I can confirm that there were negotiations with napoli which we have broken off napoli is not an option " Atletico madrid and Arsenal are the other strong rumours'</span></pre><h2 id="43a9" class="mg lc iq bd ld mh mi dn lh mj mk dp ll jy ml mm lp kc mn mo lt kg mp mq lx mr bi translated">小写字母盘</h2><p id="e416" class="pw-post-body-paragraph jn jo iq jp b jq lz js jt ju ma jw jx jy mb ka kb kc mc ke kf kg md ki kj kk ij bi translated">为了避免大小写敏感问题</p><pre class="km kn ko kp gt ng nh ni nj aw nk bi"><span id="b1fb" class="mg lc iq nh b gy nl nm l nn no">tweet = tweet.lower()</span><span id="ec36" class="mg lc iq nh b gy ns nm l nn no">#output<br/>'bayer leverkusen goalkeeeeper bernd leno will not be napoli his agent uli ferber to bild "i can confirm that there were negotiations with napoli which we have broken off napoli is not an option " atletico madrid and arsenal are the other strong rumours'</span></pre><h2 id="25f9" class="mg lc iq bd ld mh mi dn lh mj mk dp ll jy ml mm lp kc mn mo lt kg mp mq lx mr bi translated">替换收缩</h2><p id="b2ab" class="pw-post-body-paragraph jn jo iq jp b jq lz js jt ju ma jw jx jy mb ka kb kc mc ke kf kg md ki kj kk ij bi translated">去掉缩写，翻译成合适的俚语。没有通用的列表来代替缩写，所以我们为了自己的目的制作了这个列表。</p><pre class="km kn ko kp gt ng nh ni nj aw nk bi"><span id="152b" class="mg lc iq nh b gy nl nm l nn no">CONTRACTIONS = {"mayn't":"may not", "may've":"may have",......}</span><span id="1d88" class="mg lc iq nh b gy ns nm l nn no">tweet = tweet.replace("’","'")<br/>words = tweet.split()<br/>reformed = [CONTRACTIONS[word] if word in CONTRACTIONS else word for word in words]<br/>tweet = " ".join(reformed)</span><span id="0f8f" class="mg lc iq nh b gy ns nm l nn no">#input<br/>'I mayn’t like you.'</span><span id="1148" class="mg lc iq nh b gy ns nm l nn no">#output<br/>'I may not like you.'</span></pre><h2 id="6db8" class="mg lc iq bd ld mh mi dn lh mj mk dp ll jy ml mm lp kc mn mo lt kg mp mq lx mr bi translated">修复拼写错误的单词</h2><p id="6a7b" class="pw-post-body-paragraph jn jo iq jp b jq lz js jt ju ma jw jx jy mb ka kb kc mc ke kf kg md ki kj kk ij bi translated">在这里，我们实际上并没有构建任何复杂的函数来纠正拼写错误的单词，而只是检查每个字符在每个单词中出现的次数是否不超过 2 次。这是一个非常基本的拼写错误检查。</p><pre class="km kn ko kp gt ng nh ni nj aw nk bi"><span id="2fa2" class="mg lc iq nh b gy nl nm l nn no">tweet = ''.join(''.join(s)[:2] for _, s in itertools.groupby(tweet))</span><span id="61cb" class="mg lc iq nh b gy ns nm l nn no">#output<br/>'bayer leverkusen goalkeeper bernd leno will not be napoli his agent uli ferber to bild "i can confirm that there were negotiations with napoli which we have broken off napoli is not an option " atletico madrid and arsenal are the other strong rumours'</span></pre><h2 id="78fb" class="mg lc iq bd ld mh mi dn lh mj mk dp ll jy ml mm lp kc mn mo lt kg mp mq lx mr bi translated">替换表情符号或表情符号</h2><p id="c3d3" class="pw-post-body-paragraph jn jo iq jp b jq lz js jt ju ma jw jx jy mb ka kb kc mc ke kf kg md ki kj kk ij bi translated">由于表情符号和表情符号在表达情感方面发挥着重要作用，我们需要用它们在简单英语中所代表的表达方式来取代它们。</p><p id="0d70" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">对于表情符号，我们将使用<code class="fe np nq nr nh b">emoji</code>包，对于表情符号，我们将建立自己的字典。</p><pre class="km kn ko kp gt ng nh ni nj aw nk bi"><span id="4d12" class="mg lc iq nh b gy nl nm l nn no">SMILEYS = {":‑(":"sad", ":‑)":"smiley", ....}</span><span id="1209" class="mg lc iq nh b gy ns nm l nn no">words = tweet.split()<br/>reformed = [SMILEY[word] if word in SMILEY else word for word in words]<br/>tweet = " ".join(reformed)</span><span id="6316" class="mg lc iq nh b gy ns nm l nn no">#input <br/>'I am :-('</span><span id="1e98" class="mg lc iq nh b gy ns nm l nn no">#output<br/>'I am sad' </span></pre><h2 id="52ef" class="mg lc iq bd ld mh mi dn lh mj mk dp ll jy ml mm lp kc mn mo lt kg mp mq lx mr bi translated">表情符号</h2><p id="be35" class="pw-post-body-paragraph jn jo iq jp b jq lz js jt ju ma jw jx jy mb ka kb kc mc ke kf kg md ki kj kk ij bi translated">表情包返回给定表情的值为<code class="fe np nq nr nh b">:flushed_face:</code>，所以我们需要从给定的输出中删除<code class="fe np nq nr nh b">:</code>。</p><pre class="km kn ko kp gt ng nh ni nj aw nk bi"><span id="506d" class="mg lc iq nh b gy nl nm l nn no">tweet = emoji.demojize(tweet)<br/>tweet = tweet.replace(":"," ")<br/>tweet = ' '.join(tweet.split())</span><span id="a908" class="mg lc iq nh b gy ns nm l nn no">#input<br/>'He is 😳'</span><span id="bc2f" class="mg lc iq nh b gy ns nm l nn no">#output<br/>'He is flushed_face'</span></pre><p id="0adc" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">所以，我们已经清理了我们的数据。</p><h1 id="da99" class="lb lc iq bd ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly bi translated">为什么不用 NLTK 停用词？</h1><p id="c3cf" class="pw-post-body-paragraph jn jo iq jp b jq lz js jt ju ma jw jx jy mb ka kb kc mc ke kf kg md ki kj kk ij bi translated">清除数据时，删除停用词是一种有效的方法。它去掉了所有无关紧要的词，通常是每个句子中最常用的词。获取 NLTK 库中存在的所有停用词</p><pre class="km kn ko kp gt ng nh ni nj aw nk bi"><span id="96a4" class="mg lc iq nh b gy nl nm l nn no">from nltk.corpus import stopwords<br/>stop_words = stopwords.words('english')<br/>print(stop_words)</span></pre><figure class="km kn ko kp gt kq gh gi paragraph-image"><div role="button" tabindex="0" class="kr ks di kt bf ku"><div class="gh gi nt"><img src="../Images/22565d0a334fc36444425c2635c16a40.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*dJlJlbzLFJDwBxzpJ8Gtrw.png"/></div></div><figcaption class="kx ky gj gh gi kz la bd b be z dk">NLTK stop words</figcaption></figure><p id="22c9" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我们可以看到，如果使用 NLTK 停用词，那么所有的负面缩写都将被移除，这在情感分析中起着重要的作用。</p><h1 id="ee66" class="lb lc iq bd ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly bi translated">格式化数据集</h1><p id="feee" class="pw-post-body-paragraph jn jo iq jp b jq lz js jt ju ma jw jx jy mb ka kb kc mc ke kf kg md ki kj kk ij bi translated">需要格式化 fastText 监督学习所需的数据。</p><p id="fd0a" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><a class="ae me" href="https://github.com/facebookresearch/fastText/blob/master/README.md#text-classification" rel="noopener ugc nofollow" target="_blank"> FastText </a>假设标签是以字符串<code class="fe np nq nr nh b">__label__</code>为前缀的单词。</p><p id="d23b" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">fastText 模型的输入应该如下所示</p><pre class="km kn ko kp gt ng nh ni nj aw nk bi"><span id="b5d9" class="mg lc iq nh b gy nl nm l nn no">__label__NEUTRAL _d i 'm just fine i have your fanbase angry over<br/>__label__POSITIVE what a weekend of football results &amp; hearts</span></pre><p id="0c58" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我们可以使用以下方式格式化数据</p><pre class="km kn ko kp gt ng nh ni nj aw nk bi"><span id="31e0" class="mg lc iq nh b gy nl nm l nn no">def transform_instance(row):<br/>    cur_row = []<br/>    #Prefix the index-ed label with __label__<br/>    label = "__label__" + row[4]  <br/>    cur_row.append(label)<br/>    cur_row.extend(nltk.word_tokenize(tweet_cleaning_for_sentiment_analysis(row[2].lower())))<br/>    return cur_row</span><span id="c6f3" class="mg lc iq nh b gy ns nm l nn no">def preprocess(input_file, output_file):<br/>    i=0<br/>    with open(output_file, 'w') as csvoutfile:<br/>        csv_writer = csv.writer(csvoutfile, delimiter=' ', lineterminator='\n')<br/>        with open(input_file, 'r', newline='', encoding='latin1') as csvinfile: # encoding='latin1'<br/>            csv_reader = csv.reader(csvinfile, delimiter=',', quotechar='"')<br/>            for row in csv_reader:<br/>                if row[4]!="MIXED" and row[4].upper() in ['POSITIVE','NEGATIVE','NEUTRAL'] and row[2]!='':<br/>                    row_output = transform_instance(row)<br/>                    csv_writer.writerow(row_output )<br/>                    # print(row_output)<br/>                i=i+1<br/>                if i%10000 ==0:<br/>                    print(i)</span></pre><p id="3e63" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">这里，我们忽略标签不是<code class="fe np nq nr nh b">Positive, Negative and neutral</code>的推文。</p><p id="5030" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><code class="fe np nq nr nh b">nltk.<a class="ae me" href="https://www.nltk.org/api/nltk.tokenize.html#nltk.tokenize.punkt.PunktLanguageVars.word_tokenize" rel="noopener ugc nofollow" target="_blank">word_tokenize</a>()</code>将字符串转换成独立的单词。</p><pre class="km kn ko kp gt ng nh ni nj aw nk bi"><span id="29dc" class="mg lc iq nh b gy nl nm l nn no">nltk.word_tokenize('hello world!')</span><span id="5328" class="mg lc iq nh b gy ns nm l nn no">#output<br/>['hello', 'world', '!']</span></pre><h1 id="896f" class="lb lc iq bd ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly bi translated">对数据集进行上采样</h1><p id="a7b2" class="pw-post-body-paragraph jn jo iq jp b jq lz js jt ju ma jw jx jy mb ka kb kc mc ke kf kg md ki kj kk ij bi translated">在我们的数据集中，数据并没有被平均划分到不同的标签中。它包含中性标签中大约 72%的数据。因此，我们可以看到，我们的模型往往会被大班淹没，而忽略小班。</p><pre class="km kn ko kp gt ng nh ni nj aw nk bi"><span id="2ae4" class="mg lc iq nh b gy nl nm l nn no">import pandas as pd<br/>import seaborn as sns</span><span id="3dde" class="mg lc iq nh b gy ns nm l nn no">df = pd.read_csv('betsentiment-EN-tweets-sentiment-teams.csv',encoding='latin1')</span><span id="d3fd" class="mg lc iq nh b gy ns nm l nn no">df['sentiment'].value_counts(normalize=True)*100</span></pre><figure class="km kn ko kp gt kq gh gi paragraph-image"><div class="gh gi nu"><img src="../Images/c600787c67546ce30b613e1da942c53a.png" data-original-src="https://miro.medium.com/v2/resize:fit:610/format:webp/1*YbRlxnt-5yj1_vb8NZoFkQ.png"/></div><figcaption class="kx ky gj gh gi kz la bd b be z dk">percentage of tweets for each labels</figcaption></figure><pre class="km kn ko kp gt ng nh ni nj aw nk bi"><span id="26b9" class="mg lc iq nh b gy nl nm l nn no">sns.countplot(x="sentiment", data=df)</span></pre><figure class="km kn ko kp gt kq gh gi paragraph-image"><div class="gh gi nv"><img src="../Images/3ca937d09c41a326a315a3b5b8d28e96.png" data-original-src="https://miro.medium.com/v2/resize:fit:834/format:webp/1*2j7zrySOG2l-EfC7XBPQlg.png"/></div><figcaption class="kx ky gj gh gi kz la bd b be z dk">countplot for sentiment labels</figcaption></figure><p id="1845" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">由于中性类由数据集的大部分组成，该模型将始终尝试预测中性标签，因为它将保证 72%的准确性。为了防止这种情况，我们需要每个标签有相同数量的推文。我们可以通过向 minor 类添加新的 tweets 来实现这一点。向少数族裔标签添加新推文的过程被称为上采样。</p><p id="66ff" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我们将通过一次又一次地重复给定标签中的 tweet 来实现上采样，直到每个标签中 tweet 的数量相等。</p><pre class="km kn ko kp gt ng nh ni nj aw nk bi"><span id="bc48" class="mg lc iq nh b gy nl nm l nn no">def upsampling(input_file, output_file, ratio_upsampling=1):<br/>    # Create a file with equal number of tweets for each label<br/>    #    input_file: path to file<br/>    #    output_file: path to the output file<br/>    #    ratio_upsampling: ratio of each minority classes vs majority one. 1 mean there will be as much of each class than there is for the majority class <br/>    <br/>    i=0<br/>    counts = {}<br/>    dict_data_by_label = {}</span><span id="aab6" class="mg lc iq nh b gy ns nm l nn no"># GET LABEL LIST AND GET DATA PER LABEL<br/>    with open(input_file, 'r', newline='') as csvinfile: <br/>        csv_reader = csv.reader(csvinfile, delimiter=',', quotechar='"')<br/>        for row in csv_reader:<br/>            counts[row[0].split()[0]] = counts.get(row[0].split()[0], 0) + 1<br/>            if not row[0].split()[0] in dict_data_by_label:<br/>                dict_data_by_label[row[0].split()[0]]=[row[0]]<br/>            else:<br/>                dict_data_by_label[row[0].split()[0]].append(row[0])<br/>            i=i+1<br/>            if i%10000 ==0:<br/>                print("read" + str(i))</span><span id="efd9" class="mg lc iq nh b gy ns nm l nn no"># FIND MAJORITY CLASS<br/>    majority_class=""<br/>    count_majority_class=0<br/>    for item in dict_data_by_label:<br/>        if len(dict_data_by_label[item])&gt;count_majority_class:<br/>            majority_class= item<br/>            count_majority_class=len(dict_data_by_label[item])  <br/>    <br/>    # UPSAMPLE MINORITY CLASS<br/>    data_upsampled=[]<br/>    for item in dict_data_by_label:<br/>        data_upsampled.extend(dict_data_by_label[item])<br/>        if item != majority_class:<br/>            items_added=0<br/>            items_to_add = count_majority_class - len(dict_data_by_label[item])<br/>            while items_added&lt;items_to_add:<br/>                data_upsampled.extend(dict_data_by_label[item][:max(0,min(items_to_add-items_added,len(dict_data_by_label[item])))])<br/>                items_added = items_added + max(0,min(items_to_add-items_added,len(dict_data_by_label[item])))</span><span id="379d" class="mg lc iq nh b gy ns nm l nn no"># WRITE ALL<br/>    i=0</span><span id="c0df" class="mg lc iq nh b gy ns nm l nn no">with open(output_file, 'w') as txtoutfile:<br/>        for row in data_upsampled:<br/>            txtoutfile.write(row+ '\n' )<br/>            i=i+1<br/>            if i%10000 ==0:<br/>                print("writer" + str(i))</span></pre><p id="6ec0" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">至于重复推文，一次又一次，可能会导致我们的模型过度适应我们的数据集，但由于我们的数据集很大，这不是一个问题。</p><h1 id="954c" class="lb lc iq bd ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly bi translated">培养</h1><p id="6188" class="pw-post-body-paragraph jn jo iq jp b jq lz js jt ju ma jw jx jy mb ka kb kc mc ke kf kg md ki kj kk ij bi translated">尝试用<a class="ae me" href="https://github.com/facebookresearch/fastText/tree/master/python#building-fasttext" rel="noopener ugc nofollow" target="_blank"> git 克隆</a>安装 fastText，而不是使用 pip。</p><p id="35f1" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我们将使用监督训练法。</p><pre class="km kn ko kp gt ng nh ni nj aw nk bi"><span id="0963" class="mg lc iq nh b gy nl nm l nn no">hyper_params = {"lr": 0.01,<br/>                "epoch": 20,<br/>                "wordNgrams": 2,<br/>                "dim": 20}     <br/>                               <br/>        print(str(datetime.datetime.now()) + ' START=&gt;' + str(hyper_params) )</span><span id="50bc" class="mg lc iq nh b gy ns nm l nn no"># Train the model.<br/>        model = fastText.train_supervised(input=training_data_path, **hyper_params)<br/>        print("Model trained with the hyperparameter \n {}".format(hyper_params))</span></pre><p id="82e1" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><code class="fe np nq nr nh b">lr</code>代表<code class="fe np nq nr nh b">learning rate</code>，<code class="fe np nq nr nh b">epoch</code>代表<code class="fe np nq nr nh b">number of epoch</code>，<code class="fe np nq nr nh b">wordNgrams</code>代表<code class="fe np nq nr nh b">max length of word Ngram</code>，<code class="fe np nq nr nh b">dim</code>代表<code class="fe np nq nr nh b">size of word vectors</code>。</p><p id="eb06" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><code class="fe np nq nr nh b">train_supervised</code>是用于使用监督学习来训练模型的函数。</p><h1 id="ed0a" class="lb lc iq bd ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly bi translated">评价</h1><p id="453a" class="pw-post-body-paragraph jn jo iq jp b jq lz js jt ju ma jw jx jy mb ka kb kc mc ke kf kg md ki kj kk ij bi translated">我们需要评估这个模型以确定它的准确性。</p><pre class="km kn ko kp gt ng nh ni nj aw nk bi"><span id="90f3" class="mg lc iq nh b gy nl nm l nn no">model_acc_training_set = model.test(training_data_path)<br/>model_acc_validation_set = model.test(validation_data_path)<br/>        <br/># DISPLAY ACCURACY OF TRAINED MODEL<br/>text_line = str(hyper_params) + ",accuracy:" + str(model_acc_training_set[1])  + ",validation:" + str(model_acc_validation_set[1]) + '\n' </span><span id="7ba6" class="mg lc iq nh b gy ns nm l nn no">print(text_line)</span></pre><p id="5ab2" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我们将在训练和验证数据集上评估我们的模型。</p><p id="669c" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><code class="fe np nq nr nh b">test</code>返回模型的精度和召回率，而不是精度。但是在我们的例子中，两个值几乎相同，所以我们只使用精度。</p><p id="e3bf" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">总的来说，该模型对训练数据给出了 97.5%的准确度，对验证数据给出了 79.7%的准确度。</p><h1 id="1b7c" class="lb lc iq bd ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly bi translated">预测</h1><p id="1ca1" class="pw-post-body-paragraph jn jo iq jp b jq lz js jt ju ma jw jx jy mb ka kb kc mc ke kf kg md ki kj kk ij bi translated">我们将预测传递给我们训练好的模型的文本的情感。</p><pre class="km kn ko kp gt ng nh ni nj aw nk bi"><span id="21cc" class="mg lc iq nh b gy nl nm l nn no">model.predict(['why not'],k=3)<br/>model.predict(['this player is so bad'],k=1)</span></pre><p id="dc08" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><code class="fe np nq nr nh b">predict</code>让我们预测传递的字符串的情感，而<code class="fe np nq nr nh b">k</code>代表返回的带有置信度得分的标签的数量。</p><h1 id="eb3e" class="lb lc iq bd ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly bi translated">量化模型</h1><p id="0798" class="pw-post-body-paragraph jn jo iq jp b jq lz js jt ju ma jw jx jy mb ka kb kc mc ke kf kg md ki kj kk ij bi translated">量化有助于我们降低模型的规模。</p><pre class="km kn ko kp gt ng nh ni nj aw nk bi"><span id="3460" class="mg lc iq nh b gy nl nm l nn no">model.quantize(input=training_data_path, qnorm=True, retrain=True, cutoff=100000)</span></pre><h1 id="39d7" class="lb lc iq bd ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly bi translated">保存模型</h1><p id="e2c9" class="pw-post-body-paragraph jn jo iq jp b jq lz js jt ju ma jw jx jy mb ka kb kc mc ke kf kg md ki kj kk ij bi translated">我们可以保存训练好的模型，然后随时使用，而不是每次都训练它。</p><pre class="km kn ko kp gt ng nh ni nj aw nk bi"><span id="d486" class="mg lc iq nh b gy nl nm l nn no">model.save_model(os.path.join(model_path,model_name + ".ftz"))</span></pre><h1 id="945a" class="lb lc iq bd ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly bi translated">结论</h1><p id="c2f3" class="pw-post-body-paragraph jn jo iq jp b jq lz js jt ju ma jw jx jy mb ka kb kc mc ke kf kg md ki kj kk ij bi translated">我们学习如何清理数据，并将其传递给训练模型来预测推文的情绪。我们还学习使用 fastText 实现情感分析模型。</p><figure class="km kn ko kp gt kq"><div class="bz fp l di"><div class="nw nx l"/></div></figure></div></div>    
</body>
</html>