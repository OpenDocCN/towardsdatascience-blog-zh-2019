# åœ¨ 15 åˆ†é’Ÿå†…æ„å»ºæ‚¨è‡ªå·±çš„åŸºäºèšç±»çš„æ¨èå¼•æ“ï¼ï¼

> åŸæ–‡ï¼š<https://towardsdatascience.com/build-your-own-clustering-based-recommendation-engine-in-15-minutes-bdddd591d394?source=collection_archive---------1----------------------->

æ¨èå¼•æ“æ˜¯æœºå™¨å­¦ä¹ æŠ€æœ¯åœ¨å½“å‰äº’è”ç½‘æ—¶ä»£æœ€æµè¡Œçš„åº”ç”¨ä¹‹ä¸€ã€‚è¿™äº›å¹¿æ³›ç”¨äºç”µå­å•†åŠ¡ç½‘ç«™æ¨èç±»ä¼¼äº§å“å’Œç”µå½±æ¨èç½‘ç«™ã€‚ä»–ä»¬è´Ÿè´£ä¸ºæˆ‘ä»¬ç”Ÿæˆå„ç§å®šåˆ¶çš„æ–°é—»å»ºè®®ã€‚è¿™å°†æ¨åŠ¨ç”¨æˆ·å‚ä¸æ›´å¤šå†…å®¹ï¼Œä»è€Œä¸ºç»„ç»‡å¸¦æ¥æ›´å¥½çš„ç”¨æˆ·ä½“éªŒå’Œæ›´å¤šæ”¶å…¥ã€‚å› æ­¤ï¼Œå®ƒä»¬åœ¨ä»Šå¤©çš„å·¥ä¸šä¸­æå…¶é‡è¦ã€‚

æ¨èå¼•æ“åŸºæœ¬ä¸Šè¿‡æ»¤æ•°æ®å¹¶å‘ç”¨æˆ·æ¨èæœ€ç›¸å…³çš„ç»“æœã€‚è¿™äº›ç»“æœæ˜¯ä»¥æœ€å¤§å¯èƒ½æ„Ÿå…´è¶£çš„æ–¹å¼æ¨èçš„ã€‚ç°åœ¨ï¼Œæ‰€æœ‰çš„æ¨èå¼•æ“éƒ½æœ‰ç”¨æˆ·æ•°æ®å’Œä»–ä»¬çš„å†å²è®°å½•ï¼Œå¯ä»¥ç”¨æ¥åˆ›å»ºä»–ä»¬çš„è¿‡æ»¤ç®—æ³•ã€‚è¿™æœ€ç»ˆå¸®åŠ©ä»–ä»¬ä¸ºæ¯ä¸ªç‹¬ç‰¹çš„ç”¨æˆ·ç”Ÿæˆéå¸¸å‡†ç¡®çš„æ¨èã€‚

![](img/e0c3748b0fc91dd8625f58f40edf4bea.png)

User-based filtering is based on history of users and similarity b/w them from their purchase histories for example. But, Item-based recommendations are based on content based similarity. Like, â€œhow many times few items are bought togetherâ€. Next time, most frequent of these purchases will be recommended together.

åœ¨ååŒè¿‡æ»¤çš„æƒ…å†µä¸‹,â€œç”¨æˆ·è¡Œä¸ºâ€è¢«ç”¨äºæ¨èé¡¹ç›®ã€‚è¿™äº›æ¨èå¯ä»¥åˆ©ç”¨ç”¨æˆ·-ç”¨æˆ·ç›¸ä¼¼æ€§æˆ–è€…åŸºäºé¡¹ç›®-é¡¹ç›®ç›¸ä¼¼æ€§æ¥ç”Ÿæˆã€‚å¹¶ä¸”åŸºäºè¯¥ç›¸ä¼¼æ€§åº¦é‡ï¼Œå‘ç”¨æˆ·æä¾›å»ºè®®ã€‚ä½†æ˜¯ï¼Œè®©æˆ‘ä»¬è€ƒè™‘ä¸€ä¸ªåœºæ™¯ï¼Œåœ¨è¿™ä¸ªåœºæ™¯ä¸­ï¼Œæˆ‘ä»¬æ²¡æœ‰å¯ç”¨çš„ç”¨æˆ·æ•°æ®ï¼Œä½†æ˜¯æˆ‘ä»¬ä»ç„¶å¿…é¡»å‘ç”¨æˆ·æ¨èå•†å“ã€‚

> æ²¡æœ‰ç”¨æˆ·æ•°æ®æ€ä¹ˆåŠï¼Ÿæˆ‘ä»¬çš„æ¨èå¼•æ“ç°åœ¨å°†å¦‚ä½•å·¥ä½œï¼Ÿ

ç”Ÿæˆæ¨èçš„é—®é¢˜ç°åœ¨è¢«ç®€å•åœ°è½¬åŒ–ä¸ºç±»ä¼¼èšç±»çš„é—®é¢˜ã€‚å…¶ä¸­ç›¸ä¼¼æ€§åº¦é‡åŸºäºâ€œåœ¨ç”Ÿæˆæ¨èæ—¶ï¼Œä¸¤ä¸ªé¡¹ç›®æœ‰å¤šæ¥è¿‘ï¼Ÿâ€ã€‚ç”¨äºç”Ÿæˆæ¨èçš„åº¦é‡å°†åŸºäºä¸¤ä¸ªé¡¹ç›®çš„ç›¸ä¼¼æ€§ï¼Œå¦‚è¿™äº›é¡¹ç›®ä¹‹é—´çš„å‘é‡è·ç¦»ã€‚æˆ‘ä»¬å°†é’ˆå¯¹ Pluralsight çš„åœ¨çº¿è¯¾ç¨‹æ–‡æœ¬æ•°æ®è¿›è¡Œè®¨è®ºã€‚è®©æˆ‘ä»¬æ¥åšä¸€ä¸ªä»…åŸºäºæˆ‘ä»¬å¯ç”¨çš„é¡¹ç›®æ•°æ®çš„æ¨èå¼•æ“ã€‚

# åœ¨çº¿è¯¾ç¨‹æ¨èç³»ç»Ÿ

åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬å°†ä» Pluralsight çš„è¯¾ç¨‹æ•°æ®ä¸­æ„å»ºä¸€ä¸ªæ¨èç³»ç»Ÿï¼Œå¹¶æŸ¥çœ‹å¯ä»¥å¯¹æˆ‘ä»¬åŸºäºèšç±»çš„è§£å†³æ–¹æ¡ˆè¿›è¡Œçš„è¿›ä¸€æ­¥æ”¹è¿›ã€‚æˆ‘ä»¬å°†æŒ‰ä¸‹è¿°é¡ºåºè®¨è®ºè¯¥é¡¹ç›®çš„æ•´ä¸ªæ•°æ®åˆ†ææµç¨‹ã€‚ä¸ºäº†èŠ‚çœæ—¶é—´ï¼Œä½ å¯ä»¥ç›´æ¥å‚è€ƒ[é¡¹ç›®åº“](https://github.com/ashishrana160796/Online-Course-Recommendation-System)å¹¶éµå¾ªç²¾å¿ƒåˆ¶ä½œçš„ [README.md](https://github.com/ashishrana160796/Online-Course-Recommendation-System/blob/master/README.md) æ–‡ä»¶ã€‚æ­¤å¤–ï¼Œå¯ä»¥ä¸ºæåˆ°çš„æ¯ä¸ªæ¨¡å—ç›´æ¥è¿è¡Œ[å®ç”¨ç¨‹åºè„šæœ¬](https://github.com/ashishrana160796/Online-Course-Recommendation-System/blob/master/model_train_k_30.py)ã€‚

> 1.ç®€ä»‹:äº†è§£ä½ çš„æ•°æ®
> 
> 2.æ¶æ„è®¾è®¡:æ„å»ºå®ç”¨å·¥å…·
> 
> 3.é¢„å¤„ç†æ­¥éª¤
> 
> 4.é—®é¢˜è®¨è®ºã€æ¨¡å‹è®­ç»ƒå’Œä¼˜åŒ–
> 
> 5.å·¥ä½œæ¨èç³»ç»Ÿ
> 
> 6.ç»“è®º&ä¸»é¢˜å»ºæ¨¡çš„æœªæ¥æ”¹è¿›(ç‰¹åˆ«æ˜¯ LDA)

> ***è¶…çº§çœæ—¶æç¤º*** :æ‰“å¼€é¡¹ç›®çš„ [github](https://github.com/ashishrana160796/Online-Course-Recommendation-System) åº“ï¼ŒæŒ‰ç…§ [README.md](https://github.com/ashishrana160796/Online-Course-Recommendation-System/blob/master/README.md) æ–‡ä»¶è¿è¡Œä»£ç å³å¯ğŸ˜‰

# ç®€ä»‹:äº†è§£ä½ çš„æ•°æ®

è¯¥é¡¹ç›®ä½¿ç”¨çš„æ•°æ®æ˜¯ Pluralsight ç½‘ç«™ä¸Šçš„è¯¾ç¨‹åˆ—è¡¨å’Œæè¿°ã€‚è¦è·å–è¯¾ç¨‹æ•°æ®ï¼Œåªéœ€è¿è¡Œä¸‹é¢æåˆ°çš„ ReST API æŸ¥è¯¢ã€‚ä½†æ˜¯ï¼Œä¸ºäº†è·å¾—ç”¨æˆ·æ³¨å†Œæ•°æ®ï¼Œè®©æˆ‘ä»¬è¯´ä¸€ä¸ªåŸºäºåä½œè¿‡æ»¤å™¨çš„å¼•æ“ã€‚

é¦–å…ˆï¼Œè·å–åœ¨[æ–‡æ¡£](https://www.pluralsight.com/product/professional-services/white-paper/api)ä¸­æåˆ°çš„ ReST api-tokenï¼Œç„¶åè¿›è¡Œ ReST æŸ¥è¯¢ï¼Œä»¥è·å–å…³äºè¯¥ç½‘ç«™ä¸Šæ‰€æœ‰è¯¾ç¨‹å’Œæ³¨å†Œè¯¥ç½‘ç«™çš„å„ä¸ªç”¨æˆ·çš„æ•°æ®ã€‚å¦‚æœæ‚¨æƒ³è¦è·å–ç”¨æˆ·ç›¸å…³æ•°æ®ï¼Œåˆ™éœ€è¦æ­¤é”®ã€‚å¦åˆ™ï¼Œä¸ºäº†è·å¾—ç®€å•çš„è¯¾ç¨‹ç›¸å…³æ•°æ®ï¼Œæˆ‘ä»¬å¯ä»¥ç¼–å†™å¦‚ä¸‹ ReST æŸ¥è¯¢ã€‚

```
# Input
http://api.pluralsight.com/api-v0.9/courses# Output: A *Courses.csv* file for download. It will be having below mentioned structure.CourseId,CourseTitle,DurationInSeconds,ReleaseDate,Description,AssessmentStatus,IsCourseRetiredabts-advanced-topics,BizTalk 2006 Business Process Management,22198,2008-10-25,"This course covers Business Process Management features in BizTalk Server 2006, including web services, BAM, hosting, and BTS 2009 features",Live,no
abts-fundamentals,BizTalk 2006
...
```

åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬ä»…é™äºå‘åŠ¨æœºåˆ¶é€ çš„è¯¾ç¨‹æ•°æ®ã€‚å¦åˆ™ï¼Œè¿™ç§æ–¹æ³•å°†ä¸å…¶ä»–æ¨èå¼•æ“æ–‡ç« éå¸¸ç›¸ä¼¼ã€‚é€šè¿‡æŸ¥çœ‹è¿™äº›æ•°æ®ï¼Œæˆ‘ä»¬å‘ç°ä»¥ä¸‹å‡ ç‚¹åœ¨è®­ç»ƒæ¨¡å‹æ—¶éå¸¸é‡è¦ã€‚æ‚¨ä¹Ÿå¯ä»¥æ‰“å¼€ *Courses.csv* æ–‡ä»¶ï¼Œè‡ªå·±è¿›è¡Œå¦‚ä¸‹è§‚å¯Ÿã€‚

1.  è¯¾ç¨‹æ•°æ®æ–‡æœ¬æè¿°é’ˆå¯¹è¯¾ç¨‹ Idã€è¯¾ç¨‹æ ‡é¢˜å’Œè¯¾ç¨‹æè¿°åˆ—å‘ˆç°ã€‚å› æ­¤ï¼Œåœ¨æ„å»ºæˆ‘ä»¬çš„æ¨èå¼•æ“æ—¶ï¼Œè¿™äº›åˆ—æ˜¯æˆ‘ä»¬æ„Ÿå…´è¶£çš„ã€‚åˆ©ç”¨è¿™äº›åˆ—ä¸­çš„æ–‡æœ¬æ•°æ®ï¼Œæˆ‘ä»¬å°†èƒ½å¤Ÿæ„å»ºè¯å‘é‡ï¼Œæˆ‘ä»¬çš„æ¨¡å‹å°†åœ¨é¢„æµ‹ç»“æœæ—¶ä½¿ç”¨è¿™äº›è¯å‘é‡ã€‚æ­¤å¤–ï¼Œå¤§éƒ¨åˆ†ä¿¡æ¯ä»…å‡ºç°åœ¨*ã€æè¿°ã€‘*æ ä¸­ã€‚å› æ­¤ï¼Œæ²¡æœ‰æè¿°çš„è¯¾ç¨‹å°†ä»åŸ¹è®­ä¸­åˆ é™¤ã€‚
2.  â€œå·²é€€ä¼‘â€æ æè¿°äº†ç½‘ç«™ä¸Šè¯¾ç¨‹çš„å½“å‰çŠ¶æ€ï¼Œå³ç½‘ç«™ä¸Šç›®å‰æ˜¯å¦æœ‰è¯¥è¯¾ç¨‹ã€‚å› æ­¤ï¼Œæˆ‘ä»¬ä¸æƒ³æ¨èæˆ‘ä»¬è®­ç»ƒæœ‰ç´ çš„æ¨¡å‹çš„é€€å½¹è¯¾ç¨‹ã€‚ä½†æ˜¯ï¼Œæˆ‘ä»¬ç»å¯¹å¯ä»¥åœ¨æˆ‘ä»¬çš„è®­ç»ƒæ•°æ®ä¸­ä½¿ç”¨å®ƒä»¬ã€‚
3.  å¹¶å¯¹è¯¥æ•°æ®çš„é¢„å¤„ç†è¿›è¡Œäº†è®¨è®ºã€‚æ•°æ®ä¸­æ˜¾ç„¶å­˜åœ¨ä¸€äº›é¢å¤–çš„'-'æ ‡è®°ã€ä¸åŒçš„å¤§å°å†™å’Œåœç”¨è¯ã€‚æˆ‘ä»¬å°†ç›¸åº”åœ°é¢„å¤„ç†æˆ‘ä»¬çš„æ–‡æœ¬ï¼Œåªå…³æ³¨åè¯/åè¯çŸ­è¯­ã€‚

åœ¨ä¸‹ä¸€èŠ‚ä¸­ï¼Œæˆ‘ä»¬å°†è®¨è®ºæ­£åœ¨å¼€å‘çš„è¿™ä¸ªæ¨èå®ç”¨ç¨‹åºçš„åŸºæœ¬æ¶æ„ã€‚æœ‰äº†è¿™ä¸ªæ¶æ„ï¼Œæœ€ç»ˆæˆ‘ä»¬å°†æ‹¥æœ‰ä¸€ä¸ªå®Œæ•´çš„æœºå™¨å­¦ä¹ å·¥å…·ï¼Œå®ƒå°†è¯¾ç¨‹æ•°æ®ä½œä¸ºè¾“å…¥ï¼Œå¹¶åŸºäºç”¨æˆ·æŸ¥è¯¢ç”Ÿæˆå»ºè®®ã€‚

# æ¶æ„è®¾è®¡:æ„å»ºå®ç”¨å·¥å…·

ä¸‹å›¾æ¸…æ¥šåœ°è¯´æ˜äº†æˆ‘ä»¬åœ¨è¿™ä¸ªæ•°æ®ç§‘å­¦é¡¹ç›®ä¸­çš„æ¸ é“ã€‚è¯·åœ¨ä»¥ä»å·¦åˆ°å³çš„æ–¹å¼è¿›ä¸€æ­¥é˜…è¯»ä¹‹å‰å…ˆçœ‹ä¸€ä¸‹ã€‚

![](img/4231b069a63388dc9b38097c460c93d9.png)

**Three main components:** 1\. Pre-process & Train; 2\. Optimizations; 3\. Recommendation Utility Tool

è¿™ä¸ªå®ç”¨å·¥å…·ä¸»è¦åˆ†ä¸ºä¸‰ä¸ªç»„ä»¶ï¼Œæˆ‘ä»¬å°†åœ¨æ¥ä¸‹æ¥çš„ç« èŠ‚ä¸­è¯¦ç»†è®¨è®ºè¿™äº›ç»„ä»¶ã€‚ä¸»è¦æ˜¯å¯¹æ¨¡å‹è¿›è¡Œè®­ç»ƒå’Œä¼˜åŒ–ï¼Œå‡å°‘è¯¯å·®ã€‚ä¹‹åï¼Œæˆ‘ä»¬å°†ç¼–å†™å®ç”¨å·¥å…·ï¼Œè¯¥å·¥å…·å°†åŸºäºå”¯ä¸€è¯¾ç¨‹ id çš„è¾“å…¥æŸ¥è¯¢ç”Ÿæˆæ¨èã€‚

è®°ä½ä¸Šé¢çš„å·¥å…·æ¶æ„ï¼Œè®©æˆ‘ä»¬è½¬åˆ°é¢„å¤„ç†æ­¥éª¤ï¼Œå¹¶å¼€å§‹ä¸ºæˆ‘ä»¬çš„æ¨¡å‹è¿›è¡Œæ•°æ®æ‘„å–æ­¥éª¤ã€‚

# é¢„å¤„ç†æ­¥éª¤

æŒ‰ç…§ä¸‹é¢çš„ä»£ç ç‰‡æ®µï¼Œæˆ‘ä»¬å°†åšä¸€äº›å°çš„æ–‡æœ¬é¢„å¤„ç†ï¼Œå¦‚åˆ é™¤æ‰€æœ‰æ ‡ç‚¹ç¬¦å·ã€‚æ­¤å¤–ï¼Œåœ¨å¤§é‡çš„æœ¯è¯­ä¸­,â€œllâ€è¢«ç”¨åœ¨è¯¸å¦‚â€œweâ€™llâ€ã€â€œyouâ€™llâ€ç­‰æƒ…å†µä¸­ã€‚è¿™äº›ä¹Ÿä»*â€˜æè¿°â€™*æ–‡æœ¬ä¸­åˆ é™¤ã€‚æˆ‘ä»¬è¿˜å°†æ¶ˆé™¤åœç”¨è¯ï¼Œå¹¶ä»¥é€‚å½“çš„æ–¹å¼åˆå¹¶åŒ…å«æè¿°ã€è¯¾ç¨‹ idã€æ ‡é¢˜çš„åˆ—ã€‚è¯·å‚è€ƒä¸‹é¢çš„ä»£ç ç‰‡æ®µï¼Œä»¥éµå¾ªä¸Šè¿°æ­¥éª¤ã€‚

```
import pandas as pd# 1\. read data, from source
# "Courses.csv" file has been renamed
course_df = pd.read_csv("data/courses.csv")# 2\. drop rows with NaN values for any column, specifically 'Description'
# Course with no description won't be of much use
course_df = course_df.dropna(how='any')# 3\. Pre-processing step: remove words like we'll, you'll, they'll etc.
course_df['Description'] = course_df['Description'].replace({"'ll": " "}, regex=True)# 4\. Another Pre-preprocessing step: Removal of '-' from the CourseId field
course_df['CourseId'] = course_df['CourseId'].replace({"-": " "}, regex=True)# 5\. Combine three columns namely: CourseId, CourseTitle, Description
comb_frame = course_df.CourseId.str.cat(" "+course_df.CourseTitle.str.cat(" "+course_df.Description))# 6\. Remove all characters except numbers & alphabets
# Numbers are retained as they are related to specific course series also
comb_frame = comb_frame.replace({"[^A-Za-z0-9 ]+": ""}, regex=True)
```

åœ¨å¯¹ä¸Šè¿°æ•°æ®è¿›è¡ŒåŸºæœ¬çš„æ¸…ç†æ­¥éª¤åï¼Œ*â€˜comb _ frameâ€™*åŒ…å«äº†ä¸è¯¾ç¨‹ç›¸å…³çš„æ‰€æœ‰å¿…è¦çš„æ–‡å­—æè¿°ã€‚ä¹‹åï¼Œè®©æˆ‘ä»¬ç§»åŠ¨åˆ°è¿™ä¸ªæ–‡æœ¬çš„çŸ¢é‡åŒ–ï¼Œå¹¶è®­ç»ƒæˆ‘ä»¬çš„æ¨¡å‹ã€‚

# é—®é¢˜è®¨è®ºã€æ¨¡å‹è®­ç»ƒå’Œä¼˜åŒ–

ç°åœ¨ï¼Œæˆ‘ä»¬å°†æ‰€æœ‰éœ€è¦çš„æ–‡æœ¬æ•°æ®å‘ˆç°åœ¨ä¸€ä¸ªæ•°æ®æ¡†ä¸­ã€‚ä½†æ˜¯ï¼Œæˆ‘ä»¬éœ€è¦å°†å…¶è½¬æ¢æˆæœ‰æ„ä¹‰çš„è¡¨ç¤ºã€‚å› æ­¤ï¼Œå®ƒå¯ä»¥æ­£ç¡®åœ°è¾“å…¥åˆ°æˆ‘ä»¬çš„æœºå™¨å­¦ä¹ æ¨¡å‹ä¸­ã€‚

ä¸ºæ­¤ï¼Œæˆ‘ä»¬ä½¿ç”¨ ***tf-idf*** æƒé‡æ¥è¡¨ç¤ºæœ¯è¯­åœ¨æ–‡æ¡£ä¸­çš„é‡è¦æ€§ã€‚å®ƒæ˜¯å¯¹æ–‡æ¡£ä¸­å•è¯é‡è¦æ€§çš„ç»Ÿè®¡åº¦é‡ã€‚è¯¥æƒé‡ä¸å•è¯åœ¨è¯­æ–™åº“ä¸­å‡ºç°çš„æ¬¡æ•°ç›¸å…³ï¼Œä½†æ˜¯è¢«è¯­æ–™åº“ä¸­å•è¯çš„é¢‘ç‡æ‰€æŠµæ¶ˆã€‚

***Tf*** ä¸­çš„ ***tf-idf*** æƒé‡è¡¡é‡æ–‡æ¡£ä¸­çš„è¯é¢‘ã€‚ä»¥åŠ ***idf*** æµ‹é‡ç»™å®šè¯­æ–™åº“ä¸­ç»™å®šæœ¯è¯­é‡è¦æ€§ã€‚è¿™å¯ä»¥ä»ä¸‹é¢æåˆ°çš„å…¬å¼ä¸­æ¨æ–­å‡ºæ¥ã€‚

```
**TF(**t**)** = (Number of times term *'t'* appears in a document) **/** (Total number of terms in the document)**IDF(**t**)** = **log_e(**Total number of documents **/** Number of documents with term *'t'* in it**)**
```

æˆ‘ä»¬å°†ä½¿ç”¨ scikit learn å°†æˆ‘ä»¬çš„æ–‡æœ¬æ•°æ®è½¬æ¢ä¸ºä¸Šé¢å…¬å¼ä¸­æŒ‡å®šçš„å‘é‡çŸ©é˜µä¹˜ç§¯ã€‚æŒ‰ç…§ä¸‹é¢çš„ä»£ç ç‰‡æ®µè¿›è¡Œè½¬æ¢ã€‚

```
# Create word vectors from combined frames
# Make sure to make necessary importsfrom sklearn.cluster import KMeans
from sklearn import metrics
from sklearn.feature_extraction.text import TfidfVectorizervectorizer = TfidfVectorizer(stop_words='english')
X = vectorizer.fit_transform(comb_frame)
```

åœ¨æ­¤ä¹‹åï¼Œæˆ‘ä»¬å¯ä»¥å°†è¿™äº›æ•°æ®ç›´æ¥è¾“å…¥åˆ°æˆ‘ä»¬çš„ k å‡å€¼å­¦ä¹ ç®—æ³•ä¸­ã€‚ä½†æ˜¯ï¼Œå¯¹äºæˆ‘ä»¬çš„ k-means ç®—æ³•ï¼Œæˆ‘ä»¬å°†éœ€è¦***ã€kã€‘***çš„ç†æƒ³å€¼ï¼Œå¯¹æ­¤æˆ‘ä»¬è¿˜æ²¡æœ‰è®¨è®ºè¿‡ã€‚é¦–å…ˆï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨ k=8 çš„å€¼ï¼Œå› ä¸º Pluralsight æœ‰å…«ç§ä¸åŒç±»å‹çš„è¯¾ç¨‹ç±»åˆ«ï¼Œå¹¶æ£€æŸ¥æˆ‘ä»¬çš„æ¨¡å‹ç›¸åº”è®­ç»ƒçš„é¢„æµ‹èƒ½åŠ›ã€‚è·Ÿéšä¸‹é¢æåˆ°çš„ä»£ç ç‰‡æ®µã€‚

```
# true_k, derived from elbow method and confirmed from pluralsight's website
true_k = 8# Running model with 15 different centroid initializations & maximum iterations are 500
model = KMeans(n_clusters=true_k, init='k-means++', max_iter=500, n_init=15)
model.fit(X)
```

æˆ‘ä»¬å¯ä»¥è§‚å¯Ÿæ¥è‡ªæ¯ä¸ªèšç±»çš„é¡¶è¯ï¼Œä»¥æŸ¥çœ‹æ‰€å½¢æˆçš„èšç±»åœ¨è´¨é‡ä¸Šæ˜¯å¦è‰¯å¥½ï¼Œæˆ–è€…å®ƒä»¬åœ¨æŸç§æ„ä¹‰ä¸Šæ˜¯å¦éœ€è¦æ”¹è¿›ã€‚è¿è¡Œä¸‹é¢æåˆ°çš„ç‰‡æ®µï¼Œè§‚å¯Ÿæ¯ä¸ªèšç±»ä¸­çš„çƒ­é—¨è¯ã€‚

```
# Top terms in each clusters.print("Top terms per cluster:")
order_centroids = model.cluster_centers_.argsort()[:, ::-1]
terms = vectorizer.get_feature_names()
for i in range(true_k):
    print("Cluster %d:" % i),
    for ind in order_centroids[i, :15]:
        print(' %s' % terms[ind]),
    print
```

è§‚å¯Ÿè¿™äº›å•è¯åï¼Œæ‚¨å¯èƒ½ä¼šæ³¨æ„åˆ°æ‰€æœ‰å½¢æˆçš„é›†ç¾¤éƒ½ä¸åˆé€‚ï¼Œä¸€äº›è¯¾ç¨‹ç±»åˆ«åœ¨å¤šä¸ªé›†ç¾¤ä¸­é‡å¤å‡ºç°(è¯·å‚è€ƒ [README.md](https://github.com/ashishrana160796/Online-Course-Recommendation-System) æ–‡ä»¶)ã€‚é‚£ç°åœ¨è¿˜æ˜¯å¥½çš„(*ğŸ˜‰*)ï¼Œæˆ‘ä»¬çš„æ¨¡å‹å°†æ•°é‡å·¨å¤§çš„è¯¾ç¨‹ç±»åˆ«ç»†åˆ†ä¸ºå…¶ä»–å­ç±»åˆ«ã€‚å› æ­¤ï¼Œç»™å®šç±»åˆ«çš„è¯¾ç¨‹æ•°é‡çš„åŸºæ•°é—®é¢˜æš´éœ²å‡ºæ¥ï¼Œæˆ‘ä»¬çš„æ¨¡å‹æ— æ³•è§£å†³ã€‚

æˆ‘ä»¬å¯ä»¥çœ‹åˆ°ï¼Œç»†åˆ†ç±»åˆ«å¹³é¢è‰ºæœ¯ï¼Œç”µå½±è®¾è®¡ï¼ŒåŠ¨ç”»å½¢æˆäº†æ¯'åˆ›æ„-ä¸“ä¸š'ç±»åˆ«ã€‚ç”±äºè¯¾ç¨‹ç±»åˆ«ä¹‹é—´çš„æ•°æ®åˆ†å¸ƒä¸å‡ï¼Œå³æ•°æ®åŸºæ•°çš„é—®é¢˜ï¼Œå› æ­¤å½¢æˆäº†è¿™ä¸ªå­ç±»ã€‚å› æ­¤ï¼Œåƒâ€œå•†åŠ¡-ä¸“ä¸šâ€è¿™æ ·è¯¾ç¨‹æ•°é‡å°‘çš„è¯¾ç¨‹ç±»åˆ«åœ¨æˆ‘ä»¬çš„ç†æƒ³å‡è®¾ä¸­è¿·å¤±äº†ï¼Œå› ä¸º **k** ç­‰äº 8ã€‚è¿™å¾ˆå®¹æ˜“å‘ç”Ÿï¼Œå› ä¸ºåœ¨æˆ‘ä»¬ç®€å•çš„æœºå™¨å­¦ä¹ æ¨¡å‹è®­ç»ƒä¸­ï¼Œä¸ç»å¸¸å‡ºç°çš„ä¸šåŠ¡ç›¸å…³æœ¯è¯­å¾ˆå®¹æ˜“å¤±å»å…¶ tf-idf æƒé‡ã€‚

å› æ­¤ï¼Œä»è¿™ç§æ–¹æ³•å¾—åˆ°çš„èšç±»ä»ç„¶å¯ä»¥é€šè¿‡è¿›ä¸€æ­¥åˆ’åˆ†æˆå…¶ä»–èšç±»æ¥æ”¹è¿›ï¼Œä»¥ç”¨æ›´å°‘æ•°é‡çš„è¯¾ç¨‹å¾—åˆ°è¿™äº›æ›´å°çš„è¯¾ç¨‹ç±»åˆ«ã€‚å› ä¸ºï¼Œè¿™äº›è¿›ä¸€æ­¥çš„åˆ’åˆ†å¯ä»¥å…¬å¼åŒ–ä¸ºè¯¯å·®æœ€å°åŒ–çš„ä¼˜åŒ–é—®é¢˜ã€‚æˆ‘ä»¬ä¸æƒ³å› æ­¤è¿‡åº¦æ‹Ÿåˆæˆ‘ä»¬çš„æ¨¡å‹ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨ ***ã€è‚˜æµ‹è¯•ã€‘*** æ–¹æ³•æ¥å¯»æ‰¾ ***k*** çš„ç†æƒ³å€¼ã€‚*è¿™ä¸ªæƒ³æ³•æ˜¯ï¼Œæ¯å½“ç»™å®šçš„****ã€kâ€™******çš„å€¼çš„è¯¯å·®æ€¥å‰§ä¸‹é™æ—¶ï¼Œè¯¥å€¼å¯¹äºå½¢æˆèšç±»æ¥è¯´è¶³å¤Ÿå¥½ã€‚*è¿™äº›å½¢æˆçš„é›†ç¾¤å°†å…·æœ‰å°–é”çš„è¯¯å·®æå°å€¼ï¼Œå¹¶å°†ä¸ºæˆ‘ä»¬çš„æ¨¡å‹ç»™å‡ºä»¤äººæ»¡æ„çš„è§£å†³æ–¹æ¡ˆã€‚æŒ‰ç…§ä¸‹é¢æåˆ°çš„ä»£ç å¯¹æˆ‘ä»¬çš„æ•°æ®è¿›è¡Œå¼¯å¤´æµ‹è¯•ã€‚**

```
**# Continuing after vectorization step# data-structure to store Sum-Of-Square-Errors
sse = {}# Looping over multiple values of k from 1 to 30
for k in range(1, 40):
    kmeans = KMeans(n_clusters=k, init='k-means++', max_iter=100).fit(X)
    comb_frame["clusters"] = kmeans.labels_
    sse[k] = kmeans.inertia_# Plotting the curve with 'k'-value vs SSE
plt.plot(list(sse.keys()), list(sse.values()))
plt.xlabel("Number of cluster")
plt.ylabel("SSE")
# Save the Plot in current directory
plt.savefig('elbow_method.png')**
```

**è¿è¡Œä¸Šè¿°ä»£ç åï¼Œæˆ‘ä»¬å¾—åˆ°äº†ä¸‹å›¾ï¼Œåœ¨æ­¤åŸºç¡€ä¸Šï¼Œæˆ‘ä»¬ä¸º k=30 è®­ç»ƒäº†æˆ‘ä»¬çš„æ¨¡å‹ã€‚å¹¶ä¸ºæˆ‘ä»¬çš„æ¨èå¼•æ“å·¥å…·å®ç°äº†ç›¸å¯¹æ›´å¥½çš„èšç±»ã€‚**

**![](img/b628c9b3dd7d6f0e477edfe9150a2d26.png)**

**Slope is drastically diminishing after the value of k=30\. Hence, weâ€™ll opt for this value for our model.**

**æœ€åï¼Œè®©æˆ‘ä»¬ä¿å­˜æˆ‘ä»¬çš„æ¨¡å‹ï¼Œç»§ç»­æˆ‘ä»¬çš„æ¨èå®ç”¨ç¨‹åºè„šæœ¬è®¾è®¡ï¼Œå¹¶è®¨è®ºæœªæ¥çš„æ”¹è¿›æ–¹æ³•ã€‚æ‰€æœ‰è¿™äº›æåˆ°çš„ç‰‡æ®µéƒ½ä»¥ [model_train.py](https://github.com/ashishrana160796/Online-Course-Recommendation-System/blob/master/model_train_k_30.py) è„šæœ¬çš„å½¢å¼æä¾›ï¼Œæ‚¨å¯ä»¥å‚è€ƒå®ƒæ¥ç›´æ¥æ‰§è¡Œã€‚ä½†æ˜¯ï¼Œåœ¨æ­¤ä¹‹å‰ï¼Œè¯·æå– courses.csv æ•°æ®æ–‡ä»¶ï¼Œå¹¶ä»”ç»†é˜…è¯» [README.md](https://github.com/ashishrana160796/Online-Course-Recommendation-System) ã€‚**

```
**# Save machine learning model
filename = 'finalized_model.sav'
pickle.dump(model, open(filename, 'wb'))**
```

# **å·¥ä½œæ¨èç³»ç»Ÿ**

**æˆ‘ä»¬å°†ä¸ºè¿™ä¸ªæ¨èæ¨¡å—åˆ›å»ºå‡ ä¸ªå®ç”¨å‡½æ•°ã€‚ä¸€ä¸ª cluster_predict å‡½æ•°ï¼Œå®ƒå°†é¢„æµ‹è¾“å…¥å…¶ä¸­çš„ä»»ä½•æè¿°çš„åˆ†ç±»ã€‚é¦–é€‰è¾“å…¥æ˜¯æˆ‘ä»¬ä¹‹å‰åœ¨ [model_train.py](https://github.com/ashishrana160796/Online-Course-Recommendation-System/blob/master/model_train_k_30.py) æ–‡ä»¶çš„ comb_frame ä¸­è®¾è®¡çš„ç±»ä¼¼â€œæè¿°â€çš„è¾“å…¥ã€‚**

```
**def cluster_predict(str_input):
    Y = vectorizer.transform(list(str_input))
    prediction = model.predict(Y)
    return prediction**
```

**ä¹‹åï¼Œæˆ‘ä»¬å°†æ ¹æ®æ–°çš„ dataframe åˆ—ä¸­çš„æè¿°å‘é‡ä¸ºæ¯ä¸ªè¯¾ç¨‹åˆ†é…ç±»åˆ«ï¼Œå³*â€˜cluster predictionâ€™*ã€‚è§ä¸‹æ–‡ã€‚**

```
**# Create new column for storing predicted categories from our trained model.
course_df['ClusterPrediction'] = ""**
```

**æˆ‘ä»¬å°†ä¸ºåªæœ‰å®æ—¶è¯¾ç¨‹çš„æ•°æ®æ¡†å­˜å‚¨è¯¥èšç±»ç±»åˆ«åˆ†æ•°ï¼Œå³åˆ é™¤â€œæ— â€å®æ—¶æ¡ç›®çš„è¯¾ç¨‹ã€‚ä¹‹åï¼Œæˆ‘ä»¬å°†åœ¨æ•°æ®æ¡†ä¸­ä¸ºæ¯é—¨è¯¾ç¨‹è¿è¡Œé¢„æµ‹å‡½æ•°å®ç”¨ç¨‹åºï¼Œå¹¶å­˜å‚¨èšç±»ç±»åˆ«ã€‚è¿™äº›å­˜å‚¨çš„ç±»åˆ«å°†åœ¨å°†æ¥ä¸è¾“å…¥æŸ¥è¯¢åŠå…¶é¢„æµ‹ç±»åˆ«è¿›è¡ŒåŒ¹é…ï¼Œä»¥ç”Ÿæˆæ¨èã€‚**

```
**# load the complete data in a dataframe
course_df = pd.read_csv("data/courses.csv")# drop retired course from analysis. But, courses with no descriptions are kept.
course_df = course_df[course_df.IsCourseRetired == 'no']

# create new column in dataframe which is combination of (CourseId, CourseTitle, Description) in existing data-frame
course_df['InputString'] = course_df.CourseId.str.cat(" "+course_df.CourseTitle.str.cat(" "+course_df.Description))# Create new column for storing predicted categories from our trained model.
course_df['ClusterPrediction'] = ""# Cluster category for each live course
course_df['ClusterPrediction']=course_df.apply(lambda x: cluster_predict(course_df['InputString']), axis=0)**
```

**æœ€åï¼Œæ¨èå®ç”¨å‡½æ•°å°†é¢„æµ‹å…·æœ‰è¯¾ç¨‹ id çš„è¾“å…¥æŸ¥è¯¢çš„è¯¾ç¨‹ç±»åˆ«ï¼Œå¹¶ä¸”å°†ä»ä¸Šé¢è½¬æ¢çš„æ•°æ®å¸§*â€˜course _ dfâ€™*ä¸­æ¨èå‡ ä¸ªéšæœºè¯¾ç¨‹ï¼Œè¯¥æ•°æ®å¸§å…·æœ‰æ¯ä¸ªè¯¾ç¨‹çš„é¢„æµ‹å€¼ã€‚**

```
**def recommend_util(str_input):

    # match on the basis course-id and form whole 'Description' entry out of it.
    temp_df = course_df.loc[course_df['CourseId'] == str_input]
    temp_df['InputString'] = temp_df.CourseId.str.cat(" "+temp_df.CourseTitle.str.cat(" "+temp_df['Description']))
    str_input = list(temp_df['InputString'])
        # Predict category of input string category
    prediction_inp = cluster_predict(str_input)
    prediction_inp = int(prediction_inp) # Based on the above prediction 10 random courses are recommended from the whole data-frame
    # Recommendation Logic is kept super-simple for current implementation. temp_df = course_df.loc[course_df['ClusterPrediction'] == prediction_inp]
    temp_df = temp_df.sample(10)

    return list(temp_df['CourseId'])**
```

**ç”¨ä¸‹é¢ç»™å‡ºçš„æŸ¥è¯¢æµ‹è¯•ä½ è®­ç»ƒè¿‡çš„æ¨èå¼•æ“ã€‚æ‚¨ä¹Ÿå¯ä»¥é€šè¿‡ä» courses.csv è·å–è¯¾ç¨‹ id æ¥æ·»åŠ æ‚¨çš„æŸ¥è¯¢ã€‚**

```
**queries = ['play-by-play-machine-learning-exposed', 'microsoft-cognitive-services-machine-learning', 'python-scikit-learn-building-machine-learning-models', 'pandas-data-wrangling-machine-learning-engineers', 'xgboost-python-scikit-learn-machine-learning']for query in queries:
    res = recommend_util(query)
    print(res)**
```

# **ç»“è®ºå’Œæœªæ¥æ”¹è¿›**

**å½“å‰æ¨èå¼•æ“çš„å®ç°æœ¬è´¨ä¸Šæ˜¯éå¸¸åŸå§‹çš„ã€‚ç”¨ç²¾ç¡®çš„ç¡¬æ­¥éª¤é˜ˆå€¼æ¥å½¢æˆé›†ç¾¤çš„æ–¹æ³•æ˜¯ç²—ç³™çš„ï¼Œä½†æ˜¯ç»™å‡ºäº†ç”¨é›†ç¾¤åŒ–ç®—æ³•å®ç°è¿™äº›å¼•æ“çš„æƒ³æ³•ã€‚æ­¤å¤–ï¼Œç”Ÿæˆçš„æ¨èæœ¬è´¨ä¸Šæ˜¯éšæœºçš„ã€‚å¯ä»¥é‡‡ç”¨æ›´å…·ä½“çš„æ–¹æ³•(å¦‚åŸºäºæœ€é«˜å¾—åˆ†çš„æ¨èæ–¹æ³•)ä½œä¸ºæ”¹è¿›ã€‚ç›®å‰ï¼Œcourse-id ä½œä¸ºå”¯ä¸€çš„è¾“å…¥ï¼Œè€Œä¸æ˜¯æ›´å¥½çš„è‡ªç„¶è¯­è¨€è¾“å…¥ã€‚ä½†æ˜¯ï¼Œè¿™äº›åªæ˜¯åŸºäºå®æ–½çš„æ”¹è¿›ã€‚**

**åŸºæœ¬ä¸Šï¼Œä¸ºäº†å°†æ¥çš„æ”¹è¿›ï¼Œç”¨äºè®­ç»ƒçš„ç±»åˆ«åˆ†é…æœºåˆ¶å’Œæ¨¡å‹å¯ä»¥è¢«æ”¹å˜ã€‚æ­¤å¤–ï¼Œå¯ä»¥é‡‡ç”¨æ¥è‡ªä¸»é¢˜å»ºæ¨¡çš„é«˜çº§å’Œå¤æ‚çš„æœºåˆ¶ï¼Œå¦‚æ½œåœ¨ç‹„åˆ©å…‹é›·åˆ†é…(LDA)ã€‚ä¸»é¢˜å»ºæ¨¡æ˜¯è‡ªç„¶è¯­è¨€å¤„ç†çš„ä¸€ä¸ªç»Ÿè®¡åˆ†æ”¯ï¼Œå®ƒä»æ–‡æ¡£é›†ä¸­æå–æ‘˜è¦ã€‚æˆ‘ä»¬å°†ä½¿ç”¨ LDAï¼Œå®ƒå°†ä¸€ä¸ªç‰¹å®šçš„æ–‡æ¡£åˆ†é…ç»™ä¸€ä¸ªç‰¹å®šçš„ä¸»é¢˜å’Œä¸€ä¸ªå®æ•°æƒé‡åˆ†æ•°ï¼Œè¯¥åˆ†æ•°å°†ä¸ç›¸åº”ä¸»é¢˜çš„å•è¯ç›¸å…³è”ã€‚**

> **åªéœ€è¿è¡Œ [lda_train.py](https://github.com/ashishrana160796/Online-Course-Recommendation-System/blob/master/lda_train.py) æ¥è¯¦ç»†äº†è§£ lda çš„å®ç°ï¼Œæ³¨é‡Š/æ§åˆ¶å°è¾“å‡ºå°†è§£é‡Šå…³äºæ­£åœ¨æ‰§è¡Œçš„æ­¥éª¤çš„ä¸€åˆ‡ã€‚**

**è¿™äº›æŒ‡å®šçš„ä¸»é¢˜åŠå…¶ä¸å•è¯çš„å…³è”åˆ†æ•°å¯ä»¥ä½œä¸ºä¸Šè¿° *cluster_prediction* å‡½æ•°çš„é¢„æµ‹é€»è¾‘åŸºç¡€ã€‚ä½†æ˜¯ï¼Œè¿™äº›é¢„æµ‹å°†æ¯”å½“å‰ç”± k-means èšç±»ç®—æ³•ç”Ÿæˆçš„ä»»ä½•æ¨èæ›´ç²¾ç¡®ã€‚ä¸€ä¸ªåŸºäº gensim çš„ LDA å®ç°åœ¨[è¿™é‡Œ](https://github.com/ashishrana160796/Online-Course-Recommendation-System/blob/master/lda_train.py)çš„åŒä¸€ä¸ª [github](https://github.com/ashishrana160796/Online-Course-Recommendation-System) ä»“åº“ä¸­å¯ç”¨ã€‚å®ƒçš„æ¨èå®ç”¨ç¨‹åºè„šæœ¬ç›®å‰è¿˜æ²¡æœ‰æ·»åŠ ï¼Œä½ å¯ä»¥ä½œä¸ºå®¶åº­ä½œä¸šæ¥å°è¯•ã€‚**

**éœæ™®ï¼Œä½ å–œæ¬¢è¯»å®ƒï¼Œå¹¶å¾—åˆ°äº†ä¸€ä¸ªæ•°æ®ç§‘å­¦é¡¹ç›®çš„å°æ‰‹ã€‚å¦‚æœæœ‰ä»»ä½•æ”¹è¿›ï¼Œè¯·åœ¨ [github](https://github.com/ashishrana160796/Online-Course-Recommendation-System) ä¸Šåšä¸€ä¸ªå…¬å…³æˆ–å…¬å¼€ä¸€ä¸ªé—®é¢˜ã€‚**