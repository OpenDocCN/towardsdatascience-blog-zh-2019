<html>
<head>
<title>Everybody Wants to be a Cat</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">每个人都想成为一只猫</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/everybody-wants-to-be-a-cat-6dd6190c5d9c?source=collection_archive---------31-----------------------#2019-11-28">https://towardsdatascience.com/everybody-wants-to-be-a-cat-6dd6190c5d9c?source=collection_archive---------31-----------------------#2019-11-28</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="4d97" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">fast.ai《程序员实用深度学习》第六课</h2></div><p id="6c7f" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我正在学习 fast.ai 的杰瑞米·霍华德和雷切尔·托马斯的<a class="ae lb" href="https://course.fast.ai/" rel="noopener ugc nofollow" target="_blank">“程序员实用深度学习”</a>课程，并在博客上记录我的经历。由于非常慷慨的 fast.ai 社区已经为每一课做了详细的笔记(参见第六课的笔记<a class="ae lb" href="https://github.com/hiromis/notes/blob/master/Lesson6.md" rel="noopener ugc nofollow" target="_blank">这里</a>)，我只是写下讲座的部分内容，并附上我需要停下来思考几次的 Jupyter 笔记本。</p><p id="1b52" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我需要回顾的第一个主题出现在关于数据扩充的仿射变换的讨论中。“仿射”又是什么意思？与线性有关。我咨询了谷歌，找到了很多解释，都非常清晰，但是<a class="ae lb" href="https://math.stackexchange.com/questions/275310/what-is-the-difference-between-linear-and-affine-function" rel="noopener ugc nofollow" target="_blank">数学堆栈交换的这个</a>对我来说很有用:线性函数只是缩放，但是仿射函数缩放并移位。</p><p id="9717" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">第六课剩下的大部分时间，我都在理解卷积。杰里米说，文件中的所有图片都是关于猫的，因为<a class="ae lb" href="https://twitter.com/GuggerSylvain" rel="noopener ugc nofollow" target="_blank">西尔万·古格</a>喜欢猫，而且他写了大部分文件(尽管<a class="ae lb" href="https://forums.fast.ai/t/lesson-6-in-class-discussion/31440/129?u=go_go_gadget" rel="noopener ugc nofollow" target="_blank">西尔万说</a>他不喜欢猫，事实上，只是把它们放在文件中以吸引人们阅读文件，这很有趣)。</p><p id="0209" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">因此，让我们探索回旋，并保持与暴躁猫(RIP)猫的主题。</p><figure class="ld le lf lg gt lh gh gi paragraph-image"><div class="gh gi lc"><img src="../Images/2a757e51827b9207dd27678dfa5e6ba0.png" data-original-src="https://miro.medium.com/v2/resize:fit:550/format:webp/1*t7okVq8lQ75rAG8qk8QB3w.jpeg"/></div></figure><p id="81a0" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">Jeremy 使用 Bret Victor 的<a class="ae lb" href="http://setosa.io/ev/image-kernels/" rel="noopener ugc nofollow" target="_blank">图像内核动画</a>来说明卷积运算是如何工作的。给定一个矩阵，其元素表示图像的像素，卷积采用该矩阵的一个元素，并使用如下所示的 3 x 3 矩阵(通常为正方形)对所选元素/像素周围的元素值进行逐元素矩阵乘法，该像素位于矩阵的中心。如果像素靠近图像的边缘，我们可能需要“填充”矩阵，如 Francesco Visin 的动画<a class="ae lb" href="https://github.com/vdumoulin/conv_arithmetic/blob/master/README.md" rel="noopener ugc nofollow" target="_blank">所示。最后，我们将所有的乘积相加得到一个值(所以用线性代数术语来说，我们只是在做点积)。</a></p><p id="db25" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">使用下面显示的带有“锐化”内核的 Grumpy Cat 图像，我们看到内核将通过将其乘以 5 来强烈强调它“正在看”的像素(中心的像素)，同时通过将其乘以 0 或-1 来削弱其周围的像素，从而增加它们之间的对比度。</p><figure class="ld le lf lg gt lh gh gi paragraph-image"><div role="button" tabindex="0" class="ll lm di ln bf lo"><div class="gh gi lk"><img src="../Images/d3dc43d0d8999033bddb3bef0c80dc5f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*XfL4g6F381ywaLiifnnaYA.png"/></div></div></figure><p id="7691" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">类似地，使用“模糊”内核，我们看到该内核将相关像素的值降低到 0.25，但将周围像素的值降低得更多，这降低了整体对比度。</p><figure class="ld le lf lg gt lh gh gi paragraph-image"><div role="button" tabindex="0" class="ll lm di ln bf lo"><div class="gh gi lp"><img src="../Images/3e7fc42991899a00078c28bf69df851e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*OrXdQxoSNuQ5gbhWD-9VsA.png"/></div></div></figure><p id="7876" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">有时候，当学习一些东西时，可能会觉得“是的，所有这些都很有道理，我完全明白了，”然后你试图解释它，并意识到你实际上对你刚才听到的几乎一无所知。停下来向别人解释你刚学到的一个概念，即使那个人是虚构的(或者一个博客；) )，是一种高效确定自己是否真正理解的方法！</p><p id="e4e8" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这一刻对我来说是其中之一:我们正在通过一系列卷积运行张量，每个卷积都减少了高度和宽度，但增加了输出通道的数量，当我们完成时，我们得到了下图所示的张量。</p><figure class="ld le lf lg gt lh gh gi paragraph-image"><div role="button" tabindex="0" class="ll lm di ln bf lo"><div class="gh gi lq"><img src="../Images/49223367b93c5c798281ef9f49bc8859.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/1*X4KLZ0WhCje2NboyrGTVxA.gif"/></div></div><figcaption class="lr ls gj gh gi lt lu bd b be z dk"><a class="ae lb" href="https://www.youtube.com/watch?v=U7c-nYXrKD4&amp;feature=youtu.be&amp;t=5630" rel="noopener ugc nofollow" target="_blank">https://www.youtube.com/watch?v=U7c-nYXrKD4&amp;feature=youtu.be&amp;t=5630</a></figcaption></figure><p id="45cb" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">512 感觉有点正常，是 2 的幂，但是为什么我们在 11 停下来，特别是对于其他两个维度？</p><p id="f4d2" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我几乎没有写出来，因为为了弄清楚，我只是看了视频，看了几十遍笔记，最后，我觉得我没有什么要补充的。但为了理解它，我不得不按照与视频/笔记中显示的不同的顺序为自己写下它，所以这里是那篇文章，以防它对其他人有所帮助。</p><p id="b018" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">所以让我们后退。我们从表示图像的张量开始，该张量有 3 个通道(红色、蓝色和绿色)，高度为 352 像素，宽度为 352 像素。这是张量的形状:</p><figure class="ld le lf lg gt lh gh gi paragraph-image"><div role="button" tabindex="0" class="ll lm di ln bf lo"><div class="gh gi lv"><img src="../Images/00d1a50fb58dee01eb13ab346125f8eb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Btw4lJ9fRGncbmGke8j9QQ.png"/></div></div></figure><p id="66c9" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们有很多图像，这么多这样的张量，但是 PyTorch 希望我们使用每个图像的小批量，所以<a class="ae lb" href="https://youtu.be/U7c-nYXrKD4?t=5538" rel="noopener ugc nofollow" target="_blank">正如 Jeremy 所说的</a>，我们可以用特殊值<code class="fe lw lx ly lz b">None</code>索引到数组中，这创建了一个新的单位轴，给我们一个形状为<code class="fe lw lx ly lz b">[1, 3, 352, 352]</code>的秩为 4 的张量。这是一个小批量的 1 图像，它有 3 个通道，高 352 像素，宽 352 像素。我必须不断检查的一件事是，shape 函数在高度和宽度之前返回通道，但当我们将张量视为多维矩阵时，我们将维度列为高度 x 宽度 x 通道数。所以在矩阵术语中，上面的张量的维数是 352 x 352 x 3(记住 1 不是矩阵的维数；就是小批量的大小)。</p><p id="531a" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">然后我们通过一系列的激活来运行张量，从一个 2 维卷积<code class="fe lw lx ly lz b">Conv2d</code>开始，使用大小为 2 的步幅。这意味着它不是“看”矩阵的每个元素，而是“看”所有其他元素，“跳过”其中的一半。这就是导致高度和宽度减半，输出通道数量翻倍的原因。</p><figure class="ld le lf lg gt lh gh gi paragraph-image"><div role="button" tabindex="0" class="ll lm di ln bf lo"><div class="gh gi ma"><img src="../Images/3568011781aca12e5cc394dcb4ae9eb6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*jTB7VkyAO1FDl2-S6OlK0w.png"/></div></div></figure><p id="fa22" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">因此，当我们通过第一个卷积层运行张量时，我们获得一个 352 x 352 x 3 的维度矩阵，并通过 64 个步长为 2 的卷积(或内核)运行它，我们得到一个(352 / 2) x (352 / 2) x 64 的维度矩阵；也就是说，它是 176 x 176 x 64，或者用 PyTorch 形状来表示，如下所示:</p><figure class="ld le lf lg gt lh gh gi paragraph-image"><div role="button" tabindex="0" class="ll lm di ln bf lo"><div class="gh gi mb"><img src="../Images/0b18f826e56bf41088bc2ff461a2e631.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*1-ufOUlCO9HQXQCXhVkqYw.png"/></div></div></figure><p id="335c" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">然后，我们运行张量通过两个以上的层:<code class="fe lw lx ly lz b">BatchNorm2d</code>和<code class="fe lw lx ly lz b">ReLU</code>，它们不会改变形状，然后池层<code class="fe lw lx ly lz b">MaxPool2d</code>，它会改变形状为 88 x 88 x 64。我发现杰森·布朗利的<a class="ae lb" href="https://machinelearningmastery.com/pooling-layers-for-convolutional-neural-networks/" rel="noopener ugc nofollow" target="_blank">对卷积神经网络池层的温和介绍</a>对理解池层如何工作非常有帮助。</p><p id="2b2a" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们不断地对这些层进行多次检查，时不时地，我们将高度和宽度各除以 2，并将内核的数量加倍。因此，在某一点上，我们有 44 x 44 x 256，然后是 22 x 22 x 512，最后是我们想知道的 11 x 11 x 512 矩阵。</p><p id="fd01" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">所以我认为我们在高度和宽度上停留在 11，仅仅是因为 11 是一个奇数！如果我们将 11 除以 2，我们会得到 5.5，这对于矩阵来说不是一个合适的维数。感觉上我花在追逐张量上的时间和答案的简单性不成比例。尽管如此，我对立体体操的理解肯定比以前好得多，所以我想这很了不起！</p><p id="f5ee" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在 GitHub 上的<a class="ae lb" href="https://github.com/LauraLangdon/pets" rel="noopener ugc nofollow" target="_blank"> pets 笔记本</a>中查看完整代码，下周第 7 课再见！</p></div><div class="ab cl mc md hu me" role="separator"><span class="mf bw bk mg mh mi"/><span class="mf bw bk mg mh mi"/><span class="mf bw bk mg mh"/></div><div class="ij ik il im in"><p id="6bae" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">关于此主题的其他帖子:</p><p id="1ebe" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">第一课:<a class="ae lb" rel="noopener" target="_blank" href="/getting-started-with-fast-ai-350914ee65d2">fast . ai 入门</a></p><p id="e320" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">第 2 课:<a class="ae lb" rel="noopener" target="_blank" href="/classifying-pregnancy-test-results-99adda4bca4c">对妊娠试验结果进行分类</a></p><p id="bf23" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">第二课(续):<a class="ae lb" rel="noopener" target="_blank" href="/can-deep-learning-perform-better-than-pigeons-d37ef1581a2f">深度学习能比鸽子表现更好吗？</a></p><p id="df9e" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">第三课:<a class="ae lb" rel="noopener" target="_blank" href="/10-000-ways-that-wont-work-311925525cf0">一万种行不通的方法</a></p><p id="4ceb" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">第四课:<a class="ae lb" rel="noopener" target="_blank" href="/predicting-a-waiters-tips-1990342a0d02">预测服务员的小费</a></p><p id="3a44" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">第五课:<a class="ae lb" rel="noopener" target="_blank" href="/but-where-does-the-pickle-go-53619676bf5f">但是泡菜去哪里了？</a></p></div><div class="ab cl mc md hu me" role="separator"><span class="mf bw bk mg mh mi"/><span class="mf bw bk mg mh mi"/><span class="mf bw bk mg mh"/></div><div class="ij ik il im in"><p id="ae70" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我是加州大学东湾分校的数学讲师，也是一名有抱负的数据科学家。在<a class="ae lb" href="https://linkedin.com/in/laura-langdon/" rel="noopener ugc nofollow" target="_blank"> LinkedIn </a>上和我联系，或者在<a class="ae lb" href="https://twitter.com/laura_e_langdon" rel="noopener ugc nofollow" target="_blank"> Twitter </a>上和我打招呼。</p></div></div>    
</body>
</html>