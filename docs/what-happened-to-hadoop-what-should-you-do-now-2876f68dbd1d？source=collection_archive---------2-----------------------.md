# Hadoop 怎么了？你现在应该做什么？

> 原文：<https://towardsdatascience.com/what-happened-to-hadoop-what-should-you-do-now-2876f68dbd1d?source=collection_archive---------2----------------------->

![](img/3064cc7b1b740f790ef679e1a39b41f9.png)

拼接机的蒙特·兹韦本和赛义德·马哈茂德

Apache Hadoop 于 2006 年出现在 IT 领域，承诺为组织提供使用商用硬件存储前所未有的数据量的能力。这一承诺不仅解决了数据集的规模，还解决了数据的类型，例如企业越来越有兴趣分析的物联网设备、传感器、服务器和社交媒体生成的数据。数据量、速度和多样性的结合通常被称为大数据。

读取模式在 Hadoop 的流行中发挥了至关重要的作用。企业认为他们不再需要担心定义哪些表包含哪些数据以及它们如何相互连接的繁琐过程，这个过程需要几个月的时间，并且在完成之前没有一个数据仓库查询可以执行。在这个勇敢的新世界中，企业可以在基于 Hadoop 的存储库中存储尽可能多的数据，这些存储库被称为数据湖，并担心以后如何分析这些数据。

企业中开始出现数据湖。这些数据湖是通过商业大数据分发实现的，商业大数据分发是一个平台中支持的许多独立的开源计算引擎，这些平台将为数据湖提供动力，以不同的方式分析数据。最重要的是，所有这些都是开源的，可以免费尝试！什么会出错？

# 读取模式是一个错误

与生活中的许多事情一样，Hadoop 被吹捧为其优势的特性也成为了它的致命弱点。首先，随着写模式限制的解除，数 TB 的结构化和非结构化数据开始流入数据湖。由于 Hadoop 的数据治理框架和功能仍在定义中，企业越来越难以确定其数据湖的内容及其数据的血统。此外，数据还没有准备好被消费。企业开始对数据湖中的数据失去信心，慢慢地，这些数据湖开始变成数据沼泽。“构建它，它们就会到来”的读取模式哲学失败了。

# Hadoop 复杂性和胶带式计算引擎

![](img/3f036170690a17d81fc6e0ec54c1e69d.png)

其次，Hadoop 发行版提供了许多开源计算引擎，如 Apache Hive、Apache Spark 和 Apache Kafka，仅举几个例子，但这被证明是一件好事过多的情况。一个恰当的例子是，一个商业 Hadoop 平台由 26 个这样的独立引擎组成。这些计算引擎操作起来很复杂，需要专门的技能来将它们连接在一起，这在市场上很难找到。

# 错误的焦点:数据湖与应用程序

![](img/08e24730ad951cb2d8e9852f29997b53.png)

第三，也是最重要的一点，数据湖项目开始失败，因为企业优先考虑将所有企业数据存储在一个中心位置，目标是让所有开发人员都可以使用这些数据——如果你愿意，这是一个 uber 数据仓库，而不是考虑数据将如何影响应用程序。因此，Hadoop 集群经常成为企业数据管道的网关，用于过滤、处理和转换数据，然后将这些数据导出到其他数据库和数据集市，以便向下游报告，并且几乎从未在运营结构企业中找到真正的业务应用程序。因此，数据湖最终成为一组庞大的不同计算引擎，运行不同的工作负载，共享相同的存储。这很难管理。这个生态系统中的资源隔离和管理工具正在改进，但它们仍有一段路要走。所有这些复杂性—只是为了报告。

在大多数情况下，企业无法将注意力从将数据湖用作廉价的数据存储库和处理管道转移到消耗数据和驱动任务关键型应用程序的平台上。举个例子，Apache Hive 和 Apache Spark 是 Hadoop 数据湖中使用最广泛的计算引擎。这两个引擎都用于分析目的，要么处理类似 SQL 的查询(Hive)，要么执行类似 SQL 的数据转换并构建预测模型(Spark)。这些数据湖实现没有充分关注如何在应用程序中操作性地使用数据。

# 未来战略

因此，如果您的组织担心 Hadoop 生态系统的最新发展，并且在展示数据湖的价值方面面临越来越大的压力，您应该首先关注运营应用程序，然后再研究数据。

![](img/43a3215498d961fea06fe9e341cdebc7.png)

Photo by [Tiago Gerken](https://unsplash.com/@tiagogerken?utm_source=medium&utm_medium=referral&source=post_page---------------------------) on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral&source=post_page---------------------------)

通过专注于应用程序的数据和智能现代化，您将最终获得能够利用数据根据经验预测未来可能发生的事情的应用程序，并在产生卓越业务成果的时刻主动做出决策。以下是成功的应用程序现代化战略的五个要素:

1.  **选择一个需要现代化的应用**:首先，选择一个你想要现代化的应用，而不是集中精力集中数据。这方面的主要候选是许多定制应用程序中的一个，这些应用程序已经落后于市场，需要变得更加敏捷、智能和数据驱动。一旦您确定了可以为您的组织带来竞争优势的应用程序，那么您就可以专注于获取支持该应用程序所需的数据，以及是否可以从数据湖中获得该数据。
2.  **使用横向扩展 SQL 实现您的应用程序现代化** : SQL 多年来一直是企业中工作负载的主力，您的组织中有数百名开发人员、业务分析师和 IT 人员完全熟悉 SQL，无需花费额外的时间、费用和风险将您的原始 SQL 应用程序重新编写为低级 NOSQL API。选择一个平台，使您能够保持熟悉的 SQL 模式和强大的功能来更新应用程序，但要在一个可以在廉价基础架构上弹性扩展的架构上进行。横向扩展将整个集群的能力用于计算，比在集中式系统上运行的旧 SQL 系统快得多。借助横向扩展，您可以添加更多容量，也可以随着工作负载的变化而减少容量。
3.  **采用一个 ACID 平台** : ACID 合规性是一种机制，通过这种机制，事务保持数据库的完整性，并允许用户执行提交和回滚等操作。这是支持操作应用程序的一个关键功能，因为它确保了在发出 commit 之前，数据库不会对其他人进行更改。选择一个在数据库中的单个事务级别提供 ACID 功能的平台。否则，所有这些一致性问题都需要在应用程序代码中处理。所有传统的 SQL 系统都是 ACID 兼容的。数据湖错误地丢弃了这一点，使得应用程序很难编写。
4.  **统一分析引擎**:根据最近 Gartner [博客](https://blogs.gartner.com/adam-ronthal/2019/07/17/one-dbms-market/?source=post_page---------------------------)的报道，从历史上看，将 IT 基础设施分为运营(OLTP)和分析(OLAP)组件是有充分理由的，但现在不再是这样了。ETL 用延迟扼杀了我们的 SLA。过去的情况是，运营和分析工作负载相互干扰，您必须将它们分开。此外，遗留数据平台的性能很差，我们不得不将操作模式转换为更适合分析工作负载的星型模式或雪花型模式。不再需要这个 ETL，您可以在操作平台上运行分析，通常使用操作模式。通过实施该平台，您将确保您的应用程序运行在一个最大限度减少数据移动且不会增加应用程序延迟的平台上。与昨天或上周的数据相比，这可以提供您当前的见解、报告和仪表盘。
5.  **嵌入本机机器学习:**使您的应用程序现代化的主要原因之一是将 AI 和 ML 注入其中，以便它可以从经验中学习，动态适应变化，并做出即时决策。为了使您的应用程序智能化，选择一个在数据库级别内置机器学习的平台至关重要，这样模型就可以随时使用更新的数据进行实验、训练和执行。

这从根本上说是一种不同于迄今为止您使用的数据湖的方法。这种方法通过现在可以利用数据湖的应用程序，更快地向业务线交付有形的业务价值。

这种方法将确保除了使为您的企业提供竞争优势的应用程序现代化之外，您还可以保护您在数据湖中的投资。

如果您想免费尝试一个具有嵌入式分析和机器学习的横向扩展、ACID 兼容的 SQL RDBMS 示例，请单击此处的。