<html>
<head>
<title>Explainability of Missing Data Replacements</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">缺失数据替换的可解释性</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/explainability-of-missing-data-replacements-8eb164d68222?source=collection_archive---------23-----------------------#2019-08-24">https://towardsdatascience.com/explainability-of-missing-data-replacements-8eb164d68222?source=collection_archive---------23-----------------------#2019-08-24</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="a6b6" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">替换缺失的数据会让你的机器学习模型更难解释。以下是如何…</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/43b80d0600e89e6cc9055fb3b6240cb4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*QMAeWyyMjuPdgbGls3gc0w.jpeg"/></div></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk">Image by <a class="ae ky" href="https://pixabay.com/users/Anemone123-2637160/?utm_source=link-attribution&amp;utm_medium=referral&amp;utm_campaign=image&amp;utm_content=2736480" rel="noopener ugc nofollow" target="_blank">Anemone123</a> from <a class="ae ky" href="https://pixabay.com/?utm_source=link-attribution&amp;utm_medium=referral&amp;utm_campaign=image&amp;utm_content=2736480" rel="noopener ugc nofollow" target="_blank">Pixabay</a></figcaption></figure><h1 id="db80" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">介绍</h1><p id="fad2" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">输入缺失值是处理真实数据时的一个重要步骤。有几种常见的方法可以解决这个问题。一些流行的方法包括删除有缺失值的实例，为缺失元素创建一个单独的类别，或使用均值插补。它们不一定有效，还有其他算法，如<a class="ae ky" rel="noopener" target="_blank" href="/why-using-a-mean-for-missing-data-is-a-bad-idea-alternative-imputation-algorithms-837c731c1008"> KNN、MICE、MissForest </a>或<a class="ae ky" rel="noopener" target="_blank" href="/gans-and-missing-data-imputation-815a0cbc4ece"> GANs </a>可以更准确地估算缺失值。</p><p id="edc7" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">在我的研究实习项目期间，我注意到在用 KNN、小鼠和 MissForest 估算的数据集上训练的分类器实现了更高的准确性，通常是 3-4%。这是一个相当可观的精度增益，而且几乎没有现存的<a class="ae ky" rel="noopener" target="_blank" href="/why-using-a-mean-for-missing-data-is-a-bad-idea-alternative-imputation-algorithms-837c731c1008"> Python 库</a>实现这些算法。听起来不错，对吧？</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ms"><img src="../Images/2769af6e358870f03b8ef729492d4b10.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*jFmiFR_lcT54clxOko5Xtw.png"/></div></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk">Scheme for computing Classifier accuracy on the dataset with missing values [2]</figcaption></figure><p id="e9b2" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">不幸的是，在获得更高的精确度和得到可解释的结果之间有一个权衡。在这篇文章中，我们将看看缺失数据填补如何影响 ML 模型的可解释性。我文章的一部分将基于<a class="ae ky" href="https://arxiv.org/pdf/1907.12669.pdf" rel="noopener ugc nofollow" target="_blank">这篇研究论文</a>【1】。我们开始吧！</p></div><div class="ab cl mu mv hx mw" role="separator"><span class="mx bw bk my mz na"/><span class="mx bw bk my mz na"/><span class="mx bw bk my mz"/></div><div class="im in io ip iq"><p id="695d" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated"><em class="mt">我喜欢数据科学的原因是，它吸引了许多对人工智能和数据科学充满热情的志同道合的人。所以在</em><a class="ae ky" href="http://www.linkedin.com/in/kacperkubara?source=post_page---------------------------" rel="noopener ugc nofollow" target="_blank"><em class="mt">Linkedin</em></a><em class="mt">上和你联系会很棒！</em></p></div><div class="ab cl mu mv hx mw" role="separator"><span class="mx bw bk my mz na"/><span class="mx bw bk my mz na"/><span class="mx bw bk my mz"/></div><div class="im in io ip iq"><h1 id="8725" class="kz la it bd lb lc nb le lf lg nc li lj jz nd ka ll kc ne kd ln kf nf kg lp lq bi translated">不应估算的缺失数据</h1><p id="0fe6" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">保存关于缺失的信息对于 ML 模型有时可能是有用的。它还可以使模型更具解释力。</p><p id="61df" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">设想一个数据集，其中包含医院患者的信息，这些患者接受了某种疾病的检查。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ng"><img src="../Images/b468a3ebf47fd922ed3183151f8ccdd7.png" data-original-src="https://miro.medium.com/v2/resize:fit:716/format:webp/1*zfi9Ezjk_HouB2KJoU8__w.png"/></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk">Hospital patient data with missing values</figcaption></figure><p id="c0c9" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">3 号病人没有被诊断为患病。这就是为什么医生决定不再对<em class="mt">症状 _A </em>和<em class="mt">症状 _ b</em>做进一步的实验室测试。这里的遗漏有一个意思:<em class="mt">患者没有生病，因此遗漏了其他测量值</em>。如下图所示，患者 3 的输入值是错误的，没有意义。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nh"><img src="../Images/e74870fa2fe1f3951ee8a60f998ff870.png" data-original-src="https://miro.medium.com/v2/resize:fit:734/format:webp/1*MPl1cRPtWZ0uXnqvyhIvVA.png"/></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk">Hospital patient data with imputed missing values</figcaption></figure><p id="1bab" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">要保留关于缺失的信息，最好对数据进行一次性编码，并添加新的特性来指示缺失值的出现，如下所示。<em class="mt">(为了避免</em> <a class="ae ky" href="https://www.algosome.com/articles/dummy-variable-trap-regression.html" rel="noopener ugc nofollow" target="_blank"> <em class="mt">【哑变量陷阱】</em> </a> <em class="mt">我们可能应该去掉 Symptom_A_No 和 Symptom_B_No，但为了简单起见还是保留在这里)</em></p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ni"><img src="../Images/422f7013f3f5717efdf404917fc163ed.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*2EZpz8w8SHBUYNz69eaj5w.png"/></div></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk">Retaining information about missingness — rather than trying to replace it</figcaption></figure><p id="ec9a" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">在输入数据集之前，我们必须谨慎思考。这种归罪有意义吗？如果我们这样做，是否会造成重大信息损失？如果是，在这种情况下，将更难解释基于该估算数据训练的 ML 模型的结果。</p><p id="be3d" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">重要的是要注意，与我们的直觉相反，如果我们将缺失信息作为另一个特征，ML 模型的准确性可能会得到较低的准确性分数。这取决于估计器算法的性质以及它们在训练和测试阶段如何处理数据。这也是我在文章开头提到的在可解释性和准确性之间的权衡。</p><h1 id="bc96" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">缺失数据的分布可能不同</h1><p id="3478" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">数据可能以 3 种不同的方式丢失:MCAR(完全随机丢失)、马尔(随机丢失)和 NMAR(非随机丢失)。详细解释它们超出了本文的范围(如果您想了解更多，可以看看<a class="ae ky" rel="noopener" target="_blank" href="/how-to-handle-missing-data-8646b18db0d4">这篇文章</a>)。相反，我将关注 NMAR，它通常对可解释性有最大的负面影响。</p><p id="d2a3" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">NMAR 是一种缺失类型，其中缺失的数据取决于要素本身。例如，想象一下在美国进行的一项关于人民收入的调查:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nj"><img src="../Images/cd9b62998a2695be9898f798833749f3.png" data-original-src="https://miro.medium.com/v2/resize:fit:610/format:webp/1*vauyVACpEUdJ8BHvX_iWaA.png"/></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk">Annual Income with undisclosed data</figcaption></figure><p id="9fb1" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">一些调查参与者没有透露他们的工资。然而，我们不知何故从一个秘密来源得到了这些数据。没有丢失值的完整(真实)数据集如下所示。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nk"><img src="../Images/aefde20921ef7c855f55efb2f43c3873.png" data-original-src="https://miro.medium.com/v2/resize:fit:632/format:webp/1*eaFIjJsFbf-4FnfgcyIetA.png"/></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk">Annual Income with a complete (true) set of data</figcaption></figure><p id="7289" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">现在知道他们为什么不提工资了吧！他们只是比大多数人挣得多，他们可能不想和其他人分享这些信息。这正是 NMAR 的现状。<em class="mt">数据的缺失与特征本身有关。</em>在这种情况下，收入高于某个门槛的人在调查中没有透露他们的收入信息。</p><p id="a347" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">在 NMAR 的案例中，数据的估算可能会出错。问题是插补算法不知道这些缺失值的分布是什么。他们会假设它类似于整个数据集的分布，这显然是错误的！</p><p id="cf0b" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">让我们看看一个简单的均值插补是如何处理这种情况的:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nl"><img src="../Images/237657d7e94a815a8dbe62e4027c6d66.png" data-original-src="https://miro.medium.com/v2/resize:fit:628/format:webp/1*Nu1DqRgijnG-6YJMC1x3SQ.png"/></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk">Missing data replaced with the mean</figcaption></figure><p id="ce73" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">在 NMAR 的例子中，这些插补的可解释性会受到影响，模型的准确性会下降。正如数据科学家所说:“垃圾进，垃圾出”。</p><h1 id="1976" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">摘要</h1><p id="66bd" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">数据插补是机器学习管道中非常重要的一步，因为它会影响数据的质量。数据插补可以通过不同的方式降低机器学习模型的可解释性。有时，应通过创建附加要素来指示值何时缺失，从而保留关于缺失值的信息。NMAR，这种类型的数据缺失，可以使插补更难解释和不正确。还需要记住的是，更复杂的插补算法倾向于以更难解释的方式对数据进行插补，这会影响 ML 模型的可解释性。</p><h1 id="fd23" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">参考</h1><p id="7ce6" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">[1]<a class="ae ky" href="https://arxiv.org/pdf/1907.12669.pdf" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/pdf/1907.12669.pdf</a></p><p id="21c7" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">[2] <a class="ae ky" href="http://www.it-innovation.soton.ac.uk/" rel="noopener ugc nofollow" target="_blank"> IT 创新中心</a></p></div></div>    
</body>
</html>