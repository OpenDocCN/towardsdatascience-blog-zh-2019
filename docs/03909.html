<html>
<head>
<title>An “Equation-to-Code” Machine Learning Project Walk-Through — Part 4 Regularization</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">“等式到代码”机器学习项目演练—第 4 部分正则化</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/an-equation-to-code-machine-learning-project-walk-through-part-4-regularization-be3b44bb296a?source=collection_archive---------28-----------------------#2019-06-19">https://towardsdatascience.com/an-equation-to-code-machine-learning-project-walk-through-part-4-regularization-be3b44bb296a?source=collection_archive---------28-----------------------#2019-06-19</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="9372" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">用 Python 从头开始实现正则化的详细说明</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/7fc6d0005d1d25a81a0eb80689b30878.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*ixIw0lZ0FQVcQ3qk.jpg"/></div></div></figure><p id="3b08" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">大家好！这是“公式到代码”演练的第 4 部分，也是本系列的最后一部分。</p><p id="4e9d" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">在前面的文章中，我们谈到了<strong class="kw iu">中的线性可分问题</strong>中的<a class="ae lq" rel="noopener" target="_blank" href="/an-equation-to-code-machine-learning-project-walk-through-in-python-part-1-linear-separable-fd0e19ed2d7">第一部分</a>、<a class="ae lq" rel="noopener" target="_blank" href="/an-equation-to-code-machine-learning-project-walk-through-in-python-part-2-non-linear-d193c3c23bac">第二部分</a>中的<strong class="kw iu">非线性可分问题</strong>、<a class="ae lq" rel="noopener" target="_blank" href="/an-equation-to-code-machine-learning-project-walk-through-part-3-sgd-e4167225504b">第三部分</a>中的<strong class="kw iu">随机梯度下降(SGD) </strong>。就像其他部分一样，第 4 部分是独立的，您可以忽略前面的文章。</p><p id="5dc4" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">在第 4 部分中，我们将讨论如何实现回归问题的正则化，这可以使我们的模型更加健壮。</p><p id="6b03" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">下面是完整的代码，<a class="ae lq" href="https://gist.github.com/BrambleXu/4bc854fdf2a45f9eb1fbbae3aad5b291" rel="noopener ugc nofollow" target="_blank">regression _ without _ regulation . py</a>和<a class="ae lq" href="https://gist.github.com/BrambleXu/1adbbceff0da62a6d5193e5aefb00952#file-regression_with_regularization-py" rel="noopener ugc nofollow" target="_blank">regression _ with _ regulation . py</a>。</p><p id="ae6b" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">内容结构如下。</p><ol class=""><li id="5549" class="lr ls it kw b kx ky la lb ld lt lh lu ll lv lp lw lx ly lz bi translated">正规化</li><li id="7803" class="lr ls it kw b kx ma la mb ld mc lh md ll me lp lw lx ly lz bi translated">伪造一些数据样本</li><li id="5989" class="lr ls it kw b kx ma la mb ld mc lh md ll me lp lw lx ly lz bi translated">预处理</li><li id="000d" class="lr ls it kw b kx ma la mb ld mc lh md ll me lp lw lx ly lz bi translated">没有正规化的执行</li><li id="d52a" class="lr ls it kw b kx ma la mb ld mc lh md ll me lp lw lx ly lz bi translated">正规化实施</li><li id="415e" class="lr ls it kw b kx ma la mb ld mc lh md ll me lp lw lx ly lz bi translated">摘要</li></ol><h1 id="6dd1" class="mf mg it bd mh mi mj mk ml mm mn mo mp jz mq ka mr kc ms kd mt kf mu kg mv mw bi translated">1 正规化</h1><p id="2a35" class="pw-post-body-paragraph ku kv it kw b kx mx ju kz la my jx lc ld mz lf lg lh na lj lk ll nb ln lo lp im bi translated">如果我们的模型过于复杂，它会很好地拟合训练数据，但在新数据中会失败。我们把这种问题称为<strong class="kw iu">过拟合</strong>。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nc"><img src="../Images/52bdcdeb383f2e880b155b972405886a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1370/format:webp/1*zVYh5BmuBYIZeXDMkGxIFQ.png"/></div><figcaption class="nd ne gj gh gi nf ng bd b be z dk">from <a class="ae lq" href="https://slideplayer.com/slide/8012792/" rel="noopener ugc nofollow" target="_blank">ISCG8025</a></figcaption></figure><p id="5838" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">为了“不是很好地拟合训练数据”(上图中间)，我们通常使用一些技术来避免过度拟合，如交叉验证、剔除、批量标准化等。</p><p id="cd52" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">这一次，我们将讨论 L2 正则化项，它在大多数机器学习模型中被广泛使用。</p><h1 id="d971" class="mf mg it bd mh mi mj mk ml mm mn mo mp jz mq ka mr kc ms kd mt kf mu kg mv mw bi translated">2 伪造一些数据样本</h1><p id="2969" class="pw-post-body-paragraph ku kv it kw b kx mx ju kz la my jx lc ld mz lf lg lh na lj lk ll nb ln lo lp im bi translated">我们使用 beblow 多项式函数来伪造一些数据样本。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nh"><img src="../Images/1c0fe3289319ec139628815545b6bfa0.png" data-original-src="https://miro.medium.com/v2/resize:fit:660/format:webp/1*HDUqe32FCc2NJ4uSPax7RA.png"/></div></figure><p id="cef4" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">为了让数据更加真实，我们在其中加入了一些噪声。你可以在代码中看到。</p><pre class="kj kk kl km gt ni nj nk nl aw nm bi"><span id="e6dd" class="nn mg it nj b gy no np l nq nr">import numpy as np<br/>import matplotlib.pyplot as plt</span><span id="0649" class="nn mg it nj b gy ns np l nq nr"># random seed to make sure reimplement<br/>np.random.seed(0)</span><span id="1e28" class="nn mg it nj b gy ns np l nq nr"># the real model line<br/>def g(x):<br/>    return 0.1 * (x + x**2 + x**3)</span><span id="97e5" class="nn mg it nj b gy ns np l nq nr"># add noise to the model for faking data<br/>train_x = np.linspace(-2, 2, 8)<br/>train_y = g(train_x) + np.random.randn(len(train_x)) * 0.05</span><span id="b9a4" class="nn mg it nj b gy ns np l nq nr"># plot<br/>x = np.linspace(-2, 2, 100)<br/>plt.plot(train_x, train_y, 'o')<br/>plt.plot(x, g(x), linestyle='dashed')<br/>plt.ylim(-1, 2)<br/>plt.show()</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nt"><img src="../Images/515ead73a4a15abc0d8181fa17d00410.png" data-original-src="https://miro.medium.com/v2/resize:fit:1156/format:webp/1*QGD2x75_wT4i9vT-Vz8ndg.png"/></div></figure><p id="4424" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">虚线表示我们想要建模的真实线。</p><h1 id="77f1" class="mf mg it bd mh mi mj mk ml mm mn mo mp jz mq ka mr kc ms kd mt kf mu kg mv mw bi translated">3 预处理</h1><p id="8830" class="pw-post-body-paragraph ku kv it kw b kx mx ju kz la my jx lc ld mz lf lg lh na lj lk ll nb ln lo lp im bi translated">在第一步中，我们谈到了当模型过于复杂时，需要进行调整。例如，上面的实线是 3 次多项式函数。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nh"><img src="../Images/1c0fe3289319ec139628815545b6bfa0.png" data-original-src="https://miro.medium.com/v2/resize:fit:660/format:webp/1*HDUqe32FCc2NJ4uSPax7RA.png"/></div><figcaption class="nd ne gj gh gi nf ng bd b be z dk">a polynomial function of degree 3</figcaption></figure><p id="2333" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">但是如果我们选择一个 10 次多项式函数，这个模型可能会更复杂。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nu"><img src="../Images/98e31026e4e75caf930958f61085e344.png" data-original-src="https://miro.medium.com/v2/resize:fit:980/format:webp/1*vqlfGgQO0N5l2RNbFD29Ow.png"/></div><figcaption class="nd ne gj gh gi nf ng bd b be z dk">a polynomial function of degree 10</figcaption></figure><p id="7c00" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">因为我们有 10 度和一个偏项，所以我们也有 11 个参数。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nv"><img src="../Images/70a61c2b4071ded2ba4c5558fdbd6fef.png" data-original-src="https://miro.medium.com/v2/resize:fit:1204/format:webp/1*P31J3rxfN7LOepzIjrX5Gw.png"/></div></figure><p id="44ec" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">我们实现这个来模拟复杂的情况。</p><pre class="kj kk kl km gt ni nj nk nl aw nm bi"><span id="4aec" class="nn mg it nj b gy no np l nq nr">import numpy as np<br/>import matplotlib.pyplot as plt</span><span id="fc44" class="nn mg it nj b gy ns np l nq nr"># random seed to make sure reimplement<br/>np.random.seed(0)</span><span id="10dc" class="nn mg it nj b gy ns np l nq nr"># the real model line<br/>def g(x):<br/>    return 0.1 * (x + x**2 + x**3)</span><span id="38c8" class="nn mg it nj b gy ns np l nq nr"># add noise to the model for faking data<br/>train_x = np.linspace(-2, 2, 8)<br/>train_y = g(train_x) + np.random.randn(len(train_x)) * 0.05</span><span id="2614" class="nn mg it nj b gy ns np l nq nr"># standardization<br/>mu = train_x.mean()<br/>std = train_x.std()<br/>def standardizer(x):<br/>    return (x - mu) / std<br/><strong class="nj iu">std_x = standardizer(train_x)<br/></strong><br/># get matrix<br/>def to_matrix(x):<br/>    return np.vstack([<br/>        np.ones(x.size),<br/>        x,<br/>        x ** 2,<br/>        x ** 3,<br/>        x ** 4,<br/>        x ** 5,<br/>        x ** 6,<br/>        x ** 7,<br/>        x ** 8,<br/>        x ** 9,<br/>        x ** 10,<br/>    ]).T</span><span id="e18d" class="nn mg it nj b gy ns np l nq nr"><strong class="nj iu">mat_x = to_matrix(std_x)</strong></span><span id="e34c" class="nn mg it nj b gy ns np l nq nr"># initialize parameter<br/><strong class="nj iu">theta = np.random.randn(mat_x.shape[1])</strong></span><span id="d1e4" class="nn mg it nj b gy ns np l nq nr"># predict function<br/>def f(x):<br/><strong class="nj iu">    return np.dot(x, theta)</strong></span></pre><ul class=""><li id="8ed3" class="lr ls it kw b kx ky la lb ld lt lh lu ll lv lp nw lx ly lz bi translated">标准化:首先我们标准化我们的数据</li><li id="841b" class="lr ls it kw b kx ma la mb ld mc lh md ll me lp nw lx ly lz bi translated">获取矩阵:我们把数据做成矩阵形式进行矩阵运算，模拟 10 次多项式函数</li><li id="495b" class="lr ls it kw b kx ma la mb ld mc lh md ll me lp nw lx ly lz bi translated">初始化参数:根据输入数据的大小初始化参数</li><li id="ec4f" class="lr ls it kw b kx ma la mb ld mc lh md ll me lp nw lx ly lz bi translated">预测函数:这是我们的预测函数，就像上面的等式一样。</li></ul><h1 id="febb" class="mf mg it bd mh mi mj mk ml mm mn mo mp jz mq ka mr kc ms kd mt kf mu kg mv mw bi translated">4 未正规化的实施</h1><p id="c8ff" class="pw-post-body-paragraph ku kv it kw b kx mx ju kz la my jx lc ld mz lf lg lh na lj lk ll nb ln lo lp im bi translated">我们使用均方误差(MSE)作为代价函数。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nx"><img src="../Images/1a93c4f9252032d7127bd192b3cdea74.png" data-original-src="https://miro.medium.com/v2/resize:fit:916/format:webp/1*ZL5E_O1LMX4HIhbUqvxQTA.png"/></div></figure><pre class="kj kk kl km gt ni nj nk nl aw nm bi"><span id="b978" class="nn mg it nj b gy no np l nq nr"># cost function<br/>def E(x, y):<br/>    return 0.5 * np.sum((y - f(x))**2)</span><span id="c390" class="nn mg it nj b gy ns np l nq nr"># initialize error<br/>error = E(mat_x, train_y)</span></pre><p id="76e0" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">我们使用梯度下降来更新参数。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="ab gu cl ny"><img src="../Images/e0387d44ff2a1679389ae3d3faf960c9.png" data-original-src="https://miro.medium.com/v2/format:webp/1*4SKBVfcX3OQ2uLqgnTgzTw.png"/></div></figure><p id="2cd2" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">类似 Numpy 数组的版本可能容易理解。这里我只列出三个参数，只是为了看清楚这个方程。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="ab gu cl ny"><img src="../Images/d36db0c4155571da9286f6abe6235965.png" data-original-src="https://miro.medium.com/v2/format:webp/1*y5IKjksRDNbsgMu8s3PO6Q.png"/></div></figure><p id="cee6" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">代码</p><pre class="kj kk kl km gt ni nj nk nl aw nm bi"><span id="ddd7" class="nn mg it nj b gy no np l nq nr"># learning rate<br/>ETA = 1e-4</span><span id="894e" class="nn mg it nj b gy ns np l nq nr"># update parameter<br/>for _ in range(epoch):<br/>    theta = theta - ETA * np.dot(f(X) - train_y, mat_x)</span></pre><p id="19e5" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">我们将代码组合在一起</p><pre class="kj kk kl km gt ni nj nk nl aw nm bi"><span id="c741" class="nn mg it nj b gy no np l nq nr"># learning rate<br/>ETA = 1e-4</span><span id="cc7a" class="nn mg it nj b gy ns np l nq nr"># initialize difference between two epochs<br/>diff = 1</span><span id="79cb" class="nn mg it nj b gy ns np l nq nr">######## training without regularization ########<br/>while diff &gt; 1e-6:<br/>    # mat_x = (20, 4)<br/>    # f(x) - y = (20,)<br/><strong class="nj iu">    theta = theta - ETA * (np.dot(f(mat_x) - train_y, mat_x))<br/></strong>    current_error = E(mat_x, train_y)<br/>    diff = error - current_error <br/>    error = current_error</span><span id="c4b3" class="nn mg it nj b gy ns np l nq nr"># save parameters<br/>theta1 = theta</span><span id="e56d" class="nn mg it nj b gy ns np l nq nr">########## plot line ##########<br/>plt.ylim(-1, 2)<br/>plt.plot(std_x, train_y, 'o')<br/>z = standardizer(np.linspace(-2, 2, 100))</span><span id="54d4" class="nn mg it nj b gy ns np l nq nr"># plot the line without regularization<br/>theta = theta1<br/>plt.plot(z, f(to_matrix(z)), linestyle='dashed')<br/>plt.show()</span></pre><p id="4130" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">我们可以看到我们学到了什么。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nz"><img src="../Images/99a5513c919371c59720bd1da017fe78.png" data-original-src="https://miro.medium.com/v2/resize:fit:1154/format:webp/1*SNcZescZ4JhVvzAMkQw6Iw.png"/></div></figure><p id="c902" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">下面是完整的代码，<a class="ae lq" href="https://gist.github.com/BrambleXu/4bc854fdf2a45f9eb1fbbae3aad5b291" rel="noopener ugc nofollow" target="_blank">regression _ without _ regulation . py</a></p><h1 id="1ac7" class="mf mg it bd mh mi mj mk ml mm mn mo mp jz mq ka mr kc ms kd mt kf mu kg mv mw bi translated">5 正规化实施</h1><p id="2874" class="pw-post-body-paragraph ku kv it kw b kx mx ju kz la my jx lc ld mz lf lg lh na lj lk ll nb ln lo lp im bi translated">L2 监管术语看起来是这样的</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi oa"><img src="../Images/4d9cb90b478ca27a56718093d217bb35.png" data-original-src="https://miro.medium.com/v2/resize:fit:506/format:webp/1*DHIiMbslDPqXtaJ3xxtaUg.png"/></div></figure><p id="96dc" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">我们将代价函数和正则项结合在一起。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ob"><img src="../Images/e5ccf2080b04a78ffcc0c28b22cef4ea.png" data-original-src="https://miro.medium.com/v2/resize:fit:1228/format:webp/1*j-GjBWMngME7QiBO2on_4g.png"/></div></figure><p id="4d3f" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">因为我们增加了正则项，所以我们也需要相应地改变更新方程。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oc"><img src="../Images/91405ee6be047a3cef159fd4388a2d93.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Cco_KczR4Tqd-ob9VPCUqw.png"/></div></div></figure><p id="d924" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">注意，我们不使用 lambda 来更新偏差参数θ0。</p><p id="a459" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">代码</p><pre class="kj kk kl km gt ni nj nk nl aw nm bi"><span id="cfaa" class="nn mg it nj b gy no np l nq nr"># regularization parameter<br/>LAMBDA = 1</span><span id="0ca8" class="nn mg it nj b gy ns np l nq nr"># initialize difference between two epochs<br/>diff = 1</span><span id="3773" class="nn mg it nj b gy ns np l nq nr"># initialize error<br/>error = E(mat_x, train_y)</span><span id="306c" class="nn mg it nj b gy ns np l nq nr">######## training without regularization ########<br/>while diff &gt; 1e-6:<br/>    # notice we don't use regularization for theta 0<br/><strong class="nj iu">    reg_term = LAMBDA * np.hstack([0, theta[1:]])<br/></strong>    # update parameter<br/><strong class="nj iu">    theta = theta - ETA * (np.dot(mat_x.T, f(mat_x) - train_y) + reg_term)<br/></strong>    current_error = E(mat_x, train_y)<br/>    diff = error - current_error<br/>    error = current_error</span><span id="a895" class="nn mg it nj b gy ns np l nq nr"># save parameters<br/>theta2 = theta</span><span id="88f8" class="nn mg it nj b gy ns np l nq nr">########## plot the line with regularization ##########<br/>plt.ylim(-1, 2)<br/>plt.plot(std_x, train_y, 'o')<br/>z = standardizer(np.linspace(-2, 2, 100))</span><span id="ce86" class="nn mg it nj b gy ns np l nq nr">theta = theta2<br/>plt.plot(z, f(to_matrix(z)))<br/>plt.show()</span></pre><p id="a64d" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">模型看起来是这样的。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi od"><img src="../Images/6aea2dacac62296842935bef3dbb7baa.png" data-original-src="https://miro.medium.com/v2/resize:fit:1170/format:webp/1*hRucS17vwRT6o5XS-d3W6Q.png"/></div></figure><p id="02a7" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">我们可以看到，在添加正则化后，模型线变得更加平滑，更像原始的 3 次线。</p><p id="c4c3" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">下面是完整的代码，<a class="ae lq" href="https://gist.github.com/BrambleXu/1adbbceff0da62a6d5193e5aefb00952#file-regression_with_regularization-py" rel="noopener ugc nofollow" target="_blank">regression _ with _ regulation . py</a></p><h1 id="dfb6" class="mf mg it bd mh mi mj mk ml mm mn mo mp jz mq ka mr kc ms kd mt kf mu kg mv mw bi translated">6 摘要</h1><p id="8a28" class="pw-post-body-paragraph ku kv it kw b kx mx ju kz la my jx lc ld mz lf lg lh na lj lk ll nb ln lo lp im bi translated">这是“等式到代码”走查项目的最后一篇文章。希望对你有帮助。留下评论让我知道我的文章是否易懂。感谢阅读。</p><blockquote class="oe of og"><p id="5d91" class="ku kv oh kw b kx ky ju kz la lb jx lc oi le lf lg oj li lj lk ok lm ln lo lp im bi translated"><strong class="kw iu"> <em class="it">查看我的其他帖子</em> </strong> <a class="ae lq" href="https://medium.com/@bramblexu" rel="noopener"> <strong class="kw iu"> <em class="it">中等</em> </strong> </a> <strong class="kw iu"> <em class="it">同</em> </strong> <a class="ae lq" href="https://bramblexu.com/posts/eb7bd472/" rel="noopener ugc nofollow" target="_blank"> <strong class="kw iu"> <em class="it">一分类查看</em> </strong> </a> <strong class="kw iu"> <em class="it">！<br/>GitHub:</em></strong><a class="ae lq" href="https://github.com/BrambleXu" rel="noopener ugc nofollow" target="_blank"><strong class="kw iu"><em class="it">bramble Xu</em></strong></a><strong class="kw iu"><em class="it"><br/>LinkedIn:</em></strong><a class="ae lq" href="https://www.linkedin.com/in/xu-liang-99356891/" rel="noopener ugc nofollow" target="_blank"><strong class="kw iu"><em class="it">徐亮</em> </strong> </a> <strong class="kw iu"> <em class="it"> <br/>博客:</em></strong><a class="ae lq" href="https://bramblexu.com" rel="noopener ugc nofollow" target="_blank"><strong class="kw iu"><em class="it">bramble Xu</em></strong></a></p></blockquote></div></div>    
</body>
</html>