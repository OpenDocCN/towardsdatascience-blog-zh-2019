<html>
<head>
<title>AI For SEA Traffic Management: Window LSTM for Multi-Step Forecasting (Epilogue)</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">海上交通管理的人工智能:多步预报的窗口 LSTM(续)</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/ai-for-sea-traffic-management-window-lstm-for-multi-step-forecasting-epilogue-33551e1e07c9?source=collection_archive---------20-----------------------#2019-08-04">https://towardsdatascience.com/ai-for-sea-traffic-management-window-lstm-for-multi-step-forecasting-epilogue-33551e1e07c9?source=collection_archive---------20-----------------------#2019-08-04</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><figure class="ip iq gp gr ir is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi io"><img src="../Images/35ef9c0dfa418954acff2fef22bace0b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*fM09zCW21UnkFnPI"/></div></div><figcaption class="iz ja gj gh gi jb jc bd b be z dk">Angkor Wat, one of the wonders of South-East Asia</figcaption></figure><div class=""/><div class=""><h2 id="ec91" class="pw-subtitle-paragraph kc je jf bd b kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt dk translated">更新的 LSTM 架构，其中每个时间步长都在模型中预测</h2></div><p id="6b6d" class="pw-post-body-paragraph ku kv jf kw b kx ky kg kz la lb kj lc ld le lf lg lh li lj lk ll lm ln lo lp ij bi translated"><strong class="kw jg">也读作:</strong></p><p id="b213" class="pw-post-body-paragraph ku kv jf kw b kx ky kg kz la lb kj lc ld le lf lg lh li lj lk ll lm ln lo lp ij bi translated"><a class="ae lq" href="https://medium.com/@kiliantep/ai-for-sea-traffic-management-feature-engineering-part-1-2-e54f8d4eaa9e?postPublishedType=initial" rel="noopener">海上交通管理人工智能:特征工程(1/2) </a> <br/> <a class="ae lq" href="https://medium.com/@kiliantep/ai-for-sea-traffic-management-modeling-part-2-2-45cf301bd37" rel="noopener">海上交通管理人工智能:建模(2/2) </a></p><p id="d7c6" class="pw-post-body-paragraph ku kv jf kw b kx ky kg kz la lb kj lc ld le lf lg lh li lj lk ll lm ln lo lp ij bi translated"><em class="lr">在我之前的帖子中，我已经描述了我如何继续应对由 Grab 组织的</em> <a class="ae lq" href="https://www.aiforsea.com/traffic-management" rel="noopener ugc nofollow" target="_blank"> <em class="lr">人工智能海上交通管理挑战赛</em> </a> <em class="lr">。该任务包括预测 Grab 全天 15 分钟的预订需求。总之，参与者必须想出一种方法来预测时间 t 下 5 个时间步骤的需求。现在，紧迫的最后期限已经过去，我实际上有一些时间来反思和改进我以前的方法。此外，我没有使用黑客马拉松期间授予的 100 美元 AWS 积分，因为我是在 Google Colab 上训练我的第一个方法的。学分是一个尝试计算成本更高的方法的好机会。</em></p><p id="f299" class="pw-post-body-paragraph ku kv jf kw b kx ky kg kz la lb kj lc ld le lf lg lh li lj lk ll lm ln lo lp ij bi translated"><em class="lr">我所有的代码都可以在我的</em><a class="ae lq" href="https://github.com/KilianTep/traffic-management-aiforsea" rel="noopener ugc nofollow" target="_blank"><em class="lr">GitHub</em></a><em class="lr">上找到。原始数据集可以在</em>  <em class="lr">这里找到</em> <a class="ae lq" href="https://www.aiforsea.com/traffic-management" rel="noopener ugc nofollow" target="_blank"> <em class="lr">。</em></a></p><ol class=""><li id="e978" class="ls lt jf kw b kx ky la lb ld lu lh lv ll lw lp lx ly lz ma bi translated"><strong class="kw jg">以前方法的缺点</strong></li></ol><p id="5857" class="pw-post-body-paragraph ku kv jf kw b kx ky kg kz la lb kj lc ld le lf lg lh li lj lk ll lm ln lo lp ij bi translated"><a class="ae lq" href="https://medium.com/@kiliantep/ai-for-sea-traffic-management-modeling-part-2-2-45cf301bd37" rel="noopener">以前的方法</a>的主要缺点实质上源于这样一个事实，即它只专注于预测 T+1 时的<strong class="kw jg">需求。</strong></p><p id="fdb6" class="pw-post-body-paragraph ku kv jf kw b kx ky kg kz la lb kj lc ld le lf lg lh li lj lk ll lm ln lo lp ij bi translated">这种特性的第一个结果是，预测 T+1、T+2…直到 T+5 的<strong class="kw jg">需求将花费大量时间。</strong>我必须构建一个窗口函数，一次预测一个步骤。由于输入需求特征包括 T-5 时的<strong class="kw jg">需求，直到 T </strong>时的需求，我必须将预测附加到<em class="lr">需求输入向量</em>，并移除输入需求向量的最早需求。我还必须找到一种方法来移动我的<em class="lr">时间空间</em><em class="lr"/>输入向量的值，这并不容易:因为我对时间戳应用了最小-最大缩放，所以更新这个输入不像移动到下一个每小时季度那么容易。因此，在大型测试集上，生成 5 步预测的计算效率非常低。</p><p id="1247" class="pw-post-body-paragraph ku kv jf kw b kx ky kg kz la lb kj lc ld le lf lg lh li lj lk ll lm ln lo lp ij bi translated">第二，由于该模型仅设计用于预测一个步骤，因此每个预测的误差会传播到下一个步骤。换句话说，当预测接下来的 5 个时间步时，在<strong class="kw jg">需求 T+1 </strong>产生的误差将影响<strong class="kw jg">需求 T+2，</strong>将影响<strong class="kw jg">需求 T+3，以此类推。</strong></p><p id="826d" class="pw-post-body-paragraph ku kv jf kw b kx ky kg kz la lb kj lc ld le lf lg lh li lj lk ll lm ln lo lp ij bi translated">2.<strong class="kw jg">窗口 LSTM:一个通过设计集成多步预测的架构！</strong></p><p id="7bfa" class="pw-post-body-paragraph ku kv jf kw b kx ky kg kz la lb kj lc ld le lf lg lh li lj lk ll lm ln lo lp ij bi translated">总的想法是建立一个模型，使误差在更长时间内的传播最小化。该模型应该能够解释过去预测时间步长的误差，并且仍然能够相应地预测需求。</p><p id="60b6" class="pw-post-body-paragraph ku kv jf kw b kx ky kg kz la lb kj lc ld le lf lg lh li lj lk ll lm ln lo lp ij bi translated">在玩了一点 Keras 的功能后，我意识到连续预测<strong class="kw jg">几个输出</strong> <strong class="kw jg">实际上是可能的。</strong>下面的模式说明了新的方法:</p><figure class="mc md me mf gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi mb"><img src="../Images/b0ffa0ff3cacfd2725780a0c53b60f60.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*vRQhm-DPxXFmo8TW4U_cxg.png"/></div></div><figcaption class="iz ja gj gh gi jb jc bd b be z dk">Window LSTM architecture predicting each time step. The \d^{hat} correspond to the predicted demand values.</figcaption></figure><p id="4c19" class="pw-post-body-paragraph ku kv jf kw b kx ky kg kz la lb kj lc ld le lf lg lh li lj lk ll lm ln lo lp ij bi translated">一般方法如下:将需求输入向量传递到 LSTM 块，将 LSTM 块与时空输入组合，将其传递到密集块以生成下一个时间步长。然后，将预测需求附加到原始需求输入向量，并重复该过程。</p><p id="f616" class="pw-post-body-paragraph ku kv jf kw b kx ky kg kz la lb kj lc ld le lf lg lh li lj lk ll lm ln lo lp ij bi translated">现在，让我们逐一详细介绍该体系结构的每个构建块。</p><ul class=""><li id="455e" class="ls lt jf kw b kx ky la lb ld lu lh lv ll lw lp mg ly lz ma bi translated"><em class="lr">时间空间输入</em></li></ul><figure class="mc md me mf gt is gh gi paragraph-image"><div class="gh gi mh"><img src="../Images/945402e92e9ecce0ca7e2cb017e72b57.png" data-original-src="https://miro.medium.com/v2/resize:fit:1356/format:webp/1*2_r_nmuU5qo3Tng2qCZCpQ.png"/></div><figcaption class="iz ja gj gh gi jb jc bd b be z dk">Min-Max scaled lat, lon with timestamps to a 64-dimension densely connected layer</figcaption></figure><p id="46e1" class="pw-post-body-paragraph ku kv jf kw b kx ky kg kz la lb kj lc ld le lf lg lh li lj lk ll lm ln lo lp ij bi translated">为了对需求的时空依赖性进行建模，我简单地将一个带有时间戳的最小-最大缩放纬度、经度的向量传递给一个 64 维的密集连接层。然后我把这个图层和 LSTM 图层连接起来。值得一提的是，我<strong class="kw jg">没有</strong>更新时间戳，因为模型预测了后续时间步长的需求。由于时间空间输入向量是最小-最大比例的，因此相应地更新时间戳是相当棘手的。</p><ul class=""><li id="b793" class="ls lt jf kw b kx ky la lb ld lu lh lv ll lw lp mg ly lz ma bi translated"><em class="lr"> LSTM 街区</em></li></ul><p id="2c35" class="pw-post-body-paragraph ku kv jf kw b kx ky kg kz la lb kj lc ld le lf lg lh li lj lk ll lm ln lo lp ij bi translated">让我们用下面的 Keras 代码来说明 LSTM 块的架构:</p><figure class="mc md me mf gt is"><div class="bz fp l di"><div class="mi mj l"/></div></figure><p id="98fa" class="pw-post-body-paragraph ku kv jf kw b kx ky kg kz la lb kj lc ld le lf lg lh li lj lk ll lm ln lo lp ij bi translated">它将需求输入传递到几个 LSTM 层，随后是退出以减少过度拟合。经过几个 LSTM 图层后，输出被展平，以便将其与前面提到的时空输入连接起来。</p><ul class=""><li id="ea09" class="ls lt jf kw b kx ky la lb ld lu lh lv ll lw lp mg ly lz ma bi translated"><em class="lr">密集块</em></li></ul><p id="1cb2" class="pw-post-body-paragraph ku kv jf kw b kx ky kg kz la lb kj lc ld le lf lg lh li lj lk ll lm ln lo lp ij bi translated">一旦看到代码，这个密集的代码块就不言自明了:</p><figure class="mc md me mf gt is"><div class="bz fp l di"><div class="mi mj l"/></div></figure><p id="893d" class="pw-post-body-paragraph ku kv jf kw b kx ky kg kz la lb kj lc ld le lf lg lh li lj lk ll lm ln lo lp ij bi translated">然后，预测需求跟在需求块后面。</p><ul class=""><li id="2dc1" class="ls lt jf kw b kx ky la lb ld lu lh lv ll lw lp mg ly lz ma bi translated"><em class="lr">整体窗口 LSTM 建筑</em></li></ul><figure class="mc md me mf gt is"><div class="bz fp l di"><div class="mi mj l"/></div></figure><p id="657a" class="pw-post-body-paragraph ku kv jf kw b kx ky kg kz la lb kj lc ld le lf lg lh li lj lk ll lm ln lo lp ij bi translated">3.<strong class="kw jg">模特培训</strong></p><p id="6a7e" class="pw-post-body-paragraph ku kv jf kw b kx ky kg kz la lb kj lc ld le lf lg lh li lj lk ll lm ln lo lp ij bi translated">与前面的方法类似，我在前 47 天训练模型，在剩下的 14 天评估它的性能。粗略估计，训练集约有 320 万个样本，测试集有近 100 万个样本。</p><p id="5fac" class="pw-post-body-paragraph ku kv jf kw b kx ky kg kz la lb kj lc ld le lf lg lh li lj lk ll lm ln lo lp ij bi translated">这种新架构的计算成本显然要高得多。该模型在具有 36gb RAM 的 AWS EC2 GPU 上进行训练。</p><p id="5a3f" class="pw-post-body-paragraph ku kv jf kw b kx ky kg kz la lb kj lc ld le lf lg lh li lj lk ll lm ln lo lp ij bi translated">我训练了 30 个纪元的模型。我用了一个<strong class="kw jg">批量</strong> <strong class="kw jg">的 200 个训练例子。</strong>使用的优化器是<strong class="kw jg"> Adam </strong>，初始学习率<strong class="kw jg"> 0.001。</strong>我还添加了一个 Keras 回调函数，用于在训练损失达到稳定水平时调整学习率——它基本上将学习率乘以 0.2。</p><p id="4b6d" class="pw-post-body-paragraph ku kv jf kw b kx ky kg kz la lb kj lc ld le lf lg lh li lj lk ll lm ln lo lp ij bi translated">这种新架构的优势在于，Keras 使您能够在训练期间监控每个预测的损失:</p><figure class="mc md me mf gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi mk"><img src="../Images/29a0ec4001484bf2421d95bb41d1ab65.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*FCX0MU0-POfxfnLVjwSRXg.png"/></div></div><figcaption class="iz ja gj gh gi jb jc bd b be z dk">Multi-Output loss monitoring during Keras training</figcaption></figure><p id="f0da" class="pw-post-body-paragraph ku kv jf kw b kx ky kg kz la lb kj lc ld le lf lg lh li lj lk ll lm ln lo lp ij bi translated">此功能对于查看模型是否难以学习某些特定输出非常有用。</p><p id="fb4d" class="pw-post-body-paragraph ku kv jf kw b kx ky kg kz la lb kj lc ld le lf lg lh li lj lk ll lm ln lo lp ij bi translated">4.<strong class="kw jg">结果</strong></p><p id="2871" class="pw-post-body-paragraph ku kv jf kw b kx ky kg kz la lb kj lc ld le lf lg lh li lj lk ll lm ln lo lp ij bi translated">虽然训练需要更长的时间，但新架构现在为每个时间步生成结果的速度比以前的方法快得多。</p><p id="39c2" class="pw-post-body-paragraph ku kv jf kw b kx ky kg kz la lb kj lc ld le lf lg lh li lj lk ll lm ln lo lp ij bi translated">就性能而言，它比之前的方法(整体 RMSE 为 0.07)略好。对于过去 14 天的数据，每个时间步长的 RMSEs(均方根误差)如下:</p><ul class=""><li id="50af" class="ls lt jf kw b kx ky la lb ld lu lh lv ll lw lp mg ly lz ma bi translated"><strong class="kw jg">需求 T+1 </strong> : 0.04</li><li id="d887" class="ls lt jf kw b kx ml la mm ld mn lh mo ll mp lp mg ly lz ma bi translated"><strong class="kw jg">需求 T+2 </strong> : 0.05</li><li id="a6e1" class="ls lt jf kw b kx ml la mm ld mn lh mo ll mp lp mg ly lz ma bi translated"><strong class="kw jg">需求 T+3 </strong> : 0.04</li><li id="8d33" class="ls lt jf kw b kx ml la mm ld mn lh mo ll mp lp mg ly lz ma bi translated"><strong class="kw jg">需求 T+4 </strong> : 0.05</li><li id="02da" class="ls lt jf kw b kx ml la mm ld mn lh mo ll mp lp mg ly lz ma bi translated"><strong class="kw jg">需求 T+5 </strong> : 0.05</li><li id="35d0" class="ls lt jf kw b kx ml la mm ld mn lh mo ll mp lp mg ly lz ma bi translated"><strong class="kw jg">总体 RMSE </strong> : 0.05</li></ul><p id="b2f2" class="pw-post-body-paragraph ku kv jf kw b kx ky kg kz la lb kj lc ld le lf lg lh li lj lk ll lm ln lo lp ij bi translated"><strong class="kw jg">结论</strong></p><p id="6c2d" class="pw-post-body-paragraph ku kv jf kw b kx ky kg kz la lb kj lc ld le lf lg lh li lj lk ll lm ln lo lp ij bi translated">这种新方法的主要优势在于，它通过设计预测接下来的 5 个时间步长<strong class="kw jg">。</strong>在真实的生产环境中，拥有一个能够快速预测下一步时间的模型是非常重要的。</p><p id="be27" class="pw-post-body-paragraph ku kv jf kw b kx ky kg kz la lb kj lc ld le lf lg lh li lj lk ll lm ln lo lp ij bi translated">此外，Keras 能够在训练期间的不同时间步骤监控每个预测的性能。此功能对于查看特定时间步长的性能是否不是最佳非常有用。</p><p id="1da9" class="pw-post-body-paragraph ku kv jf kw b kx ky kg kz la lb kj lc ld le lf lg lh li lj lk ll lm ln lo lp ij bi translated">最后，随着时间远离时间 t，main 方法能够限制误差的传播，如结果所示，误差在所有时间步长内保持非常小。</p><p id="5f08" class="pw-post-body-paragraph ku kv jf kw b kx ky kg kz la lb kj lc ld le lf lg lh li lj lk ll lm ln lo lp ij bi translated">希望你喜欢！</p><p id="174c" class="pw-post-body-paragraph ku kv jf kw b kx ky kg kz la lb kj lc ld le lf lg lh li lj lk ll lm ln lo lp ij bi translated">基利安</p></div></div>    
</body>
</html>