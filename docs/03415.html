<html>
<head>
<title>Why you should Double-DIP for Natural Image Decomposition</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">为什么你应该双浸自然图像分解</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/why-you-should-double-dip-for-natural-image-decomposition-ee65b1c1c9bc?source=collection_archive---------20-----------------------#2019-05-31">https://towardsdatascience.com/why-you-should-double-dip-for-natural-image-decomposition-ee65b1c1c9bc?source=collection_archive---------20-----------------------#2019-05-31</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="715e" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">基于耦合深度图像先验的无监督图像分解</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/238de615b2cb37b1236e530328f8b051.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*bpNAQtbw7zYE-On5UdIvow.jpeg"/></div></div></figure><p id="ba58" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">许多计算机视觉任务都希望将图像分解成单独的部分。在图像分割中，图像被分解成有意义的子区域，例如前景和背景。在透明分离中，图像被分离成其叠加的反射和透射。另一个例子是图像去雾的任务，其目标是将有雾的图像分成其基本的无雾图像和模糊的雾层。</p><p id="a24e" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">虽然起初看起来不相关，但是这些任务可以被视为将图像分解成单独层的特殊情况。例如，如图 1 所示；图像分割(分离成前景和背景层)；透明层分离(分成反射层和透射层)；图像去雾(分离成清晰图像和模糊贴图)，等等。</p><p id="1cdf" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">在这篇文章中，我们将重点关注“双 DIP”，这是一个基于几个<a class="ae lq" rel="noopener" target="_blank" href="/how-to-perform-image-restoration-absolutely-dataset-free-d08da1a1e96d">“深度图像优先”(DIP) </a>网络的单一图像无监督层分解的统一框架。</p><blockquote class="lr ls lt"><p id="6712" class="ku kv lu kw b kx ky ju kz la lb jx lc lv le lf lg lw li lj lk lx lm ln lo lp im bi translated"><strong class="kw iu">对于热心读者:<br/> </strong>关于<a class="ae lq" rel="noopener" target="_blank" href="/how-to-perform-image-restoration-absolutely-dataset-free-d08da1a1e96d">“深度图像优先”(DIP) </a>的更多细节，查看我以前的帖子。</p></blockquote><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ly"><img src="../Images/73dbaa1b1d0ad03d401c9a7a263b0862.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*gPz6bL7yZmW6xuA1rCHHmA.png"/></div></div><figcaption class="lz ma gj gh gi mb mc bd b be z dk">Figure 1: A unified framework for image decomposition.</figcaption></figure></div><div class="ab cl md me hx mf" role="separator"><span class="mg bw bk mh mi mj"/><span class="mg bw bk mh mi mj"/><span class="mg bw bk mh mi"/></div><div class="im in io ip iq"><h1 id="6c8f" class="mk ml it bd mm mn mo mp mq mr ms mt mu jz mv ka mw kc mx kd my kf mz kg na nb bi translated">一些直觉</h1><p id="e5e1" class="pw-post-body-paragraph ku kv it kw b kx nc ju kz la nd jx lc ld ne lf lg lh nf lj lk ll ng ln lo lp im bi translated">“双倾角”主要建立在“深度图像先验”(倾角)之上；Ulyanov 等人在 DIP 中的工作表明，DIP 网络的结构足以捕获单个自然图像的低级统计。</p><p id="469c" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">DIP 网络的输入是随机噪声，它训练以重建单个图像(作为其唯一的输出训练示例)。这种网络被证明是非常强大的解决图像恢复任务，如去噪，超分辨率和修复，在一个无监督的方式。下面是一个图像去噪的例子，摘自我在<a class="ae lq" rel="noopener" target="_blank" href="/how-to-perform-image-restoration-absolutely-dataset-free-d08da1a1e96d">之前发表的关于深度图像的文章</a>:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nh"><img src="../Images/c5b268fea57415163a63365f9317e6a0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/1*LmHR7HcEpwhIQedzzWy6_g.gif"/></div></div><figcaption class="lz ma gj gh gi mb mc bd b be z dk">Figure 2: (Left) — Clean image <em class="ni">x* </em>restoration result using Deep Image Prior starting from random initialization up to convergence , (Right) — The Noisy image x^</figcaption></figure><p id="cd49" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">“双倾角”的作者观察到，通过使用多个倾角的组合来重建图像，这些倾角往往会“分裂”图像，就像人类自然分裂图像一样。此外，他们展示了如何将这种方法用于额外的计算机视觉任务，包括图像去雾、图像和视频的 Fg/Bg 分割、水印去除以及图像和视频中的透明分离。</p></div><div class="ab cl md me hx mf" role="separator"><span class="mg bw bk mh mi mj"/><span class="mg bw bk mh mi mj"/><span class="mg bw bk mh mi"/></div><div class="im in io ip iq"><h1 id="7742" class="mk ml it bd mm mn mo mp mq mr ms mt mu jz mv ka mw kc mx kd my kf mz kg na nb bi translated">“双下降”:通过耦合深度图像先验的无监督图像分解</h1><p id="4793" class="pw-post-body-paragraph ku kv it kw b kx nc ju kz la nd jx lc ld ne lf lg lh nf lj lk ll ng ln lo lp im bi translated">双下降的关键方面是固有的，即每个分解层内小块的<em class="lu">分布比原始混合图像中的<strong class="kw iu">【更简单】</strong>(更均匀)。我们用一个例子来简化一下；</em></p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nj"><img src="../Images/96dd5ee412cb38a1192cfce03839b8cb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*rwjOFO9W-yqyd5v73Y12mA.png"/></div></div><figcaption class="lz ma gj gh gi mb mc bd b be z dk">Figure 3: The complexity of mixtures of layers vs. the simplicity of the individual components</figcaption></figure><p id="1fe8" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">让我们观察图 3a 中的示例。两种不同的纹理，<em class="lu"> X </em>和<em class="lu"> Y </em>，混合起来形成一个更复杂的图像<em class="lu"> Z </em>，呈现出图层透明。每个纯纹理(<em class="lu"> X </em>和<em class="lu"> Y </em>)内部的小块和颜色的<em class="lu">分布比组合图像(<em class="lu"> Z </em>)中的块和颜色的分布更简单<strong class="kw iu">。此外，跨两种纹理的补片的相似性非常弱。</strong></em></p><p id="66c9" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">声称一幅图像可以用一种自然而简单的方式分离成它的子成分是从<a class="ae lq" href="http://staff.ustc.edu.cn/~cgong821/Wiley.Interscience.Elements.of.Information.Theory.Jul.2006.eBook-DDU.pdf" rel="noopener ugc nofollow" target="_blank"> <em class="lu">信息论</em> </a> <em class="lu">中推导出来的。</em>这里证明了对于两个<em class="lu">独立的</em>随机变量<em class="lu"> X </em>和<em class="lu"> Y </em>，它们的和<em class="lu"> Z = X+Y </em>的联合熵大于它们各自的熵。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nk"><img src="../Images/9cd61e4fa7daa0b96a0f8a6338cca485.png" data-original-src="https://miro.medium.com/v2/resize:fit:1058/format:webp/1*dwNltAHzGyRXsqwU25HN4g.png"/></div></figure><h2 id="5b66" class="nl ml it bd mm nm nn dn mq no np dp mu ld nq nr mw lh ns nt my ll nu nv na nw bi translated">单倾角与耦合倾角</h2><p id="0c34" class="pw-post-body-paragraph ku kv it kw b kx nc ju kz la nd jx lc ld ne lf lg lh nf lj lk ll ng ln lo lp im bi translated">单一 DIP 网络用于学习 pusre 图像与混合图像之间的差异可以在下面的图 4 中示出。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nx"><img src="../Images/efad0dc9078c18d1d014e3bce63c9946.png" data-original-src="https://miro.medium.com/v2/resize:fit:1216/format:webp/1*wCXv2yvM9bICqXtNi8umrQ.png"/></div><figcaption class="lz ma gj gh gi mb mc bd b be z dk">Figure 4. MSE Reconstruction Loss of a single DIP network, as a function of time</figcaption></figure><p id="34e0" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">在图 4 中，对于图 3a 中的 3 个图像中的每一个，示出了单个倾角网络的 MSE 重建损失，作为时间的函数(训练迭代)。</p><ul class=""><li id="cd29" class="ny nz it kw b kx ky la lb ld oa lh ob ll oc lp od oe of og bi translated">橙色橙色图是为重建纹理图像<em class="lu"> X </em>而训练的下降的损失</li><li id="bfa8" class="ny nz it kw b kx oh la oi ld oj lh ok ll ol lp od oe of og bi translated">蓝色图——经过训练以重建纹理的倾斜<em class="lu"> Y </em></li><li id="6524" class="ny nz it kw b kx oh la oi ld oj lh ok ll ol lp od oe of og bi translated">绿色图-经过训练以重建其叠加混合物(图像透明度)的倾斜。</li></ul><p id="6185" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">请注意，与单个分量的损失相比，混合图像的损失更大，收敛时间更长。这意味着混合图像的损失大于两个单独损失的总和。这可能与混合图像中的小块分布更加复杂和多样(更大的熵；更小的内部自相似性)。</p><p id="37df" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">最后，应用多个 DIP 显示它们倾向于在它们之间“分裂”图像碎片。也就是说，图像内类似的小块往往都是由单个 DIP 网络生成的。换句话说，每个倾角捕获图像内部统计数据的不同组成部分。</p><h2 id="c3d9" class="nl ml it bd mm nm nn dn mq no np dp mu ld nq nr mw lh ns nt my ll nu nv na nw bi translated">“双底”框架</h2><p id="a45a" class="pw-post-body-paragraph ku kv it kw b kx nc ju kz la nd jx lc ld ne lf lg lh nf lj lk ll ng ln lo lp im bi translated">图 5。演示了双 DIP 框架:两次 DIP 将输入图像<em class="lu"> I </em>分解为层(y1 和 y2)，然后根据学习到的遮罩 m 对这些层进行重组，从而重建 I 的近似图像。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi om"><img src="../Images/8929c4517ad49afbaf84b0d64f5b8db9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*TKbh-2tEQsOUMPKa5Vu7TA.png"/></div></div><figcaption class="lz ma gj gh gi mb mc bd b be z dk">Figure 5. Double-DIP Framework</figcaption></figure><h2 id="c730" class="nl ml it bd mm nm nn dn mq no np dp mu ld nq nr mw lh ns nt my ll nu nv na nw bi translated">什么是好的图像分解？</h2><p id="6137" class="pw-post-body-paragraph ku kv it kw b kx nc ju kz la nd jx lc ld ne lf lg lh nf lj lk ll ng ln lo lp im bi translated">一幅图像有无限多种可能的分层方式。作者提出以下特征来定义有意义的分解:</p><ul class=""><li id="f7a9" class="ny nz it kw b kx ky la lb ld oa lh ob ll oc lp od oe of og bi translated">当重新组合时，恢复的层重建输入图像</li><li id="1804" class="ny nz it kw b kx oh la oi ld oj lh ok ll ol lp od oe of og bi translated">每一层都应该尽可能“简单”</li><li id="9fe1" class="ny nz it kw b kx oh la oi ld oj lh ok ll ol lp od oe of og bi translated">恢复的层之间不应该有依赖性或相关性</li></ul><p id="11c5" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">这些建议转化为用于训练网络的损耗。第一个标准是通过“重建损失”来实施的，该“重建损失”测量所构建的图像和输入图像之间的误差。第二个标准是通过采用多次倾斜(每层一次)获得的。第三个标准是通过不同骤降的输出之间的“排除损失”来实施的(最小化它们的相关性)。</p><p id="fa86" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">每个 DIP 网络重建输入图像的不同层 y _ I<em class="lu">I。</em>每个 DIP 的输入是随机采样的均匀噪声 z_i</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi on"><img src="../Images/13310e7ba13118074a1d008106b00549.png" data-original-src="https://miro.medium.com/v2/resize:fit:1276/format:webp/1*jTl-xq3chM2cntPM0_Wa3A.png"/></div></div></figure><p id="dcbb" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">，其应尽可能接近输入图像<em class="lu"> I. </em>因此，优化损失为</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi om"><img src="../Images/fe5c17e34ef526f43b2564136a60330e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*bdMiLZL6CzPeBdZLDvp9ag.png"/></div></div></figure><p id="7dac" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">其中，损失第一元素，即重建损失定义为</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi oo"><img src="../Images/73e6367252ea52d0c92b9cdba91a7cc0.png" data-original-src="https://miro.medium.com/v2/resize:fit:692/format:webp/1*TYdx1XFStQ0DZDRSETCX6A.png"/></div></figure><p id="a135" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">第二个要素是排除损失，它使 y1 和 y2 的梯度之间的相关性最小化。最后，正则化掩模项将掩模<em class="lu"> m </em>拉至尽可能接近二进制图像。</p></div><div class="ab cl md me hx mf" role="separator"><span class="mg bw bk mh mi mj"/><span class="mg bw bk mh mi mj"/><span class="mg bw bk mh mi"/></div><div class="im in io ip iq"><h1 id="9898" class="mk ml it bd mm mn mo mp mq mr ms mt mu jz mv ka mw kc mx kd my kf mz kg na nb bi translated">结果</h1><p id="661a" class="pw-post-body-paragraph ku kv it kw b kx nc ju kz la nd jx lc ld ne lf lg lh nf lj lk ll ng ln lo lp im bi translated">如上所述，这种方法适用于许多计算机视觉任务，如图像分割、透明层分离、图像去雾等。</p><h2 id="90ed" class="nl ml it bd mm nm nn dn mq no np dp mu ld nq nr mw lh ns nt my ll nu nv na nw bi translated">分割</h2><p id="2d1f" class="pw-post-body-paragraph ku kv it kw b kx nc ju kz la nd jx lc ld ne lf lg lh nf lj lk ll ng ln lo lp im bi translated">将图像分割成前景和背景可以表示为将图像分解成标记为 y_1 的前景层和标记为 y_2 的背景层。这两层与二进制掩模结合将产生分解的图像，并且可以用公式 1 表示:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi op"><img src="../Images/65e2bbe957d9426216d0421ed4766762.png" data-original-src="https://miro.medium.com/v2/resize:fit:1054/format:webp/1*8G-VG7CEWUuRnD_8ySB-6g.png"/></div><figcaption class="lz ma gj gh gi mb mc bd b be z dk">Equation 1</figcaption></figure><p id="041c" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">这个公式自然地适合双倾角框架，服从符合自然图像先验的 y_1 和 y_2，并且每一个都比<em class="lu"> I. </em>更“简单”地生成</p><p id="4efd" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">正则化项在这里被定义为鼓励分割掩模被二进制化和定义</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi oq"><img src="../Images/9734130bb70890ca1aff48fbd1d66732.png" data-original-src="https://miro.medium.com/v2/resize:fit:1032/format:webp/1*GUF2hhecX9D1EZVOz0efHA.png"/></div></figure><p id="8fe6" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">下面的结果显示了双 DIP 的优点，实现了仅基于层分解的高质量分割，而无需任何额外的训练数据。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi or"><img src="../Images/b3eabc8301e43741fa0d9f90c8079a52.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ZvNriawFkdi6wzDubZMTaw.png"/></div></div><figcaption class="lz ma gj gh gi mb mc bd b be z dk">Figure 6. Foreground/Background separation results</figcaption></figure><h2 id="6709" class="nl ml it bd mm nm nn dn mq no np dp mu ld nq nr mw lh ns nt my ll nu nv na nw bi translated">水印去除</h2><p id="9ec0" class="pw-post-body-paragraph ku kv it kw b kx nc ju kz la nd jx lc ld ne lf lg lh nf lj lk ll ng ln lo lp im bi translated">水印广泛用于照片和视频的版权保护。双浸通过将水印视为图像反射的特殊情况来消除水印，其中 y1 是清除的图像，y2 是水印。</p><p id="6728" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">这里，与图像语义相反，掩模不是常数<em class="lu">m。</em>固有的透明层模糊通过两种实际方法之一解决:(I)当只有一个水印图像可用时，用户提供围绕水印位置的粗略提示(边界框);(ii)给定几个共享相同水印的图像(通常 2-3 个就足够了)，模糊性自行解决。</p><p id="9b81" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">图 7。下图显示了双浸法去除水印的显著效果。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi os"><img src="../Images/585c0c8bbe5456830d704ae73c82d4ba.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*tCgiOQzRm6G-GPaC1Uevwg.png"/></div></div><figcaption class="lz ma gj gh gi mb mc bd b be z dk">Figure 7. Watermark removal from a single image</figcaption></figure><h2 id="e415" class="nl ml it bd mm nm nn dn mq no np dp mu ld nq nr mw lh ns nt my ll nu nv na nw bi translated">透明层分离</h2><p id="6d55" class="pw-post-body-paragraph ku kv it kw b kx nc ju kz la nd jx lc ld ne lf lg lh nf lj lk ll ng ln lo lp im bi translated">在图像反射的情况下，图像<em class="lu"> I(x) </em>中的每个像素值是来自透射层<em class="lu"> y_1(x) </em>的像素和反射层<em class="lu"> y_2(x)中的对应像素的组合。</em>这也可以用等式 1 来表示。其中<em class="lu"> m(x) </em>是反射掩模。</p><p id="f359" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">下面的动画展示了真实透明图像的成功分离。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ot"><img src="../Images/a5014a7d0e3ca2ba4a3be835cee5600f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1244/1*B3_4YtM_9PRdrDT7cEmXAQ.gif"/></div></figure><h1 id="5b5b" class="mk ml it bd mm mn ou mp mq mr ov mt mu jz ow ka mw kc ox kd my kf oy kg na nb bi translated">结论</h1><p id="d50d" class="pw-post-body-paragraph ku kv it kw b kx nc ju kz la nd jx lc ld ne lf lg lh nf lj lk ll ng ln lo lp im bi translated">双 DIP 为单个图像的无监督层分解提供了一个统一的框架，并且需要额外的数据集。这个框架适用于各种各样的计算机视觉任务。</p><p id="6722" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">如果你对源代码感兴趣，可以在我的<a class="ae lq" href="https://github.com/erezposner/DoubleDIP" rel="noopener ugc nofollow" target="_blank"> Double-DIP — GitHub 库</a>中找到。</p><p id="bad9" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">一如既往，如果您有任何问题或意见，请随时在下面留下您的反馈，或者您可以随时通过<a class="ae lq" href="http://www.linkedin.com/in/erezposner" rel="noopener ugc nofollow" target="_blank"> LinkedIn </a>联系我。</p><p id="530c" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">在那之前，下一篇文章再见！😄</p></div></div>    
</body>
</html>