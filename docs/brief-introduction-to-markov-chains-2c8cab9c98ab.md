# 马尔可夫链简介

> 原文：<https://towardsdatascience.com/brief-introduction-to-markov-chains-2c8cab9c98ab?source=collection_archive---------2----------------------->

## 定义、属性和 PageRank 示例。

![](img/527e2200f6fc8f3b8b2d0bb2efef5733.png)

Credit: [Free-Photos](https://pixabay.com/fr/users/free-photos-242387/) on [Pixabay](https://pixabay.com/)

*本帖与* [*巴蒂斯特·罗卡*](https://medium.com/u/20ad1309823a?source=post_page-----2c8cab9c98ab--------------------------------) *共同撰写。*

# 介绍

1998 年，劳伦斯·佩奇(Lawrence Page)、谢尔盖·布林(Sergey Brin)、拉吉夫·莫特瓦尼(Rajeev Motwani)和特里·维诺格拉德(Terry Winograd)发表了《PageRank 引文排名:给网络带来秩序》(The PageRank Citation Ranking:bring Order to The Web)，他们在文章中介绍了谷歌起源时现在著名的 Page rank 算法。二十多年后，谷歌已经成为一个巨人，即使算法已经发展了很多，PageRank 仍然是谷歌排名算法的一个“符号”(即使很少有人能真正说出它在算法中仍然占据的权重)。

从理论的角度来看，有趣的是注意到对 PageRank 算法的一种常见解释依赖于简单但基本的马尔可夫链数学概念。我们将在本文中看到，马尔可夫链是随机建模的强大工具，对任何数据科学家都有用。更特别的是，我们将回答一些基本问题，如:什么是马尔可夫链，它们有什么好的性质，可以用它们做什么？

## 概述

在第一部分，我们将给出理解什么是马尔可夫链所需的基本定义。在第二节中，我们将讨论有限状态空间马氏链的特殊情况。然后，在第三节我们将讨论马氏链的一些基本性质，并用许多小例子来说明这些性质。最后，在第四节中，我们将链接 PageRank 算法，并通过一个玩具示例来了解如何使用马尔可夫链对图中的节点进行排序。

> **注。这个职位需要概率和线性代数的基础知识。具体来说，将使用以下概念:[条件概率](https://en.wikipedia.org/wiki/Conditional_probability)、[特征向量](https://en.wikipedia.org/wiki/Eigenvalues_and_eigenvectors)和[全概率定律](https://en.wikipedia.org/wiki/Law_of_total_probability)。**

# 什么是马尔可夫链？

## 随机变量和随机过程

在介绍马尔可夫链之前，让我们先快速回顾一下概率论中一些基本但重要的概念。

首先，在非数学术语中，**随机变量** X 是一个变量，其值被定义为随机现象的结果。这个结果可以是一个数(或“类数”，包括向量)，也可以不是。例如，我们可以将随机变量定义为掷骰子的结果(数字)以及掷硬币的结果(不是数字，除非你指定 0 为正面，1 为反面)。还要注意，随机变量的可能结果空间可以是离散的，也可以是连续的:例如，正态随机变量是连续的，而泊松随机变量是离散的。

然后，我们可以将**随机过程**(也称为随机过程)定义为由集合 T 索引的随机变量的集合，这些随机变量通常代表不同的时刻(我们将在下文中假设)。最常见的两种情况是:要么 T 是自然数的集合(离散时间随机过程)，要么 T 是实数的集合(连续时间随机过程)。例如，每天抛硬币定义了一个离散时间随机过程，而股票市场期权的价格连续变化定义了一个连续时间随机过程。不同时刻的随机变量可以彼此独立(抛硬币的例子)或以某种方式相关(股票价格的例子)，并且它们可以具有连续或离散的状态空间(每个时刻的可能结果的空间)。

![](img/ed139c2e63898d2e68b4d693316267db.png)

Different kind of random processes (discrete/continuous in space/time).

## 马尔可夫性质和马尔可夫链

存在一些众所周知的随机过程族:高斯过程、泊松过程、自回归模型、移动平均模型、马尔可夫链等。这些特殊的案例，每一个都有特定的属性，让我们可以更好地研究和理解它们。

使随机过程的研究容易得多的一个性质是“马尔可夫性质”。马尔可夫性质以一种非常非正式的方式表示，对于随机过程，如果我们知道该过程在给定时间的值，我们将不会通过收集关于过去的更多知识来获得关于该过程未来行为的任何附加信息。用稍微更数学的术语来说，对于任何给定的时间，给定当前和过去状态的过程的未来状态的条件分布仅取决于当前状态，而完全不取决于过去状态(**无记忆特性**)。具有马尔可夫性质的随机过程称为**马尔可夫过程**。

![](img/eb56c87c56ccf104aef0db9bae594cfd.png)

The Markov property expresses the fact that at a given time step and knowing the current state, we won’t get any additional information about the future by gathering information about the past.

基于前面的定义，我们现在可以定义“齐次离散时间马尔可夫链”(为了简单起见，在下文中称为“马尔可夫链”)。一个**马尔可夫链**是一个具有离散时间和离散状态空间的马尔可夫过程。因此，马尔可夫链是一个离散的状态序列，每个状态都来自一个离散的状态空间(有限的或非有限的)，并且遵循马尔可夫性质。

在数学上，我们可以用以下方式表示马尔可夫链

![](img/153c43757e87528a36504365535891ea.png)

其中在每个时刻，该过程在离散集合 E 中取其值，使得

![](img/b8e2d10a428342e992c09e7a6f810622.png)

那么，马尔可夫性质意味着我们有

![](img/0c37fbd5db0c959a9b56ab1fd4204dd3.png)

请再次注意，最后一个公式表达了这样一个事实，即对于给定的历史(我现在所在的位置和我之前所在的位置)，下一个状态(我接下来要去的位置)的概率分布只取决于当前状态，而不取决于过去的状态。

> **注。在这篇介绍性的文章中，我们决定只描述基本的齐次离散时间马尔可夫链。然而，也存在非齐次的(时间相关的)和/或时间连续的马尔可夫链。我们不会在下面讨论这些模型的变体。还要注意，上面给出的马尔可夫性质的定义是极其简化的:真正的数学定义包括过滤的概念，这远远超出了这个适度介绍的范围。**

## 表征马尔可夫链的随机动态

在前一小节中，我们已经介绍了与任何马尔可夫链相匹配的一般框架。现在让我们来看看我们需要什么来定义这样一个随机过程的一个特定“实例”。

首先注意，不验证马尔可夫性质的离散时间随机过程的完整特征可能是痛苦的:给定时间的概率分布可能取决于过去和/或未来的一个或多个时刻。所有这些可能的时间相关性使得对该过程的任何适当描述都可能是困难的。

然而，由于马尔可夫性质，马尔可夫链的动态很容易定义。事实上，我们只需要指定两件事:一个**初始概率分布**(即时刻 n=0 的概率分布)表示为

![](img/b2b6f5ec8d62ae6f5fe3cfe76b7442a9.png)

以及一个**转移概率核**(它给出了对于任何一对状态，一个状态在时间 n+1 继承到另一个状态的概率)

![](img/f2f40f8608b2e98203ff2dcfb1841d3c.png)

已知前两个对象，过程的完全(概率)动态被很好地定义。事实上，这一过程实现的概率可以用递归的方法计算出来。

例如，假设我们想知道流程前 3 个状态的概率是(s0，s1，s2)。所以，我们想计算概率

![](img/7773579bb17ff80369dd1c7d65b9c739.png)

这里，我们使用全概率定律，即拥有(s0，s1，s2)的概率等于拥有第一个 s0 的概率，乘以拥有 s1 的概率(假设我们之前拥有 s0)，乘以拥有最终 s2 的概率(假设我们之前依次拥有 s0 和 s1)。数学上，它可以写成

![](img/3c6ac5100261b747552e093d3c3009a9.png)

然后出现了由马尔可夫假设给出的简化。事实上，对于长链，我们将获得最后状态的严重条件概率。然而，在马尔可夫的情况下，我们可以简化这个表达式

![](img/0bb510620bfa8d005c4cc7b81f435304.png)

这样我们就有

![](img/958cd5216de294fe69057903f8d91bc3.png)

由于它们完全表征了过程的概率动态，因此许多其他更复杂的事件可以仅基于初始概率分布 q0 和转移概率核 p 进行计算。值得给出的最后一个基本关系是相对于时间 n 的概率分布而言的时间 n+1 的概率分布的表达式

![](img/5c5e7cd0db6844c003ef9eb491dca0c3.png)

# 有限状态空间马尔可夫链

## 矩阵和图形表示

这里我们假设在 E 中有 N 个有限的可能状态:

![](img/28079bc6ebb9de76b2897eaae05cf015.png)

然后，初始概率分布可以由大小为 N 的**行向量** q0 来描述，并且转移概率可以由大小为 N×N 的矩阵 p 来描述，使得

![](img/e36b958cb7713768daeca91e385dd89d.png)

这种记法的优点是，如果我们用原始向量 qn 来表示步骤 n 的概率分布，则它的分量由下式给出

![](img/93fec51bd438755693b196a95a5defc4.png)

那么简单的矩阵关系此后成立

![](img/13b799cd8a66e8d01fbd7c8ed18d60ad.png)

(此处不详述证明，但可以非常容易地恢复)。

![](img/d3a821a646e1db18251d75a55f4b9b7e.png)

When right multiplying a row vector representing probability distribution at a given time step by the transition probability matrix, we obtain the probability distribution at the next time step.

因此，我们在这里看到，将概率分布从一个给定的步骤发展到下一个步骤，就像将初始步骤的行概率向量乘以矩阵 p 一样简单

![](img/b714288aeb44f7062effd2388deaebf6.png)

有限状态空间马尔可夫链的随机动态可以容易地表示为有值定向图，使得图中的每个节点是一个状态，并且对于所有的状态对(ei，ej)，如果 p(ei，ej)>0，则存在从 ei 到 ej 的边。那么边缘的值就是这个相同的概率 p(ei，ej)。

## 示例:《走向数据科学》读本

让我们举一个简单的例子来说明这一切。考虑一个虚构人物对数据科学读者的日常行为。对于每一天，有 3 种可能的状态:读者这一天没有访问 TDS(N)，读者访问了 TDS 但是没有阅读完整的帖子(V)，以及读者访问了 TDS 并且阅读了至少一个完整的帖子(R)。所以，我们有下面的状态空间

![](img/bf460cf6d2f089c14408d0468dc2cb27.png)

假设在第一天，该读者有 50%的机会只访问 TDS，有 50%的机会访问 TDS 并阅读至少一篇文章。描述初始概率分布(n=0)的向量为

![](img/4151e03ec8e1d5f8d9a65c35db0178a2.png)

假设观察到以下概率:

*   当读者一天不访问 TDS，他有 25%的机会第二天仍然不访问，50%的机会只访问，25%的机会访问和阅读
*   当读者访问 TDS 一天没有阅读，第二天有 50%的机会再次访问而没有阅读，有 50%的机会访问并阅读
*   当读者访问并阅读了一天，他有 33%的几率第二天不访问*(希望这个帖子不会有这种效果！)*，33%的几率只访问，34%的几率再次访问和阅读

然后，我们有下面的转移矩阵

![](img/4fa79db9451dd7908dcbc2742009414e.png)

根据前面的小节，我们知道如何为读者计算第二天(n=1)每个状态的概率

![](img/0a937a61a603988c263736b78481d723.png)

最后，这个马尔可夫链的概率动态可以用图形表示如下

![](img/9551ec5ed0fd3f2e05df9b573d978d55.png)

Graph representation of the Markov chain modelling our fictive TDS reader behaviour.

# 马尔可夫链属性

在这一节中，我们将只给出一些基本的马氏链性质或特征。这个想法不是要深入数学细节，而是给出一个使用马尔可夫链时需要研究的兴趣点的概述。正如我们已经看到的，在有限状态空间的情况下，我们可以将马尔可夫链描绘成一个图，请注意，我们将使用图形表示来说明下面的一些特性。然而，应该记住，这些性质不一定局限于有限状态空间的情况。

## 还原性、周期性、短暂性和重现性

在这一小节中，让我们从描述一个状态或整个马尔可夫链的一些经典方法开始。
首先，我们说一个马尔可夫链是**不可约的**，如果它有可能从任何其他状态到达任何状态(不一定在一个时间步内)。如果状态空间是有限的，链可以用一个图来表示，那么我们可以说一个不可约马氏链的图是强连通的(图论)。

![](img/2f4ec4c6cceb55e94e1f4d25846ace32.png)

Illustration of the irreducibility property. The chain on the left is not irreducible: from 3 or 4 we can’t reach 1 or 2\. The chain on the right (one edge has been added) is irreducible: each state can be reached from any other state.

如果当离开一个状态时，返回到该状态需要 k 个时间步长的倍数(k 是所有可能返回路径长度的最大公约数)，则该状态具有周期 k。如果 k = 1，那么状态被认为是非周期的，如果一个完整的马尔可夫链的所有状态都是非周期的，那么它就是**非周期的**。对于一个不可约的马尔可夫链，我们还可以提到这样一个事实:如果一个状态是非周期的，那么所有的状态都是非周期的。

![](img/e2647833a47e2fa25b9dae5397e7ccc3.png)

Illustration of the periodicity property. The chain on the left is 2-periodic: when leaving any state, it always takes a multiple of 2 steps to come back to it. The chain on the right is 3-periodic.

如果当我们离开一个状态时，有一个非零的概率表明我们再也不会回到这个状态，那么这个状态就是暂时的。相反，如果我们知道，在离开一个状态之后，我们会以概率 1 返回到那个状态，那么这个状态就是**循环的**(如果它不是短暂的)。

![](img/e18aa30b8ac2e3036a6ba5fc73fab575.png)

Illustration of the recurrence/transience property. The chain of the left is such that: 1, 2 and 3 are transient (when leaving these points we can’t be absolutely sure that we will come back to them) and 3-periodic whereas 4 and 5 are recurrent (when leaving these points we are absolutely sure that we will come back to them at some time) and 2-periodic. The chain on the right has one more edge that makes the full chain recurrent and aperiodic.

对于一个循环状态，我们可以计算平均循环时间，即离开该状态时的**预期返回时间**。注意，即使收益概率等于 1，也不意味着期望收益时间是有限的。因此，在循环状态中，我们可以区分**正循环**状态(有限预期返回时间)和**零循环**状态(无限预期返回时间)。

## 平稳分布、极限行为和遍历性

在这一小节中，我们将讨论马尔可夫链所描述的(随机)动态的某些特征。

状态空间 E 上的概率分布π被称为**稳定分布**，如果它验证了

![](img/a0cd3cf166b845fc244a60ced763e1b8.png)

正如我们所做的

![](img/5b8129a29bee5359cc066c2149c50bea.png)

然后，平稳分布验证

![](img/16927c58219e1f1d9cc7b5f1a7e8640f.png)

根据定义，一个稳定的概率分布是这样的，它不会随着时间而演化。因此，如果初始分布 q 是一个平稳分布，那么它将在所有未来时间步保持不变。如果状态空间是有限的，p 可以用一个矩阵来表示，π可以用一个原始向量来表示，那么我们有

![](img/9782c1c097b698e8ce9193f49618058f.png)

再一次，它表达了一个事实，即一个稳定的概率分布不会随时间演化(正如我们看到的，概率分布乘以 p 就可以计算下一个时间步的概率分布)。注意，一个不可约的马尔可夫链有一个稳定的概率分布，当且仅当它的所有状态都是正循环的。

与平稳概率分布相关的另一个有趣的性质如下。如果链是递归正的(因此存在平稳分布)和非周期的，那么不管初始概率是多少，当时间步长趋于无穷大时，链的概率分布收敛:链被称为具有一个**极限分布**，它就是平稳分布。在一般情况下，它可以写成

![](img/1a4848733225468bf9796b8efdbe0067.png)

让我们再次强调这样一个事实，即没有对初始概率分布的假设:不管初始设置如何，链的概率分布都收敛于稳定分布(链的平衡分布)。

最后，**遍历性**是与马尔可夫链的行为相关的另一个有趣的属性。如果一个马尔可夫链是不可约的，那么我们也说这个链是“遍历的”,因为它证明了下面的遍历定理。假设我们有一个应用程序 f(。)从状态空间 E 到真实线(例如，它可以是每个状态中的成本)。我们可以定义这个应用沿着给定轨迹的平均值(时间平均值)。对于第 n 个第一项，它表示为

![](img/b4e9da14983ffc0e3b952f813ef9f2ce.png)

我们还可以计算应用 f 在集合 E 上的平均值，集合 E 由固定分布(空间平均值)加权，表示为

![](img/c9612f1d2361c80bf7b5cab75ab56494.png)

那么遍历定理告诉我们，当轨迹变得无限长时的时间均值等于空间均值(由平稳分布加权)。遍历属性可以写成

![](img/1296729d99179ee73c4c07fe3fa13687.png)

换句话说，在极限情况下，轨迹的早期行为变得可以忽略不计，只有长期稳定行为在计算时间平均值时才真正重要。

## 回到我们的 TDS 阅读器示例

我们再次考虑 TDS 阅读器的例子。在这个简单的例子中，链显然是不可约的、非周期的，并且所有状态都是循环正的。

为了展示可以用马尔可夫链计算的有趣结果，我们想看看状态 R(状态“访问和阅读”)的平均重现时间。换句话说，我们想回答以下问题:当我们的 TDS 读者在某一天访问并阅读时，在他再次访问和阅读之前，我们平均要等待多少天？让我们试着直观地了解一下如何计算这个值。

首先，我们表示

![](img/3c74325fc6f70c4de05dcad09d6c1ee1.png)

所以我们想在这里计算 m(R，R)。在离开 R 后的第一步推理中，我们得到

![](img/fe4c7f3b48a6b5009e321f6722077ac2.png)

但是，这个表达式需要知道 m(N，R)和 m(V，R)才能计算 m(R，R)。这两个量可以用同样的方式表示

![](img/b3ecab2e7f6b698f3e88386b72374f2c.png)

因此，我们有 3 个含有 3 个未知数的方程，当我们求解这个系统时，我们得到 m(N，R) = 2.67，m(V，R) = 2.00，m(R，R) = 2.54。状态 R 的平均重现时间的值是 2.54。因此，我们看到，通过一些线性代数，我们设法计算出状态 R 的平均重现时间(以及从 N 到 R 的平均时间和从 V 到 R 的平均时间)。

为了结束这个例子，让我们看看这个马尔可夫链的平稳分布是什么。为了确定平稳分布，我们必须解下面的线性代数方程

![](img/d034905cb1ebb0ff7bce9e71196d1820.png)

所以，我们必须找到与特征值 1 相关的 p 的左特征向量。解决这个问题，我们得到下面的平稳分布

![](img/d07f2fa7a7a4c22c6c01a470d4a6b337.png)

Stationary distribution of our “TDS reader” example.

我们还可以注意到π(R) = 1/m(R，R)，稍微思考一下，这是一个非常符合逻辑的恒等式(但在这篇文章中我们不会给出更多细节)。

由于链是不可约的和非周期性的，这意味着，从长远来看，概率分布将收敛到稳定分布(对于任何初始化)。换句话说，无论我们的 TDS 阅读器的初始状态是什么，如果我们等待足够长的时间并随机选择一天，那么我们有一个概率π(N)读者在这一天不访问，一个概率π(V)读者访问但不阅读，以及一个概率π(R)读者访问并阅读。为了更好地掌握收敛特性，让我们看一下下图，该图显示了从不同起点开始概率分布的演变以及(快速)收敛到稳定分布

![](img/38dbf48c62c734ccfc1dd980b0377ff3.png)

Visualisation of the convergence of 3 differently initialised probability distributions (blue, orange and green) towards the stationary distribution (red).

# 一个经典的例子:PageRank 算法

现在是时候回到 PageRank 了！在进一步讨论之前，让我们提一下这样一个事实:我们将要给出的 PageRank 的解释并不是唯一可能的，而且原始论文的作者在设计该方法时并不一定考虑到了马尔可夫链。然而，下面的解释有一个很好理解的优点。

## 随机网络冲浪者

PageRank 试图解决的问题如下:我们如何通过使用页面之间的现有链接对给定集合中的页面进行排序(我们可以假设该集合已经被过滤，例如在一些查询中)？

为了解决这个问题并能够对页面进行排序，PageRank 大致如下进行。我们认为一个随机的网上冲浪者在最初的时间是在一个页面上。然后，该冲浪者通过对每个页面点击指向所考虑的集合中的另一个页面的链接之一来开始随机导航(假设不允许链接到该集合之外的页面)。对于给定的页面，所有允许的链接都有同等的机会被点击。

这里我们有一个马尔可夫链的设置:页面是不同的可能状态，转移概率由从一个页面到另一个页面的链接来定义(加权使得在每个页面上所有链接的页面都有相等的机会被选择),并且无记忆属性由冲浪者的行为清楚地验证。如果我们还假设所定义的链是循环正的和非周期性的(使用一些小技巧来确保我们满足这个设置)，那么在很长时间之后，“当前页面”概率分布收敛到稳定分布。所以，不管起始页面是什么，如果我们选择一个随机的时间步长，很长时间后每个页面都有可能(几乎是固定的)成为当前页面。

PageRank 背后的假设是，在平稳分布中最有可能的页面也一定是最重要的(我们经常访问这些页面，因为它们从在这个过程中也经常被访问的页面接收链接)。然后，静态概率分布为每个状态定义了 PageRank 的值。

## 玩具的例子

为了让这一切更清楚，让我们考虑一个玩具的例子。假设我们有一个很小的网站，有 7 个从 1 到 7 的页面，页面之间有链接，如下图所示。

![](img/d655f057a96e2f9cc8a240d1d5c79b86.png)

为了清楚起见，在先前的表示中没有显示每个转换的概率。然而，由于“导航”被认为是完全随机的(我们也谈论“随机行走”)，使用简单的以下规则可以容易地恢复这些值:对于具有 K 个外部链接的节点(具有 K 个到其他页面的链接的页面)，每个外部链接的概率等于 1/K。因此，概率转移矩阵由下式给出

![](img/1d6dd789f7ed16624da630ae94a266db.png)

其中 0.0 值已被替换为“.”为了可读性。在任何进一步的计算之前，我们可以注意到，这个马尔可夫链是不可约的，也是非周期的，因此，在长期运行之后，系统收敛到一个平稳分布。正如我们已经看到的，我们可以通过求解下面的左特征向量问题来计算这个平稳分布

![](img/7a7d75c0a4d623aea4359748db7f17c2.png)

通过这样做，我们获得了每页的 PageRank 值(稳定分布的值)

![](img/3e3b51bdc5a2545100d5800be79f1c54.png)

PageRank values computed on our toy example that contains 7 pages.

这个小网站的页面排名是 1 > 7 > 4 > 2 > 5 = 6 > 3。

# 外卖食品

这篇文章的主要观点如下:

*   随机过程是随机变量的集合，通常随时间进行索引(索引通常代表离散或连续时间)
*   对于随机过程，马尔可夫性质表示，给定现在，未来的概率独立于过去(该性质也称为“无记忆性质”)
*   离散时间马尔可夫链是具有离散时间指标的随机过程，它验证了马尔可夫性
*   马氏链的马氏链性质使得对这些过程的研究变得更加容易，并且允许导出一些有趣的显式结果(平均重现时间，平稳分布…)
*   对 PageRank 的一种可能的解释(不是唯一的解释)在于想象一个网上冲浪者随机地从一个页面导航到另一个页面，并且将页面上的诱导的稳定分布作为排名的一个因素(粗略地说，处于稳定状态的最常被访问的页面必须是由其他非常常被访问的页面链接的页面，然后必须是最相关的)

最后，让我们再一次强调，在处理随机动态时，马尔可夫链对于问题建模是多么强大。由于其良好的特性，它们被用于各种领域，如[排队理论](https://pdfs.semanticscholar.org/ad9c/e4c0707cd3ea14d65d350996d297c3296856.pdf)(优化电信网络的性能，其中消息必须经常竞争有限的资源，并且当所有资源都已被分配时被排队)、统计学(众所周知的“[马尔可夫链蒙特卡罗](/bayesian-inference-problem-mcmc-and-variational-inference-25a8aa9bce29)“随机变量生成技术是基于马尔可夫链的”)、生物学(生物种群进化的建模)、计算机科学([隐马尔可夫模型](http://ai.stanford.edu/~pabbeel/depth_qual/Rabiner_Juang_hmms.pdf)是信息论和语音识别中的重要工具)以及其他。

显然，马尔可夫链在建模和计算方面提供的巨大可能性远远落后于这篇适度的介绍，因此，我们鼓励感兴趣的读者阅读更多关于这些完全在(数据)科学家工具箱中占有一席之地的工具的信息。

感谢阅读！

用 [Baptiste Rocca](https://medium.com/u/20ad1309823a?source=post_page-----2c8cab9c98ab--------------------------------) 写的其他文章:

[](/handling-imbalanced-datasets-in-machine-learning-7a0e84220f28) [## 机器学习中不平衡数据集的处理

### 面对不平衡的班级问题，应该做什么，不应该做什么？

towardsdatascience.com](/handling-imbalanced-datasets-in-machine-learning-7a0e84220f28) [](/ensemble-methods-bagging-boosting-and-stacking-c9214a10a205) [## 整体方法:装袋、助推和堆叠

### 理解集成学习的关键概念。

towardsdatascience.com](/ensemble-methods-bagging-boosting-and-stacking-c9214a10a205)