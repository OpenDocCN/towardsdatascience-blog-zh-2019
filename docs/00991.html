<html>
<head>
<title>Object detection &amp; Face recognition algorithms</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">对象检测和人脸识别算法</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/object-detection-face-recognition-algorithms-146fec385205?source=collection_archive---------15-----------------------#2019-02-15">https://towardsdatascience.com/object-detection-face-recognition-algorithms-146fec385205?source=collection_archive---------15-----------------------#2019-02-15</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><figure class="is it gp gr iu iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi ir"><img src="../Images/ebcf6a029f4b04368542b3b91e0090c3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_0Cu63U3TlJCoJ3kZcgNoA.jpeg"/></div></div><figcaption class="jc jd gj gh gi je jf bd b be z dk">Photo by <a class="ae jg" href="https://www.pexels.com/fr-fr/@skitterphoto?utm_content=attributionCopyText&amp;utm_medium=referral&amp;utm_source=pexels" rel="noopener ugc nofollow" target="_blank">Skitterphoto</a> downloaded from <a class="ae jg" href="https://www.pexels.com/fr-fr/photo/appareil-photo-appareils-bureau-cafe-705164/?utm_content=attributionCopyText&amp;utm_medium=referral&amp;utm_source=pexels" rel="noopener ugc nofollow" target="_blank">Pexels</a></figcaption></figure><div class=""/><div class=""><h2 id="7cee" class="pw-subtitle-paragraph kg ji jj bd b kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx dk translated">卷积神经网络.第 2 部分:实现目标探测和人脸识别算法的详细卷积结构</h2></div><p id="cc4e" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">卷积神经网络广泛用于解决基于图像的问题，例如对象/字符检测和人脸识别。在本文中，我们将重点介绍从 LeNet 到 Siamese networks 的最著名架构，其中大多数架构如下:</p><figure class="lv lw lx ly gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi lu"><img src="../Images/158e2897550258064b5422c8ea193ff2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*YejW73f36BGhNGhrtbz67g.png"/></div></div><figcaption class="jc jd gj gh gi je jf bd b be z dk">Image by Author</figcaption></figure><p id="bdf4" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">如果你没有任何关于卷积神经网络的知识，我建议你阅读这篇文章的<a class="ae jg" rel="noopener" target="_blank" href="/convolutional-neural-networks-mathematics-1beb3e6447c0">第一部分</a> t，讨论 CNN 的基础知识。</p><p id="4cd4" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">注意:因为 Medium 不支持 LaTeX，所以数学表达式是作为图像插入的。因此，为了更好的阅读体验，我建议你关闭黑暗模式。</p></div><div class="ab cl lz ma hx mb" role="separator"><span class="mc bw bk md me mf"/><span class="mc bw bk md me mf"/><span class="mc bw bk md me"/></div><div class="im in io ip iq"><h1 id="b9f7" class="mg mh jj bd mi mj mk ml mm mn mo mp mq kp mr kq ms ks mt kt mu kv mv kw mw mx bi translated">目录</h1><blockquote class="my mz na"><p id="5e8e" class="ky kz nb la b lb lc kk ld le lf kn lg nc li lj lk nd lm ln lo ne lq lr ls lt im bi translated"><em class="jj"> 1。交叉熵<br/> 2。图像分类<br/> 3。物体检测— YOLOv3 <br/> 4。人脸识别—暹罗网络</em></p></blockquote></div><div class="ab cl lz ma hx mb" role="separator"><span class="mc bw bk md me mf"/><span class="mc bw bk md me mf"/><span class="mc bw bk md me"/></div><div class="im in io ip iq"><h1 id="0350" class="mg mh jj bd mi mj mk ml mm mn mo mp mq kp mr kq ms ks mt kt mu kv mv kw mw mx bi translated">1-交叉熵</h1><p id="2fb1" class="pw-post-body-paragraph ky kz jj la b lb nf kk ld le ng kn lg lh nh lj lk ll ni ln lo lp nj lr ls lt im bi translated">当对图像进行分类时，我们通常在最后一层使用大小为(<em class="nb"> C </em>，1)的<code class="fe nk nl nm nn b">softmax</code>函数，其中<em class="nb"> C </em>是所讨论的类的数量。<br/>向量的第<em class="nb">I</em>行是输入图像属于类别<em class="nb"> i </em>的概率。<code class="fe nk nl nm nn b">predicted class</code>被设置为与<code class="fe nk nl nm nn b">highest probability.</code>相对应的那个</p><figure class="lv lw lx ly gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi no"><img src="../Images/5d75722aa9665af4f6ab662134147dec.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*fPDrhqk23bSnC5dnKsvt7Q.png"/></div></div></figure><p id="fa84" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">网络通过使用<a class="ae jg" rel="noopener" target="_blank" href="/deep-learnings-mathematics-f52b3c4d2576">反向传播</a>进行学习，并优化定义如下的<code class="fe nk nl nm nn b">cross entropy</code>:</p><figure class="lv lw lx ly gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi np"><img src="../Images/d5b1acefd0ac2b340e51e641df9deda9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_2vT_c5s6j42lcZXpdKvjg.png"/></div></div></figure><p id="666f" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">在哪里</p><ul class=""><li id="2cc3" class="nq nr jj la b lb lc le lf lh ns ll nt lp nu lt nv nw nx ny bi translated"><em class="nb"> p </em> ( <em class="nb"> x </em>，<em class="nb">类</em>)是参考概率，如果对象确实属于所填写的类，则等于 1，否则等于 0</li><li id="7c5e" class="nq nr jj la b lb nz le oa lh ob ll oc lp od lt nv nw nx ny bi translated"><em class="nb"> q </em> ( <em class="nb"> x </em>，<em class="nb">类</em>)是网络通过 softmax 获知的对象 x 属于该类的概率</li></ul><p id="e3bd" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">对于输入<em class="nb"> x </em> ∈ <em class="nb"> class_j </em>:</p><figure class="lv lw lx ly gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi oe"><img src="../Images/6b946f309f1cc851ea745f4ec1303eac.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*yM8owtQiNu6alT552V24yA.png"/></div></div></figure><p id="0e2c" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">因此，我们把<code class="fe nk nl nm nn b">loss function</code>设定为:</p><figure class="lv lw lx ly gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi of"><img src="../Images/a7083cf6f1eeae2b591b0bf1a32e776f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*nTOu65y3r1rcKMHk2WwjQw.png"/></div></div></figure><p id="5264" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">我们平均损失，其中<em class="nb"> m </em>是训练集的大小。</p></div><div class="ab cl lz ma hx mb" role="separator"><span class="mc bw bk md me mf"/><span class="mc bw bk md me mf"/><span class="mc bw bk md me"/></div><div class="im in io ip iq"><h1 id="c711" class="mg mh jj bd mi mj mk ml mm mn mo mp mq kp mr kq ms ks mt kt mu kv mv kw mw mx bi translated">2-图像分类</h1><h2 id="284f" class="og mh jj bd mi oh oi dn mm oj ok dp mq lh ol om ms ll on oo mu lp op oq mw or bi translated">LeNet —数字识别</h2><p id="9b82" class="pw-post-body-paragraph ky kz jj la b lb nf kk ld le ng kn lg lh nh lj lk ll ni ln lo lp nj lr ls lt im bi translated">LeNet 是由<a class="ae jg" href="https://www.linkedin.com/in/yann-lecun-0b999/" rel="noopener ugc nofollow" target="_blank"> Yann Lecun </a>开发的一个架构，它的目标是检测输入中出现的数字。<br/>给定从 0 到 9 的<code class="fe nk nl nm nn b">hand-written</code>位数的<code class="fe nk nl nm nn b">gray-scale</code>幅图像，卷积神经网络预测图像的位数。<br/>训练集被称为<code class="fe nk nl nm nn b">MNIST</code>，它是一个数据集，包含超过 70k 个具有 28x28x1 像素的图像。神经网络具有以下计算超过 60k 个参数的架构:</p><figure class="lv lw lx ly gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi os"><img src="../Images/bb58c5b68acc903aadd02dd7d3b3ca2a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*NOnMXgFljE4Aj3ce2Y8mew.png"/></div></div><figcaption class="jc jd gj gh gi je jf bd b be z dk">Official paper of LeNet</figcaption></figure><p id="3f87" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">更多详情，建议你看官方<a class="ae jg" href="http://yann.lecun.com/exdb/publis/pdf/lecun-01a.pdf" rel="noopener ugc nofollow" target="_blank">论文</a>。</p><h2 id="2108" class="og mh jj bd mi oh oi dn mm oj ok dp mq lh ol om ms ll on oo mu lp op oq mw or bi translated">AlexNet</h2><p id="82d0" class="pw-post-body-paragraph ky kz jj la b lb nf kk ld le ng kn lg lh nh lj lk ll ni ln lo lp nj lr ls lt im bi translated">AlexNet 是一个著名的建筑，它赢得了 2012 年的 ImageNet 竞赛。它类似于 LeNet，但有更多的层次，辍学和重新激活功能的大部分时间。</p><figure class="lv lw lx ly gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi os"><img src="../Images/e3dd6fd42dd0fb2e95a2f1a02f820513.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_5QP3edJot_b8fneDFx4ug.png"/></div></div><figcaption class="jc jd gj gh gi je jf bd b be z dk">Official paper of AlexNet</figcaption></figure><p id="2e48" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">训练集是<code class="fe nk nl nm nn b">ImageNet database</code>的子集，T3 是 1500 万张<a class="ae jg" href="http://www.image-net.org/" rel="noopener ugc nofollow" target="_blank">标记的图像</a>，具有高分辨率，代表超过 22k 个类别。<br/> AlexNet 在训练集中使用了超过 120 万张图片，在验证集中使用了 50k，在测试集中使用了 150k，这些图片都被调整到了 227x227x3。该架构有多个<code class="fe nk nl nm nn b">60 million parameters</code>，因此在<code class="fe nk nl nm nn b">2 GPUs</code>上被训练，它输出一个大小为<em class="nb"> (1000，1) </em>的<code class="fe nk nl nm nn b">softmax vector</code>。</p><p id="2651" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">要了解更多信息，我建议你阅读官方<a class="ae jg" href="https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf" rel="noopener ugc nofollow" target="_blank">文件</a>。</p><h2 id="a302" class="og mh jj bd mi oh oi dn mm oj ok dp mq lh ol om ms ll on oo mu lp op oq mw or bi translated">VGG-16</h2><p id="8126" class="pw-post-body-paragraph ky kz jj la b lb nf kk ld le ng kn lg lh nh lj lk ll ni ln lo lp nj lr ls lt im bi translated">VGG-16 在一个卷积神经网络上进行图像分类，在同一个数据集<code class="fe nk nl nm nn b">ImageNet</code>上训练，并且已经在多个<code class="fe nk nl nm nn b">138 million parameters</code>GPU 上训练。<br/>架构如下:</p><figure class="lv lw lx ly gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi ot"><img src="../Images/8a18ab10c2450c4584698137bf472125.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*gtXfhZkxl8Glp2fNsIIMpg.png"/></div></div><figcaption class="jc jd gj gh gi je jf bd b be z dk">Official paper of VGG-16</figcaption></figure><p id="7aa2" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">它比 AlexNet 更准确、更深入，因为它用连续的 3x3 内核取代了大型内核 11x11x5 和 5x5。更多细节，请查看 VGG 项目的官方文件。</p></div><div class="ab cl lz ma hx mb" role="separator"><span class="mc bw bk md me mf"/><span class="mc bw bk md me mf"/><span class="mc bw bk md me"/></div><div class="im in io ip iq"><h1 id="6583" class="mg mh jj bd mi mj mk ml mm mn mo mp mq kp mr kq ms ks mt kt mu kv mv kw mw mx bi translated">三物体检测— YOLO</h1><p id="33fe" class="pw-post-body-paragraph ky kz jj la b lb nf kk ld le ng kn lg lh nh lj lk ll ni ln lo lp nj lr ls lt im bi translated">目标检测是在图像中检测多个目标的任务，包括目标定位和目标分类。第一种粗略的方法是滑动具有可定制尺寸的窗口，并使用在裁剪图像上训练的网络来预测每次内容的类别。这个过程有很高的计算成本，幸运的是可以使用卷积来实现自动化。<br/> YOLO 代表<strong class="la jk">Y</strong>ou<strong class="la jk">O</strong>only<strong class="la jk">L</strong>ook<strong class="la jk">O</strong>nce，其基本思想是在图像上放置一个网格(通常为 19x19 ),其中:</p><blockquote class="my mz na"><p id="8472" class="ky kz nb la b lb lc kk ld le lf kn lg nc li lj lk nd lm ln lo ne lq lr ls lt im bi translated">只有一个单元，即包含对象中心/中点的单元，负责检测该对象</p></blockquote><p id="2a3d" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">网格(<em class="nb"> i </em>，<em class="nb"> j </em>)的每个单元格标记如下:</p><figure class="lv lw lx ly gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi ou"><img src="../Images/3ef551bb6df5467c043a074023fe78e5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*VTYYiB76ph_2dYMlQvfNJg.png"/></div></div></figure><figure class="lv lw lx ly gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi ov"><img src="../Images/14e518d460d621c54b9ed9f734b25e1b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*0jrU9w72-s1lsmYKaTp3lw.png"/></div></div><figcaption class="jc jd gj gh gi je jf bd b be z dk">Image by Author</figcaption></figure><p id="e03f" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">因此，对于每个图像，目标输出的大小为:</p><figure class="lv lw lx ly gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi ow"><img src="../Images/87428ab80c0d34d4480b1def6b0b6a5a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*L4Z61qSoZlHa0-GLhjmkAA.png"/></div></div></figure><h2 id="5d62" class="og mh jj bd mi oh oi dn mm oj ok dp mq lh ol om ms ll on oo mu lp op oq mw or bi translated">IOU &amp; NMS</h2><p id="9900" class="pw-post-body-paragraph ky kz jj la b lb nf kk ld le ng kn lg lh nh lj lk ll ni ln lo lp nj lr ls lt im bi translated">为了评估对象定位，我们使用<strong class="la jk">I</strong>intersection<strong class="la jk">O</strong>ver<strong class="la jk">U</strong>nion 来测量两个边界框之间的<code class="fe nk nl nm nn b">overlap</code>:</p><figure class="lv lw lx ly gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi ox"><img src="../Images/727a96cdbbafc49c7cd491e8ee5c6810.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*W0s7wnejxgJLgWxFuBnkxw.png"/></div></div><figcaption class="jc jd gj gh gi je jf bd b be z dk">Image by Author</figcaption></figure><p id="dbc3" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">当预测给定网格单元中给定对象的边界框时，可能会给出许多输出，<code class="fe nk nl nm nn b">Non-Max Suppression</code>帮助您检测对象<code class="fe nk nl nm nn b">only once</code>。它取最高的概率，并抑制具有高重叠(IOU)的其他框。<br/>对于网格的每个单元，算法如下:</p><figure class="lv lw lx ly gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi ou"><img src="../Images/6d7af5f4849a8b6e3c85c3b339df8e70.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*aiac-6PBHAVCFcK9seiuYQ.png"/></div></div></figure><figure class="lv lw lx ly gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi oy"><img src="../Images/c8a160f88a23f0975e7418feeb01b722.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*GeVmBAiWFbQYRg3ul9gNEA.png"/></div></div><figcaption class="jc jd gj gh gi je jf bd b be z dk">Image by Author</figcaption></figure><h2 id="7a39" class="og mh jj bd mi oh oi dn mm oj ok dp mq lh ol om ms ll on oo mu lp op oq mw or bi translated">锚箱</h2><p id="5106" class="pw-post-body-paragraph ky kz jj la b lb nf kk ld le ng kn lg lh nh lj lk ll ni ln lo lp nj lr ls lt im bi translated">在大多数情况下，一个网格单元可能包含<code class="fe nk nl nm nn b">multiple objects</code>，锚盒允许检测所有这些。在<code class="fe nk nl nm nn b">2 anchor boxes</code>的情况下，网格的每个单元格标记如下:</p><figure class="lv lw lx ly gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi oz"><img src="../Images/10644d72aca9b67c2c327a12a4359cdd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ljtQSkJt0AffTsp3rNRqAw.png"/></div></div></figure><figure class="lv lw lx ly gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi pa"><img src="../Images/f14ef78266aed6e0f10f1fdde5073490.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*YpDX85SxAFN3v5NvPzsj3Q.png"/></div></div><figcaption class="jc jd gj gh gi je jf bd b be z dk">Image by Author</figcaption></figure><p id="97fb" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">更一般地，输出目标的大小为:</p><figure class="lv lw lx ly gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi pb"><img src="../Images/aa59d01d36ddd97c5d3dc9bbee14d658.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*XrEI7gvxhTKRAmL-Tr_X5Q.png"/></div></div></figure><p id="ffec" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">其中<em class="nb"> N </em>为班数<em class="nb"> M </em>为锚箱数。</p><h2 id="1016" class="og mh jj bd mi oh oi dn mm oj ok dp mq lh ol om ms ll on oo mu lp op oq mw or bi translated">YOLOv3 算法</h2><p id="b56c" class="pw-post-body-paragraph ky kz jj la b lb nf kk ld le ng kn lg lh nh lj lk ll ni ln lo lp nj lr ls lt im bi translated">YOLO 接受了 coco 数据集的训练，这是一个大规模的对象检测、分割和字幕数据库，包含 80 个对象类别。YOLOv3 有一个<code class="fe nk nl nm nn b">Darknet-53</code>架构作为特征提取器，也称为<code class="fe nk nl nm nn b">backbone</code>。</p><p id="916c" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">通过使用梯度方法最小化<code class="fe nk nl nm nn b">loss function</code>来进行训练。<br/>是<code class="fe nk nl nm nn b">combined</code>的:</p><ul class=""><li id="ddb8" class="nq nr jj la b lb lc le lf lh ns ll nt lp nu lt nv nw nx ny bi translated"><em class="nb"> p_c 上的逻辑回归损失</em></li><li id="b98a" class="nq nr jj la b lb nz le oa lh ob ll oc lp od lt nv nw nx ny bi translated"><em class="nb"> b_i </em>的平方误差损失</li><li id="7a03" class="nq nr jj la b lb nz le oa lh ob ll oc lp od lt nv nw nx ny bi translated">概率<em class="nb"> c_i </em>的软最大损失(交叉熵)</li></ul><p id="eeef" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">在每个时期，在每个单元中，我们生成输出<em class="nb"> y_(i，j) </em>和<code class="fe nk nl nm nn b">evaluate</code>损失函数。<br/>进行预测时，我们检查<em class="nb"> p_c </em>是否足够高，对于每个网格单元，我们去除低概率预测，并对每个类使用非最大抑制来生成最终输出。<br/>想了解更多信息，我建议你阅读官方<a class="ae jg" href="https://arxiv.org/pdf/1804.02767.pdf" rel="noopener ugc nofollow" target="_blank">论文</a>。</p></div><div class="ab cl lz ma hx mb" role="separator"><span class="mc bw bk md me mf"/><span class="mc bw bk md me mf"/><span class="mc bw bk md me"/></div><div class="im in io ip iq"><h1 id="ff06" class="mg mh jj bd mi mj mk ml mm mn mo mp mq kp mr kq ms ks mt kt mu kv mv kw mw mx bi translated">4-人脸识别-连体网络</h1><p id="5db8" class="pw-post-body-paragraph ky kz jj la b lb nf kk ld le ng kn lg lh nh lj lk ll ni ln lo lp nj lr ls lt im bi translated">暹罗网络是神经网络，通常是卷积的，它允许计算两个输入(在我们的情况下是图像)之间的相似度，如下所示:</p><figure class="lv lw lx ly gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi oy"><img src="../Images/4bd4f1a26f4f06d8bc550fb8e6ba909f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*4jqvNSpQW6qY6fKCqQMR0A.png"/></div></div><figcaption class="jc jd gj gh gi je jf bd b be z dk">Image by Author</figcaption></figure><p id="0308" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">CNN 模块的目的是在另一个空间中表示图像上的信息，这要归功于一个函数，叫做<code class="fe nk nl nm nn b">embedding space</code>。然后，我们使用某个距离比较两个嵌入。暹罗网络中的学习是通过最小化一个目标函数来完成的，该目标函数由一个叫做<code class="fe nk nl nm nn b">triplet</code>的损失函数组成。</p><p id="0bdc" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><code class="fe nk nl nm nn b">triplet</code>函数以 3 个向量变量作为输入:一个锚点<strong class="la jk"> <em class="nb"> A </em> </strong>，一个正的<strong class="la jk"> <em class="nb"> P </em> </strong>(类似于<strong class="la jk"> <em class="nb"> A </em> </strong>)和一个负的<strong class="la jk"> <em class="nb"> N </em> </strong>(不同于<strong class="la jk"> <em class="nb"> A </em> </strong>)。因此，我们希望:</p><figure class="lv lw lx ly gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi pc"><img src="../Images/b838739ee7ffdaeacfa7eaa480b96b3c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*bczwvOkReF6InX4b3psCWw.png"/></div></div></figure><p id="2da2" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">其中∨<em class="nb">x</em>∨=&lt;<em class="nb">x</em>，<em class="nb"> x </em> &gt;为给定的标量积。</p><p id="cc50" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">为了防止学习函数<em class="nb"> f </em>为空，我们定义裕量 0 &lt; <em class="nb"> α </em> ≤1，从而:</p><figure class="lv lw lx ly gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi pb"><img src="../Images/876191046ca6abfb17e43e6fe1fd13e2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*cvNFuzu_RkT4f8QTivAfew.png"/></div></div></figure><p id="158f" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">因此，我们将<code class="fe nk nl nm nn b">loss</code>函数定义如下:</p><figure class="lv lw lx ly gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi ou"><img src="../Images/58e05043a87aed83e3cd7f87fcaac4c8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*5OXF91UZQeky5ljepgnyyw.png"/></div></div></figure><p id="6630" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">从大小为<em class="nb"> n </em>的学习数据库开始，要最小化的目标函数是:</p><figure class="lv lw lx ly gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi oz"><img src="../Images/3a30371e8c6c035c4fb0ef05fcb03e96.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*29PBSsI88Z9uMuxke-me3A.png"/></div></div></figure><p id="46d3" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">在训练架构时，对于每个时期，我们固定三元组的数量，并且对于每个三元组:</p><ul class=""><li id="5948" class="nq nr jj la b lb lc le lf lh ns ll nt lp nu lt nv nw nx ny bi translated">我们随机选择同一类别的两个图像(锚和积极的)</li><li id="c1d6" class="nq nr jj la b lb nz le oa lh ob ll oc lp od lt nv nw nx ny bi translated">我们从另一个类中随机选取一张图片(负面)</li></ul><p id="b402" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">一个三联体(<strong class="la jk"> <em class="nb">一个</em> </strong>，<strong class="la jk"> <em class="nb"> N </em> </strong>，<strong class="la jk"> <em class="nb"> P </em> </strong>)可以是:</p><ul class=""><li id="62e6" class="nq nr jj la b lb lc le lf lh ns ll nt lp nu lt nv nw nx ny bi translated"><strong class="la jk">易负</strong>，当∩<em class="nb">f</em>(<em class="nb">A</em>)<em class="nb">f</em>(<em class="nb">P</em>)∩+<em class="nb">α</em>∩<em class="nb">f</em>(<em class="nb">A</em>)<em class="nb">f</em>(【T75</li><li id="b45b" class="nq nr jj la b lb nz le oa lh ob ll oc lp od lt nv nw nx ny bi translated"><strong class="la jk">半硬负</strong>，当∩<em class="nb">f</em>(<em class="nb">A</em>)<em class="nb">f</em>(<em class="nb">P</em>)∩+<em class="nb">α</em>&gt;∩<em class="nb">f</em>(<em class="nb">A</em>)<em class="nb">f</em>(<em class="nb">N</em>)∩&gt;∩</li><li id="c6b5" class="nq nr jj la b lb nz le oa lh ob ll oc lp od lt nv nw nx ny bi translated"><strong class="la jk">硬负</strong>，当∩<em class="nb">f</em>(<em class="nb">A</em>)—<em class="nb">f</em>(<em class="nb">N</em>)∩&lt;∩<em class="nb">f</em>(<em class="nb">A</em>)<em class="nb">f</em>(<em class="nb">P</em>)∩</li></ul><p id="8912" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">我们通常选择聚焦在<em class="nb">半硬</em>底片上来训练神经网络。</p><h2 id="faff" class="og mh jj bd mi oh oi dn mm oj ok dp mq lh ol om ms ll on oo mu lp op oq mw or bi translated">应用:人脸识别</h2><p id="7532" class="pw-post-body-paragraph ky kz jj la b lb nf kk ld le ng kn lg lh nh lj lk ll ni ln lo lp nj lr ls lt im bi translated">暹罗网络可以用来开发一个能够识别人脸的系统。给定相机拍摄的图像，该架构将其与数据库中的所有图像进行比较。由于我们的数据库中不能有同一个人的多个图像，我们通常在足够丰富的开源图像集上训练暹罗网络来创建三胞胎。</p><figure class="lv lw lx ly gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi pd"><img src="../Images/76ea5d38cbd8a8eb695a7b29f9502773.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*LZX9-s8l6-GMSrAr-0cESw.png"/></div></div><figcaption class="jc jd gj gh gi je jf bd b be z dk">Image by Author</figcaption></figure><p id="a20a" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">卷积神经网络学习相似性函数<em class="nb"> f </em>，这是图像的嵌入。<br/>给定一张相机照片，我们将其与数据库中的每张<em class="nb">图像进行比较，从而:</em></p><ul class=""><li id="3e1d" class="nq nr jj la b lb lc le lf lh ns ll nt lp nu lt nv nw nx ny bi translated">如果<em class="nb"> d </em> ( <em class="nb"> f </em> ( <em class="nb">图像</em>，<em class="nb">图像 _ j</em>)≤<em class="nb">τ</em>，两幅图像代表同一个人</li><li id="0aca" class="nq nr jj la b lb nz le oa lh ob ll oc lp od lt nv nw nx ny bi translated">如果<em class="nb"> d </em> ( <em class="nb"> f </em> ( <em class="nb">图像</em>，<em class="nb">图像 _ j</em>)&gt;<em class="nb">τ</em>，图像是两个不同的人</li></ul><p id="b331" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">我们选择距离<em class="nb"> d </em>最接近<em class="nb">图像</em>的人脸<em class="nb"> image_j </em>。阈值<em class="nb"> τ </em>以这样一种方式选择，即例如<em class="nb">F</em>1-得分最高。</p></div><div class="ab cl lz ma hx mb" role="separator"><span class="mc bw bk md me mf"/><span class="mc bw bk md me mf"/><span class="mc bw bk md me"/></div><div class="im in io ip iq"><h1 id="7562" class="mg mh jj bd mi mj mk ml mm mn mo mp mq kp mr kq ms ks mt kt mu kv mv kw mw mx bi translated">结论</h1><p id="5f77" class="pw-post-body-paragraph ky kz jj la b lb nf kk ld le ng kn lg lh nh lj lk ll ni ln lo lp nj lr ls lt im bi translated">CNN 是图像处理中广泛使用的架构，它们能够实现更好更快的结果。最近，它们也被用于文本处理，其中网络的输入是标记的嵌入，而不是图像的像素。</p><p id="d652" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">不要犹豫，检查我以前的文章处理:</p><ul class=""><li id="3066" class="nq nr jj la b lb lc le lf lh ns ll nt lp nu lt nv nw nx ny bi translated"><a class="ae jg" href="https://medium.com/p/deep-learnings-mathematics-f52b3c4d2576" rel="noopener">深度学习的数学</a></li><li id="989a" class="nq nr jj la b lb nz le oa lh ob ll oc lp od lt nv nw nx ny bi translated"><a class="ae jg" href="https://medium.com/p/convolutional-neural-networks-mathematics-1beb3e6447c0" rel="noopener">卷积神经网络的数学</a></li><li id="8af4" class="nq nr jj la b lb nz le oa lh ob ll oc lp od lt nv nw nx ny bi translated"><a class="ae jg" rel="noopener" target="_blank" href="/recurrent-neural-networks-b7719b362c65">递归神经网络</a></li></ul></div><div class="ab cl lz ma hx mb" role="separator"><span class="mc bw bk md me mf"/><span class="mc bw bk md me mf"/><span class="mc bw bk md me"/></div><div class="im in io ip iq"><h1 id="4e43" class="mg mh jj bd mi mj mk ml mm mn mo mp mq kp mr kq ms ks mt kt mu kv mv kw mw mx bi translated">参考</h1><ul class=""><li id="b928" class="nq nr jj la b lb nf le ng lh pe ll pf lp pg lt nv nw nx ny bi translated"><a class="ae jg" href="https://fr.coursera.org/specializations/deep-learning" rel="noopener ugc nofollow" target="_blank">深度学习专业化</a>，Coursera，吴恩达</li><li id="2d37" class="nq nr jj la b lb nz le oa lh ob ll oc lp od lt nv nw nx ny bi translated"><a class="ae jg" href="http://deeploria.gforge.inria.fr/cours/cours1.html#/machine-learning-introduction" rel="noopener ugc nofollow" target="_blank">机器学习</a>，洛里亚，克里斯托夫·塞里萨拉</li></ul></div><div class="ab cl lz ma hx mb" role="separator"><span class="mc bw bk md me mf"/><span class="mc bw bk md me mf"/><span class="mc bw bk md me"/></div><div class="im in io ip iq"><p id="d88c" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><em class="nb">原载于 2019 年 2 月 15 日</em><a class="ae jg" href="https://www.ismailmebsout.com/Convolutional%20Neural%20Network%20-%20Part%202/" rel="noopener ugc nofollow" target="_blank"><em class="nb">【https://www.ismailmebsout.com</em></a><em class="nb">。</em></p></div></div>    
</body>
</html>