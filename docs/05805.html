<html>
<head>
<title>Visualizing Eigenvalues and Eigenvectors</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">可视化特征值和特征向量</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/visualizing-eigenvalues-and-eigenvectors-e2f9e3ac58d7?source=collection_archive---------8-----------------------#2019-08-24">https://towardsdatascience.com/visualizing-eigenvalues-and-eigenvectors-e2f9e3ac58d7?source=collection_archive---------8-----------------------#2019-08-24</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><p id="47ed" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">特征值和特征向量是线性代数和一般机器学习中非常重要的概念。在我之前的<a class="ae ko" rel="noopener" target="_blank" href="/pca-eigenvectors-and-eigenvalues-1f968bc6777a">文章</a>中，我已经从主成分分析的角度介绍了这些概念，并提供了实际的例子。在这篇文章中，我将更详细地阐述这些概念背后的数学原理，为我将要解释的内容提供一个几何解释。</p><p id="76da" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">为此，我将讨论以下主题:</p><ul class=""><li id="e89c" class="kp kq it js b jt ju jx jy kb kr kf ks kj kt kn ku kv kw kx bi translated">线性转换</li><li id="0d0a" class="kp kq it js b jt ky jx kz kb la kf lb kj lc kn ku kv kw kx bi translated">特征值和特征向量</li><li id="c25c" class="kp kq it js b jt ky jx kz kb la kf lb kj lc kn ku kv kw kx bi translated">代数和几何的多重性</li></ul><p id="1bd3" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">那么就从第一个话题开始吧。</p><h2 id="7fff" class="ld le it bd lf lg lh dn li lj lk dp ll kb lm ln lo kf lp lq lr kj ls lt lu lv bi translated">线性转换</h2><p id="24a2" class="pw-post-body-paragraph jq jr it js b jt lw jv jw jx lx jz ka kb ly kd ke kf lz kh ki kj ma kl km kn im bi translated">一般来说，变换是定义在定义域空间 V 上的任何函数，其输出在余定义域 W 中(其中 V 和 W 是多维空间，不一定是欧几里得的)。</p><figure class="mc md me mf gt mg gh gi paragraph-image"><div role="button" tabindex="0" class="mh mi di mj bf mk"><div class="gh gi mb"><img src="../Images/17f65c228ab071272d493d5885b7d891.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*YUr5MTZErHu9C0g327-FnA.png"/></div></div></figure><p id="7f3a" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">保留加法和标量乘法运算的变换，如下所示:</p><figure class="mc md me mf gt mg gh gi paragraph-image"><div role="button" tabindex="0" class="mh mi di mj bf mk"><div class="gh gi mn"><img src="../Images/4a45b93ebd6498cec004f1319d6aa73f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Y-hQC2i2pySRrs9UwEudsg.png"/></div></div></figure><p id="11a0" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">叫做线性变换，从现在开始我们称之为 t。</p><p id="1a9e" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">让我们考虑下面的两个数值例子来清楚地了解它。假设我们有一个定义在 R2 上的变换 T，输出为 R:</p><figure class="mc md me mf gt mg gh gi paragraph-image"><div class="gh gi mo"><img src="../Images/6fec677da5f26dea3befc848227273de.png" data-original-src="https://miro.medium.com/v2/resize:fit:1232/format:webp/1*dU1Yi4F6wKmOGpNWr4JQ_g.png"/></div></figure><p id="e3e3" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">如你所见，这种转换不是线性的，因为它不保持可加性。这个怎么样？</p><figure class="mc md me mf gt mg gh gi paragraph-image"><div role="button" tabindex="0" class="mh mi di mj bf mk"><div class="gh gi mp"><img src="../Images/9a08a2d0326972c706020f2e77903edf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*S_NBPqdYbtRNVlvtJdd5PA.png"/></div></div></figure><p id="a22a" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">此外:</p><figure class="mc md me mf gt mg gh gi paragraph-image"><div class="gh gi mq"><img src="../Images/636e4ca567c537cb14b504c7d28051f3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1314/format:webp/1*_2FdRqaXBiCR_ip_szIBkA.png"/></div></figure><p id="6d90" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">如你所见，加法和标量乘法被保留，因此转换是线性的。值得注意的是，从 R2 到 R 的唯一线性变换是那些看起来像 w=ax+by 的变换，因此是域向量分量的线性组合。</p><p id="1b61" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">表示定理给出了线性系统的一个非常重要的性质，表示线性变换可以表示如下:</p><figure class="mc md me mf gt mg gh gi paragraph-image"><div class="gh gi mr"><img src="../Images/286a01a36ce18601e3d2702c7ffad4be.png" data-original-src="https://miro.medium.com/v2/resize:fit:982/format:webp/1*oXSfi1NNqY8ZPZIaHOqMrw.png"/></div></figure><p id="5748" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">其中 A 是所谓的表示矩阵。我们将使用这个公式，因为它更紧凑，更方便。</p><p id="69f9" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">现在，每一个变换都可能影响一个向量的方向和范围(关于多维空间中向量形状的更清楚的解释，你可以在这里阅读我以前的文章<a class="ae ko" rel="noopener" target="_blank" href="/the-geometric-interpretation-of-3d-lines-and-planes-e67b51351bfd"/>)。然而，给定一个变换 T，存在一类非常有趣的向量，它们只在外延上受变换的影响，因为方向保持不变。具有该属性的通用向量<strong class="js iu"> v </strong>是这样的:</p><figure class="mc md me mf gt mg gh gi paragraph-image"><div class="gh gi ms"><img src="../Images/5a0ee349b636bd8898fc38a33862e243.png" data-original-src="https://miro.medium.com/v2/resize:fit:354/format:webp/1*xfs4RwOGglErRFdaysKtNQ.png"/></div></figure><p id="cc21" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">其中<em class="mt">λ</em>是扩展因子。那些向量被称为特征向量，并且与它们相关联的值被称为特征值。</p><h2 id="c791" class="ld le it bd lf lg lh dn li lj lk dp ll kb lm ln lo kf lp lq lr kj ls lt lu lv bi translated">特征值和特征向量</h2><p id="2477" class="pw-post-body-paragraph jq jr it js b jt lw jv jw jx lx jz ka kb ly kd ke kf lz kh ki kj ma kl km kn im bi translated">正如所预料的，特征向量是那些一旦通过固定的 T 变换其方向保持不变的向量，而特征值是那些与它们相关的扩张因子的值。</p><p id="293d" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">更准确地说，特征向量是不平凡的向量，因此不同于<strong class="js iu"> 0 </strong>。那是因为上面的等式总是至少有一个解，就是其中<strong class="js iu"> v=0 </strong>的平凡解。</p><p id="0736" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">在特征向量和特征值不同于平凡向量的情况下，如何找到我们的特征向量和特征值？为此，让我们用表示定理来重新构造我们的线性系统:</p><figure class="mc md me mf gt mg gh gi paragraph-image"><div role="button" tabindex="0" class="mh mi di mj bf mk"><div class="gh gi mu"><img src="../Images/43c87f8bfd862e6bc60d7f22358bf151.png" data-original-src="https://miro.medium.com/v2/resize:fit:1276/format:webp/1*XYcehGnf3rfbOpJp1PInog.png"/></div></div></figure><p id="fd25" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">正如预期的那样，这个系统至少有一个解，这是一个平凡的解。因此，我们想要找到矩阵的行列式(A-<em class="mt">λ</em>* I)等于零的那些λ值(否则，由于克莱姆定理，这将意味着系统有 1 个唯一解)。</p><p id="0439" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">让我们来设定我们的等式:</p><figure class="mc md me mf gt mg gh gi paragraph-image"><div class="gh gi mv"><img src="../Images/cd284e441028b08c37b78533efb9117c.png" data-original-src="https://miro.medium.com/v2/resize:fit:412/format:webp/1*bQOq8u7hSc_9LN5sOA5uBQ.png"/></div></figure><p id="9a2a" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">这个方程叫做特征方程，它的根就是特征值。再者，由于代数基本定理<em class="mt">“每一个 n 次多项式在 C(复数集)</em>中有 n 个解”，我们知道特征方程的次数将是与那个系统相关的特征值的个数。</p><p id="c956" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">让我们考虑下面的例子:</p><figure class="mc md me mf gt mg gh gi paragraph-image"><div role="button" tabindex="0" class="mh mi di mj bf mk"><div class="gh gi mw"><img src="../Images/3b0d43d408730391fc25812390cbbe87.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*GZf1-Jarwqw4I1yynbUDDA.png"/></div></div></figure><figure class="mc md me mf gt mg gh gi paragraph-image"><div class="gh gi mx"><img src="../Images/7da0ba0619177ca3e78acefd33ffa70f.png" data-original-src="https://miro.medium.com/v2/resize:fit:496/format:webp/1*11KwoIWDqTnQjl5pbMxElw.png"/></div></figure><p id="89aa" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">从特征方程中，我们导出了两个特征值 3 和-1。为了提供一个数字示例，我将找到与<em class="mt">λ</em>= 3 相关联的向量，称为特征向量(同样的推理适用于<em class="mt">λ</em>=-1)。如果我们考虑矩阵 A，这一目的的快速捷径可能是有用的。事实上，由于我们要求解的非唯一性，我们已经知道矩阵的行列式(A-lI)等于 0，因此在求解最终系统时，我们可以直接摆脱两个约束之一:</p><figure class="mc md me mf gt mg gh gi paragraph-image"><div role="button" tabindex="0" class="mh mi di mj bf mk"><div class="gh gi my"><img src="../Images/d785b5c62b01911e6d8fb53d9547652c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*cUeCG7Q36vO_RJgPTWGPBQ.png"/></div></div></figure><p id="f24d" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">让我们想象一下:</p><figure class="mc md me mf gt mg gh gi paragraph-image"><div role="button" tabindex="0" class="mh mi di mj bf mk"><div class="gh gi mz"><img src="../Images/6c2e775c7b685725c88e2ed7eccfb287.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*T8HyNV3GnAgzeD-uzikx-Q.png"/></div></div></figure><p id="67b9" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">基本上，位于该直线上的所有向量都是与特征值 3 相关联的特征向量:一旦通过 T 进行变换，它们将仅被延长/缩短，但方向不会改变。例如，考虑以下向量:</p><figure class="mc md me mf gt mg gh gi paragraph-image"><div class="gh gi na"><img src="../Images/f66fa90964ef3b94ece08abda85c916f.png" data-original-src="https://miro.medium.com/v2/resize:fit:352/format:webp/1*h-cklQnipAa9VYU_s2Gn2g.png"/></div></figure><figure class="mc md me mf gt mg gh gi paragraph-image"><div role="button" tabindex="0" class="mh mi di mj bf mk"><div class="gh gi nb"><img src="../Images/7e89f7adad483ad24938418366c94739.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*NTeCEBs5nIZpS9xRxEfPIg.png"/></div></div></figure><p id="b506" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">现在让我们来转换它:</p><figure class="mc md me mf gt mg gh gi paragraph-image"><div role="button" tabindex="0" class="mh mi di mj bf mk"><div class="gh gi nc"><img src="../Images/0bce1369ab90f8188d183cadc48aeac4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1230/format:webp/1*0Vn0IZbltqX7MfyP1ztcmw.png"/></div></div></figure><figure class="mc md me mf gt mg gh gi paragraph-image"><div role="button" tabindex="0" class="mh mi di mj bf mk"><div class="gh gi nd"><img src="../Images/c64d77d7d978f5d01fc84a9962869d16.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*cYrju_-iB9IgpC6CHfB9uw.png"/></div></div></figure><p id="0555" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">如你所见，现在它的大小是原来的 3 倍，但是方向还是一样。</p><p id="d2e4" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">现在让我们转向本文的最后一个主题，即与特征值和特征向量相关的代数和几何重数。</p><h2 id="7f92" class="ld le it bd lf lg lh dn li lj lk dp ll kb lm ln lo kf lp lq lr kj ls lt lu lv bi translated">代数和几何的多重性</h2><p id="e299" class="pw-post-body-paragraph jq jr it js b jt lw jv jw jx lx jz ka kb ly kd ke kf lz kh ki kj ma kl km kn im bi translated">现在假设你有一个 n 次特征方程，但是你只找到了一个根。因此，因为次数是<em class="mt"> n </em>，所以称该根的代数重数为<em class="mt"> n </em>。让我们考虑以下两个例子:</p><figure class="mc md me mf gt mg gh gi paragraph-image"><div role="button" tabindex="0" class="mh mi di mj bf mk"><div class="gh gi ne"><img src="../Images/02f89f01685325910051cc67cba591c8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*h-s0-5hp8x6G-LQ6F9coMw.png"/></div></div></figure><p id="4167" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">在第一个例子中，我们有一个等于-2 的特征值，没有重数(因为它的幂等于 1)，而特征值-1(来自二次多项式)的重数等于 2。</p><p id="f950" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">现在的问题是:这个多重性在问题的几何方面也受到尊重吗？换句话说，一个特征值在一个解中出现的次数是否等于对应的特征空间(即相关特征向量的集合)的维数/自由度？</p><p id="6a6e" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">答案并不总是如此。每当我们有一个重数等于<em class="mt"> n </em>的特征值和一个对应的维数小于<em class="mt"> n </em>的特征空间时，我们称该λ系数为不规则的(否则，称该特征值为规则的)。</p><p id="3385" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">让我们用上面的例子直观地展示一下:</p><figure class="mc md me mf gt mg gh gi paragraph-image"><div role="button" tabindex="0" class="mh mi di mj bf mk"><div class="gh gi nf"><img src="../Images/ef00db43baeb2bdba2ef9fd903c45cc2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*mKKw6AYoqNK1eZ4K31J7ug.png"/></div></div></figure><figure class="mc md me mf gt mg gh gi paragraph-image"><div role="button" tabindex="0" class="mh mi di mj bf mk"><div class="gh gi ng"><img src="../Images/0c2e7a184118929447771891a5a77afd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*uaMOpw7pB5XEEZPAF_IsAw.png"/></div></div></figure><p id="64c5" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">正如你所看到的，即使我们有一个重数为 2 的特征值，相关的特征空间只有一维，因为它等于 y=0。</p><h2 id="6490" class="ld le it bd lf lg lh dn li lj lk dp ll kb lm ln lo kf lp lq lr kj ls lt lu lv bi translated">结论</h2><p id="cf87" class="pw-post-body-paragraph jq jr it js b jt lw jv jw jx lx jz ka kb ly kd ke kf lz kh ki kj ma kl km kn im bi translated">特征值和特征向量通常是数据科学和建模的基础。除了它们在 PCA 中的使用之外，它们还被用在谱聚类和图像压缩中。因此，记住它们的几何解释是很重要的。</p></div></div>    
</body>
</html>