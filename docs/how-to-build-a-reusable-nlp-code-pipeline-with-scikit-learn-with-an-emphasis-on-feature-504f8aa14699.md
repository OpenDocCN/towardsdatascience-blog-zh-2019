# 如何使用 Scikit-Learn 构建可重用的自定义 NLP 管道

> 原文：<https://towardsdatascience.com/how-to-build-a-reusable-nlp-code-pipeline-with-scikit-learn-with-an-emphasis-on-feature-504f8aa14699?source=collection_archive---------21----------------------->

## 重点是功能工程和培训

![](img/949032d98587e37c0938b1370b944260.png)

机器学习代码管道最重要的特征之一是可重用性。一个可重用、可共享和可扩展的管道将通过对程序流强制一致地使用直观的结构元素来确保流程和代码的完整性，并因此可以增强数据科学家的开发流程，该流程本质上是迭代的。在本文中，我将演示**如何使用 scikit-learn 从头构建一个定制的机器学习代码管道，重点是以下两个组件:**

1.  **特性化**管道，支持灵活定义和选择特性
2.  一个**训练**管道，它结合了用于后续步骤的特征化管道的输出:向量化和模型训练

这两个组件都以类似的方式利用类继承；也就是说，它们的特征在于一个底层的类结构，从这个结构中可以派生出更具体的类来解决不同种类的监督学习问题或项目需求。作为本文的一个额外收获，在第 2 节中，我将触及与继承相关的一个强大的概念，即**抽象方法**，并说明它如何使所提出的管道设计如此直观和易于使用。

# 1.特征管线

![](img/ce33c3c336bd0aaeade6b576e6a9082c.png)

一个典型的 NLP 任务需要大量的特征工程，这个过程包括为训练模型准备合适的输入数据。该步骤可能需要将输入文本数据转换成单词包表示或多维向量，或者它可能涉及编写更原始的用户定义函数来提取诸如句子长度标准偏差、主要动词之前的单词数(句法复杂性的粗略度量)、可读性分数等特征的值。在任何给定的项目中，可以选择任意数量的这种特征来训练模型或首先确定特征重要性、减少维度或进行消融研究。

为了方便、控制和灵活地选择或测试特性，你可以想象有一种**“特性库”，当你需要它们的时候，你可以从中提取你(或你的队友)曾经写过的任何特性**。这个库可以表示为下面称为`BaseFeaturizer`的类，它的每个方法都包含计算特性值的逻辑。

一旦我们在`BaseFeaturizer`中定义了这些基本方法，我们就可以派生新的类来修改这些方法或者添加新的方法。但是也许**这些派生类最重要的属性是它们可以根据它们选择/引入的特性的*数量和类型而变化。***并且该信息应该在所有派生类中以一致的方式定义，即在每个派生类的 main 方法中，我将命名为`**featurize**`。

例如，假设我们要训练一个预测文档语法复杂性的文本分类模型，将它们分为两个离散的类:“简单”和“复杂”。这项任务的两个潜在有用的语法特征是:

1.  **主要动词前的单词数**:主要动词前的文本越长，该文本的语法就越复杂(可能是因为存在从句和/或主语修饰语，如从句)
2.  **可读性**:可读性分数越高，越复杂。(例如，在此阅读 Flesch–Kincaid 可读性测试[。)](https://en.wikipedia.org/wiki/Flesch%E2%80%93Kincaid_readability_tests)

(我在这个例子中有些随意地选择了这些特征，但是有各种各样的[特征选择技术](/feature-selection-techniques-in-machine-learning-with-python-f24e7da3f36e)可以用来首先确定哪些特征是最有用的，并且只包括那些在最终训练中的特征。)

下面，`**SyntacticComplexityFeaturizer**`被定义为`BaseFeaturier`的子类，两个特性的值在`featurize`中通过调用前面在`BaseFeaturizer`中定义的函数来计算。这些值存储在每个文档的`feature_dict`中，而`featurize`返回整个文档集的特征值映射。

这里有一个`feature_dicts`的例子，在`SyntacticComplexityFeaturizer`的实例上调用`featurize`的输出。

# 2.培训渠道

![](img/e4470adae7d3a8afe36b725376aa6d78.png)

这个特征化管道的输出自然会作为下一个组件(训练管道)的输入。这两个管道在形式上是同构的，因为后者也包含一个基础设计(类),从该基础设计可以导出更具体的训练管道来满足不同的训练要求。我把这个类命名为`BaseTrainingPipeline`。**这个类的一个重要属性是它继承了** `**ABC**` **(“抽象基类”的简称)**，原因很快就会明了。

`BaseTrainingPipeline`可以用您以后可能想要访问的任何属性进行初始化，例如，`self.y_test`和`self.y_preds`(这些值适合存储用于评估目的)，以及`self.models`(所有模型都基于相同的数据进行训练)。我在`__init__`函数中定义了以下属性:

接下来，该类的 main 方法`pipeline_main`包含将输入文本首先转换为数字特征，然后转换为向量所需的最少代码，这些步骤在大多数受监督的 NLP 任务中都会重复。注意，两条管道(特征化和训练)通过该方法连接，因为该方法将`FeaturizerClass`作为参数，例如`SyntacticComplexityClass.`

1.  一旦实例化(`featurizer = FeaturizerClass()`，该对象将对数据(语料库)调用`featurize`方法，返回一个特征值映射列表(第 22–23 行)。
2.  然后可以使用`DictVectorizer`(第 31–33 行)将这个列表转换成 numpy 数组或矩阵(向量)。
3.  然后，向量`X_train`和`y_train`可用于训练任何 scikit-learn 估计器(第 39–42 行)。

为了详细说明前面的观点，`**train_model**`被定义为`BaseTrainingPipeline`的一个**抽象方法**(这使得它成为一个**抽象类**)。抽象方法可以用装饰器`@abstractmethod`来装饰，相关部分转载如下:

你可以在这里阅读更多关于抽象方法的内容，但简单来说:

> 抽象类是包含一个或多个抽象方法的类。抽象方法是声明的方法，但不包含实现。抽象类可以不被实例化，并且**需要子类为抽象方法**提供实现。Python 中抽象类的子类不需要实现父类的抽象方法。

将`train_model`定义为一个抽象方法是必要的，因为它为该方法的所有实现提供了一个公共功能，这些实现由`BaseTrainingPipeline`的子类提供。也就是说，因为我们将`train_model`定义为*基类*的一个方法，所以我们可以从同一个类中定义的另一个方法中调用它(在我们的例子中，从`pipeline_main`)，然而因为它的实现只能由*子类*提供，所以我们能够以多种不同的方式定义`train_model`。这些实现可能变化的一个方面是估计器类型。

为了使这一切更具体，考虑我从`BaseTrainingPipeline` : `**ClassificationTrainingPipeline**`和`**RegressionTrainingPipeline**`得到的两个示例训练管道。这种分离具有直观的意义，因为一个处理目标变量为分类/离散的分类器，而另一个处理目标变量为数值/连续的回归变量。**这允许我们使用相同的通用(训练)流水线来支持不同类型的监督学习问题，而无需重写上面** `**pipeline_main**` **中定义的*核心*元素和*可重复*步骤的任何部分。**注意`train_model`的实现在两种情况下有什么不同:在`ClassificationTrainingPipeline`中，`train_model`为满足特定条件的模型指定新的参数设置，即`if algorithm == "logistic_regression"`(下面的第 12-19 行)，覆盖初始化模型的原始设置。`RegressionTrainingPipeline`不包含这样的覆盖设置，尽管它肯定*可能*用于任何*其*初始化的模型。

将所有这些放在一起，我们现在可以实例化这些训练管道中的一个，它将某个特征化类作为参数:

一旦我们运行了这段代码，`__init__`属性的值将会被更新，这样我们就可以访问保存的数组，比如`y_test`和`y_preds`，以及模型本身(您可能想要保存)。此时，您可以考虑扩展培训管道，以支持其他步骤，如模型评估、指标报告和可视化。例如，您可以将如下方法添加到`RegressorTrainingPipeline`中，以在 heldout 数据集上进行预测，并保存每次迭代训练的指标报告:

在本文中，我介绍了构建可重用、可扩展的 ML 代码管道的一步一步的过程，该管道可以很容易地适应各种 NLP 问题。设计的两个核心组件——特征管道和训练管道——在它们的基本组织中相互反映，并且通过类继承和在某些情况下的抽象方法，它们能够(1)适应灵活的特征定义和选择，以及(2)为训练不同种类的监督模型(例如，分类对回归)提供通用支持。

2019 年 12 月更新:关于使用 scikit-learn 的`Pipeline`实现您的 ML 管道的替代方法，请查看以下帖子:

[](/the-triune-pipeline-for-three-major-transformers-in-nlp-18c14e20530) [## 基于 Scikit-Learn 流水线的文本特征提取

### 使用 2010 年初选辩论记录

towardsdatascience.com](/the-triune-pipeline-for-three-major-transformers-in-nlp-18c14e20530)