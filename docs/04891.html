<html>
<head>
<title>How to cluster in High Dimensions</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">如何在高维空间中聚类</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/how-to-cluster-in-high-dimensions-4ef693bacc6?source=collection_archive---------0-----------------------#2019-07-24">https://towardsdatascience.com/how-to-cluster-in-high-dimensions-4ef693bacc6?source=collection_archive---------0-----------------------#2019-07-24</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><h2 id="bc18" class="ir is it bd b dl iu iv iw ix iy iz dk ja translated" aria-label="kicker paragraph"><a class="ae ep" href="https://towardsdatascience.com/tagged/stats-ml-life-sciences" rel="noopener" target="_blank">生命科学的数理统计和机器学习</a></h2><div class=""/><div class=""><h2 id="31ae" class="pw-subtitle-paragraph jz jc it bd b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq dk translated">自动检测集群数量的方法</h2></div><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi kr"><img src="../Images/eb515b3539b9ab3a21a7ce8467644f5c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*jOHmgFW3P-bkexXJxZjz3Q.png"/></div></div><figcaption class="ld le gj gh gi lf lg bd b be z dk"><a class="ae lh" href="https://www.stratio.com/blog/graph-database-clustering-solution/" rel="noopener ugc nofollow" target="_blank">Image source</a></figcaption></figure><p id="bc1e" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">这是<a class="ae lh" href="https://towardsdatascience.com/tagged/stats-ml-life-sciences" rel="noopener" target="_blank"> <strong class="lk jd">生命科学的数理统计与机器学习</strong> </a>栏目的第三篇文章。<strong class="lk jd"> </strong>之前，我们强调了<strong class="lk jd"/><a class="ae lh" href="https://en.wikipedia.org/wiki/Single_cell_sequencing" rel="noopener ugc nofollow" target="_blank"><strong class="lk jd">scRNAseq</strong></a>是<a class="ae lh" rel="noopener" target="_blank" href="/do-we-have-big-data-in-life-sciences-c6c4e9f8645c">有前途的大数据资源</a>，讨论了<strong class="lk jd"> tSNE </strong>是 scrna seq 的中心降维技术，并学习了<a class="ae lh" rel="noopener" target="_blank" href="/how-to-tune-hyperparameters-of-tsne-7c0596a18868">如何调优 tSNE </a>的超参数。tSNE 应用于 scRNAseq 数据后的下一步是进行<strong class="lk jd">聚类分析</strong>，以检测细胞群之间的边界。</p><p id="79a6" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">然而，聚类同时受到算法的<strong class="lk jd">限制和<a class="ae lh" href="https://en.wikipedia.org/wiki/Curse_of_dimensionality" rel="noopener ugc nofollow" target="_blank"> <strong class="lk jd">维数灾难</strong> </a>的影响，这经常导致 tSNE 图的视觉解释和聚类分析输出之间的矛盾。在本文中，我提出了一种<strong class="lk jd">自动化的</strong>方法，在 scRNAseq 数据分析的维度<strong class="lk jd"> </strong>缩减和聚类之间达成<strong class="lk jd">一致</strong>。</strong></p><h1 id="874d" class="me mf it bd mg mh mi mj mk ml mm mn mo ki mp kj mq kl mr km ms ko mt kp mu mv bi translated">聚类分析的假象</h1><p id="155b" class="pw-post-body-paragraph li lj it lk b ll mw kd ln lo mx kg lq lr my lt lu lv mz lx ly lz na mb mc md im bi translated">对 scRNAseq 进行聚类的一个问题是，我们在 tSNE 图中看到的<strong class="lk jd">与<strong class="lk jd">聚类分析报告的</strong>在聚类数量和聚类的单元分配方面存在差异。例如，我们在下图中清楚地观察到三个集群，甚至可以手动绘制集群之间的边界。然而，运行聚类算法可能会导致诸如<strong class="lk jd">错误的聚类数</strong>或<strong class="lk jd">错误的单元分配给聚类</strong>之类的假象，即当一个均匀的聚类碰巧被算法分割成多个块时。</strong></p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi nb"><img src="../Images/6d3b50f433d989600efff6e0501a529e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*VCxbGPnNKBbGoHa5vdca7g.png"/></div></div><figcaption class="ld le gj gh gi lf lg bd b be z dk">Results of clustering contradict our visual interpretation, <a class="ae lh" href="https://scikit-learn.org/stable/auto_examples/cluster/plot_kmeans_assumptions.html" rel="noopener ugc nofollow" target="_blank">image source</a></figcaption></figure><p id="78cb" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">此外，由于聚类算法缺乏鲁棒性，试图复制科学论文的结果可能会令人困惑。例如，使用来自<a class="ae lh" href="https://www.cell.com/cell-stem-cell/fulltext/S1934-5909(15)00418-X?_returnURL=https%3A%2F%2Flinkinghub.elsevier.com%2Fretrieve%2Fpii%2FS193459091500418X%3Fshowall%3Dtrue" rel="noopener ugc nofollow" target="_blank"> Kolodziejczyk 等人的数据，细胞干细胞 2015 </a>、<strong class="lk jd">八个集群</strong>在 tSNE 图中可见，然而本文中使用的聚类算法似乎只检测到<strong class="lk jd">三个集群</strong>。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi nc"><img src="../Images/d2dffafd37661191e90f7e64e9d7f391.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*jypimCJwDHZX9J6BIAz40w.png"/></div></div><figcaption class="ld le gj gh gi lf lg bd b be z dk">Contradiction between tSNE (left) and clustering (right) from <a class="ae lh" href="https://www.cell.com/cell-stem-cell/fulltext/S1934-5909(15)00418-X?_returnURL=https%3A%2F%2Flinkinghub.elsevier.com%2Fretrieve%2Fpii%2FS193459091500418X%3Fshowall%3Dtrue" rel="noopener ugc nofollow" target="_blank">Kolodziejczyk et al., Cell Stem Cell 2015</a></figcaption></figure><p id="90c9" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">降维和聚类之间的矛盾具有双重性。一方面，由于<a class="ae lh" href="https://en.wikipedia.org/wiki/Curse_of_dimensionality" rel="noopener ugc nofollow" target="_blank">维数灾难</a>，在高维 scRNAseq 空间中定义数据点之间的距离是出了名的困难；另一方面，聚类算法通常使用理想化的<strong class="lk jd">假设，而这些假设对于现实世界的数据来说</strong>并不成立。</p><h1 id="5eb8" class="me mf it bd mg mh mi mj mk ml mm mn mo ki mp kj mq kl mr km ms ko mt kp mu mv bi translated">高维空间中的欧氏距离突变</h1><p id="a4f5" class="pw-post-body-paragraph li lj it lk b ll mw kd ln lo mx kg lq lr my lt lu lv mz lx ly lz na mb mc md im bi translated">高维数学是一个活跃的研究领域，我将为这个主题专门写一篇文章。高维空间中会出现很多怪异的现象。其中之一是数据点和坐标系原点之间的距离随着维数 d 的平方根增长。这可以被视为<strong class="lk jd">数据点耗尽中心，并集中在<a class="ae lh" href="https://en.wikipedia.org/wiki/Volume_of_an_n-ball" rel="noopener ugc nofollow" target="_blank"> n 维球</a>的壳</strong>中。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi nd"><img src="../Images/ed5a03ade4a8bf567261bf2c40456076.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*J3nATcT6JqXybtYqoTiTdg.png"/></div></div><figcaption class="ld le gj gh gi lf lg bd b be z dk">Data points occupy the surface and deplete the center of the n-ball in high dimensions, <a class="ae lh" href="https://www.oreilly.com/learning/an-illustrated-introduction-to-the-t-sne-algorithm" rel="noopener ugc nofollow" target="_blank">image source</a></figcaption></figure><p id="6442" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">因此，数据点之间的平均距离发散并失去其意义，进而导致欧几里德距离的<strong class="lk jd">发散，欧几里德距离是用于聚类的最常见距离。<a class="ae lh" href="https://en.wikipedia.org/wiki/Taxicab_geometry" rel="noopener ugc nofollow" target="_blank">曼哈顿距离</a>对于 scRNAseq 来说是更好的选择，但是它在高维度上也没有完全的帮助。</strong></p><h1 id="1465" class="me mf it bd mg mh mi mj mk ml mm mn mo ki mp kj mq kl mr km ms ko mt kp mu mv bi translated">聚类方法的假设和限制</h1><p id="97ea" class="pw-post-body-paragraph li lj it lk b ll mw kd ln lo mx kg lq lr my lt lu lv mz lx ly lz na mb mc md im bi translated">尽管维数灾难是 scRNAseq 聚类分析的主要障碍，但由于其内部假设和限制，许多聚类算法即使在低维中也可能表现不佳<strong class="lk jd">。所有的聚类方法大致可以分为四组:</strong></p><ol class=""><li id="41fe" class="ne nf it lk b ll lm lo lp lr ng lv nh lz ni md nj nk nl nm bi translated">分层聚类</li><li id="c9ff" class="ne nf it lk b ll nn lo no lr np lv nq lz nr md nj nk nl nm bi translated">基于质心的聚类</li><li id="9f1a" class="ne nf it lk b ll nn lo no lr np lv nq lz nr md nj nk nl nm bi translated">基于图的聚类</li><li id="ad74" class="ne nf it lk b ll nn lo no lr np lv nq lz nr md nj nk nl nm bi translated">基于密度的聚类</li></ol><p id="4340" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">Python 库 Scikit-learn 提供了一组聚类方法，并提供了一个出色的<a class="ae lh" href="https://scikit-learn.org/stable/modules/clustering.html" rel="noopener ugc nofollow" target="_blank">概述</a>，强调了它们的优缺点:</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi ns"><img src="../Images/c562e19c79956a6017af16da571ce5c9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*bBsUH7eeIpissj-R-jWiuQ.png"/></div></div><figcaption class="ld le gj gh gi lf lg bd b be z dk">Clustering methods overview at <a class="ae lh" href="https://scikit-learn.org/stable/modules/clustering.html#k-means" rel="noopener ugc nofollow" target="_blank">scikit-learn</a> Python library web-page</figcaption></figure><p id="2181" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">分层(凝聚)聚类对数据中的 <strong class="lk jd">噪声</strong>过于<strong class="lk jd">敏感。基于质心的聚类(K-means，高斯混合模型)只能处理具有球形或椭球形对称性的聚类。</strong></p><p id="6f9d" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">基于图的聚类(Spectral，<a class="ae lh" href="https://academic.oup.com/bioinformatics/article/31/12/1974/214505" rel="noopener ugc nofollow" target="_blank">SNN-克里格</a>，<a class="ae lh" href="https://satijalab.org/seurat/" rel="noopener ugc nofollow" target="_blank">修拉</a>)对于高维数据来说可能是最健壮的，因为它使用了图上的<strong class="lk jd">距离，例如共享邻居的数量，与欧氏距离相比，这在高维数据中更有意义。</strong></p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi nt"><img src="../Images/88715413baa19b8d922887545be27dab.png" data-original-src="https://miro.medium.com/v2/resize:fit:1156/format:webp/1*exUPBBaec9lCM-aevzWKqg.png"/></div><figcaption class="ld le gj gh gi lf lg bd b be z dk">Graph-based clustering uses distance on a graph: A and F have 3 shared neighbors, <a class="ae lh" href="https://file.scirp.org/Html/4-4200105_40958.htm" rel="noopener ugc nofollow" target="_blank">image source</a></figcaption></figure><p id="6de0" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">然而，为了构建图形，这种方法<strong class="lk jd">仍然</strong> <strong class="lk jd">使用欧几里德距离</strong>。此外，集群的数量必须通过“分辨率”超参数隐式指定<em class="nu">先验</em>。改变超参数可以容易地导致更少或更多的聚类，这在某种程度上是任意的，因此非常不令人满意，因为没有明显的方法来定义用于自动调整超参数的目标函数。</p><p id="8197" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">在所有聚类算法中，只有基于密度的算法(Mean-Shift、DBSCAN、OPTICS、HDBSCAN)允许<strong class="lk jd">聚类，而无需指定聚类数</strong>。这些算法通过向高密度点移动的滑动窗口来工作，即它们发现存在许多密集区域。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi nv"><img src="../Images/6f05fad550a4df7fbcb043ab98972a4e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1280/1*ppQ3DkkLNtBiOYmF_Fc2mA.gif"/></div><figcaption class="ld le gj gh gi lf lg bd b be z dk">DBSCAN clustering finds dense regions in the data, <a class="ae lh" href="http://primo.ai/index.php?title=Density-Based_Spatial_Clustering_of_Applications_with_Noise_(DBSCAN)" rel="noopener ugc nofollow" target="_blank">image source</a></figcaption></figure><p id="bf56" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">此外，这些算法与<strong class="lk jd">聚类形状无关</strong>，并且可以捕获任何拓扑结构的 scRNAseq 数据。下面我将展示如何通过最小化一个目标函数来调整算法的超参数。</p><h1 id="bae5" class="me mf it bd mg mh mi mj mk ml mm mn mo ki mp kj mq kl mr km ms ko mt kp mu mv bi translated">如何调整 HDBSCAN 的超参数</h1><p id="52f6" class="pw-post-body-paragraph li lj it lk b ll mw kd ln lo mx kg lq lr my lt lu lv mz lx ly lz na mb mc md im bi translated">聚类是一个无监督的学习问题，这意味着我们不知道基本事实(聚类的数量)，并且不能使用交叉验证来优化算法的超参数。然而，有一种方法可以自动优化 HDBSCAN 的超参数。</p><p id="cd84" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">HDBSCAN 是一种强大的基于密度的聚类算法，它 1)与聚类的形状无关，2)不需要指定聚类的数目，3)对不同密度的聚类具有鲁棒性。此外，HBDSCAN 非常有吸引力，因为它只有一个超参数<strong class="lk jd"> minPts </strong>，这是一个聚类中的最小点数。对于大型数据集来说，它的<a class="ae lh" href="https://github.com/scikit-learn-contrib/hdbscan/blob/master/notebooks/Comparing%20Clustering%20Algorithms.ipynb" rel="noopener ugc nofollow" target="_blank">速度相对较快</a>，<strong class="lk jd">检测外围小区</strong>，并为每个小区报告一个<strong class="lk jd">分配给一个集群的概率</strong>。分配到一个簇的概率低的单元部分可以用作优化 minPts 的目标函数，min pts 进而给出最优的簇数。</p><p id="5fe9" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">下面，我将继续使用<a class="ae lh" href="https://www.nature.com/articles/s41467-018-07582-3" rel="noopener ugc nofollow" target="_blank">癌症相关成纤维细胞(CAFs) </a>从<a class="ae lh" rel="noopener" target="_blank" href="/how-to-tune-hyperparameters-of-tsne-7c0596a18868">以前的帖子</a>中，我们发现了最佳的困惑(<strong class="lk jd"> optPerp </strong>)和主成分数(<strong class="lk jd"> optPC </strong>)。现在，我们将针对不同最小规模的集群，即范围从 3 到 N_pt=50 的<strong class="lk jd"> minPts </strong>，对 tSNE 维数缩减运行 HDBSCAN。对于每个 minPts，我们将分数函数计算为具有低置信度(概率&lt; 5%)分配给聚类的细胞的分数，通过分数函数的最小化，我们希望减少未分配的数据点的数量。由于内部随机性，tSNE 从运行到运行是变化的，因此为了稳健性，我们重复聚类 N_iter=50 次，并对结果进行平均。绘制分数函数与 minPts 的关系揭示了某个最小聚类大小 minPts 的明确最小值。</p><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="nw nx l"/></div></figure><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi ny"><img src="../Images/e79f624addf37cd0672358ae84d561cc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*oEUwvjdeUEV0usMJXPHqhQ.png"/></div></div></figure><p id="94cd" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">现在，在我们为我们的数据集 minPts 找到簇的最佳最小大小后，我们将使用该值在 tSNE 上运行最终的 HDBSCAN，这将为我们提供簇的数量、分配给簇的单元，以及不能确定分配给任何簇的单元，即<strong class="lk jd">外围单元</strong>。与其他算法相比，后者是一个<strong class="lk jd">优势</strong>，也是基于密度的聚类的一个特点，但是这里为了简单起见，我使用<a class="ae lh" href="https://en.wikipedia.org/wiki/K-nearest_neighbors_algorithm" rel="noopener ugc nofollow" target="_blank"> KNN </a>分类器将外围单元分类到它们最近的邻居聚类中。注意，tSNE 运行 N_tsne=50 次，最小 Kullback-Leibler 散度图被选为最终图。下面，我展示了几个 scRNAseq 数据集。</p><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="nw nx l"/></div></figure><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi nz"><img src="../Images/e12fe490c4f89a7906b09c2e7617e066.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*kG1cNk5r1SbyZKEy0f2Csg.png"/></div></div><figcaption class="ld le gj gh gi lf lg bd b be z dk">Results of HDBSCAN clustering on tSNE</figcaption></figure><p id="5ab7" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">将 HDBSCAN 应用于各种 scRNAseq 数据集的结果看起来并不太差，因为这些图是通过只提供原始表达式矩阵<strong class="lk jd">而不手动调整聚类参数</strong>获得的。该函数的代码只接受一个原始的 scRNAseq 表达式矩阵，对所有超参数进行自动优化，并返回一个带有 HDBSCAN 聚类结果的 tSNE 图，可以在 my <a class="ae lh" href="https://github.com/NikolayOskolkov/ClusteringHighDimensions/blob/master/easy_scrnaseq_tsne_cluster.R" rel="noopener ugc nofollow" target="_blank"> github </a>上找到。</p><h1 id="be74" class="me mf it bd mg mh mi mj mk ml mm mn mo ki mp kj mq kl mr km ms ko mt kp mu mv bi translated">基于 tSNE、PCs 和原始表达式矩阵的聚类</h1><p id="78ba" class="pw-post-body-paragraph li lj it lk b ll mw kd ln lo mx kg lq lr my lt lu lv mz lx ly lz na mb mc md im bi translated">由于维数灾难，在原始表达式矩阵上运行聚类可能非常具有挑战性。因此，几乎总是建议在进行聚类分析之前进行任何类型的维数缩减。这里我比较了 9 种流行的聚类算法在 CAFs 数据集上的性能:HDBSCAN(如上所述)，<a class="ae lh" href="https://en.wikipedia.org/wiki/K-means_clustering" rel="noopener ugc nofollow" target="_blank"> Kmeans </a>，<a class="ae lh" href="https://www.rdocumentation.org/packages/mclust/versions/5.4.2/topics/Mclust" rel="noopener ugc nofollow" target="_blank">高斯混合模型(GMM) </a>，<a class="ae lh" href="https://www.rdocumentation.org/packages/stats/versions/3.6.1/topics/hclust" rel="noopener ugc nofollow" target="_blank">层次聚类</a>，<a class="ae lh" href="https://www.rdocumentation.org/packages/kernlab/versions/0.9-27/topics/specc" rel="noopener ugc nofollow" target="_blank">谱聚类</a>，<a class="ae lh" href="https://bioconductor.org/packages/release/bioc/html/SC3.html" rel="noopener ugc nofollow" target="_blank"> SC3 </a>，<a class="ae lh" href="https://bioconductor.org/packages/release/bioc/vignettes/ConsensusClusterPlus/inst/doc/ConsensusClusterPlus.pdf" rel="noopener ugc nofollow" target="_blank"> Bootstrap 一致性聚类</a>，<a class="ae lh" href="https://academic.oup.com/bioinformatics/article/31/12/1974/214505" rel="noopener ugc nofollow" target="_blank">SNN-克里格</a>和<a class="ae lh" href="https://satijalab.org/seurat/" rel="noopener ugc nofollow" target="_blank">修拉</a>。事实上，在原始 CAFs 表达矩阵上运行聚类算法带来了不令人满意的结果:</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi oa"><img src="../Images/88a5ad4d86dad770728e425dd04cccb2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*e5sZ4e1nS-gSXOiG9L3Wew.png"/></div></div><figcaption class="ld le gj gh gi lf lg bd b be z dk">Clustering on raw expression matrix</figcaption></figure><p id="de39" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">虽然所有的算法都无法在原始表达式矩阵上进行聚类，但是只有<strong class="lk jd"> SC3 </strong>提供了令人惊讶的好的单元分配网络，它跨不同的算法和距离度量执行一致性聚类。现在，我们将把聚类算法应用于通过在<a class="ae lh" rel="noopener" target="_blank" href="/how-to-tune-hyperparameters-of-tsne-7c0596a18868">先前帖子</a>中置换表达式矩阵找到的<strong class="lk jd">重要 PCs </strong>。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi ob"><img src="../Images/8406179a0e20398d4022899b87539a9f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*YlaURd__fMCABh-EM7wimA.png"/></div></div></figure><p id="1115" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">现在，SC3 的表现不太好，HDBSCAN 也不完美。相反，基于修拉图的社区检测和层次聚类似乎表现最好。最后，让我们将 9 种聚类算法应用于 scRNAseq 表达数据的 tSNE 降维表示:</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi ob"><img src="../Images/ce7c112749729c57e81c1a3196c6f2cb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*OXRE_Q5DqgFVD8U2vQI4Vg.png"/></div></div></figure><p id="6e77" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">尽管 tSNE 图是 2D 维数缩减，但是诸如 K-means、高斯混合模型(GMM)、分级聚类、谱聚类、Bootsrap 一致性聚类和 SC3 的许多算法都不能正确地将细胞分配到它们的聚类。HDBSCAN 和基于图的聚类方法(修拉和 SNN-克里格)似乎表现最好。然而，后者需要手动调整超参数，由于上述自动优化程序，HDBSCAN 不需要这样做。</p><h1 id="332b" class="me mf it bd mg mh mi mj mk ml mm mn mo ki mp kj mq kl mr km ms ko mt kp mu mv bi translated">摘要</h1><p id="b9dd" class="pw-post-body-paragraph li lj it lk b ll mw kd ln lo mx kg lq lr my lt lu lv mz lx ly lz na mb mc md im bi translated">在本文中，我们已经了解到，由于聚类方法的<strong class="lk jd">维数灾难</strong>和<strong class="lk jd">限制，对<strong class="lk jd">高维度</strong> scRNAseq 数据进行聚类是具有挑战性的。令人沮丧的是，大多数聚类算法需要预先指定</strong>的<strong class="lk jd">个簇<em class="nu">个</em>，由于<strong class="lk jd">交叉验证</strong>不适用于聚类，这很难优化。然而，HDBSCAN 作为一种只有一个超参数的算法在这里很突出，该算法<strong class="lk jd">很容易通过最小化未分配单元的数量来优化</strong>。</strong></p><p id="bb41" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">在下面的评论中让我知道生命科学中的哪些分析对你来说似乎特别神秘，我会在这个专栏中尽力解答。在媒体<a class="oc od ep" href="https://medium.com/u/8570b484f56c?source=post_page-----4ef693bacc6--------------------------------" rel="noopener" target="_blank">关注我，在 Twitter @NikolayOskolkov 关注我，在</a><a class="ae lh" href="http://linkedin.com/in/nikolay-oskolkov-abb321186?source=post_page---------------------------" rel="noopener ugc nofollow" target="_blank"> Linkedin </a>关注我，在我的<a class="ae lh" href="https://github.com/NikolayOskolkov/ClusteringHighDimensions" rel="noopener ugc nofollow" target="_blank"> github </a>上查看这篇文章的代码。我计划写下一篇关于<strong class="lk jd">如何标准化你的数据，你可以在传统统计学打破的单一空间中结束</strong>，敬请关注。</p></div></div>    
</body>
</html>