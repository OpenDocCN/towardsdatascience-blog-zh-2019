<html>
<head>
<title>Applying NLP in Java, all from the command-line</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">在 Java 中应用 NLP，全部来自命令行</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/applying-nlp-in-java-all-from-the-command-line-1225dd591e80?source=collection_archive---------27-----------------------#2019-11-01">https://towardsdatascience.com/applying-nlp-in-java-all-from-the-command-line-1225dd591e80?source=collection_archive---------27-----------------------#2019-11-01</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><figure class="gl gn jr js jt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi jq"><img src="../Images/c1b95491db53efc000a0cd438cdc16f1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*z1Aqukz_R_l3BCaapwWWJw.jpeg"/></div></div><figcaption class="kb kc gj gh gi kd ke bd b be z dk"><a class="ae kf" href="https://unsplash.com/photos/ZzWsHbu2y80" rel="noopener ugc nofollow" target="_blank">Image source</a> by <a class="ae kf" href="https://unsplash.com/@hannahwrightdesigner" rel="noopener ugc nofollow" target="_blank">Hannah Wright</a></figcaption></figure><h1 id="8f26" class="kg kh it bd ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld bi translated">介绍</h1><p id="cd68" class="pw-post-body-paragraph le lf it lg b lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">我们都知道通过浏览器工作的机器学习工具和云服务，它们为我们提供了一个界面，我们可以使用它来执行日常数据分析、模型训练和评估以及其他不同程度的效率任务。</p><p id="e568" class="pw-post-body-paragraph le lf it lg b lh mc lj lk ll md ln lo lp me lr ls lt mf lv lw lx mg lz ma mb im bi translated">但是，如果您想在本地机器或组织中可用的基础设施上完成这些任务，您会怎么做呢？而且，如果这些可用的资源不能满足完成体面的端到端数据科学或机器学习任务的先决条件。这时，访问云提供商不可知的深度学习管理环境，如<a class="ae kf" href="https://valohai.com" rel="noopener ugc nofollow" target="_blank"> Valohai </a>会有所帮助。此外，我们将使用所有人都可以使用的<a class="ae kf" href="https://valohai.com/pricing/" rel="noopener ugc nofollow" target="_blank"> <strong class="lg iu">自由层</strong> </a>。</p><figure class="mi mj mk ml gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi mh"><img src="../Images/2f4dca2f6485a6575185adf0544cbb5e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*E3tRjVu5Fi5LBL9e3kbKCQ.png"/></div></div><figcaption class="kb kc gj gh gi kd ke bd b be z dk"><a class="ae kf" href="https://get.valohai.com/cs/c/?cta_guid=18d3c2db-7630-414e-bbe4-e835f2ec42cb&amp;placement_guid=ce53cbd9-210d-4576-91d8-f05ffce8e0f5&amp;portal_id=2730768&amp;canon=https%3A%2F%2Fblog.valohai.com%2Fnlp_with_dl4j_in_java_all_from_the_command-line&amp;redirect_url=APefjpG1TUcWlv-eZxsAmaxlG9rqk38vQfsLAo3VQl7OzSuw2OUIBALvYxU3A69CoabsAMcniWEMdw5b8IVb6_S31r76TRKyqUaMNuD8Adq4yCgUtW2oaic2axBV2q8uZ80cmjDK-9D6&amp;click=aeaa9976-80f2-4445-99fa-e4524f1f026b&amp;hsutk=c7a00000164d193418f2016e273067b4&amp;signature=AAH58kEvsi27jm-eKViSt0dBogTwMi0_4w&amp;utm_referrer=https%3A%2F%2Fblog.valohai.com%2F&amp;pageId=19375533141" rel="noopener ugc nofollow" target="_blank"><strong class="bd mm">Create a free account</strong></a></figcaption></figure><p id="7b2a" class="pw-post-body-paragraph le lf it lg b lh mc lj lk ll md ln lo lp me lr ls lt mf lv lw lx mg lz ma mb im bi translated">我们将执行构建 Java 应用程序的任务，然后使用它训练和评估 NLP 模型，我们将从命令行界面完成所有这些工作，减少与可用 web 界面的交互，基本上这将是一个端到端的过程，一直到训练、保存和评估 NLP 模型。我们不需要太担心设置、配置或管理任何环境。</p><h1 id="2035" class="kg kh it bd ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld bi translated">目的或目标</h1><p id="294a" class="pw-post-body-paragraph le lf it lg b lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">在这篇文章中，我们将学习做一系列的事情，涵盖不同层次的抽象(没有特定的顺序):</p><ul class=""><li id="bf3d" class="mn mo it lg b lh mc ll md lp mp lt mq lx mr mb ms mt mu mv bi translated">如何在本地机器上构建和运行 NLP 模型？</li><li id="d03b" class="mn mo it lg b lh mw ll mx lp my lt mz lx na mb ms mt mu mv bi translated">如何在云上构建和运行 NLP 模型？</li><li id="cc86" class="mn mo it lg b lh mw ll mx lp my lt mz lx na mb ms mt mu mv bi translated">如何构建运行在 CPU 或 GPU 上的 NLP Java 应用？</li><li id="d957" class="mn mo it lg b lh mw ll mx lp my lt mz lx na mb ms mt mu mv bi translated">大多数例子都不是基于 Java 的，更不用说基于 Java 的了</li><li id="2ecd" class="mn mo it lg b lh mw ll mx lp my lt mz lx na mb ms mt mu mv bi translated">大多数例子都是基于 CPU 的，很少是基于 GPU 的</li><li id="c0fa" class="mn mo it lg b lh mw ll mx lp my lt mz lx na mb ms mt mu mv bi translated">如何根据资源(即 GPU)的存在与否来执行上述操作？</li><li id="69c9" class="mn mo it lg b lh mw ll mx lp my lt mz lx na mb ms mt mu mv bi translated">如何为 Java 搭建一个 CUDA docker 容器？</li><li id="a08f" class="mn mo it lg b lh mw ll mx lp my lt mz lx na mb ms mt mu mv bi translated">如何从命令行完成以上所有工作？</li><li id="759a" class="mn mo it lg b lh mw ll mx lp my lt mz lx na mb ms mt mu mv bi translated">通过单独的命令</li><li id="2c68" class="mn mo it lg b lh mw ll mx lp my lt mz lx na mb ms mt mu mv bi translated">通过 shell 脚本</li></ul><h1 id="5677" class="kg kh it bd ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld bi translated">我们需要什么，如何需要？</h1><p id="4c4d" class="pw-post-body-paragraph le lf it lg b lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">以下是我们开始行动所需要的:</p><ul class=""><li id="d968" class="mn mo it lg b lh mc ll md lp mp lt mq lx mr mb ms mt mu mv bi translated">可以在任何操作系统上构建和运行的 Java 应用程序</li><li id="8289" class="mn mo it lg b lh mw ll mx lp my lt mz lx na mb ms mt mu mv bi translated">允许连接到远程云服务的 CLI 工具</li><li id="e144" class="mn mo it lg b lh mw ll mx lp my lt mz lx na mb ms mt mu mv bi translated">管理上述所有内容的 shell 脚本和代码配置</li></ul><p id="f506" class="pw-post-body-paragraph le lf it lg b lh mc lj lk ll md ln lo lp me lr ls lt mf lv lw lx mg lz ma mb im bi translated">一旦我们明确了我们的目标和需求，这个任务的<em class="nb">如何</em>部分就不难了，我们将在接下来的章节中展开。</p><h1 id="843e" class="kg kh it bd ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld bi translated">面向 Java、DL4J 和 Valohai 的 NLP</h1><h1 id="bef6" class="kg kh it bd ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld bi translated">面向 Java 的 NLP:DL4J</h1><p id="0cd0" class="pw-post-body-paragraph le lf it lg b lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">我们在 GitHub 上为你捕获了这篇文章<a class="ae kf" href="https://github.com/valohai/dl4j-nlp-cuda-example" rel="noopener ugc nofollow" target="_blank">所需的所有代码和说明。以下是您熟悉该项目的步骤:</a></p><h2 id="e629" class="nc kh it bd ki nd ne dn km nf ng dp kq lp nh ni ku lt nj nk ky lx nl nm lc nn bi translated">快速启动</h2><p id="36dd" class="pw-post-body-paragraph le lf it lg b lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">为了快速开始，我们只需要做这些事情:</p><ul class=""><li id="64c8" class="mn mo it lg b lh mc ll md lp mp lt mq lx mr mb ms mt mu mv bi translated">在<a class="ae kf" href="https://valohai.com" rel="noopener ugc nofollow" target="_blank">https://valohai.com</a>开户，见<a class="ae kf" href="https://app.valohai.com/accounts/signup/" rel="noopener ugc nofollow" target="_blank">https://app.valohai.com/accounts/signup/</a></li><li id="8ab3" class="mn mo it lg b lh mw ll mx lp my lt mz lx na mb ms mt mu mv bi translated"><a class="ae kf" href="https://docs.valohai.com/tutorials/quick-start-cli.html" rel="noopener ugc nofollow" target="_blank">在你的本地机器上安装 Valohai CLI </a></li><li id="e077" class="mn mo it lg b lh mw ll mx lp my lt mz lx na mb ms mt mu mv bi translated">克隆回购<a class="ae kf" href="https://github.com/valohai/dl4j-nlp-cuda-example/" rel="noopener ugc nofollow" target="_blank">https://github.com/valohai/dl4j-nlp-cuda-example/</a></li></ul><pre class="mi mj mk ml gt no np nq nr aw ns bi"><span id="05f7" class="nc kh it np b gy nt nu l nv nw">$ git clone https://github.com/valohai/dl4j-nlp-cuda-example/<br/>$ cd dl4j-nlp-cuda-example</span></pre><ul class=""><li id="0780" class="mn mo it lg b lh mc ll md lp mp lt mq lx mr mb ms mt mu mv bi translated">使用<a class="ae kf" href="https://docs.valohai.com/tutorials/quick-start-cli.html?highlight%3Dcli" rel="noopener ugc nofollow" target="_blank"> Valohai CLI </a>工具创建一个<a class="ae kf" href="https://valohai.com" rel="noopener ugc nofollow" target="_blank"> Valohai </a>项目，并为其命名</li></ul><pre class="mi mj mk ml gt no np nq nr aw ns bi"><span id="a2a3" class="nc kh it np b gy nt nu l nv nw">$ vh project create</span></pre><ul class=""><li id="60dc" class="mn mo it lg b lh mc ll md lp mp lt mq lx mr mb ms mt mu mv bi translated">在设置页面(https://app . valo hai . com/p/[your-user-id]/dl4j-NLP-cuda-example/Settings/Repository/)的存储库选项卡上，将您的<a class="ae kf" href="https://valohai.com" rel="noopener ugc nofollow" target="_blank"> Valohai </a>项目与 GitHub repo<a class="ae kf" href="https://github.com/valohai/dl4j-nlp-cuda-example/" rel="noopener ugc nofollow" target="_blank">https://github.com/valohai/dl4j-nlp-cuda-example/</a>链接起来</li></ul><pre class="mi mj mk ml gt no np nq nr aw ns bi"><span id="ea93" class="nc kh it np b gy nt nu l nv nw">$ vh project open</span><span id="428c" class="nc kh it np b gy nx nu l nv nw">### Go to the Settings page &gt; Repository tab and update the git repo address with https://github.com/valohai/dl4j-nlp-cuda-example/</span></pre><ul class=""><li id="0a2d" class="mn mo it lg b lh mc ll md lp mp lt mq lx mr mb ms mt mu mv bi translated">用来自 git repo 的最新提交更新<a class="ae kf" href="https://valohai.com" rel="noopener ugc nofollow" target="_blank"> Valohai </a>项目</li></ul><pre class="mi mj mk ml gt no np nq nr aw ns bi"><span id="1523" class="nc kh it np b gy nt nu l nv nw">$ vh project fetch</span></pre><p id="59fb" class="pw-post-body-paragraph le lf it lg b lh mc lj lk ll md ln lo lp me lr ls lt mf lv lw lx mg lz ma mb im bi translated">现在，您已经准备好开始使用从命令行执行机器学习任务的能力了。</p><p id="c7a2" class="pw-post-body-paragraph le lf it lg b lh mc lj lk ll md ln lo lp me lr ls lt mf lv lw lx mg lz ma mb im bi translated"><em class="nb">参见自述文件</em>  <em class="nb">中的</em> <a class="ae kf" href="https://github.com/valohai/dl4j-nlp-cuda-example/blob/master/README.md" rel="noopener ugc nofollow" target="_blank"> <em class="nb">高级安装和设置部分，了解我们需要在您的系统上安装和配置什么，以便在您的本地机器上或 Docker 容器中运行应用程序和实验——目前这不是这篇文章所必需的，但您可以在以后尝试。</em></a></p><h2 id="b780" class="nc kh it bd ki nd ne dn km nf ng dp kq lp nh ni ku lt nj nk ky lx nl nm lc nn bi translated">关于<a class="ae kf" href="https://docs.valohai.com/valohai-yaml/index.html" rel="noopener ugc nofollow" target="_blank"> valohai.yaml </a></h2><p id="049d" class="pw-post-body-paragraph le lf it lg b lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">您可能已经注意到，我们在 git repo 中有一个<a class="ae kf" href="https://docs.valohai.com/valohai-yaml/index.html" rel="noopener ugc nofollow" target="_blank"> valohai.yaml </a>文件，我们的<a class="ae kf" href="https://github.com/neomatrix369/dl4j-nlp-cuda-example/blob/master/valohai.yaml" rel="noopener ugc nofollow" target="_blank"> valohai.yaml </a>文件包含几个您可以使用的步骤，我们已经按它们的名称登记了它们，我们将在运行我们的步骤时使用它们:</p><ul class=""><li id="2bc6" class="mn mo it lg b lh mc ll md lp mp lt mq lx mr mb ms mt mu mv bi translated"><strong class="lg iu"> build-cpu-gpu-uberjar </strong>:在<a class="ae kf" href="https://www.google.com/url?q=https://valohai.com&amp;sa=D&amp;ust=1572263065713000" rel="noopener ugc nofollow" target="_blank"> Valohai </a>上构建我们的 Uber jar(CPU 和 gpu 两个版本)</li><li id="7149" class="mn mo it lg b lh mw ll mx lp my lt mz lx na mb ms mt mu mv bi translated"><strong class="lg iu"> train-cpu-linux </strong>:在<a class="ae kf" href="https://www.google.com/url?q=https://valohai.com&amp;sa=D&amp;ust=1572263065714000" rel="noopener ugc nofollow" target="_blank"> Valohai </a>上使用 uber jar 的 cpu 版本运行 NLP 训练</li><li id="3b25" class="mn mo it lg b lh mw ll mx lp my lt mz lx na mb ms mt mu mv bi translated"><strong class="lg iu"> train-gpu-linux </strong>:在<a class="ae kf" href="https://www.google.com/url?q=https://valohai.com&amp;sa=D&amp;ust=1572263065714000" rel="noopener ugc nofollow" target="_blank"> Valohai </a>上使用 gpu 版本的 uber jar 运行 NLP 训练</li><li id="ac98" class="mn mo it lg b lh mw ll mx lp my lt mz lx na mb ms mt mu mv bi translated"><strong class="lg iu"> evaluate-model-linux </strong>:从上述<strong class="lg iu"> train-* </strong>执行步骤之一评估经过训练的 NLP 模型</li><li id="d219" class="mn mo it lg b lh mw ll mx lp my lt mz lx na mb ms mt mu mv bi translated"><strong class="lg iu">了解您的 GPU</strong>:在任何实例上运行为了收集该实例上与 GPU/Nvidia 相关的详细信息，我们对上面的其他步骤(构建和运行步骤)运行相同的脚本</li></ul><h2 id="f575" class="nc kh it bd ki nd ne dn km nf ng dp kq lp nh ni ku lt nj nk ky lx nl nm lc nn bi translated">从命令行构建 Java 应用程序</h2><p id="8e97" class="pw-post-body-paragraph le lf it lg b lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">假设您已经设置好了，我们将从在命令提示符下在<a class="ae kf" href="https://valohai.com" rel="noopener ugc nofollow" target="_blank"> Valohai </a>平台上构建 Java 应用程序开始，这就像运行两个命令之一一样简单:</p><pre class="mi mj mk ml gt no np nq nr aw ns bi"><span id="4df7" class="nc kh it np b gy nt nu l nv nw">$ vh exec run build-cpu-gpu-uberjar [--adhoc]<br/><br/>### Run `vh exec run --help` to find out more about this command</span></pre><p id="48bf" class="pw-post-body-paragraph le lf it lg b lh mc lj lk ll md ln lo lp me lr ls lt mf lv lw lx mg lz ma mb im bi translated">您将会看到一个执行计数器的提示，它不是一个数字:</p><pre class="mi mj mk ml gt no np nq nr aw ns bi"><span id="9064" class="nc kh it np b gy nt nu l nv nw">&lt;--snipped--&gt;<br/>😼  Success! Execution #1 created. See https://app.valohai.com/p/valohai/dl4j-nlp-cuda-example/execution/016dfef8-3a72-22d4-3d9b-7f992e6ac94d/</span></pre><figure class="mi mj mk ml gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi ny"><img src="../Images/425bb36ffe766940cf9543396e264c0f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*hkMzjolCp4cdhj4s.jpg"/></div></div></figure><p id="2f35" class="pw-post-body-paragraph le lf it lg b lh mc lj lk ll md ln lo lp me lr ls lt mf lv lw lx mg lz ma mb im bi translated"><em class="nb">注意:仅当您没有使用 git repo 设置您的</em><a class="ae kf" href="https://valohai.com" rel="noopener ugc nofollow" target="_blank"><em class="nb">valo hai</em></a><em class="nb">项目或者有未保存的提交并且想要在确定配置之前进行试验时，才使用</em> <code class="fe nz oa ob np b"><em class="nb">--adhoc</em></code> <em class="nb">。</em></p><p id="7291" class="pw-post-body-paragraph le lf it lg b lh mc lj lk ll md ln lo lp me lr ls lt mf lv lw lx mg lz ma mb im bi translated">您可以通过以下方式观看处决过程:</p><pre class="mi mj mk ml gt no np nq nr aw ns bi"><span id="2534" class="nc kh it np b gy nt nu l nv nw">$ vh watch 1<br/><br/>### the parameter 1 is the counter returned by the `vh exec run build-cpu-gpu-uberjar` operation above, it is the index to refer to that execution run</span></pre><p id="651c" class="pw-post-body-paragraph le lf it lg b lh mc lj lk ll md ln lo lp me lr ls lt mf lv lw lx mg lz ma mb im bi translated">您可以看到，当执行开始时，我们或者在等待分配实例，或者控制台消息在屏幕上移动。你也可以通过网络界面看到同样的内容。</p><p id="381e" class="pw-post-body-paragraph le lf it lg b lh mc lj lk ll md ln lo lp me lr ls lt mf lv lw lx mg lz ma mb im bi translated"><em class="nb">注意:实例的可用性取决于它们的受欢迎程度以及您对它们的剩余配额，如果它们最近被使用过，则它们更有可能是下一个可用的。</em></p><figure class="mi mj mk ml gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi oc"><img src="../Images/c28e55f4782ca05844be2f4df046952a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*KSpEp59ue8DE6usA.png"/></div></div></figure><p id="f8f6" class="pw-post-body-paragraph le lf it lg b lh mc lj lk ll md ln lo lp me lr ls lt mf lv lw lx mg lz ma mb im bi translated">一旦该步骤完成，您可以看到它产生了一些工件，在<a class="ae kf" href="https://valohai.com" rel="noopener ugc nofollow" target="_blank"> Valohai </a>术语中称为输出，我们可以通过以下方式看到它们:</p><pre class="mi mj mk ml gt no np nq nr aw ns bi"><span id="b504" class="nc kh it np b gy nt nu l nv nw">$ vh outputs 1<br/><br/>### Run `vh outputs --help` to find out more about this command</span></pre><figure class="mi mj mk ml gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi od"><img src="../Images/6f2f2cf0eea5c7ba2da5efffd7b8b86d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*GjlPMTKBGFmeTkKf.png"/></div></div></figure><p id="acfc" class="pw-post-body-paragraph le lf it lg b lh mc lj lk ll md ln lo lp me lr ls lt mf lv lw lx mg lz ma mb im bi translated">在接下来的步骤中，我们需要类似于<code class="fe nz oa ob np b">datum://[....some sha like notation...]</code>的 URL。您可以看到，我们有一个日志文件，其中捕获了关于正在运行的实例的 GPU 相关信息，您可以通过以下方式下载该文件:</p><pre class="mi mj mk ml gt no np nq nr aw ns bi"><span id="b5e0" class="nc kh it np b gy nt nu l nv nw">$ vh outputs --download . --filter *.logs 1<br/><br/>### Run `vh outputs --help` to find out more about this command</span></pre><h2 id="5e12" class="nc kh it bd ki nd ne dn km nf ng dp kq lp nh ni ku lt nj nk ky lx nl nm lc nn bi translated">从命令行运行 CPU/GPU 的 NLP 训练过程</h2><p id="767d" class="pw-post-body-paragraph le lf it lg b lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">我们将使用构建的工件，即用于 CPU 和 GPU 后端的 uber jars 来运行我们的培训流程:</p><pre class="mi mj mk ml gt no np nq nr aw ns bi"><span id="c5fb" class="nc kh it np b gy nt nu l nv nw">### Running the CPU uberjar<br/>$ vh exec run train-cpu-linux --cpu-linux-uberjar=datum://016dff00-43b7-b599-0e85-23a16749146e [--adhoc]<br/><br/>### Running the GPU uberjar<br/>$ vh exec run train-gpu-linux --gpu-linux-uberjar=datum://016dff00-2095-4df7-5d9e-02cb7cd009bb [--adhoc]<br/><br/>### Note these datum:// link will vary in your case<br/>### Run `vh exec run train-cpu-linux --help` to get more details on its usage</span></pre><p id="fec6" class="pw-post-body-paragraph le lf it lg b lh mc lj lk ll md ln lo lp me lr ls lt mf lv lw lx mg lz ma mb im bi translated"><em class="nb">注:看看 Valohai CLI </em>  <em class="nb"> docs 的</em> <a class="ae kf" href="https://docs.valohai.com/valohai-cli/using-inputs.html" rel="noopener ugc nofollow" target="_blank"> <em class="nb">输入，看看如何编写如上的命令。</em></a></p><p id="0609" class="pw-post-body-paragraph le lf it lg b lh mc lj lk ll md ln lo lp me lr ls lt mf lv lw lx mg lz ma mb im bi translated">如果我们喜欢，我们可以观看这个过程，但它可能会很长，所以我们可以切换到另一个任务。</p><figure class="mi mj mk ml gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi oe"><img src="../Images/98d146a8c8f6218945adf3c662161eb8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*TAYgqS5DYEETSUg3.png"/></div></div></figure><figure class="mi mj mk ml gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi of"><img src="../Images/d38269be84e323947f264bf704326175.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*UkCOtzdlnHEbvbUk.png"/></div></div></figure><p id="f110" class="pw-post-body-paragraph le lf it lg b lh mc lj lk ll md ln lo lp me lr ls lt mf lv lw lx mg lz ma mb im bi translated">上面的执行运行结束时，将模型保存到<code class="fe nz oa ob np b">${VH_OUTPUTS}</code>文件夹中，使其能够被<a class="ae kf" href="https://valohai.com" rel="noopener ugc nofollow" target="_blank"> Valohai </a>归档。型号名称后面有后缀，以记录它们是如何生产的。</p><p id="29e4" class="pw-post-body-paragraph le lf it lg b lh mc lj lk ll md ln lo lp me lr ls lt mf lv lw lx mg lz ma mb im bi translated">在我们构建、训练或评估步骤的任何时候，我们都可以通过这样做来停止正在进行的执行(排队或运行):</p><pre class="mi mj mk ml gt no np nq nr aw ns bi"><span id="b409" class="nc kh it np b gy nt nu l nv nw">$ vh stop 3<br/>(Resolved stop to execution stop.)<br/>⌛   Stopping #3...<br/>=&gt;   {"message":"Stop signal sent"}<br/>😁  Success! Done.</span></pre><h2 id="7364" class="nc kh it bd ki nd ne dn km nf ng dp kq lp nh ni ku lt nj nk ky lx nl nm lc nn bi translated">成功训练后下载保存的模型</h2><p id="2bc8" class="pw-post-body-paragraph le lf it lg b lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">我们可以通过计数器号查询执行的<code class="fe nz oa ob np b">outputs</code>,并使用以下命令下载:</p><pre class="mi mj mk ml gt no np nq nr aw ns bi"><span id="e19f" class="nc kh it np b gy nt nu l nv nw">$ vh outputs 2<br/>$ vh outputs --download . --filter Cnn*.pb  2</span></pre><figure class="mi mj mk ml gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi og"><img src="../Images/58c91c66e01a118f918c38a483f335d7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*e0Gb5eA2l1_YZEoc.png"/></div></div></figure><p id="301d" class="pw-post-body-paragraph le lf it lg b lh mc lj lk ll md ln lo lp me lr ls lt mf lv lw lx mg lz ma mb im bi translated"><em class="nb">看你</em> <a class="ae kf" href="https://github.com/valohai/dl4j-nlp-cuda-example/blob/master/docs/running-local-machine.md#run-the-app-on-your-local-machine" rel="noopener ugc nofollow" target="_blank"> <em class="nb">如何在你的本地机器</em> </a> <em class="nb">上评估下载的模型，既有由</em><a class="ae kf" href="https://github.com/valohai/dl4j-nlp-cuda-example/blob/master/docs/running-local-machine.md#evaluating" rel="noopener ugc nofollow" target="_blank"><em class="nb">CPU</em></a><em class="nb">和</em><a class="ae kf" href="https://github.com/valohai/dl4j-nlp-cuda-example/blob/master/docs/running-local-machine.md#evaluating-1" rel="noopener ugc nofollow" target="_blank"><em class="nb">GPU</em></a><em class="nb">创建的模型基于进程(各自的妖孽 jars)。只需将下载模型的名称作为参数传递给</em> <a class="ae kf" href="https://github.com/valohai/dl4j-nlp-cuda-example/blob/master/runUberJar.sh" rel="noopener ugc nofollow" target="_blank"> <em class="nb">提供的 runner shell 脚本</em> </a> <em class="nb">。</em></p><h2 id="6a6c" class="nc kh it bd ki nd ne dn km nf ng dp kq lp nh ni ku lt nj nk ky lx nl nm lc nn bi translated">评估来自先前训练执行的保存的 NLP 模型</h2><pre class="mi mj mk ml gt no np nq nr aw ns bi"><span id="5c31" class="nc kh it np b gy nt nu l nv nw">### Running the CPU uberjar and evaluating the CPU-verion of the model<br/>$ vh exec run evaluate-model-linux --uber-jar=datum://016dff00-43b7-b599-0e85-23a16749146e --model=datum://016dff2a-a0d4-3e63-d8da-6a61a96a7ba6 [--adhoc]<br/><br/>### Running the GPU uberjar and evaluating the GPU-verion of the model<br/>$ vh exec run evaluate-model-linux --uber-jar=datum://016dff00-2095-4df7-5d9e-02cb7cd009bb --model=datum://016dff2a-a0d4-3e63-d8da-6a61a96a7ba6 [--adhoc]<br/><br/>### Note these datum:// link will vary in your case<br/>### Run `vh exec run train-cpu-linux --help` to get more details on its usage</span></pre><p id="ee7b" class="pw-post-body-paragraph le lf it lg b lh mc lj lk ll md ln lo lp me lr ls lt mf lv lw lx mg lz ma mb im bi translated">在模型评估结束时，我们得到了下面的模型评估指标和在模型上运行测试集后的混淆矩阵:</p><figure class="mi mj mk ml gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi oh"><img src="../Images/a6bc651b068c95a80b3766c1ed342759.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*6n3-watQUSmH4bIF.png"/></div></div></figure><p id="b153" class="pw-post-body-paragraph le lf it lg b lh mc lj lk ll md ln lo lp me lr ls lt mf lv lw lx mg lz ma mb im bi translated"><em class="nb">注:</em> <a class="ae kf" href="https://github.com/valohai/dl4j-nlp-cuda-example/tree/master/src/main" rel="noopener ugc nofollow" target="_blank"> <em class="nb">源代码</em> </a> <em class="nb">以行内注释的形式包含了各阶段 ML 和 NLP 相关的解释。</em></p><h2 id="c7a4" class="nc kh it bd ki nd ne dn km nf ng dp kq lp nh ni ku lt nj nk ky lx nl nm lc nn bi translated">捕获关于 Nvidia 的 GPU 和 CUDA 驱动程序的环境信息</h2><p id="b692" class="pw-post-body-paragraph le lf it lg b lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">此步骤与在云上构建和运行 Java 应用程序以及使用客户端工具远程控制和查看它的整个过程无关，尽管能够了解我们在何种系统上运行培训是有用的，特别是对于培训的 GPU 方面:</p><pre class="mi mj mk ml gt no np nq nr aw ns bi"><span id="9467" class="nc kh it np b gy nt nu l nv nw">$ vh exec run know-your-gpus [--adhoc]<br/><br/>### Run `vh exec run --help` to get more details on its usage</span></pre><h2 id="b28b" class="nc kh it bd ki nd ne dn km nf ng dp kq lp nh ni ku lt nj nk ky lx nl nm lc nn bi translated">记录你的实验</h2><ul class=""><li id="8b26" class="mn mo it lg b lh li ll lm lp oi lt oj lx ok mb ms mt mu mv bi translated">在写这篇文章的时候，我做了几个实验，并以一种有效的方式跟踪成功和失败的实验，我能够使用<a class="ae kf" href="https://valohai.com" rel="noopener ugc nofollow" target="_blank"> Valohai </a>的版本控制工具</li><li id="3ab6" class="mn mo it lg b lh mw ll mx lp my lt mz lx na mb ms mt mu mv bi translated">过滤执行</li><li id="45e0" class="mn mo it lg b lh mw ll mx lp my lt mz lx na mb ms mt mu mv bi translated">通过“令牌”搜索具体执行</li><li id="a4c4" class="mn mo it lg b lh mw ll mx lp my lt mz lx na mb ms mt mu mv bi translated">重新运行成功和失败的执行</li><li id="78c1" class="mn mo it lg b lh mw ll mx lp my lt mz lx na mb ms mt mu mv bi translated">确认执行是成功的，失败的原因是正确的</li><li id="e1e9" class="mn mo it lg b lh mw ll mx lp my lt mz lx na mb ms mt mu mv bi translated">另外，在下面的<a class="ae kf" href="https://valohai.com" rel="noopener ugc nofollow" target="_blank"> Valohai </a>平台上检查<a class="ae kf" href="https://blog.valohai.com/blog-building-a-data-catalog-for-machine-learning" rel="noopener ugc nofollow" target="_blank">数据目录</a>和<a class="ae kf" href="https://blog.valohai.com/automatic-data-provenance-for-your-ml-pipeline" rel="noopener ugc nofollow" target="_blank">数据来源</a>是我的项目的一个例子(寻找<strong class="lg iu">跟踪</strong>按钮):</li></ul><figure class="mi mj mk ml gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi ol"><img src="../Images/5f12e1cadc0e172092d8944ada8f163d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*rbyqBwINW40FOBj9.png"/></div></div></figure><figure class="mi mj mk ml gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi om"><img src="../Images/7edad7edf369cc67d8fcd4138c363319.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*eZFh6u-XZ252fKxO.png"/></div></div></figure><h2 id="fd45" class="nc kh it bd ki nd ne dn km nf ng dp kq lp nh ni ku lt nj nk ky lx nl nm lc nn bi translated">比较基于 CPU 和 GPU 的进程</h2><p id="4605" class="pw-post-body-paragraph le lf it lg b lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">我们可以从以下方面讨论基于 CPU 和 GPU 的进程之间的比较:</p><ul class=""><li id="2dfb" class="mn mo it lg b lh mc ll md lp mp lt mq lx mr mb ms mt mu mv bi translated">应用程序构建性能</li><li id="5e92" class="mn mo it lg b lh mw ll mx lp my lt mz lx na mb ms mt mu mv bi translated">模型训练速度</li><li id="f11a" class="mn mo it lg b lh mw ll mx lp my lt mz lx na mb ms mt mu mv bi translated">模型评估准确性</li></ul><p id="5bc1" class="pw-post-body-paragraph le lf it lg b lh mc lj lk ll md ln lo lp me lr ls lt mf lv lw lx mg lz ma mb im bi translated">但是我们不会在这篇文章中讨论这些话题，尽管你可以获得你需要的指标，如果你想进一步研究的话。</p><h2 id="56f0" class="nc kh it bd ki nd ne dn km nf ng dp kq lp nh ni ku lt nj nk ky lx nl nm lc nn bi translated">必要的配置文件和 shells 脚本</h2><p id="319c" class="pw-post-body-paragraph le lf it lg b lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">所有必要的脚本都可以在<a class="ae kf" href="https://github.com/valohai/dl4j-nlp-cuda-example" rel="noopener ugc nofollow" target="_blank"> GitHub repo </a>上找到，它们可以在:</p><ul class=""><li id="ef93" class="mn mo it lg b lh mc ll md lp mp lt mq lx mr mb ms mt mu mv bi translated">项目的根文件夹</li><li id="6e94" class="mn mo it lg b lh mw ll mx lp my lt mz lx na mb ms mt mu mv bi translated">docker 文件夹</li><li id="3c23" class="mn mo it lg b lh mw ll mx lp my lt mz lx na mb ms mt mu mv bi translated">资源-存档文件夹</li></ul><p id="f6dc" class="pw-post-body-paragraph le lf it lg b lh mc lj lk ll md ln lo lp me lr ls lt mf lv lw lx mg lz ma mb im bi translated">也请看看<a class="ae kf" href="https://github.com/valohai/dl4j-nlp-cuda-example/blob/master/README.md" rel="noopener ugc nofollow" target="_blank"> README.md </a>文件，了解更多关于它们的用法和其他我们在这篇文章中没有提到的信息。</p><h1 id="0581" class="kg kh it bd ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld bi translated">瓦罗海——编排</h1><p id="e850" class="pw-post-body-paragraph le lf it lg b lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">如果我们注意到上述所有任务都是通过一些不同抽象层次的工具来编排的:</p><ul class=""><li id="4a8d" class="mn mo it lg b lh mc ll md lp mp lt mq lx mr mb ms mt mu mv bi translated">docker 管理基础设施和平台级配置以及版本控制管理</li><li id="e51f" class="mn mo it lg b lh mw ll mx lp my lt mz lx na mb ms mt mu mv bi translated">java 能够在任何选择的平台上运行我们的应用</li><li id="3eb8" class="mn mo it lg b lh mw ll mx lp my lt mz lx na mb ms mt mu mv bi translated">shell 脚本能够以平台无关的方式再次运行构建和执行命令，并且能够在 MacOSX 上的 GPU 等资源缺失时进行例外处理</li><li id="e8c5" class="mn mo it lg b lh mw ll mx lp my lt mz lx na mb ms mt mu mv bi translated">客户端工具，用于连接远程云服务，即<a class="ae kf" href="https://docs.valohai.com/tutorials/quick-start-cli.html?highlight%3Dcli" rel="noopener ugc nofollow" target="_blank"> Valohai CLI </a>，并查看、控制执行和下载最终结果</li></ul><p id="68b7" class="pw-post-body-paragraph le lf it lg b lh mc lj lk ll md ln lo lp me lr ls lt mf lv lw lx mg lz ma mb im bi translated">您正在利用可用于完成各种数据和机器学习任务的工具和技术，从一个点协调您的任务。</p><figure class="mi mj mk ml gt ju gh gi paragraph-image"><div class="ab gu cl on"><img src="../Images/38e8e6bf2533b37d46ff60878d8e91b7.png" data-original-src="https://miro.medium.com/v2/0*R45wYWZ6SPo56jNh"/></div><figcaption class="kb kc gj gh gi kd ke bd b be z dk"><a class="ae kf" href="https://unsplash.com/photos/yri82tuk2TQ" rel="noopener ugc nofollow" target="_blank">Image source</a> by <a class="ae kf" href="https://unsplash.com/@mrasmuson" rel="noopener ugc nofollow" target="_blank">Mark Rasmuson</a></figcaption></figure><h1 id="5bab" class="kg kh it bd ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld bi translated">结论</h1><p id="e991" class="pw-post-body-paragraph le lf it lg b lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">我们已经看到 NLP 是一项消耗资源的任务，拥有正确的方法和工具肯定会有所帮助。来自<a class="ae kf" href="https://skymind.ai" rel="noopener ugc nofollow" target="_blank"> Skymind </a>的<a class="ae kf" href="https://deeplearning4j.org" rel="noopener ugc nofollow" target="_blank"> DeepLearning4J </a>库和<a class="ae kf" href="https://valohai.com" rel="noopener ugc nofollow" target="_blank"> Valohai </a>平台再次为我们服务。感谢两个平台的创造者。此外，我们可以看到这篇文章强调的以下好处(以及更多)。</p><h1 id="b270" class="kg kh it bd ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld bi translated">利益</h1><p id="3e9f" class="pw-post-body-paragraph le lf it lg b lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">我们通过做上述事情获得了很多东西:</p><ul class=""><li id="2535" class="mn mo it lg b lh mc ll md lp mp lt mq lx mr mb ms mt mu mv bi translated">不必担心硬件和/或软件配置和版本控制管理— <a class="ae kf" href="https://hub.docker.com/r/neomatrix369/dl4j-nlp-cuda" rel="noopener ugc nofollow" target="_blank"> docker 容器</a> FTW</li><li id="6167" class="mn mo it lg b lh mw ll mx lp my lt mz lx na mb ms mt mu mv bi translated">能够运行手动一次性构建、培训和评估任务— <a class="ae kf" href="https://docs.valohai.com/tutorials/quick-start-cli.html?highlight%3Dcli" rel="noopener ugc nofollow" target="_blank"> Valohai CLI </a>工具 FTW</li><li id="dcf2" class="mn mo it lg b lh mw ll mx lp my lt mz lx na mb ms mt mu mv bi translated">让您的团队定期自动执行任务，以便能够在远程云基础架构上运行任务— <a class="ae kf" href="https://github.com/valohai/dl4j-nlp-cuda-example/blob/master/valohai.yaml" rel="noopener ugc nofollow" target="_blank">基础架构即代码</a> FTW</li><li id="bcb9" class="mn mo it lg b lh mw ll mx lp my lt mz lx na mb ms mt mu mv bi translated">克服旧的或缓慢的机器或无法访问板载 GPU 的 Mac 的限制— <a class="ae kf" href="https://github.com/valohai/dl4j-nlp-cuda-example/tree/master/docker" rel="noopener ugc nofollow" target="_blank">支持 CUDA 的 docker 映像脚本</a> FTW</li><li id="0d12" class="mn mo it lg b lh mw ll mx lp my lt mz lx na mb ms mt mu mv bi translated">克服本地或服务器基础设施上没有足够资源的情况，并且仍然能够运行需要高吞吐量和高性能环境的实验——与云提供商无关的平台，即<a class="ae kf" href="https://docs.valohai.com/valohai-cli/using-environments.html?highlight%3Denvironment" rel="noopener ugc nofollow" target="_blank">valo hai environments</a>FTW</li><li id="c6ac" class="mn mo it lg b lh mw ll mx lp my lt mz lx na mb ms mt mu mv bi translated">运行任务，而不必等待任务完成，并且能够以经济高效的方式在远程资源上同时并行运行多个任务，这是一个与云提供商无关的平台，即<a class="ae kf" href="https://docs.valohai.com/tutorials/quick-start-cli.html?highlight%3Dcli" rel="noopener ugc nofollow" target="_blank">valo hai CLI</a><a class="ae kf" href="https://www.google.com/url?q=https://docs.valohai.com/tutorials/quick-start-cli.html?highlight%3Dcli&amp;sa=D&amp;ust=1572263065733000" rel="noopener ugc nofollow" target="_blank">T3】tool FTW</a></li><li id="6206" class="mn mo it lg b lh mw ll mx lp my lt mz lx na mb ms mt mu mv bi translated">远程查看、控制配置和执行，甚至在成功执行后下载最终结果——一个与云提供商无关的平台，即<a class="ae kf" href="https://docs.valohai.com/tutorials/quick-start-cli.html?highlight%3Dcli" rel="noopener ugc nofollow" target="_blank"> Valohai CLI </a>工具 FTW</li><li id="2b5c" class="mn mo it lg b lh mw ll mx lp my lt mz lx na mb ms mt mu mv bi translated">和许多其他你会发现自己</li></ul><h1 id="7836" class="kg kh it bd ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld bi translated">建议</h1><ul class=""><li id="75c4" class="mn mo it lg b lh li ll lm lp oi lt oj lx ok mb ms mt mu mv bi translated"><strong class="lg iu">使用提供的支持 CUDA 的 docker 容器:</strong>强烈建议不要在本地机器(基于 Linux 或 Windows)上安装 Nvidia 驱动程序或 CUDA 或 cuDNN 暂时搁置，留待以后试验</li><li id="b373" class="mn mo it lg b lh mw ll mx lp my lt mz lx na mb ms mt mu mv bi translated"><strong class="lg iu">使用提供的 shell 脚本和配置文件:</strong>尽量不要执行手动 CLI 命令，而是使用 shell 脚本来自动执行重复的任务，前提是示例是一个很好的起点，并在此基础上更进一步</li><li id="b3e3" class="mn mo it lg b lh mw ll mx lp my lt mz lx na mb ms mt mu mv bi translated"><strong class="lg iu">尝试从提供的资源中学习尽可能多的</strong>:关于 GPU、CUDA、cuDNN，并寻找更多(参见帖子底部的<strong class="lg iu">资源</strong>部分)</li><li id="2344" class="mn mo it lg b lh mw ll mx lp my lt mz lx na mb ms mt mu mv bi translated">使用版本控制和基础设施即代码系统:git 和<a class="ae kf" href="https://docs.valohai.com/valohai-yaml/index.html" rel="noopener ugc nofollow" target="_blank"> valohai.yaml </a>就是很好的例子</li></ul><p id="bed7" class="pw-post-body-paragraph le lf it lg b lh mc lj lk ll md ln lo lp me lr ls lt mf lv lw lx mg lz ma mb im bi translated">在做上述所有事情时，我感到非常高效，我的时间和资源得到了有效利用，最重要的是，我可以与他人分享，每个人都可以直接重用所有这些工作——只需<a class="ae kf" href="https://github.com/valohai/dl4j-nlp-cuda-example" rel="noopener ugc nofollow" target="_blank">克隆回购</a>和<em class="nb">就可以了</em>。</p><p id="9ca2" class="pw-post-body-paragraph le lf it lg b lh mc lj lk ll md ln lo lp me lr ls lt mf lv lw lx mg lz ma mb im bi translated">我们没有提到的，也可能是一个很好的话题，就是在未来的帖子中提到的<a class="ae kf" href="https://docs.valohai.com/core-concepts/pipelines.html?highlight%3Dpipeline" rel="noopener ugc nofollow" target="_blank">瓦罗海管道</a>！</p><h1 id="8014" class="kg kh it bd ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld bi translated">资源</h1><ul class=""><li id="829e" class="mn mo it lg b lh li ll lm lp oi lt oj lx ok mb ms mt mu mv bi translated"><a class="ae kf" href="https://github.com/valohai/dl4j-nlp-cuda-example" rel="noopener ugc nofollow" target="_blank">dl4j-NLP-cuda-GitHub 上的示例</a>项目</li><li id="bdbf" class="mn mo it lg b lh mw ll mx lp my lt mz lx na mb ms mt mu mv bi translated"><a class="ae kf" href="https://hub.docker.com/r/neomatrix369/dl4j-nlp-cuda" rel="noopener ugc nofollow" target="_blank">在<a class="ae kf" href="https://hub.docker.com/" rel="noopener ugc nofollow" target="_blank"> docker Hub </a>上启用 CUDA 的 Docker 容器</a>(使用最新标签:<a class="ae kf" href="https://hub.docker.com/layers/neomatrix369/dl4j-nlp-cuda/v0.5/images/sha256-fcfcc2dcdf00839d918a0c475c39733d777181abb1a3c34d8dea68339369b137" rel="noopener ugc nofollow" target="_blank"> v0.5 </a>)</li><li id="66ee" class="mn mo it lg b lh mw ll mx lp my lt mz lx na mb ms mt mu mv bi translated"><a class="ae kf" href="https://github.com/valohai/dl4j-nlp-cuda-example/blob/master/docs/gpu-related-resources.md" rel="noopener ugc nofollow" target="_blank"> GPU，Nvidia，CUDA 和 cuDNN </a></li><li id="5b73" class="mn mo it lg b lh mw ll mx lp my lt mz lx na mb ms mt mu mv bi translated"><a class="ae kf" href="https://github.com/neomatrix369/awesome-ai-ml-dl/" rel="noopener ugc nofollow" target="_blank">牛逼的 AI/ML/DL 资源</a></li><li id="b31d" class="mn mo it lg b lh mw ll mx lp my lt mz lx na mb ms mt mu mv bi translated"><a class="ae kf" href="https://github.com/neomatrix369/awesome-ai-ml-dl/blob/master/README-details.md#java" rel="noopener ugc nofollow" target="_blank"> Java AI/ML/DL 资源</a></li><li id="08c6" class="mn mo it lg b lh mw ll mx lp my lt mz lx na mb ms mt mu mv bi translated"><a class="ae kf" href="https://github.com/neomatrix369/awesome-ai-ml-dl/blob/master/README-details.md#deep-learning" rel="noopener ugc nofollow" target="_blank">深度学习和 DL4J 资源</a></li><li id="de44" class="mn mo it lg b lh mw ll mx lp my lt mz lx na mb ms mt mu mv bi translated">厉害了 AI/ML/DL: <a class="ae kf" href="https://github.com/neomatrix369/awesome-ai-ml-dl/tree/master/natural-language-processing#natural-language-processing-nlp" rel="noopener ugc nofollow" target="_blank"> NLP 资源</a></li><li id="2a33" class="mn mo it lg b lh mw ll mx lp my lt mz lx na mb ms mt mu mv bi translated">DL4J NLP 资源</li><li id="b19c" class="mn mo it lg b lh mw ll mx lp my lt mz lx na mb ms mt mu mv bi translated"><a class="ae kf" href="https://deeplearning4j.org/docs/latest/deeplearning4j-nlp-overview" rel="noopener ugc nofollow" target="_blank">语言处理</a></li><li id="37c8" class="mn mo it lg b lh mw ll mx lp my lt mz lx na mb ms mt mu mv bi translated"><a class="ae kf" href="https://deeplearning4j.org/docs/latest/deeplearning4j-config-gpu-cpu" rel="noopener ugc nofollow" target="_blank">用于 GPU 和 CPU 的 ND4J 后端</a></li><li id="bd7a" class="mn mo it lg b lh mw ll mx lp my lt mz lx na mb ms mt mu mv bi translated"><a class="ae kf" href="https://deeplearning4j.org/docs/latest/deeplearning4j-nlp-vocabulary-cache" rel="noopener ugc nofollow" target="_blank">Vocab 缓存如何工作</a></li><li id="5246" class="mn mo it lg b lh mw ll mx lp my lt mz lx na mb ms mt mu mv bi translated"><a class="ae kf" href="https://deeplearning4j.org/docs/latest/deeplearning4j-nlp-word2vec" rel="noopener ugc nofollow" target="_blank"> Word2Vec，Doc2vec &amp; GloVe:用于自然语言处理的神经单词嵌入</a></li><li id="c4f5" class="mn mo it lg b lh mw ll mx lp my lt mz lx na mb ms mt mu mv bi translated"><a class="ae kf" href="https://deeplearning4j.org/docs/latest/deeplearning4j-nlp-doc2vec" rel="noopener ugc nofollow" target="_blank">深度学习中的 Doc2Vec 或段落向量 4j </a></li><li id="cd29" class="mn mo it lg b lh mw ll mx lp my lt mz lx na mb ms mt mu mv bi translated"><a class="ae kf" href="https://deeplearning4j.org/docs/latest/deeplearning4j-nlp-sentence-iterator" rel="noopener ugc nofollow" target="_blank">句子迭代器</a></li><li id="eb54" class="mn mo it lg b lh mw ll mx lp my lt mz lx na mb ms mt mu mv bi translated"><a class="ae kf" href="https://deeplearning4j.org/docs/latest/deeplearning4j-nlp-tokenization" rel="noopener ugc nofollow" target="_blank">什么是标记化？</a></li><li id="5103" class="mn mo it lg b lh mw ll mx lp my lt mz lx na mb ms mt mu mv bi translated">例子</li><li id="8202" class="mn mo it lg b lh mw ll mx lp my lt mz lx na mb ms mt mu mv bi translated"><a class="ae kf" href="https://github.com/eclipse/deeplearning4j-examples/tree/master/dl4j-examples" rel="noopener ugc nofollow" target="_blank">https://github . com/eclipse/deep learning 4j-examples/tree/master/dl4j-examples</a></li><li id="acd1" class="mn mo it lg b lh mw ll mx lp my lt mz lx na mb ms mt mu mv bi translated"><a class="ae kf" href="https://github.com/eclipse/deeplearning4j/tree/master/deeplearning4j/deeplearning4j-nlp-parent" rel="noopener ugc nofollow" target="_blank">https://github . com/eclipse/deep learning 4j/tree/master/deep learning 4j/deep learning 4j-NLP-parent</a></li></ul><p id="341d" class="pw-post-body-paragraph le lf it lg b lh mc lj lk ll md ln lo lp me lr ls lt mf lv lw lx mg lz ma mb im bi translated"><strong class="lg iu">瓦罗海资源</strong></p><ul class=""><li id="2d0e" class="mn mo it lg b lh mc ll md lp mp lt mq lx mr mb ms mt mu mv bi translated"><a class="ae kf" href="https://www.valohai.com/" rel="noopener ugc nofollow" target="_blank">瓦罗海</a> | <a class="ae kf" href="https://docs.valohai.com/" rel="noopener ugc nofollow" target="_blank">文档</a> | <a class="ae kf" href="https://blogs.valohai.com/" rel="noopener ugc nofollow" target="_blank">博客</a> | <a class="ae kf" href="https://github.com/valohai" rel="noopener ugc nofollow" target="_blank"> GitHub </a> | <a class="ae kf" href="https://www.youtube.com/channel/UCiR8Fpv6jRNphaZ99PnIuFg/videos" rel="noopener ugc nofollow" target="_blank">视频</a> | <a class="ae kf" href="https://valohai.com/showcase/" rel="noopener ugc nofollow" target="_blank">展柜</a> | <a class="ae kf" href="https://github.com/neomatrix369/awesome-ai-ml-dl/blob/master/data/about-Valohai.md#valohai" rel="noopener ugc nofollow" target="_blank">关于瓦罗海</a> | <a class="ae kf" href="http://community-slack.valohai.com/" rel="noopener ugc nofollow" target="_blank">懈怠</a>|<a class="ae kf" href="https://twitter.com/@valohaiai" rel="noopener ugc nofollow" target="_blank">@瓦罗海</a></li><li id="3ebb" class="mn mo it lg b lh mw ll mx lp my lt mz lx na mb ms mt mu mv bi translated"><a class="ae kf" href="https://docs.valohai.com/search.html?q=%3Cany+topic%3E" rel="noopener ugc nofollow" target="_blank">在文档中搜索任何主题</a></li><li id="32b5" class="mn mo it lg b lh mw ll mx lp my lt mz lx na mb ms mt mu mv bi translated">关于如何使用 Valohai CLI 工具的博文:<a class="ae kf" href="https://blog.valohai.com/from-zero-to-hero-with-valohai-cli" rel="noopener ugc nofollow" target="_blank">【1】</a>|<a class="ae kf" href="https://blog.valohai.com/from-zero-to-hero-with-valohai-part-2" rel="noopener ugc nofollow" target="_blank">【2】</a></li><li id="2499" class="mn mo it lg b lh mw ll mx lp my lt mz lx na mb ms mt mu mv bi translated"><a class="ae kf" href="https://docs.valohai.com/guides/build-docker-image.html" rel="noopener ugc nofollow" target="_blank">自定义 Docker 图像</a></li></ul><p id="5121" class="pw-post-body-paragraph le lf it lg b lh mc lj lk ll md ln lo lp me lr ls lt mf lv lw lx mg lz ma mb im bi translated"><strong class="lg iu">其他资源</strong></p><ul class=""><li id="8b33" class="mn mo it lg b lh mc ll md lp mp lt mq lx mr mb ms mt mu mv bi translated"><a class="ae kf" href="https://github.com/neomatrix369/awesome-graal" rel="noopener ugc nofollow" target="_blank">牛逼的 Graal</a>|<a class="ae kf" href="https://www.graalvm.org/" rel="noopener ugc nofollow" target="_blank">graalvm.org</a></li></ul><p id="95cd" class="pw-post-body-paragraph le lf it lg b lh mc lj lk ll md ln lo lp me lr ls lt mf lv lw lx mg lz ma mb im bi translated"><strong class="lg iu">其他相关岗位</strong></p><ul class=""><li id="4c8e" class="mn mo it lg b lh mc ll md lp mp lt mq lx mr mb ms mt mu mv bi translated"><a class="ae kf" href="https://blog.valohai.com/how-to-do-deep-learning-for-java-on-the-valohai-platform" rel="noopener ugc nofollow" target="_blank">如何在 Valohai 平台上做 Java 的深度学习？</a></li><li id="0851" class="mn mo it lg b lh mw ll mx lp my lt mz lx na mb ms mt mu mv bi translated">关于如何使用 Valohai CLI 工具的博文:<a class="ae kf" href="https://blog.valohai.com/from-zero-to-hero-with-valohai-cli" rel="noopener ugc nofollow" target="_blank">【1】</a>|<a class="ae kf" href="https://blog.valohai.com/from-zero-to-hero-with-valohai-part-2" rel="noopener ugc nofollow" target="_blank">【2】</a></li></ul></div><div class="ab cl oo op hx oq" role="separator"><span class="or bw bk os ot ou"/><span class="or bw bk os ot ou"/><span class="or bw bk os ot"/></div><div class="im in io ip iq"><h1 id="0030" class="kg kh it bd ki kj ov kl km kn ow kp kq kr ox kt ku kv oy kx ky kz oz lb lc ld bi translated"><em class="pa">最初发表于</em><a class="ae kf" href="https://blog.valohai.com/nlp_with_dl4j_in_java_all_from_the_command-line?from=3oxenia9mtr6" rel="noopener ugc nofollow" target="_blank"><em class="pa">【https://blog.valohai.com】</em></a><em class="pa">。</em></h1></div></div>    
</body>
</html>