<html>
<head>
<title>Why do spectrogram-based VGGs suck?</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">为什么基于声谱图的 vgg 很烂？</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/why-spectrogram-based-vggs-suck-36ca9b5b0b40?source=collection_archive---------18-----------------------#2019-01-22">https://towardsdatascience.com/why-spectrogram-based-vggs-suck-36ca9b5b0b40?source=collection_archive---------18-----------------------#2019-01-22</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><p id="4103" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我:vgg 很烂，因为它们的计算效率很低，还因为它们是对计算机视觉架构的幼稚采用。</p><p id="3c6d" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">网上随便一个人:</strong>乔迪，你可能错了。人们大量使用 vgg！</p><figure class="km kn ko kp gt kq gh gi paragraph-image"><div role="button" tabindex="0" class="kr ks di kt bf ku"><div class="gh gi kl"><img src="../Images/d45614d50f286fe18e5ec132b796428c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*IJvxT-p5OdV0hcqMIReI6A.png"/></div></div></figure><p id="2be4" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">不需要更多的介绍，这一系列的帖子是关于:我想分享我对这场讨论的诚实想法，因为思考计算机视觉深度学习架构在音频领域的作用。</p><ul class=""><li id="5062" class="kx ky iq jp b jq jr ju jv jy kz kc la kg lb kk lc ld le lf bi translated">帖子一:<a class="ae lg" rel="noopener" target="_blank" href="/why-spectrogram-based-vggs-suck-36ca9b5b0b40">为什么基于声谱图的 vgg 很烂？</a>【本帖】</li><li id="3891" class="kx ky iq jp b jq lh ju li jy lj kc lk kg ll kk lc ld le lf bi translated">帖子二:<a class="ae lg" rel="noopener" target="_blank" href="/why-do-spectrogram-based-vggs-rock-6c533ec0235c">为什么基于声谱图的 VGGs 会摇滚？</a></li><li id="4568" class="kx ky iq jp b jq lh ju li jy lj kc lk kg ll kk lc ld le lf bi translated">帖子三:<a class="ae lg" rel="noopener" target="_blank" href="/whats-up-with-waveform-based-vggs-15ff7c3afc28">基于波形的 VGGs 是怎么回事？</a></li></ul><p id="4c4c" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">在这些帖子中，我将围绕 VGG 模型进行讨论，这是一种被音频研究人员广泛使用的计算机视觉架构。简而言之，<a class="ae lg" href="https://arxiv.org/pdf/1409.1556.pdf" rel="noopener ugc nofollow" target="_blank">vgg</a>基于一个非常小的过滤器与最大池相结合的深度堆栈(见上面的简化图)。</p><p id="394e" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">值得注意的是，这种讨论不仅影响了音乐和音频深度学习研究人员，也挑战了语音社区——语音社区似乎只关心使用计算机视觉架构的集合来减少<a class="ae lg" href="https://en.wikipedia.org/wiki/Word_error_rate" rel="noopener ugc nofollow" target="_blank"> WER </a>。</p><h1 id="b5f3" class="lm ln iq bd lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj bi translated">为什么我不喜欢基于声谱图的 vgg？</h1><h2 id="f6d6" class="mk ln iq bd lo ml mm dn ls mn mo dp lw jy mp mq ma kc mr ms me kg mt mu mi mv bi translated">我总是发现使用计算机视觉架构来解决机器听力问题是非常不令人满意的。</h2><p id="e4ca" class="pw-post-body-paragraph jn jo iq jp b jq mw js jt ju mx jw jx jy my ka kb kc mz ke kf kg na ki kj kk ij bi translated">让我觉得特别不舒服的是下面这个假设:光谱图就是图像。然而，图像具有空间意义，而光谱图的轴代表时间和频率。</p><p id="e412" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">为了清楚起见，我们是不是应该开始修改我们的简历，加入我们是研究光谱图的计算机视觉研究员？</p><p id="2725" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">也就是说，请注意，计算机视觉架构的设计考虑到了它们问题的本质:可以组合几个边来符合一个形状，可以组合几个形状来构建一个鼻子或眼睛，可以进一步组合来绘制一张脸。VGG 模型的设计就是基于这一原理，这就是为什么他们分层堆叠非常小的过滤器——因为这些过滤器可以捕捉第一层中的边缘，可以分层组合来绘制面部。但是音乐/音频游戏是关于组合形状的？我不确定。</p><p id="216c" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">自然语言处理研究人员也成功地将领域知识整合到他们的设计中。例如，通常利用一组<em class="nb"> k </em>维单词向量作为输入(每个对应于句子中的第<em class="nb"> i </em>个单词)。考虑到这个输入，并且为了学习<a class="ae lg" href="https://en.wikipedia.org/wiki/N-gram" rel="noopener ugc nofollow" target="_blank"><em class="nb">n</em>-克</a>，观察<a class="ae lg" href="https://arxiv.org/pdf/1408.5882.pdf" rel="noopener ugc nofollow" target="_blank">这些 CNN 滤波器中的任何一个跨越<em class="nb"> n </em>个单词是很常见的。我不知道有什么 VGG 网可以处理这种输入，因为它基本上没有意义。</a></p><p id="8e54" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">更不用说最近由 Hinton 等人提出的<a class="ae lg" href="http://papers.nips.cc/paper/6975-dynamic-routing-between-capsules.pdf" rel="noopener ugc nofollow" target="_blank">胶囊</a>，旨在捕捉图像中物体之间的方位和相对空间关系。通过这种方式，他们可以构建对不同视角更鲁棒的潜在表示——这显然是受人类视觉系统工作方式的启发。</p><p id="5331" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir"> <em class="nb">为什么计算机视觉和自然语言研究者都有自己的架构，而音频社区几乎没有？</em> </strong>是否有我们正在错过的研究机会？这是一个死胡同，这就是为什么人们不发表许多音频专用架构？</p><h2 id="4995" class="mk ln iq bd lo ml mm dn ls mn mo dp lw jy mp mq ma kc mr ms me kg mt mu mi mv bi translated">它不仅仅是关于模型的概念化。我们可能会遇到不必要的计算成本。</h2><p id="46f3" class="pw-post-body-paragraph jn jo iq jp b jq mw js jt ju mx jw jx jy my ka kb kc mz ke kf kg na ki kj kk ij bi translated">考虑到上述原因，计算机视觉架构使用非常小的 CNN 过滤器的堆栈是有意义的。但是，考虑到小的过滤器设置(例如，整个图像)，要看到合理的上下文，需要考虑一个相当深的模型-具有许多层，处理几个特征地图。</p><p id="0469" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">假设 GPU 中的 VRAM 是有限的，并且 VGGs 中的每个特征地图表示占用相当大的空间，那么尽可能地提高内存效率似乎并不是一个坏主意。GPU 中的 VRAM 是我们的小(也是贵)宝！</p><figure class="km kn ko kp gt kq gh gi paragraph-image"><div class="gh gi nc"><img src="../Images/8f6fc083878cd5a2b1558350851478c5.png" data-original-src="https://miro.medium.com/v2/resize:fit:800/format:webp/1*UesziJszxSzsz2ZUoQS8yw.jpeg"/></div></figure><p id="8286" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">现在让我们考虑一下音频的情况，其中一个相关的线索是音色(沿声谱图的纵轴表示)。如何在小型 CNN 滤镜设置下捕捉 timbral 轨迹？嗯，尽可能深入。请记住，每层只能扩展一个小的上下文(使用一个小的滤波器和一个小的 max-pool)，为了“看到”谱图的整个垂直轴，需要堆叠几层。</p><p id="6c2e" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">然而，具有垂直滤波器的单个 CNN 层已经可以捕获 timbral 轨迹(沿着相对较大的垂直感受野表达),而无需支付深入的存储成本。发生这种情况是因为垂直滤波器已经捕获了重要的东西:音色，并且不需要存储几个层的输出(大型特征地图)来捕获该上下文。不仅如此:利用垂直滤波器的模型所需的计算量远少于 VGG 模型，因为只需运行一个层。</p><p id="1a9c" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">请注意，一个非常简单的信号观察为一个设计提供了信息，该设计使我们的深度学习模型更加有效(在时间和空间复杂性方面)。现在，节省下来的计算能力可以用来构建更具表现力的模型！</p><p id="f3c3" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">最后，值得注意的是<a class="ae lg" href="https://arxiv.org/abs/1703.06697" rel="noopener ugc nofollow" target="_blank">最近的研究</a>表明这些带有垂直过滤器的单层 CNN 可以工作得一样好(如果不是更好的话！)比 VGGs。此外，这些垂直滤波器可以被设计成音高不变的——这正是<a class="ae lg" href="http://jordipons.me/media/CBMI16.pdf" rel="noopener ugc nofollow" target="_blank">极大地提高了模型的性能</a>。</p><p id="5d68" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir"> <em class="nb">如果有更高效更简单的音频模型存在，为什么人们还要继续使用 vgg？！</em> </strong>我会在下面的帖子里回答这个问题:为什么要基于声谱图的 VGGs 摇滚？敬请关注。</p><figure class="km kn ko kp gt kq gh gi paragraph-image"><div class="gh gi nd"><img src="../Images/6f4b3c07a46f74201dc57cec4d28593a.png" data-original-src="https://miro.medium.com/v2/resize:fit:978/format:webp/1*MAMoQpXMv57AawjXgAxKyA.png"/></div></figure></div></div>    
</body>
</html>