<html>
<head>
<title>K-Means Clustering with Math</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">k-均值聚类与数学</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/k-means-clustering-for-beginners-2dc7b2994a4?source=collection_archive---------1-----------------------#2019-05-13">https://towardsdatascience.com/k-means-clustering-for-beginners-2dc7b2994a4?source=collection_archive---------1-----------------------#2019-05-13</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="7b73" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">用于数据分析的常见无监督学习技术</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/d54a6eaa15409dd1c3dde7d22a27f4da.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*RMW1dCkork-oiUBEDgQNKA.jpeg"/></div></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk">Photo by <a class="ae kv" href="https://unsplash.com/@perrygrone?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank">Perry Grone</a> on <a class="ae kv" href="https://unsplash.com/s/photos/group?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><p id="86e0" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">当我们处理大量数据时，将数据分成逻辑组并进行分析是有意义的。我们可以在 K-Means 等算法的帮助下，使用聚类将数据分组。</p><p id="ba37" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在这篇文章中，我将尝试解决</p><p id="2e44" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">a.使聚集</p><p id="d28a" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">b.k-均值和算法的工作原理。</p><p id="8a61" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">c.选择正确的 K 值</p><h1 id="d9e3" class="ls lt iq bd lu lv lw lx ly lz ma mb mc jw md jx me jz mf ka mg kc mh kd mi mj bi translated">使聚集</h1><p id="d962" class="pw-post-body-paragraph kw kx iq ky b kz mk jr lb lc ml ju le lf mm lh li lj mn ll lm ln mo lp lq lr ij bi translated">将对象组织成组的过程，使得同一组中的数据点与同一组中的数据点相似。聚类是对象的集合，其中这些对象与另一个聚类相似和不相似。</p><h1 id="1b56" class="ls lt iq bd lu lv lw lx ly lz ma mb mc jw md jx me jz mf ka mg kc mh kd mi mj bi translated">k 均值</h1><p id="8de7" class="pw-post-body-paragraph kw kx iq ky b kz mk jr lb lc ml ju le lf mm lh li lj mn ll lm ln mo lp lq lr ij bi translated">K-Means 聚类是一种无监督学习。该算法的主要目标是在数据中寻找组，组的数量由 K 表示。这是一个迭代过程，其中每个数据点基于特征相似性被分配到 K 个组中的一个。</p><h1 id="4336" class="ls lt iq bd lu lv lw lx ly lz ma mb mc jw md jx me jz mf ka mg kc mh kd mi mj bi translated">算法</h1><p id="e38c" class="pw-post-body-paragraph kw kx iq ky b kz mk jr lb lc ml ju le lf mm lh li lj mn ll lm ln mo lp lq lr ij bi translated">K-Means 算法从 K 个质心的初始估计开始，这些质心是从数据集中随机选择的。该算法在两个步骤<em class="mp">分配数据点</em>和<em class="mp">更新质心之间迭代。</em></p><h2 id="6a97" class="mq lt iq bd lu mr ms dn ly mt mu dp mc lf mv mw me lj mx my mg ln mz na mi nb bi translated">数据分配</h2><p id="bf0b" class="pw-post-body-paragraph kw kx iq ky b kz mk jr lb lc ml ju le lf mm lh li lj mn ll lm ln mo lp lq lr ij bi translated">在该步骤中，基于平方欧几里德距离，将数据点分配给其最近的质心。让我们假设一个以 c 为质心的聚类，并根据 c，x 之间的距离将数据点 x 分配给该聚类。还有一些其他的距离度量，如曼哈顿、雅克卡和余弦，它们是根据适当的数据类型使用的。</p><h2 id="0bd8" class="mq lt iq bd lu mr ms dn ly mt mu dp mc lf mv mw me lj mx my mg ln mz na mi nb bi translated">质心更新</h2><p id="c0cf" class="pw-post-body-paragraph kw kx iq ky b kz mk jr lb lc ml ju le lf mm lh li lj mn ll lm ln mo lp lq lr ij bi translated">通过取分配给特定聚类的所有数据点的平均值来重新计算质心。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi nc"><img src="../Images/240cde475d89bcd121ae02b27ece0b78.png" data-original-src="https://miro.medium.com/v2/resize:fit:960/1*iMJN0n-sx21fjlGMiRw7zw.gif"/></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk">image by <a class="ae kv" href="https://towardsdatascience.com/@george.seif94?source=post_page-----a36d136ef68----------------------" rel="noopener" target="_blank">George Seif</a></figcaption></figure><p id="2a14" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">让我们用下面的例子来完成上面的步骤。</p><ol class=""><li id="2cc5" class="nd ne iq ky b kz la lc ld lf nf lj ng ln nh lr ni nj nk nl bi translated">考虑如下 4 个数据点 A、B、C、D</li></ol><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi nm"><img src="../Images/cdbc427730c81d3305fa5540f2f1aa40.png" data-original-src="https://miro.medium.com/v2/resize:fit:476/format:webp/1*CVXCO-6kDyfSCvuKa5uNDA.jpeg"/></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk">Observations</figcaption></figure><p id="9f3a" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">2.选择两个质心 AB 和 CD，计算如下</p><blockquote class="nn no np"><p id="bffc" class="kw kx mp ky b kz la jr lb lc ld ju le nq lg lh li nr lk ll lm ns lo lp lq lr ij bi translated">AB =，B 的平均值</p><p id="3597" class="kw kx mp ky b kz la jr lb lc ld ju le nq lg lh li nr lk ll lm ns lo lp lq lr ij bi translated">CD =、D 的平均值</p></blockquote><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi nt"><img src="../Images/1f2bae0bbb22a4f9e00f59e817053a80.png" data-original-src="https://miro.medium.com/v2/resize:fit:484/format:webp/1*NWkyExbTLaxC8c9fWhXOwg.jpeg"/></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk">Two centroids AB, CD</figcaption></figure><p id="cf6a" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">3.计算所有数据点到质心 AB，CD 的平方欧几里得距离。例如，A(2，3)和 AB (4，2)之间的距离可以由 s =(2–4)+(3–2)给出。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi nu"><img src="../Images/ee56f60f44604df89e64a7e66765006a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1264/format:webp/1*tUU4n-RL3wUgcY4DQSD56g.png"/></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk">A is very near to CD than AB</figcaption></figure><p id="7422" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">4.如果我们在图中观察，突出显示的(A，CD)之间的<em class="mp">距离是 4，小于(AB，A)的距离 5。由于点 A 靠近 CD，我们可以将 A 移动到 CD 簇。</em></p><p id="7982" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">5.到目前为止已经形成了两个集群，让我们像步骤 2 一样重新计算质心，即 B，ACD。</p><blockquote class="nn no np"><p id="5969" class="kw kx mp ky b kz la jr lb lc ld ju le nq lg lh li nr lk ll lm ns lo lp lq lr ij bi translated">ACD =、C、D 的平均值</p><p id="61aa" class="kw kx mp ky b kz la jr lb lc ld ju le nq lg lh li nr lk ll lm ns lo lp lq lr ij bi translated">B = B</p></blockquote><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi nv"><img src="../Images/13c2c7143d8105b88cfb7fa3a5513856.png" data-original-src="https://miro.medium.com/v2/resize:fit:544/format:webp/1*9KlqJoNKCd3xl1Ewkxd0fw.jpeg"/></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk">New centroids B, ACD</figcaption></figure><p id="9895" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">6.我们知道 K-Means 是迭代过程，现在我们必须计算所有点(A，B，C，D)到新质心(B，ACD)的距离，类似于步骤 3。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi nw"><img src="../Images/502b89d7147bd7354d403aea08eb37bd.png" data-original-src="https://miro.medium.com/v2/resize:fit:962/format:webp/1*aXfE3j8Db87C190TPW0LSw.jpeg"/></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk">Clusters B, ACD</figcaption></figure><p id="17b5" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">7.在上图中，我们可以看到各自的聚类值最小，即 A 离聚类 B 太远而离聚类 ACD 近。所有数据点根据它们的最小距离被分配到聚类(B，ACD)。迭代过程到此结束。</p><p id="9cf7" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">8.总之，我们从两个质心开始，以两个集群结束，K=2。</p><h1 id="2ac7" class="ls lt iq bd lu lv lw lx ly lz ma mb mc jw md jx me jz mf ka mg kc mh kd mi mj bi translated">选择 K</h1><p id="fc73" class="pw-post-body-paragraph kw kx iq ky b kz mk jr lb lc ml ju le lf mm lh li lj mn ll lm ln mo lp lq lr ij bi translated">选择 K 值的一种方法是肘法。在此方法中，我们将对 K 值范围(K= 1 到 10)运行 K 均值聚类，并计算误差平方和(SSE)。SSE 计算为数据点与其聚类质心之间的平均距离。</p><p id="0841" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">然后为每个 K 的 SSE 值绘制一个折线图，如果折线图看起来像一只手臂，那么手臂上的肘部就是最佳的 K 值。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi nx"><img src="../Images/18c5a11d4196accd93117c93d7896c3e.png" data-original-src="https://miro.medium.com/v2/resize:fit:974/format:webp/1*J47uddrKNu6hQWwALhhZqQ.png"/></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk">Choose the Best K</figcaption></figure><p id="edaa" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><em class="mp">希望你喜欢！！请对任何疑问或建议发表评论。</em></p></div></div>    
</body>
</html>