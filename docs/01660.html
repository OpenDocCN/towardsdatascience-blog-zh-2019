<html>
<head>
<title>Financial Machine Learning Part 1: Labels</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">金融机器学习第 1 部分:标签</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/financial-machine-learning-part-1-labels-7eeed050f32e?source=collection_archive---------9-----------------------#2019-03-18">https://towardsdatascience.com/financial-machine-learning-part-1-labels-7eeed050f32e?source=collection_archive---------9-----------------------#2019-03-18</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><figure class="ip iq gp gr ir is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi io"><img src="../Images/68038a79607491e003039aabd6bac072.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ZEzsHb2OmhrN1E9wdL9RPA.jpeg"/></div></div></figure><div class=""/><div class=""><h2 id="c17d" class="pw-subtitle-paragraph jy ja jb bd b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp dk translated">设置监督学习问题</h2></div><h2 id="61a5" class="kq kr jb bd ks kt ku dn kv kw kx dp ky kz la lb lc ld le lf lg lh li lj lk ll bi translated">介绍</h2><p id="12db" class="pw-post-body-paragraph lm ln jb lo b lp lq kc lr ls lt kf lu kz lv lw lx ld ly lz ma lh mb mc md me ij bi translated">在<a class="ae mf" rel="noopener" target="_blank" href="/financial-machine-learning-part-0-bars-745897d4e4ba">的上一篇文章</a>中，我们探讨了几种为金融工具收集原始数据的方法，以创建被称为棒线的观察值。在这篇文章中，我们将关注机器学习管道的下一个关键阶段——标记观察。提醒一下，机器学习中的标签表示我们想要预测的随机变量的结果。</p><p id="d730" class="pw-post-body-paragraph lm ln jb lo b lp mg kc lr ls mh kf lu kz mi lw lx ld mj lz ma lh mk mc md me ij bi translated">就像本系列的其余部分一样，这篇文章中显示的技术是基于<a class="ae mf" href="https://www.amazon.com/Advances-Financial-Machine-Learning-Marcos/dp/1119482089" rel="noopener ugc nofollow" target="_blank"> <strong class="lo jc">金融机器学习的进步</strong> </a>由<a class="ae mf" href="http://www.quantresearch.org/" rel="noopener ugc nofollow" target="_blank"> <strong class="lo jc">马科斯洛佩兹德普拉多</strong> </a>。我推荐你去看看这本书，它对这个问题有更详细的论述。话虽如此，是时候跳进水里游一游了。</p><h1 id="2f7b" class="ml kr jb bd ks mm mn mo kv mp mq mr ky kh ms ki lc kk mt kl lg kn mu ko lk mv bi translated">标记观察</h1><p id="80c5" class="pw-post-body-paragraph lm ln jb lo b lp lq kc lr ls lt kf lu kz lv lw lx ld ly lz ma lh mb mc md me ij bi translated">在金融环境中，解决监督学习问题的一个简单方法是尝试预测某个工具在未来某个固定时间范围内的价格。请注意，这是一个回归任务，即我们试图预测一个连续的随机变量。这是一个很难解决的问题，因为价格是众所周知的嘈杂和序列相关的，并且所有可能的价格值的集合在技术上是无限的。另一方面，我们可以将此视为一个分类问题—我们可以预测离散化的回报，而不是预测精确的价格。</p><p id="6d20" class="pw-post-body-paragraph lm ln jb lo b lp mg kc lr ls mh kf lu kz mi lw lx ld mj lz ma lh mk mc md me ij bi translated">大多数金融文献使用固定范围标记方法，即根据未来某个固定步数的回报来标记观察值。标签由利润和损失阈值离散化:</p><figure class="mx my mz na gt is gh gi paragraph-image"><div class="gh gi mw"><img src="../Images/e53db313ca3aabfd76386682ed1c0adb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1216/format:webp/1*frd89b50RUZGNw1EfVunMg.jpeg"/></div></figure><p id="eaa9" class="pw-post-body-paragraph lm ln jb lo b lp mg kc lr ls mh kf lu kz mi lw lx ld mj lz ma lh mk mc md me ij bi translated">这种标记方法是一个良好的开端，但它有两个可解决的问题。</p><ol class=""><li id="f305" class="nb nc jb lo b lp mg ls mh kz nd ld ne lh nf me ng nh ni nj bi translated">阈值是固定的，但波动性不是——这意味着有时我们的阈值相距太远，有时又太近。当波动性较低时(例如，在夜间交易时段)，我们将获得大部分的<em class="nk"> y= </em> 0 标签，即使低回报是可预测的且具有统计显著性。</li><li id="a20a" class="nb nc jb lo b lp nl ls nm kz nn ld no lh np me ng nh ni nj bi translated">标签是路径独立的，这意味着它只取决于地平线上的回报，而不是中间回报。这是一个问题，因为标签没有准确反映交易的现实——每个策略都有止损阈值和止盈阈值，可以提前平仓。如果中间回报触及止损阈值，我们将实现亏损，持有头寸或从中获利是不现实的。相反，如果中间回报达到获利阈值，我们将关闭它以锁定收益，即使回报为零或为负。</li></ol><p id="ac3b" class="pw-post-body-paragraph lm ln jb lo b lp mg kc lr ls mh kf lu kz mi lw lx ld mj lz ma lh mk mc md me ij bi translated"><strong class="lo jc">计算动态阈值</strong></p><p id="f710" class="pw-post-body-paragraph lm ln jb lo b lp mg kc lr ls mh kf lu kz mi lw lx ld mj lz ma lh mk mc md me ij bi translated">为了解决第一个问题，我们可以将动态阈值设置为滚动波动率的函数。我们假设在这一点上我们已经有了 OHLC 酒吧。我使用<a class="ae mf" href="https://www.bitmex.com/app/seriesGuide/XBT" rel="noopener ugc nofollow" target="_blank"> BitMex:XBT </a>的美元条，这是上一篇文章中的比特币永久互换合约——如果你是从零开始，这个<a class="ae mf" href="https://gist.github.com/maks-ivanov/e668c47addfa69e86da5a44e3f634dd5" rel="noopener ugc nofollow" target="_blank">代码片段</a>将帮助你赶上。</p><p id="2b4b" class="pw-post-body-paragraph lm ln jb lo b lp mg kc lr ls mh kf lu kz mi lw lx ld mj lz ma lh mk mc md me ij bi translated">在这里，我们将估计每小时的回报率波动，以计算利润和损失的阈值。下面你会发现一个直接来自 Lopez De Prado 的稍加修改的函数，为了清楚起见还添加了注释:</p><pre class="mx my mz na gt nq nr ns nt aw nu bi"><span id="0344" class="kq kr jb nr b gy nv nw l nx ny">def get_vol(prices, span=100, delta=pd.Timedelta(hours=1)):<br/>  # 1. compute returns of the form p[t]/p[t-1] - 1</span><span id="6a3f" class="kq kr jb nr b gy nz nw l nx ny">  # 1.1 find the timestamps of p[t-1] values<br/>  df0 = prices.index.searchsorted(prices.index - delta)<br/>  df0 = df0[df0 &gt; 0]</span><span id="32ba" class="kq kr jb nr b gy nz nw l nx ny">  # 1.2 align timestamps of p[t-1] to timestamps of p[t]<br/>  df0 = pd.Series(prices.index[df0-1],    <br/>           index=prices.index[prices.shape[0]-df0.shape[0] : ])</span><span id="feb2" class="kq kr jb nr b gy nz nw l nx ny">  # 1.3 get values by timestamps, then compute returns<br/>  df0 = prices.loc[df0.index] / prices.loc[df0.values].values - 1</span><span id="8d74" class="kq kr jb nr b gy nz nw l nx ny">  # 2. estimate rolling standard deviation<br/>  df0 = df0.ewm(span=span).std()<br/>  return df0</span></pre><p id="98c0" class="pw-post-body-paragraph lm ln jb lo b lp mg kc lr ls mh kf lu kz mi lw lx ld mj lz ma lh mk mc md me ij bi translated"><strong class="lo jc">添加路径依赖:三重屏障法</strong></p><p id="4114" class="pw-post-body-paragraph lm ln jb lo b lp mg kc lr ls mh kf lu kz mi lw lx ld mj lz ma lh mk mc md me ij bi translated">为了更好地结合假设交易策略的止损和止盈场景，我们将修改固定范围标记方法，以便它反映哪个障碍首先被触及——上限、下限或范围。因此得名:三重屏障法。</p><figure class="mx my mz na gt is gh gi paragraph-image"><div class="ab gu cl oa"><img src="../Images/af46e35e38f922520768c6c4e8e5e3bc.png" data-original-src="https://miro.medium.com/v2/format:webp/0*Gi4gkPd33iJNh6kp.png"/></div><figcaption class="ob oc gj gh gi od oe bd b be z dk"><strong class="bd of"><em class="og">Triple-Barrier Label y=0</em> | </strong>Source: quantresearch.org</figcaption></figure><p id="e40f" class="pw-post-body-paragraph lm ln jb lo b lp mg kc lr ls mh kf lu kz mi lw lx ld mj lz ma lh mk mc md me ij bi translated">标签模式定义如下:</p><p id="0792" class="pw-post-body-paragraph lm ln jb lo b lp mg kc lr ls mh kf lu kz mi lw lx ld mj lz ma lh mk mc md me ij bi translated"><em class="nk"> y= </em> 1 <em class="nk">:首先碰到顶部护栏</em></p><p id="f8d0" class="pw-post-body-paragraph lm ln jb lo b lp mg kc lr ls mh kf lu kz mi lw lx ld mj lz ma lh mk mc md me ij bi translated"><em class="nk"> y= </em> 0 <em class="nk">:先击中右侧护栏</em></p><p id="69d5" class="pw-post-body-paragraph lm ln jb lo b lp mg kc lr ls mh kf lu kz mi lw lx ld mj lz ma lh mk mc md me ij bi translated"><em class="nk"> y= </em> -1 <em class="nk">:首先碰到底部护栏</em></p><p id="921a" class="pw-post-body-paragraph lm ln jb lo b lp mg kc lr ls mh kf lu kz mi lw lx ld mj lz ma lh mk mc md me ij bi translated"><strong class="lo jc">赌的一方呢？</strong></p><p id="8a47" class="pw-post-body-paragraph lm ln jb lo b lp mg kc lr ls mh kf lu kz mi lw lx ld mj lz ma lh mk mc md me ij bi translated">上面的模式适用于只做多的策略，但是当我们同时考虑多头和空头时，事情就变得复杂了。如果我们做空，我们的盈利/亏损与价格走势相反——价格下跌时我们盈利，价格上涨时我们亏损。</p><figure class="mx my mz na gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi oh"><img src="../Images/b8fd9721a38d88f94257f7421e7381a7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*JkCVZrdUI067g0as.jpg"/></div></div><figcaption class="ob oc gj gh gi od oe bd b be z dk">“Because I was inverted” — Maverick | Top Gun</figcaption></figure><p id="4d80" class="pw-post-body-paragraph lm ln jb lo b lp mg kc lr ls mh kf lu kz mi lw lx ld mj lz ma lh mk mc md me ij bi translated">为了说明这一点，我们可以简单地将<em class="nk">侧</em>表示为长 1，短-1。因此，我们可以将我们的收益乘以边数，所以每当我们做空时，负收益变成正收益，反之亦然。实际上，如果<em class="nk">侧</em> =-1，我们翻转<em class="nk"> y </em> =1 和<em class="nk"> y </em> =-1 标签。</p><p id="711e" class="pw-post-body-paragraph lm ln jb lo b lp mg kc lr ls mh kf lu kz mi lw lx ld mj lz ma lh mk mc md me ij bi translated">让我们试着实现一下(基于 MLDP 的代码)。</p><p id="dc23" class="pw-post-body-paragraph lm ln jb lo b lp mg kc lr ls mh kf lu kz mi lw lx ld mj lz ma lh mk mc md me ij bi translated">首先，我们定义了获取视界屏障时间戳的程序:</p><pre class="mx my mz na gt nq nr ns nt aw nu bi"><span id="6ad6" class="kq kr jb nr b gy nv nw l nx ny">def get_horizons(prices, delta=pd.Timedelta(minutes=15)):<br/>    t1 = prices.index.searchsorted(prices.index + delta)<br/>    t1 = t1[t1 &lt; prices.shape[0]]<br/>    t1 = prices.index[t1]<br/>    t1 = pd.Series(t1, index=prices.index[:t1.shape[0]])<br/>    return t1</span></pre><p id="2dca" class="pw-post-body-paragraph lm ln jb lo b lp mg kc lr ls mh kf lu kz mi lw lx ld mj lz ma lh mk mc md me ij bi translated">现在我们有了我们的水平障碍，我们定义一个函数，根据前面计算的波动率估计值设置上限和下限:</p><pre class="mx my mz na gt nq nr ns nt aw nu bi"><span id="8964" class="kq kr jb nr b gy nv nw l nx ny">def get_touches(prices, events, factors=[1, 1]):<br/>  '''<br/>  events: pd dataframe with columns<br/>    t1: timestamp of the next horizon<br/>    threshold: unit height of top and bottom barriers<br/>    side: the side of each bet<br/>  factors: multipliers of the threshold to set the height of <br/>           top/bottom barriers<br/>  '''</span><span id="306c" class="kq kr jb nr b gy nz nw l nx ny">  out = events[['t1']].copy(deep=True)<br/>  if factors[0] &gt; 0: thresh_uppr = factors[0] * events['threshold']<br/>  else: thresh_uppr = pd.Series(index=events.index) # no uppr thresh<br/>  if factors[1] &gt; 0: thresh_lwr = -factors[1] * events['threshold']<br/>  else: thresh_lwr = pd.Series(index=events.index)  # no lwr thresh</span><span id="eaa4" class="kq kr jb nr b gy nz nw l nx ny">  for loc, t1 in events['t1'].iteritems():<br/>    df0=prices[loc:t1]                              # path prices<br/>    df0=(df0 / prices[loc] - 1) * events.side[loc]  # path returns<br/>    out.loc[loc, 'stop_loss'] = \<br/>      df0[df0 &lt; thresh_lwr[loc]].index.min()  # earliest stop loss<br/>    out.loc[loc, 'take_profit'] = \<br/>      df0[df0 &gt; thresh_uppr[loc]].index.min() # earliest take profit<br/>  return out</span></pre><p id="27f8" class="pw-post-body-paragraph lm ln jb lo b lp mg kc lr ls mh kf lu kz mi lw lx ld mj lz ma lh mk mc md me ij bi translated">最后，我们定义一个函数来计算标签:</p><pre class="mx my mz na gt nq nr ns nt aw nu bi"><span id="6906" class="kq kr jb nr b gy nv nw l nx ny">def get_labels(touches):<br/>  out = touches.copy(deep=True)<br/>  # pandas df.min() ignores NaN values<br/>  first_touch = touches[['stop_loss', 'take_profit']].min(axis=1)<br/>  for loc, t in first_touch.iteritems():<br/>    if pd.isnull(t):<br/>      out.loc[loc, 'label'] = 0<br/>    elif t == touches.loc[loc, 'stop_loss']: <br/>      out.loc[loc, 'label'] = -1<br/>    else:<br/>      out.loc[loc, 'label'] = 1<br/>  return out</span></pre><p id="b0a3" class="pw-post-body-paragraph lm ln jb lo b lp mg kc lr ls mh kf lu kz mi lw lx ld mj lz ma lh mk mc md me ij bi translated">将所有这些放在一起:</p><pre class="mx my mz na gt nq nr ns nt aw nu bi"><span id="8f55" class="kq kr jb nr b gy nv nw l nx ny">data_ohlc = pd.read_parquet('data_dollar_ohlc.pq')<br/>data_ohlc = \<br/>  data_ohlc.assign(threshold=get_vol(data_ohlc.close)).dropna()<br/>data_ohlc = data_ohlc.assign(t1=get_horizons(data_ohlc)).dropna()<br/>events = data_ohlc[['t1', 'threshold']] <br/>events = events.assign(side=pd.Series(1., events.index)) # long only<br/>touches = get_touches(data_ohlc.close, events, [1,1])<br/>touches = get_labels(touches)<br/>data_ohlc = data_ohlc.assign(label=touches.label)</span></pre><h1 id="ecd8" class="ml kr jb bd ks mm mn mo kv mp mq mr ky kh ms ki lc kk mt kl lg kn mu ko lk mv bi translated">元标记</h1><p id="bc66" class="pw-post-body-paragraph lm ln jb lo b lp lq kc lr ls lt kf lu kz lv lw lx ld ly lz ma lh mb mc md me ij bi translated">在概念层面上，我们的目标是在我们预计会赢的地方下注，而不是在我们预计不会赢的地方下注，这就归结为一个二元分类问题(其中失败的情况既包括下注方向错误，也包括在我们应该下注的时候根本没有下注)。下面是我们刚刚生成的标签的另一种查看方式:</p><figure class="mx my mz na gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi oi"><img src="../Images/f045a0e6a24cd346b59f39636ac78c3b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*lXZsAais5VWGjiL0VwwcUw.png"/></div></div></figure><p id="fdc3" class="pw-post-body-paragraph lm ln jb lo b lp mg kc lr ls mh kf lu kz mi lw lx ld mj lz ma lh mk mc md me ij bi translated">二进制分类问题提出了 I 型错误(假阳性)和 II 型错误(假阴性)之间的折衷。增加真阳性率通常以增加假阳性率为代价。</p><p id="3f98" class="pw-post-body-paragraph lm ln jb lo b lp mg kc lr ls mh kf lu kz mi lw lx ld mj lz ma lh mk mc md me ij bi translated">为了更正式地描述这一点，让我们首先定义:</p><p id="7890" class="pw-post-body-paragraph lm ln jb lo b lp mg kc lr ls mh kf lu kz mi lw lx ld mj lz ma lh mk mc md me ij bi translated"><em class="nk"> ŷ ∈ </em> {0，1，-1} : <em class="nk">观测的主模型预测</em></p><p id="279e" class="pw-post-body-paragraph lm ln jb lo b lp mg kc lr ls mh kf lu kz mi lw lx ld mj lz ma lh mk mc md me ij bi translated"><em class="nk"> r:观察的价格回报</em></p><p id="4469" class="pw-post-body-paragraph lm ln jb lo b lp mg kc lr ls mh kf lu kz mi lw lx ld mj lz ma lh mk mc md me ij bi translated">然后在预测时，主模型的混淆矩阵如下所示。</p><figure class="mx my mz na gt is gh gi paragraph-image"><div class="gh gi oj"><img src="../Images/8638aca54e30a8e291945154bd4f37d2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1266/format:webp/1*tsKJ15R-D6Fc0RcMKJM_UQ.jpeg"/></div></figure><p id="317b" class="pw-post-body-paragraph lm ln jb lo b lp mg kc lr ls mh kf lu kz mi lw lx ld mj lz ma lh mk mc md me ij bi translated">我们不太担心假阴性——我们可能会错过一些赌注，但至少我们没有赔钱。我们最担心的是假阳性，这是我们损失金钱的地方。</p><p id="7370" class="pw-post-body-paragraph lm ln jb lo b lp mg kc lr ls mh kf lu kz mi lw lx ld mj lz ma lh mk mc md me ij bi translated">为了反映这一点，我们的元标签<em class="nk"> y* </em>可以根据图表来定义:</p><p id="6a33" class="pw-post-body-paragraph lm ln jb lo b lp mg kc lr ls mh kf lu kz mi lw lx ld mj lz ma lh mk mc md me ij bi translated"><em class="nk"> y*= </em> 1 <strong class="lo jc"> : </strong> <em class="nk">真正</em></p><p id="a38f" class="pw-post-body-paragraph lm ln jb lo b lp mg kc lr ls mh kf lu kz mi lw lx ld mj lz ma lh mk mc md me ij bi translated"><em class="nk"> y*= </em> 0 <strong class="lo jc"> : </strong></p><p id="2ce1" class="pw-post-body-paragraph lm ln jb lo b lp mg kc lr ls mh kf lu kz mi lw lx ld mj lz ma lh mk mc md me ij bi translated">实际上，主模型应该有高的<a class="ae mf" href="https://en.wikipedia.org/wiki/Precision_and_recall" rel="noopener ugc nofollow" target="_blank">回忆</a>——它应该以许多假阳性为代价，正确地识别更多的真阳性。第二模型然后将过滤掉第一模型的假阳性。</p><h2 id="35c9" class="kq kr jb bd ks kt ku dn kv kw kx dp ky kz la lb lc ld le lf lg lh li lj lk ll bi translated">元标记实现</h2><p id="55d9" class="pw-post-body-paragraph lm ln jb lo b lp lq kc lr ls lt kf lu kz lv lw lx ld ly lz ma lh mb mc md me ij bi translated">首先，我们创建一个主模型。在我们这样做之前，一个重要的预处理步骤是确保我们的训练数据有平衡的标签。</p><figure class="mx my mz na gt is gh gi paragraph-image"><div class="gh gi ok"><img src="../Images/d423e3277edb7ef98861d64cd6135c52.png" data-original-src="https://miro.medium.com/v2/resize:fit:880/format:webp/1*HGzHW8CZ8a_Mtb6sWI_4lA.png"/></div></figure><p id="f426" class="pw-post-body-paragraph lm ln jb lo b lp mg kc lr ls mh kf lu kz mi lw lx ld mj lz ma lh mk mc md me ij bi translated">原始数据集中的标签在很大程度上受 0 值支配，所以如果我们在这些标签上训练，我们会得到一个每次都预测 0 的退化模型。我们通过应用<a class="ae mf" href="https://arxiv.org/pdf/1106.1813.pdf" rel="noopener ugc nofollow" target="_blank">合成少数过采样技术</a>来创建标签计数大致相等的新训练数据集，从而解决这一问题。</p><pre class="mx my mz na gt nq nr ns nt aw nu bi"><span id="ff66" class="kq kr jb nr b gy nv nw l nx ny">from imblearn.over_sampling import SMOTE<br/>X = data_ohlc[['open', 'close', 'high', 'low', 'vwap']].values<br/>y = np.squeeze(data_ohlc[['label']].values)<br/>X_train, y_train = X[:4500], y[:4500]<br/>X_test, y_test = X[4500:], y[4500:]<br/>sm = SMOTE()<br/>X_train_res, y_train_res = sm.fit_sample(X_train, y_train)</span></pre><p id="4aa1" class="pw-post-body-paragraph lm ln jb lo b lp mg kc lr ls mh kf lu kz mi lw lx ld mj lz ma lh mk mc md me ij bi translated">接下来，我们将逻辑回归模型拟合到重新采样的训练数据中。注意，在这一点上，我们不应该期望我们的模型做得很好，因为我们还没有生成任何特征，但是当在基线模型上使用元标记时，我们仍然应该看到 F1 分数的提高。</p><pre class="mx my mz na gt nq nr ns nt aw nu bi"><span id="37c8" class="kq kr jb nr b gy nv nw l nx ny">from sklearn.linear_model import LogisticRegression<br/>clf = LogisticRegression().fit(X_train_res, y_train_res)<br/>y_pred = clf.predict(X_test)</span></pre><figure class="mx my mz na gt is gh gi paragraph-image"><div class="gh gi ok"><img src="../Images/1043d33ff13f6499dc35655abdcb393f.png" data-original-src="https://miro.medium.com/v2/resize:fit:880/format:webp/1*xX08O3sPFXUQ8czePX4gqw.png"/></div></figure><p id="77d2" class="pw-post-body-paragraph lm ln jb lo b lp mg kc lr ls mh kf lu kz mi lw lx ld mj lz ma lh mk mc md me ij bi translated">我们可以看到，我们的模型比我们的测试数据预测了更多的 1 和-1。最左和最右列的蓝色部分代表假阳性，我们打算通过元标记和训练二级模型来消除假阳性。</p><p id="f924" class="pw-post-body-paragraph lm ln jb lo b lp mg kc lr ls mh kf lu kz mi lw lx ld mj lz ma lh mk mc md me ij bi translated">让我们将三重障碍预测映射到前面介绍的二元正/负元标签中，并检查混淆矩阵:</p><pre class="mx my mz na gt nq nr ns nt aw nu bi"><span id="eed4" class="kq kr jb nr b gy nv nw l nx ny">def true_binary_label(y_pred, y_test):<br/>    bin_label = np.zeros_like(y_pred)<br/>    for i in range(y_pred.shape[0]):<br/>        if y_pred[i] != 0 and y_pred[i]*y_test[i] &gt; 0:<br/>            bin_label[i] = 1  # true positive<br/>    return bin_label</span><span id="dcca" class="kq kr jb nr b gy nz nw l nx ny">from sklearn.metrics import confusion_matrix<br/>cm= confusion_matrix(true_binary_label(y_pred, y_test), y_pred != 0)</span></pre><figure class="mx my mz na gt is gh gi paragraph-image"><div class="gh gi ol"><img src="../Images/2b384c2f0a567a736f7e95de494e7ed1.png" data-original-src="https://miro.medium.com/v2/resize:fit:574/format:webp/1*-FjBnnHBKBLHMWIPltvZdw.png"/></div><figcaption class="ob oc gj gh gi od oe bd b be z dk">primary model</figcaption></figure><p id="7c38" class="pw-post-body-paragraph lm ln jb lo b lp mg kc lr ls mh kf lu kz mi lw lx ld mj lz ma lh mk mc md me ij bi translated">正如所料，我们没有看到假阴性和大量的假阳性。我们会尽量减少假阳性而不增加太多的假阴性。</p><p id="20e2" class="pw-post-body-paragraph lm ln jb lo b lp mg kc lr ls mh kf lu kz mi lw lx ld mj lz ma lh mk mc md me ij bi">.</p><p id="fddf" class="pw-post-body-paragraph lm ln jb lo b lp mg kc lr ls mh kf lu kz mi lw lx ld mj lz ma lh mk mc md me ij bi">.</p><pre class="mx my mz na gt nq nr ns nt aw nu bi"><span id="fb02" class="kq kr jb nr b gy nv nw l nx ny"># generate predictions for training set<br/>y_train_pred = clf.predict(X_train) <br/># add the predictions to features <br/>X_train_meta = np.hstack([y_train_pred[:, None], X_train])<br/>X_test_meta = np.hstack([y_pred[:, None], X_test])<br/># generate true meta-labels<br/>y_train_meta = true_binary_label(y_train_pred, y_train)<br/># rebalance classes again<br/>sm = SMOTE()<br/>X_train_meta_res, y_train_meta_res = sm.fit_sample(X_train_meta, y_train_meta)<br/>model_secondary = LogisticRegression().fit(X_train_meta_res, y_train_meta_res)<br/>y_pred_meta = model_secondary.predict(X_test_meta)<br/># use meta-predictions to filter primary predictions<br/>cm= confusion_matrix(true_binary_label(y_pred, y_test), (y_pred * y_pred_meta) != 0)</span></pre><figure class="mx my mz na gt is gh gi paragraph-image"><div class="gh gi ol"><img src="../Images/6011ff4906ed5deec8aadf25d53b9003.png" data-original-src="https://miro.medium.com/v2/resize:fit:574/format:webp/1*0uJHaKXgoDUHGThG-2TZ7Q.png"/></div><figcaption class="ob oc gj gh gi od oe bd b be z dk">secondary model</figcaption></figure><p id="95db" class="pw-post-body-paragraph lm ln jb lo b lp mg kc lr ls mh kf lu kz mi lw lx ld mj lz ma lh mk mc md me ij bi translated">二级模型中的结果表明，我们引入了一些假阴性，但是我们从初级模型中消除了超过 30%的假阳性。虽然这并不总是一个有价值的交易，但记住交易的背景——我们错过了一些交易机会(假阴性)，但这是减少许多在我们面前爆炸的交易(假阳性)的廉价代价。分类报告证实了我们的直觉，即通过<a class="ae mf" href="https://en.wikipedia.org/wiki/F1_score" rel="noopener ugc nofollow" target="_blank"> F1 分数</a>测量，分类器的效率提高了。</p><pre class="mx my mz na gt nq nr ns nt aw nu bi"><span id="34b3" class="kq kr jb nr b gy nv nw l nx ny"># WITHOUT META-LABELING</span><span id="f49b" class="kq kr jb nr b gy nz nw l nx ny">       label    precision    recall  <strong class="nr jc">f1-score</strong>   support<br/><br/>           0       1.00      <strong class="nr jc">0.66</strong>      <strong class="nr jc">0.79</strong>      1499<br/>           1       0.14      1.00      <strong class="nr jc">0.24</strong>        81<br/><br/>   micro avg       0.67      0.67      <strong class="nr jc">0.67</strong>      1580<br/>   macro avg       0.57      0.83      <strong class="nr jc">0.52</strong>      1580<br/>weighted avg       0.96      0.67      <strong class="nr jc">0.76</strong>      1580</span><span id="39c1" class="kq kr jb nr b gy nz nw l nx ny"># WITH META-LABELING</span><span id="b1cd" class="kq kr jb nr b gy nz nw l nx ny">       label    precision    recall  f1-score   support<br/>       <br/>           0       0.97      <strong class="nr jc">0.76</strong>      <strong class="nr jc">0.85</strong>      1499<br/>           1       0.12      0.59      0.20        81<br/><br/>   micro avg       0.75      0.75      <strong class="nr jc">0.75</strong>      1580<br/>   macro avg       0.55      0.68      <strong class="nr jc">0.53</strong>      1580<br/>weighted avg       0.93      0.75      <strong class="nr jc">0.82</strong>      1580</span></pre><p id="6be7" class="pw-post-body-paragraph lm ln jb lo b lp mg kc lr ls mh kf lu kz mi lw lx ld mj lz ma lh mk mc md me ij bi translated">虽然这两个模型都不太好，但请记住，我们只是在演示一种提高分类器效率的技术，这种技术可以在更大的数据集、更好的模型和更强大的功能上很好地工作。</p><h2 id="3627" class="kq kr jb bd ks kt ku dn kv kw kx dp ky kz la lb lc ld le lf lg lh li lj lk ll bi translated">元标记:定量方法</h2><p id="9c26" class="pw-post-body-paragraph lm ln jb lo b lp lq kc lr ls lt kf lu kz lv lw lx ld ly lz ma lh mb mc md me ij bi translated">总的来说，元标注+二级模型的解释就是预测一级模型的置信度。在我们的例子中，主模型和次模型都是数据驱动的，但是并不总是这样。</p><p id="83d4" class="pw-post-body-paragraph lm ln jb lo b lp mg kc lr ls mh kf lu kz mi lw lx ld mj lz ma lh mk mc md me ij bi translated">除了提高 F1 分数，元标记还有另一个极其强大的应用——它可以在非 ML 模型之上添加一个机器学习层，包括计量经济学预测、基本面分析、技术信号，甚至是酌情策略。这提供了人类直觉/专业知识和数量优势的强大组合，因其可解释性和稳健性而受到许多资产经理的青睐。</p><h1 id="1653" class="ml kr jb bd ks mm mn mo kv mp mq mr ky kh ms ki lc kk mt kl lg kn mu ko lk mv bi translated">摘要</h1><p id="dbe5" class="pw-post-body-paragraph lm ln jb lo b lp lq kc lr ls lt kf lu kz lv lw lx ld ly lz ma lh mb mc md me ij bi translated">标注观察值是监督学习的重要组成部分。在这个演示中，我们开发了一种标记金融资产观察结果的方法，以及一种元标记技术，以帮助在分类问题中获得更好的 F1 分数。我鼓励您将这些标注技术与其他数据集和参数相结合，并分享您的结果。感谢您的阅读，欢迎您随时提出意见/建议！</p></div></div>    
</body>
</html>