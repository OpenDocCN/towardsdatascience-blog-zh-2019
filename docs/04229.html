<html>
<head>
<title>Deep Domain Adaptation In Computer Vision</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">计算机视觉中的深度域适应</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/deep-domain-adaptation-in-computer-vision-8da398d3167f?source=collection_archive---------6-----------------------#2019-07-02">https://towardsdatascience.com/deep-domain-adaptation-in-computer-vision-8da398d3167f?source=collection_archive---------6-----------------------#2019-07-02</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><p id="7f70" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">在过去的十年中，计算机视觉领域取得了巨大的进步。这一进步主要是由于卷积神经网络(CNN)不可否认的有效性。如果用高质量的带注释的训练数据进行训练，CNN 允许非常精确的预测。例如，在分类设置中，您通常会使用标准网络架构之一(ResNet、VGG 等)。)并使用您的数据集对其进行训练。这可能会带来非常好的性能。</p><p id="d01b" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">另一方面，如果您没有针对您的特定问题的大量人工注释数据集，CNN 还允许通过迁移学习来利用已经针对类似问题训练了网络的其他人。在这种情况下，您可以采用一个在大型数据集上进行预训练的网络，并使用您自己的小型带注释的数据集来调整它的一些上层。</p><p id="bd05" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">这两种方法都假设您的训练数据(无论大小)代表了基本分布。但是，如果测试时的输入与定型数据显著不同，则模型的性能可能不会很好。例如，让我们假设你是一名自动驾驶汽车工程师，你想分割汽车摄像头拍摄的图像，以便了解前方的情况(建筑物、树木、其他汽车、行人、交通灯等)。).您的 NYC 数据集有很好的人工生成的注释，并且您使用这些注释训练了一个大型网络。你在曼哈顿的街道上测试你的自动驾驶汽车，一切似乎都很好。然后你在巴黎测试同样的系统，突然事情变得非常糟糕。汽车不再能够检测交通灯，汽车看起来非常不同(巴黎没有黄色出租车)，街道也不再笔直。</p><p id="4d52" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">您的模型在这些场景中表现不佳的原因是问题域发生了变化。在这种特殊情况下，输入数据的域发生了变化，而任务域(标签)保持不变。在其他情况下，您可能希望使用来自同一域的数据(为同一基础分布绘制)来完成一项新任务。类似地，输入和任务域可以同时不同。在这些情况下，<strong class="jp ir">领域适应</strong>会帮助你。领域自适应是机器学习的一个子学科，处理<strong class="jp ir">场景，其中在源分布上训练的模型被用于不同(但相关)目标分布的上下文中</strong>。一般来说，领域自适应使用一个或多个源领域中的标记数据来解决目标领域中的新任务。因此，源域和目标域之间的相关程度通常决定了适配的成功程度。</p><p id="11b3" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">领域适应有多种方法。在<strong class="jp ir">“浅”(非深)域适应</strong>中，通常使用两种方法:<strong class="jp ir">重新加权源样本</strong>并对重新加权的样本进行训练，并尝试<strong class="jp ir">学习共享空间以匹配源和目标数据集的分布</strong>。虽然这些技术也可以应用于深度学习的环境中，但深度神经网络学习的深度特征(<strong class="jp ir"> DNNs </strong>)通常会产生更多可转移的表示(通常在较低层中学习高度可转移的特征，而在较高层中可转移性急剧下降，参见例如 Donahue 等人的<a class="ae kl" href="https://arxiv.org/pdf/1310.1531.pdf" rel="noopener ugc nofollow" target="_blank">这篇论文)。在<strong class="jp ir">深度域适配</strong>中，我们尝试利用 DNNs 的这一特性。</a></p><h1 id="0a4d" class="km kn iq bd ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj bi translated">领域适应类别</h1><p id="8402" class="pw-post-body-paragraph jn jo iq jp b jq lk js jt ju ll jw jx jy lm ka kb kc ln ke kf kg lo ki kj kk ij bi translated">以下总结主要基于<a class="ae kl" href="https://arxiv.org/pdf/1802.03601v4.pdf" rel="noopener ugc nofollow" target="_blank">Wang 等人的这篇综述论文</a>和<a class="ae kl" href="https://arxiv.org/pdf/1812.02849v2.pdf" rel="noopener ugc nofollow" target="_blank">Wilson 等人的这篇综述</a>。在该工作中，作者根据任务的复杂性、可用的标记/未标记数据的数量以及输入特征空间的差异来区分不同类型的领域适应。<strong class="jp ir">他们特别将领域适应定义为一个问题，其中任务空间相同，差异仅在于输入领域发散</strong>。基于该定义，域自适应可以是同质的(输入特征空间是相同的，但是具有不同的数据分布)或者异质的(特征空间及其维度可以不同)。</p><p id="ef93" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">域适配也可以在一个步骤中发生(<strong class="jp ir">一步域适配</strong>)，或者通过多个步骤，在过程中遍历一个或多个域(<strong class="jp ir">多步域适配</strong>)。在这篇文章中，我们将只讨论一步域适应，因为这是最常见的域适应类型。</p><p id="f6d2" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">根据您从目标领域获得的数据，领域适应可以进一步分为<strong class="jp ir">监督的</strong>(您确实有来自目标领域的标记数据，尽管这个数量对于训练整个模型来说太小了)、<strong class="jp ir">半监督的</strong>(您有标记和未标记的数据)，以及<strong class="jp ir">非监督的</strong>(您没有来自目标领域的任何标记数据)。</p><h1 id="e34d" class="km kn iq bd ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj bi translated">任务相关性</h1><p id="e3c7" class="pw-post-body-paragraph jn jo iq jp b jq lk js jt ju ll jw jx jy lm ka kb kc ln ke kf kg lo ki kj kk ij bi translated">我们如何确定在源领域中训练的模型是否可以适应我们的目标领域？事实证明，这个问题并不容易回答，任务相关性仍然是一个活跃的研究课题。如果两个任务使用相同的特征进行决策，我们可以将它们定义为相似的。另一种可能性是，如果两个任务的参数向量(即分类边界)接近，则将这两个任务定义为相似的(参见薛等人的<a class="ae kl" href="http://jmlr.csail.mit.edu/papers/volume8/xue07a/xue07a.pdf" rel="noopener ugc nofollow" target="_blank">本文</a>)。另一方面，<a class="ae kl" href="https://doi.org/10.1007/978-3-540-45167-9_41" rel="noopener ugc nofollow" target="_blank"> Ben-David 等人</a>提出，如果两个任务的数据可以使用一组变换 F 从固定的概率分布中生成，则这两个任务是 F 相关的</p><p id="829e" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">尽管有这些理论上的考虑，但在实践中，可能有必要在您自己的数据集上尝试域适应，看看您是否可以通过使用来自源任务的模型来为您的目标任务获得一些好处。通常，任务相关性可以通过简单的推理来确定，例如来自不同视角或不同照明条件的图像，或者在医学领域中，来自不同设备的图像等等。</p><h1 id="d98f" class="km kn iq bd ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj bi translated">一步域自适应技术及其应用</h1><p id="971f" class="pw-post-body-paragraph jn jo iq jp b jq lk js jt ju ll jw jx jy lm ka kb kc ln ke kf kg lo ki kj kk ij bi translated">一步域适配有三种基本技术:</p><ul class=""><li id="1fe1" class="lp lq iq jp b jq jr ju jv jy lr kc ls kg lt kk lu lv lw lx bi translated">基于散度的域自适应，</li><li id="7ff9" class="lp lq iq jp b jq ly ju lz jy ma kc mb kg mc kk lu lv lw lx bi translated">使用生成模型(GANs)或使用领域混淆损失的基于对抗的领域适应，以及</li><li id="5e4d" class="lp lq iq jp b jq ly ju lz jy ma kc mb kg mc kk lu lv lw lx bi translated">使用堆叠自动编码器(SAE)或 GANs 的基于重构的域自适应。</li></ul><h2 id="a28d" class="md kn iq bd ko me mf dn ks mg mh dp kw jy mi mj la kc mk ml le kg mm mn li mo bi translated">基于散度的领域适应</h2><p id="87cd" class="pw-post-body-paragraph jn jo iq jp b jq lk js jt ju ll jw jx jy lm ka kb kc ln ke kf kg lo ki kj kk ij bi translated">基于散度的域自适应通过<strong class="jp ir">最小化源和目标数据分布</strong>之间的一些散度标准来工作，从而实现<strong class="jp ir">域不变特征表示</strong>。如果我们找到这样的特征表示，分类器将能够在两个域上同样好地执行。这当然假设这样的表示存在，这又假设任务以某种方式相关。</p><p id="faf4" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">四种最常用的差异度量是<strong class="jp ir">最大平均差异</strong>(MMD)<strong class="jp ir">相关比对</strong>(CORAL)<strong class="jp ir">对比域差异</strong> (CCD)和 Wasserstein 度量。</p><p id="6978" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">MMD 是一种假设检验，在将两个样本映射到再生核希尔伯特空间(RKHS)后，通过比较特征的平均值来检验这两个样本是否来自同一分布。如果均值不同，分布也可能不同。这通常通过使用内核嵌入技巧和使用高斯内核比较样本来实现。这里的直觉是，如果两个分布是相同的，则来自每个分布的样本之间的平均相似性应该等于来自两个分布的混合样本之间的平均相似性。在域自适应中使用 MMD 的一个示例是 Rozantsev 等人的<a class="ae kl" href="https://arxiv.org/pdf/1603.06432.pdf" rel="noopener ugc nofollow" target="_blank">这篇论文</a>在这篇论文中，使用了双流架构，其权重不共享，但通过使用分类、正则化和域差异(MMD)损失的组合来产生相似的特征表示，如下图所示。</p><figure class="mq mr ms mt gt mu gh gi paragraph-image"><div class="gh gi mp"><img src="../Images/0f2c8cbe4ad3c1218f609938c414fb6a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1068/format:webp/1*lJR3iiBGWcxOguHWUUiA7w.png"/></div><figcaption class="mx my gj gh gi mz na bd b be z dk">Two-stream architecture by Rozantsev et al.</figcaption></figure><p id="5c72" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">因此，该设置可以是监督的、半监督的或者甚至是无监督的(在目标域中没有分类损失)。</p><p id="383a" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">CORAL ( <a class="ae kl" href="https://arxiv.org/pdf/1511.05547.pdf" rel="noopener ugc nofollow" target="_blank">链接</a>)类似于 MMD，但是它试图对齐源和目标分布的二阶统计量(相关性)，而不是使用线性变换的平均值。<a class="ae kl" href="https://arxiv.org/pdf/1607.01719.pdf" rel="noopener ugc nofollow" target="_blank">Sun 等人的论文</a>通过使用源和目标协方差矩阵之间的 Frobenius 范数构造可微分的 CORAL 损失，在深度学习的上下文中使用 CORAL。</p><p id="431f" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">CCD 也是基于 MMD，但也通过查看条件分布来利用标签分布。这确保了联合域特征仍然保持对标签的预测性。最小化 CCD 最小化类内差异，同时最大化类间差异。这需要源和目标域标签。为了摆脱这种约束，<a class="ae kl" href="https://arxiv.org/pdf/1901.00976.pdf" rel="noopener ugc nofollow" target="_blank"> Kang 等人</a>提出在联合优化目标标签和特征表示的迭代过程中使用聚类来估计丢失的目标标签。因此，通过聚类找到目标标签，然后最小化 CCD 以适应这些特征。</p><p id="8c0e" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">最后，源和目标域中的特征和标签分布可以通过考虑最优传输问题及其相应的距离，即 Wasserstein 距离来对齐。这是在<a class="ae kl" href="https://arxiv.org/pdf/1803.10081.pdf" rel="noopener ugc nofollow" target="_blank"> DeepJDOT </a> (Damodaran 等人)中提出的。作者建议通过最佳传输来最小化联合深度特征表示和标签之间的差异。</p><h2 id="a1fa" class="md kn iq bd ko me mf dn ks mg mh dp kw jy mi mj la kc mk ml le kg mm mn li mo bi translated">基于对抗的领域适应</h2><p id="d9cc" class="pw-post-body-paragraph jn jo iq jp b jq lk js jt ju ll jw jx jy lm ka kb kc ln ke kf kg lo ki kj kk ij bi translated">这种技术试图通过使用对抗训练来实现领域适应。</p><p id="d7fa" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">一种方法是使用<strong class="jp ir">生成对抗网络</strong> (GANs)生成与源域有某种关联的合成目标数据(例如通过保留标签)。这些合成数据然后用于训练目标模型。</p><p id="f7a8" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><a class="ae kl" href="https://arxiv.org/pdf/1606.07536.pdf" rel="noopener ugc nofollow" target="_blank"> <strong class="jp ir"> CoGAN 模型</strong> </a> <strong class="jp ir"> </strong>试图通过为源和目标分布使用两个生成器/鉴别器对来实现这一点。生成器和鉴别器的一些权重被共享以学习域不变特征空间。以这种方式，可以生成标记的目标数据，其可以进一步用于诸如分类的任务中。</p><figure class="mq mr ms mt gt mu gh gi paragraph-image"><div role="button" tabindex="0" class="nc nd di ne bf nf"><div class="gh gi nb"><img src="../Images/600f6c025be66d7e8d5b076acafdaf8c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*8PvKugu4lem6Ct2V4tGeHA.png"/></div></div><figcaption class="mx my gj gh gi mz na bd b be z dk">CoGAN architecture by Liu et al.</figcaption></figure><p id="93b7" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">在另一个装置中，<a class="ae kl" href="https://arxiv.org/pdf/1603.07442.pdf" rel="noopener ugc nofollow" target="_blank"> Yoo 等人</a>试图通过使用两个鉴别器来学习<strong class="jp ir">源/目标转换器网络</strong>:一个用于确保目标数据是真实的，另一个用于保持源和目标域之间的相关性。<strong class="jp ir">发生器</strong>在此<strong class="jp ir">以源数据</strong>为条件。这种方法只需要目标域中未标记的数据。</p><p id="7ff4" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">除了用于当前任务的分类损失之外，如果我们使用所谓的<strong class="jp ir">域混淆损失</strong>，我们还可以<strong class="jp ir">完全去除生成器</strong>，并且一次执行域适应。域混淆损失类似于 GANs 中的鉴别器，因为它试图匹配源和目标域的分布，以便“混淆”高级分类层。这种网络最著名的例子可能是 Ganin 等人的<strong class="jp ir">域对抗神经网络</strong> (DANN)。该网络包括两个损失，分类损失和域混淆损失。它包含一个<strong class="jp ir">梯度反转层</strong>来匹配特征分布。通过最小化源样本的分类损失和所有样本的域混淆损失(同时最大化特征提取的域混淆损失)，这确保了样本对于分类器是相互不可区分的。</p><figure class="mq mr ms mt gt mu gh gi paragraph-image"><div role="button" tabindex="0" class="nc nd di ne bf nf"><div class="gh gi ng"><img src="../Images/149e3aa86585d3fa4939ba418cea7a5e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*9aVg6JGcZFSKHUn_U4RrUQ.png"/></div></div><figcaption class="mx my gj gh gi mz na bd b be z dk">Domain-adversarial neural network architecture by <a class="ae kl" href="https://arxiv.org/pdf/1409.7495.pdf" rel="noopener ugc nofollow" target="_blank">Ganin et al.</a></figcaption></figure><h2 id="4f3a" class="md kn iq bd ko me mf dn ks mg mh dp kw jy mi mj la kc mk ml le kg mm mn li mo bi translated">基于重构的域适应</h2><p id="9ec1" class="pw-post-body-paragraph jn jo iq jp b jq lk js jt ju ll jw jx jy lm ka kb kc ln ke kf kg lo ki kj kk ij bi translated">这种方法使用<strong class="jp ir">辅助重建任务</strong>来为每个域创建共享表示。例如，<a class="ae kl" href="https://arxiv.org/pdf/1607.03516.pdf" rel="noopener ugc nofollow" target="_blank"> <strong class="jp ir">深度重建分类网络</strong></a>【DRCN】试图同时解决这两个任务:(I)源数据的分类，和(ii)未标记目标数据的重建。这确保了网络不仅学会了正确区分，而且还保存了关于目标数据的信息。在该论文中，作者还提到重建管道学习将源图像转换成类似于目标数据集的图像，这表明为两者学习了共同的表示。</p><figure class="mq mr ms mt gt mu gh gi paragraph-image"><div role="button" tabindex="0" class="nc nd di ne bf nf"><div class="gh gi nh"><img src="../Images/f010731cfd7c7866c470efb9cd1666dc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*bUq5lGJKT5zDXyLIequ-BA.png"/></div></div><figcaption class="mx my gj gh gi mz na bd b be z dk">The DRCN architecture by Ghifary et al.</figcaption></figure><p id="ffc4" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">另一种可能性是使用所谓的<strong class="jp ir">循环杆</strong>。Cycle GANs 的灵感来源于机器翻译中双重学习的概念。这个概念同时训练两个相反的语言翻译者(A-B，B-A)。循环中的反馈信号由相应的语言模型和相互 BLEU 分数组成。使用 im2im 框架可以对图像进行同样的处理。在本文的<a class="ae kl" href="https://arxiv.org/pdf/1703.10593.pdf" rel="noopener ugc nofollow" target="_blank">中，从一个图像域到另一个图像域的映射是在不使用任何成对图像样本的情况下学习的。这是通过同时训练分别在两个域中生成图像的两个 gan 来实现的。为了确保一致性，引入了<strong class="jp ir">周期一致性损失</strong>。这确保了从一个域到另一个域的变换，以及从一个域到另一个域的变换，会产生与输入大致相同的图像。因此，两个配对网络的全部损耗是两个鉴别器的 GAN 损耗和周期一致性损耗的总和。</a></p><p id="9b3b" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">最后，通过对来自另一个域的图像的输入进行调节，GANs 也可以用于编码器-解码器设置。在 Isola 等人的<a class="ae kl" href="https://arxiv.org/pdf/1611.07004.pdf" rel="noopener ugc nofollow" target="_blank">论文中，</a> <strong class="jp ir">条件 GANs </strong>用于通过在输入端调节鉴别器和发生器的输出，将图像从一个域转换到另一个域。这可以使用简单的编码器-解码器架构或者使用具有跳跃连接的 U-Net 架构来实现。</p><figure class="mq mr ms mt gt mu gh gi paragraph-image"><div role="button" tabindex="0" class="nc nd di ne bf nf"><div class="gh gi ni"><img src="../Images/769ed4cd822cac40baa9b2cfec0c3de5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*L5lSST2MTHXUWUwQYTdTGQ.png"/></div></div><figcaption class="mx my gj gh gi mz na bd b be z dk">Several results from the conditional GAN by Isola et al.</figcaption></figure><h1 id="99fd" class="km kn iq bd ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj bi translated">结论</h1><p id="cbcd" class="pw-post-body-paragraph jn jo iq jp b jq lk js jt ju ll jw jx jy lm ka kb kc ln ke kf kg lo ki kj kk ij bi translated">深度领域适应允许我们将特定 DNN 在源任务上学习的知识转移到新的相关目标任务。它已成功应用于图像分类或风格转换等任务中。在某种意义上，深度领域适应使我们能够在特定的新计算机视觉任务所需的训练数据量方面更接近人类水平的表现。因此，我认为这一领域的进展对整个计算机视觉领域至关重要，我希望它最终将引领我们在视觉任务中实现有效而简单的知识重用。</p></div></div>    
</body>
</html>