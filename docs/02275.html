<html>
<head>
<title>Building a real-time NLP pipeline using Kafka and spaCy</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用 Kafka 和 spaCy 构建实时 NLP 管道</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/building-a-realtime-nlp-pipeline-using-kafka-and-spacy-d4ad636be702?source=collection_archive---------16-----------------------#2019-04-15">https://towardsdatascience.com/building-a-realtime-nlp-pipeline-using-kafka-and-spacy-d4ad636be702?source=collection_archive---------16-----------------------#2019-04-15</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><figure class="gl gn jr js jt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi jq"><img src="../Images/9b0f3fc056f8e133ef6c8cb5f2e624fb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*umpNBiC20cpXiKaJJlLN1A.jpeg"/></div></div></figure><p id="2064" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">在本教程中，我们将使用<a class="ae kz" href="https://www.confluent.io" rel="noopener ugc nofollow" target="_blank">汇合 Kafka </a>、python 和一个名为<a class="ae kz" href="https://spacy.io/usage/spacy-101#pipelines" rel="noopener ugc nofollow" target="_blank"> spaCy </a>的预训练 NLP 库来构建一个实时管道。</p><p id="1f4b" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">作为先决条件，我们应该在本地安装 docker，因为我们将在我们的机器上运行 kafka 集群，还有 python 包 spaCy 和 confluent_kafka - <code class="fe la lb lc ld b">pip install spacy confluent_kafka.</code></p><h2 id="d2fd" class="le lf it bd lg lh li dn lj lk ll dp lm km ln lo lp kq lq lr ls ku lt lu lv lw bi translated">步骤 1:构建 kafka 集群</h2><p id="beca" class="pw-post-body-paragraph kb kc it kd b ke lx kg kh ki ly kk kl km lz ko kp kq ma ks kt ku mb kw kx ky im bi translated">为了构建集群，我们将使用一个<code class="fe la lb lc ld b">docker-compose</code>文件来启动所有需要的 docker 容器:zookeeper、一个代理和模式注册表。</p><figure class="mc md me mf gt ju"><div class="bz fp l di"><div class="mg mh l"/></div></figure><p id="c611" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">现在简单地说，kafka 是一个分布式流媒体平台，能够处理大量的消息，这些消息被组织或分组到主题中。为了能够并行处理一个主题，必须将它分成多个分区，来自这些分区的数据存储在称为代理的独立机器中。最后，zookeeper 用于管理集群中代理的资源。这是卡夫卡经典版本中的元素。汇合平台添加了另一个元素，称为模式注册表。这是一种非常方便的方法，可以确保我们在写入和读取流中的数据时保持相同的模式。通常模式是以独立于平台的方式用<code class="fe la lb lc ld b">avro</code>格式编写的，它存储在模式注册表中。</p><p id="8d72" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">为了读写 kafka 集群，我们需要一个代理地址、一个主题和模式注册中心的 url。</p><p id="8e30" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated"><code class="fe la lb lc ld b">docker-compose</code>将在<code class="fe la lb lc ld b">2181</code>端口启动<code class="fe la lb lc ld b">zookeper</code>，在<code class="fe la lb lc ld b">9092</code>端口启动<code class="fe la lb lc ld b">kafka broker</code>，在<code class="fe la lb lc ld b">9999</code>端口启动<code class="fe la lb lc ld b">schema registry</code>。除此之外，我们使用另一个 docker 容器<code class="fe la lb lc ld b">kafka-create-topic</code>的唯一目的是在 kafka 代理中创建一个主题(称为 test)。</p><p id="9583" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">要启动 kafka 集群，我们必须在定义 docker compose 文件的同一文件夹中运行以下命令行指令:</p><pre class="mc md me mf gt mi ld mj mk aw ml bi"><span id="a123" class="le lf it ld b gy mm mn l mo mp">docker-compose up</span></pre><p id="25ca" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">这将启动所有带有日志的 docker 容器。我们应该在控制台中看到类似这样的内容:</p><figure class="mc md me mf gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi mq"><img src="../Images/0e50dc642cabd20bf4d0fee9bac6930f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*CGmKOW3EiRfBCa3oo9kHDQ.png"/></div></div></figure><h2 id="2092" class="le lf it bd lg lh li dn lj lk ll dp lm km ln lo lp kq lq lr ls ku lt lu lv lw bi translated">步骤 2:启动 kafka 生成器，并在流中写入一些消息</h2><p id="482b" class="pw-post-body-paragraph kb kc it kd b ke lx kg kh ki ly kk kl km lz ko kp kq ma ks kt ku mb kw kx ky im bi translated">我们将用 python 创建一个简单的 kafka producer 来发送消息。这将通过使用<code class="fe la lb lc ld b">confluent_kafka</code>库来实现。</p><p id="05f7" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">卡夫卡的信息是键值对。该键通常用于对主题中的数据进行分区。我们将为我们的消息定义一个 avro 模式:</p><pre class="mc md me mf gt mi ld mj mk aw ml bi"><span id="36ba" class="le lf it ld b gy mm mn l mo mp">value_schema_str = """<br/>{<br/>   "namespace": "my.schema",<br/>   "name": "value",<br/>   "type": "record",<br/>   "fields" : [<br/>     {<br/>       "name" : "data",<br/>       "type" : "string"<br/>     }<br/>   ]<br/>}<br/>"""</span><span id="4f98" class="le lf it ld b gy mr mn l mo mp">key_schema_str = """<br/>{<br/>   "namespace": "my.schema",<br/>   "name": "key",<br/>   "type": "record",<br/>   "fields" : [<br/>     {<br/>       "name" : "key",<br/>       "type" : "string"<br/>     }<br/>   ]<br/>}<br/>"""</span></pre><p id="021d" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">在<code class="fe la lb lc ld b">key schema</code>中，我们有一个名为<code class="fe la lb lc ld b">key</code>的字段，类型为<code class="fe la lb lc ld b">string</code>，在<code class="fe la lb lc ld b">value schema</code>(实际数据)中，我们也只有一个名为<code class="fe la lb lc ld b">data</code>的字段，类型为 string。</p><p id="7c44" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">主要的 python 代码非常简单:</p><figure class="mc md me mf gt ju"><div class="bz fp l di"><div class="mg mh l"/></div></figure><p id="32a2" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">一旦我们用适当的配置定义了一个生产者，我们就可以向某个主题的代理异步发送大量消息。在教程的最后，我们有一个包含完整示例的 github 库的链接，包含配置和其他我们有意跳过的内容。</p><p id="98e6" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">需要注意的一件重要事情是我们生成数据和密钥的方式:</p><pre class="mc md me mf gt mi ld mj mk aw ml bi"><span id="b596" class="le lf it ld b gy mm mn l mo mp">value = {"data": random.choice(simple_messages)}        <br/>key = {"key": str(uuid.uuid4())}</span></pre><p id="a142" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">密钥是一个随机的 uuid 字符串。这将确保数据在集群中均匀分布。对于数据，我们只是从预定义的列表中随机选择一个句子。对于我们发送的每一句话，我们将在消费者端应用一些 nlp 规则。</p><p id="5ca5" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">接下来，我们将消息发送到一个缓冲区，一旦达到一定数量的消息，该缓冲区将被刷新:</p><pre class="mc md me mf gt mi ld mj mk aw ml bi"><span id="be8f" class="le lf it ld b gy mm mn l mo mp">try:            <br/>    avroProducer.produce(topic=args.topic, value=value, key=key)        except BufferError as e:            <br/>    messages_to_retry += 1</span></pre><p id="15cb" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">如果发送数据时出现问题，我们会再次重试。最后，我们只需要<code class="fe la lb lc ld b">flush</code>缓冲区，我们实际上是将消息发送到 kafka 集群。</p><p id="4a06" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">要运行生成器，我们只需在终端中运行:</p><pre class="mc md me mf gt mi ld mj mk aw ml bi"><span id="7e6e" class="le lf it ld b gy mm mn l mo mp">python3 producer.py</span></pre><p id="2a9c" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">我们应该会看到日志<code class="fe la lb lc ld b">we’ve sent 5 messages to 127.0.0.1:9092</code></p><p id="598d" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated"><code class="fe la lb lc ld b">producer.py</code>也有额外的命令行参数。例如，如果我们想要发送 10 条消息，而不是默认数量的<code class="fe la lb lc ld b">5</code>，我们可以使用<code class="fe la lb lc ld b">python3 producer.py -m 10</code>。</p><p id="d3f2" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">可选的命令行参数有:</p><ul class=""><li id="487b" class="ms mt it kd b ke kf ki kj km mu kq mv ku mw ky mx my mz na bi translated"><code class="fe la lb lc ld b">-b</code>代理 ip 和端口，默认<code class="fe la lb lc ld b">127.0.0.1:9092</code></li><li id="f777" class="ms mt it kd b ke nb ki nc km nd kq ne ku nf ky mx my mz na bi translated"><code class="fe la lb lc ld b">-s</code>模式注册表 url，默认<code class="fe la lb lc ld b"><a class="ae kz" href="http://127.0.0.1:9999" rel="noopener ugc nofollow" target="_blank">http://127.0.0.1:9999</a></code></li><li id="d317" class="ms mt it kd b ke nb ki nc km nd kq ne ku nf ky mx my mz na bi translated"><code class="fe la lb lc ld b">-t</code>卡夫卡主题，默认<code class="fe la lb lc ld b">test</code></li><li id="f730" class="ms mt it kd b ke nb ki nc km nd kq ne ku nf ky mx my mz na bi translated"><code class="fe la lb lc ld b">-m</code>消息数量，默认<code class="fe la lb lc ld b">5</code></li></ul><h2 id="03cb" class="le lf it bd lg lh li dn lj lk ll dp lm km ln lo lp kq lq lr ls ku lt lu lv lw bi translated">步骤 3:消费 kafka 消息并应用 nlp 处理</h2><p id="5c63" class="pw-post-body-paragraph kb kc it kd b ke lx kg kh ki ly kk kl km lz ko kp kq ma ks kt ku mb kw kx ky im bi translated">卡夫卡的消费者是拼图的最后一块。在这一部分中，我们创建了一个<code class="fe la lb lc ld b">AvroConsumer</code>并为其订阅了<code class="fe la lb lc ld b">test</code>主题。我们对主题进行投票，直到找到想要的消息数量，并跳过<code class="fe la lb lc ld b">null</code>或无效的消息。</p><figure class="mc md me mf gt ju"><div class="bz fp l di"><div class="mg mh l"/></div></figure><p id="a84b" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">一旦我们对一条消息进行了去序列化，我们就可以使用<code class="fe la lb lc ld b">spacy</code>来应用 nlp 管道，并从单词中提取一些信息。</p><figure class="mc md me mf gt ju"><div class="bz fp l di"><div class="mg mh l"/></div></figure><p id="dadb" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">spacy 很酷的一点是，它是根据英语中的一般单词预先训练的，所以我们几乎可以开箱即用。为了下载<code class="fe la lb lc ld b">spacy</code>的英语词汇，我们需要运行<code class="fe la lb lc ld b">python3 -m spacy download en</code>。</p><p id="04e1" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">这个<code class="fe la lb lc ld b">spacy</code> API 非常容易使用。我们只需要将我们的句子传递给<code class="fe la lb lc ld b">nlp</code>方法，这将运行一系列算法，如<code class="fe la lb lc ld b">tokenization</code>(将句子分解成单词)、<code class="fe la lb lc ld b">lemmatisation</code>(获得单词的基本形式)、<code class="fe la lb lc ld b">part-of-speech tagging</code>(从单词中获得词性，如动词、副词等。)，<code class="fe la lb lc ld b">named entity extraction</code>(识别命名实体，如组织或地理实体)。一旦应用了算法，我们就可以从每个单词中提取我们需要的数据。</p><p id="6e9f" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">要运行使用者，请执行以下操作:</p><pre class="mc md me mf gt mi ld mj mk aw ml bi"><span id="b438" class="le lf it ld b gy mm mn l mo mp">python3 consumer.py</span></pre><p id="18c9" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">使用与我们在生成器中相同的可选命令行参数。</p><p id="7b99" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">输出应该类似于下图:</p><figure class="mc md me mf gt ju gh gi paragraph-image"><div class="gh gi ng"><img src="../Images/773a55d61e5e150c9d8f1e9cfae4b099.png" data-original-src="https://miro.medium.com/v2/resize:fit:1252/format:webp/1*eI_wkhb47oW7K40eG1JyLw.png"/></div></figure><p id="abce" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">完整的代码示例可以在<a class="ae kz" href="https://github.com/BogdanCojocar/medium-articles/tree/master/kafka_nlp" rel="noopener ugc nofollow" target="_blank"> github </a>上找到。</p></div></div>    
</body>
</html>