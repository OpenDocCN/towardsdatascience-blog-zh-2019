# 利用机器学习检测信用卡欺诈

> 原文：<https://towardsdatascience.com/detecting-credit-card-fraud-using-machine-learning-a3d83423d3b8?source=collection_archive---------3----------------------->

## 用数据科学抓坏人

这篇文章描述了我关于信用卡欺诈的机器学习项目。如果你对代码感兴趣，可以在这里找到我的笔记本[。](https://github.com/lksfr/credit_card_fraud/tree/master)

![](img/4345c7bfc8d377d10b7c210621417631.png)

Source: [https://giphy.com/gifs/glitch-money-shopping-d3mmdNnW5hkoUxTG](https://giphy.com/gifs/glitch-money-shopping-d3mmdNnW5hkoUxTG)

# 介绍

E 自从开始我的数据科学之旅，我就一直在思考如何善用数据科学，同时创造价值。因此，当我在 Kaggle 上看到这个处理信用卡欺诈检测的数据集时，我立刻就被吸引住了。该数据集有 31 个特征，其中 28 个已被匿名，并被标记为 V1 到 V28。剩下的三个特征是交易的时间和金额，以及该交易是否是欺诈性的。在上传到 Kaggle 之前，匿名变量已经以 PCA(主成分分析)的形式进行了修改。此外，数据集中没有缺失值。有了对数据的基本描述，让我们开始一些探索性的数据分析。

# 探索性数据分析

由于几乎所有的预测因素都被匿名化了，在我的 EDA 中，我决定将重点放在未匿名化的预测因素交易时间和交易量上。数据集包含 284，807 项交易。所有交易的平均值为 88.35 美元，而该数据集中记录的最大交易金额为 25，691.16 美元。然而，正如你现在根据平均值和最大值所猜测的那样，所有交易的货币价值的分布是严重向右倾斜的。绝大多数事务相对较小，只有极小一部分事务接近最大值。

![](img/7543505116089252f0f106e12155b72d.png)

从数据集中的第一次交易开始，时间以秒数记录。因此，我们可以得出结论，这个数据集包括两天内记录的所有交易。与交易的货币价值分布相反，它是双峰的。这表明，在第一笔交易后大约 28 小时，交易量显著下降。虽然没有提供第一笔交易的时间，但有理由假设交易量下降发生在夜间。

![](img/94c596e95f21f0daad379a94f54d12f0.png)

班级分布呢？有多少交易是欺诈性的，有多少不是？可以预料，大多数交易都是非欺诈性的。事实上，该数据集中 99.83%的交易不是欺诈性的，而只有 0.17%是欺诈性的。下面的图像强调了这种显著的对比。

![](img/e5fb33484ad3f3662e222d1f6386928e.png)

最后，知道我们的预测因子之间是否有任何显著的相关性，特别是关于我们的类别变量，将会很有趣。确定这一点的最直观的方法之一是使用热图。

![](img/a4dff2b2926d17bff0838dd0655c5677.png)

正如你所看到的，我们的一些预测器看起来确实与类变量相关。尽管如此，对于如此大量的变量来说，似乎没有什么显著的相关性。这可能归因于两个因素:

1.  数据是使用 PCA 准备的，因此我们的预测因子是主成分。
2.  巨大的阶级不平衡可能会扭曲某些与我们的阶级变量相关的重要性。

# 数据准备

在继续我们的分析之前，重要的是不要忘记，虽然匿名化特征已经被缩放并且似乎以零为中心，但是我们的时间和数量特征却没有。如果不对它们进行缩放，将导致某些机器学习算法对特征进行加权(逻辑回归)或依赖于距离度量(KNN ),性能会差得多。为了避免这个问题，我对时间和数量列进行了标准化。幸运的是，没有缺失值，因此我们不需要担心缺失值插补。

# 为严重不平衡的数据集创建训练集

现在是具有挑战性的部分:创建一个训练数据集，让我们的算法能够挑选出使交易更有可能或更不可能是欺诈的具体特征。使用原始数据集不会被证明是一个好主意，原因很简单:因为我们 99%以上的交易都是非欺诈性的，所以总是预测交易是非欺诈性的算法将实现高于 99%的准确性。然而，这与我们想要的正好相反。我们不希望通过从不将交易标记为欺诈来实现 99%的准确性，我们希望检测欺诈交易并将其标记为欺诈交易。

有两个关键点可以帮助我们解决这个问题。首先，我们将利用**随机欠采样**来创建一个具有平衡类别分布的训练数据集，这将迫使算法检测欺诈交易，从而实现高性能。说到性能，我们不打算依赖准确性。相反，我们将利用受试者操作特征-曲线下面积或 ROC-AUC 性能测量(我在本文下面链接了进一步的阅读)。本质上，ROC-AUC 输出 0 到 1 之间的值，其中 1 是满分，0 是最差。如果一个算法的 ROC-AUC 得分高于 0.5，则它比随机猜测获得了更高的性能。

为了创建我们的平衡训练数据集，我对数据集中的所有欺诈交易进行了计数。然后，我随机选择了相同数量的非欺诈性交易，并将两者连接起来。在重组了这个新创建的数据集之后，我决定再次输出类分布，以直观显示差异。

![](img/243debacc155e0c65c521b29761fc562.png)

# 异常检测和去除

离群点检测是一个复杂的话题。减少事务数量从而减少算法可用的信息量，以及让极端异常值扭曲预测结果，这两者之间的权衡并不容易解决，并且高度依赖于您的数据和目标。在我的例子中，我决定专门关注与异常值移除的类变量的相关性为 0.5 或更高的特性。在实际剔除异常值之前，让我们先来看看这些特性的可视化效果:

![](img/128b1c2d906ffaa3e248ab08e370eab2.png)![](img/fcdde633ea1c977cc39d92aeacd726c3.png)

箱线图为我们提供了一个很好的直觉，即我们是否需要担心异常值，因为所有超出 1.5 倍 IQR(四分位间距)的交易通常都被认为是异常值。然而，删除 1.5 倍 IQR 之外的所有交易将显著减少我们的训练数据大小，这本来就不是很大。因此，我决定只关注 2.5 倍 IQR 之外的极端异常值。

# 基于 t-SNE 的可视化降维方法

可视化我们的类将被证明是非常有趣的，并向我们展示它们是否是明显可分的。然而，不可能使用我们所有的预测值来绘制一个 30 维的图。相反，使用 t-SNE 等降维技术，我们能够将这些高维分布投射到低维可视化中。对于这个项目，我决定使用 t-SNE，一种我以前没有用过的算法。如果你想知道更多关于这个算法是如何工作的，请看这里。

将我们的数据集投影到一个二维空间中，我们能够生成一个散点图，显示欺诈性和非欺诈性交易的聚类:

![](img/6a19f885bee98b267f5a71fd7b338ebb.png)

# 分类算法

到了你可能一直在等待的部分:训练机器学习算法。为了能够测试我们算法的性能，我首先执行了 80/20 的训练测试分割，将我们平衡的数据集分割成两部分。为了避免过度拟合，我使用了非常常见的 k-fold 交叉验证的重采样技术。这只是意味着您将训练数据分成 k 个部分(折叠)，然后在对第 k 个保持折叠进行预测之前，在 k-1 个折叠上拟合您的模型。然后，对每一个折叠重复这一过程，并对结果预测进行平均。

为了更好地了解哪种算法最适合我们的数据，让我们快速抽查一些最流行的分类算法:

*   逻辑回归
*   线性判别分析
*   k 最近邻(KNN)
*   分类树
*   支持向量分类器
*   随机森林分类器
*   XGBoost 分类器

抽查的结果如下所示:

![](img/0893d01e6c16bbccf4a54c87c1c235a7.png)

正如我们所见，有几个算法明显优于其他算法。现在，我们选择什么算法？如上所述，该项目不仅注重实现最高的准确性，还注重创造商业价值。因此，选择 Random Forest 而不是 XGBoost 可能是一种合理的方法，这样可以在稍微降低性能的同时实现更高程度的全面性。为了进一步说明我的意思，这里有一个我们的随机森林模型的可视化，可以很容易地用来非常简单地解释为什么做出某个决定:

![](img/c180c74cadd6e693c62b4440041bf814.png)

# 结论和未来工作

欺诈检测是一个复杂的问题，需要在使用机器学习算法之前进行大量的规划。尽管如此，这也是数据科学和机器学习的良好应用，确保客户的钱是安全的，不容易被篡改。

未来的工作将包括我前面提到的随机森林算法的全面调优。具有非匿名化特征的数据集将使这一点特别有趣，因为输出特征重要性将使人们能够看到哪些具体因素对于检测欺诈性交易最重要。

一如既往，如果您有任何问题或发现错误，请不要犹豫，联系我。本文开头提供了包含我的代码的笔记本的链接。

*参考文献*:

[1] L.J.P. van der Maaten 和 G.E. Hinton，[使用 t-SNE 可视化高维数据](https://lvdmaaten.github.io/publications/papers/JMLR_2014.pdf) (2014)，机器学习研究杂志

[2]机器学习小组— ULB，[信用卡欺诈检测](https://www.kaggle.com/mlg-ulb/creditcardfraud) (2018)，Kaggle

[3] Nathalie Japkowicz，[从不平衡数据集中学习:各种策略的比较](http://www.aaai.org/Papers/Workshops/2000/WS-00-05/WS00-05-003.pdf) (2000)，AAAI 技术报告 WS-00–05