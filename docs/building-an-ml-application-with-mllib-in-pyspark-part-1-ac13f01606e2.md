# åœ¨ Pyspark ä¸­ä½¿ç”¨ MLlib æ„å»º ML åº”ç”¨ç¨‹åº

> åŸæ–‡ï¼š<https://towardsdatascience.com/building-an-ml-application-with-mllib-in-pyspark-part-1-ac13f01606e2?source=collection_archive---------3----------------------->

## æœ¬æ•™ç¨‹å°†æŒ‡å¯¼æ‚¨å¦‚ä½•åœ¨ apache spark ä¸­åˆ›å»º ML æ¨¡å‹ï¼Œä»¥åŠå¦‚ä½•ä¸å®ƒä»¬äº¤äº’

# ä»‹ç»

Apache Spark æ˜¯ä¸€ç§æŒ‰éœ€å¤§æ•°æ®å·¥å…·ï¼Œå…¨çƒè®¸å¤šå…¬å¸éƒ½åœ¨ä½¿ç”¨å®ƒã€‚å®ƒçš„å†…å­˜è®¡ç®—å’Œå¹¶è¡Œå¤„ç†èƒ½åŠ›æ˜¯è¿™ä¸ªå·¥å…·æµè¡Œçš„ä¸»è¦åŸå› ã€‚

![](img/1ad82342d49d0c8c0c164e0af863c688.png)

Spark Stack

MLlib æ˜¯ä¸€ä¸ªå¯æ‰©å±•çš„æœºå™¨å­¦ä¹ åº“ï¼Œå®ƒä¸ Spark SQLã€Spark Streaming å’Œ GraphX ç­‰å…¶ä»–æœåŠ¡ä¸€èµ·å‡ºç°åœ¨ Spark ä¹‹ä¸Šã€‚

# **æ•°æ®é›†ç›¸å…³ä»‹ç»**

åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬å°†ä¸“æ³¨äºä¸€ä¸ªå«åšç¬”ç”»æ•°æ®é›†çš„æ•°æ®é›†ã€‚ä¸­é£æ˜¯ä¸€ç§æµå‘å¤§è„‘çš„è¡€æµåœæ­¢æˆ–è¡€æµè¿‡å¤šçš„æƒ…å†µã€‚ä¸­é£çš„å±é™©å› ç´ æœ‰

*   å¸çƒŸ
*   é«˜è¡€å‹
*   ç³–å°¿ç—…
*   è¡€æ¶²èƒ†å›ºé†‡æ°´å¹³é«˜
*   é…—é…’
*   é«˜è„‚è‚ª(å°¤å…¶æ˜¯é¥±å’Œè„‚è‚ª)å’Œé«˜ç›ï¼Œä½†ä½çº¤ç»´ã€æ°´æœå’Œè”¬èœçš„é¥®é£Ÿ
*   ç¼ºä¹ç»å¸¸é”»ç‚¼
*   è‚¥èƒ–

æ‰€ä»¥æˆ‘è¿™é‡Œå¾—åˆ°äº†ä¸€ä¸ªä¸é”™çš„æ•°æ®é›†:[*https://bigml . com/user/Francisco/gallery/model/508 b 2008570 c 6372100000 B1 # info*](https://bigml.com/user/francisco/gallery/model/508b2008570c6372100000b1#info)

ä»¥ä¸‹æ˜¯æ•°æ®é›†:

![](img/c1a06497f992bb18614cf6dd0a3a33e9.png)

Stroke Dataset

è¯¥æ•°æ®é›†å‡ ä¹åŒ…å«äº†ä¸Šè¿°ä¸­é£çš„æ‰€æœ‰é£é™©å› ç´ ã€‚å› æ­¤ï¼Œé€‰æ‹©å…·æœ‰é€‚å½“é£é™©å› ç´ çš„æ•°æ®é›†éå¸¸é‡è¦ã€‚

æˆ‘ä»¬å°†æŠŠåˆ—çš„å­—ç¬¦ä¸²å€¼å˜æˆæ•°å­—å€¼ã€‚è¿™æ ·åšçš„åŸå› å°†åœ¨åé¢è§£é‡Šã€‚ä½¿ç”¨ Excel ä¸­çš„æ›¿æ¢åŠŸèƒ½ï¼Œæˆ‘å°†æ•°æ®é›†æ›´æ”¹ä¸ºä»¥ä¸‹å†…å®¹

1.  æ€§åˆ«åˆ—â€”ç”·æ€§=1ï¼Œå¥³æ€§=0

2.å¸çƒŸå²â€”â€”ä»æœª=0ï¼Œæ›¾ç»=0.25ï¼Œå½“å‰= 0.5ï¼Œä»¥å‰= 0.75ï¼Œå½“å‰= 1.0

# **ä½¿ç”¨çš„æœåŠ¡å’Œåº“**

1.  Google cloudâ€”â€”æˆ‘ä»¬å°†åœ¨ Dataproc ä¸­å»ºç«‹æˆ‘ä»¬çš„ spark é›†ç¾¤ï¼Œå¹¶åœ¨ Jupyter ç¬”è®°æœ¬ä¸­ç¼–å†™ä»£ç 
2.  Jpmml(pyspark2pmml) â€”ç”¨äºå°†æˆ‘ä»¬çš„æ¨¡å‹è½¬æ¢æˆ pmml æ–‡ä»¶ã€‚
3.  open scoringâ€”â€”ä¸€ä¸ªä¸º PMML æ¨¡å‹è¯„åˆ†çš„ REST web æœåŠ¡ã€‚
4.  VS ä»£ç â€”â€”æˆ‘ä»¬å°†ä½¿ç”¨ React JS æ„å»ºä¸€ä¸ªä¸ REST æœåŠ¡å™¨é€šä¿¡çš„äº¤äº’å¼ç½‘ç«™ã€‚

# **æ¶æ„å›¾:**

ä¸‹å›¾å±•ç¤ºäº†æˆ‘ä»¬æ•´ä¸ªé¡¹ç›®çš„ç®€è¦æ¶æ„ã€‚

![](img/1b6fa38efe91bae3816e8c23d234519b.png)

The architecture diagram of our project

# **æ­¥éª¤ 1:è®¾ç½®è°·æ­Œäº‘**

Google cloud æœ‰ä¸€ä¸ªåä¸º Dataproc çš„æœåŠ¡ï¼Œç”¨äºåˆ›å»ºé¢„è£… Apache Spark çš„é›†ç¾¤ã€‚æˆ‘ä»¬å¯ä»¥éšæ—¶è°ƒæ•´é›†ç¾¤çš„å¤§å°ã€‚è°·æ­Œäº‘æä¾›å…è´¹çš„ 300 ç¾å…ƒä¿¡ç”¨ä½œä¸ºå…¥é—¨ä¼˜æƒ ã€‚å› æ­¤ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨è¿™äº›å…è´¹é…é¢æ¥å»ºç«‹æˆ‘ä»¬çš„é›†ç¾¤ã€‚

![](img/39770577b908ac42628bb61d2765ef90.png)

Google Cloud Console

ç‚¹å‡»â€œæ¿€æ´»â€è·å¾— 300 ç¾å…ƒçš„å…è´¹ç‚¹æ•°ã€‚

![](img/2f3dafb4e340dda3832df4e35dd91e09.png)

Registration Step-1

é€‰æ‹©æ‚¨çš„å›½å®¶ï¼Œç„¶åç‚¹å‡»â€œç»§ç»­â€ã€‚åœ¨ä¸‹ä¸€é¡µï¼Œæ‚¨å°†è¢«æç¤ºè¾“å…¥æ‚¨çš„å¸å•ç»†èŠ‚å’Œä¿¡ç”¨å¡æˆ–å€Ÿè®°å¡ç»†èŠ‚ã€‚å¡«å†™å®ƒä»¬ï¼Œç„¶åç‚¹å‡»åº•éƒ¨çš„æŒ‰é’®ã€‚

![](img/d1b30416be612a2f8eefbc3bd0f9086d.png)

Google Cloud Console - Dataproc

å°†æ‰“å¼€æ§åˆ¶å°é¡µé¢ã€‚åœ¨é¡µé¢é¡¶éƒ¨ï¼Œåœ¨æœç´¢æ ä¸­é”®å…¥ Dataprocï¼Œä¸Šé¢çš„é¡µé¢å°±ä¼šæ‰“å¼€ã€‚å•å‡» create a cluster å¼€å§‹åˆ›å»ºé›†ç¾¤ã€‚

![](img/39e3d1f108c2b34aea4e19ddca16412e.png)

GC â€” Creating a cluster-1

![](img/9d47ed6042a92ac7aa6cd270619bec52.png)

GC â€” Creating a cluster-2

![](img/75a52eed19250f50ee06751ad36ececb.png)

GC â€” Creating a cluster-3

è¯·ç¡®ä¿æ‚¨è¾“å…¥äº†ä¸ä¸Šè¿°ç›¸åŒçš„è®¾ç½®ã€‚ç‚¹å‡»é«˜çº§é€‰é¡¹ï¼ŒæŒ‰ç…§ä¸Šé¢çš„å›¾åƒè®¾ç½®ï¼Œç„¶åç‚¹å‡»åˆ›å»ºã€‚åˆ›å»ºä¸€ä¸ªé›†ç¾¤å¯èƒ½éœ€è¦ 2 åˆ° 3 åˆ†é’Ÿã€‚

![](img/bfe569e30eb841f939b1dfd684719400.png)

Google cloud â€” Dataproc clusters

å¯¼èˆªåˆ°ç¾¤é›†ï¼Œç„¶åå•å‡»è™šæ‹Ÿæœºå®ä¾‹ã€‚åœ¨ VM å®ä¾‹ä¸‹ï¼Œæˆ‘ä»¬å¯ä»¥çœ‹åˆ°åˆ›å»ºäº†ä¸€ä¸ªä¸»èŠ‚ç‚¹å’Œä¸¤ä¸ªå·¥ä½œèŠ‚ç‚¹ã€‚ä¸»èŠ‚ç‚¹çš„ä½œç”¨æ˜¯å®ƒé€šå¸¸è¯·æ±‚é›†ç¾¤ä¸­çš„èµ„æºï¼Œå¹¶ä½¿å®ƒä»¬å¯¹ spark é©±åŠ¨ç¨‹åºå¯ç”¨ã€‚å®ƒç›‘è§†å’Œè·Ÿè¸ªå·¥ä½œèŠ‚ç‚¹çš„çŠ¶æ€ï¼Œè¿™äº›å·¥ä½œèŠ‚ç‚¹çš„å·¥ä½œæ˜¯æ‰˜ç®¡ executor è¿›ç¨‹ï¼Œè¯¥è¿›ç¨‹å­˜å‚¨æ¥è‡ªä»»åŠ¡çš„è¾“å‡ºæ•°æ®å¹¶æ‰˜ç®¡ JVMã€‚è¯¦ç»†æè¿°å¯ä»¥åœ¨[è¿™é‡Œ](http://www.informit.com/articles/article.aspx?p=2928186)æ‰¾åˆ°

ç°åœ¨å•å‡»ä¸»èŠ‚ç‚¹çš„ SSH æŒ‰é’®ã€‚

![](img/eddb2f6dfa976603db2f3785b823dfe1.png)

SSH

ä¸€ä¸ªæ–°çš„ç»ˆç«¯åœ¨ä¸€ä¸ªæ–°çš„ chrome æ ‡ç­¾ä¸­æ‰“å¼€ã€‚è¿™æ˜¯å‘½ä»¤è¡Œç•Œé¢ï¼Œé€šè¿‡å®ƒæˆ‘ä»¬å¯ä»¥ä¸æˆ‘ä»¬çš„é›†ç¾¤è¿›è¡Œäº¤äº’ã€‚é”®å…¥â€œpysparkâ€æ£€æŸ¥ spark ä¸Šçš„å®‰è£…åŠå…¶ç‰ˆæœ¬ã€‚ç¡®ä¿ spark ç‰ˆæœ¬åœ¨ 2.2 ä»¥ä¸Šï¼Œpython ç‰ˆæœ¬ä¸º 3.6ã€‚

![](img/8d3ef1cc2486bd39d03b910633b5a1d5.png)

Firewall Rules

ç°åœ¨è®¾ç½® jupyter ç¬”è®°æœ¬ï¼Œæˆ‘ä»¬éœ€è¦åˆ›å»ºä¸€ä¸ªé˜²ç«å¢™è§„åˆ™ã€‚æŒ‰ç…§å›¾ç‰‡è®¾ç½®æ–°çš„é˜²ç«å¢™è§„åˆ™ã€‚ç¡®ä¿åœ¨åè®®å’Œç«¯å£ä¸­é€‰æ‹©â€œå…¨éƒ¨å…è®¸â€ã€‚

![](img/344158270934ec2965afcf7e3071b980.png)

Firewall Rules

ç‚¹å‡»ä¿å­˜å¹¶å¯¼èˆªè‡³â€œå¤–éƒ¨ IP åœ°å€â€ã€‚

![](img/4b4f7755f7b116de643d2602355becee.png)

External IP addresses

å°†â€œspark-cluster-mâ€çš„ç±»å‹æ”¹ä¸ºé™æ€ã€‚ç»™å‡ºä»»æ„ä¸€ä¸ªåå­—ï¼Œç‚¹å‡»â€œä¿ç•™â€ã€‚

ç°åœ¨å¯¼èˆªåˆ°â€œSSHâ€å¹¶é”®å…¥ä»¥ä¸‹å‘½ä»¤ã€‚

```
sudo nano ~/.jupyter_notebook_[config.py](https://www.youtube.com/redirect?event=comments&stzid=UgwMLhVicKWXmwMzyJ54AaABAg&q=http%3A%2F%2Fconfig.py%2F&redir_token=7XHzrHJ0cqu2HG4iRpSCumF2asJ8MTU2MDUzMTgyMEAxNTYwNDQ1NDIw)
```

å¤åˆ¶ä¸‹é¢çš„çº¿å¹¶ç²˜è´´å®ƒã€‚æŒ‰ CTRL+oï¼Œå›è½¦ï¼ŒCTRL+xã€‚

```
c=get_config()c.NotebookApp.ip=â€™*â€™c.NotebookApp.open_browser=Falsec.NotebookApp.port=5000
```

ç°åœ¨æˆ‘ä»¬å¯ä»¥é€šè¿‡ä¸‹é¢çš„å‘½ä»¤æ‰“å¼€ jupyter ç¬”è®°æœ¬

```
jupyter-notebook --no-browser â€” port=5000
```

åœ¨ SSH ä¸­é”®å…¥ä¸Šè¿°å‘½ä»¤ï¼Œç„¶åæ‰“å¼€ä¸€ä¸ªæ–°çš„é€‰é¡¹å¡ï¼Œå¹¶åœ¨ google chrome ä¸­é”®å…¥â€œhttps://localhost:5000â€ä»¥æ‰“å¼€ Jupyter notebookã€‚åœ¨æˆ‘çš„ä¾‹å­ä¸­ï¼Œæœ¬åœ°ä¸»æœºæ˜¯ 35.230.35.117

![](img/97c8ba9c875bfd9c9cad38e436cb7921.png)

Jupyter Notebook

# **ç¬¬äºŒæ­¥:åœ¨ Jupyter ç¬”è®°æœ¬çš„ Pyspark ä¸­ç¼–ç **

åœ¨è¿›å…¥è¿™ä¸€éƒ¨åˆ†ä¹‹å‰ï¼Œæˆ‘ä»¬éœ€è¦å®‰è£…ä¸€äº›å¤–éƒ¨åº“ã€‚

æˆ‘ä»¬éœ€è¦ Imblearn åº“æ¥æ‰§è¡Œ SMOTEï¼Œå› ä¸ºæˆ‘ä»¬çš„æ•°æ®é›†é«˜åº¦ä¸å¹³è¡¡ã€‚æ›´å¤šå…³äº smote çš„ä¿¡æ¯å¯ä»¥åœ¨è¿™ä¸ª[é“¾æ¥](https://medium.com/coinmonks/smote-and-adasyn-handling-imbalanced-data-set-34f5223e167)ä¸­æ‰¾åˆ°ã€‚

åœ¨ SSH ä¸­ï¼Œé”®å…¥

```
sudo -i
```

ç„¶åé”®å…¥ä¸‹é¢ä¸€è¡Œ

```
conda install -c glemaitre imbalanced-learn
```

é€€å‡ºæ ¹æ–‡ä»¶å¤¹ï¼Œç„¶åæ‰“å¼€ Jupyter ç¬”è®°æœ¬ã€‚å¼€å§‹ç¼–ç å§ã€‚

**å¯¼å…¥é‡è¦åº“**

```
from pyspark.sql import SQLContext
from pyspark.sql import DataFrameNaFunctions
from pyspark.ml import Pipeline
from pyspark.ml.classification import DecisionTreeClassifier
from pyspark.ml.classification import LogisticRegression
from pyspark.ml.feature import Binarizer
from pyspark.ml.feature import OneHotEncoder, VectorAssembler, StringIndexer, VectorIndexer
from pyspark.ml.classification import RandomForestClassifier
from pyspark.sql.functions import avgimport pandas as pd
import numpy as np
import matplotlib.pyplot as plt
%matplotlib inlinefrom pyspark.ml.evaluation import MulticlassClassificationEvaluator
from pyspark.mllib.evaluation import MulticlassMetrics
from pyspark.ml.evaluation import BinaryClassificationEvaluatorfrom imblearn.over_sampling import SMOTE
from imblearn.combine import SMOTEENN
from sklearn.model_selection import train_test_split
from collections import Counter
```

ç°åœ¨æˆ‘ä»¬éœ€è¦åˆ›å»ºä¸€ä¸ª spark ä¼šè¯ã€‚

```
from pyspark.context import SparkContext
from pyspark.sql.session import SparkSession
sc = SparkContext(â€˜localâ€™)
spark = SparkSession(sc)
```

æˆ‘ä»¬éœ€è¦ä»å­˜å‚¨ä¸­è®¿é—®æˆ‘ä»¬çš„æ•°æ®æ–‡ä»¶ã€‚å¯¼èˆªåˆ° google äº‘æ§åˆ¶å°ä¸­çš„â€œbucketâ€å¹¶åˆ›å»ºä¸€ä¸ªæ–°çš„ bucketã€‚æˆ‘å‘½åä¸ºâ€œdata-stroke-1 â€,å¹¶ä¸Šä¼ ä¿®æ”¹åçš„ CSV æ–‡ä»¶ã€‚

![](img/c11403e22972c6a3596afa01c98a266d.png)

Google Cloud Bucket

ç°åœ¨æˆ‘ä»¬éœ€è¦åŠ è½½å·²ç»ä¸Šä¼ åˆ°æˆ‘ä»¬çš„ bucket ä¸­çš„ CSV æ–‡ä»¶ã€‚

```
input_dir = â€˜gs://data-stroke-1/â€™
df = spark.read.format(â€˜com.databricks.spark.csvâ€™).options(header=â€™trueâ€™, inferschema=â€™trueâ€™).load(input_dir+â€™stroke.csvâ€™)
df.columns
```

![](img/989dbdfca84f7a6300464ab39fbbe87b.png)

æˆ‘ä»¬å¯ä»¥é€šè¿‡ä½¿ç”¨ä¸‹å›¾æ‰€ç¤ºçš„å‘½ä»¤æ‰“å°æ•°æ®å¸§æ¥æ£€æŸ¥å®ƒã€‚

![](img/6080f905d09774ca942afefd430f3902.png)

ç°åœ¨ï¼Œæˆ‘ä»¬éœ€è¦åˆ›å»ºä¸€ä¸ªåˆ—ï¼Œå…¶ä¸­åŒ…å«æ‰€æœ‰è´Ÿè´£é¢„æµ‹ä¸­é£å‘ç”Ÿçš„ç‰¹å¾ã€‚

```
featureColumns = [â€˜genderâ€™,â€™ageâ€™,â€˜diabetesâ€™,â€˜hypertensionâ€™,
 â€˜heart diseaseâ€™,â€˜smoking historyâ€™,â€˜BMIâ€™]
```

![](img/3af29087175391f2d167f30254ad8cea.png)

ç¡®ä¿æ‰€æœ‰åˆ—éƒ½æ˜¯åŒç²¾åº¦å€¼ã€‚æ¥ä¸‹æ¥ï¼Œè®©æˆ‘ä»¬åˆ é™¤æ‰€æœ‰ 2 å²ä»¥ä¸‹çš„æ¡ç›®ã€‚

```
df = df.filter(df.age >2)
df.count()
```

ç°åœ¨è®©æˆ‘ä»¬æ‰“å°ä¸€ä¸ªæ¡å½¢å›¾æ¥æ£€æŸ¥æ•°æ®ä¸­å­˜åœ¨çš„ç±»çš„ç±»å‹

```
responses = df.groupBy(â€˜strokeâ€™).count().collect()
categories = [i[0] for i in responses]
counts = [i[1] for i in responses]

ind = np.array(range(len(categories)))
width = 0.35
plt.bar(ind, counts, width=width, color=â€™râ€™)

plt.ylabel(â€˜countsâ€™)
plt.title(â€˜Strokeâ€™)
plt.xticks(ind + width/2., categories)
```

![](img/d7351f2fdae99bf396e9d067b67a21c5.png)

# æ­¥éª¤ 3:æ•°æ®é¢„å¤„ç†

*æ­¥éª¤ 3Aã€‚ç¼ºå¤±æ•°æ®ç®¡ç†*

ç°åœ¨ï¼Œè¿›è¡Œé€‚å½“çš„ç¼ºå¤±æ•°æ®ç®¡ç†ä»¥æœ€ç»ˆå¾—åˆ°ä¸€ä¸ªéå¸¸å¥½çš„æ¨¡å‹æ˜¯éå¸¸é‡è¦çš„ã€‚ä½¿ç”¨â€œdf.na.drop()â€å¹¶ä¸æ€»æ˜¯å¥½çš„ï¼Œå®ƒä¼šåˆ é™¤æ‰€æœ‰ä¸¢å¤±æ•°æ®çš„è¡Œã€‚ç”¨é€‚å½“åˆç†çš„ä»·å€¼è§‚æ¥å¡«å……å®ƒä»¬æ˜¯æˆ‘ä»¬å¯ä»¥å®ç°çš„ä¸€ä¸ªæƒ³æ³•ã€‚

å¦‚æˆ‘ä»¬æ‰€è§ï¼Œæˆ‘ä»¬åœ¨èº«ä½“è´¨é‡æŒ‡æ•°åˆ—å’Œå¸çƒŸå²åˆ—ä¸­ç¼ºå°‘å€¼ã€‚å¡«å……è¿™äº›èº«ä½“è´¨é‡æŒ‡æ•°å€¼çš„ä¸€ç§å¯èƒ½æ–¹æ³•æ˜¯ä½¿ç”¨å¹´é¾„å€¼æ¥å¡«å……å®ƒä»¬ã€‚

![](img/1b0558a45478f786465eaf7af07c621e.png)

taken from â€” [*https://dqydj.com/bmi-distribution-by-age-calculator-for-the-united-states/*](https://dqydj.com/bmi-distribution-by-age-calculator-for-the-united-states/)

å¯¹äºå¸çƒŸå²ï¼Œå¾ˆéš¾æ‰¾åˆ°åˆç†çš„æ•°å€¼æ¥å¡«è¡¥ã€‚é€šå¸¸æƒ…å†µä¸‹ï¼Œ16 å²ä»¥ä¸‹çš„äººå¯¹å¸çƒŸå¹¶æ²¡æœ‰é‚£ä¹ˆä¸Šç˜¾ï¼Œå› æ­¤æˆ‘ä»¬å¯ä»¥ç”¨ 0 æ¥å¡«å……é‚£äº›å¹´é¾„ç»„çš„äººçš„å€¼ã€‚å¹´é¾„åœ¨ 17 åˆ° 24 å²ä¹‹é—´çš„äººä¸€ç”Ÿä¸­å¯èƒ½è‡³å°‘å°è¯•è¿‡ä¸€æ¬¡å¸çƒŸï¼Œæ‰€ä»¥æˆ‘ä»¬å¯ä»¥ç»™è¿™äº›äºº 0.25 çš„ä»·å€¼ã€‚ç°åœ¨ï¼Œä¸€äº›äººè¿‡äº†ä¸€å®šå¹´é¾„å°±æˆ’çƒŸäº†ï¼Œå³ä½¿ä»–ä»¬æœ‰å¥åº·é—®é¢˜ï¼Œä¹Ÿå¾ˆå°‘æœ‰äººç»§ç»­å¸çƒŸã€‚æˆ‘ä»¬ä¸èƒ½å†³å®šç»™å®ƒä»¬å–ä»€ä¹ˆå€¼ï¼Œæ‰€ä»¥é»˜è®¤æƒ…å†µä¸‹ï¼Œæˆ‘ä»¬ç»™å®ƒä»¬èµ‹å€¼ 0ã€‚

*æˆ‘ä»¬æ—¢å¯ä»¥åˆ é™¤è¿™äº›åˆ—ä¸­ç¼ºå°‘å€¼çš„æ‰€æœ‰è¡Œï¼Œä¹Ÿå¯ä»¥æŒ‰ç…§ä¸Šé¢çš„é€»è¾‘å¡«å……è¿™äº›è¡Œã€‚ä½†æ˜¯å‡ºäºæœ¬æ•™ç¨‹çš„ç›®çš„ï¼Œæˆ‘å·²ç»ç”¨ä¸Šé¢çš„é€»è¾‘å¡«å……äº†ä¸¢å¤±çš„è¡Œï¼Œä½†æ˜¯å®é™…ä¸Šç¯¡æ”¹æ•°æ®è€Œæ²¡æœ‰æ•°æ®é©±åŠ¨çš„é€»è¾‘æ¥å¤‡ä»½é€šå¸¸ä¸æ˜¯ä¸€ä¸ªå¥½ä¸»æ„ã€‚*

æˆ‘ä»¬å°†å¯¹æ­¤æ•°æ®å¸§æ‰§è¡Œä¸€äº›æ“ä½œï¼Œè€Œ spark æ•°æ®å¸§ä¸æ”¯æŒä»»ä½•æ“ä½œã€‚å› æ­¤ï¼Œæˆ‘ä»¬å°†æˆ‘ä»¬çš„æ•°æ®å¸§å¤åˆ¶åˆ°ç†ŠçŒ«æ•°æ®å¸§ï¼Œç„¶åæ‰§è¡Œæ“ä½œã€‚

```
imputeDF = dfimputeDF_Pandas = imputeDF.toPandas()
```

æˆ‘ä»¬å°†æ ¹æ®å¹´é¾„å°†å®Œæ•´çš„æ•°æ®å¸§åˆ†æˆè®¸å¤šæ•°æ®å¸§ï¼Œå¹¶ç”¨åˆç†çš„å€¼å¡«å……å®ƒä»¬ï¼Œç„¶åï¼Œå°†æ‰€æœ‰æ•°æ®å¸§åˆå¹¶æˆä¸€ä¸ªæ•°æ®å¸§ï¼Œå¹¶å°†å…¶è½¬æ¢å› spark æ•°æ®å¸§ã€‚

```
df_2_9 = imputeDF_Pandas[(imputeDF_Pandas[â€˜ageâ€™] >=2 ) & (imputeDF_Pandas[â€˜ageâ€™] <= 9)]
values = {â€˜smoking historyâ€™: 0, â€˜BMIâ€™:17.125}
df_2_9 = df_2_9.fillna(value = values)df_10_13 = imputeDF_Pandas[(imputeDF_Pandas[â€˜ageâ€™] >=10 ) & (imputeDF_Pandas[â€˜ageâ€™] <= 13)]
values = {â€˜smoking historyâ€™: 0, â€˜BMIâ€™:19.5}
df_10_13 = df_10_13.fillna(value = values)df_14_17 = imputeDF_Pandas[(imputeDF_Pandas[â€˜ageâ€™] >=14 ) & (imputeDF_Pandas[â€˜ageâ€™] <= 17)]
values = {â€˜smoking historyâ€™: 0, â€˜BMIâ€™:23.05}
df_14_17 = df_14_17.fillna(value = values)df_18_24 = imputeDF_Pandas[(imputeDF_Pandas[â€˜ageâ€™] >=18 ) & (imputeDF_Pandas[â€˜ageâ€™] <= 24)]
values = {â€˜smoking historyâ€™: 0, â€˜BMIâ€™:27.1}
df_18_24 = df_18_24.fillna(value = values)df_25_29 = imputeDF_Pandas[(imputeDF_Pandas[â€˜ageâ€™] >=25 ) & (imputeDF_Pandas[â€˜ageâ€™] <= 29)]
values = {â€˜smoking historyâ€™: 0, â€˜BMIâ€™:27.9}
df_25_29 = df_25_29.fillna(value = values)df_30_34 = imputeDF_Pandas[(imputeDF_Pandas[â€˜ageâ€™] >=30 ) & (imputeDF_Pandas[â€˜ageâ€™] <= 34)]
values = {â€˜smoking historyâ€™: 0.25, â€˜BMIâ€™:29.6}
df_30_34 = df_30_34.fillna(value = values)df_35_44 = imputeDF_Pandas[(imputeDF_Pandas[â€˜ageâ€™] >=35 ) & (imputeDF_Pandas[â€˜ageâ€™] <= 44)]
values = {â€˜smoking historyâ€™: 0.25, â€˜BMIâ€™:30.15}
df_35_44 = df_35_44.fillna(value = values)df_45_49 = imputeDF_Pandas[(imputeDF_Pandas[â€˜ageâ€™] >=45 ) & (imputeDF_Pandas[â€˜ageâ€™] <= 49)]
values = {â€˜smoking historyâ€™: 0, â€˜BMIâ€™:29.7}
df_45_49 = df_45_49.fillna(value = values)df_50_59 = imputeDF_Pandas[(imputeDF_Pandas[â€˜ageâ€™] >=50 ) & (imputeDF_Pandas[â€˜ageâ€™] <= 59)]
values = {â€˜smoking historyâ€™: 0, â€˜BMIâ€™:29.95}
df_50_59 = df_50_59.fillna(value = values)df_60_74 = imputeDF_Pandas[(imputeDF_Pandas[â€˜ageâ€™] >=60 ) & (imputeDF_Pandas[â€˜ageâ€™] <= 74)]
values = {â€˜smoking historyâ€™: 0, â€˜BMIâ€™:30.1}
df_60_74 = df_60_74.fillna(value = values)df_75_plus = imputeDF_Pandas[(imputeDF_Pandas[â€˜ageâ€™] >75 )]
values = {â€˜smoking historyâ€™: 0, â€˜BMIâ€™:28.1}
df_75_plus = df_75_plus.fillna(value = values)
```

ç»„åˆæ‰€æœ‰æ•°æ®å¸§

```
all_frames = [df_2_9, df_10_13, df_14_17, df_18_24, df_25_29, df_30_34, df_35_44, df_45_49, df_50_59, df_60_74, df_75_plus]
df_combined = pd.concat(all_frames)
df_combined_converted = spark.createDataFrame(df_combined)
imputeDF = df_combined_converted
```

*æ­¥ 3Bã€‚å¤„ç†ä¸å¹³è¡¡æ•°æ®*

æˆ‘ä»¬å°†æ‰§è¡Œ [SMOTE](https://imbalanced-learn.readthedocs.io/en/stable/generated/imblearn.over_sampling.SMOTE.html) æŠ€æœ¯æ¥å¤„ç†ä¸å¹³è¡¡æ•°æ®ã€‚SMOTE å¯ä»¥ä»è¿™é‡Œå¼•ç”¨:

```
X = imputeDF.toPandas().filter(items=[â€˜genderâ€™, â€˜ageâ€™, â€˜diabetesâ€™,â€™hypertensionâ€™,â€™heart diseaseâ€™,â€™smoking historyâ€™,â€™BMIâ€™])
Y = imputeDF.toPandas().filter(items=[â€˜strokeâ€™])X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.1, random_state=0)
```

![](img/bf9be4b8403639bcf484225468d986d9.png)

```
sm = SMOTE(random_state=12, ratio = â€˜autoâ€™, kind = â€˜regularâ€™)x_train_res, y_train_res = sm.fit_sample(X_train, Y_train)print(â€˜Resampled dataset shape {}â€™.format(Counter(y_train_res)))
```

è¯·å‚è€ƒæ­¤[é“¾æ¥](https://imbalanced-learn.readthedocs.io/en/stable/generated/imblearn.over_sampling.SMOTE.html)äº†è§£å‚æ•°

![](img/3262abe2a757c1813a1f612f00610039.png)

X_train åŒ…å«é™¤ Stroke åˆ—ä¹‹å¤–çš„æ‰€æœ‰æ•°æ®åˆ—ã€‚

Y_train åŒ…å«ç¬”ç”»åˆ—æ•°æ®ã€‚

å°†é‡æ–°é‡‡æ ·çš„æ•°æ®ç»„åˆæˆä¸€ä¸ªç«èŠ±æ•°æ®å¸§

```
dataframe_1 = pd.DataFrame(x_train_res,columns=[â€˜genderâ€™, â€˜ageâ€™, â€˜diabetesâ€™, â€˜hypertensionâ€™, â€˜heart diseaseâ€™, â€˜smoking historyâ€™, â€˜BMIâ€™])
dataframe_2 = pd.DataFrame(y_train_res, columns = [â€˜strokeâ€™])# frames = [dataframe_1, dataframe_2]
result = dataframe_1.combine_first(dataframe_2)
```

å°†å…¶æ”¹å›ç«èŠ±æ•°æ®å¸§

```
imputeDF_1 = spark.createDataFrame(result)
```

æ£€æŸ¥é‡æ–°é‡‡æ ·çš„æ•°æ®ã€‚è¿™ä¸æˆ‘ä»¬ä¹‹å‰ä½¿ç”¨çš„ä»£ç ç›¸åŒã€‚

![](img/000d3ce1c825e70cf026a1327bbace97.png)

å¦‚æˆ‘ä»¬æ‰€è§ï¼Œæˆ‘ä»¬æˆåŠŸåœ°å¯¹æ•°æ®è¿›è¡Œäº†é‡æ–°é‡‡æ ·ã€‚ç°åœ¨æˆ‘ä»¬å°†è¿›å…¥ä¸‹ä¸€éƒ¨åˆ†ã€‚

# **ç¬¬å››æ­¥ã€‚æ„å»º Spark ML ç®¡é“**

ä¸‹é¢æ˜¯ä¸€ä¸ª spark ml é¡¹ç›®çš„é€šç”¨ç®¡é“ï¼Œé™¤äº†æˆ‘ä»¬æ²¡æœ‰ä½¿ç”¨å­—ç¬¦ä¸²ç´¢å¼•å™¨å’Œ oneHotEncoderã€‚

![](img/9fa039b033b8443f6c7858f44d3aff0e.png)

Spark ML Pipeline

ç°åœ¨è¦æ„å»ºä¸€ä¸ªæ±‡ç¼–å™¨ï¼Œä¸ºæ­¤ï¼Œæˆ‘ä»¬éœ€è¦ä¸€ä¸ªäºŒè¿›åˆ¶åŒ–å™¨ã€‚

```
binarizer = Binarizer(threshold=0.0, inputCol=â€strokeâ€, outputCol=â€labelâ€)
binarizedDF = binarizer.transform(imputeDF_1)binarizedDF = binarizedDF.drop(â€˜strokeâ€™)
```

è¿™å°†åˆ›å»ºä¸€ä¸ªåä¸ºâ€œlabelâ€çš„æ–°åˆ—ï¼Œå…¶å€¼ä¸ stroke åˆ—ä¸­çš„å€¼ç›¸åŒã€‚

```
assembler = VectorAssembler(inputCols = featureColumns, outputCol = â€œfeaturesâ€)
assembled = assembler.transform(binarizedDF)print(assembled)
```

æ±‡ç¼–ç¨‹åºå°†é¢„æµ‹ç¬”ç”»æ‰€éœ€çš„æ‰€æœ‰åˆ—ç»„åˆèµ·æ¥ï¼Œäº§ç”Ÿä¸€ä¸ªç§°ä¸ºç‰¹å¾çš„å‘é‡ã€‚

![](img/8db2662d404b99a3780abf8b50bd3c6c.png)

**ç°åœ¨å¼€å§‹æ‹†åˆ†æ•°æ®**

```
(trainingData, testData) = assembled.randomSplit([0.7, 0.3], seed=0)
print(â€œDistribution of Ones and Zeros in trainingData is: â€œ, trainingData.groupBy(â€œlabelâ€).count().take(3))
```

![](img/c0759fd4ac447c5a4ff21501490ec691.png)

åŸ¹å…»

```
dt = DecisionTreeClassifier(labelCol="label", featuresCol="features", maxDepth=25, minInstancesPerNode=30, impurity="gini")
pipeline = Pipeline(stages=[dt])
model = pipeline.fit(trainingData)
```

æµ‹è¯•

```
predictions = model.transform(testData)
```

AUC-ROC

```
from pyspark.mllib.evaluation import BinaryClassificationMetrics as metric
results = predictions.select(['probability', 'label'])

## prepare score-label set
results_collect = results.collect()
results_list = [(float(i[0][0]), 1.0-float(i[1])) for i in results_collect]
scoreAndLabels = sc.parallelize(results_list)

metrics = metric(scoreAndLabels)
print("Test Data Aread under ROC score is : ", metrics.areaUnderROC)
```

![](img/b473a52263abd8e95b885e19c1347604.png)

```
from sklearn.metrics import roc_curve, auc

fpr = dict()
tpr = dict()
roc_auc = dict()

y_test = [i[1] for i in results_list]
y_score = [i[0] for i in results_list]

fpr, tpr, _ = roc_curve(y_test, y_score)
roc_auc = auc(fpr, tpr)

%matplotlib inline
plt.figure()
plt.plot(fpr, tpr, label='ROC curve (area = %0.2f)' % roc_auc)
plt.plot([0, 1], [0, 1], 'k--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver operating characteristic Graph')
plt.legend(loc="lower right")
plt.show()
```

![](img/11dcedef3e984011007986464721abce.png)

AUC â€” ROC Curve

æ­£å¦‚æˆ‘ä»¬æ‰€çœ‹åˆ°çš„ï¼Œæˆ‘ä»¬å¾—åˆ°äº† 98 å·¦å³çš„ AUC-ROC åˆ†æ•°ï¼Œè¿™æ˜¯éå¸¸å¥½çš„ã€‚ç”±äº SMOTE æŠ€æœ¯çš„ä½¿ç”¨ï¼Œæ¨¡å‹å¯èƒ½ä¼šè¿‡æ‹Ÿåˆã€‚(*ä½†æ˜¯é€»è¾‘å›å½’å¯¹è¿™ä¸ªæ•°æ®é›†å¾ˆæœ‰æ•ˆã€‚ä½†æ˜¯ pyspark2pmml åº“ä¸­ä¼¼ä¹æœ‰ä¸€äº›é”™è¯¯ï¼Œä¸èƒ½æ­£ç¡®å¯¼å‡ºé€»è¾‘å›å½’æ¨¡å‹ã€‚*)å› æ­¤ï¼Œå‡ºäºæ¼”ç¤ºç›®çš„ï¼Œæˆ‘å°†ä½¿ç”¨å†³ç­–æ ‘æ¨¡å‹æ–‡ä»¶ã€‚

# ç¬¬äº”æ­¥ã€‚ä¿å­˜æ¨¡å‹æ–‡ä»¶

ä¸ºæ­¤ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨ä¸€ä¸ªåä¸º PySPark2PMML çš„åº“ï¼Œå®ƒçš„ç»†èŠ‚å¯ä»¥åœ¨è¿™é‡Œæ‰¾åˆ°([https://github.com/jpmml/pyspark2pmml](https://github.com/jpmml/pyspark2pmml))

ä¿å­˜ jupyter æ–‡ä»¶å¹¶é€€å‡º jupyter ç¬”è®°æœ¬ã€‚

ä»[https://github.com/jpmml/jpmml-sparkml/releases](https://github.com/jpmml/jpmml-sparkml/releases)ä¸‹è½½*jpmml-spark ml-executable-1 . 5 . 3 . jar*æ–‡ä»¶

ä¸Šä¼ åˆ° SSH

![](img/c611155bf8f6dc093d701c1d226c9a22.png)

ä¸Šä¼ åï¼Œå¦‚æœæˆ‘ä»¬è¿è¡Œâ€œlsâ€å‘½ä»¤æ£€æŸ¥ï¼Œæˆ‘ä»¬ä¼šçœ‹åˆ°æˆ‘ä»¬çš„æ–‡ä»¶ã€‚

![](img/b66b7d9488a05bcf0d2f74a0c3020e86.png)

ç°åœ¨æˆ‘ä»¬éœ€è¦è®¾ç½® jupyter notebookï¼Œå½“æˆ‘ä»¬åœ¨ ssh ä¸­é”®å…¥ pyspark æ—¶ï¼Œæˆ‘ä»¬éœ€è¦æ‰“å¼€ jupyter notebookã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬éœ€è¦æ›´æ”¹ç¯å¢ƒå˜é‡ã€‚

æ›´æ–° PySpark é©±åŠ¨ç¨‹åºç¯å¢ƒå˜é‡:

![](img/988437572616905058981add98bad743.png)

å°†ä¸‹é¢å‡ è¡Œæ·»åŠ åˆ°æ‚¨çš„`~/.bashrc`(æˆ–`~/.zshrc`)æ–‡ä»¶ä¸­ã€‚æŒ‰â€œIâ€æ’å…¥æ–°è¡Œã€‚å¤åˆ¶ä¸‹é¢çš„ä»£ç å¹¶ä½¿ç”¨â€œCTRL+Vâ€ç²˜è´´å®ƒã€‚

```
export PYSPARK_DRIVER_PYTHON=jupyter
export PYSPARK_DRIVER_PYTHON_OPTS='notebook'
```

è¦ä¿å­˜å¹¶é€€å‡º vi ç¼–è¾‘å™¨ï¼Œè¯·æŒ‰â€œESCâ€å’Œâ€œ:wqâ€ä¿å­˜ã€‚

![](img/575f219733f97af9f1ba4d6f360437fd.png)

é‡å¯ä½ çš„ç»ˆç«¯ï¼Œç„¶åè¾“å…¥â€œpysparkâ€ã€‚ä½ åº”è¯¥å¯ä»¥è¿è¡Œ jupyter ç¬”è®°æœ¬ã€‚

![](img/650f3585095c310ab1dfe1454d24b241.png)

æ‚¨åº”è¯¥èƒ½å¤Ÿåœ¨å…¶ä¸­ä¸€è¡Œä¸­çœ‹åˆ°ç«¯å£å·ã€‚

ç°åœ¨è¦ä½¿ç”¨ pmml åº“ï¼Œé€šè¿‡è°ƒç”¨ä¸‹é¢çš„å‘½ä»¤æ‰“å¼€ jupyter ç¬”è®°æœ¬ã€‚

```
pyspark --jars /home/yashwanthmadaka_imp24/jpmml-sparkml-executable-1.5.3.jar
```

æ‰“å¼€ jupyter ç¬”è®°æœ¬åï¼Œè¿è¡Œæˆ‘ä»¬ä¹‹å‰å†™çš„æ‰€æœ‰å•å…ƒæ ¼ã€‚ç°åœ¨ï¼Œæ·»åŠ ä¸‹é¢è¿™æ®µä»£ç ã€‚

```
trainingData = trainingData.drop(â€œfeaturesâ€)from pyspark.ml.feature import RFormula
formula = RFormula(formula = "label ~ .")
classifier = DecisionTreeClassifier(maxDepth=25, minInstancesPerNode=30, impurity="gini")
pipeline = Pipeline(stages = [formula, classifier])
pipelineModel = pipeline.fit(trainingData)from pyspark2pmml import PMMLBuilder
pmmlBuilder = PMMLBuilder(sc, trainingData, pipelineModel) \
 .putOption(classifier, "compact", True)pmmlBuilder.buildFile("dt-stroke.pmml")
```

![](img/e4e02c7bf7ada2e4de6f49bd85476186.png)

è¿è¡Œä¸Šè¿°ä»£ç åï¼Œå°†åœ¨æåˆ°çš„ä½ç½®åˆ›å»ºä¸€ä¸ªæ–°æ–‡ä»¶ã€‚å°†è¿™ä¸ªæ–‡ä»¶ä¸‹è½½åˆ°æ‚¨çš„æœ¬åœ°æ¡Œé¢ï¼Œè®©æˆ‘ä»¬å¼€å§‹æ„å»ºä¸€ä¸ªç½‘ç«™æ¥ä¸æˆ‘ä»¬çš„æ¨¡å‹æ–‡ä»¶è¿›è¡Œäº¤äº’ã€‚

æ•´ä¸ª jupyter ç¬”è®°æœ¬å¯ä»¥åœ¨[è¿™é‡Œ](https://github.com/yashwanthmadaka24/Stroke-Classification---Decision-Tree)æ‰¾åˆ°ã€‚

# ç¬¬å…­æ­¥ã€‚æ„å»ºä¸€ä¸ªå‰ç«¯ ReactJS åº”ç”¨ç¨‹åºä¸ PMML æ–‡ä»¶äº¤äº’ã€‚

*æ­¥éª¤ 6aã€‚ä»æˆ‘ä»¬çš„æ¨¡å‹æ–‡ä»¶æ„å»ºä¸€ä¸ª REST æœåŠ¡å™¨:*

å¯¹äºä¸æ¨¡å‹æ–‡ä»¶äº¤äº’çš„åº”ç”¨ç¨‹åºï¼Œæˆ‘ä»¬éœ€è¦å°†åº”ç”¨ç¨‹åºå…¬å¼€ä¸º REST web æœåŠ¡ã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬å°†å€ŸåŠ© Openscoring åº“ã€‚

æˆ‘ä»¬éœ€è¦ä½¿ç”¨ maven å®‰è£… Openscoringã€‚ç¡®ä¿å°†æˆ‘ä»¬ä» Google clouds è™šæ‹Ÿæœºä¸‹è½½çš„æ¨¡å‹æ–‡ä»¶æ”¾å…¥*PATH/open scoring/open scoring-client/target æ–‡ä»¶å¤¹*ã€‚

å…¶ä¸­ PATH = open scoring æ–‡ä»¶æ‰€åœ¨çš„è·¯å¾„ã€‚

å®‰è£…åï¼Œæˆ‘ä»¬éœ€è¦æŒ‰ç…§ä¸‹é¢çš„å‘½ä»¤å¯åŠ¨æœåŠ¡å™¨ã€‚

é¦–å…ˆï¼Œé€šè¿‡è¿›å…¥æœåŠ¡å™¨æ–‡ä»¶å¤¹å¹¶é”®å…¥ä¸‹é¢çš„å‘½ä»¤æ¥å¯åŠ¨æœåŠ¡å™¨

```
cd openscoring-server/targetjava -jar openscoring-server-executable-2.0-SNAPSHOT.jar
```

æ¥ä¸‹æ¥ï¼Œæ‰“å¼€å®¢æˆ·ç«¯æ–‡ä»¶å¤¹ï¼Œè¾“å…¥ä¸‹é¢çš„å‘½ä»¤ã€‚æ¥ä¸‹æ¥ï¼Œæ‰“å¼€ä¸€ä¸ªæ–°çš„ cmd å¹¶é”®å…¥ä»¥ä¸‹å‘½ä»¤ã€‚

```
cd openscoring-client/targetjava -cp openscoring-client-executable-2.0-SNAPSHOT.jar org.openscoring.client.Deployer --model [http://localhost:8080/openscoring/model/stroke](http://localhost:8080/openscoring/model/stroke) --file dt-stroke.pmml
```

å½“æˆ‘ä»¬è®¿é—®[http://localhost:8080/open scoring/model/stroke](http://localhost:8080/openscoring/model/stroke)æ—¶å¯ä»¥çœ‹åˆ°ä¸‹é¢çš„ç»“æ„

![](img/4ceb166a12fde7f365017221b7debfcb.png)

*æ­¥éª¤ 6bã€‚ä¸‹è½½ ReactJS å‰ç«¯å¹¶è¿è¡Œ:*

ç°åœ¨è®¿é—® this [Github é“¾æ¥](https://github.com/yashwanthmadaka24/React-Js-Website)å¹¶å…‹éš†è¿™ä¸ªé¡¹ç›®ã€‚

ä¸‹è½½åï¼Œä½¿ç”¨ VS ä»£ç æ‰“å¼€è¿™ä¸ªé¡¹ç›®æ–‡ä»¶å¤¹ã€‚æ‰“å¼€é‡Œé¢çš„ç»ˆç«¯ï¼Œè¾“å…¥

```
npm install
```

åœ¨å¯åŠ¨ ReactJS åº”ç”¨ç¨‹åºä¹‹å‰ï¼Œæˆ‘ä»¬éœ€è¦å¯ç”¨ CORSã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬å¯ä»¥æ·»åŠ ä¸€ä¸ª [chrome æ‰©å±•](https://chrome.google.com/webstore/detail/allow-cors-access-control/lhobafahddgcelffkeicbaginigeejlf?hl=en)ã€‚

æ‰“å¼€ CORS åï¼Œåœ¨ VS ä»£ç ç»ˆç«¯ä¸­é”®å…¥ä»¥ä¸‹å‘½ä»¤ã€‚

```
npm start
```

å°†æ‰“å¼€ä¸€ä¸ª web ç•Œé¢ï¼Œå¦‚ä¸‹æ‰€ç¤ºã€‚

![](img/194e978dd68b3704a0e75ab49d465855.png)

ReactJS Frontend

æˆ‘ä»¬å¯ä»¥è¾“å…¥ä»»ä½•å€¼å¹¶æµ‹è¯•å®ƒã€‚æˆ‘ä»¬ä¼šå¾—åˆ°é¢„æµ‹ï¼Œä¸­é£å‘ç”Ÿçš„æ¦‚ç‡å’Œä¸å‘ç”Ÿä¸­é£çš„æ¦‚ç‡ã€‚

æ‰€æœ‰ä¸ REST æœåŠ¡å™¨äº¤äº’çš„æ–¹æ³•éƒ½ç¼–ç åœ¨ index.js æ–‡ä»¶ä¸­ã€‚

# **é™„è¨€**

> ç°å®æ¨¡å‹çš„ 98 åˆ†æ˜¯ä¸å¯èƒ½è¾¾åˆ°çš„ï¼Œè¿™ä¸ªåšå®¢çš„ä¸»è¦æ„ä¹‰æ˜¯å±•ç¤ºå¦‚ä½•ä¸ pyspark åˆ¶ä½œçš„ ML æ¨¡å‹è¿›è¡Œäº¤äº’ã€‚
> 
> æˆ‘ä»¬çš„æ•°æ®é¢„å¤„ç†è¶Šå¥½ï¼Œæˆ‘ä»¬çš„æ¨¡å‹å°±è¶Šå¥½ã€‚æ¨¡å‹çš„è´¨é‡ç›´æ¥å–å†³äºæˆ‘ä»¬ä½¿ç”¨çš„æ•°æ®çš„è´¨é‡å’Œå¤šæ ·æ€§ã€‚å› æ­¤ï¼Œæœ€å¥½èŠ±æ›´å¤šçš„æ—¶é—´è¿›è¡Œé€‚å½“çš„æ•°æ®æ¸…ç†å’Œæ•°æ®è¿‡æ»¤æŠ€æœ¯ã€‚

# æœ‰ç”¨çš„é“¾æ¥

1.  SMOTEâ€”[https://medium . com/coin monks/SMOTE-and-adasyn-handling-unbalanced-data-set-34f 5223 e167](https://medium.com/coinmonks/smote-and-adasyn-handling-imbalanced-data-set-34f5223e167)
2.  pyspark 2 pmmlâ€”[https://github.com/jpmml/pyspark2pmml](https://github.com/jpmml/pyspark2pmml)
3.  å¼€åœºå¾—åˆ†â€”[https://github.com/openscoring/openscoring](https://github.com/openscoring/openscoring)
4.  ReactJs å‰ç«¯â€”[https://github.com/yashwanthmadaka24/React-Js-Website](https://github.com/yashwanthmadaka24/React-Js-Website)

ç°åœ¨ï¼Œæ˜¯ä¼‘æ¯çš„æ—¶å€™äº†ğŸ˜‡