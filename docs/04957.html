<html>
<head>
<title>NLP Part 3 | Exploratory Data Analysis of Text Data</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">NLP 第 3 部分|文本数据的探索性数据分析</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/nlp-part-3-exploratory-data-analysis-of-text-data-1caa8ab3f79d?source=collection_archive---------3-----------------------#2019-07-26">https://towardsdatascience.com/nlp-part-3-exploratory-data-analysis-of-text-data-1caa8ab3f79d?source=collection_archive---------3-----------------------#2019-07-26</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="0b5c" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">让我们从员工评估中收集一些见解</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/6b77fb0b73151fa8307a42f0c56db480.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*DrWLcOi6-NM1RIuu"/></div></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk">Photo by <a class="ae ky" href="https://unsplash.com/@lukechesser?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Luke Chesser</a> on <a class="ae ky" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><p id="0215" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这是关于使用 python 的 NLP 的三部分系列的继续。请随意查看我的其他文章。(<a class="ae ky" rel="noopener" target="_blank" href="/scraping-the-web-using-beautifulsoup-and-python-5df8e63d9de3">第一部分</a>，<a class="ae ky" rel="noopener" target="_blank" href="/preprocessing-text-data-using-python-576206753c28">第二部分</a>)</p><p id="59be" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">让我们更好地理解我们新清理的数据集。<br/>探索性数据分析(EDA)是数据分析师熟悉他们的数据以推动直觉并开始制定可测试假设的过程。这个过程通常利用描述性统计和可视化。</p><p id="e590" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">像往常一样，让我们从导入必要的库并打开数据集开始。</p><pre class="kj kk kl km gt lv lw lx ly aw lz bi"><span id="3ead" class="ma mb it lw b gy mc md l me mf">import pandas as pd<br/>import numpy as np<br/>import nltk<br/>import pickle<br/>import pyLDAvis.sklearn<br/>from collections import Counter<br/>from textblob import TextBlob<br/>from nltk.tokenize import word_tokenize<br/>from nltk.probability import FreqDist<br/>from sklearn.feature_extraction.text import CountVectorizer<br/>from sklearn.feature_extraction.text import TfidfVectorizer<br/>from sklearn.decomposition import LatentDirichletAllocation, NMF<br/>from wordcloud import WordCloud, ImageColorGenerator<br/>import matplotlib.pyplot as plt<br/>import seaborn as sns</span><span id="7782" class="ma mb it lw b gy mg md l me mf">%matplotlib inline<br/>pd.options.mode.chained_assignment = None<br/>pd.set_option('display.max_colwidth', 100)</span><span id="c8dd" class="ma mb it lw b gy mg md l me mf">with open('indeed_scrape_clean.pkl', 'rb') as pickle_file:<br/>    df = pickle.load(pickle_file)</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi mh"><img src="../Images/26a2732d520435617a1c4509f26e7bb0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*N-rQW2Q_ie-NZKhoCf24_A.png"/></div></div></figure><p id="2d61" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">如果您还记得我们以前的教程，我们经历了一系列预处理步骤来清理和准备我们的数据进行分析。我们的最终数据集包含许多列，但最后一列“lemmatized”包含我们最终清理的单词列表。我们将覆盖现有的数据框架，因为我们只对“rating”和“lemmatized”列感兴趣。</p><pre class="kj kk kl km gt lv lw lx ly aw lz bi"><span id="eb87" class="ma mb it lw b gy mc md l me mf">df = df[['rating', 'lemmatized']]<br/>df.head()</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi mi"><img src="../Images/8c3b78637b9e0de5827f01d89dd0709d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1242/format:webp/1*Jo3gePJggI4o85qZhVD8WA.png"/></div></figure><h1 id="3898" class="mj mb it bd mk ml mm mn mo mp mq mr ms jz mt ka mu kc mv kd mw kf mx kg my mz bi translated">情感分析</h1><p id="a033" class="pw-post-body-paragraph kz la it lb b lc na ju le lf nb jx lh li nc lk ll lm nd lo lp lq ne ls lt lu im bi translated">情感分析是确定作者的态度或观点的过程，其范围从-1(消极态度)到 1(积极态度)。我们将使用 TextBlob 库来分析情感。TextBlob 的情绪()函数需要一个字符串，但我们的“lemmatized”列当前是一个列表。让我们把列表转换成一个字符串。</p><pre class="kj kk kl km gt lv lw lx ly aw lz bi"><span id="3478" class="ma mb it lw b gy mc md l me mf">df['lemma_str'] = [' '.join(map(str,l)) for l in df['lemmatized']]<br/>df.head()</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nf"><img src="../Images/017e858e99e8ee3377da3b10b409ee22.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*d4WPrfWO8tOPK7wRF0P9rQ.png"/></div></div></figure><p id="c1fb" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">现在我们可以将“lemma_str”列传递到情感()函数中来计算情感。因为我们有“评级”栏，我们可以验证情感分析能够多好地确定作者的态度。也就是说，我们确实看到了明显的错误，因为评级#5 的评级为 5，但情绪相当低。</p><pre class="kj kk kl km gt lv lw lx ly aw lz bi"><span id="7d08" class="ma mb it lw b gy mc md l me mf">df['sentiment'] = df['lemma_str'].apply(lambda x: TextBlob(x).sentiment.polarity)<br/>df.head()</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ng"><img src="../Images/0d11802cf8a39503d04440df135ee707.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*AU-lfqsxpp7sILFxWjz4xA.png"/></div></div></figure><p id="2e11" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">当比较我们的情绪直方图时，我们可以看到，我们得出的绝大多数情绪评级都是非常积极的。当我们将其与“评级”栏进行比较时，我们可以看到类似的模式出现。我们不仅对情绪分析的准确性感到满意，而且可以看到员工对公司的整体态度非常积极。难怪谷歌经常被列入福布斯最佳工作场所名单。</p><pre class="kj kk kl km gt lv lw lx ly aw lz bi"><span id="7993" class="ma mb it lw b gy mc md l me mf">plt.figure(figsize=(50,30))<br/>plt.margins(0.02)<br/>plt.xlabel('Sentiment', fontsize=50)<br/>plt.xticks(fontsize=40)<br/>plt.ylabel('Frequency', fontsize=50)<br/>plt.yticks(fontsize=40)<br/>plt.hist(df['sentiment'], bins=50)<br/>plt.title('Sentiment Distribution', fontsize=60)<br/>plt.show()</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nh"><img src="../Images/f2ced8feffe4189d2d0813dd83bbbd63.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*fDN3q-3vV8EVwonVBxWRsw.png"/></div></div></figure><pre class="kj kk kl km gt lv lw lx ly aw lz bi"><span id="971b" class="ma mb it lw b gy mc md l me mf">x_rating = df.rating.value_counts()<br/>y_rating = x_rating.sort_index()<br/>plt.figure(figsize=(50,30))<br/>sns.barplot(x_rating.index, x_rating.values, alpha=0.8)<br/>plt.title("Rating Distribution", fontsize=50)<br/>plt.ylabel('Frequency', fontsize=50)<br/>plt.yticks(fontsize=40)<br/>plt.xlabel('Employee Ratings', fontsize=50)<br/>plt.xticks(fontsize=40)</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nh"><img src="../Images/dea38db3de9ddf1a551a782fea13d298.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*KRpJueevJaZZwyBi2acPFA.png"/></div></div></figure><pre class="kj kk kl km gt lv lw lx ly aw lz bi"><span id="5efe" class="ma mb it lw b gy mc md l me mf">plt.figure(figsize=(30,10))<br/>plt.title('Percentage of Ratings', fontsize=20)<br/>df.rating.value_counts().plot(kind='pie', labels=['Rating5', 'Rating4', 'Rating3', 'Rating2', 'Rating1'],<br/>                              wedgeprops=dict(width=.7), autopct='%1.0f%%', startangle= -20, <br/>                              textprops={'fontsize': 15})</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ni"><img src="../Images/f2ef534b94ccfe1799da967a5da0e676.png" data-original-src="https://miro.medium.com/v2/resize:fit:1198/format:webp/1*qsBltq9uNlNjE5vd7dZmzg.png"/></div></figure><pre class="kj kk kl km gt lv lw lx ly aw lz bi"><span id="a838" class="ma mb it lw b gy mc md l me mf">polarity_avg = df.groupby('rating')['sentiment'].mean().plot(kind='bar', figsize=(50,30))<br/>plt.xlabel('Rating', fontsize=45)<br/>plt.ylabel('Average Sentiment', fontsize=45)<br/>plt.xticks(fontsize=40)<br/>plt.yticks(fontsize=40)<br/>plt.title('Average Sentiment per Rating Distribution', fontsize=50)<br/>plt.show()</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nh"><img src="../Images/c5e80cc7d4eb9959c0365e6220d08b88.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Z03nYqOYFSB-kJN-nST9Mg.png"/></div></div></figure><p id="396f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">让我们创建两个额外的特性“word_count”来确定每次评论的字数，创建“review_len”来确定每次评论的字数。</p><pre class="kj kk kl km gt lv lw lx ly aw lz bi"><span id="2832" class="ma mb it lw b gy mc md l me mf">df['word_count'] = df['lemmatized'].apply(lambda x: len(str(x).split()))</span><span id="728d" class="ma mb it lw b gy mg md l me mf">df['review_len'] = df['lemma_str'].astype(str).apply(len)</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nj"><img src="../Images/fff75814778f1f310fe1a7b061bab4e4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*8LAUywXzibjnMZ4iR4SB0A.png"/></div></div></figure><p id="06f7" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">虽然差异并不大，但基于字母和单词计数的最长评论似乎是负面和中性的。似乎心怀不满的员工通常会在他们的评估中提供更多细节。这种结果并不少见，因为人类倾向于抱怨细节，而赞美简短。这可以通过检查下面的相关矩阵来进一步确认。评分和情绪都与“review_len”和“word_count”负相关。这可以解释相反的关系，因为每次评论的字母和单词数增加了总体评分，而情绪下降了。然而，相关性再次相当小，然而是负的。</p><pre class="kj kk kl km gt lv lw lx ly aw lz bi"><span id="ddab" class="ma mb it lw b gy mc md l me mf">letter_avg = df.groupby('rating')['review_len'].mean().plot(kind='bar', figsize=(50,30))<br/>plt.xlabel('Rating', fontsize=35)<br/>plt.ylabel('Count of Letters in Rating', fontsize=35)<br/>plt.xticks(fontsize=40)<br/>plt.yticks(fontsize=40)<br/>plt.title('Average Number of Letters per Rating Distribution', fontsize=40)<br/>plt.show()</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nh"><img src="../Images/fd6411a50c18a288b69d68d5e9f6c271.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Ka05fv2u9wBoyWo2rEkwSQ.png"/></div></div></figure><pre class="kj kk kl km gt lv lw lx ly aw lz bi"><span id="1917" class="ma mb it lw b gy mc md l me mf">word_avg = df.groupby('rating')['word_count'].mean().plot(kind='bar', figsize=(50,30))<br/>plt.xlabel('Rating', fontsize=35)<br/>plt.ylabel('Count of Words in Rating', fontsize=35)<br/>plt.xticks(fontsize=40)<br/>plt.yticks(fontsize=40)<br/>plt.title('Average Number of Words per Rating Distribution', fontsize=40)<br/>plt.show()</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nk"><img src="../Images/af898ab3ea9211b03e288c8ee03433aa.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*DS6D-653X7F5lWv6aw81ww.png"/></div></div></figure><pre class="kj kk kl km gt lv lw lx ly aw lz bi"><span id="bd4b" class="ma mb it lw b gy mc md l me mf">correlation = df[['rating','sentiment', 'review_len', 'word_count']].corr()<br/>mask = np.zeros_like(correlation, dtype=np.bool)<br/>mask[np.triu_indices_from(mask)] = True<br/>plt.figure(figsize=(50,30))<br/>plt.xticks(fontsize=40)<br/>plt.yticks(fontsize=40)<br/>sns.heatmap(correlation, cmap='coolwarm', annot=True, annot_kws={"size": 40}, linewidths=10, vmin=-1.5, mask=mask)</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nl"><img src="../Images/feb9c5210d75b09acebfc09aa462d342.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*G7-ZGtqHkCq3h9OXON0_mA.png"/></div></div></figure><h1 id="697d" class="mj mb it bd mk ml mm mn mo mp mq mr ms jz mt ka mu kc mv kd mw kf mx kg my mz bi translated">词频分析</h1><p id="d183" class="pw-post-body-paragraph kz la it lb b lc na ju le lf nb jx lh li nc lk ll lm nd lo lp lq ne ls lt lu im bi translated">让我们深入看看实际的评论本身。最常见的词是什么？按评分最常见的词有哪些？对这些问题的回答将为谷歌员工的观点提供进一步的见解。</p><p id="4618" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">NLTK 有一个很棒的名为“FreqDist”的库，它允许我们确定语料库中最常见术语的数量。首先，我们需要将我们单独的标记化评论列表转换成一个综合的可重复标记列表，将所有评论存储在一起。最后，我们向 FreqDist()传递“allwords”对象，并应用“most_common(100)”函数来获取 100 个最常见的单词。</p><pre class="kj kk kl km gt lv lw lx ly aw lz bi"><span id="5a56" class="ma mb it lw b gy mc md l me mf">words = df['lemmatized']<br/>allwords = []<br/>for wordlist in words:<br/>    allwords += wordlist</span><span id="0c36" class="ma mb it lw b gy mg md l me mf">print(allwords)</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nm"><img src="../Images/65b6bdf415de2e75b0623345ef7d9d3c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*0V5cxUVh-fFteGJgH0AAXw.png"/></div></div></figure><pre class="kj kk kl km gt lv lw lx ly aw lz bi"><span id="6e50" class="ma mb it lw b gy mc md l me mf">mostcommon = FreqDist(allwords).most_common(100)</span><span id="eb22" class="ma mb it lw b gy mg md l me mf">wordcloud = WordCloud(width=1600, height=800, background_color='white').generate(str(mostcommon))<br/>fig = plt.figure(figsize=(30,10), facecolor='white')<br/>plt.imshow(wordcloud, interpolation="bilinear")<br/>plt.axis('off')<br/>plt.title('Top 100 Most Common Words', fontsize=100)</span><span id="bb70" class="ma mb it lw b gy mg md l me mf">plt.tight_layout(pad=0)<br/>plt.show()</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nn"><img src="../Images/12963ea850cabf1568ed448ce93bd624.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*tX0TSqk_ww426U6_9_vQRA.png"/></div></div></figure><pre class="kj kk kl km gt lv lw lx ly aw lz bi"><span id="028e" class="ma mb it lw b gy mc md l me mf">mostcommon_small = FreqDist(allwords).most_common(25)<br/>x, y = zip(*mostcommon_small)</span><span id="b38e" class="ma mb it lw b gy mg md l me mf">plt.figure(figsize=(50,30))<br/>plt.margins(0.02)<br/>plt.bar(x, y)<br/>plt.xlabel('Words', fontsize=50)<br/>plt.ylabel('Frequency of Words', fontsize=50)<br/>plt.yticks(fontsize=40)<br/>plt.xticks(rotation=60, fontsize=40)<br/>plt.title('Frequency of 25 Most Common Words', fontsize=60)<br/>plt.show()</span></pre><p id="74fd" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">词频分析的结果肯定支持评论的总体积极情绪。诸如“伟大”、“工作”、“人”、“团队”、“公司”等术语都指向一个积极的公司环境，员工喜欢一起工作。</p><blockquote class="no np nq"><p id="7a79" class="kz la nr lb b lc ld ju le lf lg jx lh ns lj lk ll nt ln lo lp nu lr ls lt lu im bi translated">基于诸如“工作”、“谷歌”、“工作”和“公司”等术语在语料库中出现频率如此之高的事实，移除它们可能是个好主意(即将它们添加到我们的停用词中)。</p></blockquote><p id="950b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">也就是说，一个公司总是可以改进的。因此，让我们来看看每个评价中最常用的词。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nv"><img src="../Images/9d3429d551a40cfd7fe753e933e12d9a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*u6jcP-M1unb2kAkkFF6GfA.png"/></div></div></figure><p id="d44f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这似乎是评分= 1 的评论中最常见的词，与“管理”、“经理”、“人”有关。我们在解释这些结果时必须小心，因为根据上面打印的饼状图，只有 2%的评论评级为 1。</p><pre class="kj kk kl km gt lv lw lx ly aw lz bi"><span id="e2b4" class="ma mb it lw b gy mc md l me mf">group_by = df.groupby('rating')['lemma_str'].apply(lambda x: Counter(' '.join(x).split()).most_common(25))</span><span id="758c" class="ma mb it lw b gy mg md l me mf">group_by_0 = group_by.iloc[0]<br/>words0 = list(zip(*group_by_0))[0]<br/>freq0 = list(zip(*group_by_0))[1]</span><span id="b58c" class="ma mb it lw b gy mg md l me mf">plt.figure(figsize=(50,30))<br/>plt.bar(words0, freq0)<br/>plt.xlabel('Words', fontsize=50)<br/>plt.ylabel('Frequency of Words', fontsize=50)<br/>plt.yticks(fontsize=40)<br/>plt.xticks(rotation=60, fontsize=40)<br/>plt.title('Frequency of 25 Most Common Words for Rating=1', fontsize=60)<br/>plt.show()</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nw"><img src="../Images/e1774b6993363d5ff559a6671dddcf96.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ACFUkAhMz24uTuawW-hv5w.png"/></div></div></figure><p id="18ee" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">评分为 2 的评论有一个共同的主题“经理”、“管理”。评级分布再次非常不均衡，但这确实给了我们一些改进组织的线索。</p><pre class="kj kk kl km gt lv lw lx ly aw lz bi"><span id="5479" class="ma mb it lw b gy mc md l me mf">group_by_1 = group_by.iloc[1]<br/>words1 = list(zip(*group_by_1))[0]<br/>freq1 = list(zip(*group_by_1))[1]<br/>plt.figure(figsize=(50,30))<br/>plt.bar(words1, freq1)<br/>plt.xlabel('Words', fontsize=50)<br/>plt.ylabel('Frequency of Words', fontsize=50)<br/>plt.yticks(fontsize=40)<br/>plt.xticks(rotation=60, fontsize=40)<br/>plt.title('Frequency of 25 Most Common Words for Rating=2', fontsize=60)<br/>plt.show()</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nk"><img src="../Images/8664cd751e1a4814478616cbdcce7fd7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*CDoHD0w26KhDhjFMY8LfAQ.png"/></div></div></figure><p id="bb4b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">很难从“中性”评级中获得准确的见解，因为员工对公司没有任何过于积极或消极的看法。话虽如此，有趣的是,“管理”再次成为十大热门词汇。到目前为止，大约 14%的员工对谷歌的管理层持负面或中立的态度(没什么好或不好的可说)。像“工作”和“谷歌”这样的词似乎扭曲了所有评级的分布，从未来的分析中删除这些词是一个好主意。</p><p id="f718" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">请注意“…”，我们还需要执行一些数据处理。😞</p><pre class="kj kk kl km gt lv lw lx ly aw lz bi"><span id="0433" class="ma mb it lw b gy mc md l me mf">group_by_2 = group_by.iloc[2]<br/>words2 = list(zip(*group_by_2))[0]<br/>freq2 = list(zip(*group_by_2))[1]<br/>plt.figure(figsize=(50,30))<br/>plt.bar(words2, freq2)<br/>plt.xlabel('Words', fontsize=50)<br/>plt.ylabel('Frequency of Words', fontsize=50)<br/>plt.yticks(fontsize=40)<br/>plt.xticks(rotation=60, fontsize=40)<br/>plt.title('Frequency of 25 Most Common Words for Rating=3', fontsize=60)<br/>plt.show()</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nk"><img src="../Images/48c7650b254eb002bec78aa20752fdcb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*68vNnmmebIiZtOBj6Fzdjw.png"/></div></div></figure><p id="df1d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">评分为 4 和 5 的术语非常相似，因为员工似乎喜欢他们的工作，喜欢与他们一起工作的人，并且重视谷歌的环境/文化。比如“设计”、“学习机会”、“人”、“时间”、“团队”都有出现。也就是说，我们在排名前 10 位的单词中没有看到“管理”或“经理”。这是非常有见地的，因为它有助于验证评级 1、2 和 3 的结果。最后但同样重要的是，这些词频(即。等级 4 和 5)是从大量评论中得出的，这只会增加这些结果的有效性；管理当然是一个需要改进的领域。</p><pre class="kj kk kl km gt lv lw lx ly aw lz bi"><span id="42f3" class="ma mb it lw b gy mc md l me mf">group_by_3 = group_by.iloc[3]<br/>words3 = list(zip(*group_by_3))[0]<br/>freq3 = list(zip(*group_by_3))[1]<br/>plt.figure(figsize=(50,30))<br/>plt.bar(words3, freq3)<br/>plt.xlabel('Words', fontsize=50)<br/>plt.ylabel('Frequency of Words', fontsize=50)<br/>plt.yticks(fontsize=40)<br/>plt.xticks(rotation=60, fontsize=40)<br/>plt.title('Frequency of 25 Most Common Words for Rating=4', fontsize=60)<br/>plt.show()</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nh"><img src="../Images/9048586fab68d7772f28e98944a10356.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*i09hSBhyx2yIDQX-TBp3tw.png"/></div></div></figure><pre class="kj kk kl km gt lv lw lx ly aw lz bi"><span id="01c9" class="ma mb it lw b gy mc md l me mf">group_by_4 = group_by.iloc[4]<br/>words4 = list(zip(*group_by_4))[0]<br/>freq4 = list(zip(*group_by_4))[1]<br/>plt.figure(figsize=(50,30))<br/>plt.bar(words4, freq4)<br/>plt.xlabel('Words', fontsize=50)<br/>plt.ylabel('Frequency of Words', fontsize=50)<br/>plt.yticks(fontsize=40)<br/>plt.xticks(rotation=60, fontsize=40)<br/>plt.title('Frequency of 25 Most Common Words for Rating=5', fontsize=60)<br/>plt.show()</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nx"><img src="../Images/4af23a5a2f3121ad70c17b2fd2574762.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*iKwSaWCtSV3_sZBmkHWwow.png"/></div></div></figure><h1 id="6912" class="mj mb it bd mk ml mm mn mo mp mq mr ms jz mt ka mu kc mv kd mw kf mx kg my mz bi translated">主题建模</h1><p id="e76f" class="pw-post-body-paragraph kz la it lb b lc na ju le lf nb jx lh li nc lk ll lm nd lo lp lq ne ls lt lu im bi translated">最后，让我们应用一些主题建模算法来帮助我们的评论导出特定的主题。在我们确定每个评级的主题之前，我们必须执行一个额外的处理步骤。现在我们的数据/文字对我们人类来说仍然是可读的，而计算机只能理解数字。我们需要将文本转换成数字或向量。</p><h2 id="aa8a" class="ma mb it bd mk ny nz dn mo oa ob dp ms li oc od mu lm oe of mw lq og oh my oi bi translated">计数矢量器</h2><p id="661b" class="pw-post-body-paragraph kz la it lb b lc na ju le lf nb jx lh li nc lk ll lm nd lo lp lq ne ls lt lu im bi translated">对记号进行矢量化的 CountVectorizer 方法将所有单词/记号转置为特征，然后提供每个单词的出现次数。结果称为文档术语矩阵，如下所示。</p><p id="5b5f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">首先，我们创建矢量器对象。Max_df=0.9 将删除出现在 90%以上评论中的单词。Min_df=25 将删除出现在少于 25 条评论中的单词。接下来，我们创建备用矩阵作为 fit_transform()的结果。最后，我们创建一个所有单词/特征的列表。结果就是我们的文档术语矩阵。每行代表单个员工的评价，并统计每个词/特征在每次评价中出现的次数。</p><pre class="kj kk kl km gt lv lw lx ly aw lz bi"><span id="2133" class="ma mb it lw b gy mc md l me mf">tf_vectorizer = CountVectorizer(max_df=0.9, min_df=25, max_features=5000)</span><span id="b2ba" class="ma mb it lw b gy mg md l me mf">tf = tf_vectorizer.fit_transform(df['lemma_str'].values.astype('U'))<br/>tf_feature_names = tf_vectorizer.get_feature_names()</span><span id="4df1" class="ma mb it lw b gy mg md l me mf">doc_term_matrix = pd.DataFrame(tf.toarray(), columns=list(tf_feature_names))<br/>doc_term_matrix</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oj"><img src="../Images/4015d074fed4318ccdba8e5ef89fc937.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*PggGjivrqqpenzQMYjb4Lg.png"/></div></div></figure><h2 id="0d34" class="ma mb it bd mk ny nz dn mo oa ob dp ms li oc od mu lm oe of mw lq og oh my oi bi translated">潜在狄利克雷分配(LDA)主题建模</h2><p id="5a00" class="pw-post-body-paragraph kz la it lb b lc na ju le lf nb jx lh li nc lk ll lm nd lo lp lq ne ls lt lu im bi translated">既然我们已经为主题建模准备好了数据，我们将使用潜在狄利克雷分配(LDA)方法来确定语料库中的主题。在我们的模型中，我们将产生 10 个单独的主题(即 n _ 组件)。一旦创建了模型，让我们创建一个函数来显示确定的主题。每个题目由 10 个单词组成。该函数将有三个必需的参数；LDA 模型、来自文档术语矩阵的特征名称以及每个主题的字数。</p><pre class="kj kk kl km gt lv lw lx ly aw lz bi"><span id="2458" class="ma mb it lw b gy mc md l me mf">lda_model = LatentDirichletAllocation(n_components=10, learning_method='online', max_iter=500, random_state=0).fit(tf)</span><span id="d600" class="ma mb it lw b gy mg md l me mf">no_top_words = 10</span><span id="5a40" class="ma mb it lw b gy mg md l me mf">def display_topics(model, feature_names, no_top_words):<br/>    for topic_idx, topic in enumerate(model.components_):<br/>        print("Topic %d:" % (topic_idx))<br/>        print(" ".join([feature_names[i]<br/>                          for i in topic.argsort()[:-no_top_words - 1:-1]]))<br/>              <br/>display_topics(lda_model, tf_feature_names, no_top_words)</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ok"><img src="../Images/b1f7e4e5c1ea18fc329d8b3153db05e8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1282/format:webp/1*jzkKmutWWZT6STwHdL7IXw.png"/></div></figure><p id="8ea5" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">确定 LDA 模型产生的主题当然需要一点想象力。既然我们知道“工作”、“谷歌”、“工作”是很常见的作品我们几乎可以忽略它们。</p><p id="7ff5" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">主题 0:良好的设计流程</p><p id="c728" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">话题 1:良好的工作环境</p><p id="0528" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">话题 2:弹性工作时间</p><p id="6c45" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">主题 3:技能培养</p><p id="e8cd" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">话题 4:困难但愉快的工作</p><p id="7f14" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">话题 5:伟大的公司/工作</p><p id="0862" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">话题 6:关心员工</p><p id="2b2e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">主题 7:优秀承包商薪酬</p><p id="dea8" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">主题 8:客户服务</p><p id="6b2f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">话题九:？</p><h2 id="d81f" class="ma mb it bd mk ny nz dn mo oa ob dp ms li oc od mu lm oe of mw lq og oh my oi bi translated">皮尔戴维斯</h2><p id="3421" class="pw-post-body-paragraph kz la it lb b lc na ju le lf nb jx lh li nc lk ll lm nd lo lp lq ne ls lt lu im bi translated">pyLDAvis 是一个交互式 LDA 可视化 python 库。每个圆圈代表一个独特的主题，圆圈的大小代表主题的重要性，最后，每个圆圈之间的距离代表主题之间的相似程度。选择一个主题/圆圈将显示一个水平条形图，显示与该主题最相关的 30 个单词，以及每个单词在该主题和整个语料库中出现的频率。</p><p id="3794" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">相关性度量有助于区分不同于/专用于主题的单词(λλ更接近 0.0)和具有被包括在所选主题中的高概率的单词(λλ更接近 1.0)。</p><pre class="kj kk kl km gt lv lw lx ly aw lz bi"><span id="e120" class="ma mb it lw b gy mc md l me mf">pyLDAvis.enable_notebook()<br/>panel = pyLDAvis.sklearn.prepare(lda_model, tf, tf_vectorizer, mds='tsne')<br/>panel</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ol"><img src="../Images/f84b045da4b4e641a38795d752756705.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*EqnugnVc-3QAOe3V_bULDQ.png"/></div></div></figure><h2 id="8f73" class="ma mb it bd mk ny nz dn mo oa ob dp ms li oc od mu lm oe of mw lq og oh my oi bi translated">TF-IDF</h2><p id="059f" class="pw-post-body-paragraph kz la it lb b lc na ju le lf nb jx lh li nc lk ll lm nd lo lp lq ne ls lt lu im bi translated">LDA 不是主题建模的唯一方法。让我们尝试另一种方法，名为非负矩阵分解(NMF)的方法，看看我们的主题是否可以稍微更加明确。我们将使用 TF-IDF(术语频率-逆文档频率)方法，而不是使用简单的 CountVectorizer 方法来对我们的单词/标记进行矢量化。TF-IDF 方法有助于降低高频词的权重/影响(即在我们的例子中是“工作”、“谷歌”和“工作”)。</p><p id="c7a6" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">与 CountVectorizer 方法非常相似，我们首先创建矢量器对象。Max_df=0.9 将删除出现在 90%以上评论中的单词。Min_df=25 将删除出现在少于 25 条评论中的单词。接下来，我们创建备用矩阵作为 fit_transform()的结果。最后，我们创建一个所有单词/特征的列表。</p><pre class="kj kk kl km gt lv lw lx ly aw lz bi"><span id="7308" class="ma mb it lw b gy mc md l me mf">tfidf_vectorizer = TfidfVectorizer(max_df=0.90, min_df =25, max_features=5000, use_idf=True)</span><span id="dbd6" class="ma mb it lw b gy mg md l me mf">tfidf = tfidf_vectorizer.fit_transform(df['lemma_str'])<br/>tfidf_feature_names = tfidf_vectorizer.get_feature_names()</span><span id="9e71" class="ma mb it lw b gy mg md l me mf">doc_term_matrix_tfidf = pd.DataFrame(tfidf.toarray(), columns=list(tfidf_feature_names))<br/>doc_term_matrix_tfidf</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi om"><img src="../Images/58c61ac28143c2370c80a32cc1b6d099.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*2oRsp-RCfzpgT1JKHFwk3g.png"/></div></div></figure><h2 id="802f" class="ma mb it bd mk ny nz dn mo oa ob dp ms li oc od mu lm oe of mw lq og oh my oi bi translated">非负矩阵分解(NMF)</h2><pre class="kj kk kl km gt lv lw lx ly aw lz bi"><span id="c396" class="ma mb it lw b gy mc md l me mf">nmf = NMF(n_components=10, random_state=0, alpha=.1, init='nndsvd').fit(tfidf)</span><span id="e6c9" class="ma mb it lw b gy mg md l me mf">display_topics(nmf, tfidf_feature_names, no_top_words)</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi on"><img src="../Images/94c3423441276812042010c7183e66a0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1380/format:webp/1*7fCpOTpgpjDB_0-SDTcuQA.png"/></div></figure><p id="29fe" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">与 LDA 相比，通过 NMF 制作的主题似乎更加独特。</p><p id="3cc3" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">话题 0:有趣的工作文化</p><p id="3194" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">主题 1:设计过程</p><p id="3cb8" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">话题 2:愉快的工作</p><p id="60e5" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">主题 3:</p><p id="89eb" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">话题四:绝佳体验</p><p id="d11a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">话题 5:额外津贴</p><p id="d61d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">主题 6:学习机会</p><p id="47b9" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">话题 7:伟大的公司/工作</p><p id="ac5b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">主题 8:承包商员工体验</p><p id="73c6" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">主题 9:管理</p><p id="ab46" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">让我们把 LDA 和 NMF 的话题都添加到我们的数据框架中，以便进一步分析。让我们也将整数主题重新映射到我们主观导出的主题标签中。</p><pre class="kj kk kl km gt lv lw lx ly aw lz bi"><span id="ff1b" class="ma mb it lw b gy mc md l me mf">nmf_topic_values = nmf.transform(tfidf)<br/>df['nmf_topics'] = nmf_topic_values.argmax(axis=1)<br/>lda_topic_values = lda_model.transform(tf)<br/>df['lda_topics'] = lda_topic_values.argmax(axis=1)</span><span id="a370" class="ma mb it lw b gy mg md l me mf">lda_remap = {0: 'Good Design Processes', 1: 'Great Work Environment', 2: 'Flexible Work Hours', 3: 'Skill Building', 4: 'Difficult but Enjoyable Work', 5: 'Great Company/Job', 6: 'Care about Employees', 7: 'Great Contractor Pay', 8: 'Customer Service', 9: 'Unknown1'}</span><span id="bcf1" class="ma mb it lw b gy mg md l me mf">df['lda_topics'] = df['lda_topics'].map(lda_remap)</span><span id="a483" class="ma mb it lw b gy mg md l me mf">nmf_remap = {0: 'Fun Work Culture', 1: 'Design Process', 2: 'Enjoyable Job', 3: 'Difficult but Enjoyable Work', <br/>             4: 'Great Experience', 5: 'Perks', 6: 'Learning Opportunities', 7: 'Great Company/Job', <br/>             8: 'Contractor Employee Experience', 9: 'Management'}</span><span id="7f0f" class="ma mb it lw b gy mg md l me mf">df['nmf_topics'] = df['nmf_topics'].map(nmf_remap)</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nj"><img src="../Images/960709462c67770ee351f1df0355bcab.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*pZ1BRPh8LFxvk5L1VCzWrQ.png"/></div></div></figure><p id="8029" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">检查由 NMF 产生的主题的频率，我们可以看到前 5 个主题以相对相似的频率出现。请记住，这些是所有评论(正面、中立和负面)的主题，如果您记得我们的数据集是负面倾斜的，因为大多数评论都是正面的。</p><pre class="kj kk kl km gt lv lw lx ly aw lz bi"><span id="55f1" class="ma mb it lw b gy mc md l me mf">nmf_x = df['nmf_topics'].value_counts()<br/>nmf_y = nmf_x.sort_index()<br/>plt.figure(figsize=(50,30))<br/>sns.barplot(nmf_x, nmf_y.index)<br/>plt.title("NMF Topic Distribution", fontsize=50)<br/>plt.ylabel('Review Topics', fontsize=50)<br/>plt.yticks(fontsize=40)<br/>plt.xlabel('Frequency', fontsize=50)<br/>plt.xticks(fontsize=40)</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nx"><img src="../Images/5c1ab1a6ef1066706e75da65386d2f43.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*y5d0WTVCBN5pBJqOjgBD1g.png"/></div></div></figure><p id="4a02" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">让我们将数据分开，根据评分 1 和 2 检查负面评论的主题。有趣的是，尽管有负面评价，员工们仍然非常喜欢他们的工作、文化和整个公司。由于我们数据集的偏斜，很难获得关于负面评论主题的准确观点(即相对少量的负面评论)。</p><pre class="kj kk kl km gt lv lw lx ly aw lz bi"><span id="0a45" class="ma mb it lw b gy mc md l me mf">df_low_ratings = df.loc[(df['rating']==1) | (df['rating']==2)]</span><span id="a8bd" class="ma mb it lw b gy mg md l me mf">nmf_low_x = df_low_ratings['nmf_topics'].value_counts()<br/>nmf_low_y = nmf_low_x.sort_index()<br/>plt.figure(figsize=(50,30))<br/>sns.barplot(nmf_low_x, nmf_low_y.index)<br/>plt.title("NMF Topic Distribution for Low Ratings (1 &amp; 2)", fontsize=50)<br/>plt.ylabel('Frequency', fontsize=50)<br/>plt.yticks(fontsize=40)<br/>plt.xlabel('Review Topics', fontsize=50)<br/>plt.xticks(fontsize=40)</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oo"><img src="../Images/3c0ea607bedcab7255bf8ec2610e3dab.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*uuZFUCHjWtMlv59G3MAx-A.png"/></div></div></figure><p id="1eed" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">因为我们有更多正面的评论，所以通过 NMF 获得的话题会更准确。似乎承包商雇员构成了许多评论。员工们发现了一个高效的设计过程，工作虽然艰难但却令人愉快，并且对谷歌有一种总体上愉快的情绪。</p><pre class="kj kk kl km gt lv lw lx ly aw lz bi"><span id="1187" class="ma mb it lw b gy mc md l me mf">df_high_ratings = df.loc[(df['rating']==4) | (df['rating']==5)]</span><span id="00b1" class="ma mb it lw b gy mg md l me mf">nmf_high_x = df_high_ratings['nmf_topics'].value_counts()<br/>nmf_high_y = nmf_high_x.sort_index()<br/>plt.figure(figsize=(50,30))<br/>sns.barplot(nmf_high_x, nmf_high_y.index)<br/>plt.title("NMF Topic Distribution for High Ratings (3 &amp; 4)", fontsize=50)<br/>plt.ylabel('Frequency', fontsize=50)<br/>plt.yticks(fontsize=40)<br/>plt.xlabel('Review Topics', fontsize=50)<br/>plt.xticks(fontsize=40)</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oo"><img src="../Images/a5e68bf628971d2c29ae3925d0ea2547.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*xpK-42qeuS732upQP9U2Kw.png"/></div></div></figure><h1 id="20a5" class="mj mb it bd mk ml mm mn mo mp mq mr ms jz mt ka mu kc mv kd mw kf mx kg my mz bi translated">结论</h1><p id="a835" class="pw-post-body-paragraph kz la it lb b lc na ju le lf nb jx lh li nc lk ll lm nd lo lp lq ne ls lt lu im bi translated">从调查结果来看，谷歌的员工似乎非常乐于在谷歌工作。我们看到一个负偏态分布，84%的员工给谷歌打了 4 或 5 分(满分为 1-5 分的李克特量表)。一项情绪分析证实了这些结果，即使给谷歌打 2 到 3 分的员工平均情绪得分为正。</p><p id="18bf" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">随着我们对数据的进一步挖掘，我们发现了一个有趣的现象，这需要用更多的数据来验证。当我们观察每个等级的术语/词频时，似乎“<em class="nr">经理/管理层”</em>周围的术语似乎出现在等级 1、2 和 3 中。如前所述，数据是有偏差的，因为大多数评级都是正面的，但有趣的是，有负面或中性评级的员工似乎经常提到<em class="nr">【管理层】</em>。</p><p id="3671" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">另一方面，给谷歌打 4 到 5 分的员工似乎在使用诸如<em class="nr">、【伟大】、【工作】、【工作】、【设计】、【公司】、【好】、【文化】、【人】等词汇。这些结果通过对我们语料库中的话题/主题的检查得到了轻微的证实。NMF 对主题的分析表明，给谷歌打 4 或 5 分的员工渴望讨论困难但愉快的工作、伟大的文化和设计过程。有趣的是，我们还看到没有提到“经理”和“管理”这样的术语，这也说明并有助于验证我们之前的见解。</em></p><p id="1069" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">谷歌仍然是许多人首选的雇主，84%的评论是正面的。也就是说，我们从谷歌的管理者和/或管理技术中发现了一个潜在的改进领域。</p><p id="2d76" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">你能想到我们可以探索的任何其他 EDA 方法和/或策略吗？把它们贴在下面的评论里。此外，如果你有任何建设性的反馈或看到我犯了一个错误，请叫我出来😃</p><h1 id="8d75" class="mj mb it bd mk ml mm mn mo mp mq mr ms jz mt ka mu kc mv kd mw kf mx kg my mz bi translated"><strong class="ak">谢谢！</strong></h1></div></div>    
</body>
</html>