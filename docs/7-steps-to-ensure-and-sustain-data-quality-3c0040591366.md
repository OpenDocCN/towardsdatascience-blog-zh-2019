# 确保和维持数据质量的 7 个步骤

> 原文：<https://towardsdatascience.com/7-steps-to-ensure-and-sustain-data-quality-3c0040591366?source=collection_archive---------1----------------------->

![](img/641c4e47f0d2b50dfc308c51391ce3ff.png)

Image by [Gerd Altmann](https://pixabay.com/users/geralt-9301/?utm_source=link-attribution&utm_medium=referral&utm_campaign=image&utm_content=3530353) from [Pixabay](https://pixabay.com/?utm_source=link-attribution&utm_medium=referral&utm_campaign=image&utm_content=3530353) (CC0)

几年前，我遇到了一个大公司的高级主管。他提到，他工作的公司面临着影响客户满意度的数据质量问题，他花了几个月的时间调查潜在的原因以及如何解决这些问题。“你发现了什么？”我急切地问。“这是一个棘手的问题。我没有找到一个单一的原因，相反，许多事情出了差错，”他回答说。然后，他开始列举一长串导致数据质量问题的原因——几乎公司的每个部门都参与其中，他很难决定下一步从哪里开始。这是处理数据质量的一个典型案例，数据质量直接关系到一个组织如何开展业务以及数据本身的整个生命周期。

在数据科学成为主流之前，对于交付给内部或外部客户的报告，数据质量最常被提及。如今，由于机器学习需要大量的训练数据，组织内部的数据集需求很大。此外，分析人员总是渴望获得数据，并不断搜索可能增加价值的数据资产，这导致人们快速采用以前未探索或使用过的新数据集或数据源。这一趋势使得数据管理和确保良好数据质量的良好实践比以往任何时候都更加重要。

本文的目标是让您清楚地了解如何构建一个数据管道，从一开始就创建并维持良好的数据质量。换句话说，数据质量不是通过发现问题并修复问题就能从根本上改善的。相反，每个组织都应该首先从生产高质量的数据开始。

首先，什么是数据质量？一般来说，当数据满足客户、决策者、下游应用程序和流程的预期用途要求时，它就是高质量的。一个很好的类比是制造商生产的产品质量，对于制造商来说，好的产品质量不是业务成果，而是推动客户满意度并影响产品本身的价值和生命周期。同样，数据质量也是一个重要的属性，它可以推动数据的价值，从而影响业务成果的各个方面，如法规遵从性、客户满意度或决策的准确性。下面列出了用于衡量数据质量的 5 个主要标准:

*   **准确性:**无论描述什么数据，都需要准确。
*   **相关性:**数据应满足预期用途的要求。
*   **完整性:**数据不应有缺失值或缺失数据记录。
*   **时效性:**数据要最新。
*   **一致性:**数据应该具有预期的数据格式，并且可以与相同的结果进行交叉引用。

良好数据质量的标准可能因要求和数据本身的性质而异。例如，一家公司的核心客户数据集需要满足上述标准的非常高的标准，而对于第三方数据源，可能存在更高的错误或不完整性容忍度。对于一个交付高质量数据的组织来说，它需要从头到尾管理和控制在管道中创建的每个数据存储。许多组织只是关注最终数据，并在数据交付之前投资于数据质量控制工作。这还不够好，而且通常情况下，当问题最终被发现时，已经太晚了—要么需要很长时间才能找到问题的来源，要么解决问题的成本和时间都太长了。**然而，如果一个公司能够在接收或创建每个数据集时管理其数据质量，那么数据质量自然是有保证的。实现这一目标有 7 个基本步骤:**

**1。严格的数据分析和输入数据控制**

大多数情况下，坏数据来自数据接收。在一个组织中，数据通常来自公司或部门控制之外的其他来源。它可能是从另一个组织发送的数据，或者在许多情况下是由第三方软件收集的数据。因此，其数据质量无法得到保证，对输入数据进行严格的数据质量控制可能是所有数据质量控制任务中最重要的方面。一个好的数据分析工具就派上了用场；这种工具应该能够检查数据的以下方面:

*   数据格式和数据模式
*   每个记录的数据一致性
*   数据值分布和异常
*   数据的完整性

此外，还必须实现数据分析和数据质量警报的自动化，以便无论何时收到传入数据，都可以对其质量进行一致的控制和管理——在没有进行分析和检查的情况下，永远不要认为传入数据与预期的一样好。最后，应该使用相同的标准和最佳实践来管理每个传入的数据，并且应该建立一个集中的目录和 KPI 仪表板来准确记录和监控数据的质量。

**2。精心设计数据管道，避免重复数据**

重复数据是指全部或部分数据是使用相同的逻辑从相同的数据源创建的，但是由不同的人或团队出于不同的下游目的创建的。当创建重复数据时，它很可能不同步，并导致不同的结果，在多个系统或数据库中产生级联效应。最后，当出现数据问题时，跟踪根本原因变得困难或耗时，更不用说修复它了。

为了防止这种情况发生，组织需要在数据资产、数据建模、业务规则和体系结构等领域对数据管道进行清晰的定义和精心的设计。还需要有效的沟通来促进和加强组织内的数据共享，这将提高整体效率，减少数据重复造成的任何潜在的数据质量问题。这涉及到数据管理的核心，其细节超出了本文的范围。概括地说，需要建立 3 个方面来防止创建重复数据:

1.  数据治理计划，明确定义数据集的所有权，并有效沟通和促进数据集共享，以避免任何部门孤岛。
2.  集中式数据资产管理和数据建模，并定期进行审查和审计。
3.  企业级数据管道的清晰逻辑设计，在整个组织内共享。

随着当今技术平台的快速变化，可靠的数据管理和企业级数据治理对于未来成功的平台迁移至关重要。

**3。准确收集数据要求**

拥有良好的数据质量的一个重要方面是满足需求，并根据数据的用途将数据交付给客户端和用户。这并不像听起来那么简单，因为:

*   恰当地呈现数据并不容易。真正理解客户的需求需要彻底的数据发现、数据分析和清晰的沟通，通常是通过数据示例和可视化。
*   需求应该捕获所有的数据条件和场景——如果没有评审和记录所有的依赖关系或条件，那么它就被认为是不完整的。
*   清晰的需求文档，易于访问和共享，是另一个重要的方面，应该由数据治理委员会强制执行。

业务分析师的角色在需求收集中是必不可少的。他们对客户以及当前系统的了解，让他们能够说双方的语言。在收集了需求之后，业务分析师还执行影响分析，并帮助提出测试计划，以确保生成的数据满足需求。

**4。数据完整性的实施**

关系数据库的一个重要特性是能够使用外键、检查约束和触发器等技术来加强数据完整性。随着数据量的增长，以及越来越多的数据源和可交付成果，并非所有数据集都可以存在于单个数据库系统中。因此，数据的引用完整性需要由应用程序和流程来实施，它们需要由数据治理的最佳实践来定义，并包含在实现的设计中。在当今的大数据世界中，引用实施变得越来越困难。如果一开始就没有实施完整性的观念，引用的数据可能会过时、不完整或延迟，从而导致严重的数据质量问题。

**5。将数据谱系可追溯性集成到数据管道中**

对于设计良好的数据管道，解决数据问题的时间不应随着系统的复杂性或数据量的增加而增加。如果没有管道中内置的数据沿袭可追溯性，当数据问题发生时，可能需要几个小时或几天才能找到原因。有时它可能会经过多个团队，需要数据工程师查看代码进行调查。

数据沿袭可追溯性有两个方面:

*   **元数据:**追踪数据集、数据字段之间的关系以及它们之间的转换逻辑的能力。
*   **数据本身:**快速跟踪数据问题到上游数据源中的单个记录的能力。

元数据可追溯性是有效数据治理的重要组成部分。这是通过从一开始就对每个数据集(包括其字段和结构)进行清晰的文档记录和建模来实现的。当数据管道由数据治理设计和执行时，应该同时建立元数据可追溯性。如今，元数据沿袭跟踪是市场上任何数据治理工具的必备功能，这使得通过几次点击来存储和跟踪数据集和字段变得更加容易，而不是让数据专家浏览文档、数据库甚至程序。

数据追溯比元数据追溯更难。下面列出了实现这种能力的一些常用技术:

1.  通过每个数据集的唯一键进行跟踪:这首先要求每个数据集有一个或一组唯一键，然后通过管道传递到下游数据集。但是，并不是每个数据集都可以通过唯一键进行跟踪。例如，当数据集被聚合时，来自源的键会在聚合数据中丢失。
2.  当数据本身没有明显的唯一键时，构建一个唯一的序列号，例如事务标识符或记录标识符。
3.  当存在多对多关系，而不是一对一或一对多关系时，构建链接表。
4.  为每个数据记录添加时间戳(或版本),以表明它是何时添加或更改的。
5.  在日志表中记录数据更改，包括更改前的值和更改发生时的时间戳

数据可追溯性需要时间来设计和实现。然而，对于数据架构师和工程师来说，从一开始就将其构建到管道中具有战略重要性；考虑到当数据质量问题发生时，这将节省大量的时间，这绝对是值得的。此外，数据可追溯性为进一步改进数据质量报告和仪表板奠定了基础，使人们能够在数据交付给客户或内部用户之前尽早发现数据问题。

**6。作为变更管理一部分的自动化回归测试**

显然，当引入新数据集或修改现有数据集时，数据质量问题经常发生。为了有效的变更管理，测试计划应该建立两个主题:1)确认变更满足需求；2)确保改变不会对管道中不应该改变的数据产生无意的影响。对于任务关键型数据集，当发生变化时，应对每个可交付成果实施常规回归测试，并对数据集的每个字段和每一行进行比较。随着大数据技术的快速进步，系统迁移在几年内不断发生。具有彻底数据比较的自动化回归测试是必须的，以确保始终保持良好的数据质量。

**7。有能力的数据质量控制团队**

最后，两类团队在确保组织的高数据质量方面发挥着关键作用:

**质量保证:**这个团队检查软件和程序的质量，无论何时发生变化。该团队执行的严格变更管理对于确保组织中的数据质量至关重要，因为该组织正在经历数据密集型应用程序的快速转变和变化。

**生产质量控制:**根据组织的不同，这个团队并不一定是一个独立的团队。有时它可能是质量保证或业务分析师团队的一个功能。团队需要很好地理解业务规则和业务需求，并配备工具和仪表板，以检测生产中发生的异常、异常值、中断的趋势和任何其他不寻常的场景。该团队的目标是识别任何数据质量问题，并在用户和客户之前解决这些问题。这个团队还需要与客户服务团队合作，可以从客户那里获得直接反馈，并快速解决他们的问题。随着现代人工智能技术的进步，效率可能会大幅提高。然而，正如本文开头所述，最终的质量控制是必要的，但不足以确保公司创建和维持良好的数据质量。上述 6 个步骤也是必需的。

**总结**

总之，良好的数据质量需要严格的数据治理、对传入数据的严格管理、准确的需求收集、针对变更管理的全面回归测试以及数据管道的精心设计，此外还需要针对外部和内部交付数据的数据质量控制计划。对于所有质量问题，从一开始就防止数据问题的发生要比依靠防御系统和临时修复来处理数据质量问题容易得多，成本也低得多。最后，通过遵循本文中的 7 个步骤，良好的数据质量不仅可以得到保证，而且可以持续下去。