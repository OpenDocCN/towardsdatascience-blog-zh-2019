<html>
<head>
<title>Building a Better Profanity Detection Library with scikit-learn</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">用 scikit-learn 构建一个更好的亵渎检测库</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/building-a-better-profanity-detection-library-with-scikit-learn-3638b2f2c4c2?source=collection_archive---------9-----------------------#2019-02-04">https://towardsdatascience.com/building-a-better-profanity-detection-library-with-scikit-learn-3638b2f2c4c2?source=collection_archive---------9-----------------------#2019-02-04</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="1e79" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">为什么现有的库没有启发性，以及我如何建立一个更好的库。</h2></div><p id="6095" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">几个月前，我需要一种方法来检测用户提交的文本字符串中的亵渎内容:</p><figure class="lf lg lh li gt lj gh gi paragraph-image"><div class="gh gi le"><img src="../Images/eb88bd0c7740c2420230e1039dcecc2e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1368/format:webp/1*i2fk4aGvplR7le_3PPajAA.png"/></div><figcaption class="lm ln gj gh gi lo lp bd b be z dk">This shouldn’t be that hard, right?</figcaption></figure><p id="b7fe" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">为此，我最终构建并发布了自己的库，名为<a class="ae lq" href="https://github.com/vzhou842/profanity-check" rel="noopener ugc nofollow" target="_blank">亵渎检查</a>:</p><div class="lr ls gp gr lt lu"><a href="https://github.com/vzhou842/profanity-check" rel="noopener  ugc nofollow" target="_blank"><div class="lv ab fo"><div class="lw ab lx cl cj ly"><h2 class="bd iu gy z fp lz fr fs ma fu fw is bi translated">vzhou 842/亵渎性检查</h2><div class="mb l"><h3 class="bd b gy z fp lz fr fs ma fu fw dk translated">一个快速、健壮的 Python 库，用于检查字符串中的攻击性语言。-vzhou 842/亵渎-检查</h3></div><div class="mc l"><p class="bd b dl z fp lz fr fs ma fu fw dk translated">github.com</p></div></div><div class="md l"><div class="me l mf mg mh md mi lk lu"/></div></div></a></div><p id="2dce" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">当然，在我这么做之前，我在<a class="ae lq" href="https://pypi.org/" rel="noopener ugc nofollow" target="_blank"> Python 包索引</a> (PyPI)中寻找任何可以为我做这件事的现有库。搜索查询“亵渎”得到的结果只有一半还不错:</p><ul class=""><li id="c22f" class="mj mk it kk b kl km ko kp kr ml kv mm kz mn ld mo mp mq mr bi translated"><a class="ae lq" href="https://pypi.org/project/profanity/" rel="noopener ugc nofollow" target="_blank">脏话</a>(理想的包名)</li><li id="dedb" class="mj mk it kk b kl ms ko mt kr mu kv mv kz mw ld mo mp mq mr bi translated"><a class="ae lq" href="https://pypi.org/project/better-profanity/" rel="noopener ugc nofollow" target="_blank">更好——亵渎</a> : <em class="mx">“灵感来自包</em> <a class="ae lq" href="https://github.com/ben174/profanity" rel="noopener ugc nofollow" target="_blank"> <em class="mx">亵渎</em> <a class="ae lq" href="https://github.com/ben174" rel="noopener ugc nofollow" target="_blank"> <em class="mx">本·弗里德兰</em> </a> <em class="mx">的</em> </a> <em class="mx">，这个库比原来的快多了。”</em></li><li id="80ae" class="mj mk it kk b kl ms ko mt kr mu kv mv kz mw ld mo mp mq mr bi translated"><a class="ae lq" href="https://pypi.org/project/profanityfilter/" rel="noopener ugc nofollow" target="_blank">亵渎过滤器</a>(有 31 颗 Github 星，比大多数其他结果多 30 颗)</li><li id="1c23" class="mj mk it kk b kl ms ko mt kr mu kv mv kz mw ld mo mp mq mr bi translated"><a class="ae lq" href="https://pypi.org/project/profanity-filter/" rel="noopener ugc nofollow" target="_blank">脏话过滤</a>(采用机器学习，说够了吧？！)</li></ul><p id="8538" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">然而，第三方库有时可能是粗略的，所以我对这 4 个结果做了尽职调查。</p><h1 id="f96b" class="my mz it bd na nb nc nd ne nf ng nh ni jz nj ka nk kc nl kd nm kf nn kg no np bi translated">亵渎，更好的亵渎，亵渎过滤器</h1><p id="dea7" class="pw-post-body-paragraph ki kj it kk b kl nq ju kn ko nr jx kq kr ns kt ku kv nt kx ky kz nu lb lc ld im bi translated">在快速浏览了一下<code class="fe nv nw nx ny b">profanity</code>存储库之后，我找到了一个名为<a class="ae lq" href="https://github.com/ben174/profanity/blob/master/profanity/data/wordlist.txt" rel="noopener ugc nofollow" target="_blank"> wordlist.txt </a>的文件:</p><figure class="lf lg lh li gt lj gh gi paragraph-image"><div role="button" tabindex="0" class="oa ob di oc bf od"><div class="gh gi nz"><img src="../Images/eac97d63c72dd921eb1b1ec5827d89dd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*0lTbmHR5WE7HZ8wCvLpqtg.png"/></div></div><figcaption class="lm ln gj gh gi lo lp bd b be z dk">Sorry this image of profanities is so big…</figcaption></figure><p id="de59" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">整个<code class="fe nv nw nx ny b">profanity</code>库只是这个 32 个单词列表的包装器！<code class="fe nv nw nx ny b">profanity</code>只需查找其中一个单词就能检测出亵渎。</p><p id="d7e6" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">令我沮丧的是，<code class="fe nv nw nx ny b">better-profanity</code>和<code class="fe nv nw nx ny b">profanityfilter</code>都采取了同样的方法:</p><ul class=""><li id="868f" class="mj mk it kk b kl km ko kp kr ml kv mm kz mn ld mo mp mq mr bi translated"><code class="fe nv nw nx ny b">better-profanity</code>使用<a class="ae lq" href="https://github.com/snguyenthanh/better_profanity/blob/master/better_profanity/profanity_wordlist.txt" rel="noopener ugc nofollow" target="_blank">一个 140 字的单词表</a></li><li id="4c80" class="mj mk it kk b kl ms ko mt kr mu kv mv kz mw ld mo mp mq mr bi translated"><code class="fe nv nw nx ny b">profanityfilter</code>使用<a class="ae lq" href="https://github.com/areebbeigh/profanityfilter/blob/master/profanityfilter/data/badwords.txt" rel="noopener ugc nofollow" target="_blank">一个 418 字的单词表</a></li></ul><p id="3b48" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">这很糟糕，因为<strong class="kk iu">基于单词表的亵渎检测库非常主观。</strong>例如，<code class="fe nv nw nx ny b">better-profanity</code>的单词列表中就包含了单词“suck”你愿意说任何包含“吸”字的句子都是亵渎吗？此外，任何硬编码的不良词汇列表将不可避免地是不完整的——你认为只有<code class="fe nv nw nx ny b">profanity</code>的 32 个不良词汇吗？</p><figure class="lf lg lh li gt lj gh gi paragraph-image"><div class="gh gi oe"><img src="../Images/a7e341f1c261d28e1338a6bd8cd1c1fa.png" data-original-src="https://miro.medium.com/v2/resize:fit:700/format:webp/1*n5OWj4WEPkGexXO28_yteg.png"/></div><figcaption class="lm ln gj gh gi lo lp bd b be z dk">Fucking Blue Shells. source: <a class="ae lq" href="https://xkcd.com/290/" rel="noopener ugc nofollow" target="_blank">xkcd</a></figcaption></figure><p id="0e60" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">已经排除了 3 个库，我把希望放在了第 4 个也是最后一个:<code class="fe nv nw nx ny b">profanity-filter</code>。</p><h1 id="24af" class="my mz it bd na nb nc nd ne nf ng nh ni jz nj ka nk kc nl kd nm kf nn kg no np bi translated">脏话过滤器</h1><p id="5b37" class="pw-post-body-paragraph ki kj it kk b kl nq ju kn ko nr jx kq kr ns kt ku kv nt kx ky kz nu lb lc ld im bi translated"><code class="fe nv nw nx ny b">profanity-filter</code>使用机器学习！太棒了。</p><p id="9903" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">原来，是<strong class="kk iu"> <em class="mx">真的</em> </strong>慢。下面是我在 2018 年 12 月运行的一个基准测试，比较了(1) <code class="fe nv nw nx ny b">profanity-filter</code>、(2)我的库<code class="fe nv nw nx ny b">profanity-check</code>、(3) <code class="fe nv nw nx ny b">profanity</code>(有 32 个单词列表的那个):</p><figure class="lf lg lh li gt lj gh gi paragraph-image"><div role="button" tabindex="0" class="oa ob di oc bf od"><div class="gh gi of"><img src="../Images/78bfdd2021bac5bd4b66763b0a260236.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*KRJEl4YHfSTk9PmmScIcUA.png"/></div></div><figcaption class="lm ln gj gh gi lo lp bd b be z dk">A human could probably do this faster than profanity-filter can</figcaption></figure><p id="f181" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我需要能够实时执行许多预测，而<code class="fe nv nw nx ny b">profanity-filter</code>甚至还不够快。但是，嘿，也许这是一个经典的速度与准确性的权衡，对不对？</p><p id="0309" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">没有。</p><figure class="lf lg lh li gt lj gh gi paragraph-image"><div role="button" tabindex="0" class="oa ob di oc bf od"><div class="gh gi og"><img src="../Images/55984481082f3c04804927d4d7cc3505.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*LYOeGE6vTXTAKhJ_W1fZgQ.png"/></div></div><figcaption class="lm ln gj gh gi lo lp bd b be z dk">At least profanity-filter is not dead last this time</figcaption></figure><p id="4a66" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我在 PyPI 上找到的库都不能满足我的需求，所以我自己建了一个。</p><h1 id="29d7" class="my mz it bd na nb nc nd ne nf ng nh ni jz nj ka nk kc nl kd nm kf nn kg no np bi translated">建筑物亵渎检查第 1 部分:数据</h1><p id="b6b9" class="pw-post-body-paragraph ki kj it kk b kl nq ju kn ko nr jx kq kr ns kt ku kv nt kx ky kz nu lb lc ld im bi translated">我知道我希望<code class="fe nv nw nx ny b">profanity-check</code>基于数据进行分类，以避免主观<em class="mx">(理解为:可以说我使用了机器学习)</em>。我从两个公开来源收集了一个综合数据集:</p><ul class=""><li id="2189" class="mj mk it kk b kl km ko kp kr ml kv mm kz mn ld mo mp mq mr bi translated">来自<a class="ae lq" href="https://github.com/t-davidson/hate-speech-and-offensive-language/tree/master/data" rel="noopener ugc nofollow" target="_blank">t-Davidson/仇恨言论和攻击性语言</a>的“推特”数据集，包含从推特上抓取的推文。</li><li id="d855" class="mj mk it kk b kl ms ko mt kr mu kv mv kz mw ld mo mp mq mr bi translated">Alphabet 的<a class="ae lq" href="https://conversationai.github.io/" rel="noopener ugc nofollow" target="_blank"> Conversation AI </a>团队发布的来自<a class="ae lq" href="https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge" rel="noopener ugc nofollow" target="_blank"> this Kaggle competition </a>的“维基百科”数据集，其中包含来自维基百科 talk page edits 的评论。</li></ul><p id="9699" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">这些数据集中的每一个都包含了文本样本，这些样本是由人们通过众包网站手工标注的，比如<a class="ae lq" href="https://www.figure-eight.com/" rel="noopener ugc nofollow" target="_blank">Figure 8</a>。</p><p id="2637" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我的数据集最终看起来是这样的:</p><figure class="lf lg lh li gt lj gh gi paragraph-image"><div role="button" tabindex="0" class="oa ob di oc bf od"><div class="gh gi oh"><img src="../Images/05bb8a65359f19b5b9756ad6a685d1e0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Bw_we8cbs-WOpWXOCxzSTg.png"/></div></div><figcaption class="lm ln gj gh gi lo lp bd b be z dk">Combined = Tweets + Wikipedia</figcaption></figure><blockquote class="oi oj ok"><p id="0a51" class="ki kj mx kk b kl km ju kn ko kp jx kq ol ks kt ku om kw kx ky on la lb lc ld im bi translated">Twitter 数据集有一个名为<code class="fe nv nw nx ny b">class</code>的列，如果推文包含仇恨言论，则为 0，如果包含攻击性语言，则为 1，如果两者都不包含，则为 2。我将任何一条<code class="fe nv nw nx ny b">class</code>为 2 的推文归类为“不冒犯”，而将所有其他推文归类为“冒犯”。</p><p id="68d7" class="ki kj mx kk b kl km ju kn ko kp jx kq ol ks kt ku om kw kx ky on la lb lc ld im bi translated">维基百科数据集有几个二进制列(如<code class="fe nv nw nx ny b">toxic</code>或<code class="fe nv nw nx ny b">threat</code>)，表示该文本是否包含该类型的毒性。我将任何包含毒性类型的文本归类为“攻击性的”，而将所有其他文本归类为“非攻击性的”</p></blockquote><h1 id="1e9b" class="my mz it bd na nb nc nd ne nf ng nh ni jz nj ka nk kc nl kd nm kf nn kg no np bi translated">建筑亵渎检查，第 2 部分:培训</h1><p id="a635" class="pw-post-body-paragraph ki kj it kk b kl nq ju kn ko nr jx kq kr ns kt ku kv nt kx ky kz nu lb lc ld im bi translated">现在有了一个干净的组合数据集(你可以<a class="ae lq" href="https://github.com/vzhou842/profanity-check/blob/master/profanity_check/data/clean_data.csv" rel="noopener ugc nofollow" target="_blank">在这里</a>下载)，我已经准备好训练这个模型了！</p><blockquote class="oi oj ok"><p id="c828" class="ki kj mx kk b kl km ju kn ko kp jx kq ol ks kt ku om kw kx ky on la lb lc ld im bi translated">我跳过了我是如何清理数据集的，因为老实说，这很无聊——如果你有兴趣了解更多关于预处理文本数据集的信息，请查看<a class="ae lq" href="https://machinelearningmastery.com/clean-text-machine-learning-python/" rel="noopener ugc nofollow" target="_blank">这个</a>或<a class="ae lq" href="https://medium.com/@datamonsters/text-preprocessing-in-python-steps-tools-and-examples-bf025f872908" rel="noopener">这个</a>。</p></blockquote><figure class="lf lg lh li gt lj"><div class="bz fp l di"><div class="oo op l"/></div><figcaption class="lm ln gj gh gi lo lp bd b be z dk">Are you also surprised the code is so short? Apparently <a class="ae lq" href="https://scikit-learn.org/" rel="noopener ugc nofollow" target="_blank">scikit-learn</a> does everything.</figcaption></figure><p id="073a" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">这里有两个主要步骤:(1)矢量化和(2)训练。</p><h2 id="6db4" class="oq mz it bd na or os dn ne ot ou dp ni kr ov ow nk kv ox oy nm kz oz pa no pb bi translated">矢量化:单词包</h2><p id="ac3e" class="pw-post-body-paragraph ki kj it kk b kl nq ju kn ko nr jx kq kr ns kt ku kv nt kx ky kz nu lb lc ld im bi translated">我使用了<code class="fe nv nw nx ny b">scikit-learn</code>的<a class="ae lq" href="https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html" rel="noopener ugc nofollow" target="_blank"> CountVectorizer </a>类，它基本上通过计算每个给定单词出现的次数，将任何文本字符串转换成一个向量。这就是所谓的<a class="ae lq" href="https://victorzhou.com/blog/bag-of-words/" rel="noopener ugc nofollow" target="_blank">袋字</a>(鞠躬)表示法。例如，如果英语中仅有的单词是<code class="fe nv nw nx ny b">the</code>、<code class="fe nv nw nx ny b">cat</code>、<code class="fe nv nw nx ny b">sat</code>和<code class="fe nv nw nx ny b">hat</code>，则句子<code class="fe nv nw nx ny b">the cat sat in the hat</code>的可能矢量化结果可能是:</p><figure class="lf lg lh li gt lj gh gi paragraph-image"><div class="gh gi pc"><img src="../Images/e7c04daee6a453b6c453b54e9a01d46d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1228/format:webp/1*sbnts1u_QFB_V-X5DSC3pg.png"/></div><figcaption class="lm ln gj gh gi lo lp bd b be z dk">“the cat sat in the hat” -&gt; [2, 1, 1, 1, 1]</figcaption></figure><p id="7f81" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><code class="fe nv nw nx ny b">???</code>代表任何未知单词，对于这个句子来说就是<code class="fe nv nw nx ny b">in</code>。任何句子都可以这样表示为<code class="fe nv nw nx ny b">the</code>、<code class="fe nv nw nx ny b">cat</code>、<code class="fe nv nw nx ny b">sat</code>、<code class="fe nv nw nx ny b">hat</code>和<code class="fe nv nw nx ny b">???</code>的计数！</p><figure class="lf lg lh li gt lj gh gi paragraph-image"><div role="button" tabindex="0" class="oa ob di oc bf od"><div class="gh gi pd"><img src="../Images/f6420ed4dbe5ea8afb1b89b746cd8366.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*-wONWZDab2gNQP3Rfdpt_A.png"/></div></div><figcaption class="lm ln gj gh gi lo lp bd b be z dk">A handy reference table for the next time you need to vectorize “cat cat cat cat cat”</figcaption></figure><p id="bead" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">当然，英语中有更多的单词，所以在上面的代码中我使用了<code class="fe nv nw nx ny b">fit_transform()</code>方法，它做了两件事:</p><ul class=""><li id="36c3" class="mj mk it kk b kl km ko kp kr ml kv mm kz mn ld mo mp mq mr bi translated"><strong class="kk iu"> Fit: </strong>通过查看数据集中出现的所有单词来学习词汇。</li><li id="f389" class="mj mk it kk b kl ms ko mt kr mu kv mv kz mw ld mo mp mq mr bi translated"><strong class="kk iu"> Transform </strong>:将数据集中的每个文本字符串转换成它的向量形式。</li></ul><h2 id="2b51" class="oq mz it bd na or os dn ne ot ou dp ni kr ov ow nk kv ox oy nm kz oz pa no pb bi translated">训练:线性 SVM</h2><p id="f367" class="pw-post-body-paragraph ki kj it kk b kl nq ju kn ko nr jx kq kr ns kt ku kv nt kx ky kz nu lb lc ld im bi translated">我决定使用的模型是线性支持向量机(SVM)，它是由<code class="fe nv nw nx ny b">scikit-learn</code>的<a class="ae lq" href="https://scikit-learn.org/stable/modules/generated/sklearn.svm.LinearSVC.html" rel="noopener ugc nofollow" target="_blank"> LinearSVC </a>类实现的。<a class="ae lq" href="https://medium.com/machine-learning-101/chapter-2-svm-support-vector-machine-theory-f0812effc72" rel="noopener">这个</a>和<a class="ae lq" href="https://www.svm-tutorial.com/2014/11/svm-understanding-math-part-1/" rel="noopener ugc nofollow" target="_blank">这个</a>如果你不知道什么是支持向量机，是很好的介绍。</p><blockquote class="oi oj ok"><p id="a553" class="ki kj mx kk b kl km ju kn ko kp jx kq ol ks kt ku om kw kx ky on la lb lc ld im bi translated">上面代码中的<a class="ae lq" href="https://scikit-learn.org/stable/modules/generated/sklearn.calibration.CalibratedClassifierCV.html" rel="noopener ugc nofollow" target="_blank"> CalibratedClassifierCV </a>是一个包装器，为我提供了<code class="fe nv nw nx ny b">predict_proba()</code>方法，它返回每个类的概率，而不仅仅是一个分类。不过，如果最后一句对你来说毫无意义，你几乎可以忽略它。</p></blockquote><p id="2a5d" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">你可以用一种(简化的)方式来思考线性 SVM 的工作原理:在训练过程中，该模型学习哪些单词是“坏的”，以及它们有多“坏”，因为这些单词在攻击性文本中出现得更频繁。<strong class="kk iu">就好像训练过程是在为我挑出“不好的”单词</strong>，这比用我自己写的单词表好多了！</p><p id="e15c" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">线性 SVM 结合了我发现的其他亵渎检测库的最佳方面:它足够快，可以实时运行，但又足够健壮，可以处理许多不同类型的亵渎。</p><h1 id="2521" class="my mz it bd na nb nc nd ne nf ng nh ni jz nj ka nk kc nl kd nm kf nn kg no np bi translated">警告</h1><p id="2e11" class="pw-post-body-paragraph ki kj it kk b kl nq ju kn ko nr jx kq kr ns kt ku kv nt kx ky kz nu lb lc ld im bi translated">话虽如此，<code class="fe nv nw nx ny b">profanity-check</code>远非完美。让我明确一点:对<code class="fe nv nw nx ny b">profanity-check</code>的预测持保留态度，因为<strong class="kk iu">也会犯错。例如，它不擅长挑选不太常见的脏话变体，如“f4ck you”或“you b1tch ”,因为它们在训练数据中出现的频率不够高。你永远无法检测出所有的脏话(人们会想出新的方法来逃避过滤器)，但是<code class="fe nv nw nx ny b">profanity-check</code>在发现大多数方面做得很好。</strong></p><h1 id="2d00" class="my mz it bd na nb nc nd ne nf ng nh ni jz nj ka nk kc nl kd nm kf nn kg no np bi translated">亵渎-检查</h1><p id="8b4c" class="pw-post-body-paragraph ki kj it kk b kl nq ju kn ko nr jx kq kr ns kt ku kv nt kx ky kz nu lb lc ld im bi translated"><code class="fe nv nw nx ny b">profanity-check</code>是开源的，可以在 PyPI 上获得！简单地说，使用它</p><pre class="lf lg lh li gt pe ny pf pg aw ph bi"><span id="91fa" class="oq mz it ny b gy pi pj l pk pl">$ pip install profanity-check</span></pre><p id="d4ef" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">怎样才能更好？如有任何想法或建议，请随时联系我们或发表评论！</p><div class="lr ls gp gr lt lu"><a href="https://github.com/vzhou842/profanity-check" rel="noopener  ugc nofollow" target="_blank"><div class="lv ab fo"><div class="lw ab lx cl cj ly"><h2 class="bd iu gy z fp lz fr fs ma fu fw is bi translated">vzhou 842/亵渎性检查</h2><div class="mb l"><h3 class="bd b gy z fp lz fr fs ma fu fw dk translated">一个快速、健壮的 Python 库，用于检查字符串中的攻击性语言。-vzhou 842/亵渎-检查</h3></div><div class="mc l"><p class="bd b dl z fp lz fr fs ma fu fw dk translated">github.com</p></div></div><div class="md l"><div class="pm l mf mg mh md mi lk lu"/></div></div></a></div></div><div class="ab cl pn po hx pp" role="separator"><span class="pq bw bk pr ps pt"/><span class="pq bw bk pr ps pt"/><span class="pq bw bk pr ps"/></div><div class="im in io ip iq"><p id="b915" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><em class="mx">也贴在</em><a class="ae lq" href="https://victorzhou.com/blog/better-profanity-detection-with-scikit-learn/" rel="noopener ugc nofollow" target="_blank">【victorzhou.com】</a><em class="mx">上。</em></p></div></div>    
</body>
</html>