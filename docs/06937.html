<html>
<head>
<title>Build your intuition in creating a good Regression model</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">在创建一个好的回归模型时建立你的直觉</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/build-your-intuition-in-creating-a-good-regression-model-90fd5aa97058?source=collection_archive---------29-----------------------#2019-10-01">https://towardsdatascience.com/build-your-intuition-in-creating-a-good-regression-model-90fd5aa97058?source=collection_archive---------29-----------------------#2019-10-01</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="5af9" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">你可以通过分类来辨别那是猫还是不是猫。但是，要回答那只猫有多“猫”，回归是唯一的方法。</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/12303b96d827be0c3f14755f54aff4ca.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*vCOwOFLW593OsVfG"/></div></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk">Photo by <a class="ae ky" href="https://unsplash.com/@ejleusink?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Erik-Jan Leusink</a> on <a class="ae ky" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><h1 id="1943" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">分类与回归</h1><p id="f3bb" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">两个大问题，两种不同的原因。</p><p id="ca0a" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">热狗还是不是热狗，猫还是不是猫，诈骗还是不是诈骗。这些问题是分类的常见用例。</p><p id="3a9a" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">通过查看示例，您可以很容易地得出结论:分类问题就是将一些数据集划分为几个类或组。从某种意义上说，组的数量是有限的。</p><p id="ab6c" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">正如您所猜测的，另一方面，回归是将这些数据分成无限组。</p><p id="9053" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">例如，拥有一组关于房屋面积的数据。通过查看数据，你可以预测每套房子的价格。因为价格几乎是无限的，所以你可以根据这些数据建立一个回归模型。</p><p id="4723" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">那么，如何开始创建回归模型呢？</p><h1 id="a9aa" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">定义问题</h1><p id="2973" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">用例子做任何事情总是更好，因为理论不会让你走那么远。</p><p id="c3fe" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">我们来发现一些问题。</p><p id="544c" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">我发现了这个:</p><p id="49e3" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated"><a class="ae ky" href="https://www.kaggle.com/c/new-york-city-taxi-fare-prediction/data" rel="noopener ugc nofollow" target="_blank"> <strong class="lt iu">纽约市出租车费用预测</strong> </a></p><p id="3771" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">这是一个很好的开始问题，可以训练你建立良好回归模型的直觉。</p><p id="e219" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">基本上，你会得到一堆关于在纽约从一个地方到另一个地方需要付多少钱的数据。根据这些数据，你需要预测你需要支付多少打车费用。</p><p id="7346" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">他们在问题中陈述的指标是，在不做所有必要的机器学习事情的情况下，你可以得到 5 到 8 美元的 RMSE(均方根误差)。所以，让我们建立一个能给你更少误差的东西。</p><p id="b906" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">开始吧！</p><h1 id="b9f8" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">数据</h1><p id="3469" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">下载数据并打开 train.csv(是的，它很大)，您将看到大约 5500 万行包含实际出租车费用的数据。</p><p id="8d50" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">每行将由 7 列组成。</p><ol class=""><li id="819b" class="ms mt it lt b lu mn lx mo ma mu me mv mi mw mm mx my mz na bi translated"><strong class="lt iu">接送日期</strong>，当出租车开始行驶时</li><li id="b4f2" class="ms mt it lt b lu nb lx nc ma nd me ne mi nf mm mx my mz na bi translated"><strong class="lt iu">皮卡 _ 经度</strong>，出租车乘坐皮卡的经度</li><li id="90a4" class="ms mt it lt b lu nb lx nc ma nd me ne mi nf mm mx my mz na bi translated"><strong class="lt iu">皮卡 _ 纬度</strong>，乘坐皮卡的纬度</li><li id="fc25" class="ms mt it lt b lu nb lx nc ma nd me ne mi nf mm mx my mz na bi translated"><strong class="lt iu">落客 _ 经度</strong>，落客的经度</li><li id="3e04" class="ms mt it lt b lu nb lx nc ma nd me ne mi nf mm mx my mz na bi translated"><strong class="lt iu">落客 _ 纬度</strong>，落客的纬度</li><li id="8f76" class="ms mt it lt b lu nb lx nc ma nd me ne mi nf mm mx my mz na bi translated"><strong class="lt iu">乘客计数</strong>，船上乘客的数量</li><li id="e015" class="ms mt it lt b lu nb lx nc ma nd me ne mi nf mm mx my mz na bi translated"><strong class="lt iu"> fare_amount </strong>，我们要预测的那个。</li></ol><p id="6c20" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">我们走吧！</p><h1 id="43e3" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">逻辑</h1><p id="4bbc" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">对于本教程，我将使用 Python 和几个标准库，如 Numpy、Pandas 和 LGBM</p><pre class="kj kk kl km gt ng nh ni nj aw nk bi"><span id="a187" class="nl la it nh b gy nm nn l no np">import numpy as np <br/>import pandas as pd<br/>import scipy as scipy<br/>import datetime as dt<br/>from sklearn.model_selection import train_test_split<br/>import lightgbm as lgbm<br/>import os<br/>import gc</span></pre><p id="4b05" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">我导入了 GC。那是一个用 python 收集垃圾的库。垃圾收集器的 GC。</p><p id="7cc9" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated"><em class="nq">为什么要导入？</em></p><p id="1d18" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">看看数据，对于本教程，我的计算机无法加载文件中的所有行，我最多只能加载 2200 万行。甚至，手动使用垃圾收集器也有所帮助，这样我就可以释放内存来加载和处理所有这 2200 万行。</p><pre class="kj kk kl km gt ng nh ni nj aw nk bi"><span id="1c68" class="nl la it nh b gy nm nn l no np"># Reading Data<br/>train_df =  pd.read_csv('train.csv', nrows = 22000000)</span><span id="df52" class="nl la it nh b gy nr nn l no np"># Drop rows with null values<br/>train_df = train_df.dropna(how = 'any', axis = 'rows')</span><span id="8f34" class="nl la it nh b gy nr nn l no np"># Drop invalid rows<br/>train_df = train_df<!-- -->[(<!-- -->train_df<!-- -->.fare_amount &gt; 0)  &amp; (<!-- -->train_df<!-- -->.fare_amount &lt;= 500) &amp; ((<!-- -->train_df<!-- -->.pickup_longitude != 0) &amp; (<!-- -->train_df<!-- -->.pickup_latitude != 0) &amp; (<!-- -->train_df<!-- -->.dropoff_longitude != 0) &amp; (<!-- -->train_df<!-- -->.dropoff_latitude != 0))]</span></pre><p id="e1da" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">读取并删除所有缺少值或值无效的行。</p><h1 id="2c76" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">直觉</h1><p id="265f" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">现在你已经准备好了数据。下一步是什么？</p><p id="92a4" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">像这样的问题，你需要几个新的特性(数据中只有 6 个可用)。你可以试着用这些数据来训练模型，但是你给的信息对模型来说太少了。</p><p id="18a1" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">特征工程是解决方案。</p><p id="3c79" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">它基本上是使用现有的功能创建或修改数据。这样做将增加您对数据的理解，最终在训练阶段帮助您的模型。</p><p id="adf8" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">比如经纬度，直接看的话可能没有任何意义。但是，什么对你有意义呢？<strong class="lt iu">距离</strong>！正确。</p><p id="e666" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">让我们准备一个函数来计算拾取点和衰减点之间的距离。</p><pre class="kj kk kl km gt ng nh ni nj aw nk bi"><span id="e912" class="nl la it nh b gy nm nn l no np"># To Compute Haversine distance<br/>def sphere_dist(pickup_lat, pickup_lon, dropoff_lat, dropoff_lon):<br/>    """<br/>    Return distance along great radius between pickup <br/>    and dropoff coordinates.<br/>    """<br/>    #Define earth radius (km)<br/>    R_earth = 6371</span><span id="b559" class="nl la it nh b gy nr nn l no np">    #Convert degrees to radians<br/>    pickup_lat, pickup_lon, dropoff_lat, dropoff_lon =<br/>            map(np.radians, [pickup_lat, pickup_lon,dropoff_lat,        <br/>                dropoff_lon])</span><span id="0125" class="nl la it nh b gy nr nn l no np">    #Compute distances along lat, lon dimensions<br/>    dlat = dropoff_lat - pickup_lat<br/>    dlon = dropoff_lon - pickup_lon<br/>    <br/>    #Compute haversine distance<br/>    a = np.sin(dlat/2.0)**2 + np.cos(pickup_lat) * <br/>        np.cos(dropoff_lat) * np.sin(dlon/2.0)**2<br/>    return 2 * R_earth * np.arcsin(np.sqrt(a))</span></pre><p id="d211" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">这就是哈弗辛公式，一个计算两个纬度和经度之间距离的函数。</p><p id="4f75" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">然而，在导航中，除了距离之外，你经常需要计算方位，也称为方位角或在北方和游乐设备之间移动的角度。</p><pre class="kj kk kl km gt ng nh ni nj aw nk bi"><span id="f180" class="nl la it nh b gy nm nn l no np">def sphere_dist_bear(pickup_lat, pickup_lon, dropoff_lat, dropoff_lon):<br/>    """<br/>    Return distance along great radius between pickup and dropoff <br/>    coordinates.<br/>    """<br/>    <br/>    #Convert degrees to radians<br/>    pickup_lat, pickup_lon, dropoff_lat, dropoff_lon = <br/>    map(np.radians, [pickup_lat, pickup_lon, dropoff_lat, <br/>        dropoff_lon])</span><span id="90fb" class="nl la it nh b gy nr nn l no np">    #Compute distances along lat, lon dimensions<br/>    dlat = dropoff_lat - pickup_lat<br/>    dlon = pickup_lon - dropoff_lon<br/>    <br/>    #Compute the bearing<br/>    a = np.arctan2(np.sin(dlon * <br/>        np.cos(dropoff_lat)),np.cos(pickup_lat) * <br/>        np.sin(dropoff_lat) - np.sin(pickup_lat) * <br/>        np.cos(dropoff_lat) * np.cos(dlon))<br/>    return a</span></pre><p id="0fbe" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">你可以在这里阅读哈弗森距离<a class="ae ky" href="https://en.wikipedia.org/wiki/Haversine_formula" rel="noopener ugc nofollow" target="_blank">，在这里</a>阅读方位<a class="ae ky" href="https://en.wikipedia.org/wiki/Bearing_(navigation)" rel="noopener ugc nofollow" target="_blank">。</a></p><p id="b8ee" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">让我们添加数据</p><pre class="kj kk kl km gt ng nh ni nj aw nk bi"><span id="0203" class="nl la it nh b gy nm nn l no np">train_df['distance'] = sphere_dist(train_df['pickup_latitude'], <br/>                                   train_df['pickup_longitude'], <br/>                                   train_df['dropoff_latitude'], <br/>                                   train_df['dropoff_longitude']) <br/><br/>train_df['bearing'] = sphere_dist_bear(train_df['pickup_latitude'], <br/>                                       train_df['pickup_longitude'], <br/>                                       train_df['dropoff_latitude'], <br/>                                      train_df['dropoff_longitude'])</span></pre><p id="a77b" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">接下来，您可能想要将纬度和经度转换为弧度。因为用弧度计算会给你已经标准化的输入。弧度参数的最大值是 2π弧度。</p><pre class="kj kk kl km gt ng nh ni nj aw nk bi"><span id="3250" class="nl la it nh b gy nm nn l no np">def radian_conv(degree):<br/>    """<br/>    Return radian.<br/>    """<br/>    return  np.radians(degree)</span><span id="cf10" class="nl la it nh b gy nr nn l no np">train_df['pickup_latitude'] =  <br/>                       radian_conv(train_df['pickup_latitude'])<br/>train_df['pickup_longitude'] = <br/>                       radian_conv(train_df['pickup_longitude'])<br/>train_df['dropoff_latitude'] = <br/>                       radian_conv(train_df['dropoff_latitude'])<br/>train_df['dropoff_longitude'] = <br/>                       radian_conv(train_df['dropoff_longitude'])</span></pre><p id="f279" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">现在，还有什么？</p><p id="b03d" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">您可能希望从<strong class="lt iu"> datetime </strong>特性中提取详细的日期和时间数据。</p><pre class="kj kk kl km gt ng nh ni nj aw nk bi"><span id="fb15" class="nl la it nh b gy nm nn l no np">def add_datetime_info(dataset):<br/>    #Convert to datetime format<br/>    dataset['pickup_datetime'] = pd.to_datetime(dataset['pickup_datetime'],format="%Y-%m-%d %H:%M:%S UTC")<br/>    <br/>    dataset['hour'] = dataset.pickup_datetime.dt.hour<br/>    dataset['day'] = dataset.pickup_datetime.dt.day<br/>    dataset['month'] = dataset.pickup_datetime.dt.month<br/>    dataset['weekday'] = dataset.pickup_datetime.dt.weekday<br/>    dataset['year'] = dataset.pickup_datetime.dt.year<br/>    <br/>    return dataset</span><span id="5469" class="nl la it nh b gy nr nn l no np">train_df = add_datetime_info(train_df)</span></pre><p id="c960" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">这些是您可能希望看到的常见功能，因为出租车费用可能是季节性的。让我们将所有这些要素放入数据集中。</p><h1 id="112a" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">开始变得有创造力</h1><p id="183a" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">从这一点来说，您已经准备好了，因为您可能已经从初始特征中提取了所有可能的特征。</p><p id="4036" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">这一次，你可能想在餐桌上增加一些创意。</p><p id="3e7d" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">给自己一个问题。</p><p id="cb4e" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">为什么人们在纽约打车？</p><ol class=""><li id="a2e6" class="ms mt it lt b lu mn lx mo ma mu me mv mi mw mm mx my mz na bi translated">可能他们刚到机场就去市区了。在这种情况下，如果乘坐距离机场较近，而乘坐距离机场较远，情况可能会有所不同。</li><li id="0ff4" class="ms mt it lt b lu nb lx nc ma nd me ne mi nf mm mx my mz na bi translated">人们到处都乘出租车。市内，市外，靠近市中心，远离市中心。但是大概票价会因为你离纽约市中心有多远而有所不同。</li><li id="b0c2" class="ms mt it lt b lu nb lx nc ma nd me ne mi nf mm mx my mz na bi translated">自由女神像？</li></ol><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ns"><img src="../Images/22d8432d8b99a4062721a938fcd6a517.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*47vbppHzqp2F3r5Y"/></div></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk">Photo by <a class="ae ky" href="https://unsplash.com/@aussieactive?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">AussieActive</a> on <a class="ae ky" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><p id="f069" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">让我们计算一下乘车点和这些点之间的距离。</p><pre class="kj kk kl km gt ng nh ni nj aw nk bi"><span id="adde" class="nl la it nh b gy nm nn l no np">def add_airport_dist(dataset):<br/>    """<br/>    Return minumum distance from pickup or dropoff coordinates to <br/>    each airport.<br/>    JFK: John F. Kennedy International Airport<br/>    EWR: Newark Liberty International Airport<br/>    LGA: LaGuardia Airport<br/>    SOL: Statue of Liberty <br/>    NYC: Newyork Central<br/>    """<br/>    jfk_coord = (40.639722, -73.778889)<br/>    ewr_coord = (40.6925, -74.168611)<br/>    lga_coord = (40.77725, -73.872611)<br/>    sol_coord = (40.6892,-74.0445) # Statue of Liberty<br/>    nyc_coord = (40.7141667,-74.0063889) <br/>    <br/>    <br/>    pickup_lat = dataset['pickup_latitude']<br/>    dropoff_lat = dataset['dropoff_latitude']<br/>    pickup_lon = dataset['pickup_longitude']<br/>    dropoff_lon = dataset['dropoff_longitude']<br/>    <br/>    pickup_jfk = sphere_dist(pickup_lat, pickup_lon, <br/>                       jfk_coord[0], jfk_coord[1]) <br/>    dropoff_jfk = sphere_dist(jfk_coord[0], jfk_coord[1], <br/>                       dropoff_lat, dropoff_lon) <br/>    pickup_ewr = sphere_dist(pickup_lat, pickup_lon, <br/>                       ewr_coord[0], ewr_coord[1])<br/>    dropoff_ewr = sphere_dist(ewr_coord[0], ewr_coord[1], <br/>                       dropoff_lat, dropoff_lon) <br/>    pickup_lga = sphere_dist(pickup_lat, pickup_lon, <br/>                       lga_coord[0], lga_coord[1]) <br/>    dropoff_lga = sphere_dist(lga_coord[0], lga_coord[1], <br/>                       dropoff_lat, dropoff_lon)<br/>    pickup_sol = sphere_dist(pickup_lat, pickup_lon, <br/>                       sol_coord[0], sol_coord[1]) <br/>    dropoff_sol = sphere_dist(sol_coord[0], sol_coord[1], <br/>                       dropoff_lat, dropoff_lon)<br/>    pickup_nyc = sphere_dist(pickup_lat, pickup_lon, <br/>                       nyc_coord[0], nyc_coord[1]) <br/>    dropoff_nyc = sphere_dist(nyc_coord[0], nyc_coord[1], <br/>                       dropoff_lat, dropoff_lon)<br/>    <br/>    dataset['jfk_dist'] = pickup_jfk + dropoff_jfk<br/>    dataset['ewr_dist'] = pickup_ewr + dropoff_ewr<br/>    dataset['lga_dist'] = pickup_lga + dropoff_lga<br/>    dataset['sol_dist'] = pickup_sol + dropoff_sol<br/>    dataset['nyc_dist'] = pickup_nyc + dropoff_nyc<br/>    <br/>    return dataset</span><span id="0c07" class="nl la it nh b gy nr nn l no np">train_df = add_airport_dist(train_df)<br/></span></pre><p id="d815" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">这取决于你的想象力，你的特征可能不像我创造的。你可能对影响出租车费用的因素有另一种直觉，比如离商业区或住宅区的距离。或者你想象的任何东西。</p><h1 id="d73b" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">该训练了</h1><p id="e03e" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">现在，在您准备好数据之后，让我们来训练模型。</p><pre class="kj kk kl km gt ng nh ni nj aw nk bi"><span id="a3a0" class="nl la it nh b gy nm nn l no np">train_df.drop(columns=['key', 'pickup_datetime'], inplace=True)<br/><br/>y = train_df['fare_amount']<br/>train_df = train_df.drop(columns=['fare_amount'])</span><span id="71e0" class="nl la it nh b gy nr nn l no np">x_train,x_test,y_train,y_test = train_test_split(train_df, y, test_size=0.10)</span><span id="0163" class="nl la it nh b gy nr nn l no np">del train_df<br/>del y<br/>gc.collect()</span></pre><p id="a55a" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">将数据以 90:10 的比例分割成训练验证分割。获得训练数组后，不要忘记删除数据帧。它占用了大量资源。</p><pre class="kj kk kl km gt ng nh ni nj aw nk bi"><span id="9714" class="nl la it nh b gy nm nn l no np">params = {<br/>        'boosting_type':'gbdt',<br/>        'objective': 'regression',<br/>        'nthread': 4,<br/>        'num_leaves': 31,<br/>        'learning_rate': 0.05,<br/>        'max_depth': -1,<br/>        'subsample': 0.8,<br/>        'bagging_fraction' : 1,<br/>        'max_bin' : 5000 ,<br/>        'bagging_freq': 20,<br/>        'colsample_bytree': 0.6,<br/>        'metric': 'rmse',<br/>        'min_split_gain': 0.5,<br/>        'min_child_weight': 1,<br/>        'min_child_samples': 10,<br/>        'scale_pos_weight':1,<br/>        'zero_as_missing': True,<br/>        'seed':0,<br/>        'num_rounds':50000<br/>    }</span><span id="8941" class="nl la it nh b gy nr nn l no np">train_set = lgbm.Dataset(x_train, y_train, silent=False,categorical_feature=['year','month','day','weekday'])</span><span id="be74" class="nl la it nh b gy nr nn l no np">valid_set = lgbm.Dataset(x_test, y_test, silent=False,categorical_feature=['year','month','day','weekday'])</span><span id="13d4" class="nl la it nh b gy nr nn l no np">model = lgbm.train(params, train_set = train_set, num_boost_round=10000,early_stopping_rounds=500,verbose_eval=500, valid_sets=valid_set)</span></pre><p id="ebbc" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">它将永远训练，直到你的模型不能再优化结果。这将使你达到大约 25，000 次迭代，并给你<strong class="lt iu"> $3.47966 </strong>均方根误差。</p><p id="fc1a" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">这是一个巨大的提升，可以为你节省 1.5 美元到 4.5 美元的出租车费。你可以用它买一份简单的快餐。Lol。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nt"><img src="../Images/7de79ac5e9798a92a5572b3916b7af86.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*Q9c4qHlJsYp-ST67"/></div></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk">Photo by <a class="ae ky" href="https://unsplash.com/@jentheodore?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Jen Theodore</a> on <a class="ae ky" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><h1 id="d1b6" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">结论</h1><p id="bbc6" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">一开始直觉可能很难。但是你知道，通常是常识帮助你度过所有这些。通过了解基层的数据情况，可以让你比以前更直观一点。</p><p id="8ef2" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">别忘了，继续努力！</p><p id="e231" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">干杯</p></div></div>    
</body>
</html>