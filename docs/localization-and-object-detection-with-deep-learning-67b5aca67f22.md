# 具有深度学习的定位和物体检测

> 原文：<https://towardsdatascience.com/localization-and-object-detection-with-deep-learning-67b5aca67f22?source=collection_archive---------22----------------------->

定位和目标检测是计算机视觉中的两个核心任务，因为它们被应用于许多现实世界的应用中，例如自主车辆和机器人。所以，如果你想在这些行业工作，成为一名计算机视觉专家，或者你想开发一个相关的产品，你最好能很好地掌握它们。但是它们是什么呢？物体检测和定位意味着什么？为什么我们把它们归为一类？

重要的事情先来。让我们快速回顾一下最常用的术语及其含义，以避免误解:

*   **分类/识别**:给定一幅带有物体的图像，找出那个物体是什么。换句话说，从一组预定义的类别中将其分类。
*   **定位:**找到物体所在的位置，并在它周围画一个边界框
*   **物体检测**:对图像中的所有物体进行分类检测。给每个对象分配一个类，并围绕它画一个边界框。
*   **语义分割**:将图像中的每一个像素按照其上下文分类，这样每一个像素都被分配到一个对象
*   **实例分割**:将图像中的每一个像素归为一类，这样每一个像素都被分配给一个对象的不同实例

但是，请记住，这些术语在科学界没有明确的定义，因此您可能会遇到其中一个具有不同含义的术语。在我的理解中，这些是正确的解释。

当我们了解基本术语后，是时候做一些定位和物体检测了。我们怎么做呢？这些年来有许多方法，但自从深度学习到来后，卷积神经网络成为了行业标准。记住**我们的目标是对物体进行分类和定位**。但是我们确定只有一个物体吗？有没有可能有两个或者三个或者十五个物体？事实上，大多数时候是这样的。

这就是为什么我们可以把我们的问题分成两个不同的问题。在第一种情况下，我们知道对象的数量(我们将该问题称为分类+定位)，而在第二种情况下，我们不知道(对象检测)。我将从第一个开始，因为它是最简单的。

![](img/7d3a50a9a7a25ea38aac4db068f7d202.png)

> [*斯坦福大学工程学院*](https://www.youtube.com/channel/UCdKG2JnvPu6mY1NDXYFfN0g)

# 分类+本地化

如果我们只有一个对象或者我们知道对象的数量，这实际上是微不足道的。我们可以使用一个卷积神经网络，并训练它**不仅对图像进行分类，而且为边界框**输出 4 个坐标。**这样，我们将本地化视为简单的回归问题**。

例如，我们可以借用一个经过充分研究的模型，如 ResNet 或 Alexnet，它由一堆卷积、池化和其他层组成，并重新调整全连接层的用途，以产生与类别无关的边界框。它如此简单，以至于我们怀疑它是否会有结果。实际上它在实践中运行得很好。当然，您可以使用它并修改架构以服务于特定的问题或增强其准确性，但主要思想仍然存在。

请务必注意，为了使用这个模型，我们应该有一个训练集，其中包含为类和边界框注释的图像。而且做这样的标注也不是最好玩的。

但是如果我们事先不知道物体的数量呢？然后我们需要进入兔子洞，谈论一些核心的东西。你准备好了吗？之前要不要休息一下？当然，我明白，但是我警告你不要离开。这就是乐趣的开始。

# 目标检测

我开玩笑的。关于将要讨论的架构没有什么核心的东西。所有的是一些聪明的想法，使系统不能容忍输出的数量，并减少其计算成本。因此，我们不知道图像中对象的确切数量，我们希望对所有对象进行分类，并在它们周围绘制一个边界框。这意味着模型应该输出的坐标数量不是常数。如果图像有两个物体，我们需要 8 个坐标。如果它有 4 个对象，我们需要 16 个。那么我们如何建立这样一个模型呢？

传统计算机视觉的一个关键思想是区域提议。我们使用经典 CV 算法(如边缘和形状检测)生成一组可能包含对象的窗口，并且我们仅将这些窗口(或感兴趣的区域)应用于 CNN。要了解更多关于如何提议区域的信息，请务必查看此处的。

这是一篇基础的[论文](https://arxiv.org/abs/1311.2524)的基础，该论文介绍了一种叫做 RCNN 的新架构。

![](img/6837ec6a0b18a51e3cdcc4235e942ea7.png)

# R-CNN

给定具有多个对象的图像，我们使用提议方法(在 RCNN 的情况下，这种方法称为选择性搜索)生成一些感兴趣的区域，并将这些区域弯曲成固定的大小。我们将每个区域转发到卷积神经网络(如 AlexNet)，它将使用 SVM 为每个区域做出分类决定，并预测每个边界框的回归。该预测是对所提议的区域的校正，该区域可能处于正确的位置，但不是精确的大小和方向。

![](img/72c796885281f301f920f19a10e7fa75.png)

虽然这个模型产生了很好的结果，但是它有一个主要的问题。这是非常缓慢和计算昂贵的。想象一下，在一般情况下，我们产生 2000 个区域，我们需要将它们存储在磁盘中，我们将它们中的每一个都转发到 CNN 中多次传递，直到它被训练好。为了解决其中的一些问题，该模型的一个改进被称为“快速 RCNN”

# 快速 RCNN

这个想法很简单。我们将整个图像传递一次，并产生一个特征图，而不是将所有区域逐一传递到卷积层。然后，我们像以前一样(使用一些外部方法)将区域建议投影到特征图上。现在，我们在特征图中有了区域，而不是原始图像，我们可以在一些完全连接的层中转发它们，以输出分类决策和边界框校正。

![](img/ac58ff4d68c553643e9d6df75965aa85.png)

请注意，区域投影建议是使用特殊层(ROI 层)实现的，它本质上是一种最大池，池大小取决于输入，因此输出总是具有相同的大小。有关 ROI 层的更多详细信息，请查看这篇伟大的[文章](https://deepsense.ai/region-of-interest-pooling-explained/)。

# 更快的 RCNN

我们可以更进一步。使用从卷积层产生的特征图，我们使用区域提议网络而不是依赖于外部系统来推断区域提议。一旦我们有了这些建议，剩下的过程与 Fast-RCNN 相同(前进到 ROI 层，使用 SVM 分类并预测边界框)。棘手的部分是如何训练整个模型，因为我们有多个任务需要处理:

1.  区域提议网络应该为每个区域决定它是否包含对象
2.  并且它需要产生边界框坐标
3.  整个模型应该对对象进行分类
4.  并且再次预测边界框偏移

如果你想了解更多关于训练部分的内容，你应该检查一下最初的[论文](https://arxiv.org/abs/1506.01497)，但是为了给你一个概述，我们需要利用一个多任务损失来包括所有 4 个任务，并将这个损失反向传播到网络。

![](img/2be3ee161b668ebc57b76ffb32dcd7df.png)

顾名思义，FasterRCNN 比以前的模型快得多，是大多数现实应用程序的首选。

定位和目标检测是一个非常活跃和有趣的研究领域，因为现实世界中的应用需要在计算机视觉任务(自动驾驶汽车、机器人)中具有出色的性能。公司和大学定期就如何提高准确性提出新的想法。

存在另一类用于定位和对象检测的模型，称为单次检测器，其在过去几年中变得非常流行，因为它们甚至更快并且通常需要更少的计算成本。当然，它们不太精确，但它们非常适合嵌入式系统和类似的耗电应用。

但是要了解更多，你必须等待第 2 部分…

> ***如果您有任何想法、评论、问题或者您只想了解我的最新内容，请随时在***[**Linkedin**](https://www.linkedin.com/in/sergios-karagiannakos/)**，**[**Twitter**](https://twitter.com/KarSergios)**，**[**insta gram**](https://www.instagram.com/sergios_krg/)**，**[**Github**](https://github.com/SergiosKar)**或在我的**

*原载于 2019 年 3 月 25 日*[*sergioskar . github . io*](https://sergioskar.github.io/Localization_and_Object_Detection/)*。*