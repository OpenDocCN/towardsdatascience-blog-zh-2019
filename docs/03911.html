<html>
<head>
<title>k-Nearest Neighbour: Predicting the severity of a mammographic mass lesion</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">k 近邻法:预测乳腺 x 线肿块病变的严重程度</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/k-nearest-neighbour-predicting-the-severity-of-a-mammographic-mass-lesion-9d897a8f5893?source=collection_archive---------30-----------------------#2019-06-19">https://towardsdatascience.com/k-nearest-neighbour-predicting-the-severity-of-a-mammographic-mass-lesion-9d897a8f5893?source=collection_archive---------30-----------------------#2019-06-19</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="006b" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">“通过立即更换临床医生，[该算法]将允许我们实际上加快对潜在威胁生命的情况的及时诊断。”雷切尔·卡尔卡特博士。</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/d0d668b9fbe5178f243a708482ef011a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*1lZSyHjk9RMzbKUUvjVOzQ.jpeg"/></div></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk">Feature Image Source: iStock.com/Aleutie</figcaption></figure><p id="4ac4" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">本文阐述了理解 k-最近邻和调整超参数所需的基本背景。</p><p id="da09" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated"><strong class="kx ir">基于实例的学习</strong>(也称为<strong class="kx ir">基于记忆的学习</strong>)是一个学习算法家族，它不是执行数据点的泛化，而是试图将新的问题实例(测试数据)与提供的数据点(训练数据)进行比较。</p><p id="0db8" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">基于实例的学习算法的最简单形式之一是<strong class="kx ir">最近邻(NN)算法</strong>。简而言之，最近邻算法倾向于基于问题空间中数据点的最近邻来对测试数据点进行分类。最近邻算法的主要缺点之一是对噪声非常敏感。现在，最近邻算法的一个广泛使用的扩展是<strong class="kx ir">k-最近邻(k-NN)算法</strong>。与 k-最近邻中的最近邻不同，我们倾向于寻找测试数据点的 k-最近邻，并且在这些 k-最近邻中的多数投票预测测试数据点的类别。深入挖掘 k-NN 的最佳帖子之一是 Onel Harrison 的<a class="ae lr" rel="noopener" target="_blank" href="/machine-learning-basics-with-the-k-nearest-neighbors-algorithm-6a6e71d01761">关于 K-最近邻算法的机器学习基础</a>。</p></div><div class="ab cl ls lt hu lu" role="separator"><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx"/></div><div class="ij ik il im in"><h1 id="2333" class="lz ma iq bd mb mc md me mf mg mh mi mj jw mk jx ml jz mm ka mn kc mo kd mp mq bi translated">问题陈述</h1><p id="2528" class="pw-post-body-paragraph kv kw iq kx b ky mr jr la lb ms ju ld le mt lg lh li mu lk ll lm mv lo lp lq ij bi translated">乳房 x 线照相术是目前乳腺癌筛查最有效的方法。然而，从乳房 x 光片判读得到的乳房活检的低阳性预测值导致大约 70%的不必要活检具有良性结果。为了减少大量不必要的乳腺活检，近年来已经提出了几种计算机辅助诊断(CAD)系统。这些系统帮助医生决定对乳房 x 线照片中看到的可疑病变进行乳房活检，或者改为进行实用的机器学习短期随访检查。</p><p id="5564" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">我们能否找到 k-NN 系统的最佳变体，用于根据 BI-RADS 属性和患者年龄预测乳腺 x 线肿块病变的严重程度(良性或恶性)?</p><h1 id="923c" class="lz ma iq bd mb mc mw me mf mg mx mi mj jw my jx ml jz mz ka mn kc na kd mp mq bi translated">特征信息</h1><p id="43cd" class="pw-post-body-paragraph kv kw iq kx b ky mr jr la lb ms ju ld le mt lg lh li mu lk ll lm mv lo lp lq ij bi translated">有 5 个数字特征和一个二元目标类，如下所述:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nb"><img src="../Images/ebb7c4d283679b59e20eddea34d1ee9a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*RXpITXowzTHUW39KN6TSLA.png"/></div></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk">Features in Mammographic Dataset</figcaption></figure></div><div class="ab cl ls lt hu lu" role="separator"><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx"/></div><div class="ij ik il im in"><h1 id="f962" class="lz ma iq bd mb mc md me mf mg mh mi mj jw mk jx ml jz mm ka mn kc mo kd mp mq bi translated">数据分为—测试和训练集:</h1><p id="baae" class="pw-post-body-paragraph kv kw iq kx b ky mr jr la lb ms ju ld le mt lg lh li mu lk ll lm mv lo lp lq ij bi translated">创建了四个数据集，每个测试和训练有两个，因此一个数据集中有要素，另一个数据集中有目标变量。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nc"><img src="../Images/f2e25c4a924301f301ed6b16666409b4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Zi2H-VwBTBSdbrEqC5BOkw.png"/></div></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk">Train and Test Distribution of dataset</figcaption></figure><h1 id="1358" class="lz ma iq bd mb mc mw me mf mg mx mi mj jw my jx ml jz mz ka mn kc na kd mp mq bi translated">用于评估的 k-NN 变量和超参数:</h1><p id="0d23" class="pw-post-body-paragraph kv kw iq kx b ky mr jr la lb ms ju ld le mt lg lh li mu lk ll lm mv lo lp lq ij bi translated">通过改变距离矩阵来创建 k-NN 变体。改变距离矩阵也引入了许多与该距离相关的超参数。</p><h2 id="c26e" class="nd ma iq bd mb ne nf dn mf ng nh dp mj le ni nj ml li nk nl mn lm nm nn mp no bi translated">使用的 k-NN 变体在下面描述</h2><ol class=""><li id="8b10" class="np nq iq kx b ky mr lb ms le nr li ns lm nt lq nu nv nw nx bi translated"><strong class="kx ir">欧氏距离:</strong>这是最常见的距离度量，它度量的是两点之间的直线距离。下面提供了计算到数据点<strong class="kx ir"> p </strong>和<strong class="kx ir"> q </strong>的欧几里德距离的数学公式:</li></ol><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ny"><img src="../Images/bf1c70cc89bcb3b35a778dbe2024f1dd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*MDJWalqh-hiKm9lvX7CBAQ.png"/></div></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk">Formula to compute Euclidean distance</figcaption></figure><p id="dc04" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">欧几里德距离的代码:</p><pre class="kg kh ki kj gt nz oa ob oc aw od bi"><span id="9e43" class="nd ma iq oa b gy oe of l og oh">def calculateDistances(compArray, queryArray):<br/> “””<br/> Computes Euclidean distance-<br/> :param compArray: takes in 2d array i.e. training dataset <br/> :param queryArray: takes in 1d array i.e. instance of test dataset<br/> :return: sqrtArray :distance between the querry point and each point in training dataset<br/> sortedIndex : sorted index based on the distance between the querry point and each point in training dataset<br/> “””<br/> subArray =np.subtract(compArray,queryArray)<br/> powArray = subArray**2<br/> sumArray = np.sum(powArray,axis =1)<br/> sqrtArray = np.sqrt(sumArray)<br/> #sorts index of array based on respective location value<br/> sortedIndex = np.argsort(sqrtArray)<br/> return sqrtArray,sortedIndex</span></pre><p id="cb79" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">2.<strong class="kx ir">曼哈顿距离:</strong>第二种最常见的距离度量是曼哈顿距离，它测量平行于每个轴的距离，而不是像欧几里德距离中观察到的那样对角距离。下面提供了计算到数据点<strong class="kx ir"> p </strong>和<strong class="kx ir"> q </strong>的曼哈顿距离的数学公式:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi oi"><img src="../Images/674663b4e5ee6bf55fa3d48e2df92c15.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*lcET9ipMj5Uok1_bg6ZeMA.png"/></div></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk">Formula to compute Manhattan distance</figcaption></figure><p id="32de" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">曼哈顿距离代码:</p><pre class="kg kh ki kj gt nz oa ob oc aw od bi"><span id="28f1" class="nd ma iq oa b gy oe of l og oh">def calculateManhattanDistances(compArray, queryArray):<br/> “””<br/> Computes Manhattan distance-<br/> :param compArray: takes in 2d array i.e. training dataset <br/> :param queryArray: takes in 1d array i.e. instance of test dataset<br/> :return: sumArray :distance between the querry point and each point in training dataset<br/> sortedIndex : sorted index based on the distance between the querry point and each point in training dataset<br/> “””<br/> subArray =np.subtract(compArray,queryArray)<br/> subArray= np.absolute(subArray)<br/> sumArray = np.sum(subArray,axis =1)<br/> #sorts index of array based on respective location value<br/> sortedIndex = np.argsort(sumArray)<br/> return sumArray,sortedIndex</span></pre><p id="124b" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">3.<strong class="kx ir">闵可夫斯基距离:</strong>闵可夫斯基距离提供了一个一般化的公式，以找到适用于不同问题域的复杂距离度量。下面提供了计算到数据点<strong class="kx ir"> p </strong>和<strong class="kx ir"> q </strong>的闵可夫斯基距离的数学公式:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi oj"><img src="../Images/d409c7a9870a1ef241add99da6a7d2a7.png" data-original-src="https://miro.medium.com/v2/resize:fit:810/format:webp/1*XiWRwDzjXl61eFH68m2jug.png"/></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk">Formula to compute Minkowski distance</figcaption></figure><p id="3ccc" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">对于上面的等式，如果'<strong class="kx ir"> a' </strong>被认为是 1，我们将得到曼哈顿距离，如果'<strong class="kx ir"> a' </strong>被认为是 2，我们将得到欧几里德距离。</p><p id="69b5" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">闵可夫斯基距离代码:</p><pre class="kg kh ki kj gt nz oa ob oc aw od bi"><span id="53f9" class="nd ma iq oa b gy oe of l og oh">def calculateMinkowskiDistances(compArray, queryArray, alpha):<br/> “””<br/> Computes Euclidean distance-<br/> :param compArray: takes in 2d array i.e. training dataset <br/> :param queryArray: takes in 1d array i.e. instance of test dataset<br/> :param alpha: this value allow us to play with multiple values in which 1 =manhattan distance and 2= euclidean distance<br/> :return: sqrtArray :distance between the querry point and each point in training dataset<br/> sortedIndex : sorted index based on the distance between the querry point and each point in training dataset<br/> “””<br/> subArray =np.subtract(compArray,queryArray)<br/> np.absolute(subArray)<br/> powArray = subArray**alpha<br/> sumArray = np.sum(powArray,axis =1)<br/> sqrtArray = np.power(sumArray, (1./float(alpha)))<br/> #sorts index of array based on respective location value<br/> sortedIndex = np.argsort(sqrtArray)<br/> return sqrtArray,sortedIndex</span></pre><p id="a6d1" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">4.<strong class="kx ir">加权欧氏距离:</strong>上述距离度量的最大缺点是没有考虑 k 近邻之间的距离有多远或多近，导致 k-NN 模型的误分类。在距离加权 k-NN 中，来自每个邻居的投票被累积，并且基于最近邻居到测试数据点的距离来计算它们对投票的贡献，因此更近的邻居点对类的预测影响更大。计算到数据点<strong class="kx ir"> x </strong>和<strong class="kx ir"> y </strong>的加权欧几里德距离的数学公式如下:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi ok"><img src="../Images/f360267755a7917e49daae1de76b5f40.png" data-original-src="https://miro.medium.com/v2/resize:fit:966/format:webp/1*SJRpO8sHQoZhDr4uTeeEvA.png"/></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk">Formula to compute Weighted Euclidean distance</figcaption></figure><p id="ee99" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">加权欧几里德距离的代码:</p><pre class="kg kh ki kj gt nz oa ob oc aw od bi"><span id="caf9" class="nd ma iq oa b gy oe of l og oh">def getWtPrediction(computedListValue, k, n): <br/> “””<br/> This functions helps in generating prediction for each test data point-<br/> :param computedListValue: takes in list in which distance of that respective test point to all training datapoint are available<br/> :param k: It is hyper parameter which decides how many nearest neighbour should be kept in consideration while doing prediction.<br/> :param n: It is another hyper-parameter which decides the power to the inverse distance.<br/> :return: ndComputedList : which contains prediction based on the given input<br/> “””<br/> ndComputedList= np.array(computedListValue)<br/> ndComputedList.sort(axis=1)<br/> ndComputedList= ndComputedList[:, :k]<br/> ndComputedList = 1/pow(ndComputedList,n)<br/> ndComputedList = np.sum(ndComputedList, axis =1) <br/> return ndComputedList</span></pre><h2 id="02ac" class="nd ma iq bd mb ne nf dn mf ng nh dp mj le ni nj ml li nk nl mn lm nm nn mp no bi translated">下面提供了基于距离度量的与每个 k-NN 变量相关联的超参数:</h2><ol class=""><li id="44ae" class="np nq iq kx b ky mr lb ms le nr li ns lm nt lq nu nv nw nx bi translated"><strong class="kx ir">欧氏距离:</strong> ' <strong class="kx ir"> k </strong>'表示数据集中聚类的个数。</li></ol><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi ol"><img src="../Images/4d6826c61f264cefaa41de3c71529064.png" data-original-src="https://miro.medium.com/v2/resize:fit:908/format:webp/1*t_TgeEVGn0sRiP92_HJzlQ.png"/></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk">Hyper-parameter for k-NN with Euclidean distance</figcaption></figure><p id="05c2" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">2.<strong class="kx ir">曼哈顿距离:</strong> ' <strong class="kx ir"> k </strong>'表示数据集中的聚类数。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi om"><img src="../Images/ea829e0b0e9191183e90f39cff7a5792.png" data-original-src="https://miro.medium.com/v2/resize:fit:866/format:webp/1*WAVufggcINfRZpKCEBdrdg.png"/></div></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk">Hyper-parameter for k-NN with Manhattan distance</figcaption></figure><p id="9e5d" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">3.<strong class="kx ir">闵可夫斯基距离:</strong> ' <strong class="kx ir"> k </strong>'表示数据集中聚类的数量。<strong class="kx ir"> alpha </strong>表示调节距离测量的整数。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi on"><img src="../Images/2b144f93beb10373e524fb73f94bcce8.png" data-original-src="https://miro.medium.com/v2/resize:fit:850/format:webp/1*kfvgGrK7mfyshIE9znn8Ow.png"/></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk">Hyper-parameter for k-NN with Minkowski distance</figcaption></figure><p id="03f8" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">4.<strong class="kx ir">加权欧氏距离:</strong> ' <strong class="kx ir"> k </strong>表示数据集中聚类的个数。<strong class="kx ir"> n </strong>表示基于它们之间的距离的最近邻居的贡献。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi oo"><img src="../Images/a071ddf14779d08df82a31f5ef73c9ff.png" data-original-src="https://miro.medium.com/v2/resize:fit:880/format:webp/1*PK-oc_ewxKzRWvIIw_KXFA.png"/></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk">Hyper-parameter for k-NN with Weighted Euclidean distance</figcaption></figure></div><div class="ab cl ls lt hu lu" role="separator"><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx"/></div><div class="ij ik il im in"><h1 id="4f27" class="lz ma iq bd mb mc md me mf mg mh mi mj jw mk jx ml jz mm ka mn kc mo kd mp mq bi translated">k-NN 变体和超参数观察:</h1><p id="17f7" class="pw-post-body-paragraph kv kw iq kx b ky mr jr la lb ms ju ld le mt lg lh li mu lk ll lm mv lo lp lq ij bi translated">如上所述，针对超参数评估 k-NN 变体。对于一个以上的超参数，该测试发展为结合来自 sklearn 库的 ParameterGrid，以进行网格搜索优化。下面，我们将展示不同距离测量和精度所涉及的超参数。</p><ol class=""><li id="9db5" class="np nq iq kx b ky kz lb lc le op li oq lm or lq nu nv nw nx bi translated">基于欧氏距离的 k-NN；</li></ol><p id="79be" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">因为在使用欧几里德距离时只有一个超参数。因此<strong class="kx ir">‘k’</strong>相对于精度的散点图如下所示:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi os"><img src="../Images/e49bfef79599e23f68271360786c8595.png" data-original-src="https://miro.medium.com/v2/resize:fit:772/format:webp/1*LCoKKcR-2fRBalRHHKrVCw.png"/></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk">k-Value V/S Accuracy for Euclidean distance based k-NN</figcaption></figure><p id="13cd" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">2.基于曼哈顿距离的 k-NN；</p><p id="fe29" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">因为在使用曼哈顿距离时只有一个超参数。因此<strong class="kx ir">‘k’</strong>相对于精度的散点图如下所示:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi os"><img src="../Images/17890cb7e6e5b1ef2c03d589c39f8c37.png" data-original-src="https://miro.medium.com/v2/resize:fit:772/format:webp/1*UrVouEjCkMdd2srlPxV-oA.png"/></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk">k-Value V/S Accuracy for Manhattan distance based k-NN</figcaption></figure><p id="32a5" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">3.基于闵可夫斯基距离的 k-NN；</p><p id="1997" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">因为在使用闵可夫斯基距离时有两个超参数。因此<strong class="kx ir">‘k’</strong>和<strong class="kx ir">‘alpha’</strong>关于精度的散点图如下所示:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi os"><img src="../Images/0c949b1b0fd1324264fa460ea4d854fa.png" data-original-src="https://miro.medium.com/v2/resize:fit:772/format:webp/1*Ude_KZmNQjxLJd5e-ub5oA.png"/></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk">k-Value V/S Accuracy for Minkowski distance based k-NN</figcaption></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi os"><img src="../Images/bfcedaebddbefb328d1e91341a3a9299.png" data-original-src="https://miro.medium.com/v2/resize:fit:772/format:webp/1*ar3stmG7DQa4wGV-t1MvtQ.png"/></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk">alpha-Value V/S Accuracy for Minkowski distance based k-NN</figcaption></figure><p id="e6e9" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">4.基于加权欧氏距离的 k-NN；</p><p id="5fcc" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">因为在使用闵可夫斯基距离时有两个超参数。因此<strong class="kx ir">‘k’</strong>和<strong class="kx ir">‘n’</strong>关于精度的散点图如下所示:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi os"><img src="../Images/f57e1d4be572dd9a0d8cb7c49bd1cf63.png" data-original-src="https://miro.medium.com/v2/resize:fit:772/format:webp/1*A9ANeHV4Xtdd6QOs_BtGsQ.png"/></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk">k-Value V/S Accuracy for Minkowski distance based k-NN</figcaption></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi os"><img src="../Images/af3211c8e88a81820981f90681d028d9.png" data-original-src="https://miro.medium.com/v2/resize:fit:772/format:webp/1*31Pipe-sLPnTeiVPes_SVA.png"/></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk">n-Value V/S Accuracy for Minkowski distance based k-NN</figcaption></figure><h1 id="8b36" class="lz ma iq bd mb mc mw me mf mg mx mi mj jw my jx ml jz mz ka mn kc na kd mp mq bi translated">k-NN 变体总体观察:</h1><p id="12d5" class="pw-post-body-paragraph kv kw iq kx b ky mr jr la lb ms ju ld le mt lg lh li mu lk ll lm mv lo lp lq ij bi translated">k-NN 变体的最佳性能在本节中进行评估。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ot"><img src="../Images/addf1690728c1124e403e768c3662864.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*cUTOcT4ek0NEheQySRWsbg.png"/></div></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk">Distance Matrix and Accuracy</figcaption></figure><p id="e8dc" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">在条形图上显示相同的内容:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi ou"><img src="../Images/d9d4b456007de43c18f6d981936c7b9c.png" data-original-src="https://miro.medium.com/v2/resize:fit:816/format:webp/1*HQgeLuIOh9AsjRaU7Pmu1Q.png"/></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk">Distance Matrix and Accuracy</figcaption></figure><h1 id="82bf" class="lz ma iq bd mb mc mw me mf mg mx mi mj jw my jx ml jz mz ka mn kc na kd mp mq bi translated">结论:</h1><p id="8354" class="pw-post-body-paragraph kv kw iq kx b ky mr jr la lb ms ju ld le mt lg lh li mu lk ll lm mv lo lp lq ij bi translated">通过上述观察，可以推断出<strong class="kx ir">基于加权欧几里德距离的矩阵</strong>在根据 BI-RADS 属性和患者年龄预测乳房 x 线摄影肿块病变的严重程度(良性或恶性)方面非常有效</p><h1 id="9f6a" class="lz ma iq bd mb mc mw me mf mg mx mi mj jw my jx ml jz mz ka mn kc na kd mp mq bi translated"><strong class="ak">参考文献:</strong></h1><p id="811c" class="pw-post-body-paragraph kv kw iq kx b ky mr jr la lb ms ju ld le mt lg lh li mu lk ll lm mv lo lp lq ij bi translated"><a class="ae lr" href="https://courses.cit.ie/index.cfm/page/module/moduleId/index.cfm/page/module/code/index.cfm?message=module%20not%20found" rel="noopener ugc nofollow" target="_blank"> <strong class="kx ir">实用机器学习</strong> </a> <strong class="kx ir">课程来自 CIT: </strong></p><p id="b587" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated"><strong class="kx ir">链接到数据集:</strong><a class="ae lr" href="https://archive.ics.uci.edu/ml/datasets/Mammographic+Mass" rel="noopener ugc nofollow" target="_blank">https://archive.ics.uci.edu/ml/datasets/Mammographic+Mass</a></p><p id="1e31" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated"><strong class="kx ir">代码链接:</strong><a class="ae lr" href="https://github.com/praveenjoshi01/cork-institute-of-technology-Practical-Machine-Learning/blob/master/Predicting%20the%20severity%20of%20a%20mammographic%20mass%20lesion/Predicting%20the%20severity%20of%20a%20mammographic%20mass%20lesion.py" rel="noopener ugc nofollow" target="_blank">https://github . com/praveenjoshi 01/cork-institute-of-technology-Practical-Machine-Learning/blob/master/Predicting % 20 the % 20 severity % 20 of % 20a % 20 mamo graphic % 20 mass % 20</a></p></div></div>    
</body>
</html>