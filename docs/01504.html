<html>
<head>
<title>Image segmentation using fastai</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用 fastai 的图像分割</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/image-segmentation-with-fastai-9f8883cc5b53?source=collection_archive---------6-----------------------#2019-03-10">https://towardsdatascience.com/image-segmentation-with-fastai-9f8883cc5b53?source=collection_archive---------6-----------------------#2019-03-10</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="968a" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">了解如何使用 U-net 对图像的每个像素进行颜色编码</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi kf"><img src="../Images/ca6eaa7fb4452393b496896b8d6128ca.png" data-original-src="https://miro.medium.com/v2/resize:fit:1286/format:webp/1*ueGHbAEp5l69TsKnIGh1MQ.png"/></div></figure><h2 id="cafa" class="kn ko iq bd kp kq kr dn ks kt ku dp kv kw kx ky kz la lb lc ld le lf lg lh li bi translated">介绍</h2><p id="6945" class="pw-post-body-paragraph lj lk iq ll b lm ln jr lo lp lq ju lr kw ls lt lu la lv lw lx le ly lz ma mb ij bi translated">图像分割是计算机视觉的一种应用，其中我们对图像中的每个像素进行颜色编码。每个像素代表图像中的一个特定对象。如果你看上面的图片，每条街道都是紫色的，每栋建筑都是橙色的，每棵树都是绿色的，等等。我们为什么要这样做，它与对象检测有何不同？</p><p id="a561" class="pw-post-body-paragraph lj lk iq ll b lm mc jr lo lp md ju lr kw me lt lu la mf lw lx le mg lz ma mb ij bi translated">当我们关心边缘和区域时，当我们想从背景中分离出重要的对象时，通常会使用图像分割。我们希望了解一个对象的具体情况，并从那里对其进行进一步的分析。想象一下无人驾驶汽车。自动驾驶汽车不仅要识别街道，还要知道它的边缘或曲线，以便正确转弯。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi mh"><img src="../Images/0fd56266434fc9c1c8c6aab0ab2b8208.png" data-original-src="https://miro.medium.com/v2/resize:fit:600/format:webp/1*ty3XxFNJkXmj3_VvgqsEDQ.png"/></div></figure><p id="6ddb" class="pw-post-body-paragraph lj lk iq ll b lm mc jr lo lp md ju lr kw me lt lu la mf lw lx le mg lz ma mb ij bi translated">图像分割在医学领域有着重要的意义。需要研究的部分用颜色编码，并从不同角度扫描观察。然后，它们被用于器官的自动测量、细胞计数或基于提取的边界信息的模拟。</p><h2 id="209d" class="kn ko iq bd kp kq kr dn ks kt ku dp kv kw kx ky kz la lb lc ld le lf lg lh li bi translated">该过程</h2><p id="db48" class="pw-post-body-paragraph lj lk iq ll b lm ln jr lo lp lq ju lr kw ls lt lu la lv lw lx le ly lz ma mb ij bi translated">我们将图像分割视为一个分类问题，对于图像中的每个像素，我们试图预测它是什么。是自行车，道路线，人行道，还是建筑？这样，我们产生了一个彩色编码图像，其中每个物体都有相同的颜色。</p><h2 id="5404" class="kn ko iq bd kp kq kr dn ks kt ku dp kv kw kx ky kz la lb lc ld le lf lg lh li bi translated"><strong class="ak">代码</strong></h2><p id="f6b3" class="pw-post-body-paragraph lj lk iq ll b lm ln jr lo lp lq ju lr kw ls lt lu la lv lw lx le ly lz ma mb ij bi translated">像往常一样，我们从导入 fastai 库开始。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="mj mk di ml bf mm"><div class="gh gi mi"><img src="../Images/476bb43f6dc5e1696e17f2b72516b109.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*tz0O76nezpDOPph_SC8f-w.png"/></div></div></figure><p id="f8fa" class="pw-post-body-paragraph lj lk iq ll b lm mc jr lo lp md ju lr kw me lt lu la mf lw lx le mg lz ma mb ij bi translated">让我们先来看看其中的一张图片。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="mj mk di ml bf mm"><div class="gh gi mn"><img src="../Images/9192e3495de47139e753ceed18a73e84.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*G4KAiT2FnJ6B8VOoR026Lg.png"/></div></div></figure><p id="25a4" class="pw-post-body-paragraph lj lk iq ll b lm mc jr lo lp md ju lr kw me lt lu la mf lw lx le mg lz ma mb ij bi translated">接下来，我们来看看分割后的图像是什么样子。由于标记图像中的值是整数，我们不能使用相同的函数来打开它。相反，我们使用<code class="fe mo mp mq mr b">open_mask </code>和<code class="fe mo mp mq mr b">show</code>来显示图像。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="mj mk di ml bf mm"><div class="gh gi ms"><img src="../Images/e139df61828df3447a7dfa38bfd36f7b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*bEFJ5beBWpOAhleBibh4ew.png"/></div></div></figure><p id="b755" class="pw-post-body-paragraph lj lk iq ll b lm mc jr lo lp md ju lr kw me lt lu la mf lw lx le mg lz ma mb ij bi translated">注意<code class="fe mo mp mq mr b">open_mask</code>内部的<code class="fe mo mp mq mr b">get_y_fn</code>功能。在每一个分割问题中，我们都有两组图像，原始图像和标记图像。我们需要将标签图像与正常图像进行匹配。我们用文件名来做这件事。让我们来看看一些图像的文件名。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="mj mk di ml bf mm"><div class="gh gi mt"><img src="../Images/c9189348ba41291488db595684a25810.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*kSTusk04FFEMHh86PxW4Hg.png"/></div></div></figure><p id="2e9e" class="pw-post-body-paragraph lj lk iq ll b lm mc jr lo lp md ju lr kw me lt lu la mf lw lx le mg lz ma mb ij bi translated">我们看到正常图像和标记图像的文件名是相同的，除了相应的标记图像在末尾有一个<code class="fe mo mp mq mr b">_P</code>。因此，我们写了一个函数，对于每一个图像，识别其相应的标记副本。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="mj mk di ml bf mm"><div class="gh gi mu"><img src="../Images/cc992c783afcf41caadaa37cbc2e00b6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*457CVqGxBMzPekKq6FuV7A.png"/></div></div></figure><p id="6404" class="pw-post-body-paragraph lj lk iq ll b lm mc jr lo lp md ju lr kw me lt lu la mf lw lx le mg lz ma mb ij bi translated">我们还有一个名为<code class="fe mo mp mq mr b">codes.txt</code>的文件，它告诉我们标记图像中的整数对应于什么对象。让我们打开标签图像的数据。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="mj mk di ml bf mm"><div class="gh gi mv"><img src="../Images/251e3bff31279d33873b55f65d07c832.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*WrS4dG_tdX8LuVUcs3Cz-Q.png"/></div></div></figure><p id="2282" class="pw-post-body-paragraph lj lk iq ll b lm mc jr lo lp md ju lr kw me lt lu la mf lw lx le mg lz ma mb ij bi translated">现在让我们检查代码文件中这些整数的含义。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="mj mk di ml bf mm"><div class="gh gi mw"><img src="../Images/bc9383f58f0dc09490538f638f5f7b38.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*wEnccO7PSVtzDYdQbCtfeg.png"/></div></div></figure><p id="ac14" class="pw-post-body-paragraph lj lk iq ll b lm mc jr lo lp md ju lr kw me lt lu la mf lw lx le mg lz ma mb ij bi translated">标签数据里有很多 26。从代码文件中的索引 0 开始计数，我们看到整数 26 引用的对象是一棵树。</p><p id="66e8" class="pw-post-body-paragraph lj lk iq ll b lm mc jr lo lp md ju lr kw me lt lu la mf lw lx le mg lz ma mb ij bi translated">既然我们已经理解了我们的数据，我们可以继续创建一个数据束并训练我们的模型。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="mj mk di ml bf mm"><div class="gh gi mx"><img src="../Images/6b1f875bc7e636f15cffb903ecd02fc9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*dq60RsZrovgeemJ3F7z6Yg.png"/></div></div></figure><p id="6c90" class="pw-post-body-paragraph lj lk iq ll b lm mc jr lo lp md ju lr kw me lt lu la mf lw lx le mg lz ma mb ij bi translated">我们不会使用整个数据集，我们还会保持相对较小的批量，因为对每个图像中的每个像素进行分类是一项资源密集型任务。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="mj mk di ml bf mm"><div class="gh gi my"><img src="../Images/77f77514da2430437bb6dba105faefdc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*KDUzRRj1cXs_JgcUavehMg.png"/></div></div></figure><p id="401b" class="pw-post-body-paragraph lj lk iq ll b lm mc jr lo lp md ju lr kw me lt lu la mf lw lx le mg lz ma mb ij bi translated">像往常一样，我们创建我们的数据束。阅读上面的代码:</p><ul class=""><li id="2622" class="mz na iq ll b lm mc lp md kw nb la nc le nd mb ne nf ng nh bi translated">从文件夹创建数据束</li><li id="8568" class="mz na iq ll b lm ni lp nj kw nk la nl le nm mb ne nf ng nh bi translated">根据<code class="fe mo mp mq mr b">valid.txt</code>中提到的文件名将数据分为训练和测试</li><li id="3c87" class="mz na iq ll b lm ni lp nj kw nk la nl le nm mb ne nf ng nh bi translated">使用功能<code class="fe mo mp mq mr b">get_y_fn</code>找到带标签的图像，并将代码用作待预测的类别。</li><li id="dab5" class="mz na iq ll b lm ni lp nj kw nk la nl le nm mb ne nf ng nh bi translated"><a class="ae nn" href="https://medium.com/@dipam44/data-augmentations-in-fastai-84979bbcefaa" rel="noopener">在图像上应用变换</a>(注意这里的<code class="fe mo mp mq mr b">tfm_y = True</code>。这意味着我们对从属图像应用的任何变换也应该应用到目标图像上。(例如:如果我们水平翻转图像，我们也应该翻转相应的标签图像))</li></ul><p id="e7f7" class="pw-post-body-paragraph lj lk iq ll b lm mc jr lo lp md ju lr kw me lt lu la mf lw lx le mg lz ma mb ij bi translated">为了训练，我们将使用一个名为 U-Net 的 CNN 架构，因为他们擅长重建图像。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="mj mk di ml bf mm"><div class="gh gi no"><img src="../Images/6d800c17a6b0848ebe3dcc1a4d41f34b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*h0HnwVqmiQ3PNBQVZk109g.png"/></div></div></figure><p id="fdb4" class="pw-post-body-paragraph lj lk iq ll b lm mc jr lo lp md ju lr kw me lt lu la mf lw lx le mg lz ma mb ij bi translated">在解释什么是 U-Net 之前，请注意上面代码中使用的指标。什么是<code class="fe mo mp mq mr b">acc_camvid</code>？</p><p id="60e6" class="pw-post-body-paragraph lj lk iq ll b lm mc jr lo lp md ju lr kw me lt lu la mf lw lx le mg lz ma mb ij bi translated">图像分割问题中的精度与任何分类问题中的精度相同。</p><pre class="kg kh ki kj gt np mr nq nr aw ns bi"><span id="eebb" class="kn ko iq mr b gy nt nu l nv nw">Accuracy = no. of correctly classified pixels / total no. of pixels</span></pre><p id="43ce" class="pw-post-body-paragraph lj lk iq ll b lm mc jr lo lp md ju lr kw me lt lu la mf lw lx le mg lz ma mb ij bi translated">然而，在这种情况下，一些像素被标记为<code class="fe mo mp mq mr b">Void</code>(该标签也存在于<code class="fe mo mp mq mr b">codes.txt</code>)，在计算精度时不应予以考虑。因此，我们创建了一个新的函数来计算精度，在这里我们避开了这些标签。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="mj mk di ml bf mm"><div class="gh gi no"><img src="../Images/58ee78353aea34de36133d26b59eaea1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*UWIt3BVvTBsQ7ZfV8X3Pcw.png"/></div></div></figure><p id="750d" class="pw-post-body-paragraph lj lk iq ll b lm mc jr lo lp md ju lr kw me lt lu la mf lw lx le mg lz ma mb ij bi translated">CNN 的工作方式是将一幅图像分解成越来越小的部分，直到只剩下一件事可以预测(下图 U-Net 架构的左边部分)。一个 U-Net 然后把它变得越来越大，它为 CNN 的每个阶段都这样做。然而，从一个小矢量构建一幅图像是一项困难的工作。因此，我们有从原始卷积层到反卷积网络的连接。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="mj mk di ml bf mm"><div class="gh gi nx"><img src="../Images/342f2c88bc2f14bea027a44026df8a50.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*lvXoKMHoPJMKpKK7keZMEA.png"/></div></div></figure><p id="31ba" class="pw-post-body-paragraph lj lk iq ll b lm mc jr lo lp md ju lr kw me lt lu la mf lw lx le mg lz ma mb ij bi translated">像往常一样，我们找到<a class="ae nn" href="https://medium.com/@dipam44/learning-rate-and-golf-87c8d4697e31" rel="noopener">学习率</a>并训练我们的模型。即使只有一半的数据集，我们也能达到 92%的准确率。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi ny"><img src="../Images/8667529db0c4c737e61c491efcfd66cc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1066/format:webp/1*m-VvGKFkQof0fK5UwPzUiQ.png"/></div></figure><p id="02c9" class="pw-post-body-paragraph lj lk iq ll b lm mc jr lo lp md ju lr kw me lt lu la mf lw lx le mg lz ma mb ij bi translated">检查一些结果。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="mj mk di ml bf mm"><div class="gh gi nz"><img src="../Images/211e145697d403d47230cc42a6e5f04c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*5jiyzwDVitVjl8tuqcGceA.png"/></div></div></figure><p id="5f2c" class="pw-post-body-paragraph lj lk iq ll b lm mc jr lo lp md ju lr kw me lt lu la mf lw lx le mg lz ma mb ij bi translated">事实是真正的目标，而预测是我们的模型所标注的。</p><p id="4ecf" class="pw-post-body-paragraph lj lk iq ll b lm mc jr lo lp md ju lr kw me lt lu la mf lw lx le mg lz ma mb ij bi translated">我们现在可以在完整的数据集上进行训练。</p><h2 id="eff2" class="kn ko iq bd kp kq kr dn ks kt ku dp kv kw kx ky kz la lb lc ld le lf lg lh li bi translated">结论</h2><p id="ea1c" class="pw-post-body-paragraph lj lk iq ll b lm ln jr lo lp lq ju lr kw ls lt lu la lv lw lx le ly lz ma mb ij bi translated">这就是本文的全部内容。在本文中，我们看到了如何使用 U-net 对图像的每个像素进行颜色编码。U-nets 越来越受欢迎，因为它们在从模糊图像生成高分辨率图像等应用上的表现优于 GANs。因此，知道它们是什么以及如何使用它们是非常有用的。</p><p id="7c41" class="pw-post-body-paragraph lj lk iq ll b lm mc jr lo lp md ju lr kw me lt lu la mf lw lx le mg lz ma mb ij bi translated"><a class="ae nn" href="https://www.kaggle.com/dipam7/image-segmentation-using-fastai" rel="noopener ugc nofollow" target="_blank"> <em class="oa">完整的笔记本可以在这里找到。</em>T3】</a></p><p id="8aef" class="pw-post-body-paragraph lj lk iq ll b lm mc jr lo lp md ju lr kw me lt lu la mf lw lx le mg lz ma mb ij bi translated">如果你想了解更多关于深度学习的知识，可以看看我在这方面的系列文章:</p><div class="ob oc gp gr od oe"><a href="https://medium.com/@dipam44/deep-learning-series-30ad108fbe2b" rel="noopener follow" target="_blank"><div class="of ab fo"><div class="og ab oh cl cj oi"><h2 class="bd ir gy z fp oj fr fs ok fu fw ip bi translated">深度学习系列</h2><div class="ol l"><h3 class="bd b gy z fp oj fr fs ok fu fw dk translated">我所有关于深度学习的文章的系统列表</h3></div><div class="om l"><p class="bd b dl z fp oj fr fs ok fu fw dk translated">medium.com</p></div></div><div class="on l"><div class="oo l op oq or on os kl oe"/></div></div></a></div><p id="224f" class="pw-post-body-paragraph lj lk iq ll b lm mc jr lo lp md ju lr kw me lt lu la mf lw lx le mg lz ma mb ij bi translated">~快乐学习</p></div></div>    
</body>
</html>