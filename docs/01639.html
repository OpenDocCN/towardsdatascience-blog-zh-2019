<html>
<head>
<title>How to setup the Python and Spark environment for development, with good software engineering practices</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">如何使用良好的软件工程实践来设置 Python 和 Spark 开发环境</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/how-to-setup-the-pyspark-environment-for-development-with-good-software-engineering-practices-5fb457433a86?source=collection_archive---------7-----------------------#2019-03-17">https://towardsdatascience.com/how-to-setup-the-pyspark-environment-for-development-with-good-software-engineering-practices-5fb457433a86?source=collection_archive---------7-----------------------#2019-03-17</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><figure class="gl gn jr js jt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi jq"><img src="../Images/810058a93097118f26c91f8ceef0146f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*3Yl79Mdg7g4ijyLPxM3dbQ.jpeg"/></div></div></figure><p id="3041" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">在本文中，我们将讨论如何设置我们的开发环境以创建高质量的 python 代码，以及如何自动化一些繁琐的任务以加快部署。</p><p id="fd4a" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">我们将回顾以下步骤:</p><ul class=""><li id="324e" class="kz la it kd b ke kf ki kj km lb kq lc ku ld ky le lf lg lh bi translated">使用<a class="ae li" href="https://pipenv.readthedocs.io/en/latest/" rel="noopener ugc nofollow" target="_blank"> <strong class="kd iu"> pipenv </strong> </a>在隔离的虚拟环境中设置我们的依赖关系</li><li id="65d6" class="kz la it kd b ke lj ki lk km ll kq lm ku ln ky le lf lg lh bi translated">如何为多项任务设置项目结构</li><li id="8b9c" class="kz la it kd b ke lj ki lk km ll kq lm ku ln ky le lf lg lh bi translated">如何运行 pyspark 作业</li><li id="a8f8" class="kz la it kd b ke lj ki lk km ll kq lm ku ln ky le lf lg lh bi translated">如何使用<a class="ae li" href="https://opensource.com/article/18/8/what-how-makefile" rel="noopener ugc nofollow" target="_blank"> <strong class="kd iu"> Makefile </strong> </a> <strong class="kd iu"> </strong>来自动化开发步骤</li><li id="e06f" class="kz la it kd b ke lj ki lk km ll kq lm ku ln ky le lf lg lh bi translated">如何使用<a class="ae li" href="http://flake8.pycqa.org/en/latest/" rel="noopener ugc nofollow" target="_blank"> <strong class="kd iu"> flake8 </strong> </a>测试我们代码的质量</li><li id="7ed6" class="kz la it kd b ke lj ki lk km ll kq lm ku ln ky le lf lg lh bi translated">如何使用<a class="ae li" href="https://pypi.org/project/pytest-spark/" rel="noopener ugc nofollow" target="_blank"> <strong class="kd iu"> pytest-spark </strong> </a>为 PySpark 应用运行单元测试</li><li id="4f5a" class="kz la it kd b ke lj ki lk km ll kq lm ku ln ky le lf lg lh bi translated">运行测试覆盖，看看我们是否已经使用<a class="ae li" href="https://pypi.org/project/pytest-cov/" rel="noopener ugc nofollow" target="_blank"> <strong class="kd iu"> pytest-cov </strong> </a>创建了足够的单元测试</li></ul><h1 id="257f" class="lo lp it bd lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk ml bi translated">步骤 1:设置虚拟环境</h1><p id="f35b" class="pw-post-body-paragraph kb kc it kd b ke mm kg kh ki mn kk kl km mo ko kp kq mp ks kt ku mq kw kx ky im bi translated">虚拟环境有助于我们将特定应用程序的依赖关系与系统的整体依赖关系隔离开来。这很好，因为我们不会陷入现有库的依赖性问题，并且在单独的系统上安装或卸载它们更容易，比如 docker 容器或服务器。对于这个任务，我们将使用<strong class="kd iu"> pipenv。</strong></p><p id="151c" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">例如，要在 mac os 系统上安装它，请运行:</p><pre class="mr ms mt mu gt mv mw mx my aw mz bi"><span id="2a4d" class="na lp it mw b gy nb nc l nd ne">brew install pipenv</span></pre><p id="05a3" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">为了声明应用程序的依赖项(库),我们需要在项目的路径路径中创建一个<strong class="kd iu"> Pipfile </strong>:</p><pre class="mr ms mt mu gt mv mw mx my aw mz bi"><span id="8e87" class="na lp it mw b gy nb nc l nd ne">[[source]]<br/>url = '<a class="ae li" href="https://pypi.python.org/simple'" rel="noopener ugc nofollow" target="_blank">https://pypi.python.org/simple'</a><br/>verify_ssl = true<br/>name = 'pypi'</span><span id="1cc9" class="na lp it mw b gy nf nc l nd ne">[requires]<br/>python_version = "3.6"</span><span id="b693" class="na lp it mw b gy nf nc l nd ne">[packages]<br/>flake8 = "*"<br/>pytest-spark = "&gt;=0.4.4"<br/>pyspark = "&gt;=2.4.0"<br/>pytest-cov = "*"</span></pre><p id="a2e8" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">这里有三个组成部分。在<strong class="kd iu"> [[source]] </strong>标签中，我们声明了下载所有包的<strong class="kd iu"> url </strong>，在<strong class="kd iu">【requires】</strong>中，我们定义了 python 版本，最后在<strong class="kd iu">【packages】</strong>中定义了我们需要的依赖项。我们可以将一个依赖项绑定到某个版本，或者使用<strong class="kd iu">" *</strong>符号获取最新的版本。</p><p id="2e48" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">要创建虚拟环境并激活它，我们需要在终端中运行两个命令:</p><pre class="mr ms mt mu gt mv mw mx my aw mz bi"><span id="5a63" class="na lp it mw b gy nb nc l nd ne">pipenv --three install<br/>pipenv shell</span></pre><p id="b84d" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">一旦这样做了一次，您应该看到您在一个新的 venv 中，项目的名称出现在命令行的终端中(默认情况下，env 使用项目的名称):</p><pre class="mr ms mt mu gt mv mw mx my aw mz bi"><span id="d4cc" class="na lp it mw b gy nb nc l nd ne">(pyspark-project-template) host:project$ </span></pre><p id="5319" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">现在，您可以使用两个命令移入和移出。</p><p id="75c9" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">停用环境并移回标准环境:</p><pre class="mr ms mt mu gt mv mw mx my aw mz bi"><span id="dc8a" class="na lp it mw b gy nb nc l nd ne">deactivate</span></pre><p id="4fa4" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">再次激活虚拟环境(您需要在项目的根目录下):</p><pre class="mr ms mt mu gt mv mw mx my aw mz bi"><span id="30f6" class="na lp it mw b gy nb nc l nd ne">source `pipenv --venv`/bin/activate</span></pre><h1 id="4648" class="lo lp it bd lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk ml bi translated">步骤 2:项目结构</h1><p id="4afe" class="pw-post-body-paragraph kb kc it kd b ke mm kg kh ki mn kk kl km mo ko kp kq mp ks kt ku mq kw kx ky im bi translated">项目可以有以下结构:</p><pre class="mr ms mt mu gt mv mw mx my aw mz bi"><span id="9250" class="na lp it mw b gy nb nc l nd ne">pyspark-project-template<br/>    src/<br/>        jobs/   <br/>            pi/<br/>                __init__.py<br/>                resources/<br/>                    args.json<br/>            word_count/<br/>                __init__.py<br/>                resources/<br/>                    args.json<br/>                    word_count.csv<br/>        main.py<br/>    test/<br/>        jobs/<br/>            pi/<br/>                test_pi.py<br/>            word_count/<br/>                test_word_count.py</span></pre><p id="8087" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">某 __init__。为了使事情更简单，py 文件被排除在外，但是您可以在 github 上找到教程末尾的完整项目的链接。</p><p id="0de6" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">我们基本上有源代码和测试。每个作业都放在一个文件夹中，每个作业都有一个资源文件夹，我们可以在其中添加该作业所需的额外文件和配置。</p><p id="7759" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">在本教程中，我使用了两个经典的例子——<strong class="kd iu">pi</strong>，生成圆周率数字直到小数位数，以及<strong class="kd iu">字数统计</strong>，计算 csv 文件中的字数。</p><h1 id="cba8" class="lo lp it bd lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk ml bi translated">步骤 3:使用 spark-submit 运行作业</h1><p id="a90b" class="pw-post-body-paragraph kb kc it kd b ke mm kg kh ki mn kk kl km mo ko kp kq mp ks kt ku mq kw kx ky im bi translated">让我们先看看<strong class="kd iu"> main.py </strong>文件是什么样子的:</p><figure class="mr ms mt mu gt ju"><div class="bz fp l di"><div class="ng nh l"/></div></figure><p id="b502" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">当我们运行我们的作业时，我们需要两个命令行参数:<strong class="kd iu"> —作业</strong>，是我们想要运行的作业的名称(在 out case pi 或 word_count 中)和<strong class="kd iu"> — res-path </strong>，是作业的相对路径。我们需要第二个参数，因为 spark 需要知道资源的完整路径。在生产环境中，当我们在集群上部署代码时，我们会将资源转移到 HDFS 或 S3，我们会使用那条路径。</p><p id="e817" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">在进一步解释代码之前，我们需要提到，我们必须压缩<strong class="kd iu">作业</strong>文件夹，并将其传递给<strong class="kd iu"> spark-submit </strong>语句<strong class="kd iu">。</strong>假设我们在项目的根中:</p><pre class="mr ms mt mu gt mv mw mx my aw mz bi"><span id="f234" class="na lp it mw b gy nb nc l nd ne">cd src/ <br/>zip -r ../jobs.zip jobs/</span></pre><p id="f14b" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">这将使代码在我们的应用程序中作为一个模块可用。基本上在第 16 行的<strong class="kd iu"> main.py 中，</strong>我们正在编程导入<strong class="kd iu"> job </strong>模块。</p><p id="6ef8" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">我们的两个作业，<strong class="kd iu"> pi </strong>和<strong class="kd iu"> word_count，</strong>都有一个<strong class="kd iu"> run </strong>函数，所以我们只需要运行这个函数，来启动作业(main.py 中的<strong class="kd iu"> line 17)。我们也在那里传递作业的配置。</strong></p><p id="82ad" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">让我们看一下我们的<strong class="kd iu"> word_count </strong>工作来进一步理解这个例子:</p><figure class="mr ms mt mu gt ju"><div class="bz fp l di"><div class="ng nh l"/></div></figure><p id="f6c5" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">这个代码在<strong class="kd iu"> __init__ 中定义。py </strong>文件在<strong class="kd iu"> word_count </strong>文件夹中。我们可以看到，我们使用两个配置参数来读取 csv 文件:相对路径和 csv 文件在 resources 文件夹中的位置。剩下的代码只是计算字数，所以我们在这里不再赘述。值得一提的是，每个作业在 resources 文件夹中都有一个<strong class="kd iu"> args.json </strong>文件。这里我们实际上定义了传递给作业的配置。这是<strong class="kd iu">字数</strong>作业的配置文件:</p><pre class="mr ms mt mu gt mv mw mx my aw mz bi"><span id="5c8d" class="na lp it mw b gy nb nc l nd ne">{<br/>  "words_file_path": "/word_count/resources/word_count.csv"<br/>}</span></pre><p id="ead8" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">现在我们已经有了运行我们的<strong class="kd iu"> spark-submit </strong>命令的所有细节:</p><pre class="mr ms mt mu gt mv mw mx my aw mz bi"><span id="b5ab" class="na lp it mw b gy nb nc l nd ne">spark-submit --py-files jobs.zip src/main.py --job word_count --res-path /your/path/pyspark-project-template/src/jobs</span></pre><p id="4add" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">要运行另一个作业，<strong class="kd iu"> pi，</strong>，我们只需更改<strong class="kd iu"> —作业</strong>标志的参数。</p><h1 id="070b" class="lo lp it bd lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk ml bi translated">步骤 4:编写单元测试，并在覆盖范围内运行它们</h1><p id="3ab8" class="pw-post-body-paragraph kb kc it kd b ke mm kg kh ki mn kk kl km mo ko kp kq mp ks kt ku mq kw kx ky im bi translated">为了编写 pyspark 应用程序的测试，我们使用了<strong class="kd iu"> pytest-spark </strong>，一个非常容易使用的模块。</p><p id="b3bb" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated"><strong class="kd iu"> word_count </strong>作业单元测试:</p><figure class="mr ms mt mu gt ju"><div class="bz fp l di"><div class="ng nh l"/></div></figure><p id="b507" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">我们需要从<strong class="kd iu"> src </strong>模块中导入我们想要测试的函数。这里更有趣的部分是我们如何进行<strong class="kd iu"> test_word_count_run。</strong>我们可以看到没有初始化 spark 会话，我们只是在测试中将它作为参数接收。这要感谢<strong class="kd iu"> pytest-spark </strong>模块，所以我们可以专注于编写测试，而不是编写样板代码。</p><p id="f397" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">接下来让我们讨论一下代码覆盖率。我们如何知道我们是否写了足够多的单元测试？很简单，我们运行一个测试覆盖工具，它会告诉我们哪些代码还没有被测试。对于 python，我们可以使用<strong class="kd iu"> pytest-cov </strong>模块。要使用代码覆盖运行所有测试，我们必须运行:</p><pre class="mr ms mt mu gt mv mw mx my aw mz bi"><span id="855a" class="na lp it mw b gy nb nc l nd ne">pytest --cov=src test/jobs/</span></pre><p id="b4ad" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">where <strong class="kd iu"> — cov </strong>标志告诉 pytest 在哪里检查覆盖率。</p><p id="f0dc" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">测试覆盖率结果:</p><pre class="mr ms mt mu gt mv mw mx my aw mz bi"><span id="9ccb" class="na lp it mw b gy nb nc l nd ne">---------- coverage: platform darwin, python 3.7.2-final-0 -----------<br/>Name                              Stmts   Miss  Cover<br/>-----------------------------------------------------<br/>src/__init__.py                       0      0   100%<br/>src/jobs/__init__.py                  0      0   100%<br/>src/jobs/pi/__init__.py              11      0   100%<br/>src/jobs/word_count/__init__.py       9      0   100%<br/>-----------------------------------------------------<br/>TOTAL                                20      0   100%</span></pre><p id="297e" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">我们的测试覆盖率是 100%，但是等一下，少了一个文件！为什么<strong class="kd iu"> main.py </strong>没有列在那里？</p><p id="c1d9" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">如果我们认为我们有不需要测试的 python 代码，我们可以将其从报告中排除。为此，我们需要创建一个<strong class="kd iu">。coveragerc </strong>文件放在我们项目的根目录下。对于这个例子，它看起来像这样:</p><pre class="mr ms mt mu gt mv mw mx my aw mz bi"><span id="54e9" class="na lp it mw b gy nb nc l nd ne">[run]<br/>omit = src/main.py</span></pre><h1 id="2d1d" class="lo lp it bd lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk ml bi translated">步骤 5:运行静态代码分析</h1><p id="37ab" class="pw-post-body-paragraph kb kc it kd b ke mm kg kh ki mn kk kl km mo ko kp kq mp ks kt ku mq kw kx ky im bi translated">太好了，我们有一些代码，我们可以运行它，我们有覆盖率良好的单元测试。我们做得对吗？还没有！我们还需要确保按照 python 的最佳实践编写易读的代码。为此，我们必须用名为<strong class="kd iu"> flake8 的 python 模块来检查我们的代码。</strong></p><p id="1878" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">要运行它:</p><pre class="mr ms mt mu gt mv mw mx my aw mz bi"><span id="0f2d" class="na lp it mw b gy nb nc l nd ne">flake8 ./src</span></pre><p id="8a41" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">它将分析<strong class="kd iu"> src </strong>文件夹。如果我们有干净的代码，我们应该不会得到警告。但是没有，我们有几个问题:</p><pre class="mr ms mt mu gt mv mw mx my aw mz bi"><span id="3513" class="na lp it mw b gy nb nc l nd ne">flake8 ./src<br/>./src/jobs/pi/__init__.py:13:1: E302 expected 2 blank lines, found 1<br/>./src/jobs/pi/__init__.py:15:73: E231 missing whitespace after ','<br/>./src/jobs/pi/__init__.py:15:80: E501 line too long (113 &gt; 79 characters)</span></pre><p id="f290" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">让我们看看代码:</p><figure class="mr ms mt mu gt ju"><div class="bz fp l di"><div class="ng nh l"/></div></figure><p id="eba6" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">我们可以看到在第<strong class="kd iu"> 13 行有一个<strong class="kd iu"> E302 </strong>警告。这意味着我们需要在这两个方法之间多加一行。然后在<strong class="kd iu"> 15 线上安装<strong class="kd iu"> E231 </strong>和<strong class="kd iu"> E501 </strong>。</strong>这一行的第一个警告，告诉我们在<code class="fe ni nj nk mw b"><strong class="kd iu">range(1, number_of_steps +1),</strong></code> <strong class="kd iu"> </strong>和<code class="fe ni nj nk mw b"><strong class="kd iu">config[</strong></code> <strong class="kd iu"> </strong>之间需要一个额外的空格，第二个警告通知我们这一行太长了，很难读懂(我们甚至不能完整的看到大意！).</strong></p><p id="90e6" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">在我们解决了所有的警告之后，代码看起来更容易阅读了:</p><figure class="mr ms mt mu gt ju"><div class="bz fp l di"><div class="ng nh l"/></div></figure><h1 id="7bc8" class="lo lp it bd lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk ml bi translated">步骤 6:用一个 Makefile 把它们放在一起</h1><p id="1f70" class="pw-post-body-paragraph kb kc it kd b ke mm kg kh ki mn kk kl km mo ko kp kq mp ks kt ku mq kw kx ky im bi translated">因为我们已经在终端中运行了许多命令，所以在最后一步中，我们将研究如何简化和自动化这项任务。</p><p id="630a" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">我们可以在项目的根目录下创建一个<strong class="kd iu"> Makefile </strong>，如下图所示:</p><pre class="mr ms mt mu gt mv mw mx my aw mz bi"><span id="345e" class="na lp it mw b gy nb nc l nd ne">.DEFAULT_GOAL := run</span><span id="31f2" class="na lp it mw b gy nf nc l nd ne">init:<br/> pipenv --three install<br/> pipenv shell</span><span id="d7e3" class="na lp it mw b gy nf nc l nd ne">analyze:<br/> flake8 ./src</span><span id="cc22" class="na lp it mw b gy nf nc l nd ne">run_tests:<br/> pytest --cov=src test/jobs/</span><span id="531a" class="na lp it mw b gy nf nc l nd ne">run:<br/> find . -name '__pycache__' | xargs rm -rf<br/> rm -f jobs.zip</span><span id="793d" class="na lp it mw b gy nf nc l nd ne"> cd src/ &amp;&amp; zip -r ../jobs.zip jobs/</span><span id="2432" class="na lp it mw b gy nf nc l nd ne"> spark-submit --py-files jobs.zip src/main.py --job $(JOB_NAME) --res-path $(CONF_PATH)</span></pre><p id="25e6" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">如果我们想要运行覆盖率测试，我们可以简单地输入:</p><pre class="mr ms mt mu gt mv mw mx my aw mz bi"><span id="1d72" class="na lp it mw b gy nb nc l nd ne">make run_tests</span></pre><p id="118b" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">如果我们想要运行<strong class="kd iu"> pi </strong>作业:</p><pre class="mr ms mt mu gt mv mw mx my aw mz bi"><span id="0618" class="na lp it mw b gy nb nc l nd ne">make run JOB_NAME=pi CONF_PATH=/your/path/pyspark-project-template/src/jobs</span></pre><p id="df77" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">那都是乡亲们！我希望你觉得这是有用的。</p><p id="b0fd" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">一如既往，代码存储在<a class="ae li" href="https://github.com/BogdanCojocar/medium-articles/tree/master/pyspark-project-template" rel="noopener ugc nofollow" target="_blank"> github </a>上。</p></div></div>    
</body>
</html>