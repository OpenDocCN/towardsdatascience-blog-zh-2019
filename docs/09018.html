<html>
<head>
<title>Artificial Intelligence for learning Sign Language</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">学习手语的人工智能</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/artificial-intelligence-for-learning-sign-language-ab1f7937195b?source=collection_archive---------23-----------------------#2019-12-01">https://towardsdatascience.com/artificial-intelligence-for-learning-sign-language-ab1f7937195b?source=collection_archive---------23-----------------------#2019-12-01</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><figure class="gl gn jr js jt ju gh gi paragraph-image"><div class="gh gi jq"><img src="../Images/143b6b4ca0b2119bf4b62ca65b9f86fc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1392/format:webp/1*tXUZy4qBnvtPw8Z0UXUeug.jpeg"/></div><figcaption class="jx jy gj gh gi jz ka bd b be z dk">LOVE in Sign Language</figcaption></figure><p id="0cdd" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">这个故事开始于马德里<strong class="kd iu">西班牙</strong>。冬天来了，一个由四个年轻的爱好者组成的团队开始了一个项目。</p><p id="72a4" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">最初的想法是创建一个学习<em class="kz">手语</em>的应用程序，不仅因为这是我们社会的一个有趣的方面，也是为了那些需要学习它来交流的 3400 万患有残疾听力损失的儿童。</p><p id="55b7" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">技术的美妙之处在于它也可以用来帮助别人。我们的目标正是这样。</p><p id="7c9b" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">当时的主要想法是，构建一个<strong class="kd iu">神经网络模型</strong>，能够从相机捕捉的图像中实时分类用户所做手势的表示。这个“用户”可以是在家学习手语或巩固他们在学校教他或她的东西的孩子，也可以是对从头开始学习手语感兴趣的成年人，例如，从字母表字母或数字开始。</p><p id="cd69" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated"><strong class="kd iu">数据</strong></p><p id="86cc" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">在每个像我们这样与数据相关的项目中，工作的一个重要部分是数据集。没有数据，我们甚至无法开始尝试构建一个能够理解用户在摄像机前做什么手势的模型。</p><p id="02d7" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">由于我们来自西班牙，我们首先想到的是为 LSE 开发应用程序。但是研究和创新并不是一条玫瑰色的道路。我们找不到任何与西班牙语字母表相关的数据，在互联网上找不到，甚至没有写信给可能拥有这些信息的实体。所以我们不得不决定使用出现在几个网站上的数据:美国手语。</p><p id="81e2" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">作为初始阶段，我们开始探索字母和从 0 到 9 的数字。然后我们有了另一个问题。该应用从一开始就被认为是基于构建一个能够从静态图像中分类标志的<strong class="kd iu">深度神经网络</strong>。这个事实给有运动的字母带来了一个问题:J 和 z。我们决定暂时去掉这两个字母。</p><p id="a836" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">然后，我们找到了字母和数字的数据。这些数据实际上是人们手部的图像，取自 Kaggle，一个在我们社区广泛使用的存储库。</p><p id="87a7" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated"><strong class="kd iu">型号</strong></p><p id="b25f" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">第二阶段是训练一个模型，让它变得如此智能，以至于当它看到一个标志的图像时，它能识别出是哪一个。我们从一个<strong class="kd iu">卷积神经网络(CNN) </strong>开始，它有几个卷积层，最大池化、扁平化和全连接。但我们从经验中了解到，即使验证准确性很高，验证损失很低，但最重要的是实时性能，用我们的相机，用不同的手和手后面不同的背景。这不是一个好结果。</p><p id="a266" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">那时，我们决定利用以前的智能模型，一个能够从图像中分类对象的深度 CNN，用 ImageNet 训练的 VGG19。</p><figure class="lb lc ld le gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="lf lg di lh bf li"><div class="gh gi la"><img src="../Images/75f3d09c383102ad28c800e2ced54e2e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*w7XXoDrU4rvm7Qi7mHNHMQ.jpeg"/></div></div><figcaption class="jx jy gj gh gi jz ka bd b be z dk">Network architecture of the VGG19</figcaption></figure><p id="bf22" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">ImageNet 是一个大型数据库，拥有超过 1400 万张图片，包含 20000 多个类别，精简版有 1000 个类别。用这个数据集训练了几个模型，使它们能够理解图像中非常抽象和有创造性的部分。我们必须利用这些特性。这个过程在社区中被称为“T2”特征提取。只需采用一个没有顶层的预训练模型，冻结该模型，添加我们的顶层，指定我们想要分类的类别数量，并用我们的数据集对其进行训练。这似乎是一个好主意，但同样，在实时体验中，它并不像我们希望的那样好。</p><p id="d932" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">然后，我们后退一步，思考使用预训练模型的想法。用来训练 VGG19 的 ImageNet 数据集不包含徒手类，也不包含 sing 语言表示类。所以我们试图做的是强迫一个网络对一些东西进行分类，而它基本上只能智能地对世界上除了手以外的其他东西进行分类。</p><p id="4f66" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">那时我们决定进行“<strong class="kd iu">微调</strong>”，这是另一种在<strong class="kd iu">深度学习</strong>中经常使用的技术。我们决定只冻结 VGG19 的前 6 层，并用我们的数据集和顶层一起训练其他层。</p><p id="6fe2" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">另一方面，但与此同时，数据集正在经历几次变化。我们意识到初始数据集太差，然后我们给自己设定了用自己的相机获取图像的任务，我们将它们与初始数据集混合，并使用图像的混合来设置一个<strong class="kd iu">图像数据生成器</strong>，包括一些转换，如剪切范围、宽度和高度的移动等。</p><p id="74c3" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">有了这两种成分的混合，一个非常强大的数据集和一个超级智能的模型，我们只希望有好的结果。我们抓到他们了。</p><figure class="lb lc ld le gt ju"><div class="bz fp l di"><div class="lj lk l"/></div><figcaption class="jx jy gj gh gi jz ka bd b be z dk">Example of application with the Sign Language Digits</figcaption></figure><p id="3340" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">我们乐于接受对我们最初工作的反馈，因为我们目前正在开发它，以便将来有更好的应用程序来帮助他人。我们在 github 上也有开放代码，链接如下:</p><div class="ll lm gp gr ln lo"><a href="https://github.com/ecabestadistica/sign-language-translator-python-opencv" rel="noopener  ugc nofollow" target="_blank"><div class="lp ab fo"><div class="lq ab lr cl cj ls"><h2 class="bd iu gy z fp lt fr fs lu fu fw is bi translated">ecabestadistica/手语翻译-python-opencv</h2><div class="lv l"><h3 class="bd b gy z fp lt fr fs lu fu fw dk translated">项目的目标是为儿童提供必要的应用程序</h3></div><div class="lw l"><p class="bd b dl z fp lt fr fs lu fu fw dk translated">github.com</p></div></div><div class="lx l"><div class="ly l lz ma mb lx mc jv lo"/></div></div></a></div><p id="1880" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">我们是 Elisa Cabana ( <a class="ae md" href="https://twitter.com/elisacabana" rel="noopener ugc nofollow" target="_blank"> Twitter </a>)、Jessica Costoso、Jordi Viader ( <a class="ae md" href="https://www.linkedin.com/in/jordiviader/" rel="noopener ugc nofollow" target="_blank"> LinkedIn </a>)和 Miguel Gallego ( <a class="ae md" href="https://github.com/MiguelyGallego" rel="noopener ugc nofollow" target="_blank"> GitHub </a>)，在卡洛斯·辛坦拿(<a class="ae md" href="https://www.youtube.com/channel/UCy5znSnfMsDwaLlROnZ7Qbg" rel="noopener ugc nofollow" target="_blank"> Youtube </a>)的帮助下。我们希望有一天技术被用来消除那些需要我们帮助的人的障碍，因为对一些人来说，障碍实际上是所有人的损失。</p></div></div>    
</body>
</html>