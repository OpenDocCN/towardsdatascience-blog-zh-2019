<html>
<head>
<title>Layman’s Introduction to Backpropagation</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">反向传播入门</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/laymans-introduction-to-backpropagation-efa2c64437db?source=collection_archive---------5-----------------------#2019-06-13">https://towardsdatascience.com/laymans-introduction-to-backpropagation-efa2c64437db?source=collection_archive---------5-----------------------#2019-06-13</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="adc2" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">训练一个神经网络不是一件容易的事，但理解它可能很简单</h2></div><p id="9703" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">反向传播是调整<a class="ae le" href="https://medium.com/datadriveninvestor/neural-networks-an-intuition-640821d5bd83" rel="noopener">神经网络</a>的权重以提高预测精度的过程。神经网络中的信息流动有两个方向。</p><ol class=""><li id="01e7" class="lf lg it kk b kl km ko kp kr lh kv li kz lj ld lk ll lm ln bi translated"><strong class="kk iu">前向传播——也称为推理——</strong>是指数据进入神经网络并弹出预测。</li><li id="1a50" class="lf lg it kk b kl lo ko lp kr lq kv lr kz ls ld lk ll lm ln bi translated"><strong class="kk iu">反向传播</strong> —通过查看预测和实际结果之间的差异来调整权重的过程。</li></ol><figure class="lu lv lw lx gt ly gh gi paragraph-image"><div role="button" tabindex="0" class="lz ma di mb bf mc"><div class="gh gi lt"><img src="../Images/931dea9ccf4e5bd38f1bbbf68ecbd656.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*0CCGZxcqh4HdxBVl"/></div></div><figcaption class="mf mg gj gh gi mh mi bd b be z dk">Photo by <a class="ae le" href="https://unsplash.com/@pankajpatel?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Pankaj Patel</a> on <a class="ae le" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><p id="249f" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">反向传播是在神经网络准备部署到现场之前完成的。人们使用已知结果的训练数据来执行反向传播。一旦我们确信网络得到了充分的训练，我们就开始<strong class="kk iu">推理过程。</strong></p><p id="78d4" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">如今，反向传播就是使用无数工具中的一个命令。因为这些工具很容易训练神经网络，大多数人倾向于跳过理解反向传播背后的直觉。可以理解，当数学看起来像这样。</p><figure class="lu lv lw lx gt ly gh gi paragraph-image"><div role="button" tabindex="0" class="lz ma di mb bf mc"><div class="gh gi mj"><img src="../Images/95a2055109c6c341310156e1d1d90a22.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*d4_EztBjuykjxXE4OtFzog.png"/></div></div><figcaption class="mf mg gj gh gi mh mi bd b be z dk">Andrew Ng’s Coursera course: <a class="ae le" href="https://www.coursera.org/learn/machine-learning" rel="noopener ugc nofollow" target="_blank">https://www.coursera.org/learn/machine-learning</a></figcaption></figure><p id="345e" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">但是，在如此多的机器智能的核心过程背后获得一种直觉是非常有意义的。</p><h2 id="cc8c" class="mk ml it bd mm mn mo dn mp mq mr dp ms kr mt mu mv kv mw mx my kz mz na nb nc bi translated">权重在神经网络中的作用</h2><p id="278d" class="pw-post-body-paragraph ki kj it kk b kl nd ju kn ko ne jx kq kr nf kt ku kv ng kx ky kz nh lb lc ld im bi translated">在试图理解反向传播之前，让我们看看权重实际上如何影响输出，即预测。第一层的信号输入通过控制相邻层神经元之间连接强度的权重向前传播到网络中。</p><figure class="lu lv lw lx gt ly gh gi paragraph-image"><div class="gh gi ni"><img src="../Images/dc5d2d737424360d061b3d1905329480.png" data-original-src="https://miro.medium.com/v2/resize:fit:1280/format:webp/1*aS7ulcwz7vjJ7VLJfgERTg.jpeg"/></div><figcaption class="mf mg gj gh gi mh mi bd b be z dk">Source: <a class="ae le" href="http://tuxar.uk/brief-introduction-artificial-neural-networks/" rel="noopener ugc nofollow" target="_blank">http://tuxar.uk/brief-introduction-artificial-neural-networks/</a></figcaption></figure><blockquote class="nj"><p id="b6de" class="nk nl it bd nm nn no np nq nr ns ld dk translated">训练网络意味着微调其权重以提高预测精度</p></blockquote><h2 id="4a30" class="mk ml it bd mm mn nt dn mp mq nu dp ms kr nv mu mv kv nw mx my kz nx na nb nc bi translated">调整权重</h2><p id="ae54" class="pw-post-body-paragraph ki kj it kk b kl nd ju kn ko ne jx kq kr nf kt ku kv ng kx ky kz nh lb lc ld im bi translated">一开始，神经网络的权重是随机的，因此预测都是错误的。那么，我们如何改变权重，以便当给一只猫看时，神经网络以很高的可信度预测它是一只猫呢？</p><ul class=""><li id="63d9" class="lf lg it kk b kl km ko kp kr lh kv li kz lj ld ny ll lm ln bi translated">一次一个权重:训练网络的一个非常基本的方法是改变一个权重，同时保持其他权重不变。</li><li id="1e37" class="lf lg it kk b kl lo ko lp kr lq kv lr kz ls ld ny ll lm ln bi translated"><strong class="kk iu">权重组合:</strong>另一种方法是在一个范围内(比如从 1 到 1000)随机设置所有权重。可以从全 1 开始，然后全 1 和一个 2 等等。组合看起来像这样— (1，1，1)，(1，1，2)，(1，2，1)，(1，2，2)，(2，2，2)，(2，2，3)</li></ul><h2 id="6ac3" class="mk ml it bd mm mn mo dn mp mq mr dp ms kr mt mu mv kv mw mx my kz mz na nb nc bi translated">为什么这两种方法都不好？</h2><p id="3239" class="pw-post-body-paragraph ki kj it kk b kl nd ju kn ko ne jx kq kr nf kt ku kv ng kx ky kz nh lb lc ld im bi translated">这是因为如果我们尝试 N 个权重的所有可能组合，每个组合的权重范围从 1 到 1000，这将花费大量的时间来筛选解空间。对于运行在 1GHz 的处理器，2 个神经元的网络需要 1⁰⁶/1⁰⁹ = 1 毫秒。对于 4 个神经元的网络，相应的处理时间将是 16 分钟，并且对于更大的网络，处理时间将保持指数增长。</p><figure class="lu lv lw lx gt ly gh gi paragraph-image"><div role="button" tabindex="0" class="lz ma di mb bf mc"><div class="gh gi nz"><img src="../Images/50ff17ce66d5fba2ccddeb28fe5273e1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*8pWgnt_T0FjHIPegmdN11w.jpeg"/></div></div><figcaption class="mf mg gj gh gi mh mi bd b be z dk">The Curse of Dimensionality</figcaption></figure><p id="e676" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">对于 5 个神经元网络来说，这将是 11.5 天。这就是维度的诅咒。一个真正的神经网络将有 1000 个权重，需要几个世纪才能完成。</p></div><div class="ab cl oa ob hx oc" role="separator"><span class="od bw bk oe of og"/><span class="od bw bk oe of og"/><span class="od bw bk oe of"/></div><div class="im in io ip iq"><h2 id="9952" class="mk ml it bd mm mn mo dn mp mq mr dp ms kr mt mu mv kv mw mx my kz mz na nb nc bi translated">这就是反向传播的用处</h2><figure class="lu lv lw lx gt ly"><div class="bz fp l di"><div class="oh oi l"/></div></figure><p id="a718" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">一旦你对反向传播有了直观的认识，数学就很容易理解了。假设一家公司有 2 名销售人员、3 名经理和 1 名首席执行官。反向传播是首席执行官向中层管理人员提供反馈，他们反过来又向销售人员提供反馈。</p><p id="2ca6" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">每一层的员工都向所有后续层的经理汇报，用箭头的宽度表示不同的“强度”。因此，一些员工比其他人更经常向一位经理汇报工作。此外，CEO 认为设计经理(第二层的底层神经元)的意见比销售经理(自行车骑手)的意见更重要。</p><p id="146f" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">每次销售完成后，首席执行官都会计算预测结果和预期结果之间的差异。这位首席执行官稍微调整了一下，他希望对哪位经理的话给予多大的“权重”。经理汇报结构也根据首席执行官的指导方针而改变。每位经理都试图以一种让他/她更了解情况的方式重新调整权重。</p><figure class="lu lv lw lx gt ly gh gi paragraph-image"><div role="button" tabindex="0" class="lz ma di mb bf mc"><div class="gh gi oj"><img src="../Images/fad4b7e59ee41dae2fa202af962b3462.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Whv4Hue5C_72vUr98xvVYA.png"/></div></div><figcaption class="mf mg gj gh gi mh mi bd b be z dk">Top Down: Backpropagation happening after CEO receives wrong inputs from Middle Management</figcaption></figure><p id="c838" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">首席执行官重新调整对中层管理人员的信任。</p><blockquote class="nj"><p id="584d" class="nk nl it bd nm nn ok ol om on oo ld dk translated">这种将反馈传播回前几层的过程就是它被称为反向传播的原因。</p></blockquote><p id="07bc" class="pw-post-body-paragraph ki kj it kk b kl op ju kn ko oq jx kq kr or kt ku kv os kx ky kz ot lb lc ld im bi translated">首席执行官不断改变他的信任级别，直到客户的反馈开始符合预期的结果。</p></div><div class="ab cl oa ob hx oc" role="separator"><span class="od bw bk oe of og"/><span class="od bw bk oe of og"/><span class="od bw bk oe of"/></div><div class="im in io ip iq"><h2 id="3cb6" class="mk ml it bd mm mn mo dn mp mq mr dp ms kr mt mu mv kv mw mx my kz mz na nb nc bi translated">一点点数学知识</h2><figure class="lu lv lw lx gt ly gh gi paragraph-image"><div role="button" tabindex="0" class="lz ma di mb bf mc"><div class="gh gi ou"><img src="../Images/0aa2b9f547921758d2b269f0f099f942.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*um3wOfXvXGFSL2IGzcDhjw.png"/></div></div><figcaption class="mf mg gj gh gi mh mi bd b be z dk">Source: <a class="ae le" href="https://www.xkcd.com/435/" rel="noopener ugc nofollow" target="_blank">https://www.xkcd.com/435/</a></figcaption></figure><p id="36c8" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="kk iu">一撮数学<br/> </strong>一个神经网络的成功是用代价函数来衡量的。花费越少，训练越好。目标是以最小化成本函数的方式修改权重。</p><p id="5b02" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">所以两个重要的术语—</p><ul class=""><li id="d5f6" class="lf lg it kk b kl km ko kp kr lh kv li kz lj ld ny ll lm ln bi translated"><strong class="kk iu">误差</strong> =预期与现实之间的差异</li><li id="3d0f" class="lf lg it kk b kl lo ko lp kr lq kv lr kz ls ld ny ll lm ln bi translated"><strong class="kk iu">成本函数的梯度</strong> =改变权重时成本的变化。</li></ul><p id="aa78" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="kk iu"/></p><p id="20b0" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">反向传播包含单词“back”。这意味着我们从输出回到输入。我们看看错误是如何反向传播的。</p><p id="0b1d" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">看看δˡ是如何依赖δˡ⁺的</p><figure class="lu lv lw lx gt ly gh gi paragraph-image"><div role="button" tabindex="0" class="lz ma di mb bf mc"><div class="gh gi ow"><img src="../Images/47d3dcb4118642bffd1dc83e05b13951.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*JqN0u1xWo9PSyi8BNJOXFw.png"/></div></div><figcaption class="mf mg gj gh gi mh mi bd b be z dk"><a class="ae le" href="http://neuralnetworksanddeeplearning.com/chap2.html" rel="noopener ugc nofollow" target="_blank">http://neuralnetworksanddeeplearning.com/chap2.html</a></figcaption></figure><p id="365a" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">如果你仔细观察，方程的第二项有一个 z。我们在那里测量 z 变化的速度。这告诉我们误差会变化多快，因为δˡ也依赖于 z =神经元的输出。</p><figure class="lu lv lw lx gt ly gh gi paragraph-image"><div role="button" tabindex="0" class="lz ma di mb bf mc"><div class="gh gi ox"><img src="../Images/d17635a21415c2bd500652ec14a3c0ef.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*DjeWpzo0F8bWbfzDJvqPIA.png"/></div></div><figcaption class="mf mg gj gh gi mh mi bd b be z dk"><a class="ae le" href="http://neuralnetworksanddeeplearning.com/chap2.html" rel="noopener ugc nofollow" target="_blank">http://neuralnetworksanddeeplearning.com/chap2.html</a></figcaption></figure><p id="710a" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">右边的第一项只是衡量成本作为第 j 个输出激活的函数变化有多快。右边的第二项测量第 j 个神经元输出端的激活函数σ变化有多快。</p><p id="b9bc" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">结果向前流，错误向后流。由于我们反向传播误差，我们需要误差如何在两个相邻层之间流动的数值表示。成本相对于重量的变化率由下式给出</p><figure class="lu lv lw lx gt ly gh gi paragraph-image"><div role="button" tabindex="0" class="lz ma di mb bf mc"><div class="gh gi oy"><img src="../Images/dca75966fee2b64f885f03769768d668.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*StI-szMocIL6-0QolJ_rmg.png"/></div></div><figcaption class="mf mg gj gh gi mh mi bd b be z dk"><a class="ae le" href="http://neuralnetworksanddeeplearning.com/chap2.html" rel="noopener ugc nofollow" target="_blank">http://neuralnetworksanddeeplearning.com/chap2.html</a></figcaption></figure><p id="cfd1" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">有了这些基础，反向传播算法可以总结如下</p><figure class="lu lv lw lx gt ly gh gi paragraph-image"><div role="button" tabindex="0" class="lz ma di mb bf mc"><div class="gh gi oz"><img src="../Images/eb9f5c00f946ace60f44e29f14e694b4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*fZgdl3kkfD-6_yIcYgaBbg.png"/></div></div><figcaption class="mf mg gj gh gi mh mi bd b be z dk"><a class="ae le" href="http://neuralnetworksanddeeplearning.com/chap2.html" rel="noopener ugc nofollow" target="_blank">http://neuralnetworksanddeeplearning.com/chap2.html</a></figcaption></figure></div><div class="ab cl oa ob hx oc" role="separator"><span class="od bw bk oe of og"/><span class="od bw bk oe of og"/><span class="od bw bk oe of"/></div><div class="im in io ip iq"><h2 id="5a7b" class="mk ml it bd mm mn mo dn mp mq mr dp ms kr mt mu mv kv mw mx my kz mz na nb nc bi translated">从机器学习的角度考虑实际问题</h2><ul class=""><li id="294d" class="lf lg it kk b kl nd ko ne kr pa kv pb kz pc ld ny ll lm ln bi translated">即使反向传播也需要时间。最好把输入的数据分批次。(<strong class="kk iu">随机梯度下降</strong>)。</li><li id="f067" class="lf lg it kk b kl lo ko lp kr lq kv lr kz ls ld ny ll lm ln bi translated">训练数据越多，权重调整越好。通常，神经网络需要数千个预先标记的训练样本。</li></ul><p id="bb27" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">反向传播虽然现在很流行，但在引入时也遭到了反对。许多著名的科学家和认知心理学家(包括著名的英国认知心理学家 Geoff Hinton)都不相信反向传播。反向传播由于很多原因而面临反对，包括它不能代表大脑如何学习。</p><figure class="lu lv lw lx gt ly"><div class="bz fp l di"><div class="pd oi l"/></div><figcaption class="mf mg gj gh gi mh mi bd b be z dk">Quora answer</figcaption></figure><p id="30e4" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">尽管如此，它仍然是一个非常广泛使用的和非常有效的训练神经网络的方法。目前，专门的硬件正在开发，以更有效地执行反向传播。</p><div class="pe pf gp gr pg ph"><a href="https://futurism.com/self-learning-ai-this-new-neuro-inspired-computer-trains-itself" rel="noopener  ugc nofollow" target="_blank"><div class="pi ab fo"><div class="pj ab pk cl cj pl"><h2 class="bd iu gy z fp pm fr fs pn fu fw is bi translated">自我学习人工智能:这种新的受神经启发的计算机自我训练</h2><div class="po l"><h3 class="bd b gy z fp pm fr fs pn fu fw dk translated">来自比利时的一组研究人员认为他们已经接近扩展摩尔定律的预期终点，他们…</h3></div><div class="pp l"><p class="bd b dl z fp pm fr fs pn fu fw dk translated">futurism.com</p></div></div><div class="pq l"><div class="pr l ps pt pu pq pv md ph"/></div></div></a></div></div></div>    
</body>
</html>