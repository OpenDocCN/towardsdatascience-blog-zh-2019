# 大数据手册

> 原文：<https://towardsdatascience.com/the-big-data-handbook-f953e1777244?source=collection_archive---------13----------------------->

## 你知道 Hadoop 是一只黄色的玩具大象吗？

## 了解有关 Hadoop 生态系统的所有信息

![](img/b290db58bbd65606f78d398a0711f60b.png)

Photo by [Joshua Sortino](https://unsplash.com/@sortino?utm_source=medium&utm_medium=referral) on [Unsplash](https://unsplash.com?utm_source=medium&utm_medium=referral)

作为一名经济和金融背景的学生，算法、数据结构、Big-O 甚至大数据对我来说都太陌生了。文件系统、吞吐量、容器化、守护进程等术语。在我的字典里几乎没有任何意义。

这是我向普通人解释大数据的尝试(在上下文中加入一些技术术语)。

## **什么是大数据？**

大数据字面意思是大数据(换句话说，大量数据)。问题应该是，多大的数据才算大数据*大数据*？这个问题没有固定的答案，因为它取决于你问这个问题的时间。随着数据量的持续增长(指数级)，今天被视为“大”的数据在 10 年后可能不再被视为“大”。然而今天，从业者通常将 1tb 或更大的数据归类为“大”数据。

除了纯粹的**数据量**之外，我们还必须考虑产生和消费的数据的**速度**、**准确性**和**多样性**。简而言之，数据正以如此快的速度(*速度*)从不同的来源和不同的结构(*多样性*)被创造出来，以至于我们不得不考虑数据的准确度和精确度(*准确性*)。

![](img/495edc7f2c9e77fc601cf138ab6ad8e8.png)

The Four V’s of Big Data (IBM Big Data Club)

## 为什么需要大数据？

> 从人类文明开始到 2003 年，总共有 5 艾字节的信息被创造出来，但是现在每两天就有这么多的信息被创造出来。 *—谷歌执行董事长埃里克·施密特*

信息时代的曙光始于搜索引擎的出现，社交媒体平台的创建进一步加速了这一进程。随着数据量的增加，我们想要分析的数据类型也在增加。来自传统类型的结构化数据(如 CRM 数据、POS 数据、系统日志、XML、JSON 等。)到非结构化数据(例如，社交媒体、图像、电子邮件、Web 数据、音频、视频等)。)，企业显然需要能够**捕获**、**存储**、**管理**、**分析**和**优化**所有这些类型的数据。

## 谷歌是如何解决大数据问题的？

虽然这可能有点技术性，但我会尽量让它变得简单。

当互联网在 21 世纪初爆发时，谷歌面临着一个数据问题。需要处理的信息实在太多了，所有这些数据都存储在大型的*集群*(一组一起工作的计算机)。为了能够处理和分类万维网上的海量信息，谷歌的*杰弗瑞·迪恩*和*桑杰·格玛瓦特*在 2004 年发表了他们的论文——“[*MapReduce:大型集群上的简化数据处理*](https://static.googleusercontent.com/media/research.google.com/en//archive/mapreduce-osdi04.pdf) ”，这是一个用于分析网站数据以进行搜索优化的框架。2005 年， [Apache](https://en.wikipedia.org/wiki/The_Apache_Software_Foundation) ，一个开源组织，在他们的“Nutch”项目中使用了 MapReduce ( *关于这个框架的细节在下面*)这是一个高度可扩展和可伸缩的网络爬虫软件项目。

![](img/136f78427c3ef285ff2e2938fc9646d8.png)

Doug Cutting (source: [https://twitter.com/cutting/status/786058270150721540](https://twitter.com/cutting/status/786058270150721540))

现在，你可能想知道这个术语 *Hadoop* 是怎么来的？2006 年，雅虎的员工道格·卡丁(*左*)离职。然后，设计了 *Hadoop* 并以他儿子的黄色玩具大象命名，最终在 2007 年作为开源的 Apache 项目发布。它很快成为一个顶级的 Apache 项目。如今，许多公司使用 Hadoop 进行大容量数据存储和处理，因为它能够以最小的数据移动(成本)高效地查询数据。更多的细节和优点将在下面列出。

# 大数据堆栈简介

![](img/903c4ece4751ff95dbf6f5308605e849.png)

Big Data Stack (source: Singapore Management University)

## 为什么有这么多组件？

在 Hadoop 生态系统中，有许多不同的层负责不同的组件，包括数据存储、集成、访问、资源管理、执行引擎以及运营和管理。

在我失去这一段以外的读者之前，让我提供一个栈试图完成的高级描述。

当大量数据分散在许多不同的计算机上时，从数据消费、存储、处理和分析的一切都不可避免地变得更加困难。然后为这些过程中的每一个创建工具，因为它们帮助摄取和处理数据，而一些工具协调这个复杂的过程，以便获得用户想要的结果。

**警告:** *下面包含了大量的技术术语！您可能希望简单地阅读每个组件的高级描述。*

# 软件描述和功能

## Apache Hadoop

一个开源软件框架，用于商用硬件集群上数据集的**存储和大规模处理**(又称分布式计算)。简单地说，Hadoop 是为那些有大量数据要存储和分析，但没有时间、技能或资源成为分布式系统专家来处理这些数据的人而创建的。

# 数据集成

为了将传入数据存储到数据存储层中，由于传入数据的类型(流或批处理数据)和传入数据的来源各不相同，因此通常需要一个数据集成工具。

## 阿帕奇水槽

Flume 是一个分布式的、可靠的、可用的服务，用于高效地**收集、聚集和移动大量的日志数据**。它有一个简单灵活的基于**数据流**的架构。

![](img/0510b2250d13cf761702091481bdbffd.png)

Flume Basic Architecture (Source: Singapore Management University)

Flume 服务于数据接收/集成层和服务器，将数据从源移动到目的地(通常是 HDFS/Hbase)。它解决了几个问题:

*   分布式数据源
*   改变数据结构
*   源和目的地之间的阻抗不匹配(HDFS/Hbase)
*   系统和服务器的规模不断扩大

## Sqoop

SQL 到 Hadoop 的简称。顾名思义，Sqoop 旨在使用 Hadoop MapReduce 在关系数据库和 HDFS 之间传输批量数据。它的优势在于能够连接到许多流行的数据库和企业数据仓库(EDW)。

![](img/07b5396bb1b48ca56b2131d69339fe64.png)

Sqoop Basic Architecture

Sqoop 与工作流协调器 Apache Oozie 集成，允许调度和自动化导入/导出任务。

## 阿帕奇卡夫卡

Kafka 是一个分布式流媒体平台，**发布和订阅**(通常被称为“发布/订阅”系统)大量的记录流(消息系统)。它通常用于构建**实时**数据管道，在系统和应用程序之间可靠地获取数据，还用于构建实时应用程序，对数据流进行转换或做出反应。

![](img/8e2febb4ab87fd11a5c51a8802ab6390.png)

Kafka pub/sub messaging system

请注意，这与 Flume 不同，因为 Flume 只是接收日志数据流并将其存放到接收器中(即单一目的地)。另一方面，Kafka 能够在不同类型的 feed 之间轻松共享数据(即通过推拉模式分离生产者和消费者)。

# 数据存储和管理

在数据存储层，根据存储的数据类型(结构化/非结构化/半结构化数据)以及数据存储中文件的读/写频率，有不同的选项。

## **HDFS (Hadoop 分布式文件系统)**

这是 Hadoop 的存储层，存储结构化数据。这一层还负责数据分发和数据复制。它解决了几个关键问题:

1.  **数据太大，无法存储在单台机器上** —使用多台机器协同工作来存储数据(*分布式系统*
2.  **数据增长过快且不稳定** —添加更多机器进行线性扩展并避免瓶颈(*可扩展*)
3.  **机器数量越多，故障概率越高** —冗余存储数据；数据分布在多个节点上(*容错*)
4.  **分布式系统的复杂性** —抽象复杂细节的高级 API(*简单编码模型* **)**

## Apache Hbase

基于 Apache Hadoop 构建的可水平扩展、低延迟、随机访问的数据存储。它利用 HDFS 的冗余，使其具有容错能力。它与 HDFS 的不同之处在于，它是一个 **NoSQL 键值存储，使用列族**。它本质上是一个存储地图的数据库。CPU 和内存密集型，偶尔有大量顺序 I/O 访问。

# 执行引擎

执行引擎的选择通常取决于您需要解决的问题，有些执行引擎只在它为之构建的用例中才是强大的。在这种情况下，创建 MapReduce 是为了处理大数据，并在集群中的数百或数千个节点之间进行扩展。另一方面，Spark 的优势在于它有一个统一的面向最终用户的 API，使得构建数据处理管道变得容易。

## MapReduce

核心 Hadoop 处理引擎(在 Spark 推出之前)旨在利用并行性。它是由两个组件组成的框架— 1) **Map** 和 2) **Reduce** 。

*Map* 操作获取一组数据，并将其转换成另一组数据，其中各个元素被分解成元组(键/值对)。*归约*操作将来自映射(或洗牌)的输出作为输入，并将那些数据元组组合成更小的元组集。MapReduce 的优势在于，这两个操作都在每个节点上本地完成，并且跨节点传输的数据最少(低 I/O 成本)。

## 阿帕奇火花

Spark 的动机是基于 MapReduce 的局限性，它对于重复使用工作数据集的应用程序来说效率低下。出现问题的两个例子:

1.  **迭代、多阶段算法** —像[梯度下降](https://en.wikipedia.org/wiki/Gradient_descent)这样的机器学习算法将一个函数迭代地应用到同一个数据集，以优化一个参数，其中每次迭代都可以表示为一个 MapReduce 作业，因此每个作业都必须从磁盘重新加载数据，从而导致显著的性能损失
2.  **交互式数据挖掘工具** —类似地，像*小猪*和*蜂巢*这样的工具被用来在数据集上运行特别的探索性查询。每个查询都会产生很大的延迟，因为它运行一个新的 MapReduce 作业并从磁盘读取数据(而不是一次加载，多次读取)

因此，Spark 的目标是允许**内存数据共享**，从而避免复制，同时保留弹性和容错的优势。这是通过使用**弹性分布式数据集** (RDDs)通过分布式内存抽象实现的。rdd 允许以容错方式在大型集群上进行内存计算。

![](img/a89eef5c211840ce71f6109ec4ee97c7.png)

Spark Toolkit

Spark 的神奇之处在于，它是一个**统一计算引擎**，有一套大数据处理的库。这意味着通过一组一致的 API，Spark 可以用于支持广泛的数据分析任务，包括数据加载、运行 SQL 查询、机器学习和流计算。

# 数据分析

在 *Pig* 和 *Hive* 之前，数据分析是用 MapReduce 术语(Java)完成的，这使得人们很难掌握那些必要的技能。像 *join* 和 *filter* 等许多常见操作都需要自定义代码。Pig 和 Hive 是试图使数据分析民主化的两种早期解决方案。

## 猪

Pig 是一个用于分析大型数据集的平台，有两个主要组件:

1.  pig Latin——一种用于分析大型数据集的高级编程语言
2.  **Pig 引擎**—解析、优化并自动执行 PigLatin 脚本，作为 Hadoop 集群上的一系列 MapReduce 作业

## 储备

Hive 最初是由脸书在 2007 年开发的，但现在是一个开源的 Apache 项目。

Hive 是一个管理和查询**结构化数据**的系统，构建在 Hadoop 之上。业务分析师更容易访问它，因为它有一种类似 SQL 的查询语言，称为 HiveQL(非常类似于 MySQL)。

在后台，hive 引擎将 Hive 查询转换为 Map Reduce 代码，然后发送给 Hadoop 执行。

![](img/159ea521db17e446ec60a065ff470dd5.png)

Hive Query Flow

# 资源管理和协调

## Apache Hadoop YARN(又一个资源谈判者)

它是一个资源管理框架，将编程模型从资源管理基础设施中分离出来，并将许多功能委托给每个应用程序的组件。这允许多种数据处理工作负载，如交互式 SQL、实时流、机器学习，甚至对存储在单个平台上的数据进行批处理。

## 动物园管理员

ZooKeeper 是一个集中式服务，用于维护配置信息、命名、提供分布式同步和提供组服务。⁴

## 结束语

我希望这对那些对这些不同的工具如何相互集成感到困惑的人有用。很高兴收到任何反馈！

***支持我！*** —如果你喜欢我的内容并且*没有*订阅 Medium，请考虑支持我并通过我在这里的推荐链接[订阅](https://davidcjw.medium.com/membership) ( *注意:你的一部分会员费将作为推荐费*分摊给我)。

## 参考

1.  [https://mindmajix . com/MapReduce/history-and-advantages-of-Hadoop-MapReduce-programming](https://mindmajix.com/mapreduce/history-and-advantages-of-hadoop-mapreduce-programming)
2.  [https://towards data science . com/a-brief-summary-of-Apache-Hadoop-a-solution-of-big-data-problem-and-hint-from-Google-95fd 63 b 83623](/a-brief-summary-of-apache-hadoop-a-solution-of-big-data-problem-and-hint-comes-from-google-95fd63b83623)
3.  [https://flume.apache.org/](https://flume.apache.org/)
4.  [https://zookeeper.apache.org/](https://zookeeper.apache.org/)