<html>
<head>
<title>Finding Meaning: The Data Problem with Small Area Predictive Analysis in the Social Sciences (Part 2)</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">寻找意义:社会科学中小区域预测分析的数据问题(下)</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/finding-meaning-the-data-problem-with-small-area-predictive-analysis-in-the-social-sciences-part-f760019c9452?source=collection_archive---------24-----------------------#2019-06-21">https://towardsdatascience.com/finding-meaning-the-data-problem-with-small-area-predictive-analysis-in-the-social-sciences-part-f760019c9452?source=collection_archive---------24-----------------------#2019-06-21</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><p id="0d39" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">如果你还没有看过我这个项目的第一部分，请随意看看。虽然没有必要理解我在这里提出的问题，但我解释了什么是小区域分析，我对这个项目的灵感，我如何收集和准备我的数据，以及我在做这件事时面临的困难。这是一项正在进行的工作，在接下来的几天里将会有这个系列的第 3 部分。</p><blockquote class="km kn ko"><p id="d8fa" class="jn jo kp jp b jq jr js jt ju jv jw jx kq jz ka kb kr kd ke kf ks kh ki kj kk ij bi translated">本文原载于 2018 年 8 月。这是原物稍加编辑后的拷贝，被取了下来。</p></blockquote><h2 id="a3c7" class="kt ku iq bd kv kw kx dn ky kz la dp lb jy lc ld le kc lf lg lh kg li lj lk ll bi translated">在这里，我将谈谈我在对纽约市五个区的 59 个指定社区的公共卫生、环境和教育数据建模时遇到的困难。</h2><figure class="ln lo lp lq gt lr gh gi paragraph-image"><div class="gh gi lm"><img src="../Images/6ce9cab9c66056200dd31323f78d0799.png" data-original-src="https://miro.medium.com/v2/resize:fit:720/format:webp/1*Yni7obrOrpcXIwYq52QPWg.png"/></div><figcaption class="lu lv gj gh gi lw lx bd b be z dk">Community Districts of New York City</figcaption></figure><p id="81ea" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我将在这篇文章中讨论这三个主题。</p><ul class=""><li id="ab60" class="ly lz iq jp b jq jr ju jv jy ma kc mb kg mc kk md me mf mg bi translated">我考虑和尝试的不同模型</li><li id="64e3" class="ly lz iq jp b jq mh ju mi jy mj kc mk kg ml kk md me mf mg bi translated">有限数据的过拟合问题</li><li id="3a57" class="ly lz iq jp b jq mh ju mi jy mj kc mk kg ml kk md me mf mg bi translated">使用机器学习进行解释和分析，而不是预测</li></ul></div><div class="ab cl mm mn hu mo" role="separator"><span class="mp bw bk mq mr ms"/><span class="mp bw bk mq mr ms"/><span class="mp bw bk mq mr"/></div><div class="ij ik il im in"><p id="24a9" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">甚至在开始使用模型之前，我就发现了每个特性与教育程度列之间的相关性。有些很有趣。看看不同社区的健康相关指标——尤其是“含糖饮料”的相关性。</p><div class="ln lo lp lq gt ab cb"><figure class="mt lr mu mv mw mx my paragraph-image"><div role="button" tabindex="0" class="mz na di nb bf nc"><img src="../Images/e942c8d30acc59dc96cb35fd5950dce9.png" data-original-src="https://miro.medium.com/v2/resize:fit:968/format:webp/1*wBCCiz4HRCVz2RXVkARetw.png"/></div></figure><figure class="mt lr nd mv mw mx my paragraph-image"><div role="button" tabindex="0" class="mz na di nb bf nc"><img src="../Images/8d7b6591844afec017b3e1be838f081f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1034/format:webp/1*4PRrHT4WEHYs_xgwZQDcYQ.png"/></div></figure></div><p id="4405" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">在某些情况下，空气质量和“社区健康”指标(一个<em class="kp">社区</em>是否繁荣的指标)也有很强的相关性。</p><div class="ln lo lp lq gt ab cb"><figure class="mt lr ne mv mw mx my paragraph-image"><div role="button" tabindex="0" class="mz na di nb bf nc"><img src="../Images/3c98301889c00b53461fe0f600868878.png" data-original-src="https://miro.medium.com/v2/resize:fit:1102/format:webp/1*rhr3mAGPhWtiB6ooU4cT0w.png"/></div></figure><figure class="mt lr nf mv mw mx my paragraph-image"><div role="button" tabindex="0" class="mz na di nb bf nc"><img src="../Images/3e51c9e5c26a1dc39d56647299a3bce1.png" data-original-src="https://miro.medium.com/v2/resize:fit:900/format:webp/1*goBXkVo7yKZI9PuX-iUphw.png"/></div></figure></div><p id="c4c9" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">最后，种族与国家比率有着同等的相关性…</p><figure class="ln lo lp lq gt lr gh gi paragraph-image"><div class="gh gi ng"><img src="../Images/298f21d1e1f0298b814c32a796e69149.png" data-original-src="https://miro.medium.com/v2/resize:fit:1180/format:webp/1*goBXkVo7yKZI9PuX-iUphw.png"/></div></figure><h1 id="ecfc" class="nh ku iq bd kv ni nj nk ky nl nm nn lb no np nq le nr ns nt lh nu nv nw lk nx bi translated">数据建模</h1><p id="bea6" class="pw-post-body-paragraph jn jo iq jp b jq ny js jt ju nz jw jx jy oa ka kb kc ob ke kf kg oc ki kj kk ij bi translated">开始时最明显的模型是简单的线性回归。虽然可以将 scikit-learn 的<code class="fe od oe of og b">LinearRegression</code>用于多个输出(在这种情况下，没有高中文凭的成年人的比率、有高中文凭(可能有大学文凭)的成年人的比率以及有大学或更高学位的成年人的比率)，但该模型假设输出是独立的，因此基本上创建了三个完全独立的线性回归模型，每个模型对应一个输出。</p><p id="bedf" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我继续做了，完成了对所有数据的线性回归，得到了 0.95 的 R 值(三个输出的平均值)。这一切都很好，但有两个突出的问题…</p><p id="1668" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">第一个问题是，三个产出显然不是独立的；事实上，它们是如此紧密地联系在一起，以至于在每种情况下，这三个比率的总和应该是 100(这是百分比的趋势)。因此，创建三个完全独立的线性模型实际上并不能准确描述情况。</p><figure class="ln lo lp lq gt lr gh gi paragraph-image"><div class="gh gi oh"><img src="../Images/a9b4fffe34339bed72f4a3b12bd484db.png" data-original-src="https://miro.medium.com/v2/resize:fit:1004/format:webp/1*4CHqmEAT2mse_KokeCvvzA.png"/></div><figcaption class="lu lv gj gh gi lw lx bd b be z dk">seaborn pairplot of the educational attainment data</figcaption></figure><p id="9f01" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">第二个问题是，虽然这个模型似乎告诉我们，模型中包含的特征似乎确实与教育成果数据相关，但当我将我的数据分为训练集和测试集时，无论大小如何，我总是得到训练数据大于 0.95 的 R 值，而测试数据通常是负值——我得到的最高值是 0.49，这完全是基于数据的随机分割的运气。所以这里肯定存在过度拟合的问题。只有 59 个样本，因为只有 59 个社区区，这似乎是一个不可避免的问题，无论模型。</p></div><div class="ab cl mm mn hu mo" role="separator"><span class="mp bw bk mq mr ms"/><span class="mp bw bk mq mr ms"/><span class="mp bw bk mq mr"/></div><div class="ij ik il im in"><p id="23bc" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">以几种不同的方式在第一个相关教育成就特征的问题上取得进展。首先，我研究了可以处理多个输出的模型，同时考虑到它们是相关的。唯一有希望的途径似乎是尖端的神经网络。然而，这些只是在研究论文中提到过，还没有生产模型，所以在这一点上它真的只是在理论阶段…所以对我来说是一个死胡同。</p><p id="d3aa" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">唯一的另一种方法是将我的三个输出合并成一个单一的分数。最简单的方法是给每个教育程度分配一个值:0 代表没有完成高中学业，1 代表高中学历和大学学历，2 代表大学学历或更高。对于每个地区，我将每个百分比乘以其相应的值，然后将它们加在一起。这为每个地区创建了一个单一的，虽然有点抽象的“教育分数”，然后我可以用它来运行一个单一的线性回归。</p><pre class="ln lo lp lq gt oi og oj ok aw ol bi"><span id="4a9e" class="kt ku iq og b gy om on l oo op">educational_attainment['edu_score'] = educational_attainment.apply(<br/>    lambda row: row['Eduhsdegreeorsomecollege_rate'] + 2 *<br/>    row['Educollegedegreeandhigher_rate'], axis=1)</span></pre><p id="95cb" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">在整个数据集上，这种线性回归产生了 0.96 的 R 值；然而，当分成训练集和测试集时，它陷入了同样的过度拟合陷阱。</p></div><div class="ab cl mm mn hu mo" role="separator"><span class="mp bw bk mq mr ms"/><span class="mp bw bk mq mr ms"/><span class="mp bw bk mq mr"/></div><div class="ij ik il im in"><h2 id="202c" class="kt ku iq bd kv kw kx dn ky kz la dp lb jy lc ld le kc lf lg lh kg li lj lk ll bi translated">有序回归</h2><p id="ab51" class="pw-post-body-paragraph jn jo iq jp b jq ny js jt ju nz jw jx jy oa ka kb kc ob ke kf kg oc ki kj kk ij bi translated">我并不期望过拟合问题会有更好的结果，所以决定使用<code class="fe od oe of og b">mord</code>模块尝试一些有序回归。所以我用我的教育成绩，用平均值和标准差把数据分成 4 类。</p><pre class="ln lo lp lq gt oi og oj ok aw ol bi"><span id="afc8" class="kt ku iq og b gy om on l oo op"># Get the mean and standard deviation (indices 1 and 2 respectively)<br/>statistics = educational_attainment['edu_score'].describe()</span><span id="bd29" class="kt ku iq og b gy oq on l oo op"># Define my categories<br/>def get_ordinal(row):<br/>    if row.loc['edu_score'] &gt;= (statistics[1] + statistics[2]):<br/>        ordinal = 1<br/>    elif row.loc['edu_score'] &gt;= (statistics[1]):<br/>        ordinal = 2<br/>    elif row.loc['edu_score'] &gt;= (statistics[1] - statistics[2]):<br/>        ordinal = 3<br/>    else:<br/>        ordinal = 4<br/>    return ordinal<br/>    <br/>educational_attainment['ordinal'] = educational_attainment.apply(<br/>                               lambda row: get_ordinal(row), axis=1)</span></pre><p id="f3f0" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">令我惊讶的是，当我使用<code class="fe od oe of og b">mord.LogisticIT()</code>(使用即时阈值变量的有序逻辑回归)时，这在过度拟合方面稍微好一些。当作为一个整体用于数据集时，R 值为 0.93。当分成训练集和测试集时，测试数据集的 R 值至少是<em class="kp">总是</em>正值，有时高达 0.5——仍然没有什么值得夸耀的，但却是一个相当大的改进。</p></div><div class="ab cl mm mn hu mo" role="separator"><span class="mp bw bk mq mr ms"/><span class="mp bw bk mq mr ms"/><span class="mp bw bk mq mr"/></div><div class="ij ik il im in"><p id="dce5" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">对抗这种过度拟合的另一种方法可能是找到不同年份的相同数据，或者找到更多组邻域的相同数据。然而，看到找到<em class="kp">这个</em>数据有多么困难，我将把它留到以后再说。因此，虽然我们似乎可以找到相关性，但该模型的任何预测能力本质上都是无意义的，因此没有因果关系可以合理建立。</p><p id="164c" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">更有希望的途径似乎是使用 L2 正则化线性回归(也称为岭回归)来计算特征重要性，以伴随我们的原始相关性，以追求<em class="kp">理解</em>和<em class="kp">解释</em>数据，而不是试图建立一个纯粹的<em class="kp">预测</em>模型。对这种分析有用的其他模型是随机 L1 (Lasso)回归和 scikit-learn 的额外树回归。以下是我在实施这些策略时发现的结果。</p><h2 id="99b2" class="kt ku iq bd kv kw kx dn ky kz la dp lb jy lc ld le kc lf lg lh kg li lj lk ll bi translated">岭回归、随机套索和额外树</h2><p id="ffce" class="pw-post-body-paragraph jn jo iq jp b jq ny js jt ju nz jw jx jy oa ka kb kc ob ke kf kg oc ki kj kk ij bi translated">这些模型是解释数据的绝佳工具，因为这些模型是<em class="kp">稳定的</em>并且有用的特征往往具有非零系数/分数——这是算法中的冗余和平均试验和/或惩罚高系数以确保特征不会被过度呈现的结果。</p><p id="3abf" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">作为另一层，我使用了包含对<code class="fe od oe of og b">sklearn</code>的支持的<code class="fe od oe of og b">eli5</code>包来实现<code class="fe od oe of og b">PermutationImportance</code>，其中，一列接一列的值被打乱，以查看模型仍然可以预测目标的程度。</p><pre class="ln lo lp lq gt oi og oj ok aw ol bi"><span id="fb9e" class="kt ku iq og b gy om on l oo op"># Using robustly scaled columns...<br/>def get_scores(X, Y, scale_method):<br/>    index_tuples = []<br/>    model_data = []<br/>    <br/>    for level in Y.columns:<br/>        ridge_model = RidgeCV()<br/>        et_model = ExtraTreesRegressor(n_estimators=50, <br/>            bootstrap=True)<br/>        randL_model = RandomizedLasso()<br/>        models = [ridge_model, et_model]   <br/>        y = Y[level]</span><span id="7b5c" class="kt ku iq og b gy oq on l oo op">        for model in models:<br/>            model.fit(X, y)<br/>            score = model.score(X, y)<br/>            model_name = f'{model}'.split('(')[0]<br/>            try:<br/>                coefs = model.coef_<br/>            except:<br/>                try:<br/>                    importances = model.feature_importances_<br/>                except:<br/>                    importances = np.array(None)<br/>            else:<br/>                importances = np.absolute(coefs)<br/>            finally:<br/>                perm = PermutationImportance(model).fit(X, y)<br/>                perm_importances = perm.feature_importances_<br/>                index_tuple1 = (level, 'importances', score, <br/>                    model_name)<br/>                index_tuple2 = (level, 'perm_importances', score, <br/>                    model_name)<br/>        <br/>                if importances.any():<br/>                    index_tuples.append(index_tuple1)<br/>                    model_data.append(importances)<br/>                <br/>                index_tuples.append(index_tuple2)<br/>                model_data.append(perm_importances)</span></pre><p id="9306" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">当我对这些不同模型的得分进行平均，并筛选出作为社区和环境健康指标的特征时，我得到了下面的结果。</p><figure class="ln lo lp lq gt lr gh gi paragraph-image"><div class="gh gi or"><img src="../Images/bf7febccff012aad65f6bbe1268572ff.png" data-original-src="https://miro.medium.com/v2/resize:fit:1008/format:webp/1*dV3FO6ggTviPfQ5colus9g.png"/></div><figcaption class="lu lv gj gh gi lw lx bd b be z dk">The most important factors of Environmental and Community Health in predicting Educational Attainment of adults in the community. “Extremes” is an aggregation of rates for “Did Not Complete HS” and “College Degree or Higher”</figcaption></figure></div><div class="ab cl mm mn hu mo" role="separator"><span class="mp bw bk mq mr ms"/><span class="mp bw bk mq mr ms"/><span class="mp bw bk mq mr"/></div><div class="ij ik il im in"><p id="14db" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">在继续这项研究的过程中，我计划通过查看相关性和 p 值来选择适当的特征，从而减少特征的数量，希望将过度拟合的影响降至最低。我还计划继续寻找其他数据来源——尤其是可以显示随时间变化的数据。这是一项正在进行的工作。生活也是如此。</p></div></div>    
</body>
</html>