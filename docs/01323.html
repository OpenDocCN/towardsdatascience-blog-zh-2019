<html>
<head>
<title>Anomaly Detection with Time Series Forecasting</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">基于时间序列预测的异常检测</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/anomaly-detection-with-time-series-forecasting-c34c6d04b24a?source=collection_archive---------0-----------------------#2019-03-03">https://towardsdatascience.com/anomaly-detection-with-time-series-forecasting-c34c6d04b24a?source=collection_archive---------0-----------------------#2019-03-03</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><figure class="gl gn jr js jt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi jq"><img src="../Images/910836500b0b40dfe1d29735a4a1bd9f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*yeLT55Hn7s22Jujox90GDg.png"/></div></div></figure><p id="e101" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">嗨，这是一篇关于<strong class="kd iu">异常检测</strong>的后续文章(链接到上一篇文章:<a class="ae kz" href="https://medium.com/myntra-engineering/anomaly-detection-with-isolation-forest-visualization-23cd75c281e2" rel="noopener">https://medium . com/my ntra-engineering/anomaly-detection-with-isolation-forest-visualization-23 CD 75 c 281 e 2</a>其中我们使用无监督学习进行了异常检测)。</p><p id="51c6" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">这里我们将看到用<strong class="kd iu">时间序列预测</strong>检测异常。时间序列是与时间相关的任何数据(每天、每小时、每月等)。例如:商店每天的收入是一个<strong class="kd iu">天级别</strong>的时间序列数据。许多用例，如<strong class="kd iu">需求估计、销售预测</strong>是一个典型的时间序列预测问题，可以通过像<strong class="kd iu">萨里玛、LSTM、霍尔特温特斯</strong>等算法来解决。时间序列预测通过用当前数据估计未来需求，帮助我们为未来需求做准备。一旦我们有了预测，我们就可以使用这些数据，通过与实际数据进行比较来发现异常情况。我们来实现一下，看看它的利弊。</p><p id="ccd4" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">安装和导入可视化库</p><pre class="la lb lc ld gt le lf lg lh aw li bi"><span id="3903" class="lj lk it lf b gy ll lm l ln lo">#Installing specific version of plotly to avoid Invalid property for color error in recent version which needs change in layout<br/>!pip install plotly==2.7.0<br/>import pandas as pd<br/>import numpy as np<br/>from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot<br/>import plotly.plotly as py<br/>import matplotlib.pyplot as plt<br/>from matplotlib import pyplot<br/>import plotly.graph_objs as go<br/>init_notebook_mode(connected=True)<br/>time_series_df=pd.read_csv('../input/time-series-data/time_series_data.csv')<br/>time_series_df.head()</span></pre><figure class="la lb lc ld gt ju gh gi paragraph-image"><div class="gh gi lp"><img src="../Images/d1959807e14f6e55b3fc05c7d414d01d.png" data-original-src="https://miro.medium.com/v2/resize:fit:596/format:webp/1*HF9uN8_z1Goq3cLox6j0Og.png"/></div></figure><p id="9bc3" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">这里的数据顺序很重要，应该是**按时间顺序* *因为我们要预测下一个点。</p><p id="cbd9" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">将 load_date 列转换为 datetime 格式，并根据日期对数据进行排序。</p><pre class="la lb lc ld gt le lf lg lh aw li bi"><span id="f71f" class="lj lk it lf b gy ll lm l ln lo">time_series_df.load_date = pd.to_datetime(time_series_df.load_date, format='%Y%m%d')<br/>time_series_df = time_series_df.sort_values(by="load_date")<br/>time_series_df = time_series_df.reset_index(drop=True)<br/>time_series_df.head()</span></pre><figure class="la lb lc ld gt ju gh gi paragraph-image"><div class="gh gi lp"><img src="../Images/d1959807e14f6e55b3fc05c7d414d01d.png" data-original-src="https://miro.medium.com/v2/resize:fit:596/format:webp/1*HF9uN8_z1Goq3cLox6j0Og.png"/></div></figure><p id="9c27" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">提取数值并应用<strong class="kd iu">对数变换</strong>以稳定数据中的<strong class="kd iu">方差</strong>或在将数据输入模型之前使其<strong class="kd iu">稳定</strong>。</p><pre class="la lb lc ld gt le lf lg lh aw li bi"><span id="2981" class="lj lk it lf b gy ll lm l ln lo">actual_vals = time_series_df.actuals.values<br/>actual_log = np.log10(actual_vals)</span></pre><p id="264e" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">用测试数据中的 70 分来划分数据进行训练和测试。</p><p id="9674" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">首先让我们尝试应用 SARIMA 算法进行预测。SARIMA 代表<strong class="kd iu">季节性自回归综合移动平均线</strong>。它有一个季节性参数，由于我们销售数据的每周季节性，我们将其初始化为 7。其他参数是 p、d、q，它们是基于 ACF 和 PACF 图确定的，或者理想情况下，我们应该使用预测误差最小的参数。</p><p id="e792" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">更多细节可以在这里找到:<a class="ae kz" href="https://people.duke.edu/~rnau/arimrule.htm" rel="noopener ugc nofollow" target="_blank">https://people.duke.edu/~rnau/arimrule.htm</a><br/><br/>我不会在这里讨论获得正确参数集的问题，我们稍后将使用<strong class="kd iu"> Auto Arima </strong>来解决这个问题，它允许我们在误差最小的范围内获得最佳参数集。<br/> <br/>这里我指定差分因子(d)为 1。它帮助我们去除数据中的趋势和周期。</p><pre class="la lb lc ld gt le lf lg lh aw li bi"><span id="440e" class="lj lk it lf b gy ll lm l ln lo">import math<br/>import statsmodels.api as sm<br/>import statsmodels.tsa.api as smt<br/>from sklearn.metrics import mean_squared_error<br/>from matplotlib import pyplot<br/>import matplotlib.pyplot as plt<br/>import plotly.plotly as py<br/>import plotly.tools as tls</span><span id="1e07" class="lj lk it lf b gy lq lm l ln lo">train, test = actual_vals[0:-70], actual_vals[-70:]</span><span id="8338" class="lj lk it lf b gy lq lm l ln lo">train_log, test_log = np.log10(train), np.log10(test)</span><span id="1f0d" class="lj lk it lf b gy lq lm l ln lo">my_order = (1, 1, 1)<br/>my_seasonal_order = (0, 1, 1, 7)</span></pre><p id="b8ff" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">每次我们预测下一个数据点的<strong class="kd iu">，我们循环遍历训练数据以预测下一个数据，并在预测后添加下一个数据点用于进一步预测。</strong></p><p id="edd0" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">这就像一个移动窗口日水平数据(例如:前 90 点用于预测任何给定时间的下一点)。</p><p id="ca50" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">通过<strong class="kd iu">的 10 次方变换</strong>将预测数据转换回比例，并绘制结果。</p><pre class="la lb lc ld gt le lf lg lh aw li bi"><span id="2129" class="lj lk it lf b gy ll lm l ln lo">history = [x for x in train_log]<br/>predictions = list()<br/>predict_log=list()<br/>for t in range(len(test_log)):<br/>    model = sm.tsa.SARIMAX(history, order=my_order, seasonal_order=my_seasonal_order,enforce_stationarity=False,enforce_invertibility=False)<br/>    model_fit = model.fit(disp=0)<br/>    output = model_fit.forecast()<br/>    predict_log.append(output[0])<br/>    yhat = 10**output[0]<br/>    predictions.append(yhat)<br/>    obs = test_log[t]<br/>    history.append(obs)<br/>   # print('predicted=%f, expected=%f' % (output[0], obs))<br/>#error = math.sqrt(mean_squared_error(test_log, predict_log))<br/>#print('Test rmse: %.3f' % error)<br/># plot<br/>figsize=(12, 7)<br/>plt.figure(figsize=figsize)<br/>pyplot.plot(test,label='Actuals')<br/>pyplot.plot(predictions, color='red',label='Predicted')<br/>pyplot.legend(loc='upper right')<br/>pyplot.show()</span></pre><figure class="la lb lc ld gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi lr"><img src="../Images/f846cd72fa691ab3a6cd53cc85a3c78f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*TDkvMIBvU52MRoP_XEZK_Q.png"/></div></div><figcaption class="ls lt gj gh gi lu lv bd b be z dk">Actuals vs Predict forecast plot</figcaption></figure><p id="46c0" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">这是一个很好的时间序列预测。<strong class="kd iu">趋势、季节性</strong>是时间序列数据中的两个重要因素，如果您的算法能够捕捉到您数据的趋势(上升/下降)，并且如果您的数据是季节性的(每周、每天、每年的模式)，那么您的算法就适合您的情况。</p><p id="c30f" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">在这里，我们可以观察到，我们的 SARIMA 算法从峰值中捕捉到了趋势(不是通过复制它，而是通过捕捉峰值)，并在正常情况下很好地预测了实际值。</p><p id="60b5" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">我们在这里指定的参数似乎很适合这个指标，但是要进行绘图、验证和调整参数将是一项非常艰巨的任务。一个解决方案是<strong class="kd iu"> Auto Arima </strong>，它在我们指定的范围内返回算法的最佳参数集。</p><p id="a3ff" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">为 auto arima 安装金字塔-arima。</p><pre class="la lb lc ld gt le lf lg lh aw li bi"><span id="3e1d" class="lj lk it lf b gy ll lm l ln lo">!pip install pyramid-arima<br/>from pyramid.arima import auto_arima<br/>stepwise_model = auto_arima(train_log, start_p=1, start_q=1,<br/>                           max_p=3, max_q=3, m=7,<br/>                           start_P=0, seasonal=True,<br/>                           d=1, D=1, trace=True,<br/>                           error_action='ignore',  <br/>                           suppress_warnings=True, <br/>                           stepwise=True)</span></pre><p id="b9a8" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">让我们使用 auto_arima 查找 p 和 q 参数，并将 d 指定为 1 表示一阶差分，将季节性指定为 7 表示每周季节性。</p><p id="67b5" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">现在，auto arima 模型可以通过我们在上面执行的相同过程用于逐步预测:</p><pre class="la lb lc ld gt le lf lg lh aw li bi"><span id="2e12" class="lj lk it lf b gy ll lm l ln lo">import math<br/>import statsmodels.api as sm<br/>import statsmodels.tsa.api as smt<br/>from sklearn.metrics import mean_squared_error<br/>train, test = actual_vals[0:-70], actual_vals[-70:]</span><span id="23b2" class="lj lk it lf b gy lq lm l ln lo">train_log, test_log = np.log10(train), np.log10(test)</span><span id="c4f8" class="lj lk it lf b gy lq lm l ln lo"># split data into train and test-sets</span><span id="f98f" class="lj lk it lf b gy lq lm l ln lo">history = [x for x in train_log]<br/>predictions = list()<br/>predict_log=list()<br/>for t in range(len(test_log)):<br/>    #model = sm.tsa.SARIMAX(history, order=my_order, seasonal_order=my_seasonal_order,enforce_stationarity=False,enforce_invertibility=False)<br/>    stepwise_model.fit(history)<br/>    output = stepwise_model.predict(n_periods=1)<br/>    predict_log.append(output[0])<br/>    yhat = 10**output[0]<br/>    predictions.append(yhat)<br/>    obs = test_log[t]<br/>    history.append(obs)<br/>    #print('predicted=%f, expected=%f' % (output[0], obs))<br/>#error = math.sqrt(mean_squared_error(test_log, predict_log))<br/>#print('Test rmse: %.3f' % error)<br/># plot<br/>figsize=(12, 7)<br/>plt.figure(figsize=figsize)<br/>pyplot.plot(test,label='Actuals')<br/>pyplot.plot(predictions, color='red',label='Predicted')<br/>pyplot.legend(loc='upper right')<br/>pyplot.show()</span></pre><figure class="la lb lc ld gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi lw"><img src="../Images/a6d5fc9db56b2c0e2dabe5e4ec8b97ac.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*fYvDQBFwAGOylCKl9EPcug.png"/></div></div></figure><p id="9e5f" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">在这种情况下，auto arima 和我们的初始 SARIMA 在预测方面做得很好，也没有过多地追逐实际值。</p><p id="fb52" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">接下来，让我们用可用的实际数据和预测结果创建一个数据框架</p><pre class="la lb lc ld gt le lf lg lh aw li bi"><span id="64f6" class="lj lk it lf b gy ll lm l ln lo">predicted_df=pd.DataFrame()<br/>predicted_df['load_date']=time_series_df['load_date'][-70:]<br/>predicted_df['actuals']=test<br/>predicted_df['predicted']=predictions<br/>predicted_df.reset_index(inplace=True)<br/>del predicted_df['index']<br/>predicted_df.head()</span></pre><figure class="la lb lc ld gt ju gh gi paragraph-image"><div class="gh gi lx"><img src="../Images/32efea8be1dc976679629b8949e9f354.png" data-original-src="https://miro.medium.com/v2/resize:fit:932/format:webp/1*m25WIr28fEdXGa6GICFhJA.png"/></div></figure><p id="7e51" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">我们有预测和实际的结果，使用这些信息来检测异常，我使用了数据分布的属性。请注意，这仅在数据分布为<strong class="kd iu">正态/高斯</strong>时才有效。</p><p id="36cb" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">我检测异常的步骤:<br/> 1。计算<strong class="kd iu">误差</strong>项(实际-预测)。<br/> 2。计算<strong class="kd iu">滚动平均值和滚动标准差</strong>(窗口为一周)。<br/> 3。将误差为 1.5、1.75 和 2 个标准偏差的数据分类为低、中、高<strong class="kd iu">异常</strong>。(基于此属性，5%的数据点将被识别为异常)</p><p id="8bfa" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">我使用 lambda 函数对基于误差和标准偏差的异常进行分类，而不是使用单独的循环和函数。</p><pre class="la lb lc ld gt le lf lg lh aw li bi"><span id="2ac4" class="lj lk it lf b gy ll lm l ln lo">import numpy as np<br/>def detect_classify_anomalies(df,window):<br/>    df.replace([np.inf, -np.inf], np.NaN, inplace=True)<br/>    df.fillna(0,inplace=True)<br/>    df['error']=df['actuals']-df['predicted']<br/>    df['percentage_change'] = ((df['actuals'] - df['predicted']) / df['actuals']) * 100<br/>    df['meanval'] = df['error'].rolling(window=window).mean()<br/>    df['deviation'] = df['error'].rolling(window=window).std()<br/>    df['-3s'] = df['meanval'] - (2 * df['deviation'])<br/>    df['3s'] = df['meanval'] + (2 * df['deviation'])<br/>    df['-2s'] = df['meanval'] - (1.75 * df['deviation'])<br/>    df['2s'] = df['meanval'] + (1.75 * df['deviation'])<br/>    df['-1s'] = df['meanval'] - (1.5 * df['deviation'])<br/>    df['1s'] = df['meanval'] + (1.5 * df['deviation'])<br/>    cut_list = df[['error', '-3s', '-2s', '-1s', 'meanval', '1s', '2s', '3s']]<br/>    cut_values = cut_list.values<br/>    cut_sort = np.sort(cut_values)<br/>    df['impact'] = [(lambda x: np.where(cut_sort == df['error'][x])[1][0])(x) for x in<br/>                               range(len(df['error']))]<br/>    severity = {0: 3, 1: 2, 2: 1, 3: 0, 4: 0, 5: 1, 6: 2, 7: 3}<br/>    region = {0: "NEGATIVE", 1: "NEGATIVE", 2: "NEGATIVE", 3: "NEGATIVE", 4: "POSITIVE", 5: "POSITIVE", 6: "POSITIVE",<br/>              7: "POSITIVE"}<br/>    df['color'] =  df['impact'].map(severity)<br/>    df['region'] = df['impact'].map(region)<br/>    df['anomaly_points'] = np.where(df['color'] == 3, df['error'], np.nan)<br/>    df = df.sort_values(by='load_date', ascending=False)<br/>    df.load_date = pd.to_datetime(df['load_date'].astype(str), format="%Y-%m-%d")</span><span id="6f6e" class="lj lk it lf b gy lq lm l ln lo">return df</span></pre><p id="7708" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">下面是一个可视化结果的函数。<strong class="kd iu">清晰全面的可视化同样重要，有助于业务用户对异常情况提供反馈，并使结果具有可操作性。</strong></p><p id="a0c8" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">第一个图中的误差项指定了上限和下限。</p><p id="45cf" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">突出显示异常的实际值图将易于用户解释/验证。因此，第二个图突出显示了实际值和预测值以及异常情况。</p><p id="596b" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated"><strong class="kd iu">蓝线-实际值</strong></p><p id="e0be" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated"><strong class="kd iu">橙色线条-预测的</strong></p><p id="0e27" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated"><strong class="kd iu">红色-错误</strong></p><p id="79d0" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated"><strong class="kd iu">绿色——移动平均线</strong></p><p id="23be" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated"><strong class="kd iu">虚线——正常行为的上限和下限</strong></p><pre class="la lb lc ld gt le lf lg lh aw li bi"><span id="bb2f" class="lj lk it lf b gy ll lm l ln lo">def plot_anomaly(df,metric_name):<br/>    #error = pd.DataFrame(Order_results.error.values)<br/>    #df = df.sort_values(by='load_date', ascending=False)<br/>    #df.load_date = pd.to_datetime(df['load_date'].astype(str), format="%Y%m%d")<br/>    dates = df.load_date<br/>    #meanval = error.rolling(window=window).mean()<br/>    #deviation = error.rolling(window=window).std()<br/>    #res = error</span><span id="528c" class="lj lk it lf b gy lq lm l ln lo">#upper_bond=meanval + (2 * deviation)<br/>    #lower_bond=meanval - (2 * deviation)</span><span id="3257" class="lj lk it lf b gy lq lm l ln lo">#anomalies = pd.DataFrame(index=res.index, columns=res.columns)<br/>    #anomalies[res &lt; lower_bond] = res[res &lt; lower_bond]<br/>    #anomalies[res &gt; upper_bond] = res[res &gt; upper_bond]<br/>    bool_array = (abs(df['anomaly_points']) &gt; 0)</span><span id="d3d4" class="lj lk it lf b gy lq lm l ln lo">#And a subplot of the Actual Values.<br/>    actuals = df["actuals"][-len(bool_array):]<br/>    anomaly_points = bool_array * actuals<br/>    anomaly_points[anomaly_points == 0] = np.nan</span><span id="ebf5" class="lj lk it lf b gy lq lm l ln lo">#Order_results['meanval']=meanval<br/>    #Order_results['deviation']=deviation</span><span id="3592" class="lj lk it lf b gy lq lm l ln lo">color_map= {0: "'rgba(228, 222, 249, 0.65)'", 1: "yellow", 2: "orange", 3: "red"}<br/>    table = go.Table(<br/>    domain=dict(x=[0, 1],<br/>                y=[0, 0.3]),<br/>    columnwidth=[1, 2 ],<br/>    #columnorder=[0, 1, 2,],<br/>    header = dict(height = 20,<br/>                  values = [['&lt;b&gt;Date&lt;/b&gt;'],['&lt;b&gt;Actual Values &lt;/b&gt;'],<br/>                            ['&lt;b&gt;Predicted&lt;/b&gt;'], ['&lt;b&gt;% Difference&lt;/b&gt;'],['&lt;b&gt;Severity (0-3)&lt;/b&gt;']],<br/>                 font = dict(color=['rgb(45, 45, 45)'] * 5, size=14),<br/>                  fill = dict(color='#d562be')),<br/>    cells = dict(values = [df.round(3)[k].tolist() for k in ['load_date', 'actuals', 'predicted',<br/>                                                               'percentage_change','color']],<br/>                 line = dict(color='#506784'),<br/>                 align = ['center'] * 5,<br/>                 font = dict(color=['rgb(40, 40, 40)'] * 5, size=12),<br/>                 #format = [None] + [",.4f"] + [',.4f'],</span><span id="f0b5" class="lj lk it lf b gy lq lm l ln lo">#suffix=[None] * 4,<br/>                 suffix=[None] + [''] + [''] + ['%'] + [''],<br/>                 height = 27,<br/>                 #fill = dict(color=['rgb(235, 193, 238)', 'rgba(228, 222, 249, 0.65)']))<br/>                 fill=dict(color=  # ['rgb(245,245,245)',#unique color for the first column<br/>                      [df['color'].map(color_map)],<br/>                      )<br/>    ))</span><span id="5aaf" class="lj lk it lf b gy lq lm l ln lo">#df['ano'] = np.where(df['color']==3, df['error'], np.nan)</span><span id="15c0" class="lj lk it lf b gy lq lm l ln lo">anomalies = go.Scatter(name="Anomaly",<br/>                       x=dates,<br/>                       xaxis='x1',<br/>                       yaxis='y1',<br/>                       y=df['anomaly_points'],<br/>                       mode='markers',<br/>                       marker = dict(color ='red',<br/>                      size = 11,line = dict(<br/>                                         color = "red",<br/>                                         width = 2)))</span><span id="6642" class="lj lk it lf b gy lq lm l ln lo">upper_bound = go.Scatter(hoverinfo="skip",<br/>                         x=dates,<br/>                         showlegend =False,<br/>                         xaxis='x1',<br/>                         yaxis='y1',<br/>                         y=df['3s'],<br/>                         marker=dict(color="#444"),<br/>                         line=dict(<br/>                             color=('rgb(23, 96, 167)'),<br/>                             width=2,<br/>                             dash='dash'),<br/>                         fillcolor='rgba(68, 68, 68, 0.3)',<br/>                         fill='tonexty')</span><span id="4f67" class="lj lk it lf b gy lq lm l ln lo">lower_bound = go.Scatter(name='Confidence Interval',<br/>                          x=dates,<br/>                         xaxis='x1',<br/>                         yaxis='y1',<br/>                          y=df['-3s'],<br/>                          marker=dict(color="#444"),<br/>                          line=dict(<br/>                              color=('rgb(23, 96, 167)'),<br/>                              width=2,<br/>                              dash='dash'),<br/>                          fillcolor='rgba(68, 68, 68, 0.3)',<br/>                          fill='tonexty')</span><span id="01f2" class="lj lk it lf b gy lq lm l ln lo">Actuals = go.Scatter(name= 'Actuals',<br/>                     x= dates,<br/>                     y= df['actuals'],<br/>                    xaxis='x2', yaxis='y2',<br/>                     mode='line',<br/>                     marker=dict(size=12,<br/>                                 line=dict(width=1),<br/>                                 color="blue"))</span><span id="c1b8" class="lj lk it lf b gy lq lm l ln lo">Predicted = go.Scatter(name= 'Predicted',<br/>                     x= dates,<br/>                     y= df['predicted'],<br/>                    xaxis='x2', yaxis='y2',<br/>                     mode='line',<br/>                     marker=dict(size=12,<br/>                                 line=dict(width=1),<br/>                                 color="orange"))</span><span id="9351" class="lj lk it lf b gy lq lm l ln lo"># create plot for error...<br/>    Error = go.Scatter(name="Error",<br/>                   x=dates, y=df['error'],<br/>                   xaxis='x1',<br/>                   yaxis='y1',<br/>                   mode='line',<br/>                   marker=dict(size=12,<br/>                               line=dict(width=1),<br/>                               color="red"),<br/>                   text="Error")</span><span id="354a" class="lj lk it lf b gy lq lm l ln lo">anomalies_map = go.Scatter(name = "anomaly actual",<br/>                                   showlegend=False,<br/>                                   x=dates,<br/>                                   y=anomaly_points,<br/>                                   mode='markers',<br/>                                   xaxis='x2',<br/>                                   yaxis='y2',<br/>                                    marker = dict(color ="red",<br/>                                  size = 11,<br/>                                 line = dict(<br/>                                     color = "red",<br/>                                     width = 2)))</span><span id="8444" class="lj lk it lf b gy lq lm l ln lo">Mvingavrg = go.Scatter(name="Moving Average",<br/>                           x=dates,<br/>                           y=df['meanval'],<br/>                           mode='line',<br/>                           xaxis='x1',<br/>                           yaxis='y1',<br/>                           marker=dict(size=12,<br/>                                       line=dict(width=1),<br/>                                       color="green"),<br/>                           text="Moving average")</span><span id="e144" class="lj lk it lf b gy lq lm l ln lo">axis=dict(<br/>    showline=True,<br/>    zeroline=False,<br/>    showgrid=True,<br/>    mirror=True,<br/>    ticklen=4,<br/>    gridcolor='#ffffff',<br/>    tickfont=dict(size=10))</span><span id="b2f4" class="lj lk it lf b gy lq lm l ln lo">layout = dict(<br/>    width=1000,<br/>    height=865,<br/>    autosize=False,<br/>    title= metric_name,<br/>    margin = dict(t=75),<br/>    showlegend=True,<br/>    xaxis1=dict(axis, **dict(domain=[0, 1], anchor='y1', showticklabels=True)),<br/>    xaxis2=dict(axis, **dict(domain=[0, 1], anchor='y2', showticklabels=True)),<br/>    yaxis1=dict(axis, **dict(domain=[2 * 0.21 + 0.20 + 0.09, 1], anchor='x1', hoverformat='.2f')),<br/>    yaxis2=dict(axis, **dict(domain=[0.21 + 0.12, 2 * 0.31 + 0.02], anchor='x2', hoverformat='.2f')))</span><span id="d394" class="lj lk it lf b gy lq lm l ln lo">fig = go.Figure(data = [table,anomalies,anomalies_map,<br/>                        upper_bound,lower_bound,Actuals,Predicted,<br/>                        Mvingavrg,Error], layout = layout)</span><span id="a8f1" class="lj lk it lf b gy lq lm l ln lo">iplot(fig)<br/>pyplot.show()</span><span id="45b0" class="lj lk it lf b gy lq lm l ln lo">classify_df=detect_classify_anomalies(predicted_df,7)<br/>classify_df.reset_index(inplace=True)<br/>del classify_df['index']<br/>plot_anomaly(classify_df,"metric_name")</span></pre><figure class="la lb lc ld gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi jq"><img src="../Images/910836500b0b40dfe1d29735a4a1bd9f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*yeLT55Hn7s22Jujox90GDg.png"/></div></div></figure><p id="fcc6" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">通过使用<strong class="kd iu">滚动平均值和标准偏差</strong>，我们能够避免在<strong class="kd iu">大减价日</strong>这样的场景中出现连续的错误异常。</p><p id="32df" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">突出显示第一个峰值或谷值，之后调整阈值。</p><p id="190e" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">此外，提供实际数据的表格根据异常水平预测了变化和条件格式。</p><p id="509a" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">接下来，我们还尝试使用 LSTM 预测，这是一个递归神经网络。</p><p id="401c" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated"><a class="ae kz" href="https://machinelearningmastery.com/time-series-prediction-lstm-recurrent-neural-networks-python-keras/" rel="noopener ugc nofollow" target="_blank">https://machine learning mastery . com/time-series-prediction-lstm-recurrent-neural-networks-python-keras/</a>是一个非常好的使用 lstm 进行时间序列预测的教程，我们将在这里使用部分代码作为我们的用例。</p><p id="2951" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">以下是用于差分、与它们的倒数一起缩放以及训练和预测**LSTM**的辅助函数。</p><pre class="la lb lc ld gt le lf lg lh aw li bi"><span id="e68a" class="lj lk it lf b gy ll lm l ln lo">from pandas import DataFrame<br/>from pandas import Series<br/>from pandas import concat<br/>from pandas import read_csv<br/>from pandas import datetime<br/>from sklearn.metrics import mean_squared_error<br/>from sklearn.preprocessing import MinMaxScaler<br/>from keras.models import Sequential<br/>from keras.layers import Dense<br/>from keras.layers import LSTM<br/>from math import sqrt<br/><br/># frame a sequence as a supervised learning problem<br/>def timeseries_to_supervised(data, lag=1):<br/>    df = DataFrame(data)<br/>    columns = [df.shift(i) for i in range(1, lag+1)]<br/>    columns.append(df)<br/>    df = concat(columns, axis=1)<br/>    df.fillna(0, inplace=True)<br/>    return df</span><span id="c843" class="lj lk it lf b gy lq lm l ln lo"># create a differenced series<br/>def difference(dataset, interval=1):<br/>    diff = list()<br/>    for i in range(interval, len(dataset)):<br/>        value = dataset[i] - dataset[i - interval]<br/>        diff.append(value)<br/>    return Series(diff)</span><span id="3fc2" class="lj lk it lf b gy lq lm l ln lo"># invert differenced value<br/>def inverse_difference(history, yhat, interval=1):<br/>    return yhat + history[-interval]</span><span id="8724" class="lj lk it lf b gy lq lm l ln lo"># scale train and test data to [-1, 1]<br/>def scale(train, test):<br/>    # fit scaler<br/>    scaler = MinMaxScaler(feature_range=(-1, 1))<br/>    scaler = scaler.fit(train)<br/>    # transform train<br/>    train = train.reshape(train.shape[0], train.shape[1])<br/>    train_scaled = scaler.transform(train)<br/>    # transform test<br/>    test = test.reshape(test.shape[0], test.shape[1])<br/>    test_scaled = scaler.transform(test)<br/>    return scaler, train_scaled, test_scaled</span><span id="4383" class="lj lk it lf b gy lq lm l ln lo"># inverse scaling for a forecasted value<br/>def invert_scale(scaler, X, value):<br/>    new_row = [x for x in X] + [value]<br/>    array = np.array(new_row)<br/>    array = array.reshape(1, len(array))<br/>    inverted = scaler.inverse_transform(array)<br/>    return inverted[0, -1]</span><span id="d81e" class="lj lk it lf b gy lq lm l ln lo"># fit an LSTM network to training data<br/>def fit_lstm(train, batch_size, nb_epoch, neurons):<br/>    X, y = train[:, 0:-1], train[:, -1]<br/>    X = X.reshape(X.shape[0], 1, X.shape[1])<br/>    model = Sequential()<br/>    model.add(LSTM(neurons, batch_input_shape=(batch_size, X.shape[1], X.shape[2]), stateful=True))<br/>    model.add(Dense(1))<br/>    model.compile(loss='mean_squared_error', optimizer='adam')<br/>    for i in range(nb_epoch):<br/>        model.fit(X, y, epochs=1, batch_size=batch_size, verbose=0, shuffle=False)<br/>        model.reset_states()<br/>    return model</span><span id="d828" class="lj lk it lf b gy lq lm l ln lo"># make a one-step forecast<br/>def forecast_lstm(model, batch_size, X):<br/>    X = X.reshape(1, 1, len(X))<br/>    yhat = model.predict(X, batch_size=batch_size)<br/>    return yhat[0,0]</span><span id="b864" class="lj lk it lf b gy lq lm l ln lo">#### LSTM<br/>supervised = timeseries_to_supervised(actual_log, 1)<br/>supervised_values = supervised.values</span><span id="8558" class="lj lk it lf b gy lq lm l ln lo"># split data into train and test-sets<br/>train_lstm, test_lstm = supervised_values[0:-70], supervised_values[-70:]</span><span id="7ca3" class="lj lk it lf b gy lq lm l ln lo"># transform the scale of the data<br/>scaler, train_scaled_lstm, test_scaled_lstm = scale(train_lstm, test_lstm)</span><span id="f542" class="lj lk it lf b gy lq lm l ln lo"># fit the model                 batch,Epoch,Neurons<br/>lstm_model = fit_lstm(train_scaled_lstm, 1, 850 , 3)<br/># forecast the entire training dataset to build up state for forecasting<br/>train_reshaped = train_scaled_lstm[:, 0].reshape(len(train_scaled_lstm), 1, 1)<br/>#lstm_model.predict(train_reshaped, batch_size=1)</span></pre><p id="0a42" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">使用 LSTM 预测数据并绘制结果</p><pre class="la lb lc ld gt le lf lg lh aw li bi"><span id="a4e2" class="lj lk it lf b gy ll lm l ln lo">from matplotlib import pyplot<br/>import matplotlib.pyplot as plt<br/>import plotly.plotly as py<br/>import plotly.tools as tls</span><span id="8703" class="lj lk it lf b gy lq lm l ln lo"># walk-forward validation on the test data<br/>predictions = list()<br/>for i in range(len(test_scaled_lstm)):<br/>#make one-step forecast<br/>    X, y = test_scaled_lstm[i, 0:-1], test_scaled_lstm[i, -1]<br/>    yhat = forecast_lstm(lstm_model, 1, X)<br/>    # invert scaling<br/>    yhat = invert_scale(scaler, X, yhat)<br/>    # invert differencing<br/>    #yhat = inverse_difference(raw_values, yhat, len(test_scaled)+1-i)<br/>    # store forecast<br/>    predictions.append(10**yhat)<br/>    expected = actual_log[len(train_lstm) + i ]<br/># line plot of observed vs predicted<br/>figsize=(12, 7)<br/>plt.figure(figsize=figsize)<br/>pyplot.plot(actual_vals[-70:],label='Actuals')<br/>pyplot.plot(predictions, color = "red",label='Predicted')<br/>pyplot.legend(loc='upper right')<br/>pyplot.show()</span></pre><figure class="la lb lc ld gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi ly"><img src="../Images/b1f39f22ea1cb9105ff9ea616619cdae.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*CvYmLh55YJMUoGoNTstVNQ.png"/></div></div></figure><p id="edc8" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">LSTM 也很适合这个指标。LSTM 神经网络的重要参数是<strong class="kd iu">激活函数、神经元数量、批量大小和时期</strong>，需要对其进行调整以获得更好的结果。</p><p id="48b1" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">现在，让我们在不同的指标数据中尝试一下。数据是同一时期的。</p><pre class="la lb lc ld gt le lf lg lh aw li bi"><span id="0bb2" class="lj lk it lf b gy ll lm l ln lo">tf_df=pd.read_csv('../input/forecast-metric2/time_series_metric2.csv')<br/>tf_df.head()</span></pre><figure class="la lb lc ld gt ju gh gi paragraph-image"><div class="gh gi lz"><img src="../Images/d28c33979ef84a393e522fe24178bce6.png" data-original-src="https://miro.medium.com/v2/resize:fit:680/format:webp/1*d5-60hXh5rX8htJTeDm5jA.png"/></div></figure><p id="b128" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">按照与上述相同的步骤，我们使用 auto arima 获得最佳参数并逐步预测。</p><p id="bb21" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">绘制实际结果和预测结果。</p><pre class="la lb lc ld gt le lf lg lh aw li bi"><span id="6bb7" class="lj lk it lf b gy ll lm l ln lo">actual_vals = tf_df.actuals.values<br/>train, test = actual_vals[0:-70], actual_vals[-70:]<br/>train_log, test_log = np.log10(train), np.log10(test)<br/>from pyramid.arima import auto_arima<br/>stepwise_model = auto_arima(train_log, start_p=1, start_q=1,<br/>                           max_p=3, max_q=3, m=7,<br/>                           start_P=0, seasonal=True,<br/>                           d=1, D=1, trace=True,<br/>                           error_action='ignore',  <br/>                           suppress_warnings=True, <br/>                           stepwise=True)<br/>history = [x for x in train_log]<br/>predictions = list()<br/>predict_log=list()<br/>for t in range(len(test_log)):<br/>    #model = sm.tsa.SARIMAX(history, order=my_order, seasonal_order=my_seasonal_order,enforce_stationarity=False,enforce_invertibility=False)<br/>    stepwise_model.fit(history,enforce_stationarity=False,enforce_invertibility=False)<br/>    output = stepwise_model.predict(n_periods=1)<br/>    predict_log.append(output[0])<br/>    yhat = 10**output[0]<br/>    predictions.append(yhat)<br/>    obs = test_log[t]<br/>    history.append(obs)<br/>    #print('predicted=%f, expected=%f' % (output[0], obs))<br/>#error = math.sqrt(mean_squared_error(test_log, predict_log))<br/>#print('Test rmse: %.3f' % error)<br/># plot<br/>figsize=(12, 7)<br/>plt.figure(figsize=figsize)<br/>pyplot.plot(test,label='Actuals')<br/>pyplot.plot(predictions, color='red',label='Predicted')<br/>pyplot.legend(loc='upper right')<br/>pyplot.show()</span></pre><figure class="la lb lc ld gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi ma"><img src="../Images/6acee38de26c4578c75bb4036563089a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*3C-QmrGYfEU-WLflLMt8AA.png"/></div></div></figure><p id="508d" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">这里，算法试图<strong class="kd iu">追踪实际值</strong>。虽然这可能是一个误差较低的好预测，但是实际中的<strong class="kd iu">异常行为</strong>不能用这个来识别。</p><p id="0789" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">这是一个使用预测技术进行异常检测的问题。<strong class="kd iu">我们试图捕捉数据中的趋势/季节性，同时不对误差进行过多优化，以获得实际值的精确副本(这使得我们难以发现异常)。</strong></p><p id="c9d7" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">每个指标都需要用微调的参数进行验证，以便在使用预测来检测异常时检测到异常。此外，对于具有不同数据分布的指标，需要遵循不同的方法来识别异常。</p><p id="eea9" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">另一个缺点是，<strong class="kd iu">隔离林我们检测到一个用例的异常，该用例一次包含多个指标，我们向下钻取其中单个指标的异常。而使用预测机制，我们需要一个单独的关联逻辑，因为预测是针对指标的</strong>。</p><p id="f734" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">而像隔离森林这样的算法从数据中分离出异常行为，这些异常行为可用于归纳多个指标。</p></div></div>    
</body>
</html>