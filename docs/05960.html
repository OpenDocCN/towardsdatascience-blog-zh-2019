<html>
<head>
<title>Hello World in Speech Recognition</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">语音识别中的 Hello World</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/hello-world-in-speech-recognition-b2f43b6c5871?source=collection_archive---------14-----------------------#2019-08-30">https://towardsdatascience.com/hello-world-in-speech-recognition-b2f43b6c5871?source=collection_archive---------14-----------------------#2019-08-30</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="8252" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">Tensorflow 中的端到端 ASR 分解</h2></div><p id="698e" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">本博客将帮助您使用 Tensorflow 编写一个基本的端到端 ASR 系统。我将检查一个最小的神经网络和一个前缀束搜索解码器的每个组件，它需要从音频生成一个可读的抄本。我遇到了很多关于围绕计算机视觉和自然语言处理任务构建基本机器学习系统的资源，但在语音识别方面却很少。这是一个尝试，以填补这一空白，并使这一领域不那么令人生畏的初学者。</p><h2 id="437a" class="le lf it bd lg lh li dn lj lk ll dp lm kr ln lo lp kv lq lr ls kz lt lu lv lw bi translated">先决条件</h2><p id="65be" class="pw-post-body-paragraph ki kj it kk b kl lx ju kn ko ly jx kq kr lz kt ku kv ma kx ky kz mb lb lc ld im bi translated">熟悉:</p><ul class=""><li id="7a6c" class="mc md it kk b kl km ko kp kr me kv mf kz mg ld mh mi mj mk bi translated">神经网络的组件</li><li id="da28" class="mc md it kk b kl ml ko mm kr mn kv mo kz mp ld mh mi mj mk bi translated">训练神经网络</li><li id="0a42" class="mc md it kk b kl ml ko mm kr mn kv mo kz mp ld mh mi mj mk bi translated">使用语言模型获得单词序列的概率</li></ul><h2 id="0738" class="le lf it bd lg lh li dn lj lk ll dp lm kr ln lo lp kv lq lr ls kz lt lu lv lw bi translated"><strong class="ak">概述</strong></h2><ul class=""><li id="5c64" class="mc md it kk b kl lx ko ly kr mq kv mr kz ms ld mh mi mj mk bi translated"><strong class="kk iu">音频预处理:</strong>将原始音频转换成数字特征，作为神经网络的输入</li><li id="8f0b" class="mc md it kk b kl ml ko mm kr mn kv mo kz mp ld mh mi mj mk bi translated"><strong class="kk iu">神经网络:</strong>一个简单的架构，用于将音频特征转换成抄本中可能字符的概率分布</li><li id="c528" class="mc md it kk b kl ml ko mm kr mn kv mo kz mp ld mh mi mj mk bi translated"><strong class="kk iu"> CTC 损失:</strong>计算损失，而不用相应的字符标注音频的每个时间步长</li><li id="bc25" class="mc md it kk b kl ml ko mm kr mn kv mo kz mp ld mh mi mj mk bi translated"><strong class="kk iu">解码:</strong>使用前缀束搜索和语言模型从每个时间步长的概率分布创建抄本</li></ul><p id="87ea" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我将重点介绍神经网络、CTC 损失和解码部分。</p><h2 id="ec37" class="le lf it bd lg lh li dn lj lk ll dp lm kr ln lo lp kv lq lr ls kz lt lu lv lw bi translated"><strong class="ak">音频预处理</strong></h2><p id="2653" class="pw-post-body-paragraph ki kj it kk b kl lx ju kn ko ly jx kq kr lz kt ku kv ma kx ky kz mb lb lc ld im bi translated">你需要把你的音频转换成一个特征矩阵，然后输入到你的神经网络中。一个简单的方法是创建光谱图。</p><figure class="mt mu mv mw gt mx"><div class="bz fp l di"><div class="my mz l"/></div></figure><p id="84e9" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">这个函数计算音频信号的短时傅立叶变换，然后计算功率谱。输出是一个称为声谱图的矩阵。你可以直接用这个作为你的输入。其他替代方法是滤波器组和 MFCCs。音频预处理本身就是一个完整的话题。你可以在这里详细了解<a class="ae na" href="https://haythamfayek.com/2016/04/21/speech-processing-for-machine-learning.html" rel="noopener ugc nofollow" target="_blank">。</a></p><h2 id="b5fe" class="le lf it bd lg lh li dn lj lk ll dp lm kr ln lo lp kv lq lr ls kz lt lu lv lw bi translated"><strong class="ak">神经网络</strong></h2><p id="b4eb" class="pw-post-body-paragraph ki kj it kk b kl lx ju kn ko ly jx kq kr lz kt ku kv ma kx ky kz mb lb lc ld im bi translated">这是一个简单的架构。</p><figure class="mt mu mv mw gt mx gh gi paragraph-image"><div class="gh gi nb"><img src="../Images/028b8ea52e31089fe36dd372b79084ae.png" data-original-src="https://miro.medium.com/v2/resize:fit:1322/format:webp/1*YBUYeseJbPaZmZIoo-qn0Q.png"/></div><figcaption class="ne nf gj gh gi ng nh bd b be z dk">Hello World Architecture for Speech Recognition</figcaption></figure><p id="9cdd" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">谱图输入可以被认为是每个时间戳的向量。1D 卷积层从这些向量中提取特征，给你一个特征向量序列，供 LSTM 层处理。对于每个时间步长,(双)LSTM 层的输出被传递到完全连接的层，该层使用 softmax 激活给出该时间步长的角色的概率分布。该网络将用 CTC(连接主义时间分类)损失函数进行训练。在了解整个管道之后，可以随意试验更复杂的模型。</p><figure class="mt mu mv mw gt mx"><div class="bz fp l di"><div class="my mz l"/></div></figure><p id="d29a" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="kk iu">为什么选择 CTC？</strong>该网络试图预测每个时间步的字符。然而，我们的标签并不是每个时间步的字符，而只是音频的转录。请记住，转录中的每个字符可能跨越多个时间步长。如果你以某种方式标记音频中的每个时间步长，单词 C-A-T 会被理解为 C-C-C-A-A-T-T。每 10 毫秒注释一次音频数据集是不可行的。CTC 解决了这个问题，因为它不需要我们标记每个时间步长。它将上述神经网络的整个输出概率矩阵和相应的文本作为输入，忽略抄本中每个字符的位置和实际偏移量。</p><h2 id="04ef" class="le lf it bd lg lh li dn lj lk ll dp lm kr ln lo lp kv lq lr ls kz lt lu lv lw bi translated"><strong class="ak"> CTC 损失计算</strong></h2><figure class="mt mu mv mw gt mx gh gi paragraph-image"><div role="button" tabindex="0" class="nj nk di nl bf nm"><div class="gh gi ni"><img src="../Images/4cb6a6cfb169e337538bf146ae7c3fe8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*u8ah74DylC0aRCvgxvSbtA.png"/></div></div><figcaption class="ne nf gj gh gi ng nh bd b be z dk">Example of the output matrix</figcaption></figure><p id="91d6" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">假设地面真相标签是猫。在这四个时间步中，像 C-C-A-T，C-A-A-T，C-A-T-T，_-C-A-T，C-A-T-_ 这样的序列都对应于我们的基本真理。我们将通过对所有这些序列的概率求和来计算我们的地面真实的概率。根据输出概率矩阵，通过乘以其字符的概率来计算单个序列的概率。对于上述序列，总概率为 0.0288+0.0144+0.0036+0.0576+0.0012 = 0.1056。损失是这个概率的负对数。损失函数已经在 TensorFlow 中实现。你可以在这里阅读<a class="ae na" href="https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/nn/ctc_loss" rel="noopener ugc nofollow" target="_blank">文件</a>。</p><h2 id="1445" class="le lf it bd lg lh li dn lj lk ll dp lm kr ln lo lp kv lq lr ls kz lt lu lv lw bi translated"><strong class="ak">解码</strong></h2><p id="4a89" class="pw-post-body-paragraph ki kj it kk b kl lx ju kn ko ly jx kq kr lz kt ku kv ma kx ky kz mb lb lc ld im bi translated">你从上面的神经网络得到的输出就是 CTC 矩阵。CTC 矩阵给出了每个时间步中字符集中每个字符的概率。我们使用前缀束搜索从这个矩阵中产生有意义的文本。</p><p id="7106" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">CTC 矩阵中的字符集除了字母和空格字符之外，还有两个特殊的符号。这些是空白标记和字符串结束标记。</p><p id="4da4" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="kk iu">空白令牌的用途:</strong>CTC 矩阵中的时间步长通常很小。(~10 毫秒)所以口语句子的每个字符跨越多个时间步长。例如，C-A-T 变成了 C-C-C-A-A-T-T。因此，我们折叠了在 CTC 矩阵中突出的所有可能的候选字符串。像搞笑这种 N 应该重复的词呢？两个 Ns 之间的空白标记防止它们折叠成一个，而不在文本中添加任何内容。所以，F-F-U-N-[blank]-N-N - Y 崩成滑稽。</p><p id="1fab" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="kk iu">End-token 的用途:</strong> End-of-string 表示口语句子的结尾。在字符串结束标记之后的时间步长解码不会向候选字符串添加任何内容。</p><h2 id="b1bc" class="le lf it bd lg lh li dn lj lk ll dp lm kr ln lo lp kv lq lr ls kz lt lu lv lw bi translated"><strong class="ak">程序:</strong></h2><p id="8600" class="pw-post-body-paragraph ki kj it kk b kl lx ju kn ko ly jx kq kr lz kt ku kv ma kx ky kz mb lb lc ld im bi translated"><strong class="kk iu">初始化</strong>:</p><ul class=""><li id="fffe" class="mc md it kk b kl km ko kp kr me kv mf kz mg ld mh mi mj mk bi translated">我们最初有一份候选人名单。它由一个空白字符串组成。该列表还包含在每个时间步中以空白标记结束和以非空白标记结束的候选的概率。空白字符串在时间 0 以空白标记结尾的概率是 1。以非空标记结尾的概率为 0。</li></ul><p id="4882" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="kk iu">迭代次数:</strong></p><ul class=""><li id="dfbc" class="mc md it kk b kl km ko kp kr me kv mf kz mg ld mh mi mj mk bi translated">我们把这个字符串一个接一个地加上每个字符。我们获取形成的每个扩展字符串，并计算其在时间=1 时以空白和非空白标记结束的概率。然后，我们将这些扩展字符串和它们的概率一起存储在我们的列表中。我们把这些新的候选人放入我们的列表，并在下一个时间步重复这个过程。</li><li id="dae0" class="mc md it kk b kl ml ko mm kr mn kv mo kz mp ld mh mi mj mk bi translated"><strong class="kk iu">案例 A: </strong>如果添加的字符是一个空白标记，我们不改变候选字符。</li><li id="0734" class="mc md it kk b kl ml ko mm kr mn kv mo kz mp ld mh mi mj mk bi translated"><strong class="kk iu">案例 B: </strong>如果添加的字符是一个空格，我们按照语言模型用一个与候选概率成比例的数乘以概率。这可以防止不正确的拼写成为最佳候选。所以酷在最终输出中不会被拼写成 KUL。</li><li id="ca59" class="mc md it kk b kl ml ko mm kr mn kv mo kz mp ld mh mi mj mk bi translated"><strong class="kk iu">情况 C: </strong>如果添加的字符与候选字符的最后一个字符相同。(候选人=好玩。我们创建了两个新的候选人，FUNN 和 FUN。乐趣的概率是根据以空白代币结束的乐趣的概率来计算的。FUNN 的概率是使用非空令牌中 FUN 结束的概率来计算的。因此，如果乐趣不以空白令牌结束，我们就丢弃额外的 N，而不是追加它。</li></ul><p id="ea29" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="kk iu">输出:<br/> </strong>所有时间步长后的最佳候选就是输出。</p><p id="7ed6" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我们做了两处修改来加快这个过程。</p><ol class=""><li id="8c24" class="mc md it kk b kl km ko kp kr me kv mf kz mg ld nn mi mj mk bi translated">在每个时间步长之后，我们丢弃除了最佳 K 个候选项之外的所有候选项。候选项按其以空白和非空白标记结尾的概率总和排序。</li><li id="eda6" class="mc md it kk b kl ml ko mm kr mn kv mo kz mp ld nn mi mj mk bi translated">我们不考虑在矩阵中概率低于某个阈值(~0.001)的字符。</li></ol><p id="d85b" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">查看下面的代码，了解实现细节。</p><figure class="mt mu mv mw gt mx"><div class="bz fp l di"><div class="my mz l"/></div></figure><p id="20c9" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">这就完成了一个基本的语音识别系统。你可以引入一些复杂的东西来获得更好的输出。更大的网络和音频预处理技巧很有帮助。这里是完整的<a class="ae na" href="https://github.com/apoorvnandan/speech-recognition-primer" rel="noopener ugc nofollow" target="_blank">代码</a>。</p></div><div class="ab cl no np hx nq" role="separator"><span class="nr bw bk ns nt nu"/><span class="nr bw bk ns nt nu"/><span class="nr bw bk ns nt"/></div><div class="im in io ip iq"><p id="c990" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">备注:<br/> 1。上面的代码使用 TensorFlow 2.0，样本音频文件取自<a class="ae na" href="http://www.openslr.org/12" rel="noopener ugc nofollow" target="_blank"> LibriSpeech </a>数据集。<br/> 2。您需要编写自己的批处理发生器来训练音频数据集。这些实现细节不包括在代码中。<br/> 3。您将需要为解码部分编写自己的语言模型函数。最简单的实现之一是基于一些文本语料库创建二元模型及其概率的字典。</p><p id="e581" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">参考文献:<br/>【1】a . y . Hannun 等人，<a class="ae na" href="https://arxiv.org/pdf/1408.2873v2.pdf" rel="noopener ugc nofollow" target="_blank">前缀搜索解码</a> (2014)，arXiv 预印本 arXiv:1408.2873，2014<br/>【2】a . Graves 等人，<a class="ae na" href="https://www.cs.toronto.edu/~graves/icml_2006.pdf" rel="noopener ugc nofollow" target="_blank"> CTC 丢失</a> (2006)，ICML 2006<br/>【3】l . Borgholt，<a class="ae na" href="https://medium.com/corti-ai/ctc-networks-and-language-models-prefix-beam-search-explained-c11d1ee23306" rel="noopener">前缀波束搜索</a> (2018)，中</p></div></div>    
</body>
</html>