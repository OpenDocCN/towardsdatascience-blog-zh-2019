# 防止机器学习模型中的数据泄漏

> 原文：<https://towardsdatascience.com/preventing-data-leakage-in-your-machine-learning-model-9ae54b3cd1fb?source=collection_archive---------5----------------------->

## 在建立机器学习模型时，关于防止数据泄漏，您需要知道的一切。

![](img/6956d4cb415a7a8bcbde8759cca42571.png)

Photo by [Luis Quintero](https://www.pexels.com/@jibarofoto?utm_content=attributionCopyText&utm_medium=referral&utm_source=pexels) from [Pexels](https://www.pexels.com/photo/photo-of-gray-faucet-2339722/?utm_content=attributionCopyText&utm_medium=referral&utm_source=pexels)

# **数据泄露问题**

机器学习算法制作预测和分类数据的模型。常见的最佳实践是首先将可用数据集分成两个训练和测试数据子集。之后，使用训练集对模型进行训练，并通过将其性能与测试集的性能进行比较来衡量其成功。

**但是如果模型在被训练的时候暴露在测试数据中会怎么样呢？**

这就是数据泄露的问题——当用于训练模型的数据恰好包含试图预测的信息时。如果一个模型暴露于测试数据，那么它当然会在预测/分类它被训练来预测/分类的测试数据方面表现得更好。

如果未被检测到，数据泄露可能会导致问题，包括:

*   实验室中夸大的模型性能，以及
*   与真实数据一起部署时性能较差。

使用机器学习算法来建立模型的目的是模拟现实世界中看不见的数据，并找出如何一致地预测或分类数据。但是，如果发生数据泄漏，一个模型不太可能在现实世界中用新数据很好地概括。因此，在开发模型时，必须采取措施防止数据泄漏。

# 帮助防止数据泄露的 6 种方法

1.  了解数据集
2.  清除数据集的重复项
3.  选择关于目标变量相关性和时间排序的特征
4.  将数据集分为训练组、验证组和测试组
5.  在分割之后、交叉验证之前进行规范化
6.  以健康的怀疑态度评估模型性能

# 1.了解数据集

不言而喻，为了能够执行有效的分析和开发合理的模型，关于您正在处理的数据集的知识是必要的。

然而，在数据泄漏方面，很少提到的是，在将数据分成训练-验证-测试组之前，您应该避免研究数据集的分布或基本统计数据(稍后将详细介绍如何分割数据集)。如果您在分割之前检查您的数据，您将获得关于可能在您的测试组中结束的数据行的见解，这实际上是数据泄漏。

# 2.清除数据集的重复项

数据清理是大多数(如果不是全部)数据科学项目的必要步骤。一个常见的数据清理任务是处理具有重复信息的行。在数据泄漏的情况下，重要的是删除重复的行，这样就不会在训练组和测试组中都出现重复的行。

# 3.选择关于目标变量相关性和时间排序的特征

防止数据泄漏的下一个重要步骤是选择与目标变量不相关且在预测时可用的特征或独立变量。

## 考虑目标变量相关性

如果一个变量与目标变量高度相关，无疑会增加你的模型对目标的预测能力。例如，如果您的目标变量是家庭收入，并且您将家庭支出作为一个特征包含在您的模型中，那么很有理由认为您的模型会更好地预测家庭收入，因为家庭支出是家庭收入的一个非常直接的指标。因此，为了防止数据泄漏，最好从模型中省略这些特征。

## 考虑时间排序

用未来数据预测过去是数据泄露的一种形式。时间序列数据、预测发生时不可用的特征或关于未来数据的分类特征都是与数据的时间顺序(顺序计时)相关的数据泄漏威胁。

当处理**时间序列数据**时，挑战在于确保不将关于未来的信息泄露给过去。例如，将 2019 年的数据包括在一个模型中，该模型被训练来对 2018 年进行预测。克服时间序列数据泄漏的一个选择是对每个时间段进行训练-验证-测试分割。

另一种选择是移除在预测时不可用的所有数据/ **特征。例如，关于客户是否会拖欠贷款的信息可能要到客户实际拖欠并且贷款已经被批准之后才可用。因此，如果有关延迟付款状态的信息包含在决定是否批准向该客户提供贷款的模型中，将会出现数据泄漏，从而使模型在现实环境中变得不切实际。**

此外，有必要研究一下标记未来信息的**分类特征。例如，基于高购买频率，客户可能被标记为“大买家”，但是如果模型试图预测哪些客户将是频繁的回头客，此信息将导致数据泄漏。**

*关于在使用时间序列数据检验时防止数据泄漏的更多信息 Rafael Pierre 的"* [*数据泄漏，第一部分:认为你有一个很棒的机器学习模型？再想想*](/data-leakage-part-i-think-you-have-a-great-machine-learning-model-think-again-ad44921fbf34) *”并且为了更深入的解释时态排序，checkout Devin Soni 的“* [*机器学习中的数据泄漏*](/data-leakage-in-machine-learning-10bdd3eec742) *”*

# 4.将数据集分为训练组、验证组和测试组

将数据分成两组，训练组和测试组，是标准的做法。但是，我建议更进一步，将数据分成三组——训练组、验证组和测试组。有了三个组，您就有了一个验证组来帮助超调模型参数，以及一个在模型调优后使用的最终测试组。

**分割后，不要在验证和测试集上执行探索性数据分析——只对训练集执行！**通过检查验证或测试集的洞察力生成的任何附加特征或模型更新都是数据泄漏的实例。

**分区**是将数据集分成训练、验证和测试组时要考虑的一个重要步骤，因为有多个行来自同一个源。分区包括对该源的行进行分组，并且只将它们包含在一个分割集中，否则来自该源的数据将会在多个集中泄漏。

# 5.在分割之后、交叉验证之前进行规范化

很多机器学习算法都需要归一化。但是，在拆分数据后进行规范化非常重要。如果在分割前进行归一化，用于归一化数据的平均值和标准差将基于整个数据集，而不是训练子集，因此会将有关测试或验证集的信息泄漏到训练集中。

将数据拆分为训练集、验证集和测试集后，最佳方法是首先规范化训练集，然后将训练集规范化的平均值和标准差应用于验证集和测试集规范化。

但是，如果您计划使用网格搜索交叉验证来超调参数，如果在交叉验证之前进行，缩放训练集将导致数据泄漏，因为交叉验证进一步将训练集划分为附加的训练集和测试集。建议将 Pipeline 与 GridSearchCV 配合使用，以便通过标准缩放器等数据预处理程序更恰当地缩放数据。我在下面附上了一个代码截图，它使用管道在使用 GridSearchCV 时适当地缩放数据。

![](img/d52aa82133879687ec50dc96964f1734.png)

# 6.以健康的怀疑态度评估模型性能

最后，但同样重要的是，在评估模型性能时，保持健康的怀疑态度是很重要的。

多个来源警告数据科学家，当一个模型具有高性能分数时，要感到疲倦，因为优秀的分数可能表明数据泄漏。以下是评估模型性能时需要考虑的六点。这些问题的答案可能会暗示数据泄露是否正在发生。

## 考虑使用的机器学习算法

在评估你的模型的时候，先想想正在使用的机器学习算法。算法是在复杂问题上表现良好的弱算法吗？该算法过去是否用于类似的数据/问题？与您当前模型的性能相比，该算法在过去案例中的性能如何？

## 与基线比较

回头看看你的基线模型，寻找“好得令人难以置信”的表现

## 合理化功能重要性

如果你的算法返回特征重要性，试着想出一个合理的解释来解释为什么每个重要的特征是重要的。如果不存在逻辑上的原因，就有数据泄露的可能。也试着一次从你的模型中去掉一个特性，如果性能急剧下降，那么被去掉的特性有可能包含泄漏。

## 使用多个指标

建议在评估模型性能时使用多种方法。如果您只使用一个指标(例如准确性)，该指标可能会隐藏其他指标可能会发现的数据泄漏。

## 检查训练集和测试集分布

在拟合模型和测量性能之后，探索训练、验证和测试组的分布以发现差异和可以解释结果的任何模式将是有益的。

## 使用新的验证集进行测试

最后，如果您有资源，检索更多的数据来测试模型在尽可能接近现实的新验证集上的性能总是有利的。