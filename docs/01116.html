<html>
<head>
<title>Spark Joy — Saying Konmari to your event logs with grammar of data manipulation</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">spark Joy——用数据操作语法对您的事件日志说 Konmari</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/spark-joy-saying-konmari-to-your-event-logs-with-grammar-of-data-manipulation-7de2d2c6bd29?source=collection_archive---------27-----------------------#2019-02-20">https://towardsdatascience.com/spark-joy-saying-konmari-to-your-event-logs-with-grammar-of-data-manipulation-7de2d2c6bd29?source=collection_archive---------27-----------------------#2019-02-20</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><figure class="gl gn jo jp jq jr gh gi paragraph-image"><div class="gh gi jn"><img src="../Images/d0ffe936fef470942a51c5f67b38f521.png" data-original-src="https://miro.medium.com/v2/resize:fit:1200/format:webp/1*CoX5-J-NJOv8-yrAKCankg.png"/></div></figure><p id="1f97" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">当你有一大堆事件日志要解析时，首选的<em class="ks">武器</em>应该是什么？在本文中，我将分享我尝试 spark/spark ryr 解决这个问题的经验。</p><p id="767a" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">在<a class="ae kt" href="http://honestbee.com/" rel="noopener ugc nofollow" target="_blank"> Honestbee </a>捕获用户数据的事件日志🐝作为数据湖的一部分存储在 S3 自动气象站，每隔 40 分钟从<a class="ae kt" href="https://segment.com/blog/exactly-once-delivery/" rel="noopener ugc nofollow" target="_blank">段</a>发送给我们。学习如何检索这些数据非常重要，数据(科学)团队使用这些日志来评估我们的机器学习模型(又名<em class="ks"> canonical </em> A B testing)的性能。</p><p id="f0a3" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">此外，我们还使用相同的日志来跟踪业务 KPI，如<strong class="jw ir"><em class="ks">C</em></strong><em class="ks">lick</em><strong class="jw ir"><em class="ks">T</em></strong><em class="ks">through</em><strong class="jw ir"><em class="ks">R</em></strong><em class="ks">ate、</em><strong class="jw ir"><em class="ks">C</em></strong><em class="ks">on version</em><strong class="jw ir"><em class="ks">R</em></strong><em class="ks">ate 和</em></p><p id="af26" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">在本文中，我将分享我们如何利用运行 Spark 的高内存集群来解析食物推荐系统生成的日志。</p><h1 id="d1cf" class="ku kv iq bd kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr bi translated">案例研究:食物推荐系统</h1><p id="a72b" class="pw-post-body-paragraph ju jv iq jw b jx ls jz ka kb lt kd ke kf lu kh ki kj lv kl km kn lw kp kq kr ij bi translated">每当一位诚实的顾客开始结账时，我们的 ML 模型都会尽力对你最有可能加入购物车的商品进行个性化预测，尤其是你错过的商品。</p><figure class="ly lz ma mb gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="mc md di me bf mf"><div class="gh gi lx"><img src="../Images/8438acbbee651c9c1c48d58585e006aa.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*mOeE4CA7UljdtHAh.png"/></div></div></figure><blockquote class="mg mh mi"><p id="b686" class="ju jv ks jw b jx jy jz ka kb kc kd ke mj kg kh ki mk kk kl km ml ko kp kq kr ij bi translated"><em class="iq">一个</em>事后分析<em class="iq">，将要求我们查看日志，根据加权分布，查看用户被分配到哪个治疗组。</em></p></blockquote><p id="d033" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">现在，让我们开始吧。</p><p id="fd08" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">首先，我们导入必要的库:</p><figure class="ly lz ma mb gt jr"><div class="bz fp l di"><div class="mm mn l"/></div></figure><h1 id="ce4d" class="ku kv iq bd kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr bi translated">连接高记忆火花簇</h1><p id="0a11" class="pw-post-body-paragraph ju jv iq jw b jx ls jz ka kb lt kd ke kf lu kh ki kj lv kl km kn lw kp kq kr ij bi translated">接下来，我们需要连接主节点 Spark。我建议在转移到本地集群和远程集群之前，先从本地机器开始。</p><h1 id="b841" class="ku kv iq bd kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr bi translated">安装 Spark</h1><p id="9049" class="pw-post-body-paragraph ju jv iq jw b jx ls jz ka kb lt kd ke kf lu kh ki kj lv kl km kn lw kp kq kr ij bi translated">如果它还没有安装，幸运的是<code class="fe mo mp mq mr b">sparklyr</code>有一个内置的功能来帮助安装</p><pre class="ly lz ma mb gt ms mr mt mu aw mv bi"><span id="ea2a" class="mw kv iq mr b gy mx my l mz na">spark_install(<br/>    version = "2.4.0", <br/>    hadoop_version = "2.7"<br/>)</span></pre><blockquote class="mg mh mi"><p id="a346" class="ju jv ks jw b jx jy jz ka kb kc kd ke mj kg kh ki mk kk kl km ml ko kp kq kr ij bi translated"><em class="iq">注意，我们在这里也将 Hadoop 和 spark 一起安装，因为从 S3 文件系统读取文件所需的 jar 是附带的。</em></p></blockquote><h1 id="57d4" class="ku kv iq bd kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr bi translated">本地集群/单节点机箱</h1><p id="9b49" class="pw-post-body-paragraph ju jv iq jw b jx ls jz ka kb lt kd ke kf lu kh ki kj lv kl km kn lw kp kq kr ij bi translated">接下来，您将连接 spark cluster ie。建立一个<strong class="jw ir">S</strong>park<strong class="jw ir">C</strong>connection，通常缩写为 SC，会是你想要做的事情。</p><p id="39bf" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">如果您连接到本地安装的 spark 集群/单节点箱，您将设置主参数为<code class="fe mo mp mq mr b">local</code>。</p><figure class="ly lz ma mb gt jr"><div class="bz fp l di"><div class="mm mn l"/></div></figure><blockquote class="mg mh mi"><p id="b1fe" class="ju jv ks jw b jx jy jz ka kb kc kd ke mj kg kh ki mk kk kl km ml ko kp kq kr ij bi translated">你可能需要调整内存消耗，我把它设置为 150 Gb，你的里程可能会根据你的机器而有所不同。</p></blockquote><p id="7ec1" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">在笔记本电脑上运行 spark，或者作为一个更大的云实例上的单个节点安装都非常好。数据科学团队不拥有或管理集群，而是在单节点<em class="ks">超大型</em> EC2 实例上运行 spark，主要用于原型开发和 EDA。然而，当任务变得太大时，您可能会考虑更繁重的任务，比如适当的集群。</p><h1 id="9136" class="ku kv iq bd kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr bi translated">远程集群</h1><p id="afdc" class="pw-post-body-paragraph ju jv iq jw b jx ls jz ka kb lt kd ke kf lu kh ki kj lv kl km kn lw kp kq kr ij bi translated">如果您正在运行 jupyterhub / Rstudio server，特别是如果您希望为每个数据科学家提供一个集群，那么与远程 spot 集群连接的选项可能会很有吸引力。</p><p id="8833" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">在这种情况下，python / R 进程不会在集群的同一个主节点上运行。像 Qubole 和 Databricks 这样的第三方 Spark 即服务提供商可以缓解这种情况。在 Honestbee，我们也选择了这个选项，集群由我们的 AWS 帐户下的<a class="ae kt" href="https://www.qubole.com/" rel="noopener ugc nofollow" target="_blank"> Qubole </a>提供。</p><blockquote class="mg mh mi"><p id="16d3" class="ju jv ks jw b jx jy jz ka kb kc kd ke mj kg kh ki mk kk kl km ml ko kp kq kr ij bi translated">PS。Qubole 是一个很好的抢断！</p></blockquote><figure class="ly lz ma mb gt jr"><div class="bz fp l di"><div class="mm mn l"/></div></figure><p id="051e" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">上面的要点建立了一个 spark 连接<code class="fe mo mp mq mr b">sc</code>，你将需要在大多数函数中使用这个对象。</p><p id="71f5" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">另外，因为我们从 S3 读取，所以我们必须设置 S3 访问密钥和密码。这必须在执行<code class="fe mo mp mq mr b">spark_read_json</code>等功能之前进行设置</p><figure class="ly lz ma mb gt jr"><div class="bz fp l di"><div class="mm mn l"/></div></figure><blockquote class="mg mh mi"><p id="6cd7" class="ju jv ks jw b jx jy jz ka kb kc kd ke mj kg kh ki mk kk kl km ml ko kp kq kr ij bi translated"><em class="iq">所以你会问各有什么利弊。本地集群通常适合 EDA，因为您将通过 REST API (LIVY)进行通信。</em></p></blockquote><h1 id="033e" class="ku kv iq bd kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr bi translated"><em class="nb">读取 JSON 日志</em></h1><p id="1875" class="pw-post-body-paragraph ju jv iq jw b jx ls jz ka kb lt kd ke kf lu kh ki kj lv kl km kn lw kp kq kr ij bi translated">基本上有两种方法可以读取日志。第一种是把它们作为一个整体或者一个流来读——就像它们被倒进你的桶里一样。</p><p id="c9f3" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">有两个功能，<code class="fe mo mp mq mr b">spark_read_json</code>和<code class="fe mo mp mq mr b">stream_read_json</code>前者是批处理的，后者创建结构化的数据流。这也相当于读取您的拼花文件</p><h1 id="051a" class="ku kv iq bd kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr bi translated">成批的</h1><p id="a15d" class="pw-post-body-paragraph ju jv iq jw b jx ls jz ka kb lt kd ke kf lu kh ki kj lv kl km kn lw kp kq kr ij bi translated">应该用<code class="fe mo mp mq mr b">s3a</code>协议设置路径。<code class="fe mo mp mq mr b">s3a://segment_bucket/segment-logs/&lt;source_id&gt;/1550361600000.</code></p><pre class="ly lz ma mb gt ms mr mt mu aw mv bi"><span id="4281" class="mw kv iq mr b gy mx my l mz na">json_input = spark_read_json(<br/>    sc = sc,<br/>    name= "logs",<br/>    path= s3,<br/>    overwrite=TRUE<br/>)</span></pre><p id="b1c1" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">下面是魔法开始的地方:</p><figure class="ly lz ma mb gt jr"><div class="bz fp l di"><div class="mm mn l"/></div></figure><p id="9afc" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">如你所见，这是一个简单的查询…</p><ol class=""><li id="e82f" class="nc nd iq jw b jx jy kb kc kf ne kj nf kn ng kr nh ni nj nk bi translated">从<code class="fe mo mp mq mr b">Food</code>垂直方向过滤所有<code class="fe mo mp mq mr b">Added to Cart</code>事件</li><li id="f108" class="nc nd iq jw b jx nl kb nm kf nn kj no kn np kr nh ni nj nk bi translated">选择以下列:</li></ol><ul class=""><li id="e217" class="nc nd iq jw b jx jy kb kc kf ne kj nf kn ng kr nq ni nj nk bi translated"><code class="fe mo mp mq mr b">CartID</code></li><li id="dfd5" class="nc nd iq jw b jx nl kb nm kf nn kj no kn np kr nq ni nj nk bi translated"><code class="fe mo mp mq mr b">experiment_id</code></li><li id="6466" class="nc nd iq jw b jx nl kb nm kf nn kj no kn np kr nq ni nj nk bi translated"><code class="fe mo mp mq mr b">variant</code>(治疗组)和</li><li id="f3c7" class="nc nd iq jw b jx nl kb nm kf nn kj no kn np kr nq ni nj nk bi translated"><code class="fe mo mp mq mr b">timestamp</code></li></ul><p id="9a53" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">3.删除未将用户分配给模型的事件</p><p id="755a" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">4.添加新列:1。<code class="fe mo mp mq mr b">fulltime</code>可读时间，2。一天中的某个小时</p><p id="21bb" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">5.按照服务<code class="fe mo mp mq mr b">recommender</code>对日志进行分组，并计算行数</p><p id="e4ff" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">6.添加一个新列<code class="fe mo mp mq mr b">event</code>，其值为<code class="fe mo mp mq mr b">Added to Cart</code></p><p id="edd0" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">7.按时间排序</p><figure class="ly lz ma mb gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="mc md di me bf mf"><div class="gh gi nr"><img src="../Images/c202d04338a378a0dc9e4f9525a4d608.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*3-kxt6zFvtC6ooQkrPw0Eg.png"/></div></div><figcaption class="ns nt gj gh gi nu nv bd b be z dk">Here’s a plot of the output so we see Model 2 is really getting more clicks than Model 1.</figcaption></figure><h1 id="1372" class="ku kv iq bd kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr bi translated">火花流</h1><p id="d0a5" class="pw-post-body-paragraph ju jv iq jw b jx ls jz ka kb lt kd ke kf lu kh ki kj lv kl km kn lw kp kq kr ij bi translated">或者，您也可以将上述操作的结果写入结构化的火花流。</p><figure class="ly lz ma mb gt jr"><div class="bz fp l di"><div class="mm mn l"/></div></figure><p id="d280" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">您可以使用耦合到<code class="fe mo mp mq mr b">glimpse</code>的<code class="fe mo mp mq mr b">tbl</code>函数预览这些来自流的结果。</p><pre class="ly lz ma mb gt ms mr mt mu aw mv bi"><span id="e4f8" class="mw kv iq mr b gy mx my l mz na">sc %&gt;% <br/>  tbl("data_stream") %&gt;% <br/>  glimpse</span></pre><p id="ae2b" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">就这样，伙计们！</p></div><div class="ab cl nw nx hu ny" role="separator"><span class="nz bw bk oa ob oc"/><span class="nz bw bk oa ob oc"/><span class="nz bw bk oa ob"/></div><div class="ij ik il im in"><p id="663d" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">此外，我想对存储模型元数据的现有选项做一个评论，特别是当您使用多个模型进行 A|B 测试时，每个模型都有多个版本。</p><p id="2182" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">老实说，很难知道发生了什么。</p><figure class="ly lz ma mb gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="mc md di me bf mf"><div class="gh gi od"><img src="../Images/21c981a5b009e4b11c4d53772f846da5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*UkDjw0s7sS_IABA9.png"/></div></div></figure><p id="2458" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">对于我的博士学位，我个人致力于使用图形数据库来存储具有复杂关系的数据，我们目前正在努力开发这样一个系统来存储与我们的模型相关的元数据。</p><p id="cc30" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">例如:</p><ol class=""><li id="a4b5" class="nc nd iq jw b jx jy kb kc kf ne kj nf kn ng kr nh ni nj nk bi translated">它们与哪些 API 相关联</li><li id="a349" class="nc nd iq jw b jx nl kb nm kf nn kj no kn np kr nh ni nj nk bi translated">哪些气流/ <a class="ae kt" href="https://www.altoros.com/blog/kubeflow-automating-deployment-of-tensorflow-models-on-kubernetes/" rel="noopener ugc nofollow" target="_blank"> Argo </a>作业与这些模型相关联</li><li id="6d92" class="nc nd iq jw b jx nl kb nm kf nn kj no kn np kr nh ni nj nk bi translated">部署配置(舵图和地形)和其他部署元数据在哪里</li><li id="84f8" class="nc nd iq jw b jx nl kb nm kf nn kj no kn np kr nh ni nj nk bi translated">当然还有元数据，比如成绩和分数。</li></ol></div><div class="ab cl nw nx hu ny" role="separator"><span class="nz bw bk oa ob oc"/><span class="nz bw bk oa ob oc"/><span class="nz bw bk oa ob"/></div><div class="ij ik il im in"><p id="c125" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">来和我们谈谈吧，我们正在招人！<a class="ae kt" href="https://boards.greenhouse.io/honestbee/jobs/1426737" rel="noopener ugc nofollow" target="_blank">数据工程师</a>，<a class="ae kt" href="https://boards.greenhouse.io/honestbee/jobs/1427566" rel="noopener ugc nofollow" target="_blank">高级数据科学家</a></p><p id="55ed" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated"><em class="ks">原载于 2019 年 2 月 20 日</em><a class="ae kt" href="https://etheleon.github.io/articles/spark-joy/" rel="noopener ugc nofollow" target="_blank"><em class="ks">ethe Leon . github . io</em></a><em class="ks">。</em></p></div></div>    
</body>
</html>