<html>
<head>
<title>DeepFool — A simple and accurate method to fool Deep Neural Networks.</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">Deep fool——欺骗深度神经网络的简单而准确的方法。</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/deepfool-a-simple-and-accurate-method-to-fool-deep-neural-networks-17e0d0910ac0?source=collection_archive---------7-----------------------#2019-05-17">https://towardsdatascience.com/deepfool-a-simple-and-accurate-method-to-fool-deep-neural-networks-17e0d0910ac0?source=collection_archive---------7-----------------------#2019-05-17</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="6fab" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">敌对的攻击</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/5e215b8c5faed8dc3812ff962094f644.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*3-EbiajRp_pL6U2V2JP_oQ.png"/></div></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk"><strong class="bd kv">Fig 1. Its not a fish, its a bird :) </strong>[Confidences shown are the values of logits and not passed through softmax]</figcaption></figure><p id="0e1a" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><em class="ls">论文摘要<br/> </em> <strong class="ky ir"> <em class="ls"> DeepFool:一种简单准确的愚弄深度神经网络的方法</em> </strong> <em class="ls"> <br/>由</em> <strong class="ky ir"> <em class="ls">赛义德-穆赫森·穆沙维-德兹夫利、阿尔侯赛因·法齐、帕斯卡尔·弗罗萨德</em> </strong> <em class="ls"> <br/>论文链接:</em><a class="ae lt" href="https://arxiv.org/pdf/1511.04599.pdf" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/pdf/1511.04599.pdf</a></p><h1 id="b5c7" class="lu lv iq bd lw lx ly lz ma mb mc md me jw mf jx mg jz mh ka mi kc mj kd mk ml bi translated">概观</h1><p id="1456" class="pw-post-body-paragraph kw kx iq ky b kz mm jr lb lc mn ju le lf mo lh li lj mp ll lm ln mq lp lq lr ij bi translated">深度神经网络在许多任务中实现了最先进的性能，但在轻微扰动的图像上惨败，以有意义的方式(而不是随机地)扰动。</p><p id="a9cd" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">DeepFool 论文有以下主要贡献:</p><ol class=""><li id="abc1" class="mr ms iq ky b kz la lc ld lf mt lj mu ln mv lr mw mx my mz bi translated">计算不同分类器对敌对扰动的鲁棒性的简单而精确的方法。</li><li id="4456" class="mr ms iq ky b kz na lc nb lf nc lj nd ln ne lr mw mx my mz bi translated">实验表明<br/> - DeepFool 计算出更优的对抗性扰动<br/> -对抗性训练显著增加了鲁棒性。</li></ol><h1 id="2dfa" class="lu lv iq bd lw lx ly lz ma mb mc md me jw mf jx mg jz mh ka mi kc mj kd mk ml bi translated">二元分类器的 DeepFool</h1><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nf"><img src="../Images/41f1fdd68af05a4c5a9ca6e88e71fd45.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*9AO0x_FlJJQaQr5ZS4w6zw.png"/></div></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk"><strong class="bd kv">FIg 2. Simple Image with Linear model to explain what DeepFool does.</strong></figcaption></figure><p id="29ed" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">使用线性二进制分类器可以容易地看出，对于输入<code class="fe ng nh ni nj b">x_{0}</code>的模型的鲁棒性(` f `)等于<code class="fe ng nh ni nj b">x_{0}</code>到超参数平面的距离(其将两个类别分开)。</p><p id="2ad6" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">改变分类器决策的最小扰动对应于<code class="fe ng nh ni nj b">x_{0}</code>在超参数平面上的正交投影。给出者:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi nk"><img src="../Images/dd5ef839dac14b0fe9328c6aba3eae18.png" data-original-src="https://miro.medium.com/v2/resize:fit:966/format:webp/1*S9LhqWtlsM07It3QYxXatA.png"/></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk"><strong class="bd kv">Fig 3. Equation to calculate the minimal perturbation.</strong></figcaption></figure><p id="b57d" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">以下是 DeepFool 针对二元分类器的算法:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nl"><img src="../Images/23fad8443fa5bb0052bff79516207279.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*8HjJmBB9_ulPnvLWbH99vg.png"/></div></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk"><strong class="bd kv">Fig 4. Algorithm to calculate the Adversarial Image for Binary Classifiers.</strong></figcaption></figure><p id="0b17" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir"> <em class="ls">我们来过一遍算法:</em> </strong> <br/> 1。该算法采用一个输入<code class="fe ng nh ni nj b">x</code>和一个分类器<code class="fe ng nh ni nj b">f</code>。<br/> 2。输出对图像进行微分类所需的最小扰动。<br/> 3。用原始输入初始化对立图像。并将循环变量设置为 1。<br/> 4。开始并继续循环，而真实标签和对抗扰动图像的标签是相同的。<br/> 5。计算输入到最近超平面的投影。<br/>(最小扰动)6。将扰动添加到图像中并进行测试。<br/>7–8。增量循环变量；结束循环<br/> 9。返回最小扰动</p><h1 id="b011" class="lu lv iq bd lw lx ly lz ma mb mc md me jw mf jx mg jz mh ka mi kc mj kd mk ml bi translated">多类分类器的 DeepFool</h1><p id="1acc" class="pw-post-body-paragraph kw kx iq ky b kz mm jr lb lc mn ju le lf mo lh li lj mp ll lm ln mq lp lq lr ij bi translated">对于多类分类器，假设输入是<code class="fe ng nh ni nj b">x</code>,每个类都有一个超平面(将一个类与其他类分开的直平面),并根据<code class="fe ng nh ni nj b">x</code>在空间中的位置将其分类到一个类中。现在，这种算法所做的就是，找到最近的超平面，然后将<code class="fe ng nh ni nj b">x</code>投影到该超平面上，并将其推得更远一点，从而尽可能以最小的扰动将其错误分类。就是这样。(浏览论文中的第 3 节以深入了解)</p><p id="2346" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">让我们来看看算法</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nm"><img src="../Images/6d09960cca3ee333a3f8ded14b6cca51.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*IgCRmdFMEMt8vyGzxMsq9A.png"/></div></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk"><strong class="bd kv">Fig 5. Algorithm to calculate the Adversarial Image for Multiclass Classifiers.</strong></figcaption></figure><p id="0dd0" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir"> <em class="ls">让我们快速预排一下算法的每一步:</em> </strong> <br/> 1。输入是一个图像<code class="fe ng nh ni nj b">x</code>和模型分类器<code class="fe ng nh ni nj b">f</code>。<br/> 2。扰动<br/> 3 的输出。【空白】<br/> 4。我们用原始图像和循环变量初始化扰动的图像。<br/> 5。我们开始迭代并继续进行，直到原始标签和扰动标签不相等。<br/>6–9。我们考虑在原始类之后具有最大概率的<code class="fe ng nh ni nj b">n</code>类，并且我们存储原始梯度和这些类中的每一个的梯度之间的最小差异(w_{k})以及标签中的差异(f_{k})。10。内部循环存储最小值 w_{k}和 f_{k}，并使用它计算输入<code class="fe ng nh ni nj b">x</code>的最近超平面(见图 6)。对于最近超平面的计算公式)<br/> 11。我们计算将<code class="fe ng nh ni nj b">x</code>投影到我们在 10 中计算的最近超平面上的最小向量。12。我们将最小扰动添加到图像中，并检查它是否被微分类。13 至 14 岁。循环变量增加；端环<br/> 15。返回总扰动，它是所有计算扰动的总和。</p><p id="292a" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">下面是计算最近超平面的公式:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nn"><img src="../Images/b11a35f0f99736acf6b2167421fdef94.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*iYVkN0h7HfmiZpOnb7vqEA.png"/></div></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk"><strong class="bd kv">Fig 6. Equation to calculate the closest hyperplane.</strong></figcaption></figure><p id="1f9a" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">其中，以<code class="fe ng nh ni nj b">f</code>开头的<br/>变量为类别标签<br/>以<code class="fe ng nh ni nj b">w</code>开头的变量为梯度<br/>其中，以<code class="fe ng nh ni nj b">k</code>为下标的变量为真实类别之后概率最大的类别，以<code class="fe ng nh ni nj b">\hat{k}(x+{0})</code>为下标的变量为真实类别。</p><p id="bced" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">下面是计算最小扰动(将输入投影到最近超平面的向量)的等式</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi no"><img src="../Images/307b8c124a55c0a85c553e568543ecd1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*LofmSuJZ43wXNThxmkKjhA.png"/></div></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk"><strong class="bd kv">Fig 7. Equation to calculate the minimal perturbation for multiclass classifiers.</strong></figcaption></figure><h2 id="197c" class="np lv iq bd lw nq nr dn ma ns nt dp me lf nu nv mg lj nw nx mi ln ny nz mk oa bi translated">模型的对抗性稳健性</h2><p id="55c8" class="pw-post-body-paragraph kw kx iq ky b kz mm jr lb lc mn ju le lf mo lh li lj mp ll lm ln mq lp lq lr ij bi translated">DeepFool 算法还提供了一种度量算法的对抗性鲁棒性的方法。它由提供</p><pre class="kg kh ki kj gt ob nj oc od aw oe bi"><span id="feab" class="np lv iq nj b gy of og l oh oi"># For images with a batch size of 1<br/>num_images = len(tloader))<br/>adversarial_robustness = (1 / num_images) * ((torch.norm(rt.flatten()) / (torch.norm(x.flatten()))</span></pre><h1 id="ef30" class="lu lv iq bd lw lx ly lz ma mb mc md me jw mf jx mg jz mh ka mi kc mj kd mk ml bi translated">实验</h1><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi oj"><img src="../Images/d779a3cb3d81589323e57dd001383cbc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*9HYeeWVrGfXlFEsJ8sPDqg.png"/></div></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk"><strong class="bd kv">Fig 8. Table demonstrating the test error rates and robustness of the models using each attack and the time to generate one adversarial example with each attack.</strong></figcaption></figure><p id="8f4e" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">其中，<br/> 4 —是快速梯度符号法。<br/> 18 —攻击来自 Szegedy 等人题为《神经网络的有趣特性》的论文。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ok"><img src="../Images/32016c2e087e593db337f0165b1a9450.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*WxvXIkC6MnMeOYlAP1kx5Q.png"/></div></div></figure><p id="52f7" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">使用通过快速梯度符号方法和 DeepFool 生成的对抗图像显示对抗训练效果的图表。这些图表证明了用最小扰动(而不是像快速梯度符号方法那样过度扰动)的对立例子进行训练的重要性。)</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ol"><img src="../Images/e82d7dbf99845559ac115c29677314c8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*oxfT6tSXVUMA89rmmDKOIA.png"/></div></div></figure><p id="6bd4" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">该图证明用过度扰动的图像进行训练降低了模型的稳健性。在这个实验中，作者仅使用α值逐渐增加的 DeepFool(其中α是与产生的扰动相乘的值)</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi om"><img src="../Images/2b3b70038a741312703e6a2c417f12e2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*mD_MPgUNZ-L5QtPyiGyaPQ.png"/></div></div></figure><p id="5754" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">该表显示了使用不同方法微调网络后的测试错误率。该表显示，用过度扰动的图像调整网络导致更高的测试错误率(由快速梯度符号方法产生的对立图像)。)</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi on"><img src="../Images/97e36677fec7ba81a04e917f492af78d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*VbaOq623J7jiNDQzkdYczQ.png"/></div></div></figure><p id="4560" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">图表显示了使用精确指标计算模型的对抗性稳健性的重要性。在这个实验中，他们使用 FGM 攻击和 DeepFool 攻击的<code class="fe ng nh ni nj b">p_adv</code>来计算 NIN(网络中的网络)模型的鲁棒性。该图显示了使用 FGM 攻击计算的鲁棒性如何给出错误的度量，因为它实际上并不像前面的示例所示的那样鲁棒(以及使用 DeepFool 攻击计算的鲁棒性的蓝线)。此外，请注意，在第一个额外时期(在用正常图像进行原始训练后，用相反扰动的图像对网络进行 5 个额外时期的训练)，红线(FGM)不够敏感，不足以证明鲁棒性的损失。</p></div><div class="ab cl oo op hu oq" role="separator"><span class="or bw bk os ot ou"/><span class="or bw bk os ot ou"/><span class="or bw bk os ot"/></div><div class="ij ik il im in"><h1 id="5ab8" class="lu lv iq bd lw lx ov lz ma mb ow md me jw ox jx mg jz oy ka mi kc oz kd mk ml bi translated">参考</h1><ol class=""><li id="197e" class="mr ms iq ky b kz mm lc mn lf pa lj pb ln pc lr mw mx my mz bi translated"><strong class="ky ir"> <em class="ls">赛义德-穆赫辛-穆沙维-德兹夫利、阿尔侯赛因-法齐、帕斯卡尔-弗罗萨德</em></strong>T5】；IEEE 计算机视觉和模式识别会议(CVPR)，2016 年，第 2574–2582 页</li></ol></div><div class="ab cl oo op hu oq" role="separator"><span class="or bw bk os ot ou"/><span class="or bw bk os ot ou"/><span class="or bw bk os ot"/></div><div class="ij ik il im in"><p id="d52f" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">希望这篇文章足够清晰，能让你很好地理解 DeepFool 算法是什么以及它是如何工作的。如果我发现更直观的解释或需要更多关注的地方，我希望将来更新这篇文章。请务必阅读这篇论文，以便更好地理解。感谢阅读！</p></div></div>    
</body>
</html>