<html>
<head>
<title>A Generative Approach to Classification</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">分类的生成方法</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/a-generative-approach-to-classification-17a0b5876729?source=collection_archive---------7-----------------------#2019-08-25">https://towardsdatascience.com/a-generative-approach-to-classification-17a0b5876729?source=collection_archive---------7-----------------------#2019-08-25</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="92b9" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">简单的解释</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/50998bbe86609604bd551b5824aa3584.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*h8trGxgZw6Cl98JCn-aokQ.jpeg"/></div></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk">Image by Prashant Sharma from Pixabay</figcaption></figure><p id="d687" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">每当有人谈到生成性分类模型和区分性分类模型时，我总是感到困惑。</p><p id="c7b7" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">我读了一遍又一遍，但不知何故，它避开了我。</p><p id="6518" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">所以我想到了写一篇关于它的帖子来提高我的理解。</p><p id="84ab" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><strong class="la iu"> <em class="lu">这篇文章是关于理解生成模型以及它们与判别模型的区别。</em> </strong></p><p id="8d01" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><em class="lu">最后，我们将自己创建一个简单的生成模型。</em></p></div><div class="ab cl lv lw hx lx" role="separator"><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma"/></div><div class="im in io ip iq"><h1 id="4669" class="mc md it bd me mf mg mh mi mj mk ml mm jz mn ka mo kc mp kd mq kf mr kg ms mt bi translated">区别性与生成性分类器</h1><p id="667d" class="pw-post-body-paragraph ky kz it la b lb mu ju ld le mv jx lg lh mw lj lk ll mx ln lo lp my lr ls lt im bi translated"><strong class="la iu"> <em class="lu">问题陈述:</em> </strong>有了一些输入数据，<code class="fe mz na nb nc b">X</code>我们要把数据分类到标签里<code class="fe mz na nb nc b">y</code>。</p><p id="8416" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">生成模型学习<strong class="la iu">联合</strong>概率分布<code class="fe mz na nb nc b">p(x,y)</code>，而判别模型学习<strong class="la iu">条件</strong>概率分布<code class="fe mz na nb nc b">p(y|x)</code></p><p id="d813" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><strong class="la iu"> <em class="lu">那么真的，有什么区别？他们看起来几乎一样。</em> </strong></p><p id="1bd4" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">假设我们有一个小样本数据:</p><p id="8965" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><code class="fe mz na nb nc b">(x,y) : [(0,1), (1,0), (1,0), (1, 1)]</code></p><p id="3009" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">那么<code class="fe mz na nb nc b">p(x,y)</code>就是</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nd"><img src="../Images/d9be45b66236841c9c891ec81cef930a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*xfqakwlR4MVlsUUyMS4hVA.png"/></div></div></figure><p id="f707" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">而<code class="fe mz na nb nc b">p(y|x)</code>是</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nd"><img src="../Images/33566132d55020563fd8381fa0af7986.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*r7SgM9Jr6i5mqHGLNilAGw.png"/></div></div></figure><p id="ebfe" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">如你所见，他们模拟了不同的概率。</p><p id="8e1c" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">判别分布<code class="fe mz na nb nc b">p(y|x)</code>可以直接用于将示例<code class="fe mz na nb nc b">x</code>分类到类别<code class="fe mz na nb nc b">y</code>。判别分类模型的一个例子是逻辑回归，其中我们尝试对 P(y|X)建模。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ne"><img src="../Images/ccf889bf5ea5ed7f2892c64c4a485a38.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*QQmlncEVhwgiOHsWPgg-Gw.png"/></div></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk">Logistic Regression</figcaption></figure><p id="1f9b" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">生成算法模型<code class="fe mz na nb nc b">p(x,y)</code>。一个例子是朴素贝叶斯模型，在该模型中，我们尝试对 P(X，y)建模，然后使用贝叶斯方程进行预测。</p></div><div class="ab cl lv lw hx lx" role="separator"><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma"/></div><div class="im in io ip iq"><h1 id="eb2d" class="mc md it bd me mf mg mh mi mj mk ml mm jz mn ka mo kc mp kd mq kf mr kg ms mt bi translated">生成分类背后的中心思想</h1><ul class=""><li id="11a7" class="nf ng it la b lb mu le mv lh nh ll ni lp nj lt nk nl nm nn bi translated">用概率分布分别拟合每个类别。</li><li id="44d2" class="nf ng it la b lb no le np lh nq ll nr lp ns lt nk nl nm nn bi translated">对一个新的点进行分类，找出它最有可能来自哪个分布。</li></ul><p id="7f70" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><strong class="la iu"> <em class="lu">还不明白的也不要着急。你一定会在这篇文章结束时得到它。</em> </strong></p></div><div class="ab cl lv lw hx lx" role="separator"><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma"/></div><div class="im in io ip iq"><h1 id="0554" class="mc md it bd me mf mg mh mi mj mk ml mm jz mn ka mo kc mp kd mq kf mr kg ms mt bi translated">一个小例子</h1><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nt"><img src="../Images/8aaef0a5f34139e6f0b69de8cfd44c0f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*GBxSh6QQ8mE_DbWB"/></div></div></figure><p id="b3df" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">让我们使用虹膜数据集。</p><p id="e055" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">对于我们的简单示例，我们将使用单个 x 变量 SepalLength 和我们的目标变量 Species。</p><p id="05da" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">让我们看看不同物种的萼片长度的分布。为此我使用了<a class="ae nu" rel="noopener" target="_blank" href="/pythons-one-liner-graph-creation-library-with-animations-hans-rosling-style-f2cb50490396"> plotly_express </a>。</p><pre class="kj kk kl km gt nv nc nw nx aw ny bi"><span id="e3b0" class="nz md it nc b gy oa ob l oc od">import plotly_express as px<br/>px.histogram(iris, x = 'SepalLengthCm',color = 'Species',nbins=20)</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oe"><img src="../Images/1e559f103ac6a27a34f7f967e6266c87.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*XyO7cGeltBwW0cwQV_pDDg.png"/></div></div></figure><p id="9343" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">要创建创成式模型，我们需要找出两组值:</p><h2 id="ad74" class="nz md it bd me of og dn mi oh oi dp mm lh oj ok mo ll ol om mq lp on oo ms op bi translated">1.个别类别的概率:</h2><p id="13f2" class="pw-post-body-paragraph ky kz it la b lb mu ju ld le mv jx lg lh mw lj lk ll mx ln lo lp my lr ls lt im bi translated">获得单个类的概率是相当简单的——例如，我们的数据集中的实例数，即 seta 除以数据集中的案例总数。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="oq or l"/></div></figure><pre class="kj kk kl km gt nv nc nw nx aw ny bi"><span id="e25f" class="nz md it nc b gy oa ob l oc od">0.3333333333333333 0.3333333333333333 0.3333333333333333</span></pre><p id="1342" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">虹膜数据集非常平衡。</p><h2 id="581d" class="nz md it bd me of og dn mi oh oi dp mm lh oj ok mo ll ol om mq lp on oo ms op bi translated">2.每类 x 的概率分布:</h2><p id="4989" class="pw-post-body-paragraph ky kz it la b lb mu ju ld le mv jx lg lh mw lj lk ll mx ln lo lp my lr ls lt im bi translated">这里我们拟合了 X 上的概率分布。我们假设 X 数据是正态分布的。因此，我们可以找到这三个分布的样本均值和方差(因为我们有三个类别)</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="oq or l"/></div></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oe"><img src="../Images/85f316a9527535c5c337886fd26c3424.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*lKYO3ZXpZlW-UyoQyN6-FQ.png"/></div></div></figure><p id="b63c" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">在上图中，我用三个物种的样本均值和方差为每个物种拟合了三个正态分布。</p><p id="9e37" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><strong class="la iu"> <em class="lu">那么，我们如何用这个来预测呢？</em>T3】</strong></p><p id="23d6" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">假设我们得到一个新的例子，SepalLength = 7 cm。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi os"><img src="../Images/1b543dad850507e494529592569c3d66.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*pZrcIw3eueXBgjdgDRrePQ.png"/></div></div></figure><p id="9dfb" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">因为我们看到最大概率出现在 virginica，我们预测 x=7 的 Virginica，也是基于该图；这看起来是非常正确的选择。</p><p id="9681" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">您也可以使用代码获取值。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="oq or l"/></div></figure><pre class="kj kk kl km gt nv nc nw nx aw ny bi"><span id="337a" class="nz md it nc b gy oa ob l oc od">Setosa 3.062104211904799e-08<br/>Versicolor 0.029478757465669376<br/><strong class="nc iu">Virginica 0.16881724812694823</strong></span></pre></div><div class="ab cl lv lw hx lx" role="separator"><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma"/></div><div class="im in io ip iq"><p id="4cea" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">这一切都很好。但是我们什么时候处理过单一变量呢？</p><p id="3ef9" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">让我们把例子扩展到两个变量。这一次让我们也使用 PetalLength。</p><pre class="kj kk kl km gt nv nc nw nx aw ny bi"><span id="ae52" class="nz md it nc b gy oa ob l oc od">px.scatter(iris, 'SepalLengthCm', 'PetalLengthCm',color = 'Species')</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ot"><img src="../Images/661d3cc1bf9e0e33f3da6b5c10fc80c2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*nkOsFfqQMA7aYz0CGReRUw.png"/></div></div></figure><p id="b77c" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><strong class="la iu"> <em class="lu">那么在这种情况下我们该如何进行呢？</em> </strong></p><p id="6059" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">第一次我们在单个 x 上拟合正态分布，这次我们将拟合双变量正态分布。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="oq or l"/></div></figure><p id="74f0" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">这是它的样子:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ou"><img src="../Images/9077872392b8a6109ebe1373852b55c1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*QszSx2m6CnmOtyNPez7jkw.png"/></div></div></figure><p id="43bb" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">现在，其余的计算保持不变。</p><p id="c3c0" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">在上面的方程中，只有法线被二元法线代替。如你所见，通过使用二元正态分布，我们得到了更好的分类分离。</p><p id="b730" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><em class="lu">作为对多变量(多于 2 个)这种情况的扩展，我们可以使用多元正态分布。</em></p></div><div class="ab cl lv lw hx lx" role="separator"><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma"/></div><div class="im in io ip iq"><h1 id="c7f0" class="mc md it bd me mf mg mh mi mj mk ml mm jz mn ka mo kc mp kd mq kf mr kg ms mt bi translated">结论</h1><p id="0ac7" class="pw-post-body-paragraph ky kz it la b lb mu ju ld le mv jx lg lh mw lj lk ll mx ln lo lp my lr ls lt im bi translated">生成型模型擅长生成数据。但与此同时，创建这样的模型来捕捉数据的底层分布是极其困难的。</p><p id="495b" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">生成建模涉及许多假设，因此，这些模型在分类设置中的表现不如判别模型。在上面的例子中，我们还假设分布是正态的，这可能是不正确的，因此可能会引起偏差。</p><p id="038f" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">但是理解它们是如何工作的仍然是有帮助的。一类这样的模型被称为<a class="ae nu" rel="noopener" target="_blank" href="/an-end-to-end-introduction-to-gans-bf253f1fa52f">生成对抗网络</a>，它对于生成新图像非常有用，也非常有趣。</p><p id="7e9c" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><a class="ae nu" href="https://www.kaggle.com/mlwhiz/generative-modeling" rel="noopener ugc nofollow" target="_blank">这里的</a>是包含所有代码和可视化效果的内核。</p></div><div class="ab cl lv lw hx lx" role="separator"><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma"/></div><div class="im in io ip iq"><p id="6d4b" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">如果你想了解更多关于生成模型和机器学习的知识，我推荐圣地亚哥大学的这门<a class="ae nu" href="https://www.awin1.com/cread.php?awinmid=6798&amp;awinaffid=633074&amp;clickref=&amp;p=%5B%5Bhttps%3A%2F%2Fwww.edx.org%2Fcourse%2Fmachine-learning-fundamentals-4%5D%5D" rel="noopener ugc nofollow" target="_blank">机器学习基础</a>课程。上面的帖子大体上是从来自 SanDiego 的<a class="ae nu" href="https://www.awin1.com/cread.php?awinmid=6798&amp;awinaffid=633074&amp;clickref=&amp;p=%5B%5Bhttps%3A%2F%2Fwww.edx.org%2Fmicromasters%2Fuc-san-diegox-data-science%5D%5D" rel="noopener ugc nofollow" target="_blank"> MicroMasters 课程的内容中得到启发的，我目前正在努力构建我的数据科学学习。</a></p></div><div class="ab cl lv lw hx lx" role="separator"><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma"/></div><div class="im in io ip iq"><p id="4cac" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">谢谢你的阅读。将来我也会写更多初学者友好的帖子。在<a class="ae nu" href="https://medium.com/@rahul_agarwal?source=post_page---------------------------" rel="noopener"> <strong class="la iu">媒体</strong> </a>关注我，或者订阅我的<a class="ae nu" href="http://eepurl.com/dbQnuX?source=post_page---------------------------" rel="noopener ugc nofollow" target="_blank"> <strong class="la iu">博客</strong> </a>了解他们。一如既往，我欢迎反馈和建设性的批评，可以通过 Twitter <a class="ae nu" href="https://twitter.com/MLWhiz?source=post_page---------------------------" rel="noopener ugc nofollow" target="_blank"> @mlwhiz </a>联系到我。</p></div></div>    
</body>
</html>