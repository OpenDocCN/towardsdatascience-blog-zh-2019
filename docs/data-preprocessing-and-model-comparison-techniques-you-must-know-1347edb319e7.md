# 你必须知道的数据预处理和模型比较技术

> 原文：<https://towardsdatascience.com/data-preprocessing-and-model-comparison-techniques-you-must-know-1347edb319e7?source=collection_archive---------6----------------------->

## 成人人口普查收入—根据人口普查数据预测收入是否超过 5 万美元/年

![](img/68c6793870aad1b027d6c2c9480db994.png)

Photo by [Stephen Dawson](https://unsplash.com/@srd844?utm_source=medium&utm_medium=referral) on [Unsplash](https://unsplash.com?utm_source=medium&utm_medium=referral)

众所周知，在做数据科学项目时，永远不仅仅是在数据上拟合模型，获得模型性能。实际上，就好的项目而言，更多的是探索数据、清理、预处理数据，并最终比较几个模型的性能以获得最佳的一个。

在这篇文章中，我将使用来自 [UCI 机器学习库](https://archive.ics.uci.edu/ml/datasets/Census+Income)的美国人口普查数据，并介绍整个过程。在这个过程的最后，我们将解决以下几个问题:

1.  **构建一个能准确预测个人收入是否超过 5 万美元的模型。**
2.  **造成高收入和低收入的关键因素是什么？**
3.  **按性别或种族划分，这些普查属性是否存在显著差异？**
4.  **基于人口普查数据的任何底层集群(组)？**

## 探索数据

## 加载必要的 Python 库和人口普查数据

![](img/a4cb0248618ff018cb31ec9f6c55d970.png)

## 评估缺失数据

快速检查列或行中是否有任何巨大的缺失值，这可能会极大地影响后面的分析。

![](img/d5c1c4ba26ef7be2b5d075ca670f3cbd.png)

## 处理未知/缺失数据

上面的结果显示数据集中没有“null”值。但是根据提供的数据注释，未知数据被转换为“？”。因此，接下来，我们将转换'？'敬 NaNs。

![](img/0d4678efed833a1716c5cb747dbdcae8.png)

因为丢失了数据？在一个小卷中，这里我选择只删除标记为“？”的未知数据给你。但是如果丢失的数据量很大，就需要考虑用更先进的方法来输入 NaNs。

![](img/64e0989fe740a537e9e06f83a68c98a8.png)

在数据集中，列级别的最大缺失百分比是 5%，大多数列都足够完整。因此，这里我将删除 NaN 值，而不是手动输入。

![](img/eb652d2f8cc84ba1e89c3a9bc8cbd201.png)

## 探索数据分析

我们的目标是确定一个人的收入是否超过 5 万英镑，所以首先，要了解收入在数据集中的分布情况。对数据集的粗略调查将确定每个群体中有多少人，并告诉我们这些人的收入超过 50，000 美元的百分比。

在这里，我将生成一些变量来帮助分析，如下所示:
-记录总数
-年收入超过 5 万美元的人数
-年收入不超过 5 万美元的人数
-年收入超过 5 万美元的人数百分比

注意:
由于在 EDA 过程中，我们不需要测试数据，我将在这一部分中合并训练和测试数据，以便获得更好和更普遍的数据分布

![](img/da25e55dd055aa3c0555f526e7ac6c78.png)

从上面的图表中，我们可以看到 50000 人的大部分是处于职业生涯中期的人，而且 50000 人中男性比女性多一点，尤其是在 50 岁左右。

![](img/616902c93f5bf8cc39f8d7714c813c42.png)

我们可以看到收入超过 50000 的人的前三个最大的群体是行政管理人员、专业教授和销售人员。

![](img/7c58c192a0ac9f78e4195d7d293b9bf3.png)

由于种族在数据集中有点不平衡，白人占了 50K '组的大部分。而在每场比赛中，'<50K’ population is much larger than ‘> 50K '。

![](img/f6437341718bc3d9743d50c3f13020ad.png)

然后我们快速看一下教育和收入水平的关系。我们可以看到最大的群体是单身汉，其次是高材生和一些大学生。移动丢失的值后:

```
Total number of records: 45222
Individuals making more than $50,000: 11208
Individuals making at most $50,000: 34014
Percentage of individuals making more than $50,000: 24.78%
```

## 准备数据

在数据可以用作机器学习算法的输入之前，通常必须对其进行清理、格式化和重构。在处理完丢失的条目后，必须调整某些特性的某些品质。这种预处理可以极大地帮助几乎所有学习算法的结果和预测能力。

## 变换倾斜的连续要素

偏斜度可能违反模型假设，或者可能损害特征重要性的解释。因此，这里我将对倾斜的数据应用对数变换。

![](img/b13f7966729a2453d6a18e9cc95d0a20.png)

如图所示，在“资本收益”和“资本损失”特征中似乎存在偏斜。使用定量结果来确认我是否需要转换这两个变量的偏度。

![](img/0aeca5380ec745d1c6edb86529394f1d.png)

## 标准化数字特征

除了对高度倾斜的要素执行变换之外，这里还将对数字要素执行某种类型的缩放。对数据进行缩放不会改变每个特征的分布形状(如上面的“资本收益”或“资本损失”)；但是，对于依赖于数值大小的模型，缩放输入属性是很有用的，例如 k-最近邻和回归系数准备中使用的距离测量。

![](img/f207ad97e4a76a70313077ff6d097c87.png)

## 数据预处理

每个记录都有几个非数字的特征。通常，学习算法期望输入是数字，这需要转换非数字特征(称为*分类变量*)。这里通过使用**一键编码* *方案来转换分类变量。

此外，与非数字特性一样，我需要将非数字目标标签“income”转换为数字值，以便学习算法能够工作。由于这个标签只有两个可能的类别(“<=50K” and “> 50K”)，我们可以简单地将这两个类别分别编码为‘0’和‘1’。因此，我们将

1.  使用“sklearn.OneHotEncoder”对“features_log_minmax_transform”数据执行一步到位编码。
    —注意:由于测试数据是独立的，如果测试数据中有看不见的类别会使模型失败，这里使用 sklearn。OneHotEncoder 而不是 pd.get_dummies()
2.  将目标标签“income_raw”转换为数字条目。将带有“<=50K” to `0` and records with “> 50K”的记录设置为“1”。

![](img/aeddd74b6ae9a301caec07275f136eb5.png)

## 评估模型性能

在这一节中，我将研究五种不同的算法，并确定哪种算法最适合数据建模。这些算法中的四个将是监督学习器，第五个算法被称为朴素预测器。

## 朴素预测器

生成一个简单的预测器来显示没有任何智能的基础模型是什么样子。也就是说，如果我们选择一个总是预测个人收入超过 50，000 美元的模型，那么该模型在这个数据集上的准确性和 F 值会是多少？这里假设我们考虑更多的是正确预测收入超过 50K 的个人。

因此，模型准确预测那些收入超过 50，000 美元的人的能力比模型回忆那些人的能力更重要。我们可以使用 F-beta 分数作为同时考虑精确度和召回率的指标:

![](img/d900e23246e498031cef7f5ba532ce81.png)![](img/9682c47a32e7395f000a3534e9a640f0.png)

## 监督学习模型

除了基准模型之外，我将选择其他四个模型作为建立预测模型的候选模型:逻辑回归、随机森林、集成方法(AdaBoost)和支持向量机(SVM)。

1.  逻辑回归
2.  随机森林
3.  集成方法— AdaBoost
4.  支持向量机(SVM)

## 创建培训和预测渠道

为了更有效地正确评估上面选择的每个模型的性能，创建一个训练和预测管道很有帮助，它可以使用各种大小的训练数据快速有效地训练模型，并对测试数据执行预测。

流水线将:
—使学习者适应采样的训练数据，并记录训练时间。
—对测试数据“X_test”以及前 300 个训练点“X_train[:300]”进行预测。
—记录总的预测时间。
—计算训练子集和测试集的准确度分数。
—计算训练子集和测试集的 F 值。

## 初始模型评估

![](img/2c5488ea493ffc4c318e5d0c6766dba7.png)![](img/5761943d506145219c8ab09780b1d987.png)![](img/662c730bc140148b29e966a9872a4f4d.png)

## 改善结果

接下来，我将从四个监督学习模型中选择*最佳*模型用于测试数据。然后，我将在整个训练集(“X_train”和“y_train ”)上对模型进行网格搜索优化，以提高未调整模型的 F 值。

根据上面的模型性能图，尽管随机森林在训练集上表现最佳，但 AdaBoost 分类器最终在测试数据上预测最佳。虽然 AdaBoost 分类器的精度与其他模型的性能非常相似，但当模型应用于整个数据集时，AdaBoost 的 F-score 在训练和测试数据上都更好。此外，与花费更多时间来训练和预测的支持向量分类器相比，AdaBoost 更快。在二进制分类方面，AdaBoost 在这种情况下也会有很好的表现。

## 模型调整

微调选择的模型。使用网格搜索(` GridSearchCV `)。为此使用整个训练集。

![](img/8000c5f8f31eb7ccb1e01ecf72d9b6b9.png)

优化后的模型对测试数据的准确率为 0.8701，F 值为 0.7518。这两个分数都比未优化的模型好。此外，优化模型的性能比基准测试好得多

## 特征重要性

通常，在对数据集(如这里的人口普查数据)执行监督学习时，了解哪些特征提供最强的预测能力是很有用的。在这种情况下，这意味着我们希望确定少量最强有力地预测一个人最多挣 50，000 美元还是超过 50，000 美元的特征。

这里将选择一个具有“feature_importance_”属性的 scikit-learn 分类器(例如 adaboost、random forests)。使该分类器适合训练集，并使用该属性来确定人口普查数据集的前 5 个最重要的特征。

![](img/d9c224a59430e52ea200893b28e75346.png)

从结果来看，特征重要性把“资本损失”作为最重要的特征。这可能是因为更大的资本损失意味着这个人必须有足够的钱来投资。“年龄”排在第二位，这可能是因为年龄越大，给捐赠者的薪水就越高。“每周工作时间”和“性 _ 女性”排在第四和第五位，这可能是因为这不是确定的情况。这是真的，因为也许这个人工作时间更长，但单位工资更低。

从上面的可视化中，我们看到前五个最重要的特征占数据中所有特征重要性的一半以上。这暗示我们可以尝试减少特征空间并简化模型学习所需的信息。下面的代码单元将使用前面找到的相同的优化模型，并在仅具有前五个重要特性的相同训练集上对其进行训练。

![](img/6c905b3431ad9362da89e96c72dce39f.png)

如上图所示，如果我只使用重要的特性，这个模型的性能会差一点。准确率低了 5%，f 值低了 7%，所以在这种情况下，我仍然会选择使用所有特征来构建模型，除非拟合模型的时间很重要。

要更详细地了解我的分析，请随意查看我对应的 GitHub 库:

[https://github.com/JcFreya/Adult-Census-Income](https://github.com/JcFreya/Adult-Census-Income)