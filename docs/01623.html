<html>
<head>
<title>Web Traffic Forecasting</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">网络流量预测</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/web-traffic-forecasting-f6152ca240cb?source=collection_archive---------7-----------------------#2019-03-16">https://towardsdatascience.com/web-traffic-forecasting-f6152ca240cb?source=collection_archive---------7-----------------------#2019-03-16</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><blockquote class="jn jo jp"><p id="3d1d" class="jq jr js jt b ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko ij bi translated">使用谷歌 DeepMind 的 Wavenets</p></blockquote><p id="55f4" class="pw-post-body-paragraph jq jr iq jt b ju jv jw jx jy jz ka kb kp kd ke kf kq kh ki kj kr kl km kn ko ij bi translated"><em class="js">与</em> <a class="ae ks" href="https://medium.com/@apoorvareddy_24043" rel="noopener"> <em class="js">合写 Apoorva Reddy Addvalli</em></a><em class="js"/><a class="ae ks" href="https://medium.com/@bandiatindra" rel="noopener"><em class="js">at Indra Bandi</em></a></p><figure class="ku kv kw kx gt ky gh gi paragraph-image"><div role="button" tabindex="0" class="kz la di lb bf lc"><div class="gh gi kt"><img src="../Images/00fc578e3ce68f36537f66b5807533ea.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*bq3VUrIwFCxSQeVHv-wvHQ.png"/></div></div></figure><p id="f948" class="pw-post-body-paragraph jq jr iq jt b ju jv jw jx jy jz ka kb kp kd ke kf kq kh ki kj kr kl km kn ko ij bi translated"><strong class="jt ir">动机:</strong>时间序列作为统计学和机器学习中的一个重要概念，往往很少被我们这样的数据爱好者所探索。为了改变这种趋势，我们决定解决当今时代最紧迫的时间序列问题之一，<em class="js">“预测网络流量”</em>。</p><p id="6ce7" class="pw-post-body-paragraph jq jr iq jt b ju jv jw jx jy jz ka kb kp kd ke kf kq kh ki kj kr kl km kn ko ij bi translated">这个博客反映了我们在<a class="ae ks" href="https://www.kaggle.com/c/web-traffic-time-series-forecasting" rel="noopener ugc nofollow" target="_blank">网络流量时间序列预测</a>中的头脑风暴，这也是一个由 Kaggle 主办的比赛。我们相信这种预测可以帮助网站服务器有效地处理停机。我们实现的技术可以扩展到金融市场、天气预报、音频和视频处理中的各种应用。不仅如此，了解你的网站的流量轨迹也可以打开商机！</p><p id="4f0c" class="pw-post-body-paragraph jq jr iq jt b ju jv jw jx jy jz ka kb kp kd ke kf kq kh ki kj kr kl km kn ko ij bi translated"><strong class="jt ir">一、数据集</strong></p><p id="5099" class="pw-post-body-paragraph jq jr iq jt b ju jv jw jx jy jz ka kb kp kd ke kf kq kh ki kj kr kl km kn ko ij bi translated"><a class="ae ks" href="https://www.kaggle.com/c/web-traffic-time-series-forecasting/data" rel="noopener ugc nofollow" target="_blank">数据集</a>由 145k 个时间序列组成，代表不同维基百科文章的每日页面浏览量，从 2015 年 7 月 1 日开始，到 2017 年 9 月 10 日结束(804 个数据点)。目标是预测数据集中每篇文章在 2017 年 9 月 13 日到 2017 年 11 月 13 日之间的日浏览量(64 个数据点)。</p><figure class="ku kv kw kx gt ky gh gi paragraph-image"><div role="button" tabindex="0" class="kz la di lb bf lc"><div class="gh gi lf"><img src="../Images/18502ca8a6bd5acb5f498b56e76b1d77.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*XMhP4kjGnMMhe1Eg"/></div></div><figcaption class="lg lh gj gh gi li lj bd b be z dk"><strong class="bd lk">Fig 1. Trends for websites in the dataset</strong></figcaption></figure><p id="3e70" class="pw-post-body-paragraph jq jr iq jt b ju jv jw jx jy jz ka kb kp kd ke kf kq kh ki kj kr kl km kn ko ij bi translated"><strong class="jt ir">二。接近</strong></p><p id="f987" class="pw-post-body-paragraph jq jr iq jt b ju jv jw jx jy jz ka kb kp kd ke kf kq kh ki kj kr kl km kn ko ij bi translated">从过去的模式中学习来预测未来可以通过以下方式实现:</p><ol class=""><li id="4190" class="ll lm iq jt b ju jv jy jz kp ln kq lo kr lp ko lq lr ls lt bi translated">传统移动平均线，基于 ARIMA 的技术</li><li id="9623" class="ll lm iq jt b ju lu jy lv kp lw kq lx kr ly ko lq lr ls lt bi translated">递归神经网络——长短期记忆(LSTM)，门控递归单元(GRU)</li><li id="3592" class="ll lm iq jt b ju lu jy lv kp lw kq lx kr ly ko lq lr ls lt bi translated"><a class="ae ks" href="https://arxiv.org/abs/1609.03499" rel="noopener ugc nofollow" target="_blank">波网</a></li></ol><p id="adcb" class="pw-post-body-paragraph jq jr iq jt b ju jv jw jx jy jz ka kb kp kd ke kf kq kh ki kj kr kl km kn ko ij bi translated">波网的日益流行和我们对利用神经网络进行预测的兴趣使我们选择了波网。“谷歌深度思维”是 Wavenets ( <em class="js">目前用于谷歌的人工智能服务，云文本到语音</em>)背后的策划者，这进一步激发了我们的兴趣。</p><p id="722e" class="pw-post-body-paragraph jq jr iq jt b ju jv jw jx jy jz ka kb kp kd ke kf kq kh ki kj kr kl km kn ko ij bi translated">我们的研究还表明，Wavenets 的性能与 RNNs 相当或更好。这里有一篇文章的链接，这篇文章讲述了 Wavenets 如何捕捉 LSTMs 之类的长期依赖关系，但对于训练来说更快、更轻量。</p><p id="0bf1" class="pw-post-body-paragraph jq jr iq jt b ju jv jw jx jy jz ka kb kp kd ke kf kq kh ki kj kr kl km kn ko ij bi translated"><strong class="jt ir"> <em class="js">潜得更深！</em> </strong></p><p id="5744" class="pw-post-body-paragraph jq jr iq jt b ju jv jw jx jy jz ka kb kp kd ke kf kq kh ki kj kr kl km kn ko ij bi translated">为了获得直观的理解，让我们首先关注波网的复杂性，并理解为什么它们似乎适合我们的任务。</p><p id="7f54" class="pw-post-body-paragraph jq jr iq jt b ju jv jw jx jy jz ka kb kp kd ke kf kq kh ki kj kr kl km kn ko ij bi translated">波网的神奇之处在于“<em class="js">因果膨胀卷积</em>”逻辑，该逻辑提高了神经网络的效率，以捕捉时间流量&amp;长期相关性，而不增加过多的学习权重。</p><p id="5f62" class="pw-post-body-paragraph jq jr iq jt b ju jv jw jx jy jz ka kb kp kd ke kf kq kh ki kj kr kl km kn ko ij bi translated">让我们看看这些花哨的术语到底是什么意思-</p><p id="3966" class="pw-post-body-paragraph jq jr iq jt b ju jv jw jx jy jz ka kb kp kd ke kf kq kh ki kj kr kl km kn ko ij bi translated"><strong class="jt ir"> A .典型卷积层</strong></p><figure class="ku kv kw kx gt ky gh gi paragraph-image"><div role="button" tabindex="0" class="kz la di lb bf lc"><div class="gh gi lz"><img src="../Images/886cdc972f403d6e628bfb77a2e5aa99.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*i-vyhyQw6feMtPcg"/></div></div><figcaption class="lg lh gj gh gi li lj bd b be z dk"><strong class="bd lk">Fig.2 Typical Convolution Layer</strong></figcaption></figure><p id="1cef" class="pw-post-body-paragraph jq jr iq jt b ju jv jw jx jy jz ka kb kp kd ke kf kq kh ki kj kr kl km kn ko ij bi translated">上面是一个典型的卷积层的表现。对于 1d 卷积层，我们在输入序列上滑动权重过滤器，将其顺序应用于序列的<strong class="jt ir">重叠区域</strong>。</p><p id="f207" class="pw-post-body-paragraph jq jr iq jt b ju jv jw jx jy jz ka kb kp kd ke kf kq kh ki kj kr kl km kn ko ij bi translated">在上面的图像中，我们使用 X(0)和 X(1)来预测 y(0 ),这个序列对所有的 y 继续下去。我们可以看到过去和未来的数据被用来预测 y(0)。如果我们把这些 x 想象成时间序列值，那就有明显的问题了。我们会用未来来预测 y，所以我们的模型是作弊！</p><p id="d714" class="pw-post-body-paragraph jq jr iq jt b ju jv jw jx jy jz ka kb kp kd ke kf kq kh ki kj kr kl km kn ko ij bi translated">因此，我们必须确保输入不会影响及时处理它们的输出步骤。</p><p id="2f76" class="pw-post-body-paragraph jq jr iq jt b ju jv jw jx jy jz ka kb kp kd ke kf kq kh ki kj kr kl km kn ko ij bi translated">解决方法是什么？— <strong class="jt ir">因果卷积</strong></p><p id="ef85" class="pw-post-body-paragraph jq jr iq jt b ju jv jw jx jy jz ka kb kp kd ke kf kq kh ki kj kr kl km kn ko ij bi translated"><strong class="jt ir"> B. </strong> <strong class="jt ir">因果卷积</strong></p><figure class="ku kv kw kx gt ky gh gi paragraph-image"><div role="button" tabindex="0" class="kz la di lb bf lc"><div class="gh gi ma"><img src="../Images/fe15def4b931b4579fb9fe1d41726c00.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*tDjySeBTSUuuMMGp"/></div></div><figcaption class="lg lh gj gh gi li lj bd b be z dk"><strong class="bd lk">Fig 3. Causal Convolutions</strong></figcaption></figure><p id="a764" class="pw-post-body-paragraph jq jr iq jt b ju jv jw jx jy jz ka kb kp kd ke kf kq kh ki kj kr kl km kn ko ij bi translated">这就是我们调整卷积设计的步骤，以限制未来 X 影响过去的预测，加强<strong class="jt ir">因果</strong>关系。如果你也想限制你的输入，<em class="js"> keras </em>为我们简化了它。设置<em class="js">填充= </em> <strong class="jt ir"> <em class="js">【因果】</em> </strong>。</p><p id="d383" class="pw-post-body-paragraph jq jr iq jt b ju jv jw jx jy jz ka kb kp kd ke kf kq kh ki kj kr kl km kn ko ij bi translated"><strong class="jt ir"> C. </strong> <strong class="jt ir">因果性扩张回旋</strong></p><figure class="ku kv kw kx gt ky gh gi paragraph-image"><div role="button" tabindex="0" class="kz la di lb bf lc"><div class="gh gi mb"><img src="../Images/b25c54326c6e39e86fdca2de90680948.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*oTJIOVnuY4f_Kk4t"/></div></div><figcaption class="lg lh gj gh gi li lj bd b be z dk"><strong class="bd lk">Fig 4. Causal Dilated Convolutions</strong></figcaption></figure><p id="7cf4" class="pw-post-body-paragraph jq jr iq jt b ju jv jw jx jy jz ka kb kp kd ke kf kq kh ki kj kr kl km kn ko ij bi translated">现在我们已经捕获了时间流，让我们理解波网如何有效地捕获长程相关性(<em class="js">感受野</em>)，而不会导致影响计算效率的隐藏层的指数增加。</p><p id="48f2" class="pw-post-body-paragraph jq jr iq jt b ju jv jw jx jy jz ka kb kp kd ke kf kq kh ki kj kr kl km kn ko ij bi translated">为了解决这一问题，Wavenets 采用了扩张的概念，通过以<strong class="jt ir"> </strong> <em class="js">恒定扩张率</em>跳过输入，使感受野作为卷积层数的函数呈指数增加。通过设置特定的扩张率，您可以从更早的时间段获得类似季度、月份和年份的信息(在上面的表示中，我们在第一层捕获双月模式)。我们可以看到，同样的四个层现在将所有十六个输入系列值连接到高亮显示的输出。</p><p id="895a" class="pw-post-body-paragraph jq jr iq jt b ju jv jw jx jy jz ka kb kp kd ke kf kq kh ki kj kr kl km kn ko ij bi translated">由于上述规范，我们的波网可以用更少的参数捕获更多的信息，消耗更少的历元来收敛。因此，Wavenets 可以将感受野扩大到&gt; 400，而 RNNs 仅在 100-300 有效。</p><p id="6ace" class="pw-post-body-paragraph jq jr iq jt b ju jv jw jx jy jz ka kb kp kd ke kf kq kh ki kj kr kl km kn ko ij bi translated"><strong class="jt ir">三世。计算资源</strong></p><p id="ab19" class="pw-post-body-paragraph jq jr iq jt b ju jv jw jx jy jz ka kb kp kd ke kf kq kh ki kj kr kl km kn ko ij bi translated">我们在谷歌云平台(GCP)上使用<strong class="jt ir"> Nvidia </strong> Tesla K80 GPU 对我们的模型进行了 7-8 小时 3500 个纪元的训练。</p><p id="6979" class="pw-post-body-paragraph jq jr iq jt b ju jv jw jx jy jz ka kb kp kd ke kf kq kh ki kj kr kl km kn ko ij bi translated"><strong class="jt ir">四世。</strong> <strong class="jt ir">模型建筑</strong></p><p id="8d77" class="pw-post-body-paragraph jq jr iq jt b ju jv jw jx jy jz ka kb kp kd ke kf kq kh ki kj kr kl km kn ko ij bi translated">我们的解决方案受到 Kaggle 上第六名的启发。在竞争时没有缺失值处理，所以我们从缺失值处理开始。Wavenet 架构包括:</p><ul class=""><li id="a363" class="ll lm iq jt b ju jv jy jz kp ln kq lo kr lp ko mc lr ls lt bi translated">剩余块= 32</li><li id="a72b" class="ll lm iq jt b ju lu jy lv kp lw kq lx kr ly ko mc lr ls lt bi translated">跳过连接= 32</li><li id="8ffa" class="ll lm iq jt b ju lu jy lv kp lw kq lx kr ly ko mc lr ls lt bi translated">8 个扩展因果卷积层</li><li id="074f" class="ll lm iq jt b ju lu jy lv kp lw kq lx kr ly ko mc lr ls lt bi translated">每层 32 个宽度为 2 的过滤器</li><li id="2637" class="ll lm iq jt b ju lu jy lv kp lw kq lx kr ly ko mc lr ls lt bi translated">指数增长的膨胀率(1，2，4，8，…，128)</li><li id="6743" class="ll lm iq jt b ju lu jy lv kp lw kq lx kr ly ko mc lr ls lt bi translated">2 个(时间分布)完全连接的图层映射到最终输出</li></ul><figure class="ku kv kw kx gt ky gh gi paragraph-image"><div role="button" tabindex="0" class="kz la di lb bf lc"><div class="gh gi md"><img src="../Images/cd30b66ff777a7c4658029fa6bc71d00.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*kwCNgX3JCW9ya04c"/></div></div><figcaption class="lg lh gj gh gi li lj bd b be z dk"><strong class="bd lk"><em class="me">Fig 5. Overview of the residual block and the entire architecture</em></strong></figcaption></figure><p id="5cbe" class="pw-post-body-paragraph jq jr iq jt b ju jv jw jx jy jz ka kb kp kd ke kf kq kh ki kj kr kl km kn ko ij bi translated">转到围绕扩展因果卷积的主要逻辑的架构，包括</p><ul class=""><li id="fb25" class="ll lm iq jt b ju jv jy jz kp ln kq lo kr lp ko mc lr ls lt bi translated">门控激活</li><li id="4185" class="ll lm iq jt b ju lu jy lv kp lw kq lx kr ly ko mc lr ls lt bi translated">剩余连接和跳过连接</li></ul><p id="7173" class="pw-post-body-paragraph jq jr iq jt b ju jv jw jx jy jz ka kb kp kd ke kf kq kh ki kj kr kl km kn ko ij bi translated">为了获得一个鸟瞰图，扩展的因果卷积分成两个分支，并通过调节信息流的激活单元(<em class="js"> tanh 和 sigmoid </em>),这本质上类似于递归神经网络中的门控机制。它们随后通过逐元素乘法被重新组合。</p><p id="fd38" class="pw-post-body-paragraph jq jr iq jt b ju jv jw jx jy jz ka kb kp kd ke kf kq kh ki kj kr kl km kn ko ij bi translated">在时间序列中，当我们使用跳过连接在网络中前进时，需要保留较早的要素图层。可以认为这是对季节性和趋势的延续，季节性和趋势是最终预测处理的时间序列的主要驱动因素。架构中的剩余连接使模块的输入能够通过卷积，然后与卷积输出进行积分。</p><p id="82b5" class="pw-post-body-paragraph jq jr iq jt b ju jv jw jx jy jz ka kb kp kd ke kf kq kh ki kj kr kl km kn ko ij bi translated"><strong class="jt ir">五.精度测量</strong></p><p id="854f" class="pw-post-body-paragraph jq jr iq jt b ju jv jw jx jy jz ka kb kp kd ke kf kq kh ki kj kr kl km kn ko ij bi translated">我们使用 SMAPE(对称平均绝对百分比误差)的修改版本作为我们的准确性度量，这也是竞争的目标损失。SMAPE 由下式给出:</p><figure class="ku kv kw kx gt ky gh gi paragraph-image"><div class="gh gi mf"><img src="../Images/2c13defe06ecb790bf5afe5311230fac.png" data-original-src="https://miro.medium.com/v2/resize:fit:282/0*ee2yyzSLmfWjYE-x"/></div></figure><p id="f489" class="pw-post-body-paragraph jq jr iq jt b ju jv jw jx jy jz ka kb kp kd ke kf kq kh ki kj kr kl km kn ko ij bi translated">SMAPE 不能直接使用，因为在零值附近行为不稳定。在代码中，我们通过用 1 替换这些值来忽略不连续性。</p><p id="b36e" class="pw-post-body-paragraph jq jr iq jt b ju jv jw jx jy jz ka kb kp kd ke kf kq kh ki kj kr kl km kn ko ij bi translated"><strong class="jt ir">六。结果</strong></p><p id="5991" class="pw-post-body-paragraph jq jr iq jt b ju jv jw jx jy jz ka kb kp kd ke kf kq kh ki kj kr kl km kn ko ij bi translated">我们从两个方面验证了我们的结果。我们上传了我们的提交文件，得到了 35.89 的最终解决方案，略高于第二名的分数。</p><figure class="ku kv kw kx gt ky gh gi paragraph-image"><div role="button" tabindex="0" class="kz la di lb bf lc"><div class="gh gi mg"><img src="../Images/50cd4bc3235c0f17dc249508744f116f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*3mNXQPY7TCis74kh"/></div></div></figure><p id="8046" class="pw-post-body-paragraph jq jr iq jt b ju jv jw jx jy jz ka kb kp kd ke kf kq kh ki kj kr kl km kn ko ij bi translated">我们通过模型预测了数据集中过去 64 天的数据。以下是我们随机选择的 6 篇维基百科文章的趋势。正如你所看到的，页面浏览日志的趋势被很好地捕捉到了。像所有时间序列预测一样，峰值仍然很难捕捉。</p><figure class="ku kv kw kx gt ky gh gi paragraph-image"><div role="button" tabindex="0" class="kz la di lb bf lc"><div class="gh gi mh"><img src="../Images/286049c5593263e45c810c42fbd772bb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*HDSIgBj7XFOk_i3K"/></div></div><figcaption class="lg lh gj gh gi li lj bd b be z dk"><strong class="bd lk">Fig 6. Forecasted Trends</strong></figcaption></figure><p id="43aa" class="pw-post-body-paragraph jq jr iq jt b ju jv jw jx jy jz ka kb kp kd ke kf kq kh ki kj kr kl km kn ko ij bi translated"><strong class="jt ir">七。结论</strong></p><p id="8e7e" class="pw-post-body-paragraph jq jr iq jt b ju jv jw jx jy jz ka kb kp kd ke kf kq kh ki kj kr kl km kn ko ij bi translated">●实现了高质量的长期预测</p><p id="fd01" class="pw-post-body-paragraph jq jr iq jt b ju jv jw jx jy jz ka kb kp kd ke kf kq kh ki kj kr kl km kn ko ij bi translated">●有效捕捉季节性模式和长期趋势</p><p id="4841" class="pw-post-body-paragraph jq jr iq jt b ju jv jw jx jy jz ka kb kp kd ke kf kq kh ki kj kr kl km kn ko ij bi translated">●包括节假日、星期几、语言等外部信息，可能有助于我们的模型更准确地捕捉高点和低点</p><p id="4d8e" class="pw-post-body-paragraph jq jr iq jt b ju jv jw jx jy jz ka kb kp kd ke kf kq kh ki kj kr kl km kn ko ij bi translated">请随意浏览我们的<a class="ae ks" href="https://github.com/apoorva1995reddy/Web-Traffic-Forecasting-" rel="noopener ugc nofollow" target="_blank">代码</a>。</p><p id="7d74" class="pw-post-body-paragraph jq jr iq jt b ju jv jw jx jy jz ka kb kp kd ke kf kq kh ki kj kr kl km kn ko ij bi translated"><strong class="jt ir">八世。参考文献</strong></p><ol class=""><li id="263a" class="ll lm iq jt b ju jv jy jz kp ln kq lo kr lp ko lq lr ls lt bi translated">【https://arxiv.org/pdf/1609.03499.pdf T4】</li><li id="4f7a" class="ll lm iq jt b ju lu jy lv kp lw kq lx kr ly ko lq lr ls lt bi translated"><a class="ae ks" href="https://github.com/sjvasquez/web-traffic-forecasting" rel="noopener ugc nofollow" target="_blank">https://github.com/sjvasquez/web-traffic-forecasting</a></li><li id="f4b6" class="ll lm iq jt b ju lu jy lv kp lw kq lx kr ly ko lq lr ls lt bi translated"><a class="ae ks" href="https://bair.berkeley.edu/blog/2018/08/06/recurrent/" rel="noopener ugc nofollow" target="_blank">https://bair.berkeley.edu/blog/2018/08/06/recurrent/</a></li><li id="39f6" class="ll lm iq jt b ju lu jy lv kp lw kq lx kr ly ko lq lr ls lt bi translated"><a class="ae ks" href="https://medium.com/@kion.kim/wavenet-a-network-good-to-know-7caaae735435" rel="noopener">https://medium . com/@ kion . Kim/wave net-a-network-good-to-know-7 caaae 735435</a></li><li id="c29d" class="ll lm iq jt b ju lu jy lv kp lw kq lx kr ly ko lq lr ls lt bi translated"><a class="ae ks" href="https://github.com/JEddy92/TimeSeries_Seq2Seq" rel="noopener ugc nofollow" target="_blank">https://github.com/JEddy92/TimeSeries_Seq2Seq</a></li><li id="6024" class="ll lm iq jt b ju lu jy lv kp lw kq lx kr ly ko lq lr ls lt bi translated"><a class="ae ks" href="https://github.com/Arturus/kaggle-web-traffic" rel="noopener ugc nofollow" target="_blank">https://github.com/Arturus/kaggle-web-traffic</a></li><li id="ab38" class="ll lm iq jt b ju lu jy lv kp lw kq lx kr ly ko lq lr ls lt bi translated"><a class="ae ks" href="https://www.kaggle.com/arjunsurendran/using-lstm-on-training-data" rel="noopener ugc nofollow" target="_blank">https://www . ka ggle . com/arjunsurendran/using-lstm-on-training-data</a></li></ol></div></div>    
</body>
</html>