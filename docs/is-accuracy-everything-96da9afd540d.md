# 准确性就是一切吗？

> 原文：<https://towardsdatascience.com/is-accuracy-everything-96da9afd540d?source=collection_archive---------4----------------------->

## 评估分类模型的各种指标

![](img/a89ad5508b181902f071e99cd42c2619.png)

[Source](https://unsplash.com/)

如果你从事机器学习已经有一段时间了，那么你必须开发模型来获得高**精确度**，因为精确度是比较模型的主要指标，但是如果我告诉你模型评估并不总是考虑精确度**而只是**呢？

当我们必须评估一个模型时，我们确实会考虑准确性，但我们主要关注的是我们的模型有多**稳健**，它在不同数据集上的表现如何，以及它必须提供多少**灵活性**。

毫无疑问，准确性是一个需要考虑的重要指标，但是它并不总是给出全部情况。

当我们说模型是稳健的时，我们的意思是它已经认识到并且*正确地并且合意地学习了*关于数据，因此它做出的预测接近实际值。

由于涉及大量的数学技术和数据的不确定性，该模型可能会产生更好的准确性，但不能正确地实现数据，因此当数据变化时表现不佳。
这意味着该模型不够稳健，因此限制了它的使用。

例如，假设我们有 980 个苹果和 20 个橙子，我们有一个模型将每个水果分类为一个苹果。那么模型的准确性是 980/1000 = 98%，这意味着我们有一个高度*准确的*模型，但是如果我们使用这个模型来预测未来的水果，那么它将悲惨地失败，因为该模型被破坏，因为它只能预测一个类别。

人们一定经历过这样一种情况:模型在一个测试集上取得了很好的准确性，但在提供新数据(相同性质)时却表现不佳。

了解模型的全貌，即它如何实现数据以及如何进行预测，有助于深入理解模型，并有助于改进模型。

所以，假设你开发了一个达到 80%准确率的模型，那么你打算如何改进它？要改正错误，首先，我们要认识到错误。
同样，为了改进模型，我们必须从更深层次*审视我们的模型表现如何。
这不能通过简单地查看准确性来实现，因此需要考虑其他指标。*

在这篇文章中，我将带你了解一些最常用和最重要的分类模型的指标。

首先，我们必须看看**混淆矩阵**。

混淆矩阵是用于评估分类模型性能的表格。看起来是这样的。

![](img/523b8d6784b5fb6a96a05aff028d886c.png)

confusion matrix

这里，TN =真负值，即当实际值为“否”时，模型预测为“否”(即正确预测)。

FP =假阳性，即当实际值为“否”时，模型预测为“是”(即错误预测)

FN =假阴性，即当实际值为“是”时，模型预测为“否”(即错误预测)

并且 TP =真阳性，即，当实际值为“是”时，模型预测为“是”(即，正确的预测)

如果你研究过分类技术，那么你一定熟悉混淆矩阵，如果不是，我强烈建议你熟悉。

混淆矩阵是我们计算分类模型的所有指标所需要的。是啊！！！

让我们看看以下指标:

*   ***精度:*** 它是用下列公式计算的:

准确度= (TN + TP)/(TP + TN + FP + FN)

精确度表明了模型做出正确预测的总体频率。

*   ***错误率:*** 错误率告诉我们模型做出错误预测的频率。

分类错误**=**(FP**+**FN)**/**(TP**+**TN**+**FP**+**FN)

从上面的公式可以清楚地看出，

**误差= 1-精度**

*   ***敏感度:*** 敏感度(也称为**召回**)是已经检索到的相关实例占相关实例总数的比例。
    这意味着召回率是实际值为“是”(或正)时正确预测的值与实际值为“是”(正)的值的总数之比。
    换句话说，当实际值为‘是’(正值)时，那么预测值正确的频率，就是回忆。

其计算方法如下:

灵敏度(回忆)**=**TP**/**(FN**+**TP)

这里我们只考虑“是”(正值)的实际值。
从上面的表达式可以清楚地看出，回忆是一个分数(在 0 和 1 之间，包括 0 和 1)。

回忆是一种度量，它告诉我们当所有的实际值都是正数时，我们的模型有多好。

如果 Recall = 0，这意味着当实际值为“是”(正值)时，模型被破坏，甚至不能做出一个正确的预测。
如果 Recall = 1，这意味着当实际值为“是”(正值)时，模型足够好，可以正确地做出预测，但存在一些漏洞，将进一步讨论这些漏洞。

现在有人可能会问——当准确性提供了一般信息时，为什么我们需要考虑回忆呢？

为了回答这个问题，让我们考虑一个例子。假设我们有一个二元分类问题。
假设我们的数据集中有 100 个实例，其中 90 个为 0(负)，10 个为 1(正)。
现在让我们假设，由于类别不平衡，我们的模型预测所有 100 个条目为 0(负)。
准确度等于 90/100 = 90%
如果一个人只看准确度，那么他/她可以说该模型高度准确。但是现在让我们检查一下召回。

Recall = 0/10 = 0
我们得到 Recall = 0，这意味着模型坏了，当实际值为正时，它甚至不能正确分类单个条目。
由此可见，回忆对于评论车型性能是多么重要。
此外，这也表明仅仅依靠准确性并不是评估一个模型的最佳方式。

所以，我们不想要一个非常低的召回值，但是如果我们的召回值非常高(非常接近或等于 1)呢？
如果 recall = 1，那么这意味着当实际值为正时，模型已经正确地对所有值进行了分类。但这也可能是我们的模型预测所有值都为正值的情况，这意味着该模型的精度较低。在进一步讨论之前，让我们先定义一下什么是精度。

*   ***精度:*** 精度(也叫*正预测值*)是相关实例在检索到的实例中所占的比例。

换句话说，这意味着当模型预测为正值时，模型做出正确预测的几率有多大。

其计算方法如下:

精度**=**TP**/**(TP**+**FP)

这意味着我们希望最大化模型的精度，以便它可以正确地分类相关的实例，但是如果精度太高(非常接近或等于 1)，那么模型将具有非常低的召回率，因为我们仍然会有大量的假阴性。

因此，我们有一个精确召回权衡。我们希望两者都最大化，但最大化一个会最小化另一个。

我读过一个很好的解释:

> 回忆表达了在数据集中找到所有相关实例的能力，而精确表达了我们的模型所说的相关数据点实际上是相关的数据点的比例。

如果你碰巧在这个领域呆了很长时间，那么你一定知道最大化其中一个是视情况而定的。我们经常会遇到这样的数据集，我们要么需要最大化召回率，要么需要最大化精确度，而不考虑其他因素，因为这几乎没有区别。我能想到一些例子，但我不会深入细节，因为这不是我博客的目的。

为了得到精确召回情况的更“组合”的表达，我们考虑另一个称为 F1-score 的度量。

*   ***F1-Score:***F1-Score 是通过取召回率和准确率的调和平均值来组合召回率和准确率的度量。

F1 得分= 2*(召回率*精确度)/(召回率+精确度)

我们使用调和平均值而不是简单平均值，因为它会惩罚极值。精度为 1.0、召回率为 0.0 的分类器的简单平均值为 0.5，但 f 1 值为 0。F1 分数对这两个指标赋予了同等的权重，并且是一般 Fβ指标的一个具体示例，其中β可以调整为对召回率或精确度赋予更大的权重。
因此，如果我们想要一个平衡的分类模型，具有最优的召回率和准确率，那么我们试图最大化 F1 值。

F1 分数是 Fβ指标的一个特例，让我们看看一般情况。

*   ***Fβ-score:*** 它也是一个结合了召回率和准确率的指标，但通过给它们中的每一个赋予不同的权重来实现。
    它允许数据科学家更重视召回率或精确度。
    计算如下:

![](img/40e47317d9548ffd5a0717a111817f31.png)

最常用的β值是，β = 0.5，1 和 2。

*   ***特异性:*** 又称为*真阴性率。* 它测量被正确识别的实际底片的比例。

使用以下公式进行计算:

特异性= TN/(TN + FP)

特异性告诉我们的模型对于正确识别假(阴性)有多好。

*   ***假阳性率(FPR):*** 假阳性率计算为被错误分类为阳性(假阳性)的阴性事件数与实际阴性事件总数之比。

使用以下公式进行计算:

FPR = FP/(FP + TN)

因此，FPR 告诉我们，当实际值为负值(假)时，模型对数据的分类是多么错误。换句话说，如果我们只看负面(错误)，那么这个模型把它们归类为正面(正确)是多么错误，这就是 FPR。
也就是说，模型在多大比例下发出错误警报。

## 马修斯相关系数

到目前为止，我们一直在寻找不能单独用来描述模型稳健性的指标，但是如果我告诉你有一个指标可以“单独”完成这项工作呢？

许多科学家认为，对于任何二元分类器，MCC 是唯一最具信息量的度量。

MCC(就像其他指标一样)是使用 TN、FN、TP 和 FP 计算的。
MCC 不是一个有偏差的指标，也不够灵活，即使在高度不平衡的数据中也能正常工作。

MCC 返回一个介于-1 和+1 之间的值。
系数+1 表示完美预测，
系数 0 表示不比随机预测好，
系数 1 表示预测和观察完全不一致。

其计算方法如下:

![](img/1d3663dfcfa6b8a7bf3c3315804222d3.png)

## 结论

因此，我们已经讨论了相当多的指标来评估我们的模型，我们已经看到了准确性如何不是一个人应该考虑判断模型的唯一指标。

我希望这篇文章对你有用，如果你有任何疑问或建议，请写在评论区。

谢谢大家！！