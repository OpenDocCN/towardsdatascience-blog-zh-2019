<html>
<head>
<title>Understanding Logistic Regression</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">理解逻辑回归</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/understanding-logistic-regression-using-a-simple-example-163de52ea900?source=collection_archive---------2-----------------------#2019-05-05">https://towardsdatascience.com/understanding-logistic-regression-using-a-simple-example-163de52ea900?source=collection_archive---------2-----------------------#2019-05-05</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><figure class="is it gp gr iu iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi ir"><img src="../Images/d42420f67744ffbbbf67743434a99614.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*aaHoPgvq2JfxArsyRn7O6A.png"/></div></div></figure><div class=""/><div class=""><h2 id="232e" class="pw-subtitle-paragraph kb jd je bd b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks dk translated">通过简单的端到端示例建立直觉</h2></div><blockquote class="kt ku kv"><p id="9c30" class="kw kx ky kz b la lb kf lc ld le ki lf lg lh li lj lk ll lm ln lo lp lq lr ls im bi translated">如果你有兴趣运行我在这个分析中使用的代码，请查看我的<a class="ae lt" href="https://github.com/yiuhyuk/Basketball_Logit_Blog" rel="noopener ugc nofollow" target="_blank"> GitHub </a>。</p></blockquote><p id="af46" class="pw-post-body-paragraph kw kx je kz b la lb kf lc ld le ki lf lu lh li lj lv ll lm ln lw lp lq lr ls im bi translated">逻辑回归是进行分类的基本工具之一。作为一名未来的数据科学家，我希望做大量的分类工作。所以我想我更好地理解了逻辑回归在更深层次上的作用(不仅仅是来自 sklearn . linear _ model import logistic regression)。</p><p id="2b3e" class="pw-post-body-paragraph kw kx je kz b la lb kf lc ld le ki lf lu lh li lj lv ll lm ln lw lp lq lr ls im bi translated">下面的例子从头到尾介绍了一个非常基本的逻辑回归，这样我(希望你，读者)可以对它的工作原理有更多的直觉。</p></div><div class="ab cl lx ly hx lz" role="separator"><span class="ma bw bk mb mc md"/><span class="ma bw bk mb mc md"/><span class="ma bw bk mb mc"/></div><div class="im in io ip iq"><h1 id="4eff" class="me mf je bd mg mh mi mj mk ml mm mn mo kk mp kl mq kn mr ko ms kq mt kr mu mv bi translated">投篮篮</h1><p id="3ae9" class="pw-post-body-paragraph kw kx je kz b la mw kf lc ld mx ki lf lu my li lj lv mz lm ln lw na lq lr ls im bi translated">比方说，我想检查我的篮球投篮准确性和我投篮距离之间的关系。更确切地说，我想要一个模型，它以英尺为单位计算“离篮筐的距离”,并计算出我投篮的概率。</p><p id="1e2b" class="pw-post-body-paragraph kw kx je kz b la lb kf lc ld le ki lf lu lh li lj lv ll lm ln lw lp lq lr ls im bi translated">首先我需要一些数据。所以我出去从各种距离投篮，同时记录每个结果(1 表示成功，0 表示失败)。在散点图上绘制时，结果如下所示:</p><figure class="nc nd ne nf gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi nb"><img src="../Images/d376cfe6a3f60c651722c020571a0403.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*1pPTMg0Y_kg1lVxsF4bUGw.png"/></div></div></figure><p id="de78" class="pw-post-body-paragraph kw kx je kz b la lb kf lc ld le ki lf lu lh li lj lv ll lm ln lw lp lq lr ls im bi translated">一般来说，我离篮筐越远，投篮就越不准。因此，我们已经可以看到我们的模型的大致轮廓:当给定一个小距离时，它应该预测高概率，当给定一个大距离时，它应该预测低概率。</p><p id="1519" class="pw-post-body-paragraph kw kx je kz b la lb kf lc ld le ki lf lu lh li lj lv ll lm ln lw lp lq lr ls im bi translated">在高层次上，逻辑回归的工作方式很像传统的线性回归。因此，让我们从熟悉的线性回归方程开始:</p><blockquote class="ng"><p id="65cb" class="nh ni je bd nj nk nl nm nn no np ls dk translated"><strong class="ak"> <em class="nq"> Y = B0 + B1*X </em> </strong></p></blockquote><p id="8f71" class="pw-post-body-paragraph kw kx je kz b la nr kf lc ld ns ki lf lu nt li lj lv nu lm ln lw nv lq lr ls im bi translated">在线性回归中，输出<strong class="kz jf"> <em class="ky"> Y </em> </strong>与目标变量(您试图预测的事物)的单位相同。然而，在逻辑回归中，输出<strong class="kz jf"> <em class="ky"> Y </em> </strong>是对数概率。除非你花很多时间在体育博彩或赌场上，否则你可能对赔率不太熟悉。赔率只是事件发生概率的另一种表达方式，<strong class="kz jf"> <em class="ky"> P(事件)</em> </strong>。</p><blockquote class="ng"><p id="8f01" class="nh ni je bd nj nk nl nm nn no np ls dk translated"><strong class="ak"> <em class="nq">赔率= P(事件)/【1-P(事件)】</em> </strong></p></blockquote><p id="bfed" class="pw-post-body-paragraph kw kx je kz b la nr kf lc ld ns ki lf lu nt li lj lv nu lm ln lw nv lq lr ls im bi translated">继续我们的篮球主题，假设我投了 100 个罚球，投进了 70 个。基于这个样本，我罚球的概率是 70%。我罚球的几率可以计算为:</p><blockquote class="ng"><p id="e4d1" class="nh ni je bd nj nk nl nm nn no np ls dk translated"><strong class="ak"> <em class="nq">赔率= 0.70/(1–0.70)= 2.333</em></strong></p></blockquote><p id="d707" class="pw-post-body-paragraph kw kx je kz b la nr kf lc ld ns ki lf lu nt li lj lv nu lm ln lw nv lq lr ls im bi translated">因此，如果他们基本上告诉我们同样的事情，为什么麻烦呢？概率被限制在 0 和 1 之间，这成为回归分析中的一个问题。如下图所示，赔率范围从 0 到无穷大。</p><figure class="nc nd ne nf gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi nb"><img src="../Images/f36454b11f2f70cfa4dd1c5c8fa882e6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*7CHc798JLgar9m3bTpTfOQ.png"/></div></div></figure><p id="7605" class="pw-post-body-paragraph kw kx je kz b la lb kf lc ld le ki lf lu lh li lj lv ll lm ln lw lp lq lr ls im bi translated">如果我们取概率的自然对数，那么我们得到的对数概率是无界的(范围从负到正无穷大),并且在大多数概率上大致是线性的！由于我们可以通过逻辑回归估计对数概率，我们也可以估计概率，因为对数概率只是概率的另一种表述方式。</p><figure class="nc nd ne nf gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi nb"><img src="../Images/bd7bbb36365aef23a13ca0456b97c6d6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*eqnu4wL2PdLmtLqH2zmt_w.png"/></div></div><figcaption class="nw nx gj gh gi ny nz bd b be z dk">Notice that the middle section of the plot is linear</figcaption></figure><p id="0f43" class="pw-post-body-paragraph kw kx je kz b la lb kf lc ld le ki lf lu lh li lj lv ll lm ln lw lp lq lr ls im bi translated">我们可以写出我们的逻辑回归方程:</p><blockquote class="ng"><p id="70a9" class="nh ni je bd nj nk nl nm nn no np ls dk translated">z = B0+B1 *距离篮子</p><p id="d0ff" class="nh ni je bd nj nk nl nm nn no np ls dk translated">其中 Z = log(投篮命中率)</p></blockquote><p id="ef5c" class="pw-post-body-paragraph kw kx je kz b la nr kf lc ld ns ki lf lu nt li lj lv nu lm ln lw nv lq lr ls im bi translated">为了从对数赔率中的<strong class="kz jf"> <em class="ky"> Z、</em> </strong>得到概率，我们应用了 sigmoid 函数。应用<a class="ae lt" href="https://en.wikipedia.org/wiki/Sigmoid_function" rel="noopener ugc nofollow" target="_blank"> sigmoid 函数</a>是描述以下转换的一种奇特方式:</p><blockquote class="ng"><p id="a1da" class="nh ni je bd nj nk nl nm nn no np ls dk translated">投篮命中率= 1/[1+e^(-z]</p></blockquote><p id="d207" class="pw-post-body-paragraph kw kx je kz b la nr kf lc ld ns ki lf lu nt li lj lv nu lm ln lw nv lq lr ls im bi translated">既然我们已经了解了如何从对数赔率的线性估计到概率，那么让我们检查一下系数<strong class="kz jf"> <em class="ky"> B0 </em> </strong>和<strong class="kz jf"> <em class="ky"> B1 </em> </strong>在我们用来计算<strong class="kz jf"> <em class="ky"> Z </em> </strong>的逻辑回归方程中是如何实际估计的。这里有一些在幕后进行的数学计算，但是我将尽我所能用简单的英语解释它，这样你(和我)都可以对这个模型有一个直观的理解。</p></div><div class="ab cl lx ly hx lz" role="separator"><span class="ma bw bk mb mc md"/><span class="ma bw bk mb mc md"/><span class="ma bw bk mb mc"/></div><div class="im in io ip iq"><h1 id="8800" class="me mf je bd mg mh mi mj mk ml mm mn mo kk mp kl mq kn mr ko ms kq mt kr mu mv bi translated">成本函数</h1><p id="0b0f" class="pw-post-body-paragraph kw kx je kz b la mw kf lc ld mx ki lf lu my li lj lv mz lm ln lw na lq lr ls im bi translated">像大多数统计模型一样，逻辑回归寻求最小化成本函数。所以我们先来思考一下什么是成本函数。成本函数试图衡量你的错误程度。因此，如果我的预测是正确的，那么应该没有成本，如果我只是有一点点错误，应该有一个小成本，如果我是严重错误，应该有一个高成本。这在线性回归世界中很容易想象，因为我们有一个连续的目标变量(我们可以简单地将实际结果和我们的预测之间的差平方，以计算每个预测对成本的贡献)。但是这里我们处理的是一个只包含 0 和 1 的目标变量。不要绝望，我们可以做一些非常类似的事情。</p><p id="f80f" class="pw-post-body-paragraph kw kx je kz b la lb kf lc ld le ki lf lu lh li lj lv ll lm ln lw lp lq lr ls im bi translated">在我的篮球例子中，我从篮筐的正下方第一次投篮——也就是<strong class="kz jf"> <em class="ky">【投篮结果= 1 |距离篮筐= 0】</em></strong>。耶，我篮球打得并不差。我们如何将此转化为成本？</p><ul class=""><li id="bb8a" class="oa ob je kz b la lb ld le lu oc lv od lw oe ls of og oh oi bi translated">首先我的模型需要给出一个概率。假设它估计值为 0.95，这意味着它预计我 95%的投篮都是从 0 英尺外命中的。</li><li id="ff50" class="oa ob je kz b la oj ld ok lu ol lv om lw on ls of og oh oi bi translated">在实际数据中，我只从 0 英尺处拍摄了一次，所以我从 0 英尺处拍摄的实际(采样)精度是 100%。带上那个愚蠢的模特！</li><li id="f969" class="oa ob je kz b la oj ld ok lu ol lv om lw on ls of og oh oi bi translated">所以这个模型是错误的，因为根据我们的数据，答案是 100%，但它预测的是 95%。但是这只是一个小小的错误，所以我们只想罚一点点。这种情况下的惩罚是 0.0513(见下面的计算)。请注意，它与实际概率和预测的差值有多接近。还有，我要强调的是，这个误差不同于分类误差。假设默认截止值为 50%，该模型将正确预测 1(因为其预测值为 95% &gt; 50%)。但是这个模型不能 100%确定我会成功，所以我们对它的不确定性进行了一点惩罚。</li></ul><blockquote class="ng"><p id="6306" class="nh ni je bd nj nk oo op oq or os ls dk translated">-log(0.95) = 0.0513</p></blockquote><ul class=""><li id="0859" class="oa ob je kz b la nr ld ns lu ot lv ou lw ov ls of og oh oi bi translated">现在让我们假设我们建立了一个蹩脚的模型，它吐出的概率是 0.05。在这种情况下，我们大错特错，我们的代价是:</li></ul><blockquote class="ng"><p id="6a39" class="nh ni je bd nj nk oo op oq or os ls dk translated">-log(0.05) = 2.996</p></blockquote><ul class=""><li id="0c29" class="oa ob je kz b la nr ld ns lu ot lv ou lw ov ls of og oh oi bi translated">这个成本要高很多。模型非常确定我会错过，这是错误的，所以我们要强烈惩罚它；我们之所以能够做到这一点，要感谢我们采用了天然原木。</li></ul><p id="17bb" class="pw-post-body-paragraph kw kx je kz b la lb kf lc ld le ki lf lu lh li lj lv ll lm ln lw lp lq lr ls im bi translated">下面的曲线图显示了成本与我们的预测之间的关系(第一个曲线图描绘了当<strong class="kz jf"> <em class="ky">实际结果=1 </em> </strong>时，成本相对于我们的预测如何变化，第二个曲线图显示了当 A <strong class="kz jf"> <em class="ky">实际结果= 0 </em> </strong>时，成本如何变化)。</p><figure class="nc nd ne nf gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi nb"><img src="../Images/667df54fc7475cfc189a8cb55e3ceba6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Mij8dTgwA0P7fIiFr-W_xg.png"/></div></div></figure><figure class="nc nd ne nf gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi nb"><img src="../Images/117c04cc2f9529670d43268e2460989a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*UPq__aNaR9wzJJfBAvA6UQ.png"/></div></div></figure><p id="28cd" class="pw-post-body-paragraph kw kx je kz b la lb kf lc ld le ki lf lu lh li lj lv ll lm ln lw lp lq lr ls im bi translated">因此，对于给定的观察，我们可以将成本计算为:</p><ul class=""><li id="b4e5" class="oa ob je kz b la lb ld le lu oc lv od lw oe ls of og oh oi bi translated">如果<strong class="kz jf"> <em class="ky">实际结果= 1 </em> </strong>，那么<strong class="kz jf"> <em class="ky">成本= -log(pred_prob) </em> </strong></li><li id="aa7d" class="oa ob je kz b la oj ld ok lu ol lv om lw on ls of og oh oi bi translated">否则如果<strong class="kz jf"> <em class="ky">实际结果= 0 </em> </strong>，那么<strong class="kz jf"> <em class="ky">成本= -log(1-pred_prob) </em> </strong></li><li id="b22f" class="oa ob je kz b la oj ld ok lu ol lv om lw on ls of og oh oi bi translated">其中<strong class="kz jf"> <em class="ky"> pred_prob </em> </strong>是跳出我们模型的预测概率。</li></ul><p id="b768" class="pw-post-body-paragraph kw kx je kz b la lb kf lc ld le ki lf lu lh li lj lv ll lm ln lw lp lq lr ls im bi translated">对于我们的整个数据集，我们可以通过下式计算出<strong class="kz jf"> <em class="ky">总成本</em> </strong>:</p><ol class=""><li id="2a11" class="oa ob je kz b la lb ld le lu oc lv od lw oe ls ow og oh oi bi translated">使用上述程序计算每个观察的个体成本。</li><li id="2f0a" class="oa ob je kz b la oj ld ok lu ol lv om lw on ls ow og oh oi bi translated">将所有单项成本相加得到<strong class="kz jf"> <em class="ky">总成本</em> </strong>。</li></ol><p id="045a" class="pw-post-body-paragraph kw kx je kz b la lb kf lc ld le ki lf lu lh li lj lv ll lm ln lw lp lq lr ls im bi translated">这个<strong class="kz jf"> <em class="ky">总成本</em> </strong>是我们想要最小化的数字，我们可以通过<a class="ae lt" href="https://en.wikipedia.org/wiki/Gradient_descent" rel="noopener ugc nofollow" target="_blank">梯度下降</a>优化来实现。换句话说，我们可以运行优化来找到最小化总成本<strong class="kz jf"><em class="ky"/></strong>的<strong class="kz jf"> <em class="ky"> B0 </em> </strong>和<strong class="kz jf"> <em class="ky"> B1 </em> </strong>的值。一旦我们搞清楚了这一点，我们就有了我们的模型。激动人心！</p></div><div class="ab cl lx ly hx lz" role="separator"><span class="ma bw bk mb mc md"/><span class="ma bw bk mb mc md"/><span class="ma bw bk mb mc"/></div><div class="im in io ip iq"><h1 id="9223" class="me mf je bd mg mh mi mj mk ml mm mn mo kk mp kl mq kn mr ko ms kq mt kr mu mv bi translated">把这一切联系在一起</h1><p id="fae1" class="pw-post-body-paragraph kw kx je kz b la mw kf lc ld mx ki lf lu my li lj lv mz lm ln lw na lq lr ls im bi translated">综上所述，首先我们用最优化来搜索使我们的代价函数最小的<strong class="kz jf"> <em class="ky"> B0 </em> </strong>和<strong class="kz jf"> <em class="ky"> B1 </em> </strong>的值。这给了我们一个模型:</p><blockquote class="ng"><p id="6c35" class="nh ni je bd nj nk nl nm nn no np ls dk translated">Z = B0 + B1*X</p><p id="7b37" class="nh ni je bd nj nk nl nm nn no np ls dk translated">其中 B0 = 2.5，B1 = -0.2(通过优化确定)</p></blockquote><p id="5cab" class="pw-post-body-paragraph kw kx je kz b la nr kf lc ld ns ki lf lu nt li lj lv nu lm ln lw nv lq lr ls im bi translated">我们可以看一下我们的斜率，<strong class="kz jf"> <em class="ky"> B1 </em> </strong>，它衡量的是距离对我射击精度的影响。我们估计<strong class="kz jf">T5】B1T7 为-0.2。这意味着距离每增加 1 英尺，我投篮的几率就会减少 0.2。<strong class="kz jf"> <em class="ky"> B0 </em> </strong>，y 轴截距，值为 2.5。这是我从 0 英尺(就在篮筐旁边)投篮时，模型的对数赔率预测。通过 sigmoid 函数我们得到了 92.4%的预测概率。在下面的图中，绿点描绘了<strong class="kz jf"> <em class="ky"> Z </em> </strong>，我们预测的对数几率。</strong></p><figure class="nc nd ne nf gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi nb"><img src="../Images/4cd74f93b9cd1f531d319729b1ea97f0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*acHvl43B_zFQRfgWWU3U2g.png"/></div></div><figcaption class="nw nx gj gh gi ny nz bd b be z dk">Almost there!</figcaption></figure><p id="af8c" class="pw-post-body-paragraph kw kx je kz b la lb kf lc ld le ki lf lu lh li lj lv ll lm ln lw lp lq lr ls im bi translated">我们快完成了！由于<strong class="kz jf"> <em class="ky"> Z </em> </strong>是对数赔率，我们需要使用 sigmoid 函数将其转换成概率:</p><blockquote class="ng"><p id="5633" class="nh ni je bd nj nk nl nm nn no np ls dk translated">投篮命中率= 1/[1+e^(-z]</p></blockquote><p id="45d9" class="pw-post-body-paragraph kw kx je kz b la nr kf lc ld ns ki lf lu nt li lj lv nu lm ln lw nv lq lr ls im bi translated"><strong class="kz jf"> <em class="ky">投中概率，</em> </strong>我们所追求的最终输出在下图中用橙色的点来描绘。注意曲率。这意味着我的特征(距离)和我的目标之间的关系不是线性的。在概率空间中(不像对数赔率或线性回归)，我们不能说我投篮的距离和我投篮的概率之间有恒定的关系。相反，距离对概率的影响(连接橙色点的线的斜率)本身就是我目前站在离篮子多远的函数。</p><figure class="nc nd ne nf gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi nb"><img src="../Images/a9017ba8e945de7df3a1625b31e2c970.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*gTYL2fmfjpZnXAtQO403Kg.png"/></div></div><figcaption class="nw nx gj gh gi ny nz bd b be z dk">Nice! We have our probabilities now</figcaption></figure><p id="cbd4" class="pw-post-body-paragraph kw kx je kz b la lb kf lc ld le ki lf lu lh li lj lv ll lm ln lw lp lq lr ls im bi translated">希望这有助于你更好地理解逻辑回归(写它肯定帮助了我)。</p></div><div class="ab cl lx ly hx lz" role="separator"><span class="ma bw bk mb mc md"/><span class="ma bw bk mb mc md"/><span class="ma bw bk mb mc"/></div><div class="im in io ip iq"><p id="77f4" class="pw-post-body-paragraph kw kx je kz b la lb kf lc ld le ki lf lu lh li lj lv ll lm ln lw lp lq lr ls im bi translated">如果你总体上喜欢这篇文章和我的写作，请考虑通过我的推荐链接注册 Medium 来支持我的写作。谢谢！  </p></div></div>    
</body>
</html>