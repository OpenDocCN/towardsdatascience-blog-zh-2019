# 利用有限数据进行 Kaggle 图像分类的最新成功技术

> 原文：<https://towardsdatascience.com/latest-winning-techniques-for-kaggle-image-classification-with-limited-data-5259e7736327?source=collection_archive---------5----------------------->

## 关于如何防止模型在小数据集上过度拟合但仍能进行准确分类的教程

![](img/2b0ae5e88c3b8af18ae51756751802d5.png)

[http://www.dakanarts.com/13-black-white/](http://www.dakanarts.com/13-black-white/)

在本文中，我将介绍我在[课堂卡格尔挑战](https://www.kaggle.com/c/cs-ioc5008-hw1/overview)中使用的方法。我花了大约两周的时间进行挑战，最终提交分数为 **0.97115** ，在最终排行榜上名列第二。我从借用[的这篇文章](https://medium.com/neuralspace/kaggle-1-winning-approach-for-image-classification-challenge-9c1188157a86)开始，我也推荐这篇文章。

# 挑战攻略

提出的挑战是一个自然图像分类任务，有 **13** 和**类**。这项挑战的第一个困难是可用数据的稀缺:只有 3 859 张图像用于训练。挑战的规则是在训练中不使用外部数据。在数据很少的情况下，模型将更容易过度拟合，而不学习概括。

此外，由于这些图像处于**灰度**，它们包含的信息比 ImageNet 数据集等彩色图像少，因此彩色图像上的预训练模型不能直接应用于此任务。在进一步检查数据集时，许多类包含视觉上非常**相似**或包含相同元素的图像。混淆此类类别时，模型将失去准确性。

![](img/55160ad995d26dc7ff74a9dd15966c15.png)![](img/ee04c7819528b370194c65a77bd1149d.png)![](img/9e78021eb65f1be6aef63d6870dbe345.png)![](img/9a230f034f13bc14ac48d11c2fe1cf10.png)![](img/14e3898ad18c9959a1f0323a3c61a2f9.png)![](img/7c6dc09437265220dbfc4bbdd2a89583.png)

Some examples of images to classify

# 数据处理

首先，我们数据集中的图像并不都具有相同的尺寸，所以我们在将图像输入到模型之前，调整了所有图像的尺寸。一半以上的训练图像的尺寸为 256 x 256，因此我们将其他图像的尺寸调整或裁剪到这个尺寸。

![](img/58649c80644790e29f24bc9e508dfaf0.png)

我们还将应用**规范化**。最初，图像被表示为像素值范围从 0 到 255 的张量。我们简单地将每个值除以 255，以重新调整并获得神经网络首选的 0 到 1 之间的值。此外，我们将**对比度拉伸**应用于所有图像以增强图像。这将有助于模型更清楚地“看到”图像中的细节。

![](img/e75ec17562af344504a7b6ece7564b44.png)

这些类也是不平衡的，这意味着每个类之间的数据量不相等。这将使模型或多或少地偏向某些类。为了解决这个问题，我们人为地添加更多的图像，使得每个类都有与最大类一样多的图像。为了对小班进行**重采样**，我们在图像中随机裁剪一个区域来创建一个新样本。这是基于这样的假设，即裁剪后的图像将包含作为该类特征的相同元素。

![](img/7bcff74c96edd536484fd54346c43442.png)

最后，随着深度网络在大量训练数据的情况下表现和概括得更好，我们执行了**数据增强**。我们的目标是人为地创造出包含同类特征的新图像。为此，我使用的技术可以总结如下:

![](img/a84448674d4314c8155a248deb5ad14b.png)

在开始训练之前，我们将数据集分成训练集(80%)和验证集(20%)。除了仅在训练集上使用的图像增强之外，我们在两个集上都应用了上面讨论的所有处理技术。

# 迁移学习

因为我们的数据集包含的图像与 ImageNet 中的图像相似，所以我们将从一个已经在 ImageNet 上经过**预训练**的 CNN 模型开始。我们的想法是冻结预训练模型的较低层，这些模型可以捕捉通用特征，同时针对我们的特定领域对较高层进行微调。我们还重新定义了最后一层来输出 13 个值，每个类一个。

![](img/1c71e42e01c6fffe27acb549a635e9d6.png)

[ImageNet dataset samples](https://www.researchgate.net/figure/Examples-in-the-ImageNet-dataset_fig7_314646236)

PyTorch 提供了几种不同架构的预训练模型。其中， **ResNet18** 是我采用的架构，因为在运行了 5 个时期的各种架构后，它在对我们的数据进行训练时给出了最佳的验证准确性。在对不同数量的冷冻层进行实验后，发现 7 是最好的。我还使用了 **SGD 优化器**和**权重衰减**来阻止过度拟合。

# 学习率调度

为了进一步改善结果并使模型收敛到全局最小值，我们希望调整学习率。我选择使用**循环学习率调度**，而不是通过实验来确定最佳学习率。这种方法使得学习速率循环变化，从而使模型能够收敛和逃离几个局部极小值。它还消除了“手动”寻找最佳学习率的需要。

![](img/400bdf429414b7d681337c998e41b603.png)

# 快照集成

**集成方法**在提高模型整体性能方面非常强大。然而，为集成学习分别训练几个不同的模型在计算上也是昂贵的。这就是我选择使用**快照集合**和循环 LR 调度的原因。

快照集合在训练期间定期保存模型的参数**。想法是在循环 LR 调度期间，模型收敛到不同的局部最小值。因此，通过在不同的局部最小值保存模型参数，我们获得了一组模型，这些模型可以为我们的预测提供不同的见解。这使得我们可以在一个**单一训练周期**中集合一群模型。**

**![](img/0713a98387c5ed6d08225fbeae242219.png)**

**[https://arxiv.org/abs/1704.00109](https://arxiv.org/abs/1704.00109)**

**对于每个图像，我们连接每个“快照”模型的分类概率预测以形成新的数据点。这个新数据然后被输入到一个 **XGBoost** 模型中，根据快照模型给出一个预测。**

# **子类决策**

**在检查单个模型的验证集上的混淆矩阵时，我们发现它经常将一个类与相同的另一个类混淆。事实上，我们发现**的三个子类**经常被混淆在一起:**

*   **【房间】:卧室、厨房、客厅、办公室**
*   **“自然”:海岸、森林、山脉、野外、公路**
*   **“城市”:城市、街道、高楼**

**![](img/cc62bf72c5064e7b7b6b5afac351f770.png)**

**此外，该模型已经非常善于区分这些子类(并找到郊区)。要获得良好的性能，剩下的就是让模型准确地识别子类中的分类。**

**为此，我们使用与之前相同的方法，在每个子类上训练三个新的独立模型。有些类的训练数据很少，所以我们增加数据扩充量。我们还发现了针对每个子类调整的新参数。**

**在预测过程中，我们首先使用在整个数据集上训练的模型。然后，对于得到的每个预测，如果类概率低于某个阈值，我们取相关子类模型预测的类来代替。**

# **抗锯齿**

**大多数现代卷积网络，如 ResNet18，都不是移位不变的。网络输出可能会随着输入的微小偏移或转换而发生剧烈变化。这是因为卷积网络中的跨步操作忽略了奈奎斯特采样定理和混叠，从而破坏了移位等方差**。****

**我决定应用最近于 2019 年 4 月发表的论文[中提出的反走样方法](https://arxiv.org/abs/1904.11486)。这是通过在网络的卷积层之后简单地添加“模糊池”层来实现的，即模糊滤波器和子采样层。这种方法已被证明改善了图像的不同偏移之间的分类一致性，并且由于更好的概括而具有更高的分类准确度。**

**![](img/5d43a1f7a652c6fc7e946bf63d626d05.png)**

**[https://arxiv.org/abs/1904.11486](https://arxiv.org/abs/1904.11486)**

**我使用预训练的抗锯齿 ResNet18 模型来微调挑战的数据集。通过反走样，我希望通过将模型推广到图像平移和移动来克服由于数据匮乏而导致的过度拟合。**

**如果你想更多地了解这种反走样方法，我在这里更详细地解释了“让卷积网络再次保持平移不变”这篇文章:**

**[](/https-towardsdatascience-com-making-convolutional-networks-shift-invariant-again-f16acca06df2) [## 使卷积网络再次保持平移不变

### 现代卷积网络有什么问题，如何修复？如果你使用 CNN，你可能想读这个。

towardsdatascience.com](/https-towardsdatascience-com-making-convolutional-networks-shift-invariant-again-f16acca06df2) 

# 结果摘要

所用的方法可总结如下:

![](img/21f132fbc01648f0b5b9e3f4db886e97.png)

对 ResNet18 模型进行 5 个时期的数据微调，除了调整大小之外不进行任何处理，已经给出了 0.91442 的测试精度。这揭示了**迁移学习**的显著效率——用很少的数据和计算，该模型已经可以在相关任务上表现出良好的性能。

加上数据扩充和 10 个历元的较长训练，我们得到的测试精度为 **0.93076** 。这证实了拥有**大型训练数据集**和增强技术**可扩展性**的重要性。

增加**类平衡**和**学习率调度**，测试精度上升到 **0.94230** 。此外，混淆矩阵表明，平衡后，该模型以更高的精度预测代表性不足的类别。这也说明了学习率是模型收敛的一个重要参数。

然后，通过在所有数据上训练的模型上的**快照集合**，测试精度提高到 **0.95000** 。这说明了循环 LR 调度如何允许我们通过单个训练循环获得具有不同行为的模型，并且 XGBoost 元学习器可以从它们的预测中提取有用的信息。

通过**对比拉伸**所有图像以及特定子类上的训练模型并结合它们的预测，测试精度上升到 **0.95865** 。混淆矩阵显示了子类内精确分类的改进，特别是对于“城市”子类。开发在某些类上是“专家”的模型，并将它们与善于区分子类的模型一起使用，被证明是非常有效的。

最后，在**反走样**resnet 18 网络并结合训练集和验证集使用所有可用于训练的标注数据后，测试精度上升到 **0.97115** 。反走样是提高泛化能力的有力手段，在图像数据有限的情况下尤为重要。

![](img/369f4592bb5a3bfd0c48b27fbd969b9f.png)

Yay!

# 其他想法

以下是我为应对这一挑战而想出的一些其他主意，它们要么效果不好，要么我没有办法去尝试。

## 单通道图像

这些图像是灰度的，所以尽管它们在加载时被编码成三个通道，但它们可以被表示为单通道矩阵。我的想法是，这种降维可以加速训练，同时保留所有必要的信息，但通过实验，这种方法显示出在没有显著加速训练的情况下损失了准确性。

## 其他集成方法

我还尝试对通过其他方式检索的模型进行集成，例如在不同处理方法(有/没有类别平衡、不同图像增强技术、不同数据增强方法)之后对图像进行训练的模型，但是这些方法计算量更大，并且不能提供明显更好的准确性。

## 生成对抗网络

如前所述，数据扩充和类平衡在模型性能中起着关键作用。除了经典的图像处理，生成模型可以单独用于合成带注释的数据。例如，DAGAN 模型可用于数据扩充，而 BAGAN 可用于平衡。

## 灰度图像网络预训练

所提供的数据集中的图像具有与组成 ImageNet 数据集的自然图像相似的内容，不同之处在于我们的图像是黑白的。因此，在灰度图像上预先训练的模型将更适合于这个任务。

## 人工图像彩色化

如果我不能获得灰度图像的预训练模型，我的下一个想法是人工给图像着色，希望增加额外的信息。人工图像着色的预训练模型确实存在，并且是公开可用的，如果你尝试这种方法，请告诉我！** 

**感谢阅读，我希望你喜欢这篇文章！你可以在 GitHub 上找到我的方法的完整代码。**