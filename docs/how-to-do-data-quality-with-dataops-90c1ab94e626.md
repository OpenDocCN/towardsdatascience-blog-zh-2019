# 如何使用 DataOps 提高数据质量

> 原文：<https://towardsdatascience.com/how-to-do-data-quality-with-dataops-90c1ab94e626?source=collection_archive---------16----------------------->

## 利用数据测试和安全环境使数据质量成为接触数据的每个人的日常活动

![](img/d54aa249c133ea33967e3b4c7d1e9c97.png)

Image Source: [Pixbay](https://pixabay.com/photos/businessman-quality-control-quality-3075839/)

# 坏数据的代价

数据质量差的成本如此之高，以至于许多人难以相信这些统计数据。Gartner 估计，由于数据质量差，[平均每个组织每年都会损失](https://www.gartner.com/smarterwithgartner/how-to-stop-data-quality-undermining-your-business/)1500 万美元。对于一些组织来说，这甚至是致命的。我经常想起我的数据科学创新峰会共同主持人、来自多米诺数据实验室的[丹·恩托文讲的一个故事，关于一家高频交易公司](https://www.linkedin.com/in/enthoven)[骑士资本](https://dealbook.nytimes.com/2012/08/02/knight-capital-says-trading-mishap-cost-it-440-million/)，他们在没有测试其效果的情况下部署了一个错误的算法更新。一天之内，该公司就自动取走了几乎所有的资本，并不得不策划向另一家公司的紧急出售。

他还提到一家信用卡公司未能验证来自第三方提供商的 FICO 信用评分字段。当该公司后来更换提供商时，新的提供商显示“无信用”，非法值为 999 (850 是最高合法值)。因为没有适当的数据质量检查，他们的自动批准算法开始批准这些具有巨大信贷限额的申请，导致重大损失。

# DataOps 确保保持数据质量

在之前的一篇文章中，我[讨论了向数据操作](/the-rise-of-dataops-from-the-ashes-of-data-governance-da3e0c3ac2c4)的深刻转变，这将改变数据管理的方式。就在最近，我们获得了大规模重复版本和复制数据的能力，这将使我们能够从应用于数据系统的流程和控制(即控制委员会会议)转向系统内的保证。将受到影响的数据治理的关键要素之一是数据质量管理，它将从分配给试图在数据被破坏后“清理”数据的数据管理员的任务转移到产生数据的组织内所有开发活动的一部分。

## 首先是几个定义，这样我们就在同一页上了:

在我们开始之前，最好给出一些将在本文中使用的定义(因为我们正在讨论数据质量，所以最好是精确的):

**数据源** —随着时间的推移生成数据并使该数据作为数据实体可供消费的任何东西。可能是运营应用程序、精细数据仓库、第三方 API、传感器等。

**数据产品** —满足特定需求的数据实体，通常通过转换和组合来自数据源的数据而产生

**数据管道** —一系列的转换，在这些转换中，数据从数据源流入，从数据源流出，进入数据产品

**数据定义** —描述特定数据实体的元数据。该定义应该使数据消费者能够在没有额外输入的情况下使用数据实体。它通常包括实体的位置、模式和格式，以及每个字段的描述和约束。

# 数据质量是每个人工作的一部分

同步的另一个重要定义是您组织中使用数据产生见解的广泛人群。我称他们为数据产品创造者。他们可能来自各种背景，通常拥有数据分析师、数据工程师或数据科学家的头衔。每一个都将遵循稍微不同的开发过程，并且可能使用不同的工具集。然而，他们都应该有责任维护和提高数据质量。

![](img/efbf6c791fa31f1323711a60e3e51f6e.png)

The 3 types of Data Product Creators all have data quality responsibilities

为了将数据质量从事后数据管家操作转移到日常生活中，所有接触数据的角色都必须参与到保持测试最新的过程中，以保持数据的整洁。这意味着所有创建数据产品的角色都必须考虑通常分配给数据管理员的任务。这并不意味着数据管理员的角色应该完全消失，因为组织中仍然有大量的数据源和数据集没有进行积极的开发。

# 数据操作和测试驱动的开发

编译器需要比它们编译的代码更健壮。鉴于数据管道代码实际上只是将数据编译成数据产品，并且在编写代码时数据本身不受您的控制，您的数据管道代码应该足够健壮以处理任何可能的数据场景。当构建库代码时，软件开发人员通常利用像[微软 Intellitest](https://docs.microsoft.com/en-us/visualstudio/test/intellitest-manual/getting-started?view=vs-2019) 这样的工具来生成考虑到所有可能的输入场景的测试输入。

> “我们希望管道所有者将模式视为与源代码同等的生产资产，并采用最佳实践来审查、版本化和维护模式。”—谷歌数据工程

在 DataOps 中，当开发使用数据作为输入的新代码(即数据管道代码)时，数据定义(即可能值的模式和规则集)必须准确表示输入数据的预期约束。为了引导这个过程，像 [Great Expectations](https://github.com/great-expectations/great_expectations) 这样的库可以用来从示例数据中生成数据定义的约束。从那里，数据工程师或分析师可以修改和添加额外的约束。接下来，一个数据模糊库，比如谷歌的 [LibFuzz 结构化模糊库](https://github.com/google/fuzzing/blob/master/docs/structure-aware-fuzzing.md#example-protocol-buffers)或 [Faker](https://faker.readthedocs.io/en/latest/index.html) ，可以用来基于数据定义中的约束生成潜在的数据输入。基于这些测试产生的失败，输入有助于强化处理代码和数据定义。关于谷歌使用的实践的更多细节可以在本文中找到[。大多数情况下，这种能力揭示了使数据定义更清楚地了解什么是可能的所需的更新，但有时它也揭示了可能破坏数据管道的代码错误。](https://blog.acolyer.org/2019/06/05/data-validation-for-machine-learning/)

数据测试和代码测试有许多共同的特点。这些测试被提交到源代码控制中，并且可以作为持续集成过程的一部分运行，使用像 Jenkins 或 Circle CI 这样的工具，测试的覆盖率可以根据样本数据集进行测量。然而，数据测试在一个重要方面有所不同:如果它们失败了，就会留下坏数据需要清理。在传统的数据开发架构中，确保数据管道真正工作的唯一方法。因此，在创建测试以评估数据质量时，数据产品创建者应该在安全的开发环境中工作，使用 DataKitchen 所谓的[修复架构的权利](https://medium.com/data-ops/the-right-to-repair-data-architecture-with-dataops-48ea79361f2c)。这允许他们创建或修改数据产品，而不会将坏数据引入生产中。

![](img/45b31dd0e356e2b4480a32e02ec669fd.png)

在许多情况下，测试变得更加困难，因为交付的数据产品只是生成它们的数据输入的表示(例如填充仪表板的图表和图形)。在这种情况下，很难编写基于代码的单元测试来为数据集指定完整的约束集。因此，这组测试通常确保管道不会以意外的方式中断，但不能保证数据是高质量的。这与编译器不检查代码中的业务逻辑缺陷非常相似。在敏捷软件开发中，编码人员必须与产品负责人一起工作，为要接受的特性定义测试。在数据产品开发中，数据所有者应该能够指定他们在数据中期望的条件，而不需要太复杂的编码。

## 数据定义和持续集成

这样，数据质量的定义就成为数据定义的内在内容:

1.  数据定义被视为一级代码:版本化、测试和发布
2.  在合并或混合多个输入的流水线步骤中，输入被指定为一个组，允许为输入数据之间的关系编写测试。
3.  当数据加载到生产中的数据平台时，会根据数据定义对数据进行检查。这些检查可用于将统计过程控制应用于运行平台。

通过结合这些原则，团队可以保证在接收时捕获数据问题。

![](img/42ec57759769f51cba73784260a95139.png)

The data validation procedure in use at Google, from: [Data validation for machine learning](https://www.sysml.cc/doc/2019/167.pdf)

# 调试问题和根本原因自动化

在任何系统中，最终用户都会发现一些问题。在自助服务的世界里，我们希望数据消费者能够快速、轻松地报告他们正在利用的数据产品的问题。仅仅能够报告问题，并为其他数据消费者记录这些问题并不能建立信任。对于数据所有者来说，快速确定根本原因并解决问题非常重要。然而，众所周知，诊断数据问题既困难又耗时。出现的问题是:

1.  **What** :问题是由代码中的错误还是来源处的错误输入数据引起的？
2.  **哪里**:如果是一个代码错误，这个问题是在管道的哪个阶段引入的？
3.  **如何**:如果是源问题，我们对源数据的理解是否正确？
4.  谁:如果是源问题，用户是否贡献了其他不良数据？
5.  **多大**:还有哪些数据产品使用同样的不良输入数据(因此也是不正确的)？
6.  **When** :在哪个时间点引入了数据问题(存在多少其他类似的坏数据)？

有了数据和管道代码版本控制，以及针对管道中的数据持续运行的测试，我们可以更快地回答这些问题。

有了 DataOps 基础，就可以系统地获得上述根本原因(什么、哪里和如何)问题的答案。详细的数据沿袭允许我们利用以下过程:

1.  与数据消费者合作，了解他们的期望
2.  更新数据产品定义以包含这些期望
3.  产生一个违背期望的数据测试(潜在地利用模糊测试工具来帮助这个过程)
4.  确定导致测试失败的特定数据输入，并确定它们是否保证数据定义更新，因为它们是不现实的
5.  如果数据输入是真实的，返回到管道中的前一阶段，并为新的输出预期添加测试
6.  继续向后移动并添加测试，直到您发现输出中的问题与一组特定的输入无关。在这种情况下，有问题的管道阶段是问题的根本原因。
7.  如果到达了管道的数据源，那么源数据就是问题所在，您需要适当地丢弃管道中的数据。

由此，可以使用数据分析来确定数据问题是何时出现的。源数据上的元数据可用于确定谁导致了问题，而谱系图可以通过从数据问题的来源到其他受影响的数据产品来回答问题有多严重。

## 数据问题文档和解决方案

数据谱系图还为我们提供了通知受检测到的数据问题影响的数据产品的所有消费者的能力。考虑下面的高等教育注册场景，其中有多个数据管道来利用注册指标来帮助进行预算和营销。基于各种中间数据产品之间的谱系图，一旦在管道中检测到问题，系统就可以自动警告下游消费者。类似的警报模式可用于多种类型的问题(该图显示了作业失败和运行缓慢的作业中的 3 个示例问题)。这些警报允许数据消费者确定他们是否应该使用受影响的数据产品(仪表板、应用程序等)。)，或者等待修复。

![](img/c2a5465514f4204f08223e389f630dc5.png)

此外，谱系图可用于在系统中传播数据质量文档。当检测到上面显示的任何数据质量问题时，它可以自动添加为数据目录中数据定义的注释。然后，质量问题可以传播到所有下游数据产品，允许任何其他数据产品创建者了解他们正在使用的数据源中存在的数据质量问题。

![](img/db1bdcc999d6a0957ec97326cdf58b57.png)

这种质量问题的延续也会在没有应用校正代码的记录的元数据中记录下来。然后，当在数据管道内应用修复来纠正坏的源数据时，该修复可以传播到元数据，并且可以从源和受影响的数据定义中移除数据质量注释。