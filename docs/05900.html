<html>
<head>
<title>A FaceNet-Style Approach to Facial Recognition on the Google Coral Development board</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">Google Coral 开发板上的一种 FaceNet 风格的面部识别方法</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/a-facenet-style-approach-to-facial-recognition-dc0944efe8d1?source=collection_archive---------6-----------------------#2019-08-28">https://towardsdatascience.com/a-facenet-style-approach-to-facial-recognition-dc0944efe8d1?source=collection_archive---------6-----------------------#2019-08-28</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><figure class="gl gn jo jp jq jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi jn"><img src="../Images/f2a0679b879a27155f6b553e9a6ea457.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*OmFw4wZx5Rx3w4TpB7hS-g.png"/></div></div></figure><h1 id="a5f1" class="jy jz iq bd ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv bi translated">介绍</h1><p id="1de4" class="pw-post-body-paragraph kw kx iq ky b kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt ij bi translated">在这篇博文中，我们介绍了面部识别的主题，并描述了我们对之前<a class="ae lu" href="https://medium.com/@pietraferreira/facial-recognition-on-the-new-google-coral-development-board-34efc4375691" rel="noopener">博文</a>中介绍的问题的解决方法。</p><p id="fdb8" class="pw-post-body-paragraph kw kx iq ky b kz lv lb lc ld lw lf lg lh lx lj lk ll ly ln lo lp lz lr ls lt ij bi translated">当决定实现面部识别时，首先想到的是 FaceNet。FaceNet 是一个人脸识别管道，它学习从人脸到多维空间中一个位置的映射，其中点之间的距离直接对应于人脸相似性的度量。</p><p id="a34f" class="pw-post-body-paragraph kw kx iq ky b kz lv lb lc ld lw lf lg lh lx lj lk ll ly ln lo lp lz lr ls lt ij bi translated">以下摘自 FaceNet <a class="ae lu" href="https://arxiv.org/abs/1503.03832" rel="noopener ugc nofollow" target="_blank">的论文</a>给出了其主要概念的概述:</p><p id="b588" class="pw-post-body-paragraph kw kx iq ky b kz lv lb lc ld lw lf lg lh lx lj lk ll ly ln lo lp lz lr ls lt ij bi translated"><em class="ma">“[……]我们致力于从图像 x 到特征空间的嵌入 f(x)，使得独立于成像条件，相同身份的所有人脸之间的平方距离很小，而来自不同身份的一对人脸图像之间的平方距离很大。</em></p><p id="8ce7" class="pw-post-body-paragraph kw kx iq ky b kz lv lb lc ld lw lf lg lh lx lj lk ll ly ln lo lp lz lr ls lt ij bi translated">这允许一个身份的面孔生活在一个流形上，同时仍然加强了与其他身份的距离和区分度。”</p><p id="a2f4" class="pw-post-body-paragraph kw kx iq ky b kz lv lb lc ld lw lf lg lh lx lj lk ll ly ln lo lp lz lr ls lt ij bi translated">FaceNet 的 TensorFlow 实现目前在<a class="ae lu" href="https://github.com/davidsandberg/facenet" rel="noopener ugc nofollow" target="_blank"> GitHub </a>上可用。</p><p id="4813" class="pw-post-body-paragraph kw kx iq ky b kz lv lb lc ld lw lf lg lh lx lj lk ll ly ln lo lp lz lr ls lt ij bi translated">基于之前在 FaceNet 上的工作，我们的解决方案分为三个阶段:</p><p id="5253" class="pw-post-body-paragraph kw kx iq ky b kz lv lb lc ld lw lf lg lh lx lj lk ll ly ln lo lp lz lr ls lt ij bi translated">1.<strong class="ky ir">预处理</strong> —一种用于获取一组图像并将其全部转换为统一格式的方法——在我们的例子中，是一个仅包含人脸的正方形图像。当使用边缘 TPU 时，由于我们的计算资源有限，因此统一数据集有助于减少训练时的方差。<br/> 2。<strong class="ky ir">嵌入</strong> —这是一个过程，是 FaceNet 工作方式的基础，它在多维空间中学习人脸的表示，其中距离对应于人脸相似性的度量。<br/> 3。<strong class="ky ir">分类</strong> —使用嵌入过程给出的信息来分离不同人脸的最后一步。</p><p id="e324" class="pw-post-body-paragraph kw kx iq ky b kz lv lb lc ld lw lf lg lh lx lj lk ll ly ln lo lp lz lr ls lt ij bi translated">我们还想实现的另一个功能是重量印记。权重印记是一种将训练过程分为两步的方法，第一步在大型数据集上训练整个模型，第二步仅在新数据上训练最后一层，同时利用前一步中获得的知识。重量印记允许在设备上进行学习，只需要很少的样本图像。它可以学习从未见过的人脸的内在属性，并将这些属性与它从已知数据集学习到的属性进行比较。</p><h1 id="9443" class="jy jz iq bd ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv bi translated">我们解决方案的架构</h1><p id="2850" class="pw-post-body-paragraph kw kx iq ky b kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt ij bi translated">鉴于我们前面描述的三个阶段，我们为我们的具体实现构建了一个架构，并考虑了在 Edge TPU 上实现它的实用性。</p><p id="61c5" class="pw-post-body-paragraph kw kx iq ky b kz lv lb lc ld lw lf lg lh lx lj lk ll ly ln lo lp lz lr ls lt ij bi translated">该架构将使用以下方法:</p><p id="1158" class="pw-post-body-paragraph kw kx iq ky b kz lv lb lc ld lw lf lg lh lx lj lk ll ly ln lo lp lz lr ls lt ij bi translated">1.使用对齐脚本进行预处理；<br/> 2。训练深度 Mobilenet 模型以识别人脸，然后在表示嵌入的层将其分割；<br/> 3。附加单层分类模型并使用权重印记来训练它。</p><h1 id="f63c" class="jy jz iq bd ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv bi translated">对准</h1><p id="1430" class="pw-post-body-paragraph kw kx iq ky b kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt ij bi translated">训练和推理过程的第一步都是对齐图像。这将总是发生在除了 Edge TPU 之外的机器上，因为 Edge TPU 环境不支持所需的库。我们目前正在运行来自<a class="ae lu" href="https://github.com/davidsandberg/facenet/blob/master/src/align/align_dataset_mtcnn.py" rel="noopener ugc nofollow" target="_blank"> Facenet GitHub 库</a>的<strong class="ky ir"> align_dataset_mtcnn.py </strong>脚本。</p><p id="292b" class="pw-post-body-paragraph kw kx iq ky b kz lv lb lc ld lw lf lg lh lx lj lk ll ly ln lo lp lz lr ls lt ij bi translated">通过执行脚本，我们可以指定面部缩略图的大小，并对齐它们。</p><p id="507a" class="pw-post-body-paragraph kw kx iq ky b kz lv lb lc ld lw lf lg lh lx lj lk ll ly ln lo lp lz lr ls lt ij bi translated">这一步对于确保数据集中的一致性非常重要。如果没有这种一致性，模型将不得不学习对同一张脸的图像之间存在不必要差异的数据集进行分类。一个强大到足以做到这一点的模型对于第一次尝试在 TPU 边缘实现某些东西来说可能太复杂了。</p><p id="bf58" class="pw-post-body-paragraph kw kx iq ky b kz lv lb lc ld lw lf lg lh lx lj lk ll ly ln lo lp lz lr ls lt ij bi translated">在我们的例子中，为了处理图像，我们必须在服务器上运行脚本，因为本地机器需要大量的时间。<br/>执行的命令是:</p><pre class="mb mc md me gt mf mg mh mi aw mj bi"><span id="2a23" class="mk jz iq mg b gy ml mm l mn mo">for N in {1..20}; do \<br/>python3 src/align/align_dataset_mtcnn.py \<br/>—image_size 182 \<br/>—margin 44 \<br/>—random_order \<br/>—gpu_memory_fraction 0.05 \<br/>&amp; done</span></pre><p id="de2e" class="pw-post-body-paragraph kw kx iq ky b kz lv lb lc ld lw lf lg lh lx lj lk ll ly ln lo lp lz lr ls lt ij bi translated">在一台 20 核服务器上，我们花了大约 30 分钟来对齐包含数十万张图像的 CASIA Webface 数据集。相比之下，我们预计在 MacBook Pro 上运行类似的脚本至少需要 2.5 小时。</p><h1 id="11b0" class="jy jz iq bd ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv bi translated">把...嵌入</h1><p id="5256" class="pw-post-body-paragraph kw kx iq ky b kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt ij bi translated">与对齐相反，嵌入和分类旨在在边缘 TPU 上运行。</p><p id="1638" class="pw-post-body-paragraph kw kx iq ky b kz lv lb lc ld lw lf lg lh lx lj lk ll ly ln lo lp lz lr ls lt ij bi translated">嵌入模型是卷积层的串联，它寻找特征并将它们映射到多维空间。为了获得我们的嵌入层，我们从 MobileNet 模型的预训练版本开始——我将在下一篇文章中详细介绍——并重新训练它。值得注意的是，我们使用了整个模型，这意味着它既创建了嵌入，也对它们进行了分类。然而，该模型随后被分割，因此我们可以使用其输出(嵌入)作为单一层分类模型的输入。</p><p id="515d" class="pw-post-body-paragraph kw kx iq ky b kz lv lb lc ld lw lf lg lh lx lj lk ll ly ln lo lp lz lr ls lt ij bi translated">为了进行训练，我们使用了<strong class="ky ir">mobilenet _ v1 _ L2 norm _ train . py</strong>脚本，该脚本将 TFRecord 格式的数据集和检查点作为输入，这些都是预训练模型提供的。</p><p id="4feb" class="pw-post-body-paragraph kw kx iq ky b kz lv lb lc ld lw lf lg lh lx lj lk ll ly ln lo lp lz lr ls lt ij bi translated">然后，我们必须保存模型的一个<strong class="ky ir"> GraphDef </strong> *并冻结图形。我们通过训练时创建的新检查点实现了这一点。重要的是，与我们之前描述的面网分类器相比，我们还去除了 L2 范数算子，因为它不受边缘 TPU 的支持。</p><p id="aa2b" class="pw-post-body-paragraph kw kx iq ky b kz lv lb lc ld lw lf lg lh lx lj lk ll ly ln lo lp lz lr ls lt ij bi translated">为了冻结图表，我们使用了 Tensorflow 工具<strong class="ky ir"> freeze_graph </strong>，这是一个简单的程序，只需要训练后的检查点。通过使用<strong class="ky ir">转换图</strong>工具，将冻结图作为输入，该模型去除了 L2 范数算子。</p><p id="5d6c" class="pw-post-body-paragraph kw kx iq ky b kz lv lb lc ld lw lf lg lh lx lj lk ll ly ln lo lp lz lr ls lt ij bi translated">*更多关于 Tensorflow 中图形对象的信息可以在<a class="ae lu" href="https://www.tensorflow.org/guide/extend/model_files#graphdef" rel="noopener ugc nofollow" target="_blank">这里</a>找到。</p><h1 id="2fc8" class="jy jz iq bd ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv bi translated">分类</h1><p id="d976" class="pw-post-body-paragraph kw kx iq ky b kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt ij bi translated">对于分类，我们必须将模型分成两部分——嵌入提取器和分类层——然后将它们重新连接起来。</p><p id="c602" class="pw-post-body-paragraph kw kx iq ky b kz lv lb lc ld lw lf lg lh lx lj lk ll ly ln lo lp lz lr ls lt ij bi translated">这种分离的原因是，如前所述，我们计划使用嵌入作为单层分类模型的输入。这一步确保了我们能够使用权重印记，这意味着该模型将能够在有限的数据集(大约 5 到 10 张图像)上训练(在 TPU 边缘)，以识别一张从未见过的脸。</p><p id="afa2" class="pw-post-body-paragraph kw kx iq ky b kz lv lb lc ld lw lf lg lh lx lj lk ll ly ln lo lp lz lr ls lt ij bi translated">为了实现这一点，我们首先使用<strong class="ky ir"> tflite_convert </strong>将整个冻结的图形转换为一个 TFLite 文件，它接受 GraphDef 文件并输出一个 tflite 文件。<br/>由于<strong class="ky ir"> tflite_convert </strong>不支持<strong class="ky ir">，我们随后使用<a class="ae lu" href="https://github.com/tensorflow/tensorflow/tree/master/tensorflow/lite/toco" rel="noopener ugc nofollow" target="_blank"> <strong class="ky ir"> toco </strong> </a>创建了基础图作为其自己的文件。tflite </strong>文件作为输入。</p><p id="a5d4" class="pw-post-body-paragraph kw kx iq ky b kz lv lb lc ld lw lf lg lh lx lj lk ll ly ln lo lp lz lr ls lt ij bi translated">由此，我们有了与分类层完全分离的嵌入提取器。然后，我们使用<strong class="ky ir"> toco </strong>创建头部图，然后使用 Edge TPU 编译器编译基础图。</p><p id="29fa" class="pw-post-body-paragraph kw kx iq ky b kz lv lb lc ld lw lf lg lh lx lj lk ll ly ln lo lp lz lr ls lt ij bi translated">最后一步是使用谷歌的<strong class="ky ir"> join_tflite_models </strong>工具重新连接编译好的基础图和头部图。</p><h1 id="5b4d" class="jy jz iq bd ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv bi translated">摘要</h1><p id="5a52" class="pw-post-body-paragraph kw kx iq ky b kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt ij bi translated">我们从分析 FaceNet 论文开始，提出了面部识别系统的三步计划:预处理、嵌入和分类。</p><p id="50b6" class="pw-post-body-paragraph kw kx iq ky b kz lv lb lc ld lw lf lg lh lx lj lk ll ly ln lo lp lz lr ls lt ij bi translated">为了进行预处理，我们使用了服务器上的 FaceNet git 存储库中的一个脚本。然后，我们在我们选择的数据集上重新训练了一个预训练模型，并冻结了它的图形。最后，我们将模型分为一个基础(嵌入)和一个头(分类)以允许我们稍后进行权重印记。然后，我们应该有一个在我们选择的数据集上训练的工作编译模型。</p></div></div>    
</body>
</html>