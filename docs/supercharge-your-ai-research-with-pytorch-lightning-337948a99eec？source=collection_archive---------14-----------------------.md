# Pytorch é—ªç”µçš„ 36 ç§æ–¹å¼å¯ä»¥å¢å¼ºä½ çš„äººå·¥æ™ºèƒ½ç ”ç©¶

> åŸæ–‡ï¼š<https://towardsdatascience.com/supercharge-your-ai-research-with-pytorch-lightning-337948a99eec?source=collection_archive---------14----------------------->

![](img/0fd284f34ef3a05eef9e73dd5b5718e9.png)

Come at me AGI

AGI ä¸ä¼šè‡ªå·±è§£å†³é—®é¢˜(åœ¨å†…å¿ƒæ·±å¤„ä½ çŸ¥é“æˆ‘ä»¬æ˜¯å¦ä¸€ä¸ªäººå·¥æ™ºèƒ½çš„ AGIğŸ¤¯).

ä½†æ˜¯è®©æˆ‘ä»¬å‡è®¾å®ƒåšåˆ°äº†â€¦

æƒ³è±¡ä¸€ä¸‹ï¼Œç¿»å¼€ä½ çš„ç¬”è®°æœ¬ç”µè„‘ï¼Œä½ ä¼šå‘ç°ä¸€ä¸ªä¸ºä½ ç¼–å†™çš„è¿™æ ·çš„ç®—æ³•ã€‚

```
def AGI(data):
    data = clean(data)
    agi = magic(data)
    return agi
```

å—¯å¥½çš„ğŸ¤”ã€‚è®©æˆ‘ä»¬çœ‹çœ‹è¿™æ˜¯æ€ä¹ˆå›äº‹ã€‚ä½ è¯´æœä½ çš„ç ”ç©¶å°ç»„ä½ éœ€è¦å¯¹æ­¤è¿›è¡Œä¸€äº›è¯•éªŒã€‚

ä½†æ˜¯ obvs è¿™ä¸ä¼šåƒå†™çš„é‚£æ ·è¿è¡Œã€‚é¦–å…ˆï¼Œæˆ‘ä»¬éœ€è¦ä¸€ä¸ªè®­ç»ƒå¾ªç¯:

```
for epoch in range(10):
    for batch in data:
        agi = AGI(batch)
        agi.backward()
        ...
```

å¥½äº†ï¼Œç°åœ¨æˆ‘ä»¬ç®—æ˜¯è®­ç»ƒäº†ã€‚ä½†æ˜¯æˆ‘ä»¬ä»ç„¶éœ€è¦æ·»åŠ ä¸€ä¸ªéªŒè¯å¾ªç¯â€¦

```
def validate(dataset):
   # more magic
```

æ¯’å“ã€‚ä½†æ˜¯ LOL AGI åœ¨ä¸€ä¸ª CPU ä¸Šï¼Ÿ

ä½ æƒ³å¾—ç¾ã€‚

è®©æˆ‘ä»¬åœ¨å¤šä¸ª GPU ä¸Šè¿è¡Œè¿™ä¸ªâ€¦ä½†æ˜¯ç­‰ç­‰ï¼Œä½ ä¹Ÿå·²ç»[è¯»åˆ°è¿‡](/9-tips-for-training-lightning-fast-neural-networks-in-pytorch-8e63a502f565)16 ä½å¯ä»¥åŠ é€Ÿä½ çš„è®­ç»ƒã€‚å¤©å“ªï¼Œä½†æ˜¯æœ‰ 3 ç§æ–¹æ³•å¯ä»¥è¿›è¡Œ GPU åˆ†å¸ƒå¼è®­ç»ƒã€‚

æ‰€ä»¥ä½ èŠ±äº†ä¸€å‘¨çš„æ—¶é—´ç¼–å†™ä»£ç ã€‚ä½†æ˜¯ä»ç„¶å¾ˆæ…¢ï¼Œæ‰€ä»¥æ‚¨å†³å®šä½¿ç”¨è®¡ç®—é›†ç¾¤ã€‚ç°åœ¨äº‹æƒ…å˜å¾—æœ‰ç‚¹å¤æ‚äº†ã€‚

![](img/0253cf9791744d713ca7dc352d902ce6.png)

Sad times

ä¸æ­¤åŒæ—¶ï¼Œä½ çš„ AGI æœ‰ä¸€ä¸ª bugï¼Œä½†ä½ ä¸ç¡®å®šè¿™æ˜¯ä½ çš„ GPU åˆ†é…ä»£ç ï¼Œè¿˜æ˜¯ä½ å¦‚ä½•åŠ è½½ä½ çš„æ•°æ®ï¼Œæˆ–è€…å…¶ä»–ä»»ä½•ä½ å¯èƒ½ç¼–ç é”™è¯¯çš„äº‹æƒ…ã€‚

ä½ å†³å®šä½ ä¸å¤ªæƒ³å¤„ç†æ‰€æœ‰çš„è®­ç»ƒç»†èŠ‚ï¼Œä½ å°è¯• Kerasï¼Œä½†æ˜¯å®ƒä¸èƒ½è®©ä½ å¾ˆå¥½åœ°å®ç° AGI å‡½æ•°ï¼Œå› ä¸ºä½ éœ€è¦å¯¹è®­ç»ƒæœ‰æ›´å¤šçš„æ§åˆ¶ã€‚Fast.ai ä¹Ÿæ˜¯ä¸å¯èƒ½çš„ï¼Œå› ä¸ºè¿™ä¸æ˜¯ç°æˆçš„ç®—æ³•ã€‚

å¥½å§ï¼Œé‚£å¤ªç³Ÿç³•äº†ï¼Œç°åœ¨ä½ å·²ç»è‡ªå·±ç¼–ç äº†â€¦

æ²¡æœ‰ã€‚

# Pytorch é—ªç”µ

![](img/9f48d9bc577bc4c8fa56dea7e7fe577b.png)

How you feel when running a single model on 200 GPUs

[Pytorch Lightning](https://github.com/williamFalcon/pytorch-lightning) å·²ç»ä¸ºä½ ç¼–å†™äº†æ‰€æœ‰è¿™äº›ä»£ç ï¼ŒåŒ…æ‹¬[æµ‹è¯•](https://travis-ci.org/williamFalcon/pytorch-lightning)åˆ°**ä¿è¯**ç¨‹åºçš„é‚£éƒ¨åˆ†æ²¡æœ‰é”™è¯¯ã€‚

è¿™æ„å‘³ç€ä½ å¯ä»¥ä¸“æ³¨äºç ”ç©¶çš„æ ¸å¿ƒï¼Œè€Œä¸å¿…æ‹…å¿ƒæ‰€æœ‰ç¹ççš„å·¥ç¨‹ç»†èŠ‚ï¼Œå¦‚æœä½ ä¸å¿…ä¸“æ³¨äºæ ¸å¿ƒç ”ç©¶ç†å¿µï¼Œå¤„ç†è¿™äº›ç»†èŠ‚ä¼šå¾ˆæœ‰è¶£ã€‚

è¿™é‡Œæœ‰ä¸€ä¸ªæ¸…æ™°çš„å›¾è¡¨ï¼Œæ˜¾ç¤ºäº†ä»€ä¹ˆæ˜¯è‡ªåŠ¨åŒ–çš„ã€‚ç°è‰²éƒ¨åˆ†æ˜¯è‡ªåŠ¨åŒ–çš„ï¼Œé€šè¿‡æ•™ç»ƒæ——æ§åˆ¶ã€‚ä½ å¯ä»¥ä½¿ç”¨ä½ æƒ³è¦çš„ä»»ä½•åº•å±‚æ¨¡å‹(ä½ è‡ªå·±çš„ã€é¢„è®­ç»ƒçš„ä¸œè¥¿ã€fast.ai æ¶æ„ç­‰ç­‰)ï¼Œå°†è“è‰²éƒ¨åˆ†å®šä¹‰ä¸ºä½ æƒ³è¦çš„ä»»æ„å¤æ‚ã€‚

![](img/bde86d83846ddb89e160740f03ef469f.png)

You own the blue. Lightning owns the rest.

# é—ªç”µæ¨¡å‹

Lightning çš„æ ¸å¿ƒæ˜¯ä¸¤ä»¶äº‹ï¼Œä¸€ä¸ª LightningModelï¼Œä¸€ä¸ª Trainerã€‚LightningModel æ˜¯ä½  90%çš„æ—¶é—´èŠ±åœ¨è¿™é‡Œçš„åœ°æ–¹ã€‚

Lightning Module Template

è¯·æ³¨æ„ï¼Œæ‚¨æ­£åœ¨å®šä¹‰åŸ¹è®­å¾ªç¯ä¸­å‘ç”Ÿçš„äº‹æƒ…

```
for epoch in range(10):
    for batch in data:
      # training_step above is what happens here
      # lightning handles the rest (backward, gradient clip, etc...)
```

éªŒè¯ä¹Ÿæ˜¯ä¸€æ ·

```
for val_batch in data:
    # validation_step above is what happens here
    # with no grad, eval, etc... all handled for you automatically
```

ä¸Šé¢è¿™ä¸¤ä¸ªå‡½æ•°ä¼šå˜å¾—éå¸¸å¤æ‚ã€‚äº‹å®ä¸Šï¼Œæ‚¨å¯ä»¥åœ¨è¿™ä¸¤ä¸ªå‡½æ•°ä¸­å®šä¹‰ä¸€ä¸ªå®Œæ•´çš„ transformerï¼Œseq-2-seqï¼Œfairseq æ¨¡å‹ã€‚

# **åŸ¹è®­å¸ˆ**

![](img/0208d0f54ddf816a1ba975f9ab04ad42.png)

åŸ¹è®­å¸ˆå¤„ç†æ‚¨ä¸æƒ³ç¼–ç çš„ä¸œè¥¿çš„æ‰€æœ‰æ ¸å¿ƒé€»è¾‘ï¼Œä½†æ˜¯æ‚¨éœ€è¦ä¿è¯å®ƒè¢«æ­£ç¡®åœ°å®Œæˆå¹¶ä¸”ä½¿ç”¨æœ€æ–°çš„æœ€ä½³å®è·µã€‚

åªéœ€è®¾ç½®å‡ ä¸ªæ ‡å¿—ï¼Œä½ å°±å¯ä»¥åœ¨ CPUã€[å¤š GPU](https://williamfalcon.github.io/pytorch-lightning/Trainer/Distributed%20training/#Multi-GPU)æˆ–[å¤šèŠ‚ç‚¹](https://williamfalcon.github.io/pytorch-lightning/Trainer/Distributed%20training/#Multi-node)é›†ç¾¤ä¸Šè®­ç»ƒä½ çš„ AGIã€‚ä¸ä»…å¦‚æ­¤ï¼Œæ‚¨è¿˜å¯ä»¥å¯ç”¨[æ¸å˜è£å‰ª](https://williamfalcon.github.io/pytorch-lightning/Trainer/Training%20Loop/#gradient-clipping)ã€[ç´¯ç§¯æ¸å˜](https://williamfalcon.github.io/pytorch-lightning/Trainer/Training%20Loop/#accumulated-gradients)ã€ [16 ä½ç²¾åº¦](https://williamfalcon.github.io/pytorch-lightning/Trainer/Distributed%20training/#16-bit-mixed-precision)ã€[è‡ªåŠ¨èšç±»ä¿å­˜](https://williamfalcon.github.io/pytorch-lightning/Trainer/Distributed%20training/#Multi-node)ã€[è¶…å‚æ•°å¿«ç…§](https://williamfalcon.github.io/pytorch-lightning/Trainer/Logging/#save-a-snapshot-of-all-hyperparameters)ã€[å¼ é‡æ¿å¯è§†åŒ–](https://williamfalcon.github.io/pytorch-lightning/Trainer/Logging/#tensorboard-support)ç­‰

ä½ æ˜ç™½äº†ã€‚

ä½ ä¸ä»…å¯ä»¥è·å¾—è®­ç»ƒäººå·¥æ™ºèƒ½ç³»ç»Ÿçš„æœ€æ–°å’Œæœ€æ£’çš„æŠ€å·§ï¼Œè¿˜å¯ä»¥ä¿è¯å®ƒä»¬èƒ½å¤Ÿæ­£å¸¸å·¥ä½œå¹¶ä¸”ç»è¿‡æ­£ç¡®çš„æµ‹è¯•ã€‚

è¿™æ„å‘³ç€ä½ åªéœ€è¦æ‹…å¿ƒä½ çš„éƒ¨åˆ†â€”â€”æ–°ç®—æ³•â€”â€”æ˜¯å¦æ­£ç¡®ã€‚å¦‚ä½•åŠ è½½æ•°æ®ä»¥åŠåœ¨åŸ¹è®­çš„æ ¸å¿ƒéƒ¨åˆ†åšäº›ä»€ä¹ˆç”±ä½ å†³å®šã€‚

é‚£ä¹ˆï¼ŒPytorch é—ªç”µçš„ 36 ç§å¸®åŠ©æ–¹å¼å‘¢ï¼Ÿå¤§çº¦æœ‰ 36 ä¸ªä½ é€šå¸¸è‡ªå·±å®ç°çš„ä¸œè¥¿å¯èƒ½ä¼šæœ‰ bugã€‚Lightning ä¼šåšå¹¶æµ‹è¯•å®ƒï¼Œæ‰€ä»¥æ‚¨ä¸å¿…è¿™æ ·åšï¼

ç‚¹å‡»è¿™é‡ŒæŸ¥çœ‹å®Œæ•´åˆ—è¡¨

æ­å–œä½ ã€‚ä½ å¯ä»¥åˆ©ç”¨åˆšåˆšå›æ¥çš„æ‰€æœ‰ç©ºé—²æ—¶é—´æ¥å®Œæˆä½ æ­£åœ¨åšçš„å…¼èŒé¡¹ç›®(å¯èƒ½æ˜¯ä½ å°ç‹—çš„èŠå¤©æœºå™¨äººï¼Œæˆ–è€…æ˜¯ä¼˜æ­¥çš„ç‘œä¼½è£¤)ã€‚

![](img/a6f759fb705079bef4540552beabb169.png)