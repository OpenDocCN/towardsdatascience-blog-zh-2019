# 选择机器学习模型

> 原文：<https://towardsdatascience.com/part-i-choosing-a-machine-learning-model-9821eecdc4ce?source=collection_archive---------11----------------------->

挑选完美的机器学习模型的部分艺术，部分科学。

![](img/34ba9a384c206505bf80fe8287f1518f.png)

外面闪亮模型的数量可能是压倒性的，这意味着很多时候人们依靠他们最信任的几个，并用它们来解决所有新问题。这可能导致次优结果。

今天，我们将学习如何快速有效地缩小可用模型的范围，找到最有可能解决您的问题类型的模型。我们还将看到如何使用权重和偏差来跟踪模型的表现，并对它们进行比较。

你可以在这里找到伴随代码。

# 我们将涵盖的内容

*   竞争数据科学与现实世界中的模型选择
*   模特们的盛大集会
*   比较模型

我们开始吧！

与指环王不同，在机器学习中，没有一个戒指(模型)可以统治所有的戒指。不同类别的模型擅长对不同类型数据集的底层模式进行建模。例如，决策树适用于数据形状复杂的情况:

![](img/55817ccdd0a426585bd49946b45d3fbd.png)

而线性模型最适合数据集可线性分离的情况:

![](img/b944032b7c908a9a4d3c4d5e64ad7782.png)

在我们开始之前，让我们稍微深入一下现实世界中的模型选择与竞争数据科学之间的差异。

# 竞争数据科学与现实世界中的模型选择

正如 William Vorhies 在他的[博客文章](https://www.datasciencecentral.com/profiles/blogs/want-to-win-at-kaggle-pay-attention-to-your-ensembles)中所说，“Kaggle 竞赛就像数据科学的方程式赛车。赢家在小数点后第四位击败竞争对手，就像 f1 赛车一样，我们中没有多少人会把他们误认为日常车手。投入的时间和有时极端的技术不适合数据科学生产环境。”

Kaggle 模型确实像赛车，它们不是为日常使用而制造的。现实世界的量产车型更像雷克萨斯——可靠但不浮华。

Kaggle 竞赛和真实世界针对非常不同的事情进行优化，其中一些关键差异是:

# 问题定义

现实世界允许您定义您的问题，并选择封装您的模型成功的度量标准。这允许你优化一个更复杂的效用函数，而不仅仅是一个单一的指标，其中 Kaggle 竞争只带有一个预定义的指标，并且不允许你有效地定义问题。

# 韵律学

在现实世界中，我们关心推理和训练速度、资源和部署约束以及其他性能指标，而在 Kaggle 竞赛中，我们唯一关心的是一个评估指标。想象一下，我们有一个精度为 0.98 的模型，它非常耗费资源和时间，而另一个精度为 0.95 的模型速度更快，计算量更少。在现实世界中，对于许多领域，我们可能更喜欢 0.95 的精度模型，因为我们可能更关心推理的时间。在 Kaggle 比赛中，无论训练模型需要多长时间，或者需要多少 GPU，精度越高总是越好。

# 可解释性

类似地，在现实世界中，我们喜欢更简单的模型，更容易向利益相关者解释，而在 Kaggle 中，我们不关注模型的复杂性。模型可解释性很重要，因为它允许我们采取具体的行动来解决潜在的问题。例如，在现实世界中，查看我们的模型并能够看到特征(例如街道上的坑洼)和问题(例如街道上发生车祸的可能性)之间的相关性，比将预测精度提高 0.005%更有帮助。

# 数据质量

最后，在 Kaggle 比赛中，我们的数据集被收集并为我们争论。任何研究过数据科学的人都知道，现实生活中几乎不会出现这种情况。但是能够收集和组织我们的数据也让我们对数据科学过程有了更多的控制。

# 激励

所有这些激励我们花费大量的时间来调整我们的超参数，以从我们的模型中提取最后的性能下降，有时，复杂的特征工程方法。虽然 Kaggle 竞赛是学习数据科学和特征工程的一种极好的方式，但它们并没有解决现实世界中的问题，如模型可解释性、问题定义或部署约束。

# 模特们的盛大集会

是时候开始选模特了！

当选择我们的初始模型集进行测试时，我们需要注意一些事情:

# 选择一组不同的初始模型

不同类别的模型擅长对数据中不同种类的底层模式进行建模。因此，一个好的第一步是快速测试几个不同类别的模型，以了解哪些模型能够最有效地捕捉数据集的底层结构！在我们的问题类型(回归、分类、聚类)领域中，我们希望尝试基于树、基于实例和基于内核的混合模型。从每个班级中挑选一个模型进行测试。我们将在下面的“要尝试的模型”一节中详细讨论不同的模型类型。

# 为每个模型尝试一些不同的参数

虽然我们不想花太多时间寻找超参数的最佳集合，但我们确实想尝试一些不同的超参数组合，以使每个模型类都有机会表现良好。

# 挑选最强有力的竞争者

我们可以使用这个阶段中表现最好的模型来给我们直觉，让我们知道我们想要进一步深入哪个类别的模型。您的权重和偏好仪表板将引导您找到最适合您的问题的模型类别。

# 深入研究最佳性能模型类中的模型。

接下来，我们选择更多属于我们上面列出的最佳表现类别的模型！例如，如果线性回归似乎效果最好，那么尝试套索或岭回归也是一个好主意。

# 更详细地探索超参数空间。

在这个阶段，我鼓励你花一些时间调整候选模型的超参数。(本系列的下一篇文章将深入探讨为模型选择最佳超参数的直觉。)在这一阶段结束时，您应该拥有所有最强模型的最佳执行版本。

# 做出最终选择——ka ggle

从不同的模型中挑选最终提交的作品。理想情况下，我们希望从多个类别的模型中选择最佳模型。这是因为如果你只从一类模型中进行选择，而恰好是错误的，那么你提交的所有模型都将表现不佳。Kaggle 竞赛通常允许你选择一个以上的参赛作品进行最终提交。我建议从不同的类中选择你最强的模型所做的预测，以在你的提交中建立一些冗余。

**排行榜不是你的朋友，你的交叉验证分数才是。**最重要的是要记住，公共排行榜不是你的朋友。仅仅根据你的公开排行榜分数来挑选你的模型将会导致训练数据集过拟合。当私人排行榜在比赛结束后公布时，有时你可能会看到你的排名下降很多。您可以在训练模型时使用交叉验证来避免这个小陷阱。然后选择交叉验证分数最高的模型，而不是排行榜分数最高的模型。通过这样做，您可以根据多个验证集来衡量模型的性能，而不仅仅是公共排行榜使用的一个测试数据子集，从而应对过度拟合。

# 做出最终选择——真实世界

**资源限制。**不同的模型占用不同类型的资源，了解您是将模型部署在带有小型硬盘和处理器的物联网/移动设备上，还是部署在云中，对于选择正确的模型至关重要。

**训练时间 vs 预测时间 vs 准确率。**了解您正在优化的指标对于选择正确的模型也至关重要。例如，自动驾驶汽车需要极快的预测时间，而欺诈检测系统需要快速更新其模型，以跟上最新的网络钓鱼攻击。对于医疗诊断等其他情况，我们关心的是准确性(或 ROC 曲线下的面积),而不是训练次数。

**复杂性与可解释性的权衡。**更复杂的模型可以使用数量级更多的特征来训练和预测，这需要更多的计算，但如果训练正确，可以捕捉数据集中真正有趣的模式。这也使得它们令人费解，难以解释。知道向利益相关者简单解释模型与在放弃可解释性的同时捕捉一些真正有趣的趋势是多么重要，是选择模型的关键。

**伸缩性。**了解您的模型需要扩展的速度和规模可以帮助您适当地缩小选择范围。

**训练数据的大小。对于非常大的数据集或具有许多特征的数据集，神经网络或增强树可能是一个很好的选择。而较小的数据集可能更适合使用逻辑回归、朴素贝叶斯或 KNNs。**

**参数数量。**具有大量参数的模型为您提供了很大的灵活性，以获得真正出色的性能。然而，可能会有这样的情况，你没有所需的时间，例如，从头开始训练神经网络的参数。在这种情况下，开箱即用的模型将是最佳选择！

# 比较模型

[权重和偏差](http://wandb.com)让您用一行代码跟踪和比较模型的性能。

一旦你选择了你想尝试的模型，训练它们，然后简单地添加*wandb . log({ ' score ':cv _ score })*来记录你的模型状态。一旦你完成训练，你可以在一个简单的仪表板上比较你的模型表现！

你可以在这里找到有效完成这项工作的代码[。我鼓励你分叉](https://www.kaggle.com/lavanyashukla01/picking-the-best-model-a-whirlwind-tour-of-model)[这个内核](https://www.kaggle.com/lavanyashukla01/picking-the-best-model-a-whirlwind-tour-of-model)并摆弄代码！

就是这样，现在您拥有了为您的问题选择正确模型所需的所有工具！

模型选择可能会非常复杂，但我希望这篇指南能给你一些启发，并给你一个挑选模型的好框架。

在第二部分，机器学习模型的旋风式旅行中，我们将更深入地研究 ML 模型，何时应该使用它们！

如果您有任何问题或反馈，请随时 [**发微博给我**](https://twitter.com/lavanyaai) ！