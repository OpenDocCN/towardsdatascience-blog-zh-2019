<html>
<head>
<title>Merging with AI: How to Make a Brain-Computer Interface to Communicate with Google using Keras and OpenBCI</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">与人工智能融合:如何使用 Keras 和 OpenBCI 制作脑机接口与 Google 通信</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/merging-with-ai-how-to-make-a-brain-computer-interface-to-communicate-with-google-using-keras-and-f9414c540a92?source=collection_archive---------6-----------------------#2019-09-05">https://towardsdatascience.com/merging-with-ai-how-to-make-a-brain-computer-interface-to-communicate-with-google-using-keras-and-f9414c540a92?source=collection_archive---------6-----------------------#2019-09-05</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><figure class="is it gp gr iu iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi ir"><img src="../Images/cbd9ac9b6d59104873bcf67918411dfe.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*JJxvp7785uQ1Xcgh-dZ-PA.jpeg"/></div></div></figure><div class=""/><p id="db2d" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi kz translated"><span class="l la lb lc bm ld le lf lg lh di"> E </span> lon Musk 和 Neuralink 希望建立一个可以充当大脑第三层的脑机接口，让人类与人工智能形成共生关系。</p><p id="300a" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">但是如果你已经可以做到了呢？</p><p id="5730" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">在(非常)有限的形式下，你确实可以。</p></div><div class="ab cl li lj hx lk" role="separator"><span class="ll bw bk lm ln lo"/><span class="ll bw bk lm ln lo"/><span class="ll bw bk lm ln"/></div><div class="im in io ip iq"><h1 id="3c96" class="lp lq je bd lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk ml mm bi translated"><strong class="ak">背景</strong></h1><p id="cec5" class="pw-post-body-paragraph kb kc je kd b ke mn kg kh ki mo kk kl km mp ko kp kq mq ks kt ku mr kw kx ky im bi translated">脑机接口(Brain-Computer Interface，BCI)泛指在神经系统和电子设备之间建立直接连接的任何系统。这些装置可以通过手术植入大脑，也可以在体外。典型的范例包括允许用户控制<a class="ae ms" href="https://www.ncbi.nlm.nih.gov/pubmed/10404201" rel="noopener ugc nofollow" target="_blank">致动器</a>或<a class="ae ms" href="https://elifesciences.org/articles/18554" rel="noopener ugc nofollow" target="_blank">键盘</a>，允许设备向用户发送<a class="ae ms" href="https://ieeexplore.ieee.org/document/7514940" rel="noopener ugc nofollow" target="_blank">传感数据</a>，或<a class="ae ms" href="https://www.uchicagomedicine.org/forefront/neurosciences-articles/2016/october/researchers-help-paralyzed-man-regain-sense-of-touch-through-a-robotic-arm" rel="noopener ugc nofollow" target="_blank">涉及传感数据和电机控制的双向通信</a>(即接收电机控制输入并发送压力或温度传感数据的假肢)</p><p id="eac7" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">历史上，神经假体一直是 BCI 研究的主要动机。这些技术包括为截肢者安装假肢、为聋人安装人工耳蜗，以及为癫痫患者提供深部脑刺激。这些设备已经改善了数百万人的生活，它们的广泛使用证明了大脑和电子设备之间实现直接双向通信的好处。然而，该技术的可能应用远远超出了医疗保健。即使在神经假体领域，我们也可以想象超越修复，考虑增强我们的能力，使之超过正常人的水平。总有一天，假肢会发展到以任何客观标准来衡量都比自然假肢优越的地步。这些肢体可能看起来和感觉起来就像正常的肢体，但会更加强壮和灵活。另一个例子是人造眼睛，其分辨率远高于人眼，能够放大或缩小，并能看到紫外线或红外线光谱。</p><p id="6cd5" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">当考虑认知和技能形成时，可能性变得更加有趣。最近的一项研究表明，刺激大脑的某些部分可以改善记忆的形成和回忆。其他的<a class="ae ms" href="https://www.nature.com/articles/nn.3970" rel="noopener ugc nofollow" target="_blank">实验</a>已经成功地将记忆人工植入动物体内。举个例子，也许可以应用这些研究的方法来提高你快速学习一种乐器的能力。或者，也许有可能将各种神经刺激器和传感器结合起来，开发一种“算术处理单元”，它可以检测大脑中与数学或逻辑推理相关的特定区域何时被激活，并与它们通信以增强能力。</p><p id="b59a" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">埃隆·马斯克和 Neuralink 想要追求的正是这种认知增强的延伸。根据马斯克和许多领先的人工智能理论家的说法，人类相对于人工智能的智力进步的一个关键障碍是带宽问题:尽管计算机和人工智能变得越来越快，处理和生成知识的能力越来越强，但我们在做同样事情的能力方面面临着直接和根本的限制。我们主要通过我们的感官和解释语言的能力来获取信息。在你的眼睛和视觉皮层阅读和理解一个句子的时间里，计算机可以扫描成千上万页的文本。可以想象，在几十年的时间里，我们可能会有运行在专门的神经形态硬件上的高级人工智能，这些硬件具有世界如何工作的令人难以置信的精确模型，以及在几分钟内分析和理解数百万份文件的能力，做出远超人类理解的决策和推断。在一个越来越依赖人工智能驱动决策的世界，人类可能会发现自己在商业、科学和政治决策过程的所有部分都过时了。我们的大脑并没有进化到用数万亿颗棋子来下一盘棋，也没有进化到理解预先计划了数百万步棋的战略。正是对这个超级智能黑匣子的恐惧，激发了<a class="ae ms" href="https://www.neuralink.com/" rel="noopener ugc nofollow" target="_blank"> Neuralink </a>、<a class="ae ms" href="https://kernel.co" rel="noopener ugc nofollow" target="_blank"> Kernel </a>和其他几个相关组织目前的大部分工作。</p><p id="6eaa" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">BCI 技术的大多数前沿研究都试图最大限度地提高信息带宽，通常是通过将电极直接植入大脑或神经的侵入式方法。然而，非侵入性方法，特别是脑电图(EEG)和肌电图(EMG)被常规使用，并取得了相当大的成功。这些包括将电极放置在你的头部表面(EEG)或肌肉上方的皮肤上(EMG ),以测量下面累积的电活动。这些数据的粒度很低，与最终实现 BCI 研究更宏伟目标所需的精度和带宽水平相去甚远。尽管如此，EEG/EMG 支持的 BCI 已经取得了令人难以置信的成就，如用思想控制无人机、视频游戏和键盘，并且它们提供了进一步研究可能解开的可能性的一瞥。此外，像<a class="ae ms" href="https://www.cognixion.com/" rel="noopener ugc nofollow" target="_blank"> Cognixion </a>和<a class="ae ms" href="http://www.neurable.com/" rel="noopener ugc nofollow" target="_blank"> Neurable </a>这样的几家公司正在探索基于 EEG 的脑机接口的真实世界应用，并且已经获得了大量的资金和支持，许多令人兴奋的项目正在进行中。</p></div><div class="ab cl li lj hx lk" role="separator"><span class="ll bw bk lm ln lo"/><span class="ll bw bk lm ln lo"/><span class="ll bw bk lm ln"/></div><div class="im in io ip iq"><h1 id="9caa" class="lp lq je bd lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk ml mm bi translated"><strong class="ak">概述</strong></h1><p id="f77f" class="pw-post-body-paragraph kb kc je kd b ke mn kg kh ki mo kk kl km mp ko kp kq mq ks kt ku mr kw kx ky im bi translated">在这个项目中，我们在你的神经系统和外部人工智能代理之间建立了一个直接的连接。这个代理可能是任何你能得到的 API:谷歌助手，Siri，Alexa，Watson 等。像 Dictionary 或 YouTube 这样的服务也符合条件，但这些服务会将应用程序局限于内容查询，而不是通用请求。</p><p id="78e1" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">为了这个项目的目的，我们将直接查询谷歌搜索，因为它提供了最大的灵活性，也是最容易设置的。完成后，你应该能够简单地通过思考在谷歌上查询一些术语。</p><p id="c9e5" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">我们使用的技术利用了你的大脑在默念过程中产生的神经信号。这是当你慢慢地、有意识地阅读或思考时，发生在你大脑内部的“内心独白”。你可能已经注意到自己在默读的时候会这样做，有时你会在不知不觉中微妙地移动你的下巴和舌头。当你收到 SAT、MCAT、GRE 或其他标准化考试准备的提示时，你可能也遇到过这个概念。考生被建议避免默读，因为这是一个降低阅读速度的坏习惯。</p><p id="22c3" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">我们能够利用默念，因为大脑向你的喉头发送与你想说的话相对应的信号，即使你并不打算大声说出来。通过将电极放置在你面部的喉部和下颌神经上，我们可以记录与特定单词对应的信号，并使用它们来训练深度学习模型，以辨别不同的单词。换句话说(没有双关语的意思)，我们可以从你思考某个单词的行为中辨别出你在思考这个单词。</p><figure class="mu mv mw mx gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi mt"><img src="../Images/ef6e8495a93b0d27f7ca1b74fe025dfa.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*8HHSoPPgRXNpuezp4N8A-w.png"/></div></div><figcaption class="my mz gj gh gi na nb bd b be z dk">Brain and Laryngeal Nerves</figcaption></figure><p id="d36c" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">这种技术有其局限性，它绝不是完美的，也不适合实际应用。然而，自从两年前由麻省理工学院媒体实验室首次在现实世界中演示以来，它已经被成功地用于允许用户做数学、打电话、订披萨，甚至在下棋时接受帮助的设备中。</p><figure class="mu mv mw mx gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi nc"><img src="../Images/15e1040f19cc2b16497d9213de864ffa.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*JI6b3FyQQHaZVSlaDP6Wag.jpeg"/></div></div><figcaption class="my mz gj gh gi na nb bd b be z dk">MIT Media Lab AlterEgo Headset</figcaption></figure></div><div class="ab cl li lj hx lk" role="separator"><span class="ll bw bk lm ln lo"/><span class="ll bw bk lm ln lo"/><span class="ll bw bk lm ln"/></div><div class="im in io ip iq"><h1 id="9f26" class="lp lq je bd lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk ml mm bi translated"><strong class="ak">设置&amp;材料</strong></h1><p id="9e20" class="pw-post-body-paragraph kb kc je kd b ke mn kg kh ki mo kk kl km mp ko kp kq mq ks kt ku mr kw kx ky im bi translated">所需的主要硬件工具是 OpenBCI 神经节板。有各种各样的其他硬件可供选择，但是我发现 OpenBCI 有一个最大的开发人员社区来提供支持。它花了你大约 200 美元，但是考虑到你可以用它建造难以置信的东西，它是非常值得的。</p><figure class="mu mv mw mx gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi nd"><img src="../Images/a1054f9517bd00b5d022c5625ff5ed66.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*LlKorw8sr3XBenEiXtubVg.jpeg"/></div></div><figcaption class="my mz gj gh gi na nb bd b be z dk">OpenBCI Board and Electrodes</figcaption></figure><p id="6dc4" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">除了电路板，你还需要电极和电线。一套金杯电极和电极凝胶应该花费 50 美元，应该工作正常。</p><p id="691f" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated"><a class="ae ms" href="https://shop.openbci.com/collections/frontpage/products/pre-order-ganglion-board" rel="noopener ugc nofollow" target="_blank">神经节板</a></p><p id="6884" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated"><a class="ae ms" href="https://shop.openbci.com/collections/frontpage/products/openbci-gold-cup-electrodes" rel="noopener ugc nofollow" target="_blank">电极</a></p><p id="1e55" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated"><a class="ae ms" href="https://shop.openbci.com/collections/frontpage/products/ten20-conductive-paste-2oz-jars" rel="noopener ugc nofollow" target="_blank">电极凝胶</a></p><p id="29e2" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">或者，你可以获得一个完整的 OpenBCI 入门套件，包括电路板和多种类型的干电极，以及一个电极头带，价格为 465 美元。有点贵，所以金杯设置完全没问题。不过，如果你打算尝试 BCI 的其他应用，比如虚拟现实(Unity VR 教程即将推出！)，头带和干电极带来更好的体验。</p><p id="8867" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated"><a class="ae ms" href="https://shop.openbci.com/collections/frontpage/products/bundle2?variant=13036379766856" rel="noopener ugc nofollow" target="_blank">生物传感入门套件</a></p><p id="5ccb" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">OpenBCI 还提供 8 和 16 通道板。这些将提供优越的数据质量，但 4 通道神经节将足以为这个项目。</p></div><div class="ab cl li lj hx lk" role="separator"><span class="ll bw bk lm ln lo"/><span class="ll bw bk lm ln lo"/><span class="ll bw bk lm ln"/></div><div class="im in io ip iq"><h1 id="719e" class="lp lq je bd lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk ml mm bi translated"><strong class="ak">配置</strong></h1><p id="55cd" class="pw-post-body-paragraph kb kc je kd b ke mn kg kh ki mo kk kl km mp ko kp kq mq ks kt ku mr kw kx ky im bi translated">在 Linux 机器上，检查是否有 Python 3.4 或更高版本。打开您的终端并键入以下命令:</p><pre class="mu mv mw mx gt ne nf ng nh aw ni bi"><span id="3c7e" class="nj lq je nf b gy nk nl l nm nn">python3 --version</span></pre><p id="07e7" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">如果您没有 Python，或者您有旧版本，请输入:</p><pre class="mu mv mw mx gt ne nf ng nh aw ni bi"><span id="8308" class="nj lq je nf b gy nk nl l nm nn">$ sudo apt-get update<br/>$ sudo apt-get install python3.6</span></pre><p id="745a" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">现在，下载或克隆<a class="ae ms" href="https://github.com/OpenBCI/pyOpenBCI" rel="noopener ugc nofollow" target="_blank"> pyOpenBCI </a>目录。</p><p id="d6b8" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">将目录更改为存储库，并运行以下命令来安装必备软件包:</p><pre class="mu mv mw mx gt ne nf ng nh aw ni bi"><span id="2d99" class="nj lq je nf b gy nk nl l nm nn">$ pip install numpy pyserial bitstring xmltodict requests bluepy</span></pre><p id="0210" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">您现在可以安装 pyOpenBCI 了</p><pre class="mu mv mw mx gt ne nf ng nh aw ni bi"><span id="143a" class="nj lq je nf b gy nk nl l nm nn">$ pip install pyOpenBCI</span></pre><p id="5ad8" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">要查看一些操作，请将目录更改为<strong class="kd jf"/><em class="no">pyOpenBCI/Examples</em><strong class="kd jf"><em class="no"/></strong>并找到<a class="ae ms" href="https://github.com/OpenBCI/pyOpenBCI/blob/master/Examples/print_raw_example.py" rel="noopener ugc nofollow" target="_blank"> print_raw_example.py </a>。用您最喜欢的代码编辑器打开这个文件，并在第 7 行进行如下修改:</p><pre class="mu mv mw mx gt ne nf ng nh aw ni bi"><span id="cc1a" class="nj lq je nf b gy nk nl l nm nn">board = OpenBCICyton(daisy = False)</span></pre><p id="c899" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">应改为:</p><pre class="mu mv mw mx gt ne nf ng nh aw ni bi"><span id="7fd0" class="nj lq je nf b gy nk nl l nm nn">board = OpenBCIGanglion(mac=’*’)</span></pre><p id="7665" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">这使得 pyOpenBCI 能够为我们正在使用的特定电路板采用适当的模块。</p><p id="2af7" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">现在，打开你的主板。</p><p id="6a23" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">在您的计算机上，从<em class="no">示例</em> <strong class="kd jf"> </strong>目录中键入以下命令:</p><pre class="mu mv mw mx gt ne nf ng nh aw ni bi"><span id="587a" class="nj lq je nf b gy nk nl l nm nn">$ sudo python print_raw_example</span></pre><p id="4e18" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">嘣！！你的终端现在应该充满了来自电路板的原始输入数据流。</p></div><div class="ab cl li lj hx lk" role="separator"><span class="ll bw bk lm ln lo"/><span class="ll bw bk lm ln lo"/><span class="ll bw bk lm ln"/></div><div class="im in io ip iq"><h1 id="83b8" class="lp lq je bd lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk ml mm bi translated"><strong class="ak">记录信号</strong></h1><p id="9b8d" class="pw-post-body-paragraph kb kc je kd b ke mn kg kh ki mo kk kl km mp ko kp kq mq ks kt ku mr kw kx ky im bi translated">既然我们可以获得原始信号，我们就可以开始设计和构建数据管道。首先，我们必须首先将原始数据转换成 LSL 流。LSL 指的是实验室流层，是由加州大学圣地亚哥分校<a class="ae ms" href="http://sccn.ucsd.edu/people/" rel="noopener ugc nofollow" target="_blank">斯沃茨计算神经科学中心</a>开发的一种协议，旨在促进实时数据流的记录和分析。LSL 将我们的脑电图数据传输到本地主机，从那里它可以被其他应用程序或脚本拾取。</p><p id="ba4b" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">修改<strong class="kd jf"/><em class="no">pyOpenBCI/Examples</em>中的<a class="ae ms" href="https://github.com/OpenBCI/pyOpenBCI/blob/master/Examples/lsl_example.py" rel="noopener ugc nofollow" target="_blank"> lsl_example.py </a>文件，删除我们不需要的 AUX 流，增加一个标记流:</p><figure class="mu mv mw mx gt iv"><div class="bz fp l di"><div class="np nq l"/></div></figure><p id="1275" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">我们现在必须定义一个实验设置，以我们想要的形式记录数据，并将其存储以备将来使用。我们希望该实验生成一个时间序列 EEG 数据的数据集，这些数据被分成多个区间，每个区间对应于一个单词的无声化。为了实现这一点，我们可以执行一个实验，开始 N 个间隔的记录会话，每个间隔持续 T 秒。给定区间内的所有样本都用区间索引和指示用户默写的特定单词来标注。</p><p id="902f" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">来自<a class="ae ms" href="https://github.com/neurotech-berkeley" rel="noopener ugc nofollow" target="_blank">神经科技伯克利分校</a>的<a class="ae ms" href="https://github.com/neurotech-berkeley/neurotech-course/blob/master/lab4/lsl-record.py" rel="noopener ugc nofollow" target="_blank"> lsl-record.py </a>文件是一个很好的起点。根据我们定义的设置修改文件:</p><figure class="mu mv mw mx gt iv"><div class="bz fp l di"><div class="np nq l"/></div></figure><p id="b390" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">您可以调整术语库(第 64 行),在不同的上下文中尝试不同的单词组合。您也可以在每次会话前调整默认持续时间(第 12 行)。</p><p id="6c48" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">现在是有趣的部分了！将电极插入电路板:</p><figure class="mu mv mw mx gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi nr"><img src="../Images/7bc1eb9b216009933ecfd9b8d6befc8d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*zDlPRy1NxVx8muhieP44mA.png"/></div></div><figcaption class="my mz gj gh gi na nb bd b be z dk">Left 4 channels are EEG in, right 2 channels are ground</figcaption></figure><p id="8f47" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">按照以下配置将它们贴在脸上:</p><figure class="mu mv mw mx gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi ns"><img src="../Images/20a23c733276a2dafbbdd85ad0282916.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*m5vj3G1QlQzRFkA91AZxNw.jpeg"/></div></div></figure><p id="fc40" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">找一个安静的地方坐下，在不同的终端中输入以下行:</p><pre class="mu mv mw mx gt ne nf ng nh aw ni bi"><span id="a427" class="nj lq je nf b gy nk nl l nm nn">// Terminal 1: converts raw data to LSL and streams it<br/>$ sudo python lsl_example</span><span id="2ff1" class="nj lq je nf b gy nt nl l nm nn">// Terminal 2: reads LSL data stream and executes experiment<br/>$ sudo python lsl_record</span></pre><p id="189b" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated"><em class="no">注意:我们作为 sudo 运行，以允许脚本检测板的 MAC 地址</em></p><p id="615a" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">这将启动指定持续时间的记录会话。你将被提示从你的词库中随机抽取一个单词，间隔 2 秒钟默读。录制过程可能会让人不舒服，容易入睡，所以最好在中间休息一下，进行多次小范围的录制。此外，如果频繁出现干扰(即突然移动或使不正确的单词不发音)，我们的实验设置可能会导致数据质量差。</p><p id="e659" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">您可以设计和实现一个更灵活的设置，可以选择在注意到干扰时击一个键来删除当前和以前的间隔。另一个解决方法是进行多个小的会话，并在最后合并数据，丢弃干扰过大的会话。一些噪声是不可避免的，你不必太挑剔，因为随着样本数量的增加，模型变得更有弹性。</p><p id="58cc" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">为了获得最佳结果，你的词库中的每个词至少要有 1000 个高质量的样本。</p></div><div class="ab cl li lj hx lk" role="separator"><span class="ll bw bk lm ln lo"/><span class="ll bw bk lm ln lo"/><span class="ll bw bk lm ln"/></div><div class="im in io ip iq"><h1 id="f9f2" class="lp lq je bd lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk ml mm bi translated"><strong class="ak">过程信号</strong></h1><p id="0638" class="pw-post-body-paragraph kb kc je kd b ke mn kg kh ki mo kk kl km mp ko kp kq mq ks kt ku mr kw kx ky im bi translated">一旦你有了足够的数据，就该为机器学习做准备了。</p><p id="4f99" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">对数据进行适当的组合和预处理，使其具有以下格式:</p><figure class="mu mv mw mx gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi nu"><img src="../Images/374aaeef2551bed0fda5d9fd9429e172.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_6IpAh983veBuOVwynztJg.png"/></div></div><figcaption class="my mz gj gh gi na nb bd b be z dk">Example Data Table</figcaption></figure><ul class=""><li id="7401" class="nv nw je kd b ke kf ki kj km nx kq ny ku nz ky oa ob oc od bi translated">单词是从 1 到<strong class="kd jf"> NumIntervals，</strong>的索引，T5 是总会话数中<strong class="kd jf"> SessionDuration/2 </strong>的总和</li><li id="c6e3" class="nv nw je kd b ke oe ki of km og kq oh ku oi ky oa ob oc od bi translated">术语对应于每个时间间隔显示的单词</li><li id="90ee" class="nv nw je kd b ke oe ki of km og kq oh ku oi ky oa ob oc od bi translated">[A，B，C，D]是脑电图通道</li><li id="6013" class="nv nw je kd b ke oe ki of km og kq oh ku oi ky oa ob oc od bi translated">每个单词、术语组合对应于大约 800 行数据</li></ul><p id="313b" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">使用 numpy 将您的 CSV 文件导入 python。您应该将所有数据加载到脚本中的 NumLines x 6n array 中。</p><p id="5110" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">第一步是过滤数据，去除我们感兴趣的频率之外的噪声。信息 EEG 频率对应于以下频段:</p><figure class="mu mv mw mx gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi oj"><img src="../Images/bb20d3cd0c818851f587a665ee32f2ec.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*LPO42XrjJ6qcUZ8f2gx6CQ.png"/></div></div><figcaption class="my mz gj gh gi na nb bd b be z dk">EEG Wave Frequencies</figcaption></figure><p id="6720" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">对 4 Hz 至 100 Hz 之间的频率进行滤波似乎是合理的，但会失败，因为 60 Hz 是电网的频率(可能因国家而异)，这必然是一个重要的噪声源。为了获得最佳结果，我们应该在 4 Hz 和 50 Hz 之间进行滤波。</p><p id="75bc" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">我们可以使用 Scipy 的巴特沃兹滤波器来选择我们想要保持的频率范围。用下面的<a class="ae ms" href="https://stackoverflow.com/questions/12093594/how-to-implement-band-pass-butterworth-filter-with-scipy-signal-butter" rel="noopener ugc nofollow" target="_blank">代码</a>定义一个过滤器:</p><figure class="mu mv mw mx gt iv"><div class="bz fp l di"><div class="np nq l"/></div></figure><p id="5184" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">然后，生成一个时间戳列(因为我们合并了多个数据集，并使原始时间戳无效)，并将过滤器应用于每个通道:</p><figure class="mu mv mw mx gt iv"><div class="bz fp l di"><div class="np nq l"/></div></figure><p id="ec51" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">过滤后，使用下面的代码将数据重组为一个三维的 ndarrray 数组，其维度为<strong class="kd jf">IntervalLength x channel count x interval count</strong>。</p><figure class="mu mv mw mx gt iv"><div class="bz fp l di"><div class="np nq l"/></div></figure><p id="f1c2" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">我们用上面的代码有效地将时间序列数据转换成图像数据。这听起来可能有点不可思议，但是你可以把每两秒钟的间隔想象成一幅图像，每一个像素对应于在一个特定的(<strong class="kd jf">通道号</strong>、<strong class="kd jf">线路号</strong>)坐标上获取的信号值。换句话说，我们有一堆<strong class="kd jf">间隔计数</strong>图像，每个图像的大小都是<strong class="kd jf">间隔长度</strong> x <strong class="kd jf">通道计数</strong>。</p><figure class="mu mv mw mx gt iv gh gi paragraph-image"><div class="gh gi ok"><img src="../Images/8833fa6fba8d500c8b4f53a7dd91f006.png" data-original-src="https://miro.medium.com/v2/resize:fit:154/format:webp/1*3eeEbz0m-l02Hug-zkWlnw.png"/></div><figcaption class="my mz gj gh gi na nb bd b be z dk">First 120 data points of an EEG interval</figcaption></figure><p id="6933" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">这项技术由<a class="ae ms" href="https://medium.com/@justlv/using-ai-to-read-your-thoughts-with-keras-and-an-eeg-sensor-167ace32e84a" rel="noopener"> Justin Alvey </a>在一个类似的项目中演示，非常强大，因为它允许我们将时间序列数据视为图像数据，允许我们利用计算机视觉和卷积神经网络(CNN)的力量。您甚至可以通过将特定的默写绘制成图像来将其可视化</p><p id="a632" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">此外，使用 CNN 允许我们跳过傅立叶变换，因为神经网络可以学习各种频率(在每个图像上以模式出现)，而无需明确指定它应该寻找什么频率。</p><p id="2432" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">现在我们准备开始建设 CNN。由于我们只有 1 个颜色维度，我们可以使用输入维度为<strong class="kd jf"> IntervalLength </strong>和<strong class="kd jf"> ChannelCount </strong>的 1D CNN。您可以尝试不同的超参数和架构。我选定了一个卷积层、两个完全连接层和两个合并层。</p><figure class="mu mv mw mx gt iv"><div class="bz fp l di"><div class="np nq l"/></div></figure><p id="33bc" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">有关一维 CNN 以及它们如何应用于时间序列数据的更详细分析，请参考 Nils Ackermann 的这篇文章<a class="ae ms" href="https://blog.goodaudience.com/introduction-to-1d-convolutional-neural-networks-in-keras-for-time-sequences-3a7ff801a2cf" rel="noopener ugc nofollow" target="_blank">。</a></p><p id="f789" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">我们现在有了一个模型，它应该能够将一段时间的脑电图数据与你的词库中的一个特定单词进行匹配。</p><p id="2d91" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">让我们看看它做得有多好。将模型应用于测试数据，并将预测结果与实际结果进行比较。</p><pre class="mu mv mw mx gt ne nf ng nh aw ni bi"><span id="b438" class="nj lq je nf b gy nk nl l nm nn"># Test Model<br/>y_predicted = model.predict(X_test)</span></pre><p id="a7ee" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">用银行这两个词，我可以达到 90%的准确率。不出所料，随着单词的增加，准确率略有下降，三向准确率为 86%，四向准确率为 81%。</p><figure class="mu mv mw mx gt iv gh gi paragraph-image"><div class="gh gi ol"><img src="../Images/2316cd2100b1b5084676add27e31ce96.png" data-original-src="https://miro.medium.com/v2/resize:fit:1206/format:webp/1*gjnxDHYXHxWC3px2i7WURg.png"/></div><figcaption class="my mz gj gh gi na nb bd b be z dk">Sample truth chart from two word classification. Left is Actual, Right is Predicted</figcaption></figure><p id="2eed" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">一种在不影响准确性的情况下增加术语库大小的可能方法是创建具有多词查询的分层“术语树”。然后，您可以在树上执行深度优先搜索——每一层的单词只与同一子树的同一层中的其他单词进行比较——以找到最佳匹配。</p></div><div class="ab cl li lj hx lk" role="separator"><span class="ll bw bk lm ln lo"/><span class="ll bw bk lm ln lo"/><span class="ll bw bk lm ln"/></div><div class="im in io ip iq"><h1 id="78fc" class="lp lq je bd lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk ml mm bi translated"><strong class="ak">谷歌搜索</strong></h1><p id="98ea" class="pw-post-body-paragraph kb kc je kd b ke mn kg kh ki mo kk kl km mp ko kp kq mq ks kt ku mr kw kx ky im bi translated">我们现在已经有了使用 BCI 查询谷歌的所有必要信息。定义特定子可视化和查询之间的映射，并进行适当的调用:</p><figure class="mu mv mw mx gt iv"><div class="bz fp l di"><div class="np nq l"/></div></figure><p id="0276" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">还有…</p><figure class="mu mv mw mx gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi om"><img src="../Images/d2871cccdc8b3523f9b7ef33abc62768.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*UR7qAvzSlSW-7Zzokhc0Bg.jpeg"/></div></div></figure><p id="0844" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">要想进行实时查询，请修改 lsl_record.py 脚本并将其作为一个模块导入。然后，您可以调用它来读取 LSL 流，以 2 秒的时间间隔响应用户输入。</p><p id="866c" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">就是这样！你现在不用说或输入一个字就可以搜索谷歌。</p></div><div class="ab cl li lj hx lk" role="separator"><span class="ll bw bk lm ln lo"/><span class="ll bw bk lm ln lo"/><span class="ll bw bk lm ln"/></div><div class="im in io ip iq"><h1 id="5991" class="lp lq je bd lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk ml mm bi translated"><strong class="ak">结论</strong></h1><p id="4070" class="pw-post-body-paragraph kb kc je kd b ke mn kg kh ki mo kk kl km mp ko kp kq mq ks kt ku mr kw kx ky im bi translated">你不能用一个三四个单词的术语库做太多事情(除非实现前面提到的术语树)。经历所有这些步骤来搜索到你最近的加油站的方向比正常的谷歌搜索稍微复杂一些。然而，重要的是要考虑这项技术的进一步发展可能会导致什么。我们可以想象这种设备的改进版和不太显眼的版本，与麻省理工学院团队已经拥有的版本没有太大区别，用于导航、网络查询、短信、智能家居管理或任何数量的日常任务。当与不断改进的人工智能助手的能力相结合时，这种可能性会进一步扩大。</p><p id="8bc9" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">基于脑电图的脑机接口的应用是世界各地公司和大学实验室的尖端研究最终可能实现的一小部分。心灵感应交流、超人智能、附加感官、模拟体验、人类意识数字化、与人工智能融合等都值得考虑。如果这些可能性得以实现，它们将不仅仅重新定义我们与技术的关系:它们还将重新定义对人类意味着什么。</p></div><div class="ab cl li lj hx lk" role="separator"><span class="ll bw bk lm ln lo"/><span class="ll bw bk lm ln lo"/><span class="ll bw bk lm ln"/></div><div class="im in io ip iq"><p id="a298" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated"><strong class="kd jf">参考文献</strong></p><p id="eea9" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">以下是我发现有助于完成这个项目和了解 BCIs 的资源和组织列表。我要特别感谢麻省理工学院媒体实验室的 AlterEgo 团队，他们是这个项目的最初灵感来源，也感谢 Alvey 先生和 NeuroTech Berkeley，感谢他们之前对 BCI 社区的代码和教程贡献。此外，我要感谢加州大学戴维斯分校的教职员工，特别是<a class="ae ms" href="https://faculty.engineering.ucdavis.edu/tagkopoulos/biography/" rel="noopener ugc nofollow" target="_blank">伊利亚斯·塔格科普洛斯</a>、<a class="ae ms" href="https://bme.ucdavis.edu/people/karen-moxon" rel="noopener ugc nofollow" target="_blank">卡伦·莫克森</a>和<a class="ae ms" href="https://ece.ucdavis.edu/directory/erkin-seker" rel="noopener ugc nofollow" target="_blank">埃尔金·谢克尔</a>博士，感谢他们一直以来的帮助和支持。</p><figure class="mu mv mw mx gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi on"><img src="../Images/f245371498b59c216924e720580c26fd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*zlt_wRZCGofSbmSqduds9w.png"/></div></div></figure><ul class=""><li id="645c" class="nv nw je kd b ke kf ki kj km nx kq ny ku nz ky oa ob oc od bi translated"><a class="ae ms" href="https://www.media.mit.edu/publications/alterego-IUI/" rel="noopener ugc nofollow" target="_blank"> AlterEgo:一款个性化的可穿戴式无声语音界面</a></li><li id="b85a" class="nv nw je kd b ke oe ki of km og kq oh ku oi ky oa ob oc od bi translated"><a class="ae ms" href="https://medium.com/@justlv/using-ai-to-read-your-thoughts-with-keras-and-an-eeg-sensor-167ace32e84a" rel="noopener">利用深度学习“读取你的想法”——借助 Keras 和 EEG——贾斯汀·阿尔维</a></li><li id="40b5" class="nv nw je kd b ke oe ki of km og kq oh ku oi ky oa ob oc od bi translated"><a class="ae ms" href="https://github.com/neurotech-berkeley/neurotech-course" rel="noopener ugc nofollow" target="_blank">神经科技伯克利 Github </a></li><li id="1ae1" class="nv nw je kd b ke oe ki of km og kq oh ku oi ky oa ob oc od bi translated"><a class="ae ms" href="https://github.com/OpenBCI" rel="noopener ugc nofollow" target="_blank">打开 BCI Gitub </a></li><li id="9bce" class="nv nw je kd b ke oe ki of km og kq oh ku oi ky oa ob oc od bi translated">脑机接口:介绍</li></ul><p id="a794" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">最后，我想对不断成长的 BCI/神经技术社区大声疾呼，他们为未来提供了无尽的支持、资源和热情。</p><ul class=""><li id="1c46" class="nv nw je kd b ke kf ki kj km nx kq ny ku nz ky oa ob oc od bi translated"><a class="ae ms" href="https://neurotechx.com/" rel="noopener ugc nofollow" target="_blank"> NeuroTechX </a></li><li id="4d9b" class="nv nw je kd b ke oe ki of km og kq oh ku oi ky oa ob oc od bi translated">BCI 红迪网</li><li id="8b4d" class="nv nw je kd b ke oe ki of km og kq oh ku oi ky oa ob oc od bi translated">Reddit Neuralink </li><li id="ce34" class="nv nw je kd b ke oe ki of km og kq oh ku oi ky oa ob oc od bi translated"><a class="ae ms" href="https://openbci.com/community/" rel="noopener ugc nofollow" target="_blank"> OpenBCI </a></li></ul><p id="4d70" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated"><em class="no">如果您想进一步讨论或联系，请随时联系</em><a class="ae ms" href="https://www.linkedin.com/in/jagveersingh/" rel="noopener ugc nofollow" target="_blank"><em class="no">LinkedIn</em></a></p></div></div>    
</body>
</html>