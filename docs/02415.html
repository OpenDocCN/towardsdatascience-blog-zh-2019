<html>
<head>
<title>Histopathological Cancer Detection with Deep Neural Networks</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">基于深度神经网络的组织病理学癌症检测</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/histopathological-cancer-detection-with-deep-neural-networks-3399be879671?source=collection_archive---------11-----------------------#2019-04-20">https://towardsdatascience.com/histopathological-cancer-detection-with-deep-neural-networks-3399be879671?source=collection_archive---------11-----------------------#2019-04-20</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><p id="3bd6" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><em class="ko">(注:相关 Jupyter 笔记本及原帖可在此处找到:</em><a class="ae kp" href="https://www.humanunsupervised.com/post/histopathological-cancer-detection" rel="noopener ugc nofollow" target="_blank"><em class="ko">https://www . human unsupervised . com/post/organisotrophic-cancer-detection</em></a><em class="ko">)</em></p><p id="fb72" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">能够利用机器学习和深度神经网络在病理扫描中自动检测转移的癌症是医学成像和诊断的一个领域，具有潜在的临床用途。</p><p id="5be5" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">在这里，我们探索一个为这种类型的分析和诊断准备的特定数据集 PatchCamelyon 数据集(PCam)。</p><p id="3909" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">PCam 是一个二元分类图像数据集，包含大约 300，000 个从数字组织病理学扫描中提取的淋巴结切片的标记低分辨率图像。每张图像都由训练有素的病理学家标记是否存在转移癌。</p><p id="791d" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">这项工作的目标是在 PCam 数据集上训练一个卷积神经网络，并获得接近或接近最先进的结果。</p><p id="0fec" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">正如我们将看到的，利用 Fastai 库，我们在 PCam 数据集中预测癌症的准确率达到了 98.6%。</p><figure class="kr ks kt ku gt kv gh gi paragraph-image"><div role="button" tabindex="0" class="kw kx di ky bf kz"><div class="gh gi kq"><img src="../Images/f32b0775a78d2f5d0f3acf55cc948c0d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*vhWka79INGhODB00kL67OQ.png"/></div></div></figure></div><div class="ab cl lc ld hx le" role="separator"><span class="lf bw bk lg lh li"/><span class="lf bw bk lg lh li"/><span class="lf bw bk lg lh"/></div><div class="im in io ip iq"><p id="f97a" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">我们通过准备和训练具有以下特征的神经网络来实现这一点:</p><ol class=""><li id="f989" class="lj lk it js b jt ju jx jy kb ll kf lm kj ln kn lo lp lq lr bi translated">以预先训练的 Resnet50 ImageNet 模型为基础的迁移学习。</li><li id="41e6" class="lj lk it js b jt ls jx lt kb lu kf lv kj lw kn lo lp lq lr bi translated">以下数据增强:图像大小调整、随机裁剪和</li><li id="f4d8" class="lj lk it js b jt ls jx lt kb lu kf lv kj lw kn lo lp lq lr bi translated">水平和垂直轴图像翻转。</li><li id="0d07" class="lj lk it js b jt ls jx lt kb lu kf lv kj lw kn lo lp lq lr bi translated">适合一个周期的方法来优化我们培训的学习率选择。</li><li id="040e" class="lj lk it js b jt ls jx lt kb lu kf lv kj lw kn lo lp lq lr bi translated">有区别的学习率进行微调。</li></ol><p id="a176" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">此外，我们在培训中应用了以下“开箱即用”的优化和规范化技术:</p><ul class=""><li id="6c79" class="lj lk it js b jt ju jx jy kb ll kf lm kj ln kn lx lp lq lr bi translated">拒绝传统社会的人</li><li id="9c73" class="lj lk it js b jt ls jx lt kb lu kf lv kj lw kn lx lp lq lr bi translated">重量衰减</li><li id="f2df" class="lj lk it js b jt ls jx lt kb lu kf lv kj lw kn lx lp lq lr bi translated">批量标准化</li><li id="c780" class="lj lk it js b jt ls jx lt kb lu kf lv kj lw kn lx lp lq lr bi translated">平均池和最大池</li><li id="be19" class="lj lk it js b jt ls jx lt kb lu kf lv kj lw kn lx lp lq lr bi translated">亚当乐观主义者</li><li id="5e11" class="lj lk it js b jt ls jx lt kb lu kf lv kj lw kn lx lp lq lr bi translated">ReLU 激活</li></ul></div><div class="ab cl lc ld hx le" role="separator"><span class="lf bw bk lg lh li"/><span class="lf bw bk lg lh li"/><span class="lf bw bk lg lh"/></div><div class="im in io ip iq"><blockquote class="ly lz ma"><p id="963d" class="jq jr ko js b jt ju jv jw jx jy jz ka mb kc kd ke mc kg kh ki md kk kl km kn im bi translated">本笔记本展示了使用 Fastai + PyTorch 对该数据集的研究和分析，并作为参考、教程和开源资源提供给其他人参考。它并不打算成为严肃的临床应用的生产就绪资源。相反，我们在这里使用 Camelyon16 数据集中原始高分辨率临床扫描的低分辨率版本进行教育和研究。这被证明是原型化和测试各种深度学习算法的有效性的有用基础。</p></blockquote><h1 id="dba7" class="me mf it bd mg mh mi mj mk ml mm mn mo mp mq mr ms mt mu mv mw mx my mz na nb bi translated">背景和数据来源</h1><h2 id="784e" class="nc mf it bd mg nd ne dn mk nf ng dp mo kb nh ni ms kf nj nk mw kj nl nm na nn bi translated">原始资料来源:Camelyon16</h2><p id="1b60" class="pw-post-body-paragraph jq jr it js b jt no jv jw jx np jz ka kb nq kd ke kf nr kh ki kj ns kl km kn im bi translated">PCam 实际上是 Camelyon16 数据集的子集；一组淋巴结切片的高分辨率全切片图像(WSI)。该数据集由荷兰 Nijmegen 的 Radboud 大学医学中心(Radboudumc)的诊断图像分析组(DIAG)和病理学部门提供。以下是他们网站的摘录:<a class="ae kp" href="https://camelyon16.grand-challenge.org/Data/" rel="noopener ugc nofollow" target="_blank">https://camelyon16.grand-challenge.org/Data/</a></p><p id="f2a3" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><em class="ko">本次挑战中的数据包含总共 400 张前哨淋巴结的全切片图像(WSIs ),这些图像来自两个独立的数据集，分别收集于拉德布大学医学中心(荷兰奈梅亨)和乌得勒支大学医学中心(荷兰乌得勒支)。</em></p><p id="8458" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><em class="ko">第一个训练数据集由 170 个淋巴结 WSI(100 个正常和 70 个包含转移)和第二个 100 个 WSI(包括 60 个正常载玻片和 40 个包含转移的载玻片)组成。</em></p><p id="dadf" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><em class="ko">测试数据集由从两所大学收集的 130 个 WSI 组成。</em></p><figure class="kr ks kt ku gt kv gh gi paragraph-image"><div role="button" tabindex="0" class="kw kx di ky bf kz"><div class="gh gi nt"><img src="../Images/507dcd692a03a515f275055c4be12f21.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*dEaVvL2ris6Uqrd1pStBsQ.png"/></div></div><figcaption class="nu nv gj gh gi nw nx bd b be z dk">Examples above of a metastatic region (from Camelyon16)</figcaption></figure><h2 id="933f" class="nc mf it bd mg nd ne dn mk nf ng dp mo kb nh ni ms kf nj nk mw kj nl nm na nn bi translated">PatchCam (Kaggle)</h2><p id="dabe" class="pw-post-body-paragraph jq jr it js b jt no jv jw jx np jz ka kb nq kd ke kf nr kh ki kj ns kl km kn im bi translated">PCam 是由来自荷兰的健康机器学习博士生 Bas Veeling 编写的，专门用于帮助对这一特定问题感兴趣的机器学习从业者。它由 327，680，96x96 的彩色图像组成。可以在这里找到数据集的精彩概述:<a class="ae kp" href="http://basveeling.nl/posts/pcam/" rel="noopener ugc nofollow" target="_blank">http://basveeling.nl/posts/pcam/</a>，也可以通过 github 上的下载获得，那里有关于数据的进一步信息:<a class="ae kp" href="https://github.com/basveeling/pcam" rel="noopener ugc nofollow" target="_blank">https://github.com/basveeling/pcam</a></p><p id="8e93" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">这个特殊的数据集是通过 Kaggle API 直接从 Kaggle 下载的，它是原始 PCam(patchcamelion)数据集的一个版本，但删除了重复项。</p><p id="7333" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">PCam 旨在成为执行基本机器学习分析的良好数据集。顾名思义，它是用于执行类似分析(<a class="ae kp" href="https://camelyon16.grand-challenge.org/Data/" rel="noopener ugc nofollow" target="_blank">https://camelyon16.grand-challenge.org/Data/</a>)的大得多的 Camelyon16 数据集的缩小版</p><p id="b4bb" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">出自作者的话:</p><p id="4e65" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><em class="ko"> PCam 将转移检测的临床相关任务打包成直接的二值图像分类任务，类似于 CIFAR-10 和 MNIST。模型可以在几个小时内在单个 GPU 上轻松训练，并在肿瘤检测和全切片图像诊断的 Camelyon16 任务中获得有竞争力的分数。此外，任务难度和易处理性之间的平衡使其成为主动学习、模型不确定性和可解释性等主题的基础机器学习研究的主要怀疑对象。</em></p></div><div class="ab cl lc ld hx le" role="separator"><span class="lf bw bk lg lh li"/><span class="lf bw bk lg lh li"/><span class="lf bw bk lg lh"/></div><div class="im in io ip iq"><p id="f1b4" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">了解了一些数据背景之后，让我们开始设置我们的项目和工作目录…</p><figure class="kr ks kt ku gt kv gh gi paragraph-image"><div role="button" tabindex="0" class="kw kx di ky bf kz"><div class="gh gi ny"><img src="../Images/f560f626dec558240c1a2b1d07ebe733.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ytp-m6ai28oXtLd53bxZ5Q.png"/></div></div></figure><h1 id="aff6" class="me mf it bd mg mh mi mj mk ml mm mn mo mp mq mr ms mt mu mv mw mx my mz na nb bi translated">获取数据</h1><p id="8558" class="pw-post-body-paragraph jq jr it js b jt no jv jw jx np jz ka kb nq kd ke kf nr kh ki kj ns kl km kn im bi translated">我们使用的数据存在于 Kaggle 上。我们使用 Kaggle 的 SDK 直接从那里下载数据集。要使用 Kaggle SDK 和 API，您需要在您的 Kaggle 帐户中创建一个 Kaggle API 令牌。</p><p id="4839" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">登录 Kaggle 后，导航至“我的帐户”，然后向下滚动至“创建新的 API 令牌”。这会将一个 JSON 文件下载到您的计算机上，其中包含您的用户名和令牌字符串。把这些内容复制给你~/。kaggle/kaggle.json 令牌文件。</p><figure class="kr ks kt ku gt kv gh gi paragraph-image"><div role="button" tabindex="0" class="kw kx di ky bf kz"><div class="gh gi nz"><img src="../Images/5f57e7d79ccabc219c2f8940569dfd85.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*3c3bMDgvw_Kt8LiJn3Hulw.png"/></div></div></figure><h1 id="89f5" class="me mf it bd mg mh mi mj mk ml mm mn mo mp mq mr ms mt mu mv mw mx my mz na nb bi translated">使用 ImageDataBunch 准备数据</h1><p id="14ac" class="pw-post-body-paragraph jq jr it js b jt no jv jw jx np jz ka kb nq kd ke kf nr kh ki kj ns kl km kn im bi translated">下载完数据后，我们创建一个 ImageDataBunch 对象来帮助我们将数据加载到模型中，设置数据扩充，并将数据分成训练集和测试集。</p><figure class="kr ks kt ku gt kv gh gi paragraph-image"><div role="button" tabindex="0" class="kw kx di ky bf kz"><div class="gh gi oa"><img src="../Images/03ac20ef5f31ac665953a4ee0f910c44.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*8AO0YohUSobTt5UxRnlDuw.png"/></div></div></figure><p id="26b7" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">ImageDataBunch 包含了许多功能，可以帮助我们将数据准备成一种在训练时可以使用的格式。下面让我们来看看它执行的一些关键功能:</p><h2 id="9b80" class="nc mf it bd mg nd ne dn mk nf ng dp mo kb nh ni ms kf nj nk mw kj nl nm na nn bi translated">数据扩充</h2><p id="4784" class="pw-post-body-paragraph jq jr it js b jt no jv jw jx np jz ka kb nq kd ke kf nr kh ki kj ns kl km kn im bi translated">默认情况下，ImageDataBunch 对数据集执行许多修改和扩充:</p><ol class=""><li id="f9f1" class="lj lk it js b jt ju jx jy kb ll kf lm kj ln kn lo lp lq lr bi translated">居中裁剪图像</li><li id="2d13" class="lj lk it js b jt ls jx lt kb lu kf lv kj lw kn lo lp lq lr bi translated">出于数据扩充的目的，在何处以及如何进行裁剪方面也引入了一些随机性</li><li id="8274" class="lj lk it js b jt ls jx lt kb lu kf lv kj lw kn lo lp lq lr bi translated">重要的是，所有图像的大小必须相同，以便模型能够进行训练。</li></ol><p id="3993" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><em class="ko">图像翻转</em></p><p id="3d2e" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">我们还可以使用各种其他数据增强。但是我们激活的关键之一是垂直方向的图像翻转。</p><p id="a686" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">对于病理扫描，这是要激活的合理的数据扩充，因为扫描是定向在垂直轴还是水平轴上并不重要，</p><p id="254d" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">默认情况下，fastai 将在水平方向翻转，但我们需要在垂直方向打开翻转。</p><h2 id="3750" class="nc mf it bd mg nd ne dn mk nf ng dp mo kb nh ni ms kf nj nk mw kj nl nm na nn bi translated">批量</h2><p id="671e" class="pw-post-body-paragraph jq jr it js b jt no jv jw jx np jz ka kb nq kd ke kf nr kh ki kj ns kl km kn im bi translated">我们将使用 1cycle 策略(fit_one_cycle())来训练我们的网络(稍后将详细介绍)。这是一个超参数优化，允许我们使用更高的学习率。</p><p id="2802" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">更高的学习率是 1 周期政策中的一种规范化形式。回想一下，小批量增加了规则性，因此当在 1 周期学习中使用大批量时，允许使用更大的学习速率。</p><p id="63ea" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">这里的建议是使用 1 周期策略进行训练时，使用我们的 GPU 支持的最大批量。</p><h2 id="f852" class="nc mf it bd mg nd ne dn mk nf ng dp mo kb nh ni ms kf nj nk mw kj nl nm na nn bi translated">培训、验证和测试集</h2><ol class=""><li id="c294" class="lj lk it js b jt no jx np kb ob kf oc kj od kn lo lp lq lr bi translated">我们指定数据的文件夹位置(子文件夹 train 和 test 与 csv 数据一起存在的位置)</li><li id="aaf0" class="lj lk it js b jt ls jx lt kb lu kf lv kj lw kn lo lp lq lr bi translated">ImageDataBunch 将图像(在 train 子文件夹中)分割成训练集和验证集(默认为 80/20 分割)。在训练集中有 176，020 幅图像，在验证集中有大约 44，005 幅图像。</li><li id="68bb" class="lj lk it js b jt ls jx lt kb lu kf lv kj lw kn lo lp lq lr bi translated">我们还指定了 test 子文件夹的位置，它包含未标记的图像。我们的学习模型将针对该数据集测量准确性和错误率</li><li id="84d6" class="lj lk it js b jt ls jx lt kb lu kf lv kj lw kn lo lp lq lr bi translated">还指定了包含数据标签的 CSV 文件</li></ol><h2 id="3333" class="nc mf it bd mg nd ne dn mk nf ng dp mo kb nh ni ms kf nj nk mw kj nl nm na nn bi translated">基于基础架构和目标架构的图像大小</h2><p id="6c9b" class="pw-post-body-paragraph jq jr it js b jt no jv jw jx np jz ka kb nq kd ke kf nr kh ki kj ns kl km kn im bi translated">目标 PCam 数据集中的图像是 96×96 的正方形图像。然而，当将预训练的 ImageNet 模型引入我们的网络时，我们需要相应地设置大小，以考虑该数据集中的图像大小。</p><p id="6189" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">我们选择 224 作为开始时的默认大小。</p><h2 id="7174" class="nc mf it bd mg nd ne dn mk nf ng dp mo kb nh ni ms kf nj nk mw kj nl nm na nn bi translated">使图像正常化</h2><p id="8751" class="pw-post-body-paragraph jq jr it js b jt no jv jw jx np jz ka kb nq kd ke kf nr kh ki kj ns kl km kn im bi translated">一旦我们设置了 ImageDataBunch 对象，我们还会对图像进行标准化。</p><p id="40ab" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">标准化图像使用图像的<strong class="js iu">平均值</strong>和<strong class="js iu">标准偏差</strong>将图像值转换为标准化分布，这对于神经网络的训练更有效。</p><figure class="kr ks kt ku gt kv gh gi paragraph-image"><div role="button" tabindex="0" class="kw kx di ky bf kz"><div class="gh gi oe"><img src="../Images/89c4c1d75842ea15015f0afa7d18dfb9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*P-e7wCSQf01xKvb2pcbPBA.png"/></div></div></figure><p id="642d" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">下面我们来看看一些随机的数据样本，这样我们就可以了解我们在网络中输入了什么。这是一个二元分类问题，所以只有两类:</p><p id="df66" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">阴性(0) /转移(1)</p><figure class="kr ks kt ku gt kv gh gi paragraph-image"><div role="button" tabindex="0" class="kw kx di ky bf kz"><div class="gh gi of"><img src="../Images/9d8be137a75dca743bcafef9db293f9e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*FXL8UVh9WnW30AosMK4oVA.png"/></div></div></figure><h1 id="1e15" class="me mf it bd mg mh mi mj mk ml mm mn mo mp mq mr ms mt mu mv mw mx my mz na nb bi translated">学习者(CNN Resnet50)</h1><p id="ec67" class="pw-post-body-paragraph jq jr it js b jt no jv jw jx np jz ka kb nq kd ke kf nr kh ki kj ns kl km kn im bi translated">一旦我们正确地设置了 ImageDataBunch 对象，我们现在就可以将它和预先训练的 ImageNet 模型一起传递给 cnn_learner。我们将使用 Resnet50 作为我们的主干。</p><figure class="kr ks kt ku gt kv gh gi paragraph-image"><div role="button" tabindex="0" class="kw kx di ky bf kz"><div class="gh gi og"><img src="../Images/7612a0cad0e74e9b4b65f8a9e967eba2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*KJq3R-Yk9yfLcc98CqNuSg.png"/></div></div></figure><p id="664d" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">Fastai 在其 cnn_learner 中包装了许多最先进的计算机视觉学习。它是管理我们的模型训练和集成我们的数据的顶级构造。</p><h1 id="cc52" class="me mf it bd mg mh mi mj mk ml mm mn mo mp mq mr ms mt mu mv mw mx my mz na nb bi translated">迁移学习</h1><p id="1cbc" class="pw-post-body-paragraph jq jr it js b jt no jv jw jx np jz ka kb nq kd ke kf nr kh ki kj ns kl km kn im bi translated">从已经在另一个数据集上预先训练好的表现良好的模型的主干网络开始，是一种叫做<em class="ko">迁移学习</em>的方法。</p><p id="8724" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">迁移学习的工作前提是，你可以使用来自另一个机器学习模型的学习(即学习的权重)作为起点，而不是从头开始训练你的数据。</p><blockquote class="ly lz ma"><p id="efad" class="jq jr ko js b jt ju jv jw jx jy jz ka mb kc kd ke mc kg kh ki md kk kl km kn im bi translated">这是一种令人难以置信的有效训练方法，并巩固了当前训练深度神经网络的最先进实践。</p></blockquote><p id="9b8e" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">当使用预训练模型时，我们特别利用与预训练模型和目标数据集(PCam)最共有的学习特征。</p><p id="454a" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">因此，例如，对于在 ImageNet(如 Resnet50)上预先训练的模型，训练将利用已经从基本数据集(特别是前几层)学习到的共同特征(例如线、几何图形、图案)在目标数据集上进行训练。</p><p id="e83c" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">对于我们的模型，我们将使用 Resnet50。Resnet50 是使用 50 层在 ImageNet 数据上训练的残差神经网络，并且将为我们的网络提供良好的起点。</p><h1 id="53ad" class="me mf it bd mg mh mi mj mk ml mm mn mo mp mq mr ms mt mu mv mw mx my mz na nb bi translated">训练和健身一个周期</h1><h2 id="8e96" class="nc mf it bd mg nd ne dn mk nf ng dp mo kb nh ni ms kf nj nk mw kj nl nm na nn bi translated">适合一个周期</h2><p id="7382" class="pw-post-body-paragraph jq jr it js b jt no jv jw jx np jz ka kb nq kd ke kf nr kh ki kj ns kl km kn im bi translated">我们将用一种叫做“适合一个周期”的方法来训练我们的网络。这种优化是一种针对特定层组在我们的训练运行中跨总次数应用可变学习率的方式。这已被证明是一个非常有效的方法来调整学习率超参数的训练。</p><p id="dde3" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">“适合一个周期”改变学习率，从第一个时期的最小值(默认为 lr_max/div_factor)到预定的最大值(lr_max)，然后再下降到剩余时期的最小值。这个最小-最大-最小学习率方差称为一个周期。</p><p id="6eef" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">在 fastai docs<a class="ae kp" href="https://docs.fast.ai/callbacks.one_cycle.html" rel="noopener ugc nofollow" target="_blank">https://docs.fast.ai/callbacks.one_cycle.html</a>中可以找到很好的概述，以及 Leslie Smith [7]的原始论文中更详细的解释，其中提出了这种超参数调谐方法。</p><p id="3ca6" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">那么，我们如何确定最合适的最大学习速率来适应一个周期呢？我们运行 fastai 的 lr_find()方法。</p><p id="33dc" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">在解冻网络之前运行 lr_find 会产生下图。我们想在损失开始指数增长之前选择一个学习率。</p><figure class="kr ks kt ku gt kv gh gi paragraph-image"><div role="button" tabindex="0" class="kw kx di ky bf kz"><div class="gh gi oh"><img src="../Images/52e5d9d643a5f9b29025825cf21074c5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*X74U6_RB0rkfy8Xd0OFjIw.png"/></div></div></figure><p id="f43c" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">从所得学习率图的视觉观察来看，以 1e-02 的学习率开始似乎是初始 lr 值的合理选择。</p><h2 id="272d" class="nc mf it bd mg nd ne dn mk nf ng dp mo kb nh ni ms kf nj nk mw kj nl nm na nn bi translated">冻结</h2><p id="3646" class="pw-post-body-paragraph jq jr it js b jt no jv jw jx np jz ka kb nq kd ke kf nr kh ki kj ns kl km kn im bi translated">默认情况下，我们开始与我们的网络<em class="ko">冻结</em>。这意味着我们预训练的 Resnet50 模型的层应用了 trainable = False，并且训练仅在目标数据集上开始。我们提供给 fit_one_cycle()的学习率仅适用于此初始训练运行的层组。</p><figure class="kr ks kt ku gt kv gh gi paragraph-image"><div role="button" tabindex="0" class="kw kx di ky bf kz"><div class="gh gi oi"><img src="../Images/5b7a427de5236dedd1bb786169b5b752.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_K3SVUYFLv7p3jZ81s33HQ.png"/></div></div></figure><figure class="kr ks kt ku gt kv gh gi paragraph-image"><div role="button" tabindex="0" class="kw kx di ky bf kz"><div class="gh gi oj"><img src="../Images/e9386a5d41be79062750df83d710bb0a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*KTQLx1h1TieNwEJ6zoE54w.png"/></div></div></figure><h1 id="348c" class="me mf it bd mg mh mi mj mk ml mm mn mo mp mq mr ms mt mu mv mw mx my mz na nb bi translated">分析初步结果</h1><p id="51d2" class="pw-post-body-paragraph jq jr it js b jt no jv jw jx np jz ka kb nq kd ke kf nr kh ki kj ns kl km kn im bi translated">分析初始训练运行的图，我们可以看到，随着训练的进行，训练损失和验证损失都稳步下降并开始收敛。</p><p id="b2f8" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">目前的准确率是 97.76%。</p><p id="167b" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">我们可以通过使用 Fastai 的混淆矩阵和绘制我们的最高损失来了解这次训练的更多信息。</p><figure class="kr ks kt ku gt kv gh gi paragraph-image"><div role="button" tabindex="0" class="kw kx di ky bf kz"><div class="gh gi ok"><img src="../Images/d21a5befb6aa6d187fc3e0d914d3f8f0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*pxNarnX4GNYY6RKPMB0zMw.png"/></div></div></figure><figure class="kr ks kt ku gt kv gh gi paragraph-image"><div role="button" tabindex="0" class="kw kx di ky bf kz"><div class="gh gi ol"><img src="../Images/f63764af599ae44ec4fb9b96fd08f555.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*lE-gRp7NPhWG2mQ6Dtyj-A.png"/></div></div></figure><p id="636d" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">困惑矩阵是一个方便的工具，可以帮助我们获得关于培训效果的更多细节。具体来说，我们对神经网络预测的假阳性和假阴性的数量有所了解。</p><p id="b4bf" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">绘制我们的最高损失可以让我们更详细地检查特定的图像。Fastai 生成了我们预测错误的图像热图。热图允许我们检查使我们的网络混乱的图像区域。这样做是很有用的，这样我们就可以更好地了解我们的模型在每次测试中的表现，并指引我们找到如何改进它的线索。</p><h1 id="36c7" class="me mf it bd mg mh mi mj mk ml mm mn mo mp mq mr ms mt mu mv mw mx my mz na nb bi translated">微调、解冻和区别学习率</h1><p id="96e0" class="pw-post-body-paragraph jq jr it js b jt no jv jw jx np jz ka kb nq kd ke kf nr kh ki kj ns kl km kn im bi translated">第一次训练的初步结果已经很好了。但是通过更多的微调，我们实际上可以做得更好。</p><h2 id="b564" class="nc mf it bd mg nd ne dn mk nf ng dp mo kb nh ni ms kf nj nk mw kj nl nm na nn bi translated">迁移学习+微调=更好的概括</h2><p id="c52d" class="pw-post-body-paragraph jq jr it js b jt no jv jw jx np jz ka kb nq kd ke kf nr kh ki kj ns kl km kn im bi translated">光是迁移学习就比从头开始训练我们的网络要远得多。但是当连接预先训练的网络时，这种方法容易在脆弱的适应层之间出现优化困难。我们通过微调我们的模型来解决这个问题；使我们网络的所有层，包括预训练的 Resnet50 层，都是可训练的。当我们解冻时，我们训练我们所有的层。(参见[6])</p><p id="93a5" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">这导致了更好的结果和更强的归纳新例子的能力。</p><h2 id="efc1" class="nc mf it bd mg nd ne dn mk nf ng dp mo kb nh ni ms kf nj nk mw kj nl nm na nn bi translated">区别学习率和 1 周期</h2><p id="0ce8" class="pw-post-body-paragraph jq jr it js b jt no jv jw jx np jz ka kb nq kd ke kf nr kh ki kj ns kl km kn im bi translated">随着我们网络中所有层的解冻和开放训练，我们现在还可以结合 fit_one_cycle 使用<em class="ko">区别学习率</em>来进一步改进我们的优化。</p><p id="4ba0" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">区别学习率允许我们将特定的学习率应用于网络中的层组，为每个组进行优化。然后，Fit one cycle 对这些值进行操作，并根据 1cycle 策略使用它们来改变学习率。(<a class="ae kp" href="https://docs.fast.ai/basic_train.html#Discriminative-layer-training" rel="noopener ugc nofollow" target="_blank">https://docs . fast . ai/basic _ train . html #判别层训练</a>)</p><p id="3874" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">我们如何找到用于 fit 1cycle 的最佳学习率范围？我们可以使用 lr_find()来帮助我们。</p><figure class="kr ks kt ku gt kv gh gi paragraph-image"><div role="button" tabindex="0" class="kw kx di ky bf kz"><div class="gh gi om"><img src="../Images/53dc7594eddd24f57068810ebe4a7760.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Ce0tafSWiTZfdh4DUeHWGA.png"/></div></div></figure><p id="8ca7" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">分析上面的 lr 图，我们在损失开始急剧增加之前选择一个学习率范围，并将其应用于下面的 fit_one_cycle 方法。</p><p id="7478" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">从上面的图来看，选择 1e-4 的上限速率似乎是合理的，作为下限速率的推荐规则，我们可以选择比上限小 10 倍的值，在本例中为 1e-5。</p><p id="a634" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">下限速率将应用于我们预训练的 Resnet50 层组中的层。这里的权重已经被很好地学习了，所以我们可以对这组层进行较慢的学习速率。</p><p id="230b" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">上限比率将应用于我们上次在目标数据集上运行训练时训练的最终图层组。该组中的层将受益于更快的学习速率。</p><figure class="kr ks kt ku gt kv gh gi paragraph-image"><div role="button" tabindex="0" class="kw kx di ky bf kz"><div class="gh gi on"><img src="../Images/63a5ce3f082038c5168a02092e26a3c2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*MAHkQTUlwJAa_RXAEUilCw.png"/></div></div></figure><figure class="kr ks kt ku gt kv gh gi paragraph-image"><div role="button" tabindex="0" class="kw kx di ky bf kz"><div class="gh gi oo"><img src="../Images/704e0573e3d947967b25c8a408f16bee.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*I57JmHXQ5eCHoxzWnkjIjg.png"/></div></div></figure><figure class="kr ks kt ku gt kv gh gi paragraph-image"><div role="button" tabindex="0" class="kw kx di ky bf kz"><div class="gh gi op"><img src="../Images/92cfedd343612e885f77ee1c83af0620.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*T7X-o37ePIWem_GjXG8Gfg.png"/></div></div></figure><h1 id="1f3b" class="me mf it bd mg mh mi mj mk ml mm mn mo mp mq mr ms mt mu mv mw mx my mz na nb bi translated">最后分析</h1><p id="536f" class="pw-post-body-paragraph jq jr it js b jt no jv jw jx np jz ka kb nq kd ke kf nr kh ki kj ns kl km kn im bi translated">在最后的微调训练运行中，我们可以看到，我们的训练损失和验证损失现在在训练中期开始彼此偏离，并且训练损失以比验证损失快得多的速度逐渐改善，稳步下降，直到在运行的最后时期稳定到稳定的值范围。</p><p id="6032" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">在训练损失持续减少的情况下，我们验证损失的任何进一步增加都会导致过度拟合，不能很好地推广到新的例子。</p><p id="905e" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">在我们训练的这一点上完成，产生了比第一阶段训练运行结果高 98.6%的微调准确度。</p><h1 id="a8be" class="me mf it bd mg mh mi mj mk ml mm mn mo mp mq mr ms mt mu mv mw mx my mz na nb bi translated">参考</h1><p id="2d27" class="pw-post-body-paragraph jq jr it js b jt no jv jw jx np jz ka kb nq kd ke kf nr kh ki kj ns kl km kn im bi translated">[1]程序员实用深度学习，v3。法斯泰。杰瑞米·霍华德。雷切尔·汤姆森。【https://course.fast.ai/index.html T4】</p><p id="562b" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">[2] B. S .韦林，j .林曼斯，j .温肯斯，t .科恩，m .韦林。“用于数字病理学的旋转等变 CNN”。arXiv:1806.03962</p><p id="0d4f" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">[3] Ehteshami Bejnordi 等.用于检测乳腺癌妇女淋巴结转移的深度学习算法的诊断评估。JAMA:美国医学协会杂志，318(22)，2199–2210。doi:jama.2017.14585</p><p id="6070" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">[4] Camelyon16 挑战赛<a class="ae kp" href="https://camelyon16.grand-challenge.org/" rel="noopener ugc nofollow" target="_blank">https://camelyon16.grand-challenge.org</a></p><p id="43b1" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">[5]卡格尔。组织病理学癌症检测—在淋巴结切片的组织病理学扫描中识别转移组织<a class="ae kp" href="https://www.kaggle.com/c/histopathologic-cancer-detection" rel="noopener ugc nofollow" target="_blank">https://www.kaggle.com/c/histopathologic-cancer-detection</a></p><p id="6f73" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">[6]杰森·约辛斯基。杰夫·克伦。约舒亚·本吉奥。霍德·利普森。"深度神经网络的特征有多容易转移？"。arXiv:1411.1792v1 [cs。LG]</p><p id="c89e" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">7 莱斯利·n·史密斯。“神经网络超参数的训练方法:第 1 部分——学习速率、批量大小、动量和权重衰减”。arXiv:1803.09820v2 [cs。LG]</p></div></div>    
</body>
</html>