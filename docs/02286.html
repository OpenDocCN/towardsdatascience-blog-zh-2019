<html>
<head>
<title>How do I learn mathematics: Bayes Theorem for Dummy.</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">我如何学习数学:哑吧的贝叶斯定理？</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/bayes-theorem-for-dummy-how-do-i-learn-mathematics-e9bff5538cd8?source=collection_archive---------27-----------------------#2019-04-15">https://towardsdatascience.com/bayes-theorem-for-dummy-how-do-i-learn-mathematics-e9bff5538cd8?source=collection_archive---------27-----------------------#2019-04-15</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><p id="a911" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">我是从[1]开始学习 SVM 的，作者提到:“<em class="ko">如果你没有读过《朴素贝叶斯》，我会建议你通过</em> <a class="ae kp" href="https://medium.com/machine-learning-101/chapter-1-supervised-learning-and-naive-bayes-classification-part-1-theory-8b9e361897d5" rel="noopener"> <em class="ko">这里</em> </a> <em class="ko">”来阅读。这让我很好奇，我想我应该浏览一下，因为两年前上完数学课后，我仍然不明白贝叶斯定理，哈哈…</em></p><h1 id="0416" class="kq kr it bd ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln bi translated">如果你只是想知道贝叶斯定理，跳过这一步</h1><p id="6c69" class="pw-post-body-paragraph jq jr it js b jt lp jv jw jx lq jz ka kb lr kd ke kf ls kh ki kj lt kl km kn im bi translated">因为我打算攻读计算机科学博士学位，所以我开始阅读大量的研究论文，试图理解数学(尽管一开始很难)，并开始在谷歌上搜索大量的数学解释。当我不理解的时候，我坚持去理解。我试着把数学写出来，我试着阅读 10~20 个解释它的资料。</p><p id="b21c" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">当我开始思考我在高中期间学到了什么但不明白的东西(例如奇怪的<strong class="js iu"> <em class="ko"> e </em> </strong> <em class="ko"> </em>常数)时，我搜索了它并试图理解它，结果发现它并没有那么难，只是我的高中和大学讲师没有解释它的起源，如果你对它感兴趣，你可以去<a class="ae kp" href="https://betterexplained.com/articles/an-intuitive-guide-to-exponential-functions-e/" rel="noopener ugc nofollow" target="_blank">这里</a>自己阅读。</p><p id="4951" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">我在第一年有机会进入深度学习，然而，我对此一无所知，但现在我可以说，在 Youtube 上观看了<a class="ae kp" href="https://www.youtube.com/watch?v=NfnWJUyUJYU&amp;list=PLkt2uSq6rBVctENoVBg1TpCC7OQi31AlC" rel="noopener ugc nofollow" target="_blank">斯坦福 CS231n 系列</a>之后，我至少熟悉了深度学习的基础知识。我之前不明白 DL 里的交叉熵，信息论里的熵到底是什么，多亏了[3]，终于，我明白了。当你不懂的时候，就试着反复阅读，强迫自己<strong class="js iu">经常谷歌</strong>，试着<strong class="js iu">从基础开始学习</strong>和<strong class="js iu">耐心点</strong>，总有一天你会明白的。</p><h2 id="b474" class="lu kr it bd ks lv lw dn kw lx ly dp la kb lz ma le kf mb mc li kj md me lm mf bi translated">TLDR；如何理解数学</h2><ol class=""><li id="ac87" class="mg mh it js b jt lp jx lq kb mi kf mj kj mk kn ml mm mn mo bi translated">耐心(你的决心)</li><li id="66cc" class="mg mh it js b jt mp jx mq kb mr kf ms kj mt kn ml mm mn mo bi translated">从基础开始学习(如果你基础真的很差，请不要急于学习)</li><li id="f8d6" class="mg mh it js b jt mp jx mq kb mr kf ms kj mt kn ml mm mn mo bi translated">问问你的讲师、导师或你认识的数学得了 A++++的人(在中国我们称他们为学霸)。</li><li id="2fb9" class="mg mh it js b jt mp jx mq kb mr kf ms kj mt kn ml mm mn mo bi translated">谷歌的发明是有原因的，孩子。</li></ol><figure class="mv mw mx my gt mz gh gi paragraph-image"><div class="gh gi mu"><img src="../Images/825805fe2f5b97c5f10e746da35efbda.png" data-original-src="https://miro.medium.com/v2/resize:fit:1200/format:webp/1*gLIxWxgG2etzMW6HAvxlXQ.jpeg"/></div></figure></div><div class="ab cl nc nd hx ne" role="separator"><span class="nf bw bk ng nh ni"/><span class="nf bw bk ng nh ni"/><span class="nf bw bk ng nh"/></div><div class="im in io ip iq"><h1 id="5a23" class="kq kr it bd ks kt nj kv kw kx nk kz la lb nl ld le lf nm lh li lj nn ll lm ln bi translated"><strong class="ak">贝叶斯定理</strong></h1><h2 id="18f6" class="lu kr it bd ks lv lw dn kw lx ly dp la kb lz ma le kf mb mc li kj md me lm mf bi translated">一些基础知识</h2><p id="9ee3" class="pw-post-body-paragraph jq jr it js b jt lp jv jw jx lq jz ka kb lr kd ke kf ls kh ki kj lt kl km kn im bi translated">永远记住概率背景下的乘法，等于<strong class="js iu">和</strong>。<br/>每当他们说给定某事的概率时，你可以把它们转换成数字。例如，你可以认为你有 100 个球在一个盒子里，其中 50 个是红色的，30 个是绿色的，20 个是蓝色的，因此你得到一个红色球的概率是 50/100 = 0.5(除非你把这个球拿出来，然后放回盒子里，这样盒子里总是有 100 个球，这叫做<strong class="js iu">替换</strong>样本)。</p><p id="d36e" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">你有 3 种不同颜色的球(例如红色、绿色、蓝色)。给定每个球的概率(r=0.5，g=0.3，b=0.2)，我们想知道得到 3 个不同颜色的球的概率(意味着一个红色，一个绿色和一个蓝色)。</p><p id="5724" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">P(1R &amp; 1G &amp; 1B) = 0.5 * 0.3 * 0.2 = 0.03 =你有 3%的机会得到 3 个不同颜色的球。用话说，我有 50%的机会得到红球，得到一个红球后，我不想再得到另一个红球，我想得到绿色或蓝色。因此，得到一个绿色球的几率是 0.5 * 0.3 = 0.15，或者得到一个蓝色球的几率是 0.5 * 0.2 = 0.1，这意味着我有 10%和 15%的机会得到一个绿色球或蓝色球，或者合计 25%的机会得到非红色球，同样计算最后一个球，得到 3 个不同颜色的 3 个球是极其困难的。<strong class="js iu"> <em class="ko">(如果我说错了请指正。)</em> </strong></p><h2 id="ec0a" class="lu kr it bd ks lv lw dn kw lx ly dp la kb lz ma le kf mb mc li kj md me lm mf bi translated">贝叶斯定理</h2><p id="9a27" class="pw-post-body-paragraph jq jr it js b jt lp jv jw jx lq jz ka kb lr kd ke kf ls kh ki kj lt kl km kn im bi translated">我实际上是从[2]中理解的，我以他们为例。</p><p id="de48" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">P(A|B) = P(B|A) * P(A) / P(B)</p><p id="f181" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">P(A) =事件 A 的概率<br/> P(B) =事件 B 的概率<br/> P(A|B) =给定 B 发生的事件 A 的概率<br/> P(B|A) =给定 A 发生的事件 B 的概率</p><p id="ddca" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">比如我们想知道，当我们看到烟的时候，火灾发生的概率是多少。(我们可能不想知道，但如果你是政府，你希望是否应该在工业区附近建立一个消防站，这可能会有用。)</p><p id="0397" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">P(火)=发生火灾的概率<br/> P(烟)=看到烟的概率<br/> P(火|烟)=当我们看到烟时发生火灾的概率<br/> P(烟|火)=发生火灾时看到烟的概率</p><p id="fef1" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">p(火灾)= 0.01 表示有 1%的火灾。P(烟雾)= 0.1，表示我们看到 10%的烟雾。<br/> P(Smoke|Fire) = 0.9 意思是当火灾发生时，90%的时间我们都能看到烟。</p><p id="90fe" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">给定贝叶斯叔叔的方程和上面的情况，我们想求 P(火|烟)。</p><p id="3872" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">P(火|烟)= P(烟|火)* P(火)/ P(烟)= 0.9 * 0.01 / 0.1 = 0.09 意味着如果我们看到一个工厂冒出烟，就会发生 9%的火灾。</p><p id="c38b" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">先说 P(烟|火)* P(火)= 0.9 * 0.01=0.009 (0.9%)，这意味着有烟发生火灾的概率是 0.9%。我们也可以说，没有烟的火是 0.1%。(0.09 + 0.01 = 0.1 = 1%有烟或无烟火灾)</p><p id="5dae" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">我们知道看到烟并不意味着有火灾，只能说有<strong class="js iu">机会</strong>有火灾。从方程中我们知道，当我们除以 P(烟)时，<strong class="js iu">几率</strong>是 9%，P(有烟的火)/P(烟)= 0.009/0.1 = 0.09。超过这 10%的看到烟的机会，我们可以说，我们观察工业区 10000 次，我们看到烟 1000 次(0.1)，有 90 次发生火灾(0.009)，因此，90/1000 = 9%的机会发生火灾。</p><p id="8994" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">换句话说，10000 次我们观察工业区，1000 次我们看到烟，100 次有火灾发生，90 次火灾有烟，10 次火灾没有烟。因此，当我们看到烟时，实际上有 9%的可能性发生火灾。</p><pre class="mv mw mx my gt no np nq nr aw ns bi"><span id="552f" class="lu kr it np b gy nt nu l nv nw">+-----------+----------------+-------+<br/>|           | Fire | No Fire |       |<br/>+-----------+----------------+-------+<br/>| Smoke     | 90   | 910     | 1000  |<br/>| No Smoke  | 10   | 8990    | 9000  |<br/>+-----------+------------------------+<br/>|           | 100  | 9900    | 10000 |<br/>+-----------+------+-----------------+</span><span id="4e3d" class="lu kr it np b gy nx nu l nv nw">Based on this table, total smoke = 1000, fire with smoke = 90, given number of smoke, smoke with fire = 90/1000 = 0.09 = 9%</span></pre><p id="9602" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">这就是我对贝叶斯定理的理解。贝叶斯定理有一些修改，</p><p id="ade6" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">P(A | B)= P(B | A)* P(A)/(P(B | A)* P(A)+P(B | A ')* P(A ')</p><p id="23d6" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">这个方程基本上和我刚才解释的一样。试着把数字放进去数数，这会帮助你更好地理解问题。</p><p id="2c03" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">1000 次冒烟相当于 90 次有烟着火+ 910 次无烟着火。</p><h1 id="b967" class="kq kr it bd ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln bi translated">结论</h1><p id="cf24" class="pw-post-body-paragraph jq jr it js b jt lp jv jw jx lq jz ka kb lr kd ke kf ls kh ki kj lt kl km kn im bi translated">请注意，我们总是可以用一个数字来表示概率，因为这实际上是统计学。</p><p id="5f6e" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">这是我如何理解一个数学公式和贝叶斯定理。希望这篇文章能帮助你理解更多关于贝叶斯定理的知识，并帮助你在统计考试中给这类问题打分。</p><h1 id="d66f" class="kq kr it bd ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln bi translated">参考</h1><p id="192d" class="pw-post-body-paragraph jq jr it js b jt lp jv jw jx lq jz ka kb lr kd ke kf ls kh ki kj lt kl km kn im bi translated">[1]<a class="ae kp" href="https://medium.com/machine-learning-101/chapter-2-svm-support-vector-machine-theory-f0812effc72" rel="noopener">https://medium . com/machine-learning-101/chapter-2-SVM-support-vector-machine-theory-f 0812 effc 72</a></p><p id="fd4d" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">[2]<a class="ae kp" href="https://medium.com/machine-learning-101/chapter-1-supervised-learning-and-naive-bayes-classification-part-1-theory-8b9e361897d5" rel="noopener">https://medium . com/machine-learning-101/chapter-1-supervised-learning-and-naive-Bayes-class ification-part-1-theory-8b9e 361897 D5</a></p><p id="d67e" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">[3]<a class="ae kp" rel="noopener" target="_blank" href="/demystifying-entropy-f2c3221e2550">https://towards data science . com/demystifying-entropy-f2c 3221 e 2550</a></p></div></div>    
</body>
</html>