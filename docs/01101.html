<html>
<head>
<title>Back-propagation Demystified in 7 Minutes</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">反向传播在 7 分钟内揭开神秘面纱</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/back-propagation-demystified-in-7-minutes-4294d71a04d7?source=collection_archive---------12-----------------------#2019-02-20">https://towardsdatascience.com/back-propagation-demystified-in-7-minutes-4294d71a04d7?source=collection_archive---------12-----------------------#2019-02-20</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><p id="13d4" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">在过去的 10 年里，表现最好的机器学习实现，如面部识别和语音识别器，都源于一种称为“深度学习”的技术深度学习由神经网络组成，神经网络是一种通过分析训练样本来执行某种任务的手段。神经网络的神经元如何从训练样本中学习？</p><p id="f982" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">有三个步骤。</p><ol class=""><li id="973a" class="ko kp it js b jt ju jx jy kb kq kf kr kj ks kn kt ku kv kw bi translated"><em class="kx">让你的神经网络猜测输出。</em></li><li id="5488" class="ko kp it js b jt ky jx kz kb la kf lb kj lc kn kt ku kv kw bi translated"><em class="kx">评估你的人际网络表现如何。</em></li><li id="b932" class="ko kp it js b jt ky jx kz kb la kf lb kj lc kn kt ku kv kw bi translated"><em class="kx">根据第二步的评估修改/训练你的神经网络。又名反向传播</em></li></ol><h1 id="431f" class="ld le it bd lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma bi translated">第一步。让你的神经网络向前传递猜测。</h1><p id="805b" class="pw-post-body-paragraph jq jr it js b jt mb jv jw jx mc jz ka kb md kd ke kf me kh ki kj mf kl km kn im bi translated">当你使用神经网络进行预测时，</p><figure class="mh mi mj mk gt ml gh gi paragraph-image"><div role="button" tabindex="0" class="mm mn di mo bf mp"><div class="gh gi mg"><img src="../Images/64529130095b6877000c11091725dfee.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Z-RMBvX41mRQ8BK3urvcuQ.png"/></div></div></figure><p id="3c4c" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">为了训练一个神经网络，你需要评估你的预测有多好。这就是损失函数发挥作用的时候。</p><h1 id="8e6f" class="ld le it bd lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma bi translated">第二步。评估你的网络做得有多好。</h1><figure class="mh mi mj mk gt ml gh gi paragraph-image"><div role="button" tabindex="0" class="mm mn di mo bf mp"><div class="gh gi ms"><img src="../Images/4ecb69c1965b30bb24a8ee327597a842.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*c1yt2y3s5qtrzxfRaMTheA.png"/></div></div></figure><p id="ddc0" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">损失函数将输出的预期值与神经网络的预测值进行比较。损失函数最常见的例子之一是<a class="ae mt" href="https://en.wikipedia.org/wiki/Mean_squared_error" rel="noopener ugc nofollow" target="_blank">均方误差</a> (MSE)。它会计算真实值和预测值之间的差异，并对其求平方。你对结果求平方的原因是为了使负差不相关。</p><figure class="mh mi mj mk gt ml gh gi paragraph-image"><div role="button" tabindex="0" class="mm mn di mo bf mp"><div class="gh gi mu"><img src="../Images/5718a1721e8bc083c0f030419397bdc2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*7On_d0wVmcB5gybhohEFFA.png"/></div></div></figure><p id="7ec9" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">如果你有多个预言和真理，这就是你所做的。</p><figure class="mh mi mj mk gt ml gh gi paragraph-image"><div role="button" tabindex="0" class="mm mn di mo bf mp"><div class="gh gi mv"><img src="../Images/f6c76b7163c8125a8c8d0e54d1960bcc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*yCXjsF7LYCNdHWNBW4jSVQ.png"/></div></div></figure><p id="f1dc" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">在这种情况下，</p><figure class="mh mi mj mk gt ml gh gi paragraph-image"><div role="button" tabindex="0" class="mm mn di mo bf mp"><div class="gh gi mw"><img src="../Images/204e187da37f4ce91b1937bd4b1f8121.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*kcliAZzJVPZo3KlmxbeaCQ.png"/></div></div></figure><p id="920e" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">你的损失函数会给出 36 的误差。你想让你的均方差尽可能的低。理想情况下，你想让它为 0，但我们会对任何足够接近它的值感到满意。</p><h1 id="5c9e" class="ld le it bd lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma bi translated">第三步。修改/教授你的神经网络</h1><p id="1b09" class="pw-post-body-paragraph jq jr it js b jt mb jv jw jx mc jz ka kb md kd ke kf me kh ki kj mf kl km kn im bi translated">你的误差值在下图的某处。你可能需要增加重量或者减少重量来达到最小误差。这个步骤叫做<strong class="js iu">反向传播</strong>。为了达到这个达到最小误差的目标，有多种方法可以采用。我将讨论两种流行的方法。</p><figure class="mh mi mj mk gt ml gh gi paragraph-image"><div role="button" tabindex="0" class="mm mn di mo bf mp"><div class="gh gi mx"><img src="../Images/d8339d19fcaa90c191a5367a9009afa1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*2QQC8W7Mmxu72BhKhY7W2g.png"/></div></div><figcaption class="my mz gj gh gi na nb bd b be z dk"><a class="ae mt" href="https://www.edureka.co/blog/backpropagation/" rel="noopener ugc nofollow" target="_blank">https://www.edureka.co/blog/backpropagation/</a></figcaption></figure><h2 id="f623" class="nc le it bd lf nd ne dn lj nf ng dp ln kb nh ni lr kf nj nk lv kj nl nm lz nn bi translated">方法 1。求导并设其等于 0，然后求解</h2><p id="84f6" class="pw-post-body-paragraph jq jr it js b jt mb jv jw jx mc jz ka kb md kd ke kf me kh ki kj mf kl km kn im bi translated">在微积分课上，我们学过，为了达到最优点，你可以对输入求函数的导数，设为 0，然后求解。</p><figure class="mh mi mj mk gt ml gh gi paragraph-image"><div role="button" tabindex="0" class="mm mn di mo bf mp"><div class="gh gi no"><img src="../Images/268f3db53563b97b254e0643b15eb4c8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*5AAF7Tj2z9Plg94V-Mf3ew.png"/></div></div></figure><p id="879a" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">通过求解<strong class="js iu"> w </strong>，我们得到<strong class="js iu"> w =真值/输入</strong>。在这种情况下，事实是 12，输入是 3，所以我们的 w 变成了 4。我们终于教会了我们的神经网络！</p><p id="a26d" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">这种方法简单快速，但并不总是有效，因为大多数损失函数没有封闭形式的导数。</p><h2 id="5cfd" class="nc le it bd lf nd ne dn lj nf ng dp ln kb nh ni lr kf nj nk lv kj nl nm lz nn bi translated">方法 2。梯度下降</h2><p id="509a" class="pw-post-body-paragraph jq jr it js b jt mb jv jw jx mc jz ka kb md kd ke kf me kh ki kj mf kl km kn im bi translated">微积分中的梯度是偏导数的集合。事实证明，梯度是最陡的上升方向。如果前面的句子让你感到困惑，你需要知道的是，当你求导时，这个值会告诉你，该往哪个方向走，才能到达图上的最高点。然而，我们想要到达最低点，因为我们的图的 y 轴是误差，并且我们想要最小化误差，我们将通过取梯度的负的值<strong class="js iu">来到达梯度的相反方向。</strong></p><figure class="mh mi mj mk gt ml gh gi paragraph-image"><div role="button" tabindex="0" class="mm mn di mo bf mp"><div class="gh gi np"><img src="../Images/ed5532721ea2cd182b7b841d03a056ca.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*vfglxAeL7CUhfG95vhVdLw.png"/></div></div><figcaption class="my mz gj gh gi na nb bd b be z dk"><a class="ae mt" href="https://www.youtube.com/watch?v=b4Vyma9wPHo" rel="noopener ugc nofollow" target="_blank">https://www.youtube.com/watch?v=b4Vyma9wPHo</a></figcaption></figure><p id="0f5d" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">你从图上的某个地方开始，为了达到最小值，你一直朝着梯度的相反方向前进。您可以在下面的 python 实现中看到梯度下降。</p><figure class="mh mi mj mk gt ml gh gi paragraph-image"><div role="button" tabindex="0" class="mm mn di mo bf mp"><div class="gh gi nq"><img src="../Images/7d60fde31a80724636cd9f421469e9b6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Ip_HlJZZejJVEm8NkGoSlQ.png"/></div></div></figure><h1 id="7ecf" class="ld le it bd lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma bi translated">链式法则</h1><p id="ee33" class="pw-post-body-paragraph jq jr it js b jt mb jv jw jx mc jz ka kb md kd ke kf me kh ki kj mf kl km kn im bi translated">在上面的例子中，只有一个权重，这在现实世界中并不常见。让我们来看一个多重权重的例子，以及如何应用链式法则来计算导数。</p><p id="9e10" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">我们将用图表来表示权重和损失函数。请注意,“a”和“b”代表权重,“f”代表我们希望最小化的损失函数。我们将使用链式法则来看看调整权重是如何影响输出的。</p><figure class="mh mi mj mk gt ml gh gi paragraph-image"><div role="button" tabindex="0" class="mm mn di mo bf mp"><div class="gh gi nr"><img src="../Images/96b78f1b2338e9749c9e69d91269e692.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*AhJ2SS6MptCRkq0_tz6pLA.png"/></div></div><figcaption class="my mz gj gh gi na nb bd b be z dk"><a class="ae mt" href="https://twitter.com/random_forests" rel="noopener ugc nofollow" target="_blank">https://twitter.com/random_forests</a></figcaption></figure><p id="6c32" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">损失相对于权重的梯度可以用两种方式表示，因为有两个权重。如果要为上面的向前传递定义一个函数，它应该是这样的:</p><figure class="mh mi mj mk gt ml gh gi paragraph-image"><div role="button" tabindex="0" class="mm mn di mo bf mp"><div class="gh gi ns"><img src="../Images/4e2bb3bb4c494d9e9d39e7b5d58b2418.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*fXbBl8yLKYj38D4y1TqXIA.png"/></div></div><figcaption class="my mz gj gh gi na nb bd b be z dk"><a class="ae mt" href="https://twitter.com/random_forests" rel="noopener ugc nofollow" target="_blank">https://twitter.com/random_forests</a></figcaption></figure><p id="e1ef" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">先来计算一下<strong class="js iu"> dL/da = df/da </strong>。问题是损失函数<strong class="js iu"> f </strong>不知道<strong class="js iu"> a </strong>。每个节点只知道它的相邻节点。</p><figure class="mh mi mj mk gt ml gh gi paragraph-image"><div role="button" tabindex="0" class="mm mn di mo bf mp"><div class="gh gi nt"><img src="../Images/a9a7b6d22df9485e482cd0ce47fb005a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*tREDSx4n2ddslOygsuO6eA.png"/></div></div><figcaption class="my mz gj gh gi na nb bd b be z dk"><a class="ae mt" href="https://twitter.com/random_forests" rel="noopener ugc nofollow" target="_blank">https://twitter.com/random_forests</a></figcaption></figure><p id="0659" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">因此，为了计算 df/da，需要使用<a class="ae mt" href="https://www.khanacademy.org/math/ap-calculus-ab/ab-differentiation-2-new/ab-3-1a/a/chain-rule-review" rel="noopener ugc nofollow" target="_blank">链式法则</a>。简单地说，当你有复合函数时，就要用到链式法则。</p><figure class="mh mi mj mk gt ml gh gi paragraph-image"><div class="gh gi nu"><img src="../Images/ed6228eb4e65b37aae28fca1408d8360.png" data-original-src="https://miro.medium.com/v2/resize:fit:788/1*EqcwwY7S6SPlCedG0ZXcLQ.gif"/></div><figcaption class="my mz gj gh gi na nb bd b be z dk"><a class="ae mt" href="https://i.pinimg.com/originals/c2/f1/a3/c2f1a350856c3ee7c66fdcec1c66b3f3.gif" rel="noopener ugc nofollow" target="_blank">https://i.pinimg.com/originals/c2/f1/a3/c2f1a350856c3ee7c66fdcec1c66b3f3.gif</a></figcaption></figure><p id="564a" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">由于 df/da 不能直接从不知道节点<strong class="js iu"> a </strong>的<strong class="js iu"> f </strong>节点中计算出来，所以你将做<strong class="js iu"> df/da = df/dc * dc/da。</strong></p><p id="48c3" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">现在，让我们计算<strong class="js iu"> dL/db = df/db </strong>。由于有两条边从节点 b 出来，当我们反向传播时，我们需要使用求和规则来添加两条路径到节点<strong class="js iu"> b </strong>。</p><figure class="mh mi mj mk gt ml gh gi paragraph-image"><div role="button" tabindex="0" class="mm mn di mo bf mp"><div class="gh gi nv"><img src="../Images/6fa84ad5d549807a75c2045adcfa794e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Zr8EA8wehfVJ5r2lEL7f2w.png"/></div></div><figcaption class="my mz gj gh gi na nb bd b be z dk"><a class="ae mt" href="https://twitter.com/random_forests" rel="noopener ugc nofollow" target="_blank">https://twitter.com/random_forests</a></figcaption></figure><p id="96fa" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">每条路径都可以用链式法则来计算:df/dc * dc/db 和 df/dd * dd/db，最后我们可以对它们求和。</p><p id="b917" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">实际上，这些权重是矢量化的，所以当我们进行反向传播时，所有权重都是同时计算的。</p><h1 id="6a6b" class="ld le it bd lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma bi translated">反向传播的复杂性</h1><p id="1c56" class="pw-post-body-paragraph jq jr it js b jt mb jv jw jx mc jz ka kb md kd ke kf me kh ki kj mf kl km kn im bi translated">让我们把我们的神经网络想象成一个图形。一个节点代表一个操作，一条边代表一个权重。为了计算每个权重的梯度，每个边必须至少访问一次。因此，反向传播的复杂度与边数成线性关系。</p><h1 id="2133" class="ld le it bd lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma bi translated">如何快速达到最低？</h1><p id="0055" class="pw-post-body-paragraph jq jr it js b jt mb jv jw jx mc jz ka kb md kd ke kf me kh ki kj mf kl km kn im bi translated">在反向传播时，有时可能需要一段时间才能达到最小值。你可以做一些小技巧/调整来快速达到最小值。</p><ol class=""><li id="5a92" class="ko kp it js b jt ju jx jy kb kq kf kr kj ks kn kt ku kv kw bi translated"><strong class="js iu">调整学习率</strong></li></ol><p id="daf6" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">学习率是您乘以梯度的值，要从损失函数中减去该值才能达到最小值。</p><figure class="mh mi mj mk gt ml gh gi paragraph-image"><div role="button" tabindex="0" class="mm mn di mo bf mp"><div class="gh gi nw"><img src="../Images/3a8aaf31c060c7ea5f73e1025dc3ff59.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*xcF9RNNIG7rSoncH2W2qTQ.png"/></div></div><figcaption class="my mz gj gh gi na nb bd b be z dk"><a class="ae mt" href="https://twitter.com/random_forests" rel="noopener ugc nofollow" target="_blank">https://twitter.com/random_forests</a></figcaption></figure><p id="fdef" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">如果你让学习率变小，你可以确保达到最小值，但这需要一段时间。</p><figure class="mh mi mj mk gt ml gh gi paragraph-image"><div role="button" tabindex="0" class="mm mn di mo bf mp"><div class="gh gi nx"><img src="../Images/8ae68646414ebe5ad3e124c59b219144.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*sIug1U01irFjvcyrWBxt0w.png"/></div></div><figcaption class="my mz gj gh gi na nb bd b be z dk"><a class="ae mt" href="https://twitter.com/random_forests" rel="noopener ugc nofollow" target="_blank">https://twitter.com/random_forests</a></figcaption></figure><p id="b5c3" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">如果你的学习率太大，你可能无法达到最小值，因为你可以跳过最小值。所以你想让学习率大到足以收敛到足够快接近最小值，然后再调整到足够小以达到最小值。</p><p id="b02c" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu"> 2。调整势头</strong></p><p id="f8a2" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">通过使用动量，过去步骤的梯度被累积，而不是仅使用当前步骤的梯度来引导搜索。</p><figure class="mh mi mj mk gt ml gh gi paragraph-image"><div role="button" tabindex="0" class="mm mn di mo bf mp"><div class="gh gi ny"><img src="../Images/0d0834daa80feb0a4c3855dfca89e00b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*RLI8jGv8uFdRjUk3xSD9tQ.png"/></div></div><figcaption class="my mz gj gh gi na nb bd b be z dk"><a class="ae mt" href="https://blog.paperspace.com/intro-to-optimization-momentum-rmsprop-adam/" rel="noopener ugc nofollow" target="_blank">https://blog.paperspace.com/intro-to-optimization-momentum-rmsprop-adam/</a></figcaption></figure><p id="cf22" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">使用动量的原因如下。在上图中，考虑点 a。如果我们将这些向量相加，相反的方向会抵消，因此沿着<strong class="js iu"> w1 </strong>方向的分量会抵消，但是<strong class="js iu"> w2 </strong>方向会增加，这是我们想要达到最优的理想路径。</p><p id="4ba4" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu"> 3。改变批量</strong></p><p id="2a6b" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">Batch 是计算梯度的整个训练集。您可以一次选择随机训练样本(<strong class="js iu">随机</strong>)或一次使用一小批数据(<strong class="js iu">小批量</strong>)，而不是使用整批数据。</p><figure class="mh mi mj mk gt ml gh gi paragraph-image"><div role="button" tabindex="0" class="mm mn di mo bf mp"><div class="gh gi nz"><img src="../Images/413719487b7a0bc8fb333bcb543d0c64.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*AqG5NPLN_uGFTg_pSN5jpw.png"/></div></div><figcaption class="my mz gj gh gi na nb bd b be z dk"><a class="ae mt" href="https://twitter.com/random_forests" rel="noopener ugc nofollow" target="_blank">https://twitter.com/random_forests</a></figcaption></figure><p id="83b0" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">随机方法大大减少了计算梯度下降的时间；然而，它一次只使用一个例子，所以它的最佳路径更嘈杂，比批梯度更随机。但是它不会有很大的影响，因为我们不关心这种方法走的是什么样的道路(只是现在)，只要在较短的训练时间内达到了最小点。</p><h1 id="58ea" class="ld le it bd lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma bi translated">本地和全局最小值</h1><p id="4a75" class="pw-post-body-paragraph jq jr it js b jt mb jv jw jx mc jz ka kb md kd ke kf me kh ki kj mf kl km kn im bi translated">如果我们有多个最小值，我们希望达到全局最小值。然而，我们可能会陷入局部最小值，如下图所示。</p><figure class="mh mi mj mk gt ml gh gi paragraph-image"><div role="button" tabindex="0" class="mm mn di mo bf mp"><div class="gh gi oa"><img src="../Images/db1c024bef9a5f0e04bb6c63c96c108c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*jddMSRiR1uVebViR6NwJAg.png"/></div></div><figcaption class="my mz gj gh gi na nb bd b be z dk"><a class="ae mt" href="https://twitter.com/random_forests" rel="noopener ugc nofollow" target="_blank">https://twitter.com/random_forests</a></figcaption></figure><p id="9a2b" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">在这种情况下，摆脱局部最小值的最佳方法是随机重启。摆脱局部最小值的一种方法是随机重启，这增加了在其他地方达到最小值的概率。</p><figure class="mh mi mj mk gt ml gh gi paragraph-image"><div role="button" tabindex="0" class="mm mn di mo bf mp"><div class="gh gi ob"><img src="../Images/70d1f13d1cd95cc7c9503e4f87d5d542.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*RWNGeMWmyc0TzAd8c4IXXA.png"/></div></div><figcaption class="my mz gj gh gi na nb bd b be z dk"><a class="ae mt" href="https://twitter.com/random_forests" rel="noopener ugc nofollow" target="_blank">https://twitter.com/random_forests</a></figcaption></figure></div></div>    
</body>
</html>