<html>
<head>
<title>Viewing text through the eyes of a machine</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">通过机器的眼睛看文本</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/viewing-text-through-the-eyes-of-a-machine-db30c744ee17?source=collection_archive---------11-----------------------#2019-05-27">https://towardsdatascience.com/viewing-text-through-the-eyes-of-a-machine-db30c744ee17?source=collection_archive---------11-----------------------#2019-05-27</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="8a8f" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">如何让黑盒语言模型更加透明</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/a84c943e6585ae7818acbf1d00036951.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*hKeqIQawev6-vyDN8KmGyw.png"/></div></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk">Visualising how machines read text. In this article we will build a heatmap to identify where a text model is ‘reading’ to determine whether a coffee is a light or dark roast</figcaption></figure><p id="3c6c" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">多年来，我们已经能够在计算机视觉任务中揭开卷积神经网络(CNN)的盖子。这给该领域带来了重大改进，具体表现在:</p><ul class=""><li id="766b" class="lu lv it la b lb lc le lf lh lw ll lx lp ly lt lz ma mb mc bi translated">提高模型的稳健性；</li><li id="3978" class="lu lv it la b lb md le me lh mf ll mg lp mh lt lz ma mb mc bi translated">模型偏差的可见性和减少；和</li><li id="e088" class="lu lv it la b lb md le me lh mf ll mg lp mh lt lz ma mb mc bi translated">更好地理解对立图像如何改变深度学习模型的输出。</li></ul><p id="7a3a" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">既然更好的模型理解带来了如此明显的好处，为什么我们在自然语言处理(NLP)领域对模型可解释性的关注程度似乎不一样呢？</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi mi"><img src="../Images/fe40369f4c0cd9c0c6d8567f504bd29a.png" data-original-src="https://miro.medium.com/v2/resize:fit:980/format:webp/0*FHh8H_K0ttpAyKog.png"/></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk">This is what a neural network thinks dumbbells look like. Notice that the model has not separated arms from weights in this case and therefore has not learned generalised representations of this class. Photo from <a class="ae mj" href="https://ai.googleblog.com/2015/06/inceptionism-going-deeper-into-neural.html" rel="noopener ugc nofollow" target="_blank">Google AI Blog</a></figcaption></figure><h1 id="e39f" class="mk ml it bd mm mn mo mp mq mr ms mt mu jz mv ka mw kc mx kd my kf mz kg na nb bi translated">创建一个 CNN 正在看的地方的可视化:</h1><p id="b3bb" class="pw-post-body-paragraph ky kz it la b lb nc ju ld le nd jx lg lh ne lj lk ll nf ln lo lp ng lr ls lt im bi translated">在这篇文章中，我们将看到如何应用同样的技术来理解基于视觉的 CNN 在看什么，并将其应用于文本。然后，我们将创建一个热图，显示 CNN 在输入文本的特定区域“聚焦”的位置，以便进行分类。</p><p id="3472" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">是的，我知道，在 GPT-2，伯特，埃尔莫等时代，CNN 现在被认为有点“过时”。然而，它们仍然提供了很好的现实世界性能，没有这些尖端模型带来的大模型大小，长推理时间和大内存使用。</p><h2 id="a11e" class="nh ml it bd mm ni nj dn mq nk nl dp mu lh nm nn mw ll no np my lp nq nr na ns bi translated">预测咖啡烘焙:</h2><p id="e6ba" class="pw-post-body-paragraph ky kz it la b lb nc ju ld le nd jx lg lh ne lj lk ll nf ln lo lp ng lr ls lt im bi translated">为了浏览一个例子，我们将首先建立一个简单的分类器，根据它的描述来预测一杯咖啡是浅烘焙咖啡还是深烘焙咖啡。</p><p id="b2b6" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">我们的数据集是一系列咖啡评论。在这张桌子上，我们将使用盲品笔记来尝试预测烘焙的颜色是浅还是深。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nt"><img src="../Images/148591ee8025d1558c1f076994bb01af.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*D392IAYlwofiysnux3w90g.png"/></div></div></figure><p id="9c47" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">在 Keras 中构建 CNN 并根据这些数据对其进行训练的代码如下:</p><pre class="kj kk kl km gt nu nv nw nx aw ny bi"><span id="e40a" class="nh ml it nv b gy nz oa l ob oc">X = df.blind_assesment.values<br/>y = df.y.values</span><span id="80e8" class="nh ml it nv b gy od oa l ob oc">tokenizer = Tokenizer(num_words=4000)<br/>tokenizer.fit_on_texts(X)</span><span id="ba97" class="nh ml it nv b gy od oa l ob oc">X = tokenizer.texts_to_sequences(X)</span><span id="d6f8" class="nh ml it nv b gy od oa l ob oc">vocab_size = len(tokenizer.word_index) + 1  # Adding 1 because of reserved 0 index</span><span id="6936" class="nh ml it nv b gy od oa l ob oc">maxlen = 200<br/>embedding_dim = 50</span><span id="af7d" class="nh ml it nv b gy od oa l ob oc">X = pad_sequences(X, padding='post', maxlen=maxlen)</span><span id="a968" class="nh ml it nv b gy od oa l ob oc">sequence_input = layers.Input(shape=(maxlen,), dtype='int32')<br/>embedded_sequences = layers.Embedding(vocab_size, embedding_dim, input_length=maxlen)(sequence_input)<br/>l_cov1  = layers.Conv1D(317, 3, activation='relu')(embedded_sequences)<br/>l_pool1 = layers.MaxPooling1D(2)(l_cov1)<br/>l_cov2  = layers.Conv1D(317, 1, activation='relu')(l_pool1)<br/>l_cov3  = layers.Conv1D(317, 2, activation='relu')(l_cov2)<br/>l_pool3 = layers.GlobalMaxPooling1D()(l_cov3)  # global max pooling<br/>l_bnorm = layers.BatchNormalization()(l_pool3)<br/>l_dense = layers.Dense(128, activation='relu')(l_pool3)<br/>preds   = layers.Dense(1, activation='sigmoid',name='preds')(l_dense)</span><span id="4bf7" class="nh ml it nv b gy od oa l ob oc">model = Model(sequence_input, outputs=preds)</span><span id="6ebc" class="nh ml it nv b gy od oa l ob oc">model.compile(optimizer='adam',<br/>              loss='binary_crossentropy',<br/>              metrics=['accuracy'])<br/>model.summary()</span><span id="1229" class="nh ml it nv b gy od oa l ob oc">model.fit(X, y, epochs=3, validation_split=0.1, batch_size=10)</span></pre><p id="7024" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">如果 Keras 中的模型看起来有点不同，这是因为它使用了函数式 API ( <a class="ae mj" href="https://keras.io/getting-started/functional-api-guide/" rel="noopener ugc nofollow" target="_blank">这里有更多细节</a>)。该代码训练并拟合模型，验证准确率约为 75–80%。有很多关于构建 CNN 文本分类器的其他帖子，所以我在这里不再赘述。相反，我们将关注如何解释这个分类器做出的预测。</p><h2 id="8ca8" class="nh ml it bd mm ni nj dn mq nk nl dp mu lh nm nn mw ll no np my lp nq nr na ns bi translated">创建激活图:</h2><p id="e513" class="pw-post-body-paragraph ky kz it la b lb nc ju ld le nd jx lg lh ne lj lk ll nf ln lo lp ng lr ls lt im bi translated">使用 Keras，这既快速又简单，只需要几行代码:</p><ol class=""><li id="4938" class="lu lv it la b lb lc le lf lh lw ll lx lp ly lt oe ma mb mc bi translated">得到模型预测和网络的最终 CNN 层:</li></ol><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi of"><img src="../Images/e391b2dc5cf3449b0e2c35dde4b8060b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*lrrGBUY6yHzZKvUIQIgN_Q.png"/></div></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk">You can get a breakdown of the model structure in Keras using model.summary(). Here conv1d_45 is the name of the final CNN layer in the model</figcaption></figure><p id="89ad" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">然后，以下代码获取预测类和最后一个 CNN 图层:</p><pre class="kj kk kl km gt nu nv nw nx aw ny bi"><span id="3109" class="nh ml it nv b gy nz oa l ob oc">class_idx = np.argmax(y_pred[0]) #not needed in this case as only two classes<br/>class_output = model.output[:, class_idx]<br/>last_conv_layer = model.get_layer("conv1d_45")</span></pre><p id="1171" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">2.由此，我们可以计算类输出相对于特征图的梯度，然后汇集所有的梯度。这听起来很复杂，但使用 Keras 后端函数，只需几行代码就可以完成:</p><pre class="kj kk kl km gt nu nv nw nx aw ny bi"><span id="9a97" class="nh ml it nv b gy nz oa l ob oc">grads = K.gradients(class_output, last_conv_layer.output)[0]<br/>pooled_grads = K.mean(grads)<br/>iterate = K.function([model.input], [pooled_grads, last_conv_layer.output[0]])<br/>pooled_grads_value, conv_layer_output_value = iterate([Xtst])</span></pre><p id="d19c" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">3.然后，我们对该特征图进行平均，并将其归一化到 0 和 1 之间:</p><pre class="kj kk kl km gt nu nv nw nx aw ny bi"><span id="df33" class="nh ml it nv b gy nz oa l ob oc">heatmap = np.mean(conv_layer_output_value, axis=-1)<br/>heatmap = np.maximum(heatmap,0)<br/>heatmap /= np.max(heatmap)#normalise values in the prediction</span></pre><p id="7d31" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">我们现在有了预测类在最后一个 CNN 层的输出形状长度上的激活热图。我们现在需要做的就是根据原始输入的长度(单词数)来调整(拉伸)它，以了解哪些单词触发了网络。</p><h2 id="0a77" class="nh ml it bd mm ni nj dn mq nk nl dp mu lh nm nn mw ll no np my lp nq nr na ns bi translated">用 HTML 可视化输出:</h2><p id="8cc5" class="pw-post-body-paragraph ky kz it la b lb nc ju ld le nd jx lg lh ne lj lk ll nf ln lo lp ng lr ls lt im bi translated">向最终预测添加一些基本的 HTML 可以创建一个非常有影响力的用户界面，同时增加了理解模型如何达到其预测的能力:</p><pre class="kj kk kl km gt nu nv nw nx aw ny bi"><span id="f092" class="nh ml it nv b gy nz oa l ob oc">norm_len = maxlen/last_conv_layer.output_shape[1] # find the ratio of the text vs the conv layer length</span><span id="db0c" class="nh ml it nv b gy od oa l ob oc">html = ""<br/>if y_pred[0]&gt;0.5:<br/>  pred = 'light'<br/>else:<br/>  pred = 'dark'<br/>html += "&lt;span&gt;&lt;h3&gt;Based on the description, the model believes that this is a {} coffee roast. ".format(pred)<br/>html += "&lt;small&gt;&lt;br&gt;Confidence: {:.0f}%&lt;br&gt;&lt;br&gt;&lt;/small&gt;&lt;/h3&gt;&lt;/span&gt;".format(abs(((y_pred[0][0]*100)-50)*2))<br/>for j,i in enumerate(tokenizer.sequences_to_texts(Xtst)[0].split()):<br/>  html += "&lt;span style='background-color:rgba({},0,150,{})'&gt;{} &lt;/span&gt;".format(heatmap[math.floor(j/norm_len)]*255,heatmap[math.floor(j/norm_len)]-0.3,i)</span><span id="0492" class="nh ml it nv b gy od oa l ob oc">HTML(html)</span></pre><p id="b6a8" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">这个 HTML 片段在 Google Colab 中创建了以下输出:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi og"><img src="../Images/d4d9d1f7f7cc7956aacd4351472897c8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*kbJf4O-En-r6dsL95Xxkfg.png"/></div></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk">Here we can see the model has ‘read’ that the coffee in question has tastes of ‘wild strawberry’ and has a ‘sweet’, ‘fresh acidity’ and is therefore (correctly) confident that this is a light roast.</figcaption></figure><p id="ab72" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">总之，在本文中，我们已经看到了如何轻松地突出显示模型正在“阅读”的文本区域，以进行预测。这些信息对于以下工作至关重要:</p><ol class=""><li id="fe5a" class="lu lv it la b lb lc le lf lh lw ll lx lp ly lt oe ma mb mc bi translated">执行基本模型调试和意义检查。</li><li id="78cb" class="lu lv it la b lb md le me lh mf ll mg lp mh lt oe ma mb mc bi translated">更好地理解为什么模型会对训练样本进行错误分类。</li><li id="d07b" class="lu lv it la b lb md le me lh mf ll mg lp mh lt oe ma mb mc bi translated">检测潜在的模型偏差。</li></ol><p id="3424" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">感谢阅读。如果你有任何问题，请在评论中告诉我。</p><p id="313e" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">完整的代码可以在下面的 Colab 笔记本中找到:</p><div class="oh oi gp gr oj ok"><a href="https://colab.research.google.com/drive/1taIt9A9tsENJTYh3eK0ZuUyRIdrHeNty" rel="noopener  ugc nofollow" target="_blank"><div class="ol ab fo"><div class="om ab on cl cj oo"><h2 class="bd iu gy z fp op fr fs oq fu fw is bi translated">CNN 文字热图</h2><div class="or l"><h3 class="bd b gy z fp op fr fs oq fu fw dk translated">文本可解释性</h3></div><div class="os l"><p class="bd b dl z fp op fr fs oq fu fw dk translated">colab.research.google.com</p></div></div><div class="ot l"><div class="ou l ov ow ox ot oy ks ok"/></div></div></a></div></div></div>    
</body>
</html>