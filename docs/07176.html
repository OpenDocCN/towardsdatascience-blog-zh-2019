<html>
<head>
<title>The Deep Music Visualizer: Using sound to explore the latent space of BigGAN</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">深度音乐可视化:用声音探索比根的潜在空间</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/the-deep-music-visualizer-using-sound-to-explore-the-latent-space-of-biggan-198cd37dac9a?source=collection_archive---------5-----------------------#2019-10-10">https://towardsdatascience.com/the-deep-music-visualizer-using-sound-to-explore-the-latent-space-of-biggan-198cd37dac9a?source=collection_archive---------5-----------------------#2019-10-10</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="c4c5" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">人工智能艺术家、视觉骑师、联觉者和心理学家的工具。</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/d255f34a51e061efbd550f5659045bdb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*UnHAs2pfQAhVYRAo40yemA.jpeg"/></div></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk">A deep musician</figcaption></figure><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="ky kz l"/></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk">A deep music video</figcaption></figure><p id="5881" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">想做一个有深度的音乐视频？把你的思想放在比根身上。由<a class="ae lw" href="https://arxiv.org/abs/1809.11096" rel="noopener ugc nofollow" target="_blank">布洛克等人(2018) </a>在谷歌开发的 BigGAN 是生成对抗网络(GANs)的<a class="ae lw" href="https://blog.floydhub.com/gans-story-so-far/" rel="noopener ugc nofollow" target="_blank">简史</a>中的最近一章。gan 是由两个竞争的神经网络训练的人工智能模型:一个生成器基于从一组示例图像中学习的统计模式创建新图像，一个鉴别器试图将图像分类为真实或虚假。通过训练发生器欺骗鉴别器，甘人学会了创造逼真的图像。</p><p id="9dbb" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">BigGAN 被认为是大的，因为它包含了在数百个谷歌 TPU 上训练的超过 3 亿个参数，估计花费了 6 万美元。结果是一个人工智能模型，它从 1128 个输入参数中生成图像:</p><p id="cdbd" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">I)对应于 1000 个<a class="ae lw" href="https://gist.github.com/yrevar/942d3a0ac09ec9e5eb3a" rel="noopener ugc nofollow" target="_blank"> ImageNet 类</a>或对象类别的权重{0 ≤ 1}的 1000 单位<strong class="lc iu">类向量</strong>。</p><p id="e84c" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">ii)128 单位的噪声向量<strong class="lc iu">的值{-2 ≤ 2}，控制输出图像中对象的视觉特征，如颜色、大小、位置和方向。</strong></p><p id="6d0a" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">在<em class="lx">花瓶</em>类中，除了 1 以外的 0 的类向量输出一个花瓶:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ly"><img src="../Images/b7b145c66c723061776c4c81c69ec878.png" data-original-src="https://miro.medium.com/v2/resize:fit:512/format:webp/1*jDEbiOM9ikvJ14d0VtDpLg.png"/></div></figure><p id="a189" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">在不改变噪声向量的情况下在类别之间进行插值揭示了潜在空间中的共享特征，如人脸:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ly"><img src="../Images/7166462abee5d66fc1928865add93870.png" data-original-src="https://miro.medium.com/v2/resize:fit:512/1*Y_Pgg5A9pOIW76bMILTj_Q.gif"/></div></figure><p id="87a4" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">随机向量之间的插值揭示了<em class="lx">更深层次的</em>结构:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ly"><img src="../Images/792dd8f3ffbfd6ffabee3f6b8032ff2e.png" data-original-src="https://miro.medium.com/v2/resize:fit:512/1*wdxNOILInl0i96jZUes1Eg.gif"/></div></figure><p id="6871" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">如果你感兴趣，加入艺术家、计算机科学家和神秘动物学家在这个陌生前沿的探险。像<a class="ae lw" href="https://artbreeder.com/" rel="noopener ugc nofollow" target="_blank">art breader</a>这样的应用程序已经为创建人工智能艺术品提供了简单的界面，当一些用户忙于搜索蒙娜丽莎时<a class="ae lw" href="https://medium.com/@genekogan/artist-in-the-cloud-8384824a75c7" rel="noopener">自主人工艺术家</a>出现了。</p><p id="3b05" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">其他人给比根配乐。</p><p id="3855" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">这些“深度音乐视频”获得了不同的反应，在<em class="lx">美丽、迷幻、</em>和<em class="lx">恐怖</em>之间变化。平心而论，明智的做法是害怕潜伏在潜在空间中的东西…</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="lz kz l"/></div></figure><p id="19b5" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">还有哪些不太可能的嵌合体、神秘的生物、无价的艺术品和熟悉的梦居住在比根？为了找到答案，我们需要覆盖更多的区域。这就是为什么我建立了 deep music visualizer，一个开源的，易于使用的工具，用声音导航潜在的空间。</p><p id="1d73" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">一艘隐形飞船，带蓝牙。</p><p id="ce6e" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">带着它转一圈，一路上创作一些很酷的音乐视频。一定要分享你的发现。</p></div><div class="ab cl ma mb hx mc" role="separator"><span class="md bw bk me mf mg"/><span class="md bw bk me mf mg"/><span class="md bw bk me mf"/></div><div class="im in io ip iq"><h1 id="5924" class="mh mi it bd mj mk ml mm mn mo mp mq mr jz ms ka mt kc mu kd mv kf mw kg mx my bi translated">教程:使用深度音乐可视化工具</h1><p id="e670" class="pw-post-body-paragraph la lb it lc b ld mz ju lf lg na jx li lj nb ll lm ln nc lp lq lr nd lt lu lv im bi translated">克隆 GitHub 库，并遵循<a class="ae lw" href="https://github.com/msieg/deep-music-visualizer/blob/master/README.md" rel="noopener ugc nofollow" target="_blank">自述文件</a>中的安装说明。</p><div class="ne nf gp gr ng nh"><a href="https://github.com/msieg/deep-music-visualizer" rel="noopener  ugc nofollow" target="_blank"><div class="ni ab fo"><div class="nj ab nk cl cj nl"><h2 class="bd iu gy z fp nm fr fs nn fu fw is bi translated">msieg/深度音乐可视化工具</h2><div class="no l"><h3 class="bd b gy z fp nm fr fs nn fu fw dk translated">深度音乐可视化器使用 BigGAN (Brock et al .，2018)，一种生成神经网络来可视化音乐。像这样…</h3></div><div class="np l"><p class="bd b dl z fp nm fr fs nn fu fw dk translated">github.com</p></div></div><div class="nq l"><div class="nr l ns nt nu nq nv ks nh"/></div></div></a></div><p id="cd26" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">在您的终端中运行以下命令:</p><pre class="kj kk kl km gt nw nx ny nz aw oa bi"><span id="9e28" class="ob mi it nx b gy oc od l oe of">python visualize.py --song beethoven.mp3</span></pre><p id="1d19" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">就是这样。以下是输出结果:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="ky kz l"/></div></figure><p id="b85a" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">这是怎么回事？deep music visualizer 将<em class="lx"> pitch </em>与类向量同步，将<em class="lx">音量和速度</em>与噪声向量同步，这样 pitch 控制每一帧中的对象、形状和纹理，而音量和速度控制帧之间的移动。在歌曲的每个时间点，十二个半音音符的色度图确定类别向量中多达十二个<a class="ae lw" href="https://gist.github.com/yrevar/942d3a0ac09ec9e5eb3a" rel="noopener ugc nofollow" target="_blank"> ImageNet 类别</a>的权重<em class="lx"> </em> {0 ≤ 1}。独立地，音量(主要是打击乐)的变化率控制噪声矢量的变化率。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi og"><img src="../Images/04a67ab4b1c3041417da2e8363fbc8f5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*FKaaLad96Mhqsx4W_ShQTw.jpeg"/></div></div></figure><h1 id="d60e" class="mh mi it bd mj mk oh mm mn mo oi mq mr jz oj ka mt kc ok kd mv kf ol kg mx my bi translated">视频定制</h1><h2 id="7ca3" class="ob mi it bd mj om on dn mn oo op dp mr lj oq or mt ln os ot mv lr ou ov mx ow bi translated">解决</h2><ul class=""><li id="3528" class="ox oy it lc b ld mz lg na lj oz ln pa lr pb lv pc pd pe pf bi translated">128、256 或 512</li><li id="1dd4" class="ox oy it lc b ld pg lg ph lj pi ln pj lr pk lv pc pd pe pf bi translated"><strong class="lc iu">默认值</strong> : 512</li></ul><p id="204e" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">比根很大，因此很慢。如果你在笔记本电脑上运行第一个例子，大概需要 7 个小时来渲染。分辨率为 128x128，只需 25 分钟(每分钟视频)。</p><pre class="kj kk kl km gt nw nx ny nz aw oa bi"><span id="1277" class="ob mi it nx b gy oc od l oe of">python visualize.py --song beethoven.mp3 --resolution 128</span></pre><p id="ac76" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">然而，我建议你通过在 google cloud 上启动<a class="ae lw" href="https://medium.com/@jamsawamsa/running-a-google-cloud-gpu-for-fast-ai-for-free-5f89c707bae6" rel="noopener">虚拟 GPU 来生成高分辨率视频，从而将运行时间从大约 7 个小时大幅缩短到几分钟。虽然它不是免费的，但谷歌会奖励新用户 300 美元的积分，而 GPU 的费用是每小时 1 美元。</a></p><h2 id="b0b5" class="ob mi it bd mj om on dn mn oo op dp mr lj oq or mt ln os ot mv lr ou ov mx ow bi translated">持续时间(秒)</h2><ul class=""><li id="6d1e" class="ox oy it lc b ld mz lg na lj oz ln pa lr pb lv pc pd pe pf bi translated">整数≥ 1</li><li id="509f" class="ox oy it lc b ld pg lg ph lj pi ln pj lr pk lv pc pd pe pf bi translated"><strong class="lc iu">默认</strong>:音频全长</li></ul><p id="775e" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">在测试一些其他输入参数时，生成较短的视频以限制运行时间可能是有用的。</p><h2 id="dc39" class="ob mi it bd mj om on dn mn oo op dp mr lj oq or mt ln os ot mv lr ou ov mx ow bi translated">音高敏感度</h2><ul class=""><li id="a7f1" class="ox oy it lc b ld mz lg na lj oz ln pa lr pb lv pc pd pe pf bi translated">范围:1–299</li><li id="dc5b" class="ox oy it lc b ld pg lg ph lj pi ln pj lr pk lv pc pd pe pf bi translated"><strong class="lc iu">默认</strong> : 220</li></ul><p id="374e" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">音高敏感度是类别向量对音高变化的敏感度。在更高的音高敏感度下，视频中的形状、纹理和对象变化更快，并且更精确地符合音乐中的音符。</p><h2 id="e8fb" class="ob mi it bd mj om on dn mn oo op dp mr lj oq or mt ln os ot mv lr ou ov mx ow bi translated">速度敏感度</h2><ul class=""><li id="7b88" class="ox oy it lc b ld mz lg na lj oz ln pa lr pb lv pc pd pe pf bi translated">范围:0 ≤ 1</li><li id="bf6d" class="ox oy it lc b ld pg lg ph lj pi ln pj lr pk lv pc pd pe pf bi translated"><strong class="lc iu">默认值</strong> : 0.25</li></ul><p id="4211" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">速度敏感度是噪声向量对音量和速度变化的敏感度。更高的速度敏感度产生更多的运动。</p><p id="a857" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">在本例中，由于音高敏感度较高，类与音高紧密相关，但由于速度敏感度较低，整体运动很少。</p><pre class="kj kk kl km gt nw nx ny nz aw oa bi"><span id="af28" class="ob mi it nx b gy oc od l oe of">python visualize.py --song moon_river.mp3 --duration 60<br/>--pitch_sensitivity 290 --tempo_sensitivity 0</span></pre><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="ky kz l"/></div></figure><p id="25f0" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">在本例中，由于音高敏感度较低，类别混合几乎没有变化，但由于速度敏感度较高，整体移动较多。</p><pre class="kj kk kl km gt nw nx ny nz aw oa bi"><span id="8e2a" class="ob mi it nx b gy oc od l oe of">python visualize.py --song moon_river.mp3 --duration 60<br/>--pitch_sensitivity 10 --tempo_sensitivity 0.6</span></pre><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="ky kz l"/></div></figure><h2 id="9e84" class="ob mi it bd mj om on dn mn oo op dp mr lj oq or mt ln os ot mv lr ou ov mx ow bi translated">民数记班</h2><ul class=""><li id="a8fb" class="ox oy it lc b ld mz lg na lj oz ln pa lr pb lv pc pd pe pf bi">1–12</li><li id="b315" class="ox oy it lc b ld pg lg ph lj pi ln pj lr pk lv pc pd pe pf bi translated"><strong class="lc iu">默认</strong> : 12</li></ul><p id="238a" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">减少类的数量以混合更少的对象。</p><h2 id="9ab1" class="ob mi it bd mj om on dn mn oo op dp mr lj oq or mt ln os ot mv lr ou ov mx ow bi translated">班级</h2><ul class=""><li id="3b38" class="ox oy it lc b ld mz lg na lj oz ln pa lr pb lv pc pd pe pf bi translated">多达 12 个索引{ 0–999 }，对应于 1000 个 ImageNet 类</li><li id="b484" class="ox oy it lc b ld pg lg ph lj pi ln pj lr pk lv pc pd pe pf bi translated"><strong class="lc iu">默认</strong>:12 个随机指数</li></ul><p id="17f3" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">您可以选择要在视频中包含哪些课程。这些类别按照半音顺序(A、A#、B…)与音高同步。</p><p id="c87b" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">或者，如果您喜欢按优先顺序输入类，则将<strong class="lc iu"> sort_classes_by_power </strong>设置为 1。</p><p id="76fb" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">在这个例子中，视频包括<em class="lx">雏菊</em> (#985)和<em class="lx">水母</em> (#107)，但其中<em class="lx">雏菊</em>比<em class="lx">水母多:</em></p><pre class="kj kk kl km gt nw nx ny nz aw oa bi"><span id="f1b5" class="ob mi it nx b gy oc od l oe of">python visualize.py --song cold.mp3 --duration 10 <br/>--pitch_sensitivity 260 --tempo_sensitivity 0.8 --num_classes 2 <br/>--classes 985 107 --sort_classes_by_power 1</span></pre><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="ky kz l"/></div></figure><h2 id="4721" class="ob mi it bd mj om on dn mn oo op dp mr lj oq or mt ln os ot mv lr ou ov mx ow bi translated">帧长度</h2><ul class=""><li id="d7f4" class="ox oy it lc b ld mz lg na lj oz ln pa lr pb lv pc pd pe pf bi translated">64 的倍数</li><li id="a824" class="ox oy it lc b ld pg lg ph lj pi ln pj lr pk lv pc pd pe pf bi translated"><strong class="lc iu">默认:</strong> 512</li></ul><p id="899b" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">帧长度是每个视频帧中音频样本的数量。默认帧长度为 512，视频帧速率约为 43 fps。减少帧长度会增加帧速率，因此图像会更频繁地更新(但视频会花费更长的时间来渲染)。这对于可视化快速音乐非常有用。</p><pre class="kj kk kl km gt nw nx ny nz aw oa bi"><span id="df98" class="ob mi it nx b gy oc od l oe of">python visualize.py --song T69_collapse.mp3 --duration 30 --num_classes 4 --classes 527 511 545 611 --sort_classes_by_power 1 <br/>--frame_length 128</span></pre><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="ky kz l"/></div></figure></div><div class="ab cl ma mb hx mc" role="separator"><span class="md bw bk me mf mg"/><span class="md bw bk me mf mg"/><span class="md bw bk me mf"/></div><div class="im in io ip iq"><p id="97fe" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">我希望你觉得这个教程很有趣，内容丰富。如果你想表达感谢，<a class="ae lw" href="https://twitter.com/MattSiegelman" rel="noopener ugc nofollow" target="_blank">发推特给我</a>一个你用这段代码创作的深度音乐视频！</p><p id="62f0" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">你可以在这里找到更多我的视频。</p><h1 id="5ee7" class="mh mi it bd mj mk oh mm mn mo oi mq mr jz oj ka mt kc ok kd mv kf ol kg mx my bi translated">开放式问题</h1><ul class=""><li id="2ca0" class="ox oy it lc b ld mz lg na lj oz ln pa lr pb lv pc pd pe pf bi translated">甘斯<em class="lx">不能</em>创造什么样的艺术？艺术一定要模仿现实吗？</li><li id="da6e" class="ox oy it lc b ld pg lg ph lj pi ln pj lr pk lv pc pd pe pf bi translated">音乐有内在的视觉结构吗？某些声音、乐器、歌曲和流派是否由某些 ImageNet 类更好地表示？有联觉的人可能会这么想。</li><li id="6c55" class="ox oy it lc b ld pg lg ph lj pi ln pj lr pk lv pc pd pe pf bi translated">比格根的艺术能力是不是可以用深度神经网络和人类视觉皮层之间的<a class="ae lw" href="https://www.annualreviews.org/doi/10.1146/annurev-vision-082114-035447" rel="noopener ugc nofollow" target="_blank">表征相似性来解释？如果是这样，潜在空间能代表人类想象力的拓扑图吗？BigGAN 能预测物体的可成像性吗？例如，想象一个挂钟。你真的想象过所有的数字吗？</a><a class="ae lw" href="https://twitter.com/MichaelFriese10/status/1169756130391650306?ref_src=twsrc%5Etfw" rel="noopener ugc nofollow" target="_blank">比根</a>也没有。</li></ul><h1 id="159e" class="mh mi it bd mj mk oh mm mn mo oi mq mr jz oj ka mt kc ok kd mv kf ol kg mx my bi translated">未来项目</h1><ul class=""><li id="3b9e" class="ox oy it lc b ld mz lg na lj oz ln pa lr pb lv pc pd pe pf bi translated">构建一个实时响应现场音乐的可视化工具。</li><li id="c059" class="ox oy it lc b ld pg lg ph lj pi ln pj lr pk lv pc pd pe pf bi translated">使用自然语言处理基于与歌词(或有声读物)的语义关联来自动选择 ImageNet 类。</li><li id="a100" class="ox oy it lc b ld pg lg ph lj pi ln pj lr pk lv pc pd pe pf bi translated">在 fMRI 中向人们播放音乐，并将类别和噪声向量与神经活动相结合，以创建来自大脑的深度音乐视频。</li><li id="1dfb" class="ox oy it lc b ld pg lg ph lj pi ln pj lr pk lv pc pd pe pf bi translated">所有这些同时发生吗？</li></ul></div><div class="ab cl ma mb hx mc" role="separator"><span class="md bw bk me mf mg"/><span class="md bw bk me mf mg"/><span class="md bw bk me mf"/></div><div class="im in io ip iq"><h2 id="468e" class="ob mi it bd mj om on dn mn oo op dp mr lj oq or mt ln os ot mv lr ou ov mx ow bi translated">参考</h2><p id="61d7" class="pw-post-body-paragraph la lb it lc b ld mz ju lf lg na jx li lj nb ll lm ln nc lp lq lr nd lt lu lv im bi translated">[1] A. Brock，J. Donahu 和 K. Simonyan，高保真自然图像合成的大规模 GAN 训练(2018)，第八届学习表示国际会议。</p><p id="3dcf" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">[2] N. Kriegeskorte，深度神经网络:生物视觉和大脑信息处理建模的新框架(2015)，视觉科学年度评论。</p></div></div>    
</body>
</html>