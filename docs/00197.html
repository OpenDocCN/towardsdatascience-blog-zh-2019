<html>
<head>
<title>Sound UX</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">声音 UX</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/sound-ux-sound-representation-of-machine-learning-estimation-on-image-and-temperature-data-by-5b71bb4bb745?source=collection_archive---------29-----------------------#2019-01-08">https://towardsdatascience.com/sound-ux-sound-representation-of-machine-learning-estimation-on-image-and-temperature-data-by-5b71bb4bb745?source=collection_archive---------29-----------------------#2019-01-08</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="783b" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">通过粒度合成对图像和温度数据进行机器学习估计的声音表示</h2></div><p id="9c14" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">本研究的目的是通过发音显示捕获的图像和温度数据。发音是一种将各种数据转换为声音的技术，用于辅助功能、媒体艺术和交互设计。我们提出了一种系统，通过图像和温度数据中的机器学习，根据移动对象之间的最小距离和路径预测来生成声音。声音依赖于基于 k-means、拟合和光流的路径预测数据的最小距离，并通过粒度合成和拍现象声音来设计。我们还检查了光流上的流动矢量图像分类和结果的声音分配。</p><p id="6a74" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">本研究中考虑了环境智能，并提出了智能空间的概念，其中设备通过各种协议连接。环境智能必须是嵌入式的、环境感知的、个性化的、自适应的和预期的。[1]机器学习和人工智能是实现自适应和预期功能的关键技术。我们已经通过对象跟踪和对象识别考虑了环境空间，并且已经假设该空间具有通过各种协议彼此连接的设备，具有智能并且通过声音激活来提供服务。我们也考虑基于几种方法的研究，如 r .默里·斯查费和巴里·特鲁阿克斯提倡的声景、交互设计和媒体艺术</p><h2 id="04fc" class="lb lc iq bd ld le lf dn lg lh li dp lj ko lk ll lm ks ln lo lp kw lq lr ls lt bi translated"><strong class="ak">发音和机器学习</strong></h2><figure class="lv lw lx ly gt lz gh gi paragraph-image"><div class="gh gi lu"><img src="../Images/e7f2dd53cda8206584807420c2cc9bfa.png" data-original-src="https://miro.medium.com/v2/resize:fit:1070/format:webp/1*ROsfPU9wFNHZcwyqD3v0yA.png"/></div><figcaption class="mc md gj gh gi me mf bd b be z dk">Figure 1. Conceptual Diagram</figcaption></figure><p id="9b22" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">为了实现所提出的系统，考虑了通过发音和机器学习的响应系统。发音是一种从各种类型的数据到声音的转换<strong class="kh ir"> </strong>技术，这种技术有很多实现方式。在这里，我们关注从图像数据到声音的转换。图 1 显示了这个过程的概念图。与图像中的对比度轮廓相关的数据通过声音设计被映射到指定的声音。图 1(a)显示了来自图像数据的实时声音映射，声音指示图像的当前状态。声音不包含未来信息。图 1(b)显示了来自图像数据的实时声音映射，包括指示当前状态的声音，以及机器学习和 AI 的预测。此外，系统可以将当前状态和预测作为未来信息进行比较。该系统是根据图 1(b)所示的类型设计的，图像数据使用实时数据和预测进行超声处理。</p><p id="8a4e" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir">声音导航</strong></p><p id="ec7d" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们考虑了声音导航以及图像和温度的声音表示。对声音导航的研究，包括诸如可访问性、交互设计和媒体艺术等领域，已经进行了。[4]为了用声音表示图像或温度数据，考虑了以下目标。</p><p id="eb4a" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir"> 1 方向和距离的声音表示</strong></p><p id="388d" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">从图像中提取的数据被转换成数字声音，并表示为空间信息。声音是根据距离和方向的不同而设计的。音高或音调取决于距离和方向，声音也因不同而变化。换句话说，如果物体的估计轨迹和实际轨迹之间的距离很大，则分配给这些轨迹的声音显著不同。</p><p id="ff10" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir"> 2 使用光流的运动物体的声音表现</strong></p><p id="1981" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">光流信息由运动物体的速度矢量组成，图像中的点显示为矢量。流向量用于定义当前状态。我们使用相关系数和指定的声音来计算状态。</p><h2 id="17d7" class="lb lc iq bd ld le lf dn lg lh li dp lj ko lk ll lm ks ln lo lp kw lq lr ls lt bi translated"><strong class="ak">温度的发音</strong></h2><p id="a66d" class="pw-post-body-paragraph kf kg iq kh b ki mg jr kk kl mh ju kn ko mi kq kr ks mj ku kv kw mk ky kz la ij bi translated">我们考虑了温度的发音。所实现的系统可以从传感器连续获得温度数据，并且我们检查了测井数据的发音。</p><p id="e1fb" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir">系统型号</strong></p><figure class="lv lw lx ly gt lz gh gi paragraph-image"><div role="button" tabindex="0" class="mm mn di mo bf mp"><div class="gh gi ml"><img src="../Images/24fb38f91298c86f782315c206c0a432.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*-5WZb63Z4tf_MabHDq-dKQ.png"/></div></div><figcaption class="mc md gj gh gi me mf bd b be z dk"><strong class="bd mq">Figure 2 System Model</strong></figcaption></figure><p id="cc85" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">图 2 显示了本研究中使用的系统模型。这个系统的一个目的是用声音来表示方向和距离。我们通过机器学习实现了系统的嵌入式算法，以估计路径预测，并通过声音揭示预测和对象之间的差异。</p><h2 id="4cbc" class="lb lc iq bd ld le lf dn lg lh li dp lj ko lk ll lm ks ln lo lp kw lq lr ls lt bi translated"><strong class="ak">机器学习</strong></h2><figure class="lv lw lx ly gt lz gh gi paragraph-image"><div role="button" tabindex="0" class="mm mn di mo bf mp"><div class="gh gi mr"><img src="../Images/b47596f4019fc8e77c9d1f6384342284.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*2XNHfw0kexvWt05_PQ33Iw.png"/></div></div><figcaption class="mc md gj gh gi me mf bd b be z dk">・<strong class="bd mq">Figure 3. Object Tracking</strong></figcaption></figure><p id="e543" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">图 3 示出了对象跟踪图像。基于通过强度变化进行阈值处理并从原始图像中减去该图像，由照相机捕获的图像被转换成二进制图像。(右)如果图像中的对象连续移动，则减影图像中会保留白色像素，并通过标记算法为检测到的对象分配编号。(左)作为学习数据的对象的轨迹用于图像中的路径预测和状态。</p><p id="59cd" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir">通过多项式近似的路径预测</strong></p><p id="6d1b" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">通过目标跟踪记录轨迹点，通过多项式逼近估计路径预测。多项式近似由最小二乘法导出。</p><p id="7636" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir">距估计轨迹点的最小距离</strong></p><figure class="lv lw lx ly gt lz gh gi paragraph-image"><div class="gh gi ms"><img src="../Images/741dca8c1d7a5c5592d4a8a8a587c3e4.png" data-original-src="https://miro.medium.com/v2/resize:fit:930/format:webp/1*ly_0N25tnQL9PXaYLJYpcg.png"/></div><figcaption class="mc md gj gh gi me mf bd b be z dk"><strong class="bd mq">Figure 4. Minimum Distance from Estimated Trajectory Point</strong></figcaption></figure><p id="f235" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">图 4 显示了从直线(a)和曲线(b)的估计轨迹点的最小距离。在系统中计算基于公式的最小距离。</p><p id="9a71" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir">移动物体轨迹的 K 均值聚类</strong></p><figure class="lv lw lx ly gt lz gh gi paragraph-image"><div class="gh gi mt"><img src="../Images/e99ab6f20f0e95abb92070edbd4b924e.png" data-original-src="https://miro.medium.com/v2/resize:fit:976/format:webp/1*xwzJMOC2kYDtAms8FCrEHw.png"/></div><figcaption class="mc md gj gh gi me mf bd b be z dk"><strong class="bd mq">Figure 5. K-means Clustering for Moving Objects</strong></figcaption></figure><p id="6e1d" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">系统中的摄像机可以检测与移动物体上的许多点相关的数据。为了将点分成若干组，在系统中使用了 K-均值聚类。图 5 示出了在三个集群的情况下移动对象的 k 均值聚类，并且三个组在图中由不同的颜色表示。红点表示与行人相关的移动物体上的点。将这些点分类成组取决于群集的数量，这必须决定。基于轮廓系数确定最佳聚类数。[5]图 6 示出了聚类数和轮廓系数之间的关系。在图 6 中，簇的数量是 3，轮廓系数随着接近 1 而提高。</p><figure class="lv lw lx ly gt lz gh gi paragraph-image"><div class="gh gi mu"><img src="../Images/c63a31d1a052888ce9cf9aa7b022b08a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1096/format:webp/1*6umLAFt8hhaMBSQ-liBzOw.png"/></div><figcaption class="mc md gj gh gi me mf bd b be z dk"><strong class="bd mq">Figure 6. Silhouette Coefficient[5]</strong></figcaption></figure><p id="6e7e" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">图 7 示出了通过 k 均值和拟合的路径预测。该系统在将移动物体分类成组(三个集群)后，通过拟合来估计行人的轨迹。图 8 显示了估计轨迹的最小距离。该系统计算移动物体(行人)的最小距离并估计轨迹。</p><figure class="lv lw lx ly gt lz gh gi paragraph-image"><div role="button" tabindex="0" class="mm mn di mo bf mp"><div class="gh gi mv"><img src="../Images/ed224c82862951570ec2137aaf9198e4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*cV0tDiM54BIJClsFbp3tTw.png"/></div></div><figcaption class="mc md gj gh gi me mf bd b be z dk"><strong class="bd mq">Figure 7. Path Prediction</strong></figcaption></figure><figure class="lv lw lx ly gt lz gh gi paragraph-image"><div class="gh gi mw"><img src="../Images/e562a84e9ed07d64a918fc0cc1956b5e.png" data-original-src="https://miro.medium.com/v2/resize:fit:768/format:webp/1*rOZT2j3PD8KsQ7Ra6vO6VA.png"/></div><figcaption class="mc md gj gh gi me mf bd b be z dk">Figure 8. Minimum Distance from Estimated Trajectories</figcaption></figure><h2 id="d36f" class="lb lc iq bd ld le lf dn lg lh li dp lj ko lk ll lm ks ln lo lp kw lq lr ls lt bi translated"><strong class="ak">光流</strong></h2><p id="83ef" class="pw-post-body-paragraph kf kg iq kh b ki mg jr kk kl mh ju kn ko mi kq kr ks mj ku kv kw mk ky kz la ij bi translated">Gunnar Farneback 算法的高斯滤波器用于计算光流，并计算图像中均匀间隔的网格的速度矢量，以便测量作为大气的矢量流。图 9 示出了通过光流计算的速度矢量的例子。还计算了相关系数和向量之和。我们研究了基于光流速度矢量的客观标准的计算。</p><figure class="lv lw lx ly gt lz gh gi paragraph-image"><div class="gh gi mx"><img src="../Images/f1ec2f92ba9c35a7d73d572f6a05f847.png" data-original-src="https://miro.medium.com/v2/resize:fit:1280/format:webp/1*V1KN7MnZ1ICFDSU5IZfqCA.png"/></div><figcaption class="mc md gj gh gi me mf bd b be z dk">Figure 9. Example of Velocity Vectors by Optical Flow</figcaption></figure><h2 id="1b90" class="lb lc iq bd ld le lf dn lg lh li dp lj ko lk ll lm ks ln lo lp kw lq lr ls lt bi translated"><strong class="ak">温度数据</strong></h2><p id="c9c1" class="pw-post-body-paragraph kf kg iq kh b ki mg jr kk kl mh ju kn ko mi kq kr ks mj ku kv kw mk ky kz la ij bi translated">该系统使用温度计获取温度数据，然后用于确定空间的状态。来自温度数据的参数通过 OSC [7]发送到声音引擎(Max/MSP ),并进行发音。</p><h2 id="4938" class="lb lc iq bd ld le lf dn lg lh li dp lj ko lk ll lm ks ln lo lp kw lq lr ls lt bi translated"><strong class="ak">发音</strong></h2><p id="e0e3" class="pw-post-body-paragraph kf kg iq kh b ki mg jr kk kl mh ju kn ko mi kq kr ks mj ku kv kw mk ky kz la ij bi translated">声音是为系统设计的，考虑了以下因素:</p><p id="d25a" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">每拍的声音被分配给与预测轨迹的距离。</p><p id="f5bd" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">通过粒度合成的声音和通过距离控制参数的节拍变化。</p><p id="e186" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir">声音分配</strong></p><p id="f1d7" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在系统通知表示距离或速度信息的声音之前，声音是通过声音映射生成的，距离被映射到声音。我们在声音映射中考虑了节拍和颗粒合成。</p><h2 id="36e7" class="lb lc iq bd ld le lf dn lg lh li dp lj ko lk ll lm ks ln lo lp kw lq lr ls lt bi translated"><strong class="ak">击败</strong></h2><figure class="lv lw lx ly gt lz gh gi paragraph-image"><div class="gh gi my"><img src="../Images/4d107453885eeed4b1397c9921f07d1d.png" data-original-src="https://miro.medium.com/v2/resize:fit:848/format:webp/1*UdKN09C-kSC3rND9XpwVgw.png"/></div><figcaption class="mc md gj gh gi me mf bd b be z dk">Figure 10. Beat</figcaption></figure><p id="9119" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">拍是两个频率略有不同的波之间的干涉图案。图 10 显示了 440 Hz 和 445 Hz 正弦波产生拍频的情况。该模式是周期性振动。图 11 显示了一个最大/MSP 节拍补丁示例。</p><figure class="lv lw lx ly gt lz gh gi paragraph-image"><div class="gh gi mz"><img src="../Images/b42d70d109428fe5a5ad4000a93a1546.png" data-original-src="https://miro.medium.com/v2/resize:fit:998/format:webp/1*ZnGTjUnO3cIZrrB-3zQqpw.png"/></div><figcaption class="mc md gj gh gi me mf bd b be z dk">Figure 11. An Example of Max/MSP Patch (Beat)</figcaption></figure><h2 id="a5ff" class="lb lc iq bd ld le lf dn lg lh li dp lj ko lk ll lm ks ln lo lp kw lq lr ls lt bi translated"><strong class="ak">颗粒合成</strong></h2><p id="f030" class="pw-post-body-paragraph kf kg iq kh b ki mg jr kk kl mh ju kn ko mi kq kr ks mj ku kv kw mk ky kz la ij bi translated">我们研究了系统中颗粒合成的声音生成。颗粒合成得到的声音由颗粒组成，颗粒是被分裂成小波片段的样本。图 12 显示了颗粒合成的原理。通过以下程序制造颗粒。</p><p id="3c1e" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">1.样品中谷物的提取</p><p id="0c0d" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">2.乘以窗口函数</p><p id="ed83" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">提取的样本<em class="na"> s </em> ( <em class="na"> n </em>)乘以一个窗口函数，得到一个区间之外的值。我们根据移动物体和估计轨迹之间的距离，通过改变振幅和频率来设计颗粒。交叉合成是通过卷积进行的信号处理，它涉及两个谱函数的相乘。</p><figure class="lv lw lx ly gt lz gh gi paragraph-image"><div role="button" tabindex="0" class="mm mn di mo bf mp"><div class="gh gi nb"><img src="../Images/cf0270c03f5ff6286fd06d633b7f829f.png" data-original-src="https://miro.medium.com/v2/resize:fit:636/format:webp/1*CSek_DqCYDcZk68FEw0djA.png"/></div></div><figcaption class="mc md gj gh gi me mf bd b be z dk">Figure 12. Granular Synthesis</figcaption></figure><p id="0342" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们通过交叉合成设计声音，并假设抽象的声音，其中包括一些音高和环境声音，如汽车噪音。图 13 显示了利用正弦波和汽车噪声的两个 880Hz 样本进行交叉合成获得的频谱。</p><figure class="lv lw lx ly gt lz gh gi paragraph-image"><div role="button" tabindex="0" class="mm mn di mo bf mp"><div class="gh gi nc"><img src="../Images/c63ac79dc31852f8bf27546561e1c962.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*CCfi6t7hoJTAHKjSrIi_1Q.png"/></div></div><figcaption class="mc md gj gh gi me mf bd b be z dk">Figure 13. Spectrum by Cross Synthesis (Car Noise and Sine Wave)</figcaption></figure><p id="1f92" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在图 13 中，上方正弦波的最大幅度为 0.7，下方正弦波的最大幅度为 0.2。由于正弦波的影响，880 Hz 左右的频率存在于较低正弦波的底部。相比之下，由于汽车噪音的影响，较高正弦波的顶部存在一个频率范围。这意味着自波动以来，熵在上层的顶部增加了。图 14 显示了颗粒合成贴片(Max/MSP)。声音的产生取决于与运动物体和轨迹之间的距离有关的控制参数。</p><figure class="lv lw lx ly gt lz gh gi paragraph-image"><div role="button" tabindex="0" class="mm mn di mo bf mp"><div class="gh gi nd"><img src="../Images/26ebc85e96c246c5e53f2fa063531b72.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*-8e1bOl7_lkCX9frnilJDg.png"/></div></div><figcaption class="mc md gj gh gi me mf bd b be z dk">Figure 14. Granular Synthesis Patch (Max/MSP)</figcaption></figure><h2 id="6eed" class="lb lc iq bd ld le lf dn lg lh li dp lj ko lk ll lm ks ln lo lp kw lq lr ls lt bi translated"><strong class="ak">系统实现</strong></h2><figure class="lv lw lx ly gt lz gh gi paragraph-image"><div role="button" tabindex="0" class="mm mn di mo bf mp"><div class="gh gi ne"><img src="../Images/5eda2ce99f2e1e0e699b3110ed01eff6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*1WYgnkQe8Evj3be5hTCVmw.png"/></div></div><figcaption class="mc md gj gh gi me mf bd b be z dk">Figure 15. System Implementation</figcaption></figure><p id="2545" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">该系统由数据分析器、摄像机、温度计和声音引擎组成(图 15)。数据分析器通过 OpenCV 和传感器数据库分析图像数据和温度数据。一些关于移动物体的数据和温度数据存储在一个文件中，并由与机器学习相关的 python 脚本进行分析。获得的数据通过 OSC 协议发送到声音引擎(Max/MSP ),声音通过粒度合成和实时节拍生成。</p><h2 id="4bd2" class="lb lc iq bd ld le lf dn lg lh li dp lj ko lk ll lm ks ln lo lp kw lq lr ls lt bi translated"><strong class="ak">总结</strong></h2><figure class="lv lw lx ly gt lz gh gi paragraph-image"><div role="button" tabindex="0" class="mm mn di mo bf mp"><div class="gh gi nf"><img src="../Images/ef0be8838ca616fa86a0da10907c0414.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*u7qLN7igaEk6jdoC6iB8UQ.png"/></div></div><figcaption class="mc md gj gh gi me mf bd b be z dk">Figure 16. Correlation Coefficients of Velocity Vectors</figcaption></figure><p id="901a" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">基于光流数据的结果，我们研究了速度矢量的相关系数。图 16 显示了速度矢量图像(a)、(b)和(c)。红线表示速度矢量。如果存在移动物体，图像中会出现许多红线。我们计算了每个组合的速度向量的相关系数。表 1 显示了这些组合的结果。图 16(a)和(b)没有显示速度矢量，而图 16(c)中出现了许多速度矢量。基于速度向量的相似性，图 16(a)和 16(c)之间的相关系数非常低(0.026171)，而图 16(b)和 16(c)之间的相关系数很高(0.2745)。</p><p id="88a5" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">本研究的结论如下:</p><p id="26bc" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">1 相关系数和平均值是判断图像情况的标准。</p><p id="0d6f" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">2 运动物体和轨迹之间的距离是影响路径预测的一个重要因素。</p><h2 id="9e92" class="lb lc iq bd ld le lf dn lg lh li dp lj ko lk ll lm ks ln lo lp kw lq lr ls lt bi translated">参考</h2><p id="9810" class="pw-post-body-paragraph kf kg iq kh b ki mg jr kk kl mh ju kn ko mi kq kr ks mj ku kv kw mk ky kz la ij bi translated">1.阿尔茨，e。和 b。埃根(编辑。) [2002].家庭实验室的环境智能研究。恩德霍芬菲利普斯研究公司。</p><p id="a6b1" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">2.“建筑用户界面:建筑设计和人机交互发展的主题、趋势和方向”，Martyn Dade-Robertson，《国际建筑计算杂志》，2013 年 3 月 1 日</p><p id="a2ed" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">3.“为响应式环境设计声音表现”Takuya Yamauchi，第 22 届听觉显示国际年会(ICAD2016)，澳大利亚国立大学，堪培拉，2016 年 7 月 3 日至 7 日</p><p id="b151" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">4.“声音珠宝”山内拓哉和岩武彻莱昂纳多音乐杂志第 18 期麻省理工学院出版社</p><p id="ccb6" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">5.《Python 机器学习》，塞巴斯蒂安·拉什卡，Packt 出版社</p><p id="e9d9" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">6.建筑用户界面:建筑设计和人机交互发展的主题、趋势和方向。</p><p id="2fd8" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">7.Wright，m .，Freed，A .，“开放式声音控制:与声音合成器通信的新协议”，国际计算机音乐会议，塞萨洛尼基，希腊，1997 年</p></div></div>    
</body>
</html>