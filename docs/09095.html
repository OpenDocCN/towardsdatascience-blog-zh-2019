<html>
<head>
<title>Conquer Class Imbalanced Dataset Issues using GANs</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用 GANs 解决类不平衡数据集问题</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/conquer-class-imbalanced-dataset-issues-using-gans-2482b52593aa?source=collection_archive---------14-----------------------#2019-12-03">https://towardsdatascience.com/conquer-class-imbalanced-dataset-issues-using-gans-2482b52593aa?source=collection_archive---------14-----------------------#2019-12-03</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="f482" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">DC-甘生成图像的某些类类型，以改善图像分类</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/1f226c31d8f7fc7ba67cb8202e992c70.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Ia7Z8Mzn3C0KQ7K7ePagiA.jpeg"/></div></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk">Created by Lluisa lborra from Noun Project</figcaption></figure><p id="ae4f" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">现实生活中深度学习应用的一个常见问题是，一些类在训练集中的样本数量明显高于其他类。让我们考虑一个制造商正在构建一个视觉检测系统来检测受损产品。没有哪个厂商会有好的产品形象那么多损坏的产品形象。这种差异被称为阶级不平衡。类别不平衡数据集在不同领域都很常见，如卫生、银行、安全和其他领域。对于这样的数据集，学习算法通常偏向于多数类，因此对于少数类实例有更高的误分类率。</p><p id="77ac" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">有不同的策略来解决这个问题，例如过采样、欠采样、两阶段训练和成本敏感学习。与算法改进相比，为少数类生成人工数据的方法构成了更通用的方法。本文旨在利用深度卷积生成对抗网络(DC-GAN)来改善分类性能，从而缩小数据集中的这一差距。</p><p id="5ebc" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">甘斯就像魔方。一旦你知道解决立方体的诀窍，有多种方法可以得到完美的立方体。它可以快至 3.47 秒(3×3 魔方的当前世界纪录)，如果你搞砸了，很容易发现。但是，如果你不知道解决立方体的诀窍，它可能要花很长时间。GAN 的失败时间和成本相当高(考虑到培训时间和资源的美元价值)，尤其是当您的资源有限，并且您可能仍然不知道哪里出了问题时。一旦你知道了 GAN 的依赖性，就相对容易得到一个完美的解决方案。</p><p id="c2b4" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated"><strong class="kx ir">在本文中，我们将探讨以下主题- </strong></p><ol class=""><li id="4869" class="lr ls iq kx b ky kz lb lc le lt li lu lm lv lq lw lx ly lz bi translated">使 GANs 工作/稳定的提示和技巧。</li><li id="f4b2" class="lr ls iq kx b ky ma lb mb le mc li md lm me lq lw lx ly lz bi translated">如何定义甘？如何为 Kaggle 比赛的真实世界数据集塑造 GAN？</li><li id="46f3" class="lr ls iq kx b ky ma lb mb le mc li md lm me lq lw lx ly lz bi translated">令人兴奋的 GANs 用例。</li></ol><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi mf"><img src="../Images/d95d9342ace934ba1ac68828fda0a1f3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1028/format:webp/1*DHQotwAUbqK3pfRhsjV4sA.png"/></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk">Created by Tresnatiq from Noun Project</figcaption></figure></div><div class="ab cl mg mh hu mi" role="separator"><span class="mj bw bk mk ml mm"/><span class="mj bw bk mk ml mm"/><span class="mj bw bk mk ml"/></div><div class="ij ik il im in"><p id="8a71" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated"><strong class="kx ir">使 GANs 工作/稳定的技巧和诀窍- </strong></p><p id="8e41" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">开发用于生成图像的 GAN 需要用于对给定图像是真实的还是生成的进行分类的鉴别器卷积神经网络模型，以及使用逆卷积层将输入转换为像素值的完整二维图像的生成器模型。</p><p id="cfcf" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">这些生成器和鉴别器模型在零和游戏中竞争。这意味着对一个模型的改进是以降低另一个模型的性能为代价的。结果是一个非常不稳定的训练过程，经常会导致失败。</p><p id="29a4" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">虽然 GANs 的研究继续提高这些模型的基本稳定性，但有许多技巧可以训练它们并使它们稳定。</p><ol class=""><li id="49f4" class="lr ls iq kx b ky kz lb lc le lt li lu lm lv lq lw lx ly lz bi translated">使用步长卷积&gt;&gt;不要使用最大池层数，而是使用卷积层中的步长在鉴别器模型中执行下采样。使用 Conv2DTranspose 和 stride 进行上采样。</li><li id="d6a1" class="lr ls iq kx b ky ma lb mb le mc li md lm me lq lw lx ly lz bi translated">移除全连接层&gt;&gt;鉴别器中不使用全连接层，而是将卷积层展平并直接传递到输出层。</li><li id="550e" class="lr ls iq kx b ky ma lb mb le mc li md lm me lq lw lx ly lz bi translated">使用批处理规范化&gt;&gt;在鉴别器和生成器模型中都建议使用批处理规范图层，但生成器的输出和鉴别器的输入除外。</li><li id="6855" class="lr ls iq kx b ky ma lb mb le mc li md lm me lq lw lx ly lz bi translated">建议仅在发生器中使用 ReLU、Leaky ReLU 和 Tanh &gt;&gt; ReLU，但对于允许小于零的值的 ReLU 鉴别器变化，建议使用 Leaky ReLU。此外，生成器使用双曲正切函数，鉴别器在输出层使用 Sigmoid 激活函数。</li><li id="46ef" class="lr ls iq kx b ky ma lb mb le mc li md lm me lq lw lx ly lz bi translated">归一化输入&gt;&gt;归一化-1 到 1 之间的输入图像。为真实和虚假构建不同的小批量，即每个小批量只需要包含所有真实图像或所有生成的图像。</li><li id="51f4" class="lr ls iq kx b ky ma lb mb le mc li md lm me lq lw lx ly lz bi translated">学习率&gt;&gt;对鉴别器(1e-3)和发生器(1e-4)使用不同的学习率。对两者都使用 Adam optimizer。</li><li id="b088" class="lr ls iq kx b ky ma lb mb le mc li md lm me lq lw lx ly lz bi translated">Performance hack &gt; &gt;训练鉴别器两次，生成器一次。在发电机中使用 50%的压差。</li><li id="48f8" class="lr ls iq kx b ky ma lb mb le mc li md lm me lq lw lx ly lz bi translated">早期跟踪故障&gt;&gt;鉴别器中损失 0.0 是故障模式。如果发生器的损耗稳步下降，很可能用垃圾图像愚弄鉴别器。当训练顺利进行时，鉴别器损耗具有低方差并随时间下降。</li></ol><p id="5221" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">所有这些技巧，我们需要放在一起，以创造一个完美的甘。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi mn"><img src="../Images/2b8e56add93304df9188ad0ca48d2418.png" data-original-src="https://miro.medium.com/v2/resize:fit:1132/format:webp/1*TGUbpPBf-ENJlEi9Ta2ZRA.png"/></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk">Created by Lluisa Iborra from Noun Project</figcaption></figure></div><div class="ab cl mg mh hu mi" role="separator"><span class="mj bw bk mk ml mm"/><span class="mj bw bk mk ml mm"/><span class="mj bw bk mk ml"/></div><div class="ij ik il im in"><p id="4e13" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated"><strong class="kx ir">如何定义甘？如何为 Kaggle 比赛的真实世界数据集塑造 GAN？- </strong></p><p id="2b6c" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">研究人员开发了多种口味的 gan，网上也有多种解决方案来解决类别不平衡问题，但所有这些主要是在玩具数据集上，如 MNIST，CIFAR-10 和 ImageNet。我一直在研究来自 Kaggle 竞赛的医学图像分类(<a class="ae mo" href="https://www.kaggle.com/c/diabetic-retinopathy-detection/overview" rel="noopener ugc nofollow" target="_blank">糖尿病视网膜病变检测</a>)数据集。该数据集有 4 个类，其中类 1 有 13k 个样本，而类 4 只有 600 个样本。Kaggle 竞赛获胜者最近使用的解决阶级不平衡问题的方法之一就是使用 DC-甘。我们将使用 DC-甘为 4 类糖尿病视网膜病变检测数据库创建人工样本。</p><p id="7d52" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">让我们开始编码练习，并实现这些技巧来生成新的图像。所有的实验都是在 NVIDIA Quadro M400 GPU 上完成的。这款 GPU 有 8 GB 内存。GPU 在 Ubuntu 16.04 实例上为 GPU 1.8.0 配置了 CUDA 9.0、cuDNN 7.4、TF。</p><p id="bebb" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">导入所有必要的环境。这段代码期望所有的包都预先安装好。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mp mq l"/></div></figure><p id="3a65" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">我已经从 Kaggle 下载了<a class="ae mo" href="https://www.kaggle.com/c/diabetic-retinopathy-detection/overview" rel="noopener ugc nofollow" target="_blank">数据库</a>。该数据库中的图像很难用肉眼区分，因此该数据集与所有玩具数据集非常不同。数据库有几个 zip 文件，我们需要将它们解压缩到包含各自图像的 train/test 文件夹中。列车图像的所有标签都在单独的 csv 文件中提供。</p><p id="72d0" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">在下面的代码中，我们将读取一个包含图像标签和名称的 csv 文件。我们需要做一些健全的检查(添加。jpeg 扩展，删除所有大小为 0 KB 的图像，从数据帧中移除已删除图像的条目)。</p><p id="dc69" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">在该数据集中，类别 3 和 4 是少数类别，因为它们在整个数据集中的代表性非常低。我们将训练 GAN 为第 4 课生成图像。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mp mq l"/></div></figure><p id="5101" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">以下部分定义了鉴别器和生成器。鉴别器使用 2 x 2 步长的卷积层对输入图像进行下采样(技巧#1 和 2)。输出层使用 Sigmoid 激活函数来预测输入样本是真是假。该模型被训练为使用 Adam 优化器(技巧#4)来最小化二元交叉熵损失函数。</p><p id="2383" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">发生器由 Conv2DTranspose 定义，步长为 2 x 2，可将图像上采样至最高 128 像素。输出层使用双曲正切激活函数来确保输出值在[-1，1]的期望范围内(技巧#4)。我们有意对鉴别器和生成器使用不同的学习速率(技巧 6)。</p><p id="ece0" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated"><em class="mr"> define_gan() </em>函数使用已经定义的生成器和鉴别器模型，并创建一个新的逻辑模型。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mp mq l"/></div></figure><p id="af19" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">下面的函数<em class="mr"> load_real_samples() </em>将从数据集中读取实际数据并归一化图像(技巧#5)，然后在调用<em class="mr"> train()时将它们馈送到<em class="mr"> generate_real_samples() </em>。</em></p><p id="269e" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated"><em class="mr">generate _ fake _ samples()</em>函数生成带有随机像素值和假标签 0 的图像。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mp mq l"/></div></figure><p id="e53d" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">没有评估 GAN 性能的指标，生成的图像必须由操作员进行质量评估。这使得很难决定在哪里停止训练。</p><p id="faa6" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">由于敌对的性质，发电机的属性在每个纪元后都在变化。一旦生成了可接受质量的图像，生成器可能不会提高性能，在许多情况下甚至会随着后续时期而降低性能。</p><p id="2aaa" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">使用 3 个选项来处理这个问题</p><ol class=""><li id="66dc" class="lr ls iq kx b ky kz lb lc le lt li lu lm lv lq lw lx ly lz bi translated">定期评估鉴别器对真假图像的分类精度。</li><li id="e22a" class="lr ls iq kx b ky ma lb mb le mc li md lm me lq lw lx ly lz bi translated">定期生成图像并保存，供操作员查看。</li><li id="738b" class="lr ls iq kx b ky ma lb mb le mc li md lm me lq lw lx ly lz bi translated">定期保存生成器模型以备后用。</li></ol><p id="8f62" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">所有这些操作将由<em class="mr">summary _ performance()</em>函数执行，以评估鉴别器模型。多个历元的训练 GAN 将同时每 10 个历元生成模型的快照<em class="mr"> save_plat() </em>将继续保存图像。这将有助于回溯 GAN 图像生成的进程。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mp mq l"/></div></figure><p id="3a9a" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated"><em class="mr"> train() </em>函数定义如下，每个时期内的批次数量由批次大小分成训练数据集的次数来定义。</p><p id="0ceb" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">训练鉴别器模型被更新两次(每次用假的和真的样本),并且对于每批迭代生成器被更新一次(技巧#7)。</p><p id="9537" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">训练 GAN 时观察损耗至关重要，鉴频器损耗的突然下降表明发生器模型已经开始产生鉴频器可以轻易辨别的坏样本(技巧 8)。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mp mq l"/></div></figure><p id="992c" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">为了可视化模型，我们可以使用<em class="mr"> plot_model() </em>函数绘制它们。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ms"><img src="../Images/62ac3977f9821e9d518f6093fabfba7a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*FwRyKvw8gnzssJCP8rhPMw.png"/></div></div></figure><p id="960c" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated"><em class="mr"> summary() </em>功能也可用于查看模型布局和可训练参数的数量。调用<em class="mr"> train() </em>函数开始鉴别器和发电机训练。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mp mq l"/></div></figure><p id="03c6" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">鉴别器模型</p><pre class="kg kh ki kj gt mt mu mv mw aw mx bi"><span id="4e3f" class="my mz iq mu b gy na nb l nc nd">_________________________________________________________________<br/>Layer (type)                 Output Shape              Param #   <br/>=================================================================<br/>conv2d_1 (Conv2D)            (None, 128, 128, 16)      448       <br/>_________________________________________________________________<br/>leaky_re_lu_1 (LeakyReLU)    (None, 128, 128, 16)      0         <br/>_________________________________________________________________<br/>conv2d_2 (Conv2D)            (None, 64, 64, 8)         1160      <br/>_________________________________________________________________<br/>leaky_re_lu_2 (LeakyReLU)    (None, 64, 64, 8)         0         <br/>_________________________________________________________________<br/>conv2d_3 (Conv2D)            (None, 32, 32, 16)        1168      <br/>_________________________________________________________________<br/>leaky_re_lu_3 (LeakyReLU)    (None, 32, 32, 16)        0         <br/>_________________________________________________________________<br/>conv2d_4 (Conv2D)            (None, 16, 16, 8)         1160      <br/>_________________________________________________________________<br/>leaky_re_lu_4 (LeakyReLU)    (None, 16, 16, 8)         0         <br/>_________________________________________________________________<br/>flatten_1 (Flatten)          (None, 2048)              0         <br/>_________________________________________________________________<br/>dropout_1 (Dropout)          (None, 2048)              0         <br/>_________________________________________________________________<br/>dense_1 (Dense)              (None, 1)                 2049      <br/>=================================================================<br/>Total params: 11,970<br/>Trainable params: 5,985<br/>Non-trainable params: 5,985<br/>_________________________________________________________________</span></pre><p id="9ce9" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">发电机模型</p><pre class="kg kh ki kj gt mt mu mv mw aw mx bi"><span id="ab4e" class="my mz iq mu b gy na nb l nc nd">_________________________________________________________________<br/>Layer (type)                 Output Shape              Param #   <br/>=================================================================<br/>dense_2 (Dense)              (None, 65536)             6619136   <br/>_________________________________________________________________<br/>leaky_re_lu_5 (LeakyReLU)    (None, 65536)             0         <br/>_________________________________________________________________<br/>reshape_1 (Reshape)          (None, 16, 16, 256)       0         <br/>_________________________________________________________________<br/>conv2d_transpose_1 (Conv2DTr (None, 32, 32, 128)       524416    <br/>_________________________________________________________________<br/>leaky_re_lu_6 (LeakyReLU)    (None, 32, 32, 128)       0         <br/>_________________________________________________________________<br/>conv2d_transpose_2 (Conv2DTr (None, 64, 64, 128)       262272    <br/>_________________________________________________________________<br/>leaky_re_lu_7 (LeakyReLU)    (None, 64, 64, 128)       0         <br/>_________________________________________________________________<br/>conv2d_transpose_3 (Conv2DTr (None, 128, 128, 128)     262272    <br/>_________________________________________________________________<br/>leaky_re_lu_8 (LeakyReLU)    (None, 128, 128, 128)     0         <br/>_________________________________________________________________<br/>conv2d_5 (Conv2D)            (None, 128, 128, 3)       3459      <br/>=================================================================<br/>Total params: 7,671,555<br/>Trainable params: 7,671,555<br/>Non-trainable params: 0<br/>_________________________________________________________________</span></pre><p id="179d" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">培训流程将如下所示</p><pre class="kg kh ki kj gt mt mu mv mw aw mx bi"><span id="401b" class="my mz iq mu b gy na nb l nc nd">.....<br/>&gt;319, 5/10, d1=0.692, d2=0.761 g=0.709<br/>&gt;319, 6/10, d1=0.822, d2=0.759 g=0.690<br/>&gt;319, 7/10, d1=0.733, d2=0.764 g=0.723<br/>&gt;319, 8/10, d1=0.662, d2=0.740 g=0.743<br/>&gt;319, 9/10, d1=0.701, d2=0.683 g=0.758<br/>&gt;319, 10/10, d1=0.830, d2=0.744 g=0.728<br/>&gt;320, 1/10, d1=0.749, d2=0.717 g=0.731<br/>&gt;320, 2/10, d1=0.677, d2=0.796 g=0.722<br/>&gt;320, 3/10, d1=0.766, d2=0.700 g=0.717<br/>&gt;320, 4/10, d1=0.676, d2=0.736 g=0.765<br/>&gt;320, 5/10, d1=0.792, d2=0.762 g=0.730<br/>&gt;320, 6/10, d1=0.690, d2=0.710 g=0.719<br/>&gt;320, 7/10, d1=0.807, d2=0.759 g=0.708<br/>&gt;320, 8/10, d1=0.715, d2=0.747 g=0.711<br/>&gt;320, 9/10, d1=0.719, d2=0.720 g=0.731<br/>&gt;320, 10/10, d1=0.695, d2=0.717 g=0.694<br/>################# Summarize ###################<br/>&gt;Accuracy real: 35%, fake: 57%</span></pre><p id="53f3" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">经过 320 个时代，下面是我能够产生的图像质量。这个 GAN 的训练花了大约 30 分钟。更复杂的发生器和鉴别器模型可以产生更好质量的图像。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi ne"><img src="../Images/77e8fee6f1374f96845f9fc5db46275d.png" data-original-src="https://miro.medium.com/v2/resize:fit:864/format:webp/1*cKhwXXTrvWfcnRfw5NRjaw.png"/></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk">save_plot() will generate a 7 by 7 matrix of images</figcaption></figure><p id="e208" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">GAN 向完美立方体的进展</p><div class="kg kh ki kj gt ab cb"><figure class="nf kk ng nh ni nj nk paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><img src="../Images/8deaf7e11de6e5d6f7256472559dc6bb.png" data-original-src="https://miro.medium.com/v2/resize:fit:654/format:webp/1*DHQotwAUbqK3pfRhsjV4sA.png"/></div></figure><figure class="nf kk nl nh ni nj nk paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><img src="../Images/6895a42ba4ee10a39ba9be7d4270d1b9.png" data-original-src="https://miro.medium.com/v2/resize:fit:686/format:webp/1*EwktPHm1Q_emdEyPk3pWCA.png"/></div></figure><figure class="nf kk nm nh ni nj nk paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><img src="../Images/d22e434d353f8877382a5d7034b536be.png" data-original-src="https://miro.medium.com/v2/resize:fit:664/format:webp/1*K5njIA98Whb_IAhBLVs1RQ.png"/></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk nn di no np">Created by Tresnatiq from Noun Project</figcaption></figure></div><p id="9de1" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">现在，这些新生成的少数民族类图像可以添加到原始不平衡数据集中。这将有助于将不平衡的多类数据转换成平衡的数据集。这将提高模型的分类性能。</p><p id="662b" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">可以在这里找到针对这种不平衡数据集的图像分类算法</p><div class="nq nr gp gr ns nt"><a rel="noopener follow" target="_blank" href="/the-quest-of-higher-accuracy-for-cnn-models-42df5d731faf"><div class="nu ab fo"><div class="nv ab nw cl cj nx"><h2 class="bd ir gy z fp ny fr fs nz fu fw ip bi translated">对 CNN 模型更高精度的探索</h2><div class="oa l"><h3 class="bd b gy z fp ny fr fs nz fu fw dk translated">在本帖中，我们将学习使用数据重新设计、超参数调整和模型改进准确性的技术…</h3></div><div class="ob l"><p class="bd b dl z fp ny fr fs nz fu fw dk translated">towardsdatascience.com</p></div></div><div class="oc l"><div class="od l oe of og oc oh kp nt"/></div></div></a></div><p id="ce3e" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">所有的 iPython 笔记本都可以在<a class="ae mo" href="https://github.com/swanandM/DC-GAN-RetinopathyImages" rel="noopener ugc nofollow" target="_blank">https://github.com/swanandM/DC-GAN-RetinopathyImages</a>买到</p><p id="e695" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">图像分类笔记本<a class="ae mo" href="https://github.com/swanandM/Diabetic-Retinopathy-Detection-with-TF" rel="noopener ugc nofollow" target="_blank">https://github . com/swanandM/Diabetic-Retinopathy-Detection-with-TF</a></p></div><div class="ab cl mg mh hu mi" role="separator"><span class="mj bw bk mk ml mm"/><span class="mj bw bk mk ml mm"/><span class="mj bw bk mk ml"/></div><div class="ij ik il im in"><p id="f1ee" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated"><strong class="kx ir">GANs 的精彩用例</strong></p><p id="e767" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">GAN 在最初几年取得了令人印象深刻的进步。2017 年，甘能够创作出 1024 x 1024 大小的图像，几乎可以骗过所有人。尽管这种技术会产生严重的社会信任问题，但考虑到这些天发布的假新闻的数量。工程师在开发任何会引起社会动荡的应用程序之前必须小心谨慎。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi oi"><img src="../Images/23fd07901747f33f7103e21240078c0b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*JWFx7UEr6S2d3U-uPRVefA.png"/></div></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk"><a class="ae mo" href="https://arxiv.org/pdf/1708.05509.pdf" rel="noopener ugc nofollow" target="_blank">Towards the automatic Anime characters creation with Generative Adversarial Networks</a></figcaption></figure><p id="1f60" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">为游戏和电影创作动画需要付出巨大的努力。甘可以在没有任何专业技能的情况下自动生成这些动画角色。除此之外，一个专业的动画创作者可以从这些设计中获得灵感。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi oj"><img src="../Images/5d741b093ffa8f282c92b9c03973a2ed.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*XNfGlwwmVOXuKsYB8VMLag.png"/></div></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk"><a class="ae mo" href="https://github.com/junyanz/CycleGAN" rel="noopener ugc nofollow" target="_blank">CycleGAN</a></figcaption></figure><p id="7bf6" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">CycleGAN 可以将图像从一个域转换到另一个域。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ok"><img src="../Images/b2c532a8434fc2aeace129c56259de5d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*uPPL4aWMG3_h34CzeNNyBQ.png"/></div></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk"><a class="ae mo" href="https://github.com/fxia22/PixelDTGAN" rel="noopener ugc nofollow" target="_blank">PixelDTGAN</a></figcaption></figure><p id="fd78" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">PixelDTGAN 用于根据名人照片生成营销图像。这也用作基于图像的建议工具。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ol"><img src="../Images/52758c7cea5c6ccc723860609615165f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*PD1B8rs7rjVoJHyyJopqrQ.png"/></div></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk"><a class="ae mo" href="https://github.com/hanzhanggit/StackGAN" rel="noopener ugc nofollow" target="_blank">StackGAN</a></figcaption></figure><p id="22cd" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated"><a class="ae mo" href="https://arxiv.org/pdf/1612.03242v1.pdf" rel="noopener ugc nofollow" target="_blank">文字转图像</a>是域转移 GAN 的应用之一。这有巨大的应用，包括照片编辑和计算机辅助设计。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi om"><img src="../Images/e69e6721a93a05ac183333fbc907e9fd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*uFw6MGk2hN7O5I88APqPLg.png"/></div></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk"><a class="ae mo" href="https://arxiv.org/pdf/1611.02200.pdf" rel="noopener ugc nofollow" target="_blank">DTN</a></figcaption></figure><p id="2208" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">根据图片创建表情符号是 Snap chat 和 Instagram 等平台已经使用的知名应用之一。</p></div><div class="ab cl mg mh hu mi" role="separator"><span class="mj bw bk mk ml mm"/><span class="mj bw bk mk ml mm"/><span class="mj bw bk mk ml"/></div><div class="ij ik il im in"><p id="63fd" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated"><strong class="kx ir">参考文献</strong></p><ol class=""><li id="3a1d" class="lr ls iq kx b ky kz lb lc le lt li lu lm lv lq lw lx ly lz bi translated"><a class="ae mo" href="https://www.sciencedirect.com/science/article/pii/S0957417417306346" rel="noopener ugc nofollow" target="_blank">使用条件生成对抗网络进行不平衡学习的有效数据生成</a></li><li id="edcc" class="lr ls iq kx b ky ma lb mb le mc li md lm me lq lw lx ly lz bi translated"><a class="ae mo" href="https://machinelearningmastery.com/how-to-develop-a-generative-adversarial-network-for-a-cifar-10-small-object-photographs-from-scratch/" rel="noopener ugc nofollow" target="_blank">如何开发 GAN 以生成 CIFAR10 小型彩色照片</a></li><li id="611d" class="lr ls iq kx b ky ma lb mb le mc li md lm me lq lw lx ly lz bi translated"><a class="ae mo" href="https://medium.com/@jonathan_hui/gan-some-cool-applications-of-gans-4c9ecca35900" rel="noopener">甘的一些炫酷应用</a></li><li id="be7b" class="lr ls iq kx b ky ma lb mb le mc li md lm me lq lw lx ly lz bi translated"><a class="ae mo" href="https://github.com/soumith/ganhacks#authors" rel="noopener ugc nofollow" target="_blank">如何训练一个甘？</a></li></ol></div></div>    
</body>
</html>