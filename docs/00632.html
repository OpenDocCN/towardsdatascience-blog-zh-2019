<html>
<head>
<title>Text Matching with Deep Learning</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">深度学习的文本匹配</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/text-matching-with-deep-learning-e6aa05333399?source=collection_archive---------6-----------------------#2019-01-29">https://towardsdatascience.com/text-matching-with-deep-learning-e6aa05333399?source=collection_archive---------6-----------------------#2019-01-29</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><p id="c21d" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">在我们的日常生活中，我们总是想知道它们是否是相似的东西。典型的例子之一是 Face ID。苹果推出了一个面部识别系统，用于解锁你的 iPhone X。你必须拍几张照片作为黄金图像。当你想解锁你的 iPhone，iPhone 计算当前照片是否匹配预定义的照片。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi ko"><img src="../Images/057eb5d3157f3f3e4be8e94be1b830cf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*FLSUhNZ5-WGHzm3M"/></div></div><figcaption class="la lb gj gh gi lc ld bd b be z dk">Photo by <a class="ae le" href="https://unsplash.com/@makcedward?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Edward Ma</a> on <a class="ae le" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><p id="ca14" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">在以前的博客中，我分享了使用<a class="ae le" rel="noopener" target="_blank" href="/3-basic-distance-measurement-in-text-mining-5852becff1d7">单词存在测量</a>和<a class="ae le" rel="noopener" target="_blank" href="/word-distance-between-word-embeddings-cc3e9cf1d632"> WMD </a>来计算两个句子之间的差异。与以前的方法不同，我们应用神经网络来解决同样的问题。</p><p id="9989" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">看完这篇文章，你会明白:</p><ul class=""><li id="9582" class="lf lg it js b jt ju jx jy kb lh kf li kj lj kn lk ll lm ln bi translated">计算句子相似度的原因</li><li id="265a" class="lf lg it js b jt lo jx lp kb lq kf lr kj ls kn lk ll lm ln bi translated">曼哈顿 LSTM</li><li id="5620" class="lf lg it js b jt lo jx lp kb lq kf lr kj ls kn lk ll lm ln bi translated">曼哈顿 LSTM 变体</li></ul><h1 id="9548" class="lt lu it bd lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk ml mm mn mo mp mq bi translated">计算句子相似度的原因</h1><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi mr"><img src="../Images/6cc3b153b5fc7e97b193ab2f29d248a2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*v_uSvq8PGrtdK7v5"/></div></div><figcaption class="la lb gj gh gi lc ld bd b be z dk">“black clothes hanged in rack” by <a class="ae le" href="https://unsplash.com/@creativeexchange?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">The Creative Exchange</a> on <a class="ae le" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><p id="161d" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">除了图像领域，我们能在自然语言处理领域应用相似性检查吗？作为 Stack Overflow 这样的论坛所有者，你不希望有很多重复的问题，因为这会损害用户体验。当从搜索引擎中搜索某个东西时，你会发现搜索结果包含一些相似的东西，但不仅仅是你输入的内容。</p><p id="389f" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">根据我的项目经验，我利用这种方法来比较客户名称。由于某些原因，输入是模糊的，模型必须为应用程序找到最相似的客户名称。</p><h1 id="d561" class="lt lu it bd lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk ml mm mn mo mp mq bi translated">曼哈顿 LSTM</h1><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi ms"><img src="../Images/b56ce4d0f6b47d162417b34fb2d30a71.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*1Jn7GCDjZt_86ZNW"/></div></div><figcaption class="la lb gj gh gi lc ld bd b be z dk">“New York street during daytime” by <a class="ae le" href="https://unsplash.com/@jmkong?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Aaron Sebastian</a> on <a class="ae le" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><p id="65ee" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">Muelle 等人在 2016 年提出了用于学习句子相似性的曼哈顿 LSTM 架构。曼哈顿 LSTM 的总体目标是比较两个句子，以确定它们是否相同。这种神经网络结构包括两个相同的神经网络。两个输入通过相同的神经网络(共享权重)。</p><p id="4cd8" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">首先，将两个句子转换为向量表示(即嵌入)，然后将其传递给神经网络。两个向量表示将进入两个子神经网络(共享权重)。与其他语言模型 RNN 架构不同，它不预测下一个单词，而是计算两个句子之间的相似度。</p><p id="84b1" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">在实验过程中，Muelle 等人使用:</p><ul class=""><li id="a0d9" class="lf lg it js b jt ju jx jy kb lh kf li kj lj kn lk ll lm ln bi translated">矢量:<a class="ae le" rel="noopener" target="_blank" href="/3-silver-bullets-of-word-embedding-in-nlp-10fa8f50cc5a"> word2vec </a></li><li id="e1f5" class="lf lg it js b jt lo jx lp kb lq kf lr kj ls kn lk ll lm ln bi translated">词向量维数:300</li><li id="99f5" class="lf lg it js b jt lo jx lp kb lq kf lr kj ls kn lk ll lm ln bi translated">损失函数:均方误差(MSE)</li><li id="db66" class="lf lg it js b jt lo jx lp kb lq kf lr kj ls kn lk ll lm ln bi translated">优化器:Adadelta</li><li id="4873" class="lf lg it js b jt lo jx lp kb lq kf lr kj ls kn lk ll lm ln bi translated">LSTM 单位数量:50</li></ul><h1 id="a5a1" class="lt lu it bd lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk ml mm mn mo mp mq bi translated">曼哈顿 LSTM 变体</h1><p id="8873" class="pw-post-body-paragraph jq jr it js b jt mt jv jw jx mu jz ka kb mv kd ke kf mw kh ki kj mx kl km kn im bi translated">这个概念是，你可以建立任何简单或复杂的神经网络，只要它接受两个输入。根据我的经验，你可以尝试任何更复杂的曼哈顿 LSTM 神经网络。我还包括了<a class="ae le" rel="noopener" target="_blank" href="/besides-word-embedding-why-you-need-to-know-character-embedding-6096a34a3b10">额外的单词特性</a>和其他 RNN 架构，如 GRU 或注意力机制。</p><h1 id="d800" class="lt lu it bd lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk ml mm mn mo mp mq bi translated">拿走</h1><ul class=""><li id="6c20" class="lf lg it js b jt mt jx mu kb my kf mz kj na kn lk ll lm ln bi translated">准备<strong class="js iu">大量带标签的数据</strong>很重要</li><li id="086a" class="lf lg it js b jt lo jx lp kb lq kf lr kj ls kn lk ll lm ln bi translated"><strong class="js iu">总计算时间可能很长</strong>。对于我的情况，我必须在预测时比较所有客户名称(&gt; 5M)。因此，我不得不使用其他方法来减少记录数量，使其能够满足在线预测的要求。</li></ul><h1 id="8acf" class="lt lu it bd lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk ml mm mn mo mp mq bi translated">关于我</h1><p id="49f6" class="pw-post-body-paragraph jq jr it js b jt mt jv jw jx mu jz ka kb mv kd ke kf mw kh ki kj mx kl km kn im bi translated">我是湾区的数据科学家。专注于数据科学、人工智能，尤其是 NLP 和平台相关领域的最新发展。你可以通过<a class="ae le" href="http://medium.com/@makcedward/" rel="noopener">媒体博客</a>、<a class="ae le" href="https://www.linkedin.com/in/edwardma1026" rel="noopener ugc nofollow" target="_blank"> LinkedIn </a>或<a class="ae le" href="https://github.com/makcedward" rel="noopener ugc nofollow" target="_blank"> Github </a>联系我。</p><h1 id="7641" class="lt lu it bd lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk ml mm mn mo mp mq bi translated">参考</h1><p id="b626" class="pw-post-body-paragraph jq jr it js b jt mt jv jw jx mu jz ka kb mv kd ke kf mw kh ki kj mx kl km kn im bi translated">Keras 实施:<a class="ae le" href="https://github.com/likejazz/Siamese-LSTM" rel="noopener ugc nofollow" target="_blank">https://github.com/likejazz/Siamese-LSTM</a></p><p id="3c6b" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">Thyagarajan muelle j ...“用于学习句子相似性的暹罗循环结构”。2016.h<a class="ae le" href="http://www.mit.edu/~jonasm/info/MuellerThyagarajan_AAAI16.pdf" rel="noopener ugc nofollow" target="_blank">TTP://www . MIT . edu/~ jonasm/info/MuellerThyagarajan _ aaai 16 . pdf</a></p><p id="f7b7" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">放大图片作者:Koch G ...“用于一次性图像识别的连体神经网络”。2015.<a class="ae le" href="http://www.cs.cmu.edu/~rsalakhu/papers/oneshot1.pdf" rel="noopener ugc nofollow" target="_blank">http://www.cs.cmu.edu/~rsalakhu/papers/oneshot1.pdf</a></p></div></div>    
</body>
</html>