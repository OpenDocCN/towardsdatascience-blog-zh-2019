<html>
<head>
<title>How to improve your kaggle competition leaderboard ranking</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">如何提高你的 kaggle 竞赛排行榜排名</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/how-to-improve-your-kaggle-competition-leaderboard-ranking-bcd16643eddf?source=collection_archive---------15-----------------------#2019-09-08">https://towardsdatascience.com/how-to-improve-your-kaggle-competition-leaderboard-ranking-bcd16643eddf?source=collection_archive---------15-----------------------#2019-09-08</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="d5f1" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">美国有线电视新闻网失明检测新大楼的提示</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/f3fbede4c5b1f96c7ddb911fcae8a45c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*f0lBOZ06-2E6uPPlHM8CVg.jpeg"/></div></div></figure><blockquote class="kr ks kt"><p id="2845" class="ku kv kw kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">在最近参加了 2019 年 APTOS 失明检测 Kaggle 比赛并获得前 32%的成绩后，我想分享一下我训练卷积神经网络的过程。我之前唯一的深度学习经验是完成 Deeplearning.ai 专业化，因此这是你阅读本文所需的全部内容。</p></blockquote><h2 id="612f" class="lr ls iq bd lt lu lv dn lw lx ly dp lz ma mb mc md me mf mg mh mi mj mk ml mm bi translated"><strong class="ak">本条的章节</strong></h2><ol class=""><li id="e80d" class="mn mo iq kx b ky mp lb mq ma mr me ms mi mt lq mu mv mw mx bi translated">竞争环境</li><li id="1961" class="mn mo iq kx b ky my lb mz ma na me nb mi nc lq mu mv mw mx bi translated">写日志</li><li id="8de8" class="mn mo iq kx b ky my lb mz ma na me nb mi nc lq mu mv mw mx bi translated">获取更多数据</li><li id="fc89" class="mn mo iq kx b ky my lb mz ma na me nb mi nc lq mu mv mw mx bi translated">利用现有内核</li><li id="fd82" class="mn mo iq kx b ky my lb mz ma na me nb mi nc lq mu mv mw mx bi translated">预处理图像</li><li id="79b0" class="mn mo iq kx b ky my lb mz ma na me nb mi nc lq mu mv mw mx bi translated">训练是一个非常非常缓慢的过程(但是不要担心)</li><li id="1c9e" class="mn mo iq kx b ky my lb mz ma na me nb mi nc lq mu mv mw mx bi translated">迁移学习</li><li id="2fea" class="mn mo iq kx b ky my lb mz ma na me nb mi nc lq mu mv mw mx bi translated">型号选择</li></ol><h2 id="30e4" class="lr ls iq bd lt lu lv dn lw lx ly dp lz ma mb mc md me mf mg mh mi mj mk ml mm bi translated">竞争环境</h2><p id="3427" class="pw-post-body-paragraph ku kv iq kx b ky mp jr la lb mq ju ld ma nd lg lh me ne lk ll mi nf lo lp lq ij bi translated">我在过去的 2-3 个月里断断续续地参加了 Kaggle 上的<a class="ae ng" href="https://www.kaggle.com/c/aptos2019-blindness-detection" rel="noopener ugc nofollow" target="_blank"> APTOS 2019 失明检测比赛</a>，比赛要求你将人们眼睛的图像分为 5 类糖尿病视网膜病变严重程度。在本文的剩余部分，我将谈论一些你可以在<em class="kw">任何 kaggle vision 竞赛中使用的技巧和诀窍，</em>，因为我觉得我从这个竞赛中学到的东西基本上是普遍适用的<em class="kw">。</em></p><h2 id="b90c" class="lr ls iq bd lt lu lv dn lw lx ly dp lz ma mb mc md me mf mg mh mi mj mk ml mm bi translated">记日志</h2><p id="c05e" class="pw-post-body-paragraph ku kv iq kx b ky mp jr la lb mq ju ld ma nd lg lh me ne lk ll mi nf lo lp lq ij bi translated">像任何好的科学实验一样，我们一次改变一件事，并将我们的结果与我们的对照进行比较。因此，当训练 CNN(卷积神经网络)时，我们也应该这样做，并在日志中记录变化和结果。这是我在失明检测挑战赛中用过的。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nh"><img src="../Images/5e43a954708ae3c92fee65be6ada7324.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*AE9K_knHKbU0mI2ZJIG1gQ.png"/></div></div><figcaption class="ni nj gj gh gi nk nl bd b be z dk">My logbook for Kaggle APTOS Blindness Detection Challenge</figcaption></figure><p id="bbf9" class="pw-post-body-paragraph ku kv iq kx b ky kz jr la lb lc ju ld ma lf lg lh me lj lk ll mi ln lo lp lq ij bi translated">我并不声称我在这里使用的精确的表格是理想的(远非如此)，但是我发现至少能够识别每次我进行更改时，模型是否在以前的更改基础上有所改进是非常有用的。无论如何，我强烈建议你保持某种形式的日志，因为很难确定你所做的事情是否有效。</p><p id="1d50" class="pw-post-body-paragraph ku kv iq kx b ky kz jr la lb lc ju ld ma lf lg lh me lj lk ll mi ln lo lp lq ij bi translated">我对下一份比赛日志的一些想法是:</p><ol class=""><li id="e7d9" class="mn mo iq kx b ky kz lb lc ma nm me nn mi no lq mu mv mw mx bi translated">建立一个单一的基线模型来比较所有未来的变化</li><li id="6a84" class="mn mo iq kx b ky my lb mz ma na me nb mi nc lq mu mv mw mx bi translated">想出一堆您想要尝试的调整，并为每个调整独立地运行基线的修改版本，而不是以累积的方式。</li><li id="1a31" class="mn mo iq kx b ky my lb mz ma na me nb mi nc lq mu mv mw mx bi translated">尽可能长时间保持相同的(最小的)CNN 架构，因为这将使迭代更快，并且通过一些观察，许多超参数应该体面地转移到更大更复杂的模型。</li></ol><h2 id="b148" class="lr ls iq bd lt lu lv dn lw lx ly dp lz ma mb mc md me mf mg mh mi mj mk ml mm bi translated">获取更多数据</h2><p id="bee3" class="pw-post-body-paragraph ku kv iq kx b ky mp jr la lb mq ju ld ma nd lg lh me ne lk ll mi nf lo lp lq ij bi translated">在你开始编码之前做一些研究，看看以前是否有类似的比赛，或者是否有类似标签的训练集的数据库可以使用。更多的数据永远不会对你的模型造成真正的伤害(假设标签的质量还不错)，所以尽可能地获取更多的数据，但是不要忘记从提供给你的原始数据集中保留你的验证和测试集，否则你可能会以训练测试不匹配而告终<em class="kw">。</em></p><h2 id="e61d" class="lr ls iq bd lt lu lv dn lw lx ly dp lz ma mb mc md me mf mg mh mi mj mk ml mm bi translated">利用现有内核</h2><p id="cefc" class="pw-post-body-paragraph ku kv iq kx b ky mp jr la lb mq ju ld ma nd lg lh me ne lk ll mi nf lo lp lq ij bi translated">如果你是深度学习竞赛的新手(像我一样)，你可能不想从头开始编写整个笔记本——特别是当别人可能已经为你的竞赛发布了一个入门内核时(为什么要重新发明轮子呢？).这可能会为您节省大量调试时间，并通过调整其他人的模型让您更快地学习新东西。</p><p id="e7e9" class="pw-post-body-paragraph ku kv iq kx b ky kz jr la lb lc ju ld ma lf lg lh me lj lk ll mi ln lo lp lq ij bi translated">这是一个很好的启动内核,我在几乎所有的进一步试验中使用并改进了它。</p><div class="np nq gp gr nr ns"><a href="https://www.kaggle.com/mathormad/aptos-resnet50-baseline" rel="noopener  ugc nofollow" target="_blank"><div class="nt ab fo"><div class="nu ab nv cl cj nw"><h2 class="bd ir gy z fp nx fr fs ny fu fw ip bi translated">[APTOS] resnet50 基准</h2><div class="nz l"><h3 class="bd b gy z fp nx fr fs ny fu fw dk translated">下载数千个项目的开放数据集+在一个平台上共享项目。探索热门话题，如政府…</h3></div><div class="oa l"><p class="bd b dl z fp nx fr fs ny fu fw dk translated">www.kaggle.com</p></div></div><div class="ob l"><div class="oc l od oe of ob og kp ns"/></div></div></a></div><p id="ae55" class="pw-post-body-paragraph ku kv iq kx b ky kz jr la lb lc ju ld ma lf lg lh me lj lk ll mi ln lo lp lq ij bi translated"><strong class="kx ir">一个警告:</strong>如果一个内核建议你的模型使用一些技术，你应该检查它们是否陈述了最终的性能提升，否则，在盲目地将它们合并到你自己的模型之前，要持怀疑态度并自己进行测试:)</p><h2 id="6a42" class="lr ls iq bd lt lu lv dn lw lx ly dp lz ma mb mc md me mf mg mh mi mj mk ml mm bi translated">预处理图像</h2><p id="ad9c" class="pw-post-body-paragraph ku kv iq kx b ky mp jr la lb mq ju ld ma nd lg lh me ne lk ll mi nf lo lp lq ij bi translated"><strong class="kx ir">裁剪&amp;其他增强:</strong>这一步是必须的。训练图像可能处于非常原始的状态。例如，在失明检测挑战中，所有图像都以不同的比例裁剪，这意味着一个愚蠢的算法可能会过度适应眼睛周围的黑色空间，这在一个类别中比另一个类别中更普遍。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi oh"><img src="../Images/efa7ac77cd44e6571c5bc45056322052.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*qri2bBJ8yISy2xDShSmbmg.png"/></div></div><figcaption class="ni nj gj gh gi nk nl bd b be z dk">Source: <a class="ae ng" href="https://www.kaggle.com/taindow/be-careful-what-you-train-on" rel="noopener ugc nofollow" target="_blank">https://www.kaggle.com/taindow/be-careful-what-you-train-on</a></figcaption></figure><p id="9324" class="pw-post-body-paragraph ku kv iq kx b ky kz jr la lb lc ju ld ma lf lg lh me lj lk ll mi ln lo lp lq ij bi translated">因此，以稳健的方式裁剪图像和调整图像大小是这场竞赛的关键部分。也有许多图像增强技术，如随机裁剪，旋转，对比度和亮度等，我有不同程度的成功。</p><p id="c857" class="pw-post-body-paragraph ku kv iq kx b ky kz jr la lb lc ju ld ma lf lg lh me lj lk ll mi ln lo lp lq ij bi translated">不均衡的职业:总有一些职业比其他职业有更多的训练例子，所以你需要在开始训练前解决这个问题。在小批量梯度下降过程中，<em class="kw">过采样/欠采样</em>以及<em class="kw">混合</em> (Zhang 等人，2019)是一组行之有效的技术组合。</p><p id="4954" class="pw-post-body-paragraph ku kv iq kx b ky kz jr la lb lc ju ld ma lf lg lh me lj lk ll mi ln lo lp lq ij bi translated"><strong class="kx ir">预处理计算:</strong>数据集通常会非常大，应用基本程序(如标准化尺寸和图像裁剪)应在单独的内核 t(或离线 dep)中完成。数据集的大小)并作为原始数据的修改版本重新上传——否则，您将不得不在模型的每个时期/运行时进行这种计算(这是对时间的极大浪费)。</p><h2 id="9a91" class="lr ls iq bd lt lu lv dn lw lx ly dp lz ma mb mc md me mf mg mh mi mj mk ml mm bi translated">训练是一个非常非常缓慢的过程</h2><p id="0e06" class="pw-post-body-paragraph ku kv iq kx b ky mp jr la lb mq ju ld ma nd lg lh me ne lk ll mi nf lo lp lq ij bi translated">现在你已经写了你的第一个内核，你需要测试它！Kaggle 内核可以运行长达 9 个小时(内核时间限制可能因竞争而异)，该网站也运行许多模型，因此在一天中的某些时间可能会比其他时间慢。我最好的建议是，首先在浏览器中快速运行 1 到 2 次，以确保你没有犯任何错误，然后获得几个你想同时测试的想法，然后点击提交所有想法，几个小时后再回来检查。注意，如果你点击提交而不是运行内核，你就不必让你的笔记本电脑一直运行:)。</p><h2 id="d99a" class="lr ls iq bd lt lu lv dn lw lx ly dp lz ma mb mc md me mf mg mh mi mj mk ml mm bi translated">迁移学习</h2><p id="327c" class="pw-post-body-paragraph ku kv iq kx b ky mp jr la lb mq ju ld ma nd lg lh me ne lk ll mi nf lo lp lq ij bi translated">你不会从头开始训练一个足够大的模型。通常情况下，我们只需要在 imagenet 或其他大型数据集上预先训练一个大型模型，并根据我们的目的对其进行微调。几乎在所有情况下，您都应该在微调期间解冻模型的所有层，因为结果可能是最稳定的。</p><blockquote class="kr ks kt"><p id="167f" class="ku kv kw kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">这张图表很好地说明了这一点(Yosinski 等人，2014 年),其中两个网络在数据集 A 和 B 上进行训练，然后网络在第 n 层被切断，之前的层被冻结或微调(用+表示)。在第二幅图中可以看到结论，其中 to 线 AnB+的所有 7 层都经过了调整，产生了最佳的 top-1 精度。</p></blockquote><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi oi"><img src="../Images/2e4f9fb6b471cf905d7872854efde6fc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*PhUtaoTPUAOF0kHKTO5SKA.png"/></div></div><figcaption class="ni nj gj gh gi nk nl bd b be z dk">(Yosinski et al. 2014)</figcaption></figure><h2 id="90e1" class="lr ls iq bd lt lu lv dn lw lx ly dp lz ma mb mc md me mf mg mh mi mj mk ml mm bi translated">型号选择</h2><p id="0713" class="pw-post-body-paragraph ku kv iq kx b ky mp jr la lb mq ju ld ma nd lg lh me ne lk ll mi nf lo lp lq ij bi translated">您可能最好从一个较小的模型(如 ResNet 50)开始，然后尝试一些较大的架构，如(Resnet-101、InceptionNets、EfficientNets)。所有这些网络都有可用的论文，在你继续使用它们之前绝对值得一读，尽管通常你应该期望用新的模型比旧的模型获得更好的准确性。</p><h2 id="5930" class="lr ls iq bd lt lu lv dn lw lx ly dp lz ma mb mc md me mf mg mh mi mj mk ml mm bi translated">结束语</h2><p id="32fa" class="pw-post-body-paragraph ku kv iq kx b ky mp jr la lb mq ju ld ma nd lg lh me ne lk ll mi nf lo lp lq ij bi translated">有了我上面提供的信息，你应该能在公共和私人排行榜上获得一个真正体面的分数。</p><p id="b37c" class="pw-post-body-paragraph ku kv iq kx b ky kz jr la lb lc ju ld ma lf lg lh me lj lk ll mi ln lo lp lq ij bi translated">我参加这项挑战的直觉告诉我，进入公开排行榜的前 30 名，就有很大机会进入私人排行榜的前 10 名，因为剩下的数据集存在不确定性。</p><p id="27a9" class="pw-post-body-paragraph ku kv iq kx b ky kz jr la lb lc ju ld ma lf lg lh me lj lk ll mi ln lo lp lq ij bi translated">在 APTOS 挑战赛中，排名前 32%和赢得第一名之间的差距比我的分数提高了不到 3%，所以继续调整你的模型吧！</p><h2 id="5ed5" class="lr ls iq bd lt lu lv dn lw lx ly dp lz ma mb mc md me mf mg mh mi mj mk ml mm bi translated">参考</h2><p id="ba7d" class="pw-post-body-paragraph ku kv iq kx b ky mp jr la lb mq ju ld ma nd lg lh me ne lk ll mi nf lo lp lq ij bi translated">Yosinski，j .，Clune，j .，Bengio，y .和 Lipson，H. (2019)。深度神经网络中的特征有多大的可转移性？。[在线]arXiv.org。地点:【https://arxiv.org/abs/1411.1792】T2。</p><p id="4bc7" class="pw-post-body-paragraph ku kv iq kx b ky kz jr la lb lc ju ld ma lf lg lh me lj lk ll mi ln lo lp lq ij bi translated">张，h .，西塞，m .，多芬，y .和洛佩斯-帕兹，D. (2019)。<em class="kw">混乱:超越经验风险最小化</em>。[在线]arXiv.org。可在:<a class="ae ng" href="https://arxiv.org/abs/1710.09412" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/abs/1710.09412</a>【2019 年 9 月 8 日获取】。</p></div></div>    
</body>
</html>