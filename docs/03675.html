<html>
<head>
<title>From zero to Real-Time Hand Keypoints detection in five months with OpenCV, Tensorflow, and Fastai</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">利用 OpenCV、Tensorflow 和 Fastai，在五个月内从零到实时手关键点检测</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/from-zero-to-real-time-hand-keypoints-detection-in-five-months-with-opencv-tensorflow-and-fastai-f98e87221475?source=collection_archive---------12-----------------------#2019-06-11">https://towardsdatascience.com/from-zero-to-real-time-hand-keypoints-detection-in-five-months-with-opencv-tensorflow-and-fastai-f98e87221475?source=collection_archive---------12-----------------------#2019-06-11</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/></div><div class="ab cl jq jr hx js" role="separator"><span class="jt bw bk ju jv jw"/><span class="jt bw bk ju jv jw"/><span class="jt bw bk ju jv"/></div><div class="im in io ip iq"><p id="a282" class="pw-post-body-paragraph jx jy it jz b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku im bi translated">在这篇文章中，我将一步一步地向你展示如何用 OpenCV、Tensorflow 和 Fastai (Python 3.7)构建你自己的实时手部关键点检测器。在为期 5 个月的精彩旅程中，我将专注于我在建造它时所面临的挑战。</p><p id="5351" class="pw-post-body-paragraph jx jy it jz b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku im bi translated">你可以在这里看到这些模型:</p><figure class="kw kx ky kz gt la gh gi paragraph-image"><div role="button" tabindex="0" class="lb lc di ld bf le"><div class="gh gi kv"><img src="../Images/7b8d3173dc069421c1e510fd5ababff8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/1*w49cw0ZA4naV4-MI_kQ-Vw.gif"/></div></div><figcaption class="lh li gj gh gi lj lk bd b be z dk">The light green box detects the hand on the image, then i crop around the image by connecting the magenta dots before feeding a CNN for hand keypoints detection</figcaption></figure></div><div class="ab cl jq jr hx js" role="separator"><span class="jt bw bk ju jv jw"/><span class="jt bw bk ju jv jw"/><span class="jt bw bk ju jv"/></div><div class="im in io ip iq"><h1 id="e20a" class="ll lm it bd ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi bi translated"><strong class="ak">动机:</strong></h1><p id="99a0" class="pw-post-body-paragraph jx jy it jz b ka mj kc kd ke mk kg kh ki ml kk kl km mm ko kp kq mn ks kt ku im bi translated">这一切都始于对理解人工智能核心动态的难以置信的痴迷。五个月前，我在谷歌上搜索了“人工智能 vs 机器学习 vs 深度学习”，这是我第一次试图抓住不同概念之间的细微差别😊。</p><p id="4a95" class="pw-post-body-paragraph jx jy it jz b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku im bi translated">在查看了多个视频和文章后，我决定从计算机视觉开始，使用移动相机开发自己的手部关键点检测器。</p><p id="15aa" class="pw-post-body-paragraph jx jy it jz b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku im bi translated">我知道人脑只需要 20 瓦的能量就能运作，我的目标一直是保持事物的简单性，尽可能降低任何模型的计算要求。复杂的事物需要复杂的微积分，而复杂的微积分本身是高度耗能的。</p></div><div class="ab cl jq jr hx js" role="separator"><span class="jt bw bk ju jv jw"/><span class="jt bw bk ju jv jw"/><span class="jt bw bk ju jv"/></div><div class="im in io ip iq"><h1 id="86ad" class="ll lm it bd ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi bi translated"><strong class="ak">简单说说我的学习曲线:</strong></h1><p id="d190" class="pw-post-body-paragraph jx jy it jz b ka mj kc kd ke mk kg kh ki ml kk kl km mm ko kp kq mn ks kt ku im bi translated">我有土木工程的学术背景，有一些 visual basic 的编码技能。毕业后一直在金融领域工作。</p><p id="b8af" class="pw-post-body-paragraph jx jy it jz b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku im bi translated">很不一般，我是从学习<a class="ae mo" href="https://www.freecodecamp.org/" rel="noopener ugc nofollow" target="_blank"> Javascript </a> ( <a class="ae mo" href="https://codepen.io/rafik-/pens/popular/" rel="noopener ugc nofollow" target="_blank"> ex1 </a>，<a class="ae mo" href="https://glitch.com/@rafik.rahoui" rel="noopener ugc nofollow" target="_blank"> ex2 </a>)开始我的旅程的。这帮助我理解了代码背后的一般逻辑，当我后来开始学习 Python &amp; Django 时，这当然很有用。</p><p id="6782" class="pw-post-body-paragraph jx jy it jz b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku im bi translated">在密集编码的三个半月之后，我开始了吴恩达机器学习课程，同时阅读了成百上千的文章。通过从头开始构建我自己的人工神经网络，并对传播和反向传播进行编码，理解所有的机制是很重要的。</p></div><div class="ab cl jq jr hx js" role="separator"><span class="jt bw bk ju jv jw"/><span class="jt bw bk ju jv jw"/><span class="jt bw bk ju jv"/></div><div class="im in io ip iq"><h1 id="995a" class="ll lm it bd ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi bi translated"><strong class="ak">管道:</strong></h1><p id="9ee4" class="pw-post-body-paragraph jx jy it jz b ka mj kc kd ke mk kg kh ki ml kk kl km mm ko kp kq mn ks kt ku im bi translated">我用相机检测手部关键点的过程遵循以下架构:</p><figure class="kw kx ky kz gt la gh gi paragraph-image"><div role="button" tabindex="0" class="lb lc di ld bf le"><div class="gh gi mp"><img src="../Images/1cd055baf6dcce944e1fd7b9a2070fc1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*A7QAZHKHWoJTZvsv9fiWXA.jpeg"/></div></div><figcaption class="lh li gj gh gi lj lk bd b be z dk">pipline for hand keypoints detection</figcaption></figure><p id="eaa7" class="pw-post-body-paragraph jx jy it jz b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku im bi translated">⁃的图像被摄像机捕捉到；</p><p id="fb70" class="pw-post-body-paragraph jx jy it jz b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku im bi translated">⁃第一深度学习模型检测图像上的手，并估计其周围方框的坐标(通过重新训练手检测上的 tensorflow 对象检测 API 模型来完成，您也可以通过构建定制的深度学习模型来实现)；</p><p id="476c" class="pw-post-body-paragraph jx jy it jz b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku im bi translated">⁃第二个深度学习回归模型采用盒子内部的图像，并估计所有手部关键点的坐标(通过用定制的头部微调 resnet34 来实现)。</p><h1 id="62f4" class="ll lm it bd ln lo mq lq lr ls mr lu lv lw ms ly lz ma mt mc md me mu mg mh mi bi translated"><strong class="ak">手检测:</strong></h1><p id="5811" class="pw-post-body-paragraph jx jy it jz b ka mj kc kd ke mk kg kh ki ml kk kl km mm ko kp kq mn ks kt ku im bi translated">对于这一部分，我决定在 hand 数据集上重新训练 tensorflow 的对象检测模型(在 COCO 数据集上训练)。为了速度，我选择了 MobileNet_v2。</p><p id="cd88" class="pw-post-body-paragraph jx jy it jz b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku im bi translated">这部分我就不细说了。你可以从公共资源中找到很多<a class="ae mo" rel="noopener" target="_blank" href="/creating-your-own-object-detector-ad69dda69c85">教程。</a></p><p id="aa33" class="pw-post-body-paragraph jx jy it jz b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku im bi translated">如果您使用 Open Image dataset，我已经编写了一个自定义脚本来将数据转换为所需的格式:</p><figure class="kw kx ky kz gt la gh gi paragraph-image"><div role="button" tabindex="0" class="lb lc di ld bf le"><div class="gh gi mv"><img src="../Images/c33f35e5fe0a48e8b76a01df23b11066.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*5tDAjrhL-yEfqBdQpxlYeA.png"/></div></div></figure><p id="6332" class="pw-post-body-paragraph jx jy it jz b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku im bi translated">我花了大约 6 个小时重新训练模型。</p><h1 id="5cbc" class="ll lm it bd ln lo mq lq lr ls mr lu lv lw ms ly lz ma mt mc md me mu mg mh mi bi translated"><strong class="ak">关键点检测:</strong></h1><p id="2988" class="pw-post-body-paragraph jx jy it jz b ka mj kc kd ke mk kg kh ki ml kk kl km mm ko kp kq mn ks kt ku im bi translated">在坚持使用 Fastai 之前，我尝试了不同的方法:</p><p id="288f" class="pw-post-body-paragraph jx jy it jz b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku im bi translated">1-我第一次尝试使用 Keras 和 Tensorflow，但在早期阶段面临着数据扩充的挑战。我别无选择，只能使用 Tensorpack(一种低级 api)用 Python 实现自己的数据扩充，这相当复杂，因为我必须执行大量的转换(缩放、裁剪、拉伸、闪电和旋转)…并且因为所有的图像转换都必须影响以 Json 或 Csv 格式存储的坐标。</p><p id="5061" class="pw-post-body-paragraph jx jy it jz b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku im bi translated">2-第二种方法是在灰度图像上画出与每只手相关的坐标位置(参见下面的蒙版图),并使用 Keras 的 DataImageGenerator 对图像及其相应的蒙版进行数据扩充。就指标(损失和准确性)而言，该模型表现良好，但预测是混乱的。我想不出哪里出了问题，于是采取了不同的方法。Keras 是一个很好的 API，但是在我的例子中很难调试。</p><figure class="kw kx ky kz gt la gh gi paragraph-image"><div class="gh gi mw"><img src="../Images/d0adaad49f31dd694e6c7350929a70e2.png" data-original-src="https://miro.medium.com/v2/resize:fit:474/format:webp/1*TyKzMk-51H-VnVWYpwXu-Q.jpeg"/></div><figcaption class="lh li gj gh gi lj lk bd b be z dk">Hand keypoints mask (grayscale image)</figcaption></figure><p id="82ef" class="pw-post-body-paragraph jx jy it jz b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku im bi translated">3-下一步证明是成功的。看了 Fastai，决定试一试。Fastai 的第一个优势在于您可以调试所有代码。第二个优点是坐标扩充是库核心开发的一部分。</p><p id="1125" class="pw-post-body-paragraph jx jy it jz b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku im bi translated">我按照<a class="ae mo" href="https://course.fast.ai/videos/?lesson=1" rel="noopener ugc nofollow" target="_blank">的第一课教程</a>来习惯它，并立即开始在 Jupyter 笔记本上实现我的代码。</p><p id="2c1b" class="pw-post-body-paragraph jx jy it jz b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku im bi translated">关于 Fastai 和 Pytorch 最有趣的事情是<a class="ae mo" href="https://github.com/rafik-rahoui/Hand-keypoints-detection" rel="noopener ugc nofollow" target="_blank">整个代码</a>总结成下面的脚本(简单，对吧😊！):</p><figure class="kw kx ky kz gt la gh gi paragraph-image"><div role="button" tabindex="0" class="lb lc di ld bf le"><div class="gh gi mx"><img src="../Images/590d76dc65e64fcc1cb57faeb4ef173d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*nNB9cbmfKo1RjrNfpJ8L6g.png"/></div></div></figure><figure class="kw kx ky kz gt la gh gi paragraph-image"><div role="button" tabindex="0" class="lb lc di ld bf le"><div class="gh gi my"><img src="../Images/9d29912bf5bc9fd0bbc0c81e651be112.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*2h4Uff6QzYcM4kZAtoGPaQ.png"/></div></div></figure><p id="1676" class="pw-post-body-paragraph jx jy it jz b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku im bi translated">在执行了“learn.lr_find()”和“learn.recorder.plot()”之后，为了确定最优的学习速率，我在不同的周期内总共运行了 3 天代码(在一个 CPU 上！).</p><p id="3da2" class="pw-post-body-paragraph jx jy it jz b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku im bi translated">最后一个循环“learn.fit_one_cycle(36，slice(6e-3))”以以下结果结束:</p><figure class="kw kx ky kz gt la gh gi paragraph-image"><div role="button" tabindex="0" class="lb lc di ld bf le"><div class="gh gi mz"><img src="../Images/7126b00353b2acaca223f33c2e68b715.png" data-original-src="https://miro.medium.com/v2/resize:fit:738/format:webp/1*sFquk0OkJfKsYZJFswkhlw.png"/></div></div></figure><p id="e3f1" class="pw-post-body-paragraph jx jy it jz b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku im bi translated">要对单个图像进行预测，请使用以下代码之一:</p><blockquote class="na nb nc"><p id="cd55" class="jx jy nd jz b ka kb kc kd ke kf kg kh ne kj kk kl nf kn ko kp ng kr ks kt ku im bi translated"><em class="it">img = im . open _ image(' path _ to/hand _ image . png ')</em></p><p id="996b" class="jx jy nd jz b ka kb kc kd ke kf kg kh ne kj kk kl nf kn ko kp ng kr ks kt ku im bi translated"><em class="it">preds = learn . predict(img)</em></p><p id="34ff" class="jx jy nd jz b ka kb kc kd ke kf kg kh ne kj kk kl nf kn ko kp ng kr ks kt ku im bi translated"><em class="it"> img.show(y=preds[0]) </em></p></blockquote><p id="f393" class="pw-post-body-paragraph jx jy it jz b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku im bi translated">或者:</p><blockquote class="na nb nc"><p id="831c" class="jx jy nd jz b ka kb kc kd ke kf kg kh ne kj kk kl nf kn ko kp ng kr ks kt ku im bi translated"><em class="it">img = im . open _ image(' path _ to/hand _ image . png ')</em></p><p id="c671" class="jx jy nd jz b ka kb kc kd ke kf kg kh ne kj kk kl nf kn ko kp ng kr ks kt ku im bi translated"><em class="it">preds = learn . predict(img)</em></p><p id="a50b" class="jx jy nd jz b ka kb kc kd ke kf kg kh ne kj kk kl nf kn ko kp ng kr ks kt ku im bi translated"><em class="it">preds = preds[1]+torch . ones(21，2) </em> <strong class="jz iu"> <em class="it"> #反规格化</em> </strong></p><p id="ae41" class="jx jy nd jz b ka kb kc kd ke kf kg kh ne kj kk kl nf kn ko kp ng kr ks kt ku im bi translated"><em class="it"> preds=torch.mm(preds，torch.tensor([[img.size[0]/2，0]，</em></p><p id="3aee" class="jx jy nd jz b ka kb kc kd ke kf kg kh ne kj kk kl nf kn ko kp ng kr ks kt ku im bi translated"><em class="it"> [0，img.size[1]/2]]，dtype=torch.float)) </em></p><p id="86b1" class="jx jy nd jz b ka kb kc kd ke kf kg kh ne kj kk kl nf kn ko kp ng kr ks kt ku im bi translated"><em class="it">预测值=图像点(流场(图像大小，预测值))</em></p><p id="6760" class="jx jy nd jz b ka kb kc kd ke kf kg kh ne kj kk kl nf kn ko kp ng kr ks kt ku im bi translated"><em class="it"> img.show(y=preds) </em></p></blockquote><h1 id="4e5c" class="ll lm it bd ln lo mq lq lr ls mr lu lv lw ms ly lz ma mt mc md me mu mg mh mi bi translated"><strong class="ak">推理和可视化:</strong></h1><p id="2de1" class="pw-post-body-paragraph jx jy it jz b ka mj kc kd ke mk kg kh ki ml kk kl km mm ko kp kq mn ks kt ku im bi translated">使用 learn.export()导出模型用于推理。您应该注意到 Fastai 在导出整形函数和自定义损失类时失败。在调用模型进行推理之前，应该将这些合并到您的脚本中。</p><p id="859d" class="pw-post-body-paragraph jx jy it jz b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku im bi translated">要绘制关键点，您需要将以下内容添加到可视化代码中:</p><blockquote class="na nb nc"><p id="faaa" class="jx jy nd jz b ka kb kc kd ke kf kg kh ne kj kk kl nf kn ko kp ng kr ks kt ku im bi translated">首先:</p><p id="4223" class="jx jy nd jz b ka kb kc kd ke kf kg kh ne kj kk kl nf kn ko kp ng kr ks kt ku im bi translated">learn = load _ learner(' path _ to _ export . pkl ')#加载之前用 learn.export()保存的推理模型</p></blockquote><p id="a383" class="pw-post-body-paragraph jx jy it jz b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku im bi translated">然后:</p><figure class="kw kx ky kz gt la gh gi paragraph-image"><div role="button" tabindex="0" class="lb lc di ld bf le"><div class="gh gi nh"><img src="../Images/b1fdd70dca811c0c71d41827e7488975.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*UQi-QDt41_FVBfCTS9wKjQ.png"/></div></div></figure><h1 id="a6e7" class="ll lm it bd ln lo mq lq lr ls mr lu lv lw ms ly lz ma mt mc md me mu mg mh mi bi translated">我该何去何从？</h1><p id="2c45" class="pw-post-body-paragraph jx jy it jz b ka mj kc kd ke mk kg kh ki ml kk kl km mm ko kp kq mn ks kt ku im bi translated">1-我想利用深度学习开发一个股票交易模型。我在过去开发了几个定量模型，它们实现起来冗长而复杂。现在我很好奇通过 DL 看市场是什么样子的。</p><p id="c451" class="pw-post-body-paragraph jx jy it jz b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku im bi translated">2-此外，我想在计算机视觉和增强现实的交叉点上推出一些有趣的端到端 ios 应用程序。</p><p id="70c8" class="pw-post-body-paragraph jx jy it jz b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku im bi translated">感谢您的关注。</p></div><div class="ab cl jq jr hx js" role="separator"><span class="jt bw bk ju jv jw"/><span class="jt bw bk ju jv jw"/><span class="jt bw bk ju jv"/></div><div class="im in io ip iq"><p id="bdaa" class="pw-post-body-paragraph jx jy it jz b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku im bi translated">如果你有任何问题，请随时加入我的 linkedin。</p></div></div>    
</body>
</html>