<html>
<head>
<title>Unlocking Drug Discovery With Machine Learning</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">利用机器学习开启药物研发</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/unlocking-drug-discovery-through-machine-learning-part-1-8b2a64333e07?source=collection_archive---------6-----------------------#2019-11-23">https://towardsdatascience.com/unlocking-drug-discovery-through-machine-learning-part-1-8b2a64333e07?source=collection_archive---------6-----------------------#2019-11-23</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="c05c" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">通过利用机器学习来生成和创建分子的逆向合成路径，从而加速药物发现。</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/c11cee92acafe5c534e641b12ded6403.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*dXAsxs-cxTyu6WyT"/></div></div></figure><p id="389b" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">我们发现药物的方式效率极低。需要做点什么。</p><p id="2087" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">尽管最近制药行业发生了很多创新，尤其是在癌症研究领域，但仍有巨大的差距需要改进！</p><p id="ca02" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">自 20 世纪 20 年代以来，我们目前的药物发现方法没有太大变化。</p><blockquote class="lo lp lq"><p id="c0eb" class="kr ks ln kt b ku kv jr kw kx ky ju kz lr lb lc ld ls lf lg lh lt lj lk ll lm ij bi translated"><strong class="kt ir"> <em class="iq">这是曾经发现毒品的故事:</em> </strong></p></blockquote><p id="ffb8" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">1928 年，病理学家亚历山大·弗莱明(Alexander Fleming)经常被描述为“无忧无虑”，他在去度一个月的假之前，不小心把培养皿放在了窗户旁边，没有盖上盖子。</p><p id="5c0d" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">从他美好的假期回来后，发生了更美好的事情。让他吃惊的是，这个被丢弃的培养皿让弗莱明有了惊人的发现，发现了世界上第一种抗生素——青霉素，这一发现颠覆了制药业🤯<strong class="kt ir">。</strong></p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi lu"><img src="../Images/aa663dca5ff27dd3e5ed8443a8970464.png" data-original-src="https://miro.medium.com/v2/resize:fit:1200/format:webp/1*tOucQprr0DAZPkjex4rF8A.jpeg"/></div></figure><p id="e3f3" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">这只是一个小错误如何成为治疗突破的众多例子之一。</p><blockquote class="lo lp lq"><p id="1e66" class="kr ks ln kt b ku kv jr kw kx ky ju kz lr lb lc ld ls lf lg lh lt lj lk ll lm ij bi translated"><strong class="kt ir"> <em class="iq">快进到大约 8 年后，这是目前发现的药物:</em> </strong></p></blockquote><p id="5e2f" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">最近，纽西兰的研究人员* <strong class="kt ir"> <em class="ln">出人意料地* </em> </strong>发现，先前在 21 世纪初用于对抗脑膜炎疫情的疫苗，随后也降低了淋病的风险<strong class="kt ir">。</strong></p><p id="84c5" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">尽管发生了这么多进展，药物发现的秘方似乎从未逃脱意外收获的魔力。</p><p id="a8d5" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">在过去的 80 年里，技术进步呈指数增长，但药物研发领域的进展相对停滞。</p><p id="fa65" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">手机甚至都不是东西，更别说 1928 年的苹果了(如果你不是苹果粉丝，我们就不是朋友——开玩笑的😁)，现在我们不仅有苹果，而且我们还有脑机接口，人工智能将创新带入每个行业，量子计算(最近，<em class="ln">谷歌宣布量子至上</em>)和大量指数级技术的出现。</p><p id="c2b3" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">但是，相比之下，在改进药物发现过程方面进展甚微。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi lv"><img src="../Images/ad38efbfca10a142101ced9402585b2a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1136/format:webp/1*fe-g8_J9waYvo64zWRLdqA.png"/></div><figcaption class="lw lx gj gh gi ly lz bd b be z dk">I meant I love eating apples 🍏</figcaption></figure><h1 id="45a5" class="ma mb iq bd mc md me mf mg mh mi mj mk jw ml jx mm jz mn ka mo kc mp kd mq mr bi translated">目前的药物发现过程是什么样的？</h1><blockquote class="lo lp lq"><p id="a32f" class="kr ks ln kt b ku kv jr kw kx ky ju kz lr lb lc ld ls lf lg lh lt lj lk ll lm ij bi translated"><em class="iq">有大量的证据表明，目前的药物发现过程仅仅是</em> <strong class="kt ir"> <em class="iq"> </em>不足</strong> <em class="iq">，</em> <strong class="kt ir">不足</strong> <em class="iq">针对那些最需要的人——患有慢性和致命疾病的人。</em></p></blockquote><p id="df39" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">据估计，将一种药物从研究阶段推向市场平均需要花费 26 亿美元，并且需要 10 年以上的时间😱<strong class="kt ir">。</strong>由于药物研发非常耗费资源，最近的大部分进展都集中在癌症研究等高回报市场。</p><p id="cd0b" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">这部分解释了<strong class="kt ir">90%以上的罕见疾病缺乏有效治疗。</strong></p><p id="6e3f" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">但是为什么会这样呢？让我们看看药物发现管道(又名药物开发的多方面过程)。</p><p id="859b" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">我们都希望这些救命药物能够更快、更便宜地送到有需要的患者手中。</p><p id="5873" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">为什么这个过程如此漫长和昂贵的简单答案是纯粹的复杂性。</p><p id="7c51" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">药物研发管道看起来像这样:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ms"><img src="../Images/72b43f345806b70459a01bd23cee89d3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*z39aiZ3VaYvjRMyXc7QRDA.png"/></div></div><figcaption class="lw lx gj gh gi ly lz bd b be z dk">Drug discovery pipeline! There are a total of 7 phases.</figcaption></figure><p id="2d8c" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">复杂吧？我们来分解一下…</p><p id="d6b8" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">药物研发有七个阶段:</p><h2 id="dbe5" class="mt mb iq bd mc mu mv dn mg mw mx dp mk la my mz mm le na nb mo li nc nd mq ne bi translated">1.目标识别:发现(2 年以上)</h2><p id="10fa" class="pw-post-body-paragraph kr ks iq kt b ku nf jr kw kx ng ju kz la nh lc ld le ni lg lh li nj lk ll lm ij bi translated">第一步甚至不是关于药物，而是关于理解导致疾病的目标。这些靶标通常由 DNA 突变、错误折叠的蛋白质和其他潜在的疾病生物标志物组成。但是，青霉素的发现显然不是这样，纯粹是偶然发现推动的。</p><p id="1376" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated"><strong class="kt ir">问题#1: </strong>虽然理想的途径是确定靶点，然后开发出专门对抗疾病靶点的药物，但这个过程并没有保证。青霉素的发现显然是这个过程的一个例外，而且还有更多例外。有这么多可能的化合物，这么多可能的目标，人类很难理解所有这些可能的组合。</p><h2 id="eae3" class="mt mb iq bd mc mu mv dn mg mw mx dp mk la my mz mm le na nb mo li nc nd mq ne bi translated">2.线索发现:临床前(1-2 年以上)</h2><p id="dbbf" class="pw-post-body-paragraph kr ks iq kt b ku nf jr kw kx ng ju kz la nh lc ld le ni lg lh li nj lk ll lm ij bi translated">这是筛选数千种旨在干扰疾病靶标的化合物的过程。目标是显著缩小各种潜在化合物的范围。</p><h2 id="b5c8" class="mt mb iq bd mc mu mv dn mg mw mx dp mk la my mz mm le na nb mo li nc nd mq ne bi translated">3.药物化学:临床前(1-2 年以上)</h2><p id="34fc" class="pw-post-body-paragraph kr ks iq kt b ku nf jr kw kx ng ju kz la nh lc ld le ni lg lh li nj lk ll lm ij bi translated">这一阶段包括进一步测试化合物的过程，以分析它们与疾病靶标的相互作用。可以进行的一些分析包括，例如，考虑化合物的 3D 构型来研究化合物的相互作用。根据分析得出的结果，朝着预期目标进一步优化化合物。</p><h2 id="6bdc" class="mt mb iq bd mc mu mv dn mg mw mx dp mk la my mz mm le na nb mo li nc nd mq ne bi translated">4.体外研究:临床前(1-2 年以上)</h2><p id="5b72" class="pw-post-body-paragraph kr ks iq kt b ku nf jr kw kx ng ju kz la nh lc ld le ni lg lh li nj lk ll lm ij bi translated">作为概念的证明，进入这一阶段的化合物在细胞系统中进行测试，这是一种疾病的体外模型。这是培养皿研究发生的阶段。体外研究试图详细检查该化合物在干扰靶标方面的有效性。</p><p id="391a" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated"><strong class="kt ir"> <em class="ln">问题#2: </em> </strong> <em class="ln">体外研究结果往往不能反映动物或临床研究结果，导致</em> <strong class="kt ir"> <em class="ln">失败率高。</em> </strong> <em class="ln">根据麻省理工学院的一项研究，</em> <strong class="kt ir"> <em class="ln">临床试验成功率徘徊在 14%左右，这太疯狂了！</em> </strong> <em class="ln">这是因为我们的体外细胞系统模型往往是对我们复杂的人类系统的粗略简化。生物学不是以 2D 模式运行的，但培养皿研究是细胞的 2D 模型，是一种广泛使用的体外研究方法。</em></p><h2 id="a6a2" class="mt mb iq bd mc mu mv dn mg mw mx dp mk la my mz mm le na nb mo li nc nd mq ne bi translated">5.体内研究:动物研究(1-2 年以上)</h2><p id="628c" class="pw-post-body-paragraph kr ks iq kt b ku nf jr kw kx ng ju kz la nh lc ld le ni lg lh li nj lk ll lm ij bi translated">体外研究成功后(耶，但最困难的部分还在后面)，该化合物通常在动物模型中测试，如大鼠或小鼠模型。与 2D 体外细胞培养模型相比，动物研究的结果通常更具代表性。然而，它明显比体外研究更昂贵。这一阶段的失败率也更高，因为由于细胞模型结构的差异，体外研究的结果不一定与动物研究相关。</p><p id="4947" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated"><strong class="kt ir"> <em class="ln">注意要牢记:</em> </strong> <em class="ln">如果我们能早点失败，而不是晚点失败呢？在如此昂贵的阶段失败是没有意义的，如果我们在体外研究阶段失败了呢？</em></p><h2 id="df85" class="mt mb iq bd mc mu mv dn mg mw mx dp mk la my mz mm le na nb mo li nc nd mq ne bi translated">6.最后，我们进行临床试验(6 年以上)</h2><p id="9c1a" class="pw-post-body-paragraph kr ks iq kt b ku nf jr kw kx ng ju kz la nh lc ld le ni lg lh li nj lk ll lm ij bi translated">如果上述所有阶段的结果都表明该化合物有前景，那么它将进入临床试验。临床试验有三个阶段，每个阶段都有不同的目标。临床试验的主要目标是验证化合物或潜在药物在人类环境中的有效性和安全性。</p><p id="922b" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated"><strong class="kt ir"> <em class="ln">问题#3: </em> </strong> <em class="ln">临床试验有许多监管方面，这就是为什么它是最漫长和最昂贵的阶段。证明药物的疗效往往不是一件容易的事；具体来说，化合物的长期副作用通常在一段时间后仍然未知。在人身上试验新药总是存在巨大的内在风险。三期临床试验的平均费用估计为 1900 万美元。</em></p><h2 id="9358" class="mt mb iq bd mc mu mv dn mg mw mx dp mk la my mz mm le na nb mo li nc nd mq ne bi translated">7.还有最后一个阶段:FDA 批准和商业化(1 年以上)</h2><p id="6541" class="pw-post-body-paragraph kr ks iq kt b ku nf jr kw kx ng ju kz la nh lc ld le ni lg lh li nj lk ll lm ij bi translated">一旦所有测试完成，该化合物可以提交给美国食品和药物管理局审查批准。一旦获得批准，这种药物终于可以在患者手中商业化，以改善生活和治疗疾病！！！！！！—有史以来最激动人心的部分，但这是一次极其漫长和昂贵的旅程！</p><p id="bbd4" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated"><strong class="kt ir"> <em class="ln">问题#4: </em> </strong> <em class="ln">新上市的药物往往极其昂贵，这是因为研发的成本非常高。公司通常有 20 年的专利来保护他们的药物/产品免受竞争。这意味着他们可以将药物定价在他们认为合理的价格上。有时，这一价格可能高达数十万美元，使普通大众无法承受。</em></p><p id="b04a" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated"><strong class="kt ir">需要牢记的注意事项:</strong>我们如何才能加快药物发现的进程？</p><p id="afa2" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">哇，那是一次旅行🌄！</p><p id="e0e8" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">但是，如果有一种方法可以将早期药物发现(除了临床试验+商业化之外的所有阶段)的过程从 6 年大大加快到 6 天，会怎么样呢？我很乐观，我一点也不觉得这是科幻！其实这是有可能的！我们并不缺乏实现这一点所需的工具，我们只是缺乏乐观和合适的人。</p><h2 id="011c" class="mt mb iq bd mc mu mv dn mg mw mx dp mk la my mz mm le na nb mo li nc nd mq ne bi translated">当前的创新:加速药物发现</h2><ul class=""><li id="1db9" class="nk nl iq kt b ku nf kx ng la nm le nn li no lm np nq nr ns bi translated"><a class="ae nt" href="https://www.technologyreview.com/f/614251/an-ai-system-identified-a-potential-new-drug-in-just-46-days/" rel="noopener ugc nofollow" target="_blank">in silico Medicine</a>(AI+pharmaceutical startup)能够在短短 46 天内设计、合成和验证新的候选药物。</li><li id="a4ee" class="nk nl iq kt b ku nu kx nv la nw le nx li ny lm np nq nr ns bi translated"><a class="ae nt" href="https://deepmind.com/blog/article/alphafold" rel="noopener ugc nofollow" target="_blank"> AlphaFold </a>(谷歌的人工智能算法)能够以前所未有的速度和精度预测蛋白质的三维结构(药物发现中的关键评估)，超过了该领域一些世界上最好的生物学家和研究人员。</li></ul><p id="e955" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">人是推动增长的唯一最重要的因素，而不是其他因素。不管你是一个 16 岁的高中生(剧透:那是我)，还是一个著名的人工智能研究者，我相信我们所有人都可以做一些事情来创造影响。作为一个好奇的 16 岁少年，这也是我决定做点什么的根本原因。</p><h1 id="c1ed" class="ma mb iq bd mc md me mf mg mh mi mj mk jw ml jx mm jz mn ka mo kc mp kd mq mr bi translated">Synbiolic 简介:利用变分自动编码器进行药物发现</h1><p id="1a15" class="pw-post-body-paragraph kr ks iq kt b ku nf jr kw kx ng ju kz la nh lc ld le ni lg lh li nj lk ll lm ij bi translated">我们已经坚持同样的过程，做了大量的湿实验室实验，经历了一堆药物发现的试验和错误太久了！药物研发的人工流程必须改变！</p><p id="61fe" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">是时候来点新的了，<strong class="kt ir"> </strong>介绍<strong class="kt ir"> <em class="ln"> Synbiolic </em>:推断人工智能的潜力，特别是变型自动编码器(VAE)以 SMILES </strong>的格式生成新的&amp;有效分子(简化的分子输入行输入系统)。</p><h2 id="57c8" class="mt mb iq bd mc mu mv dn mg mw mx dp mk la my mz mm le na nb mo li nc nd mq ne bi translated">Synbiolic 的魔法是如何发挥作用的？</h2><ol class=""><li id="60e8" class="nk nl iq kt b ku nf kx ng la nm le nn li no lm nz nq nr ns bi translated"><em class="ln">使用</em><strong class="kt ir"><em class="ln">VAE</em></strong><em class="ln">的魔棒生成分子</em></li><li id="6eb5" class="nk nl iq kt b ku nu kx nv la nw le nx li ny lm nz nq nr ns bi translated"><em class="ln">使用更多的魔法将生成的分子列表过滤成几个真正好的分子</em></li></ol><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi oa"><img src="../Images/2c3279a34cc0e7f79344dee611cd69b8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*YMGEO19ENC1Y7GxEvidGpQ.jpeg"/></div></div><figcaption class="lw lx gj gh gi ly lz bd b be z dk">Imagine if drug discovery was as easy and fun as lego building!</figcaption></figure><p id="e57f" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">这里有一个<em class="ln">内部</em>的魔术是怎么回事！</p><h2 id="aeff" class="mt mb iq bd mc mu mv dn mg mw mx dp mk la my mz mm le na nb mo li nc nd mq ne bi translated">除了是一个人工智能+书呆子的时髦词，什么是变化的自动编码器？</h2><p id="2eda" class="pw-post-body-paragraph kr ks iq kt b ku nf jr kw kx ng ju kz la nh lc ld le ni lg lh li nj lk ll lm ij bi translated">变分自动编码器(VAE)是一种类型的<strong class="kt ir"><em class="ln"/></strong>机器学习算法。<strong class="kt ir">生成模型是一种人工智能架构，它能够<em class="ln">生成与训练数据特征相似的新数据</em>。</strong></p><p id="7c6b" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">它由两个神经网络组成:<strong class="kt ir"> (1)编码器，和(2)解码器。<em class="ln"> </em> </strong> <em class="ln">注:编码器和解码器可以使用不同的神经网络。</em></p><p id="fe37" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated"><strong class="kt ir">编码器网络负责降低输入到模型中的数据的维度，解码器网络通过将数据的紧凑表示重建回其原始维度/输入来反转该过程。</strong></p><p id="a181" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">数据的紧凑表示被称为<strong class="kt ir">潜在空间表示</strong>(也称为瓶颈)。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ob"><img src="../Images/1d462425c48ccd74d9d5a9ccb848c5af.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*jpwzYCRuQNYhBKqdzF_SFg.png"/></div></div><figcaption class="lw lx gj gh gi ly lz bd b be z dk">Autoencoder 💻</figcaption></figure><p id="9a14" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">Synbiolic 利用 VAE 生成新的分子，这些分子具有类似药物的特性，类似于用于训练模型的分子。生成的分子与训练分子并不完全相同，而是训练分子的变体。</p><p id="795a" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">为了更直观地理解编码器和解码器模型的功能，让我们来玩一个猜字谜游戏！</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi oc"><img src="../Images/60bfc65e339f6785c1a77ff5a7bdb049.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*-lIsIUnR1KAjZgy5e5k4cQ.jpeg"/></div></div><figcaption class="lw lx gj gh gi ly lz bd b be z dk">Finding Demo 😍</figcaption></figure><p id="7152" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">让我们进入编程模式，从声明一些变量开始🤖:</p><ul class=""><li id="dd4e" class="nk nl iq kt b ku kv kx ky la od le oe li of lm np nq nr ns bi translated">右边的女士=编码器</li><li id="60eb" class="nk nl iq kt b ku nu kx nv la nw le nx li ny lm np nq nr ns bi translated">左边的先生=解码器</li><li id="6494" class="nk nl iq kt b ku nu kx nv la nw le nx li ny lm np nq nr ns bi translated">海底总动员=潜在空间/分子的紧凑表示</li><li id="d807" class="nk nl iq kt b ku nu kx nv la nw le nx li ny lm np nq nr ns bi translated">动作=生成的分子</li></ul><p id="bfe5" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">猜测短语“海底总动员”<em class="ln">(*分子的紧凑表示*) </em>的女士类似于编码器，因为她将“动作”<em class="ln">(*分子*) </em>浓缩成短语<em class="ln">(*分子的紧凑表示*)。</em>就 AI 语言而言，她本质上是在建构“行动”的潜在表征<em class="ln">(*分子*) </em>。这类似于编码器如何将用于表示分子的维度减少到更紧凑的形式。</p><p id="46fc" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">扮演“海底总动员”的绅士<em class="ln">(*分子的紧凑表示*) </em>类似于解码者，因为他试图将短语重新解释为动作<em class="ln">(*分子*) </em>，这是扩展的表示。就生成分子而言，解码器通过基于其浓缩特征或潜在空间表示来重建分子来实现这一点。</p><h2 id="cf3c" class="mt mb iq bd mc mu mv dn mg mw mx dp mk la my mz mm le na nb mo li nc nd mq ne bi translated">但是，等等，是什么让变分自动编码器不同于普通自动编码器？</h2><p id="90c0" class="pw-post-body-paragraph kr ks iq kt b ku nf jr kw kx ng ju kz la nh lc ld le ni lg lh li nj lk ll lm ij bi translated">一个变化的自动编码器有一个编码器和解码器网络，就像上图中普通的自动编码器一样(在海底总动员之前的那个)👆。然而，它不仅仅是一个常规的机器学习模型，<strong class="kt ir"> VAE 为其编码器网络使用了一种概率方法。</strong></p><p id="026c" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">之所以用 VAE 代替自动编码器，主要是因为<strong class="kt ir">普通的自动编码器不能生成数据</strong>。这是因为普通的自动编码器(特别是编码器)似乎无法找出一种好的方法来创建“可用的”潜在空间表示，以馈入解码器网络，从而生成“好的”分子。</p><p id="b92f" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">当自动编码器试图生成新数据时，最终发生的是一个随机的潜在表示/向量被输入到解码器模型中，这反过来生成<em class="ln">真正时髦和无用的数据</em>。这是因为<strong class="kt ir">除了强迫编码器从训练数据中创建潜在向量之外，普通的自动编码器不知道如何获得“好的”潜在向量。</strong></p><p id="ca00" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated"><strong class="kt ir">普通自动编码器的潜在空间不是连续的，这就是它们不适合生成数据的原因。</strong></p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi og"><img src="../Images/ff1d7717fc142552dbb1b576f60a0352.png" data-original-src="https://miro.medium.com/v2/resize:fit:1098/format:webp/1*y8tDLIVygcrKtIn3a2B1Nw.png"/></div></figure><p id="5147" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">这意味着，采用上述图片中的潜在表示，解码器能够生成看起来不错的图片，但如果肤色等潜在参数中的一个从 0.85 到 0.84 稍有改变，那么解码器网络就会完全出错，最终可能会生成类似这样的结果:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi oh"><img src="../Images/82de220923fae7126fd7d36d12f4bae5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*xQMbMYiVQFApGpFu.jpg"/></div></div></figure><p id="a771" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated"><strong class="kt ir">这都是因为潜在空间表征不是连续的。</strong></p><p id="71b2" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">生成<em class="ln">随机</em>数据也没那么神奇。自动编码器无法实现的 VAE 的神奇之处在于，它是最好的生成模型之一，可以用来在<em class="ln">期望的方向上对你已经拥有的数据进行变化。</em> </p><p id="6734" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">编码器网络被表示为 q(z|x ),解码器网络被表示为 p(x|z ),因为 x 表示网络的输入，z 是潜在表示(它是一个向量)。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi oh"><img src="../Images/520c5a859ea985ebb608a2297e9e2e81.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*UQH8M9Rm-XkiX5Sl.png"/></div></div><figcaption class="lw lx gj gh gi ly lz bd b be z dk">Variational Autoencoder breakdown: Green is the encoder network, blue is the decoder network</figcaption></figure><p id="98a5" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">变化自动编码器的不同之处在于它的编码器网络利用了一个<em class="ln">概率模型</em>。<strong class="kt ir"> </strong>这使得<strong class="kt ir">潜在空间是连续的。</strong></p><p id="1d80" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">VAE 通过让它的编码器组合两个向量来做到这一点:<strong class="kt ir">一个向量取平均值，另一个向量取输入数据的标准偏差。</strong>然后从均值向量和标准差向量中通过<em class="ln">采样</em>构建潜在向量 z。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi oi"><img src="../Images/538d29640263a694c2b6e6b7d99ff888.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*KEl5nP779X3hOcNv.png"/></div></div><figcaption class="lw lx gj gh gi ly lz bd b be z dk"><strong class="bd oj">μ</strong> represents the mean and <strong class="bd oj">σ </strong>represents the standard deviation</figcaption></figure><p id="7209" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">通过采样，这允许潜在空间是连续的，而不是离散的。这就是为什么 VAEs 可以生成本质上是训练数据的变体的合成数据的原因。(我们可以通过优化潜在空间来有意地应用这些“变化”,以生成具有所需属性的新数据。)</p><p id="4a70" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">让我们继续关注这一切背后的<em class="ln">秘方</em>，也就是 Synbiolic 的 VAE 所用的模型。</p><p id="fd17" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated"><strong class="kt ir">对于编码器和解码器模型，使用以下神经网络:</strong></p><ul class=""><li id="de7e" class="nk nl iq kt b ku kv kx ky la od le oe li of lm np nq nr ns bi translated">编码器网络=卷积神经网络(CNN)</li><li id="f5dd" class="nk nl iq kt b ku nu kx nv la nw le nx li ny lm np nq nr ns bi translated">解码器网络=一种称为门控递归单元(GRU)的递归神经网络(RNN)</li></ul><h1 id="e304" class="ma mb iq bd mc md me mf mg mh mi mj mk jw ml jx mm jz mn ka mo kc mp kd mq mr bi translated">理解卷积神经网络:编码器</h1><p id="81ac" class="pw-post-body-paragraph kr ks iq kt b ku nf jr kw kx ng ju kz la nh lc ld le ni lg lh li nj lk ll lm ij bi translated">在我们深入 CNN 之前，让我们先来探索降维实际上是什么。</p><p id="8618" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated"><strong class="kt ir">降维是机器学习中的一种技术，用于通过<em class="ln">减少其特征来降低数据。</em> </strong></p><p id="e73c" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">编码器模型可以使用两种技术来执行维度缩减:</p><ol class=""><li id="f0a9" class="nk nl iq kt b ku kv kx ky la od le oe li of lm nz nq nr ns bi translated">按要素选择-仅选择部分要素，排除其余要素</li><li id="c0a6" class="nk nl iq kt b ku nu kx nv la nw le nx li ny lm nz nq nr ns bi translated">通过特征提取-将输入数据转换为潜在表示</li></ol><p id="91e7" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">这两种技术的区别在于，特征选择<em class="ln">不会改变特征，而特征提取会改变特征，因为它会对“输入特征/数据”进行变换，以获得潜在空间表示。</em></p><p id="e442" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">卷积神经网络(CNN)是一种深度学习算法，由于其检测特征的能力而广泛用于图像分类。</p><p id="9c7c" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated"><strong class="kt ir">他们通过实施特征提取来做到这一点，从而降低输入数据的维度。</strong></p><p id="b477" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">和其他深度学习算法一样，CNN 由<strong class="kt ir">【1】个输入层、【2】个隐藏层、【3】个输出层组成。</strong></p><p id="d291" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">隐藏层由几个不同类型的层组成，如卷积层、池层和全连接层。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ok"><img src="../Images/d3fac43fc6926d91875044d625750815.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*F2Ik_XFzmu5jZF-byiAKQQ.jpeg"/></div></div><figcaption class="lw lx gj gh gi ly lz bd b be z dk">Convolutional Neural Networks</figcaption></figure><p id="3cfb" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">使“卷积神经网络”成为“卷积神经网络”的是卷积层。是的，就这么简单，实际上，也许没那么简单…</p><p id="e8f1" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">卷积层本质上执行输入和滤波器之间的点积，以获得数据的低维表示(也就是说，卷积层由数学支持)。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi ol"><img src="../Images/4db6bcc911dbcb7a7e0ada37c896fe9e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1052/0*IVIiDkrtcKAhgbLT.gif"/></div><figcaption class="lw lx gj gh gi ly lz bd b be z dk"><strong class="bd oj">The yellow matrix is the filter</strong>, the green matrix is the input image, and the pink matrix is the convolved feature or latent representation.</figcaption></figure><p id="571b" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">如你所见，卷积特征在尺寸上比原始输入更加紧凑。</p><p id="ae3b" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">要了解更多关于卷积神经网络及其在皮肤癌检测中的应用，请查看本文！</p><p id="87b9" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">我没有像从痣的图像中检测皮肤癌那样使用 CNN 进行图像分类，而是在分子数据集上训练 CNN。</p><p id="5e7c" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">VAE 在包含 250 000 个分子的锌数据集上进行训练。编码器(CNN)将分子特征的表示转化为更紧凑的表示。</p><h1 id="4d9f" class="ma mb iq bd mc md me mf mg mh mi mj mk jw ml jx mm jz mn ka mo kc mp kd mq mr bi translated">解码器呢？</h1><p id="aa26" class="pw-post-body-paragraph kr ks iq kt b ku nf jr kw kx ng ju kz la nh lc ld le ni lg lh li nj lk ll lm ij bi translated">对于解码器，使用一种称为门控递归单元(GRU)的特定类型的递归神经网络(RNN)。</p><p id="e3f0" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">与其他类型的神经网络不同，<strong class="kt ir">rnn 具有内部记忆能力。</strong>rnn 通常应用于<strong class="kt ir">序列数据</strong>，因为它们的特殊属性是它们的决策受网络内的先前输入和输出<strong class="kt ir"> <em class="ln">的影响。</em></strong></p><p id="d990" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">普通神经网络也具有“记忆”事物的能力，但它们仅限于记忆来自<strong class="kt ir"> <em class="ln">先前</em>训练迭代的事物。</strong></p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi om"><img src="../Images/596f20089b7958cf8970c4ca4b4936bd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*50hQh5I_Zs-dNJFT.png"/></div></div><figcaption class="lw lx gj gh gi ly lz bd b be z dk">“Vanilla” Neural Network</figcaption></figure><p id="4d77" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">相比之下，rnn 记住每次训练迭代中的事情，并根据输入和前一个隐藏状态生成的输出做出决策。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi om"><img src="../Images/2f6905db96f9c4e30d3a743e194b4fa6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*U4H-F0XTnwbSxJH1.png"/></div></div><figcaption class="lw lx gj gh gi ly lz bd b be z dk">x nodes are the inputs, y nodes are the outputs, and h nodes are the hidden nodes</figcaption></figure><p id="06bd" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated"><strong class="kt ir">这样想:</strong>还记得你的数学老师曾经告诉你，如果你不知道数字的加减乘除，你将永远无法掌握微积分！这是因为作为人类，我们理解概念的基础是我们之前学过的概念。</p><p id="43aa" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">这类似于你在读这句话时，你是基于对前面单词的理解来理解这句话的。如果我只写“以前的话”作为句子，你不会明白我想说什么。本质上，这是 rnn 真正擅长做的事情:像句子结构一样剖析顺序数据的含义。</p><p id="8667" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">RNNs 的内部存储容量指的是它能够记住网络中以前的信息，以帮助它做出决策。他们能够通过理解序列中前一个值之间的联系来预测序列数据中的下一个值。</p><p id="b0b6" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">所有机器学习都是由数学驱动的，RNNs 的数学由隐藏状态(h)组成，这些隐藏状态是隐藏节点。</p><p id="bd7b" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">隐藏状态是相互联系的。在每个隐藏状态中，都有门，门是控制信息传递的神经网络。</p><p id="d9b7" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">对于计算信息的隐藏状态，必须对其进行预处理并将其转换为矩阵/向量表示。</p><p id="9f4c" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">“普通”rnn 的隐藏状态如下所示:</p><ul class=""><li id="88c5" class="nk nl iq kt b ku kv kx ky la od le oe li of lm np nq nr ns bi translated">前一隐藏状态的输出与当前输入组合形成一个向量，该向量包括关于当前和前一输入的信息。</li><li id="9672" class="nk nl iq kt b ku nu kx nv la nw le nx li ny lm np nq nr ns bi translated">这个向量通过一个 tanh 激活函数，该函数将范围限制在-1 和 1 之间，以产生新的隐藏状态。</li></ul><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi on"><img src="../Images/6a42b266c1d4b6fb7640fd8dc389941e.png" data-original-src="https://miro.medium.com/v2/resize:fit:836/format:webp/1*NOufYE9aGGwIiFi7y5wtcg.png"/></div></figure><p id="680e" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">然而，传统的 RNN 遭遇了一个被称为消失梯度下降的问题。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi om"><img src="../Images/c4ed1a86660e9f2578468d57deb671b7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*BTHuJTX-CywYl21l.png"/></div></div></figure><p id="a60b" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">当训练传统 RNN 时发生的是，随着权重被更新，梯度变得如此之小，以至于更新的权重变得不重要。如果原始权重实际上保持不变，这意味着在该模型中有<em class="ln">很少或没有学习</em>。</p><p id="a07b" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">小的梯度更新不会导致任何显著的学习，从而阻止模型完成它的工作。</p><p id="b237" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">为了解决这个问题，我为解码器实现了门控循环单元(RNN，但有所改变),而不是使用“传统的”RNN。</p><p id="7fec" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">门控循环单元(GRU)中涉及两个门:<strong class="kt ir">更新门和复位门。</strong>本质上，门只是隐藏节点内的<em class="ln">神经网络</em>。</p><p id="9b91" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">与 RNN 不同，<strong class="kt ir"> GRU 只记住重要的短语和单词，而不是记住句子中的每个单词。</strong></p><p id="bacf" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">比如，我们来看看这句话:</p><blockquote class="lo lp lq"><p id="4558" class="kr ks ln kt b ku kv jr kw kx ky ju kz lr lb lc ld ls lf lg lh lt lj lk ll lm ij bi translated"><em class="iq">“为了研究如何最好地加速罕见病研究的问题，我们将回顾一些罕见病研究中的挑战以及最近的科学进步为治疗发展带来的机遇。”</em></p></blockquote><p id="7f3d" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">像“to”、“the”、“of”、“that”和“for”这样的词与句子的意思并不相关，因此 GRU 人会忘记这些词。</p><blockquote class="lo lp lq"><p id="4f14" class="kr ks ln kt b ku kv jr kw kx ky ju kz lr lb lc ld ls lf lg lh lt lj lk ll lm ij bi translated"><em class="iq">为了考察如何最好地</em> <strong class="kt ir"> <em class="iq">加速罕见病研究</em> </strong> <em class="iq">的问题，我们将回顾一下</em> <strong class="kt ir"> <em class="iq">中的一些挑战</em></strong><em class="iq"/><strong class="kt ir"><em class="iq">罕见病研究</em> </strong> <em class="iq">和</em> <strong class="kt ir"> <em class="iq">中的机遇</em> </strong> <em class="iq">对于</em> <strong class="kt ir"> <em class="iq">疗法的发展</em></strong></p></blockquote><p id="6c82" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">RNN 可能试图记住整个句子，而 GRU 只记住重要的术语(上面用粗体表示)。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi oo"><img src="../Images/1f9ee15d65b7cc409c8376d2cb6e8d4c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*jToDg3P4GEiZU1j0.png"/></div></div><figcaption class="lw lx gj gh gi ly lz bd b be z dk">Gated Recurrent Unit</figcaption></figure><h2 id="3ca0" class="mt mb iq bd mc mu mv dn mg mw mx dp mk la my mz mm le na nb mo li nc nd mq ne bi translated">更新门</h2><p id="195f" class="pw-post-body-paragraph kr ks iq kt b ku nf jr kw kx ng ju kz la nh lc ld le ni lg lh li nj lk ll lm ij bi translated">更新门的职责是确定需要保留多少来自先前隐藏状态的信息。<strong class="kt ir">消失梯度下降问题通过通过这个门来解决，因为模型能够决定它需要将多少过去的信息传递给未来的隐藏状态。</strong></p><h2 id="0fad" class="mt mb iq bd mc mu mv dn mg mw mx dp mk la my mz mm le na nb mo li nc nd mq ne bi translated">复位门</h2><p id="b1d0" class="pw-post-body-paragraph kr ks iq kt b ku nf jr kw kx ng ju kz la nh lc ld le ni lg lh li nj lk ll lm ij bi translated">来自先前隐藏状态的输出和当前输入组合形成一个向量，该向量包括关于当前输入和先前输入的信息。每个向量不仅包含当前隐藏状态的信息，还包含先前隐藏状态的信息。</p><p id="9b53" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">重置门的工作是决定模型应该忘记哪些过去的信息。本质上，这个门的功能与更新门的功能相反。</p><p id="41d0" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">在生成分子的场景中，GRU 或解码器的输入是表示分子的压缩形式或潜在空间表示的向量。GRU 的最终输出是分子在其原始/扩展表示中的重建。</p><p id="f102" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">衡量分子药物相似性的量称为 QED(药物相似性的定量估计)。我获得了生成分子的 QED，以验证它们是类药物分子。</p><p id="0709" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">QED 低于 0.5 的所有生成分子都被忽略，这确保了生成分子的质量。可以合成具有最高 QED 值的分子，以通过体外和体内研究进一步验证它们的性质！</p></div><div class="ab cl op oq hu or" role="separator"><span class="os bw bk ot ou ov"/><span class="os bw bk ot ou ov"/><span class="os bw bk ot ou"/></div><div class="ij ik il im in"><p id="a323" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">耶！我们能够成功地设计和验证分子！这个被归类为早期药物设计的过程至少需要 3 年的传统研究才能完成！</p><p id="39d2" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">如果你感兴趣，可以在这里查看来自 Github 的源代码。</p><p id="3a3b" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">这要感谢我的优秀团队:<a class="ow ox ep" href="https://medium.com/u/bd6ad9886982?source=post_page-----8b2a64333e07--------------------------------" rel="noopener" target="_blank">雅利安·米斯拉</a> &amp; <a class="ow ox ep" href="https://medium.com/u/b295dac7f56?source=post_page-----8b2a64333e07--------------------------------" rel="noopener" target="_blank">埃利亚斯·昆图里斯</a>！</p><h2 id="2b4f" class="mt mb iq bd mc mu mv dn mg mw mx dp mk la my mz mm le na nb mo li nc nd mq ne bi translated">关键要点:</h2><ul class=""><li id="eef8" class="nk nl iq kt b ku nf kx ng la nm le nn li no lm np nq nr ns bi translated">药物研发极其昂贵且漫长</li><li id="10ba" class="nk nl iq kt b ku nu kx nv la nw le nx li ny lm np nq nr ns bi translated">VAE 是一种生成神经网络，可用于生成药物发现的分子</li><li id="83af" class="nk nl iq kt b ku nu kx nv la nw le nx li ny lm np nq nr ns bi translated">人工智能是一个强大的工具，可以用来彻底改变医疗保健</li></ul><h2 id="0e87" class="mt mb iq bd mc mu mv dn mg mw mx dp mk la my mz mm le na nb mo li nc nd mq ne bi translated">不要忘记:</h2><ul class=""><li id="b2d5" class="nk nl iq kt b ku nf kx ng la nm le nn li no lm np nq nr ns bi translated">访问 Synbiolic 的网站,了解更多关于 16 岁青少年的活动！</li><li id="b7be" class="nk nl iq kt b ku nu kx nv la nw le nx li ny lm np nq nr ns bi translated">在<a class="ae nt" href="https://www.linkedin.com/in/joey-mach-6293b1175/?originalSubdomain=ca" rel="noopener ugc nofollow" target="_blank"> LinkedIn </a>上和我联系！</li></ul><p id="03ee" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated"><strong class="kt ir"> <em class="ln">来自《走向数据科学》编辑的提示:</em> </strong> <em class="ln">虽然我们允许独立作者根据我们的</em> <a class="ae nt" rel="noopener" target="_blank" href="/questions-96667b06af5"> <em class="ln">规则和指导方针</em> </a> <em class="ln">发表文章，但我们并不认可每个作者的贡献。你不应该在没有寻求专业建议的情况下依赖一个作者的作品。详见我们的</em> <a class="ae nt" rel="noopener" target="_blank" href="/readers-terms-b5d780a700a4"> <em class="ln">读者术语</em> </a> <em class="ln">。</em></p></div></div>    
</body>
</html>