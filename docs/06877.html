<html>
<head>
<title>Prediction &amp; Calibration Techniques to Optimize Performance of Machine Learning Models</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">优化机器学习模型性能的预测和校准技术</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/calibration-techniques-of-machine-learning-models-d4f1a9c7a9cf?source=collection_archive---------10-----------------------#2019-09-30">https://towardsdatascience.com/calibration-techniques-of-machine-learning-models-d4f1a9c7a9cf?source=collection_archive---------10-----------------------#2019-09-30</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><h2 id="2b33" class="ir is it bd b dl iu iv iw ix iy iz dk ja translated" aria-label="kicker paragraph">机器学习性能优化</h2><div class=""/><div class=""><h2 id="0087" class="pw-subtitle-paragraph jz jc it bd b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq dk translated">Python 代码示例</h2></div><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi kr"><img src="../Images/5bc93a29a2af20e227bda5a720e5b503.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*zHcJj8EKmDh7nv_XLIWTOw.png"/></div></div><figcaption class="ld le gj gh gi lf lg bd b be z dk">Image by author</figcaption></figure><p id="386c" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi md translated"><span class="l me mf mg bm mh mi mj mk ml di"> C </span> <strong class="lj jd">校准</strong>是改善预测模型误差分布的后处理技术。</p><p id="27f0" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">机器学习(ML)模型的评估是部署之前的关键步骤。因此，有必要对一个 ML 模型进行行为分析。在许多实际应用中，除了模型的平均误差之外，了解该误差是如何分布的以及概率估计的好坏也很重要。根据我的经验，许多当前的 ML 技术在总体结果上是好的，但是具有差的误差分布评估。我将讨论常用的校准技术和使用分类的校准方法。</p><blockquote class="mm mn mo"><p id="2008" class="lh li mp lj b lk ll kd lm ln lo kg lp mq lr ls lt mr lv lw lx ms lz ma mb mc im bi translated">从科学的角度来看，ML 方法的主要目标是从给定的数据集建立一个假设(模型)。在学习过程之后，必须尽可能精确地评估假设的质量。</p></blockquote><p id="0578" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">对于基于分类的模型，常见的度量是精度(误差的倒数)、f 度量或宏观平均。在概率分类中，除了正确分类实例的百分比之外，还使用了其他度量，如对数损失、均方误差(MSE)(或 Brier 氏评分)或 ROC 曲线下面积(AUROC)。如果输出不是二进制的，而是 0 到 1 之间的浮点数，那么分数可以用于排名。但是 0 和 1 之间的浮点数导致了<em class="mp">概率</em>，我们怎么知道我们是否可以相信它们是概率呢？</p><h2 id="d95c" class="mt mu it bd mv mw mx dn my mz na dp nb lq nc nd ne lu nf ng nh ly ni nj nk iz bi translated">为什么我们需要校准的分类器:</h2><p id="2ad5" class="pw-post-body-paragraph lh li it lj b lk nl kd lm ln nm kg lp lq nn ls lt lu no lw lx ly np ma mb mc im bi translated">我们需要一个好的分类器来区分真阳性和真阴性。我们这里要处理电信客户数据；因此，在" C <em class="mp"> hurn" </em>分析中，我们期望分类器触发"<em class="mp"> Churn </em>"和"<em class="mp"> NoChurn </em>"之间的标志，这允许我们通过调整阈值来校准该模型的灵敏度。这意味着，如果分类器可以检测到 90%的“流失”可能性，企业应该将其视为真正的标签。此外，大多数与分类相关的数据非常不平衡，其中<em class="mp">【流失】</em>的数量远远小于<em class="mp">无流失</em>。因此，我们可能想要重新采样数据以平衡它们，这样我们可能会使我们的模型过于激进，从而导致一些<em class="mp">偏差</em>。</p><h2 id="05c3" class="mt mu it bd mv mw mx dn my mz na dp nb lq nc nd ne lu nf ng nh ly ni nj nk iz bi translated">二元分类器:</h2><p id="bf2f" class="pw-post-body-paragraph lh li it lj b lk nl kd lm ln nm kg lp lq nn ls lt lu no lw lx ly np ma mb mc im bi translated">在处理两类分类问题时，我们总是可以把一类标为正类，而把另一类标为负类。测试集由 P 个正例和 N 个负例组成。一个分类器给他们每个人分配一个类，但是有些分配是错误的。为了评估分类结果，我们计算真阳性(TP)、真阴性(TN)、假阳性(FP)(实际上是阴性，但被分类为阳性)和假阴性(FN)(实际上是阳性，但被分类为阴性)例子的数量。它保持住了</p><ul class=""><li id="8a12" class="nq nr it lj b lk ll ln lo lq ns lu nt ly nu mc nv nw nx ny bi translated">TP + FN = P 和</li><li id="c68a" class="nq nr it lj b lk nz ln oa lq ob lu oc ly od mc nv nw nx ny bi translated">TN + FP = N</li></ul><p id="8927" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">分类器将 TP + FP 实例分配给正类，将 TN + FN 实例分配给负类。让我们定义几个众所周知和广泛使用的衡量标准:</p><ul class=""><li id="02b4" class="nq nr it lj b lk ll ln lo lq ns lu nt ly nu mc nv nw nx ny bi translated">FPrate = FP /N</li><li id="cffb" class="nq nr it lj b lk nz ln oa lq ob lu oc ly od mc nv nw nx ny bi translated">TPrate = TP /P = Recall</li><li id="d0ee" class="nq nr it lj b lk nz ln oa lq ob lu oc ly od mc nv nw nx ny bi translated">Yrate = (TP + FP) /(P + N)</li><li id="f159" class="nq nr it lj b lk nz ln oa lq ob lu oc ly od mc nv nw nx ny bi translated">精度= TP/ (TP + FP)</li><li id="b9a5" class="nq nr it lj b lk nz ln oa lq ob lu oc ly od mc nv nw nx ny bi translated">准确率= (TP + TN)/ (P + N)。</li></ul><p id="e8bc" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">精度和准确度通常用来衡量二元分类器的分类质量。也可以定义用于特殊目的的其他几种度量。我们将在下面的章节中对它们进行描述</p><h2 id="f867" class="mt mu it bd mv mw mx dn my mz na dp nb lq nc nd ne lu nf ng nh ly ni nj nk iz bi translated">概率分类器:</h2><p id="3597" class="pw-post-body-paragraph lh li it lj b lk nl kd lm ln nm kg lp lq nn ls lt lu no lw lx ly np ma mb mc im bi translated">概率分类器是一个函数 f : X → [0，1],它将每个例子 X 映射到一个实数 f(x)。通常，选择阈值 t，其中 f(x) ≥ t 的例子被认为是正的，其他的被认为是负的。这意味着每对概率分类器和阈值 t 定义了一个二元分类器。因此，上一节中定义的度量也可用于概率分类器，但它们始终是阈值 t 的函数。注意，TP(t)和 FP(t)始终是单调递减函数。对于有限的示例集，它们是逐步的，而不是连续的。通过改变 t，我们得到一族二元分类器。</p><p id="c387" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">让我们用现有的电信数据做实验。</p><pre class="ks kt ku kv gt oe of og oh aw oi bi"><span id="cdb8" class="mt mu it of b gy oj ok l ol om"># Loading the CSV with pandas<br/>data = pd.read_csv(‘Telco_Customer_Churn.csv’)</span><span id="9e04" class="mt mu it of b gy on ok l ol om">data.dtypes # types of data in data set</span></pre><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi oo"><img src="../Images/9bd712f4b874f44b4a2f72d1b3508d50.png" data-original-src="https://miro.medium.com/v2/resize:fit:598/format:webp/1*OuGQPRIgldQFOzKb1PhNzw.png"/></div></figure><pre class="ks kt ku kv gt oe of og oh aw oi bi"><span id="0870" class="mt mu it of b gy oj ok l ol om">#Removing customer IDs from the data set the columns not used in the predictive model.<br/>df = data.drop(“customerID”, axis=1)<br/>df.info()</span></pre><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi op"><img src="../Images/6d8e691ce0a82f6dee2f8ede6462c8bf.png" data-original-src="https://miro.medium.com/v2/resize:fit:848/format:webp/1*hUzcfaFyllHOoCwZP7cVBQ.png"/></div></figure><p id="371b" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">我们将转换分类变量(<em class="mp">‘是’，‘否’</em>，等等)。)转换成数值。此外，需要将“<em class="mp">总费用”</em>转换为数字数据类型。此外，“<em class="mp">总费用</em>有 11 个缺失值。因此它将替换数据集中的 11 行。这里的预测变量是“<em class="mp">Churn”</em>。因此，也有必要将预测变量转换为二进制数值变量。</p><pre class="ks kt ku kv gt oe of og oh aw oi bi"><span id="a56b" class="mt mu it of b gy oj ok l ol om">df.dropna(inplace = True)</span><span id="30dc" class="mt mu it of b gy on ok l ol om">df[‘Churn’].replace(to_replace=’Yes’, value=1, inplace=True)<br/>df[‘Churn’].replace(to_replace=’No’, value=0, inplace=True)</span><span id="52ae" class="mt mu it of b gy on ok l ol om"># converting all the categorical variables into dummy variables<br/>df_dummies = pd.get_dummies(df)<br/>df_dummies.info()</span></pre><h2 id="e0df" class="mt mu it bd mv mw mx dn my mz na dp nb lq nc nd ne lu nf ng nh ly ni nj nk iz bi translated">分类算法:</h2><p id="fbaa" class="pw-post-body-paragraph lh li it lj b lk nl kd lm ln nm kg lp lq nn ls lt lu no lw lx ly np ma mb mc im bi translated">我们将考虑物流回归和随机森林分类器来预测客户流失。重要的是在回归中调整变量，使所有变量都在 0 到 1 的范围内。</p><pre class="ks kt ku kv gt oe of og oh aw oi bi"><span id="838d" class="mt mu it of b gy oj ok l ol om">df_dummies = df_dummies.drop(“TotalCharges”, axis=1) # removing Total Charges to avoid multi-colinearity.</span><span id="5da8" class="mt mu it of b gy on ok l ol om"># Using the data frame where we had created dummy variables<br/>y = df_dummies[‘Churn’].values<br/>X = df_dummies.drop(columns = [‘Churn’])</span><span id="7def" class="mt mu it of b gy on ok l ol om"># Scaling all the variables to a range of 0 to 1<br/>features = X.columns.values<br/>scaler = MinMaxScaler(feature_range = (0,1))<br/>scaler.fit(X)<br/>X = pd.DataFrame(scaler.transform(X))<br/>X.columns = features</span></pre><h2 id="bba1" class="mt mu it bd mv mw mx dn my mz na dp nb lq nc nd ne lu nf ng nh ly ni nj nk iz bi translated">方法:</h2><p id="43bc" class="pw-post-body-paragraph lh li it lj b lk nl kd lm ln nm kg lp lq nn ls lt lu no lw lx ly np ma mb mc im bi translated">我们的第一步是使用 train-test-split 将我们的数据分成训练集和测试集，这将允许我们稍后交叉验证我们的结果。我们还对训练-测试-分割进行了分层，以确保在我们的训练集和测试集中发现相同比例的目标变量。</p><h2 id="41af" class="mt mu it bd mv mw mx dn my mz na dp nb lq nc nd ne lu nf ng nh ly ni nj nk iz bi translated">拆分数据:</h2><p id="57ee" class="pw-post-body-paragraph lh li it lj b lk nl kd lm ln nm kg lp lq nn ls lt lu no lw lx ly np ma mb mc im bi translated">x 是自变量的数据，y 是因变量的数据。测试大小变量决定了数据的分割比例。在 90 的培训/10 的测试比例中，这样做是很常见的。此外，需要对培训-测试-拆分进行分层，以获得平衡的拆分</p><pre class="ks kt ku kv gt oe of og oh aw oi bi"><span id="649a" class="mt mu it of b gy oj ok l ol om">X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=101)<br/>print(‘length of X_train and x_test: ‘, len(X_train), len(X_test))<br/>print(‘length of y_train and y_test: ‘, len(y_train), len(y_test))</span></pre><h2 id="9d9b" class="mt mu it bd mv mw mx dn my mz na dp nb lq nc nd ne lu nf ng nh ly ni nj nk iz bi translated">逻辑回归:</h2><p id="9030" class="pw-post-body-paragraph lh li it lj b lk nl kd lm ln nm kg lp lq nn ls lt lu no lw lx ly np ma mb mc im bi translated">使用 ML 算法和因变量，这里的流失 1 或流失 0 是分类的。经过训练的模型可用于预测客户是否对测试数据集产生了兴趣。结果保存在“prediction_test”中，然后测量并打印准确度分数。</p><pre class="ks kt ku kv gt oe of og oh aw oi bi"><span id="6a56" class="mt mu it of b gy oj ok l ol om">lr_model = LogisticRegression(solver=’lbfgs’).fit(X_train, y_train)<br/>lr_prediction = lr_model.predict_proba(X_test)<br/>prediction_test = lr_model.predict(X_test)<br/>lr_pred = lr_model.predict(X_test)</span><span id="e41d" class="mt mu it of b gy on ok l ol om">print(classification_report(y_test, prediction_test))</span></pre><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi oq"><img src="../Images/d3dbb889154adf2b1778aa7772d93d20.png" data-original-src="https://miro.medium.com/v2/resize:fit:1016/format:webp/1*FLlCD8hefgjbwnyBJ3k27w.png"/></div></figure><ul class=""><li id="ab6a" class="nq nr it lj b lk ll ln lo lq ns lu nt ly nu mc nv nw nx ny bi translated">在第一类(NoChurn)的 557 个点中，该模型成功地正确识别了其中的 502 个点</li><li id="80f9" class="nq nr it lj b lk nz ln oa lq ob lu oc ly od mc nv nw nx ny bi translated">在第 1 类的 147 个点中，模型正确预测了其中的 77 个点</li><li id="6238" class="nq nr it lj b lk nz ln oa lq ob lu oc ly od mc nv nw nx ny bi translated">在总共 704 个中，模型正确预测了其中 579 个。</li></ul><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi or"><img src="../Images/3ee7bf1b9aaaa9b29120b982334a9823.png" data-original-src="https://miro.medium.com/v2/resize:fit:1166/format:webp/1*3cvIHezBvZZiIcXXMnwPWQ.png"/></div></figure><p id="bf09" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">准确率 82%(精确到 82.24%)。然而，考虑到数据是倾斜的，并且目标类别不平衡，这可能不是正确的衡量标准。所以，我们研究精确度，回忆，F 值。</p><p id="c96d" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">混淆矩阵清楚地显示了模型性能，分为真阳性、真阴性、假阳性和假阴性。</p><ul class=""><li id="6b77" class="nq nr it lj b lk ll ln lo lq ns lu nt ly nu mc nv nw nx ny bi translated">精度是分类器不将实际上是负的实例标记为正的能力。对于每个类别，它被定义为真阳性与真阳性和假阳性之和的比率。</li><li id="3929" class="nq nr it lj b lk nz ln oa lq ob lu oc ly od mc nv nw nx ny bi translated">召回是分类器找到所有肯定实例的能力。对于每个类别，它被定义为真阳性与真阳性和假阴性之和的比率。</li><li id="e5cf" class="nq nr it lj b lk nz ln oa lq ob lu oc ly od mc nv nw nx ny bi translated">F1 分数是精确度和召回率的加权调和平均值，最好的分数是 1.0，最差的是 0.0。</li></ul><h2 id="cbcf" class="mt mu it bd mv mw mx dn my mz na dp nb lq nc nd ne lu nf ng nh ly ni nj nk iz bi translated">等级校准(CC):</h2><p id="2867" class="pw-post-body-paragraph lh li it lj b lk nl kd lm ln nm kg lp lq nn ls lt lu no lw lx ly np ma mb mc im bi translated">CC 是真实类别分布与估计类别分布的近似程度。以这种方式校准模型的标准方法是通过改变确定模型何时预测“<em class="mp">客户流失</em>或“NoChurn”的阈值，使该阈值对“客户流失”类更严格，对“NoChurn”类更温和，以平衡比例。</p><pre class="ks kt ku kv gt oe of og oh aw oi bi"><span id="b74e" class="mt mu it of b gy oj ok l ol om">y_scores=lr_prediction<br/>prec, rec, tre = precision_recall_curve(y_test, y_scores[:,1], )</span><span id="e024" class="mt mu it of b gy on ok l ol om">def plot_prec_recall_vs_tresh(precisions, recalls, thresholds):<br/> fig, ax = plt.subplots(figsize=(10,6))<br/> plt.plot(thresholds, precisions[:-1], “r — “, label=”Precisions”)<br/> plt.plot(thresholds, recalls[:-1], “#424242”, label=”Recalls”)<br/> plt.ylabel(“Level of Precision and Recall”, fontsize=12)<br/> plt.title(“Precision and Recall Scores as a function of the decision threshold”, fontsize=12)<br/> plt.xlabel(‘Thresholds’, fontsize=12)<br/> plt.legend(loc=”best”, fontsize=12)<br/> plt.ylim([0,1])<br/> plt.axvline(x=0.47, linewidth=3, color=”#0B3861")<br/> <br/>plot_prec_recall_vs_tresh(prec, rec, tre)<br/>plt.show()</span></pre><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi os"><img src="../Images/cfc2a1cf0e114a42236361e41626e611.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*kTw1PBCLP8wdj7YTI4iklg.png"/></div></div></figure><p id="c431" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">正面类(<em class="mp">【流失】</em>)预测的准确率(58.33%)和召回率(52.38%)相对较低。交叉点上方的区域是良好性能水平的区域。下面的另一个区域是表现不佳的区域。原则上，这种类型的校准可能会产生更多的误差。事实上，通常情况下，我们希望获得一个有用的模型来解决非常不平衡的类分布问题，即少数类的例子非常少。</p><h2 id="2307" class="mt mu it bd mv mw mx dn my mz na dp nb lq nc nd ne lu nf ng nh ly ni nj nk iz bi translated">AUROC 曲线:</h2><p id="875a" class="pw-post-body-paragraph lh li it lj b lk nl kd lm ln nm kg lp lq nn ls lt lu no lw lx ly np ma mb mc im bi translated">衡量二元分类器性能的一种更直观的方法是接收器工作特性(AUROC)曲线下的面积。它说明了模型在多大程度上能够区分流失和非流失。</p><pre class="ks kt ku kv gt oe of og oh aw oi bi"><span id="c0f2" class="mt mu it of b gy oj ok l ol om">lr_prediction = lr_model.predict_proba(X_test)<br/>skplt.metrics.plot_roc(y_test, lr_prediction)</span></pre><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi ot"><img src="../Images/9ae64f663c2258b31b83d792ce3f7e06.png" data-original-src="https://miro.medium.com/v2/resize:fit:1118/format:webp/1*wfUrDl6kYUAOPVbj11CM4A.png"/></div></figure><blockquote class="ou"><p id="ed96" class="ov ow it bd ox oy oz pa pb pc pd mc dk translated">众所周知，AUROC 曲线很少受到类别分布变化的影响(放大对 FP 的影响很小，而我们可以看到对 TP 的一些影响)。</p></blockquote><p id="c8aa" class="pw-post-body-paragraph lh li it lj b lk pe kd lm ln pf kg lp lq pg ls lt lu ph lw lx ly pi ma mb mc im bi translated">宏平均独立计算每个类的指标，然后取平均值(因此平等对待所有类)，而微平均聚合所有类的贡献来计算平均指标。如果我们想知道系统在数据集上的整体表现，我们将考虑宏观平均。我们不应该用这个平均数做出任何具体的决定。另一方面，当我们的数据集大小不同时，微观平均是一个有用的度量。</p><p id="bb6b" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">因此，我们在这里看到，ROC 曲线未能明确显示平衡和不平衡情况之间的差异。此外，AUROC 分数不足以评估早期检索性能，尤其是当曲线相互交叉时。</p><p id="4299" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">我们将检查随机森林分类器；不过，我们就不再赘述了。类似的一套过程，如逻辑回归，可以做比较。</p><h2 id="e1e6" class="mt mu it bd mv mw mx dn my mz na dp nb lq nc nd ne lu nf ng nh ly ni nj nk iz bi translated">随机森林分类器:</h2><p id="e561" class="pw-post-body-paragraph lh li it lj b lk nl kd lm ln nm kg lp lq nn ls lt lu no lw lx ly np ma mb mc im bi translated">同样，训练一个随机森林模型并在验证集上进行预测。</p><pre class="ks kt ku kv gt oe of og oh aw oi bi"><span id="64b4" class="mt mu it of b gy oj ok l ol om">rf_model = RandomForestClassifier(random_state=101, n_estimators=100).fit(X_train, y_train)<br/>rf_prediction = rf_model.predict_proba(X_test)<br/>rf_model.score(X_test, y_test)</span></pre><p id="aec9" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi"># 0.7798295454545454</p><h2 id="5149" class="mt mu it bd mv mw mx dn my mz na dp nb lq nc nd ne lu nf ng nh ly ni nj nk iz bi translated">概率校准(PC):</h2><p id="7568" class="pw-post-body-paragraph lh li it lj b lk nl kd lm ln nm kg lp lq nn ls lt lu no lw lx ly np ma mb mc im bi translated">PC 伴随着概率估计的每个预测。如果我们预测我们有 99%的把握，如果我们只有 50%的时间是正确的，这是没有校准的，因为我们的估计过于乐观。类似地，如果我们预测我们只有 60%的把握，而我们 80%的时间是正确的，这是没有校准的，因为我们的估计太悲观了。在这两种情况下，正确猜测的数量或比例的期望值(在这种情况下是概率或置信度评估)与实际值不匹配。然后，校准被定义为预测概率与实际概率的接近程度。准确度和校准虽然相互依赖，但却是截然不同的两码事。</p><p id="29d6" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">这里，我们有类别概率和标签来计算校准图的箱。</p><pre class="ks kt ku kv gt oe of og oh aw oi bi"><span id="84e3" class="mt mu it of b gy oj ok l ol om">lr_y, lr_x = calibration_curve(y_test, lr_prediction[:,1], n_bins=20)<br/>rf_y, rf_x = calibration_curve(y_test, rf_prediction[:,1], n_bins=20)</span><span id="86f6" class="mt mu it of b gy on ok l ol om">fig, ax = plt.subplots()<br/># only these two lines are calibration curves<br/>plt.plot(lr_x,lr_y, marker=’o’, linewidth=1, label=’lr’)<br/>plt.plot(rf_x, rf_y, marker=’o’, linewidth=1, label=’rf’)</span><span id="e75f" class="mt mu it of b gy on ok l ol om"># reference line, legends, and axis labels<br/>line = mlines.Line2D([0, 1], [0, 1], color=’black’)<br/>transform = ax.transAxes<br/>line.set_transform(transform)<br/>ax.add_line(line)<br/>fig.suptitle(‘Calibration plot for Telecom data’)<br/>ax.set_xlabel(‘Predicted probability’)<br/>ax.set_ylabel(‘True probability in each bin’)<br/>plt.legend(); plt.show()</span></pre><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi pj"><img src="../Images/b67e41250bfc36bb7c6cf960433872d6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1044/format:webp/1*7i4-dN_sgjJBy_JaedLMSA.png"/></div></figure><pre class="ks kt ku kv gt oe of og oh aw oi bi"><span id="9ba0" class="mt mu it of b gy oj ok l ol om">def bin_total(y_true, y_prob, n_bins):<br/> bins = np.linspace(0., 1. + 1e-8, n_bins + 1)</span><span id="bcd1" class="mt mu it of b gy on ok l ol om"># In sklearn.calibration.calibration_curve the last value in the array is always 0.<br/> binids = np.digitize(y_prob, bins) — 1</span><span id="1534" class="mt mu it of b gy on ok l ol om">return np.bincount(binids, minlength=len(bins))<br/>bin_total(y_test, lr_prediction[:,1], n_bins=20)</span></pre><p id="e79c" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">#数组([191，88，47，58，46，32，30，32，24，24，25，22，22，19，24，17，2，1，0，0，0])</p><pre class="ks kt ku kv gt oe of og oh aw oi bi"><span id="9709" class="mt mu it of b gy oj ok l ol om">bin_total(y_test, rf_prediction[:,1], n_bins=20)</span></pre><p id="7843" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated"># array([213，70，59，47，39，42，27，27，22，18，26，21，22，18，7，12，10，6，7，11，0])</p><p id="b808" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">缺失的条柱具有 75%、85%和 95%的端点值。我们希望我们的预测能够避开那些空箱子，变得有鉴别力。在分类问题中，辨别和校准是并行不悖的。如果构建模型的目标是自动做出决策，而不是提供统计估计，有时它会出现在校准之前。在这里，查看 bin 中的点数，随机森林(橙色线)似乎比逻辑回归(蓝色线)更好。</p><p id="d401" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">一篇关于模型校准的有趣文章可以在<a class="ae pk" href="https://bit.ly/2IU9E7L" rel="noopener ugc nofollow" target="_blank"> <strong class="lj jd"> <em class="mp">这里</em> </strong> </a> <strong class="lj jd"> <em class="mp"> </em> </strong>找到补充阅读。</p><h1 id="3154" class="pl mu it bd mv pm pn po my pp pq pr nb ki ps kj ne kl pt km nh ko pu kp nk pv bi translated">总结:</h1><p id="3051" class="pw-post-body-paragraph lh li it lj b lk nl kd lm ln nm kg lp lq nn ls lt lu no lw lx ly np ma mb mc im bi translated">校准技术通常基于导出将值或概率转换为更好的估计值的变换。在分类的情况下，大多数转换技术通常包括宁滨或排序。我将为模型拟合评估推荐一个拟合优度测试(Hosmer-Lemeshow)。如果你有兴趣，你可以阅读<a class="ae pk" href="https://www2.stat.duke.edu/~zo2/dropbox/goflogistic.pdf" rel="noopener ugc nofollow" target="_blank"> <strong class="lj jd"> <em class="mp">这篇</em> </strong> </a>的文章来了解更多。</p><p id="b513" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated"><strong class="lj jd">我这里可以到达</strong><a class="ae pk" href="https://www.linkedin.com/in/saritmaitra/" rel="noopener ugc nofollow" target="_blank"><strong class="lj jd"><em class="mp"/></strong></a><strong class="lj jd">。</strong></p></div></div>    
</body>
</html>