<html>
<head>
<title>Tensorflow 2.0 Data Transformation for Text Classification</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">面向文本分类的 Tensorflow 2.0 数据转换</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/tensorflow-2-0-data-transformation-for-text-classification-b86ee2ad8877?source=collection_archive---------13-----------------------#2019-10-30">https://towardsdatascience.com/tensorflow-2-0-data-transformation-for-text-classification-b86ee2ad8877?source=collection_archive---------13-----------------------#2019-10-30</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="9166" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">一个完整的端到端文本分类过程</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/55d1485a79ba8b0f1e7cbf2d2233353a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Px_m10-RrcD-luiflXvW7g.png"/></div></div></figure><p id="0263" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">在本文中，我们将利用 Tensorflow 2.0 和 Python 来创建一个用于对电影评论进行分类的端到端流程。大多数 Tensorflow 教程侧重于如何使用预处理数据集设计和训练模型。通常，预处理数据是人工智能项目中最耗时的部分。本文将带您完成这一过程。注意:我们并不试图在这里生成一个最先进的分类模型。目标是解释如何在张量流模型中准备用于训练和评估的数据。我们将使用本页的<a class="ae lq" href="https://www.tensorflow.org/tutorials/keras/text_classification" rel="noopener ugc nofollow" target="_blank">中定义的模型，并通过解决本教程中未涉及的两个挑战来改进流程:</a></p><ol class=""><li id="0f53" class="lr ls it kw b kx ky la lb ld lt lh lu ll lv lp lw lx ly lz bi translated">我们如何将原始文本加载到模型中并对其进行训练？</li><li id="fa69" class="lr ls it kw b kx ma la mb ld mc lh md ll me lp lw lx ly lz bi translated">一旦创建并训练了模型，我们如何使用它根据新的输入数据生成预测？</li></ol><h2 id="586a" class="mf mg it bd mh mi mj dn mk ml mm dp mn ld mo mp mq lh mr ms mt ll mu mv mw mx bi translated">挑战 1</h2><p id="5ff2" class="pw-post-body-paragraph ku kv it kw b kx my ju kz la mz jx lc ld na lf lg lh nb lj lk ll nc ln lo lp im bi translated">我们如何将原始文本加载到模型中并对其进行训练？</p><p id="75b1" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">关于神经网络，你能知道的最重要的事情是，它们只对数字数据起作用。因此，为了进行文本分类，必须将原始文本数据转换为数字。Tensorflow 教程使用预处理数据集，其中所有文本都已转换为数值。这对于构建原型和评估不同的模型是很好的，但是它跳过了将文本数据转换成数字数据的过程。为了解决这个问题，我们将不使用预处理数据。相反，我们将下载并使用斯坦福大学提供的带标签的 IMDB 评论中的原始文本数据。</p><pre class="kj kk kl km gt nd ne nf ng aw nh bi"><span id="1d92" class="mf mg it ne b gy ni nj l nk nl">!wget -q <a class="ae lq" href="http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz" rel="noopener ugc nofollow" target="_blank">http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz</a><br/>!tar zxf aclImdb_v1.tar.gz<br/>!tree -d aclImdb</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nm"><img src="../Images/901e73c404144b19f25e45e4f129bcbd.png" data-original-src="https://miro.medium.com/v2/resize:fit:480/format:webp/1*JsqYBFWN6MJfiA8UtkdkuA.png"/></div></figure><p id="dddb" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">根目录包含我们的<em class="nn">测试</em>和<em class="nn">训练</em>数据集的子目录。在每个目录下，都有包含<em class="nn"> pos </em>和<em class="nn"> neg </em>评论的目录。每个目录包含 12500 条评论。注意，对于本教程，我们不使用<em class="nn">unsupp</em>目录。</p><p id="3968" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">现在我们需要创建一个 train 和 test dataframes，每个 dataframes 有两列:<strong class="kw iu"> text </strong>(评论文本)<strong class="kw iu"> </strong>和<strong class="kw iu"> sent </strong>(评论的情绪)。我们通过遍历该函数中的目录来实现这一点:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="no np l"/></div></figure><p id="d865" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">现在我们已经加载了数据，是时候将文本数据转换成数值了:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="no np l"/></div></figure><p id="3ebb" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">NUM_WORDS 是一个变量，包含我们希望保留在词汇表中的单词数。对于本例，我们将其设置为 8000。第 2 行和第 3 行创建了一个标记器，用于索引我们的训练数据中最常用的 8000 个标记。第 6&amp;7 行使用索引为评论中的每个单词生成数值。SEQ _ 伦是我们定义的另一个变量，用于确定每次评论使用多少单词。在本例中，我们将其设置为 256。因为我们模型的每个输入必须包含相同数量的标记，所以第 11 &amp; 12 行将每个评论截断为 256 个字符，如果评论少于 256 个字符，则填充它。</p><p id="fb3e" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">现在是时候构建和训练我们的模型了。大部分代码直接取自 Tensorflow 2.0 教程，尽管我对培训部分做了一些改进，我将在下面描述:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="no np l"/></div></figure><p id="0ce7" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">第 1 行到第 10 行直接来自教程，没有任何修改。在第 13 行到第 15 行，我添加了一个<strong class="kw iu"> EarlyStopping </strong>回调，如果验证精度开始下降，它会导致模型停止训练，这有助于减少过度拟合。第 16–20 行是我们实际训练模型的地方。我使用的参数与本教程略有不同，所以下面是对每个参数的描述:</p><ul class=""><li id="e065" class="lr ls it kw b kx ky la lb ld lt lh lu ll lv lp nq lx ly lz bi translated">batch_size —传递给训练周期每批的示例数量。最初的教程将此设置为 512。这是一个可调超参数的例子。在尝试了不同的值之后，16 给了我最好的结果，但是通过更新 BATCH_SIZE 常量可以很容易地改变它。</li><li id="2c45" class="lr ls it kw b kx ma la mb ld mc lh md ll me lp nq lx ly lz bi translated">epochs —我们通过模型运行完整训练集进行训练的次数。它被设置为 20，但是由于 EarlyStopping 被启用，它很可能永远不会达到这个值。如果达到了 20，你可以增加它来看看你是否能得到更好的结果。</li><li id="27d7" class="lr ls it kw b kx ma la mb ld mc lh md ll me lp nq lx ly lz bi translated">validation_split —这里我们说 20%的输入数据将用于验证我们的模型学习得有多好。如果我们开始看到我们的准确性增加，同时看到我们的验证准确性下降，那么我们是过度拟合。在这种情况下，我们应该停止训练，因为这已经是最好的了。</li><li id="3cf2" class="lr ls it kw b kx ma la mb ld mc lh md ll me lp nq lx ly lz bi translated">回调——这是我们传递早期停止回调的地方。</li></ul><p id="f560" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">在第 22 行，我们通过传入模型从未见过的新输入数据来评估模型。您应该会看到大约 87%的准确性，考虑到我们的神经网络仅用了大约四行代码来构建，这是相当不错的。在文章的最后，我将讨论一些事情，试图使模型更加准确。</p><h2 id="98fc" class="mf mg it bd mh mi mj dn mk ml mm dp mn ld mo mp mq lh mr ms mt ll mu mv mw mx bi translated">挑战#2</h2><p id="a51f" class="pw-post-body-paragraph ku kv it kw b kx my ju kz la mz jx lc ld na lf lg lh nb lj lk ll nc ln lo lp im bi translated">一旦创建并训练了模型，我们如何使用它根据新的输入数据生成预测？</p><p id="7d6c" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">原 Tensorflow 教程到此结束。在这一点上，我们有一个经过训练的模型，但还不清楚我们将来如何使用它来根据新数据进行预测。</p><p id="c71c" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">首先，我们需要保存模型和我们的标记器。我们是这样做的:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="no np l"/></div></figure><p id="603d" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">在第 2 行中，我们将模型及其所有权重保存到一个名为 model.h5 的文件中。然后我们可以删除我们的模型和记号化器，因为我们已经完成了训练。</p><p id="75c6" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">现在，我们准备使用我们的训练模型对一些新数据进行一些推断:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="no np l"/></div></figure><ul class=""><li id="3fcf" class="lr ls it kw b kx ky la lb ld lt lh lu ll lv lp nq lx ly lz bi translated">第 1–4 行从磁盘加载我们的模型和标记器。</li><li id="ac97" class="lr ls it kw b kx ma la mb ld mc lh md ll me lp nq lx ly lz bi translated">第 6–9 行将我们的文本输入转换为我们的模型需要的数字输入，其方式类似于我们为训练所做的。</li><li id="63c5" class="lr ls it kw b kx ma la mb ld mc lh md ll me lp nq lx ly lz bi translated">第 11-14 行包含了我写的一些评论。请随意在这里添加一些您自己的评论。</li><li id="bbdc" class="lr ls it kw b kx ma la mb ld mc lh md ll me lp nq lx ly lz bi translated">第 15 行调用我们的数据准备函数来为我们的输入数据生成数字序列。</li><li id="af63" class="lr ls it kw b kx ma la mb ld mc lh md ll me lp nq lx ly lz bi translated">第 17 行根据我们的输入数据做出预测。</li></ul><p id="10bb" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">需要注意的是，loaded_model.predict 的返回值是一组评论为正面的概率。为了解决这个问题，我使用一个阈值来确定一个评论是否是正面的。在这种情况下，如果它在 60%以上，那么它是一个积极的评论。否则就是否定的。这是一个您可以试验和修改的任意阈值。下面是一些查看和解释推理结果的帮助器代码:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="no np l"/></div></figure><ul class=""><li id="9763" class="lr ls it kw b kx ky la lb ld lt lh lu ll lv lp nq lx ly lz bi translated">第 1-3 行创建了一个包含原始文本和预测情感的数据框架。</li><li id="59e2" class="lr ls it kw b kx ma la mb ld mc lh md ll me lp nq lx ly lz bi translated">第 5 行根据阈值将数字情感值转换为“正”或“负”</li><li id="3ed0" class="lr ls it kw b kx ma la mb ld mc lh md ll me lp nq lx ly lz bi translated">第 7 行打印出我们的结果:</li></ul><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nr"><img src="../Images/2438cd9ff544686242b140ee64e900f1.png" data-original-src="https://miro.medium.com/v2/resize:fit:798/format:webp/1*A8I4IoGPr1b-D_FYwGekOA.png"/></div></figure><p id="c8ad" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">在本文中，我们采用电影评论的原始文本，并对其进行预处理，以输入到 Tensorflow 2.0 神经网络模型中。然后，我们将数据输入到一个模型中，并取得了一些不错的结果(大约 87%的准确率)。一些增强功能可能会改善这种情况:</p><ol class=""><li id="7956" class="lr ls it kw b kx ky la lb ld lt lh lu ll lv lp lw lx ly lz bi translated">在构建我们的模型之前过滤掉停用词。停用词是正常英语所必需的词，但对确定文章的意思没有任何价值。一些例子包括:" the "，" of "，" a "，…这将有助于我们的模型只关注有意义的单词。</li><li id="c5c4" class="lr ls it kw b kx ma la mb ld mc lh md ll me lp lw lx ly lz bi translated">对模型的细微调整。Tensorflow 2.0 使向我们的神经网络添加新层变得极其简单。我们可能希望在我们的 GlobalAveragePooling1D 层和最终的密集层之间添加一些密集层和/或下降层。</li><li id="0f8c" class="lr ls it kw b kx ma la mb ld mc lh md ll me lp lw lx ly lz bi translated">对模型的重大调整。这是一个非常简单的模型，还有更复杂的模型，比如 RNN 的、LSTM 的和 CNN 的。也有全新的方法，如 BERT。</li></ol><p id="b323" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">需要注意的最重要的一点是，无论您选择什么方法，您仍然必须遵循这里介绍的步骤来为神经网络处理您的数据。</p><p id="7113" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">我已经在<a class="ae lq" href="https://colab.research.google.com/drive/1OeJQyZV9hW2bs6I7wyFCR1wftLB15JTF" rel="noopener ugc nofollow" target="_blank"> Google Colab </a>上分享了这个模型。我期待在下面的评论区听到你的反馈。</p></div></div>    
</body>
</html>