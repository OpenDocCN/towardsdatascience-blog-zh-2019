<html>
<head>
<title>Machine Learning Project 17 — Compare Classification Algorithms</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">机器学习项目 17 —比较分类算法</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/machine-learning-project-17-compare-classification-algorithms-87cb50e1cb60?source=collection_archive---------13-----------------------#2019-09-17">https://towardsdatascience.com/machine-learning-project-17-compare-classification-algorithms-87cb50e1cb60?source=collection_archive---------13-----------------------#2019-09-17</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><p id="d0db" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">在过去的 7 个项目中，我们使用不同的分类算法实现了同一个项目，即“<a class="ae ko" href="https://medium.com/@omairaasim/machine-learning-project-10-predict-which-customers-bought-an-iphone-ea7b153db676" rel="noopener">逻辑回归</a>”、“<a class="ae ko" href="https://medium.com/@omairaasim/machine-learning-project-11-whose-my-neighbor-k-nearest-neighbor-3e9184ce5f89" rel="noopener"> KNN </a>”、“<a class="ae ko" href="https://medium.com/@omairaasim/machine-learning-project-12-using-support-vector-classification-8f940c25101a" rel="noopener"> SVM </a>”、“<a class="ae ko" href="https://medium.com/@omairaasim/machine-learning-project-13-using-kernel-support-vector-machine-9ca23bf39ac0" rel="noopener">核 SVM </a>”、“<a class="ae ko" href="https://medium.com/@omairaasim/machine-learning-project-14-naive-bayes-classifier-step-by-step-a1f4a5e5f834" rel="noopener">朴素贝叶斯</a>”、“<a class="ae ko" href="https://medium.com/@omairaasim/machine-learning-project-15-decision-tree-classifier-step-by-step-aaaae0c2a111" rel="noopener">决策树</a>、<a class="ae ko" href="https://medium.com/@omairaasim/machine-learning-project-16-random-forest-classifier-414bb558d2c2" rel="noopener">随机森林</a>。</p><p id="53b7" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">我为每种算法分别写一篇文章的原因是为了理解每种算法背后的直觉。</p><p id="bb15" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu"># 100 daysofml code # 100 projects inml</strong></p><p id="b8ec" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">在真实的场景中，当我们遇到一个问题时，我们无法预测哪种算法会表现得最好。显然从问题中，我们可以判断出是需要应用回归还是分类算法。但是很难事先知道应用哪种回归或分类算法。只有通过反复试验和检查性能指标，我们才能缩小范围并选择某些算法。</p><p id="3b67" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">今天，我将向您展示如何比较不同的分类算法，并挑选出最佳的算法。而不是用一个算法实现整个项目，然后发现性能不好，我们会先检查一堆算法的性能，然后再决定用哪一个来实现项目。</p><p id="ddc3" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">让我们开始吧。</p></div><div class="ab cl kp kq hx kr" role="separator"><span class="ks bw bk kt ku kv"/><span class="ks bw bk kt ku kv"/><span class="ks bw bk kt ku"/></div><div class="im in io ip iq"><h1 id="c21b" class="kw kx it bd ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt bi translated">项目目标</h1><p id="28a5" class="pw-post-body-paragraph jq jr it js b jt lu jv jw jx lv jz ka kb lw kd ke kf lx kh ki kj ly kl km kn im bi translated">我们将使用在<a class="ae ko" href="https://medium.com/@omairaasim/machine-learning-project-10-predict-which-customers-bought-an-iphone-ea7b153db676" rel="noopener">项目 10 </a>中使用的相同数据集。我们的目标是评估几种分类算法，并根据准确性选择最佳算法。</p><p id="a8ce" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">示例行如下所示。完整的数据集可以在访问<a class="ae ko" href="https://github.com/omairaasim/machine_learning/tree/master/project_17_compare_classification_algorithms" rel="noopener ugc nofollow" target="_blank">。</a></p><figure class="lz ma mb mc gt md"><div class="bz fp l di"><div class="me mf l"/></div></figure></div><div class="ab cl kp kq hx kr" role="separator"><span class="ks bw bk kt ku kv"/><span class="ks bw bk kt ku kv"/><span class="ks bw bk kt ku"/></div><div class="im in io ip iq"><h1 id="8b38" class="kw kx it bd ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt bi translated">步骤 1:加载数据集</h1><p id="24cc" class="pw-post-body-paragraph jq jr it js b jt lu jv jw jx lv jz ka kb lw kd ke kf lx kh ki kj ly kl km kn im bi translated">我们将自变量“性别”、“工资”和“年龄”赋给 x。因变量“购买的 iphone”捕捉用户是否购买了该手机。我们会把这个赋值给 y。</p><figure class="lz ma mb mc gt md"><div class="bz fp l di"><div class="me mf l"/></div></figure></div><div class="ab cl kp kq hx kr" role="separator"><span class="ks bw bk kt ku kv"/><span class="ks bw bk kt ku kv"/><span class="ks bw bk kt ku"/></div><div class="im in io ip iq"><h1 id="994d" class="kw kx it bd ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt bi translated">步骤 2:将性别转换为数字</h1><p id="6fc1" class="pw-post-body-paragraph jq jr it js b jt lu jv jw jx lv jz ka kb lw kd ke kf lx kh ki kj ly kl km kn im bi translated">我们有一个必须转换成数字的分类变量“性别”。我们将使用 LabelEncoder 类将性别转换为数字。</p><figure class="lz ma mb mc gt md"><div class="bz fp l di"><div class="me mf l"/></div></figure></div><div class="ab cl kp kq hx kr" role="separator"><span class="ks bw bk kt ku kv"/><span class="ks bw bk kt ku kv"/><span class="ks bw bk kt ku"/></div><div class="im in io ip iq"><h1 id="d78d" class="kw kx it bd ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt bi translated">步骤 3:特征缩放</h1><p id="465c" class="pw-post-body-paragraph jq jr it js b jt lu jv jw jx lv jz ka kb lw kd ke kf lx kh ki kj ly kl km kn im bi translated">除了决策树和随机森林分类器，其他分类器要求我们对数据进行缩放。所以让我们现在就开始吧。</p><figure class="lz ma mb mc gt md"><div class="bz fp l di"><div class="me mf l"/></div></figure></div><div class="ab cl kp kq hx kr" role="separator"><span class="ks bw bk kt ku kv"/><span class="ks bw bk kt ku kv"/><span class="ks bw bk kt ku"/></div><div class="im in io ip iq"><h1 id="8d52" class="kw kx it bd ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt bi translated">步骤 4:比较分类算法</h1><p id="d2f9" class="pw-post-body-paragraph jq jr it js b jt lu jv jw jx lv jz ka kb lw kd ke kf lx kh ki kj ly kl km kn im bi translated">这是所有有趣的事情发生的地方:)</p><p id="2e51" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">我将比较 6 种分类算法——我在以前的项目中介绍过的算法。也可以随意添加和测试其他内容。</p><ul class=""><li id="b350" class="mg mh it js b jt ju jx jy kb mi kf mj kj mk kn ml mm mn mo bi translated">逻辑回归</li><li id="5bd3" class="mg mh it js b jt mp jx mq kb mr kf ms kj mt kn ml mm mn mo bi translated">KNN</li><li id="c45b" class="mg mh it js b jt mp jx mq kb mr kf ms kj mt kn ml mm mn mo bi translated">内核 SVM</li><li id="c0be" class="mg mh it js b jt mp jx mq kb mr kf ms kj mt kn ml mm mn mo bi translated">朴素贝叶斯</li><li id="a44c" class="mg mh it js b jt mp jx mq kb mr kf ms kj mt kn ml mm mn mo bi translated">决策图表</li><li id="28d7" class="mg mh it js b jt mp jx mq kb mr kf ms kj mt kn ml mm mn mo bi translated">随机森林</li></ul><p id="1c38" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">我们将使用 10 倍交叉验证来评估每个算法，我们将找到平均精度和标准偏差精度。</p><p id="42d6" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">首先，我们将创建一个列表，并添加我们想要评估的不同分类器的对象。然后，我们遍历列表，使用 cross_val_score 方法来获得准确性。</p><figure class="lz ma mb mc gt md"><div class="bz fp l di"><div class="me mf l"/></div></figure><pre class="lz ma mb mc gt mu mv mw mx aw my bi"><span id="b751" class="mz kx it mv b gy na nb l nc nd">Here is the output:</span><span id="84ea" class="mz kx it mv b gy ne nb l nc nd">Logistic Regression: Mean Accuracy = 82.75% — SD Accuracy = 11.37%<br/>K Nearest Neighbor: Mean Accuracy = 90.50% — SD Accuracy = 7.73%<br/>Kernel SVM: Mean Accuracy = 90.75% — SD Accuracy = 9.15%<br/>Naive Bayes: Mean Accuracy = 85.25% — SD Accuracy = 10.34%<br/>Decision Tree: Mean Accuracy = 84.50% — SD Accuracy = 8.50%<br/>Random Forest: Mean Accuracy = 88.75% — SD Accuracy = 8.46%</span></pre></div><div class="ab cl kp kq hx kr" role="separator"><span class="ks bw bk kt ku kv"/><span class="ks bw bk kt ku kv"/><span class="ks bw bk kt ku"/></div><div class="im in io ip iq"><h1 id="e44b" class="kw kx it bd ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt bi translated">结论</h1><p id="6c62" class="pw-post-body-paragraph jq jr it js b jt lu jv jw jx lv jz ka kb lw kd ke kf lx kh ki kj ly kl km kn im bi translated">从结果中，我们可以看到，对于这个特定的数据集，<strong class="js iu"> KNN </strong>和<strong class="js iu">内核 SVM </strong>表现得比其他人更好。所以我们可以把这两个人列入这个项目的候选名单。这与我们分别实现这些算法得出的结论完全相同。</p><p id="7c13" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">希望你玩得开心。你可以在这里找到《T4》的全部源代码。</p></div></div>    
</body>
</html>