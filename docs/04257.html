<html>
<head>
<title>Robot following a walkway using image segmentation</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">基于图像分割的机器人行走路径</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/robot-following-a-walkway-using-image-segmentation-272bebd93a83?source=collection_archive---------34-----------------------#2019-07-02">https://towardsdatascience.com/robot-following-a-walkway-using-image-segmentation-272bebd93a83?source=collection_archive---------34-----------------------#2019-07-02</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><p id="8e71" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">在我之前的故事中，我正在教一只<a class="ae ko" href="https://medium.com/@const.toporov/raspberry-pi-photo-tank-robot-cf5ca7288adf" rel="noopener">覆盆子驱动的机器人坦克</a>自己在人行道上导航。瓶颈是道路识别——我通过 OpenCV 使用了一种简单的颜色过滤方法，结果并不可靠。</p><p id="d65c" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">一般来说，这是一个图像分割的任务。有一篇<a class="ae ko" rel="noopener" target="_blank" href="/image-segmentation-using-pythons-scikit-image-module-533a61ecc980">的好文章</a>描述了最流行的方法。它们很简单，通常不会在现实生活的照片上产生完美的效果。和我基于颜色的实现一样。</p><p id="d8b7" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">为了寻找改进的方法，我决定使用语义分割。神经网络只是在最近才被用于这项任务，但已经展示了令人印象深刻的结果。来自 PyImageSearch 的这篇<a class="ae ko" href="https://www.pyimagesearch.com/2018/09/03/semantic-segmentation-with-opencv-and-deep-learning/" rel="noopener ugc nofollow" target="_blank">很棒的文章给了我灵感，并将我从理论推向了实践。本文介绍了用 E-net 神经网络进行图像分割。</a></p><p id="8c00" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">原来，E 网是比较年轻，不知名的网络。它是基于更著名的 U-net 架构的成功而开发的。</p><h1 id="af7c" class="kp kq it bd kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm bi translated">优信网</h1><p id="56dd" class="pw-post-body-paragraph jq jr it js b jt ln jv jw jx lo jz ka kb lp kd ke kf lq kh ki kj lr kl km kn im bi translated"><a class="ae ko" href="https://en.wikipedia.org/wiki/U-Net" rel="noopener ugc nofollow" target="_blank"> U-net </a>是第一个也是最著名的用于语义分割的神经网络。最初它是为德国的医疗需要而开发的。原始文档在<a class="ae ko" href="https://arxiv.org/abs/1505.04597" rel="noopener ugc nofollow" target="_blank">这里</a>可用。</p><p id="8c72" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">人们很快发现这种方法可以用于比 x 光阅读更广泛的用途。有一些关于如何训练和使用 U-net 在城市图像上进行道路分割的文章:</p><ul class=""><li id="1d88" class="ls lt it js b jt ju jx jy kb lu kf lv kj lw kn lx ly lz ma bi translated"><a class="ae ko" rel="noopener" target="_blank" href="/fastai-image-segmentation-eacad8543f6f">一个</a></li><li id="8dcd" class="ls lt it js b jt mb jx mc kb md kf me kj mf kn lx ly lz ma bi translated"><a class="ae ko" href="https://github.com/aschneuw/road-segmentation-unet" rel="noopener ugc nofollow" target="_blank">两个</a></li><li id="fbfb" class="ls lt it js b jt mb jx mc kb md kf me kj mf kn lx ly lz ma bi translated"><a class="ae ko" rel="noopener" target="_blank" href="/training-road-scene-segmentation-on-cityscapes-with-supervisely-tensorflow-and-unet-1232314781a8">三个</a></li></ul><p id="84b8" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">有很多有趣的和新的信息，但我正在寻找一个现成的网络来使用我的坦克了。不幸的是，搜索没有很快产生结果。</p><p id="5836" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">所以转回到 E-net。</p><h1 id="dca7" class="kp kq it bd kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm bi translated">电子网络</h1><p id="d48c" class="pw-post-body-paragraph jq jr it js b jt ln jv jw jx lo jz ka kb lp kd ke kf lq kh ki kj lr kl km kn im bi translated">E-net 是基于 U-net 产生的想法。根据<a class="ae ko" href="https://arxiv.org/abs/1606.02147" rel="noopener ugc nofollow" target="_blank">来源</a>，它最初是为城市图像分割而设计的。一些开放数据集用于在道路场景上进行训练:</p><p id="2d7b" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><a class="ae ko" href="http://mi.eng.cam.ac.uk/research/projects/VideoRec/CamVid/" rel="noopener ugc nofollow" target="_blank">剑桥街道数据集又名 CamVid </a></p><p id="4aee" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><a class="ae ko" href="https://www.cityscapes-dataset.com/" rel="noopener ugc nofollow" target="_blank">德国和瑞士街道数据集又名城市景观</a></p><p id="ba18" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">有一篇关于 E-net 的介绍性文章。</p><p id="98d1" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">如果有人想深入了解，这里有一份关于如何训练和使用 E-net 网络的详细文件。我认为这是一个强制性的步骤——根据自己的需要和要求定制网络。</p><p id="7879" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">但是我太兴奋了，不能马上得到结果，决定使用上面提到的来自<a class="ae ko" href="https://www.pyimagesearch.com/2018/09/03/semantic-segmentation-with-opencv-and-deep-learning/" rel="noopener ugc nofollow" target="_blank"> PyImageSearch </a>的现成网络。</p><h1 id="1208" class="kp kq it bd kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm bi translated">运行电子网络</h1><p id="4d36" class="pw-post-body-paragraph jq jr it js b jt ln jv jw jx lo jz ka kb lp kd ke kf lq kh ki kj lr kl km kn im bi translated">到目前为止，我的目标是只识别人行道，而不是网络训练检测的 20 类物体。为此，我用颜色编辑了文件，忽略了除道路以外的所有类。</p><p id="9b91" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">然后从文件系统中读取模型:</p><pre class="mg mh mi mj gt mk ml mm mn aw mo bi"><span id="484f" class="mp kq it ml b gy mq mr l ms mt">def load_segment_model():<br/>    try:<br/>        classes = None<br/>        with open(PiConf.SEGMENT_CLASSES) as f:<br/>            classes = f.read().strip().split("\n")<br/>        colors = None<br/>        with open(PiConf.SEGMENT_COLORS) as f:<br/>            colors= f.read().strip().split("\n")<br/>        colors = [np.array(c.split(",")).astype("int") for c in colors]<br/>        colors = np.array(colors, dtype="uint8")<br/>        print("[INFO] loading model...")<br/>        net = cv2.dnn.readNet(PiConf.SEGMENT_MODEL)<br/>        return net, classes, colors<br/>    except Exception as e:<br/>        logging.exception("Cannot load segment model")<br/>    return None, None, None</span></pre><p id="ff89" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">进行细分:</p><pre class="mg mh mi mj gt mk ml mm mn aw mo bi"><span id="6ef1" class="mp kq it ml b gy mq mr l ms mt">def segment_image(image_path, seg_net, seg_classes, seg_colors):</span><span id="29c6" class="mp kq it ml b gy mu mr l ms mt">    image0 = cv2.imread(image_path)<br/>    image = cv2.resize(image0, (1024, 512), interpolation=cv2.INTER_NEAREST)<br/>    blob = cv2.dnn.blobFromImage(image, 1 / 255.0, (1024, 512), 0, swapRB=True, crop=False)</span><span id="0ac8" class="mp kq it ml b gy mu mr l ms mt">    seg_net.setInput(blob)<br/>    start = time.time()<br/>    output = seg_net.forward()<br/>    end = time.time()</span><span id="0a67" class="mp kq it ml b gy mu mr l ms mt">    print("[INFO] inference took {:.4f} seconds".format(end - start))</span><span id="4804" class="mp kq it ml b gy mu mr l ms mt">    (numClasses, height, width) = output.shape[1:4]</span><span id="a095" class="mp kq it ml b gy mu mr l ms mt">    classMap = np.argmax(output[0], axis=0)</span><span id="f344" class="mp kq it ml b gy mu mr l ms mt">    mask = seg_colors[classMap]</span><span id="0e02" class="mp kq it ml b gy mu mr l ms mt">    mask = cv2.resize(mask, (image0.shape[1], image0.shape[0]), interpolation=cv2.INTER_NEAREST)<br/>    classMap = cv2.resize(classMap, (image0.shape[1], image0.shape[0]), interpolation=cv2.INTER_NEAREST)</span><span id="5105" class="mp kq it ml b gy mu mr l ms mt">    gmask = cv2.cvtColor(mask, cv2.COLOR_BGR2GRAY)<br/>    gmask = cv2.resize(gmask, (128, 64), interpolation=cv2.INTER_NEAREST)<br/>    gmask = gmask[0:64,32:96]</span><span id="8685" class="mp kq it ml b gy mu mr l ms mt">    output = ((0.6 * image0) + (0.4 * mask)).astype("uint8")       <br/>    return output, gmask</span></pre><p id="6434" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">第一个问题出现在代码中，它是输入图像的尺寸。该网络在相当大的 1024x512 图像上进行训练。为了节省处理资源，我的树莓相机设置为 320x240。</p><h1 id="c199" class="kp kq it bd kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm bi translated">分段测试</h1><p id="2cb9" class="pw-post-body-paragraph jq jr it js b jt ln jv jw jx lo jz ka kb lp kd ke kf lq kh ki kj lr kl km kn im bi translated">代码移植后，是时候处理坦克已经在人行道上拍摄的照片了。</p><h2 id="f904" class="mp kq it bd kr mv mw dn kv mx my dp kz kb mz na ld kf nb nc lh kj nd ne ll nf bi translated">首次测试</h2><figure class="mg mh mi mj gt nh gh gi paragraph-image"><div role="button" tabindex="0" class="ni nj di nk bf nl"><div class="gh gi ng"><img src="../Images/000bc84f0b250f29bb9b899983856fd3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*Alks9IIGOPZXy_pR.jpeg"/></div></div></figure><p id="a4a5" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">只能认出走道的左边部分。</p><p id="971b" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">缩小图片并将其中心切割为 64x64(此遮罩由<a class="ae ko" href="https://github.com/tprlab/pitanq-selfwalk/" rel="noopener ugc nofollow" target="_blank">另一个神经网络</a>决定方向)。</p><figure class="mg mh mi mj gt nh gh gi paragraph-image"><div class="gh gi no"><img src="../Images/cd92ead3d6f8c16f22a9df4de9d9afe0.png" data-original-src="https://miro.medium.com/v2/resize:fit:128/format:webp/0*quWs9kGZzUm0M3k5.jpeg"/></div></figure><p id="9461" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">方向网络(它是一个 3 级分类器)命令向左行驶。不是最好的决定，但可以忍受。</p><h2 id="8c3e" class="mp kq it bd kr mv mw dn kv mx my dp kz kb mz na ld kf nb nc lh kj nd ne ll nf bi translated">第二次测试</h2><figure class="mg mh mi mj gt nh gh gi paragraph-image"><div role="button" tabindex="0" class="ni nj di nk bf nl"><div class="gh gi ng"><img src="../Images/ce7427d649652813ad0241654b7d15df.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*tjnw4UKnZovyHnUj.jpeg"/></div></div></figure><p id="f942" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">类似的情况，右下角又不识别了。大概是湿漉漉的表面把网络搞糊涂了。但是道路的最大部分被正确识别。面具看起来很一致:</p><figure class="mg mh mi mj gt nh gh gi paragraph-image"><div class="gh gi no"><img src="../Images/455d2e032479a8da9023a0372bc46809.png" data-original-src="https://miro.medium.com/v2/resize:fit:128/format:webp/0*lsykvZmRvKJbLhuZ.jpeg"/></div></figure><p id="de01" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">而方向网决定往前走。</p><h2 id="8b23" class="mp kq it bd kr mv mw dn kv mx my dp kz kb mz na ld kf nb nc lh kj nd ne ll nf bi translated">第三次测试</h2><figure class="mg mh mi mj gt nh gh gi paragraph-image"><div role="button" tabindex="0" class="ni nj di nk bf nl"><div class="gh gi ng"><img src="../Images/14eda35aadc8d2fadc7696d14a1bde70.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*L7ZRtpj2qImptFK0.jpeg"/></div></div></figure><p id="fd76" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">这是一个失败的状态——机器人位于人行道中间，需要向右走。</p><p id="640e" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">这条路几乎完全被认出来了。</p><figure class="mg mh mi mj gt nh gh gi paragraph-image"><div class="gh gi no"><img src="../Images/086d9b4a45e732b22aa54b6b1a41e063.png" data-original-src="https://miro.medium.com/v2/resize:fit:128/format:webp/0*cauOS0kKjPd7XEgi.jpeg"/></div></figure><p id="4e80" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">方向分类器命令向右。就是这样。</p><p id="ba11" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">因此，道路识别的结果要比旧实现中简单的颜色过滤好得多。让我们在真正的坦克上运行它。</p><h1 id="6a23" class="kp kq it bd kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm bi translated">在覆盆子馅饼上奔跑</h1><p id="31f7" class="pw-post-body-paragraph jq jr it js b jt ln jv jw jx lo jz ka kb lp kd ke kf lq kh ki kj lr kl km kn im bi translated">不幸的是，注意到的输入图像大小立刻引起了问题。覆盆子太慢了，无法处理这么大的图像。一次分割大约需要 6 秒钟，这对于实时车辆来说是不可接受的。神经网络工作得很好，但当它工作时，坦克偏离了道路。</p><p id="bd71" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">所以唯一的解决方案是用更小的图片来训练我自己的电子网络。</p><p id="eeea" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">此外，使用外部电源进行分割也可能是一个好主意，例如英特尔神经计算机棒或类似产品。</p><p id="c5c9" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">最后一幅图表明，即使是道路决策也是有效的，因为它们做得太晚了。</p><figure class="mg mh mi mj gt nh gh gi paragraph-image"><div role="button" tabindex="0" class="ni nj di nk bf nl"><div class="gh gi ng"><img src="../Images/a3537ca7c296611355d10779334a2dc2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*2pwdG35fYtRoS5c9.png"/></div></div></figure><h1 id="1be5" class="kp kq it bd kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm bi translated">链接</h1><ul class=""><li id="f31e" class="ls lt it js b jt ln jx lo kb np kf nq kj nr kn lx ly lz ma bi translated"><a class="ae ko" rel="noopener" target="_blank" href="/robot-following-a-walkway-with-opencv-and-tensorflow-a631eb72cb8c">之前尝试在人行道上驾驶——基于颜色的分割</a></li><li id="4578" class="ls lt it js b jt mb jx mc kb md kf me kj mf kn lx ly lz ma bi translated"><a class="ae ko" href="https://github.com/tprlab/pitanq/tree/segmentation" rel="noopener ugc nofollow" target="_blank">git hub 上带有 E-net 分段的坦克固件</a></li><li id="f62a" class="ls lt it js b jt mb jx mc kb md kf me kj mf kn lx ly lz ma bi translated"><a class="ae ko" href="https://www.pyimagesearch.com/2018/09/03/semantic-segmentation-with-opencv-and-deep-learning/" rel="noopener ugc nofollow" target="_blank"> PyImageSearch 促使我迈出这一步的文章</a></li><li id="4b90" class="ls lt it js b jt mb jx mc kb md kf me kj mf kn lx ly lz ma bi translated"><a class="ae ko" href="https://github.com/TimoSaemann/ENet/tree/master/Tutorial" rel="noopener ugc nofollow" target="_blank">如何训练自己的 E-net 实现指南</a></li><li id="d683" class="ls lt it js b jt mb jx mc kb md kf me kj mf kn lx ly lz ma bi translated"><a class="ae ko" href="http://pitanq.com" rel="noopener ugc nofollow" target="_blank">您可以获取更多信息并购买坦克自制套件的坦克基地</a></li></ul></div></div>    
</body>
</html>