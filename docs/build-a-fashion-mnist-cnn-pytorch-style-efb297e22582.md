# è®©æˆ‘ä»¬å»ºç«‹ä¸€ä¸ªæ—¶å°š-MNIST æœ‰çº¿ç”µè§†æ–°é—»ç½‘ï¼ŒPyTorch é£æ ¼

> åŸæ–‡ï¼š<https://towardsdatascience.com/build-a-fashion-mnist-cnn-pytorch-style-efb297e22582?source=collection_archive---------2----------------------->

## å¦‚ä½•ä½¿ç”¨ Google Colab å’Œ TensorBoard ä»å¤´å¼€å§‹æ„å»º PyTorch ML é¡¹ç›®çš„é€è¡ŒæŒ‡å—

![](img/f2ea5451cfa450d03fee3c36ffde0d5e.png)

å½“è°ˆåˆ°æŠ€æœ¯ä¸­çš„æ¡†æ¶æ—¶ï¼Œä¸€ä»¶æœ‰è¶£çš„äº‹æƒ…æ˜¯ï¼Œä»ä¸€å¼€å§‹ï¼Œä¼¼ä¹æ€»æ˜¯æœ‰å„ç§å„æ ·çš„é€‰æ‹©ã€‚ä½†éšç€æ—¶é—´çš„æ¨ç§»ï¼Œç«äº‰å°†æ¼”å˜ä¸ºåªå‰©ä¸‹ä¸¤ä¸ªå¼ºæœ‰åŠ›çš„ç«äº‰è€…ã€‚å…¸å‹çš„ä¾‹å­æœ‰â€œPC vs Macâ€ã€â€œiOS vs Androidâ€ã€â€œReact.js vs Vue.jsâ€ç­‰ã€‚è€Œç°åœ¨ï¼Œæˆ‘ä»¬åœ¨æœºå™¨å­¦ä¹ æ–¹é¢æœ‰äº†â€˜py torch vs tensor flowâ€™ã€‚

ç”±è°·æ­Œæ”¯æŒçš„ [TensorFlow](https://github.com/tensorflow/tensorflow) æ— ç–‘æ˜¯è¿™æ–¹é¢çš„é¢†è·‘è€…ã€‚å®ƒäº 2015 å¹´ä½œä¸ºå¼€æºæœºå™¨å­¦ä¹ æ¡†æ¶å‘å¸ƒï¼Œè¿…é€Ÿè·å¾—äº†å¤§é‡å…³æ³¨å’Œæ¥å—ï¼Œç‰¹åˆ«æ˜¯åœ¨ç”Ÿäº§å‡†å¤‡å’Œéƒ¨ç½²éå¸¸å…³é”®çš„è¡Œä¸šã€‚ [PyTorch](https://github.com/pytorch/pytorch) ç”±è„¸ä¹¦åœ¨ 2017 å¹´æ¨å‡ºï¼Œä½†ç”±äºå…¶åŠ¨æ€è®¡ç®—å›¾å’Œ'[python å¼](https://legacy.python.org/dev/peps/pep-0020/)'é£æ ¼ï¼Œå¾ˆå¿«è·å¾—äº†ä»ä¸šè€…å’Œç ”ç©¶äººå‘˜çš„å–œçˆ±ã€‚

![](img/8f467add53fb4ec27a654b070f6d119b.png)

Image from [The Gradient](https://thegradient.pub/state-of-ml-frameworks-2019-pytorch-dominates-research-tensorflow-dominates-industry/)

[The Gradient](https://thegradient.pub/state-of-ml-frameworks-2019-pytorch-dominates-research-tensorflow-dominates-industry/) æœ€è¿‘çš„ç ”ç©¶è¡¨æ˜ï¼ŒPyTorch åœ¨ç ”ç©¶äººå‘˜ä¸­è¡¨ç°å‡ºè‰²ï¼ŒTensorFlow åœ¨ä¸šç•Œå æ®ä¸»å¯¼åœ°ä½:

> 2019 å¹´ï¼ŒML æ¡†æ¶çš„æˆ˜äº‰è¿˜æœ‰ä¸¤ä¸ªä¸»è¦ç«äº‰è€…:PyTorch å’Œ TensorFlowã€‚æˆ‘çš„åˆ†æè¡¨æ˜ï¼Œç ”ç©¶äººå‘˜æ­£åœ¨æ”¾å¼ƒ TensorFlowï¼Œæˆç¾¤ç»“é˜Ÿåœ°æ¶Œå‘ PyTorchã€‚ä¸æ­¤åŒæ—¶ï¼Œåœ¨è¡Œä¸šä¸­ï¼ŒTensorflow æ˜¯ç›®å‰çš„é¦–é€‰å¹³å°ï¼Œä½†è¿™ç§æƒ…å†µå¯èƒ½ä¸ä¼šæŒç»­å¤ªä¹…ã€‚â€” [å¡åº¦](https://thegradient.pub/state-of-ml-frameworks-2019-pytorch-dominates-research-tensorflow-dominates-industry/)

æœ€è¿‘å‘å¸ƒçš„ PyTorch 1.3 å¼•å…¥äº† PyTorch Mobileã€quantization å’Œå…¶ä»–å¥½ä¸œè¥¿ï¼Œå®ƒä»¬éƒ½æœç€ç¼©å°å·®è·çš„æ­£ç¡®æ–¹å‘å‰è¿›ã€‚å¦‚æœä½ å¯¹ç¥ç»ç½‘ç»œåŸºç¡€æœ‰ç‚¹ç†Ÿæ‚‰ï¼Œä½†æƒ³å°è¯• PyTorch ä½œä¸ºä¸€ç§ä¸åŒçš„é£æ ¼ï¼Œé‚£ä¹ˆè¯·ç»§ç»­é˜…è¯»ã€‚æˆ‘å°†å°è¯•è§£é‡Šå¦‚ä½•ä½¿ç”¨ PyTorch ä¸ºæ—¶å°š-MNIST æ•°æ®é›†ä»å¤´æ„å»ºä¸€ä¸ªå·ç§¯ç¥ç»ç½‘ç»œåˆ†ç±»å™¨ã€‚å¦‚æœä½ æ²¡æœ‰å¼ºå¤§çš„æœ¬åœ°ç¯å¢ƒï¼Œè¿™é‡Œçš„ä»£ç å¯ä»¥åœ¨ Google Colab å’Œ Tensor Board ä¸Šä½¿ç”¨ã€‚äº‹ä¸å®œè¿Ÿï¼Œæˆ‘ä»¬å¼€å§‹å§ã€‚æ‚¨å¯ä»¥åœ¨ä¸‹é¢æ‰¾åˆ° Google Colab ç¬”è®°æœ¬å’Œ GitHub é“¾æ¥:

[ğŸ“™**è°·æ­Œ Colab ç¬”è®°æœ¬**](https://colab.research.google.com/drive/1YWzAjpAnLI23irBQtLvDTYT1A94uCloM)

ğŸ‘½ [**GitHub**](https://github.com/wayofnumbers/SideProjects/blob/master/PyTorch_Tutorial_Basic_v1.ipynb)

# å¯¼å…¥

é¦–å…ˆï¼Œè®©æˆ‘ä»¬å¯¼å…¥å¿…è¦çš„æ¨¡å—ã€‚

```
# import standard PyTorch modules
import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
from torch.utils.tensorboard import SummaryWriter # TensorBoard support

# import torchvision module to handle image manipulation
import torchvision
import torchvision.transforms as transforms

# calculate train time, writing train data to files etc.
import time
import pandas as pd
import json
from IPython.display import clear_output

torch.set_printoptions(linewidth=120)
torch.set_grad_enabled(True)     # On by default, leave it here for clarity
```

PyTorch æ¨¡å—éå¸¸ç®€å•ã€‚

## ç«ç‚¬

`torch`æ˜¯ä¸»æ¨¡å—ï¼ŒåŒ…å«äº†**å¼ é‡**è®¡ç®—æ‰€éœ€çš„æ‰€æœ‰ä¸œè¥¿ã€‚æ‚¨å¯ä»¥å•ç‹¬ä½¿ç”¨å¼ é‡è®¡ç®—æ¥æ„å»ºä¸€ä¸ªå…¨åŠŸèƒ½çš„ç¥ç»ç½‘ç»œï¼Œä½†è¿™ä¸æ˜¯æœ¬æ–‡è¦è®¨è®ºçš„å†…å®¹ã€‚æˆ‘ä»¬å°†åˆ©ç”¨æ›´å¼ºå¤§ã€æ›´æ–¹ä¾¿çš„`torch.nn`ã€`torch.optim`å’Œ`torchvision`ç±»æ¥å¿«é€Ÿæ„å»ºæˆ‘ä»¬çš„ CNNã€‚å¯¹äºé‚£äº›æœ‰å…´è¶£çŸ¥é“å¦‚ä½•ä»â€œä»*æŠ“åˆ°*å¼€å§‹åšè¿™ä»¶äº‹çš„äººï¼Œè¯·è®¿é—®è¿™ä¸ª[å¥‡å¦™çš„ PyTorch å®˜æ–¹ tutoria](https://pytorch.org/tutorials/beginner/nn_tutorial.html) l ä½œè€…[æ°ç‘ç±³Â·éœåå¾·](https://medium.com/u/34ab754f8c5e?source=post_page-----efb297e22582--------------------------------)ã€‚

## torch.nn å’Œ torch.nn åŠŸèƒ½

![](img/af347b724f99ed5f02a39918018680be.png)

Photo by [Alphacolor](https://unsplash.com/@duck58cth?utm_source=medium&utm_medium=referral) on [Unsplash](https://unsplash.com?utm_source=medium&utm_medium=referral)

`torch.nn`æ¨¡å—æä¾›äº†è®¸å¤šæ„å»ºç¥ç»ç½‘ç»œçš„ç±»å’Œå‡½æ•°ã€‚ä½ å¯ä»¥æŠŠå®ƒæƒ³è±¡æˆç¥ç»ç½‘ç»œçš„åŸºæœ¬æ„ä»¶:æ¨¡å‹ã€å„ç§å±‚ã€æ¿€æ´»å‡½æ•°ã€å‚æ•°ç±»ç­‰ç­‰ã€‚å®ƒå…è®¸æˆ‘ä»¬åƒç»„è£…ä¹é«˜ç©å…·ä¸€æ ·æ¥å»ºé€ æ¨¡å‹ã€‚

## ç«ç‚¬. optim

`torch.optim`æä¾›æ‰€æœ‰ä¼˜åŒ–å™¨ï¼Œå¦‚ SGDã€ADAM ç­‰ã€‚ï¼Œè¿™æ ·å°±ä¸ç”¨ä»å¤´å¼€å§‹å†™äº†ã€‚

## ç«ç‚¬è§†è§‰

`torchvision`åŒ…å«å¤§é‡æµè¡Œçš„æ•°æ®é›†ã€æ¨¡å‹æ¶æ„å’Œè®¡ç®—æœºè§†è§‰çš„å¸¸è§å›¾åƒè½¬æ¢ã€‚æˆ‘ä»¬ä»ä¸­è·å–æ—¶å°š MNIST æ•°æ®é›†ï¼Œå¹¶ä½¿ç”¨å…¶å˜æ¢ã€‚

## æ‘˜è¦è®°å½•å™¨(å¼ é‡æ¿)

`SummaryWriter`ä½¿ PyTorch èƒ½å¤Ÿä¸ºå¼ é‡æ¿ç”ŸæˆæŠ¥å‘Šã€‚æˆ‘ä»¬å°†ä½¿ç”¨ Tensor Board æŸ¥çœ‹æˆ‘ä»¬çš„è®­ç»ƒæ•°æ®ï¼Œæ¯”è¾ƒç»“æœå¹¶è·å¾—ç›´è§‰ã€‚å¼ é‡æ¿æ›¾ç»æ˜¯ TensorFlow ç›¸å¯¹äº PyTorch çš„æœ€å¤§ä¼˜åŠ¿ï¼Œä½†æ˜¯ç°åœ¨ä» v1.2 å¼€å§‹ PyTorch æ­£å¼æ”¯æŒå¼ é‡æ¿ã€‚

æˆ‘ä»¬è¿˜å¼•å…¥äº†å…¶ä»–ä¸€äº›å®ç”¨æ¨¡å—ï¼Œå¦‚`time`ã€`json`ã€`pandas`ç­‰ã€‚

# èµ„æ–™ç»„

`torchvision`å·²ç»æœ‰äº†æ—¶å°š MNIST æ•°æ®é›†ã€‚å¦‚æœä½ ä¸ç†Ÿæ‚‰æ—¶å°š MNIST æ•°æ®é›†:

> `Fashion-MNIST`æ˜¯ä¸€ä¸ªç”± [Zalando](https://jobs.zalando.com/tech/) çš„æ–‡ç« å›¾åƒç»„æˆçš„æ•°æ®é›†ï¼Œç”± 60ï¼Œ000 ä¸ªç¤ºä¾‹çš„è®­ç»ƒé›†å’Œ 10ï¼Œ000 ä¸ªç¤ºä¾‹çš„æµ‹è¯•é›†ç»„æˆã€‚æ¯ä¸ªç¤ºä¾‹éƒ½æ˜¯ 28x28 ç°åº¦å›¾åƒï¼Œä¸ 10 ä¸ªç±»åˆ«çš„æ ‡ç­¾ç›¸å…³è”ã€‚æˆ‘ä»¬æ‰“ç®—å°†`Fashion-MNIST`ä½œä¸ºåŸå§‹ [MNIST æ•°æ®é›†](http://yann.lecun.com/exdb/mnist/)çš„ç›´æ¥æ›¿ä»£ï¼Œç”¨äºæœºå™¨å­¦ä¹ ç®—æ³•çš„åŸºå‡†æµ‹è¯•ã€‚å®ƒå…±äº«è®­ç»ƒå’Œæµ‹è¯•åˆ†å‰²çš„ç›¸åŒå›¾åƒå¤§å°å’Œç»“æ„ã€‚â€” [æ¥è‡ª Github](https://github.com/zalandoresearch/fashion-mnist)

![](img/5b2eb440c08f4773c113766533f98674.png)

Fashion MNIST Dataset â€” [From GitHub](https://github.com/zalandoresearch/fashion-mnist)

```
# Use standard FashionMNIST dataset
train_set = torchvision.datasets.FashionMNIST(
    root = './data/FashionMNIST',
    train = True,
    download = True,
    transform = transforms.Compose([
        transforms.ToTensor()                                 
    ])
)
```

è¿™ä¸ªä¸éœ€è¦è¿‡å¤šè§£é‡Šã€‚æˆ‘ä»¬æŒ‡å®šæ ¹ç›®å½•æ¥å­˜å‚¨æ•°æ®é›†ï¼ŒæŠ“å–è®­ç»ƒæ•°æ®ï¼Œå¦‚æœæœ¬åœ°æœºå™¨ä¸Šæ²¡æœ‰ï¼Œå…è®¸ä¸‹è½½å®ƒï¼Œç„¶ååº”ç”¨`transforms.ToTensor`å°†å›¾åƒè½¬æ¢æˆ**å¼ é‡**ï¼Œè¿™æ ·æˆ‘ä»¬å°±å¯ä»¥åœ¨æˆ‘ä»¬çš„ç½‘ç»œä¸­ç›´æ¥ä½¿ç”¨å®ƒã€‚æ•°æ®é›†å­˜å‚¨åœ¨åä¸º`train_set.`çš„`dataset`ç±»ä¸­

# ç½‘ç»œ

åœ¨ PyTorch ä¸­æ„å»ºå®é™…çš„ç¥ç»ç½‘ç»œæ—¢æœ‰è¶£åˆç®€å•ã€‚æˆ‘å‡è®¾ä½ å¯¹å·ç§¯ç¥ç»ç½‘ç»œçš„å·¥ä½œåŸç†æœ‰ä¸€äº›åŸºæœ¬çš„æ¦‚å¿µã€‚å¦‚æœæ²¡æœ‰ï¼Œå¯ä»¥å‚è€ƒ deeplizard çš„è¿™ä¸ªè§†é¢‘:

æ—¶å°š MNIST åªæœ‰ 28x28 px å¤§å°ï¼Œæ‰€ä»¥æˆ‘ä»¬å®é™…ä¸Šä¸éœ€è¦éå¸¸å¤æ‚çš„ç½‘ç»œã€‚æˆ‘ä»¬å¯ä»¥åƒè¿™æ ·å»ºç«‹ä¸€ä¸ªç®€å•çš„ CNN:

![](img/948c7a17db8d399075d43517bbeefcbc.png)

æˆ‘ä»¬æœ‰ä¸¤ä¸ªå·ç§¯å±‚ï¼Œæ¯ä¸ªå·ç§¯å±‚æœ‰ 5x5 ä¸ªå†…æ ¸ã€‚åœ¨æ¯ä¸ªå·ç§¯å±‚ä¹‹åï¼Œæˆ‘ä»¬æœ‰ä¸€ä¸ªè·¨åº¦ä¸º 2 çš„æœ€å¤§æ± å±‚ã€‚è¿™å…è®¸æˆ‘ä»¬ä»å›¾åƒä¸­æå–å¿…è¦çš„ç‰¹å¾ã€‚ç„¶åæˆ‘ä»¬å±•å¹³å¼ é‡ï¼Œå°†å®ƒä»¬æ”¾å…¥å¯†é›†å±‚ï¼Œé€šè¿‡å¤šå±‚æ„ŸçŸ¥å™¨(MLP)æ¥æ‰§è¡Œæˆ‘ä»¬çš„ 10 ä¸ªç±»åˆ«çš„åˆ†ç±»ä»»åŠ¡ã€‚

ç°åœ¨æˆ‘ä»¬å·²ç»æ¸…æ¥šäº†ç½‘ç»œçš„ç»“æ„ï¼Œè®©æˆ‘ä»¬çœ‹çœ‹å¦‚ä½•ä½¿ç”¨ PyTorch æ¥æ„å»ºå®ƒ:

```
# Build the neural network, expand on top of nn.Module
class Network(nn.Module):
  def __init__(self):
    super().__init__()

    # define layers
    self.conv1 = nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5)
    self.conv2 = nn.Conv2d(in_channels=6, out_channels=12, kernel_size=5)

    self.fc1 = nn.Linear(in_features=12*4*4, out_features=120)
    self.fc2 = nn.Linear(in_features=120, out_features=60)
    self.out = nn.Linear(in_features=60, out_features=10)

  # define forward function
  def forward(self, t):
    # conv 1
    t = self.conv1(t)
    t = F.relu(t)
    t = F.max_pool2d(t, kernel_size=2, stride=2)

    # conv 2
    t = self.conv2(t)
    t = F.relu(t)
    t = F.max_pool2d(t, kernel_size=2, stride=2)

    # fc1
    t = t.reshape(-1, 12*4*4)
    t = self.fc1(t)
    t = F.relu(t)

    # fc2
    t = self.fc2(t)
    t = F.relu(t)

    # output
    t = self.out(t)
    # don't need softmax here since we'll use cross-entropy as activation.

    return t
```

é¦–å…ˆ PyTorch ä¸­æ‰€æœ‰çš„ç½‘ç»œç±»éƒ½æ˜¯åœ¨åŸºç±»ä¸Šæ‰©å±•çš„:`nn.Module`ã€‚å®ƒåŒ…å«äº†æ‰€æœ‰çš„åŸºç¡€çŸ¥è¯†:**æƒé‡ã€åå·®ã€æ­£å‘æ–¹æ³•**ä»¥åŠä¸€äº›å®ç”¨å±æ€§å’Œæ–¹æ³•ï¼Œå¦‚`.parameters()`å’Œ`.zero_grad()`ï¼Œæˆ‘ä»¬ä¹Ÿå°†ä½¿ç”¨å®ƒä»¬ã€‚

æˆ‘ä»¬çš„ç½‘ç»œç»“æ„åœ¨`__init__` dunder å‡½æ•°ä¸­å®šä¹‰ã€‚

```
def __init__(self): 
  super().__init__()   # define layers 
  self.conv1 = nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5)
  self.conv2 = nn.Conv2d(in_channels=6, out_channels=12, kernel_size=5)
  self.fc1 = nn.Linear(in_features=12*4*4, out_features=120)
  self.fc2 = nn.Linear(in_features=120, out_features=60)
  self.out = nn.Linear(in_features=60, out_features=10)
```

`nn.Conv2d`å’Œ`nn.Linear`æ˜¯åœ¨`torch.nn`æ¨¡å—ä¸­å®šä¹‰çš„ä¸¤ä¸ªæ ‡å‡† PyTorch å±‚ã€‚è¿™äº›éƒ½æ˜¯ä¸è¨€è‡ªæ˜çš„ã€‚éœ€è¦æ³¨æ„çš„ä¸€ç‚¹æ˜¯ï¼Œæˆ‘ä»¬åœ¨è¿™é‡Œåªå®šä¹‰äº†å®é™…çš„å±‚ã€‚æ¿€æ´»å’Œæœ€å¤§æ± åŒ–**æ“ä½œ**åŒ…å«åœ¨ä¸‹é¢è§£é‡Šçš„è½¬å‘åŠŸèƒ½ä¸­ã€‚

```
# define forward function  
def forward(self, t):  
  # conv 1  
  t = self.conv1(t)  
  t = F.relu(t)  
  t = F.max_pool2d(t, kernel_size=2, stride=2)     # conv 2  
  t = self.conv2(t)   
  t = F.relu(t)  
  t = F.max_pool2d(t, kernel_size=2, stride=2)     # fc1   
  t = t.reshape(-1, 12*4*4)  
  t = self.fc1(t)  
  t = F.relu(t)     # fc2  
  t = self.fc2(t)  
  t = F.relu(t)    # output  
  t = self.out(t)    # don't need softmax here since we'll use cross-entropy as activation.   
  return t
```

ä¸€æ—¦å®šä¹‰äº†å±‚ï¼Œæˆ‘ä»¬å°±å¯ä»¥ä½¿ç”¨å±‚æœ¬èº«æ¥è®¡ç®—æ¯ä¸€å±‚çš„è½¬å‘ç»“æœï¼ŒåŠ ä¸Šæ¿€æ´»å‡½æ•°(ReLu)å’Œæœ€å¤§æ± æ“ä½œï¼Œæˆ‘ä»¬å¯ä»¥å¾ˆå®¹æ˜“åœ°ç¼–å†™æˆ‘ä»¬çš„ç½‘ç»œçš„è½¬å‘å‡½æ•°ï¼Œå¦‚ä¸Šæ‰€è¿°ã€‚æ³¨æ„ï¼Œåœ¨`fc1`(å®Œå…¨è¿æ¥ç¬¬ 1 å±‚)ä¸Šï¼Œæˆ‘ä»¬ä½¿ç”¨ PyTorch çš„å¼ é‡è¿ç®—`t.reshape`æ¥å±•å¹³å¼ é‡ï¼Œè¿™æ ·å®ƒå°±å¯ä»¥ä¼ é€’ç»™åé¢çš„è‡´å¯†å±‚ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬æ²¡æœ‰åœ¨è¾“å‡ºå±‚æ·»åŠ  softmax æ¿€æ´»å‡½æ•°ï¼Œå› ä¸º PyTorch çš„ **CrossEntropy** å‡½æ•°ä¼šä¸ºæˆ‘ä»¬å¤„ç†è¿™ä¸ªé—®é¢˜ã€‚

# è¶…å‚æ•°

é€šå¸¸æƒ…å†µä¸‹ï¼Œæˆ‘ä»¬å¯ä»¥åªæ‰‹åŠ¨é€‰æ‹©ä¸€ç»„è¶…å‚æ•°ï¼Œå¹¶ç”¨å®ƒä»¬åšä¸€äº›å®éªŒã€‚åœ¨è¿™ä¸ªä¾‹å­ä¸­ï¼Œæˆ‘ä»¬æƒ³é€šè¿‡å¼•å…¥ä¸€äº›ç»“æ„åŒ–æ¥åšæ›´å¤šçš„äº‹æƒ…ã€‚æˆ‘ä»¬å°†æ„å»ºä¸€ä¸ªç³»ç»Ÿæ¥ç”Ÿæˆä¸åŒçš„è¶…å‚æ•°ç»„åˆï¼Œå¹¶ä½¿ç”¨å®ƒä»¬æ¥æ‰§è¡Œè®­ç»ƒâ€œè¿è¡Œâ€ã€‚æ¯æ¬¡â€œè¿è¡Œâ€ä½¿ç”¨ä¸€ç»„è¶…å‚æ•°ç»„åˆã€‚å°†æ¯æ¬¡è·‘æ­¥çš„è®­ç»ƒæ•°æ®/ç»“æœå¯¼å‡ºåˆ° Tensor Boardï¼Œä»¥ä¾¿æˆ‘ä»¬å¯ä»¥ç›´æ¥æ¯”è¾ƒå¹¶æŸ¥çœ‹å“ªä¸ªè¶…å‚æ•°é›†è¡¨ç°æœ€ä½³ã€‚

æˆ‘ä»¬å°†æ‰€æœ‰çš„è¶…å‚æ•°å­˜å‚¨åœ¨ä¸€ä¸ª [**æœ‰åºæŒ‡ä»¤**](https://www.geeksforgeeks.org/ordereddict-in-python/) ä¸­:

```
# put all hyper params into a OrderedDict, easily expandable
params = OrderedDict(
    lr = [.01, .001],
    batch_size = [100, 1000],
    shuffle = [True, False]
)
epochs = 3
```

`lr`:å­¦ä¹ ç‡ã€‚æˆ‘ä»¬æƒ³ä¸ºæˆ‘ä»¬çš„æ¨¡å‹å°è¯• 0.01 å’Œ 0.001ã€‚

`batch_size`:æ‰¹é‡ï¼ŒåŠ é€Ÿè®­ç»ƒè¿‡ç¨‹ã€‚æˆ‘ä»¬ä¼šç”¨ 100 å’Œ 1000ã€‚

`shuffle` : Shuffle toggleï¼Œæˆ‘ä»¬æ˜¯å¦åœ¨è®­ç»ƒå‰æ´—ç‰Œã€‚

ä¸€æ—¦å‚æ•°ä¸‹é™ã€‚æˆ‘ä»¬ä½¿ç”¨ä¸¤ä¸ªåŠ©æ‰‹ç±»:`RunBuilder`å’Œ`RunManager`æ¥ç®¡ç†æˆ‘ä»¬çš„è¶…å‚æ•°å’Œè®­ç»ƒè¿‡ç¨‹ã€‚

## è¿è¡Œç”Ÿæˆå™¨

ç±»`RunBuilder`çš„ä¸»è¦ç›®çš„æ˜¯æä¾›ä¸€ä¸ªé™æ€æ–¹æ³•`get_runs`ã€‚å®ƒå°† OrderedDict(å…¶ä¸­å­˜å‚¨äº†æ‰€æœ‰è¶…å‚æ•°)ä½œä¸ºä¸€ä¸ªå‚æ•°ï¼Œå¹¶ç”Ÿæˆä¸€ä¸ªåä¸ºå…ƒç»„ `Run`çš„[ï¼Œæ¯ä¸ª`run`å…ƒç´ ä»£è¡¨è¶…å‚æ•°çš„ä¸€ç§å¯èƒ½ç»„åˆã€‚è¿™ä¸ªå‘½åå…ƒç»„ç¨åç”±è®­ç»ƒå¾ªç¯ä½¿ç”¨ã€‚ä»£ç å¾ˆå®¹æ˜“ç†è§£ã€‚](https://www.youtube.com/watch?v=GfxJYp9_nJA)

```
# import modules to build RunBuilder and RunManager helper classes
from collections  import OrderedDict
from collections import namedtuple
from itertools import product

# Read in the hyper-parameters and return a Run namedtuple containing all the 
# combinations of hyper-parameters
class RunBuilder():
  @staticmethod
  def get_runs(params):

    Run = namedtuple('Run', params.keys())

    runs = []
    for v in product(*params.values()):
      runs.append(Run(*v))

    return runs
```

## è¿è¡Œç®¡ç†å™¨

`RunManager` ç±»æœ‰å››ä¸ªä¸»è¦ç›®çš„ã€‚

1.  è®¡ç®—å¹¶è®°å½•æ¯ä¸ªæ—¶æœŸå’Œè¿è¡Œçš„æŒç»­æ—¶é—´ã€‚
2.  è®¡ç®—æ¯ä¸ªå†å…ƒå’Œè¿è¡Œçš„è®­ç»ƒæŸå¤±å’Œå‡†ç¡®åº¦ã€‚
3.  è®°å½•è®­ç»ƒæ•°æ®(å¦‚æŸè€—ã€å‡†ç¡®åº¦ã€é‡é‡ã€æ¢¯åº¦ã€è®¡ç®—å›¾ç­‰)ã€‚)å¹¶è¿è¡Œï¼Œç„¶åå°†å®ƒä»¬å¯¼å‡ºåˆ°å¼ é‡æ¿ä»¥ä¾›è¿›ä¸€æ­¥åˆ†æã€‚
4.  å°†æ‰€æœ‰è®­ç»ƒç»“æœä¿å­˜åœ¨`csv`å’Œ`json`ä¸­ï¼Œä»¥å¤‡å°†æ¥å‚è€ƒæˆ–æå– APIã€‚

å¦‚ä½ æ‰€è§ï¼Œå®ƒå¸®åŠ©æˆ‘ä»¬å¤„ç†åå‹¤å·¥ä½œï¼Œè¿™å¯¹æˆ‘ä»¬æˆåŠŸè®­ç»ƒæ¨¡å‹ä¹Ÿå¾ˆé‡è¦ã€‚è®©æˆ‘ä»¬çœ‹çœ‹ä»£ç ã€‚è¿™æœ‰ç‚¹é•¿ï¼Œè¯·åŸè°…:

```
# Helper class, help track loss, accuracy, epoch time, run time, 
# hyper-parameters etc. Also record to TensorBoard and write into csv, json
class RunManager():
  def __init__(self):

    # tracking every epoch count, loss, accuracy, time
    self.epoch_count = 0
    self.epoch_loss = 0
    self.epoch_num_correct = 0
    self.epoch_start_time = None

    # tracking every run count, run data, hyper-params used, time
    self.run_params = None
    self.run_count = 0
    self.run_data = []
    self.run_start_time = None

    # record model, loader and TensorBoard 
    self.network = None
    self.loader = None
    self.tb = None

  # record the count, hyper-param, model, loader of each run
  # record sample images and network graph to TensorBoard  
  def begin_run(self, run, network, loader):

    self.run_start_time = time.time()

    self.run_params = run
    self.run_count += 1

    self.network = network
    self.loader = loader
    self.tb = SummaryWriter(comment=f'-{run}')

    images, labels = next(iter(self.loader))
    grid = torchvision.utils.make_grid(images)

    self.tb.add_image('images', grid)
    self.tb.add_graph(self.network, images)

  # when run ends, close TensorBoard, zero epoch count
  def end_run(self):
    self.tb.close()
    self.epoch_count = 0

  # zero epoch count, loss, accuracy, 
  def begin_epoch(self):
    self.epoch_start_time = time.time()

    self.epoch_count += 1
    self.epoch_loss = 0
    self.epoch_num_correct = 0

  # 
  def end_epoch(self):
    # calculate epoch duration and run duration(accumulate)
    epoch_duration = time.time() - self.epoch_start_time
    run_duration = time.time() - self.run_start_time

    # record epoch loss and accuracy
    loss = self.epoch_loss / len(self.loader.dataset)
    accuracy = self.epoch_num_correct / len(self.loader.dataset)

    # Record epoch loss and accuracy to TensorBoard 
    self.tb.add_scalar('Loss', loss, self.epoch_count)
    self.tb.add_scalar('Accuracy', accuracy, self.epoch_count)

    # Record params to TensorBoard
    for name, param in self.network.named_parameters():
      self.tb.add_histogram(name, param, self.epoch_count)
      self.tb.add_histogram(f'{name}.grad', param.grad, self.epoch_count)

    # Write into 'results' (OrderedDict) for all run related data
    results = OrderedDict()
    results["run"] = self.run_count
    results["epoch"] = self.epoch_count
    results["loss"] = loss
    results["accuracy"] = accuracy
    results["epoch duration"] = epoch_duration
    results["run duration"] = run_duration

    # Record hyper-params into 'results'
    for k,v in self.run_params._asdict().items(): results[k] = v
    self.run_data.append(results)
    df = pd.DataFrame.from_dict(self.run_data, orient = 'columns')

    # display epoch information and show progress
    clear_output(wait=True)
    display(df)

  # accumulate loss of batch into entire epoch loss
  def track_loss(self, loss):
    # multiply batch size so variety of batch sizes can be compared
    self.epoch_loss += loss.item() * self.loader.batch_size

  # accumulate number of corrects of batch into entire epoch num_correct
  def track_num_correct(self, preds, labels):
    self.epoch_num_correct += self._get_num_correct(preds, labels)

  @torch.no_grad()
  def _get_num_correct(self, preds, labels):
    return preds.argmax(dim=1).eq(labels).sum().item()

  # save end results of all runs into csv, json for further analysis
  def save(self, fileName):

    pd.DataFrame.from_dict(
        self.run_data, 
        orient = 'columns',
    ).to_csv(f'{fileName}.csv')

    with open(f'{fileName}.json', 'w', encoding='utf-8') as f:
      json.dump(self.run_data, f, ensure_ascii=False, indent=4)
```

`**__init__**`:åˆå§‹åŒ–å¿…è¦çš„å±æ€§ï¼Œå¦‚è®¡æ•°ã€ä¸¢å¤±ã€æ­£ç¡®é¢„æµ‹æ•°ã€å¼€å§‹æ—¶é—´ç­‰ã€‚

`**begin_run**`:è®°å½•è¿è¡Œå¼€å§‹æ—¶é—´ï¼Œä»¥ä¾¿å½“è¿è¡Œç»“æŸæ—¶ï¼Œå¯ä»¥è®¡ç®—è¿è¡Œçš„æŒç»­æ—¶é—´ã€‚åˆ›å»ºä¸€ä¸ª`SummaryWriter`å¯¹è±¡æ¥å­˜å‚¨æˆ‘ä»¬åœ¨è¿è¡Œè¿‡ç¨‹ä¸­æƒ³è¦å¯¼å‡ºåˆ°å¼ é‡æ¿çš„æ‰€æœ‰å†…å®¹ã€‚å°†ç½‘ç»œå›¾å’Œæ ·æœ¬å›¾åƒå†™å…¥`SummaryWriter`å¯¹è±¡ã€‚

`**end_run**`:è¿è¡Œå®Œæˆåï¼Œå…³é—­ SummaryWriter å¯¹è±¡ï¼Œå¹¶å°†å†å…ƒè®¡æ•°é‡ç½®ä¸º 0(å‡†å¤‡ä¸‹ä¸€æ¬¡è¿è¡Œ)ã€‚

`**begin_epoch**`:è®°å½•å†å…ƒå¼€å§‹æ—¶é—´ï¼Œä»¥ä¾¿åœ¨å†å…ƒç»“æŸæ—¶è®¡ç®—å†å…ƒæŒç»­æ—¶é—´ã€‚å¤ä½`epoch_loss`å’Œ`epoch_num_correct`ã€‚

è¿™ä¸ªå‡½æ•°æ˜¯å¤§å¤šæ•°äº‹æƒ…å‘ç”Ÿçš„åœ°æ–¹ã€‚å½“ä¸€ä¸ªæ—¶æœŸç»“æŸæ—¶ï¼Œæˆ‘ä»¬å°†è®¡ç®—æ—¶æœŸæŒç»­æ—¶é—´å’Œè¿è¡ŒæŒç»­æ—¶é—´(ç›´åˆ°è¿™ä¸ªæ—¶æœŸï¼Œè€Œä¸æ˜¯æœ€åçš„è¿è¡ŒæŒç»­æ—¶é—´ï¼Œé™¤éæ˜¯è¿è¡Œçš„æœ€åä¸€ä¸ªæ—¶æœŸ)ã€‚æˆ‘ä»¬å°†è®¡ç®—è¿™ä¸ªæ—¶æœŸçš„æ€»æŸè€—å’Œç²¾ç¡®åº¦ï¼Œç„¶åå°†æŸè€—ã€ç²¾ç¡®åº¦ã€æƒé‡/åå·®ã€æ¢¯åº¦å¯¼å‡ºåˆ°å¼ é‡æ¿ä¸­ã€‚ä¸ºäº†ä¾¿äºåœ¨ Jupyter ç¬”è®°æœ¬ä¸­è·Ÿè¸ªï¼Œæˆ‘ä»¬è¿˜åˆ›å»ºäº†ä¸€ä¸ª **OrderedDict** å¯¹è±¡`results`ï¼Œå¹¶å°†æˆ‘ä»¬æ‰€æœ‰çš„è¿è¡Œæ•°æ®(æŸå¤±ã€å‡†ç¡®åº¦ã€è¿è¡Œè®¡æ•°ã€å†å…ƒè®¡æ•°ã€è¿è¡ŒæŒç»­æ—¶é—´ã€å†å…ƒæŒç»­æ—¶é—´ã€æ‰€æœ‰è¶…å‚æ•°)æ”¾å…¥å…¶ä¸­ã€‚ç„¶åæˆ‘ä»¬å°†ä½¿ç”¨**ç†ŠçŒ«**æ¥è¯»å–å®ƒï¼Œå¹¶ä»¥æ•´æ´çš„è¡¨æ ¼æ ¼å¼æ˜¾ç¤ºå‡ºæ¥ã€‚

`**track_loss**` **ã€** `**track_num_correct**` **ã€** `**_get_num_correct**`:è¿™äº›æ˜¯ç´¯è®¡æŸå¤±çš„æ•ˆç”¨å‡½æ•°ï¼Œæ¯æ‰¹çš„æ­£ç¡®é¢„æµ‹æ•°ï¼Œä»¥ä¾¿ä»¥åè®¡ç®—å†å…ƒæŸå¤±å’Œç²¾åº¦ã€‚

`**save**`:å°†æ‰€æœ‰è¿è¡Œæ•°æ®(æ‰€æœ‰è¿è¡Œçš„`results` **OrderedDict** å¯¹è±¡åˆ—è¡¨)ä¿å­˜ä¸º`csv`å’Œ`json`æ ¼å¼ï¼Œä»¥ä¾¿è¿›ä¸€æ­¥åˆ†ææˆ– API è®¿é—®ã€‚

è¿™é—¨è¯¾æœ‰å¾ˆå¤šä¸œè¥¿è¦å­¦ã€‚æ­å–œä½ èµ°åˆ°è¿™ä¸€æ­¥ï¼æœ€å›°éš¾çš„éƒ¨åˆ†å·²ç»è¿‡å»äº†ã€‚ä»ç°åœ¨å¼€å§‹ï¼Œä¸€åˆ‡éƒ½ä¼šå˜å¾—æœ‰æ„ä¹‰ã€‚

# åŸ¹å…»

ç»ˆäºï¼Œæˆ‘ä»¬å‡†å¤‡å¥½è¿›è¡Œä¸€äº›è®­ç»ƒäº†ï¼åœ¨æˆ‘ä»¬çš„`RunBuilder` å’Œ`RunManager`è¯¾ç¨‹çš„å¸®åŠ©ä¸‹ï¼ŒåŸ¹è®­è¿‡ç¨‹å˜å¾—è½»è€Œæ˜“ä¸¾:

```
m = RunManager()

# get all runs from params using RunBuilder class
for run in RunBuilder.get_runs(params):

    # if params changes, following line of code should reflect the changes too
    network = Network()
    loader = torch.utils.data.DataLoader(train_set, batch_size = run.batch_size)
    optimizer = optim.Adam(network.parameters(), lr=run.lr)

    m.begin_run(run, network, loader)
    for epoch in range(epochs):

      m.begin_epoch()
      for batch in loader:

        images = batch[0]
        labels = batch[1]
        preds = network(images)
        loss = F.cross_entropy(preds, labels)

        optimizer.zero_grad()
        loss.backward()
        optimizer.step()

        m.track_loss(loss)
        m.track_num_correct(preds, labels)

      m.end_epoch()
    m.end_run()

# when all runs are done, save results to files
m.save('results')
```

é¦–å…ˆï¼Œæˆ‘ä»¬ä½¿ç”¨`RunBuilder`åˆ›å»ºè¶…å‚æ•°çš„è¿­ä»£å™¨ï¼Œç„¶åéå†æ¯ä¸ªè¶…å‚æ•°ç»„åˆæ¥æ‰§è¡Œæˆ‘ä»¬çš„è®­ç»ƒ:

```
for run in RunBuilder.get_runs(params):
```

ç„¶åï¼Œæˆ‘ä»¬ä»ä¸Šé¢å®šä¹‰çš„`Network`ç±»åˆ›å»ºæˆ‘ä»¬çš„`network`å¯¹è±¡ã€‚`network = Network()`ã€‚è¿™ä¸ª`network`ç‰©ä½“æ‰¿è½½äº†æˆ‘ä»¬éœ€è¦è®­ç»ƒçš„æ‰€æœ‰é‡é‡/åå·®ã€‚

æˆ‘ä»¬è¿˜éœ€è¦åˆ›å»ºä¸€ä¸ª`DataLoader` å¯¹è±¡ã€‚å®ƒæ˜¯ä¸€ä¸ª PyTorch ç±»ï¼Œä¿å­˜æˆ‘ä»¬çš„è®­ç»ƒ/éªŒè¯/æµ‹è¯•æ•°æ®é›†ï¼Œå®ƒå°†éå†æ•°æ®é›†ï¼Œå¹¶æŒ‰æŒ‡å®šçš„`batch_size`æ‰¹é‡ç»™æˆ‘ä»¬è®­ç»ƒæ•°æ®ã€‚

```
loader = torch.utils.data.DataLoader(train_set, batch_size = run.batch_size)
```

ä¹‹åï¼Œæˆ‘ä»¬å°†ä½¿ç”¨`torch.optim`ç±»åˆ›å»ºä¸€ä¸ªä¼˜åŒ–å™¨ã€‚`optim`ç±»è·å–ç½‘ç»œå‚æ•°å’Œå­¦ä¹ ç‡ä½œä¸ºè¾“å…¥ï¼Œå°†å¸®åŠ©æˆ‘ä»¬é€æ­¥å®Œæˆè®­ç»ƒè¿‡ç¨‹å¹¶æ›´æ–°æ¢¯åº¦ç­‰ã€‚æˆ‘ä»¬å°†ä½¿ç”¨ Adam ä½œä¸ºä¼˜åŒ–ç®—æ³•ã€‚

```
optimizer = optim.Adam(network.parameters(), lr=run.lr)
```

å¥½çš„ã€‚ç°åœ¨æˆ‘ä»¬å·²ç»åˆ›å»ºäº†ç½‘ç»œï¼Œå‡†å¤‡å¥½äº†æ•°æ®åŠ è½½å™¨ï¼Œé€‰æ‹©äº†ä¼˜åŒ–å™¨ã€‚è®©æˆ‘ä»¬å¼€å§‹è®­ç»ƒå§ï¼

æˆ‘ä»¬å°†éå†æ‰€æœ‰æˆ‘ä»¬æƒ³è¦è®­ç»ƒçš„çºªå…ƒ(è¿™é‡Œæ˜¯ 3 ä¸ª),æ‰€ä»¥æˆ‘ä»¬å°†æ‰€æœ‰ä¸œè¥¿éƒ½æ”¾åœ¨ä¸€ä¸ªâ€œçºªå…ƒâ€å¾ªç¯ä¸­ã€‚æˆ‘ä»¬è¿˜ä½¿ç”¨æˆ‘ä»¬çš„`RunManager`ç±»çš„`begin_run`æ–¹æ³•æ¥å¼€å§‹è·Ÿè¸ªè·‘æ­¥è®­ç»ƒæ•°æ®ã€‚

```
m.begin_run(run, network, loader)    
for epoch in range(epochs):
```

å¯¹äºæ¯ä¸ªæ—¶æœŸï¼Œæˆ‘ä»¬å°†éå†æ¯æ‰¹å›¾åƒæ¥è¿›è¡Œè®­ç»ƒã€‚

```
m.begin_epoch()    
for batch in loader:              
  images = batch[0]      
  labels = batch[1]      
  preds = network(images)      
  loss = F.cross_entropy(preds, labels)

  optimizer.zero_grad()  
  loss.backward()      
  optimizer.step()

  m.track_loss(loss)      
  m.track_num_correct(preds, labels)
```

ä¸Šé¢çš„ä»£ç æ˜¯çœŸæ­£çš„è®­ç»ƒå‘ç”Ÿçš„åœ°æ–¹ã€‚æˆ‘ä»¬ä»æ‰¹å¤„ç†ä¸­è¯»å…¥å›¾åƒå’Œæ ‡ç­¾ï¼Œä½¿ç”¨`network`ç±»è¿›è¡Œå‰å‘ä¼ æ’­(è¿˜è®°å¾—ä¸Šé¢çš„`forward`æ–¹æ³•å—ï¼Ÿ)å¹¶å¾—åˆ°é¢„æµ‹ã€‚é€šè¿‡é¢„æµ‹ï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨`cross_entropy`å‡½æ•°è®¡ç®—è¯¥æ‰¹æ¬¡çš„æŸå¤±ã€‚ä¸€æ—¦è®¡ç®—å‡ºæŸå¤±ï¼Œæˆ‘ä»¬ç”¨`.zero_grad()`é‡ç½®æ¢¯åº¦(å¦åˆ™ PyTorch ä¼šç´¯ç§¯æ¢¯åº¦ï¼Œè¿™ä¸æ˜¯æˆ‘ä»¬æƒ³è¦çš„)ï¼Œä½¿ç”¨`loss.backward()`æ–¹æ³•è¿›è¡Œä¸€æ¬¡åå‘ä¼ æ’­ï¼Œä»¥è®¡ç®—æƒé‡/åå·®çš„æ‰€æœ‰æ¢¯åº¦ã€‚ç„¶åï¼Œæˆ‘ä»¬ä½¿ç”¨ä¸Šé¢å®šä¹‰çš„ä¼˜åŒ–å™¨æ¥æ›´æ–°æƒé‡/åå·®ã€‚ç°åœ¨ç½‘ç»œå·²ç»ä¸ºå½“å‰æ‰¹æ¬¡æ›´æ–°ï¼Œæˆ‘ä»¬å°†è®¡ç®—æ­£ç¡®é¢„æµ‹çš„æŸå¤±å’Œæ•°é‡ï¼Œå¹¶ä½¿ç”¨æˆ‘ä»¬çš„`RunManager`ç±»çš„`track_loss`å’Œ`track_num_correct`æ–¹æ³•ç´¯ç§¯/è·Ÿè¸ªå®ƒä»¬ã€‚

ä¸€æ—¦å…¨éƒ¨å®Œæˆï¼Œæˆ‘ä»¬å°†ä½¿ç”¨`m.save('results')`å°†ç»“æœä¿å­˜åœ¨æ–‡ä»¶ä¸­ã€‚

ç¬”è®°æœ¬ä¸­è¿è¡Œçš„è¾“å‡ºå¦‚ä¸‹æ‰€ç¤º:

![](img/20a7dba510027e44f8a02993d059b2be.png)

# å¼ é‡æ¿

![](img/b670ba8b9acdf3c9b98659c116f6f755.png)

Image from Tensorboard.org

ä¼ æ„Ÿå™¨æ¿æ˜¯ä¸€ä¸ª TensorFlow å¯è§†åŒ–å·¥å…·ï¼Œç°åœ¨ PyTorch ä¹Ÿæ”¯æŒå®ƒã€‚æˆ‘ä»¬å·²ç»åŠªåŠ›å°†æ‰€æœ‰å†…å®¹è¾“å‡ºåˆ°ã€‚/runs 'æ–‡ä»¶å¤¹ï¼ŒTensor Board å°†åœ¨å…¶ä¸­æŸ¥æ‰¾è¦ä½¿ç”¨çš„è®°å½•ã€‚æˆ‘ä»¬ç°åœ¨éœ€è¦åšçš„åªæ˜¯å¯åŠ¨å¼ é‡æ¿å¹¶è¿›è¡Œæ£€æŸ¥ã€‚ç”±äºæˆ‘åœ¨ Google Colab ä¸Šè¿è¡Œè¿™ä¸ªæ¨¡å‹ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨ä¸€ä¸ªåä¸º`ngrok`çš„æœåŠ¡æ¥ä»£ç†å’Œè®¿é—®æˆ‘ä»¬åœ¨ Colab è™šæ‹Ÿæœºä¸Šè¿è¡Œçš„å¼ é‡æ¿ã€‚å…ˆå®‰è£…`ngrok` :

```
!wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip!unzip ngrok-stable-linux-amd64.zip
```

ç„¶åï¼ŒæŒ‡å®šæˆ‘ä»¬è¦ä»ä¸­è¿è¡Œå¼ é‡æ¿çš„æ–‡ä»¶å¤¹ï¼Œå¹¶å¯åŠ¨å¼ é‡æ¿ web ç•Œé¢ã€‚/runs æ˜¯é»˜è®¤å€¼):

```
LOG_DIR = './runs'get_ipython().system_raw('tensorboard --logdir {} --host 0.0.0.0 --port 6006 &'.format(LOG_DIR))
```

å¯åŠ¨`ngrok`ä»£ç†:

```
get_ipython().system_raw('./ngrok http 6006 &')
```

ç”Ÿæˆä¸€ä¸ª URLï¼Œä»¥ä¾¿æˆ‘ä»¬å¯ä»¥ä» Jupyter ç¬”è®°æœ¬ä¸­è®¿é—®æˆ‘ä»¬çš„å¼ é‡æ¿:

```
! curl -s http://localhost:4040/api/tunnels | python3 -c \"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])"
```

æ­£å¦‚æˆ‘ä»¬åœ¨ä¸‹é¢çœ‹åˆ°çš„ï¼ŒTensorBoard æ˜¯ä¸€ä¸ªéå¸¸æ–¹ä¾¿çš„å¯è§†åŒ–å·¥å…·ï¼Œè®©æˆ‘ä»¬å¯ä»¥æ·±å…¥äº†è§£æˆ‘ä»¬çš„è®­ç»ƒï¼Œå¹¶å¯ä»¥æå¤§åœ°å¸®åŠ©è¶…å‚æ•°è°ƒæ•´è¿‡ç¨‹ã€‚æˆ‘ä»¬å¯ä»¥å¾ˆå®¹æ˜“åœ°æ‰¾å‡ºå“ªä¸ªè¶…å‚æ•°ç»„ä»¶è¡¨ç°æœ€å¥½ï¼Œç„¶åç”¨å®ƒæ¥åšæˆ‘ä»¬çœŸæ­£çš„è®­ç»ƒã€‚

![](img/23a6b096511ceb3324d05ca28106aa54.png)![](img/082aca40dbaad8ee63b4f96d7565ff73.png)![](img/9ed4dc0229aadf0d21ca6a0fcc235c59.png)

# ç»“è®º

æ­£å¦‚ä½ æ‰€çœ‹åˆ°çš„ï¼ŒPyTorch ä½œä¸ºä¸€ä¸ªæœºå™¨å­¦ä¹ æ¡†æ¶æ˜¯çµæ´»çš„ã€å¼ºå¤§çš„å’Œå¯Œæœ‰è¡¨ç°åŠ›çš„ã€‚ä½ åªéœ€è¦å†™ Python ä»£ç ã€‚ç”±äºæœ¬æ–‡çš„ä¸»è¦é‡ç‚¹æ˜¯å±•ç¤ºå¦‚ä½•ä½¿ç”¨ PyTorch æ„å»ºä¸€ä¸ªå·ç§¯ç¥ç»ç½‘ç»œï¼Œå¹¶ä»¥ç»“æ„åŒ–çš„æ–¹å¼å¯¹å…¶è¿›è¡Œè®­ç»ƒï¼Œå› æ­¤æˆ‘æ²¡æœ‰å®Œæˆæ•´ä¸ªè®­ç»ƒæ—¶æœŸï¼Œç²¾åº¦ä¹Ÿä¸æ˜¯æœ€ä½³çš„ã€‚ä½ å¯ä»¥è‡ªå·±è¯•è¯•ï¼Œçœ‹çœ‹æ¨¡å‹è¡¨ç°å¦‚ä½•ã€‚

è¿™ç¯‡æ–‡ç« å¾ˆå¤§ç¨‹åº¦ä¸Šå—åˆ°äº† deeplizard åœ¨ YouTube ä¸Šçš„ PyTorch è§†é¢‘ç³»åˆ—çš„å¯å‘ã€‚ç”šè‡³å¤§éƒ¨åˆ†ä»£ç ç‰‡æ®µéƒ½æ˜¯ç›´æ¥æŠ„è¢­è¿‡æ¥çš„ã€‚æˆ‘æƒ³æ„Ÿè°¢ä»–ä»¬çš„ä¼Ÿå¤§å†…å®¹ï¼Œå¦‚æœä½ è§‰å¾—æœ‰å¿…è¦æ·±å…¥ç ”ç©¶ï¼Œéšæ—¶å»çœ‹çœ‹ï¼Œå¹¶è®¢é˜…ä»–ä»¬çš„é¢‘é“ã€‚

è§‰å¾—è¿™ç¯‡æ–‡ç« æœ‰ç”¨ï¼Ÿåœ¨ Medium ä¸Šå…³æ³¨æˆ‘([æç«‹ä¼Ÿ](https://medium.com/u/72c98619a048?source=post_page-----efb297e22582--------------------------------))æˆ–è€…ä½ å¯ä»¥åœ¨ Twitter [@lymenlee](https://twitter.com/lymenlee) æˆ–è€…æˆ‘çš„åšå®¢ç½‘ç«™[wayofnumbers.com](https://wayofnumbers.com)ä¸Šæ‰¾åˆ°æˆ‘ã€‚ä½ ä¹Ÿå¯ä»¥çœ‹çœ‹æˆ‘ä¸‹é¢æœ€å—æ¬¢è¿çš„æ–‡ç« ï¼

[](/this-is-cs50-a-pleasant-way-to-kick-off-your-data-science-education-d6075a6e761a) [## â€œè¿™æ˜¯ CS50â€:å¼€å§‹æ•°æ®ç§‘å­¦æ•™è‚²çš„æ„‰å¿«æ–¹å¼

### ä¸ºä»€ä¹ˆ CS50 ç‰¹åˆ«é€‚åˆå·©å›ºä½ çš„è½¯ä»¶å·¥ç¨‹åŸºç¡€

towardsdatascience.com](/this-is-cs50-a-pleasant-way-to-kick-off-your-data-science-education-d6075a6e761a) [](/two-sides-of-the-same-coin-fast-ai-vs-deeplearning-ai-b67e9ec32133) [## ä¸€æšç¡¬å¸çš„ä¸¤é¢:æ°ç‘ç±³Â·éœåå¾·çš„ fast.ai vs å´æ©è¾¾çš„ deeplearning.ai

### å¦‚ä½•ä¸é€šè¿‡åŒæ—¶å‚åŠ  fast.ai å’Œ deeplearning.ai è¯¾ç¨‹æ¥â€œè¿‡åº¦é€‚åº”â€ä½ çš„äººå·¥æ™ºèƒ½å­¦ä¹ 

towardsdatascience.com](/two-sides-of-the-same-coin-fast-ai-vs-deeplearning-ai-b67e9ec32133) [](https://medium.com/datadriveninvestor/thoughts-on-andrew-ngs-machine-learning-course-7724df76320f) [## æˆ‘å®Œæˆäº†å´æ©è¾¾çš„æœºå™¨å­¦ä¹ è¯¾ç¨‹ï¼Œæ„Ÿè§‰æ£’æäº†ï¼

### å¥½çš„ï¼Œåçš„ï¼Œç¾ä¸½çš„

medium.com](https://medium.com/datadriveninvestor/thoughts-on-andrew-ngs-machine-learning-course-7724df76320f)