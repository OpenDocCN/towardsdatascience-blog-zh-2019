<html>
<head>
<title>Create a customized gym environment for Star Craft 2</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">为星际争霸 2 创建一个定制的健身房环境</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/create-a-customized-gym-environment-for-star-craft-2-8558d301131f?source=collection_archive---------29-----------------------#2019-11-25">https://towardsdatascience.com/create-a-customized-gym-environment-for-star-craft-2-8558d301131f?source=collection_archive---------29-----------------------#2019-11-25</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><p id="bbf6" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><em class="kl">在本帖中，你将能够学习什么是健身房环境，以及如何以地图 DefeatZerglingsAndBanelings 上的 PySC2 为例创建一个 OpenAI 定制的健身房环境。</em></p><figure class="kn ko kp kq gt kr gh gi paragraph-image"><div role="button" tabindex="0" class="ks kt di ku bf kv"><div class="gh gi km"><img src="../Images/2bf02198e5c0cfde38509db760f4e4b4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*vIBz4it1NNWgaPlbOHS2hA.jpeg"/></div></div><figcaption class="ky kz gj gh gi la lb bd b be z dk">OpenAI Gym x Star Craft 2</figcaption></figure><p id="c133" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">目前，有多种强化学习框架可用(例如，OpenAI 基线、稳定基线、TFAgent、多巴胺和 TensorForce 等。)各有利弊。然而，如果您想在各种应用程序环境下使用这些工具，最常见和最方便的方法是构建一个定制的健身房环境。</p><h1 id="29f6" class="lc ld iq bd le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz bi translated">健身房环境</h1><p id="ad7c" class="pw-post-body-paragraph jn jo iq jp b jq ma js jt ju mb jw jx jy mc ka kb kc md ke kf kg me ki kj kk ij bi translated">那么什么是健身房环境呢？</p><p id="d016" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">在我们开始回答之前，让我们回顾一下强化学习的过程。</p><p id="d51d" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">强化学习基本上是一个马尔可夫决策过程(MDP ),在这个过程中，主体将根据对环境的观察采取一些行动，以换取反馈。根据反馈，无论是积极的还是消极的，代理人所使用的决策策略将相应地加强或削弱。</p><figure class="kn ko kp kq gt kr gh gi paragraph-image"><div class="gh gi mf"><img src="../Images/46089d4ba6161c6e585a1d2e36af1497.png" data-original-src="https://miro.medium.com/v2/resize:fit:702/format:webp/1*-dWnfinbC7e_TnDhKnByCg.png"/></div><figcaption class="ky kz gj gh gi la lb bd b be z dk">MDPs</figcaption></figure><p id="35ed" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">MDP 需要两个关键组件，即行动和对环境的相应观察。由于不同的环境有不同的观察和行动空间，为了迎合环境不断变化的需求而重新发明各种算法是非常耗时和不切实际的。因此，提出一个可以表示各种设置并可以轻松插入多个框架的标准化环境似乎是一个可行的解决方案。</p><p id="8524" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">这就是健身房环境发挥作用的地方。健身房环境为强化学习过程提供了一个标准化的界面。</p><p id="625a" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">在健身房环境中，<code class="fe mg mh mi mj b">__init__</code>函数是<strong class="jp ir"> </strong>用于初始化环境。在训练过程中，动作通过一个<code class="fe mg mh mi mj b">step</code>函数传递给环境，新的观察作为返回。<strong class="jp ir">动作</strong>和<strong class="jp ir">观察空间</strong>都被编码到<code class="fe mg mh mi mj b"><a class="ae mk" href="https://github.com/openai/gym/tree/master/gym/spaces" rel="noopener ugc nofollow" target="_blank">gym.spaces</a></code>中，用标准化的数字表示。<code class="fe mg mh mi mj b">reset</code>功能用于初始阶段或每集结束时重置环境。<code class="fe mg mh mi mj b">close</code>学习过程结束时调用函数，正确终止环境。此外，您还可以定义一个<code class="fe mg mh mi mj b">render</code>函数来在每一步之后渲染环境。</p><figure class="kn ko kp kq gt kr gh gi paragraph-image"><div class="gh gi ml"><img src="../Images/7dbf526f235101f8e40cf75a38dc3e61.png" data-original-src="https://miro.medium.com/v2/resize:fit:1242/format:webp/1*Fo4Lb3hhm4RRsRTWV973-g.png"/></div><figcaption class="ky kz gj gh gi la lb bd b be z dk">A gym environment structure</figcaption></figure><p id="82d5" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">下面是一个健身房环境的框架代码:</p><figure class="kn ko kp kq gt kr"><div class="bz fp l di"><div class="mm mn l"/></div></figure><h2 id="f08a" class="mo ld iq bd le mp mq dn li mr ms dp lm jy mt mu lq kc mv mw lu kg mx my ly mz bi translated">建立一个定制的健身房环境</h2><p id="0aa3" class="pw-post-body-paragraph jn jo iq jp b jq ma js jt ju mb jw jx jy mc ka kb kc md ke kf kg me ki kj kk ij bi translated">现在让我们用星际争霸 2 (SC2)建立一个定制的健身房环境。要了解更多关于 SC2 和 pysc2 的信息，请参考 deepmind <a class="ae mk" href="https://github.com/deepmind/pysc2" rel="noopener ugc nofollow" target="_blank"> git </a>资源库。</p><p id="9771" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">因为我们将使用来自 SC2 的原始观察和操作，所以我们需要安装 pysc2 的开发分支来完成这里的教程。</p><p id="267f" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">要安装 pysc2 的开发分支:</p><pre class="kn ko kp kq gt na mj nb nc aw nd bi"><span id="fccf" class="mo ld iq mj b gy ne nf l ng nh">git clone <a class="ae mk" href="https://github.com/deepmind/pysc2.git" rel="noopener ugc nofollow" target="_blank">https://github.com/deepmind/pysc2.git</a><br/>git checkout -t origin/dev<br/>pip install -e .</span></pre><p id="0ecf" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">要启动一个定制的健身房环境，我们需要创建下面的文件结构，如<a class="ae mk" href="https://github.com/openai/gym/blob/master/docs/creating-environments.md" rel="noopener ugc nofollow" target="_blank"> OpenAI </a>所述:</p><pre class="kn ko kp kq gt na mj nb nc aw nd bi"><span id="5bd0" class="mo ld iq mj b gy ne nf l ng nh">gym-foo/<br/>  README.md<br/>  setup.py<br/>  gym_foo/<br/>    __init__.py<br/>    envs/<br/>      __init__.py<br/>      <strong class="mj ir">foo_env1.py<br/>      foo_env2.py</strong><br/>      ...</span></pre><p id="91c1" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">配置<em class="kl"> setup.py </em>文件和所有的<em class="kl"> __init__。py </em>文件可以在这里<a class="ae mk" href="https://github.com/openai/gym/blob/master/docs/creating-environments.md" rel="noopener ugc nofollow" target="_blank">查看。因为我们将主要关注于<em class="kl"> foo_env.py </em>的实现，所以我包含了一个文件结构的</a><a class="ae mk" href="https://github.com/fyr91/gym-env-skeleton" rel="noopener ugc nofollow" target="_blank">框架</a>，您可以直接下载。</p><p id="fcf2" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">在<em class="kl"> envs </em>文件夹中，让我们创建一个名为<em class="kl">defeat _ zeglings _ banelings _ env . py 的环境文件。</em>这将是我们的健身房环境文件，我们将使用以下代码开始在这里创建我们的环境:</p><figure class="kn ko kp kq gt kr"><div class="bz fp l di"><div class="mm mn l"/></div></figure><p id="07de" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">注意到<code class="fe mg mh mi mj b">kwargs</code>被传递给了<code class="fe mg mh mi mj b">__init__</code>函数。这用于使用特定设置初始化 pysc2 环境。</p><p id="5c38" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我们将使用观察和操作定义一个默认设置来初始化微型地图 DefeatZerglingsAndBanelings 的 pysc2 环境:</p><figure class="kn ko kp kq gt kr"><div class="bz fp l di"><div class="mm mn l"/></div></figure><p id="f015" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><code class="fe mg mh mi mj b">players</code>由于设置需求，规范是需要的，虽然它在这里没有做任何事情。<code class="fe mg mh mi mj b">realtime</code>如果用于训练，可以设置为假。</p><p id="1869" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">接下来，我们将开始初始化 gym 和 pysc2 环境:</p><figure class="kn ko kp kq gt kr"><div class="bz fp l di"><div class="mm mn l"/></div></figure><p id="6e49" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><code class="fe mg mh mi mj b">env</code>用于存储 pysc2 游戏环境的实例。<code class="fe mg mh mi mj b">marines</code>、<code class="fe mg mh mi mj b">banelings</code>、<code class="fe mg mh mi mj b">zerglings</code>定义为保留对应的部队。我们为<code class="fe mg mh mi mj b">action_space</code>定义了大小为 123 的离散动作，包括站位、上移、下移、侧移以及用不同的单位攻击不同的目标。对于<code class="fe mg mh mi mj b">observation_space</code>，我们定义了一个 19x3 的 2D 矩阵，其下限和上限分别设置为 0 和 64。观察空间的每一行都将包含战场上每个单位的信息，包括坐标和 HP。</p><p id="a700" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">现在，我们需要从<code class="fe mg mh mi mj b">reset</code>函数初始化环境，因为它将在最开始被调用:</p><figure class="kn ko kp kq gt kr"><div class="bz fp l di"><div class="mm mn l"/></div></figure><p id="61e6" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">如果<code class="fe mg mh mi mj b">self.env</code>尚未设置，它将首先调用<code class="fe mg mh mi mj b">init_env</code>函数，用特定设置初始化 pysc2 环境。然后一切都会恢复原状。原始观测值将由<code class="fe mg mh mi mj b">get_derived_obs</code>函数处理，它将返回一个派生的 19x3 观测值矩阵。</p><p id="5ed5" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">接下来，我们将填充<code class="fe mg mh mi mj b">step</code>功能。让我们看看完整的代码:</p><figure class="kn ko kp kq gt kr"><div class="bz fp l di"><div class="mm mn l"/></div></figure><p id="b4b3" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">在<code class="fe mg mh mi mj b">step</code>函数中，<code class="fe mg mh mi mj b">take_action</code>会消耗一个动作值(从 0 到 122)，映射到一个游戏内动作并相应执行。之后，将计算导出的观测值。最后，返回四个值，包括导出的观察值、先前动作获得的奖励、用于重置环境的情节结束指示符和用于调试的诊断信息字典。</p><p id="ec7d" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">最后，我们即将在这里完成定制的健身房环境。由于我们不会触及<code class="fe mg mh mi mj b">render</code>函数，剩下的唯一事情就是用<code class="fe mg mh mi mj b">close</code>函数正确关闭 pysc2 游戏环境:</p><figure class="kn ko kp kq gt kr"><div class="bz fp l di"><div class="mm mn l"/></div></figure><p id="30ba" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">瞧啊。现在，我们为 SC2 定制了一个工作环境。完整的环境代码可以从<a class="ae mk" href="https://github.com/fyr91/sc2env" rel="noopener ugc nofollow" target="_blank">这里</a>下载。</p><figure class="kn ko kp kq gt kr gh gi paragraph-image"><div class="gh gi ni"><img src="../Images/b4db418f9392d7e80b48f1be61c90aac.png" data-original-src="https://miro.medium.com/v2/resize:fit:550/1*mgIabNcs-qtTnzsf72SO2Q.gif"/></div></figure><p id="e286" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">如果您已经知道如何从这一点继续定制环境，那么您可以在这里停下来享受一下。否则，我会在下一节中包含一个简短的演示，演示如何使用我们创建的强化学习框架。</p><h1 id="3618" class="lc ld iq bd le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz bi translated">稳定基线</h1><p id="96ea" class="pw-post-body-paragraph jn jo iq jp b jq ma js jt ju mb jw jx jy mc ka kb kc md ke kf kg me ki kj kk ij bi translated">出于演示目的，我们将在这里使用稳定的基线<strong class="jp ir"> </strong>。要安装稳定的基线，请遵循其官方文档页面<a class="ae mk" href="https://stable-baselines.readthedocs.io/en/master/" rel="noopener ugc nofollow" target="_blank">中的说明。</a></p><p id="af22" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">除了安装稳定的基线，我们还需要设置我们自己刚刚创建的定制环境。为此，切换到<em class="kl"> sc2env </em>根目录并输入以下内容:</p><pre class="kn ko kp kq gt na mj nb nc aw nd bi"><span id="e4e5" class="mo ld iq mj b gy ne nf l ng nh">pip install -e. </span></pre><p id="0d62" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">一旦安装过程完成，我们就可以开始使用 PPO2(您选择的算法)轻松地在我们自己的环境中进行训练。</p><p id="2c83" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">代码如下:</p><figure class="kn ko kp kq gt kr"><div class="bz fp l di"><div class="mm mn l"/></div></figure><p id="34c6" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">培训就像使用<code class="fe mg mh mi mj b">scikit-learn</code>模型一样简单:</p><ol class=""><li id="3997" class="nj nk iq jp b jq jr ju jv jy nl kc nm kg nn kk no np nq nr bi translated">指定要使用的型号(本例中为 PPO2)。</li><li id="1089" class="nj nk iq jp b jq ns ju nt jy nu kc nv kg nw kk no np nq nr bi translated">使用<code class="fe mg mh mi mj b">.learn()</code>开始学习。</li><li id="fddb" class="nj nk iq jp b jq ns ju nt jy nu kc nv kg nw kk no np nq nr bi translated">使用<code class="fe mg mh mi mj b">.save()</code>保存训练好的模型。</li></ol><p id="0b9f" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">请注意，PySC2 环境需要<code class="fe mg mh mi mj b">absl</code>包。</p><p id="dbbc" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">如果在 Windows 系统上运行，我们将能够在训练时看到渲染的游戏:</p><figure class="kn ko kp kq gt kr gh gi paragraph-image"><div class="gh gi nx"><img src="../Images/234d490bac8304043797ea3d1fd3dc54.png" data-original-src="https://miro.medium.com/v2/resize:fit:1360/1*IK534p0i9_iqL66wsDxqFg.gif"/></div></figure><p id="4515" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">否则，如果它运行在 Linux 系统上，我们可以使用 headless 模式加快训练速度。</p><p id="4c98" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">为了监控训练过程，tensorboard 得到了本机支持。我们需要做的就是在定义模型时指定日志目录。</p><h1 id="e2a6" class="lc ld iq bd le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz bi translated">摘要</h1><p id="90c8" class="pw-post-body-paragraph jn jo iq jp b jq ma js jt ju mb jw jx jy mc ka kb kc md ke kf kg me ki kj kk ij bi translated">现在你有了工具，但这并不意味着你将能够使用我们创造的环境直接获得智能人工智能。你还可以做更多的事情，让它变得有趣和聪明。你可以定义一些基本的动作，比如撤退或者攻击最近的。你可以提供更多的观察信息。你可以录制一些游戏，进行模仿学习或行为克隆。你也可以创建你自己的迷你地图来帮助你的 AI 建立一些课程来逐步学习技能。</p><figure class="kn ko kp kq gt kr gh gi paragraph-image"><div class="gh gi ny"><img src="../Images/71f59459b7d9346e34fde4ee18f8fbc6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1200/1*rYtXbuonkYkTzENWHoc8uQ.gif"/></div><figcaption class="ky kz gj gh gi la lb bd b be z dk">Result from environment with predefined basic actions suggested above</figcaption></figure><p id="051e" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">最后，我们已经到了这篇文章的结尾。在这篇文章中，我包含了一个使用 pysc2 创建定制健身房环境的教程，并演示了如何使用具有稳定基线的定制健身房环境。</p><p id="b968" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">希望这些有帮助。敬请期待，再见~</p><figure class="kn ko kp kq gt kr gh gi paragraph-image"><div class="gh gi nz"><img src="../Images/7549b92b28f970b8a0e5d85d455116ff.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/1*6oFFx5rulJ30XEYoXLm_QA.gif"/></div></figure></div></div>    
</body>
</html>