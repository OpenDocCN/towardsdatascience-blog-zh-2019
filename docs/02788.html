<html>
<head>
<title>Github Autocompletion with Machine Learning</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">带有机器学习的 Github 自动完成</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/github-autocompletion-with-machine-learning-a833cb90983e?source=collection_archive---------16-----------------------#2019-05-06">https://towardsdatascience.com/github-autocompletion-with-machine-learning-a833cb90983e?source=collection_archive---------16-----------------------#2019-05-06</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><p id="c9d2" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><em class="ko">作者</em><a class="ae kp" href="https://medium.com/@olarayej" rel="noopener"><em class="ko">óscar d . Lara Yejas</em></a><em class="ko">和</em> <a class="ae kp" href="https://medium.com/@jha_ankit" rel="noopener"> <em class="ko"> Ankit Jha </em> </a></p><figure class="kr ks kt ku gt kv gh gi paragraph-image"><div role="button" tabindex="0" class="kw kx di ky bf kz"><div class="gh gi kq"><img src="../Images/0315a5c5143237d0b12c5fbdd4d8648e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*j53G7KYBDUQsm8P1PasxkQ.png"/></div></div></figure><p id="fbf1" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">作为数据科学家，软件开发是更贴近我们的领域之一，因为毕竟我们是各种帮助我们构建模型的软件包和框架的狂热用户。</p><p id="e1f3" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">GitHub 是支持软件开发生命周期的关键技术之一，包括跟踪缺陷、任务、故事、提交等等。在一个大型的开发组织中，可能会有多个团队(即<em class="ko">小队</em>)承担特定的职责，例如<em class="ko">性能小队</em>、<em class="ko">安装小队</em>、<em class="ko"> UX 小队</em>和<em class="ko">文档小队</em>等。当创建一个新的工作条目时，这会带来挑战，因为用户可能不知道一个任务或者缺陷应该被分配给哪个团队，或者谁应该是它的所有者。但是机器学习能有帮助吗？答案是<em class="ko">是的</em>，特别是，如果我们有一些来自 GitHub 库的历史数据。</p><h1 id="19cd" class="lc ld it bd le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz bi translated"><strong class="ak">问题陈述</strong></h1><p id="5b6d" class="pw-post-body-paragraph jq jr it js b jt ma jv jw jx mb jz ka kb mc kd ke kf md kh ki kj me kl km kn im bi translated">我们在本文中试图解决的问题是:<em class="ko">我们是否可以创建一个 ML 模型，根据 GitHub 工作项的标题和其他特征来建议团队和所有者</em>？</p><h1 id="403b" class="lc ld it bd le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz bi translated"><strong class="ak">工具</strong></h1><p id="cfa2" class="pw-post-body-paragraph jq jr it js b jt ma jv jw jx mb jz ka kb mc kd ke kf md kh ki kj me kl km kn im bi translated">在本文中，我们将使用 R 编程语言。需要以下 R 包:</p><pre class="kr ks kt ku gt mf mg mh mi aw mj bi"><span id="ebbd" class="mk ld it mg b gy ml mm l mn mo">suppressWarnings({<br/>    <strong class="mg iu">library</strong>(tm)<br/>    <strong class="mg iu">library</strong>(zoo)<br/>    <strong class="mg iu">library</strong>(SnowballC)<br/>    <strong class="mg iu">library</strong>(wordcloud)<br/>    <strong class="mg iu">library</strong>(plotly)    <br/>    <strong class="mg iu">library</strong>(rword2vec)<br/>    <strong class="mg iu">library</strong>(text2vec)<br/>    <strong class="mg iu">library</strong>("reshape")<br/>    <strong class="mg iu">library</strong>(nnet)<br/>    <strong class="mg iu">library</strong>(randomForest)<br/>})</span></pre><h1 id="a10f" class="lc ld it bd le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz bi translated"><strong class="ak">数据集</strong></h1><p id="7f47" class="pw-post-body-paragraph jq jr it js b jt ma jv jw jx mb jz ka kb mc kd ke kf md kh ki kj me kl km kn im bi translated">GitHub 提供了不同的工作项特征，如<em class="ko"> id </em>、<em class="ko">标题</em>、<em class="ko">类型</em>、<em class="ko">严重性</em>、<em class="ko">小队</em>、<em class="ko">作者</em>、<em class="ko">状态</em>、<em class="ko">日期</em>等。<em class="ko">标题</em>将是我们的主要数据源，因为它总是需要的，并且可能具有最高的相关性；不难想象，比如工作项标题为<em class="ko">“尝试部署 Docker 实例时安装程序失败”</em>的话，很可能应该分配给<em class="ko">安装程序</em>小队。或者，一个标题，如<em class="ko">“特征 XYZ 的文档丢失”</em>，表明该工作项可能被分配给文档团队。下面是 GitHub 数据集的一个例子。</p><pre class="kr ks kt ku gt mf mg mh mi aw mj bi"><span id="475c" class="mk ld it mg b gy ml mm l mn mo"># Load the dataset from a CSV file<br/>workItems &lt;- <strong class="mg iu">read.csv</strong>('../github-data.csv')</span><span id="9760" class="mk ld it mg b gy mp mm l mn mo"># Show the dataset<br/><strong class="mg iu">show</strong>(workItems)</span></pre><figure class="kr ks kt ku gt kv gh gi paragraph-image"><div role="button" tabindex="0" class="kw kx di ky bf kz"><div class="gh gi mq"><img src="../Images/ba6394545734452f63f9843f3a386270.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*LbAWW3w9z6k6Luk-WPctIQ.png"/></div></div><figcaption class="mr ms gj gh gi mt mu bd b be z dk">Table 1: Sample GitHub dataset</figcaption></figure><p id="f715" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">注意，无论是<em class="ko">小队</em>还是<em class="ko">受让人</em>(即主人)，都是地面真相，在历史资料中给出。这意味着，我们可以把它当作一个分类问题。现在，由于工作项标题是以自由文本的形式给出的，所以可以使用一些自然语言处理技术来获得一些特性。</p><p id="9032" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu">自然语言处理(NLP)基础知识</strong></p><p id="7920" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">让我们介绍一些 NLP 术语:</p><ul class=""><li id="e9bf" class="mv mw it js b jt ju jx jy kb mx kf my kj mz kn na nb nc nd bi translated">我们的数据集(工作条目标题的集合)将被称为<em class="ko">语料库</em>。</li><li id="5d3e" class="mv mw it js b jt ne jx nf kb ng kf nh kj ni kn na nb nc nd bi translated">每个工作项标题都是一个<em class="ko">文档。</em></li><li id="fc7d" class="mv mw it js b jt ne jx nf kb ng kf nh kj ni kn na nb nc nd bi translated">语料库中所有不同单词的集合就是<em class="ko">词典</em>。</li></ul><p id="e006" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">从自由文本中提取特征的一个非常简单的方法是计算<em class="ko">词频</em> (TF)，即计算字典中的每个单词在每个文档中出现的次数。出现的次数越高，这个词的相关性就越强。这产生了一个<em class="ko">文档-术语矩阵(DTM) </em>，每个文档有一行，列数与字典中的单词数一样多。该矩阵的位置【T10(I，j)】表示单词<em class="ko"> j </em>在标题<em class="ko"> i </em>中出现的次数。</p><p id="2d73" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">您可以立即看到，得到的特征集将非常稀疏(即，具有大量零值)，因为字典中可能有数千个单词，但每个文档(即，标题)将只包含几十个单词。</p><p id="c5e8" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">TF 的一个常见问题是诸如“the”、“a”、“in”等词。倾向于非常频繁地出现，然而它们可能并不相关。这就是为什么 TF-IDF 通过将一个单词除以它在整个语料库中的频率函数，从而将该单词在文档中的频率归一化。这样，最相关的单词将是出现在文档中但在整个语料库中不常见的单词。</p><h1 id="adfe" class="lc ld it bd le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz bi translated"><strong class="ak">数据监管</strong></h1><p id="9ab2" class="pw-post-body-paragraph jq jr it js b jt ma jv jw jx mb jz ka kb mc kd ke kf md kh ki kj me kl km kn im bi translated">现在，在应用任何 NLP 技术之前，需要进行一些文本处理。这包括删除停用词(例如，介词、冠词等。)、大小写、标点符号和词干，这是指将词形变化/派生的单词简化为它们的基本或词根形式。下面的代码执行所需的文本预处理:</p><pre class="kr ks kt ku gt mf mg mh mi aw mj bi"><span id="ae7b" class="mk ld it mg b gy ml mm l mn mo">preprocess &lt;- <strong class="mg iu">function</strong>(text) {<br/>    corpus &lt;- VCorpus(VectorSource(tolower(text)))<br/>    corpus &lt;- tm_map(corpus, PlainTextDocument)<br/>    corpus &lt;- tm_map(corpus, removePunctuation)<br/>    corpus &lt;- tm_map(corpus, removeWords, stopwords('english'))<br/>    corpus &lt;- tm_map(corpus, stemDocument)<br/>    data.frame(text=unlist(sapply(corpus, `[`, "content")),<br/>        stringsAsFactors=F)<br/>}</span><span id="9fa1" class="mk ld it mg b gy mp mm l mn mo">curatedText &lt;- preprocess(workItems$TITLE)</span></pre><figure class="kr ks kt ku gt kv gh gi paragraph-image"><div role="button" tabindex="0" class="kw kx di ky bf kz"><div class="gh gi nj"><img src="../Images/19e9ed8335693cb16980e49e72b5c623.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*4_8sGbeXGmE_SbswaRoVPQ.png"/></div></div><figcaption class="mr ms gj gh gi mt mu bd b be z dk">Table 2: Results of text curation after removing stop words, punctuation, and case, as well as stemming the documents.</figcaption></figure><h1 id="b604" class="lc ld it bd le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz bi translated"><strong class="ak">特征提取</strong></h1><p id="26a2" class="pw-post-body-paragraph jq jr it js b jt ma jv jw jx mb jz ka kb mc kd ke kf md kh ki kj me kl km kn im bi translated">以下代码将通过将 TF-IDF 应用于我们的策划文本来创建功能。生成的 DTM 在字典中每个单词都有一列。</p><pre class="kr ks kt ku gt mf mg mh mi aw mj bi"><span id="1d39" class="mk ld it mg b gy ml mm l mn mo"># Create a tokenizer<br/>it &lt;- itoken(curatedText$text, progressbar = <strong class="mg iu">FALSE</strong>)</span><span id="5826" class="mk ld it mg b gy mp mm l mn mo"># Create a vectorizer<br/>v &lt;- create_vocabulary(it)  %&gt;%<br/>    prune_vocabulary(doc_proportion_max = 0.1, term_count_min = 5)</span><span id="acf8" class="mk ld it mg b gy mp mm l mn mo">vectorizer &lt;- vocab_vectorizer(v)</span><span id="de51" class="mk ld it mg b gy mp mm l mn mo"># Create a document term matrix (DTM)<br/>dtmCorpus &lt;- create_dtm(it, vectorizer)<br/>tfidf &lt;- TfIdf$new()<br/>dtm_tfidf &lt;- fit_transform(dtmCorpus, tfidf)<br/>featuresTFIDF &lt;- as.data.frame(as.matrix(dtm_tfidf))</span><span id="6973" class="mk ld it mg b gy mp mm l mn mo"># Add prefix to column names since there could be names starting <br/># with numbers<br/>colnames(featuresTFIDF) &lt;- paste0("word_", colnames(featuresTFIDF))</span><span id="bfe8" class="mk ld it mg b gy mp mm l mn mo"># Append the squad and type to the feature set for classification<br/>featureSet &lt;- cbind(featuresTFIDF, <br/>                    "SQUAD"=workItems$SQUAD, <br/>                    "TYPE"=workItemsCurated$TYPE)</span></pre><figure class="kr ks kt ku gt kv gh gi paragraph-image"><div role="button" tabindex="0" class="kw kx di ky bf kz"><div class="gh gi nk"><img src="../Images/9006a38885fd51ec9784bc3976842a74.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*fwSSgwT-4btn1XCXfRv6mg.png"/></div></div><figcaption class="mr ms gj gh gi mt mu bd b be z dk">Feature set example.</figcaption></figure><p id="3552" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">现在我们有了一个特性集，其中每行是一个工作项，每列是它的 TF-IDF 分数。我们也有工作项目的类型(例如，任务或者缺陷)和基本事实(例如，团队)。</p><h1 id="d2b1" class="lc ld it bd le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz bi translated"><strong class="ak">文本分类</strong></h1><p id="c1a4" class="pw-post-body-paragraph jq jr it js b jt ma jv jw jx mb jz ka kb mc kd ke kf md kh ki kj me kl km kn im bi translated">接下来，我们将为训练集和测试集创建拆分:</p><pre class="kr ks kt ku gt mf mg mh mi aw mj bi"><span id="3bc1" class="mk ld it mg b gy ml mm l mn mo">random &lt;- runif(nrow(featureSet))</span><span id="f968" class="mk ld it mg b gy mp mm l mn mo">train &lt;- featureSet[random &gt; 0.2, ]<br/>trainRaw &lt;- workItemsFiltered[random &gt; 0.2, ]</span><span id="ae86" class="mk ld it mg b gy mp mm l mn mo">test &lt;- featureSet[random &lt; 0.2, ]<br/>testRaw &lt;- workItemsFiltered[random &lt; 0.2, ]</span></pre><p id="65d7" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu">随机森林</strong></p><p id="b3ba" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">r 提供了<em class="ko"> randomForest </em>包，它允许训练一个随机森林分类器，如下所示:</p><pre class="kr ks kt ku gt mf mg mh mi aw mj bi"><span id="d645" class="mk ld it mg b gy ml mm l mn mo"># Train a Random Forest model<br/>&gt; model &lt;- randomForest(SQUAD ~ ., train, ntree = 500)</span><span id="234a" class="mk ld it mg b gy mp mm l mn mo"># Compute predictions<br/>&gt; predictions &lt;- predict(model, test)</span><span id="a1ee" class="mk ld it mg b gy mp mm l mn mo"># Compute overall accuracy<br/>&gt; sum(predictions == test$SQUAD) / length(predictions)<br/>[1] 0.59375</span></pre><p id="b11f" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">音符准确度低于 60%,这在大多数情况下是非常糟糕的。然而，仅仅根据标题来预测一个工作项目应该被分配到哪个组是一项非常具有挑战性的任务，即使对人类来说也是如此。因此，让我们为用户提供两到三个关于给定工作项的最可能团队的建议。</p><p id="3cf5" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">为此，让我们使用由<em class="ko"> randomForest </em>提供的每个单独类的概率。我们需要做的就是对这些概率进行排序，并选择具有最高值的类。下面的代码正是这样做的:</p><pre class="kr ks kt ku gt mf mg mh mi aw mj bi"><span id="9e24" class="mk ld it mg b gy ml mm l mn mo"># A function for ranking numbers<br/>ranks &lt;- function(d) {<br/>            data.frame(t(apply(-d, 1, rank, ties.method='min')))<br/>         }</span><span id="4541" class="mk ld it mg b gy mp mm l mn mo"># Score the Random Forest model and return probabilities<br/>rfProbs &lt;- predict(model, test, type="prob")</span><span id="45d0" class="mk ld it mg b gy mp mm l mn mo"># Compute probability ranks<br/>probRanks &lt;- ranks(rfProbs)</span><span id="8173" class="mk ld it mg b gy mp mm l mn mo">cbind("Title" = testRaw$TITLE, <br/>      probRanks, <br/>      "SQUAD" = testRaw$SQUAD,  <br/>      "PRED" = predictions)</span><span id="0572" class="mk ld it mg b gy mp mm l mn mo">rfSquadsPreds &lt;- as.data.frame(t(apply(probRanks,<br/>                               MARGIN=1, <br/>                               FUN=function(x) <br/>                                       names(head(sort(x,      <br/>                                       decreasing=F), 3)))))</span><span id="708b" class="mk ld it mg b gy mp mm l mn mo"># Compute accuracy of any of the two recommendations to be correct<br/>&gt; sum(rfSquadsPreds$V1 == rfSquadsPreds$SQUAD | <br/>    rfSquadsPreds$V2 == rfSquadsPreds$SQUAD) / nrow(rfSquadsPreds)<br/>[1] 0.76</span><span id="ca6d" class="mk ld it mg b gy mp mm l mn mo"># Compute accuracy of any of the three recommendations to be correct<br/>&gt; sum(rfSquadsPreds$V1 == rfSquadsPreds$SQUAD | <br/>    rfSquadsPreds$V2 == rfSquadsPreds$SQUAD |<br/>    rfSquadsPreds$V3 == rfSquadsPreds$SQUAD) / nrow(rfSquadsPreds)[1] 0.87</span></pre><p id="d093" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">请注意，有两个建议，其中任何一个正确的概率是 76%，而有三个建议，这个概率变成 87%，这使得模型更加有用。</p><p id="4f4e" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu">其他算法</strong></p><p id="8a0a" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">我们还探讨了逻辑回归、XGBoost、Glove 和 RNNs/LSTMs。然而，结果并不比随机森林好多少。</p><p id="c061" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu">特征重要性</strong></p><figure class="kr ks kt ku gt kv gh gi paragraph-image"><div role="button" tabindex="0" class="kw kx di ky bf kz"><div class="gh gi nl"><img src="../Images/24d83e21f953d99db5524f98055e91c9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*CwsscDqpLL8PK8y1Xg_r1Q.png"/></div></div><figcaption class="mr ms gj gh gi mt mu bd b be z dk">Feature importance (Given by XGBoost)</figcaption></figure><h1 id="a4fa" class="lc ld it bd le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz bi translated"><strong class="ak">部署</strong></h1><p id="2406" class="pw-post-body-paragraph jq jr it js b jt ma jv jw jx mb jz ka kb mc kd ke kf md kh ki kj me kl km kn im bi translated">为了将这个模型投入生产，我们首先需要导出(1)模型本身和(2)TF-IDF 转换。前者将用于评分，而后者将提取用于训练的相同特征(即单词)。</p><p id="eded" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu">导出资产</strong></p><pre class="kr ks kt ku gt mf mg mh mi aw mj bi"><span id="0faf" class="mk ld it mg b gy ml mm l mn mo"># Save TF-IDF transformations<br/>saveRDS(vectorizer, "../docker/R/vectorizer.rds")<br/>saveRDS(dtmCorpus,"../docker/R/dtmCorpus_training_data.rds")</span><span id="2c3f" class="mk ld it mg b gy mp mm l mn mo"># Save DTM<br/>saveRDS(model, "squad_prediction_rf.rds")</span></pre><p id="b8c4" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu">码头工和管道工</strong></p><p id="8619" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">Docker 是一个非常有用的工具，可以将我们的资产转化为容器化的应用程序。这将帮助我们在任何地方发布、构建和运行应用程序。</p><p id="f9f0" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">对于大多数软件服务来说，API 端点是消费预测模型的最佳方式。我们探索了像<strong class="js iu"> OpenCPU </strong>和<strong class="js iu"> plumbr </strong>这样的选项。Plumber 看起来更简单，但却非常强大，可以流畅地读取 CSV 文件和运行分析，因此它是我们的选择。</p><p id="c06f" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">Plumber 的代码风格(即使用 decorators)也更加直观，这使得管理端点 URL、HTTP 头和响应有效负载变得更加容易。</p><p id="d9fc" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">docker 文件示例如下:</p><pre class="kr ks kt ku gt mf mg mh mi aw mj bi"><span id="e877" class="mk ld it mg b gy ml mm l mn mo">FROM trestletech/plumber</span><span id="d34b" class="mk ld it mg b gy mp mm l mn mo"># Install required packages<br/>RUN apt-get install -y libxml2-dev</span><span id="73f3" class="mk ld it mg b gy mp mm l mn mo"># Install the randomForest package<br/>RUN R -e ‘install.packages(c(“tm”,”text2vec”,<br/>          ”plotly”,”randomForest”,”SnowballC”))’</span><span id="536c" class="mk ld it mg b gy mp mm l mn mo"># Copy model and scoring script<br/>RUN mkdir /model<br/>WORKDIR /model</span><span id="d440" class="mk ld it mg b gy mp mm l mn mo"># plumb and run server<br/>EXPOSE 8000</span><span id="f4f1" class="mk ld it mg b gy mp mm l mn mo">ENTRYPOINT [“R”, “-e”, \“pr &lt;- <br/>    plumber::plumb(‘/model/squad_prediction_score.R’);         <br/>    pr$run(host=’0.0.0.0', port=8000)”]</span></pre><p id="86ed" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">评分文件<em class="ko"> squad_prediction_score 的一个片段。R </em>如下图:</p><pre class="kr ks kt ku gt mf mg mh mi aw mj bi"><span id="9a73" class="mk ld it mg b gy ml mm l mn mo">x &lt;- c(“tm”,”text2vec”,”plotly”,”randomForest”,”SnowballC”)<br/>lapply(x, require, character.only = TRUE)</span><span id="f108" class="mk ld it mg b gy mp mm l mn mo"># Load tf-idf<br/>vectorizer = readRDS(“/model/vectorizer.rds”)</span><span id="d217" class="mk ld it mg b gy mp mm l mn mo">dtmCorpus_training_data = <br/>readRDS(“/model/dtmCorpus_training_data.rds”)</span><span id="477d" class="mk ld it mg b gy mp mm l mn mo">tfidf = TfIdf$new()</span><span id="a3f4" class="mk ld it mg b gy mp mm l mn mo">tfidf$fit_transform(dtmCorpus_training_data)</span><span id="61bd" class="mk ld it mg b gy mp mm l mn mo"># Load the model<br/>squad_prediction_rf &lt;- readRDS(“/model/squad_prediction_rf.rds”)</span><span id="49aa" class="mk ld it mg b gy mp mm l mn mo">#* @param df data frame of variables<br/>#* @serializer unboxedJSON<br/>#* @post /score<br/>score &lt;- function(req, df) {<br/>    curatedText &lt;- preprocess(df$TITLE)<br/>    df$CURATED_TITLE &lt;- curatedText$text<br/>    featureSet &lt;- feature_extraction(df)<br/>    rfProbs &lt;- predict(squad_prediction_rf, featureSet,type=”prob”)<br/>    probRanks &lt;- ranks(rfProbs)<br/>    rfSquadsPreds &lt;- as.data.frame(t(apply(probRanks, MARGIN=1,  <br/>        FUN=function(x) names(head(sort(x, decreasing=F), 3)))))</span><span id="7654" class="mk ld it mg b gy mp mm l mn mo">    result &lt;- list(“1” = rfSquadsPreds$V1, <br/>                   “2” = rfSquadsPreds$V2, <br/>                   “3” = rfSquadsPreds$V3)<br/>    result<br/>}</span><span id="4257" class="mk ld it mg b gy mp mm l mn mo">#* @param df data frame of variables<br/>#* @post /train<br/>train &lt;- function(req, df) {<br/>    ...<br/>}</span><span id="1b9a" class="mk ld it mg b gy mp mm l mn mo">preprocess &lt;- function(text) {<br/>    ...<br/>}</span><span id="c7aa" class="mk ld it mg b gy mp mm l mn mo">feature_extraction &lt;- function(df) {<br/>    ...<br/>}</span></pre><p id="f1a6" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">现在，要针对您自己的存储库运行该模型，您只需要构建您自己的 docker 映像并点击端点:</p><pre class="kr ks kt ku gt mf mg mh mi aw mj bi"><span id="c168" class="mk ld it mg b gy ml mm l mn mo">docker build -t squad_pred_image .<br/>docker run — rm -p 8000:8000 squad_pred_image</span></pre><p id="eb18" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">一旦 docker 映像准备就绪，示例 API 调用将如下所示:</p><pre class="kr ks kt ku gt mf mg mh mi aw mj bi"><span id="3f0d" class="mk ld it mg b gy ml mm l mn mo">curl -X POST \<br/>    <a class="ae kp" href="http://localhost:8000/score" rel="noopener ugc nofollow" target="_blank">http://localhost:8000/score</a> \<br/>    -H ‘Content-Type: application/json’ \<br/>    -H ‘cache-control: no-cache’ \<br/>    -d ‘{<br/>        “df”: [{<br/>            “ID”: “4808”,<br/>            “TITLE”: “Data virtualization keeps running out of <br/>             memory”,<br/>            “TYPE”: “type: Defect”<br/>        }]<br/>    }’</span></pre><p id="211b" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">API 调用输出示例如下:</p><pre class="kr ks kt ku gt mf mg mh mi aw mj bi"><span id="1d26" class="mk ld it mg b gy ml mm l mn mo">{<br/>    “1”: “squad.core”,<br/>    “2”: “squad.performance”,<br/>    “3”: “squad.dv”<br/>}</span></pre><h1 id="6e20" class="lc ld it bd le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz bi translated"><strong class="ak">自己试试</strong></h1><p id="3970" class="pw-post-body-paragraph jq jr it js b jt ma jv jw jx mb jz ka kb mc kd ke kf md kh ki kj me kl km kn im bi translated">您是否希望使用 GitHub 帮助您的开发组织提高工作效率？用你自己的数据集试试我们的代码。让我们知道你的结果。</p></div><div class="ab cl nm nn hx no" role="separator"><span class="np bw bk nq nr ns"/><span class="np bw bk nq nr ns"/><span class="np bw bk nq nr"/></div><div class="im in io ip iq"><h1 id="6e74" class="lc ld it bd le lf nt lh li lj nu ll lm ln nv lp lq lr nw lt lu lv nx lx ly lz bi translated"><strong class="ak">关于作者</strong></h1><blockquote class="ny nz oa"><p id="4838" class="jq jr ko js b jt ju jv jw jx jy jz ka ob kc kd ke oc kg kh ki od kk kl km kn im bi translated">scar D. Lara Yejas 是高级数据科学家，也是 IBM 机器学习中心的创始人之一。他与世界上一些最大的企业密切合作，将 ML 应用于他们的特定用例，包括医疗保健、金融、制造、政府和零售。他还为 IBM 大数据产品组合做出了贡献，特别是在大规模机器学习领域，是 Apache Spark 和 Apache SystemML 的贡献者。</p><p id="00fb" class="jq jr ko js b jt ju jv jw jx jy jz ka ob kc kd ke oc kg kh ki od kk kl km kn im bi translated">scar 拥有南佛罗里达大学的计算机科学和工程博士学位。他是《人类活动识别:使用可穿戴传感器和智能手机》一书的作者，并发表了大量关于大数据、机器学习、以人为中心的传感和组合优化的研究/技术论文。</p><p id="a657" class="jq jr ko js b jt ju jv jw jx jy jz ka ob kc kd ke oc kg kh ki od kk kl km kn im bi translated"><strong class="js iu"> Ankit Jha </strong>是一名从事 IBM Cloud Private For Data platform 的数据科学家。他也是平台的可维护性团队的一员，使用 ML 技术进行日志收集和分析。Ankit 是一位经验丰富的软件专业人士，他还拥有辛辛那提大学的分析硕士学位。</p></blockquote></div></div>    
</body>
</html>