<html>
<head>
<title>An Intuitive Explanation of EmbedS</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">嵌入的直观解释</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/an-intuitive-explanation-of-embeds-558844e4798?source=collection_archive---------35-----------------------#2019-11-13">https://towardsdatascience.com/an-intuitive-explanation-of-embeds-558844e4798?source=collection_archive---------35-----------------------#2019-11-13</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="4691" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">大多数 GDL 技术忽略了网络的语义。嵌入也旨在表示语义关系。</h2></div><h1 id="9848" class="ki kj it bd kk kl km kn ko kp kq kr ks jz kt ka ku kc kv kd kw kf kx kg ky kz bi translated">介绍</h1><p id="6338" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">在前面的故事中，我们讨论了几种从不同角度解决节点表示问题的 GDL 技术。我们从名为 DeepWalk 的直推式方法开始，接着是 GraphSAGE 归纳方法。在上一篇文章中，我们讨论了 NeoDTI 从异构图中学习特定于任务的节点嵌入。你可以在下面找到这个故事。</p><div class="lw lx gp gr ly lz"><a rel="noopener follow" target="_blank" href="/an-intuitive-explanation-of-neodti-e1859d178031"><div class="ma ab fo"><div class="mb ab mc cl cj md"><h2 class="bd iu gy z fp me fr fs mf fu fw is bi translated">NeoDTI 的直观解释</h2><div class="mg l"><h3 class="bd b gy z fp me fr fs mf fu fw dk translated">NeoDTI 是一种用于异构网络上链路预测的特定任务节点嵌入学习算法。</h3></div><div class="mh l"><p class="bd b dl z fp me fr fs mf fu fw dk translated">towardsdatascience.com</p></div></div><div class="mi l"><div class="mj l mk ml mm mi mn mo lz"/></div></div></a></div><p id="69ea" class="pw-post-body-paragraph la lb it lc b ld mp ju lf lg mq jx li lj mr ll lm ln ms lp lq lr mt lt lu lv im bi translated">在这个故事中，我们将用嵌入[1]来结束 GDL 方法系列。嵌入目标是大多数 GDL 模型的常见缺陷。虽然现有方法可以有效地反映节点嵌入中基于邻域的相似性，但它们不足以嵌入更高级别的语义，如子类(人是人的子类)关系。这种语义在 DBPedia 和 FreeBase 等知识图(KG)中很常见，应该与节点嵌入一起表示。</p><p id="c6b3" class="pw-post-body-paragraph la lb it lc b ld mp ju lf lg mq jx li lj mr ll lm ln ms lp lq lr mt lt lu lv im bi translated">KG 不同于我们到目前为止分析过的网络，它包含了语义上更丰富的信息。除了这些类的成员之外，kg 通常还包含类、层次结构及其交互。例如，一个包含人物和电视连续剧的 KG 将包括人物和电视连续剧的分类，而我们到目前为止看到的网络仅代表这些类的成员之间的交互。下面我们可以看到这样一个 KG。</p><figure class="mv mw mx my gt mz gh gi paragraph-image"><div role="button" tabindex="0" class="na nb di nc bf nd"><div class="gh gi mu"><img src="../Images/17f803cf8212072d42a17be43bcc6e11.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*akVIGPr13-RtcR3Z4Cse9A.png"/></div></div><figcaption class="nf ng gj gh gi nh ni bd b be z dk">A KG to represent interactions between people and TV Series</figcaption></figure><p id="945b" class="pw-post-body-paragraph la lb it lc b ld mp ju lf lg mq jx li lj mr ll lm ln ms lp lq lr mt lt lu lv im bi translated">在显示的 KG 中，实线表示<em class="nj">主演的</em>一个人和电视剧之间的关系，而虚线表示<em class="nj">可以出演</em>一个阶层间的关系。我们总是可以添加更多的关系类型，比如<em class="nj"> canWatch，可以在这两个类之间创建</em>或者引入新的类，比如<em class="nj"> Movies。如果我们使用了 HN，我们将只有成员之间的链接，没有类层次，没有类间的交互。</em></p><p id="976f" class="pw-post-body-paragraph la lb it lc b ld mp ju lf lg mq jx li lj mr ll lm ln ms lp lq lr mt lt lu lv im bi translated">请注意，虽然 kg 看起来像 HNs，但我们不能在 HN 中表示职业等级。一个 KG 类就像一个<em class="nj">超节点</em>包含一组节点并与其他类交互，而不是一个简单的节点与不同类型的节点交互。以这种方式，kg 是具有丰富语义的非常强大和可扩展的表示方案。KGs 中丰富的语义不能用常规的 HN 嵌入技术(如 NeoDTI)有效地嵌入到空间中。嵌入目标就是这个问题。</p><h1 id="d292" class="ki kj it bd kk kl km kn ko kp kq kr ks jz kt ka ku kc kv kd kw kf kx kg ky kz bi translated">使...嵌入</h1><p id="2364" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">EmbedS 是作为一种<em class="nj">本体感知的</em>图嵌入方法提出的，旨在以几何方式表示高级语义。嵌入了 RDFS 格式的作品，这是一种在网络中表示语义的标记方案。为了这个研究的目的，他们定义了五个谓词(或关系)作为<em class="nj">类型、子类、子属性、域</em>和<em class="nj">范围。</em>目标是学习属性表示，以及类和节点表示。</p><p id="dc6e" class="pw-post-body-paragraph la lb it lc b ld mp ju lf lg mq jx li lj mr ll lm ln ms lp lq lr mt lt lu lv im bi translated">为了表示节点，他们随机创建 N 维向量，并在优化过程中更新它们，与之前的工作类似。另一方面，它们定义<em class="nj">区域</em>来通过一个<em class="nj"> N </em>维向量和一个半径<em class="nj"> r </em>来表示类。属性也用区域表示，其中中心用两个<em class="nj"> N </em>维向量和一个半径<em class="nj"> r </em>表示。类似于节点向量，类和属性中心及其半径在优化期间被更新。因此，财产和阶级区域随着时间的推移而扩大和缩小。</p><p id="e80a" class="pw-post-body-paragraph la lb it lc b ld mp ju lf lg mq jx li lj mr ll lm ln ms lp lq lr mt lt lu lv im bi translated">现在我们将解释将用于更新模型参数的损失函数背后的直觉。EmbedS 使用一个两部分损失函数，将它们相加以获得总损失。第一部分被定义为反映节点之间的邻域信息。换句话说，当两个节点的嵌入可用于恢复这些节点之间的交互(或链路、边)时，第一部分被最小化，类似于 NeoDTI 方法。</p><p id="7caf" class="pw-post-body-paragraph la lb it lc b ld mp ju lf lg mq jx li lj mr ll lm ln ms lp lq lr mt lt lu lv im bi translated">在损失函数的第二部分，目标是保持由上面列出的五个谓词定义的关系。嵌入基于谓词本身、类和节点将成本与每个谓词类型相关联。因为节点是点，而类和属性是区域，所以我们有两种不同的丢失情况。我们可以计算一个点和一个区域之间或者两个区域之间的损耗。</p><p id="6231" class="pw-post-body-paragraph la lb it lc b ld mp ju lf lg mq jx li lj mr ll lm ln ms lp lq lr mt lt lu lv im bi translated">为了计算点和区域之间的损失，我们计算节点和区域中心之间的 L2 距离，然后减去区域的半径。为了计算区域到区域的成本，我们计算中心之间的 L2 距离，然后减去半径之和。下面我们可以看到一个图，显示了节点和类之间的开销，其中开销用红线显示。</p><figure class="mv mw mx my gt mz gh gi paragraph-image"><div class="gh gi nk"><img src="../Images/40c7da9e8752f761803b7d581af38b02.png" data-original-src="https://miro.medium.com/v2/resize:fit:792/format:webp/1*-9b7o4CVxqdakvqRXdSGuQ.png"/></div><figcaption class="nf ng gj gh gi nh ni bd b be z dk">Cost computation from between an entity and a class. [1]</figcaption></figure><p id="00d8" class="pw-post-body-paragraph la lb it lc b ld mp ju lf lg mq jx li lj mr ll lm ln ms lp lq lr mt lt lu lv im bi translated">为了最小化这样的损失函数，必须调整参数以满足谓词，而不仅仅是邻域关系。在优化过程中，每个类和谓词的半径将被更新，以最小化损失和中心。例如，我们期望的结果是，如果类<em class="nj"> x </em>是类<em class="nj"> y </em>的<em class="nj">子类</em>，那么<em class="nj"> x </em>的区域在<em class="nj">y</em>的区域内。因此，类的层次结构反映在几何空间中。这同样适用于其他谓词。</p><blockquote class="nl"><p id="2204" class="nm nn it bd no np nq nr ns nt nu lv dk translated">因此，高层语义反映在空间和嵌入是本体感知的。</p></blockquote><h1 id="2102" class="ki kj it bd kk kl km kn ko kp kq kr ks jz nv ka ku kc nw kd kw kf nx kg ky kz bi translated">结论</h1><p id="895d" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">嵌入是在网络中表示更丰富的语义的一个步骤，这是大多数 GDL 技术所缺少的。用区域来表示类和谓词，而不是空间中的点，这是一种可以进一步研究的新方法。然而，定义的损失函数需要特定于谓词的工程，这对于大型网络来说可能难以实现。此外，EmbedS 目前还没有经过广泛的测试，其跨任务的性能也值得怀疑。</p><h2 id="c824" class="ny kj it bd kk nz oa dn ko ob oc dp ks lj od oe ku ln of og kw lr oh oi ky oj bi translated">参考</h2><p id="3743" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">[1] <a class="ae ok" href="https://expolab.org/papers/embeds.pdf" rel="noopener ugc nofollow" target="_blank">嵌入纸张。</a></p></div></div>    
</body>
</html>