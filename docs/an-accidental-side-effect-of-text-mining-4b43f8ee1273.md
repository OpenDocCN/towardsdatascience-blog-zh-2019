# æ–‡æœ¬æŒ–æ˜çš„æ„å¤–å‰¯ä½œç”¨

> åŸæ–‡ï¼š<https://towardsdatascience.com/an-accidental-side-effect-of-text-mining-4b43f8ee1273?source=collection_archive---------25----------------------->

![](img/349f0355d83452bfc34a13cf88fe9051.png)

## æ–‡æœ¬æŒ–æ˜çœŸçš„æœ‰ç”¨å—ï¼Ÿç¬¬ä¸€æ‰‹æµ‹è¯•ã€‚

> â€œæˆ‘ä»¬æ¢ç´¢çš„ç»ˆç‚¹å°†æ˜¯åˆ°è¾¾æˆ‘ä»¬å¼€å§‹çš„åœ°æ–¹ï¼Œå¹¶ç¬¬ä¸€æ¬¡äº†è§£è¿™ä¸ªåœ°æ–¹ã€‚â€
> 
> â€”tÂ·sÂ·è‰¾ç•¥ç‰¹

æˆ‘æœ€è¿‘è¯»äº†å¾ˆå¤šå…³äºç”Ÿäº§åŠ›å’Œè‡ªæˆ‘å‘å±•çš„ä¹¦ï¼Œç»å¸¸ä¼šå‘ç°ä¸€äº›æˆ‘æƒ³ä»¥åå†è¯»çš„å»ºè®®ã€‚kindle ä¸Šçš„é«˜äº®é€‰é¡¹ä½¿è¿™å˜å¾—éå¸¸å®¹æ˜“ã€‚é€šè¿‡æŒç»­é˜…è¯»å’Œå¼ºè°ƒï¼Œæˆ‘ç§¯ç´¯äº†å¤§é‡çš„æ–‡æœ¬ï¼Œè¿™äº›æ–‡æœ¬å¾ˆå¥½åœ°ä»£è¡¨äº†æˆ‘è¯»è¿‡çš„ä¹¦ã€‚

å› ä¸ºæˆ‘å¯¹å†…å®¹éå¸¸äº†è§£ã€‚æˆ‘æƒ³å¯¹è¿™äº›æ•°æ®åº”ç”¨**æ–‡æœ¬æŒ–æ˜**å’Œ**æƒ…æ„Ÿåˆ†æ**ï¼Œè¿™æ ·æˆ‘å°±å¯ä»¥å°†ç»“æœä¸æˆ‘å¯¹ä¹¦ç±çš„çœŸå®çœ‹æ³•è¿›è¡Œæ¯”è¾ƒã€‚å¦‚æœå®ƒä»¬åŒ¹é…ï¼Œæˆ‘ä¼šæ›´æœ‰ä¿¡å¿ƒå°†å…¶åº”ç”¨äºæˆ‘çš„ä¸‹ä¸€ä¸ªä¸šåŠ¡é—®é¢˜ã€‚

åœ¨æŸç§ç¨‹åº¦ä¸Šï¼Œè¿™ä¹Ÿæ˜¯ä¸€æ¬¡è‡ªæˆ‘æ¢ç´¢ï¼Œå› ä¸ºæˆ‘å¯ä»¥å›ç­”ä¸€äº›é—®é¢˜ï¼Œæ¯”å¦‚æˆ‘æ›´å–œæ¬¢ä»€ä¹ˆæ ·çš„å†…å®¹ï¼Œä»–ä»¬çš„æƒ…æ„Ÿè¯‰æ±‚æ˜¯ä»€ä¹ˆï¼Ÿ

**è®©æˆ‘ä»¬æ¥å¯»æ‰¾ç­”æ¡ˆã€‚**

å®¢è§‚çš„è¯´ï¼Œæˆ‘ä¼šåˆ›é€ ä¸€ä¸ªç‹¬ç«‹çš„è§’è‰²ï¼Œå«åšâ€œè™è â€ã€‚ä»–çš„ä¸‹ä¸€ä¸ªä»»åŠ¡æ˜¯é»‘è¿›æˆ‘çš„æ•°æ®å¹¶åˆ†æå®ƒï¼Œä¸ºå–ç»™æˆ‘æ›´å¤šçš„ä¹¦æ”¶é›†è§è§£ã€‚å¯æƒœè¯»ä¹¦ä¸æ˜¯ä»–çš„ç‰¹é•¿ã€‚

ä»–è¿›æ¥æ—¶ï¼Œæˆ¿é—´é‡Œä¹±ä¸ƒå…«ç³Ÿã€‚å½“ä»–æŠŠ USB é©±åŠ¨å™¨æ’åœ¨ç¬”è®°æœ¬ç”µè„‘ä¸Šæ—¶ï¼Œä»–å‡ ä¹å¬ä¸åˆ°è¿˜å¼€ç€çš„æ”¶éŸ³æœºã€‚è®°è€…:

> ä»æˆ‘ä»¬ä¸€å¤§æ—©æ‰“å¼€æ‰‹æœºå¤„ç† Whatsapp æˆ–è„¸ä¹¦ä¿¡æ¯æˆ–æ¨æ–‡å½¢å¼çš„å¤§é‡ä¿¡æ¯çš„é‚£ä¸€åˆ»èµ·ï¼Œç›´åˆ°æˆ‘ä»¬åœ¨æ™šä¸Šç¡è§‰æ—¶é‡å†™æˆ–é˜…è¯»äº§å“è¯„è®ºï¼Œæˆ‘ä»¬åœ¨äº’è”ç½‘ä¸Šç•™ä¸‹äº†é¢åŒ…å±‘ç»™è‡ªå·±çš„ä¸ªäººå£å‘³ã€‚
> 
> è®¸å¤šä¼ä¸šä½¿ç”¨è¿™ç§éç»“æ„åŒ–æ•°æ®ï¼Œé€šè¿‡æœ‰é’ˆå¯¹æ€§çš„äº§å“æ¨èè¿›è¡Œæ›´å¥½çš„è¥é”€æ¥æ¨åŠ¨é”€å”®ï¼Œæˆ–è€…éš”ç¦»ä»–ä»¬çš„å®¢æˆ·â€¦

çœ‹åˆ° 28 æœ¬ä¹¦ 21000 è¡Œæ–‡å­—çš„æ•°æ®ï¼Œä»–å’¬ç´§ç‰™å…³ã€‚ä»–çš„ç¬¬ä¸€æ¬¡æ¥è§¦æ˜¯å¡ç½—å°”Â·å¾·éŸ¦å…‹çš„ä¹¦[â€œå¿ƒæ€â€](https://www.amazon.com/Mindset-Psychology-Carol-S-Dweck/dp/0345472322)ï¼Œä¹¦ä¸­å¥¹ä»‹ç»äº† [**æˆé•¿å¿ƒæ€**çš„æ¦‚å¿µã€‚èƒŒåçš„æƒ³æ³•æ˜¯ï¼Œæœ‰æˆé•¿å¿ƒæ€çš„äººç›¸ä¿¡ä»–ä»¬çš„èƒ½åŠ›å¯ä»¥é€šè¿‡åŠªåŠ›æ¥æé«˜ï¼Œè€Œæœ‰å›ºå®šå¿ƒæ€çš„äººç›¸ä¿¡ä»–ä»¬çš„èƒ½åŠ›åœ¨å‡ºç”Ÿæ—¶å°±å›ºå®šäº†ã€‚ç»“æœï¼Œæœ‰å›ºå®šæ€ç»´æ¨¡å¼çš„äººé”™è¿‡äº†åœ¨è®¸å¤šäº‹æƒ…ä¸Šåšå¾—æ›´å¥½çš„æœºä¼šï¼Œå°½ç®¡ä»–ä»¬å¯ä»¥åšåˆ°ã€‚å¾ˆç®€å•ï¼Œå› ä¸ºä»–ä»¬ä¸€å¼€å§‹å°±ä¸ç›¸ä¿¡ã€‚](https://www.mindsetworks.com/science/)

å¦‚æœä½ å¯¹è¿™ä¸ªæ¦‚å¿µä¸ç†Ÿæ‚‰ï¼Œè¿™é‡Œæœ‰ä¸€æ®µå¡ç½—å°”Â·å¾·éŸ¦å…‹çš„è§†é¢‘ï¼Œè§£é‡Šå¥¹å¯¹æˆé•¿å¿ƒæ€çš„ç ”ç©¶ã€‚

Carol Dweck explaining her research on growth mindset.

é•¿é•¿çš„æ–‡å­—è®©ä»–ç–²æƒ«ä¸å ªï¼Œä»–æ²¡æœ‰æ„è¯†åˆ°æ—¶é—´æ˜¯å¦‚ä½•æµé€çš„ã€‚ç°åœ¨ï¼Œä»–æ˜¯ä¸€ä¸ªæˆé•¿ä¸­çš„äººã€‚ä»–å†³å®šå­¦ä¹ æ–‡æœ¬æŒ–æ˜ã€‚

ä»–å¼€å§‹å­¦ä¹ ç”¨äºæ–‡æœ¬æŒ–æ˜çš„ R åŒ…ï¼Œä»–ä¸å–œæ¬¢è¿™ä¸ªåŒ…çš„åå­— [tidytext](https://www.tidytextmining.com/) ï¼Œä½†æ˜¯ä»–æ­£åœ¨ç¨å¾®å¤±å»ä»–çš„åè§ã€‚è¿™æ˜¯ä¸€ä¸ªæ¼«é•¿çš„å¤œæ™šã€‚å¤ªé˜³æ…¢æ…¢å‡èµ·æ—¶ï¼Œä»–è¶´åœ¨æ¡Œå­ä¸Šç¡ç€äº†ã€‚

å®ƒç…§äº®äº†æˆ‘çš„åèŠ±å›­ï¼Œåœ¨é‚£é‡Œæˆ‘å¯ä»¥ä¸æ—¶åœ°ç¥ä¸€çœ¼è¢«ä¸€å¤œâ›„ï¸.çš„é›ªæ¶‚æˆçš„æ ‘æˆ‘ä¸çŸ¥é“é•‡ä¸Šçš„å¦ä¸€ä¸ªåœ°æ–¹å‘ç”Ÿäº†ä»€ä¹ˆï¼Œæˆ‘ç»§ç»­é˜…è¯»ï¼Œä¸€è¾¹å–ç€çº¢é…’ä¸€è¾¹ç‚¹ç€æˆ‘çš„ kindleğŸ·ã€‚

æˆ‘ä»¬ç¨åä¼šçŸ¥é“æˆ‘ä»¬çš„é»‘å®¢å‘ç”Ÿäº†ä»€ä¹ˆã€‚é¦–å…ˆï¼Œæˆ‘ä»¬ä¸€èµ·å»ç¿»ç¿»ä»–çš„ç¬”è®°æœ¬ã€‚

**é»‘å®¢ç¬”è®°**

è¿™æ˜¯å¯¼å‡ºçš„ kindle highlights çš„æ ·å­ã€‚

![](img/3c0355471333b87ee106f93204c0b536.png)

**è¯»å–å¹¶è§£ææ–‡æœ¬æ–‡ä»¶**

```
# Use readLines function to parse the text filehighlights <- readLines("Kindle_highlights_Serdar.Rmd", encoding = "UTF-8")# Create a dataframe where each row is a line from the textdf <- data.frame(highlights)# Packages
library(tidyverse)   
*# includes* ***ggplot2****,* ***dplyr****, tidyr, readr, purrr,* ***tibble****,* ***stringr****, forcats*library(tidytext)
library(wordcloud2)
```

æ¯ä¸ªæ•°æ®ç§‘å­¦é¡¹ç›®éƒ½éœ€è¦æŸç§æ•°æ®å‡†å¤‡ã€‚**åœç”¨è¯**é€šå¸¸æ˜¯è¯­è¨€ä¸­æœ€å¸¸è§çš„è¯ï¼Œé€šå¸¸åœ¨å¤„ç†æ–‡æœ¬æ•°æ®ä¹‹å‰è¢«è¿‡æ»¤æ‰ã€‚

è®©æˆ‘ä»¬çœ‹çœ‹ tidytext åŒ…ä¸­çš„ **stop_words** æ•°æ®é›†ã€‚å› ä¸ºè¿™æ˜¯ä¸€ä¸ªå¾ˆé•¿çš„å•è¯åˆ—è¡¨(> 1K) **æˆ‘å°†æ‰“å°æ¯ç¬¬äº”ä¸ªå•è¯ä½œä¸ºä¾‹å­ã€‚**

```
**data(stop_words)**# print every 50th word stop_words_small <- **stop_words[seq(1, nrow(stop_words), 50),]**stop_words_small %>% print(n=50)# A tibble: 23 x 2
   word       lexicon 
   <chr>      <chr>   
 1 a          SMART   
 2 at         SMART   
 3 contain    SMART   
 4 few        SMART   
 5 hers       SMART   
 6 last       SMART   
 7 nine       SMART   
 8 presumably SMART   
 9 some       SMART   
10 they'd     SMART   
11 very       SMART   
12 without    SMART   
13 what       snowball
14 they'll    snowball
15 during     snowball
16 again      onix    
17 but        onix    
18 finds      onix    
19 if         onix    
20 much       onix    
21 parted     onix    
22 since      onix    
23 under      onix
```

**ä»”ç»†è§‚å¯Ÿå¯ä»¥å‘ç°ï¼Œåœç”¨è¯ä½¿ç”¨å•å¼•å·ï¼Œè€Œåœ¨æ–‡æœ¬æ•°æ®ä¸­ä½¿ç”¨æ’‡å·(')ã€‚**

```
e.g. **they'll** in stop_words
```

ä»¥åŠå•è¯**ä»–ä»¬å°†**å¦‚ä½•å‡ºç°åœ¨æ–‡æœ¬ä¸­:

> é»„è‰²é«˜äº®| Page: 200
> è®°å¿†éšç€æˆ‘ä»¬ä»ä¸­è·å¾—çš„æ„ä¹‰ä¸æ–­è¢«ä¿®æ­£ï¼Œå› æ­¤åœ¨æœªæ¥**å®ƒä»¬ä¼š**æ›´åŠ æœ‰ç”¨ã€‚

æˆ‘ä»¬å¿…é¡»ä½¿åœç”¨è¯å’Œæˆ‘ä»¬çš„æ•°æ®å…¼å®¹ï¼Œå¦åˆ™ä¸€äº›è¯å¦‚**ä»–ä»¬ä¼šï¼Œä¸ä¼šï¼Œä¸èƒ½å¯èƒ½å‡ºç°åœ¨æˆ‘ä»¬çš„ç»“æœä¸­ã€‚**

æˆ‘ä»¬å¯ä»¥ä½¿ç”¨ stringr åŒ…ä¸­çš„ **str_replace_all()** å‡½æ•°ï¼Œæ‰¾å‡ºæ‰€æœ‰çš„æ’‡å·ï¼Œè½¬æ¢æˆå•å¼•å·ã€‚

![](img/0ee70253d22ff3002fb1c1c2c3bf7b49.png)

ç°åœ¨ï¼Œæ–‡æœ¬å·²ç»å‡†å¤‡å¥½è¿›è¡Œé¢‘ç‡åˆ†æäº†ã€‚æ–‡æœ¬æŒ–æ˜é¡¹ç›®ä¸­çš„å•è¯ç§°ä¸º**è®°å·ã€‚**æˆ‘ä»¬å¯ä»¥é€šè¿‡ tidytext åŒ…ä¸­çš„ **unnest_tokens()** å‡½æ•°å°†æ–‡æœ¬æ‹†åˆ†æˆå•ä¸ªå•è¯ï¼Œè¿‡æ»¤ **stop_words** å¹¶è®¡æ•°ã€‚

```
df$highlights <- str_replace_all(df$highlights, "â€™", "'")df <- df %>% unnest_tokens(word, highlights) %>%
             anti_join(stop_words) %>% 
             filter(!word %in% c("highlights","highlight", "page", 
                      "location", "yellow", "pink", "orange", "blue"))
```

ä»–è¿˜åœ¨è¿™é‡Œæ·»åŠ äº†ä¸€äº›ç»å¸¸å‡ºç°åœ¨ kindle highlights è¾“å‡ºä¸­çš„é¢å¤–å•è¯ã€‚

Dplyr()åŒ…å‡½æ•°å¯¹äºå¯¹æ•°æ®æ¡†ä¸­çš„å•è¯è¿›è¡Œåˆ†ç»„å’Œè®¡æ•°éå¸¸æœ‰ç”¨ã€‚

```
**top_kindle_highlights** <- df %>% 
 group_by(word) %>% 
 count() %>% 
 arrange(desc(n))
```

ä»–è®°ä¸‹äº†ä»–çš„ç¬¬ä¸€ä¸ªè§è§£ã€‚**æˆ‘çš„ kindle æœ€å¸¸ç”¨çš„ 10 ä¸ªå•è¯ã€‚**

```
**people** 592   
**story**  340   
life   318   
time   309   
**mind **  213   
**change** 212   
feel   211   
world  171   
person 170   
**habits** 157 
```

å¦‚æœä½ ä¸å–œæ¬¢çœ‹ä¸€é•¿ä¸²å•è¯**çš„è¯ï¼Œå•è¯äº‘**å’Œ**T3 éƒ½æ˜¯ä¸é”™çš„é€‰æ‹©ã€‚Wordcloud2 åŒ…ä¸ºä½ çš„ Wordcloud æä¾›äº†é¢å¤–çš„å®šåˆ¶é€‰é¡¹ï¼Œä¾‹å¦‚ä½ å¯ä»¥ä½¿ç”¨ä»»ä½•å›¾åƒä½œä¸ºæ ‡è®°ã€‚**

![](img/48cf04c91d03cde3c72aa8b42ed54006.png)

ä¸Šé¢çš„å•è¯äº‘ä»£ç æ˜¯:

```
**wordcloud2**(top_kindle_highlights, figPath = bat, size = 1, backgroundColor = "white", color = color_vector(data$freq) )
```

ä¸€äº›æƒ³æ³•å¼€å§‹å‡ºç°åœ¨ä»–çš„è„‘æµ·é‡Œã€‚ä»–è®¤ä¸ºåšå‡ºè¿™äº›äº®ç‚¹çš„äººæ˜¯å¯¹è®²æ•…äº‹ã€å†™ä½œå’Œè‰¯å¥½çš„æ²Ÿé€šæ„Ÿå…´è¶£çš„äººï¼Œæ˜¯æœ‰è‰¯å¥½ä¹ æƒ¯çš„äººã€‚æƒ³ä»¥ç§¯æçš„æ–¹å¼å½±å“è‡ªå·±ç”Ÿæ´»çš„äººã€‚**ä»–å¯¹ä¹¦ç±è¶Šæ¥è¶Šæ„Ÿå…´è¶£ã€‚ä»–æƒ³æ·±å…¥æŒ–æ˜ã€‚**

**äºŒå…ƒæ¨¡å‹åˆ†æ**

å•è¯æ˜¯ä¹¦ç±å†…å®¹çš„ä¸€ä¸ªå¾ˆå¥½çš„èµ·ç‚¹ã€‚**ä½†æ˜¯æ²¡æœ‰ä¸Šä¸‹æ–‡ï¼Œå®ƒä»¬å°±å—åˆ°é™åˆ¶ã€‚**è¿˜å¯ä»¥æ‰§è¡Œé¢‘ç‡åˆ†ææ¥æµ‹é‡å•è¯å¯¹**(äºŒå…ƒæ¨¡å‹)**åœ¨æ–‡æœ¬ä¸­å‡ºç°çš„é¢‘ç‡ã€‚è¿™ä½¿æˆ‘ä»¬èƒ½å¤Ÿæ•æ‰åˆ°æ–‡æœ¬ä¸­æ›´ç»†å¾®çš„ç»†èŠ‚ã€‚

ä¸ºæ­¤ï¼Œä»–å°†ä¸Šé¢éš”ç¦»çš„æœªåµŒå¥—çš„å•ä¸ªæ ‡è®°ç»„åˆå›ä¸€ä¸ªè¿ç»­æ–‡æœ¬ï¼Œç„¶åæ‰§è¡ŒäºŒå…ƒè¯­æ³•åˆ†æã€‚æ‚¨å¯ä»¥ä½¿ç”¨ stringr åŒ…ä¸­çš„ **str_c()** å‡½æ•°æ¥è¿æ¥å•ä¸ªå•è¯ã€‚

```
df_com <- **str_c**(df$word, â€œ â€œ) 
df_com <- data.frame(df_com)
```

è®©æˆ‘ä»¬å°†æ–‡æœ¬æ‹†åˆ†æˆäºŒå…ƒæ¨¡å‹ï¼Œå¹¶æ‰¾å‡ºæœ€å¸¸è§çš„ã€‚

```
df_bigram <- df_com %>% 
 **unnest_tokens**(bigram, df_com, token = â€œngramsâ€, 
 n = 3, n_min = 2)**top_bigrams** <- df_bigram %>% 
 group_by(bigram) %>% 
 count() %>% 
 arrange(desc(n))%>% 
 print(n=20)
```

å¹¶å°†å®ƒä»¬å¯è§†åŒ–åœ¨å›¾ä¸Š

```
top <- top_bigrams[1:25,]

top %>% ungroup() %>% mutate(bigram = fct_reorder(bigram, n)) %>% 
 ggplot(aes(x=bigram, y=n)) + 
 geom_col() + 
 coord_flip() +
 theme_classic() + 
 theme(legend.position = â€œnoneâ€,
 text = element_text(size=18)) 
```

![](img/ea57c7de08a3cb69ebcaee7632c143ac.png)

æˆ‘å‘ç°æœ€å¸¸è§çš„äºŒå…ƒæ¨¡å‹ä¹‹ä¸€æ˜¯**è¡Œä¸ºå˜åŒ–ã€‚æˆ‘ä»¬å¯ä»¥åˆ©ç”¨è¿™äº›ä¿¡æ¯æ¥ç†è§£æˆ‘ä»¬ä¹‹å‰çš„å‘ç°ã€‚ä¾‹å¦‚ï¼Œä¸€ä¸ªæœ€å¸¸è§çš„è¯æ˜¯å˜åŒ–ã€‚æˆ‘ä»¬ä»äºŒå…ƒæ¨¡å‹åˆ†æä¸­çœ‹åˆ°,â€œæ”¹å˜â€è¿™ä¸ªè¯ä¸»è¦ç”¨åœ¨è¡Œä¸ºæ”¹å˜çš„ä¸Šä¸‹æ–‡ä¸­ã€‚**æ‰€ä»¥äºŒå…ƒæ¨¡å‹æ˜¯è·å¾—å…³äºæ–‡æœ¬å†…å®¹çš„æ›´æ·±å±‚æ¬¡è§è§£çš„æœ‰ç”¨å·¥å…·ã€‚****

æˆ‘çªå‡ºæ˜¾ç¤ºçš„æ–‡æœ¬æ•°æ®æ¥è‡ª 28 æœ¬ä¸åŒçš„ä¹¦ï¼Œé€šè¿‡æŸ¥çœ‹æ•´ä¸ªæ–‡æ¡£ä¸­æœ€å¸¸è§çš„å•è¯å’ŒäºŒå…ƒæ¨¡å‹ï¼Œæˆ‘ä»¬å¯¹å®ƒä»¬æœ‰äº†ä¸€ä¸ªæ¦‚è¿°ã€‚

ä¸ºäº†äº†è§£æ¯æœ¬ä¹¦çš„ä¸åŒä¹‹å¤„ï¼Œæˆ‘ä»¬å¯ä»¥å¯¹æ¯æœ¬ä¹¦é‡å¤è¿™ä¸€è¿‡ç¨‹ã€‚

ä½†æ˜¯æˆ‘ä»¬å¦‚ä½•å•ç‹¬æ•æ‰å®ƒä»¬å‘¢ï¼Ÿ

è®©æˆ‘ä»¬å…ˆæŠŠè¯¾æ–‡å†çœ‹ä¸€éã€‚

![](img/80918f8f4a124aa70f286e0fa730ca98.png)

åœ¨æ¯æœ¬ä¹¦ä¹‹å‰éƒ½ä¼šå‡ºç°**â€œæ‚¨çš„ Kindle ç¬”è®°:â€**ã€‚è®©æˆ‘ä»¬æ‰¾å‡ºæ¯æœ¬ä¹¦çš„å¼€å¤´å’Œç»“å°¾çš„è¡Œå·ï¼Œå¹¶ä½¿ç”¨è¿™äº›ç´¢å¼•æ¥æ‰¾å‡ºæ¯æœ¬ä¹¦ã€‚

æˆ‘ä»¬å°†é‡ç”¨ä¸Šé¢åˆ›å»ºçš„æ•°æ®å¸§ dfã€‚ **str_which()** å‡½æ•°è¿”å›åŒ…å«ç»™å®šè¾“å…¥æ¨¡å¼çš„è¡Œç´¢å¼•å·ã€‚

åœ¨æœ€åä¸€æ­¥ï¼Œä¸€ä¸ª for å¾ªç¯**æ•è·ä¸¤ä¸ªè¿ç»­ç´¢å¼•ä¹‹é—´çš„æ–‡æœ¬**å°†ç»™å‡ºå®ƒä»¬ä¹‹é—´çš„ä¹¦ã€‚

```
**# Getting the index number for each book**indexes <- **str_which**(df$highlights, **pattern** = fixed(**"Your Kindle Notes For"**))
**book_names** <- df$highlights[indexes + 1]
**indexes** <-  c(indexes,nrow(df))**# Create an empty list** books <- list()**# Now the trick. Capture each 28 book separately in a list.** **for**(i in 1:(length(indexes)-1)) {
    books[[i]] <- data.frame(df$highlights[(indexes[i]:indexes[i+1]-1)])
    colnames(books[[i]]) <- "word_column"
    books[[i]]$word_column <- as.character(books[[i]]$word_column)
} 
```

è®©æˆ‘ä»¬çœ‹çœ‹å®ƒæ˜¯å¦æœ‰æ•ˆï¼Œä¾‹å¦‚ä½ å¯ä»¥åœ¨æˆ‘ä»¬çš„åˆ—è¡¨ä¸­æŸ¥æ‰¾ç¬¬äº”æœ¬ä¹¦ã€‚

```
**head(books[[5]])** word_column
1                                                    
2                              Your Kindle Notes For:
3 Bird by Bird: Some Instructions on Writing and Life
4                                         Anne Lamott
5             Last accessed on Saturday July 27, 2019
6                         75 Highlight(s) | 4 Note(s)
```

ç°åœ¨ï¼Œæˆ‘ä»¬æ•è·äº†æ‰€æœ‰ 28 æœ¬ä¹¦ï¼Œæˆ‘ä»¬å¯ä»¥åº”ç”¨ç›¸åŒçš„è¿‡ç¨‹ï¼Œé€šè¿‡å¦ä¸€ä¸ª for å¾ªç¯æ¥åˆ†æå®ƒä»¬ã€‚

```
top <- list()**for**(i in 1:28){
**books[[i]]** <- books[[i]] %>% **unnest_tokens**(word, word_column) %>%
             anti_join(stop_words) %>% 
             filter(!word %in% c("highlights","highlight", "page", 
                      "location", "yellow", "pink", "orange", "blue"))**# Find out the top words in each book and capture them in a list (top)** **top[[i]]** <- books[[i]] %>% 
              group_by(word) %>% 
              count() %>% 
              arrange(desc(n))}**for(i in 1:28)**{
  print(book_names[[i]])
  print(top[[i]])
}
```

è¿™æ˜¯ä¸Šé¢ä»£ç è¾“å‡ºçš„ä¸€éƒ¨åˆ†ã€‚

```
## [1] "Crucial Conversations Tools for Talking When Stakes Are High, Second Edition"## # A tibble: 1,834 x 2
## # Groups:   word [1,834]
##    word          n
##    <chr>     <int>
##  1 people       84
##  2 dialogue     40
##  3 stories      40
##  4 due          34
##  5 export       33
##  6 feel         33
##  7 hidden       33
##  8 limits       33
##  9 truncated    33
## 10 crucial      31
## # ... with 1,824 more rows## [1] "Pre-Suasion: A Revolutionary Way to Influence and Persuade"## # A tibble: 526 x 2
## # Groups:   word [526]
##    word             n
##    <chr>        <int>
##  1 attention        6
##  2 influence        5
##  3 mental           5
##  4 trust            5
##  5 visitors         5
##  6 comfort          4
##  7 emotional        4
##  8 experience       4
##  9 message          4
## 10 associations     3
## # ... with 516 more rows## [1] "Made to Stick: Why some ideas take hold and others come unstuck"## # A tibble: 1,754 x 2
## # Groups:   word [1,754]
##    word          n
##    <chr>     <int>
##  1 people       64
##  2 knowledge    27
##  3 story        25
##  4 ideas        24
##  5 concrete     18
##  6 surprise     17
##  7 care         16
##  8 time         15
##  9 attention    14
## 10 core         14
```

ç°åœ¨ï¼Œçœ‹çœ‹æ¯æœ¬ä¹¦ä¸­æœ€å¸¸ç”¨çš„å•è¯ï¼Œæˆ‘ä»¬å¯ä»¥æ›´æ·±å…¥åœ°äº†è§£å®ƒä»¬æ˜¯å…³äºä»€ä¹ˆçš„ã€‚

åŒä¸€æœ¬ä¹¦çš„äºŒå…ƒæ¨¡å‹ã€‚

```
**## [1] "Crucial Conversations Tools for Talking When Stakes Are High, Second Edition"**## # A tibble: 8,774 x 2
## # Groups:   bigram [8,774]
##    bigram                    n
##    <chr>                 <int>
**##  1 due export               33
##  2 due export limits        33
##  3 export limits            33
##  4 hidden truncated         33
##  5 hidden truncated due     33
##  6 truncated due            33
##  7 truncated due export     33
##  8 crucial conversations    19
##  9 export limits 27         10
## 10 limits 27                10**
## # ... with 8,764 more rows**## [1] "Pre-Suasion: A Revolutionary Way to Influence and Persuade"**
## # A tibble: 1,265 x 2
## # Groups:   bigram [1,265]
##    bigram                      n
##    <chr>                   <int>
##  1 attention goal              2
##  2 concept audience            2
##  3 levels importance           2
##  4 mandel johnson              2
##  5 mental activity             2
##  6 social proof                2
##  7 thousand dollars            2
##  8 twenty thousand             2
##  9 twenty thousand dollars     2
## 10 writing session             2
## # ... with 1,255 more rows**## [1] "Made to Stick: Why some ideas take hold and others come unstuck"**## # A tibble: 6,376 x 2
## # Groups:   bigram [6,376]
##    bigram                      n
##    <chr>                   <int>
##  1 curse knowledge             7
##  2 guessing machines           6
##  3 people care                 6
##  4 goodyear tires              5
##  5 knowledge gaps              5
##  6 people's attention          5
##  7 popcorn popper              5
##  8 security goodyear           5
##  9 security goodyear tires     5
## 10 sinatra test                5
```

ç°åœ¨ï¼Œä½ å¯èƒ½åœ¨ç¬¬ä¸€æœ¬ä¹¦é‡Œçœ‹åˆ°äº†å¥‡æ€ªçš„äºŒå…ƒæ¨¡å‹ã€‚Kindle é™åˆ¶ä½ å¯ä»¥é«˜äº®æ˜¾ç¤ºçš„æ–‡æœ¬é•¿åº¦ï¼Œä¾‹å¦‚ä½ ä¸èƒ½é«˜äº®æ˜¾ç¤º 5 é¡µçš„æ–‡æœ¬ã€‚è¿™å¯ä»¥é˜²æ­¢äººä»¬çªå‡ºæ˜¾ç¤ºæ•´æœ¬ä¹¦å¹¶å¯¼å‡ºåˆ° word æ–‡æ¡£ã€‚

å› ä¸ºæˆ‘å¶å°”ä¼šé«˜äº®æ˜¾ç¤ºå¾ˆé•¿çš„æ–‡æœ¬ï¼Œæ‰€ä»¥åƒâ€œåˆ°æœŸâ€ã€â€œå¯¼å‡ºâ€å’Œâ€œé™åˆ¶â€è¿™æ ·çš„è¯ä¼šä½œä¸ºè­¦å‘Šå‡ºç°åœ¨æˆ‘å¯¼å‡ºçš„é«˜äº®æ˜¾ç¤ºä¸Šã€‚

ç°åœ¨ï¼Œæˆ‘å°†è¿”å›å¹¶é€šè¿‡å°†è¿™äº›å•è¯æ·»åŠ åˆ° filter()å‡½æ•°ä¸­æ¥è¿›è¡Œæ›´å¤šçš„æ¸…ç†ã€‚

**ä¸€æœ¬ä¹¦ä¸€æœ¬ä¹¦åœ°çœ‹ç€ï¼Œä»–å¯¹æˆ‘ kindle é‡Œçš„ä¹¦è¶Šæ¥è¶Šç€è¿·ã€‚ä»–å†³å®šè®¢è´­å‡ ä¸ªã€‚**

*å¦‚æœä½ æƒ³çœ‹è¿™ä¸ªæ•æ‰è¿‡ç¨‹çš„å¦ä¸€ä¸ªä¾‹å­ï¼Œä½ å¯ä»¥åœ¨è¿™é‡Œçœ‹çœ‹æˆ‘æœ€è¿‘çš„* [*å¸–å­ã€‚*](https://dataatomic.com/r/data-wrangling-text-mining/)

æˆ‘ä»¬å¯ä»¥ä½¿ç”¨**æƒ…æ„Ÿåˆ†æ**æ¥è¯„ä¼°æ–‡æœ¬æ•°æ®ä¸­çš„æƒ…æ„Ÿè´Ÿè·ã€‚æœ€å¸¸è§çš„ç”¨é€”æ˜¯ç¤¾äº¤åª’ä½“ç›‘æ§ã€å®¢æˆ·ä½“éªŒç®¡ç†å’Œå®¢æˆ·ä¹‹å£°ï¼Œä»¥äº†è§£ä»–ä»¬çš„æ„Ÿå—ã€‚

> bing è¯å…¸ä»¥äºŒè¿›åˆ¶æ–¹å¼å°†å•è¯åˆ†ä¸ºç§¯æå’Œæ¶ˆæä¸¤ç±»ã€‚nrc çš„è¯å…¸ä½¿ç”¨äº†ç§¯æã€æ¶ˆæã€æ„¤æ€’ã€æœŸå¾…ã€åŒæ¶ã€ææƒ§ã€å¿«ä¹ã€æ‚²ä¼¤ã€æƒŠè®¶å’Œä¿¡ä»»ç­‰ç±»åˆ«ã€‚

**ä½¿ç”¨å¿…åº”è¯å…¸**

æˆ‘åˆ—å‡ºäº†å¯¹æ¯ä¸ªæƒ…æ„Ÿç±»åˆ«è´¡çŒ®æœ€å¤§çš„å•è¯ã€‚ä¾‹å¦‚æˆåŠŸå’Œæœ‰æ•ˆå¯¹äºç§¯ææƒ…ç»ªï¼Œä¸å¥½å’Œå›°éš¾å¯¹äºæ¶ˆææƒ…ç»ªã€‚

![](img/958633982dcc78f15674c13c612a346d.png)

ä¸‹é¢æ˜¯ R æ˜¯å¦‚ä½•åˆ¶ä½œå‡ºä¸Šè¿°æƒ…èŠ‚çš„:

```
bing_word_counts <- df %>% inner_join(get_sentiments("bing")) %>% 
  count(word, sentiment, sort = TRUE) %>%
  ungroup()bing_word_counts# **Sentiment plot for top positive negative contributors**
# Select top 10 positive and negative wordsbing <- bing_word_counts %>% 
  group_by(sentiment) %>% 
  top_n(10) %>% 
  ggplot(aes(reorder(word, n), n, fill=sentiment)) + 
  geom_bar(alpha=0.8, stat="identity", show.legend = FALSE)+
  facet_wrap(~sentiment, scales = "free_y") +
  labs(y= "Contribution to sentiment", x = NULL) +
  coord_flip()bing
```

**ä½¿ç”¨ nrc lexion**

å¦‚æœä¸€ç¯‡æ–‡ç« æ˜¯æ­£é¢çš„è€Œä¸æ˜¯è´Ÿé¢çš„ï¼Œæˆ‘æ›´æœ‰å¯èƒ½çªå‡ºå®ƒã€‚è¿˜æœ‰ä¿¡ä»»ã€æœŸå¾…å’Œå–œæ‚¦ï¼Œè€Œä¸æ˜¯æ‚²ä¼¤æˆ–æ„¤æ€’ã€‚

```
sentiment <- df %>%
        left_join(get_sentiments("nrc")) %>%
        filter(!is.na(sentiment)) %>%
        count(sentiment, sort = TRUE)
sentiment## # A tibble: 10 x 2
##    **sentiment        n**
##    <chr>        <int>
##  1 positive      8471
##  2 trust         4227
##  3 negative      3963
##  4 anticipation  3466
##  5 joy           2701
##  6 fear          2467
##  7 sadness       1853
##  8 anger         1814
##  9 surprise      1353
## 10 disgust       1102
```

**æ­£å¸¸åŒ–æƒ…ç»ª**

é‡è¦çš„æ˜¯è¦è¡¥å……ä¸€ç‚¹ï¼Œå› ä¸ºæ¯ç§æƒ…æ„Ÿç±»åˆ«åœ¨ä¸€ç§è¯­è¨€ä¸­æœ‰ä¸åŒæ•°é‡çš„å•è¯ã€‚å­—æ•°å°‘çš„æƒ…æ„Ÿç±»ï¼Œåœ¨ç»™å®šæ–‡æœ¬ä¸­å‡ºç°çš„å¯èƒ½æ€§æ›´å°ã€‚å› æ­¤ï¼Œ**æˆ‘æƒ³æ ¹æ®å®ƒä»¬åœ¨è¯å…¸ä¸­çš„å‡ºç°é¢‘ç‡å¯¹å®ƒä»¬è¿›è¡Œæ ‡å‡†åŒ–ï¼Œçœ‹çœ‹å®ƒä¸ä¸Šé¢çš„ç»“æœæœ‰ä½•ä¸åŒã€‚**

```
***# I will add numbers of each categories from the NRC lexicon***lexicon <- c(2317, 3338, 1234, 842, 1483, 691, 1250, 1195, 1060, 535)
polarity <-  c(1,1,1,1,1,0,0,0,0,0)
sentiment <- data.frame(sentiment, lexicon)
norm_sentiment <- sentiment %>% mutate( normalized = n/lexicon) %>% arrange(desc(normalized))
sentiment <- data.frame(norm_sentiment, polarity)
sentiment##       sentiment    n lexicon **normalized** polarity
## 1  anticipation 3466     842   4.116390        1
## 2      positive 8471    2317   3.656021        1
## 3          fear 2467     691   3.570188        1
## 4      negative 3963    1234   3.211507        1
## 5       disgust 1102     535   2.059813        1
## 6           joy 2701    1483   1.821308        0
## 7         anger 1814    1195   1.517992        0
## 8       sadness 1853    1250   1.482400        0
## 9      surprise 1353    1060   1.276415        0
## 10        trust 4227    3338   1.266327        0
```

ç°åœ¨ï¼Œ**æœŸå¾…**æ˜¯æ–‡æœ¬ä¸­å‘ç°çš„æœ€é«˜æƒ…æ„Ÿã€‚åœ¨æˆ‘çœ‹æ¥ï¼Œè¿™ä¸æ˜¯å·§åˆã€‚å› ä¸ºæˆ‘ä»¬åˆ†æçš„å¤§éƒ¨åˆ†ä¹¦ç±éƒ½æ˜¯å…³äºç”Ÿäº§åŠ›å’Œè‡ªæˆ‘å‘å±•çš„ã€‚ç”Ÿäº§åŠ›æç¤ºå’Œå·¥å…·é€šå¸¸åŒ…å«ä¸é¢„æœŸç›¸å…³çš„è¯æ±‡ã€‚

**åŒæ ·ï¼Œæˆ‘å¯ä»¥çœ‹çœ‹ä¸ªäººå¯¹ä¹¦ç±çš„çœ‹æ³•**

```
sentiment <- list()
**for** (i **in** 1:28){
sentiment[[i]] <- books[[i]] %>%
        left_join(get_sentiments("nrc")) %>%
        filter(!is.na(sentiment)) %>%
        count(sentiment, sort = TRUE)
        print(book_names[i])
        print(sentiment[[i]])
}
```

å¯¹ä¸ªäººä¹¦ç±çš„çœ‹æ³•ã€‚æˆ‘åœ¨è¿™é‡Œå±•ç¤ºäº†å…¶ä¸­çš„å‡ ä¸ªã€‚

```
## [1] "Crucial Conversations Tools for Talking When Stakes Are High, Second Edition"## # A tibble: 10 x 2
##    sentiment        n
##    <chr>        <int>
##  1 positive       758
##  2 negative       496
##  3 trust          412
##  4 fear           282
##  5 anticipation   258
##  6 anger          243
##  7 joy            216
##  8 sadness        196
##  9 disgust        142
## 10 surprise       108## Joining, by = "word"## [1] "Pre-Suasion: A Revolutionary Way to Influence and Persuade"
## # A tibble: 10 x 2
##    sentiment        n
##    <chr>        <int>
##  1 positive        84
##  2 trust           51
##  3 negative        31
##  4 anticipation    27
##  5 fear            24
##  6 joy             22
##  7 anger           14
##  8 sadness         12
##  9 surprise         9
## 10 disgust          3## Joining, by = "word"## [1] "Made to Stick: Why some ideas take hold and others come unstuck"
## # A tibble: 10 x 2
##    sentiment        n
##    <chr>        <int>
##  1 positive       499
##  2 trust          236
##  3 anticipation   198
##  4 negative       167
##  5 joy            156
##  6 fear           123
##  7 surprise       107
##  8 sadness         74
##  9 anger           65
## 10 disgust         60
```

ä¸ºäº†æœ‰ä¸€ä¸ªæ¦‚è¿°ï¼Œä½ å¯ä»¥é€šè¿‡ç»˜åˆ¶æ¯æœ¬ä¹¦çš„é˜³æ€§ç‡æ¥æ€»ç»“æ•°æ®ã€‚

![](img/23e2fb0ffdc9bcc2790f852d316e81b3.png)

æˆ‘ä»¬æ¥çœ‹çœ‹ç§¯ææ€§å¾—åˆ†æœ€ä½çš„é‚£æœ¬ä¹¦ã€‚[**ç”·äººçš„å¯»æ‰¾æ„ä¹‰**](https://www.amazon.com/Mans-Search-Meaning-Viktor-Frankl/dp/080701429X) **ã€‚è¿™æœ¬ä¹¦æ˜¯æ ¹æ®ç»´å…‹å¤šÂ·å¼—å…°å…‹åœ¨ç¬¬äºŒæ¬¡ä¸–ç•Œå¤§æˆ˜æœŸé—´çš„é­é‡å†™æˆçš„ã€‚è¿™ä¹Ÿæ˜¯æ„æ–™ä¹‹ä¸­çš„ã€‚**

> æˆ‘è¶Šæ¥è¶Šæ„Ÿå—åˆ°æ–‡æœ¬æŒ–æ˜çš„åŠ›é‡ã€‚

ã€Šå±€å¤–äººã€‹è¿™æœ¬ä¹¦å‡ºç°åœ¨ç§¯ææ€§å›¾çš„é¡¶éƒ¨ï¼Œæ˜¯ä¸€ä¸ªçœŸæ­£çš„å±€å¤–äººã€‚ğŸ˜®

ä»å¤´å¼€å§‹äº†è§£ä¸€åˆ‡æ˜¯å¾ˆéš¾çš„ï¼Œæˆ‘ä»¬å°†å›å»åšä¸€äº›é¢å¤–çš„æ¸…ç†ã€‚ã€Šå±€å¤–äººã€‹ä¸€ä¹¦çš„å­—æ•°æ˜¯ 107 ä¸ªã€‚**è¿™ä¸ªçœŸçš„å¾ˆä½ã€‚å› æ­¤åœ¨ä¸‹ä¸€æ¬¡è¿­ä»£ä¸­ï¼Œæˆ‘å°†ä»åˆ†æä¸­åˆ é™¤å®ƒï¼Œå› ä¸ºå®ƒä¸å¯é ã€‚**

```
book_names[[27]]**## [1] "Outliers: The Story of Success"**top[[27]]# A tibble: 107 x 2
# Groups:   **word [107]**
word             n
<chr>        <int>
1 ability          3
2 knowing          3
3 sense            3
4 communicate      2
5 distance         2
6 family           2
7 intelligence     2
8 power            2
9 practical        2
10 sternberg        2
# ... with 97 more rows
```

ä»¥ä¸‹æ˜¯æˆ‘ç”¨æ¥ç»˜åˆ¶ç§¯ææ€§å¾—åˆ†çš„ä»£ç :

```
books <- **str_trunc**(book_names, width=22) # Shorten the book namesall <- list()for (i in 1:28) {
all[[i]] <- sentiment[[i]] %>% 
  filter(sentiment %in% c('positive','negative')) %>% 
  mutate(n2 = n/sum(n)) %>% 
  print()
}all_bound <- do.call("rbind", all) %>% filter(sentiment == "positive")**library(ggrepel) # Useful for preventing overlapping labels**all_bound %>% ggplot(aes(x= book_names, y=n2)) + 
              geom_point() + 
              **geom_label_repel**(aes(label=books, color = ifelse(n2 <0.55, "red", "blue")), size = 4) + 
              theme_classic() + 
              theme(legend.position = "none",
                    text = element_text(size=18), 
                    axis.text.x = element_blank()) + 
              xlab("Books") + 
              ylab("Positivity score")
```

# æ‘˜è¦

é˜…è¯»æ•°ç™¾ä¸‡é¡µæ¥æ£€æŸ¥æ–‡æœ¬æŒ–æ˜æ˜¯å¦å¯é æ˜¯ä¸å¯è¡Œçš„ã€‚ä½†åœ¨è¿™é‡Œï¼Œæˆ‘å¾—åˆ°äº†ä¸€äº›æˆ‘çŸ¥é“å†…å®¹çš„æ•°æ®ï¼Œå¹¶åº”ç”¨äº†æ–‡æœ¬æŒ–æ˜å’Œæƒ…æ„Ÿåˆ†æã€‚

å­—æ¯ç»„åˆæˆ–å­—æ¯ç»„åˆéƒ½è¡¨æ˜äº†è¿™äº›ä¹¦çš„ç›¸ä¼¼ä¹‹å¤„ã€‚è¿™ç§æƒ…ç»ªå’Œæˆ‘ kindle é‡Œçš„ä¹¦çš„ç±»å‹æœ‰å…³ç³»ã€‚

è®©æˆ‘ä»¬å›åˆ°æˆ‘ä»¬çš„é»‘å®¢ã€‚

æ–‡æœ¬æŒ–æ˜çš„ä¸€ä¸ªæ„æƒ³ä¸åˆ°çš„å‰¯ä½œç”¨æ°¸è¿œæ”¹å˜äº†ä»–ã€‚åˆ†ææˆ‘çš„ä¹¦å¹¶ä»ä¸­è·å¾—çœŸçŸ¥ç¼è§ä½¿ä»–å¯¹é˜…è¯»è¶Šæ¥è¶Šæ„Ÿå…´è¶£ã€‚ä»–å¼€å§‹å…³å¿ƒä»–å‘¨å›´çš„ä¸–ç•Œã€‚ä¸–ç•Œå˜äº†ã€‚

æˆ‘ä¸ºè‡ªå·±åšçš„äº‹ï¼Œä»–ä¹Ÿä¸ºè‡ªå·±åšäº†ã€‚ä»–å˜æˆäº†ä¸€ä¸ªæ›´å¥½çš„è‡ªå·±ã€‚

ä¸–ç•Œå˜å¾—æ›´åŠ æ˜äº®ã€‚â˜€ï¸

æ”¶éŸ³æœºæ‰“ç ´äº†å¯‚é™ã€‚

> â€œbrrringâ€¦..br æ­£åœ¨â€¦..br æ­£åœ¨â€¦â€¦â€

æˆ‘é†’äº†ã€‚

æ„Ÿè°¢æ‚¨çš„é˜…è¯»ã€‚ä½ å¯ä»¥åœ¨æˆ‘çš„ [github repo ä¸­æ‰¾åˆ°æ•°æ®å’Œä»£ç ã€‚](https://github.com/korur/textmining)

å¸Œæœ›ä½ ä»ä¸­æœ‰æ‰€æ”¶è·æˆ–è€…æœ‰æ‰€å¯å‘ã€‚è¯·éšæ—¶ç•™ä¸‹è¯„è®ºã€å»ºè®®å’Œé—®é¢˜ã€‚(ä½ å¯ä»¥é€šè¿‡ç”µå­é‚®ä»¶è”ç³»æˆ‘ï¼Œåœ°å€æ˜¯ serdar.korur@gmail.com)

ä¸‹æ¬¡è§ï¼

å¡å°”è¾¾å°”