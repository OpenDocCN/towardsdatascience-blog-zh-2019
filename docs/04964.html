<html>
<head>
<title>Deep CARs— Transfer Learning With Pytorch</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">深度汽车 Pytorch 迁移学习</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/deep-cars-transfer-learning-with-pytorch-3e7541212e85?source=collection_archive---------10-----------------------#2019-07-26">https://towardsdatascience.com/deep-cars-transfer-learning-with-pytorch-3e7541212e85?source=collection_archive---------10-----------------------#2019-07-26</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><blockquote class="jq"><p id="4221" class="jr js it bd jt ju jv jw jx jy jz ka dk translated">完成<em class="kb"> Hackathon Auto-matic </em>的逐步指南</p></blockquote><figure class="kd ke kf kg kh ki gh gi paragraph-image"><div role="button" tabindex="0" class="kj kk di kl bf km"><div class="gh gi kc"><img src="../Images/4abae8d2942707ba24b3402e1cad5e55.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*NmS_1S_2Qvw9qX6N6sxziA.jpeg"/></div></div><figcaption class="kp kq gj gh gi kr ks bd b be z dk">Source: <a class="ae kt" href="https://www.freewebheaders.com/transport/cars-headers/" rel="noopener ugc nofollow" target="_blank">Honda Small Sports EV Concept Electric Car</a></figcaption></figure><p id="9702" class="pw-post-body-paragraph ku kv it kw b kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq ka im bi translated">你如何教计算机识别不同的汽车品牌？你想给任何一辆车拍照，然后你的手机自动告诉你这辆车的品牌吗？</p><p id="fa20" class="pw-post-body-paragraph ku kv it kw b kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq ka im bi translated">如果这让你兴奋，那么你来对地方了。我们要写一个可以识别 196 种不同类型汽车的模型。</p><blockquote class="lr ls lt"><p id="738b" class="ku kv lu kw b kx ky kz la lb lc ld le lv lg lh li lw lk ll lm lx lo lp lq ka im bi translated"><strong class="kw iu"> <em class="it">侧注</em> </strong></p><p id="a694" class="ku kv lu kw b kx ky kz la lb lc ld le lv lg lh li lw lk ll lm lx lo lp lq ka im bi translated">自动黑客马拉松是我和四位女士(来自世界各地)发起的组织周末黑客马拉松的第二个项目</p><p id="abb3" class="ku kv lu kw b kx ky kz la lb lc ld le lv lg lh li lw lk ll lm lx lo lp lq ka im bi translated">作为 facebook 赞助的 Udacity 上的<strong class="kw iu">安全和私人 AI 奖学金挑战赛的 5000 名学生的一部分，</strong>我们决定组织周末黑客马拉松；用 Pytorch 解决一个问题的 48 小时，玩得开心，互相竞争。令我们惊讶的是，在我们的第一次黑客马拉松中，有 41 个团队参加了🙌。<a class="ae kt" href="https://www.kaggle.com/spaics/hackathon-blossom-flower-classification" rel="noopener ugc nofollow" target="_blank"> <strong class="kw iu">黑客马拉松开花</strong> </a>是给第一届黑客马拉松起的名字。<a class="ae kt" href="https://www.kaggle.com/c/virtual-hack" rel="noopener ugc nofollow" target="_blank"><strong class="kw iu">Hackathon Auto-matic</strong></a><strong class="kw iu"/>和 Hackathon Blossom 一样也是基于图像分类。</p><p id="7ce8" class="ku kv lu kw b kx ky kz la lb lc ld le lv lg lh li lw lk ll lm lx lo lp lq ka im bi translated">我可以继续讲述这个机会是多么不可思议，以及我们在那里拥有的令人惊叹的社区。我最好就此打住，回到我们今天的目标:)</p></blockquote><h1 id="9d5c" class="ly lz it bd ma mb mc md me mf mg mh mi mj mk ml mm mn mo mp mq mr ms mt mu mv bi translated">入门指南</h1><p id="e746" class="pw-post-body-paragraph ku kv it kw b kx mw kz la lb mx ld le lf my lh li lj mz ll lm ln na lp lq ka im bi translated">我们将使用神经网络来实现我们的目标。更准确地说，我们将使用一个非常深的神经网络，因此命名为<strong class="kw iu">深车。</strong></p><p id="d356" class="pw-post-body-paragraph ku kv it kw b kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq ka im bi translated">本教程分为两部分:</p><p id="45d3" class="pw-post-body-paragraph ku kv it kw b kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq ka im bi translated"><strong class="kw iu">第 1 部分:构建汽车分类器</strong></p><p id="3600" class="pw-post-body-paragraph ku kv it kw b kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq ka im bi translated"><strong class="kw iu">第 2 部分:部署分类器(进行中…) </strong></p><p id="9bed" class="pw-post-body-paragraph ku kv it kw b kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq ka im bi translated">在本文中，我们将浏览第 1 部分</p><h1 id="fb6f" class="ly lz it bd ma mb mc md me mf mg mh mi mj mk ml mm mn mo mp mq mr ms mt mu mv bi translated">第 1 部分:构建汽车分类器</h1><p id="3595" class="pw-post-body-paragraph ku kv it kw b kx mw kz la lb mx ld le lf my lh li lj mz ll lm ln na lp lq ka im bi translated"><em class="lu">先决条件:</em></p><p id="4683" class="pw-post-body-paragraph ku kv it kw b kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq ka im bi translated">为了跟进，需要以下方面的一些知识:</p><ul class=""><li id="ebe8" class="nb nc it kw b kx ky lb lc lf nd lj ne ln nf ka ng nh ni nj bi translated"><em class="lu">Python</em>——uda city 提供了一个关于<a class="ae kt" href="https://www.udacity.com/course/introduction-to-python--ud1110" rel="noopener ugc nofollow" target="_blank">Python 简介</a>的很棒的课程</li><li id="fbf1" class="nb nc it kw b kx nk lb nl lf nm lj nn ln no ka ng nh ni nj bi translated"><em class="lu">卷积神经网络</em> — Adit 在 CNN 上提供了一个伟大的<a class="ae kt" href="https://adeshpande3.github.io/adeshpande3.github.io/A-Beginner's-Guide-To-Understanding-Convolutional-Neural-Networks/" rel="noopener ugc nofollow" target="_blank">解释</a></li><li id="31b6" class="nb nc it kw b kx nk lb nl lf nm lj nn ln no ka ng nh ni nj bi translated"><em class="lu"> Pytorch </em>的基础知识</li></ul><p id="5866" class="pw-post-body-paragraph ku kv it kw b kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq ka im bi translated">我们将使用一种叫做<strong class="kw iu">迁移学习</strong>的方法来训练我们的分类器。</p><h1 id="7a7f" class="ly lz it bd ma mb mc md me mf mg mh mi mj mk ml mm mn mo mp mq mr ms mt mu mv bi translated">什么是迁移学习？</h1><p id="3892" class="pw-post-body-paragraph ku kv it kw b kx mw kz la lb mx ld le lf my lh li lj mz ll lm ln na lp lq ka im bi translated">迁移学习是深度学习中的一种方法，其中为解决一项任务而开发的模型被重新用作另一项任务的起点。比方说，你想建立一个网络来识别鸟类，而不是从头开始编写一个模型，这可能是一个非常复杂的任务，至少可以使用一个已经存在的模型来完成相同或类似的任务(在我们识别鸟类的情况下，我们可以使用一个识别其他动物的网络)。运用迁移学习的优势；<em class="lu">学习过程更快、更准确，需要的训练数据更少</em>。已经存在的模型被称为<strong class="kw iu">预训练模型。</strong></p><p id="3ad1" class="pw-post-body-paragraph ku kv it kw b kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq ka im bi translated">迁移学习中使用的大多数预训练模型都基于大型卷积神经网络。一些人预训练的模型有 VGGNet，ResNet，DenseNet，Google 的 Inception 等。这些网络中的大多数都是在<a class="ae kt" href="http://www.image-net.org/" rel="noopener ugc nofollow" target="_blank"> ImageNet </a>上训练出来的。ImageNet 是一个大规模数据集，包含 1000 个类别中超过 100 万个带标签的图像。</p><p id="2138" class="pw-post-body-paragraph ku kv it kw b kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq ka im bi translated">在 Pytorch 中，很容易加载基于 ImageNet 的预训练网络，这些网络<a class="ae kt" href="https://pytorch.org/docs/0.3.0/torchvision/models.html" rel="noopener ugc nofollow" target="_blank">可从 torchvision </a>获得。我们将使用这些预先训练好的模型来训练我们的网络。</p><p id="3abf" class="pw-post-body-paragraph ku kv it kw b kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq ka im bi translated">我们的模型将使用以下步骤在 Google Colab 上构建(笔记本可在此处找到<a class="ae kt" href="https://github.com/ivyclare/DeepCars---Transfer-Learning-With-Pytorch/blob/master/Ivy__Deep_Cars_Identifying_Car_Brands.ipynb" rel="noopener ugc nofollow" target="_blank"><em class="lu"/></a>):</p><ol class=""><li id="9791" class="nb nc it kw b kx ky lb lc lf nd lj ne ln nf ka np nh ni nj bi translated">加载数据并执行转换</li><li id="5ce9" class="nb nc it kw b kx nk lb nl lf nm lj nn ln no ka np nh ni nj bi translated">建立模型</li><li id="344b" class="nb nc it kw b kx nk lb nl lf nm lj nn ln no ka np nh ni nj bi translated">训练模型</li><li id="7378" class="nb nc it kw b kx nk lb nl lf nm lj nn ln no ka np nh ni nj bi translated">在看不见的数据上测试模型</li></ol><p id="3a9e" class="pw-post-body-paragraph ku kv it kw b kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq ka im bi translated"><strong class="kw iu">导入库</strong></p><p id="026b" class="pw-post-body-paragraph ku kv it kw b kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq ka im bi translated">在这里，我们只是加载库，并确保 GPU 是打开的。由于我们将使用预先训练的模型，这些模型是非常深的网络，所以 CPU 上的训练不是一个真正的选项，因为这将需要很长时间。GPU 并行执行线性代数计算，因此训练速度提高了 100 倍。</p><p id="1c8f" class="pw-post-body-paragraph ku kv it kw b kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq ka im bi translated">如果你的 GPU 是关闭的，并且你正在使用 Colab，在你的笔记本上进入<strong class="kw iu">编辑= &gt;笔记本设置</strong>。确保<strong class="kw iu">运行时</strong>设置为<strong class="kw iu"> Python 3 </strong>并且在<strong class="kw iu">硬件加速器</strong>下选择<strong class="kw iu"> GPU。</strong></p><p id="1178" class="pw-post-body-paragraph ku kv it kw b kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq ka im bi translated">你会注意到我们正在检查 cuda 是否可用。大多数深度学习框架使用 CUDA 来计算 GPU 上的向前和向后传递。</p><figure class="nq nr ns nt gt ki"><div class="bz fp l di"><div class="nu nv l"/></div></figure><h1 id="6ece" class="ly lz it bd ma mb mc md me mf mg mh mi mj mk ml mm mn mo mp mq mr ms mt mu mv bi translated"><strong class="ak"> 1。执行转换并加载数据集</strong></h1><p id="17a5" class="pw-post-body-paragraph ku kv it kw b kx mw kz la lb mx ld le lf my lh li lj mz ll lm ln na lp lq ka im bi translated"><strong class="kw iu"> 1.1 下载数据集</strong></p><p id="7b6d" class="pw-post-body-paragraph ku kv it kw b kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq ka im bi translated">现在我们的库已经导入，我们从<a class="ae kt" href="https://www.kaggle.com/c/virtual-hack/data" rel="noopener ugc nofollow" target="_blank"> Kaggle </a>加载数据集。该数据集包含 196 个汽车品牌。</p><p id="2b01" class="pw-post-body-paragraph ku kv it kw b kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq ka im bi translated">在这里，我们下载数据集并使用 Pytorch 数据加载器加载它们。我们将数据直接下载到谷歌硬盘，因此我们必须获得授权访问。</p><pre class="nq nr ns nt gt nw nx ny nz aw oa bi"><span id="8c85" class="ob lz it nx b gy oc od l oe of">#Mounting google drive inorder to access data<br/>from google.colab import drive<br/>drive.mount('/content/drive')</span></pre><p id="de26" class="pw-post-body-paragraph ku kv it kw b kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq ka im bi translated">运行后:点击出现的链接，登录到你的帐户，点击允许，然后复制生成的文本并粘贴到你的笔记本上。查看这篇<a class="ae kt" rel="noopener" target="_blank" href="/setting-up-kaggle-in-google-colab-ebb281b61463">文章</a>，这篇文章向您展示了如何轻松获得 API 密钥和下载数据集。我们加上这一行<em class="lu">！解压缩\*。zip </em>解压下载的文件。您的代码应该是这样的:</p><figure class="nq nr ns nt gt ki"><div class="bz fp l di"><div class="nu nv l"/></div></figure><p id="a340" class="pw-post-body-paragraph ku kv it kw b kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq ka im bi translated">注意我们有两个目录；培训和测试目录。稍后，我们将使用我们的模型来预测测试集的值。我们必须将训练数据分为训练数据和验证数据。在拆分之前，让我们了解什么是转换，并写出我们的转换。</p><p id="7433" class="pw-post-body-paragraph ku kv it kw b kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq ka im bi translated"><strong class="kw iu"> 1.2 数据转换</strong></p><p id="8efd" class="pw-post-body-paragraph ku kv it kw b kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq ka im bi translated">既然数据集已经下载，我们就对数据执行转换。转换是将数据从一种形式转换成另一种形式。我们将对我们的图像应用两个主要的变换:</p><ul class=""><li id="aae3" class="nb nc it kw b kx ky lb lc lf nd lj ne ln nf ka ng nh ni nj bi translated"><strong class="kw iu">数据增强</strong></li></ul><p id="49cc" class="pw-post-body-paragraph ku kv it kw b kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq ka im bi translated">这是一种在不实际收集新数据的情况下增加用于训练的数据集的多样性和大小的策略。诸如调整大小、裁剪、水平翻转、填充甚至 GANs 等技术被应用于数据集上的图像，并且“新的”图像被创建。它有两个主要优点:<strong class="kw iu">从有限的数据中生成更多的数据，并防止过拟合</strong>。</p><p id="78d3" class="pw-post-body-paragraph ku kv it kw b kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq ka im bi translated">但是，不要期望在数据集中看到这些生成的图像。它们仅在批量生成期间创建，因此即使您没有看到数据集中的图像数量增加，训练期间的实际图像也会增加。</p><p id="56d6" class="pw-post-body-paragraph ku kv it kw b kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq ka im bi translated">在我们的模型中，我们应用了 3 种增强策略；<em class="lu">调整大小(RandomResize)、裁剪(RandomCrop)和水平翻转(HorizontalFlip)。</em></p><p id="8d77" class="pw-post-body-paragraph ku kv it kw b kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq ka im bi translated">请注意，对于测试数据，我们不执行 RandomResizedCrop、RandomRotation 和 RandomHorizontalFlip 转换。相反，我们只是将测试图像的大小调整为 256×256，并裁剪掉中心 224×224，以便能够将它们用于预训练的模型。</p><ul class=""><li id="6678" class="nb nc it kw b kx ky lb lc lf nd lj ne ln nf ka ng nh ni nj bi translated"><strong class="kw iu">数据标准化</strong></li></ul><p id="675b" class="pw-post-body-paragraph ku kv it kw b kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq ka im bi translated">执行增强后，图像被转换为张量，并通过使用 ImageNet 中所有图像的平均值和标准偏差进行归一化。通常，对于非常大的数据集，使用数据集本身的平均值和标准差。鉴于我们的数据集不是太大，我们使用 ImageNet 的数据集:<em class="lu">【0.485，0.456，0.406】，【0.229，0.224，0.225】</em></p><figure class="nq nr ns nt gt ki"><div class="bz fp l di"><div class="nu nv l"/></div></figure><p id="80f6" class="pw-post-body-paragraph ku kv it kw b kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq ka im bi translated">执行这些转换后，我们使用 Pytorch 中的 ImageFolder 加载数据。但是首先我们需要验证数据，所以我们拆分了训练集。我们的数据中只有 1%被选择用于验证，其余的用于训练。</p><figure class="nq nr ns nt gt ki"><div class="bz fp l di"><div class="nu nv l"/></div></figure><ul class=""><li id="7872" class="nb nc it kw b kx ky lb lc lf nd lj ne ln nf ka ng nh ni nj bi translated"><strong class="kw iu">可视化标签</strong></li></ul><p id="9f13" class="pw-post-body-paragraph ku kv it kw b kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq ka im bi translated">我们可视化我们的标签来查看文件的结构。</p><figure class="nq nr ns nt gt ki gh gi paragraph-image"><div role="button" tabindex="0" class="kj kk di kl bf km"><div class="gh gi og"><img src="../Images/ef640760373474d8b61e32f544d6bd6f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*z0IxJ7scZVb3henLbMgE3w.png"/></div></div><figcaption class="kp kq gj gh gi kr ks bd b be z dk">Output from printing names.csv</figcaption></figure><p id="834a" class="pw-post-body-paragraph ku kv it kw b kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq ka im bi translated">我们看到 0 上面出现了一个车名。因此，在读取 csv 文件时，我们必须添加一个头名，这样才能得到正确的输出。需要注意的是，我们的标签从 0 到 195 开始(非常重要)</p><figure class="nq nr ns nt gt ki gh gi paragraph-image"><div class="gh gi oh"><img src="../Images/6b3ffaa74879cb06ee68f914ca8e788b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1008/format:webp/1*zhnIHR8b9q9qkjcD9VMtZw.png"/></div></figure><p id="6d5b" class="pw-post-body-paragraph ku kv it kw b kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq ka im bi translated"><strong class="kw iu"> 3 可视化图像</strong></p><p id="8ee6" class="pw-post-body-paragraph ku kv it kw b kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq ka im bi translated">我们现在可以加载和可视化我们的数据。创建了一个方法<em class="lu"> imshow() </em>(来自挑战课程)来显示我们的图像。</p><figure class="nq nr ns nt gt ki"><div class="bz fp l di"><div class="nu nv l"/></div></figure><p id="4cc9" class="pw-post-body-paragraph ku kv it kw b kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq ka im bi translated">训练集中的图像如下所示。我们注意到其中一些已经翻转或旋转。</p><figure class="nq nr ns nt gt ki gh gi paragraph-image"><div role="button" tabindex="0" class="kj kk di kl bf km"><div class="gh gi oi"><img src="../Images/35081af4ee44e2c42df12a9429290dfb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*pDhfuni5j61NwEeF-xLuvA.png"/></div></div><figcaption class="kp kq gj gh gi kr ks bd b be z dk">Images from train set after transformations</figcaption></figure><h1 id="02b2" class="ly lz it bd ma mb mc md me mf mg mh mi mj mk ml mm mn mo mp mq mr ms mt mu mv bi translated"><strong class="ak"> 2。构建和训练模型</strong></h1><p id="52b3" class="pw-post-body-paragraph ku kv it kw b kx mw kz la lb mx ld le lf my lh li lj mz ll lm ln na lp lq ka im bi translated">如前所述，我们将使用基于 ImageNet 的预训练模型。</p><p id="1f9f" class="pw-post-body-paragraph ku kv it kw b kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq ka im bi translated">我们将用于构建和培训的步骤是:</p><ol class=""><li id="194e" class="nb nc it kw b kx ky lb lc lf nd lj ne ln nf ka np nh ni nj bi translated">加载预训练模型</li><li id="814c" class="nb nc it kw b kx nk lb nl lf nm lj nn ln no ka np nh ni nj bi translated">冻结卷积层中的参数</li><li id="c7fa" class="nb nc it kw b kx nk lb nl lf nm lj nn ln no ka np nh ni nj bi translated">创建自定义分类器并定义超参数</li><li id="5b41" class="nb nc it kw b kx nk lb nl lf nm lj nn ln no ka np nh ni nj bi translated">训练自定义分类器</li></ol><p id="3b8f" class="pw-post-body-paragraph ku kv it kw b kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq ka im bi translated"><strong class="kw iu"> 2.2 加载预训练模型</strong></p><p id="e7a9" class="pw-post-body-paragraph ku kv it kw b kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq ka im bi translated">我们将尝试不同的架构；<strong class="kw iu"> densenet161 </strong>、<strong class="kw iu"> inceptionv3 </strong>、<strong class="kw iu"> resnet121 </strong>和<strong class="kw iu"> vggnet </strong>架构。在这里，我们加载不同的模型，并在模型的全连接层中指定输入要素的数量，因为我们在构建自定义分类器时将需要这一点。</p><figure class="nq nr ns nt gt ki"><div class="bz fp l di"><div class="nu nv l"/></div></figure><p id="e2f1" class="pw-post-body-paragraph ku kv it kw b kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq ka im bi translated"><strong class="kw iu"> 2.3 冻结参数并创建自定义分类器</strong></p><p id="3a89" class="pw-post-body-paragraph ku kv it kw b kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq ka im bi translated">因为我们的预训练模型中的大多数参数已经为我们训练好了，所以我们不通过它们进行反向投影。这将允许我们保留早期卷积层的预训练权重(其目的是用于特征提取)。我们通过将<em class="lu"> requires_grad </em>字段重置为 false 来实现这一点。</p><p id="fa69" class="pw-post-body-paragraph ku kv it kw b kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq ka im bi translated">在此之后，我们替换完全连接的网络，该网络将具有与我们的预训练神经元相同的输入、自定义隐藏层和我们的输出。我们的<em class="lu">build _ classifier</em>方法很灵活，当我们不希望网络中有隐藏层，或者我们希望有多个隐藏层时，这种方法很有效。激活功能(在本例中为<em class="lu"> relu </em>)和<em class="lu">漏失</em>也被定义。</p><figure class="nq nr ns nt gt ki"><div class="bz fp l di"><div class="nu nv l"/></div></figure><p id="71f3" class="pw-post-body-paragraph ku kv it kw b kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq ka im bi translated">现在我们指定我们的超参数和隐藏层。</p><figure class="nq nr ns nt gt ki"><div class="bz fp l di"><div class="nu nv l"/></div></figure><p id="5076" class="pw-post-body-paragraph ku kv it kw b kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq ka im bi translated">我们指定了标准，不同的优化器，如 Adam，Adadelta，SGD，其中包含了学习率和动量。我们为不同的预训练网络使用这些超参数，并选择给我们最好结果的那些。我们为 resnet 和 vggnet 使用两种不同的调度程序。他们是这样做的:</p><p id="d829" class="pw-post-body-paragraph ku kv it kw b kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq ka im bi translated"><code class="fe oj ok ol nx b">torch.optim.lr_scheduler</code>提供了几种根据时期数调整学习率的方法。<code class="fe oj ok ol nx b"><a class="ae kt" href="https://pytorch.org/docs/stable/optim.html#torch.optim.lr_scheduler.ReduceLROnPlateau" rel="noopener ugc nofollow" target="_blank">torch.optim.lr_scheduler.ReduceLROnPlateau</a></code>允许基于某些验证测量的动态学习率降低。更多阅读<a class="ae kt" href="https://pytorch.org/docs/stable/optim.html" rel="noopener ugc nofollow" target="_blank">此处</a></p><p id="c03d" class="pw-post-body-paragraph ku kv it kw b kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq ka im bi translated"><strong class="kw iu"> 2.4 培训和验证</strong></p><p id="338c" class="pw-post-body-paragraph ku kv it kw b kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq ka im bi translated">为了用 PyTorch 训练我们的模型，我们通常在迭代每个时期时执行以下步骤:</p><ul class=""><li id="0b3a" class="nb nc it kw b kx ky lb lc lf nd lj ne ln nf ka ng nh ni nj bi translated">使用<em class="lu"> forward(images) </em>向前通过网络</li><li id="9802" class="nb nc it kw b kx nk lb nl lf nm lj nn ln no ka ng nh ni nj bi translated">使用<em class="lu">标准</em>功能中的网络输出来计算损耗</li><li id="0e1b" class="nb nc it kw b kx nk lb nl lf nm lj nn ln no ka ng nh ni nj bi translated">使用<em class="lu"> loss.backward() </em>对网络进行反向遍历，以计算梯度</li><li id="0e33" class="nb nc it kw b kx nk lb nl lf nm lj nn ln no ka ng nh ni nj bi translated">与优化器一起更新权重<em class="lu"> optimizer.step() </em></li></ul><p id="fea7" class="pw-post-body-paragraph ku kv it kw b kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq ka im bi translated"><em class="lu"> optimizer.zero_grad() </em>用于清除累积的梯度</p><p id="e22b" class="pw-post-body-paragraph ku kv it kw b kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq ka im bi translated">称为<strong class="kw iu">提前停止</strong>的技术用于防止过度拟合。当验证数据集的性能开始下降时，它会导致训练停止。随着训练的进行，当我们获得最佳准确度时，我们也保存模型(检查点)。这样，如果断电或训练由于某种原因中断，可以恢复检查点并继续训练。</p><p id="f663" class="pw-post-body-paragraph ku kv it kw b kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq ka im bi translated">该模型改编自<a class="ae kt" href="https://pytorch.org/tutorials/beginner/transfer_learning_tutorial.html" rel="noopener ugc nofollow" target="_blank"> PyTorch 网站</a></p><figure class="nq nr ns nt gt ki"><div class="bz fp l di"><div class="nu nv l"/></div></figure><p id="08ec" class="pw-post-body-paragraph ku kv it kw b kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq ka im bi translated">现在我们训练我们的模型。</p><figure class="nq nr ns nt gt ki"><div class="bz fp l di"><div class="nu nv l"/></div></figure><pre class="nq nr ns nt gt nw nx ny nz aw oa bi"><span id="de7b" class="ob lz it nx b gy oc od l oe of">Epoch 1/60 <br/>---------- <br/>train Loss: 0.5672 Acc: 0.8441 <br/>valid Loss: 0.6750 Acc: 0.8329 <br/> Epoch 2/60 <br/>---------- <br/>train Loss: 0.6184 Acc: 0.8357 <br/>valid Loss: 0.5980 Acc: 0.8415  <br/>Epoch 3/60 <br/>---------- <br/>train Loss: 0.5695 Acc: 0.8487 <br/>valid Loss: 0.5503 Acc: 0.8575  <br/>...</span></pre><p id="d6d7" class="pw-post-body-paragraph ku kv it kw b kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq ka im bi translated">这看起来很有希望。这个模型似乎在不断学习。此外，我们的模型似乎没有过度拟合(至少是过度拟合)，因为训练和验证指标没有偏离太多。该模型的特定时期结果是通过 ResNet 架构获得的，这是第二次培训。精度开始很低，但随着时间的推移而提高。对我们得到的精度影响很大的超参数是<strong class="kw iu">优化器、调度器、历元数和架构</strong>。调整这些值要么给出非常低的精度(低至 0，甚至为负)，要么以 0.013 这样的精度开始，该精度随着历元数的增加而增加(这里耐心是关键)。</p><p id="b416" class="pw-post-body-paragraph ku kv it kw b kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq ka im bi translated"><strong class="kw iu"> 4。在看不见的数据上测试模型</strong></p><p id="e995" class="pw-post-body-paragraph ku kv it kw b kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq ka im bi translated">一旦我们对我们的验证准确性感到满意，我们就加载我们保存的模型，并对测试数据进行预测。课堂竞赛要求我们以 csv 格式提交结果，格式为<strong class="kw iu"> Id，预测</strong>。<em class="lu"> Id </em>这是我们图像文件的名称，不带扩展名。jpg 和<em class="lu">预测的</em>是我们的模型为每张图片预测的类(应该在 1 到 196 之间)。请记住，我们的标签从 0 到 195 开始，所以我们必须在预测的类中加 1 才能得到正确的值。</p><p id="eb36" class="pw-post-body-paragraph ku kv it kw b kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq ka im bi translated">我们加载我们保存的模型</p><pre class="nq nr ns nt gt nw nx ny nz aw oa bi"><span id="a170" class="ob lz it nx b gy oc od l oe of">model.load_state_dict(torch.load('/content/drive/MyDrive/ResnetCars.pt'))<br/>model.to(device)</span></pre><p id="0975" class="pw-post-body-paragraph ku kv it kw b kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq ka im bi translated">现在，我们加载测试数据集，并通过数据集传递我们的模型。因为我们只做预测，所以不需要计算梯度。我们通过<em class="lu"> torch.no_grad() </em>并设置为 evaluation <em class="lu"> model.eval()来实现这一点。我们计算预测。</em></p><figure class="nq nr ns nt gt ki"><div class="bz fp l di"><div class="nu nv l"/></div></figure><p id="9364" class="pw-post-body-paragraph ku kv it kw b kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq ka im bi translated">得到结果后，我们打印数据框，并将结果写入一个. csv 文件，然后在竞赛网站上提交。</p><figure class="nq nr ns nt gt ki"><div class="bz fp l di"><div class="nu nv l"/></div></figure><figure class="nq nr ns nt gt ki gh gi paragraph-image"><div class="gh gi om"><img src="../Images/0ac7965e6c0b98b5914c69c66ce99a80.png" data-original-src="https://miro.medium.com/v2/resize:fit:930/format:webp/1*Dw_-lCs-DYgKil5bFyZCkQ.png"/></div><figcaption class="kp kq gj gh gi kr ks bd b be z dk">CSV FIle to be submitted</figcaption></figure><p id="f2b2" class="pw-post-body-paragraph ku kv it kw b kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq ka im bi translated">看看 Khush Patel 的令人惊叹的内核，它以 99.18%的准确率赢得了黑客马拉松的冠军。他使用了 inceptionV3 架构，带有 CrossEntropyLoss 和一个 SGD 优化器。你的模型能打败这个吗？:)</p><p id="20c0" class="pw-post-body-paragraph ku kv it kw b kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq ka im bi translated">你可以在 Kaggle 上参加<a class="ae kt" href="https://www.kaggle.com/c/virtual-hack/overview" rel="noopener ugc nofollow" target="_blank">的班级竞赛。</a></p></div><div class="ab cl op oq hx or" role="separator"><span class="os bw bk ot ou ov"/><span class="os bw bk ot ou ov"/><span class="os bw bk ot ou"/></div><div class="im in io ip iq"><p id="24f6" class="pw-post-body-paragraph ku kv it kw b kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq ka im bi translated">我们结束了。</p><p id="fe07" class="pw-post-body-paragraph ku kv it kw b kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq ka im bi translated">恭喜👏这是一篇很长的文章，但你坚持到了最后。现在你可以用迁移学习建立你自己的模型。代码是可重用的，您也可以将它用于其他数据集。</p><p id="eb4f" class="pw-post-body-paragraph ku kv it kw b kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq ka im bi translated">感谢阅读！你可以随时在 Twitter 和 LinkedIn 上联系。</p><p id="e5d5" class="pw-post-body-paragraph ku kv it kw b kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq ka im bi translated"><strong class="kw iu">参考文献</strong></p><p id="50f2" class="pw-post-body-paragraph ku kv it kw b kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq ka im bi translated">[1] F. Zaidi，<a class="ae kt" href="https://www.datascience.com/blog/transfer-learning-in-pytorch-part-one" rel="noopener ugc nofollow" target="_blank">py torch 中的迁移学习，第 1 部分:如何使用数据加载器并构建完全连接的类</a> (2019)</p><p id="18c9" class="pw-post-body-paragraph ku kv it kw b kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq ka im bi translated">[2] G. Adjei，<a class="ae kt" href="https://heartbeat.fritz.ai/transfer-learning-with-pytorch-cfcb69016c72" rel="noopener ugc nofollow" target="_blank">用 PyTorch </a>，(2019)，心跳</p></div></div>    
</body>
</html>