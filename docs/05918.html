<html>
<head>
<title>Deep Learning using Transfer Learning -Python Code for ResNet50</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用迁移学习的深度学习-用于 ResNet50 的 Python 代码</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/deep-learning-using-transfer-learning-python-code-for-resnet50-8acdfb3a2d38?source=collection_archive---------0-----------------------#2019-08-29">https://towardsdatascience.com/deep-learning-using-transfer-learning-python-code-for-resnet50-8acdfb3a2d38?source=collection_archive---------0-----------------------#2019-08-29</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><p id="7cb4" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">这是本系列的第二部分，我们将使用 ResNet50 编写应用迁移学习的代码。在这里，我们将使用迁移学习，使用预训练的 ResNet50 模型，然后微调 ResNet50。</p><p id="23b4" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><a class="ae ko" href="https://medium.com/@arshren/deep-learning-using-transfer-learning-cfbce1578659" rel="noopener">迁移学习概念</a>第一部分</p><p id="3df1" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">对于代码实现，我们将使用<a class="ae ko" href="https://github.com/keras-team/keras-applications/blob/master/keras_applications/resnet50.py" rel="noopener ugc nofollow" target="_blank"> ResNet50 </a>。ResNet 是<a class="ae ko" href="https://arxiv.org/pdf/1512.03385.pdf" rel="noopener ugc nofollow" target="_blank">残网</a>的简称。这是一个 50 层的剩余网络</p><h1 id="9e42" class="kp kq it bd kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm bi translated">ResNet50</h1><p id="5933" class="pw-post-body-paragraph jq jr it js b jt ln jv jw jx lo jz ka kb lp kd ke kf lq kh ki kj lr kl km kn im bi translated">当我们向深层神经网络添加更多层时，性能会变得停滞不前或开始下降。这是由于消失梯度问题造成的。当梯度通过深度神经网络反向传播并重复相乘时，这使得梯度非常小，从而导致消失梯度问题。</p><p id="35cf" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">ResNet 通过使用<strong class="js iu">标识快捷连接或跳过一层或多层的跳过连接</strong>解决了渐变消失的问题。S <strong class="js iu">快捷连接将第 N 层的输出连接到第 N+Z 层的输入</strong></p><p id="b114" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">我们将使用<a class="ae ko" href="https://www.kaggle.com/c/dogs-vs-cats/data" rel="noopener ugc nofollow" target="_blank">猫狗数据集</a>来演示迁移学习使用</p><ul class=""><li id="eaf6" class="ls lt it js b jt ju jx jy kb lu kf lv kj lw kn lx ly lz ma bi translated">预训练的 ResNet50 模型作为特征提取器</li><li id="d274" class="ls lt it js b jt mb jx mc kb md kf me kj mf kn lx ly lz ma bi translated">微调预训练模型 ResNet50</li></ul><h1 id="e2ec" class="kp kq it bd kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm bi translated">创建数据集</h1><p id="251f" class="pw-post-body-paragraph jq jr it js b jt ln jv jw jx lo jz ka kb lp kd ke kf lq kh ki kj lr kl km kn im bi translated">导入基本库。我们将在需要时导入额外的库</p><pre class="mg mh mi mj gt mk ml mm mn aw mo bi"><span id="b3f9" class="mp kq it ml b gy mq mr l ms mt">import glob<br/>import numpy as np<br/>import pandas as pd<br/>import os<br/>import shutil <br/>import matplotlib.pyplot as plt<br/>from keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array, array_to_img<br/>%matplotlib inline</span></pre><p id="d653" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">我已经把所有的猫和狗的图片保存在了 dogs-vs-cats 文件夹中。我们读了猫狗档案。我们有 25003 张猫和狗的图片</p><pre class="mg mh mi mj gt mk ml mm mn aw mo bi"><span id="e75a" class="mp kq it ml b gy mq mr l ms mt">files = glob.glob('E:\\Data\\Images\\dogs-vs-cats\\*') <br/> <br/>cat_files = [fn for fn in files if 'cat' in fn] <br/>dog_files = [fn for fn in files if 'dog' in fn] <br/>len(cat_files), len(dog_files)</span></pre><p id="be52" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">我在一个较小的数据集上进行训练，因此减少了我的训练、测试和验证数据集的大小。如果您想在所有图像上进行训练，则不需要此步骤。</p><p id="44b5" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">训练数据集将具有每只猫和狗 1500 张图像，测试数据集将具有每只猫和狗 500 张图像，验证数据集也将具有每只猫和狗 500 张图像</p><pre class="mg mh mi mj gt mk ml mm mn aw mo bi"><span id="c942" class="mp kq it ml b gy mq mr l ms mt">cat_train = np.random.choice(cat_files, size=1500, replace=False) <br/>dog_train = np.random.choice(dog_files, size=1500, replace=False) <br/>cat_files = list(set(cat_files) — set(cat_train)) <br/>dog_files = list(set(dog_files) — set(dog_train)) <br/> <br/>cat_val = np.random.choice(cat_files, size=500, replace=False) <br/>dog_val = np.random.choice(dog_files, size=500, replace=False) <br/>cat_files = list(set(cat_files) — set(cat_val)) <br/>dog_files = list(set(dog_files) — set(dog_val)) <br/> <br/>cat_test = np.random.choice(cat_files, size=500, replace=False) <br/>dog_test = np.random.choice(dog_files, size=500, replace=False) <br/> <br/>print(‘Cat datasets:’, cat_train.shape, cat_val.shape, cat_test.shape) <br/>print(‘Dog datasets:’, dog_train.shape, dog_val.shape, dog_test.shape)</span></pre><p id="399c" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">加载训练和验证数据集。我们的图像尺寸将是 300×300 像素</p><pre class="mg mh mi mj gt mk ml mm mn aw mo bi"><span id="f2b7" class="mp kq it ml b gy mq mr l ms mt"><strong class="ml iu">IMG_WIDTH=300<br/>IMG_HEIGHT=300<br/>IMG_DIM = (IMG_WIDTH, IMG_HEIGHT)</strong></span><span id="ca40" class="mp kq it ml b gy mu mr l ms mt">train_files = glob.glob(‘E:\\Data\\Images\\dogs-vs-cats\\training_data\\*’)</span><span id="6d7d" class="mp kq it ml b gy mu mr l ms mt">train_imgs = [img_to_array(load_img(img, target_size=IMG_DIM)) for img in train_files]<br/>train_imgs = np.array(train_imgs)<br/>train_labels = [fn.split(‘\\’)[-1].split(‘.’)[0].strip() for fn in train_files]</span><span id="fc6f" class="mp kq it ml b gy mu mr l ms mt">validation_files = glob.glob(‘E:\\Data\\Images\\dogs-vs-cats\\validation_data\\*’)<br/>validation_imgs = [img_to_array(load_img(img, target_size=IMG_DIM)) for img in validation_files]<br/>validation_imgs = np.array(validation_imgs)<br/>validation_labels = [fn.split(‘\\’)[-1].split(‘.’)[0].strip() for fn in validation_files]</span><span id="8ca5" class="mp kq it ml b gy mu mr l ms mt">print(‘Train dataset shape:’, train_imgs.shape, <br/> ‘\tValidation dataset shape:’, validation_imgs.shape)</span></pre><p id="494d" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">现在，每个图像的大小为 300 x 300，并具有红色、绿色和蓝色(RGB)三个通道。</p><p id="eef7" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">图像的像素值介于 0 和 255 之间。深度神经网络在较小的输入值下工作良好。用 0 到 1 之间的值缩放每个图像。</p><pre class="mg mh mi mj gt mk ml mm mn aw mo bi"><span id="3379" class="mp kq it ml b gy mq mr l ms mt">train_imgs_scaled = train_imgs.astype(‘float32’) <br/>validation_imgs_scaled = validation_imgs.astype(‘float32’) <br/>train_imgs_scaled /= 255 <br/>validation_imgs_scaled /= 255 <br/> <br/># visualize a sample image <br/>print(train_imgs[0].shape) <br/>array_to_img(train_imgs[0]</span></pre><figure class="mg mh mi mj gt mw gh gi paragraph-image"><div class="gh gi mv"><img src="../Images/5f3f795e5e06cbf6a084fc346a29e418.png" data-original-src="https://miro.medium.com/v2/resize:fit:926/format:webp/1*oiA_R59skWFaKLOnoR9gxQ.png"/></div></figure><p id="5faf" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">对猫和狗的文本类别标签进行编码</p><pre class="mg mh mi mj gt mk ml mm mn aw mo bi"><span id="37ba" class="mp kq it ml b gy mq mr l ms mt"># encode text category labels <br/>from sklearn.preprocessing import LabelEncoder <br/> <br/>le = LabelEncoder() <br/>le.fit(train_labels) <br/>train_labels_enc = le.transform(train_labels) <br/>validation_labels_enc = le.transform(validation_labels) <br/> <br/>print(train_labels[1495:1505], train_labels_enc[1495:1505])</span></pre><figure class="mg mh mi mj gt mw gh gi paragraph-image"><div role="button" tabindex="0" class="na nb di nc bf nd"><div class="gh gi mz"><img src="../Images/f07757cfe7245e0a17b258d372b44f0f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ygO8E4q1ITcQ_9j9zFC_dw.png"/></div></div></figure><h2 id="96ff" class="mp kq it bd kr ne nf dn kv ng nh dp kz kb ni nj ld kf nk nl lh kj nm nn ll no bi translated">将数据增强应用于图像</h2><p id="05f8" class="pw-post-body-paragraph jq jr it js b jt ln jv jw jx lo jz ka kb lp kd ke kf lq kh ki kj lr kl km kn im bi translated">Keras 框架有一个优秀的实用工具，叫做<strong class="js iu"> ImageDataGenerator。</strong>通过实时数据增强生成批量张量图像数据。</p><p id="bf8d" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">对于我们的训练和验证数据集，我们将使用 zoom_range 参数将图像随机缩放 0.3 倍。我们使用 rotation_range 参数将图像随机旋转 50 度。使用 width_shift_range 和 height_shift_range 参数，以图像宽度或高度的 0.2 倍水平或垂直随机平移图像。使用 shear_range 参数随机应用基于剪切的变换。使用 horizontal_flip 参数随机水平翻转一半的图像。在我们应用任何前面的操作(尤其是旋转或平移)之后，利用 fill_mode 参数为图像填充新的像素。在这种情况下，我们只是用最近的周围像素值填充新像素。</p><pre class="mg mh mi mj gt mk ml mm mn aw mo bi"><span id="469f" class="mp kq it ml b gy mq mr l ms mt">train_datagen = ImageDataGenerator(rescale=1./255, zoom_range=0.3, rotation_range=50,<br/> width_shift_range=0.2, height_shift_range=0.2, shear_range=0.2, <br/> horizontal_flip=True, fill_mode=’nearest’)</span><span id="2ab1" class="mp kq it ml b gy mu mr l ms mt">val_datagen = ImageDataGenerator(rescale=1./255)</span></pre><p id="5c92" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">让我们看看一些增强图像是什么样子的。我们将从我们的训练数据集中选取两个样本图像来说明这一点。第一个图像是猫的图像，第二个图像是狗的图像</p><pre class="mg mh mi mj gt mk ml mm mn aw mo bi"><span id="3bcf" class="mp kq it ml b gy mq mr l ms mt">img_id = 2500<br/>cat_generator = train_datagen.flow(train_imgs[img_id:img_id+1], <br/> train_labels[img_id:img_id+1], <br/> batch_size=1) <br/>cat = [next(cat_generator) for i in range(0,5)] <br/>fig, ax = plt.subplots(1,5, figsize=(16, 6))</span><span id="616f" class="mp kq it ml b gy mu mr l ms mt">print(‘Labels:’, [item[1][0] for item in cat]) <br/>l = [ax[i].imshow(cat[i][0][0]) for i in range(0,5)]</span></pre><figure class="mg mh mi mj gt mw gh gi paragraph-image"><div role="button" tabindex="0" class="na nb di nc bf nd"><div class="gh gi np"><img src="../Images/e20eab634eab7f93578d6b19bb8886f1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*tapODw8yAorzE7iopKH8Pw.png"/></div></div></figure><pre class="mg mh mi mj gt mk ml mm mn aw mo bi"><span id="9497" class="mp kq it ml b gy mq mr l ms mt">img_id = 4001 <br/>dog_generator = train_datagen.flow(train_imgs[img_id:img_id+1], <br/> train_labels[img_id:img_id+1], <br/> batch_size=1) <br/>dog = [next(dog_generator) for i in range(0,5)] <br/>fig, ax = plt.subplots(1,5, figsize=(15, 6)) <br/>print(‘Labels:’, [item[1][0] for item in dog]) <br/>l = [ax[i].imshow(dog[i][0][0]) for i in range(0,5)]</span></pre><figure class="mg mh mi mj gt mw gh gi paragraph-image"><div role="button" tabindex="0" class="na nb di nc bf nd"><div class="gh gi nq"><img src="../Images/4811b8e3570bbdd7dc09086c4ca1458b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*q6mVUGm5HjqbRbkTRx76jQ.png"/></div></div></figure><p id="70d9" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">对于我们的测试生成器，我们需要将原始测试图像发送给模型进行评估。我们只是在 0 和 1 之间缩放图像像素，并且不应用任何变换。</p><p id="8efe" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">我们只是将图像增强变换仅应用于我们的训练集图像和验证图像</p><pre class="mg mh mi mj gt mk ml mm mn aw mo bi"><span id="7ede" class="mp kq it ml b gy mq mr l ms mt">train_generator = train_datagen.flow(train_imgs, train_labels_enc,batch_size=30)</span><span id="137b" class="mp kq it ml b gy mu mr l ms mt">val_generator = val_datagen.flow(validation_imgs, validation_labels_enc, batch_size=30)</span></pre><h1 id="2190" class="kp kq it bd kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm bi translated">使用预训练模型作为特征提取器的迁移学习</h1><p id="b3a5" class="pw-post-body-paragraph jq jr it js b jt ln jv jw jx lo jz ka kb lp kd ke kf lq kh ki kj lr kl km kn im bi translated">我们使用 ResNet50 深度学习模型作为迁移学习的特征提取的预训练模型。</p><ul class=""><li id="f1ee" class="ls lt it js b jt ju jx jy kb lu kf lv kj lw kn lx ly lz ma bi translated">为了实现迁移学习，我们将删除预训练 ResNet50 模型的最后一个预测层，并用我们自己的预测层来替换它们。FC-T1 和 FC_T2 如下所示</li><li id="4d03" class="ls lt it js b jt mb jx mc kb md kf me kj mf kn lx ly lz ma bi translated">使用 ResNet50 预训练模型的权重作为特征提取器</li><li id="f72c" class="ls lt it js b jt mb jx mc kb md kf me kj mf kn lx ly lz ma bi translated">预训练模型的权重被冻结，并且在训练期间不被更新</li></ul><figure class="mg mh mi mj gt mw gh gi paragraph-image"><div class="gh gi nr"><img src="../Images/00056c7e7d83b77d37d70f6fb31b998e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1316/format:webp/1*1rUm4OpT_HXl6-HFCW9fUw.png"/></div></figure><p id="364a" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">我们不想加载充当分类器的最后完全连接的层。我们通过使用“<strong class="js iu"> include_top=False </strong>”来实现这一点。我们这样做是为了<strong class="js iu">我们可以在 ResNet50 模型之上添加我们自己的全连接层，用于我们的特定任务分类。</strong></p><p id="eda6" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu">我们通过设置可训练为“假”来冻结模型的权重</strong>。这将在训练期间停止对预训练权重的任何更新。我们不希望训练 ResNet 层，因为我们希望利用深度神经网络从以前的数据集(在我们的情况下是“imagenet ”)中训练的知识</p><pre class="mg mh mi mj gt mk ml mm mn aw mo bi"><span id="19c4" class="mp kq it ml b gy mq mr l ms mt">from keras.applications.resnet50 import ResNet50<br/>from keras.models import Model<br/>import keras</span><span id="9880" class="mp kq it ml b gy mu mr l ms mt"><strong class="ml iu">restnet = ResNet50(include_top=False, weights='imagenet', input_shape=(IMG_HEIGHT,IMG_WIDTH,3))</strong></span><span id="c24d" class="mp kq it ml b gy mu mr l ms mt">output = restnet.layers[-1].output<br/>output = keras.layers.Flatten()(output)</span><span id="8914" class="mp kq it ml b gy mu mr l ms mt">restnet = Model(restnet.input, output=output)</span><span id="204a" class="mp kq it ml b gy mu mr l ms mt">for layer in restnet.layers:<br/>    <strong class="ml iu">layer.trainable = False</strong></span><span id="b5dc" class="mp kq it ml b gy mu mr l ms mt">restnet.summary()</span></pre><figure class="mg mh mi mj gt mw gh gi paragraph-image"><div role="button" tabindex="0" class="na nb di nc bf nd"><div class="gh gi ns"><img src="../Images/d7203c26db45502de5f9b0feed6f0ebb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*S4Wlk_kiPuJ5MIgyFy1VEA.png"/></div></div><figcaption class="nt nu gj gh gi nv nw bd b be z dk">ResNet50 with 23, 587,712 frozen weights</figcaption></figure><p id="21ff" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">现在，我们使用迁移学习，通过添加我们自己的全连接层和使用 sigmoid 激活函数的最终分类器，使用预训练的 ResNet50 来创建我们的模型。</p><pre class="mg mh mi mj gt mk ml mm mn aw mo bi"><span id="cf22" class="mp kq it ml b gy mq mr l ms mt">from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, InputLayer<br/>from keras.models import Sequential<br/>from keras import optimizers</span><span id="23d6" class="mp kq it ml b gy mu mr l ms mt">model = Sequential()<br/>model.add(restnet)<br/>model.add(Dense(512, activation='relu', input_dim=input_shape))<br/>model.add(Dropout(0.3))<br/>model.add(Dense(512, activation='relu'))<br/>model.add(Dropout(0.3))<br/>model.add(Dense(1, activation='sigmoid'))</span><span id="20d4" class="mp kq it ml b gy mu mr l ms mt">model.compile(loss='binary_crossentropy',<br/>              optimizer=optimizers.RMSprop(lr=2e-5),<br/>              metrics=['accuracy'])<br/>model.summary()</span></pre><figure class="mg mh mi mj gt mw gh gi paragraph-image"><div role="button" tabindex="0" class="na nb di nc bf nd"><div class="gh gi nx"><img src="../Images/e0c594af7930d7d047c6120f208d5a8b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*5pxFqZ0YM22FMfpK8Yu5CA.png"/></div></div></figure><p id="6149" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">我们看到 ResNet50 的重量是不可训练的，因为我们已经冻结了它们。</p><p id="67f6" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">我们现在运行这个模型</p><pre class="mg mh mi mj gt mk ml mm mn aw mo bi"><span id="415b" class="mp kq it ml b gy mq mr l ms mt">history = model.fit_generator(train_generator, <br/>                              steps_per_epoch=100, <br/>                              epochs=100,<br/>                              validation_data=val_generator, <br/>                              validation_steps=50, <br/>                              verbose=1)</span></pre><p id="c8b5" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">保存训练过的重量</p><pre class="mg mh mi mj gt mk ml mm mn aw mo bi"><span id="0df5" class="mp kq it ml b gy mq mr l ms mt">model.save(‘cats_dogs_tlearn_img_aug_cnn_restnet50.h5’)</span></pre><h1 id="c744" class="kp kq it bd kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm bi translated">微调预先训练的模型</h1><ul class=""><li id="f01b" class="ls lt it js b jt ln jx lo kb ny kf nz kj oa kn lx ly lz ma bi translated">我们可以使用深度神经网络，如 VGG-16，VGG-19，Inception V3，ResNet-50，Xception 作为预训练模型</li><li id="dd6f" class="ls lt it js b jt mb jx mc kb md kf me kj mf kn lx ly lz ma bi translated">为了实现带有微调的迁移学习，我们删除了预训练模型的最后一个预测层，并用我们自己的预测层来替换它们。FC-T1 和 FC_T2 如下所示。</li><li id="eb8e" class="ls lt it js b jt mb jx mc kb md kf me kj mf kn lx ly lz ma bi translated">网络的初始较低层从预先训练的模型中学习非常一般的特征。为了实现这一点，预训练模型的初始层权重被冻结，并且在训练期间不被更新</li><li id="d250" class="ls lt it js b jt mb jx mc kb md kf me kj mf kn lx ly lz ma bi translated">较高层用于学习特定任务的特征。预训练模型的更高层是可训练的或可微调的</li><li id="3f5d" class="ls lt it js b jt mb jx mc kb md kf me kj mf kn lx ly lz ma bi translated">用更少的培训时间提高绩效</li></ul><figure class="mg mh mi mj gt mw gh gi paragraph-image"><div role="button" tabindex="0" class="na nb di nc bf nd"><div class="gh gi ob"><img src="../Images/08cd10a4e275683a16f39035500a62da.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*furTQNGfh9pDeW97_WBOHA.png"/></div></div></figure><p id="16a7" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">我们已经用图像增强创建了数据集，并且我们已经创建了基本的 ResNet50 模型。</p><p id="b5d3" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">我们现在将使用 ResNet50 通过图像增强来微调迁移学习。我们通过解冻一些最后的卷积块，同时保持最初的早期 conv 块冻结来实现这一点。这将有助于我们使用早期图层学习非常通用的功能。预训练模型的更高层将是可训练的或微调的。</p><pre class="mg mh mi mj gt mk ml mm mn aw mo bi"><span id="b1b9" class="mp kq it ml b gy mq mr l ms mt">restnet.trainable = True</span><span id="4fc7" class="mp kq it ml b gy mu mr l ms mt">set_trainable = False</span><span id="deb0" class="mp kq it ml b gy mu mr l ms mt">for layer in restnet.layers:<br/>    if layer.name in ['res5c_branch2b', 'res5c_branch2c', 'activation_97']:<br/>        set_trainable = True<br/>    if set_trainable:<br/>        layer.trainable = True<br/>    else:<br/>        layer.trainable = False</span><span id="50d3" class="mp kq it ml b gy mu mr l ms mt">layers = [(layer, layer.name, layer.trainable) for layer in restnet.layers]<br/>pd.DataFrame(layers, columns=['Layer Type', 'Layer Name', 'Layer Trainable'])</span></pre><figure class="mg mh mi mj gt mw gh gi paragraph-image"><div role="button" tabindex="0" class="na nb di nc bf nd"><div class="gh gi oc"><img src="../Images/24a860db0cc599a3ae93cbd7bc52d64e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*xuER8OOlxmbEnCZZo6JqUA.png"/></div></div></figure><p id="e7ad" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">我们看到，我们已经将 ResNet50 的早期层的训练设置为 false，ResNet50 的最后几层现在是可训练的。</p><p id="f67e" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">我们现在在 ResNet50 上添加我们自己的全连接层和分类器。我们已经从 ResNet50 中移除了最后一个完全连接的层和分类器层</p><pre class="mg mh mi mj gt mk ml mm mn aw mo bi"><span id="698d" class="mp kq it ml b gy mq mr l ms mt">from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, InputLayer<br/>from keras.models import Sequential<br/>from keras import optimizers</span><span id="d059" class="mp kq it ml b gy mu mr l ms mt">model_finetuned = Sequential()<br/>model_finetuned.add(restnet)<br/>model_finetuned.add(Dense(512, activation='relu', input_dim=input_shape))<br/>model_finetuned.add(Dropout(0.3))<br/>model_finetuned.add(Dense(512, activation='relu'))<br/>model_finetuned.add(Dropout(0.3))<br/>model_finetuned.add(Dense(1, activation='sigmoid'))</span><span id="689c" class="mp kq it ml b gy mu mr l ms mt">model_finetuned.compile(loss='binary_crossentropy',<br/>              optimizer=optimizers.RMSprop(lr=1e-5),<br/>              metrics=['accuracy'])</span><span id="1620" class="mp kq it ml b gy mu mr l ms mt">model_finetuned.summary()</span></pre><figure class="mg mh mi mj gt mw gh gi paragraph-image"><div role="button" tabindex="0" class="na nb di nc bf nd"><div class="gh gi od"><img src="../Images/6e59803add919a73abc80c9ebd5cd765.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*O97Vpswa_qOy_N1FpDPZhA.png"/></div></div></figure><p id="113f" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">我们最终运行了这个模型</p><pre class="mg mh mi mj gt mk ml mm mn aw mo bi"><span id="5399" class="mp kq it ml b gy mq mr l ms mt">history_1 = model_finetuned.fit_generator(train_generator, <br/>                                  steps_per_epoch=100, <br/>                                  epochs=2,<br/>                                  validation_data=val_generator, <br/>                                  validation_steps=100, <br/>                                  verbose=1)</span></pre><p id="7a2a" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">保存微调模型的权重</p><pre class="mg mh mi mj gt mk ml mm mn aw mo bi"><span id="3aa4" class="mp kq it ml b gy mq mr l ms mt">model.save(‘cats_dogs_tlearn_finetune_img_aug_restnet50.h5’)</span></pre><h2 id="9d61" class="mp kq it bd kr ne nf dn kv ng nh dp kz kb ni nj ld kf nk nl lh kj nm nn ll no bi translated">参考资料:</h2><p id="cca9" class="pw-post-body-paragraph jq jr it js b jt ln jv jw jx lo jz ka kb lp kd ke kf lq kh ki kj lr kl km kn im bi translated">关于迁移学习的调查</p><p id="3dc8" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><a class="ae ko" rel="noopener" target="_blank" href="/a-comprehensive-hands-on-guide-to-transfer-learning-with-real-world-applications-in-deep-learning-212bf3b2f27a">一份全面的实践指南，旨在将学习转化为深度学习中的实际应用</a></p><p id="4a11" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><a class="ae ko" href="https://github.com/dipanjanS/hands-on-transfer-learning-with-python/blob/master/notebooks/Ch05%20-%20Unleash%20the%20Power%20of%20Transfer%20Learning/CNN%20with%20Transfer%20Learning.ipynb" rel="noopener ugc nofollow" target="_blank"> GitHub 用 Python 进行实际迁移学习</a></p></div></div>    
</body>
</html>