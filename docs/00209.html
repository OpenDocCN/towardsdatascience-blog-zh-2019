<html>
<head>
<title>A Comprehensive Guide To Object Detection Using YOLO Framework — Part II</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">利用 YOLO 框架进行目标探测的综合指南——第二部分</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/object-detection-part2-6a265827efe1?source=collection_archive---------10-----------------------#2019-01-09">https://towardsdatascience.com/object-detection-part2-6a265827efe1?source=collection_archive---------10-----------------------#2019-01-09</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="e5a8" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">使用 Python 实现</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi kf"><img src="../Images/799754050dbdc65d0a82421468c53a8d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1120/format:webp/1*ke01D55BF4eRd6xuu-v6Dg.png"/></div><figcaption class="kn ko gj gh gi kp kq bd b be z dk">Cover Image (Source: Author)</figcaption></figure><p id="b4fd" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi ln translated">在最后一部分，我们了解了 YOLO 是什么以及它是如何工作的。在本节中，让我们了解如何使用预先训练的权重应用它并获得结果。这篇文章受到了<a class="ae lw" href="https://www.coursera.org/specializations/deep-learning" rel="noopener ugc nofollow" target="_blank">吴恩达深度学习专业化</a>课程的极大启发。我还试图从各种其他文章/资源中收集信息，以使这个概念更容易理解。</p><p id="c34e" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">现在是时候使用 Python 实现我们所理解的内容了。您可以借助 Jupyter 笔记本电脑(或您选择的任何其他 IDE)来完成这项工作。YOLO 的实现取自<a class="ae lw" href="https://github.com/enggen/Deep-Learning-Coursera" rel="noopener ugc nofollow" target="_blank">吴恩达的 Github 库</a>。您还必须下载这个<a class="ae lw" href="https://drive.google.com/open?id=1j3N1Tp112CfDzRchwa3d-D2zksChMVtY" rel="noopener ugc nofollow" target="_blank"> zip 文件</a>，其中包含预训练的权重和包来实现 YOLO。这里有一个<a class="ae lw" href="https://github.com/iampratheesh/Object-Detection-YOLO" rel="noopener ugc nofollow" target="_blank">链接</a>到我的 GitHub 库，你可以在那里找到 Jupyter 笔记本。</p><p id="723f" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">为了更好地理解，我已经尝试对尽可能多的代码行进行注释。</p><h1 id="8df3" class="lx ly iq bd lz ma mb mc md me mf mg mh jw mi jx mj jz mk ka ml kc mm kd mn mo bi translated">导入库:</h1><p id="bd8a" class="pw-post-body-paragraph kr ks iq kt b ku mp jr kw kx mq ju kz la mr lc ld le ms lg lh li mt lk ll lm ij bi translated">让我们首先导入所有需要的库。</p><pre class="kg kh ki kj gt mu mv mw mx aw my bi"><span id="c7d8" class="mz ly iq mv b gy na nb l nc nd">import os<br/>import imageio<br/>import matplotlib.pyplot as plt<br/>from matplotlib.pyplot import imshow<br/>import scipy.io<br/>import scipy.misc<br/>import numpy as np<br/>import pandas as pd<br/>import PIL<br/>import tensorflow as tf<br/>from skimage.transform import resize<br/>from keras import backend as K<br/>from keras.layers import Input, Lambda, Conv2D<br/>from keras.models import load_model, Model<br/>from yolo_utils import read_classes, read_anchors, generate_colors, preprocess_image,draw_boxes, scale_boxes<br/>from yad2k.models.keras_yolo import yolo_head, yolo_boxes_to_corners, preprocess_true_boxes, yolo_loss, yolo_body<br/>%matplotlib inline</span></pre><h1 id="7533" class="lx ly iq bd lz ma mb mc md me mf mg mh jw mi jx mj jz mk ka ml kc mm kd mn mo bi translated">应用过滤器:</h1><p id="da11" class="pw-post-body-paragraph kr ks iq kt b ku mp jr kw kx mq ju kz la mr lc ld le ms lg lh li mt lk ll lm ij bi translated">首先，我们将应用阈值过滤器。我们可以通过去掉那些分数低于所选阈值的盒子来做到这一点。</p><p id="b447" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">该模型包含 80 个不同的检测类别。它总共给出了 19x19x5x85 个数字，其中:</p><p id="7e37" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">19x19:网格的形状</p><p id="fc65" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">5:锚箱数量</p><p id="ff1d" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">85:每盒包含 85 个号码(Pc，bx，by，bh，bw，c1，c2…..c80)</p><pre class="kg kh ki kj gt mu mv mw mx aw my bi"><span id="ad91" class="mz ly iq mv b gy na nb l nc nd">def yolo_filter_boxes(box_confidence, boxes, box_class_probs, threshold = .6):</span><span id="90a6" class="mz ly iq mv b gy ne nb l nc nd">'''<br/>box confidence: tensor of shape (19,19,5,1) containing Pc<br/>boxes: tensor of shape (19,19,5,4)<br/>box_class_probs: tensor of shape (19,19,5,80)<br/>threshold: if Pc&lt;threshold, get rid of that box<br/>'''<br/>    #Computing box scores<br/>    box_scores = box_confidence*box_class_probs</span><span id="ffc4" class="mz ly iq mv b gy ne nb l nc nd">    #Finding the index of the class with maximum box score<br/>    box_classes = K.argmax(box_scores, -1)</span><span id="f43c" class="mz ly iq mv b gy ne nb l nc nd">    #Getting the corresponding box score<br/>    box_class_scores = K.max(box_scores,-1)</span><span id="8dcd" class="mz ly iq mv b gy ne nb l nc nd">    #Creating a filtering mask. The mask will be true for all the boxes        we intend to keep (pc &gt;= threshold) and false for the rest<br/>    filtering_mask = box_class_scores&gt;threshold</span><span id="07e5" class="mz ly iq mv b gy ne nb l nc nd">    #Applying the mask to scores, boxes and classes<br/>    scores = tf.boolean_mask(box_class_scores, filtering_mask)<br/>    boxes = tf.boolean_mask(boxes, filtering_mask)<br/>    classes = tf.boolean_mask(box_classes, filtering_mask)</span><span id="0a83" class="mz ly iq mv b gy ne nb l nc nd">'''<br/>scores: contains class probability score for the selected boxes<br/>boxes: contains (bx,by,bh,bw) coordinates of selected boxes<br/>classes: contains the index of class detected by the selected boxes<br/>'''    <br/>    return scores, boxes, classes</span></pre><h1 id="2367" class="lx ly iq bd lz ma mb mc md me mf mg mh jw mi jx mj jz mk ka ml kc mm kd mn mo bi translated">实现并集上的交集(IoU):</h1><p id="9119" class="pw-post-body-paragraph kr ks iq kt b ku mp jr kw kx mq ju kz la mr lc ld le ms lg lh li mt lk ll lm ij bi translated">现在我们要实现 IoU。这将用于评估边界框。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="ng nh di ni bf nj"><div class="gh gi nf"><img src="../Images/eb5636c15f3da7c8c1fb4480df88cbcd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*H9tZoYlNb_jbco1WkRiHUQ.jpeg"/></div></div><figcaption class="kn ko gj gh gi kp kq bd b be z dk">Intersection over Union (Edited by Author)</figcaption></figure><p id="c84c" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">我们将使用它的两个角(左上角和右下角)来定义一个盒子。坐标可以命名为(x1，y1，x2，y2)。</p><p id="d08b" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">我们还必须找出两个盒子的交点坐标。</p><p id="6586" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated"><strong class="kt ir"> xi1: </strong>两个框的 x1 坐标的最大值。</p><p id="f4a9" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated"><strong class="kt ir"> yi1: </strong>两个框的 y1 坐标的最大值。</p><p id="12d2" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated"><strong class="kt ir"> xi2: </strong>两个框的 x2 坐标的最小值。</p><p id="55d7" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated"><strong class="kt ir"> yi2: </strong>两个框的 y2 坐标的最小值。</p><p id="603d" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">相交后形成的矩形的面积可以使用公式计算:(xi2-xi1)*(yi2-yi1)</p><p id="52df" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">计算借据的公式是:</p><pre class="kg kh ki kj gt mu mv mw mx aw my bi"><span id="d925" class="mz ly iq mv b gy na nb l nc nd">(Intersection area)/(Union area)</span></pre><p id="4014" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">现在让我们定义一个函数来计算 IoU。</p><pre class="kg kh ki kj gt mu mv mw mx aw my bi"><span id="2d0e" class="mz ly iq mv b gy na nb l nc nd">def iou(box1, box2):</span><span id="54d0" class="mz ly iq mv b gy ne nb l nc nd">    #Calculating (xi1,yi1,xi2,yi2) of the intersection of box1 and box2 <br/>    xi1 = max(box1[0], box2[0])<br/>    yi1 = max(box1[1], box2[1])<br/>    xi2 = min(box1[2], box2[2])<br/>    yi2 = min(box1[3], box2[3])<br/>    #Calculating the area of intersection<br/>    inter_area = (yi2-yi1)*(xi2-xi1)</span><span id="4bb6" class="mz ly iq mv b gy ne nb l nc nd">    #Calculating the areas of box1 and box2 using the same formula<br/>    box1_area = (box1[3] - box1[1])*(box1[2] - box1[0])<br/>    box2_area = (box2[3] - box2[1])*(box2[2] - box2[0])<br/>    #Calculating the union area by using the formula: union(A,B) = A+B-Inter(A,B)<br/>    union_area = box1_area + box2_area - inter_area</span><span id="bd5b" class="mz ly iq mv b gy ne nb l nc nd">    #Calculating iou<br/>    iou = inter_area/union_area<br/>    <br/>    return iou</span></pre><h1 id="72d7" class="lx ly iq bd lz ma mb mc md me mf mg mh jw mi jx mj jz mk ka ml kc mm kd mn mo bi translated">实施非最大抑制:</h1><p id="4ca4" class="pw-post-body-paragraph kr ks iq kt b ku mp jr kw kx mq ju kz la mr lc ld le ms lg lh li mt lk ll lm ij bi translated">接下来，我们将实现非最大抑制来移除同一对象的所有重复边界框。涉及的步骤有:</p><ol class=""><li id="9647" class="nk nl iq kt b ku kv kx ky la nm le nn li no lm np nq nr ns bi translated">选择得分最高的方框。</li><li id="acff" class="nk nl iq kt b ku nt kx nu la nv le nw li nx lm np nq nr ns bi translated">计算其与所有其他盒子的 IoU，并移除 IoU 大于所述阈值的那些盒子。</li><li id="d15d" class="nk nl iq kt b ku nt kx nu la nv le nw li nx lm np nq nr ns bi translated">重复此操作，直到不再有分数低于所选框的框。</li></ol><p id="2b2e" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">让我们来定义这个函数</p><pre class="kg kh ki kj gt mu mv mw mx aw my bi"><span id="9c51" class="mz ly iq mv b gy na nb l nc nd">def yolo_non_max_suppression(scores, boxes, classes, max_boxes = 10, iou_threshold = 0.5):</span><span id="0fc2" class="mz ly iq mv b gy ne nb l nc nd">    #tensor used in tf.image.non_max_suppression()of size 'max_boxes' <br/>    max_boxes_tensor = K.variable(max_boxes, dtype = 'int32')</span><span id="4a54" class="mz ly iq mv b gy ne nb l nc nd">    #initiating the tensor <br/>    K.get_session().run(tf.variables_initializer([max_boxes_tensor]))</span><span id="8db2" class="mz ly iq mv b gy ne nb l nc nd">    #Using the tensorflow function tf.image.non_max_suppression to get the indices of boxes kept<br/>    nms_indices = tf.image.non_max_suppression(boxes, scores, max_boxes, iou_threshold)</span><span id="39c1" class="mz ly iq mv b gy ne nb l nc nd">    #Using K.gather to individually access scores, boxes and classes from nms_indices<br/>    scores = K.gather(scores, nms_indices)<br/>    boxes = K.gather(boxes, nms_indices)<br/>    classes = K.gather(classes, nms_indices)<br/>    <br/>    return scores, boxes, classes</span></pre><h1 id="83de" class="lx ly iq bd lz ma mb mc md me mf mg mh jw mi jx mj jz mk ka ml kc mm kd mn mo bi translated">调用上面定义的函数:</h1><p id="e96e" class="pw-post-body-paragraph kr ks iq kt b ku mp jr kw kx mq ju kz la mr lc ld le ms lg lh li mt lk ll lm ij bi translated">现在是实现一个函数的时候了，该函数获取深度 CNN 的输出，然后使用上述函数过滤盒子。</p><p id="c706" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">注意，有几种方法可以表示一个边界框，即通过它们的角或中点和高度/宽度。YOLO 在几种格式之间进行转换，其中有一个名为“yolo _ boxes _ to _ corners”的函数。</p><p id="d385" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">此外，YOLO 还接受了 608 x 608 尺寸图像的训练。如果我们提供的图像的尺寸大于或小于原始尺寸(YOLO 在其上被训练),那么我们将不得不相应地重新缩放边界框以适合图像。为此，我们将使用一个名为“scale _ boxes”的函数。</p><pre class="kg kh ki kj gt mu mv mw mx aw my bi"><span id="7884" class="mz ly iq mv b gy na nb l nc nd">def yolo_eval(yolo_outputs, image_shape = (720., 1280.), max_boxes = 10, score_threshold = .6, iou_threshold = .5):</span><span id="70bb" class="mz ly iq mv b gy ne nb l nc nd">    '''<br/>    yolo_outputs contains:<br/>    box_confidence, box_xy, box_wh, box_class_probs<br/>    ''' </span><span id="2b20" class="mz ly iq mv b gy ne nb l nc nd">    #Retrieving output<br/>    box_confidence, box_xy, box_wh, box_class_probs = yolo_outputs</span><span id="d342" class="mz ly iq mv b gy ne nb l nc nd">    #Converting the boxes for filtering functions<br/>    boxes = yolo_boxes_to_corners(box_xy, box_wh)</span><span id="ab52" class="mz ly iq mv b gy ne nb l nc nd">    #Using the function defined before to remove boxes with less confidence score<br/>    scores, boxes, classes = yolo_filter_boxes(box_confidence, boxes, box_class_probs, threshold = score_threshold)</span><span id="4a53" class="mz ly iq mv b gy ne nb l nc nd">    #Scaling the boxes<br/>    boxes = scale_boxes(boxes, image_shape)</span><span id="c080" class="mz ly iq mv b gy ne nb l nc nd">    #Using the function defined before for non-max suppression<br/>   scores, boxes, classes = yolo_non_max_suppression(scores, boxes, classes, max_boxes, iou_threshold)<br/>    <br/>    return scores, boxes, classes</span></pre><h1 id="49a9" class="lx ly iq bd lz ma mb mc md me mf mg mh jw mi jx mj jz mk ka ml kc mm kd mn mo bi translated">加载预训练模型:</h1><p id="3526" class="pw-post-body-paragraph kr ks iq kt b ku mp jr kw kx mq ju kz la mr lc ld le ms lg lh li mt lk ll lm ij bi translated">现在，我们将在图像上测试 YOLO 预训练模型。为此，我们必须创建一个会话。此外，请记住，我们正在尝试检测 80 个类别，并使用 5 个锚盒。我们在“coco_classes.txt”和“yolo_anchors.txt”中有所有的课程信息，这些信息必须存在于您之前在“model_data”文件夹中下载的 zip 文件中。</p><p id="1c33" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">YOLO 模型的训练需要很长时间，尤其是如果你没有一个高规格的系统。因此，我们将加载存储在“yolo.h5”中的现有预训练的 Keras YOLO 模型。这些是 YOLOv2 模型的预训练重量。</p><p id="14a4" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">让我们创建一个会话并加载这些文件。</p><pre class="kg kh ki kj gt mu mv mw mx aw my bi"><span id="6ccd" class="mz ly iq mv b gy na nb l nc nd">sess = K.get_session()<br/>class_names = read_classes("model_data/coco_classes.txt")<br/>anchors = read_anchors("model_data/yolo_anchors.txt")<br/>yolo_model = load_model("model_data/yolo.h5")</span></pre><p id="9e61" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated"><strong class="kt ir"> <em class="ny">注意:</em> </strong> <em class="ny">在某些情况下，加载砝码时会弹出警告。如果是这种情况，就忽略警告。</em></p><pre class="kg kh ki kj gt mu mv mw mx aw my bi"><span id="5239" class="mz ly iq mv b gy na nb l nc nd">#Converting the output of model into usable bounding box tensors<br/>yolo_outputs = yolo_head(yolo_model.output, anchors, len(class_names))<br/>#Filtering the boxes<br/>scores, boxes, classes = yolo_eval(yolo_outputs, image_shape)</span></pre><p id="99d4" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">到目前为止，我们已经创建了一个会话图，它被提供给 yolo_model 来计算输出，由 yolo_head 处理，并经过过滤函数 yolo_eval。</p><h1 id="74af" class="lx ly iq bd lz ma mb mc md me mf mg mh jw mi jx mj jz mk ka ml kc mm kd mn mo bi translated">在图像上应用 YOLO:</h1><p id="2a30" class="pw-post-body-paragraph kr ks iq kt b ku mp jr kw kx mq ju kz la mr lc ld le ms lg lh li mt lk ll lm ij bi translated">现在我们必须实现一个运行图形的函数来测试图像上的 YOLO。</p><pre class="kg kh ki kj gt mu mv mw mx aw my bi"><span id="2e6f" class="mz ly iq mv b gy na nb l nc nd">def predict(sess, image_file):</span><span id="7f43" class="mz ly iq mv b gy ne nb l nc nd">    #Preprocessing the image<br/>    image, image_data = preprocess_image("images/"+image_file, model_image_size = (608,608))</span><span id="895e" class="mz ly iq mv b gy ne nb l nc nd">    #Running the session and feeding the input to it<br/>   out_scores, out_boxes, out_classes = sess.run([scores, boxes, classes],feed_dict = {yolo_model.input: image_data, K.learning_phase(): 0})</span><span id="16e5" class="mz ly iq mv b gy ne nb l nc nd">    #Prints the predicted information<br/>    print('Found {} boxes for {}'.format(len(out_boxes), image_file))</span><span id="c245" class="mz ly iq mv b gy ne nb l nc nd">    #Generates color for drawing bounding boxes<br/>    colors = generate_colors(class_names)</span><span id="ef40" class="mz ly iq mv b gy ne nb l nc nd">    #Draws bounding boxes on the image file<br/>    draw_boxes(image, out_scores, out_boxes, out_classes, class_names, colors)</span><span id="961b" class="mz ly iq mv b gy ne nb l nc nd">    #Saving the predicted bounding box on the image<br/>    image.save(os.path.join("out", image_file), quality = 150)</span><span id="2e9a" class="mz ly iq mv b gy ne nb l nc nd">    #Displaying the results in notebook<br/>    output_image = imageio.imread(os.path.join("out", image_file))<br/>    plt.figure(figsize=(12,12))<br/>    imshow(output_image)</span><span id="8a69" class="mz ly iq mv b gy ne nb l nc nd">    return out_scores, out_boxes, out_classes</span></pre><p id="d274" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">在您的测试图像上运行以下单元格以查看结果。</p><pre class="kg kh ki kj gt mu mv mw mx aw my bi"><span id="924c" class="mz ly iq mv b gy na nb l nc nd">#Loading the image<br/>img = plt.imread('images/traffic.jpeg')</span><span id="b25f" class="mz ly iq mv b gy ne nb l nc nd">#Calculating the size of image and passing it as a parameter to yolo_eval<br/>image_shape = float(img.shape[0]),float(img.shape[1])<br/>scores, boxes, classes = yolo_eval(yolo_outputs, image_shape)</span><span id="0cf9" class="mz ly iq mv b gy ne nb l nc nd">#Predicts the output<br/>out_scores, out_boxes, out_classes = predict(sess, "traffic.jpeg")</span></pre><p id="6b78" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">输出是:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="ng nh di ni bf nj"><div class="gh gi nz"><img src="../Images/d53e60ad06cc8daf6c9bfc4ab20cc2f6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*2S3euf4QTVkv63wWT845BQ.jpeg"/></div></div><figcaption class="kn ko gj gh gi kp kq bd b be z dk">Output after feeding image to the model.</figcaption></figure><h1 id="0af7" class="lx ly iq bd lz ma mb mc md me mf mg mh jw mi jx mj jz mk ka ml kc mm kd mn mo bi translated">结论:</h1><p id="69d0" class="pw-post-body-paragraph kr ks iq kt b ku mp jr kw kx mq ju kz la mr lc ld le ms lg lh li mt lk ll lm ij bi translated">如果你已经走了这么远，非常感谢。请注意，如果使用相同的图像进行检测，结果可能相同，也可能不同。您可以进一步自定义每个图像的最大边界框数、阈值等。以获得更好的结果。</p><p id="d439" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">如果你有任何建议让这个博客更好，请在评论中提出。我会努力做出改变。</p><h1 id="b2f5" class="lx ly iq bd lz ma mb mc md me mf mg mh jw mi jx mj jz mk ka ml kc mm kd mn mo bi translated">参考资料:</h1><ul class=""><li id="8dd6" class="nk nl iq kt b ku mp kx mq la oa le ob li oc lm od nq nr ns bi translated"><a class="ae lw" href="https://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/Redmon_You_Only_Look_CVPR_2016_paper.pdf" rel="noopener ugc nofollow" target="_blank">你只看一次:统一的、实时的物体检测</a></li><li id="dff0" class="nk nl iq kt b ku nt kx nu la nv le nw li nx lm od nq nr ns bi translated"><a class="ae lw" href="https://www.coursera.org/learn/convolutional-neural-networks?specialization=deep-learning" rel="noopener ugc nofollow" target="_blank">Coursera-卷积神经网络</a></li><li id="9d1f" class="nk nl iq kt b ku nt kx nu la nv le nw li nx lm od nq nr ns bi translated"><a class="ae lw" href="https://www.analyticsvidhya.com/blog/2018/06/understanding-building-object-detection-model-python/" rel="noopener ugc nofollow" target="_blank">用 Python 从零开始理解和构建对象检测模型</a></li></ul></div></div>    
</body>
</html>