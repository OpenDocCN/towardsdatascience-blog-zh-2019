<html>
<head>
<title>January Edition: Image and Speech Recognition</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">一月版:图像和语音识别</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/january-edition-image-and-speech-recognition-43a15669fe75?source=collection_archive---------21-----------------------#2019-01-07">https://towardsdatascience.com/january-edition-image-and-speech-recognition-43a15669fe75?source=collection_archive---------21-----------------------#2019-01-07</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="5984" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">10 篇必读文章</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/be099819f8b18c659c63142933f91473.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*rsRZqgsz-VHihVcyxfk61g.jpeg"/></div></div></figure><p id="f48a" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">多亏了进化，人类取得了长足的进步。贪得无厌的探索和实验欲望使人类超越了其他生物。要想做大，首先你需要一步一步来，一次一步来。复杂的人体解剖学进化了数百万年，这将继续进化到一个我们甚至无法想象的状态。对探索和实验的贪得无厌的渴望源于人类通过其基本的五种感官“视觉”、“听觉”、“嗅觉”、“味觉”和“触觉”来推断其周围环境的能力。</p><p id="4b98" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">如果我们将进化快进到今天，作为人类，我们可以为自己迄今为止走过的旅程感到无比自豪。今天，我们讨论殖民火星和超越我们的银河系。毫无疑问，人类在知识、科学和技术方面取得了巨大的成功。技术已经成为日常生活中的必需品，并以显著的方式提高了生活质量。即使人们利用技术，我们在技术进步方面处于一个超高的位置，这些工具背后的驱动力仍然是人类的勇气和大脑。20 世纪 50 年代和 60 年代的科学家开始研究和实验“如何教机器像人类一样学习”的想法。正如进化过程需要年复一年，这个想法也需要几十年才能迈出最初的几步。</p><p id="a6fd" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">感谢有远见的思想家的辛勤工作，他们是现代人工智能(深度学习)的先驱，我们看到了通往人类进化下一个时代的充满希望的旅程。“数据是新的石油”。随着海量数据的可用性，高性能计算、分布式系统(云计算)的力量，以及能够访问免费和开源技术，今天我们看到了人工智能的巨大创新。人工智能的最终目标是让人类能够做我们以前从未想象过的巨大工作。今天，我们听到关于机器在某些任务/工作(DOTA、医学成像等)中击败人类智能的新闻。)，但这并不是它的结束，它仅仅是一个漫长的成功旅程的开始。</p><p id="f9c2" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">当今研究界试图解决的挑战之一是，赋予机器从视觉和声音中识别、生成和推断决策的能力。过去几年，我们看到围绕深度学习的许多方面进行了大量的研究工作，特别是在计算机视觉、自然语言处理/生成、几何深度学习和 GANs 等领域，研究人员试图将视觉和语音引入机器。根据我们的读者统计和反馈，我们希望在“图像和语音识别”主题下展示我们平台的几篇精选文章</p><p id="8ab7" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">TDS 编辑助理查敏·纳林达。</p></div><div class="ab cl lp lq hu lr" role="separator"><span class="ls bw bk lt lu lv"/><span class="ls bw bk lt lu lv"/><span class="ls bw bk lt lu"/></div><div class="ij ik il im in"><h1 id="a7c8" class="lw lx iq bd ly lz ma mb mc md me mf mg jw mh jx mi jz mj ka mk kc ml kd mm mn bi translated">图像识别/生成</h1><h2 id="9c3f" class="mo lx iq bd ly mp mq dn mc mr ms dp mg la mt mu mi le mv mw mk li mx my mm mz bi translated"><a class="ae na" rel="noopener" target="_blank" href="/tutorial-build-a-lane-detector-679fd8953132">教程:搭建车道检测器</a></h2><p id="c375" class="pw-post-body-paragraph kr ks iq kt b ku nb jr kw kx nc ju kz la nd lc ld le ne lg lh li nf lk ll lm ij bi">By <a class="ln lo ep" href="https://medium.com/u/3ac7f8d471e?source=post_page-----43a15669fe75--------------------------------" rel="noopener" target="_blank">Chuan En Lin 林傳恩</a> — 10 min read</p><p id="d256" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">Waymo 的自动驾驶出租车服务本月刚刚上路——但自动驾驶汽车是如何工作的呢？道路上画的线向人类驾驶员指示车道在哪里，并作为相应地驾驶车辆的方向的指导参考，以及车辆代理如何在道路上和谐互动的约定。</p></div><div class="ab cl lp lq hu lr" role="separator"><span class="ls bw bk lt lu lv"/><span class="ls bw bk lt lu lv"/><span class="ls bw bk lt lu"/></div><div class="ij ik il im in"><h2 id="35da" class="mo lx iq bd ly mp mq dn mc mr ms dp mg la mt mu mi le mv mw mk li mx my mm mz bi translated"><a class="ae na" rel="noopener" target="_blank" href="/the-10-coolest-papers-from-cvpr-2018-11cb48585a49">2018 年 CVPR 十大最酷论文</a></h2><p id="7370" class="pw-post-body-paragraph kr ks iq kt b ku nb jr kw kx nc ju kz la nd lc ld le ne lg lh li nf lk ll lm ij bi translated">到<a class="ln lo ep" href="https://medium.com/u/e2af5c8737ec?source=post_page-----43a15669fe75--------------------------------" rel="noopener" target="_blank">乔治·赛义夫</a> — 8 分钟读完</p><p id="c04f" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">2018 年计算机视觉和模式识别大会(CVPR)于上周在美国盐湖城举行。这是计算机视觉领域的世界顶级会议。今年，CVPR 收到了 3300 份主要会议论文，接受了 979 份。超过 6500 人参加了会议，好家伙，这是史诗！6500 人挤进了这个房间:</p></div><div class="ab cl lp lq hu lr" role="separator"><span class="ls bw bk lt lu lv"/><span class="ls bw bk lt lu lv"/><span class="ls bw bk lt lu"/></div><div class="ij ik il im in"><h2 id="11ad" class="mo lx iq bd ly mp mq dn mc mr ms dp mg la mt mu mi le mv mw mk li mx my mm mz bi translated"><a class="ae na" rel="noopener" target="_blank" href="/yolo-v3-object-detection-53fb7d3bfe6b">YOLO v3 有什么新功能？</a></h2><p id="d81c" class="pw-post-body-paragraph kr ks iq kt b ku nb jr kw kx nc ju kz la nd lc ld le ne lg lh li nf lk ll lm ij bi translated">通过<a class="ln lo ep" href="https://medium.com/u/bea6d51d2712?source=post_page-----43a15669fe75--------------------------------" rel="noopener" target="_blank"> Ayoosh Kathuria </a> — 9 分钟读取</p><p id="7122" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">你只看一次，或 YOLO，是一个更快的对象检测算法。虽然它不再是最准确的对象检测算法，但当您需要实时检测时，它是一个非常好的选择，不会损失太多的准确性。</p></div><div class="ab cl lp lq hu lr" role="separator"><span class="ls bw bk lt lu lv"/><span class="ls bw bk lt lu lv"/><span class="ls bw bk lt lu"/></div><div class="ij ik il im in"><h2 id="1d53" class="mo lx iq bd ly mp mq dn mc mr ms dp mg la mt mu mi le mv mw mk li mx my mm mz bi translated"><a class="ae na" rel="noopener" target="_blank" href="/only-numpy-implementing-gan-general-adversarial-networks-and-adam-optimizer-using-numpy-with-2a7e4e032021"> Only Numpy:使用带有交互代码的 Numpy 实现 GAN 和 Adam 优化器。</a></h2><p id="d263" class="pw-post-body-paragraph kr ks iq kt b ku nb jr kw kx nc ju kz la nd lc ld le ne lg lh li nf lk ll lm ij bi translated">由<a class="ln lo ep" href="https://medium.com/u/70eb2d57a447?source=post_page-----43a15669fe75--------------------------------" rel="noopener" target="_blank"> Jae Duk Seo </a> — 6 分钟阅读</p><p id="68da" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">所以今天我被这篇博文“TensorFlow 中的生成性对抗网络”所启发，我想用 Numpy 自己实现 GAN。这里是<strong class="kt ir"> @ </strong> goodfellow_ian 的 GAN 论文原文。下面是从简单的 GAN 生成的所有图像的 gif。</p></div><div class="ab cl lp lq hu lr" role="separator"><span class="ls bw bk lt lu lv"/><span class="ls bw bk lt lu lv"/><span class="ls bw bk lt lu"/></div><div class="ij ik il im in"><h2 id="1cdd" class="mo lx iq bd ly mp mq dn mc mr ms dp mg la mt mu mi le mv mw mk li mx my mm mz bi translated"><a class="ae na" rel="noopener" target="_blank" href="/real-time-and-video-processing-object-detection-using-tensorflow-opencv-and-docker-2be1694726e5">使用 Tensorflow、OpenCV 和 Docker 进行实时和视频处理对象检测。</a></h2><p id="16a9" class="pw-post-body-paragraph kr ks iq kt b ku nb jr kw kx nc ju kz la nd lc ld le ne lg lh li nf lk ll lm ij bi translated">由莱奥·博科特 — 7 分钟读完</p><p id="5367" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">在本文中，我将介绍如何在 Docker 容器中使用 Tensorflow 对象检测 API 来执行实时(网络摄像头)和视频后处理。我使用 OpenCV 和 python3 多处理和多线程库。</p></div><div class="ab cl lp lq hu lr" role="separator"><span class="ls bw bk lt lu lv"/><span class="ls bw bk lt lu lv"/><span class="ls bw bk lt lu"/></div><div class="ij ik il im in"><h1 id="75bf" class="lw lx iq bd ly lz ma mb mc md me mf mg jw mh jx mi jz mj ka mk kc ml kd mm mn bi translated">音频/语音识别</h1><h2 id="d5a6" class="mo lx iq bd ly mp mq dn mc mr ms dp mg la mt mu mi le mv mw mk li mx my mm mz bi translated"><a class="ae na" rel="noopener" target="_blank" href="/recurrent-neural-networks-the-powerhouse-of-language-modeling-d45acc50444f">递归神经网络:语言建模的发电站</a></h2><p id="1887" class="pw-post-body-paragraph kr ks iq kt b ku nb jr kw kx nc ju kz la nd lc ld le ne lg lh li nf lk ll lm ij bi translated">由<a class="ln lo ep" href="https://medium.com/u/52aa38cb8e25?source=post_page-----43a15669fe75--------------------------------" rel="noopener" target="_blank">詹姆斯·勒</a> — 12 分钟读完</p><p id="c00a" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">大学三年级春季学期，我有机会去丹麦哥本哈根留学。在此之前，我从未去过欧洲，所以我非常兴奋地沉浸在一种新的文化中，结识新的人，去新的地方旅行，最重要的是，遇到一种新的语言。</p></div><div class="ab cl lp lq hu lr" role="separator"><span class="ls bw bk lt lu lv"/><span class="ls bw bk lt lu lv"/><span class="ls bw bk lt lu"/></div><div class="ij ik il im in"><h2 id="3e75" class="mo lx iq bd ly mp mq dn mc mr ms dp mg la mt mu mi le mv mw mk li mx my mm mz bi translated"><a class="ae na" rel="noopener" target="_blank" href="/automatic-speech-recognition-data-collection-with-youtube-v3-api-mask-rcnn-and-google-vision-api-2370d6776109">使用 Youtube V3 API、Mask-RCNN 和 Google Vision API 自动收集语音识别数据</a></h2><p id="ce68" class="pw-post-body-paragraph kr ks iq kt b ku nb jr kw kx nc ju kz la nd lc ld le ne lg lh li nf lk ll lm ij bi">By <a class="ln lo ep" href="https://medium.com/u/2fc7b9c3f02a?source=post_page-----43a15669fe75--------------------------------" rel="noopener" target="_blank">黃功詳 Steeve Huang</a> — 8 min read</p><p id="3161" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">随着机器学习特别是深度学习的快速发展，语音识别得到了显著的提高。这种技术依赖于大量高质量的数据。</p></div><div class="ab cl lp lq hu lr" role="separator"><span class="ls bw bk lt lu lv"/><span class="ls bw bk lt lu lv"/><span class="ls bw bk lt lu"/></div><div class="ij ik il im in"><h2 id="8819" class="mo lx iq bd ly mp mq dn mc mr ms dp mg la mt mu mi le mv mw mk li mx my mm mz bi translated"><a class="ae na" rel="noopener" target="_blank" href="/audio-classification-using-fastai-and-on-the-fly-frequency-transforms-4dbe1b540f89">使用 FastAI 和即时频率变换的音频分类</a></h2><p id="dcf9" class="pw-post-body-paragraph kr ks iq kt b ku nb jr kw kx nc ju kz la nd lc ld le ne lg lh li nf lk ll lm ij bi translated">约翰·哈特奎斯特 — 9 分钟阅读</p><p id="78cd" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">虽然深度学习模型能够帮助解决许多不同类型的问题，但图像分类是课程和框架最普遍的例子，通常充当“你好，世界”的介绍。</p></div><div class="ab cl lp lq hu lr" role="separator"><span class="ls bw bk lt lu lv"/><span class="ls bw bk lt lu lv"/><span class="ls bw bk lt lu"/></div><div class="ij ik il im in"><h2 id="7af5" class="mo lx iq bd ly mp mq dn mc mr ms dp mg la mt mu mi le mv mw mk li mx my mm mz bi translated"><a class="ae na" rel="noopener" target="_blank" href="/human-like-machine-hearing-with-ai-1-3-a5713af6e2f8">具有人工智能的仿人机器听觉</a></h2><p id="b2f9" class="pw-post-body-paragraph kr ks iq kt b ku nb jr kw kx nc ju kz la nd lc ld le ne lg lh li nf lk ll lm ij bi translated">丹尼尔·罗斯曼(Daniel Rothmann)—9 分钟阅读</p><p id="7400" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">人工智能技术的重大突破是通过模拟人类系统实现的。虽然人工神经网络(NNs)是与实际人类神经元的功能方式仅松散耦合的数学模型，但它们在解决复杂和模糊的现实世界问题方面的应用已经非常广泛。</p></div><div class="ab cl lp lq hu lr" role="separator"><span class="ls bw bk lt lu lv"/><span class="ls bw bk lt lu lv"/><span class="ls bw bk lt lu"/></div><div class="ij ik il im in"><h2 id="706e" class="mo lx iq bd ly mp mq dn mc mr ms dp mg la mt mu mi le mv mw mk li mx my mm mz bi translated"><a class="ae na" rel="noopener" target="_blank" href="/kaggle-tensorflow-speech-recognition-challenge-b46a3bca2501"> Kaggle Tensorflow 语音识别挑战</a></h2><p id="ca4d" class="pw-post-body-paragraph kr ks iq kt b ku nb jr kw kx nc ju kz la nd lc ld le ne lg lh li nf lk ll lm ij bi translated">由<a class="ln lo ep" href="https://medium.com/u/1155630a63a8?source=post_page-----43a15669fe75--------------------------------" rel="noopener" target="_blank">克里斯迪南</a> — 12 分钟阅读</p><p id="c46b" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">从 2017 年 11 月到 2018 年 1 月，谷歌大脑团队在<a class="ae na" href="https://www.kaggle.com/c/tensorflow-speech-recognition-challenge#" rel="noopener ugc nofollow" target="_blank"> Kaggle </a>上举办了一场语音识别挑战赛。这项挑战的目标是编写一个程序，能够正确识别一秒钟长的音频文件中 10 个单词中的一个。</p></div><div class="ab cl lp lq hu lr" role="separator"><span class="ls bw bk lt lu lv"/><span class="ls bw bk lt lu lv"/><span class="ls bw bk lt lu"/></div><div class="ij ik il im in"><p id="3350" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">我们也感谢最近加入我们的所有伟大的新作家，<a class="ln lo ep" href="https://medium.com/u/e04dea89c8ac?source=post_page-----43a15669fe75--------------------------------" rel="noopener" target="_blank">古伊列梅·利尚德</a>，<a class="ln lo ep" href="https://medium.com/u/164118e39a35?source=post_page-----43a15669fe75--------------------------------" rel="noopener" target="_blank">艾蒙·汗</a>，<a class="ln lo ep" href="https://medium.com/u/530fbe8385a9?source=post_page-----43a15669fe75--------------------------------" rel="noopener" target="_blank">波尔·费兰多</a>，<a class="ln lo ep" href="https://medium.com/u/164118e39a35?source=post_page-----43a15669fe75--------------------------------" rel="noopener" target="_blank">艾蒙·汗</a>，<a class="ln lo ep" href="https://medium.com/u/5209cde059f5?source=post_page-----43a15669fe75--------------------------------" rel="noopener" target="_blank">皮查亚·蒂普卡姆</a>，<a class="ln lo ep" href="https://medium.com/u/1fcdafbd2cf7?source=post_page-----43a15669fe75--------------------------------" rel="noopener" target="_blank">萨利赫·图顿博士</a>，<a class="ln lo ep" href="https://medium.com/u/4e86aa4781ca?source=post_page-----43a15669fe75--------------------------------" rel="noopener" target="_blank">伊恩·马科姆伯</a>，<a class="ln lo ep" href="https://medium.com/u/386ab9aa0da4?source=post_page-----43a15669fe75--------------------------------" rel="noopener" target="_blank">道格拉斯·科英布拉·德安德拉德</a>，<a class="ln lo ep" href="https://medium.com/u/1e79b582503a?source=post_page-----43a15669fe75--------------------------------" rel="noopener" target="_blank">里沙布·加尔格</a>，<a class="ln lo ep" href="https://medium.com/u/4e86aa4781ca?source=post_page-----43a15669fe75--------------------------------" rel="noopener" target="_blank"> </a><a class="ln lo ep" href="https://medium.com/u/342a4846c139?source=post_page-----43a15669fe75--------------------------------" rel="noopener" target="_blank">法兰克福学派</a>、<a class="ln lo ep" href="https://medium.com/u/3d87ebf60118?source=post_page-----43a15669fe75--------------------------------" rel="noopener" target="_blank">戈塔姆·内坎蒂</a>、<a class="ln lo ep" href="https://medium.com/u/4e623cf1c796?source=post_page-----43a15669fe75--------------------------------" rel="noopener" target="_blank">马西莫·贝洛尼</a>、<a class="ln lo ep" href="https://medium.com/u/4c025b201745?source=post_page-----43a15669fe75--------------------------------" rel="noopener" target="_blank">托默·克图雷尔</a>、<a class="ln lo ep" href="https://medium.com/u/2e8e06482696?source=post_page-----43a15669fe75--------------------------------" rel="noopener" target="_blank">乔纳森·奥海克斯</a>、<a class="ln lo ep" href="https://medium.com/u/2879ca55026a?source=post_page-----43a15669fe75--------------------------------" rel="noopener" target="_blank">文森特·万霍克</a>、<a class="ln lo ep" href="https://medium.com/u/21eb61594228?source=post_page-----43a15669fe75--------------------------------" rel="noopener" target="_blank">妮可·关</a>、<a class="ln lo ep" href="https://medium.com/u/500f7dca1ad3?source=post_page-----43a15669fe75--------------------------------" rel="noopener" target="_blank">科林·辛克莱</a>、<a class="ln lo ep" href="https://medium.com/u/4e63b4921b6?source=post_page-----43a15669fe75--------------------------------" rel="noopener" target="_blank">阿什里斯</a>、<a class="ln lo ep" href="https://medium.com/u/3865848842f9?source=post_page-----43a15669fe75--------------------------------" rel="noopener" target="_blank">迈克尔·亨格</a>、<a class="ln lo ep" href="https://medium.com/u/3865848842f9?source=post_page-----43a15669fe75--------------------------------" rel="noopener" target="_blank"> 我们邀请你看看他们的简介，看看他们的工作。</a></p></div></div>    
</body>
</html>