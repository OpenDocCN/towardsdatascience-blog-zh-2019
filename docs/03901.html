<html>
<head>
<title>Concept of Regularization</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">正则化概念</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/concept-of-regularization-28f593cf9f8c?source=collection_archive---------20-----------------------#2019-06-19">https://towardsdatascience.com/concept-of-regularization-28f593cf9f8c?source=collection_archive---------20-----------------------#2019-06-19</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="869d" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">这就是为什么正则化是机器学习中重要的一步！</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/12c8bab2f602d5ba7ca1b7e519e731e0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Ez1XaxyVVCJdrnubJfzPZw.jpeg"/></div></div></figure><p id="846e" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">让我们考虑我们正在开发一个机器学习模型。该模型通常使用“训练数据集”进行训练，并使用“测试数据集”进行测试。如果数据集未经预处理，模型的准确性通常会下降。事实上，在训练模型之前，大部分时间都花在预处理数据上。</p><p id="ca54" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">模型精确度低的可能原因是什么？</p><p id="adb5" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">有两种主要的可能性:</p><ol class=""><li id="a904" class="lq lr it kw b kx ky la lb ld ls lh lt ll lu lp lv lw lx ly bi translated">欠拟合</li><li id="9cf9" class="lq lr it kw b kx lz la ma ld mb lh mc ll md lp lv lw lx ly bi translated">过度拟合</li></ol><h1 id="aaee" class="me mf it bd mg mh mi mj mk ml mm mn mo jz mp ka mq kc mr kd ms kf mt kg mu mv bi translated">欠拟合</h1><p id="000e" class="pw-post-body-paragraph ku kv it kw b kx mw ju kz la mx jx lc ld my lf lg lh mz lj lk ll na ln lo lp im bi translated">欠拟合是一种模型没有学习到数据集的广义模式的现象。这可能是由于数据集不充分，或者对该特定数据集使用了不适当的机器学习算法。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nb"><img src="../Images/78e409fbd8bf4018f67876d9c0d7ea0a.png" data-original-src="https://miro.medium.com/v2/resize:fit:796/format:webp/1*VIf_dsQH1UbvRtFQke1wIA.png"/></div><figcaption class="nc nd gj gh gi ne nf bd b be z dk">Underfitting</figcaption></figure><p id="e4a7" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">让我们考虑一个例子。该图包含表示正弦曲线的数据点。这些数据点被输入线性回归算法。这条线是模型的预测输出。很明显，模型的精确度并不是很高！为什么这样因为线性模型是在非线性数据集上训练的。因此，用一条线性线来拟合非线性数据<em class="ng">会过度简化</em>模型。</p><h1 id="c5c6" class="me mf it bd mg mh mi mj mk ml mm mn mo jz mp ka mq kc mr kd ms kf mt kg mu mv bi translated">过度拟合</h1><p id="5342" class="pw-post-body-paragraph ku kv it kw b kx mw ju kz la mx jx lc ld my lf lg lh mz lj lk ll na ln lo lp im bi translated">过度拟合是一种模型从数据集学习过多的现象。过度拟合模型在对其进行训练的数据中表现得非常好，但是在对一组新数据执行时，其准确性往往会降低。</p><p id="ece9" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">让我们考虑同样的例子。在这种情况下，让我们使用多项式回归模型。通过使用多项式特征变换，可以找到数组中每个元素的幂，直到指定的幂。存储在多维数组中的这些值可用于输入多项式回归模型。随着多项式特征转换器中指定幂的增加，模型似乎学习到了比所需更多的内容，并且似乎是对训练数据集非常“特定”的输出。</p><blockquote class="nh ni nj"><p id="76f4" class="ku kv ng kw b kx ky ju kz la lb jx lc nk le lf lg nl li lj lk nm lm ln lo lp im bi translated">过拟合模型被称为具有高方差</p></blockquote><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nn"><img src="../Images/7ed6d3457f05a708f1e8682d63537df7.png" data-original-src="https://miro.medium.com/v2/resize:fit:800/format:webp/1*bAor-JJcZGRVjq67N91S5A.png"/></div><figcaption class="nc nd gj gh gi ne nf bd b be z dk">overfitting</figcaption></figure><p id="e9f0" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated"><strong class="kw iu"> <em class="ng">当基函数的系数较大且相互抵消时，会出现过拟合现象！</em> </strong></p><h1 id="fbc8" class="me mf it bd mg mh mi mj mk ml mm mn mo jz mp ka mq kc mr kd ms kf mt kg mu mv bi translated">正规化防止过度拟合！</h1><p id="1a67" class="pw-post-body-paragraph ku kv it kw b kx mw ju kz la mx jx lc ld my lf lg lh mz lj lk ll na ln lo lp im bi translated">正则化技术用于通过在给定的训练集上适当地拟合函数来减少误差，以避免过度拟合。这些函数实质上减少了每个特征的系数(β),从而减少了值被抵消的机会。回归方程的一个例子如下:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi no"><img src="../Images/ccbe80e09c4f9f4a1487b582dbe60b2b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*k2bLmeYIG7z7dCyxADedhQ.png"/></div></div><figcaption class="nc nd gj gh gi ne nf bd b be z dk">Linear Regression</figcaption></figure><h1 id="8717" class="me mf it bd mg mh mi mj mk ml mm mn mo jz mp ka mq kc mr kd ms kf mt kg mu mv bi translated">正规化的类型</h1><ol class=""><li id="de8d" class="lq lr it kw b kx mw la mx ld np lh nq ll nr lp lv lw lx ly bi translated"><strong class="kw iu"> L1 </strong></li><li id="c258" class="lq lr it kw b kx lz la ma ld mb lh mc ll md lp lv lw lx ly bi translated"><strong class="kw iu"> L2 </strong></li><li id="597b" class="lq lr it kw b kx lz la ma ld mb lh mc ll md lp lv lw lx ly bi translated"><strong class="kw iu">弹力网</strong></li></ol><h2 id="f605" class="ns mf it bd mg nt nu dn mk nv nw dp mo ld nx ny mq lh nz oa ms ll ob oc mu od bi translated"><strong class="ak"> L1(套索正规化):</strong></h2><p id="90fe" class="pw-post-body-paragraph ku kv it kw b kx mw ju kz la mx jx lc ld my lf lg lh mz lj lk ll na ln lo lp im bi translated">L1 正则化背后的思想是将数据集减少到仅影响“目标变量”的最重要的特征。L1 正则化增加了等于系数绝对值之和的惩罚。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi oe"><img src="../Images/b633a1a0a8cd34c7b5e14bc3b614dacc.png" data-original-src="https://miro.medium.com/v2/resize:fit:600/format:webp/1*bQUf2joCx9bQt0pwqqSCvg.png"/></div></figure><p id="c9d1" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">通过添加上述惩罚，<strong class="kw iu">一些特征的系数变为 0 </strong>，剩余的特征将是最有用的特征。这种正则化方法可以看作是一种特征选择方法。</p><h2 id="a444" class="ns mf it bd mg nt nu dn mk nv nw dp mo ld nx ny mq lh nz oa ms ll ob oc mu od bi translated">L2(岭正则化):</h2><p id="8608" class="pw-post-body-paragraph ku kv it kw b kx mw ju kz la mx jx lc ld my lf lg lh mz lj lk ll na ln lo lp im bi translated">L2 正则化附加了一个等于系数平方值之和的惩罚。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi of"><img src="../Images/0a62909d39274380c280722a97b014b8.png" data-original-src="https://miro.medium.com/v2/resize:fit:528/1*N1xzNp0DpNgVv8XRZ8kW3Q.gif"/></div></figure><p id="c2cd" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">等式中的λ是控制惩罚强度的超参数。</p><p id="21a6" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">当λ→0 时，结果类似于线性回归</p><p id="d400" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">当λ→∞，所有特征都减少到 0。</p><p id="2326" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">当施加惩罚时，系数不会剧烈变化到 0，而是缓慢降低到 0。因此，与 L1 不同，L2 不能用于特征选择。</p><p id="5381" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">在这两种情况下，</p><p id="ebbf" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated"><strong class="kw iu"> <em class="ng">惩罚越大，系数越小。</em> </strong></p><h2 id="f442" class="ns mf it bd mg nt nu dn mk nv nw dp mo ld nx ny mq lh nz oa ms ll ob oc mu od bi translated">弹性网:</h2><p id="f403" class="pw-post-body-paragraph ku kv it kw b kx mw ju kz la mx jx lc ld my lf lg lh mz lj lk ll na ln lo lp im bi translated">弹性网正则化是 L1 正则化和 L2 正则化的结合。</p><p id="56a4" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">适用的罚款(P)如下:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi og"><img src="../Images/26b00621e0e5c5927806674c487d6399.png" data-original-src="https://miro.medium.com/v2/resize:fit:854/1*DuJ-7L4evUd7YneLrsQf9A.gif"/></div></figure><p id="c8af" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">在这种情况下，λ是一个共享参数，用于设置 L1 和 L2 之间的比率。因此，结果将是 L1 和 L2 正则化的混合。正则化的几何表示如下所示:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi oh"><img src="../Images/f61ede6b285a9744b400d2bf1eed664c.png" data-original-src="https://miro.medium.com/v2/resize:fit:722/format:webp/1*hEdWblu9h1x-rEtNCF5JFA.png"/></div></figure><h1 id="52a5" class="me mf it bd mg mh mi mj mk ml mm mn mo jz mp ka mq kc mr kd ms kf mt kg mu mv bi translated">正规化的实施</h1><h2 id="9250" class="ns mf it bd mg nt nu dn mk nv nw dp mo ld nx ny mq lh nz oa ms ll ob oc mu od bi translated">导入所需的库:</h2><pre class="kj kk kl km gt oi oj ok ol aw om bi"><span id="0b5a" class="ns mf it oj b gy on oo l op oq">import pandas as pd<br/>import numpy as np<br/>import matplotlib.pyplot as plt<br/>%matplotlib inline<br/>import warnings<br/>warnings.filterwarnings('ignore')<br/>from sklearn.preprocessing import PolynomialFeatures<br/>from sklearn.linear_model import Lasso,Ridge<br/>from sklearn.pipeline import make_pipeline</span></pre><h2 id="4a02" class="ns mf it bd mg nt nu dn mk nv nw dp mo ld nx ny mq lh nz oa ms ll ob oc mu od bi translated">加载数据集(本例中，使用了<a class="ae or" href="https://www.kaggle.com/c/house-prices-advanced-regression-techniques/overview" rel="noopener ugc nofollow" target="_blank"> Ames Housing 数据集</a>:</h2><pre class="kj kk kl km gt oi oj ok ol aw om bi"><span id="b6a9" class="ns mf it oj b gy on oo l op oq">data = pd.read_csv('house_prices.csv')<br/>data.head()</span></pre><h2 id="2581" class="ns mf it bd mg nt nu dn mk nv nw dp mo ld nx ny mq lh nz oa ms ll ob oc mu od bi translated">将数据分为“列车数据”和“测试数据”:</h2><pre class="kj kk kl km gt oi oj ok ol aw om bi"><span id="535d" class="ns mf it oj b gy on oo l op oq">from sklearn.model_selection import train_test_split</span><span id="9009" class="ns mf it oj b gy os oo l op oq">X = data.iloc[:,:-1]<br/>y = data.SalePrice</span><span id="f17b" class="ns mf it oj b gy os oo l op oq">X_train,X_test,y_train,y_test = train_test_split(X,y,random_state = 9,train_size = 0.5)</span></pre><h2 id="a2a2" class="ns mf it bd mg nt nu dn mk nv nw dp mo ld nx ny mq lh nz oa ms ll ob oc mu od bi translated">1.要执行线性回归:</h2><pre class="kj kk kl km gt oi oj ok ol aw om bi"><span id="48ff" class="ns mf it oj b gy on oo l op oq">from sklearn.linear_model import LinearRegression,Lasso,Ridge<br/>from sklearn.metrics import mean_squared_error</span><span id="652d" class="ns mf it oj b gy os oo l op oq">regressor = LinearRegression() #Linear model<br/>regressor.fit(X_train,y_train)<br/>y_pred = regressor.predict(X_test)<br/>mean_squared_error(y_test,y_pred)</span></pre><h2 id="acb5" class="ns mf it bd mg nt nu dn mk nv nw dp mo ld nx ny mq lh nz oa ms ll ob oc mu od bi translated">2.要执行套索回归:</h2><pre class="kj kk kl km gt oi oj ok ol aw om bi"><span id="1069" class="ns mf it oj b gy on oo l op oq">lasso_model = Lasso(alpha = 140,max_iter = 100000, random_state=9)<br/>lasso_model.fit(X_train,y_train) #Lasso model<br/>y_pred = lasso_model.predict(X_test)<br/>mean_squared_error(y_test,y_pred)</span></pre><h2 id="5865" class="ns mf it bd mg nt nu dn mk nv nw dp mo ld nx ny mq lh nz oa ms ll ob oc mu od bi translated">3.要执行岭回归，请执行以下操作:</h2><pre class="kj kk kl km gt oi oj ok ol aw om bi"><span id="637e" class="ns mf it oj b gy on oo l op oq">ridge_model = Ridge(alpha = 0.00002,max_iter = 100000,random_state = 9)<br/>ridge_model.fit(X_train,y_train) #Ridge model<br/>y_pred = ridge_model.predict(X_test)<br/>mean_squared_error(y_test,y_pred)</span></pre><p id="2308" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">在每种情况下，都要从模型验证的测试数据中找到预测的“目标变量”和实际的“目标变量”之间的<em class="ng">均方误差</em>。</p></div><div class="ab cl ot ou hx ov" role="separator"><span class="ow bw bk ox oy oz"/><span class="ow bw bk ox oy oz"/><span class="ow bw bk ox oy"/></div><div class="im in io ip iq"><p id="82dd" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">谢谢你阅读这篇文章。</p><p id="cd8d" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">请通过<a class="ae or" href="http://www.linkedin.com/in/abhishekchandar" rel="noopener ugc nofollow" target="_blank"> LinkedIn </a>与我联系，或者您可以<a class="ae or" href="http://abhishekchandar23@gmail.com" rel="noopener ugc nofollow" target="_blank">将</a>发到我 LinkedIn 个人资料上的邮箱。</p></div></div>    
</body>
</html>