<html>
<head>
<title>Marketing Analytics: Customer Engagement, Random Forest Style</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">营销分析:客户参与，随机森林风格</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/marketing-analytics-customer-engagement-random-forest-style-7df06a390979?source=collection_archive---------11-----------------------#2019-09-06">https://towardsdatascience.com/marketing-analytics-customer-engagement-random-forest-style-7df06a390979?source=collection_archive---------11-----------------------#2019-09-06</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><figure class="gl gn jr js jt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi jq"><img src="../Images/c5ea9d1560e3f45c211c2c0e1e78d497.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*CckUnJl_Dflg56V_"/></div></div></figure><p id="836e" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">我们将讨论如何建立一个关于客户营销参与的随机森林预测模型。通过更好地预测客户将如何参与某些营销活动，营销人员可以为不同的受众量身定制策略[1]。我们在这里寻找的官方营销术语是“参与的可能性”一个具体的例子是区分哪种类型的客户会对哪种类型的广告做出反应(例如，20-39 岁的女性对脸书广告和谷歌广告的反应——完全是编造的)。</p><h1 id="bc81" class="kz la it bd lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw bi translated">数据设置</h1><p id="82bc" class="pw-post-body-paragraph kb kc it kd b ke lx kg kh ki ly kk kl km lz ko kp kq ma ks kt ku mb kw kx ky im bi translated">今天的数据由 ka ggle[2]:<br/><a class="ae mc" href="https://www.kaggle.com/pankajjsh06/ibm-watson-marketing-customer-value-data/downloads/ibm-watson-marketing-customer-value-data.zip/1" rel="noopener ugc nofollow" target="_blank"><em class="md">https://www . ka ggle . com/pankajjsh 06/IBM-Watson-marketing-customer-value-data/downloads/IBM-Watson-marketing-customer-value-data . zip/1</em></a>慷慨提供</p><p id="6ffc" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">是时候导入所有的包了。</p><pre class="me mf mg mh gt mi mj mk ml aw mm bi"><span id="e017" class="mn la it mj b gy mo mp l mq mr">import matplotlib.pyplot as plt<br/>import pandas as pd<br/>%matplotlib inline<br/>from sklearn.model_selection import train_test_split<br/>from sklearn.ensemble import RandomForestClassifier<br/>from sklearn.metrics import accuracy_score, precision_score, recall_score<br/>from sklearn.metrics import roc_curve, auc</span></pre><p id="3ba0" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">接下来，带来数据。</p><pre class="me mf mg mh gt mi mj mk ml aw mm bi"><span id="7301" class="mn la it mj b gy mo mp l mq mr">#load data<br/>df = pd.read_csv('WA_Fn-UseC_-Marketing-Customer-Value-Analysis.csv')<br/>﻿﻿custd.head()</span></pre><figure class="me mf mg mh gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi jq"><img src="../Images/a02f6675c1952ef090fa3f51ee0fbea1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*g_8x9bt2eJI4S8Vs"/></div></div></figure><p id="79c6" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">作为模型输出的“响应”变量不是一个数字。这将被调整成一个数字，否则 Python 会发疯的。</p><pre class="me mf mg mh gt mi mj mk ml aw mm bi"><span id="bbed" class="mn la it mj b gy mo mp l mq mr">#Encoding output variable<br/>custd['Engaged'] = custd['Response'].apply(lambda x: 1 if x == 'Yes' else 0)</span></pre><p id="d785" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">应用功能将“是”的回答转换为“1 ”,将其他所有回答转换为“0”。“是”表示客户参与了，而“否”表示没有参与。所以平均参与率是</p><pre class="me mf mg mh gt mi mj mk ml aw mm bi"><span id="63e6" class="mn la it mj b gy mo mp l mq mr">custd['Engaged'].mean()</span></pre><p id="88ec" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">0.1432，意味着我们的平均参与率大约为 14%。现在，你知道为什么他们说销售是一个数字游戏。只有少数人说是。</p><h1 id="cb68" class="kz la it bd lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw bi translated">特征工程</h1><p id="f374" class="pw-post-body-paragraph kb kc it kd b ke lx kg kh ki ly kk kl km lz ko kp kq ma ks kt ku mb kw kx ky im bi translated">让我们来看看我们的客户参与模型的特性。</p><pre class="me mf mg mh gt mi mj mk ml aw mm bi"><span id="f0ac" class="mn la it mj b gy mo mp l mq mr">#Checking out features<br/>custd.describe()</span></pre><figure class="me mf mg mh gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi jq"><img src="../Images/9c539fda9ecba4a1ccf4bbff8247745c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*6Q4OqZqIh41WltQc"/></div></div></figure><p id="a470" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">酷，我们用 describe 隔离了所有的数值或连续列。</p><pre class="me mf mg mh gt mi mj mk ml aw mm bi"><span id="f7d6" class="mn la it mj b gy mo mp l mq mr">continuous_features = ['Customer Lifetime Value', 'Income', 'Monthly Premium Auto',<br/>'Months Since Last Claim', 'Months Since Policy Inception',<br/>'Number of Open Complaints', 'Number of Policies', 'Total Claim Amount']</span></pre><p id="2b1a" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">现在，来处理所有的分类栏目。</p><pre class="me mf mg mh gt mi mj mk ml aw mm bi"><span id="fbf5" class="mn la it mj b gy mo mp l mq mr">columns_to_encode = ['Sales Channel', 'Vehicle Size', 'Vehicle Class', 'Policy', 'Policy Type', <br/>    'EmploymentStatus', 'Marital Status', 'Education', 'Coverage']</span><span id="fb1d" class="mn la it mj b gy ms mp l mq mr">categorical_features = []<br/>for col in columns_to_encode:<br/>    encoded_df = pd.get_dummies(custd[col])<br/>    encoded_df.columns = [col.replace(' ', '.') + '.' + x for x in encoded_df.columns]<br/>    <br/>    categorical_features += list(encoded_df.columns)<br/>    <br/>    custd = pd.concat([custd, encoded_df], axis=1)<br/>    <br/>custd['Is.Female'] = custd['Gender'].apply(lambda x: 1 if x == 'F' else 0)</span><span id="2bd6" class="mn la it mj b gy ms mp l mq mr">categorical_features.append('Is.Female')</span></pre><p id="6a08" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">在将所有需要的变量编码成数字后，我们需要将所有内容组合回一个数据框架中。</p><pre class="me mf mg mh gt mi mj mk ml aw mm bi"><span id="3a5a" class="mn la it mj b gy mo mp l mq mr">all_features = continuous_features + categorical_features<br/>response = 'Engaged'<br/>﻿﻿sample_custd = custd[all_features + [response]]<br/>sample_custd.columns = [x.replace(' ', '.') for x in sample_custd.columns]<br/>all_features = [x.replace(' ', '.') for x in all_features]<br/>﻿<br/>﻿﻿sample_custd.head()</span></pre><figure class="me mf mg mh gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi jq"><img src="../Images/7bb4a7633a570093c32df899159c4a65.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*Ce9woaENHMyzi3ff"/></div></div></figure><p id="c644" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">在一些特征工程之后总是检查你的数据以确保你没有错过任何东西，这不是一个坏主意。在我们的例子中，看起来我们成功地将所有东西都转换成了数字。现在来看模型！</p><h1 id="2f66" class="kz la it bd lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw bi translated">构建随机森林</h1><p id="7f89" class="pw-post-body-paragraph kb kc it kd b ke lx kg kh ki ly kk kl km lz ko kp kq ma ks kt ku mb kw kx ky im bi translated">我们需要做的第一件事是在训练集和测试集之间分割数据，以便稍后进行评估。</p><pre class="me mf mg mh gt mi mj mk ml aw mm bi"><span id="dbcf" class="mn la it mj b gy mo mp l mq mr"># model phase - train/test<br/>x_train, x_test, y_train, y_test = train_test_split(sample_custd[all_features], sample_custd[response], test_size=0.3)</span></pre><p id="9b01" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">现在我们可以训练和拟合随机森林模型。请随意调整模型设置，以获得更好的解决方案。</p><pre class="me mf mg mh gt mi mj mk ml aw mm bi"><span id="0f5c" class="mn la it mj b gy mo mp l mq mr">#Building random forest model<br/>rf_model = RandomForestClassifier(n_estimators=200,max_depth=5)</span><span id="e204" class="mn la it mj b gy ms mp l mq mr">#Features<br/>X = x_train<br/>#Output<br/>y = y_train</span><span id="6e63" class="mn la it mj b gy ms mp l mq mr">#Fit model to training data<br/>rf_model.fit(X, y)</span></pre><figure class="me mf mg mh gt ju gh gi paragraph-image"><div class="gh gi mt"><img src="../Images/40f136b72c8eec91fbd6597474c91033.png" data-original-src="https://miro.medium.com/v2/resize:fit:1204/0*WOylFmacYW82LMrf"/></div></figure><p id="be22" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">另外，在随机森林中，你可以看到一棵树是如何投票的。</p><pre class="me mf mg mh gt mi mj mk ml aw mm bi"><span id="df9b" class="mn la it mj b gy mo mp l mq mr">#looking at individual trees<br/>rf_model.estimators_<br/>﻿<br/>﻿﻿#individual tree setting<br/>rf_model.estimators_[0]<br/>﻿<br/>﻿﻿#individual tree prediction<br/>rf_model.estimators_[0].predict(x_test)[:10]</span></pre><figure class="me mf mg mh gt ju gh gi paragraph-image"><div class="gh gi mu"><img src="../Images/e1d7868b2d669413622800fa66a34b2f.png" data-original-src="https://miro.medium.com/v2/resize:fit:750/0*MnqvPsdPmknmxfuK"/></div></figure><p id="bb69" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">上面的数组是 0 号树对前 10 个样本的投票结果。很酷，对吧？回到 random forest，我们来看看模型是怎么想的，哪些功能对客户参与度最重要。</p><pre class="me mf mg mh gt mi mj mk ml aw mm bi"><span id="b309" class="mn la it mj b gy mo mp l mq mr">#Examining what RF thinks are important features<br/>rf_model.feature_importances_<br/>﻿<br/>﻿﻿feature_importance_df = pd.DataFrame(list(zip(rf_model.feature_importances_, all_features)))<br/>feature_importance_df.columns = ['feature.importance', 'feature']</span><span id="2389" class="mn la it mj b gy ms mp l mq mr">featsorted = feature_importance_df.sort_values(by='feature.importance', ascending=False)<br/>featsorted</span></pre><figure class="me mf mg mh gt ju gh gi paragraph-image"><div class="gh gi mv"><img src="../Images/666be0207043ccc58939c7511481aa7f.png" data-original-src="https://miro.medium.com/v2/resize:fit:710/0*sjeHCm8wWKdz5uf9"/></div></figure><p id="07df" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">好吧，那是一张长桌子。让我们以图形的形式让它更容易阅读——十大最重要的特性。</p><pre class="me mf mg mh gt mi mj mk ml aw mm bi"><span id="e8b8" class="mn la it mj b gy mo mp l mq mr">featsortedtop10 = featsorted.head(10)</span><span id="8849" class="mn la it mj b gy ms mp l mq mr">featsortedtop10.plot(kind='bar', x='feature')</span></pre><figure class="me mf mg mh gt ju gh gi paragraph-image"><div class="gh gi mw"><img src="../Images/55c299967d987dd28efc40042f5dd0db.png" data-original-src="https://miro.medium.com/v2/resize:fit:756/0*OHgZZtKuAivK2hcL"/></div></figure><p id="fcd3" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">根据 random forest 模型，退休员工最倾向于参与我们的营销工作。这并不奇怪，因为我们的数据集是关于一家保险公司的营销。</p><h1 id="d6fe" class="kz la it bd lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw bi translated">模型评估</h1><pre class="me mf mg mh gt mi mj mk ml aw mm bi"><span id="13ee" class="mn la it mj b gy mo mp l mq mr">in_sample = rf_model.predict(x_train)<br/>out_sample = rf_model.predict(x_test)</span><span id="7c59" class="mn la it mj b gy ms mp l mq mr">print('In-Sample Accuracy: %0.4f' % accuracy_score(y_train, in_sample))<br/>print('Out-of-Sample Accuracy: %0.4f' % accuracy_score(y_test, out_sample))</span></pre><p id="974c" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">样本内精度:0.8746</p><p id="cf72" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">样本外精度:0.8814</p><p id="422e" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">准确度是正确预测的数量除以预测的总数。基本上，随机森林模型在预测谁将参与营销活动方面是正确的。</p><pre class="me mf mg mh gt mi mj mk ml aw mm bi"><span id="ad5b" class="mn la it mj b gy mo mp l mq mr">print('In-Sample Precision: %0.4f' % precision_score(y_train, in_sample))<br/>print('Out-of-Sample Precision: %0.4f' % precision_score(y_test, out_sample))</span></pre><p id="d78c" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">样本内精度:0.9574</p><p id="2c57" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">样本外精度:0.8714</p><p id="cc08" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">精度是真阳性的数量除以真阳性和假阳性的数量。当你想知道预测有多正确时，你需要精确。例如，有多少客户实际参与了 X 营销活动，而不是那些被预测参与和没有参与的客户。</p><pre class="me mf mg mh gt mi mj mk ml aw mm bi"><span id="6b4c" class="mn la it mj b gy mo mp l mq mr">print('In-Sample Recall: %0.4f' % recall_score(y_train, in_sample))<br/>print('Out-of-Sample Recall: %0.4f' % recall_score(y_test, out_sample))</span></pre><p id="e0f5" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">样本召回率:0.1450</p><p id="72ce" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">样本外召回:0.1618</p><p id="61c8" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">召回是真阳性的数量除以真阳性和假阴性的数量。换句话说，有多少模型正确地预测了与 X 活动接触的客户，而不是那些实际接触的客户。</p><p id="999e" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">当我学习精确和回忆的区别时，我有点困惑。对我有帮助的是看到一个好的和另一个坏的区别。例如，高精度和低召回率可以发现目标输出，但是会遗漏一些目标输出机会。另一方面，高召回率和低精确度可能导致发现所有目标输出，但是预测实际上没有的目标输出。</p><pre class="me mf mg mh gt mi mj mk ml aw mm bi"><span id="688f" class="mn la it mj b gy mo mp l mq mr"># ROC and AUC curves<br/>in_sample = rf_model.predict_proba(x_train)[:,1]<br/>out_sample = rf_model.predict_proba(x_test)[:,1]<br/>in_sample_fpr, in_sample_tpr, in_sample_thresholds = roc_curve(y_train, in_sample)<br/>out_sample_fpr, out_sample_tpr, out_sample_thresholds = roc_curve(y_test, out_sample)<br/>in_sample_roc_auc = auc(in_sample_fpr, in_sample_tpr)<br/>out_sample_roc_auc = auc(out_sample_fpr, out_sample_tpr)</span><span id="9ef3" class="mn la it mj b gy ms mp l mq mr">print('In-Sample AUC: %0.4f' % in_sample_roc_auc)<br/>print('Out-Sample AUC: %0.4f' % out_sample_roc_auc)</span></pre><p id="10b6" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">样本内 AUC: 0.8824</p><p id="06a3" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">样本外 AUC: 0.8623</p><pre class="me mf mg mh gt mi mj mk ml aw mm bi"><span id="41df" class="mn la it mj b gy mo mp l mq mr">plt.figure(figsize=(10,7))</span><span id="479e" class="mn la it mj b gy ms mp l mq mr">plt.plot(<br/>    out_sample_fpr, out_sample_tpr, color='darkorange', label='Out-Sample ROC curve (area = %0.4f)' % in_sample_roc_auc<br/>)<br/>plt.plot(<br/>    in_sample_fpr, in_sample_tpr, color='navy', label='In-Sample ROC curve (area = %0.4f)' % out_sample_roc_auc<br/>)<br/>plt.plot([0, 1], [0, 1], color='gray', lw=1, linestyle='--')<br/>plt.grid()<br/>plt.xlim([0.0, 1.0])<br/>plt.ylim([0.0, 1.05])<br/>plt.xlabel('False Positive Rate')<br/>plt.ylabel('True Positive Rate')<br/>plt.title('RandomForest Model ROC Curve')<br/>plt.legend(loc="lower right")</span><span id="d401" class="mn la it mj b gy ms mp l mq mr">plt.show()</span></pre><figure class="me mf mg mh gt ju gh gi paragraph-image"><div class="gh gi mx"><img src="../Images/7e8983256cdacf2daed6497aa0fcd244.png" data-original-src="https://miro.medium.com/v2/resize:fit:1234/0*9d2KwVQ65TFLGx6J"/></div></figure><p id="c5af" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">ROC 曲线显示了真阳性和假阳性的比率，您希望曲线最快到达左上角以获得最佳模型性能。我们的样本内和样本外曲线都没问题。如果两者之间的差距越来越大，那么这是一个迹象，表明该模型过于适合训练数据，而没有找到营销参与的一般模式[4]。</p><h1 id="a1bf" class="kz la it bd lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw bi translated">结论</h1><p id="eb81" class="pw-post-body-paragraph kb kc it kd b ke lx kg kh ki ly kk kl km lz ko kp kq ma ks kt ku mb kw kx ky im bi translated">恭喜，我们已经从头到尾建立了一个营销客户参与随机森林模型。首先，我们做了一些简单的数据探索，并对数据进行了特征工程处理，使之成为数值。接下来，我们创建了随机森林模型，并查看了各个决策树。之后，我们评估了训练集和测试集的数据，得到了一个非常好的 ROC 曲线。从我们的数据来看，客户退休似乎是一个关键特征，而总索赔和收入接近。向前发展的业务解决方案可以建议总是预先获取这些数据点。</p><p id="af26" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">免责声明:本文陈述的所有内容都是我个人的观点，不代表任何雇主。</p><h1 id="a6bb" class="kz la it bd lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw bi translated">参考</h1><p id="360f" class="pw-post-body-paragraph kb kc it kd b ke lx kg kh ki ly kk kl km lz ko kp kq ma ks kt ku mb kw kx ky im bi translated">[1] A. McEachern，什么是客户参与，为什么它很重要？(2019)<a class="ae mc" href="https://blog.smile.io/what-is-customer-engagement-and-why-is-it-important" rel="noopener ugc nofollow" target="_blank">https://blog . smile . io/什么是客户参与度以及它为什么重要</a></p><p id="5187" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">[2] IBM Watson，营销客户价值数据(n . d .)<br/>https://www . ka ggle . com/pankajjsh 06/IBM-Watson-Marketing-Customer-Value-Data/downloads/IBM-Watson-Marketing-Customer-Value-Data . zip/1</p><p id="05dd" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">[3] B. Mikulski，Precision vs . recall-explain(n . d .)<a class="ae mc" href="https://www.mikulskibartosz.name/precision-vs-recall-explanation/" rel="noopener ugc nofollow" target="_blank">https://www . mikulskibartosz . name/Precision-vs-recall-explain/</a></p><p id="d688" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">[4] Y. Hwang,《营销数据科学实践》( 2019 年),派克特出版社</p></div></div>    
</body>
</html>