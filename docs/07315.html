<html>
<head>
<title>Pyspark – Feature engineering (P1)</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">py spark–特征工程(P1)</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/pyspark-feature-engineering-p1-f55cbd2b7565?source=collection_archive---------19-----------------------#2019-10-14">https://towardsdatascience.com/pyspark-feature-engineering-p1-f55cbd2b7565?source=collection_archive---------19-----------------------#2019-10-14</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="728a" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">计算、聚合、转换任何数据</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/c642dff3a6b7d10764cc9b447e82d151.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*jvxJNDq39isZ-Kgf9VsSAQ.png"/></div></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk"><a class="ae ky" href="https://upload.wikimedia.org/wikipedia/commons/f/f3/Apache_Spark_logo.svg" rel="noopener ugc nofollow" target="_blank">https://upload.wikimedia.org/wikipedia/commons/f/f3/Apache_Spark_logo.svg</a></figcaption></figure></div><div class="ab cl kz la hx lb" role="separator"><span class="lc bw bk ld le lf"/><span class="lc bw bk ld le lf"/><span class="lc bw bk ld le"/></div><div class="im in io ip iq"><p id="bea2" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">在本文中，我们将看到如何通过连接、窗口函数、UDF 和向量操作来计算新变量。</p><p id="44f8" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">提醒一下，下面是我们使用的表格:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi mc"><img src="../Images/8220ac449c5a320e7bcdd679007f6832.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*LMC9FazVQkWw9lTB.png"/></div></div></figure><h2 id="2d39" class="md me it bd mf mg mh dn mi mj mk dp ml lp mm mn mo lt mp mq mr lx ms mt mu mv bi translated">。使用列和 sql 函数</h2><p id="0048" class="pw-post-body-paragraph lg lh it li b lj mw ju ll lm mx jx lo lp my lr ls lt mz lv lw lx na lz ma mb im bi translated">要在 Spark 上创建新的列，只需传递函数。withColumn 并添加 sql 函数</p><pre class="kj kk kl km gt nb nc nd ne aw nf bi"><span id="3bf6" class="md me it nc b gy ng nh l ni nj">df = (df<br/> .withColumn('dayofyear', F.dayofyear(F.col("ID_DAY")))<br/> .withColumn('Month', F.Month(F.col('ID_DAY')))<br/> .withColumn('ratio_ticket_qty', F.col('F_TOTAL_QTY')/F.col('NB_TICKET'))<br/> )</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nk"><img src="../Images/a51d568591575922ad1152358880578e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*75QIHtO_Ea4ZPJ5Mh4ed3w.png"/></div></div></figure><p id="b513" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">更多请看这里:<a class="ae ky" href="https://spark.apache.org/docs/latest/api/python/pyspark.sql.html" rel="noopener ugc nofollow" target="_blank"> <strong class="li iu"> SQL 函数</strong> </a></p><h2 id="7fd2" class="md me it bd mf mg mh dn mi mj mk dp ml lp mm mn mo lt mp mq mr lx ms mt mu mv bi translated">。条件为 f 的列</h2><p id="5e81" class="pw-post-body-paragraph lg lh it li b lj mw ju ll lm mx jx lo lp my lr ls lt mz lv lw lx na lz ma mb im bi translated">与 sql 一样，可以使用 when 框进行条件计算。</p><pre class="kj kk kl km gt nb nc nd ne aw nf bi"><span id="657b" class="md me it nc b gy ng nh l ni nj">df = df.withColumn("day_to_xmas", F.when((F.col("ID_DAY").between("2018-12-01", "2018-12-31")) | (F.col('ID_DAY').between("2019-12-01", "2019-12-31")), <br/>    F.lit('xmas_is_coming')).otherwise(F.datediff(F.col("ID_DAY"), F.lit('2018-12-01').cast(DateType())))<br/>)</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nl"><img src="../Images/32b2d6566685ec669b6750b94d134c64.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*H8S-FVzVestNCszK-dZ3qw.png"/></div></div></figure><h2 id="c8cb" class="md me it bd mf mg mh dn mi mj mk dp ml lp mm mn mo lt mp mq mr lx ms mt mu mv bi translated">。带列和窗口功能</h2><p id="2705" class="pw-post-body-paragraph lg lh it li b lj mw ju ll lm mx jx lo lp my lr ls lt mz lv lw lx na lz ma mb im bi translated">窗口函数对于计算时间轴上的值或保存用户连接非常有用</p><pre class="kj kk kl km gt nb nc nd ne aw nf bi"><span id="b06a" class="md me it nc b gy ng nh l ni nj">grouped_windows = Window.partitionBy(F.col('SID_STORE'), F.col('Month'))</span><span id="5052" class="md me it nc b gy nm nh l ni nj">rolling_windows = (Window.orderBy(F.col("dayofyear").cast(IntegerType())).rangeBetween(-7, 0))</span><span id="3b51" class="md me it nc b gy nm nh l ni nj">df = (df<br/> .withColumn('rolling_average', F.avg("F_TOTAL_QTY").over(rolling_windows))<br/> .withColumn('monthly_qty', F.avg('F_TOTAL_QTY').over(grouped_windows))<br/> )</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nn"><img src="../Images/a651763706e72e89a3e63848eaf599f6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*LtwvfvN87J-kZofwH8w2ug.png"/></div></div></figure><h2 id="331a" class="md me it bd mf mg mh dn mi mj mk dp ml lp mm mn mo lt mp mq mr lx ms mt mu mv bi translated">只是一个连接</h2><p id="1256" class="pw-post-body-paragraph lg lh it li b lj mw ju ll lm mx jx lo lp my lr ls lt mz lv lw lx na lz ma mb im bi translated">我们可以通过连接对 monthly_qty 进行与 windows 函数完全相同的计算。</p><pre class="kj kk kl km gt nb nc nd ne aw nf bi"><span id="c456" class="md me it nc b gy ng nh l ni nj">month_qty = df.groupBy('SID_STORE', 'Month').agg(F.avg('F_TOTAL_QTY').alias('monthly_qty_by_join'))<br/>df = df.join(month_qty, how = "left", on = ["SID_STORE", "Month"])</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi no"><img src="../Images/22bbbf1a19dc48e9b5bd316ff02550cd.png" data-original-src="https://miro.medium.com/v2/resize:fit:678/format:webp/1*cCP7rxne_m6Erc3h7jfkvg.png"/></div></div></figure><h2 id="8a30" class="md me it bd mf mg mh dn mi mj mk dp ml lp mm mn mo lt mp mq mr lx ms mt mu mv bi translated">用户定义的函数(UDF)</h2><p id="a81a" class="pw-post-body-paragraph lg lh it li b lj mw ju ll lm mx jx lo lp my lr ls lt mz lv lw lx na lz ma mb im bi translated">我们可以像在 python 上一样在 pyspark 上定义函数，但它不会(直接)与我们的 spark 数据框架兼容。为此，我们需要定义一个 UDF(用户定义的函数),它将允许我们在 Spark 数据帧上应用我们的函数。缺点是 UDF 可能很长，因为它们是逐行应用的。要应用一个 UDF，只需将它作为函数的修饰者，用一种与其输出相关联的数据类型来添加即可。</p><pre class="kj kk kl km gt nb nc nd ne aw nf bi"><span id="c441" class="md me it nc b gy ng nh l ni nj"><strong class="nc iu">from</strong> pyspark.sql.functions <strong class="nc iu">import</strong> udf</span><span id="9ba8" class="md me it nc b gy nm nh l ni nj">@udf("long")<br/><strong class="nc iu">def</strong> squared_udf(s):<br/>  <strong class="nc iu">return</strong> s * s</span><span id="555e" class="md me it nc b gy nm nh l ni nj">df = df.withColumn('squared_col', squared_udf(F.col('my_columns')))</span></pre><p id="3961" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">仅此而已。</p><h2 id="13f2" class="md me it bd mf mg mh dn mi mj mk dp ml lp mm mn mo lt mp mq mr lx ms mt mu mv bi translated">向量 UDT 和 numpy 处理复杂数组操作</h2><p id="8cdb" class="pw-post-body-paragraph lg lh it li b lj mw ju ll lm mx jx lo lp my lr ls lt mz lv lw lx na lz ma mb im bi translated">现在，我们将计算每个商店的参考数量，即 1 年前同一天的销售量。然而，这一天可能没有销售，所以我们将在这个参考日期前后平均 7 天。这个功能会更复杂，需要<strong class="li iu"> numpy。T </strong> t 确实有可能把 numpy 和 spark 说清楚，我们来看看怎么做。</p><p id="c68a" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">首先，必须定义一个用户定义的函数，以矢量化和稀疏的方式从每个存储中提取时间序列。我们之前已经了解了什么是 UDF，我们将定义一个稀疏向量，它用一年中的天数和相关量的值来索引</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="np nq l"/></div></figure><p id="418e" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">好吧，让我们休息一下，他有一些事情要解释。</p><ul class=""><li id="f16c" class="nr ns it li b lj lk lm ln lp nt lt nu lx nv mb nw nx ny nz bi translated">输入:我们要求一个日期索引和相关数量值的列表</li><li id="186f" class="nr ns it li b lj oa lm ob lp oc lt od lx oe mb nw nx ny nz bi translated">输出:我们返回一个按日索引的稀疏向量，这允许我们找到与他的日索引相关的数量</li></ul><p id="138e" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">整个过程通过一个 UDF，并期望成为一个<code class="fe of og oh nc b"><a class="ae ky" href="https://spark.apache.org/docs/2.1.2/api/java/org/apache/spark/mllib/linalg/VectorUDT.html" rel="noopener ugc nofollow" target="_blank">VectorUDT</a></code>简洁地说，这是一种可以被 UDF 操纵的向量。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="np nq l"/></div></figure><p id="27a1" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">然后，为了响应函数请求的输入，我们将每年创建一个聚合数据帧，存储并应用一个 collect_list 到日期和数量。正如您在下面看到的，我们恢复了商店当年的所有日数量值。这两个列表进入我们的 UDF 来创建想要的向量，现在我们可以在 numpy 中处理这个向量了！</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oi"><img src="../Images/2c4a30d1ec1b55ca80e21f2940265827.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*DXergYNAJBBmQB7-2G_omQ.png"/></div></div></figure><p id="56c9" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">现在我们可以定义一个作用于这个向量的函数，并再次把它放到 UDF 中。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="np nq l"/></div></figure><p id="0638" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">并应用它:</p><pre class="kj kk kl km gt nb nc nd ne aw nf bi"><span id="5d83" class="md me it nc b gy ng nh l ni nj">df= (df<br/>    .join(self_join<br/>        , ([self_join.p_id_store == df.SID_STORE, self_join.year_join ==  df.year]),<br/>        how = "left"<br/>        )<br/>        .withColumn("qty_reference", getReference(F.col("yearday"), F.col("qties_vectorized")))<br/>        )</span></pre><p id="4d3c" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">让我们详细描述一下这个函数，首先它试图找到准确的参考日，我们已经将数据帧和它的前一年连接在一起，所以我们希望当前日等于向量中的索引日并得到值。如果无法检索该值，我们将围绕该关键日期定义一个窗口，并对该窗口的值进行平均。</p><p id="c915" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">最后的结果是:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi oj"><img src="../Images/066f53e2b78d2ef32401dc979f7e044c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1136/format:webp/1*jKBP_KH49wslkfd6u464-w.png"/></div></figure><h2 id="e228" class="md me it bd mf mg mh dn mi mj mk dp ml lp mm mn mo lt mp mq mr lx ms mt mu mv bi translated">更快的..更强壮的..再进一步！将您的特征工程包装在管道中！</h2><p id="2856" class="pw-post-body-paragraph lg lh it li b lj mw ju ll lm mx jx lo lp my lr ls lt mz lv lw lx na lz ma mb im bi translated">在这里，我写的另一篇文章介绍了如何创建一个定制管道来一次性集成所有这些特性:</p><ul class=""><li id="eb08" class="nr ns it li b lj lk lm ln lp nt lt nu lx nv mb nw nx ny nz bi translated"><a class="ae ky" rel="noopener" target="_blank" href="/pyspark-wrap-your-feature-engineering-in-a-pipeline-ee63bdb913">https://towards data science . com/py spark-wrap-your-feature-engineering-in-a-pipeline-ee 63 BDB 913</a></li></ul><h1 id="f7cc" class="ok me it bd mf ol om on mi oo op oq ml jz or ka mo kc os kd mr kf ot kg mu ou bi translated">最后</h1><p id="d265" class="pw-post-body-paragraph lg lh it li b lj mw ju ll lm mx jx lo lp my lr ls lt mz lv lw lx na lz ma mb im bi translated">现在，您已经构建了令人惊叹的特征，您需要索引您的分类特征，或者对它们进行一次性编码，并且可能应用一些特征缩减，然后将所有内容打包到一个向量组装器中进行建模！不介意这是下一篇:)</p><p id="b49b" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">【Y】You 可以在这里找到代码<em class="ov">:</em><a class="ae ky" href="https://github.com/AlexWarembourg/Medium" rel="noopener ugc nofollow" target="_blank"><em class="ov">https://github.com/AlexWarembourg/Medium</em></a></p></div></div>    
</body>
</html>