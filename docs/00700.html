<html>
<head>
<title>The Complete Beginner’s Guide to Deep Learning: Convolutional Neural Networks and Image Classification</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">深度学习完全初学者指南:卷积神经网络和图像分类</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/wtf-is-image-classification-8e78a8235acb?source=collection_archive---------0-----------------------#2019-02-02">https://towardsdatascience.com/wtf-is-image-classification-8e78a8235acb?source=collection_archive---------0-----------------------#2019-02-02</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="85be" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">在几分钟内攻克 CNN 和图像分类的基础知识</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/4951f64ee0dec007c192d8996f6bc063.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*mlB-5dhmRuU267pMkPKWnQ.jpeg"/></div></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk">Image by VislazFotosas via <a class="ae ky" href="http://pixabay.com" rel="noopener ugc nofollow" target="_blank">Pixabay</a></figcaption></figure><blockquote class="kz la lb"><p id="4c39" class="lc ld le lf b lg lh ju li lj lk jx ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">“我很早就注意到的一件事是，你不会把将要拍出来的东西放进照片里。或者反过来，出来的不是你放进去的。”</p><p id="1a4c" class="lc ld le lf b lg lh ju li lj lk jx ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">― <strong class="lf iu">黛安·阿勃斯</strong></p></blockquote><p id="306d" class="pw-post-body-paragraph lc ld it lf b lg lh ju li lj lk jx ll lz ln lo lp ma lr ls lt mb lv lw lx ly im bi translated">你最喜欢的社交网络上弹出通知，有人发布了一张可能有你的照片。</p><p id="cf19" class="pw-post-body-paragraph lc ld it lf b lg lh ju li lj lk jx ll lz ln lo lp ma lr ls lt mb lv lw lx ly im bi translated">没错。</p><p id="17d2" class="pw-post-body-paragraph lc ld it lf b lg lh ju li lj lk jx ll lz ln lo lp ma lr ls lt mb lv lw lx ly im bi translated">这是你有史以来最差的照片。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="mc md l"/></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk">GIF via <a class="ae ky" href="https://giphy.com/gifs/4wpr7XmetlW6Y" rel="noopener ugc nofollow" target="_blank">GIPHY</a></figcaption></figure><p id="db54" class="pw-post-body-paragraph lc ld it lf b lg lh ju li lj lk jx ll lz ln lo lp ma lr ls lt mb lv lw lx ly im bi translated">那是怎么发生的？</p><p id="1de3" class="pw-post-body-paragraph lc ld it lf b lg lh ju li lj lk jx ll lz ln lo lp ma lr ls lt mb lv lw lx ly im bi translated"><strong class="lf iu">图像分类</strong>！</p><p id="1328" class="pw-post-body-paragraph lc ld it lf b lg lh ju li lj lk jx ll lz ln lo lp ma lr ls lt mb lv lw lx ly im bi translated">卷积神经网络(CNN)是<strong class="lf iu">深度学习神经网络</strong>的一类。CNN 代表了图像识别的巨大突破。它们最常用于分析视觉图像，并且经常在图像分类的幕后工作。从脸书的照片标签到无人驾驶汽车，它们都是一切事物的核心。从医疗保健到安全，他们都在幕后努力工作。</p><p id="1892" class="pw-post-body-paragraph lc ld it lf b lg lh ju li lj lk jx ll lz ln lo lp ma lr ls lt mb lv lw lx ly im bi translated">他们又快又有效率。但是它们是如何工作的呢？</p><p id="1567" class="pw-post-body-paragraph lc ld it lf b lg lh ju li lj lk jx ll lz ln lo lp ma lr ls lt mb lv lw lx ly im bi translated">图像分类是获取一个<strong class="lf iu">输入</strong>(像一张图片)并输出一个<strong class="lf iu">类</strong>(像“猫”)或一个<strong class="lf iu">概率</strong>输入是一个特定的类(“这个输入有 90%的概率是一只猫”)。你可以看着一张照片，知道你正在看一张你自己的可怕的照片，但是计算机怎么能学会这样做呢？</p><p id="76a2" class="pw-post-body-paragraph lc ld it lf b lg lh ju li lj lk jx ll lz ln lo lp ma lr ls lt mb lv lw lx ly im bi translated">用卷积神经网络！</p><p id="940a" class="pw-post-body-paragraph lc ld it lf b lg lh ju li lj lk jx ll lz ln lo lp ma lr ls lt mb lv lw lx ly im bi translated">美国有线电视新闻网</p><ul class=""><li id="def8" class="me mf it lf b lg lh lj lk lz mg ma mh mb mi ly mj mk ml mm bi translated">卷积层</li><li id="d8b0" class="me mf it lf b lg mn lj mo lz mp ma mq mb mr ly mj mk ml mm bi translated">ReLU 层</li><li id="9760" class="me mf it lf b lg mn lj mo lz mp ma mq mb mr ly mj mk ml mm bi translated">池层</li><li id="202f" class="me mf it lf b lg mn lj mo lz mp ma mq mb mr ly mj mk ml mm bi translated">完全连接的层</li></ul><p id="8d6e" class="pw-post-body-paragraph lc ld it lf b lg lh ju li lj lk jx ll lz ln lo lp ma lr ls lt mb lv lw lx ly im bi translated">一个经典的 CNN 架构应该是这样的:</p><p id="546a" class="pw-post-body-paragraph lc ld it lf b lg lh ju li lj lk jx ll lz ln lo lp ma lr ls lt mb lv lw lx ly im bi translated"><strong class="lf iu">输入- &gt;卷积- &gt; ReLU - &gt;卷积- &gt; ReLU - &gt;汇集- &gt; <br/> ReLU - &gt;卷积- &gt; ReLU - &gt;汇集- &gt;全连接</strong></p><p id="0aef" class="pw-post-body-paragraph lc ld it lf b lg lh ju li lj lk jx ll lz ln lo lp ma lr ls lt mb lv lw lx ly im bi translated">CNN <strong class="lf iu">卷积</strong>(非卷积…)学习输入数据的特征，并使用 2D 卷积层。这意味着这种类型的网络是处理 2D 图像的理想选择。与其他图像分类算法相比，CNN 实际上很少使用预处理。这意味着他们可以<strong class="lf iu">学习</strong>其他算法中必须手工制作的过滤器。CNN 可以用于大量的应用，从图像和视频识别、图像分类和推荐系统到自然语言处理和医学图像分析。</p><p id="db97" class="pw-post-body-paragraph lc ld it lf b lg lh ju li lj lk jx ll lz ln lo lp ma lr ls lt mb lv lw lx ly im bi translated">CNN 受到生物过程的启发。他们基于 Hubel 和 Wiesel 在 60 年代对猫和猴子的视觉所做的一些很酷的研究。CNN 的连接模式来自他们对视觉皮层组织的研究。在哺乳动物的眼睛中，单个神经元只在感受野对视觉刺激做出反应，这是一个受限制的区域。不同区域的感受野部分重叠，从而覆盖整个视野。这就是 CNN 的工作方式！</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ms"><img src="../Images/21bd4f6d281aaf1a2d71a14072e6bad8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1280/format:webp/1*YsGD43vMQNzgapTxQzH2uA.jpeg"/></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk">Image by NatWhitePhotography on <a class="ae ky" href="http://pixabay.com" rel="noopener ugc nofollow" target="_blank">Pixabay</a></figcaption></figure><p id="094b" class="pw-post-body-paragraph lc ld it lf b lg lh ju li lj lk jx ll lz ln lo lp ma lr ls lt mb lv lw lx ly im bi translated">CNN 有输入层、输出层和隐藏层。隐藏层通常由卷积层、ReLU 层、池层和全连接层组成。</p><ul class=""><li id="50ed" class="me mf it lf b lg lh lj lk lz mg ma mh mb mi ly mj mk ml mm bi translated">卷积层对输入应用卷积运算。这将信息传递到下一层。</li><li id="68f6" class="me mf it lf b lg mn lj mo lz mp ma mq mb mr ly mj mk ml mm bi translated">汇集将神经元簇的输出组合成下一层中的单个神经元。</li><li id="ab7b" class="me mf it lf b lg mn lj mo lz mp ma mq mb mr ly mj mk ml mm bi translated">完全连接的层将一层中的每个神经元连接到下一层中的每个神经元。</li></ul><p id="de71" class="pw-post-body-paragraph lc ld it lf b lg lh ju li lj lk jx ll lz ln lo lp ma lr ls lt mb lv lw lx ly im bi translated">在卷积层中，神经元仅接收来自前一层的子区域的输入。在完全连接的层中，每个神经元接收来自前一层的每个元素的<em class="le">输入。</em></p><p id="719f" class="pw-post-body-paragraph lc ld it lf b lg lh ju li lj lk jx ll lz ln lo lp ma lr ls lt mb lv lw lx ly im bi translated">CNN 的工作原理是从图像中提取特征。这消除了手动特征提取的需要。特征没有经过训练！它们是在网络对一组图像进行训练时学习的。这使得深度学习模型对于计算机视觉任务来说极其准确。CNN 通过几十或几百个隐藏层学习特征检测。每一层都增加了所学特征的复杂性。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="mt md l"/></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk">GIF via <a class="ae ky" href="https://gph.is/1bviWQm" rel="noopener ugc nofollow" target="_blank">GIPHY</a></figcaption></figure><h2 id="7583" class="mu mv it bd mw mx my dn mz na nb dp nc lz nd ne nf ma ng nh ni mb nj nk nl nm bi translated">美国有线电视新闻网</h2><ul class=""><li id="b108" class="me mf it lf b lg nn lj no lz np ma nq mb nr ly mj mk ml mm bi translated">从输入图像开始</li><li id="bdb6" class="me mf it lf b lg mn lj mo lz mp ma mq mb mr ly mj mk ml mm bi translated">对其应用许多不同的过滤器以创建特征地图</li><li id="658e" class="me mf it lf b lg mn lj mo lz mp ma mq mb mr ly mj mk ml mm bi translated">应用 ReLU 函数来增加非线性</li><li id="8c03" class="me mf it lf b lg mn lj mo lz mp ma mq mb mr ly mj mk ml mm bi translated">将池化图层应用于每个要素地图</li><li id="58d5" class="me mf it lf b lg mn lj mo lz mp ma mq mb mr ly mj mk ml mm bi translated">将合并的图像展平为一个长矢量。</li><li id="9368" class="me mf it lf b lg mn lj mo lz mp ma mq mb mr ly mj mk ml mm bi translated">将向量输入到完全连接的人工神经网络中。</li><li id="2d58" class="me mf it lf b lg mn lj mo lz mp ma mq mb mr ly mj mk ml mm bi translated">通过网络处理要素。最后的全连接层提供了我们所追求的类的“投票”。</li><li id="f3ff" class="me mf it lf b lg mn lj mo lz mp ma mq mb mr ly mj mk ml mm bi translated">通过前向传播和后向传播训练很多很多个时代。这一过程一直重复，直到我们拥有一个定义明确的神经网络，该网络具有经过训练的权重和特征检测器。</li></ul><h2 id="0041" class="mu mv it bd mw mx my dn mz na nb dp nc lz nd ne nf ma ng nh ni mb nj nk nl nm bi translated">这意味着什么呢？</h2><p id="6cd3" class="pw-post-body-paragraph lc ld it lf b lg nn ju li lj no jx ll lz ns lo lp ma nt ls lt mb nu lw lx ly im bi translated">在这个过程的最开始，输入图像被分解成像素。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nv md l"/></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk">GIF via <a class="ae ky" href="https://giphy.com/gifs/l0HlMr2G3EKFgpUY0" rel="noopener ugc nofollow" target="_blank">GIPHY</a></figcaption></figure><p id="8967" class="pw-post-body-paragraph lc ld it lf b lg lh ju li lj lk jx ll lz ln lo lp ma lr ls lt mb lv lw lx ly im bi translated">对于黑白图像，这些像素被解释为 2D 阵列(例如，2x2 像素)。每个像素的值都在 0 到 255 之间。(零全黑，255 全白。灰度存在于这些数字之间。)基于这些信息，计算机可以开始处理这些数据。</p><p id="5510" class="pw-post-body-paragraph lc ld it lf b lg lh ju li lj lk jx ll lz ln lo lp ma lr ls lt mb lv lw lx ly im bi translated">对于彩色图像，这是一个包含蓝色层、绿色层和红色层的 3D 阵列。每一种颜色都有自己的值，在 0 到 255 之间。可以通过组合三层中每一层的值来找到颜色。</p><h1 id="05f4" class="nw mv it bd mw nx ny nz mz oa ob oc nc jz od ka nf kc oe kd ni kf of kg nl og bi translated">CNN 的基本组成部分是什么？</h1><h2 id="4b22" class="mu mv it bd mw mx my dn mz na nb dp nc lz nd ne nf ma ng nh ni mb nj nk nl nm bi translated"><strong class="ak">卷积</strong></h2><p id="59da" class="pw-post-body-paragraph lc ld it lf b lg nn ju li lj no jx ll lz ns lo lp ma nt ls lt mb nu lw lx ly im bi translated">卷积步骤的主要目的是从输入图像中提取特征。卷积层总是 CNN 的第一步。</p><p id="1d65" class="pw-post-body-paragraph lc ld it lf b lg lh ju li lj lk jx ll lz ln lo lp ma lr ls lt mb lv lw lx ly im bi translated">您有一个输入图像、一个特征检测器和一个特征图。你把滤镜一个像素一个像素地应用到输入图像上。你可以通过矩阵相乘来实现。</p><p id="0b05" class="pw-post-body-paragraph lc ld it lf b lg lh ju li lj lk jx ll lz ln lo lp ma lr ls lt mb lv lw lx ly im bi translated">假设你有一个手电筒和一张气泡纸。你的手电筒照亮了一个 5 个泡泡 x 5 个泡泡的区域。要查看整张纸，你可以用手电筒扫过每个 5x5 的正方形，直到看到所有的气泡。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ms"><img src="../Images/3d5c1bedf04b2e4172f658b8531ac927.png" data-original-src="https://miro.medium.com/v2/resize:fit:1280/format:webp/1*J_uJZ1GTA6OlZlVGFbMIjQ.jpeg"/></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk">Photo by stux on <a class="ae ky" href="http://pixabay.com" rel="noopener ugc nofollow" target="_blank">Pixabay</a></figcaption></figure><p id="1f72" class="pw-post-body-paragraph lc ld it lf b lg lh ju li lj lk jx ll lz ln lo lp ma lr ls lt mb lv lw lx ly im bi translated">手电筒发出的光是你的<strong class="lf iu">滤镜</strong>，你滑过的区域是<strong class="lf iu">感受野</strong>。滑过感受野的光是你的手电筒<strong class="lf iu">回旋</strong>。您的过滤器是一组数字(也称为权重或参数)。手电筒发出的光在行进过程中滑动的距离(你是在一次一排气泡上移动滤镜吗？两个？)被称为<strong class="lf iu">步幅</strong>。例如，步幅为 1 意味着您一次移动一个像素的滤镜。大会是一步两个脚印。</p><p id="8efc" class="pw-post-body-paragraph lc ld it lf b lg lh ju li lj lk jx ll lz ln lo lp ma lr ls lt mb lv lw lx ly im bi translated">滤镜的深度必须与输入的深度相同，所以如果我们看的是彩色图像，深度应该是 3。这使得该滤波器的尺寸为 5x5x3。在每个位置，滤镜将滤镜中的值与像素中的原始值相乘。这是元素式乘法。将乘法相加，得到一个数。如果您从气泡包装的左上角开始，这个数字代表左上角。现在你移动你的过滤器到下一个位置，重复这个过程。你最终得到的数组叫做<strong class="lf iu">特性图</strong>或者<strong class="lf iu">激活图</strong>！您可以使用多个过滤器，这样可以更好地保留空间关系。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="oh md l"/></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk">GIF via <a class="ae ky" href="https://giphy.com/gifs/blog-daniel-keypoints-i4NjAwytgIRDW" rel="noopener ugc nofollow" target="_blank">GIPHY</a></figcaption></figure><p id="b6f3" class="pw-post-body-paragraph lc ld it lf b lg lh ju li lj lk jx ll lz ln lo lp ma lr ls lt mb lv lw lx ly im bi translated">您将指定过滤器数量、过滤器大小、网络架构等参数。CNN 在训练过程中自己学习滤波器的值。您有许多选项可以用来为您的任务制作最佳的图像分类器。您可以选择用零填充输入矩阵(<strong class="lf iu">零填充</strong>)，将过滤器应用于输入图像矩阵的边界元素。这也允许您控制特征地图的大小。加零填充是<strong class="lf iu">宽卷积</strong>。不加补零是<strong class="lf iu">窄卷积</strong>。</p><p id="6720" class="pw-post-body-paragraph lc ld it lf b lg lh ju li lj lk jx ll lz ln lo lp ma lr ls lt mb lv lw lx ly im bi translated">这基本上就是我们检测图像的方式！我们不会查看图像的每一个像素。我们看到像帽子、红色连衣裙、纹身等特征。每时每刻都有如此多的信息进入我们的眼睛，我们不可能处理其中的每一个像素。我们允许我们的模型做同样的事情。</p><p id="3d25" class="pw-post-body-paragraph lc ld it lf b lg lh ju li lj lk jx ll lz ln lo lp ma lr ls lt mb lv lw lx ly im bi translated">这样的结果就是卷积后的<strong class="lf iu">特征图</strong>。它比原始输入图像小。这使得处理起来更加容易和快速。我们会失去信息吗？一些，是的。但同时，特征检测器的目的是检测特征，这正是它的作用。</p><p id="69f5" class="pw-post-body-paragraph lc ld it lf b lg lh ju li lj lk jx ll lz ln lo lp ma lr ls lt mb lv lw lx ly im bi translated">我们创建了许多特征地图来得到我们的第一个卷积层。这允许我们识别程序可以用来学习的许多不同的特征。</p><p id="a3de" class="pw-post-body-paragraph lc ld it lf b lg lh ju li lj lk jx ll lz ln lo lp ma lr ls lt mb lv lw lx ly im bi translated">可以用不同的值设置特征检测器，以获得不同的结果。例如，可以应用能够锐化和聚焦图像或者模糊图像的过滤器。这将对所有的价值给予同等的重视。您可以进行边缘增强、边缘检测等操作。您可以通过应用不同的特征检测器来创建不同的特征地图。计算机能够确定哪些过滤器最有意义并应用它们。</p><p id="e1e6" class="pw-post-body-paragraph lc ld it lf b lg lh ju li lj lk jx ll lz ln lo lp ma lr ls lt mb lv lw lx ly im bi translated">这里的主要目的是找到图像中的要素，将它们放入要素地图中，并仍然保留像素之间的空间关系。这一点很重要，这样像素才不会变得混乱。</p><h2 id="8ddd" class="mu mv it bd mw mx my dn mz na nb dp nc lz nd ne nf ma ng nh ni mb nj nk nl nm bi translated">让我们想象一下这个东西！</h2><blockquote class="oi"><p id="e3d8" class="oj ok it bd ol om on oo op oq or ly dk translated">向我的小朋友问好:</p></blockquote><figure class="os ot ou ov ow kn gh gi paragraph-image"><div class="gh gi ms"><img src="../Images/3f47df9029183939bf34e82788199bf8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1280/format:webp/1*Bxk2390QZIbcZlSAMiIkaQ.jpeg"/></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk">Photo by Kirgiz03 on <a class="ae ky" href="http://pixabay.com" rel="noopener ugc nofollow" target="_blank">Pixabay</a></figcaption></figure><p id="bfbd" class="pw-post-body-paragraph lc ld it lf b lg lh ju li lj lk jx ll lz ln lo lp ma lr ls lt mb lv lw lx ly im bi translated">我们要用这个家伙作为我们的输入图像。</p><p id="260d" class="pw-post-body-paragraph lc ld it lf b lg lh ju li lj lk jx ll lz ln lo lp ma lr ls lt mb lv lw lx ly im bi translated">我们会让他黑白分明</p><pre class="kj kk kl km gt ox oy oz pa aw pb bi"><span id="d42d" class="mu mv it oy b gy pc pd l pe pf">import cv2<br/>import matplotlib.pyplot as plt<br/>%matplotlib inline</span><span id="4d94" class="mu mv it oy b gy pg pd l pe pf">img_path = 'data/pixabay_Kirgiz03.jpg'</span><span id="6172" class="mu mv it oy b gy pg pd l pe pf"># Load color image <br/>bgr_img = cv2.imread(img_path)</span><span id="9ebd" class="mu mv it oy b gy pg pd l pe pf"># Convert to grayscale<br/>gray_img = cv2.cvtColor(bgr_img, cv2.COLOR_BGR2GRAY)</span><span id="a5e7" class="mu mv it oy b gy pg pd l pe pf"># Normalize, rescale entries to lie in [0,1]<br/>gray_img = gray_img.astype("float32")/255</span><span id="98bc" class="mu mv it oy b gy pg pd l pe pf"># Plot image<br/>plt.imshow(gray_img, cmap='gray')<br/>plt.show()</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ph"><img src="../Images/2d9aad91ac9db73ab96970eeca688b34.png" data-original-src="https://miro.medium.com/v2/resize:fit:864/format:webp/1*q8in0sL_1wgQptwFwK58ew.png"/></div></figure><p id="9324" class="pw-post-body-paragraph lc ld it lf b lg lh ju li lj lk jx ll lz ln lo lp ma lr ls lt mb lv lw lx ly im bi translated">让我们定义并可视化我们的过滤器</p><pre class="kj kk kl km gt ox oy oz pa aw pb bi"><span id="1ac4" class="mu mv it oy b gy pc pd l pe pf">import numpy as np</span><span id="5e22" class="mu mv it oy b gy pg pd l pe pf">filter_vals = np.array([[-1, -1, 1, 1], [-1, -1, 1, 1], [-1, -1, 1, 1], [-1, -1, 1, 1]])</span><span id="316e" class="mu mv it oy b gy pg pd l pe pf">print('Filter shape: ', filter_vals.shape)</span></pre><p id="a7b9" class="pw-post-body-paragraph lc ld it lf b lg lh ju li lj lk jx ll lz ln lo lp ma lr ls lt mb lv lw lx ly im bi translated"><strong class="lf iu">滤镜形状:(4，4) </strong></p><pre class="kj kk kl km gt ox oy oz pa aw pb bi"><span id="4e92" class="mu mv it oy b gy pc pd l pe pf"># Define four different filters, all of which are linear combinations of the `filter_vals` defined above</span><span id="4a43" class="mu mv it oy b gy pg pd l pe pf">filter_1 = filter_vals<br/>filter_2 = -filter_1<br/>filter_3 = filter_1.T<br/>filter_4 = -filter_3<br/>filters = np.array([filter_1, filter_2, filter_3, filter_4])</span><span id="42f9" class="mu mv it oy b gy pg pd l pe pf"># Print out the values of filter 1 as an example<br/>print('Filter 1: \n', filter_1)</span></pre><p id="24b4" class="pw-post-body-paragraph lc ld it lf b lg lh ju li lj lk jx ll lz ln lo lp ma lr ls lt mb lv lw lx ly im bi translated">我们看到:</p><pre class="kj kk kl km gt ox oy oz pa aw pb bi"><span id="040f" class="mu mv it oy b gy pc pd l pe pf"><strong class="oy iu">Filter 1: <br/> [[-1 -1  1  1]<br/> [-1 -1  1  1]<br/> [-1 -1  1  1]<br/> [-1 -1  1  1]]</strong></span></pre><p id="41ba" class="pw-post-body-paragraph lc ld it lf b lg lh ju li lj lk jx ll lz ln lo lp ma lr ls lt mb lv lw lx ly im bi translated">这是我们的四个过滤器的可视化</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pi"><img src="../Images/3c9beb2485466bc8032dfaf8d2f8849d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*haC2Sp7AN6nYuM4wRzD2FQ.png"/></div></div></figure><p id="8106" class="pw-post-body-paragraph lc ld it lf b lg lh ju li lj lk jx ll lz ln lo lp ma lr ls lt mb lv lw lx ly im bi translated">现在让我们定义一个卷积层(我现在很喜欢 PyTorch，所以这就是我们在这里使用的。)</p><pre class="kj kk kl km gt ox oy oz pa aw pb bi"><span id="c060" class="mu mv it oy b gy pc pd l pe pf">import torch<br/>import torch.nn as nn<br/>import torch.nn.functional as F<br/>    <br/># Neural network with one convolutional layer with four filters<br/>class Net(nn.Module):<br/>    <br/>    def __init__(self, weight):<br/>        super(Net, self).__init__()<br/>        # Initializes the weights of the convolutional layer to be the weights of the 4 defined filters<br/>        k_height, k_width = weight.shape[2:]<br/>        # Assumes there are 4 grayscale filters<br/>        self.conv = nn.Conv2d(1, 4, kernel_size=(k_height, k_width), bias=False)<br/>        self.conv.weight = torch.nn.Parameter(weight)</span><span id="42e4" class="mu mv it oy b gy pg pd l pe pf">def forward(self, x):<br/>        # Calculates the output of a convolutional layer pre- and post-activation<br/>        conv_x = self.conv(x)<br/>        activated_x = F.relu(conv_x)<br/>        <br/>        # Returns both layers<br/>        return conv_x, activated_x<br/>    <br/># Instantiate the model and set the weights<br/>weight = torch.from_numpy(filters).unsqueeze(1).type(torch.FloatTensor)<br/>model = Net(weight)</span><span id="4604" class="mu mv it oy b gy pg pd l pe pf"># Print out the layer in the network<br/>print(model)</span></pre><p id="4498" class="pw-post-body-paragraph lc ld it lf b lg lh ju li lj lk jx ll lz ln lo lp ma lr ls lt mb lv lw lx ly im bi translated">我们走着瞧</p><pre class="kj kk kl km gt ox oy oz pa aw pb bi"><span id="a65d" class="mu mv it oy b gy pc pd l pe pf"><strong class="oy iu">Net(<br/>  (conv): Conv2d(1, 4, kernel_size=(4, 4), stride=(1, 1), bias=False)<br/>)</strong></span></pre><p id="ddc7" class="pw-post-body-paragraph lc ld it lf b lg lh ju li lj lk jx ll lz ln lo lp ma lr ls lt mb lv lw lx ly im bi translated">再多加一点代码</p><pre class="kj kk kl km gt ox oy oz pa aw pb bi"><span id="bd0c" class="mu mv it oy b gy pc pd l pe pf">def viz_layer(layer, n_filters= 4):<br/>    fig = plt.figure(figsize=(20, 20))<br/>    <br/>    for i in range(n_filters):<br/>        ax = fig.add_subplot(1, n_filters, i+1, xticks=[], yticks=[])<br/>        # Grab layer outputs<br/>        ax.imshow(np.squeeze(layer[0,i].data.numpy()), cmap='gray')<br/>        ax.set_title('Output %s' % str(i+1))</span></pre><p id="1957" class="pw-post-body-paragraph lc ld it lf b lg lh ju li lj lk jx ll lz ln lo lp ma lr ls lt mb lv lw lx ly im bi translated">然后再多一点</p><pre class="kj kk kl km gt ox oy oz pa aw pb bi"><span id="d0af" class="mu mv it oy b gy pc pd l pe pf"># Plot original image<br/>plt.imshow(gray_img, cmap='gray')</span><span id="d466" class="mu mv it oy b gy pg pd l pe pf"># Visualize all of the filters<br/>fig = plt.figure(figsize=(12, 6))<br/>fig.subplots_adjust(left=0, right=1.5, bottom=0.8, top=1, hspace=0.05, wspace=0.05)<br/>for i in range(4):<br/>    ax = fig.add_subplot(1, 4, i+1, xticks=[], yticks=[])<br/>    ax.imshow(filters[i], cmap='gray')<br/>    ax.set_title('Filter %s' % str(i+1))</span><span id="b50b" class="mu mv it oy b gy pg pd l pe pf"># Convert the image into an input tensor<br/>gray_img_tensor = torch.from_numpy(gray_img).unsqueeze(0).unsqueeze(1)</span><span id="f709" class="mu mv it oy b gy pg pd l pe pf"># Get the convolutional layer (pre and post activation)<br/>conv_layer, activated_layer = model(gray_img_tensor)</span><span id="d4bb" class="mu mv it oy b gy pg pd l pe pf"># Visualize the output of a convolutional layer<br/>viz_layer(conv_layer)</span></pre><p id="f614" class="pw-post-body-paragraph lc ld it lf b lg lh ju li lj lk jx ll lz ln lo lp ma lr ls lt mb lv lw lx ly im bi translated">我们可以在应用 ReLu 激活函数之前可视化卷积层的输出！</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pj"><img src="../Images/6e5c79ebc8df910af4e67b35698c97ce.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*7J3lT36zo3IeBvIDOFMVqw.png"/></div></div></figure><p id="bf0e" class="pw-post-body-paragraph lc ld it lf b lg lh ju li lj lk jx ll lz ln lo lp ma lr ls lt mb lv lw lx ly im bi translated">现在让我们使用 Sobel 算子作为边缘检测滤波器来创建一个自定义内核。Sobel 滤波器非常常用于边缘检测。它在寻找图像中的强度模式方面做得很好。对图像应用 Sobel 滤波器是一种在 x 或 y 方向上分别对图像的导数进行近似的方法。</p><p id="d0c4" class="pw-post-body-paragraph lc ld it lf b lg lh ju li lj lk jx ll lz ln lo lp ma lr ls lt mb lv lw lx ly im bi translated">我们将把我们的小家伙转换成灰度进行过滤</p><pre class="kj kk kl km gt ox oy oz pa aw pb bi"><span id="6db3" class="mu mv it oy b gy pc pd l pe pf">gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)</span><span id="c77e" class="mu mv it oy b gy pg pd l pe pf">plt.imshow(gray, cmap='gray')</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ph"><img src="../Images/2d9aad91ac9db73ab96970eeca688b34.png" data-original-src="https://miro.medium.com/v2/resize:fit:864/format:webp/1*q8in0sL_1wgQptwFwK58ew.png"/></div></figure><p id="cc66" class="pw-post-body-paragraph lc ld it lf b lg lh ju li lj lk jx ll lz ln lo lp ma lr ls lt mb lv lw lx ly im bi translated">开始了。</p><pre class="kj kk kl km gt ox oy oz pa aw pb bi"><span id="4c33" class="mu mv it oy b gy pc pd l pe pf"># 3x3 array for edge detection<br/>sobel_y = np.array([[ -1, -2, -1], <br/>                   [ 0, 0, 0], <br/>                   [ 1, 2, 1]])</span><span id="b621" class="mu mv it oy b gy pg pd l pe pf">sobel_x = np.array([[ -1, 0, 1], <br/>                   [ 0, 0, 0], <br/>                   [ 1, 2, 1]])<br/>  <br/>filtered_image = cv2.filter2D(gray, -1, sobel_y)</span><span id="ea6a" class="mu mv it oy b gy pg pd l pe pf">plt.imshow(filtered_image, cmap='gray')</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi pk"><img src="../Images/7fde77f07e25944ae1c2087677947862.png" data-original-src="https://miro.medium.com/v2/resize:fit:1152/format:webp/1*A6b8G4KfGx5aIiIuTFwkKQ.png"/></div></figure><p id="fe39" class="pw-post-body-paragraph lc ld it lf b lg lh ju li lj lk jx ll lz ln lo lp ma lr ls lt mb lv lw lx ly im bi translated"><em class="le">想看看数学吗？看看</em> <a class="ae ky" href="https://web.stanford.edu/class/cs231a/lectures/intro_cnn.pdf" rel="noopener ugc nofollow" target="_blank"> <em class="le">卷积神经网络简介</em> </a> <em class="le">作者吴建新</em></p><h2 id="284d" class="mu mv it bd mw mx my dn mz na nb dp nc lz nd ne nf ma ng nh ni mb nj nk nl nm bi translated">ReLU 层</h2><p id="09ff" class="pw-post-body-paragraph lc ld it lf b lg nn ju li lj no jx ll lz ns lo lp ma nt ls lt mb nu lw lx ly im bi translated">ReLU(校正线性单位)层是我们卷积层的另一个步骤。您正在将一个<strong class="lf iu">激活</strong> <strong class="lf iu">函数</strong>应用到您的特征地图上，以增加网络中的非线性。这是因为图像本身是高度非线性的！它通过将负值设置为零来从激活图中移除负值。</p><p id="8e41" class="pw-post-body-paragraph lc ld it lf b lg lh ju li lj lk jx ll lz ln lo lp ma lr ls lt mb lv lw lx ly im bi translated">卷积是一种线性运算，包括元素间的矩阵乘法和加法。我们希望 CNN 了解的真实世界数据将是非线性的。我们可以用 ReLU 这样的操作来说明这一点。您可以使用其他操作，如<strong class="lf iu"> tanh </strong>或<strong class="lf iu"> sigmoid </strong>。然而，ReLU 是一个受欢迎的选择，因为它可以更快地训练网络，而不会对泛化精度产生任何重大影响。</p><p id="290d" class="pw-post-body-paragraph lc ld it lf b lg lh ju li lj lk jx ll lz ln lo lp ma lr ls lt mb lv lw lx ly im bi translated"><em class="le">查看 C.-C. Jay Kuo </em> <a class="ae ky" href="https://arxiv.org/abs/1609.04112" rel="noopener ugc nofollow" target="_blank"> <em class="le">用数学模型理解卷积神经网络</em> </a> <em class="le">。</em></p><p id="bf4f" class="pw-post-body-paragraph lc ld it lf b lg lh ju li lj lk jx ll lz ln lo lp ma lr ls lt mb lv lw lx ly im bi translated"><em class="le">想深入挖掘？试试何等</em> <a class="ae ky" href="https://arxiv.org/abs/1502.01852" rel="noopener ugc nofollow" target="_blank"> <em class="le">深究整流器:在 ImageNet 分类上超越人类水平的表现</em> </a> <em class="le">。</em></p><p id="d1df" class="pw-post-body-paragraph lc ld it lf b lg lh ju li lj lk jx ll lz ln lo lp ma lr ls lt mb lv lw lx ly im bi translated"><em class="le">如果你需要更多关于</em> <a class="ae ky" rel="noopener" target="_blank" href="/simply-deep-learning-an-effortless-introduction-45591a1c4abb"> <em class="le">激活函数的基础知识，你可以在这里找到</em> </a> <em class="le">！</em></p><p id="0d48" class="pw-post-body-paragraph lc ld it lf b lg lh ju li lj lk jx ll lz ln lo lp ma lr ls lt mb lv lw lx ly im bi translated">这是我们的小伙伴在 ReLU 激活功能将所有负像素值变成黑色后的样子</p><pre class="kj kk kl km gt ox oy oz pa aw pb bi"><span id="b2b7" class="mu mv it oy b gy pc pd l pe pf">viz_layer(activated_layer)</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pl"><img src="../Images/1deafef5c266560dc2206a99ea8c9e49.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*OMJBem1-sdfYCvum2FybSA.png"/></div></div></figure><h2 id="d2ca" class="mu mv it bd mw mx my dn mz na nb dp nc lz nd ne nf ma ng nh ni mb nj nk nl nm bi translated">联营</h2><p id="a6c4" class="pw-post-body-paragraph lc ld it lf b lg nn ju li lj no jx ll lz ns lo lp ma nt ls lt mb nu lw lx ly im bi translated">您最不希望看到的是网络在确切位置的确切阴影中查找某个特定要素。那对一个好的 CNN 来说没用！您想要翻转、旋转、挤压等的图像。您想要同一事物的大量照片，以便您的网络可以在所有图像中识别一个对象(比如说，一只豹子)。无论大小或位置如何。无论光线如何，无论斑点数量多少，无论豹子是在熟睡还是在撕咬猎物。你要<strong class="lf iu">空间方差</strong>！你需要灵活性。这就是联营的意义所在。</p><p id="bac7" class="pw-post-body-paragraph lc ld it lf b lg lh ju li lj lk jx ll lz ln lo lp ma lr ls lt mb lv lw lx ly im bi translated">池逐渐减小输入表示的大小。这使得检测图像中的物体成为可能，无论它们位于何处。池有助于减少所需参数的数量和所需的计算量。这也有助于控制<strong class="lf iu">过度拟合</strong>。</p><p id="1048" class="pw-post-body-paragraph lc ld it lf b lg lh ju li lj lk jx ll lz ln lo lp ma lr ls lt mb lv lw lx ly im bi translated">过度拟合有点像你在没有理解信息的情况下，在考试前记忆超级具体的细节。当你记住细节的时候，你可以在家里用你的抽认卡做得很好。但是，如果给你提供新的信息，你将无法通过真正的测试。</p><p id="66bb" class="pw-post-body-paragraph lc ld it lf b lg lh ju li lj lk jx ll lz ln lo lp ma lr ls lt mb lv lw lx ly im bi translated">(另一个例子:如果你的训练数据中的所有狗都有斑点和深色眼睛，你的网络将认为，对于要被分类为狗的图像，它必须有斑点和深色眼睛。如果你用同样的训练数据来测试你的数据，它将会对狗进行惊人的正确分类！但是，如果你的输出只有“狗”和“猫”，而你的网络呈现的新图像包含，比如说，一只罗威纳犬和一只哈士奇犬，它很可能会把罗威纳犬和哈士奇犬都归类为猫。可以看出问题了！)</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pm"><img src="../Images/8711f39536a83a3bc693eb0d8bcea23a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*d7n9JHWA7r_Bjean"/></div></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk">Photo by <a class="ae ky" href="https://unsplash.com/@_hybrid_?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Hybrid</a> on <a class="ae ky" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><p id="3cc1" class="pw-post-body-paragraph lc ld it lf b lg lh ju li lj lk jx ll lz ln lo lp ma lr ls lt mb lv lw lx ly im bi translated">如果没有方差，对于与训练数据不完全匹配的图像，您的网络将毫无用处。<strong class="lf iu">永远，永远，永远把你的训练和测试数据分开</strong>！如果你用你训练过的数据进行测试，你的网络会记住这些信息！当引入任何新数据时，它会做得很糟糕。</p><blockquote class="oi"><p id="673c" class="oj ok it bd ol om on oo op oq or ly dk translated">过度合身并不酷。</p></blockquote><p id="3f18" class="pw-post-body-paragraph lc ld it lf b lg pn ju li lj po jx ll lz pp lo lp ma pq ls lt mb pr lw lx ly im bi translated">因此，对于这一步，你采取<strong class="lf iu">特征地图</strong>，应用<strong class="lf iu">池层</strong>，结果是<strong class="lf iu">池特征地图</strong>。</p><p id="3617" class="pw-post-body-paragraph lc ld it lf b lg lh ju li lj lk jx ll lz ln lo lp ma lr ls lt mb lv lw lx ly im bi translated">最常见的池例子是<strong class="lf iu">最大池</strong>。在 max pooling 中，输入图像被划分为一组不重叠的区域。每个区域的输出是每个区域的最大值。这使得尺寸更小，参数更少。</p><p id="558d" class="pw-post-body-paragraph lc ld it lf b lg lh ju li lj lk jx ll lz ln lo lp ma lr ls lt mb lv lw lx ly im bi translated">最大池化就是获取图像中每个点的最大值。这去掉了 75%的非特征信息。通过取像素的最大值，你就考虑到了失真。如果要素向左或向右旋转一点点，合并后的要素将保持不变。你在减少尺寸和参数。这很好，因为这意味着模型不会过度适应这些信息。</p><p id="5c0a" class="pw-post-body-paragraph lc ld it lf b lg lh ju li lj lk jx ll lz ln lo lp ma lr ls lt mb lv lw lx ly im bi translated">你可以使用<strong class="lf iu">平均池</strong>或<strong class="lf iu">总和池</strong>，但它们并不是常见的选择。在实践中，最大池往往比两者都表现得更好。在 max pooling 中，您将获得最大的像素值。在平均池中，取图像中该点所有像素值的平均值。(实际上，现在有一种趋势是使用更小的过滤器或完全放弃池层。这是对代表人数大幅减少的回应。)</p><p id="7b0a" class="pw-post-body-paragraph lc ld it lf b lg lh ju li lj lk jx ll lz ln lo lp ma lr ls lt mb lv lw lx ly im bi translated"><em class="le">想多了解一下为什么你会选择最大池，为什么你会喜欢两个像素的步长？看看张秀坤·舍雷尔等人。a1，</em> <a class="ae ky" href="http://ais.uni-bonn.de/papers/icann2010_maxpool.pdf" rel="noopener ugc nofollow" target="_blank"> <em class="le">用于对象识别的卷积架构中的池操作评估</em> </a> <em class="le">。</em></p><p id="a3dd" class="pw-post-body-paragraph lc ld it lf b lg lh ju li lj lk jx ll lz ln lo lp ma lr ls lt mb lv lw lx ly im bi translated">如果你去<a class="ae ky" href="http://scs.ryerson.ca/~aharley/vis/conv/flat.html" rel="noopener ugc nofollow" target="_blank">这里</a>你可以看到一个非常有趣的卷积层的 2D 可视化。在屏幕左侧的框中画一个数字，然后真正地浏览输出。您可以看到卷积和汇集层以及猜测。尝试将鼠标悬停在单个像素上，以便可以看到应用滤镜的位置。</p><p id="97ab" class="pw-post-body-paragraph lc ld it lf b lg lh ju li lj lk jx ll lz ln lo lp ma lr ls lt mb lv lw lx ly im bi translated">现在我们有了一个输入图像、一个应用的卷积层和一个应用的池层。</p><p id="8615" class="pw-post-body-paragraph lc ld it lf b lg lh ju li lj lk jx ll lz ln lo lp ma lr ls lt mb lv lw lx ly im bi translated">让我们来看一看池层的输出！</p><p id="ea59" class="pw-post-body-paragraph lc ld it lf b lg lh ju li lj lk jx ll lz ln lo lp ma lr ls lt mb lv lw lx ly im bi translated">我们在这里:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ps"><img src="../Images/58d6ef96cac3a01c623782b2ed06af41.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*LkLaKe6AK79-6xCLFuzMUw.png"/></div></div></figure><p id="e6bd" class="pw-post-body-paragraph lc ld it lf b lg lh ju li lj lk jx ll lz ln lo lp ma lr ls lt mb lv lw lx ly im bi translated">汇集图层将上图中的要素地图作为输入，并减少这些地图的维度。它通过构建一个新的、更小的图像来实现这一点，该图像仅包含给定内核区域中的最大(最亮)值。</p><p id="34c5" class="pw-post-body-paragraph lc ld it lf b lg lh ju li lj lk jx ll lz ln lo lp ma lr ls lt mb lv lw lx ly im bi translated">看到图像是如何改变大小的了吗？</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pt"><img src="../Images/fab628e29b02d963e7297fac61197e47.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*J0Ax1EKVpa5hAtrj3H61Bw.png"/></div></div></figure><p id="2699" class="pw-post-body-paragraph lc ld it lf b lg lh ju li lj lk jx ll lz ln lo lp ma lr ls lt mb lv lw lx ly im bi translated">很酷，对吧？</p><h2 id="e1f9" class="mu mv it bd mw mx my dn mz na nb dp nc lz nd ne nf ma ng nh ni mb nj nk nl nm bi translated">变平</h2><p id="4733" class="pw-post-body-paragraph lc ld it lf b lg nn ju li lj no jx ll lz ns lo lp ma nt ls lt mb nu lw lx ly im bi translated">这是一个非常简单的步骤。您将汇集的要素地图展平为一列连续的数字(一个长向量)。这使得该信息成为人工神经网络的输入层，用于进一步处理。</p><h2 id="5654" class="mu mv it bd mw mx my dn mz na nb dp nc lz nd ne nf ma ng nh ni mb nj nk nl nm bi translated">全连接层</h2><p id="8dd9" class="pw-post-body-paragraph lc ld it lf b lg nn ju li lj no jx ll lz ns lo lp ma nt ls lt mb nu lw lx ly im bi translated">在这一步，我们将一个<strong class="lf iu">人工神经网络</strong>添加到我们的卷积神经网络中。(不确定人工神经网络？你可以在这里了解他们！)</p><p id="7d49" class="pw-post-body-paragraph lc ld it lf b lg lh ju li lj lk jx ll lz ln lo lp ma lr ls lt mb lv lw lx ly im bi translated">人工神经网络的主要目的是将我们的特征组合成更多的属性。这些将更准确地预测类别。这结合了可以更好地预测类的特征和属性。</p><p id="9d72" class="pw-post-body-paragraph lc ld it lf b lg lh ju li lj lk jx ll lz ln lo lp ma lr ls lt mb lv lw lx ly im bi translated">在这一步，计算误差，然后反向传播。权重和特征检测器被调整以帮助优化模型的性能。然后这个过程一次又一次的发生。我们的网络就是这样训练数据的！</p><p id="7335" class="pw-post-body-paragraph lc ld it lf b lg lh ju li lj lk jx ll lz ln lo lp ma lr ls lt mb lv lw lx ly im bi translated">当有一个以上的神经元时，输出神经元是如何工作的？</p><p id="12ca" class="pw-post-body-paragraph lc ld it lf b lg lh ju li lj lk jx ll lz ln lo lp ma lr ls lt mb lv lw lx ly im bi translated">首先，我们必须了解什么样的权重应用于连接输出的突触。我们想知道哪些先前的神经元对输出是重要的。</p><p id="9feb" class="pw-post-body-paragraph lc ld it lf b lg lh ju li lj lk jx ll lz ln lo lp ma lr ls lt mb lv lw lx ly im bi translated">例如，如果您有两个输出类，一个是猫的，一个是狗的，则读取“0”的神经元绝对不能确定该特征属于猫。一个读到“1”的神经元绝对确定这个特征属于一只猫。在最终完全连接的层中，神经元将读取 0 和 1 之间的值。这意味着不同层次的确定性。值 0.9 表示 90%的确定性。</p><p id="5585" class="pw-post-body-paragraph lc ld it lf b lg lh ju li lj lk jx ll lz ln lo lp ma lr ls lt mb lv lw lx ly im bi translated">当一个特征被识别出来时，猫的神经元就知道这个图像是一只猫。他们说数学上相当于，“这些是我的神经元！我应该被触发了！”如果这种情况发生多次，网络就会知道当某些特征被激活时，这个图像就是一只猫。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pu"><img src="../Images/e1ae3dd69c3bc58a3f041d012289a295.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*8W81I29Ri9pZCvL6"/></div></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk">Photo by <a class="ae ky" href="https://unsplash.com/@linneasandbakk?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Linnea Sandbakk</a> on <a class="ae ky" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><p id="9d71" class="pw-post-body-paragraph lc ld it lf b lg lh ju li lj lk jx ll lz ln lo lp ma lr ls lt mb lv lw lx ly im bi translated">通过大量的迭代，猫神经元知道当某些特征被激活时，图像就是一只猫。例如，狗的神经元知道当某些其他特征被激发时，这个图像就是一只狗。例如，狗神经元再次了解到，“大湿鼻子”神经元和“软耳朵”神经元对狗神经元有很大的贡献。它赋予“大湿鼻子”神经元和“软耳朵”神经元更大的权重。狗神经元学会或多或少忽略“胡须”神经元和“猫虹膜”神经元。猫神经元学会给予像“胡须”和“猫虹膜”这样的神经元更大的权重。</p><p id="ec4c" class="pw-post-body-paragraph lc ld it lf b lg lh ju li lj lk jx ll lz ln lo lp ma lr ls lt mb lv lw lx ly im bi translated">(好吧，实际上并没有“大湿鼻子”或“胡须”神经元。但是检测到的特征确实具有特定类别的区别特征。)</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pv"><img src="../Images/705dea9a95844bc34820aa09a543d036.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*T2D3DdAcXIKRhF_h"/></div></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk">Photo by <a class="ae ky" href="https://unsplash.com/@noemiphotography?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Noémi Macavei-Katócz</a> on <a class="ae ky" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><p id="16e0" class="pw-post-body-paragraph lc ld it lf b lg lh ju li lj lk jx ll lz ln lo lp ma lr ls lt mb lv lw lx ly im bi translated">一旦训练好网络，你就可以传入一幅图像，神经网络将能够非常确定地确定该图像的图像分类概率。</p><p id="839d" class="pw-post-body-paragraph lc ld it lf b lg lh ju li lj lk jx ll lz ln lo lp ma lr ls lt mb lv lw lx ly im bi translated">全连接层是传统的多层感知器。它在输出层使用一个分类器。分类器通常是 softmax 激活函数。完全连接意味着前一层中的每个神经元都连接到下一层中的每个神经元。这一层的目的是什么？使用来自前一层的输出的特征来基于训练数据对输入图像进行分类。</p><p id="7825" class="pw-post-body-paragraph lc ld it lf b lg lh ju li lj lk jx ll lz ln lo lp ma lr ls lt mb lv lw lx ly im bi translated">一旦你的网络建立并运行，你可以看到，例如，你有 95%的可能性你的图像是一只狗，5%的可能性你的图像是一只猫。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ms"><img src="../Images/c3e663b2b4f9bae5f9b36c2a47e5ebf1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1280/format:webp/1*t5oLqixdsFGgJB-rxnyxtQ.jpeg"/></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk">Photo by Alexas_Fotos on <a class="ae ky" href="http://pixabay.com" rel="noopener ugc nofollow" target="_blank">Pixabay</a></figcaption></figure><p id="867d" class="pw-post-body-paragraph lc ld it lf b lg lh ju li lj lk jx ll lz ln lo lp ma lr ls lt mb lv lw lx ly im bi translated">为什么这些数字加起来都是 1.0？(0.95 + 0.05)</p><p id="1fe3" class="pw-post-body-paragraph lc ld it lf b lg lh ju li lj lk jx ll lz ln lo lp ma lr ls lt mb lv lw lx ly im bi translated">没有任何东西表明这两个输出是相互联系的。是什么让他们联系在一起？本质上，它们不会，但是当我们引入 softmax 函数时，它们会。这使值介于 0 和 1 之间，并使它们相加为 1 (100%)。(你可以在<a class="ae ky" href="https://en.wikipedia.org/wiki/Softmax_function" rel="noopener ugc nofollow" target="_blank">维基百科</a>上阅读所有相关内容。)softmax 函数获取分数向量，并将其压缩为 0 到 1 之间的值的向量，这些值的总和为 1。</p><p id="2cd3" class="pw-post-body-paragraph lc ld it lf b lg lh ju li lj lk jx ll lz ln lo lp ma lr ls lt mb lv lw lx ly im bi translated">应用 softmax 函数后，可以应用损失函数。交叉熵通常与 softmax 密切相关。我们希望最小化损失函数，以便最大化网络性能。</p><p id="c171" class="pw-post-body-paragraph lc ld it lf b lg lh ju li lj lk jx ll lz ln lo lp ma lr ls lt mb lv lw lx ly im bi translated">在反向传播的开始，你的输出值会很小。这就是为什么你可能会选择交叉熵损失。梯度会非常低，神经网络很难开始向正确的方向调整。使用交叉熵有助于网络评估甚至一个微小的错误，并更快地达到最佳状态。</p><p id="01c3" class="pw-post-body-paragraph lc ld it lf b lg lh ju li lj lk jx ll lz ln lo lp ma lr ls lt mb lv lw lx ly im bi translated"><em class="le">想要更多吗？检查</em></p><ul class=""><li id="5edc" class="me mf it lf b lg lh lj lk lz mg ma mh mb mi ly mj mk ml mm bi translated"><em class="le">这段</em> <a class="ae ky" href="https://www.youtube.com/watch?v=mlaLLQofmR8" rel="noopener ugc nofollow" target="_blank"> <em class="le">视频由杰弗里·辛顿</em> </a> <em class="le">在 softmax 函数上</em></li><li id="81e3" class="me mf it lf b lg mn lj mo lz mp ma mq mb mr ly mj mk ml mm bi translated"><a class="ae ky" href="https://rdipietro.github.io/friendly-intro-to-cross-entropy-loss/" rel="noopener ugc nofollow" target="_blank"> <em class="le">对交叉熵损失的友好介绍</em> </a> <em class="le">作者 Rob DiPietro </em></li><li id="d3fd" class="me mf it lf b lg mn lj mo lz mp ma mq mb mr ly mj mk ml mm bi translated"><a class="ae ky" href="https://peterroelants.github.io/posts/cross-entropy-softmax/" rel="noopener ugc nofollow" target="_blank"> <em class="le">如何实现一个神经网络间奏曲 2 </em> </a> <em class="le">作者彼得·罗伦茨</em></li></ul><h2 id="47ed" class="mu mv it bd mw mx my dn mz na nb dp nc lz nd ne nf ma ng nh ni mb nj nk nl nm bi translated">现在怎么办？</h2><p id="e510" class="pw-post-body-paragraph lc ld it lf b lg nn ju li lj no jx ll lz ns lo lp ma nt ls lt mb nu lw lx ly im bi translated">在这一点上，一切都是通过许多许多时代的向前和向后传播来训练的。我们最终得到了一个定义非常明确的神经网络，所有的权重和特征都经过了训练。现在我们有了可以识别和分类图像的东西！(<a class="ae ky" rel="noopener" target="_blank" href="/simply-deep-learning-an-effortless-introduction-45591a1c4abb">不确定正向传播和反向传播？查看这里的绝对基础知识</a>！)</p><h2 id="e5ba" class="mu mv it bd mw mx my dn mz na nb dp nc lz nd ne nf ma ng nh ni mb nj nk nl nm bi translated">刚刚发生了什么？</h2><p id="783b" class="pw-post-body-paragraph lc ld it lf b lg nn ju li lj no jx ll lz ns lo lp ma nt ls lt mb nu lw lx ly im bi translated">我们从输入图像开始，应用多种不同的特征来创建特征图。我们应用了 ReLU 来增加非线性，并对每个特征地图应用了汇集层。(我们这样做是为了确保我们的图像中有空间差异，减少图像的大小，避免模型过度适应数据，同时仍然保留我们想要的特征。)我们将所有汇集的图像展平成一个长向量。我们将向量输入到完全连接的人工神经网络中。这是通过网络处理所有要素的地方。这给了我们最终的全连接层，它提供了我们所追求的类的“投票”。所有这些都是通过前向传播和反向传播来训练的，直到我们最终得到了一个定义良好的神经网络，其中训练了权重和特征检测器。</p><p id="7d20" class="pw-post-body-paragraph lc ld it lf b lg lh ju li lj lk jx ll lz ln lo lp ma lr ls lt mb lv lw lx ly im bi translated">现在我们可以识别和分类图像了！</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pw"><img src="../Images/0a960f00dd03b9a282204424c52eac73.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*4YLXSuoStSYjL7rN"/></div></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk">Photo by <a class="ae ky" href="https://unsplash.com/@lucassankey?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Lucas Sankey</a> on <a class="ae ky" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><p id="368e" class="pw-post-body-paragraph lc ld it lf b lg lh ju li lj lk jx ll lz ln lo lp ma lr ls lt mb lv lw lx ly im bi translated">您正在朝着能够做到这一点的方向前进:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi px"><img src="../Images/45082b6e3722acb292f9291501bf205c.png" data-original-src="https://miro.medium.com/v2/resize:fit:964/format:webp/1*Fi7JoYukc0CVUmpeJVqXNw.png"/></div></figure><p id="f8b1" class="pw-post-body-paragraph lc ld it lf b lg lh ju li lj lk jx ll lz ln lo lp ma lr ls lt mb lv lw lx ly im bi translated">(你想那样做吗？这里有一个清晰完整的蓝图，可以用 PyTorch 创建一个极其精确的图像分类器！你可以创建一个图像分类器，它可以非常确定地告诉你你正在看的是哪种花！)</p><p id="d47e" class="pw-post-body-paragraph lc ld it lf b lg lh ju li lj lk jx ll lz ln lo lp ma lr ls lt mb lv lw lx ly im bi translated"><em class="le">想了解更多？结账</em></p><ul class=""><li id="3eae" class="me mf it lf b lg lh lj lk lz mg ma mh mb mi ly mj mk ml mm bi translated"><a class="ae ky" href="https://web.stanford.edu/class/cs231a/lectures/intro_cnn.pdf" rel="noopener ugc nofollow" target="_blank"> <em class="le">吴建新</em> </a>卷积神经网络导论</li><li id="81fa" class="me mf it lf b lg mn lj mo lz mp ma mq mb mr ly mj mk ml mm bi translated">Yann LeCun 的原创文章，<a class="ae ky" href="http://yann.lecun.com/exdb/publis/pdf/lecun-01a.pdf" rel="noopener ugc nofollow" target="_blank"> <em class="le">基于梯度的学习应用于文档识别</em> </a></li><li id="4525" class="me mf it lf b lg mn lj mo lz mp ma mq mb mr ly mj mk ml mm bi translated"><a class="ae ky" href="https://adeshpande3.github.io/The-9-Deep-Learning-Papers-You-Need-To-Know-About.html" rel="noopener ugc nofollow" target="_blank"> <em class="le">你需要了解的九篇深度学习论文(了解 CNN 第三部分)</em> </a> <em class="le">作者 Adit Deshpande </em></li></ul><p id="ab7e" class="pw-post-body-paragraph lc ld it lf b lg lh ju li lj lk jx ll lz ln lo lp ma lr ls lt mb lv lw lx ly im bi translated"><strong class="lf iu">感谢关注</strong> <a class="ae ky" rel="noopener" target="_blank" href="/intro-to-deep-learning-c025efd92535"> <strong class="lf iu">新手、新手和新手深度学习</strong> </a> <strong class="lf iu">系列的第 3 部分！</strong></p><p id="b9d0" class="pw-post-body-paragraph lc ld it lf b lg lh ju li lj lk jx ll lz ln lo lp ma lr ls lt mb lv lw lx ly im bi translated"><em class="le">你可以在这里找到第一部分:</em> <a class="ae ky" rel="noopener" target="_blank" href="/intro-to-deep-learning-c025efd92535"> <em class="le">深度学习简介</em> </a></p><div class="py pz gp gr qa qb"><a rel="noopener follow" target="_blank" href="/intro-to-deep-learning-c025efd92535"><div class="qc ab fo"><div class="qd ab qe cl cj qf"><h2 class="bd iu gy z fp qg fr fs qh fu fw is bi translated">深度学习简介</h2><div class="qi l"><h3 class="bd b gy z fp qg fr fs qh fu fw dk translated">新手、新手和新手的神经网络。</h3></div><div class="qj l"><p class="bd b dl z fp qg fr fs qh fu fw dk translated">towardsdatascience.com</p></div></div><div class="qk l"><div class="ql l qm qn qo qk qp ks qb"/></div></div></a></div><p id="77cd" class="pw-post-body-paragraph lc ld it lf b lg lh ju li lj lk jx ll lz ln lo lp ma lr ls lt mb lv lw lx ly im bi translated"><em class="le">和这里的第二部分:</em> <a class="ae ky" rel="noopener" target="_blank" href="/simply-deep-learning-an-effortless-introduction-45591a1c4abb"> <em class="le">人工网络完全初学者指南</em> </a></p><div class="py pz gp gr qa qb"><a rel="noopener follow" target="_blank" href="/simply-deep-learning-an-effortless-introduction-45591a1c4abb"><div class="qc ab fo"><div class="qd ab qe cl cj qf"><h2 class="bd iu gy z fp qg fr fs qh fu fw is bi translated">深度学习完全初学者指南:人工神经网络</h2><div class="qi l"><h3 class="bd b gy z fp qg fr fs qh fu fw dk translated">深度学习入门！在 15 分钟内攻克人工神经网络的基础知识</h3></div><div class="qj l"><p class="bd b dl z fp qg fr fs qh fu fw dk translated">towardsdatascience.com</p></div></div><div class="qk l"><div class="qq l qm qn qo qk qp ks qb"/></div></div></a></div><p id="18c5" class="pw-post-body-paragraph lc ld it lf b lg lh ju li lj lk jx ll lz ln lo lp ma lr ls lt mb lv lw lx ly im bi translated">如果你对这些信息做了什么了不起的事情，请在下面的回复中告诉我，或者发推特<a class="ae ky" href="https://twitter.com/annebonnerdata" rel="noopener ugc nofollow" target="_blank"> @annebonnerdata </a>！</p></div></div>    
</body>
</html>