<html>
<head>
<title>Octave Convolution: Taking a step back and looking at inputs ?</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">八度卷积:退一步看输入？</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/octave-convolution-taking-a-step-back-and-at-looking-inputs-235c313a362c?source=collection_archive---------19-----------------------#2019-07-19">https://towardsdatascience.com/octave-convolution-taking-a-step-back-and-at-looking-inputs-235c313a362c?source=collection_archive---------19-----------------------#2019-07-19</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="e406" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">倍频程卷积的介绍、简要说明和详细 PyTorch 实现。</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/df532105abc32bc3824838a60d16d068.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*7WOSbjWay0ICUEgfvd4k3w.png"/></div></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk">Figure from <a class="ae ky" href="https://arxiv.org/pdf/1904.05049.pdf" rel="noopener ugc nofollow" target="_blank">here</a></figcaption></figure><p id="58e0" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">卷积神经网络(CNN)已经主导了计算机视觉领域。在这篇文章中，我们将看看最近从这篇文章中提出的倍频程卷积:降低一个倍频程:<a class="ae ky" href="https://arxiv.org/pdf/1904.05049.pdf" rel="noopener ugc nofollow" target="_blank">使用倍频程卷积</a>减少卷积神经网络中的空间冗余。</p><p id="5049" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">倍频程卷积可以用来替代普通卷积。作者已经证明，使用倍频程卷积可以实现类似(有时更好)的精度，同时节省大量所需的触发器。八度和香草卷积的模型大小是相同的。</p><p id="0731" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">普通卷积在所有输入通道中执行高频卷积。另一方面，倍频程卷积将所有声道分为两部分:高频和低频。低频通道比高频卷积小一个倍频程(高度和宽度)。此外，在发送输出之前，高频和低频通道相互组合。</p><p id="e39c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">从图中可以看出，每个倍频程卷积模块内部最多可以有 4 个分支，每个分支执行普通卷积。绿色路径不会改变从输入到输出的空间维度。然而，红色路径会增加(从低到高)或减少(从高到低)从输入到输出的空间维度。</p><p id="7785" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">当从高频输入到低频输出(HtoL 路径)时，执行 2x2 合并操作，以获得用于卷积的缩减输入。所以，HtoL 路径是<strong class="lb iu">conv _ 香草(pool(in_high)) </strong></p><p id="362c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">类似地，当从低频输入到高频输出(LtoH 路径)时，普通卷积以双线性插值为顶，以对低分辨率 conv 输出进行上采样。所以，LtoH 路径是<strong class="lb iu">bilenear _ interpolation(vanilla _ convolution(in _ low))</strong>。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi lv"><img src="../Images/8f42ce005e2524321eaa309328250b0a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ddtqFnqQGTeifm10UjtxyA.png"/></div></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk">Figure from <a class="ae ky" href="https://arxiv.org/pdf/1904.05049.pdf" rel="noopener ugc nofollow" target="_blank">here</a></figcaption></figure><p id="0868" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">八度卷积的核心是α的概念(低频卷积使用的总通道的比率)。对于第一个卷积层，没有低频输入通道，所以α_{in} = 0。同样，对于最后一个卷积层，没有低频输出通道，α_{out} = 0。对于所有其他层，作者假设α_{in} = α_{out} = 0.5。</p><p id="bc30" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">作者在论文中展示了大量结果。我觉得最有趣的一个如下图所示。如您所见，对于一小部分低频成分(0.125 或 0.25)，网络性能优于所有高频通道的基线模型。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi lw"><img src="../Images/362bd09f3d90774536e4298218537339.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Kbih4TZd8cvoY3R6dWGG6w.png"/></div></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk">Figure from <a class="ae ky" href="https://arxiv.org/pdf/1904.05049.pdf" rel="noopener ugc nofollow" target="_blank">here</a></figcaption></figure><p id="2856" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">下面是 Pytorch 的实现。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="lx ly l"/></div></figure><p id="116c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">完整的实现可以在我的<a class="ae ky" href="https://github.com/amohant4/OctConv" rel="noopener ugc nofollow" target="_blank"> git repo </a>中找到。为了测试这个实现，我在 CIFAR10 上训练了一个 2 层的普通 CNN 大约 20 个时期。然后我把所有卷积都换成了八度卷积。网络表现稍好(2–3%)。我觉得，对于更大的网络，这种差异可能会更好。</p></div></div>    
</body>
</html>