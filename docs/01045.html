<html>
<head>
<title>How to PyTorch in Production</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">如何生产 PyTorch</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/how-to-pytorch-in-production-743cb6aac9d4?source=collection_archive---------8-----------------------#2019-02-18">https://towardsdatascience.com/how-to-pytorch-in-production-743cb6aac9d4?source=collection_archive---------8-----------------------#2019-02-18</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><figure class="gl gn jo jp jq jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi jn"><img src="../Images/d3d9e2ff63a7e10d7236c97a564fec28.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*TjqNKaFojBVFvfx6HgpMJA.jpeg"/></div></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk">Photo by <a class="ae kc" href="https://unsplash.com/photos/3gnf1rhy2fE?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank">Sharon McCutcheon</a> on <a class="ae kc" href="https://unsplash.com/?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><p id="c6e1" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">ML 好玩，ML 流行，ML 无处不在。大多数公司使用 TensorFlow 或 PyTorch。例如，有些老同性恋更喜欢咖啡。大部分都是关于谷歌和脸书之战。</p><p id="070b" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我的大部分经验都去了 PyTorch，即使大部分教程和在线教程都用 TensofFlow(或者希望是 bare numpy)。目前，在 Lalafo(人工智能驱动的分类)，我们正在与 PyTorch 玩得开心。不，真的，我们试过 caffe，它太棒了，除非你还没有花几天时间安装它。更好的是，PyTorch 现在是 1.0，我们从 0.3 开始使用它，它非常简单和健壮。啊啊..也许这里稍微调整一下，那里稍微调整一下。大多数问题都很容易解决，没有给我们带来任何问题。在公园散步，真的。</p><p id="480a" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在这里，我想分享在生产中使用 PyTorch 最常见的 5 个错误。考虑用 CPU？多线程？使用更多的 GPU 内存？我们已经经历过了。现在让我也来引导你。</p><h1 id="f697" class="lb lc iq bd ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly bi translated">错误# 1——在推理模式下存储动态图</h1><p id="68d0" class="pw-post-body-paragraph kd ke iq kf b kg lz ki kj kk ma km kn ko mb kq kr ks mc ku kv kw md ky kz la ij bi translated">如果您以前使用过 TensorFlow，您可能会意识到 TF 和 PT 之间的关键区别——静态图和动态图。由于每次模型改变时都要重建图形，所以调试 TFlow 非常困难。这需要时间、努力和你的希望。当然现在 TensorFlow 更好。</p><p id="fa2d" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">总的来说，为了使调试更容易，ML 框架使用了与 PyTorch 中所谓的<code class="fe me mf mg mh b">Variables</code>相关的动态图。您使用的每个变量都链接到前一个变量，为反向传播建立关系。</p><p id="8877" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">下面是它在实践中的样子:</p><figure class="mj mk ml mm gt jr gh gi paragraph-image"><div class="gh gi mi"><img src="../Images/87979693fb58f6dbf415df08d5ba1075.png" data-original-src="https://miro.medium.com/v2/resize:fit:1280/0*1OC4Mwp856fOqmrq.gif"/></div></figure><p id="099f" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在大多数情况下，您希望在模型定型后优化所有计算。如果你看火炬界面，有很多选项，特别是在优化方面。<code class="fe me mf mg mh b">eval</code>模式、<code class="fe me mf mg mh b">detach</code>和<code class="fe me mf mg mh b">no_grad</code>方法造成的很多混乱。让我解释一下它们是如何工作的。在模型被训练和部署后，这里是你关心的事情:速度，速度和 CUDA 内存不足异常。</p><p id="af24" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">为了加速 pytorch 模式，你需要将它切换到<code class="fe me mf mg mh b">eval</code>模式。它通知所有层在推理模式下使用 batchnorm 和 dropout 层(简单说就是停用 dropout)。现在，有一种<code class="fe me mf mg mh b">detach</code>方法，它从计算图中删除变量。当你从零开始构建模型时，它是有用的，但是当你想要重用最先进的模型时，它就不那么有用了。一个更全局的解决方案是在<code class="fe me mf mg mh b">torch.no_grad</code>上下文中向前回绕，通过不在结果中存储图形链接来减少内存消耗。它节省了内存，简化了计算，从而提高了速度，减少了内存的使用。答对了。</p><h1 id="a13d" class="lb lc iq bd ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly bi translated">错误 2——没有启用 cudnn 优化算法</h1><p id="deab" class="pw-post-body-paragraph kd ke iq kf b kg lz ki kj kk ma km kn ko mb kq kr ks mc ku kv kw md ky kz la ij bi translated">在 nn 中有很多布尔标志可以设置。模块，你必须知道的存储在 cudnn 命名空间。使用<code class="fe me mf mg mh b">cudnn.benchmark = True</code>启用 cudnn 优化。为了确保 cudnn 寻找最优算法，通过设置<code class="fe me mf mg mh b">cudnn.enabled = True</code>启用它。NVIDIA 在优化方面给你带来了很多好处。</p><p id="36e0" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">请注意，您的数据必须在 GPU 上，模型输入大小不应变化。数据的形式越多样化，可以进行的优化就越少。例如，为了标准化数据，可以对图像进行预处理。总的来说，要有创意，但不要太多。</p><h1 id="3794" class="lb lc iq bd ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly bi translated">错误 3——重用 JIT 编译</h1><p id="0327" class="pw-post-body-paragraph kd ke iq kf b kg lz ki kj kk ma km kn ko mb kq kr ks mc ku kv kw md ky kz la ij bi translated">PyTorch 提供了一种简单的方法来优化和重用来自不同语言的模型(阅读 Python-To-Cpp)。如果你足够勇敢，你可能会更有创造力，用其他语言注入你的模型(我不是，<code class="fe me mf mg mh b">CUDA: Out of memory</code>是我的座右铭)</p><p id="258d" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">如果输入的形状不变，JIT 编译允许优化计算图形。这意味着如果你的数据没有太大的变化(见错误 2 ), JIT 是一个不错的选择。老实说，与上面提到的<code class="fe me mf mg mh b">no_grad</code>和<code class="fe me mf mg mh b">cudnn</code>相比，这并没有太大的不同，但是可能会。这只是第一个版本，潜力巨大。</p><p id="be0e" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">请注意，如果您的模型中有<code class="fe me mf mg mh b">conditions</code>，它将不起作用，这在 RNNs 中是常见的情况。</p><p id="35ff" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">完整文档可在 pytorch.org/docs/stable/jit<a class="ae kc" href="https://pytorch.org/docs/stable/jit.html" rel="noopener ugc nofollow" target="_blank">网站</a>上找到</p><h1 id="d558" class="lb lc iq bd ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly bi translated">错误#4 —试图使用 CPU 实例进行扩展</h1><p id="8f75" class="pw-post-body-paragraph kd ke iq kf b kg lz ki kj kk ma km kn ko mb kq kr ks mc ku kv kw md ky kz la ij bi translated">作为云中的虚拟机，GPU 非常昂贵。即使你查 AWS 一个实例也要 100 $/天左右(最低价 0.7$/h)参考:<a class="ae kc" href="https://aws.amazon.com/ec2/pricing/on-demand/" rel="noopener ugc nofollow" target="_blank">aws.amazon.com/ec2/pricing/on-demand/</a>。我使用的另一个有用的备忘单是<a class="ae kc" href="https://www.ec2instances.info/" rel="noopener ugc nofollow" target="_blank"> www.ec2instances.info </a>每个从 3d 年级毕业的人都会想:“好吧，如果我买 5 个 CPU 实例而不是 1 个 GPU 会怎么样”。试过在 CPU 上运行 NN 模型的人都知道这是个死胡同。是的，你可以为 CPU 优化一个模型，但是最终它还是会比 GPU 慢。我强烈建议放松一下，忘掉这个想法，相信我。</p><h1 id="7fa1" class="lb lc iq bd ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly bi translated">错误 5——处理向量而不是矩阵</h1><ul class=""><li id="7f95" class="mn mo iq kf b kg lz kk ma ko mp ks mq kw mr la ms mt mu mv bi translated"><code class="fe me mf mg mh b">cudnn</code> -检查</li><li id="8fc6" class="mn mo iq kf b kg mw kk mx ko my ks mz kw na la ms mt mu mv bi translated"><code class="fe me mf mg mh b">no_grad</code> -检查</li><li id="7967" class="mn mo iq kf b kg mw kk mx ko my ks mz kw na la ms mt mu mv bi translated"><code class="fe me mf mg mh b">GPU with correct version of CUDA</code> -检查</li><li id="7e0d" class="mn mo iq kf b kg mw kk mx ko my ks mz kw na la ms mt mu mv bi translated"><code class="fe me mf mg mh b">JIT-compilation</code> -检查</li></ul><p id="155c" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">万事俱备，还能做什么？</p><p id="e2ff" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">现在是时候运用一点数学知识了。如果你记得大多数神经网络是如何使用所谓的张量来训练的。张量从数学上讲是一个 N 维数组或者多线性几何向量。你可以做的是将输入分组(如果你愿意的话)到张量或矩阵中，并输入到你的模型中。例如，使用图像数组作为发送到 PyTorch 的矩阵。性能增益等于同时传递的对象数量。</p><p id="94c0" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这是一个显而易见的解决方案，但很少有人真正使用它，因为大多数时候对象是一个接一个处理的，从架构上建立这样的流程可能有点困难。别担心，你会成功的！</p><h1 id="f090" class="lb lc iq bd ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly bi translated">下一步是什么？</h1><p id="2522" class="pw-post-body-paragraph kd ke iq kf b kg lz ki kj kk ma km kn ko mb kq kr ks mc ku kv kw md ky kz la ij bi translated">关于如何在 PyTorch 中优化模型，肯定有更多的技巧。我会继续张贴我们在野外使用脸书小子的经验。你呢，你有什么技巧可以在推理上取得更好的表现？</p></div><div class="ab cl nb nc hu nd" role="separator"><span class="ne bw bk nf ng nh"/><span class="ne bw bk nf ng nh"/><span class="ne bw bk nf ng"/></div><div class="ij ik il im in"><p id="0068" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><em class="ni">原载于 2019 年 2 月 18 日</em><a class="ae kc" href="https://tarasmatsyk.com/posts/4-how-to-pytorch-in-production/" rel="noopener ugc nofollow" target="_blank"><em class="ni">【tarasmatsyk.com】</em></a><em class="ni">。</em></p></div></div>    
</body>
</html>