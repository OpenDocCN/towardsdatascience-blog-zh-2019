<html>
<head>
<title>The Story of Missing Data</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">缺失数据的故事</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/the-story-of-missing-data-9922e611e56b?source=collection_archive---------22-----------------------#2019-12-28">https://towardsdatascience.com/the-story-of-missing-data-9922e611e56b?source=collection_archive---------22-----------------------#2019-12-28</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><h2 id="9f2b" class="ir is it bd b dl iu iv iw ix iy iz dk ja translated" aria-label="kicker paragraph">机器学习</h2><div class=""/><div class=""><h2 id="18c1" class="pw-subtitle-paragraph jz jc it bd b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq dk translated">快速解释缺失数据在机器学习中的重要性以及如何处理它</h2></div><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi kr"><img src="../Images/0789364de362d14253b146db729dc85e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*FHoFVLk5eamIUROvvqcZUg.jpeg"/></div></div><figcaption class="ld le gj gh gi lf lg bd b be z dk">Photo by <a class="ae lh" href="https://unsplash.com/@dlewiskennedy?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank">David Kennedy</a> on <a class="ae lh" href="https://unsplash.com/s/photos/story?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><p id="0830" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">顾名思义，缺失数据意味着—</p><blockquote class="me"><p id="199b" class="mf mg it bd mh mi mj mk ml mm mn md dk translated">手边的数据集中缺少特征值或目标值</p></blockquote><h1 id="f41b" class="mo mp it bd mq mr ms mt mu mv mw mx my ki mz kj na kl nb km nc ko nd kp ne nf bi translated">基于缺失原因的缺失数据分类</h1><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi ng"><img src="../Images/92cdf8f697ef1f3d9f6e1ecdb559e029.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*5rifWEzN3wGpA4iEUkOHKQ.jpeg"/></div></div><figcaption class="ld le gj gh gi lf lg bd b be z dk"><strong class="bd nh">Randomness everywhere.. </strong>(Photo by <a class="ae lh" href="https://unsplash.com/@jacc?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank">Jack Hamilton</a> on <a class="ae lh" href="https://unsplash.com/s/photos/shuffle?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank">Unsplash</a>)</figcaption></figure><p id="ce31" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">缺失数据基本上分为 3 类—</p><ol class=""><li id="48e5" class="ni nj it lk b ll lm lo lp lr nk lv nl lz nm md nn no np nq bi translated"><strong class="lk jd">随机缺失(MAR) </strong> —因为特征(预测值)或目标缺失随机值的原因可以从探索性数据分析本身来理解。(此处阅读关于此事的深入<a class="ae lh" href="https://medium.com/@danberdov/types-of-missing-data-902120fa4248" rel="noopener"/></li><li id="a0ce" class="ni nj it lk b ll nr lo ns lr nt lv nu lz nv md nn no np nq bi translated"><strong class="lk jd">完全随机失踪(MCAR) </strong> —没有什么猫腻，失踪绝对是随机的！(在此阅读关于此的深入<a class="ae lh" href="https://medium.com/@danberdov/types-of-missing-data-902120fa4248" rel="noopener">)</a></li><li id="7cbe" class="ni nj it lk b ll nr lo ns lr nt lv nu lz nv md nn no np nq bi translated"><strong class="lk jd">不是随机遗漏(MNAR)</strong>-对于机器学习爱好者或学生来说，这是最不幸的情况，因为这里遗漏的原因可以解释，但不能用数据集中的变量来解释。这种情况要求对数据分析的初始阶段(数据收集)进行彻底的调查！(在此阅读关于此的深入<a class="ae lh" href="https://medium.com/@danberdov/types-of-missing-data-902120fa4248" rel="noopener">)</a></li></ol></div><div class="ab cl nw nx hx ny" role="separator"><span class="nz bw bk oa ob oc"/><span class="nz bw bk oa ob oc"/><span class="nz bw bk oa ob"/></div><div class="im in io ip iq"><h1 id="dbcf" class="mo mp it bd mq mr od mt mu mv oe mx my ki of kj na kl og km nc ko oh kp ne nf bi translated">基于变量的缺失数据分类</h1><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi oi"><img src="../Images/0b214d518c7824b16eeb1cbb76a6768b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*4vTUfp1iSu4qUrHPHmFYSQ.jpeg"/></div></div><figcaption class="ld le gj gh gi lf lg bd b be z dk"><strong class="bd nh">Let the variables decide..</strong>(Photo by <a class="ae lh" href="https://unsplash.com/@nhillier?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank">Nick Hillier</a> on <a class="ae lh" href="https://unsplash.com/s/photos/numbers?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank">Unsplash</a>)</figcaption></figure><p id="e89b" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">在机器学习术语中，变量基本上有两种类型—</p><ol class=""><li id="3364" class="ni nj it lk b ll lm lo lp lr nk lv nl lz nm md nn no np nq bi translated">特征/预测值和</li><li id="b2d3" class="ni nj it lk b ll nr lo ns lr nt lv nu lz nv md nn no np nq bi translated">目标</li></ol><p id="9a82" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">因此，可以在这两个变量中找到缺失数据，因此可以分类如下:</p><p id="c1e1" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated"><em class="oj"> a. </em>特征变量中缺失数据或<strong class="lk jd">特征缺失</strong></p><p id="dcb3" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated"><em class="oj"> b. </em>目标变量中的数据缺失或<strong class="lk jd">目标缺失</strong>——当目标变量本质上是离散的时，这种缺失也被称为<strong class="lk jd">类缺失</strong>，就像在二元或多类分类问题中一样。在连续目标变量的情况下，术语<strong class="lk jd">目标缺失</strong>可以用作默认值。</p></div><div class="ab cl nw nx hx ny" role="separator"><span class="nz bw bk oa ob oc"/><span class="nz bw bk oa ob oc"/><span class="nz bw bk oa ob"/></div><div class="im in io ip iq"><h1 id="6565" class="mo mp it bd mq mr od mt mu mv oe mx my ki of kj na kl og km nc ko oh kp ne nf bi translated">丢失数据的后果以及如何处理</h1><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi ok"><img src="../Images/1f24e3c944391217690241dba7e4d932.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*K5qVKSwC7JLLj0HGMTG5HA.jpeg"/></div></div><figcaption class="ld le gj gh gi lf lg bd b be z dk"><strong class="bd nh">The challenges </strong>(Photo by <a class="ae lh" href="https://unsplash.com/@findthevision?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank">Danny</a> on <a class="ae lh" href="https://unsplash.com/s/photos/library?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank">Unsplash</a>)</figcaption></figure><p id="a2f8" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">缺失数据提出了两个主要问题—</p><ol class=""><li id="adf7" class="ni nj it lk b ll lm lo lp lr nk lv nl lz nm md nn no np nq bi translated"><strong class="lk jd">信息丢失</strong> —这个问题与<strong class="lk jd">特征缺失</strong>有关，最好的处理方法是使用<strong class="lk jd">插补技术</strong>。一些插补技术有:均值、中值、众数或常值插补。</li><li id="4cbc" class="ni nj it lk b ll nr lo ns lr nt lv nu lz nv md nn no np nq bi translated"><strong class="lk jd">不平衡数据集</strong> —此问题仅与类缺失相关，与目标缺失情况无关。这是大多数分类问题中的基本问题之一。这个问题的解决方案是使用像<strong class="lk jd">过采样或欠采样技术</strong>这样的技术。如果存在目标缺失问题，我的建议是删除对应于每个目标缺失案例的数据点。</li></ol></div><div class="ab cl nw nx hx ny" role="separator"><span class="nz bw bk oa ob oc"/><span class="nz bw bk oa ob oc"/><span class="nz bw bk oa ob"/></div><div class="im in io ip iq"><h1 id="d80e" class="mo mp it bd mq mr od mt mu mv oe mx my ki of kj na kl og km nc ko oh kp ne nf bi translated">丢弃还是估算？</h1><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi ol"><img src="../Images/0a9b6531d7b801e09d1c7851c1e04e6d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ca_FsiAPzEc-awjkfUQqLg.jpeg"/></div></div><figcaption class="ld le gj gh gi lf lg bd b be z dk"><strong class="bd nh">Which way? </strong>(Photo by <a class="ae lh" href="https://unsplash.com/@adigold1?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank">Adi Goldstein</a> on <a class="ae lh" href="https://unsplash.com/s/photos/which-way?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank">Unsplash</a>)</figcaption></figure><p id="19f7" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">以下是我自己的策略，只应如此重视:</p><blockquote class="om on oo"><p id="bf86" class="li lj oj lk b ll lm kd ln lo lp kg lq op ls lt lu oq lw lx ly or ma mb mc md im bi translated">如果<strong class="lk jd">特征缺失案例的缺失值&gt; 5%——丢弃特征本身，否则对一个或多个特征进行插补。</strong></p></blockquote><p id="0188" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">5%或 10%或任何上限——由你决定。</p><blockquote class="me"><p id="f0c8" class="mf mg it bd mh mi mj mk ml mm mn md dk translated">基本思想是过多的插补是对基本分布行为的改变</p></blockquote></div><div class="ab cl nw nx hx ny" role="separator"><span class="nz bw bk oa ob oc"/><span class="nz bw bk oa ob oc"/><span class="nz bw bk oa ob"/></div><div class="im in io ip iq"><h1 id="d1d7" class="mo mp it bd mq mr od mt mu mv oe mx my ki of kj na kl og km nc ko oh kp ne nf bi translated">过采样还是欠采样？</h1><p id="1904" class="pw-post-body-paragraph li lj it lk b ll os kd ln lo ot kg lq lr ou lt lu lv ov lx ly lz ow mb mc md im bi translated">在解释过采样和欠采样之前，我们必须了解<strong class="lk jd">多数阶级</strong>和<strong class="lk jd">少数阶级</strong>。</p><h2 id="7d23" class="ox mp it bd mq oy oz dn mu pa pb dp my lr pc pd na lv pe pf nc lz pg ph ne iz bi translated">多数阶级和少数阶级</h2><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi pi"><img src="../Images/0718fb6dfa593f3b4ee7b87a3d3b782e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*vXEfgsP0pzxvJ-MQUhvSYQ.jpeg"/></div></div><figcaption class="ld le gj gh gi lf lg bd b be z dk"><strong class="bd nh">Classes in society</strong> ( Photo by <a class="ae lh" href="https://unsplash.com/@dylu?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank">Jacek Dylag</a> on <a class="ae lh" href="https://unsplash.com/s/photos/crowd?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank">Unsplash</a>)</figcaption></figure><p id="d0c7" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">这个术语与前面提到的分类问题密切相关。多数类是支配目标(或类)变量分布的离散变量值，份额最小的类是少数类。例如，在一项 100 人随机调查中，70 名男性代表多数群体，30 名女性代表少数群体。</p><blockquote class="om on oo"><p id="36c2" class="li lj oj lk b ll lm kd ln lo lp kg lq op ls lt lu oq lw lx ly or ma mb mc md im bi translated"><strong class="lk jd">过采样人为地将对应于少数类的新的或克隆的数据点引入数据集</strong>并增加数据集的维数<em class="it">，同时</em> <strong class="lk jd"> <em class="it">将数据集从不平衡转换为完全平衡</em> </strong>。这意味着，过采样是针对少数阶级的。</p><p id="ab7b" class="li lj oj lk b ll lm kd ln lo lp kg lq op ls lt lu oq lw lx ly or ma mb mc md im bi translated"><strong class="lk jd">欠采样与过采样</strong>相反——它消除了一些多数类数据点<strong class="lk jd">以确保数据集完全平衡</strong>。</p></blockquote><h2 id="daba" class="ox mp it bd mq oy oz dn mu pa pb dp my lr pc pd na lv pe pf nc lz pg ph ne iz bi translated">一些过采样技术—</h2><ol class=""><li id="8bb5" class="ni nj it lk b ll os lo ot lr pj lv pk lz pl md nn no np nq bi translated">引导或重采样(替换采样)-包括过采样和欠采样</li><li id="8b61" class="ni nj it lk b ll nr lo ns lr nt lv nu lz nv md nn no np nq bi translated">合成少数过采样技术(<a class="ae lh" href="https://medium.com/coinmonks/smote-and-adasyn-handling-imbalanced-data-set-34f5223e167" rel="noopener"> SMOTE </a>)和</li><li id="af22" class="ni nj it lk b ll nr lo ns lr nt lv nu lz nv md nn no np nq bi translated">自适应合成采样方法</li></ol><h2 id="6507" class="ox mp it bd mq oy oz dn mu pa pb dp my lr pc pd na lv pe pf nc lz pg ph ne iz bi translated">一些欠采样技术—</h2><ol class=""><li id="12c7" class="ni nj it lk b ll os lo ot lr pj lv pk lz pl md nn no np nq bi translated">托梅克-林克斯欠采样</li><li id="b8eb" class="ni nj it lk b ll nr lo ns lr nt lv nu lz nv md nn no np nq bi translated">群集质心</li></ol><h2 id="dc46" class="ox mp it bd mq oy oz dn mu pa pb dp my lr pc pd na lv pe pf nc lz pg ph ne iz bi translated">混合技术——过采样+欠采样</h2><ol class=""><li id="20fc" class="ni nj it lk b ll os lo ot lr pj lv pk lz pl md nn no np nq bi translated">SMOTE 后跟 Tomek-Links</li></ol><blockquote class="om on oo"><p id="6db8" class="li lj oj lk b ll lm kd ln lo lp kg lq op ls lt lu oq lw lx ly or ma mb mc md im bi translated">查看关于不平衡数据集重采样技术的简单 Kaggle 笔记本— <a class="ae lh" href="https://www.kaggle.com/rafjaa/resampling-strategies-for-imbalanced-datasets" rel="noopener ugc nofollow" target="_blank"> <strong class="lk jd">此处</strong> </a></p></blockquote><p id="55ed" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">所有的过采样和欠采样技术 API 都可以在 sci-kit learn 的<a class="ae lh" href="https://github.com/scikit-learn-contrib/imbalanced-learn" rel="noopener ugc nofollow" target="_blank">“不平衡学习”</a>中找到</p></div><div class="ab cl nw nx hx ny" role="separator"><span class="nz bw bk oa ob oc"/><span class="nz bw bk oa ob oc"/><span class="nz bw bk oa ob"/></div><div class="im in io ip iq"><h1 id="6c70" class="mo mp it bd mq mr od mt mu mv oe mx my ki of kj na kl og km nc ko oh kp ne nf bi translated">参考</h1><ol class=""><li id="2ef4" class="ni nj it lk b ll os lo ot lr pj lv pk lz pl md nn no np nq bi translated">medium—<a class="ae lh" href="https://medium.com/@danberdov/types-of-missing-data-902120fa4248" rel="noopener">https://medium . com/@ danberdov/types-of-missing-data-902120 fa 4248</a></li><li id="1de8" class="ni nj it lk b ll nr lo ns lr nt lv nu lz nv md nn no np nq bi translated">medium—<a class="ae lh" href="https://medium.com/coinmonks/smote-and-adasyn-handling-imbalanced-data-set-34f5223e167" rel="noopener">https://medium . com/coin monks/smote-and-adasyn-handling-unbalanced-data-set-34f 5223 e167</a></li><li id="d00a" class="ni nj it lk b ll nr lo ns lr nt lv nu lz nv md nn no np nq bi translated">ka ggle—<a class="ae lh" href="https://www.kaggle.com/rafjaa/resampling-strategies-for-imbalanced-datasets" rel="noopener ugc nofollow" target="_blank">https://www . ka ggle . com/RAF jaa/重采样-不平衡数据集策略</a></li><li id="a4ca" class="ni nj it lk b ll nr lo ns lr nt lv nu lz nv md nn no np nq bi translated">sci-kit learn @ Github—<a class="ae lh" href="https://github.com/scikit-learn-contrib/imbalanced-learn" rel="noopener ugc nofollow" target="_blank">https://github.com/scikit-learn-contrib/imbalanced-learn</a></li></ol></div></div>    
</body>
</html>