<html>
<head>
<title>How to solve an ODE with a neural network</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">如何用神经网络求解常微分方程</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/how-to-solve-an-ode-with-a-neural-network-917d11918932?source=collection_archive---------9-----------------------#2019-09-15">https://towardsdatascience.com/how-to-solve-an-ode-with-a-neural-network-917d11918932?source=collection_archive---------9-----------------------#2019-09-15</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><p id="36d3" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">如今，<a class="ae kl" href="https://arxiv.org/abs/1502.05767" rel="noopener ugc nofollow" target="_blank">自动微分</a>使得从机器学习的角度处理微积分问题成为可能。也许你在 NIPS 2018 上听到过关于<a class="ae kl" href="https://arxiv.org/abs/1806.07366" rel="noopener ugc nofollow" target="_blank">神经常微分方程</a>论文的一些议论，这篇论文是由作者之一<a class="ae kl" href="https://github.com/HIPS/autograd" rel="noopener ugc nofollow" target="_blank">大卫·杜文瑙德</a>提交<a class="ae kl" href="https://www.youtube.com/watch?v=V6nGT0Gakyg" rel="noopener ugc nofollow" target="_blank">并签名</a>的。同时，亲笔签名已经被 JAX 取代，这就是我们将在这里使用的。</p><p id="371b" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">主要问题如下:我们想找一个由微分方程定义的未知函数<em class="km"> y=f(x) </em>，比如<em class="km"> y'=-2xy，</em>加上一些初始条件，比如<em class="km"> y(0)=1 </em>。例子来自 Kreyszig 的<a class="ae kl" href="https://www.amazon.com/Advanced-Engineering-Mathematics-Erwin-Kreyszig/dp/0471553808/" rel="noopener ugc nofollow" target="_blank"> <em class="km">高等工程数学</em> </a>的前几页。这个特定初始值问题的解析解是<em class="km"> y=exp(-x)，</em>我们将使用它来验证神经网络提供的结果。</p><p id="bcdc" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">一般来说，对于常微分方程可能没有封闭形式的解，但是可以用神经网络来近似未知函数<em class="km"> y=f(x) </em>。为了简单起见，我们将使用一个具有带<em class="km"> 10 </em>个节点的单个隐藏层的神经网络来解决问题<em class="km">y’=-2xy</em>和<em class="km"> y(0)=1 </em>。</p><p id="6124" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">这是我们神经网络的示意图:</p><figure class="ko kp kq kr gt ks gh gi paragraph-image"><div class="gh gi kn"><img src="../Images/aa1f93fed7f355aeb1b65841daf4d86b.png" data-original-src="https://miro.medium.com/v2/resize:fit:930/format:webp/1*ABVRsdzou1-jjtUwH7qUKw.png"/></div></figure><p id="5946" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">总的来说，网络有<em class="km"> 31 </em>个可训练参数:隐藏层的权重和偏差，加上输出层的权重和偏差。</p><p id="e676" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">让我们按如下方式实现网络:</p><figure class="ko kp kq kr gt ks"><div class="bz fp l di"><div class="kv kw l"/></div></figure><p id="8af7" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我们使用类似 JAX NumPy 的 API，这样，稍后，我们可以通过自动微分计算<code class="fe kx ky kz la b">f</code>的导数。注意，<code class="fe kx ky kz la b">f</code>有两个参数:一个网络参数数组(<code class="fe kx ky kz la b">params</code>)和一个输入值(<code class="fe kx ky kz la b">x</code>)。在机器学习中，我们通常根据模型的参数来区分模型，这里我们也将根据<code class="fe kx ky kz la b">x</code>来区分<code class="fe kx ky kz la b">f</code>，以便求解 ODE。</p><p id="136b" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">网络参数可以随机初始化，例如使用正态分布:</p><figure class="ko kp kq kr gt ks"><div class="bz fp l di"><div class="kv kw l"/></div></figure><p id="9fe5" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">这里我们使用 JAX 提供的<em class="km">伪随机数发生器</em> (PRNG)。通过用某个种子创建 PRNG 键，我们确保我们的结果是可重复的。</p><p id="4fc1" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><code class="fe kx ky kz la b">f</code>相对于<code class="fe kx ky kz la b">x</code>的导数可以通过调用<code class="fe kx ky kz la b">grad</code>来获得:</p><figure class="ko kp kq kr gt ks"><div class="bz fp l di"><div class="kv kw l"/></div></figure><p id="d6ca" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">其中<code class="fe kx ky kz la b">1</code>表示我们想要<code class="fe kx ky kz la b">f</code>相对于其<em class="km">第二</em>自变量<code class="fe kx ky kz la b">x</code>(从零开始的索引)的梯度。在 JAX 中，<code class="fe kx ky kz la b">grad</code>返回一个函数，该函数计算<code class="fe kx ky kz la b">f</code>的梯度，并具有与原始<code class="fe kx ky kz la b">f</code>相同的参数。</p><p id="b097" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">现在，我们会想要求解某个域中的 ODE，例如在<em class="km"> -2 ≤ x ≤ 2 </em>中。因此，我们在该范围内创建一个输入值数组:</p><figure class="ko kp kq kr gt ks"><div class="bz fp l di"><div class="kv kw l"/></div></figure><p id="67fd" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">其中<em class="km"> 401 </em>点是任意选择在区间<em class="km"> [-2，2] </em>内具有<em class="km"> 0.01 </em>的分辨率。</p><p id="db06" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">然而，<code class="fe kx ky kz la b">f</code>接受单个值<code class="fe kx ky kz la b">x</code>作为输入。我们可以以数组的形式传递给它，但是为了便于区分，JAX 需要一个标量函数，所以我们必须传递一个单一的值作为输入，以便得到一个单一的值作为输出。为了有效地计算输入值数组的<code class="fe kx ky kz la b">f</code>及其导数<code class="fe kx ky kz la b">dfdx</code>，我们使用<code class="fe kx ky kz la b">vmap</code>对这些函数进行矢量化:</p><figure class="ko kp kq kr gt ks"><div class="bz fp l di"><div class="kv kw l"/></div></figure><p id="15d9" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">其中<code class="fe kx ky kz la b">(None, 0)</code>指定每个函数将映射到第二个参数(<code class="fe kx ky kz la b">x</code>)的<code class="fe kx ky kz la b">0</code>-轴上，而第一个参数(<code class="fe kx ky kz la b">params</code>)应保持不变(使用<code class="fe kx ky kz la b">None</code>，它将在映射中传播)。</p><p id="c534" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我们现在可以定义我们的损失函数(是的，任何机器学习项目中出现的<em class="km">损失函数</em>，其最小化将产生我们想要的解决方案):</p><figure class="ko kp kq kr gt ks"><div class="bz fp l di"><div class="kv kw l"/></div></figure><p id="bb13" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">注意微分方程<em class="km"> y'=-2xy </em>和初始条件<em class="km"> y(0)=1 </em>是如何分别在<code class="fe kx ky kz la b">eq</code>和<code class="fe kx ky kz la b">ic</code>中被捕获的。为了使训练过程中的残差<em class="km"> y'+2xy </em>和<em class="km"> y(0)-1 </em>最小化，它们被表示为<em class="km"> y'+2xy=0 </em>和<em class="km"> y(0)-1=0 </em>。我们在这个函数上使用 JIT(实时编译)来加速它在加速器硬件上的执行，比如 GPU 或 TPU，如果可用的话。</p><p id="5d7b" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">如同任何机器学习项目一样，我们现在根据可训练参数来区分损失函数:</p><figure class="ko kp kq kr gt ks"><div class="bz fp l di"><div class="kv kw l"/></div></figure><p id="2c11" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">其中<code class="fe kx ky kz la b">0</code>意味着我们想要损失函数相对于它的<em class="km">第一个</em>自变量(<code class="fe kx ky kz la b">params</code>)的梯度。同样，我们使用 JIT 来加速这个新函数的执行。</p><p id="e140" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">该开始训练了！为了加快速度，我们将使用带有内斯特罗夫动量的梯度下降。回想一下<a class="ae kl" href="http://proceedings.mlr.press/v28/sutskever13.pdf" rel="noopener ugc nofollow" target="_blank">内斯特罗夫加速梯度</a> (NAG)的公式:</p><figure class="ko kp kq kr gt ks gh gi paragraph-image"><div class="gh gi lb"><img src="../Images/9fbb64c551c976df18e44c6b93daac75.png" data-original-src="https://miro.medium.com/v2/resize:fit:740/format:webp/1*KCRAjTK4244WKBZC6Zm8RQ.png"/></div></figure><p id="7a03" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">因此，我们实施如下培训流程:</p><figure class="ko kp kq kr gt ks"><div class="bz fp l di"><div class="kv kw l"/></div></figure><p id="9385" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">让我们运行它！</p><figure class="ko kp kq kr gt ks"><div class="bz fp l di"><div class="kv kw l"/></div></figure><p id="cf5c" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">最后，让我们绘制结果并与解析解进行比较:</p><figure class="ko kp kq kr gt ks"><div class="bz fp l di"><div class="kv kw l"/></div></figure><figure class="ko kp kq kr gt ks gh gi paragraph-image"><div class="gh gi lc"><img src="../Images/18bcd499bf8a813fd714f11bc84efd11.png" data-original-src="https://miro.medium.com/v2/resize:fit:1100/format:webp/1*wiiw9SBGm_8UYnuQW3C4vA.png"/></div></figure><p id="5538" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">这就对了，神经网络近似看起来和精确的解析解几乎没有区别。</p><p id="127d" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">最后一个问题:在近似的域<em class="km"> [-2，2] </em>之外会发生什么？好吧，我将把它作为一个练习留给读者……<br/>(提示:重新定义<code class="fe kx ky kz la b">inputs</code>，并再次绘制结果。)</p></div></div>    
</body>
</html>