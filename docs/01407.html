<html>
<head>
<title>Mark Twain once wrote… or was it Poe?</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">马克·吐温曾写道…或者是爱伦坡？</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/mark-twain-once-wrote-or-was-it-poe-47268538ecab?source=collection_archive---------26-----------------------#2019-03-05">https://towardsdatascience.com/mark-twain-once-wrote-or-was-it-poe-47268538ecab?source=collection_archive---------26-----------------------#2019-03-05</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><figure class="is it gp gr iu iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi ir"><img src="../Images/b52f177721794cf98da6a57aafb1ca3c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*V3Mdo8q8B-B9-PUgyg_jCQ.png"/></div></div><figcaption class="jc jd gj gh gi je jf bd b be z dk">BiblioEater is all set to identify the writer</figcaption></figure><div class=""/><div class=""><h2 id="c317" class="pw-subtitle-paragraph kf jh ji bd b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw dk translated">作者归属的 StanfordNLP 和 Keras</h2></div><p id="0c1a" class="pw-post-body-paragraph kx ky ji kz b la lb kj lc ld le km lf lg lh li lj lk ll lm ln lo lp lq lr ls im bi translated">假设你追随某个作家，吞食了她/他的任何一部作品。如果给你提供一本全新的书，你检查几段就能认出作者的风格吗？</p><p id="d9e4" class="pw-post-body-paragraph kx ky ji kz b la lb kj lc ld le km lf lg lh li lj lk ll lm ln lo lp lq lr ls im bi translated">很可能你会。这篇文章的目的是探索一台机器完全做到这一点的可能性。我们将分析两位著名作家作品的一些文学特征，然后训练一个神经网络将新的文本分配给一位或另一位作家。</p><p id="30dd" class="pw-post-body-paragraph kx ky ji kz b la lb kj lc ld le km lf lg lh li lj lk ll lm ln lo lp lq lr ls im bi translated">我们的工具将是刚刚推出的<a class="ae lt" href="https://stanfordnlp.github.io/stanfordnlp/" rel="noopener ugc nofollow" target="_blank"> StanfordNLP </a> Python 包，我们最近写了一个<a class="ae lt" href="https://levelup.gitconnected.com/first-look-at-stanfordnlp-2b7d43190957" rel="noopener ugc nofollow" target="_blank">简短介绍</a>以及直观的深度学习 API Keras，在我们的例子中是 Tensorflow。我们将由此产生的模型戏称为<em class="lu">食书者。</em></p><figure class="lw lx ly lz gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi lv"><img src="../Images/f13d2302103c5a8ea7ab94fd0b657acf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*nKzKQD_66Ho1CEU_fB9eOQ.png"/></div></div><figcaption class="jc jd gj gh gi je jf bd b be z dk">Edgar Allan Poe and Mark Twain</figcaption></figure><h1 id="de2c" class="ma mb ji bd mc md me mf mg mh mi mj mk ko ml kp mm kr mn ks mo ku mp kv mq mr bi translated">作者和他们的书</h1><p id="1659" class="pw-post-body-paragraph kx ky ji kz b la ms kj lc ld mt km lf lg mu li lj lk mv lm ln lo mw lq lr ls im bi translated">我们选出了两位十九世纪的著名作家。一边是非常有趣的马克·吐温，另一边是才华横溢的讲故事者埃德加·爱伦·坡。两个原因导致我们选择他们。我们需要足够老的作品进入公共领域。我们还希望两位作者使用大致相同的语言变体，在他们的例子中是美国英语。</p><p id="81ac" class="pw-post-body-paragraph kx ky ji kz b la lb kj lc ld le km lf lg lh li lj lk ll lm ln lo lp lq lr ls im bi translated">请记住，StanfordNLP 包括能够处理 53 种不同人类语言的模型，因此您可以使用相同的方法将雨果与左拉或塞万提斯与奎维多进行比较。</p><p id="9f8b" class="pw-post-body-paragraph kx ky ji kz b la lb kj lc ld le km lf lg lh li lj lk ll lm ln lo lp lq lr ls im bi translated">我们将从一个稍微更具挑战性的角度来处理这个问题，而不是像机器学习中的规范那样，获取每个作者的一批文本，并在训练和验证桶中分割数据集。我们将用两本小说进行训练，用两本不同的作品进行验证。即:</p><ul class=""><li id="be79" class="mx my ji kz b la lb ld le lg mz lk na lo nb ls nc nd ne nf bi translated">亚瑟·戈登·皮姆的叙述将被用来训练埃德加·爱伦·坡式的读书人。</li><li id="f693" class="mx my ji kz b la ng ld nh lg ni lk nj lo nk ls nc nd ne nf bi translated">《汤姆·索亚历险记》将被用来为马克·吐温做同样的事情。</li><li id="ae07" class="mx my ji kz b la ng ld nh lg ni lk nj lo nk ls nc nd ne nf bi translated"><em class="lu"> Eureka </em>将用于验证 Poe 模型。爱伦·坡主要写短篇小说，但我们选择了长篇小说，尽管不太长。</li><li id="91bd" class="mx my ji kz b la ng ld nh lg ni lk nj lo nk ls nc nd ne nf bi translated">而<em class="lu">哈克贝利·费恩历险记</em>是吐温为了验证而选的作品。</li></ul><p id="e8c1" class="pw-post-body-paragraph kx ky ji kz b la lb kj lc ld le km lf lg lh li lj lk ll lm ln lo lp lq lr ls im bi translated">这种方法有许多障碍:书籍的主题不同，作者可能随着时间的推移而演变，等等。</p><p id="827b" class="pw-post-body-paragraph kx ky ji kz b la lb kj lc ld le km lf lg lh li lj lk ll lm ln lo lp lq lr ls im bi translated">此外，在所选的吐温小说中，作者使用了当地方言。虽然这可能有助于对文本进行分类，但从解析的角度来看，这将是一个挑战。</p><p id="c8e7" class="pw-post-body-paragraph kx ky ji kz b la lb kj lc ld le km lf lg lh li lj lk ll lm ln lo lp lq lr ls im bi translated">另一方面,《尤利卡》不是一部虚构的作品，爱伦坡在写作的时候，他的个性可能已经跨越了天才和疯子之间的界限。</p><p id="3829" class="pw-post-body-paragraph kx ky ji kz b la lb kj lc ld le km lf lg lh li lj lk ll lm ln lo lp lq lr ls im bi translated">然而，我们打赌，每个作者的作品中都有某种文学特征。</p><h1 id="7276" class="ma mb ji bd mc md me mf mg mh mi mj mk ko ml kp mm kr mn ks mo ku mp kv mq mr bi translated">环境</h1><p id="b2b1" class="pw-post-body-paragraph kx ky ji kz b la ms kj lc ld mt km lf lg mu li lj lk mv lm ln lo mw lq lr ls im bi translated">我们在一个 Ubuntu 盒子里用 Python 3.6 工作过。GitHub 中提供了用于生成本文中讨论的结果的完整代码(细节在底部)。</p><p id="5dcb" class="pw-post-body-paragraph kx ky ji kz b la lb kj lc ld le km lf lg lh li lj lk ll lm ln lo lp lq lr ls im bi translated">数据集足够小，可以在没有 GPU 的工作站上运行神经网络训练，尽管有一个 GPU 总是有帮助的。下载英文版的 StanfordNLP 模型可能是更耗时的任务。</p><figure class="lw lx ly lz gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi nl"><img src="../Images/ea2d420d684f19b336b5119b40688bf4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*hKfqhMMamSX_AMigE2qcMA.png"/></div></div><figcaption class="jc jd gj gh gi je jf bd b be z dk">Polishing the text — but not a lot!</figcaption></figure><h1 id="689e" class="ma mb ji bd mc md me mf mg mh mi mj mk ko ml kp mm kr mn ks mo ku mp kv mq mr bi translated">文本准备</h1><p id="17bc" class="pw-post-body-paragraph kx ky ji kz b la ms kj lc ld mt km lf lg mu li lj lk mv lm ln lo mw lq lr ls im bi translated">只要遵守许可条款，古腾堡计划就有数以千计的免费电子书——大多数情况下，你必须避免分发任何修改过的副本。我们用网络浏览器下载了上面提到的四篇文章。</p><p id="cd09" class="pw-post-body-paragraph kx ky ji kz b la lb kj lc ld le km lf lg lh li lj lk ll lm ln lo lp lq lr ls im bi translated">之后，我们用标准的文本编辑器删除了不需要分析的文本部分。这使得我们无法按照古登堡计划的许可分发它们，所以如果你想运行代码，你需要直接从古登堡计划下载电子书。</p><p id="c3d5" class="pw-post-body-paragraph kx ky ji kz b la lb kj lc ld le km lf lg lh li lj lk ll lm ln lo lp lq lr ls im bi translated">我们还在吐温的两部作品中发现了许多弯曲的双引号和下划线。我们在文本编辑器中处理它们。对于我们的目的，这种级别的数据清理就足够了。然而，让我们记住，一流的数据准备+平均算法往往胜过平均数据清理+一流的算法。</p><h2 id="645b" class="nm mb ji bd mc nn no dn mg np nq dp mk lg nr ns mm lk nt nu mo lo nv nw mq nx bi translated">从语法上分析</h2><p id="62bc" class="pw-post-body-paragraph kx ky ji kz b la ms kj lc ld mt km lf lg mu li lj lk mv lm ln lo mw lq lr ls im bi translated">正如我们在上一篇文章中所解释的，我们将应用 StanfordNLP 模型来解析这些书中的每一个句子。这将为每个单词分配<a class="ae lt" href="https://universaldependencies.org/u/pos/" rel="noopener ugc nofollow" target="_blank">的词性</a>和<a class="ae lt" href="https://universaldependencies.org/u/feat/" rel="noopener ugc nofollow" target="_blank">的特征</a>。例如:</p><blockquote class="ny nz oa"><p id="0874" class="kx ky lu kz b la lb kj lc ld le km lf ob lh li lj oc ll lm ln od lp lq lr ls im bi translated">他拿起画笔，平静地开始工作</p></blockquote><p id="a8c7" class="pw-post-body-paragraph kx ky ji kz b la lb kj lc ld le km lf lg lh li lj lk ll lm ln lo lp lq lr ls im bi translated">从汤姆·索亚，变成了</p><pre class="lw lx ly lz gt oe of og oh aw oi bi"><span id="7690" class="nm mb ji of b gy oj ok l ol om">He (PRON - Case=Nom|Gender=Masc|Number=Sing|Person=3|PronType=Prs) took (VERB - Mood=Ind|Tense=Past|VerbForm=Fin) up (ADP - _) his (PRON - Gender=Masc|Number=Sing|Person=3|Poss=Yes|PronType=Prs) brush (NOUN - Number=Sing) and (CCONJ - _) went (VERB - Mood=Ind|Tense=Past|VerbForm=Fin) tranquilly (ADV - _) to (PART - _) work (VERB - VerbForm=Inf)</span></pre><p id="ad98" class="pw-post-body-paragraph kx ky ji kz b la lb kj lc ld le km lf lg lh li lj lk ll lm ln lo lp lq lr ls im bi translated">看看不同句子中语言的使用，我们期望捕捉到作者的部分写作风格。例如，这项研究的一个目标曾经写道:</p><blockquote class="on"><p id="6161" class="oo op ji bd oq or os ot ou ov ow ls dk translated">当你抓住一个形容词时，杀死它。(马克·吐温)</p></blockquote><p id="3549" class="pw-post-body-paragraph kx ky ji kz b la ox kj lc ld oy km lf lg oz li lj lk pa lm ln lo pb lq lr ls im bi translated">所以你不会期望在他的文章中过度使用形容词。事实上，我们会看到坡在形容词的使用上超过了吐温——尽管不是很多。</p><h1 id="d0ac" class="ma mb ji bd mc md me mf mg mh mi mj mk ko ml kp mm kr mn ks mo ku mp kv mq mr bi translated">一些文体特征</h1><p id="bc1a" class="pw-post-body-paragraph kx ky ji kz b la ms kj lc ld mt km lf lg mu li lj lk mv lm ln lo mw lq lr ls im bi translated">我们接受这样的假设，每个作家都有他/她自己的文学风格，这样的个人足迹应该是显而易见的，即使看一些粗糙的特征，就像下面的那些。有一门名为<a class="ae lt" href="https://en.wikipedia.org/wiki/Stylistics" rel="noopener ugc nofollow" target="_blank">文体学</a>的成熟学科专门研究这些现象。</p><h2 id="dcd2" class="nm mb ji bd mc nn no dn mg np nq dp mk lg nr ns mm lk nt nu mo lo nv nw mq nx bi translated">句子长度</h2><figure class="lw lx ly lz gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi lv"><img src="../Images/e7ca5a918ff402a33c65cbae568c97e0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*MOBRF5I_zx8jgbLTic3yJg.png"/></div></div></figure><p id="2395" class="pw-post-body-paragraph kx ky ji kz b la lb kj lc ld le km lf lg lh li lj lk ll lm ln lo lp lq lr ls im bi translated">你喜欢简短直接的句子，还是喜欢制造复杂冗长的句子？(哦不，四个形容词，对不起马克！)在所附的图表中，很明显吐温比爱伦·坡更喜欢使用短句——这并不奇怪。</p><p id="2230" class="pw-post-body-paragraph kx ky ji kz b la lb kj lc ld le km lf lg lh li lj lk ll lm ln lo lp lq lr ls im bi translated">以这样或那样的方式，我们的作者属性算法应该捕捉这个特征，因为它看起来很有鉴别性。</p><h2 id="41fe" class="nm mb ji bd mc nn no dn mg np nq dp mk lg nr ns mm lk nt nu mo lo nv nw mq nx bi translated">词类的使用</h2><p id="ca26" class="pw-post-body-paragraph kx ky ji kz b la ms kj lc ld mt km lf lg mu li lj lk mv lm ln lo mw lq lr ls im bi translated">在 StanfordNLP 的帮助下，我们为两本书的每个句子都指定了词类。作者中动词、形容词和名词的比例是多少？数据会有什么不同吗？</p><figure class="lw lx ly lz gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi lv"><img src="../Images/0051d467bed63d9fba5dea004136dcea.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*8aS-qHrXSxwGHkzR3mvM_g.png"/></div></div><figcaption class="jc jd gj gh gi je jf bd b be z dk">Usage of parts-of-speech in both works</figcaption></figure><p id="1290" class="pw-post-body-paragraph kx ky ji kz b la lb kj lc ld le km lf lg lh li lj lk ll lm ln lo lp lq lr ls im bi translated">Poe 倾向于更重视介词，如中的<em class="lu">或<em class="lu">到</em>，以及从属连词，如<em class="lu"> if </em>或<em class="lu"> while。这暗示了一种更复杂的风格。吐温的书比坡的书包括更多的标点符号，这与组成更短的句子是一致的。</em></em></p><p id="e399" class="pw-post-body-paragraph kx ky ji kz b la lb kj lc ld le km lf lg lh li lj lk ll lm ln lo lp lq lr ls im bi translated">这个简单的分析没有显示出词性之间的顺序关系。正如我们将要展示的，这是一份适合<em class="lu">阅读者</em>的好工作。</p><h2 id="0260" class="nm mb ji bd mc nn no dn mg np nq dp mk lg nr ns mm lk nt nu mo lo nv nw mq nx bi translated">其他功能</h2><p id="7818" class="pw-post-body-paragraph kx ky ji kz b la ms kj lc ld mt km lf lg mu li lj lk mv lm ln lo mw lq lr ls im bi translated">以上只是我们可以在两个文本中分析的特征的几个例子。鉴于 StanfordNLP 所提供的，我们可以看看作品的其他特点:</p><ul class=""><li id="594b" class="mx my ji kz b la lb ld le lg mz lk na lo nb ls nc nd ne nf bi translated">单词特征可用于建立动词的使用方式(哪种时态和模式是首选？)以及类似的名词(单数、复数)。</li><li id="6f4c" class="mx my ji kz b la ng ld nh lg ni lk nj lo nk ls nc nd ne nf bi translated">词汇的使用。例如，单词<em class="lu"> vessel </em>在《亚瑟·戈登·皮姆》中出现了 96 次，而在《汤姆·索亚》中一次也没有出现。同样，吐温写了 156 次男孩，这个词没有出现在 Pym 中。这似乎是一个棘手的话题，因为词汇可能过多地与情节联系在一起，就像这里的情况，而不是与写作风格联系在一起。</li><li id="6d1e" class="mx my ji kz b la ng ld nh lg ni lk nj lo nk ls nc nd ne nf bi translated">我们甚至还没有触及 StanfordNLP 中的<a class="ae lt" href="https://nlp.stanford.edu/software/nndep.html" rel="noopener ugc nofollow" target="_blank">依赖解析器</a>。它分析句子，识别主要术语或句法中心。那些词头(动词、名词等)的选择。)可能与每个作家的选择有关。</li></ul><h1 id="e0c1" class="ma mb ji bd mc md me mf mg mh mi mj mk ko ml kp mm kr mn ks mo ku mp kv mq mr bi translated">文本结构分类与作者归属</h1><p id="2bf0" class="pw-post-body-paragraph kx ky ji kz b la ms kj lc ld mt km lf lg mu li lj lk mv lm ln lo mw lq lr ls im bi translated">让我们直接进入分类。给定这些书中的一篇短文，找出它最可能的作者。</p><h2 id="4b48" class="nm mb ji bd mc nn no dn mg np nq dp mk lg nr ns mm lk nt nu mo lo nv nw mq nx bi translated">战略</h2><p id="a44f" class="pw-post-body-paragraph kx ky ji kz b la ms kj lc ld mt km lf lg mu li lj lk mv lm ln lo mw lq lr ls im bi translated">有许多关于二进制或多标签文本分类的深入文章。这就是为什么我们在这里做一些稍微不同的事情。我们不是用实际的文本来训练我们的网络，而是只输入它的语法结构。</p><p id="6606" class="pw-post-body-paragraph kx ky ji kz b la lb kj lc ld le km lf lg lh li lj lk ll lm ln lo lp lq lr ls im bi translated">所以对于<em class="lu"> BiblioEater </em>来说，这两句话看起来是一样的:</p><blockquote class="ny nz oa"><p id="6e65" class="kx ky lu kz b la lb kj lc ld le km lf ob lh li lj oc ll lm ln od lp lq lr ls im bi translated">红狮子追逐瞪羚</p><p id="311f" class="kx ky lu kz b la lb kj lc ld le km lf ob lh li lj oc ll lm ln od lp lq lr ls im bi translated">我们年轻的研究员找到了解决办法</p></blockquote><p id="0018" class="pw-post-body-paragraph kx ky ji kz b la lb kj lc ld le km lf lg lh li lj lk ll lm ln lo lp lq lr ls im bi translated">因为两者都符合 DET-ADJ-名词-动词-DET-名词的顺序。让我们记住，我们不会使用单词特征，例如限定词是被定义的冠词(<em class="lu"/>)还是所有格代词(<em class="lu"> Our </em>)。</p><p id="af3c" class="pw-post-body-paragraph kx ky ji kz b la lb kj lc ld le km lf lg lh li lj lk ll lm ln lo lp lq lr ls im bi translated">通过这样做，我们忽略了<strong class="kz jj">大量的</strong>信息，我们的模型可能会因为保留它们而变得更好。然而，这篇文章的目的是要表明，即使信息有限，我们也能捕捉到作者的部分风格。请继续阅读。</p><h2 id="1bd9" class="nm mb ji bd mc nn no dn mg np nq dp mk lg nr ns mm lk nt nu mo lo nv nw mq nx bi translated">一键编码</h2><p id="91b5" class="pw-post-body-paragraph kx ky ji kz b la ms kj lc ld mt km lf lg mu li lj lk mv lm ln lo mw lq lr ls im bi translated">如果我们是在处理文字，比如加利纳·奥莱尼克 <a class="ae lt" rel="noopener" target="_blank" href="/word-embeddings-exploration-explanation-and-exploitation-with-code-in-python-5dac99d5d795">这里</a>所解释的 word2vec 将是一个自然的选择。但是我们只处理 17 种不同的词性。因此，我们可以很容易地提供一个独热编码，将它们中的每一个表示为长度为 17 的向量，所有元素都设置为零，只有一个元素对应于语音的顺序位置。视觉上，</p><blockquote class="ny nz oa"><p id="f30d" class="kx ky lu kz b la lb kj lc ld le km lf ob lh li lj oc ll lm ln od lp lq lr ls im bi translated">红狮子追赶瞪羚。(DET-ADJ-名词-动词-DET-名词-标点)</p></blockquote><p id="f5b4" class="pw-post-body-paragraph kx ky ji kz b la lb kj lc ld le km lf lg lh li lj lk ll lm ln lo lp lq lr ls im bi translated">转换为</p><figure class="lw lx ly lz gt iv gh gi paragraph-image"><div class="gh gi pe"><img src="../Images/be31a65431b14e42b52a5e0b7b3e6021.png" data-original-src="https://miro.medium.com/v2/resize:fit:1394/format:webp/1*EGj9dfQ2pM5eRZeibl_00Q.png"/></div></figure><h2 id="eca7" class="nm mb ji bd mc nn no dn mg np nq dp mk lg nr ns mm lk nt nu mo lo nv nw mq nx bi translated">段落，而不是句子</h2><p id="fbc7" class="pw-post-body-paragraph kx ky ji kz b la ms kj lc ld mt km lf lg mu li lj lk mv lm ln lo mw lq lr ls im bi translated">在确定了我们将如何处理文本之后，我们现在来解决我们向模型提供多少文本以确定作者的问题。一次一个句子似乎太少了，因为两个作者产生相同句法结构的几率有时似乎很高。</p><p id="6e52" class="pw-post-body-paragraph kx ky ji kz b la lb kj lc ld le km lf lg lh li lj lk ll lm ln lo lp lq lr ls im bi translated">我们决定输入 3 个连续的句子作为网络的输入。我们称之为一个段落，尽管从技术上来说，大部分时间它并不是一个段落。</p><p id="47c2" class="pw-post-body-paragraph kx ky ji kz b la lb kj lc ld le km lf lg lh li lj lk ll lm ln lo lp lq lr ls im bi translated">Tom Sawyer 是两部作品中最长的一部，我们对所有生成的段落进行采样，因此 Tom 和 Pym 在训练过程中使用相同数量的段落来代表他们。</p><p id="a2ea" class="pw-post-body-paragraph kx ky ji kz b la lb kj lc ld le km lf lg lh li lj lk ll lm ln lo lp lq lr ls im bi translated">输出显然是二进制的:要么是 Poe，要么是 Twain 是作者。</p><figure class="lw lx ly lz gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi pf"><img src="../Images/00763f7ead241e68719e18675b9c5623.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ZT_4l7rtU4pg8rJ7t8vqlQ.jpeg"/></div></div><figcaption class="jc jd gj gh gi je jf bd b be z dk">Ready to eat books</figcaption></figure><h1 id="64bd" class="ma mb ji bd mc md me mf mg mh mi mj mk ko ml kp mm kr mn ks mo ku mp kv mq mr bi translated">阅读者——神经网络</h1><p id="df9a" class="pw-post-body-paragraph kx ky ji kz b la ms kj lc ld mt km lf lg mu li lj lk mv lm ln lo mw lq lr ls im bi translated">在定义神经网络的拓扑结构时，你可以随心所欲地发挥创造力。但是考虑几件事情:</p><ul class=""><li id="bab8" class="mx my ji kz b la lb ld le lg mz lk na lo nb ls nc nd ne nf bi translated">我们讨论的是输入层的几千个段落。不完全是大数据，是吗？我们必须小心，不要设计太重的网。</li><li id="d257" class="mx my ji kz b la ng ld nh lg ni lk nj lo nk ls nc nd ne nf bi translated">整个练习归结为一个简化的文本分类问题，就像 Yoon<a class="ae lt" href="https://arxiv.org/abs/1408.5882" rel="noopener ugc nofollow" target="_blank">描述的用词性代替原始单词的问题。</a></li></ul><p id="b438" class="pw-post-body-paragraph kx ky ji kz b la lb kj lc ld le km lf lg lh li lj lk ll lm ln lo lp lq lr ls im bi translated">因此，我们选择了相对简单的设计，甚至比 Yoon 论文中的设计还要简单:</p><figure class="lw lx ly lz gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi lv"><img src="../Images/577acd60036208df93857b6fbeaa2b38.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*pr5utu27wC6d7_Xun86RJA.png"/></div></div><figcaption class="jc jd gj gh gi je jf bd b be z dk">BiblioEater topology</figcaption></figure><p id="b870" class="pw-post-body-paragraph kx ky ji kz b la lb kj lc ld le km lf lg lh li lj lk ll lm ln lo lp lq lr ls im bi translated">它由一系列基本的卷积层和最大池层对组成，最后由两个密集层组成，以获得二进制输出。你也可以找几个脱层作为防止过度合身的安全网。该代码保存了 BiblioEater 类中的所有细节。</p><p id="873c" class="pw-post-body-paragraph kx ky ji kz b la lb kj lc ld le km lf lg lh li lj lk ll lm ln lo lp lq lr ls im bi translated">驱动训练过程的各种参数，例如过滤器数量、步幅等。可以在代码中找到。它们被隔离为常量，以便于调整和比较结果。</p><p id="9970" class="pw-post-body-paragraph kx ky ji kz b la lb kj lc ld le km lf lg lh li lj lk ll lm ln lo lp lq lr ls im bi translated">当 StanfordNLP 使用 PyTorch 进行机器学习时，我们自然会选择 PyTorch 而不是 Keras。然而，我们用 Keras，因为它通常更容易阅读。</p><h1 id="157d" class="ma mb ji bd mc md me mf mg mh mi mj mk ko ml kp mm kr mn ks mo ku mp kv mq mr bi translated">结果</h1><p id="5cbc" class="pw-post-body-paragraph kx ky ji kz b la ms kj lc ld mt km lf lg mu li lj lk mv lm ln lo mw lq lr ls im bi translated">利用代码中保存的建模值，<em class="lu"> BiblioEater </em>有 18，954 个参数，不是很多，因此即使是一个无 GPU 的工作站也可以轻松处理训练工作。我们输入了来自两本书的偶数个带标签的段落，得到了 0.9313 的准确度。不算太坏，我们已经提到了所有的警告。</p><p id="b548" class="pw-post-body-paragraph kx ky ji kz b la lb kj lc ld le km lf lg lh li lj lk ll lm ln lo lp lq lr ls im bi translated">但是当我们强迫<em class="lu">食书者</em>吞下《尤利卡》和《哈克贝利·费恩历险记》时，布丁的真正证据就来了。请记住，这些书中的任何文本都没有包含在培训中。还要记住，每次网络上出现的都是 3 句话的段落，这并不多。这是我们得到的混淆矩阵。</p><figure class="lw lx ly lz gt iv gh gi paragraph-image"><div class="gh gi pg"><img src="../Images/c77be11a0f75740a79788281bc02defe.png" data-original-src="https://miro.medium.com/v2/resize:fit:708/format:webp/1*XPK7JRGvojLmfPDUh1hRxQ.png"/></div></figure><p id="20c3" class="pw-post-body-paragraph kx ky ji kz b la lb kj lc ld le km lf lg lh li lj lk ll lm ln lo lp lq lr ls im bi translated">因此,<em class="lu">阅读者</em>在 90%以上的时间里都对两本它以前没看过的书。这是考虑到我们决定不包括但在文本中存在的所有特征。如果我们给它输入 4 句话的段落，我们可以为每个作者增加大约 0.015 的准确率。</p><p id="58e8" class="pw-post-body-paragraph kx ky ji kz b la lb kj lc ld le km lf lg lh li lj lk ll lm ln lo lp lq lr ls im bi translated">调整参数，我们得到了类似的结果，但结果有些不稳定，这表明数据集有点小。也许我们应该选择狄更斯的所有作品！</p><h1 id="c235" class="ma mb ji bd mc md me mf mg mh mi mj mk ko ml kp mm kr mn ks mo ku mp kv mq mr bi translated">我能运行代码吗？</h1><p id="7152" class="pw-post-body-paragraph kx ky ji kz b la ms kj lc ld mt km lf lg mu li lj lk mv lm ln lo mw lq lr ls im bi translated">你当然可以。从<a class="ae lt" href="https://github.com/angelnew/biblioeater" rel="noopener ugc nofollow" target="_blank"> github </a>下载，请先通读 README.md 文件。</p><h1 id="0f07" class="ma mb ji bd mc md me mf mg mh mi mj mk ko ml kp mm kr mn ks mo ku mp kv mq mr bi translated">结论</h1><p id="16ba" class="pw-post-body-paragraph kx ky ji kz b la ms kj lc ld mt km lf lg mu li lj lk mv lm ln lo mw lq lr ls im bi translated">作家在作品中打上自己风格印记并不新鲜。我们在这篇文章中试图传达的是他如何仅仅基于三个连续句子的词性来处理文本归属。添加我们忽略的功能后，我们的结果应该会显著改善。高质量开源软件(Keras、Tensorflow 和最近的 StanfordNLP)的出现使这成为可能。</p></div></div>    
</body>
</html>