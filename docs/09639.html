<html>
<head>
<title>Segmentation of Roads in Aerial Images.</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">航空图像中道路的分割。</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/road-segmentation-727fb41c51af?source=collection_archive---------7-----------------------#2019-12-18">https://towardsdatascience.com/road-segmentation-727fb41c51af?source=collection_archive---------7-----------------------#2019-12-18</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="0139" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">这篇全面的文章将帮助您创建一个道路分割模型，它可以检测和分割航空图像中的道路。</h2></div><p id="aba6" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">卷积神经网络(C.N.N.s)的出现是计算机视觉领域的一项突破，因为它们从根本上改变了计算机“看”图像的方式。机器视觉已经从它开始的地方走了很长的路，但它今天仍然处于研究的前沿。语义分割是将图像中的每个像素归属于某一类的过程。这个类可以是一只狗，一辆车，或者在我们的例子中是道路。</p><figure class="lf lg lh li gt lj gh gi paragraph-image"><div role="button" tabindex="0" class="lk ll di lm bf ln"><div class="gh gi le"><img src="../Images/5c52e955af60fd153ea1cbd9cd397ba9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*SLE9uNCgsOg4UW-LDKyFJw.png"/></div></div><figcaption class="lq lr gj gh gi ls lt bd b be z dk">You can view the interactive output <a class="ae lu" href="https://generationai.wixsite.com/evolve" rel="noopener ugc nofollow" target="_blank">here</a>.</figcaption></figure><p id="d30a" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">地球上所有道路的总长度约为 3350 万公里。让我换一种说法——如果我们能把所有的路都排成一条直线，那么我们将走过地球和太阳之间距离的四分之一。手动标注道路的每一部分是一项艰巨的任务，如果不是不可能的话。这就是深度学习发挥作用的地方，这也是我们将通过这个项目完成的事情。简单来说，我们将训练一个深度学习模型来识别航拍图像中的道路。</p><p id="b3b4" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">您可以在本文末尾找到源代码的链接。如果你想了解这篇文章的范围，请参考目录。项目中使用的所有资源都是公开可用的，因此建议您遵守。本文涵盖了该项目的实践和理论两个方面，我希望这对您来说是一次愉快的学习经历。</p><h1 id="6395" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">目录</h1><ol class=""><li id="c955" class="mn mo it kk b kl mp ko mq kr mr kv ms kz mt ld mu mv mw mx bi translated"><strong class="kk iu">数据<br/>一、我们需要的数据类型。<br/>二。数据集<br/> iii。正在下载数据集。</strong></li><li id="18e5" class="mn mo it kk b kl my ko mz kr na kv nb kz nc ld mu mv mw mx bi translated"><strong class="kk iu">预处理</strong></li><li id="3a79" class="mn mo it kk b kl my ko mz kr na kv nb kz nc ld mu mv mw mx bi translated"><strong class="kk iu">神经建模<br/>一、关于 F.C.N <br/>二。网络架构</strong></li><li id="2693" class="mn mo it kk b kl my ko mz kr na kv nb kz nc ld mu mv mw mx bi translated"><strong class="kk iu">训练模型<br/>一、损失函数和优化器<br/>二。回调<br/>三。训练模型</strong></li><li id="07d1" class="mn mo it kk b kl my ko mz kr na kv nb kz nc ld mu mv mw mx bi translated"><strong class="kk iu">测试模型</strong></li><li id="8601" class="mn mo it kk b kl my ko mz kr na kv nb kz nc ld mu mv mw mx bi translated"><strong class="kk iu">改进范围</strong></li><li id="96bb" class="mn mo it kk b kl my ko mz kr na kv nb kz nc ld mu mv mw mx bi translated"><strong class="kk iu">结论</strong></li><li id="c288" class="mn mo it kk b kl my ko mz kr na kv nb kz nc ld mu mv mw mx bi translated"><strong class="kk iu">链接和引用</strong></li></ol><p id="786b" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">让我们开始吧。</p><h1 id="9aae" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">1.数据</h1><p id="cefd" class="pw-post-body-paragraph ki kj it kk b kl mp ju kn ko mq jx kq kr nd kt ku kv ne kx ky kz nf lb lc ld im bi translated">不同类型的机器学习模型需要不同类型的数据，数据越多越好。更多的数据训练意味着我们的模型将能够学习更多的潜在模式，并且能够更好地区分异常值。</p><h2 id="9337" class="ng lw it bd lx nh ni dn mb nj nk dp mf kr nl nm mh kv nn no mj kz np nq ml nr bi translated">我们需要的数据类型。</h2><p id="c32b" class="pw-post-body-paragraph ki kj it kk b kl mp ju kn ko mq jx kq kr nd kt ku kv ne kx ky kz nf lb lc ld im bi translated">通常，对于分割挑战，我们需要图像以及它们各自的(最好是手绘的)地图。对于这个项目，我们需要航空图像，以及它们的分段地图，其中只显示了道路。这个想法是，我们的模型将专注于表示道路的白色像素，它将学习输入图像和输出地图之间的相关性。</p><h2 id="9865" class="ng lw it bd lx nh ni dn mb nj nk dp mf kr nl nm mh kv nn no mj kz np nq ml nr bi translated">二。数据集</h2><p id="f723" class="pw-post-body-paragraph ki kj it kk b kl mp ju kn ko mq jx kq kr nd kt ku kv ne kx ky kz nf lb lc ld im bi translated">对于这个项目，我们将使用<a class="ae lu" href="https://www.cs.toronto.edu/~vmnih/data/" rel="noopener ugc nofollow" target="_blank">马萨诸塞州道路数据集</a>。该数据集包含 1171 幅航空影像，以及它们各自的地图。它们的尺寸是 1500 x 1500 英寸。tiff 格式。请看看下面的样品。</p><figure class="lf lg lh li gt lj gh gi paragraph-image"><div role="button" tabindex="0" class="lk ll di lm bf ln"><div class="gh gi ns"><img src="../Images/62aaf869667938b70951f0891b94ec8a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*sk0l0FF_k21FJtfFHjaWjw.jpeg"/></div></div><figcaption class="lq lr gj gh gi ls lt bd b be z dk">Just look at how elaborately the image was annotated.</figcaption></figure><h2 id="57b8" class="ng lw it bd lx nh ni dn mb nj nk dp mf kr nl nm mh kv nn no mj kz np nq ml nr bi translated">三。正在下载数据集。</h2><p id="12cb" class="pw-post-body-paragraph ki kj it kk b kl mp ju kn ko mq jx kq kr nd kt ku kv ne kx ky kz nf lb lc ld im bi translated">您可以从克隆我的 GitHub <a class="ae lu" href="https://github.com/Paulymorphous/Road-Segmentation" rel="noopener ugc nofollow" target="_blank"> repo </a>开始，然后使用 Src 文件夹中的 download_images.py 脚本下载数据集。如果你有一个不可靠的持续波动的互联网连接，那么请使用<em class="nt">学术洪流</em>来获取数据集。你可以在这里找到数据集<a class="ae lu" href="http://academictorrents.com/details/630d2c7e265af1d957cbee270f4328c54ccef333" rel="noopener ugc nofollow" target="_blank">。</a></p><h1 id="a790" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">2.预处理</h1><p id="ccf5" class="pw-post-body-paragraph ki kj it kk b kl mp ju kn ko mq jx kq kr nd kt ku kv ne kx ky kz nf lb lc ld im bi translated">数据的质量极大地影响了我们模型的性能，因此预处理是确保我们的模型以正确的形式接收数据的重要一步。我尝试了多种预处理技术，以下方法产生了最好的结果:</p><p id="0147" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="kk iu">一、手选</strong>:数据集中有少数(<em class="nt"> ~50 </em>)图像缺失了一大块航拍图像。大部分图像包含白色像素，但它们有完整的分割图。因为这样会影响模型，所以我手动删除了它们。</p><p id="ca82" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="kk iu">二。裁剪而不是调整尺寸</strong>:在大图像上训练我们的模型不仅是资源密集型的，而且一定会花费很多时间。将图像调整到较低的尺寸可能是一个解决办法，但是调整尺寸是有代价的。无论我们在调整大小时选择什么样的插值方法，我们最终都会丢失信息。</p><p id="c94a" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">因此，我们将从大图像中裁剪出较小的 256 x 256 的图像。这样做给我们留下了大约 22，000 幅有用的图像和地图。</p><p id="1a41" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">三。<strong class="kk iu">对图进行阈值处理和二值化:</strong>灰度图像是包含不同灰度的单通道图像。每个像素可以取 256 个可能的灰度值，0 代表黑色像素，255 代表白色像素。在语义分割中，我们本质上预测每个像素的这个值。我们将只提供两个选项，而不是提供 256 个离散选项供模型选择。你可能已经注意到了，我们的地图只有两种颜色:黑色和白色。白色像素代表道路，黑色像素代表除道路以外的一切。</p><p id="84d7" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">仔细观察我们的双色分割图，会发现当我们想要的是黑白时，有许多灰色像素。我们将从阈值像素值为 100 开始。使得所有具有高于某个阈值的值的像素被分配最大值 255，而所有其他像素被分配零。这样做确保了在分段掩码中只有两个唯一的像素值。现在，0 和 255 是一个很大的范围。通过将所有地图除以 255，我们将地图归一化，现在我们最终只有两个值— 0 和 1。</p><p id="812d" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="kk iu">四。打包(可选)</strong>:我在 Google Colab 上训练了我的模型。衷心感谢谷歌为成千上万的数据科学家和机器学习工程师提供资源。</p><p id="5ba0" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我注意到在训练期间从 Gdrive 向模型提供图像(使用 ImageDataGenerator)最终会消耗额外的时间。但是，如果您在系统上训练模型，这就不正确了，因为在这种情况下加载文件要快得多。我将整个图像和地图数组打包成两个独立的<em class="nt"> .h5py </em>文件，并将它们加载到内存中。这样做加快了训练过程。</p><h1 id="4d8c" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">3.神经建模</h1><p id="c5aa" class="pw-post-body-paragraph ki kj it kk b kl mp ju kn ko mq jx kq kr nd kt ku kv ne kx ky kz nf lb lc ld im bi translated">既然我们已经处理了数据，是时候开始模拟我们的神经网络了。为了完成我们的分段任务，我们将使用全卷积网络。这类网络大多由卷积层组成，与更传统的神经网络不同，没有完全连接的层。</p><h2 id="265d" class="ng lw it bd lx nh ni dn mb nj nk dp mf kr nl nm mh kv nn no mj kz np nq ml nr bi translated">一、关于 F.C.N</h2><p id="9be1" class="pw-post-body-paragraph ki kj it kk b kl mp ju kn ko mq jx kq kr nd kt ku kv ne kx ky kz nf lb lc ld im bi translated">德国弗赖堡大学计算机科学系开发了用于生物医学图像分割的全卷积网络[1]。后来人们意识到，这些网络的范围远远超出了医学领域。这些网络可以对任何类型的对象进行多类分割——无论是分割人、汽车还是建筑物。</p><h2 id="5067" class="ng lw it bd lx nh ni dn mb nj nk dp mf kr nl nm mh kv nn no mj kz np nq ml nr bi translated">二。网络体系结构</h2><p id="cf58" class="pw-post-body-paragraph ki kj it kk b kl mp ju kn ko mq jx kq kr nd kt ku kv ne kx ky kz nf lb lc ld im bi translated">这个项目使用 U-net，这是一个完全卷积的神经网络，它的名字很直观。该网络采用 256x256 多通道图像，并输出相同尺寸的单通道图。</p><p id="58de" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">U-net 有两部分——编码器或下采样部分，解码器或上采样部分。看看下面的图片就知道了。</p><figure class="lf lg lh li gt lj gh gi paragraph-image"><div role="button" tabindex="0" class="lk ll di lm bf ln"><div class="gh gi nu"><img src="../Images/1d33d6045ffbfb7997fa8ddd8c87953e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*YPy533pmOsZN7P4qDqpwxA.png"/></div></div><figcaption class="lq lr gj gh gi ls lt bd b be z dk">Dissecting a U-net</figcaption></figure><p id="4029" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="kk iu">编码器:</strong>下采样部分。此部分使用卷积层来学习图像中的时间特征，并使用汇集层对其进行下采样。这部分负责学习图像中的物体。在这种情况下，这部分学习道路看起来如何，并可以检测它。我添加了 dropout 层，它将随机忽略神经元以防止过度拟合，我添加了 BatchNormalization 以确保每一层都可以独立于前一层进行学习。</p><p id="bf23" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="kk iu">解码器:</strong>又叫上采样段。连续的池操作会导致图像空间信息的丢失。模型确实知道图像的内容，但是不知道它在哪里。解码器网络背后的整个想法是使用我们在上一步中提取的特征图来重建空间数据。我们使用转置卷积对图像进行上采样。与普通插值不同，Conv2DTranspose 具有可学习的参数。</p><p id="6676" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="kk iu">跳过连接:</strong>编码器段中的层与解码器段中的层之间的直接连接称为跳过连接。它们被称为跳过连接，因为它们桥接两层，而忽略所有中间层。跳过连接为上采样层提供空间信息，并帮助它们重建图像和“将东西放入适当的位置”(字面意思)。</p><p id="3391" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">请使用以下代码复制 U-net。</p><p id="0757" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我们的 U-net 闪耀着光辉。</p><h1 id="7473" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">4.训练模型</h1><h2 id="df89" class="ng lw it bd lx nh ni dn mb nj nk dp mf kr nl nm mh kv nn no mj kz np nq ml nr bi translated">一.损失函数和超参数</h2><p id="3870" class="pw-post-body-paragraph ki kj it kk b kl mp ju kn ko mq jx kq kr nd kt ku kv ne kx ky kz nf lb lc ld im bi translated">在像素级别，这种分割挑战可以被认为是二元分类问题，其中模型对每个像素是白色(道路)还是黑色(非道路)进行分类。但是，我们需要一个平衡的数据集来促进正确的分割，因为这些图像中黑色像素的数量远远超过白色像素，所以我们有一个不平衡的数据集。</p><p id="4239" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">有几种不同的方法来处理不平衡的数据问题。在这个挑战中，我们将使用软骰子损失，因为它是基于骰子系数。Dice 系数是预测样本和基础真实样本之间重叠的度量，该值的范围在 0 和 1 之间。其中 0 表示没有重叠，1 表示完全重叠。</p><figure class="lf lg lh li gt lj gh gi paragraph-image"><div role="button" tabindex="0" class="lk ll di lm bf ln"><div class="gh gi nv"><img src="../Images/716ccd835a800e7ed88c8d9f8ea324e4.png" data-original-src="https://miro.medium.com/v2/resize:fit:408/format:webp/0*TDrWE7FVJ8QkoHj5.png"/></div></div><figcaption class="lq lr gj gh gi ls lt bd b be z dk">The formula for the Dice Coefficient. Deja Vu?</figcaption></figure><p id="f9e7" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">平滑骰子损失就是<em class="nt"> 1 —骰子系数</em>，这样做是为了创建一个最小化损失函数【2】。请看下面骰子丢失的代码。</p><pre class="lf lg lh li gt nw nx ny nz aw oa bi"><span id="7431" class="ng lw it nx b gy ob oc l od oe">def dice_coef(y_true, y_pred, smooth = 1):<br/>   y_true_f = K.flatten(y_true)<br/>   y_pred_f = K.flatten(y_pred)<br/>   <br/>   intersection = K.sum(y_true_f * y_pred_f)<br/>   dice = (2. * intersection + smooth) / (K.sum(y_true_f)    K.sum(y_pred_f) + smooth)<br/>   <br/>   return dice</span><span id="e4a2" class="ng lw it nx b gy of oc l od oe">def soft_dice_loss(y_true, y_pred):<br/>   return 1-dice_coef(y_true, y_pred)</span></pre><p id="6ade" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">可以看到，我们使用了一个名为 smooth 的参数，默认值为 1。通过将分子和分母都加 1，我们可以确保永远不会被零除。</p><figure class="lf lg lh li gt lj gh gi paragraph-image"><div class="gh gi og"><img src="../Images/2ba485c4d65a4acc644f8f3cfdd6fb87.png" data-original-src="https://miro.medium.com/v2/resize:fit:600/format:webp/1*ll7mcZnX_vg0j6HdFcMncw.png"/></div><figcaption class="lq lr gj gh gi ls lt bd b be z dk">Source:pyimagesearch.com</figcaption></figure><p id="021b" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="kk iu">准确性度量</strong>:准确性度量告诉我们生成的分割图的正确性。我们将使用 Jaccard 索引，也就是 Union 上的交集，来告诉我们生成的地图有多精确。顾名思义，交集超过并集是分割图正确性的度量。分子是预测图和基本事实标注之间的交集，而分母是基本事实标注和分割图的总面积(使用联合运算计算)。下面的代码片段用于计算 Jaccard 索引。</p><pre class="lf lg lh li gt nw nx ny nz aw oa bi"><span id="83b9" class="ng lw it nx b gy ob oc l od oe">def IoU(y_pred, y_true):<br/>   I = tf.reduce_sum(y_pred * y_true, axis=(1, 2))<br/>   U = tf.reduce_sum(y_pred + y_true, axis=(1, 2)) - I<br/>   return tf.reduce_mean(I / U)</span></pre><p id="4113" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我们使用 Adam 作为优化器来编译模型。我们将以 0.00001 的学习率开始，我们将它设置为运行 100 个时期。我们使用软骰子损失作为损失函数，使用 Jaccard 指数作为精度指标。</p><h2 id="9222" class="ng lw it bd lx nh ni dn mb nj nk dp mf kr nl nm mh kv nn no mj kz np nq ml nr bi translated">二。复试</h2><p id="968e" class="pw-post-body-paragraph ki kj it kk b kl mp ju kn ko mq jx kq kr nd kt ku kv ne kx ky kz nf lb lc ld im bi translated">在训练过程中可以调用的一组函数称为回调函数。在这个项目中，我们将使用四次回调:</p><ol class=""><li id="7fa0" class="mn mo it kk b kl km ko kp kr oh kv oi kz oj ld mu mv mw mx bi translated"><strong class="kk iu">模型检查点</strong>:监控验证损失，保存验证损失最低的模型的权重。</li><li id="fe0c" class="mn mo it kk b kl my ko mz kr na kv nb kz nc ld mu mv mw mx bi translated"><strong class="kk iu">提前停止</strong>:监控确认损失，如果确认损失在一定次数后没有增加，则终止训练过程。</li><li id="8c43" class="mn mo it kk b kl my ko mz kr na kv nb kz nc ld mu mv mw mx bi translated"><strong class="kk iu"> ReduceLROnPlateau </strong>:监控验证损失，如果验证损失在一定次数后没有降低，则降低学习率。</li><li id="4c52" class="mn mo it kk b kl my ko mz kr na kv nb kz nc ld mu mv mw mx bi translated">TensorBoardColab :是 Tensorboard 的一个特殊版本，专门用于 Google Colab。我们可以在培训过程中监控准确性和其他指标。</li></ol><h2 id="72f1" class="ng lw it bd lx nh ni dn mb nj nk dp mf kr nl nm mh kv nn no mj kz np nq ml nr bi translated">三。训练模型</h2><p id="70b4" class="pw-post-body-paragraph ki kj it kk b kl mp ju kn ko mq jx kq kr nd kt ku kv ne kx ky kz nf lb lc ld im bi translated">我们已经做了所有的功课，现在是时候拟合模型了。但在此之前，我们将使用<em class="nt">trainttestsplit()</em>将数据拆分为分别包含 17，780 和 4446 幅图像的训练集和测试集。一旦模型开始对训练数据进行训练，你也许可以去跑步，因为这需要一些时间。好的一面是，我们不必照看模型，你可以回到一个训练有素的模型和输出的重量。</p><p id="52d5" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">该模型运行了 57 个时期，然后早期停止开始并停止了训练过程。最小验证损失为 0.2352。您可以在下图中观察验证和培训指标的趋势。</p><figure class="lf lg lh li gt lj gh gi paragraph-image"><div role="button" tabindex="0" class="lk ll di lm bf ln"><div class="gh gi ok"><img src="../Images/48511e3fd92e18bbe07b93ec3fe68fc9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*fSofHJMt5DYohuxmeztaeg.png"/></div></div><figcaption class="lq lr gj gh gi ls lt bd b be z dk">Tensorgrab</figcaption></figure><h1 id="5ebb" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">5.测试模型</h1><p id="bafa" class="pw-post-body-paragraph ki kj it kk b kl mp ju kn ko mq jx kq kr nd kt ku kv ne kx ky kz nf lb lc ld im bi translated">我们的测试集包含 4446 幅图像，我们的模型几乎可以立即预测它们的分割图。我们的模型在测试集上的性能可以使用 Dice 系数来衡量，该系数达到 0.59(该值介于 0 和 1 之间)。当然还有改进的余地。您可以在下图中观察到一些预测的输出。</p><figure class="lf lg lh li gt lj gh gi paragraph-image"><div role="button" tabindex="0" class="lk ll di lm bf ln"><div class="gh gi ol"><img src="../Images/6347099e16fd988ab334c8ce40cb6e5a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*LdYHmYCuDrr1ANproCq0Qg.png"/></div></div><figcaption class="lq lr gj gh gi ls lt bd b be z dk">Few Samples</figcaption></figure><p id="b5b0" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">再看一下，您会注意到我们的模型可以分割注释者遗漏的部分道路。在下图中，注释者跳过了右下角的方块，而我们的模型能够捕捉到它。我们的模型成功地分割了车道、停车场和死胡同。</p><figure class="lf lg lh li gt lj gh gi paragraph-image"><div role="button" tabindex="0" class="lk ll di lm bf ln"><div class="gh gi om"><img src="../Images/efbaaf0b5bd33a1b9b3d8141a5829a6a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*oZkFzr5Zb6tl6oJHMTwn8w.png"/></div></div><figcaption class="lq lr gj gh gi ls lt bd b be z dk">Our model was able to pick up the square region</figcaption></figure><h1 id="3930" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">6.改进的范围</h1><p id="48fa" class="pw-post-body-paragraph ki kj it kk b kl mp ju kn ko mq jx kq kr nd kt ku kv ne kx ky kz nf lb lc ld im bi translated">在某些地图上，道路并不完全可见，请看下面的例子。我们的模型无法检测左侧的道路。尽管没有一个模型能产生 100%准确的结果，但总有改进的空间。</p><figure class="lf lg lh li gt lj gh gi paragraph-image"><div role="button" tabindex="0" class="lk ll di lm bf ln"><div class="gh gi on"><img src="../Images/5631fb1abeb5a144032f146d1b803c90.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*fOQFIsrIvKxW0CZ9FJoFAQ.png"/></div></div><figcaption class="lq lr gj gh gi ls lt bd b be z dk">Missing predictions</figcaption></figure><p id="8645" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我们可以通过采取某些措施来提高模型的性能，这些措施如下:</p><ol class=""><li id="8bd6" class="mn mo it kk b kl km ko kp kr oh kv oi kz oj ld mu mv mw mx bi translated"><strong class="kk iu">图像数据增强</strong>:它是通过应用各种操作，如颜色偏移、旋转等，使图像轻微失真的方法。来产生更多的数据。</li><li id="b8a4" class="mn mo it kk b kl my ko mz kr na kv nb kz nc ld mu mv mw mx bi translated"><strong class="kk iu">使用损失乘数处理职业不平衡</strong>:如前所述，我们有一个职业不平衡的问题，为了解决它，我们使用了软骰子损失。我们希望最大化我们的 dice 系数，但是当与二元交叉熵相比时，后者具有更好的梯度，因此将是我们定制损失函数的良好代理，并且可以容易地最大化。唯一的问题是，与软骰子损失不同，二进制交叉熵不是为了处理类别不平衡而构建的，这导致了乌黑的分割图。然而，如果我们应用类乘数，使得模型被激励来忽略频繁出现的类，那么我们可以使用二进制交叉熵来代替骰子损失。这将带来流畅的训练体验。</li><li id="bd47" class="mn mo it kk b kl my ko mz kr na kv nb kz nc ld mu mv mw mx bi translated"><strong class="kk iu">使用预训练模型:</strong>预训练模型可以针对这个问题进行微调，它们将充当最佳特征提取器。使用迁移学习导致更快的训练时间，并且通常产生更好的分割图。</li></ol><h1 id="7d47" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">7.结论</h1><p id="e46a" class="pw-post-body-paragraph ki kj it kk b kl mp ju kn ko mq jx kq kr nd kt ku kv ne kx ky kz nf lb lc ld im bi translated">在这个项目中，我们创建了一个深度学习模型，可以从航拍图像中分割道路。我们获取了图像，并对其进行处理以满足我们的需求。我们创建了一个 U-net 并了解了它的工作原理。我们使用软骰子损失作为我们的成本函数，并训练了 57 个时期的模型。然后，我们在测试集上测试我们的模型，并观察一些样本。</p><p id="251b" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">本项目的几点收获:</p><ol class=""><li id="38f9" class="mn mo it kk b kl km ko kp kr oh kv oi kz oj ld mu mv mw mx bi translated">裁剪图像而不是调整它们的大小可以保留空间信息。</li><li id="409c" class="mn mo it kk b kl my ko mz kr na kv nb kz nc ld mu mv mw mx bi translated">将分割图二值化将图中不同值的数量减少到两个。</li><li id="03c8" class="mn mo it kk b kl my ko mz kr na kv nb kz nc ld mu mv mw mx bi translated">使用 ModelCheckpoint 回调来保存模型权重是一个好主意。为了以防万一，如果程序在训练过程中崩溃，你可以随时重新加载重量并恢复训练。</li><li id="cf70" class="mn mo it kk b kl my ko mz kr na kv nb kz nc ld mu mv mw mx bi translated">最后，如果你曾经走进了死胡同，那么<a class="oo op ep" href="https://medium.com/u/d41130ab0af4?source=post_page-----727fb41c51af--------------------------------" rel="noopener" target="_blank"> Slav Ivanov </a>已经写了一篇全面的<a class="ae lu" href="https://blog.slavv.com/37-reasons-why-your-neural-network-is-not-working-4020854bd607" rel="noopener ugc nofollow" target="_blank">文章</a>，它将帮助你克服任何与深度学习相关的障碍。</li></ol><h1 id="1154" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">8.链接和参考</h1><p id="2333" class="pw-post-body-paragraph ki kj it kk b kl mp ju kn ko mq jx kq kr nd kt ku kv ne kx ky kz nf lb lc ld im bi translated">这个挑战的确很有趣，感谢您通读这篇文章。如果您有任何反馈或问题，请随时在下面的评论部分输入。</p><p id="c618" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">如果你期待更多有趣的教程，那么请关注我的<a class="ae lu" href="https://twitter.com/Paulymorphous" rel="noopener ugc nofollow" target="_blank"> Twitter </a>和 Medium。</p><h2 id="06fd" class="ng lw it bd lx nh ni dn mb nj nk dp mf kr nl nm mh kv nn no mj kz np nq ml nr bi translated">链接</h2><ol class=""><li id="9999" class="mn mo it kk b kl mp ko mq kr mr kv ms kz mt ld mu mv mw mx bi translated"><a class="ae lu" href="https://github.com/Paulymorphous/Road-Segmentation" rel="noopener ugc nofollow" target="_blank">源代码</a>。</li><li id="04d4" class="mn mo it kk b kl my ko mz kr na kv nb kz nc ld mu mv mw mx bi translated"><a class="ae lu" href="http://cs231n.stanford.edu/" rel="noopener ugc nofollow" target="_blank"> CS231n:用于视觉识别的卷积神经网络</a></li></ol><h2 id="25d6" class="ng lw it bd lx nh ni dn mb nj nk dp mf kr nl nm mh kv nn no mj kz np nq ml nr bi translated">参考</h2><p id="7f2b" class="pw-post-body-paragraph ki kj it kk b kl mp ju kn ko mq jx kq kr nd kt ku kv ne kx ky kz nf lb lc ld im bi translated">[1] <a class="ae lu" href="https://en.wikipedia.org/wiki/U-Net" rel="noopener ugc nofollow" target="_blank">优信网—维基百科</a></p><p id="7de8" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">[2] <a class="ae lu" href="https://www.jeremyjordan.me/evaluating-image-segmentation-models/" rel="noopener ugc nofollow" target="_blank">评估图像分割模型—杰瑞米·乔登</a></p><p id="bf8c" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">想了解更多？查看我的其他几篇文章:</p><ol class=""><li id="608d" class="mn mo it kk b kl km ko kp kr oh kv oi kz oj ld mu mv mw mx bi translated"><a class="ae lu" rel="noopener" target="_blank" href="/s01e01-3eb397d458d">创建自定义人脸识别模型，并在您的系统上运行。</a></li><li id="61e3" class="mn mo it kk b kl my ko mz kr na kv nb kz nc ld mu mv mw mx bi translated"><a class="ae lu" href="https://medium.com/free-code-camp/facial-emotion-recognition-develop-a-c-n-n-and-break-into-kaggle-top-10-f618c024faa7" rel="noopener">构建活体情感识别模型</a>。</li></ol></div></div>    
</body>
</html>