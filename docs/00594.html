<html>
<head>
<title>Mario vs. Wario — round 2: CNNs in PyTorch and Google Colab</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">马里奥对瓦里奥——第二轮:CNN 在 PyTorch 和 Google Colab</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/mario-vs-wario-round-2-cnns-in-pytorch-and-google-colab-48b968cf4ace?source=collection_archive---------9-----------------------#2019-01-27">https://towardsdatascience.com/mario-vs-wario-round-2-cnns-in-pytorch-and-google-colab-48b968cf4ace?source=collection_archive---------9-----------------------#2019-01-27</a></blockquote><div><div class="fc ij ik il im in"/><div class="io ip iq ir is"><figure class="iu iv gp gr iw ix gh gi paragraph-image"><div role="button" tabindex="0" class="iy iz di ja bf jb"><div class="gh gi it"><img src="../Images/b16380fec0435af0f72b7e4b677a302a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*lg6DbiMd48RM9DijL83VQw.jpeg"/></div></div></figure><div class=""/><div class=""><h2 id="059d" class="pw-subtitle-paragraph kd jf jg bd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku dk translated">在 PyTorch 中快速构建卷积神经网络对视频游戏截图进行分类</h2></div><p id="1fa6" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq io bi translated">很长一段时间我都在玩 Google Colab(是的，免费访问 GPU…)。我认为这是一个非常棒的倡议，它使个人电脑上没有 GPU 的人能够玩深度学习和训练模型，否则他们将无法训练。基本上，我们有 12 个小时的时间来玩，然后虚拟机就死了。但是，我们当然可以开始一个新的会议，并且有办法继续以前会议的工作。</p><p id="4f03" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq io bi translated">在这篇文章中，我想介绍我之前的<a class="ae lr" rel="noopener" target="_blank" href="/mario-vs-wario-image-classification-in-python-ae8d10ac6d63">作品</a>的延伸。然而这一次，我将使用 PyTorch 构建一个 CNN，并在 Google Colab 上对其进行训练。最终，我希望取得比以前更好的成绩！开始吧:)</p><h1 id="089d" class="ls lt jg bd lu lv lw lx ly lz ma mb mc km md kn me kp mf kq mg ks mh kt mi mj bi translated"><strong class="ak"> 1。建立谷歌实验室</strong></h1><p id="2aa4" class="pw-post-body-paragraph kv kw jg kx b ky mk kh la lb ml kk ld le mm lg lh li mn lk ll lm mo lo lp lq io bi translated">Medium 上已经有一些关于如何开始使用 Google Colab、如何启用 GPU 等的好文章。我想展示几个有用的命令来检查我们实际上在做什么样的硬件/软件:</p><figure class="mq mr ms mt gt ix gh gi paragraph-image"><div role="button" tabindex="0" class="iy iz di ja bf jb"><div class="gh gi mp"><img src="../Images/9bf9a0f44120f8286304ba1ca5fc4eff.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*nEWfJqJt2pH1jS_nY6S7Fw.png"/></div></div></figure><figure class="mq mr ms mt gt ix gh gi paragraph-image"><div role="button" tabindex="0" class="iy iz di ja bf jb"><div class="gh gi mu"><img src="../Images/e383182ee17d27f7c277a9aeaf9ad3d2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*FWGjhzywCCplqg-CUG15aw.png"/></div></div></figure><p id="5952" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq io bi translated">我们看到我们正在开发 Tesla K80，并且已经安装了 Cuda 9.2。这样事情就简单多了！</p><p id="b3e8" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq io bi translated">找到如何有效处理存储在 Google Drive 上的大型数据集并不容易。许多课程和帖子使用 PyTorch 或其他库中的内置数据集。但是一开始，我发现使用我自己的一组图像有点棘手。所以我做了以下事情:</p><ul class=""><li id="f3da" class="mv mw jg kx b ky kz lb lc le mx li my lm mz lq na nb nc nd bi translated">将数据集(带有训练/测试文件夹的压缩文件)上传到 Google Drive。</li></ul><p id="b8a8" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq io bi translated">这可以通过驱动程序 UI 轻松完成。最初的目录树如下所示:</p><pre class="mq mr ms mt gt ne nf ng nh aw ni bi"><span id="8cb8" class="nj lt jg nf b gy nk nl l nm nn">mario_vs_wario/<br/>    training_set/<br/>        mario/<br/>            mario_1.jpg<br/>            mario_2.jpg<br/>            ...<br/>        wario/<br/>            wario_1.jpg<br/>            wario_2.jpg<br/>            ...<br/>    test_set/<br/>        mario/<br/>            mario_1.jpg<br/>            mario_2.jpg<br/>            ...<br/>        wario/<br/>            wario_1.jpg<br/>            wario_2.jpg<br/>            ...</span></pre><ul class=""><li id="26c2" class="mv mw jg kx b ky kz lb lc le mx li my lm mz lq na nb nc nd bi translated">安装 Google Drive</li></ul><p id="dd45" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq io bi translated">使用 Colab 时，重要的是将文件存储在 Colab 目录中，而不是安装在 Google Drive 上。下面的单元格包含连接到 Google Drive 并安装该驱动器的代码，这样我们就可以访问存储在那里的所有文件。然而，用从 Google Drive 加载的数据训练神经网络(即使启用了 GPU)在大多数情况下会比在 CPU 上本地训练它慢得多。这是由于在 Colab 和 Drive 目录之间复制所有数据，这非常慢。</p><figure class="mq mr ms mt gt ix"><div class="bz fp l di"><div class="no np l"/></div></figure><ul class=""><li id="79a1" class="mv mw jg kx b ky kz lb lc le mx li my lm mz lq na nb nc nd bi translated">将 zip 文件从我的 Google Drive(通过可共享的链接)移动到在 Colab 环境中创建的目录中，然后解压缩。</li></ul><p id="687c" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq io bi translated">为了解决上述问题，我分别压缩了训练集和测试集，并通过使用<code class="fe nq nr ns nf b">gdown</code>和 Google Drive 的链接(当您在 Drive 的 UI 中单击 download shareable link)下载文件。然后，我将包含图像的文件夹解压到指定的目录。在最后一步，我删除了一个剩余的目录。</p><figure class="mq mr ms mt gt ix"><div class="bz fp l di"><div class="no np l"/></div></figure><h1 id="45a1" class="ls lt jg bd lu lv lw lx ly lz ma mb mc km md kn me kp mf kq mg ks mh kt mi mj bi translated">2.加载数据</h1><p id="85aa" class="pw-post-body-paragraph kv kw jg kx b ky mk kh la lb ml kk ld le mm lg lh li mn lk ll lm mo lo lp lq io bi translated">在这一部分，我加载并预处理数据(图像)。我将一步一步地描述这个过程:</p><ol class=""><li id="1116" class="mv mw jg kx b ky kz lb lc le mx li my lm mz lq nt nb nc nd bi translated">首先，我定义了一些参数和我想在图像上执行的转换(调整到 128x128，转换成张量和归一化)。这也是我可以进行图像放大(随机裁剪，剪切，旋转等)的步骤。).然而，由于这个特殊的问题是关于视频游戏图像的分类，我认为应用这些转换没有意义，因为图像将不再类似于原始截图。但是，如果您正在构建一个猫/狗分类器，并且没有真正大的数据集(即使您有)，这将是应用转换的地方。</li><li id="491f" class="mv mw jg kx b ky nu lb nv le nw li nx lm ny lq nt nb nc nd bi translated">我为训练/测试数据指定目录，并应用所选择的转换。</li><li id="e1a8" class="mv mw jg kx b ky nu lb nv le nw li nx lm ny lq nt nb nc nd bi translated">我从训练集中随机选择了一个索引子集来使用它们进行验证。我还创建了从给定索引(不是整个数据集)中采样图像的<code class="fe nq nr ns nf b">SubsetRandomSampler</code>。</li><li id="a110" class="mv mw jg kx b ky nu lb nv le nw li nx lm ny lq nt nb nc nd bi translated">我通过组合数据集和采样器来创建<code class="fe nq nr ns nf b">DataLoader</code>。在 GPU 上训练的情况下，我使用<code class="fe nq nr ns nf b">pin_memory = True</code>(推荐设置)。对于<code class="fe nq nr ns nf b">test_loader</code>,我也混洗数据集，否则，它将首先从一个类中取出所有观察值，然后从第二个类中取出所有观察值，而不进行任何混洗。在测试集的情况下，这实际上无关紧要。但是知道这个功能是很好的。</li></ol><figure class="mq mr ms mt gt ix"><div class="bz fp l di"><div class="no np l"/></div></figure><p id="8087" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq io bi translated">在下面的代码中，我检查了 10 张随机选择的图片。由于<code class="fe nq nr ns nf b">DataLoaders</code>作为迭代器工作，我首先使用<code class="fe nq nr ns nf b">iter()</code>，然后使用<code class="fe nq nr ns nf b">next()</code>来获得随机选择的图像及其标签(来自第一批)。</p><figure class="mq mr ms mt gt ix"><div class="bz fp l di"><div class="no np l"/></div></figure><figure class="mq mr ms mt gt ix gh gi paragraph-image"><div role="button" tabindex="0" class="iy iz di ja bf jb"><div class="gh gi nz"><img src="../Images/e0441a8f9a6a7b21eb4e49d56fc8e5c1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Pwsi_Hb56wFHTK8ZepTnLA.png"/></div></div></figure><h1 id="fe4e" class="ls lt jg bd lu lv lw lx ly lz ma mb mc km md kn me kp mf kq mg ks mh kt mi mj bi translated">3.CNN 架构</h1><p id="c30c" class="pw-post-body-paragraph kv kw jg kx b ky mk kh la lb ml kk ld le mm lg lh li mn lk ll lm mo lo lp lq io bi translated">我提出了两种定义神经网络结构的方法。第一种方法是构建一个继承自<code class="fe nq nr ns nf b">nn.Module</code>的类。第二个更类似于 Keras，我们创建了一系列的层。这里没有对错，完全看个人喜好。</p><p id="9679" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq io bi translated">在这两种方法中，我使用了相同的架构，所以在培训之前应该只使用一种。</p><h1 id="0e35" class="ls lt jg bd lu lv lw lx ly lz ma mb mc km md kn me kp mf kq mg ks mh kt mi mj bi translated">3.1.课堂教学方法</h1><p id="e2ff" class="pw-post-body-paragraph kv kw jg kx b ky mk kh la lb ml kk ld le mm lg lh li mn lk ll lm mo lo lp lq io bi translated">我定义了一个继承自<code class="fe nq nr ns nf b">nn.Module</code>的类，它与<code class="fe nq nr ns nf b">super().__init__()</code>结合创建了一个跟踪神经网络架构的类，并提供了各种方法和属性。需要注意的是，该类必须继承自<code class="fe nq nr ns nf b">nn.Module</code>。</p><p id="b1d1" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq io bi translated">该类必须包含两个方法:<code class="fe nq nr ns nf b">__init__</code>和<code class="fe nq nr ns nf b">forward</code>。</p><p id="092b" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq io bi translated">我会对每一个必需的方法做更多的解释:</p><ul class=""><li id="8f21" class="mv mw jg kx b ky kz lb lc le mx li my lm mz lq na nb nc nd bi translated"><code class="fe nq nr ns nf b">__init__</code> -用于定义类的属性，并在初始化时填充指定的值。一个规则是总是调用<code class="fe nq nr ns nf b">super()</code>方法来初始化父类。除此之外，我们可以定义所有的层，这些层具有一些要优化的参数(要调整的权重)。我们不需要定义激活函数，比如这里的<code class="fe nq nr ns nf b">relu</code>，因为给定相同的输入，它们将总是返回相同的输出。定义的层的顺序并不重要，因为这些纯粹是定义，而不是指定层如何连接的架构。</li><li id="43e5" class="mv mw jg kx b ky nu lb nv le nw li nx lm ny lq na nb nc nd bi translated"><code class="fe nq nr ns nf b">forward</code> -在这种方法中，我们定义了层之间的连接。我们指定它们连接的顺序，并最终返回网络的输出。另外，变量不一定要被称为<code class="fe nq nr ns nf b">x</code>，重要的是它以正确的顺序通过各层。</li></ul><figure class="mq mr ms mt gt ix"><div class="bz fp l di"><div class="no np l"/></div></figure><h1 id="5f70" class="ls lt jg bd lu lv lw lx ly lz ma mb mc km md kn me kp mf kq mg ks mh kt mi mj bi translated">3.2.顺序方法</h1><p id="6463" class="pw-post-body-paragraph kv kw jg kx b ky mk kh la lb ml kk ld le mm lg lh li mn lk ll lm mo lo lp lq io bi translated">对于那些使用过 Keras 的人来说,<code class="fe nq nr ns nf b">Sequential</code>方法可能很熟悉。我创建了一个<code class="fe nq nr ns nf b">OrderedDict</code>,按照执行的顺序指定了每一层。使用<code class="fe nq nr ns nf b">OrderedDict</code>的原因是我可以给这些层起一个有意义的名字。如果不这样做，它们的名字将是整数。</p><p id="5b6f" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq io bi translated">开始时，我定义了一个<code class="fe nq nr ns nf b">Flatten</code>类，它基本上将矩阵重新整形为一个长向量，就像 CNN 通常做的那样。<code class="fe nq nr ns nf b">OrderedDict</code>放在<code class="fe nq nr ns nf b">nn.Sequential</code>中，它定义了我们的模型。</p><figure class="mq mr ms mt gt ix"><div class="bz fp l di"><div class="no np l"/></div></figure><h1 id="4601" class="ls lt jg bd lu lv lw lx ly lz ma mb mc km md kn me kp mf kq mg ks mh kt mi mj bi translated">4.损失函数和优化器</h1><p id="94e4" class="pw-post-body-paragraph kv kw jg kx b ky mk kh la lb ml kk ld le mm lg lh li mn lk ll lm mo lo lp lq io bi translated">第一步是将模型转移到 Cuda，以防它将在 GPU 上训练。然后，我将二进制分类问题的损失函数和优化器指定为学习率为 0.01 的随机梯度下降。</p><h1 id="267e" class="ls lt jg bd lu lv lw lx ly lz ma mb mc km md kn me kp mf kq mg ks mh kt mi mj bi translated">5.训练网络</h1><p id="87ea" class="pw-post-body-paragraph kv kw jg kx b ky mk kh la lb ml kk ld le mm lg lh li mn lk ll lm mo lo lp lq io bi translated">网上已经有很多关于训练神经网络所需步骤的资料。我将只概述这些步骤:</p><ol class=""><li id="eda2" class="mv mw jg kx b ky kz lb lc le mx li my lm mz lq nt nb nc nd bi translated">正向通过网络(如<code class="fe nq nr ns nf b">forward()</code>方法中所述)</li><li id="8d1c" class="mv mw jg kx b ky nu lb nv le nw li nx lm ny lq nt nb nc nd bi translated">根据网络输出计算损耗</li><li id="b16b" class="mv mw jg kx b ky nu lb nv le nw li nx lm ny lq nt nb nc nd bi translated">用<code class="fe nq nr ns nf b">loss.backward()</code>反向通过网络计算梯度</li><li id="1509" class="mv mw jg kx b ky nu lb nv le nw li nx lm ny lq nt nb nc nd bi translated">通过使用优化器来更新权重</li></ol><p id="481d" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq io bi translated">还有其他一些事情值得一提:</p><ul class=""><li id="16e2" class="mv mw jg kx b ky kz lb lc le mx li my lm mz lq na nb nc nd bi translated"><code class="fe nq nr ns nf b">optimizer.zero_grad()</code> -当使用相同的参数进行多次反向传递时，梯度在累积。这就是为什么我们需要在每次向前传递时将梯度归零。</li><li id="8fec" class="mv mw jg kx b ky nu lb nv le nw li nx lm ny lq na nb nc nd bi translated">训练时，我们可能会使用辍学来防止过度适应。然而，对于预测/验证，我们想要使用整个网络，因此我们需要通过使用<code class="fe nq nr ns nf b">model.eval()</code>将丢失概率更改为 0(关闭它)。要返回训练模式，我们使用<code class="fe nq nr ns nf b">model.train()</code>。</li><li id="698e" class="mv mw jg kx b ky nu lb nv le nw li nx lm ny lq na nb nc nd bi translated"><code class="fe nq nr ns nf b">torch.no_grad()</code> -关闭验证渐变，节省内存和计算</li></ul><p id="4e55" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq io bi translated">为了有一个可重用的框架来训练 CNN，我将逻辑封装在一个函数中。我假设网络将在训练和验证损失的情况下被训练。当然，它可以进一步参数化，只有当参数不是<code class="fe nq nr ns nf b">None</code>时，才可以考虑验证集。不过对于这款笔记本的情况来说，相信这已经足够了。</p><figure class="mq mr ms mt gt ix"><div class="bz fp l di"><div class="no np l"/></div></figure><p id="05dc" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq io bi translated">那么训练模型就归结为:</p><figure class="mq mr ms mt gt ix"><div class="bz fp l di"><div class="no np l"/></div></figure><figure class="mq mr ms mt gt ix gh gi paragraph-image"><div role="button" tabindex="0" class="iy iz di ja bf jb"><div class="gh gi oa"><img src="../Images/66bafe03ebbd804b1862f78ada51b8ee.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*GlNiOij76VorYiALnirGfg.png"/></div></div></figure><p id="d0a5" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq io bi translated">我检查了显示培训/估价损失随时代演变的图表。我们的目标不仅是减少培训损失，也是减少验证损失。如果训练损失继续减少，而验证损失增加，我们将观察到过度拟合-模型将不能很好地概括训练期间没有看到的数据。在这种情况下，我们看到模型的损失在第 7 个历元之后(或者更早，取决于偏好)没有显著减少。</p><p id="0f4c" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq io bi translated">鉴于此，我将从第 7 纪元开始加载模型。通过保存所有的中间模型，我能够看到测试集的性能会是什么样子(以防万一，我想比较)。</p><h1 id="fe8b" class="ls lt jg bd lu lv lw lx ly lz ma mb mc km md kn me kp mf kq mg ks mh kt mi mj bi translated">6.评估测试集的结果</h1><p id="b5df" class="pw-post-body-paragraph kv kw jg kx b ky mk kh la lb ml kk ld le mm lg lh li mn lk ll lm mo lo lp lq io bi translated">在这一部分，我在测试集上评估网络的结果，<em class="ob">即</em>网络在训练期间没有见过的那个。我编写了一个与验证脚本类似的脚本，不同之处在于我存储的用于评估的指标数量。</p><figure class="mq mr ms mt gt ix"><div class="bz fp l di"><div class="no np l"/></div></figure><p id="759d" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq io bi translated">准确率 99%，甜！让我们来看一些更详细的统计数据:</p><ul class=""><li id="cc65" class="mv mw jg kx b ky kz lb lc le mx li my lm mz lq na nb nc nd bi translated">99.2%的召回率——这意味着从数据集中的所有 Wario 截图来看，该模型正确预测了其中的 99.2%。</li><li id="5f44" class="mv mw jg kx b ky nu lb nv le nw li nx lm ny lq na nb nc nd bi translated">99.3%的精确度——这意味着在所有的 Wario 预测中，99.3%实际上都是 Wario。</li><li id="8912" class="mv mw jg kx b ky nu lb nv le nw li nx lm ny lq na nb nc nd bi translated">99.25%的 F1 分数—没有明确的解释，因为 F1 分数是精确度和召回率的加权平均值。在类分布不均匀的情况下，F1 比精度更有用。就像在这种情况下，测试集中有相同数量的 Mario/Wario 类，准确度= F1 分数。</li></ul><p id="fc26" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq io bi translated">总的来说，该网络在图像分类方面做得非常出色。2000 张照片中只有 15 张分类错误。为了获得更多的洞察力，我们将在下面考察其中的一些。</p><figure class="mq mr ms mt gt ix gh gi paragraph-image"><div role="button" tabindex="0" class="iy iz di ja bf jb"><div class="gh gi oc"><img src="../Images/ddcc6201eb1dbbecade14b768afc8864.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*KVqCVMSdYE7KRqy7srfzOw.png"/></div></div></figure><p id="7d29" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq io bi translated">我不得不说，网络在这些图片上遇到麻烦并不奇怪。有些明显是来自游戏的过渡帧(地图和关卡之间或者屏幕之间加载屏幕)。没有办法从中推断出正确的游戏。其余的是地图或来自 Wario(第三张图片)的特定屏幕。这些游戏的地图非常相似，就像从等轴视图中看到的角色一样。</p><p id="b0c0" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq io bi translated">我不得不说，我对这个网络的表现和 PyTorch 总体上非常满意。它提供了很多可能性，并且非常具有 pythonic 风格。要了解更多关于 PyTorch 的基础知识，我会推荐你去 Udacity 的免费“PyTorch 深度学习简介”MOOC，你可以在这里找到<a class="ae lr" href="https://www.udacity.com/course/deep-learning-pytorch--ud188" rel="noopener ugc nofollow" target="_blank"/>。</p><p id="2685" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq io bi translated">如果你对这篇文章有任何反馈，请在评论中告诉我。一如既往，整个笔记本可以在我的<a class="ae lr" href="https://github.com/erykml/mario_vs_wario/blob/master/mario_vs_wario_pytorch.ipynb" rel="noopener ugc nofollow" target="_blank"> GitHub repo </a>上找到。</p></div></div>    
</body>
</html>