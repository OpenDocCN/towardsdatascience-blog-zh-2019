# 关于文本矢量化

> 原文：<https://towardsdatascience.com/the-magic-behind-embedding-models-part-1-974d539f21fd?source=collection_archive---------17----------------------->

## 将文本转换成数字的魔力

![](img/50120b1cace6741141d297200332fe68.png)

Image by [Artem Maltsev](https://unsplash.com/@art_maltsev) — Unsplash

这篇文章将带你了解文本矢量化的基础知识，即将文本转换成矢量(数字列表)。在本帖中，我们将展示单词包(BOW)及其风格:频率向量、一种热门编码(OHE)和术语频率/逆文档频率(TF/IDF)。

# 为什么要文本矢量化？

用数字表示文本有很多好处，主要是:

1.  计算机不理解文本以及单词和句子之间的关系，所以你需要一种用数字来表示这些单词的方法，这是计算机能够理解的。
2.  这种向量可以用在许多应用中，例如问题回答系统、推荐系统、情感分析、文本分类，并且它还使得搜索、返回同义词等更容易。

## **包话(鞠躬)**

BOW 是一种解析文档特征的技术。特征的含义是你可以用来做决定的特征和属性(买房子时，你会寻找一些特征，比如有多少个房间和它的位置)。文本的特征是语料库中有多少独特的词以及每个词的出现次数等。BOW 是一种特征提取技术，其输出是表示语料库中每个文档的向量空间。这个向量的长度(维度)对应于语料库中唯一单词的数量(没有重复，每个单词只出现一次)。BOW 模型有不同的风格，每个都扩展或修改了基本 BOW。接下来将讨论三个不同的向量:频率向量(计数向量)、一个热编码和术语频率/逆文档频率。

## **频率矢量**

这是最简单的编码技术，但在某些用例中仍然有效。简单地说，我们用每个单词在文档中出现的次数来填充文档向量。例如，假设我们的语料库有两个文档。第一个文档包含“**爱丽丝喜欢意大利面**”，第二个文档包含“**爱丽丝喜欢鱼。爱丽丝和鲍勃是朋友。为了表示计数，我们可以使用表格或 JavaScript 对象符号(JSON ),如下所示:**

```
 Table representation:+-------+-------+-------+-------+------+-----+-----+-----+---------+
|       | Alice | loves | pasta | fish | and | Bob | are | friends |
+-------+-------+-------+-------+------+-----+-----+-----+---------+
|  doc1 |   1   |   1   |   1   |   0  |  0  |  0  |  0  |    0    |
+-------+-------+-------+-------+------+-----+-----+-----+---------+
|  doc2 |   2   |   1   |   0   |   1  |  1  |  1  |  1  |    1    |  
+-------+-------+-------+-------+------+-----+-----+-----+---------+JSON representation:doc1: {"Alice":1, "loves":1, "pasta":1}
doc2: {"Alice":2, "loves":1, "fish":1, "and":1, "Bob":1,                "are":1, "friends":1}You can combine them: {"Alice":3, "loves":2, "pasta":1, "fish":1, "and":1, "Bob":1, "are":1, "friends":1}
```

如你所见，我们的语料库中有 8 个独特的单词。因此，我们的向量大小为 8。为了表示文档 1，我们只需取表中的第一行[1，1，1，0，0，0，0]。这个向量有助于比较文档。虽然这种技术在一些用例中是有帮助的，但是它具有一些限制，例如:不保持文档结构(不保持单词的顺序，而是仅仅计数)，并且它还具有稀疏性问题(向量中的大多数值都是零，这增加了时间复杂度并且增加了模型的偏差，以及停止词(例如‘and’，‘or’，‘is’，‘the’等)。)出现的次数比这句话多很多倍。因此，我们使用一些技术，如**词干化和词汇化**。我们还删除了停用词和在整个语料库中只出现过几次的罕见词。

## **一个热编码**

正如在频率向量中所讨论的，频繁出现的标记比较少出现的标记具有更大的幅度。因此，OHE 向量提供了一个布尔向量作为这个问题的解决方案，我们只用 1 和 0 填充向量。如果单词出现在文档中，我们放置 1(1 而不是计数)，否则放置 0。文档 2 可以表示为[1，1，0，1，1，1，1，1，1]。

一种热编码也可以用来表示单词。1 代表我们想要表示的单词，0 代表其余的单词。单词“Alice”可以表示为[1，0，0，0，0，0，0，0]，或者我们也可以添加计数，因此“Alice”可以表示为[3，0，0，0，0，0，0，0](将在本博客的第 2 部分详细讨论这一点)。

## **词频/逆文档频**

到目前为止，我们一直将每个文档视为一个独立的实体，而不考虑语料库的上下文。TF/IDF 是一种常见的技术，用于根据语料库上下文对文档中的标记频率进行归一化。TF/ID 代表两件事:

**1。术语频率** *tf(t，d):* 术语(t)在文档(d)中出现的频率。如果我们用`*f(t, d)*`来表示原始计数，那么最简单的 *tf* 方案就是`*tf(t, d) = f(t, d)*` (下面讨论的其他技术)，让我们用`*len(d)*`来表示文档 d 中出现的总字数。例如，为了排列与查询“蓝天”最相关的文档，我们计算每个单词在每个文档中出现的次数。然而，由于每个文档的大小不同，所以比较一个单词在 10 个单词的文档和 1M 单词的文档中出现的次数是不公平的。因此，我们缩放 *tf* 以防止长文档的偏差，如下 *:*

`***tf(t, d) = f(t, d) / len(d)***`

*tf* 调整和减少文档中最大重复字数**计数**的其他方法:

*   布尔频率:如果 *t* 出现在 *d* 中，则为`*tf(t, d) = 1*`，否则为 0
*   根据文件长度调整的词频:`*tf(t, d) = f(t, d)/len(d)*`
*   对数标度频率:`*tf(t, d) = log( 1 + f(t, d))*`
*   增强频率:`*tf(t, d) = 1 * f(t, d) / m*`，其中 m 是在 *d* 中出现次数最多的单词

**2)逆文档频率:**衡量一个术语的重要程度。IDF 减少出现在不同文档中的常用词的**值**。在我们前面的例子“蓝天”中，单词“the”是一个常用词，因此术语“频率”倾向于错误地强调具有较少值的重复单词的文档，例如“the”。作为一个解决方案，我们计算了文档总数 *(D)* 除以 *n* 的 *log()* ，n 是带有 *t* 的文档出现在:

`***idf(t, D) = log(D / n)***`

最后，TF/IDF 可以计算为:

`**tf-idf(t, d, D) = t(t, d) . idf(t, D)**`

最后，我们只是在向量中添加 TF-IDF 分数，而不是频率计数或 OHE。

## 资源:

*   [Tony oje da、Rebecca Bilbro、Benjamin Bengfort 利用 Python 进行应用文本分析](https://www.oreilly.com/library/view/applied-text-analysis/9781491963036/ch04.html)
*   [维基百科:TF-IDF](https://en.wikipedia.org/wiki/Tf%E2%80%93idf#:~:targetText=In%20information%20retrieval%2C%20tf%E2%80%93idf,in%20a%20collection%20or%20corpus.)
*   [维基百科:词汇袋](https://en.wikipedia.org/wiki/Bag-of-words_model)