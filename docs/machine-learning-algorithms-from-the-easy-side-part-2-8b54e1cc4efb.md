# 简单的机器学习算法(第二部分)

> 原文：<https://towardsdatascience.com/machine-learning-algorithms-from-the-easy-side-part-2-8b54e1cc4efb?source=collection_archive---------15----------------------->

在[第一部分](https://medium.com/@itembe2a/machine-learning-algorithms-from-the-easy-side-part-1-14f2dee005ab?source=friends_link&sk=629100d1f7b0ab7bf92d612409399e9c)中，我们解释了什么是 ML 以及一些机器学习算法。在这个新的部分中，我们将更深入地了解更多的方法，这些方法可以帮助我们教会机器完成一项任务。

**SVM(支持向量机)**

现在我们看到另一种方法来思考更多。在这个例子中，我们有三个红色和三个灰色的点被一条以上的线分开。

![](img/6cc98f149411946ecfae9a0b1f9f6735.png)

现在我们将研究哪条线最符合数据。

![](img/e63b1bf10709cb42286c731890f60c3c.png)

我们可以看到绿线离点很近，而粉线离点没那么近。粉红色的线似乎离圆点足够远，因此能够很好地将它们分开。粉线在这里赢过绿线。从对数回归来看，我们必须解释如何找到最适合这些点的直线。我们应该计算点和线之间的距离。这里我们可以看到每个点到直线的距离，我们发现这些距离下的最小值是各个点离直线的距离。

![](img/e135f2a65e262ae87912369da65f5a3f.png)

通过只看六个距离中的最小值，我们可以忽略那些离直线非常远的点。

![](img/90d9b0648bdaa917efe8b1c35fa9afa6.png)

由此，我们可以得出结论，粉线可以更好地分离数据，因为粉线的最小值大于绿线的最小值。这里的目标是通过使用前面方法中的梯度下降来最大化距离。这种算法被称为支持向量机(SVM)。这里的支持向量是靠近超平面的点。粉色线是分隔点的超平面。SVM 可用于分类任务。

![](img/3772ff1738dc86f5307d37c729b81c4e.png)

**神经网络**

这里我们将继续我们的肿瘤数据。现在，数据排列如下图所示。这是一个新型号。

![](img/c454113a94dcd2ef995b470f885e02bc.png)

有时数据可以这样排列:

![](img/e31d708da92532f8679510cb9194c7aa.png)

不幸的是，在这种情况下，我们无法使用一条线来分隔数据。

![](img/a165f4eb7488577266fbe34f27145bd4.png)

我们可以用多条线或一个圆来分隔数据。

![](img/e91eb939f368231f8d4939f513d20da6.png)

通过使用梯度下降，我们可以最小化误差函数并找到这些线。这种方法叫做神经网络。这个名字来源于人类大脑如何工作的灵感，尤其是在多任务处理时。例如，一个人可以一边走在街上，一边操作他的手机(这可能是危险的)。

现在，假设我们有一台功率较小的计算机，无法同时执行多项任务。例如，如果我们想知道一个新数据是否属于恶性肿瘤类型，我们必须将大任务分成许多小任务。第一个任务或问题是:新数据是否在紫线之上？

![](img/9334eb0ac93081c04b32659a32f3b0cc.png)

答案是肯定的。下一个问题是:这些新数据是否越过了绿线？

![](img/10c292967c945c3cf974307cc6a83c6d.png)

答案也是肯定的。在两个答案都是肯定的情况下，我们可以断定新数据是恶性肿瘤。

![](img/fb9bad68a04495e643719cfef6e3e25e.png)

因此，我们可以用“是”或“否”来完成其他区域

![](img/a73528ee60264c5444a7341f35d5e60a.png)

所以右下角的区域会有 1-否/2-是。在左上方区域，我们会有 1-是/2-否，最后在左下方区域，我们会有 1-否/2-否。现在我们可以在一个图表中用节点表示任务，如下所示:

![](img/d10732f11b5e8554123f2bdb84cf1753.png)

对于这个带有绿色节点的小图，我们提出这样一个问题，带有坐标的数据(重现梯度=70%，增长速度梯度=20%)是否在绿线之上，答案是否定的。对另一个图进行相同的过程，其中另一个问题，带有坐标的数据(重现梯度=70%，增长速度梯度=20%)是否在紫线之上，答案是否定的。

![](img/a2f7284eb31167a24157ad33f52b8cca.png)

对于下一个问题，我们只是将上面两个图的输出合并到一个新的节点。

![](img/646c4b2ef21db05dfe2ba1b3c11bfb5a.png)

这两个值的组合是使用 AND 逻辑完成的。让我们看看这个和运算符。

![](img/2aca111ab521b43e413244f3185b67e4.png)

它有两个输入，Yes 和 No(或数字 0 和 1 ),有一个输出。如果我们输入 Yes 和 No(或 1 和 0)，输出将是 No(或 0)。如果输入为 No 和 No(或 0 和 0)，则输出为 No(或 0)。

新节点与两个小图的组合称为神经网络。在神经网络中，我们首先有一个输入层，我们输入递归梯度=70%，增长速度梯度=20%。然后，输入层中关于梯度的信息被转发到中间层。从中间层的节点得到答案“否”和“是”。这些然后被转发到输出层，并且将被与逻辑评估，并且神经网络的与逻辑或的输出是“否”

![](img/4ca251d2f3940a4a124c9ece432d1643.png)

可以向该网络添加额外的层和节点来解决更复杂的任务。

![](img/d7ea63b9e437d8d00c3b29b7a3576a94.png)

这是一个强大而伟大的机器学习算法。它被用于许多项目，如驾驶辅助系统、手写识别、使用 TNA(热中子分析)检测行李箱中的炸弹，也许在未来还会有读心术等等。

**内核方法**

在这个新的例子中，我们将看到一个新的方法，可以将线性不可分的数据转换成线性可分的数据。我们有如下几点安排。

![](img/7c34b3e031fe9154d190beed648a7f29.png)

在这些情况下，不可能用一条线来分隔这些点。

![](img/3443580719ed9460a9b0e8104348fa43.png)

在这里，我们必须以不同的方式进行。我们可以想象这些点显示在一个网格中，然后我们用一条曲线将它们分开。

![](img/24ff760cd841b9e252fa7028c6396b84.png)

同样，我们可以想象这些点在空间中，并用一个平面来分隔它们。为此，我们添加了一个额外的轴，z 轴。然后，通过将 2D 中的点的坐标(x，y)与 3D 中的坐标(x，y，z)进行匹配，将两个红点沿 z 轴移动，其中 z 可以是依赖于 x 或 y 的方程，如 x y，x+y，…随后，我们将能够使用平面图来分离这些点。

![](img/0bbcaeb2cb60540ddc58af86bd7984e9.png)

这两个招数是一样的。这种方法主要用于支持向量机，称为核技巧。我们将继续这里的点排列像在(a)和曲线作为分隔符。为了分离这些点，我们将使用一些等式来帮助我们分离这些点。我们有 xy，x+y，x，x。

这些点的坐标被应用到方程式中。输出将为我们提供更多关于方程或函数如何分离这些点的信息。我们使用一个表格来显示结果。

![](img/3073e43409bdf4069d00361e71711267.png)

第一行对应于点的坐标(从左到右)，第一列包含方程式。我们可以在表格中看到所有的结果。例如，对于 x 中的(4，0)，这使得 5x5x5=125，对于 x+y 中的(1，3)，我们有 1+3=4。

现在的问题是，哪个方程把点分开。首先我们有 x+y，我们可以看到两个蓝点和两个红点的坐标有相同的结果，4。因此，方程不能分离点。对于 x 和 x，可以看出蓝色点和红色点有不同的结果，并且红色点的值在蓝色点的值之间。因此，这些方程也不能分离这些点。最后，我们有 xy，注意蓝色点有相同的值 0，红色点有相同的值 3。该函数可以分离这些点，因为它为红点提供了一个值，为蓝点提供了另一个值。

蓝点的 xy=0，红点的 xy=3。我们知道 1 和 2 在 0 和 3 之间，所以 1 和 2 把 0 和 3 分开。这给出了方程 xy=1 和 xy=2，从而得到函数 y=1/x 和 y=2/x。

![](img/fc373eedc2da597fcac8a7453f07c24e.png)

由此我们得出结论，函数 1/x(或 2/x)分隔了平面中的点。

![](img/0bd584820c7f93896ddd9d072ae7cff6.png)

利用该方法，非线性数据可以被映射到更高维(n-dim)空间。在这个新的空间中，可以使用平面或曲线轻松地分离数据。该方法可用于手写识别、3D 重建、地质统计学等等。

**结论**

在本文中，分为两部分，我们已经看到了机器学习中使用的几个重要算法。目标是使用各种示例以简单的方式向他们解释算法。现在我们到达了“轻松潜水”的终点。

![](img/6aebf2d51df6f376dbf4ddc416c9315a.png)

所以祝你在机器学习的美好世界里玩得开心。

**一些不错的参考资料**

[1]伊恩·古德费勒，约舒阿·本吉奥和亚伦·库维尔。深度学习。ISBN 9780262035613。网址 https://mitpress.mit.edu/books/deep-learning。

[2]克里斯托弗·h·兰伯特。计算机视觉中的核方法。计算机图形和视觉的基础和趋势。网址[http://www.nowpublishers.com/article/Details/CGV-027](http://www.nowpublishers.com/article/Details/CGV-027)。