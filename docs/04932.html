<html>
<head>
<title>The Complete Guide to Decision Trees</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">决策树完全指南</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/the-complete-guide-to-decision-trees-17a874301448?source=collection_archive---------15-----------------------#2019-07-25">https://towardsdatascience.com/the-complete-guide-to-decision-trees-17a874301448?source=collection_archive---------15-----------------------#2019-07-25</a></blockquote><div><div class="fc ij ik il im in"/><div class="io ip iq ir is"><div class=""/><div class=""><h2 id="17ab" class="pw-subtitle-paragraph js iu iv bd b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj dk translated">决策树的完整介绍，如何使用它们进行回归和分类，以及如何在项目设置中实现算法</h2></div><figure class="kl km kn ko gt kp gh gi paragraph-image"><div class="gh gi kk"><img src="../Images/186d04a6d9e3eb70f1d0d930c4fb2623.png" data-original-src="https://miro.medium.com/v2/resize:fit:1154/format:webp/1*yF3Unc48F81ATxrTmaas0g.jpeg"/></div><figcaption class="ks kt gj gh gi ku kv bd b be z dk">They are… don’t even try something else</figcaption></figure><p id="273f" class="pw-post-body-paragraph kw kx iv ky b kz la jw lb lc ld jz le lf lg lh li lj lk ll lm ln lo lp lq lr io bi translated">基于树的方法可用于回归或分类。它们包括将预测空间分割成许多简单的区域。分割规则的集合可以总结为一棵树，因此被命名为<strong class="ky iw">决策树</strong>方法。</p><p id="7be5" class="pw-post-body-paragraph kw kx iv ky b kz la jw lb lc ld jz le lf lg lh li lj lk ll lm ln lo lp lq lr io bi translated">单个决策树往往不如<a class="ae ls" rel="noopener" target="_blank" href="/linear-regression-understanding-the-theory-7e53ac2831b5">线性回归</a>、<a class="ae ls" href="https://becominghuman.ai/classification-part-1-intro-to-logistic-regression-f6258791d309" rel="noopener ugc nofollow" target="_blank">逻辑回归</a>、<a class="ae ls" rel="noopener" target="_blank" href="/classification-part-2-linear-discriminant-analysis-ea60c45b9ee5"> LDA </a>等性能好。但是，通过引入 bagging、随机森林和 boosting，它可以显著提高预测的准确性，但会损失一些解释能力。</p><p id="6e93" class="pw-post-body-paragraph kw kx iv ky b kz la jw lb lc ld jz le lf lg lh li lj lk ll lm ln lo lp lq lr io bi translated">在这篇文章中，我们介绍了你需要知道的关于决策树、装袋、随机森林和 boosting 的一切。这将是一个漫长的阅读，但它将是值得的！</p><blockquote class="lt"><p id="d4b3" class="lu lv iv bd lw lx ly lz ma mb mc lr dk translated">关于机器学习、深度学习和人工智能的实践视频教程，请查看我的<a class="ae ls" href="https://www.youtube.com/channel/UC-0lpiwlftqwC7znCcF83qg?view_as=subscriber" rel="noopener ugc nofollow" target="_blank"> YouTube 频道</a>。</p></blockquote><figure class="md me mf mg mh kp"><div class="bz fp l di"><div class="mi mj l"/></div><figcaption class="ks kt gj gh gi ku kv bd b be z dk">Just Bob Ross painting a tree</figcaption></figure><h1 id="39ab" class="mk ml iv bd mm mn mo mp mq mr ms mt mu kb mv kc mw ke mx kf my kh mz ki na nb bi translated">决策树的基础</h1><h2 id="32e0" class="nc ml iv bd mm nd ne dn mq nf ng dp mu lf nh ni mw lj nj nk my ln nl nm na nn bi translated">回归树</h2><p id="0ad1" class="pw-post-body-paragraph kw kx iv ky b kz no jw lb lc np jz le lf nq lh li lj nr ll lm ln ns lp lq lr io bi translated">在进入理论之前，我们需要一些基本的术语。</p><p id="e46f" class="pw-post-body-paragraph kw kx iv ky b kz la jw lb lc ld jz le lf lg lh li lj lk ll lm ln lo lp lq lr io bi translated">树是倒着画的。最后的区域被称为<em class="nt">叶。</em>树内发生分裂的点是一个<em class="nt">区间节点</em>。最后，连接节点的线段是<em class="nt">分支</em>。</p><figure class="kl km kn ko gt kp gh gi paragraph-image"><div role="button" tabindex="0" class="nv nw di nx bf ny"><div class="gh gi nu"><img src="../Images/347c843a92a67de1cf7c7b0ec8ebb819.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Sn0qSjCTrnQZUNG56gx5gA.png"/></div></div><figcaption class="ks kt gj gh gi ku kv bd b be z dk">Decision tree schematic</figcaption></figure><p id="b4ef" class="pw-post-body-paragraph kw kx iv ky b kz la jw lb lc ld jz le lf lg lh li lj lk ll lm ln lo lp lq lr io bi translated">要创建回归树，请执行以下操作:</p><ol class=""><li id="b3b8" class="nz oa iv ky b kz la lc ld lf ob lj oc ln od lr oe of og oh bi translated">将预测器空间划分为<em class="nt"> J </em>个不同且不重叠的区域</li><li id="0e89" class="nz oa iv ky b kz oi lc oj lf ok lj ol ln om lr oe of og oh bi translated">对于落在一个区域中的每个观察值，预测该区域中响应值的平均值</li></ol><p id="e7e2" class="pw-post-body-paragraph kw kx iv ky b kz la jw lb lc ld jz le lf lg lh li lj lk ll lm ln lo lp lq lr io bi translated">每个区域被分割以最小化 RSS。为此，需要一种<strong class="ky iw">自顶向下的贪婪方法</strong>，也称为<em class="nt">递归二进制分裂</em>。</p><p id="6f01" class="pw-post-body-paragraph kw kx iv ky b kz la jw lb lc ld jz le lf lg lh li lj lk ll lm ln lo lp lq lr io bi translated">为什么自上而下？</p><p id="95da" class="pw-post-body-paragraph kw kx iv ky b kz la jw lb lc ld jz le lf lg lh li lj lk ll lm ln lo lp lq lr io bi translated">因为在第一次分裂之前，所有观测值都在单个区域中。</p><p id="bf58" class="pw-post-body-paragraph kw kx iv ky b kz la jw lb lc ld jz le lf lg lh li lj lk ll lm ln lo lp lq lr io bi translated">为什么是贪婪的方法？</p><p id="5dd5" class="pw-post-body-paragraph kw kx iv ky b kz la jw lb lc ld jz le lf lg lh li lj lk ll lm ln lo lp lq lr io bi translated">因为最佳分割发生在特定步骤，而不是向前看并进行分割，这将导致对未来步骤的更好预测。</p><p id="159f" class="pw-post-body-paragraph kw kx iv ky b kz la jw lb lc ld jz le lf lg lh li lj lk ll lm ln lo lp lq lr io bi translated">数学上，我们将这对半平面定义为:</p><figure class="kl km kn ko gt kp gh gi paragraph-image"><div role="button" tabindex="0" class="nv nw di nx bf ny"><div class="gh gi on"><img src="../Images/d0578d80a948bd786e8ef1f080b55be1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*924APFCk97K6xQmdA2gLaA.png"/></div></div></figure><p id="c7f5" class="pw-post-body-paragraph kw kx iv ky b kz la jw lb lc ld jz le lf lg lh li lj lk ll lm ln lo lp lq lr io bi translated">并且我们寻求<em class="nt"> j </em>和<em class="nt"> s </em>来最小化:</p><figure class="kl km kn ko gt kp gh gi paragraph-image"><div role="button" tabindex="0" class="nv nw di nx bf ny"><div class="gh gi on"><img src="../Images/53dbde0f020a3dcc208903600858f5d4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*W5SX4T8aK6Zb9oAtt44Few.png"/></div></div></figure><p id="015c" class="pw-post-body-paragraph kw kx iv ky b kz la jw lb lc ld jz le lf lg lh li lj lk ll lm ln lo lp lq lr io bi translated">但是，这可能会导致过度拟合。修剪树将产生一个更小的子树，我们可以用交叉验证来验证它。</p><figure class="kl km kn ko gt kp gh gi paragraph-image"><div role="button" tabindex="0" class="nv nw di nx bf ny"><div class="gh gi oo"><img src="../Images/90b2db105664cd3bdec9d2a87afae535.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ZESO9xDGYUAZ3SA5QTlHNg.png"/></div></div><figcaption class="ks kt gj gh gi ku kv bd b be z dk">Schematic of an unpruned tree</figcaption></figure><h2 id="a999" class="nc ml iv bd mm nd ne dn mq nf ng dp mu lf nh ni mw lj nj nk my ln nl nm na nn bi translated">分类树</h2><p id="f67e" class="pw-post-body-paragraph kw kx iv ky b kz no jw lb lc np jz le lf nq lh li lj nr ll lm ln ns lp lq lr io bi translated">分类树与回归树非常相似。但是，我们不能使用响应的平均值，所以我们现在预测一个区域中最常出现的类。当然，RSS 不能作为评判标准。相反，每次分割都是为了最小化<strong class="ky iw">分类错误率</strong>。</p><p id="2112" class="pw-post-body-paragraph kw kx iv ky b kz la jw lb lc ld jz le lf lg lh li lj lk ll lm ln lo lp lq lr io bi translated">分类错误率只是不属于最常见类别的区域中训练观察值的分数。</p><figure class="kl km kn ko gt kp gh gi paragraph-image"><div role="button" tabindex="0" class="nv nw di nx bf ny"><div class="gh gi on"><img src="../Images/118bb8c54db58473bc1ea75d85e2f906.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*x4KfFYJweAXZzDZx9XcCnA.png"/></div></div><figcaption class="ks kt gj gh gi ku kv bd b be z dk">Classification error rate</figcaption></figure><p id="f42e" class="pw-post-body-paragraph kw kx iv ky b kz la jw lb lc ld jz le lf lg lh li lj lk ll lm ln lo lp lq lr io bi translated">不幸的是，这对于植树来说不够灵敏。在实践中，还使用了另外两种方法。</p><p id="9ca4" class="pw-post-body-paragraph kw kx iv ky b kz la jw lb lc ld jz le lf lg lh li lj lk ll lm ln lo lp lq lr io bi translated">还有<strong class="ky iw">基尼指数</strong>:</p><figure class="kl km kn ko gt kp gh gi paragraph-image"><div role="button" tabindex="0" class="nv nw di nx bf ny"><div class="gh gi on"><img src="../Images/079133c269c3271e9ae7963e18326fc4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*a7K4aU1g1DwVZW3kL8mOPQ.png"/></div></div><figcaption class="ks kt gj gh gi ku kv bd b be z dk">Gini index</figcaption></figure><p id="4097" class="pw-post-body-paragraph kw kx iv ky b kz la jw lb lc ld jz le lf lg lh li lj lk ll lm ln lo lp lq lr io bi translated">这是对所有类别的总方差的度量。正如你所看到的，如果比例接近 0 或 1，基尼指数就会很小，所以它是一个很好的衡量<strong class="ky iw">节点纯度</strong>的指标。</p><p id="0f74" class="pw-post-body-paragraph kw kx iv ky b kz la jw lb lc ld jz le lf lg lh li lj lk ll lm ln lo lp lq lr io bi translated">类似的基本原理也适用于另一种叫做<strong class="ky iw">交叉熵</strong>的方法:</p><figure class="kl km kn ko gt kp gh gi paragraph-image"><div role="button" tabindex="0" class="nv nw di nx bf ny"><div class="gh gi on"><img src="../Images/e43c76c7bbe884ba94748913e9f06297.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*1tWQOdP85CpcWTKWIMBtpQ.png"/></div></div><figcaption class="ks kt gj gh gi ku kv bd b be z dk">Cross-entropy</figcaption></figure><p id="f738" class="pw-post-body-paragraph kw kx iv ky b kz la jw lb lc ld jz le lf lg lh li lj lk ll lm ln lo lp lq lr io bi translated">既然我们已经看到了基本决策树是如何工作的，那么让我们来看看如何提高它的性能！</p><h1 id="9912" class="mk ml iv bd mm mn mo mp mq mr ms mt mu kb mv kc mw ke mx kf my kh mz ki na nb bi translated">装袋、随机成林、助推</h1><h2 id="f570" class="nc ml iv bd mm nd ne dn mq nf ng dp mu lf nh ni mw lj nj nk my ln nl nm na nn bi translated">制袋材料</h2><p id="517b" class="pw-post-body-paragraph kw kx iv ky b kz no jw lb lc np jz le lf nq lh li lj nr ll lm ln ns lp lq lr io bi translated">我们知道 bootstrap 可以计算任何感兴趣的量的标准差。对于决策树来说，方差非常大。因此，通过 bootstrap aggregation 或<strong class="ky iw"> bagging </strong>，我们可以减少方差并提高决策树的性能。</p><p id="a34e" class="pw-post-body-paragraph kw kx iv ky b kz la jw lb lc ld jz le lf lg lh li lj lk ll lm ln lo lp lq lr io bi translated">装袋包括从数据集中重复提取样本。这产生了<em class="nt"> B </em>不同的引导训练集。然后，我们对所有自举训练集进行训练，以获得每个集的预测，并对这些预测进行平均。</p><p id="34eb" class="pw-post-body-paragraph kw kx iv ky b kz la jw lb lc ld jz le lf lg lh li lj lk ll lm ln lo lp lq lr io bi translated">数学上，平均预测是:</p><figure class="kl km kn ko gt kp gh gi paragraph-image"><div role="button" tabindex="0" class="nv nw di nx bf ny"><div class="gh gi on"><img src="../Images/97eb2b85ad848a6a99d44ed6543579b4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*PjktOnIB270YeVUPymD2kA.png"/></div></div></figure><p id="6a7b" class="pw-post-body-paragraph kw kx iv ky b kz la jw lb lc ld jz le lf lg lh li lj lk ll lm ln lo lp lq lr io bi translated">将此应用于决策树，这意味着我们可以构建大量具有高方差和低偏差的树。然后，我们可以对他们的预测进行平均，以减少方差，从而提高决策树的性能。</p><h2 id="cd7b" class="nc ml iv bd mm nd ne dn mq nf ng dp mu lf nh ni mw lj nj nk my ln nl nm na nn bi translated">随机森林</h2><p id="29c9" class="pw-post-body-paragraph kw kx iv ky b kz no jw lb lc np jz le lf nq lh li lj nr ll lm ln ns lp lq lr io bi translated">随机森林通过一个小调整提供了对袋装树的改进，这个小调整就是<em class="nt">去关联</em>树。</p><p id="783a" class="pw-post-body-paragraph kw kx iv ky b kz la jw lb lc ld jz le lf lg lh li lj lk ll lm ln lo lp lq lr io bi translated">像装袋一样，建立多个决策树。然而，在每次分割时，从所有<em class="nt"> p </em>预测值中选择一个随机样本<em class="nt"> m </em>预测值。分割只允许使用一个<em class="nt"> m </em>预测值，通常:</p><figure class="kl km kn ko gt kp gh gi paragraph-image"><div class="gh gi op"><img src="../Images/9590328b830a46bff907140bc560dc38.png" data-original-src="https://miro.medium.com/v2/resize:fit:1080/format:webp/1*py3JZV7TQuxIc2tfT7-shA.png"/></div></figure><p id="54e9" class="pw-post-body-paragraph kw kx iv ky b kz la jw lb lc ld jz le lf lg lh li lj lk ll lm ln lo lp lq lr io bi translated">换句话说，在每次分割时，不允许算法考虑大多数可用的预测值！</p><p id="848e" class="pw-post-body-paragraph kw kx iv ky b kz la jw lb lc ld jz le lf lg lh li lj lk ll lm ln lo lp lq lr io bi translated">为什么？</p><p id="5dfc" class="pw-post-body-paragraph kw kx iv ky b kz la jw lb lc ld jz le lf lg lh li lj lk ll lm ln lo lp lq lr io bi translated">假设数据集中有一个非常强的预测因子，以及其他中等强度的预测因子。然后在套袋树的采集中，他们都会在顶裂中使用这个强预测器。因此，所有装袋的树将非常相似，平均它们的预测不会减少方差，因为预测将高度相关。</p><p id="8841" class="pw-post-body-paragraph kw kx iv ky b kz la jw lb lc ld jz le lf lg lh li lj lk ll lm ln lo lp lq lr io bi translated">随机森林通过强制每次分割只考虑预测子的子集来克服这个问题，这有效地消除了树的<em class="nt">相关性</em>。</p><p id="34bd" class="pw-post-body-paragraph kw kx iv ky b kz la jw lb lc ld jz le lf lg lh li lj lk ll lm ln lo lp lq lr io bi translated">当然，如果<em class="nt"> m </em>等于<em class="nt"> p </em>，那么就跟装袋一样。通常情况下，<em class="nt"> p </em>的平方根给出了如下所示的最佳结果。</p><figure class="kl km kn ko gt kp gh gi paragraph-image"><div role="button" tabindex="0" class="nv nw di nx bf ny"><div class="gh gi oq"><img src="../Images/3bd067c85c6f03eed2c0b188a34b47c7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*5rcQnqiM2J_qmOa89HN1Rg.png"/></div></div><figcaption class="ks kt gj gh gi ku kv bd b be z dk">Classification error as a function of the number of trees. Each line represents the number of predictors available at each split.</figcaption></figure><h2 id="46e4" class="nc ml iv bd mm nd ne dn mq nf ng dp mu lf nh ni mw lj nj nk my ln nl nm na nn bi translated">助推</h2><p id="11cd" class="pw-post-body-paragraph kw kx iv ky b kz no jw lb lc np jz le lf nq lh li lj nr ll lm ln ns lp lq lr io bi translated">Boosting 的工作方式与 bagging 类似，但树是按顺序生长的:每棵树都使用来自先前生长的树的信息。</p><p id="ad89" class="pw-post-body-paragraph kw kx iv ky b kz la jw lb lc ld jz le lf lg lh li lj lk ll lm ln lo lp lq lr io bi translated">这意味着算法学习<em class="nt">很慢</em>。每棵树都适合模型的残差，而不是目标变量。因此，每棵树都很小，在表现不好的地方会慢慢改善预测。</p><p id="53a7" class="pw-post-body-paragraph kw kx iv ky b kz la jw lb lc ld jz le lf lg lh li lj lk ll lm ln lo lp lq lr io bi translated">升压有三个调整参数:</p><p id="e4b4" class="pw-post-body-paragraph kw kx iv ky b kz la jw lb lc ld jz le lf lg lh li lj lk ll lm ln lo lp lq lr io bi translated">1.树的数量(<strong class="ky iw"> <em class="nt"> B </em> </strong>):与套袋和随机森林不同，如果<em class="nt"> B </em>太大，boosting 可能会溢出。使用交叉验证来选择正确的树的数量。</p><p id="9588" class="pw-post-body-paragraph kw kx iv ky b kz la jw lb lc ld jz le lf lg lh li lj lk ll lm ln lo lp lq lr io bi translated">2.收缩参数(<strong class="ky iw"> <em class="nt"> alpha </em> </strong>):控制 boosting 学习速率的小正数。它通常设置为 0.01 或 0.001。</p><p id="52eb" class="pw-post-body-paragraph kw kx iv ky b kz la jw lb lc ld jz le lf lg lh li lj lk ll lm ln lo lp lq lr io bi translated">3.每棵树的分裂数(<strong class="ky iw"> <em class="nt"> d </em> </strong>):控制增强整体的复杂度。通常，单个拆分(<em class="nt"> d </em> = 1)效果很好。它也被称为<strong class="ky iw"><em class="nt"/></strong><em class="nt">。</em></p><figure class="kl km kn ko gt kp gh gi paragraph-image"><div role="button" tabindex="0" class="nv nw di nx bf ny"><div class="gh gi or"><img src="../Images/adf1732e268fef1fd521dab46842f780.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*NviMtps1tigoNnRNep7MBg.png"/></div></div><figcaption class="ks kt gj gh gi ku kv bd b be z dk">Classification error as a function of the number of trees. Each line represents a different interaction depth.</figcaption></figure><p id="8f4b" class="pw-post-body-paragraph kw kx iv ky b kz la jw lb lc ld jz le lf lg lh li lj lk ll lm ln lo lp lq lr io bi translated">正如你在上面看到的，交互深度为 1 似乎给出了最好的结果。</p><h1 id="1a81" class="mk ml iv bd mm mn mo mp mq mr ms mt mu kb mv kc mw ke mx kf my kh mz ki na nb bi translated">项目</h1><p id="8b84" class="pw-post-body-paragraph kw kx iv ky b kz no jw lb lc np jz le lf nq lh li lj nr ll lm ln ns lp lq lr io bi translated">现在，让我们应用我们所学的知识来预测乳腺癌。许多关于乳腺癌的数据集包含关于肿瘤的信息。然而，我很幸运地找到了一个数据集，其中包含了乳腺癌患者和非乳腺癌患者的常规血液检查信息。潜在地，如果我们能够准确地预测一个病人是否患有癌症，那么这个病人可以接受非常早期的治疗，甚至在肿瘤被发现之前！</p><p id="f3f1" class="pw-post-body-paragraph kw kx iv ky b kz la jw lb lc ld jz le lf lg lh li lj lk ll lm ln lo lp lq lr io bi translated">当然，数据集和完整的笔记本都可以在这里<a class="ae ls" href="https://github.com/marcopeix/ISL-Decision-Trees" rel="noopener ugc nofollow" target="_blank">获得</a>，我强烈建议你也一起编码。</p><h2 id="f89d" class="nc ml iv bd mm nd ne dn mq nf ng dp mu lf nh ni mw lj nj nk my ln nl nm na nn bi translated">探索性数据分析</h2><p id="a3f1" class="pw-post-body-paragraph kw kx iv ky b kz no jw lb lc np jz le lf nq lh li lj nr ll lm ln ns lp lq lr io bi translated">在开始 Jupyter 的工作之前，我们可以在这里获得关于数据集<a class="ae ls" href="https://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Coimbra" rel="noopener ugc nofollow" target="_blank">的信息</a>。</p><p id="a616" class="pw-post-body-paragraph kw kx iv ky b kz la jw lb lc ld jz le lf lg lh li lj lk ll lm ln lo lp lq lr io bi translated">首先，您会注意到数据集非常小，只有 116 个实例。这带来了几个挑战，因为决策树可能会过度拟合数据，或者由于缺乏其他观察，我们的预测模型可能不是最好的。然而，这是一个很好的概念验证，可能证明通过简单的血液测试预测乳腺癌的真正潜力。</p><p id="158e" class="pw-post-body-paragraph kw kx iv ky b kz la jw lb lc ld jz le lf lg lh li lj lk ll lm ln lo lp lq lr io bi translated">数据集仅包含以下十个属性:</p><p id="2870" class="pw-post-body-paragraph kw kx iv ky b kz la jw lb lc ld jz le lf lg lh li lj lk ll lm ln lo lp lq lr io bi translated">1.年龄:患者的年龄(岁)</p><p id="6fab" class="pw-post-body-paragraph kw kx iv ky b kz la jw lb lc ld jz le lf lg lh li lj lk ll lm ln lo lp lq lr io bi translated">2.身体质量指数:体重指数(千克/米)</p><p id="493a" class="pw-post-body-paragraph kw kx iv ky b kz la jw lb lc ld jz le lf lg lh li lj lk ll lm ln lo lp lq lr io bi translated">3.葡萄糖:血液中的葡萄糖浓度(毫克/分升)</p><p id="e056" class="pw-post-body-paragraph kw kx iv ky b kz la jw lb lc ld jz le lf lg lh li lj lk ll lm ln lo lp lq lr io bi translated">4.胰岛素:血液中的胰岛素浓度(微单位/毫升)</p><p id="bfe1" class="pw-post-body-paragraph kw kx iv ky b kz la jw lb lc ld jz le lf lg lh li lj lk ll lm ln lo lp lq lr io bi translated">5.HOMA:胰岛素抵抗的稳态模型评估(<em class="nt">葡萄糖</em>乘以<em class="nt">胰岛素</em></p><p id="104b" class="pw-post-body-paragraph kw kx iv ky b kz la jw lb lc ld jz le lf lg lh li lj lk ll lm ln lo lp lq lr io bi translated">6.瘦素:能量消耗激素瘦素的浓度(ng/mL)</p><p id="0cda" class="pw-post-body-paragraph kw kx iv ky b kz la jw lb lc ld jz le lf lg lh li lj lk ll lm ln lo lp lq lr io bi translated">7.脂联素:脂联素的浓度——一种调节葡萄糖水平的蛋白质(微克/毫升)</p><p id="136b" class="pw-post-body-paragraph kw kx iv ky b kz la jw lb lc ld jz le lf lg lh li lj lk ll lm ln lo lp lq lr io bi translated">8.抵抗素:抵抗素的浓度——脂肪组织分泌的一种蛋白质(ng/mL)</p><p id="f5f9" class="pw-post-body-paragraph kw kx iv ky b kz la jw lb lc ld jz le lf lg lh li lj lk ll lm ln lo lp lq lr io bi translated">9.MCP . 1:MCP-1 的浓度——一种由于组织损伤或炎症而将单核细胞募集到炎症部位的蛋白质(pg/dL)</p><p id="a1e2" class="pw-post-body-paragraph kw kx iv ky b kz la jw lb lc ld jz le lf lg lh li lj lk ll lm ln lo lp lq lr io bi translated">10.分类:健康对照(1)或患者(2)</p><p id="4260" class="pw-post-body-paragraph kw kx iv ky b kz la jw lb lc ld jz le lf lg lh li lj lk ll lm ln lo lp lq lr io bi translated">现在我们知道了我们将使用什么，我们可以从导入我们常用的库开始:</p><figure class="kl km kn ko gt kp gh gi paragraph-image"><div role="button" tabindex="0" class="nv nw di nx bf ny"><div class="gh gi on"><img src="../Images/24db7f20ae45bba10870dfc326aac67d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*6KFquWknR43vw2YLR5qX9Q.png"/></div></div></figure><p id="0bee" class="pw-post-body-paragraph kw kx iv ky b kz la jw lb lc ld jz le lf lg lh li lj lk ll lm ln lo lp lq lr io bi translated">然后，定义数据集的路径，让我们预览一下:</p><figure class="kl km kn ko gt kp gh gi paragraph-image"><div role="button" tabindex="0" class="nv nw di nx bf ny"><div class="gh gi on"><img src="../Images/0b3a7bdd1b253671b65ded5f6e3334a1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*X_0CUgJ3Hy-Q3b-id9LhYQ.png"/></div></div></figure><p id="270e" class="pw-post-body-paragraph kw kx iv ky b kz la jw lb lc ld jz le lf lg lh li lj lk ll lm ln lo lp lq lr io bi translated">太好了！现在，因为这是一个分类问题，所以让我们看看这些类别是否平衡:</p><figure class="kl km kn ko gt kp gh gi paragraph-image"><div role="button" tabindex="0" class="nv nw di nx bf ny"><div class="gh gi on"><img src="../Images/e302a93683751305c25d8033d0249c28.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*UCtPstUs4jpKoMsuO9K7sw.png"/></div></div></figure><p id="e624" class="pw-post-body-paragraph kw kx iv ky b kz la jw lb lc ld jz le lf lg lh li lj lk ll lm ln lo lp lq lr io bi translated">结果应该是:</p><figure class="kl km kn ko gt kp gh gi paragraph-image"><div role="button" tabindex="0" class="nv nw di nx bf ny"><div class="gh gi os"><img src="../Images/71e435802b5f95c4ddb8a05b39e110b9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*aAZUUQyOQYK_Uhf1uXtHtA.png"/></div></div></figure><p id="a2f0" class="pw-post-body-paragraph kw kx iv ky b kz la jw lb lc ld jz le lf lg lh li lj lk ll lm ln lo lp lq lr io bi translated">如你所见，病人和健康对照的数量几乎相同。</p><p id="0783" class="pw-post-body-paragraph kw kx iv ky b kz la jw lb lc ld jz le lf lg lh li lj lk ll lm ln lo lp lq lr io bi translated">现在，看看健康人和病人的每个特征的分布和密度会很有趣。为此，一个<strong class="ky iw">小提琴情节</strong>是理想的。它显示了单一地块中要素的密度和分布。让我们有九个小提琴情节:每个特征一个:</p><figure class="kl km kn ko gt kp gh gi paragraph-image"><div role="button" tabindex="0" class="nv nw di nx bf ny"><div class="gh gi on"><img src="../Images/135788d491c47436470f14d89cd0ac86.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*nUkeXcIX2_zeQ1HKddUobA.png"/></div></div></figure><p id="4a85" class="pw-post-body-paragraph kw kx iv ky b kz la jw lb lc ld jz le lf lg lh li lj lk ll lm ln lo lp lq lr io bi translated">花点时间回顾一下所有的图，试着找出健康对照和患者之间的一些差异。</p><p id="c292" class="pw-post-body-paragraph kw kx iv ky b kz la jw lb lc ld jz le lf lg lh li lj lk ll lm ln lo lp lq lr io bi translated">最后，让我们检查一下是否有丢失的值:</p><figure class="kl km kn ko gt kp gh gi paragraph-image"><div role="button" tabindex="0" class="nv nw di nx bf ny"><div class="gh gi on"><img src="../Images/2f3e860acd321c5cefde93532438e6b2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*8pWP3qYnwuV2ezA0vZ6OpQ.png"/></div></div></figure><p id="274a" class="pw-post-body-paragraph kw kx iv ky b kz la jw lb lc ld jz le lf lg lh li lj lk ll lm ln lo lp lq lr io bi translated">您应该看到没有一列缺少值！我们现在准备开始建模！</p><h2 id="5040" class="nc ml iv bd mm nd ne dn mq nf ng dp mu lf nh ni mw lj nj nk my ln nl nm na nn bi translated">系统模型化</h2><p id="4134" class="pw-post-body-paragraph kw kx iv ky b kz no jw lb lc np jz le lf nq lh li lj nr ll lm ln ns lp lq lr io bi translated">首先，我们需要将类编码为 0 和 1:</p><figure class="kl km kn ko gt kp gh gi paragraph-image"><div role="button" tabindex="0" class="nv nw di nx bf ny"><div class="gh gi on"><img src="../Images/9a66b44f378b606fb51999dc81b4cb9d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*d2tegfi4is7zqL_ptOPD6Q.png"/></div></div></figure><p id="7e44" class="pw-post-body-paragraph kw kx iv ky b kz la jw lb lc ld jz le lf lg lh li lj lk ll lm ln lo lp lq lr io bi translated">现在，0 代表健康对照，1 代表病人。</p><p id="f421" class="pw-post-body-paragraph kw kx iv ky b kz la jw lb lc ld jz le lf lg lh li lj lk ll lm ln lo lp lq lr io bi translated">然后，我们将数据集分为训练集和测试集:</p><figure class="kl km kn ko gt kp gh gi paragraph-image"><div role="button" tabindex="0" class="nv nw di nx bf ny"><div class="gh gi on"><img src="../Images/0778c078cb6cace01027836e916a4970.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*nYCcnhCfb4ALRVviWJlvDQ.png"/></div></div></figure><p id="3690" class="pw-post-body-paragraph kw kx iv ky b kz la jw lb lc ld jz le lf lg lh li lj lk ll lm ln lo lp lq lr io bi translated">在编写模型之前，我们需要定义适当的误差度量。在这种情况下，由于这是一个分类问题，我们可以使用<strong class="ky iw">混淆矩阵</strong>并使用分类误差。让我们编写一个帮助函数来绘制混淆矩阵:</p><figure class="kl km kn ko gt kp gh gi paragraph-image"><div role="button" tabindex="0" class="nv nw di nx bf ny"><div class="gh gi on"><img src="../Images/c76ada0b362938c65b1c0dc3039dd4a6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*hTaOZi6PiCYUllNwyCPqMw.png"/></div></div></figure><p id="ec51" class="pw-post-body-paragraph kw kx iv ky b kz la jw lb lc ld jz le lf lg lh li lj lk ll lm ln lo lp lq lr io bi translated">厉害！现在，让我们实现一个决策树。</p><h2 id="8b81" class="nc ml iv bd mm nd ne dn mq nf ng dp mu lf nh ni mw lj nj nk my ln nl nm na nn bi translated">决策图表</h2><p id="ff6c" class="pw-post-body-paragraph kw kx iv ky b kz no jw lb lc np jz le lf nq lh li lj nr ll lm ln ns lp lq lr io bi translated">使用<em class="nt"> scikit-learn </em>，决策树很容易实现:</p><figure class="kl km kn ko gt kp gh gi paragraph-image"><div role="button" tabindex="0" class="nv nw di nx bf ny"><div class="gh gi on"><img src="../Images/d8d22bf67a2b27349de643bfcbd1486c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Wf88liKmUfUDAK_3Apw3AQ.png"/></div></div></figure><p id="a5d7" class="pw-post-body-paragraph kw kx iv ky b kz la jw lb lc ld jz le lf lg lh li lj lk ll lm ln lo lp lq lr io bi translated">您应该得到以下混淆矩阵:</p><figure class="kl km kn ko gt kp gh gi paragraph-image"><div role="button" tabindex="0" class="nv nw di nx bf ny"><div class="gh gi ot"><img src="../Images/680c8eb25be153c90d7d4e1dbab04a5f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_ydBTEg-Rl9-ugSCWB8PcA.png"/></div></div></figure><p id="302e" class="pw-post-body-paragraph kw kx iv ky b kz la jw lb lc ld jz le lf lg lh li lj lk ll lm ln lo lp lq lr io bi translated">如您所见，它错误地分类了三个实例。因此，我们来看看套袋、助推或随机森林是否能提高树的性能。</p><h2 id="aa02" class="nc ml iv bd mm nd ne dn mq nf ng dp mu lf nh ni mw lj nj nk my ln nl nm na nn bi translated">制袋材料</h2><p id="0d52" class="pw-post-body-paragraph kw kx iv ky b kz no jw lb lc np jz le lf nq lh li lj nr ll lm ln ns lp lq lr io bi translated">为了实现带有 bagging 的决策树，我们编写以下代码:</p><figure class="kl km kn ko gt kp gh gi paragraph-image"><div role="button" tabindex="0" class="nv nw di nx bf ny"><div class="gh gi on"><img src="../Images/22270d83fbc24e2cfe68d7563791ecad.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*yUdfwgSqxCTScJJHcztwwA.png"/></div></div></figure><p id="e3a5" class="pw-post-body-paragraph kw kx iv ky b kz la jw lb lc ld jz le lf lg lh li lj lk ll lm ln lo lp lq lr io bi translated">你会得到下面的混淆矩阵:</p><figure class="kl km kn ko gt kp gh gi paragraph-image"><div role="button" tabindex="0" class="nv nw di nx bf ny"><div class="gh gi ou"><img src="../Images/2eda7611bbde5c954480eefd1556c0fc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*YgsSrrh6azRb_Is9RLhqbg.png"/></div></div></figure><p id="5ac3" class="pw-post-body-paragraph kw kx iv ky b kz la jw lb lc ld jz le lf lg lh li lj lk ll lm ln lo lp lq lr io bi translated">太神奇了！该模型对测试集中的所有实例进行了正确分类！为了得到更多的练习，让我们也实现一个随机森林分类器并使用 boosting。</p><h2 id="1850" class="nc ml iv bd mm nd ne dn mq nf ng dp mu lf nh ni mw lj nj nk my ln nl nm na nn bi translated">随机森林分类器</h2><p id="3a25" class="pw-post-body-paragraph kw kx iv ky b kz no jw lb lc np jz le lf nq lh li lj nr ll lm ln ns lp lq lr io bi translated">这里，对于随机森林分类器，我们指定我们想要的树的数量。让我们用 100:</p><figure class="kl km kn ko gt kp gh gi paragraph-image"><div role="button" tabindex="0" class="nv nw di nx bf ny"><div class="gh gi on"><img src="../Images/8d5e601366eea11aad3e4e6a7185b7a0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*C-KMALDYa5ALGwuJDspxQw.png"/></div></div></figure><p id="5b8c" class="pw-post-body-paragraph kw kx iv ky b kz la jw lb lc ld jz le lf lg lh li lj lk ll lm ln lo lp lq lr io bi translated">你会得到这个混乱矩阵:</p><figure class="kl km kn ko gt kp gh gi paragraph-image"><div role="button" tabindex="0" class="nv nw di nx bf ny"><div class="gh gi ov"><img src="../Images/78702c19e753d87f10d2e15b56dca834.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Wny1QVXx6_vedqktkKq03w.png"/></div></div></figure><p id="41f6" class="pw-post-body-paragraph kw kx iv ky b kz la jw lb lc ld jz le lf lg lh li lj lk ll lm ln lo lp lq lr io bi translated">在这里，虽然只有一个实例被错误分类，但是模型实际上说一个病人是健康的，而实际上这个人患有癌症！这是非常不理想的情况。</p><h2 id="3ffd" class="nc ml iv bd mm nd ne dn mq nf ng dp mu lf nh ni mw lj nj nk my ln nl nm na nn bi translated">助推</h2><p id="2713" class="pw-post-body-paragraph kw kx iv ky b kz no jw lb lc np jz le lf nq lh li lj nr ll lm ln ns lp lq lr io bi translated">最后，对于升压:</p><figure class="kl km kn ko gt kp gh gi paragraph-image"><div role="button" tabindex="0" class="nv nw di nx bf ny"><div class="gh gi on"><img src="../Images/0a9435d73bdce9f6371aff948d111071.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*wt8sNPv6J7fVRgdZjpccjg.png"/></div></div></figure><p id="531d" class="pw-post-body-paragraph kw kx iv ky b kz la jw lb lc ld jz le lf lg lh li lj lk ll lm ln lo lp lq lr io bi translated">我们得到了以下结果:</p><figure class="kl km kn ko gt kp gh gi paragraph-image"><div role="button" tabindex="0" class="nv nw di nx bf ny"><div class="gh gi ow"><img src="../Images/bf322499d0c70d5c834fcbecad3d540b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*IggCyl6Xwj8EuVlIohZ84g.png"/></div></div></figure><p id="e3a4" class="pw-post-body-paragraph kw kx iv ky b kz la jw lb lc ld jz le lf lg lh li lj lk ll lm ln lo lp lq lr io bi translated">同样，只有一个实例被错误分类。</p><h1 id="fc0f" class="mk ml iv bd mm mn mo mp mq mr ms mt mu kb mv kc mw ke mx kf my kh mz ki na nb bi translated">结论</h1><p id="1384" class="pw-post-body-paragraph kw kx iv ky b kz no jw lb lc np jz le lf nq lh li lj nr ll lm ln ns lp lq lr io bi translated">这篇文章涵盖了很多！您学习了基于树的方法的基本理论，您学习了我们如何提高它们的性能，并且我们在项目设置中实现了每个算法。</p><p id="e642" class="pw-post-body-paragraph kw kx iv ky b kz la jw lb lc ld jz le lf lg lh li lj lk ll lm ln lo lp lq lr io bi translated">我希望这篇文章对您有用，并且您将在未来的项目中使用它。</p></div></div>    
</body>
</html>