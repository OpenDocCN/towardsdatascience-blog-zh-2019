<html>
<head>
<title>Understanding Customer Churning with Big Data Analytics</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">利用大数据分析了解客户流失</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/understanding-customer-churning-with-big-data-analytics-70ce4eb17669?source=collection_archive---------12-----------------------#2019-01-24">https://towardsdatascience.com/understanding-customer-churning-with-big-data-analytics-70ce4eb17669?source=collection_archive---------12-----------------------#2019-01-24</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="ec2b" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">如何利用数据科学为您的企业带来价值的实例</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/58d62db70229e252bf83e1407193493e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*osBfh8-eqc3KdA3uV5M1yQ.jpeg"/></div></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk">Photo by <a class="ae ky" href="https://unsplash.com/@__matthoffman__?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank">Matt Hoffman</a> on <a class="ae ky" href="https://unsplash.com/s/photos/water-leak?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><p id="5ad2" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">猜猜看。目前世界上最有价值的资产是什么？</p><p id="f242" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">不是黄金，不是原油……是数据。您一定听说过流行的术语“大数据”，并且想知道这个术语到底是什么意思。想想你最喜欢的音乐流媒体服务——Spotify、Pandora 等。在世界各地，每秒钟都有许多不同的用户登录到该服务，与该服务进行公平的交互。由于每一次移动都对应一个可收集的数据点，所以您可以想象存储如此大的数据会面临怎样的挑战。</p><p id="ff23" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">幸运的是，如果以正确的方式使用，这些大型数据集可以为企业带来真正的价值。在这篇博文中，我们将讨论这些大数据集的一个常见用例——预测客户流失。</p><p id="0428" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">了解流失</strong></p><p id="a5fb" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">客户流失指的是从大量客户中悄悄流失客户的行为。一些客户可能会转向竞争对手，而一些人可能会永远离开服务。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="ab gu cl lv"><img src="../Images/0220eb1465c3379c92d390e90b9ff3d7.png" data-original-src="https://miro.medium.com/v2/format:webp/1*osC29H34Bw19gqYFc6FWcA@2x.jpeg"/></div></figure><p id="6145" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">开始时可能不明显，但随着时间的推移，这种损失的影响会逐渐积累。作为这些音乐流媒体服务提供商的决策者，我们希望了解这种搅动行为的成因，这将成为我们今天项目的主要目标。</p><p id="9287" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们将从检查可用的数据集开始。</p><p id="b5a9" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">完整的数据集是存储在 12 GB 中的用户日志。json 文件——这个大小只能由一些大数据工具处理，比如 Spark。为了充分理解可用的字段，我们将从获取数据的一个小子集(大约 128 MB)开始，以便在单台机器上进行探索性的数据分析。我们将通过以下命令加载数据集，</p><pre class="kj kk kl km gt lw lx ly lz aw ma bi"><span id="fbd9" class="mb mc it lx b gy md me l mf mg"># create a Spark session<br/><strong class="lx iu">spark = (SparkSession.builder <br/>                    .master("local") <br/>                    .appName("Creating Features") <br/>                    .getOrCreate())</strong></span><span id="3137" class="mb mc it lx b gy mh me l mf mg"># Read in .json file as events<strong class="lx iu"><br/>events = spark.read.json('mini_sparkify_event_data.json')<br/>events.persist()</strong></span></pre><p id="663a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">Spark 有一个很棒的单行快捷方式，可以显示所有字段及其各自的数据类型</p><pre class="kj kk kl km gt lw lx ly lz aw ma bi"><span id="5c8b" class="mb mc it lx b gy md me l mf mg"><strong class="lx iu">events.printSchema()</strong></span><span id="1a07" class="mb mc it lx b gy mh me l mf mg">root<br/> |-- artist: string (nullable = true)<br/> |-- auth: string (nullable = true)<br/> |-- firstName: string (nullable = true)<br/> |-- gender: string (nullable = true)<br/> |-- itemInSession: long (nullable = true)<br/> |-- lastName: string (nullable = true)<br/> |-- length: double (nullable = true)<br/> |-- level: string (nullable = true)<br/> |-- location: string (nullable = true)<br/> |-- method: string (nullable = true)<br/> |-- page: string (nullable = true)<br/> |-- registration: long (nullable = true)<br/> |-- sessionId: long (nullable = true)<br/> |-- song: string (nullable = true)<br/> |-- status: long (nullable = true)<br/> |-- ts: long (nullable = true)<br/> |-- userAgent: string (nullable = true)<br/> |-- userId: string (nullable = true)</span></pre><p id="d598" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在查看数据集的头部后，我们会发现所有的用户交互都记录在<em class="mi">页面的</em>列中。</p><p id="9e38" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">当大多数用户继续播放下一首歌曲时，有一些用户进入了“取消”页面——他们都通过“取消确认”页面确认了他们的取消(参见相同数量的“取消”和“取消确认”.<strong class="lb iu">我们将搅动活动具体定义为取消确认的数量</strong>。第<em class="mi">页</em>列有“取消确认”的用户将是我们特别感兴趣的搅动用户。</p><p id="1a70" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">特征工程</strong></p><p id="470b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们已经成功地识别了流失的用户，现在是时候用我们的商业思维来思考用户流失的影响因素了。<strong class="lb iu"> <em class="mi">如果你真的很讨厌你的音乐流媒体服务，你会怎么做？</em> </strong>我想出了下面 7 个特性，</p><ol class=""><li id="c7fe" class="mj mk it lb b lc ld lf lg li ml lm mm lq mn lu mo mp mq mr bi translated"><strong class="lb iu">代表性用户互动</strong></li></ol><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ms"><img src="../Images/a769d52387e8c3ecc33628c3fad05a2f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*LrKAMbjmA30VupdhuIY99w.png"/></div></div></figure><p id="4069" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们有理由期待其他一些用户互动最终会导致我们的用户流失。我们可以使用箱线图来执行第一级过滤。箱线图将有效地帮助我们可视化特定数据分布的最小值、第 25 个百分点、平均值、第 75 个百分点和最大值。通过绘制搅动和非搅动用户的箱线图，我们可以清楚地解释特定交互中两类用户之间的差异。</p><p id="0310" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">以下相互作用显示了两组之间的显著分布差异，</p><ul class=""><li id="68dd" class="mj mk it lb b lc ld lf lg li ml lm mm lq mn lu mt mp mq mr bi translated">添加好友——喝醉的用户不太可能添加好友</li><li id="2a13" class="mj mk it lb b lc mu lf mv li mw lm mx lq my lu mt mp mq mr bi translated"><strong class="lb iu">添加到播放列表</strong> —喝醉的用户不太可能添加到播放列表</li><li id="2cb4" class="mj mk it lb b lc mu lf mv li mw lm mx lq my lu mt mp mq mr bi translated"><strong class="lb iu">升级</strong> —被搅动的用户有各种各样的升级活动</li><li id="2007" class="mj mk it lb b lc mu lf mv li mw lm mx lq my lu mt mp mq mr bi translated"><strong class="lb iu">下一首歌</strong>——喝醉的用户不太可能播放下一首歌</li><li id="78c8" class="mj mk it lb b lc mu lf mv li mw lm mx lq my lu mt mp mq mr bi translated"><strong class="lb iu">拇指朝上</strong>——喝醉的用户不太可能竖起大拇指</li><li id="9617" class="mj mk it lb b lc mu lf mv li mw lm mx lq my lu mt mp mq mr bi translated"><strong class="lb iu">滚动广告</strong>——被搅动的用户在滚动广告上有更广泛的传播</li><li id="0d19" class="mj mk it lb b lc mu lf mv li mw lm mx lq my lu mt mp mq mr bi translated"><strong class="lb iu">设置</strong> —搅动的用户不太可能访问设置页面</li><li id="3fbd" class="mj mk it lb b lc mu lf mv li mw lm mx lq my lu mt mp mq mr bi translated"><strong class="lb iu">注销</strong> —大量用户不太可能注销(由于登录次数减少)</li><li id="d393" class="mj mk it lb b lc mu lf mv li mw lm mx lq my lu mt mp mq mr bi translated"><strong class="lb iu">帮助</strong>——不焦虑的用户更有可能寻求帮助</li><li id="9fcb" class="mj mk it lb b lc mu lf mv li mw lm mx lq my lu mt mp mq mr bi translated">首页——不安的用户不太可能访问主页</li></ul><p id="7f59" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">请注意，我们所有的用户交互都在同一列中，我们需要透视和聚合每个客户的某个交互的总数。基于以上筛选，我们将去掉一些不太重要的交互。</p><pre class="kj kk kl km gt lw lx ly lz aw ma bi"><span id="cd25" class="mb mc it lx b gy md me l mf mg"><strong class="lx iu">events = events.drop('firstName', 'lastName', 'auth',<br/>                      'gender', 'song','artist',<br/>                      'status', 'method', 'location', <br/>                      'registration', 'itemInSession')</strong></span><span id="8520" class="mb mc it lx b gy mh me l mf mg"><strong class="lx iu">events_pivot = (events.groupby(["userId"])<br/>                      .pivot("page")<br/>                      .count()<br/>                      .fillna(0))</strong></span><span id="18db" class="mb mc it lx b gy mh me l mf mg"><strong class="lx iu">events_pivot = events_pivot.drop('About', 'Cancel', 'Login',  <br/>                                 'Submit Registration','Register',<br/>                                 'Save Settings')</strong></span></pre><p id="710b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">2.<strong class="lb iu">平均音乐播放时间</strong></p><p id="49e2" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">对我自己来说，我使用它的时间可能会比普通用户短。因此，<strong class="lb iu">用户花在播放音乐上的平均时间长度</strong>将是一个非常重要的因素。一个简单的可视化显示确认结果如下。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi mz"><img src="../Images/3bd061b28c193793a41e8f28c635b1c6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*AMAdYmKxIN633VOlkFIbCg.png"/></div></div></figure><p id="d3c5" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们将把这个特性添加到我们的<em class="mi"> events_pivot </em>表中，</p><pre class="kj kk kl km gt lw lx ly lz aw ma bi"><span id="6f45" class="mb mc it lx b gy md me l mf mg"># filter events log to contain only next song<br/><strong class="lx iu">events_songs = events.filter(events.page == 'NextSong')</strong></span><span id="e200" class="mb mc it lx b gy mh me l mf mg"># Total songs length played<br/><strong class="lx iu">total_length = (events_songs.groupby(events_songs.userId)<br/>                           .agg(sum('length')))</strong></span><span id="0ce5" class="mb mc it lx b gy mh me l mf mg"># join events pivot<br/><strong class="lx iu">events_pivot = (events_pivot.join(total_length, on = 'userId', <br/>                                  how = 'left')<br/>                     .withColumnRenamed("Cancellation Confirmation",<br/>                                        "Churn")<br/>                     .withColumnRenamed("sum(length)", <br/>                                        "total_length"))</strong></span></pre><p id="d1f5" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">3.<strong class="lb iu">活动天数</strong></p><p id="7512" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们还期望搅动组和非搅动组之间活动天数的差异。由于 datetime 列只包含以秒为单位的单位，我们将需要使用一个窗口函数来合计每个客户的总活动时间，并将该值转换为天数。我们将把这个特性添加到<em class="mi"> events_pivot </em>中。</p><pre class="kj kk kl km gt lw lx ly lz aw ma bi"><span id="a21e" class="mb mc it lx b gy md me l mf mg"><strong class="lx iu">convert = 1000*60*60*24</strong> # conversion factor to days</span><span id="9097" class="mb mc it lx b gy mh me l mf mg"># Find minimum/maximum time stamp of each user<br/><strong class="lx iu">min_timestmp = events.select(["userId", "ts"])<br/>                     .groupby("userId")<br/>                     .min("ts")</strong></span><span id="9aaf" class="mb mc it lx b gy mh me l mf mg"><strong class="lx iu">max_timestmp = events.select(["userId", "ts"])<br/>                     .groupby("userId")<br/>                     .max("ts")</strong></span><span id="ec33" class="mb mc it lx b gy mh me l mf mg"># Find days active of each user<br/><strong class="lx iu">daysActive = min_timestmp.join(max_timestmp, on="userId")<br/>daysActive = (daysActive.withColumn("days_active", <br/>                      (col("max(ts)")-col("min(ts)")) / convert))</strong></span><span id="c9d4" class="mb mc it lx b gy mh me l mf mg"><strong class="lx iu">daysActive = daysActive.select(["userId", "days_active"])</strong></span><span id="b3ad" class="mb mc it lx b gy mh me l mf mg"># join events pivot<br/><strong class="lx iu">events_pivot = events_pivot.join(daysActive, <br/>                                 on = 'userId',<br/>                                 how = 'left')</strong></span></pre><p id="9f3d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">4.<strong class="lb iu">付费用户的天数</strong></p><p id="c771" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">类似地，我们也可以通过使用窗口函数来计算付费用户的天数，我们只需要为要成为付费用户的客户添加一个过滤器。</p><pre class="kj kk kl km gt lw lx ly lz aw ma bi"><span id="5801" class="mb mc it lx b gy md me l mf mg"># Find minimum/maximum time stamp of each user as paid user<br/><strong class="lx iu">paid_min_ts = events.filter(events.level == 'paid')<br/>                    .groupby("userId").min("ts")</strong></span><span id="74c1" class="mb mc it lx b gy mh me l mf mg"><strong class="lx iu">paid_max_ts = events.filter(events.level == 'paid')<br/>                    .groupby("userId").max("ts")</strong></span><span id="88fc" class="mb mc it lx b gy mh me l mf mg"># Find days as paid user of each user</span><span id="3220" class="mb mc it lx b gy mh me l mf mg"><strong class="lx iu">daysPaid = paid_min_ts.join(paid_max_ts, on="userId")<br/>daysPaid = (daysPaid.withColumn("days_paid", <br/>                    (col("max(ts)")-col("min(ts)")) / convert))</strong></span><span id="fcd2" class="mb mc it lx b gy mh me l mf mg"><strong class="lx iu">daysPaid = daysPaid.select(["userId", "days_paid"])</strong></span><span id="df2d" class="mb mc it lx b gy mh me l mf mg"># join events pivot<br/><strong class="lx iu">events_pivot = events_pivot.join(daysPaid,<br/>                                 on = 'userId', <br/>                                 how='left')</strong></span></pre><p id="67c9" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">5.<strong class="lb iu">免费用户的天数</strong></p><p id="6b33" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">现在使用免费用户过滤器，我们可以找到每个客户作为免费用户的天数，</p><pre class="kj kk kl km gt lw lx ly lz aw ma bi"><span id="5ab7" class="mb mc it lx b gy md me l mf mg"># Find minimum/maximum time stamp of each user as paid user<br/><strong class="lx iu">free_min_ts = events.filter(events.level == 'free')<br/>                    .groupby("userId").min("ts")<br/>free_max_ts = events.filter(events.level == 'free')<br/>                    .groupby("userId").max("ts")</strong></span><span id="e22f" class="mb mc it lx b gy mh me l mf mg"># Find days as paid user of each user<br/><strong class="lx iu">daysFree = free_min_ts.join(free_max_ts, on="userId")<br/>daysFree = (daysFree.withColumn("days_free", <br/>                        (col("max(ts)")-col("min(ts)")) / convert))</strong></span><span id="493b" class="mb mc it lx b gy mh me l mf mg"><strong class="lx iu">daysFree = daysFree.select(["userId", "days_free"])</strong></span><span id="68b9" class="mb mc it lx b gy mh me l mf mg"># join events pivot<br/><strong class="lx iu">events_pivot = events_pivot.join(daysFree, <br/>                                on = 'userId', <br/>                                how='left')</strong></span></pre><p id="6eb7" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">6.<strong class="lb iu">会议次数</strong></p><p id="10f3" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">音乐播放的次数也可能是一个影响因素。由于这个数据集中有<em class="mi"> sessionId </em>，我们可以使用<strong class="lb iu"> <em class="mi"> groupby </em> </strong>子句直接计算每个用户的惟一 Id 的数量。</p><pre class="kj kk kl km gt lw lx ly lz aw ma bi"><span id="fecc" class="mb mc it lx b gy md me l mf mg"># count the number of sessions<strong class="lx iu"><br/>numSessions = (events.select(["userId", "sessionId"])<br/>                      .distinct()<br/>                      .groupby("userId")<br/>                       .count()<br/>                      .withColumnRenamed("count", "num_session</strong>s"))</span><span id="6759" class="mb mc it lx b gy mh me l mf mg"># join events pivot<br/><strong class="lx iu">events_pivot = events_pivot.join(numSessions,<br/>                                 on = 'userId',<br/>                                 how = 'left')</strong></span></pre><p id="0e09" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">7.<strong class="lb iu">用户访问代理</strong></p><p id="de61" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">流服务在不同的用户代理上可能具有不同的性能。我们将尝试在模型中加入这一因素。由于有 56 个不同的用户代理，我们将使用 Spark 的 one-hot 编码器将这些不同的用户代理转换成一个向量。</p><pre class="kj kk kl km gt lw lx ly lz aw ma bi"><span id="5d48" class="mb mc it lx b gy md me l mf mg"># find user access agents, and perform one-hot encoding on the user <br/><strong class="lx iu">userAgents = events.select(['userId', 'userAgent']).distinct()<br/>userAgents = userAgents.fillna('Unknown')</strong></span><span id="1adb" class="mb mc it lx b gy mh me l mf mg"># build string indexer<br/><strong class="lx iu">stringIndexer = StringIndexer(inputCol="userAgent",      <br/>                              outputCol="userAgentIndex")</strong></span><span id="019e" class="mb mc it lx b gy mh me l mf mg"><strong class="lx iu">model = stringIndexer.fit(userAgents)<br/>userAgents = model.transform(userAgents)</strong></span><span id="ea76" class="mb mc it lx b gy mh me l mf mg"># one hot encode userAgent column<br/><strong class="lx iu">encoder = OneHotEncoder(inputCol="userAgentIndex", <br/>                        outputCol="userAgentVec")<br/>userAgents = encoder.transform(userAgents)<br/>                    .select(['userId', 'userAgentVec'])</strong></span><span id="2b00" class="mb mc it lx b gy mh me l mf mg"># join events pivot<br/><strong class="lx iu">events_pivot = events_pivot.join(userAgents, <br/>                                 on = 'userId',<br/>                                 how ='left')</strong></span></pre><p id="5a86" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">模型构建</strong></p><p id="8d4f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在我们设计了适当的功能后，我们将构建三个模型——逻辑回归、随机森林和梯度推进树。为了避免编写冗余代码，我们将构建 stage 对象，并在管道末端用不同的分类器构建管道。</p><pre class="kj kk kl km gt lw lx ly lz aw ma bi"><span id="ca81" class="mb mc it lx b gy md me l mf mg"># Split data into train and test set<br/><strong class="lx iu">events_pivot = events_pivot.withColumnRenamed('Churn', 'label')<br/>training, test = events_pivot.randomSplit([0.8, 0.2])</strong></span><span id="3691" class="mb mc it lx b gy mh me l mf mg"># Create vector from feature data<br/><strong class="lx iu">feature_names = events_pivot.drop('label', 'userId').schema.names<br/>vec_asembler = VectorAssembler(inputCols = feature_names,<br/>                               outputCol = "Features")</strong></span><span id="5c04" class="mb mc it lx b gy mh me l mf mg"># Scale each column<br/><strong class="lx iu">scalar = MinMaxScaler(inputCol="Features", <br/>                      outputCol="ScaledFeatures")</strong></span><span id="6aef" class="mb mc it lx b gy mh me l mf mg"># Build classifiers<br/><strong class="lx iu">rf = RandomForestClassifier(featuresCol="ScaledFeatures", <br/>                            labelCol="label",<br/>                            numTrees = 50, <br/>                            featureSubsetStrategy='sqrt')</strong></span><span id="8a81" class="mb mc it lx b gy mh me l mf mg"><strong class="lx iu">lr = LogisticRegression(featuresCol="ScaledFeatures",  <br/>                        labelCol="label", <br/>                        maxIter=10,<br/>                        regParam=0.01)</strong></span><span id="926b" class="mb mc it lx b gy mh me l mf mg"><strong class="lx iu">gbt = GBTClassifier(featuresCol="ScaledFeatures", <br/>                    labelCol="label")</strong></span><span id="8ca1" class="mb mc it lx b gy mh me l mf mg"># Consturct 3 pipelines<br/><strong class="lx iu">pipeline_rf = Pipeline(stages=[vec_asembler, scalar, rf])<br/>pipeline_lr = Pipeline(stages=[vec_asembler, scalar, lr])<br/>pipeline_gbt = Pipeline(stages=[vec_asembler, scalar, gbt])</strong></span><span id="9551" class="mb mc it lx b gy mh me l mf mg"># Fit the models<br/><strong class="lx iu">rf_model = pipeline_rf.fit(training)<br/>lr_model = pipeline_lr.fit(training)<br/>gbt_model = pipeline_gbt.fit(training)</strong></span></pre><p id="0742" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">现在三个对象<em class="mi"> rf_model </em>、<em class="mi"> lr_model </em>、<em class="mi"> gbt_model </em>，代表了 3 种不同的拟合模型。</p><p id="ed79" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">车型评价</strong></p><p id="453a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们将测试拟合模型的性能，并选择具有最佳性能的模型作为最终模型。我们将首先构建一个专门用于此目的的函数，</p><pre class="kj kk kl km gt lw lx ly lz aw ma bi"><span id="e92d" class="mb mc it lx b gy md me l mf mg"><strong class="lx iu">def modelEvaluations(model, metric, data):</strong><br/>    """ Evaluate a machine learning model's performance <br/>        Input: <br/>            model - pipeline object<br/>            metric - the metric of the evaluations<br/>            data - data being evaluated<br/>        Output:<br/>            [score, confusion matrix]<br/>    """<br/>    # generate predictions<br/>    <strong class="lx iu">evaluator = MulticlassClassificationEvaluator(<br/>                metricName = metric)<br/>    predictions = model.transform(data)</strong><br/>    <br/>    # calcualte score<br/><strong class="lx iu">    score = evaluator.evaluate(predictions)<br/>    confusion_matrix = (predictions.groupby("label")<br/>                                   .pivot("prediction")<br/>                                   .count()<br/>                                   .toPandas())<br/>    return [score, confusion_matrix]</strong></span></pre><p id="a1f6" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们将调用上面的函数来评估上面的模型</p><pre class="kj kk kl km gt lw lx ly lz aw ma bi"><span id="2912" class="mb mc it lx b gy md me l mf mg"><strong class="lx iu">f1_rf, conf_mtx_rf = modelEvaluations(rf_model, 'f1', test)<br/>f1_lr, conf_mtx_lr = modelEvaluations(lr_model, 'f1', test)<br/>f1_gbt, conf_mtx_gbt = modelEvaluations(gbt_model, 'f1', test)</strong></span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi na"><img src="../Images/d8eb45c18871d40c4c188c4dff80dc7c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*3QdhWElYxOlTyQaqJ-w8dA.png"/></div></div></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nb"><img src="../Images/4ad45e0f2b150184e347a135ff82c642.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*pnR-V6A_So-KcoBNhUN-NQ.png"/></div></div></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nc"><img src="../Images/031704df014f4ca02de6c5b5abca738f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Aw6HguY46FR35-ACbk0-yA.png"/></div></div></figure><p id="c7f5" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">梯度推进模型在测试集中表现出最好的性能(F1 分数)。F1 分数定义为精确度和召回率的调和平均值，计算如下</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="ab gu cl lv"><img src="../Images/28789c5dabdd7575bd6d9cd5bcac52c8.png" data-original-src="https://miro.medium.com/v2/1*SUL4LXxJHHUGFZXESAh4jg.gif"/></div></figure><p id="dfad" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">精度是计算正确的正类标识的比例，在数学表达式中是这样的</p><p id="e415" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><em class="mi">精度= tp/(tp + fp) </em></p><p id="4148" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">召回是计算实际正类样本被正确识别的比例，在数学表达式中，</p><p id="ae7d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><em class="mi">召回= tp/(tp + fn) </em></p><p id="f860" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">您可能想知道为什么我们选择更复杂的度量标准而不是最直观的准确性，这是因为数据集中存在不平衡的类分布。<strong class="lb iu">由于只有一小部分用户最终会流失，我们希望我们的模型能够正确识别他们，而不是追求高整体性能</strong>。想象一下，如果只有 6%的客户会在真实的人口分布中流失，预测每个人都不会流失仍然会给我们 94%的准确性。另一方面，F1 分数将惩罚单个班级的不良表现，这将有效地缓解这些问题。不平衡类特征将出现在每个流失预测问题中——F1 将始终是未来使用的指标。</p><p id="7a43" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">特征重要性</strong></p><p id="6371" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们将利用特征重要性函数，并可视化我们构建的每个特征的相对重要性等级。由于最后一个特性<em class="mi"> userAgentVec </em>实际上是一个热编码向量，我们将把<em class="mi"> userAgentVec </em>特性视为一个。下面的代码将对从独热编码向量获得的所有子特征的所有特征重要性值求和。</p><pre class="kj kk kl km gt lw lx ly lz aw ma bi"><span id="3992" class="mb mc it lx b gy md me l mf mg"><strong class="lx iu">feature_importances = np.array(gbt_model.stages[-1]<br/>                               .featureImportances)</strong></span><span id="d219" class="mb mc it lx b gy mh me l mf mg"><strong class="lx iu">userAgentVec = feature_importances[len(feature_names) :].sum()<br/>feature_importances = feature_importances[:len(feature_names)]<br/>                      + [userAgentVec]</strong></span></pre><p id="09f8" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">现在我们绘制梯度推进树的特征重要性。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nd"><img src="../Images/9fbb9595af645f8e0032351a321e4be9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*haiRkea9lEpB8EWi9DSqCg.png"/></div></div></figure><p id="5f24" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们构建的大多数功能都是用户流失的重要因素，其中<em class="mi"> days_active </em>是最重要的因素。</p><p id="c6d7" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">全数据集运行</strong></p><p id="a172" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们已经构建了适当的框架——我们准备按照上面相同的步骤，使用 AWS 的 EMR 服务让模型在完整的 12 GB 数据集上运行。我们将通过以下方式初始化会话</p><pre class="kj kk kl km gt lw lx ly lz aw ma bi"><span id="6467" class="mb mc it lx b gy md me l mf mg"># Create spark session<br/><strong class="lx iu">spark = (SparkSession <br/>        .builder <br/>        .appName("Sparkify") <br/>        .getOrCreate())</strong></span><span id="98df" class="mb mc it lx b gy mh me l mf mg"># Read in full sparkify dataset<br/><strong class="lx iu">event_data = "s3n://dsnd-sparkify/sparkify_event_data.json"<br/>events = spark.read.json(event_data)</strong></span></pre><p id="6f18" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们不再重复这些步骤——我已经在<a class="ae ky" href="https://nbviewer.jupyter.org/github/chenbowen184/Data_Science_Portfolio/blob/master/Capstone%20Project/Spark%20-%20Full%20Dataset.ipynb" rel="noopener ugc nofollow" target="_blank"> nbviewer 网站</a>上附上了完整的脚本。</p><p id="6347" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">最终，梯度推进模式产生了 0.8896 的<strong class="lb iu"> F1 成绩，这是一个很棒的表现。</strong></p><pre class="kj kk kl km gt lw lx ly lz aw ma bi"><span id="1986" class="mb mc it lx b gy md me l mf mg">+-----+----+---+<br/>|label| 0.0|1.0|<br/>+-----+----+---+<br/>|    0|1612| 70|<br/>|    1| 163|344|<br/>+-----+----+---+</span></pre><p id="dabc" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">经营战略</strong></p><p id="f033" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们经历了怎样的旅程——但我们还没有完成我们的使命。在数据科学领域，每个模型背后都有一个商业意图。有了我们创造的功能重要性，我们肯定可以想出一些商业策略来应对客户的抱怨。我们将简要讨论两种可能的策略，它们将真正为我们的提供商带来一些价值。</p><p id="9919" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们知道<strong class="lb iu">活跃天数是最重要的因素，</strong>我们可以建议<strong class="lb iu">高层管理人员建立一个奖励系统，鼓励低活跃度用户长时间保持在线</strong>。</p><p id="27ed" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">此外，由于<strong class="lb iu">用户用来访问服务的代理也很重要，</strong>我们还可以<strong class="lb iu">找出表现不佳的代理，并让我们的工程团队专门解决这个问题。</strong></p></div><div class="ab cl ne nf hx ng" role="separator"><span class="nh bw bk ni nj nk"/><span class="nh bw bk ni nj nk"/><span class="nh bw bk ni nj"/></div><div class="im in io ip iq"><p id="4f13" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我希望你能像我喜欢写这篇文章一样喜欢读这篇文章。我们一起使用大数据分析框架 Spark 来构建端到端的机器学习工作流，以从用户日志中识别潜在的音乐流媒体服务客户。我们执行了以下步骤，</p><ol class=""><li id="09d2" class="mj mk it lb b lc ld lf lg li ml lm mm lq mn lu mo mp mq mr bi translated">探索性数据分析</li><li id="f09d" class="mj mk it lb b lc mu lf mv li mw lm mx lq my lu mo mp mq mr bi translated">特征工程</li><li id="4a4b" class="mj mk it lb b lc mu lf mv li mw lm mx lq my lu mo mp mq mr bi translated">模型结构</li><li id="2ce5" class="mj mk it lb b lc mu lf mv li mw lm mx lq my lu mo mp mq mr bi translated">模型评估</li><li id="9496" class="mj mk it lb b lc mu lf mv li mw lm mx lq my lu mo mp mq mr bi translated">模型放大</li><li id="77c2" class="mj mk it lb b lc mu lf mv li mw lm mx lq my lu mo mp mq mr bi translated">商业策略</li></ol><p id="24b1" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">由于我们正在处理的数据规模庞大，执行超参数搜索变得尤为困难。可以想象，让笔记本电脑长时间开着并不是使用资源的最有效方式。使用 ssh 来保持程序运行的一些好技巧肯定有助于应对这一挑战。</p><p id="8193" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">如果说我们应该从这篇文章中学到什么的话，那就是我们在故事开始时提到的那一点。作为杰出的工程师，我们经常被吸引去通过各种技术构建最好的高性能模型，但是<strong class="lb iu">我们的模型需要解决商业问题才能有价值。</strong></p></div></div>    
</body>
</html>