<html>
<head>
<title>Approaches to sentimental analysis on a small imbalanced dataset without Deep Learning</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">无需深度学习的小规模不平衡数据集情感分析方法</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/approaches-to-sentimental-analysis-on-a-small-imbalanced-dataset-without-deep-learning-a314817e687?source=collection_archive---------14-----------------------#2019-08-09">https://towardsdatascience.com/approaches-to-sentimental-analysis-on-a-small-imbalanced-dataset-without-deep-learning-a314817e687?source=collection_archive---------14-----------------------#2019-08-09</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="17e5" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">让我们让 logreg 再次变得伟大！</h2></div><h1 id="73e2" class="ki kj it bd kk kl km kn ko kp kq kr ks jz kt ka ku kc kv kd kw kf kx kg ky kz bi translated">介绍</h1><p id="3169" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">现在有很多用于 NLP 的预训练网络，它们是 SOTA，并且击败了所有基准:BERT、XLNet、RoBERTa、ERNIE…它们被成功地应用于各种数据集，即使在数据很少的情况下。</p><p id="4072" class="pw-post-body-paragraph la lb it lc b ld lw ju lf lg lx jx li lj ly ll lm ln lz lp lq lr ma lt lu lv im bi translated">在 7 月底(2019 年 7 月 23 日–2019 年 7 月 28 日),有一个关于分析 Vidhya 的小型在线黑客马拉松，他们让参与者对药物评论进行感性分析。这很复杂，原因有几个:</p><ul class=""><li id="a5b9" class="mb mc it lc b ld lw lg lx lj md ln me lr mf lv mg mh mi mj bi translated">只有 5279 个样本在训练中，有 3 类(阴性、中性、阳性)不平衡；</li><li id="16e1" class="mb mc it lc b ld mk lg ml lj mm ln mn lr mo lv mg mh mi mj bi translated">一些标签似乎是不正确的，这种情况有时会发生在人工标注文本的时候；</li><li id="ab34" class="mb mc it lc b ld mk lg ml lj mm ln mn lr mo lv mg mh mi mj bi translated">有些课文很短，有些很长。在某些情况下，评论不仅包含评论本身，还包含人们回答的评论的引用；</li><li id="bdae" class="mb mc it lc b ld mk lg ml lj mm ln mn lr mo lv mg mh mi mj bi translated">另一个更有趣的问题是:一般来说，评论可能是积极的，但对一种药物有负面情绪(以及任何其他对情绪)；</li></ul><p id="90d2" class="pw-post-body-paragraph la lb it lc b ld lw ju lf lg lx jx li lj ly ll lm ln lz lp lq lr ma lt lu lv im bi translated">一方面，如果情况复杂，需要对背景有深刻的理解，深度学习模型应该可以很好地工作；另一方面，我们只有几千个样本，这似乎不足以进行深度学习。</p><p id="8179" class="pw-post-body-paragraph la lb it lc b ld lw ju lf lg lx jx li lj ly ll lm ln lz lp lq lr ma lt lu lv im bi translated">剧透:据我所知，winners 对 BERT 和 XLnet 进行了微调，但没有共享代码，具体的我就说不出来了。</p><p id="a236" class="pw-post-body-paragraph la lb it lc b ld lw ju lf lg lx jx li lj ly ll lm ln lz lp lq lr ma lt lu lv im bi translated">我知道我不能在这个比赛上花太多时间，所以我决定尝试普通的方法(单词袋和逻辑回归)，看看他们能走多远。</p><p id="add3" class="pw-post-body-paragraph la lb it lc b ld lw ju lf lg lx jx li lj ly ll lm ln lz lp lq lr ma lt lu lv im bi translated">排行榜可在此处获得(指标为 f1-macro):<a class="ae mp" href="https://datahack.analyticsvidhya.com/contest/innoplexus-online-hiring-hackathon/pvt_lb" rel="noopener ugc nofollow" target="_blank">https://data hack . analyticsvidhya . com/contest/innoplexus-online-hiring-hackathon/PVT _ lb</a></p><p id="3112" class="pw-post-body-paragraph la lb it lc b ld lw ju lf lg lx jx li lj ly ll lm ln lz lp lq lr ma lt lu lv im bi translated">我以 0.5274 的分数获得了第 21 名(第一名的分数为 0.6634)。我还提交了一份得分为 0.5525 的作品，这将使我获得第 12 名，但我没有选择它😞</p><figure class="mr ms mt mu gt mv gh gi paragraph-image"><div role="button" tabindex="0" class="mw mx di my bf mz"><div class="gh gi mq"><img src="../Images/57c0ef0f0103627d101294b5c4827022.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*34FjBYVVrfH1pHqh0gfHFA.png"/></div></div></figure><h1 id="5eda" class="ki kj it bd kk kl km kn ko kp kq kr ks jz kt ka ku kc kv kd kw kf kx kg ky kz bi translated">数据概述</h1><p id="aa4a" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">在任何项目的开始，我总是从 EDA 开始。所以我们来看看数据。我们有一些唯一的 id，评论的文本，药物的名称和情绪(1 是负面的，2 是中性的，0 是正面的)。</p><figure class="mr ms mt mu gt mv gh gi paragraph-image"><div role="button" tabindex="0" class="mw mx di my bf mz"><div class="gh gi nc"><img src="../Images/50161c4090c5eddf556ff1485b888b57.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*fFn4dGLaIpygiBOUKzbS1A.png"/></div></div></figure><p id="90d9" class="pw-post-body-paragraph la lb it lc b ld lw ju lf lg lx jx li lj ly ll lm ln lz lp lq lr ma lt lu lv im bi translated">人们通常会写下他们的疾病、症状和药物。</p><figure class="mr ms mt mu gt mv gh gi paragraph-image"><div class="gh gi nd"><img src="../Images/0fd5223cd6b086efdb894acaf5f16ce0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1080/format:webp/1*AQ0JP8nkyWdWqq2Hq5d0rw.png"/></div></figure><p id="07a6" class="pw-post-body-paragraph la lb it lc b ld lw ju lf lg lx jx li lj ly ll lm ln lz lp lq lr ma lt lu lv im bi translated">训练和测试数据集中的药物有所重叠，但并不完全重叠，有些药物只出现在一个数据集中。</p><p id="9925" class="pw-post-body-paragraph la lb it lc b ld lw ju lf lg lx jx li lj ly ll lm ln lz lp lq lr ma lt lu lv im bi translated">正如我在开始时所写的，大多数文本都很短，但也有一些很长的文本，可能是因为错误而出现在这里。</p><figure class="mr ms mt mu gt mv gh gi paragraph-image"><div role="button" tabindex="0" class="mw mx di my bf mz"><div class="gh gi ne"><img src="../Images/63e8bf6de036840b36203ae505649043.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*vvycqcn2VYRKu_ZXfyqbpQ.png"/></div></div></figure><h1 id="048f" class="ki kj it bd kk kl km kn ko kp kq kr ks jz kt ka ku kc kv kd kw kf kx kg ky kz bi translated">设置基线</h1><p id="cbfa" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">写一个基线通常是一个好主意，它将在以后用作参考，并确保一切正常工作。</p><p id="1943" class="pw-post-body-paragraph la lb it lc b ld lw ju lf lg lx jx li lj ly ll lm ln lz lp lq lr ma lt lu lv im bi translated">主要步骤如下:</p><ul class=""><li id="6039" class="mb mc it lc b ld lw lg lx lj md ln me lr mf lv mg mh mi mj bi translated">处理数据，为建模做准备；</li><li id="0b07" class="mb mc it lc b ld mk lg ml lj mm ln mn lr mo lv mg mh mi mj bi translated">建立模型；</li><li id="0e21" class="mb mc it lc b ld mk lg ml lj mm ln mn lr mo lv mg mh mi mj bi translated">执行验证(可以与训练模型同时进行)；</li></ul><p id="7ffd" class="pw-post-body-paragraph la lb it lc b ld lw ju lf lg lx jx li lj ly ll lm ln lz lp lq lr ma lt lu lv im bi translated">基本的方法是跳过任何文本预处理，使用文本矢量器。我使用 NLTK 的 TweetTokenizer，因为它通常比默认的 sklearn tokenizer 更好。它可以提取表情符号和许多其他有用的令牌。而且使用 n 元单词比单词更好。</p><p id="d74b" class="pw-post-body-paragraph la lb it lc b ld lw ju lf lg lx jx li lj ly ll lm ln lz lp lq lr ma lt lu lv im bi translated">我们可以直接使用<code class="fe nf ng nh ni b">sentiment</code>特征作为目标，因为它已经是数值，并且从 0 开始。</p><pre class="mr ms mt mu gt nj ni nk nl aw nm bi"><span id="955e" class="nn kj it ni b gy no np l nq nr">tokenizer = TweetTokenizer()<br/>vectorizer = TfidfVectorizer(ngram_range=(1, 3), tokenizer=tokenizer.tokenize)<br/>full_text = list(train['text'].values) + list(test['text'].values)<br/>vectorizer.fit(full_text)<br/>train_vectorized = vectorizer.transform(train['text'])<br/>test_vectorized = vectorizer.transform(test['text'])<br/>y = train['sentiment']</span></pre><p id="478c" class="pw-post-body-paragraph la lb it lc b ld lw ju lf lg lx jx li lj ly ll lm ln lz lp lq lr ma lt lu lv im bi translated">我们有一个多类分类问题。有两种主要的方法:为每个类或其他类建立二元分类器，或者为每对类建立二元分类器。我更喜欢第一种方法，并将它与逻辑回归一起使用。</p><pre class="mr ms mt mu gt nj ni nk nl aw nm bi"><span id="d576" class="nn kj it ni b gy no np l nq nr">logreg = LogisticRegression(class_weight='balanced')<br/>ovr = OneVsRestClassifier(logreg)</span></pre><p id="d5a4" class="pw-post-body-paragraph la lb it lc b ld lw ju lf lg lx jx li lj ly ll lm ln lz lp lq lr ma lt lu lv im bi translated">现在有必要建立一种方法来检查我们模型的质量。我们可以简单地分割训练数据，一部分训练模型，另一部分检查质量。但是我更喜欢使用交叉验证。这样我们训练了 N 个模型，验证了 N 次，并且对模型的质量有了更好的度量。因此，我在我们的模型中使用了<code class="fe nf ng nh ni b">cross_val_score</code>函数，使用了<code class="fe nf ng nh ni b">f1_macro</code>指标，因此它将跟随排行榜分数，并定义简单的 3 倍分割。</p><pre class="mr ms mt mu gt nj ni nk nl aw nm bi"><span id="e80b" class="nn kj it ni b gy no np l nq nr">scores = cross_val_score(ovr, train_vectorized, y, scoring='f1_macro', n_jobs=-1, cv=3)<br/>print('Cross-validation mean f1_score {0:.2f}%, std {1:.2f}.'.format(np.mean(scores), np.std(scores)))</span></pre><p id="421d" class="pw-post-body-paragraph la lb it lc b ld lw ju lf lg lx jx li lj ly ll lm ln lz lp lq lr ma lt lu lv im bi translated">交叉验证的得分是 0.4580。现在我们可以对测试数据进行预测，生成提交文件并提交。</p><pre class="mr ms mt mu gt nj ni nk nl aw nm bi"><span id="a93a" class="nn kj it ni b gy no np l nq nr">pred = ovr.predict_proba(test_vectorized)<br/>sub['sentiment'] = pred.argmax(1)<br/>sub.to_csv('sub.csv', index=False)</span></pre><p id="c626" class="pw-post-body-paragraph la lb it lc b ld lw ju lf lg lx jx li lj ly ll lm ln lz lp lq lr ma lt lu lv im bi translated">结果是 0.4499。这是一个好的开始，并且表明我们的验证方案足够好(具有相似的分数)。</p><h2 id="efa2" class="nn kj it bd kk ns nt dn ko nu nv dp ks lj nw nx ku ln ny nz kw lr oa ob ky oc bi translated">改变超参数。第一步。</h2><p id="3d66" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">让我们努力提高分数。第一步是尝试改变预处理步骤。我使用带有 1-3 个 ngrams 和单词的<code class="fe nf ng nh ni b">TfidfVectorizer</code>作为标记。有许多可能的方法来处理文本数据:</p><ul class=""><li id="20e1" class="mb mc it lc b ld lw lg lx lj md ln me lr mf lv mg mh mi mj bi translated">干净的文本。这可能包括将缩写改为完整的单词，删除数字/标点符号/特殊符号，纠正拼写错误等等；</li><li id="d10b" class="mb mc it lc b ld mk lg ml lj mm ln mn lr mo lv mg mh mi mj bi translated">词汇化或词干化以减少独特单词的数量；</li><li id="6189" class="mb mc it lc b ld mk lg ml lj mm ln mn lr mo lv mg mh mi mj bi translated">使用字母/符号作为标记(相对于使用单词)；</li><li id="4972" class="mb mc it lc b ld mk lg ml lj mm ln mn lr mo lv mg mh mi mj bi translated">许多其他想法；</li></ul><p id="8307" class="pw-post-body-paragraph la lb it lc b ld lw ju lf lg lx jx li lj ly ll lm ln lz lp lq lr ma lt lu lv im bi translated">作为第一个实验，我将<code class="fe nf ng nh ni b">TfidfVectorizer</code>参数改为<code class="fe nf ng nh ni b">TfidfVectorizer(ngram_range=(1, 5), analyzer='char'</code>。这使我的交叉验证分数增加到 0.4849，并将公共排行榜上的分数提高到 0.4624。对于改变一行代码来说，这是一个很好的改进，是吗？</p><p id="dc25" class="pw-post-body-paragraph la lb it lc b ld lw ju lf lg lx jx li lj ly ll lm ln lz lp lq lr ma lt lu lv im bi translated">下一个想法:我们可以同时使用单词和字符标记！我们简单地连接矩阵:</p><pre class="mr ms mt mu gt nj ni nk nl aw nm bi"><span id="7fd2" class="nn kj it ni b gy no np l nq nr">vectorizer = TfidfVectorizer(ngram_range=(1, 3), tokenizer=tokenizer.tokenize, stop_words='english')<br/>full_text = list(train['text'].values) + list(test['text'].values)<br/>vectorizer.fit(full_text)<br/>train_vectorized = vectorizer.transform(train['text'])<br/>test_vectorized = vectorizer.transform(test['text'])</span><span id="b4d7" class="nn kj it ni b gy od np l nq nr">vectorizer1 = TfidfVectorizer(ngram_range=(1, 5), analyzer='char')<br/>full_text = list(train['text'].values) + list(test['text'].values)<br/>vectorizer1.fit(full_text)<br/>train_vectorized1 = vectorizer1.transform(train['text'])<br/>test_vectorized1 = vectorizer1.transform(test['text'])</span><span id="4021" class="nn kj it ni b gy od np l nq nr">train_matrix = hstack((train_vectorized, train_vectorized1))<br/>test_matrix = hstack((test_vectorized, test_vectorized1))</span></pre><p id="ac85" class="pw-post-body-paragraph la lb it lc b ld lw ju lf lg lx jx li lj ly ll lm ln lz lp lq lr ma lt lu lv im bi translated">这给了我 0.4930 的交叉验证分数和 0.4820 的排行榜。</p><h2 id="a6d1" class="nn kj it bd kk ns nt dn ko nu nv dp ks lj nw nx ku ln ny nz kw lr oa ob ky oc bi translated">使用文本</h2><p id="a11e" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">正如我在开头所写的——课文包含了大量的信息，但并不是所有的信息都是有用的。人们可以引用其他文本，写长篇故事，比较几种药物等等。</p><p id="45a3" class="pw-post-body-paragraph la lb it lc b ld lw ju lf lg lx jx li lj ly ll lm ln lz lp lq lr ma lt lu lv im bi translated">几次尝试之后，我做了以下事情:</p><pre class="mr ms mt mu gt nj ni nk nl aw nm bi"><span id="e4e6" class="nn kj it ni b gy no np l nq nr">train['new_text'] = train.apply(lambda row: ' '.join([i for i in row.text.lower().split('.') if row.drug in i]), axis=1)</span></pre><p id="ffca" class="pw-post-body-paragraph la lb it lc b ld lw ju lf lg lx jx li lj ly ll lm ln lz lp lq lr ma lt lu lv im bi translated">现在我们有了新的文本，其中只包含提到相关药物的句子。在此之后，我调整了超参数，并以这个矢量器结束:</p><pre class="mr ms mt mu gt nj ni nk nl aw nm bi"><span id="2bc5" class="nn kj it ni b gy no np l nq nr">TfidfVectorizer(ngram_range=(1, 3),  max_df=0.75, min_df=10, sublinear_tf=True)</span></pre><p id="8f7f" class="pw-post-body-paragraph la lb it lc b ld lw ju lf lg lx jx li lj ly ll lm ln lz lp lq lr ma lt lu lv im bi translated">这在交叉验证中得到 0.5206 分，在公共排行榜中得到 0.5279 分。是我选择的提交让我在排行榜上获得了第 21 名。</p><h2 id="2548" class="nn kj it bd kk ns nt dn ko nu nv dp ks lj nw nx ku ln ny nz kw lr oa ob ky oc bi translated">模型口译</h2><p id="22a0" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">了解模型预测的内容和方式通常是一个好主意，这可以带来一些见解，从而改进我们的模型。</p><p id="655a" class="pw-post-body-paragraph la lb it lc b ld lw ju lf lg lx jx li lj ly ll lm ln lz lp lq lr ma lt lu lv im bi translated"><a class="ae mp" href="https://eli5.readthedocs.io/en/latest/overview.html" rel="noopener ugc nofollow" target="_blank"> ELI5 </a>可以这样解释我们的模型并显示预测:</p><figure class="mr ms mt mu gt mv gh gi paragraph-image"><div role="button" tabindex="0" class="mw mx di my bf mz"><div class="gh gi oe"><img src="../Images/67afd714536013da5009d1b0a890eecc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*5kmdRFAjOwOcAVrT5K1uYQ.png"/></div></div></figure><p id="534e" class="pw-post-body-paragraph la lb it lc b ld lw ju lf lg lx jx li lj ly ll lm ln lz lp lq lr ma lt lu lv im bi translated">红色单词意味着这个单词减少了这个类的概率，绿色单词增加了这个类的概率。</p><p id="a253" class="pw-post-body-paragraph la lb it lc b ld lw ju lf lg lx jx li lj ly ll lm ln lz lp lq lr ma lt lu lv im bi translated"><strong class="lc iu">一个更好的解决方案</strong></p><p id="e7a0" class="pw-post-body-paragraph la lb it lc b ld lw ju lf lg lx jx li lj ly ll lm ln lz lp lq lr ma lt lu lv im bi translated">我尝试了很多东西来提高分数:不同的模型(像 SGD)，超参数优化，文本清洗，欠采样，半监督学习和其他东西。让我们看看我的最佳解决方案是如何创建的。</p><ul class=""><li id="08c1" class="mb mc it lc b ld lw lg lx lj md ln me lr mf lv mg mh mi mj bi translated">更好的文本预处理</li></ul><p id="dd77" class="pw-post-body-paragraph la lb it lc b ld lw ju lf lg lx jx li lj ly ll lm ln lz lp lq lr ma lt lu lv im bi translated">清理文本对我不起作用，但我能够改进我缩短文本的方法。现在我不仅用提到药物的那句话，还用下一句话——我觉得人们第一次提到药物后，一般会写点别的。我也只取前 10 个句子:大部分文本都在这个范围内，但也有一些巨大的文本，这会使训练变得更糟。</p><pre class="mr ms mt mu gt nj ni nk nl aw nm bi"><span id="f2af" class="nn kj it ni b gy no np l nq nr">def get_text(row):<br/>    splitted_text = row.text.lower().split('.')<br/>    indices = [splitted_text.index(j) for j in [i for i in splitted_text if row.drug in i]]<br/>    full_indices = []<br/>    for i in indices:<br/>        full_indices.append(i)<br/>        if i &lt; len(splitted_text) -1:<br/>            full_indices.append(i + 1)<br/>    full_indices = list(set(full_indices))<br/>    full_text = []<br/>    for i in full_indices:<br/>        full_text.append(splitted_text[i])<br/>    return ' '.join(full_text[-10:])</span></pre><ul class=""><li id="0ed2" class="mb mc it lc b ld lw lg lx lj md ln me lr mf lv mg mh mi mj bi translated">超参数优化</li></ul><p id="fb0d" class="pw-post-body-paragraph la lb it lc b ld lw ju lf lg lx jx li lj ly ll lm ln lz lp lq lr ma lt lu lv im bi translated">超参数优化总是很重要。Sklearn API 允许使用方便的语法构建管道并优化它们:</p><pre class="mr ms mt mu gt nj ni nk nl aw nm bi"><span id="26cb" class="nn kj it ni b gy no np l nq nr">combined_features = FeatureUnion([('tfidf', TfidfVectorizer(ngram_range=(1, 3))),<br/>                                  ('tfidf_char', TfidfVectorizer(ngram_range=(1, 3), analyzer='char'))])<br/>pipeline = Pipeline([("features", combined_features),<br/>                     ('clf', OneVsRestClassifier(LogisticRegression(class_weight='balanced')))])</span><span id="61d3" class="nn kj it ni b gy od np l nq nr">parameters = {<br/>    'features__tfidf__max_df': (0.3, 0.75),<br/>    'features__tfidf_char__max_df': (0.3, 0.75),    <br/>    'clf__estimator__C': (1.0, 10.0)<br/>}<br/>grid_search = GridSearchCV(pipeline, parameters, cv=folds,<br/>                               n_jobs=-1, verbose=1, scoring='f1_macro')<br/>grid_search.fit(train['new_text'], train['sentiment'])</span></pre><p id="1a63" class="pw-post-body-paragraph la lb it lc b ld lw ju lf lg lx jx li lj ly ll lm ln lz lp lq lr ma lt lu lv im bi translated">这样，我们可以优化两个矢量器和“OneVsRestClassifier”中的逻辑回归模型的参数。</p><ul class=""><li id="b21f" class="mb mc it lc b ld lw lg lx lj md ln me lr mf lv mg mh mi mj bi translated">欠采样</li></ul><p id="1d56" class="pw-post-body-paragraph la lb it lc b ld lw ju lf lg lx jx li lj ly ll lm ln lz lp lq lr ma lt lu lv im bi translated">我已经决定，可能是阶级不平衡太严重了，应该对此采取一些措施。有许多方法可以处理它:欠采样，过采样，SMOTE，改变类不平衡。你可以注意到我使用了平衡类权重的逻辑回归，但是这还不够。经过几次尝试，我决定做一个简单的欠采样，随机抽取 2000 个中性类样本。</p><ul class=""><li id="9997" class="mb mc it lc b ld lw lg lx lj md ln me lr mf lv mg mh mi mj bi translated">半监督学习</li></ul><p id="47e9" class="pw-post-body-paragraph la lb it lc b ld lw ju lf lg lx jx li lj ly ll lm ln lz lp lq lr ma lt lu lv im bi translated">这个想法很简单:在我们训练了我们的模型之后，它应该给出很好的预测(嗯，至少我们希望如此:)，大多数有信心的预测应该是正确的，或者至少是大部分正确的。我选取了 1000 个最佳预测，并将它们添加到训练数据集中。在增加的数据集上训练了一个新模型后，我在公开排行榜上得到了 0.5169。这个提交在私人排行榜上的价值是 0.5525，但我没有足够的信任去选择它。</p><h1 id="f204" class="ki kj it bd kk kl km kn ko kp kq kr ks jz kt ka ku kc kv kd kw kf kx kg ky kz bi translated">结论</h1><p id="cadb" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">一方面，使用更传统的 ML 方法可能获得高结果，另一方面，现在这些方法不足以击败使用预训练模型的深度学习。这是否意味着更简单的模型没有用武之地？我认为，有时在商业中使用逻辑回归可能是合理的:它建立起来更快，更容易解释，需要的资源更少。然而，从长远来看，使用深度学习是一种成功的方式。</p></div></div>    
</body>
</html>