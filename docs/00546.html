<html>
<head>
<title>Deploy your machine learning models with tensorflow serving and kubernetes</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用 tensorflow 服务和 kubernetes 部署您的机器学习模型</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/deploy-your-machine-learning-models-with-tensorflow-serving-and-kubernetes-9d9e78e569db?source=collection_archive---------6-----------------------#2019-01-25">https://towardsdatascience.com/deploy-your-machine-learning-models-with-tensorflow-serving-and-kubernetes-9d9e78e569db?source=collection_archive---------6-----------------------#2019-01-25</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><figure class="gl gn jo jp jq jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi jn"><img src="../Images/2a06a82376205f742abdfd8296255fef.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*JbRs8n8Vm3xsyhuHD4GuFg.png"/></div></div></figure><p id="230c" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">机器学习应用正在蓬勃发展，但数据工程师没有很多工具可以将这些强大的模型集成到生产系统中。在这里，我将讨论 tensorflow-serving 如何帮助您在产品中加速交付模型。这篇博文是关于服务机器学习模型的— <em class="kw">什么意思？</em></p><blockquote class="kx ky kz"><p id="17b1" class="jy jz kw ka b kb kc kd ke kf kg kh ki la kk kl km lb ko kp kq lc ks kt ku kv ij bi translated">服务是你如何在训练后应用一个 ML 模型——从事 tensorflow 服务的 Noah Fiedel 软件工程师</p></blockquote></div><div class="ab cl ld le hu lf" role="separator"><span class="lg bw bk lh li lj"/><span class="lg bw bk lh li lj"/><span class="lg bw bk lh li"/></div><div class="ij ik il im in"><p id="3e23" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">为了说明<a class="ae lk" href="https://www.tensorflow.org/serving/" rel="noopener ugc nofollow" target="_blank"> tensorflow 服务于</a>的能力，我将介绍服务于对象检测模型的步骤。在我的 GitHub 上找到与本文相关的所有代码:<a class="ae lk" href="https://github.com/fpaupier/tensorflow-serving_sidecar" rel="noopener ugc nofollow" target="_blank">https://github.com/fpaupier/tensorflow-serving_sidecar</a></p><figure class="lm ln lo lp gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi ll"><img src="../Images/20aaa4c94e282d0a161b651fcf83f1d1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*u1gb4jbIjJmeNDxtkONWXA.png"/></div></div><figcaption class="lq lr gj gh gi ls lt bd b be z dk">Summary of a machine learning pipeline — here we focus on serving the model</figcaption></figure><p id="6bd0" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated"><em class="kw">张量流简而言之</em></p><p id="ac24" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">Tensorflow 服务使您能够无缝地服务于您的机器学习模型。</p><ul class=""><li id="361a" class="lu lv iq ka b kb kc kf kg kj lw kn lx kr ly kv lz ma mb mc bi translated">部署新版本的模型，让 tensorflow 服务优雅地完成当前请求，同时开始使用新模型服务新请求。</li><li id="29af" class="lu lv iq ka b kb md kf me kj mf kn mg kr mh kv lz ma mb mc bi translated">分开考虑，数据科学家可以专注于构建出色的模型，而运营部门则可以专注于构建可服务于这些模型的高度灵活且可扩展的架构。</li></ul></div><div class="ab cl ld le hu lf" role="separator"><span class="lg bw bk lh li lj"/><span class="lg bw bk lh li lj"/><span class="lg bw bk lh li"/></div><div class="ij ik il im in"><h1 id="eee1" class="mi mj iq bd mk ml mm mn mo mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne nf bi translated">第 1 部分—预热:设置本地 tensorflow 服务器</h1><p id="e033" class="pw-post-body-paragraph jy jz iq ka b kb ng kd ke kf nh kh ki kj ni kl km kn nj kp kq kr nk kt ku kv ij bi translated">在上线之前，最好确保你的服务器在本地工作。我在这里给出了大的步骤，在项目<code class="fe nl nm nn no b">readme</code>中找到更多的文档。<br/> <a class="ae lk" href="https://github.com/fpaupier/tensorflow-serving_sidecar/blob/master/docs/setup.md" rel="noopener ugc nofollow" target="_blank">看看设置步骤</a>以确保您能从本教程中获得最大收益:</p><ol class=""><li id="6fb0" class="lu lv iq ka b kb kc kf kg kj lw kn lx kr ly kv np ma mb mc bi translated">git 克隆<a class="ae lk" href="https://github.com/fpaupier/tensorflow-serving_sidecar" rel="noopener ugc nofollow" target="_blank">https://github.com/fpaupier/tensorflow-serving_sidecar</a>，创建 python3.6.5 虚拟环境并安装<code class="fe nl nm nn no b">requirements.txt</code></li><li id="f197" class="lu lv iq ka b kb md kf me kj mf kn mg kr mh kv np ma mb mc bi translated">获取 tensorflow 服务 docker 图片<code class="fe nl nm nn no b">docker pull tensorflow/serving</code></li><li id="cfed" class="lu lv iq ka b kb md kf me kj mf kn mg kr mh kv np ma mb mc bi translated">得到一个模型来服务→我用这个，它执行对象检测<a class="ae lk" href="http://download.tensorflow.org/models/object_detection/faster_rcnn_resnet101_coco_2018_01_28.tar.gz" rel="noopener ugc nofollow" target="_blank">更快 _rcnn_resnet101_coco </a></li><li id="ec97" class="lu lv iq ka b kb md kf me kj mf kn mg kr mh kv np ma mb mc bi translated">转到模型目录，用版本号重命名<code class="fe nl nm nn no b">saved model</code>子目录，因为我们在这里做的是 v1，让我们称它为<code class="fe nl nm nn no b">00001</code>(它必须是数字)。我们这样做是因为 tensorflow serving docker image 在搜索要提供的模型时会搜索以该约定命名的文件夹。</li><li id="fcfa" class="lu lv iq ka b kb md kf me kj mf kn mg kr mh kv np ma mb mc bi translated">现在运行 tensorflow 服务器:</li></ol><pre class="lm ln lo lp gt nq no nr ns aw nt bi"><span id="e26e" class="nu mj iq no b gy nv nw l nx ny"># From tensorflow-serving_sidecar/<br/>docker run -t --rm -p 8501:8501 \<br/>   -v "$(pwd)/data/faster_rcnn_resnet101_coco_2018_01_28:/models/faster_rcnn_resnet" \<br/>   -e MODEL_NAME=faster_rcnn_resnet \<br/>   tensorflow/serving &amp;</span></pre><p id="893c" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">在继续之前，请注意:</p><figure class="lm ln lo lp gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi nz"><img src="../Images/72752a00c433b785e6113df364fc500e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*oCzPBR-ZYFGoKHCBEBhgag.jpeg"/></div></div><figcaption class="lq lr gj gh gi ls lt bd b be z dk">docker -v arg in our use case</figcaption></figure><p id="1046" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">这里我们绑定了容器的端口和本地主机。因此，当我们在<code class="fe nl nm nn no b">localhost:8501</code>上调用推断时，我们实际上将调用 tensorflow 服务器。</p><p id="31fd" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">您还会注意到我们将本地主机目录<code class="fe nl nm nn no b">faster_rcnn_resnet101_coco_2018_01_28</code>——存储模型的地方——与容器<code class="fe nl nm nn no b">/models/faster_rcnn_resnet</code>路径链接起来。</p><p id="30ed" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">请记住，此时<code class="fe nl nm nn no b">savedModel.pb</code>只在您的机器上，而不在容器中。</p><p id="df05" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">6.执行客户呼叫:</p><pre class="lm ln lo lp gt nq no nr ns aw nt bi"><span id="4419" class="nu mj iq no b gy nv nw l nx ny"># Don't forget to activate your python3.6.5 venv<br/><br/># From tensorflow-serving_sidecar/<br/>python client.py --server_url "http://localhost:8501/v1/models/faster_rcnn_resnet:predict" \<br/>--image_path "$(pwd)/object_detection/test_images/image1.jpg" \<br/>--output_json "$(pwd)/object_detection/test_images/out_image1.json" \<br/>--save_output_image "True" \<br/>--label_map "$(pwd)/data/labels.pbtxt"</span></pre><p id="7f43" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">去查看<code class="fe nl nm nn no b">--output_json </code>指定的路径，享受结果。(提供 json 和 jpeg 输出)</p><figure class="lm ln lo lp gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi oa"><img src="../Images/4c9dd8b370c77bdb8d8e1611362ce6e0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1300/format:webp/1*7rMW1PVA7g6Sbh4w8xFtUg.jpeg"/></div></div><figcaption class="lq lr gj gh gi ls lt bd b be z dk">expected inference with our object detection model</figcaption></figure><p id="0bc3" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">很好，现在我们的模型运行良好，让我们将它部署到云上。</p></div><div class="ab cl ld le hu lf" role="separator"><span class="lg bw bk lh li lj"/><span class="lg bw bk lh li lj"/><span class="lg bw bk lh li"/></div><div class="ij ik il im in"><h1 id="29ce" class="mi mj iq bd mk ml mm mn mo mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne nf bi translated">第 2 部分—在具有 tensorflow 服务的 kubernetes 集群上服务您的机器学习应用程序</h1><p id="7a52" class="pw-post-body-paragraph jy jz iq ka b kb ng kd ke kf nh kh ki kj ni kl km kn nj kp kq kr nk kt ku kv ij bi translated">在生产环境中，您希望能够随着应用程序负载的增加而扩展。你不希望你的服务器不堪重负。</p><figure class="lm ln lo lp gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi ob"><img src="../Images/95aed95ad261b4b86fa833caa93e66d5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Jx5Dj0s00JbFtMosWDB0Sw.png"/></div></div><figcaption class="lq lr gj gh gi ls lt bd b be z dk">An exhausted tensorflow server directly exposed over the network</figcaption></figure><p id="1655" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">为了避免这个问题，您将使用 kubernetes 集群来服务您的 tensorflow-server 应用程序。预期的主要改进:</p><ul class=""><li id="0dd0" class="lu lv iq ka b kb kc kf kg kj lw kn lx kr ly kv lz ma mb mc bi translated">负载将在您的副本之间平衡，您无需考虑这一点。</li><li id="d20b" class="lu lv iq ka b kb md kf me kj mf kn mg kr mh kv lz ma mb mc bi translated">您是否希望在不停机的情况下部署新模型？没问题，kubernetes 支持你。执行滚动更新，逐步为您的新模型提供服务，同时适度终止旧模型上的当前请求。</li></ul><figure class="lm ln lo lp gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi oc"><img src="../Images/1c417cc48a4de81d9aa09fe04b000d82.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*SZ6-Iwo1fgraBQARcsCfqA.png"/></div></div><figcaption class="lq lr gj gh gi ls lt bd b be z dk">a tensorflow server application running on many replicas in a k8s cluster, ensuring high availability to users</figcaption></figure><p id="d0c8" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated"><strong class="ka ir">我们开始吧</strong></p><p id="c587" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">首先，我们想要创建一个嵌入了对象检测模型的完整 docker 图像。一旦完成，我们将在 kubernetes 集群上部署它。我在<a class="ae lk" href="https://cloud.google.com/" rel="noopener ugc nofollow" target="_blank">谷歌云平台</a>上运行我的例子，因为免费层使得免费运行这个教程成为可能。为了帮助你在 GCP 建立云环境，你可以点击这里查看我的教程。</p><h2 id="999b" class="nu mj iq bd mk od oe dn mo of og dp ms kj oh oi mw kn oj ok na kr ol om ne on bi translated">创建自定义 tensorflow 服务 docker 图像</h2><ol class=""><li id="0924" class="lu lv iq ka b kb ng kf nh kj oo kn op kr oq kv np ma mb mc bi translated">将服务映像作为守护程序运行:</li></ol><pre class="lm ln lo lp gt nq no nr ns aw nt bi"><span id="5df2" class="nu mj iq no b gy nv nw l nx ny">docker run -d --name serving_base tensorflow/serving</span></pre><p id="932a" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">2.将<code class="fe nl nm nn no b">faster_rcnn_resnet101_coco</code>模型数据复制到容器的<code class="fe nl nm nn no b">models/</code>文件夹中:</p><pre class="lm ln lo lp gt nq no nr ns aw nt bi"><span id="91e2" class="nu mj iq no b gy nv nw l nx ny"># From tensorflow-serving_sidecar/<br/>docker cp $(pwd)/data/faster_rcnn_resnet101_coco_2018_01_28 serving_base:/models/faster_rcnn_resnet</span></pre><p id="5d39" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">3.提交容器以服务于<code class="fe nl nm nn no b">faster_rcnn_resnet</code>模型:</p><pre class="lm ln lo lp gt nq no nr ns aw nt bi"><span id="ee22" class="nu mj iq no b gy nv nw l nx ny">docker commit --change "ENV MODEL_NAME faster_rcnn_resnet" serving_base faster_rcnn_resnet_serving</span></pre><p id="bdf5" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated"><em class="kw">注意:</em>如果您使用不同的型号，相应地更改<code class="fe nl nm nn no b">--change</code>参数中的<code class="fe nl nm nn no b">faster_rcnn_resnet</code>。</p><p id="5c47" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated"><code class="fe nl nm nn no b">faster_rcnn_resnet_serving</code>将成为我们新的服务形象。您可以通过运行<code class="fe nl nm nn no b">docker images</code>来检查这一点，您应该会看到一个新的 docker 图像:</p><figure class="lm ln lo lp gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi or"><img src="../Images/75b310f8ff1895830118302330223e26.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*NO7yue0KJ_apO8I9-X0_8g.png"/></div></div><figcaption class="lq lr gj gh gi ls lt bd b be z dk">docker images result after creating a custom tensorflow-serving image</figcaption></figure><p id="ad43" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">4.停止服务基本容器</p><pre class="lm ln lo lp gt nq no nr ns aw nt bi"><span id="aca2" class="nu mj iq no b gy nv nw l nx ny">docker kill serving_base<br/>docker rm serving_base</span></pre><p id="56ff" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">太好了，下一步是测试我们全新的<code class="fe nl nm nn no b">faster_rcnn_resnet_serving </code>形象。</p><h2 id="e45e" class="nu mj iq bd mk od oe dn mo of og dp ms kj oh oi mw kn oj ok na kr ol om ne on bi translated">测试定制服务器</h2><p id="d16e" class="pw-post-body-paragraph jy jz iq ka b kb ng kd ke kf nh kh ki kj ni kl km kn nj kp kq kr nk kt ku kv ij bi translated">在 kubernetes 上部署我们的应用程序之前，让我们确保它正常工作。</p><ol class=""><li id="cd70" class="lu lv iq ka b kb kc kf kg kj lw kn lx kr ly kv np ma mb mc bi translated">启动服务器:</li></ol><pre class="lm ln lo lp gt nq no nr ns aw nt bi"><span id="6de4" class="nu mj iq no b gy nv nw l nx ny">docker run -p 8501:8501 -t faster_rcnn_resnet_serving &amp;</span></pre><p id="3a23" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated"><em class="kw">注意:</em>确保您已经停止(<code class="fe nl nm nn no b">docker stop &lt;CONTAINER_NAME&gt;</code>)之前运行的服务器，否则端口<code class="fe nl nm nn no b">8501</code>可能会被锁定。</p><p id="4e45" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">2.我们可以使用相同的客户端代码来调用服务器。</p><pre class="lm ln lo lp gt nq no nr ns aw nt bi"><span id="8de9" class="nu mj iq no b gy nv nw l nx ny"># From tensorflow-serving_sidecar/<br/>python client.py --server_url "http://localhost:8501/v1/models/faster_rcnn_resnet:predict" \<br/>--image_path "$(pwd)/object_detection/test_images/image1.jpg" \<br/>--output_json "$(pwd)/object_detection/test_images/out_image2.json" \<br/>--save_output_image "True" \<br/>--label_map "$(pwd)/data/labels.pbtxt"</span></pre><p id="b6bf" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">我们可以检查我们是否有相同的好的，现在让我们在<code class="fe nl nm nn no b">kubernetes</code>集群上运行它。</p><h2 id="ecde" class="nu mj iq bd mk od oe dn mo of og dp ms kj oh oi mw kn oj ok na kr ol om ne on bi translated">在 kubernetes 上部署我们的应用</h2><p id="2293" class="pw-post-body-paragraph jy jz iq ka b kb ng kd ke kf nh kh ki kj ni kl km kn nj kp kq kr nk kt ku kv ij bi translated">除非你已经在 GCP 上运行了一个项目，否则我建议你检查一下<a class="ae lk" href="https://github.com/fpaupier/tensorflow-serving_sidecar/blob/master/docs/gcp_setup.md" rel="noopener ugc nofollow" target="_blank">谷歌云设置步骤</a>。</p><p id="343c" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">我假设你已经创建并登录了一个名为<code class="fe nl nm nn no b">tensorflow-serving</code>的<code class="fe nl nm nn no b">gcloud</code>项目</p><p id="3002" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">您将使用之前构建的容器映像<code class="fe nl nm nn no b">faster_rcnn_resnet_serving</code>在<a class="ae lk" href="https://cloud.google.com/" rel="noopener ugc nofollow" target="_blank"> Google 云平台</a>中部署带有<a class="ae lk" href="https://kubernetes.io/" rel="noopener ugc nofollow" target="_blank"> Kubernetes </a>的服务集群。</p><ol class=""><li id="8cd7" class="lu lv iq ka b kb kc kf kg kj lw kn lx kr ly kv np ma mb mc bi translated">登录您的项目，首先用<code class="fe nl nm nn no b">gcloud projects list</code>列出可用的项目，选择项目的<code class="fe nl nm nn no b">PROJECT_ID</code>并运行</li></ol><pre class="lm ln lo lp gt nq no nr ns aw nt bi"><span id="241a" class="nu mj iq no b gy nv nw l nx ny"># Get the PROJECT_ID, not the name<br/>gcloud projects list </span><span id="6d04" class="nu mj iq no b gy os nw l nx ny"># Set the project with the right PROJECT_ID, i.e. for me it is tensorflow-serving-229609<br/>gcloud config set project tensorflow-serving-229609<br/>gcloud auth login</span></pre><p id="61eb" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">2.创建一个容器集群</p><ul class=""><li id="5af4" class="lu lv iq ka b kb kc kf kg kj lw kn lx kr ly kv lz ma mb mc bi translated">首先，我们为服务部署创建一个<a class="ae lk" href="https://cloud.google.com/container-engine/" rel="noopener ugc nofollow" target="_blank"> Google Kubernetes 引擎</a>集群。由于免费试用的限制，您在这里不能使用超过 2 个节点，您可以升级或使用两个节点，这对我们的用例来说已经足够好了。在你的免费试用中，你的限额是 8 个 CPU。)</li></ul><pre class="lm ln lo lp gt nq no nr ns aw nt bi"><span id="22ad" class="nu mj iq no b gy nv nw l nx ny">gcloud container clusters create faster-rcnn-serving-cluster --num-nodes 2 --zone 'us-east1'</span></pre><p id="82be" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">您可以更新<code class="fe nl nm nn no b">zone</code> arg，您可以在<em class="kw">中选择，例如</em> : <code class="fe nl nm nn no b">europe-west1</code>，<code class="fe nl nm nn no b">asia-east1</code> -您可以使用<code class="fe nl nm nn no b">gcloud compute zones list</code>检查所有可用的区域。你应该有这样的东西:</p><figure class="lm ln lo lp gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi ot"><img src="../Images/494904ca822443354cdcbc6179db50ae.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*MXrZekqAqVIDQShZ-k7QrQ.png"/></div></div><figcaption class="lq lr gj gh gi ls lt bd b be z dk">kubernetes cluster creation output</figcaption></figure><p id="6859" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">3.为 gcloud container 命令设置默认集群，并将集群凭证传递给<a class="ae lk" href="https://kubernetes.io/docs/reference/kubectl/overview/" rel="noopener ugc nofollow" target="_blank"> kubectl </a>。</p><pre class="lm ln lo lp gt nq no nr ns aw nt bi"><span id="1a8f" class="nu mj iq no b gy nv nw l nx ny">gcloud config set container/cluster faster-rcnn-serving-cluster<br/>gcloud container clusters get-credentials faster-rcnn-serving-cluster --zone 'us-east1'</span></pre><p id="1fd5" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">之后您应该会看到这样的内容:</p><figure class="lm ln lo lp gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi ou"><img src="../Images/f3579e4e6d0fc1e02ea538d6c7c88246.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*fZ3THPtLIHBWvn6ca0kANA.png"/></div></div><figcaption class="lq lr gj gh gi ls lt bd b be z dk">gcloud container clusters get-credentials output</figcaption></figure><p id="724b" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">4.上传我们之前构建的自定义 tensorflow 服务 docker 图像。让我们将我们的图像推送到<a class="ae lk" href="https://cloud.google.com/container-registry/docs/" rel="noopener ugc nofollow" target="_blank"> Google 容器注册表</a>，这样我们就可以在 Google 云平台上运行它。</p><p id="bb94" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">使用容器注册表格式和我们的项目 id 标记<code class="fe nl nm nn no b">faster_rcnn_resnet_serving</code>图像，用您的<code class="fe nl nm nn no b">PROJECT_ID</code>更改<code class="fe nl nm nn no b">tensorflow-serving-229609</code>。最后还要修改标签，这是我们的第一个版本，所以我把标签设为<code class="fe nl nm nn no b">v0.1.0</code>。</p><pre class="lm ln lo lp gt nq no nr ns aw nt bi"><span id="4eed" class="nu mj iq no b gy nv nw l nx ny">docker tag faster_rcnn_resnet_serving gcr.io/tensorflow-serving-229609/faster_rcnn_resnet_serving:v0.1.0</span></pre><p id="2d27" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">如果你运行<code class="fe nl nm nn no b">docker images</code>，你现在会看到一个额外的<code class="fe nl nm nn no b">gcr.io/tensorflow-serving-229609/faster_rcnn_resnet_serving:v0.1.0</code>图像。</p><p id="950a" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">这个<code class="fe nl nm nn no b">gcr.io</code>前缀允许我们将图像直接推送到容器注册中心，</p><pre class="lm ln lo lp gt nq no nr ns aw nt bi"><span id="2e64" class="nu mj iq no b gy nv nw l nx ny"># To do only once<br/>gcloud auth configure-docker</span><span id="8876" class="nu mj iq no b gy os nw l nx ny">docker push gcr.io/tensorflow-serving-229609/faster_rcnn_resnet_serving:v0.1.0</span></pre><p id="7cce" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">您已经成功地将您的图像推送到 GCP 集装箱注册中心，您可以在线查看:</p><figure class="lm ln lo lp gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi ov"><img src="../Images/2733008e38eead7638fe5b4a441d5f13.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*QoM7Wpdm33TZil_5xX9oGQ.png"/></div></div><figcaption class="lq lr gj gh gi ls lt bd b be z dk">docker image successfully pushed on Google Container Registry</figcaption></figure><p id="8495" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">5.创建 Kubernetes 部署和服务</p><p id="2994" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">该部署由一个由<a class="ae lk" href="https://kubernetes.io/docs/concepts/workloads/controllers/deployment/" rel="noopener ugc nofollow" target="_blank"> Kubernetes 部署</a>控制的 fast-rcnn 推理服务器的单一副本组成。副本通过<a class="ae lk" href="https://kubernetes.io/docs/concepts/services-networking/service/" rel="noopener ugc nofollow" target="_blank"> Kubernetes 服务</a>和<a class="ae lk" href="https://kubernetes.io/docs/tasks/access-application-cluster/create-external-load-balancer/" rel="noopener ugc nofollow" target="_blank">外部负载平衡器</a>对外公开。</p><p id="a5e4" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">使用单个副本实际上没有意义。我这样做只是为了在自由层内通过。如果您只有一个实例来指导您的查询，那么负载平衡是没有用的。在生产设置中，使用多个副本。</p><p id="276c" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">我们使用示例 Kubernetes config<a class="ae lk" href="https://github.com/fpaupier/tensorflow-serving_sidecar/blob/master/faster_rcnn_resnet_k8s.yaml" rel="noopener ugc nofollow" target="_blank">faster _ rcnn _ resnet _ k8s . YAML</a>来创建它们。您只需要更新 docker 图像以在文件中使用，用您的实际图像全名替换行<code class="fe nl nm nn no b">image: &lt;YOUR_FULL_IMAGE_NAME_HERE&gt;</code>，看起来像这样:</p><pre class="lm ln lo lp gt nq no nr ns aw nt bi"><span id="5745" class="nu mj iq no b gy nv nw l nx ny">image: gcr.io/tensorflow-serving-229609/faster_rcnn_resnet_serving@sha256:9f7eca6da7d833b240f7c54b630a9f85df8dbdfe46abe2b99651278dc4b13c53</span></pre><p id="b8bb" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">您可以在容器注册表中找到它:</p><figure class="lm ln lo lp gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi ow"><img src="../Images/5b1d26e761c5c81e8cb7c49e64cd04f7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*5d9pt3RpzfmXMrkZCcHXzw.png"/></div></div><figcaption class="lq lr gj gh gi ls lt bd b be z dk">find your docker full image name on google container registry</figcaption></figure><p id="1a66" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">然后运行以下命令</p><pre class="lm ln lo lp gt nq no nr ns aw nt bi"><span id="0e3a" class="nu mj iq no b gy nv nw l nx ny"># From tensorflow-serving_sidecar/<br/>kubectl create -f faster_rcnn_resnet_k8s.yaml</span></pre><p id="29e0" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">要检查部署和 pod 的状态，请使用<code class="fe nl nm nn no b">kubectl get deployments</code>来监视整个部署，使用<code class="fe nl nm nn no b">kubectl get pods</code>来监视部署的每个副本，使用<code class="fe nl nm nn no b">kubectl get services</code>来监视服务。</p><figure class="lm ln lo lp gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi ox"><img src="../Images/a517c70f5adb2a392a692c9e169c0132.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Bbh5PObnAp86RDNwade-jw.png"/></div></div><figcaption class="lq lr gj gh gi ls lt bd b be z dk">sanity check for deployment</figcaption></figure><p id="f9df" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">一切正常运行可能需要一段时间。服务外部<code class="fe nl nm nn no b">IP</code>地址列在负载平衡器入口的旁边。您可以使用<code class="fe nl nm nn no b">kubectl describe service</code>命令来检查它:</p><pre class="lm ln lo lp gt nq no nr ns aw nt bi"><span id="a4e3" class="nu mj iq no b gy nv nw l nx ny">kubectl describe service faster-rcnn-resnet-service</span></pre><figure class="lm ln lo lp gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi oy"><img src="../Images/8729214487fde65313f4e5775648c0f4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*oVF9YMFtJDvlJZI6hXVTqg.png"/></div></div><figcaption class="lq lr gj gh gi ls lt bd b be z dk">find the IP address to query upon to perform inference</figcaption></figure><h2 id="3ef6" class="nu mj iq bd mk od oe dn mo of og dp ms kj oh oi mw kn oj ok na kr ol om ne on bi translated">查询您的在线模型</h2><p id="98a9" class="pw-post-body-paragraph jy jz iq ka b kb ng kd ke kf nh kh ki kj ni kl km kn nj kp kq kr nk kt ku kv ij bi translated">最后，让我们来测试一下。我们可以使用相同的<a class="ae lk" href="https://github.com/fpaupier/tensorflow-serving_sidecar/blob/master/client.py" rel="noopener ugc nofollow" target="_blank">客户端代码</a>。简单地将前面使用的<code class="fe nl nm nn no b">--server-url</code>参数中的<code class="fe nl nm nn no b">localhost</code>替换为上面指定的负载平衡器入口的<code class="fe nl nm nn no b">IP</code>地址。</p><pre class="lm ln lo lp gt nq no nr ns aw nt bi"><span id="67c0" class="nu mj iq no b gy nv nw l nx ny"># From tensorflow-serving_sidecar/<br/>python client.py --server_url "http://34.73.137.228:8501/v1/models/faster_rcnn_resnet:predict" \<br/>--image_path "$(pwd)/object_detection/test_images/image1.jpg" \<br/>--output_json "$(pwd)/object_detection/test_images/out_image3.json" \<br/>--save_output_image "True" \<br/>--label_map "$(pwd)/data/labels.pbtxt"</span></pre><h1 id="a453" class="mi mj iq bd mk ml oz mn mo mp pa mr ms mt pb mv mw mx pc mz na nb pd nd ne nf bi translated">外卖食品</h1><p id="6d8d" class="pw-post-body-paragraph jy jz iq ka b kb ng kd ke kf nh kh ki kj ni kl km kn nj kp kq kr nk kt ku kv ij bi translated">Tensorflow 服务提供了一个很好的基础，您可以依靠它以很少的开销在生产中快速部署您的模型。</p><ul class=""><li id="62e1" class="lu lv iq ka b kb kc kf kg kj lw kn lx kr ly kv lz ma mb mc bi translated">机器学习应用程序的容器化部署能够<em class="kw">分离运营和数据科学家之间的关注点</em></li><li id="708b" class="lu lv iq ka b kb md kf me kj mf kn mg kr mh kv lz ma mb mc bi translated">Kubernetes 等容器编排解决方案与 tensorflow-serving 相结合，为不熟悉分布式计算的人提供了在几分钟内部署高可用性模型的可能性。</li></ul><p id="e80e" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated"><strong class="ka ir">资源📚</strong></p><ul class=""><li id="90f4" class="lu lv iq ka b kb kc kf kg kj lw kn lx kr ly kv lz ma mb mc bi translated">Tensorflow 服务由谷歌的软件工程师 Noah Fiedel 解释，他从事 Tensorflow 服务。它让我们深入了解它是如何建造的以及建造的目的是什么<a class="ae lk" href="https://www.youtube.com/watch?v=q_IkJcPyNl0" rel="noopener ugc nofollow" target="_blank">https://www.youtube.com/watch?v=q_IkJcPyNl0</a></li><li id="3622" class="lu lv iq ka b kb md kf me kj mf kn mg kr mh kv lz ma mb mc bi translated">免费提供预训练模型库<a class="ae lk" href="https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/detection_model_zoo.md" rel="noopener ugc nofollow" target="_blank">https://github . com/tensor flow/models/blob/master/research/object _ detection/g3doc/detection _ model _ zoo . MD</a></li><li id="320f" class="lu lv iq ka b kb md kf me kj mf kn mg kr mh kv lz ma mb mc bi translated">Tyler Labonte medium post 将 tensorflow 模型导出为保存的检查点<a class="ae lk" href="https://medium.com/@tmlabonte/serving-image-based-deep-learning-models-with-tensorflow-servings-restful-api-d365c16a7dc4" rel="noopener">https://medium . com/@ tmlabonte/serving-image-based-deep-learning-models-with-tensor flow-servings-restful-API-d 365 c 16 a7 DC 4</a></li><li id="a141" class="lu lv iq ka b kb md kf me kj mf kn mg kr mh kv lz ma mb mc bi translated">提供一个没有合适框架的 ML 模型是多么麻烦的例子<a class="ae lk" rel="noopener" target="_blank" href="/how-to-build-and-deploy-a-lyrics-generation-model-framework-agnostic-589f3026fd53">https://towardsdatascience . com/how-to-build-and-deploy-a-lyrics-generation-model-framework-agnostic-589 f 3026 FD 53</a></li><li id="edd6" class="lu lv iq ka b kb md kf me kj mf kn mg kr mh kv lz ma mb mc bi translated">Cloud ML，用于部署 ML 模型的 Google 托管解决方案:<a class="ae lk" href="https://cloud.google.com/ml-engine/docs/tensorflow/deploying-models" rel="noopener ugc nofollow" target="_blank">https://cloud . Google . com/ML-engine/docs/tensor flow/deploying-models</a></li></ul></div></div>    
</body>
</html>