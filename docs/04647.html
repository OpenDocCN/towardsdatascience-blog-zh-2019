<html>
<head>
<title>Group thousands of similar spreadsheet text cells in seconds</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">在几秒钟内将数千个相似的电子表格文本单元格分组</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/group-thousands-of-similar-spreadsheet-text-cells-in-seconds-2493b3ce6d8d?source=collection_archive---------3-----------------------#2019-07-16">https://towardsdatascience.com/group-thousands-of-similar-spreadsheet-text-cells-in-seconds-2493b3ce6d8d?source=collection_archive---------3-----------------------#2019-07-16</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="4c88" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">用 TF-IDF 和余弦相似度在 Python 中进行字符串匹配</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ki"><img src="../Images/8faaede317796c09801afd96f2818aa8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*QNp4TNCNwo1HMqjFV4jq1g.png"/></div><figcaption class="kq kr gj gh gi ks kt bd b be z dk">This image — explained below — visualizes the cosine similarity of a document term matrix in a multidimensional space.</figcaption></figure><p id="1eb4" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">下面是一个常见的电子表格或数据库问题:</p><pre class="kj kk kl km gt lq lr ls lt aw lu bi"><span id="4f52" class="lv lw it lr b gy lx ly l lz ma">+-----+-------------------+<br/>| row |     fullname      |<br/>+-----+-------------------+<br/>|   1 | John F. Doe       |<br/>|   2 | Esquivel, Mara    |<br/>|   3 | Doe, John F       |<br/>|   4 | Whyte, Luke       |<br/>|   5 | Doe, John Francis |<br/>+-----+-------------------+</span></pre><p id="67b6" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">第 1、3 和 5 行可能指的是同一个人，只是在拼写和格式上略有不同。在小型数据集中，可以手动清理像元。但是在巨大的数据集中呢？我们如何梳理成千上万的文本条目并对相似的实体进行分组？</p><p id="81b6" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">理想情况下，应该有一种简单的方法来添加第三列，如下所示:</p><pre class="kj kk kl km gt lq lr ls lt aw lu bi"><span id="f24a" class="lv lw it lr b gy lx ly l lz ma">+-----+-------------------+---------------+<br/>| row |     fullname      |  name_groups  |<br/>+-----+-------------------+---------------+<br/>|   1 | John F. Doe       | Doe John F    |<br/>|   2 | Esquivel, Mara    | Esquivel Mara |<br/>|   3 | Doe, John F       | Doe John F    |<br/>|   4 | Whyte, Luke       | Whyte Luke    |<br/>|   5 | Doe, John Francis | Doe John F    |<br/>+-----+-------------------+---------------+</span></pre><p id="d601" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">嗯，有，这就是我们要做的。</p><blockquote class="mb mc md"><p id="ff3c" class="ku kv me kw b kx ky ju kz la lb jx lc mf le lf lg mg li lj lk mh lm ln lo lp im bi translated">TLDR:我为此制作了一个工具。你可以<a class="ae mi" href="https://github.com/lukewhyte/textpack" rel="noopener ugc nofollow" target="_blank">在这里</a>安装 Python 模块。但是如果你想了解这个工具背后的概念——或者你只是强烈地不信任我(嗨，亲爱的)——请继续读下去。</p></blockquote><p id="148c" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated"><strong class="kw iu">我们将讨论的话题:</strong></p><ol class=""><li id="c169" class="mj mk it kw b kx ky la lb ld ml lh mm ll mn lp mo mp mq mr bi translated">用 TF-IDF 和 N 元文法构建文档术语矩阵</li><li id="858d" class="mj mk it kw b kx ms la mt ld mu lh mv ll mw lp mo mp mq mr bi translated">使用余弦相似度计算字符串之间的接近度</li><li id="fa6e" class="mj mk it kw b kx ms la mt ld mu lh mv ll mw lp mo mp mq mr bi translated">使用散列表将我们的发现转换为电子表格中的“组”列</li></ol><p id="829d" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">在本教程中，我将使用<a class="ae mi" href="https://data.world/lukewhyte/us-dept-of-labor-wage-theft-investigations" rel="noopener ugc nofollow" target="_blank">美国劳工部工资盗窃调查的数据集</a>。它包含了从 1984 年到 2018 年因违反最低工资或加班而对雇主进行的每一次 DOL 调查。</p><p id="e381" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">该数据包括一个<code class="fe mx my mz lr b">legal_name</code>列，其中列出了被调查公司的名称。然而，条目格式千差万别:</p><pre class="kj kk kl km gt lq lr ls lt aw lu bi"><span id="1563" class="lv lw it lr b gy lx ly l lz ma">+-----+----------------------+<br/>| row |      legal_name      |<br/>+-----+----------------------+<br/>|   1 | Wal-mart Inc         |<br/>|   2 | Walmart Stores Inc.  |<br/>|   3 | Wal-mart stores Inc  |<br/>|   4 | Wal-Mart stores Inc. |<br/>+-----+----------------------+</span></pre><p id="935c" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">我们将对<code class="fe mx my mz lr b">legal_name</code>下的条目进行标准化和分组，然后使用我们的组进行一些快速分析。</p><h2 id="977a" class="lv lw it bd na nb nc dn nd ne nf dp ng ld nh ni nj lh nk nl nm ll nn no np nq bi translated"><strong class="ak">第一步:用 TF-IDF 和 N 元语法构建文档术语矩阵</strong></h2><p id="9aaf" class="pw-post-body-paragraph ku kv it kw b kx nr ju kz la ns jx lc ld nt lf lg lh nu lj lk ll nv ln lo lp im bi translated">我们这里最大的挑战是，我们专栏中的每个条目都需要与其他每个条目进行比较。因此，一张 400，000 行的表格需要 400，000 次计算，当我在记得关闭 Photoshop 之前打开网飞时，我的笔记本电脑过热了。</p><p id="057c" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">如果我们可以使用矩阵乘法来进行同时计算，这将会快得多，我们可以使用文档术语矩阵、TF-IDF 和 N-Grams 来进行计算。</p><p id="0c37" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">让我们来定义这些术语:</p><p id="ece7" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated"><strong class="kw iu">文档术语矩阵</strong></p><p id="18a7" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">文档术语矩阵本质上是单词包概念的扩展，我喜欢这个概念，因为它听起来像是一个蒙面人在芝麻街上偷的东西。</p><p id="e099" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">BOW 包括计算字符串中单词的频率。所以，鉴于这句话:</p><p id="ddc2" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">“罗德岛既不是路，也不是岛。讨论。”</p><p id="27f2" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">我们可以像这样制作一个弓:</p><pre class="kj kk kl km gt lq lr ls lt aw lu bi"><span id="9466" class="lv lw it lr b gy lx ly l lz ma">+---------+-------+<br/>|  term   | count |<br/>+---------+-------+<br/>| rhode   |     1 |<br/>| island  |     2 |<br/>| is      |     2 |<br/>| neither |     1 |<br/>| a       |     1 |<br/>| road    |     1 |<br/>| nor     |     1 |<br/>| it      |     1 |<br/>| an      |     1 |<br/>| discuss |     1 |<br/>+---------+-------+</span></pre><p id="3f4d" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">文档术语矩阵(DTM)将 BOW 扩展到多个字符串(或者在术语中称为“多个文档”)。假设我们有以下三个字符串:</p><ol class=""><li id="fe45" class="mj mk it kw b kx ky la lb ld ml lh mm ll mn lp mo mp mq mr bi translated">“连我哥哥都有需求”</li><li id="bf28" class="mj mk it kw b kx ms la mt ld mu lh mv ll mw lp mo mp mq mr bi translated">“我弟弟需要搭车”</li><li id="0453" class="mj mk it kw b kx ms la mt ld mu lh mv ll mw lp mo mp mq mr bi translated">“老弟，你到底举不举？”</li></ol><p id="849f" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">DTM 可能是这样的:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nw nx l"/></div></figure><p id="ab85" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">每个条目的值通过计算每个单词在每个字符串中出现的次数来确定。</p><p id="09c3" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">上述方法的问题在于，像“The”、“is”和“if”这样的无关紧要的词往往比重要的词出现得更频繁，这可能会扭曲我们的分析。</p><p id="43a8" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">因此，我们可以给它们分配一个 TF-IDF 分数，来评估每个单词对 DTM 的重要性，而不是计算单词数。</p><p id="9efd" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated"><strong class="kw iu"> TF-IDF </strong></p><p id="624f" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">为了计算 TF-IDF 得分，我们将一个术语在单个文档中出现的次数(术语频率或 TF)乘以该术语对整个语料库的重要性(逆文档频率或 IDF)——一个单词在文档中出现的次数越多，该单词在区分文档中的价值就越低。</p><p id="1b99" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">如果你对计算 TF-IDF 分数背后的数学感兴趣，看看这里的。</p><p id="c4e3" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">重要的是，对于我们的文档术语矩阵中的每个单词，如果我们用 TF-IDF 分数替换单词计数，我们可以在检查字符串相似性时更有效地加权单词。</p><p id="439b" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated"><strong class="kw iu"> N-Grams </strong></p><p id="f229" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">最后，我们将解决这个问题:</p><p id="f758" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated"><code class="fe mx my mz lr b">Burger King</code>是两个字。<code class="fe mx my mz lr b">BurgerKing</code>应该是两个字，但是电脑会把它看成一个。因此，当我们计算文档术语矩阵时，这些术语将不匹配。</p><p id="15d5" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">n 元语法是一种将字符串分成更小块的方法，其中<code class="fe mx my mz lr b">N</code>是块的大小。所以，如果我们将<code class="fe mx my mz lr b">N</code>设为<code class="fe mx my mz lr b">3</code>，我们得到:</p><pre class="kj kk kl km gt lq lr ls lt aw lu bi"><span id="4928" class="lv lw it lr b gy lx ly l lz ma">['Bur', 'urg', 'rge', 'ger', 'er ', 'r K', ' Ki', 'Kin', 'ing']</span></pre><p id="687e" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">并且:</p><pre class="kj kk kl km gt lq lr ls lt aw lu bi"><span id="dc6b" class="lv lw it lr b gy lx ly l lz ma">['Bur', 'urg', 'rge', 'ger', 'erK', 'rKi', 'Kin', 'ing']</span></pre><p id="2091" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">这些字符串比原始字符串有更多的重叠。</p><p id="56a1" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">因此，当我们构建我们的文档术语矩阵时，让我们计算 N-Grams 而不是单词的 TF-IDF 分数。</p><p id="74ba" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated"><strong class="kw iu">最后，一些代码:</strong></p><p id="c498" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">下面是构建文档术语矩阵的代码，使用 N-gram 作为列标题，使用 TF-IDF 分值作为值:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nw nx l"/></div></figure><p id="6de9" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">在第 6 行，我们将 CSV 转换成一个<a class="ae mi" href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html" rel="noopener ugc nofollow" target="_blank">熊猫数据帧</a>。</p><p id="0e6c" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">第 10 行从数据集的<code class="fe mx my mz lr b">legal_name</code>列中提取唯一值，并将它们放入一维 NumPy 数组中。</p><p id="2d14" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">在第 14 行，我们编写了构建我们的 5 个字符的 N-Grams 的函数(我从这里提取了函数<a class="ae mi" href="https://bergvca.github.io/2017/10/14/super-fast-string-matching.html" rel="noopener ugc nofollow" target="_blank">)。使用正则表达式过滤掉一些字符。</a></p><p id="64f1" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">第 20 行将<code class="fe mx my mz lr b">ngrams_analyzer</code>传递给 TF-IDF 矢量器，我们将使用它来构建矩阵。</p><p id="8c7c" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">最后，在第 23 行，我们构建了我们的文档术语矩阵。</p><p id="49c2" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated"><strong class="kw iu">稀疏矩阵与密集矩阵以及如何让你的电脑崩溃</strong></p><p id="8690" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">上面代码的结果<code class="fe mx my mz lr b">tfidf_matrix</code>，是一个压缩的稀疏行(CSR)矩阵。</p><p id="e2b0" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">如果你不熟悉稀疏矩阵，<a class="ae mi" href="https://machinelearningmastery.com/sparse-matrices-for-machine-learning/" rel="noopener ugc nofollow" target="_blank">这是一个伟大的介绍</a>。出于我们的目的，要知道任何大部分值为零的矩阵都是稀疏矩阵。这不同于大部分非零值的密集矩阵。</p><p id="cf1d" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">我们的 N 元模型矩阵有 237，573 行和 389，905 列。前 10 行和前 10 列如下所示:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nw nx l"/></div><figcaption class="kq kr gj gh gi ks kt bd b be z dk">(I added the underscores to represent blank characters.)</figcaption></figure><p id="ab0c" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">那是相当稀少的。没有理由在内存中存储所有这些零。如果我们这样做，就有可能耗尽 RAM 并触发<code class="fe mx my mz lr b">MemoryError</code>。</p><p id="e83f" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">进入 CSR 矩阵，它只存储矩阵的非零值和对其原始位置的引用。</p><p id="9262" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">这是一个过于简化的问题，你可以在这里学习细节。重要的一点是，CSR 格式节省了内存，同时还允许快速的行访问和矩阵乘法。</p><h2 id="fe85" class="lv lw it bd na nb nc dn nd ne nf dp ng ld nh ni nj lh nk nl nm ll nn no np nq bi translated"><strong class="ak">步骤二:使用余弦相似度计算字符串之间的接近度</strong></h2><p id="3ec6" class="pw-post-body-paragraph ku kv it kw b kx nr ju kz la ns jx lc ld nt lf lg lh nu lj lk ll nv ln lo lp im bi translated">余弦相似度是一个介于 0 和 1 之间的度量，用于确定字符串的相似程度，而不考虑其长度。</p><p id="9709" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">它测量多维空间中字符串之间角度的余弦值。该值越接近 1(余弦值为 0)，字符串相似度越高。</p><p id="b680" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">取以下三个字符串:</p><ol class=""><li id="018a" class="mj mk it kw b kx ky la lb ld ml lh mm ll mn lp mo mp mq mr bi translated">我喜欢狗</li><li id="ae1f" class="mj mk it kw b kx ms la mt ld mu lh mv ll mw lp mo mp mq mr bi translated">我爱爱爱爱爱爱爱狗</li><li id="060e" class="mj mk it kw b kx ms la mt ld mu lh mv ll mw lp mo mp mq mr bi translated">我讨厌讨厌讨厌猫</li></ol><p id="d458" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">并将它们放入文档术语矩阵中:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nw nx l"/></div></figure><p id="977c" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">然后在多维空间上绘制这个矩阵，其中每个维度对应于我们四个术语中的一个。可能是这样的:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ki"><img src="../Images/8faaede317796c09801afd96f2818aa8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*QNp4TNCNwo1HMqjFV4jq1g.png"/></div></figure><p id="b522" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">如果我们看一下我们之间的距离，“我爱狗”和“我讨厌猫”比“我爱狗”和“我爱…爱狗”在身体上更接近。</p><p id="0ce2" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">然而，如果我们看看我们的点的线之间的<em class="me">角度——</em>余弦距离——我们可以看到，“我爱狗”和“我爱……爱狗”之间的角度比“我爱狗”和“我讨厌猫”之间的角度小得多。</p><p id="1770" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">因此，字符串 1 和字符串 2 之间的余弦相似度将比字符串 1 和字符串 3 之间的余弦相似度更高(更接近 1)。</p><p id="da05" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated"><a class="ae mi" href="https://www.machinelearningplus.com/nlp/cosine-similarity/" rel="noopener ugc nofollow" target="_blank">下面是更深入的解释</a>。</p><p id="097d" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated"><strong class="kw iu">用 Python 计算余弦相似度</strong></p><p id="ceca" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">我们可以使用<a class="ae mi" href="https://scikit-learn.org/stable/modules/generated/sklearn.metrics.pairwise.cosine_similarity.html" rel="noopener ugc nofollow" target="_blank"> scikit-learn </a>来计算余弦相似度。这将返回具有余弦相似值的成对矩阵，如下所示:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nw nx l"/></div></figure><p id="b5e4" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">然后，我们将通过相似性阈值(类似于 0.75 或 0.8)过滤这个矩阵，以便对我们认为代表相同实体的字符串进行分组。</p><p id="3633" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">然而，如果我们使用由 ING Bank 的数据科学家构建的模块<a class="ae mi" href="https://github.com/ing-bank/sparse_dot_topn" rel="noopener ugc nofollow" target="_blank">和</a>,我们可以在构建矩阵时根据相似性阈值进行过滤。该方法比 scikit-learn 更快，并返回一个较少占用内存的 CSR 矩阵供我们使用。</p><p id="f2e8" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">ING <a class="ae mi" href="https://medium.com/wbaa/https-medium-com-ingwbaa-boosting-selection-of-the-most-similar-entities-in-large-scale-datasets-450b3242e618" rel="noopener">写了一篇博客解释为什么</a>，如果你感兴趣的话。</p><p id="6eb8" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated"><strong class="kw iu">因此，让我们将以下内容添加到我们的脚本中:</strong></p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nw nx l"/></div></figure><p id="a24a" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">现在我们有了一个 CSR 矩阵来表示所有字符串之间的余弦相似性。是时候带它回家了。</p><h2 id="d504" class="lv lw it bd na nb nc dn nd ne nf dp ng ld nh ni nj lh nk nl nm ll nn no np nq bi translated"><strong class="ak">第三步:构建一个</strong>散列表，将我们的发现转换为电子表格中的“groups”列</h2><p id="3088" class="pw-post-body-paragraph ku kv it kw b kx nr ju kz la ns jx lc ld nt lf lg lh nu lj lk ll nv ln lo lp im bi translated">我们现在将构建一个 Python 字典，为我们的<code class="fe mx my mz lr b">legal_name</code>列中的每个唯一字符串提供一个键。</p><p id="3ca9" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">最快的方法是将我们的 CSR 矩阵转换成坐标(首席运营官)矩阵。首席运营官矩阵是稀疏矩阵的另一种表示。</p><p id="b673" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">举例来说，如果我们有这个稀疏矩阵:</p><pre class="kj kk kl km gt lq lr ls lt aw lu bi"><span id="ede9" class="lv lw it lr b gy lx ly l lz ma">+------------+<br/>| 0, 0, 0, 4 |<br/>| 0, 1, 0, 0 |<br/>| 0, 0, 0, 0 |<br/>| 3, 0, 0, 7 |<br/>+------------+</span></pre><p id="ec90" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">我们将其转换为首席运营官矩阵，它将成为一个具有三个属性的对象— <code class="fe mx my mz lr b">row</code>、<code class="fe mx my mz lr b">col</code>、<code class="fe mx my mz lr b">data</code> —分别包含以下三个数组:</p><ol class=""><li id="9142" class="mj mk it kw b kx ky la lb ld ml lh mm ll mn lp mo mp mq mr bi translated"><code class="fe mx my mz lr b">[0, 1, 3, 3]</code>:每个非零值的行索引(索引为 0)</li><li id="bec4" class="mj mk it kw b kx ms la mt ld mu lh mv ll mw lp mo mp mq mr bi translated"><code class="fe mx my mz lr b">[3, 1, 0, 3]</code>:每个非零值的列索引(索引为 0)</li><li id="0b2e" class="mj mk it kw b kx ms la mt ld mu lh mv ll mw lp mo mp mq mr bi translated"><code class="fe mx my mz lr b">[4, 1, 3, 7]</code>:矩阵中的非零值</li></ol><p id="4c85" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">因此，我们可以说值<code class="fe mx my mz lr b">4</code>(存储在<code class="fe mx my mz lr b">matrix.data[0]</code>)的坐标是<code class="fe mx my mz lr b">(0,3)</code>(存储在<code class="fe mx my mz lr b">(matrix.row[0],matrix.col[0]</code>)。</p><p id="d035" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">让我们建立我们的首席运营官矩阵，并用它来填充我们的字典:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nw nx l"/></div></figure><p id="ad73" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">在第 2 行，我们将余弦矩阵转换为坐标矩阵。</p><p id="e044" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">在第 39–43 行，我们遍历坐标矩阵，提取非零值的行和列索引，记住，所有非零值的余弦相似度都超过 0.8，然后将它们转换为字符串值。</p><p id="d170" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">为了澄清，让我们用一个简化的例子进一步解开第 39–43 行。再来看这个余弦矩阵:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nw nx l"/></div></figure><p id="c6d8" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">如果我们使用阈值设置为 0.8 的<code class="fe mx my mz lr b">awesome_cossim_topn</code>构建它，然后将其转换为首席运营官矩阵，我们可以这样表示它:</p><pre class="kj kk kl km gt lq lr ls lt aw lu bi"><span id="88b5" class="lv lw it lr b gy lx ly l lz ma">  (row, col) | data  <br/> ------------|------ <br/>  (0,0)      |    1 <br/>  (0,2)      | 0.84 <br/>  (1,1)      |    1 <br/>  (2,0)      | 0.84 <br/>  (2,2)      |    1</span></pre><p id="99eb" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated"><code class="fe mx my mz lr b">vals</code>将等于<code class="fe mx my mz lr b">['Walmart', 'Target', 'Wal-mart stores']</code>。</p><p id="17dd" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">因此，在循环内部，我们第一个通过<code class="fe mx my mz lr b">row != col</code>条件的<code class="fe mx my mz lr b">(row, col)</code>对将是<code class="fe mx my mz lr b">(0, 2)</code>，然后我们将它作为<code class="fe mx my mz lr b">(vals[0], vals[2)</code>或<code class="fe mx my mz lr b">('Walmart', 'Wal-mart stores')</code>传递给<code class="fe mx my mz lr b">add_pair_to_lookup</code>。</p><p id="a3ee" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">继续这个例子，在我们所有的字符串都通过<code class="fe mx my mz lr b">add_pair_to_lookup</code>之后，我们会得到:</p><pre class="kj kk kl km gt lq lr ls lt aw lu bi"><span id="f23a" class="lv lw it lr b gy lx ly l lz ma">&gt;&gt;&gt; group_lookup<br/>{<br/>    <!-- -->'Walmart': 'Walmart',<br/>    'Wal-mart stores': 'Walmart'<br/>}</span></pre><p id="4da7" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">没有类似于“Target”的字符串，因此没有为其分配组。</p><p id="e540" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated"><strong class="kw iu">向量化熊猫</strong></p><p id="eaeb" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">最后，我们可以使用 Pandas 中的<a class="ae mi" href="https://engineering.upside.com/a-beginners-guide-to-optimizing-pandas-code-for-speed-c09ef2c6a4d6" rel="noopener ugc nofollow" target="_blank">矢量化功能，将每个<code class="fe mx my mz lr b">legal_name</code>值映射到数据帧中的一个新的<code class="fe mx my mz lr b">Group</code>列，并导出我们的新 CSV。</a></p><p id="521f" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">由于 Pandas 函数可以同时对整个数组进行操作——而不是依次对单个值进行操作——这个过程非常快:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nw nx l"/></div></figure><p id="fcb4" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated"><code class="fe mx my mz lr b">fillna</code>方法允许我们在<code class="fe mx my mz lr b">group_lookup</code>中不存在键时用<code class="fe mx my mz lr b">legal_name</code>值代替<code class="fe mx my mz lr b">Group</code>。</p><p id="6b81" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated"><strong class="kw iu">把所有的放在一起:</strong></p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nw nx l"/></div></figure><p id="e9af" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">剩下要做的就是将这些数据放入数据透视表，看看哪些雇主欠员工的工资最多。</p><p id="485f" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">剧透提示:是沃尔玛。183 项调查导致他们同意支付近 4100 万美元的欠薪。</p><p id="e705" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated"><strong class="kw iu">最后一个提示</strong></p><p id="a246" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">如果您希望按两列或更多列而不是一列进行分组，一种方法是创建一个临时列，用于在数据帧中将每列的条目连接成一个字符串进行分组:</p><pre class="kj kk kl km gt lq lr ls lt aw lu bi"><span id="601a" class="lv lw it lr b gy lx ly l lz ma">columns_to_group = ['legal_name', 'address']</span><span id="ce73" class="lv lw it lr b gy ny ly l lz ma">df['grouper'] = df[<br/>   columns_to_group.pop(0)<br/>].astype(<em class="me">str</em>).str.cat(<br/>   df[columns_to_group].astype(<em class="me">str</em>)<br/>)</span></pre><p id="dde8" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">然后将<code class="fe mx my mz lr b">vals</code>设置为:</p><pre class="kj kk kl km gt lq lr ls lt aw lu bi"><span id="a534" class="lv lw it lr b gy lx ly l lz ma">vals = df['grouper'].unique().astype('U')</span></pre><p id="33b8" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">最后导出时，删除该列:</p><pre class="kj kk kl km gt lq lr ls lt aw lu bi"><span id="8a09" class="lv lw it lr b gy lx ly l lz ma">df.drop(columns=['grouper']).to_csv('./dol-data-grouped.csv')</span></pre><p id="d653" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">同样，我创建了一个 Python 模块来完成这一切。<a class="ae mi" href="https://github.com/lukewhyte/textpack" rel="noopener ugc nofollow" target="_blank">来看看</a>！！</p></div></div>    
</body>
</html>