# 面向文本分类的 Tensorflow 2.0 数据转换

> 原文：<https://towardsdatascience.com/tensorflow-2-0-data-transformation-for-text-classification-b86ee2ad8877?source=collection_archive---------13----------------------->

## 一个完整的端到端文本分类过程

![](img/55d1485a79ba8b0f1e7cbf2d2233353a.png)

在本文中，我们将利用 Tensorflow 2.0 和 Python 来创建一个用于对电影评论进行分类的端到端流程。大多数 Tensorflow 教程侧重于如何使用预处理数据集设计和训练模型。通常，预处理数据是人工智能项目中最耗时的部分。本文将带您完成这一过程。注意:我们并不试图在这里生成一个最先进的分类模型。目标是解释如何在张量流模型中准备用于训练和评估的数据。我们将使用本页的[中定义的模型，并通过解决本教程中未涉及的两个挑战来改进流程:](https://www.tensorflow.org/tutorials/keras/text_classification)

1.  我们如何将原始文本加载到模型中并对其进行训练？
2.  一旦创建并训练了模型，我们如何使用它根据新的输入数据生成预测？

## 挑战 1

我们如何将原始文本加载到模型中并对其进行训练？

关于神经网络，你能知道的最重要的事情是，它们只对数字数据起作用。因此，为了进行文本分类，必须将原始文本数据转换为数字。Tensorflow 教程使用预处理数据集，其中所有文本都已转换为数值。这对于构建原型和评估不同的模型是很好的，但是它跳过了将文本数据转换成数字数据的过程。为了解决这个问题，我们将不使用预处理数据。相反，我们将下载并使用斯坦福大学提供的带标签的 IMDB 评论中的原始文本数据。

```
!wget -q [http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz](http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz)
!tar zxf aclImdb_v1.tar.gz
!tree -d aclImdb
```

![](img/901e73c404144b19f25e45e4f129bcbd.png)

根目录包含我们的*测试*和*训练*数据集的子目录。在每个目录下，都有包含 *pos* 和 *neg* 评论的目录。每个目录包含 12500 条评论。注意，对于本教程，我们不使用*unsupp*目录。

现在我们需要创建一个 train 和 test dataframes，每个 dataframes 有两列: **text** (评论文本)和 **sent** (评论的情绪)。我们通过遍历该函数中的目录来实现这一点:

现在我们已经加载了数据，是时候将文本数据转换成数值了:

NUM_WORDS 是一个变量，包含我们希望保留在词汇表中的单词数。对于本例，我们将其设置为 8000。第 2 行和第 3 行创建了一个标记器，用于索引我们的训练数据中最常用的 8000 个标记。第 6&7 行使用索引为评论中的每个单词生成数值。SEQ _ 伦是我们定义的另一个变量，用于确定每次评论使用多少单词。在本例中，我们将其设置为 256。因为我们模型的每个输入必须包含相同数量的标记，所以第 11 & 12 行将每个评论截断为 256 个字符，如果评论少于 256 个字符，则填充它。

现在是时候构建和训练我们的模型了。大部分代码直接取自 Tensorflow 2.0 教程，尽管我对培训部分做了一些改进，我将在下面描述:

第 1 行到第 10 行直接来自教程，没有任何修改。在第 13 行到第 15 行，我添加了一个 **EarlyStopping** 回调，如果验证精度开始下降，它会导致模型停止训练，这有助于减少过度拟合。第 16–20 行是我们实际训练模型的地方。我使用的参数与本教程略有不同，所以下面是对每个参数的描述:

*   batch_size —传递给训练周期每批的示例数量。最初的教程将此设置为 512。这是一个可调超参数的例子。在尝试了不同的值之后，16 给了我最好的结果，但是通过更新 BATCH_SIZE 常量可以很容易地改变它。
*   epochs —我们通过模型运行完整训练集进行训练的次数。它被设置为 20，但是由于 EarlyStopping 被启用，它很可能永远不会达到这个值。如果达到了 20，你可以增加它来看看你是否能得到更好的结果。
*   validation_split —这里我们说 20%的输入数据将用于验证我们的模型学习得有多好。如果我们开始看到我们的准确性增加，同时看到我们的验证准确性下降，那么我们是过度拟合。在这种情况下，我们应该停止训练，因为这已经是最好的了。
*   回调——这是我们传递早期停止回调的地方。

在第 22 行，我们通过传入模型从未见过的新输入数据来评估模型。您应该会看到大约 87%的准确性，考虑到我们的神经网络仅用了大约四行代码来构建，这是相当不错的。在文章的最后，我将讨论一些事情，试图使模型更加准确。

## 挑战#2

一旦创建并训练了模型，我们如何使用它根据新的输入数据生成预测？

原 Tensorflow 教程到此结束。在这一点上，我们有一个经过训练的模型，但还不清楚我们将来如何使用它来根据新数据进行预测。

首先，我们需要保存模型和我们的标记器。我们是这样做的:

在第 2 行中，我们将模型及其所有权重保存到一个名为 model.h5 的文件中。然后我们可以删除我们的模型和记号化器，因为我们已经完成了训练。

现在，我们准备使用我们的训练模型对一些新数据进行一些推断:

*   第 1–4 行从磁盘加载我们的模型和标记器。
*   第 6–9 行将我们的文本输入转换为我们的模型需要的数字输入，其方式类似于我们为训练所做的。
*   第 11-14 行包含了我写的一些评论。请随意在这里添加一些您自己的评论。
*   第 15 行调用我们的数据准备函数来为我们的输入数据生成数字序列。
*   第 17 行根据我们的输入数据做出预测。

需要注意的是，loaded_model.predict 的返回值是一组评论为正面的概率。为了解决这个问题，我使用一个阈值来确定一个评论是否是正面的。在这种情况下，如果它在 60%以上，那么它是一个积极的评论。否则就是否定的。这是一个您可以试验和修改的任意阈值。下面是一些查看和解释推理结果的帮助器代码:

*   第 1-3 行创建了一个包含原始文本和预测情感的数据框架。
*   第 5 行根据阈值将数字情感值转换为“正”或“负”
*   第 7 行打印出我们的结果:

![](img/2438cd9ff544686242b140ee64e900f1.png)

在本文中，我们采用电影评论的原始文本，并对其进行预处理，以输入到 Tensorflow 2.0 神经网络模型中。然后，我们将数据输入到一个模型中，并取得了一些不错的结果(大约 87%的准确率)。一些增强功能可能会改善这种情况:

1.  在构建我们的模型之前过滤掉停用词。停用词是正常英语所必需的词，但对确定文章的意思没有任何价值。一些例子包括:" the "，" of "，" a "，…这将有助于我们的模型只关注有意义的单词。
2.  对模型的细微调整。Tensorflow 2.0 使向我们的神经网络添加新层变得极其简单。我们可能希望在我们的 GlobalAveragePooling1D 层和最终的密集层之间添加一些密集层和/或下降层。
3.  对模型的重大调整。这是一个非常简单的模型，还有更复杂的模型，比如 RNN 的、LSTM 的和 CNN 的。也有全新的方法，如 BERT。

需要注意的最重要的一点是，无论您选择什么方法，您仍然必须遵循这里介绍的步骤来为神经网络处理您的数据。

我已经在 [Google Colab](https://colab.research.google.com/drive/1OeJQyZV9hW2bs6I7wyFCR1wftLB15JTF) 上分享了这个模型。我期待在下面的评论区听到你的反馈。