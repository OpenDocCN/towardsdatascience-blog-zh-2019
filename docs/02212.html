<html>
<head>
<title>Log Compacted Topics in Apache Kafka</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">Apache Kafka 中的日志压缩主题</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/log-compacted-topics-in-apache-kafka-b1aa1e4665a7?source=collection_archive---------1-----------------------#2019-04-12">https://towardsdatascience.com/log-compacted-topics-in-apache-kafka-b1aa1e4665a7?source=collection_archive---------1-----------------------#2019-04-12</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><p id="e2be" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">当我开始阅读 Kafka 文档时，尽管日志压缩主题似乎是一个简单的概念，但我并不清楚 Kafka 如何在文件系统中内部保存它们的状态。这个月我有时间阅读了更多关于这个特性的内容，我想和你分享我的理解。</p><h1 id="e244" class="kl km iq bd kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li bi translated">TL；速度三角形定位法(dead reckoning)</h1><p id="779c" class="pw-post-body-paragraph jn jo iq jp b jq lj js jt ju lk jw jx jy ll ka kb kc lm ke kf kg ln ki kj kk ij bi translated">在这篇文章中，我将描述卡夫卡中的日志压缩主题。然后，我将向您展示 Kafka 如何在文件系统中内部保存这些主题的状态。</p><h1 id="b026" class="kl km iq bd kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li bi translated">先决条件</h1><p id="c2be" class="pw-post-body-paragraph jn jo iq jp b jq lj js jt ju lk jw jx jy ll ka kb kc lm ke kf kg ln ki kj kk ij bi translated">我假设您已经熟悉 Apache Kafka 的基本概念，如代理、主题、分区、消费者和生产者。另外，如果您想运行示例命令，您必须运行一个 Kafka broker <em class="lo">和一个 Zookeeper 服务器。</em></p><h1 id="0d33" class="kl km iq bd kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li bi translated">什么是日志压缩主题</h1><p id="d3f9" class="pw-post-body-paragraph jn jo iq jp b jq lj js jt ju lk jw jx jy ll ka kb kc lm ke kf kg ln ki kj kk ij bi translated">卡夫卡的文献记载说:</p><blockquote class="lp lq lr"><p id="bc38" class="jn jo lo jp b jq jr js jt ju jv jw jx ls jz ka kb lt kd ke kf lu kh ki kj kk ij bi translated">日志压缩是一种机制，可以提供更细粒度的按记录保留，而不是更粗粒度的基于时间的保留。这个想法是有选择地删除具有相同主键的更新记录。这样可以保证日志中至少有每个键的最新状态。</p></blockquote><p id="baf5" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">为了简化这种描述，当分区日志中存在具有相同关键字的新版本时，Kafka 会删除任何旧记录。作为示例，考虑名为“最新产品价格”的日志压缩主题的以下部分:</p><figure class="lw lx ly lz gt ma gh gi paragraph-image"><div role="button" tabindex="0" class="mb mc di md bf me"><div class="gh gi lv"><img src="../Images/a961e255546f1c299b5a1ce4f0810262.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*wKnOLt56gvutDFzfyjNzJg.jpeg"/></div></div></figure><p id="1c78" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">正如您首先看到的，有两条带有键 p3 的记录。但是因为这是一个日志压缩的主题，Kafka 在一个后台线程中删除了旧的记录(在接下来的小节中会有更多的介绍)。现在假设我们有一个生产者向这个分区发送新记录。生产者产生 3 个记录，分别具有键 p6、p5、p5:</p><figure class="lw lx ly lz gt ma gh gi paragraph-image"><div role="button" tabindex="0" class="mb mc di md bf me"><div class="gh gi mh"><img src="../Images/993e413f5e05f40e95dadfdccab5ff5e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Ax7sGwQ202tETYbP5dFNTw.jpeg"/></div></div></figure><p id="1d12" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">Kafka broker 中的一个后台线程再次删除了带有键 p5 和 p6 的旧记录。请注意，压缩日志由两部分组成:尾部和头部。Kafka 确保尾部分中的所有记录都有唯一的键，因为尾部分是在清理过程的前一个循环中扫描的。但是 head 部分可以有重复的值。</p><p id="9813" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">既然我们已经了解了什么是日志压缩主题，那么是时候使用<code class="fe mi mj mk ml b">kafka-topics</code>工具来创建它们了。</p><h1 id="2944" class="kl km iq bd kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li bi translated">创建日志压缩主题</h1><p id="5657" class="pw-post-body-paragraph jn jo iq jp b jq lj js jt ju lk jw jx jy ll ka kb kc lm ke kf kg ln ki kj kk ij bi translated">创建一个压缩主题(我将详细描述所有配置):</p><pre class="lw lx ly lz gt mm ml mn mo aw mp bi"><span id="e358" class="mq km iq ml b gy mr ms l mt mu">kafka-topics --create --zookeeper zookeeper:2181 --topic latest-product-price --replication-factor 1 --partitions 1 --config "cleanup.policy=compact" --config "delete.retention.ms=100"  --config "segment.ms=100" --config "min.cleanable.dirty.ratio=0.01"</span></pre><p id="1097" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">制作一些记录:</p><pre class="lw lx ly lz gt mm ml mn mo aw mp bi"><span id="a349" class="mq km iq ml b gy mr ms l mt mu">kafka-console-producer --broker-list localhost:9092 --topic latest-product-price --property parse.key=true --property key.separator=:<br/>&gt;p3:10$<br/>&gt;p5:7$<br/>&gt;p3:11$<br/>&gt;p6:25$<br/>&gt;p6:12$<br/>&gt;p5:14$<br/>&gt;p5:17$</span></pre><p id="6489" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">注意，在上面的命令中，我用<code class="fe mi mj mk ml b">:</code>分隔了键和值。现在消费题目:</p><pre class="lw lx ly lz gt mm ml mn mo aw mp bi"><span id="7d9a" class="mq km iq ml b gy mr ms l mt mu">kafka-console-consumer --bootstrap-server localhost:9092 --topic latest-product-price --property  print.key=true --property key.separator=: --from-beginning<br/>p3:11$<br/>p6:12$<br/>p5:14$<br/>p5:17$</span></pre><p id="dee7" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">如您所见，带有重复键的记录被删除。p5:14$记录没有被删除，我们将在描述清理过程时看到原因。但我们首先要看卡夫卡内部是如何储存信息的。</p><h1 id="aa4c" class="kl km iq bd kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li bi translated">片段</h1><p id="51a9" class="pw-post-body-paragraph jn jo iq jp b jq lj js jt ju lk jw jx jy ll ka kb kc lm ke kf kg ln ki kj kk ij bi translated">分区日志是一种抽象，它允许我们轻松地消费分区内部的有序消息，而不必担心 Kafka 的内部存储。然而实际上，分区日志被 Kafka broker 分成了<strong class="jp ir">段</strong>。段是存储在文件系统中的文件(在数据目录和分区目录中)，它们的名称以<code class="fe mi mj mk ml b">.log</code>结尾。在下图中，分区日志分为 3 个部分:</p><figure class="lw lx ly lz gt ma gh gi paragraph-image"><div role="button" tabindex="0" class="mb mc di md bf me"><div class="gh gi mv"><img src="../Images/7f06d9ebea1c37a07f91c025365aabf3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*tXOSydkHJTEWw_lOQaupQA.jpeg"/></div></div></figure><p id="4b84" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">如您所见，我们有一个分区日志，它包含 7 条记录，分别位于 3 个独立的段文件中。一个段的第一个偏置称为该段的<strong class="jp ir">基准偏置</strong>。段文件名始终等于其基本偏移值。</p><p id="75b4" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">分区中的最后一个段称为<strong class="jp ir">活动段</strong>。只有日志的活动段可以接收新生成的消息。我们将会看到卡夫卡在清理压缩原木的过程中是如何处理活动段的。</p><p id="b896" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">回到我们的例子，我们可以通过下面的命令查看我们的主题分区的段文件(假设您的 Kafka 数据目录是<code class="fe mi mj mk ml b">/var/lib/kafka/data</code>):</p><pre class="lw lx ly lz gt mm ml mn mo aw mp bi"><span id="a540" class="mq km iq ml b gy mr ms l mt mu">ls /var/lib/kafka/data/latest-product-price-0/<br/>00000000000000000000.index 00000000000000000006.log<br/>00000000000000000000.log 00000000000000000006.snapshot<br/>00000000000000000000.timeindex 00000000000000000006.timeindex<br/>00000000000000000005.snapshot leader-epoch-checkpoint<br/>00000000000000000006.index</span></pre><p id="7411" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><code class="fe mi mj mk ml b">00000000000000000000.log</code>和<code class="fe mi mj mk ml b">00000000000000000006.log</code>是该分区的段，<code class="fe mi mj mk ml b">00000000000000000006.log</code>是活动段。</p><p id="ff1d" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">卡夫卡什么时候创造了一个新的片段？一种方法是在主题创建期间设置<code class="fe mi mj mk ml b">segment.bytes</code>(默认为 1GB)配置。当您的分段大小变得大于该值时，Kafka 将创建一个新的分段。另一个选择是通过设置<code class="fe mi mj mk ml b">segment.ms</code>，就像你之前看到的那样。使用该选项，当 Kafka 收到一个生产请求时，它将检查活动段是否比<code class="fe mi mj mk ml b">segment.ms</code>值旧。如果它是旧的，那么它将创建一个新的段。在我们的命令中，我们设置<code class="fe mi mj mk ml b">segment.ms=100</code> <em class="lo"> </em>来确保每 100 毫秒创建一个新的段。</p><p id="a3f6" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">有趣的是，当你设置<code class="fe mi mj mk ml b">segment.ms=100</code>时，你可能会有更小的段。在清理过程(见下一节)之后，Kafka broker 将合并非活动段并从中创建一个大段。</p><p id="72da" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">有关 Kafka 的分段和内部存储的更多信息，您可以阅读<a class="ae mw" href="https://thehoard.blog/how-kafkas-storage-internals-work-3a29b02e026" rel="noopener ugc nofollow" target="_blank">Kafka 的存储内部结构如何工作</a>和<a class="ae mw" href="https://medium.com/@durgaswaroop/a-practical-introduction-to-kafka-storage-internals-d5b544f6925f" rel="noopener">Kafka 存储内部结构实用介绍</a>文章。</p><h1 id="70e1" class="kl km iq bd kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li bi translated">洁化过程</h1><p id="6066" class="pw-post-body-paragraph jn jo iq jp b jq lj js jt ju lk jw jx jy ll ka kb kc lm ke kf kg ln ki kj kk ij bi translated">在启动过程中，Kafka broker 会创建一些<strong class="jp ir">清理线程</strong>，负责清理压缩的日志(这些线程的数量可以通过<code class="fe mi mj mk ml b">log.cleaner.threads</code> config 进行配置)。清洁线程会不断尝试在代理中找到最脏的日志，然后尝试清理它。对于每个日志，它按如下方式计算<strong class="jp ir">脏比</strong>:</p><pre class="lw lx ly lz gt mm ml mn mo aw mp bi"><span id="595a" class="mq km iq ml b gy mr ms l mt mu">dirty ratio = the number of bytes in the head / total number of bytes in the log(tail + head)</span></pre><p id="e4e1" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">cleaner 线程然后选择具有最高<strong class="jp ir">脏比</strong>的日志。这个日志被称为最脏的日志，如果它的值大于<code class="fe mi mj mk ml b">min.cleanable.dirty.ratio</code> config，它将被清除。否则，清洁线程将被阻塞数毫秒(可通过<code class="fe mi mj mk ml b">log.cleaner.backoff.ms</code>配置)。</p><p id="f064" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">在找到最脏的日志后，我们希望找到可清理的日志部分。请注意，日志的某些部分是不可清除的，因此不会被扫描:</p><ul class=""><li id="226e" class="mx my iq jp b jq jr ju jv jy mz kc na kg nb kk nc nd ne nf bi translated">活动段内的所有记录。这就是为什么我们仍然在消费者中看到重复的 p5:14$记录。</li><li id="b1dc" class="mx my iq jp b jq ng ju nh jy ni kc nj kg nk kk nc nd ne nf bi translated">如果您将<code class="fe mi mj mk ml b">min.compaction.lag.ms</code>配置设置为大于 0，那么任何包含时间戳早于此配置的记录的段都不会被清除。不会对这些段进行压缩扫描。</li></ul><p id="bf5c" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">现在我们知道了要压缩哪些记录。从日志中的第一条记录到第一条不可清除的记录。在本文中，为了简单起见，我们假设头中的所有记录都是可清除的。</p><p id="ce0e" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">请注意，我们知道日志尾部的每条记录都有一个唯一的键，因为重复的记录在上次清理中被删除了。只可能我们在 head 部分有一些记录，它们的键在日志中不是唯一的。为了更快地找到重复记录，Kafka 在 head 部分为记录创建了一个映射。回到我们的示例，偏移贴图结构如下所示:</p><figure class="lw lx ly lz gt ma gh gi paragraph-image"><div role="button" tabindex="0" class="mb mc di md bf me"><div class="gh gi mh"><img src="../Images/c7aa8c8b300601db68c03e053e55f8a8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*mm0FKL_BaasuIukWl-1FRQ.jpeg"/></div></div></figure><p id="7c32" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">如你所见，Kafka 创建了一个名为<strong class="jp ir">偏移贴图</strong>的结构，它为 head 部分中的每个关键点保存其对应的偏移。如果我们在头部有重复，卡夫卡使用最新的偏移。在上图中，键为 p6 的记录位于偏移量 5 处，p5 的最新偏移量为 7。现在，cleaner thread 检查日志中的每条记录，如果 offset map 中有任何记录具有相同的键，并且它的偏移量与 map 中的条目不同，就删除它(我们不想删除最新的记录)。</p><p id="3c02" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">在压缩日志的清理过程中，不仅会删除重复的消息，而且 Kafka 还会删除值为 null 的记录。这些记录被称为<strong class="jp ir">墓碑</strong>。您可以通过设置<code class="fe mi mj mk ml b">delete.retention.ms </code>配置来延迟删除它们。通过设置此配置，Kafka 检查包含此记录的数据段的修改时间戳，如果修改时间早于配置值，则记录将被保留。</p><p id="bd16" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">现在木头变得干净了。经过这个清洗过程，我们有了一个新的尾巴和一个新的头！为清理而扫描的最后一个偏移(在我们的例子中是旧头中的最后一个记录)是新尾的最后一个偏移。</p><p id="799b" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">Kafka 在数据目录的根目录下的一个名为<code class="fe mi mj mk ml b">cleaner-offset-checkpoint</code>的文件中保存新头的起始偏移量。该文件用于日志的下一个清理周期。我们可以查看我们的主题检查点文件:</p><pre class="lw lx ly lz gt mm ml mn mo aw mp bi"><span id="a485" class="mq km iq ml b gy mr ms l mt mu">cat /var/lib/kafka/data/cleaner-offset-checkpoint<br/>0<br/>1<br/>latest-product-price 0 6</span></pre><p id="768a" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">如你所见，有三行。第一行是文件的版本(我认为是为了向后兼容)，第二行的值为 1，表示这一行之后有多少行(只有一行)，最后一行包含压缩日志主题的名称、分区号和这个分区的头偏移量。</p><h1 id="bdd0" class="kl km iq bd kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li bi translated">结论</h1><p id="2aef" class="pw-post-body-paragraph jn jo iq jp b jq lj js jt ju lk jw jx jy ll ka kb kc lm ke kf kg ln ki kj kk ij bi translated">在本文中，我向您展示了什么是日志压缩主题，它们是如何存储的，以及 Kafka 如何定期清理它们。最后，我想指出的是，日志压缩非常适合于缓存场景，在这种场景中，您希望几乎实时地保存每条记录的最新值。假设您想在应用程序启动时构建缓存。您可以直接读取压缩的主题并构建您的缓存，因为 Kafka 按顺序读取消息，这比使用 SQL 数据库预热您的缓存要快得多。</p><p id="82d0" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">你可以在 Martin Kleppmann <a class="ae mw" href="https://martin.kleppmann.com/2015/03/04/turning-the-database-inside-out.html" rel="noopener ugc nofollow" target="_blank">的文章《翻转数据库》中读到更多关于这种技术的内容。你可能还会发现我以前的文章</a><a class="ae mw" href="https://medium.com/@mousavi310/beat-cache-invalidation-in-asp-net-core-using-kafka-and-debezium-65cd1d80554d" rel="noopener">使用 Kafka 和 Debezium </a>在 ASP.NET 内核中击败缓存失效很有用，它是这种技术的一个实现。</p><h1 id="09cd" class="kl km iq bd kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li bi translated">参考</h1><p id="0570" class="pw-post-body-paragraph jn jo iq jp b jq lj js jt ju lk jw jx jy ll ka kb kc lm ke kf kg ln ki kj kk ij bi translated"><a class="ae mw" href="https://github.com/apache/kafka/" rel="noopener ugc nofollow" target="_blank">https://github.com/apache/kafka/</a><br/>T3】https://thehoard . blog/how-kafkas-storage-internals-work-3a 29 b 02 e 026<br/><a class="ae mw" href="https://medium.com/@durgaswaroop/a-practical-introduction-to-kafka-storage-internals-d5b544f6925f" rel="noopener">https://medium . com/@ durgaswaroop/a-practical-introduction-to-Kafka-storage-internals-d5b 544 f 6925 f</a><br/><a class="ae mw" href="https://kafka.apache.org/documentation/" rel="noopener ugc nofollow" target="_blank">https://kafka.apache.org/documentation/</a></p></div></div>    
</body>
</html>