<html>
<head>
<title>Classifying Literary Movements through Machine Learning</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">通过机器学习分类文学运动</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/classifying-literary-movements-through-machine-learning-ea49cb4339c1?source=collection_archive---------34-----------------------#2019-09-09">https://towardsdatascience.com/classifying-literary-movements-through-machine-learning-ea49cb4339c1?source=collection_archive---------34-----------------------#2019-09-09</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><figure class="is it gp gr iu iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi ir"><img src="../Images/a96bf0b31094f170d5e1089b95d8fcda.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*6U7BThaPhB04do1o7ZIS8A.jpeg"/></div></div><figcaption class="jc jd gj gh gi je jf bd b be z dk">Photo by<a class="ae jg" href="https://unsplash.com/@zeak" rel="noopener ugc nofollow" target="_blank"> Dmitrij Paskevic</a></figcaption></figure><div class=""/><p id="8770" class="pw-post-body-paragraph kg kh jj ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">谁不喜欢图书馆和书架？他们储存知识的对象和所有故事的大门。负责订购书籍的是图书馆员，他们经过多年的培训，知道人们阅读的是什么类型的文本，因此知道在哪里存放它们。传统上来说，这种排序或“分类”是通过字母来完成的，所以图书管理员可以很容易地通过例如埃德加·艾伦<strong class="ki jk">坡</strong>在<strong class="ki jk">下</strong>部分<strong class="ki jk"> P </strong>来找到书籍。但是，文学运动呢？如果这些图书馆员对作者的名字视而不见，只留下原始文本，他们将被迫仔细阅读每一个文本，以确定文学运动，从而对其进行正确分类。例如，我们知道爱伦坡被认为是一个浪漫主义者(更多关于文学运动<a class="ae jg" href="https://en.wikipedia.org/wiki/List_of_literary_movements" rel="noopener ugc nofollow" target="_blank">在这里</a>)，但我们知道这一点是因为我们被告知如此，因为我们已经学会识别构成<em class="le">浪漫主义的关键词、语义形式和文学形式。</em></p><p id="d80d" class="pw-post-body-paragraph kg kh jj ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在这里，我开始寻求创造(训练)一个<strong class="ki jk"> <em class="le">图书管理员算法</em> </strong>，如果你希望这样称呼它，它可以对来自三个不同文学运动的表现相对较好的文本进行分类:<em class="le">浪漫主义</em>、<em class="le">现实主义</em>和<em class="le">超现实主义。</em>为此，我将使用 Python 3 环境和典型的机器学习库，以及 TensorFlow 的一个不太典型但相当惊人的预训练深度学习算法，该算法可以通过在 16 种不同语言中嵌入的<a class="ae jg" rel="noopener" target="_blank" href="/use-cases-of-googles-universal-sentence-encoder-in-production-dd5aaab4fc15">句子将任何给定的句子编码成数字表示！更令人惊奇的是，这种转换是在没有任何特殊文本处理的情况下完成的，您只需以其原始形式(当然是在任何支持的语言中)使用它，它就会计算各自的嵌入向量。</a></p><p id="f9b1" class="pw-post-body-paragraph kg kh jj ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我希望在本文的最后，你会对如何应用这个算法，如何在你自己的项目中使用它，以及如何改进我为你自己的优势而写的所有代码有一个更好的想法。我现在将详细描述方法和结果，抓紧了！</p></div><div class="ab cl lf lg hx lh" role="separator"><span class="li bw bk lj lk ll"/><span class="li bw bk lj lk ll"/><span class="li bw bk lj lk"/></div><div class="im in io ip iq"><p id="06ea" class="pw-post-body-paragraph kg kh jj ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我们需要做的第一件事是从这三个类别中收集一些报价。为此，我选择了 Goodreads，这是一个令人难以置信的网站，在这里你可以搜索到成千上万作者的语录。对于这个分析，我存储了(手动，这里没有使用抓取方法，正常的复制/粘贴)至少三种不同语言的大约 170 个报价，其中英语是绝对最常见的。有些引文是法语的，有些是西班牙语的，极少数是葡萄牙语的。我本可以只用英文引号，但是我想测试一下这种嵌入算法的灵活性。</p><p id="c1ba" class="pw-post-body-paragraph kg kh jj ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">然后，我创建了三个文件，每个运动一个:浪漫主义. txt、现实主义. txt 和超现实主义. txt，所有文件都包含作者的名字，后跟每个作者的八段引文，每个运动分别有 8、6 和 7 个作者(总共 168 段引文)。我使用了多少作者和引用完全是随意的选择，但是如果你想知道的话，类别或引用的不平衡是故意的。</p><p id="67e2" class="pw-post-body-paragraph kg kh jj ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="ki jk">你可以在这里找到完整的笔记本和报价文件</strong><a class="ae jg" href="https://github.com/VictorSaenger/literature-movements" rel="noopener ugc nofollow" target="_blank"><strong class="ki jk"/></a>如果你想亲自尝试的话。</p><p id="b424" class="pw-post-body-paragraph kg kh jj ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">对于整个管道，您需要导入这些模块，因此确保安装了它们(<strong class="ki jk"> pip 安装包</strong>通常会在大多数情况下起作用):</p><pre class="lm ln lo lp gt lq lr ls lt aw lu bi"><span id="d915" class="lv lw jj lr b gy lx ly l lz ma">#Tensorflow , tf-hub and tf-sentencepiece, all needed to calculate #embbedings. Check <a class="ae jg" href="https://github.com/tensorflow/hub/issues/345" rel="noopener ugc nofollow" target="_blank">this discussion</a> to install compatible versions. #At the time of this writing, a compatible mix of packages is tf #v1.13.1, hub v0.5.0 and sentencepiece v0.1.82.1:</span><span id="4cb1" class="lv lw jj lr b gy mb ly l lz ma">import tensorflow as tf<br/>import tensorflow_hub as hub<br/>import tf_sentencepiece</span><span id="d898" class="lv lw jj lr b gy mb ly l lz ma">#numpy and random</span><span id="a19b" class="lv lw jj lr b gy mb ly l lz ma">import numpy as np<br/>import random</span><span id="6b9e" class="lv lw jj lr b gy mb ly l lz ma"># sklearn and imblearn packages:</span><span id="1e2a" class="lv lw jj lr b gy mb ly l lz ma">from sklearn.neural_network import MLPClassifier<br/>from sklearn.metrics import confusion_matrix, f1_score<br/>from sklearn.preprocessing import StandardScaler<br/>from sklearn.model_selection import StratifiedShuffleSplit<br/>from imblearn.under_sampling import EditedNearestNeighbours</span><span id="b657" class="lv lw jj lr b gy mb ly l lz ma">#Visualization:<br/>import seaborn as sns<br/>import matplotlib.pyplot as plt<br/>import networkx as nx</span></pre><p id="85d6" class="pw-post-body-paragraph kg kh jj ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">然后，第一个预处理步骤当然是加载数据。为此，我使用了以下代码行:</p><pre class="lm ln lo lp gt lq lr ls lt aw lu bi"><span id="ca42" class="lv lw jj lr b gy lx ly l lz ma"># This loads each file to variables f_X:<br/>f_rom = open(“Romanticism.txt”, “r”)<br/>f_rea = open(“Realism.txt”, “r”)<br/>f_sur = open(“Surrealism.txt”, “r”)</span><span id="58c2" class="lv lw jj lr b gy mb ly l lz ma">#This creates a list of all author names plus their quotes:<br/>list_all_rom = f_rom.readlines()<br/>list_all_rea = f_rea.readlines()<br/>list_all_sur = f_sur.readlines()</span></pre><p id="ed2a" class="pw-post-body-paragraph kg kh jj ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">其中每个列表都是这样的:</p><pre class="lm ln lo lp gt lq lr ls lt aw lu bi"><span id="6110" class="lv lw jj lr b gy lx ly l lz ma">['"Author1","quote1","quote2","quote3"\n', '"Author2..."\n']</span></pre><p id="61da" class="pw-post-body-paragraph kg kh jj ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">然后，我们可以用这个函数合并每个文学运动的所有引用:</p><figure class="lm ln lo lp gt iv"><div class="bz fp l di"><div class="mc md l"/></div></figure><p id="9351" class="pw-post-body-paragraph kg kh jj ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">然后简单地运行这个命令，将它们合并成一个大列表:</p><pre class="lm ln lo lp gt lq lr ls lt aw lu bi"><span id="6163" class="lv lw jj lr b gy lx ly l lz ma">merged_list_rom = merge_list(list_all_rom)<br/>merged_list_rea = merge_list(list_all_rea)<br/>merged_list_sur = merge_list(list_all_sur)</span><span id="3da6" class="lv lw jj lr b gy mb ly l lz ma">merged_list_all = merged_list_rom + merged_list_rea + merged_list_sur</span></pre><p id="92f1" class="pw-post-body-paragraph kg kh jj ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在这里，<strong class="ki jk"> merged_list_all </strong>是所有运动(有序)的引用集合，看起来像这样(如果你是一个好的图书管理员，你可能会认出作者，也可能认出某些引用的运动！):</p><pre class="lm ln lo lp gt lq lr ls lt aw lu bi"><span id="a75a" class="lv lw jj lr b gy lx ly l lz ma">'I have absolutely no pleasure in the stimulants in which I sometimes so madly indulge...',<br/>'Once upon a midnight dreary, while I pondered, weak and weary, Over many a quaint...',<br/>'This is what you shall do; Love the earth and sun and the animals, despise riches, give alms to every...',<br/>...<br/>...<br/>...<br/>'Avec ce coeur débile et blême Quand on est l'ombre de soi-même Comment se pourrait-il comment Comment se ... ,'<br/>... <br/>x 168</span></pre><p id="95b0" class="pw-post-body-paragraph kg kh jj ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">这些引用是我们嵌入分析的输入。现在有趣的部分来了！首先是从 TensorFlow 的 hub 加载我之前谈到的预训练深度神经网络，称为<a class="ae jg" href="https://tfhub.dev/google/universal-sentence-encoder-multilingual/1" rel="noopener ugc nofollow" target="_blank">通用句子编码器多语言</a> ( <a class="ae jg" href="https://arxiv.org/abs/1907.04307" rel="noopener ugc nofollow" target="_blank"> Yan et al .，2019 </a>)并初始化其会话:</p><figure class="lm ln lo lp gt iv"><div class="bz fp l di"><div class="mc md l"/></div></figure><p id="4555" class="pw-post-body-paragraph kg kh jj ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我建议先下载并保存网络，这样你就不用担心每次重启电脑时都要下载了，因为模型总是保存在/tmp 中(至少在 Linux 中是这样)，如果你这样做了，就可以避免这一步。反正用网速下载也要 1 分钟左右。你可以在这里阅读更多关于如何做这件事的<a class="ae jg" href="https://medium.com/@xianbao.qian/how-to-run-tf-hub-locally-without-internet-connection-4506b850a915" rel="noopener">。</a></p></div><div class="ab cl lf lg hx lh" role="separator"><span class="li bw bk lj lk ll"/><span class="li bw bk lj lk ll"/><span class="li bw bk lj lk"/></div><div class="im in io ip iq"><p id="d49c" class="pw-post-body-paragraph kg kh jj ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">到目前为止，我们正在准备我们的环境来进行实际的机器学习。第一个<em class="le">机器学习</em>代码如下，它计算并存储所有句子嵌入，并计算所有可能引用对的距离(<a class="ae jg" href="https://www.tutorialspoint.com/numpy/numpy_inner.htm" rel="noopener ugc nofollow" target="_blank">内积</a>)(当然是在嵌入空间中)。后者以后会派上用场。</p><figure class="lm ln lo lp gt iv"><div class="bz fp l di"><div class="mc md l"/></div></figure><p id="dd55" class="pw-post-body-paragraph kg kh jj ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">请注意，此函数使用之前加载的会话，因此请确保它在您的 Python 环境中进行了初始化。然后，我们将合并的报价列表提供给这个函数:</p><pre class="lm ln lo lp gt lq lr ls lt aw lu bi"><span id="d47a" class="lv lw jj lr b gy lx ly l lz ma">sM_All, e_All = similarity_matrix(merged_list_all)</span></pre><p id="c70d" class="pw-post-body-paragraph kg kh jj ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">还要注意的是，<strong class="ki jk"> e_all </strong>是一个维数为 x 512 的数组(这个数字是 TensorFlow 预训练算法使用的默认嵌入向量大小),而<strong class="ki jk"> sM_All </strong>是我们将在本次分析结束时使用的语义相似度矩阵。因为我们想要做的是对文本进行分类，所以我们缺少了这个难题的一个重要部分，一个类数组。我们知道<strong class="ki jk"> e_All </strong>中所有栏目的排序，我们知道第一大块是<em class="le">浪漫主义</em>，其次是<em class="le">现实主义</em>，最后是<em class="le">超现实主义</em>(所以，三个乐章)。因此，我们可以确定在<strong class="ki jk"> merge_list_all </strong>中给出的每个动作有多少报价，因此:</p><pre class="lm ln lo lp gt lq lr ls lt aw lu bi"><span id="803f" class="lv lw jj lr b gy lx ly l lz ma">classes = np.asarray([1 for i in range(len(merged_list_rom))] + \<br/>[2 for i in range(len(merged_list_rea))] + [3 for i in range(len(merged_list_sur))])</span></pre><p id="64e0" class="pw-post-body-paragraph kg kh jj ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">创建一个类列表，类似于:[1，1，1，1，… 2，2，2，2，…3，3，3]，每个类有正确的实例数。现在我们准备建立一个分类器管道来训练我们的<em class="le">图书管理员算法</em>，并做交叉验证来测试它有多好。为此，我编写了这个简单的函数，增加了提供任何分类器作为输入的灵活性:</p><figure class="lm ln lo lp gt iv"><div class="bz fp l di"><div class="mc md l"/></div></figure><p id="b7e4" class="pw-post-body-paragraph kg kh jj ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">然后，我们定义一个分类器(在这种情况下，我们将使用 sklearn 的多层感知器，您可以尝试其他人，如 SVM、KNN 等。):</p><pre class="lm ln lo lp gt lq lr ls lt aw lu bi"><span id="36bb" class="lv lw jj lr b gy lx ly l lz ma">clf = MLPClassifier(max_iter=500,activation="tanh")</span></pre><p id="fe5d" class="pw-post-body-paragraph kg kh jj ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">然后运行该函数:</p><pre class="lm ln lo lp gt lq lr ls lt aw lu bi"><span id="fe91" class="lv lw jj lr b gy lx ly l lz ma">class_pred, class_test, f1_score = class_pipeline(StandardScaler().fit_transform(e_All),classes,clf)</span></pre><p id="9343" class="pw-post-body-paragraph kg kh jj ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">注意<strong class="ki jk"> e_All </strong>要先标准化，这是另一个<a class="ae jg" href="https://scikit-learn.org/stable/modules/preprocessing.html" rel="noopener ugc nofollow" target="_blank">常见的预处理步骤</a>。</p></div><div class="ab cl lf lg hx lh" role="separator"><span class="li bw bk lj lk ll"/><span class="li bw bk lj lk ll"/><span class="li bw bk lj lk"/></div><div class="im in io ip iq"><p id="6349" class="pw-post-body-paragraph kg kh jj ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">太好了！现在让我们看看结果！所有<em class="le"> k </em>倍的平均值 F1(我们有一个略微不平衡的类别分布，因此，根据一个众所周知的经验法则，在这些情况下，F1 是一个比精确度更好的性能估计值)为:</p><pre class="lm ln lo lp gt lq lr ls lt aw lu bi"><span id="1cea" class="lv lw jj lr b gy lx ly l lz ma">&gt;&gt;&gt;print(np.mean(f1_score))</span><span id="f1b3" class="lv lw jj lr b gy mb ly l lz ma">&gt;&gt;&gt;0.73</span></pre><p id="bd1d" class="pw-post-body-paragraph kg kh jj ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">这么小的样本，一个 F1 = 0.73 真的不差！现在让我们来看看混淆矩阵，以便更好地了解正在发生的事情:</p><figure class="lm ln lo lp gt iv"><div class="bz fp l di"><div class="mc md l"/></div></figure><figure class="lm ln lo lp gt iv gh gi paragraph-image"><div class="gh gi me"><img src="../Images/b203bb2782e636705197d072bfc160f4.png" data-original-src="https://miro.medium.com/v2/resize:fit:606/format:webp/1*NmwIbigvZ0-2W8xyP-unGQ.png"/></div><figcaption class="jc jd gj gh gi je jf bd b be z dk">Confusion Matrix for literary movements</figcaption></figure><p id="c2b3" class="pw-post-body-paragraph kg kh jj ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">看起来<em class="le">现实主义</em>带来了更多的麻烦。这可能是因为它是最少表示的类，这是机器学习中的一个常见问题。我们可以试着用采样下的<strong class="ki jk">(<strong class="ki jk">超过</strong>采样创建合成数据，所以最好使用我们现有的来自<a class="ae jg" href="https://imbalanced-learn.readthedocs.io/en/stable/api.html" rel="noopener ugc nofollow" target="_blank"> imblearn </a>的方法来平衡这些类。现在，我将平衡交叉验证循环之外的类。在实践中，我总是喜欢在验证循环中，并且只在训练集中这样做。为此，只需取消 class_pipeline 中第 6–7 行的注释即可:</strong></p><pre class="lm ln lo lp gt lq lr ls lt aw lu bi"><span id="24e8" class="lv lw jj lr b gy lx ly l lz ma">#sm = EditedNearestNeighbours()<br/>#[features, class_ground] = sm.fit_resample(features, class_ground)</span></pre><p id="1a3f" class="pw-post-body-paragraph kg kh jj ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">现在让我们看看结果:</p><pre class="lm ln lo lp gt lq lr ls lt aw lu bi"><span id="e215" class="lv lw jj lr b gy lx ly l lz ma">&gt;&gt;&gt;print(np.mean(f1_score))</span><span id="0228" class="lv lw jj lr b gy mb ly l lz ma">&gt;&gt;&gt;0.78</span></pre><p id="a2b2" class="pw-post-body-paragraph kg kh jj ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">越来越好！这可能表明一个更大和更平衡的数据集会显示更好的结果！</p><p id="1ec0" class="pw-post-body-paragraph kg kh jj ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">你可能最终会争辩说文学运动是主观定义的，那么为什么这些类会足够强大来显示一致的结果呢？为了测试这一点，我们可以重组类并重新运行管道。简单地做:</p><pre class="lm ln lo lp gt lq lr ls lt aw lu bi"><span id="a45f" class="lv lw jj lr b gy lx ly l lz ma">random.shuffle(classes)</span></pre><p id="4786" class="pw-post-body-paragraph kg kh jj ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">打乱我们一开始定义的课程顺序。再次运行它(使用混排的类)会抛出 F1 = 0.25，反映出我们最初的类边界(<em class="le">浪漫主义</em>、<em class="le">现实主义</em> &amp; <em class="le">超现实主义</em>)是由文本中存在的真实可测量的特征定义的。有意思！</p><p id="fc13" class="pw-post-body-paragraph kg kh jj ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">总之，这一切看起来相当好！请记住，<strong class="ki jk">这是用相对较小的样本(总共不到 170 条引文)和四种不同的语言完成的</strong>！这种方法似乎很有前途！你如何改进它？你认为用这种方法还能做什么？</p></div><div class="ab cl lf lg hx lh" role="separator"><span class="li bw bk lj lk ll"/><span class="li bw bk lj lk ll"/><span class="li bw bk lj lk"/></div><div class="im in io ip iq"><p id="2014" class="pw-post-body-paragraph kg kh jj ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我们可以做的最后一个分析是用我们的距离矩阵来查看所有引用之间的语义距离。还记得<strong class="ki jk"> sM_All </strong>吗？嗯，现在是我们使用它的时候了:</p><figure class="lm ln lo lp gt iv"><div class="bz fp l di"><div class="mc md l"/></div></figure><figure class="lm ln lo lp gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi mf"><img src="../Images/e38cb801cbbec111ac25cd633d2dfdc9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*YPTEbtn99KMPyB8q-fjOuA.png"/></div></div><figcaption class="jc jd gj gh gi je jf bd b be z dk">Semantic similarity between all posible quote pairs. Heatmap represents a symmetric matrix with all semantic similarity values where <em class="mg">very similar quotes are </em>colored in blue and very different in yellow. Right graph represents a render of this matrix where nodes are quotes and connections portray thresholded (see source code) similarity values. Romanticism highlighted with a turquoise blue line, Realism with green and Surrealism with gray. Final figure tweaked with <a class="ae jg" href="https://inkscape.org/" rel="noopener ugc nofollow" target="_blank">Inkscape</a>.</figcaption></figure><p id="00d6" class="pw-post-body-paragraph kg kh jj ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">太好了！使用这种方法，您可以直观地看到完整的报价生态系统。正如您所看到的，一些引用对比其他引用对更相似(距离更接近 1)。具体报价呢？有了这些信息，我们可以检查任何给定的引用，哪一个引用在语义形式上是最接近的！对此我们可以用:</p><figure class="lm ln lo lp gt iv"><div class="bz fp l di"><div class="mc md l"/></div></figure><pre class="lm ln lo lp gt lq lr ls lt aw lu bi"><span id="ebd4" class="lv lw jj lr b gy lx ly l lz ma">#Quote 0 as an example (from Poe):<br/>find_closest(sM_All,merged_list_all,names_mult,0)</span></pre><p id="89bb" class="pw-post-body-paragraph kg kh jj ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">其输出为:</p><pre class="lm ln lo lp gt lq lr ls lt aw lu bi"><span id="8cae" class="lv lw jj lr b gy lx ly l lz ma">‘Edgar_Alan_Poe’,<br/> ‘I have absolutely no pleasure in the stimulants in which I sometimes so madly indulge. It has not been in the pursuit of pleasure that I have periled life and reputation and reason. It has been the desperate attempt to escape from torturing memories, from a sense of insupportable loneliness and a dread of some strange impending doom.’,<br/> ‘Georges_Bataille’,<br/> ‘I enjoyed the innocence of unhappiness and of helplessness; could I blame myself for a sin which attracted me, which flooded me with pleasure precisely to the extent it brought me to despair?’</span></pre><p id="7b11" class="pw-post-body-paragraph kg kh jj ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">你觉得这些引文在语义内容上看起来相似吗？对我来说是的！其他语录/作者呢？您可以研究一下代码来找出答案。这部分分析是我打算在未来深入探讨的。</p><p id="ce02" class="pw-post-body-paragraph kg kh jj ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">提醒:您可以在此查看该项目的完整笔记本<a class="ae jg" href="https://github.com/VictorSaenger/literature-movements" rel="noopener ugc nofollow" target="_blank">。</a></p></div><div class="ab cl lf lg hx lh" role="separator"><span class="li bw bk lj lk ll"/><span class="li bw bk lj lk ll"/><span class="li bw bk lj lk"/></div><div class="im in io ip iq"><p id="a776" class="pw-post-body-paragraph kg kh jj ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我希望这个演示能为您提供一些关于如何使用句子嵌入、分类以及文本相似性的呈现和可视化的见解。你可以在任何领域应用这个，不要觉得局限于文学。事实上，可能的应用程序数量相当大，并且支持如此多的语言，这种算法将长期存在。就我个人而言，我非常惊讶在如此小的样本中看到如此高的 F1 分数。最后，这就是机器学习的力量(当然包括深度学习):通过正确的处理步骤，你可以构建算法，完成手头原始数据似乎不可能完成的工作。图书管理员会很高兴有这样的算法的帮助。</p><p id="909b" class="pw-post-body-paragraph kg kh jj ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">感谢您的阅读！</p></div></div>    
</body>
</html>