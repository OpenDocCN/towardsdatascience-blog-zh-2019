<html>
<head>
<title>Frieze London 2018 (Part 3): Computer Vision</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">2018 年伦敦 Frieze 展(第三部分):计算机视觉</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/frieze-london-2018-part-3-computer-vision-50314f2f4b1?source=collection_archive---------15-----------------------#2019-01-18">https://towardsdatascience.com/frieze-london-2018-part-3-computer-vision-50314f2f4b1?source=collection_archive---------15-----------------------#2019-01-18</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="9519" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">第 3 部分:使用计算机视觉分析 9k 社交媒体图像</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/5001c1c3882717c9f1eb874f519066a3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*kjJkOLSejHBzd3a2niHf7A@2x.png"/></div></div></figure><h2 id="c250" class="ku kv it bd kw kx ky dn kz la lb dp lc ld le lf lg lh li lj lk ll lm ln lo lp bi translated">介绍</h2><p id="068a" class="pw-post-body-paragraph lq lr it ls b lt lu ju lv lw lx jx ly ld lz ma mb lh mc md me ll mf mg mh mi im bi translated">在这一系列的最后一篇博文中，我应用计算机视觉技术来理解 2018 年 10 月 4 日至 7 日举行的 Frieze 伦敦艺术博览会的 9000 张图像。</p><p id="85a9" class="pw-post-body-paragraph lq lr it ls b lt mj ju lv lw mk jx ly ld ml ma mb lh mm md me ll mn mg mh mi im bi translated">Frieze 是每年十月在伦敦摄政公园举办的大型当代艺术博览会，吸引了成千上万的人。来自 20 多个国家的 150 多家画廊参加了盈利性艺术博览会。在过去的几年里，Frieze 还在公园里开创了一个雕塑展。</p><p id="72a0" class="pw-post-body-paragraph lq lr it ls b lt mj ju lv lw mk jx ly ld ml ma mb lh mm md me ll mn mg mh mi im bi translated">在本系列的<a class="ae mo" rel="noopener" target="_blank" href="/london-design-festival-2018-part-2-natural-language-processing-595f3c2dc24f?source=friends_link&amp;sk=23ff5746ca0810a255e2023e52ebd450">第二部分</a>和<a class="ae mo" rel="noopener" target="_blank" href="/analyzing-the-london-design-festival-2018-part-1-7edac3bfb165?source=friends_link&amp;sk=5cbb7a0f8ad17446129f3be1a54b4c85">第一部分</a>中，我展示了对 9000 篇关于展会的社交媒体帖子的自然语言处理和探索性数据分析。本文的目的是<strong class="ls iu">使用计算机视觉分析来理解和联系</strong>9000 张关于 2018 年伦敦奥运会的图片。</p><p id="f09a" class="pw-post-body-paragraph lq lr it ls b lt mj ju lv lw mk jx ly ld ml ma mb lh mm md me ll mn mg mh mi im bi translated">请向下滚动查看分析！</p><h2 id="b86b" class="ku kv it bd kw kx ky dn kz la lb dp lc ld le lf lg lh li lj lk ll lm ln lo lp bi translated">数据和方法</h2><p id="edf1" class="pw-post-body-paragraph lq lr it ls b lt lu ju lv lw lx jx ly ld lz ma mb lh mc md me ll mf mg mh mi im bi translated">这一事件的官方标签是#frieze。在事件<a class="ae mo" rel="noopener" target="_blank" href="/access-data-from-twitter-api-using-r-and-or-python-b8ac342d3efe">发生时，我通过 Twitter API </a>和<a class="ae mo" href="https://developers.facebook.com/docs/instagram-api/" rel="noopener ugc nofollow" target="_blank"> Instagram API </a>收集了 9000 个包含这个标签的帖子。<a class="ae mo" rel="noopener" target="_blank" href="/frieze-london-2018-part-2-natural-language-processing-66d0627f39af">阅读第 2 部分了解更多</a>。</p><p id="eb19" class="pw-post-body-paragraph lq lr it ls b lt mj ju lv lw mk jx ly ld ml ma mb lh mm md me ll mn mg mh mi im bi translated">然后，使用<a class="ae mo" href="https://cloud.google.com/vision/docs/" rel="noopener ugc nofollow" target="_blank">谷歌云的视觉 API </a>提取每张图像的标签。Cloud Vision API 利用“谷歌庞大的机器学习专业知识网络”(g <a class="ae mo" href="https://medium.com/@srobtweets/exploring-the-cloud-vision-api-1af9bcf080b8" rel="noopener"> reat article </a>作者<a class="mp mq ep" href="https://medium.com/u/7f2ab73b39f8?source=post_page-----50314f2f4b1--------------------------------" rel="noopener" target="_blank"> Sara Robinson </a>)来检测图像的特征和标签。总共有 1045 个不同的标签被赋予了 3300 张图片。</p><p id="3c2c" class="pw-post-body-paragraph lq lr it ls b lt mj ju lv lw mk jx ly ld ml ma mb lh mm md me ll mn mg mh mi im bi translated">被称为<strong class="ls iu">特征提取</strong>和<strong class="ls iu">反向图像搜索</strong>的机器学习技术然后使用<a class="ae mo" href="http://ml4a.github.io/ml4a/" rel="noopener ugc nofollow" target="_blank">基因科岗的代码</a>完成，以基于视觉相似性找到图像。首先，使用预训练的卷积神经网络来提取每幅图像的“特征”，然后，计算这些特征的<a class="ae mo" href="https://en.wikipedia.org/wiki/Cosine_similarity" rel="noopener ugc nofollow" target="_blank">余弦相似度</a>，以“搜索”与查询图像相似的少量图像。</p><p id="6bf6" class="pw-post-body-paragraph lq lr it ls b lt mj ju lv lw mk jx ly ld ml ma mb lh mm md me ll mn mg mh mi im bi translated">特征在计算机视觉中的主要作用是“<a class="ae mo" href="https://medium.com/machine-learning-world/feature-extraction-and-similar-image-search-with-opencv-for-newbies-3c59796bf774" rel="noopener">将视觉信息转换到向量空间</a>”。相似的图像应该产生相似的特征，我们可以利用这些特征进行信息检索。基于这些特征，我们还可以使用一种叫做 t-SNE 的方法通过相似性对图像进行聚类。</p><h2 id="8b3d" class="ku kv it bd kw kx ky dn kz la lb dp lc ld le lf lg lh li lj lk ll lm ln lo lp bi translated">图像分析</h2><p id="501e" class="pw-post-body-paragraph lq lr it ls b lt lu ju lv lw lx jx ly ld lz ma mb lh mc md me ll mf mg mh mi im bi translated">在这一节中，我将展示我的计算机视觉分析的结果。下面，我报告以下三个指标:</p><ol class=""><li id="8a5e" class="mr ms it ls b lt mj lw mk ld mt lh mu ll mv mi mw mx my mz bi translated">图像的标签检测；</li><li id="41aa" class="mr ms it ls b lt na lw nb ld nc lh nd ll ne mi mw mx my mz bi translated">基于视觉相似性的图像搜索:</li><li id="78eb" class="mr ms it ls b lt na lw nb ld nc lh nd ll ne mi mw mx my mz bi translated">基于视觉相似性的图像聚类。</li></ol><h2 id="b682" class="ku kv it bd kw kx ky dn kz la lb dp lc ld le lf lg lh li lj lk ll lm ln lo lp bi translated">标签检测</h2><p id="9032" class="pw-post-body-paragraph lq lr it ls b lt lu ju lv lw lx jx ly ld lz ma mb lh mc md me ll mf mg mh mi im bi translated">每张照片的标签都是使用<a class="ae mo" href="https://cloud.google.com/vision/" rel="noopener ugc nofollow" target="_blank">谷歌云视觉 API </a>生成的。这背后的想法是将图片分类，这样我就可以识别相似的图片。下面的条形图显示了 3，300 张图片的前 10 个标签。</p><p id="4740" class="pw-post-body-paragraph lq lr it ls b lt mj ju lv lw mk jx ly ld ml ma mb lh mm md me ll mn mg mh mi im bi translated">我们看到，“艺术”是最常见的标签，其次是“现代”、“绘画”和“艺术品”。但是看到“树”、“草”和“天空”出现也很有趣，因为它表明许多图像是关于雕塑公园的(我们将在后面看到更多)。</p><p id="93cf" class="pw-post-body-paragraph lq lr it ls b lt mj ju lv lw mk jx ly ld ml ma mb lh mm md me ll mn mg mh mi im bi translated">然而，这些标签并没有明确描述艺术品本身——我对稍微详细一点的上下文理解感兴趣——这凸显了一些 API 标签检测技术的缺点。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nf ng l"/></div></figure><h2 id="d9d6" class="ku kv it bd kw kx ky dn kz la lb dp lc ld le lf lg lh li lj lk ll lm ln lo lp bi translated">图像搜索—视觉相似性</h2><p id="5ae2" class="pw-post-body-paragraph lq lr it ls b lt lu ju lv lw lx jx ly ld lz ma mb lh mc md me ll mf mg mh mi im bi translated">我们可以通过编程让计算机学习图像之间的视觉相似性，而不是使用标签来理解图像。一种叫做<strong class="ls iu">特征提取</strong>和<strong class="ls iu">反向图像搜索</strong>的技术就是这样做的。</p><p id="7d53" class="pw-post-body-paragraph lq lr it ls b lt mj ju lv lw mk jx ly ld ml ma mb lh mm md me ll mn mg mh mi im bi translated">使用在<a class="ae mo" href="https://www.tensorflow.org/guide/keras" rel="noopener ugc nofollow" target="_blank"> TensorFlow 后端</a>上运行的<a class="ae mo" href="https://keras.io/applications/#vgg16" rel="noopener ugc nofollow" target="_blank"> Keras VGG16 </a>神经网络模型，我首先为数据集中的每张图像提取了一个特征。一个特征是每个图像的 4096 元素的数字数组。我们的期望是“该特征形成图像的非常好的表示，使得相似的图像将具有相似的特征”(<a class="ae mo" href="http://ml4a.github.io/ml4a/convnets/" rel="noopener ugc nofollow" target="_blank">吉恩·科岗，2018 </a>)。</p><p id="0136" class="pw-post-body-paragraph lq lr it ls b lt mj ju lv lw mk jx ly ld ml ma mb lh mm md me ll mn mg mh mi im bi translated">然后使用主成分分析(PCA)降低特征的维度，以创建一个<a class="ae mo" href="https://developers.google.com/machine-learning/crash-course/embeddings/video-lecture" rel="noopener ugc nofollow" target="_blank">嵌入</a>，然后计算一个图像的 PCA 嵌入到另一个图像的距离<a class="ae mo" href="https://en.wikipedia.org/wiki/Cosine_similarity" rel="noopener ugc nofollow" target="_blank">余弦距离</a>。我终于能够向计算机发送随机查询图像，它选择并返回数据集中具有相似特征向量的五个其他图像。</p><p id="8576" class="pw-post-body-paragraph lq lr it ls b lt mj ju lv lw mk jx ly ld ml ma mb lh mm md me ll mn mg mh mi im bi translated">以下是四个例子:</p><div class="kj kk kl km gt ab cb"><figure class="nh kn ni nj nk nl nm paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><img src="../Images/e87072af6d59a43b2ee435109271f519.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*v0BmRvLiW1v4UqKuFeQ4OA@2x.png"/></div></figure><figure class="nh kn ni nj nk nl nm paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><img src="../Images/dff5bd5a524d21fc78f74f4aaa5c58f0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*Ct2R3qOVl9WAGGpp560yFw@2x.png"/></div><figcaption class="nn no gj gh gi np nq bd b be z dk nr di ns nt">Richard Woods, ‘Holiday Home’ Alan Cristea Gallery (left) and Conrad Shawcross, ‘Optic Labyrinth (Arrangement I)’, Victoria Miro (right) at Sculpture Park</figcaption></figure></div><div class="ab cb"><figure class="nh kn ni nj nk nl nm paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><img src="../Images/72bd4d4514c283528e173fb79cbc0faa.png" data-original-src="https://miro.medium.com/v2/resize:fit:1002/format:webp/1*l69vPlv-4d0R_2DStiXnow@2x.png"/></div></figure><figure class="nh kn ni nj nk nl nm paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><img src="../Images/8705e80a3893c6a5ed4a29710a9f52e1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1002/format:webp/1*q-xkdJslT_wUylvCZKPozg@2x.png"/></div><figcaption class="nn no gj gh gi np nq bd b be z dk nr di ns nt">David Shrigley, Distractions (2018) and “My Artwork is Terrible and I am a Very Bad Person”, Stephen Friedman Gallery at Frieze London Art Fair 2018</figcaption></figure></div><p id="2258" class="pw-post-body-paragraph lq lr it ls b lt mj ju lv lw mk jx ly ld ml ma mb lh mm md me ll mn mg mh mi im bi translated">当试图从一个包含许多图片的相册中找到相似的图片时，这种技术非常有用，事实上我就是这么做的！</p><h2 id="d9e9" class="ku kv it bd kw kx ky dn kz la lb dp lc ld le lf lg lh li lj lk ll lm ln lo lp bi translated">图像聚类—相似性</h2><p id="e3c7" class="pw-post-body-paragraph lq lr it ls b lt lu ju lv lw lx jx ly ld lz ma mb lh mc md me ll mf mg mh mi im bi translated">既然我们在向量空间中嵌入了每个图像，我们可以使用一种流行的叫做 t-SNE 的机器学习可视化算法来聚类，然后在二维空间中可视化向量空间。</p><blockquote class="nu"><p id="9de2" class="nv nw it bd nx ny nz oa ob oc od mi dk translated">“tSNE 的目标是聚集相似数据点的小“邻域”,同时减少数据的整体维度，以便更容易可视化”(谷歌人工智能博客，2018 年)</p></blockquote><p id="9785" class="pw-post-body-paragraph lq lr it ls b lt oe ju lv lw of jx ly ld og ma mb lh oh md me ll oi mg mh mi im bi translated">下面我们看到基于视觉相似性的聚类形成。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oj"><img src="../Images/eb24807abd600437a20d48ef19d3d0dc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*4OJI9RNQMKsz-St_fcW5TA@2x.png"/></div></div></figure><p id="8442" class="pw-post-body-paragraph lq lr it ls b lt mj ju lv lw mk jx ly ld ml ma mb lh mm md me ll mn mg mh mi im bi translated">在下面的图片中，我突出了一些来自博览会的艺术品——大卫·施莱格利的<em class="ok">分心</em>，塔蒂亚娜·特鲁夫的<em class="ok">萨满</em>和来自弗里兹雕塑公园的各种雕塑——以及它们的集群简介。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ol"><img src="../Images/b0addc00ad75e8ead12a0b46744a2581.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*VM_ptgV2y3gjxgrwTYJgAg@2x.png"/></div></div><figcaption class="nn no gj gh gi np nq bd b be z dk">The clustering of images of works of art at Frieze London 2018. Source: Instagram, Twitter, Flickr</figcaption></figure><h2 id="b019" class="ku kv it bd kw kx ky dn kz la lb dp lc ld le lf lg lh li lj lk ll lm ln lo lp bi translated">结论</h2><p id="a7f4" class="pw-post-body-paragraph lq lr it ls b lt lu ju lv lw lx jx ly ld lz ma mb lh mc md me ll mf mg mh mi im bi translated">所以你有它！我只是刚刚涉足计算机视觉的奇妙世界。还有很多东西需要我去学习，但这对我来说是很好的第一步。</p><p id="f4f3" class="pw-post-body-paragraph lq lr it ls b lt mj ju lv lw mk jx ly ld ml ma mb lh mm md me ll mn mg mh mi im bi translated">我的发现表明，使用机器学习和计算机视觉技术来理解和联系 Frieze air fair 的图像是可能的。</p><p id="c72c" class="pw-post-body-paragraph lq lr it ls b lt mj ju lv lw mk jx ly ld ml ma mb lh mm md me ll mn mg mh mi im bi translated">对我来说，下一步显然是计算在数据集中出现了多少艺术装置，以衡量“受欢迎程度”。我将继续研究这个数据集。</p><h2 id="3516" class="ku kv it bd kw kx ky dn kz la lb dp lc ld le lf lg lh li lj lk ll lm ln lo lp bi translated">结束了</h2><p id="b3b2" class="pw-post-body-paragraph lq lr it ls b lt lu ju lv lw lx jx ly ld lz ma mb lh mc md me ll mf mg mh mi im bi translated">这是我关于 Frieze London 2018 的博客系列的结尾！这个系列是我正在进行的关于使用数据科学来理解和衡量城市文化影响的长期讨论的一部分。</p><p id="43c2" class="pw-post-body-paragraph lq lr it ls b lt mj ju lv lw mk jx ly ld ml ma mb lh mm md me ll mn mg mh mi im bi translated">今年，我将开始新的项目，主要是 JavaScript。敬请期待！</p><p id="a77e" class="pw-post-body-paragraph lq lr it ls b lt mj ju lv lw mk jx ly ld ml ma mb lh mm md me ll mn mg mh mi im bi translated">感谢阅读！</p><p id="17b6" class="pw-post-body-paragraph lq lr it ls b lt mj ju lv lw mk jx ly ld ml ma mb lh mm md me ll mn mg mh mi im bi translated">Vishal</p><p id="a950" class="pw-post-body-paragraph lq lr it ls b lt mj ju lv lw mk jx ly ld ml ma mb lh mm md me ll mn mg mh mi im bi translated"><a class="ae mo" href="https://vishalkumar.london/" rel="noopener ugc nofollow" target="_blank"> <em class="ok"> Vishal </em> </a> <em class="ok">是伦敦 UCL</em><a class="ae mo" href="https://www.ucl.ac.uk/bartlett/" rel="noopener ugc nofollow" target="_blank"><em class="ok">The Bartlett</em></a><em class="ok">的文化数据科学家和研究生。他对城市文化的经济和社会影响感兴趣。</em></p></div></div>    
</body>
</html>