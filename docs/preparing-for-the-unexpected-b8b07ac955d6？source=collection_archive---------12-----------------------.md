# 为意外做准备

> 原文：<https://towardsdatascience.com/preparing-for-the-unexpected-b8b07ac955d6?source=collection_archive---------12----------------------->

## 如何将您的模型应用到从未见过的输入中

![](img/ae754b6c563e126c84cb03fa01e05030.png)

我们使用机器学习解决的一些问题涉及代表现实世界对象的分类特征，如单词、项目和类别。那么，当我们在推理时得到从未见过的新对象值时，会发生什么呢？我们如何提前做好准备，以便仍然能够理解输入的内容？

看不见的值，也称为 OOV(不在词汇表中)值，必须正确处理。不同的算法有不同的方法来处理 OOV 值。对分类特征的不同假设也应区别对待。

在这篇文章中，我将重点关注深度学习应用于动态数据的情况，其中新的值一直在出现。我将以 Taboola 的推荐系统为例。模型在推理时获得的一些输入包含看不见的值——这在推荐系统中很常见。例子包括:

*   项目 id:每个可推荐的项目都有一个唯一的标识符。每天都有数以千计的新项目进入系统。
*   广告商 id:赞助内容是由广告商创建的。与新项目的数量相比，新的每日广告客户的数量要少得多。尽管如此，正确处理它们是很重要的，尤其是因为我们想要支持新的广告客户。

那么，OOV 价值观的挑战是什么？

# 学习处理 OOV 价值观

OOV 值与模型在训练时看不到的值相关联。因此，如果我们在推理时得到一个 OOV 值，模型不知道如何处理它。

一个简单的解决方案是在训练之前用一个特殊的 OOV 令牌替换所有罕见的值。因为从模型的角度来看，所有 OOV 值都是相同的，所以我们将在推理时用 OOV 令牌替换它们。该解决方案有两个积极的结果:

1.  模特在训练时会接触到 OOV 令牌。在深度学习中，我们通常嵌入分类特征。训练后，模型将学习所有 OOV 值的有意义的嵌入。
2.  将减轻过度适应稀有值的风险。这些值出现在少数示例中。如果我们学习这些值的嵌入，模型可能会学习使用它们来解释这些特定示例中的特殊性或随机噪声。学习这些嵌入可能导致的另一个灾难是没有足够的梯度更新传播给它们。因此，相对于通过训练学习的信号，随机初始化将支配结果嵌入。

问题解决了…还是？

# 处理 OOV 价值观很难！

该模型使用项目 id 功能来记忆每个项目的不同信息，类似于纯粹的[协同过滤](https://en.wikipedia.org/wiki/Collaborative_filtering)方法。注入了 OOV 令牌的稀有物品无法从中受益，因此模型对它们的性能更差。

有趣的是，即使我们在训练时完全不使用物品 id，模型在稀有物品上的表现仍然更差！这是因为他们来自不同于一般人群的分布。它们具有特定的特征——可能它们在网上的表现很差，这导致 Taboola 的推荐系统较少推荐它们，反过来——它们在数据集中变得罕见。那么为什么这种分布差异很重要呢？

如果我们用这个特殊分布来学习 OOV 嵌入，它不会推广到一般人群。请这样想——每个项目在某个时候都是一个新项目。在那时，它被注入了 OOV 令牌。所以 OOV 嵌入应该对所有可能的项目都执行得很好。

# 随机性是数据科学家最好的朋友

为了使用一般群体来学习 OOV 嵌入，我们可以在开始训练过程之前将 OOV 令牌注入到来自数据集中的随机样本集中。但是有多少例子就够了呢？

我们采样越多，OOV 嵌入就越好。但同时，该模型将暴露于更少数量的非 OOV 值，因此性能将下降。

我们如何使用大量的例子来训练 OOV 嵌入，同时使用相同的例子来训练非 OOV 嵌入？我们没有在开始训练之前随机注入 OOV 令牌，而是选择了以下方法:在每个时期，模型使用所有可用的值进行训练(不注入 OOV 令牌)。在纪元结束时，我们随机抽取一组样本，注入 OOV 令牌，并再次训练模型。这样，我们享受两个世界！

和前面的方法一样，我们也将 OOV 令牌注入稀有值，以避免过度拟合。

为了评估新的方法，我们将 OOV 令牌注入到所有的示例中，并评估了我们的离线度量(MSE)。与在模型开始训练之前随机注入 OOV 令牌相比，它提高了 15%。

# 最后的想法

在我们想到新方法之前，我们的模型已经在生产中使用了很长时间。很容易忽略这种潜在的性能提升，因为该模型整体性能良好。它只是强调了一个事实，你总是要寻找意想不到的！

*原文由我在*[](https://engineering.taboola.com/preparing-for-the-unexpected)**发表。**