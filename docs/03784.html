<html>
<head>
<title>An End to End Introduction to GANs</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">GANs 的端到端介绍</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/an-end-to-end-introduction-to-gans-bf253f1fa52f?source=collection_archive---------4-----------------------#2019-06-15">https://towardsdatascience.com/an-end-to-end-introduction-to-gans-bf253f1fa52f?source=collection_archive---------4-----------------------#2019-06-15</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="fea9" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">柠檬榨汁机</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/5e5d71400aa9765c8740b99429add950.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*DGcskWESjWM59OEs.png"/></div></div></figure><p id="7481" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">我敢打赌，我们大多数人最近都见过很多人工智能生成的人脸，无论是在报纸上还是博客上。我们已经到达了一个阶段，在这个阶段，区分真实的人脸和人工智能生成的人脸变得越来越困难。</p><p id="0cbe" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">在这篇文章中，我将帮助读者理解他们如何自己创建和构建这样的应用程序。T3】</p><p id="0242" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">对于初学者来说，我会尽可能保持这篇文章的直观性，同时不会让它变得太简单。</p><p id="4679" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated"><strong class="kw iu"> <em class="lq">这个帖子是关于了解</em></strong><a class="ae lr" href="https://amzn.to/32FMOWF" rel="noopener ugc nofollow" target="_blank"><strong class="kw iu"><em class="lq">GANs</em></strong></a><strong class="kw iu"><em class="lq">如何工作的。</em> </strong></p></div><div class="ab cl ls lt hx lu" role="separator"><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx"/></div><div class="im in io ip iq"><h1 id="3977" class="lz ma it bd mb mc md me mf mg mh mi mj jz mk ka ml kc mm kd mn kf mo kg mp mq bi translated">任务概述</h1><p id="0542" class="pw-post-body-paragraph ku kv it kw b kx mr ju kz la ms jx lc ld mt lf lg lh mu lj lk ll mv ln lo lp im bi translated">我将致力于使用动漫人物数据集创建我们自己的动漫人物。 </p><p id="736f" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">我在这里使用的 DC-甘风格的甘不仅可以生成人脸或者新的动漫角色；它还可以用于创建现代时尚风格，用于一般的内容创建，有时也用于数据扩充目的。</p><p id="61e6" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">在我看来，GANs 将会改变视频游戏和特效的制作方式。这种方法可以按需创建逼真的纹理或角色。T25】</p><p id="62fc" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">你可以在 Github 库中找到本章的完整代码。我还把代码上传到了谷歌实验室，这样你就可以自己尝试了。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="ab gu cl mw"><img src="../Images/e18cf18ffb74ce2c136d7d3b4cfae612.png" data-original-src="https://miro.medium.com/v2/format:webp/1*g_x1-5iYRn-SmdVucceiWw.png"/></div></figure></div><div class="ab cl ls lt hx lu" role="separator"><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx"/></div><div class="im in io ip iq"><h1 id="a91d" class="lz ma it bd mb mc md me mf mg mh mi mj jz mk ka ml kc mm kd mn kf mo kg mp mq bi translated">使用 DCGAN 架构生成动漫图像</h1><p id="91a0" class="pw-post-body-paragraph ku kv it kw b kx mr ju kz la ms jx lc ld mt lf lg lh mu lj lk ll mv ln lo lp im bi translated">像往常一样，在我们进入编码之前，深入研究一下理论会有所帮助。</p><p id="93a1" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">DC-甘的主要思想源于亚历克·拉德福德、卢克·梅斯和索史密斯·钦塔拉在 2016 年写的论文<a class="ae lr" href="https://arxiv.org/pdf/1511.06434.pdf" rel="noopener ugc nofollow" target="_blank">深度卷积生成对抗网络的无监督表示学习</a>。</p><p id="bb03" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">虽然我将在接下来的几节中解释这篇论文，但是请务必看一看它。这是一篇优秀的论文。</p></div><div class="ab cl ls lt hx lu" role="separator"><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx"/></div><div class="im in io ip iq"><h1 id="5f57" class="lz ma it bd mb mc md me mf mg mh mi mj jz mk ka ml kc mm kd mn kf mo kg mp mq bi translated">直觉:生成假图像的 GANs 简介</h1><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi mx"><img src="../Images/1b1d8b1e130cc57b964b46e9ab9a6adf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*btO2vBsXLOT-VY9z"/></div></div></figure><p id="4fee" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">通常情况下，<strong class="kw iu"> <em class="lq"> GANs 采用两个决斗神经网络来训练计算机学习数据集的性质，足以生成令人信服的假货。</em> </strong></p><p id="4fc3" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">我们可以将此视为两个系统，其中一个神经网络工作以生成假货(生成器)，另一个神经网络(鉴别器)试图对哪个图像是假货进行分类。</p><p id="c447" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">由于发生器和鉴别器网络都重复这样做，网络最终会更好地完成各自的任务。</p><p id="964d" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated"><strong class="kw iu"> <em class="lq">把这个想成剑术那么简单。</em> </strong>两个 noobs 开始互相对打。过了一会儿，两人的剑术都变得更好。</p><p id="ab53" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated"><strong class="kw iu"> <em class="lq">或者你也可以把这个想成一个强盗(发电机)和一个警察(鉴别器)。在多次盗窃之后，强盗变得更擅长偷窃，而警察变得更擅长抓强盗。<em class="lq">在理想的世界里。</em></em></strong></p><p id="9c25" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">这些神经网络中的损耗主要是另一个网络表现如何的函数:</p><ul class=""><li id="ac70" class="my mz it kw b kx ky la lb ld na lh nb ll nc lp nd ne nf ng bi translated">鉴别器网络损耗是发生器网络质量的函数——如果鉴别器被发生器的假图像欺骗，那么鉴别器的损耗很高</li><li id="9a2a" class="my mz it kw b kx nh la ni ld nj lh nk ll nl lp nd ne nf ng bi translated">发电机网络损耗是鉴频器网络质量的函数，如果发电机不能欺骗鉴频器，损耗就很高。</li></ul><p id="3e1f" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">在训练阶段，我们依次训练鉴别器和发生器网络，以提高鉴别器和发生器的性能。</p><p id="079d" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">目标是最终得到帮助生成器生成逼真图像的权重。<strong class="kw iu"> <em class="lq">最后，我们可以使用生成器神经网络从随机噪声中生成假图像。</em>T13】</strong></p></div><div class="ab cl ls lt hx lu" role="separator"><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx"/></div><div class="im in io ip iq"><h1 id="e70f" class="lz ma it bd mb mc md me mf mg mh mi mj jz mk ka ml kc mm kd mn kf mo kg mp mq bi translated">发电机架构</h1><p id="9d06" class="pw-post-body-paragraph ku kv it kw b kx mr ju kz la ms jx lc ld mt lf lg lh mu lj lk ll mv ln lo lp im bi translated">我们面对的一个主要问题是 GANs 的训练不是很稳定。因此，我们必须想出一个生成器架构来解决我们的问题，并产生稳定的训练。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nm"><img src="../Images/149bd8ad9cc855f3c5d1cba77111cfaa.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*5vJpiPPC366PPsir.png"/></div></div></figure><p id="5053" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">上图摘自论文，解释了 DC-GAN 发生器的架构。这可能看起来有点混乱。</p><p id="9ebd" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">本质上，我们可以将生成器神经网络视为一个黑盒，它接受一个 100 大小的正常生成的数字向量作为输入，并为我们提供一个图像:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nn"><img src="../Images/8bdbfebd31c12b24cbc0d0ca525d0b4b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*G-tHnbG4LqP7fj1_.png"/></div></div></figure><p id="c304" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated"><strong class="kw iu"> <em class="lq">我们如何得到这样的架构？</em> </strong></p><p id="acfc" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">在下面的架构中，我们使用大小为 4x4x1024 的密集层从这个 100 维向量中创建一个密集向量。然后，我们用 1024 个滤镜将这个密集矢量重新塑造成 4x4 的图像形状，如下图所示:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi no"><img src="../Images/99815ad5e749d4c5501534d482548e58.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*u25dV4ccF-xDljhR.png"/></div></div></figure><p id="e067" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">我们现在不必担心任何权重，因为网络本身会在训练时学习这些权重。</p><p id="fa3c" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">一旦我们有了 1024 个 4x4 的贴图，我们就使用一系列转置卷积进行上采样，在每次操作之后，图像的大小加倍，贴图的数量减半。在最后一步中，虽然我们没有将贴图的数量减半，但是将每个 RGB 通道的贴图数量减少到 3 个通道/贴图，因为我们需要 3 个通道来输出图像。</p><h2 id="3fb7" class="np ma it bd mb nq nr dn mf ns nt dp mj ld nu nv ml lh nw nx mn ll ny nz mp oa bi translated">什么是转置卷积？</h2><p id="ce7c" class="pw-post-body-paragraph ku kv it kw b kx mr ju kz la ms jx lc ld mt lf lg lh mu lj lk ll mv ln lo lp im bi translated">最简单地说，<strong class="kw iu"> <em class="lq">转置卷积为我们提供了一种对图像进行上采样的方法。</em> </strong>在卷积运算中，我们试图从 4x4 图像到 2x2 图像，而在转置卷积中，我们从 2x2 到 4x4 进行卷积，如下图所示:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ob"><img src="../Images/54d99735e5093255c716fa94a580cc0b.png" data-original-src="https://miro.medium.com/v2/resize:fit:688/format:webp/0*r94-kX2tOj-W73Bi.png"/></div><figcaption class="oc od gj gh gi oe of bd b be z dk"><strong class="bd og">Upsampling a 2x2 image to 4x4 image</strong></figcaption></figure><p id="97e0" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated"><strong class="kw iu"> <em class="lq">问:</em> </strong>我们知道，在卷积神经网络(CNN)中，Un-pooling 普遍用于对输入特征图进行上采样。为什么我们不使用取消池？</p><p id="a6c6" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">这是因为取消汇集不涉及任何学习。然而，转置卷积是可以学习的，这就是为什么我们更喜欢转置卷积而不是反池。它们的参数可以被发电机学习，我们将在一段时间内看到。</p><h1 id="e07f" class="lz ma it bd mb mc oh me mf mg oi mi mj jz oj ka ml kc ok kd mn kf ol kg mp mq bi translated">鉴别器架构</h1><p id="e9af" class="pw-post-body-paragraph ku kv it kw b kx mr ju kz la ms jx lc ld mt lf lg lh mu lj lk ll mv ln lo lp im bi translated">现在，我们已经理解了生成器架构，这里是作为黑盒的鉴别器。</p><p id="611b" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">实际上，它包含一系列的卷积层，并在末端包含一个密集层，以预测图像是否是假的，如下图所示:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi om"><img src="../Images/24fdd9612e2be003f174a03356004631.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*DYURqDN7siVz3uNs.png"/></div></div></figure><p id="1b88" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">将图像作为输入，并预测它是真是假。<strong class="kw iu"><em class="lq">conv 网曾经的每一个形象。</em>T11】</strong></p><h1 id="9a42" class="lz ma it bd mb mc oh me mf mg oi mi mj jz oj ka ml kc ok kd mn kf ol kg mp mq bi translated">数据预处理和可视化</h1><p id="39bd" class="pw-post-body-paragraph ku kv it kw b kx mr ju kz la ms jx lc ld mt lf lg lh mu lj lk ll mv ln lo lp im bi translated">我们要做的第一件事是查看数据集中的一些图像。以下是可视化数据集中部分影像的 python 命令:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="on oo l"/></div></figure><p id="f87f" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">结果输出如下:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi op"><img src="../Images/b75d6e931c365da80b930625878447e5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*SCwcaj-Clra42SOd.png"/></div></div></figure><p id="781d" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">我们可以看到图像的大小和图像本身。</p><p id="ea04" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">在这种特殊情况下，我们还需要函数将图像预处理为 64x64x3 的标准大小，然后再继续我们的训练。</p><p id="abae" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">在我们使用它来训练我们的 GAN 之前，我们还需要标准化图像像素。你可以看到它的代码被很好地注释了。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="on oo l"/></div></figure><p id="1c1d" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">正如您将看到的，我们将在代码的培训部分使用前面定义的函数。</p></div><div class="ab cl ls lt hx lu" role="separator"><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx"/></div><div class="im in io ip iq"><h1 id="9420" class="lz ma it bd mb mc md me mf mg mh mi mj jz mk ka ml kc mm kd mn kf mo kg mp mq bi translated">DCGAN 的实现</h1><p id="f767" class="pw-post-body-paragraph ku kv it kw b kx mr ju kz la ms jx lc ld mt lf lg lh mu lj lk ll mv ln lo lp im bi translated">这是我们定义 DCGAN 的部分。我们将定义噪声发生器功能、发生器架构和鉴别器架构。</p><h2 id="ad32" class="np ma it bd mb nq nr dn mf ns nt dp mj ld nu nv ml lh nw nx mn ll ny nz mp oa bi translated">为发电机生成噪声矢量</h2><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oq"><img src="../Images/ff5baba16389f4dead8f04624b702feb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*2SepujHOsQHutYj8"/></div></div><figcaption class="oc od gj gh gi oe of bd b be z dk">Kids: Normal Noise generators</figcaption></figure><p id="695f" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">下面的代码块是一个帮助器函数，为生成器创建一个预定义长度的噪声向量。它将产生噪声，我们希望使用我们的发生器架构将其转换为图像。</p><p id="9e29" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">我们使用正态分布</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi or"><img src="../Images/10bf3f63dfd3e14303315adb50fbbad2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*MQspqgJbMj2BnO22.png"/></div></div></figure><p id="6ade" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">要生成噪声矢量，请执行以下操作:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="on oo l"/></div></figure><h2 id="a38e" class="np ma it bd mb nq nr dn mf ns nt dp mj ld nu nv ml lh nw nx mn ll ny nz mp oa bi translated">发电机架构</h2><p id="59e3" class="pw-post-body-paragraph ku kv it kw b kx mr ju kz la ms jx lc ld mt lf lg lh mu lj lk ll mv ln lo lp im bi translated">发电机是 GAN 中最关键的部分。</p><p id="11c9" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">在这里，我通过添加一些转置卷积层来创建一个生成器，以便对图像的噪声向量进行上采样。</p><p id="f780" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">正如你所注意到的，这个发生器的结构与 DC-甘最初的论文中给出的不同。</p><p id="da50" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">我需要对架构进行一些更改，以更好地适应我们的数据，因此我在中间添加了一个卷积层，并从生成器架构中删除了所有密集层，使其完全卷积。</p><p id="da96" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">我也用了很多动量为 0.5，漏 ReLU 激活的 Batchnorm 层。我用的是β=0.5 的亚当优化器。下面的代码块是我将用来创建生成器的函数:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="on oo l"/></div></figure><p id="c7cf" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">您可以绘制最终的发电机模型:</p><pre class="kj kk kl km gt os ot ou ov aw ow bi"><span id="6c8b" class="np ma it ot b gy ox oy l oz pa">plot_model(generator, to_file='gen_plot.png', show_shapes=True, show_layer_names=True)</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi pb"><img src="../Images/fe049200bd734639f5fdd539cba68944.png" data-original-src="https://miro.medium.com/v2/resize:fit:1250/format:webp/1*zW9vQ-2SKZg1c-GpF4cIxg.png"/></div><figcaption class="oc od gj gh gi oe of bd b be z dk">Generator Architecture</figcaption></figure><h2 id="2cd0" class="np ma it bd mb nq nr dn mf ns nt dp mj ld nu nv ml lh nw nx mn ll ny nz mp oa bi translated">鉴别器架构</h2><p id="ef29" class="pw-post-body-paragraph ku kv it kw b kx mr ju kz la ms jx lc ld mt lf lg lh mu lj lk ll mv ln lo lp im bi translated">这是鉴别器架构，我使用一系列卷积层和最后的密集层来预测图像是否是假的。</p><p id="e0e7" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">以下是鉴别器的架构:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="on oo l"/></div></figure><pre class="kj kk kl km gt os ot ou ov aw ow bi"><span id="37ac" class="np ma it ot b gy ox oy l oz pa">plot_model(discriminator, to_file='dis_plot.png', show_shapes=True, show_layer_names=True)</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi pb"><img src="../Images/eee8a54b31e71a9756eeac324c32da92.png" data-original-src="https://miro.medium.com/v2/resize:fit:1250/format:webp/1*oSzLQpc1VgOg2YE_sebVgA.png"/></div><figcaption class="oc od gj gh gi oe of bd b be z dk">Discriminator Architecture</figcaption></figure></div><div class="ab cl ls lt hx lu" role="separator"><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx"/></div><div class="im in io ip iq"><h1 id="47a2" class="lz ma it bd mb mc md me mf mg mh mi mj jz mk ka ml kc mm kd mn kf mo kg mp mq bi translated">培养</h1><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oq"><img src="../Images/4b5db2cdacf7e588d15580b4bdc7f59f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*OjIw7GFIkonGjfcc"/></div></div></figure><p id="a1ea" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">理解 GAN 中的培训是非常重要的。或许还有点意思。</p><p id="9ff7" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">我首先使用上一节中定义的函数创建我们的鉴别器和生成器:</p><pre class="kj kk kl km gt os ot ou ov aw ow bi"><span id="e443" class="np ma it ot b gy ox oy l oz pa">discriminator = get_disc_normal(image_shape)<br/>generator = get_gen_normal(noise_shape)</span></pre><p id="ccf1" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">然后，发生器和鉴别器相结合，形成最终的 GAN。</p><pre class="kj kk kl km gt os ot ou ov aw ow bi"><span id="b661" class="np ma it ot b gy ox oy l oz pa">discriminator.trainable = False</span><span id="273e" class="np ma it ot b gy pc oy l oz pa"># Optimizer for the GAN<br/>opt = Adam(lr=0.00015, beta_1=0.5) #same as generator<br/># Input to the generator<br/>gen_inp = Input(shape=noise_shape)</span><span id="6d3a" class="np ma it ot b gy pc oy l oz pa">GAN_inp = generator(gen_inp)<br/>GAN_opt = discriminator(GAN_inp)</span><span id="678c" class="np ma it ot b gy pc oy l oz pa"># Final GAN<br/>gan = Model(input = gen_inp, output = GAN_opt)<br/>gan.compile(loss = 'binary_crossentropy', optimizer = opt, metrics=['accuracy'])</span><span id="79de" class="np ma it ot b gy pc oy l oz pa">plot_model(gan, to_file='gan_plot.png', show_shapes=True, show_layer_names=True)</span></pre><p id="b4d6" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">这是我们整个 GAN 的架构:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi pd"><img src="../Images/74d974d3a30178800bceb6f7f2b36cb1.png" data-original-src="https://miro.medium.com/v2/resize:fit:816/format:webp/0*Qn0oyAYAK67oawZl.png"/></div></figure><h2 id="a373" class="np ma it bd mb nq nr dn mf ns nt dp mj ld nu nv ml lh nw nx mn ll ny nz mp oa bi translated">训练循环</h2><p id="6608" class="pw-post-body-paragraph ku kv it kw b kx mr ju kz la ms jx lc ld mt lf lg lh mu lj lk ll mv ln lo lp im bi translated">这是一个主要的区域，我们需要了解到目前为止我们所创建的模块是如何组装和协同工作的。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="on oo l"/></div></figure><p id="0b99" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">别担心，我会在这里一步步尝试破解上面的代码。每个训练迭代的主要步骤是:</p><p id="bca9" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated"><strong class="kw iu">步骤 1: </strong>从数据集目录中采样一批归一化图像</p><pre class="kj kk kl km gt os ot ou ov aw ow bi"><span id="940d" class="np ma it ot b gy ox oy l oz pa"># Use a fixed noise vector to see how the GAN Images transition through time on a fixed noise. <br/>fixed_noise = gen_noise(16,noise_shape)</span><span id="aefd" class="np ma it ot b gy pc oy l oz pa"># To keep Track of losses<br/>avg_disc_fake_loss = []<br/>avg_disc_real_loss = []<br/>avg_GAN_loss = []</span><span id="1273" class="np ma it ot b gy pc oy l oz pa"># We will run for num_steps iterations<br/>for step in range(num_steps): <br/>    tot_step = step<br/>    print("Begin step: ", tot_step)<br/>    # to keep track of time per step<br/>    step_begin_time = time.time() <br/>    <br/>    # sample a batch of normalized images from the dataset<br/>    real_data_X = sample_from_dataset(batch_size, image_shape, data_dir=data_dir)</span></pre><p id="0efd" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated"><strong class="kw iu">第二步:</strong>产生输入到发电机的噪声</p><pre class="kj kk kl km gt os ot ou ov aw ow bi"><span id="e540" class="np ma it ot b gy ox oy l oz pa"># Generate noise to send as input to the generator<br/>    noise = gen_noise(batch_size,noise_shape)</span></pre><p id="0666" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated"><strong class="kw iu">第三步:</strong>使用随机噪声生成器生成图像。</p><pre class="kj kk kl km gt os ot ou ov aw ow bi"><span id="e977" class="np ma it ot b gy ox oy l oz pa"># Use generator to create(predict) images<br/>    fake_data_X = generator.predict(noise)<br/>    <br/>    # Save predicted images from the generator every 100th step<br/>    if (tot_step % 100) == 0:<br/>        step_num = str(tot_step).zfill(4)</span><span id="54d6" class="np ma it ot b gy pc oy l oz pa">save_img_batch(fake_data_X,img_save_dir+step_num+"_image.png")</span></pre><p id="11d7" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated"><strong class="kw iu">第四步:</strong>使用生成器图像(伪图像)和真实归一化图像(真实图像)及其噪声标签训练鉴别器。</p><pre class="kj kk kl km gt os ot ou ov aw ow bi"><span id="0a5d" class="np ma it ot b gy ox oy l oz pa"># Create the labels for real and fake data. We don't give exact ones and zeros but add a small amount of noise. This is an important GAN training trick<br/>    real_data_Y = np.ones(batch_size) - np.random.random_sample(batch_size)*0.2<br/>    fake_data_Y = np.random.random_sample(batch_size)*0.2<br/>        <br/>    # train the discriminator using data and labels</span><span id="70f1" class="np ma it ot b gy pc oy l oz pa">discriminator.trainable = True<br/>    generator.trainable = False</span><span id="4635" class="np ma it ot b gy pc oy l oz pa"># Training Discriminator seperately on real data<br/>    dis_metrics_real = discriminator.train_on_batch(real_data_X,real_data_Y) <br/>    # training Discriminator seperately on fake data<br/>    dis_metrics_fake = discriminator.train_on_batch(fake_data_X,fake_data_Y) <br/>    <br/>    print("Disc: real loss: %f fake loss: %f" % (dis_metrics_real[0], dis_metrics_fake[0]))<br/>    <br/>    # Save the losses to plot later<br/>    avg_disc_fake_loss.append(dis_metrics_fake[0])<br/>    avg_disc_real_loss.append(dis_metrics_real[0])</span></pre><p id="20e7" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated"><strong class="kw iu">步骤 5: </strong>使用噪声作为 X，1(有噪声的)作为 Y 来训练 GAN，同时保持鉴别器不可训练。</p><pre class="kj kk kl km gt os ot ou ov aw ow bi"><span id="4469" class="np ma it ot b gy ox oy l oz pa"># Train the generator using a random vector of noise and its labels (1's with noise)<br/>    generator.trainable = True<br/>    discriminator.trainable = False</span><span id="f65f" class="np ma it ot b gy pc oy l oz pa">GAN_X = gen_noise(batch_size,noise_shape)<br/>    GAN_Y = real_data_Y<br/>   <br/>    gan_metrics = gan.train_on_batch(GAN_X,GAN_Y)<br/>    print("GAN loss: %f" % (gan_metrics[0]))</span></pre><p id="c5a3" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">我们使用 for 循环重复这些步骤，最终得到一个好的鉴别器和生成器。</p></div><div class="ab cl ls lt hx lu" role="separator"><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx"/></div><div class="im in io ip iq"><h1 id="cdc4" class="lz ma it bd mb mc md me mf mg mh mi mj jz mk ka ml kc mm kd mn kf mo kg mp mq bi translated">结果</h1><p id="b15a" class="pw-post-body-paragraph ku kv it kw b kx mr ju kz la ms jx lc ld mt lf lg lh mu lj lk ll mv ln lo lp im bi translated">最终的输出图像如下所示。正如我们所看到的，GAN 可以为我们的内容编辑朋友生成非常好的图像。</p><p id="1b97" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">它们可能有点粗糙，但仍然是我们 GAN 之旅的开始。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pe"><img src="../Images/399fa22877508723b5bcee04f496f88f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*knKOWYKYjfesr_Xj.png"/></div></div></figure><h2 id="b100" class="np ma it bd mb nq nr dn mf ns nt dp mj ld nu nv ml lh nw nx mn ll ny nz mp oa bi translated">训练期间的损失</h2><p id="ed7b" class="pw-post-body-paragraph ku kv it kw b kx mr ju kz la ms jx lc ld mt lf lg lh mu lj lk ll mv ln lo lp im bi translated">这是为损失生成的图表。我们可以看到，随着步骤的增加，GAN 损耗平均在下降，方差也在下降。为了获得更好的结果，可能需要进行更多的迭代训练。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pf"><img src="../Images/ab10c122bc1cc9e2e5eb5a9b747f6d46.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*gB21j4tJpkIzMxnc.png"/></div></div></figure><h2 id="cf8f" class="np ma it bd mb nq nr dn mf ns nt dp mj ld nu nv ml lh nw nx mn ll ny nz mp oa bi translated">每 1500 步生成一幅图像</h2><p id="5dff" class="pw-post-body-paragraph ku kv it kw b kx mr ju kz la ms jx lc ld mt lf lg lh mu lj lk ll mv ln lo lp im bi translated">您可以在<a class="ae lr" href="https://colab.research.google.com/drive/1Mxbfn0BUW4BlgEPc-minaE_M0_PaYIIX#scrollTo=pqPNyVnSqru1" rel="noopener ugc nofollow" target="_blank"> Colab </a>中看到输出和运行代码:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="on oo l"/></div></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pg"><img src="../Images/32bd3d8c7995cb601265a8d2d9f49e46.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/1*rLPMvOP6EDjn-9zRNgnbJA.gif"/></div></div></figure><p id="7dd0" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">下面给出了在不同的训练步骤中生成一些图像的代码。正如我们所见，随着步数的增加，图像变得越来越好。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="on oo l"/></div></figure><p id="f4dc" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">下面给出了 GAN 在不同时间步长的结果:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ph"><img src="../Images/dcd11e71bb893f5666c7507ea9b32d68.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*rfKbSQzG8IRliFSM.png"/></div></div></figure><h1 id="4891" class="lz ma it bd mb mc oh me mf mg oi mi mj jz oj ka ml kc ok kd mn kf ol kg mp mq bi translated">结论</h1><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pi"><img src="../Images/6414b41e89686c1ad39793771b6649a3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*KgvJNS2eBH1HUa9f"/></div></div><figcaption class="oc od gj gh gi oe of bd b be z dk">Power in your hands</figcaption></figure><p id="ef4c" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">在本帖中，<strong class="kw iu"> <em class="lq">我们了解了</em> </strong> <a class="ae lr" href="https://amzn.to/32FMOWF" rel="noopener ugc nofollow" target="_blank"> <strong class="kw iu"> <em class="lq">甘</em></strong><strong class="kw iu"><em class="lq">s</em></strong>的基本知识。我们还了解了 DC-甘的生成器和鉴别器架构，并构建了一个简单的 DC-甘来从头开始生成动画图像。</a></p><p id="bec0" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">这个模型不太擅长生成假图像，但我们通过这个项目了解了 GANs 的基本知识，并且随着我们的发展，我们有信心建立更多令人兴奋和复杂的 GANs。</p><p id="7872" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">GANs 的 DC-GAN 风格不仅可以广泛应用于生成人脸或新的动画角色，还可以用于生成新的时尚风格，用于一般的内容创建，有时也用于数据增强目的。</p><p id="383c" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">如果我们手头有训练数据，我们现在可以按需变出逼真的纹理或角色，这可不是一个小壮举。T3】</p></div><div class="ab cl ls lt hx lu" role="separator"><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx"/></div><div class="im in io ip iq"><p id="eec6" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">如果你想了解更多关于深度学习的应用和用例，可以看看 Andrew NG 的<a class="ae lr" href="https://coursera.pxf.io/7mKnnY" rel="noopener ugc nofollow" target="_blank">深度学习专业化</a>中的<a class="ae lr" href="https://coursera.pxf.io/b3rQ7m" rel="noopener ugc nofollow" target="_blank">序列模型</a>课程。Andrew 是一位很棒的讲师，这门课程也很棒。</p></div><div class="ab cl ls lt hx lu" role="separator"><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx"/></div><div class="im in io ip iq"><p id="58a0" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">我以后也会写更多这样的帖子。让我知道你对这个系列的看法。在<a class="ae lr" href="https://medium.com/@rahul_agarwal" rel="noopener"> <strong class="kw iu">媒体</strong> </a>关注我，或者订阅我的<a class="ae lr" href="http://eepurl.com/dbQnuX" rel="noopener ugc nofollow" target="_blank"> <strong class="kw iu">博客</strong> </a>了解他们。一如既往，我欢迎反馈和建设性的批评，可以通过 Twitter <a class="ae lr" href="https://twitter.com/MLWhiz" rel="noopener ugc nofollow" target="_blank"> @mlwhiz </a>联系。</p></div></div>    
</body>
</html>