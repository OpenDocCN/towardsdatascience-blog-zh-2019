<html>
<head>
<title>Generate a corpus of public “tweets” containing a subject/keyword of interest</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">生成包含感兴趣的主题/关键词的公共“tweets”语料库</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/generate-a-corpus-of-public-tweets-containing-a-subject-keyword-of-interest-da86bc90259f?source=collection_archive---------22-----------------------#2019-10-25">https://towardsdatascience.com/generate-a-corpus-of-public-tweets-containing-a-subject-keyword-of-interest-da86bc90259f?source=collection_archive---------22-----------------------#2019-10-25</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><figure class="gl gn jr js jt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi jq"><img src="../Images/ed0c8dc6a8a6d79742eeb498c5f1bdea.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*SGlP9hO68NEgNQGUTIU6Tg.png"/></div></div></figure><p id="2619" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">通常很难对人们的兴趣进行研究，民意测验和调查结果经常是有偏差的，或者有无意中加载的问题。因此，这意味着理解人们兴趣的最真实的 T2 方法在于他们想要分享或谈论什么，而不受任何外部影响。最简单的方法是在网上搜索包含某些特征的 twitter 帖子。</p><h2 id="0a6e" class="la lb it bd lc ld le dn lf lg lh dp li km lj lk ll kq lm ln lo ku lp lq lr ls bi translated">Twitter API</h2><p id="e1cf" class="pw-post-body-paragraph kb kc it kd b ke lt kg kh ki lu kk kl km lv ko kp kq lw ks kt ku lx kw kx ky im bi translated">最初，最直观的方法是查看 twitter API。要使用它，你首先必须在 https://developer.twitter.com/en/apply-for-access 注册一个开发者账户(免费)</p><p id="53b2" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">这里为您分配了一组凭证，您可以将它们保存为以下格式的 JSON 文件:</p><pre class="lz ma mb mc gt md me mf mg aw mh bi"><span id="ed4e" class="la lb it me b gy mi mj l mk ml">{<br/> “twitter”: {<br/> “auth”: {<br/>     “consumer_key”: “xxxx”,<br/>     “consumer_secret”: “xxx”,<br/>     “access_token_key”: “xxx”,<br/>     “access_token_secret”: “xxx”<br/> },<br/>  “token”: “xxx”,<br/>  “secret”: “xxx”<br/> }<br/>}</span></pre><p id="52dc" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">接下来，我们需要安装 Twython 库<code class="fe mm mn mo me b">pip install twython</code>(不幸的是 python 3)，之后我们可以根据需要定制下面的脚本。</p><pre class="lz ma mb mc gt md me mf mg aw mh bi"><span id="f0f3" class="la lb it me b gy mi mj l mk ml"># Import the Twython class<br/>from twython import Twython<br/>import json</span><span id="761e" class="la lb it me b gy mp mj l mk ml"># Load credentials from json file<br/>with open("twitter_credentials.json", "r") as file:<br/>    creds = json.load(file)['twitter']['auth']</span><span id="70f4" class="la lb it me b gy mp mj l mk ml"># Instantiate an object<br/>python_tweets = Twython(creds['consumer_key'], creds['consumer_secret'])<br/># Create our query<br/>query = {'q': 'air quality',<br/>        'result_type': 'popular',  # other options 'mixed'<br/>        'count': 100,   # max 100<br/>         # 'until':"2019-02-01",<br/>        }</span><span id="103b" class="la lb it me b gy mp mj l mk ml">import pandas as pd<br/># Search tweets<br/>dict_ = {'user': [], 'date': [], 'text': [], 'favorite_count': []}<br/>for status in python_tweets.search(**query)['statuses']:<br/>    dict_['user'].append(status['user']['screen_name'])<br/>    dict_['date'].append(status['created_at'])<br/>    dict_['text'].append(status['text'])<br/>    dict_['favorite_count'].append(status['favorite_count'])</span><span id="8aca" class="la lb it me b gy mp mj l mk ml"># Structure data in a pandas DataFrame for easier manipulation<br/>df = pd.DataFrame(dict_)</span></pre><p id="453b" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">这种方法的缺点是结果仅限于过去 7 天，并且最多只能返回 100 条推文。</p><h2 id="7dfc" class="la lb it bd lc ld le dn lf lg lh dp li km lj lk ll kq lm ln lo ku lp lq lr ls bi translated">访问两个日期之间的所有推文</h2><p id="7fbb" class="pw-post-body-paragraph kb kc it kd b ke lt kg kh ki lu kk kl km lv ko kp kq lw ks kt ku lx kw kx ky im bi translated">相反，如果我们希望获得更久以前日期之间的所有推文，我们需要依靠其他方法。要做到这一点，我们可以依赖 GetTweetsFrom 库；<a class="ae ly" href="https://github.com/Jefferson-Henrique/GetOldTweets-python" rel="noopener ugc nofollow" target="_blank">https://github.com/Jefferson-Henrique/GetOldTweets-python</a></p><p id="9355" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">这是在<strong class="kd iu"> python 2 </strong>上设计的，尽管有一个 python 3 的实验接口，它可能工作也可能不工作。</p><p id="4212" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">因为我希望只提取每条 tweet 的文本，并将其保存在新的一行上进行文本处理(word2vec)，所以对库提供的原始示例代码进行了轻微的调整。这里，我对查询、开始和结束日期以及输出文件名进行了硬编码。</p><p id="ed16" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">下面的脚本遍历两个日期之间的每一天，并下载它找到的与查询匹配的前 1000 条 tweets。这可以适应用户的需求。</p><pre class="lz ma mb mc gt md me mf mg aw mh bi"><span id="aa3d" class="la lb it me b gy mi mj l mk ml"># -*- coding: utf-8 -*-<br/>import sys,getopt,datetime,codecs<br/>from datetime import date, timedelta</span><span id="1237" class="la lb it me b gy mp mj l mk ml">edate = date(2019, 10, 1)   # start date<br/>sdate = date(2018, 10, 1)   # end date</span><span id="1eef" class="la lb it me b gy mp mj l mk ml">query = 'atmospheric chemistry'<br/>maxtweets = 1000<br/>toptweet=False<br/>outputFileName = 'myoutput.csv'</span><span id="49f8" class="la lb it me b gy mp mj l mk ml">delta = edate - sdate       # as timedelta<br/>dates = [(sdate + timedelta(days=i)) for i in range(delta.days + 1)]</span><span id="d69b" class="la lb it me b gy mp mj l mk ml">if sys.version_info[0] &lt; 3:<br/>    import got<br/>else:<br/>    import got3 as got</span><span id="cb0a" class="la lb it me b gy mp mj l mk ml">def main():</span><span id="ad87" class="la lb it me b gy mp mj l mk ml">try:</span><span id="7cf7" class="la lb it me b gy mp mj l mk ml">tweetCriteria = got.manager.TweetCriteria()</span><span id="7bf8" class="la lb it me b gy mp mj l mk ml">tweetCriteria.querySearch = query<br/>        tweetCriteria.topTweets = toptweet<br/>        tweetCriteria.maxTweets = maxtweets</span><span id="b4a7" class="la lb it me b gy mp mj l mk ml">outputFile = codecs.open(outputFileName, "w+", "utf-8")</span><span id="7985" class="la lb it me b gy mp mj l mk ml">def receiveBuffer(tweets):<br/>            for t in tweets:<br/>                outputFile.write('\n%s'% t.text)<br/>            outputFile.flush()</span><span id="27e1" class="la lb it me b gy mp mj l mk ml">for dt in dates:<br/>            print (dt)<br/>            tweetCriteria.since = str(dt)<br/>            tweetCriteria.until = str(dt + timedelta(days=1))</span><span id="a24e" class="la lb it me b gy mp mj l mk ml">got.manager.TweetManager.getTweets(tweetCriteria, receiveBuffer)</span><span id="4c28" class="la lb it me b gy mp mj l mk ml">except arg:<br/>        print('Arguments parser error, try -h' + arg)<br/>   finally:<br/>        outputFile.close()<br/>        print('Done. Output file generated "%s".' % outputFileName)</span><span id="dd4e" class="la lb it me b gy mp mj l mk ml">if __name__ == '__main__':<br/>   main()</span></pre><h2 id="bbdf" class="la lb it bd lc ld le dn lf lg lh dp li km lj lk ll kq lm ln lo ku lp lq lr ls bi translated">结论</h2><ul class=""><li id="3429" class="mq mr it kd b ke lt ki lu km ms kq mt ku mu ky mv mw mx my bi translated">Twitter API 仅用于收集过去 7 天的推文。</li><li id="4b7f" class="mq mr it kd b ke mz ki na km nb kq nc ku nd ky mv mw mx my bi translated">如果您需要历史数据，GetOldTweets 库非常有用</li><li id="f5f2" class="mq mr it kd b ke mz ki na km nb kq nc ku nd ky mv mw mx my bi translated">然后，生成的输出文件可以用作基于 NLP 的机器学习和预测的语料库，或者关于该主题的公众观点的样本。</li><li id="a0e3" class="mq mr it kd b ke mz ki na km nb kq nc ku nd ky mv mw mx my bi translated">这两种方法都非常容易使用，而且几乎是即插即用的(一旦您使用了正确版本的 python)。</li></ul></div></div>    
</body>
</html>