<html>
<head>
<title>Real-time Object Detection Without Machine Learning</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">无需机器学习的实时目标检测</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/real-time-object-detection-without-machine-learning-5139b399ee7d?source=collection_archive---------7-----------------------#2019-11-24">https://towardsdatascience.com/real-time-object-detection-without-machine-learning-5139b399ee7d?source=collection_archive---------7-----------------------#2019-11-24</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><figure class="is it gp gr iu iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi ir"><img src="../Images/680c586f57a6174b0bc7c1006e035cb1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*vTCxpeI9BBxBSbTpOMIadA.png"/></div></div></figure><div class=""/><div class=""><h2 id="a3ae" class="pw-subtitle-paragraph kb jd je bd b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks dk translated">深度学习与启发式</h2></div><p id="cd0b" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">今年早些时候，IBM 的软件开发人员 Nick Bourdakos 发布了一系列视频，演示在网络浏览器中进行实时物体检测。他早期的一个视频迅速走红，在 LinkedIn 上获得了超过 16000 个赞和 900 多条评论。以下是原帖:</p><div class="is it gp gr iu lp"><a href="https://www.linkedin.com/posts/nicholasbourdakos_machinelearning-javascript-activity-6496499508409561088-1M00" rel="noopener  ugc nofollow" target="_blank"><div class="lq ab fo"><div class="lr ab ls cl cj lt"><h2 class="bd jf gy z fp lu fr fs lv fu fw jd bi translated">LinkedIn 上的 Nicholas Bourdakos:“在您的浏览器中实时可定制的对象检测…</h2><div class="lw l"><h3 class="bd b gy z fp lu fr fs lv fu fw dk translated">2019 年 1 月 30 日:尼古拉斯·布尔达科斯在 LinkedIn 上发帖</h3></div><div class="lx l"><p class="bd b dl z fp lu fr fs lv fu fw dk translated">www.linkedin.com</p></div></div><div class="ly l"><div class="lz l ma mb mc ly md ja lp"/></div></div></a></div><p id="3c82" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">视频显示，三个瓶子(可口可乐、百事可乐和激浪)被举到摄像机前，计算机实时识别。当检测到每个瓶子时，会给它一个文本标签，并在其周围绘制一个边界框。如果举起一个以上的瓶子，系统将正确标记不同的瓶子。</p><p id="8e8e" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">Nick 的系统现在已经进化成了<a class="ae me" href="https://cloud.annotations.ai" rel="noopener ugc nofollow" target="_blank"> IBM cloud annotations </a>，但是上面的演示使用了 TensorFlow.js 以及 COCO-SSD 深度学习模型。SSD，或单次多盒探测器，是一种广泛使用的技术，用于检测一帧中的多个子图像，详细描述<a class="ae me" rel="noopener" target="_blank" href="/understanding-ssd-multibox-real-time-object-detection-in-deep-learning-495ef744fab">这里</a>。这是深度学习擅长的任务，这些技术现在非常普遍，你可能在口袋里有一个深度学习网络，为照片或社交网络应用程序运行手机的对象检测。</p><h2 id="69fa" class="mf mg je bd mh mi mj dn mk ml mm dp mn lc mo mp mq lg mr ms mt lk mu mv mw mx bi translated">“没有机器学习”的挑战</h2><p id="ae79" class="pw-post-body-paragraph kt ku je kv b kw my kf ky kz mz ki lb lc na le lf lg nb li lj lk nc lm ln lo im bi translated">受到尼克帖子的启发，我决定挑战自己，探索是否可以在不使用机器学习的情况下<em class="nd">取得类似的结果。我突然想到，最初演示中使用的瓶子可以根据它们的颜色或其他特征以及一些简单的匹配规则来检测。这被称为解决问题的<a class="ae me" href="https://en.wikipedia.org/wiki/Heuristic" rel="noopener ugc nofollow" target="_blank">启发式</a>方法。</em></p><p id="3c7e" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">这样做的潜在优势包括:</p><ul class=""><li id="5049" class="ne nf je kv b kw kx kz la lc ng lg nh lk ni lo nj nk nl nm bi translated">易于开发和概念化</li><li id="d43a" class="ne nf je kv b kw nn kz no lc np lg nq lk nr lo nj nk nl nm bi translated">降低 CPU 和内存使用</li><li id="8329" class="ne nf je kv b kw nn kz no lc np lg nq lk nr lo nj nk nl nm bi translated">更少的依赖性</li></ul><p id="5485" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">在 CPU 和内存方面，在我的 i5 MacBook Pro 上，IBM Cloud Annotations 演示使用了超过 100%的 CPU 和超过 1.5 GB 的 RAM。它还依赖于一个网络浏览器和一些严重的依赖，包括 Tensorflow，React.js，node.js 和 COCO-SSD 本身。</p><p id="6469" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">我自己定的规则是:</p><ol class=""><li id="6b9d" class="ne nf je kv b kw kx kz la lc ng lg nh lk ni lo ns nk nl nm bi translated">可口可乐、百事可乐和激浪瓶必须贴上正确的标签</li><li id="f718" class="ne nf je kv b kw nn kz no lc np lg nq lk nr lo ns nk nl nm bi translated">当瓶子移动时，应该在每个瓶子周围画一个矩形</li><li id="a99c" class="ne nf je kv b kw nn kz no lc np lg nq lk nr lo ns nk nl nm bi translated">最小代码</li><li id="0cf8" class="ne nf je kv b kw nn kz no lc np lg nq lk nr lo ns nk nl nm bi translated">没有机器学习技术！</li></ol><p id="2b19" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">最初的演示声称只使用了 10 行代码，然而包括样板文件，当前的演示是 107 行 JavaScript。我认为低于 100 行是这个任务的一个很好的目标。</p><h2 id="6073" class="mf mg je bd mh mi mj dn mk ml mm dp mn lc mo mp mq lg mr ms mt lk mu mv mw mx bi translated">方法和解决方案</h2><p id="d7e0" class="pw-post-body-paragraph kt ku je kv b kw my kf ky kz mz ki lb lc na le lf lg nb li lj lk nc lm ln lo im bi translated">首先，我决定将我的项目建立在 OpenCV 的基础上，因为我以前在工作项目中使用过它，它有相对简单的设置，并且是专门为计算机视觉设计的<em class="nd"/>。OpenCV 是用 C++写的，有 Python 和<a class="ae me" href="https://docs.opencv.org/3.4/d5/d10/tutorial_js_root.html" rel="noopener ugc nofollow" target="_blank"> JavaScript </a>的绑定。为了方便起见，我决定使用 Python 版本。</p><p id="9d14" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">我开始只是认出一个可乐瓶子。为此，一个简单的解决方案是分析视频帧中的颜色，并在发现<a class="ae me" href="https://usbrandcolors.com/coca-cola-colors/" rel="noopener ugc nofollow" target="_blank">可乐红</a>的地方贴上标签。这里的一个问题是，根据照明条件和相机颜色精度，瓶子标签不太可能准确地为<em class="nd">RGB 244 0 0。</em></p><p id="6d1c" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">为了解决这个问题，我们可以使用一个<a class="ae me" href="https://en.wikipedia.org/wiki/HSL_and_HSV" rel="noopener ugc nofollow" target="_blank"> HSV </a>颜色表示以及<a class="ae me" href="https://docs.opencv.org/trunk/d2/de8/group__core__array.html#ga48af0ab51e36436c5d04340e036ce981" rel="noopener ugc nofollow" target="_blank"> cv::inRange </a>来查找图像中给定<em class="nd">范围内的颜色。</em>想想“红色的深浅”。这给了我们一个图像遮罩，所有红色区域为白色，其他区域为黑色。然后，我们可以使用<a class="ae me" href="https://docs.opencv.org/3.4/d3/dc0/group__imgproc__shape.html#ga17ed9f5d79ae97bd4c7cf18403e1689a" rel="noopener ugc nofollow" target="_blank"> cv::findContours </a>来提供一个定义框架内每个“红色区域”的点列表。基本代码如下所示:</p><pre class="nt nu nv nw gt nx ny nz oa aw ob bi"><span id="9ff5" class="mf mg je ny b gy oc od l oe of">mask = cv2.inRange(hsv, colour.lower, colour.upper)<br/>conts, heirarchy = cv2.findContours(mask.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)<br/>biggest = sorted(conts, key=cv2.contourArea, reverse=True)[0]</span></pre><p id="47d6" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">第三行代码对检测到的“红色”轮廓进行排序，并返回最大的轮廓。搞定了。…对吗？不幸的是没有。像这样，程序经常在图像中找到可乐，即使图像中没有可乐。</p><figure class="nt nu nv nw gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi og"><img src="../Images/ac46b38c02c4090f0caa0e82953ed5b9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Sx2NF1FlaQmq0S_jcnuE_A.png"/></div></div><figcaption class="oh oi gj gh gi oj ok bd b be z dk">Coke false positive</figcaption></figure><p id="c44f" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">为了解决这个问题，我们需要一个额外的启发。我发现简单地排除任何小于 50×50 的轮廓就足够了。</p><pre class="nt nu nv nw gt nx ny nz oa aw ob bi"><span id="d423" class="mf mg je ny b gy oc od l oe of">if w &lt; 50 or h &lt; 50:<br/>    continue</span></pre><p id="d0c6" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">最后，为了让我们的检测系统工作良好，我们需要排除在其他颜色“内部”的颜色。例如，百事可乐和激浪标签<em class="nd">都含有</em>红色，除非我们排除它，否则它会被检测为可口可乐。因此，我们为可乐添加了一个特殊的试探法，如果它在另一个瓶子的垂直边界内，则忽略检测。</p><pre class="nt nu nv nw gt nx ny nz oa aw ob bi"><span id="e236" class="mf mg je ny b gy oc od l oe of">if name == "Coke":<br/>    if any([contains_vertical(rects[n], rect) for n in rects]):<br/>        continue</span></pre><h2 id="a529" class="mf mg je bd mh mi mj dn mk ml mm dp mn lc mo mp mq lg mr ms mt lk mu mv mw mx bi translated">示范</h2><p id="477e" class="pw-post-body-paragraph kt ku je kv b kw my kf ky kz mz ki lb lc na le lf lg nb li lj lk nc lm ln lo im bi translated">综上所述，这是最终系统的工作演示。</p><figure class="nt nu nv nw gt iv"><div class="bz fp l di"><div class="ol om l"/></div></figure><p id="0d3c" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">在我的 i5 MacBook Pro 上，它在 45%左右的 CPU 和略高于 50MB 的 RAM 下运行顺畅。完整的源代码有 85 行，可以在这里<a class="ae me" href="https://github.com/jamiebullock/heuristic-bottle-detection" rel="noopener ugc nofollow" target="_blank">找到。</a></p><h2 id="bc35" class="mf mg je bd mh mi mj dn mk ml mm dp mn lc mo mp mq lg mr ms mt lk mu mv mw mx bi translated">限制</h2><p id="1e62" class="pw-post-body-paragraph kt ku je kv b kw my kf ky kz mz ki lb lc na le lf lg nb li lj lk nc lm ln lo im bi translated">这种基于颜色的方法的一个限制是，它不在瓶子周围放置边界框，而只在着色区域放置。我们可以定义额外的规则来考虑检测区域上方或下方的颜色，或者尝试猜测边界框应该在哪里，但是代码会很快变得复杂。</p><p id="f0ea" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">另一个限制是，虽然我们的系统可以同时识别可乐和百事可乐瓶，但它不能检测两个可乐瓶。我们可以添加进一步的启发式方法来处理这个问题，但是如果需要添加这么多的复杂性，我会质疑启发式方法是否是正确的选择。</p><h2 id="8791" class="mf mg je bd mh mi mj dn mk ml mm dp mn lc mo mp mq lg mr ms mt lk mu mv mw mx bi translated">深度学习 vs 启发式</h2><p id="7a17" class="pw-post-body-paragraph kt ku je kv b kw my kf ky kz mz ki lb lc na le lf lg nb li lj lk nc lm ln lo im bi translated">我已经展示了为高度受限的任务构建一个与基于深度学习的系统精度相当的启发式检测器是很简单的。此外，启发式对象检测器在概念上更简单，具有更少的依赖性，占用更少的 CPU，并且使用更少数量级的存储器。</p><p id="44f6" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">然而，启发式方法不像使用深度学习那样健壮或准确。深度学习系统可以很容易地识别同一物体在不同比例和旋转下的多个实例，这取决于它的训练方式。它还可以做一些事情，比如即使关键特征缺失也能识别部分物体。</p><h2 id="582e" class="mf mg je bd mh mi mj dn mk ml mm dp mn lc mo mp mq lg mr ms mt lk mu mv mw mx bi translated">结论</h2><p id="ebcc" class="pw-post-body-paragraph kt ku je kv b kw my kf ky kz mz ki lb lc na le lf lg nb li lj lk nc lm ln lo im bi translated">对我来说，这不是深度学习的明显胜利，我认为启发式方法仍然有一席之地。可以对检测条件(一致的背景和/或比例、受约束的对象类型、诸如颜色的区别特征)做出的假设越多，试探法就越有吸引力。作为一名开发人员，如果时间和资源紧张，并且输入约束明确，我会考虑基于启发式的解决方案。如果我想要增加健壮性和灵活性，我会选择机器学习。这两种方法肯定都有它们的位置，问题是要为工作选择正确的工具。</p></div></div>    
</body>
</html>