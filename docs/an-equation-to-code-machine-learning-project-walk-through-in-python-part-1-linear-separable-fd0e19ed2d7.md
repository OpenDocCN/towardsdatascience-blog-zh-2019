# Python ä¸­çš„â€œç­‰å¼åˆ°ä»£ç â€æœºå™¨å­¦ä¹ é¡¹ç›®æ¼”ç»ƒâ€”ç¬¬ 1 éƒ¨åˆ†çº¿æ€§å¯åˆ†é—®é¢˜

> åŸæ–‡ï¼š<https://towardsdatascience.com/an-equation-to-code-machine-learning-project-walk-through-in-python-part-1-linear-separable-fd0e19ed2d7?source=collection_archive---------13----------------------->

## æ•°å­¦æ–¹ç¨‹å¼èƒŒåçš„è¯¦ç»†è§£é‡Šï¼Œä¸ºæ‚¨çš„æœºå™¨å­¦ä¹ æˆ–æ·±åº¦å­¦ä¹ ä¹‹æ—…å¥ å®šå®ç”¨çš„æ•°å­¦åŸºç¡€

![](img/1cb250d58d84bd641b389fcb7b501d5b.png)

Photo: Halfpoint/Shutterstock

ä»å·¥ç¨‹å¸ˆåˆ°æœºå™¨å­¦ä¹ å·¥ç¨‹å¸ˆçš„ä¸€å¤§å·®è·æ˜¯å°†æ•°å­¦æ–¹ç¨‹è½¬æ¢ä¸ºçœŸå®ä»£ç çš„èƒ½åŠ›ã€‚æœ‰æ—¶æˆ‘ä»¬çœŸçš„éœ€è¦ä»å¤´å®ç°ä¸€äº›åŸºæœ¬æ¦‚å¿µï¼Œä»¥æ›´å¥½åœ°ç†è§£å¹•åçš„é­”åŠ›ï¼Œè€Œä¸æ˜¯åœ¨æ²¡æœ‰è¿›ä¸€æ­¥ç†è§£çš„æƒ…å†µä¸‹åªå¯¼å…¥åº“ã€‚

æ‰€ä»¥æˆ‘å†³å®šå†™ä¸€äº›æ–‡ç« æ¥è§£é‡Šå¦‚ä½•å°†æ•°å­¦æ–¹ç¨‹å¼è½¬æ¢æˆçœŸæ­£çš„ä»£ç ã€‚è¿™æ˜¯ç¬¬ 1 éƒ¨åˆ†ï¼Œæˆ‘å°†ç»™å‡ºä¸€ä¸ªä½¿ç”¨é€»è¾‘å›å½’å¯¹ä¸€ä¸ªçº¿æ€§å¯åˆ†é—®é¢˜è¿›è¡Œåˆ†ç±»çš„ä¾‹å­ã€‚æˆ‘ä¼šå°½å¯èƒ½ç®€å•åœ°è§£é‡Šã€‚

è¿™é‡Œæ˜¯[æ•°æ®](https://gist.github.com/BrambleXu/738812287e7900428478c9035157db22#file-linear_data-csv)å’Œ[ä»£ç ](https://gist.github.com/BrambleXu/2640af09b1f43b93c2d951ba91ca3d5c)ã€‚

å†…å®¹ç»“æ„å¦‚ä¸‹ã€‚çœ‹èµ·æ¥æœ‰ç‚¹é•¿ï¼Œ

1.  çœ‹æ•°æ®
2.  çº¿æ€§å¯åˆ†é—®é¢˜
3.  å‘é‡è¡¨ç¤ºæ³•
4.  æ ‡å‡†åŒ–
5.  æ·»åŠ åå·®
6.  Sigmoid å‡½æ•°
7.  ä¼¼ç„¶å‡½æ•°
8.  æ›´æ–°å‚æ•°Î¸
9.  ç»˜åˆ¶ç›´çº¿
10.  æ‘˜è¦

# 1 çœ‹æ•°æ®

ä¸‹é¢æ˜¯æ•°æ®ï¼Œ [linear_data.csv](https://gist.github.com/BrambleXu/738812287e7900428478c9035157db22#file-linear_data-csv)

```
x1,x2,y
153,432,0
220,262,0
118,214,0
474,384,1
485,411,1
233,430,0
396,321,1
484,349,1
429,259,1
286,220,1
399,433,0
403,300,1
252,34,1
497,372,1
379,416,0
76,163,0
263,112,1
26,193,0
61,473,0
420,253,1
```

é¦–å…ˆï¼Œæˆ‘ä»¬éœ€è¦ç»˜åˆ¶è¿™äº›æ•°æ®ï¼Œçœ‹çœ‹å®ƒæ˜¯ä»€ä¹ˆæ ·å­çš„ã€‚æˆ‘ä»¬åˆ›å»ºä¸€ä¸ª Python æ–‡ä»¶ï¼Œå¹¶å°†å…¶å‘½åä¸º logistic_regression.pyã€‚

```
import numpy as np
import matplotlib.pyplot as plt# read data
data = np.loadtxt("linear_data.csv", *delimiter*=',', *skiprows*=1)
train_x = data[:, 0:2]
train_y = data[:, 2]# plot
plt.plot(train_x[train_y == 1, 0], train_x[train_y == 1, 1], 'o')
plt.plot(train_x[train_y == 0, 0], train_x[train_y == 0, 1], 'x')
plt.show()
```

è¿è¡Œä¸Šé¢çš„è„šæœ¬åï¼Œæ‚¨åº”è¯¥ä¼šçœ‹åˆ°ä¸‹å›¾ã€‚

![](img/b629defe8bf338343cf864c526c86a90.png)

æˆ‘ä»¬å¯èƒ½è®¤ä¸ºä¸€æ¡ç›´çº¿åº”è¯¥èƒ½å¾ˆå¥½åœ°æŠŠ X å’Œ O åˆ†å¼€ã€‚è€Œè¿™æ˜¯ä¸€ä¸ª[çº¿æ€§å¯åˆ†é—®é¢˜](http://www.ece.utep.edu/research/webfuzzy/docs/kk-thesis/kk-thesis-html/node19.html)ã€‚

# 2 çº¿æ€§å¯åˆ†é—®é¢˜

æˆ‘ä»¬éœ€è¦ä¸ºè¿™æ ·çš„é—®é¢˜æ‰¾åˆ°ä¸€ä¸ªæ¨¡å‹ã€‚æœ€ç®€å•çš„æƒ…å†µæ˜¯ä½¿ç”¨[çº¿æ€§å‡½æ•°](https://en.wikipedia.org/wiki/Linear_function_(calculus)?oldformat=true#Properties)ã€‚

![](img/8a7f6b94f05f89b47964230a43fb407f.png)

æˆ‘ä»¬ç”¨Î¸æ¥è¡¨ç¤ºå‚æ•°ã€‚å·¦è¾¹çš„Î¸æ ‡è®°è¡¨ç¤ºå‡½æ•° f(x)æœ‰å‚æ•°Î¸ã€‚å³è¾¹çš„Î¸è¡¨ç¤ºæœ‰ä¸¤ä¸ªå‚æ•°ã€‚

æˆ‘ä»¬å¯ä»¥æŠŠå®ƒå†™æˆä»£ç 

```
import numpy as np
import matplotlib.pyplot as plt# read data
data = np.loadtxt("linear_data.csv", *delimiter*=',', *skiprows*=1)
train_x = data[:, 0:2]
train_y = data[:, 2]theta = np.random.randn(2)**def f(x):
    return theta[0] + theta[1] * x**
```

# 3 çŸ¢é‡è¡¨ç¤ºæ³•

æˆ‘ä»¬ä¹Ÿå¯ä»¥æŠŠçº¿æ€§å‡½æ•°æ”¹å†™æˆæ›´ç®€å•çš„æ–¹å¼ï¼Œå‘é‡æ–¹å¼ã€‚

![](img/ec094bb58596f362b9205f22912ca839.png)

è¿™é‡Œçš„Î¸å’Œ x éƒ½æ˜¯åˆ—å‘é‡ã€‚

![](img/24dfdfa6900a0fdf473cd4dd67c94259.png)

ä¹‹æ‰€ä»¥ç”¨Î¸çš„è½¬ç½®ï¼Œæ˜¯å› ä¸ºå¯ä»¥ç”¨çŸ©é˜µä¹˜æ³•ã€‚

![](img/a63d9131d91fa66e0bf7ed1aaa9174fa.png)

æˆ‘ä»¬å¯ä»¥å†™ä¸‹é¢çš„ä»£ç 

```
import numpy as np
import numpy as np
import matplotlib.pyplot as plt# read data
data = np.loadtxt("linear_data.csv", *delimiter*=',', *skiprows*=1)
train_x = data[:, 0:2]
train_y = data[:, 2]# initialize parameter
theta = np.random.randn(2)**# dot product
def f(x):
    return np.dot(theta, x)**
```

ä½ å¯èƒ½æƒ³çŸ¥é“ä¸ºä»€ä¹ˆæˆ‘ä»¬ä¸å†™`np.dot(theta.T, x)`ï¼Ÿå› ä¸º[æ–‡æ¡£](https://docs.scipy.org/doc/numpy/reference/generated/numpy.dot.html)è¯´**å¦‚æœä¸¤ä¸ª*å‘é‡*éƒ½æ˜¯ä¸€ç»´æ•°ç»„ï¼Œé‚£ä¹ˆå°±æ˜¯å‘é‡çš„å†…ç§¯(æ²¡æœ‰å¤å…±è½­)**ã€‚æ‰€ä»¥`np.dot(theta, x)`åšå’Œ`np.dot(theta.T, x)`ä¸€æ ·çš„äº‹æƒ…ã€‚

# 4 æ ‡å‡†åŒ–

ä¸ºäº†ä½¿è®­ç»ƒå¿«é€Ÿæ”¶æ•›ï¼Œæˆ‘ä»¬ä½¿ç”¨[æ ‡å‡†åŒ–](https://stats.stackexchange.com/a/10298/116970)ï¼Œä¹Ÿå« **z** - **è¯„åˆ†ã€‚æˆ‘ä»¬æ˜¯æŒ‰åˆ—æ¥åšçš„ã€‚**

![](img/5c3f709c7b442c54fde9bf1fc63508c0.png)

*   ğœ‡åœ¨æ¯ä¸€æ éƒ½å¾ˆåˆ»è–„
*   ğœæ˜¯æ¯åˆ—çš„æ ‡å‡†åå·®

```
import numpy as np
import numpy as np
import matplotlib.pyplot as plt# read data
data = np.loadtxt("linear_data.csv", *delimiter*=',', *skiprows*=1)
train_x = data[:, 0:2]
train_y = data[:, 2]# initialize parameter
theta = np.random.randn(2)**# standardization
mu = train_x.mean(axis=0)
sigma = train_x.std(axis=0)****def standardizer(x):
    return (x - mu) / sigma
std_x = standardizer(train_x)**# dot product
def f(x):
    return np.dot(theta, x)
```

# 5 æ·»åŠ åå·®

æˆ‘ä»¬éœ€è¦åœ¨å‡½æ•°ä¸­åŠ å…¥ä¸€ä¸ªåå·®é¡¹ï¼Œä½¿æˆ‘ä»¬çš„æ¨¡å‹å…·æœ‰æ›´å¥½çš„æ³›åŒ–èƒ½åŠ›ã€‚æ‰€ä»¥æˆ‘ä»¬æŠŠå‚æ•°ä» 2 å¢åŠ åˆ° 3ã€‚å¹¶ä¸”æ·»åŠ å¸¸æ•° x0=1ï¼Œä»¥ä¾¿å¯¹é½çŸ¢é‡è¡¨ç¤ºã€‚

![](img/16fd761140a8162a584bb5b602c2e8ef.png)

ä¸ºäº†ä½¿è®¡ç®—æ›´ç®€å•ï¼Œæˆ‘ä»¬æŠŠ x è½¬æ¢æˆçŸ©é˜µã€‚

```
import numpy as np
import numpy as np
import matplotlib.pyplot as plt# read data
data = np.loadtxt("linear_data.csv", *delimiter*=',', *skiprows*=1)
train_x = data[:, 0:2]
train_y = data[:, 2]**# initialize parameter
theta = np.random.randn(3)**# standardization
mu = train_x.mean(axis=0)
sigma = train_x.std(axis=0)def standardizer(x):
    return (x - mu) / sigma
std_x = standardizer(train_x)**# get matrix
def to_matrix(std_x):
    return np.array([[1, x1, x2] for x1, x2 in std_x])
mat_x = to_matrix(std_x)**# dot product
def f(x):
    return np.dot**(x, theta)**
```

`std_x`çš„å°ºå¯¸ä¸º`(20, 2)`ã€‚`to_matrix(std_x)`ä¹‹å`mat_x`çš„å°ºå¯¸ä¸º`(20, 3)`ã€‚è‡³äºç‚¹ç§¯éƒ¨åˆ†ï¼Œæ³¨æ„è¿™é‡Œæˆ‘ä»¬æ”¹å˜äº† x å’ŒÎ¸çš„ä½ç½®ï¼ŒÎ¸çš„é‡çº²æ˜¯`(3,)`ã€‚æ‰€ä»¥ç‚¹ç”Ÿæˆçš„ç»“æœåº”è¯¥æ˜¯`(20,3) x (3,)->(20,)`ï¼Œè¿™æ˜¯ä¸€ä¸ªåŒ…å« 20 ä¸ªæ ·æœ¬é¢„æµ‹çš„ä¸€ç»´æ•°ç»„ã€‚

# 6 Sigmoid å‡½æ•°

ä¸‹é¢æ˜¯æˆ‘ä»¬åˆ°ç›®å‰ä¸ºæ­¢è®²è¿‡çš„çº¿æ€§å‡½æ•°ã€‚

![](img/ec094bb58596f362b9205f22912ca839.png)

ç†Ÿæ‚‰äº†çº¿æ€§å‡½æ•°ä¹‹åã€‚æˆ‘ä»¬å°†åœ¨æ­¤åŸºç¡€ä¸Šæ„å»ºä¸€ä¸ªæ›´å¼ºå¤§çš„é¢„æµ‹å‡½æ•°ï¼Œsigmoid å‡½æ•°ã€‚

![](img/44394e6ff94cf4e874f2d9253a6f806f.png)

æˆ‘ä»¬ç”¨ z æ¥è¡¨ç¤ºçº¿æ€§å‡½æ•°ï¼Œå¹¶å°†å…¶ä¼ é€’ç»™ sigmoid å‡½æ•°ã€‚sigmoid å‡½æ•°å°†ç»™å‡ºæ¯ä¸ªæ•°æ®æ ·æœ¬çš„æ¦‚ç‡ã€‚æˆ‘ä»¬çš„æ•°æ®ä¸­æœ‰ä¸¤ä¸ªç±»ï¼Œä¸€ä¸ªæ˜¯`1`ï¼Œå¦ä¸€ä¸ªæ˜¯`0`ã€‚

![](img/598ca2a33e63ef98b71a31237199f730.png)

æˆ‘ä»¬å¯ä»¥çœ‹åˆ°æ¨¡å‹åŸºäºçº¿æ€§å‡½æ•°éƒ¨åˆ†é¢„æµ‹æ ·æœ¬ã€‚

![](img/76e6302b06c1921c101316eb5574518b.png)

æˆ‘ä»¬å¯ä»¥å†™ä¸‹é¢çš„ä»£ç 

```
import numpy as np
import matplotlib.pyplot as plt# read data
data = np.loadtxt("linear_data.csv", delimiter=',', skiprows=1)
train_x = data[:, 0:2]
train_y = data[:, 2]# initialize parameter
theta = np.random.randn(3)# standardization
mu = train_x.mean(axis=0)
sigma = train_x.std(axis=0)
def standardizer(x):
    return (x - mu) / sigma
std_x = standardizer(train_x)# get matrix
def to_matrix(std_x):
    return np.array([[1, x1, x2] for x1, x2 in std_x])
mat_x = to_matrix(std_x)**# sigmoid function
def f(x):
    return 1 / (1 + np.exp(-np.dot(x, theta)))**
```

# 7 ä¼¼ç„¶å‡½æ•°

> å¦‚æœä½ å¯¹æ–¹ç¨‹å¼çš„è§£é‡Šä¸æ„Ÿå…´è¶£ï¼Œä½ å¯ä»¥ç›´æ¥è·³åˆ°ç¬¬ 7 æ­¥çš„æœ€åä¸€éƒ¨åˆ†ã€‚

å¥½äº†ï¼Œæˆ‘ä»¬å‡†å¤‡äº†æ•°æ®ã€æ¨¡å‹(sigmoid ),è¿˜éœ€è¦ä»€ä¹ˆï¼Ÿæ˜¯çš„ï¼Œä¸€ä¸ªç›®æ ‡å‡½æ•°ã€‚**ç›®æ ‡å‡½æ•°å¯ä»¥æŒ‡å¯¼æˆ‘ä»¬å¦‚ä½•ä»¥æ­£ç¡®çš„æ–¹å¼æ›´æ–°å‚æ•°ã€‚**å¯¹äº sigmoid(é€»è¾‘å›å½’)ï¼Œæˆ‘ä»¬é€šå¸¸ä½¿ç”¨[å¯¹æ•°ä¼¼ç„¶](https://www.wikiwand.com/en/Likelihood_function#/Log-likelihood)ä½œä¸ºç›®æ ‡å‡½æ•°

![](img/3de81529a87d49a1798074dc8c709b82.png)

ç­‰ç­‰ï¼Œç­‰ç­‰â€¦è¿™äº›ä¸œè¥¿åˆ°åº•æ˜¯æ€ä¹ˆå›äº‹ï¼

**ä¸è¦æ…Œã€‚å†·é™ç‚¹ã€‚**

è®©æˆ‘ä»¬æŠŠå®ƒæ‹†å¼€ã€‚

*   1->2(å¦‚ä½•ä»ç¬¬ 1 è¡Œåˆ°ç¬¬ 2 è¡Œ):`log(ab) = log a + log b`
*   2->3: `log(a)^b = b * log a`
*   3->4:ç”±äºæˆ‘ä»¬åªæœ‰ä¸¤ä¸ªç±»ï¼Œy=0 å’Œ y=1ï¼Œæ‰€ä»¥æˆ‘ä»¬å¯ä»¥ä½¿ç”¨ä¸‹é¢çš„ç­‰å¼:

![](img/7a8e5fda818e6cb17e20c614240fd8d9.png)

3->4

*   4->5:æˆ‘ä»¬ä½¿ç”¨ä¸‹é¢çš„å˜æ¢ä½¿ç­‰å¼æ›´å…·å¯è¯»æ€§

![](img/d710cf2c40d17501bede7769043057d7.png)

æ‰€ä»¥æˆ‘ä»¬å¾—åˆ°äº†æœ€åä¸€éƒ¨åˆ†ã€‚

![](img/203b7f77765d76082d62d215395437a5.png)

åˆ«å¿˜äº†æˆ‘ä»¬ä¸ºä»€ä¹ˆå¼€å§‹è¿™ä¸ªã€‚**ç›®æ ‡å‡½æ•°å¯ä»¥æŒ‡å¯¼æˆ‘ä»¬å¦‚ä½•ä»¥æ­£ç¡®çš„æ–¹å¼æ›´æ–°å‚æ•°ã€‚**

æˆ‘ä»¬éœ€è¦ç”¨è¿™ä¸ªæ¥è®¡ç®—æŸè€—ï¼Œä»¥æ›´æ–°å‚æ•°ã€‚æ›´å…·ä½“åœ°è¯´ï¼Œæˆ‘ä»¬éœ€è¦è®¡ç®—å¯¹æ•°ä¼¼ç„¶å‡½æ•°çš„**å¯¼æ•°**ã€‚è¿™é‡Œæˆ‘ç›´æ¥ç»™å‡ºæœ€åçš„æ›´æ–°æ–¹ç¨‹å¼ã€‚(å¦‚æœä½ å¯¹å¦‚ä½•å¾—åˆ°è¿™ä¸ªæ–¹ç¨‹æ„Ÿå…´è¶£ï¼Œè¿™ä¸ª[è§†é¢‘](https://www.youtube.com/watch?v=SB2vz57eKgc)åº”è¯¥ä¼šæœ‰å¸®åŠ©)

![](img/92da534e72a3ead43346ba4017d5b243.png)

**ç¬¬å…­æ­¥ï¼Œæœ€é‡è¦çš„æ–¹ç¨‹å°±æ˜¯è¿™ä¸ªã€‚å¦‚æœä½ ä¸æ˜ç™½å¦‚ä½•åšåˆ°è¿™ä¸€ç‚¹ï¼Œè¿™æ˜¯å®Œå…¨å¯ä»¥çš„ã€‚æˆ‘ä»¬éœ€è¦åšçš„å°±æ˜¯æŠŠå®ƒå†™æˆçœŸæ­£çš„ä»£ç ã€‚**

# 8 æ›´æ–°å‚æ•°Î¸

ç¬¬å…«æ­¥ç¨å¾®é•¿ä¸€ç‚¹ï¼Œä½†æ˜¯å¾ˆé‡è¦ã€‚**åˆ«æ…Œ**ã€‚æˆ‘ä»¬ä¼šç ´è§£å®ƒã€‚

![](img/92da534e72a3ead43346ba4017d5b243.png)

Î¸j æ˜¯ç¬¬ j ä¸ªå‚æ•°ã€‚

*   Î·æ˜¯å­¦ä¹ ç‡ï¼Œæˆ‘ä»¬è®¾ä¸º 0.001 (1e-3)ã€‚
*   n æ˜¯æ•°æ®æ ·æœ¬çš„æ•°é‡ï¼Œåœ¨æˆ‘ä»¬çš„ä¾‹å­ä¸­ï¼Œæˆ‘ä»¬æœ‰ 20 ä¸ªã€‚
*   I æ˜¯ç¬¬ I ä¸ªæ•°æ®æ ·æœ¬

å› ä¸ºæˆ‘ä»¬æœ‰ä¸‰ä¸ªå‚æ•°ï¼Œæ‰€ä»¥å¯ä»¥å†™æˆä¸‰ä¸ªæ–¹ç¨‹ã€‚

![](img/7a9e965a97b40a8ba3c400ce39ffbf6e.png)

`:=`ç¬¦å·å°±åƒ`=`ã€‚ä½ å¯ä»¥åœ¨è¿™é‡Œæ‰¾åˆ°è§£é‡Š[ã€‚](https://math.stackexchange.com/questions/25214/what-does-mean)

æœ€éš¾çš„éƒ¨åˆ†æ˜¯Ïƒ(æ±‚å’Œç¬¦å·)ï¼Œæ‰€ä»¥ä¸ºäº†æ›´å¥½åœ°ç†è§£ï¼Œæˆ‘æ‰©å±•äº†Ïƒã€‚

![](img/7a7baf204f5c9c3b1b98e1d2ee82a4c3.png)

ä»”ç»†çœ‹ã€‚

![](img/355c4a8cdd9a21d1188add3cdc42ffa1.png)

æˆ‘ç»™ç­‰å¼ä¸­çš„ä¸‰ä¸ªéƒ¨åˆ†æ¶‚ä¸Šé¢œè‰²ï¼Œå› ä¸ºæˆ‘ä»¬å¯ä»¥ç”¨çŸ©é˜µæ¥è¡¨ç¤ºå®ƒä»¬ã€‚çœ‹ç¬¬ä¸€è¡Œçº¢è‰²å’Œè“è‰²çš„éƒ¨åˆ†ï¼Œæˆ‘ä»¬æ›´æ–°äº†Î¸0ã€‚

![](img/db5e3e16ff2281e3fa518c2470f6e0b7.png)

æˆ‘ä»¬æŠŠçº¢è‰²éƒ¨åˆ†å’Œè“è‰²éƒ¨åˆ†å†™æˆåˆ—å‘é‡ã€‚

![](img/5eba89b5540ee2ca291c4f4d071858f4.png)

å› ä¸ºæˆ‘ä»¬æœ‰ 20 ä¸ªæ•°æ®æ ·æœ¬ï¼Œæ‰€ä»¥`f`çš„ç»´æ•°æ˜¯`(20,1)`ã€‚`x0`çš„å°ºå¯¸ä¸º`(20,1)`ã€‚æˆ‘ä»¬å¯ä»¥ç”¨è½¬ç½®å†™çŸ©é˜µä¹˜æ³•ã€‚

![](img/0cf3d8cd3910b07662571919f704f771.png)

æ‰€ä»¥å°ºå¯¸åº”è¯¥æ˜¯`(1, 20) x (20, 1) -> (1,)`ã€‚æˆ‘ä»¬å¾—åˆ°ä¸€ä¸ªæ ‡åº¦æ¥æ›´æ–°Î¸0ã€‚

`x1`å’Œ`x2`ä¹Ÿæ˜¯åˆ—å‘é‡ã€‚æˆ‘ä»¬å¯ä»¥æŠŠå®ƒä»¬å†™æˆä¸€ä¸ª **X** çŸ©é˜µã€‚

![](img/a0f08b53e8aeba7abfd865b533cbe659.png)![](img/9aa651712deb36f2d95eba3ae6ab24b8.png)

Î¸æ˜¯ä¸€ä¸ªè¡Œå‘é‡

![](img/0b453a82676456e6ce95b9f33493b9fe.png)

å›åˆ°ç­‰å¼ã€‚

![](img/355c4a8cdd9a21d1188add3cdc42ffa1.png)

æˆ‘ä»¬å¯ä»¥å†™ä¸º

![](img/e7d9398e8018be0e822d43685ebaa7c2.png)

å†™ä½œæ˜¯ä¸€ä¸ªç­‰å¼ã€‚

![](img/cba3402100ab21cdce3de0cf1ab08c27.png)

ç±»ä¼¼ Numpy æ•°ç»„çš„ç‰ˆæœ¬å¯èƒ½å®¹æ˜“ç†è§£ã€‚

![](img/4d4440cecbd94b183434d49bde879e56.png)

è®©æˆ‘ä»¬åšä¸€ç‚¹è®¡ç®—ï¼Œä»¥ç¡®ä¿å°ºå¯¸æ˜¯æ­£ç¡®çš„ã€‚

```
Î¸: (1, 3) 
f^T: (1, 20) 
x: (20, 3)dot production: (1, 20) x (20, 3) -> (1, 3)
```

ä¸€åˆ‡çœ‹èµ·æ¥éƒ½é‚£ä¹ˆæ­£ç¡®ã€‚è®©æˆ‘ä»¬å†™ä»£ç ã€‚å®é™…ä¸Šï¼Œåªæœ‰ä¸¤è¡Œã€‚

```
import numpy as np
import matplotlib.pyplot as plt# read data
data = np.loadtxt("linear_data.csv", delimiter=',', skiprows=1)
train_x = data[:, 0:2]
train_y = data[:, 2]# initialize parameter
theta = np.random.randn(3)# standardization
mu = train_x.mean(axis=0)
sigma = train_x.std(axis=0)
def standardizer(x):
    return (x - mu) / sigma
std_x = standardizer(train_x)# get matrix
def to_matrix(std_x):
    return np.array([[1, x1, x2] for x1, x2 in std_x])
mat_x = to_matrix(std_x)# dot product
def f(x):
    return np.dot(x, theta)# sigmoid function
def f(x):
    return 1 / (1 + np.exp(-np.dot(x, theta)))# update times
epoch = 2000# learning rate
ETA = 1e-3# update parameter
**for _ in range(epoch):
**    """
    f(mat_x) - train_y: (20,)
    mat_x: (20, 3)
    theta: (3,)

    dot production: (20,) x (20, 3) -> (3,)
    """ **theta = theta - ETA * np.dot(f(X) - train_y, mat_x)**
```

å¥‡æ€ªçš„äº‹ï¼Ÿè¿˜è®°å¾—æˆ‘ä»¬åœ¨ä»£ç å‰å†™äº†ä»€ä¹ˆå—ï¼Ÿ

```
dot production: (1, 20) x (20, 3) -> (1, 3)The dimension changes make sense here.
```

ä½†æ˜¯ä¸ºä»€ä¹ˆæˆ‘ä»¬å†™ä»£ç çš„æ—¶å€™è¦ç”¨`(20,) x (20, 3) -> (3,)`ï¼Ÿ

å®é™…ä¸Šï¼Œè¿™ä¸æ˜¯çœŸæ­£çš„æ•°å­¦ç¬¦å·ï¼Œè¿™æ˜¯ Numpy ç¬¦å·ã€‚è€Œä¸”å¦‚æœä½ ç”¨çš„æ˜¯ TensorFlow æˆ–è€… PyTroch çš„è¯ï¼Œåº”è¯¥å¾ˆç†Ÿæ‚‰ã€‚

`(20,)`è¡¨ç¤ºè¿™æ˜¯ä¸€ä¸ªåŒ…å« 20 ä¸ªæ•°å­—çš„ä¸€ç»´æ•°ç»„ã€‚å®ƒå¯ä»¥æ˜¯è¡Œå‘é‡ï¼Œä¹Ÿå¯ä»¥æ˜¯åˆ—å‘é‡ï¼Œå› ä¸ºå®ƒåªæœ‰ä¸€ç»´ã€‚å¦‚æœæˆ‘ä»¬å°†å…¶è®¾ç½®ä¸ºäºŒç»´æ•°ç»„ï¼Œåƒ`(20, 1)`æˆ–`(1, 20)`ï¼Œæˆ‘ä»¬å¯ä»¥å¾ˆå®¹æ˜“åœ°ç¡®å®š`(20, 1)`æ˜¯ä¸€ä¸ªåˆ—å‘é‡è€Œ`(1, 20)`æ˜¯ä¸€ä¸ªè¡Œå‘é‡ã€‚

**ä½†æ˜¯ä¸ºä»€ä¹ˆä¸æ˜¾å¼è®¾ç½®ç»´åº¦æ¥æ¶ˆé™¤æ­§ä¹‰å‘¢ï¼Ÿ**

å¥½å§ã€‚ç›¸ä¿¡æˆ‘ï¼Œæˆ‘ç¬¬ä¸€æ¬¡çœ‹åˆ°è¿™ä¸ªçš„æ—¶å€™å°±æœ‰æ¥ç¼é—®é¢˜ã€‚ä½†æ˜¯ç»è¿‡ä¸€äº›ç¼–ç å®è·µï¼Œæˆ‘æƒ³æˆ‘çŸ¥é“åŸå› äº†ã€‚

å› ä¸ºå®ƒå¯ä»¥èŠ‚çœæˆ‘ä»¬çš„æ—¶é—´ï¼

æˆ‘ä»¬ä»¥`(20,) x (20, 3) -> (3,)`ä¸ºä¾‹ã€‚å¦‚æœæˆ‘ä»¬æƒ³å¾—åˆ°`(1, 20) x (20, 3) -> (1, 3)`ï¼Œæˆ‘ä»¬éœ€è¦ç”¨`(20,) x (20, 3) -> (3,)`åšä»€ä¹ˆï¼Ÿ

*   å°†(20ï¼Œ)è½¬æ¢ä¸º(1ï¼Œ20)
*   è®¡ç®—(1ï¼Œ20) x (20ï¼Œ3) -> (1ï¼Œ3)
*   å› ä¸º(1ï¼Œ3)æ˜¯ä¸€ä¸ªäºŒç»´åˆ—å‘é‡ï¼Œæˆ‘ä»¬éœ€è¦å°†å…¶è½¬æ¢ä¸ºä¸€ç»´æ•°ç»„ã€‚(1,3) -> (3,)

è€å®è¯´ï¼Œè¿™å¾ˆä»¤äººæ²®ä¸§ã€‚ä¸ºä»€ä¹ˆæˆ‘ä»¬ä¸èƒ½ä¸€æ­¥åˆ°ä½ï¼Ÿ

å¯¹ï¼Œæ‰€ä»¥æˆ‘ä»¬æ‰èƒ½å†™`(20,) x (20, 3) -> (3,)`ã€‚

å¥½äº†ï¼Œæˆ‘ä»¬æ¥çœ‹çœ‹ [numpy.dot()](https://docs.scipy.org/doc/numpy/reference/generated/numpy.dot.html) doc æ˜¯æ€ä¹ˆè¯´çš„ã€‚

> [numpy.dot()](https://docs.scipy.org/doc/numpy/reference/generated/numpy.dot.html) :å¦‚æœ *a* æ˜¯ä¸€ä¸ª N ç»´æ•°ç»„ï¼Œ *b* æ˜¯ä¸€ä¸ª 1 ç»´æ•°ç»„ï¼Œé‚£ä¹ˆå®ƒå°±æ˜¯ *a* å’Œ *b* æœ€åä¸€ä¸ªè½´ä¸Šçš„å’Œç§¯ã€‚

å—¯ï¼Œäº‹å®ä¸Šæˆ‘ä¸æ˜ç™½ã€‚ä½†æ˜¯ [np.matmul()](https://docs.scipy.org/doc/numpy/reference/generated/numpy.matmul.html#numpy.matmul) æè¿°äº†ä¸(20ï¼Œ1)æˆ–(1ï¼Œ20)çš„æ•´å½¢ç±»ä¼¼çš„è®¡ç®—ï¼Œä»¥æ‰§è¡Œæ ‡å‡†çš„ 2d çŸ©é˜µä¹˜ç§¯ã€‚ä¹Ÿè®¸æˆ‘ä»¬èƒ½å¾—åˆ°ä¸€äº›çµæ„Ÿã€‚

> [np.matmul()](https://docs.scipy.org/doc/numpy/reference/generated/numpy.matmul.html#numpy.matmul) :å¦‚æœç¬¬ä¸€ä¸ªå‚æ•°æ˜¯ 1-Dï¼Œåˆ™é€šè¿‡åœ¨å®ƒçš„ç»´æ•°å‰åŠ ä¸Š 1 æ¥å°†å…¶æå‡ä¸ºçŸ©é˜µã€‚åœ¨çŸ©é˜µä¹˜æ³•ä¹‹åï¼Œå‰ç½®çš„ 1 è¢«ç§»é™¤ã€‚

å“ˆï¼Œè¿™å°±æ˜¯ç¼ºå¤±çš„éƒ¨åˆ†ï¼æ‰€ä»¥åœ¨æˆ‘ä»¬çš„ä¾‹å­ä¸­ï¼Œ`(20,)`å˜æˆäº†`(1, 20)`ï¼Œå› ä¸º`(20,3)`çš„ç¬¬ä¸€ç»´åº¦æ˜¯ 20ã€‚è¿˜æœ‰`(1, 20) * (20, 3) -> (1, 3)`ã€‚ç„¶åå‰ç½® 1 è¢«åˆ é™¤ï¼Œæ‰€ä»¥æˆ‘ä»¬å¾—åˆ°`(3,)`ã€‚ä¸€æ­¥åˆ°ä½ã€‚

# 9 ç”»å‡ºè¿™æ¡çº¿

åœ¨æ›´æ–°å‚æ•° 2000 æ¬¡åï¼Œæˆ‘ä»¬åº”è¯¥ç»˜åˆ¶ç»“æœæ¥æŸ¥çœ‹æˆ‘ä»¬çš„æ¨¡å‹çš„æ€§èƒ½ã€‚

æˆ‘ä»¬å°†ä¸€äº›æ•°æ®ç‚¹åšä¸º x1ï¼Œæ ¹æ®æˆ‘ä»¬æ‰€å­¦çš„å‚æ•°è®¡ç®— x2ã€‚

![](img/95ff60843ac84bb3b2f3aa7e562cb166.png)

```
# plot line
x1 = np.linspace(-2, 2, 100)
**x2 = - (theta[0] + x1 * theta[1]) / theta[2]**plt.plot(std_x[train_y == 1, 0], std_x[train_y == 1, 1], 'o') # train data of class 1
plt.plot(std_x[train_y == 0, 0], std_x[train_y == 0, 1], 'x') # train data of class 0
**plt.plot(x1, x2, linestyle='dashed') # plot the line we learned** plt.show()
```

![](img/de0927daf1dc6705710da9eaf535da4f.png)

# 10 æ‘˜è¦

æ­å–œä½ ï¼æˆ‘å¾ˆé«˜å…´ä½ èƒ½æ¥ã€‚å¸Œæœ›æˆ‘çš„æ–‡ç« å¯¹ä½ æœ‰å¸®åŠ©ã€‚ä½ å¯ä»¥åœ¨ä¸‹é¢æ‰¾åˆ°å®Œæ•´çš„ä»£ç ã€‚ç•™ä¸‹è¯„è®ºè®©æˆ‘çŸ¥é“æˆ‘çš„æ–‡ç« æ˜¯å¦æ˜“æ‡‚ã€‚è¯·ç»§ç»­å…³æ³¨æˆ‘çš„ä¸‹ä¸€ç¯‡å…³äºéçº¿æ€§å¯åˆ†æ€§é—®é¢˜çš„æ–‡ç« ã€‚

> ***æŸ¥çœ‹æˆ‘çš„å…¶ä»–å¸–å­*** [***ä¸­ç­‰***](https://medium.com/@bramblexu) ***åŒ*** [***åˆ†ç±»æŸ¥çœ‹***](https://bramblexu.com/posts/eb7bd472/) ***ï¼
> GitHub:***[***bramble Xu***](https://github.com/BrambleXu) ***LinkedIn:***[***å¾äº®***](https://www.linkedin.com/in/xu-liang-99356891/) ***åšå®¢:***[***bramble Xu***](https://bramblexu.com)