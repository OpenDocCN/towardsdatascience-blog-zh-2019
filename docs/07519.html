<html>
<head>
<title>Machine Learning Concept behind Linear Regression</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">线性回归背后的机器学习概念</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/how-machine-learns-from-data-a-simple-method-for-co2-pollution-prediction-af18430ce12b?source=collection_archive---------19-----------------------#2019-10-20">https://towardsdatascience.com/how-machine-learns-from-data-a-simple-method-for-co2-pollution-prediction-af18430ce12b?source=collection_archive---------19-----------------------#2019-10-20</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="3b52" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">简单 ML 模型在 CO2 预测中的应用</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/0a73305cd703bfce9812e14cb0d3c76b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*DArLHop2Z_wjhxzr"/></div></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk">Photo by <a class="ae kv" href="https://unsplash.com/@alexander_tsang?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Alexander Tsang</a> on <a class="ae kv" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><h1 id="e37f" class="kw kx iq bd ky kz la lb lc ld le lf lg jw lh jx li jz lj ka lk kc ll kd lm ln bi translated">介绍</h1><p id="d786" class="pw-post-body-paragraph lo lp iq lq b lr ls jr lt lu lv ju lw lx ly lz ma mb mc md me mf mg mh mi mj ij bi translated">在过去的几年里，有很多关于人工智能的炒作。从用声音开灯到完全自主的自动驾驶汽车，你几乎可以在任何地方找到它。</p><p id="6468" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">现代 AI 大多需要大量数据。你给的越多，它学的越好。例如，为了训练 AI 理解猫的图像，你需要给出大量猫和非猫的图像，以便它能够区分这两者。</p><blockquote class="mp mq mr"><p id="a964" class="lo lp ms lq b lr mk jr lt lu ml ju lw mt mm lz ma mu mn md me mv mo mh mi mj ij bi translated">但是 AI 到底是如何从数据中学习的呢？</p></blockquote><p id="8f4b" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">在本帖中，我们将通过一个非常简单的模型来了解人工智能是如何学习的。我们将关注过去 55 年全球二氧化碳排放量，并试图预测 2030 年的排放量。</p><h1 id="5fc7" class="kw kx iq bd ky kz la lb lc ld le lf lg jw lh jx li jz lj ka lk kc ll kd lm ln bi translated">二氧化碳排放数据</h1><p id="0806" class="pw-post-body-paragraph lo lp iq lq b lr ls jr lt lu lv ju lw lx ly lz ma mb mc md me mf mg mh mi mj ij bi translated">我们将使用的数据来自<a class="ae kv" href="https://data.worldbank.org/indicator/EN.ATM.CO2E.KT" rel="noopener ugc nofollow" target="_blank">世界银行</a>。不幸的是，该数据不是截至 2019 年的当前日期(在撰写本文时)。这是从 1960 年到 2014 年，但这对于这个实验来说很好。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi mw"><img src="../Images/c6c21c62460b556d35d3df4d9e85fb8b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Mx4PMGrYRu_hAeOXen1BVg.png"/></div></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk">Fig 1: Amount of CO2 Emission annually from 1960 to 2014. Source: <a class="ae kv" href="https://data.worldbank.org/indicator/EN.ATM.CO2E.KT" rel="noopener ugc nofollow" target="_blank">WorldBank Data</a></figcaption></figure><p id="535c" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">x 轴对应年份(假设 0 年是 1960 年)，y 轴对应 CO2 排放量。根据图表，我们也许能够对 2030 年的价值做一个粗略的估计。</p><blockquote class="mp mq mr"><p id="0280" class="lo lp ms lq b lr mk jr lt lu ml ju lw mt mm lz ma mu mn md me mv mo mh mi mj ij bi translated">假设我们只是<strong class="lq ir"> </strong>画一条最符合这个数据的直线，如果我们把这条线越拉越远，我们就可以预测未来。</p></blockquote><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi mx"><img src="../Images/4347dd16f5afce71339c600cf611f832.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*kU3pGkD0jBwTN9VjbxvtDQ.png"/></div></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk">Fig 2: Fit a line and use it to make a rough estimation at year 70 (2030)</figcaption></figure><p id="fcac" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">请记住，我们无法准确预测未来。事情可能会变得更好，但为了简单起见，我们只是假设变化率是恒定的。</p><h1 id="794f" class="kw kx iq bd ky kz la lb lc ld le lf lg jw lh jx li jz lj ka lk kc ll kd lm ln bi translated">线性回归</h1><p id="380b" class="pw-post-body-paragraph lo lp iq lq b lr ls jr lt lu lv ju lw lx ly lz ma mb mc md me mf mg mh mi mj ij bi translated">让我们引入一点数学知识。上面的蓝线你可能很熟悉。这是一条简单的直线，用下面的等式表示。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi my"><img src="../Images/9242ac349aa4fdf35f6d3124fd4e63c8.png" data-original-src="https://miro.medium.com/v2/resize:fit:322/format:webp/1*w0mokU2QVDCoJvQ6v-uGUA.png"/></div></figure><p id="ea52" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">嗯哼。现在你记起来了。同样，<strong class="lq ir"> x </strong>是年份，<strong class="lq ir"> y </strong>是排放量。为了得到图 2 所示的线，m=446，334，b=9，297，274。不用担心 m 和 b，后面我会详细解释。</p><p id="2690" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">如果我们想知道 2030 年的信息(如果从 1960 年算起，是 70 年)，我们现在可以使用上面的等式。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi mz"><img src="../Images/2ffb8821de70a3e4c8bd76d97e99787b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1214/format:webp/1*h52SqelmQoclyHrliJAPOw.png"/></div></figure><p id="d37c" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">现在按照承诺，让我们仔细看看什么是<strong class="lq ir"> m </strong>和<strong class="lq ir"> b </strong>。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi na"><img src="../Images/ca87c0ce91c76497320ded514c9b4eb2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/1*N2xt8cMLIhWiIFNYmkzqpg.gif"/></div></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk">Fig 3: Behavior of m on the line</figcaption></figure><p id="d8d5" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">在图 3 中，当我们改变 m 的值时，直线旋转。因此，变量 m 控制<strong class="lq ir">线</strong>的方向。而在图 4 中，变量 b 通过上下移动线来控制线<strong class="lq ir">的位置。</strong></p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi na"><img src="../Images/25ef0a70dd7fb7c7055285cd03b0009e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/1*J-iWWnKUxEcNbm-x0yejhQ.gif"/></div></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk">Fig 4: Behavior of b on the line</figcaption></figure><h1 id="a8d7" class="kw kx iq bd ky kz la lb lc ld le lf lg jw lh jx li jz lj ka lk kc ll kd lm ln bi translated">学习过程</h1><blockquote class="mp mq mr"><p id="ae30" class="lo lp ms lq b lr mk jr lt lu ml ju lw mt mm lz ma mu mn md me mv mo mh mi mj ij bi translated">有了 m 和 b，我们就可以控制这条线，并将其调整到最适合我们的数据。</p></blockquote><p id="622b" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">现在的问题是我们如何找到变量 m 和 b 的值？想法是这样的:</p><ol class=""><li id="152c" class="nb nc iq lq b lr mk lu ml lx nd mb ne mf nf mj ng nh ni nj bi translated">随机化 m 和 b 的值。</li><li id="dae5" class="nb nc iq lq b lr nk lu nl lx nm mb nn mf no mj ng nh ni nj bi translated">将变量赋予损失函数，以确定该线与数据相比有多差，也称为差错率。</li><li id="b48d" class="nb nc iq lq b lr nk lu nl lx nm mb nn mf no mj ng nh ni nj bi translated">根据错误率调整 m 和 b 的值。</li><li id="de2a" class="nb nc iq lq b lr nk lu nl lx nm mb nn mf no mj ng nh ni nj bi translated">回到步骤 2。重复直到变量停止变化。</li></ol><h1 id="0450" class="kw kx iq bd ky kz la lb lc ld le lf lg jw lh jx li jz lj ka lk kc ll kd lm ln bi translated">损失函数</h1><p id="52e2" class="pw-post-body-paragraph lo lp iq lq b lr ls jr lt lu lv ju lw lx ly lz ma mb mc md me mf mg mh mi mj ij bi translated">如果我们的线路很差，这个损失函数会给出非常大的误差。同时，如果直线与数据拟合得很好，误差也会很小。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi np"><img src="../Images/dc0028bc8556ed25d6fa02e28fa10877.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*wdp8HIGXxrI-JEgBdeyDXA.png"/></div></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk">Fig 5: The difference between predicted line and actual data</figcaption></figure><p id="15a0" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">该线每年都有其预测值<strong class="lq ir">y’</strong>。然后，我们可以将预测值<strong class="lq ir">y’</strong>与实际值<strong class="lq ir"> y </strong>进行比较，找出差异。我们每年计算这个值，取其平均值。这也被称为<em class="ms">均方误差</em> (MSE)。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi nq"><img src="../Images/cdffd5b1d66d7f8b714768a9116be57e.png" data-original-src="https://miro.medium.com/v2/resize:fit:564/format:webp/1*9x_UfZ6XKvJarktQx-t1dQ.png"/></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk">Fig 6: Closed form of MSE</figcaption></figure><p id="7d83" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">现在我们差不多准备好更新我们的变量了。有一个小问题。我们之前发现的错误率总是正的。我们几乎不知道哪个方向应该更新我们的线。它应该顺时针旋转还是逆时针旋转？这时<strong class="lq ir">渐变下降</strong>出现了。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nr"><img src="../Images/34ba8406f7c5d2db80cb4a3f3684e753.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*gMiy_eU-H5AJc8py4USjyA.png"/></div></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk">Fig 7: Formula to update each variable (in this case, variable <em class="ns">m</em>)</figcaption></figure><p id="ea7a" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">简而言之，这说明了方向以及每个变量对误差的影响程度。<strong class="lq ir">越是有效果，越应该改变价值。然后，我们可以使用这些信息来更新我们的变量。我们不会深入探究衍生品，但如果你感兴趣，你可以在 Coursera 上查看<a class="ae kv" href="https://www.coursera.org/learn/machine-learning/lecture/kCvQc/gradient-descent-for-linear-regression" rel="noopener ugc nofollow" target="_blank">这个视频</a>。我发现那里的解释相当清楚。</strong></p><p id="634b" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">注意阿尔法<strong class="lq ir">阿尔法</strong>，也称为<strong class="lq ir">学习率</strong>，是控制我们应该更新变量的多少。通常，我们将它设置为一个小值，比如 0.001，这样我们就可以慢慢地将变量更新到最佳值。</p><blockquote class="mp mq mr"><p id="506a" class="lo lp ms lq b lr mk jr lt lu ml ju lw mt mm lz ma mu mn md me mv mo mh mi mj ij bi translated">好消息是:在实践中，我们不会手动进行这种推导。</p></blockquote><p id="72e7" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">像 Tensorflow 或 PyTorch 这样的流行框架会自动计算这一点。但是我把它放在这里是为了简单说明它是如何知道向哪个方向改变值的。</p><h1 id="45e3" class="kw kx iq bd ky kz la lb lc ld le lf lg jw lh jx li jz lj ka lk kc ll kd lm ln bi translated">履行</h1><p id="72d1" class="pw-post-body-paragraph lo lp iq lq b lr ls jr lt lu lv ju lw lx ly lz ma mb mc md me mf mg mh mi mj ij bi translated">那么，您需要像上面描述的那样编写所有代码来让线性回归工作吗？幸运的是，许多现有的库为您简化了一切。在这个例子中，我们将探索为 Python 构建的机器学习库<a class="ae kv" href="https://scikit-learn.org" rel="noopener ugc nofollow" target="_blank"> scikit-learn </a>，以预测二氧化碳排放。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nt nu l"/></div></figure><p id="e2e3" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">只需几行代码，scikit-learn 就能让线性回归变得非常容易。仅第 9 行就完成了训练模型所需的所有必要步骤。唷，你是在杞人忧天，不是吗？这不仅适用于线性回归，也适用于用几行代码实现许多其他的 ML 算法。</p><h1 id="03fc" class="kw kx iq bd ky kz la lb lc ld le lf lg jw lh jx li jz lj ka lk kc ll kd lm ln bi translated">结论</h1><p id="3d6a" class="pw-post-body-paragraph lo lp iq lq b lr ls jr lt lu lv ju lw lx ly lz ma mb mc md me mf mg mh mi mj ij bi translated">就是这样。没那么复杂吧(推导部分除外)？线性回归是一种简单而有效的方法，尽管它只是一条直线。在这篇文章中，我们只看了只有一个变量(年份)的情况。实际上，这可以扩展到处理多个变量，但这是后面文章的主题。</p></div><div class="ab cl nv nw hu nx" role="separator"><span class="ny bw bk nz oa ob"/><span class="ny bw bk nz oa ob"/><span class="ny bw bk nz oa"/></div><div class="ij ik il im in"><h1 id="e22c" class="kw kx iq bd ky kz oc lb lc ld od lf lg jw oe jx li jz of ka lk kc og kd lm ln bi translated">参考</h1><ol class=""><li id="b316" class="nb nc iq lq b lr ls lu lv lx oh mb oi mf oj mj ng nh ni nj bi translated"><a class="ae kv" href="https://en.wikipedia.org/wiki/Linear_regression" rel="noopener ugc nofollow" target="_blank">https://en.wikipedia.org/wiki/Linear_regression</a></li><li id="80bc" class="nb nc iq lq b lr nk lu nl lx nm mb nn mf no mj ng nh ni nj bi translated"><a class="ae kv" rel="noopener" target="_blank" href="/introduction-to-machine-learning-algorithms-linear-regression-14c4e325882a">https://towards data science . com/introduction-to-machine-learning-algorithms-linear-regression-14c4e 325882 a</a></li><li id="7a48" class="nb nc iq lq b lr nk lu nl lx nm mb nn mf no mj ng nh ni nj bi translated"><a class="ae kv" href="https://developers.google.com/machine-learning/crash-course/descending-into-ml/linear-regression" rel="noopener ugc nofollow" target="_blank">https://developers . Google . com/machine-learning/速成/descending-into-ml/linear-regression</a></li><li id="1652" class="nb nc iq lq b lr nk lu nl lx nm mb nn mf no mj ng nh ni nj bi translated"><a class="ae kv" href="https://www.coursera.org/learn/machine-learning/lecture/kCvQc/gradient-descent-for-linear-regression" rel="noopener ugc nofollow" target="_blank">https://www . coursera . org/learn/machine-learning/lecture/kCvQc/gradient-descent-for-linear-regression</a></li></ol></div></div>    
</body>
</html>