<html>
<head>
<title>Apache Hive Optimization Techniques — 1</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">Apache Hive 优化技术— 1</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/apache-hive-optimization-techniques-1-ce55331dbf5e?source=collection_archive---------5-----------------------#2019-08-09">https://towardsdatascience.com/apache-hive-optimization-techniques-1-ce55331dbf5e?source=collection_archive---------5-----------------------#2019-08-09</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><figure class="gl gn jo jp jq jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi jn"><img src="../Images/c24cc0955217ac18a5c00639865e7ca7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*nd79weIivnt7f43-mlP-DQ.png"/></div></div></figure><p id="af62" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">Apache Hive 是一个查询和分析引擎，构建在 Apache Hadoop 之上，使用 MapReduce 编程模型。它提供了一个抽象层，通过使用 Java API 实现传统的 SQL 查询，使用 SQL 语法查询大数据。蜂巢的主要组件如下:</p><ul class=""><li id="f576" class="kw kx iq ka b kb kc kf kg kj ky kn kz kr la kv lb lc ld le bi translated">Metastore</li><li id="ac0d" class="kw kx iq ka b kb lf kf lg kj lh kn li kr lj kv lb lc ld le bi translated">驾驶员</li><li id="bddb" class="kw kx iq ka b kb lf kf lg kj lh kn li kr lj kv lb lc ld le bi translated">编译程序</li><li id="ab3f" class="kw kx iq ka b kb lf kf lg kj lh kn li kr lj kv lb lc ld le bi translated">【计算机】优化程序</li><li id="4ec3" class="kw kx iq ka b kb lf kf lg kj lh kn li kr lj kv lb lc ld le bi translated">执行者</li><li id="4632" class="kw kx iq ka b kb lf kf lg kj lh kn li kr lj kv lb lc ld le bi translated">客户</li></ul><p id="3f38" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">虽然 Hadoop/hive 可以处理几乎任何数量的数据，但优化可以在处理时间和成本方面带来与数据量成比例的巨大节省。在 hive 中可以应用大量的优化。让我们来看看我们将要涉及的优化技术:</p><ol class=""><li id="e4ce" class="kw kx iq ka b kb kc kf kg kj ky kn kz kr la kv lk lc ld le bi translated">分割</li><li id="9505" class="kw kx iq ka b kb lf kf lg kj lh kn li kr lj kv lk lc ld le bi translated">桶装</li><li id="0365" class="kw kx iq ka b kb lf kf lg kj lh kn li kr lj kv lk lc ld le bi translated">使用 Tez 作为执行引擎</li><li id="bb0e" class="kw kx iq ka b kb lf kf lg kj lh kn li kr lj kv lk lc ld le bi translated">使用压缩</li><li id="aa30" class="kw kx iq ka b kb lf kf lg kj lh kn li kr lj kv lk lc ld le bi translated">使用 ORC 格式</li><li id="2ec2" class="kw kx iq ka b kb lf kf lg kj lh kn li kr lj kv lk lc ld le bi translated">连接优化</li><li id="0230" class="kw kx iq ka b kb lf kf lg kj lh kn li kr lj kv lk lc ld le bi translated">基于成本的优化器</li></ol></div><div class="ab cl ll lm hu ln" role="separator"><span class="lo bw bk lp lq lr"/><span class="lo bw bk lp lq lr"/><span class="lo bw bk lp lq"/></div><div class="ij ik il im in"><h1 id="20b2" class="ls lt iq bd lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk ml mm mn mo mp bi translated"><strong class="ak">分区</strong></h1><p id="7561" class="pw-post-body-paragraph jy jz iq ka b kb mq kd ke kf mr kh ki kj ms kl km kn mt kp kq kr mu kt ku kv ij bi translated">分区根据特定列的值将表分成几个部分。一个表可以有多个分区列来标识一个特定的分区。使用分区很容易对数据切片进行查询。分区列的数据不保存在文件中。在检查文件结构时，您会注意到它根据分区列值创建文件夹。这确保了在执行特定作业时只读取相关数据，减少了查询所需的 I/O 时间。因此，提高了查询性能。</p><p id="2c42" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">当我们在分区表上查询数据时，它只会扫描要查询的相关分区，跳过不相关的分区。现在，假设即使进行分区，分区中的数据也相当大，为了进一步将它分成更易于管理的块，我们可以使用分块。</p><blockquote class="mv"><p id="0c1d" class="mw mx iq bd my mz na nb nc nd ne kv dk translated"><em class="nf">创建由(partition1 data_type，partition2 data_type，…)分区的表 table_name (column1 data_type，column2 data_type，…)。);</em></p></blockquote><ul class=""><li id="3d7a" class="kw kx iq ka b kb ng kf nh kj ni kn nj kr nk kv lb lc ld le bi translated">表的列列表中未定义分区列。</li><li id="f3d6" class="kw kx iq ka b kb lf kf lg kj lh kn li kr lj kv lb lc ld le bi translated">在插入查询中，分区在开头被提及，并且它们的列值也与其他列的值一起被给出，但是在结尾。</li></ul><blockquote class="mv"><p id="3ee2" class="mw mx iq bd my mz nl nm nn no np kv dk translated"><strong class="ak"> <em class="nf">向表中插入 table_name 分区(partition1 = 'partition1_val '，partition2 = 'partition2_val '，…)值(col1_val，col2_val，…，partition1_val，partition2_val，…)；</em> </strong></p></blockquote><ul class=""><li id="f690" class="kw kx iq ka b kb ng kf nh kj ni kn nj kr nk kv lb lc ld le bi translated">分区基本上有两种类型:<strong class="ka ir">静态</strong>和<strong class="ka ir">动态</strong>。名字是不言自明的。</li><li id="2e58" class="kw kx iq ka b kb lf kf lg kj lh kn li kr lj kv lb lc ld le bi translated"><strong class="ka ir">静态分区<br/> </strong>当我们知道将要加载的数据的分区时，就可以进行静态分区。当从大文件中加载表中的数据时，这应该是首选方法。它在严格模式下执行:</li></ul><blockquote class="mv"><p id="e27b" class="mw mx iq bd my mz nl nm nn no np kv dk translated"><strong class="ak"> <em class="nf">设置 hive . mapred . mode = strict；</em> </strong></p></blockquote><ul class=""><li id="7a2c" class="kw kx iq ka b kb ng kf nh kj ni kn nj kr nk kv lb lc ld le bi translated"><strong class="ka ir">动态分区<br/> </strong>当我们不知道数据的分区时，就使用它。在表中加载数据需要更多时间。通常，我们使用另一个包含未分区数据的表来装载表中的数据。<br/>在配置单元中启用动态分区:</li></ul><blockquote class="mv"><p id="88e2" class="mw mx iq bd my mz nl nm nn no np kv dk translated"><strong class="ak">T5】设置 hive . exec . dynamic . partition = true； </strong></p></blockquote><p id="744f" class="pw-post-body-paragraph jy jz iq ka b kb ng kd ke kf nh kh ki kj nq kl km kn nr kp kq kr ns kt ku kv ij bi translated"><strong class="ka ir">动态分区有两种模式:</strong> <br/> <strong class="ka ir">严格:</strong>这需要在加载数据时至少有一列是静态的。<br/> <strong class="ka ir">非严格:</strong>这允许我们拥有所有分区列的动态值。</p><blockquote class="mv"><p id="5ceb" class="mw mx iq bd my mz na nb nc nd ne kv dk translated"><strong class="ak">SET hive . exec . dynamic . partition . mode = non strict；</strong></p></blockquote><p id="3b98" class="pw-post-body-paragraph jy jz iq ka b kb ng kd ke kf nh kh ki kj nq kl km kn nr kp kq kr ns kt ku kv ij bi translated">使用动态分区时，还需要配置其他一些东西，比如</p><blockquote class="nt nu nv"><p id="dbe0" class="jy jz nw ka b kb kc kd ke kf kg kh ki nx kk kl km ny ko kp kq nz ks kt ku kv ij bi translated"><strong class="ka ir">hive . exec . max . dynamic . partitions . pernode:</strong>每个映射器/缩减器节点中要创建的最大分区数</p><p id="8c6c" class="jy jz nw ka b kb kc kd ke kf kg kh ki nx kk kl km ny ko kp kq nz ks kt ku kv ij bi translated"><strong class="ka ir">hive . exec . max . dynamic . partitions:</strong>总共允许创建的最大动态分区数</p><p id="b94e" class="jy jz nw ka b kb kc kd ke kf kg kh ki nx kk kl km ny ko kp kq nz ks kt ku kv ij bi translated"><strong class="ka ir">hive . exec . max . created . files:</strong>MapReduce 作业中所有 mapper/reducer 创建的最大 HDFS 文件数</p><p id="2286" class="jy jz nw ka b kb kc kd ke kf kg kh ki nx kk kl km ny ko kp kq nz ks kt ku kv ij bi translated"><strong class="ka ir">hive . error . on . empty . partition:</strong>如果动态分区插入生成空结果，是否抛出异常</p></blockquote></div><div class="ab cl ll lm hu ln" role="separator"><span class="lo bw bk lp lq lr"/><span class="lo bw bk lp lq lr"/><span class="lo bw bk lp lq"/></div><div class="ij ik il im in"><h1 id="6ff0" class="ls lt iq bd lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk ml mm mn mo mp bi translated">桶装</h1><p id="9f9e" class="pw-post-body-paragraph jy jz iq ka b kb mq kd ke kf mr kh ki kj ms kl km kn mt kp kq kr mu kt ku kv ij bi translated">存储桶提供了灵活性，可以进一步将数据分成更易于管理的部分，称为存储桶或集群。存储基于哈希函数，哈希函数取决于存储列的类型。由相同列值存储的记录将始终保存在相同的存储桶中。<strong class="ka ir"> CLUSTERED BY </strong>子句用于将表分成桶。对于具有高基数的列，它工作得很好。</p><blockquote class="mv"><p id="5fef" class="mw mx iq bd my mz na nb nc nd ne kv dk translated">创建由(partition1 data_type，partition2 data_type，…)分区的表 table_name (column1 data_type，column2 data_type，…)。)按(clus_col1)聚类按(sort_col2)排序到 n 个桶中；</p></blockquote><p id="5cbc" class="pw-post-body-paragraph jy jz iq ka b kb ng kd ke kf nh kh ki kj nq kl km kn nr kp kq kr ns kt ku kv ij bi translated">在 Hive 分区中，每个<strong class="ka ir">分区</strong>将被创建为一个<strong class="ka ir">目录</strong>。但是在 Hive 桶中，每个<strong class="ka ir">桶</strong>将被创建为一个<strong class="ka ir">文件</strong>。</p><blockquote class="mv"><p id="acc7" class="mw mx iq bd my mz na nb nc nd ne kv dk translated"><strong class="ak">设置 hive . enforce . bucket ing = true；</strong></p></blockquote><p id="ad9a" class="pw-post-body-paragraph jy jz iq ka b kb ng kd ke kf nh kh ki kj nq kl km kn nr kp kq kr ns kt ku kv ij bi translated">使用分桶，我们还可以使用一个或多个列对数据进行排序。因为数据文件是大小相等的部分，所以分桶表上的映射端连接会更快。</p><p id="8245" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">当与 ORC 文件一起使用并用作连接列时，分段也有它自己的好处。我们将进一步讨论这些好处。</p><h1 id="b800" class="ls lt iq bd lu lv oa lx ly lz ob mb mc md oc mf mg mh od mj mk ml oe mn mo mp bi translated">使用 Tez 作为执行引擎</h1><p id="62e7" class="pw-post-body-paragraph jy jz iq ka b kb mq kd ke kf mr kh ki kj ms kl km kn mt kp kq kr mu kt ku kv ij bi translated">Apache Tez 是一个客户端库，它像一个执行引擎一样运行，是传统 MapReduce 引擎的替代引擎，在 Hive 和 Pig 下，它允许使用 DAG 格式更快地处理作业。</p><p id="56fb" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">为了研究 Tez 如何帮助优化作业，我们将首先研究 MapReduce 作业的定型处理序列:</p><figure class="og oh oi oj gt jr gh gi paragraph-image"><div class="gh gi of"><img src="../Images/939772491b6035db804f2a45a81b6e13.png" data-original-src="https://miro.medium.com/v2/resize:fit:746/format:webp/1*mRPF-3T7q50jsTtaJSWMEQ.png"/></div></figure><ul class=""><li id="8d83" class="kw kx iq ka b kb kc kf kg kj ky kn kz kr la kv lb lc ld le bi translated">Mapper 函数从文件系统中读取数据，将其处理成键值对，然后临时存储在本地磁盘上。这些按键值分组的键值对通过网络发送给 reducers。</li><li id="cbe8" class="kw kx iq ka b kb lf kf lg kj lh kn li kr lj kv lb lc ld le bi translated">在要运行 Reducers 的节点上，数据被接收并保存在本地磁盘上，等待来自所有映射器的数据到达。然后，将一个键的整组值读入一个 reducer，进行处理，并进一步写入输出，然后根据配置进一步复制输出。</li><li id="8c70" class="kw kx iq ka b kb lf kf lg kj lh kn li kr lj kv lb lc ld le bi translated">正如您所注意到的，单个 MapReduce 作业中包含了大量不必要的读/写开销。运行多个 MapReduce 作业来完成单个配置单元查询，并且 MapReduce 作业的所有输出首先被写入 DFS，然后被传输到节点，并且由于两个 MapReduce 作业之间没有协调，所以循环被重复。</li></ul><p id="97f9" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">Apache Tez 通过不中断多个 MapReduce 作业中的 Hive-query 来优化它。因为，Tez 是一个客户端库，用于编排 MapReduce 作业的处理。Tez 使用如下步骤优化作业:</p><figure class="og oh oi oj gt jr gh gi paragraph-image"><div class="gh gi ok"><img src="../Images/00b3dd4ce7c8d1e1144a06773e85c431.png" data-original-src="https://miro.medium.com/v2/resize:fit:802/format:webp/1*sHCF1sPMTb2rKiipqzsQkQ.png"/></div></figure><ul class=""><li id="3b8a" class="kw kx iq ka b kb kc kf kg kj ky kn kz kr la kv lb lc ld le bi translated">跳过缩减器的 DFS 写入，并将缩减器的输出直接作为输入管道传输到后续映射器中。</li><li id="18f7" class="kw kx iq ka b kb lf kf lg kj lh kn li kr lj kv lb lc ld le bi translated">级联一系列减速器，而不插入映射器步骤。</li><li id="29cb" class="kw kx iq ka b kb lf kf lg kj lh kn li kr lj kv lb lc ld le bi translated">连续加工阶段容器的重复使用。</li><li id="c0f6" class="kw kx iq ka b kb lf kf lg kj lh kn li kr lj kv lb lc ld le bi translated">使用预热容器实现最佳资源利用。</li><li id="e73d" class="kw kx iq ka b kb lf kf lg kj lh kn li kr lj kv lb lc ld le bi translated">基于成本的优化。</li><li id="4666" class="kw kx iq ka b kb lf kf lg kj lh kn li kr lj kv lb lc ld le bi translated">矢量化查询处理。</li></ul><p id="b344" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">我们可以使用下面的查询来设置执行引擎，或者在 hive-site.xml 中设置它。</p><blockquote class="mv"><p id="0601" class="mw mx iq bd my mz na nb nc nd ne kv dk translated"><strong class="ak">设置 hive . execution . engine = tez/Mr</strong></p></blockquote><h1 id="213d" class="ls lt iq bd lu lv oa lx ly lz ob mb mc md ol mf mg mh om mj mk ml on mn mo mp bi translated">使用压缩</h1><p id="c035" class="pw-post-body-paragraph jy jz iq ka b kb mq kd ke kf mr kh ki kj ms kl km kn mt kp kq kr mu kt ku kv ij bi translated">正如您可能已经注意到的，hive 查询涉及大量的磁盘 I/O 或网络 I/O 操作，通过压缩减少数据的大小可以很容易地减少这些操作。Hive 中的大多数数据格式都是基于文本的格式，可压缩性很强，可以节省大量成本。但是，当我们考虑压缩时，有一个权衡，压缩和解压缩的 CPU 成本。</p><p id="2028" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">以下是执行 I/O 操作和压缩可以节省成本的主要情况:</p><ul class=""><li id="485b" class="kw kx iq ka b kb kc kf kg kj ky kn kz kr la kv lb lc ld le bi translated">从本地 DFS 目录中读取数据</li><li id="3afc" class="kw kx iq ka b kb lf kf lg kj lh kn li kr lj kv lb lc ld le bi translated">从非本地 DFS 目录读取数据</li><li id="72b2" class="kw kx iq ka b kb lf kf lg kj lh kn li kr lj kv lb lc ld le bi translated">将数据从缩减器移动到下一级映射器/缩减器</li><li id="8320" class="kw kx iq ka b kb lf kf lg kj lh kn li kr lj kv lb lc ld le bi translated">将最终输出移回 DFS。</li></ul><p id="b8c1" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">此外，DFS 复制数据也是为了容错，当我们复制数据时，会涉及更多的 I/O 操作。</p><p id="1701" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">您可以将使用 Gzip 或 Bzip2 压缩的文本文件直接导入存储为 TextFile 的表格中。使用 LOAD 语句或通过在压缩数据位置上创建表，可以将压缩数据直接加载到 Hive 中。将自动检测压缩，并在查询执行期间动态解压缩文件。然而，在这种情况下，Hadoop 将无法将您的文件分割成块/块，并并行运行多个映射。但是，压缩的序列文件可以分割成多个。</p><p id="4d37" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">上面的优化将会节省大量的执行成本，并且会使作业执行得更快。在下一篇文章的<a class="ae oo" href="https://medium.com/@info.ankitp/apache-hive-optimization-techniques-2-e60b6200eeca" rel="noopener">中，我们将讨论剩下的技术:使用 ORC 文件的优化、连接查询的优化以及基于成本的优化。</a></p><p id="4744" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">我希望你会发现这篇文章内容丰富且简单易学。如果你有任何疑问，请随时拨打 info.ankitp@gmail.com<a class="ae oo" href="mailto:info.ankitp@gmail.com" rel="noopener ugc nofollow" target="_blank">的电话联系我</a></p></div></div>    
</body>
</html>