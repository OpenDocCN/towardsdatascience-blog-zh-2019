<html>
<head>
<title>Calculating Loss of Yolo (v3) Layer</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">计算 Yolo (v3)层的损耗</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/calculating-loss-of-yolo-v3-layer-8878bfaaf1ff?source=collection_archive---------4-----------------------#2019-09-13">https://towardsdatascience.com/calculating-loss-of-yolo-v3-layer-8878bfaaf1ff?source=collection_archive---------4-----------------------#2019-09-13</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="50c1" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">Yolo v3 模型的实现</h2></div><p id="f106" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">Yolov3 是最先进的对象检测模型，使其成为快速准确的实时对象检测模型。有没有想过 Yolov3 车型的症结在哪里？秘密在于 Yolo 模型的 Yolo 层。</p><h1 id="55a0" class="le lf it bd lg lh li lj lk ll lm ln lo jz lp ka lq kc lr kd ls kf lt kg lu lv bi translated">Yolov3 架构</h1><p id="f34c" class="pw-post-body-paragraph ki kj it kk b kl lw ju kn ko lx jx kq kr ly kt ku kv lz kx ky kz ma lb lc ld im bi translated">Yolov3 模型接收 416x416 的图像，用经过训练的 Darknet-53 主干对其进行处理，并在三个尺度上产生检测。在每个比例下，输出检测的形状为(批量大小 x 锚盒数量 x 网格大小 x 网格大小 x 85 维)。</p><figure class="mc md me mf gt mg gh gi paragraph-image"><div role="button" tabindex="0" class="mh mi di mj bf mk"><div class="gh gi mb"><img src="../Images/7081f5d49edfb8123de576d415627ea4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*vDfofpXSxcJ_zVITxCQDlA.png"/></div></div><figcaption class="mn mo gj gh gi mp mq bd b be z dk">Output detections of shape (batch_size x num_of_anchor_boxes x grid_size x grid_size x 85 dimensions)</figcaption></figure><p id="ac1b" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">Yolov3 的架构在<a class="ae mr" rel="noopener" target="_blank" href="/yolo-v3-object-detection-53fb7d3bfe6b">https://towardsdatascience . com/Yolo-v3-object-detection-53 FB 7d 3 bfe 6 b</a>的 Yolo v3 网络架构图中描绘得非常好(请阅读这个故事了解 Yolo v3 架构)。在该图描述的所有组件中，有 3 个检测层，它们也是 Yolo 层。三个 Yolo 层中的每一层负责计算三个不同尺度的损耗。然后将三个不同尺度的损耗相加，用于反向传播。每个 Yolo 层利用 85 个维度来计算损耗。前 4 个维度对应于边界框的中心线、中心线、宽度和高度。接下来的 1 维对应于边界框的客观性分数，最后的 80 维对应于边界框的独热编码类预测。计算以下 4 种损失:</p><ol class=""><li id="6926" class="ms mt it kk b kl km ko kp kr mu kv mv kz mw ld mx my mz na bi translated">包围盒的中心线、中心线、宽度和高度的 MSE</li></ol><p id="ef93" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">2.包围盒的客观分数的 BCE</p><p id="05be" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">3.包围盒的无客观性分数的 BCE</p><p id="e3da" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">4.包围盒的多类预测的 BCE</p><p id="aab9" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">详细实现代码由<a class="ae mr" rel="noopener" target="_blank" href="/yolo-v3-object-detection-53fb7d3bfe6b">https://towards data science . com/yolo-v3-object-detection-53 FB 7d 3 bfe 6 b</a>。解释和张量形状被附加以帮助解释下面的代码。</p><p id="2274" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">Yolo 层采用一个复杂的形状特征(批量大小 x 锚盒数量 x 网格大小 x 网格大小 x 85 个维度)来计算上述 4 个损失。首先，基于标记的目标，它首先创建形状的 Obj 掩码((batch _ size x num _ of _ anchor _ boxes x grid _ size x grid _ size x 85 维)以指示哪些边界框应该包含预测，并创建形状的 Noobj 掩码(batch _ size x num _ of _ anchor _ boxes x grid _ size x grid _ size x 85 维)以指示哪些边界框不应该包含预测。有了掩模，可以成功地将目标与相同形状的预测进行比较，以计算四个损失。具体实现见下文。</p><figure class="mc md me mf gt mg gh gi paragraph-image"><div role="button" tabindex="0" class="mh mi di mj bf mk"><div class="gh gi nb"><img src="../Images/364bf4d3735b551c2efb4aec88dcfc10.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*3nFz1dLOUvdXI-V4udqrIQ.png"/></div></div><figcaption class="mn mo gj gh gi mp mq bd b be z dk">YoloLayer Class from models.py from <a class="ae mr" rel="noopener" target="_blank" href="/yolo-v3-object-detection-53fb7d3bfe6b">https://towardsdatascience.com/yolo-v3-object-detection-53fb7d3bfe6b</a></figcaption></figure><p id="c616" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">从数据集中选取 batch_size 目标，如下所示:</p><figure class="mc md me mf gt mg gh gi paragraph-image"><div role="button" tabindex="0" class="mh mi di mj bf mk"><div class="gh gi nc"><img src="../Images/da8978ee7c1b1fab02e9fcd40df11c7c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*fI46KaqHLdb9izz9Bjlw7w.png"/></div></div><figcaption class="mn mo gj gh gi mp mq bd b be z dk">A batch_size targets</figcaption></figure><p id="d88f" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">基于标记的目标，下面的 build_targets 函数创建形状的 obj 掩码(batch _ size x num _ of _ anchor boxes x gridsize x gridsize)来指示哪些边界框应该包含预测，并创建形状的 noobj 掩码(batch _ size x num _ of _ anchor boxes x gridsize x gridsize)来指示哪些边界框不应该包含预测。</p><figure class="mc md me mf gt mg gh gi paragraph-image"><div role="button" tabindex="0" class="mh mi di mj bf mk"><div class="gh gi nd"><img src="../Images/008f179ed47452dd08d15fd74648cbeb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*FfbxLz9cayYH4b_GQa6EGA.png"/></div></div><figcaption class="mn mo gj gh gi mp mq bd b be z dk">Build_targets function from utils.utils.py from <a class="ae mr" rel="noopener" target="_blank" href="/yolo-v3-object-detection-53fb7d3bfe6b">https://towardsdatascience.com/yolo-v3-object-detection-53fb7d3bfe6b</a></figcaption></figure></div></div>    
</body>
</html>