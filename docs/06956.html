<html>
<head>
<title>Image recommendation engine — leverage transfer learning</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">图像推荐引擎—利用迁移学习</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/image-recommendation-engine-leverage-transfert-learning-ec9af32f5239?source=collection_archive---------12-----------------------#2019-10-02">https://towardsdatascience.com/image-recommendation-engine-leverage-transfert-learning-ec9af32f5239?source=collection_archive---------12-----------------------#2019-10-02</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="7eac" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">应用于图像推荐的预训练模型世界之旅</h2></div><p id="2c4d" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在本文中，我们将开发一个基于图像这种非结构化数据的推荐系统。为了有一个快速、可操作的模型，而不需要费力地微调<code class="fe le lf lg lh b"><a class="ae li" href="https://en.wikipedia.org/wiki/Convolutional_neural_network" rel="noopener ugc nofollow" target="_blank">Convolutional neural network</a></code>算法，我们将使用<code class="fe le lf lg lh b"><a class="ae li" href="https://en.wikipedia.org/wiki/Transfer_learning" rel="noopener ugc nofollow" target="_blank">Transfer Learning</a></code>。</p><blockquote class="lj lk ll"><p id="1265" class="ki kj lm kk b kl km ju kn ko kp jx kq ln ks kt ku lo kw kx ky lp la lb lc ld im bi translated"><strong class="kk iu">迁移学习</strong>是<a class="ae li" href="https://en.wikipedia.org/wiki/Machine_learning" rel="noopener ugc nofollow" target="_blank">机器学习</a>中的一个研究问题，它专注于存储在解决一个问题时获得的知识，并将其应用于另一个不同但相关的问题。<a class="ae li" href="https://en.wikipedia.org/wiki/Transfer_learning#cite_note-1" rel="noopener ugc nofollow" target="_blank">【1】</a>例如，在学习<a class="ae li" href="https://en.wikipedia.org/wiki/Computer_vision#Recognition" rel="noopener ugc nofollow" target="_blank">识别</a>汽车时获得的知识可以应用于识别卡车</p></blockquote><p id="7c17" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">为了使它更容易，我们将使用高级 API <code class="fe le lf lg lh b"><a class="ae li" href="https://keras.io/" rel="noopener ugc nofollow" target="_blank">Keras</a></code>。Keras 提供了几个预训练模型，这些模型已经证明了它们在泛化方面的价值。让我们立即开始建模吧！</p></div><div class="ab cl lq lr hx ls" role="separator"><span class="lt bw bk lu lv lw"/><span class="lt bw bk lu lv lw"/><span class="lt bw bk lu lv"/></div><div class="im in io ip iq"><p id="d66a" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我有一些关于时尚产品的数据，我在这里得到了<a class="ae li" href="https://www.kaggle.com/paramaggarwal/fashion-product-images-classifier" rel="noopener ugc nofollow" target="_blank"/>，由于计算时间的原因，我将语料库减少到 2000 张图片。因此，正如我之前所说，Keras 提供了几个只需导入的预训练模型。</p><figure class="lx ly lz ma gt mb"><div class="bz fp l di"><div class="mc md l"/></div></figure><p id="9c9a" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我输入了他们已经在训练的算法，现在我该怎么办？有几个初步的步骤，我们将准备我们的图像语料库并重新设计算法，以便它将返回通过训练确定的高级特征。</p><h2 id="d437" class="me mf it bd mg mh mi dn mj mk ml dp mm kr mn mo mp kv mq mr ms kz mt mu mv mw bi translated">1.准备图片语料库</h2><p id="6b36" class="pw-post-body-paragraph ki kj it kk b kl mx ju kn ko my jx kq kr mz kt ku kv na kx ky kz nb lb lc ld im bi translated">我们有一份巴布亚新几内亚的清单:</p><ul class=""><li id="27b2" class="nc nd it kk b kl km ko kp kr ne kv nf kz ng ld nh ni nj nk bi translated">对于每个 png，我们将调整它的大小</li><li id="7550" class="nc nd it kk b kl nl ko nm kr nn kv no kz np ld nh ni nj nk bi translated">把它变成三维数组</li><li id="b366" class="nc nd it kk b kl nl ko nm kr nn kv no kz np ld nh ni nj nk bi translated">在 3D 数组列表上构建矩阵</li><li id="a72e" class="nc nd it kk b kl nl ko nm kr nn kv no kz np ld nh ni nj nk bi translated">用 Keras 内置函数对其进行预处理。</li></ul><h2 id="0c75" class="me mf it bd mg mh mi dn mj mk ml dp mm kr mn mo mp kv mq mr ms kz mt mu mv mw bi translated">2.准备算法</h2><ul class=""><li id="a402" class="nc nd it kk b kl mx ko my kr nq kv nr kz ns ld nh ni nj nk bi translated">为了预测最后一个要素而不是预测的 1000 个标注的最后一层，我们需要重新设计模型以移除预测层。</li></ul><p id="b631" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">首先，我们需要知道模型的输入是什么形状，并根据这个形状调整图像的大小。让我们用 VGG16 来做我们的预处理，它有如下结构。</p><figure class="lx ly lz ma gt mb gh gi paragraph-image"><div class="gh gi nt"><img src="../Images/9eaef824c2b7a453384a912fbbecb4fe.png" data-original-src="https://miro.medium.com/v2/resize:fit:988/format:webp/1*Wz_rBggMU2GDWYhI2v7MEw.png"/></div><figcaption class="nw nx gj gh gi ny nz bd b be z dk">VGG16 structure model</figcaption></figure><p id="87f4" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">由于我们看到输入层中的输入形状是(none，224，224，3)，我们将直接从模型中提取输入中请求的大小和宽度，这样我们就不必查看每个模型的摘要。</p><pre class="lx ly lz ma gt oa lh ob oc aw od bi"><span id="ba1e" class="me mf it lh b gy oe of l og oh">#with vgg model (or any model above)<br/>image_width = eval(str(vgg_model.layers[0].output.shape[1]))<br/>image_height = eval(str(vgg_model.layers[0].output.shape[2]))</span></pre><p id="42cb" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">注意:由于 self . model . layers[0]. output . shape[1]的输出是<strong class="kk iu"><em class="lm">tensor flow . python . framework . tensor _ shape。Dimension </em> </strong>对象，我将对其求值以获得整数。然后，我们加载和调整图像大小为一个<strong class="kk iu"> <em class="lm"> PIL。Image . Image</em>T10】</strong></p><pre class="lx ly lz ma gt oa lh ob oc aw od bi"><span id="a9d2" class="me mf it lh b gy oe of l og oh">pil_img = load_img('image.png',  target_size=(image_width, image_height))</span></pre><p id="79ca" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我们将它转换为 shape (224，224，3)数组，并使用额外的维度对其进行扩展，以适应算法所需的(none，224，224，3)输入形状。</p><pre class="lx ly lz ma gt oa lh ob oc aw od bi"><span id="25ec" class="me mf it lh b gy oe of l og oh">from keras.preprocessing.image import load_img,img_to_array</span><span id="e0ab" class="me mf it lh b gy oi of l og oh">array_img = img_to_array(pil_img)<br/>images = np.expand_dims(array_img, axis=0)</span></pre><p id="31ea" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我们可以对每个文件都这样做，然后把它变成一个矩阵。</p><figure class="lx ly lz ma gt mb"><div class="bz fp l di"><div class="mc md l"/></div></figure><p id="0493" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="kk iu">预处理 _ 输入</strong>减去数据的平均 RGB 通道。这是因为您正在使用的模型已经在不同的数据集上进行了训练:<code class="fe le lf lg lh b">image.shape</code>仍然是带有堆栈和预处理 _ 输入的<code class="fe le lf lg lh b">(1, 224, 224, 3)</code>，它变成了带有 n 个输入数(即图像数)的<code class="fe le lf lg lh b">(n, 224, 224, 3)</code>。</p><p id="1f94" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">现在我们的输入已经准备好了，可以放入算法中了。我们需要重新设计我们的模型，在新模型中加入预先训练的输入和输出的倒数第二层。</p><pre class="lx ly lz ma gt oa lh ob oc aw od bi"><span id="7c07" class="me mf it lh b gy oe of l og oh">from keras.models import Model</span><span id="3189" class="me mf it lh b gy oi of l og oh">feat_extract = Model(inputs=vgg_model.input,outputs=vgg_model.layers[-2].output)</span></pre><p id="a4c6" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">有了这个模型，我们就可以使用<strong class="kk iu">。预测方法</strong>得到的图像特征与第二层特征一样多(vgg_model 'fc2 层'为 4096)。</p><pre class="lx ly lz ma gt oa lh ob oc aw od bi"><span id="e172" class="me mf it lh b gy oe of l og oh">imgs_features = feat_extract.predict(dense_mat)</span></pre><p id="173f" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">现在，我们可以计算每个图像之间的余弦相似性，以获得索引和列中有 png 的(n*n)密集矩阵，然后我们可以提出一个或多个推荐。</p><pre class="lx ly lz ma gt oa lh ob oc aw od bi"><span id="146e" class="me mf it lh b gy oe of l og oh">cosSimilarities = cosine_similarity(imgs_features)</span><span id="9613" class="me mf it lh b gy oi of l og oh">cos_similarities_df = pd.DataFrame(cosSimilarities, columns=files, index=files)</span></pre><p id="2c2a" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">让我们将所有这些归纳起来，一次测试几个模型。</p><figure class="lx ly lz ma gt mb"><div class="bz fp l di"><div class="mc md l"/></div></figure><p id="fc25" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我们已经定义了一个通用类，它采用任何预训练模型，并相应地调整图像集，并针对给定的图像提出建议，让我们看看结果。</p><ul class=""><li id="bb35" class="nc nd it kk b kl km ko kp kr ne kv nf kz ng ld nh ni nj nk bi translated">MobileNetV2</li></ul><figure class="lx ly lz ma gt mb gh gi paragraph-image"><div role="button" tabindex="0" class="ok ol di om bf on"><div class="gh gi oj"><img src="../Images/c0c78f2ab2f509214f3882775be62c46.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*SDCWbeEMGwbIQBE56gDseQ.png"/></div></div></figure><figure class="lx ly lz ma gt mb gh gi paragraph-image"><div role="button" tabindex="0" class="ok ol di om bf on"><div class="gh gi oo"><img src="../Images/81e65b3181830e6b40dfffb9ef785efa.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*zAo_8sl2SIuUDTzqrBFy6A.png"/></div></div></figure><ul class=""><li id="c2bd" class="nc nd it kk b kl km ko kp kr ne kv nf kz ng ld nh ni nj nk bi translated">移动网络</li></ul><figure class="lx ly lz ma gt mb gh gi paragraph-image"><div role="button" tabindex="0" class="ok ol di om bf on"><div class="gh gi op"><img src="../Images/baaf0e3a4c97d5f3f6d0cb871c4c8792.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*VRZXgofND4Zh2lf9xjWIRQ.png"/></div></div></figure><figure class="lx ly lz ma gt mb gh gi paragraph-image"><div role="button" tabindex="0" class="ok ol di om bf on"><div class="gh gi oq"><img src="../Images/372015f353e04e338e92c693ef871cb2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*2DnAHh5K5AaiYSy0my4u6w.png"/></div></div></figure><ul class=""><li id="ed41" class="nc nd it kk b kl km ko kp kr ne kv nf kz ng ld nh ni nj nk bi translated">InceptionResNet</li></ul><figure class="lx ly lz ma gt mb gh gi paragraph-image"><div role="button" tabindex="0" class="ok ol di om bf on"><div class="gh gi or"><img src="../Images/63c242506c3396aad5c75f0bcca2e7a4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*0euXm3HuDX4_KY5jEVK1Hg.png"/></div></div></figure><figure class="lx ly lz ma gt mb gh gi paragraph-image"><div role="button" tabindex="0" class="ok ol di om bf on"><div class="gh gi os"><img src="../Images/51b74f758bc160d0003d83b42c548021.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*sXt9RJ_8ea9ikm1bbkixbQ.png"/></div></div></figure><ul class=""><li id="3470" class="nc nd it kk b kl km ko kp kr ne kv nf kz ng ld nh ni nj nk bi translated">VGG16</li></ul><figure class="lx ly lz ma gt mb gh gi paragraph-image"><div role="button" tabindex="0" class="ok ol di om bf on"><div class="gh gi ot"><img src="../Images/838c0f5e89818653c3debf3fa90a6268.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ZHkyX_-nu9QR25N_RSUehQ.png"/></div></div></figure><figure class="lx ly lz ma gt mb gh gi paragraph-image"><div role="button" tabindex="0" class="ok ol di om bf on"><div class="gh gi ot"><img src="../Images/f12a3f23c503b266fa05cf38c86d731f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*2MbPw9TzHKif2pox9jLgIg.png"/></div></div></figure><p id="c6b8" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">很酷不是吗！尽管我们使用了只有 2000 张图片的语料库，但我们有非常相关的推荐。</p><h1 id="bc50" class="ou mf it bd mg ov ow ox mj oy oz pa mm jz pb ka mp kc pc kd ms kf pd kg mv pe bi translated">最后</h1><p id="bd65" class="pw-post-body-paragraph ki kj it kk b kl mx ju kn ko my jx kq kr mz kt ku kv na kx ky kz nb lb lc ld im bi translated">我们已经看到了使用迁移学习的优势。为了有一个更准确的推荐系统，创建我们自己的卷积网络会更有意义，这将是下一篇文章的主题<strong class="kk iu">，保持联系！谢了。</strong></p><p id="2479" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">此处代码:<a class="ae li" href="https://github.com/AlexWarembourg/Medium/blob/master/product_recommendation.ipynb" rel="noopener ugc nofollow" target="_blank">https://github.com/AlexWarembourg/Medium/blob/master/</a>T19】product _ recommendation . ipynb</p></div></div>    
</body>
</html>