<html>
<head>
<title>The Importance of Ethics in Artificial Intelligence</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">伦理在人工智能中的重要性</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/the-importance-of-ethics-in-artificial-intelligence-16af073dedf8?source=collection_archive---------17-----------------------#2019-12-30">https://towardsdatascience.com/the-importance-of-ethics-in-artificial-intelligence-16af073dedf8?source=collection_archive---------17-----------------------#2019-12-30</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><figure class="is it gp gr iu iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi ir"><img src="../Images/51ca204b63b95ef1b8625240cb5518ce.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*zhr8diA5GGRB42-TeXtPsg.jpeg"/></div></div><figcaption class="jc jd gj gh gi je jf bd b be z dk">Photo by <a class="ae jg" href="https://www.pexels.com/nl-nl/@thisisengineering?utm_content=attributionCopyText&amp;utm_medium=referral&amp;utm_source=pexels" rel="noopener ugc nofollow" target="_blank">ThisIsEngineering</a> on <a class="ae jg" href="https://www.pexels.com/nl-nl/foto/code-geprojecteerd-op-vrouw-3861969/?utm_content=attributionCopyText&amp;utm_medium=referral&amp;utm_source=pexels" rel="noopener ugc nofollow" target="_blank">Pexels</a></figcaption></figure><div class=""/><div class=""><h2 id="2a7b" class="pw-subtitle-paragraph kg ji jj bd b kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx dk translated"><strong class="ak">(或任何其他形式的技术)</strong></h2></div><p id="a94e" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><em class="lu">“仅仅因为我们可以，并不意味着我们应该”可能是在谈到技术创新时要记住的事情。互联网的到来将创新的速度提高了 10 倍，让我们几乎可以创造任何我们能想到的东西。人工智能是一个很好的例子，在这个空间里，我们可以建造任何我们喜欢的东西，但我们应该这样做吗？</em></p><h1 id="6732" class="lv lw jj bd lx ly lz ma mb mc md me mf kp mg kq mh ks mi kt mj kv mk kw ml mm bi translated">和它的开发者一样道德</h1><blockquote class="mn mo mp"><p id="d178" class="ky kz lu la b lb lc kk ld le lf kn lg mq li lj lk mr lm ln lo ms lq lr ls lt im bi translated"><strong class="la jk">伦理(<em class="jj">名词</em> ): </strong> <em class="jj">管理一个人的行为或进行一项活动的道德原则。</em>(“许多科学家质疑残酷实验的伦理”<em class="jj"> ) </em></p></blockquote><p id="3434" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">我们人类有一种叫做“道德指南针”的东西。它是一种存在于我们大脑中的代理，基本上能辨别是非。当你看到不公正时，你的大脑会告诉你有些事情不对劲。由此而来的行动由你决定，但你可以分辨对错。你的道德标准很大程度上取决于你的教养和环境，但大多数人都有这样的标准。这也是公司建立道德和合规的基础，什么是对的，什么是错的，以及我们如何在此基础上制定规则。</p><p id="c4a7" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">人工智能缺乏这样的指南针。事实上，它没有任何指南针。人工智能只能根据贴有“正确”和“错误”标签的数据来区分对错。人工智能没有自我意识，也没有所谓的“同理心”，这是伦理学的基础。当谈论人工智能时，唯一的道德指南针是它的开发者，他们为什么是对什么是错设置了标准。如果开发者的道德罗盘很低，他/她可能会怀着不良意图开发 AI，反之亦然。这并不意味着人工智能实际上会一直遵循这些标准，因为<a class="ae jg" href="https://medium.com/@ferryhoes/a-i-isnt-the-all-knowing-superbrain-you-think-it-is-75328746cfcc" rel="noopener">人工智能不是被编码的，而是被训练的</a>。这意味着它可能是善意的，但仍然像人们希望的那样，起草成道德上不那么认可或“为好”的东西。</p><h1 id="2be6" class="lv lw jj bd lx ly lz ma mb mc md me mf kp mg kq mh ks mi kt mj kv mk kw ml mm bi translated">那么，为什么技术中的伦理如此重要呢？</h1><p id="8c57" class="pw-post-body-paragraph ky kz jj la b lb mt kk ld le mu kn lg lh mv lj lk ll mw ln lo lp mx lr ls lt im bi translated">嗯，如果我们不基于道德来构建技术，并确保我们了解我们实现的每个算法的结果，我们就有可能不道德。因此，我不是说“吃饭时使用刀叉”是道德的。我的意思是——不是种族主义或牵连无辜的人——道德。听起来很重？我们已经有<a class="ae jg" href="https://www.bbc.com/news/technology-49717378" rel="noopener ugc nofollow" target="_blank">有偏见的数据</a>导致潜在的种族主义决策的例子。</p><p id="f5e9" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">或者更糟，那次脸书开发了两个会说话的人工智能机器人。他们用英语交谈了一会儿，然后构建了他们自己的语言，开发者无法理解。这是不道德的吗？从人类无法监控正在发生的事情的意义上来说，这些对话的结果(或内容)很可能是不道德的。</p><blockquote class="mn mo mp"><p id="cef7" class="ky kz lu la b lb lc kk ld le lf kn lg mq li lj lk mr lm ln lo ms lq lr ls lt im bi translated">人工智能没有自我意识，也没有所谓的“同理心”，这是伦理学的基础。</p></blockquote><h1 id="36a3" class="lv lw jj bd lx ly lz ma mb mc md me mf kp mg kq mh ks mi kt mj kv mk kw ml mm bi translated">控制行为</h1><p id="1d2a" class="pw-post-body-paragraph ky kz jj la b lb mt kk ld le mu kn lg lh mv lj lk ll mw ln lo lp mx lr ls lt im bi translated">让我们再一次抓住伦理的定义:“伦理是支配一个人行为的道德原则”。如果我们不能控制我们建造的东西的行为，我们怎么能检查它的伦理呢？我们需要永远(永远永远)成为决定人工智能行为的人。当然，对于像“自我学习”这样的选项，我们不想减慢它的发展过程，因为那样会违背它的整个目的。这最终意味着两件事:</p><ol class=""><li id="eff6" class="my mz jj la b lb lc le lf lh na ll nb lp nc lt nd ne nf ng bi translated"><em class="lu">我们需要将伦理道德融入为什么开发某种配备人工智能的技术的想法中</em></li><li id="e063" class="my mz jj la b lb nh le ni lh nj ll nk lp nl lt nd ne nf ng bi translated"><em class="lu">我们需要监控/检查/监管特定技术的结果，以便充分理解它的行为，并确保它不违反我们(人类)的道德准则。</em></li></ol><p id="bea2" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">因此，伦理不仅在技术领域(尤其是人工智能领域)很重要，而且应该是任何创新的基础。我们不能冒构建不道德工具的风险。因此，如果某件事为了创新或经济利益而冒不道德的风险，我们应该想到:</p><blockquote class="mn mo mp"><p id="ddda" class="ky kz lu la b lb lc kk ld le lf kn lg mq li lj lk mr lm ln lo ms lq lr ls lt im bi translated">“仅仅因为我们可以，并不意味着我们应该”</p></blockquote><p id="b177" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">以上是技术应该如何帮助我们，而不是与我们作对的基础。如果你想更多地了解这种不可避免的未来方式或工作方式，请查看以下网站的研究:<a class="ae jg" href="https://brandhumanizing.com/research/brand-humanizing-an-inevitable-and-humane-turn-on-business-in-an-increasingly-robotic-world/" rel="noopener ugc nofollow" target="_blank">https://brand humanizing . com/research/brand-humanizing-an-accessible-and-humanized-on-business-in-a-incremented-robotic-world/</a></p></div></div>    
</body>
</html>