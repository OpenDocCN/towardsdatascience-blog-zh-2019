<html>
<head>
<title>Predicting bankruptcy using Machine Learning</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用机器学习预测破产</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/predicting-bankruptcy-f4611afe8d2c?source=collection_archive---------18-----------------------#2019-02-11">https://towardsdatascience.com/predicting-bankruptcy-f4611afe8d2c?source=collection_archive---------18-----------------------#2019-02-11</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><p id="2f21" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">维克拉姆·迪瓦塔&amp;迪瓦希什·迪曼</p><p id="fdd1" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">2008 年的经济危机引发了一场关于市场可持续性以及可用于预测市场可持续性的工具的讨论。为了避免未来发生这样的灾难性事件，对更好的预测模型的需求变得显而易见。公司和企业的破产在多个方面影响金融市场，因此通过监控多个变量来预测公司破产的需求变得更加重要。更好地理解破产和预测破产的能力将会影响全球贷款机构的盈利能力</p><p id="9b17" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">作为一项分类工作，数据分析师有太多的选择。著名统计学家乔治·博克斯(George Box)曾经说过，“<em class="kl">所有的模型都是错的，但有些是有用的</em>”(维基百科，自由百科，2019)。考虑到这一点，我们承担了构建不同的监督机器学习算法的任务，并对每个模型进行了比较分析，以确定哪些模型更适合预测经济破产</p><p id="a7a5" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我们遵循的分析流程概述如下:</p><figure class="kn ko kp kq gt kr gh gi paragraph-image"><div class="gh gi km"><img src="../Images/bee47920866b41d20ff6534147496f5a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1322/format:webp/1*zoVEO0sfZL0mqWc0B9VDJA.png"/></div></figure><h2 id="3963" class="ku kv iq bd kw kx ky dn kz la lb dp lc jy ld le lf kc lg lh li kg lj lk ll lm bi translated">关于数据集</h2><p id="acd9" class="pw-post-body-paragraph jn jo iq jp b jq ln js jt ju lo jw jx jy lp ka kb kc lq ke kf kg lr ki kj kk ij bi translated">本次练习使用的数据集是波兰公司在 5 年研究期内的破产状况，可从这里下载:【https://goo.gl/e2Px2y<a class="ae ls" href="https://goo.gl/e2Px2y" rel="noopener ugc nofollow" target="_blank"/>。它包含 43405 个观察值，分布在 5 个子集(每年一个)，每个观察值有 64 个财务比率。这里有一个<a class="ae ls" href="https://archive.ics.uci.edu/ml/datasets/Polish+companies+bankruptcy+data" rel="noopener ugc nofollow" target="_blank"> URL </a>，其中提供了属性的名称(感谢 Harsha Danda 找到了这个链接)。一些公司在研究期间破产(用“1”表示)，而其他公司幸存下来(用“0”表示)。研究期间每年的总结如下。</p><figure class="kn ko kp kq gt kr gh gi paragraph-image"><div role="button" tabindex="0" class="lu lv di lw bf lx"><div class="gh gi lt"><img src="../Images/552b95837436190d85d5f2a6892c9f72.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*NGgADa3fJ3I67zN_AyV8Vg.png"/></div></div></figure><h2 id="b8c9" class="ku kv iq bd kw kx ky dn kz la lb dp lc jy ld le lf kc lg lh li kg lj lk ll lm bi translated">性能指标</h2><p id="d104" class="pw-post-body-paragraph jn jo iq jp b jq ln js jt ju lo jw jx jy lp ka kb kc lq ke kf kg lr ki kj kk ij bi translated">经过适当的输入和预处理后，数据以 70:30 的比例分成训练数据集和测试数据集。分类器建立在训练数据上，并且它们的性能使用训练和测试数据集的混淆矩阵来测量，如下所示:</p><figure class="kn ko kp kq gt kr gh gi paragraph-image"><div class="gh gi ly"><img src="../Images/8d255ed626edef15cf9d89231ed19821.png" data-original-src="https://miro.medium.com/v2/resize:fit:860/format:webp/1*7EcPtd8DXu1ObPnZSukIdQ.png"/></div></figure><p id="a0e2" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">其中 TP =真阳性的数量，<br/> TN =真阴性的数量，<br/> FP =假阳性的数量，<br/> FN =假阴性的数量。</p><p id="c072" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">这些可用于计算以下指标:</p><p id="bbc5" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">观察次数，n = TN+FP+FN+TP <br/>错误数= FP+FN <br/>错误分类(错误率)= FP+FN / n <br/>敏感度(真阳性)= TP / FN+TP <br/>假阳性= FP / TN+FP <br/>特异性(真阴性)= TN / TN+FP <br/>精度= TP / FP+TP <br/>患病率= FN+TP / n <br/>准确度= TN+TP</p><p id="bced" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">由于我们感兴趣的是将公司分类为可能破产(或不破产)，上述比率可以解释如下:</p><p id="46bc" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">错误分类(错误率):分类器出错的频率有多高？<br/>敏感性(真阳性):当一家公司实际上“破产”时，分类器正确预测结果的频率是多少？<br/>误报:当一家公司实际上“没有 _ 破产”时，分类器出错的频率是多少？<br/>特异性(真阴性):假设一家公司“没有破产”，那么分类器有多准确？<br/>精度:当分类器预测“破产”时，它的正确率是多少？<br/>普遍性:数据集中“破产”实际上发生的频率有多高？<br/>准确性:总体而言，分类器正确的频率如何？</p><h2 id="4655" class="ku kv iq bd kw kx ky dn kz la lb dp lc jy ld le lf kc lg lh li kg lj lk ll lm bi translated">构建模型</h2><p id="2d48" class="pw-post-body-paragraph jn jo iq jp b jq ln js jt ju lo jw jx jy lp ka kb kc lq ke kf kg lr ki kj kk ij bi translated">使用 R 和 Python 为这个练习构建了不同的机器学习算法。可以在这里找到运行代码的视频:<a class="ae ls" href="https://youtu.be/OWbuOza_Gao" rel="noopener ugc nofollow" target="_blank">https://youtu.be/OWbuOza_Gao</a></p><p id="db5f" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">逻辑回归<br/>感知器作为分类器<br/>深度神经网络分类器(具有不同的大小和深度)<br/> Fischer 线性判别分析<br/> K 最近邻分类器(具有不同的 K 值)<br/>朴素贝叶斯分类器<br/>决策树(具有不同的桶大小阈值)<br/>袋装决策树<br/>随机森林(具有不同的树大小)<br/>梯度推进<br/>支持向量机(具有不同的核)</p><p id="410c" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">有些算法是用不同的初始化构建的，为了找到最佳的初始化，记录了每种算法的性能。例如，对于 K-最近邻，尝试了从 1 到 19 的不同 K 值。下面以从红到绿的颜色编码显示了每个人的表现，红色表示“差”，绿色表示“好”:</p><figure class="kn ko kp kq gt kr gh gi paragraph-image"><div role="button" tabindex="0" class="lu lv di lw bf lx"><div class="gh gi lz"><img src="../Images/4f3a886475c452403eca2d4ce3209e17.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*hbqIxg6dmI3XHpohz-Sh-Q.png"/></div></div></figure><p id="a791" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我们看到，随着 k 的增加，错误率(以及准确性)降低，然后又开始增加。灵敏度随着 k 的增加而增加，而特异性随着 k 的增加而降低。</p><p id="a720" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">类似地，我们为随机森林尝试了不同数量的树，范围从 50–500，跳跃 50:</p><figure class="kn ko kp kq gt kr gh gi paragraph-image"><div class="gh gi ma"><img src="../Images/e00d56d94dfaf0519917e24377dd13f6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1380/format:webp/1*Iur5EY30AG1xZ-Z8tVBL9g.png"/></div></figure><p id="056c" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">该模型在有 200 棵树的情况下表现最佳。</p><h2 id="bd86" class="ku kv iq bd kw kx ky dn kz la lb dp lc jy ld le lf kc lg lh li kg lj lk ll lm bi translated">模型比较</h2><p id="d757" class="pw-post-body-paragraph jn jo iq jp b jq ln js jt ju lo jw jx jy lp ka kb kc lq ke kf kg lr ki kj kk ij bi translated">我们制作了一个所有模型的对比图。基于所使用的超参数以及为测量性能而选择的度量标准，可以看出这些模型表现不同。下面给出了关于训练数据的度量的概述。</p><figure class="kn ko kp kq gt kr gh gi paragraph-image"><div role="button" tabindex="0" class="lu lv di lw bf lx"><div class="gh gi mb"><img src="../Images/4766702962f91b12320820d4e43c2f81.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*5MKNha-LYBPEA9DpHPlixQ.png"/></div></div></figure><figure class="kn ko kp kq gt kr gh gi paragraph-image"><div role="button" tabindex="0" class="lu lv di lw bf lx"><div class="gh gi mc"><img src="../Images/b46a9689264476021629a6aa138bbc49.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*f9XtoZT-1INrxBbbbzXXqQ.png"/></div></div></figure><p id="9a60" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">测试数据的指标概述如下:</p><figure class="kn ko kp kq gt kr gh gi paragraph-image"><div role="button" tabindex="0" class="lu lv di lw bf lx"><div class="gh gi mb"><img src="../Images/21de37aceff9deb457cb5d933d9ff379.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*oKGt_doDslbkhY0NEblMWA.png"/></div></div></figure><figure class="kn ko kp kq gt kr gh gi paragraph-image"><div role="button" tabindex="0" class="lu lv di lw bf lx"><div class="gh gi mc"><img src="../Images/4a3f03f1a9c74199f2ba46de308d0a28.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*1DWZnEuxPlQIpOxFh9BMNg.png"/></div></div></figure><h2 id="dd95" class="ku kv iq bd kw kx ky dn kz la lb dp lc jy ld le lf kc lg lh li kg lj lk ll lm bi translated">一些发现</h2><p id="5480" class="pw-post-body-paragraph jn jo iq jp b jq ln js jt ju lo jw jx jy lp ka kb kc lq ke kf kg lr ki kj kk ij bi translated">数据集有大量的“0”(没有破产的公司)，很少的“1”(破产的公司)。因此，大多数模型给出了很高的精确度，但是在预测“1”时表现很差。由于任务是预测破产，我们认为我们必须把重点放在敏感性(真正的积极)作为比较模型的相关措施。</p><p id="8f53" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我们发现，集成模型如梯度推进和袋装决策树在训练和测试数据集上表现最好，甚至优于神经网络算法。他们的计算速度也很快，只需几分钟就能完成训练并得分。表现最差的模型是朴素贝叶斯模型，它导致了大量的错误和较差的敏感性得分。</p><h2 id="1eef" class="ku kv iq bd kw kx ky dn kz la lb dp lc jy ld le lf kc lg lh li kg lj lk ll lm bi translated">后续步骤</h2><p id="8bd1" class="pw-post-body-paragraph jn jo iq jp b jq ln js jt ju lo jw jx jy lp ka kb kc lq ke kf kg lr ki kj kk ij bi translated">合理的下一步是探索为什么朴素贝叶斯表现如此之差，以及不同的打包和提升模型以进一步提高模型的性能。可以考虑的另一种方法是仅对前 30 个主要成分运行上述模型，因为它们可以解释 97%以上的数据变化，如下所示。</p><figure class="kn ko kp kq gt kr gh gi paragraph-image"><div class="gh gi md"><img src="../Images/5235cff946765eee402871949c78bd39.png" data-original-src="https://miro.medium.com/v2/resize:fit:782/format:webp/1*YkQDpRDb0IjDsuSk3BfPqg.png"/></div></figure><p id="5e3b" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">如果您在电脑上试用了这些模型，请与我们分享您的结果！你可以在 LinkedIn 上找到我们。</p><figure class="kn ko kp kq gt kr gh gi paragraph-image"><div role="button" tabindex="0" class="lu lv di lw bf lx"><div class="gh gi me"><img src="../Images/9108b558f038224c6c13738168f46096.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Z-wrekgFWJcoee05G73pcQ.jpeg"/></div></div><figcaption class="mf mg gj gh gi mh mi bd b be z dk">Photo by <a class="ae ls" href="https://www.pexels.com/@karoldach?utm_content=attributionCopyText&amp;utm_medium=referral&amp;utm_source=pexels" rel="noopener ugc nofollow" target="_blank">Karol D</a> from <a class="ae ls" href="https://www.pexels.com/photo/close-up-of-coins-on-table-325154/?utm_content=attributionCopyText&amp;utm_medium=referral&amp;utm_source=pexels" rel="noopener ugc nofollow" target="_blank">Pexels</a></figcaption></figure><h2 id="002c" class="ku kv iq bd kw kx ky dn kz la lb dp lc jy ld le lf kc lg lh li kg lj lk ll lm bi translated">参考</h2><p id="1cc5" class="pw-post-body-paragraph jn jo iq jp b jq ln js jt ju lo jw jx jy lp ka kb kc lq ke kf kg lr ki kj kk ij bi translated">英国马卡姆(2014 年 3 月 25 日)。<em class="kl">混淆矩阵术语简单指南</em>。检索 2019 年 2 月 7 日，来自数据学校:<a class="ae ls" href="https://www.dataschool.io/simple-guide-to-confusion-matrix-terminology/" rel="noopener ugc nofollow" target="_blank">https://www . Data School . io/simple-guide-to-focus-matrix-terminals/</a></p><p id="62f8" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">Géron，A. (2019，1 1)。<em class="kl">第一章。人工神经网络导论</em>。检索 26 2019，来自神经网络与深度学习:<a class="ae ls" href="https://www.oreilly.com/library/view/neural-networks-and/9781492037354/ch01.html" rel="noopener ugc nofollow" target="_blank">https://www . oreilly . com/library/view/Neural-networks-and/9781492037354/ch01 . html</a></p><p id="c4e7" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">扁平图标。(2019, 1 1).<em class="kl">每月一包</em>。检索到 2019 年 2 月 7 日，来自平面图标:<a class="ae ls" href="https://www.flaticon.com" rel="noopener ugc nofollow" target="_blank">https://www.flaticon.com</a></p><p id="d7c7" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">未知。(-, — -).<em class="kl">算法特点</em>。检索 22019 年 6 月，来自 r studio PUBS:<a class="ae ls" href="http://rstudio-pubs-static.s3.amazonaws.com/4239_fcb292ade17648b097a9806fbe026e74.html" rel="noopener ugc nofollow" target="_blank">http://r studio-pubs-static . S3 . amazonaws . com/4239 _ fcb 292 ade 17648 b 097 a 9806 FBE 026 e 74 . html</a></p><p id="a6c3" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">郭，法律顾问(未注明)。<em class="kl">基于 Yelp 数据集预测餐厅的评分和受欢迎程度。</em>斯坦福大学经济系 CS 229 机器学习期末项目。</p><p id="3005" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">马切伊·zięba，S. K. (2016)。<em class="kl">集成提升树与合成特征生成在破产预测中的应用。</em>弗罗茨瓦夫科技大学，计算机科学系，运筹学系，计算机科学与管理学院，弗罗茨瓦夫。</p><p id="c42c" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">维基百科，免费的百科全书。(2019, 2 5).<em class="kl">所有型号都是错的</em>。(T. F. Wikipedia，制作人)检索 2019 年 7 月 2 日，来自维基百科，免费百科:【https://en.wikipedia.org/wiki/All_models_are_wrongT2</p></div></div>    
</body>
</html>