<html>
<head>
<title>How I used transfer learning and ensemble learning to get 90% accuracy in Kaggle competition</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">我如何使用迁移学习和集成学习在 Kaggle 竞赛中获得 90%的准确率</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/how-i-used-transfer-learning-and-ensemble-learning-to-get-90-accuracy-in-kaggle-competition-5a5e4c7e63e?source=collection_archive---------11-----------------------#2019-12-15">https://towardsdatascience.com/how-i-used-transfer-learning-and-ensemble-learning-to-get-90-accuracy-in-kaggle-competition-5a5e4c7e63e?source=collection_archive---------11-----------------------#2019-12-15</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="2c8f" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">图像分类是一项经典的机器学习任务，自深度神经网络诞生以来，它一直是机器学习研究的关键驱动因素。本文将指导您使用迁移学习和集成方法轻松解决这个问题。</h2></div><figure class="kh ki kj kk gt kl gh gi paragraph-image"><div role="button" tabindex="0" class="km kn di ko bf kp"><div class="gh gi kg"><img src="../Images/11ee1bfcded60f97e740adbe73b6dd95.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ZI0LIunbOr-_8sfsJiPq_Q.jpeg"/></div></div><figcaption class="ks kt gj gh gi ku kv bd b be z dk">Photo by <a class="ae kw" href="https://unsplash.com/@blakeconnally?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank">Blake Connally</a> on <a class="ae kw" href="https://unsplash.com/s/photos/code?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure></div><div class="ab cl kx ky hu kz" role="separator"><span class="la bw bk lb lc ld"/><span class="la bw bk lb lc ld"/><span class="la bw bk lb lc"/></div><div class="ij ik il im in"><h1 id="05b6" class="le lf iq bd lg lh li lj lk ll lm ln lo jw lp jx lq jz lr ka ls kc lt kd lu lv bi translated">1.介绍</h1><p id="1090" class="pw-post-body-paragraph lw lx iq ly b lz ma jr mb mc md ju me mf mg mh mi mj mk ml mm mn mo mp mq mr ij bi translated">在这个比赛中，我要对不同车辆类型的图像进行分类，包括汽车、自行车、货车、救护车等。(共 17 类)。竞赛的数据包括带有类别标签的训练数据和不带标签的测试数据。任务是预测测试数据的秘密标签。你可以在这里找到并下载数据集<a class="ae kw" href="https://www.kaggle.com/c/vehicle/data" rel="noopener ugc nofollow" target="_blank"/>。</p><h1 id="34a1" class="le lf iq bd lg lh ms lj lk ll mt ln lo jw mu jx lq jz mv ka ls kc mw kd lu lv bi translated">2.迁移学习</h1><blockquote class="mx"><p id="fd48" class="my mz iq bd na nb nc nd ne nf ng mr dk translated">迁移学习是机器学习中的一个研究问题，它专注于存储在解决一个问题时获得的知识，并将其应用于不同但相关的问题。[1]</p></blockquote><p id="bf49" class="pw-post-body-paragraph lw lx iq ly b lz nh jr mb mc ni ju me mf nj mh mi mj nk ml mm mn nl mp mq mr ij bi translated">在<strong class="ly ir">计算机视觉</strong>中，迁移学习通常用预先训练好的模型来表示。预训练模型是由其他人创建的用于解决类似问题的模型。可以使用预先训练的模型作为起点，而不是从头开始构建模型。我在比赛中选择使用的型号有<a class="ae kw" href="https://keras.io/applications/#inceptionv3" rel="noopener ugc nofollow" target="_blank"> InceptionV3 </a>、<a class="ae kw" href="https://keras.io/applications/#mobilenetv2" rel="noopener ugc nofollow" target="_blank"> MobilenetV2、</a>和<a class="ae kw" href="https://keras.io/applications/#densenet" rel="noopener ugc nofollow" target="_blank"> Densenet201 </a>。</p><h1 id="5041" class="le lf iq bd lg lh ms lj lk ll mt ln lo jw mu jx lq jz mv ka ls kc mw kd lu lv bi translated">3.预训练模型</h1><p id="ba13" class="pw-post-body-paragraph lw lx iq ly b lz ma jr mb mc md ju me mf mg mh mi mj mk ml mm mn mo mp mq mr ij bi translated">这是一个如何将预训练模型应用于您的问题的示例。</p><figure class="kh ki kj kk gt kl"><div class="bz fp l di"><div class="nm nn l"/></div></figure><p id="d87e" class="pw-post-body-paragraph lw lx iq ly b lz no jr mb mc np ju me mf nq mh mi mj nr ml mm mn ns mp mq mr ij bi translated">一些注意事项:</p><ul class=""><li id="a05a" class="nt nu iq ly b lz no mc np mf nv mj nw mn nx mr ny nz oa ob bi translated"><em class="oc"> Include-top </em>:是否包含网络顶部的全连通层。您应该在这里设置<em class="oc"> False </em>来自己修改网络。</li><li id="3781" class="nt nu iq ly b lz od mc oe mf of mj og mn oh mr ny nz oa ob bi translated"><em class="oc">globalaveragepool2d:在空间维度上应用</em>平均池。这里，我在基本模型的最后一个输出层应用了平均池操作。</li><li id="dffb" class="nt nu iq ly b lz od mc oe mf of mj og mn oh mr ny nz oa ob bi translated"><em class="oc">类别交叉熵损失:</em>用于单标签分类的损失函数。一个图像只能属于一个类。</li><li id="e1af" class="nt nu iq ly b lz od mc oe mf of mj og mn oh mr ny nz oa ob bi translated"><em class="oc">Adel ta optimizer:</em>Adagrad 的一个更健壮的扩展，它基于梯度更新的移动窗口来调整学习速率，而不是累积所有过去的梯度。</li><li id="913e" class="nt nu iq ly b lz od mc oe mf of mj og mn oh mr ny nz oa ob bi translated"><em class="oc"> Model.summary: </em>获取模型的摘要</li></ul><p id="b0cb" class="pw-post-body-paragraph lw lx iq ly b lz no jr mb mc np ju me mf nq mh mi mj nr ml mm mn ns mp mq mr ij bi translated">您也可以对其他模型使用相同的代码概念。在比赛中，我只对其他车型做了小调整。(InceptionV3 和 Densenet201)。</p><h1 id="b814" class="le lf iq bd lg lh ms lj lk ll mt ln lo jw mu jx lq jz mv ka ls kc mw kd lu lv bi translated">4.准备数据</h1><p id="56c2" class="pw-post-body-paragraph lw lx iq ly b lz ma jr mb mc md ju me mf mg mh mi mj mk ml mm mn mo mp mq mr ij bi translated">我们必须将训练数据分成两个文件夹:训练和测试。每个文件夹包含以类别命名的子文件夹，每个子文件夹包含属于该类别的图像。</p><p id="8db1" class="pw-post-body-paragraph lw lx iq ly b lz no jr mb mc np ju me mf nq mh mi mj nr ml mm mn ns mp mq mr ij bi translated">以下是如何做到这一点的示例:</p><figure class="kh ki kj kk gt kl"><div class="bz fp l di"><div class="nm nn l"/></div></figure><p id="ba25" class="pw-post-body-paragraph lw lx iq ly b lz no jr mb mc np ju me mf nq mh mi mj nr ml mm mn ns mp mq mr ij bi translated">之后，为了增加数据量并避免过度拟合，我使用 ImageDataGenerator 对训练数据进行了扩充。它将获取原始图像，对其进行随机转换，并返回新的随机转换图像。然后，我为 fit_generator 函数(稍后使用)创建了训练和测试生成器，以便在训练期间动态生成数据。</p><figure class="kh ki kj kk gt kl"><div class="bz fp l di"><div class="nm nn l"/></div></figure><h1 id="abbd" class="le lf iq bd lg lh ms lj lk ll mt ln lo jw mu jx lq jz mv ka ls kc mw kd lu lv bi translated">5.培养</h1><p id="c202" class="pw-post-body-paragraph lw lx iq ly b lz ma jr mb mc md ju me mf mg mh mi mj mk ml mm mn mo mp mq mr ij bi translated">在 Keras 中，使用<em class="oc"> fit() </em>对于可以加载到内存中的较小数据集来说很好。但是在这里，我们的数据集太大了，所以使用<em class="oc"> fit() </em>是不实际的。解决方法是使用<em class="oc"> fit_generator() </em>，它可以在训练期间将图像加载到内存中。</p><figure class="kh ki kj kk gt kl"><div class="bz fp l di"><div class="nm nn l"/></div></figure><p id="3e5d" class="pw-post-body-paragraph lw lx iq ly b lz no jr mb mc np ju me mf nq mh mi mj nr ml mm mn ns mp mq mr ij bi translated">一些注意事项:</p><ul class=""><li id="32ec" class="nt nu iq ly b lz no mc np mf nv mj nw mn nx mr ny nz oa ob bi translated">根据您电脑的内存，您可能想要更改批处理大小。</li><li id="7c05" class="nt nu iq ly b lz od mc oe mf of mj og mn oh mr ny nz oa ob bi translated">您可能还希望在培训中添加检查点以进行备份，以防培训过程出现问题。</li></ul><p id="b0ef" class="pw-post-body-paragraph lw lx iq ly b lz no jr mb mc np ju me mf nq mh mi mj nr ml mm mn ns mp mq mr ij bi translated">在训练每个模型大约 80 个时期后，下面是每个模型的准确度分数:</p><ul class=""><li id="50c6" class="nt nu iq ly b lz no mc np mf nv mj nw mn nx mr ny nz oa ob bi translated">InceptionV3:训练准确率:93.76 %，验证准确率:92.30 %，Kaggle 评分:89.2%</li><li id="fbef" class="nt nu iq ly b lz od mc oe mf of mj og mn oh mr ny nz oa ob bi translated">MobilenetV2:训练准确率:88.25 %，验证准确率:92.30 %，Kaggle 评分:85.6%</li><li id="48cd" class="nt nu iq ly b lz od mc oe mf of mj og mn oh mr ny nz oa ob bi translated">Densenet201:训练准确率:92.3 %，验证准确率:90.3 %</li></ul><h1 id="d960" class="le lf iq bd lg lh ms lj lk ll mt ln lo jw mu jx lq jz mv ka ls kc mw kd lu lv bi translated">6.集成学习</h1><p id="9ba4" class="pw-post-body-paragraph lw lx iq ly b lz ma jr mb mc md ju me mf mg mh mi mj mk ml mm mn mo mp mq mr ij bi translated">集成学习是训练多个模型而不是单个模型，并组合来自这些模型的预测。这减少了预测的方差并减少了泛化错误。结果是预测这比任何单一的模型都要好。[2]想要更多的动力，你可以看看<a class="ae kw" href="http://www.image-net.org/challenges/LSVRC/2015/results" rel="noopener ugc nofollow" target="_blank"> ILSVRC2015 </a>的结果，看到比赛的 12 强使用了多种模式的组合，而不是只有一种。</p><p id="a303" class="pw-post-body-paragraph lw lx iq ly b lz no jr mb mc np ju me mf nq mh mi mj nr ml mm mn ns mp mq mr ij bi translated">如何实现集成学习:</p><figure class="kh ki kj kk gt kl"><div class="bz fp l di"><div class="nm nn l"/></div></figure><p id="480b" class="pw-post-body-paragraph lw lx iq ly b lz no jr mb mc np ju me mf nq mh mi mj nr ml mm mn ns mp mq mr ij bi translated"><strong class="ly ir">集成学习结果:</strong> 91.1% <em class="oc"> </em> Kaggle 评分。</p><p id="8370" class="pw-post-body-paragraph lw lx iq ly b lz no jr mb mc np ju me mf nq mh mi mj nr ml mm mn ns mp mq mr ij bi translated">以下是一些<strong class="ly ir">预测图像</strong>:</p><figure class="kh ki kj kk gt kl gh gi paragraph-image"><div class="gh gi oi"><img src="../Images/89408d12a686718fe539167e0dcc62fd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1286/format:webp/1*_XgDXIpl8mkYob4ylJST4A.png"/></div><figcaption class="ks kt gj gh gi ku kv bd b be z dk">Truck image</figcaption></figure><figure class="kh ki kj kk gt kl gh gi paragraph-image"><div class="gh gi oj"><img src="../Images/faf66440e558120d06f75ab16ed97f46.png" data-original-src="https://miro.medium.com/v2/resize:fit:1274/format:webp/1*oTYgP1DneyiRKpsSL9nvzg.png"/></div><figcaption class="ks kt gj gh gi ku kv bd b be z dk">Tank image</figcaption></figure><h1 id="709a" class="le lf iq bd lg lh ms lj lk ll mt ln lo jw mu jx lq jz mv ka ls kc mw kd lu lv bi translated">7.摘要</h1><p id="0cf1" class="pw-post-body-paragraph lw lx iq ly b lz ma jr mb mc md ju me mf mg mh mi mj mk ml mm mn mo mp mq mr ij bi translated">要找到我在这个项目中使用的完整代码，你可以去这个<a class="ae kw" href="https://github.com/hoanhle/Vehicle-Type-Detection" rel="noopener ugc nofollow" target="_blank">链接</a>。</p><p id="f58e" class="pw-post-body-paragraph lw lx iq ly b lz no jr mb mc np ju me mf nq mh mi mj nr ml mm mn ns mp mq mr ij bi translated">我希望你在这篇文章中找到一些有用的东西，可以用在你的深度学习和计算机视觉项目中。这是一个有趣和令人兴奋的领域，每个人每天都在尝试新的想法和技术。</p><p id="79c1" class="pw-post-body-paragraph lw lx iq ly b lz no jr mb mc np ju me mf nq mh mi mj nr ml mm mn ns mp mq mr ij bi translated">我很乐意帮助你，所以如果你有任何问题或改进的想法，请告诉我。</p><h1 id="69ed" class="le lf iq bd lg lh ms lj lk ll mt ln lo jw mu jx lq jz mv ka ls kc mw kd lu lv bi translated">8.参考</h1><ol class=""><li id="2684" class="nt nu iq ly b lz ma mc md mf ok mj ol mn om mr on nz oa ob bi translated">韦斯特，杰里米；文图拉，丹；肖恩·沃尼克(2007 年)。<a class="ae kw" href="https://web.archive.org/web/20070801120743/http://cpms.byu.edu/springresearch/abstract-entry?id=861" rel="noopener ugc nofollow" target="_blank">“春季研究报告:归纳转移的理论基础”</a>。杨百翰大学物理和数学科学学院</li><li id="fc9d" class="nt nu iq ly b lz od mc oe mf of mj og mn oh mr on nz oa ob bi translated"><a class="ae kw" href="https://machinelearningmastery.com/ensemble-methods-for-deep-learning-neural-networks/" rel="noopener ugc nofollow" target="_blank">https://machine learning mastery . com/ensemble-methods-for-deep-learning-neural-networks/</a></li></ol></div></div>    
</body>
</html>