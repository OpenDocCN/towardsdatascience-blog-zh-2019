<html>
<head>
<title>Normality testing: The graphical way</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">正态性检验:图解方法</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/normality-testing-the-graphical-way-20902abd8543?source=collection_archive---------32-----------------------#2019-11-19">https://towardsdatascience.com/normality-testing-the-graphical-way-20902abd8543?source=collection_archive---------32-----------------------#2019-11-19</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><p id="cacb" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><em class="ko">下面的要点提供了全部代码</em></p><p id="6e0c" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">在处理回归问题时，有一些特定的假设是适用的。以线性回归为例，我们有以下假设-</p><p id="74cc" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">1)我们在自变量和目标变量之间有一个线性关系。<br/> 2)我们的数据是同方差的<br/> 3)残差具有正态分布<br/> 4)最小多重共线性</p><p id="8f55" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">本笔记的主题是第三点:我们如何知道线性回归模型的残差是正态分布的？这就引出了一个更普遍的问题。给定一个数据集，我们能说数据是正态分布的吗？这似乎是一个相当小的问题，只需绘制数据的直方图，看看它是否像正态分布。直方图可能具有欺骗性，它取决于您选择的箱数，而箱数又取决于可用数据点的数量。</p><p id="bf7d" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">幸运的是，我们可以使用某些工具来确定一个数据集是否来自正态分布。</p><p id="30f6" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">在这本笔记本中，我们将介绍两种图形工具:<br/> 1)图形方式:直方图<br/> 2)图形方式:分位数-分位数(qq)图</p><p id="6d81" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">用于确定数据是否来自正态分布的检验称为正态性检验。</p><p id="bd1d" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">在我们进入之前，让我们设置一个问题。我们生成一个数据集并建立一个线性回归问题。我们给它拟合一个模型，得到残差。</p><pre class="kp kq kr ks gt kt ku kv kw aw kx bi"><span id="9763" class="ky kz it ku b gy la lb l lc ld"># # generate data and visualize it<br/>np.random.seed(1)<br/>x = np.arange(0,1000)<br/>noise = np.random.normal(0,10,1000)<br/>slope = 0.1<br/>b = 5.0</span><span id="57a2" class="ky kz it ku b gy le lb l lc ld">y = (slope*x)+b <br/>y_noised = y+noise</span><span id="2fb9" class="ky kz it ku b gy le lb l lc ld"># test train split <br/>x_train, x_test, y_train, y_test = train_test_split(x,y_noised, test_size=0.2, random_state=1)</span><span id="2941" class="ky kz it ku b gy le lb l lc ld">x_train_shape = x_train.shape[0]<br/>y_train_shape = y_train.shape[0]</span><span id="877d" class="ky kz it ku b gy le lb l lc ld">x_train_reshaped = x_train.reshape(x_train_shape, 1)<br/>y_train_reshaped = y_train.reshape(y_train_shape, 1)</span><span id="b6e2" class="ky kz it ku b gy le lb l lc ld">x_test_shape = x_test.shape[0]<br/>x_test_reshaped = x_test.reshape(x_test_shape, 1)</span><span id="fe1e" class="ky kz it ku b gy le lb l lc ld"># fitting the model in sklearn <br/>lr = LinearRegression()<br/>lr.fit(x_train_reshaped, y_train_reshaped)</span><span id="5575" class="ky kz it ku b gy le lb l lc ld">pred_slope = lr.coef_<br/>pred_b = lr.intercept_<br/>y_pred= lr.predict(x_test_reshaped)<br/>residuals = y_test — y_pred.reshape(y_pred.shape[0],)</span><span id="c0d6" class="ky kz it ku b gy le lb l lc ld"># fitting the model line to the data <br/>model_line = (pred_slope*x)+pred_b<br/>model_line_reshaped = model_line.reshape(model_line.shape[1])</span><span id="80f2" class="ky kz it ku b gy le lb l lc ld">fig = make_subplots(rows=1, cols=2,subplot_titles=[“Linear data”, “Residual Plot”])</span><span id="2a2d" class="ky kz it ku b gy le lb l lc ld">fig.add_trace(go.Scatter(x=x,y=y_noised, mode=’markers’, marker={‘color’:’green’}, name=”noised data”), row=1, col=1)<br/>fig.add_trace(go.Scatter(x=x, y=model_line_reshaped, mode=’lines’, marker={‘color’:’red’}, name=’model’), row=1, col=1)<br/>fig.add_trace(go.Scatter(x=x_test, y=residuals, mode=’markers’, marker={‘color’:’blue’}, name=’residuals’), row=1, col=2)</span><span id="9b2d" class="ky kz it ku b gy le lb l lc ld">fig.update_xaxes(title_text=”x” ,row=1, col=1)<br/>fig.update_xaxes(title_text=”x”, row=1, col=2)<br/>fig.update_yaxes(title_text=”Y noised”, row=1, col=1)<br/>fig.update_yaxes(title_text=”error = predicted-observed” , row=1, col=2)<br/>fig.update_layout(title_text=”Figure 1")</span><span id="f84e" class="ky kz it ku b gy le lb l lc ld">iplot(fig)</span></pre><figure class="kp kq kr ks gt lg gh gi paragraph-image"><div role="button" tabindex="0" class="lh li di lj bf lk"><div class="gh gi lf"><img src="../Images/9588f7649b125c06c14256f2a417d727.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*6nObGm0EsLJj-dnZ7pEvIg.png"/></div></div></figure><h1 id="8505" class="ln kz it bd lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj bi translated"><strong class="ak">直方图的问题</strong></h1><p id="8c6e" class="pw-post-body-paragraph jq jr it js b jt mk jv jw jx ml jz ka kb mm kd ke kf mn kh ki kj mo kl km kn im bi translated">图 1 右边的图是残差图。残差是实际值(图 1 左侧图中的绿点)和预测值(红线)之间的差值。线性回归的假设之一是残差来自正态分布，另一种说法是直方图类似正态分布。请看下面的图 2。直方图具有单峰，在面元-5 到 0 周围有 20 个面元，并在两侧下降。但是，我们能说这个直方图代表的是正态分布吗？也许吧。当我们改变箱的大小时，我们的结论变得更加模糊，因为没有简单的方法来说明正态分布的峰值在哪里。这使得我们很难判断哪种箱大小适合解释分布。</p><p id="0156" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">直方图是说明数据来自正态分布的一种图形方式，但直方图可能具有欺骗性，因为改变条柱的数量会改变分布的形状，这可能会导致一些混淆。我们需要一种更好的方法来识别数据是否来自正态分布。这就是分位数-分位数图的用处。</p><pre class="kp kq kr ks gt kt ku kv kw aw kx bi"><span id="7f3a" class="ky kz it ku b gy la lb l lc ld">residual_df = pd.DataFrame(data=residuals,columns=[“residuals”])</span><span id="3e5d" class="ky kz it ku b gy le lb l lc ld"># callback function for the slider</span><span id="4805" class="ky kz it ku b gy le lb l lc ld"><strong class="ku iu">def</strong> change_bins(number_bins):<br/> return px.histogram(residual_df, x=”residuals”, nbins=int(number_bins), title=”Figure 2")</span><span id="c416" class="ky kz it ku b gy le lb l lc ld">slider_obj = widgets.FloatSlider(value=20, min=10, max=100,step=5, description=”Num of bins”, continuous_update=False)<br/>interact(change_bins, number_bins=slider_obj);</span></pre><figure class="kp kq kr ks gt lg gh gi paragraph-image"><div role="button" tabindex="0" class="lh li di lj bf lk"><div class="gh gi lf"><img src="../Images/77521621c15d3338b1bf7418a6ee35a0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*gtssyrreZ5nZ5_C5nw5L4Q.png"/></div></div></figure><h1 id="8820" class="ln kz it bd lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj bi translated"><strong class="ak">使用 Plotly 的简单分位数-分位数图</strong></h1><p id="793e" class="pw-post-body-paragraph jq jr it js b jt mk jv jw jx ml jz ka kb mm kd ke kf mn kh ki kj mo kl km kn im bi translated">使用直方图的替代方法是使用分位数-分位数图。分位数-分位数图(qq 图)是一种散点图，其中我们绘制数据集值与从数据集确定的分位数的正态分布值。qq 图的 y 坐标是数据集值，x 坐标是正态分布的值。</p><p id="9a57" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">为了生成分位数-分位数图的数据，我们必须定义需要正态分布值的分位数，所以首先我们写-</p><pre class="kp kq kr ks gt kt ku kv kw aw kx bi"><span id="ff20" class="ky kz it ku b gy la lb l lc ld">num_divisions = residuals.shape[0]+1<br/>quantiles = np.arange(1,residuals.shape[0])/num_divisions<br/></span></pre><p id="5a6f" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">num_divisions 告诉我们在正态分布中我们需要多少个除法。如果你运行上面的代码，你会看到分位数是-</p><pre class="kp kq kr ks gt kt ku kv kw aw kx bi"><span id="fdd9" class="ky kz it ku b gy la lb l lc ld">[0.00497512, 0.00995025, 0.01492537, 0.0199005 …]</span></pre><p id="f698" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">所以如果一个数据集中有*n*个数据点，我们需要把正态分布分成*n+1*个区域，从正态分布得到*n*。</p><p id="d4ba" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">例如，在我们的案例中，数据集中有 200 个点，因此我们需要在正态分布中有 201 个分区。一旦我们有了分位数值，我们就将它们插入 ppf 函数。这是累积分布的倒数，它给出了给定分位数值的正态分布的 z 得分。</p><p id="f79e" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">我们输入到 ppf 函数中的分位数值只不过是正态曲线下面积与 1 的比值。</p><pre class="kp kq kr ks gt kt ku kv kw aw kx bi"><span id="741b" class="ky kz it ku b gy la lb l lc ld"><br/>qq_x_data = sps.norm.ppf(quantiles)<br/></span></pre><p id="198c" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">这些值是 qq 图的 x 值，我们通过对残差排序得到 y 值</p><pre class="kp kq kr ks gt kt ku kv kw aw kx bi"><span id="17e4" class="ky kz it ku b gy la lb l lc ld">qq_y_data = np.sort(residuals)<br/></span></pre><p id="160c" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">接下来，我们需要获取绘制参考线的数据。为此，我们需要两点来确定直线的斜率和 y 轴截距。为此，我们将采用克里夫兰在可视化数据方面的建议[[1](<a class="ae mp" href="https://dl.acm.org/citation.cfm?id=529269" rel="noopener ugc nofollow" target="_blank">https://dl.acm.org/citation.cfm?id=529269</a>)]。<br/>第一个和第三个四分位数的 x 值将来自正态分布。y 值将来自我们的有序数据集。因此我们写道-</p><pre class="kp kq kr ks gt kt ku kv kw aw kx bi"><span id="8249" class="ky kz it ku b gy la lb l lc ld"># guide line data<br/>line_x0 = sps.norm.ppf(0.25)<br/>line_x1 = sps.norm.ppf(0.75)</span><span id="3a21" class="ky kz it ku b gy le lb l lc ld">line_y0 = np.quantile(residuals, 0.25)<br/>line_y1 = np.quantile(residuals, 0.75)</span></pre><p id="de0f" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">用这两点我们组成一条线-</p><pre class="kp kq kr ks gt kt ku kv kw aw kx bi"><span id="6a60" class="ky kz it ku b gy la lb l lc ld">slope = (line_y1-line_y0)/(line_x1-line_x0)<br/>line_intercept = line_y1 — (slope*line_x1)</span><span id="b5de" class="ky kz it ku b gy le lb l lc ld">x_range_line = np.arange(-3,3,0.001)<br/>y_values_line = (slope*x_range_line) + line_intercept</span></pre><p id="713b" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">注意:不要对 qq 图上的点拟合回归线，这将不会满足线性回归的假设(想想吧！为什么？)</p><p id="576e" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">现在我们有了 qq 图和参考线的数据，我们将使用 plotly 来绘制它们。</p><pre class="kp kq kr ks gt kt ku kv kw aw kx bi"><span id="bf86" class="ky kz it ku b gy la lb l lc ld">fig = go.Figure()</span><span id="79e0" class="ky kz it ku b gy le lb l lc ld">fig.add_trace(go.Scatter(x=qq_x_data,<br/> y=qq_y_data,<br/> mode=’markers’,<br/> marker={‘color’:’blue’},<br/> name=”qq data”))<br/>fig.add_trace(go.Scatter(x=x_range_line,<br/> y=y_values_line,<br/> mode=’lines’,<br/> marker={‘color’:’red’},<br/> name=”guide line”))</span><span id="203b" class="ky kz it ku b gy le lb l lc ld">fig[‘layout’].update(title=’Figure 3',<br/> xaxis={<br/> ‘title’: ‘Theoritical Quantities’,<br/> ‘zeroline’: True<br/> },<br/> yaxis={<br/> ‘title’: ‘Sample Quantities’<br/> },<br/> showlegend=True,<br/> )</span><span id="9f9d" class="ky kz it ku b gy le lb l lc ld">iplot(fig)</span></pre><figure class="kp kq kr ks gt lg gh gi paragraph-image"><div role="button" tabindex="0" class="lh li di lj bf lk"><div class="gh gi lf"><img src="../Images/01e0674df75ed35f6209712cbafb1a58.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*TlY_H50swPR2FF5IM7Pr9Q.png"/></div></div></figure><p id="2315" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">看一个 qq 图的方法是看有多少点落在参考线上。如果大多数点落在这条线上，那么我们假设数据代表正态分布。如果大多数点不遵循这一趋势，那么我们可以说数据不具有正常趋势。通常在这种情况下，我们应该尝试其他的正态性检验，如安德森-达林检验、KS 检验等，以确保数据不是正态的。我们将在下一个笔记本中深入研究，看看如何结合和解释正态性的图形和假设检验。</p><p id="e384" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">从该图中可以得出的主要结论是，qq 图是解读数据集是否遵循正态分布的简单图形方式。</p><h1 id="9987" class="ln kz it bd lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj bi translated">分位数-各种分布数据的分位数图</h1><p id="d3ef" class="pw-post-body-paragraph jq jr it js b jt mk jv jw jx ml jz ka kb mm kd ke kf mn kh ki kj mo kl km kn im bi translated">在本节中，我们将研究来自不同分布类型的数据，并展示如何使用 qq 图将它们与正态分布进行比较。</p><p id="b793" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">假设我们有一个服从均匀分布的数据集。那么 qq 剧情看起来就不一样了。</p><pre class="kp kq kr ks gt kt ku kv kw aw kx bi"><span id="6b51" class="ky kz it ku b gy la lb l lc ld">uniform_data = np.random.uniform(0,10,1000)</span><span id="f1a8" class="ky kz it ku b gy le lb l lc ld">num_divisions = uniform_data.shape[0]+1<br/>quantiles = np.arange(1,uniform_data.shape[0])/num_divisions</span><span id="2aca" class="ky kz it ku b gy le lb l lc ld"># scatter data <br/>qq_uniform_x = sps.norm.ppf(quantiles)<br/>qq_uniform_y = np.sort(uniform_data)</span><span id="e02f" class="ky kz it ku b gy le lb l lc ld">line_y0 = np.quantile(uniform_data, 0.25)<br/>line_y1 = np.quantile(uniform_data, 0.75)</span><span id="2c49" class="ky kz it ku b gy le lb l lc ld">slope = (line_y1-line_y0)/(line_x1-line_x0)<br/>line_intercept = line_y1 — (slope*line_x1)</span><span id="2e24" class="ky kz it ku b gy le lb l lc ld"># points to plot the line <br/>x_uniform = np.arange(-3,3,0.001)<br/>y_uniform = (slope*x_range_line) + line_intercept</span><span id="2f02" class="ky kz it ku b gy le lb l lc ld">fig = make_subplots(rows=1, cols=2,subplot_titles=[“Data histogram”, “QQ plot”])</span><span id="d115" class="ky kz it ku b gy le lb l lc ld">fig.add_trace(go.Histogram(x=uniform_data,<br/> name=”uniform data”),<br/> row=1,<br/> col=1)<br/>fig.add_trace(go.Scatter(x=qq_uniform_x,<br/> y=qq_uniform_y,<br/> mode=’markers’,<br/> marker={‘color’:’blue’},<br/> name=”qq data”),<br/> row=1,<br/> col=2)<br/>fig.add_trace(go.Scatter(x=x_uniform,<br/> y=y_uniform,<br/> mode=’lines’,<br/> marker={‘color’:’red’},<br/> name=”guide line”),<br/> row=1,<br/> col=2)</span><span id="fbb5" class="ky kz it ku b gy le lb l lc ld">fig.update_xaxes(title_text=”data values”, row=1, col=1)<br/>fig.update_xaxes(title_text=”theoretical quantiles”, range=[-4,4], row=1, col=2)<br/>fig.update_yaxes(title_text=”Count”, row=1, col=1)<br/>fig.update_yaxes(title_text=”observed quantiles” , row=1, col=2)</span><span id="9df7" class="ky kz it ku b gy le lb l lc ld">iplot(fig)</span></pre><figure class="kp kq kr ks gt lg gh gi paragraph-image"><div role="button" tabindex="0" class="lh li di lj bf lk"><div class="gh gi lf"><img src="../Images/a06c3b1387e0cacc594784f6b36368ab.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ZS2m5USiVWq6_sETKkfDAQ.png"/></div></div></figure><p id="8492" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">您可以看到分散点呈 s 形曲线，许多点不在参考线上。这是一个好迹象，表明观察到的数据不是来自正态分布。在直方图中也可以看到同样的情况。</p><p id="cced" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">事实上，我们可以对许多其他分布类型这样做。这是一个比较残差数据和多重分布的图表。为此，我们将使用 ipython 小部件将多个情节浓缩成 plotly。</p><p id="6f1b" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">在分布函数中探讨分布的参数，以生成不同形状的数据分布。例如，更改对数正态分布的平均值和标准差，以查看直方图和 qq 图会发生什么变化。这将有助于您查看不同类型的数据及其 qq 图。</p><pre class="kp kq kr ks gt kt ku kv kw aw kx bi"><span id="45f9" class="ky kz it ku b gy la lb l lc ld">def get_qqdata(observed_data):<br/> np.random.seed(0)<br/> num_divisions = observed_data.shape[0]+1<br/> quantiles = np.arange(1,observed_data.shape[0])/num_divisions</span><span id="bca1" class="ky kz it ku b gy le lb l lc ld"># scatter data <br/> qq_x = sps.norm.ppf(quantiles)<br/> qq_y = np.sort(observed_data)</span><span id="c102" class="ky kz it ku b gy le lb l lc ld">line_y0 = np.quantile(observed_data, 0.25)<br/> line_y1 = np.quantile(observed_data, 0.75)</span><span id="0ee4" class="ky kz it ku b gy le lb l lc ld">slope = (line_y1-line_y0)/(line_x1-line_x0)<br/> line_intercept = line_y1 — (slope*line_x1)</span><span id="6e07" class="ky kz it ku b gy le lb l lc ld"># points to plot the line <br/> x_line = np.arange(-3,3,0.001)<br/> y_line = (slope*x_range_line) + line_intercept</span><span id="a26c" class="ky kz it ku b gy le lb l lc ld">qq_data = {‘qqx’: qq_x, ‘qqy’:qq_y, ‘linex’: x_line, ‘liney’:y_line}<br/> <br/> return qq_data</span><span id="7c76" class="ky kz it ku b gy le lb l lc ld">def dist_qqplot(dist_data, dist_name) :<br/> qq_data = get_qqdata(dist_data)</span><span id="5474" class="ky kz it ku b gy le lb l lc ld">fig = make_subplots(rows=1, cols=2,subplot_titles=[“Data histogram”, “QQ plot”])<br/> fig.add_trace(go.Histogram(x=dist_data, name=dist_name), row=1, col=1)<br/> fig.update_xaxes(title_text=”data values” ,row=1, col=1)<br/> fig.add_trace(go.Scatter(x=qq_data[“qqx”] , y=qq_data[“qqy”], mode=’markers’, marker={‘color’:’blue’}, name=”qq data”), row=1,col=2)<br/> fig.add_trace(go.Scatter(x=qq_data[“linex”], y=qq_data[“liney”], mode=’lines’, marker={‘color’:’red’}, name=”guide line”), row=1,col=2)</span><span id="368e" class="ky kz it ku b gy le lb l lc ld">fig.update_xaxes(title_text=”theoretical quantiles”, range=[-4,4], row=1, col=2)<br/> fig.update_yaxes(title_text=”Count”, row=1, col=1)<br/> fig.update_yaxes(title_text=”observed quantiles” , row=1, col=2)<br/> <br/> return iplot(fig)</span><span id="40ee" class="ky kz it ku b gy le lb l lc ld">def distributions(dist): <br/> <br/> # change parameter values here to see how the qq plot can change<br/> selected_data ={“triangular”: np.random.triangular(10,100,115,1000),<br/> ‘lognormal’: np.random.lognormal(10,1,1000),<br/> ‘chi square’: np.random.chisquare(8,1000)}<br/> <br/> return dist_qqplot(selected_data[dist], dist )</span><span id="0a72" class="ky kz it ku b gy le lb l lc ld">toggle_obj = widgets.ToggleButtons(description=”Distribution:”, options=[“triangular”,”lognormal”, “chi square”])<br/>interact(distributions, dist=toggle_obj);</span></pre><figure class="kp kq kr ks gt lg gh gi paragraph-image"><div role="button" tabindex="0" class="lh li di lj bf lk"><div class="gh gi lf"><img src="../Images/cfe871d050897d87503fbc8a432f5716.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*BllYktQ0ST0epfl1AZxNcQ.png"/></div></div><figcaption class="mq mr gj gh gi ms mt bd b be z dk">Histogram and qq plot for a triangular distribution with right value = 10, mode = 100, left = 115 with 1000 samples.</figcaption></figure><figure class="kp kq kr ks gt lg gh gi paragraph-image"><div role="button" tabindex="0" class="lh li di lj bf lk"><div class="gh gi lf"><img src="../Images/981e4b69dd11fb812a460d7d8bfa2c1e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*xxe5VFyfHQNP_slXPqm_4g.png"/></div></div><figcaption class="mq mr gj gh gi ms mt bd b be z dk">Histogram and qq plot for a lognormal distribution with a mean = 10 and std dev = 1. 1000 samples were generated</figcaption></figure><figure class="kp kq kr ks gt lg gh gi paragraph-image"><div role="button" tabindex="0" class="lh li di lj bf lk"><div class="gh gi lf"><img src="../Images/a9f3bfe9cf9a7c9ea29e15d5b2626f4c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*wSUL5dEZwNskBtlZ424kog.png"/></div></div><figcaption class="mq mr gj gh gi ms mt bd b be z dk">Histogram and qq plot for a chi-square distribution with degree of freedom = 8 and 1000 samples are generated</figcaption></figure><figure class="kp kq kr ks gt lg"><div class="bz fp l di"><div class="mu mv l"/></div></figure></div></div>    
</body>
</html>