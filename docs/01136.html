<html>
<head>
<title>The Data Fabric for Machine Learning. Part 1-b: Deep Learning on Graphs.</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">机器学习的数据结构。第 1-b 部分:图上的深度学习。</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/the-data-fabric-for-machine-learning-part-1-b-deep-learning-on-graphs-309316774fe7?source=collection_archive---------16-----------------------#2019-02-21">https://towardsdatascience.com/the-data-fabric-for-machine-learning-part-1-b-deep-learning-on-graphs-309316774fe7?source=collection_archive---------16-----------------------#2019-02-21</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="6302" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">图形的深度学习日益重要。在这里，我将通过库 Spektral 和平台 MatrixDS 展示在图上思考机器学习和深度学习的基础知识。第一部分<a class="ae kf" rel="noopener" target="_blank" href="/the-data-fabric-for-machine-learning-part-1-2c558b7035d7">这里</a>。</h2></div><figure class="kh ki kj kk gt kl gh gi paragraph-image"><div role="button" tabindex="0" class="km kn di ko bf kp"><div class="gh gi kg"><img src="../Images/448d61d103444d54892b37e7609e421a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*blkpaGjw1VeTVfHYAjLphg.jpeg"/></div></div></figure><blockquote class="ks"><p id="44ae" class="kt ku iq bd kv kw kx ky kz la lb lc dk translated">声明:这不是第二部分的<a class="ae kf" rel="noopener" target="_blank" href="/the-data-fabric-for-machine-learning-part-1-2c558b7035d7">过去的文章</a>的主题；这是第一部分的延续，强调深度学习。</p></blockquote><h1 id="05f1" class="ld le iq bd lf lg lh li lj lk ll lm ln jw lo jx lp jz lq ka lr kc ls kd lt lu bi translated">介绍</h1><figure class="kh ki kj kk gt kl gh gi paragraph-image"><div role="button" tabindex="0" class="km kn di ko bf kp"><div class="gh gi lv"><img src="../Images/a164f6ae987bb51d795d6e80c8b3b43d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*2ikKD0QxQM4ht93R"/></div></div></figure><p id="ce90" class="pw-post-body-paragraph lw lx iq ly b lz ma jr mb mc md ju me mf mg mh mi mj mk ml mm mn mo mp mq lc ij bi translated">我们正在定义一种新的机器学习方式，专注于一种新的范式，即数据结构。</p><p id="365a" class="pw-post-body-paragraph lw lx iq ly b lz ma jr mb mc md ju me mf mg mh mi mj mk ml mm mn mo mp mq lc ij bi translated">在过去的文章中，我给出了我对机器学习的新定义:</p><blockquote class="ks"><p id="96ee" class="kt ku iq bd kv kw mr ms mt mu mv lc dk translated">机器学习是通过使用算法发现数据结构中隐藏的见解的自动过程，这些算法能够在没有专门编程的情况下找到这些见解，以创建解决特定(或多个)问题的模型。</p></blockquote><p id="807c" class="pw-post-body-paragraph lw lx iq ly b lz mw jr mb mc mx ju me mf my mh mi mj mz ml mm mn na mp mq lc ij bi translated">理解这一点的前提是我们已经创建了一个数据结构。对我来说，最好的工具就是我在其他文章中提到的 Anzo。</p><figure class="kh ki kj kk gt kl gh gi paragraph-image"><div class="ab gu cl nb"><img src="../Images/e5fa07a4e0903df8c8ba23218714b300.png" data-original-src="https://miro.medium.com/v2/format:webp/1*v2nboJXUzRq9OmMM7LpjTA.png"/></div><figcaption class="nc nd gj gh gi ne nf bd b be z dk"><a class="ae kf" href="https://www.cambridgesemantics.com/" rel="noopener ugc nofollow" target="_blank">https://www.cambridgesemantics.com/</a></figcaption></figure><p id="12f0" class="pw-post-body-paragraph lw lx iq ly b lz ma jr mb mc md ju me mf mg mh mi mj mk ml mm mn mo mp mq lc ij bi translated">你可以用 Anzo 建立一个叫做“企业知识图”的东西，当然也可以创建你的数据结构。</p><p id="8897" class="pw-post-body-paragraph lw lx iq ly b lz ma jr mb mc md ju me mf mg mh mi mj mk ml mm mn mo mp mq lc ij bi translated">但是现在我想把重点放在机器学习内部的一个话题，深度学习。在<a class="ae kf" href="https://becominghuman.ai/deep-learning-made-easy-with-deep-cognition-403fbe445351" rel="noopener ugc nofollow" target="_blank">的另一篇文章</a>中，我给出了深度学习的定义:</p><blockquote class="ks"><p id="38ce" class="kt ku iq bd kv kw mr ms mt mu mv lc dk translated">深度学习是机器学习的一个特定子领域，是从数据中学习表示的一种新方式，它强调学习越来越有意义的表示的连续<strong class="ak">“层</strong>【神经网络】。</p></blockquote><p id="56c1" class="pw-post-body-paragraph lw lx iq ly b lz mw jr mb mc mx ju me mf my mh mi mj mz ml mm mn na mp mq lc ij bi translated">在这里，我们将讨论深度学习和图论的结合，并看看它如何帮助我们的研究向前发展。</p><h1 id="2cec" class="ld le iq bd lf lg lh li lj lk ll lm ln jw ng jx lp jz nh ka lr kc ni kd lt lu bi translated">目标</h1><h2 id="5696" class="nj le iq bd lf nk nl dn lj nm nn dp ln mf no np lp mj nq nr lr mn ns nt lt nu bi translated">一般</h2><blockquote class="ks"><p id="8882" class="kt ku iq bd kv kw mr ms mt mu mv lc dk translated">为在数据结构上进行深度学习奠定基础。</p></blockquote><h2 id="f5c1" class="nj le iq bd lf nk nv dn lj nm nw dp ln mf nx np lp mj ny nr lr mn nz nt lt nu bi translated">细节</h2><ul class=""><li id="d52e" class="oa ob iq ly b lz oc mc od mf oe mj of mn og lc oh oi oj ok bi translated">在图上描述深度学习的基础。</li><li id="7ee1" class="oa ob iq ly b lz ol mc om mf on mj oo mn op lc oh oi oj ok bi translated">探索图书馆的特色。</li><li id="7c50" class="oa ob iq ly b lz ol mc om mf on mj oo mn op lc oh oi oj ok bi translated">验证在数据结构上进行深度学习的可能性。</li></ul><h1 id="ffba" class="ld le iq bd lf lg lh li lj lk ll lm ln jw ng jx lp jz nh ka lr kc ni kd lt lu bi translated">主要假设</h1><p id="7cba" class="pw-post-body-paragraph lw lx iq ly b lz oc jr mb mc od ju me mf oq mh mi mj or ml mm mn os mp mq lc ij bi translated">如果我们可以构建一个支持公司所有数据的<strong class="ly ir">数据结构</strong>，那么通过使用<strong class="ly ir">神经网络</strong>(深度学习)从数据中<strong class="ly ir">学习越来越有意义的表示</strong>来发现见解的<strong class="ly ir">自动过程</strong>就可以在数据结构内部运行。</p><h1 id="9c60" class="ld le iq bd lf lg lh li lj lk ll lm ln jw ng jx lp jz nh ka lr kc ni kd lt lu bi translated">第一节。关于图的深度学习？</h1><figure class="kh ki kj kk gt kl gh gi paragraph-image"><div class="gh gi ot"><img src="../Images/a38f2b84307ec7b7c4ea247a572df1d0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1100/format:webp/0*PMxUTkuIlREthZ1_.png"/></div><figcaption class="nc nd gj gh gi ne nf bd b be z dk"><a class="ae kf" href="https://tkipf.github.io/graph-convolutional-networks/" rel="noopener ugc nofollow" target="_blank">https://tkipf.github.io/graph-convolutional-networks/</a></figcaption></figure><p id="874f" class="pw-post-body-paragraph lw lx iq ly b lz ma jr mb mc md ju me mf mg mh mi mj mk ml mm mn mo mp mq lc ij bi translated">通常我们使用张量来创建神经网络，但是记住我们也可以用矩阵来定义张量，并且<a class="ae kf" rel="noopener" target="_blank" href="/graph-databases-whats-the-big-deal-ec310b1bc0ed">图</a>可以通过矩阵来定义。</p><p id="5553" class="pw-post-body-paragraph lw lx iq ly b lz ma jr mb mc md ju me mf mg mh mi mj mk ml mm mn mo mp mq lc ij bi translated">在库<a class="ae kf" href="https://danielegrattarola.github.io/spektral/data/" rel="noopener ugc nofollow" target="_blank">speck tral</a>的文档中，他们声明一个图通常由三个矩阵表示:</p><ul class=""><li id="8bcc" class="oa ob iq ly b lz ma mc md mf ou mj ov mn ow lc oh oi oj ok bi translated">A∈{0,1}^(N×N): a 二元邻接矩阵，其中如果节点<em class="ox"> i </em>和<em class="ox"> j </em>之间有连接，A_ <em class="ox"> ij </em> =1，否则 a _<em class="ox">ij</em>= 0；</li><li id="5b1b" class="oa ob iq ly b lz ol mc om mf on mj oo mn op lc oh oi oj ok bi translated">X∈ℝ^(N×F):编码节点属性(或特征)的矩阵，其中 FF 维属性向量与每个节点相关联；</li><li id="7644" class="oa ob iq ly b lz ol mc om mf on mj oo mn op lc oh oi oj ok bi translated">E∈ℝ^(N×N×S):一个编码边属性的矩阵，其中一个<em class="ox"> S </em>维属性向量与每个边相关联。</li></ul><p id="5a43" class="pw-post-body-paragraph lw lx iq ly b lz ma jr mb mc md ju me mf mg mh mi mj mk ml mm mn mo mp mq lc ij bi translated">我不会在这里详细介绍，但如果你想更全面地了解图形深度学习，请查看<a class="oy oz ep" href="https://medium.com/u/565f7254b058?source=post_page-----309316774fe7--------------------------------" rel="noopener" target="_blank"> Tobias Skovgaard Jepsen </a>的文章:</p><div class="pa pb gp gr pc pd"><a rel="noopener follow" target="_blank" href="/how-to-do-deep-learning-on-graphs-with-graph-convolutional-networks-7d2250723780"><div class="pe ab fo"><div class="pf ab pg cl cj ph"><h2 class="bd ir gy z fp pi fr fs pj fu fw ip bi translated">如何用图卷积网络在图上做深度学习</h2><div class="pk l"><h3 class="bd b gy z fp pi fr fs pj fu fw dk translated">第 1 部分:图卷积网络的高级介绍</h3></div><div class="pl l"><p class="bd b dl z fp pi fr fs pj fu fw dk translated">towardsdatascience.com</p></div></div><div class="pm l"><div class="pn l po pp pq pm pr kq pd"/></div></div></a></div><p id="35a9" class="pw-post-body-paragraph lw lx iq ly b lz ma jr mb mc md ju me mf mg mh mi mj mk ml mm mn mo mp mq lc ij bi translated">这里重要的部分是图形神经网络(GNN)的概念。</p><h2 id="911a" class="nj le iq bd lf nk nl dn lj nm nn dp ln mf no np lp mj nq nr lr mn ns nt lt nu bi translated">图形神经网络(GNN)</h2><figure class="kh ki kj kk gt kl gh gi paragraph-image"><div role="button" tabindex="0" class="km kn di ko bf kp"><div class="gh gi ps"><img src="../Images/ae3aa36af31991c33636b279eb951cca.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*kCcqLTz17w6oVU0UTmRD6g.png"/></div></div><figcaption class="nc nd gj gh gi ne nf bd b be z dk"><a class="ae kf" href="https://arxiv.org/pdf/1812.04202.pdf" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/pdf/1812.04202.pdf</a></figcaption></figure><p id="8db1" class="pw-post-body-paragraph lw lx iq ly b lz ma jr mb mc md ju me mf mg mh mi mj mk ml mm mn mo mp mq lc ij bi translated">GNN 的思路很简单:对图的结构信息进行编码，每个节点 v_ <em class="ox"> i </em>可以用一个低维状态向量 s_ <em class="ox"> i </em>，1 ≤ <em class="ox"> i </em> ≤ N 来表示(记住向量可以认为是秩 1 的张量，张量可以用矩阵来表示)。</p><p id="41e7" class="pw-post-body-paragraph lw lx iq ly b lz ma jr mb mc md ju me mf mg mh mi mj mk ml mm mn mo mp mq lc ij bi translated">学习图上的深度模型的任务可以大致分为两个领域:</p><ul class=""><li id="3330" class="oa ob iq ly b lz ma mc md mf ou mj ov mn ow lc oh oi oj ok bi translated"><strong class="ly ir">以节点为中心的任务:</strong>任务与图中的单个节点相关联。例子包括节点分类、链接预测和节点推荐。</li><li id="1789" class="oa ob iq ly b lz ol mc om mf on mj oo mn op lc oh oi oj ok bi translated"><strong class="ly ir">以图形为中心的任务:</strong>任务与整个图形相关联。示例包括图形分类、估计图形的某些属性或生成图形。</li></ul><h1 id="d6fa" class="ld le iq bd lf lg lh li lj lk ll lm ln jw ng jx lp jz nh ka lr kc ni kd lt lu bi translated">第二节。使用 Spektral 进行深度学习</h1><figure class="kh ki kj kk gt kl gh gi paragraph-image"><div role="button" tabindex="0" class="km kn di ko bf kp"><div class="gh gi pt"><img src="../Images/ae771bd445622446114c3794ce8b0c58.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*L9nmD2lvITEpQFar.png"/></div></div><figcaption class="nc nd gj gh gi ne nf bd b be z dk"><a class="ae kf" href="https://github.com/danielegrattarola/spektral/" rel="noopener ugc nofollow" target="_blank">https://github.com/danielegrattarola/spektral/</a></figcaption></figure><p id="cde8" class="pw-post-body-paragraph lw lx iq ly b lz ma jr mb mc md ju me mf mg mh mi mj mk ml mm mn mo mp mq lc ij bi translated">作者将 Spektral 定义为一个关系表示学习的框架，用 Python 构建，基于 Keras API。</p><h2 id="385c" class="nj le iq bd lf nk nl dn lj nm nn dp ln mf no np lp mj nq nr lr mn ns nt lt nu bi translated">装置</h2><p id="bf53" class="pw-post-body-paragraph lw lx iq ly b lz oc jr mb mc od ju me mf oq mh mi mj or ml mm mn os mp mq lc ij bi translated">我们将使用<a class="ae kf" href="https://matrixds.com/" rel="noopener ugc nofollow" target="_blank"> MatrixDS </a>作为运行我们代码的工具。请记住，在 Anzo 中，你也可以带着这段代码在那里运行。</p><p id="1468" class="pw-post-body-paragraph lw lx iq ly b lz ma jr mb mc md ju me mf mg mh mi mj mk ml mm mn mo mp mq lc ij bi translated">您需要做的第一件事是派生 MatrixDS 项目:</p><div class="pa pb gp gr pc pd"><a href="https://community.platform.matrixds.com/community/project/5c6ae7c8c1b06ba1e18f2a6e/files" rel="noopener  ugc nofollow" target="_blank"><div class="pe ab fo"><div class="pf ab pg cl cj ph"><h2 class="bd ir gy z fp pi fr fs pj fu fw ip bi translated">MatrixDS |数据项目工作台</h2><div class="pk l"><h3 class="bd b gy z fp pi fr fs pj fu fw dk translated">MatrixDS 是一个构建、共享和管理任何规模的数据项目的地方。</h3></div><div class="pl l"><p class="bd b dl z fp pi fr fs pj fu fw dk translated">community.platform.matrixds.com</p></div></div></div></a></div><p id="9024" class="pw-post-body-paragraph lw lx iq ly b lz ma jr mb mc md ju me mf mg mh mi mj mk ml mm mn mo mp mq lc ij bi translated">点击:</p><figure class="kh ki kj kk gt kl gh gi paragraph-image"><div class="gh gi pu"><img src="../Images/20fa5a503471670fcdd1aca2ee957476.png" data-original-src="https://miro.medium.com/v2/resize:fit:234/format:webp/1*hHi396lQHDjTDpodph-XxQ.png"/></div></figure><p id="383c" class="pw-post-body-paragraph lw lx iq ly b lz ma jr mb mc md ju me mf mg mh mi mj mk ml mm mn mo mp mq lc ij bi translated">您将已经安装了库，并且一切都正常工作:)。</p><p id="76d0" class="pw-post-body-paragraph lw lx iq ly b lz ma jr mb mc md ju me mf mg mh mi mj mk ml mm mn mo mp mq lc ij bi translated">如果你在外面运行这个，记住这个框架是为 Ubuntu 16.04 和 18.04 测试的，你应该安装:</p><pre class="kh ki kj kk gt pv pw px py aw pz bi"><span id="654d" class="nj le iq pw b gy qa qb l qc qd">sudo apt install graphviz libgraphviz-dev libcgraph6</span></pre><p id="b1cb" class="pw-post-body-paragraph lw lx iq ly b lz ma jr mb mc md ju me mf mg mh mi mj mk ml mm mn mo mp mq lc ij bi translated">然后使用以下内容安装该库:</p><pre class="kh ki kj kk gt pv pw px py aw pz bi"><span id="b853" class="nj le iq pw b gy qa qb l qc qd">pip install spektral</span></pre><h2 id="dc72" class="nj le iq bd lf nk nl dn lj nm nn dp ln mf no np lp mj nq nr lr mn ns nt lt nu bi translated">数据表示法</h2><p id="9602" class="pw-post-body-paragraph lw lx iq ly b lz oc jr mb mc od ju me mf oq mh mi mj or ml mm mn os mp mq lc ij bi translated">在 Spektral 中，一些层和函数被实现为在单个图形上工作，而其他层和函数则考虑图形的集合(即数据集或批次)。</p><p id="49ab" class="pw-post-body-paragraph lw lx iq ly b lz ma jr mb mc md ju me mf mg mh mi mj mk ml mm mn mo mp mq lc ij bi translated">该框架区分三种主要<em class="ox">操作模式</em>:</p><ul class=""><li id="6f67" class="oa ob iq ly b lz ma mc md mf ou mj ov mn ow lc oh oi oj ok bi translated"><strong class="ly ir">单个</strong>，这里我们考虑一个单个的图，以及它的拓扑和属性；</li><li id="9ce8" class="oa ob iq ly b lz ol mc om mf on mj oo mn op lc oh oi oj ok bi translated"><strong class="ly ir"> batch </strong>，这里我们考虑一个图的集合，每个图都有自己的拓扑和属性；</li><li id="32ab" class="oa ob iq ly b lz ol mc om mf on mj oo mn op lc oh oi oj ok bi translated"><strong class="ly ir">混合</strong>，这里我们考虑一个具有固定拓扑的图，但是是不同属性的集合；这可以被视为批处理模式的一种特殊情况(即，所有邻接矩阵都相同的情况)，但是出于计算原因而被分开处理。</li></ul><figure class="kh ki kj kk gt kl gh gi paragraph-image"><div class="gh gi qe"><img src="../Images/95b0660bafdc9c9d4cd837943772c386.png" data-original-src="https://miro.medium.com/v2/resize:fit:874/format:webp/1*bz1_Mhb2eyU5D948vspgHQ.png"/></div></figure><p id="5064" class="pw-post-body-paragraph lw lx iq ly b lz ma jr mb mc md ju me mf mg mh mi mj mk ml mm mn mo mp mq lc ij bi translated">例如，如果我们跑</p><pre class="kh ki kj kk gt pv pw px py aw pz bi"><span id="6d0e" class="nj le iq pw b gy qa qb l qc qd">from spektral.datasets import citation<br/>adj, node_features, edge_features, _, _, _, _, _ = citation.load_data('cora')</span></pre><p id="0ff6" class="pw-post-body-paragraph lw lx iq ly b lz ma jr mb mc md ju me mf mg mh mi mj mk ml mm mn mo mp mq lc ij bi translated">我们将以单一模式加载数据:</p><p id="2d99" class="pw-post-body-paragraph lw lx iq ly b lz ma jr mb mc md ju me mf mg mh mi mj mk ml mm mn mo mp mq lc ij bi translated">我们的邻接矩阵是:</p><pre class="kh ki kj kk gt pv pw px py aw pz bi"><span id="1b37" class="nj le iq pw b gy qa qb l qc qd">In [3]: adj.shape <br/>Out[3]: (2708, 2708)</span></pre><p id="4f75" class="pw-post-body-paragraph lw lx iq ly b lz ma jr mb mc md ju me mf mg mh mi mj mk ml mm mn mo mp mq lc ij bi translated">出音符属性包括:</p><pre class="kh ki kj kk gt pv pw px py aw pz bi"><span id="a77c" class="nj le iq pw b gy qa qb l qc qd">In [3]: node_attributes.shape <br/>Out[3]: (2708, 2708)</span></pre><p id="1a3c" class="pw-post-body-paragraph lw lx iq ly b lz ma jr mb mc md ju me mf mg mh mi mj mk ml mm mn mo mp mq lc ij bi translated">我们的优势是:</p><pre class="kh ki kj kk gt pv pw px py aw pz bi"><span id="3071" class="nj le iq pw b gy qa qb l qc qd">In [3]: edge_attributes.shape <br/>Out[3]: (2708, 7)</span></pre><h2 id="2708" class="nj le iq bd lf nk nl dn lj nm nn dp ln mf no np lp mj nq nr lr mn ns nt lt nu bi translated">基于图关注层的半监督分类</h2><blockquote class="ks"><p id="b3b0" class="kt ku iq bd kv kw mr ms mt mu mv lc dk translated">声明:我假设你从这里知道 Keras。</p></blockquote><p id="1231" class="pw-post-body-paragraph lw lx iq ly b lz mw jr mb mc mx ju me mf my mh mi mj mz ml mm mn na mp mq lc ij bi translated">有关更多详细信息和代码视图:</p><div class="pa pb gp gr pc pd"><a href="https://community.platform.matrixds.com/community/project/5c6ae7c8c1b06ba1e18f2a6e/files" rel="noopener  ugc nofollow" target="_blank"><div class="pe ab fo"><div class="pf ab pg cl cj ph"><h2 class="bd ir gy z fp pi fr fs pj fu fw ip bi translated">MatrixDS |数据项目工作台</h2><div class="pk l"><h3 class="bd b gy z fp pi fr fs pj fu fw dk translated">MatrixDS 是一个构建、共享和管理任何规模的数据项目的地方。</h3></div><div class="pl l"><p class="bd b dl z fp pi fr fs pj fu fw dk translated">community.platform.matrixds.com</p></div></div></div></a></div><p id="80ce" class="pw-post-body-paragraph lw lx iq ly b lz ma jr mb mc md ju me mf mg mh mi mj mk ml mm mn mo mp mq lc ij bi translated">GAT 是一种新颖的神经网络体系结构，利用掩蔽的自注意层对图结构数据进行操作。在 Spektral 中，<em class="ox"> GraphAttention </em>层计算类似于<code class="fe qf qg qh pw b">layers.GraphConv</code>的卷积，但是使用 Attention 机制对邻接矩阵进行加权，而不是使用归一化拉普拉斯算子。</p><p id="4241" class="pw-post-body-paragraph lw lx iq ly b lz ma jr mb mc md ju me mf mg mh mi mj mk ml mm mn mo mp mq lc ij bi translated">它们的工作方式是通过堆叠层，其中节点能够关注其邻域的特征，这使得能够(隐式地)为邻域中的不同节点指定不同的权重，而不需要任何代价高昂的矩阵运算(如求逆)，也不依赖于预先知道的图结构。</p><figure class="kh ki kj kk gt kl gh gi paragraph-image"><div class="gh gi qi"><img src="../Images/f75e14be3788aa3b7c7c3cb6c38c8c3f.png" data-original-src="https://miro.medium.com/v2/resize:fit:472/format:webp/1*7__z-bYUg-o-ito9q0imkA.png"/></div><figcaption class="nc nd gj gh gi ne nf bd b be z dk"><a class="ae kf" href="https://arxiv.org/pdf/1812.04202.pdf" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/pdf/1812.04202.pdf</a>. The attention mechanism employed by the model, parametrized by a weight vector, applying a LeakyReLU activation.</figcaption></figure><p id="a35a" class="pw-post-body-paragraph lw lx iq ly b lz ma jr mb mc md ju me mf mg mh mi mj mk ml mm mn mo mp mq lc ij bi translated">我们将使用的模型非常简单:</p><pre class="kh ki kj kk gt pv pw px py aw pz bi"><span id="6525" class="nj le iq pw b gy qa qb l qc qd"># Layers<br/>dropout_1 = Dropout(dropout_rate)(X_in)<br/>graph_attention_1 = GraphAttention(gat_channels,<br/>                                   attn_heads=n_attn_heads,<br/>                                   attn_heads_reduction='concat',<br/>                                   dropout_rate=dropout_rate,<br/>                                   activation='elu',<br/>                                   kernel_regularizer=l2(l2_reg),<br/>                                   attn_kernel_regularizer=l2(l2_reg))([dropout_1, A_in])<br/>dropout_2 = Dropout(dropout_rate)(graph_attention_1)<br/>graph_attention_2 = GraphAttention(n_classes,<br/>                                   attn_heads=1,<br/>                                   attn_heads_reduction='average',<br/>                                   dropout_rate=dropout_rate,<br/>                                   activation='softmax',<br/>                                   kernel_regularizer=l2(l2_reg),<br/>                                   attn_kernel_regularizer=l2(l2_reg))([dropout_2, A_in])</span><span id="574b" class="nj le iq pw b gy qj qb l qc qd"># Build model<br/>model = Model(inputs=[X_in, A_in], outputs=graph_attention_2)<br/>optimizer = Adam(lr=learning_rate)<br/>model.compile(optimizer=optimizer,<br/>              loss='categorical_crossentropy',<br/>              weighted_metrics=['acc'])<br/>model.summary()</span><span id="ad34" class="nj le iq pw b gy qj qb l qc qd"># Callbacks<br/>es_callback = EarlyStopping(monitor='val_weighted_acc', patience=es_patience)<br/>tb_callback = TensorBoard(log_dir=log_dir, batch_size=N)<br/>mc_callback = ModelCheckpoint(log_dir + 'best_model.h5',<br/>                              monitor='val_weighted_acc',<br/>                              save_best_only=True,<br/>                              save_weights_only=True)</span></pre><p id="6e62" class="pw-post-body-paragraph lw lx iq ly b lz ma jr mb mc md ju me mf mg mh mi mj mk ml mm mn mo mp mq lc ij bi translated">顺便说一句，模型很大:</p><pre class="kh ki kj kk gt pv pw px py aw pz bi"><span id="3fa2" class="nj le iq pw b gy qa qb l qc qd">__________________________________________________________________________________________________<br/>Layer (type)                    Output Shape         Param #     Connected to                     <br/>==================================================================================================<br/>input_1 (InputLayer)            (None, 1433)         0                                            <br/>__________________________________________________________________________________________________<br/>dropout_1 (Dropout)             (None, 1433)         0           input_1[0][0]                    <br/>__________________________________________________________________________________________________<br/>input_2 (InputLayer)            (None, 2708)         0                                            <br/>__________________________________________________________________________________________________<br/>graph_attention_1 (GraphAttenti (None, 64)           91904       dropout_1[0][0]                  <br/>                                                                 input_2[0][0]                    <br/>__________________________________________________________________________________________________<br/>dropout_18 (Dropout)            (None, 64)           0           graph_attention_1[0][0]          <br/>__________________________________________________________________________________________________<br/>graph_attention_2 (GraphAttenti (None, 7)            469         dropout_18[0][0]                 <br/>                                                                 input_2[0][0]                    <br/>==================================================================================================<br/>Total params: 92,373<br/>Trainable params: 92,373<br/>Non-trainable params: 0</span></pre><p id="ad5f" class="pw-post-body-paragraph lw lx iq ly b lz ma jr mb mc md ju me mf mg mh mi mj mk ml mm mn mo mp mq lc ij bi translated">因此，如果你没有那么多的力量，就减少使用它的次数。请记住，升级您的<a class="ae kf" href="https://matrixds.com/pricing/" rel="noopener ugc nofollow" target="_blank"> MatrixDS 帐户</a>非常容易。</p><p id="673b" class="pw-post-body-paragraph lw lx iq ly b lz ma jr mb mc md ju me mf mg mh mi mj mk ml mm mn mo mp mq lc ij bi translated">然后我们训练它(如果你没有足够的电力，这可能需要几个小时):</p><pre class="kh ki kj kk gt pv pw px py aw pz bi"><span id="dd3a" class="nj le iq pw b gy qa qb l qc qd"># Train model<br/>validation_data = ([node_features, adj], y_val, val_mask)<br/>model.fit([node_features, adj],<br/>          y_train,<br/>          sample_weight=train_mask,<br/>          epochs=epochs,<br/>          batch_size=N,<br/>          validation_data=validation_data,<br/>          shuffle=False,  # Shuffling data means shuffling the whole graph<br/>          callbacks=[es_callback, tb_callback, mc_callback])</span></pre><p id="9f0e" class="pw-post-body-paragraph lw lx iq ly b lz ma jr mb mc md ju me mf mg mh mi mj mk ml mm mn mo mp mq lc ij bi translated">获得最佳型号:</p><pre class="kh ki kj kk gt pv pw px py aw pz bi"><span id="1776" class="nj le iq pw b gy qa qb l qc qd">model.load_weights(log_dir + 'best_model.h5')</span></pre><p id="ea95" class="pw-post-body-paragraph lw lx iq ly b lz ma jr mb mc md ju me mf mg mh mi mj mk ml mm mn mo mp mq lc ij bi translated">并对其进行评估:</p><pre class="kh ki kj kk gt pv pw px py aw pz bi"><span id="19e7" class="nj le iq pw b gy qa qb l qc qd">print('Evaluating model.')<br/>eval_results = model.evaluate([node_features, adj],<br/>                              y_test,<br/>                              sample_weight=test_mask,<br/>                              batch_size=N)<br/>print('Done.\n'<br/>      'Test loss: {}\n'<br/>      'Test accuracy: {}'.format(*eval_results))</span></pre><p id="fc43" class="pw-post-body-paragraph lw lx iq ly b lz ma jr mb mc md ju me mf mg mh mi mj mk ml mm mn mo mp mq lc ij bi translated">在 MatrixDS 项目中查看更多信息:</p><div class="pa pb gp gr pc pd"><a href="https://community.platform.matrixds.com/community/project/5c6ae7c8c1b06ba1e18f2a6e/files" rel="noopener  ugc nofollow" target="_blank"><div class="pe ab fo"><div class="pf ab pg cl cj ph"><h2 class="bd ir gy z fp pi fr fs pj fu fw ip bi translated">MatrixDS |数据项目工作台</h2><div class="pk l"><h3 class="bd b gy z fp pi fr fs pj fu fw dk translated">MatrixDS 是一个构建、共享和管理任何规模的数据项目的地方。</h3></div><div class="pl l"><p class="bd b dl z fp pi fr fs pj fu fw dk translated">community.platform.matrixds.com</p></div></div></div></a></div><h1 id="ca8a" class="ld le iq bd lf lg lh li lj lk ll lm ln jw ng jx lp jz nh ka lr kc ni kd lt lu bi translated">第三节。这在数据结构中处于什么位置？</h1><p id="bea8" class="pw-post-body-paragraph lw lx iq ly b lz oc jr mb mc od ju me mf oq mh mi mj or ml mm mn os mp mq lc ij bi translated">如果您还记得上一部分，如果我们有一个数据结构:</p><figure class="kh ki kj kk gt kl gh gi paragraph-image"><div class="ab gu cl nb"><img src="../Images/ec52264dd7a60802bd2802ade8e731d0.png" data-original-src="https://miro.medium.com/v2/format:webp/1*b04zqRXIGDWoAdUsKiiL1w.png"/></div></figure><p id="35cf" class="pw-post-body-paragraph lw lx iq ly b lz ma jr mb mc md ju me mf mg mh mi mj mk ml mm mn mo mp mq lc ij bi translated">洞察力可以被认为是其中的一个凹痕:</p><figure class="kh ki kj kk gt kl gh gi paragraph-image"><div class="ab gu cl nb"><img src="../Images/658c7eaf07c55c7d0559e819800cd0fd.png" data-original-src="https://miro.medium.com/v2/format:webp/1*h0eLec-nM_Qn7UEFW4PoRw.png"/></div></figure><p id="2ecb" class="pw-post-body-paragraph lw lx iq ly b lz ma jr mb mc md ju me mf mg mh mi mj mk ml mm mn mo mp mq lc ij bi translated">如果您在 MatrixDS 平台上阅读本教程，您会意识到我们使用的数据不是简单的 CS，但是我们为库提供了:</p><ul class=""><li id="de68" class="oa ob iq ly b lz ma mc md mf ou mj ov mn ow lc oh oi oj ok bi translated">一个 N 乘 N 邻接矩阵(N 是节点数)，</li><li id="234a" class="oa ob iq ly b lz ol mc om mf on mj oo mn op lc oh oi oj ok bi translated">N 乘 D 特征矩阵(D 是每个节点的特征数量)，以及</li><li id="d04f" class="oa ob iq ly b lz ol mc om mf on mj oo mn op lc oh oi oj ok bi translated">一个 N 乘 E 的二进制标签矩阵(E 是类的数量)。</li></ul><p id="7ae2" class="pw-post-body-paragraph lw lx iq ly b lz ma jr mb mc md ju me mf mg mh mi mj mk ml mm mn mo mp mq lc ij bi translated">存储的是一系列文件:</p><pre class="kh ki kj kk gt pv pw px py aw pz bi"><span id="5f8f" class="nj le iq pw b gy qa qb l qc qd">ind.dataset_str.x =&gt; the feature vectors of the training instances as scipy.sparse.csr.csr_matrix object;    ind.dataset_str.tx =&gt; the feature vectors of the test instances as scipy.sparse.csr.csr_matrix object;    ind.dataset_str.allx =&gt; the feature vectors of both labeled and unlabeled training instances        (a superset of ind.dataset_str.x) as scipy.sparse.csr.csr_matrix object;    ind.dataset_str.y =&gt; the one-hot labels of the labeled training instances as numpy.ndarray object;    ind.dataset_str.ty =&gt; the one-hot labels of the test instances as numpy.ndarray object;    ind.dataset_str.ally =&gt; the labels for instances in ind.dataset_str.allx as numpy.ndarray object;    ind.dataset_str.graph =&gt; a dict in the format {index: [index_of_neighbor_nodes]} as collections.defaultdict        object;    ind.dataset_str.test.index =&gt; the indices of test instances in graph, for the inductive setting as list object.</span></pre><p id="4bb0" class="pw-post-body-paragraph lw lx iq ly b lz ma jr mb mc md ju me mf mg mh mi mj mk ml mm mn mo mp mq lc ij bi translated">所以这些数据存在于图表中。我们所做的就是将数据加载到库中。实际上，您可以在库中将数据转换为 NetworkX、numpy 和 sdf 格式。</p><p id="caec" class="pw-post-body-paragraph lw lx iq ly b lz ma jr mb mc md ju me mf mg mh mi mj mk ml mm mn mo mp mq lc ij bi translated">这意味着，如果我们将数据存储在一个数据结构中，我们就有了我们的知识图，所以我们已经有了许多这些特征，我们所拥有的是找到一种将它与库连接起来的方法。这是现在最棘手的部分。</p><blockquote class="ks"><p id="c580" class="kt ku iq bd kv kw mr ms mt mu mv lc dk translated">然后，我们可以通过对数据结构中的图表运行深度学习算法，开始在数据结构中寻找见解。</p></blockquote><p id="6164" class="pw-post-body-paragraph lw lx iq ly b lz mw jr mb mc mx ju me mf my mh mi mj mz ml mm mn na mp mq lc ij bi translated">有趣的是，在图表本身中可能有运行这些算法的方法，为此我们需要能够利用图表结构中固有的存储数据来构建模型，<a class="oy oz ep" href="https://medium.com/u/db0210be98bc?source=post_page-----309316774fe7--------------------------------" rel="noopener" target="_blank"> Lauren Shin </a>在 Neo4j 中有一个非常有趣的方法:</p><div class="pa pb gp gr pc pd"><a rel="noopener follow" target="_blank" href="/graphs-and-ml-multiple-linear-regression-c6920a1f2e70"><div class="pe ab fo"><div class="pf ab pg cl cj ph"><h2 class="bd ir gy z fp pi fr fs pj fu fw ip bi translated">图形和 ML:多元线性回归</h2><div class="pk l"><h3 class="bd b gy z fp pi fr fs pj fu fw dk translated">同样的 neo4j 线性回归程序，现在自变量无限！更多功能，无需额外…</h3></div><div class="pl l"><p class="bd b dl z fp pi fr fs pj fu fw dk translated">towardsdatascience.com</p></div></div><div class="pm l"><div class="qk l po pp pq pm pr kq pd"/></div></div></a></div><p id="d029" class="pw-post-body-paragraph lw lx iq ly b lz ma jr mb mc md ju me mf mg mh mi mj mk ml mm mn mo mp mq lc ij bi translated">但这也是一项正在进行的工作。我想象这个过程是这样的:</p><figure class="kh ki kj kk gt kl gh gi paragraph-image"><div role="button" tabindex="0" class="km kn di ko bf kp"><div class="gh gi kg"><img src="../Images/041673cc9de49e4ce39e54b71a0f11b2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*YA0N8xVJqF13NyzRWSsR_Q.jpeg"/></div></div></figure><p id="eafe" class="pw-post-body-paragraph lw lx iq ly b lz ma jr mb mc md ju me mf mg mh mi mj mk ml mm mn mo mp mq lc ij bi translated">这意味着神经网络可以生活在数据结构中，算法将与其中的资源一起运行。</p><p id="c5e6" class="pw-post-body-paragraph lw lx iq ly b lz ma jr mb mc md ju me mf mg mh mi mj mk ml mm mn mo mp mq lc ij bi translated">有一件重要的事情我在这里甚至没有提到，那就是<strong class="ly ir">非欧几里德数据</strong>的概念，但是我稍后会讲到。</p></div><div class="ab cl ql qm hu qn" role="separator"><span class="qo bw bk qp qq qr"/><span class="qo bw bk qp qq qr"/><span class="qo bw bk qp qq"/></div><div class="ij ik il im in"><h1 id="df04" class="ld le iq bd lf lg qs li lj lk qt lm ln jw qu jx lp jz qv ka lr kc qw kd lt lu bi translated">结论</h1><p id="9432" class="pw-post-body-paragraph lw lx iq ly b lz oc jr mb mc od ju me mf oq mh mi mj or ml mm mn os mp mq lc ij bi translated">如果我们可以将知识图与 Spektral(或其他)库连接起来，通过为我们拥有的图形数据部署图形神经网络模型，就有可能在数据结构上运行深度学习算法。</p><p id="f93a" class="pw-post-body-paragraph lw lx iq ly b lz ma jr mb mc md ju me mf mg mh mi mj mk ml mm mn mo mp mq lc ij bi translated">除了节点或图分类等标准的图推理任务，基于图的深度学习方法还被应用于广泛的学科领域，如建模社会影响、推荐系统、化学、物理、疾病或药物预测、自然语言处理(NLP)、计算机视觉、交通预测、程序归纳和解决基于图的 NP 问题。见<a class="ae kf" href="https://arxiv.org/pdf/1812.04202.pdf" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/pdf/1812.04202.pdf</a>。</p><p id="ae69" class="pw-post-body-paragraph lw lx iq ly b lz ma jr mb mc md ju me mf mg mh mi mj mk ml mm mn mo mp mq lc ij bi translated">应用是无止境的，这是一个新时代的开始。敬请关注更多:)</p></div></div>    
</body>
</html>