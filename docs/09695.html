<html>
<head>
<title>Practical Graph Neural Networks for Molecular Machine Learning</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">用于分子机器学习的实用图形神经网络</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/practical-graph-neural-networks-for-molecular-machine-learning-5e6dee7dc003?source=collection_archive---------1-----------------------#2019-12-20">https://towardsdatascience.com/practical-graph-neural-networks-for-molecular-machine-learning-5e6dee7dc003?source=collection_archive---------1-----------------------#2019-12-20</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><figure class="is it gp gr iu iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi ir"><img src="../Images/a786953b0e0fa44e0eebf8d963cf5e61.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*gC8q4uABSQtM8zyXG2wOog.png"/></div></div><figcaption class="jc jd gj gh gi je jf bd b be z dk">Graph convolutions</figcaption></figure><div class=""/><div class=""><h2 id="d245" class="pw-subtitle-paragraph kf jh ji bd b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw dk translated">直到最近，从业者将使用分子指纹(本质上是不同分子亚结构的一键编码)作为机器学习模型的输入。然而，该领域正开始朝着使用深度学习自动学习指纹本身(自动特征工程)的方向发展。这是一个实现简单神经指纹的演示。</h2></div></div><div class="ab cl kx ky hx kz" role="separator"><span class="la bw bk lb lc ld"/><span class="la bw bk lb lc ld"/><span class="la bw bk lb lc"/></div><div class="im in io ip iq"><h1 id="4371" class="le lf ji bd lg lh li lj lk ll lm ln lo ko lp kp lq kr lr ks ls ku lt kv lu lv bi translated">1.化学指纹</h1><p id="ba72" class="pw-post-body-paragraph lw lx ji ly b lz ma kj mb mc md km me mf mg mh mi mj mk ml mm mn mo mp mq mr im bi translated">化学指纹[1]长期以来一直是用于将化学结构表示为数字的表示方法，这些数字是机器学习模型的合适输入。简而言之，化学指纹表明是否存在化学特征或亚结构，如下所示:</p><figure class="mt mu mv mw gt iv gh gi paragraph-image"><div class="gh gi ms"><img src="../Images/152c2c11eb2940b26cc733fe443ccccd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1254/format:webp/1*x-8BkQummZpox5_WcPBNZQ.png"/></div><figcaption class="jc jd gj gh gi je jf bd b be z dk">Chemical fingerprints</figcaption></figure><p id="a244" class="pw-post-body-paragraph lw lx ji ly b lz mx kj mb mc my km me mf mz mh mi mj na ml mm mn nb mp mq mr im bi translated">在我的另一篇博文<a class="ae nc" rel="noopener" target="_blank" href="/a-practical-introduction-to-the-use-of-molecular-fingerprints-in-drug-discovery-7f15021be2b1">中提供了化学指纹的简要总结。</a></p><p id="cd47" class="pw-post-body-paragraph lw lx ji ly b lz mx kj mb mc my km me mf mz mh mi mj na ml mm mn nb mp mq mr im bi translated">使用 RDkit [2]可以在 Python 中轻松计算指纹，如下所示:</p><figure class="mt mu mv mw gt iv"><div class="bz fp l di"><div class="nd ne l"/></div><figcaption class="jc jd gj gh gi je jf bd b be z dk">How to make a fingerprint in Python</figcaption></figure><p id="9093" class="pw-post-body-paragraph lw lx ji ly b lz mx kj mb mc my km me mf mz mh mi mj na ml mm mn nb mp mq mr im bi translated">上面，我们计算了<a class="ae nc" href="https://en.wikipedia.org/wiki/Atorvastatin" rel="noopener ugc nofollow" target="_blank">阿伐他汀</a>的指纹，这种药物在 2003-2013 年间创造了超过 1000 亿美元的收入。</p><figure class="mt mu mv mw gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi nf"><img src="../Images/16ea3ae7bddf14e94e8d7fd765daa87e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*2oPWfA_Af60lR7RlLP5mcA.png"/></div></div><figcaption class="jc jd gj gh gi je jf bd b be z dk">Atorvastatin/Lipitor</figcaption></figure><h1 id="5fea" class="le lf ji bd lg lh ng lj lk ll nh ln lo ko ni kp lq kr nj ks ls ku nk kv lu lv bi translated">2.图形卷积</h1><p id="8ac1" class="pw-post-body-paragraph lw lx ji ly b lz ma kj mb mc md km me mf mg mh mi mj mk ml mm mn mo mp mq mr im bi translated">几年前的某个时候，人们开始意识到[3]我们可以计算一个可微指纹，而不是计算一个不可微指纹。然后，通过反向传播，我们不仅可以训练深度学习模型，还可以训练指纹生成函数本身。承诺将是学习更丰富的分子表示。</p><figure class="mt mu mv mw gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi nl"><img src="../Images/96b49e86a8ffd3f5f589c730145b7f28.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*aFL9A-wv-Oyj7N6aAfi0Vg.png"/></div></div><figcaption class="jc jd gj gh gi je jf bd b be z dk">Circular vs Neural fingerprints [3]</figcaption></figure><p id="9763" class="pw-post-body-paragraph lw lx ji ly b lz mx kj mb mc my km me mf mz mh mi mj na ml mm mn nb mp mq mr im bi translated">其思想是将相邻节点的特征聚集在一起。这就是“图形卷积”这个名字的由来，因为我们对每个原子的相邻原子进行卷积(执行某种聚合)。</p><p id="facf" class="pw-post-body-paragraph lw lx ji ly b lz mx kj mb mc my km me mf mz mh mi mj na ml mm mn nb mp mq mr im bi translated">我们可以使用<a class="ae nc" href="https://github.com/rusty1s/pytorch_geometric" rel="noopener ugc nofollow" target="_blank">py torch-Geometric</a>【4】实现上面提出的神经图指纹算法。以下实现允许批量训练(PyTorch-Geometric 将一批分子/图形建模为一个大的不连接图形)。</p><h2 id="d59b" class="nm lf ji bd lg nn no dn lk np nq dp lo mf nr ns lq mj nt nu ls mn nv nw lu nx bi translated">2a。原子特征和键连接(边指数)</h2><p id="f71c" class="pw-post-body-paragraph lw lx ji ly b lz ma kj mb mc md km me mf mg mh mi mj mk ml mm mn mo mp mq mr im bi translated">我们将使用这些 atom 特性:</p><p id="bec8" class="pw-post-body-paragraph lw lx ji ly b lz mx kj mb mc my km me mf mz mh mi mj na ml mm mn nb mp mq mr im bi translated">A)一个<a class="ae nc" href="https://en.wikipedia.org/wiki/Atomic_number" rel="noopener ugc nofollow" target="_blank">原子序数</a>(它也决定原子类型)</p><p id="55b8" class="pw-post-body-paragraph lw lx ji ly b lz mx kj mb mc my km me mf mz mh mi mj na ml mm mn nb mp mq mr im bi translated">b)连接在原子上的氢的数量。</p><p id="d926" class="pw-post-body-paragraph lw lx ji ly b lz mx kj mb mc my km me mf mz mh mi mj na ml mm mn nb mp mq mr im bi translated">这些是基本特性，但对我们的目的来说已经足够了。</p><figure class="mt mu mv mw gt iv"><div class="bz fp l di"><div class="nd ne l"/></div></figure><figure class="mt mu mv mw gt iv"><div class="bz fp l di"><div class="nd ne l"/></div></figure><p id="811c" class="pw-post-body-paragraph lw lx ji ly b lz mx kj mb mc my km me mf mz mh mi mj na ml mm mn nb mp mq mr im bi translated">最后，我们可以定义模型。</p><figure class="mt mu mv mw gt iv"><div class="bz fp l di"><div class="nd ne l"/></div></figure><p id="117a" class="pw-post-body-paragraph lw lx ji ly b lz mx kj mb mc my km me mf mz mh mi mj na ml mm mn nb mp mq mr im bi translated">我们可以测试我们的模型，以确保它的工作:</p><figure class="mt mu mv mw gt iv"><div class="bz fp l di"><div class="nd ne l"/></div></figure><h1 id="d356" class="le lf ji bd lg lh ng lj lk ll nh ln lo ko ni kp lq kr nj ks ls ku nk kv lu lv bi translated">3.通过反向传播学习指纹</h1><p id="b39b" class="pw-post-body-paragraph lw lx ji ly b lz ma kj mb mc md km me mf mg mh mi mj mk ml mm mn mo mp mq mr im bi translated">[3]中一个有趣的发现是，随机初始化的神经指纹在模拟化学特征方面与传统指纹一样好，甚至更好。</p><figure class="mt mu mv mw gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi ny"><img src="../Images/34f520df76e9ead4391b8d2e48833fa3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*mM6s3fQj3qpBhi4C3yFcXw.png"/></div></div><figcaption class="jc jd gj gh gi je jf bd b be z dk">Duvenaud et al. [3]</figcaption></figure><p id="83ac" class="pw-post-body-paragraph lw lx ji ly b lz mx kj mb mc my km me mf mz mh mi mj na ml mm mn nb mp mq mr im bi translated">如果随机初始化的指纹和传统指纹一样好，那么如果我们通过反向传播来训练指纹，它们肯定会做得更好。</p><p id="be19" class="pw-post-body-paragraph lw lx ji ly b lz mx kj mb mc my km me mf mz mh mi mj na ml mm mn nb mp mq mr im bi translated">这是希望和承诺，但我们必须确保我们不要在小数据集中过度拟合噪声。让我们在真实数据集上尝试我们的神经指纹。我们将使用 DeepChem [7]的 BACE [6]回归数据集。</p><figure class="mt mu mv mw gt iv"><div class="bz fp l di"><div class="nd ne l"/></div></figure><p id="2dae" class="pw-post-body-paragraph lw lx ji ly b lz mx kj mb mc my km me mf mz mh mi mj na ml mm mn nb mp mq mr im bi translated">我们现在在我们的神经指纹之上建立一个小的 MLP(多层感知器)。我们只给它一个隐藏层(维度 100):</p><figure class="mt mu mv mw gt iv"><div class="bz fp l di"><div class="nd ne l"/></div></figure><p id="7485" class="pw-post-body-paragraph lw lx ji ly b lz mx kj mb mc my km me mf mz mh mi mj na ml mm mn nb mp mq mr im bi translated">定义我们用于培训和验证的效用函数:</p><figure class="mt mu mv mw gt iv"><div class="bz fp l di"><div class="nd ne l"/></div></figure><p id="d2af" class="pw-post-body-paragraph lw lx ji ly b lz mx kj mb mc my km me mf mz mh mi mj na ml mm mn nb mp mq mr im bi translated">最后，我们的优化器和训练循环:</p><figure class="mt mu mv mw gt iv"><div class="bz fp l di"><div class="nd ne l"/></div><figcaption class="jc jd gj gh gi je jf bd b be z dk">Training loop</figcaption></figure><p id="133c" class="pw-post-body-paragraph lw lx ji ly b lz mx kj mb mc my km me mf mz mh mi mj na ml mm mn nb mp mq mr im bi translated">注意，当我们训练模型时，我们训练神经指纹以及它上面的线性层。</p><h1 id="256f" class="le lf ji bd lg lh ng lj lk ll nh ln lo ko ni kp lq kr nj ks ls ku nk kv lu lv bi translated">4.展望未来，以及当前的最新技术</h1><p id="dfc5" class="pw-post-body-paragraph lw lx ji ly b lz ma kj mb mc md km me mf mg mh mi mj mk ml mm mn mo mp mq mr im bi translated">上述数据集包含约 1000 个分子和 1 个靶标。目前的数据集有 10 万多个分子和 100 多个目标。因此，大规模多任务监督预训练可用于获得非常丰富的表示[8]。</p><p id="dc21" class="pw-post-body-paragraph lw lx ji ly b lz mx kj mb mc my km me mf mz mh mi mj na ml mm mn nb mp mq mr im bi translated">此外，人们开始使用无监督图预训练技术[9]，跟随 NLP 中无监督预训练的成功之路[10]。</p><figure class="mt mu mv mw gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi nz"><img src="../Images/28d71d597a4f30482d174629689b778f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*bAgefDmCH13-ZkjX-yGE7w.png"/></div></div><figcaption class="jc jd gj gh gi je jf bd b be z dk">Pretaining graph neural networks on millions of molecules</figcaption></figure><h1 id="9e23" class="le lf ji bd lg lh ng lj lk ll nh ln lo ko ni kp lq kr nj ks ls ku nk kv lu lv bi translated">5.结论</h1><p id="4142" class="pw-post-body-paragraph lw lx ji ly b lz ma kj mb mc md km me mf mg mh mi mj mk ml mm mn mo mp mq mr im bi translated">我们看到神经指纹可以用来代替传统指纹。随机初始化的神经指纹表现得和传统指纹一样好，甚至更好。如果有足够的数据并采取措施避免过度拟合，经过训练的神经指纹有可能形成更丰富的表示。</p><h1 id="cd8c" class="le lf ji bd lg lh ng lj lk ll nh ln lo ko ni kp lq kr nj ks ls ku nk kv lu lv bi translated">6.后续步骤</h1><p id="d36e" class="pw-post-body-paragraph lw lx ji ly b lz ma kj mb mc md km me mf mg mh mi mj mk ml mm mn mo mp mq mr im bi translated">在 LinkedIn 上与我联系，让我知道你是否最终使用了神经指纹。</p><h1 id="2bc6" class="le lf ji bd lg lh ng lj lk ll nh ln lo ko ni kp lq kr nj ks ls ku nk kv lu lv bi translated">参考</h1><p id="54bd" class="pw-post-body-paragraph lw lx ji ly b lz ma kj mb mc md km me mf mg mh mi mj mk ml mm mn mo mp mq mr im bi translated">[1] D 罗杰斯，m 哈恩。扩展连接指纹。化学信息与建模杂志，50(5):742–754，2010。</p><p id="aa12" class="pw-post-body-paragraph lw lx ji ly b lz mx kj mb mc my km me mf mz mh mi mj na ml mm mn nb mp mq mr im bi translated">[2] G .兰德鲁姆。RDKit:开源化学信息学。【www.rdkit.org】T2。【于 2013 年 4 月 11 日获取】。</p><p id="6270" class="pw-post-body-paragraph lw lx ji ly b lz mx kj mb mc my km me mf mz mh mi mj na ml mm mn nb mp mq mr im bi translated">[3]迪韦瑙德、马克劳林、阿吉莱拉-伊帕拉吉雷、戈麦斯-邦巴雷里、希尔泽尔、阿斯普鲁-古齐克、亚当斯。用于学习分子指纹的图上卷积网络。<em class="oa"> arXiv 预印本</em> arXiv:1509.09292，2015。</p><p id="4f9e" class="pw-post-body-paragraph lw lx ji ly b lz mx kj mb mc my km me mf mz mh mi mj na ml mm mn nb mp mq mr im bi translated">[4] M .菲，J. E .伦森。PyTorch 几何图形的快速图形表示学习。<em class="oa"> arXiv 预印本</em> arXiv:1903.02428，2019。</p><p id="6be2" class="pw-post-body-paragraph lw lx ji ly b lz mx kj mb mc my km me mf mz mh mi mj na ml mm mn nb mp mq mr im bi translated">[5]鲁梅尔哈特、辛顿、威廉斯。通过反向传播误差学习表征。<em class="oa">性质</em> <strong class="ly jj"> 323，</strong>533–536(1986)doi:10.1038/323533 A0</p><p id="c138" class="pw-post-body-paragraph lw lx ji ly b lz mx kj mb mc my km me mf mz mh mi mj na ml mm mn nb mp mq mr im bi translated">[6] R. Vassar，D. M. Kovacs，Y. Riquang，P. C. Wong。健康和阿尔茨海默病中的β-分泌酶 BACE:调节、细胞生物学、功能和治疗潜力。<a class="ae nc" href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2879048/#" rel="noopener ugc nofollow" target="_blank"> <em class="oa"> J 神经科学</em> </a> <em class="oa">。</em> 2009 年 10 月 14 日；29(41): 12787–12794.</p><p id="256d" class="pw-post-body-paragraph lw lx ji ly b lz mx kj mb mc my km me mf mz mh mi mj na ml mm mn nb mp mq mr im bi translated">[7] DeepChem:药物发现和量子化学的深度学习模型。https://github . com/deep chem/deep chem，访问时间:2017–09–27。</p><p id="7358" class="pw-post-body-paragraph lw lx ji ly b lz mx kj mb mc my km me mf mz mh mi mj na ml mm mn nb mp mq mr im bi translated">[8] B. Ramsundar 等人,《药物发现的大规模多任务网络》。arXiv 预印本 : 1502.02072，2015</p><p id="dda2" class="pw-post-body-paragraph lw lx ji ly b lz mx kj mb mc my km me mf mz mh mi mj na ml mm mn nb mp mq mr im bi translated">[9]胡、刘、戈麦斯、兹特尼克、梁、、莱斯科维奇。图形神经网络的预训练策略。<em class="oa"> arXiv 预印本</em> : 1905.12265，2019</p><p id="19ba" class="pw-post-body-paragraph lw lx ji ly b lz mx kj mb mc my km me mf mz mh mi mj na ml mm mn nb mp mq mr im bi translated">[10] J .德夫林、m .张、k .李、k .图塔诺瓦。BERT:用于语言理解的深度双向转换器的预训练。arXiv 预印本 : 1810.04805，2018</p></div></div>    
</body>
</html>