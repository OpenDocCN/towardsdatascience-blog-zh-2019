<html>
<head>
<title>A Dog Detector and Breed Classifier</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">一种狗检测器和品种分类器</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/a-dog-detector-and-breed-classifier-4feb99e1f852?source=collection_archive---------6-----------------------#2019-01-30">https://towardsdatascience.com/a-dog-detector-and-breed-classifier-4feb99e1f852?source=collection_archive---------6-----------------------#2019-01-30</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><p id="ffc5" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">在像物理学这样的领域，事情变得越来越难，以至于除非用高度简化的术语，否则很难理解前沿发生了什么。然而，在计算机科学中，尤其是人工智能，世界各地的人们经过 70 多年慢慢积累起来的知识仍然是非常直观的。事实上，由于高级编程语言、框架和重视以易于访问的格式共享知识的社区，进入这个领域变得越来越容易了！</p><p id="0c54" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">在这篇博文中，我们将做一些十年前不可能的事情，但像我这样的学生现在可以用几行 Python 代码完成；建立一个系统，可以识别照片中是人还是狗，并告诉我们它是什么品种(或者最像！).</p><p id="cbaa" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">你可以在我的<a class="ae kl" href="https://github.com/HenryDashwood/dog_breed_classifier" rel="noopener ugc nofollow" target="_blank"> Github </a>找到代码。</p><h1 id="7269" class="km kn iq bd ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj bi translated">探测人和狗</h1><p id="e2b5" class="pw-post-body-paragraph jn jo iq jp b jq lk js jt ju ll jw jx jy lm ka kb kc ln ke kf kg lo ki kj kk ij bi translated">有几种方法可以解决图像分类问题。在这篇博文中，我们将使用卷积神经网络来确定狗的品种。在此之前，我们将使用<a class="ae kl" href="https://www.cs.cmu.edu/~efros/courses/LBMV07/Papers/viola-cvpr-01.pdf" rel="noopener ugc nofollow" target="_blank"> Viola-Jones haar 级联分类器方法</a>来检测照片中是否包含人脸。</p><p id="1223" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">CNN 现在得到了最多的关注，但是你以前肯定见过 Viola-Jones 方法。每当你打开相机，它就会在人脸周围画出方框。<a class="ae kl" href="https://www.youtube.com/watch?v=uEJ71VlUmMQ" rel="noopener ugc nofollow" target="_blank">诺丁汉大学的迈克·庞德做了一个很棒的视频讲解，可以在这里观看</a>。简而言之，我们找出哪些过滤器最擅长区分人脸和非人脸。最佳滤波器应用于图像的每个区域。如果一个区域通过，它将在下一个过滤器上被测试。对大约 6000 个其他过滤器重复这一过程，如果一个区域通过了所有这些过滤器，我们就断定它包含一张脸。</p><p id="2904" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">报纸上还有很多其他的东西。例如，作者开发了一种简单而聪明的方法来有效地计算图像中某个区域的像素值。我们所需要做的就是从一个名为<a class="ae kl" href="https://opencv.org/" rel="noopener ugc nofollow" target="_blank"> OpenCV </a>的库中下载这些预先训练好的滤镜，并通过它们运行我们的照片。</p><pre class="lp lq lr ls gt lt lu lv lw aw lx bi"><span id="7a62" class="ly kn iq lu b gy lz ma l mb mc">import cv2</span><span id="8272" class="ly kn iq lu b gy md ma l mb mc">def face_detector(img_path):<br/>    img = cv2.imread(img_path)<br/>    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)<br/>    faces = face_cascade.detectMultiScale(gray)<br/>    return len(faces) &gt; 0</span></pre><p id="7a36" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">就这样，它计算出图像中有多少张人脸！</p><p id="3d46" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">不幸的是，OpenCV 的好人们没有为我们建立一些好的 haar 过滤器。相反，我们将使用 ImageNet，这是一个由 1400 万张图片组成的数据集，分为 2 万个类别。在过去十年中，它一直是领先的计算机视觉基准之一。我们将使用一个较小版本的 ImageNet，包含 1000 个类别，其中类别 151–268 是狗的品种。</p><p id="f3fd" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我们可以使用一个名为 Resnet 的预训练 CNN，我们可以从 Keras 的网站上下载(稍后会有更多关于 Keras 的内容)。</p><pre class="lp lq lr ls gt lt lu lv lw aw lx bi"><span id="0db8" class="ly kn iq lu b gy lz ma l mb mc">from keras.applications.resnet50 import ResNet50</span><span id="394d" class="ly kn iq lu b gy md ma l mb mc">ResNet50_model_ = ResNet50(weights='imagenet')</span></pre><p id="a440" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我们需要做一些预处理，以便模型可以对我们的图像做出预测:</p><pre class="lp lq lr ls gt lt lu lv lw aw lx bi"><span id="b2fa" class="ly kn iq lu b gy lz ma l mb mc">from keras.preprocessing import image             <br/>from tqdm import tqdm</span><span id="8b44" class="ly kn iq lu b gy md ma l mb mc">def path_to_tensor(img_path):<br/>    img = image.load_img(img_path, target_size=(224, 224))<br/>    x = image.img_to_array(img)<br/>    return np.expand_dims(x, axis=0)</span><span id="5b7a" class="ly kn iq lu b gy md ma l mb mc">def paths_to_tensor(img_paths):<br/>    list_of_tensors = [path_to_tensor(img_path) for img_path in tqdm(img_paths)]<br/>    return np.vstack(list_of_tensors)</span></pre><p id="3ec6" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">现在，我们可以看到模型做出的预测是否符合某个犬种类别:</p><pre class="lp lq lr ls gt lt lu lv lw aw lx bi"><span id="ed4d" class="ly kn iq lu b gy lz ma l mb mc">from keras.applications.resnet50 import preprocess_input, decode_predictions</span><span id="68de" class="ly kn iq lu b gy md ma l mb mc">def ResNet50_predict_labels(img_path):<br/>    img = preprocess_input(path_to_tensor(img_path))<br/>    return np.argmax(ResNet50_model_.predict(img))</span><span id="7338" class="ly kn iq lu b gy md ma l mb mc">def dog_detector(img_path):<br/>    prediction = ResNet50_predict_labels(img_path)<br/>    return ((prediction &lt;= 268) &amp; (prediction &gt;= 151))</span></pre><p id="a7f4" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">最后，当我在 100 张样本图像上测试检测器时，人脸和狗的检测器没有任何假阴性。狗探测器也没有任何误报！</p><figure class="lp lq lr ls gt mf gh gi paragraph-image"><div class="gh gi me"><img src="../Images/481e4372d72159451b9f0b3a34f730f8.png" data-original-src="https://miro.medium.com/v2/resize:fit:654/format:webp/1*cLTjcSXqx2GFFWebr3stbw.png"/></div><figcaption class="mi mj gj gh gi mk ml bd b be z dk">Our human face detector results</figcaption></figure><figure class="lp lq lr ls gt mf gh gi paragraph-image"><div class="gh gi me"><img src="../Images/0b40ae5efbcefa08d77d25a9297094b1.png" data-original-src="https://miro.medium.com/v2/resize:fit:654/format:webp/1*4SOLnFwPfy-x0kJ50RcnqA.png"/></div><figcaption class="mi mj gj gh gi mk ml bd b be z dk">Our dog detector results</figcaption></figure><h2 id="bcd0" class="ly kn iq bd ko mm mn dn ks mo mp dp kw jy mq mr la kc ms mt le kg mu mv li mw bi translated">决定狗的品种</h2><p id="c4dd" class="pw-post-body-paragraph jn jo iq jp b jq lk js jt ju ll jw jx jy lm ka kb kc ln ke kf kg lo ki kj kk ij bi translated">所以我们可以说在这幅画中有某种狗或人。但我本可以做到的。我能说出 117 个不同品种的区别吗？可能不能。让我们看看是否可以用机器学习来区分。</p><p id="c253" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">是时候破解 Keras 库了。像 Tensorflow、Pytorch、Theano 或 CNTK 这样的框架为我们执行机器学习操作。Keras 是一个建立在这些之上的库，所以我们可以用一种更简洁易读的方式编写代码。</p><p id="3937" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">以下是我们在 Keras 对 CNN 的定义:</p><pre class="lp lq lr ls gt lt lu lv lw aw lx bi"><span id="9e1b" class="ly kn iq lu b gy lz ma l mb mc">model = Sequential()</span><span id="877e" class="ly kn iq lu b gy md ma l mb mc">model.add(Conv2D(32, (3, 3), input_shape = (224, 224, 3), use_bias=False))<br/>model.add(BatchNormalization())<br/>model.add(Activation('relu'))<br/>model.add(MaxPooling2D(pool_size = (2,2)))<br/>model.add(Dropout(0.2))</span><span id="5999" class="ly kn iq lu b gy md ma l mb mc">model.add(Conv2D(64, (2,2), use_bias=False))<br/>model.add(BatchNormalization())<br/>model.add(Activation('relu'))<br/>model.add(MaxPooling2D(pool_size = (2,2)))<br/>model.add(Dropout(0.2))</span><span id="90c7" class="ly kn iq lu b gy md ma l mb mc">model.add(Conv2D(128, (2,2), use_bias=False))<br/>model.add(BatchNormalization())<br/>model.add(Activation('relu'))<br/>model.add(MaxPooling2D(pool_size=(2,2)))<br/>model.add(Dropout(0.2))</span><span id="fd35" class="ly kn iq lu b gy md ma l mb mc">model.add(Flatten())</span><span id="3f61" class="ly kn iq lu b gy md ma l mb mc">model.add(Dense(512, use_bias=False))<br/>model.add(BatchNormalization())<br/>model.add(Activation('relu'))<br/>model.add(Dropout(0.2))</span><span id="e3e2" class="ly kn iq lu b gy md ma l mb mc">model.add(Dense(256, use_bias=False))<br/>model.add(BatchNormalization())<br/>model.add(Activation('relu'))<br/>model.add(Dropout(0.2))</span><span id="62e0" class="ly kn iq lu b gy md ma l mb mc">model.add(Dense(len(dog_names), activation='softmax'))</span><span id="67bc" class="ly kn iq lu b gy md ma l mb mc">model.summary()</span></pre><p id="de3d" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">这是怎么回事？我们有 3 个卷积层，后面是 3 个全连接层。这最后一层有一个 softmax 激活函数，这意味着我们的输出将是一个有 1000 个值的概率分布，我们使用的 ImageNet-1000 数据库中的每个可能结果都有一个值。</p><p id="b0d3" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">接下来我们将定义优化器和损失函数。这一行有许多术语，所以我将试着解释一下。</p><ul class=""><li id="6ca7" class="mx my iq jp b jq jr ju jv jy mz kc na kg nb kk nc nd ne nf bi translated"><em class="ng"> SGD </em>或随机梯度下降是最好的比喻，滚下一座山。如果你找到了下去的路，继续走。如果没有，请尝试不同的方向。请记住，在多维数学世界中，不仅仅只有 3 个维度可供选择。当你在某个方向达到局部最小值时，你就会知道，因为你所在的曲线的梯度会变小。这些都是在引擎盖下为我们处理的。</li><li id="ffac" class="mx my iq jp b jq nh ju ni jy nj kc nk kg nl kk nc nd ne nf bi translated"><em class="ng"> lr </em>是我们的学习率。给定一条新信息，我们应该在多大程度上改变模型？小比率意味着缓慢的训练，但大比率意味着我们可能会跳过最佳解决方案到山谷的另一边。最佳解决方案是使用…</li><li id="6648" class="mx my iq jp b jq nh ju ni jy nj kc nk kg nl kk nc nd ne nf bi translated"><em class="ng">衰减</em>意味着我们开始时学习率很高，当我们接近山/谷底部时，学习率随着每个时期而降低。</li><li id="847f" class="mx my iq jp b jq nh ju ni jy nj kc nk kg nl kk nc nd ne nf bi translated"><em class="ng"> clipnorm </em>用于裁剪渐变，这样它们就不会变得过大或过浅，这会使渐变下降变得困难。<em class="ng"> clipnorm </em>如果发生这种情况，剪辑值，但也缩放梯度，所以我们没有剪辑一些而不是其他的</li><li id="6687" class="mx my iq jp b jq nh ju ni jy nj kc nk kg nl kk nc nd ne nf bi translated"><em class="ng">涅斯捷罗夫</em>动量是我们向前看了一步后计算的梯度。这有助于我们更快地训练。</li><li id="64c0" class="mx my iq jp b jq nh ju ni jy nj kc nk kg nl kk nc nd ne nf bi translated"><em class="ng">分类 _ 交叉熵</em>是损失函数。这意味着我们正在判断模型的性能，以及我们需要在多大程度上调整它，这取决于我们在检查结果后收到了多少新信息。如果我确定我见过一只金毛寻回犬，并且我是对的，那么就没有多少新的信息被创造出来。如果我不确定，那么已经创造了一些。如果我确定它不是金毛寻回犬，但它确实是，那么大量的信息就产生了。</li><li id="18df" class="mx my iq jp b jq nh ju ni jy nj kc nk kg nl kk nc nd ne nf bi translated"><em class="ng">准确性</em>是我们将监控的指标。它就像罐头上说的那样。它<em class="ng">为多类分类问题</em>计算所有预测的平均准确率。换句话说，有多少狗被正确分类。</li></ul><pre class="lp lq lr ls gt lt lu lv lw aw lx bi"><span id="6429" class="ly kn iq lu b gy lz ma l mb mc">sgd = SGD(lr=0.01, clipnorm=1, decay=1e-6, <br/>          momentum = 0.9, nesterov=True)</span><span id="f49d" class="ly kn iq lu b gy md ma l mb mc">model.compile(optimizer=sgd, loss='categorical_crossentropy',   <br/>              metrics=['accuracy'])</span></pre><p id="bf42" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">然后我们就好训练了！</p><pre class="lp lq lr ls gt lt lu lv lw aw lx bi"><span id="09ee" class="ly kn iq lu b gy lz ma l mb mc">checkpointer = ModelCheckpoint(     <br/>             filepath='saved_models/weights.best.from_scratch.hdf5', <br/>             verbose=1, save_best_only=True)</span><span id="1713" class="ly kn iq lu b gy md ma l mb mc">model.fit(train_tensors, train_targets, <br/>          validation_data=(valid_tensors, valid_targets), epochs=5,   <br/>          batch_size=20, callbacks=[checkpointer], verbose=1)</span></pre><p id="f9f7" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">如果我们运行 6 个时期，会发生以下情况:</p><figure class="lp lq lr ls gt mf gh gi paragraph-image"><div class="gh gi nm"><img src="../Images/6a0b52f564b7710be51483a4a958a192.png" data-original-src="https://miro.medium.com/v2/resize:fit:1042/format:webp/1*fDk1NrMmUH_8D2hhs90lMQ.png"/></div><figcaption class="mi mj gj gh gi mk ml bd b be z dk">The training and validation losses as our model trained</figcaption></figure><p id="5740" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">培训损失随着我们的培训而改善，但验证损失看起来将趋于平缓。这意味着如果我们长时间训练它，我们的模型将开始过度拟合。</p><p id="62f8" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">在测试集上，该模型正确预测了它看到的 3.7%的狗的品种。这比随机猜测要好 4 倍，但仍有相当大的改进空间。</p><h2 id="0d5f" class="ly kn iq bd ko mm mn dn ks mo mp dp kw jy mq mr la kc ms mt le kg mu mv li mw bi translated">迁移学习</h2><p id="21e0" class="pw-post-body-paragraph jn jo iq jp b jq lk js jt ju ll jw jx jy lm ka kb kc ln ke kf kg lo ki kj kk ij bi translated">进入迁移学习。我们可以采取一个预训练的模型，就像我们对探测器所做的那样，并在它的末端添加我们自己的层来为我们做出预测。我们将使用的模型是 Resnet50，已经由微软的研究人员在更大的机器上进行了训练，时间超过了我所能获得的时间。</p><p id="a34e" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我们可以下载权重，将它们存储在本地，然后像这样解包特性:</p><pre class="lp lq lr ls gt lt lu lv lw aw lx bi"><span id="1306" class="ly kn iq lu b gy lz ma l mb mc">bottleneck_features = np.load(<br/>                           'bottleneck_features/DogResnet50Data.npz'<br/>                           )<br/>train_Resnet50 = bottleneck_features['train']<br/>valid_Resnet50 = bottleneck_features['valid']<br/>test_Resnet50 = bottleneck_features['test']</span></pre><p id="e666" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">使用 Keras 很容易获得 Resnet50 并在它的末尾添加我们自己的层。同样，我们希望我们的输出是每个品种的概率分布</p><pre class="lp lq lr ls gt lt lu lv lw aw lx bi"><span id="7320" class="ly kn iq lu b gy lz ma l mb mc">Resnet50_model = Sequential()<br/>Resnet50_model.add(<br/>        GlobalAveragePooling2D(input_shape=train_Resnet50.shape[1:])<br/>        )<br/>Resnet50_model.add(Dense(133, activation='softmax'))</span></pre><p id="b0cc" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">之后就和以前一样了</p><pre class="lp lq lr ls gt lt lu lv lw aw lx bi"><span id="d1a4" class="ly kn iq lu b gy lz ma l mb mc">Resnet50_model.compile(<br/>                       loss='categorical_crossentropy', <br/>                       optimizer=sgd, <br/>                       metrics=['accuracy']<br/>                      )</span><span id="6b9b" class="ly kn iq lu b gy md ma l mb mc">checkpointer = ModelCheckpoint(<br/>                 filepath='saved_models/weights.best.Resnet50.hdf5', <br/>                 verbose=1, <br/>                 save_best_only=True<br/>                 )</span><span id="02bd" class="ly kn iq lu b gy md ma l mb mc">resnet50_hist = Resnet50_model.fit(<br/>                    train_Resnet50, <br/>                    train_targets, <br/>                    validation_data=(valid_Resnet50, valid_targets),<br/>                    epochs=20, <br/>                    batch_size=56, <br/>                    callbacks=[checkpointer],    <br/>                    verbose=1<br/>                    )</span></pre><figure class="lp lq lr ls gt mf gh gi paragraph-image"><div class="gh gi nn"><img src="../Images/d7de7577cafba803dabae2fd483305be.png" data-original-src="https://miro.medium.com/v2/resize:fit:1018/format:webp/1*KPiUmQEPHntKbt0AtWN5kQ.png"/></div></figure><p id="4654" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">这种模式有多好？在测试集上，它正确预测了 84%的品种！这比我和我的疯狗家庭得到的要多得多。</p><h2 id="5e30" class="ly kn iq bd ko mm mn dn ks mo mp dp kw jy mq mr la kc ms mt le kg mu mv li mw bi translated">尝试一下</h2><p id="a225" class="pw-post-body-paragraph jn jo iq jp b jq lk js jt ju ll jw jx jy lm ka kb kc ln ke kf kg lo ki kj kk ij bi translated">将我们的人类和狗检测器与品种预测器结合起来，让我们在一些照片上尝试一下。</p><figure class="lp lq lr ls gt mf gh gi paragraph-image"><div class="gh gi no"><img src="../Images/5f88446cbd182a411ffbcde0f2f0fe1a.png" data-original-src="https://miro.medium.com/v2/resize:fit:902/format:webp/1*I5Xgfs50BTX8-wbBH-Z_HA.png"/></div><figcaption class="mi mj gj gh gi mk ml bd b be z dk">Correct! Not even the Barbour jacket confuses it</figcaption></figure><figure class="lp lq lr ls gt mf gh gi paragraph-image"><div class="gh gi np"><img src="../Images/e5ba4f5a40af6c95c90f563c529b0010.png" data-original-src="https://miro.medium.com/v2/resize:fit:758/format:webp/1*-vEZoRhUNgvRnDGeC19SbQ.png"/></div><figcaption class="mi mj gj gh gi mk ml bd b be z dk">Correct! Ironically, my it’s my dog who is overfitting in this photo (those ducks are plastic!)</figcaption></figure><figure class="lp lq lr ls gt mf gh gi paragraph-image"><div class="gh gi nq"><img src="../Images/10af6e88618676d3a5ed544e80d8e9a5.png" data-original-src="https://miro.medium.com/v2/resize:fit:956/format:webp/1*ce-zHHHp-Pb7N4e1w2eCrQ.png"/></div><figcaption class="mi mj gj gh gi mk ml bd b be z dk">Wrong, this is actually a Border Collie.</figcaption></figure><figure class="lp lq lr ls gt mf gh gi paragraph-image"><div class="gh gi nr"><img src="../Images/872d2242421e3523b246ded0213df9ee.png" data-original-src="https://miro.medium.com/v2/resize:fit:550/format:webp/1*jkzB7lcGEZtbMw1VvUI4kg.jpeg"/></div><figcaption class="mi mj gj gh gi mk ml bd b be z dk">But he does look like an Australian Shepherd</figcaption></figure><figure class="lp lq lr ls gt mf gh gi paragraph-image"><div class="gh gi ns"><img src="../Images/56e28dc6c3c73286e4ecf9fc49a4407b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1328/format:webp/1*ghmD3J8rPPYN5bOFcMUK8g.png"/></div></figure><figure class="lp lq lr ls gt mf gh gi paragraph-image"><div class="gh gi nt"><img src="../Images/36a01f153b7f0e9a09edb28a608951cf.png" data-original-src="https://miro.medium.com/v2/resize:fit:366/format:webp/1*av-dZmmD93TyvUAA7NQ4jg.jpeg"/></div><figcaption class="mi mj gj gh gi mk ml bd b be z dk">Silky Terrier, who knew?</figcaption></figure><figure class="lp lq lr ls gt mf gh gi paragraph-image"><div role="button" tabindex="0" class="nv nw di nx bf ny"><div class="gh gi nu"><img src="../Images/62fa541ff81878852d56fd86ad4d88bd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*1Qjhi-MMZrl1vnleiM3RZQ.png"/></div></div><figcaption class="mi mj gj gh gi mk ml bd b be z dk">It’s got a bit confused by Pongo…</figcaption></figure><p id="47b9" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">然而，如果我们仔细观察模型的预测，我们可以看到达尔马提是第二名，所以不算太坏。</p><pre class="lp lq lr ls gt lt lu lv lw aw lx bi"><span id="3ff3" class="ly kn iq lu b gy lz ma l mb mc">bottleneck_feature = extract_Resnet50(path_to_tensor('images/pongo.png'))<br/>predicted_vector = Resnet50_model.predict(bottleneck_feature)</span><span id="fb09" class="ly kn iq lu b gy md ma l mb mc">top_predictions = np.argpartition(predicted_vector.flatten(), -4)[-4:]<br/>for i in top_predictions:<br/>    print(dog_names[i])</span></pre><figure class="lp lq lr ls gt mf gh gi paragraph-image"><div class="gh gi nz"><img src="../Images/4d692ea62c5c35f57506d58cc9d16f38.png" data-original-src="https://miro.medium.com/v2/resize:fit:640/format:webp/1*Wtp9uRWJ6tGm_zsb_ojhLA.png"/></div></figure><figure class="lp lq lr ls gt mf gh gi paragraph-image"><div class="gh gi oa"><img src="../Images/98d549eb9c4851dac5b6aa5dc5ce54c8.png" data-original-src="https://miro.medium.com/v2/resize:fit:786/format:webp/1*phJ2ciHr7aZKG1f57gbLsQ.png"/></div><figcaption class="mi mj gj gh gi mk ml bd b be z dk">Well you can’t win them all!</figcaption></figure><h2 id="c77a" class="ly kn iq bd ko mm mn dn ks mo mp dp kw jy mq mr la kc ms mt le kg mu mv li mw bi translated">潜在的改进</h2><p id="0a87" class="pw-post-body-paragraph jn jo iq jp b jq lk js jt ju ll jw jx jy lm ka kb kc ln ke kf kg lo ki kj kk ij bi translated">我们在这里可以做更多的事情。世界上最好的模型在有更多可能类别的 ImageNet 版本上获得了比我更好的测试精度。我们可以通过租用多个 GPU、获取更多带标签的图像等来获得一些改进，但这基本上归结为花钱，在概念上不是很有趣。</p><p id="3a45" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我们可以改进这个模型的一个方法是使用数据扩充。例如，通过翻转、移动、旋转、变暗、变亮、添加噪声和许多其他可能的操作，我们可以人为地增加模型可以暴露的图像的数量。我在这个项目中试验了数据扩充，结果令人失望。有可能通过一些参数调整和更长时间的训练，我会看到一些改善。</p><p id="13e3" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我们可以改变 CNN 本身。有可能更多的层，更多的特征，不同的损失函数，学习率和其他各种变化会使它表现得更好。深度学习的很大一部分是对模型进行修改，只有在它确实改善了事情的情况下才进行学习。如果我有更多的 GPU 时间，我可能会尝试使用网格搜索在一夜之间系统地实验不同的超参数。</p><h2 id="f471" class="ly kn iq bd ko mm mn dn ks mo mp dp kw jy mq mr la kc ms mt le kg mu mv li mw bi translated">结论</h2><p id="ae18" class="pw-post-body-paragraph jn jo iq jp b jq lk js jt ju ll jw jx jy lm ka kb kc ln ke kf kg lo ki kj kk ij bi translated">在本帖中，我们有:</p><ul class=""><li id="de69" class="mx my iq jp b jq jr ju jv jy mz kc na kg nb kk nc nd ne nf bi translated">从 ImageNet 加载并预处理图像。</li><li id="f85a" class="mx my iq jp b jq nh ju ni jy nj kc nk kg nl kk nc nd ne nf bi translated">加载了一些预训练的 haar 级联分类器，以便使用 Viola Jones 方法检测人脸。</li><li id="c9c7" class="mx my iq jp b jq nh ju ni jy nj kc nk kg nl kk nc nd ne nf bi translated">加载了一个预先训练好的 CNN 来探测狗。</li><li id="1e4b" class="mx my iq jp b jq nh ju ni jy nj kc nk kg nl kk nc nd ne nf bi translated">从头开始编写和训练了一个 CNN 来对狗的品种进行分类。这在测试集上成功了 3.7%，这听起来很低，但比机会好 4 倍。</li><li id="3469" class="mx my iq jp b jq nh ju ni jy nj kc nk kg nl kk nc nd ne nf bi translated">使用迁移学习从根本上改善了 CNN 的性能，使其在测试集上的准确率达到 84%。</li><li id="ba86" class="mx my iq jp b jq nh ju ni jy nj kc nk kg nl kk nc nd ne nf bi translated">用我自己的几张照片测试了这个模型。</li><li id="d564" class="mx my iq jp b jq nh ju ni jy nj kc nk kg nl kk nc nd ne nf bi translated">讨论了未来改进模型的方法。</li></ul><p id="16c9" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">也许你在这篇文章中学到了一些东西。我从写作中学到了很多。如果你发现了一个错误，或者认为有些东西可以更好地措辞，让我知道，我会更新它！</p><figure class="lp lq lr ls gt mf gh gi paragraph-image"><div role="button" tabindex="0" class="nv nw di nx bf ny"><div class="gh gi ob"><img src="../Images/444a898346b94601f87405ba3cf99c2a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*FmEDv3if0FnNjiUnnq7A9Q.jpeg"/></div></div><figcaption class="mi mj gj gh gi mk ml bd b be z dk">Happy Coding!</figcaption></figure></div></div>    
</body>
</html>