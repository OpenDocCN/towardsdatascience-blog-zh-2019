# 2019 年即将结束。AI 的下一步是什么？

> 原文：<https://towardsdatascience.com/2019-is-coming-to-an-end-whats-next-for-ai-3a4cd45f70aa?source=collection_archive---------46----------------------->

## 深度学习和人工智能伦理的限制垄断了对人工智能未来的讨论

![](img/93d6c0067f070ec1701767770aad23a1.png)

AI Now and AI Index 2019 Reports

2019 年即将结束，两份最着名的人工智能研究报告-[**《人工智能 2019 年报告》**](https://ainowinstitute.org/AI_Now_2019_Report.pdf) 和 [**《人工智能指数 2019**](https://hai.stanford.edu/ai-index/2019)-已经出炉。他们对人工智能的技术水平有什么看法？**AI 下一步走向何方？**我会试着在这篇短文中总结一下。

先说 AI Index 2019，由斯坦福大学**以人为中心的人工研究所**开发。作为今年的一个新事物，人工智能指数首次包括了两个强大的数据可视化工具:

*   [**全球人工智能活力工具**](http://vibrancy.aiindex.org/) ，允许您在包括 R & D、经济、包容性在内的三个指标下比较各国围绕人工智能的活动。

![](img/533194eccda25e1c1dbd282a6b2aaf26.png)

Ai Vibrancy Dashboard example

*   [**ArXiv Monitor**](http://arxiv.aiindex.org/)，一个全论文搜索引擎，跟踪 ArXiv 上发表的人工智能论文的指标。

![](img/9e7492732bd329bbc3b889c151a634b2.png)

ArXiv Monitor search engine

通过使用这些工具，任何人都可以深入了解有关国家或学科人工智能状况的详细信息，但**我将尝试在这里列出一些我认为更有趣的报告要点，同时将它们与一些个人想法或我与该领域一些专家分享的想法进行交叉**:

*   中国现在每年发表的人工智能论文和欧洲一样多，已经在 2006 年超过了美国。
*   出席人工智能会议的人数继续大幅增加。例如，2019 年 NeuIPS 的与会者超过 13，000 人，比 2018 年增加了 41%(相对于 2012 年增加了 800%)。
*   2012 年后，**人工智能计算能力每 3.4 个月翻一番**。也就是说，该报告还提到“在一些广泛的自然语言处理分类任务上，如 SuperGLUE 和 SQuAD2.0 基准测试中所捕获的，进展非常迅速；**在一些需要推理的 NLP 任务上，性能仍然较低**，例如 AI2 推理挑战，或者人类水平的概念学习任务，例如 Omniglot 挑战。

在与一些专家讨论这些数字时，他们得到的感觉是:

*   **纸张原稿量明显减少**。
*   **大量的论文现在只关注通过调整模型，甚至通过应用蛮力(都包括数据集规模或计算能力)来展示对先前工作的微小改进**。

我个人认识的专家似乎没有指出那个方向，正如你在[这篇文章](https://www.wired.com/story/sobering-message-future-ai-party/)中看到的，Yoshua Bengio 警告说“**进展正在放缓，巨大的挑战仍然存在，简单地将更多的计算机投入到一个问题中是不可持续的**”。其他文章，比如来自**麻省理工科技评论**的这篇文章**进一步暗示深度学习的时代可能会结束**。

还有，就像我在我的文章《[深度学习是不是太大太失败了？](/is-deep-learning-too-big-to-fail-8930505d7ab1?source=your_stories_page---------------------------)“看起来**深度学习模型变得越来越庞大，而规模准确性却没有从中受益太多**。

另一个寻求进步的有趣领域是教育。虽然**人工智能培训**(传统大学和在线)**的报名人数正在增长**，但我仍然发现**两个令人担忧的领域**。其中一个在 AI Index 2019 报告要点中提到，另一个没有提到:

*   人工智能的多样性仍然是一个问题。特别是性别的多样性，女性在 2018 年新聘教师或人工智能博士获得者中所占比例不到 20%。
*   虽然该报告对人工智能人才给予了大量关注，但另一个相关主题却被忽略了，即政府和公司如何培训他们的非技术人才为人工智能做准备。实际上，AI Now 2019 报告的执行摘要明确指出“**算法管理技术在工作场所的传播正在增加工人和雇主之间的权力不对称。人工智能不仅威胁到不成比例地取代低收入者，而且威胁到降低工资、工作保障和其他对那些最需要的人的保护。**

最后，人工智能指数报告强调指出了一个在过去几个月中非常明显的趋势。人工智能伦理正变得与可解释性和可解释性非常相关，成为最常提到的伦理挑战。这让我想到了第二份报告, **AI Now 2019 报告**，该报告重点关注道德问题。让我来总结一下我认为第二份报告中最相关的几点。首先，一些执行要点:

*   人工智能的伦理压力主要来自社区、记者和研究人员，而不是公司本身。
*   **虽然正在努力监管人工智能，但政府对监控的采用超过了他们**。
*   **人工智能投资在气候变化(注意之前提到的计算能力增长率)以及地缘政治和不平等加剧方面有着深远的影响**。

其次，关于建议，作者明确表示，像**影响识别或面部识别这样的技术应该被禁止或不使用，同时在可能影响人们生活和获得机会的敏感环境**中不受管制。**关于偏见，作者指出，研究应该超越技术修正**以解决更广泛的政治后果。

虽然我同意，**但我真诚地认为还有另一件重要的事情需要考虑，那就是偏倚控制应该从研究转向商业实施**，将这与论文的另一项建议联系起来，即**让数据科学家对与他们的模型和数据相关的潜在风险和危害负责**。

当然，报告涉及更多的主题，我将非常乐意讨论你感兴趣的任何相关方面。对你来说，这两份报告的亮点是什么？