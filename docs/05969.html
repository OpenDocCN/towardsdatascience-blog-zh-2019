<html>
<head>
<title>Neural Networks: Generalizing Abstractions</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">神经网络:概括抽象</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/neural-networks-generalizing-abstractions-7f4574f1619a?source=collection_archive---------23-----------------------#2019-08-30">https://towardsdatascience.com/neural-networks-generalizing-abstractions-7f4574f1619a?source=collection_archive---------23-----------------------#2019-08-30</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><figure class="gl gn jo jp jq jr gh gi paragraph-image"><div class="gh gi jn"><img src="../Images/eba0396c0e8fa54abc6900536044eb7b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Dc4sbX9IJcw48zL1y3yYrQ.jpeg"/></div><figcaption class="ju jv gj gh gi jw jx bd b be z dk"><a class="ae jy" href="https://unsplash.com/photos/XookgCxFw6Q" rel="noopener ugc nofollow" target="_blank">https://unsplash.com/photos/XookgCxFw6Q</a></figcaption></figure><p id="ec8e" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">神经网络，只要给出足够多的例子，就能区分猫和狗。然而，当进行区分时，对网络参与的详细研究显示，视觉网络对 T2 纹理非常敏感，而人类看到的是 T4 的轮廓。如果把猫的图片换成猫的<strong class="kb ir">形状</strong>的绿叶图案，人类还是会识别出它是猫。神经网络见榕树。</p><p id="56cc" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">总的来说，神经网络似乎从这些微妙的结构差异中获得了大部分性能，而从未理解复杂的关系或构想“整体”。人工智能看不到森林或树木——它们都只是“树叶”。<em class="kx">为了处理复杂的任务，就像寻找新的数学证明一样，神经网络将需要形成</em> <strong class="kb ir"> <em class="kx">抽象</em> </strong> <em class="kx">，并且还需要一种方法在这些抽象</em>之间 <strong class="kb ir"> <em class="kx">概括</em> </strong> <em class="kx">。那些是思想的轮廓。</em></p><p id="3e2d" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated"><strong class="kb ir">想法气球</strong></p><p id="8077" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">考虑一个正在观看数百万个 YouTube 视频的神经网络。它看到一个人拿着一个棒球，让它落入另一只手里。在目睹了棒球的类似事件后，我们希望神经网络能够说“啊，所有这些棒球<em class="kx">在释放时都以抛物线方式</em>下落……”抛物线行为是一种<em class="kx">抽象</em>，当其条件满足时，可以预测未来。</p><p id="b376" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">然后，观看沙滩球的视频，我们希望网络得出结论:“哦，这些沙滩球与棒球类似地下落，尽管它们以大致可预测的方式不同……”神经网络将这两种行为联系起来，在它们之间进行归纳——“沙滩球和棒球都服从重力<strong class="kb ir">。”</strong></p><p id="66d9" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">最后，假设网络观看气球的视频。“哇！这些与沙滩球和棒球不同，但它们做的是一种类似的事情，<em class="kx">倒立</em>！”这种网络可以查看所有物理学家的数据，并找到新的理论。那么，我们怎么去呢？</p><p id="9a2f" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated"><strong class="kb ir">两步</strong></p><p id="af5d" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">神经网络体系结构的主要范例是创建一个单一的整体网络，一端是输入数据，另一端是输出数据。然后，通过训练，网络被修剪下来。我们看到许多迹象表明，这是<em class="kx">而不是</em>构建智能的最佳方式。相比之下，彩票假说是一个奇妙而令人困惑的例子。</p><p id="f5c9" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">彩票的过程很简单，尽管<em class="kx">完全违背了</em>的直觉。像平常一样，从一个随机加权的网络开始。像平常一样训练网络。然后，看看每个神经元连接:它要么<em class="kx">开始</em>变弱，而<em class="kx">保持</em>变弱，要么<em class="kx">变强，要么它开始变强，并保持强或变弱。<strong class="kb ir">只保留<em class="kx">开始弱</em>变强</strong>的。没错。<em class="kx">去掉神经连接，使</em> <strong class="kb ir"> <em class="kx">开始</em></strong><em class="kx"/><strong class="kb ir"><em class="kx">保持</em> </strong> <em class="kx">强</em>。你不会想要这些的。很奇怪。</em></p><p id="82bc" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">然后，<strong class="kb ir">重置</strong>所有剩余神经元的权重<em class="kx">为你从</em>开始的随机值。是啊，把你刚刚学的东西都扔掉。而且，你<strong class="kb ir">不能</strong>使用一些<em class="kx">新的</em>随机权重——只有<em class="kx">原来的</em>随机权重才可以。现在，训练那个微小的网络，它将实现一个<strong class="kb ir">更高的最终性能</strong>，用<strong class="kb ir">更少的训练</strong>，只使用<strong class="kb ir">十分之一的处理能力</strong>。WTF？</p><p id="7614" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">显然，我们不知道自己在做什么，甚至盲目地磕磕绊绊也足以发现不可思议的进步。艾是一个<em class="kx">果园</em>低垂的果实。</p><p id="2ff0" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">神经网络架构的另一种模式可能会产生我们所寻求的抽象和概括:<strong class="kb ir">生成</strong>新的迷你网络，然后<strong class="kb ir">合并</strong>它们。怎么会？</p><p id="3420" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated"><strong class="kb ir">假定翻译，假定共享状态</strong></p><p id="7b11" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">GANs 擅长获取一组数据，比如一个城市的照片，并将其转换为一组相关的数据——这个城市的一幅画，或者这个城市在秋天，而不是春天。如果我们创建一个<em class="kx">迷你网络</em>，其任务是<strong class="kb ir">将</strong>的‘棒球坠落’视频转换成‘沙滩球坠落’视频，我们就有了功能类比的存在证据。</p><p id="e48d" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">如果在两种行为之间有一个有效的类比，那么这意味着两种情况共享一个隐藏的状态。抽象概念。在我们的例子中重力。要搞清楚这一点，另一个小型网络是必要的:找到一个分类器，将棒球事件和沙滩球事件归类为相同的事件，尽管棒球和沙滩球在 T2 的其他情况下被归类为不同的事件。起初，分类器不能准确地识别重力效应的存在。它只看到“棒球”、“沙滩球”和“落垒/沙滩球”。在排除除重力之外的所有因素之前，你需要在配对之间进行大量的归纳。(并且，隐藏状态<em class="kx">本身</em>可以被概括和抽象——例如，将流体动力学与电磁学联系起来……它变得元。)</p><p id="b6a4" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">因为每一个事件群，棒球-沙滩球-气球，都由一个迷你 GAN 联系起来，并且它的区别特征由一个迷你分类器识别，所有这些事件都变成了一个相关现象的<strong class="kb ir"> GLOB </strong>。当遇到<em class="kx">新的</em>系列事件时，您只需要为<em class="kx">glob</em>的一个成员训练一个迷你 GAN，以评估新事件是否属于该 glob 的类型。(“如果游泳的鱼不会像棒球一样落下，它们可能也不会像沙滩球一样落下。”)</p><p id="f322" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">Globs 可以训练一个单一的、统一的网络，用于任意两个成员之间的翻译，尽管这可能只值得定期进行。我们需要一段时间来消化和整合新的思想，所以这种局限性并不奇怪。并且，整个 glob 共享相同的隐藏状态，该隐藏状态先前由每个小型分类器识别，因此超级分类器可以从所有这些分类器一起提取相同的结论。不过，随着每一个球的成长，它也需要重新训练。</p><p id="9847" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated"><strong class="kb ir">结婚戒指</strong></p><p id="7d37" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">如果我们的小型网络可以缝合在一起，而不是针对整个特定实例组进行重新训练，我们将接近一个可行的抽象概括机器。这就是模糊的地方。</p><p id="ce3c" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">彩票假设的运作原理是，如果你从一个单一的整体网络和随机权重开始，那么该网络会有一些<strong class="kb ir">子集</strong>(…并且<em class="kx">你想要哪个</em>子集是特定于随机权重的——因此，你必须将修整后的网络返回到<em class="kx">原始的</em>随机权重，<strong class="kb ir">而不是</strong>新随机权重)，这将比任何其他子集训练得更快，结果更好。奇怪的是，精简到那个神奇网络的方法是只挑选“改进最多的”神经连接。</p><p id="65b5" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">我认为，在我们所有公认的智慧之外，可能有一个相对简单的缝合迷你网络的过程。</p><p id="1716" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">以猫的照片为例-在网络的每一层，由于较小要素的存在，较大要素被识别出来。小花絮分层组合，反映了现实的组成性质。然而，图像的某些方面在神经元之间以模糊不清的形式传输，只有在网络的某个更高层才会变得清晰。也有这个<em class="kx">完形</em>在起作用。</p><p id="1191" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">如果我们想要结合许多小型网络，我们必须提取每个小型网络使用的组合特征——如果这些特征中的一些被多个小型网络共享，我们实现一些压缩。而且，我们必须保留那些<em class="kx">模糊的东西</em>，它们只有在更高的层次才会变得清晰。如果我们把这些模糊的东西缝合在一起，找到一种方法来重叠它们，我们就有了一个超级网络<strong class="kb ir">而不需要重新训练</strong>，它可以形成抽象，并在这些抽象之间进行概括。我想再买一张乐透彩票…</p></div></div>    
</body>
</html>