<html>
<head>
<title>Reading between the layers (LSTM Network)</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">层间阅读(LSTM 网络)</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/reading-between-the-layers-lstm-network-7956ad192e58?source=collection_archive---------8-----------------------#2019-02-21">https://towardsdatascience.com/reading-between-the-layers-lstm-network-7956ad192e58?source=collection_archive---------8-----------------------#2019-02-21</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="9092" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">使用 PyTorch 框架进行深度学习</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/561127b10c5009b73f2348f4d5e31b38.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*nA-mv01jKUKVxl3C"/></div></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk">Photo by <a class="ae ky" href="https://unsplash.com/@pawelskor?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Paul Skorupskas</a> on <a class="ae ky" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><blockquote class="kz"><p id="1dfd" class="la lb it bd lc ld le lf lg lh li lj dk translated">构建深度神经网络的最关键部分之一是——当数据流经经历维度变化、形状改变、展平然后重新成形的层时，要有一个清晰的视图…</p></blockquote><p id="0370" class="pw-post-body-paragraph lk ll it lm b ln lo ju lp lq lr jx ls lt lu lv lw lx ly lz ma mb mc md me lj im bi translated">我们将参考之前在情感分析教程中看到的 LSTM 架构。链接到这篇文章。</p><div class="mf mg gp gr mh mi"><a rel="noopener follow" target="_blank" href="/sentiment-analysis-using-lstm-step-by-step-50d074f09948"><div class="mj ab fo"><div class="mk ab ml cl cj mm"><h2 class="bd iu gy z fp mn fr fs mo fu fw is bi translated">使用 LSTM 逐步进行情感分析</h2><div class="mp l"><h3 class="bd b gy z fp mn fr fs mo fu fw dk translated">使用 PyTorch 框架进行深度学习</h3></div><div class="mq l"><p class="bd b dl z fp mn fr fs mo fu fw dk translated">towardsdatascience.com</p></div></div><div class="mr l"><div class="ms l mt mu mv mr mw ks mi"/></div></div></a></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi mx"><img src="../Images/a96838abe1abeec9e9e4a249faf1e573.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*SICYykT7ybua1gVJDNlajw.png"/></div></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk">LSTM Network Architecture for Sentiment Analysis</figcaption></figure><p id="f8b4" class="pw-post-body-paragraph lk ll it lm b ln my ju lp lq mz jx ls lt na lv lw lx nb lz ma mb nc md me lj im bi translated">这些层如下所示:</p><p id="1cb7" class="pw-post-body-paragraph lk ll it lm b ln my ju lp lq mz jx ls lt na lv lw lx nb lz ma mb nc md me lj im bi translated">0.令牌化:这不是 LSTM 网络的一个层，而是将我们的单词转换成令牌(整数)的一个强制步骤</p><ol class=""><li id="fc8b" class="nd ne it lm b ln my lq mz lt nf lx ng mb nh lj ni nj nk nl bi translated">嵌入层:将单词标记(整数)转换成特定大小的嵌入</li><li id="2ce2" class="nd ne it lm b ln nm lq nn lt no lx np mb nq lj ni nj nk nl bi translated">LSTM 层:由隐藏状态变暗和层数定义</li><li id="93fb" class="nd ne it lm b ln nm lq nn lt no lx np mb nq lj ni nj nk nl bi translated">全连接图层:将 LSTM 图层的输出映射到所需的输出大小</li><li id="c71a" class="nd ne it lm b ln nm lq nn lt no lx np mb nq lj ni nj nk nl bi translated">Sigmoid 激活层:将所有输出值转换为 0 到 1 之间的值</li><li id="dea7" class="nd ne it lm b ln nm lq nn lt no lx np mb nq lj ni nj nk nl bi translated">输出:最后一个时间步的 Sigmoid 输出被认为是该网络的最终输出</li></ol><p id="89fa" class="pw-post-body-paragraph lk ll it lm b ln my ju lp lq mz jx ls lt na lv lw lx nb lz ma mb nc md me lj im bi translated"><strong class="lm iu">在定义模型类之前，仔细观察每一层会有很好的洞察力。</strong>这将有助于您更清楚地了解如何为模型架构的嵌入、LSTM 和线性层准备输入</p><h2 id="7561" class="nr ns it bd nt nu nv dn nw nx ny dp nz lt oa ob oc lx od oe of mb og oh oi oj bi translated">背景:</h2><p id="5c7a" class="pw-post-body-paragraph lk ll it lm b ln ok ju lp lq ol jx ls lt om lv lw lx on lz ma mb oo md me lj im bi translated">我们正在使用<a class="ae ky" href="http://ai.stanford.edu/~amaas/data/sentiment/" rel="noopener ugc nofollow" target="_blank"> IMDB 电影回顾数据集</a>，数据处理和准备步骤已经完成。如果您需要重新查看这些步骤，请点击此处的<a class="ae ky" rel="noopener" target="_blank" href="/sentiment-analysis-using-lstm-step-by-step-50d074f09948">按钮</a>。我们从数据加载器开始(我们已经定义了<code class="fe op oq or os b">batch_size=50</code>和<code class="fe op oq or os b">sequence length=200</code>)。根据我关于使用 LSTM 构建<a class="ae ky" rel="noopener" target="_blank" href="/sentiment-analysis-using-lstm-step-by-step-50d074f09948">情感分析模型的文章，我们正在用显微镜观察第 14 步——</a></p><ul class=""><li id="4305" class="nd ne it lm b ln my lq mz lt nf lx ng mb nh lj ot nj nk nl bi translated"><strong class="lm iu">我们先来看看来自</strong>的 <code class="fe op oq or os b"><strong class="lm iu">inupts</strong></code> <strong class="lm iu">和</strong> <code class="fe op oq or os b"><strong class="lm iu">targets</strong></code> <strong class="lm iu"/></li></ul><pre class="kj kk kl km gt ou os ov ow aw ox bi"><span id="818d" class="nr ns it os b gy oy oz l pa pb">dataiter = iter(train_loader)<br/>x, y = dataiter.next()<br/>x = x.type(torch.LongTensor)<br/>print ('X is', x)</span><span id="dbc4" class="nr ns it os b gy pc oz l pa pb">print ('Shape of X and y are :', x.shape, y.shape)</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi pd"><img src="../Images/baeedecee9f5030b8f5bf89be620bdbf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*2BP1zoAwvu9OHTxmaD-opg.png"/></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk">Reviews converted into tokens (integers)</figcaption></figure><p id="c848" class="pw-post-body-paragraph lk ll it lm b ln my ju lp lq mz jx ls lt na lv lw lx nb lz ma mb nc md me lj im bi translated">从<code class="fe op oq or os b">X</code>的形状我们可以看出<code class="fe op oq or os b">X</code>是一个 50 行(=批量)&amp; 200 列(=序列长度)的张量。这确保了我们的令牌化过程运行良好。这个<code class="fe op oq or os b">X</code>将作为嵌入层的输入</p><ul class=""><li id="d7a9" class="nd ne it lm b ln my lq mz lt nf lx ng mb nh lj ot nj nk nl bi translated"><strong class="lm iu">嵌入层:</strong></li></ul><p id="7008" class="pw-post-body-paragraph lk ll it lm b ln my ju lp lq mz jx ls lt na lv lw lx nb lz ma mb nc md me lj im bi translated">允许你使用嵌入的模块是<code class="fe op oq or os b">torch.nn.Embedding</code>。它需要两个参数:词汇量和嵌入的维数</p><pre class="kj kk kl km gt ou os ov ow aw ox bi"><span id="d81a" class="nr ns it os b gy oy oz l pa pb">from torch import nn</span><span id="b47a" class="nr ns it os b gy pc oz l pa pb">vocab_size = len(words)<br/>embedding_dim = 30<br/>embeds = nn.Embedding(vocab_size, embedding_dim)<br/>print ('Embedding layer is ', embeds)<br/>print ('Embedding layer weights ', embeds.weight.shape)</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pe"><img src="../Images/31869080909a6e16bf6fc0fd60e5e25b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*5pXR-CrpVMEsaDKEvVPU4g.png"/></div></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk">Embedding Layer ‘Weight Matrix’ or ‘Look-up Table’</figcaption></figure><pre class="kj kk kl km gt ou os ov ow aw ox bi"><span id="aefd" class="nr ns it os b gy oy oz l pa pb">embeds_out = embeds(x)<br/>print ('Embedding layer output shape', embeds_out.shape)<br/>print ('Embedding layer output ', embeds_out)</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pf"><img src="../Images/a48e922825f3c882b5fdebf76f10349a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Jatuwtd8f-P-Tpm2hbOqEA.png"/></div></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk">Input tokens converted into embedding vectors</figcaption></figure><p id="3a4a" class="pw-post-body-paragraph lk ll it lm b ln my ju lp lq mz jx ls lt na lv lw lx nb lz ma mb nc md me lj im bi translated">从嵌入层的输出我们可以看到，由于嵌入了权重，它创建了一个三维张量。现在它有 50 行，200 列和 30 个嵌入维度，也就是说，在我们的评论中，对于每个标记化的单词，我们都添加了嵌入维度。这些数据现在将被传送到 LSTM 图层</p><ul class=""><li id="8988" class="nd ne it lm b ln my lq mz lt nf lx ng mb nh lj ot nj nk nl bi translated"><strong class="lm iu"> LSTM 层:</strong></li></ul><p id="63c9" class="pw-post-body-paragraph lk ll it lm b ln my ju lp lq mz jx ls lt na lv lw lx nb lz ma mb nc md me lj im bi translated">在定义 LSTM 层时，我们保持 Batch First = True，隐藏单元数= 512。</p><pre class="kj kk kl km gt ou os ov ow aw ox bi"><span id="c16f" class="nr ns it os b gy oy oz l pa pb"># initializing the hidden state to 0<br/>hidden=None<br/>lstm = nn.LSTM(input_size=embedding_dim, hidden_size=512, num_layers=1, batch_first=True)<br/>lstm_out, h = lstm(embeds_out, hidden)<br/>print ('LSTM layer output shape', lstm_out.shape)<br/>print ('LSTM layer output ', lstm_out)</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pg"><img src="../Images/1a253aa6fbae44a10b3bae7117b858c4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*WVEVEwPIGMcNyP8eldOjOg.png"/></div></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk">Output of LSTM layer</figcaption></figure><p id="8277" class="pw-post-body-paragraph lk ll it lm b ln my ju lp lq mz jx ls lt na lv lw lx nb lz ma mb nc md me lj im bi translated">通过观察 LSTM 层的输出，我们看到我们的张量现在有 50 行，200 列和 512 个 LSTM 节点。接下来，该数据被提取到完全连接的层中</p><ul class=""><li id="2bc2" class="nd ne it lm b ln my lq mz lt nf lx ng mb nh lj ot nj nk nl bi translated"><strong class="lm iu">全连通层:</strong></li></ul><p id="77d9" class="pw-post-body-paragraph lk ll it lm b ln my ju lp lq mz jx ls lt na lv lw lx nb lz ma mb nc md me lj im bi translated">对于完全连接的图层，输入要素的数量= LSTM 中隐藏单元的数量。输出大小= 1，因为我们只二进制输出(1/0；正/负)</p><p id="0495" class="pw-post-body-paragraph lk ll it lm b ln my ju lp lq mz jx ls lt na lv lw lx nb lz ma mb nc md me lj im bi translated">请注意，在将 lstm 输出放入 fc 层之前，必须将其展平。</p><pre class="kj kk kl km gt ou os ov ow aw ox bi"><span id="94fb" class="nr ns it os b gy oy oz l pa pb">fc = nn.Linear(in_features=512, out_features=1)<br/>fc_out = fc(lstm_out.contiguous().view(-1, 512))<br/>print ('FC layer output shape', fc_out.shape)<br/>print ('FC layer output ', fc_out)</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ph"><img src="../Images/b12700f929b86e057193659cf6e2477d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1318/format:webp/1*3-k3_FVd4vbwBn9UgiCgbw.png"/></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk">Output from Fully Connected Layer</figcaption></figure><ul class=""><li id="f95c" class="nd ne it lm b ln my lq mz lt nf lx ng mb nh lj ot nj nk nl bi translated"><strong class="lm iu">乙状结肠激活层:</strong></li></ul><p id="68aa" class="pw-post-body-paragraph lk ll it lm b ln my ju lp lq mz jx ls lt na lv lw lx nb lz ma mb nc md me lj im bi translated">只需要将全连接层的所有输出值转换为 0 和 1 之间的值</p><pre class="kj kk kl km gt ou os ov ow aw ox bi"><span id="637a" class="nr ns it os b gy oy oz l pa pb">sigm = nn.Sigmoid()<br/>sigm_out = sigm(fc_out)<br/>print ('Sigmoid layer output shape', sigm_out.shape)<br/>print ('Sigmoid layer output ', sigm_out)</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi pi"><img src="../Images/71d2452ad815401efdd52955739cbeea.png" data-original-src="https://miro.medium.com/v2/resize:fit:992/format:webp/1*eE8rADzp0EHEHzYzSCxK6Q.png"/></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk">Output from Sigmoid Activation Layer</figcaption></figure><ul class=""><li id="3953" class="nd ne it lm b ln my lq mz lt nf lx ng mb nh lj ot nj nk nl bi translated"><strong class="lm iu">最终输出:</strong></li></ul><p id="7a42" class="pw-post-body-paragraph lk ll it lm b ln my ju lp lq mz jx ls lt na lv lw lx nb lz ma mb nc md me lj im bi translated">这包括两个步骤:首先，重新调整输出，使行数=批量大小</p><pre class="kj kk kl km gt ou os ov ow aw ox bi"><span id="3f33" class="nr ns it os b gy oy oz l pa pb">batch_size = x.shape[0]<br/>out = sigm_out.view(batch_size, -1)<br/>print ('Output layer output shape', out.shape)<br/>print ('Output layer output ', out)</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pj"><img src="../Images/c0a6c5fdd0d6194b29fa1a2b6522636d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*hl7mmUEu6znclI1fq3S58A.png"/></div></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk">Sigmoid Activation Layer output reshaped</figcaption></figure><p id="3feb" class="pw-post-body-paragraph lk ll it lm b ln my ju lp lq mz jx ls lt na lv lw lx nb lz ma mb nc md me lj im bi translated">第二，正如我们在网络架构中看到的，我们只想要最后一个序列之后的输出(最后一个时间步长之后)</p><pre class="kj kk kl km gt ou os ov ow aw ox bi"><span id="1128" class="nr ns it os b gy oy oz l pa pb">print ('Final sentiment prediction, ', out[:,-1])</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pk"><img src="../Images/cac9c5585f606dacdf9bf69b645eed56.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*2Avh77tRD9A8BK59okC2LA.png"/></div></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk">Final output from the model</figcaption></figure><p id="60d2" class="pw-post-body-paragraph lk ll it lm b ln my ju lp lq mz jx ls lt na lv lw lx nb lz ma mb nc md me lj im bi translated">这些输出来自未经训练的网络，因此这些值可能还不能说明任何问题。这只是为了举例说明，我们将使用这些知识来正确定义模型。</p><h2 id="7a1a" class="nr ns it bd nt nu nv dn nw nx ny dp nz lt oa ob oc lx od oe of mb og oh oi oj bi translated">结束语:</h2><ul class=""><li id="2b07" class="nd ne it lm b ln ok lq ol lt pl lx pm mb pn lj ot nj nk nl bi translated">我希望你读它的时候和我写这篇文章的时候一样开心</li><li id="6d5b" class="nd ne it lm b ln nm lq nn lt no lx np mb nq lj ot nj nk nl bi translated">试着为你正在尝试实现的任何其他深度学习模型复制这个过程</li><li id="959e" class="nd ne it lm b ln nm lq nn lt no lx np mb nq lj ot nj nk nl bi translated">请随意写下您的想法/建议/反馈</li></ul></div></div>    
</body>
</html>