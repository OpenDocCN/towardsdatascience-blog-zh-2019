<html>
<head>
<title>Generating Modern Art using
Generative Adversarial Network(GAN) on Spell</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">利用生成性对抗网络生成现代艺术</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/generating-modern-arts-using-generative-adversarial-network-gan-on-spell-39f67f83c7b4?source=collection_archive---------2-----------------------#2019-11-13">https://towardsdatascience.com/generating-modern-arts-using-generative-adversarial-network-gan-on-spell-39f67f83c7b4?source=collection_archive---------2-----------------------#2019-11-13</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><h2 id="a0ac" class="ir is it bd b dl iu iv iw ix iy iz dk ja translated" aria-label="kicker paragraph">趣味甘</h2><div class=""/><div class=""><h2 id="556c" class="pw-subtitle-paragraph jz jc it bd b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq dk translated">创建一个生成性对抗网络来生成现代艺术，并在 Spell 平台的 GPU 上对其进行训练</h2></div><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi kr"><img src="../Images/4d2c3e52c51adf114c6f68f9a55a44de.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*1prOPM-kWOJ2tT21"/></div></div><figcaption class="ld le gj gh gi lf lg bd b be z dk">Arts Generated By Our GAN</figcaption></figure><h1 id="f574" class="lh li it bd lj lk ll lm ln lo lp lq lr ki ls kj lt kl lu km lv ko lw kp lx ly bi translated">先决条件</h1><p id="7e15" class="pw-post-body-paragraph lz ma it mb b mc md kd me mf mg kg mh mi mj mk ml mm mn mo mp mq mr ms mt mu im bi translated">你需要很好地理解:</p><ol class=""><li id="e752" class="mv mw it mb b mc mx mf my mi mz mm na mq nb mu nc nd ne nf bi translated">图像处理</li><li id="6b27" class="mv mw it mb b mc ng mf nh mi ni mm nj mq nk mu nc nd ne nf bi translated">Python 编程语言</li><li id="c469" class="mv mw it mb b mc ng mf nh mi ni mm nj mq nk mu nc nd ne nf bi translated">numpy——科学计算图书馆</li><li id="7cff" class="mv mw it mb b mc ng mf nh mi ni mm nj mq nk mu nc nd ne nf bi translated">Keras —深度学习图书馆</li></ol><p id="0348" class="pw-post-body-paragraph lz ma it mb b mc mx kd me mf my kg mh mi nl mk ml mm nm mo mp mq nn ms mt mu im bi translated">和一些基本知识:</p><ol class=""><li id="33b3" class="mv mw it mb b mc mx mf my mi mz mm na mq nb mu nc nd ne nf bi translated">生成对抗网络</li></ol></div><div class="ab cl no np hx nq" role="separator"><span class="nr bw bk ns nt nu"/><span class="nr bw bk ns nt nu"/><span class="nr bw bk ns nt"/></div><div class="im in io ip iq"><h1 id="b9de" class="lh li it bd lj lk nv lm ln lo nw lq lr ki nx kj lt kl ny km lv ko nz kp lx ly bi translated">使用的数据集</h1><p id="ac44" class="pw-post-body-paragraph lz ma it mb b mc md kd me mf mg kg mh mi mj mk ml mm mn mo mp mq mr ms mt mu im bi translated">本项目中使用的图像数据收集自<a class="ae oa" href="https://www.wikiart.org/" rel="noopener ugc nofollow" target="_blank"><strong class="mb jd"/></a>。</p></div><div class="ab cl no np hx nq" role="separator"><span class="nr bw bk ns nt nu"/><span class="nr bw bk ns nt nu"/><span class="nr bw bk ns nt"/></div><div class="im in io ip iq"><h1 id="7bfb" class="lh li it bd lj lk nv lm ln lo nw lq lr ki nx kj lt kl ny km lv ko nz kp lx ly bi translated">介绍</h1><p id="7fd3" class="pw-post-body-paragraph lz ma it mb b mc md kd me mf mg kg mh mi mj mk ml mm mn mo mp mq mr ms mt mu im bi translated">在本教程中，我们将看一步一步的过程来创建一个生成性的对抗性网络，以生成现代艺术，并使用 Python 和 Keras 编写代码。</p><p id="173c" class="pw-post-body-paragraph lz ma it mb b mc mx kd me mf my kg mh mi nl mk ml mm nm mo mp mq nn ms mt mu im bi translated">之后，为了训练模型，我们将使用一个强大的拼写平台的 GPU 实例。一切都将在途中解释，并提供进一步阅读的链接。</p><p id="3593" class="pw-post-body-paragraph lz ma it mb b mc mx kd me mf my kg mh mi nl mk ml mm nm mo mp mq nn ms mt mu im bi translated">我们开始吧！</p></div><div class="ab cl no np hx nq" role="separator"><span class="nr bw bk ns nt nu"/><span class="nr bw bk ns nt nu"/><span class="nr bw bk ns nt"/></div><div class="im in io ip iq"><h1 id="ffca" class="lh li it bd lj lk nv lm ln lo nw lq lr ki nx kj lt kl ny km lv ko nz kp lx ly bi translated">探索数据集</h1><p id="d051" class="pw-post-body-paragraph lz ma it mb b mc md kd me mf mg kg mh mi mj mk ml mm mn mo mp mq mr ms mt mu im bi translated">在开始之前，让我们看看我们的图像数据集。</p><p id="6eac" class="pw-post-body-paragraph lz ma it mb b mc mx kd me mf my kg mh mi nl mk ml mm nm mo mp mq nn ms mt mu im bi translated">WikiArt 收藏了大量不同风格的现代艺术作品。对于我们的特定项目，我们将使用<a class="ae oa" href="https://www.wikiart.org/en/paintings-by-style/cubism?select=featured#!#filterName:featured,viewType:masonry" rel="noopener ugc nofollow" target="_blank"> <strong class="mb jd">立体派</strong> </a>风格的图像。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi ob"><img src="../Images/2c37c95ba75bd99173d3a1777b0376cc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*wem4QJWtp9GO6bfB"/></div></figure><p id="1ea8" class="pw-post-body-paragraph lz ma it mb b mc mx kd me mf my kg mh mi nl mk ml mm nm mo mp mq nn ms mt mu im bi translated">你可以从 WikiArt.org 了解更多的艺术风格和现代艺术。</p><h1 id="8c8c" class="lh li it bd lj lk ll lm ln lo lp lq lr ki ls kj lt kl lu km lv ko lw kp lx ly bi translated">下载图像</h1><p id="9c39" class="pw-post-body-paragraph lz ma it mb b mc md kd me mf mg kg mh mi mj mk ml mm mn mo mp mq mr ms mt mu im bi translated">你既可以从 WikiArt 下载你喜欢的图片，也可以通过<a class="ae oa" href="https://github.com/cs-chan/ArtGAN/tree/master/WikiArt%20Dataset" rel="noopener ugc nofollow" target="_blank"> <strong class="mb jd"> cs-chan </strong> </a>前往该库下载 26GB 的 WikiArt 图片。</p><p id="1efe" class="pw-post-body-paragraph lz ma it mb b mc mx kd me mf my kg mh mi nl mk ml mm nm mo mp mq nn ms mt mu im bi translated">因为它有所有不同类型的集合，我们将只选择<strong class="mb jd">立体主义</strong>并将它们存储在名为 dataset 的文件夹中。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi oc"><img src="../Images/f5953c58db7a4de3cc7dec021fbb4b2c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*-xytA99_61uWlUg_"/></div></div></figure><h2 id="47ab" class="od li it bd lj oe of dn ln og oh dp lr mi oi oj lt mm ok ol lv mq om on lx iz bi translated">处理图像数据</h2><p id="028d" class="pw-post-body-paragraph lz ma it mb b mc md kd me mf mg kg mh mi mj mk ml mm mn mo mp mq mr ms mt mu im bi translated">我们数据集中的图像大小不同，为了将它们输入到我们的生成性对抗性神经网络中，我们将把所有图像的大小调整为 128X128。</p><p id="65ca" class="pw-post-body-paragraph lz ma it mb b mc mx kd me mf my kg mh mi nl mk ml mm nm mo mp mq nn ms mt mu im bi translated">开始之前，在数据集文件夹所在的根目录下创建一个 python 文件。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi oo"><img src="../Images/2b3c960cdc91b923c6f0ede6eb483445.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*7VIiCX8zmcstVMC1"/></div></div></figure><p id="c6f1" class="pw-post-body-paragraph lz ma it mb b mc mx kd me mf my kg mh mi nl mk ml mm nm mo mp mq nn ms mt mu im bi translated">现在，让我们编写一个小的 python 脚本，从文件夹中选择所有图像，并将其大小调整为 128X128，然后保存在<strong class="mb jd"> cubism_data.npy </strong>文件中。</p><pre class="ks kt ku kv gt op oq or os aw ot bi"><span id="f64f" class="od li it oq b gy ou ov l ow ox"><em class="oy">## image_resizer.py</em><br/><em class="oy"># Importing required libraries</em><br/><strong class="oq jd">import</strong> os<br/><strong class="oq jd">import</strong> numpy <strong class="oq jd">as</strong> np<br/><strong class="oq jd">from</strong> PIL <strong class="oq jd">import</strong> Image<br/><br/><em class="oy"># Defining an image size and image channel</em><br/><em class="oy"># We are going to resize all our images to 128X128 size and since our images are colored images</em><br/><em class="oy"># We are setting our image channels to 3 (RGB)</em><br/><br/>IMAGE_SIZE = 128<br/>IMAGE_CHANNELS = 3<br/>IMAGE_DIR = 'dataset/'<br/><br/><em class="oy"># Defining image dir path. Change this if you have different directory</em><br/>images_path = IMAGE_DIR <br/><br/>training_data = []<br/><br/><em class="oy"># Iterating over the images inside the directory and resizing them using</em><br/><em class="oy"># Pillow's resize method.</em><br/>print('resizing...')<br/><br/><strong class="oq jd">for</strong> filename <strong class="oq jd">in</strong> os.listdir(images_path):<br/>    path = os.path.join(images_path, filename)<br/>    image = Image.open(path).resize((IMAGE_SIZE, IMAGE_SIZE), Image.ANTIALIAS)<br/><br/>    training_data.append(np.asarray(image))<br/><br/>training_data = np.reshape(<br/>    training_data, (-1, IMAGE_SIZE, IMAGE_SIZE, IMAGE_CHANNELS))<br/>training_data = training_data / 127.5 - 1<br/><br/>print('saving file...')<br/>np.save('cubism_data.npy', training_data)</span></pre><p id="c44d" class="pw-post-body-paragraph lz ma it mb b mc mx kd me mf my kg mh mi nl mk ml mm nm mo mp mq nn ms mt mu im bi translated">我们来分解一下。</p><p id="b357" class="pw-post-body-paragraph lz ma it mb b mc mx kd me mf my kg mh mi nl mk ml mm nm mo mp mq nn ms mt mu im bi translated">在上面的代码块中，在前几行，我们已经导入了执行调整大小操作所需的所有库。</p><pre class="ks kt ku kv gt op oq or os aw ot bi"><span id="7c4b" class="od li it oq b gy ou ov l ow ox"><strong class="oq jd">import</strong> os<br/><strong class="oq jd">import</strong> numpy <strong class="oq jd">as</strong> np<br/><strong class="oq jd">from</strong> PIL <strong class="oq jd">import</strong> Image<br/><br/>IMAGE_SIZE = 128<br/>IMAGE_CHANNELS = 3<br/>IMAGE_DIR = 'dataset/'<br/><br/>images_path = IMAGE_DIR</span></pre><p id="4dfe" class="pw-post-body-paragraph lz ma it mb b mc mx kd me mf my kg mh mi nl mk ml mm nm mo mp mq nn ms mt mu im bi translated">这里，我们使用 Pillow 将所有图像调整到我们想要的大小，并将它们作为 numpy 数组添加到一个列表中。</p><pre class="ks kt ku kv gt op oq or os aw ot bi"><span id="e8dc" class="od li it oq b gy ou ov l ow ox">training_data = []</span><span id="e760" class="od li it oq b gy oz ov l ow ox"><strong class="oq jd">for</strong> filename <strong class="oq jd">in</strong> os.listdir(images_path):<br/> path = os.path.join(images_path, filename)<br/> image = Image.open(path).resize((IMAGE_SIZE, IMAGE_SIZE), Image.ANTIALIAS)<br/>training_data.append(np.asarray(image))</span></pre><p id="0a01" class="pw-post-body-paragraph lz ma it mb b mc mx kd me mf my kg mh mi nl mk ml mm nm mo mp mq nn ms mt mu im bi translated">之后，我们使用<strong class="mb jd"> numpy </strong>以合适的格式重塑数组，并规范化数据。</p><pre class="ks kt ku kv gt op oq or os aw ot bi"><span id="d897" class="od li it oq b gy ou ov l ow ox">training_data = np.reshape(<br/>training_data, (-1, IMAGE_SIZE, IMAGE_SIZE, IMAGE_CHANNELS))<br/>training_data = training_data / 127.5–1</span></pre><p id="0942" class="pw-post-body-paragraph lz ma it mb b mc mx kd me mf my kg mh mi nl mk ml mm nm mo mp mq nn ms mt mu im bi translated">标准化之后，我们将图像数组保存在<strong class="mb jd"> npy </strong>二进制文件中，这样我们就不必每次都遍历所有的图像。</p><pre class="ks kt ku kv gt op oq or os aw ot bi"><span id="5533" class="od li it oq b gy ou ov l ow ox">np.save(‘cubism_data.npy’, training_data)</span></pre><p id="9799" class="pw-post-body-paragraph lz ma it mb b mc mx kd me mf my kg mh mi nl mk ml mm nm mo mp mq nn ms mt mu im bi translated">这就是处理我们的图像数据。</p></div><div class="ab cl no np hx nq" role="separator"><span class="nr bw bk ns nt nu"/><span class="nr bw bk ns nt nu"/><span class="nr bw bk ns nt"/></div><div class="im in io ip iq"><h1 id="7c99" class="lh li it bd lj lk nv lm ln lo nw lq lr ki nx kj lt kl ny km lv ko nz kp lx ly bi translated">创建 GAN</h1><p id="5675" class="pw-post-body-paragraph lz ma it mb b mc md kd me mf mg kg mh mi mj mk ml mm mn mo mp mq mr ms mt mu im bi translated">现在是我们项目中最激动人心的部分了，从这里开始我们将为生成性对抗网络(GAN)编写代码。</p><p id="edcc" class="pw-post-body-paragraph lz ma it mb b mc mx kd me mf my kg mh mi nl mk ml mm nm mo mp mq nn ms mt mu im bi translated">我们将使用<strong class="mb jd">Keras——一个深度学习库</strong>来创建我们的 GAN。</p><p id="6fb4" class="pw-post-body-paragraph lz ma it mb b mc mx kd me mf my kg mh mi nl mk ml mm nm mo mp mq nn ms mt mu im bi translated">开始之前，让我们简单了解一下什么是 GAN 及其结构。</p><h2 id="d4a8" class="od li it bd lj oe of dn ln og oh dp lr mi oi oj lt mm ok ol lv mq om on lx iz bi translated">甘是什么？</h2><p id="9a63" class="pw-post-body-paragraph lz ma it mb b mc md kd me mf mg kg mh mi mj mk ml mm mn mo mp mq mr ms mt mu im bi translated">生成对抗网络(GANs)是机器学习领域一项令人兴奋的最新创新。伊恩·哥德费罗在他的论文<a class="ae oa" href="https://arxiv.org/abs/1406.2661" rel="noopener ugc nofollow" target="_blank"> <strong class="mb jd">中首次提出了生成对抗网络</strong> </a>。</p><p id="83fe" class="pw-post-body-paragraph lz ma it mb b mc mx kd me mf my kg mh mi nl mk ml mm nm mo mp mq nn ms mt mu im bi translated">gan 是<strong class="mb jd">生成型</strong>模型:在给定一些训练数据后，它们可以创建看起来像你的训练数据的新数据实例。例如，GANs 可以创建看起来像人脸照片的图像，即使这些人脸不属于任何真实的人。</p><p id="6933" class="pw-post-body-paragraph lz ma it mb b mc mx kd me mf my kg mh mi nl mk ml mm nm mo mp mq nn ms mt mu im bi translated">关于 GAN 的一个很好的例子，你可以访问<a class="ae oa" href="https://www.thispersondoesnotexist.com/" rel="noopener ugc nofollow" target="_blank"><strong class="mb jd"/></a>，它是由<strong class="mb jd"> Nvidia </strong>创造的。它生成了一个不存在的人的高质量图像。</p><p id="5d63" class="pw-post-body-paragraph lz ma it mb b mc mx kd me mf my kg mh mi nl mk ml mm nm mo mp mq nn ms mt mu im bi translated">听起来很有趣，对吗？</p><h2 id="c02e" class="od li it bd lj oe of dn ln og oh dp lr mi oi oj lt mm ok ol lv mq om on lx iz bi translated">它是如何工作的？</h2><p id="e248" class="pw-post-body-paragraph lz ma it mb b mc md kd me mf mg kg mh mi mj mk ml mm mn mo mp mq mr ms mt mu im bi translated">让我们了解它的结构和工作原理。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi pa"><img src="../Images/b49fa3d3a65d82ee60b9ae11a65a4ae5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*cWzeYvhtN48sjqGN"/></div></div></figure><p id="550a" class="pw-post-body-paragraph lz ma it mb b mc mx kd me mf my kg mh mi nl mk ml mm nm mo mp mq nn ms mt mu im bi translated">甘提出了两种模型:生成模型和判别模型。</p><p id="1ead" class="pw-post-body-paragraph lz ma it mb b mc mx kd me mf my kg mh mi nl mk ml mm nm mo mp mq nn ms mt mu im bi translated">生成模型负责生成不同种类的噪声数据，而鉴别模型负责鉴别给定数据是真的还是假的。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi pa"><img src="../Images/db22525b859ad378af2a5517c6eb02fa.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*IZtx-_pohl2NzGMP"/></div></div></figure><p id="afe8" class="pw-post-body-paragraph lz ma it mb b mc mx kd me mf my kg mh mi nl mk ml mm nm mo mp mq nn ms mt mu im bi translated">生成模型不断地训练自己，通过生成假噪声数据来欺骗判别模型，而判别模型从训练集中训练自己来分类数据是否来自数据集，并且不被生成模型欺骗。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi pb"><img src="../Images/1be2d3558adad42bf3a3591e60cf2faa.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*NdsdJRXUhpa45UJH"/></div></div><figcaption class="ld le gj gh gi lf lg bd b be z dk">GAN structure <a class="ae oa" href="https://skymind.ai/images/wiki/GANs.png" rel="noopener ugc nofollow" target="_blank">source</a></figcaption></figure><h2 id="0bda" class="od li it bd lj oe of dn ln og oh dp lr mi oi oj lt mm ok ol lv mq om on lx iz bi translated">损失函数</h2><p id="66ef" class="pw-post-body-paragraph lz ma it mb b mc md kd me mf mg kg mh mi mj mk ml mm mn mo mp mq mr ms mt mu im bi translated">GAN 中的鉴别器使用交叉熵损失，因为鉴别器的工作是分类；交叉熵损失是最好的方法。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi pc"><img src="../Images/b34e845c9fd944741b9f802f654a6c74.png" data-original-src="https://miro.medium.com/v2/resize:fit:730/0*w4ITupD2-EPV8pgh"/></div></figure><p id="f257" class="pw-post-body-paragraph lz ma it mb b mc mx kd me mf my kg mh mi nl mk ml mm nm mo mp mq nn ms mt mu im bi translated">这个公式表示 p:真实分布和 q:估计分布之间的交叉熵损失。</p><p id="1fd9" class="pw-post-body-paragraph lz ma it mb b mc mx kd me mf my kg mh mi nl mk ml mm nm mo mp mq nn ms mt mu im bi translated">(p)和(q)是 m 维的，其中 m 是类的数量。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi pd"><img src="../Images/4683c62a75ca94ff3bd233703397c225.png" data-original-src="https://miro.medium.com/v2/resize:fit:1192/0*a0s18Q1a596HEHId"/></div></figure><p id="115c" class="pw-post-body-paragraph lz ma it mb b mc mx kd me mf my kg mh mi nl mk ml mm nm mo mp mq nn ms mt mu im bi translated">在 GAN 中，鉴别器是一个二元分类器。它需要区分数据是真的还是假的。也就是说 m = 2。真正的分布是一个仅包含 2 项的热向量。</p><p id="1f5d" class="pw-post-body-paragraph lz ma it mb b mc mx kd me mf my kg mh mi nl mk ml mm nm mo mp mq nn ms mt mu im bi translated">对于 n 个样本，我们可以对损失求和。</p><p id="b57d" class="pw-post-body-paragraph lz ma it mb b mc mx kd me mf my kg mh mi nl mk ml mm nm mo mp mq nn ms mt mu im bi translated">上面所示的等式是二元交叉熵损失，其中 y 可以取两个值 0 和 1。</p><p id="c2e9" class="pw-post-body-paragraph lz ma it mb b mc mx kd me mf my kg mh mi nl mk ml mm nm mo mp mq nn ms mt mu im bi translated">GAN 有一个潜在向量 z，图像 G(z)就神奇地从中生成。我们对真实图像 x 和生成的图像 G(z)应用鉴别器函数 D。</p><p id="d157" class="pw-post-body-paragraph lz ma it mb b mc mx kd me mf my kg mh mi nl mk ml mm nm mo mp mq nn ms mt mu im bi translated">损失函数的目的是将真实图像的预测推向 1，将伪图像推向 0。我们用对数概率项来做。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi pe"><img src="../Images/9b90fdc8eaf1b71bcdd9f661e2d89b4a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*WFN6GA_JM5_h1q1k"/></div></div></figure><p id="797e" class="pw-post-body-paragraph lz ma it mb b mc mx kd me mf my kg mh mi nl mk ml mm nm mo mp mq nn ms mt mu im bi translated"><strong class="mb jd">注</strong> : <strong class="mb jd"> ~ </strong>符号表示:分布为，这里的<strong class="mb jd"> Ex </strong>表示期望值:由于我们不知道样本是如何被送入鉴别器的，所以我们将它们表示为期望值而不是总和。</p><p id="8fee" class="pw-post-body-paragraph lz ma it mb b mc mx kd me mf my kg mh mi nl mk ml mm nm mo mp mq nn ms mt mu im bi translated">如果我们观察联合损失函数，我们将最大化鉴别器项，这意味着 D(x)的 log 应该逐渐接近零，而 D(G(z))的 log 应该接近 1。在这里，生成器试图使 D(G(z))英寸更接近 1，而鉴别器试图做相反的事情。</p></div><div class="ab cl no np hx nq" role="separator"><span class="nr bw bk ns nt nu"/><span class="nr bw bk ns nt nu"/><span class="nr bw bk ns nt"/></div><div class="im in io ip iq"><h1 id="d198" class="lh li it bd lj lk nv lm ln lo nw lq lr ki nx kj lt kl ny km lv ko nz kp lx ly bi translated">GAN 的代码</h1><p id="e44c" class="pw-post-body-paragraph lz ma it mb b mc md kd me mf mg kg mh mi mj mk ml mm mn mo mp mq mr ms mt mu im bi translated">现在，让我们毫不迟疑地写我们的 GAN。</p><p id="9fa6" class="pw-post-body-paragraph lz ma it mb b mc mx kd me mf my kg mh mi nl mk ml mm nm mo mp mq nn ms mt mu im bi translated">我们将把我们的文件命名为<strong class="mb jd"> art_gan.py </strong>，并将其存储在根目录中。这个文件将包含我们的生成器和鉴别器的所有超参数和函数。</p><p id="cc4d" class="pw-post-body-paragraph lz ma it mb b mc mx kd me mf my kg mh mi nl mk ml mm nm mo mp mq nn ms mt mu im bi translated">让我们写一些代码:</p><pre class="ks kt ku kv gt op oq or os aw ot bi"><span id="ae03" class="od li it oq b gy ou ov l ow ox"><strong class="oq jd">from</strong> keras.layers <strong class="oq jd">import</strong> Input, Reshape, Dropout, Dense, Flatten, BatchNormalization, Activation, ZeroPadding2D<br/><strong class="oq jd">from</strong> keras.layers.advanced_activations <strong class="oq jd">import</strong> LeakyReLU<br/><strong class="oq jd">from</strong> keras.layers.convolutional <strong class="oq jd">import</strong> UpSampling2D, Conv2D<br/><strong class="oq jd">from</strong> keras.models <strong class="oq jd">import</strong> Sequential, Model, load_model<br/><strong class="oq jd">from</strong> keras.optimizers <strong class="oq jd">import</strong> Adam<br/><strong class="oq jd">import</strong> numpy <strong class="oq jd">as</strong> np<br/><strong class="oq jd">from</strong> PIL <strong class="oq jd">import</strong> Image<br/><strong class="oq jd">import</strong> os</span></pre><p id="1feb" class="pw-post-body-paragraph lz ma it mb b mc mx kd me mf my kg mh mi nl mk ml mm nm mo mp mq nn ms mt mu im bi translated">在这里，我们导入创建 GAN 所需的所有库和辅助函数。</p><p id="93e4" class="pw-post-body-paragraph lz ma it mb b mc mx kd me mf my kg mh mi nl mk ml mm nm mo mp mq nn ms mt mu im bi translated">所有的导入都是不言自明的。在这里，我们正在导入一些 keras 层来创建我们的模型。</p><p id="a72f" class="pw-post-body-paragraph lz ma it mb b mc mx kd me mf my kg mh mi nl mk ml mm nm mo mp mq nn ms mt mu im bi translated">现在让我们定义一些参数:</p><pre class="ks kt ku kv gt op oq or os aw ot bi"><span id="593c" class="od li it oq b gy ou ov l ow ox"><em class="oy"># Preview image Frame<br/>PREVIEW_ROWS = 4<br/>PREVIEW_COLS = 7<br/>PREVIEW_MARGIN = 4<br/>SAVE_FREQ = 100</em></span><span id="1894" class="od li it oq b gy oz ov l ow ox"><em class="oy"># Size vector to generate images from<br/>NOISE_SIZE = 100</em></span><span id="8f74" class="od li it oq b gy oz ov l ow ox"><em class="oy"># Configuration<br/>EPOCHS = 10000 # number of iterations<br/>BATCH_SIZE = 32</em></span><span id="83ce" class="od li it oq b gy oz ov l ow ox"><em class="oy">GENERATE_RES = 3<br/>IMAGE_SIZE = 128 # rows/cols</em></span><span id="59d5" class="od li it oq b gy oz ov l ow ox">IMAGE_CHANNELS = 3</span></pre><p id="12c4" class="pw-post-body-paragraph lz ma it mb b mc mx kd me mf my kg mh mi nl mk ml mm nm mo mp mq nn ms mt mu im bi translated">在这里的前几行，我们已经定义了图像帧的大小和填充来保存我们生成的图像。</p><p id="a2a2" class="pw-post-body-paragraph lz ma it mb b mc mx kd me mf my kg mh mi nl mk ml mm nm mo mp mq nn ms mt mu im bi translated">这里是生成我们的图像的潜在维度大小。</p><p id="2e40" class="pw-post-body-paragraph lz ma it mb b mc mx kd me mf my kg mh mi nl mk ml mm nm mo mp mq nn ms mt mu im bi translated"><strong class="mb jd"> EPOCHS </strong>是迭代次数:它定义了我们想要迭代训练图像的次数，而<strong class="mb jd"> BATCH_SIZE </strong>是每次迭代中要输入的图像数量。</p><p id="91ba" class="pw-post-body-paragraph lz ma it mb b mc mx kd me mf my kg mh mi nl mk ml mm nm mo mp mq nn ms mt mu im bi translated"><strong class="mb jd"> IMAGE_SIZE </strong>是我们之前调整到 128X128 的图像尺寸，而<strong class="mb jd"> IMAGE_CHANNELS </strong>是我们图像中的通道数；也就是 3。</p><blockquote class="pf pg ph"><p id="1340" class="lz ma oy mb b mc mx kd me mf my kg mh pi nl mk ml pj nm mo mp pk nn ms mt mu im bi translated"><em class="it">注意:图像应始终为方形尺寸</em></p></blockquote><p id="d274" class="pw-post-body-paragraph lz ma it mb b mc mx kd me mf my kg mh mi nl mk ml mm nm mo mp mq nn ms mt mu im bi translated">让我们加载之前创建的 npy 数据文件。</p><pre class="ks kt ku kv gt op oq or os aw ot bi"><span id="3ebe" class="od li it oq b gy ou ov l ow ox">training_data = np.load(‘cubism_data.npy’)</span></pre><p id="a3c6" class="pw-post-body-paragraph lz ma it mb b mc mx kd me mf my kg mh mi nl mk ml mm nm mo mp mq nn ms mt mu im bi translated">为了加载 npy 文件，我们使用 numpy 的 load 函数并将文件路径作为参数传递。</p><p id="d8e1" class="pw-post-body-paragraph lz ma it mb b mc mx kd me mf my kg mh mi nl mk ml mm nm mo mp mq nn ms mt mu im bi translated">因为我们的数据文件在根目录中，所以不需要额外的路径参数。如果您已经将数据存储在其他地方，您可以使用以下代码来加载数据:</p><pre class="ks kt ku kv gt op oq or os aw ot bi"><span id="00eb" class="od li it oq b gy ou ov l ow ox">training_data = np.load(os.path.join(‘dirname’, ‘filename.npy’))</span></pre><p id="7f61" class="pw-post-body-paragraph lz ma it mb b mc mx kd me mf my kg mh mi nl mk ml mm nm mo mp mq nn ms mt mu im bi translated">这就是加载我们的训练数据。</p></div><div class="ab cl no np hx nq" role="separator"><span class="nr bw bk ns nt nu"/><span class="nr bw bk ns nt nu"/><span class="nr bw bk ns nt"/></div><div class="im in io ip iq"><p id="cd41" class="pw-post-body-paragraph lz ma it mb b mc mx kd me mf my kg mh mi nl mk ml mm nm mo mp mq nn ms mt mu im bi translated">现在我们可以创建生成器和鉴别器函数了。</p><p id="c453" class="pw-post-body-paragraph lz ma it mb b mc mx kd me mf my kg mh mi nl mk ml mm nm mo mp mq nn ms mt mu im bi translated">让我们看看代码:</p><pre class="ks kt ku kv gt op oq or os aw ot bi"><span id="1f84" class="od li it oq b gy ou ov l ow ox"><strong class="oq jd">def</strong> <strong class="oq jd">build_discriminator</strong>(image_shape):</span><span id="cce5" class="od li it oq b gy oz ov l ow ox">    model = Sequential()</span><span id="e378" class="od li it oq b gy oz ov l ow ox">    model.add(Conv2D(32, kernel_size=3, strides=2,<br/>    input_shape=image_shape, padding=”same”))<br/>    model.add(LeakyReLU(alpha=0.2))<br/>    model.add(Dropout(0.25))</span><span id="247b" class="od li it oq b gy oz ov l ow ox">    model.add(Conv2D(64, kernel_size=3, strides=2, padding=”same”))<br/>    model.add(ZeroPadding2D(padding=((0, 1), (0, 1))))<br/>    model.add(BatchNormalization(momentum=0.8))<br/>    model.add(LeakyReLU(alpha=0.2))<br/>    model.add(Dropout(0.25))</span><span id="587f" class="od li it oq b gy oz ov l ow ox">    model.add(Conv2D(128, kernel_size=3, strides=2, padding=”same”))<br/>    model.add(BatchNormalization(momentum=0.8))<br/>    model.add(LeakyReLU(alpha=0.2))<br/>    model.add(Dropout(0.25))</span><span id="83f9" class="od li it oq b gy oz ov l ow ox">    model.add(Conv2D(256, kernel_size=3, strides=1, padding=”same”))<br/>    model.add(BatchNormalization(momentum=0.8))<br/>    model.add(LeakyReLU(alpha=0.2))</span><span id="8d2b" class="od li it oq b gy oz ov l ow ox">    model.add(Dropout(0.25))<br/>    model.add(Conv2D(512, kernel_size=3, strides=1, padding=”same”))<br/>    model.add(BatchNormalization(momentum=0.8))<br/>    model.add(LeakyReLU(alpha=0.2))</span><span id="5c1d" class="od li it oq b gy oz ov l ow ox">    model.add(Dropout(0.25))<br/>    model.add(Flatten())<br/>    model.add(Dense(1, activation=’sigmoid’))</span><span id="cfb8" class="od li it oq b gy oz ov l ow ox">    input_image = Input(shape=image_shape)<br/>    validity = model(input_image)<br/>    <strong class="oq jd">return</strong> Model(input_image, validity)</span></pre><p id="5711" class="pw-post-body-paragraph lz ma it mb b mc mx kd me mf my kg mh mi nl mk ml mm nm mo mp mq nn ms mt mu im bi translated">分解一下:</p><p id="abe7" class="pw-post-body-paragraph lz ma it mb b mc mx kd me mf my kg mh mi nl mk ml mm nm mo mp mq nn ms mt mu im bi translated">如果您对 keras 有所了解，那么代码是不言自明的。</p><p id="cead" class="pw-post-body-paragraph lz ma it mb b mc mx kd me mf my kg mh mi nl mk ml mm nm mo mp mq nn ms mt mu im bi translated">总的来说，我们正在定义一个以<strong class="mb jd"> image_shape </strong>为参数的函数。</p><p id="7fa6" class="pw-post-body-paragraph lz ma it mb b mc mx kd me mf my kg mh mi nl mk ml mm nm mo mp mq nn ms mt mu im bi translated">在这个函数中，我们从 keras 中初始化一个顺序模型，帮助我们创建线性层堆栈。</p><pre class="ks kt ku kv gt op oq or os aw ot bi"><span id="0da6" class="od li it oq b gy ou ov l ow ox">model = Sequential()</span></pre><p id="092c" class="pw-post-body-paragraph lz ma it mb b mc mx kd me mf my kg mh mi nl mk ml mm nm mo mp mq nn ms mt mu im bi translated">之后，我们在顺序模型中添加一些层。</p><p id="44d1" class="pw-post-body-paragraph lz ma it mb b mc mx kd me mf my kg mh mi nl mk ml mm nm mo mp mq nn ms mt mu im bi translated">我们的第一层是一个 32 形状的卷积层，其 kernel_size 为 3，我们的步幅值为 2，填充值相同。因为它是第一层，所以它保存输入形状。</p><p id="f7f2" class="pw-post-body-paragraph lz ma it mb b mc mx kd me mf my kg mh mi nl mk ml mm nm mo mp mq nn ms mt mu im bi translated">要了解这是怎么回事，可以参考 keras 官方文档页面。</p><p id="d9e0" class="pw-post-body-paragraph lz ma it mb b mc mx kd me mf my kg mh mi nl mk ml mm nm mo mp mq nn ms mt mu im bi translated">简单地说，我们在这里定义一个卷积层，它有一个大小为 3X3 的滤波器，该滤波器跨越我们的图像数据。我们有相同的衬垫，这意味着，没有额外的衬垫。它仍然和原来一样。</p><pre class="ks kt ku kv gt op oq or os aw ot bi"><span id="402c" class="od li it oq b gy ou ov l ow ox">model.add(Conv2D(32, kernel_size=3, strides=2,<br/>  input_shape=image_shape, padding=”same”))</span><span id="e00e" class="od li it oq b gy oz ov l ow ox">model.add(LeakyReLU(alpha=0.2))</span></pre><p id="3fe3" class="pw-post-body-paragraph lz ma it mb b mc mx kd me mf my kg mh mi nl mk ml mm nm mo mp mq nn ms mt mu im bi translated">之后，我们添加了一个激活函数 LeakyRelu 层。</p><p id="7109" class="pw-post-body-paragraph lz ma it mb b mc mx kd me mf my kg mh mi nl mk ml mm nm mo mp mq nn ms mt mu im bi translated">类似地，在其他块中，层被添加到顺序模型中，具有一些漏失和批量标准化，以防止过度拟合。</p><p id="f369" class="pw-post-body-paragraph lz ma it mb b mc mx kd me mf my kg mh mi nl mk ml mm nm mo mp mq nn ms mt mu im bi translated">我们模型的最后一层是具有激活函数 sigmoid 的全连接层。</p><p id="3a65" class="pw-post-body-paragraph lz ma it mb b mc mx kd me mf my kg mh mi nl mk ml mm nm mo mp mq nn ms mt mu im bi translated">由于我们的鉴别器的工作是分类给定的图像是否是假的，这是一个二元分类任务，sigmoid 是一个将每个值压缩到 0 和 1 之间的激活。</p><pre class="ks kt ku kv gt op oq or os aw ot bi"><span id="c21b" class="od li it oq b gy ou ov l ow ox">model.add(Flatten())<br/>model.add(Dense(1, activation=’sigmoid’))</span></pre></div><div class="ab cl no np hx nq" role="separator"><span class="nr bw bk ns nt nu"/><span class="nr bw bk ns nt nu"/><span class="nr bw bk ns nt"/></div><div class="im in io ip iq"><p id="d1b8" class="pw-post-body-paragraph lz ma it mb b mc mx kd me mf my kg mh mi nl mk ml mm nm mo mp mq nn ms mt mu im bi translated">现在，在初始化我们的鉴别器模型之后，让我们也创建一个生成模型。</p><pre class="ks kt ku kv gt op oq or os aw ot bi"><span id="04c5" class="od li it oq b gy ou ov l ow ox"><strong class="oq jd">def</strong> <strong class="oq jd">build_generator</strong>(noise_size, channels):<br/>    model = Sequential()<br/>    model.add(Dense(4 * 4 * 256, activation=”relu”,       input_dim=noise_size))<br/>    model.add(Reshape((4, 4, 256)))</span><span id="a6a2" class="od li it oq b gy oz ov l ow ox">    model.add(UpSampling2D())<br/>    model.add(Conv2D(256, kernel_size=3, padding=”same”))<br/>    model.add(BatchNormalization(momentum=0.8))<br/>    model.add(Activation(“relu”))</span><span id="b6d0" class="od li it oq b gy oz ov l ow ox">    model.add(UpSampling2D())<br/>    model.add(Conv2D(256, kernel_size=3, padding=”same”))<br/>    model.add(BatchNormalization(momentum=0.8))<br/>    model.add(Activation(“relu”))</span><span id="9441" class="od li it oq b gy oz ov l ow ox">    <strong class="oq jd">for</strong> i <strong class="oq jd">in</strong> range(GENERATE_RES):<br/>         model.add(UpSampling2D())<br/>         model.add(Conv2D(256, kernel_size=3, padding=”same”))<br/>         model.add(BatchNormalization(momentum=0.8))<br/>         model.add(Activation(“relu”))</span><span id="9649" class="od li it oq b gy oz ov l ow ox">    model.summary()<br/>    model.add(Conv2D(channels, kernel_size=3, padding=”same”))<br/>    model.add(Activation(“tanh”))</span><span id="cd28" class="od li it oq b gy oz ov l ow ox">    input = Input(shape=(noise_size,))<br/>    generated_image = model(input)<br/>    <br/>    <strong class="oq jd">return</strong> Model(input, generated_image)</span></pre><p id="17c2" class="pw-post-body-paragraph lz ma it mb b mc mx kd me mf my kg mh mi nl mk ml mm nm mo mp mq nn ms mt mu im bi translated">分解一下:</p><p id="3b75" class="pw-post-body-paragraph lz ma it mb b mc mx kd me mf my kg mh mi nl mk ml mm nm mo mp mq nn ms mt mu im bi translated">这里我们定义了一个函数，它将 noise_size 和 channels 作为参数。</p><p id="e2a3" class="pw-post-body-paragraph lz ma it mb b mc mx kd me mf my kg mh mi nl mk ml mm nm mo mp mq nn ms mt mu im bi translated">在函数内部，我们再次初始化了一个序列模型。</p><p id="63f3" class="pw-post-body-paragraph lz ma it mb b mc mx kd me mf my kg mh mi nl mk ml mm nm mo mp mq nn ms mt mu im bi translated">因为我们的生成器模型必须从噪声向量生成图像，所以我们的第一层是大小为 4096 (4 * 4 * 256)的完全连接的密集层，它将 noise_size 作为参数。</p><pre class="ks kt ku kv gt op oq or os aw ot bi"><span id="07d1" class="od li it oq b gy ou ov l ow ox">model.add(Dense(4 * 4 * 256, activation=”relu”, input_dim=noise_size))</span></pre><blockquote class="pf pg ph"><p id="7935" class="lz ma oy mb b mc mx kd me mf my kg mh pi nl mk ml pj nm mo mp pk nn ms mt mu im bi translated"><em class="it">注意:我们已经定义了它的大小为 4096，以便在 4X4X256 的图层中调整它的大小。</em></p></blockquote><p id="f430" class="pw-post-body-paragraph lz ma it mb b mc mx kd me mf my kg mh mi nl mk ml mm nm mo mp mq nn ms mt mu im bi translated">之后，我们使用整形图层将完全连接的图层整形为 4X4X256 的形状。</p><pre class="ks kt ku kv gt op oq or os aw ot bi"><span id="790b" class="od li it oq b gy ou ov l ow ox">model.add(Reshape((4, 4, 256)))</span></pre><p id="ddc0" class="pw-post-body-paragraph lz ma it mb b mc mx kd me mf my kg mh mi nl mk ml mm nm mo mp mq nn ms mt mu im bi translated">这之后的层块只是一个具有批量归一化和激活函数 relu 的卷积层。</p><p id="9173" class="pw-post-body-paragraph lz ma it mb b mc mx kd me mf my kg mh mi nl mk ml mm nm mo mp mq nn ms mt mu im bi translated">为了看到和理解它的样子，我们来看一下模型摘要:</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi pl"><img src="../Images/3ca622651111d45347414be1e43109b8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1348/0*TGPVC1OWza25W4J5"/></div></figure><p id="3bea" class="pw-post-body-paragraph lz ma it mb b mc mx kd me mf my kg mh mi nl mk ml mm nm mo mp mq nn ms mt mu im bi translated">从 4X4 的形状扩展到 128X128 的大小，这是我们的 training_data 形状。</p><p id="0d41" class="pw-post-body-paragraph lz ma it mb b mc mx kd me mf my kg mh mi nl mk ml mm nm mo mp mq nn ms mt mu im bi translated">我们的生成器模型将噪声作为输入，输出图像。</p></div><div class="ab cl no np hx nq" role="separator"><span class="nr bw bk ns nt nu"/><span class="nr bw bk ns nt nu"/><span class="nr bw bk ns nt"/></div><div class="im in io ip iq"><p id="da7e" class="pw-post-body-paragraph lz ma it mb b mc mx kd me mf my kg mh mi nl mk ml mm nm mo mp mq nn ms mt mu im bi translated">初始化生成器和鉴别器模型后，让我们编写一个助手函数，在一些迭代后保存图像。</p><pre class="ks kt ku kv gt op oq or os aw ot bi"><span id="d6c9" class="od li it oq b gy ou ov l ow ox"><strong class="oq jd">def</strong> save_images(cnt, noise):<br/>    image_array = np.full((<br/>        PREVIEW_MARGIN + (PREVIEW_ROWS * (IMAGE_SIZE + PREVIEW_MARGIN)),<br/>        PREVIEW_MARGIN + (PREVIEW_COLS * (IMAGE_SIZE + PREVIEW_MARGIN)), 3),<br/>        255, dtype=np.uint8)</span><span id="e98c" class="od li it oq b gy oz ov l ow ox">generated_images = generator.predict(noise)</span><span id="9d7c" class="od li it oq b gy oz ov l ow ox">generated_images = 0.5 * generated_images + 0.5</span><span id="8512" class="od li it oq b gy oz ov l ow ox">image_count = 0<br/>    <strong class="oq jd">for</strong> row in range(PREVIEW_ROWS):<br/>        <strong class="oq jd">for</strong> col in range(PREVIEW_COLS):<br/>            r = row * (IMAGE_SIZE + PREVIEW_MARGIN) + PREVIEW_MARGIN<br/>            c = col * (IMAGE_SIZE + PREVIEW_MARGIN) + PREVIEW_MARGIN<br/>            image_array[r:r + IMAGE_SIZE, c:c +<br/>                        IMAGE_SIZE] = generated_images[image_count] * 255<br/>            image_count += 1</span><span id="d811" class="od li it oq b gy oz ov l ow ox">output_path = 'output'<br/>    if not os.path.exists(output_path):<br/>        os.makedirs(output_path)</span><span id="395d" class="od li it oq b gy oz ov l ow ox">filename = os.path.join(output_path, f"trained-{cnt}.png")<br/>    im = Image.fromarray(image_array)<br/>    im.save(filename)</span></pre><p id="8179" class="pw-post-body-paragraph lz ma it mb b mc mx kd me mf my kg mh mi nl mk ml mm nm mo mp mq nn ms mt mu im bi translated">我们的 save_images 函数将计数和噪声作为输入。</p><p id="0032" class="pw-post-body-paragraph lz ma it mb b mc mx kd me mf my kg mh mi nl mk ml mm nm mo mp mq nn ms mt mu im bi translated">在函数内部，它根据我们上面定义的参数生成帧，并存储我们根据噪声输入生成的图像数组。</p><p id="4fd2" class="pw-post-body-paragraph lz ma it mb b mc mx kd me mf my kg mh mi nl mk ml mm nm mo mp mq nn ms mt mu im bi translated">之后，它会将其保存为图像。</p><p id="1a7e" class="pw-post-body-paragraph lz ma it mb b mc mx kd me mf my kg mh mi nl mk ml mm nm mo mp mq nn ms mt mu im bi translated">现在，是我们编译模型并训练它们的时候了。</p><p id="5af5" class="pw-post-body-paragraph lz ma it mb b mc mx kd me mf my kg mh mi nl mk ml mm nm mo mp mq nn ms mt mu im bi translated">让我们也为此编写一段代码:</p><pre class="ks kt ku kv gt op oq or os aw ot bi"><span id="c06f" class="od li it oq b gy ou ov l ow ox">image_shape = (IMAGE_SIZE, IMAGE_SIZE, IMAGE_CHANNELS)</span><span id="74a3" class="od li it oq b gy oz ov l ow ox">optimizer = Adam(1.5e-4, 0.5)</span><span id="447a" class="od li it oq b gy oz ov l ow ox">discriminator = build_discriminator(image_shape)<br/>discriminator.compile(loss=”binary_crossentropy”,<br/>optimizer=optimizer, metrics=[“accuracy”])<br/>generator = build_generator(NOISE_SIZE, IMAGE_CHANNELS)</span><span id="105b" class="od li it oq b gy oz ov l ow ox">random_input = Input(shape=(NOISE_SIZE,))</span><span id="de11" class="od li it oq b gy oz ov l ow ox">generated_image = generator(random_input)</span><span id="d27c" class="od li it oq b gy oz ov l ow ox">discriminator.trainable = <strong class="oq jd">False</strong></span><span id="472f" class="od li it oq b gy oz ov l ow ox">validity = discriminator(generated_image)</span><span id="5aae" class="od li it oq b gy oz ov l ow ox">combined = Model(random_input, validity)<br/>combined.compile(loss=”binary_crossentropy”,<br/>optimizer=optimizer, metrics=[“accuracy”])</span><span id="16ab" class="od li it oq b gy oz ov l ow ox">y_real = np.ones((BATCH_SIZE, 1))<br/>y_fake = np.zeros((BATCH_SIZE, 1))</span><span id="bd90" class="od li it oq b gy oz ov l ow ox">fixed_noise = np.random.normal(0, 1, (PREVIEW_ROWS * PREVIEW_COLS, NOISE_SIZE))</span><span id="384e" class="od li it oq b gy oz ov l ow ox">cnt = 1<br/><strong class="oq jd">for</strong> epoch <strong class="oq jd">in</strong> range(EPOCHS):<br/> idx = np.random.randint(0, training_data.shape[0], BATCH_SIZE)<br/> x_real = training_data[idx]<br/> <br/> noise= np.random.normal(0, 1, (BATCH_SIZE, NOISE_SIZE))<br/> x_fake = generator.predict(noise)<br/> <br/> discriminator_metric_real = discriminator.train_on_batch(x_real, y_real)</span><span id="69d9" class="od li it oq b gy oz ov l ow ox">discriminator_metric_generated = discriminator.train_on_batch(<br/> x_fake, y_fake)<br/> <br/>discriminator_metric = 0.5 * np.add(discriminator_metric_real, discriminator_metric_generated)</span><span id="898f" class="od li it oq b gy oz ov l ow ox">generator_metric = combined.train_on_batch(noise, y_real)</span><span id="66ab" class="od li it oq b gy oz ov l ow ox"><strong class="oq jd">if</strong> epoch % SAVE_FREQ == 0:<br/>   save_images(cnt, fixed_noise)<br/>   cnt += 1<br/> <br/>   print(f”{epoch} epoch, Discriminator accuracy: {100*  discriminator_metric[1]}, Generator accuracy: {100 * generator_metric[1]}”)</span></pre><p id="dacd" class="pw-post-body-paragraph lz ma it mb b mc mx kd me mf my kg mh mi nl mk ml mm nm mo mp mq nn ms mt mu im bi translated">分解一下:</p><p id="4052" class="pw-post-body-paragraph lz ma it mb b mc mx kd me mf my kg mh mi nl mk ml mm nm mo mp mq nn ms mt mu im bi translated">在这里的前几行中，我们已经定义了我们的输入形状:128X128X3 (image_size，image_size，image_channel)。</p><p id="5b01" class="pw-post-body-paragraph lz ma it mb b mc mx kd me mf my kg mh mi nl mk ml mm nm mo mp mq nn ms mt mu im bi translated">之后，我们使用亚当作为我们的优化器。</p><blockquote class="pf pg ph"><p id="998e" class="lz ma oy mb b mc mx kd me mf my kg mh pi nl mk ml pj nm mo mp pk nn ms mt mu im bi translated"><em class="it">注:所有参数均来源于论文[1]。</em></p></blockquote><pre class="ks kt ku kv gt op oq or os aw ot bi"><span id="bab7" class="od li it oq b gy ou ov l ow ox">image_shape = (IMAGE_SIZE, IMAGE_SIZE, IMAGE_CHANNELS)</span><span id="1780" class="od li it oq b gy oz ov l ow ox">optimizer = Adam(1.5e-4, 0.5)</span><span id="337f" class="od li it oq b gy oz ov l ow ox">discriminator = build_discriminator(image_shape)<br/>discriminator.compile(loss=”binary_crossentropy”,<br/>optimizer=optimizer, metrics=[“accuracy”])</span></pre><p id="6087" class="pw-post-body-paragraph lz ma it mb b mc mx kd me mf my kg mh mi nl mk ml mm nm mo mp mq nn ms mt mu im bi translated">初始化优化器后，我们调用 build_discriminator 函数并传递图像形状，然后用损失函数和优化器对其进行编译。</p><p id="4146" class="pw-post-body-paragraph lz ma it mb b mc mx kd me mf my kg mh mi nl mk ml mm nm mo mp mq nn ms mt mu im bi translated">因为它是一个分类模型，我们使用准确性作为它的性能度量。</p><p id="03f7" class="pw-post-body-paragraph lz ma it mb b mc mx kd me mf my kg mh mi nl mk ml mm nm mo mp mq nn ms mt mu im bi translated">类似地，在下一行中，我们调用 build_generator 函数并传递 random_input 噪声向量作为它的输入。</p><pre class="ks kt ku kv gt op oq or os aw ot bi"><span id="696e" class="od li it oq b gy ou ov l ow ox">generator = build_generator(NOISE_SIZE, IMAGE_CHANNELS)</span><span id="e653" class="od li it oq b gy oz ov l ow ox">random_input = Input(shape=(NOISE_SIZE,))</span><span id="b0a3" class="od li it oq b gy oz ov l ow ox">generated_image = generator(random_input)</span></pre><p id="6350" class="pw-post-body-paragraph lz ma it mb b mc mx kd me mf my kg mh mi nl mk ml mm nm mo mp mq nn ms mt mu im bi translated">它将生成的图像作为输出返回。</p><p id="d356" class="pw-post-body-paragraph lz ma it mb b mc mx kd me mf my kg mh mi nl mk ml mm nm mo mp mq nn ms mt mu im bi translated">现在，GAN 的一个重要部分是我们应该阻止我们的鉴别器进行训练。</p><pre class="ks kt ku kv gt op oq or os aw ot bi"><span id="8d08" class="od li it oq b gy ou ov l ow ox">discriminator.trainable = <strong class="oq jd">False</strong></span><span id="1b58" class="od li it oq b gy oz ov l ow ox">validity = discriminator(generated_image)</span><span id="f008" class="od li it oq b gy oz ov l ow ox">combined = Model(random_input, validity)<br/>combined.compile(loss=”binary_crossentropy”,<br/>optimizer=optimizer, metrics=[“accuracy”])</span></pre><p id="2981" class="pw-post-body-paragraph lz ma it mb b mc mx kd me mf my kg mh mi nl mk ml mm nm mo mp mq nn ms mt mu im bi translated">因为我们在这里只是训练生成器，所以我们不想调整鉴别器的权重。</p><p id="c9cc" class="pw-post-body-paragraph lz ma it mb b mc mx kd me mf my kg mh mi nl mk ml mm nm mo mp mq nn ms mt mu im bi translated">这就是对抗性网络中“对抗性”的真正含义。</p><p id="ece4" class="pw-post-body-paragraph lz ma it mb b mc mx kd me mf my kg mh mi nl mk ml mm nm mo mp mq nn ms mt mu im bi translated">如果我们不设置这个，生成器会调整它的权重，这样它就能更好的愚弄鉴别器，它也会调整鉴别器的权重，使它更好的被愚弄。</p><p id="770b" class="pw-post-body-paragraph lz ma it mb b mc mx kd me mf my kg mh mi nl mk ml mm nm mo mp mq nn ms mt mu im bi translated">我们不想这样。所以，我们要分开训练他们，互相对抗。</p><p id="2352" class="pw-post-body-paragraph lz ma it mb b mc mx kd me mf my kg mh mi nl mk ml mm nm mo mp mq nn ms mt mu im bi translated">然后，我们用损失函数和优化器编译生成模型。</p><p id="f67b" class="pw-post-body-paragraph lz ma it mb b mc mx kd me mf my kg mh mi nl mk ml mm nm mo mp mq nn ms mt mu im bi translated">之后，我们将两个向量定义为 y_real 和 y_fake。</p><pre class="ks kt ku kv gt op oq or os aw ot bi"><span id="ae46" class="od li it oq b gy ou ov l ow ox">y_real = np.ones((BATCH_SIZE, 1))<br/>y_fake = np.zeros((BATCH_SIZE, 1))</span><span id="cea5" class="od li it oq b gy oz ov l ow ox">fixed_noise = np.random.normal(0, 1, (PREVIEW_ROWS * PREVIEW_COLS, NOISE_SIZE))</span></pre><p id="e037" class="pw-post-body-paragraph lz ma it mb b mc mx kd me mf my kg mh mi nl mk ml mm nm mo mp mq nn ms mt mu im bi translated">这些向量由随机的 0 和 1 值组成。</p><p id="485c" class="pw-post-body-paragraph lz ma it mb b mc mx kd me mf my kg mh mi nl mk ml mm nm mo mp mq nn ms mt mu im bi translated">之后，我们创建一个 fixed_noise:这将导致生成的图像被保存下来，我们可以看到它在每次迭代中变得更好。</p><p id="332f" class="pw-post-body-paragraph lz ma it mb b mc mx kd me mf my kg mh mi nl mk ml mm nm mo mp mq nn ms mt mu im bi translated">之后，我们将使用我们定义的时期范围迭代我们的训练数据。</p><pre class="ks kt ku kv gt op oq or os aw ot bi"><span id="70b5" class="od li it oq b gy ou ov l ow ox">cnt = 1<br/><strong class="oq jd">for</strong> epoch <strong class="oq jd">in</strong> range(EPOCHS):<br/>  idx = np.random.randint(0, training_data.shape[0], BATCH_SIZE)<br/>  x_real = training_data[idx]<br/> <br/>  noise= np.random.normal(0, 1, (BATCH_SIZE, NOISE_SIZE))<br/>  x_fake = generator.predict(noise)<br/> <br/>  discriminator_metric_real = discriminator.train_on_batch(x_real, y_real)</span><span id="2d49" class="od li it oq b gy oz ov l ow ox">  discriminator_metric_generated = discriminator.train_on_batch(<br/> x_fake, y_fake)<br/> <br/>  discriminator_metric = 0.5 * np.add(discriminator_metric_real,   discriminator_metric_generated)</span><span id="e747" class="od li it oq b gy oz ov l ow ox"><br/>  generator_metric = combined.train_on_batch(noisse, y_real)<br/>  <strong class="oq jd">if</strong> epoch % SAVE_FREQ == 0:<br/>     save_images(cnt, fixed_noise)<br/>     cnt += 1<br/> <br/>     print(f”{epoch} epoch, Discriminator accuracy: {100*  discriminator_metric[1]}, Generator accuracy: {100 * generator_metric[1]}”)</span></pre><p id="f724" class="pw-post-body-paragraph lz ma it mb b mc mx kd me mf my kg mh mi nl mk ml mm nm mo mp mq nn ms mt mu im bi translated">在迭代过程中，我们从真实图像中提取样本，并将其放在 x_real 上。之后，我们定义一个噪声向量，并将其传递给我们的生成器模型，以在 x_fake 中生成一个假图像。</p><p id="ac46" class="pw-post-body-paragraph lz ma it mb b mc mx kd me mf my kg mh mi nl mk ml mm nm mo mp mq nn ms mt mu im bi translated">然后，我们分别在真实和虚假图像中训练我们的鉴别器模型。</p><pre class="ks kt ku kv gt op oq or os aw ot bi"><span id="b8e9" class="od li it oq b gy ou ov l ow ox">discriminator_metric_real = discriminator.train_on_batch(x_real, y_real)</span><span id="bb6b" class="od li it oq b gy oz ov l ow ox">discriminator_metric_generated = discriminator.train_on_batch(<br/> x_fake, y_fake)</span></pre><p id="862b" class="pw-post-body-paragraph lz ma it mb b mc mx kd me mf my kg mh mi nl mk ml mm nm mo mp mq nn ms mt mu im bi translated">一些研究表明，分别训练他们可以让我们得到更好的结果。</p><p id="c223" class="pw-post-body-paragraph lz ma it mb b mc mx kd me mf my kg mh mi nl mk ml mm nm mo mp mq nn ms mt mu im bi translated">训练后，我们从两个模型中提取指标并取平均值。</p><pre class="ks kt ku kv gt op oq or os aw ot bi"><span id="2982" class="od li it oq b gy ou ov l ow ox">discriminator_metric = 0.5 * np.add(discriminator_metric_real, discriminator_metric_generated)</span></pre><p id="12eb" class="pw-post-body-paragraph lz ma it mb b mc mx kd me mf my kg mh mi nl mk ml mm nm mo mp mq nn ms mt mu im bi translated">通过这种方式，我们获得了鉴别器模型的指标，现在，对于发生器模型，我们在噪声向量和 y_real:上训练它，y _ real:是 1 的向量。</p><p id="fb70" class="pw-post-body-paragraph lz ma it mb b mc mx kd me mf my kg mh mi nl mk ml mm nm mo mp mq nn ms mt mu im bi translated">在这里，我们试图训练发电机。超时生成器将从这些输入中变得更好，并且鉴别器将不能鉴别输入是假还是真。</p><p id="0865" class="pw-post-body-paragraph lz ma it mb b mc mx kd me mf my kg mh mi nl mk ml mm nm mo mp mq nn ms mt mu im bi translated">这里需要注意的一点是，我们的组合模型是基于直接链接到鉴别器模型的生成器模型。这里我们的输入是发生器想要的输入:噪声，输出是鉴别器给我们的。</p><p id="60fa" class="pw-post-body-paragraph lz ma it mb b mc mx kd me mf my kg mh mi nl mk ml mm nm mo mp mq nn ms mt mu im bi translated">最后，我们有一个 if 语句来检查我们的检查点。</p><pre class="ks kt ku kv gt op oq or os aw ot bi"><span id="fb26" class="od li it oq b gy ou ov l ow ox"><strong class="oq jd">if</strong> epoch % SAVE_FREQ == 0:<br/> save_images(cnt, fixed_noise)<br/> cnt += 1<br/> <br/> print(f”{epoch} epoch, Discriminator accuracy: {100* discriminator_metric[1]}, Generator accuracy: {100 * generator_metric[1]}”)</span></pre><p id="48bb" class="pw-post-body-paragraph lz ma it mb b mc mx kd me mf my kg mh mi nl mk ml mm nm mo mp mq nn ms mt mu im bi translated">如果到达检查点，则保存当前迭代噪声并打印生成器和鉴别器的当前精度。</p><p id="d5bc" class="pw-post-body-paragraph lz ma it mb b mc mx kd me mf my kg mh mi nl mk ml mm nm mo mp mq nn ms mt mu im bi translated">这都是为了创建 GAN 的编码部分，但我们还没有完成。</p><p id="5c64" class="pw-post-body-paragraph lz ma it mb b mc mx kd me mf my kg mh mi nl mk ml mm nm mo mp mq nn ms mt mu im bi translated">我们刚刚为它编写了代码，现在我们必须实际训练这些模型，并查看它的输出表现如何。</p></div><div class="ab cl no np hx nq" role="separator"><span class="nr bw bk ns nt nu"/><span class="nr bw bk ns nt nu"/><span class="nr bw bk ns nt"/></div><div class="im in io ip iq"><h1 id="f864" class="lh li it bd lj lk nv lm ln lo nw lq lr ki nx kj lt kl ny km lv ko nz kp lx ly bi translated">训练甘</h1><p id="cf3c" class="pw-post-body-paragraph lz ma it mb b mc md kd me mf mg kg mh mi mj mk ml mm mn mo mp mq mr ms mt mu im bi translated">在普通的笔记本电脑上训练 GAN 是不可能的，因为它需要很高的计算能力。</p><p id="41d9" class="pw-post-body-paragraph lz ma it mb b mc mx kd me mf my kg mh mi nl mk ml mm nm mo mp mq nn ms mt mu im bi translated">普通 CPU 的普通笔记本电脑无法处理如此庞大的任务，所以我们准备用<a class="ae oa" href="https://web.spell.run/refer/anyesh" rel="noopener ugc nofollow" target="_blank"> <strong class="mb jd">拼</strong> </a>:这是机器学习和深度学习最快最强大的端到端平台。</p><h2 id="7c2d" class="od li it bd lj oe of dn ln og oh dp lr mi oi oj lt mm ok ol lv mq om on lx iz bi translated">为什么拼写？</h2><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi pm"><img src="../Images/54c5ca3105ec9286f2ac46298dd21a1c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*78pyUstpRlfgMyoQ.png"/></div></div></figure><p id="c1dd" class="pw-post-body-paragraph lz ma it mb b mc mx kd me mf my kg mh mi nl mk ml mm nm mo mp mq nn ms mt mu im bi translated">魔咒是构建和管理机器学习项目的强大平台。魔咒负责基础设施，使机器学习项目更容易启动，更快获得结果，更有组织性，比自己管理基础设施更安全。</p><blockquote class="pf pg ph"><p id="7186" class="lz ma oy mb b mc mx kd me mf my kg mh pi nl mk ml pj nm mo mp pk nn ms mt mu im bi translated">在每一个法术注册，你可以获得 10 元免费信贷！</p></blockquote><p id="81c1" class="pw-post-body-paragraph lz ma it mb b mc mx kd me mf my kg mh mi nl mk ml mm nm mo mp mq nn ms mt mu im bi translated">简单地说，我们将把我们的数据文件上传到拼写平台，让它处理我们所有的训练任务。Spell 在他们强大的 GPU 中运行我们的任务，这样我们就什么都不用担心了。我们可以从他们的 Web GUI 监控我们的日志，并且我们所有的输出都被安全地保存。</p><h2 id="69b4" class="od li it bd lj oe of dn ln og oh dp lr mi oi oj lt mm ok ol lv mq om on lx iz bi translated">培训过程</h2><p id="4f62" class="pw-post-body-paragraph lz ma it mb b mc md kd me mf mg kg mh mi mj mk ml mm mn mo mp mq mr ms mt mu im bi translated">在<a class="ae oa" href="https://spell.run/" rel="noopener ugc nofollow" target="_blank">拼写</a>运行我们的项目之前，有几件事情要涉及。</p><p id="9dc9" class="pw-post-body-paragraph lz ma it mb b mc mx kd me mf my kg mh mi nl mk ml mm nm mo mp mq nn ms mt mu im bi translated">首先，我们必须创建我们的法术账户。在他们的官方页面上有很好很容易上手的<a class="ae oa" href="https://spell.run/docs/" rel="noopener ugc nofollow" target="_blank">文档</a>。</p><p id="2104" class="pw-post-body-paragraph lz ma it mb b mc mx kd me mf my kg mh mi nl mk ml mm nm mo mp mq nn ms mt mu im bi translated">创建帐户后，我们可以使用 pip install 安装 Spell CLI:</p><pre class="ks kt ku kv gt op oq or os aw ot bi"><span id="71f2" class="od li it oq b gy ou ov l ow ox">pip install spell</span></pre><p id="2e89" class="pw-post-body-paragraph lz ma it mb b mc mx kd me mf my kg mh mi nl mk ml mm nm mo mp mq nn ms mt mu im bi translated">这就把所有的法术能量都安装到了我们的笔记本电脑上。我们既可以使用 Web GUI，也可以轻松地登录到 spell 服务器，从 cmd 或 bash 执行命令。</p><p id="7a6b" class="pw-post-body-paragraph lz ma it mb b mc mx kd me mf my kg mh mi nl mk ml mm nm mo mp mq nn ms mt mu im bi translated">为了上传我们的项目，我们将使用命令行工具。</p><p id="f4c9" class="pw-post-body-paragraph lz ma it mb b mc mx kd me mf my kg mh mi nl mk ml mm nm mo mp mq nn ms mt mu im bi translated">让我们在项目文件夹的根目录中打开命令行终端，并使用拼写登录命令登录到服务器:</p><pre class="ks kt ku kv gt op oq or os aw ot bi"><span id="4fb8" class="od li it oq b gy ou ov l ow ox">spell login</span></pre><p id="747a" class="pw-post-body-paragraph lz ma it mb b mc mx kd me mf my kg mh mi nl mk ml mm nm mo mp mq nn ms mt mu im bi translated">成功登录后，现在我们可以上传我们的训练数据文件，并在拼写服务器中运行我们的代码:</p><pre class="ks kt ku kv gt op oq or os aw ot bi"><span id="962a" class="od li it oq b gy ou ov l ow ox">Spell upload “filename”</span></pre><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi pn"><img src="../Images/6a1a3ead9d1f19b7cf2e1b5b2cd87b1a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*bZOaWNYVA8gKEHkU"/></div></div></figure><p id="93db" class="pw-post-body-paragraph lz ma it mb b mc mx kd me mf my kg mh mi nl mk ml mm nm mo mp mq nn ms mt mu im bi translated">之后，我们的训练数据将被上传到服务器。</p><blockquote class="pf pg ph"><p id="3604" class="lz ma oy mb b mc mx kd me mf my kg mh pi nl mk ml pj nm mo mp pk nn ms mt mu im bi translated"><em class="it">注意:在服务器运行代码之前，代码已经被推送到 github。</em></p></blockquote><p id="2fd5" class="pw-post-body-paragraph lz ma it mb b mc mx kd me mf my kg mh mi nl mk ml mm nm mo mp mq nn ms mt mu im bi translated">现在我们准备在拼写服务器中执行我们的代码。</p><p id="fade" class="pw-post-body-paragraph lz ma it mb b mc mx kd me mf my kg mh mi nl mk ml mm nm mo mp mq nn ms mt mu im bi translated">在命令行中，让我们运行以下命令:</p><pre class="ks kt ku kv gt op oq or os aw ot bi"><span id="9fa4" class="od li it oq b gy ou ov l ow ox">Spell run python art_gan.py -t V100 -m uploads/art_gan/cubism_data.npy</span></pre><p id="e800" class="pw-post-body-paragraph lz ma it mb b mc mx kd me mf my kg mh mi nl mk ml mm nm mo mp mq nn ms mt mu im bi translated">上面的命令在机器类型为 V100 的 Spell 服务器上运行我们的代码，这是一台 GPU 机器。最后一个参数挂载数据集目录，以便我们的代码可以访问它。</p><p id="4719" class="pw-post-body-paragraph lz ma it mb b mc mx kd me mf my kg mh mi nl mk ml mm nm mo mp mq nn ms mt mu im bi translated">现在代码已经成功执行，您可以在控制台上看到日志。如果您想在 GUI 中进行监控，那么您可以登录到 Spell 的 Web GUI，查看“运行”部分。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi po"><img src="../Images/06d68a417b3f0287aadd53bbb0fb2bfe.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*KcHHE6mAGHLxHmnr"/></div></div></figure><p id="441d" class="pw-post-body-paragraph lz ma it mb b mc mx kd me mf my kg mh mi nl mk ml mm nm mo mp mq nn ms mt mu im bi translated">如您所见，它保存了我们最近运行的所有信息。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi pa"><img src="../Images/1c592fa45b8c3ad51f157e32ea0b1551.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*EHHElwcQWATC6Yss"/></div></div></figure><p id="fb4f" class="pw-post-body-paragraph lz ma it mb b mc mx kd me mf my kg mh mi nl mk ml mm nm mo mp mq nn ms mt mu im bi translated">就像我们写的代码一样。在每 100 次迭代中，我们生成的图像被保存在输出目录中，并打印带有精度度量的日志。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi pp"><img src="../Images/8a8aec2d5f9dbc9466f2406d13104e7a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*qvvsvEZCJePKR-K7"/></div></div></figure><p id="ec21" class="pw-post-body-paragraph lz ma it mb b mc mx kd me mf my kg mh mi nl mk ml mm nm mo mp mq nn ms mt mu im bi translated">您可以在日志部分查看它们。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi pq"><img src="../Images/68cf002d5568e7b966611d5fef2c33c6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*fcBliro5ZjrSbrsw"/></div></div></figure><p id="9cbc" class="pw-post-body-paragraph lz ma it mb b mc mx kd me mf my kg mh mi nl mk ml mm nm mo mp mq nn ms mt mu im bi translated">太棒了，不是吗？当它为你训练和保存输出时，你可以做你的其他工作。</p><h2 id="6e32" class="od li it bd lj oe of dn ln og oh dp lr mi oi oj lt mm ok ol lv mq om on lx iz bi translated">输出</h2><p id="1487" class="pw-post-body-paragraph lz ma it mb b mc md kd me mf mg kg mh mi mj mk ml mm mn mo mp mq mr ms mt mu im bi translated">现在，训练完成后，Spell 会自动将我们的输出保存在 resources/runs 目录中。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi pa"><img src="../Images/1588863a08aae15973be05ff8bbf160f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*H6Sh3jIK1o8RvQvj"/></div></div></figure><p id="353c" class="pw-post-body-paragraph lz ma it mb b mc mx kd me mf my kg mh mi nl mk ml mm nm mo mp mq nn ms mt mu im bi translated">之后，我们可以使用以下命令将 Spell 运行的输出下载到我们的本地机器上:</p><pre class="ks kt ku kv gt op oq or os aw ot bi"><span id="400c" class="od li it oq b gy ou ov l ow ox">spell cp [OPTIONS] SOURCE_PATH [LOCAL_DIR]</span></pre><p id="72fa" class="pw-post-body-paragraph lz ma it mb b mc mx kd me mf my kg mh mi nl mk ml mm nm mo mp mq nn ms mt mu im bi translated">对于这个项目，它将是:</p><pre class="ks kt ku kv gt op oq or os aw ot bi"><span id="f530" class="od li it oq b gy ou ov l ow ox">spell cp runs/44</span></pre><p id="5a3e" class="pw-post-body-paragraph lz ma it mb b mc mx kd me mf my kg mh mi nl mk ml mm nm mo mp mq nn ms mt mu im bi translated">您只需输入 runs/ <number of="" your="" run="">即可下载该 runs 的内容。</number></p><p id="a81c" class="pw-post-body-paragraph lz ma it mb b mc mx kd me mf my kg mh mi nl mk ml mm nm mo mp mq nn ms mt mu im bi translated">就是这样！！现在，您已经在本地机器上的 Spell 的 GPU 机器上训练了 GAN 的输出。现在，您可以从输出图像中直观地看到 GAN 执行情况。</p></div><div class="ab cl no np hx nq" role="separator"><span class="nr bw bk ns nt nu"/><span class="nr bw bk ns nt nu"/><span class="nr bw bk ns nt"/></div><div class="im in io ip iq"><h1 id="a7d2" class="lh li it bd lj lk nv lm ln lo nw lq lr ki nx kj lt kl ny km lv ko nz kp lx ly bi translated">结论</h1><p id="e69d" class="pw-post-body-paragraph lz ma it mb b mc md kd me mf mg kg mh mi mj mk ml mm mn mo mp mq mr ms mt mu im bi translated">GANs 是一个令人兴奋且快速变化的领域，它实现了生成模型的承诺，能够在一系列问题领域生成真实的例子。一夜之间理解 GAN 或者任何机器学习、深度学习领域都不是一件容易的事情。这需要耐心、大量的练习和理解。</p><p id="202a" class="pw-post-body-paragraph lz ma it mb b mc mx kd me mf my kg mh mi nl mk ml mm nm mo mp mq nn ms mt mu im bi translated">在以前，对于像我们这样有抱负的 ML 爱好者来说，进行重复的练习来看看发生了什么是不可能的。但是现在，像<strong class="mb jd"> Spell </strong>这样的平台帮助我们提供一个系统来运行和管理我们的项目，这样我们就可以运行和测试我们的模型。</p><p id="e2c3" class="pw-post-body-paragraph lz ma it mb b mc mx kd me mf my kg mh mi nl mk ml mm nm mo mp mq nn ms mt mu im bi translated">我们所创造的只是 GAN 如何被创造和 GAN 能做什么的简单表示。还有更高级的调整有待执行。</p><p id="6a88" class="pw-post-body-paragraph lz ma it mb b mc mx kd me mf my kg mh mi nl mk ml mm nm mo mp mq nn ms mt mu im bi translated">为了更进一步，你可以调整参数，看看它如何不同地生成图像。</p><p id="cfde" class="pw-post-body-paragraph lz ma it mb b mc mx kd me mf my kg mh mi nl mk ml mm nm mo mp mq nn ms mt mu im bi translated">还有很多东西可以研究。</p></div><div class="ab cl no np hx nq" role="separator"><span class="nr bw bk ns nt nu"/><span class="nr bw bk ns nt nu"/><span class="nr bw bk ns nt"/></div><div class="im in io ip iq"><p id="5395" class="pw-post-body-paragraph lz ma it mb b mc mx kd me mf my kg mh mi nl mk ml mm nm mo mp mq nn ms mt mu im bi translated">如有任何疑问和讨论，你可以从这里加入拼写社区:【https://chat.spell.ml/ T2】</p></div><div class="ab cl no np hx nq" role="separator"><span class="nr bw bk ns nt nu"/><span class="nr bw bk ns nt nu"/><span class="nr bw bk ns nt"/></div><div class="im in io ip iq"><h1 id="43ee" class="lh li it bd lj lk nv lm ln lo nw lq lr ki nx kj lt kl ny km lv ko nz kp lx ly bi translated">参考</h1><p id="a3c9" class="pw-post-body-paragraph lz ma it mb b mc md kd me mf mg kg mh mi mj mk ml mm mn mo mp mq mr ms mt mu im bi translated">[1] <strong class="mb jd">生成对抗网络</strong>，伊恩·古德菲勒，让·普盖-阿巴迪，迈赫迪·米尔扎，徐炳，大卫·沃德-法利，谢尔吉尔·奥泽尔，亚伦·库维尔，约舒阿·本吉奥，2014</p><p id="a6bb" class="pw-post-body-paragraph lz ma it mb b mc mx kd me mf my kg mh mi nl mk ml mm nm mo mp mq nn ms mt mu im bi translated">[2] <strong class="mb jd">生成性对抗网络(GANs)的温和介绍</strong>杰森·布朗利，2019【在线】<a class="ae oa" href="https://machinelearningmastery.com/what-are-generative-adversarial-networks-gans/" rel="noopener ugc nofollow" target="_blank">https://machine learning mastery . com/what-are-Generative-Adversarial-Networks-GANs/</a></p><p id="cdfe" class="pw-post-body-paragraph lz ma it mb b mc mx kd me mf my kg mh mi nl mk ml mm nm mo mp mq nn ms mt mu im bi translated">[3] <strong class="mb jd">生成对抗网络(GANs)入门指南</strong>克里斯，2019【在线】<a class="ae oa" href="https://skymind.ai/wiki/generative-adversarial-network-gan" rel="noopener ugc nofollow" target="_blank">https://skymind.ai/wiki/generative-adversarial-network-gan</a></p></div></div>    
</body>
</html>