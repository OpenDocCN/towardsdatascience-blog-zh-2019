<html>
<head>
<title>Real-time Twitter Sentiment Analysis for Brand Improvement and Topic Tracking (Chapter 2/3)</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">用于品牌提升和话题跟踪的实时 Twitter 情感分析(第 2/3 章)</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/real-time-twitter-sentiment-analysis-for-brand-improvement-and-topic-tracking-chapter-2-3-1caf05346721?source=collection_archive---------6-----------------------#2019-09-01">https://towardsdatascience.com/real-time-twitter-sentiment-analysis-for-brand-improvement-and-topic-tracking-chapter-2-3-1caf05346721?source=collection_archive---------6-----------------------#2019-09-01</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><h2 id="54df" class="io ip iq bd b dl ir is it iu iv iw dk ix translated" aria-label="kicker paragraph">行业中的数据科学</h2><div class=""/><div class=""><h2 id="f0f5" class="pw-subtitle-paragraph jw iz iq bd b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn dk translated">使用 RE、TextBlob、NLTK 和 Plotly 进行 Twitter 情感分析和交互式数据可视化</h2></div><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi ko"><img src="../Images/539cede38ac9d047756c6eb73bd50e28.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*2ouAbzO_RoQwh_Ig"/></div></div><figcaption class="la lb gj gh gi lc ld bd b be z dk">Photo by <a class="ae le" href="https://unsplash.com/@r3dmax?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Jonatan Pie</a> on <a class="ae le" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><p id="bd56" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">教程将教你如何一步一步地在 Twitter 数据上应用 1) <strong class="lh ja">自然语言处理</strong>和<strong class="lh ja">情感分析</strong>，2)利用<strong class="lh ja"> Plotly </strong>构建一个<strong class="lh ja">交互式数据可视化</strong>。</p><p id="9d56" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">这是一个独立的组件，用于执行情绪分析和话题跟踪，并在 Jupiter Notebook 上构建分析仪表板，尽管它是我的综合实时 Twitter 监控系统教程的第二部分。在前一章中解释并实现了流 Twitter 数据收集。</p><ul class=""><li id="446f" class="mb mc iq lh b li lj ll lm lo md ls me lw mf ma mg mh mi mj bi translated"><a class="ae le" rel="noopener" target="_blank" href="/real-time-twitter-sentiment-analysis-for-brand-improvement-and-topic-tracking-chapter-1-3-e02f7652d8ff"> <strong class="lh ja">第 1 章</strong> </a> <strong class="lh ja"> : </strong>使用 Tweepy、MySQL、&amp; Python 的流 Twitter API 收集 Twitter 数据</li><li id="7ae2" class="mb mc iq lh b li mk ll ml lo mm ls mn lw mo ma mg mh mi mj bi translated"><strong class="lh ja">第二章(你来了！):</strong>使用 RE、TextBlob、NLTK 和 Plotly 进行 Twitter 情感分析和交互式数据可视化</li><li id="103a" class="mb mc iq lh b li mk ll ml lo mm ls mn lw mo ma mg mh mi mj bi translated"><a class="ae le" href="http://bit.ly/2msOUbR" rel="noopener ugc nofollow" target="_blank"> <strong class="lh ja">第三章</strong> </a> <strong class="lh ja"> : </strong>使用 Python 中的 Dash &amp; Plotly 在 Heroku 上部署一个实时的 Twitter 分析 Web App</li><li id="b6fd" class="mb mc iq lh b li mk ll ml lo mm ls mn lw mo ma mg mh mi mj bi translated"><strong class="lh ja">第 4 章</strong>(可选)<strong class="lh ja"> : </strong>使用 Scala、Kafka 和 Spark Streaming 实现流媒体 Twitter 情感分析的并行化</li></ul><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi mp"><img src="../Images/a36e56712db16599d87c4dbb3af76bea.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*oHjuVRvCbv2eWlyJaoCgLQ.png"/></div></div><figcaption class="la lb gj gh gi lc ld bd b be z dk">Data Visualization based on Plotly in this Chapter</figcaption></figure><p id="4b53" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">上面的<a class="ae le" href="https://nbviewer.jupyter.org/github/Chulong-Li/Real-time-Sentiment-Tracking-on-Twitter-for-Brand-Improvement-and-Trend-Recognition/blob/master/Trend_Analysis_Complex.ipynb" rel="noopener ugc nofollow" target="_blank"><strong class="lh ja"/></a>分析仪表板(带完整代码)就是我们今天要做的，它为下一章的<a class="ae le" href="http://bit.ly/30VS87a" rel="noopener ugc nofollow" target="_blank"> <strong class="lh ja">实时 Twitter 监控 Web App </strong> </a>奠定了基础，因为 Dash(python framework for analytical Web apps)是在 Plotly 之上编写的。查看我的<a class="ae le" href="http://bit.ly/33UKT12" rel="noopener ugc nofollow" target="_blank"> <strong class="lh ja"> GitHub 回购</strong> </a>了解更多详情。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi mq"><img src="../Images/31b488cada146cc088031ad457da5918.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/1*mPZ0eqG1LYCRl5m0sm75tQ.gif"/></div></div><figcaption class="la lb gj gh gi lc ld bd b be z dk">Web App based on Dash-Plotly in next chapter</figcaption></figure></div><div class="ab cl mr ms hu mt" role="separator"><span class="mu bw bk mv mw mx"/><span class="mu bw bk mv mw mx"/><span class="mu bw bk mv mw"/></div><div class="ij ik il im in"><p id="b1fc" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated"><strong class="lh ja">第</strong>章的技术栈:RE，NLTK，TextBlob，Plotly，MySQL，Python (time，datetime，math，itertools)</p><ul class=""><li id="8d84" class="mb mc iq lh b li lj ll lm lo md ls me lw mf ma mg mh mi mj bi translated"><a class="ae le" href="https://docs.python.org/3.7/library/re.html" rel="noopener ugc nofollow" target="_blank"> <strong class="lh ja"> RE </strong> </a> : <strong class="lh ja">正则表达式</strong>识别给定字符序列中是否存在模式的操作</li><li id="9695" class="mb mc iq lh b li mk ll ml lo mm ls mn lw mo ma mg mh mi mj bi translated"><a class="ae le" href="https://www.nltk.org" rel="noopener ugc nofollow" target="_blank"> <strong class="lh ja"> NLTK </strong> </a> : <strong class="lh ja">自然语言</strong>工具包，构建 Python 程序处理人类语言数据的领先平台</li><li id="c7a6" class="mb mc iq lh b li mk ll ml lo mm ls mn lw mo ma mg mh mi mj bi translated"><a class="ae le" href="https://textblob.readthedocs.io/en/dev/" rel="noopener ugc nofollow" target="_blank"> <strong class="lh ja"> TextBlob </strong> </a> : <strong class="lh ja">自然语言处理</strong>库，用于处理文本数据，提供一个<strong class="lh ja">简单的 API </strong>用于潜入普通的 NLP。</li><li id="3b26" class="mb mc iq lh b li mk ll ml lo mm ls mn lw mo ma mg mh mi mj bi translated"><a class="ae le" href="https://plot.ly/python/" rel="noopener ugc nofollow" target="_blank"><strong class="lh ja"/></a>:一个<strong class="lh ja">交互式</strong>，开源的，基于浏览器的<strong class="lh ja">Python 图形库</strong></li></ul></div><div class="ab cl mr ms hu mt" role="separator"><span class="mu bw bk mv mw mx"/><span class="mu bw bk mv mw mx"/><span class="mu bw bk mv mw"/></div><div class="ij ik il im in"><h2 id="7010" class="my mz iq bd na nb nc dn nd ne nf dp ng lo nh ni nj ls nk nl nm lw nn no np iw bi translated">加载和准备 Twitter 数据</h2><p id="bc87" class="pw-post-body-paragraph lf lg iq lh b li nq ka lk ll nr kd ln lo ns lq lr ls nt lu lv lw nu ly lz ma ij bi translated">首先，我们需要从数据源中提取 Twitter 数据。简单起见可以直接从<code class="fe nv nw nx ny b">sample_data.csv</code>开始读。</p><pre class="kp kq kr ks gt nz ny oa ob aw oc bi"><span id="9d65" class="my mz iq ny b gy od oe l of og">df = pd.read_csv("sample_data.csv")</span></pre><p id="a8eb" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">或者以一种更正式的方式，从我们的 MySQL 数据库中提取数据，该数据库已经在第 1 章中建立并填充了实时 Twitter 数据。</p><pre class="kp kq kr ks gt nz ny oa ob aw oc bi"><span id="83fb" class="my mz iq ny b gy od oe l of og">db_connection = mysql.connector.connect(<br/>    host="localhost",<br/>    user="root",<br/>    passwd="password",<br/>    database="TwitterDB",<br/>    charset = 'utf8'<br/> )<br/>time_now = datetime.datetime.utcnow()<br/>time_10mins_before = datetime.timedelta(hours=0,minutes=10)) \<br/>    .strftime('%Y-%m-%d %H:%M:%S'<br/>time_interval = time_now - time_10mins_before</span></pre><p id="452a" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">读取过去 30 分钟内发布的数据，并通过 SQL 查询将其加载到 Pandas DataFrame 中。</p><pre class="kp kq kr ks gt nz ny oa ob aw oc bi"><span id="2472" class="my mz iq ny b gy od oe l of og">query = "SELECT id_str, text, created_at, polarity,          \<br/>         user_location FROM <strong class="ny ja">{}</strong> WHERE created_at &gt;= '<strong class="ny ja">{}</strong>'"     \<br/>        .format(settings.TABLE_NAME, time_interval)<br/>df = pd.read_sql(query, con=db_connection)</span></pre><p id="3c24" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">然后把 DATETIME (MySQL 数据类型)转换成 Datetime (Pandas 数据类型)。</p><pre class="kp kq kr ks gt nz ny oa ob aw oc bi"><span id="bee7" class="my mz iq ny b gy od oe l of og"><em class="oh"># UTC for date time at default</em><br/>df['created_at'] = pd.to_datetime(df['created_at'])</span></pre><h2 id="684e" class="my mz iq bd na nb nc dn nd ne nf dp ng lo nh ni nj ls nk nl nm lw nn no np iw bi translated">使用<a class="ae le" href="https://textblob.readthedocs.io/en/dev/" rel="noopener ugc nofollow" target="_blank">文本块</a>进行情感分析</h2><p id="59c8" class="pw-post-body-paragraph lf lg iq lh b li nq ka lk ll nr kd ln lo ns lq lr ls nt lu lv lw nu ly lz ma ij bi translated">情感分析的核心是使用 TextBlob，以便从 tweet 文本中提取<strong class="lh ja">极性</strong> &amp; <strong class="lh ja">主观性</strong>，这实际上是上一章为了更好地存储数据而进行的数据预处理。负面推文代表-1，正面推文代表+1，中性推文代表 0。</p><pre class="kp kq kr ks gt nz ny oa ob aw oc bi"><span id="bad1" class="my mz iq ny b gy od oe l of og">from <strong class="ny ja">textblob</strong> import TextBlob<br/>sentiment = TextBlob(tweet_text).sentiment<br/>polarity = sentiment.polarity<br/>subjectivity = sentiment.subjectivity</span></pre><p id="73f9" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">将整个时间序列转换为 2 秒一组，并计算每个时间间隔组中每种极性(例如-1、0 和 1)的情绪数量。</p><p id="d065" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">应用<strong class="lh ja">拆栈</strong>技术以确保每组中的所有类别都被显示，即使其中一个类别没有任何值。因为我们只显示最近 30 分钟内发布的实时推文，所以在实践中，2 秒间隔的组最好显示在屏幕上。之后，重命名这些列，使它们能够自我解释。</p><pre class="kp kq kr ks gt nz ny oa ob aw oc bi"><span id="866a" class="my mz iq ny b gy od oe l of og"><em class="oh"># Clean and transform data to enable time series</em><br/>result = df.groupby(                                        \<br/>      [pd.Grouper(key='created_at', freq='2s'), 'polarity'] \<br/>    ).count().unstack(fill_value=0).stack().reset_index()<br/><br/>result = result.rename(columns=                             \<br/>    { "id_str": "Num of '{}' mentions".format(TRACK_WORD),  \<br/>      "created_at":"Time in UTC" })</span></pre><p id="3b52" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">以 2 秒的间隔记录时间序列，以便进一步使用索引。</p><pre class="kp kq kr ks gt nz ny oa ob aw oc bi"><span id="761a" class="my mz iq ny b gy od oe l of og">time_series = result["Time in UTC"][result['polarity']==0]  \ <br/>    .reset_index(drop=<strong class="ny ja">True</strong>)</span></pre><p id="22b9" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">使用简单的<a class="ae le" href="https://plot.ly/python/plotly-express/" rel="noopener ugc nofollow" target="_blank"><strong class="lh ja">Plotly Express</strong></a>快速可视化折线图。注意:Plotly Express 是一个简洁、一致、高级的<code class="fe nv nw nx ny b">plotly.graph_objects</code>包装器，用于快速数据探索和图形生成。</p><pre class="kp kq kr ks gt nz ny oa ob aw oc bi"><span id="2812" class="my mz iq ny b gy od oe l of og">import <strong class="ny ja">plotly.express</strong> as px<br/>fig = px.line(result, x='Time in UTC',                      \<br/>    y="Num of '{}' mentions".format(TRACK_WORD),            \<br/>    color='polarity')<br/>fig.show()</span></pre><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi oi"><img src="../Images/a65d5a03593583270743c7479da41d20.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*AK0caqDJhnjt_PIihy5Ebw.png"/></div></div><figcaption class="la lb gj gh gi lc ld bd b be z dk">Line Chart for Sentiment Analysis</figcaption></figure><h2 id="4e97" class="my mz iq bd na nb nc dn nd ne nf dp ng lo nh ni nj ls nk nl nm lw nn no np iw bi translated"><strong class="ak">使用 RE 的自然语言处理的主题跟踪&amp; NLTK </strong></h2><p id="c17b" class="pw-post-body-paragraph lf lg iq lh b li nq ka lk ll nr kd ln lo ns lq lr ls nt lu lv lw nu ly lz ma ij bi translated">为了跟踪推文中最热门的词或最常用的符号，我们加入所有推文，删除 URL，清除“RT”和“T36”(也称为“T37”)amp；。)符号，并将所有字符转换成小写。</p><pre class="kp kq kr ks gt nz ny oa ob aw oc bi"><span id="ee29" class="my mz iq ny b gy od oe l of og">content = ' '.join(df["text"])<br/>content = re.sub(r"http\S+", "", content)<br/>content = content.replace('RT ', ' ').replace('&amp;amp;', 'and')<br/>content = re.sub('[^A-Za-z0-9]+', ' ', content)<br/>content = content.lower()</span></pre><p id="c51e" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">第一次使用 python 脚本从 NLTK 下载这两个文件。<a class="ae le" href="https://www.nltk.org/api/nltk.tokenize.html#module-nltk.tokenize.punkt" rel="noopener ugc nofollow" target="_blank"> <strong class="lh ja"> Punkt 句子分词器</strong> </a>用于通过使用无监督算法将文本分成一系列句子。</p><pre class="kp kq kr ks gt nz ny oa ob aw oc bi"><span id="296e" class="my mz iq ny b gy od oe l of og"><em class="oh">import nltk<br/>nltk.download('punkt')</em><br/><em class="oh">nltk.download('stopwords')</em></span></pre><p id="6bf5" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">然后<strong class="lh ja">从所有推文中对整个文本进行</strong>分词，使用<a class="ae le" href="https://www.geeksforgeeks.org/removing-stop-words-nltk-python/" rel="noopener ugc nofollow" target="_blank"> <strong class="lh ja">停用词</strong> </a>去除常用词，并提取所有词的<a class="ae le" href="http://www.nltk.org/api/nltk.html?highlight=freqdist#nltk.probability.FreqDist" rel="noopener ugc nofollow" target="_blank"> <strong class="lh ja">频率分布</strong> </a>中最常见的 10 个词。</p><pre class="kp kq kr ks gt nz ny oa ob aw oc bi"><span id="fc54" class="my mz iq ny b gy od oe l of og">from <strong class="ny ja">nltk.probability</strong> import FreqDist<br/>from <strong class="ny ja">nltk.tokenize</strong> import word_tokenize<br/>from <strong class="ny ja">nltk.corpus</strong> import stopwords</span><span id="723b" class="my mz iq ny b gy oj oe l of og">tokenized_word = word_tokenize(content)<br/>stop_words=set(stopwords.words("english"))<br/>filtered_sent=[]<br/><strong class="ny ja">for</strong> w <strong class="ny ja">in</strong> tokenized_word:<br/>    <strong class="ny ja">if</strong> w <strong class="ny ja">not</strong> <strong class="ny ja">in</strong> stop_words:<br/>        filtered_sent.append(w)<br/>fdist = FreqDist(filtered_sent)<br/>fd = pd.DataFrame(fdist.most_common(10),                    \<br/>    columns = ["Word","Frequency"]).drop([0]).reindex()</span></pre><p id="5d38" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">再次使用简单的<a class="ae le" href="https://plot.ly/python/plotly-express/" rel="noopener ugc nofollow" target="_blank"> <strong class="lh ja">图形表达</strong> </a>快速可视化条形图。</p><pre class="kp kq kr ks gt nz ny oa ob aw oc bi"><span id="a098" class="my mz iq ny b gy od oe l of og">import <strong class="ny ja">plotly.express</strong> as px<br/>fig = px.bar(fd, x="Word", y="Frequency")<br/>fig.update_traces(marker_color='rgb(240,128,128)',          \<br/>    marker_line_color='rgb(8,48,107)',                      \<br/>    marker_line_width=1.5, opacity=0.8)<br/>fig.show()</span></pre><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi ok"><img src="../Images/07d87ddeb6656721a8593ad008f0f852.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*PqodldjO9UhGDEf0_24xAw.png"/></div></div><figcaption class="la lb gj gh gi lc ld bd b be z dk">Bar Chart for Topic Tracking</figcaption></figure><h2 id="9a5b" class="my mz iq bd na nb nc dn nd ne nf dp ng lo nh ni nj ls nk nl nm lw nn no np iw bi translated">文本处理中的地理分割识别</h2><p id="6402" class="pw-post-body-paragraph lf lg iq lh b li nq ka lk ll nr kd ln lo ns lq lr ls nt lu lv lw nu ly lz ma ij bi translated">为了探索用户的地理分布，我们需要通过他们的<strong class="lh ja">用户资料</strong>来识别他们的<strong class="lh ja">位置</strong>，而不是附有推文的位置，因为只有不到 1%的人会附上他们的推文位置。然而，根据用户简档中的位置，它们可能包括一个或多个县、城市、州、国家或星球。因此，将这些数据过滤成美国州级位置是地理分段识别的核心。</p><p id="3d99" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">将所有<strong class="lh ja">状态名</strong>及其<strong class="lh ja">缩写</strong>设置为常量，用于进一步的缩写-名称转换。</p><pre class="kp kq kr ks gt nz ny oa ob aw oc bi"><span id="5f53" class="my mz iq ny b gy od oe l of og">STATES = ['Alabama', 'AL', 'Alaska', 'AK',                    \ <br/>    ...... # Text hided for readability                       \<br/>    'WV', 'Wisconsin', 'WI', 'Wyoming', 'WY']</span><span id="5e6c" class="my mz iq ny b gy oj oe l of og">STATE_DICT = dict(itertools.zip_longest(*[iter(STATES)] * 2, fillvalue=""))<br/>INV_STATE_DICT = dict((v,k) <strong class="ny ja">for</strong> k,v <strong class="ny ja">in</strong> STATE_DICT.items())</span></pre><p id="a37c" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">通过<strong class="lh ja">迭代</strong>州名列表和用户位置列表，从他们的位置提取州信息。</p><pre class="kp kq kr ks gt nz ny oa ob aw oc bi"><span id="5746" class="my mz iq ny b gy od oe l of og">is_in_US=[]<br/>geo = df[['user_location']]<br/>df = df.fillna(" ")<br/><strong class="ny ja">for</strong> x <strong class="ny ja">in</strong> df['user_location']:<br/>    check = <strong class="ny ja">False</strong><br/>    <strong class="ny ja">for</strong> s <strong class="ny ja">in</strong> STATES:<br/>        <strong class="ny ja">if</strong> s <strong class="ny ja">in</strong> x:<br/>            is_in_US.append(STATE_DICT[s] <strong class="ny ja">if</strong> s <strong class="ny ja">in</strong> STATE_DICT <strong class="ny ja">else</strong> s)<br/>            check = <strong class="ny ja">True</strong><br/>            <strong class="ny ja">break</strong><br/>    <strong class="ny ja">if</strong> <strong class="ny ja">not</strong> check:<br/>        is_in_US.append(<strong class="ny ja">None</strong>)<br/><br/>geo_dist = pd.DataFrame(is_in_US, columns['State'])           \<br/>    .dropna().reset_index()</span></pre><p id="f0d3" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">统计美国各州发布的推文数量，用<strong class="lh ja">对数</strong>数字避开<strong class="lh ja">极值</strong>(如加州 500+，北达科他州 3)更好的可视化。</p><pre class="kp kq kr ks gt nz ny oa ob aw oc bi"><span id="d773" class="my mz iq ny b gy od oe l of og">geo_dist = geo_dist.groupby('State').count().                 \ <br/>    rename(columns={"index": "Number"}).sort_values(          \<br/>    by=['Number'], ascending=<strong class="ny ja">False</strong>).reset_index()<br/>geo_dist["Log Num"] = geo_dist["Number"]                      \<br/>    .apply(<strong class="ny ja">lambda</strong> x: math.log(x, 2))</span></pre><p id="cef5" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">为稍后仪表板上的悬停文本添加说明性文本信息。</p><pre class="kp kq kr ks gt nz ny oa ob aw oc bi"><span id="e955" class="my mz iq ny b gy od oe l of og">geo_dist['Full State Name'] = geo_dist['State']               \<br/>    .apply(<strong class="ny ja">lambda</strong> x: INV_STATE_DICT[x])<br/>geo_dist['text'] = geo_dist['Full State Name'] + '&lt;br&gt;' +     \<br/>    'Num: ' + geo_dist['Number'].astype(str)</span></pre><p id="f301" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">这一次，我们使用<strong class="lh ja"> Plotly </strong>(不是 Plotly Express)来可视化美国地图。</p><p id="5a76" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated"><strong class="lh ja">注</strong> : <code class="fe nv nw nx ny b">plotly.graph_objects</code>是 Plotly 库的核心，包含更多通用函数，用于更复杂的用途。<code class="fe nv nw nx ny b">locationmode</code>是“仓位”中仓位匹配条目的集合。<code class="fe nv nw nx ny b">text</code>是悬停文本。<code class="fe nv nw nx ny b">marker_line_color</code>是状态间线条标记的颜色。设置<code class="fe nv nw nx ny b">geo_scope</code>将地图范围限制在美国。</p><pre class="kp kq kr ks gt nz ny oa ob aw oc bi"><span id="a307" class="my mz iq ny b gy od oe l of og">import <strong class="ny ja">plotly.graph_objects</strong> as go<br/>fig = go.Figure(data=go.Choropleth(<br/>    locations=geo_dist['State'], <em class="oh"># Spatial coordinates</em><br/>    z = geo_dist['Log Num'].astype(float), <em class="oh"># Data to be color-coded</em><br/><br/>    locationmode = 'USA-states', <br/>    colorscale = "Reds",<br/>    text=geo_dist['text'],<br/>    marker_line_color='white', <em class="oh"># line markers between states</em><br/>    colorbar_title = "Numbers in Log2"<br/>))<br/><br/>fig.update_layout(<br/>    geo_scope='usa', <br/>)<br/><br/>fig.show()</span></pre><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi ol"><img src="../Images/2af3ddfb23dfccef1bbff1c2c9ff097d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*GI24m7MAtPxlTRfYsnZU9Q.png"/></div></div></figure></div><div class="ab cl mr ms hu mt" role="separator"><span class="mu bw bk mv mw mx"/><span class="mu bw bk mv mw mx"/><span class="mu bw bk mv mw"/></div><div class="ij ik il im in"><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi om"><img src="../Images/6c5c7de27640af261e6cca0afff5afb0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*uQyvOhYYydoM4DlO"/></div></div><figcaption class="la lb gj gh gi lc ld bd b be z dk">Photo by <a class="ae le" href="https://unsplash.com/@karsten_wuerth?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Karsten Würth (@karsten.wuerth)</a> on <a class="ae le" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><h2 id="8d71" class="my mz iq bd na nb nc dn nd ne nf dp ng lo nh ni nj ls nk nl nm lw nn no np iw bi translated">带有<a class="ae le" href="https://plot.ly/python/" rel="noopener ugc nofollow" target="_blank"> Plotly </a>的交互式分析仪表板</h2><p id="b62b" class="pw-post-body-paragraph lf lg iq lh b li nq ka lk ll nr kd ln lo ns lq lr ls nt lu lv lw nu ly lz ma ij bi translated">现在我们可以使用<code class="fe nv nw nx ny b">Plotly.subplots</code>将所有数据可视化部分集成到一个<strong class="lh ja">仪表板</strong>中。同时显示多个图形可以大大提高阅读效率，增强多个见解之间的可比性。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi on"><img src="../Images/9496ae5652530b37b788930157afef29.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*191tvdmt7u3-Xn-I5E6Rdg.png"/></div></div></figure><p id="5ec9" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">首先创建一个包含 2 个<strong class="lh ja"> × </strong> 2 个<strong class="lh ja">支线剧情</strong>的<strong class="lh ja">剧情图</strong>，左边是<strong class="lh ja">线图</strong>，右上角是<strong class="lh ja">贴图</strong>，右下角是<strong class="lh ja">条形图</strong>。</p><pre class="kp kq kr ks gt nz ny oa ob aw oc bi"><span id="57f0" class="my mz iq ny b gy od oe l of og">from <strong class="ny ja">plotly.subplots</strong> import make_subplots<br/>fig = make_subplots(<br/>        rows=2, cols=2,<br/>        column_widths=[1, 0.4],<br/>        row_heights=[0.6, 0.4],<br/>        specs=[[{"type": "scatter", "rowspan": 2}, <br/>                {"type": "choropleth"}],<br/>               [<strong class="ny ja">None</strong>, {"type": "bar"}]]<br/>        )</span></pre><p id="bde5" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">使用<code class="fe nv nw nx ny b">add_trace</code>和<code class="fe nv nw nx ny b">go.Scatter</code>在第一个子情节中添加三行<strong class="lh ja">负片、中性片和正片</strong>。另外，<code class="fe nv nw nx ny b">row</code>和<code class="fe nv nw nx ny b">col</code>代表这个支线剧情在大图中的位置。</p><pre class="kp kq kr ks gt nz ny oa ob aw oc bi"><span id="5a50" class="my mz iq ny b gy od oe l of og">fig.add_trace(go.Scatter(<br/>    x=time_series,<br/>    y=result["Num of '<strong class="ny ja">{}</strong>' mentions"                     \<br/>        .format(settings.TRACK_WORDS[0])]               \<br/>        [result['polarity']==0].reset_index(drop=<strong class="ny ja">True</strong>), \<br/>    name="Neural",<br/>    opacity=0.8), row=1, col=1)   </span><span id="e485" class="my mz iq ny b gy oj oe l of og">fig.add_trace(go.Scatter(<br/>    x=time_series,<br/>    y=result["Num of '<strong class="ny ja">{}</strong>' mentions"                     \<br/>        .format(settings.TRACK_WORDS[0])]               \ <br/>        [result['polarity']==-1].reset_index(drop=<strong class="ny ja">True</strong>),<br/>    name="Negative",<br/>    opacity=0.8), row=1, col=1)</span><span id="c875" class="my mz iq ny b gy oj oe l of og">fig.add_trace(go.Scatter(<br/>    x=time_series,<br/>    y=result["Num of '<strong class="ny ja">{}</strong>' mentions"                     \<br/>        .format(settings.TRACK_WORDS[0])]               \<br/>        [result['polarity']==1].reset_index(drop=<strong class="ny ja">True</strong>), \<br/>    name="Positive",<br/>    opacity=0.8), row=1, col=1)</span></pre><p id="ed33" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">使用<code class="fe nv nw nx ny b">add_trace</code>和<code class="fe nv nw nx ny b">go.Bar</code>添加主题频率分布的<strong class="lh ja">条形图</strong>。您可以使用<code class="fe nv nw nx ny b">rgb(xx,xx,xx)</code>或<code class="fe nv nw nx ny b">rgba(xx,xx,xx,x)</code>改变图中某些元素的颜色。</p><pre class="kp kq kr ks gt nz ny oa ob aw oc bi"><span id="e3aa" class="my mz iq ny b gy od oe l of og">fig.add_trace(go.Bar(x=fd["Word"], y=fd["Frequency"],       \<br/>    name="Freq Dist"), row=2, col=2)<br/><br/>fig.update_traces(marker_color='rgb(59, 89, 152)',          \<br/>    marker_line_color='rgb(8,48,107)',                      \<br/>    marker_line_width=0.5, opacity=0.7, row=2, col=2)</span></pre><p id="88f3" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">然后在右上角插入<strong class="lh ja">地图</strong>，并设置位置和每个位置的编号。</p><pre class="kp kq kr ks gt nz ny oa ob aw oc bi"><span id="c2c2" class="my mz iq ny b gy od oe l of og">fig.add_trace(go.Choropleth(<br/>    locations=geo_dist['State'], <em class="oh"># Spatial coordinates</em><br/>    z = geo_dist['Log Num'].astype(float), <em class="oh"># Data to be color-coded</em><br/>    locationmode = 'USA-states', <br/>    colorscale = "Blues",<br/>    text=geo_dist['text'], <em class="oh"># hover text</em><br/>    showscale=<strong class="ny ja">False</strong>,<br/>    geo = 'geo'<br/>    ), row=1, col=2)</span></pre><p id="71d3" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">在我们的图的布局中添加<strong class="lh ja">标题</strong>，缩小我们地图的<strong class="lh ja">地理范围</strong>，将<strong class="lh ja">模板主题</strong>变为暗，使用<code class="fe nv nw nx ny b">go.layout.Annotation</code>为布局添加<a class="ae le" href="https://plot.ly/python/text-and-annotations/" rel="noopener ugc nofollow" target="_blank"> <strong class="lh ja">标注</strong> </a>。</p><pre class="kp kq kr ks gt nz ny oa ob aw oc bi"><span id="9ed6" class="my mz iq ny b gy od oe l of og">fig.update_layout(<br/>    title_text =                                            \<br/>      "Real-time tracking '<strong class="ny ja">{}</strong>' mentions on Twitter <strong class="ny ja">{} </strong>UTC"  \<br/>      .format(settings.TRACK_WORDS[0]        <br/>        ,datetime.datetime.utcnow().strftime('%m-%d %H:%M') \<br/>      ),<br/>    geo = dict(<br/>        scope='usa',<br/>    ),<br/>    template="plotly_dark",<br/>    margin=dict(r=20, t=50, b=50, l=20),<br/>    annotations=[<br/>        go.layout.Annotation(<br/>            text="Source: Twitter",<br/>            showarrow=<strong class="ny ja">False</strong>,<br/>            xref="paper",<br/>            yref="paper",<br/>            x=0,<br/>            y=0)<br/>    ],<br/>    showlegend=<strong class="ny ja">False</strong>,<br/>    xaxis_rangeslider_visible=<strong class="ny ja">True<br/></strong>)</span></pre><p id="20ff" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">最后，显示单一图形中的所有支线剧情。</p><pre class="kp kq kr ks gt nz ny oa ob aw oc bi"><span id="4de8" class="my mz iq ny b gy od oe l of og">fig.show()</span></pre></div><div class="ab cl mr ms hu mt" role="separator"><span class="mu bw bk mv mw mx"/><span class="mu bw bk mv mw mx"/><span class="mu bw bk mv mw"/></div><div class="ij ik il im in"><p id="6d7d" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated"><strong class="lh ja">作者的话</strong>:这一章有点复杂，因为它使用 NLP 和情感分析方法将数据点转化为洞察力。通过使用先进的自然语言处理方法，可以实现对主题跟踪的进一步改进。</p><p id="89b5" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">下一章将是最激动人心的部分，使用 Dash 在 Heroku 服务器上集成和部署所有功能。一如既往，我感谢您的任何反馈！😃</p><p id="1422" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated"><strong class="lh ja">9 月 20 日更新:</strong> <a class="ae le" href="http://bit.ly/2msOUbR" rel="noopener ugc nofollow" target="_blank">第三章</a>已出版！</p></div></div>    
</body>
</html>