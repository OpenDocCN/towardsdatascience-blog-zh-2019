# 使用三重损失的图像相似性

> 原文：<https://towardsdatascience.com/image-similarity-using-triplet-loss-3744c0f67973?source=collection_archive---------2----------------------->

![](img/b5d32fdf2170c9bfed8bd4878d33fd8a.png)

你训练过机器学习模型解决分类问题吗？如果是，班级数量是多少？也许 10 到 200？还是 1000？班级数量在百万量级的情况下，同样的模式是否行得通？如果答案是否定的，这篇文章是给你的。

行业中的几个真实世界的应用，从人脸识别到对象检测，从 POS 标记到 NLP 中的文档排序，都被公式化为多类分类问题。由于网络的稀疏性，当输出层中的类别数量过多时，典型的基于 softmax 的深度网络将不会有所帮助。相反，这种问题可以用不同的方式来表述。想法是以这样的方式学习数据点的分布式嵌入表示，即在高维向量空间中，上下文相似的数据点被投影在附近的区域中，而不相似的数据点被投影在彼此远离的地方。

三重损失结构通过相似性和相异性的概念帮助我们学习分布式嵌入。这是一种神经网络架构，其中多个并行网络被训练，彼此共享权重。在预测期间，输入数据通过一个网络来计算输入数据的分布式嵌入表示。

在本文中，我们将讨论如何训练三重态损失以及如何在预测过程中使用训练好的模型。

**培训数据准备:**

对于三元组丢失，目标是构建三元组<anchor positive="" negative="">，由锚图像、正图像(与锚图像相似)和负图像(与锚图像不同)组成。有不同的方法来定义相似和不相似的图像。如果您的数据集具有多个作为目标类的标注，则同一类的图像可被视为相似，而不同类的图像可被视为不相似。</anchor>

我有一个包含 6 个不同类别的地质图像数据集。为了生成三元组，首先，随机选择 2 个类。然后，从一个类中选择两个图像，从另一个类中选择一个图像。现在，相同类别的图像被认为是相似的，所以它们中的一个被用作锚，而另一个是正面的，而来自另一个类别的图像被认为是负面的图像。

同样，对于每一批，选择一组 n 个三联体。

**损失函数:**

三重态损失的成本函数如下:

**L(a，p，n) = max(0，D(a，p) — D(a，n) + margin)**

其中 **D(x，y):**x 和 y 的学习向量表示之间的距离。可以使用 L2 距离或(1 -余弦相似度)作为距离度量。该功能的目的是保持锚点和正极之间的距离小于锚点和负极之间的距离。

**模型架构:**

想法是有 3 个相同的网络具有相同的神经网络架构，它们应该共享权重。我重复一遍，所有的网络应该共享潜在的权重向量。【请参考 github 知识库，了解 tensorflow 实现中如何在网络间共享权重】。深度网络的最后一层具有 D 个神经元，用于学习 D 维向量表示。

锚、正和负图像通过它们各自的网络传递，并且在反向传播期间，使用共享架构更新权重向量。在预测期间，任何一个网络都用于计算输入数据的矢量表示。

![](img/8a603df08d4ecd50570af37883cfd95b.png)

Triplet Loss architecture

下面是实现的张量板可视化。

![](img/0a0c6d9df8264560c97ee086f2388f7d.png)

tensorboard visualization of the computation graph

**模型学习:**

该模型不仅学会了同时为不同的类制定聚类，而且还成功地将相似的图像投影到它们的邻域中。在分类架构的情况下，该模型试图学习一对类之间的决策边界，但是该模型不考虑类内相似和不相似图像之间的完整性。

为了了解训练模型的学习有多好，我随机选择了 20%的图像，并在对高维向量空间表示进行降维后，在 2D 空间中绘制这些图像。

![](img/eb3f6a58a7a851b4b380b79b6f78169c.png)

Plot of data points in 2D space

**成绩:**

以下是模型执行情况的快照。我已经从测试图像的语料库中随机选择了 20 个查询图像。并且对于每个查询图像，绘制出在高维向量空间表示上在余弦相似性方面相似的前 10 个最可能图像。

![](img/06bb15b60e6f96e52439f9c287dd8120.png)

**结论:**

三重损耗架构帮助我们解决了几个类数量非常多的问题。假设你想建立一个人脸识别系统，你有一个 100 万张人脸的数据库，预先计算每张人脸的三维向量。现在，给定一张人脸图像(作为测试图像),使用所有一百万个预先计算的向量计算余弦相似度，无论哪张图像具有最高的相似度，都将是被选中的候选图像。如果测试图像只是噪声，则最高相似度将非常低，并且将低于阈值参数。

计算语料库中每个图像的余弦相似度在计算上是非常低效的。同时，它可能需要大量的物理内存来存储语料库图像的矢量表示。

faiss 是 facebook-research 开发的一个开源框架，它帮助建立了一个基于可用内存的语料库索引，并提供了几种方法来相对更快地找到相似的图像。

**Git 存储库:**

克隆 git 库:[https://github.com/sanku-lib/triplet_loss.git](https://github.com/sanku-lib/triplet_loss.git)

**延伸阅读:**

[用 PyTorch 中的暹罗网络实现基于内容的图像检索](https://neptune.ai/blog/content-based-image-retrieval-with-siamese-networks)

**参考文献:**

[1][https://www.cs.cmu.edu/~rsalakhu/papers/oneshot1.pdf](https://www.cs.cmu.edu/~rsalakhu/papers/oneshot1.pdf)

[https://arxiv.org/pdf/1503.03832.pdf](https://arxiv.org/pdf/1503.03832.pdf)

[3][https://arxiv.org/pdf/1702.08734.pdf](https://arxiv.org/pdf/1702.08734.pdf)