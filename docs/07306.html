<html>
<head>
<title>Build Your First Computer Vision Project — Dog Breed Classification</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">建立你的第一个计算机视觉项目——狗的品种分类</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/build-your-first-computer-vision-project-dog-breed-classification-a622d8fc691e?source=collection_archive---------10-----------------------#2019-10-14">https://towardsdatascience.com/build-your-first-computer-vision-project-dog-breed-classification-a622d8fc691e?source=collection_archive---------10-----------------------#2019-10-14</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="afd2" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">在不到 30 分钟的时间内开始构建您的第一个计算机视觉项目。</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/3ac2962178f1c2dcd1a6cd95522732b8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*ey6drJha0Jol63fM"/></div></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk">Photo by <a class="ae ky" href="https://unsplash.com/@joeyc?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Joe Caione</a> on <a class="ae ky" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><p id="791a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">对我们人类来说，区分不同品种的狗是很容易的。如果你说的是 10-20 种受欢迎的狗品种。当我们谈论 100 多种狗时，情况就完全不同了。对于一个人来说，要正确并一致地对大量品种进行分类，我们需要一种不同于单纯记忆的方法。我们需要开始提取与不同品种相对应的“特征”，如皮毛颜色、耳朵形状、面部形状、尾巴长度等。即使这样，我们也需要记住什么品种有什么特征，这不是一件容易或有趣的任务。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi lv"><img src="../Images/c34c80c1eb772586a10f7bac26b30e21.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*XoKKtUOntQ5aG_UL.jpeg"/></div></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk"><a class="ae ky" href="https://medium.com/nanonets/how-to-easily-build-a-dog-breed-image-classification-model-2fd214419cde" rel="noopener">Image credit</a>: It is hard to classify a large number of dog breeds</figcaption></figure><p id="0626" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">人类难以识别大量物种是计算机比我们更好的一个完美例子。这并不是说天网要来杀我们所有人；我认为我们现在还不应该为此担心。许多人认为，两个种族一起工作的混合方式比任何一个种族单独工作都要好，而不是用机器来代替人类。你可以在 Andrew McAfee 所著的《机器、平台、人群》一书中了解更多相关信息。</p><p id="2b2f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在这个项目中，我将带你经历建立和训练卷积神经网络(CNN)的步骤，该网络将对 133 种不同的狗进行分类。这个项目是我的数据科学家 Nanodegree 的一部分，你可以在这里找到更多关于它的信息。这个项目的代码可在我的<a class="ae ky" href="https://github.com/tuanchris/dog-project" rel="noopener ugc nofollow" target="_blank"> GitHub repo </a>上获得，如果你想跟着做，请确保你安装了所需的包。</p><h1 id="5582" class="lw lx it bd ly lz ma mb mc md me mf mg jz mh ka mi kc mj kd mk kf ml kg mm mn bi translated">你需要知道的是</h1><h2 id="6555" class="mo lx it bd ly mp mq dn mc mr ms dp mg li mt mu mi lm mv mw mk lq mx my mm mz bi translated">计算机如何理解图像</h2><p id="1b33" class="pw-post-body-paragraph kz la it lb b lc na ju le lf nb jx lh li nc lk ll lm nd lo lp lq ne ls lt lu im bi translated">由于数百万年的进化完善了我们的眼睛和大脑的视觉能力，我们非常擅长识别事物。计算机将图像“视为”一系列数字。屏幕上的一个像素由从 0 到 255 的三个数字表示。每个数字都表示为红色、绿色和蓝色的强度。一张 1024*768 的图片可以表示为一个 1024*768*3 的矩阵，相当于一系列 239，616 个数字。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nf"><img src="../Images/ca56ed988a8a9b440d30b77c3b6c6a0f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1186/format:webp/0*xTMAS4WkeyDWuZYE.png"/></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk"><a class="ae ky" href="https://introcomputing.org/image-introduction.html" rel="noopener ugc nofollow" target="_blank">Image credit</a>: Image represented as numbers</figcaption></figure><p id="e110" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">传统上，计算机很难识别或分类图像中的对象。随着计算能力和神经网络研究的最新进展，计算机现在可以在许多特定任务上具有人类级别的视觉能力。</p><h2 id="2255" class="mo lx it bd ly mp mq dn mc mr ms dp mg li mt mu mi lm mv mw mk lq mx my mm mz bi translated">什么是神经网络</h2><p id="9b64" class="pw-post-body-paragraph kz la it lb b lc na ju le lf nb jx lh li nc lk ll lm nd lo lp lq ne ls lt lu im bi translated">有许多很好的资源可以解释什么是神经网络。下面是我最喜欢的解释，借用这个<a class="ae ky" rel="noopener" target="_blank" href="/how-to-build-your-own-neural-network-from-scratch-in-python-68998a08e4f6">帖子</a>:</p><p id="b582" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">神经网络由以下组件组成</p><ul class=""><li id="4452" class="ng nh it lb b lc ld lf lg li ni lm nj lq nk lu nl nm nn no bi translated">一个<strong class="lb iu">输入层</strong>、<strong class="lb iu">T3、x</strong></li><li id="7202" class="ng nh it lb b lc nq lf nr li ns lm nt lq nu lu nl nm nn no bi translated">任意数量的<strong class="lb iu">隐藏层</strong></li><li id="ab90" class="ng nh it lb b lc nq lf nr li ns lm nt lq nu lu nl nm nn no bi translated">一个<strong class="lb iu">输出层</strong>，<strong class="lb iu">，<em class="np"> ŷ </em>，</strong></li><li id="b700" class="ng nh it lb b lc nq lf nr li ns lm nt lq nu lu nl nm nn no bi translated">一组<strong class="lb iu">权重</strong>和<strong class="lb iu">在各层之间偏向</strong>，<strong class="lb iu"> <em class="np"> W 和 b </em> </strong></li><li id="1cdb" class="ng nh it lb b lc nq lf nr li ns lm nt lq nu lu nl nm nn no bi translated">一个选择<strong class="lb iu">激活功能</strong>用于每个隐藏层，<strong class="lb iu"><em class="np"/></strong>。在本教程中，我们将使用一个 Sigmoid 激活函数。</li></ul><p id="d816" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">下图显示了 2 层神经网络的架构(<em class="np">注意，在计算神经网络的层数时，输入层通常被排除在外</em></p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nv"><img src="../Images/a9ce9dbf2c11bf124f73e183fd174422.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/0*FwwadItNgdV6JocO.png"/></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk"><a class="ae ky" rel="noopener" target="_blank" href="/how-to-build-your-own-neural-network-from-scratch-in-python-68998a08e4f6">Image credit</a>: A simplified neural network architecture</figcaption></figure><p id="c761" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">详细解释神经网络如何工作超出了这篇文章的范围。你可以在 Medium 上找到许多解释神经网络如何工作的优秀文章。对于我们的狗分类项目，我们的输入层将是用数字表示的狗图像。隐藏层将是许多具有权重和偏差的层，这些权重和偏差将在我们训练模型时更新。输出将是我们 133 个犬种的一系列概率。</p><p id="f904" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">虽然对于各种机器学习问题有不同的神经网络架构，但是卷积神经网络(CNN)是用于图像分类问题的最流行的一种。</p><h2 id="4832" class="mo lx it bd ly mp mq dn mc mr ms dp mg li mt mu mi lm mv mw mk lq mx my mm mz bi translated">什么是卷积神经网络</h2><p id="e73f" class="pw-post-body-paragraph kz la it lb b lc na ju le lf nb jx lh li nc lk ll lm nd lo lp lq ne ls lt lu im bi translated">CNN 是通常用于图像分类问题的神经网络的架构。典型的架构包括一个输入层、几个卷积层、一个池层、一个全连接层(FC)和一个输出层。你可以在这里和<a class="ae ky" href="https://hackernoon.com/visualizing-parts-of-convolutional-neural-networks-using-keras-and-cats-5cc01b214e59" rel="noopener ugc nofollow" target="_blank">这里</a>阅读 CNN <a class="ae ky" href="https://medium.com/@RaghavPrabhu/understanding-of-convolutional-neural-network-cnn-deep-learning-99760835f148" rel="noopener">更全面的解释。</a></p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nw"><img src="../Images/3c49fb9e13ca12d4c33b917b015c5ae3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*id9uUraaY0eCVvF3.jpeg"/></div></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk"><a class="ae ky" href="https://medium.com/@RaghavPrabhu/understanding-of-convolutional-neural-network-cnn-deep-learning-99760835f148" rel="noopener">Image credit</a>: Architecture of a CNN</figcaption></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nx"><img src="../Images/fa968481698fd61d1464e44222b136d9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1052/0*a9s1naxU6dsM3TAq.gif"/></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk"><a class="ae ky" href="https://hackernoon.com/visualizing-parts-of-convolutional-neural-networks-using-keras-and-cats-5cc01b214e59" rel="noopener ugc nofollow" target="_blank">Image credit:</a> Visualization of a convolutional layer</figcaption></figure><h2 id="ce78" class="mo lx it bd ly mp mq dn mc mr ms dp mg li mt mu mi lm mv mw mk lq mx my mm mz bi translated">什么是迁移学习</h2><blockquote class="ny nz oa"><p id="4307" class="kz la np lb b lc ld ju le lf lg jx lh ob lj lk ll oc ln lo lp od lr ls lt lu im bi translated"><strong class="lb iu">迁移学习</strong>利用解决一个问题时获得的知识，并将其应用于另一个不同但相关的问题。</p></blockquote><p id="4f00" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">现代卷积网络是在 ImageNet 这样的大型数据集上训练的，需要数周才能完成。所以很多时候，你并不想自己去训练一个全新的 ConvNet。</p><p id="ea4a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">有很多著名的预训练模型，比如 VGG-16，雷斯网-50，Inception，Xception 等。这些模型已经在大型数据集上进行了训练，您可以利用特征提取步骤，并将它们作为特征提取器应用于您的特定问题。你可以在这里阅读更多关于迁移学习<a class="ae ky" rel="noopener" target="_blank" href="/a-comprehensive-hands-on-guide-to-transfer-learning-with-real-world-applications-in-deep-learning-212bf3b2f27a">的内容。</a></p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oe"><img src="../Images/f830be0afa2dbede4cd218daabf83d4b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*U4lmA3nb3litRBgC.png"/></div></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk"><a class="ae ky" rel="noopener" target="_blank" href="/a-comprehensive-hands-on-guide-to-transfer-learning-with-real-world-applications-in-deep-learning-212bf3b2f27a">Image credit</a>: Visualization of transfer learning architecture</figcaption></figure><h1 id="d475" class="lw lx it bd ly lz ma mb mc md me mf mg jz mh ka mi kc mj kd mk kf ml kg mm mn bi translated">准备数据</h1><h2 id="3607" class="mo lx it bd ly mp mq dn mc mr ms dp mg li mt mu mi lm mv mw mk lq mx my mm mz bi translated">获取数据</h2><p id="73c7" class="pw-post-body-paragraph kz la it lb b lc na ju le lf nb jx lh li nc lk ll lm nd lo lp lq ne ls lt lu im bi translated">你可以在这里下载数据集<a class="ae ky" href="https://s3-us-west-1.amazonaws.com/udacity-aind/dog-project/dogImages.zip" rel="noopener ugc nofollow" target="_blank">。该数据集包含 8，351 张狗图像，133 个狗品种，分为 6，680 张用于训练的图像，836 张用于测试的图像，以及 835 张用于验证的图像。</a></p><p id="6f78" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">注意，如果你有一个 NVIDIA GPU，你应该遵循这个教程。关于 CPU 的培训需要很多时间。或者，你可以在这里免费使用谷歌实验室<a class="ae ky" href="https://colab.research.google.com/" rel="noopener ugc nofollow" target="_blank"/>。</p><p id="af26" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">可以按如下方式加载标签和文件路径的键值对字典:</p><pre class="kj kk kl km gt of og oh oi aw oj bi"><span id="9bb8" class="mo lx it og b gy ok ol l om on"><strong class="og iu">from</strong> <strong class="og iu">sklearn.datasets</strong> <strong class="og iu">import</strong> load_files       <br/><strong class="og iu">from</strong> <strong class="og iu">keras.utils</strong> <strong class="og iu">import</strong> np_utils<br/><strong class="og iu">import</strong> <strong class="og iu">numpy</strong> <strong class="og iu">as</strong> <strong class="og iu">np</strong><br/><strong class="og iu">from</strong> <strong class="og iu">glob</strong> <strong class="og iu">import</strong> glob</span><span id="35ad" class="mo lx it og b gy oo ol l om on"><em class="np"># define function to load train, test, and validation datasets</em><br/><strong class="og iu">def</strong> load_dataset(path):<br/>    data = load_files(path)<br/>    dog_files = np.array(data['filenames'])<br/>    dog_targets = np_utils.to_categorical(np.array(data['target']), 133)<br/>    <strong class="og iu">return</strong> dog_files, dog_targets</span><span id="4231" class="mo lx it og b gy oo ol l om on"><em class="np"># load train, test, and validation datasets</em><br/>train_files, train_targets = load_dataset('dogImages/train')<br/>valid_files, valid_targets = load_dataset('dogImages/valid')<br/>test_files, test_targets = load_dataset('dogImages/test')</span></pre><p id="d178" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">不同的图像可能有不同的大小。以下代码将输入调整为 224*224 像素的图像，并将其作为 numpy 系列加载到内存中:</p><pre class="kj kk kl km gt of og oh oi aw oj bi"><span id="8c60" class="mo lx it og b gy ok ol l om on"><strong class="og iu">from</strong> <strong class="og iu">keras.preprocessing</strong> <strong class="og iu">import</strong> image                  <br/><strong class="og iu">from</strong> <strong class="og iu">tqdm</strong> <strong class="og iu">import</strong> tqdm</span><span id="08c0" class="mo lx it og b gy oo ol l om on"><strong class="og iu">def</strong> path_to_tensor(img_path):<br/>    <em class="np"># loads RGB image as PIL.Image.Image type</em><br/>    img = image.load_img(img_path, target_size=(224, 224))<br/>    <em class="np"># convert PIL.Image.Image type to 3D tensor with shape (224, 224, 3)</em><br/>    x = image.img_to_array(img)<br/>    <em class="np"># convert 3D tensor to 4D tensor with shape (1, 224, 224, 3) and return 4D tensor</em><br/>    <strong class="og iu">return</strong> np.expand_dims(x, axis=0)</span><span id="11de" class="mo lx it og b gy oo ol l om on"><strong class="og iu">def</strong> paths_to_tensor(img_paths):<br/>    list_of_tensors = [path_to_tensor(img_path) <strong class="og iu">for</strong> img_path <strong class="og iu">in</strong> tqdm(img_paths)]<br/>    <strong class="og iu">return</strong> np.vstack(list_of_tensors)</span></pre><h2 id="c2e7" class="mo lx it bd ly mp mq dn mc mr ms dp mg li mt mu mi lm mv mw mk lq mx my mm mz bi translated">预处理数据</h2><p id="f92e" class="pw-post-body-paragraph kz la it lb b lc na ju le lf nb jx lh li nc lk ll lm nd lo lp lq ne ls lt lu im bi translated">我们需要标准化我们的数据，以消除测量单位。归一化可以帮助我们的模型更好地比较不同尺度的数据。</p><pre class="kj kk kl km gt of og oh oi aw oj bi"><span id="620b" class="mo lx it og b gy ok ol l om on"><strong class="og iu">from</strong> <strong class="og iu">PIL</strong> <strong class="og iu">import</strong> ImageFile                            <br/>ImageFile.LOAD_TRUNCATED_IMAGES = <strong class="og iu">True</strong></span><span id="ddcf" class="mo lx it og b gy oo ol l om on"><em class="np"># pre-process the data for Keras</em><br/>train_tensors = paths_to_tensor(train_files).astype('float32')/255<br/>valid_tensors = paths_to_tensor(valid_files).astype('float32')/255<br/>test_tensors = paths_to_tensor(test_files).astype('float32')/255</span></pre><h2 id="026a" class="mo lx it bd ly mp mq dn mc mr ms dp mg li mt mu mi lm mv mw mk lq mx my mm mz bi translated">培训用数据</h2><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi op"><img src="../Images/fb52a6f7e1a8e17d56cc82e1251def16.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*2os9TNTONAqvHTkd1OyW9g.png"/></div></div></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi oq"><img src="../Images/7b8d0486d48019600689f6f0060bd182.png" data-original-src="https://miro.medium.com/v2/resize:fit:1336/format:webp/1*HUGzcpIItmAxFVZEtONE7A.png"/></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk">It’s challenging even for humans to identify a dog breed</figcaption></figure><p id="0b26" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">让我们来看看我们的一些数据。我们的例子表明，准确识别狗的品种是具有挑战性的，即使对人类来说也是如此。还有许多其他现实世界的因素会影响我们的模型:</p><ul class=""><li id="fdfb" class="ng nh it lb b lc ld lf lg li ni lm nj lq nk lu nl nm nn no bi translated"><strong class="lb iu">灯光条件:</strong>不同的灯光改变颜色的显示方式</li><li id="8e01" class="ng nh it lb b lc nq lf nr li ns lm nt lq nu lu nl nm nn no bi translated">目标定位:我们的狗可以帮助很多不同的姿势</li><li id="0013" class="ng nh it lb b lc nq lf nr li ns lm nt lq nu lu nl nm nn no bi translated">相框:特写人像相框和全身照片非常不同</li><li id="7508" class="ng nh it lb b lc nq lf nr li ns lm nt lq nu lu nl nm nn no bi translated"><strong class="lb iu">缺失特征:</strong>照片中并没有显示狗狗的所有特征</li></ul><p id="3b1c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">因此，传统方法不可能在计算机视觉任务中取得进展。让我们看看 CNN 和转移学习能做些什么。</p><h1 id="66df" class="lw lx it bd ly lz ma mb mc md me mf mg jz mh ka mi kc mj kd mk kf ml kg mm mn bi translated">创建一个你自己的模型</h1><h2 id="f096" class="mo lx it bd ly mp mq dn mc mr ms dp mg li mt mu mi lm mv mw mk lq mx my mm mz bi translated">模型架构</h2><p id="bd28" class="pw-post-body-paragraph kz la it lb b lc na ju le lf nb jx lh li nc lk ll lm nd lo lp lq ne ls lt lu im bi translated">用 Keras 创建 CNN 很简单。您可以用下面的代码定义您的模型架构。</p><pre class="kj kk kl km gt of og oh oi aw oj bi"><span id="00b5" class="mo lx it og b gy ok ol l om on"><strong class="og iu">from</strong> <strong class="og iu">keras.layers</strong> <strong class="og iu">import</strong> Conv2D, MaxPooling2D, GlobalAveragePooling2D<br/><strong class="og iu">from</strong> <strong class="og iu">keras.layers</strong> <strong class="og iu">import</strong> Dropout, Flatten, Dense<br/><strong class="og iu">from</strong> <strong class="og iu">keras.models</strong> <strong class="og iu">import</strong> Sequential</span><span id="0ee6" class="mo lx it og b gy oo ol l om on">model = Sequential()<br/>model.add(Conv2D(filters=16, kernel_size=2, padding='same',activation='relu',input_shape=(224,224,3)))<br/>model.add(MaxPooling2D())<br/>model.add(Conv2D(filters=32, kernel_size=2, padding='same',activation='relu'))<br/>model.add(MaxPooling2D())<br/>model.add(Conv2D(filters=64, kernel_size=2, padding='same',activation='relu'))<br/>model.add(MaxPooling2D())<br/>model.add(GlobalAveragePooling2D())<br/>model.add(Dense(133,activation='softmax'))</span><span id="11db" class="mo lx it og b gy oo ol l om on">model.summary()</span></pre><p id="a8f4" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们的原始模型架构有一个形状为 224*224*3 的输入层。然后，输入馈入两个卷积层，接着是最大池层(用于下采样)。然后，输出被馈送到全局平均池层，以通过减少参数的数量来最小化过拟合。输出层为我们的品种返回 133 个概率。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi or"><img src="../Images/15ae19867becfd85cf19d4e3c3950e4d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*lfb-JIF6d8s1Gj8U.gif"/></div></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk"><a class="ae ky" href="https://hackernoon.com/visualizing-parts-of-convolutional-neural-networks-using-keras-and-cats-5cc01b214e59" rel="noopener ugc nofollow" target="_blank">Image credit</a>: Visualization of pooling layers such as MaxPooling and AveragePooling</figcaption></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi os"><img src="../Images/9ba598298444a049bc94986006957881.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*NM9eYbJFI04rJfoGMvh3tA.png"/></div></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk">Our primitive model summary</figcaption></figure><h2 id="7306" class="mo lx it bd ly mp mq dn mc mr ms dp mg li mt mu mi lm mv mw mk lq mx my mm mz bi translated">韵律学</h2><p id="a3a1" class="pw-post-body-paragraph kz la it lb b lc na ju le lf nb jx lh li nc lk ll lm nd lo lp lq ne ls lt lu im bi translated">在这个项目中，我们的目标是正确预测狗的品种。因此，在每次迭代之后，我们使用准确性作为选择的度量来改进我们的模型。准确性就是我们的模型正确预测犬种的次数。</p><h2 id="21a3" class="mo lx it bd ly mp mq dn mc mr ms dp mg li mt mu mi lm mv mw mk lq mx my mm mz bi translated">编译和训练模型</h2><p id="6eea" class="pw-post-body-paragraph kz la it lb b lc na ju le lf nb jx lh li nc lk ll lm nd lo lp lq ne ls lt lu im bi translated">然后需要编译我们的模型。我们使用<em class="np"> rmsprop </em>作为我们的优化器，<em class="np">category _ cross entropy，</em>作为我们的损失函数，准确性作为我们的度量。</p><pre class="kj kk kl km gt of og oh oi aw oj bi"><span id="ae58" class="mo lx it og b gy ok ol l om on">model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])</span></pre><p id="0dbd" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">然后，我们可以使用以下代码训练模型:</p><pre class="kj kk kl km gt of og oh oi aw oj bi"><span id="316a" class="mo lx it og b gy ok ol l om on"><strong class="og iu">from</strong> <strong class="og iu">keras.callbacks</strong> <strong class="og iu">import</strong> ModelCheckpoint</span><span id="c79a" class="mo lx it og b gy oo ol l om on">epochs = 5</span><span id="bdea" class="mo lx it og b gy oo ol l om on">checkpointer = ModelCheckpoint(filepath='saved_models/weights.best.from_scratch.hdf5', <br/>                               verbose=1, save_best_only=<strong class="og iu">True</strong>)</span><span id="1472" class="mo lx it og b gy oo ol l om on">model.fit(train_tensors, train_targets, <br/>          validation_data=(valid_tensors, valid_targets),<br/>          epochs=epochs, batch_size=20, callbacks=[checkpointer], verbose=1)</span></pre><p id="1f55" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">用<strong class="lb iu">五个纪元</strong>和大约<strong class="lb iu">八分钟</strong>，我们取得了<strong class="lb iu"> 3.2297% </strong>的准确率，比随机猜测(1/133 = 0.75%)要好。</p><p id="2c65" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">虽然我们的模型比随机猜测的表现好得多，但 3.2297%的模型在现实中没有用。训练和调整我们的模型以达到有意义的准确性需要大量的时间、大量的数据集和大量的计算资源。幸运的是，我们可以使用迁移学习来减少训练时间，而不牺牲准确性。</p><h1 id="ae4f" class="lw lx it bd ly lz ma mb mc md me mf mg jz mh ka mi kc mj kd mk kf ml kg mm mn bi translated">使用迁移学习创建模型</h1><h2 id="9835" class="mo lx it bd ly mp mq dn mc mr ms dp mg li mt mu mi lm mv mw mk lq mx my mm mz bi translated">获取瓶颈特征</h2><p id="a70b" class="pw-post-body-paragraph kz la it lb b lc na ju le lf nb jx lh li nc lk ll lm nd lo lp lq ne ls lt lu im bi translated">Keras 提供了以下经过预先培训的最新架构，您可以在几分钟内使用它们:VGG-19、ResNet-50、Inception 和 Xception。在这个项目中，我们将使用 ResNet-50，但是您可以自己尝试其他体系结构。下面的代码下载预先训练好的模型并加载<a class="ae ky" href="https://www.quora.com/What-is-the-definition-of-bottleneck-features-in-transfer-learning" rel="noopener ugc nofollow" target="_blank">瓶颈特性</a>。</p><pre class="kj kk kl km gt of og oh oi aw oj bi"><span id="ffed" class="mo lx it og b gy ok ol l om on"><strong class="og iu">import</strong> <strong class="og iu">requests</strong><br/>url = 'https://s3-us-west-1.amazonaws.com/udacity-aind/dog-project/DogResnet50Data.npz'<br/>r = requests.get(url)</span><span id="fde2" class="mo lx it og b gy oo ol l om on"><strong class="og iu">with</strong> open('bottleneck_features/DogResnet50Data.npz', 'wb') <strong class="og iu">as</strong> f:<br/>    f.write(r.content)</span><span id="f10e" class="mo lx it og b gy oo ol l om on">bottleneck_features = np.load('bottleneck_features/DogResnet50Data.npz')<br/>train_Resnet50 = bottleneck_features['train']<br/>valid_Resnet50 = bottleneck_features['valid']<br/>test_Resnet50 = bottleneck_features['test']</span></pre><h2 id="1785" class="mo lx it bd ly mp mq dn mc mr ms dp mg li mt mu mi lm mv mw mk lq mx my mm mz bi translated">模型架构</h2><p id="9246" class="pw-post-body-paragraph kz la it lb b lc na ju le lf nb jx lh li nc lk ll lm nd lo lp lq ne ls lt lu im bi translated">借助预训练的 ResNet-50 模型，我们使用以下代码创建全连接(FC)层。我们还增加了两个下降层，以防止过度拟合。</p><pre class="kj kk kl km gt of og oh oi aw oj bi"><span id="8bf8" class="mo lx it og b gy ok ol l om on">Resnet50_model = Sequential()<br/>Resnet50_model.add(GlobalAveragePooling2D(input_shape=train_Resnet50.shape[1:]))<br/>Resnet50_model.add(Dropout(0.3))<br/>Resnet50_model.add(Dense(1024,activation='relu'))<br/>Resnet50_model.add(Dropout(0.4))<br/>Resnet50_model.add(Dense(133, activation='softmax'))<br/>Resnet50_model.summary()</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ot"><img src="../Images/ea4258b716478e8fdc7d3e9026f2d3b7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*DVITJ3mJ_76lJNVDcZfztg.png"/></div></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk">Our model architecture using transfer learning looks like this</figcaption></figure><h2 id="f913" class="mo lx it bd ly mp mq dn mc mr ms dp mg li mt mu mi lm mv mw mk lq mx my mm mz bi translated">模型性能</h2><p id="c697" class="pw-post-body-paragraph kz la it lb b lc na ju le lf nb jx lh li nc lk ll lm nd lo lp lq ne ls lt lu im bi translated">使用迁移学习(ResNet-50)，在<strong class="lb iu">二十个历元</strong>和<strong class="lb iu">不到两分钟</strong>的情况下，我们取得了<strong class="lb iu"> 80.8612% </strong>的测试准确率。这是对我们原始模型的巨大改进。</p><p id="f09f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">使用上面描述的模型，我创建了一个小的命令行应用程序。如果你输入一只狗的照片，这个应用程序会预测它的品种。如果你输入一个人的图像，比如你的一个朋友说，这个应用程序会预测最接近的匹配犬种。如果没有狗或人出现，应用程序将输出一个错误。你可以按照我的 GitHub repo 上的<a class="ae ky" href="https://github.com/tuanchris/dog-project" rel="noopener ugc nofollow" target="_blank"> README.md </a>文件中的说明进行操作。</p><h1 id="1556" class="lw lx it bd ly lz ma mb mc md me mf mg jz mh ka mi kc mj kd mk kf ml kg mm mn bi translated">结论</h1><p id="19fc" class="pw-post-body-paragraph kz la it lb b lc na ju le lf nb jx lh li nc lk ll lm nd lo lp lq ne ls lt lu im bi translated">在这个项目中，我将带你了解一些构建你的第一个计算机视觉项目所需的核心概念。我解释了<strong class="lb iu">计算机如何理解图像</strong>，简要回顾了什么是<strong class="lb iu">神经网络</strong>、<strong class="lb iu">卷积神经网络</strong>、<strong class="lb iu">、</strong>和<strong class="lb iu">迁移学习</strong>。</p><p id="ba3f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们还从零开始构建并训练了一个<strong class="lb iu"> CNN 架构</strong>以及应用<strong class="lb iu">迁移学习</strong>来大幅提高我们模型的准确率<strong class="lb iu">从 3.2%到 81%。</strong>在做这个项目时，我对你如何利用迁移学习来提高准确性，同时显著减少培训时间印象深刻。以下是我们模型的一些预测:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ou"><img src="../Images/bbbb6b02e472fcade5f1107ea07d7be8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*noOBOkzMlBuOhhfxow0keA.png"/></div></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk">Some predictions of our model</figcaption></figure><h1 id="ba94" class="lw lx it bd ly lz ma mb mc md me mf mg jz mh ka mi kc mj kd mk kf ml kg mm mn bi translated">未来的改进</h1><p id="8c35" class="pw-post-body-paragraph kz la it lb b lc na ju le lf nb jx lh li nc lk ll lm nd lo lp lq ne ls lt lu im bi translated">如果我有更多的时间，这里是这个项目的几个未来发展:</p><ul class=""><li id="1e73" class="ng nh it lb b lc ld lf lg li ni lm nj lq nk lu nl nm nn no bi translated"><strong class="lb iu">扩充数据:</strong>当前的实现只接受标准图像作为输入。因此，该模型在现实环境中可能不够健壮。我可以增加训练数据，使我们的模型不容易过度拟合。我可以通过随机裁剪、翻转、旋转训练数据来创建更多的训练样本。</li><li id="f20d" class="ng nh it lb b lc nq lf nr li ns lm nt lq nu lu nl nm nn no bi translated"><strong class="lb iu">调优模型:</strong>我还可以调优模型超参数，以达到更好的精度。一些用于调优的潜在超参数包括优化器、损失函数、激活函数、模型架构等。我也可以用 Keras 使用 Sklearn 的 GridSearch。</li><li id="0c5c" class="ng nh it lb b lc nq lf nr li ns lm nt lq nu lu nl nm nn no bi translated"><strong class="lb iu">尝试其他模型:</strong>在这个项目中，我尝试在 VGG-16 和 ResNet-50 上训练模型。下一步可能是尝试使用不同的架构来训练模型，以及改变我们完全连接的层的架构。</li><li id="b0d6" class="ng nh it lb b lc nq lf nr li ns lm nt lq nu lu nl nm nn no bi translated">创建一个 web/移动应用程序:我也可以用这个模型创建一个 web 应用程序或移动应用程序来取乐。</li></ul><p id="025b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">感谢你的阅读，希望你能学到东西:)</strong></p></div></div>    
</body>
</html>