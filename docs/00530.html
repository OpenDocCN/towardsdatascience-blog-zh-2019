<html>
<head>
<title>How to Beat Google’s AutoML - Hyperparameter Optimisation with Flair</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">如何用天赋打败谷歌的自动超参数优化</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/how-to-beat-automl-hyperparameter-optimisation-with-flair-3b2f5092d9f5?source=collection_archive---------11-----------------------#2019-01-24">https://towardsdatascience.com/how-to-beat-automl-hyperparameter-optimisation-with-flair-3b2f5092d9f5?source=collection_archive---------11-----------------------#2019-01-24</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="a837" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">使用 Flair 进行文本分类的超参数优化</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/acb33386efd4b125dbbf663bea685705.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*hheGKxwarcLPXlaTocIYQQ.png"/></div></div></figure><p id="400d" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">这是我们之前关于<a class="ae ln" rel="noopener" target="_blank" href="/text-classification-with-state-of-the-art-nlp-library-flair-b541d7add21f">最先进的文本分类</a>的帖子的后续。我们解释了如何使用 Flair Python NLP 库进行超参数优化，以在文本分类中获得优于 Google AutoML 自然语言的最佳结果。</p><h1 id="b723" class="lo lp iq bd lq lr ls lt lu lv lw lx ly jw lz jx ma jz mb ka mc kc md kd me mf bi translated">什么是超参数优化，为什么我们不能简单地手动完成？</h1><p id="7ef7" class="pw-post-body-paragraph kr ks iq kt b ku mg jr kw kx mh ju kz la mi lc ld le mj lg lh li mk lk ll lm ij bi translated">超参数优化(或调整)是为机器学习算法选择一组最佳参数的过程。数据预处理器、优化器和 ML 算法都接收一组指导其行为的参数。为了实现最佳性能，需要对它们进行调整，以适应所用数据集的统计属性、要素类型和大小。深度学习中最典型的超参数包括学习速率、深度神经网络中的隐藏层数、批量大小、退出率…</p><p id="c5d0" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">在自然语言处理中，我们还会遇到许多其他与预处理和文本嵌入相关的超参数，如嵌入类型、嵌入维数、RNN 层数等</p><p id="9185" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">通常，如果我们足够幸运，问题足够简单，只需要一个或两个具有一些离散值的超参数(例如 k-means 中的 k)，我们可以简单地尝试所有可能的选项。但是随着参数数量的增加，试错法变得困难。</p><blockquote class="ml"><p id="061f" class="mm mn iq bd mo mp mq mr ms mt mu lm dk translated">我们的搜索空间随着调整的参数数量呈指数增长。</p></blockquote><p id="0dd0" class="pw-post-body-paragraph kr ks iq kt b ku mv jr kw kx mw ju kz la mx lc ld le my lg lh li mz lk ll lm ij bi translated">假设离散选项，这意味着如果我们有 8 个参数，其中每个参数有 10 个离散选项，我们最终得到超参数的 10⁸可能组合。假设训练一个模型通常需要相当多的时间和资源，这使得手工挑选参数不可行。</p><p id="4505" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">有许多超参数优化技术，如网格搜索、随机搜索、贝叶斯优化、梯度方法以及最终的 TPE。<a class="ae ln" href="https://papers.nips.cc/paper/4443-algorithms-for-hyper-parameter-optimization.pdf" rel="noopener ugc nofollow" target="_blank">树形结构的 Parzen 估计器</a> (TPE)是我们在 Flair 的包装器 Hyperopt 中使用的方法，Hyperopt 是一个流行的 Python 超参数优化库。</p><h1 id="a48e" class="lo lp iq bd lq lr ls lt lu lv lw lx ly jw lz jx ma jz mb ka mc kc md kd me mf bi translated">使用 Flair 进行超参数调谐</h1><p id="1ae1" class="pw-post-body-paragraph kr ks iq kt b ku mg jr kw kx mh ju kz la mi lc ld le mj lg lh li mk lk ll lm ij bi translated">Flair 提供了一个简单的 API 来调整您的文本分类器参数。然而，我们需要告诉它需要调整哪些类型的超参数，以及应该为它们考虑哪些值。<br/>运行优化器并不比训练分类器本身更难，但它需要更多的时间和资源，因为它本质上要执行大量的训练。因此，建议在 GPU 加速的硬件上运行。</p><p id="5e9c" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">我们将对在 Kaggle 垃圾短信收集数据集上训练的文本分类器模型进行超参数优化，以区分垃圾短信和非垃圾短信。</p><h2 id="b9ce" class="na lp iq bd lq nb nc dn lu nd ne dp ly la nf ng ma le nh ni mc li nj nk me nl bi translated">做好准备</h2><p id="8a7d" class="pw-post-body-paragraph kr ks iq kt b ku mg jr kw kx mh ju kz la mi lc ld le mj lg lh li mk lk ll lm ij bi translated">要准备数据集，请参考<a class="ae ln" rel="noopener" target="_blank" href="/text-classification-with-state-of-the-art-nlp-library-flair-b541d7add21f">最新文本分类</a>的“预处理—构建数据集”部分，在此我们获得<code class="fe nm nn no np b">train.csv</code>、<code class="fe nm nn no np b">test.csv</code>和<code class="fe nm nn no np b">dev.csv</code>。确保数据集存储在与运行 Flair 的脚本相同的目录中。</p><p id="cb4e" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">您可以通过运行以下命令来检查您是否有可用于培训的 GPU:</p><pre class="kg kh ki kj gt nq np nr ns aw nt bi"><span id="713a" class="na lp iq np b gy nu nv l nw nx">import torch<br/>torch.cuda.is_available()</span></pre><p id="11b6" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">它返回一个 boolean 值，指示 CUDA 是否可用于 PyTorch(在它上面写有 Flair)。</p><h2 id="2912" class="na lp iq bd lq nb nc dn lu nd ne dp ly la nf ng ma le nh ni mc li nj nk me nl bi translated">调整参数</h2><p id="0fe7" class="pw-post-body-paragraph kr ks iq kt b ku mg jr kw kx mh ju kz la mi lc ld le mj lg lh li mk lk ll lm ij bi translated">超参数优化的第一步很可能包括<strong class="kt ir">定义搜索空间。</strong>这意味着定义我们想要调整的所有超参数，以及优化器应该只考虑它们的一组离散值还是在一个有界的连续空间中搜索。</p><p id="88e4" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">对于离散参数，使用:</p><pre class="kg kh ki kj gt nq np nr ns aw nt bi"><span id="c9d9" class="na lp iq np b gy nu nv l nw nx">search_space.add(Parameter.PARAMNAME, hp.choice, options=[1, 2, ..])</span></pre><p id="04b0" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">对于均匀连续的参数，使用:</p><pre class="kg kh ki kj gt nq np nr ns aw nt bi"><span id="a387" class="na lp iq np b gy nu nv l nw nx">search_space.add(Parameter.PARAMNAME, hp.uniform, low=0.0, high=0.5)</span></pre><p id="03d7" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">所有可能参数的列表可在<a class="ae ln" href="https://github.com/zalandoresearch/flair/blob/master/flair/hyperparameter/parameter.py" rel="noopener ugc nofollow" target="_blank">这里</a>看到。</p><p id="d84f" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">接下来，您需要指定一些参数，这些参数涉及我们想要使用的文本分类器的类型，以及要运行多少个<code class="fe nm nn no np b">training_runs</code>和<code class="fe nm nn no np b">epochs</code>。</p><pre class="kg kh ki kj gt nq np nr ns aw nt bi"><span id="0201" class="na lp iq np b gy nu nv l nw nx">param_selector = TextClassifierParamSelector(<br/>    corpus=corpus, <br/>    multi_label=False, <br/>    base_path='resources/results', <br/>    document_embedding_type='lstm',<br/>    max_epochs=10, <br/>    training_runs=1,<br/>    optimization_value=OptimizationValue.DEV_SCORE<br/>)</span></pre><p id="7bfc" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">注意<code class="fe nm nn no np b">DEV_SCORE</code>被设置为我们的优化值。这是非常重要的，因为我们不想基于测试集优化我们的超参数，因为这会导致过度拟合。</p><p id="c7f3" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">最后，我们运行<code class="fe nm nn no np b">param_selector.optimize(search_space, max_evals=100)</code>，它将执行优化器的 100 次评估，并将结果保存到<code class="fe nm nn no np b">resources/results/param_selection.txt</code></p><p id="9656" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">运行整个过程的完整源代码如下:</p><pre class="kg kh ki kj gt nq np nr ns aw nt bi"><span id="a7bd" class="na lp iq np b gy nu nv l nw nx">from flair.hyperparameter.param_selection import TextClassifierParamSelector, OptimizationValue<br/>from hyperopt import hp<br/>from flair.hyperparameter.param_selection import SearchSpace, Parameter<br/>from flair.embeddings import WordEmbeddings, FlairEmbeddings<br/>from flair.data_fetcher import NLPTaskDataFetcher<br/>from pathlib import Path</span><span id="8c53" class="na lp iq np b gy ny nv l nw nx">corpus = NLPTaskDataFetcher.load_classification_corpus(Path('./'), test_file='test.csv', dev_file='dev.csv', train_file='train.csv')</span><span id="b892" class="na lp iq np b gy ny nv l nw nx">word_embeddings = [[WordEmbeddings('glove'), FlairEmbeddings('news-forward'), FlairEmbeddings('news-backward')]]</span><span id="30d7" class="na lp iq np b gy ny nv l nw nx">search_space = SearchSpace()<br/>search_space.add(Parameter.EMBEDDINGS, hp.choice, options=word_embeddings)<br/>search_space.add(Parameter.HIDDEN_SIZE, hp.choice, options=[32, 64, 128, 256, 512])<br/>search_space.add(Parameter.RNN_LAYERS, hp.choice, options=[1, 2])<br/>search_space.add(Parameter.DROPOUT, hp.uniform, low=0.0, high=0.5)<br/>search_space.add(Parameter.LEARNING_RATE, hp.choice, options=[0.05, 0.1, 0.15, 0.2])<br/>search_space.add(Parameter.MINI_BATCH_SIZE, hp.choice, options=[16, 32, 64])</span><span id="bb69" class="na lp iq np b gy ny nv l nw nx">param_selector = TextClassifierParamSelector(<br/>    corpus=corpus, <br/>    multi_label=False, <br/>    base_path='resources/results', <br/>    document_embedding_type='lstm',<br/>    max_epochs=10, <br/>    training_runs=1,<br/>    optimization_value=OptimizationValue.DEV_SCORE<br/>)</span><span id="b817" class="na lp iq np b gy ny nv l nw nx">param_selector.optimize(search_space, max_evals=100)</span></pre><p id="0eeb" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">我们的搜索空间包括学习率、文档嵌入隐藏大小、文档嵌入 RNN 层数、丢失值和批量大小。注意，尽管只使用了一种类型的单词嵌入(一堆新闻向前、新闻向后和手套),我们仍然必须将它传递给搜索空间，因为它是一个必需的参数。</p><h1 id="9b03" class="lo lp iq bd lq lr ls lt lu lv lw lx ly jw lz jx ma jz mb ka mc kc md kd me mf bi translated">结果</h1><p id="c0ec" class="pw-post-body-paragraph kr ks iq kt b ku mg jr kw kx mh ju kz la mi lc ld le mj lg lh li mk lk ll lm ij bi translated">优化器在 GPU 上运行了大约 6 个小时，执行了 100 次评估。最终结果写入<code class="fe nm nn no np b">resources/results/param_selection.txt</code>。</p><p id="07b2" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">最后几行显示最佳参数组合，如下所示:</p><pre class="kg kh ki kj gt nq np nr ns aw nt bi"><span id="b5a6" class="na lp iq np b gy nu nv l nw nx">--------evaluation run 97<br/>dropout: 0.19686569599930906<br/>embeddings: ./glove.gensim, ./english-forward-v0.2rc.pt, lm-news-english-backward-v0.2rc.pt<br/>hidden_size: 256<br/>learning_rate: 0.05<br/>mini_batch_size: 32<br/>rnn_layers: 2<br/>score: 0.009033333333333374<br/>variance: 8.888888888888905e-07<br/>test_score: 0.9923<br/>...<br/>----------best parameter combination<br/>dropout: 0.19686569599930906<br/>embeddings: 0 <br/>hidden_size: 3<br/>learning_rate: 0 &lt;- *this means 0th option*<br/>mini_batch_size: 1<br/>rnn_layers: 1</span></pre><p id="c19f" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">根据进一步评估确认的调优结果的<code class="fe nm nn no np b">test_score</code>，我们获得了测试 f1 分数<strong class="kt ir"> 0.9923 (99.23%) </strong>！</p><p id="2607" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">这意味着我们以微弱优势超过了谷歌的 AutoML。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nz"><img src="../Images/83bb2e99ecebc010db54b37cc61be311.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*m4PMiXvOT18hCs-AMwkZXw.png"/></div></div><figcaption class="oa ob gj gh gi oc od bd b be z dk">Results obtained on Google AutoML Natural Language</figcaption></figure><p id="88f5" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated"><em class="oe">提示:如果</em> <code class="fe nm nn no np b"><em class="oe">precision</em></code> <em class="oe"> = </em> <code class="fe nm nn no np b"><em class="oe">recall</em></code> <em class="oe">那么</em><code class="fe nm nn no np b"><em class="oe">f-score</em></code><em class="oe">=</em><code class="fe nm nn no np b"><em class="oe">precision</em></code><em class="oe">=</em><code class="fe nm nn no np b"><em class="oe">recall</em></code></p><p id="6971" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated"><strong class="kt ir">这是否意味着我可以按照这个指南一直达到最先进的效果？</strong></p><p id="4551" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">简短回答:不。该指南应该让您很好地了解如何使用 Flair 的超参数优化器，并且不是 NLP 文本分类框架的全面比较。使用所描述的方法肯定会产生与其他最先进的框架相当的结果，但是它们会根据数据集、使用的预处理方法和定义的超参数搜索空间而变化。</p><p id="973d" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated"><strong class="kt ir">注意</strong>当选择最佳参数组合时，Flair 会考虑所获得结果的损失和变化。因此，损失最低且 f1-得分最高的车型不一定会被选为最佳车型。</p><h2 id="85c1" class="na lp iq bd lq nb nc dn lu nd ne dp ly la nf ng ma le nh ni mc li nj nk me nl bi translated">那么我现在如何使用参数来训练一个实际的模型呢？</h2><p id="67c5" class="pw-post-body-paragraph kr ks iq kt b ku mg jr kw kx mh ju kz la mi lc ld le mj lg lh li mk lk ll lm ij bi translated">要在实际模型上使用最佳性能参数，您需要从<code class="fe nm nn no np b">param_selection.txt</code>中读取最佳参数，并手动将它们一个接一个地复制到将训练我们的模型<a class="ae ln" href="https://medium.com/@tadejmagajna/text-classification-with-state-of-the-art-nlp-library-flair-b541d7add21f" rel="noopener">的代码中，就像我们在第 1 部分</a>中所做的那样。</p><p id="737b" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">虽然我们对这个库非常满意，但是如果能够以一种更加代码友好的格式提供最佳参数，或者更好的是，在优化过程中可以选择简单地导出最佳模型，那就更好了。</p></div></div>    
</body>
</html>