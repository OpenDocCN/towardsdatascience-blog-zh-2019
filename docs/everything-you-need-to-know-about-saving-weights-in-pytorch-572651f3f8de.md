# 关于在 PyTorch 减肥，你需要知道的一切

> 原文：<https://towardsdatascience.com/everything-you-need-to-know-about-saving-weights-in-pytorch-572651f3f8de?source=collection_archive---------0----------------------->

一旦我们完成了对模型的训练，我们深度学习实践者会做什么？

**我们心寒！！！**

*哈哈哈* *开个玩笑……*

我们要么保存学习到的权重，要么保存整个模型，以便我们可以进一步训练模型，或者使用训练好的模型进行推理！

接下来你们可能有兴趣知道的是，我们什么时候只保存学习过的权重，什么时候保存整个模型。

在这篇博客中，我们将试图找到这些问题的答案。

我将非常简单明了地向您解释在 PyTorch 中保存模型架构及其权重的艺术的来龙去脉。

我们还将学习如何访问不同的模块。准确地说，在任何给定的 PyTorch 模型中。

所以可以随意分叉这个 kaggle 内核并使用 [**代码**](https://www.kaggle.com/n0obcoder/things-to-know-about-saving-weights-in-pytorch) :)

我们开始吧！！！

我们从使用 PyTorch 导入编码的 [*基本必需品*](https://www.youtube.com/watch?v=5dhSdnDb3tk) 开始。

接下来，我们定义一个基于 CNN 的模型。

让我们初始化并打印*模型*，看看里面有什么。

打印出*模型*向你展示它的架构。但是我们要潜得更深，因为我们是深度学习的实践者！

我们需要确保我们理解模型里面到底有什么。

有一种方法可以访问模型的每个可学习参数及其名称。顺便说一下，[*torch . nn . parameter*](https://pytorch.org/docs/stable/nn.html#torch.nn.Parameter)是一个张量子类，当与[*torch . nn . module*](https://pytorch.org/docs/stable/nn.html#torch.nn.Module)一起使用时，它会自动添加到其参数列表中，并出现在例如 *parameters()* 或*named _ parameters()**迭代器中。另一方面添加一个 *torch.nn.Tensor* 则没有这样的效果。稍后将详细介绍这一点！*

*回到打印模型的所有参数。*

*喔喔喔！这里刚刚发生了什么？*

*让我们进入 *named_parameters()* 函数。*

*model.named_parameters()本身就是一个生成器。它返回*名称*和*参数*，它们只不过是参数的名称和参数本身。这里返回的参数是 *torch.nn.Parameter* 类，是一种张量。由于 param 是张量的一种类型，所以它也具有*形状* 和*要求 _grad* 属性。 *param.shape* 是张量的简单形状，而*param . requires _ grad***是一个布尔值，它表明参数是否可学习。由于模型中的所有参数都具有**requires _ grad****= True**，这意味着所有参数都是可学习的，并且将在训练模型时更新。如果任何特定的*参数*被设置为**假**，则该参数的权重不会在训练模型时更新。***

***因此， *requires_grad* 是当您想要*训练/冻结*您的模型的一组特定层时，您可能想要更改的标志。***

***现在，我们将尝试冻结所有，但最后一层的模型。如果我们浏览模型所有参数的所有名称，我们可以看到最后一层的名称是*‘fc’*，代表‘全连接’。***

***因此，让我们冻结所有参数，除了名称为*【fc . weight】*或*【fc . bias】*的参数***

***我们可以通过为模型的所有参数打印出 *requires_grad* 来验证所需的更改已经成功完成***

***我们可以看到，所需的更改已经成功完成！***

***因此，我们已经了解了如何为模型的任何所需参数更改 *requires_grad* 标志。我们还了解到，在我们想要*学习/冻结*模型中某些特定参数/层的权重的情况下，这样做非常方便。***

***我们现在将学习两种广为人知的保存模型权重/参数的方法。***

1.  ***torch.save(model.state_dict()，' weights_path_name.pth')
    它只保存模型的****权重*******
2.  *****torch.save(model，' model_path_name.pth')
    保存整个模型(架构**以及权重**)*****

# *****state_dict()是什么，在哪里使用？*****

*****我们将首先看看如何编写 *state_dict* 的语法。这很简单。*****

*****这只是一个 python 的有序字典。*****

*****但是，打印这个，会导致混乱。所以我们不会在这里打印整个模型的 *state_dict* ，但是我鼓励你们继续在屏幕上打印出来！*****

*****我想这是转移话题的好时机。*****

*****看，打印*帮助(模型)*告诉我们，模型是 *nn 的一个实例。模块******

*****也可以使用 python 的 isinstance 函数进行验证*****

******model.fc* 也是 *nn 的实例吗？模块*？*****

*****显然是的！*****

*****但是 *fc* **，**到底是什么，又是从何而来？*****

*****我们什么都能看到 *nn。模块*对象位于模型下*****

*****在任何 *nn 上应用的 *named_children()* 。模块*对象返回它的所有直接子对象(也是 *nn。模块*对象)。看看上面这段代码的结果，我们知道*‘sequential’，‘layer 1’，‘layer 2’，*和*‘fc’，*都是 model 的子节点，所有这些都是 *nn。模块*类对象。现在我们都知道*【fc】*是从哪里来的了。*****

*****你知道吗？ *state_dict()* 作用于任何 *nn。模块*对象并返回它的所有直接子对象(属于类 *nn。模块*)。*****

*****所以我们来试试模型的*‘fc’*层上的 *state_dict()* 函数。*****

*****记住 *model.fc.state_dict()* 或者任何 *nnModule.state_dict()* 都是一个**有序字典**。所以迭代它给了我们字典的键，可以用来访问参数张量，顺便说一下，它不是一个 *nn。模块*对象，而是一个简单的*火炬。具有*形状*和*的张量*需要 _grad* 属性。*****

*****所以一定要注意，当我们保存一个 *nn 的 *state_dict()* 时。模块*对象例如模型、*焊枪。张量*物体被保存！*****

*****这就是我们保存整个模型的 *state_dict* 的方法。*****

*****这在工作目录中生成了一个 *'weights_only.pth'* 文件，它在一个有序的字典中保存了*火炬。张量*模型所有层的对象。*****

*****我们现在将尝试加载保存的重量。但是在此之前，我们需要首先定义模型架构。首先定义模型，然后在其中加载权重是有意义的，因为保存的信息**只是**权重而**不是**模型架构。*****

*****一旦权重被加载到定义的模型中，让我们检查 model_new 所有层的 *requires_grad* 属性。*****

*****等等！什么？*****

*****我们为所有不同层设置的所有 *requires_grad* 标志发生了什么变化？似乎所有的 *requires_grad* 标志都被重置为 **True** 。*****

*****其实我们从来没有在第一时间保存参数的 *required_grad* 标志。记住，一个 *state_dict* 只是一个 python 字典对象，它将每个层映射到它的参数张量。它不保存参数的 *requires_grad* 属性。*****

*****因此，我们需要再次对所有参数的 *requires_grad* 属性进行必要的更改，然后才能继续对模型进行更多时期的训练*****

# *****如何保存整个模型，什么时候做？*****

*****是的，我们有第二种保存东西的方法，也可以保存整个模型。对于整个模型，我指的是模型的**架构**以及它的**重量**。*****

*****因此，我们将从冻结模型的最后一层(即*‘fc’*层)的地方继续，并保存整个模型。*****

*****这将在工作目录中创建一个*‘entire _ model . PTH’*文件，它包含模型架构**以及**保存的权重。*****

*****我们现在将尝试加载保存的模型。这一次，我们不需要定义模型架构，因为关于模型架构的信息已经存储在保存的文件中。*****

*****一旦模型被加载，让我们检查 model_new 所有层的属性。*****

*****这正是我们想要看到的，不是吗？:D*****

*****所以当我们保存整个模型时，我们保存了 *nn。模块*对象，这样做也保存了其所有参数的 *requires_grad* 标志。*****

## *****我强烈建议你们把这个[**public ka ggle kernel**](https://www.kaggle.com/n0obcoder/things-to-know-about-saving-weights-in-pytorch)叉出来，玩玩代码，感受一下！*****

# *******总结*******

*****我们在这个博客中学到了很多东西。*****

1.  *****在 *nn 上应用 ***命名参数()*** 。模块*对象，例如*模型*或
    或*模型.图层 2* 或*模型. fc* 返回所有的名称和各自的参数。这些参数是 *nn。参数*(*火炬的子类。张量*对象，因此它们具有*形状*和*要求 _grad* 属性。*****

*****2. ***需要 *nn 的 _grad**** 属性。参数对象(可学习参数对象)决定是否训练或冻结特定参数。例如，如果我们想要冻结模型的*层 1* ，我们将使用下面的代码。*****

*****3.将 ***命名为 _children()*** 应用于任何 *nn 上。模块*对象返回它的所有直接子对象(也是 *nn。模块*对象)。*****

*****4.任何 *nn 的一个 ***state_dict()*** 。模块*对象，例如*模型*或*模型.层 2* 或*模型. fc* 只是一个 python **有序字典**对象，它将每个参数映射到其参数张量(*火炬。张量*对象)。该有序字典的**键**是参数的名称，可用于访问相应的参数张量。*****

*****5.保存一个 *nn。模块*对象的 *state_dict* 仅**保存该对象的各种参数的** **权重**而**不保存模型架构**。也不涉及权重的 **requires_grad** 属性。所以在加载 state_dict 之前，必须先定义模型。*****

*****6.整个模型( *nn。模块*对象)也可以被保存，这将包括**模型架构及其权重**。既然我们在拯救 *nn。模块*对象， **requires_grad** 属性也以这种方式**保存**。此外，我们不需要在加载保存的文件之前定义模型架构，因为保存的文件中已经保存了模型架构。*****

*****7.保存 *state_dict* 只能用来保存模型的权重。它不会保存 *required_grad* 标志，而保存整个模型会保存模型架构、它的权重以及所有参数的 *requires_grad* 属性。*****

*****8.state _ dict 和整个模型都可以被保存以进行推断。*****

*****我写这篇博客是因为我通过阅读别人的博客学到了很多东西，我觉得我也应该尽可能多地写下并分享我的学习和知识。所以请在下面的评论区留下你的反馈。此外，我是写博客的新手，所以任何关于如何提高我的写作的建议将不胜感激！:D*****

*****我也是一个独立的音乐艺术家，喜欢在空闲时间演奏和录制音乐。也许你可以在 Spotify 上查看我的艺人页面，表示支持:)
[Spotify 上的 8 楼和声！](https://open.spotify.com/artist/7G2BgSnludIYl1gFyJKG6X?si=Bv5L4ZAVQrmIsl5SgGRAUw)*****