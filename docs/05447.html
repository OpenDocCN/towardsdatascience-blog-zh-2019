<html>
<head>
<title>Anisotropic, Dynamic, Spectral and Multiscale Filters Defined on Graphs</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">定义在图上的各向异性、动态、谱和多尺度滤波器</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/tutorial-on-graph-neural-networks-for-computer-vision-and-beyond-part-2-be6d71d70f49?source=collection_archive---------12-----------------------#2019-08-12">https://towardsdatascience.com/tutorial-on-graph-neural-networks-for-computer-vision-and-beyond-part-2-be6d71d70f49?source=collection_archive---------12-----------------------#2019-08-12</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="9260" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">作为“计算机视觉图形神经网络教程”的一部分</h2></div><p id="d3b1" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我将通过使用 Python 和 PyTorch 提取关键思想并解释里程碑方法背后的简单直觉，来概述重要的图形神经网络工作。本帖继续 <a class="ae lf" href="https://medium.com/p/3d9fada3b80d" rel="noopener"> <em class="le">我的教程第一部分</em> </a> <em class="le">。</em></p><figure class="lh li lj lk gt ll gh gi paragraph-image"><div role="button" tabindex="0" class="lm ln di lo bf lp"><div class="gh gi lg"><img src="../Images/b9072358c1b452466f6b0ab17823e8df.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*GMDzusqMN82diJjSxgSW8w.png"/></div></div><figcaption class="ls lt gj gh gi lu lv bd b be z dk">Graph of Graph Neural Network (GNN) and related works. Some other important works and edges are not shown to avoid further clutter. For example, there is a large body of works on dynamic graphs that deserve a separate overview. Best viewed on a very wide screen in color.</figcaption></figure><h1 id="de60" class="lw lx it bd ly lz ma mb mc md me mf mg jz mh ka mi kc mj kd mk kf ml kg mm mn bi translated">20 多年的图形神经网络</h1><p id="d955" class="pw-post-body-paragraph ki kj it kk b kl mo ju kn ko mp jx kq kr mq kt ku kv mr kx ky kz ms lb lc ld im bi translated">在上面的“<strong class="kk iu">图神经网络(GNN)的图及相关著作</strong>”中，我补充了我最近一年接触到的关于图的论文。在该图中，两个作品之间的有向边表示一篇论文基于另一篇论文(尽管没有必要引用它),作品的颜色表示:</p><ul class=""><li id="c797" class="mt mu it kk b kl km ko kp kr mv kv mw kz mx ld my mz na nb bi translated">红色— <strong class="kk iu">光谱方法</strong>(需要拉普拉斯图的特征分解，这将在下面解释)</li><li id="708e" class="mt mu it kk b kl nc ko nd kr ne kv nf kz ng ld my mz na nb bi translated">绿色—在<strong class="kk iu">空间域</strong>中工作的方法(不需要拉普拉斯图的特征分解)</li><li id="6491" class="mt mu it kk b kl nc ko nd kr ne kv nf kz ng ld my mz na nb bi translated">蓝色—相当于光谱方法，但不需要特征分解(因此，实际上是空间方法)</li><li id="29e7" class="mt mu it kk b kl nc ko nd kr ne kv nf kz ng ld my mz na nb bi translated">黑色——是 GNNs 的补充方法，与 GNN 本身的选择无关(例如，集中注意力)。</li></ul><p id="4cee" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">请注意，为了避免混乱，其他一些重要的作品和边缘没有显示出来，只有一小部分作品，用粗体框突出显示的<strong class="kk iu">将在本文中介绍。声明:我仍然在那里找到了挤压我们自己最近作品的空间😊。</strong></p><p id="54c6" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">大多数重要的方法都包含在这个非详尽的作品列表中:</p><ul class=""><li id="aa57" class="mt mu it kk b kl km ko kp kr mv kv mw kz mx ld my mz na nb bi translated">Nicket 等人，2015 年，<a class="ae lf" href="https://arxiv.org/abs/1503.00759" rel="noopener ugc nofollow" target="_blank">知识图的关系机器学习综述</a></li><li id="31ed" class="mt mu it kk b kl nc ko nd kr ne kv nf kz ng ld my mz na nb bi translated">布朗斯坦等，2016，<a class="ae lf" href="https://arxiv.org/abs/1611.08097" rel="noopener ugc nofollow" target="_blank">几何深度学习:超越欧几里德数据</a></li><li id="8c5f" class="mt mu it kk b kl nc ko nd kr ne kv nf kz ng ld my mz na nb bi translated">汉密尔顿等，2017，<a class="ae lf" href="https://arxiv.org/abs/1709.05584" rel="noopener ugc nofollow" target="_blank">图上的表征学习:方法与应用</a></li><li id="f28f" class="mt mu it kk b kl nc ko nd kr ne kv nf kz ng ld my mz na nb bi translated">Kipf 等人，2018，<a class="ae lf" href="http://tkipf.github.io/misc/SlidesCambridge.pdf" rel="noopener ugc nofollow" target="_blank">结构化深度模型:图形上的深度学习及超越</a>，演示幻灯片。</li><li id="4c2a" class="mt mu it kk b kl nc ko nd kr ne kv nf kz ng ld my mz na nb bi translated">巴塔格利亚等人，2018 年，<a class="ae lf" href="https://arxiv.org/abs/1806.01261" rel="noopener ugc nofollow" target="_blank">关系归纳偏差、深度学习和图网络</a></li><li id="52d6" class="mt mu it kk b kl nc ko nd kr ne kv nf kz ng ld my mz na nb bi translated">张等，2018 <a class="ae lf" href="https://arxiv.org/abs/1812.04202" rel="noopener ugc nofollow" target="_blank">关于图的深度学习:一个调查</a></li><li id="1f4f" class="mt mu it kk b kl nc ko nd kr ne kv nf kz ng ld my mz na nb bi translated">周等，2018，<a class="ae lf" href="https://arxiv.org/abs/1812.08434" rel="noopener ugc nofollow" target="_blank">图神经网络:方法与应用综述</a></li><li id="3f7e" class="mt mu it kk b kl nc ko nd kr ne kv nf kz ng ld my mz na nb bi translated">吴等，2019，【图神经<br/>网络综合研究】</li><li id="33b4" class="mt mu it kk b kl nc ko nd kr ne kv nf kz ng ld my mz na nb bi translated">Petar Velič ković，2019，<a class="ae lf" href="https://www.repository.cam.ac.uk/handle/1810/292230" rel="noopener ugc nofollow" target="_blank">深度神经网络中结构的复兴</a>，博士论文。</li><li id="2934" class="mt mu it kk b kl nc ko nd kr ne kv nf kz ng ld my mz na nb bi translated">尼普斯和 CVPR <a class="ae lf" href="https://sungsoo.github.io/2018/02/01/geometric-deep-learning.html" rel="noopener ugc nofollow" target="_blank">视频教程</a></li></ul><p id="40ac" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">使用神经网络对图进行分类的第一项工作似乎是由<a class="ae lf" href="https://ieeexplore.ieee.org/document/572108" rel="noopener ugc nofollow" target="_blank">亚历桑德罗·斯佩尔杜蒂和安东尼娜·斯塔丽塔在</a>发表的一篇<strong class="kk iu"> 1997 </strong>关于“用于结构分类的监督神经网络”的论文。</p><figure class="lh li lj lk gt ll gh gi paragraph-image"><div role="button" tabindex="0" class="lm ln di lo bf lp"><div class="gh gi nh"><img src="../Images/39d9bfa336852a10f6a74c4468e4ecaf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*9CdkztOnwaRFkiZTu1gYgQ.png"/></div></div><figcaption class="ls lt gj gh gi lu lv bd b be z dk">A figure from (<a class="ae lf" href="https://ieeexplore.ieee.org/document/572108" rel="noopener ugc nofollow" target="_blank">Sperduti &amp; Starita, 1997</a>), which is strikingly similar to what we are doing now, after more than 20 years.</figcaption></figure><blockquote class="ni"><p id="8331" class="nj nk it bd nl nm nn no np nq nr ld dk translated"><a class="ae lf" href="https://ieeexplore.ieee.org/document/572108" rel="noopener ugc nofollow" target="_blank">斯珀杜蒂&amp;斯塔里塔，1997 </a>:“到目前为止，神经网络已经被用于对非结构化模式和序列进行分类。然而，标准的神经网络和统计方法通常被认为在处理复杂结构时是不够的，因为它们是基于特征的方法。”</p></blockquote><p id="6e16" class="pw-post-body-paragraph ki kj it kk b kl ns ju kn ko nt jx kq kr nu kt ku kv nv kx ky kz nw lb lc ld im bi translated">自 1997 年以来，关于从图中学习的大量工作已经在如此多的不同方向上增长，如果没有一些智能的自动化系统，很难保持跟踪。我相信我们正在使用基于神经网络的方法(基于我的教程第一部分<em class="le">】</em>中的<a class="ae lf" href="https://medium.com/p/3d9fada3b80d" rel="noopener"> <em class="le">中解释的公式(2)】,或者神经网络和其他方法的某种组合。</em></a></p><figure class="lh li lj lk gt ll gh gi paragraph-image"><div role="button" tabindex="0" class="lm ln di lo bf lp"><div class="gh gi nx"><img src="../Images/ff77f544d880031dbcd0027950da2b13.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Ht9tBXaTrV2gkbMIe7zxMg.png"/></div></div><figcaption class="ls lt gj gh gi lu lv bd b be z dk">Graph neural layer’s formula (2) from <a class="ae lf" href="https://medium.com/p/3d9fada3b80d" rel="noopener"><em class="ny">the first part of my tutorial</em></a><em class="ny"> that we will also need in this part. Keep in mind, that if we need to compute a specific loss for the output features or if we need to stack these layers, we apply some activation like ReLU or Softmax.</em></figcaption></figure><p id="bfcb" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">回顾一下我们在第一部分中使用的符号，我们有一些无向图<em class="le"> G </em>和<em class="le"> N </em>节点。该图中的每个节点都有一个<em class="le"> C </em>维特征向量，所有节点的特征都表示为一个<em class="le"> N </em> × <em class="le"> C </em>维矩阵<em class="le"> X⁽ˡ⁾.</em>在一个典型的图网络中，比如 GCN ( <a class="ae lf" href="https://arxiv.org/abs/1609.02907" rel="noopener ugc nofollow" target="_blank"> Kipf &amp; Welling，ICLR，2017 </a>)，我们将这些特征<em class="le"> X⁽ˡ⁾ </em>馈送到一个具有<em class="le"> C </em> × <em class="le"> F </em>维可训练权重<em class="le"> W⁽ˡ⁾ </em>的图神经层，这样该层的输出就是一个<em class="le"> N </em> × <em class="le"> F </em>矩阵<em class="le">𝓐是一个<em class="le"> N </em> × <em class="le"> N </em>矩阵，其中条目𝓐 <em class="le"> ᵢⱼ </em>指示节点<em class="le"> i </em>是否连接到节点<em class="le"> j </em>的相邻节点<em class="le">。这个矩阵被称为<em class="le">邻接矩阵</em>。我使用𝓐而不是普通的<em class="le"> A </em>来强调这个矩阵可以被<em class="le">规范化</em>以促进深层网络中的特征传播。出于本教程的目的，我们可以假设𝓐= <em class="le"> A </em>，即矩阵乘积𝓐 <em class="le"> X⁽ˡ⁾ </em>的第<em class="le"> i </em>至第<em class="le">t51】行将包含节点<em class="le"> i </em>邻居的特征的总和。</em></em></em></p><p id="3047" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在本部分教程的剩余部分，我将简要解释概览图中用<strong class="kk iu">粗体</strong>框显示的我选择的作品。我推荐<a class="ae lf" href="https://arxiv.org/abs/1611.08097" rel="noopener ugc nofollow" target="_blank">布朗斯坦等人的评论</a>进行更全面和正式的分析。</p><p id="ad06" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">请注意，尽管我在下面深入研究了<strong class="kk iu">光谱图卷积</strong>的一些技术细节，但最近的许多作品(如<a class="ae lf" href="https://arxiv.org/abs/1810.00826" rel="noopener ugc nofollow" target="_blank">徐等人的 GIN，2019 </a>)都是在没有光谱卷积的情况下建立的，并在一些任务中显示出很好的结果。然而，了解谱卷积的工作原理仍然有助于理解和避免其他方法的潜在问题。</p><h1 id="5329" class="lw lx it bd ly lz ma mb mc md me mf mg jz mh ka mi kc mj kd mk kf ml kg mm mn bi translated"><strong class="ak"> 1。光谱图卷积</strong></h1><p id="595d" class="pw-post-body-paragraph ki kj it kk b kl mo ju kn ko mp jx kq kr mq kt ku kv mr kx ky kz ms lb lc ld im bi translated"><a class="ae lf" href="https://arxiv.org/abs/1312.6203" rel="noopener ugc nofollow" target="_blank">布鲁纳等人，2014，ICLR 2014 </a></p><p id="3465" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我在我的<a class="ae lf" rel="noopener" target="_blank" href="/spectral-graph-convolution-explained-and-implemented-step-by-step-2e495b57f801">另一篇文章</a>中详细解释了谱图卷积。</p><p id="d901" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">为了这部分教程的目的，我在这里简单总结一下。谱图卷积的正式定义与信号/图像处理中的<a class="ae lf" href="https://en.wikipedia.org/wiki/Convolution_theorem" rel="noopener ugc nofollow" target="_blank">卷积定理</a>非常相似，可以写成:</p><figure class="lh li lj lk gt ll gh gi paragraph-image"><div role="button" tabindex="0" class="lm ln di lo bf lp"><div class="gh gi nz"><img src="../Images/d84facfea1cd1a9c42cd1a0dbf5a468b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*wBIfFw54z8usWq_merON8A.png"/></div></div><figcaption class="ls lt gj gh gi lu lv bd b be z dk">Spectral graph convolution, where ⊙ means element-wise multiplication.</figcaption></figure><p id="0555" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">其中<em class="le"> V </em>为特征向量，<em class="le">λ</em>为<a class="ae lf" href="https://en.wikipedia.org/wiki/Laplacian_matrix" rel="noopener ugc nofollow" target="_blank"> <strong class="kk iu">图拉普拉斯</strong> </a> <strong class="kk iu"> </strong> <em class="le"> L </em>的特征值，通过特征分解可以找到:<em class="le">l</em>=<em class="le">vλvᵀ；w</em>_ 光谱滤光片。在本教程中，我将假设“<em class="le">对称归一化拉普拉斯算子</em>”。它是基于图的邻接矩阵<em class="le"> A </em>上的<em class="le">唯一</em>来计算的，这可以用几行 Python 代码来完成，如下所示:</p><pre class="lh li lj lk gt oa ob oc od aw oe bi"><span id="6914" class="of lx it ob b gy og oh l oi oj"><strong class="ob iu"># Computing the graph Laplacian<br/># A is an adjacency matrix<br/></strong>import numpy as np</span><span id="7b32" class="of lx it ob b gy ok oh l oi oj">N = A.shape[0] <strong class="ob iu"># number of nodes in a graph</strong><br/>D = np.sum(A, 0) <strong class="ob iu"># node degrees</strong><br/>D_hat = np.diag((D + 1e-5)**(-0.5)) <strong class="ob iu"># normalized node degrees</strong><br/>L = np.identity(N) — np.dot(D_hat, A).dot(D_hat) <strong class="ob iu"># Laplacian</strong></span></pre><p id="a24e" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">这里，我们假设<em class="le"> A </em>是对称的，即<em class="le"> A </em> = <em class="le"> A </em> ᵀ，并且我们的图是无向图，否则节点度不是明确定义的，并且必须做出一些假设来计算拉普拉斯算子。在计算机视觉和机器学习的背景下，图形拉普拉斯定义了如果我们以公式(2)的形式堆叠几个图形神经层，节点特征将如何更新。</p><p id="0b76" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">所以，给定图的拉普拉斯<em class="le"> L </em>，节点特征<em class="le"> X </em>和过滤器<em class="le"> W </em> _spectral，在 Python <strong class="kk iu">图上的谱卷积</strong>看起来非常简单:</p><pre class="lh li lj lk gt oa ob oc od aw oe bi"><span id="e6c3" class="of lx it ob b gy og oh l oi oj"><strong class="ob iu"># Spectral convolution on graphs<br/># X is an <em class="le">N×1 matrix of 1-dimensional node features<br/></em></strong><strong class="ob iu"># L </strong><strong class="ob iu">is an </strong><strong class="ob iu"><em class="le">N</em></strong><strong class="ob iu"><em class="le">×N</em> graph Laplacian computed above<br/># W_spectral are </strong><strong class="ob iu"><em class="le">N</em></strong><strong class="ob iu"><em class="le">×</em></strong><strong class="ob iu"><em class="le">F weights (filters) that we want to train<br/></em></strong>from <!-- -->scipy.sparse.linalg import eigsh <strong class="ob iu"># assumes <em class="le">L</em> to be symmetric</strong></span><span id="a1e0" class="of lx it ob b gy ok oh l oi oj"><em class="le">Λ</em><em class="le">,V</em> = eigsh(L,k=20,which=’SM’) <strong class="ob iu"># </strong><strong class="ob iu">eigen-decomposition (i.e. find <em class="le">Λ</em></strong><strong class="ob iu"><em class="le">,V)</em></strong><br/>X_hat = V.T.dot(X) <strong class="ob iu"># <em class="le">20</em></strong><strong class="ob iu">×</strong><strong class="ob iu"><em class="le">1</em> node features in the "spectral" domain</strong><br/>W_hat = V.T.dot(W_spectral)  <strong class="ob iu"># 20×<em class="le">F</em> filters in the </strong><strong class="ob iu">"spectral" domain</strong><br/>Y = V.dot(X_hat * W_hat)  <strong class="ob iu"># <em class="le">N</em></strong><strong class="ob iu"><em class="le">×</em></strong><strong class="ob iu"><em class="le">F</em> result of convolution</strong></span></pre><p id="bee5" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">其中我们假设我们的节点特征<em class="le"> X⁽ˡ⁾ </em>是一维的，例如 m 像素，但是它可以扩展到<em class="le"> C </em>维的情况:我们将只需要对每个<em class="le">通道</em>重复这个卷积，然后像在信号/图像卷积中一样对<em class="le"> C </em>求和。</p><p id="0544" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">公式(3)本质上与使用傅立叶变换的规则网格上的信号的<a class="ae lf" href="https://en.wikipedia.org/wiki/Convolution_theorem" rel="noopener ugc nofollow" target="_blank">频谱卷积</a>相同，因此为机器学习产生了一些问题:</p><ol class=""><li id="08c2" class="mt mu it kk b kl km ko kp kr mv kv mw kz mx ld ol mz na nb bi translated">可训练权重(滤波器)的维数取决于图中节点的数量；</li><li id="68c5" class="mt mu it kk b kl nc ko nd kr ne kv nf kz ng ld ol mz na nb bi translated"><em class="le"> W_ </em>光谱也取决于图结构中编码的特征向量<em class="le"> V. </em></li></ol><p id="f14d" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">这些问题阻碍了扩展到具有可变结构的大型图形的数据集。</p><p id="162e" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">为了解决第一个问题，<a class="ae lf" href="https://arxiv.org/abs/1312.6203" rel="noopener ugc nofollow" target="_blank">布鲁纳等人</a>提出在谱域对<em class="le">滤波器进行平滑</em>，根据谱理论使<em class="le">滤波器在空间域更加局部化</em>。其思想是，您可以将公式(3)中的滤波器<em class="le"> W_ </em>频谱表示为𝐾预定义函数(如样条函数)的和，并且我们学习这个和的<em class="le"> W </em>的<em class="le"> N </em>值，而不是学习这个和的<em class="le"> K </em>系数<em class="le"> α </em>:</p><figure class="lh li lj lk gt ll gh gi paragraph-image"><div role="button" tabindex="0" class="lm ln di lo bf lp"><div class="gh gi om"><img src="../Images/e4bc0d9cd74eadddfdd33be6cd0db3c0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*sZoZfh6faYLBm7_Nq3xrQw.png"/></div></div><figcaption class="ls lt gj gh gi lu lv bd b be z dk">We can approximate our N dimensional filter<strong class="bd on"> </strong><em class="ny">W_</em>spectral as a finite sum of<em class="ny"> K</em> functions f, such as splines shown below. So, instead of learning N values of <em class="ny">W_</em>spectral, we can learn K coefficients (alpha) of those functions; it becomes efficient when K &lt;&lt; N.</figcaption></figure><p id="22a3" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">虽然<em class="le"> fk </em>的维数确实取决于节点<em class="le"> N </em>的数量，但是这些函数是固定的，所以我们不学习它们。我们唯一知道的是系数<em class="le"> α </em>，因此<em class="le"> W_ </em>光谱不再依赖于<em class="le"> N </em>。为了使我们在公式(4)中的近似合理，我们希望<em class="le"> K </em> &lt; &lt; <em class="le"> N </em>将可训练参数的数量从<em class="le"> N </em>减少到<em class="le"> K </em>，更重要的是，使其独立于<em class="le"> N </em>，以便我们的 GNN 可以消化任何大小的图。</p><p id="7e37" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">虽然解决了第一个问题，但是这种平滑方法没有解决第二个问题。</p><h1 id="87c3" class="lw lx it bd ly lz ma mb mc md me mf mg jz mh ka mi kc mj kd mk kf ml kg mm mn bi translated"><strong class="ak"> 2。切比雪夫</strong>图<strong class="ak">卷积</strong></h1><p id="1617" class="pw-post-body-paragraph ki kj it kk b kl mo ju kn ko mp jx kq kr mq kt ku kv mr kx ky kz ms lb lc ld im bi translated"><a class="ae lf" href="https://arxiv.org/abs/1606.09375" rel="noopener ugc nofollow" target="_blank"> Defferrard 等人，NeurIPS，2016 年</a></p><p id="0389" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">上面的频谱卷积及其平滑版本的主要缺点是，它仍然需要对一个<em class="le"> N </em> × <em class="le"> N </em>维拉普拉斯图<em class="le"> L </em>进行本征分解，这产生了两个主要问题:</p><ol class=""><li id="52ec" class="mt mu it kk b kl km ko kp kr mv kv mw kz mx ld ol mz na nb bi translated">🙁特征分解的复杂度是巨大的，O( <em class="le"> N </em>)。此外，在大图的情况下，在 RAM 中以密集格式保持图拉普拉斯是不可行的。一种解决方案是使用稀疏矩阵，并用 Python 中的<code class="fe oo op oq ob b">scipy.sparse.linalg.eigs</code>找到特征向量。此外，您可以在具有大量 RAM 和 CPU 内核的专用服务器上预处理所有训练图。在很多应用中，你的测试图也可以提前预处理，但是如果你不断有新的大图涌入，特征分解会让你难过。</li><li id="2ccb" class="mt mu it kk b kl nc ko nd kr ne kv nf kz ng ld ol mz na nb bi translated">🙁另一个问题是，你训练的模型最终与图的特征向量<em class="le"> V </em>密切相关。如果您的训练图和测试图具有非常不同的结构(节点和边的数量)，这可能是一个大问题。否则，如果所有的图形都非常相似，问题就不大了。此外，如果您在频域中使用一些平滑滤波器，如上面讨论的样条，那么您的滤波器将变得更加局部化，适应新图形的问题似乎更加不明显。然而，这些模型仍然非常有限。</li></ol><p id="ee1d" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">那么，切比雪夫图卷积和这些有什么关系呢？</p><p id="4165" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">原来它同时解决了<strong class="kk iu">两个问题！</strong>😃</p><p id="fd19" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">也就是说，它避免了计算昂贵的特征分解，并且滤波器不再“附着”于特征向量(然而它们仍然是特征值<em class="le">λ)</em>的函数)。此外，它有一个非常有用的参数，通常表示为<em class="le"> K </em>，具有与我们上面的公式(4)中的<em class="le"> K </em>相似的直觉，确定滤波器的局部性。非正式地:对于<em class="le"> K </em> =1，我们只将节点特性<em class="le"> X⁽ˡ⁾ </em>提供给我们的 gnn 对于<em class="le"> K </em> =2，我们馈<em class="le"> X⁽ˡ⁾ </em> <strong class="kk iu"> </strong>和𝓐<em class="le">x⁽ˡ⁾</em>；对于 K=3，我们馈<em class="le">x⁽ˡ⁾</em><strong class="kk iu"/>𝓐<em class="le">x⁽ˡ⁾</em><strong class="kk iu"/>和𝓐<em class="le">x⁽ˡ⁾</em>；对于更大的<em class="le"> K </em>以此类推(我希望你已经注意到这个模式)。更准确正式的定义见<a class="ae lf" href="https://arxiv.org/abs/1606.09375" rel="noopener ugc nofollow" target="_blank"> Defferrard et al. </a>和下面我的代码，加上额外的分析在(<a class="ae lf" href="https://arxiv.org/abs/1811.09595" rel="noopener ugc nofollow" target="_blank"> Knyazev et al .，NeurIPS-W，2018 </a>)中给出。</p><p id="76a6" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">由于邻接矩阵的<a class="ae lf" href="https://en.wikipedia.org/wiki/Adjacency_matrix#Matrix_powers" rel="noopener ugc nofollow" target="_blank">幂属性</a>，当我们执行𝓐 <em class="le"> X⁽ˡ⁾ </em>时，我们实际上对 2 跳邻居进行平均(或求和，取决于𝓐如何归一化)，并且类似地，对𝓐 <em class="le"> ⁿX⁽ˡ⁾ </em>中的任何<em class="le"> n </em>进行平均，如下图所示，其中我们对<em class="le"> n </em>跳邻居进行平均。</p><figure class="lh li lj lk gt ll gh gi paragraph-image"><div role="button" tabindex="0" class="lm ln di lo bf lp"><div class="gh gi or"><img src="../Images/65e27b1442b5903c759766e4f3a2a5ab.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ybJ4HOmtSwhmCB1f2JX07A.png"/></div></div><figcaption class="ls lt gj gh gi lu lv bd b be z dk">Chebyshev convolution for <em class="ny">K</em>=3 for node 1 (dark blue). Circled nodes denote the nodes affecting feature representation of node 1. The [,] operator denotes concatenation over the feature dimension. W<em class="ny">⁽ˡ⁾ are 3C</em>×F dimensional weights.</figcaption></figure><p id="4aba" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">注意，为了满足切比雪夫基的正交性，𝓐 <strong class="kk iu"> </strong>假设图中没有回路，因此在矩阵乘积𝓐 <em class="le"> X⁽ˡ⁾ </em>的每<em class="le"> i </em>行中，我们将具有节点<em class="le"> i </em>的邻居的特征，但是<strong class="kk iu">没有</strong>节点<em class="le"> i </em>本身的特征。节点<em class="le"> i </em>的特征将作为矩阵<em class="le"> X⁽ˡ⁾.单独输入</em></p><p id="9f86" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">如果<em class="le"> K </em>等于节点数<em class="le"> N </em>，则切比雪夫卷积非常接近于频谱卷积，因此滤波器的感受域将是整个图形。但是，正如卷积网络的情况一样，由于我已经讨论过的一些原因，我们不希望滤波器与输入图像一样大，因此在实践中，<em class="le"> K </em>取合理的小值。</p><blockquote class="ni"><p id="ff9b" class="nj nk it bd nl nm os ot ou ov ow ld dk translated">根据我的经验，这是最强大的 gnn 之一，在非常广泛的图形任务中取得了很好的结果。主要的缺点是在向前/向后传递中必须循环遍历<em class="ny"> K </em>(因为切比雪夫多项式是递归的，所以不可能并行化它们)，这会降低模型的速度。</p></blockquote><p id="acdc" class="pw-post-body-paragraph ki kj it kk b kl ns ju kn ko nt jx kq kr nu kt ku kv nv kx ky kz nw lb lc ld im bi translated">与上面讨论的样条一样，我们不是训练滤波器，而是训练切比雪夫多项式的系数。</p><figure class="lh li lj lk gt ll gh gi paragraph-image"><div role="button" tabindex="0" class="lm ln di lo bf lp"><div class="gh gi ox"><img src="../Images/ded74043e7cfcc4998b6db7490c8e1c3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*SGSYcSA5WqGYPYDwKTQT1g.png"/></div></div><figcaption class="ls lt gj gh gi lu lv bd b be z dk">Chebyshev basis used to approximate convolution in the spectral domain.</figcaption></figure><p id="418c" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">要生成切比雪夫基，可以使用以下 Python 代码:</p><pre class="lh li lj lk gt oa ob oc od aw oe bi"><span id="7f8a" class="of lx it ob b gy og oh l oi oj"><strong class="ob iu"># Set K to some integer &gt; 0, like 4 or 5 in our plots above<br/># Set n_points to a number of points on a curve (we set to 100)<br/></strong>import numpy as np</span><span id="22f8" class="of lx it ob b gy ok oh l oi oj">x = np.linspace(-1, 1, n_points)<br/>T = np.zeros((K, len(x)))<br/>T[0,:] = 1<br/>T[1,:] = x<br/>for n in range(1, K-1):<br/>    T[n+1, :] = 2*x*T[n, :] - T[n-1, :] <strong class="ob iu"># recursive computation</strong>   <br/>return T</span></pre><p id="9b99" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">生成样条和切比雪夫基的完整代码在<a class="ae lf" href="https://github.com/bknyaz/examples/blob/master/splines_cheb.py" rel="noopener ugc nofollow" target="_blank">我的 github repo </a>中。</p><p id="0601" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">为了说明切比雪夫滤波器在不规则网格上的表现，我再次遵循<a class="ae lf" href="https://arxiv.org/abs/1312.6203" rel="noopener ugc nofollow" target="_blank">布鲁纳等人</a>的实验，从 MNIST 网格中随机抽取 400 个点，其方式与我展示拉普拉斯图的特征向量的方式相同。我在从这 400 个位置采样的 MNIST 图像上训练了一个切比雪夫图卷积模型(相同的不规则网格用于所有图像),下面显示了一个用于<em class="le"> K </em> =1 和<em class="le"> K </em> =20 的过滤器。</p><figure class="lh li lj lk gt ll gh gi paragraph-image"><div class="gh gi oy"><img src="../Images/74e53897cf90f815bdd93486cd829cec.png" data-original-src="https://miro.medium.com/v2/resize:fit:792/1*Hd0dkgJNOfOs5KAo3oIiwQ.gif"/></div><figcaption class="ls lt gj gh gi lu lv bd b be z dk">A single Chebyshev filter (K=3 on the left and K=20 on the right) trained on MNIST and applied at different locations (shown as a red pixel) on a irregular grid with 400 points. Compared to filters of standard ConvNets, GNN filters have different shapes depending <em class="ny">on the node at which they are applied</em>, because each node has a different neighborhood structure.</figcaption></figure><h1 id="ec2c" class="lw lx it bd ly lz ma mb mc md me mf mg jz mh ka mi kc mj kd mk kf ml kg mm mn bi translated"><strong class="ak"> 3。GCN </strong></h1><p id="e647" class="pw-post-body-paragraph ki kj it kk b kl mo ju kn ko mp jx kq kr mq kt ku kv mr kx ky kz ms lb lc ld im bi translated"><a class="ae lf" href="https://arxiv.org/abs/1609.02907" rel="noopener ugc nofollow" target="_blank"> Kipf &amp;韦林，ICLR，2017 </a></p><p id="6f20" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">您可能已经注意到，如果增加切比雪夫卷积的<em class="le"> K </em>，可训练参数的总数就会增加。例如，对于<em class="le"> K </em> =2，我们的权重<em class="le"> W⁽ˡ⁾ </em>将是 2 <em class="le"> C </em> × <em class="le"> F </em>而不是仅仅<em class="le"> C </em> × <em class="le"> F </em>。这是因为我们将特征<em class="le">x⁽ˡ⁾</em>t16】t17】和𝓐 <em class="le"> X⁽ˡ⁾ </em>连接成一个单一的<em class="le"> N </em> ×2 <em class="le"> C </em>矩阵。更多的训练参数意味着模型<em class="le"> </em>比<em class="le"> </em>更难训练，需要标注更多的数据<em class="le"> </em>进行训练。图表数据集通常非常小。在计算机视觉中，MNIST 被认为是一个很小的数据集，因为图像只有 28×28 维，只有 60k 个训练图像，而在图网络中，MNIST 是相当大的，因为每个图将有<em class="le"> N </em> =784 个节点，60k 是大量的训练图。与计算机视觉任务相比，许多图形数据集只有大约 20-100 个节点和 200-1000 个训练样本。这些图可以表示某些小分子，标记化学/生物数据通常比标记图像更昂贵。因此，训练切比雪夫卷积模型可能导致训练集的严重过拟合(即，模型将具有接近 0 的训练损失，但将具有较大的验证或测试误差)。所以，<a class="ae lf" href="https://arxiv.org/abs/1609.02907" rel="noopener ugc nofollow" target="_blank"> Kipf &amp; Welling </a>的 GCN 本质上是将节点特征<em class="le">x⁽ˡ⁾</em>t36】t37】和𝓐 <em class="le"> X⁽ˡ⁾ </em>的矩阵“合并”成一个单独的<em class="le"> N </em> × <em class="le"> C </em>矩阵。结果，与具有<em class="le"> K </em> =2 的切比雪夫卷积相比，该模型需要训练的参数少了两倍，但具有 1 跳的相同感受野。主要的技巧是通过将一个<a class="ae lf" href="https://en.wikipedia.org/wiki/Identity_matrix" rel="noopener ugc nofollow" target="_blank">单位矩阵</a> <em class="le"> I </em>添加到𝓐 <em class="le"> </em>中，并以特定的方式对其进行规范化，从而将“自循环”添加到您的图中，因此现在在矩阵乘积的每一行<em class="le">I</em><em class="le">x⁽ˡ⁾</em>中，我们将拥有节点<em class="le"> i、</em> <strong class="kk iu">的邻居的特征，以及节点<em class="le"> i. </em>的</strong>特征</p><blockquote class="ni"><p id="123e" class="nj nk it bd nl nm os ot ou ov ow ld dk translated">这个模型似乎是一个标准的基线选择，非常适合许多应用程序，因为它的轻量级、良好的性能和对较大图形的可伸缩性。</p></blockquote><h2 id="1b23" class="of lx it bd ly oz pa dn mc pb pc dp mg kr pd pe mi kv pf pg mk kz ph pi mm pj bi translated">3.1.GCN vs 切比雪夫层</h2><p id="44ba" class="pw-post-body-paragraph ki kj it kk b kl mo ju kn ko mp jx kq kr mq kt ku kv mr kx ky kz ms lb lc ld im bi translated">GCN 卷积和切比雪夫卷积的区别如下图所示。</p><figure class="lh li lj lk gt ll"><div class="bz fp l di"><div class="pk pl l"/></div></figure><p id="8292" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">上面的代码遵循与我的教程 的第一部分<a class="ae lf" href="https://medium.com/p/3d9fada3b80d" rel="noopener"> <em class="le">中相同的结构，在那里我比较了经典的 NN 和 GNN。GCN 和切比雪夫卷积中的一个主要步骤是重新标度图拉普拉斯<em class="le"> L </em>的计算。进行这种重新调整是为了使特征值在[-1，1]的范围内，以便于训练(这在实践中可能不是非常重要的步骤，因为权重可以在训练期间适应)。在 GCN，如上所述，在计算拉普拉斯算子之前，通过添加单位矩阵将自循环添加到图中。这两种方法的主要区别在于，在切比雪夫卷积中，我们<em class="le">递归地</em>遍历<em class="le"> K </em>来捕获<em class="le"> K </em>跳邻域中的特征。我们可以将这样的 GCN 或切比雪夫层与非线性交错堆叠起来，构建一个图形神经网络。</em></a></p></div><div class="ab cl pm pn hx po" role="separator"><span class="pp bw bk pq pr ps"/><span class="pp bw bk pq pr ps"/><span class="pp bw bk pq pr"/></div><div class="im in io ip iq"><p id="2593" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">现在，让我礼貌地打断一下😃我们的频谱讨论并给出了另外两种令人兴奋的方法背后的大致想法:边缘条件滤波器，由<a class="ae lf" href="https://arxiv.org/abs/1704.02901" rel="noopener ugc nofollow" target="_blank"> Simonovsky &amp; Komodakis，CVPR，2017 </a>和莫奈，由<a class="ae lf" href="https://arxiv.org/abs/1611.08402" rel="noopener ugc nofollow" target="_blank"> Monti 等人，CVPR，2017 </a>，它们共享一些类似的概念。</p><h1 id="2258" class="lw lx it bd ly lz ma mb mc md me mf mg jz mh ka mi kc mj kd mk kf ml kg mm mn bi translated"><strong class="ak"> 4。边缘调节的</strong>滤波器</h1><p id="6fd1" class="pw-post-body-paragraph ki kj it kk b kl mo ju kn ko mp jx kq kr mq kt ku kv mr kx ky kz ms lb lc ld im bi translated"><a class="ae lf" href="https://arxiv.org/abs/1704.02901" rel="noopener ugc nofollow" target="_blank">西蒙诺夫斯基&amp;CVPR 科莫达基斯，2017 </a></p><p id="d939" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">如你所知，在 ConvNets 中，我们通过优化一些损失来学习权重(过滤器)，如<a class="ae lf" href="https://pytorch.org/docs/stable/nn.html#torch.nn.CrossEntropyLoss" rel="noopener ugc nofollow" target="_blank">交叉熵</a>。同样，我们在 GNNs 中学习 W⁽ˡ⁾。想象一下，你有另一个网络来预测这些权重，而不是学习这些权重。因此，在训练过程中，我们学习辅助网络的权重，它以一幅图像或一个图形作为输入，并返回权重<em class="le"> W⁽ˡ⁾ </em>(他们工作中的θ)作为输出。该想法基于<strong class="kk iu">动态滤波器网络</strong> ( <a class="ae lf" href="https://arxiv.org/abs/1605.09673" rel="noopener ugc nofollow" target="_blank"> Brabandere 等人，NIPS，2016 </a>)，其中“动态”意味着滤波器<em class="le"> W⁽ˡ⁾ </em>将根据输入而不同，这与标准模型相反，在标准模型中，滤波器在训练后是固定的(或静态的)。</p><figure class="lh li lj lk gt ll gh gi paragraph-image"><div role="button" tabindex="0" class="lm ln di lo bf lp"><div class="gh gi pt"><img src="../Images/d86fbbe0ab053ff325c21ee2760a1de4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*0v1xygb2cN-3do55tAh1eg.png"/></div></div><figcaption class="ls lt gj gh gi lu lv bd b be z dk">Using an auxiliary “filter generating network” Fˡ to predict edge-specific weights Θ for the main network. Xˡ⁻¹ are input node features and Xˡ are output features. The figure shows a single iteration of “dynamic convolution” for node 1 (in yellow). Standard GNNs typically would simply average (or sum) features of node 1 neighbors (nodes 2, 3, 4, 5) , which would correspond to having an isotropic filter (Θ would be a constant vector). In contrast, this model has anisotropic filters, because it predicts different edge values between node 1 and all it’s neighbors based on edge labels L, so that features Xˡ(1) are computed as a weighted average of neighbors’ features. Figure from (<a class="ae lf" href="https://arxiv.org/abs/1704.02901" rel="noopener ugc nofollow" target="_blank">Simonovsky &amp; Komodakis, CVPR, 2017</a>).</figcaption></figure><p id="2ee5" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">这是一种非常普遍的卷积形式，除了图像之外，还可以很容易地应用于图形或点云，正如他们在 CVPR 的论文中所做的那样，并获得了出色的结果。然而，没有“<a class="ae lf" href="https://en.wikipedia.org/wiki/No_free_lunch_theorem" rel="noopener ugc nofollow" target="_blank">免费的午餐</a>”，训练这样的模型相当具有挑战性，因为常规的网格约束现在已经放松，解决方案的范围急剧增加。这对于具有许多边的较大图形或较深层中的卷积来说尤其如此，这些图形通常具有数百个通道(特征数量，<em class="le"> C) </em>，因此您可能最终会为每个输入总共生成数千个数字！在这方面，标准 ConvNets 非常好，因为我们没有浪费模型的能力来训练预测这些权重，而是直接强制要求滤波器对所有输入都应该相同。但是，这种先验使 ConvNets 受到限制，我们不能直接将它们应用于图形或点云。因此，一如既往，在特定任务中，灵活性和性能之间会有一些权衡。</p><blockquote class="ni"><p id="cfec" class="nj nk it bd nl nm os ot ou ov ow ld dk translated">当应用于图像时，如 MNIST，边缘条件模型可以学习预测<em class="ny">各向异性</em>滤波器——对方向敏感的滤波器，如边缘检测器。与我的教程 的第一部分<a class="ae lf" href="https://medium.com/p/3d9fada3b80d" rel="noopener"> <em class="ny">中讨论的高斯滤波器相比，这些滤波器能够更好地捕捉图像中的某些模式，例如数字中的笔画。</em></a></p></blockquote><figure class="pv pw px py pz ll gh gi paragraph-image"><div class="gh gi pu"><img src="../Images/f9388b8936b6a2f15a73a9967db5605b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1038/format:webp/1*aApSWc8LXLpEwvO312yuUg.png"/></div><figcaption class="ls lt gj gh gi lu lv bd b be z dk">Convolutional filters learned on MNIST sampled in low (left) and high (right) resolutions. Figure from (<a class="ae lf" href="https://arxiv.org/abs/1704.02901" rel="noopener ugc nofollow" target="_blank">Simonovsky &amp; Komodakis, CVPR, 2017</a>).</figcaption></figure><p id="1ff2" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我想再强调一次，每当我们有一个带有辅助网络的复杂模型时，在某种意义上它就变成了一个先有鸡还是先有蛋的问题。为了解决这个问题，其中一个网络(辅助网络或主网络)应该接收到非常强的信号，这样它就可以隐式地监控另一个网络。在我们的<a class="ae lf" href="https://arxiv.org/abs/1907.09000" rel="noopener ugc nofollow" target="_blank"> BMVC 论文</a>中，类似于<a class="ae lf" href="https://arxiv.org/abs/1704.02901" rel="noopener ugc nofollow" target="_blank">Simonovsky&amp;Komodakis</a>的工作，我们在生成边的网络上应用了额外的约束来促进训练。我将在后面的帖子中详细描述我们的工作。</p><h1 id="ed94" class="lw lx it bd ly lz ma mb mc md me mf mg jz mh ka mi kc mj kd mk kf ml kg mm mn bi translated"><strong class="ak"> 5。莫奈</strong></h1><p id="d755" class="pw-post-body-paragraph ki kj it kk b kl mo ju kn ko mp jx kq kr mq kt ku kv mr kx ky kz ms lb lc ld im bi translated"><a class="ae lf" href="https://arxiv.org/abs/1611.08402" rel="noopener ugc nofollow" target="_blank">蒙蒂等人，CVPR，2017 年</a></p><p id="bbdd" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">MoNet 不同于本文中讨论的其他作品，因为它假定具有节点坐标的概念，因此更适合于几何任务，如 3D 网格分析或图像/视频推理。它有点类似于<a class="ae lf" href="https://arxiv.org/abs/1704.02901" rel="noopener ugc nofollow" target="_blank"> Simonovsky &amp; Komodakis </a>的边缘条件滤波器，因为它们也引入了预测权重的辅助可学习函数𝐷(𝑤、𝜃 <em class="le">，ρ </em>。不同的是，这些权重取决于节点极坐标(角度𝜃和半径<em class="le">ρ</em>)；并且该函数的可训练参数𝑤被约束为高斯分布的均值和方差，从而我们不是学习<em class="le"> N </em> × <em class="le"> N </em>矩阵，而是仅学习与图大小<em class="le"> N </em>无关的固定大小的向量(均值和方差)。就标准 ConvNets 而言，对于每个滤波器来说，只学习 2 个值(高斯分布的平均值和方差)是相同的，而不是分别学习 3×3、5×5 或 11×11 维滤波器的 9、25 或 121 个值。这种<em class="le">参数化</em>将极大地减少 ConvNet 中的参数数量，但滤波器捕捉图像特征的能力非常有限。</p><p id="a2fe" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><a class="ae lf" href="https://arxiv.org/abs/1611.08402" rel="noopener ugc nofollow" target="_blank"> Monti 等人</a>训练高斯的𝐽均值和方差，转换节点坐标的过程类似于将它们拟合到<a class="ae lf" href="https://scikit-learn.org/stable/modules/mixture.html" rel="noopener ugc nofollow" target="_blank">高斯混合模型</a>。如果我们希望我们的过滤器足够全局，那么这个模型的训练计算量相当大，但它可能是视觉任务的一个很好的选择(参见我们的<a class="ae lf" href="https://arxiv.org/abs/1907.09000" rel="noopener ugc nofollow" target="_blank"> BMVC 论文</a>进行比较)，但在非视觉任务上，它往往比简单的 GCN 差(<a class="ae lf" href="https://arxiv.org/abs/1811.09595" rel="noopener ugc nofollow" target="_blank"> Knyazev 等人，NeurIPS-W，2018 </a>)。由于函数<em class="le"> D </em>依赖于坐标，生成的滤波器也是各向异性的，并且具有如下图所示的定向和拉长的高斯形状。</p><figure class="lh li lj lk gt ll gh gi paragraph-image"><div class="gh gi qa"><img src="../Images/ce2745eb015b147d66e6b5fcf7225d40.png" data-original-src="https://miro.medium.com/v2/resize:fit:576/format:webp/1*TM_3zmnc4esqwqIdfgTvvA.png"/></div><figcaption class="ls lt gj gh gi lu lv bd b be z dk">Filters trained with MoNet in polar coordinates 𝜃 and <em class="ny">ρ</em>. Each ellipse corresponds to a slice of a Gaussian at some fixed level. The idea is that if the coordinates of the i-th node are close to the middle of the j-th Gaussian, then the generated weight at index (i,j) will have a value close to 1.</figcaption></figure><pre class="lh li lj lk gt oa ob oc od aw oe bi"><span id="27fc" class="of lx it ob b gy og oh l oi oj"><strong class="ob iu"><em class="le">Pseudo-code of the MoNet layer using PyTorch</em></strong></span><span id="8c17" class="of lx it ob b gy ok oh l oi oj"><strong class="ob iu"># assume X to be input <em class="le">N</em></strong>×<strong class="ob iu"><em class="le">C</em> node features</strong><br/><strong class="ob iu"># coord are <em class="le">N</em>×<em class="le">N</em>×<em class="le">2</em> node coordinate differences between all pairs of nodes (node degrees for non-geometric tasks)<br/># coord can be viewed as angular and radial edges between nodes</strong></span><span id="291c" class="of lx it ob b gy ok oh l oi oj">1. Generate <em class="le">J</em> Gaussian-shaped filters based on coordinates of nodes    using some trainable function D<br/>   weights = D(coord)  # weights: <em class="le">J</em>×<em class="le">N</em>×<em class="le">N</em><br/>2. Multiply node features X by these weights<br/>   X = torch.bmm(weights, X.expand(J, N, C))  # X: <em class="le">J</em>×<em class="le">N</em>×<em class="le">C</em><br/>3. Project features by a learnable linear transformation<br/>   X = fc(X.permute(1, 2, 0).view(N, J*C))  # X: <em class="le">N</em>×<em class="le">F<br/></em>4. Feed X to the next layer</span></pre><h1 id="453c" class="lw lx it bd ly lz ma mb mc md me mf mg jz mh ka mi kc mj kd mk kf ml kg mm mn bi translated">结论</h1><p id="5692" class="pw-post-body-paragraph ki kj it kk b kl mo ju kn ko mp jx kq kr mq kt ku kv mr kx ky kz ms lb lc ld im bi translated">尽管讨论了很长时间，我们只是触及了皮毛。图形神经网络的应用正在扩展，远远超出了典型的图形推理任务，如分子分类。不同图形神经层的数量增长非常快，类似于几年前卷积网络的情况，因此很难跟踪它们。在这一点上，<a class="ae lf" href="https://github.com/rusty1s/pytorch_geometric" rel="noopener ugc nofollow" target="_blank">py torch Geometric(PyG)</a>——一个从图表中学习的好工具箱——经常用新颖的图层和技巧填充它的集合。</p><p id="e7de" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><em class="le">鸣谢:本教程的很大一部分是我在 SRI International 实习期间在</em> <a class="qb qc ep" href="https://medium.com/u/6cf41cb2c546?source=post_page-----be6d71d70f49--------------------------------" rel="noopener" target="_blank"> <em class="le">穆罕默德·阿梅尔</em> </a> <em class="le"> ( </em> <a class="ae lf" href="https://mohamedramer.com/" rel="noopener ugc nofollow" target="_blank"> <em class="le">主页</em> </a> <em class="le">)和我的博士导师格拉汉姆·泰勒(</em> <a class="ae lf" href="https://www.gwtaylor.ca/" rel="noopener ugc nofollow" target="_blank"> <em class="le">主页</em> </a> <em class="le">)的指导下编写的。我也感谢</em><a class="ae lf" href="https://www.linkedin.com/in/carolynaugusta/" rel="noopener ugc nofollow" target="_blank"><em class="le">Carolyn Augusta</em></a><em class="le">的有用反馈。</em></p><p id="349e" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在<a class="ae lf" href="https://github.com/bknyaz/" rel="noopener ugc nofollow" target="_blank"> Github </a>、<a class="ae lf" href="https://www.linkedin.com/in/boris-knyazev-39690948/" rel="noopener ugc nofollow" target="_blank"> LinkedIn </a>和<a class="ae lf" href="https://twitter.com/BorisAKnyazev" rel="noopener ugc nofollow" target="_blank"> Twitter </a>上找我。<a class="ae lf" href="https://bknyaz.github.io/" rel="noopener ugc nofollow" target="_blank">我的主页</a>。</p><p id="dfe7" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">如果你想在你的论文中引用这篇博文，请使用:<br/><a class="ae lf" href="http://twitter.com/misc" rel="noopener ugc nofollow" target="_blank"><em class="le">@ misc</em></a><em class="le">{ Knyazev 2019 Tutorial，<br/>title = {用于计算机视觉及超越的图形神经网络教程}，<br/> author={Knyazev，Boris and Taylor，Graham W and Amer，Mohamed R}，<br/> year={2019} <br/> } </em></p></div></div>    
</body>
</html>