<html>
<head>
<title>The Fundamentals of Scalable Data Science with Apache Spark</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">Apache Spark 的可扩展数据科学基础</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/a-summary-of-the-advanced-data-science-with-ibm-specialization-1-4-5caf48c011df?source=collection_archive---------22-----------------------#2019-12-01">https://towardsdatascience.com/a-summary-of-the-advanced-data-science-with-ibm-specialization-1-4-5caf48c011df?source=collection_archive---------22-----------------------#2019-12-01</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><h2 id="53bb" class="ir is it bd b dl iu iv iw ix iy iz dk ja translated" aria-label="kicker paragraph"><a class="ae ep" href="https://towardsdatascience.com/tagged/advanced-data-science" rel="noopener" target="_blank"> IBM 高级数据科学专业</a></h2><div class=""/><div class=""><h2 id="c0c2" class="pw-subtitle-paragraph jz jc it bd b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq dk translated">我的想法是，对 IBM 高级数据科学专业中可伸缩数据科学基础的关键概念进行分解</h2></div><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi kr"><img src="../Images/632dc5b4391419f3b0aaddbdfba3bf2e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*HmyQPuPpYkcpCEA1"/></div></div><figcaption class="ld le gj gh gi lf lg bd b be z dk">Photo by <a class="ae lh" href="https://unsplash.com/@sonson?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Carson Masterson</a> on <a class="ae lh" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><p id="7efb" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi me translated"><span class="l mf mg mh bm mi mj mk ml mm di"> W </span>当在网上浏览数据科学/机器学习认证时，很容易在大量可用的产品中感到困惑和迷失。</p><p id="fb78" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">我之前参加了斯坦福大学认证的著名的机器学习(在这里阅读<a class="ae lh" rel="noopener" target="_blank" href="/a-review-of-stanfords-machine-learning-certification-9614ebee2b06"/>)，我非常喜欢。我原本计划继续在吴恩达工作，并从 deeplearning.ai 的深度学习专业开始。虽然这看起来很神奇，但我偶然发现了 IBM 提供的这个专业。</p><p id="d95f" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">那么，是什么吸引我走向 IBM 的专业化呢？有两个主要原因:</p><ul class=""><li id="dc18" class="mn mo it lk b ll lm lo lp lr mp lv mq lz mr md ms mt mu mv bi translated"><strong class="lk jd"> Apache Spark </strong> —这是最大的原因，云计算在机器学习的世界中非常重要，Apache Spark 在这个领域非常庞大。我对云计算的了解有限，也没有使用 Apache Spark 的经验，所以这对我来说是一个很大的卖点。</li><li id="a01e" class="mn mo it lk b ll mw lo mx lr my lv mz lz na md ms mt mu mv bi translated">看起来更广泛(尽管可能更浅)的关注点，例如云计算、物联网和信号处理对数据科学的实际应用。</li></ul><p id="aabc" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">作为可扩展数据科学的基础，这篇文章自然是关于我在专业化第一部分(第一至第四周)的经历。我们还将涵盖:</p><ul class=""><li id="e6ee" class="mn mo it lk b ll lm lo lp lr mp lv mq lz mr md ms mt mu mv bi translated">Apache Spark 的基础知识(架构、rdd 和 ApacheSparkSQL)</li><li id="504b" class="mn mo it lk b ll mw lo mx lr my lv mz lz na md ms mt mu mv bi translated">四个统计时刻(非常简短)</li><li id="d99e" class="mn mo it lk b ll mw lo mx lr my lv mz lz na md ms mt mu mv bi translated">协方差、相关性及其各自的矩阵</li><li id="2fb2" class="mn mo it lk b ll mw lo mx lr my lv mz lz na md ms mt mu mv bi translated">主成分分析降维</li></ul><p id="f0d1" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">我们开始吧！</p><h1 id="1009" class="nb nc it bd nd ne nf ng nh ni nj nk nl ki nm kj nn kl no km np ko nq kp nr ns bi translated">可扩展数据科学基础</h1><h2 id="c4fe" class="nt nc it bd nd nu nv dn nh nw nx dp nl lr ny nz nn lv oa ob np lz oc od nr iz bi translated">第 1 周—简要介绍…</h2><p id="e2ce" class="pw-post-body-paragraph li lj it lk b ll oe kd ln lo of kg lq lr og lt lu lv oh lx ly lz oi mb mc md im bi translated">本课程首先由课程讲师 Romeo(IBM 的首席数据科学家)简要介绍 Apache Spark，以及我们将在接下来的几周内讨论的内容。接下来是如何使用 IBM Watson Studio 安装 Apache Spark 的说明，IBM Watson Studio 是贯穿整个课程的云服务。</p><p id="063a" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">然后有两个简短的编程<em class="oj">【任务】</em>，只是为了确保你有正确的环境设置。这个星期可以很容易地在不到一个小时内完成，我不会称之为一个星期...</p><h2 id="5dde" class="nt nc it bd nd nu nv dn nh nw nx dp nl lr ny nz nn lv oa ob np lz oc od nr iz bi translated">第 2 周—数据存储、Apache Spark、RDDs 和 SQL</h2><p id="1d4f" class="pw-post-body-paragraph li lj it lk b ll oe kd ln lo of kg lq lr og lt lu lv oh lx ly lz oi mb mc md im bi translated">在这里，我们开始了解不同的数据存储解决方案。即:</p><ul class=""><li id="0cf0" class="mn mo it lk b ll lm lo lp lr mp lv mq lz mr md ms mt mu mv bi translated">结构化查询语言</li><li id="e1c4" class="mn mo it lk b ll mw lo mx lr my lv mz lz na md ms mt mu mv bi translated">NoSQL</li><li id="9019" class="mn mo it lk b ll mw lo mx lr my lv mz lz na md ms mt mu mv bi translated">对象存储</li></ul><p id="3eae" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">在讨论了各自的优缺点之后，我们开始学习 Apache Spark，重点是<strong class="lk jd">可伸缩性和并行处理</strong>。这部分其实很有意思！我们来看看 Apache Spark 的所有不同组件，包括硬件和软件。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi ok"><img src="../Images/5b1e2d03ed7ad81947b3cfbff998b45e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ZBN8OiyN0HmufJmv7xglPQ.jpeg"/></div></div><figcaption class="ld le gj gh gi lf lg bd b be z dk">The JBOD with HDFS architecture (left) and the off-node solution using a switching fabric (right)</figcaption></figure><p id="836d" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">我们了解到 ApacheSpark 是一个 Java 虚拟机(JVM)。为了加快我们的计算速度，我们可以并行使用多个工作节点，在如何分割工作负载方面，我们有两种选择:(1)在工作节点之间分割我们的数据和计算(JBOD 方法)或(2)在工作节点之间分割我们的计算，并使用“交换结构”从节点外的源提取数据。</p><p id="5140" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">选项(1)需要一个软件组件将物理上独立的存储磁盘视为一个磁盘，采用 JBOD(Just Bunch of Disks)方法(正式名称为<strong class="lk jd"> <em class="oj">跨越</em> </strong>)。该软件是“Hadoop 分布式文件系统”(HDFS)，它在工作节点的单个存储组件上创建一个虚拟视图，然后该视图可以被视为跨集群的单个虚拟文件。</p><p id="17c2" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">选项(2)更简单，但由于节点外数据存储和工作节点之间的传输速度，延迟程度较小。这是我们在整个课程中使用的设置。</p><h2 id="e7ec" class="nt nc it bd nd nu nv dn nh nw nx dp nl lr ny nz nn lv oa ob np lz oc od nr iz bi translated">RDDs，SQL API</h2><p id="d051" class="pw-post-body-paragraph li lj it lk b ll oe kd ln lo of kg lq lr og lt lu lv oh lx ly lz oi mb mc md im bi translated">从这里我们可以了解更多关于 Spark 的架构和 API。Spark 将数据存储在弹性分布式数据集中(RDD)。我们可以创建一个随机数据集，执行简单的计算并收集前 5 个结果，如下所示:</p><pre class="ks kt ku kv gt ol om on oo aw op bi"><span id="ecf3" class="nt nc it om b gy oq or l os ot">import random<br/>rdd = sc.parallelize(random(range(100), 100))<br/>rdd.map(lambda x: x + 1).take(5)</span></pre><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi ou"><img src="../Images/25403501aae04f08c185bc35d7d1450e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Fmy0P_ERjC47R9SxQwEmGQ.jpeg"/></div></div></figure><p id="4ceb" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">或者，Spark 通过 ApacheSparkSQL 提供 SQL 支持。这将 RDD 封装在数据帧中，允许关系查询。然后使用 ApacheSparkSQL 进行交互。使用此设置查询 dataframe 产品中产品总体的产品大小的标准偏差的示例:</p><pre class="ks kt ku kv gt ol om on oo aw op bi"><span id="dbc2" class="nt nc it om b gy oq or l os ot">spark.sql(<br/>  "SELECT STDDEV_POP(p_size) AS sdsize FROM products"<br/>).first().p_size</span></pre><p id="32ad" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">即使在使用 SQL 查询时，我们仍然可以直接与 RDD 交互，例如，如果我们想从一列中提取所有数据:</p><pre class="ks kt ku kv gt ol om on oo aw op bi"><span id="4e92" class="nt nc it om b gy oq or l os ot">data = spark.sql(<br/>   "SELECT p_size FROM products WHERE p_size &gt; 0.5"<br/>)<br/>data.rdd.map(lambda x: x.p_size).collect()</span></pre><h2 id="1c0c" class="nt nc it bd nd nu nv dn nh nw nx dp nl lr ny nz nn lv oa ob np lz oc od nr iz bi translated">第 3 周—统计</h2><p id="e86f" class="pw-post-body-paragraph li lj it lk b ll oe kd ln lo of kg lq lr og lt lu lv oh lx ly lz oi mb mc md im bi translated">这个星期很简单，但仍然很有用。我们着眼于四个统计矩以及协方差、协方差矩阵和相关性。最后我们引入多维向量空间。</p><p id="9c42" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">在本周的第一部分，我们来看四个统计时刻:</p><ul class=""><li id="39b9" class="mn mo it lk b ll lm lo lp lr mp lv mq lz mr md ms mt mu mv bi translated">平均值(或集中趋势的量度)(如平均数和中位数)</li><li id="a0de" class="mn mo it lk b ll mw lo mx lr my lv mz lz na md ms mt mu mv bi translated">标准偏差(和方差)</li><li id="9163" class="mn mo it lk b ll mw lo mx lr my lv mz lz na md ms mt mu mv bi translated">歪斜</li><li id="bb42" class="mn mo it lk b ll mw lo mx lr my lv mz lz na md ms mt mu mv bi translated">峭度</li></ul><p id="9189" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">如果你有统计学背景，这些概念你大概知道。令人尴尬的是，我不知道峰度实际上被称为“峰度”，但尽管如此，它们都是非常容易理解和应用的概念。</p><p id="e6a9" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">接下来我们引入协方差和相关性，我认为它们更有趣。我们使用这些属性来帮助我们理解不同列之间的关系。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi ov"><img src="../Images/59a5fd6d513734486e23d84797d739a9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*1_1o7PijBSnQZlVKZeJYqQ.jpeg"/></div></div><figcaption class="ld le gj gh gi lf lg bd b be z dk">Covariance of two variables with different relationships</figcaption></figure><p id="d193" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">相关性只是依赖性的一种度量，如果两个维度之间有很强的正相关关系，我们会发现相关值接近+1，如果有很强的负相关关系，我们会发现-1。对于两个完全独立的维度，我们会发现相关值为零。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi ow"><img src="../Images/fd23a2f64c9650f11b343f58c63691df.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*K662_4a05Qd2l1wJOW2dAA.jpeg"/></div></div><figcaption class="ld le gj gh gi lf lg bd b be z dk">Correlation between two dimensions X and Y</figcaption></figure><p id="78c1" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">为了计算相关性，我们需要计算维度 X、Y(见下文)的协方差超过两个维度的标准偏差。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi ox"><img src="../Images/c8d7dd6d8dd4b17edb767926288ca15a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*GKSQJ1bgiW1TtyOK7Z5HWw.jpeg"/></div></div><figcaption class="ld le gj gh gi lf lg bd b be z dk">Covariance between two dimensions X and Y</figcaption></figure><p id="5c6d" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">我认为非常有用的东西是相关或协方差矩阵，因为我以前遇到过几次。它们的功能相同，但一个测量相关性，另一个测量协方差。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi oy"><img src="../Images/c431ce41eced0b9ffd384004611414a2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Kjj1uZuZTCgpg-HOxxhm0w.jpeg"/></div></div><figcaption class="ld le gj gh gi lf lg bd b be z dk">Correlation matrix for dataset with four dimensions</figcaption></figure><p id="3fe0" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">在上面的<strong class="lk jd">相关性</strong>矩阵中，我们可以看到，第四维与其他任何维度都没有相关性。我们可以这样理解，第四维要么包含大量有用的信息，要么完全不相关。要在 Spark 中构建相关矩阵，我们可以使用 MLLib 库。</p><pre class="ks kt ku kv gt ol om on oo aw op bi"><span id="ccc0" class="nt nc it om b gy oq or l os ot"># data is a (number of samples (n), number of dimensions) array<br/># where we have 4 dimensions, data.shape = (n, 4)</span><span id="8cc9" class="nt nc it om b gy oz or l os ot">from pyspark.mllib.stat import Statistics  # import MLlib<br/>Statistics.corr(data)  # get correlation matrix for data</span><span id="1987" class="nt nc it om b gy oz or l os ot">Out []: array(([ 1.  ,  0.98, -0.97, -0.12],<br/>               [ 0.98,  1.  , -0.97, -0.12],<br/>               [-0.97, -0.97,  1.  ,  0.12],<br/>               [-0.12, -0.12,  0.12,  1.  ]))</span></pre><p id="40a0" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">一旦我们完成了 Spark 视频中的基本统计，我们就有了多维向量空间的最后一部分，这是非常小和直接的。接下来是本周的第二次也是最后一次测验和编程作业。编程任务简单而有趣，将上面学到的统计方法应用到 Spark 中。</p><h2 id="f0ed" class="nt nc it bd nd nu nv dn nh nw nx dp nl lr ny nz nn lv oa ob np lz oc od nr iz bi translated">第 4 周—可视化和 PCA</h2><p id="f40d" class="pw-post-body-paragraph li lj it lk b ll oe kd ln lo of kg lq lr og lt lu lv oh lx ly lz oi mb mc md im bi translated">最后一周从快速浏览 matplotlib 绘图开始。Matplotlib 没有内置到 Spark 中，所以我们从 RDD 中提取数据，然后像往常一样将其输入 matplotlib。如果你已经使用 Python 了，这部分会超级简单。</p><p id="d428" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">接下来是<strong class="lk jd">降维</strong>。在这里，我们看一下如何使用主成分分析(PCA)算法来减少数据集中的维数(我将用非常简单的术语快速解释 PCA)。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi pa"><img src="../Images/ccc5a4bb1f3fb0ee5387b1449517dd0f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*nIn98BcBXI-Ri88wgBYTTw.jpeg"/></div></div></figure><p id="41d5" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">我们了解到 PCA 用于降低数据集的维度，同时<strong class="lk jd">保留维度之间的关系</strong>。以上面的图为例，我们有一个三维向量空间(R^n ),我们想把它放入一个二维向量空间(R^k).我们希望找到一个表面，可以将 3D 数据映射到该表面上，同时最小化移动的距离。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi pb"><img src="../Images/3669174948909d39ae4ea19199704b11.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*jP9uy26o1L7HWyrJiUb43w.jpeg"/></div></div></figure><p id="22b0" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">一旦我们找到一个最小化距离变化的平面，我们就将 3D 点投影到新的 2D 平面上，从而降低维度。这实质上是找到变化不大的方向，并将其去除。在现实中，我们会经常处理高维向量空间，但简化概念是相同的。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi pc"><img src="../Images/fd2c6df9edaa1dec400a7a667f1303f3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*lyX-xbBvMA_YfjZW6HY6kQ.jpeg"/></div></div></figure><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi pd"><img src="../Images/f96d2130f68e7a8695f627757aa9f828.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*w2OuT5xkPxpn3yntapegrA.jpeg"/></div></div></figure><p id="0330" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">在课程中，Romeo(讲师)指出，PCA 保持的关键属性之一是点与点之间的距离比，其符号如上。我认为这是一个有趣的观点，除了上面的解释，我认为肯定有助于提高我对 PCA 实际上在做什么的理解。</p><p id="9677" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">在 PCA 视频之后，我们有一个快速测验和一个最终的编程任务。两者都很简单，我发现这个编程作业是最简单的，因为之前作业中的大部分困难都源于缺乏 Spark 经验，但此时我感觉舒服多了。</p><h1 id="becf" class="nb nc it bd nd ne nf ng nh ni nj nk nl ki nm kj nn kl no km np ko nq kp nr ns bi translated">最后的想法</h1><p id="e76e" class="pw-post-body-paragraph li lj it lk b ll oe kd ln lo of kg lq lr og lt lu lv oh lx ly lz oi mb mc md im bi translated">好了，这就是 IBMs 高级数据科学专业化的第一部分！老实说，我认为课程非常简单，但同时也很好地介绍了 Apache Spark。</p><p id="a5cd" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">在这一点上，我唯一的<em class="oj">小抱怨是编程任务可能太抽象了，我希望自己设置 RDDs 和 ApacheSparkSQL 对象，但是我认为这样做是为了保持专门化的介绍部分简单。</em></p><p id="02d0" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">教练罗密欧非常好，我相信他非常有才华，他似乎有很强的解释一切的能力。内容是直接的，并且有很强的理论背景来加深对正在使用的工具的理解。</p><p id="ab00" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">我在两周内完成了课程，同时工作也非常忙。所以它非常简短，但是我认为它很好地介绍了 Apache Spark。</p><p id="0ddb" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">总的来说，我对我学到的东西非常满意，我会向所有对数据科学云计算基础感兴趣的人强烈推荐这门课程。让我知道你的想法！</p><p id="6f56" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated"><em class="oj">如果你有兴趣了解斯坦福大学的机器学习 MOOC，请看这里:</em></p><div class="pe pf gp gr pg ph"><a rel="noopener follow" target="_blank" href="/a-review-of-stanfords-machine-learning-certification-9614ebee2b06"><div class="pi ab fo"><div class="pj ab pk cl cj pl"><h2 class="bd jd gy z fp pm fr fs pn fu fw jc bi translated">斯坦福大学机器学习认证述评</h2><div class="po l"><h3 class="bd b gy z fp pm fr fs pn fu fw dk translated">在快速变化的数据科学环境中，这仍然值得吗？</h3></div><div class="pp l"><p class="bd b dl z fp pm fr fs pn fu fw dk translated">towardsdatascience.com</p></div></div><div class="pq l"><div class="pr l ps pt pu pq pv lb ph"/></div></div></a></div><p id="748f" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">谢谢，</p></div></div>    
</body>
</html>