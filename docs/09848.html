<html>
<head>
<title>Food for Thought — Paper Tuesday</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">思考的食粮——纸星期二</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/food-for-thought-paper-tuesday-bffb85506bfd?source=collection_archive---------11-----------------------#2019-12-25">https://towardsdatascience.com/food-for-thought-paper-tuesday-bffb85506bfd?source=collection_archive---------11-----------------------#2019-12-25</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="f0bb" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">用于快速在线更新的新矩阵分解</h2></div><p id="d7e3" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">每周二，我都会强调我在研究或工作中遇到的一篇有趣的论文。希望我的评论能帮助你在 2 分钟内获得论文中最多汁的部分！</p><h1 id="c87f" class="lb lc iq bd ld le lf lg lh li lj lk ll jw lm jx ln jz lo ka lp kc lq kd lr ls bi translated">基本思想</h1><p id="a652" class="pw-post-body-paragraph kf kg iq kh b ki lt jr kk kl lu ju kn ko lv kq kr ks lw ku kv kw lx ky kz la ij bi translated">无数的项目已经证明，自 2006 年 Netflix 奖竞赛以来，矩阵分解(MF)是无与伦比的最强大的推荐生成算法之一。关键思想是将用户-项目交互矩阵分解成两个具有较低等级的子矩阵。</p><figure class="lz ma mb mc gt md gh gi paragraph-image"><div role="button" tabindex="0" class="me mf di mg bf mh"><div class="gh gi ly"><img src="../Images/a463f5a25bf264d4c728cd72e0ea632a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*RrGHfz_87DUSLOsXBQOD0A.png"/></div></div><figcaption class="mk ml gj gh gi mm mn bd b be z dk">From <a class="ae mo" href="https://aws.amazon.com/blogs/machine-learning/build-a-movie-recommender-with-factorization-machines-on-amazon-sagemaker/" rel="noopener ugc nofollow" target="_blank">amazon aws</a></figcaption></figure><p id="0869" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">通过分解交互矩阵，MF 以某种方式提取出潜在的特征，这些特征在描述用户和物品方面表现惊人的好。如果您想了解算法本身的更多信息，可以参考以下资源列表:</p><ol class=""><li id="71c3" class="mp mq iq kh b ki kj kl km ko mr ks ms kw mt la mu mv mw mx bi translated">https://data jobs . com/data-science-repo/Recommender-Systems-[网飞]。pdf </li><li id="9053" class="mp mq iq kh b ki my kl mz ko na ks nb kw nc la mu mv mw mx bi translated"><a class="ae mo" href="https://www.cs.cmu.edu/~mgormley/courses/10601-s17/slides/lecture25-mf.pdf" rel="noopener ugc nofollow" target="_blank">https://www . cs . CMU . edu/~ mgormley/courses/10601-s17/slides/lecture 25-MF . pdf</a></li><li id="d5ff" class="mp mq iq kh b ki my kl mz ko na ks nb kw nc la mu mv mw mx bi translated"><a class="ae mo" href="https://developers.google.com/machine-learning/recommendation" rel="noopener ugc nofollow" target="_blank">https://developers . Google . com/machine-learning/推荐</a></li></ol><p id="0f77" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">传统 MF 在实践中的一个问题是，当矩阵变得巨大时(想象亚马逊必须分解其用户-商品交互矩阵，这将是一个数百万乘数百万的矩阵)，定期更新潜在特征变得不可行(当用户进行新的购买时，我们希望该交易稍微影响潜在向量)。我看到了贺湘南、张汉旺、Kan Min-Yen 和 Tat-Seng Chua 的一篇论文，名为<em class="nd">用于隐式反馈在线推荐的快速矩阵分解。他们提出了一种叫做 eALS 的新方法，这种方法大大加快了在线更新过程。</em></p><p id="21a8" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">下面是链接:<a class="ae mo" href="https://arxiv.org/abs/1708.05024" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/abs/1708.05024</a></p><p id="0ee7" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">作者提出了一种通过缓存重复使用的值来加速 ALS 的新方法，以及一种避免每次新更新到来时解决整个问题的新技巧。</p><figure class="lz ma mb mc gt md gh gi paragraph-image"><div role="button" tabindex="0" class="me mf di mg bf mh"><div class="gh gi ne"><img src="../Images/2025b31389edd06ea914856d0ce0b76c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*7bFMdjyNnGs9ltDMOLIMRg.png"/></div></div><figcaption class="mk ml gj gh gi mm mn bd b be z dk">from <a class="ae mo" href="https://arxiv.org/abs/1708.05024" rel="noopener ugc nofollow" target="_blank">He et al 2017</a></figcaption></figure><p id="e55f" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">为了使在线模型更有效地响应最新的输入，作者提出了一种权重策略。</p><figure class="lz ma mb mc gt md gh gi paragraph-image"><div role="button" tabindex="0" class="me mf di mg bf mh"><div class="gh gi nf"><img src="../Images/d1f4e7087399b852ee7d1ec5900184fe.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*bmTp6wOpGCK6fg8c4FlCng.png"/></div></div><figcaption class="mk ml gj gh gi mm mn bd b be z dk">from <a class="ae mo" href="https://arxiv.org/abs/1708.05024" rel="noopener ugc nofollow" target="_blank">He et al 2017</a></figcaption></figure><figure class="lz ma mb mc gt md gh gi paragraph-image"><div role="button" tabindex="0" class="me mf di mg bf mh"><div class="gh gi ng"><img src="../Images/c06ef36976579d30100c1f0bd411a7e0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*v8nOpFFuXYJ5PTArC1GwGA.png"/></div></div><figcaption class="mk ml gj gh gi mm mn bd b be z dk">from <a class="ae mo" href="https://arxiv.org/abs/1708.05024" rel="noopener ugc nofollow" target="_blank">He et al 2017</a></figcaption></figure><p id="b7e1" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">论文中另一个有趣的提议是他们所谓的面向项目的缺失数据加权，它可以将领域知识整合到算法中。例如，如果一个用户从来没有购买过一个流行的物品，那么这个物品应该比一个未被浏览的稀有物品更像是负面反馈。</p><figure class="lz ma mb mc gt md gh gi paragraph-image"><div role="button" tabindex="0" class="me mf di mg bf mh"><div class="gh gi nh"><img src="../Images/fb80a38396c5e7b7ee0d9018cc532449.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*MxOO4oDOPT9Z9UYyRSHKGw.png"/></div></div><figcaption class="mk ml gj gh gi mm mn bd b be z dk">from <a class="ae mo" href="https://arxiv.org/abs/1708.05024" rel="noopener ugc nofollow" target="_blank">He et al 2017</a></figcaption></figure><h1 id="be78" class="lb lc iq bd ld le lf lg lh li lj lk ll jw lm jx ln jz lo ka lp kc lq kd lr ls bi translated">结果</h1><p id="0eea" class="pw-post-body-paragraph kf kg iq kh b ki lt jr kk kl lu ju kn ko lv kq kr ks lw ku kv kw lx ky kz la ij bi translated">作者根据经验证明，置信度参数 c(见上图)确实在一定程度上提高了性能。</p><figure class="lz ma mb mc gt md gh gi paragraph-image"><div class="gh gi ni"><img src="../Images/674ce845e45727e4520613a24d9f5a2f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1388/format:webp/1*uKfnQo13yH1sGS05uXKrew.png"/></div><figcaption class="mk ml gj gh gi mm mn bd b be z dk">from <a class="ae mo" href="https://arxiv.org/abs/1708.05024" rel="noopener ugc nofollow" target="_blank">He et al 2017</a></figcaption></figure><p id="0560" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">新的相互作用参数 W 的影响(W 越高，意味着新的相互作用的权重越大)</p><figure class="lz ma mb mc gt md gh gi paragraph-image"><div role="button" tabindex="0" class="me mf di mg bf mh"><div class="gh gi nj"><img src="../Images/212490e0b22e956cace872e1dd4b1802.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*TJ9XAOXFX8cpyYTxeNjYQQ.png"/></div></div><figcaption class="mk ml gj gh gi mm mn bd b be z dk">from <a class="ae mo" href="https://arxiv.org/abs/1708.05024" rel="noopener ugc nofollow" target="_blank">He et al 2017</a></figcaption></figure><p id="06d3" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">最令我兴奋的结果是时间复杂度的显著改善。所提出的新方法比普通的交替最小二乘法快 100+倍，交替最小二乘法是一种众所周知的解决矩阵分解的方法(这是有意义的，因为 ALS 每次需要更新潜在向量时都需要解决整个问题，而 e ALS 仅在附加数据上工作，并且以更高的空间复杂度为代价)。</p><figure class="lz ma mb mc gt md gh gi paragraph-image"><div role="button" tabindex="0" class="me mf di mg bf mh"><div class="gh gi nk"><img src="../Images/e2dbf67956b5c122b759ae134c9ad1b3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*kz69Lwh2TV3FI3BiW_q-Kw.png"/></div></div></figure><h1 id="1db6" class="lb lc iq bd ld le lf lg lh li lj lk ll jw lm jx ln jz lo ka lp kc lq kd lr ls bi translated">一些想法</h1><p id="e2ff" class="pw-post-body-paragraph kf kg iq kh b ki lt jr kk kl lu ju kn ko lv kq kr ks lw ku kv kw lx ky kz la ij bi translated">我在暑期实习期间自己开发了一个推荐系统，在线更新让我很头疼。我很高兴这篇论文让我们离模型更近了一步，模型可以很容易地更新，并包含更多的领域知识。</p></div></div>    
</body>
</html>