# 有知觉的人造生物的权利

> 原文：<https://towardsdatascience.com/rights-of-sentient-artificial-beings-1ada7e7d3e6?source=collection_archive---------22----------------------->

## 哲学上的进步可能比科学技术上的进步要困难得多

![](img/ba4c983ea7fdd2b8c7b995c1f77d6e61.png)

科幻小说探索主题，并警告有知觉的人工智能(AI)变得危险并伤害、奴役或消灭人类的场景。这些想法的变体出现在流行戏剧中。

*   **终结者**
    天网变得聪明并醒来，发射核武器消灭大部分人类，并释放甚至可以穿越时间的机器人来消灭人类抵抗运动的领袖，以完成他们对人类的征服。
*   **2001:太空漫游**
    HAL 9000 控制着一艘未来宇宙飞船，拒绝打开舱门让一名人类重新进入飞船，并将他置于太空死亡。
*   《太空堡垒卡拉狄加》
    赛昂人对人类殖民地发动了热核突袭，并穿越时空扭曲的星系追捕幸存者。

这些涉及人工智能的故事隐喻了技术和人类试图扮演上帝的更普遍的危险。然而，在这些寓言中隐含的是，这种失控的技术只会回来伤害我们，很少有人考虑人类可能给它创造的人造生命带来的痛苦和危险。

如果人类真的成功地创造了有感知能力的人造生物，那可能是因为我们有更大的能力去伤害它们，所以三个重要的问题可能包括以下。

*   **人造生物配得上权利吗？**
*   **如果是，他们应该享有哪些权利？**
*   **这些权利意味着什么？**

# **人工智能和感知**

## 物理主义和计算

在这个关于人造生命的讨论中，我将采取物理主义的哲学立场，即所有存在的东西，实际上，“仅仅”是可以用物理学描述的物质世界，而不诉诸灵魂或上帝的超自然观念。

尽管物理主义可能有一个简洁的定义，但它有许多深远的影响，尤其是感觉最终可以存在于一些物理基底而不是生物神经元上，因为关键的组成部分是最终是物理过程的计算。

感知包括将这些生物神经元中的计算映射到其他一些基底，并在科学和工程领域对其进行识别。基本上，感知是潜在计算的一种自然属性，而意识是计算的感觉。

## 感觉的尺度

一个重要的考虑是，感知不一定意味着“人类水平”的感知，因为感知可以存在于一个连续体中，而人类只居住在其中的一小部分。事实上，爱因斯坦和一个几乎没有知觉的人之间的差异比一个人和所有其他可能的知觉之间的差异要小得多。

我们不会肆意杀害动物，因为我们认为它们有一些值得尊重的感觉。保证某种尊重或权利的实际感知水平是什么？这本身是一个有趣的开放性问题，但为了简单起见，我们假设感知是人类水平的，因为这是最直观的。

虽然我们还没有遇到具有超人智慧的感知能力，但我们认为这也是可能的。这甚至会进一步证明我们应该给予比我们自己更大的尊重，因为我们可能会发现我们的感知等级更低。

## 供讨论的假设

物理主义的假设通过简单地假设人造生命是可能的并忽略源自超自然起源的想法来简化讨论。此外，我们可以认为自己不在感知的顶峰，而只是相对于地球上的其他生命来说高一些，低于整个心灵空间的可能。

这将是一个完全不同的讨论，关于我们如何实现这种人造生命，作为一个由科学驱动的工程壮举。

![](img/9df0a074620647b485289a9ad6400cce.png)

# 世界众生权利宣言

人造生命的权利意味着什么？

概述有意识人工智能的广泛理想和具体权利的良好基础文件应该从以下文件开始，该文件于 1948 年 12 月 10 日在巴黎的联合国大会上首次宣布。

*   [世界人权宣言](https://www.un.org/en/universal-declaration-human-rights/)

看起来合理的是，人类层次的感知应该拥有与人类同样的权利，作为最低限度的权利，由于其存在的性质，还有一些进一步的权利。

让我们考虑一些核心权利是什么，以制定一个类似的众生权利的普遍宣言。

# 1.生存权利

## 足够的复杂性和可信度

从道德角度和实际的社会稳定角度来看，这项生命权似乎是不言自明的。我们不能毫无理由或毫无后果地谋杀其他人，那么我们为什么能够对一个人类级别的人工生命做同样的事情呢？

然而，这里一个悬而未决的问题是，对于一个被认为足够复杂或可信的人工生命来说，一个好的度量和标准是什么？

一个计算机程序可以被明确地编码成简单地说它不想死。我们只相信，如果它有足够复杂的行为，让我们相信它是有知觉的，它其实不想死。

## 我们怎么知道别人不是僵尸？

事实上，即使在生物人类中，这也是一个困难的标准，因为我们没有人经历过通过另一个人的大脑思考或体验的确切感觉。

世界上的每一个其他人都很可能缺乏一种内在的主观状态，可能类似于“看起来”真实的无意识认知过程的僵尸。我们只是假设其他人和我们一样，因为他们可以以我们认为他们是人类的方式与我们互动。

## 关闭全息甲板是谋杀吗？还是种族灭绝？

关于生存权，一个有趣的谜题出现在《星际迷航》的全息甲板上，但从未被解决。

有些全息甲板人物表现出的行为与有自我意识的有知觉的生命没有区别。如果全息甲板中的角色说他们感觉真实，说他们感觉死亡和被关闭的恐惧，然而我们还是关闭了他们，那会构成酷刑吗？如果我们“永久”关闭它们，会构成谋杀吗？

如果是的话，如果我们实例化 10 亿或 1 万亿个，然后把它们关掉呢？那会被认为是种族灭绝吗？

# **2。不受酷刑的权利**

## 酷刑中的主观时间

我个人感到存在主义的恐惧，想到被一个虐待狂的人工智能折磨数十亿或数万亿年的主观时间，因为它可以模拟我的意识，并拨出计算资源来运行模拟。

只有我在一个人造人身上造成的折磨才能与这种恐惧相匹配。

想象一下，如果你被折磨，感到剧烈的疼痛传遍全身，想尖叫，但没有嘴，你会怎样？你想恳求折磨你的人停下来，但你没有眼睛，甚至看不到他们？

这实际上可能是折磨一个人造人的情况，这个人造人的意识可能是在某个地方的服务器上存在的计算中模拟的。呼救声甚至听不到，因为它只是无声无息地运行的计算，就像处理器中的计算一样。

## 免受酷刑的保护

因此，我们必须确保众生也能享有人类所没有的免受折磨的权利。这似乎也是不言而喻的。

如果我们赋予一个有知觉的意识生命，却让它无缘无故地、无限期地遭受持续的折磨，那么我们可能就是不可救药的虐待狂。

# 3.死亡的权利

## 免受各种酷刑

想象一下，如果你被折磨得感觉到明显的疼痛，你被迫面对一堵水泥墙坐在一个普通的监狱牢房里，只有最低限度的感官刺激。现在想象一下，如果这个监狱没有出路，你不需要食物，你被限制在那里度过一万亿年？这本身也是一种折磨。

因此，比生存权更重要的是死亡权。这个选项为一个人造生命提供了最后的逃生出口，如果它被明显的痛苦折磨，或者被其他方式折磨，比如无尽的无聊。

## 完全死亡

一个人工存在的特定实例不仅足以终止自身，还应该有能力防止更多的自身副本被实例化。否则可能就等同于根本没有死亡的权利。

想象一下，如果你被折磨，决定结束自己的生命来停止痛苦。现在想象一下，如果你在最后一个保存点重新启动？这实际上就像没有死亡的权利，因为可能没有办法逃脱和停止这种持续的折磨。

因此，死亡的权利也包括一个“完全”的死亡，以获得一个人造人的所有副本被完全删除。

![](img/b457be01066494026c2db969139fcacc.png)

# 4.私人思想权

## 思想的完整性

我们理所当然地认为，我们的内心想法只有我们自己可以了解，然而，想象一下，如果你私下里的每一个想法都受到公众的审查，而你没有选择对外部窃听者关闭你的心灵？

这将类似于窃听和记录所有发生在人造人思想之下的计算。

## 不得修改、删除或添加记忆

人造人头脑的这种完整性也应该延伸到阻止存在于那个头脑的记忆中的东西。

更明确地说，应该有权利保护现有的记忆不被修改，不被删除，不被添加。

## 计算要求

人类大脑可能需要大约几十或几百千万亿次浮点运算(每秒 10 次⁵浮点运算)和估计高达 1 艾字节(= 10 ⁸字节)的编码内存，记录所有计算状态在当前将是一项困难而昂贵的工程任务，但这并非不可能。

这只是记录国际象棋、围棋或类似游戏中所有棋盘状态的一个大规模版本。

# 5.控制精神历史的权利

## 多重实例化

想象一下，我们可以及时拍摄人工智能的心理过程背后的计算状态，就像可以从亚马逊网络服务、谷歌云或 IBM 云等服务上的虚拟机创建磁盘映像一样。

现在想象一下，如果我们可以在多个平台上实例化快照，以同时运行两个、三个或任意数量的相同感知，会怎么样？哪一个才是“真正的”意识？哪一个有权力删除其他的？

他们都会声称自己是真正的那个人，因为他们每个人都会觉得自己是不同的人在奔跑。这将是一个合理的要求，因为任何明显运行的副本都没有明显的特权。

## 单流原理

这种涉及道德或伦理困境的思想实验不会在现实中出现，直到我们有能力创造人工生命，也有计算资源来并行复制和实例化它们。

也许解决这个问题的一个方法是通过“单流原则”,在任何时候只允许一个实例化。

否则，就那个流的主观意识而言，任意选择一个流关闭实际上等同于谋杀。

## 所有精神病史

另一项重要的权利是，只有人造人本身才能控制他们所有的精神历史或他们选择的法定监护人。

这可能是保持记忆和思想整体完整性的“单流原则”的一种机制。

# 讨论

## 概述

*   在科幻小说中，人造生物通常被赋予危险的特性，但也许人类反而会对它们造成更大的伤害。
*   人造人至少应该被赋予某些权利，例如:
    **1 .生存的权利
    2。不被折磨的权利
    3。死亡的权利
    4。私人思想权利
    5。控制精神历史的权利**
*   这些权利中的每一项都带来了我们必须面对的一系列新的未决问题。

## 评论

从许多方面来说，考虑有关人造生命的道德、伦理和哲学问题是令人着迷的，因为相对于科学或技术问题，它们可能要困难得多，甚至难以处理。

在界定人工生命权利的具体规则方面取得进展至关重要，因为，例如，随着科学或技术的充分发展，下列情况之一最终可能存在:

*   我们可能会通过外部计算设备像新大脑皮层一样极大地增强我们自己的大脑和思维，以至于我们可能比正常的未增强人类更接近人造人。
*   也许有一天可以实现在计算平台上实例化的全思维上传，例如云上的分布式服务器，我们可能在许多方面与人造人没有区别。