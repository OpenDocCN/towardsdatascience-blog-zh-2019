<html>
<head>
<title>Sentiment analysis of the lead Characters on F.R.I.E.N.D.S</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">《神盾局》主角的情感分析</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/sentiment-analysis-of-the-lead-characters-on-f-r-i-e-n-d-s-51aa5abf1fa6?source=collection_archive---------29-----------------------#2019-08-12">https://towardsdatascience.com/sentiment-analysis-of-the-lead-characters-on-f-r-i-e-n-d-s-51aa5abf1fa6?source=collection_archive---------29-----------------------#2019-08-12</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><figure class="gl gn jr js jt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi jq"><img src="../Images/0d92d106ab659b0f4798c3f913ac91a3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ollNeMqPvOemB9oXObkHBg.jpeg"/></div></div><figcaption class="kb kc gj gh gi kd ke bd b be z dk">Central Perk — Where this beautiful journey began.</figcaption></figure><p id="1ab0" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">我是这部美国情景喜剧的最大爱好者之一——自从我开始看这部剧以来就是朋友。最近，我开始在网上寻找这个节目的文字记录(<a class="ae ld" href="https://fangj.github.io/friends/" rel="noopener ugc nofollow" target="_blank">https://fangj.github.io/friends/</a>)。我在这些抄本上找不到太多的数据科学，除了每个角色对话数量的简单统计，他们说出的名字的数量和类似的统计。我想如果我能为像我一样的观众做更多的事情，从数据科学的角度更广泛地了解这部剧，那将会很有趣。</p><p id="637b" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">作为第一步，我整理了 plain 可以获得的所有 html 脚本(全部 10 季)。csv 文件(也可以复制成文本，不会造成差异)。皈依者。所有赛季的 csv 文件都可以从我的 github 链接获取——(<a class="ae ld" href="https://github.com/shilpibhattacharyya/Friends_Analysis/tree/master/transcripts_friends" rel="noopener ugc nofollow" target="_blank">https://github . com/shilpibattacharyya/Friends _ Analysis/tree/master/transcripts _ Friends</a>)。然后，我使用下面的命令将它们合并在一起。</p><pre class="le lf lg lh gt li lj lk ll aw lm bi"><span id="a0b9" class="ln lo it lj b gy lp lq l lr ls">## Command to append multiple files in a directory - 1* represent all files for season1 and so on ...#</span><span id="549b" class="ln lo it lj b gy lt lq l lr ls">sed 1d 1*.csv 2*.csv 3*.csv 4*.csv 5*.csv 6*.csv 7*.csv 8*.csv 9*.csv 100*.csv&gt; merged.csv *</span></pre><p id="ec4c" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">然后使用下面的实用程序将每个角色(瑞秋、罗斯、乔伊、菲比、钱德勒、莫妮卡)的对白分开:</p><pre class="le lf lg lh gt li lj lk ll aw lm bi"><span id="5c3c" class="ln lo it lj b gy lp lq l lr ls">def rem_tabs_newline(str_val):<br/>    str_val = str_val.strip('\\n')<br/>    str_val = str_val.strip('\\t')<br/>    str_val = str_val.replace('\\n','')<br/>    str_val = str_val.replace('\\t','')<br/>    return str_val</span><span id="ae60" class="ln lo it lj b gy lt lq l lr ls">friends_chars={} <br/>Rachel=''<br/>Ross=''<br/>Joey=''<br/>Chandler=''<br/>Phoebe=''<br/>Monica=''<br/>with open("transcripts_friends/season_all/merged.csv", "r+") as fp:<br/>    for cnt, line in enumerate(fp):<br/>        if line.startswith('Rachel:'):<br/>            Rachel=Rachel+' '+(line[8:])<br/>        elif line.startswith('Ross:'):<br/>            Ross=Ross+' '+(line[6:])<br/>        elif line.startswith('Monica:'):<br/>            Monica=Monica+' '+(line[8:])<br/>        elif line.startswith('Chandler:'):<br/>            Chandler=Chandler+' '+(line[10:])<br/>        if line.startswith('Phoebe:'):<br/>            Phoebe=Phoebe+' '+(line[8:])<br/>        if line.startswith('Joey:'):<br/>            Joey=Joey+' '+(line[6:])</span><span id="50b1" class="ln lo it lj b gy lt lq l lr ls">friends_chars['RACHEL']=rem_tabs_newline(Rachel)<br/>friends_chars['ROSS']=rem_tabs_newline(Ross)<br/>friends_chars['MONICA']=rem_tabs_newline(Monica)<br/>friends_chars['PHOEBE']=rem_tabs_newline(Phoebe)<br/>friends_chars['CHANDLER']=rem_tabs_newline(Chandler)<br/>friends_chars['JOEY']=rem_tabs_newline(Joey)</span></pre><p id="bb9b" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">下面的代码使用 nltk 库清除数据，删除停用词、制表符和换行符。</p><pre class="le lf lg lh gt li lj lk ll aw lm bi"><span id="4456" class="ln lo it lj b gy lp lq l lr ls">from nltk.corpus import stopwords <br/>from nltk.tokenize import word_tokenize <br/>from nltk.tokenize import sent_tokenize</span><span id="2f25" class="ln lo it lj b gy lt lq l lr ls">stop_words = set(stopwords.words('english'))</span><span id="6050" class="ln lo it lj b gy lt lq l lr ls">def clean_data(val):<br/>    val = val.strip('\\n')<br/>    val = val.strip('\\t')<br/>    val = val.replace('\\n','')<br/>    val = val.replace('\\t','')<br/>    word_tokens = word_tokenize(str(val).lower().strip('[]') )<br/>    filtered_sentence = [w for w in word_tokens if not w in stop_words]</span><span id="8aeb" class="ln lo it lj b gy lt lq l lr ls">filtered_sentence = []</span><span id="d0f6" class="ln lo it lj b gy lt lq l lr ls">for w in word_tokens: <br/>        if w not in stop_words: <br/>            filtered_sentence.append(w)<br/>    return list(filtered_sentence)</span></pre><p id="ef2f" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">一旦我清理了数据并收集了单词，我就为每个字符创建一个集合语料库列表，如下所示。</p><pre class="le lf lg lh gt li lj lk ll aw lm bi"><span id="1f93" class="ln lo it lj b gy lp lq l lr ls">rachel_corpus=list(set(clean_data(str(friends_chars['RACHEL']).strip('[]'))))<br/>ross_corpus=list(set(clean_data(str(friends_chars['ROSS']).strip('[]'))))<br/>mon_corpus=list(set(clean_data(str(friends_chars['MONICA']).strip('[]'))))<br/>joe_corpus=list(set(clean_data(str(friends_chars['JOEY']).strip('[]'))))<br/>phoebs_corpus=list(set(clean_data(str(friends_chars['PHOEBE']).strip('[]'))))<br/>chandler_corpus=list(set(clean_data(str(friends_chars['CHANDLER']).strip('[]'))))</span></pre><p id="eec6" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">然后，只过滤掉长度大于 3 的单词，这样我就可以去掉常见的单词，如下所示。</p><pre class="le lf lg lh gt li lj lk ll aw lm bi"><span id="bd99" class="ln lo it lj b gy lp lq l lr ls">words_rach=[w for w in rachel_corpus if len(w)&gt;3]<br/>words_mon=[w for w in mon_corpus if len(w)&gt;3]<br/>words_ross=[w for w in ross_corpus if len(w)&gt;3] <br/>words_phoebs=[w for w in phoebs_corpus if len(w)&gt;3]<br/>words_joe=[w for w in joe_corpus if len(w)&gt;3]<br/>words_chandler=[w for w in chandler_corpus if len(w)&gt;3]</span></pre><p id="43ba" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">我将进一步使用 nltk lemmatizer 来查找所有单词的词干作为有效单词。请注意，我在避免使用 portstemmer，因为它也会产生一些无效单词。</p><pre class="le lf lg lh gt li lj lk ll aw lm bi"><span id="ede2" class="ln lo it lj b gy lp lq l lr ls">WNLemma=nltk.WordNetLemmatizer()<br/>stem_freq_words_rach=[WNLemma.lemmatize(t) for t in words_rach]<br/>stem_freq_words_ross=[WNLemma.lemmatize(t) for t in words_ross]<br/>stem_freq_words_chandler=[WNLemma.lemmatize(t) for t in words_chandler]<br/>stem_freq_words_mon=[WNLemma.lemmatize(t) for t in words_mon]<br/>stem_freq_words_phoebs=[WNLemma.lemmatize(t) for t in words_phoebs]<br/>stem_freq_words_joe=[WNLemma.lemmatize(t) for t in words_joe]</span></pre><p id="6668" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">接下来，我将添加所有单词，并为每个角色创建一个口语单词字符串，以提供给 IBM Watson NLU 服务进行情感分析。</p><pre class="le lf lg lh gt li lj lk ll aw lm bi"><span id="f450" class="ln lo it lj b gy lp lq l lr ls">s_rachel=""<br/>for w in stem_freq_words_rach:<br/>   s_rachel=s_rachel+' '+w</span><span id="cb49" class="ln lo it lj b gy lt lq l lr ls">s_ross=""<br/>for w in stem_freq_words_ross:<br/>   s_ross=s_ross+' '+w</span><span id="368a" class="ln lo it lj b gy lt lq l lr ls">s_phoebs=""<br/>for w in stem_freq_words_phoebs:<br/>   s_phoebs=s_phoebs+' '+w</span><span id="348e" class="ln lo it lj b gy lt lq l lr ls">s_joe=""<br/>for w in stem_freq_words_joe:<br/>   s_joe=s_joe+' '+w</span><span id="b890" class="ln lo it lj b gy lt lq l lr ls">s_chandler=""<br/>for w in stem_freq_words_chandler:<br/>   s_chandler=s_chandler+' '+w</span><span id="5708" class="ln lo it lj b gy lt lq l lr ls">s_mon=""<br/>for w in stem_freq_words_mon:<br/>   s_mon=s_mon+' '+w</span></pre><p id="3596" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">然后，我会调用沃森 NLU 服务，并传递每个角色的口语单词进行情感分析，如下所示。</p><pre class="le lf lg lh gt li lj lk ll aw lm bi"><span id="ce53" class="ln lo it lj b gy lp lq l lr ls">import json<br/>from ibm_watson import NaturalLanguageUnderstandingV1<br/>from ibm_watson.natural_language_understanding_v1 import Features, EmotionOptions<br/>import pandas as pd<br/>import matplotlib.pyplot as plt</span><span id="b039" class="ln lo it lj b gy lt lq l lr ls">dicti={}<br/>natural_language_understanding = NaturalLanguageUnderstandingV1(<br/>        version='2019-07-12',<br/>        iam_apikey='please put your api key here',<br/>        url='<a class="ae ld" href="https://gateway.watsonplatform.net/natural-language-understanding/api'" rel="noopener ugc nofollow" target="_blank">https://gateway.watsonplatform.net/natural-language-understanding/api'</a>)</span><span id="dd82" class="ln lo it lj b gy lt lq l lr ls">#rachel</span><span id="a399" class="ln lo it lj b gy lt lq l lr ls">response = natural_language_understanding.analyze(<br/>    text=s_rachel,<br/>    features=Features(emotion=EmotionOptions())).get_result()<br/>print("Rachel")<br/>print("======================================")<br/>dicti["Rachel"]=response["emotion"]["document"]["emotion"]<br/>print(json.dumps(response["emotion"]["document"]["emotion"], indent=2))</span><span id="7d7b" class="ln lo it lj b gy lt lq l lr ls">#ross<br/>response = natural_language_understanding.analyze(<br/>    text=s_ross,<br/>    features=Features(emotion=EmotionOptions())).get_result()<br/>dicti["Ross"]=response["emotion"]["document"]["emotion"]<br/></span><span id="ea9b" class="ln lo it lj b gy lt lq l lr ls">#monica<br/>response = natural_language_understanding.analyze(<br/>    text=s_mon,<br/>    features=Features(emotion=EmotionOptions())).get_result()<br/>dicti["Monica"]=response["emotion"]["document"]["emotion"]<br/></span><span id="5839" class="ln lo it lj b gy lt lq l lr ls">#phoebe<br/>response = natural_language_understanding.analyze(<br/>    text=s_phoebs,<br/>    features=Features(emotion=EmotionOptions())).get_result()<br/>dicti["Phoebe"]=response["emotion"]["document"]["emotion"]<br/></span><span id="b95d" class="ln lo it lj b gy lt lq l lr ls">#chandler<br/>response = natural_language_understanding.analyze(<br/>    text=s_chandler,<br/>    features=Features(emotion=EmotionOptions())).get_result()<br/>dicti["Chandler"]=response["emotion"]["document"]["emotion"]<br/></span><span id="0a76" class="ln lo it lj b gy lt lq l lr ls">#joey<br/>response = natural_language_understanding.analyze(<br/>    text=s_joe,<br/>    features=Features(emotion=EmotionOptions())).get_result()<br/>dicti["Joey"]=response["emotion"]["document"]["emotion"]</span><span id="8bf4" class="ln lo it lj b gy lt lq l lr ls">print(json.dumps(dicti, indent=2))</span></pre><p id="cc00" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">我将输出转换成 dataframe 并打印如下。</p><pre class="le lf lg lh gt li lj lk ll aw lm bi"><span id="121e" class="ln lo it lj b gy lp lq l lr ls">df = pd.DataFrame(dicti)<br/>df</span></pre><figure class="le lf lg lh gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi lu"><img src="../Images/2871a97796cacd8546a0dc1c31edbaaa.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*R-qL_ncba-hoI4JsLXoNog.png"/></div></div><figcaption class="kb kc gj gh gi kd ke bd b be z dk">Sentiment density distribution for each of the Characters</figcaption></figure><p id="2f47" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">为了更好的形象化，我绘制了如下图。</p><pre class="le lf lg lh gt li lj lk ll aw lm bi"><span id="0622" class="ln lo it lj b gy lp lq l lr ls">df.transpose().plot(kind='bar')<br/>plt.show()</span></pre><figure class="le lf lg lh gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi lv"><img src="../Images/6b6bf184edcbf3565fde64d7595d4fa9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*g58gECsGMB66b4vlzKQ8Tw.png"/></div></div><figcaption class="kb kc gj gh gi kd ke bd b be z dk">Bar chart for sentiment density distribution for each of the Characters</figcaption></figure><p id="4454" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated"><strong class="kh iu">从上面的条形图推断</strong></p><p id="bc75" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">根据情感密度分布，节目中的所有角色都非常相似。这可能是他们相处融洽、形影不离的原因。这些角色充满了欢乐、悲伤和厌恶:)。</p><p id="78cd" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">然后，我可视化一个饼图，以便更好地理解这些角色，如下所示(代码可以为每个角色复制—这里只为 Rachel 提供)。</p><pre class="le lf lg lh gt li lj lk ll aw lm bi"><span id="facf" class="ln lo it lj b gy lp lq l lr ls">colors = ['b', 'g', 'r', 'c', 'm']<br/>labels = ['Anger', 'Disgust', 'Fear', 'Joy', 'Sadness']<br/>explode = (0.2, 0.2, 0.2, 0.2, 0.1)<br/>plt.pie(df.Rachel, colors=colors, labels=labels,<br/>explode=explode, autopct='%1.1f%%',<br/>counterclock=False, shadow=True)<br/>plt.title('Sentiment Density Index for Rachel')<br/>plt.show()</span></pre><div class="le lf lg lh gt ab cb"><figure class="lw ju lx ly lz ma mb paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><img src="../Images/6cb40b559997edb3facb7b42aead5e9f.png" data-original-src="https://miro.medium.com/v2/resize:fit:676/format:webp/1*zAOX0rMNE6FnZcJqbWEbuw.png"/></div></figure><figure class="lw ju mc ly lz ma mb paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><img src="../Images/9699eb509af5bf1e4edd338e4169d26b.png" data-original-src="https://miro.medium.com/v2/resize:fit:700/format:webp/1*K7Ee2ikbp7EHKArF2_1dcg.png"/></div></figure><figure class="lw ju md ly lz ma mb paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><img src="../Images/76039bd8c5a928e8381a9b90b09e85e9.png" data-original-src="https://miro.medium.com/v2/resize:fit:628/format:webp/1*iZ3U1f6d_r8AXEZmn8iuIw.png"/></div></figure></div><div class="ab cb"><figure class="lw ju me ly lz ma mb paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><img src="../Images/a0c3479123ec32d1df855a449982e78e.png" data-original-src="https://miro.medium.com/v2/resize:fit:660/format:webp/1*4h7Y6FQPVH2IwEOyklanww.png"/></div></figure><figure class="lw ju mf ly lz ma mb paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><img src="../Images/1b4bb172e08c3f4b7b3caaf458940fb4.png" data-original-src="https://miro.medium.com/v2/resize:fit:672/format:webp/1*aoQY4PJEsBA2c2p8oOmjiQ.png"/></div></figure><figure class="lw ju mg ly lz ma mb paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><img src="../Images/d759632d65215d7fbf8d9a927b2092ee.png" data-original-src="https://miro.medium.com/v2/resize:fit:672/format:webp/1*4_B6X-K4dre1FOpGzHBfFg.png"/></div></figure></div><p id="76a2" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated"><strong class="kh iu">从上面的饼状图推断</strong></p><p id="0d3c" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">最平衡的角色是钱德勒，其次是瑞秋和莫妮卡。菲比和乔伊彼此非常相似，罗斯、瑞秋和莫妮卡也是。</p><p id="a5b5" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">我还引入了一个新的变量“快乐商数”,来计算每个角色的快乐相对于其他情绪的比例。</p><p id="7dd9" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">我们可以用类似的方式来评估所有其他情感的这个商。</p><pre class="le lf lg lh gt li lj lk ll aw lm bi"><span id="8752" class="ln lo it lj b gy lp lq l lr ls">happy_quotient_Rach=df.Rachel.joy/df['Rachel'].sum()<br/>happy_quotient_Ross=df.Ross.joy/df['Ross'].sum()<br/>happy_quotient_Joey=df.Joey.joy/df['Joey'].sum()<br/>happy_quotient_Monica=df.Monica.joy/df['Monica'].sum()<br/>happy_quotient_Phoebe=df.Phoebe.joy/df['Phoebe'].sum()<br/>happy_quotient_Chandler=df.Chandler.joy/df['Chandler'].sum()</span></pre><p id="643a" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">让我们看一个散点图，找出最幸福的人物。</p><pre class="le lf lg lh gt li lj lk ll aw lm bi"><span id="2bb1" class="ln lo it lj b gy lp lq l lr ls">x = ['Rachel','Ross','Joey','Monica','Phoebe','Chandler']<br/>y = [happy_quotient_Rach,happy_quotient_Ross,happy_quotient_Joey,happy_quotient_Monica,happy_quotient_Phoebe,happy_quotient_Chandler]colors = np.where(df_hq.Happiness_Quotient &gt; 0.25, '#ff748c', '#497087')<br/>plt.scatter(x,y,s=120, c=colors)<br/>plt.show(</span></pre><p id="8016" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">情商的曲线图如下。</p><pre class="le lf lg lh gt li lj lk ll aw lm bi"><span id="97c3" class="ln lo it lj b gy lp lq l lr ls">x_happy = ['Rachel','Ross','Joey','Monica','Phoebe','Chandler']<br/>y_happy = [happy_quotient_Rach,happy_quotient_Ross,happy_quotient_Joey,happy_quotient_Monica,happy_quotient_Phoebe,happy_quotient_Chandler]<br/>colors = ['r','g','b','y','cyan','m']<br/>plt.scatter(x_happy,y_happy,s=120, c=colors)<br/>plt.title('Happiness Quotient for the Characters')<br/>plt.show()</span></pre><div class="le lf lg lh gt ab cb"><figure class="lw ju mh ly lz ma mb paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><img src="../Images/72227f8a1e3d97cd1c6a3b9491ea26bd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1014/format:webp/1*OeE28-oShC4PL9hz6li1VQ.png"/></div></figure><figure class="lw ju mi ly lz ma mb paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><img src="../Images/bd1fbb8ba3ca93db0ef88374dedeffe3.png" data-original-src="https://miro.medium.com/v2/resize:fit:988/format:webp/1*6EPq0Q_CMW9JLjOAPDnq4Q.png"/></div></figure></div><div class="ab cb"><figure class="lw ju mj ly lz ma mb paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><img src="../Images/970dcc40879d189867d161473f72872b.png" data-original-src="https://miro.medium.com/v2/resize:fit:674/format:webp/1*m3aFtk_OycbId6g5oAT3XQ.png"/></div></figure><figure class="lw ju mk ly lz ma mb paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><img src="../Images/7691312d4ca0a6d0978ee3a3c0ea4f62.png" data-original-src="https://miro.medium.com/v2/resize:fit:684/format:webp/1*rNpwLTrfVQ21bmZiDMWv8A.png"/></div></figure><figure class="lw ju ml ly lz ma mb paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><img src="../Images/307b3684ba610ab3917c97ea80ede59f.png" data-original-src="https://miro.medium.com/v2/resize:fit:644/format:webp/1*vRJN1JIaMNn8MkJeBFFXJw.png"/></div></figure></div><p id="3968" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated"><strong class="kh iu">从上面的散点图推断</strong></p><p id="b819" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">最幸福的<strong class="kh iu">角色依次是:罗斯、乔伊、菲比、瑞秋、钱德勒</strong></p><p id="596a" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">最悲伤的<strong class="kh iu">角色依次是:菲比、乔伊、罗斯、莫妮卡、瑞秋、钱德勒</strong></p><p id="0db2" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">最恶心的<strong class="kh iu">角色依次是:钱德勒、莫妮卡、罗斯、乔伊、菲比、瑞秋</strong></p><p id="b0fe" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">最害怕的角色依次是:瑞秋、莫妮卡、钱德勒、乔伊、菲比、罗斯</p><p id="6ccd" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">最愤怒的<strong class="kh iu">角色依次是:菲比、乔伊、罗斯、瑞秋、莫妮卡、钱德勒</strong></p><p id="f0ea" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated"><strong class="kh iu">备注</strong></p><p id="acec" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">这是一次尝试，通过网上的文字记录来了解角色的情感，看看我是否能把它与我在观看这部剧时对这些角色的感受联系起来。</p><p id="64b4" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">我会继续研究这个数据集，希望很快能有更多的见解。</p></div></div>    
</body>
</html>