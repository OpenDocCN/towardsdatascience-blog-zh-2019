<html>
<head>
<title>Probability Learning II: How Bayes’ Theorem is applied in Machine Learning</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">概率学习 II:贝叶斯定理如何应用于机器学习</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/probability-learning-ii-how-bayes-theorem-is-applied-in-machine-learning-bd747a960962?source=collection_archive---------5-----------------------#2019-08-14">https://towardsdatascience.com/probability-learning-ii-how-bayes-theorem-is-applied-in-machine-learning-bd747a960962?source=collection_archive---------5-----------------------#2019-08-14</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="15c3" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">了解贝叶斯定理是如何在机器学习中进行分类和回归的！</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/799e3f3f1db39fcf996982e4ef90485b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*g3Ht6gKYF_1pUSqXFUkBAA.jpeg"/></div></div></figure><p id="7978" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">在上一篇文章中，我们看到了<strong class="kw iu">什么是贝叶斯定理</strong>，并通过一个简单直观的例子展示了它是如何工作的。你可以在这里  <strong class="kw iu">找到这个帖子<a class="ae lq" rel="noopener" target="_blank" href="/probability-learning-i-bayes-theorem-708a4c02909a?source=friends_link&amp;sk=29a5c9c9301a1204f16460781eaba113">。如果你不知道贝叶斯定理是什么，并且你还没有阅读它的乐趣，我推荐你去读，因为它会让你更容易理解这篇文章。</a></strong></p><p id="634d" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">在本帖中，我们将看到这个定理在<em class="lr">机器学习中的<strong class="kw iu">用途。</strong></em>T11】</p><p id="de9f" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated"><em class="lr">在我们开始之前，这里有一些额外的资源可以让你的机器学习事业突飞猛进:</em></p><pre class="kj kk kl km gt ls lt lu lv aw lw bi"><span id="a899" class="lx ly it lt b gy lz ma l mb mc"><em class="lr">Awesome Machine Learning Resources:</em></span><span id="5cc1" class="lx ly it lt b gy md ma l mb mc"><em class="lr">- For </em><strong class="lt iu"><em class="lr">learning resources</em></strong><em class="lr"> go to </em><a class="ae lq" href="https://howtolearnmachinelearning.com/books/machine-learning-books/" rel="noopener ugc nofollow" target="_blank"><strong class="lt iu"><em class="lr">How to Learn Machine Learning</em></strong></a><em class="lr">! <br/>- For </em><strong class="lt iu"><em class="lr">professional</em></strong><em class="lr"> </em><strong class="lt iu"><em class="lr">resources</em></strong><em class="lr"> (jobs, events, skill tests) go to </em><a class="ae lq" href="https://aigents.co/" rel="noopener ugc nofollow" target="_blank"><strong class="lt iu"><em class="lr">AIgents.co — A career community for Data Scientists &amp; Machine Learning Engineers</em></strong></a><strong class="lt iu"><em class="lr">.</em></strong></span></pre><p id="2fd5" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated"><strong class="kw iu"> <em class="lr">准备好了吗？那我们走吧！</em> </strong></p><h1 id="5b03" class="me ly it bd mf mg mh mi mj mk ml mm mn jz mo ka mp kc mq kd mr kf ms kg mt mu bi translated">机器学习中的贝叶斯定理</h1><p id="8351" class="pw-post-body-paragraph ku kv it kw b kx mv ju kz la mw jx lc ld mx lf lg lh my lj lk ll mz ln lo lp im bi translated">正如上一篇文章中提到的，贝叶斯定理告诉我们，当我们获得更多关于某件事的证据时，如何逐渐更新我们对某件事的知识。</p><p id="0226" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">通常，在<strong class="kw iu">监督机器学习</strong>中，当我们想要训练一个模型时，<strong class="kw iu">主要构件</strong>是一组包含<strong class="kw iu">特征</strong>(定义这种数据点的属性)<strong class="kw iu">这种数据点的标签</strong>(我们稍后想要在新数据点上预测的数字或分类标签)，以及将这种特征与其相应标签相链接的<strong class="kw iu">假设函数</strong>或模型。我们还有一个<strong class="kw iu">损失函数</strong>，它是模型预测和真实标签之间的差异，我们希望减少该差异以实现最佳可能结果。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi na"><img src="../Images/d1ed8b90536c7bf75d78d11b155e37b1.png" data-original-src="https://miro.medium.com/v2/resize:fit:706/format:webp/1*27chiFtrt0GznmDuGAhqCg.png"/></div><figcaption class="nb nc gj gh gi nd ne bd b be z dk">Main elements of a supervised Learning Problem</figcaption></figure><p id="d366" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">这些受监督的机器学习问题可以分为<strong class="kw iu">两个主要类别:回归</strong>，其中我们希望计算与一些数据(例如房子的价格)相关联的一个数字或<strong class="kw iu">数字</strong> <strong class="kw iu">值</strong>，以及<strong class="kw iu">分类</strong>，其中我们希望将数据点分配给<strong class="kw iu">某个类别</strong>(例如，如果一幅图像显示一只狗或猫)。</p><p id="df2a" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated"><strong class="kw iu">贝叶斯定理既可以用于回归，也可以用于分类。</strong></p><p id="70ba" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">让我们看看如何！</p><h2 id="088c" class="lx ly it bd mf nf ng dn mj nh ni dp mn ld nj nk mp lh nl nm mr ll nn no mt np bi translated"><strong class="ak">回归中的贝叶斯定理</strong></h2><p id="28dd" class="pw-post-body-paragraph ku kv it kw b kx mv ju kz la mw jx lc ld mx lf lg lh my lj lk ll mz ln lo lp im bi translated">假设我们有一组非常简单的<strong class="kw iu">数据</strong>，它代表一个城镇的某个地区一年中每天的<strong class="kw iu">温度(数据点的<strong class="kw iu">特征</strong>，以及该地区一家当地商店每天卖出的<strong class="kw iu">数量</strong>(数据点的<strong class="kw iu">标签</strong>)。</strong></p><p id="4281" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">通过制作一个<strong class="kw iu">非常简单的模型</strong>，我们可以<strong class="kw iu">查看这两者是否相关</strong>，如果相关，然后使用这个模型<strong class="kw iu">进行预测</strong>，以便根据温度储备水瓶，永远不会缺货，或者避免库存过多。</p><p id="9be7" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">我们可以尝试一个非常简单的<strong class="kw iu">线性回归模型</strong>来看看这些变量是如何相关的。在下面描述这个线性模型的公式中，y 是目标标签(在我们的例子中是水瓶的数量)，<strong class="kw iu">每个θs 是模型的参数</strong>(y 轴的斜率和切割)，x 是我们的特征(在我们的例子中是温度)。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nq"><img src="../Images/f90984070b5763ab6fe597e09261b304.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*4Y-w0Em_qLcIdIxKBDDnkQ.png"/></div></div><figcaption class="nb nc gj gh gi nd ne bd b be z dk">Equation describing a linear model</figcaption></figure><p id="72ae" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">这种训练的目标是<strong class="kw iu">减少提到的损失函数</strong>，以便模型对已知数据点的预测接近这些数据点的标签的实际值。</p><p id="1257" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">用可用数据训练模型后，我们将得到两个<strong class="kw iu"> θs </strong>的值。该训练可以通过使用类似梯度下降的<strong class="kw iu">迭代过程</strong>或类似最大似然的另一种<strong class="kw iu">概率方法</strong>来执行。无论如何，我们只需要<strong class="kw iu">为每个参数设定一个值</strong>。</p><p id="7d16" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">以这种方式，当我们得到没有标签的<strong class="kw iu">新数据(新的温度预测)时，因为我们知道<strong class="kw iu"> θs </strong>的值，我们可以使用这个简单的等式来获得想要的<strong class="kw iu"> <em class="lr"> Ys </em> </strong>(每天需要的水瓶数量)。</strong></p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nr"><img src="../Images/57db0c7fcdac448fb52ebde6e6dbba5c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*-8ClELx0__LmrQNuCqwuCQ.png"/></div></div><figcaption class="nb nc gj gh gi nd ne bd b be z dk">Figure of an uni-variate linear regression. Using the initial blue data points, we calculate the line that best fits these points, and then when we get a new temperature we can easily calculate the Nº sold bottles for that day.</figcaption></figure><p id="117d" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">当我们使用贝叶斯定理进行回归时，不是<strong class="kw iu">认为模型的参数</strong>(θs)具有单一的唯一值，而是将它们<strong class="kw iu">表示为具有特定分布</strong>的参数<strong class="kw iu">:参数的先验分布。下图显示了一般贝叶斯公式，以及如何将其应用于机器学习模型。</strong></p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ns"><img src="../Images/10e99063ec193ac95cb257bf6e86b2e2.png" data-original-src="https://miro.medium.com/v2/resize:fit:514/format:webp/1*Otz1cC9Qlvh-1ZetbHuzkg.png"/></div><figcaption class="nb nc gj gh gi nd ne bd b be z dk">Bayes formula</figcaption></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nt"><img src="../Images/ded305b557300a3b29f2e188de2a6393.png" data-original-src="https://miro.medium.com/v2/resize:fit:960/format:webp/1*gdgddVSaJQ_BXWJJNYtZ9g.png"/></div><figcaption class="nb nc gj gh gi nd ne bd b be z dk">Bayes formula applied to a machine learning model</figcaption></figure><p id="2b4d" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">这背后的想法是，<strong class="kw iu">我们在没有任何实际数据之前，已经有了模型</strong>参数的一些先验知识:<strong class="kw iu"> <em class="lr"> P(模型)</em> </strong>就是这个先验概率。然后，<strong class="kw iu">当我们得到一些新的数据时，我们更新模型的参数</strong>的分布，使之成为后验概率<strong class="kw iu"> <em class="lr"> P(模型|数据)</em> </strong>。</p><p id="61e6" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">这意味着<strong class="kw iu">我们的参数集</strong>(我们模型的θs)不是常数，而是<strong class="kw iu">有自己的分布</strong>。基于先前的知识(例如，来自专家，或来自其他作品)<strong class="kw iu">我们对我们的模型的参数分布做出第一个假设</strong>。然后，当我们用更多的数据<strong class="kw iu"/>，<strong class="kw iu">训练我们的模型时，这个分布得到更新</strong>，变得更加精确(实际上方差变得更小)。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nu"><img src="../Images/7d52ee8384f040771ca46b2ee1ac274f.png" data-original-src="https://miro.medium.com/v2/resize:fit:972/format:webp/1*KmnRZ_zc_cD7CIWylEyrFg.png"/></div><figcaption class="nb nc gj gh gi nd ne bd b be z dk">Figure of the a priori and posteriori parameter distributions. θMap is the maximum posteior estimation, which we would then use in our models.</figcaption></figure><p id="6a72" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">该图显示了模型参数的<strong class="kw iu">初始分布<em class="lr"> p(θ) </em> </strong>，以及当我们添加更多数据时，该分布<strong class="kw iu">如何更新，</strong>使其更精确地增长到<strong class="kw iu"> <em class="lr"> p(θ|x) </em> </strong>，其中 x 表示该新数据。这里的θ相当于上图公式中的<em class="lr">型号</em>，这里的<em class="lr">x</em>T37 相当于这样公式中的<em class="lr">数据</em>。</p><p id="97bf" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">贝叶斯公式一如既往地告诉我们如何从先验概率到后验概率。随着我们获得越来越多的数据，我们在迭代过程中这样做，让<strong class="kw iu">后验概率成为下一次迭代的先验概率</strong>。一旦我们用足够的数据训练了模型，为了选择最终参数组，我们将搜索<strong class="kw iu">最大后验(MAP)估计，以使用模型参数的一组具体值。</strong></p><p id="1890" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">这种分析<strong class="kw iu">从最初的先验分布</strong>中获得其优势:如果我们没有任何先验信息，并且不能对其做出任何假设，那么像最大似然法这样的其他概率方法更适合。</p><p id="8204" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">然而，<strong class="kw iu">如果我们有一些关于参数分布的先验信息，贝叶斯方法被证明是非常有效的</strong>，特别是在有<strong class="kw iu">不可靠的训练数据</strong>的情况下。在这种情况下，由于我们不是使用该数据从零开始构建模型和计算其参数，而是使用某种先前的知识来推断这些参数的初始分布，<strong class="kw iu">该先前的分布使得参数更加稳健，并且更少受到不准确数据的影响。</strong></p><p id="1cd8" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">我不想在这部分讲太多技术，但是所有这些推理背后的数学是美丽的；如果你想了解它，不要犹豫，给我发电子邮件到 jaimezorno@gmail.com 或者通过<a class="ae lq" href="https://www.linkedin.com/in/jaime-zornoza/" rel="noopener ugc nofollow" target="_blank"> LinkdIn </a>联系我。</p><h2 id="6984" class="lx ly it bd mf nf ng dn mj nh ni dp mn ld nj nk mp lh nl nm mr ll nn no mt np bi translated"><strong class="ak">分类中的贝叶斯定理</strong></h2><p id="cb41" class="pw-post-body-paragraph ku kv it kw b kx mv ju kz la mw jx lc ld mx lf lg lh my lj lk ll mz ln lo lp im bi translated">我们已经看到，通过估计线性模型的参数，贝叶斯定理可以用于回归分析。同样的推理可以应用于其他类型的回归算法。</p><p id="4d01" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">现在我们将看看如何使用贝叶斯定理进行分类。这就是所谓的<strong class="kw iu">贝叶斯最优分类器</strong>。现在的推理和之前的很像。</p><p id="e31c" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">假设我们有一个分类问题，用<strong class="kw iu"> <em class="lr"> i </em>不同的类</strong>。我们在这里追求的是<strong class="kw iu">每个类<strong class="kw iu">w<em class="lr">I</em>T17】的类概率</strong>。与之前的回归案例一样，我们也区分先验概率和后验概率，但现在我们有了<strong class="kw iu">先验类概率</strong> <strong class="kw iu"> <em class="lr"> p(wi) </em> </strong>和<strong class="kw iu">后验类概率</strong>，在使用数据或观测值<strong class="kw iu"> <em class="lr"> p(wi|x) </em> </strong>之后。</strong></p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nv"><img src="../Images/b9eba679543b2b6a5796373e80d14319.png" data-original-src="https://miro.medium.com/v2/resize:fit:1004/format:webp/1*c63H7VlsTrcntMc5P2v7aw.png"/></div><figcaption class="nb nc gj gh gi nd ne bd b be z dk">Bayes formula used for Bayes’ optimal classifier</figcaption></figure><p id="af70" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">这里的<strong class="kw iu"><em class="lr">【x】</em></strong>是<strong class="kw iu">所有数据点</strong><strong class="kw iu"><em class="lr">【x | wi】</em></strong>所共有的<strong class="kw iu">密度函数，是属于<em class="lr"> wi </em> </strong>类的数据点的<strong class="kw iu">密度函数，<strong class="kw iu"> <em class="lr"> P(wi) </em> </strong>是<strong class="kw iu"> <em class="lr"> wi 类的先验分布<strong class="kw iu"> <em class="lr"> P(x|wi) </em> </strong>是从训练数据中计算出来的，假设某个分布，并计算每个类别</em></strong>的<strong class="kw iu">均值向量和属于该类别的数据点的特征</strong>的<strong class="kw iu">协方差。先验类分布<strong class="kw iu"> <em class="lr"> P(wi) </em> </strong>是基于<strong class="kw iu">领域知识</strong>、专家建议或以前的工作来估计的，就像回归示例中一样。</strong></strong></p><p id="fe87" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">让我们看一个如何工作的例子:图像我们测量了 34 个人的身高:<strong class="kw iu"> 25 个男性(蓝色)</strong>和<strong class="kw iu"> 9 个女性(红色)</strong>，我们得到了一个 172 cm 的<strong class="kw iu">新的</strong>身高<strong class="kw iu">观察值</strong>，我们想将它分类为男性或女性。下图显示了使用<strong class="kw iu">最大似然分类器和贝叶斯最优分类器获得的预测。</strong></p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nw"><img src="../Images/f04259983ddc6f01b0107fc14949e433.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*okTibKIXXCSLC3ZuKqKwPQ.png"/></div></div><figcaption class="nb nc gj gh gi nd ne bd b be z dk">On the left, the training data for both classes with their estimated normal distributions. On the right, Bayes optimal classifier, with prior class probabilities p(wA) of male being 25/34 and p(wB) of female being 9/34.</figcaption></figure><p id="3a15" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">在这种情况下，我们使用训练数据<strong class="kw iu">中的<strong class="kw iu">个样本</strong>作为</strong>的<strong class="kw iu">先验知识</strong>用于我们的类别分布，但是例如，如果我们对特定国家的身高和性别进行相同的区分，并且我们知道那里的女性特别高，也知道男性的平均身高，我们可以使用这个<strong class="kw iu">信息来构建我们的先验类别分布。</strong></p><p id="0c63" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">从例子中我们可以看出，使用这些<strong class="kw iu">先验知识会导致与不使用它们</strong>不同的结果。假设先前的知识是高质量的(否则我们不会使用它)，这些预测应该比没有结合这些信息的类似试验更加准确。</p><p id="3e28" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">在这之后，一如既往，当我们得到更多的数据时，这些分布会得到更新以反映从这些数据中获得的知识。</p><p id="f98f" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">和前一个案例一样，我不想太过技术化，或者过多地延伸文章，所以我就不深究数学上的细节了，但是<strong class="kw iu">如果你对它们</strong>感兴趣，可以随时联系我。</p><h1 id="2482" class="me ly it bd mf mg mh mi mj mk ml mm mn jz mo ka mp kc mq kd mr kf ms kg mt mu bi translated">结论</h1><p id="0abc" class="pw-post-body-paragraph ku kv it kw b kx mv ju kz la mw jx lc ld mx lf lg lh my lj lk ll mz ln lo lp im bi translated">我们已经看到<strong class="kw iu">贝叶斯定理是如何用于机器学习的</strong>；无论是在<strong class="kw iu">回归</strong>还是<strong class="kw iu">分类</strong>中，都要将以前的知识融入到我们的模型中并加以改进。</p><p id="0e19" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">在接下来的文章中，我们将看到贝叶斯定理的简化如何成为自然语言处理中最常用的技术之一，以及它们如何应用于许多真实世界的用例，如垃圾邮件过滤器或情感分析工具。来看看<a class="ae lq" href="https://medium.com/@jaimezornoza" rel="noopener"> <strong class="kw iu">跟我上媒</strong> </a>，敬请期待！</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nx"><img src="../Images/3cd428905639a85202a3ebcce2c70447.png" data-original-src="https://miro.medium.com/v2/resize:fit:1286/format:webp/1*Cbg-PaZv5rRo1iXSElH2wg.png"/></div><figcaption class="nb nc gj gh gi nd ne bd b be z dk">Another example of Bayesian classification</figcaption></figure><p id="97b2" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">就这些，我希望你喜欢这个帖子。欢迎在 LinkedIn<a class="ae lq" href="https://www.linkedin.com/in/jaime-zornoza/" rel="noopener ugc nofollow" target="_blank">上与我联系，或者在 Twitter 上关注我，邮箱:<strong class="kw iu"> @jaimezorno </strong>。还有，你可以看看我其他关于数据科学和机器学习的帖子<strong class="kw iu"> </strong> </a><a class="ae lq" href="https://medium.com/@jaimezornoza" rel="noopener"> <strong class="kw iu">这里</strong> </a>。好好读！</p><h1 id="9280" class="me ly it bd mf mg mh mi mj mk ml mm mn jz mo ka mp kc mq kd mr kf ms kg mt mu bi translated">额外资源</h1><p id="0e35" class="pw-post-body-paragraph ku kv it kw b kx mv ju kz la mw jx lc ld mx lf lg lh my lj lk ll mz ln lo lp im bi translated">如果您想更深入地研究贝叶斯和机器学习，请查看以下其他资源:</p><ul class=""><li id="4c4e" class="ny nz it kw b kx ky la lb ld oa lh ob ll oc lp od oe of og bi translated"><a class="ae lq" href="https://brohrer.github.io/how_bayesian_inference_works.html" rel="noopener ugc nofollow" target="_blank">贝叶斯推理如何工作</a></li><li id="9e54" class="ny nz it kw b kx oh la oi ld oj lh ok ll ol lp od oe of og bi translated"><a class="ae lq" href="https://www.youtube.com/watch?v=YsJ4W1k0hUg" rel="noopener ugc nofollow" target="_blank">贝叶斯统计 Youtube 系列</a></li><li id="184f" class="ny nz it kw b kx oh la oi ld oj lh ok ll ol lp od oe of og bi translated"><a class="ae lq" href="https://slideplayer.com/slide/4940573/" rel="noopener ugc nofollow" target="_blank">机器学习贝叶斯学习幻灯片</a></li><li id="1694" class="ny nz it kw b kx oh la oi ld oj lh ok ll ol lp od oe of og bi translated"><a class="ae lq" href="https://www.umass.edu/landeco/teaching/ecodata/schedule/bayesian.pdf" rel="noopener ugc nofollow" target="_blank">贝叶斯推断</a></li><li id="ee77" class="ny nz it kw b kx oh la oi ld oj lh ok ll ol lp od oe of og bi translated"><a class="ae lq" href="https://howtolearnmachinelearning.com/online-courses/statistics-and-probability-courses/" rel="noopener ugc nofollow" target="_blank">统计与概率网络课程</a></li></ul><p id="2263" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">有关机器学习和数据科学的更多资源，请查看以下资源库:<a class="ae lq" href="https://howtolearnmachinelearning.com/books/machine-learning-books/" rel="noopener ugc nofollow" target="_blank"> <strong class="kw iu">如何学习机器学习</strong> </a>！有关职业资源(工作、事件、技能测试)，请访问<a class="ae lq" href="https://aigents.co/" rel="noopener ugc nofollow" target="_blank"><strong class="kw iu">AIgents.co——数据科学家的职业社区&amp;机器学习工程师</strong> </a>，如有任何问题，请联系我。祝你有美好的一天，继续学习。</p></div></div>    
</body>
</html>