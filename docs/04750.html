<html>
<head>
<title>Speeding up Neural Net Training with LR-Finder</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">用 LR-Finder 加速神经网络训练</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/speeding-up-neural-net-training-with-lr-finder-c3b401a116d0?source=collection_archive---------11-----------------------#2019-07-19">https://towardsdatascience.com/speeding-up-neural-net-training-with-lr-finder-c3b401a116d0?source=collection_archive---------11-----------------------#2019-07-19</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="6093" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">为你的网络找到良好的初始学习率</h2></div><h1 id="8f95" class="ki kj it bd kk kl km kn ko kp kq kr ks jz kt ka ku kc kv kd kw kf kx kg ky kz bi translated">简介:优化器和 LR</h1><p id="bda0" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">当训练一个深度神经网络时，选择一个好的学习速率对于快速收敛和较低的误差都是至关重要的。我们还必须选择一个优化器，它决定如何在 DNN 中完成重量更新。</p><p id="5e1c" class="pw-post-body-paragraph la lb it lc b ld lw ju lf lg lx jx li lj ly ll lm ln lz lp lq lr ma lt lu lv im bi translated">有各种各样的优化器可用，如 Adam、SGD+momentum、Adagrad、RMSprop、AdaDelta、AdaBound。其中亚当和新币+动量最受欢迎。在训练全连接 DNN 或卷积网络时，大多数现有技术的网络使用 SGD+momentum。这是因为它更好地概括了看不见的数据，并给出了更好的验证/测试分数。</p><h1 id="dffb" class="ki kj it bd kk kl km kn ko kp kq kr ks jz kt ka ku kc kv kd kw kf kx kg ky kz bi translated">为什么我们需要找一个好的 LR？</h1><p id="c541" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">不过，SGD 有两个小问题，与 Adam 相比，SGD 收敛较慢，而且 SGD 需要调整学习速率。令人惊讶的是，解决这两个问题的方法是使用一个好的开始学习率。如果你的 LR 太高，你的误差永远不会减少，训练也不会收敛。太低的 LR 和你必须等待太长的训练收敛。因此，我们从 LR-Finder 给出的一个好的 LR 开始，然后在到达终点时稍微衰减它。</p><h1 id="2b69" class="ki kj it bd kk kl km kn ko kp kq kr ks jz kt ka ku kc kv kd kw kf kx kg ky kz bi translated">那么 LR finders 是如何工作的呢？</h1><p id="610f" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">LR 探测器的基本目标是找到最高的 LR，该最高的 LR 仍然最小化损失并且不会使损失爆炸/发散。我们通过训练一个模型来做到这一点，同时在每批之后增加 LR，我们记录损失，最后我们在损失爆发之前使用 LR。我们这样做一个时期。</p><pre class="mb mc md me gt mf mg mh mi aw mj bi"><span id="793c" class="mk kj it mg b gy ml mm l mn mo">start_lr = 0.0001<br/>end_lr = 1.0<br/>num_batches = len(Data)/batch_size<br/>cur_lr = start_lr<br/>lr_multiplier = (end_lr / start_lr) ** (1.0 / num_batches)<br/>losses = []<br/>lrs = []</span><span id="ae9d" class="mk kj it mg b gy mp mm l mn mo">for i in 1 to num_batches:<br/>    loss = train_model_get_loss(batch=i)<br/>    losses.append(loss)<br/>    lrs.append(cur_lr)<br/>    cur_lr = cur_lr*lr_multiplier # increase LR</span><span id="bfdf" class="mk kj it mg b gy mp mm l mn mo">plot(lrs,losses)</span></pre><p id="e441" class="pw-post-body-paragraph la lb it lc b ld lw ju lf lg lx jx li lj ly ll lm ln lz lp lq lr ma lt lu lv im bi translated">你会得到一个如下图所示的图</p><figure class="mb mc md me gt mr gh gi paragraph-image"><div role="button" tabindex="0" class="ms mt di mu bf mv"><div class="gh gi mq"><img src="../Images/a221726b92d6089eb6144091c31f469c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*JCpN-adtEIS0rhm2NZq4DA.png"/></div></div><figcaption class="my mz gj gh gi na nb bd b be z dk">Loss vs LR</figcaption></figure><p id="8783" class="pw-post-body-paragraph la lb it lc b ld lw ju lf lg lx jx li lj ly ll lm ln lz lp lq lr ma lt lu lv im bi translated">我们用箭头标出这些点，以指示我们的实现中的<a class="ae nc" href="https://github.com/faizanahemad/data-science-utils/blob/master/data_science_utils/vision/keras/lr_finder.py" rel="noopener ugc nofollow" target="_blank">位置</a></p><figure class="mb mc md me gt mr gh gi paragraph-image"><div role="button" tabindex="0" class="ms mt di mu bf mv"><div class="gh gi nd"><img src="../Images/5cfa03acf8c28fec51a2ffcc014f5406.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Q7AJgVsacgcegOka5qmajg.png"/></div></div><figcaption class="my mz gj gh gi na nb bd b be z dk">LR Finder with Annotation</figcaption></figure><p id="3bec" class="pw-post-body-paragraph la lb it lc b ld lw ju lf lg lx jx li lj ly ll lm ln lz lp lq lr ma lt lu lv im bi translated">从这个图中，我们找到了一个点，在这个点之后，损失开始增加太多。</p><h2 id="06b7" class="mk kj it bd kk ne nf dn ko ng nh dp ks lj ni nj ku ln nk nl kw lr nm nn ky no bi translated">使用</h2><p id="cd39" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">我写了一个包含 LR 查找器的小库。这是给 Keras 的。对于 pytorch fast.ai 实现有效。<br/>安装:</p><pre class="mb mc md me gt mf mg mh mi aw mj bi"><span id="f454" class="mk kj it mg b gy ml mm l mn mo">pip install --upgrade --upgrade-strategy only-if-needed <a class="ae nc" href="https://github.com/faizanahemad/data-science-utils/tarball/master" rel="noopener ugc nofollow" target="_blank">https://github.com/faizanahemad/data-science-utils/tarball/master</a> &gt; /dev/null</span></pre><p id="4cd9" class="pw-post-body-paragraph la lb it lc b ld lw ju lf lg lx jx li lj ly ll lm ln lz lp lq lr ma lt lu lv im bi translated">您笔记本中的下一项(针对 Cifar 10)</p><p id="c8cb" class="pw-post-body-paragraph la lb it lc b ld lw ju lf lg lx jx li lj ly ll lm ln lz lp lq lr ma lt lu lv im bi translated">首先为我们的数据集定义导入和数据生成器。</p><pre class="mb mc md me gt mf mg mh mi aw mj bi"><span id="4662" class="mk kj it mg b gy ml mm l mn mo">from data_science_utils.vision.keras import *</span><span id="90db" class="mk kj it mg b gy mp mm l mn mo">X_train, Y_train, X_test, Y_test = get_cifar10_data()</span><span id="e686" class="mk kj it mg b gy mp mm l mn mo">cutout_fn = get_cutout_eraser(p=0.75, s_l=0.1, s_h=0.3, r_1=0.3, r_2=1 / 0.3, max_erasures_per_image=2, pixel_level=True)<br/>datagen = ImageDataGenerator(featurewise_center=True,featurewise_std_normalization=True,<br/>                           preprocessing_function=cutout_fn)</span><span id="5be7" class="mk kj it mg b gy mp mm l mn mo">datagen_validation = ImageDataGenerator(featurewise_center=True,featurewise_std_normalization=True,)<br/>datagen_validation.fit(X_train)</span><span id="59b7" class="mk kj it mg b gy mp mm l mn mo">model = build_model()</span></pre><p id="ace9" class="pw-post-body-paragraph la lb it lc b ld lw ju lf lg lx jx li lj ly ll lm ln lz lp lq lr ma lt lu lv im bi translated">接下来，我们建立我们的模型，并使用 LR 查找器。</p><pre class="mb mc md me gt mf mg mh mi aw mj bi"><span id="9c80" class="mk kj it mg b gy ml mm l mn mo">model = build_model() # returns an instance of Keras Model<br/>lrf = LRFinder(model)<br/>generator = datagen.flow(X_train, Y_train, batch_size=256,shuffle=True)<br/>test_generator = datagen_validation.flow(X_test, Y_test, batch_size=256, shuffle=True)<br/>lrf.find_generator(generator, 0.0001, 10.0,test_generator, epochs=1, steps_per_epoch=None,)<br/>lrf.plot_loss()</span></pre><p id="6ef6" class="pw-post-body-paragraph la lb it lc b ld lw ju lf lg lx jx li lj ly ll lm ln lz lp lq lr ma lt lu lv im bi translated">你看到的上面两张图就是用这个生成的。你可以在<a class="ae nc" href="https://colab.research.google.com/drive/1snEPXi418CrctkDP240KdEkff1z83buV" rel="noopener ugc nofollow" target="_blank">这款谷歌 Colab 笔记本</a>中看到例子。</p><h2 id="c456" class="mk kj it bd kk ne nf dn ko ng nh dp ks lj ni nj ku ln nk nl kw lr nm nn ky no bi translated">使用 LR 取景器时的注意事项</h2><ul class=""><li id="fcbd" class="np nq it lc b ld le lg lh lj nr ln ns lr nt lv nu nv nw nx bi translated">我们使用最小值作为我们的候选 lr。您可以注意到，其中一些是局部最小值，总损耗相当高，对于候选 LRs，总损耗应该接近最小损耗。所以我们过滤这些局部最小值</li><li id="b56f" class="np nq it lc b ld ny lg nz lj oa ln ob lr oc lv nu nv nw nx bi translated">我们需要使用验证集来寻找损失，使用训练集来寻找损失不会产生正确的结果，因为权重会超出训练集。</li><li id="318b" class="np nq it lc b ld ny lg nz lj oa ln ob lr oc lv nu nv nw nx bi translated">当我们生成候选 lr 时，我们需要确保它们足够清晰。例如，生成像 0.552 和 0.563 这样的候选值没有意义，因为这些 lr 太接近了。因此，我们应用了一个规则，即每个 LR 应该至少与之前较低的 LR 相差 20%。</li><li id="c9a7" class="np nq it lc b ld ny lg nz lj oa ln ob lr oc lv nu nv nw nx bi translated">注意 LR Finder 给你一个近似值，所以你取不取精确值并不重要。就像如果 LRF 给你 0.012，那么你也可以用 0.01。如果它给出 0.056，那么 0.05 和 0.06 都可以。</li></ul><h2 id="f2cd" class="mk kj it bd kk ne nf dn ko ng nh dp ks lj ni nj ku ln nk nl kw lr nm nn ky no bi translated">后期微调 LR</h2><p id="9b23" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">我们可以使用 LR 调度或 LR 衰减来降低后面时期的 LR，因为我们最初是从高 LR 开始的。</p><h1 id="bd5d" class="ki kj it bd kk kl km kn ko kp kq kr ks jz kt ka ku kc kv kd kw kf kx kg ky kz bi translated">结果</h1><h2 id="909f" class="mk kj it bd kk ne nf dn ko ng nh dp ks lj ni nj ku ln nk nl kw lr nm nn ky no bi translated">在 LR 取景器之前</h2><p id="95ac" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">我们直接用了 SGD，learning_rate 为 0.01，nesterov 的动量。我们在 CIFAR-10 上训练了 100 个时期的网络。我们的网络有 45 万个参数。</p><figure class="mb mc md me gt mr gh gi paragraph-image"><div role="button" tabindex="0" class="ms mt di mu bf mv"><div class="gh gi od"><img src="../Images/8b31ab7680eacb332f5472bad56a8d31.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ww3fUK6M4E5okHo38pTtNQ.png"/></div></div><figcaption class="my mz gj gh gi na nb bd b be z dk">Without LR Finder</figcaption></figure><p id="3892" class="pw-post-body-paragraph la lb it lc b ld lw ju lf lg lx jx li lj ly ll lm ln lz lp lq lr ma lt lu lv im bi translated">正如你所注意到的，验证误差收敛需要大约 60 个历元，准确率为 86.7%。</p><h2 id="6eb3" class="mk kj it bd kk ne nf dn ko ng nh dp ks lj ni nj ku ln nk nl kw lr nm nn ky no bi translated">后左后取景器</h2><p id="dfdb" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">我们使用 LR finder 提供的 LR。其他一切都一样。</p><figure class="mb mc md me gt mr gh gi paragraph-image"><div role="button" tabindex="0" class="ms mt di mu bf mv"><div class="gh gi oe"><img src="../Images/bb71cb2e8e518064310e8ad036709466.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*-QfrISeP7CWOhbDq_YwQGw.png"/></div></div><figcaption class="my mz gj gh gi na nb bd b be z dk">After LR Finder</figcaption></figure><p id="a19a" class="pw-post-body-paragraph la lb it lc b ld lw ju lf lg lx jx li lj ly ll lm ln lz lp lq lr ma lt lu lv im bi translated">你可以看到，这里我们得到了 86.4%的准确性，但训练收敛于 40 个时期，而不是 60 个。使用 LR finder 提供的 LR 和 EarlyStopping 可以大大减少计算时间。</p><h2 id="fb0a" class="mk kj it bd kk ne nf dn ko ng nh dp ks lj ni nj ku ln nk nl kw lr nm nn ky no bi translated">在 LR 查找器和 LR 调度之后</h2><p id="cfd1" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">我们使用 keras 的 LR 调度来减少每个时期的 LR。基本上，在每个时期之后，我们通过乘以 0.97 来减少 LR。您可以在示例笔记本中查看<a class="ae nc" href="https://colab.research.google.com/drive/1snEPXi418CrctkDP240KdEkff1z83buV" rel="noopener ugc nofollow" target="_blank"> LR 调度部分</a></p><figure class="mb mc md me gt mr gh gi paragraph-image"><div role="button" tabindex="0" class="ms mt di mu bf mv"><div class="gh gi of"><img src="../Images/97e52b5ff43a45505032dcc3dc829396.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*MkjQ2yUjtjxEGkdRu9uwGQ.png"/></div></div><figcaption class="my mz gj gh gi na nb bd b be z dk">With LR scheduling</figcaption></figure><p id="d588" class="pw-post-body-paragraph la lb it lc b ld lw ju lf lg lx jx li lj ly ll lm ln lz lp lq lr ma lt lu lv im bi translated">注意，在相同的网络和 LR 下，我们得到 88.4%。还要注意，到最后，损耗和精度图不再像以前那样波动。</p><p id="84bb" class="pw-post-body-paragraph la lb it lc b ld lw ju lf lg lx jx li lj ly ll lm ln lz lp lq lr ma lt lu lv im bi translated">因此，仅通过使用 LR 查找器和 LR 调度，我们就获得了超过 1%的准确性提高，使用了我们开始时使用的相同的 100 个时期。</p><h1 id="a435" class="ki kj it bd kk kl km kn ko kp kq kr ks jz kt ka ku kc kv kd kw kf kx kg ky kz bi translated">结论和参考文献</h1><p id="eba7" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">使用 LR Finder 被证明有利于更快的训练和提高准确性。我们还用一个<a class="ae nc" href="https://colab.research.google.com/drive/1snEPXi418CrctkDP240KdEkff1z83buV" rel="noopener ugc nofollow" target="_blank">笔记本</a>例子展示了如何使用 LR finder。LR 寻像器的代码在这里是<a class="ae nc" href="https://github.com/faizanahemad/data-science-utils/blob/master/data_science_utils/vision/keras/lr_finder.py" rel="noopener ugc nofollow" target="_blank"/>。</p><p id="eafc" class="pw-post-body-paragraph la lb it lc b ld lw ju lf lg lx jx li lj ly ll lm ln lz lp lq lr ma lt lu lv im bi translated">如果你觉得这很有用，请访问我的<a class="ae nc" href="https://github.com/faizanahemad/data-science-utils/blob/master/data_science_utils/vision/keras/GradCam_with_misclassified_LRFinder.ipynb" rel="noopener ugc nofollow" target="_blank">笔记本/Github </a>获取完整代码。</p></div></div>    
</body>
</html>