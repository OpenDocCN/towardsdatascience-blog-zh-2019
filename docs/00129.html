<html>
<head>
<title>A non technical intro to NLP</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">自然语言处理的非技术性介绍</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/intro-to-nlp-using-inaugural-speeches-of-presidents-8c7ca32cbdfe?source=collection_archive---------18-----------------------#2019-01-06">https://towardsdatascience.com/intro-to-nlp-using-inaugural-speeches-of-presidents-8c7ca32cbdfe?source=collection_archive---------18-----------------------#2019-01-06</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="b63e" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">总统就职演说分析</h2></div><p id="0506" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">虽然神经网络和 CNN 在计算机视觉领域取得了巨大的进步，但自然语言处理却没有得到应有的重视。它经常被忽视，因为还没有超越人类水平的表现。然而，正如我们将通过这个系列看到的，我们可以制作一些非常漂亮的工具，不仅可以帮助我们获得洞察力，还可以自动化任务。</p><p id="c272" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">所有提到的代码都可以在这里<a class="ae lb" href="https://github.com/divyanshrai/medium-code/blob/master/Class%201%20medium.ipynb" rel="noopener ugc nofollow" target="_blank">获得。你可能需要从 github 链接中复制一些我写的帮助函数。在这里提到它会使一切都过于集中。</a></p><p id="aca6" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">首先，我们将对从第一任总统到 2009 年奥巴马的演讲做一个基本的分析。这里我们将使用三个库<br/> 1。nltk <br/> 2。pyphen——将单词分成音节。matplotlib——嗯，为了绘图<br/>,所有这些都可以使用 pip install 安装。</p><p id="edee" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">你需要下载语料库。您可以通过执行下面给出的代码来做到这一点</p><pre class="lc ld le lf gt lg lh li lj aw lk bi"><span id="3431" class="ll lm iq lh b gy ln lo l lp lq">nltk.download(‘inaugural’)<br/>nltk.download('stopwords')</span></pre><p id="6547" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">或者你可以直接执行<em class="lr"> nltk.download() </em>在下载器弹出后下载语料库部分的“inaugral”和“stopwords”，如下图截屏所示。您也可以通过这种方式探索其他语料库。</p><figure class="lc ld le lf gt lt gh gi paragraph-image"><div role="button" tabindex="0" class="lu lv di lw bf lx"><div class="gh gi ls"><img src="../Images/55e68004a69035bfb5b57b98caf42cc5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1136/format:webp/1*e12k7BYWcAqfZOWcqu0pjQ.png"/></div></div><figcaption class="ma mb gj gh gi mc md bd b be z dk">how to download nltk corpus</figcaption></figure><p id="a8fa" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">现在我们用下面的代码导入 nltk 包和语音(这可能需要几秒钟，取决于您的计算机)</p><pre class="lc ld le lf gt lg lh li lj aw lk bi"><span id="b0eb" class="ll lm iq lh b gy ln lo l lp lq">import nltk<br/>from nltk.corpus import stopwords <br/>from nltk.corpus import inaugural<br/>from nltk.tokenize import word_tokenize, sent_tokenize<br/>import matplotlib.pyplot as plt<br/>import pyphen</span></pre><p id="7d02" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">现在我们已经导入了就职演说，我们可以看看数据。我们可以看到我们有 56 位总统的数据，从华盛顿到 2009 年的奥巴马。</p><figure class="lc ld le lf gt lt gh gi paragraph-image"><div role="button" tabindex="0" class="lu lv di lw bf lx"><div class="gh gi me"><img src="../Images/26ea91ea8e52df228e0c16ec07e1f734.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*rU5UZiog41pLuhtjx7z2ng.png"/></div></div></figure><p id="6c2b" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">让我们来看看这些演讲。要获得数据的原始格式，我们可以简单地使用<code class="fe mf mg mh lh b">inaugural.raw()</code>。但正如我们所看到的，我们不能清楚地把它分成单词。幸运的是，我们有<code class="fe mf mg mh lh b">inaugural.words()</code>为我们做这项工作。</p><figure class="lc ld le lf gt lt gh gi paragraph-image"><div role="button" tabindex="0" class="lu lv di lw bf lx"><div class="gh gi mi"><img src="../Images/76f21d1f38d0b5b703c8e5e470b62a44.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*6JqEHljKU6k2XrGX2QyrYQ.png"/></div></div></figure><p id="c479" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">既然我们已经把我们的演讲分解成单词，我们可以开始对它做一些基本的分析。我们从频率分布开始。这将告诉我们一个特定的单词出现了多少次。而且已经按降序排列了。</p><figure class="lc ld le lf gt lt gh gi paragraph-image"><div role="button" tabindex="0" class="lu lv di lw bf lx"><div class="gh gi mj"><img src="../Images/b69f15094f258c932f6c1684893cf503.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*PKnhm_yjIaYZ0vh2ZD2GSA.png"/></div></div></figure><p id="5dfd" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们遇到了一个问题，它被停用词淹没了。通常有一些单词和标点符号比其他单词和标点符号重复得更频繁，它们通常不会给我们提供更多的数据信息。nltk 已经有了一个类似的单词列表，它们被称为<code class="fe mf mg mh lh b">stopwords</code>。它们可用于多种语言。我们在导入的停用词列表中添加了一些符号。</p><figure class="lc ld le lf gt lt gh gi paragraph-image"><div role="button" tabindex="0" class="lu lv di lw bf lx"><div class="gh gi mk"><img src="../Images/0624c2dc556ceb9c460e665d42af318d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*C1FIXLjp45oa4zq24B4Vrw.png"/></div></div></figure><p id="042b" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">现在我们有了一个停用词列表，我们编写一个小代码来删除演讲中的所有停用词，并再次找出频率分布。</p><figure class="lc ld le lf gt lt gh gi paragraph-image"><div role="button" tabindex="0" class="lu lv di lw bf lx"><div class="gh gi ml"><img src="../Images/b95dafd3281f95b73868ca28128d4c9e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*rQukHirIQQJJbj9T0TKVaA.png"/></div></div></figure><p id="20dc" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这更好，也给了我们一些关于数据的见解。但这只给了我们一次演讲的数据，我们需要一些东西来比较更多总统的演讲。</p><p id="4ea7" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">所以我们开始计算 xyz 总统使用了多少个 2，3，4 字母单词。然后，我们取每位总统每个词的平均字母数，并绘制出来。</p><p id="fcf0" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">“我感到快乐”——每个单词的平均字母数为 3.33 (1+4+5)/3。</p><p id="5d74" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">“我散发出欣快感”——每个单词的平均字母数为 4.66(1+5+8)/3。</p><p id="ee3a" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">更高的每个单词的字母数意味着总统最常用“大”字。我们先数一下每位总统用了多少个 x 字母单词。</p><figure class="lc ld le lf gt lt gh gi paragraph-image"><div role="button" tabindex="0" class="lu lv di lw bf lx"><div class="gh gi mm"><img src="../Images/62ccbfbf3c6e623e0c42e0163acbfefb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*qLH0jGn6m_-4r_aeneyknQ.png"/></div></div></figure><p id="e7c3" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">当我们这样做的时候，我们还将每个单词的平均字母数存储在一个名为<code class="fe mf mg mh lh b">presidents_avg</code>的变量中。使用 matplotlib 来绘制它，我们可以看到它明显地随着时间/总统而减少。</p><figure class="lc ld le lf gt lt gh gi paragraph-image"><div class="gh gi mn"><img src="../Images/fce709e960b360347cfd828a31626109.png" data-original-src="https://miro.medium.com/v2/resize:fit:1374/format:webp/1*eUeIvT7HrAgz4Z7j0hfO9w.png"/></div></figure><p id="0bb3" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">沿着类似的路径，我们开始计算 xyz 总统在一个句子中说了多少个单词。然后我们取每位总统每句话的平均字数，并绘制出来。</p><p id="2c10" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">每句话的平均字数更高意味着总统最常用“大”句子。我们还将每句话的平均字数存储在一个名为<code class="fe mf mg mh lh b">presidents_avg_words_per_sentence</code>的变量中。使用 matplotlib 来绘制它，我们可以看到它明显地随着时间/总统而减少。</p><figure class="lc ld le lf gt lt gh gi paragraph-image"><div role="button" tabindex="0" class="lu lv di lw bf lx"><div class="gh gi mo"><img src="../Images/2265bf13bcf00746f09130c29e9e80b6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Pux6UO_HhruhTV0d8qBRKA.png"/></div></div></figure><p id="26d2" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">现在让我们看看单体型分析是否能给我们带来什么。在语料库语言学中，hapax legomenon 是一个在语境/言语中只出现一次的词。<code class="fe mf mg mh lh b">words.hapaxes()</code>给出了给定语料库中所有独特的单词。</p><p id="4dd6" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">但是计算独特单词的数量是不够的。我们还需要用它除以整个演讲的长度。为什么？因为演讲的长度变化很大，所以一个更大的演讲可能有更多独特的单词，我们需要消除这种偏见。因此，我们在一篇演讲中找到独特的词，统计它们，平均它们，并为每位总统绘制它们。</p><figure class="lc ld le lf gt lt gh gi paragraph-image"><div class="gh gi mp"><img src="../Images/41e23bb5f5c55685aba52175448cc285.png" data-original-src="https://miro.medium.com/v2/resize:fit:1116/format:webp/1*XlQ7tNQX21MHYVjfMIg6GQ.png"/></div></figure><p id="57d0" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">似乎在减少一点，虽然不是很明显。</p><p id="e4e8" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在最后的分析中，我们计算每位总统在演讲中使用的每个单词的音节，我们使用 pyphen 库，因为像“Afghasnistan”这样的名词通常没有预定义的音节数。</p><p id="64a5" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">然后我们取每位总统每个词的平均音节数，并绘制出来。</p><p id="e862" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">当我们看到图表时，我们看到它随着时间的推移而减少。</p><figure class="lc ld le lf gt lt gh gi paragraph-image"><div class="gh gi mq"><img src="../Images/00d10b8a64556fe775fc2de9beeee2ef.png" data-original-src="https://miro.medium.com/v2/resize:fit:1256/format:webp/1*kD-wnbqEekynFVXm-9kRxQ.png"/></div></figure><p id="1ee5" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">所以相比较而言，现在的总统比以前的总统使用更少的单词和更短的句子。<br/>这可能是由多种原因造成的，英语本身在 200 年的时间里发展了很多，但也可能是因为媒体的进步。随着总统的演讲开始被普通人所接受，他们自然喜欢较短的句子和较小的单词，总统的演讲开始根据新的听众而改变。他们不是为了给华盛顿少数受过教育的人留下深刻印象，而是为了从普通人那里获得选票。</p></div></div>    
</body>
</html>