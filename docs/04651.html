<html>
<head>
<title>Various Types of Convolutional Neural Network</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">各种类型的卷积神经网络</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/various-types-of-convolutional-neural-network-8b00c9a08a1b?source=collection_archive---------7-----------------------#2019-07-16">https://towardsdatascience.com/various-types-of-convolutional-neural-network-8b00c9a08a1b?source=collection_archive---------7-----------------------#2019-07-16</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><figure class="gl gn jr js jt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi jq"><img src="../Images/3f16878785ad3e6b610ac18e6bc06b21.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*oPuwy2daa_GlW4gqWage8Q.png"/></div></div></figure><p id="66ab" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">该帖子将出现在 CNN 的各种<strong class="kd iu">类型</strong>上，在图像处理和物体识别的各个领域中成功设计并实现。如果你对卷积神经网络有所了解会更好。<br/>你可能听说过<a class="ae kz" href="http://www.image-net.org/" rel="noopener ugc nofollow" target="_blank"> <strong class="kd iu"> ImageNet </strong> </a>。这是一个大型的有组织的视觉图像数据库，供研究人员和开发人员用来训练他们的模型。现在，他们主办了一年一度的竞赛，名为<a class="ae kz" href="http://www.image-net.org/challenges/LSVRC/" rel="noopener ugc nofollow" target="_blank"> ImageNet 大规模视觉识别挑战赛(ILSVRC)</a>——一场与大规模物体检测和图像分类相关的竞赛。一般来说，这场比赛中表现最好的选手能够在物体分类领域设定一个基准。这份各种建筑的列表，在他们的设计中是独一无二的，在这场竞赛中获得了最高的位置，并且正在成功地应用于各种任务中。<br/> <strong class="kd iu">注意:除非另有说明，这些网络都实现了<em class="la">同填充</em>，实质上保留了图像卷积后的原始大小。</strong> <br/>让我们看看它们:</p><h1 id="fc03" class="lb lc it bd ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly bi translated">LeNet:</h1><figure class="ma mb mc md gt ju gh gi paragraph-image"><div class="gh gi lz"><img src="../Images/6bf627b472a5ab4d818b95bbb14492f6.png" data-original-src="https://miro.medium.com/v2/resize:fit:830/format:webp/1*SQePQNijX1AerF3w7oqdxQ.jpeg"/></div><figcaption class="me mf gj gh gi mg mh bd b be z dk">LeNet Architecture.</figcaption></figure><p id="2580" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">没有这一点，就不能开始讨论有线电视新闻网的架构。就对象分类而言，这是一个开创性的算法，是同类算法中的第一个，也是有能力的。<strong class="kd iu">最初接受 MNIST 数据集 0-9 手写数字分类的训练</strong>。它由 7 层组成，均由可训练参数组成。它采用 32 X 32 像素的图像，相对于训练网络的数据集内的图像，其尺寸相对较大。应用的激活功能为<strong class="kd iu"> RELU </strong>功能。这些层按以下方式排列:</p><figure class="ma mb mc md gt ju gh gi paragraph-image"><div class="gh gi mi"><img src="../Images/9c1cd8375f9bd50c243e614fa0aeb9d0.png" data-original-src="https://miro.medium.com/v2/resize:fit:842/format:webp/1*vzR5N-EJDpV12QGfVDqAiw.png"/></div><figcaption class="me mf gj gh gi mg mh bd b be z dk">LeNet Architecture, but with more details.</figcaption></figure><ol class=""><li id="4a9f" class="mj mk it kd b ke kf ki kj km ml kq mm ku mn ky mo mp mq mr bi translated"><strong class="kd iu">第一卷积层</strong>由<strong class="kd iu"> 6 个尺寸为<strong class="kd iu">5 X 5</strong>的滤波器</strong>和 1 个的<strong class="kd iu">步长组成。</strong></li><li id="3017" class="mj mk it kd b ke ms ki mt km mu kq mv ku mw ky mo mp mq mr bi translated"><strong class="kd iu">第二层</strong>为<strong class="kd iu">尺寸 2×2</strong>的<strong class="kd iu">亚取样</strong>或<strong class="kd iu">平均汇集</strong>层，2 的<strong class="kd iu">步距。</strong></li><li id="00db" class="mj mk it kd b ke ms ki mt km mu kq mv ku mw ky mo mp mq mr bi translated"><strong class="kd iu">第三层</strong>也是<strong class="kd iu">卷积层</strong>，由<strong class="kd iu"> 16 个 5×5</strong>尺寸的滤波器和<strong class="kd iu">1 步长的滤波器组成。</strong></li><li id="b2c9" class="mj mk it kd b ke ms ki mt km mu kq mv ku mw ky mo mp mq mr bi translated"><strong class="kd iu">第四层</strong>同样是<strong class="kd iu">平均汇集层</strong>的<strong class="kd iu">尺寸为 2×2</strong>和<strong class="kd iu">跨距为 2。</strong></li><li id="9cb3" class="mj mk it kd b ke ms ki mt km mu kq mv ku mw ky mo mp mq mr bi translated"><strong class="kd iu">第五层</strong>将<em class="la">第四层</em> ( <strong class="kd iu"> 400 参数</strong>)的输出连接到<strong class="kd iu"> 120 节点的<strong class="kd iu">全连接层</strong>。</strong></li><li id="b49e" class="mj mk it kd b ke ms ki mt km mu kq mv ku mw ky mo mp mq mr bi translated"><strong class="kd iu">第六层</strong>是一个类似的<strong class="kd iu">全连接层，由<strong class="kd iu"> 84 个节点</strong>组成</strong>，从<em class="la">第五层的 120 个节点的输出中导出。</em></li><li id="2dfb" class="mj mk it kd b ke ms ki mt km mu kq mv ku mw ky mo mp mq mr bi translated"><strong class="kd iu">第七层(，或最后一层)</strong>包括<strong class="kd iu">将最后一层的输出分类成 10 类，与它最初被训练分类的 10 位数字</strong>相关。</li></ol><p id="35d5" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">它是当时实现的对手写数字进行分类的成功的数字识别算法之一。今天，在数据集上实现这种架构，使用各种库，可以获得大约 98.9 %的准确率。然而，当涉及到处理大尺寸图像和在大量类别的对象中进行分类时，该网络在计算成本或准确性方面不能有效地工作。</p><p id="b966" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated"><a class="ae kz" href="http://yann.lecun.com/exdb/publis/pdf/lecun-01a.pdf" rel="noopener ugc nofollow" target="_blank">链接到论文。</a></p><h1 id="88a6" class="lb lc it bd ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly bi translated">AlexNet:</h1><figure class="ma mb mc md gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi mx"><img src="../Images/32edac1d715f21ee08cd73f0a1eeefb0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Dh5NbFHB_yj_jTZbgMfryw.png"/></div></div><figcaption class="me mf gj gh gi mg mh bd b be z dk">AlexNet Architecture</figcaption></figure><p id="f536" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">ImageNet ILSVRC-2012 竞赛的<strong class="kd iu">获胜者 AlexNet 由<strong class="kd iu"> Alex Krizhevsky、Ilya Sutskever 和 Geoffery E. Hinton </strong>设计。它能够将<strong class="kd iu">前五名的错误率降低到 15.3 % </strong>，而该比赛亚军的错误率为 26.2%。该网络类似于 LeNet 架构，但与原始 LeNet 相比具有大量过滤器，因此能够在一大类对象中进行分类。此外，它使用“退出”而不是正则化来处理过度拟合。(退出实质上减少了在训练/学习过程中要考虑的参数数量的大小)。简而言之，让我们来定义这些层。</strong></p><p id="5f5e" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">它输入一个尺寸为<strong class="kd iu"> 224 X 224 </strong>的颜色<strong class="kd iu"> (RGB) </strong>图像。</p><ol class=""><li id="0edc" class="mj mk it kd b ke kf ki kj km ml kq mm ku mn ky mo mp mq mr bi translated">首先，尺寸为 11×11 且步距为 4 的<strong class="kd iu"> 96 个滤波器的<strong class="kd iu">卷积层(CL) </strong>。</strong></li><li id="ebeb" class="mj mk it kd b ke ms ki mt km mu kq mv ku mw ky mo mp mq mr bi translated">接下来，一个<strong class="kd iu"> Max-Pooling Layer (M-PL) </strong>的<strong class="kd iu">过滤器大小为 3 X 3，跨距= 2。</strong></li><li id="6e14" class="mj mk it kd b ke ms ki mt km mu kq mv ku mw ky mo mp mq mr bi translated">同样，256 的一个<strong class="kd iu"> CL 过滤<strong class="kd iu">大小为 5×5 且跨距= 4 的</strong>。</strong></li><li id="8767" class="mj mk it kd b ke ms ki mt km mu kq mv ku mw ky mo mp mq mr bi translated">然后，一个<strong class="kd iu"> M-PL 的滤镜大小为 3×3，步幅= 2。</strong></li><li id="c2b4" class="mj mk it kd b ke ms ki mt km mu kq mv ku mw ky mo mp mq mr bi translated">同样，384 个尺寸为 3×3 且跨距= 4 的滤波器的<strong class="kd iu"> CL。</strong></li><li id="062b" class="mj mk it kd b ke ms ki mt km mu kq mv ku mw ky mo mp mq mr bi translated">同样，384 个尺寸为 3×3 且跨距= 4 的滤波器的<strong class="kd iu"> CL。</strong></li><li id="2f5d" class="mj mk it kd b ke ms ki mt km mu kq mv ku mw ky mo mp mq mr bi translated">同样，256 个大小为 3×3 且跨距= 4 的滤波器的<strong class="kd iu"> CL。</strong></li><li id="96c8" class="mj mk it kd b ke ms ki mt km mu kq mv ku mw ky mo mp mq mr bi translated">然后，滤波器大小为 3×3 并且跨距= 2 的一个<strong class="kd iu"> M-Pl。</strong></li><li id="e680" class="mj mk it kd b ke ms ki mt km mu kq mv ku mw ky mo mp mq mr bi translated">当最后一层的输出被转换成输入层时，像对于由 9261 个节点组成的全连接块一样，<strong class="kd iu"> <em class="la">全连接</em>到具有 4096 个节点的隐藏层。</strong></li><li id="4e95" class="mj mk it kd b ke ms ki mt km mu kq mv ku mw ky mo mp mq mr bi translated">第一隐藏层再次<strong class="kd iu"> <em class="la">完全连接</em>到由 4096 个节点组成的另一隐藏层。</strong></li><li id="e496" class="mj mk it kd b ke ms ki mt km mu kq mv ku mw ky mo mp mq mr bi translated">最后一个隐藏层<strong class="kd iu"> <em class="la">完全连接</em>到输出层，实现 1000 个节点的“softmax 回归”。</strong></li></ol><p id="a3d1" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">现在，我所写的可能看起来与第一张图片(原始图片)中所示的架构大相径庭。仔细查看，对于两个管道(或两个部分)，<strong class="kd iu">在每个块输出中添加</strong>它们的通道号，并查看它是否与描述相匹配。造成这种差异的原因是 AlexNet 同时在<strong class="kd iu">两个 Nvidia GeForce GTX 580 GPU</strong>上进行训练，导致了架构的这两条流水线。<br/>这个网络有<strong class="kd iu">6230 万个参数</strong>，需要<strong class="kd iu">十亿个计算单元</strong>。这种巨大的计算成本导致在多个 GPU 上同时训练该架构以加速该过程。最初的网络只在两个 GPU 上训练。<br/> <strong class="kd iu">他们从网络中获得的一个有趣的结果</strong>是在分析了来自两个 GPU 的第一个卷积块的滤波器之后。他们发现，一个生成高频灰度特征，另一个生成低频颜色特征。</p><figure class="ma mb mc md gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi my"><img src="../Images/fdee3266a91b20c21cd7c7e97549804e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*sHJfrWQFX68lO4k_QqwNbw.png"/></div></div><figcaption class="me mf gj gh gi mg mh bd b be z dk">Visualization of few layers at the beginning of the AlexNet model.</figcaption></figure><p id="4e17" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated"><a class="ae kz" href="https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf" rel="noopener ugc nofollow" target="_blank">链接到论文。</a></p><h1 id="11db" class="lb lc it bd ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly bi translated">VGGNet 16:</h1><p id="ad36" class="pw-post-body-paragraph kb kc it kd b ke mz kg kh ki na kk kl km nb ko kp kq nc ks kt ku nd kw kx ky im bi translated">这个特殊的网络架构是由<strong class="kd iu"> Simonyan 和 Zisserman </strong>设计的<strong class="kd iu"> ILSVRC-2014 </strong>竞赛的<strong class="kd iu">亚军</strong>。很容易达到 5.1% 的<strong class="kd iu">前五名错误率。虽然这看起来很复杂，需要考虑一大堆参数，但实际上非常简单。当谈到特征提取时，开发人员非常喜欢它，因为它遵循简单的模式。关于卷积层和汇集层的过滤器尺寸和步距的基本<em class="la">超参数</em>是恒定的:<strong class="kd iu">卷积层</strong>具有尺寸为 3×3</strong>的<strong class="kd iu">过滤器和<strong class="kd iu">步距= 1 </strong>，而<strong class="kd iu">最大汇集层</strong>具有尺寸为 2×2</strong>的<strong class="kd iu">过滤器和<strong class="kd iu">步距= 2 </strong>。这些层以特定的顺序应用于整个网络。只有为每个<em class="la">卷积块</em>定义的滤波器数量不同。让我们来看看:</strong></p><figure class="ma mb mc md gt ju gh gi paragraph-image"><div class="gh gi ne"><img src="../Images/9541abddc69bd7697661efc88bf25d70.png" data-original-src="https://miro.medium.com/v2/resize:fit:1146/format:webp/1*D4tVL4jEmEIMJEldrK7QFw.jpeg"/></div><figcaption class="me mf gj gh gi mg mh bd b be z dk">The VGG16 Network Architecture.</figcaption></figure><p id="013a" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">它接收 224 X 224 尺寸的彩色(RGB)图像。</p><ol class=""><li id="635a" class="mj mk it kd b ke kf ki kj km ml kq mm ku mn ky mo mp mq mr bi translated"><strong class="kd iu">64 个滤波器的卷积层(CL)。</strong></li><li id="9c0f" class="mj mk it kd b ke ms ki mt km mu kq mv ku mw ky mo mp mq mr bi translated"><strong class="kd iu">CL 64 的再次过滤。</strong></li><li id="491c" class="mj mk it kd b ke ms ki mt km mu kq mv ku mw ky mo mp mq mr bi translated"><strong class="kd iu">最大池层(M-PL) </strong></li><li id="f2fd" class="mj mk it kd b ke ms ki mt km mu kq mv ku mw ky mo mp mq mr bi translated"><strong class="kd iu">128 个过滤器的 CL。</strong></li><li id="3fc3" class="mj mk it kd b ke ms ki mt km mu kq mv ku mw ky mo mp mq mr bi translated"><strong class="kd iu">CL 128 的再次过滤。</strong></li><li id="c0bd" class="mj mk it kd b ke ms ki mt km mu kq mv ku mw ky mo mp mq mr bi translated">M-PL。</li><li id="fb6e" class="mj mk it kd b ke ms ki mt km mu kq mv ku mw ky mo mp mq mr bi translated"><strong class="kd iu">256 个过滤器的 CL。</strong></li><li id="c6ec" class="mj mk it kd b ke ms ki mt km mu kq mv ku mw ky mo mp mq mr bi translated"><strong class="kd iu">CL 256 的再次过滤。</strong></li><li id="d74c" class="mj mk it kd b ke ms ki mt km mu kq mv ku mw ky mo mp mq mr bi translated"><strong class="kd iu">CL 256 的再次过滤。</strong></li><li id="4196" class="mj mk it kd b ke ms ki mt km mu kq mv ku mw ky mo mp mq mr bi translated"><strong class="kd iu"> M-PL。</strong></li><li id="df07" class="mj mk it kd b ke ms ki mt km mu kq mv ku mw ky mo mp mq mr bi translated"><strong class="kd iu">CL 512 过滤器。</strong></li><li id="d743" class="mj mk it kd b ke ms ki mt km mu kq mv ku mw ky mo mp mq mr bi translated"><strong class="kd iu">CL 512 的再次过滤。</strong></li><li id="396d" class="mj mk it kd b ke ms ki mt km mu kq mv ku mw ky mo mp mq mr bi translated"><strong class="kd iu">CL 512 的再次过滤。</strong></li><li id="7902" class="mj mk it kd b ke ms ki mt km mu kq mv ku mw ky mo mp mq mr bi translated"><strong class="kd iu"> M-PL。</strong></li><li id="ad90" class="mj mk it kd b ke ms ki mt km mu kq mv ku mw ky mo mp mq mr bi translated"><strong class="kd iu">CL 512 过滤器。</strong></li><li id="0dbc" class="mj mk it kd b ke ms ki mt km mu kq mv ku mw ky mo mp mq mr bi translated"><strong class="kd iu">CL 512 的再次过滤。</strong></li><li id="7bed" class="mj mk it kd b ke ms ki mt km mu kq mv ku mw ky mo mp mq mr bi translated"><strong class="kd iu">CL 512 的再次过滤。</strong></li><li id="5b85" class="mj mk it kd b ke ms ki mt km mu kq mv ku mw ky mo mp mq mr bi translated"><strong class="kd iu"> M-PL。</strong></li><li id="6ce6" class="mj mk it kd b ke ms ki mt km mu kq mv ku mw ky mo mp mq mr bi translated">最后一个池层的输出被送入由 4096 个节点组成的<strong class="kd iu"> <em class="la">全连接</em>隐藏层。</strong></li><li id="fb5e" class="mj mk it kd b ke ms ki mt km mu kq mv ku mw ky mo mp mq mr bi translated">这是<strong class="kd iu">再次<em class="la">完全连接</em>到另一个同样由 4096 个节点组成的隐藏层。</strong></li><li id="b738" class="mj mk it kd b ke ms ki mt km mu kq mv ku mw ky mo mp mq mr bi translated">这是<em class="la"> f </em> <strong class="kd iu"> <em class="la">完全连接</em>到实现“softmax 回归”的输出层，在 1000 类对象中分类。</strong></li></ol><p id="db7e" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">那有很多层。因此，它有将近 1 . 4 亿个参数需要处理，这使得实现这个网络的任务充满挑战。然而，预先训练的 VGGNet 的权重很容易获得，并且可以由开发人员在他们的项目中使用。</p><p id="408a" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated"><a class="ae kz" href="https://arxiv.org/pdf/1409.1556" rel="noopener ugc nofollow" target="_blank">链接到论文。</a></p><h1 id="931e" class="lb lc it bd ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly bi translated">GoogleNet / Inception:</h1><figure class="ma mb mc md gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi nf"><img src="../Images/766cbc3b7a1307afac756a1c2b2319bb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*mLVowQhnvAcIOEfJm3Zd-w.png"/></div></div><figcaption class="me mf gj gh gi mg mh bd b be z dk">Inception Network Architecture</figcaption></figure><p id="f42a" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated"><strong class="kd iu"> GoogleNet 或盗梦空间网络</strong>是 ILSVRC 2014 竞赛的<strong class="kd iu">冠军，取得了 6.67% </strong>的<strong class="kd iu">前五名错误率，几乎等同于人类水平的表现，太棒了！该模型由谷歌开发，包括原始 LeNet 架构的一个更智能的实现。这是基于先启模块的思想。<br/>这些模块背后的基本思想是，我们不是在不同的层中实现各种超参数的卷积层，而是一起进行所有的卷积，以输出包含来自所有滤波器操作的矩阵的结果。这是一个简单 inception 模块的图像，其中各种卷积层一起实现:</strong></p><figure class="ma mb mc md gt ju gh gi paragraph-image"><div class="gh gi ng"><img src="../Images/8e91c1c5a085fb003edbd1ac13e59edf.png" data-original-src="https://miro.medium.com/v2/resize:fit:612/format:webp/1*VWXMcnkhvg9kohOvLmGvkg.png"/></div><figcaption class="me mf gj gh gi mg mh bd b be z dk">The Inception module.</figcaption></figure><p id="39e6" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">级联输出由所有卷积运算的结果组成。请注意，实现了一个包含大小为 1 X 1 的滤波器的卷积层。这减小了图像的大小，在该图像上应用了包含大小为 5×5 的滤波器的另一个卷积层。这背后的原因是，计算单元的总数<strong class="kd iu">在很大程度上减少了</strong>。<br/>比如，当一只<strong class="kd iu"> Conv。32 层大小为 5×5 的滤波器</strong>被应用于某层<strong class="kd iu">的输出矩阵，其尺寸为 28×28×192</strong>。因此，总计算次数为<strong class="kd iu">28×28×32(输出矩阵大小)* 5×5×192(权重矩阵大小)</strong><strong class="kd iu">= 1.2 亿(接近)</strong>。<br/>而若一个<strong class="kd iu"> Conv。在实施 Conv 之前，首先应用大小为 1 X 1 </strong>的 16 个过滤器层。大小为 5×5 的 32 个滤波器的层，矩阵的<strong class="kd iu">大小减小到<strong class="kd iu">28×28×16</strong>，然后进行第二次卷积。<br/>因此总计算次数= {<strong class="kd iu">28×28×16(第一 conv 层的输出)* 1×1×192(第一 conv 层的权重矩阵的大小)</strong>}+{<strong class="kd iu">28×28×32(第二 conv 层的输出)* 5×5×16(第二 conv 层的权重矩阵的大小)</strong>}<br/>=<strong class="kd iu">240 万+1000 万(接近)</strong>因此，总成本降低了。<br/>上面显示的 inception 模块(图片很难查看，但是相信我，我没有发现更好的图片可以有更清晰的细节)，是这个网络的<strong class="kd iu">构建模块</strong>。仔细看看盗梦空间网络图像。这是一个由许多块<em class="la">开始块</em>组成的堆栈，在一些块之间有一些 Max-Pooling 层来改变图像的尺寸。<strong class="kd iu">最后一层是<em class="la">全连接</em>网络层</strong>，后面是<strong class="kd iu">“soft max 回归”，用于输出层</strong>中的分类。</strong></p><p id="a00a" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated"><a class="ae kz" href="https://arxiv.org/pdf/1409.4842" rel="noopener ugc nofollow" target="_blank">链接到论文。</a></p><h1 id="40ba" class="lb lc it bd ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly bi translated">ResNets:</h1><figure class="ma mb mc md gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi nh"><img src="../Images/f21d89fcc3451c80caf1738d7446fd04.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*nb6h9Jj40C5sJurX8TCvBA.png"/></div></div><figcaption class="me mf gj gh gi mg mh bd b be z dk">A 34-layer deep ResNet Architecture</figcaption></figure><p id="d707" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">大概是在 AlexNet 之后，CNN 架构开发领域最具开创性的发展发生在<strong class="kd iu"> ResNet 或者残余网络</strong>身上。这是基于“<em class="la">跳过连接</em>”的<strong class="kd iu">思想，并实现了<strong class="kd iu">重批量标准化</strong>，这有助于它有效地训练数千层，而不会降低长期性能。随着对更深层次网络的训练，问题出现了。<strong class="kd iu">“消失梯度”</strong>的问题，当梯度被反向传播时，重复的乘法操作使得梯度无限小。这导致性能下降。(看一看反向传播和梯度下降，以便清楚地了解在训练阶段实际发生了什么。)<br/>这个架构中注入的思想是“<em class="la">身份快捷连接</em>”，这意味着将一些层的结果转移到一些更深的层，跳过中间的一些其他层。这张图片可能有助于你理解这个想法:</strong></p><figure class="ma mb mc md gt ju gh gi paragraph-image"><div class="gh gi ni"><img src="../Images/8e70e44a010a68ae9024d560489eb2f7.png" data-original-src="https://miro.medium.com/v2/resize:fit:866/format:webp/1*k87z1JPRWyEauo2z_VNrgg.png"/></div><figcaption class="me mf gj gh gi mg mh bd b be z dk">The skip-connection in ResNet models.</figcaption></figure><p id="e608" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated"><strong class="kd iu">其背后的直觉是，较深的层不应该比其较浅的对应层产生更高的训练错误。跳过连接就是为了实现这个想法。该网络的开发人员实现了残差块的预激活变体，其中梯度可以通过快捷方式连接到早期层，从而减少“消失梯度”问题。希望这个图像能够解释它自己。这个<strong class="kd iu"> 1001 层深度 ResNet </strong>实现了<strong class="kd iu">3.57%</strong>的前 5 名错误率，在数据集上实际上击败了人类水平的性能。尽管它有很深的网络，但它提供了比大多数 VGGNet 架构更好的性能。它<strong class="kd iu">囊括了 2015 年 ILSVRC 在分类、检测和定位领域的所有奖项</strong>。</strong></p><p id="4f0e" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">希望你喜欢读它。请评论，如果有任何错误或错误的信息从我这边提供。欢迎任何形式的建议。</p><p id="d07d" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated"><a class="ae kz" href="https://arxiv.org/abs/1512.03385" rel="noopener ugc nofollow" target="_blank">链接到论文。</a></p><p id="8a8e" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">长命百岁，编码。</p></div></div>    
</body>
</html>