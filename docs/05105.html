<html>
<head>
<title>Computer Vision: Instance Segmentation with Mask R-CNN</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">计算机视觉:掩模 R-CNN 的实例分割</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/computer-vision-instance-segmentation-with-mask-r-cnn-7983502fcad1?source=collection_archive---------2-----------------------#2019-07-31">https://towardsdatascience.com/computer-vision-instance-segmentation-with-mask-r-cnn-7983502fcad1?source=collection_archive---------2-----------------------#2019-07-31</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><p id="b331" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">这是计算机视觉旅程 <strong class="js iu"> <em class="ko">系列<em class="ko">的第四部分。在本文中，我们将探索掩模 R-CNN，以了解实例分割如何与掩模 R-CNN 一起工作，然后使用 Keras </em> </em></strong>预测具有掩模 R-CNN 的图像的分割</p><p id="cc03" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><a class="ae kp" href="https://medium.com/datadriveninvestor/computer-vision-a-journey-from-cnn-to-mask-r-cnn-and-yolo-1d141eba6e04?source=post_page---------------------------" rel="noopener"> <strong class="js iu"> <em class="ko">第一部分——CNN，R-CNN，快速 R-CNN，更快 R-CNN </em> </strong> </a></p><p id="cb1b" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><a class="ae kp" href="https://medium.com/@arshren/computer-vision-a-journey-from-cnn-to-mask-r-cnn-and-yolo-part-2-b0b9e67762b1?source=post_page---------------------------" rel="noopener"> <strong class="js iu"> <em class="ko">第二部分——了解 YOLO、约洛夫 2、YOLO v3 </em> </strong> </a></p><p id="2224" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><a class="ae kp" href="https://medium.com/datadriveninvestor/object-detection-using-yolov3-using-keras-80bf35e61ce1" rel="noopener"> <strong class="js iu"> <em class="ko">第三部分——用 YOLOv3 使用 Keras 进行物体检测</em> </strong> </a></p><p id="bad9" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu"> <em class="ko">什么是实例切分，与语义切分有什么不同？</em> </strong></p><blockquote class="kq"><p id="4e3d" class="kr ks it bd kt ku kv kw kx ky kz kn dk translated"><strong class="ak">语义分割在像素级检测图像中存在的所有对象。输出具有不同类别或对象的区域</strong></p><p id="99e9" class="kr ks it bd kt ku kv kw kx ky kz kn dk translated">语义分割以语义上有意义的方式对像素进行分组。属于人、道路、建筑物、栅栏、自行车、汽车或树木的像素被单独分组。</p></blockquote><figure class="lb lc ld le lf lg gh gi paragraph-image"><div class="gh gi la"><img src="../Images/e233282f112f90d2bdbd44ffcfe26d32.png" data-original-src="https://miro.medium.com/v2/resize:fit:802/format:webp/1*tPseg2AQy6FkNe7m4jFmrg.png"/></div><figcaption class="lj lk gj gh gi ll lm bd b be z dk">Semantic Segmentation</figcaption></figure><blockquote class="kq"><p id="ae45" class="kr ks it bd kt ku ln lo lp lq lr kn dk translated"><strong class="ak">实例分割是识别图像中每个已知对象的每个对象实例</strong>。</p></blockquote><p id="92fc" class="pw-post-body-paragraph jq jr it js b jt ls jv jw jx lt jz ka kb lu kd ke kf lv kh ki kj lw kl km kn im bi translated">实例分割为图像的每个像素分配一个标签。它用于计算物体数量等任务</p><figure class="ly lz ma mb gt lg gh gi paragraph-image"><div class="gh gi lx"><img src="../Images/8ea033dfc3c5fceb4923b883bfed6ec3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1308/format:webp/1*nQIhlCKQuiqjji-NvNrxFw.png"/></div><figcaption class="lj lk gj gh gi ll lm bd b be z dk">Instance segmentation</figcaption></figure><p id="f9f0" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">实例分段需要</p><ul class=""><li id="c020" class="mc md it js b jt ju jx jy kb me kf mf kj mg kn mh mi mj mk bi translated">图像中所有对象的对象检测。这里的目标是对单个对象进行分类，并使用边界框对每个对象实例进行定位</li><li id="827c" class="mc md it js b jt ml jx mm kb mn kf mo kj mp kn mh mi mj mk bi translated">分割每个实例。这里的目标是在不区分对象实例的情况下，将每个像素分类到一组固定的类别中</li></ul><h1 id="83d2" class="mq mr it bd ms mt mu mv mw mx my mz na nb nc nd ne nf ng nh ni nj nk nl nm nn bi translated">屏蔽 R-CNN</h1><blockquote class="kq"><p id="8bdd" class="kr ks it bd kt ku kv kw kx ky kz kn dk translated">屏蔽 R-CNN 扩展更快 R-CNN。</p></blockquote><p id="1ba0" class="pw-post-body-paragraph jq jr it js b jt ls jv jw jx lt jz ka kb lu kd ke kf lv kh ki kj lw kl km kn im bi translated"><strong class="js iu"> <em class="ko">屏蔽 R-CNN 和更快的 R-CNN 有什么不同？</em> </strong></p><blockquote class="kq"><p id="1fce" class="kr ks it bd kt ku kv kw kx ky kz kn dk translated">掩模 R-CNN 具有用于以像素到像素的方式预测每个感兴趣区域(RoI)上的分割掩模的附加分支</p><p id="558e" class="kr ks it bd kt ku kv kw kx ky kz kn dk translated">更快的 R-CNN 不是为网络输入和输出之间的像素到像素对齐而设计的。</p></blockquote><p id="3be6" class="pw-post-body-paragraph jq jr it js b jt ls jv jw jx lt jz ka kb lu kd ke kf lv kh ki kj lw kl km kn im bi translated">更快的 R-CNN 有两个输出</p><ul class=""><li id="5bab" class="mc md it js b jt ju jx jy kb me kf mf kj mg kn mh mi mj mk bi translated">对于每个候选对象，类别标签和包围盒偏移；</li></ul><p id="5bbd" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">屏蔽 R-CNN 有三个输出</p><ul class=""><li id="abc4" class="mc md it js b jt ju jx jy kb me kf mf kj mg kn mh mi mj mk bi translated">对于每个候选对象，类别标签和包围盒偏移；</li><li id="e32c" class="mc md it js b jt ml jx mm kb mn kf mo kj mp kn mh mi mj mk bi translated">第三个输出是对象遮罩</li></ul><p id="3087" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu"> <em class="ko">口罩 R-CNN 和更快的 R-CNN 有什么相似之处？</em> </strong></p><blockquote class="kq"><p id="df16" class="kr ks it bd kt ku kv kw kx ky kz kn dk translated">-掩码 R-CNN 和更快的 R-CNN 都有一个用于分类和包围盒回归的分支。</p><p id="020e" class="kr ks it bd kt ku kv kw kx ky kz kn dk translated">-两者都使用 ResNet 101 架构从图像中提取特征。</p><p id="66c9" class="kr ks it bd kt ku kv kw kx ky kz kn dk translated">-两者都使用区域提议网络(RPN)来生成兴趣区域(RoI)</p></blockquote><p id="74db" class="pw-post-body-paragraph jq jr it js b jt ls jv jw jx lt jz ka kb lu kd ke kf lv kh ki kj lw kl km kn im bi translated"><strong class="js iu"><em class="ko">Mask R-CNN 是如何工作的？</em>T3】</strong></p><p id="f57f" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">掩模 R-CNN 模型分为两部分</p><ul class=""><li id="0cea" class="mc md it js b jt ju jx jy kb me kf mf kj mg kn mh mi mj mk bi translated"><strong class="js iu">区域提议网络(RPN)提出候选对象包围盒。</strong></li><li id="4274" class="mc md it js b jt ml jx mm kb mn kf mo kj mp kn mh mi mj mk bi translated"><strong class="js iu">二进制掩码分类器，为每个类别生成掩码</strong></li></ul><figure class="ly lz ma mb gt lg gh gi paragraph-image"><div role="button" tabindex="0" class="np nq di nr bf ns"><div class="gh gi no"><img src="../Images/68948a2c71a083d4d0373a9eb2f06384.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*UNSeS1DJ_UGlSQajfZBunQ.png"/></div></div><figcaption class="lj lk gj gh gi ll lm bd b be z dk">Mask R-CNN Source: <a class="ae kp" href="https://arxiv.org/pdf/1703.06870.pdf\" rel="noopener ugc nofollow" target="_blank">Mask R-CNN Paper</a></figcaption></figure><ul class=""><li id="bf1b" class="mc md it js b jt ju jx jy kb me kf mf kj mg kn mh mi mj mk bi translated">图像通过 CNN 运行以生成特征地图。</li><li id="84fa" class="mc md it js b jt ml jx mm kb mn kf mo kj mp kn mh mi mj mk bi translated">区域提议网络(RPN)使用一个 CNN 来生成多个感兴趣区域(RoI ),使用一个轻量级的二进制分类器。它在图像上使用了 9 个定位框。分类器返回对象/非对象分数。非最大抑制应用于具有高客观性分数的锚点</li><li id="7686" class="mc md it js b jt ml jx mm kb mn kf mo kj mp kn mh mi mj mk bi translated">RoI 对准网络输出多个边界框而不是单个确定的边界框，并将它们扭曲成固定的尺寸。</li><li id="d507" class="mc md it js b jt ml jx mm kb mn kf mo kj mp kn mh mi mj mk bi translated">然后将扭曲的要素输入到完全连接的图层中，使用 softmax 进行分类，并使用回归模型进一步优化边界框预测</li><li id="eb10" class="mc md it js b jt ml jx mm kb mn kf mo kj mp kn mh mi mj mk bi translated">扭曲的特征也被送入掩模分类器，该分类器由两个 CNN 组成，为每个 RoI 输出一个二进制掩模。掩码分类器允许网络为每个类别生成掩码，而不会在类别之间产生竞争</li></ul><figure class="ly lz ma mb gt lg gh gi paragraph-image"><div role="button" tabindex="0" class="np nq di nr bf ns"><div class="gh gi nt"><img src="../Images/548973a110f779aaaba74266ff670443.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ui1roGvi_F77TY07PdaI8w.png"/></div></div></figure><h1 id="858a" class="mq mr it bd ms mt mu mv mw mx my mz na nb nc nd ne nf ng nh ni nj nk nl nm nn bi translated">锚箱</h1><p id="5562" class="pw-post-body-paragraph jq jr it js b jt nu jv jw jx nv jz ka kb nw kd ke kf nx kh ki kj ny kl km kn im bi translated">Mask R-CNN 使用锚定框来检测图像中的多个对象、不同比例的对象以及重叠的对象。这提高了目标检测的速度和效率。</p><p id="1ad1" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">锚点<em class="ko">框</em>是一组具有一定高度和宽度的预定义边界框。定义这些框是为了捕捉要检测的特定对象类的比例和纵横比。</p><figure class="ly lz ma mb gt lg gh gi paragraph-image"><div role="button" tabindex="0" class="np nq di nr bf ns"><div class="gh gi nz"><img src="../Images/6373dbac73766b6e4c59e4d8609dc445.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ryi4m758IblLvDLhl_l9aA.png"/></div></div><figcaption class="lj lk gj gh gi ll lm bd b be z dk">Image with multiple anchor boxes Source: <a class="ae kp" href="https://github.com/matterport/Mask_RCNN" rel="noopener ugc nofollow" target="_blank">matterport</a></figcaption></figure><p id="577a" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">为了预测图像中的多个对象或对象的多个实例，Mask R-CNN 进行了数千次预测。最终的目标检测是通过去除属于背景类的锚框来完成的，剩余的锚框通过它们的置信度得分来过滤。我们发现 IoU 大于 0.5 的锚盒。使用下面解释的非最大抑制来选择具有最大置信度得分的锚框</p><h1 id="38be" class="mq mr it bd ms mt mu mv mw mx my mz na nb nc nd ne nf ng nh ni nj nk nl nm nn bi translated">并集上的交集— IoU</h1><p id="d7ef" class="pw-post-body-paragraph jq jr it js b jt nu jv jw jx nv jz ka kb nw kd ke kf nx kh ki kj ny kl km kn im bi translated">IoU 通过算法计算两个边界框的并集上的交集，即地面真实的边界框和预测框的边界框</p><figure class="ly lz ma mb gt lg gh gi paragraph-image"><div class="gh gi oa"><img src="../Images/05eb07a822a38ed04ee1e3b0636a74a8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1132/format:webp/0*UAaCsD7EiVef8bBM.png"/></div></figure><p id="173b" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu">当 IoU 为 1 时，这将意味着预测的和真实边界框完全重叠。</strong></p><p id="71b4" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">为了在图像中检测一次对象，<strong class="js iu">非最大抑制会考虑 IoU &gt;为 0.5 </strong>的所有边界框</p><p id="82e5" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu"> <em class="ko">如果我有多个 IoU 大于 0.5 的边界框怎么办？</em> </strong></p><h1 id="f411" class="mq mr it bd ms mt mu mv mw mx my mz na nb nc nd ne nf ng nh ni nj nk nl nm nn bi translated">非最大抑制</h1><ul class=""><li id="8228" class="mc md it js b jt nu jx nv kb ob kf oc kj od kn mh mi mj mk bi translated">非最大抑制将移除 IoU 小于或等于 0.5 的所有边界框</li><li id="6108" class="mc md it js b jt ml jx mm kb mn kf mo kj mp kn mh mi mj mk bi translated">选取 IoU 值最高的边界框，并抑制其他边界框以识别同一对象</li></ul><figure class="ly lz ma mb gt lg gh gi paragraph-image"><div role="button" tabindex="0" class="np nq di nr bf ns"><div class="gh gi oe"><img src="../Images/24a4eeb8559aeafdaa795cb4351d4652.png" data-original-src="https://miro.medium.com/v2/resize:fit:1398/format:webp/1*VVreunjbEtKAN79lE-v4aw.png"/></div></div><figcaption class="lj lk gj gh gi ll lm bd b be z dk">Bounding refinement after applying Non Max Suppression</figcaption></figure><h1 id="bbc9" class="mq mr it bd ms mt mu mv mw mx my mz na nb nc nd ne nf ng nh ni nj nk nl nm nn bi translated">使用 Keras 屏蔽 R-CNN 代码</h1><p id="05dc" class="pw-post-body-paragraph jq jr it js b jt nu jv jw jx nv jz ka kb nw kd ke kf nx kh ki kj ny kl km kn im bi translated">为此我们使用<strong class="js iu"/><a class="ae kp" href="https://github.com/matterport/Mask_RCNN" rel="noopener ugc nofollow" target="_blank"><strong class="js iu">matter port Mask R-CNN</strong></a><strong class="js iu">。</strong>本例中使用的 Mask R-CNN 模型是在 COCO 数据集上预训练的。</p><p id="562b" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu">步骤 1:克隆屏蔽 R-CNN 库</strong></p><pre class="ly lz ma mb gt of og oh oi aw oj bi"><span id="2576" class="ok mr it og b gy ol om l on oo">git clone <a class="ae kp" href="https://github.com/matterport/Mask_RCNN.git" rel="noopener ugc nofollow" target="_blank">https://github.com/matterport/Mask_RCNN.git</a></span><span id="969a" class="ok mr it og b gy op om l on oo">cd Mask_RCNN</span><span id="fdfb" class="ok mr it og b gy op om l on oo">$ python setup.py install</span></pre><p id="beaa" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu">第二步:从</strong><a class="ae kp" href="https://github.com/matterport/Mask_RCNN/releases/download/v2.0/mask_rcnn_coco.h5" rel="noopener ugc nofollow" target="_blank"><strong class="js iu">matter port</strong></a>下载 COCO 模型的预训练权重。将文件放在名为“mask_rcnn_coco.h5”的 Mask_RCNN 文件夹中</p><p id="cd89" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu">第三步:导入所需的库</strong></p><pre class="ly lz ma mb gt of og oh oi aw oj bi"><span id="77a0" class="ok mr it og b gy ol om l on oo"># import the necessary packages<br/>from mrcnn.config import Config<br/>from mrcnn import model as modellib<br/>from mrcnn import visualize<br/>import mrcnn<br/>import numpy as np<br/>import colorsys<br/>import argparse<br/>import imutils<br/>import random<br/>import cv2<br/>import os</span><span id="73fa" class="ok mr it og b gy op om l on oo">from matplotlib import pyplot<br/>from matplotlib.patches import Rectangle</span><span id="c488" class="ok mr it og b gy op om l on oo">%matplotlib inline</span></pre><p id="8fd9" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu">第四步:</strong>我们创建一个<strong class="js iu"><em class="ko">myMaskRCNNConfig</em></strong>类，它继承了<strong class="js iu"><em class="ko">Mask R-CNN Config</em></strong>类。</p><p id="8c92" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">因为我正在使用 CPU，所以设置 GPU_COUNT=1</p><p id="ee78" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">COCO 数据集有 80 个标签，所以我们将 NUM_CLASSES 设置为 80 + 1(用于背景)</p><pre class="ly lz ma mb gt of og oh oi aw oj bi"><span id="2c73" class="ok mr it og b gy ol om l on oo">class myMaskRCNNConfig(Config):<br/> # give the configuration a recognizable name<br/> <strong class="og iu">NAME = “MaskRCNN_inference”</strong><br/> <br/> # set the number of GPUs to use along with the number of images<br/> # per GPU<br/> <strong class="og iu">GPU_COUNT = 1</strong><br/> <strong class="og iu">IMAGES_PER_GPU = 1</strong><br/> <br/> # number of classes (we would normally add +1 for the background<br/> # but the background class is *already* included in the class<br/> # names)<br/> <strong class="og iu">NUM_CLASSES = 1+80</strong></span></pre><p id="0a72" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu">步骤 5:创建一个<em class="ko"> myMaskRCNNConfig </em>类</strong>的实例</p><pre class="ly lz ma mb gt of og oh oi aw oj bi"><span id="efb5" class="ok mr it og b gy ol om l on oo">config = myMaskRCNNConfig()</span></pre><p id="066b" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu">步骤 6:使用我们创建的配置实例</strong>初始化<em class="ko">“推理”</em>的屏蔽 R-CNN 模型</p><pre class="ly lz ma mb gt of og oh oi aw oj bi"><span id="322c" class="ok mr it og b gy ol om l on oo">print(“loading  weights for Mask R-CNN model…”)<br/><strong class="og iu">model = modellib.MaskRCNN(mode=”inference”, config=config, model_dir=’./’)</strong></span></pre><p id="02ff" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu">第七步:为屏蔽 R-CNN 加载权重。这些是 COCO 数据集</strong>的预训练权重</p><pre class="ly lz ma mb gt of og oh oi aw oj bi"><span id="cb77" class="ok mr it og b gy ol om l on oo"><strong class="og iu">model.load_weights(‘mask_rcnn_coco.h5’, by_name=True)</strong></span></pre><p id="d77e" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu">步骤 8:定义 coco 模型的 80 个类和 1 个用于背景(BG) </strong></p><pre class="ly lz ma mb gt of og oh oi aw oj bi"><span id="5772" class="ok mr it og b gy ol om l on oo"><strong class="og iu">class_names </strong>= [<strong class="og iu">‘BG’</strong>, ‘person’, ‘bicycle’, ‘car’, ‘motorcycle’, ‘airplane’,<br/> ‘bus’, ‘train’, ‘truck’, ‘boat’, ‘traffic light’,<br/> ‘fire hydrant’, ‘stop sign’, ‘parking meter’, ‘bench’, ‘bird’,<br/> ‘cat’, ‘dog’, ‘horse’, ‘sheep’, ‘cow’, ‘elephant’, ‘bear’,<br/> ‘zebra’, ‘giraffe’, ‘backpack’, ‘umbrella’, ‘handbag’, ‘tie’,<br/> ‘suitcase’, ‘frisbee’, ‘skis’, ‘snowboard’, ‘sports ball’,<br/> ‘kite’, ‘baseball bat’, ‘baseball glove’, ‘skateboard’,<br/> ‘surfboard’, ‘tennis racket’, ‘bottle’, ‘wine glass’, ‘cup’,<br/> ‘fork’, ‘knife’, ‘spoon’, ‘bowl’, ‘banana’, ‘apple’,<br/> ‘sandwich’, ‘orange’, ‘broccoli’, ‘carrot’, ‘hot dog’, ‘pizza’,<br/> ‘donut’, ‘cake’, ‘chair’, ‘couch’, ‘potted plant’, ‘bed’,<br/> ‘dining table’, ‘toilet’, ‘tv’, ‘laptop’, ‘mouse’, ‘remote’,<br/> ‘keyboard’, ‘cell phone’, ‘microwave’, ‘oven’, ‘toaster’,<br/> ‘sink’, ‘refrigerator’, ‘book’, ‘clock’, ‘vase’, ‘scissors’,<br/> ‘teddy bear’, ‘hair drier’, ‘toothbrush’]</span></pre><p id="f22e" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu">步骤 9:为图像中检测到的对象绘制方框的功能</strong></p><pre class="ly lz ma mb gt of og oh oi aw oj bi"><span id="e3e8" class="ok mr it og b gy ol om l on oo"># draw an image with detected objects<br/><br/><strong class="og iu">def draw_image_with_boxes(filename, boxes_list):</strong><br/>     # load the image<br/>     data = pyplot.imread(filename)<br/>     # plot the image<br/>     pyplot.imshow(data)<br/>     # get the context for drawing boxes<br/>     ax = pyplot.gca()<br/>     # plot each box<br/>     for box in boxes_list:<br/>          # get coordinates<br/>          y1, x1, y2, x2 = box<br/>          # calculate width and height of the box<br/>          width, height = x2 - x1, y2 - y1<br/>          # create the shape<br/>          rect = Rectangle((x1, y1), width, height, fill=False, color='red', lw=5)<br/>          # draw the box<br/>          ax.add_patch(rect)<br/>     # show the plot<br/>     pyplot.show()</span></pre><p id="d108" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu">步骤 10:我们最终做出预测，并在检测到的物体周围画出包围盒</strong></p><p id="1d63" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">加载图像，然后将其转换为 numpy 数组</p><pre class="ly lz ma mb gt of og oh oi aw oj bi"><span id="d38f" class="ok mr it og b gy ol om l on oo">from keras.preprocessing.image import load_img<br/>from keras.preprocessing.image import img_to_array</span><span id="0b82" class="ok mr it og b gy op om l on oo">img = load_img(‘donuts.jpg’)</span><span id="45a8" class="ok mr it og b gy op om l on oo">pyplot.imshow(img)</span><span id="02f8" class="ok mr it og b gy op om l on oo">img = img_to_array(img)</span></pre><figure class="ly lz ma mb gt lg gh gi paragraph-image"><div class="gh gi oq"><img src="../Images/9b2aef467dc356a6f14d3949bac4074e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1010/format:webp/1*pA_hNl4Gn3GepxNa9-vpPg.png"/></div><figcaption class="lj lk gj gh gi ll lm bd b be z dk">Original image of Donuts</figcaption></figure><p id="aab8" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">我们现在做出预测</p><pre class="ly lz ma mb gt of og oh oi aw oj bi"><span id="2c0a" class="ok mr it og b gy ol om l on oo"># make prediction<br/>results = model.detect([img], verbose=0)</span></pre><p id="aa5a" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu">结果是我们传递给<em class="ko"> detect() </em>函数的图像的字典。</strong></p><p id="a5f1" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">字典中有边界框、遮罩、类别和分数的关键字。每个键指向图像中检测到的多个可能对象的列表。</p><p id="449e" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">这本字典的关键字是</p><ul class=""><li id="86e4" class="mc md it js b jt ju jx jy kb me kf mf kj mg kn mh mi mj mk bi translated"><strong class="js iu"><em class="ko">ROI</em></strong>’:被检测物体的感兴趣区域(ROI)。</li><li id="7360" class="mc md it js b jt ml jx mm kb mn kf mo kj mp kn mh mi mj mk bi translated"><strong class="js iu"> <em class="ko">遮罩</em></strong>’:被检测对象的遮罩。</li><li id="92a9" class="mc md it js b jt ml jx mm kb mn kf mo kj mp kn mh mi mj mk bi translated"><strong class="js iu"><em class="ko">Class _ ids</em></strong>’:被检测对象的类整数。</li><li id="288d" class="mc md it js b jt ml jx mm kb mn kf mo kj mp kn mh mi mj mk bi translated"><strong class="js iu"> <em class="ko">分数</em></strong>’:每个预测类别的置信概率。</li></ul><p id="3d00" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu">步骤 11:通过在感兴趣区域(ROI)周围绘制边界框来可视化结果</strong></p><pre class="ly lz ma mb gt of og oh oi aw oj bi"><span id="efac" class="ok mr it og b gy ol om l on oo"># visualize the results<br/>draw_image_with_boxes('donuts.jpg', results[0]['rois'])</span></pre><figure class="ly lz ma mb gt lg gh gi paragraph-image"><div class="gh gi or"><img src="../Images/27e8cdce426e8fe7e7c878453e1a6aab.png" data-original-src="https://miro.medium.com/v2/resize:fit:1126/format:webp/1*2jN0K5vB6nHIWm7QitCRMQ.png"/></div></figure><p id="24c8" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">画面具</p><pre class="ly lz ma mb gt of og oh oi aw oj bi"><span id="154e" class="ok mr it og b gy ol om l on oo"># get dictionary for first prediction<br/><strong class="og iu">from mrcnn.visualize import display_instances<br/>r = results[0]</strong></span><span id="9229" class="ok mr it og b gy op om l on oo"># show photo with bounding boxes, masks, class labels and scores<br/><strong class="og iu">display_instances(img, r[‘rois’], r[‘masks’], r[‘class_ids’], class_names, r[‘scores’])</strong></span></pre><figure class="ly lz ma mb gt lg gh gi paragraph-image"><div class="gh gi os"><img src="../Images/c260190ee5758e271d73d5869321d9f5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1302/format:webp/1*KXvvBy7BuF8N49ygjmQSuw.png"/></div><figcaption class="lj lk gj gh gi ll lm bd b be z dk">Bounding boxes, masks, class and their scores using Mask R-CNN</figcaption></figure><p id="4255" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">要查找对象和类的数量</p><pre class="ly lz ma mb gt of og oh oi aw oj bi"><span id="840e" class="ok mr it og b gy ol om l on oo">classes= r['class_ids']<br/>print("Total Objects found", len(classes))<br/>for i in range(len(classes)):<br/>    print(class_names[classes[i]])</span></pre><figure class="ly lz ma mb gt lg gh gi paragraph-image"><div class="gh gi ot"><img src="../Images/7adb2ba25ecc97a9e24c892de9c45ee8.png" data-original-src="https://miro.medium.com/v2/resize:fit:552/format:webp/1*hxvmA3uhGWDxvZgGISgM1A.png"/></div><figcaption class="lj lk gj gh gi ll lm bd b be z dk">No. of objects and their classes</figcaption></figure><p id="912e" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><a class="ae kp" href="https://github.com/arshren/Mask_RCNN/blob/master/m_rcnn.ipynb" rel="noopener ugc nofollow" target="_blank">使用 github 提供的掩码 R-CNN 进行预测的代码</a></p><h2 id="df68" class="ok mr it bd ms ou ov dn mw ow ox dp na kb oy oz ne kf pa pb ni kj pc pd nm pe bi translated">参考资料:</h2><p id="9f34" class="pw-post-body-paragraph jq jr it js b jt nu jv jw jx nv jz ka kb nw kd ke kf nx kh ki kj ny kl km kn im bi translated"><a class="ae kp" href="https://arxiv.org/pdf/1703.06870.pdf" rel="noopener ugc nofollow" target="_blank">面具 R-CNN 纸</a></p><p id="de9d" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><a class="ae kp" href="https://engineering.matterport.com/splash-of-color-instance-segmentation-with-mask-r-cnn-and-tensorflow-7c761e238b46" rel="noopener ugc nofollow" target="_blank">https://engineering . matter port . com/splash-of-color-instance-segmentation-with-mask-r-CNN-and-tensor flow-7c 761 e 238 b 46</a></p><p id="6389" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><a class="ae kp" href="https://medium.com/@jonathan_hui/image-segmentation-with-mask-r-cnn-ebe6d793272" rel="noopener">https://medium . com/@ Jonathan _ hui/image-segmentation-with-mask-r-CNN-ebe6d 793272</a></p><p id="b09b" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><a class="ae kp" href="http://www.cs.toronto.edu/~urtasun/courses/CSC2541/08_instance.pdf" rel="noopener ugc nofollow" target="_blank">http://www . cs . Toronto . edu/~ urta sun/courses/CSC 2541/08 _ instance . pdf</a></p><div class="pf pg gp gr ph pi"><a href="https://machinelearningmastery.com/how-to-perform-object-detection-in-photographs-with-mask-r-cnn-in-keras/" rel="noopener  ugc nofollow" target="_blank"><div class="pj ab fo"><div class="pk ab pl cl cj pm"><h2 class="bd iu gy z fp pn fr fs po fu fw is bi translated">如何在 Keras 中使用 Mask R-CNN 进行照片中的对象检测</h2><div class="pp l"><h3 class="bd b gy z fp pn fr fs po fu fw dk translated">目标检测是计算机视觉中的一项任务，涉及识别一个或多个目标的存在、位置和类型</h3></div><div class="pq l"><p class="bd b dl z fp pn fr fs po fu fw dk translated">machinelearningmastery.com</p></div></div><div class="pr l"><div class="ps l pt pu pv pr pw lh pi"/></div></div></a></div></div></div>    
</body>
</html>