<html>
<head>
<title>Review: Shake-Shake Regularization (Image Classification)</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">综述:抖动正则化(图像分类)</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/review-shake-shake-regularization-image-classification-d22bb8587953?source=collection_archive---------17-----------------------#2019-05-13">https://towardsdatascience.com/review-shake-shake-regularization-image-classification-d22bb8587953?source=collection_archive---------17-----------------------#2019-05-13</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="db09" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">在训练过程中给梯度添加噪声的概念，胜过<a class="ae kf" rel="noopener" target="_blank" href="/review-wrns-wide-residual-networks-image-classification-d3feb3fb2004"> WRN </a>、<a class="ae kf" rel="noopener" target="_blank" href="/review-resnext-1st-runner-up-of-ilsvrc-2016-image-classification-15d7f17b42ac">雷斯 NeXt </a>和<a class="ae kf" rel="noopener" target="_blank" href="/review-densenet-image-classification-b6631a8ef803">登森特</a>。</h2></div><p id="70b4" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi lc translated"><span class="l ld le lf bm lg lh li lj lk di">在</span>这个故事中，来自<strong class="ki ir">伦敦商学院</strong>的<strong class="ki ir"> Xavier Gastaldi </strong>的<strong class="ki ir"> Shake-Shake 正则化(Shake-Shake) </strong>被简要回顾。本文的动机是在输入图像上应用数据增强，也可能<strong class="ki ir">将数据增强技术应用于内部表示</strong>。</p><p id="0725" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated">在现有技术中发现，在训练期间向梯度添加噪声有助于复杂神经网络的训练和泛化。并且<strong class="ki ir">摇动-摇动正则化可以被视为这个概念的扩展，其中梯度噪声被一种形式的梯度增强所取代</strong>。这是<strong class="ki ir"> 2017 ICLR 研讨会</strong>上的一篇论文，被引用<strong class="ki ir"> 10 多次</strong>。而<strong class="ki ir"> 2017 arXiv </strong>中的长版已经获得了<strong class="ki ir"> 100 次引用</strong>。(<a class="ll lm ep" href="https://medium.com/u/aff72a0c1243?source=post_page-----d22bb8587953--------------------------------" rel="noopener" target="_blank"> Sik-Ho Tsang </a> @中)</p></div><div class="ab cl ln lo hu lp" role="separator"><span class="lq bw bk lr ls lt"/><span class="lq bw bk lr ls lt"/><span class="lq bw bk lr ls"/></div><div class="ij ik il im in"><h1 id="1204" class="lu lv iq bd lw lx ly lz ma mb mc md me jw mf jx mg jz mh ka mi kc mj kd mk ml bi translated">概述</h1><ol class=""><li id="e6f7" class="mm mn iq ki b kj mo km mp kp mq kt mr kx ms lb mt mu mv mw bi translated"><strong class="ki ir">抖动调整</strong></li><li id="1aaa" class="mm mn iq ki b kj mx km my kp mz kt na kx nb lb mt mu mv mw bi translated"><strong class="ki ir">实验结果</strong></li><li id="b6c0" class="mm mn iq ki b kj mx km my kp mz kt na kx nb lb mt mu mv mw bi translated"><strong class="ki ir">进一步评估</strong></li></ol></div><div class="ab cl ln lo hu lp" role="separator"><span class="lq bw bk lr ls lt"/><span class="lq bw bk lr ls lt"/><span class="lq bw bk lr ls"/></div><div class="ij ik il im in"><h1 id="8980" class="lu lv iq bd lw lx ly lz ma mb mc md me jw mf jx mg jz mh ka mi kc mj kd mk ml bi translated"><strong class="ak"> 1。抖动调整</strong></h1><figure class="nd ne nf ng gt nh gh gi paragraph-image"><div role="button" tabindex="0" class="ni nj di nk bf nl"><div class="gh gi nc"><img src="../Images/f547f6c8230709df7ca9cc034ea27e26.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*bv237F-CqdOXlPe4FwmWXg.png"/></div></div><figcaption class="no np gj gh gi nq nr bd b be z dk"><strong class="bd ns">Left: Forward training pass. Center: Backward training pass. Right: At test time.</strong></figcaption></figure><ul class=""><li id="15e9" class="mm mn iq ki b kj kk km kn kp nt kt nu kx nv lb nw mu mv mw bi translated">特别是，本文研究的<strong class="ki ir">三分支</strong><a class="ae kf" rel="noopener" target="_blank" href="/review-resnet-winner-of-ilsvrc-2015-image-classification-localization-detection-e39402bfa5d8"><strong class="ki ir">ResNet</strong></a><strong class="ki ir"/>如上图所示，方程如下:</li></ul><figure class="nd ne nf ng gt nh gh gi paragraph-image"><div class="gh gi nx"><img src="../Images/4786de759e8656d31447dd1ab1b74925.png" data-original-src="https://miro.medium.com/v2/resize:fit:1062/format:webp/1*2IQmCFm52k70yavVoaKU2g.png"/></div></figure><ul class=""><li id="206c" class="mm mn iq ki b kj kk km kn kp nt kt nu kx nv lb nw mu mv mw bi translated">通过抖动调整，增加了<em class="ny"> α </em>:</li></ul><figure class="nd ne nf ng gt nh gh gi paragraph-image"><div class="gh gi nz"><img src="../Images/0b89335b107d8097e89caba8b3d8b60e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1328/format:webp/1*nMAUjPWfCJ5_WmFyz5wTnQ.png"/></div></figure><ul class=""><li id="8f49" class="mm mn iq ki b kj kk km kn kp nt kt nu kx nv lb nw mu mv mw bi translated"><em class="ny"> α </em>在测试时间内设置为 0.5，就像 Dropout 一样。</li></ul></div><div class="ab cl ln lo hu lp" role="separator"><span class="lq bw bk lr ls lt"/><span class="lq bw bk lr ls lt"/><span class="lq bw bk lr ls"/></div><div class="ij ik il im in"><h1 id="c015" class="lu lv iq bd lw lx ly lz ma mb mc md me jw mf jx mg jz mh ka mi kc mj kd mk ml bi translated"><strong class="ak"> 2。实验结果</strong></h1><h2 id="3cda" class="oa lv iq bd lw ob oc dn ma od oe dp me kp of og mg kt oh oi mi kx oj ok mk ol bi translated">2.1.CIFAR-10</h2><ul class=""><li id="d7d7" class="mm mn iq ki b kj mo km mp kp mq kt mr kx ms lb nw mu mv mw bi translated">使用 26 个 2×32d <a class="ae kf" rel="noopener" target="_blank" href="/review-resnet-winner-of-ilsvrc-2015-image-classification-localization-detection-e39402bfa5d8"> ResNet </a>(即网络深度为 26，2 个剩余分支，第一个剩余块宽度为 32)。</li><li id="1633" class="mm mn iq ki b kj mx km my kp mz kt na kx nb lb nw mu mv mw bi translated"><strong class="ki ir">摇动</strong>:在通过之前，所有的缩放系数都被新的随机数覆盖。</li><li id="51f1" class="mm mn iq ki b kj mx km my kp mz kt na kx nb lb nw mu mv mw bi translated"><strong class="ki ir">偶数</strong>:所有缩放系数在通过之前都设置为 0.5。</li><li id="c502" class="mm mn iq ki b kj mx km my kp mz kt na kx nb lb nw mu mv mw bi translated"><strong class="ki ir">保持</strong>:对于后向通道，保持前向通道使用的缩放系数。</li><li id="888a" class="mm mn iq ki b kj mx km my kp mz kt na kx nb lb nw mu mv mw bi translated"><strong class="ki ir">批次</strong>:对于每个残差块<em class="ny"> i </em>，相同的缩放系数应用于小批次中的所有图像。</li><li id="3fcc" class="mm mn iq ki b kj mx km my kp mz kt na kx nb lb nw mu mv mw bi translated"><strong class="ki ir">图像</strong>:对于每个残差块<em class="ny"> i </em>，对小批量中的每个图像应用不同的缩放系数。</li></ul><figure class="nd ne nf ng gt nh gh gi paragraph-image"><div role="button" tabindex="0" class="ni nj di nk bf nl"><div class="gh gi om"><img src="../Images/3c79c727bb28776d96b8913b5fdc2c65.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*qCWvjfnr6tHqA5F8YeVxzA.png"/></div></div><figcaption class="no np gj gh gi nq nr bd b be z dk"><strong class="bd ns">Error Rates of CIFAR-10</strong></figcaption></figure><ul class=""><li id="0381" class="mm mn iq ki b kj kk km kn kp nt kt nu kx nv lb nw mu mv mw bi translated">在向前传球时使用 Shake 有更好的表现。</li><li id="8037" class="mm mn iq ki b kj mx km my kp mz kt na kx nb lb nw mu mv mw bi translated">并且<strong class="ki ir">Shake-Shake-Image(</strong>S-S-I<strong class="ki ir">)</strong>对于 26 个 2×64d <a class="ae kf" rel="noopener" target="_blank" href="/review-resnet-winner-of-ilsvrc-2015-image-classification-localization-detection-e39402bfa5d8"> ResNet </a>和 26 个 2×96d <a class="ae kf" rel="noopener" target="_blank" href="/review-resnet-winner-of-ilsvrc-2015-image-classification-localization-detection-e39402bfa5d8"> ResNet </a>获得最佳结果。</li></ul><h2 id="66b5" class="oa lv iq bd lw ob oc dn ma od oe dp me kp of og mg kt oh oi mi kx oj ok mk ol bi translated">2.2.西发尔-100</h2><figure class="nd ne nf ng gt nh gh gi paragraph-image"><div role="button" tabindex="0" class="ni nj di nk bf nl"><div class="gh gi on"><img src="../Images/22361b9f710fcd90d7177c84430a06e6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*5ZFrLrIoRQvTHZu3y3yLfQ.png"/></div></div><figcaption class="no np gj gh gi nq nr bd b be z dk"><strong class="bd ns">Error Rates of CIFAR-100</strong></figcaption></figure><ul class=""><li id="9cfd" class="mm mn iq ki b kj kk km kn kp nt kt nu kx nv lb nw mu mv mw bi translated">在向前传球时再次使用摇动可以提高性能。</li><li id="f1a7" class="mm mn iq ki b kj mx km my kp mz kt na kx nb lb nw mu mv mw bi translated">特别地，抖动平均图像(S-E-I)是最好的。</li></ul><h2 id="d4d2" class="oa lv iq bd lw ob oc dn ma od oe dp me kp of og mg kt oh oi mi kx oj ok mk ol bi translated">2.3.与最先进方法的比较</h2><figure class="nd ne nf ng gt nh gh gi paragraph-image"><div role="button" tabindex="0" class="ni nj di nk bf nl"><div class="gh gi oo"><img src="../Images/aebb09ec8b41ed475434f946db194580.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Mna6h47vyPUHWy_WAOzdIg.png"/></div></div><figcaption class="no np gj gh gi nq nr bd b be z dk"><strong class="bd ns">Test error (%) and Model Size on CIFAR</strong></figcaption></figure><ul class=""><li id="79d1" class="mm mn iq ki b kj kk km kn kp nt kt nu kx nv lb nw mu mv mw bi translated">在 CIFAR-10 上，S-S-I 的表现超过了<a class="ae kf" rel="noopener" target="_blank" href="/review-wrns-wide-residual-networks-image-classification-d3feb3fb2004"> WRN </a>、<a class="ae kf" rel="noopener" target="_blank" href="/review-resnext-1st-runner-up-of-ilsvrc-2016-image-classification-15d7f17b42ac">雷斯 NeXt </a>和<a class="ae kf" rel="noopener" target="_blank" href="/review-densenet-image-classification-b6631a8ef803">登盛内特</a>。</li><li id="9ebf" class="mm mn iq ki b kj mx km my kp mz kt na kx nb lb nw mu mv mw bi translated">在 CIFAR-100 上，S-E-I 的表现也超过了<a class="ae kf" rel="noopener" target="_blank" href="/review-wrns-wide-residual-networks-image-classification-d3feb3fb2004"> WRN </a>、<a class="ae kf" rel="noopener" target="_blank" href="/review-resnext-1st-runner-up-of-ilsvrc-2016-image-classification-15d7f17b42ac">雷斯 NeXt </a>和<a class="ae kf" rel="noopener" target="_blank" href="/review-densenet-image-classification-b6631a8ef803">登盛内特</a>。</li></ul></div><div class="ab cl ln lo hu lp" role="separator"><span class="lq bw bk lr ls lt"/><span class="lq bw bk lr ls lt"/><span class="lq bw bk lr ls"/></div><div class="ij ik il im in"><h1 id="0183" class="lu lv iq bd lw lx ly lz ma mb mc md me jw mf jx mg jz mh ka mi kc mj kd mk ml bi translated">3.<strong class="ak">进一步评估</strong></h1><h2 id="ad07" class="oa lv iq bd lw ob oc dn ma od oe dp me kp of og mg kt oh oi mi kx oj ok mk ol bi translated">3.1.剩余分支之间的相关性</h2><ul class=""><li id="bebf" class="mm mn iq ki b kj mo km mp kp mq kt mr kx ms lb nw mu mv mw bi translated">为了计算相关性，首先转发 mini-batch，通过残差分支 1 和<strong class="ki ir">将输出张量</strong>存储在<em class="ny"> yi </em> (1)中。类似于剩余分支 2，并将其存储在<em class="ny"> yi </em> (2)中。</li><li id="87d7" class="mm mn iq ki b kj mx km my kp mz kt na kx nb lb nw mu mv mw bi translated">然后<strong class="ki ir">将</strong> <em class="ny">夷</em> (1)和<em class="ny">夷</em> (2)分别展平为<em class="ny"> flati </em> (1)和<em class="ny"> flati </em> (2)。并且<strong class="ki ir">计算 2 个向量中每个对应项之间的协方差</strong>。</li><li id="a479" class="mm mn iq ki b kj mx km my kp mz kt na kx nb lb nw mu mv mw bi translated"><strong class="ki ir">计算<em class="ny"> flati </em> (1)和<em class="ny"> flati </em> (2)的方差</strong>。</li><li id="c228" class="mm mn iq ki b kj mx km my kp mz kt na kx nb lb nw mu mv mw bi translated">重复直到测试集中的所有图像。<strong class="ki ir">使用得到的协方差和方差计算相关性。</strong></li></ul><figure class="nd ne nf ng gt nh gh gi paragraph-image"><div role="button" tabindex="0" class="ni nj di nk bf nl"><div class="gh gi op"><img src="../Images/62b8ffad57f494a8828599e630d5b225.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Aqad-wYGXLdfTLf_Xe_URQ.png"/></div></div><figcaption class="no np gj gh gi nq nr bd b be z dk"><strong class="bd ns">Correlation results on E-E-B and S-S-I models</strong></figcaption></figure><ul class=""><li id="44bb" class="mm mn iq ki b kj kk km kn kp nt kt nu kx nv lb nw mu mv mw bi translated">首先，<strong class="ki ir">2 个剩余分支的输出张量之间的相关性似乎通过正则化而降低。</strong>这将支持一个假设，即<strong class="ki ir">正规化迫使分支机构学习不同的东西</strong>。</li></ul><figure class="nd ne nf ng gt nh gh gi paragraph-image"><div role="button" tabindex="0" class="ni nj di nk bf nl"><div class="gh gi oq"><img src="../Images/07c03227a7d5c587f3533f4ff0d4f7e9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*paXBNoT9TD95y_cuqvtyKg.png"/></div></div><figcaption class="no np gj gh gi nq nr bd b be z dk"><strong class="bd ns">Layer-wise correlation between the first 3 layers of each residual block</strong></figcaption></figure><ul class=""><li id="3a64" class="mm mn iq ki b kj kk km kn kp nt kt nu kx nv lb nw mu mv mw bi translated">残差块末尾的求和迫使左和右残差分支上的层对齐。</li><li id="e53f" class="mm mn iq ki b kj mx km my kp mz kt na kx nb lb nw mu mv mw bi translated"><strong class="ki ir">正则化降低了相关性。</strong></li></ul><h2 id="6d1f" class="oa lv iq bd lw ob oc dn ma od oe dp me kp of og mg kt oh oi mi kx oj ok mk ol bi translated">3.2.正则化强度</h2><figure class="nd ne nf ng gt nh gh gi paragraph-image"><div role="button" tabindex="0" class="ni nj di nk bf nl"><div class="gh gi or"><img src="../Images/0c55d1e0e8ed13061295812b4fb46917.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*aIoqQG-3ku70nrCjU5kHgQ.png"/></div></div><figcaption class="no np gj gh gi nq nr bd b be z dk"><strong class="bd ns">Update Rules for β</strong></figcaption></figure><figure class="nd ne nf ng gt nh gh gi paragraph-image"><div role="button" tabindex="0" class="ni nj di nk bf nl"><div class="gh gi os"><img src="../Images/421e626a3d8f122031714fdb2c3cb689.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*FZmSHAKpcygnvn6-2C47rA.png"/></div></div><figcaption class="no np gj gh gi nq nr bd b be z dk"><strong class="bd ns">Left: Training curves (dark) and test curves (light) of models M1 to M5. Right: Illustration of the different methods in the above Table.</strong></figcaption></figure><ul class=""><li id="dd33" class="mm mn iq ki b kj kk km kn kp nt kt nu kx nv lb nw mu mv mw bi translated"><em class="ny"> β </em>离<em class="ny"> α </em>越远，正则化效果越强。</li></ul><h2 id="aa10" class="oa lv iq bd lw ob oc dn ma od oe dp me kp of og mg kt oh oi mi kx oj ok mk ol bi translated">3.3.删除跳过连接/批处理规范化</h2><ul class=""><li id="6070" class="mm mn iq ki b kj mo km mp kp mq kt mr kx ms lb nw mu mv mw bi translated">建筑 A 为 26 2×32d，但没有跳接。</li><li id="5796" class="mm mn iq ki b kj mx km my kp mz kt na kx nb lb nw mu mv mw bi translated">架构 B 与 A 相同，但每个分支只有 1 个卷积层，块数是 A 的两倍。</li><li id="ca96" class="mm mn iq ki b kj mx km my kp mz kt na kx nb lb nw mu mv mw bi translated">架构 C 与 A 相同，但没有批处理规范化。</li></ul><figure class="nd ne nf ng gt nh gh gi paragraph-image"><div role="button" tabindex="0" class="ni nj di nk bf nl"><div class="gh gi ot"><img src="../Images/d2169d157661b9aacdc5669d9bd24835.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*MHQX1PY0bLk-UDp-z2iZiw.png"/></div></div><figcaption class="no np gj gh gi nq nr bd b be z dk"><strong class="bd ns">Error Rates of CIFAR-10</strong></figcaption></figure><ul class=""><li id="500b" class="mm mn iq ki b kj kk km kn kp nt kt nu kx nv lb nw mu mv mw bi translated"><strong class="ki ir">架构 A </strong>的结果清楚地表明<strong class="ki ir">抖动正则化甚至可以在没有跳跃连接</strong>的情况下工作。</li><li id="e3f2" class="mm mn iq ki b kj mx km my kp mz kt na kx nb lb nw mu mv mw bi translated"><strong class="ki ir">架构 B </strong>的结果显示<strong class="ki ir">正则化不再起作用。</strong></li><li id="22d2" class="mm mn iq ki b kj mx km my kp mz kt na kx nb lb nw mu mv mw bi translated"><strong class="ki ir">架构 C 使得模型难以收敛</strong>，使得模型更加敏感。也很容易使模型发散。</li></ul></div><div class="ab cl ln lo hu lp" role="separator"><span class="lq bw bk lr ls lt"/><span class="lq bw bk lr ls lt"/><span class="lq bw bk lr ls"/></div><div class="ij ik il im in"><p id="b7bd" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated">凭借简单而新颖的想法和积极的成果，它在 2017 年 ICLR 研讨会上发表，这非常令人鼓舞。</p></div><div class="ab cl ln lo hu lp" role="separator"><span class="lq bw bk lr ls lt"/><span class="lq bw bk lr ls lt"/><span class="lq bw bk lr ls"/></div><div class="ij ik il im in"><h2 id="4ad2" class="oa lv iq bd lw ob oc dn ma od oe dp me kp of og mg kt oh oi mi kx oj ok mk ol bi translated">参考</h2><p id="f116" class="pw-post-body-paragraph kg kh iq ki b kj mo jr kl km mp ju ko kp ou kr ks kt ov kv kw kx ow kz la lb ij bi translated">【2017 arXiv】【摇一摇】<br/> <a class="ae kf" href="https://arxiv.org/abs/1705.07485" rel="noopener ugc nofollow" target="_blank">摇一摇正规化</a></p><p id="c05c" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated">【2017 ICLR 研讨会】【摇一摇】<br/> <a class="ae kf" href="https://pdfs.semanticscholar.org/22aa/426aeffb77339646cc03da8e94de22396efc.pdf" rel="noopener ugc nofollow" target="_blank">三分支残差网络的摇一摇正则化</a></p><h2 id="bf66" class="oa lv iq bd lw ob oc dn ma od oe dp me kp of og mg kt oh oi mi kx oj ok mk ol bi translated">我以前的评论</h2><p id="4da9" class="pw-post-body-paragraph kg kh iq ki b kj mo jr kl km mp ju ko kp ou kr ks kt ov kv kw kx ow kz la lb ij bi translated">)(他)(们)(都)(不)(在)(这)(些)(事)(上)(,)(我)(们)(还)(不)(在)(这)(些)(事)(上)(有)(什)(么)(情)(况)(?)(我)(们)(都)(不)(在)(这)(些)(情)(况)(上)(,)(我)(们)(还)(没)(有)(什)(么)(情)(况)(,)(我)(们)(还)(没)(有)(什)(么)(情)(况)(,)(我)(们)(还)(没)(有)(什)(么)(情)(况)(,)(我)(们)(还)(没)(有)(什)(么)(好)(好)(的)(情)(感)(。 )(他)(们)(都)(不)(在)(这)(些)(事)(上)(,)(她)(们)(还)(不)(在)(这)(些)(事)(上)(有)(什)(么)(情)(况)(呢)(?)(她)(们)(都)(不)(在)(这)(些)(情)(况)(下)(,)(她)(们)(还)(不)(在)(这)(些)(事)(上)(有)(什)(么)(情)(况)(吗)(?)(她)(们)(们)(都)(不)(在)(这)(些)(事)(上)(,)(她)(们)(们)(还)(不)(在)(这)(些)(事)(上)(,)(她)(们)(们)(还)(不)(在)(这)(些)(事)(上)(有)(什)(么)(好)(的)(情)(情)(况)(。 [ ] [ ] [ ] [ ] [ ] [ ] [ ] [ ] [ ] [ ] [ ] [ ] [ ] [ ] [ ] [ ] [ ] [ ] [ ] [ ] [ ] [ ] [ ] [ ] [ ] [ ] [ ] [ ] [ ] [ ] [ ] [ ] [ ] [ ] [ ] [ ] [ ] [ ] [ ] [ ] [ ] [ ] [ ] [ ] [ ] [ ] [ ] [ ] [ ] [ ] [ ] [ ] [ ] [ ] [ ] [ ] [ ] [ ] [ ] [ ] [ ] [ ] [ ] [ ] [ ] [ ] [ ] [ ] [ ] [ ] [ ] [ ] [ ] [ ] [ ] [ ] [ ] [ ] [ ] [ ] [ ] [ ] [ ] [ ] [ ] [ ] [ ] [ ] [ ] [ ] [ ] [ ] [ ] [ ] [ ] [ ] [ ] [ ] [ ] [ ]</p><p id="8b77" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated"><strong class="ki ir">物体检测<br/></strong><a class="ae kf" href="https://medium.com/coinmonks/review-of-overfeat-winner-of-ilsvrc-2013-localization-task-object-detection-a6f8b9044754" rel="noopener">过食</a><a class="ae kf" href="https://medium.com/coinmonks/review-r-cnn-object-detection-b476aba290d1" rel="noopener">R-CNN</a><a class="ae kf" href="https://medium.com/coinmonks/review-fast-r-cnn-object-detection-a82e172e87ba" rel="noopener">快 R-CNN</a><a class="ae kf" rel="noopener" target="_blank" href="/review-faster-r-cnn-object-detection-f5685cb30202">快 R-CNN</a><a class="ae kf" rel="noopener" target="_blank" href="/review-mr-cnn-s-cnn-multi-region-semantic-aware-cnns-object-detection-3bd4e5648fde">MR-CNN&amp;S-CNN</a><a class="ae kf" rel="noopener" target="_blank" href="/review-deepid-net-def-pooling-layer-object-detection-f72486f1a0f6">DeepID-Net</a><a class="ae kf" rel="noopener" target="_blank" href="/review-craft-cascade-region-proposal-network-and-fast-r-cnn-object-detection-2ce987361858">CRAFT</a><a class="ae kf" rel="noopener" target="_blank" href="/review-r-fcn-positive-sensitive-score-maps-object-detection-91cd2389345c">R-FCN</a>】<a class="ae kf" rel="noopener" target="_blank" href="/review-ion-inside-outside-net-2nd-runner-up-in-2015-coco-detection-object-detection-da19993f4766"> [</a><a class="ae kf" rel="noopener" target="_blank" href="/review-g-rmi-winner-in-2016-coco-detection-object-detection-af3f2eaf87e4">G-RMI</a>][<a class="ae kf" href="https://medium.com/datadriveninvestor/review-tdm-top-down-modulation-object-detection-3f0efe9e0151" rel="noopener">TDM</a>][<a class="ae kf" rel="noopener" target="_blank" href="/review-ssd-single-shot-detector-object-detection-851a94607d11">SSD</a>][<a class="ae kf" rel="noopener" target="_blank" href="/review-dssd-deconvolutional-single-shot-detector-object-detection-d4821a2bbeb5">DSSD</a>][<a class="ae kf" rel="noopener" target="_blank" href="/yolov1-you-only-look-once-object-detection-e1f3ffec8a89">约洛夫 1 </a> ] [ <a class="ae kf" rel="noopener" target="_blank" href="/review-yolov2-yolo9000-you-only-look-once-object-detection-7883d2b02a65">约洛夫 2 /约洛 9000 </a> ] [ <a class="ae kf" rel="noopener" target="_blank" href="/review-yolov3-you-only-look-once-object-detection-eab75d7a1ba6">约洛夫 3</a>[<a class="ae kf" rel="noopener" target="_blank" href="/review-fpn-feature-pyramid-network-object-detection-262fc7482610">FPN</a>[<a class="ae kf" rel="noopener" target="_blank" href="/review-retinanet-focal-loss-object-detection-38fba6afabe4">视网膜网</a>[<a class="ae kf" rel="noopener" target="_blank" href="/review-dcn-deformable-convolutional-networks-2nd-runner-up-in-2017-coco-detection-object-14e488efce44">DCN</a></p><p id="6582" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated"><strong class="ki ir">语义切分<br/></strong><a class="ae kf" rel="noopener" target="_blank" href="/review-fcn-semantic-segmentation-eb8c9b50d2d1">FCN</a><a class="ae kf" rel="noopener" target="_blank" href="/review-deconvnet-unpooling-layer-semantic-segmentation-55cf8a6e380e">de convnet</a><a class="ae kf" rel="noopener" target="_blank" href="/review-deeplabv1-deeplabv2-atrous-convolution-semantic-segmentation-b51c5fbde92d">deeplabv 1&amp;deeplabv 2</a><a class="ae kf" rel="noopener" target="_blank" href="/review-crf-rnn-conditional-random-fields-as-recurrent-neural-networks-semantic-segmentation-a11eb6e40c8c">CRF-RNN</a>】<a class="ae kf" rel="noopener" target="_blank" href="/review-segnet-semantic-segmentation-e66f2e30fb96">SegNet</a>】<a class="ae kf" href="https://medium.com/datadriveninvestor/review-parsenet-looking-wider-to-see-better-semantic-segmentation-aa6b6a380990" rel="noopener">parse net</a><a class="ae kf" rel="noopener" target="_blank" href="/review-dilated-convolution-semantic-segmentation-9d5a5bd768f5">dilated net</a><a class="ae kf" rel="noopener" target="_blank" href="/review-drn-dilated-residual-networks-image-classification-semantic-segmentation-d527e1a8fb5">DRN</a><a class="ae kf" rel="noopener" target="_blank" href="/review-refinenet-multi-path-refinement-network-semantic-segmentation-5763d9da47c1">RefineNet</a><a class="ae kf" rel="noopener" target="_blank" href="/review-refinenet-multi-path-refinement-network-semantic-segmentation-5763d9da47c1"/></p><p id="fc65" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated"><strong class="ki ir">生物医学图像分割<br/></strong>[<a class="ae kf" href="https://medium.com/datadriveninvestor/review-cumedvision1-fully-convolutional-network-biomedical-image-segmentation-5434280d6e6" rel="noopener">cumed vision 1</a>][<a class="ae kf" href="https://medium.com/datadriveninvestor/review-cumedvision2-dcan-winner-of-2015-miccai-gland-segmentation-challenge-contest-biomedical-878b5a443560" rel="noopener">cumed vision 2/DCAN</a>][<a class="ae kf" rel="noopener" target="_blank" href="/review-u-net-biomedical-image-segmentation-d02bf06ca760">U-Net</a>][<a class="ae kf" href="https://medium.com/datadriveninvestor/review-cfs-fcn-biomedical-image-segmentation-ae4c9c75bea6" rel="noopener">CFS-FCN</a>][<a class="ae kf" href="https://medium.com/datadriveninvestor/review-u-net-resnet-the-importance-of-long-short-skip-connections-biomedical-image-ccbf8061ff43" rel="noopener">U-Net+ResNet</a>][<a class="ae kf" rel="noopener" target="_blank" href="/review-multichannel-segment-colon-histology-images-biomedical-image-segmentation-d7e57902fbfc">多通道</a>][<a class="ae kf" rel="noopener" target="_blank" href="/review-v-net-volumetric-convolution-biomedical-image-segmentation-aa15dbaea974">V-Net</a>][<a class="ae kf" rel="noopener" target="_blank" href="/review-3d-u-net-volumetric-segmentation-medical-image-segmentation-8b592560fac1">3D U-Net</a>][<a class="ae kf" rel="noopener" target="_blank" href="/review-m²fcn-multi-stage-multi-recursive-input-fully-convolutional-networks-biomedical-image-4f8d5e3f07f1">M FCN</a></p><p id="3134" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated"><strong class="ki ir"> 实例分割 <br/> </strong> <a class="ae kf" href="https://medium.com/datadriveninvestor/review-sds-simultaneous-detection-and-segmentation-instance-segmentation-80b2a8ce842b" rel="noopener"> SDS </a> <a class="ae kf" rel="noopener" target="_blank" href="/review-hypercolumn-instance-segmentation-367180495979"> Hypercolumn </a> <a class="ae kf" rel="noopener" target="_blank" href="/review-deepmask-instance-segmentation-30327a072339"> DeepMask </a> <a class="ae kf" rel="noopener" target="_blank" href="/review-sharpmask-instance-segmentation-6509f7401a61"> SharpMask </a> <a class="ae kf" rel="noopener" target="_blank" href="/review-multipath-mpn-1st-runner-up-in-2015-coco-detection-segmentation-object-detection-ea9741e7c413"> MultiPathNet </a> <a class="ae kf" rel="noopener" target="_blank" href="/review-mnc-multi-task-network-cascade-winner-in-2015-coco-segmentation-instance-segmentation-42a9334e6a34"> MNC </a> <a class="ae kf" rel="noopener" target="_blank" href="/review-instancefcn-instance-sensitive-score-maps-instance-segmentation-dbfe67d4ee92"> InstanceFCN </a> <a class="ae kf" rel="noopener" target="_blank" href="/review-fcis-winner-in-2016-coco-segmentation-instance-segmentation-ee2d61f465e2"> FCIS </a></p><p id="58de" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated">)(我)(们)(都)(不)(知)(道)(,)(我)(们)(还)(是)(不)(知)(道)(,)(我)(们)(还)(是)(不)(知)(道)(,)(我)(们)(还)(是)(不)(知)(道)(,)(我)(们)(还)(是)(不)(知)(道)(,)(我)(们)(还)(是)(不)(知)(道)(,)(我)(们)(还)(是)(不)(知)(道)(。</p><p id="f29d" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated"><strong class="ki ir">人体姿态估计</strong><br/><a class="ae kf" rel="noopener" target="_blank" href="/review-deeppose-cascade-of-cnn-human-pose-estimation-cf3170103e36">深度姿态</a><a class="ae kf" rel="noopener" target="_blank" href="/review-tompson-nips14-joint-training-of-cnn-and-graphical-model-human-pose-estimation-95016bc510c">汤普森·尼普斯 14</a><a class="ae kf" rel="noopener" target="_blank" href="/review-tompson-cvpr15-spatial-dropout-human-pose-estimation-c7d6a5cecd8c">汤普森·CVPR 15</a><a class="ae kf" href="https://medium.com/@sh.tsang/review-cpm-convolutional-pose-machines-human-pose-estimation-224cfeb70aac" rel="noopener">CPM</a>]</p></div></div>    
</body>
</html>