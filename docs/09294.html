<html>
<head>
<title>Linear Regression with one or more variables</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">一个或多个变量的线性回归</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/machine-learning-for-biomedical-data-linear-regression-7d43461cdfa9?source=collection_archive---------5-----------------------#2019-12-09">https://towardsdatascience.com/machine-learning-for-biomedical-data-linear-regression-7d43461cdfa9?source=collection_archive---------5-----------------------#2019-12-09</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><h2 id="2d3f" class="ir is it bd b dl iu iv iw ix iy iz dk ja translated" aria-label="kicker paragraph"><a class="ae ep" href="https://towardsdatascience.com/tagged/ml-for-bio-data" rel="noopener" target="_blank">生物医学数据的机器学习</a></h2><div class=""/><div class=""><h2 id="eb43" class="pw-subtitle-paragraph jz jc it bd b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq dk translated">如何在医学中使用线性回归进行结果预测</h2></div><h1 id="26a2" class="kr ks it bd kt ku kv kw kx ky kz la lb ki lc kj ld kl le km lf ko lg kp lh li bi translated"><strong class="ak">简介</strong></h1><p id="b3d8" class="pw-post-body-paragraph lj lk it ll b lm ln kd lo lp lq kg lr ls lt lu lv lw lx ly lz ma mb mc md me im bi translated">线性回归是一种用于机器学习的统计模型，属于“监督学习”类算法，适用于生物医学数据的分析。我们使用它来预测连续值输出，这与逻辑回归不同，逻辑回归用于预测离散值输出(即分类)。</p><p id="77e8" class="pw-post-body-paragraph lj lk it ll b lm mf kd lo lp mg kg lr ls mh lu lv lw mi ly lz ma mj mc md me im bi translated">在开始之前，我建议读者先去 Coursera 上学习 Andrew NG 教授的有趣的机器学习课程。本课程对这篇文章中讨论的所有论点提供了一个很好的解释。</p><p id="8e06" class="pw-post-body-paragraph lj lk it ll b lm mf kd lo lp mg kg lr ls mh lu lv lw mi ly lz ma mj mc md me im bi translated">让我们从我们的例子开始:我们有一个检查收缩压(SBP)并监测年龄和体重的患者数据集，我们想预测一个新患者的 SBP。我们假设体重和年龄等因素会影响 SBP。对于我们的数据集，我们将从[2]中获取一个表的值</p><figure class="ml mm mn mo gt mp gh gi paragraph-image"><div role="button" tabindex="0" class="mq mr di ms bf mt"><div class="gh gi mk"><img src="../Images/89b94f5fd82d6f3614d6bd19f05015dd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*kFP6ps7p9dJ6Hh-WJZCVSg.png"/></div></div><figcaption class="mw mx gj gh gi my mz bd b be z dk"><em class="na">Table 1: Dataset</em></figcaption></figure><p id="38d0" class="pw-post-body-paragraph lj lk it ll b lm mf kd lo lp mg kg lr ls mh lu lv lw mi ly lz ma mj mc md me im bi translated">要说明的变量(SBP)称为<strong class="ll jd"> <em class="nb">因变量</em> </strong>，或<strong class="ll jd"> <em class="nb">响应变量</em> </strong>，它与我们的<strong class="ll jd"> <em class="nb">输出</em> </strong> <em class="nb"> </em>变量或<strong class="ll jd"> <em class="nb">目标向量</em> </strong>相匹配。而是将解释<strong class="ll jd"> <em class="nb">输入</em> </strong>(年龄和体重)的变量称为<strong class="ll jd"> <em class="nb">自变量</em> </strong>或<strong class="ll jd"> <em class="nb">预测变量</em> </strong>，或<strong class="ll jd"> <em class="nb">特征</em> </strong>。如果因变量和自变量是连续的，如<em class="nb"> SBP、</em>和<em class="nb">体重</em>的情况，那么可以计算出一个<strong class="ll jd">相关系数</strong>作为它们之间关系强度的度量。[3]</p><p id="c1df" class="pw-post-body-paragraph lj lk it ll b lm mf kd lo lp mg kg lr ls mh lu lv lw mi ly lz ma mj mc md me im bi translated">我们说<strong class="ll jd">线性回归</strong>代表了<strong class="ll jd">相关性</strong>的进化。两者的区别在于:相关性是指两个或多个变量之间关系的强弱。相反，回归指的是描述两个或多个变量之间关系的统计技术和算法的集合[2]。</p><p id="a663" class="pw-post-body-paragraph lj lk it ll b lm mf kd lo lp mg kg lr ls mh lu lv lw mi ly lz ma mj mc md me im bi translated">线性回归假设一个或多个输入要素与相对目标矢量(输出)之间的关系近似呈线性。[4]，它能够识别和表征这种关系。这种假设的结果是，在线性回归模型中，输入特征对目标向量(输出)有“影响”，并且这种影响是恒定的。</p><p id="6c96" class="pw-post-body-paragraph lj lk it ll b lm mf kd lo lp mg kg lr ls mh lu lv lw mi ly lz ma mj mc md me im bi translated">“影响”通常被确定为“系数”、“权重”或“参数”，更简单地说，我们说线性回归计算输入特征的加权和，加上一个称为“偏差项”或截距的常数[5]。</p><p id="ef29" class="pw-post-body-paragraph lj lk it ll b lm mf kd lo lp mg kg lr ls mh lu lv lw mi ly lz ma mj mc md me im bi translated">为了简化，让我们从应用一个变量的线性回归开始。</p><h1 id="396c" class="kr ks it bd kt ku kv kw kx ky kz la lb ki lc kj ld kl le km lf ko lg kp lh li bi translated"><strong class="ak">一元线性回归</strong></h1><p id="7fdb" class="pw-post-body-paragraph lj lk it ll b lm ln kd lo lp lq kg lr ls lt lu lv lw lx ly lz ma mb mc md me im bi translated">如果我们想彻底理解线性回归是如何工作的，从一个变量开始是一个基本步骤。我们将使用表 1 中的数据集，只外推特征“年龄”并使用“SBP”列作为输出。</p><p id="81d9" class="pw-post-body-paragraph lj lk it ll b lm mf kd lo lp mg kg lr ls mh lu lv lw mi ly lz ma mj mc md me im bi translated">本文中的所有代码都是用 Python 2.7 编写的，对于移植到许多其他语言来说，它也是不言自明的。对于实现环境，我建议使用<a class="ae nc" href="https://jupyter.org/" rel="noopener ugc nofollow" target="_blank"> Jupyter 笔记本</a>。</p><p id="e472" class="pw-post-body-paragraph lj lk it ll b lm mf kd lo lp mg kg lr ls mh lu lv lw mi ly lz ma mj mc md me im bi translated">将主要使用线性代数计算，因为它在尽可能避免“while”和“for”循环方面具有内在优势。为了实现这个目标，我们将使用<a class="ae nc" href="https://numpy.org/" rel="noopener ugc nofollow" target="_blank"> NumPy </a>，这是一个强大的数学函数库，用于使用 Python 进行科学计算。</p><p id="408c" class="pw-post-body-paragraph lj lk it ll b lm mf kd lo lp mg kg lr ls mh lu lv lw mi ly lz ma mj mc md me im bi translated">在开始描述线性回归模型之前，有必要看一下我们的数据，并尝试了解线性回归是否适用于这些数据。目标是基于患者年龄预测例如收缩压值。</p><h1 id="0568" class="kr ks it bd kt ku kv kw kx ky kz la lb ki lc kj ld kl le km lf ko lg kp lh li bi translated"><strong class="ak">第一步:导入 Python 库</strong></h1><p id="c647" class="pw-post-body-paragraph lj lk it ll b lm ln kd lo lp lq kg lr ls lt lu lv lw lx ly lz ma mb mc md me im bi translated">首先，我们导入本帖将要讨论的 Python 代码所需的所有包:<strong class="ll jd"> NumPy </strong>、<strong class="ll jd"> Pandas </strong>和<strong class="ll jd"> matplot </strong>。这些软件包属于 SciPy.org，这是一个基于 Python 的数学、科学和工程开源软件生态系统。</p><p id="4852" class="pw-post-body-paragraph lj lk it ll b lm mf kd lo lp mg kg lr ls mh lu lv lw mi ly lz ma mj mc md me im bi translated">Numpy 对于线性代数计算是必要的。</p><p id="09f1" class="pw-post-body-paragraph lj lk it ll b lm mf kd lo lp mg kg lr ls mh lu lv lw mi ly lz ma mj mc md me im bi translated">Pandas 是一个开源库，为 Python 提供高性能、数据结构和数据分析工具。pandas 数据帧是一个二维大小可变的、潜在异构的表格数据结构。它由三个主要部分组成，数据、行和列，带有标记的轴(行和列)。点击这个<a class="ae nc" href="https://www.geeksforgeeks.org/python-pandas-dataframe/" rel="noopener ugc nofollow" target="_blank">链接到 GeeksForGeeks 门户网站</a>，获取关于熊猫数据框架使用的详细信息。</p><p id="f061" class="pw-post-body-paragraph lj lk it ll b lm mf kd lo lp mg kg lr ls mh lu lv lw mi ly lz ma mj mc md me im bi translated">Matplotlib 是创建所有绘图的基础。</p><figure class="ml mm mn mo gt mp"><div class="bz fp l di"><div class="nd ne l"/></div><figcaption class="mw mx gj gh gi my mz bd b be z dk"><em class="na">Code 1: import Python libraries</em></figcaption></figure><h1 id="e1d5" class="kr ks it bd kt ku kv kw kx ky kz la lb ki lc kj ld kl le km lf ko lg kp lh li bi translated"><strong class="ak">第二步:创建数据集</strong></h1><p id="5730" class="pw-post-body-paragraph lj lk it ll b lm ln kd lo lp lq kg lr ls lt lu lv lw lx ly lz ma mb mc md me im bi translated">在这一步中，我们将使用我们的值创建一个数据集。带有标题的逗号分隔值格式的示例如下:</p><p id="b0f5" class="pw-post-body-paragraph lj lk it ll b lm mf kd lo lp mg kg lr ls mh lu lv lw mi ly lz ma mj mc md me im bi translated"><strong class="ll jd">年龄体重 SBP </strong> <br/> 60，58，117 <br/> 61，90，120 <br/> 74，96，145 <br/> 57，72，129 <br/> 63，62，132 <br/> 68，79，130 <br/> 66，69，110 <br/> 77，96，163 <br/> 63，96，136<br/>50</p><p id="16b2" class="pw-post-body-paragraph lj lk it ll b lm mf kd lo lp mg kg lr ls mh lu lv lw mi ly lz ma mj mc md me im bi translated">复制并粘贴文件中的值，并将其保存为“SBP.csv”</p><h1 id="8951" class="kr ks it bd kt ku kv kw kx ky kz la lb ki lc kj ld kl le km lf ko lg kp lh li bi translated"><strong class="ak">第三步:打开数据集</strong></h1><p id="1497" class="pw-post-body-paragraph lj lk it ll b lm ln kd lo lp lq kg lr ls lt lu lv lw lx ly lz ma mb mc md me im bi translated">一旦我们创建了 SBP.csv 数据集，上传它并使用 Pandas <em class="nb"> pd </em>对象创建一个 DataFrame。数据集上传的 Python 代码如下:</p><figure class="ml mm mn mo gt mp"><div class="bz fp l di"><div class="nd ne l"/></div><figcaption class="mw mx gj gh gi my mz bd b be z dk"><em class="na">Code 2: upload data and create a pandas DataFrame</em></figcaption></figure><p id="5951" class="pw-post-body-paragraph lj lk it ll b lm mf kd lo lp mg kg lr ls mh lu lv lw mi ly lz ma mj mc md me im bi translated">在 Jupyter 单元格中键入“df ”,将显示如下数据帧内容:</p><figure class="ml mm mn mo gt mp gh gi paragraph-image"><div class="gh gi nf"><img src="../Images/f7d22e5c842338fba0cfed29c2c3cf54.png" data-original-src="https://miro.medium.com/v2/resize:fit:680/format:webp/1*6a9v6TbVOrs_2OffyY3f_Q.png"/></div><figcaption class="mw mx gj gh gi my mz bd b be z dk">Table 2: Visualizing a pandas DataFrame</figcaption></figure><h1 id="98c7" class="kr ks it bd kt ku kv kw kx ky kz la lb ki lc kj ld kl le km lf ko lg kp lh li bi translated"><strong class="ak">步骤 4:上传数据集</strong></h1><p id="961c" class="pw-post-body-paragraph lj lk it ll b lm ln kd lo lp lq kg lr ls lt lu lv lw lx ly lz ma mb mc md me im bi translated">SBP 数据集由 3 列组成(年龄、体重和 SBP)，但我们将上传第一列和最后一列(年龄和 SBP)；我们的模型将决定年龄和 SBP 之间关系的强度。Pandas 使访问 DataFrame 变量变得容易，这些变量将被复制到一个包含输入的<em class="nb"> X </em>向量和一个用于输出的<em class="nb"> y </em>向量中。</p><figure class="ml mm mn mo gt mp"><div class="bz fp l di"><div class="nd ne l"/></div><figcaption class="mw mx gj gh gi my mz bd b be z dk"><em class="na">Code 3: Uploading the dataset</em></figcaption></figure><h1 id="2370" class="kr ks it bd kt ku kv kw kx ky kz la lb ki lc kj ld kl le km lf ko lg kp lh li bi translated"><strong class="ak">第五步:特征缩放和归一化</strong></h1><p id="3c32" class="pw-post-body-paragraph lj lk it ll b lm ln kd lo lp lq kg lr ls lt lu lv lw lx ly lz ma mb mc md me im bi translated">在继续之前，此处报告的 SBP 数据集必须进行重新缩放和归一化。在机器学习中，需要缩放和归一化，尤其是当特征和输出之间出现数量级差异时。如简介中所述，我们将在矩阵上使用线性代数，以尽可能避免<em class="nb">而</em>和<em class="nb"> for </em>在变量上循环。此外，编程线性代数将导致代码的良好可读性。</p><p id="13c3" class="pw-post-body-paragraph lj lk it ll b lm mf kd lo lp mg kg lr ls mh lu lv lw mi ly lz ma mj mc md me im bi translated">为此，在 Python 中，我们可以利用 NumPy。如前所述，NumPy 是一个用于科学计算和线性代数的数学函数库。所有的操作都可以简化，创建一个 NumPy 对象，并使用一些相关的方法。我们之所以要使用 NumPy，是因为尽管矩阵上的许多操作可以使用常规操作符(+、-、*、/)来完成，但 NumPy 保证了对操作的更好控制，尤其是在矩阵很大的情况下。例如，使用 NumPy，我们可以逐元素地乘以参数，如特征矩阵<em class="nb"> X </em>和输出向量<em class="nb"> y </em>:</p><figure class="ml mm mn mo gt mp"><div class="bz fp l di"><div class="nd ne l"/></div><figcaption class="mw mx gj gh gi my mz bd b be z dk"><em class="na">Code 4: Multiply arguments element-wise</em></figcaption></figure><p id="6d48" class="pw-post-body-paragraph lj lk it ll b lm mf kd lo lp mg kg lr ls mh lu lv lw mi ly lz ma mj mc md me im bi translated">关于 NumPy 使用的深入讨论超出了本文的范围。为了实现特性的<em class="nb">缩放和规范化</em>，我们需要以下代码:</p><figure class="ml mm mn mo gt mp"><div class="bz fp l di"><div class="nd ne l"/></div><figcaption class="mw mx gj gh gi my mz bd b be z dk"><em class="na">Code 5: The FeatureScalingNormalization() function.</em></figcaption></figure><p id="d8d9" class="pw-post-body-paragraph lj lk it ll b lm mf kd lo lp mg kg lr ls mh lu lv lw mi ly lz ma mj mc md me im bi translated"><em class="nb">代码 5 </em>实现了一个名为<em class="nb"> FeatureScalingNormalization()的 Python 函数。</em>该函数将特征向量<em class="nb"> X </em>作为参数，返回 3 个参数:1)同一个<em class="nb"> X </em>向量，但经过缩放和归一化(<strong class="ll jd"> <em class="nb"> X_norm </em> </strong>)，2) <strong class="ll jd"> <em class="nb"> mu </em> </strong>，即训练集中<em class="nb"> X </em>的平均值，3) <strong class="ll jd"> <em class="nb"> sigma </em> </strong>，即标准差。此外，我们将存储<em class="nb"> mu </em>和<em class="nb"> sigma </em>，因为这些参数在后面会很重要。复制以下代码并将其粘贴到新的 Jupyter 笔记本单元格中:</p><figure class="ml mm mn mo gt mp"><div class="bz fp l di"><div class="nd ne l"/></div><figcaption class="mw mx gj gh gi my mz bd b be z dk"><em class="na">Code 6: Run the FeatureScalingNormalization function.</em></figcaption></figure><p id="2cd1" class="pw-post-body-paragraph lj lk it ll b lm mf kd lo lp mg kg lr ls mh lu lv lw mi ly lz ma mj mc md me im bi translated">在笔记本单元格中键入“X”将显示新的<em class="nb"> X </em>值:</p><pre class="ml mm mn mo gt ng nh ni nj aw nk bi"><span id="b56e" class="nl ks it nh b gy nm nn l no np">array([-0.73189052, -0.59728997,  1.15251726, -1.13569219, -0.32808885, 0.34491392,  0.07571281,  1.55631892, -0.32808885, -1.53949386, -0.32808885,  1.42171837, -0.73189052, -0.59728997, -0.05888774, 1.82552004])</span></pre><p id="5d62" class="pw-post-body-paragraph lj lk it ll b lm mf kd lo lp mg kg lr ls mh lu lv lw mi ly lz ma mj mc md me im bi translated">包含<em class="nb">年龄</em>值的 X 向量现在被归一化。</p><h1 id="daa5" class="kr ks it bd kt ku kv kw kx ky kz la lb ki lc kj ld kl le km lf ko lg kp lh li bi translated"><strong class="ak">第六步:给 X 向量添加一列 1</strong></h1><p id="4049" class="pw-post-body-paragraph lj lk it ll b lm ln kd lo lp lq kg lr ls lt lu lv lw lx ly lz ma mb mc md me im bi translated">现在我们将把一列 1 添加到向量<em class="nb"> X </em>中。</p><figure class="ml mm mn mo gt mp"><div class="bz fp l di"><div class="nd ne l"/></div><figcaption class="mw mx gj gh gi my mz bd b be z dk"><em class="na">Code 7: Add a column of ones to the X vector.</em></figcaption></figure><p id="c895" class="pw-post-body-paragraph lj lk it ll b lm mf kd lo lp mg kg lr ls mh lu lv lw mi ly lz ma mj mc md me im bi translated">这是 X 的新结构:</p><pre class="ml mm mn mo gt ng nh ni nj aw nk bi"><span id="5068" class="nl ks it nh b gy nm nn l no np">array([[ 1.        , -0.73189052],<br/>       [ 1.        , -0.59728997],<br/>       [ 1.        ,  1.15251726],<br/>       [ 1.        , -1.13569219],<br/>       [ 1.        , -0.32808885],<br/>       [ 1.        ,  0.34491392],<br/>       [ 1.        ,  0.07571281],<br/>       [ 1.        ,  1.55631892],<br/>       [ 1.        , -0.32808885],<br/>       [ 1.        , -1.53949386],<br/>       [ 1.        , -0.32808885],<br/>       [ 1.        ,  1.42171837],<br/>       [ 1.        , -0.73189052],<br/>       [ 1.        , -0.59728997],<br/>       [ 1.        , -0.05888774],<br/>       [ 1.        ,  1.82552004]])</span></pre><h1 id="11b9" class="kr ks it bd kt ku kv kw kx ky kz la lb ki lc kj ld kl le km lf ko lg kp lh li bi translated"><strong class="ak">第七步:绘制数据集</strong></h1><p id="e1c8" class="pw-post-body-paragraph lj lk it ll b lm ln kd lo lp lq kg lr ls lt lu lv lw lx ly lz ma mb mc md me im bi translated">当我们想知道数据是如何分布的时候，绘制数据图是一种有用的做法。使用 matplotlib 散点图方法绘制数据:</p><figure class="ml mm mn mo gt mp"><div class="bz fp l di"><div class="nd ne l"/></div><figcaption class="mw mx gj gh gi my mz bd b be z dk"><em class="na">Code 8: Plot data</em></figcaption></figure><figure class="ml mm mn mo gt mp gh gi paragraph-image"><div class="gh gi nq"><img src="../Images/3f866915101255dc0aafb9534a29dcee.png" data-original-src="https://miro.medium.com/v2/resize:fit:792/format:webp/1*3iTjO-pGIFDkuQgZrRl1cw.png"/></div><figcaption class="mw mx gj gh gi my mz bd b be z dk"><em class="na">Figure 1: Plot Age-SBP</em></figcaption></figure><p id="21de" class="pw-post-body-paragraph lj lk it ll b lm mf kd lo lp mg kg lr ls mh lu lv lw mi ly lz ma mj mc md me im bi translated">将数据可视化一目了然，我们可以注意到<em class="nb">年龄</em>和<em class="nb"> SBP </em>之间增加关系的模式。这是我们所期望的，因为收缩压在生理上与年龄增长有关。</p><h1 id="bf6f" class="kr ks it bd kt ku kv kw kx ky kz la lb ki lc kj ld kl le km lf ko lg kp lh li bi translated"><strong class="ak">第八步:假设(线性回归模型)</strong></h1><p id="3c9a" class="pw-post-body-paragraph lj lk it ll b lm ln kd lo lp lq kg lr ls lt lu lv lw lx ly lz ma mb mc md me im bi translated">线性回归的基本思想由基于输入特征<em class="nb"> X </em>预测输出<em class="nb"> y </em>的函数来表示。</p><figure class="ml mm mn mo gt mp gh gi paragraph-image"><div class="gh gi nr"><img src="../Images/b997bc04f9e8d8af36c9701d1f9ffe97.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*rWqU4adpoXcHwnwpkOfH_g.png"/></div><figcaption class="mw mx gj gh gi my mz bd b be z dk"><em class="na">Equation 1: Linear Regression Model</em></figcaption></figure><p id="878d" class="pw-post-body-paragraph lj lk it ll b lm mf kd lo lp mg kg lr ls mh lu lv lw mi ly lz ma mj mc md me im bi translated">预测输出是<strong class="ll jd"> h = θ * X </strong>项，它等于一个称为“偏差项”或“截距项”或<strong class="ll jd"> θ_0 </strong>的常数加上输入特征 X <strong class="ll jd">、</strong>的加权和，其中<strong class="ll jd"> θ_1 </strong>代表<em class="nb">X</em>T56】的权重。我们将这个函数称为“假设”，我们将使用它从<em class="nb"> X </em>(年龄)到<em class="nb"> y </em> (SBP)进行“映射”。</p><p id="6d33" class="pw-post-body-paragraph lj lk it ll b lm mf kd lo lp mg kg lr ls mh lu lv lw mi ly lz ma mj mc md me im bi translated">由于我们使用线性代数，对于所有计算，我们可以将假设模型写成矢量化形式:</p><figure class="ml mm mn mo gt mp gh gi paragraph-image"><div role="button" tabindex="0" class="mq mr di ms bf mt"><div class="gh gi ns"><img src="../Images/b5c71564a78844e543569d0a8e52c433.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*GayXDlmhgmCK4XVsWFoUtg.png"/></div></div><figcaption class="mw mx gj gh gi my mz bd b be z dk"><em class="na">Equation 2: Linear Regression Model in vectorized form</em></figcaption></figure><p id="d793" class="pw-post-body-paragraph lj lk it ll b lm mf kd lo lp mg kg lr ls mh lu lv lw mi ly lz ma mj mc md me im bi translated">其中<strong class="ll jd">θ<em class="nb">_</em>0<em class="nb"/></strong>和<strong class="ll jd"> θ <em class="nb"> _ </em> 1 </strong>表示为向量<strong class="ll jd">θ=【θ_ 0，<em class="nb"/>θ<em class="nb">_</em>1】</strong>，假设等于<strong class="ll jd"> θX </strong>。</p><p id="1e0e" class="pw-post-body-paragraph lj lk it ll b lm mf kd lo lp mg kg lr ls mh lu lv lw mi ly lz ma mj mc md me im bi translated">预测<em class="nb"> y </em>的最佳性能包括找到预测的<em class="nb"> y </em>值和实际的<em class="nb"> y </em>值之间的距离更接近最小值的θ <em class="nb"> </em>值。</p><p id="1e5b" class="pw-post-body-paragraph lj lk it ll b lm mf kd lo lp mg kg lr ls mh lu lv lw mi ly lz ma mj mc md me im bi translated">让我们试试随机选择的两个参数，对于向量θ，例如:θ <em class="nb"> = </em> [140.0，5.0]，看看会发生什么:</p><figure class="ml mm mn mo gt mp"><div class="bz fp l di"><div class="nd ne l"/></div><figcaption class="mw mx gj gh gi my mz bd b be z dk"><em class="na">Code 9: Plot the Hypothesis with θ = [140.0, 5.0]</em></figcaption></figure><figure class="ml mm mn mo gt mp gh gi paragraph-image"><div role="button" tabindex="0" class="mq mr di ms bf mt"><div class="gh gi nt"><img src="../Images/d310a003ab6230ec32dc0660a12c034e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ty48tJzwQL4LlVtte5_LbQ.png"/></div></div><figcaption class="mw mx gj gh gi my mz bd b be z dk"><em class="na">Figure 2: </em>θ<em class="na"> = [140.0; 5.0]</em></figcaption></figure><p id="7256" class="pw-post-body-paragraph lj lk it ll b lm mf kd lo lp mg kg lr ls mh lu lv lw mi ly lz ma mj mc md me im bi translated">图 2 中用红线表示的假设模型应该预测<em class="nb">y</em>(SBP)。对于<em class="nb">θ=</em>【140.0，5.0】的值，它表示我们在预测<em class="nb"> y </em>时的<em class="nb"> h=θX </em>向量。但是这个模型显然不符合我们的数据。正如用红线连接圆点的蓝线所突出显示的，假设“触及”了一些<em class="nb"> y </em>值，但是剩余的<em class="nb"> h </em>向量远不是最小值。所以我们很想猜测当设置不同的值时，哪个<em class="nb"> θ </em>可以预测<em class="nb"> y </em>。我们可以“通过试错法”选择<em class="nb"> θ </em>来最小化<em class="nb">假设</em>和<em class="nb">y</em>之间的所有距离。为了实现这个目标，我们可以为我们的模型计算<strong class="ll jd"> <em class="nb">成本函数</em> </strong>。</p><h1 id="6d37" class="kr ks it bd kt ku kv kw kx ky kz la lb ki lc kj ld kl le km lf ko lg kp lh li bi translated"><strong class="ak">第九步:计算成本函数</strong></h1><p id="04c6" class="pw-post-body-paragraph lj lk it ll b lm ln kd lo lp lq kg lr ls lt lu lv lw lx ly lz ma mb mc md me im bi translated"><strong class="ll jd"> <em class="nb">成本函数</em> </strong>可以记录我们离假设模型的最小值有多远，并可以帮助我们找到最佳θ <em class="nb">。</em>描述成本函数的等式如下:</p><figure class="ml mm mn mo gt mp gh gi paragraph-image"><div role="button" tabindex="0" class="mq mr di ms bf mt"><div class="gh gi nu"><img src="../Images/3ea4c4381e9a2feae6f4a2bfb4bec3fa.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*hOpw7SQY1nsN-lhI58Ok3w.png"/></div></div><figcaption class="mw mx gj gh gi my mz bd b be z dk"><em class="na">Equation 3: Linear Regression Cost Function</em></figcaption></figure><p id="d55e" class="pw-post-body-paragraph lj lk it ll b lm mf kd lo lp mg kg lr ls mh lu lv lw mi ly lz ma mj mc md me im bi translated">其中<strong class="ll jd"> <em class="nb"> m </em> </strong>是<em class="nb"> X </em>向量的长度(在我们的例子中= 16)，而<em class="nb"> i </em>是分配给数据集中每一项的索引。该等式由三部分组成:</p><ol class=""><li id="a0b6" class="nv nw it ll b lm mf lp mg ls nx lw ny ma nz me oa ob oc od bi translated">假设(<em class="nb"> h=θX </em>)</li><li id="a5cf" class="nv nw it ll b lm oe lp of ls og lw oh ma oi me oa ob oc od bi translated">平方误差即= ( <em class="nb"> h-y </em> ) ^2</li><li id="728f" class="nv nw it ll b lm oe lp of ls og lw oh ma oi me oa ob oc od bi translated">成本函数 J 计算如下:J = 1/2m * Sum(平方误差)</li></ol><p id="171d" class="pw-post-body-paragraph lj lk it ll b lm mf kd lo lp mg kg lr ls mh lu lv lw mi ly lz ma mj mc md me im bi translated">由于我们使用线性代数，等式 3 的矢量化实现如下:</p><figure class="ml mm mn mo gt mp gh gi paragraph-image"><div role="button" tabindex="0" class="mq mr di ms bf mt"><div class="gh gi oj"><img src="../Images/25975e47bfad69cb11727dc81eb9eb17.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*AKw83mdAnxreo2AKc6VNuw.png"/></div></div><figcaption class="mw mx gj gh gi my mz bd b be z dk"><em class="na">Equation 4: Linear Regression Cost Function (vectorized form)</em></figcaption></figure><p id="2c9f" class="pw-post-body-paragraph lj lk it ll b lm mf kd lo lp mg kg lr ls mh lu lv lw mi ly lz ma mj mc md me im bi translated"><strong class="ll jd">直觉一.</strong></p><p id="7d16" class="pw-post-body-paragraph lj lk it ll b lm mf kd lo lp mg kg lr ls mh lu lv lw mi ly lz ma mj mc md me im bi translated">为了简化解释，让我们尝试手动计算仅由 SBP 数据集的前 3 个值组成的较小数据集的<em class="nb">成本函数</em>，以及θ = [120.0，10.0]的<em class="nb">。</em>目前，这些参数是随机选择的，因为我们现在不需要设置最佳的<em class="nb">θ</em><em class="nb">。</em>我们将分割<em class="nb"> X </em>和<em class="nb"> y </em>，产生数组<em class="nb"> X_1 </em>和<em class="nb"> y_1 </em>:</p><figure class="ml mm mn mo gt mp"><div class="bz fp l di"><div class="nd ne l"/></div><figcaption class="mw mx gj gh gi my mz bd b be z dk"><em class="na">Code 10: Make a vector X_1 and y_1 with the first 3 values of X, and y.</em></figcaption></figure><p id="c9df" class="pw-post-body-paragraph lj lk it ll b lm mf kd lo lp mg kg lr ls mh lu lv lw mi ly lz ma mj mc md me im bi translated">同样，我们必须设置<em class="nb"> m=3 </em>，因为我们现在有三个样本。让我们将数据和假设绘制如下:</p><figure class="ml mm mn mo gt mp"><div class="bz fp l di"><div class="nd ne l"/></div><figcaption class="mw mx gj gh gi my mz bd b be z dk"><em class="na">Code 11: Plot data and Hypothesis</em></figcaption></figure><figure class="ml mm mn mo gt mp gh gi paragraph-image"><div role="button" tabindex="0" class="mq mr di ms bf mt"><div class="gh gi ok"><img src="../Images/eb6375760d2b1ffb9705a63b322bcb1b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Bs5poLEvmurrEkoRcKR4tA.png"/></div></div><figcaption class="mw mx gj gh gi my mz bd b be z dk"><em class="na">Figure 4: Plot of the first 3 values of the dataset; θ = [120.0; 10.0]</em></figcaption></figure><p id="1214" class="pw-post-body-paragraph lj lk it ll b lm mf kd lo lp mg kg lr ls mh lu lv lw mi ly lz ma mj mc md me im bi translated">SBP 前三个值(蓝点)对应的矢量<em class="nb"> y </em>为:</p><p id="722f" class="pw-post-body-paragraph lj lk it ll b lm mf kd lo lp mg kg lr ls mh lu lv lw mi ly lz ma mj mc md me im bi translated"><em class="nb"> y = [117.0，120.0，145.0] </em></p><p id="9e30" class="pw-post-body-paragraph lj lk it ll b lm mf kd lo lp mg kg lr ls mh lu lv lw mi ly lz ma mj mc md me im bi translated">由于我们的<em class="nb"> θ </em>为=【120，10.0】，<em class="nb"> h = </em> <em class="nb"> θ* </em> X_1 的乘积将由以下向量表示，(红线上的点高亮显示):</p><p id="e115" class="pw-post-body-paragraph lj lk it ll b lm mf kd lo lp mg kg lr ls mh lu lv lw mi ly lz ma mj mc md me im bi translated"><em class="nb"> h = θ*X_1 = [112.7，114.0，131.5] </em></p><p id="dd46" class="pw-post-body-paragraph lj lk it ll b lm mf kd lo lp mg kg lr ls mh lu lv lw mi ly lz ma mj mc md me im bi translated">蓝色虚线突出显示了实际<em class="nb"> y_1 </em>值和预测值之间的距离。现在，我们有了所有我们需要的，来计算成本函数<em class="nb"> J </em>。我们将应用解决方案 1 中描述的<em class="nb">成本函数</em>:</p><figure class="ml mm mn mo gt mp gh gi paragraph-image"><div role="button" tabindex="0" class="mq mr di ms bf mt"><div class="gh gi ol"><img src="../Images/d0186220d15bfd218f156f05771ac1f6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*l78L7y0A1y_z9WyT8LF5Pg.png"/></div></div><figcaption class="mw mx gj gh gi my mz bd b be z dk"><em class="na">Solution I</em>: Calculating the Cost Function</figcaption></figure><p id="b3a9" class="pw-post-body-paragraph lj lk it ll b lm mf kd lo lp mg kg lr ls mh lu lv lw mi ly lz ma mj mc md me im bi translated">…成本函数(J)是= 39.3</p><p id="7820" class="pw-post-body-paragraph lj lk it ll b lm mf kd lo lp mg kg lr ls mh lu lv lw mi ly lz ma mj mc md me im bi translated"><strong class="ll jd">Python 中的代价函数。</strong></p><p id="955d" class="pw-post-body-paragraph lj lk it ll b lm mf kd lo lp mg kg lr ls mh lu lv lw mi ly lz ma mj mc md me im bi translated">以下 Python 代码实现了<em class="nb">成本函数</em>:</p><figure class="ml mm mn mo gt mp"><div class="bz fp l di"><div class="nd ne l"/></div><figcaption class="mw mx gj gh gi my mz bd b be z dk"><em class="na">Code 12: The code for calculating the Cost Function</em></figcaption></figure><p id="612d" class="pw-post-body-paragraph lj lk it ll b lm mf kd lo lp mg kg lr ls mh lu lv lw mi ly lz ma mj mc md me im bi translated">该代码逐步实现<em class="nb">等式 4 中描述的成本函数(矢量化)。</em>让我们再重复一遍:</p><ol class=""><li id="ffe0" class="nv nw it ll b lm mf lp mg ls nx lw ny ma nz me oa ob oc od bi translated">假设(<em class="nb"> h=θX </em>)</li><li id="3c2a" class="nv nw it ll b lm oe lp of ls og lw oh ma oi me oa ob oc od bi translated">平方误差即= (h-y) ^2)</li><li id="cc38" class="nv nw it ll b lm oe lp of ls og lw oh ma oi me oa ob oc od bi translated">成本函数<em class="nb"> J </em>即= 1/2m * Sum(平方误差)</li></ol><p id="11be" class="pw-post-body-paragraph lj lk it ll b lm mf kd lo lp mg kg lr ls mh lu lv lw mi ly lz ma mj mc md me im bi translated">既然我们已经理解了<em class="nb">成本函数</em>计算的机制，让我们回到完整的 SBP 数据集(16 名患者)。如果我们想计算整个 SBP 数据集的成本函数，使用<em class="nb">θ=【140.0；5.0]，</em>我们将键入:</p><figure class="ml mm mn mo gt mp"><div class="bz fp l di"><div class="nd ne l"/></div><figcaption class="mw mx gj gh gi my mz bd b be z dk"><em class="na">Code 13: Running calcCostFunction</em></figcaption></figure><p id="dbbd" class="pw-post-body-paragraph lj lk it ll b lm mf kd lo lp mg kg lr ls mh lu lv lw mi ly lz ma mj mc md me im bi translated">该函数将返回 J = 138.04，这是为<em class="nb">θ=【140.0】计算的<em class="nb">代价函数</em>；5.0] </em>。这个<em class="nb"> J </em>不是我们能找到的最小<em class="nb"> J </em>，因为我们已经手动设置了<em class="nb"> θ，</em>不知道如何最小化它。下面的直觉 II 可以帮助我们更好地理解我们手工方法的局限性。</p><p id="0e4a" class="pw-post-body-paragraph lj lk it ll b lm mf kd lo lp mg kg lr ls mh lu lv lw mi ly lz ma mj mc md me im bi translated"><strong class="ll jd">直觉二。</strong></p><p id="b0d3" class="pw-post-body-paragraph lj lk it ll b lm mf kd lo lp mg kg lr ls mh lu lv lw mi ly lz ma mj mc md me im bi translated">以下代码随机生成 10 个<em class="nb"> θ </em>向量，并将它们传递给<em class="nb"> calcCostFunction </em>，生成一个相对成本函数表(<em class="nb"> J </em>):</p><figure class="ml mm mn mo gt mp"><div class="bz fp l di"><div class="nd ne l"/></div><figcaption class="mw mx gj gh gi my mz bd b be z dk"><em class="na">Code 14: Try random θ and calculate the Cost Function</em></figcaption></figure><p id="2bc5" class="pw-post-body-paragraph lj lk it ll b lm mf kd lo lp mg kg lr ls mh lu lv lw mi ly lz ma mj mc md me im bi translated">产生的输出是:</p><pre class="ml mm mn mo gt ng nh ni nj aw nk bi"><span id="623d" class="nl ks it nh b gy nm nn l no np"><strong class="nh jd">[Th0 Th1] J</strong><br/>[38. 55.] 5100.4688623710845<br/>[71. 47.] 2352.6631642080174<br/>[28. 76.] 7148.466632549135<br/>[73. 75.] 3579.826857778751<br/>[79. 47.] 1925.1631642080174<br/>[12. 42.] 7320.026790356101<br/>[68. 25.] 1992.2131192595837<br/>[25. 92.] 8565.015528875269<br/>[51. 46.] 3667.1483894376343<br/>[13. 62.] 7992.509785763768</span></pre><p id="b0c2" class="pw-post-body-paragraph lj lk it ll b lm mf kd lo lp mg kg lr ls mh lu lv lw mi ly lz ma mj mc md me im bi translated">“带回家的信息”是试图手工最小化<em class="nb"> J </em>不是正确的方法。在随机选择的<em class="nb"> θ的</em>上运行 10 次之后，<em class="nb"> J </em>的行为是不可预测的。而且，没有办法根据<em class="nb"> θ来猜测<em class="nb"> J </em>。</em>那么问题来了:我们如何选择<em class="nb"> θ，</em>求最小 J？我们需要一个能为我们最小化<em class="nb"> J </em>的算法，这个算法就是下一步的论证。</p><h1 id="d7b3" class="kr ks it bd kt ku kv kw kx ky kz la lb ki lc kj ld kl le km lf ko lg kp lh li bi translated"><strong class="ak">步骤 10:梯度下降</strong></h1><p id="9897" class="pw-post-body-paragraph lj lk it ll b lm ln kd lo lp lq kg lr ls lt lu lv lw lx ly lz ma mb mc md me im bi translated">我们感兴趣的是使用<strong class="ll jd"> <em class="nb">【梯度下降】</em></strong><em class="nb"/><strong class="ll jd"><em class="nb"/></strong>找到<em class="nb">成本函数</em>的最小值，这是一种可以使这种搜索自动化的算法。梯度下降计算<em class="nb">代价函数</em>的导数，通过参数<em class="nb"> α、</em>更新向量<em class="nb"> θ </em> <strong class="ll jd"> <em class="nb"> </em> </strong>，即学习率。从现在开始，我们将把 SBP 数据集称为<strong class="ll jd">训练集。</strong>这种澄清是必要的，因为<em class="nb">梯度下降</em>将使用数据集的实际矢量<em class="nb"> y </em>和<em class="nb"> h </em>矢量预测之间的差异来“学习”如何找到最小值<em class="nb"> J </em>。该算法将重复，直到它将收敛。<em class="nb"> θ </em>更新必须同时进行。</p><figure class="ml mm mn mo gt mp gh gi paragraph-image"><div role="button" tabindex="0" class="mq mr di ms bf mt"><div class="gh gi om"><img src="../Images/f7e1a6a498442f10153b5c3f3e0b48e4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*n_cDh4ootRTtZttCf9xfGw.png"/></div></div><figcaption class="mw mx gj gh gi my mz bd b be z dk"><em class="na">Equation 4: Gradient Descent implementation</em></figcaption></figure><p id="c503" class="pw-post-body-paragraph lj lk it ll b lm mf kd lo lp mg kg lr ls mh lu lv lw mi ly lz ma mj mc md me im bi translated">由于我们使用线性代数，矢量化实现如下:</p><figure class="ml mm mn mo gt mp gh gi paragraph-image"><div role="button" tabindex="0" class="mq mr di ms bf mt"><div class="gh gi on"><img src="../Images/3ea7fa35bcfdacc397918ea79fdee6c9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*av02yv5VOvj8jheI_QpcWQ.png"/></div></div><figcaption class="mw mx gj gh gi my mz bd b be z dk"><em class="na">Equation 5: Gradient Descent (vectorized form)</em></figcaption></figure><p id="e60b" class="pw-post-body-paragraph lj lk it ll b lm mf kd lo lp mg kg lr ls mh lu lv lw mi ly lz ma mj mc md me im bi translated">注意，这里我们必须转置<em class="nb"> X </em>，因为<em class="nb"> X </em>是一个[16，2]矩阵，而<em class="nb">错误</em>是一个[16，1]向量。</p><p id="e6c4" class="pw-post-body-paragraph lj lk it ll b lm mf kd lo lp mg kg lr ls mh lu lv lw mi ly lz ma mj mc md me im bi translated"><strong class="ll jd">梯度下降实现。</strong></p><p id="5c0a" class="pw-post-body-paragraph lj lk it ll b lm mf kd lo lp mg kg lr ls mh lu lv lw mi ly lz ma mj mc md me im bi translated">以下 Python 代码实现了梯度下降。我们将使用<em class="nb">方程 5 </em>的矢量化形式:</p><figure class="ml mm mn mo gt mp"><div class="bz fp l di"><div class="nd ne l"/></div><figcaption class="mw mx gj gh gi my mz bd b be z dk"><em class="na">Code 15: The Gradient Descent function</em></figcaption></figure><p id="52ef" class="pw-post-body-paragraph lj lk it ll b lm mf kd lo lp mg kg lr ls mh lu lv lw mi ly lz ma mj mc md me im bi translated">要运行<em class="nb">梯度下降</em>，我们必须初始化<em class="nb"> θ </em>、<em class="nb">迭代、</em>和<em class="nb"> α、</em>，它们与<em class="nb"> X </em>和<em class="nb"> y </em>一起是<em class="nb">梯度下降</em>函数的参数:</p><figure class="ml mm mn mo gt mp"><div class="bz fp l di"><div class="nd ne l"/></div><figcaption class="mw mx gj gh gi my mz bd b be z dk"><em class="na">Code 16: Running the Gradient Descent</em></figcaption></figure><p id="203d" class="pw-post-body-paragraph lj lk it ll b lm mf kd lo lp mg kg lr ls mh lu lv lw mi ly lz ma mj mc md me im bi translated">结果收集在“结果”列表中。该列表由找到的<em class="nb"> θ、</em>加上包含<em class="nb"> θ </em>和<em class="nb"> J </em>历史的两个列表组成。经过 2000 次迭代后，<em class="nb">梯度下降</em>找到了<em class="nb">θ=【128.4，9.9】</em>和<em class="nb"> J = 59.7 </em>，这是 J 的最小值。我们将使用这两个列表来绘制<em class="nb">梯度下降</em>活动。以下代码将绘制训练集和<em class="nb"> h </em>。</p><figure class="ml mm mn mo gt mp"><div class="bz fp l di"><div class="nd ne l"/></div><figcaption class="mw mx gj gh gi my mz bd b be z dk"><em class="na">Code 17: Plot dataset and h for θ = [128.4, 9.9]. </em>J = 59.7 is the minimum</figcaption></figure><figure class="ml mm mn mo gt mp gh gi paragraph-image"><div class="gh gi nq"><img src="../Images/4bd520aca1d5b6435f4ae46357b3bee8.png" data-original-src="https://miro.medium.com/v2/resize:fit:792/format:webp/1*ObtZl1j2YTR6uW28kUvBqQ.png"/></div><figcaption class="mw mx gj gh gi my mz bd b be z dk"><em class="na">Figure 5: Plot of dataset and h; θ = [128.4; 9.9]; J = 59.7</em></figcaption></figure><p id="5b38" class="pw-post-body-paragraph lj lk it ll b lm mf kd lo lp mg kg lr ls mh lu lv lw mi ly lz ma mj mc md me im bi translated"><em class="nb">假设 h </em>现在符合我们的数据！</p><p id="e395" class="pw-post-body-paragraph lj lk it ll b lm mf kd lo lp mg kg lr ls mh lu lv lw mi ly lz ma mj mc md me im bi translated">我们来绘制一下<em class="nb"> θ历史:</em></p><figure class="ml mm mn mo gt mp"><div class="bz fp l di"><div class="nd ne l"/></div><figcaption class="mw mx gj gh gi my mz bd b be z dk"><em class="na">Code 18: Plot the θ history</em></figcaption></figure><p id="bcb8" class="pw-post-body-paragraph lj lk it ll b lm mf kd lo lp mg kg lr ls mh lu lv lw mi ly lz ma mj mc md me im bi translated"><em class="nb"> θ </em>历史曲线如图<em class="nb">图 6 </em>所示。红色曲线代表<em class="nb"> θ </em> _0，绿色曲线代表<em class="nb"> θ </em> _1。2000 次迭代后，<em class="nb"> θ </em>为<em class="nb">=【128.4；9.9] </em></p><figure class="ml mm mn mo gt mp gh gi paragraph-image"><div class="gh gi oo"><img src="../Images/8d74c48da866ff5c4222cf7dd48eea45.png" data-original-src="https://miro.medium.com/v2/resize:fit:784/format:webp/1*DFd-HuHJ7qC-HTyuzoAQYQ.png"/></div><figcaption class="mw mx gj gh gi my mz bd b be z dk"><em class="na">Figure 6: The θ history plot. The red curve represents θ0; the green curve represents θ1</em></figcaption></figure><p id="6ee5" class="pw-post-body-paragraph lj lk it ll b lm mf kd lo lp mg kg lr ls mh lu lv lw mi ly lz ma mj mc md me im bi translated">现在我们来绘制一下<em class="nb"> J </em>的历史:</p><figure class="ml mm mn mo gt mp"><div class="bz fp l di"><div class="nd ne l"/></div><figcaption class="mw mx gj gh gi my mz bd b be z dk"><em class="na">Code 19: Plot the J history</em></figcaption></figure><figure class="ml mm mn mo gt mp gh gi paragraph-image"><div class="gh gi op"><img src="../Images/ff2145ba8c3f326dd01caaeeca0f5d08.png" data-original-src="https://miro.medium.com/v2/resize:fit:796/format:webp/1*UIiPbA2sVstWeQS0ck_bcg.png"/></div><figcaption class="mw mx gj gh gi my mz bd b be z dk"><em class="na">Figure 7: The J history plot</em></figcaption></figure><p id="b7a0" class="pw-post-body-paragraph lj lk it ll b lm mf kd lo lp mg kg lr ls mh lu lv lw mi ly lz ma mj mc md me im bi translated">在大约 200 次迭代之后，成本函数下降，在 1500 次迭代之后稳定在 59.7 左右。<em class="nb"> J </em>曲线取决于我们设置为 0.01 的<em class="nb"> α、</em>。</p><h1 id="79d0" class="kr ks it bd kt ku kv kw kx ky kz la lb ki lc kj ld kl le km lf ko lg kp lh li bi translated"><strong class="ak">第 11 步:预测</strong></h1><p id="8fc5" class="pw-post-body-paragraph lj lk it ll b lm ln kd lo lp lq kg lr ls lt lu lv lw lx ly lz ma mb mc md me im bi translated">现在我们已经找到了最佳的<em class="nb"> θ，</em>我们可以预测一个 75 岁老人的收缩压。该查询是一个向量，由两个数字[1，75]组成。第一个数字对应于特征<em class="nb"> x_0 </em>。为了运行预测，我们必须使用我们在<em class="nb">步骤 5:特征缩放和归一化</em>中计算的<em class="nb">μ</em>和<em class="nb">σ</em>参数来缩放和归一化查询向量。查询向量将是[1，1.29]。然后，我们要将<em class="nb">查询</em>乘以<em class="nb"> θ </em>向量(<em class="nb">θ</em>=【128.4，9.95】)。下面的代码实现了预测。</p><figure class="ml mm mn mo gt mp"><div class="bz fp l di"><div class="nd ne l"/></div><figcaption class="mw mx gj gh gi my mz bd b be z dk"><em class="na">Code 20: Predicting SBP</em></figcaption></figure><p id="e85e" class="pw-post-body-paragraph lj lk it ll b lm mf kd lo lp mg kg lr ls mh lu lv lw mi ly lz ma mj mc md me im bi translated">75 岁老人的 SBP 是:141.2</p><h1 id="bbe0" class="kr ks it bd kt ku kv kw kx ky kz la lb ki lc kj ld kl le km lf ko lg kp lh li bi translated"><strong class="ak">步骤 12:关于<em class="na"> </em>学习常数</strong> <em class="na"> α </em>的直觉</h1><p id="deea" class="pw-post-body-paragraph lj lk it ll b lm ln kd lo lp lq kg lr ls lt lu lv lw lx ly lz ma mb mc md me im bi translated">让我们用学习率<em class="nb"> α </em>做一些实验。改变<em class="nb"> α </em>会影响<em class="nb"> J </em>的动态。如果<em class="nb"> α </em>过小，<em class="nb">梯度下降</em>会收敛缓慢，我们需要用更多的迭代来训练它，以找到<em class="nb"> J </em>的最小值。相反，如果<em class="nb"> α </em>太大，则<em class="nb">梯度下降</em>有永不收敛的风险。有趣的是，对于大约 1.9 的<em class="nb"> α </em>值，<em class="nb">梯度下降</em>收敛，但是对于最初的 40 次迭代，<em class="nb"> θ </em>的行为是紊乱的，以便连续达到稳定。(图 8)</p><figure class="ml mm mn mo gt mp gh gi paragraph-image"><div role="button" tabindex="0" class="mq mr di ms bf mt"><div class="gh gi oq"><img src="../Images/5053d36b642b031bffbecab0cb0a6c24.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*QB6R8S008QoCS_3Bt0ZJ-w.png"/></div></div><figcaption class="mw mx gj gh gi my mz bd b be z dk">Figure 8: Experiments with α. Panel <strong class="bd or">A</strong> shows <em class="na">h</em>, <em class="na">J</em> and <em class="na">θ</em>, with α = 0.001. If α is too little, 2000 iterations are not sufficient; Gradient Descent will be slow in converging, and it will require ~ 10000 iterations for finding the minimum J (data not shown). Panel <strong class="bd or">B </strong>shows the opposite situation. With α = 1.9, Gradient Descent converges, but initially,<em class="na"> </em>the searching of <em class="na">θ </em>shows turbulence. After 40 iterations <em class="na">θ </em>reaches stability, and finally, the algorithm converges.</figcaption></figure><h1 id="7e1a" class="kr ks it bd kt ku kv kw kx ky kz la lb ki lc kj ld kl le km lf ko lg kp lh li bi translated"><strong class="ak">步骤 13:J 和</strong> <em class="na"> θ </em>的等高线图</h1><p id="42b6" class="pw-post-body-paragraph lj lk it ll b lm ln kd lo lp lq kg lr ls lt lu lv lw lx ly lz ma mb mc md me im bi translated">我们可以创建一个等高线图，它是一个包含许多同心轨迹的图形。对于每条轨道，有多对与恒定值<em class="nb"> J </em>相关联的<em class="nb"> θ </em>。最小值<em class="nb"> J </em>对应的<em class="nb"> θ </em>位于中心(红点)。其他同心线对应<em class="nb"> J </em>的所有不同值。距离中心越远，成本函数值<em class="nb"> J </em>越高。</p><figure class="ml mm mn mo gt mp"><div class="bz fp l di"><div class="nd ne l"/></div><figcaption class="mw mx gj gh gi my mz bd b be z dk"><em class="na">Code 21: Drawing a Contout Plot of J and θ</em></figcaption></figure><p id="bf4c" class="pw-post-body-paragraph lj lk it ll b lm mf kd lo lp mg kg lr ls mh lu lv lw mi ly lz ma mj mc md me im bi translated"><em class="nb">代码 20 </em>产生以下图形:</p><figure class="ml mm mn mo gt mp gh gi paragraph-image"><div class="gh gi os"><img src="../Images/8a84290a01c73a643fe592f1e18be345.png" data-original-src="https://miro.medium.com/v2/resize:fit:814/format:webp/1*h254gk7_x9eYuDtbHB7YOg.png"/></div><figcaption class="mw mx gj gh gi my mz bd b be z dk">Figure 9: The contour plot of J and theta</figcaption></figure><p id="45e2" class="pw-post-body-paragraph lj lk it ll b lm mf kd lo lp mg kg lr ls mh lu lv lw mi ly lz ma mj mc md me im bi translated">注意<em class="nb">θ</em><em class="nb">=【128.4；9.9] </em>对应的最小值<em class="nb"> J </em> (59.7)，就是图形中心的红点。蓝点跟踪<em class="nb">梯度下降</em>收敛到最小值的路径。</p><h1 id="ff1a" class="kr ks it bd kt ku kv kw kx ky kz la lb ki lc kj ld kl le km lf ko lg kp lh li bi translated"><strong class="ak">步骤 14:如何修改多变量代码</strong></h1><p id="435c" class="pw-post-body-paragraph lj lk it ll b lm ln kd lo lp lq kg lr ls lt lu lv lw lx ly lz ma mb mc md me im bi translated">我们已经解释了具有一个变量的<em class="nb">线性回归的统计机制:SBP 数据集中的</em>特征<em class="nb">年龄</em>。这里提出的代码的主要部分也适用于多个变量。SBP 数据集由两个特征(<em class="nb">年龄</em>和<em class="nb">体重</em>)和一个输出:<em class="nb"> SBP </em>。在这一步中，我们将更新代码，使其能够适应多个变量。唯一需要调整的是:</p><ol class=""><li id="99c2" class="nv nw it ll b lm mf lp mg ls nx lw ny ma nz me oa ob oc od bi translated"><em class="nb">数据集上传</em></li><li id="d678" class="nv nw it ll b lm oe lp of ls og lw oh ma oi me oa ob oc od bi translated"><em class="nb">特征缩放和归一化功能</em></li><li id="e514" class="nv nw it ll b lm oe lp of ls og lw oh ma oi me oa ob oc od bi translated">向向量<em class="nb"> X </em>添加一列“1”的代码</li><li id="74c3" class="nv nw it ll b lm oe lp of ls og lw oh ma oi me oa ob oc od bi translated"><em class="nb">预测查询</em>。</li></ol><p id="b379" class="pw-post-body-paragraph lj lk it ll b lm mf kd lo lp mg kg lr ls mh lu lv lw mi ly lz ma mj mc md me im bi translated"><strong class="ll jd"> <em class="nb">数据集上传</em> </strong></p><p id="3c91" class="pw-post-body-paragraph lj lk it ll b lm mf kd lo lp mg kg lr ls mh lu lv lw mi ly lz ma mj mc md me im bi translated">必须修改上传数据集的代码，以生成新的<em class="nb"> X </em>向量，其中包含每位患者的<em class="nb">年龄</em>和<em class="nb">体重</em>:</p><figure class="ml mm mn mo gt mp"><div class="bz fp l di"><div class="nd ne l"/></div><figcaption class="mw mx gj gh gi my mz bd b be z dk"><em class="na">Code 22: The code for uploading the dataset for multiple variables</em></figcaption></figure><p id="cc04" class="pw-post-body-paragraph lj lk it ll b lm mf kd lo lp mg kg lr ls mh lu lv lw mi ly lz ma mj mc md me im bi translated">用于产生新 X 向量的 numpy 方法是<em class="nb">。因为我们现在想要一个具有两组不同特征的 X 向量。</em></p><p id="3ea4" class="pw-post-body-paragraph lj lk it ll b lm mf kd lo lp mg kg lr ls mh lu lv lw mi ly lz ma mj mc md me im bi translated"><strong class="ll jd"> <em class="nb">特征缩放和归一化功能</em> </strong></p><p id="a921" class="pw-post-body-paragraph lj lk it ll b lm mf kd lo lp mg kg lr ls mh lu lv lw mi ly lz ma mj mc md me im bi translated">在矢量<em class="nb"> mu </em>和<em class="nb"> sigma 中修改关于<em class="nb">特征缩放和归一化</em>的代码。现在这两个向量将各接受两个参数。</em></p><figure class="ml mm mn mo gt mp"><div class="bz fp l di"><div class="nd ne l"/></div><figcaption class="mw mx gj gh gi my mz bd b be z dk"><em class="na">Code 23: The FeatureScalingNormalization function for Linear Regression with Multiple Variables.</em></figcaption></figure><p id="3dec" class="pw-post-body-paragraph lj lk it ll b lm mf kd lo lp mg kg lr ls mh lu lv lw mi ly lz ma mj mc md me im bi translated"><strong class="ll jd">向向量<em class="nb"> X </em> </strong>添加一列“1”</p><p id="4474" class="pw-post-body-paragraph lj lk it ll b lm mf kd lo lp mg kg lr ls mh lu lv lw mi ly lz ma mj mc md me im bi translated">向<em class="nb"> X </em>向量添加“1”的行修改如下:</p><figure class="ml mm mn mo gt mp"><div class="bz fp l di"><div class="nd ne l"/></div><figcaption class="mw mx gj gh gi my mz bd b be z dk"><em class="na">Code 24: Adding a column of “ones” to the vector X.</em></figcaption></figure><p id="3f84" class="pw-post-body-paragraph lj lk it ll b lm mf kd lo lp mg kg lr ls mh lu lv lw mi ly lz ma mj mc md me im bi translated"><strong class="ll jd"><em class="nb">预测查询</em> </strong></p><p id="cba2" class="pw-post-body-paragraph lj lk it ll b lm mf kd lo lp mg kg lr ls mh lu lv lw mi ly lz ma mj mc md me im bi translated">预测的查询和归一化的代码修改如下:</p><figure class="ml mm mn mo gt mp"><div class="bz fp l di"><div class="nd ne l"/></div><figcaption class="mw mx gj gh gi my mz bd b be z dk"><em class="na">Code 25: The Query in Linear Regression with Multiple Variables</em></figcaption></figure><p id="d729" class="pw-post-body-paragraph lj lk it ll b lm mf kd lo lp mg kg lr ls mh lu lv lw mi ly lz ma mj mc md me im bi translated">在这种情况下，预测结果是 SBP =143.47</p><p id="7145" class="pw-post-body-paragraph lj lk it ll b lm mf kd lo lp mg kg lr ls mh lu lv lw mi ly lz ma mj mc md me im bi translated">有了这些变化，Python 代码就可以进行多变量线性回归了。每次从训练集中添加新功能时，您都必须更新代码！</p><p id="adac" class="pw-post-body-paragraph lj lk it ll b lm mf kd lo lp mg kg lr ls mh lu lv lw mi ly lz ma mj mc md me im bi translated">希望这篇帖子对你有用！</p><h1 id="09b3" class="kr ks it bd kt ku kv kw kx ky kz la lb ki lc kj ld kl le km lf ko lg kp lh li bi translated"><strong class="ak">参考文献</strong></h1><ol class=""><li id="a6f6" class="nv nw it ll b lm ln lp lq ls ot lw ou ma ov me oa ob oc od bi translated">Andrew NG，机器学习| Coursera。</li><li id="d914" class="nv nw it ll b lm oe lp of ls og lw oh ma oi me oa ob oc od bi translated">约翰·佩祖罗，假人生物统计学，威利，ISBN-13:9781185585</li><li id="2b7b" class="nv nw it ll b lm oe lp of ls og lw oh ma oi me oa ob oc od bi translated">施耐德，A；Hommel，G；Blettner，m .科学出版物评价系列的线性回归分析第 14 部分，Dtsch Arztebl Int 2010107(44): 776–82;DOI: 10.3238</li><li id="dd8a" class="nv nw it ll b lm oe lp of ls og lw oh ma oi me oa ob oc od bi translated">Chris Albon,《Python 机器学习指南》, O'Really，ISBN-13:978–1491989388。</li><li id="398e" class="nv nw it ll b lm oe lp of ls og lw oh ma oi me oa ob oc od bi translated">Aurélien Géron，使用 Scikit-Learn 和 TensorFlow 进行机器学习:构建智能系统的概念、工具和技术，O'Reilly，ISBN-13:978–1491962299。</li></ol></div></div>    
</body>
</html>