<html>
<head>
<title>Autonomous Agents And Multi-Agent Systems 101: Agents And Deception</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">自主代理和多代理系统 101:代理和欺骗</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/autonomous-agents-and-multi-agent-systems-101-agents-and-deception-775025f09d7b?source=collection_archive---------23-----------------------#2019-11-09">https://towardsdatascience.com/autonomous-agents-and-multi-agent-systems-101-agents-and-deception-775025f09d7b?source=collection_archive---------23-----------------------#2019-11-09</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="29f7" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">本文简要介绍了自主代理和多系统代理。此外，对代理使用的欺骗机制进行了展望。</h2></div><figure class="kh ki kj kk gt kl gh gi paragraph-image"><div role="button" tabindex="0" class="km kn di ko bf kp"><div class="gh gi kg"><img src="../Images/0b576c182e01a7ac80d39d92b3635668.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*B-OMt7n2GuFwUcy9"/></div></div><figcaption class="ks kt gj gh gi ku kv bd b be z dk">Photo by <a class="ae kw" href="https://unsplash.com/@dhudson_creative?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Debby Hudson</a> on <a class="ae kw" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><p id="10f8" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">人类使用<strong class="kz ir">欺骗机制来获得超越其他人类的优势</strong>。一些最典型的机制是(1)，不分享他们的信念(2)，假装能够执行某些动作甚至假装不能执行某个动作。在<strong class="kz ir">自治</strong> <strong class="kz ir">智能体和多智能体系统</strong>中，行话，(1)对应隐藏的实用程序，(2)对应隐藏的动作，(3)对应诱骗动作。</p><p id="42ab" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">有人可能会问，一个代理人如何利用欺骗来最大化自己的回报？一个特工也能使用欺骗手段吗？在合作环境中，代理人可以使用欺骗手段吗？</p><p id="6b16" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">为了回答这些问题，我们首先引入一个<strong class="kz ir">主体</strong><em class="lt">【P . Maes，1993】</em>的概念:</p><p id="2d68" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">一个(理性的)主体是一个试图在复杂环境中实现一组目标的系统，它从所有可能的行动中选择对自己具有最佳预期结果的行动(具有更大<strong class="kz ir">效用</strong>的行动)。为了应对环境的变迁，智能体需要具有自主性和适应性。在多代理场景中，代理可以竞争，它们之间的交互由游戏遭遇来描述。为了使效用最大化，效用函数根据不同选项对个人的效用对它们进行排序。合作的代理有相同的目标，可以一起工作来实现一个共同的目标。</p><figure class="kh ki kj kk gt kl gh gi paragraph-image"><div role="button" tabindex="0" class="km kn di ko bf kp"><div class="gh gi lu"><img src="../Images/e38c1d9cfcd266e0699e15e0f19c4a34.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*VUvJHYlMh7wnl9X1"/></div></div><figcaption class="ks kt gj gh gi ku kv bd b be z dk">Nice looking agent. Photo by <a class="ae kw" href="https://unsplash.com/@agkdesign?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Alex Knight</a> on <a class="ae kw" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><p id="30cd" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">事实上，我们的行为类似于代理人:理性的人希望通过选择最大化我们成功机会的行动来实现一组目标。至少有时候是这样。</p><p id="32d5" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">为了形式化代理之间的交互，这通常是在欺骗发生时，让我们考虑<strong class="kz ir">游戏和</strong>游戏遭遇的概念:</p><p id="c7e0" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">游戏是一种竞争活动，玩家根据定义的规则(策略)相互竞争(互动)<em class="lt">【Wooldridge m .，Paterson S .，2002】</em>。玩家只能采取由环境定义的特定动作。假设代理同时选择一个动作来执行，他们动作的结果取决于动作的<strong class="kz ir">组合。</strong>然后，根据所有代理执行的一组累积动作，改变环境。这个事实产生了一个问题:如果所有的代理人都影响环境，如果所有的代理人都想最大化他们的效用，<strong class="kz ir">他们应该如何行动？</strong>适当行动的选择有一些相关问题，包括但不限于目标的性质(静态或动态)、可重用性、对导致紧急行为的行动的理解深度以及感知和行动之间的关系。博弈论研究以效用最大化为目标的理性主体之间的相互作用。代理人可以通过谈判来获得对双方都有利的地位。</p><p id="cb46" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">在描绘代理人之间的游戏遭遇之前，让我们更深入地了解一下<strong class="kz ir">欺骗</strong>的概念:</p><p id="5790" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">人类在谈判时经常使用欺骗来提高成功的概率。在目标冲突的情况下，代理人有效谈判的能力与对手掌握的信息有关。让我们假设两个相互竞争的代理人相遇，他们有可能使用以下欺骗机制。隐藏的公用事业和三。诱饵行动。不完全信息下的代理间谈判可能出现欺骗技术，因为谈判通常假设代理值得信任，但情况并非总是如此【Zlotkin G .，Josenschein J .，1991】。由于代理共存并可能干扰所执行的动作的结果，因此存在合作的可能性，以互相帮助并以较低的总成本实现两个目标。</p><p id="d852" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">让我们假设一场游戏遭遇战发生了。游戏由<em class="lt">双矩阵 b </em>表示，其中<em class="lt">智能体 i </em>和<em class="lt">智能体 j </em>的目标不同，分别为<em class="lt"> gi </em>和<em class="lt"> gj，</em>。入口的值分别对应于<em class="lt">代理人 i </em>和<em class="lt">代理人 j </em>的让渡效用。两个代理人都想将世界从初始状态转变为满足其目标的状态。<em class="lt">代理 i </em>是行播放器<em class="lt">代理 j </em>是列播放器。两个玩家可以执行相同的行动，A 和 b。<strong class="kz ir">欺骗技术可以用来最大化其中一个代理的整体效用。</strong>游戏如下表所示:</p><figure class="kh ki kj kk gt kl gh gi paragraph-image"><div class="gh gi lv"><img src="../Images/08a6257e3be741565db08db385343c4b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1088/format:webp/0*5910IqR_zHZrKiGW.png"/></div></figure><p id="3f93" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">让我们假设<em class="lt">代理人 i </em>知道<em class="lt">代理人 j i </em>将执行动作 a。结果产生:</p><figure class="kh ki kj kk gt kl gh gi paragraph-image"><div class="gh gi lw"><img src="../Images/dcbbb44bafd2c3fc64837a2ea9023f7b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1050/format:webp/0*PqJ7gtKVyLyJQB8V.png"/></div></figure><p id="7b63" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">在这种情况下，<em class="lt">代理 i </em>也应该执行<em class="lt">动作 A </em>，因为交付的效用最大。如果但如果<em class="lt">代理 j </em>采取<em class="lt">行动 B </em>，我们有:</p><figure class="kh ki kj kk gt kl gh gi paragraph-image"><div class="gh gi lx"><img src="../Images/66bc52891fc38d5a8ff94eba193949a5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1024/format:webp/0*kbWqQ76ehb7s6cj_.png"/></div></figure><p id="ef13" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">因此，<em class="lt">代理 i </em>也会选择<em class="lt">动作 B </em>，因为 1 大于 0。<em class="lt">代理人 i </em>的最优策略由<em class="lt">代理人 j </em>的选择决定。如果<em class="lt">代理 j </em>通知<em class="lt">代理 i </em>他只能采取<em class="lt">动作 B </em>(隐藏动作)，这将导致<em class="lt">代理 i </em>执行<em class="lt">动作 B </em>(因为 1 大于 0，因此该动作是提供最大效用的动作)。尽管如此，<em class="lt">代理 i </em>可以执行<em class="lt">动作 A </em>，为他产生效用二，为<em class="lt">代理 i </em>产生效用零。</p><p id="cf66" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">隐藏的效用机制被不想分享它的效用的代理人使用。如果一个代理不共享它与每个动作相关的效用，那么另一个代理将会只根据它的效用来选择动作(至少最初是这样)。这样的决定会导致次优选项，例如，当<em class="lt">代理 j </em>选择<em class="lt">动作 A </em>而<em class="lt">代理 i </em>选择<em class="lt">动作 B </em>时。现在让我们假设<em class="lt">代理 j </em>只能执行<em class="lt">动作 A </em>，但是正在使用<strong class="kz ir">诱饵动作</strong>机制，<strong class="kz ir">假装他可以执行<em class="lt">动作 B </em> </strong>。合作代理总是理性地选择<em class="lt">动作 A </em>，因为它可能产生最高的结果。尽管如此，如果<em class="lt">代理人 i </em>是一个竞争代理人，不仅旨在最大化其效用，而且旨在最小化其对手效用(<strong class="kz ir">零和博弈</strong>)，他可以理性地选择<em class="lt">行动 B </em>。诱饵行动是一种防范竞争对手并想最小化他人效用的手段。很明显，在竞争的情况下，一个代理人可以使用几种欺骗技术来最大化其报酬。</p><p id="f9ae" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">相反，在代理人希望最小化总成本(最大化总效用)的情况下，通常使用欺骗机制是没有意义的，因为它们会给任务带来额外的困难。在没有严格优势策略的情况下，需要更多的规则来解决博弈。</p><p id="49ab" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">纳什均衡的概念和帕累托最优的概念对得出结论很重要。纳什均衡是每个参与人的一套策略，比如每个参与人都没有单方面改变策略的动机。纳什均衡本质上是 T4 稳定的，可以帮助解决第一场比赛的问题。在第一场比赛中，有两个纳什均衡:<strong class="kz ir">当两个代理人选择相同的行动</strong>。如果没有其他结果在不使其他人变得更糟的情况下提高一个参与者的效用，那么这个结果就是帕累托有效的。<strong class="kz ir">欺骗的影响会影响代理人，因为他们相信某个结果处于纳什均衡或帕累托有效，而实际上并非如此</strong>。</p><figure class="kh ki kj kk gt kl gh gi paragraph-image"><div role="button" tabindex="0" class="km kn di ko bf kp"><div class="gh gi ly"><img src="../Images/9ae92edc997c5c0afc9eb261a75812a3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*Gydko_28lu-NUIdl"/></div></div><figcaption class="ks kt gj gh gi ku kv bd b be z dk">Nash Equilibrium. Neither of the rocks that compose the pile has the motivation to move. Photo by <a class="ae kw" href="https://unsplash.com/@dhudson_creative?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Debby Hudson</a> on <a class="ae kw" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><p id="afa5" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">我们假设在<em class="lt">游戏 1 </em>，<em class="lt">代理人 i </em>只能挑选<em class="lt">动作 A </em>，但是告诉代理人 j 他可以挑选所有动作。给定纳什均衡，当两个代理都选择<em class="lt">行动 B </em>时，有欺骗的空间。如果<em class="lt">代理人 i </em>选择<em class="lt">动作 A </em>，而<em class="lt">代理人 j </em>选择<em class="lt">动作 B </em>，那么<em class="lt">代理人 i </em>将获得两个效用点，而<em class="lt">代理人 j </em>将获得零个效用点。反过来，<em class="lt">代理人 i </em>可以告诉<em class="lt">代理人 j </em>他不能选择<em class="lt">行动 B </em>，从而暗示<em class="lt">代理人 j </em>总能选择<em class="lt">行动 A </em>(纳什均衡)。<em class="lt">代理人 i </em>可以选择<em class="lt">行动 B </em>，这样就不会获得太多的效用，但同时，会使对手的效用最小化。欺骗会给人一种纳什均衡的错觉。这种推理类似于帕累托最优。</p><p id="eedd" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">从上面的分析中，我们可以提炼出一些在自利和合作环境下设计理性主体的原则。</p><p id="b00b" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">在利己的情况下:</p><p id="812a" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">💢一个人应该隐藏他们的效用，以获得最初的优势。</p><p id="8d4f" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">💢一个人可以使用诱饵行动来防范另一个代理(强制情况，如纳什均衡)。</p><p id="35c9" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">💢如果目标是最小化对手的效用，人们可以隐藏他们的行动</p><p id="e305" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">尽管这些原则在理论上是合理的，但在实践中，竞争而不是合作会导致更糟糕的结果。</p><p id="a7af" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">✔️在合作场景中，大多数情况下，欺骗机制没有意义，因为它们难以沟通，从而使实现共同目标变得复杂。</p><p id="01d9" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated"><strong class="kz ir">结论</strong>欺骗机制可以被竞争的代理人用来最大化他们的效用，在竞争、零和的情况下产生更好的结果。通常，通过合作或策略，如纳什均衡，可以获得很好的交易。</p><p id="f794" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated"><strong class="kz ir">致谢</strong>感谢 Rui Henriques 教授提供的课程材料，这些材料是本文的基础，同时也感谢他的指导和建议。</p></div></div>    
</body>
</html>