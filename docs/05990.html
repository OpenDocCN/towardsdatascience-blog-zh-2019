<html>
<head>
<title>Generating Titles for Kaggle Kernels with LSTM</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">用 LSTM 为 Kaggle 内核生成标题</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/generating-titles-for-kaggle-kernels-with-lstm-957541aff48f?source=collection_archive---------17-----------------------#2019-08-31">https://towardsdatascience.com/generating-titles-for-kaggle-kernels-with-lstm-957541aff48f?source=collection_archive---------17-----------------------#2019-08-31</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><figure class="is it gp gr iu iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi ir"><img src="../Images/97736b801937cb2729b90dfcd1151c2c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*9UdtXe0Mln5dBYKFLqcfKA.jpeg"/></div></div><figcaption class="jc jd gj gh gi je jf bd b be z dk">Photo by <a class="ae jg" href="https://www.pexels.com/@donatello-trisolino-572447?utm_content=attributionCopyText&amp;utm_medium=referral&amp;utm_source=pexels" rel="noopener ugc nofollow" target="_blank">Donatello Trisolino </a>from <a class="ae jg" href="https://www.pexels.com/photo/person-typing-1375261/?utm_content=attributionCopyText&amp;utm_medium=referral&amp;utm_source=pexels" rel="noopener ugc nofollow" target="_blank">Pexels</a></figcaption></figure><div class=""/><div class=""><h2 id="7d08" class="pw-subtitle-paragraph kg ji jj bd b kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx dk translated">使用 PyTorch 的小型深度学习项目</h2></div><h1 id="94cd" class="ky kz jj bd la lb lc ld le lf lg lh li kp lj kq lk ks ll kt lm kv ln kw lo lp bi translated">介绍</h1><p id="2c26" class="pw-post-body-paragraph lq lr jj ls b lt lu kk lv lw lx kn ly lz ma mb mc md me mf mg mh mi mj mk ml im bi translated">当我第一次发现<a class="ae jg" href="https://medium.com/machine-learning-bites/deeplearning-series-sequence-models-7855babeb586" rel="noopener">序列模型</a>时，我惊讶于我们可以如此容易地将它们应用于广泛的问题:文本分类、文本生成、音乐生成、机器翻译等等。在本文中，我将重点介绍创建模型的一步一步的过程，不会涉及序列模型和 LSTMs 理论。</p><p id="608f" class="pw-post-body-paragraph lq lr jj ls b lt mm kk lv lw mn kn ly lz mo mb mc md mp mf mg mh mq mj mk ml im bi translated">我有了一个想法，使用<a class="ae jg" href="https://www.kaggle.com/kaggle/meta-kaggle" rel="noopener ugc nofollow" target="_blank">元 Kaggle </a>数据集来训练一个模型，为 Kaggle 生成新的内核标题。内核是用户发布在 Kaggle 上的 R 或 Python 语言的笔记本。Kaggle 用户可以投票支持内核。根据支持票的数量，果仁会获得奖章。生成内核标题的 Model 可以帮助捕捉 Kaggle 内核的趋势，并作为编写新内核和获得奖牌的灵感。在本文中:</p><ul class=""><li id="621f" class="mr ms jj ls b lt mm lw mn lz mt md mu mh mv ml mw mx my mz bi translated">我描述了如何从<a class="ae jg" href="https://www.kaggle.com/kaggle/meta-kaggle" rel="noopener ugc nofollow" target="_blank">元数据集中加载和预处理内核数据。</a></li><li id="1e90" class="mr ms jj ls b lt na lw nb lz nc md nd mh ne ml mw mx my mz bi translated">我演示了如何训练 PyTorch LSTM 模型来生成新的 Kaggle 标题并显示结果。</li></ul><p id="9955" class="pw-post-body-paragraph lq lr jj ls b lt mm kk lv lw mn kn ly lz mo mb mc md mp mf mg mh mq mj mk ml im bi translated">这个小项目的完整代码可以在<a class="ae jg" href="https://github.com/Lexie88rus/sequence-models/blob/master/lstm-for-kernel-title-generation-with-pytorch.ipynb" rel="noopener ugc nofollow" target="_blank"> GitHub </a>上获得，或者你可以在 Kaggle 上玩代码<a class="ae jg" href="https://www.kaggle.com/aleksandradeis/lstm-for-kernel-title-generation-with-pytorch" rel="noopener ugc nofollow" target="_blank">。</a></p><h1 id="3660" class="ky kz jj bd la lb lc ld le lf lg lh li kp lj kq lk ks ll kt lm kv ln kw lo lp bi translated">加载数据</h1><p id="5f5e" class="pw-post-body-paragraph lq lr jj ls b lt lu kk lv lw lx kn ly lz ma mb mc md me mf mg mh mi mj mk ml im bi translated">首先，我需要加载数据。我正在加载内核和 KernelVersions 表，其中包含所有内核的信息、每个内核的投票总数(稍后我会解释为什么我们需要这个)和内核标题。</p><figure class="nf ng nh ni gt iv"><div class="bz fp l di"><div class="nj nk l"/></div></figure><h1 id="f78b" class="ky kz jj bd la lb lc ld le lf lg lh li kp lj kq lk ks ll kt lm kv ln kw lo lp bi translated">列出流行的内核名称</h1><p id="e7ce" class="pw-post-body-paragraph lq lr jj ls b lt lu kk lv lw lx kn ly lz ma mb mc md me mf mg mh mi mj mk ml im bi translated">下一步是列出最流行的内核标题，然后将其转换成单词序列并传递给模型。结果是内核标题<strong class="ls jk">极其混乱</strong>:拼写错误的单词、外来词、特殊符号或者有像‘kernel 678 hggy’这样糟糕的名字。</p><p id="8929" class="pw-post-body-paragraph lq lr jj ls b lt mm kk lv lw mn kn ly lz mo mb mc md mp mf mg mh mq mj mk ml im bi translated">这就是为什么:</p><ul class=""><li id="b8c8" class="mr ms jj ls b lt mm lw mn lz mt md mu mh mv ml mw mx my mz bi translated"><strong class="ls jk">我从分析中丢弃没有投票的内核</strong>。我假设向上投票的内核应该有更好的质量和更有意义的标题。</li><li id="8750" class="mr ms jj ls b lt na lw nb lz nc md nd mh ne ml mw mx my mz bi translated">我根据投票总数对内核进行排序，而<strong class="ls jk">只选择投票最多的内核</strong>。</li></ul><figure class="nf ng nh ni gt iv"><div class="bz fp l di"><div class="nj nk l"/></div></figure><h1 id="81b5" class="ky kz jj bd la lb lc ld le lf lg lh li kp lj kq lk ks ll kt lm kv ln kw lo lp bi translated">预处理内核标题并创建词汇表</h1><p id="121b" class="pw-post-body-paragraph lq lr jj ls b lt lu kk lv lw lx kn ly lz ma mb mc md me mf mg mh mi mj mk ml im bi translated">我决定尝试一个基于单词的模型。这就是为什么，在下一步，我需要<strong class="ls jk">创建一个词汇表</strong>，它应该被用来编码单词序列。</p><p id="8ef2" class="pw-post-body-paragraph lq lr jj ls b lt mm kk lv lw mn kn ly lz mo mb mc md mp mf mg mh mq mj mk ml im bi translated">要创建词汇表，我必须执行以下步骤:</p><ul class=""><li id="1247" class="mr ms jj ls b lt mm lw mn lz mt md mu mh mv ml mw mx my mz bi translated"><strong class="ls jk">清理每个标题</strong>去掉标点符号，所有单词小写。</li><li id="11bf" class="mr ms jj ls b lt na lw nb lz nc md nd mh ne ml mw mx my mz bi translated"><strong class="ls jk">将每个标题拆分成单词</strong>并将每个单词添加到词汇表中。</li><li id="d48a" class="mr ms jj ls b lt na lw nb lz nc md nd mh ne ml mw mx my mz bi translated"><strong class="ls jk">引入一个符号，表示标题的结尾</strong>(我选了`.`，不过可以改)，加入词汇表。</li></ul><p id="e55c" class="pw-post-body-paragraph lq lr jj ls b lt mm kk lv lw mn kn ly lz mo mb mc md mp mf mg mh mq mj mk ml im bi translated">让我们引入一个简单的函数来清理内核标题:</p><figure class="nf ng nh ni gt iv"><div class="bz fp l di"><div class="nj nk l"/></div></figure><p id="36d1" class="pw-post-body-paragraph lq lr jj ls b lt mm kk lv lw mn kn ly lz mo mb mc md mp mf mg mh mq mj mk ml im bi translated">现在我们来介绍一个标题结尾的符号和一个单词提取功能:</p><figure class="nf ng nh ni gt iv"><div class="bz fp l di"><div class="nj nk l"/></div></figure><p id="8bbc" class="pw-post-body-paragraph lq lr jj ls b lt mm kk lv lw mn kn ly lz mo mb mc md mp mf mg mh mq mj mk ml im bi translated">下一步是制作由提取的单词组成的词汇表:</p><figure class="nf ng nh ni gt iv"><div class="bz fp l di"><div class="nj nk l"/></div></figure><h1 id="ee19" class="ky kz jj bd la lb lc ld le lf lg lh li kp lj kq lk ks ll kt lm kv ln kw lo lp bi translated">准备训练集</h1><p id="15ce" class="pw-post-body-paragraph lq lr jj ls b lt lu kk lv lw lx kn ly lz ma mb mc md me mf mg mh mi mj mk ml im bi translated">在本节中，我将为我们的未来模型创建一个训练集:</p><ul class=""><li id="36f6" class="mr ms jj ls b lt mm lw mn lz mt md mu mh mv ml mw mx my mz bi translated"><strong class="ls jk">介绍使用上面创建的词汇表将每个单词编码成张量</strong>的函数。我使用单词的一键编码:每个单词被表示为一个张量，其中 0 和 1 的位置都是 0 和 1，这与单词在词汇表中的索引有关。使用单词嵌入代替一次性编码无疑是对我的方法的改进。</li><li id="3763" class="mr ms jj ls b lt na lw nb lz nc md nd mh ne ml mw mx my mz bi translated"><strong class="ls jk">从内核标题中生成序列。</strong>序列的长度是一个超参数。我选择了长度等于 3 的序列。因此，我们给该模型一个包含 3 个单词的编码的张量和一个预测目标，该预测目标包含后面第 4 个单词的索引。</li></ul><p id="ce46" class="pw-post-body-paragraph lq lr jj ls b lt mm kk lv lw mn kn ly lz mo mb mc md mp mf mg mh mq mj mk ml im bi translated">以下函数将单词编码成张量:</p><figure class="nf ng nh ni gt iv"><div class="bz fp l di"><div class="nj nk l"/></div></figure><p id="c2b0" class="pw-post-body-paragraph lq lr jj ls b lt mm kk lv lw mn kn ly lz mo mb mc md mp mf mg mh mq mj mk ml im bi translated">现在让我们从最流行的内核名称中生成单词序列:</p><figure class="nf ng nh ni gt iv"><div class="bz fp l di"><div class="nj nk l"/></div></figure><h1 id="85b7" class="ky kz jj bd la lb lc ld le lf lg lh li kp lj kq lk ks ll kt lm kv ln kw lo lp bi translated">构建序列模型</h1><p id="c8fc" class="pw-post-body-paragraph lq lr jj ls b lt lu kk lv lw lx kn ly lz ma mb mc md me mf mg mh mi mj mk ml im bi translated">下一步是构建一个简单的<strong class="ls jk"> LSTM 模型</strong>:</p><ul class=""><li id="d197" class="mr ms jj ls b lt mm lw mn lz mt md mu mh mv ml mw mx my mz bi translated"><strong class="ls jk">模型的输入和输出大小</strong>应该等于词汇表的大小，因为我们试图预测一个序列的下一个单词；</li><li id="391d" class="mr ms jj ls b lt na lw nb lz nc md nd mh ne ml mw mx my mz bi translated">LSTM 区块有 128 个隐藏单元；</li><li id="cfd8" class="mr ms jj ls b lt na lw nb lz nc md nd mh ne ml mw mx my mz bi translated">一个<strong class="ls jk">线性层</strong>从隐藏尺寸转换成输出尺寸；</li><li id="4b98" class="mr ms jj ls b lt na lw nb lz nc md nd mh ne ml mw mx my mz bi translated">使用<strong class="ls jk"> Softmax 激活</strong>。</li></ul><p id="6ff1" class="pw-post-body-paragraph lq lr jj ls b lt mm kk lv lw mn kn ly lz mo mb mc md mp mf mg mh mq mj mk ml im bi translated">所以让我们用 PyTorch 定义并初始化一个模型:</p><figure class="nf ng nh ni gt iv"><div class="bz fp l di"><div class="nj nk l"/></div></figure><p id="a4ef" class="pw-post-body-paragraph lq lr jj ls b lt mm kk lv lw mn kn ly lz mo mb mc md mp mf mg mh mq mj mk ml im bi translated">我还需要一个实用函数将模型的输出转换成一个词:</p><figure class="nf ng nh ni gt iv"><div class="bz fp l di"><div class="nj nk l"/></div></figure><h1 id="2fd2" class="ky kz jj bd la lb lc ld le lf lg lh li kp lj kq lk ks ll kt lm kv ln kw lo lp bi translated">训练模型</h1><p id="d746" class="pw-post-body-paragraph lq lr jj ls b lt lu kk lv lw lx kn ly lz ma mb mc md me mf mg mh mi mj mk ml im bi translated">现在，数据集和模型已经为训练做好了准备。在训练之前，我需要做的另一件事是引入一个函数，它将词汇表中单词的索引转换为张量:</p><figure class="nf ng nh ni gt iv"><div class="bz fp l di"><div class="nj nk l"/></div></figure><p id="4fc2" class="pw-post-body-paragraph lq lr jj ls b lt mm kk lv lw mn kn ly lz mo mb mc md mp mf mg mh mq mj mk ml im bi translated">下一步是设置超参数和设备(CPU 或 GPU，如果可用):</p><figure class="nf ng nh ni gt iv"><div class="bz fp l di"><div class="nj nk l"/></div></figure><p id="94fc" class="pw-post-body-paragraph lq lr jj ls b lt mm kk lv lw mn kn ly lz mo mb mc md mp mf mg mh mq mj mk ml im bi translated">定义模型培训程序:</p><figure class="nf ng nh ni gt iv"><div class="bz fp l di"><div class="nj nk l"/></div></figure><p id="fd0b" class="pw-post-body-paragraph lq lr jj ls b lt mm kk lv lw mn kn ly lz mo mb mc md mp mf mg mh mq mj mk ml im bi translated">现在训练本身的一切都准备好了:</p><figure class="nf ng nh ni gt iv"><div class="bz fp l di"><div class="nj nk l"/></div></figure><p id="0a5d" class="pw-post-body-paragraph lq lr jj ls b lt mm kk lv lw mn kn ly lz mo mb mc md mp mf mg mh mq mj mk ml im bi translated">作为训练的结果，我们应该看到损失是如何随着像这样的时期的数量而减少的:</p><figure class="nf ng nh ni gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi nl"><img src="../Images/b12ed307dbed690238c19ca728b1c9f7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*qQ9jbzIjziAlcR_fZyYavA.png"/></div></div><figcaption class="jc jd gj gh gi je jf bd b be z dk">Training loss decreases over the number of epochs</figcaption></figure><h1 id="0d88" class="ky kz jj bd la lb lc ld le lf lg lh li kp lj kq lk ks ll kt lm kv ln kw lo lp bi translated">来自模型的示例内核标题</h1><p id="3d92" class="pw-post-body-paragraph lq lr jj ls b lt lu kk lv lw lx kn ly lz ma mb mc md me mf mg mh mi mj mk ml im bi translated">最激动人心的部分来了。现在我们可以使用我们训练过的模型来生成新的内核标题！我们需要做的就是编写一个简单的采样程序:</p><ol class=""><li id="f562" class="mr ms jj ls b lt mm lw mn lz mt md mu mh mv ml nm mx my mz bi translated">介绍标题中<strong class="ls jk">最大字数</strong>(以 10 为例)；</li><li id="b5cd" class="mr ms jj ls b lt na lw nb lz nc md nd mh ne ml nm mx my mz bi translated">向模型传递零个张量作为初始字<strong class="ls jk">和隐藏状态</strong>；</li><li id="044d" class="mr ms jj ls b lt na lw nb lz nc md nd mh ne ml nm mx my mz bi translated">重复以下步骤，直到对标题符号的结尾进行采样或超过标题中的最大字数:</li></ol><ul class=""><li id="4e38" class="mr ms jj ls b lt mm lw mn lz mt md mu mh mv ml mw mx my mz bi translated">使用来自模型输出的概率来<strong class="ls jk">得到序列的下一个单词</strong>；</li><li id="1609" class="mr ms jj ls b lt na lw nb lz nc md nd mh ne ml mw mx my mz bi translated"><strong class="ls jk">将采样的字作为下一个输入</strong>传递给模型。</li></ul><p id="e3ed" class="pw-post-body-paragraph lq lr jj ls b lt mm kk lv lw mn kn ly lz mo mb mc md mp mf mg mh mq mj mk ml im bi translated">因此，让我们定义采样函数，并从模型中采样一些标题:</p><figure class="nf ng nh ni gt iv"><div class="bz fp l di"><div class="nj nk l"/></div></figure><h1 id="6cd7" class="ky kz jj bd la lb lc ld le lf lg lh li kp lj kq lk ks ll kt lm kv ln kw lo lp bi translated">结论</h1><p id="ad88" class="pw-post-body-paragraph lq lr jj ls b lt lu kk lv lw lx kn ly lz ma mb mc md me mf mg mh mi mj mk ml im bi translated">在这个小项目中:</p><ul class=""><li id="5076" class="mr ms jj ls b lt mm lw mn lz mt md mu mh mv ml mw mx my mz bi translated">我加载并预处理了真实文本数据。</li><li id="baca" class="mr ms jj ls b lt na lw nb lz nc md nd mh ne ml mw mx my mz bi translated">我创建了一个基于单词的序列模型，可以用来生成新的内核标题。</li></ul><p id="a111" class="pw-post-body-paragraph lq lr jj ls b lt mm kk lv lw mn kn ly lz mo mb mc md mp mf mg mh mq mj mk ml im bi translated">你可以看到这个模型没有产生有意义的东西，但是仍然有一些有趣的结果，比如:</p><ul class=""><li id="1c77" class="mr ms jj ls b lt mm lw mn lz mt md mu mh mv ml mw mx my mz bi translated">财富碗数据挖掘</li><li id="7036" class="mr ms jj ls b lt na lw nb lz nc md nd mh ne ml mw mx my mz bi translated">补充批准的数据库</li><li id="1875" class="mr ms jj ls b lt na lw nb lz nc md nd mh ne ml mw mx my mz bi translated">平面忽略人口竞争</li><li id="34d4" class="mr ms jj ls b lt na lw nb lz nc md nd mh ne ml mw mx my mz bi translated">规划超级食物处方调查</li><li id="8916" class="mr ms jj ls b lt na lw nb lz nc md nd mh ne ml mw mx my mz bi translated">晚餐课网络放映</li><li id="6e60" class="mr ms jj ls b lt na lw nb lz nc md nd mh ne ml mw mx my mz bi translated">弹性网游乐场</li></ul><p id="0861" class="pw-post-body-paragraph lq lr jj ls b lt mm kk lv lw mn kn ly lz mo mb mc md mp mf mg mh mq mj mk ml im bi translated">当模型挤入现实生活数据时，这种事情就会发生。它们包含缩写、昵称、不同语言的单词、拼写错误的单词等等。当然，你可以通过<strong class="ls jk">更好的数据预处理</strong>来改善这些结果。我在下面描述了改善结果的措施。</p><h1 id="afa3" class="ky kz jj bd la lb lc ld le lf lg lh li kp lj kq lk ks ll kt lm kv ln kw lo lp bi translated">进一步改进</h1><p id="79f1" class="pw-post-body-paragraph lq lr jj ls b lt lu kk lv lw lx kn ly lz ma mb mc md me mf mg mh mi mj mk ml im bi translated">虽然我设法获得了一些令人兴奋的结果，但我还有很多可以改进的地方:</p><ul class=""><li id="bf89" class="mr ms jj ls b lt mm lw mn lz mt md mu mh mv ml mw mx my mz bi translated"><strong class="ls jk">更好的数据清理</strong>:许多标题应该从分析中删除，因为它们不是英文的，或者它们就是不能使用(例如“kernel123”)。</li><li id="b1c4" class="mr ms jj ls b lt na lw nb lz nc md nd mh ne ml mw mx my mz bi translated"><strong class="ls jk">自动纠正拼错的单词</strong>:标题可以通过自动纠正拼错的单词进行预处理(比如考虑<a class="ae jg" href="https://facelessuser.github.io/pyspelling/" rel="noopener ugc nofollow" target="_blank"> PySpell 包</a>)。这个过程需要很长时间。然而，这仍然是一种选择，因为数据预处理只在训练前进行一次。</li><li id="871c" class="mr ms jj ls b lt na lw nb lz nc md nd mh ne ml mw mx my mz bi translated"><strong class="ls jk">超参数调整</strong>:我认为学习率和序列长度可以被调整以达到更好的结果。</li><li id="124d" class="mr ms jj ls b lt na lw nb lz nc md nd mh ne ml mw mx my mz bi translated"><strong class="ls jk">使用</strong> <a class="ae jg" href="https://hackernoon.com/word-embeddings-in-nlp-and-its-applications-fab15eaf7430" rel="noopener ugc nofollow" target="_blank"> <strong class="ls jk">单词嵌入</strong> </a> <strong class="ls jk">代替对单词的一键编码</strong>。</li></ul></div></div>    
</body>
</html>