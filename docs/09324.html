<html>
<head>
<title>Preventing imbalanced data from leading to abominable classification: A satellite imagery illustration</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">防止不平衡数据导致恶劣分类:卫星图像说明</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/preventing-imbalanced-data-from-leading-to-abominable-classification-a-satellite-imagery-d2fecdac7d93?source=collection_archive---------35-----------------------#2019-12-09">https://towardsdatascience.com/preventing-imbalanced-data-from-leading-to-abominable-classification-a-satellite-imagery-d2fecdac7d93?source=collection_archive---------35-----------------------#2019-12-09</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><h2 id="285b" class="ir is it bd b dl iu iv iw ix iy iz dk ja translated" aria-label="kicker paragraph">使用卫星图像识别城市区域</h2><div class=""/><div class=""><h2 id="3afa" class="pw-subtitle-paragraph jz jc it bd b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq dk translated">不平衡的数据如何在分类中造成破坏，以及用于解决这一问题的技术的发展。</h2></div><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi kr"><img src="../Images/eb280aeb3f430466db1705709a47f619.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Gv0p_r95d-_LYsGcTEMtLw.jpeg"/></div></div><figcaption class="ld le gj gh gi lf lg bd b be z dk">Photo by <a class="ae lh" href="https://unsplash.com/@matthewhenry?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank">Matthew Henry</a> on <a class="ae lh" href="https://unsplash.com/s/photos/data?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><h1 id="dc8f" class="li lj it bd lk ll lm ln lo lp lq lr ls ki lt kj lu kl lv km lw ko lx kp ly lz bi translated">不平衡数据:意味着什么？</h1><p id="e574" class="pw-post-body-paragraph ma mb it mc b md me kd mf mg mh kg mi mj mk ml mm mn mo mp mq mr ms mt mu mv im bi translated">当属于数据集的一个类的实例的出现是<em class="mw">海量</em>而属于其他类的实例是<em class="mw">百万分之一</em>的时候，我们称之为不平衡数据集。</p><blockquote class="mx my mz"><p id="441c" class="ma mb mw mc b md na kd mf mg nb kg mi nc nd ml mm ne nf mp mq ng nh mt mu mv im bi translated">"一个好的榜样远胜于一句好的箴言."― <a class="ae lh" href="http://www.brainyquote.com/quotes/authors/d/dwight_l_moody.html" rel="noopener ugc nofollow" target="_blank">德怀特·l·穆迪</a></p></blockquote><p id="6a4f" class="pw-post-body-paragraph ma mb it mc b md na kd mf mg nb kg mi mj nd ml mm mn nf mp mq mr nh mt mu mv im bi translated">话虽如此，不平衡数据的典型例子是将电子邮件分类为垃圾邮件或垃圾邮件、欺诈检测等。你也可以在<a class="ae lh" href="https://www.kaggle.com/datasets" rel="noopener ugc nofollow" target="_blank"> Kaggle </a>上找到与之相关的数据集。</p><h1 id="45f2" class="li lj it bd lk ll lm ln lo lp lq lr ls ki lt kj lu kl lv km lw ko lx kp ly lz bi translated">究竟是什么让我选择了卫星图像？</h1><p id="5153" class="pw-post-body-paragraph ma mb it mc b md me kd mf mg mh kg mi mj mk ml mm mn mo mp mq mr ms mt mu mv im bi translated">嗯，答案就藏在问题本身！让我引用一段话来解释一下:</p><blockquote class="mx my mz"><p id="1cc6" class="ma mb mw mc b md na kd mf mg nb kg mi nc nd ml mm ne nf mp mq ng nh mt mu mv im bi translated">“当你看到卫星的数量、它们在做什么以及它们代表什么时，这真的是一个试图将世界掌控在你手中的愿景。”</p><p id="9ec5" class="ma mb mw mc b md na kd mf mg nb kg mi nc nd ml mm ne nf mp mq ng nh mt mu mv im bi translated">— <a class="ae lh" href="https://www.brainyquote.com/authors/trevor-paglen-quotes" rel="noopener ugc nofollow" target="_blank">特雷弗·帕格伦</a></p></blockquote><p id="7c4a" class="pw-post-body-paragraph ma mb it mc b md na kd mf mg nb kg mi mj nd ml mm mn nf mp mq mr nh mt mu mv im bi translated">这听起来一定有些哲学意味。下面是一些实用的例子:</p><blockquote class="mx my mz"><p id="2b89" class="ma mb mw mc b md na kd mf mg nb kg mi nc nd ml mm ne nf mp mq ng nh mt mu mv im bi translated">“卫星记录了我们看不到的光谱不同部分的数据。正是这些信息让卫星在观察植被健康等方面变得如此强大，找到可能表明石油储藏或某种可以开采的矿物储藏的不同地质类型。”</p><p id="ba9c" class="ma mb mw mc b md na kd mf mg nb kg mi nc nd ml mm ne nf mp mq ng nh mt mu mv im bi translated">“科学家利用卫星追踪天气、绘制冰盖融化图、检测疾病、展示生态系统变化……这样的例子不胜枚举。我认为几乎每个科学领域都受益于或可能受益于卫星图像分析。”</p><p id="ab84" class="ma mb mw mc b md na kd mf mg nb kg mi nc nd ml mm ne nf mp mq ng nh mt mu mv im bi translated">莎拉·帕尔卡</p></blockquote><p id="a6aa" class="pw-post-body-paragraph ma mb it mc b md na kd mf mg nb kg mi mj nd ml mm mn nf mp mq mr nh mt mu mv im bi translated">为了更深入地挖掘这一点，维基百科在此提供帮助。</p><p id="8b69" class="pw-post-body-paragraph ma mb it mc b md na kd mf mg nb kg mi mj nd ml mm mn nf mp mq mr nh mt mu mv im bi translated"><strong class="mc jd">注:</strong>如果你是遥感新手，那么<a class="ae lh" href="https://www.nrcan.gc.ca/maps-tools-publications/satellite-imagery-air-photos/tutorial-fundamentals-remote-sensing/9309" rel="noopener ugc nofollow" target="_blank">加拿大测绘与地球观测中心(或加拿大遥感中心)的遥感教程</a>是你的绝佳资源。</p><p id="d4fc" class="pw-post-body-paragraph ma mb it mc b md na kd mf mg nb kg mi mj nd ml mm mn nf mp mq mr nh mt mu mv im bi translated">好吧！现在让我们动手对卫星图像进行分类。</p><h1 id="d7f9" class="li lj it bd lk ll lm ln lo lp lq lr ls ki lt kj lu kl lv km lw ko lx kp ly lz bi translated">意图:</h1><p id="5372" class="pw-post-body-paragraph ma mb it mc b md me kd mf mg mh kg mi mj mk ml mm mn mo mp mq mr ms mt mu mv im bi translated">这里的意图很简单，但却很有效。我们感兴趣的是从卫星图像中找出城市区域(标记为<strong class="mc jd">建筑</strong>，搁置图像的其余部分(标记为<strong class="mc jd">非建筑</strong>)。通过卫星图像监测城市地区有利于城市规划、可持续发展以及在灾害发生时快速更新城市地区地图。此外，它在研究城市扩张对生态系统和环境的影响方面也很突出。</p><h1 id="12a7" class="li lj it bd lk ll lm ln lo lp lq lr ls ki lt kj lu kl lv km lw ko lx kp ly lz bi translated">数据:</h1><p id="2f10" class="pw-post-body-paragraph ma mb it mc b md me kd mf mg mh kg mi mj mk ml mm mn mo mp mq mr ms mt mu mv im bi translated">我使用<a class="ae lh" href="https://en.wikipedia.org/wiki/Sentinel-2" rel="noopener ugc nofollow" target="_blank">2A 哨兵，1C 级数据</a>从<a class="ae lh" href="https://earthexplorer.usgs.gov/" rel="noopener ugc nofollow" target="_blank">美国地质调查局(USGS)网站</a>下载<strong class="mc jd">位于印度北方邦西部的城市莫拉达巴德</strong>作为我的<strong class="mc jd">研究区域</strong>。首先，<a class="ae lh" href="https://www.nrcan.gc.ca/maps-tools-publications/satellite-imagery-air-photos/remote-sensing-tutorials/image-interpretation-analysis/digital-image-processing/9279" rel="noopener ugc nofollow" target="_blank">预处理</a>卫星图像是必须的。然而，1C 级产品是大气顶部反射率数据，在进行正射校正的同时，还进行了辐射测量和几何校正。</p><p id="f6e4" class="pw-post-body-paragraph ma mb it mc b md na kd mf mg nb kg mi mj nd ml mm mn nf mp mq mr nh mt mu mv im bi translated"><strong class="mc jd">花絮:</strong>预处理卫星图像，为机器学习估值器预处理数据(均值去除和方差缩放等。)就像粉笔和奶酪一样，也就是说，他们不一样。</p><p id="80dc" class="pw-post-body-paragraph ma mb it mc b md na kd mf mg nb kg mi mj nd ml mm mn nf mp mq mr nh mt mu mv im bi translated">四个<a class="ae lh" href="https://www.nrcan.gc.ca/maps-tools-publications/satellite-imagery-air-photos/remote-sensing-tutorials/introduction/characteristics-images/14641" rel="noopener ugc nofollow" target="_blank">波段</a>【2(蓝色)、3(绿色)、4(红色)、8(近红外)】以 10m <a class="ae lh" href="https://www.nrcan.gc.ca/maps-tools-publications/satellite-imagery-air-photos/remote-sensing-tutorials/satellites-sensors/spatial-resolution-pixel-size-and-scale/9407" rel="noopener ugc nofollow" target="_blank">空间分辨率</a>合成并裁剪到研究区域。使用研究区域的 4 波段-10m 合成和组合掩膜进行分类。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi ni"><img src="../Images/32b2b943f0661ef8d0fe29b2a890834a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*cDighlX67yzDjaZ-6dKh9g.png"/></div></div><figcaption class="ld le gj gh gi lf lg bd b be z dk">‘Copernicus Sentinel data [2018]’ . 4-Band <a class="ae lh" href="https://earthobservatory.nasa.gov/features/FalseColor" rel="noopener ugc nofollow" target="_blank">False Color Composite (FCC)</a> of the Study Area. Think of it as the input variable X</figcaption></figure><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi nj"><img src="../Images/d33996275ec51695384e56c8da784057.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*eBzDDcp8xiq3caMVO5PuKg.png"/></div></div><figcaption class="ld le gj gh gi lf lg bd b be z dk">Built-up Mask of the Study Area. Think of it as the target variable y.</figcaption></figure><h1 id="15ce" class="li lj it bd lk ll lm ln lo lp lq lr ls ki lt kj lu kl lv km lw ko lx kp ly lz bi translated">一个在不平衡数据上训练的模型差一张牌就有一副牌了！</h1><p id="0c36" class="pw-post-body-paragraph ma mb it mc b md me kd mf mg mh kg mi mj mk ml mm mn mo mp mq mr ms mt mu mv im bi translated">考虑二进制分类问题，如果负类的实例数量比正类的实例数量多得多，那么模型将总是试图预测负类，以便达到高精度。但这确实会产生误导。</p><p id="4611" class="pw-post-body-paragraph ma mb it mc b md na kd mf mg nb kg mi mj nd ml mm mn nf mp mq mr nh mt mu mv im bi translated">该场景可能如下所示:</p><div class="ks kt ku kv gt ab cb"><figure class="nk kw nl nm nn no np paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><img src="../Images/6bfbbc52dcfb1809d70ba3aa5f855cff.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*P1ccnXeq7jGSFByE6a3Q8g.png"/></div></figure><figure class="nk kw nl nm nn no np paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><img src="../Images/f1e7edcc32a623a904ee96151e00c6c3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*85aALRfISyoUyq_iPa9ktA.png"/></div></figure></div></div><div class="ab cl nq nr hx ns" role="separator"><span class="nt bw bk nu nv nw"/><span class="nt bw bk nu nv nw"/><span class="nt bw bk nu nv"/></div><div class="im in io ip iq"><p id="39b0" class="pw-post-body-paragraph ma mb it mc b md na kd mf mg nb kg mi mj nd ml mm mn nf mp mq mr nh mt mu mv im bi translated">让我们通过数据集深入了解一下这个场景。</p><p id="6862" class="pw-post-body-paragraph ma mb it mc b md na kd mf mg nb kg mi mj nd ml mm mn nf mp mq mr nh mt mu mv im bi translated">我使用<a class="ae lh" href="https://pypi.org/project/GDAL/" rel="noopener ugc nofollow" target="_blank"> GDAL </a> python 包获取复合图的<a class="ae lh" href="https://en.wikipedia.org/wiki/Digital_image" rel="noopener ugc nofollow" target="_blank">栅格</a>波段作为数组，并将数据转换为 CSV 文件格式。然而，这不是强制性的，只是为了方便起见。</p><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="nx ny l"/></div></figure><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi nz"><img src="../Images/8b48e17ce5fcc01072e3d6398636089e.png" data-original-src="https://miro.medium.com/v2/resize:fit:486/format:webp/1*wjB3g1QFgk625y5wQ1lnJg.png"/></div></figure><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="nx ny l"/></div></figure><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="nx ny l"/></div></figure><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi oa"><img src="../Images/58c42db41cf4beb72544439a020ee82f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1114/format:webp/1*6D-w2UvX8CLM1KgfEB26LA.png"/></div></figure><p id="bd74" class="pw-post-body-paragraph ma mb it mc b md na kd mf mg nb kg mi mj nd ml mm mn nf mp mq mr nh mt mu mv im bi translated">从条形图中可以明显看出，我们的数据集是高度不平衡的，81.86%的非构建类(负类)和仅 18.14%的构建类(正类)。</p><p id="ed44" class="pw-post-body-paragraph ma mb it mc b md na kd mf mg nb kg mi mj nd ml mm mn nf mp mq mr nh mt mu mv im bi translated">如果我们试图在这种数据上训练我们的模型，它将成为所谓的<a class="ae lh" href="https://en.wikipedia.org/wiki/Accuracy_paradox" rel="noopener ugc nofollow" target="_blank">准确性悖论</a>的牺牲品。更详细地说明这一点，我们的模型将试图揭示隐藏在准确性伪装下的类分布。</p><h1 id="8b6e" class="li lj it bd lk ll lm ln lo lp lq lr ls ki lt kj lu kl lv km lw ko lx kp ly lz bi translated">寻找灵丹妙药:</h1><p id="2174" class="pw-post-body-paragraph ma mb it mc b md me kd mf mg mh kg mi mj mk ml mm mn mo mp mq mr ms mt mu mv im bi translated">有几个博客是关于对抗不平衡班级的技术的。但是，我发现这个像一个光滑的迪斯科球一样闪闪发光。</p><p id="40aa" class="pw-post-body-paragraph ma mb it mc b md na kd mf mg nb kg mi mj nd ml mm mn nf mp mq mr nh mt mu mv im bi translated">我发现下面的技巧比其他的更有吸引力。</p><ol class=""><li id="6d8c" class="ob oc it mc b md na mg nb mj od mn oe mr of mv og oh oi oj bi translated">使用流行的决策树算法，随机森林就是其中之一。</li><li id="c1a6" class="ob oc it mc b md ok mg ol mj om mn on mr oo mv og oh oi oj bi translated">通过使用 SMOTE(合成少数过采样技术)生成合成样本，对少数类进行过采样。</li></ol><p id="9dba" class="pw-post-body-paragraph ma mb it mc b md na kd mf mg nb kg mi mj nd ml mm mn nf mp mq mr nh mt mu mv im bi translated">这篇博客的重点将是上面列出的两种技术中的第一种。</p><p id="1e21" class="pw-post-body-paragraph ma mb it mc b md na kd mf mg nb kg mi mj nd ml mm mn nf mp mq mr nh mt mu mv im bi translated">这个问题被分解为 3 个简单的步骤:</p><ol class=""><li id="cb29" class="ob oc it mc b md na mg nb mj od mn oe mr of mv og oh oi oj bi translated">使用 scikit-learn 的<strong class="mc jd"> train_test_split </strong>辅助函数对数据分割应用随机森林分类器，并决定用于我们数据的性能指标。</li><li id="12ab" class="ob oc it mc b md ok mg ol mj om mn on mr oo mv og oh oi oj bi translated">通过<strong class="mc jd">分层 K 倍</strong> <strong class="mc jd">交叉验证</strong>更进一步。</li><li id="7fbd" class="ob oc it mc b md ok mg ol mj om mn on mr oo mv og oh oi oj bi translated">使用<strong class="mc jd">网格搜索交叉验证</strong>调整模型的超参数。(将在本博客的后续部分全面讨论)。</li></ol><h2 id="517d" class="op lj it bd lk oq or dn lo os ot dp ls mj ou ov lu mn ow ox lw mr oy oz ly iz bi translated"><strong class="ak">第一步</strong></h2><h2 id="290f" class="op lj it bd lk oq or dn lo os ot dp ls mj ou ov lu mn ow ox lw mr oy oz ly iz bi translated">随机森林分类器:</h2><p id="39d1" class="pw-post-body-paragraph ma mb it mc b md me kd mf mg mh kg mi mj mk ml mm mn mo mp mq mr ms mt mu mv im bi translated">对<a class="ae lh" href="https://en.wikipedia.org/wiki/Decision_tree" rel="noopener ugc nofollow" target="_blank">决策树</a>和<a class="ae lh" href="https://en.wikipedia.org/wiki/Bootstrap_aggregating" rel="noopener ugc nofollow" target="_blank">打包</a> (Bootstrap Aggregating)有一个概述是继续之前的先决条件。</p><p id="f7ab" class="pw-post-body-paragraph ma mb it mc b md na kd mf mg nb kg mi mj nd ml mm mn nf mp mq mr nh mt mu mv im bi translated">通俗地说，<a class="ae lh" href="https://en.wikipedia.org/wiki/Random_forest" rel="noopener ugc nofollow" target="_blank">随机森林</a>是通常用于<em class="mw">【恰当】</em>对抗决策树的高方差(过拟合)的决策树集合。与 Bagging 不同，随机森林限制了在每次分裂时要评估的特征，即，在每次分裂时使用特征的随机子集，导致决策树高度不相关。由于这个原因，随机森林广泛用于分类和回归任务。</p><p id="fbf3" class="pw-post-body-paragraph ma mb it mc b md na kd mf mg nb kg mi mj nd ml mm mn nf mp mq mr nh mt mu mv im bi translated">让我们跟上潮流，考虑随机森林分类器的默认参数，检查我们的模型如何执行。</p><h2 id="8bb8" class="op lj it bd lk oq or dn lo os ot dp ls mj ou ov lu mn ow ox lw mr oy oz ly iz bi translated"><strong class="ak">等等，我们为什么要分割数据？</strong></h2><p id="9794" class="pw-post-body-paragraph ma mb it mc b md me kd mf mg mh kg mi mj mk ml mm mn mo mp mq mr ms mt mu mv im bi translated">当一个模型在整个输入数据上被训练时，被告知预测同样的输入数据，它表现得像一个天才。但它实际上已经成为一个谎言。当被告知要预测看不见的数据时，它将很难产生预期的结果。这种情况称为“过拟合”。为了防止这种情况，我们将数据分为训练集和测试集，其中模型不包含测试集，而是在训练集上进行训练。然后在测试集上评估模型的性能。</p><h2 id="37db" class="op lj it bd lk oq or dn lo os ot dp ls mj ou ov lu mn ow ox lw mr oy oz ly iz bi translated">将数据分为 80%的训练集和 20%的测试集:</h2><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="nx ny l"/></div></figure><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="nx ny l"/></div><figcaption class="ld le gj gh gi lf lg bd b be z dk"><a class="ae lh" href="https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html" rel="noopener ugc nofollow" target="_blank">train_test_split Documentation</a></figcaption></figure><h2 id="5fb6" class="op lj it bd lk oq or dn lo os ot dp ls mj ou ov lu mn ow ox lw mr oy oz ly iz bi translated"><strong class="ak">训练随机森林分类器(默认参数)并在测试集上预测结果:</strong></h2><p id="ecc1" class="pw-post-body-paragraph ma mb it mc b md me kd mf mg mh kg mi mj mk ml mm mn mo mp mq mr ms mt mu mv im bi translated">在我们在训练集上训练我们的模型之前，我们需要执行特征缩放以将我们的数据带入特定范围内，以便模型不会因其系数或权重的微小变化而偏向特定特征。值得注意的是，我们仅在训练集上安装了定标器，并使用它来转换训练集和测试集，以防止<a class="ae lh" href="https://machinelearningmastery.com/data-leakage-machine-learning/" rel="noopener ugc nofollow" target="_blank">数据泄漏</a>，即在训练模型时，测试集的信息不应泄漏。</p><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="nx ny l"/></div><figcaption class="ld le gj gh gi lf lg bd b be z dk"><a class="ae lh" href="https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html" rel="noopener ugc nofollow" target="_blank">StandardScaler Documentation</a></figcaption></figure><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="nx ny l"/></div><figcaption class="ld le gj gh gi lf lg bd b be z dk"><a class="ae lh" href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html" rel="noopener ugc nofollow" target="_blank">Random Forest Classifier Documentation</a></figcaption></figure><p id="0935" class="pw-post-body-paragraph ma mb it mc b md na kd mf mg nb kg mi mj nd ml mm mn nf mp mq mr nh mt mu mv im bi translated"><strong class="mc jd">查看森林的平均节点数和最大深度:</strong></p><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="nx ny l"/></div></figure><p id="0073" class="pw-post-body-paragraph ma mb it mc b md na kd mf mg nb kg mi mj nd ml mm mn nf mp mq mr nh mt mu mv im bi translated"><strong class="mc jd">对森林中某棵树的外观感到好奇？</strong></p><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="nx ny l"/></div></figure><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi pa"><img src="../Images/f0841e3df4d222db13abc340cba23351.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ZQHolhRv5Pxar7EBhkzi9Q.png"/></div></div></figure><p id="074f" class="pw-post-body-paragraph ma mb it mc b md na kd mf mg nb kg mi mj nd ml mm mn nf mp mq mr nh mt mu mv im bi translated"><strong class="mc jd">测试集上的预测:</strong></p><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="nx ny l"/></div></figure><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi pb"><img src="../Images/df6463a100508f7dcba1e3295f6e0620.png" data-original-src="https://miro.medium.com/v2/resize:fit:422/format:webp/1*f06jrMOqkeLFSwzVzLzEsA.png"/></div></figure><p id="6f0f" class="pw-post-body-paragraph ma mb it mc b md na kd mf mg nb kg mi mj nd ml mm mn nf mp mq mr nh mt mu mv im bi translated">为了预测测试集中实例的类，我们使用<strong class="mc jd"> <em class="mw"> predict() </em> </strong>函数。</p><p id="4522" class="pw-post-body-paragraph ma mb it mc b md na kd mf mg nb kg mi mj nd ml mm mn nf mp mq mr nh mt mu mv im bi translated">给定测试集中的一个实例，它可能落入的每个类的概率是多少，由<strong class="mc jd"><em class="mw">predict _ proba()</em></strong>函数描述。</p><p id="f7ae" class="pw-post-body-paragraph ma mb it mc b md na kd mf mg nb kg mi mj nd ml mm mn nf mp mq mr nh mt mu mv im bi translated"><strong class="mc jd">注:</strong>我们感兴趣的是预测正类，即累积类，因此我们将只关注先证者[:，1]部分。在博客接下来的部分，我们将用它来绘制精确召回曲线。</p><h2 id="acaa" class="op lj it bd lk oq or dn lo os ot dp ls mj ou ov lu mn ow ox lw mr oy oz ly iz bi translated">我们的模型达到预期了吗？</h2><p id="3e4f" class="pw-post-body-paragraph ma mb it mc b md me kd mf mg mh kg mi mj mk ml mm mn mo mp mq mr ms mt mu mv im bi translated">有几种方法可以评估我们的模型。在哪种情况下使用哪种评估指标确实让我们挠头！</p><p id="40ac" class="pw-post-body-paragraph ma mb it mc b md na kd mf mg nb kg mi mj nd ml mm mn nf mp mq mr nh mt mu mv im bi translated"><strong class="mc jd">混淆矩阵:</strong></p><p id="7d07" class="pw-post-body-paragraph ma mb it mc b md na kd mf mg nb kg mi mj nd ml mm mn nf mp mq mr nh mt mu mv im bi translated">顾名思义，它描述了模型在预测类时所经历的混乱。</p><p id="b27c" class="pw-post-body-paragraph ma mb it mc b md na kd mf mg nb kg mi mj nd ml mm mn nf mp mq mr nh mt mu mv im bi translated">但是理解混乱矩阵本身往往是混乱的！让我们用最简单的方式来理解它。</p><p id="ca11" class="pw-post-body-paragraph ma mb it mc b md na kd mf mg nb kg mi mj nd ml mm mn nf mp mq mr nh mt mu mv im bi translated">在二进制分类问题中，混淆矩阵看起来像:</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi pc"><img src="../Images/1a17c3c1e1403f6df75a1f3a2cc978a5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*nJcANGRvjKoToqxWThBOMQ.png"/></div></div></figure><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="nx ny l"/></div><figcaption class="ld le gj gh gi lf lg bd b be z dk"><a class="ae lh" href="https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html" rel="noopener ugc nofollow" target="_blank">Confusion Matrix Documentation</a></figcaption></figure><p id="eaa8" class="pw-post-body-paragraph ma mb it mc b md na kd mf mg nb kg mi mj nd ml mm mn nf mp mq mr nh mt mu mv im bi translated"><strong class="mc jd">真阳性(TP): </strong>其实——造，模特说——造，我说，“牛逼！”</p><p id="27ca" class="pw-post-body-paragraph ma mb it mc b md na kd mf mg nb kg mi mj nd ml mm mn nf mp mq mr nh mt mu mv im bi translated"><strong class="mc jd">假阳性(FP): </strong>其实——非杜撰，模型说——杜撰，我说“你觉得正面的，其实是负面的！”</p><p id="95f0" class="pw-post-body-paragraph ma mb it mc b md na kd mf mg nb kg mi mj nd ml mm mn nf mp mq mr nh mt mu mv im bi translated"><strong class="mc jd">假阴性(FN): </strong>实际上——是捏造的，模型说——不是捏造的，我说:“唉！这是有史以来最糟糕的预测。”</p><p id="065d" class="pw-post-body-paragraph ma mb it mc b md na kd mf mg nb kg mi mj nd ml mm mn nf mp mq mr nh mt mu mv im bi translated"><strong class="mc jd">真否定(TN): </strong>实际上——非虚构，模型说——非虚构，我说:“最后，你开始知道否定也是现实的事实！”</p><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="nx ny l"/></div></figure><p id="444f" class="pw-post-body-paragraph ma mb it mc b md na kd mf mg nb kg mi mj nd ml mm mn nf mp mq mr nh mt mu mv im bi translated">记住这个的诀窍是:</p><p id="91bb" class="pw-post-body-paragraph ma mb it mc b md na kd mf mg nb kg mi mj nd ml mm mn nf mp mq mr nh mt mu mv im bi translated">我们已经知道了<strong class="mc jd"> <em class="mw">的实际值</em> </strong>，因此我们将它们归类为<strong class="mc jd"><em class="mw"/></strong>和<strong class="mc jd"> <em class="mw">假</em> </strong>。</p><p id="4176" class="pw-post-body-paragraph ma mb it mc b md na kd mf mg nb kg mi mj nd ml mm mn nf mp mq mr nh mt mu mv im bi translated">我们评估由我们的模型预测的 的<strong class="mc jd"> <em class="mw">结果，我们通常将“结果”分类为<strong class="mc jd"><em class="mw"/></strong>和<strong class="mc jd"> <em class="mw">负</em> </strong>。</em></strong></p><p id="4000" class="pw-post-body-paragraph ma mb it mc b md na kd mf mg nb kg mi mj nd ml mm mn nf mp mq mr nh mt mu mv im bi translated"><strong class="mc jd">性能指标:</strong></p><p id="5f44" class="pw-post-body-paragraph ma mb it mc b md na kd mf mg nb kg mi mj nd ml mm mn nf mp mq mr nh mt mu mv im bi translated"><strong class="mc jd">精度:</strong></p><blockquote class="mx my mz"><p id="955f" class="ma mb mw mc b md na kd mf mg nb kg mi nc nd ml mm ne nf mp mq ng nh mt mu mv im bi translated">“不要专注于错误的预测；只专注于正确的，你就会蓬勃发展。”</p></blockquote><p id="660e" class="pw-post-body-paragraph ma mb it mc b md na kd mf mg nb kg mi mj nd ml mm mn nf mp mq mr nh mt mu mv im bi translated">这就是准确性的含义。因此，对于不平衡的数据集，这是评估模型的最差方式。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi pd"><img src="../Images/6b87cd8a7b2e2422da38ba42c7040046.png" data-original-src="https://miro.medium.com/v2/resize:fit:766/format:webp/1*rwWVrEhdxtxpIdiPsfYOtA.png"/></div></figure><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="nx ny l"/></div><figcaption class="ld le gj gh gi lf lg bd b be z dk"><a class="ae lh" href="https://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html" rel="noopener ugc nofollow" target="_blank">Accuracy Score Documentation</a></figcaption></figure><p id="acc0" class="pw-post-body-paragraph ma mb it mc b md na kd mf mg nb kg mi mj nd ml mm mn nf mp mq mr nh mt mu mv im bi translated">占据重要位置的指标，尤其是在我们的案例中:</p><p id="35a3" class="pw-post-body-paragraph ma mb it mc b md na kd mf mg nb kg mi mj nd ml mm mn nf mp mq mr nh mt mu mv im bi translated"><strong class="mc jd">精度:</strong></p><p id="852d" class="pw-post-body-paragraph ma mb it mc b md na kd mf mg nb kg mi mj nd ml mm mn nf mp mq mr nh mt mu mv im bi translated">“精确”是指<em class="mw">非常精确的</em>。顾名思义，precision 描述了一个模型的<em class="mw">【精确】</em>。在所有的<em class="mw">预测阳性</em>中，有多少是我们真正感兴趣的，这就是精度。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi pe"><img src="../Images/2a8cc221725eebfab204f3a09d7ec856.png" data-original-src="https://miro.medium.com/v2/resize:fit:558/format:webp/1*irqQ_7dY-Xv-aMJoEZBRKQ.png"/></div></figure><p id="6d7e" class="pw-post-body-paragraph ma mb it mc b md na kd mf mg nb kg mi mj nd ml mm mn nf mp mq mr nh mt mu mv im bi translated"><strong class="mc jd">回忆:</strong></p><p id="5bdf" class="pw-post-body-paragraph ma mb it mc b md na kd mf mg nb kg mi mj nd ml mm mn nf mp mq mr nh mt mu mv im bi translated">召回描述了模型的“完整性”。它从<em class="mw">实际阳性值</em>中计算出真实阳性值。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi pf"><img src="../Images/7b713d35d0f7468bf0435cd3076644fd.png" data-original-src="https://miro.medium.com/v2/resize:fit:472/format:webp/1*ItS0QBG_59NnyhX8dZPyoA.png"/></div></figure><p id="b7fa" class="pw-post-body-paragraph ma mb it mc b md na kd mf mg nb kg mi mj nd ml mm mn nf mp mq mr nh mt mu mv im bi translated"><strong class="mc jd">F1-得分:</strong></p><p id="9bf9" class="pw-post-body-paragraph ma mb it mc b md na kd mf mg nb kg mi mj nd ml mm mn nf mp mq mr nh mt mu mv im bi translated">f1-得分是精确度和召回率的调和平均值<strong class="mc jd">和</strong>。在评估一个模型时，要注意精度和召回的贡献是平衡的。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi pg"><img src="../Images/1036b3fe441b726ebad58673e9a218d1.png" data-original-src="https://miro.medium.com/v2/resize:fit:816/format:webp/1*9eQhDKCpHctg1ir0pYb0dA.png"/></div></div></figure><p id="727c" class="pw-post-body-paragraph ma mb it mc b md na kd mf mg nb kg mi mj nd ml mm mn nf mp mq mr nh mt mu mv im bi translated">你可能会有问题。为什么只有“调和”的意思而没有“算术”或“几何”的意思？<a class="ae lh" href="https://medium.com/@srinivas.sateesh/have-you-asked-why-f1-score-is-a-harmonic-mean-hm-of-precision-and-recall-febc233ce247" rel="noopener">这里有</a>的原因。</p><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="nx ny l"/></div><figcaption class="ld le gj gh gi lf lg bd b be z dk"><a class="ae lh" href="https://scikit-learn.org/stable/modules/generated/sklearn.metrics.classification_report.html" rel="noopener ugc nofollow" target="_blank">Classification Report Documentation</a></figcaption></figure><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi ph"><img src="../Images/7aacecd996d8dce631660fdc614b8a68.png" data-original-src="https://miro.medium.com/v2/resize:fit:822/format:webp/1*yrdeRbVnkYFbFCOBvpcveQ.png"/></div></div></figure><p id="be83" class="pw-post-body-paragraph ma mb it mc b md na kd mf mg nb kg mi mj nd ml mm mn nf mp mq mr nh mt mu mv im bi translated"><strong class="mc jd">科恩的卡帕统计:</strong></p><p id="ffcc" class="pw-post-body-paragraph ma mb it mc b md na kd mf mg nb kg mi mj nd ml mm mn nf mp mq mr nh mt mu mv im bi translated">根据<a class="ae lh" href="https://en.wikipedia.org/wiki/Cohen's_kappa" rel="noopener ugc nofollow" target="_blank">维基百科</a>，科恩的卡帕测量了两个评分者之间的协议，他们各自将<em class="mw"> N </em>个项目分类为<em class="mw"> C </em>个互斥的类别。<a class="ae lh" href="https://stats.stackexchange.com/questions/82162/cohens-kappa-in-plain-english" rel="noopener ugc nofollow" target="_blank">这里</a>是对此的详细解释。它可以是介于-1 和 1 之间的值，其中-1 表示<em class="mw">不一致</em>，1 表示<em class="mw">完全一致</em>。Kappa 统计优选地用于不平衡等级分布的情况，因为它没有考虑多数等级的支配效应。</p><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="nx ny l"/></div><figcaption class="ld le gj gh gi lf lg bd b be z dk"><a class="ae lh" href="https://scikit-learn.org/stable/modules/generated/sklearn.metrics.cohen_kappa_score.html" rel="noopener ugc nofollow" target="_blank">Kappa Statistic Documentation</a></figcaption></figure><p id="4d55" class="pw-post-body-paragraph ma mb it mc b md na kd mf mg nb kg mi mj nd ml mm mn nf mp mq mr nh mt mu mv im bi translated">在我们的案例中，kappa 统计值约为 0.74，这意味着测试集和模型预测之间存在<em class="mw">基本一致</em>。这表明该模型表现非常好。</p><p id="99f7" class="pw-post-body-paragraph ma mb it mc b md na kd mf mg nb kg mi mj nd ml mm mn nf mp mq mr nh mt mu mv im bi translated"><strong class="mc jd"> <em class="mw">引擎盖下是怎么回事？</em> </strong></p><p id="2782" class="pw-post-body-paragraph ma mb it mc b md na kd mf mg nb kg mi mj nd ml mm mn nf mp mq mr nh mt mu mv im bi translated">再次参考<a class="ae lh" href="https://stats.stackexchange.com/questions/82162/cohens-kappa-in-plain-english" rel="noopener ugc nofollow" target="_blank">此链接</a>。</p><p id="7ed2" class="pw-post-body-paragraph ma mb it mc b md na kd mf mg nb kg mi mj nd ml mm mn nf mp mq mr nh mt mu mv im bi translated">在我们的例子中，混淆矩阵看起来像:</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi pc"><img src="../Images/4c1a2ce2917679998a2fae739792fb8b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*dkb47x9TyoTr9uJM8nj6Yw.png"/></div></div></figure><p id="e1dd" class="pw-post-body-paragraph ma mb it mc b md na kd mf mg nb kg mi mj nd ml mm mn nf mp mq mr nh mt mu mv im bi translated">根据上面的混淆矩阵:</p><p id="838d" class="pw-post-body-paragraph ma mb it mc b md na kd mf mg nb kg mi mj nd ml mm mn nf mp mq mr nh mt mu mv im bi translated">总实例数: 379080</p><p id="c7a3" class="pw-post-body-paragraph ma mb it mc b md na kd mf mg nb kg mi mj nd ml mm mn nf mp mq mr nh mt mu mv im bi translated"><strong class="mc jd">实际:</strong></p><p id="0aa3" class="pw-post-body-paragraph ma mb it mc b md na kd mf mg nb kg mi mj nd ml mm mn nf mp mq mr nh mt mu mv im bi translated"><em class="mw">组合实例总数:</em> 68373，<em class="mw">非组合实例总数:</em> 310707</p><p id="540f" class="pw-post-body-paragraph ma mb it mc b md na kd mf mg nb kg mi mj nd ml mm mn nf mp mq mr nh mt mu mv im bi translated"><strong class="mc jd">预测:</strong></p><p id="b802" class="pw-post-body-paragraph ma mb it mc b md na kd mf mg nb kg mi mj nd ml mm mn nf mp mq mr nh mt mu mv im bi translated"><em class="mw">组合实例总数:</em> <strong class="mc jd"> </strong> 61625，<em class="mw">非组合实例总数:</em> <strong class="mc jd"> </strong> 317455</p><p id="5203" class="pw-post-body-paragraph ma mb it mc b md na kd mf mg nb kg mi mj nd ml mm mn nf mp mq mr nh mt mu mv im bi translated"><strong class="mc jd">观测精度:</strong></p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi pi"><img src="../Images/a8e2d512f6bfd896a52778c3d722a794.png" data-original-src="https://miro.medium.com/v2/resize:fit:704/format:webp/1*qyPIY6eP44FmroQqhpIGCg.png"/></div></figure><p id="5b2c" class="pw-post-body-paragraph ma mb it mc b md na kd mf mg nb kg mi mj nd ml mm mn nf mp mq mr nh mt mu mv im bi translated">在我们的例子中，观测精度= (51241 + 10384) / 379080 = 0.927</p><p id="32ad" class="pw-post-body-paragraph ma mb it mc b md na kd mf mg nb kg mi mj nd ml mm mn nf mp mq mr nh mt mu mv im bi translated"><strong class="mc jd">预期精度:</strong></p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi pj"><img src="../Images/476e5fbfce60ab02c017c3cdcf1751b6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*dn9h70XJWuXYZJJCQnDyAg.png"/></div></div></figure><p id="4627" class="pw-post-body-paragraph ma mb it mc b md na kd mf mg nb kg mi mj nd ml mm mn nf mp mq mr nh mt mu mv im bi translated">在我们的例子中，</p><p id="389f" class="pw-post-body-paragraph ma mb it mc b md na kd mf mg nb kg mi mj nd ml mm mn nf mp mq mr nh mt mu mv im bi translated">预期精度(组合)=(68373 * 61625) / 379080 = 11115.03</p><p id="626a" class="pw-post-body-paragraph ma mb it mc b md na kd mf mg nb kg mi mj nd ml mm mn nf mp mq mr nh mt mu mv im bi translated">同样的，</p><p id="f218" class="pw-post-body-paragraph ma mb it mc b md na kd mf mg nb kg mi mj nd ml mm mn nf mp mq mr nh mt mu mv im bi translated">预期精度(非组合)=(310707 * 317455)/379080 = 260197.03</p><p id="80aa" class="pw-post-body-paragraph ma mb it mc b md na kd mf mg nb kg mi mj nd ml mm mn nf mp mq mr nh mt mu mv im bi translated"><strong class="mc jd"> <em class="mw">总预期精度:</em> </strong></p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi pk"><img src="../Images/e911829af69e1030565d9bba55bb8a8a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1020/format:webp/1*gP0MG1MIZ7cAsXsfyK6mUg.png"/></div></figure><p id="4b53" class="pw-post-body-paragraph ma mb it mc b md na kd mf mg nb kg mi mj nd ml mm mn nf mp mq mr nh mt mu mv im bi translated">在我们的例子中，总的预期精度=(11115.03+260197.03)/379080 = 0.7157</p><p id="a534" class="pw-post-body-paragraph ma mb it mc b md na kd mf mg nb kg mi mj nd ml mm mn nf mp mq mr nh mt mu mv im bi translated"><strong class="mc jd">卡帕统计:</strong></p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi pl"><img src="../Images/7fe96f112328405c7363158d30b53164.png" data-original-src="https://miro.medium.com/v2/resize:fit:980/format:webp/1*FtbLSNgodzOWfm5bYyVg1Q.png"/></div></figure><p id="5858" class="pw-post-body-paragraph ma mb it mc b md na kd mf mg nb kg mi mj nd ml mm mn nf mp mq mr nh mt mu mv im bi translated">在我们的例子中，Kappa 统计量=(0.927–0.7157)/(1–0.7157)= 0.744</p><p id="a0c3" class="pw-post-body-paragraph ma mb it mc b md na kd mf mg nb kg mi mj nd ml mm mn nf mp mq mr nh mt mu mv im bi translated">因此，在评估模型时，Kappa 统计明智地取消了非组合类的优势。</p><p id="f6c2" class="pw-post-body-paragraph ma mb it mc b md na kd mf mg nb kg mi mj nd ml mm mn nf mp mq mr nh mt mu mv im bi translated"><strong class="mc jd">精确召回曲线:</strong></p><p id="34bc" class="pw-post-body-paragraph ma mb it mc b md na kd mf mg nb kg mi mj nd ml mm mn nf mp mq mr nh mt mu mv im bi translated">精度-召回曲线是在 y 轴上具有精度并且在 x 轴上具有不同阈值的召回的图。曲线下面积(AUC)用于总结曲线。AUC 越大，我们的模型表现越好。这在我们的情况下非常有用，通常比 ROC 曲线更可取。在我关注的这个博客中，一切都解释得非常清楚。</p><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="nx ny l"/></div></figure><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="nx ny l"/></div><figcaption class="ld le gj gh gi lf lg bd b be z dk"><a class="ae lh" href="https://scikit-learn.org/stable/modules/generated/sklearn.metrics.precision_recall_curve.html" rel="noopener ugc nofollow" target="_blank">PR Curve Documentation</a></figcaption></figure><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi pm"><img src="../Images/58a5b9fbb54b870b1a297a9a53c10b78.png" data-original-src="https://miro.medium.com/v2/resize:fit:850/format:webp/1*3dpVx25-cQ0xB5w-jLYN7g.png"/></div></figure><p id="1f78" class="pw-post-body-paragraph ma mb it mc b md na kd mf mg nb kg mi mj nd ml mm mn nf mp mq mr nh mt mu mv im bi translated">AUC 是 0.865。这表明我们的模型在预测正类时表现良好。</p><p id="9b22" class="pw-post-body-paragraph ma mb it mc b md na kd mf mg nb kg mi mj nd ml mm mn nf mp mq mr nh mt mu mv im bi translated"><strong class="mc jd">对精度和召回的深入了解:</strong></p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi pn"><img src="../Images/50ad9f9e64f474d6ad8f58b410a0f72a.png" data-original-src="https://miro.medium.com/v2/resize:fit:800/format:webp/1*k0tNllIQuFO_EKhG5a4aHw.png"/></div><figcaption class="ld le gj gh gi lf lg bd b be z dk">Image Source: <a class="ae lh" href="https://en.wikipedia.org/wiki/Precision_and_recall" rel="noopener ugc nofollow" target="_blank">Wikipedia</a></figcaption></figure><p id="6229" class="pw-post-body-paragraph ma mb it mc b md na kd mf mg nb kg mi mj nd ml mm mn nf mp mq mr nh mt mu mv im bi translated"><strong class="mc jd">精度:</strong></p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi po"><img src="../Images/d2ee460f83ca82f33cf9553ad431597c.png" data-original-src="https://miro.medium.com/v2/resize:fit:482/format:webp/1*1_0K59CLMFcDuGp4QuYAMw.png"/></div></figure><p id="55c3" class="pw-post-body-paragraph ma mb it mc b md na kd mf mg nb kg mi mj nd ml mm mn nf mp mq mr nh mt mu mv im bi translated">用 TP 除分子和分母，我们得到:</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi pp"><img src="../Images/a0ff11fefdd68a829cd56317148f1811.png" data-original-src="https://miro.medium.com/v2/resize:fit:542/format:webp/1*n6eVA8OpDDqoB6SCBq_q7g.png"/></div></figure><p id="a2d6" class="pw-post-body-paragraph ma mb it mc b md na kd mf mg nb kg mi mj nd ml mm mn nf mp mq mr nh mt mu mv im bi translated">我们知道精度的值在范围[0，1]内。</p><p id="befd" class="pw-post-body-paragraph ma mb it mc b md na kd mf mg nb kg mi mj nd ml mm mn nf mp mq mr nh mt mu mv im bi translated">当比率(FP / TP)趋于无穷大时，精度将为 0，为此，FP 应该趋于无穷大(实际上，应该具有非常大的值)或者 TP 应该为 0。我们显然不想这样。</p><p id="224f" class="pw-post-body-paragraph ma mb it mc b md na kd mf mg nb kg mi mj nd ml mm mn nf mp mq mr nh mt mu mv im bi translated">当比率(FP / TP)为 0 时，精度将为 1，因此 FP 应为 0。因此，这是最好的情况，因为当假阳性的数量减少时会产生高精度值。</p><p id="011b" class="pw-post-body-paragraph ma mb it mc b md na kd mf mg nb kg mi mj nd ml mm mn nf mp mq mr nh mt mu mv im bi translated"><strong class="mc jd">回忆:</strong></p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi pq"><img src="../Images/23dbc26bd13c638e763dbc10b100c9b9.png" data-original-src="https://miro.medium.com/v2/resize:fit:444/format:webp/1*kMFGsAJbho5olydsamFO1Q.png"/></div></figure><p id="def7" class="pw-post-body-paragraph ma mb it mc b md na kd mf mg nb kg mi mj nd ml mm mn nf mp mq mr nh mt mu mv im bi translated">用 TP 除分子和分母，我们得到:</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi pr"><img src="../Images/9d6aafadb9dbf156efcdbc3e42ae4814.png" data-original-src="https://miro.medium.com/v2/resize:fit:446/format:webp/1*mQUQbJIObAhmpaM0Yz5q4Q.png"/></div></figure><p id="e283" class="pw-post-body-paragraph ma mb it mc b md na kd mf mg nb kg mi mj nd ml mm mn nf mp mq mr nh mt mu mv im bi translated">我们知道召回值在范围[0，1]内。</p><p id="43e2" class="pw-post-body-paragraph ma mb it mc b md na kd mf mg nb kg mi mj nd ml mm mn nf mp mq mr nh mt mu mv im bi translated">当比率(FN / TP)趋于无穷大时，召回将为 0，为此 FN 应该趋于无穷大(实际上应该具有非常大的值)或者 TP 应该为 0。我们显然不想这样。</p><p id="1cf7" class="pw-post-body-paragraph ma mb it mc b md na kd mf mg nb kg mi mj nd ml mm mn nf mp mq mr nh mt mu mv im bi translated">当比率(FN / TP)为 0 时，召回将为 1，此时 FN 应为 0。我们知道，FN 是最坏的预测。因此，这是最好的情况，因为当假阴性的数量减少时会产生高召回值。</p><p id="f885" class="pw-post-body-paragraph ma mb it mc b md na kd mf mg nb kg mi mj nd ml mm mn nf mp mq mr nh mt mu mv im bi translated"><strong class="mc jd">总而言之，</strong></p><blockquote class="mx my mz"><p id="ccb8" class="ma mb mw mc b md na kd mf mg nb kg mi nc nd ml mm ne nf mp mq ng nh mt mu mv im bi translated">当涉及到不平衡数据分类时，Kappa 统计和精确召回曲线价值连城。</p></blockquote><h1 id="427b" class="li lj it bd lk ll lm ln lo lp lq lr ls ki lt kj lu kl lv km lw ko lx kp ly lz bi translated"><strong class="ak">第二步</strong></h1><h2 id="91dd" class="op lj it bd lk oq or dn lo os ot dp ls mj ou ov lu mn ow ox lw mr oy oz ly iz bi translated"><strong class="ak">交叉验证:</strong></h2><p id="bdee" class="pw-post-body-paragraph ma mb it mc b md me kd mf mg mh kg mi mj mk ml mm mn mo mp mq mr ms mt mu mv im bi translated">train_test_split 辅助函数不报告模型的概化能力，因为结果仅取决于一个特定的随机分割。</p><p id="e722" class="pw-post-body-paragraph ma mb it mc b md na kd mf mg nb kg mi mj nd ml mm mn nf mp mq mr nh mt mu mv im bi translated">此外，当我们调整参数设置(超参数)直到得到好的结果时，会出现一个问题。这可能给模型一个关于测试数据的提示，并且模型可能再次过拟合。为了防止这种情况，我们需要一个“验证集”，在其上对训练好的模型进行验证，然后最终在测试数据上进行测试，以防止它被泄露。但是这将大大减少训练样本的数量。这就是交叉验证帮助我们的地方。它避免了对验证集的需要。参见<a class="ae lh" href="https://scikit-learn.org/stable/modules/cross_validation.html" rel="noopener ugc nofollow" target="_blank"> scikit-learn 文档</a>了解这一事实。</p><p id="3494" class="pw-post-body-paragraph ma mb it mc b md na kd mf mg nb kg mi mj nd ml mm mn nf mp mq mr nh mt mu mv im bi translated">有几种交叉验证技术，可以应用于自己的数据。</p><p id="0600" class="pw-post-body-paragraph ma mb it mc b md na kd mf mg nb kg mi mj nd ml mm mn nf mp mq mr nh mt mu mv im bi translated">我使用了<a class="ae lh" href="https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.StratifiedKFold.html#sklearn.model_selection.StratifiedKFold" rel="noopener ugc nofollow" target="_blank">分层 K-fold </a>交叉验证技术，以便在每个训练和验证 fold 中近似保留相对类频率。这对于阶级不平衡的情况很重要。</p><p id="eb40" class="pw-post-body-paragraph ma mb it mc b md na kd mf mg nb kg mi mj nd ml mm mn nf mp mq mr nh mt mu mv im bi translated"><strong class="mc jd">分层 K 倍交叉验证是如何工作的？</strong></p><p id="4d13" class="pw-post-body-paragraph ma mb it mc b md na kd mf mg nb kg mi mj nd ml mm mn nf mp mq mr nh mt mu mv im bi translated">在分层的 K 折叠交叉验证中，数据集被分成 K 个大小大致相等的组(折叠),每个折叠的<em class="mw">保持原始数据集中的类别比例。</em>在这 K 个折叠中，K-1 个折叠用于训练模型，剩余的折叠用于验证模型。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi ps"><img src="../Images/758a93affd2cf2cd6b00ad4532633b2c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1200/format:webp/1*0J2s2JTltcezFtqXt9Ljbw.png"/></div><figcaption class="ld le gj gh gi lf lg bd b be z dk">Image source: <a class="ae lh" href="https://scikit-learn.org/stable/modules/cross_validation.html#stratified-k-fold" rel="noopener ugc nofollow" target="_blank">scikit-learn</a></figcaption></figure><p id="2115" class="pw-post-body-paragraph ma mb it mc b md na kd mf mg nb kg mi mj nd ml mm mn nf mp mq mr nh mt mu mv im bi translated"><strong class="mc jd">分层五重交叉验证:</strong></p><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="nx ny l"/></div><figcaption class="ld le gj gh gi lf lg bd b be z dk"><a class="ae lh" href="https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.StratifiedKFold.html" rel="noopener ugc nofollow" target="_blank">Stratified K-Fold Documentation</a></figcaption></figure><p id="3408" class="pw-post-body-paragraph ma mb it mc b md na kd mf mg nb kg mi mj nd ml mm mn nf mp mq mr nh mt mu mv im bi translated"><strong class="mc jd">注意:</strong>StratifiedKFold()中的参数“shuffle”被设置为“True ”,因为我们的数据不是任意的，因此，在我们分割数据之前，有必要对数据进行洗牌。当<em class="mw"> shuffle=True 时，</em>我们必须将“random_state”参数设置为一个随机数，这样可以防止代码执行多次时结果发生变化。</p><p id="f6c7" class="pw-post-body-paragraph ma mb it mc b md na kd mf mg nb kg mi mj nd ml mm mn nf mp mq mr nh mt mu mv im bi translated"><strong class="mc jd">卡帕统计:</strong></p><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="nx ny l"/></div></figure><p id="d11b" class="pw-post-body-paragraph ma mb it mc b md na kd mf mg nb kg mi mj nd ml mm mn nf mp mq mr nh mt mu mv im bi translated">低标准偏差表明模型没有过度拟合。此外，Kappa 统计值(此处为 0.746)比之前的情况(0.744)有所改善，尽管幅度很小。</p><p id="71d5" class="pw-post-body-paragraph ma mb it mc b md na kd mf mg nb kg mi mj nd ml mm mn nf mp mq mr nh mt mu mv im bi translated"><strong class="mc jd">精确召回曲线:</strong></p><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="nx ny l"/></div></figure><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi pt"><img src="../Images/7f21eb60492131558cc031e0c732cc43.png" data-original-src="https://miro.medium.com/v2/resize:fit:1148/format:webp/1*QM-JiDRiEv2CzvedQznCoQ.png"/></div></figure><p id="fa7f" class="pw-post-body-paragraph ma mb it mc b md na kd mf mg nb kg mi mj nd ml mm mn nf mp mq mr nh mt mu mv im bi translated">在每一个折叠中，几乎相似的 kappa 统计值和几乎相似的 AUC 值证明我们的模型具有良好的泛化能力。</p><h1 id="c700" class="li lj it bd lk ll lm ln lo lp lq lr ls ki lt kj lu kl lv km lw ko lx kp ly lz bi translated"><strong class="ak">步骤 3(概述)</strong></h1><h2 id="d217" class="op lj it bd lk oq or dn lo os ot dp ls mj ou ov lu mn ow ox lw mr oy oz ly iz bi translated"><strong class="ak">调节超参数:</strong></h2><p id="4601" class="pw-post-body-paragraph ma mb it mc b md me kd mf mg mh kg mi mj mk ml mm mn mo mp mq mr ms mt mu mv im bi translated">超参数是其值在学习过程开始之前设置的参数，并且不由模型直接学习。</p><p id="6b25" class="pw-post-body-paragraph ma mb it mc b md na kd mf mg nb kg mi mj nd ml mm mn nf mp mq mr nh mt mu mv im bi translated">调整超参数有助于我们努力为特定模型找到理想的参数套件，从而获得最佳分数。</p><p id="3d5c" class="pw-post-body-paragraph ma mb it mc b md na kd mf mg nb kg mi mj nd ml mm mn nf mp mq mr nh mt mu mv im bi translated"><a class="ae lh" href="https://scikit-learn.org/stable/modules/grid_search.html#grid-search" rel="noopener ugc nofollow" target="_blank"> GridSearchCV 和 RandomizedSearchCV </a>最常用于调整超参数。</p><p id="0dae" class="pw-post-body-paragraph ma mb it mc b md na kd mf mg nb kg mi mj nd ml mm mn nf mp mq mr nh mt mu mv im bi translated">在接下来的部分中，我们将尝试使用 GridSearchCV 来揭示有助于进一步提高所讨论的评估指标值的最佳超参数。</p></div><div class="ab cl nq nr hx ns" role="separator"><span class="nt bw bk nu nv nw"/><span class="nt bw bk nu nv nw"/><span class="nt bw bk nu nv"/></div><div class="im in io ip iq"><p id="2468" class="pw-post-body-paragraph ma mb it mc b md na kd mf mg nb kg mi mj nd ml mm mn nf mp mq mr nh mt mu mv im bi translated">在我的<a class="ae lh" href="https://github.com/MitaliBhurani/Scouting-out-urban-areas-from-satellite-imagery" rel="noopener ugc nofollow" target="_blank"> GitHub 库</a>中找到完整的代码。</p><p id="c7b3" class="pw-post-body-paragraph ma mb it mc b md na kd mf mg nb kg mi mj nd ml mm mn nf mp mq mr nh mt mu mv im bi translated">希望热心的读者喜欢它，并有他们的发言权！敬请关注即将到来的部分！</p><h1 id="a1d5" class="li lj it bd lk ll lm ln lo lp lq lr ls ki lt kj lu kl lv km lw ko lx kp ly lz bi translated"><strong class="ak">参考文献:</strong></h1><p id="535d" class="pw-post-body-paragraph ma mb it mc b md me kd mf mg mh kg mi mj mk ml mm mn mo mp mq mr ms mt mu mv im bi translated">[1] <a class="ae lh" href="https://www.nrcan.gc.ca/maps-tools-publications/satellite-imagery-air-photos/tutorial-fundamentals-remote-sensing/9309" rel="noopener ugc nofollow" target="_blank">遥感教程——加拿大自然资源部加拿大测绘和地球观测中心(或加拿大遥感中心)。</a></p><p id="1d09" class="pw-post-body-paragraph ma mb it mc b md na kd mf mg nb kg mi mj nd ml mm mn nf mp mq mr nh mt mu mv im bi translated">[2]'哥白尼哨兵数据[2018]' ( <a class="ae lh" href="https://earthexplorer.usgs.gov/" rel="noopener ugc nofollow" target="_blank">从 USGS 网站</a>下载)</p><p id="435a" class="pw-post-body-paragraph ma mb it mc b md na kd mf mg nb kg mi mj nd ml mm mn nf mp mq mr nh mt mu mv im bi translated">[3] Thanh Noi，p；使用 Sentinel-2 影像进行土地覆盖分类的随机森林、k-最近邻和支持向量机分类器的比较。<em class="mw">传感器</em> <strong class="mc jd"> 2018 </strong>，<em class="mw"> 18 </em>，18。</p><p id="9a01" class="pw-post-body-paragraph ma mb it mc b md na kd mf mg nb kg mi mj nd ml mm mn nf mp mq mr nh mt mu mv im bi translated">[4]博客:<a class="ae lh" href="https://machinelearningmastery.com/" rel="noopener ugc nofollow" target="_blank">机器学习掌握</a>，<a class="ae lh" href="https://medium.com/@srinivas.sateesh/have-you-asked-why-f1-score-is-a-harmonic-mean-hm-of-precision-and-recall-febc233ce247" rel="noopener">你有没有问过为什么 F1-Score 是精度和召回率的调和均值(HM)？</a></p></div></div>    
</body>
</html>