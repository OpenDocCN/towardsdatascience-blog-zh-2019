<html>
<head>
<title>Self-Supervised GANs</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">自我监督的甘斯</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/self-supervised-gans-2aec1eadaccd?source=collection_archive---------17-----------------------#2019-02-04">https://towardsdatascience.com/self-supervised-gans-2aec1eadaccd?source=collection_archive---------17-----------------------#2019-02-04</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><h1 id="2c2a" class="jn jo iq bd jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk bi translated">甘斯</h1><p id="ebed" class="pw-post-body-paragraph kl km iq kn b ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">如果你不熟悉生成对抗网络(GANs)，它们是一种非常流行的生成建模技术，由两个深度神经网络(一个生成器和一个鉴别器)相互对抗而形成。这种对抗性的损失引发了许多深度学习和人工智能研究人员的兴趣。然而，尽管 GAN 公式很美，最先进的架构也令人大开眼界，但 GAN 通常很难训练。使用 GANs 获得更好结果的最好方法之一是提供类别标签。这是有条件 GAN 模型的基础。本文将展示自我监督学习如何克服训练 GAN 对类别标签的需求，并与条件 GAN 模型的性能相媲美。</p><h1 id="b65f" class="jn jo iq bd jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk bi translated"><strong class="ak">自我监督学习</strong></h1><p id="5fe9" class="pw-post-body-paragraph kl km iq kn b ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">在我们进入自我监督学习如何改进 GANs 之前，我们将介绍自我监督学习的概念。与监督和非监督学习的流行系列相比，自我监督学习与非监督学习最为相似。自我监督的任务包括图像着色、预测从图像中提取的补丁的相对位置，或者在这种情况下，预测图像的旋转角度。这些任务被称为“自我监督的”，因为这些数据有助于这些替代任务。在这个意义上，自监督任务采用(X，Y)对的形式，然而，X，Y 对是从数据集本身自动构建的，并且不需要人工标记。这篇文章中讨论的论文将自我监督学习总结为“一个人可以对给定的图像进行编辑，并要求网络预测编辑的部分”。这是自我监督学习背后的基本思想。</p><h1 id="f3b3" class="jn jo iq bd jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk bi translated"><strong class="ak">有条件和无条件的 GANs </strong></h1><p id="1422" class="pw-post-body-paragraph kl km iq kn b ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">现在，我们将把自我监督学习与训练 GANs 的相关问题联系起来。在其理想形式中，GANs 是一种无监督的生成建模形式，其中您可以只提供数据，并让模型从中创建合成数据。然而，最先进的 GANs 使用一种称为条件 GANs 的技术，该技术将生成建模任务转变为监督学习任务，需要标记数据。在 Conditional-GANs 中，类标签被嵌入到生成器和鉴别器中，以便于生成性建模过程。无条件 GANs 指的是 Goodfellow 最初的想法，即生成式建模不需要类标签。本文将向您展示自我监督的学习任务如何能够消除对带有 GANs 的标记数据的需求。</p><figure class="lk ll lm ln gt lo gh gi paragraph-image"><div role="button" tabindex="0" class="lp lq di lr bf ls"><div class="gh gi lj"><img src="../Images/93348bfeeb3bdeaa0d7e6ec3cbad89de.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*N8eQpGBSmg-F-Vb9TonmyA.png"/></div></div><figcaption class="lv lw gj gh gi lx ly bd b be z dk">Conditional GANs require class labels to work, (pictured in green)</figcaption></figure><h1 id="7a73" class="jn jo iq bd jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk bi translated"><strong class="ak">辅助旋转任务</strong></h1><p id="a5b0" class="pw-post-body-paragraph kl km iq kn b ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">本文将讨论在以下论文中提出的自监督学习 GAN 架构的细节:</p><div class="lz ma gp gr mb mc"><a href="https://arxiv.org/abs/1811.11212" rel="noopener  ugc nofollow" target="_blank"><div class="md ab fo"><div class="me ab mf cl cj mg"><h2 class="bd ir gy z fp mh fr fs mi fu fw ip bi translated">自我监督的生成对抗网络</h2><div class="mj l"><h3 class="bd b gy z fp mh fr fs mi fu fw dk translated">条件甘处于自然图像合成的前沿。这种模型的主要缺点是需要…</h3></div><div class="mk l"><p class="bd b dl z fp mh fr fs mi fu fw dk translated">arxiv.org</p></div></div></div></a></div><p id="8f6b" class="pw-post-body-paragraph kl km iq kn b ko ml kq kr ks mm ku kv kw mn ky kz la mo lc ld le mp lg lh li ij bi translated">从高层次来看，本文中的辅助的、自我监督的学习任务是容易理解的。(如下图)</p><figure class="lk ll lm ln gt lo gh gi paragraph-image"><div role="button" tabindex="0" class="lp lq di lr bf ls"><div class="gh gi mq"><img src="../Images/99eed358b7ac0fa07a29a64dc5d1cb53.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*o5WfTLn3EMeEj__p"/></div></div></figure><p id="0161" class="pw-post-body-paragraph kl km iq kn b ko ml kq kr ks mm ku kv kw mn ky kz la mo lc ld le mp lg lh li ij bi translated">GAN 的发生器部分完全不知道辅助旋转任务，除了它必须学会在旋转时产生与真实图像共享相似特征的图像。轮换任务对鉴别器网络有巨大的影响。鉴别器现在有两个任务。第一个是预测图像是来自原始训练集还是由生成器创建的，就像所有的 GANs 一样。第二个任务是这篇论文如此有趣的原因。这组真实和虚假图像被旋转成 0、90、180 和 270 度旋转的相等分区，并且鉴别器必须对这些图像的旋转角度进行分类。鉴别器的旋转误差仅在真实图像上的误差上受到惩罚，以阻止来自生成器的不健康的收敛。</p><h1 id="e82e" class="jn jo iq bd jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk bi translated"><strong class="ak">鉴别器遗忘</strong></h1><p id="a093" class="pw-post-body-paragraph kl km iq kn b ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">作者提出，由于难以从非平稳分布中学习，无条件 gan 表现不佳。这是持续学习中重点研究的问题，本文讨论了许多方法，如连接持续学习和 GANs 的弹性权重分配。提出的一个有趣的观点是，在最优生成器的情况下，鉴别器不需要学习有用的特征。</p><p id="2b56" class="pw-post-body-paragraph kl km iq kn b ko ml kq kr ks mm ku kv kw mn ky kz la mo lc ld le mp lg lh li ij bi translated">为了展示自监督 GAN 如何减轻鉴别器遗忘，他们从鉴别器中提取特征，并使用它来训练逻辑回归模型，以在监督的鉴别任务中对数据进行分类。</p><figure class="lk ll lm ln gt lo gh gi paragraph-image"><div class="gh gi mr"><img src="../Images/52c7e8aa2435e256e2a47a90c18ebaa1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1192/0*qmn9zHu3vSXdyTgQ"/></div></figure><p id="d9b5" class="pw-post-body-paragraph kl km iq kn b ko ml kq kr ks mm ku kv kw mn ky kz la mo lc ld le mp lg lh li ij bi translated">上面的图表明，无条件 GAN 将无法学习用于辨别任务的有用特征，而自监督 GAN(具有辅助旋转分类任务)学习的特征在训练期间继续学习用于监督学习模型的有用特征。</p><figure class="lk ll lm ln gt lo gh gi paragraph-image"><div role="button" tabindex="0" class="lp lq di lr bf ls"><div class="gh gi ms"><img src="../Images/02b1d6e0ce881200c3a84e6de279fc0c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*Mm8wzVNqTibjBfLN"/></div></div></figure><p id="42b1" class="pw-post-body-paragraph kl km iq kn b ko ml kq kr ks mm ku kv kw mn ky kz la mo lc ld le mp lg lh li ij bi translated">关于图像输出的质量，上图显示了通常用于定量评估两种自监督 GAN 以及有条件和无条件 GAN 模型的图像质量的 FID 分数。这些图显示，具有自调制批量标准化(sBN)的 SS-GAN 在 ImageNet 和 CIFAR-10 上的性能与有条件 GAN 一样好，右上方的图显示了无条件 GAN 在 ImageNet 生成任务上的性能。</p><figure class="lk ll lm ln gt lo gh gi paragraph-image"><div class="gh gi mt"><img src="../Images/ff0ca051a077996aa4d1ebb61d67a615.png" data-original-src="https://miro.medium.com/v2/resize:fit:788/0*o1PpjyJ7-dsDaluO"/></div></figure><p id="adfa" class="pw-post-body-paragraph kl km iq kn b ko ml kq kr ks mm ku kv kw mn ky kz la mo lc ld le mp lg lh li ij bi translated">上面的图比较了使用鉴别器特征在其他流行的自我监督学习任务中训练分类模型的结果。有许多不同的方法来设置自我监督的学习任务，我发现看到这种比较非常有趣。</p></div><div class="ab cl mu mv hu mw" role="separator"><span class="mx bw bk my mz na"/><span class="mx bw bk my mz na"/><span class="mx bw bk my mz"/></div><div class="ij ik il im in"><figure class="lk ll lm ln gt lo"><div class="bz fp l di"><div class="nb nc l"/></div></figure><p id="788e" class="pw-post-body-paragraph kl km iq kn b ko ml kq kr ks mm ku kv kw mn ky kz la mo lc ld le mp lg lh li ij bi translated">感谢您的阅读！这是一个非常有趣的结果，通过使用辅助的自我监督任务来探索完全无监督的生成建模，请查看论文以了解更多细节！</p></div></div>    
</body>
</html>