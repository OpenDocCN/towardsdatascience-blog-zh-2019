<html>
<head>
<title>Convolutional Neural Network</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">卷积神经网络</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/covolutional-neural-network-cb0883dd6529?source=collection_archive---------0-----------------------#2019-02-24">https://towardsdatascience.com/covolutional-neural-network-cb0883dd6529?source=collection_archive---------0-----------------------#2019-02-24</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="9fa4" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">从 basic 学习卷积神经网络及其在 Keras 中的实现</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/a82f291a6ee1d16848a735facc639291.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*z7hd8FZeI_eodazwIapvAw.png"/></div></div></figure><h2 id="5f42" class="kr ks iq bd kt ku kv dn kw kx ky dp kz la lb lc ld le lf lg lh li lj lk ll lm bi translated">目录</h2><ul class=""><li id="6cea" class="ln lo iq lp b lq lr ls lt la lu le lv li lw lx ly lz ma mb bi translated">CNN 是什么？</li><li id="50d5" class="ln lo iq lp b lq mc ls md la me le mf li mg lx ly lz ma mb bi translated">为什么要用 CNN？</li><li id="2af0" class="ln lo iq lp b lq mc ls md la me le mf li mg lx ly lz ma mb bi translated">几个定义</li><li id="21d5" class="ln lo iq lp b lq mc ls md la me le mf li mg lx ly lz ma mb bi translated">CNN 中的图层</li><li id="1221" class="ln lo iq lp b lq mc ls md la me le mf li mg lx ly lz ma mb bi translated">Keras 实施</li></ul><h1 id="8e4f" class="mh ks iq bd kt mi mj mk kw ml mm mn kz jw mo jx ld jz mp ka lh kc mq kd ll mr bi translated">1.CNN 是什么？</h1><p id="6c80" class="pw-post-body-paragraph ms mt iq lp b lq lr jr mu ls lt ju mv la mw mx my le mz na nb li nc nd ne lx ij bi translated">计算机视觉每天都在快速发展。原因之一是深度学习。当我们谈论计算机视觉时，我们脑海中会出现一个术语卷积神经网络(缩写为 CNN)，因为 CNN 在这里被大量使用。计算机视觉中 CNN 的例子有人脸识别、图像分类等。它类似于基本的神经网络。CNN 也有像神经网络一样的可学习参数，即权重、偏差等。</p><h1 id="4266" class="mh ks iq bd kt mi mj mk kw ml mm mn kz jw mo jx ld jz mp ka lh kc mq kd ll mr bi translated">2.为什么要用 CNN？</h1><h2 id="e5d0" class="kr ks iq bd kt ku kv dn kw kx ky dp kz la lb lc ld le lf lg lh li lj lk ll lm bi translated">前馈神经网络的问题</h2><p id="0d5a" class="pw-post-body-paragraph ms mt iq lp b lq lr jr mu ls lt ju mv la mw mx my le mz na nb li nc nd ne lx ij bi translated">假设您正在处理 MNIST 数据集，您知道 MNIST 的每幅图像都是 28 x 28 x 1(黑白图像仅包含一个通道)。输入层的神经元总数将是 28×28 = 784，这是可以管理的。如果图像的大小是 1000 x 1000，这意味着你需要在输入层 10⁶神经元。哦！这似乎需要大量的神经元来运作。它在计算上是无效的。所以卷积神经网络或者 CNN 来了。简而言之，CNN 所做的就是提取图像的特征，并将其转换到低维，而不丢失其特征。在下面的例子中你可以看到初始图像的大小是 224 x 224 x 3。如果不进行卷积，那么在输入层中需要 224 x 224 x 3 = 100，352 个神经元，但是在应用卷积之后，输入张量维数减少到 1 x 1 x 1000。这意味着在前向神经网络的第一层只需要 1000 个神经元。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nf"><img src="../Images/13ba1cd1798b521255e0bd2ddece519d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*V6hPq-srR86AIWYrgFYLfA.png"/></div></div><figcaption class="ng nh gj gh gi ni nj bd b be z dk">Fig. Downsampling</figcaption></figure><h1 id="7636" class="mh ks iq bd kt mi mj mk kw ml mm mn kz jw mo jx ld jz mp ka lh kc mq kd ll mr bi translated">3.几个定义</h1><p id="96a2" class="pw-post-body-paragraph ms mt iq lp b lq lr jr mu ls lt ju mv la mw mx my le mz na nb li nc nd ne lx ij bi translated">在了解 CNN 之前，有几个你应该知道的定义</p><h2 id="c5cb" class="kr ks iq bd kt ku kv dn kw kx ky dp kz la lb lc ld le lf lg lh li lj lk ll lm bi translated">3.1 图像表示</h2><p id="814d" class="pw-post-body-paragraph ms mt iq lp b lq lr jr mu ls lt ju mv la mw mx my le mz na nb li nc nd ne lx ij bi translated">想想图像，很容易理解它有高度和宽度，所以用二维结构(矩阵)来表示图像中包含的信息是有意义的，直到你记得图像有颜色，为了添加关于颜色的信息，我们需要另一个维度，这就是张量变得特别有用的时候。</p><p id="b2b2" class="pw-post-body-paragraph ms mt iq lp b lq nk jr mu ls nl ju mv la nm mx my le nn na nb li no nd ne lx ij bi translated">图像被编码到颜色通道中，图像数据在给定点被表示为颜色通道中的每个颜色强度，最常见的是 RGB，这意味着红色、蓝色和绿色。包含在图像中的信息是每个通道颜色的强度到图像的宽度和高度，就像这样</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi np"><img src="../Images/865c8623a8816a7bf43dc7e53265779a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*125JKUHmij9bzKcREpq9ew.png"/></div></div><figcaption class="ng nh gj gh gi ni nj bd b be z dk">Fig. RGB representation of a image</figcaption></figure><p id="9d11" class="pw-post-body-paragraph ms mt iq lp b lq nk jr mu ls nl ju mv la nm mx my le nn na nb li no nd ne lx ij bi translated">因此，红色通道在每个点上的强度以及宽度和高度可以表示为一个矩阵，蓝色和绿色通道也是如此，因此我们最终有三个矩阵，当这些矩阵组合在一起时，它们就形成了一个张量。</p><h2 id="9c6b" class="kr ks iq bd kt ku kv dn kw kx ky dp kz la lb lc ld le lf lg lh li lj lk ll lm bi translated">3.2 边缘检测</h2><p id="bf5c" class="pw-post-body-paragraph ms mt iq lp b lq lr jr mu ls lt ju mv la mw mx my le mz na nb li nc nd ne lx ij bi translated">每个图像都有垂直和水平边缘，它们实际上组合在一起形成一个图像。卷积运算与一些用于检测边缘的滤波器一起使用。假设你有尺寸为 6×6 的灰度图像和尺寸为 3×3 的过滤器。当 6×6 灰度级图像与 3×3 滤波器卷积时，我们得到 4×4 图像。首先，将 3×3 滤波器矩阵乘以我们灰度图像的第一个 3×3 尺寸，然后我们将一列向右移动到末尾，之后我们移动一行，依此类推。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi np"><img src="../Images/2817e5421f6d40c31695bcc2eda6e327.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Ekm4QJ1rHE-bJbQllBWLPA.png"/></div></div><figcaption class="ng nh gj gh gi ni nj bd b be z dk">Convolution operation</figcaption></figure><p id="89f1" class="pw-post-body-paragraph ms mt iq lp b lq nk jr mu ls nl ju mv la nm mx my le nn na nb li no nd ne lx ij bi translated">卷积运算可以用下面的方式来表示。这里，我们的图像尺寸是 4 x 4，过滤器是 3 x 3，因此我们得到卷积后的输出是 2 x 2。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi nq"><img src="../Images/867d341cd4b8e3a2435aa5fc4b5546d4.png" data-original-src="https://miro.medium.com/v2/resize:fit:488/1*4h_J0Zpx93_sFHKxWUoHAw.gif"/></div><figcaption class="ng nh gj gh gi ni nj bd b be z dk">Visualization of convolution</figcaption></figure><p id="bdd6" class="pw-post-body-paragraph ms mt iq lp b lq nk jr mu ls nl ju mv la nm mx my le nn na nb li no nd ne lx ij bi translated">如果我们有 N×N 的图像大小和 F×F 的滤波器大小，那么卷积后的结果将是</p><pre class="kg kh ki kj gt nr ns nt nu aw nv bi"><span id="e160" class="kr ks iq ns b gy nw nx l ny nz">(N x N) * (F x F) = (N-F+1)x(N-F+1)(Apply this for above case)</span></pre><h2 id="9501" class="kr ks iq bd kt ku kv dn kw kx ky dp kz la lb lc ld le lf lg lh li lj lk ll lm bi translated">3.3 步幅和衬垫</h2><p id="ac24" class="pw-post-body-paragraph ms mt iq lp b lq lr jr mu ls lt ju mv la mw mx my le mz na nb li nc nd ne lx ij bi translated">步幅表示在卷积的每一步中我们移动了多少步。默认情况下是一个。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi oa"><img src="../Images/a5df45e1f37652fc22951cddbe07cc4a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/1*g0OmDI1w9KqN7Rpw6Qo8Xg@2x.gif"/></div></div><figcaption class="ng nh gj gh gi ni nj bd b be z dk">Convolution with Stride 1</figcaption></figure><p id="7f02" class="pw-post-body-paragraph ms mt iq lp b lq nk jr mu ls nl ju mv la nm mx my le nn na nb li no nd ne lx ij bi translated">我们可以观察到输出的大小小于输入的大小。为了保持输入中输出的维数，我们使用填充。填充是将零对称地添加到输入矩阵的过程。在下面的示例中，额外的灰色块表示填充。它用于使输出的尺寸与输入的尺寸相同。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi np"><img src="../Images/deb54bc7c4faf8e23c18af594e47f589.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/1*17TNPi4m0pBqOCGrXzU27w.gif"/></div></div><figcaption class="ng nh gj gh gi ni nj bd b be z dk">Stride 1 with Padding 1</figcaption></figure><p id="ecfa" class="pw-post-body-paragraph ms mt iq lp b lq nk jr mu ls nl ju mv la nm mx my le nn na nb li no nd ne lx ij bi translated">假设“p”是填充</p><p id="6fb5" class="pw-post-body-paragraph ms mt iq lp b lq nk jr mu ls nl ju mv la nm mx my le nn na nb li no nd ne lx ij bi translated">最初(无填充)</p><pre class="kg kh ki kj gt nr ns nt nu aw nv bi"><span id="ba61" class="kr ks iq ns b gy nw nx l ny nz">(N x N) * (F x F) = (N-F+1)x(N-F+1)---(1)</span></pre><p id="4e67" class="pw-post-body-paragraph ms mt iq lp b lq nk jr mu ls nl ju mv la nm mx my le nn na nb li no nd ne lx ij bi translated">应用填充后</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi ob"><img src="../Images/ac7cd30f35e40c82be2d71aa5b1c06b5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1200/format:webp/1*8VwvmOay_k_0MLTrwqQtEg.png"/></div><figcaption class="ng nh gj gh gi ni nj bd b be z dk">After applying padding</figcaption></figure><p id="ec9a" class="pw-post-body-paragraph ms mt iq lp b lq nk jr mu ls nl ju mv la nm mx my le nn na nb li no nd ne lx ij bi translated">如果我们在带有填充的(N+2p) x (N+2p)输入矩阵中应用滤波器 F x F，那么我们将得到输出矩阵维数(N+2p-F+1) x (N+2p-F+1)。正如我们所知，应用填充后，我们将获得与原始输入尺寸相同的尺寸(N x N)。因此我们有，</p><pre class="kg kh ki kj gt nr ns nt nu aw nv bi"><span id="cabb" class="kr ks iq ns b gy nw nx l ny nz">(N+2p-F+1)x(N+2p-F+1) equivalent to NxN<br/> N+2p-F+1 = N ---(2)<br/> p = (F-1)/2 ---(3)</span></pre><p id="9bcd" class="pw-post-body-paragraph ms mt iq lp b lq nk jr mu ls nl ju mv la nm mx my le nn na nb li no nd ne lx ij bi translated">等式(3)清楚地表明，填充取决于滤波器的尺寸。</p><h1 id="d0cd" class="mh ks iq bd kt mi mj mk kw ml mm mn kz jw mo jx ld jz mp ka lh kc mq kd ll mr bi translated">4.CNN 中的图层</h1><p id="0b6e" class="pw-post-body-paragraph ms mt iq lp b lq lr jr mu ls lt ju mv la mw mx my le mz na nb li nc nd ne lx ij bi translated">CNN 有五个不同的层次</p><ul class=""><li id="824b" class="ln lo iq lp b lq nk ls nl la oc le od li oe lx ly lz ma mb bi translated">输入层</li><li id="2b85" class="ln lo iq lp b lq mc ls md la me le mf li mg lx ly lz ma mb bi translated">卷积层(卷积+ ReLU)</li><li id="0895" class="ln lo iq lp b lq mc ls md la me le mf li mg lx ly lz ma mb bi translated">汇集层</li><li id="1b7f" class="ln lo iq lp b lq mc ls md la me le mf li mg lx ly lz ma mb bi translated">全连接(FC)层</li><li id="23a3" class="ln lo iq lp b lq mc ls md la me le mf li mg lx ly lz ma mb bi translated">soft max/逻辑层</li><li id="e9d9" class="ln lo iq lp b lq mc ls md la me le mf li mg lx ly lz ma mb bi translated">输出层</li></ul><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi of"><img src="../Images/1825b4a8b82aa60882e8623ff5d5b8b3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*0bCOXLJLxkRktiTTDug6GA.png"/></div><figcaption class="ng nh gj gh gi ni nj bd b be z dk">Different layers of CNN</figcaption></figure><h2 id="1493" class="kr ks iq bd kt ku kv dn kw kx ky dp kz la lb lc ld le lf lg lh li lj lk ll lm bi translated">4.1 输入层</h2><p id="1330" class="pw-post-body-paragraph ms mt iq lp b lq lr jr mu ls lt ju mv la mw mx my le mz na nb li nc nd ne lx ij bi translated">CNN 中的输入层应该包含图像数据。正如我们前面看到的，图像数据由三维矩阵表示。你需要把它改造成一列。假设您有一个尺寸为 28 x 28 =784 的图像，您需要在输入之前将其转换为 784 x 1。如果有“m”个训练示例，那么输入的维数将是(784，m)。</p><h2 id="cf60" class="kr ks iq bd kt ku kv dn kw kx ky dp kz la lb lc ld le lf lg lh li lj lk ll lm bi translated">4.2.卷积层</h2><p id="8f0b" class="pw-post-body-paragraph ms mt iq lp b lq lr jr mu ls lt ju mv la mw mx my le mz na nb li nc nd ne lx ij bi translated">卷积层有时被称为特征提取层，因为图像的特征是在该层中提取的。首先，将图像的一部分连接到卷积层，以执行我们前面看到的卷积运算，并计算感受野(它是输入图像的一个局部区域，与滤波器的大小相同)和滤波器之间的点积。运算结果是输出量的单个整数。然后，我们将过滤器在同一输入图像的下一个感受野上滑动一个步长，并再次进行相同的操作。我们将一次又一次地重复同样的过程，直到我们看完整个图像。输出将成为下一层的输入。</p><p id="f251" class="pw-post-body-paragraph ms mt iq lp b lq nk jr mu ls nl ju mv la nm mx my le nn na nb li no nd ne lx ij bi translated">卷积层还包含 ReLU 激活，使所有负值为零。</p><h2 id="0f33" class="kr ks iq bd kt ku kv dn kw kx ky dp kz la lb lc ld le lf lg lh li lj lk ll lm bi translated">4.3.汇集层</h2><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi og"><img src="../Images/43c9d1def28f9c877534635172a57cd8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*GksqN5XY8HPpIddm5wzm7A.jpeg"/></div></div><figcaption class="ng nh gj gh gi ni nj bd b be z dk"><a class="ae oh" href="http://cs231n.github.io/assets/cnn/pool.jpeg" rel="noopener ugc nofollow" target="_blank">Source</a> : CS231n Convolutional Neural Network</figcaption></figure><p id="8f26" class="pw-post-body-paragraph ms mt iq lp b lq nk jr mu ls nl ju mv la nm mx my le nn na nb li no nd ne lx ij bi translated">池层用于减少卷积后输入图像的空间体积。它用于两个卷积层之间。如果我们在卷积层之后应用 FC，而不应用池化或最大池化，那么它将是计算上昂贵的，我们不想要它。因此，最大池化是减少输入图像空间体积的唯一方法。在上面的示例中，我们在跨距为 2 的单个深度切片中应用了最大池。您可以观察到 4 x 4 维输入减少到 2 x 2 维。</p><p id="3321" class="pw-post-body-paragraph ms mt iq lp b lq nk jr mu ls nl ju mv la nm mx my le nn na nb li no nd ne lx ij bi translated">池层中没有参数，但有两个超参数-过滤器(F)和步幅(S)。</p><p id="6c33" class="pw-post-body-paragraph ms mt iq lp b lq nk jr mu ls nl ju mv la nm mx my le nn na nb li no nd ne lx ij bi translated">一般来说，如果我们有输入维数 W1 x H1 x D1，那么</p><p id="e8dc" class="pw-post-body-paragraph ms mt iq lp b lq nk jr mu ls nl ju mv la nm mx my le nn na nb li no nd ne lx ij bi translated">w2 =(W1 F)/S+1</p><p id="623b" class="pw-post-body-paragraph ms mt iq lp b lq nk jr mu ls nl ju mv la nm mx my le nn na nb li no nd ne lx ij bi translated">H2 =(H1 F)/S+1</p><p id="5857" class="pw-post-body-paragraph ms mt iq lp b lq nk jr mu ls nl ju mv la nm mx my le nn na nb li no nd ne lx ij bi translated">D2 = D1</p><p id="040e" class="pw-post-body-paragraph ms mt iq lp b lq nk jr mu ls nl ju mv la nm mx my le nn na nb li no nd ne lx ij bi translated">其中 W2、H2 和 D2 是输出的宽度、高度和深度。</p><h2 id="2a75" class="kr ks iq bd kt ku kv dn kw kx ky dp kz la lb lc ld le lf lg lh li lj lk ll lm bi translated">4.4.全连接层</h2><p id="d0c3" class="pw-post-body-paragraph ms mt iq lp b lq lr jr mu ls lt ju mv la mw mx my le mz na nb li nc nd ne lx ij bi translated">全连接层包括权重、偏差和神经元。它将一层中的神经元连接到另一层中的神经元。它用于通过训练对不同类别的图像进行分类。</p><h2 id="b5ce" class="kr ks iq bd kt ku kv dn kw kx ky dp kz la lb lc ld le lf lg lh li lj lk ll lm bi translated">4.5.Softmax /逻辑层</h2><p id="209a" class="pw-post-body-paragraph ms mt iq lp b lq lr jr mu ls lt ju mv la mw mx my le mz na nb li nc nd ne lx ij bi translated">Softmax 或逻辑层是 CNN 的最后一层。它位于光纤通道层的末端。Logistic 用于二分类，softmax 用于多分类。</p><h2 id="2f5f" class="kr ks iq bd kt ku kv dn kw kx ky dp kz la lb lc ld le lf lg lh li lj lk ll lm bi translated">4.6.输出层</h2><p id="8f0f" class="pw-post-body-paragraph ms mt iq lp b lq lr jr mu ls lt ju mv la mw mx my le mz na nb li nc nd ne lx ij bi translated">输出层包含的标签是以一键编码的形式。</p><p id="8570" class="pw-post-body-paragraph ms mt iq lp b lq nk jr mu ls nl ju mv la nm mx my le nn na nb li no nd ne lx ij bi translated">现在你对 CNN 有了很好的了解。让我们在 Keras 实现一个 CNN。</p><h1 id="ece3" class="mh ks iq bd kt mi mj mk kw ml mm mn kz jw mo jx ld jz mp ka lh kc mq kd ll mr bi translated">5.Keras 实施</h1><p id="3479" class="pw-post-body-paragraph ms mt iq lp b lq lr jr mu ls lt ju mv la mw mx my le mz na nb li nc nd ne lx ij bi translated">我们将使用 CIFAR-10 数据集来构建 CNN 图像分类器。CIFAR-10 数据集有 10 个不同的标签</p><ul class=""><li id="d6fa" class="ln lo iq lp b lq nk ls nl la oc le od li oe lx ly lz ma mb bi translated">飞机</li><li id="f674" class="ln lo iq lp b lq mc ls md la me le mf li mg lx ly lz ma mb bi translated">汽车</li><li id="4193" class="ln lo iq lp b lq mc ls md la me le mf li mg lx ly lz ma mb bi translated">伯德</li><li id="c065" class="ln lo iq lp b lq mc ls md la me le mf li mg lx ly lz ma mb bi translated">猫</li><li id="7f39" class="ln lo iq lp b lq mc ls md la me le mf li mg lx ly lz ma mb bi translated">鹿</li><li id="e6ab" class="ln lo iq lp b lq mc ls md la me le mf li mg lx ly lz ma mb bi translated">狗</li><li id="2472" class="ln lo iq lp b lq mc ls md la me le mf li mg lx ly lz ma mb bi translated">青蛙</li><li id="e93b" class="ln lo iq lp b lq mc ls md la me le mf li mg lx ly lz ma mb bi translated">马</li><li id="fb5b" class="ln lo iq lp b lq mc ls md la me le mf li mg lx ly lz ma mb bi translated">船</li><li id="5a07" class="ln lo iq lp b lq mc ls md la me le mf li mg lx ly lz ma mb bi translated">卡车</li></ul><p id="d445" class="pw-post-body-paragraph ms mt iq lp b lq nk jr mu ls nl ju mv la nm mx my le nn na nb li no nd ne lx ij bi translated">它有 50000 个训练数据和 10000 个测试图像数据。CIFAR-10 中的图像大小为 32 x 32 x 3。它带有 Keras 库。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi oi"><img src="../Images/7f9b8235677b50e9e0822568065f9b94.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_p1DwmIPQU_gAiB197PBMQ.png"/></div></div><figcaption class="ng nh gj gh gi ni nj bd b be z dk">Fig. Model visualization</figcaption></figure><p id="2584" class="pw-post-body-paragraph ms mt iq lp b lq nk jr mu ls nl ju mv la nm mx my le nn na nb li no nd ne lx ij bi translated">如果你用的是 google colaboratory，那么要确保你用的是 GPU。来检查你的 GPU 是否开着。尝试以下代码。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="oj ok l"/></div></figure><p id="caa7" class="pw-post-body-paragraph ms mt iq lp b lq nk jr mu ls nl ju mv la nm mx my le nn na nb li no nd ne lx ij bi translated">输出:</p><pre class="kg kh ki kj gt nr ns nt nu aw nv bi"><span id="ae17" class="kr ks iq ns b gy nw nx l ny nz">Found GPU at: /device:GPU:0</span></pre><p id="a1a5" class="pw-post-body-paragraph ms mt iq lp b lq nk jr mu ls nl ju mv la nm mx my le nn na nb li no nd ne lx ij bi translated">首先，导入所有必需的模块和库。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="oj ok l"/></div></figure><p id="5bd9" class="pw-post-body-paragraph ms mt iq lp b lq nk jr mu ls nl ju mv la nm mx my le nn na nb li no nd ne lx ij bi translated">然后加载数据集，并将其分成训练集和测试集。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="oj ok l"/></div></figure><p id="4c9f" class="pw-post-body-paragraph ms mt iq lp b lq nk jr mu ls nl ju mv la nm mx my le nn na nb li no nd ne lx ij bi translated">我们将打印 CIFAR-10 中的训练样本形状、测试样本形状和总类数。正如我们之前看到的，有 10 个类。为了举例，我们将打印来自训练集和测试集的两个示例图像。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="oj ok l"/></div></figure><p id="1f4f" class="pw-post-body-paragraph ms mt iq lp b lq nk jr mu ls nl ju mv la nm mx my le nn na nb li no nd ne lx ij bi translated">输出:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi ol"><img src="../Images/2c668f8c3a4bfab301b412eaa8c66b1b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1324/format:webp/1*Ll4rMotiPgs14_ubaPMiDA.png"/></div></figure><p id="610e" class="pw-post-body-paragraph ms mt iq lp b lq nk jr mu ls nl ju mv la nm mx my le nn na nb li no nd ne lx ij bi translated">找到输入图像的形状，然后将其整形为训练集和测试集的输入格式。之后，将所有数据类型转换成浮点数。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="oj ok l"/></div></figure><p id="2620" class="pw-post-body-paragraph ms mt iq lp b lq nk jr mu ls nl ju mv la nm mx my le nn na nb li no nd ne lx ij bi translated">通过将训练数据和测试数据除以 255 来标准化 0-1 之间的数据，然后使用<em class="om"> to_catagorical() </em>函数将所有标签转换为一个热点向量。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="oj ok l"/></div></figure><p id="014d" class="pw-post-body-paragraph ms mt iq lp b lq nk jr mu ls nl ju mv la nm mx my le nn na nb li no nd ne lx ij bi translated">使用一键编码显示类别标签的更改。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="oj ok l"/></div></figure><p id="b2a3" class="pw-post-body-paragraph ms mt iq lp b lq nk jr mu ls nl ju mv la nm mx my le nn na nb li no nd ne lx ij bi translated">输出:</p><pre class="kg kh ki kj gt nr ns nt nu aw nv bi"><span id="7846" class="kr ks iq ns b gy nw nx l ny nz">Original label 0 :  [6]<br/>After conversion to categorical ( one-hot ) :  <br/>[0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]</span></pre><p id="5319" class="pw-post-body-paragraph ms mt iq lp b lq nk jr mu ls nl ju mv la nm mx my le nn na nb li no nd ne lx ij bi translated">现在创建我们的模型。我们将添加卷积层，然后是池层。然后我们将连接密集(FC)层来预测类别。输入数据馈送到第一卷积层，该卷积层的输出充当下一卷积层的输入，依此类推。最后，数据被馈送到 FC 层，该层尝试预测正确的标签。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="oj ok l"/></div></figure><p id="39c2" class="pw-post-body-paragraph ms mt iq lp b lq nk jr mu ls nl ju mv la nm mx my le nn na nb li no nd ne lx ij bi translated">初始化所有参数并用 rmsprops 优化器编译我们的模型。有许多优化工具，例如 adam、SGD、GradientDescent、Adagrad、Adadelta 和 Adamax，请随意尝试。这里的批次是 256，包含 50 个纪元。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="oj ok l"/></div></figure><p id="e4d3" class="pw-post-body-paragraph ms mt iq lp b lq nk jr mu ls nl ju mv la nm mx my le nn na nb li no nd ne lx ij bi translated"><em class="om"> model.summary() </em>用于查看模型中各层的所有参数和形状。您可以看到，总参数为 276，138，总可训练参数为 276，138。不可训练参数为 0。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="oj ok l"/></div></figure><p id="d91a" class="pw-post-body-paragraph ms mt iq lp b lq nk jr mu ls nl ju mv la nm mx my le nn na nb li no nd ne lx ij bi translated">输出:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi on"><img src="../Images/da52d5207c290c05d6636965417bd81f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1148/format:webp/1*d5VQgxM1x42Q5g_c3WXCXg.png"/></div><figcaption class="ng nh gj gh gi ni nj bd b be z dk">Model Summary</figcaption></figure><p id="2d6a" class="pw-post-body-paragraph ms mt iq lp b lq nk jr mu ls nl ju mv la nm mx my le nn na nb li no nd ne lx ij bi translated">在编译我们的模型之后，我们将使用<em class="om"> fit() </em>方法训练我们的模型，然后对它进行评估。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="oj ok l"/></div></figure><p id="7d80" class="pw-post-body-paragraph ms mt iq lp b lq nk jr mu ls nl ju mv la nm mx my le nn na nb li no nd ne lx ij bi translated">输出:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi oo"><img src="../Images/560dd515977057b9a06f7fe9d0ddd84e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*W92nauZaGJyvScsou4N_IA.png"/></div></div></figure><p id="2c75" class="pw-post-body-paragraph ms mt iq lp b lq nk jr mu ls nl ju mv la nm mx my le nn na nb li no nd ne lx ij bi translated">经过训练，我们得到了 83.86%的准确率和 75.48%的验证准确率。其实一点也不差。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi op"><img src="../Images/38f746da27b54d1fc054fc81fda4ab0b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*wm4Q77KFHqlFNNJDPfs3Jg.png"/></div></div><figcaption class="ng nh gj gh gi ni nj bd b be z dk">Loss vs Epochs graph</figcaption></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi oq"><img src="../Images/4d10d84b80fe38c83b1d5d7849a44b07.png" data-original-src="https://miro.medium.com/v2/resize:fit:1392/format:webp/1*QYevfO6ll_naJiPX0EDxhA.png"/></div><figcaption class="ng nh gj gh gi ni nj bd b be z dk">Accuracy vs Epochs graph</figcaption></figure><h1 id="8b4b" class="mh ks iq bd kt mi mj mk kw ml mm mn kz jw mo jx ld jz mp ka lh kc mq kd ll mr bi translated">结论:</h1><p id="507e" class="pw-post-body-paragraph ms mt iq lp b lq lr jr mu ls lt ju mv la mw mx my le mz na nb li nc nd ne lx ij bi translated">恭喜你！你通过了解卷积神经网络的基本概念，在 Keras 中制作了卷积神经网络。你可以随意改变它的超参数，并在评论区告诉我。</p><p id="8454" class="pw-post-body-paragraph ms mt iq lp b lq nk jr mu ls nl ju mv la nm mx my le nn na nb li no nd ne lx ij bi translated"><a class="ae oh" href="https://github.com/dshahid380/CIFAR-10" rel="noopener ugc nofollow" target="_blank"> <strong class="lp ir"> <em class="om">你可以在我的 Github 里找到所有代码</em> </strong> </a></p><h2 id="9b6f" class="kr ks iq bd kt ku kv dn kw kx ky dp kz la lb lc ld le lf lg lh li lj lk ll lm bi translated">参考资料:</h2><ol class=""><li id="f5ce" class="ln lo iq lp b lq lr ls lt la lu le lv li lw lx or lz ma mb bi translated"><a class="ae oh" href="http://cs231n.github.io/convolutional-networks/" rel="noopener ugc nofollow" target="_blank"> CS231n 卷积神经网络</a></li><li id="001c" class="ln lo iq lp b lq mc ls md la me le mf li mg lx or lz ma mb bi translated"><a class="ae oh" href="https://keras.io/" rel="noopener ugc nofollow" target="_blank"> Keras 文档</a></li><li id="e653" class="ln lo iq lp b lq mc ls md la me le mf li mg lx or lz ma mb bi translated"><a class="ae oh" href="https://medium.com/deep-learning-turkey/deep-learning-lab-episode-2-cifar-10-631aea84f11e" rel="noopener">深度学习实验室</a></li><li id="d374" class="ln lo iq lp b lq mc ls md la me le mf li mg lx or lz ma mb bi translated">关于卷积神经网络的 deeplearning.ai 课程</li></ol></div></div>    
</body>
</html>