<html>
<head>
<title>London Design Festival (Part 3): Computer Vision</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">伦敦设计节(第三部分):计算机视觉</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/london-design-festival-part-3-computer-vision-36eed9667da4?source=collection_archive---------24-----------------------#2019-01-16">https://towardsdatascience.com/london-design-festival-part-3-computer-vision-36eed9667da4?source=collection_archive---------24-----------------------#2019-01-16</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="cfe0" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">第三部分:用计算机视觉分析推特上的 3K 图片</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/5cfe51a657e35cdf14fb8efad43c0e1b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*0phh3tGKQipV_6OsahQr4Q.png"/></div></div></figure><h2 id="744e" class="ku kv it bd kw kx ky dn kz la lb dp lc ld le lf lg lh li lj lk ll lm ln lo lp bi translated">介绍</h2><p id="068a" class="pw-post-body-paragraph lq lr it ls b lt lu ju lv lw lx jx ly ld lz ma mb lh mc md me ll mf mg mh mi im bi translated">在这一系列的最后一篇博文中，我应用计算机视觉技术来理解 3300 幅关于 2018 年伦敦设计节的图像，这是一个为期七天的设计节，于 2018 年 9 月 15 日至 23 日举行。</p><p id="72a0" class="pw-post-body-paragraph lq lr it ls b lt mj ju lv lw mk jx ly ld ml ma mb lh mm md me ll mn mg mh mi im bi translated">伦敦设计节 2018 (LDF18)有一个非常活跃的活动计划，横跨伦敦 11 个不同的“设计区”、5 个“设计目的地”和 3 条“设计路线”。这是伦敦作为一个建筑环境的灵活性的另一个极好的例子，作为一个画布来展示创造性的想法。</p><p id="b815" class="pw-post-body-paragraph lq lr it ls b lt mj ju lv lw mk jx ly ld ml ma mb lh mm md me ll mn mg mh mi im bi translated">在本系列的<a class="ae mo" rel="noopener" target="_blank" href="/london-design-festival-2018-part-2-natural-language-processing-595f3c2dc24f?source=friends_link&amp;sk=23ff5746ca0810a255e2023e52ebd450">第二部分</a>和<a class="ae mo" rel="noopener" target="_blank" href="/analyzing-the-london-design-festival-2018-part-1-7edac3bfb165?source=friends_link&amp;sk=5cbb7a0f8ad17446129f3be1a54b4c85">第一部分</a>中，我展示了自然语言处理和对 11000 条关于这个节日的推文的探索性数据分析。然而，这些推文中只有 3300 条有媒体数据(图像)，所以这篇文章的目的是使用计算机视觉分析来理解和语境化我从 Twitter 上传的这些图像。</p><p id="f09a" class="pw-post-body-paragraph lq lr it ls b lt mj ju lv lw mk jx ly ld ml ma mb lh mm md me ll mn mg mh mi im bi translated">请向下滚动查看分析！</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi mp"><img src="../Images/53c2dfe35ff194c8a46d385c274de15e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1280/format:webp/1*jdUaw7XPO4Iqyg7aEntYeg.jpeg"/></div><figcaption class="mq mr gj gh gi ms mt bd b be z dk">An image of LDF18 at the V&amp;A Museum. Source: Flickr</figcaption></figure><h2 id="fdf5" class="ku kv it bd kw kx ky dn kz la lb dp lc ld le lf lg lh li lj lk ll lm ln lo lp bi translated">数据和方法</h2><p id="de4b" class="pw-post-body-paragraph lq lr it ls b lt lu ju lv lw lx jx ly ld lz ma mb lh mc md me ll mf mg mh mi im bi translated">使用 Twitter API，我收集了包含标签<strong class="ls iu"> #LDF18 </strong>的关于 LDF18 的推文。总共有 11，000 条推文，但只有 3，300 条推文有媒体数据(图片)。<a class="ae mo" rel="noopener" target="_blank" href="/london-design-festival-2018-part-2-natural-language-processing-595f3c2dc24f?source=friends_link&amp;sk=23ff5746ca0810a255e2023e52ebd450">阅读第 2 部分了解更多</a>。</p><p id="ba0b" class="pw-post-body-paragraph lq lr it ls b lt mj ju lv lw mk jx ly ld ml ma mb lh mm md me ll mn mg mh mi im bi translated">然后，使用<a class="ae mo" href="https://cloud.google.com/vision/docs/" rel="noopener ugc nofollow" target="_blank">谷歌云的视觉 API </a>提取每张图像的标签。云视觉 API 利用“谷歌庞大的机器学习专业知识网络”(g <a class="ae mo" href="https://medium.com/@srobtweets/exploring-the-cloud-vision-api-1af9bcf080b8" rel="noopener"> reat 文章</a>作者<a class="mu mv ep" href="https://medium.com/u/7f2ab73b39f8?source=post_page-----36eed9667da4--------------------------------" rel="noopener" target="_blank"> Sara Robinson </a>)来检测图像的特征和标签。总共有 1045 个不同的标签被赋予了 3300 张图片。</p><p id="3c2c" class="pw-post-body-paragraph lq lr it ls b lt mj ju lv lw mk jx ly ld ml ma mb lh mm md me ll mn mg mh mi im bi translated">被称为<strong class="ls iu">特征提取</strong>和<strong class="ls iu">反向图像搜索</strong>的机器学习技术然后使用<a class="ae mo" href="http://ml4a.github.io/ml4a/" rel="noopener ugc nofollow" target="_blank">基因科岗的代码</a>完成，以基于视觉相似性找到图像。首先，使用预训练的卷积神经网络来提取每幅图像的“特征”，然后，计算这些特征的<a class="ae mo" href="https://en.wikipedia.org/wiki/Cosine_similarity" rel="noopener ugc nofollow" target="_blank">余弦相似度</a>，以“搜索”与查询图像相似的少量图像。</p><p id="6bf6" class="pw-post-body-paragraph lq lr it ls b lt mj ju lv lw mk jx ly ld ml ma mb lh mm md me ll mn mg mh mi im bi translated">特征在计算机视觉中的主要作用是“<a class="ae mo" href="https://medium.com/machine-learning-world/feature-extraction-and-similar-image-search-with-opencv-for-newbies-3c59796bf774" rel="noopener">将视觉信息转换到向量空间</a>”。相似的图像应该产生相似的特征，我们可以利用这些特征进行信息检索。基于这些特征，我们还可以使用一种叫做 t-SNE 的方法通过相似性对图像进行聚类。</p><h2 id="fcaa" class="ku kv it bd kw kx ky dn kz la lb dp lc ld le lf lg lh li lj lk ll lm ln lo lp bi translated">图像分析</h2><p id="6674" class="pw-post-body-paragraph lq lr it ls b lt lu ju lv lw lx jx ly ld lz ma mb lh mc md me ll mf mg mh mi im bi translated">在这一节中，我将展示我的计算机视觉分析的结果。下面，我报告以下三个指标:</p><ol class=""><li id="8a5e" class="mw mx it ls b lt mj lw mk ld my lh mz ll na mi nb nc nd ne bi translated">图像的标签检测；</li><li id="41aa" class="mw mx it ls b lt nf lw ng ld nh lh ni ll nj mi nb nc nd ne bi translated">基于视觉相似性的图像搜索:</li><li id="78eb" class="mw mx it ls b lt nf lw ng ld nh lh ni ll nj mi nb nc nd ne bi translated">基于视觉相似性的图像聚类。</li></ol><h2 id="4240" class="ku kv it bd kw kx ky dn kz la lb dp lc ld le lf lg lh li lj lk ll lm ln lo lp bi translated">标签检测</h2><p id="fde4" class="pw-post-body-paragraph lq lr it ls b lt lu ju lv lw lx jx ly ld lz ma mb lh mc md me ll mf mg mh mi im bi translated">每张照片的标签都是使用<a class="ae mo" href="https://cloud.google.com/vision/" rel="noopener ugc nofollow" target="_blank">谷歌云视觉 API </a>生成的。这背后的想法是将图片分类，这样我就可以识别相似的图片。下面的条形图显示了 3，300 张图片的前 10 个标签。</p><p id="4740" class="pw-post-body-paragraph lq lr it ls b lt mj ju lv lw mk jx ly ld ml ma mb lh mm md me ll mn mg mh mi im bi translated">我们看到“产品”、“字体”、“家具”、“桌子”、“设计”出现的次数最多。这些标签是有意义的，因为这是一个设计节！这是一个好消息，它证明了 Cloud Vision API 在标记关于设计节的图像方面做得很好。</p><p id="93cf" class="pw-post-body-paragraph lq lr it ls b lt mj ju lv lw mk jx ly ld ml ma mb lh mm md me ll mn mg mh mi im bi translated">然而，这些标签并没有明确描述艺术品本身——我对更详细的上下文理解感兴趣——这凸显了一些标签检测技术的缺点。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nk nl l"/></div></figure><h2 id="6202" class="ku kv it bd kw kx ky dn kz la lb dp lc ld le lf lg lh li lj lk ll lm ln lo lp bi translated">图像搜索—视觉相似性</h2><p id="fca5" class="pw-post-body-paragraph lq lr it ls b lt lu ju lv lw lx jx ly ld lz ma mb lh mc md me ll mf mg mh mi im bi translated">我们可以通过编程让计算机学习图像之间的视觉相似性，而不是使用标签来理解图像。一种叫做<strong class="ls iu">特征提取</strong>和<strong class="ls iu">反向图像搜索</strong>的技术就是这样做的。</p><p id="7d53" class="pw-post-body-paragraph lq lr it ls b lt mj ju lv lw mk jx ly ld ml ma mb lh mm md me ll mn mg mh mi im bi translated">使用在<a class="ae mo" href="https://www.tensorflow.org/guide/keras" rel="noopener ugc nofollow" target="_blank"> TensorFlow 后端</a>上运行的<a class="ae mo" href="https://keras.io/applications/#vgg16" rel="noopener ugc nofollow" target="_blank"> Keras VGG16 </a>神经网络模型，我首先为数据集中的每张图像提取了一个特征。一个特征是每个图像的 4096 元素的数字数组。我们的期望是“该特征形成图像的非常好的表示，使得相似的图像将具有相似的特征”(<a class="ae mo" href="http://ml4a.github.io/ml4a/convnets/" rel="noopener ugc nofollow" target="_blank">吉恩·科岗，2018 </a>)。</p><p id="0136" class="pw-post-body-paragraph lq lr it ls b lt mj ju lv lw mk jx ly ld ml ma mb lh mm md me ll mn mg mh mi im bi translated">然后使用主成分分析(PCA)降低特征的维度，以创建一个<a class="ae mo" href="https://developers.google.com/machine-learning/crash-course/embeddings/video-lecture" rel="noopener ugc nofollow" target="_blank">嵌入</a>，然后计算一个图像的 PCA 嵌入到另一个图像的距离<a class="ae mo" href="https://en.wikipedia.org/wiki/Cosine_similarity" rel="noopener ugc nofollow" target="_blank">余弦距离</a>。我终于能够向计算机发送随机查询图像，它选择并返回数据集中具有相似特征向量的五个其他图像。</p><p id="8576" class="pw-post-body-paragraph lq lr it ls b lt mj ju lv lw mk jx ly ld ml ma mb lh mm md me ll mn mg mh mi im bi translated">下面是三个例子:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nm"><img src="../Images/17cc9a39b47b56fe81db0c4540b28397.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*oNJ7RhTqmvKPcRlk0rmXvQ@2x.png"/></div></div><figcaption class="mq mr gj gh gi ms mt bd b be z dk">A reverse image search for Dazzle by Pentagram and 14–18 NOW at LDF18</figcaption></figure><div class="kj kk kl km gt ab cb"><figure class="nn kn no np nq nr ns paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><img src="../Images/6e3ec3adf5e265ec01ded31b5c1fae76.png" data-original-src="https://miro.medium.com/v2/resize:fit:1002/format:webp/1*vZCFXAqCao-Ew3VWXgFjWg@2x.png"/></div></figure><figure class="nn kn no np nq nr ns paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><img src="../Images/650a988808e506bba17e7d95677ff195.png" data-original-src="https://miro.medium.com/v2/resize:fit:1002/format:webp/1*OrFlSchym3dHPQnBuGtn_w@2x.png"/></div><figcaption class="mq mr gj gh gi ms mt bd b be z dk nt di nu nv">A reverse image search for The Onion Farm by Henrik Vibskov and Full Spectrum by Flynn Talbot at LDF18</figcaption></figure></div><p id="688b" class="pw-post-body-paragraph lq lr it ls b lt mj ju lv lw mk jx ly ld ml ma mb lh mm md me ll mn mg mh mi im bi translated">当试图从一个包含许多图片的相册中找到相似的图片时，这种技术非常有用，事实上我就是这么做的！</p><h2 id="f09d" class="ku kv it bd kw kx ky dn kz la lb dp lc ld le lf lg lh li lj lk ll lm ln lo lp bi translated">图像聚类—相似性</h2><p id="842d" class="pw-post-body-paragraph lq lr it ls b lt lu ju lv lw lx jx ly ld lz ma mb lh mc md me ll mf mg mh mi im bi translated">既然我们在向量空间中嵌入了每个图像，我们可以使用一种流行的叫做 t-SNE 的机器学习可视化算法来聚类，然后在二维空间中可视化向量空间。</p><blockquote class="nw"><p id="9de2" class="nx ny it bd nz oa ob oc od oe of mi dk translated">“tSNE 的目标是聚集相似数据点的小“邻域”,同时减少数据的整体维度，以便更容易可视化”(谷歌人工智能博客，2018 年)</p></blockquote><p id="9785" class="pw-post-body-paragraph lq lr it ls b lt og ju lv lw oh jx ly ld oi ma mb lh oj md me ll ok mg mh mi im bi translated">下面我们看到基于视觉相似性的聚类形成。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nm"><img src="../Images/39720580cf370da57fdb1810ed35451a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*JCChl9HHKkKnf2NjKqX65g@2x.png"/></div></div></figure><p id="707b" class="pw-post-body-paragraph lq lr it ls b lt mj ju lv lw mk jx ly ld ml ma mb lh mm md me ll mn mg mh mi im bi translated">在下面的图片中，我突出了三件艺术品——沃·西斯尔顿建筑师的<em class="ol">乘</em>、Es Devlin 的<em class="ol">请喂狮子</em>和五角星的<em class="ol">炫</em>——以及它们的集群轮廓。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi om"><img src="../Images/b55efdfa25b9e3a955d7910957a1039c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*94Ci5dw_YeD0aR0JBXxstQ@2x.png"/></div></div><figcaption class="mq mr gj gh gi ms mt bd b be z dk">The clustering of images of three art installations at LDF18. Source: Twitter</figcaption></figure><h2 id="08c2" class="ku kv it bd kw kx ky dn kz la lb dp lc ld le lf lg lh li lj lk ll lm ln lo lp bi translated"><strong class="ak">结论</strong></h2><p id="a7f4" class="pw-post-body-paragraph lq lr it ls b lt lu ju lv lw lx jx ly ld lz ma mb lh mc md me ll mf mg mh mi im bi translated">所以你有它！我只是刚刚涉足计算机视觉的奇妙世界。还有很多东西需要我去学习，但这对我来说是很好的第一步。</p><p id="f4f3" class="pw-post-body-paragraph lq lr it ls b lt mj ju lv lw mk jx ly ld ml ma mb lh mm md me ll mn mg mh mi im bi translated">我的发现表明，使用机器学习和计算机视觉技术来理解和联系关于 LDF18 的图像是可能的。</p><p id="c72c" class="pw-post-body-paragraph lq lr it ls b lt mj ju lv lw mk jx ly ld ml ma mb lh mm md me ll mn mg mh mi im bi translated">对我来说，下一步显然是计算在数据集中出现了多少艺术装置，以衡量“受欢迎程度”。我将继续研究这个数据集。</p><h2 id="3516" class="ku kv it bd kw kx ky dn kz la lb dp lc ld le lf lg lh li lj lk ll lm ln lo lp bi translated">结束了</h2><p id="b3b2" class="pw-post-body-paragraph lq lr it ls b lt lu ju lv lw lx jx ly ld lz ma mb lh mc md me ll mf mg mh mi im bi translated">这是我关于 LDF18 的博客系列的结尾！这个系列是我正在进行的关于使用数据科学来理解和衡量城市文化影响的长期讨论的一部分。</p><p id="43c2" class="pw-post-body-paragraph lq lr it ls b lt mj ju lv lw mk jx ly ld ml ma mb lh mm md me ll mn mg mh mi im bi translated">今年，我将开始新的项目，主要是 JavaScript。敬请期待！</p><p id="a77e" class="pw-post-body-paragraph lq lr it ls b lt mj ju lv lw mk jx ly ld ml ma mb lh mm md me ll mn mg mh mi im bi translated">感谢阅读！</p><p id="17b6" class="pw-post-body-paragraph lq lr it ls b lt mj ju lv lw mk jx ly ld ml ma mb lh mm md me ll mn mg mh mi im bi translated">Vishal</p><p id="a950" class="pw-post-body-paragraph lq lr it ls b lt mj ju lv lw mk jx ly ld ml ma mb lh mm md me ll mn mg mh mi im bi translated"><a class="ae mo" href="https://vishalkumar.london/" rel="noopener ugc nofollow" target="_blank"> <em class="ol"> Vishal </em> </a> <em class="ol">是伦敦 UCL</em><a class="ae mo" href="https://www.ucl.ac.uk/bartlett/" rel="noopener ugc nofollow" target="_blank"><em class="ol">The Bartlett</em></a><em class="ol">的文化数据科学家和研究生。他对城市文化的经济和社会影响感兴趣。</em></p></div></div>    
</body>
</html>