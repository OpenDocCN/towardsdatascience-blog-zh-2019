<html>
<head>
<title>Autonomous Truck Simulator with PyTorch — finetuning and single shot detectors</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">带 PyTorch 的自动卡车模拟器——微调和单发探测器</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/autonomous-truck-simulator-with-pytorch-3695dfc05555?source=collection_archive---------32-----------------------#2019-10-09">https://towardsdatascience.com/autonomous-truck-simulator-with-pytorch-3695dfc05555?source=collection_archive---------32-----------------------#2019-10-09</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><p id="d7fc" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">这是上一篇<a class="ae ko" href="https://medium.com/datadriveninvestor/how-i-developed-an-in-game-self-driving-vehicle-using-fast-ai-and-american-truck-simulator-2524891dbaf" rel="noopener">文章</a>的延续，在上一篇文章中，我做了如何使用 fast.ai 构建自动卡车模拟器的完整演练，但最终这些方法可以在任何需要微调预训练模型或开发预测边界框和类的模型的情况下工作。</p><p id="de22" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">现在，我的目标是浏览训练和推理过程的一些更技术性的方面，并解释它们如何在 PyTorch 中实现的细节。也可以参考<a class="ae ko" href="https://github.com/jchaykow/trucksim" rel="noopener ugc nofollow" target="_blank">本 Github repo </a>中的代码库。</p><p id="633e" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">回想一下上一篇文章，这里有两个神经网络在工作。</p><ol class=""><li id="4f87" class="kp kq it js b jt ju jx jy kb kr kf ks kj kt kn ku kv kw kx bi translated">DNN 预测转向方向。</li><li id="23dc" class="kp kq it js b jt ky jx kz kb la kf lb kj lc kn ku kv kw kx bi translated">预测汽车、人等的边界框和类别的 DNN。</li></ol><h1 id="2e39" class="ld le it bd lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma bi translated">微调转向模型</h1><p id="f1ae" class="pw-post-body-paragraph jq jr it js b jt mb jv jw jx mc jz ka kb md kd ke kf me kh ki kj mf kl km kn im bi translated">这两个网络都是从一个预先训练好的 resnet34 网络开始，并针对适当的任务进行微调。</p><p id="f932" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">可从<code class="fe mg mh mi mj b">torchvision.models</code>获得预训练结果 34</p><pre class="mk ml mm mn gt mo mj mp mq aw mr bi"><span id="e88c" class="ms le it mj b gy mt mu l mv mw"><strong class="mj iu">import</strong> torchvision.models <strong class="mj iu">as</strong> models</span><span id="eda5" class="ms le it mj b gy mx mu l mv mw">arch = models.resnet34(pretrained=<strong class="mj iu">True</strong>)</span></pre><p id="7f32" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">所有预训练的模型都已经在 1000 类 Imagenet 数据集上进行了预训练。</p><p id="02a1" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">为了微调预训练的网络，我们基本上只是从一堆权重开始，这些权重已经嵌入了许多关于 Imagenet 数据集的信息。所以我们可以用两种方法之一。一种方法是通过设置<code class="fe mg mh mi mj b">requires_grad=<strong class="js iu">False</strong></code>来冻结所有早期层，然后只为最终层设置<code class="fe mg mh mi mj b">requires_grad=<strong class="js iu">True</strong></code> <strong class="js iu"> </strong>。另一种方法是只使用所有的权重作为初始化，并在新的训练数据上继续训练。</p><p id="5824" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">对于选项 1，我们冻结早期层并仅训练最终层，我们可以为所有层设置<code class="fe mg mh mi mj b">requires_grad=<strong class="js iu">False</strong></code> <strong class="js iu"> </strong>，然后移除并替换最后的层(无论何时将层分配给网络，它都会自动将<code class="fe mg mh mi mj b">requires_grad</code>属性设置为<strong class="js iu">真</strong>)。</p><pre class="mk ml mm mn gt mo mj mp mq aw mr bi"><span id="14ac" class="ms le it mj b gy mt mu l mv mw"><strong class="mj iu">class</strong> Flatten(nn.Module):<br/>    <strong class="mj iu">def</strong> __init__(self):<br/>        super(Flatten, self).__init__()</span><span id="49d7" class="ms le it mj b gy mx mu l mv mw"><strong class="mj iu">def</strong> forward(self, x):<br/>        x = x.view(x.size(0), -1)<br/>        <strong class="mj iu">return</strong> x</span><span id="737e" class="ms le it mj b gy mx mu l mv mw"><strong class="mj iu">class</strong> normalize(nn.Module):<br/>    <strong class="mj iu">def</strong> __init__(self):<br/>        super(normalize, self).__init__()</span><span id="1df8" class="ms le it mj b gy mx mu l mv mw"><strong class="mj iu">def</strong> forward(self, x):<br/>        x = F.normalize(x, p=2, dim=1)<br/>        <strong class="mj iu">return</strong> x</span><span id="d77d" class="ms le it mj b gy mx mu l mv mw">layer_list = list(arch.children())[-2:]<br/>arch = nn.Sequential(<strong class="mj iu">*</strong>list(arch.children())[:-2])<br/>arch.avgpool = nn.AdaptiveAvgPool2d(output_size=(1,1))<br/>arch.fc = nn.Sequential(<br/>    Flatten(),<br/>    nn.Linear(in_features=layer_list[1].in_features, <br/>              out_features=3, <br/>              bias=<strong class="mj iu">True</strong>),<br/>    normalize()<br/>)<br/>arch = arch.to(device)</span></pre><p id="6838" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">如果你观察 resnet34 的架构，你可以看到最后一个 conv 模块后面是一个<code class="fe mg mh mi mj b">AdaptiveAvgPool2d</code>和一个<code class="fe mg mh mi mj b">Linear</code>层。</p><pre class="mk ml mm mn gt mo mj mp mq aw mr bi"><span id="e18a" class="ms le it mj b gy mt mu l mv mw">(2): BasicBlock(<br/>      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=<strong class="mj iu">False</strong>)<br/>      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=nn.Sequential, track_running_stats=<strong class="mj iu">True</strong>)<br/>      (relu): ReLU(inplace=<strong class="mj iu">True</strong>)<br/>      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=<strong class="mj iu">False</strong>)<br/>      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=<strong class="mj iu">True</strong>)<br/>    )<br/>  )<br/>  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))<br/>  (fc): Linear(in_features=512, out_features=1000, bias=<strong class="mj iu">True</strong>)<br/>)</span></pre><p id="f4cc" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">我们可以用<code class="fe mg mh mi mj b">nn.Sequential(<strong class="js iu">*</strong>list(arch.children())[:-2])</code>去掉最后两层，然后用<code class="fe mg mh mi mj b">arch.avgpool = nn.AdaptiveAvgPool2d(output_size=(1,1))</code>和另一个带有<code class="fe mg mh mi mj b">Flatten</code>、<code class="fe mg mh mi mj b">Linear</code>和<code class="fe mg mh mi mj b">normalize</code>层的<code class="fe mg mh mi mj b">nn.Sequential</code>把它们重新连接到末端。我们最终想要预测 3 个类别:左、右、直——所以我们的<code class="fe mg mh mi mj b">out_features</code>将是 3。</p><p id="b358" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">现在，我们将为方向模型创建数据集和数据加载器。由于我们的数据只是图像和类[左，右，直]，我们可以只使用内置的 torch dataset 类，但我喜欢使用自定义类，因为我可以更容易地看到数据是如何提取的。</p><pre class="mk ml mm mn gt mo mj mp mq aw mr bi"><span id="8daf" class="ms le it mj b gy mt mu l mv mw"><strong class="mj iu">class</strong> DirectionsDataset(Dataset):<br/>    """Directions dataset."""<br/>    <strong class="mj iu">def</strong> __init__(self, csv_file, root_dir, transform=None):<br/>        """<br/>        Args:<br/>            csv_file (string): Path to the csv file with labels.<br/>            root_dir (string): Directory with all the images.<br/>            transform (callable, optional): Optional transform<br/>        """<br/>        self.label = pd.read_csv(csv_file)<br/>        self.root_dir = root_dir<br/>        self.transform = transform</span><span id="1c36" class="ms le it mj b gy mx mu l mv mw">    <strong class="mj iu">def</strong> __len__(self):<br/>        <strong class="mj iu">return</strong> len(self.label)</span><span id="86f4" class="ms le it mj b gy mx mu l mv mw">    <strong class="mj iu">def</strong> __getitem__(self, idx):<br/>        img_name = os.path.join(self.root_dir,<br/>                                self.label.iloc[idx, 0])<br/>        image = io.imread(img_name+'.jpg')<br/>        sample = image<br/>        label = self.label.iloc[idx, 1]</span><span id="e5b5" class="ms le it mj b gy mx mu l mv mw">        if self.transform:<br/>            sample = self.transform(sample)</span><span id="8cab" class="ms le it mj b gy mx mu l mv mw">        <strong class="mj iu">return</strong> sample, label</span></pre><p id="529f" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">我在 csv 文件中的图像名称没有扩展名，因此没有<code class="fe mg mh mi mj b">img_name+’.jpg’</code>。</p><pre class="mk ml mm mn gt mo mj mp mq aw mr bi"><span id="a5eb" class="ms le it mj b gy mt mu l mv mw">tensor_dataset = DirectionsDataset(csv_file='data/labels_directions.csv',<br/>                  root_dir='data/train3/',<br/>                  transform=transforms.Compose([<br/>                                transforms.ToTensor(),<br/>                                transforms.Normalize(<br/>                  (0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]))</span><span id="dd65" class="ms le it mj b gy mx mu l mv mw">dataloader = DataLoader(tensor_dataset, batch_size=16, shuffle=<strong class="mj iu">True</strong>)</span></pre><p id="c10a" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">所以我们准备开始训练模型。</p><pre class="mk ml mm mn gt mo mj mp mq aw mr bi"><span id="b6bf" class="ms le it mj b gy mt mu l mv mw"><strong class="mj iu">def</strong> train_model(model, criterion, optimizer, scheduler, <br/>                dataloader, num_epochs=25):<br/>    since = time.time()<br/>    FT_losses = []</span><span id="412f" class="ms le it mj b gy mx mu l mv mw">    best_model_wts = copy.deepcopy(model.state_dict())<br/>    best_acc = 0.0<br/>    iters = 0</span><span id="1140" class="ms le it mj b gy mx mu l mv mw">    <strong class="mj iu">for</strong> epoch <strong class="mj iu">in</strong> range(num_epochs):<br/>        <strong class="mj iu">print</strong>('Epoch {}/{}'.format(epoch, num_epochs - 1))<br/>        <strong class="mj iu">print</strong>('-' * 10)</span><span id="ef3a" class="ms le it mj b gy mx mu l mv mw">        scheduler.step()<br/>        model.train()  # Set model to training mode</span><span id="44e9" class="ms le it mj b gy mx mu l mv mw">        running_loss = 0.0<br/>        running_corrects = 0</span><span id="4fd7" class="ms le it mj b gy mx mu l mv mw">        # Iterate over data.<br/>        <strong class="mj iu">for</strong> i, (inputs, labels) <strong class="mj iu">in</strong> enumerate(dataloader):<br/>            #set_trace()<br/>            inputs = inputs.to(device)<br/>            labels = labels.to(device)</span><span id="2a81" class="ms le it mj b gy mx mu l mv mw">            # zero the parameter gradients<br/>            optimizer.zero_grad()</span><span id="800e" class="ms le it mj b gy mx mu l mv mw">            # forward<br/>            # track history if only in train<br/>            model.eval()   # Set model to evaluate mode<br/>            <strong class="mj iu">with</strong> torch.no_grad():<br/>                outputs = model(inputs)<br/>                #set_trace()<br/>                _, preds = torch.max(outputs, 1)<br/>            <br/>            outputs = model(inputs)<br/>            loss = criterion(outputs, labels)</span><span id="44ad" class="ms le it mj b gy mx mu l mv mw">            # backward + optimize only if in training phase<br/>            loss.backward()<br/>            optimizer.step()</span><span id="41db" class="ms le it mj b gy mx mu l mv mw">            FT_losses.append(loss.item())<br/>            # statistics<br/>            running_loss += loss.item() * inputs.size(0)<br/>            running_corrects += torch.sum(preds == labels.data)<br/>            #set_trace()<br/>            iters += 1<br/>            <br/>            if iters % 2 == 0:<br/>                 <strong class="mj iu">print</strong>('Prev Loss: {:.4f} Prev Acc: {:.4f}'.format(<br/>                     loss.item(), torch.sum(preds == labels.data) / inputs.size(0)))</span><span id="843a" class="ms le it mj b gy mx mu l mv mw">        epoch_loss = running_loss / dataset_size<br/>        epoch_acc = running_corrects.double() / dataset_size</span><span id="1c52" class="ms le it mj b gy mx mu l mv mw">        print('Loss: {:.4f} Acc: {:.4f}'.format(<br/>            epoch_loss, epoch_acc))</span><span id="e99f" class="ms le it mj b gy mx mu l mv mw">        # deep copy the model<br/>        if epoch_acc &gt; best_acc:<br/>            best_acc = epoch_acc<br/>            best_model_wts = copy.deepcopy(model.state_dict())</span><span id="3e2d" class="ms le it mj b gy mx mu l mv mw">    time_elapsed = time.time() - since<br/>    <strong class="mj iu">print</strong>('Training complete in {:.0f}m {:.0f}s'.format(<br/>        time_elapsed // 60, time_elapsed % 60))<br/>    <strong class="mj iu">print</strong>('Best val Acc: {:4f}'.format(best_acc))</span><span id="418f" class="ms le it mj b gy mx mu l mv mw">    # load best model weights<br/>    model.load_state_dict(best_model_wts)<br/>    <strong class="mj iu">return</strong> model, FT_losses</span></pre><p id="0dbc" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">在这个训练循环中，如果历元精度是迄今为止最好的，我们可以跟踪最佳模型权重。我们还可以跟踪每次迭代和每个时期的损失，并在结束时返回，以绘制并查看调试或演示的效果。</p><p id="9ce7" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">请记住，该模型在每次迭代时都被训练，如果您停止训练循环，它将保留那些权重，只需再次运行<code class="fe mg mh mi mj b">train_model()</code>命令，训练就可以再次继续。要从头开始，请返回并使用预训练的架构重新初始化权重。</p><pre class="mk ml mm mn gt mo mj mp mq aw mr bi"><span id="bf97" class="ms le it mj b gy mt mu l mv mw">criterion = nn.CrossEntropyLoss()<br/># Observe that all parameters are being optimized<br/>optimizer_ft = optim.SGD(arch.parameters(), lr=1e-2, momentum=0.9)<br/># Decay LR by a factor of *gamma* every *step_size* epochs<br/>exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)</span><span id="2268" class="ms le it mj b gy mx mu l mv mw">arch, FT_losses = train_model(arch, criterion, optimizer_ft, exp_lr_scheduler, dataloader, num_epochs=5)</span></pre><h1 id="676d" class="ld le it bd lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma bi translated">微调边界框模型</h1><figure class="mk ml mm mn gt mz gh gi paragraph-image"><div role="button" tabindex="0" class="na nb di nc bf nd"><div class="gh gi my"><img src="../Images/944ce43268abab97b9211be9a63e801d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*7k7RzbKbJLg1v6FiEZ9WvQ.png"/></div></div><figcaption class="ng nh gj gh gi ni nj bd b be z dk">sample data</figcaption></figure><p id="2c1d" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">同样，我们将使用预训练的 resnet34 架构。然而，这一次我们将不得不对它进行更多的编辑，以输出类预测和边界框值。此外，这是一个多类预测问题，因此可能有 1 个边界框，也可能有 15 个类。</p><p id="7a86" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">我们将为该架构创建一个<em class="nk">自定义 head </em>，其方式与我们替换方向模型中的层的方式类似。</p><pre class="mk ml mm mn gt mo mj mp mq aw mr bi"><span id="e602" class="ms le it mj b gy mt mu l mv mw"><strong class="mj iu">class</strong> StdConv(nn.Module):<br/>    <strong class="mj iu">def</strong> __init__(self, nin, nout, stride=2, drop=0.1):<br/>        super().__init__()<br/>        self.conv = nn.Conv2d(nin, nout, 3, stride=stride, padding=1)<br/>        self.bn = nn.BatchNorm2d(nout)<br/>        self.drop = nn.Dropout(drop)<br/>        <br/>    <strong class="mj iu">def</strong> forward(self, x): <br/>        <strong class="mj iu">return</strong> self.drop(self.bn(F.relu(self.conv(x))))<br/>        <br/><strong class="mj iu">def</strong> flatten_conv(x,k):<br/>    bs,nf,gx,gy = x.size()<br/>    x = x.permute(0,2,3,1).contiguous()<br/>    <strong class="mj iu">return</strong> x.view(bs,-1,nf//k)</span><span id="54ec" class="ms le it mj b gy mx mu l mv mw"><strong class="mj iu">class</strong> OutConv(nn.Module):<br/>    <strong class="mj iu">def</strong> __init__(self, k, nin, bias):<br/>        super().__init__()<br/>        self.k = k<br/>        self.oconv1 = nn.Conv2d(nin, (len(id2cat)+1)*k, 3, padding=1)<br/>        self.oconv2 = nn.Conv2d(nin, 4*k, 3, padding=1)<br/>        self.oconv1.bias.data.zero_().add_(bias)<br/>        <br/>    <strong class="mj iu">def</strong> forward(self, x):<br/>        <strong class="mj iu">return</strong> [flatten_conv(self.oconv1(x), self.k),<br/>                flatten_conv(self.oconv2(x), self.k)]</span><span id="7f6c" class="ms le it mj b gy mx mu l mv mw">drop=0.4</span><span id="dc4a" class="ms le it mj b gy mx mu l mv mw"><strong class="mj iu">class</strong> SSD_MultiHead(nn.Module):<br/>    <strong class="mj iu">def</strong> __init__(self, k, bias):<br/>        super().__init__()<br/>        self.drop = nn.Dropout(drop)<br/>        self.sconv0 = StdConv(512,256, stride=1, drop=drop)<br/>        self.sconv1 = StdConv(256,256, drop=drop)<br/>        self.sconv2 = StdConv(256,256, drop=drop)<br/>        self.sconv3 = StdConv(256,256, drop=drop)<br/>        self.out0 = OutConv(k, 256, bias)<br/>        self.out1 = OutConv(k, 256, bias)<br/>        self.out2 = OutConv(k, 256, bias)<br/>        self.out3 = OutConv(k, 256, bias)</span><span id="ba87" class="ms le it mj b gy mx mu l mv mw">    <strong class="mj iu">def</strong> forward(self, x):<br/>        x = self.drop(F.relu(x))<br/>        x = self.sconv0(x)<br/>        x = self.sconv1(x)<br/>        o1c,o1l = self.out1(x)<br/>        x = self.sconv2(x)<br/>        o2c,o2l = self.out2(x)<br/>        x = self.sconv3(x)<br/>        o3c,o3l = self.out3(x)<br/>        <strong class="mj iu">return</strong> [torch.cat([o1c,o2c,o3c], dim=1),<br/>                torch.cat([o1l,o2l,o3l], dim=1)]</span></pre><p id="c2cf" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">因此，现在我们希望将这个自定义头连接到 resnet34 架构，我们有一个方便的函数来完成这项工作。</p><pre class="mk ml mm mn gt mo mj mp mq aw mr bi"><span id="562a" class="ms le it mj b gy mt mu l mv mw"><strong class="mj iu">class</strong> ConvnetBuilder():<br/>    <strong class="mj iu">def</strong> __init__(self, f, c, is_multi, is_reg, ps=<strong class="mj iu">None</strong>,<br/>                 xtra_fc=<strong class="mj iu">None</strong>, xtra_cut=0, <br/>                 custom_head=<strong class="mj iu">None</strong>,pretrained=<strong class="mj iu">True</strong>):<br/>        self.f,self.c,self.is_multi,self.is_reg,self.xtra_cut = f,c,is_multi,is_reg,xtra_cut<br/>        xtra_fc = [512]<br/>        ps = [0.25]*len(xtra_fc) + [0.5]<br/>        self.ps,self.xtra_fc = ps,xtra_fc</span><span id="81c7" class="ms le it mj b gy mx mu l mv mw">        cut,self.lr_cut = [8,6] # specific to resnet_34 arch<br/>        cut-=xtra_cut<br/>        layers = cut_model(f(pretrained), cut)<br/>        self.nf = num_features(layers)*2<br/>        self.top_model = nn.Sequential(*layers)</span><span id="ed57" class="ms le it mj b gy mx mu l mv mw">        n_fc = len(self.xtra_fc)+1<br/>        self.ps = [self.ps]*n_fc</span><span id="410c" class="ms le it mj b gy mx mu l mv mw">        fc_layers = [custom_head]<br/>        self.n_fc = len(fc_layers)<br/>        self.fc_model = nn.Sequential(*fc_layers).to(device)<br/>        self.model = nn.Sequential(*(layers+fc_layers)).to(device)</span><span id="2067" class="ms le it mj b gy mx mu l mv mw"><strong class="mj iu">def</strong> cut_model(m, cut):<br/>    <strong class="mj iu">return</strong> list(m.children())[:cut] if cut else [m]</span><span id="3536" class="ms le it mj b gy mx mu l mv mw"><strong class="mj iu">def</strong> num_features(m):<br/>    c=children(m)<br/>    if len(c)==0: return None<br/>    for l in reversed(c):<br/>        if hasattr(l, 'num_features'): return l.num_features<br/>        res = num_features(l)<br/>        if res is not None: return res</span><span id="221f" class="ms le it mj b gy mx mu l mv mw"><strong class="mj iu">def</strong> children(m): <strong class="mj iu">return</strong> m <strong class="mj iu">if</strong> isinstance(m, (list, tuple)) <strong class="mj iu">else</strong> list(m.children())</span></pre><p id="75b7" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">使用这个<code class="fe mg mh mi mj b">ConvnetBuilder</code>类，我们可以将自定义头和 resnet34 架构结合起来。</p><pre class="mk ml mm mn gt mo mj mp mq aw mr bi"><span id="ff03" class="ms le it mj b gy mt mu l mv mw">k = len(anchor_scales)<br/>head_reg4 = SSD_MultiHead(k, -4.)<br/>f_model = models.resnet34<br/>modelss = ConvnetBuilder(f_model, 0, 0, 0, custom_head=head_reg4)</span></pre><p id="a091" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><code class="fe mg mh mi mj b">k</code>是 9</p><p id="d6e5" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">我们现在可以通过<code class="fe mg mh mi mj b">modelss</code>上的<code class="fe mg mh mi mj b">model</code>属性访问模型。</p><p id="156e" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">损失函数必须能够接受分类(类)和连续值(边界框),并输出单个损失值。</p><pre class="mk ml mm mn gt mo mj mp mq aw mr bi"><span id="b3b2" class="ms le it mj b gy mt mu l mv mw"><strong class="mj iu">def</strong> ssd_loss(pred,targ,print_it=<strong class="mj iu">False</strong>):<br/>    lcs,lls = 0.,0.<br/>    <strong class="mj iu">for</strong> b_c,b_bb,bbox,clas <strong class="mj iu">in</strong> zip(*pred,*targ):<br/>        loc_loss,clas_loss = ssd_1_loss(b_c,b_bb,bbox,clas,print_it)<br/>        lls += loc_loss<br/>        lcs += clas_loss<br/>    <strong class="mj iu">if</strong> print_it: <br/>        <strong class="mj iu">print</strong>(f'loc: {lls.data.item()}, clas: {lcs.data.item()}')<br/>    <strong class="mj iu">return</strong> lls+lcs</span><span id="7186" class="ms le it mj b gy mx mu l mv mw"><strong class="mj iu">def</strong> ssd_1_loss(b_c,b_bb,bbox,clas,print_it=<strong class="mj iu">False</strong>):<br/>    bbox,clas = get_y(bbox,clas)<br/>    a_ic = actn_to_bb(b_bb, anchors)<br/>    overlaps = jaccard(bbox.data, anchor_cnr.data)<br/>    gt_overlap,gt_idx = map_to_ground_truth(overlaps,print_it)<br/>    gt_clas = clas[gt_idx]<br/>    pos = gt_overlap &gt; 0.4<br/>    pos_idx = torch.nonzero(pos)[:,0]<br/>    gt_clas[1-pos] = len(id2cat)<br/>    gt_bbox = bbox[gt_idx]<br/>    loc_loss = ((a_ic[pos_idx] - gt_bbox[pos_idx]).abs()).mean()<br/>    clas_loss  = loss_f(b_c, gt_clas)<br/>    <strong class="mj iu">return</strong> loc_loss, clas_loss</span><span id="1010" class="ms le it mj b gy mx mu l mv mw"><strong class="mj iu">def</strong> one_hot_embedding(labels, num_classes):<br/>    <strong class="mj iu">return</strong> torch.eye(num_classes)[labels.data.long().cpu()]</span><span id="d692" class="ms le it mj b gy mx mu l mv mw"><strong class="mj iu">class</strong> BCE_Loss(nn.Module):<br/>    <strong class="mj iu">def</strong> __init__(self, num_classes):<br/>        super().__init__()<br/>        self.num_classes = num_classes</span><span id="4480" class="ms le it mj b gy mx mu l mv mw"><strong class="mj iu">def</strong> forward(self, pred, targ):<br/>        t = one_hot_embedding(targ, self.num_classes+1)<br/>        t = V(t[:,:-1].contiguous()).cpu()<br/>        x = pred[:,:-1]<br/>        w = self.get_weight(x,t)<br/>        <strong class="mj iu">return</strong> F.binary_cross_entropy_with_logits(x, t, w, size_average=False)/self.num_classes<br/>    <br/>    <strong class="mj iu">def</strong> get_weight(self,x,t): <strong class="mj iu">return</strong> None</span><span id="bb1a" class="ms le it mj b gy mx mu l mv mw">loss_f = BCE_Loss(len(id2cat))</span><span id="60c0" class="ms le it mj b gy mx mu l mv mw"><strong class="mj iu">def</strong> get_y(bbox,clas):<br/>    bbox = bbox.view(-1,4)/sz<br/>    bb_keep = ((bbox[:,2]-bbox[:,0])&gt;0).nonzero()[:,0]<br/>    <strong class="mj iu">return</strong> bbox[bb_keep],clas[bb_keep]</span><span id="51af" class="ms le it mj b gy mx mu l mv mw"><strong class="mj iu">def</strong> actn_to_bb(actn, anchors):<br/>    actn_bbs = torch.tanh(actn)<br/>    actn_centers = (actn_bbs[:,:2]/2 * grid_sizes) + anchors[:,:2]<br/>    actn_hw = (actn_bbs[:,2:]/2+1) * anchors[:,2:]<br/>    <strong class="mj iu">return</strong> hw2corners(actn_centers, actn_hw)</span><span id="8410" class="ms le it mj b gy mx mu l mv mw"><strong class="mj iu">def</strong> intersect(box_a, box_b):<br/>    max_xy = torch.min(box_a[:, None, 2:], box_b[<strong class="mj iu">None</strong>, :, 2:])<br/>    min_xy = torch.max(box_a[:, None, :2], box_b[<strong class="mj iu">None</strong>, :, :2])<br/>    inter = torch.clamp((max_xy - min_xy), min=0)<br/>    <strong class="mj iu">return</strong> inter[:, :, 0] * inter[:, :, 1]</span><span id="6c2e" class="ms le it mj b gy mx mu l mv mw"><strong class="mj iu">def</strong> box_sz(b): <strong class="mj iu">return</strong> ((b[:, 2]-b[:, 0]) * (b[:, 3]-b[:, 1]))</span><span id="3c4a" class="ms le it mj b gy mx mu l mv mw"><strong class="mj iu">def</strong> jaccard(box_a, box_b):<br/>    inter = intersect(box_a, box_b)<br/>    union = box_sz(box_a).unsqueeze(1) + box_sz(box_b).unsqueeze(0) - inter<br/>    <strong class="mj iu">return</strong> inter / union</span></pre><p id="1d46" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">一旦设置了数据集和数据加载器，我们就可以在 bbox 模型的批处理输出中测试损失函数。</p><p id="76c3" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">这里我们实际上需要一个定制的数据集类来处理这些数据类型。</p><pre class="mk ml mm mn gt mo mj mp mq aw mr bi"><span id="16c4" class="ms le it mj b gy mt mu l mv mw"><strong class="mj iu">class</strong> BboxDataset(Dataset):<br/>    """Bbox dataset."""<br/>    <strong class="mj iu">def</strong> __init__(self, csv_file, root_dir, transform=<strong class="mj iu">None</strong>):<br/>        """<br/>        Args:<br/>            csv_file (string): Path to csv file with bounding boxes.<br/>            root_dir (string): Directory with all the images.<br/>            transform (callable, optional): Optional transform.<br/>        """<br/>        self.label = pd.read_csv(csv_file)<br/>        self.root_dir = root_dir<br/>        self.transform = transform<br/>        self.sz = 224</span><span id="a79a" class="ms le it mj b gy mx mu l mv mw">    <strong class="mj iu">def</strong> __len__(self):<br/>        <strong class="mj iu">return</strong> len(self.label)</span><span id="1402" class="ms le it mj b gy mx mu l mv mw">    <strong class="mj iu">def</strong> __getitem__(self, idx):<br/>        img_name = os.path.join(self.root_dir,<br/>                                self.label.iloc[idx, 0])<br/>        image = io.imread(img_name)<br/>        sample = image<br/>        <br/>        h, w = sample.shape[:2]; new_h, new_w = (224,224)<br/>        bb = np.array([float(x) <strong class="mj iu">for</strong> x <strong class="mj iu">in</strong> self.label.iloc[idx, 1].split(' ')], dtype=np.float32)<br/>        bb = np.reshape(bb, (int(bb.shape[0]/2),2))<br/>        bb = bb * [new_h / h, new_w / w]<br/>        bb = bb.flatten()<br/>        bb = T(np.concatenate((np.zeros((189*4) - len(bb)), bb), axis=None)) # 189 is 21 * 9 where 9 = k</span><span id="41ae" class="ms le it mj b gy mx mu l mv mw">        <strong class="mj iu">if</strong> self.transform:<br/>            sample = self.transform(sample)</span><span id="ed6e" class="ms le it mj b gy mx mu l mv mw">        <strong class="mj iu">return</strong> sample, bb</span></pre><figure class="mk ml mm mn gt mz gh gi paragraph-image"><div role="button" tabindex="0" class="na nb di nc bf nd"><div class="gh gi nl"><img src="../Images/b24d3b32b111a8d69016c839fa93343c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*vILh1w0CNrjlFc0IXQT7Jw.png"/></div></div><figcaption class="ng nh gj gh gi ni nj bd b be z dk">mbb.csv</figcaption></figure><p id="34c5" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">这个自定义的数据集类处理边界框，但是我们想要一个既处理类又处理边界框的数据集类。</p><pre class="mk ml mm mn gt mo mj mp mq aw mr bi"><span id="f697" class="ms le it mj b gy mt mu l mv mw">bb_dataset = BboxDataset(csv_file='data/pascal/tmp/mbb.csv',<br/>             root_dir='data/pascal/VOCdevkit2/VOC2007/JPEGImages/',<br/>             transform=transforms.Compose([<br/>                       transforms.ToPILImage(),<br/>                       transforms.Resize((224,224)),<br/>                       transforms.ToTensor(),<br/>                       transforms.Normalize(<br/>             (0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]))</span><span id="6daa" class="ms le it mj b gy mx mu l mv mw">bb_dataloader = DataLoader(bb_dataset, batch_size=16, shuffle=<strong class="mj iu">True</strong>)</span></pre><p id="a483" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">在这里，我们可以连接两个数据集类，这样每个图像的类和边界框都会被返回。</p><pre class="mk ml mm mn gt mo mj mp mq aw mr bi"><span id="c974" class="ms le it mj b gy mt mu l mv mw"><strong class="mj iu">class</strong> ConcatLblDataset(Dataset):<br/>    <strong class="mj iu">def</strong> __init__(self, ds, y2):<br/>        self.ds,self.y2 = ds,y2<br/>        self.sz = ds.sz<br/>    <strong class="mj iu">def</strong> __len__(self): <strong class="mj iu">return</strong> len(self.ds)<br/>    <br/>    <strong class="mj iu">def</strong> __getitem__(self, i):<br/>        self.y2[i] = np.concatenate((np.zeros(189 - len(self.y2[i])), self.y2[i]), axis=None)<br/>        x,y = self.ds[i]<br/>        <strong class="mj iu">return</strong> (x, (y,self.y2[i]))</span><span id="7e8d" class="ms le it mj b gy mx mu l mv mw">trn_ds2 = ConcatLblDataset(bb_dataset, mcs)</span></pre><p id="ca06" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">其中<code class="fe mg mh mi mj b">mcs</code>是具有每个训练图像的类的数组的 numpy 数组。</p><pre class="mk ml mm mn gt mo mj mp mq aw mr bi"><span id="2162" class="ms le it mj b gy mt mu l mv mw">PATH_pascal = Path('data/pascal')<br/>trn_j = json.load((PATH_pascal / 'pascal_train2007.json').open())<br/>cats = dict((o['id'], o['name']) <strong class="mj iu">for</strong> o <strong class="mj iu">in</strong> trn_j['categories'])</span><span id="3478" class="ms le it mj b gy mx mu l mv mw">mc = [[cats[p[1]] <strong class="mj iu">for</strong> p <strong class="mj iu">in</strong> trn_anno[o]] <strong class="mj iu">for</strong> o <strong class="mj iu">in</strong> trn_ids]<br/>id2cat = list(cats.values())<br/>cat2id = {v:k for k,v in enumerate(id2cat)}<br/>mcs = np.array([np.array([cat2id[p] <strong class="mj iu">for</strong> p <strong class="mj iu">in</strong> o]) <strong class="mj iu">for</strong> o <strong class="mj iu">in</strong> mc])</span></pre><p id="75af" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">现在我们可以测试我们的客户损失。</p><pre class="mk ml mm mn gt mo mj mp mq aw mr bi"><span id="ba10" class="ms le it mj b gy mt mu l mv mw">sz=224<br/>x,y = <strong class="mj iu">next</strong>(<strong class="mj iu">iter</strong>(bb_dataloader2))</span><span id="6daf" class="ms le it mj b gy mx mu l mv mw">batch = modelss.model(x)</span><span id="5a41" class="ms le it mj b gy mx mu l mv mw">ssd_loss(batch, y, <strong class="mj iu">True</strong>)</span><span id="75ec" class="ms le it mj b gy mx mu l mv mw">tensor([0.6254])<br/>tensor([0.6821, 0.7257, 0.4922])<br/>tensor([0.9563])<br/>tensor([0.6522, 0.5276, 0.6226])<br/>tensor([0.6811, 0.3338])<br/>tensor([0.7008])<br/>tensor([0.5316, 0.2926])<br/>tensor([0.9422])<br/>tensor([0.5487, 0.7187, 0.3620, 0.1578])<br/>tensor([0.6546, 0.3753, 0.4231, 0.4663, 0.2125, 0.0729])<br/>tensor([0.3756, 0.5085])<br/>tensor([0.2304, 0.1390, 0.0853])<br/>tensor([0.2484])<br/>tensor([0.6419])<br/>tensor([0.5954, 0.5375, 0.5552])<br/>tensor([0.2383])<br/>loc: 1.844399333000183, clas: 79.79206085205078</span></pre><p id="762f" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu">出动【1024】:</strong></p><pre class="mk ml mm mn gt mo mj mp mq aw mr bi"><span id="18f5" class="ms le it mj b gy mt mu l mv mw">tensor(81.6365, grad_fn=&lt;AddBackward0&gt;)</span></pre><p id="db00" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">现在来训练 ssd 模型。</p><pre class="mk ml mm mn gt mo mj mp mq aw mr bi"><span id="1d1b" class="ms le it mj b gy mt mu l mv mw">beta1 = 0.5<br/>optimizer = optim.Adam(modelss.model.parameters(), lr=1e-3, betas=(beta1, 0.99))<br/># Decay LR by a factor of *gamma* every *step_size* epochs<br/>exp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)</span></pre><p id="5d64" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">我们可以像以前一样使用基本相同的<code class="fe mg mh mi mj b">train_model()</code>函数，但是这一次我们将一个边界框和类的列表传递给损失函数<code class="fe mg mh mi mj b">ssd_loss()</code>。</p><p id="d81c" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">现在，我们已经在新的训练数据集上训练了我们的两个模型，我们准备在我们的卡车模拟器游戏中使用它们进行推理。</p><p id="c38d" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">我鼓励您查看这个 Github repo 来了解完整的实现，您可以在其中训练模型、记录训练数据并在视频游戏上测试实现。</p><p id="8e13" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">玩得开心！</p></div></div>    
</body>
</html>