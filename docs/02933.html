<html>
<head>
<title>Machine Learning in the Browser: Train and Serve a Mobilenet Model for Custom Image Classification</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">浏览器中的机器学习:为自定义图像分类训练和服务 Mobilenet 模型</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/training-custom-image-classification-model-on-the-browser-with-tensorflow-js-and-angular-f1796ed24934?source=collection_archive---------19-----------------------#2019-05-12">https://towardsdatascience.com/training-custom-image-classification-model-on-the-browser-with-tensorflow-js-and-angular-f1796ed24934?source=collection_archive---------19-----------------------#2019-05-12</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><figure class="gl gn jr js jt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi jq"><img src="../Images/6b5830bf7cc1a9528ddfc9923b8364ed.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*pE8aHxC6Hex5W-pl"/></div></div><figcaption class="kb kc gj gh gi kd ke bd b be z dk">Photo by <a class="ae kf" href="https://unsplash.com/@louishansel?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Louis Hansel</a> on <a class="ae kf" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><h1 id="90fe" class="kg kh it bd ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld bi translated">Tensorflow.js</h1><p id="95d8" class="pw-post-body-paragraph le lf it lg b lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">有几种方法可以微调深度学习模型，但在 web 浏览器上使用 WebGL 加速是我们不久前经历的事情，引入了<a class="ae kf" href="https://www.tensorflow.org/js" rel="noopener ugc nofollow" target="_blank"> Tensorflow.js </a>。我将使用 Tensorflow.js 与<a class="ae kf" href="https://angular.io/" rel="noopener ugc nofollow" target="_blank"> Angular </a>一起构建一个 Web 应用程序，该应用程序在<a class="ae kf" href="https://arxiv.org/abs/1704.04861" rel="noopener ugc nofollow" target="_blank"> Mobilenet </a>和<a class="ae kf" href="https://www.kaggle.com/iarunava/cell-images-for-detecting-malaria" rel="noopener ugc nofollow" target="_blank"> Kaggle 数据集</a>的帮助下训练卷积神经网络来检测疟疾感染的细胞，该数据集包含 27.558 个感染和未感染的细胞图像。</p><h1 id="513a" class="kg kh it bd ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld bi translated">演示 WebApp</h1><p id="0782" class="pw-post-body-paragraph le lf it lg b lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">访问<a class="ae kf" href="https://tfjs-customimageclassification.web.app/" rel="noopener ugc nofollow" target="_blank">现场演示应用程序</a>查看运行中的代码。该应用程序在 Google Chrome 浏览器中运行没有任何问题。</p><p id="63e0" class="pw-post-body-paragraph le lf it lg b lh mc lj lk ll md ln lo lp me lr ls lt mf lv lw lx mg lz ma mb im bi translated">访问我的<a class="ae kf" href="https://github.com/eisbilen/TFJS-CustomImageClassification" rel="noopener ugc nofollow" target="_blank"> GitHub repositor </a> y 获取该项目的完整代码。您可以在此存储库的<a class="ae kf" href="https://github.com/eisbilen/TFJS-CustomImageClassification/tree/master/assets" rel="noopener ugc nofollow" target="_blank">资产文件夹中找到图像，以及将图像加载到浏览器所需的</a><a class="ae kf" href="https://github.com/eisbilen/TFJS-CustomImageClassification/tree/master/assets" rel="noopener ugc nofollow" target="_blank"> CSV 文件</a>。您应该解压缩这些图像，并将它们放入您正在处理的 Angular 项目的 assets 文件夹中。</p><h1 id="3d91" class="kg kh it bd ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld bi translated">作为基础模型的 Mobilenet</h1><p id="025e" class="pw-post-body-paragraph le lf it lg b lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">正如我上面提到的，我将使用“mobilenet”作为自定义图像分类器的基础模型。预训练的“mobilenet”模型，兼容 tensorflow.js，相对较小(20MB)，可以直接从<a class="ae kf" href="https://storage.googleapis.com/tfjs-models/tfjs/mobilenet_v1_0.25_224/model.json" rel="noopener ugc nofollow" target="_blank"> Google API 存储文件夹</a>下载。</p><p id="8bd9" class="pw-post-body-paragraph le lf it lg b lh mc lj lk ll md ln lo lp me lr ls lt mf lv lw lx mg lz ma mb im bi translated">未感染和寄生细胞，这是我想用我们的定制模型分类的两个类别，而原始的“mobilenet”模型被训练来分类 1000 个不同的对象。</p><p id="e9f3" class="pw-post-body-paragraph le lf it lg b lh mc lj lk ll md ln lo lp me lr ls lt mf lv lw lx mg lz ma mb im bi translated">我将使用除最后 5 层之外的所有“mobilenet”层，并在这个截断模型的顶部添加一个具有 2 个单元和 softmax 激活的密集层，以使修改后的模型适合我们的分类任务。</p><p id="f1b9" class="pw-post-body-paragraph le lf it lg b lh mc lj lk ll md ln lo lp me lr ls lt mf lv lw lx mg lz ma mb im bi translated">我不会训练所有的层，因为这将需要大量的时间和计算能力。这对于我们的情况也是不必要的，因为我们使用预先训练的模型，该模型已经学习了许多表示。相反，我将冻结大多数层，只保留最后 2 层可训练。</p><h1 id="77c1" class="kg kh it bd ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld bi translated">疟疾细胞图像的预处理</h1><p id="66e9" class="pw-post-body-paragraph le lf it lg b lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">在开始编码之前，我们必须考虑如何在训练期间将图像输入到我们的定制模型中。mobilenet 模型需要特定的图像大小(224x224x3)和图像预处理操作，我们必须对图像应用相同的预处理，然后才能将它们提供给我们的模型。此外，为了不使我们的模型偏向一个类，我们必须在训练时期为每个类提供相同数量的图像。</p><figure class="mi mj mk ml gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi mh"><img src="../Images/a1e1e9ee407e6b9226917a1a1a410fda.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*ETR5hnMEZ9p6gT7S"/></div></div><figcaption class="kb kc gj gh gi kd ke bd b be z dk">Photo by <a class="ae kf" href="https://unsplash.com/@pawel_czerwinski?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Paweł Czerwiński</a> on <a class="ae kf" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure></div><div class="ab cl mm mn hx mo" role="separator"><span class="mp bw bk mq mr ms"/><span class="mp bw bk mq mr ms"/><span class="mp bw bk mq mr"/></div><div class="im in io ip iq"><h1 id="06e6" class="kg kh it bd ki kj mt kl km kn mu kp kq kr mv kt ku kv mw kx ky kz mx lb lc ld bi translated">Angular WebApp 正在初始化</h1><p id="7559" class="pw-post-body-paragraph le lf it lg b lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">在我们清楚了模型和数据集之后，是时候使用 Angular 命令行界面来初始化<a class="ae kf" href="https://angular.io" rel="noopener ugc nofollow" target="_blank"> Angular </a> web 应用程序了。</p><pre class="mi mj mk ml gt my mz na nb aw nc bi"><span id="5116" class="nd kh it mz b gy ne nf l ng nh">npm install -g @angular/cli<br/>ng new TFJS-CustomImageClassification<br/>cd TFJS-CustomImageClassification</span></pre><p id="6927" class="pw-post-body-paragraph le lf it lg b lh mc lj lk ll md ln lo lp me lr ls lt mf lv lw lx mg lz ma mb im bi translated">然后我会使用' nmp '包管理器来安装 tensorflow.js 库。为了完善 web 应用程序，我将使用<a class="ae kf" href="https://material.angular.io/" rel="noopener ugc nofollow" target="_blank">角状材料</a>类。</p><pre class="mi mj mk ml gt my mz na nb aw nc bi"><span id="f02e" class="nd kh it mz b gy ne nf l ng nh">TFJS-CustomImageClassification <strong class="mz iu">npm install @tensorflow/tfjs --save<br/></strong>TFJS-CustomImageClassification <strong class="mz iu">ng add @angular/material</strong></span></pre><h1 id="4610" class="kg kh it bd ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld bi translated">生成基于自定义 Mobilenet 的模型</h1><p id="c7a4" class="pw-post-body-paragraph le lf it lg b lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">首先，让我们开始编码，生成一个函数来修改预训练的模型，以便我们可以使用这个修改后的模型来完成我们的特定任务，即对感染疟疾的图像进行分类。由于我不想从头开始训练模型，我将冻结所有层，除了我需要重新训练微调模型的层。</p><pre class="mi mj mk ml gt my mz na nb aw nc bi"><span id="23ae" class="nd kh it mz b gy ne nf l ng nh">//-------------------------------------------------------------<br/>// modifies the pre-trained mobilenet to detect malaria infected<br/>// cells, freezes layers to train only the last couple of layers<br/>//-------------------------------------------------------------<br/>async getModifiedMobilenet()<br/>{<br/> <em class="ni">const</em> trainableLayers=     ['denseModified','conv_pw_13_bn','conv_pw_13','conv_dw_13_bn','conv _dw_13'];<br/> <em class="ni">const</em> mobilenet =  await<br/> tf.loadLayersModel('https://storage.googleapis.com/tfjs- models/tfjs/mobilenet_v1_0.25_224/model.json');</span><span id="2150" class="nd kh it mz b gy nj nf l ng nh"><em class="ni">console</em>.log('Mobilenet model is loaded')<br/> <em class="ni">const</em> x=mobilenet.getLayer('global_average_pooling2d_1');<br/> <em class="ni">const</em> predictions= &lt;tf.SymbolicTensor&gt; tf.layers.dense({units: 2,  activation: 'softmax',name: 'denseModified'}).apply(x.output); <br/> <em class="ni">let</em> mobilenetModified = tf.model({inputs: mobilenet.input, outputs:  predictions, name: 'modelModified' });<br/> <em class="ni">console</em>.log('Mobilenet model is modified')</span><span id="cf26" class="nd kh it mz b gy nj nf l ng nh">mobilenetModified =<br/> this.freezeModelLayers(trainableLayers,mobilenetModified)<br/> <em class="ni">console</em>.log('ModifiedMobilenet model layers are freezed')</span><span id="87fb" class="nd kh it mz b gy nj nf l ng nh">mobilenetModified.compile({loss: categoricalCrossentropy,  optimizer: tf.train.adam(1e-3), metrics:   ['accuracy','crossentropy']});</span><span id="2bf3" class="nd kh it mz b gy nj nf l ng nh">mobilenet.dispose();<br/> x.dispose();<br/> return mobilenetModified<br/>}<br/>//-------------------------------------------------------------<br/>// freezes mobilenet layers to make them untrainable<br/>// just keeps final layers trainable with argument trainableLayers<br/>//-------------------------------------------------------------freezeModelLayers(<em class="ni">trainableLayers</em>,<em class="ni">mobilenetModified</em>)<br/>{<br/> for (<em class="ni">const</em> layer of mobilenetModified.layers)<br/> {<br/>  layer.trainable = false;<br/>  for (<em class="ni">const</em> tobeTrained of trainableLayers)<br/>  {<br/>    if (layer.name.indexOf(tobeTrained) === 0)<br/>     {<br/>      layer.trainable = true;<br/>      break;<br/>     }<br/>   }<br/>  }<br/> return mobilenetModified;<br/>}</span></pre><figure class="mi mj mk ml gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi nk"><img src="../Images/e5040a048cf1faa15efcf1381e75b614.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*ogQrSjevSKGjhLqR"/></div></div><figcaption class="kb kc gj gh gi kd ke bd b be z dk">Photo by <a class="ae kf" href="https://unsplash.com/@heftiba?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Toa Heftiba</a> on <a class="ae kf" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><h1 id="dd3a" class="kg kh it bd ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld bi translated">准备培训数据</h1><p id="d774" class="pw-post-body-paragraph le lf it lg b lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">为了训练该模型，我们需要 224×224×3 形状张量和另一个包含 1，0 值的 1 维张量中的未感染和感染细胞图像来指示图像的类别。我要做的是读取包含图像 src 和类信息的 CSV 文件，然后生成 HTMLImageElement 以在浏览器中查看它们。Capture()函数然后将获取图像 id，以便从浏览器上的图像生成所需的图像张量。请注意，我们必须预处理图像张量，因为 mobilenet 需要标准化的输入。老实说，我在这里使用的数据管道并不是正确的方式，因为我是一次将整块图像数据加载到内存中。使用<a class="ae kf" href="https://js.tensorflow.org/api/latest/#tf.LayersModel.fitDataset" rel="noopener ugc nofollow" target="_blank"> <strong class="lg iu"> tf.fitDataset </strong> </a>并在需要时迭代使用内存会好得多。</p><pre class="mi mj mk ml gt my mz na nb aw nc bi"><span id="e956" class="nd kh it mz b gy ne nf l ng nh">//-------------------------------------------------------------<br/>// this function generate input and target tensors for the training<br/>// input tensor is produced from 224x224x3 image in HTMLImageElement<br/>// target tensor shape2 is produced from the class definition<br/>//-------------------------------------------------------------<br/>generateData (<em class="ni">trainData</em>,<em class="ni">batchSize</em>)<br/>{<br/>  <em class="ni">const</em> imageTensors = [];<br/>  <em class="ni">const</em> targetTensors = [];</span><span id="cb5d" class="nd kh it mz b gy nj nf l ng nh"><em class="ni">let</em> allTextLines = this.csvContent.split(/\r|\n|\r/);<br/>  <em class="ni">const</em> csvSeparator = ',';<br/>  <em class="ni">const</em> csvSeparator_2 = '.';</span><span id="08d1" class="nd kh it mz b gy nj nf l ng nh">for ( <em class="ni">let</em> i = 0; i &lt; batchSize; i++)<br/>  {<br/>    // split content based on comma<br/>    <em class="ni">const</em> cols: <em class="ni">string</em>[] = allTextLines[i].split(csvSeparator);<br/>    <em class="ni">console</em>.log(cols[0].split(csvSeparator_2)[0])</span><span id="0e54" class="nd kh it mz b gy nj nf l ng nh">if (cols[0].split(csvSeparator_2)[1]=="png")<br/>    {<br/>     <em class="ni">const</em> imageTensor = this.capture(i);<br/>      <em class="ni">let</em> targetTensor   =tf.tensor1d([this.label_x1[i],this.label_x2[i]]);<br/>      targetTensor.print();<br/>      imageTensors.push(imageTensor);<br/>      targetTensors.push(targetTensor);<br/>    }<br/>  }<br/>  <em class="ni">const</em> images = tf.stack(imageTensors);<br/>  <em class="ni">const</em> targets = tf.stack(targetTensors);<br/>  return {images, targets};<br/>}<br/>//-------------------------------------------------------------<br/>// converts images in HTMLImageElement into the tensors<br/>// takes Image Id in HTML as argument<br/>//-------------------------------------------------------------<br/>capture(<em class="ni">imgId</em>)<br/>{<br/>  // Reads the image as a Tensor from the &lt;image&gt; element.<br/>  this.picture = &lt;HTMLImageElement&gt; document.getElementById(imgId);<br/>  <em class="ni">const</em> trainImage = tf.browser.fromPixels(this.picture);<br/>  // Normalize the image between -1 and 1. The image comes in  between  0-255, so we divide by 127 and subtract 1.<br/>  <em class="ni">const</em> trainim =  trainImage.toFloat().div(tf.scalar(127)).sub(tf.scalar(1));<br/>  return trainim;<br/>}</span></pre><figure class="mi mj mk ml gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi nl"><img src="../Images/5e8b9f437bdd98c6ba2c09bf6b15ec6a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*2c5tTI_M-3-K-jNPCaDXBw.jpeg"/></div></div><figcaption class="kb kc gj gh gi kd ke bd b be z dk">Cell Images listed in Web App</figcaption></figure><h1 id="c1a8" class="kg kh it bd ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld bi translated">微调模型</h1><p id="d54f" class="pw-post-body-paragraph le lf it lg b lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">当我们准备好数据和模型时，现在是时候对模型进行微调，以便它可以对感染疟疾的细胞图像进行分类。为了减少训练过程的时间，我将总共使用 120 幅图像，5 个时期的训练过程，每个时期包含 24 幅图像。损失函数为'<a class="ae kf" href="https://gombru.github.io/2018/05/23/cross_entropy_loss/" rel="noopener ugc nofollow" target="_blank"> <strong class="lg iu">类别交叉熵</strong> </a> <strong class="lg iu"> ' </strong>和<strong class="lg iu">'一个</strong> <a class="ae kf" href="https://machinelearningmastery.com/adam-optimization-algorithm-for-deep-learning/" rel="noopener ugc nofollow" target="_blank"> <strong class="lg iu">坝优化器</strong> </a> <strong class="lg iu"> ' </strong>用于学习率值相对较小的训练。我使用<a class="ae kf" href="https://keras.io/" rel="noopener ugc nofollow" target="_blank"> <strong class="lg iu"> Keras </strong> </a>提供的“<a class="ae kf" href="https://keras.io/callbacks/" rel="noopener ugc nofollow" target="_blank"><strong class="lg iu">on batchend</strong></a><strong class="lg iu">”</strong>回调函数将每个历元的训练指标写入控制台。一旦训练完成，我们必须释放张量来释放内存。最后一步，我们将把训练好的模型保存到我们的本地存储器中，以便以后用于推理。</p><pre class="mi mj mk ml gt my mz na nb aw nc bi"><span id="9f51" class="nd kh it mz b gy ne nf l ng nh">async fineTuneModifiedModel(<em class="ni">model</em>,<em class="ni">images</em>,<em class="ni">targets</em>)<br/>{<br/>  <em class="ni">function</em> onBatchEnd(<em class="ni">batch</em>, <em class="ni">logs</em>)<br/>  {<br/>    <em class="ni">console</em>.log('Accuracy', logs.acc);<br/>    <em class="ni">console</em>.log('CrossEntropy', logs.ce);<br/>    <em class="ni">console</em>.log('All', logs);<br/>  }<br/>  <em class="ni">console</em>.log('Finetuning the model...');<br/>  <br/>  await model.fit(images, targets,<br/>  {<br/>    epochs: 5,<br/>    batchSize: 24,<br/>    validationSplit: 0.2,<br/>    callbacks: {onBatchEnd}<br/>    }).then(<em class="ni">info</em> <em class="ni">=&gt;</em> {<br/>    <em class="ni">console</em>.log<br/>    <em class="ni">console</em>.log('Final accuracy', info.history.acc);<br/>    <em class="ni">console</em>.log('Cross entropy', info.ce);<br/>    <em class="ni">console</em>.log('All', info);<br/>    <em class="ni">console</em>.log('All', info.history['acc'][0]);<br/>   <br/>    for ( <em class="ni">let</em> k = 0; k &lt; 5; k++)<br/>    {<br/>      this.traningMetrics.push({acc: 0, ce: 0 , loss: 0});<br/>      this.traningMetrics[k].acc=info.history['acc'][k];<br/>      this.traningMetrics[k].ce=info.history['ce'][k];<br/>      this.traningMetrics[k].loss=info.history['loss'][k];<br/>    }<br/>    images.dispose();<br/>    targets.dispose();<br/>    model.dispose();<br/>  });<br/>}</span></pre></div><div class="ab cl mm mn hx mo" role="separator"><span class="mp bw bk mq mr ms"/><span class="mp bw bk mq mr ms"/><span class="mp bw bk mq mr"/></div><div class="im in io ip iq"><figure class="mi mj mk ml gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi nm"><img src="../Images/4a2f379073f9e124eec18695d70ca668.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*IM9kEBcJ1On4wRQC"/></div></div><figcaption class="kb kc gj gh gi kd ke bd b be z dk">Photo by <a class="ae kf" href="https://unsplash.com/@vixenly?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Kym MacKinnon</a> on <a class="ae kf" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><h1 id="67c9" class="kg kh it bd ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld bi translated">完整代码</h1><p id="ecdf" class="pw-post-body-paragraph le lf it lg b lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">访问 my <a class="ae kf" href="https://github.com/eisbilen/TFJS-CustomImageClassification" rel="noopener ugc nofollow" target="_blank"> GitHub repositor </a> y 获取该项目的完整代码。您可以在这个存储库的<a class="ae kf" href="https://github.com/eisbilen/TFJS-CustomImageClassification/tree/master/assets" rel="noopener ugc nofollow" target="_blank"> assets 文件夹中找到图像，以及将图像加载到浏览器所需的</a><a class="ae kf" href="https://github.com/eisbilen/TFJS-CustomImageClassification/tree/master/assets" rel="noopener ugc nofollow" target="_blank"> CSV 文件</a>。您应该解压缩这些图像，并将它们放入您正在处理的 Angular 项目的 assets 文件夹中。</p><h1 id="8f4c" class="kg kh it bd ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld bi translated">演示 WebApp</h1><p id="c545" class="pw-post-body-paragraph le lf it lg b lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">访问<a class="ae kf" href="https://tfjs-customimageclassification.web.app/" rel="noopener ugc nofollow" target="_blank">现场演示应用</a>查看运行中的代码。该应用程序在 Google Chrome 浏览器中运行没有任何问题。</p></div></div>    
</body>
</html>