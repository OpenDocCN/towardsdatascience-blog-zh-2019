<html>
<head>
<title>A short journey of outlier detection</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">离群点检测的短暂旅程</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/a-short-journey-of-outlier-detection-bdf143464a92?source=collection_archive---------8-----------------------#2019-01-12">https://towardsdatascience.com/a-short-journey-of-outlier-detection-bdf143464a92?source=collection_archive---------8-----------------------#2019-01-12</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="74cd" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">查找异常值的几种方法的快速概述</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/e396458148e0997eb90d8e59e6b42231.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*K5nc0J2em_pB2o49CZ6VUA.jpeg"/></div></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk"><a class="ae ky" href="http://Source" rel="noopener ugc nofollow" target="_blank">Source</a>: Pexels by Pedro Figueras</figcaption></figure><h2 id="d9fa" class="kz la it bd lb lc ld dn le lf lg dp lh li lj lk ll lm ln lo lp lq lr ls lt lu bi translated"><strong class="ak">目录:</strong></h2><ul class=""><li id="3d37" class="lv lw it lx b ly lz ma mb li mc lm md lq me mf mg mh mi mj bi translated">目标</li><li id="b005" class="lv lw it lx b ly mk ma ml li mm lm mn lq mo mf mg mh mi mj bi translated">单变量异常值检测</li><li id="9ba7" class="lv lw it lx b ly mk ma ml li mm lm mn lq mo mf mg mh mi mj bi translated">线性回归模型的异常值检测</li></ul></div><div class="ab cl mp mq hx mr" role="separator"><span class="ms bw bk mt mu mv"/><span class="ms bw bk mt mu mv"/><span class="ms bw bk mt mu"/></div><div class="im in io ip iq"><h1 id="5396" class="mw la it bd lb mx my mz le na nb nc lh jz nd ka ll kc ne kd lp kf nf kg lt ng bi translated"><strong class="ak">目标</strong></h1><p id="7e03" class="pw-post-body-paragraph nh ni it lx b ly lz ju nj ma mb jx nk li nl nm nn lm no np nq lq nr ns nt mf im bi translated">根据我们工作的内容和当前使用的模型，有很多方法可以捕捉异常数据。当我们需要精确的统计数据和模型时，注意异常数据是至关重要的，因为这些数据，如异常值，会极大地影响均值、标准差和方差。在本文中，我们将体验三种类型的技术:</p><ul class=""><li id="e89f" class="lv lw it lx b ly nu ma nv li nw lm nx lq ny mf mg mh mi mj bi translated">对于带有<em class="nz"> Z-socre </em>和<em class="nz"> IQR </em>的单变量</li><li id="fdd3" class="lv lw it lx b ly mk ma ml li mm lm mn lq mo mf mg mh mi mj bi translated">对于带有简单<em class="nz">杠杆统计</em>、<em class="nz">库克距离</em>和<em class="nz"> DFFITS </em>的线性回归模型，以及</li><li id="c504" class="lv lw it lx b ly mk ma ml li mm lm mn lq mo mf mg mh mi mj bi translated">对于具有<em class="nz">稳健协方差</em>、<em class="nz">局部异常因子</em>和<em class="nz">隔离森林</em>的双变量和高维</li></ul><p id="1f47" class="pw-post-body-paragraph nh ni it lx b ly nu ju nj ma nv jx nk li oa nm nn lm ob np nq lq oc ns nt mf im bi translated">我们的主要目标是获得更深一层的理解，而不仅仅是通过阅读文章获得想法，并从实验中获得洞察力。我们还寻求实现它们的能力，这样我们就可以在需要时优化我们的算法，这样我们就可以在使用开源软件时处理意想不到的问题。</p></div><div class="ab cl mp mq hx mr" role="separator"><span class="ms bw bk mt mu mv"/><span class="ms bw bk mt mu mv"/><span class="ms bw bk mt mu"/></div><div class="im in io ip iq"><h1 id="b184" class="mw la it bd lb mx my mz le na nb nc lh jz nd ka ll kc ne kd lp kf nf kg lt ng bi translated">单变量</h1><p id="ccd8" class="pw-post-body-paragraph nh ni it lx b ly lz ju nj ma mb jx nk li nl nm nn lm no np nq lq nr ns nt mf im bi translated">在处理单变量时，我们的方法很简单。因为我们有高中的数学知识，我们已经知道如何处理异常值。</p><h2 id="a78b" class="kz la it bd lb lc ld dn le lf lg dp lh li lj lk ll lm ln lo lp lq lr ls lt lu bi translated">IQR</h2><p id="c9d1" class="pw-post-body-paragraph nh ni it lx b ly lz ju nj ma mb jx nk li nl nm nn lm no np nq lq nr ns nt mf im bi translated">第一种方法是 IOR(四分位间距)。设<strong class="lx iu"> <em class="nz"> X </em> </strong>为一元变量，一组值，s.t. <strong class="lx iu"> <em class="nz"> X </em> </strong> ={0，1，2，3，4，5，<strong class="lx iu"> <em class="nz"> 6 </em> </strong>，7，8，9，10，11，20}。用<strong class="lx iu"> <em class="nz"> X </em> </strong>，我们简单算一下 Q1、Q2、Q3。在这种情况下，Q1=3，Q2(中位数)=6，Q3=9，IQR 是 Q3-Q1=6。异常值定义为</p><p id="b28a" class="pw-post-body-paragraph nh ni it lx b ly nu ju nj ma nv jx nk li oa nm nn lm ob np nq lq oc ns nt mf im bi translated"><strong class="lx iu"> <em class="nz"> Q1-1.5*IQR </em> </strong>或<strong class="lx iu"> <em class="nz"> Q3+1.5*IQR </em> </strong>，</p><p id="11bf" class="pw-post-body-paragraph nh ni it lx b ly nu ju nj ma nv jx nk li oa nm nn lm ob np nq lq oc ns nt mf im bi translated">因此，在这种情况下，如果 a 值小于-6 或大于 18，则为异常值。在数据集<strong class="lx iu"> <em class="nz"> X </em> </strong>中，20 是离群值。</p><h2 id="6d03" class="kz la it bd lb lc ld dn le lf lg dp lh li lj lk ll lm ln lo lp lq lr ls lt lu bi translated"><strong class="ak"> Z 分数</strong></h2><p id="f3e0" class="pw-post-body-paragraph nh ni it lx b ly lz ju nj ma mb jx nk li nl nm nn lm no np nq lq nr ns nt mf im bi translated">使用 Z 分数来检测这种异常值也很简单。与 IQR 的不同之处在于首先将原始数据转换成 Z 值。z 分数定义为</p><p id="eada" class="pw-post-body-paragraph nh ni it lx b ly nu ju nj ma nv jx nk li oa nm nn lm ob np nq lq oc ns nt mf im bi translated"><strong class="lx iu"> <em class="nz"> z=(x-μ)/ </em> σ，</strong></p><p id="0cec" class="pw-post-body-paragraph nh ni it lx b ly nu ju nj ma nv jx nk li oa nm nn lm ob np nq lq oc ns nt mf im bi translated">其中<strong class="lx iu"> <em class="nz"> x </em> </strong>是原始数据，<strong class="lx iu"> <em class="nz"> μ </em> </strong>只是<strong class="lx iu"><em class="nz">x</em></strong><strong class="lx iu">σ</strong>是<strong class="lx iu"> <em class="nz"> x </em> </strong>的标准差。异常值也被定义为</p><p id="47f0" class="pw-post-body-paragraph nh ni it lx b ly nu ju nj ma nv jx nk li oa nm nn lm ob np nq lq oc ns nt mf im bi translated"><strong class="lx iu"><em class="nz">Z 值小于 1.0 或大于 3.0 的 x</em></strong></p><p id="28b7" class="pw-post-body-paragraph nh ni it lx b ly nu ju nj ma nv jx nk li oa nm nn lm ob np nq lq oc ns nt mf im bi translated">在代码以下的数据样本中，30 是一个异常值。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="od oe l"/></div></figure><p id="1dae" class="pw-post-body-paragraph nh ni it lx b ly nu ju nj ma nv jx nk li oa nm nn lm ob np nq lq oc ns nt mf im bi translated">这是异常检测和单变量检测。Z 分数的概念值得注意，因为它用于计算 Mahalanobis 距离。此外，在比较稳健协方差作为异常检测的性能时，马氏距离是一个基本概念。</p><h1 id="a033" class="mw la it bd lb mx of mz le na og nc lh jz oh ka ll kc oi kd lp kf oj kg lt ng bi translated">线性回归模型</h1><p id="cf89" class="pw-post-body-paragraph nh ni it lx b ly lz ju nj ma mb jx nk li nl nm nn lm no np nq lq nr ns nt mf im bi translated">接下来我们将看看线性回归模型的异常检测技术，具体来说，<em class="nz">杠杆统计</em>、<em class="nz">库克距离</em>和<em class="nz"> DFFITS </em>。他们的目的是相同的，然而他们的方法是不同的。</p><h2 id="2c68" class="kz la it bd lb lc ld dn le lf lg dp lh li lj lk ll lm ln lo lp lq lr ls lt lu bi translated"><strong class="ak">杠杆统计</strong></h2><p id="647c" class="pw-post-body-paragraph nh ni it lx b ly lz ju nj ma mb jx nk li nl nm nn lm no np nq lq nr ns nt mf im bi translated">杠杆统计是对数据与他人的距离/影响力的诊断。这里我们要观察<strong class="lx iu">杠杆</strong> <strong class="lx iu">点</strong>，它是对回归模型没有影响，但对数据集的均值、方差有影响的数据点，以及<strong class="lx iu">影响点</strong>，它是<strong class="lx iu"> </strong>对两者都有影响的数据点。我们将测量每个点的观测影响，并检测对从观测中提取的信息量有很大影响的异常数据。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ok"><img src="../Images/b10da86be90054c77243986de0a17ab5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1084/format:webp/1*6y3Rd_tWXD_Z-3p_qSr5ig.png"/></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk">Influence point (blue point) v.s. Leverage point (red point)</figcaption></figure><p id="44c6" class="pw-post-body-paragraph nh ni it lx b ly nu ju nj ma nv jx nk li oa nm nn lm ob np nq lq oc ns nt mf im bi translated">设<strong class="lx iu"> <em class="nz"> X </em> </strong>为设计矩阵，<strong class="lx iu"> <em class="nz"> x </em> </strong>为<strong class="lx iu"> <em class="nz"> X </em> </strong>，<strong class="lx iu"> <em class="nz"> x ⊆ X </em> </strong>的变量。在杠杆统计中，我们计算杠杆分数，并将其与临界值进行比较。超过临界值的分数是杠杆或影响点。截止值定义为</p><p id="8579" class="pw-post-body-paragraph nh ni it lx b ly nu ju nj ma nv jx nk li oa nm nn lm ob np nq lq oc ns nt mf im bi translated"><strong class="lx iu"> <em class="nz"> 2*(全球平均观测影响(OI)/n)，OI =痕迹(H)，</em> </strong></p><p id="3c2c" class="pw-post-body-paragraph nh ni it lx b ly nu ju nj ma nv jx nk li oa nm nn lm ob np nq lq oc ns nt mf im bi translated">其中<strong class="lx iu"> <em class="nz"> n </em> </strong>为观察数，<strong class="lx iu"> <em class="nz"> H </em> </strong>为<strong class="lx iu"> <em class="nz"> X </em> </strong>的投影矩阵。投影矩阵<strong class="lx iu"> <em class="nz"> H = X(XᵀX)⁻ Xᵀ </em> </strong>，各次观测的杠杆分数<strong class="lx iu"><em class="nz"/></strong>是<strong class="lx iu"><em class="nz"/></strong>的对角线入口。</p><p id="6c56" class="pw-post-body-paragraph nh ni it lx b ly nu ju nj ma nv jx nk li oa nm nn lm ob np nq lq oc ns nt mf im bi translated">为了实现这一点，我们首先制作简单的样本数据，并用红色添加一个影响点。如果一个杠杆分数超过截止值，那么我们也把它涂成红色。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="od oe l"/></div></figure><div class="kj kk kl km gt ab cb"><figure class="ol kn om on oo op oq paragraph-image"><img src="../Images/e0bebee216ce76b4985371a764350086.png" data-original-src="https://miro.medium.com/v2/resize:fit:958/format:webp/1*W6fIr6uGbvxFV4yMtNkO8Q.png"/></figure><figure class="ol kn om on oo op oq paragraph-image"><img src="../Images/890c03c261417b1652fb182b53737a21.png" data-original-src="https://miro.medium.com/v2/resize:fit:958/format:webp/1*vcmgdhyd7FoKXUU1IWzygw.png"/><figcaption class="ku kv gj gh gi kw kx bd b be z dk or di os ot">Fig. left: Plot data points with influence point (red). Fig. right: Applying leverage statistics and detecting leverage and influence points(red)</figcaption></figure></div><p id="fafb" class="pw-post-body-paragraph nh ni it lx b ly nu ju nj ma nv jx nk li oa nm nn lm ob np nq lq oc ns nt mf im bi translated">从右图中我们可以看到，高度偏离的数据点被检测为杠杆点和影响点。</p><h2 id="ec71" class="kz la it bd lb lc ld dn le lf lg dp lh li lj lk ll lm ln lo lp lq lr ls lt lu bi translated"><strong class="ak">d fits</strong></h2><p id="57cd" class="pw-post-body-paragraph nh ni it lx b ly lz ju nj ma mb jx nk li nl nm nn lm no np nq lq nr ns nt mf im bi translated">当我们拟合了一些估计量的值时，如 OLS，我们可以用 DFFITS 来寻找异常点。当我们在杠杆统计中计算分数时，我们在 DFT ifts 中做同样的事情。DFFITS 用两个不同估计量的拟合值之差来度量分数。其得分公式定义为</p><p id="33ad" class="pw-post-body-paragraph nh ni it lx b ly nu ju nj ma nv jx nk li oa nm nn lm ob np nq lq oc ns nt mf im bi translated"><strong class="lx iu"> <em class="nz"> DFFITSᵢ = (ŷᵢ-ŷᵢᵢ) / s*√hᵢᵢ，</em> </strong></p><p id="5940" class="pw-post-body-paragraph nh ni it lx b ly nu ju nj ma nv jx nk li oa nm nn lm ob np nq lq oc ns nt mf im bi translated">其中，<strong class="lx iu"><em class="nz"/></strong>是由估计器基于包括第 I 个观测值的数据集预测的第 I 个拟合值，而<strong class="lx iu"><em class="nz">【ŷᵢᵢ】</em></strong>是由基于估计器的不包括第 I 个观测值的数据集预测的拟合值。<strong class="lx iu"> <em class="nz"> s </em> </strong>是由基于估计量的数据集预测的独立值和拟合值的误差的标准偏差，不包括第 I 次观察。</p><p id="293c" class="pw-post-body-paragraph nh ni it lx b ly nu ju nj ma nv jx nk li oa nm nn lm ob np nq lq oc ns nt mf im bi translated">上面的公式等于，</p><p id="2c13" class="pw-post-body-paragraph nh ni it lx b ly nu ju nj ma nv jx nk li oa nm nn lm ob np nq lq oc ns nt mf im bi translated"><strong class="lx iu"><em class="nz">dffitsᵢ=tᵢ* √[hᵢᵢ/(1-hᵢᵢ)】</em></strong></p><p id="a049" class="pw-post-body-paragraph nh ni it lx b ly nu ju nj ma nv jx nk li oa nm nn lm ob np nq lq oc ns nt mf im bi translated">其中<strong class="lx iu"> <em class="nz"> tᵢ </em> </strong>是一个<a class="ae ky" href="https://en.wikipedia.org/wiki/Studentized_residual" rel="noopener ugc nofollow" target="_blank"> R-student </a>。</p><p id="0f29" class="pw-post-body-paragraph nh ni it lx b ly nu ju nj ma nv jx nk li oa nm nn lm ob np nq lq oc ns nt mf im bi translated">在下面的代码中，我们用第 I 个观察值来计算 DFFITS。因此<strong class="lx iu"> <em class="nz"> tᵢ </em> </strong>被称为<em class="nz"> </em>内化残。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="od oe l"/></div></figure><h2 id="3f58" class="kz la it bd lb lc ld dn le lf lg dp lh li lj lk ll lm ln lo lp lq lr ls lt lu bi translated">库克的距离</h2><p id="2467" class="pw-post-body-paragraph nh ni it lx b ly lz ju nj ma mb jx nk li nl nm nn lm no np nq lq nr ns nt mf im bi translated">就 DFFITS 而言，当我们已经知道拟合值时，Cook 距离也是一种有用的方法。该方法通过计算由估计器基于包括第 I 个观察值数据集预测的第 I 个拟合值和由估计器基于排除所有第 I 个数据的第 I 个观察值的数据集预测的拟合值之间的平方误差来测量得分。因此，该公式定义为</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ou"><img src="../Images/70c443f0a8121e587b1d46f8c9ed8383.png" data-original-src="https://miro.medium.com/v2/resize:fit:570/format:webp/1*eSJq8DwdUZg6tA2j6FM3zQ.png"/></div></figure><p id="8e68" class="pw-post-body-paragraph nh ni it lx b ly nu ju nj ma nv jx nk li oa nm nn lm ob np nq lq oc ns nt mf im bi translated">其中<strong class="lx iu"> <em class="nz"> p </em> </strong>为变量个数，<strong class="lx iu"> <em class="nz"> s </em> </strong>为回归模型的均方误差，拟合值定义与 DFFITS 中相同。对于小样本量，<a class="ae ky" href="https://www.researchgate.net/publication/258174106_Best-Practice_Recommendations_for_Defining_Identifying_and_Handling_Outliers" rel="noopener ugc nofollow" target="_blank">临界值</a>推荐为<em class="nz"> 2*(p+1)/n </em>，对于大样本量，<em class="nz"> 3*(p+1)/n </em>。</p><p id="6836" class="pw-post-body-paragraph nh ni it lx b ly nu ju nj ma nv jx nk li oa nm nn lm ob np nq lq oc ns nt mf im bi translated">上述公式等于</p><p id="2aa3" class="pw-post-body-paragraph nh ni it lx b ly nu ju nj ma nv jx nk li oa nm nn lm ob np nq lq oc ns nt mf im bi translated"><strong class="lx iu"><em class="nz">dᵢ=(tᵢ/p*s)* √[hᵢᵢ/(1-hᵢᵢ)】</em></strong></p><p id="086b" class="pw-post-body-paragraph nh ni it lx b ly nu ju nj ma nv jx nk li oa nm nn lm ob np nq lq oc ns nt mf im bi translated">这方面的术语同上。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="od oe l"/></div></figure><p id="361c" class="pw-post-body-paragraph nh ni it lx b ly nu ju nj ma nv jx nk li oa nm nn lm ob np nq lq oc ns nt mf im bi translated">在<a class="ae ky" href="https://www.statsmodels.org/dev/generated/statsmodels.stats.outliers_influence.OLSInfluence.summary_frame.html" rel="noopener ugc nofollow" target="_blank"> Statsmodels </a>中提供了库克距离和 DFFITS。为了进行 n 次实验，看看库克距离和 DFT ifts 之间的结果有多大差异，现在我们来看下面的代码。我们使用来自 Kaggle( <a class="ae ky" href="https://www.kaggle.com/pitasr/falldata" rel="noopener ugc nofollow" target="_blank">来源</a>)的跌倒检测数据集。为了方便起见，我们取时间(监测时间)和 HR(心率)，检查<strong class="lx iu"> <em class="nz"> cooks_d </em> </strong>和<strong class="lx iu"> <em class="nz"> dffits </em> </strong>值。在这两个图中，蓝线是 OLS 的回归线。Cook 的距离检测 HR 值方面的远杠杆数据和高变量数据点，而<strong class="lx iu"> <em class="nz"> DFFITS </em> </strong>倾向于检测回归线以上的数据点，而不检测位于远右上方的数据点。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="od oe l"/></div></figure></div></div>    
</body>
</html>