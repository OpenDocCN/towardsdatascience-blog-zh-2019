# 用 OpenCV 实现图像全景拼接

> 原文：<https://towardsdatascience.com/image-panorama-stitching-with-opencv-2402bde6b46c?source=collection_archive---------0----------------------->

![](img/b1a0a8137a8e4af0df715b171cf2b4c8.png)

图像拼接是计算机视觉中最成功的应用之一。如今，很难找到不包含此功能的手机或图像处理 API。

在这篇文章中，我们将讨论如何使用 Python 和 OpenCV 执行图像拼接。给定一对共享一些公共区域的图像，我们的目标是“缝合”它们并创建一个全景图像场景。

在整篇文章中，我们回顾了一些最著名的计算机视觉技术。其中包括:

*   关键点检测
*   局部不变描述符(SIFT、SURF 等)
*   特征匹配
*   使用 RANSAC 的单应性估计
*   透视扭曲

我们探索了许多特征提取器，如 SIFT、SURF、BRISK 和 ORB。你可以使用这款 [Colab 笔记本](https://colab.research.google.com/drive/11Md7HWh2ZV6_g3iCYSUw76VNr4HzxcX5)进行跟踪，甚至用你的图片进行尝试。

![](img/29625ee2f641997b03a17a23e062b252.png)

# 特征检测和提取

给定一对像上面这样的图像，我们想把它们拼接起来，创建一个全景场景。需要注意的是，两个图像需要共享一些公共区域。

此外，我们的解决方案必须是健壮的，即使图片在以下一个或多个方面有差异**:**

*   **缩放比例**
*   **角**
*   **空间位置**
*   **捕捉设备**

**这个方向的第一步是提取一些关键点和感兴趣的特征。然而，这些特征需要具有一些特殊的属性。**

**让我们首先考虑一个简单的解决方案。**

# **关键点检测**

**一个最初的可能是幼稚的方法是使用算法提取关键点，比如 Harris Corners。然后，我们可以尝试基于某种相似性度量(如欧几里德距离)来匹配相应的关键点。我们知道，角点有一个很好的性质:**它们对于旋转**是不变的。这意味着，一旦我们检测到一个角点，如果我们旋转图像，这个角点将仍然存在。**

**然而，如果我们旋转然后缩放一幅图像呢？在这种情况下，我们将有一段艰难的时间，因为角落不是不变的比例。也就是说，如果我们放大一幅图像，之前检测到的角点可能会变成一条线！**

**总之，我们需要对旋转和缩放不变的特征。这就是 SIFT、SURF 和 ORB 等更健壮的方法的用武之地。**

# **要点和描述符。**

**像 SIFT 和 SURF 这样的方法试图解决角点检测算法的局限性。通常，角点检测算法使用固定大小的核来检测图像上的感兴趣区域(角点)。很容易看出，当我们缩放图像时，这个内核可能会变得太小或太大。**

**为了解决这个限制，像 SIFT 这样的方法使用高斯差分(DoD)。这个想法是将 DoD 应用于同一幅图像的不同比例版本。它还使用相邻像素信息来寻找和改进关键点和相应的描述符。**

**首先，我们需要加载两个图像，一个查询图像和一个训练图像。最初，我们从提取关键点和描述符开始。我们可以使用 OpenCV*detectAndCompute()*函数一步完成。注意，为了使用 *detectAndCompute()* ，我们需要一个关键点检测器和描述符对象的实例。可以是 ORB，SIFT 或者 SURF 等。此外，在将图像输入 *detectAndCompute()* 之前，我们将它们转换成灰度。**

**我们在查询和火车图像上运行 *detectAndCompute()* 。此时，我们有了两幅图像的一组关键点和描述符。如果我们使用 SIFT 作为特征提取器，它为每个关键点返回一个 128 维的特征向量。如果选择 SURF，我们得到一个 64 维的特征向量。下图显示了使用 SIFT、SURF、BRISK 和 ORB 提取的一些特征。**

**![](img/124fc70c00ec233973e8f6e0162e1754.png)**

**Detection of key points and descriptors using SIFT**

**![](img/aecc57b16bbd46ee83211d9c5da98647.png)**

**Detection of key points and descriptors using SURF**

**![](img/559d7b2e0eb4176b9d0533c6bde07e8d.png)**

**Detection of key points and descriptors using BRISK and Hamming distances.**

**![](img/c6baaf5e961784745201fc6d14daa8c1.png)**

**Detection of key points and descriptors using ORB and Hamming distances.**

# **特征匹配**

**如我们所见，我们从两幅图像中获得了大量特征。现在，我们想比较两组特征，并坚持使用显示更多相似性的特征对。**

**在 OpenCV 中，特征匹配需要一个 Matcher 对象。在这里，我们探索两种口味:**

*   **强力匹配器**
*   **KNN(k-最近邻)**

**BruteForce (BF)匹配器正如其名所示。给定 2 组特征(来自图像 A 和图像 B)，将 A 组中的每个特征与 B 组中的所有特征进行比较。默认情况下，BF Matcher 计算两点之间的**欧几里德距离。因此，对于集合 A 中的每个特征，它返回集合 b 中最接近的特征。对于 SIFT 和 SURF，OpenCV 建议使用欧几里德距离。对于其他特征提取器，如 ORB 和 BRISK，建议使用汉明距离。****

**要使用 OpenCV 创建一个 BruteForce 匹配器，我们只需要指定 2 个参数。第一个是距离度量。第二个是*交叉检查*布尔参数。**

***crossCheck* bool 参数指示两个特征是否必须相互匹配才能被视为有效。换句话说，对于被认为有效的一对特征( *f1，F2*),*f1*需要匹配 *f2* ，并且 *f2* 也必须匹配 *f1* 作为最接近的匹配。该过程确保了一组更稳健的匹配特征，并且在原始 SIFT 论文中有所描述。**

**然而，对于我们想要考虑多个候选匹配的情况，我们可以使用基于 KNN 的匹配过程。**

> **KNN 不会返回给定要素的单个最佳匹配，而是返回 k 个最佳匹配。**

**注意，k 值必须由用户预先定义。正如我们所料，KNN 提供了更多的候选特性。然而，我们需要确保所有这些匹配对在进一步之前都是健壮的。**

# **比率测试**

**为了确保 KNN 返回的特征具有很好的可比性，SIFT 论文的作者建议使用一种叫做**比率测试**的技术。基本上，我们迭代 KNN 返回的每一对，并执行距离测试。对于每一对特征( *f1，f2* )，如果 *f1* 和 *f2* 之间的距离在一定比例之内，我们保留它，否则，我们丢弃它。此外，比率值必须手动选择。**

**本质上，比率测试的工作与来自 BruteForce Matcher 的交叉检查选项相同。两者都确保一对检测到的特征确实足够接近以被认为是相似的。下图显示了 BF 和 KNN 匹配器在 SIFT 特征上的结果。我们选择只显示 100 个匹配点，以便清晰可视化。**

**![](img/b0bcb85f402c075cdfe53cf4e5645354.png)**

**Feature matching using KNN and Ration Testing on SIFT features**

**![](img/4ef5889c41782e861b0122a728a701ae.png)**

**Feature matching using Brute Force Matcher on SIFT features**

**请注意，即使在 KNN 对暴力和比率测试进行了交叉检查之后，一些特性仍然不能正确匹配。**

**然而，匹配器算法将从两幅图像中给我们最好的(更相似的)特征集。现在，我们需要获得这些点，并找到转换矩阵，该矩阵将基于它们的匹配点将两幅图像缝合在一起。**

**这种变换称为单应矩阵。简而言之，单应矩阵是一个 3×3 矩阵，可用于许多应用，如相机姿态估计、透视校正和图像拼接。单应是 2D 变换。它将点从一个平面(图像)映射到另一个平面。让我们看看我们如何得到它。**

# **估计单应性**

**随机样本一致性或 RANSAC 是一种拟合线性模型的迭代算法。与其他线性回归不同，RANSAC 旨在对异常值保持稳健。**

**线性回归等模型使用最小二乘估计来拟合数据的最佳模型。然而，普通最小二乘法对异常值非常敏感。因此，如果离群值的数量很大，它可能会失败。**

**RANSAC 通过仅使用数据中的**内嵌器**的子集来估计参数，从而解决了这个问题。下图显示了线性回归和 RANSAC 之间的比较。首先，注意数据集包含相当多的异常值。**

**我们可以看到，线性回归模型很容易受到异常值的影响。这是因为它试图减少平均误差。因此，它倾向于支持最小化从所有数据点到模型本身的总距离的模型。这包括离群值。**

**相反，RANSAC 仅在被识别为内点的点的子集上拟合模型。**

**这个特征对我们的用例非常重要。这里，我们将使用 RANSAC 来估计单应矩阵。事实证明，单应性对我们传递给它的数据质量非常敏感。因此，重要的是要有一种算法(RANSAC ),能够将明显属于数据分布的点从不属于数据分布的点中过滤出来。**

**![](img/d7f2896dc271e22a2c24115907627e44.png)**

**Comparison between Least Squares and RANSAC model fitting. Note the substantial number of outliers in the data.**

**一旦我们有了估计的单应性，我们需要将其中一个图像扭曲到一个公共平面上。**

**这里，我们将对其中一幅图像应用透视变换。基本上，透视变换可以组合一个或多个操作，如旋转、缩放、平移或剪切。想法是转换其中一个图像，使两个图像合并为一个。为此，我们可以使用 OpenCV *warpPerspective()* 函数。它接受一幅图像和单应性作为输入。然后，基于单应性将源图像扭曲到目的图像。**

**生成的全景图像如下所示。正如我们看到的，结果中有几个工件。更具体地说，我们可以看到一些与图像边界处的光照条件和边缘效应相关的问题。理想情况下，我们可以执行后处理技术来归一化亮度，如**直方图匹配**。这可能会使结果看起来更真实。**

****感谢阅读！****

**![](img/46a14c541d53591b70779ae573a9f6b3.png)****![](img/a0ba060b2ddeeddbeb8acbc3bac2cc45.png)

Input image pair** **![](img/e35951329a444cddad7d21154b061922.png)**

**Panoramic Image**

**![](img/66ce4169d51fa79bd97424af6d94fa07.png)****![](img/931e606741f5d0dff104bc91c86ad2f2.png)**

**Input image pair**

**![](img/0b0d8355375bf09fdeef7d73cc0b8c73.png)**

**Panoramic Image**

**![](img/466858993bc66b1d0e0ba745062b30f0.png)****![](img/117dcf21f7c0a9dbd1a9b0c2991d4c2c.png)**

**Input image pair**

**![](img/0e66f5fd79c2eab590ada65008219ffc.png)**

**Panoramic Image**

**![](img/4ee59b9d0049fc2f17eb755846174ed5.png)****![](img/76298e71be9bf03457211e7529e22238.png)**

**Input image pair.**

**![](img/85948f581d9ecce92e8d6fb56c50d0b0.png)**

**Panoramic Image**