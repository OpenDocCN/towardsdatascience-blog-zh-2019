<html>
<head>
<title>Data Handling Using Pandas: Cleaning and Processing</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用 Pandas 处理数据:清理和处理</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/data-handling-using-pandas-cleaning-and-processing-3aa657dc9418?source=collection_archive---------5-----------------------#2019-04-06">https://towardsdatascience.com/data-handling-using-pandas-cleaning-and-processing-3aa657dc9418?source=collection_archive---------5-----------------------#2019-04-06</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="b7f7" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">掌握熊猫处理“脏数据”</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/b87cbc0e2ddea0fcc3336a41847188ed.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*V-LRUpcD7sORoDMmQL6R7g.jpeg"/></div></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk">Keep calm, learn Pandas! (<a class="ae ky" href="https://pixabay.com/photos/animal-branch-cute-red-panda-1851593/" rel="noopener ugc nofollow" target="_blank">Source: Pixabay</a>)</figcaption></figure><p id="c846" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在为一些老的 Kaggle 项目实践时，我意识到在应用机器学习算法之前准备数据文件要花很多时间。这篇文章回顾了一些关于<a class="ae ky" href="https://pandas.pydata.org/" rel="noopener ugc nofollow" target="_blank">熊猫</a>的初级到高级水平的数据处理技术，作为另一篇文章<a class="ae ky" href="https://medium.com/swlh/practical-data-analysis-using-pandas-global-terrorism-database-20b29009adad" rel="noopener">的前奏，在另一篇文章</a>中，我使用了全球恐怖主义数据和熊猫的一些高级功能进行数据分析。这篇文章是关于数据清理和处理的。让我们立即开始吧！</p><p id="93c6" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在这篇文章中，我使用了<a class="ae ky" href="https://www.kaggle.com/carolzhangdc/imdb-5000-movie-dataset/kernels" rel="noopener ugc nofollow" target="_blank"> IMDB movie-dataset </a>来介绍最相关的数据清理和处理技术。我们可以从了解以下数据集开始</p><pre class="kj kk kl km gt lv lw lx ly aw lz bi"><span id="934e" class="ma mb it lw b gy mc md l me mf">movies_df = pd.read_csv("movie_metadata.csv")<br/>print "data-frame shape: ", movies_df.shape </span><span id="7b15" class="ma mb it lw b gy mg md l me mf">&gt;&gt;&gt; data-frame shape:  (5043, 28)</span></pre><p id="57bf" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">因此数据集有 5043 行，28 列，我们可以用</p><pre class="kj kk kl km gt lv lw lx ly aw lz bi"><span id="dc98" class="ma mb it lw b gy mc md l me mf">print "column names: ", movies_df.columns.values</span><span id="e5ba" class="ma mb it lw b gy mg md l me mf">&gt;&gt;&gt; column names:  <br/>['color' 'director_name' 'num_critic_for_reviews' 'duration'<br/> 'director_facebook_likes' 'actor_3_facebook_likes' 'actor_2_name'<br/> 'actor_1_facebook_likes' 'gross' 'genres' 'actor_1_name' 'movie_title'<br/> 'num_voted_users' 'cast_total_facebook_likes' 'actor_3_name'<br/> 'facenumber_in_poster' 'plot_keywords' 'movie_imdb_link'<br/> 'num_user_for_reviews' 'language' 'country' 'content_rating' 'budget'<br/> 'title_year' 'actor_2_facebook_likes' 'imdb_score' 'aspect_ratio'<br/> 'movie_facebook_likes']</span></pre><p id="10f3" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在我们应用一些最大似然算法进行预测之前，比如说“imdb_score”，我们需要对数据集进行更多的调查，因为它不像<a class="ae ky" href="https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_boston.html" rel="noopener ugc nofollow" target="_blank">波士顿大厦数据集</a>那样得到很好的处理。首先，我将讨论如何处理丢失的数据。</p></div><div class="ab cl mh mi hx mj" role="separator"><span class="mk bw bk ml mm mn"/><span class="mk bw bk ml mm mn"/><span class="mk bw bk ml mm"/></div><div class="im in io ip iq"><h2 id="e4c9" class="ma mb it bd mo mp mq dn mr ms mt dp mu li mv mw mx lm my mz na lq nb nc nd ne bi translated">处理缺失数据:DataFrame.isna()，DataFrame.fillna()</h2><p id="394a" class="pw-post-body-paragraph kz la it lb b lc nf ju le lf ng jx lh li nh lk ll lm ni lo lp lq nj ls lt lu im bi translated">我们可以使用<code class="fe nk nl nm lw b"><a class="ae ky" href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.isna.html" rel="noopener ugc nofollow" target="_blank">pandas.DataFrame.isna</a>()</code>来检测数组类对象的缺失值。这将返回一个大小相同的布尔对象，其中 NA 值(如 None 或<code class="fe nk nl nm lw b">numpy.NaN</code>)被映射为 True，而其他所有值都被映射为 False。这与<code class="fe nk nl nm lw b"><a class="ae ky" href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.isnull.html" rel="noopener ugc nofollow" target="_blank">pandas.DataFrame.isnull(</a>)</code>如出一辙。</p><pre class="kj kk kl km gt lv lw lx ly aw lz bi"><span id="5ba0" class="ma mb it lw b gy mc md l me mf">print "null values: \n", <br/>print movies_df.isna()</span></pre><p id="8305" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">上述命令返回以下输出</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nn"><img src="../Images/428e454548c9877f7a073d7a0459ab83.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*daY09Rhms8LMN7sT47w7QQ.jpeg"/></div></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk">Looking For Missing Data in data-frame</figcaption></figure><p id="241c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们可以通过在前面的命令中添加一个<code class="fe nk nl nm lw b">.sum()</code>来提取相关信息，而不是打印出带有 True/False 条目的数据帧。这样我们就可以找到每一列缺失值的总数。</p><pre class="kj kk kl km gt lv lw lx ly aw lz bi"><span id="d2b1" class="ma mb it lw b gy mc md l me mf">print movies_df.isna().sum()</span><span id="17cd" class="ma mb it lw b gy mg md l me mf">&gt;&gt;&gt;</span><span id="822a" class="ma mb it lw b gy mg md l me mf">color                         19<br/>director_name                104<br/>num_critic_for_reviews        50<br/>duration                      15<br/>director_facebook_likes      104<br/>actor_3_facebook_likes        23<br/>actor_2_name                  13<br/>actor_1_facebook_likes         7<br/>gross                        884<br/>genres                         0<br/>actor_1_name                   7<br/>movie_title                    0<br/>num_voted_users                0<br/>cast_total_facebook_likes      0<br/>actor_3_name                  23<br/>facenumber_in_poster          13<br/>plot_keywords                153<br/>movie_imdb_link                0<br/>num_user_for_reviews          21<br/>language                      12<br/>country                        5<br/>content_rating               303<br/>budget                       492<br/>title_year                   108<br/>actor_2_facebook_likes        13<br/>imdb_score                     0<br/>aspect_ratio                 329<br/>movie_facebook_likes           0<br/>dtype: int64</span></pre><p id="ce27" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">添加另一个。sum()返回数据集中空值的总数。</p><pre class="kj kk kl km gt lv lw lx ly aw lz bi"><span id="9155" class="ma mb it lw b gy mc md l me mf">print "total null values: ", movies_df.isna().sum().sum()</span><span id="cfb0" class="ma mb it lw b gy mg md l me mf">&gt;&gt; total null values: 2698</span></pre><p id="e99e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">移除包含 NA <em class="no">的行的最简单的方法之一是</em> <strong class="lb iu"> <em class="no">删除</em> </strong> <em class="no">它们，</em>当所有列都包含 NA 或任何列都包含 NA 时。让我们从删除任何列中包含 NA 值的行开始。</p><pre class="kj kk kl km gt lv lw lx ly aw lz bi"><span id="b6e4" class="ma mb it lw b gy mc md l me mf">clean_movies_df = movies_df.dropna(how='any')</span><span id="b0da" class="ma mb it lw b gy mg md l me mf">print "new dataframe shape: ", clean_movies_df.shape<br/>print "old dataframe shape: "</span><span id="2619" class="ma mb it lw b gy mg md l me mf">&gt;&gt;&gt; </span><span id="f122" class="ma mb it lw b gy mg md l me mf">new dataframe shape:  (3756, 28)<br/>old dataframe shape:  (5043, 28)</span></pre><p id="cecd" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">因此，删除任何列中包含 NA 值的行都会减少将近 1300 行。这对于行数较少的数据集非常重要，因为删除所有缺少值的行会导致我们丢失必要的信息。在这种情况下，我们可以使用指定的方法使用<code class="fe nk nl nm lw b"><a class="ae ky" href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.fillna.html" rel="noopener ugc nofollow" target="_blank">pandas.DataFrame.fillna(</a>)</code>方法向<strong class="lb iu"> <em class="no">填充 NA/NaN 值</em> </strong>。用某个固定值(例如 0)填充所有 NA/nan 的最简单方法。我们可以简单地通过</p><pre class="kj kk kl km gt lv lw lx ly aw lz bi"><span id="c591" class="ma mb it lw b gy mc md l me mf">movies_df.fillna(value=0, inplace = True) </span></pre><p id="7760" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们可以选择一些特定的列，然后使用下面的<code class="fe nk nl nm lw b">DataFrame.fillna()</code>方法，而不是用零填充所有缺失的值</p><pre class="kj kk kl km gt lv lw lx ly aw lz bi"><span id="1862" class="ma mb it lw b gy mc md l me mf">movies_df[['gross', 'budget']] = movies_df[['gross', 'budget']].fillna(value=0)</span></pre><p id="833e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">对于“object”数据类型的列，例如“language”列，我们可以使用“no info”这样的词来填充缺少的条目。</p><pre class="kj kk kl km gt lv lw lx ly aw lz bi"><span id="44c3" class="ma mb it lw b gy mc md l me mf">movies_df['language'].fillna("no info", inplace=True)</span></pre><p id="d9f6" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">填充缺失值的另一个<code class="fe nk nl nm lw b">method</code>可以是<code class="fe nk nl nm lw b"><strong class="lb iu">ffill</strong></code>方法，它将上一个有效的观察传播到下一个。类似地<code class="fe nk nl nm lw b"><strong class="lb iu">bfill</strong></code>方法使用下一个观察来填补空白。</p><pre class="kj kk kl km gt lv lw lx ly aw lz bi"><span id="f71d" class="ma mb it lw b gy mc md l me mf">movies_df['language'].fillna(method='ffill', inplace=True)</span></pre><p id="16e4" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">另一个有效的方法是用<strong class="lb iu"> <em class="no">列的平均值来填充缺失值</em> </strong>如下</p><pre class="kj kk kl km gt lv lw lx ly aw lz bi"><span id="7723" class="ma mb it lw b gy mc md l me mf">movies_df['budget'].fillna(movies_df[budget].mean(), inplace=True)</span></pre><p id="0c8c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">关于如何使用 Pandas 处理缺失值的更多细节，您可以查看 Pandas 用户指南中关于缺失数据的文档。</p></div><div class="ab cl mh mi hx mj" role="separator"><span class="mk bw bk ml mm mn"/><span class="mk bw bk ml mm mn"/><span class="mk bw bk ml mm"/></div><div class="im in io ip iq"><h2 id="b49a" class="ma mb it bd mo mp mq dn mr ms mt dp mu li mv mw mx lm my mz na lq nb nc nd ne bi translated">数据帧中的重复数据:DataFrame.duplicated()</h2><p id="df68" class="pw-post-body-paragraph kz la it lb b lc nf ju le lf ng jx lh li nh lk ll lm ni lo lp lq nj ls lt lu im bi translated">除了丢失的数据，在一个数据帧中还可能有<em class="no">重复行</em>。为了确定一个数据集是否包含重复的行，我们可以使用 Pandas<a class="ae ky" href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.duplicated.html" rel="noopener ugc nofollow" target="_blank">data frame . duplicated()</a>来处理所有的列或一些选定的列。<code class="fe nk nl nm lw b"><strong class="lb iu">pandas.Dataframe.duplicated()</strong></code>返回表示重复行的布尔序列。让我们首先找出这个电影数据集中有多少重复行。</p><pre class="kj kk kl km gt lv lw lx ly aw lz bi"><span id="b5ff" class="ma mb it lw b gy mc md l me mf">duplicate_rows_df = movies_df[movies_df.duplicated()]</span><span id="e659" class="ma mb it lw b gy mg md l me mf">print "number of duplicate rows: ", duplicate_rows_df.shape</span><span id="6e65" class="ma mb it lw b gy mg md l me mf">&gt;&gt;&gt; <br/>number of duplicate rows:  (45, 28)</span></pre><p id="c174" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">因此，每列中有 45 行存在重复的元素。我们也可以对单个列进行检查—</p><pre class="kj kk kl km gt lv lw lx ly aw lz bi"><span id="2a3e" class="ma mb it lw b gy mc md l me mf">duplicated_rows_df_imdb_link= movies_df[movies_df.duplicated(['movie_imdb_link'])]</span><span id="489a" class="ma mb it lw b gy mg md l me mf">print duplicate_rows_df_imdb_link.shape</span><span id="6968" class="ma mb it lw b gy mg md l me mf">&gt;&gt;&gt; <br/>(124, 28)</span></pre><p id="fc7e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">所以有 124 种情况下 imdb 链接是相同的，检查相同的另一种方法是使用<code class="fe nk nl nm lw b"><a class="ae ky" href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.unique.html" rel="noopener ugc nofollow" target="_blank"><strong class="lb iu">pandas.Series.unique()</strong></a></code>方法。让我们看看:</p><pre class="kj kk kl km gt lv lw lx ly aw lz bi"><span id="557b" class="ma mb it lw b gy mc md l me mf">print len(movies_df.movie_imdb_link.unique())</span><span id="cd5c" class="ma mb it lw b gy mg md l me mf">&gt;&gt;&gt; <br/>4919</span></pre><p id="536b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">因此，唯一链接的总数是 4919，如果您注意到重复链接是 124，将它们相加得到(4919 + 124 = 5043)总行数。为了更好地分析，有必要选择唯一的行，这样至少我们可以删除所有列中具有相同值的行。我们可以简单地使用下面的<code class="fe nk nl nm lw b"><a class="ae ky" href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.drop_duplicates.html" rel="noopener ugc nofollow" target="_blank"><strong class="lb iu">pandas.DataFrame.drop_duplicates()</strong></a></code>来完成</p><pre class="kj kk kl km gt lv lw lx ly aw lz bi"><span id="304a" class="ma mb it lw b gy mc md l me mf">print "shape of dataframe after dropping duplicates", movies_df.drop_duplicates().shape </span><span id="ae9e" class="ma mb it lw b gy mg md l me mf">&gt;&gt;&gt; <br/>shape of dataframe after dropping duplicates (4998, 28)</span></pre></div><div class="ab cl mh mi hx mj" role="separator"><span class="mk bw bk ml mm mn"/><span class="mk bw bk ml mm mn"/><span class="mk bw bk ml mm"/></div><div class="im in io ip iq"><h2 id="9082" class="ma mb it bd mo mp mq dn mr ms mt dp mu li mv mw mx lm my mz na lq nb nc nd ne bi translated">宁滨数据:pandas.cut()</h2><p id="3b6f" class="pw-post-body-paragraph kz la it lb b lc nf ju le lf ng jx lh li nh lk ll lm ni lo lp lq nj ls lt lu im bi translated">另一个非常重要的数据处理技术是<strong class="lb iu"> <em class="no">数据分桶或数据宁滨</em> </strong>。我们将在这里看到一个例子，宁滨·IMDb 使用<code class="fe nk nl nm lw b"><a class="ae ky" href="https://pandas.pydata.org/pandas-docs/version/0.23.4/generated/pandas.cut.html" rel="noopener ugc nofollow" target="_blank"><strong class="lb iu">pandas.cut()</strong></a></code>方法得分。基于分数[0。,4., 7., 10.]，我想把电影放在不同的桶里['shyyyte '，'适中'，'好']。如你所知，得分在 0-4 之间的电影将被放入“shyyyte”桶中，以此类推。我们可以用下面几行代码做到这一点</p><pre class="kj kk kl km gt lv lw lx ly aw lz bi"><span id="c84b" class="ma mb it lw b gy mc md l me mf">op_labels = ['shyttte', 'moderate', 'good']<br/>category = [0.,4.,7.,10.]</span><span id="5559" class="ma mb it lw b gy mg md l me mf">movies_df['imdb_labels'] = pd.cut(movies_df['imdb_score'], labels=op_labels, bins=category, include_lowest=False)</span></pre><p id="c122" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这里创建了一个包含标签的新列“imdb_labels ”,让我们来看看——</p><pre class="kj kk kl km gt lv lw lx ly aw lz bi"><span id="6be0" class="ma mb it lw b gy mc md l me mf">print movies_df[['movie_title', 'imdb_score', 'imdb_labels']][209:220]</span><span id="10f5" class="ma mb it lw b gy mg md l me mf">&gt;&gt;&gt; </span><span id="4d2d" class="ma mb it lw b gy mg md l me mf">          movie_title     imdb_score     imdb_labels</span><span id="5841" class="ma mb it lw b gy mg md l me mf">209     Rio 2               6.4            moderate<br/>210     X-Men 2             7.5             good<br/>211     Fast Five           7.3             good<br/>212     Sherlock Holmes:..  7.5             good<br/>213     Clash of the...     5.8            moderate<br/>214     Total Recall        7.5             good<br/>215     The 13th Warrior    6.6            moderate<br/>216     The Bourne Legacy   6.7            moderate<br/>217     Batman &amp; Robin      3.7             shyttte<br/>218     How the Grinch..    6.0            moderate<br/>219     The Day After T..   6.4            moderate</span></pre><p id="ff0c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">为了充分利用<code class="fe nk nl nm lw b"><strong class="lb iu">pandas.cut()</strong></code>方法，您可以查看<a class="ae ky" href="https://pandas.pydata.org/pandas-docs/version/0.23.4/generated/pandas.cut.html" rel="noopener ugc nofollow" target="_blank">文档</a>。</p></div><div class="ab cl mh mi hx mj" role="separator"><span class="mk bw bk ml mm mn"/><span class="mk bw bk ml mm mn"/><span class="mk bw bk ml mm"/></div><div class="im in io ip iq"><h2 id="495e" class="ma mb it bd mo mp mq dn mr ms mt dp mu li mv mw mx lm my mz na lq nb nc nd ne bi translated">检测数据集中的异常值:</h2><p id="ab0b" class="pw-post-body-paragraph kz la it lb b lc nf ju le lf ng jx lh li nh lk ll lm ni lo lp lq nj ls lt lu im bi translated">大多数时候对于探索性数据分析(EDA)，<strong class="lb iu"> <em class="no">离群点检测</em> </strong>是一个重要的环节，因为，特定特征的离群点可能会扭曲真实情况，所以我们需要忽略它们。具体来说，当我们想要应用机器学习算法进行预测时，离群值可能会造成严重破坏。同时异常值甚至可以帮助我们进行异常检测。因此，让我们看看如何使用熊猫来检测这个特定数据框架中的异常值。</p><p id="5c3e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu"> <em class="no">海风盒子剧情:</em> </strong></p><p id="45af" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><em class="no">箱线图是一种基于中位数、四分位数和异常值的可视化数据分布的标准方法。</em>也许你已经知道这些量到底是什么，但我还是在下图中做了简短的回顾。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi np"><img src="../Images/f1dd58b12187d26887d0c8f87b438862.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*UHRkKdaQARo6vGNpH8y6bw.png"/></div></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk">Figure 1: Schematic of Box Plot (Source: Author)</figcaption></figure><p id="0dbb" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们可以使用 python 数据可视化库<a class="ae ky" href="https://seaborn.pydata.org/index.html" rel="noopener ugc nofollow" target="_blank"> Seaborn </a>来绘制这样的箱线图。让我们用方框图来描绘电影海报中的演员数量分布。</p><pre class="kj kk kl km gt lv lw lx ly aw lz bi"><span id="62b8" class="ma mb it lw b gy mc md l me mf">sns.boxplot(x=movies_df['facenumber_in_poster'], color='lime')<br/>plt.xlabel('No. of Actors Featured in Poster', fontsize=14)<br/>plt.show()</span></pre><p id="56bf" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">上面的代码产生了下面的图</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nq"><img src="../Images/b4ef162fd30880b95b19fdedc2a01e4e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*zn284QdGcJmDVqGBEkOwWw.png"/></div></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk">Figure 2: Too many outliers in number of faces featured in movie poster</figcaption></figure><p id="816e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">让我们检查一下电影海报中演员(面孔)数量最多的电影。</p><pre class="kj kk kl km gt lv lw lx ly aw lz bi"><span id="8cf7" class="ma mb it lw b gy mc md l me mf">print movies_df[['movie_title', 'facenumber_in_poster']].iloc[movies_df['facenumber_in_poster'].idxmax()]</span><span id="8770" class="ma mb it lw b gy mg md l me mf">&gt;&gt;&gt;<br/>movie_title             500 Days of Summer <br/>facenumber_in_poster                     43</span></pre><p id="9360" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">因此，电影'<a class="ae ky" href="https://en.wikipedia.org/wiki/500_Days_of_Summer" rel="noopener ugc nofollow" target="_blank">夏日 500 天</a>'中出现了最多的面孔(43 张)。让我们用<code class="fe nk nl nm lw b"><a class="ae ky" href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.describe.html" rel="noopener ugc nofollow" target="_blank"><strong class="lb iu">pandas.DataFrame.describe()</strong></a></code>的方法来看看这个专栏‘face number _ in _ poster’的一个基本统计细节。</p><pre class="kj kk kl km gt lv lw lx ly aw lz bi"><span id="15e9" class="ma mb it lw b gy mc md l me mf">print movies_df['facenumber_in_poster'].describe()</span><span id="f302" class="ma mb it lw b gy mg md l me mf">&gt;&gt;&gt;</span><span id="40e6" class="ma mb it lw b gy mg md l me mf">count    5030.000000<br/>mean        1.371173<br/>std         2.013576<br/>min         0.000000<br/>25%         0.000000<br/>50%         1.000000<br/>75%         2.000000<br/>max        43.000000</span></pre><p id="c8ad" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">有了这个，可能盒子的情节对你来说更有意义。</p><p id="232e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">另一种检测异常值的方法是使用 Z 分数。让我们看看它是如何工作的。</p><p id="a70b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu"> <em class="no"> Z 得分和离群值:</em> </strong></p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nr"><img src="../Images/746b55d20d798051a44f16ae5eef264f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*v5p7vyzCeJWK4MobWOni9g.png"/></div></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk">Figure 3: 1σ and 3σ Standard deviation on a normal distribution with 0 μ. (Source: Author)</figcaption></figure><p id="70ef" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu"> <em class="no"> Z 得分是一个数字(无量纲的),表示一个数据点相对于平均值的标准偏差。</em> Z 得分可以简单地定义为— </strong></p><p id="a694" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu"> <em class="no"> Z =(X-μ)/σ，其中μ为总体均值，σ为标准差，X 为总体中的一个元素。</em> </strong></p><p id="535c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">为了绘制下图，我使用了正态分布<code class="fe nk nl nm lw b"><a class="ae ky" href="https://docs.scipy.org/doc/numpy/reference/generated/numpy.random.normal.html" rel="noopener ugc nofollow" target="_blank">numpy.random.normal(</a>)</code>，在正态分布中，几乎所有的值(约 99.7%)都落在平均值的 3 σ偏差范围内(此处的图μ = 0)。我们可以使用 Z 得分来拒绝异常值的方法是考虑 Z 得分 3 个单位以内的数据点。可以使用下面的<code class="fe nk nl nm lw b">scipy.stats</code>为所有包含“非对象”类型数据的列完成此操作。</p><p id="dc6e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">1.检查数据框<strong class="lb iu">(</strong><a class="ae ky" href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.dtypes.html" rel="noopener ugc nofollow" target="_blank"><strong class="lb iu">data frame . dtypes</strong></a><strong class="lb iu">)中所有列的数据类型。</strong></p><pre class="kj kk kl km gt lv lw lx ly aw lz bi"><span id="3041" class="ma mb it lw b gy mc md l me mf">print "data types: \n", movies_df.dtypes</span><span id="2081" class="ma mb it lw b gy mg md l me mf">&gt;&gt;&gt;<br/>data types: <br/>color                         object<br/>director_name                 object<br/>num_critic_for_reviews       float64<br/>duration                     float64<br/>director_facebook_likes      float64<br/>actor_3_facebook_likes       float64<br/>actor_2_name                  object<br/>actor_1_facebook_likes       float64<br/>gross                        float64<br/>genres                        object<br/>actor_1_name                  object<br/>movie_title                   object<br/>num_voted_users                int64<br/>cast_total_facebook_likes      int64<br/>actor_3_name                  object<br/>facenumber_in_poster         float64<br/>plot_keywords                 object<br/>movie_imdb_link               object<br/>num_user_for_reviews         float64<br/>language                      object<br/>country                       object<br/>content_rating                object<br/>budget                       float64<br/>title_year                   float64<br/>actor_2_facebook_likes       float64<br/>imdb_score                   float64<br/>aspect_ratio                 float64<br/>movie_facebook_likes           int64</span></pre><p id="0b0e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">2.创建一个新的数据框，排除所有“对象”类型列<a class="ae ky" href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.select_dtypes.html" rel="noopener ugc nofollow" target="_blank"><strong class="lb iu">data frame . select _ dtypes</strong></a></p><pre class="kj kk kl km gt lv lw lx ly aw lz bi"><span id="52a6" class="ma mb it lw b gy mc md l me mf">print "shape before :", movies_df.shape</span><span id="345d" class="ma mb it lw b gy mg md l me mf">movies_df_num = movies_df.select_dtypes(exclude=['object'])</span><span id="08a8" class="ma mb it lw b gy mg md l me mf">print "shape after excluding object columns: ", movies_df_num.shape</span><span id="2f0d" class="ma mb it lw b gy mg md l me mf">&gt;&gt;&gt;</span><span id="8afc" class="ma mb it lw b gy mg md l me mf">shape before : (3756, 28)<br/>shape after excluding object columns:  (3756, 16)</span></pre><p id="cf88" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">3.从每列中选择位于 Z 得分 3 个单位内的元素</p><pre class="kj kk kl km gt lv lw lx ly aw lz bi"><span id="4f57" class="ma mb it lw b gy mc md l me mf">movies_df_Zscore = movies_df_num[(np.abs(stats.zscore(movies_df_num))&lt;3).all(axis=1)]</span><span id="3e22" class="ma mb it lw b gy mg md l me mf">print "shape after rejecting outliers: ", movies_df_Zscore.shape</span><span id="9576" class="ma mb it lw b gy mg md l me mf">&gt;&gt;&gt;</span><span id="e6bc" class="ma mb it lw b gy mg md l me mf">shape after rejecting outliers:  (3113, 16)</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ns"><img src="../Images/718262095af0898015c35d921d28aac8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*w-AuQgwdhmWmpCy1zqqxMg.png"/></div></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk">Figure 4: Box plot of number of faces featured in a movie poster. After applying the Z score method.</figcaption></figure><p id="a687" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们可以通过再次绘制“facenumber_in_poster”的方框图来检查上述步骤的效果。这里我们可以看到与图 2 相比的不同之处，在图 2 中，我们有一个考虑了“facenumber_in_poster”列中所有元素的方框图。</p></div><div class="ab cl mh mi hx mj" role="separator"><span class="mk bw bk ml mm mn"/><span class="mk bw bk ml mm mn"/><span class="mk bw bk ml mm"/></div><div class="im in io ip iq"><p id="4aea" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这些是人们可以准备用于分析的数据和应用机器学习算法进行预测的一些方法。有效地准备数据集对全面分析有很大帮助，我希望这篇文章能帮助你更有条理地准备数据集以供进一步分析。根据问题和数据集的不同，你可能需要决定、选择和重复这些过程来解释什么是影响，所以，祝你好运探索你的数据集。</p><p id="3197" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">保持坚强，干杯！！</p><p id="bcd8" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这篇文章使用的代码可以在我的<a class="ae ky" href="https://github.com/suvoooo/Machine_Learning/tree/master/datacleaning" rel="noopener ugc nofollow" target="_blank"> Github </a>上找到。</p><p id="cdf6" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><em class="no">在</em><a class="ae ky" href="https://www.linkedin.com/in/saptashwa/" rel="noopener ugc nofollow" target="_blank"><em class="no">Linkedin</em></a><em class="no">找我。</em></p></div></div>    
</body>
</html>