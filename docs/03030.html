<html>
<head>
<title>10x Faster Parallel Python Without Python Multiprocessing</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">没有 Python 多重处理，并行 Python 速度快 10 倍</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/10x-faster-parallel-python-without-python-multiprocessing-e5017c93cce1?source=collection_archive---------0-----------------------#2019-05-16">https://towardsdatascience.com/10x-faster-parallel-python-without-python-multiprocessing-e5017c93cce1?source=collection_archive---------0-----------------------#2019-05-16</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="ccbc" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">更快的 Python，无需重构代码</h2></div><p id="666d" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">虽然<a class="ae lb" href="https://docs.python.org/3/library/multiprocessing.html#module-multiprocessing" rel="noopener ugc nofollow" target="_blank"> Python 的多重处理库</a>已经成功地用于广泛的应用程序，但在这篇博客文章中，我们发现它在几个重要的应用程序类别中表现不佳，包括数值数据处理、有状态计算和带有昂贵初始化的计算。有两个主要原因:</p><ul class=""><li id="9db6" class="lc ld iq kh b ki kj kl km ko le ks lf kw lg la lh li lj lk bi translated">对数字数据的低效处理。</li><li id="3f42" class="lc ld iq kh b ki ll kl lm ko ln ks lo kw lp la lh li lj lk bi translated">缺少有状态计算的抽象(例如，无法在独立的“任务”之间共享变量)。</li></ul><p id="81a1" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><a class="ae lb" href="https://ray.io/" rel="noopener ugc nofollow" target="_blank"> <em class="lq"> Ray </em> </a> <em class="lq">是一个快速、简单的框架，用于构建和运行解决这些问题的分布式应用</em>。关于一些基本概念的介绍，请看<a class="ae lb" href="https://medium.com/@robertnishihara/modern-parallel-and-distributed-python-a-quick-tutorial-on-ray-99f8d70369b8" rel="noopener">这篇博文</a>。Ray 利用 Apache Arrow 提供高效的数据处理，并为分布式计算提供 task 和 actor 抽象。</p><p id="2f2a" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这篇博客文章对三个不容易用 Python 多处理表达的工作负载进行了基准测试，并比较了<a class="ae lb" href="https://github.com/ray-project/ray" rel="noopener ugc nofollow" target="_blank"> Ray </a>、Python 多处理和串行 Python 代码。请注意<a class="ae lb" href="http://www.frankmcsherry.org/graph/scalability/cost/2015/01/15/COST.html" rel="noopener ugc nofollow" target="_blank">务必始终与优化的单线程代码</a>进行比较。</p><p id="5f35" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在这些基准测试中，<a class="ae lb" href="https://ray.io/" rel="noopener ugc nofollow" target="_blank"><em class="lq"/></a><em class="lq">比串行 Python</em><strong class="kh ir"><em class="lq"/></strong><em class="lq">快 10–30x，</em> <strong class="kh ir"> <em class="lq">比多处理快 5–25x</em></strong><em class="lq">，比大型机器上的这两个</em>快 5–15x<strong class="kh ir"><em class="lq"/></strong><em class="lq">。</em></p><figure class="ls lt lu lv gt lw gh gi paragraph-image"><div class="gh gi lr"><img src="../Images/ab75bcc565432649c3a56eda06f2d5bd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1200/format:webp/1*BXnuxGm7vYUh1pfwbTy-XA.jpeg"/></div><figcaption class="lz ma gj gh gi mb mc bd b be z dk">On a machine with 48 physical cores, Ray is <strong class="bd md">9x</strong> faster than Python multiprocessing and <strong class="bd md">28x</strong> faster than single-threaded Python. Error bars are depicted, but in some cases are too small to see. Code for reproducing these numbers is available below. The workload is scaled to the number of cores, so more work is done on more cores (which is why serial Python takes longer on more cores).</figcaption></figure><p id="fbf8" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">基准测试使用<a class="ae lb" href="https://aws.amazon.com/ec2/instance-types/m5/" rel="noopener ugc nofollow" target="_blank"> m5 实例类型</a>在 EC2 上运行(m5.large 用于 1 个物理内核，m5.24xlarge 用于 48 个物理内核)。<a class="ae lb" href="https://gist.github.com/robertnishihara/2b81595abd4f50a049767a040ce435ab" rel="noopener ugc nofollow" target="_blank">运行所有基准测试的代码可从这里获得</a>。缩写片段包括在这篇文章中。主要区别在于，完整的基准测试包括 1)计时和打印代码，2)预热 Ray 对象存储的代码，以及 3)使基准测试适应较小机器的代码。</p><h1 id="9d60" class="me mf iq bd mg mh mi mj mk ml mm mn mo jw mp jx mq jz mr ka ms kc mt kd mu mv bi translated">基准 1:数字数据</h1><p id="6afb" class="pw-post-body-paragraph kf kg iq kh b ki mw jr kk kl mx ju kn ko my kq kr ks mz ku kv kw na ky kz la ij bi translated">许多机器学习、科学计算和数据分析工作负载大量使用大型数据阵列。例如，一个数组可能代表一个大型图像或数据集，应用程序可能希望有多个任务来分析该图像。高效处理数字数据至关重要。</p><p id="ad25" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">下面 for 循环的每一遍使用 Ray 花费<strong class="kh ir">0.84 秒</strong>，使用 Python 多处理花费<strong class="kh ir">7.5 秒</strong>，使用串行 Python 花费<strong class="kh ir">24 秒</strong>(在 48 个物理核上)。这种性能差距解释了为什么可以在 Ray 上构建像<a class="ae lb" href="https://github.com/modin-project/modin" rel="noopener ugc nofollow" target="_blank"> Modin </a>这样的库，而不能在其他库上构建。</p><p id="7444" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">用<a class="ae lb" href="https://ray.readthedocs.io/en/latest/" rel="noopener ugc nofollow" target="_blank">射线</a>看代码如下。</p><figure class="ls lt lu lv gt lw"><div class="bz fp l di"><div class="nb nc l"/></div><figcaption class="lz ma gj gh gi mb mc bd b be z dk">Code for a toy image processing example using Ray.</figcaption></figure><p id="980d" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">通过调用<code class="fe nd ne nf ng b">ray.put(image)</code>，大数组被存储在共享内存中，并且可以被所有工作进程访问，而无需创建副本。这不仅适用于数组，也适用于包含数组的对象(如数组列表)。</p><p id="486f" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">当工人执行<code class="fe nd ne nf ng b">f</code>任务时，结果再次存储在共享内存中。然后当脚本调用<code class="fe nd ne nf ng b">ray.get([...])</code>时，它创建由共享内存支持的 numpy 数组，而不必反序列化或复制值。</p><p id="bc5d" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这些优化之所以成为可能，是因为 Ray 使用了<a class="ae lb" href="https://arrow.apache.org/" rel="noopener ugc nofollow" target="_blank"> Apache Arrow </a>作为底层数据布局和序列化格式，以及<a class="ae lb" href="https://arrow.apache.org/docs/python/plasma.html" rel="noopener ugc nofollow" target="_blank"> Plasma 共享内存对象存储</a>。</p><p id="82a3" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">使用<a class="ae lb" href="https://docs.python.org/3/library/multiprocessing.html" rel="noopener ugc nofollow" target="_blank"> Python 多重处理</a>的代码如下所示。</p><figure class="ls lt lu lv gt lw"><div class="bz fp l di"><div class="nb nc l"/></div><figcaption class="lz ma gj gh gi mb mc bd b be z dk">Code for a toy image processing example using multiprocessing.</figcaption></figure><p id="b112" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这里的区别是 Python 多处理在进程间传递大型对象时使用 pickle 来序列化它们。这种方法要求每个进程创建自己的数据副本，这增加了大量的内存使用和昂贵的反序列化开销，Ray 通过使用<a class="ae lb" href="https://arrow.apache.org/" rel="noopener ugc nofollow" target="_blank"> Apache Arrow </a>数据布局和<a class="ae lb" href="https://ray-project.github.io/2017/10/15/fast-python-serialization-with-ray-and-arrow.html" rel="noopener ugc nofollow" target="_blank">零副本序列化</a>以及<a class="ae lb" href="https://arrow.apache.org/docs/python/plasma.html" rel="noopener ugc nofollow" target="_blank">等离子存储</a>来避免这种情况。</p><h1 id="dc91" class="me mf iq bd mg mh mi mj mk ml mm mn mo jw mp jx mq jz mr ka ms kc mt kd mu mv bi translated">基准 2:有状态计算</h1><p id="6869" class="pw-post-body-paragraph kf kg iq kh b ki mw jr kk kl mx ju kn ko my kq kr ks mz ku kv kw na ky kz la ij bi translated">需要在许多小工作单元之间共享大量“状态”的工作负载是对 Python 多处理提出挑战的另一类工作负载。这种模式非常常见，我在这里用一个玩具流处理应用程序来说明它。</p><figure class="ls lt lu lv gt lw gh gi paragraph-image"><div class="gh gi lr"><img src="../Images/6292719950e81912e5e97439840ef432.png" data-original-src="https://miro.medium.com/v2/resize:fit:1200/format:webp/1*zeYrD-RHIQoK8B8GgbX3xg.jpeg"/></div><figcaption class="lz ma gj gh gi mb mc bd b be z dk">On a machine with 48 physical cores, Ray is <strong class="bd md">6x</strong> faster than Python multiprocessing and <strong class="bd md">17x</strong> faster than single-threaded Python. Python multiprocessing doesn’t outperform single-threaded Python on fewer than 24 cores. The workload is scaled to the number of cores, so more work is done on more cores (which is why serial Python takes longer on more cores).</figcaption></figure><p id="6573" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">状态通常封装在 Python 类中，<a class="ae lb" href="https://ray.readthedocs.io/en/latest/" rel="noopener ugc nofollow" target="_blank"> Ray </a>提供了一个<a class="ae lb" href="https://ray.readthedocs.io/en/latest/actors.html" rel="noopener ugc nofollow" target="_blank"> actor 抽象</a>，这样类就可以在并行和分布式环境中使用。相比之下，Python 多处理并没有提供并行化 Python 类的自然方法，因此用户经常需要在<code class="fe nd ne nf ng b">map</code>调用之间传递相关状态。这种策略在实践中可能很难实现(许多 Python 变量不容易序列化),而且当它起作用时可能会很慢。</p><p id="dc1e" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">下面是一个玩具示例，它使用并行任务一次处理一个文档，提取每个单词的前缀，并在最后返回最常见的前缀。前缀计数存储在 actor 状态中，并根据不同的任务而变化。</p><p id="0d3e" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这个例子用 Ray 的<strong class="kh ir"> 3.2s </strong>，Python 多处理的<strong class="kh ir"> 21s </strong>，串行 Python 的<strong class="kh ir"> 54s </strong>(在 48 个物理核上)。</p><p id="55a6" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><a class="ae lb" href="https://github.com/ray-project/ray" rel="noopener ugc nofollow" target="_blank">射线</a>版本如下图。</p><figure class="ls lt lu lv gt lw"><div class="bz fp l di"><div class="nb nc l"/></div><figcaption class="lz ma gj gh gi mb mc bd b be z dk">Code for a toy stream processing example using Ray.</figcaption></figure><p id="4e6b" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">Ray 在这里表现得很好，因为 Ray 的抽象符合当前的问题。这个应用程序需要一种在分布式环境中封装和改变状态的方法，而 actors 符合这个要求。</p><p id="eee0" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><a class="ae lb" href="https://docs.python.org/3/library/multiprocessing.html" rel="noopener ugc nofollow" target="_blank">多重处理</a>版本如下。</p><figure class="ls lt lu lv gt lw"><div class="bz fp l di"><div class="nb nc l"/></div><figcaption class="lz ma gj gh gi mb mc bd b be z dk">Code for a toy stream processing example using multiprocessing.</figcaption></figure><p id="6070" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这里的挑战是<code class="fe nd ne nf ng b">pool.map</code>执行无状态函数，这意味着在一个<code class="fe nd ne nf ng b">pool.map</code>调用中产生的任何变量，如果您想在另一个<code class="fe nd ne nf ng b">pool.map</code>调用中使用，都需要从第一个调用中返回，并传递给第二个调用。对于小对象来说，这种方法是可以接受的，但是当需要共享大的中间结果时，传递它们的成本是令人望而却步的(注意，如果变量是在线程之间共享的，这就不正确了，但是因为它们是跨进程边界共享的，所以必须使用像<a class="ae lb" href="https://docs.python.org/3/library/pickle.html" rel="noopener ugc nofollow" target="_blank"> pickle </a>这样的库将变量序列化为一个字节串)。</p><p id="951e" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">因为它必须传递如此多的状态，多处理版本看起来非常笨拙，最终只实现了比串行 Python 小的加速。实际上，您不会编写这样的代码，因为您不会使用 Python 多重处理进行流处理。相反，您可能会使用专用的流处理框架。这个例子表明 Ray 非常适合构建这样的框架或应用程序。</p><p id="4f6d" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">有一点需要注意，使用 Python 多处理有很多方法。在这个例子中，我们与<code class="fe nd ne nf ng b">Pool.map</code>进行比较，因为它给出了最接近的 API 比较。在这个例子中，通过启动不同的进程并在它们之间设置多个<a class="ae lb" href="https://docs.python.org/3/library/multiprocessing.html#exchanging-objects-between-processes" rel="noopener ugc nofollow" target="_blank">多重处理队列</a>，应该可以获得更好的性能，但是这导致了复杂而脆弱的设计。</p><h1 id="d941" class="me mf iq bd mg mh mi mj mk ml mm mn mo jw mp jx mq jz mr ka ms kc mt kd mu mv bi translated">基准 3:昂贵的初始化</h1><p id="3a47" class="pw-post-body-paragraph kf kg iq kh b ki mw jr kk kl mx ju kn ko my kq kr ks mz ku kv kw na ky kz la ij bi translated">与前面的例子相反，许多并行计算不一定需要在任务之间共享中间计算，但无论如何都会从中受益。当状态初始化代价很高时，甚至无状态计算也可以从共享状态中受益。</p><p id="d5d6" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">下面是一个例子，我们想从磁盘加载一个保存的神经网络，并用它来并行分类一堆图像。</p><figure class="ls lt lu lv gt lw gh gi paragraph-image"><div class="gh gi lr"><img src="../Images/557a63044e5419cb8a9d68066e066122.png" data-original-src="https://miro.medium.com/v2/resize:fit:1200/format:webp/1*hvBAjp4pyXUAwWVA5uk9-g.jpeg"/></div><figcaption class="lz ma gj gh gi mb mc bd b be z dk">On a machine with 48 physical cores, Ray is <strong class="bd md">25x</strong> faster than Python multiprocessing and <strong class="bd md">13x</strong> faster than single-threaded Python. Python multiprocessing doesn’t outperform single-threaded Python in this example. Error bars are depicted, but in some cases are too small to see. The workload is scaled to the number of cores, so more work is done on more cores. In this benchmark, the “serial” Python code actually uses multiple threads through TensorFlow. The variability of the Python multiprocessing code comes from the variability of repeatedly loading the model from disk, which the other approaches don’t need to do.</figcaption></figure><p id="f54a" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这个例子用 Ray 的<strong class="kh ir"> 5s </strong>，Python 多处理的<strong class="kh ir"> 126s </strong>，串行 Python 的<strong class="kh ir"> 64s </strong>(在 48 个物理核上)。在这种情况下，串行 Python 版本使用许多内核(通过 TensorFlow)来并行化计算，因此它实际上不是单线程的。</p><p id="1476" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">假设我们已经通过运行以下代码创建了模型。</p><figure class="ls lt lu lv gt lw"><div class="bz fp l di"><div class="nb nc l"/></div><figcaption class="lz ma gj gh gi mb mc bd b be z dk">Code for saving a neural network model to disk.</figcaption></figure><p id="ca54" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">现在，我们希望加载模型，并使用它来分类一堆图像。我们分批进行，因为在应用程序中，图像可能不会同时可用，图像分类可能需要与数据加载并行进行。</p><p id="30cf" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><a class="ae lb" href="https://github.com/ray-project/ray" rel="noopener ugc nofollow" target="_blank">射线</a>版本如下。</p><figure class="ls lt lu lv gt lw"><div class="bz fp l di"><div class="nb nc l"/></div><figcaption class="lz ma gj gh gi mb mc bd b be z dk">Code for a toy classification example using Ray.</figcaption></figure><p id="881f" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">加载模型非常慢，我们只想做一次。Ray 版本通过在 actor 的构造函数中加载一次模型来分摊成本。如果模型需要放在 GPU 上，那么初始化会更加昂贵。</p><p id="a462" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">多处理版本较慢，因为它需要在每次 map 调用中重新加载模型，因为映射的函数被假定为无状态的。</p><p id="7c65" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><a class="ae lb" href="https://docs.python.org/3/library/multiprocessing.html" rel="noopener ugc nofollow" target="_blank">多重处理</a>版本如下。请注意，在某些情况下，可以使用<code class="fe nd ne nf ng b">initializer</code>到<code class="fe nd ne nf ng b">multiprocessing.Pool</code>的参数来实现这一点。然而，这限于这样的设置，其中初始化对于每个过程是相同的，并且不允许不同的过程执行不同的设置功能(例如，加载不同的神经网络模型)，并且不允许不同的任务针对不同的工作者。</p><figure class="ls lt lu lv gt lw"><div class="bz fp l di"><div class="nb nc l"/></div><figcaption class="lz ma gj gh gi mb mc bd b be z dk">Code for a toy classification example using multiprocessing.</figcaption></figure><p id="4ddd" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们在所有这些例子中看到的是，Ray 的性能不仅仅来自于它的性能优化，还来自于拥有适合手头任务的抽象。有状态计算对许多应用程序都很重要，将有状态计算强制转换成无状态抽象是有代价的。</p><h1 id="c56a" class="me mf iq bd mg mh mi mj mk ml mm mn mo jw mp jx mq jz mr ka ms kc mt kd mu mv bi translated">运行基准测试</h1><p id="b126" class="pw-post-body-paragraph kf kg iq kh b ki mw jr kk kl mx ju kn ko my kq kr ks mz ku kv kw na ky kz la ij bi translated">在运行这些基准测试之前，您需要安装以下软件。</p><pre class="ls lt lu lv gt nh ng ni nj aw nk bi"><span id="63b4" class="nl mf iq ng b gy nm nn l no np">pip install numpy psutil ray scipy tensorflow</span></pre><p id="0f3b" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">然后<a class="ae lb" href="https://gist.github.com/robertnishihara/2b81595abd4f50a049767a040ce435ab" rel="noopener ugc nofollow" target="_blank">上面所有的数字都可以通过运行这些脚本来重现。</a></p><p id="077b" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">如果你安装<code class="fe nd ne nf ng b">psutil</code>有困难，那么尝试使用<a class="ae lb" href="https://www.anaconda.com/distribution/#download-section" rel="noopener ugc nofollow" target="_blank"> Anaconda Python </a>。</p><p id="0ba0" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">最初的性能指标评测是在 EC2 上运行的，使用的是 m5 实例类型(1 个物理内核使用 m5.large，48 个物理内核使用 m5.24xlarge)。</p><p id="928d" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">为了使用正确的配置在 AWS 或 GCP 上启动一个实例，您可以使用<a class="ae lb" href="https://docs.ray.io/en/latest/cluster/cloud.html" rel="noopener ugc nofollow" target="_blank">射线集群启动器</a>并运行以下命令。</p><pre class="ls lt lu lv gt nh ng ni nj aw nk bi"><span id="75c0" class="nl mf iq ng b gy nm nn l no np">ray up config.yaml</span></pre><p id="6a95" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这里提供的<a class="ae lb" href="https://gist.github.com/robertnishihara/2b81595abd4f50a049767a040ce435ab#file-config-yaml" rel="noopener ugc nofollow" target="_blank">就是一个<code class="fe nd ne nf ng b">config.yaml</code>的例子</a>(用于启动一个 m5.4x 大型实例)。</p><h1 id="6eb5" class="me mf iq bd mg mh mi mj mk ml mm mn mo jw mp jx mq jz mr ka ms kc mt kd mu mv bi translated">关于雷的更多信息</h1><p id="bdc2" class="pw-post-body-paragraph kf kg iq kh b ki mw jr kk kl mx ju kn ko my kq kr ks mz ku kv kw na ky kz la ij bi translated">虽然这篇博客文章关注的是<a class="ae lb" href="https://github.com/ray-project/ray" rel="noopener ugc nofollow" target="_blank"> Ray </a>和 Python 多处理之间的基准测试，但是苹果之间的比较是具有挑战性的，因为这些库不是非常相似。差异包括以下几点。</p><ul class=""><li id="d5f4" class="lc ld iq kh b ki kj kl km ko le ks lf kw lg la lh li lj lk bi translated">Ray 是为可伸缩性而设计的，可以在笔记本电脑和集群上运行相同的代码(多处理只能在单台机器上运行)。</li><li id="1516" class="lc ld iq kh b ki ll kl lm ko ln ks lo kw lp la lh li lj lk bi translated">Ray 工作负载会自动从机器和进程故障中恢复。</li><li id="38ab" class="lc ld iq kh b ki ll kl lm ko ln ks lo kw lp la lh li lj lk bi translated">Ray 是以一种与语言无关的方式设计的，并且初步支持<a class="ae lb" href="https://github.com/ray-project/ray/tree/master/java" rel="noopener ugc nofollow" target="_blank"> Java </a>。</li></ul><p id="05f6" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">更多相关链接在下面。</p><ul class=""><li id="1572" class="lc ld iq kh b ki kj kl km ko le ks lf kw lg la lh li lj lk bi translated">GitHub 上的<a class="ae lb" href="https://github.com/ray-project/ray" rel="noopener ugc nofollow" target="_blank">代码库。</a></li><li id="48de" class="lc ld iq kh b ki ll kl lm ko ln ks lo kw lp la lh li lj lk bi translated"><a class="ae lb" href="https://docs.ray.io/en/master/index.html" rel="noopener ugc nofollow" target="_blank">射线文档</a>。</li><li id="e586" class="lc ld iq kh b ki ll kl lm ko ln ks lo kw lp la lh li lj lk bi translated">在<a class="ae lb" href="https://discuss.ray.io/" rel="noopener ugc nofollow" target="_blank">雷论坛</a>上提问。</li><li id="f733" class="lc ld iq kh b ki ll kl lm ko ln ks lo kw lp la lh li lj lk bi translated">Ray 包括用于<a class="ae lb" href="https://docs.ray.io/en/latest/rllib/index.html" rel="noopener ugc nofollow" target="_blank">缩放强化学习</a>、<a class="ae lb" href="https://docs.ray.io/en/latest/tune/index.html" rel="noopener ugc nofollow" target="_blank">缩放超参数调整</a>、<a class="ae lb" href="https://docs.ray.io/en/latest/serve/index.html" rel="noopener ugc nofollow" target="_blank">缩放模型服务</a>和<a class="ae lb" href="https://docs.ray.io/en/latest/data/dataset.html" rel="noopener ugc nofollow" target="_blank">缩放数据处理</a>的库。</li><li id="f497" class="lc ld iq kh b ki ll kl lm ko ln ks lo kw lp la lh li lj lk bi translated">Ray 包括一个<a class="ae lb" href="https://docs.ray.io/en/latest/cluster/cloud.html" rel="noopener ugc nofollow" target="_blank">集群发射器</a>用于在 AWS 和 GCP 上发射集群。</li><li id="669d" class="lc ld iq kh b ki ll kl lm ko ln ks lo kw lp la lh li lj lk bi translated">雷<a class="ae lb" href="https://ray.io/" rel="noopener ugc nofollow" target="_blank">网页</a>。</li></ul></div></div>    
</body>
</html>