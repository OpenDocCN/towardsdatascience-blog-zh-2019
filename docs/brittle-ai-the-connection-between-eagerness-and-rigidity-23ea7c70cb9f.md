# 脆弱的人工智能:渴望和僵化之间的联系

> 原文：<https://towardsdatascience.com/brittle-ai-the-connection-between-eagerness-and-rigidity-23ea7c70cb9f?source=collection_archive---------21----------------------->

![](img/d0f34d93821aff2326ca5bb9ca2e9be2.png)

PatiencePhoto by [Michel Porro](https://unsplash.com/@michelporro?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText) on [Unsplash](https://unsplash.com/s/photos/patience?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)

# **AI 为什么脆？**

今天困扰人工智能的是脆性。有人推出了这个神奇的人工智能程序，它在一些任务上表现出超人的性能，但对输入的微小调整就让它屈服了。在识别图像中的物体方面表现出色的人工智能系统可以被欺骗，通过改变单个像素来看到不存在的长颈鹿。自动驾驶汽车，它尖叫着“AI！！!"比其他任何人都更容易被仅仅是贴纸的东西蒙骗，在错误的道路上行驶。

是什么让 AI 变脆了？我提出了一个被忽视的原因，我认为这是这种脆弱性的关键:对*热切方法的严重依赖，这是我从编程语言中借用的术语。渴望是尽早决定，除了关闭选择和混合多种选择的大门。渴望是板球击球手丑陋的预先思考的镜头，是新生的高斯林将第一个移动的物体视为妈妈的“决定”，是阿尔伯特·爱因斯坦哀叹的信念诱导的认知固定性，当他提出 19 世纪物理学停滞的发生是因为物理学家“在经典力学中看到了所有物理学的坚实和最终的基础，是的，确实是所有自然科学的基础”。*

在构建计算机系统的过程中，渴望表现为一种信念，让人联想到认知的固定性，即系统的某些方面是固有的，是一成不变的，因此我们必须在一开始就设计好，然后冻结。一些这样的假设是没有根据的，现有的系统没有这样的假设。例子包括“一种编程语言有固定的语法”“一个深度学习系统的神经网络有固定的形状”；现代编程语言和 AutoML 分别显示了这种假设的谬误。其他假设弥漫在今天的人工智能中，有些是因为它们看起来如此明显地固定，例如 backprop 中的损失函数，有些是因为将某些东西视为固定是方便的，有些是因为我们还没有想出如何改变这些。此外，我们急切地将假设融入到问题的定义中，正如我们希望我们的情感分类系统将电影评论分为积极和消极两类时所做的那样(但是，唉，评论作者不合作，他们添加细微差别，列出好和坏的方面，而不是一劳永逸地给我们一个好-坏光谱上的单点)。

脆性源于对语义不连续性的错误处理。社会学家 Eviatar Zerubavel 的优秀著作《细线》充满了任意不连续的例子:如果两个点相隔几英寸，它们之间有不同的法律，如果相隔几分钟，相隔几分钟的两个时间看起来不一样。加里·马库斯认为，常识是人工智能中缺失的成分。常识往往依赖于这种不连续性:动物在死亡前几分钟还活着，但在死亡后几分钟还活着，在鸡肉盘中放蔬菜是可以的，但在素食盘中放鸡肉却不行。

一种使用其对类似情况的了解来推理一种情况的技术——基于案例的推理和想到的向量空间表示——最好对相似性有高超的掌握。脆性将是一种技术，这种技术将两种食谱之间的相似性建立在共享成分的比例上，因为这种技术对单一成分越过的重要界限不敏感:围绕素食、围绕犹太食品、围绕无花生食品的界限。健康食品和不健康食品之间的界限更模糊，也更典型，但即使在这里，重叠的成分列表也可能与这种粗略划分两边的食品相同。

如果一个计算机系统对分界线两侧的两点使用相同的表示，我们说该表示对该边界不敏感，至少在那里是如此。渴望导致了这种代表性的崩溃，抹去了界限，如果它建立了什么样的区别需要关心，因此什么样的区别可以安全地忽略的话。

在这篇文章中，我从显著性决策和随之而来的代表性崩溃(1)开始，接着是渴望和僵化在两个领域的相互作用:动物行为中的固定动作模式(2)和编程语言(3)。并非所有的人工智能都渴望，许多最近的发展，如 BERT，AutoML 和 AlphaZero，比他们改进的系统更有耐心(4)，但许多人工智能链，包括这三个，保留了大量的渴望和随之而来的脆弱性(5)。下一篇文章将描述展现出某种耐心的算法，从我与丹·罗斯和锡德·米塔尔的合作，到我与道格拉斯·霍夫施塔特在一个名为[的认知架构上的合作。](https://cogsci.indiana.edu/pub/Seqsee%20--%20double%20sided.pdf)

我应该强调，我的目标不是诋毁渴望；渴望有它的用处，如果我们试图消除它，我们的工具箱会变得更穷。我的目标是指出效率和刚性之间的权衡，并建议如果我们理解脆性在哪里蔓延，那么在保持效率的同时保持灵活性是可能的。

# **1。显著性决策和表征崩溃**

我们并不代表世界的全部细节——要代表的东西太多了，我们忽略了大多数微小的差异。对变化视而不见的现象证明了我们表征的简单性:我们不会注意到根本性的变化，甚至是如此彻底的变化，以至于我们刚才与之交谈的人被另一个人取代了。在一个变化盲的例子中，一名实验者向一名路人询问去一栋建筑的方向。在路人完成他的回答之前，另外两个实验者扛着一扇大门闯进了他们中间，在混乱中，其中一个扛门的人和原来的实验者交换了位置。令人惊讶的是，过路人并没有察觉到这种转换，从而强调了他所形成的不完整的表象。变化盲是一个经过彻底测试的强健现象，你可以在这里观看视频。

简而言之，我们关注对我们重要的事情。威利安·詹姆士很好地抓住了这一点:

> 让四个人去欧洲旅行。一个人只能带回家如画的印象——服装和颜色、公园和风景、建筑作品、图画和雕像。对另一个人来说，这一切都不存在；距离和价格，人口和排水系统的安排，门和窗户的紧固，和其他有用的统计数据将取代它们的位置。第三个会给一个丰富的剧院，餐厅，公共舞会，除此之外什么也没有；而第四将可能是如此包裹在自己的主观沉思，告诉比几个他通过的地方的名字。每个人都从大量呈现的对象中选择了适合自己兴趣的对象，并由此获得了经验。

通过选择重要的东西，我们含蓄地决定了我们可以忽略什么。仅仅在这些不重要的细节上不一致的截然不同的情况因此可以被一致地表示出来。一个普通的袖珍计算器的“记忆”功能就是一个极好的例子。计算器的内存只够存储三个数字，但它可以“跟踪”数百万个数字，并报告它们的总和、平均值和标准偏差。它实现这一壮举的方式是，它不是跟踪所有的数字——这些数字太多了，无法跟踪——而是记住三个量:它看到了多少个数字，它们的总和，以及它们的平方和。这三个*总结*足以计算出现在已经被遗忘很久的序列的标准差。
因此，不同的数字序列可能导致相同的状态。因此，如果它看到了数字 1、5、6、8 和 8，它会记住这五个数字，它们的和是 28，它们的平方和是 190。相反，如果它看到 3、4、4、7 和 10，它会达到相同的状态。因此，这两个不同的序列合并成一个单一的表示。注意，对于它支持的计算，这两个序列是等价的。对于不同的任务，比如说计算几何平均值，汇总表示是不够的。

这种极端的减少在计算器的正常使用中很难察觉，但也不是完全没有问题。它会导致计算器支持的一个操作出现奇怪的行为。为了告诉计算器要计算的一组数字，我们对每个数字按“M+”。另一个标有“M-”的按钮会删除一个数字，以防不小心输入了一个数字。在上面的例子中，如果我们从集合{1，5，6，8，8}中去掉 20(事实上它并不在那里，这个事实必然会在计算器上丢失)，新的状态是:四个数字，它们的和是 8，它们的平方和是-210。奇怪的结果，因为平方和总是正的。稍微超出正常的使用范围，我们就会看到这个优雅而高效的算法中令人想起的漏洞。

原始的一组数字将永久丢失，并且无法从压缩版本中恢复。生成表示(即数字序列)所消耗的成分已经完全融合到最终的表示(三个摘要)中。这种不可逆转的崩溃对我的论点很重要，我们稍后将看到人工智能系统如何做出急切的显著决策，并丢弃“无关紧要的细微差别”，这些细微差别最终证明并不那么无关紧要。

在崩溃的“等价”情况下隐藏的危险是，尽管这种崩溃成为一种节俭的表现是有效的，但在现实世界中，等价是短暂的。在一个世界中，两个国际象棋位置可能是等价的——比如说，在标准国际象棋的世界中——但在一个略有不同的世界中，这些位置可能相距数英里——比如说，等级膨胀国际象棋，这是我发明的一种国际象棋变体，棋子不是在第八行提升，而是在第七行提升。或者，对于一个不需要改变规则的更轻微的变化，对于一个专业棋手来说，当与一个新手(他天生缺乏利用微妙弱点的专业知识)对弈时，两个位置实际上可能是相等的，但是当与卡斯帕罗夫对弈时，同样的两个位置可能是截然不同的。

# **2。极度渴望:基因中的选择**

舞台魔术师兼哲学家丹尼尔·丹尼特喜欢指出，魔术对观众来说很难理解，因为当观众认为魔术开始时，魔术师已经完成了魔术。我们的一些“决定”和选择也可能发生同样的情况，这些决定和选择可能早在出生之前就已经为我们做出了，动物世界提供了一些很好的例证。

Sphex 黄蜂有一个奇怪的仪式，很好地适应了它的环境。道格拉斯·霍夫施塔特在*哥德尔、埃舍尔和巴赫*中引用了这种无脑者和智者的奇怪组合:

> 当产卵的时间到了，黄蜂 Sphex 为此建造了一个洞穴，并找到了一只蟋蟀，她用这种方式刺它，使它瘫痪但不杀死它。她把蟋蟀拖进洞穴，在旁边产下卵，关上洞穴，然后飞走，再也没有回来。在适当的时候，卵孵化，黄蜂幼虫以瘫痪的蟋蟀为食，它没有腐烂，一直被保存在黄蜂相当于深度冷冻的地方。对人类来说，这样一个精心组织的、看似有目的的例行程序传达了一种令人信服的逻辑和思考的味道——直到更多的细节被检验。例如，黄蜂的惯例是把瘫痪的蟋蟀带到洞穴，放在门槛上，进去看看一切正常，出来，然后把蟋蟀拖进去。如果蟋蟀被移动了几英寸远，而黄蜂正在里面进行初步检查，黄蜂从洞穴出来后，会把蟋蟀带回门槛，但不是在里面，然后会重复进入洞穴的准备程序，以确保一切正常。如果当黄蜂在里面时，蟋蟀又被移开几英寸，她会再一次把蟋蟀移到门槛上，重新进入洞穴做最后的检查。黄蜂从没想过把蟋蟀直接拉进来。有一次，这个过程重复了四十次，总是得到同样的结果。

黄蜂在这件事上没有真正的选择。它不能选择不验证陋居的安全性——这个决定在她出生前几千年就已经做出了，编码在她的基因中(或者更准确地说，是基因与黄蜂的宏观和微观环境的相互作用，但这并没有改变我的论点)。

这种硬编码行为很常见。在斑尾鹟养父母的巢中，一只新生的早期孵出的布谷鸟，通过有目的地滚动和投掷巢中的蛋来杀死它未孵化的鹟“兄弟姐妹”。与其说它选择这样做，不如说它感到懊悔。另一个著名的例子是灰雁本能地与它们看到的第一个移动物体结合——同样不是有意识的选择。

我们可以说这种*固定的行动模式*在动物的大脑中是根深蒂固的。它们不同寻常之处在于它们相对来说不受环境的影响。不变行为是可预测的，这可能导致它们被人类或其他动物利用。如果环境改变了，这样的行为就变得不适应了。因此，在复杂动物中生存下来的固定行为对于生命来说是必不可少的，或者在速度(即缺乏学习)至关重要的地方。一个这样的例子是人类新生儿的吮吸反射，当父母的贿赂和哄骗不太可能有效时，它保持良好的喂养。

如前一节所述，等效是短暂的，我们看到情况的不良影响被隐含地视为等效，因此值得同样的反应。正如诺贝尔奖得主尼科·丁伯根用银鸥展示的那样，银鸥的父母喙上有一个红点，当被雏鸟啄时，父母会给雏鸟喂食，雏鸟会强迫性地啄任何红点甚至黑点，即使那些点是在棍子上，而不是在喙上。上面画有圆点的棍子在自然界是不存在的，没有理由增加任何机械来处理那种情况。

在基因中编码行为是热切的。进化预测到了——很有能力，但没有理解——一个物种的动物可能面临的一些情况，并将某些触发因素与特定行为联系起来。这种行为可以拯救生命，并且可以有效地实施，但对于我们人类乐于称之为智能的东西来说，这是不够的。

## 对大脑发育和性别决定有耐心

这些例子来自《依赖基因》一书[(感谢@freerecall 推荐！).](https://en.wikipedia.org/wiki/The_Dependent_Gene)

在胚胎成长为成人的过程中，大脑与各种“外围设备”相连:眼睛、耳朵、四肢等等。但是对于每种有多少，信息是如何存储的呢？令人惊讶的答案是，也许不是，这种联系是机会主义的。大脑抓住一切可以利用的东西，通过它们的化学特征吸引潜在的目标；没有连接起来的神经元得不到“营养因子”化学物质并枯萎。如果更少(因为意外或实验操纵)，它们被连接起来，每个得到更多的大脑处理；如果有更多，那也很好。不需要硬编码“分支数量”——这可以是运行时的决定。

同样，我们认为个体的性别是固定的和固有的。然而，对于珊瑚鱼来说，一只雄性鱼控制着一群雌性鱼。当雄性死去，最大的雌性，在几个小时内，[变成雄性](https://www.ncbi.nlm.nih.gov/pubmed/17788814)，完成精液的产生。

## 软件解决方案

与硬编码动作模式的盲目能力相比，“软件解决方案”提供了一个更灵活的系统来组织从刺激到动作的映射。这里的类比是，计算机硬件可以支持不同的软件。如果我们可以将触发器与一些内部符号挂钩，并将它们与动作挂钩，而不是将触发器和结果动作硬连接在一起，这种松散耦合将像在计算机编程中一样实现间接性，我们将在下一节中看到这一点。人类婴儿并不是生来就被硬编码为英语、汉语或原始印欧语，但是我们可以在这些设置中的任何一个或几个设置中对其进行配置。这样的配置并不急切——其环境的特殊性将允许婴儿说英语或克林贡语。一个出生时就有任何特殊天赋的婴儿在当今世界将会是一个不适应的人。

进化并没有预料到当今世界所需要的许多职业能力:小鸡性别鉴定师、爵士乐教练、迪斯尼世界的公主、保险承保人等等。目前还不清楚如何将基因和蛋白质表达的正确序列连接起来，以产生这些职业所必需的行动模式。这种灵活性似乎在很大程度上归功于语言和形成抽象、命名具体和抽象事物以及引用这些抽象的能力。接下来，我们将看到一组几乎相同的附加功能是如何在编程语言中实现灵活性的。

# **3。耐心使编程语言更加灵活**

我们倾向于假设任何编程语言都有固定的语法。事实上，传统编程语言的语法被正式指定为语法，任何不符合这种严格语法的程序都是无效的，不会被编译。由于其固定的语法，即使研究 C++程序的一个很小的片段，将它分割成记号，并将这些记号分类为变量、函数调用或其他东西，都是可能的。

这种“一种语言一种语法”的假设被一些所谓的*动态*编程语言*打破了——或者说粉碎了。在 Perl 这种语言中，程序员可以切换到完全不同的语法，甚至在一个文件中混合几种语法。标准的 Perl 语法充斥着符号%、$、和@，而且词序很重要:像任何其他编程语言一样，语句“a=b”不同于“b=a”。虽然 Perl 的设计者没有预见到用格式良好的语法拉丁语(通过-um 和-o 这样的大小写结尾实现词序的流动性)编码的渴望，但他们预见到了 Perl 的灵活性。漫威在达米安·康威的[大师展示了这个完全合法的 Perl 程序的拉丁语编程](http://users.monash.edu/~damian/papers/HTML/Perligata.html)，它使用被称为厄拉多塞筛的算法一个接一个地打印所有的质数。正如康威博士指出的，如果你必须问为什么有人可能希望用拉丁语编程，答案对你来说不太可能有意义。*

```
use Lingua::Romana::Perligata;
maximum inquementum tum biguttam egresso scribe.
meo maximo vestibulo perlegamentum da.
da duo tum maximum conscribementa meis listis.
dum listis decapitamentum damentum nexto
fac sic
    nextum tum novumversum scribe egresso.
    lista sic hoc recidementum nextum cis
    vannementa da listis.
cis.
```

在我们考虑是什么实现了这种灵活性，这种中途改变语法的能力之前，让我们看两个进一步的例子，对比传统语言的刚性和 Perl 的流动性。

首先是变量的*类型*的概念(即变量是否存储整数、字符串等等)，以及传统语言坚持在运行程序之前(用技术术语来说，“在编译时”)知道每个变量的类型，这种坚持导致它还要求知道每个数组的类型，并且该数组的所有成员共享一个类型。相比之下，Perl 是悠闲的，在编译时不需要知道变量的类型。当它运行那一行代码时，它只需要知道类型，如果一个数组包含不相关类型的混合，没有问题。

第二个区别要深刻得多，因为它涉及到语言如何在内存中表示对象，如何为这些对象分派方法，如何构造一个类的新对象。这些问题是语言设计的核心，对于任何语言来说都是不可避免的。但是对于像 Perl 和 Python 这样的语言，使用所谓的元类，即使这样我们也可以改变，我们可以在一个程序中自由地混合几种类型的对象。在这里，我们也看到，我们认为对于特定语言来说是铁板一块的东西，实际上是可以混合搭配的。

所有这些因素使得用动态语言编写代码变得更加简单。这种灵活性可能会有问题，但这不是我们在这里关心的问题。问题是，对于由数百名程序员执行的超大型项目，如果不同的程序员选择不同的方法来实现相同的目标，这种灵活性可能是灾难性的。正如 Perl 的创造者拉里·沃尔喜欢说的那样，Perl 给了你足够的绳索来搬起石头砸自己的脚。但是，我们不要让这分散我们对手头业务的注意力，理解灵活性的起源。

顺便说一下，在编程语言中，早和晚的区别有好几个名称。“早期”通常被称为急切或编译类型或静态，而“后期”被称为懒惰或运行时或动态。

**刚性来源**

传统编程语言的大部分刚性来自于*静态分析*——在编译过程中，在将程序翻译成机器代码的同时对其进行分析。这个过程自然是“早期”的——在它运行任何代码之前。这个过程删除了“不相关的”信息——它通过将“等同的”程序映射到相同的机器代码来折叠它们。

正如您可能猜到的，不相关的信息对于实现上面讨论的灵活性是必不可少的。那么这个不相关的信息是什么呢？名字。变量名、函数名和类名。除了替换这些名称之外，两个无法区分的程序将产生相同的机器代码。

但是等等。只有当我们不能以任何方式引用变量名时，两个具有不同变量名的程序才是等价的。那么，在这些编程语言中，我们不能写“对于每个名字包含 *x、*的变量，将值增加 1”。

这里的刚性来自于强加的等价。通过将这种等价性分割开来，仅仅通过存储变量名和数据类型并允许通过名称引用它们，新的编程技术就变得可用，包括“动态分派”，它选择在运行时而不是在编译时调用函数。

使用变量、函数和类的名称来定位它们的能力打开了一个全新的可能性领域:现在可以在运行时创建新的函数和类，反过来又可以创建更多的函数和类，令人厌烦。在我们的日常生活中，我们创造新的概念，随着概念在语义空间的任何区域迅速增长，我们也看到新的单词在那里出现，因为如果我们要使用它们，能够引用概念是必要的。我们也在“运行时”创造概念和新词。

有一个普遍的原则，有时被称为“软件工程的基本定理”，并归功于大卫惠勒:“我们可以通过引入一个额外的间接层来解决任何问题。”有时这句话会被修改，加上“除了过多间接引起的问题”。在这里，间接指的是两个事物是如何联系在一起的:直接，或者通过一个中间标签，或者一系列这样的标签。

我们在这里看到的灵活性来自于间接性:我们不是将一个对象(比如一个名为 *lion* 的变量)连接到我们可以调用这个对象的方法(比如 *roar* 和 *eat* 等等)，而是将这个对象连接到一个中间抽象(比如 *animal* )，然后连接到这些方法。这样，我们可以通过单个中介将几个对象连接到这些方法，并且改变中介的特性是影响许多变量的一种廉价方式。这种添加单词、名称或符号的好处的概念在安迪·克拉克的论文 [Magic Words](https://www.nyu.edu/gsas/dept/philo/courses/concepts/magicwords.html) 中得到了呼应，他在论文中指出了单词可以增强我们计算能力的几种方式，包括基于其他概念构建概念的能力。

# **4。今天耐心等待 AI**

最近的三项人工智能进展之所以超过了它们的前辈，是因为它们推迟了某些选择。

**从 W2V 到 Elmo 和 BERT**

所谓的“语义嵌入”将单词映射到向量空间中的点，将相似的单词映射到附近的点。直到几年前，最先进的系统还在使用上下文无关的嵌入:它将单词 jaguar 的每个实例映射到同一点。尽管一个是动物，另一个是汽车，但每个句子中的美洲虎都接收到相同的向量:“美洲虎幼崽咕噜咕噜”和“美洲虎经销商咕噜咕噜”。

ELMo 是最近推出的一个提供上下文嵌入的 NLP 系统，它更有耐心。它一直等到在句子中看到这个单词，才产生一个向量。因此，这两个捷豹将获得不同的表现。W2V 将所有的美洲虎折叠成相同的表示，心照不宣地忽略了各种美洲虎之间的“无关紧要的差异”——动物、汽车、吉他、战斗机、阿兹特克战士、杰克逊维尔的足球运动员等等——而 ELMo 跳过了这种急切的折叠。

如果我们相信 NLP 基准，ELMo 和它的继任者 BERT 在各种各样的任务上表现得非常好。

**从香草深度学习到 AutoML**

普通的深度学习项目从精确定位要使用的架构开始。架构的选择是一个早期的决定，还有几个超参数的设置。现在，通过参数网格搜索，甚至通过模型空间的搜索，我们可以推迟这样的决定。

**从启发式计算机象棋到 AlphaZero**

深度学习的早期承诺之一是学习功能。无人监管的方法，如自动编码器，是承诺的乌托邦，将把我们从手动识别特征和手动调整权重中解放出来，通过允许“数据自己说话”，提供最稳健的权重集。特征工程是昂贵的和繁重的，并且需要技巧，如果有成千上万的问题我们想要解决，为每一个设计特征是行不通的。

现在最好的“传统”国际象棋系统是 Stockfish。它利用启发式方法来评估棋盘位置:它评估每个位置对白棋的有利程度，以厘泊为单位，领先 100 厘泊相当于拥有一个额外的棋子。为了评估一个位置，它会检查一些方面，如物质优势，兵的发展，国王的安全，两个主教是否幸存，打开的文件，一个骑士是否在前哨，等等——有数百个组成部分。在许多世纪的游戏中，人类玩家已经认识到这些方面的重要性。

Stockfish 是一个非常强大的玩家。它与中村光对弈，后者是 FIDE 国际象棋比赛中闪电战和快速棋类最高级别的棋手。电脑玩的时候有一个障碍:它在缺了一个棋子的情况下下黑棋，但却打败了人类冠军。

尽管它很强大，但在 2017 年，一个更先进更强大的 Stockfish 版本严重输给了谷歌的 AlphaZero。AlphaZero 没有从启发式规则开始，而是使用神经网络作为评估函数。人们可以把手工调整的试探法列表看作是急切的——对重要问题的早期决定。相比之下，AlphaZero 将重要的事情推迟到以后选择，从而使游戏更加灵活，更好地适应它在训练中探索的国际象棋位置的空间区域。

这些耐心的方法结出了果实，但这些(和其他深度学习解决方案)有一个共同的热切核心，我们接下来将讨论这个核心。

# **5。今日 AI 急切**

让我们暂停一下，考虑一下前面讨论过的这些系统表现出的耐心:编程语言 Perl ( 3)、ELMo、AutoML 和 AlphaZero ( 5)。每一个都取代了系统中看似内在的东西，由于这种内在的东西在整个系统中是一致的，因此必须在一开始就决定。这些不可侵犯的单色外观被一种色彩丰富的拼布所取代，其选择可能会被推迟。Perl 不同意语法是固定的，或者整个程序用一种语法编写，或者只有一种最好的方法来表示对象和方法分派的工作方式。被认真对待的 Perl 的座右铭贯穿了它的设计:“有不止一种方法可以做到”，缩写为 TIMTOWDI，拉里·沃尔的 Twitter 昵称是@TimToady。AutoML 不相信网络的形状是固定的(因此我们不必在任何工作开始之前决定形状)，AlphaZero 不相信一个单一的象棋位置评估函数(因此可以跳过选择)，ELMo 不相信对某个单词的所有实例使用相同的向量。

从优秀的老式人工智能到现代深度学习系统，人工智能系统已经做出了急切的决定，这些决定被硬编码到他们的程序中。这些不胜枚举，我仅列举几个。

**热切选择的表征和语义原子主义**

有意义的原子可以结合起来形成，或者一个人被引导去相信，任何和所有的意义。我最早接触 AI 的一个领域是罗杰·尚克(Roger Schank)的“概念依赖”(Conceptual Dependency)系统，该系统试图用少量的原语(如 PTRANS(物理运动)、MTRANS(信息的运动)和 ATRANS(抽象转移，如给予)来表示所有的意义，包括完整的故事。那么，这是一个不到 100 个有意义原子的清单。在更大的范围内，今天的 WSD 系统倾向于也是意义的库存，并且每个术语有一组固定的含义。他们可能会为某个术语列出 4 个意义，而为另一个术语列出 10 个意义，但通常每个术语都有一个固定的集合，并且该集合的成员是离散的。另一个中等大小的感官库存是 WordNet。如今，也有免费的基础和知识图。

人类的概念不是这样工作的，将几个原子结合到我们所拥有的感官的细微层次中。我很熟悉“太阳底下没有新东西”这句话，以及所有思想都是先前思想的混合物或类似的说法，但新概念可以而且确实会产生。这是如何发生的将是另一篇文章的主题，重点是亚瑟·库斯勒、迈克尔·阿加尔、吉勒·福康尼耶和马克·特纳等人的想法。

当像 WordNet 这样的系统被用作人工智能系统的目标输出时，我们已经对可能的含义集做出了早期的决定。更糟糕的是，这些意义不符合人类的意义，人类的意义显示出灰色和等级隶属关系的阴影，以及在适当的时候通过隐喻、转喻或类比延伸意义的显著能力。

一组有限的意义意味着有限数量的歧视，许多有意义的边界被抹去。

**监督与强化:固定损失函数还是固定效用函数**

人们的一生，甚至一个小时，都不会有固定的损失函数。我们的目标变化很快，有些受饥渴等因素的影响，有些受吸引我们注意力的事情的影响，有时我们只关注正在进行的任务中的一个子问题。随着目标的改变，成功的标准也会改变。

我没有在训练中替换损失函数的建议，但我不认为应该只有一个。

**固定输出类**

我把我认为 NLP 中最大的问题留到最后:期望输出的固定和有限的范围。许多任务是分类任务，实际上是问“输入属于这三个类中的哪一个？”。具体的任务可能是“将句子分类为正确的情感，可以是这四种中的一种”或者唯一稍微开放一点的“在输入句子中找到一个双关语(顺便说一句，在 WordNet 中是双关语)”。

为什么我认为这些限制是急切的，为什么我们会变得脆弱？考虑将产品评论分为两类的任务，*正面的*和*负面的*，想象你已经训练了一个系统来处理这个问题。但是由于*负面*并不是一个铁板一块的类别，它实际上是由许多重叠的原因形成的，这些原因使评论变得糟糕:也许产品很糟糕，也许卖家不知何故搞砸了，很粗鲁，等等，这根本不会反映在产品上。系统没有压力分别表示否定的这两个子类——这两个之间的表示会崩溃。在一个一切都是积极或消极的世界里，消极的子类之间的区别无关紧要。消除这些区别会使系统概括得很糟糕，并阻止它学习抽象概念，例如“如果一个评论在一个维度上是正面的，但在另一个维度上是负面的，我们就称之为正面的。”

**我能坚持下去**

上面的例子仅仅触及了表面。我们还没有讨论我的导师道格拉斯·霍夫施塔特(Douglas Hofstadter)在认知的计算模型方面的工作，他在那里展示了认知和识别是如何相互交织、相互依存的，这是一个论点，即表征不应该是先验固定的。例如，当我们着手一个研究项目时，我们可能甚至不知道我们应该向自己提出的精确问题，而要测量的精确数量只有随着时间的推移才会变得清楚。同样，这篇博文一开始是一个非常简单的想法，经过六次重大修改，抛弃了许多文本，杀死了许多宠儿，它达到了目前的形式，与我想象的相去甚远。

如果我们希望我们的计算机最终具有创造力并能够深刻理解，我们还有很长的路要走，而这段旅程将需要许多层面来解开我们目前认为是港口甚至是固体陆地的锚。