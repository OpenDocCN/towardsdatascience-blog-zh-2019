<html>
<head>
<title>A new perspective on Shapley values: the Naïve Shapley method</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">Shapley 值的新视角:天真的 Shapley 方法</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/a-new-perspective-on-shapley-values-the-radical-shapley-method-6c2f4af7f922?source=collection_archive---------18-----------------------#2019-12-01">https://towardsdatascience.com/a-new-perspective-on-shapley-values-the-radical-shapley-method-6c2f4af7f922?source=collection_archive---------18-----------------------#2019-12-01</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><figure class="is it gp gr iu iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi ir"><img src="../Images/8d2b6b8ac0c04696bb370ebc98549aaa.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*RwJ4VHpdxoE5NOEx8hNZzQ.png"/></div></div><figcaption class="jc jd gj gh gi je jf bd b be z dk">Image adapted from <a class="ae jg" href="https://shap.readthedocs.io/" rel="noopener ugc nofollow" target="_blank">shap.readthedocs.io</a></figcaption></figure><div class=""/><div class=""><h2 id="fd54" class="pw-subtitle-paragraph kg ji jj bd b kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx dk translated">通过探索一个概念性的替代方案来更好地了解 SHAP。</h2></div><p id="1c4c" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">** <strong class="la jk">编辑，2020 年 1 月:</strong>我把这里介绍的方法从不太直观的<em class="lu">激进的 Shapley </em>改名为<em class="lu">幼稚的 Shapley </em>。这在整篇文章中都有所改变，但是代码片段和 git 库可能仍然反映了旧的名称。**</p><h1 id="3ebe" class="lv lw jj bd lx ly lz ma mb mc md me mf kp mg kq mh ks mi kt mj kv mk kw ml mm bi translated">你为什么要读这篇文章？</h1><ul class=""><li id="8d59" class="mn mo jj la b lb mp le mq lh mr ll ms lp mt lt mu mv mw mx bi translated"><strong class="la jk">了解沙普利值和 SHAP 工具</strong>。关于这些主题的大多数其他来源是基于现有主要来源的解释(例如，学术论文和 SHAP 文档)。这篇文章试图通过实证的方法来获得一些理解。</li><li id="c3ee" class="mn mo jj la b lb my le mz lh na ll nb lp nc lt mu mv mw mx bi translated"><strong class="la jk">了解计算 Shapley 值的另一种方法</strong>，在某些(有限的)情况下，这种方法可能比 SHAP 更可取(或者等待下一篇文章，以获得更广泛适用的想法)。</li></ul><p id="3f25" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><strong class="la jk">如果你不熟悉 Shaply values 或 SHAP </strong>，或者想简单回顾一下 SHAP 的解释者是如何工作的，<a class="ae jg" href="https://medium.com/@edden.gerber/a-new-perspective-on-shapley-values-an-intro-to-shapley-and-shap-6f1c70161e8d" rel="noopener">看看这篇文章</a>。</p><p id="d0eb" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><strong class="la jk">赶时间？我强调了关键句子来帮助你快速阅读。</strong></p><h1 id="35c3" class="lv lw jj bd lx ly lz ma mb mc md me mf kp mg kq mh ks mi kt mj kv mk kw ml mm bi translated">更加冗长的介绍</h1><figure class="ne nf ng nh gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi nd"><img src="../Images/3db308dadcf8c469418def132f464150.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*YR1NvVEjKnAVjWG4.jpg"/></div></div></figure><p id="2559" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">当我在最近的一次黑客马拉松中使用 SHAP 图书馆来解释一个隔离森林模型的预测时，我对 Shapley 值的兴趣被激发了。我注意到，对于我们的模型，SHAP 计算似乎非常低效，在整个数据集上运行需要太长时间。事实上，时间太长了，以至于我想知道在这种情况下，Shapley 值的“蛮力”指数复杂方法是否是一个更好的选择。这让我编写了一个函数，使用一种对我来说似乎很直观的方法来计算 Shapley 值:<strong class="la jk">不是通过对可能的值进行积分来模拟缺失的特征(如 SHAP 方法)，而是可以在训练期间将它们从模型中完全删除</strong>。由于文献中缺乏现有的术语，我决定将这些称为<strong class="la jk">朴素沙普利值</strong>，在某种意义上，它们仅基于数据集(加上一个模型类)，而不是基于训练好的模型。</p><p id="9cd9" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">作为一名神经科学研究生，我学到的一件事是，如果你想理解——并信任——你的分析工具，你需要对它们进行仔细的实证研究，就好像它们是你真正的研究对象一样。阅读现有的文献很重要，亲自获得实践经验也很重要，但我发现真正的洞察力来自于不要认为工具的结果是理所当然的，而是要结合人为的边缘情况或其他方法来测试它。<strong class="la jk">这篇文章的主旨是，通过与朴素的 Shapley 方法进行比较，更好地理解 SHAP 解释者的优势和局限性。</strong></p><p id="8445" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><strong class="la jk">Shapley 函数的代码</strong>和本文中使用的例子可以在<a class="ae jg" href="https://github.com/edden-gerber/radical-shapley-values" rel="noopener ugc nofollow" target="_blank">这里</a>找到。</p><h1 id="c02c" class="lv lw jj bd lx ly lz ma mb mc md me mf kp mg kq mh ks mi kt mj kv mk kw ml mm bi translated">大纲(不太是 TL；博士)</h1><p id="3c93" class="pw-post-body-paragraph ky kz jj la b lb mp kk ld le mq kn lg lh ni lj lk ll nj ln lo lp nk lr ls lt im bi translated">在这篇文章中，我将尝试展示以下内容:</p><ul class=""><li id="0db5" class="mn mo jj la b lb lc le lf lh nl ll nm lp nn lt mu mv mw mx bi translated"><strong class="la jk">通过为每个 2ᴹ特征子集(其中<em class="lu"> M </em>是特征的数量)重新训练模型，可以为少量特征</strong>计算朴素沙普利值。</li><li id="56b0" class="mn mo jj la b lb my le mz lh na ll nb lp nc lt mu mv mw mx bi translated"><strong class="la jk">SHAP 图书馆的解释者和朴素的 Shapley 方法对 Shapley 值提供了两种不同的解释。</strong>前者最适合解释给定(已训练)模型的单个预测，后者更适合解释数据集和模型<em class="lu">类</em>的特征重要性(例如，用某些参数初始化的随机森林，但不是已训练的随机森林)。</li><li id="cc6f" class="mn mo jj la b lb my le mz lh na ll nb lp nc lt mu mv mw mx bi translated"><strong class="la jk">在某些(有限的)情况下，朴素沙普利计算可以比 SHAP 方法更快。</strong>当以下所有情况都为真时，这些情况是广义的:<strong class="la jk"> a. </strong>少量特征(&lt; ~15)，<strong class="la jk"> b. </strong>使用不被高效的 SHAP 解释器支持的模型，以及<strong class="la jk"> c. </strong>大量样本(例如，整个数据集)需要 Shapley 值。</li></ul><p id="8c02" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">在以后的文章中，我希望讨论一个更实用的，多项式复杂的替代方法，用抽样来估计朴素的 Shapley 值。</p><h1 id="389a" class="lv lw jj bd lx ly lz ma mb mc md me mf kp mg kq mh ks mi kt mj kv mk kw ml mm bi translated">那么什么是“<strong class="ak">幼稚</strong>”的沙普利价值观呢？</h1><figure class="ne nf ng nh gt iv gh gi paragraph-image"><div class="gh gi no"><img src="../Images/a41ddcda6c59432ead3efc081cfb8b74.png" data-original-src="https://miro.medium.com/v2/resize:fit:1224/format:webp/0*x_LtoyIAF_fbQkuw.jpg"/></div></figure><p id="087d" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><strong class="la jk">首先，什么是沙普利值？</strong>如果你有一个团队，每个人都对总收益做出贡献，但他们的贡献不一定是独立的(就像团队经理的贡献取决于也有做出贡献的工人)，那么 Shapley 值将每个人对总收益的贡献量化为他们在所有可能的团队中的边际贡献的加权平均值(因此我们的团队经理的贡献可能是 0，没有额外的工人，100，至少有一个工人，等等。并且这是在团队的所有可能排列中的平均值)。用更专业的术语来说，Shapley 值反映了在不包括玩家的所有可能联盟中，将玩家加入联盟所产生的剩余收益的期望值。</p><p id="6aca" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">在统计模型领域，Shapley 值量化了模型预测中的差异，这种差异是通过在模型中添加每个要素来驱动的。但是，由于此类模型通常无法处理不完整的输入，因此不可能简单地从数据集中移除要素来计算其边际贡献。因此，<strong class="la jk">实现 Shapley 值的概念来解释预测模型是一些解释的问题</strong>。具体来说，</p><ul class=""><li id="e2d5" class="mn mo jj la b lb lc le lf lh nl ll nm lp nn lt mu mv mw mx bi translated"><strong class="la jk">在预测阶段</strong>，对于给定的样本，SHAP 的解释者将“添加一个特征”解释为具有特定的值，而其值是未知的。例如,“年龄=30”对预测个人收入水平的模型输出的边际贡献可以相对于平均预测收入水平来计算，当用其他可能的值替换数据集中的“年龄”时。另一方面，</li><li id="1eb1" class="mn mo jj la b lb my le mz lh na ll nb lp nc lt mu mv mw mx bi translated"><strong class="la jk">朴素的 Shapley 方法基于另一种直觉，即在训练过程中，衡量某个特性对模型的影响</strong>。因此，在我们的示例中,“年龄=30”的贡献是相对于模型最初完全没有年龄特征的情况而言的。</li></ul><p id="1486" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><strong class="la jk">这两种解释都符合 Shapley 值的数学概念，但它们测量的东西略有不同。</strong></p><h1 id="56c1" class="lv lw jj bd lx ly lz ma mb mc md me mf kp mg kq mh ks mi kt mj kv mk kw ml mm bi translated">计算朴素的 Shapley 值</h1><p id="3eeb" class="pw-post-body-paragraph ky kz jj la b lb mp kk ld le mq kn lg lh ni lj lk ll nj ln lo lp nk lr ls lt im bi translated"><strong class="la jk">计算朴素 Shapley 值的函数</strong>(此处代码<a class="ae jg" href="https://github.com/edden-gerber/radical-shapley-values" rel="noopener ugc nofollow" target="_blank"/>)<strong class="la jk">采用一个数据集和一个收益函数，计算每个可能的特征组合(或“玩家联盟”)的收益。</strong>然后使用标准的 Shapley 公式计算 Shapley 值:</p><figure class="ne nf ng nh gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi np"><img src="../Images/fcdadc5c07ba625e5bda789e7e763dd1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*KWgr8OkooalNU6N0.png"/></div></div><figcaption class="jc jd gj gh gi je jf bd b be z dk"><em class="nq">φi</em> is the Shapley value for feature <em class="nq">i</em>, <em class="nq">S</em> is a coalition of features, <em class="nq">v(S)</em> is the payoff for this coalition, and N is the total number of features. <em class="nq">N\{i}</em> is all the possible feature coalitions not containing <em class="nq">i</em>. The first term within the sum corresponds to the fraction of times <em class="nq">S</em> appears within the possible feature permutations; intuitively, this gives the highest weight to the most informative contributions of a feature, i.e. when it is isolated or when it is added to a full set of features.</figcaption></figure><p id="25cb" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">输出的格式与 SHAP 库解释器的格式相同，因此所有的 SHAP 绘图工具都可以用来可视化它。</p><p id="201b" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><strong class="la jk">收益函数可以是任何接受数据集并返回分数</strong>的函数(例如，我们的工人团队为任何团队构成产生的利润)。因此，它是一个通用函数，可用于任何类型的 Shapley 计算，但为了生成简单的 Shapley 值，它将始终是一个为数据集定型特定类型模型的函数，并为每一行返回一个预测。</p><p id="5728" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><strong class="la jk">例如</strong>:假设我们想要为 XGBoost 模型计算简单的 Shapley 值。我们将编写一个自定义的支付函数，它初始化一个 xgb 模型，训练它并返回每个样本的预测(或者可能只针对一个验证集)。Shapley 函数会将输入要素的每个可能组合输入到支付函数中，并使用结果输出来计算每个样本和要素的 Shapley 值(您很快就会看到一个活生生的例子)。</p><p id="0658" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><strong class="la jk">该算法的主要缺点是其计算复杂度</strong> —它需要运行 2ᴹ次(其中<em class="lu"> M </em>是特征的数量)，每次都要重新训练模型。这种复杂性当然是需要 SHAP 图书馆的主要原因；另一方面，在某些有限的情况下，这可能是比使用 SHAP 内核解释器更快的选择。<strong class="la jk">比较运行时间的问题将在本文</strong>的结尾讨论。</p><h1 id="000e" class="lv lw jj bd lx ly lz ma mb mc md me mf kp mg kq mh ks mi kt mj kv mk kw ml mm bi translated">这和 SHAP 有什么不同，我们为什么要关心？</h1><p id="bbd0" class="pw-post-body-paragraph ky kz jj la b lb mp kk ld le mq kn lg lh ni lj lk ll nj ln lo lp nk lr ls lt im bi translated"><strong class="la jk">我将 Naive Shapley 方法的结果与 SHAP KernelExplainer 和 TreeExplainer 的结果进行了比较。</strong>我没有与 DeepExplainer 进行比较，因为神经网络模型很少具有使比较相关的少量输入变量。简而言之，朴素沙普利方法在概念上不同于所有的 SHAP 解释者，它代表了特征对模型本身的贡献，而不是对个体预测的贡献。同时，虽然在某些情况下，in 可能比 KernelExplainer 更有效，但它通常较慢(对于数量较少的功能来说不切实际)。再一次，如果你不确定 SHAP 的解释者在做什么，这篇文章可以帮助你。</p><h2 id="ff85" class="nr lw jj bd lx ns nt dn mb nu nv dp mf lh nw nx mh ll ny nz mj lp oa ob ml oc bi translated">天真的 Shapley 值与 TreeExplainer</h2><p id="cddc" class="pw-post-body-paragraph ky kz jj la b lb mp kk ld le mq kn lg lh ni lj lk ll nj ln lo lp nk lr ls lt im bi translated">TreeExplainer 是与 Naive Shapley 方法进行比较的一个很好的首选，因为与 KernelExplainer 不同，它们都是确定性的(不依赖于基于采样的估计)，并且对特性之间的依赖关系不敏感(至少在 TreeExplainer 的默认实现中)。这使我们能够关注概念差异在处理缺失特征方面的影响，即通过重新训练模型与对特征值进行积分。</p><p id="8955" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">我们可以用一个简单的人为例子来证明这种差异的重要性。让我们生成一个 3 特征线性回归模型，其中一个特征<em class="lu"> x1 </em>是<em class="lu"> y </em>的强预测器，第二个特征<em class="lu"> x2 </em>与之强相关(因此对<em class="lu"> y </em>的预测性稍差)，第三个非预测器特征<em class="lu"> x3 </em>:</p><figure class="ne nf ng nh gt iv"><div class="bz fp l di"><div class="od oe l"/></div></figure><p id="dc47" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">为了获得简单的 Shapley 值，我们需要首先定义支付函数，它简单地训练模型并返回它的预测(为了简单起见，我不包括任何训练-验证分割等。).</p><figure class="ne nf ng nh gt iv"><div class="bz fp l di"><div class="od oe l"/></div></figure><p id="b4f3" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">现在运行 Shapley 函数本身(<em class="lu"> reshape_shapley_output </em>只是重新排列原始输出，因为<em class="lu"> compute_shapley_values </em>返回一个不采用特定支付格式的字典。在<a class="ae jg" href="https://github.com/edden-gerber/radical-shapley-values" rel="noopener ugc nofollow" target="_blank"> github </a>上提供了功能输入和输出的说明。</p><figure class="ne nf ng nh gt iv"><div class="bz fp l di"><div class="od oe l"/></div></figure><p id="0d72" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">为了获得 SHAP 值，我们将定义 XGB 回归模型，对其进行训练，并使用 TreeExplainer 计算 SHAP 值:</p><figure class="ne nf ng nh gt iv"><div class="bz fp l di"><div class="od oe l"/></div></figure><p id="8786" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">现在让我们看看 SHAP 值和天真的沙普利值是如何相互比较的。我们将使用 SHAP 图书馆的简洁的<em class="lu"> summary_plot </em>可视化工具，该工具绘制每个特征的 Shapley 值的分布:</p><figure class="ne nf ng nh gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi of"><img src="../Images/0e84a3be9a7515d54083dafd443bc2d6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*T2LtVRlZMBPhkJG5UrGxyw.png"/></div></div></figure><p id="e85d" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">让我们来分解一下:</p><ul class=""><li id="1532" class="mn mo jj la b lb lc le lf lh nl ll nm lp nn lt mu mv mw mx bi translated">使用 TreeExplainer，模型已经用所有 3 个特征进行了训练，因此<strong class="la jk"> SHAP 值反映了这样一个事实，即<em class="lu"> x1 </em>在训练的模型</strong>中具有最高的影响，而<em class="lu"> x2 </em>具有小得多的作用，因为它大部分是冗余的。</li><li id="5c99" class="mn mo jj la b lb my le mz lh na ll nb lp nc lt mu mv mw mx bi translated">另一方面，使用朴素的 Shapley 方法，x2 对<em class="lu"> y </em>的影响几乎与 x1 的影响一样大，因为<strong class="la jk">在没有<em class="lu"> x1 </em>的情况下训练模型时，<em class="lu"> x2 </em>的信息量几乎与</strong>一样多。</li><li id="df65" class="mn mo jj la b lb my le mz lh na ll nb lp nc lt mu mv mw mx bi translated">与此同时，非预测性的<em class="lu"> x3 </em>使用朴素的 Shapley 方法被认为具有更高的影响——这仅仅是因为，特别是当我们没有进行训练/验证分割时，在没有更好的预测器的情况下，它会过度拟合数据。</li></ul><p id="8166" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><strong class="la jk">现在让我们尝试一个真实世界的例子</strong>。我们将查看 SHAP 图书馆中包含的一个数据集的 Shapley 值——成人普查数据库，该数据库具有 12 个人口统计特征，用于预测个人的收入是否为&gt; 5 万美元(load with<em class="lu">shap . datasets . adult()</em>)。为了清晰和减少计算运行时间，我们将在我们的模型中只包括 12 个特征中的 6 个(<em class="lu">年龄、每周小时数、教育、婚姻状况、资本收益和性别</em>)。我们的模型将是一个 XGBoost 分类器。在这种情况下，TreeExplainer 的 SHAP 值和 Naive Shapley 值如何相互比较？散点图给我们一个快速的第一印象:</p><figure class="ne nf ng nh gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi og"><img src="../Images/b3024ac814b0b14c2870e42fa89233f1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ZXOAEuEZezdgGvNxniyPWQ.png"/></div></div></figure><p id="efc2" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">结果似乎是高度相关的，这应该已经给了我们一个提示，尽管他们的概念不同，这两种方法在结果上可能不会有太大的差异。现在用<em class="lu">总结 _ 情节</em>:</p><figure class="ne nf ng nh gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi oh"><img src="../Images/ab5559a7942a858f1bd624df6bc77504.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*qCJW-WvNoai5fkTqJay0Tw.png"/></div></div></figure><p id="3d2b" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">这里的结果看起来也很相似(尽管差异很大，以至于全局特征重要性的顺序有所改变)。但是让我们放大一下<em class="lu">性别</em>变量的 Shapley 值分布的差异:</p><figure class="ne nf ng nh gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi oi"><img src="../Images/3bbadbd2fdfb8857c8a3f04f712ab5a8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*-oanlleLDb1cxkTFzb8SFQ.png"/></div></div></figure><p id="073a" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">这是怎么回事？</p><ul class=""><li id="1579" class="mn mo jj la b lb lc le lf lh nl ll nm lp nn lt mu mv mw mx bi translated">天真的 Shapley 结果向我们展示了<strong class="la jk">对所有可能的特征组合进行了平均，添加该变量将对该数据集</strong>(你好性别工资差距)的预测产生一致的影响。</li><li id="a09f" class="mn mo jj la b lb my le mz lh na ll nb lp nc lt mu mv mw mx bi translated">TreeExplainer 的结果向我们展示了<strong class="la jk">在我们的训练模型中，该变量对样本预测的影响较小且不太一致</strong>，很可能是因为它用于解释较小的残差方差，因为它传达的大部分信息是由其他更具预测性的特征提供的。</li></ul><blockquote class="oj ok ol"><p id="7046" class="ky kz lu la b lb lc kk ld le lf kn lg om li lj lk on lm ln lo oo lq lr ls lt im bi translated"><strong class="la jk">注意:</strong>实现我们自己的自定义 Shapley 函数的一个好处是，我们可以轻松地获得大量的中间结果，例如，我们计算的每个可能的特征组合在有或没有给定特征的情况下的利润率(其加权平均值是每个样本的 Shapley 值)。只是为了好玩，我从<em class="jj"> compute_shapley_values </em>函数中提取了它，这样我们可以看看最终的 shapley 值是如何从这些单独的支付利润中产生的。这些是<em class="jj">性别</em>变量的收益边际分布，相对于它所添加的功能数量绘制:</p></blockquote><figure class="ne nf ng nh gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi op"><img src="../Images/dc66738cff457e01b43e0a37ee850637.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*ckRyRal_oeYSr4AB.png"/></div></div></figure><blockquote class="oj ok ol"><p id="b62d" class="ky kz lu la b lb lc kk ld le lf kn lg om li lj lk on lm ln lo oo lq lr ls lt im bi translated">我们可以看到模型中已经存在的特性越多，这个特性的边际影响就变得越小，越不明显。以<em class="jj"> Education_Num </em>的利润率分布为例，无论有多少其他特征组成模型，它的贡献基本上保持不变，这表明它对模型的贡献很大程度上与它们无关:</p></blockquote><figure class="ne nf ng nh gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi op"><img src="../Images/ad24282845d9d55f6163d660bb4e2832.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*oissMiyJxaqpl8x8.png"/></div></div></figure><p id="a131" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">那么，我们应该用哪种方法来解释我们的数据和模型中的性别变量<em class="lu">的作用呢？我认为最好的表达方式是:</em></p><ul class=""><li id="d64e" class="mn mo jj la b lb lc le lf lh nl ll nm lp nn lt mu mv mw mx bi translated"><strong class="la jk">朴素的 Shapley 值更好地代表了数据集</strong>中特征的全局影响，而</li><li id="18a6" class="mn mo jj la b lb my le mz lh na ll nb lp nc lt mu mv mw mx bi translated"><strong class="la jk">给定我们现有的训练模型</strong>，SHAP 值可以更好地解释特定的预测。</li></ul><p id="f984" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">在继续之前，还有两点需要注意:</p><blockquote class="oj ok ol"><p id="32ef" class="ky kz lu la b lb lc kk ld le lf kn lg om li lj lk on lm ln lo oo lq lr ls lt im bi translated"><strong class="la jk">实际注意事项</strong>:我并不是建议如果您关心数据集中的全局特征影响，就一定要使用朴素的 Shapley 方法，这主要是因为在大多数情况下，这在计算上是很难处理的(尽管在最后几节中可能会出现这种情况)。从我的例子中也可以明显看出，SHAP 解释者的结果通常没有太大的不同，因此不应该用于这个目的。我在这里的主要动机是更好地理解 SHAP 结果及其局限性。</p><p id="205f" class="ky kz lu la b lb lc kk ld le lf kn lg om li lj lk on lm ln lo oo lq lr ls lt im bi translated"><strong class="la jk">技术提示</strong>:如果您熟悉 TreeExplainer，您可能知道，由于在二进制分类的情况下，树节点的权重保存的不是概率，而是对数奇数值(最后一步使用逻辑函数将其转换为概率)，TreeExplainer 使用的默认优化方法提供了加起来等于这些未转换值(而不是最终概率)的 SHAP 值。简单地将逻辑函数应用于 SHAP 值本身是行不通的，因为转换值的总和！=总和的转换值。为了生成与概率输出直接对应的 SHAP 值，TreeExplainer 不得不牺牲一些效率，并使用类似于 KernelExplainer 的方法，通过用背景数据集替换来模拟缺失的要素，这自然是一种更慢、更不精确的方法。另一方面，为了用朴素的 Shapley 方法直接解释概率输出，我们需要做的就是选择支付函数的输出作为概率。<strong class="la jk">由于使用朴素的 Shapley 方法，我们总是支付最大的计算成本，我们不妨使用一个支付函数，它给出了我们所希望的 Shapley 值来解释</strong>。</p></blockquote><h2 id="e233" class="nr lw jj bd lx ns nt dn mb nu nv dp mf lh nw nx mh ll ny nz mj lp oa ob ml oc bi translated">天真的 Shapley 值与 KernelExplainer</h2><p id="7726" class="pw-post-body-paragraph ky kz jj la b lb mp kk ld le mq kn lg lh ni lj lk ll nj ln lo lp nk lr ls lt im bi translated">KernelExplainer 是一种计算 SHAP 值的模型盲方法。简单总结一下，它的工作原理是:</p><ol class=""><li id="0737" class="mn mo jj la b lb lc le lf lh nl ll nm lp nn lt oq mv mw mx bi translated">仅对可能的特征排列的小子集进行采样。</li><li id="9968" class="mn mo jj la b lb my le mz lh na ll nb lp nc lt oq mv mw mx bi translated">对于每一个这样的排列，通过生成许多自举样本来模拟“缺失的特征”,其中这些特征的值被来自小的“背景数据集”的值所替换，并且平均这些样本的预测。</li></ol><p id="9d8a" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">这意味着<strong class="la jk">与 TreeExplainer 相比，KernelExplainer 是</strong>:</p><ol class=""><li id="34bd" class="mn mo jj la b lb lc le lf lh nl ll nm lp nn lt oq mv mw mx bi translated"><strong class="la jk">较慢</strong>-需要为数据集中的每个解释实例计算大量预测(因为缺失值是通过对要素的许多可能值进行平均来模拟的)。</li><li id="5b58" class="mn mo jj la b lb my le mz lh na ll nb lp nc lt oq mv mw mx bi translated"><strong class="la jk">不确定性</strong> —估计 KernelExplainer 的 SHAP 值，方差由联合抽样方法和背景数据集选择引入。</li></ol><p id="3ff8" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><strong class="la jk">当比较 KernelExplainer SHAP 值和天真的 Shapley 值时，这是怎么回事？</strong>让我们使用预测收入为&gt; 50 万美元的相同 6 特征人口普查数据集作为测试案例。这一次，按照 SHAP 图书馆笔记本中的<a class="ae jg" href="https://slundberg.github.io/shap/notebooks/Census%20income%20classification%20with%20scikit-learn.html" rel="noopener ugc nofollow" target="_blank">示例，我们将使用 KNN 模型进行预测，并使用 KernelExplainer 提供 Shapley 值，我们可以将其与朴素的 Shapley 值进行比较:</a></p><figure class="ne nf ng nh gt iv"><div class="bz fp l di"><div class="od oe l"/></div></figure><p id="fd63" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">比较结果:</p><figure class="ne nf ng nh gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi or"><img src="../Images/0ccad3cd53863aa9975d1d7842612626.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*GI1Jcc7YjQqYS-dGUUiIOg.png"/></div></div></figure><p id="2f8f" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">这两种方法产生不同但相关的结果。如果我们对每个样本的 Shapley 值进行排序和分级(从 1 到 6)，则顺序平均会相差大约 0.75 级(例如，在大约 75%的样本中，两个相邻特征的顺序被交换)。让我们记住，我们不是在看精确值和它们的噪声估计之间的关系:相反，<strong class="la jk">朴素<em class="lu">沙普利值是一个事物的确定性度量，而核 SHAP 值是另一个(相关)事物的估计</em> </strong>。</p><p id="243e" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">我认为，这里要强调的最后一点是，尽管这两种方法之间存在差异，但结果总体上仍然非常相似，这告诉我们<strong class="la jk">在许多情况下，这些方法可能可以互换使用</strong>，假设差异对我们来说并不重要。</p><h1 id="e5cc" class="lv lw jj bd lx ly lz ma mb mc md me mf kp mg kq mh ks mi kt mj kv mk kw ml mm bi translated">天真的 Shapley 能比 KernelExplainer 快吗？</h1><figure class="ne nf ng nh gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi os"><img src="../Images/3e36b1168b0df1bd1bd6f2e09ac02be3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*H0R2uX2I3evhT5VR.jpg"/></div></div></figure><p id="fa3b" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">正如我们已经建立的，天真的 Shapely 方法需要重新训练模型并产生预测 2ᴹ时报。这使得当特性的数量不低时(比如说，超过 15–20)这是不切实际的。但是它能和 SHAP 解释者的少量特性相比吗？</p><p id="2213" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">需要指出的一点是<strong class="la jk">优化的 SHAP 解释器总是比简单的 Shapley 方法更快，但是模型盲的 KernelExplainer 在解释大型数据集时会非常慢</strong>。为了更好地理解，让我们来看看 KernelExplainer 与简单的 Shapley 方法的运行时间:</p><figure class="ne nf ng nh gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi ot"><img src="../Images/c4c0d2d5c7bbf93108a736a88d7691f0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*sMHGsXc_CO-rwpRHRyitsw.png"/></div></div></figure><p id="e4ef" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">粗体条目强调了每种方法的弱点。Naive Shapley 方法当然最容易受到特征数量增加的影响，并且还依赖于模型训练时间，而 KernelExplainer 不受这些因素的影响(尽管其预测随着特征数量的增加而变得更加多变)。KernelExplainer 在运行时间方面的缺点是，虽然它不需要花费时间来重新训练模型，但它会为每个解释的预测单独运行(而 Naive Shapley 会立即为所有预测运行)，每次都必须为大约 200K 个样本(<em class="lu"> nsamples </em> X <em class="lu"> num)生成预测。背景样本</em>，默认分别为 2048+2M 和 100)。</p><p id="8f6b" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><strong class="la jk">Naive Shapley 方法可能比 KernelExplainer 执行速度更快的模型的一个很好的例子是<em class="lu">隔离森林</em>模型</strong>，这是一个流行的异常检测工具，尽管它是一个基于树的模型，但它不受 TreeExplainer 的支持，并且它的训练时间(与预测相比)相对较快。为了证明这一点，我使用来自 Kaggle 的<a class="ae jg" href="https://www.kaggle.com/mlg-ulb/creditcardfraud" rel="noopener ugc nofollow" target="_blank">信用卡欺诈检测数据集，一个大约 285K 的样本，30 个用于预测异常信用卡交易的特征数据集。在我们的演示中，让我们使用 100K 个样本，将 30 个特征减少到 15 个。在我的旧笔记本电脑上，我得到了以下大致的运行时间:</a></p><p id="352d" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><em class="lu"> -训练模型</em> : <strong class="la jk"> 8 秒</strong> <br/> - <em class="lu">对所有 100K 样本进行预测</em> : <strong class="la jk"> 8 秒</strong> <br/> - <em class="lu">计算单个预测的 SHAP 值</em> : <strong class="la jk"> 18 秒</strong>(不出所料，这大约是计算约 200K 引导样本的预测所需的时间)</p><p id="c63a" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">基于此，我们可以粗略估计计算整个数据集的 Shapley 值需要多长时间。内核解释器应该只需要 100，000 x 18 秒，或者大约 500 小时。朴素的 Shapley 函数将运行多达 2 ⁵*(15+13)秒，或者<strong class="la jk">大约 150 小时</strong>(实际上，更好的估计可能是大约 50 小时，因为在算法的每次迭代中用于训练的自举数据集将具有 1 到 15 个特征，或者平均 7 到 8 个，使得训练通常更快)。这两种方法都很慢(尽管两者都可以从并行化中获益)，但是这里重要的不是具体的例子，而是理解每种情况下计算时间的来源。总结一下:</p><ul class=""><li id="7d6c" class="mn mo jj la b lb lc le lf lh nl ll nm lp nn lt mu mv mw mx bi translated"><strong class="la jk">如果只需要解释一小部分“重要”的预测，KernelExplainer 应该足够快了。</strong></li><li id="26bd" class="mn mo jj la b lb my le mz lh na ll nb lp nc lt mu mv mw mx bi translated">如果你需要解释一百万个预测，而你只有不到 10-15 个特征，简单的 Shapley 方法会快得多。</li></ul><h1 id="9ffc" class="lv lw jj bd lx ly lz ma mb mc md me mf kp mg kq mh ks mi kt mj kv mk kw ml mm bi translated">实际的妥协？用抽样估计朴素 Shapley 值</h1><p id="ee83" class="pw-post-body-paragraph ky kz jj la b lb mp kk ld le mq kn lg lh ni lj lk ll nj ln lo lp nk lr ls lt im bi translated"><strong class="la jk">如果我们的模型仅受 KernelExplainer 支持，并且我们确实需要整个庞大数据集的 Shapley 值，但有太多的特征来计算天真的 Shapley 值，该怎么办？</strong></p><p id="c649" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">那么，为什么不尝试<strong class="la jk">使用联合抽样</strong>来估计天真的沙普利值呢？<strong class="la jk"> </strong>使用随机抽样来估计大量玩家的 Shapley 值(如 KernelExplainer 所做的那样)已经在文献中进行了彻底的讨论，并且改进的方法仍在开发中(例如参见<a class="ae jg" href="https://www.sciencedirect.com/science/article/pii/S0305054808000804" rel="noopener ugc nofollow" target="_blank"> Castro 等人 2009 年</a>、<a class="ae jg" href="https://www.sciencedirect.com/science/article/pii/S030505481730028X" rel="noopener ugc nofollow" target="_blank"> Castro 等人 2017 年</a>或<a class="ae jg" href="https://www.sciencedirect.com/science/article/abs/pii/S0377221719304448" rel="noopener ugc nofollow" target="_blank"> Benati 等人 2019 年</a>)。我认为采样可以很好地与朴素的 Shapley 方法结合使用，也就是说，对模型训练的特征组合空间进行采样(因此不需要通过对自举样本求平均来模拟缺失的特征)。</p><p id="5835" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><strong class="la jk">去除算法中的指数分量将大大减少运行时间，并使该方法对于大量特征变得可行</strong>(以一些估计方差为代价)，而保持重新训练方法仍将确保在计算大型数据集的 Shapley 值时运行时间较短。</p><p id="0507" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">在这一点上这只是一个理论上的想法，这个帖子足够长，无需在此展开。我很乐意听取你对这个想法的任何意见(也许你已经在别的地方遇到过了？)，也希望在以后的帖子里展开讨论。</p></div><div class="ab cl ou ov hx ow" role="separator"><span class="ox bw bk oy oz pa"/><span class="ox bw bk oy oz pa"/><span class="ox bw bk oy oz"/></div><div class="im in io ip iq"><p id="6374" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><em class="lu">原载于 2019 年 12 月 8 日</em><a class="ae jg" href="https://edden-gerber.github.io/shapley-part-2/" rel="noopener ugc nofollow" target="_blank"><em class="lu">https://edden-gerber . github . io</em></a><em class="lu">。</em></p></div></div>    
</body>
</html>