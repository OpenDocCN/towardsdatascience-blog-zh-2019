<html>
<head>
<title>Predicting Titanic Survivors (A Kaggle Competition)</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">预测泰坦尼克号幸存者(卡格尔竞赛)</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/predicting-titanic-survivors-a-kaggle-competition-625405f5031e?source=collection_archive---------15-----------------------#2019-06-09">https://towardsdatascience.com/predicting-titanic-survivors-a-kaggle-competition-625405f5031e?source=collection_archive---------15-----------------------#2019-06-09</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><p id="9b5b" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">本案例研究的目的是记录我在第一次 Kaggle 竞赛中创建预测的过程，该竞赛名为<strong class="jp ir"> Titanic:机器从灾难中学习</strong>。对于外行人来说，Kaggle 是一个受欢迎的数据科学网站，拥有数千个公共数据集，提供课程，通常作为具有分析思维的社区中心。他们还举办各种目标的机器学习竞赛。这个特殊比赛的目标是建立一个分类模型，可以成功地确定泰坦尼克号乘客的生死。</p><figure class="km kn ko kp gt kq gh gi paragraph-image"><div role="button" tabindex="0" class="kr ks di kt bf ku"><div class="gh gi kl"><img src="../Images/bc5fe381c0183ca307230636722c7049.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*9U1fjvwmz1PDixKr8Wtz7Q.jpeg"/></div></div><figcaption class="kx ky gj gh gi kz la bd b be z dk">Could our data science efforts have helped? We’ll find out!</figcaption></figure><p id="5a90" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我们开始吧！</p><h1 id="0b4c" class="lb lc iq bd ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly bi translated">1.0 导入数据</h1><p id="98b6" class="pw-post-body-paragraph jn jo iq jp b jq lz js jt ju ma jw jx jy mb ka kb kc mc ke kf kg md ki kj kk ij bi translated">这个过程的第一步总是加载数据和必要的包。在我使用的编程语言 R 中，包是允许用户执行特定任务的算法集合。有创造美丽的情节，建立股票投资组合和几乎任何你能想象的东西的软件包。在这里，我加载了许多包，允许我利用一些强大的机器学习(ML)模型。</p><pre class="km kn ko kp gt me mf mg mh aw mi bi"><span id="355c" class="mj lc iq mf b gy mk ml l mm mn">lapply(c(“caret”,<br/> “h2o”,<br/> “pROC”,<br/> “randomForest”,<br/> “readr”,<br/> “tidyverse”,<br/> “xgboost”),<br/> library,<br/> character.only = TRUE)<br/> h2o.init()<br/> h2o.no_progress()<br/> set.seed(123)<br/> <br/> train &lt;- read_csv(“~/Downloads/train.csv”)<br/> test &lt;- read_csv(“~/Downloads/test.csv”)</span></pre><p id="75b7" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">竞争数据集来自两个文件:训练和测试。正如您可能猜到的，前者用于训练 ML 模型，而测试用于做出最终提交的预测。</p><h1 id="e1a6" class="lb lc iq bd ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly bi translated">2.0 探索数据</h1><p id="b5cb" class="pw-post-body-paragraph jn jo iq jp b jq lz js jt ju ma jw jx jy mb ka kb kc mc ke kf kg md ki kj kk ij bi translated">将我的数据放入 R 后，是时候探索数据的形状了。</p><pre class="km kn ko kp gt me mf mg mh aw mi bi"><span id="8ae3" class="mj lc iq mf b gy mk ml l mm mn">train %&gt;% glimpse()</span><span id="9477" class="mj lc iq mf b gy mo ml l mm mn">## Observations: 891<br/> ## Variables: 12<br/> ## $ PassengerId &lt;dbl&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 1…<br/> ## $ Survived &lt;dbl&gt; 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1…<br/> ## $ Pclass &lt;dbl&gt; 3, 1, 3, 1, 3, 3, 1, 3, 3, 2, 3, 1, 3, 3, 3, 2, 3, 2…<br/> ## $ Name &lt;chr&gt; “Braund, Mr. Owen Harris”, “Cumings, Mrs. John Bradl…<br/> ## $ Sex &lt;chr&gt; “male”, “female”, “female”, “female”, “male”, “male”…<br/> ## $ Age &lt;dbl&gt; 22, 38, 26, 35, 35, NA, 54, 2, 27, 14, 4, 58, 20, 39…<br/> ## $ SibSp &lt;dbl&gt; 1, 1, 0, 1, 0, 0, 0, 3, 0, 1, 1, 0, 0, 1, 0, 0, 4, 0…<br/> ## $ Parch &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 1, 2, 0, 1, 0, 0, 5, 0, 0, 1, 0…<br/> ## $ Ticket &lt;chr&gt; “A/5 21171”, “PC 17599”, “STON/O2. 3101282”, “113803…<br/> ## $ Fare &lt;dbl&gt; 7.2500, 71.2833, 7.9250, 53.1000, 8.0500, 8.4583, 51…<br/> ## $ Cabin &lt;chr&gt; NA, “C85”, NA, “C123”, NA, NA, “E46”, NA, NA, NA, “G…<br/> ## $ Embarked &lt;chr&gt; “S”, “C”, “S”, “S”, “S”, “Q”, “S”, “S”, “S”, “C”, “S…</span><span id="a3b7" class="mj lc iq mf b gy mo ml l mm mn">test %&gt;% glimpse()</span><span id="8340" class="mj lc iq mf b gy mo ml l mm mn">## Observations: 418<br/> ## Variables: 11<br/> ## $ PassengerId &lt;dbl&gt; 892, 893, 894, 895, 896, 897, 898, 899, 900, 901, 90…<br/> ## $ Pclass &lt;dbl&gt; 3, 3, 2, 3, 3, 3, 3, 2, 3, 3, 3, 1, 1, 2, 1, 2, 2, 3…<br/> ## $ Name &lt;chr&gt; “Kelly, Mr. James”, “Wilkes, Mrs. James (Ellen Needs…<br/> ## $ Sex &lt;chr&gt; “male”, “female”, “male”, “male”, “female”, “male”, …<br/> ## $ Age &lt;dbl&gt; 34.5, 47.0, 62.0, 27.0, 22.0, 14.0, 30.0, 26.0, 18.0…<br/> ## $ SibSp &lt;dbl&gt; 0, 1, 0, 0, 1, 0, 0, 1, 0, 2, 0, 0, 1, 1, 1, 1, 0, 0…<br/> ## $ Parch &lt;dbl&gt; 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…<br/> ## $ Ticket &lt;chr&gt; “330911”, “363272”, “240276”, “315154”, “3101298”, “…<br/> ## $ Fare &lt;dbl&gt; 7.8292, 7.0000, 9.6875, 8.6625, 12.2875, 9.2250, 7.6…<br/> ## $ Cabin &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, “B45…<br/> ## $ Embarked &lt;chr&gt; “Q”, “S”, “Q”, “S”, “S”, “S”, “Q”, “S”, “C”, “S”, “S…</span></pre><p id="31f8" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">上面的代码说的是，训练数据有 891 行，包含 12 个不同的变量。这些变量包括乘客的姓名、性别和年龄、票价和上车地点等。这里最重要的变量是名为“Survived”的变量，这是一个由 1 和 0 组成的列表，分别表示乘客是死是活。测试数据包含 418 行，缺少“幸存”变量，因为这是竞争对手要求我们预测的。</p><p id="ca82" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">虽然现在的数据中包含了大量信息，但并不是所有的信息都可以以当前的形式使用。为了提取尽可能多的有用信息，我必须转换其中的一些变量。</p><h1 id="33f6" class="lb lc iq bd ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly bi translated">3.0 转换数据</h1><p id="21b1" class="pw-post-body-paragraph jn jo iq jp b jq lz js jt ju ma jw jx jy mb ka kb kc mc ke kf kg md ki kj kk ij bi translated">我要查看的第一个变量是“名称”据我所知，击沉泰坦尼克号的冰山与任何乘客都没有私人恩怨，所以简单地使用乘客的全名不会提供任何有用的信息。然而，可能是乘客的头衔。像“先生”、“夫人”或“伯爵夫人”这样的头衔可以帮助我们确定乘客的社会地位(例如，他们是平民还是贵族？)对他们的生存有任何影响。</p><p id="2eac" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">为了获得这些标题，我必须从“Name”中提取它们，下面的代码就是这样做的。</p><pre class="km kn ko kp gt me mf mg mh aw mi bi"><span id="6857" class="mj lc iq mf b gy mk ml l mm mn">titles &lt;- c(unique(str_extract(str_extract(train$Name, “\\,\\s[A-Za-z]+”), “[A-Za-z]+”)))<br/> titles &lt;- replace(titles, titles == “the”, “Countess”)<br/> titles</span><span id="1ab3" class="mj lc iq mf b gy mo ml l mm mn">## [1] “Mr” “Mrs” “Miss” “Master” “Don” “Rev” <br/> ## [7] “Dr” “Mme” “Ms” “Major” “Lady” “Sir” <br/> ## [13] “Mlle” “Col” “Capt” “Countess” “Jonkheer”</span></pre><p id="0760" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">如果你想知道，“Jonkheer”是荷兰贵族使用的尊称。泰坦尼克号上有一个叫约翰·乔治·罗克林的人，剧透一下，他死了。\_(ツ)_/</p><p id="2f4e" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">除了使用这个标题列表来创建一个新变量之外，我还将从“Cabin”中提取 Deck 并创建一个名为“Family_Size”的变量，它只是“SibSp”和“Parch”的组合，前者是船上兄弟姐妹和配偶的计数，后者是船上父母和子女的计数。我还将清理一些其他变量，使它们更容易为 ML 模型所理解。</p><pre class="km kn ko kp gt me mf mg mh aw mi bi"><span id="544a" class="mj lc iq mf b gy mk ml l mm mn">train &lt;- train %&gt;% mutate(Survived = factor(Survived), Sex = factor(recode(Sex, <br/> male = 1, female = 0)), Pclass = factor(Pclass), Embarked = factor(Embarked), <br/> Deck = factor(replace_na(substr(train$Cabin, 1, 1), “Unknown”)), Title = factor(str_extract(train$Name, <br/> paste(titles, collapse = “|”))), Family_Size = SibSp + Parch) %&gt;% select(-c(Cabin, <br/> Name, Ticket))<br/> <br/> test &lt;- test %&gt;% mutate(Sex = factor(recode(Sex, male = 1, female = 0)), Pclass = factor(Pclass), <br/> Embarked = factor(Embarked), Deck = factor(replace_na(substr(test$Cabin, <br/> 1, 1), “Unknown”)), Title = factor(str_extract(test$Name, paste(titles, <br/> collapse = “|”))), Family_Size = SibSp + Parch, Fare = ifelse(is.na(Fare), <br/> mean(Fare, na.rm = TRUE), Fare)) %&gt;% select(-c(Cabin, Name, Ticket))</span></pre><h1 id="fd07" class="lb lc iq bd ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly bi translated">3.1 预测乘客年龄</h1><p id="a721" class="pw-post-body-paragraph jn jo iq jp b jq lz js jt ju ma jw jx jy mb ka kb kc mc ke kf kg md ki kj kk ij bi translated">我之前检查数据时没有指出的一点是，有多少乘客的年龄没有被记录下来。在我们拥有数据的 1309 名乘客中，有 266 名没有年龄。丢失的信息以后会有问题，所以我觉得有必要用猜测来代替那些空值。</p><p id="a365" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">简而言之，下面的代码将训练和测试数据结合起来，提取出有年龄的记录，并拟合一个随机森林(RF)模型，该模型确定乘客年龄和其他变量之间的关系。最后，它会用对他们年龄的最佳猜测来填充所有缺失的年龄。</p><p id="e64d" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">旁注:深入描述什么是 RF 模型将完全偏离本案例研究。如果你有兴趣了解更多关于射频模型及其工作原理的信息，<a class="ae mp" href="https://en.wikipedia.org/wiki/Random_forest" rel="noopener ugc nofollow" target="_blank">请访问这个网站</a>。</p><pre class="km kn ko kp gt me mf mg mh aw mi bi"><span id="cfa4" class="mj lc iq mf b gy mk ml l mm mn"><em class="mq"># Combining the training and test data and selecting only the rows with ages</em><br/> age &lt;- train %&gt;% select(-Survived) %&gt;% rbind(test) %&gt;% filter(!is.na(Age)) %&gt;% <br/> filter(!is.na(Embarked))<br/> <br/> <em class="mq"># Building a prediction model</em><br/> age_rf_model &lt;- randomForest(Age ~ . — PassengerId, age, ntree = 5000, mtry = 9, <br/> na.action = na.exclude)<br/> <br/> <em class="mq"># Determining the accuracy of the model</em><br/> age %&gt;% select(Age) %&gt;% add_column(Pred = predict(age_rf_model, age)) %&gt;% na.omit() %&gt;% <br/> mutate(Error = Age — Pred, Error_Pct = Error/Age) %&gt;% summarize(RMSE = sqrt(mean(Error²)), <br/> MAPE = mean(abs(Error_Pct)))</span><span id="ee61" class="mj lc iq mf b gy mo ml l mm mn">## # A tibble: 1 x 2<br/> ## RMSE MAPE<br/> ## &lt;dbl&gt; &lt;dbl&gt;<br/> ## 1 7.30 0.302</span><span id="50eb" class="mj lc iq mf b gy mo ml l mm mn"><em class="mq"># Using the model to predict passenger age</em><br/> train &lt;- train %&gt;% mutate(Age = ifelse(is.na(Age), round(predict(age_rf_model, <br/> train)), Age))<br/> test &lt;- rbind(train[1, c(1, 3:12)], test)<br/> test &lt;- test[-1, ]<br/> test &lt;- test %&gt;% mutate(Age = ifelse(is.na(Age), round(predict(age_rf_model, <br/> test)), Age))</span></pre><p id="5766" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">为了检查 RF 模型的预测有多准确，我计算了预测的均方根误差(RMSE)和平均绝对百分比误差(MAPE ),以衡量这些预测的质量。<a class="ae mp" href="https://medium.com/@auggieheschmeyer/forecasting-walmart-sales-using-machine-learning-models-3bf38f6c533" rel="noopener">关于这两个指标的简要描述，请参阅我之前的文章。</a></p><p id="f1b2" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">长话短说:两种误差指标都很低。MAPE 告诉我，平均预测只有 0.3%的误差，所以虽然不完美，但我觉得对于我预测生存的最终目标来说，这是可以接受的。</p><h1 id="b58b" class="lb lc iq bd ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly bi translated">4.0 训练模型</h1><p id="c37f" class="pw-post-body-paragraph jn jo iq jp b jq lz js jt ju ma jw jx jy mb ka kb kc mc ke kf kg md ki kj kk ij bi translated">既然数据是干净的，是我开始用数据训练 ML 模型的时候了。因为我想确保我的模型在看不见的数据上表现良好，所以我将把我的训练数据分成一个较小的训练和测试数据集。这样，我可以在将模型带到 Kaggle 提供的实际测试数据之前评估模型的准确性(记住，我不能评估准确性，因为数据缺少“存活”变量)。</p><pre class="km kn ko kp gt me mf mg mh aw mi bi"><span id="0c17" class="mj lc iq mf b gy mk ml l mm mn">train_1 &lt;- stratified(train, c(“Survived”, “Deck”, “Title”), size = 0.7, replace = FALSE)<br/> train_2 &lt;- setdiff(train, train_1)</span></pre><p id="377d" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我将使用四种不同的模型，每种模型都有自己的预测方式:<a class="ae mp" href="https://en.wikipedia.org/wiki/Logistic_regression" rel="noopener ugc nofollow" target="_blank">线性模型</a>，随机森林模型，<a class="ae mp" href="https://en.wikipedia.org/wiki/XGBoost" rel="noopener ugc nofollow" target="_blank"> XGBoost </a>(极端梯度推进)模型和<a class="ae mp" href="https://en.wikipedia.org/wiki/H2O_(software)#Iterative_methods_for_real-time_problems" rel="noopener ugc nofollow" target="_blank"> H2O 的 AutoML </a>。同样，您可以随意点击超链接来了解这些模型是什么以及它们在做什么。</p><p id="548d" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">为了让下面发生的事情更容易理解，想象一下，我们想要赢得一场综合武术比赛，而不是预测泰坦尼克号的幸存者。在比赛开始前，我们只有足够的时间掌握一种武术，所以我们需要弄清楚我们应该学习哪一种才能最有机会获胜。我们知道竞争对手是谁(即我们的测试数据)，但我们不确定哪种武术最适合我们。下面是我们正在进行的模拟，我们学习四种不同的武术(比如拳击、柔术、太极拳和跆拳道)，看看我们如何应对与锦标赛中类似的竞争对手(即我们的训练数据)。</p><pre class="km kn ko kp gt me mf mg mh aw mi bi"><span id="98eb" class="mj lc iq mf b gy mk ml l mm mn"><em class="mq"># Linear Model — — </em><br/> glm_model &lt;- glm(Survived ~ . — PassengerId, family = “binomial”, train_1)<br/> <br/> <em class="mq"># Random Forest — — </em><br/> rf_model &lt;- randomForest(Survived ~ . — PassengerId, train_1, ntree = 10000, mtry = 3, na.action = na.exclude)<br/> <br/> <em class="mq"># XGBoost — — </em><br/> dummy_1 &lt;- dummyVars(Survived ~ ., train_1[,2:12])<br/> train_1_dummy &lt;- predict(dummy_1, train_1)<br/> dummy_2 &lt;- dummyVars(Survived ~ ., train_2[,2:12])<br/> train_2_dummy &lt;- predict(dummy_2, train_2)<br/> dtrain &lt;- xgb.DMatrix(data = train_1_dummy, label = as.vector(train_1$Survived))<br/> dtest &lt;- xgb.DMatrix(data = train_2_dummy, label = as.vector(train_2$Survived))<br/> <br/> watchlist &lt;- list(train = dtrain, test = dtest)<br/> <br/> xgb_model &lt;- xgb.train(<br/> data = dtrain,<br/> watchlist = watchlist,<br/> booster = “gbtree”,<br/> max.depth = 3,<br/> nthread = 2,<br/> nrounds = 5000,<br/> objective = “binary:logistic”,<br/> early_stopping_rounds = 500,<br/> print_every_n = 500<br/> )<br/> <br/> <em class="mq"># H2O — — </em><br/> train_1_h2o &lt;- train_1 %&gt;%<br/> select(-PassengerId) %&gt;%<br/> mutate(Pclass = factor(Pclass, ordered = FALSE)) %&gt;%<br/> as.h2o<br/> train_2_h2o &lt;- train_2 %&gt;%<br/> select(-PassengerId) %&gt;%<br/> mutate(Pclass = factor(Pclass, ordered = FALSE)) %&gt;%<br/> as.h2o<br/> <br/> y &lt;- “Survived”<br/> x &lt;- setdiff(colnames(train_1_h2o), y)<br/> <br/> split &lt;- h2o.splitFrame(train_1_h2o, ratios = c(.70, .15))<br/> <br/> t1 &lt;- split[[1]]<br/> t2 &lt;- split[[2]]<br/> t3 &lt;- split[[3]]<br/> <br/> h2o_model &lt;- h2o.automl(<br/> x = x,<br/> y = y,<br/> train = t1,<br/> validation_frame = t2,<br/> leaderboard_frame = t3,<br/> nfolds = 5,<br/> stopping_metric = “AUC”,<br/> max_runtime_secs = 120<br/> )<br/> h2o_leader &lt;- h2o_model@leader</span></pre><h1 id="fa0e" class="lb lc iq bd ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly bi translated">5.0 模型比较</h1><p id="4941" class="pw-post-body-paragraph jn jo iq jp b jq lz js jt ju ma jw jx jy mb ka kb kc mc ke kf kg md ki kj kk ij bi translated">继续上面的比喻，没有一种武术能胜过所有的对手，所以我们要试着找到表现最好的一种。对于武术来说，衡量的标准可能是获胜的次数。对于《泰坦尼克号》的预测，我将精确地衡量它(主要是因为这是 Kaggle 用来给这场比赛打分的)。</p><p id="c168" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">为了确定这种准确性，我将生成一个所谓的置信矩阵。简单地说，这是一个 2x2 的盒子，沿着 x 轴显示实际值(在输出中称为“参考值”)，沿着 y 轴显示预测值。这使您可以看到四个变量:</p><p id="3ced" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">真阳性:预测= 1，实际= 1</p><p id="44ed" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">真负数:预测= 0，实际= 0</p><p id="cb86" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">误报:预测= 1，实际= 0</p><p id="4799" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">假阴性:预测= 0，实际= 1</p><p id="a1ee" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">准确性是对所有预测中有多少真阳性和真阴性的一种衡量。</p><pre class="km kn ko kp gt me mf mg mh aw mi bi"><span id="61ce" class="mj lc iq mf b gy mk ml l mm mn">compare_set &lt;- train_2 %&gt;% add_column(GLM_Pred = predict(glm_model, train_2, <br/> type = “response”)) %&gt;% add_column(RF_Pred = predict(rf_model, train_2)) %&gt;% <br/> add_column(XGB_Pred = predict(xgb_model, train_2_dummy)) %&gt;% add_column(H2O_Pred = h2o.predict(h2o_leader, <br/> newdata = train_2_h2o) %&gt;% as_tibble() %&gt;% pull(predict)) %&gt;% mutate_at(vars(GLM_Pred, <br/> XGB_Pred), list(~factor(as.numeric(. &gt; 0.5))))<br/> <br/> for (i in 13:16) {<br/> conmat &lt;- confusionMatrix(compare_set$Survived, compare_set[[i]], positive = “1”)<br/> print(colnames(compare_set[, i]))<br/> print(conmat$table)<br/> print(conmat$overall[1])<br/> }</span><span id="7788" class="mj lc iq mf b gy mo ml l mm mn">## [1] “GLM_Pred”<br/> ##            Reference<br/> ## Prediction 0   1<br/> ##          0 141 21<br/> ##          1 23  75<br/> ## Accuracy <br/> ## 0.8307692 <br/> ## [1] “RF_Pred”<br/> ##            Reference<br/> ## Prediction 0   1<br/> ##          0 149 13<br/> ##          1 26  72<br/> ## Accuracy <br/> ## 0.85 <br/> ## [1] “XGB_Pred”<br/> ##            Reference<br/> ## Prediction 0   1<br/> ##          0 147 15<br/> ##          1 20  79<br/> ## Accuracy <br/> ## 0.8659004 <br/> ## [1] “H2O_Pred”<br/> ##            Reference<br/> ## Prediction 0   1<br/> ##          0 151 11<br/> ##          1 38  61<br/> ## Accuracy <br/> ## 0.8122605</span></pre><p id="603a" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">正如你所看到的，就纯粹的准确性而言，XGBoost 模型的表现最好，它正确预测了训练数据中所有幸存者的 86.6%。然而，准确性并不总是最好的衡量标准。如果您查看 XGBoost 的置信度矩阵，您会看到有 15 个假阴性。RF 模型虽然在准确性方面表现不佳，但只有 13 个假阴性。为什么这可能很重要取决于具体情况。</p><p id="8758" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">假设你是一名医生，负责确定病人是否患有某种疾病。假设对没有患病的人进行治疗是无害的，但如果不进行治疗，患病的人肯定会死亡。鉴于上述数字，RF 模型比 XGBoost 模型多拯救了两条生命。这里的要点是，永远不要简单地看准确性，并在此基础上做出最终判断。</p><p id="0a7b" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">所以我不会在这里！</p><p id="c2cc" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">相反，我将使用 RF 和 XGBoost 模型进行预测。由于第三次提交参赛作品不花我一分钱，我也将使用线性模型进行预测，因为它的准确性不会远远落后于其他两个模型。</p><h1 id="30fa" class="lb lc iq bd ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly bi translated">6.0 做出最终预测</h1><p id="8c39" class="pw-post-body-paragraph jn jo iq jp b jq lz js jt ju ma jw jx jy mb ka kb kc mc ke kf kg md ki kj kk ij bi translated">既然我已经有了训练有素的模型(或者说战士，如果你喜欢这个比喻的话)，是时候让它们发挥作用了。我将把它们用在测试数据上，这些数据是模型从未见过的。</p><pre class="km kn ko kp gt me mf mg mh aw mi bi"><span id="565a" class="mj lc iq mf b gy mk ml l mm mn"><em class="mq"># XGBoost</em><br/> dummy_test &lt;- dummyVars(PassengerId ~ ., test)<br/> test_dummy &lt;- predict(dummy_test, test)<br/> <br/> submission_xgboost &lt;- test %&gt;% add_column(Survived = predict(xgb_model, test_dummy)) %&gt;% <br/> mutate(Survived = as.numeric(Survived &gt; 0.5)) %&gt;% select(PassengerId, Survived)<br/> <br/> <em class="mq"># Random Forest</em><br/> submission_rf &lt;- test %&gt;% add_column(Survived = predict(rf_model, test)) %&gt;% <br/> select(PassengerId, Survived)<br/> <br/> <em class="mq"># Linear Model</em><br/> submission_glm &lt;- test %&gt;% add_column(Survived = predict(glm_model, test)) %&gt;% <br/> mutate(Survived = as.numeric(Survived &gt; 0.5)) %&gt;% select(PassengerId, Survived)</span></pre><p id="afee" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">让我们看看每个模型是如何预测测试数据中前 10 名乘客的存活率的。</p><pre class="km kn ko kp gt me mf mg mh aw mi bi"><span id="70b4" class="mj lc iq mf b gy mk ml l mm mn">submission_xgboost %&gt;% left_join(submission_rf, by = “PassengerId”) %&gt;% left_join(submission_glm, <br/> by = “PassengerId”) %&gt;% rename(XGBoost = Survived.x, RF = Survived.y, Linear = Survived) %&gt;% <br/> head(10)</span><span id="5d85" class="mj lc iq mf b gy mo ml l mm mn">## # A tibble: 10 x 4<br/> ##   PassengerId XGBoost RF    Linear<br/> ##   &lt;dbl&gt;       &lt;dbl&gt;   &lt;fct&gt; &lt;dbl&gt;<br/> ## 1 892         0       0     0<br/> ## 2 893         0       0     0<br/> ## 3 894         0       0     0<br/> ## 4 895         0       0     0<br/> ## 5 896         0       0     1<br/> ## 6 897         0       0     0<br/> ## 7 898         0       0     1<br/> ## 8 899         0       0     0<br/> ## 9 900         1       1     1<br/> ## 10 901        0       0     0</span></pre><p id="d32e" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">如你所见，三个模型都预测乘客 900 幸存。线性模型还预测乘客 896 和 898 幸存。</p><h1 id="b864" class="lb lc iq bd ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly bi translated">7.0 提交预测</h1><p id="07b2" class="pw-post-body-paragraph jn jo iq jp b jq lz js jt ju ma jw jx jy mb ka kb kc mc ke kf kg md ki kj kk ij bi translated">现在我有了我的预测，是时候把它们提交给 Kaggle，看看它们做得如何。首先，我必须将这些预测导出到一个 CSV 文件中，这样我就可以上传它们。</p><pre class="km kn ko kp gt me mf mg mh aw mi bi"><span id="5de9" class="mj lc iq mf b gy mk ml l mm mn">write_csv(submission_xgboost, “~/Downloads/Submission XGBoost.csv”)<br/> write_csv(submission_rf, “~/Downloads/Submission RF.csv”)<br/> write_csv(submission_glm, “~/Downloads/Submission GLM.csv”)</span></pre><p id="8239" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">上传 CSV 后，Kaggle 会生成我每次提交的最终分数。所以，让我们看看我做得怎么样。</p><figure class="km kn ko kp gt kq gh gi paragraph-image"><div role="button" tabindex="0" class="kr ks di kt bf ku"><div class="gh gi mr"><img src="../Images/8c7cd32ca5c1f0d4821e201a8c07ae3c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*qMc2p3EsBMjlXwWFk_w-HA.png"/></div></div></figure><p id="d850" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">哇！看那黑马胜利！完全出乎意料！尽管对训练数据执行了三个模型中的第三个，但线性模型实际上对测试数据执行了所有模型中最好的。我真的没想到会这样。这只是表明你可以做世界上所有的训练，有时胜利只是靠运气。</p><p id="937d" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">客观地说，78.9%的分数并不令人印象深刻，因为还有其他提交的作品获得了满分。但鉴于这是我的第一次比赛，我在 11098 名参赛者中名列第 3149 名(比其他参赛者的 71.6%要好)，我觉得这是一次令人满意的努力。</p><p id="e6d4" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">感谢您的阅读。我希望在下一个案例研究中见到您。</p></div></div>    
</body>
</html>