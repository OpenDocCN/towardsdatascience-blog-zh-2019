<html>
<head>
<title>Make Your Data Processing Code Fly in 5 Minutes</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">让你的数据处理代码在 5 分钟内飞起来</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/make-your-data-processing-code-fly-in-5-minutes-c4998e6da094?source=collection_archive---------6-----------------------#2019-04-12">https://towardsdatascience.com/make-your-data-processing-code-fly-in-5-minutes-c4998e6da094?source=collection_archive---------6-----------------------#2019-04-12</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="7a26" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">在 10 行代码内释放计算机的全部能力</h2></div><p id="79cc" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">尽管数据科学家被称为 21 世纪“最性感”的工作，但数据处理是数据从业者日常工作的重要组成部分，既费力又不有趣。在大数据时代，数据处理更加耗时，轻松需要几十个小时才能完成。这既是一个挫折，也阻碍了项目的进展。因此，数据从业者愿意编写复杂的代码，只是为了一点点的性能提升。然而，加速数据处理并不难！在本文中，我将介绍一些简单直观的方法来减少几种常见数据处理工作的运行时间。</p><h1 id="7600" class="lb lc iq bd ld le lf lg lh li lj lk ll jw lm jx ln jz lo ka lp kc lq kd lr ls bi translated">全力以赴</h1><p id="4359" class="pw-post-body-paragraph kf kg iq kh b ki lt jr kk kl lu ju kn ko lv kq kr ks lw ku kv kw lx ky kz la ij bi translated"><strong class="kh ir">首先</strong>，现代 CPU 快如闪电。像英特尔 i7 系列这样的流行 CPU 可以轻松实现 3 GHz 时钟，并且至少有 4 个内核，这意味着它们应该能够在合理的时间内执行大多数数据处理任务。然而，CPU 经常处于饥饿状态，这意味着代码受到其他因素的限制，如 I/O 延迟(磁盘到 RAM、RAM 到缓存等)。因此，减少 I/O 延迟至关重要。</p><figure class="lz ma mb mc gt md gh gi paragraph-image"><div role="button" tabindex="0" class="me mf di mg bf mh"><div class="gh gi ly"><img src="../Images/4f4367f3b94289ee4100fd6989a09ba3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*guU7MQitTJ2bN6CyZ6aB8w.png"/></div></div><figcaption class="mk ml gj gh gi mm mn bd b be z dk">from David Jeppesen’s <a class="ae mo" href="https://www.prowesscorp.com/computer-latency-at-a-human-scale/" rel="noopener ugc nofollow" target="_blank">‘Computer Latency at a Human Scale’</a></figcaption></figure><p id="2b81" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">正如你所看到的，从硬盘(旋转磁盘)读取数据相当慢。因此，如果您的任务是<a class="ae mo" href="https://stackoverflow.com/questions/868568/what-do-the-terms-cpu-bound-and-i-o-bound-mean" rel="noopener ugc nofollow" target="_blank"> <strong class="kh ir"> I/O 绑定的</strong>，您可以通过将数据读/写文件夹移动到 SSD 来提高其速度。</a></p><p id="d908" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir">其次</strong>，如果操作是<strong class="kh ir"> CPU 受限的</strong>，我们将不得不更深入地挖掘并行机制。并行性可以充分利用 CPU 的潜力，让您付出的每一分钱都物有所值。Python 提供了各种各样的并行计算库，但不幸的是，其中大多数都需要大量的额外设置代码和对线程/进程/同步等的理解。<strong class="kh ir"> Dask </strong>是一个库，它提供了并行计算，而无需向用户暴露并行配置的本质细节。我将向您展示在 Dask 的帮助下加速代码是多么容易。</p><h2 id="21a8" class="mp lc iq bd ld mq mr dn lh ms mt dp ll ko mu mv ln ks mw mx lp kw my mz lr na bi translated">系统配置</h2><p id="b30c" class="pw-post-body-paragraph kf kg iq kh b ki lt jr kk kl lu ju kn ko lv kq kr ks lw ku kv kw lx ky kz la ij bi translated">Dask 默认安装在 Anaconda Python 环境中。如果没有安装 dask，只需在终端中输入这一行代码</p><pre class="lz ma mb mc gt nb nc nd ne aw nf bi"><span id="6711" class="mp lc iq nc b gy ng nh l ni nj">pip3 install dask </span></pre><p id="c496" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">建立一个本地集群(集群中的每个核心都是一个工作者)</p><pre class="lz ma mb mc gt nb nc nd ne aw nf bi"><span id="b9f9" class="mp lc iq nc b gy ng nh l ni nj"># in python<br/>from dask.distributed import Client<br/>client = Client(scheduler = 'threads') # set up a local cluster<br/>client # prints out the url to dask dashboard, which can be helpful</span></pre><figure class="lz ma mb mc gt md gh gi paragraph-image"><div class="gh gi nk"><img src="../Images/321c11d19f373d3119cb4a1ac086a829.png" data-original-src="https://miro.medium.com/v2/resize:fit:810/format:webp/1*Cw9RjLAYh-sKhXiCyA3_VA.png"/></div></figure><p id="d721" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">就是这样！你现在有几个工人供你支配。</p><h1 id="c6ea" class="lb lc iq bd ld le lf lg lh li lj lk ll jw lm jx ln jz lo ka lp kc lq kd lr ls bi translated">容易加速的常见任务</h1><h2 id="b887" class="mp lc iq bd ld mq mr dn lh ms mt dp ll ko mu mv ln ks mw mx lp kw my mz lr na bi translated"><strong class="ak"> a .文件格式转换</strong></h2><p id="72e3" class="pw-post-body-paragraph kf kg iq kh b ki lt jr kk kl lu ju kn ko lv kq kr ks lw ku kv kw lx ky kz la ij bi translated"><strong class="kh ir"> <em class="nl">例 1:将 JSON 文件转换为 CSV</em></strong></p><p id="790c" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">将 JSON 转换为 CSV 是 web 爬行中的常见任务。处理 JSON 文件的一种常见方法是:</p><pre class="lz ma mb mc gt nb nc nd ne aw nf bi"><span id="e0f3" class="mp lc iq nc b gy ng nh l ni nj">file_list = os.listdir(base_dir)<br/>json_list = [file  for file in file_list if file.endswith('.json')]<br/>for file in json_list:<br/>    inp = os.path.join(base_dir, file)<br/>    out = os.path.join(base_dir, new_name)<br/>    json_process(inp, out) # convert each json to a csv</span></pre><p id="9cfe" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">但是，这种串行方法没有充分发挥机器的潜力。稍加修改，我们就能写出更好的代码:</p><pre class="lz ma mb mc gt nb nc nd ne aw nf bi"><span id="8f00" class="mp lc iq nc b gy ng nh l ni nj">file_list = os.listdir(base_dir)<br/>json_list = [file  for file in file_list if file.endswith('.json')]<br/>parallel_work = []<br/>for file in json_list:<br/>    inp = os.path.join(base_dir, file)<br/>    out = os.path.join(base_dir, new_name)<br/>    <strong class="nc ir">parallel_work.append(dask.delayed(json_process)(inp, out))# lazy<br/>dask.compute(*parallel_work) # make dask compute</strong></span></pre><p id="d36d" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir"> dask.delayed()是一个惰性信号，</strong>这意味着它不会执行函数(在本例中为 json_process ),除非被明确告知这样做。使用 delayed()的好处是系统会<strong class="kh ir">智能确定可并行化部分</strong>。</p><p id="bc52" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">例如，dask 可以在下面的操作中识别底层的任务依赖，然后同时处理尽可能多的操作(在本例中是 4 个任务)</p><pre class="lz ma mb mc gt nb nc nd ne aw nf bi"><span id="d777" class="mp lc iq nc b gy ng nh l ni nj">def add(x,y):<br/>    return x+y<br/>def minus(x,y):<br/>    return x-y;<br/>x = 10<br/>y = 1<br/>result = dask.delayed(add)(x,y) * dask.delayed(minus)(x,y) +  dask.delayed(minus)(x,y)/dask.delayed(add)(x,y)<br/><strong class="nc ir">result.visualize()# show task dependency</strong></span></pre><figure class="lz ma mb mc gt md gh gi paragraph-image"><div class="gh gi nm"><img src="../Images/5f2f9d79bb743394282ca3328d893c22.png" data-original-src="https://miro.medium.com/v2/resize:fit:822/format:webp/1*4ENPJnkimvpSyjNlWqAtHQ.png"/></div><figcaption class="mk ml gj gh gi mm mn bd b be z dk">task dependency graph generated by dask</figcaption></figure><p id="eae8" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">基准:将 JSON 文件处理成 CSV 格式的 dataframe。</p><figure class="lz ma mb mc gt md gh gi paragraph-image"><div class="gh gi nn"><img src="../Images/d42df27fa5dd3a9cc3715768d9ec364c.png" data-original-src="https://miro.medium.com/v2/resize:fit:972/format:webp/1*3HkqZLLIZaRhakAj7xMdPA.png"/></div><figcaption class="mk ml gj gh gi mm mn bd b be z dk">you can get the max speedup = # of cores</figcaption></figure><p id="6ec1" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir"> <em class="nl">例 2:将 CSV 合并成一个大 CSV </em> </strong></p><p id="53a5" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">数据从业者的另一个主要问题是合并 CSV。这是我在网上找到的一个代码:</p><pre class="lz ma mb mc gt nb nc nd ne aw nf bi"><span id="d52d" class="mp lc iq nc b gy ng nh l ni nj">#code 1<br/>df = pd.read_csv(file)<br/>for file in csv_list:<br/>    a = pd.read_csv(os.path.join(base_dir, file))<br/>    df = pd.concat([df,a])</span></pre><p id="35fe" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这段代码的性能会很差，因为 pd.concat()是一个开销很大的函数。pd.concat(df1，df2)重新分配新的内存空间，并将两个数据帧都复制到新的数据帧中。上面的代码给你二次运行时间。</p><figure class="lz ma mb mc gt md gh gi paragraph-image"><div role="button" tabindex="0" class="me mf di mg bf mh"><div class="gh gi no"><img src="../Images/f4176c9ccf63a34dc80371ed06f89e49.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*r8J3cpVesHZTLCzKpKI6gg.png"/></div></div><figcaption class="mk ml gj gh gi mm mn bd b be z dk">runtime analysis</figcaption></figure><p id="8da5" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">更好的解决方案:</p><pre class="lz ma mb mc gt nb nc nd ne aw nf bi"><span id="b7b0" class="mp lc iq nc b gy ng nh l ni nj">#code 2<br/>df_list= []<br/>for file in csv_list[1:]:<br/>    df= pd.read_csv(os.path.join(base_dir, file))<br/>    df_list.append(df)<br/>df = pd.concat(my_list)</span></pre><p id="53d6" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这段代码只复制数据帧一次，因此产生线性运行时间。我们不能显著改进这段代码，但是我们可以使用 dask 对它进行次线性改进。</p><pre class="lz ma mb mc gt nb nc nd ne aw nf bi"><span id="7258" class="mp lc iq nc b gy ng nh l ni nj">#code 3 with dask<br/>df_list =[]<br/>for file in csv_list:<br/>    df = dask.delayed(pd.read_csv)(os.path.join(base_dir, file))<br/>    df_list.append(df)<br/>df = dask.delayed(pd.concat)(df_list).compute)</span></pre><p id="c7e0" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">基准</p><figure class="lz ma mb mc gt md gh gi paragraph-image"><div class="gh gi np"><img src="../Images/367c81248268ac6066c2265af43f36be.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*02GEt8nEXj0zkBvynwV2ZA.png"/></div></figure><h2 id="317d" class="mp lc iq bd ld mq mr dn lh ms mt dp ll ko mu mv ln ks mw mx lp kw my mz lr na bi translated"><strong class="ak"> b .数据汇总</strong></h2><p id="1eae" class="pw-post-body-paragraph kf kg iq kh b ki lt jr kk kl lu ju kn ko lv kq kr ks lw ku kv kw lx ky kz la ij bi translated">Dask 提供了几种数据结构，dask.dataframe 是其中之一。Dask.dataframe 允许用户将一个巨大的数据帧分成多个块，这允许内核之间的协作。要创建 dask.dataframe，只需:</p><pre class="lz ma mb mc gt nb nc nd ne aw nf bi"><span id="1b8f" class="mp lc iq nc b gy ng nh l ni nj">from dask import dataframe as dd<br/><strong class="nc ir">dd_df = dd.from_pandas(df, npartitions=6)</strong><br/>dd_df.visualize()</span></pre><figure class="lz ma mb mc gt md gh gi paragraph-image"><div class="gh gi nq"><img src="../Images/9925d3b26af96680f89fa6198fe5a6f2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1170/format:webp/1*TJBQFWrtQXEe1LSgfyXXow.png"/></div><figcaption class="mk ml gj gh gi mm mn bd b be z dk">dask dataframe visualization</figcaption></figure><p id="b8d2" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">Dask.dataframe 对象与 pandas dataframe 非常相似(许多命令完全相同)。举个例子，</p><pre class="lz ma mb mc gt nb nc nd ne aw nf bi"><span id="6bbb" class="mp lc iq nc b gy ng nh l ni nj"># in pandas<br/>df.groupby(['Feature1']).sum()<br/>df['Feature1'].min()<br/>df['Feature1'].rolling(10).mean()</span><span id="acff" class="mp lc iq nc b gy nr nh l ni nj"># in dask<br/>dd_df.groupby('Feature1').sum().compute()<br/>dd_df['Feature1'].min().compute()<br/>dd_df['Feature1'].rolling(10).mean().compute()</span></pre><p id="af83" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">基准测试:groupby()</p><figure class="lz ma mb mc gt md gh gi paragraph-image"><div class="gh gi ns"><img src="../Images/978ea024acb50f0fb0bdd4f956e11874.png" data-original-src="https://miro.medium.com/v2/resize:fit:1024/format:webp/1*yiID872YDtAexwz3SpMbRQ.png"/></div></figure><figure class="lz ma mb mc gt md gh gi paragraph-image"><div class="gh gi nt"><img src="../Images/0769c5dff531556df2af86dcf6f00fec.png" data-original-src="https://miro.medium.com/v2/resize:fit:1056/format:webp/1*j4BSRvDPxV5kyln8JWVRWA.png"/></div></figure><p id="1e49" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">重要的一点是:数据帧分区不是随机的工作；根据您拥有的内核数量对数据进行分区是一个好主意。太多的分区将不可避免地增加通信开销。</p><h2 id="e313" class="mp lc iq bd ld mq mr dn lh ms mt dp ll ko mu mv ln ks mw mx lp kw my mz lr na bi translated"><strong class="ak"> c .特征工程</strong></h2><p id="901c" class="pw-post-body-paragraph kf kg iq kh b ki lt jr kk kl lu ju kn ko lv kq kr ks lw ku kv kw lx ky kz la ij bi translated">特征工程是一个好模型的重要前提。尽可能对代码进行矢量化总是一个好主意。例如:</p><pre class="lz ma mb mc gt nb nc nd ne aw nf bi"><span id="e7d0" class="mp lc iq nc b gy ng nh l ni nj">%timeit df['Feature3'] = df['Feature1'] **2<br/>#47.3 ms ± 982 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)<br/>%timeit df['Feature3'] = df['Feature1'].apply(transformsform)<br/>#2.62 s ± 47.8 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)</span></pre><p id="15bc" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">Pandas 基于<a class="ae mo" href="https://stackoverflow.com/questions/8385602/why-are-numpy-arrays-so-fast" rel="noopener ugc nofollow" target="_blank"> numpy 库</a>，一个高性能的计算库，因此任何矢量化的操作都非常快。幸运的是，我们在 dask 中得到相同的 API:</p><pre class="lz ma mb mc gt nb nc nd ne aw nf bi"><span id="d490" class="mp lc iq nc b gy ng nh l ni nj">dd_df['F1'] = dd_df['F1']**2 + dd_df['F2'] (lazy)</span></pre><p id="3cd3" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">然而，并不是所有的作品都可以矢量化。例如:如果您的数据帧看起来像这样，并且您希望提取名字，您必须使用 apply()。</p><figure class="lz ma mb mc gt md gh gi paragraph-image"><div class="gh gi nu"><img src="../Images/8341ee0dc747e238007740f14c845eda.png" data-original-src="https://miro.medium.com/v2/resize:fit:1042/format:webp/1*It9z_MW4UFOnbc9xkxbojg.png"/></div></figure><pre class="lz ma mb mc gt nb nc nd ne aw nf bi"><span id="a1ba" class="mp lc iq nc b gy ng nh l ni nj">#you can't vectorize this<br/>def operation(x):<br/>    return x.split(':')[0]</span></pre><p id="2c81" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">因为矢量化的操作通常足够快，所以我将重点放在不可矢量化的操作上。</p><p id="44f1" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir"> <em class="nl">例 1:列变换</em> </strong></p><pre class="lz ma mb mc gt nb nc nd ne aw nf bi"><span id="a1f4" class="mp lc iq nc b gy ng nh l ni nj">def operation(x):<br/>#some un-vectorizable operations with process time M<br/>return y</span><span id="dea0" class="mp lc iq nc b gy nr nh l ni nj">df['new'] = df.F1.apply(operation) # pandas<br/>ddf['new'] = ddf.F1.apply(operation).compute(<strong class="nc ir">scheduler ='processes'</strong>) # dask</span></pre><p id="064c" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我将调度器设置为‘processes ’,因为这段代码完全由 operation()控制。在这种情况下，向其他进程发送数据以换取真正的并行性是合理的(每个进程在一个分区上工作)。参见 dask 提供的解释:</p><blockquote class="nv nw nx"><p id="f819" class="kf kg nl kh b ki kj jr kk kl km ju kn ny kp kq kr nz kt ku kv oa kx ky kz la ij bi translated"><a class="ae mo" href="http://docs.dask.org/en/latest/scheduling.html" rel="noopener ugc nofollow" target="_blank"> <strong class="kh ir">引用</strong></a><em class="iq">‘线程调度器……是轻量级的……它引入了非常少的任务开销(每个任务大约 50us 然而，由于 Python 的全局解释器锁(GIL)，该调度器仅在您的计算由非 Python 代码主导时提供并行性。”</em></p><p id="f5e1" class="kf kg nl kh b ki kj jr kk kl km ju kn ny kp kq kr nz kt ku kv oa kx ky kz la ij bi translated">多处理调度程序…每一个任务及其所有的依赖项都被 <strong class="kh ir"> <em class="iq">运至</em> </strong> <em class="iq">的一个局部流程，执行完毕，然后它们的结果被</em> <strong class="kh ir"> <em class="iq">运回</em> </strong> <em class="iq">的主流程。这意味着它能够</em> <strong class="kh ir"> <em class="iq">绕过 GIL </em> </strong> <em class="iq">的问题，甚至在纯 Python 代码占主导地位的计算上提供并行性</em></p></blockquote><p id="04ab" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">基准:</p><p id="e465" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">移动数据的成本很高，这就是为什么只有当您希望执行的操作比进程间通信成本更高时，使用进程调度程序才有帮助:</p><figure class="lz ma mb mc gt md gh gi paragraph-image"><div role="button" tabindex="0" class="me mf di mg bf mh"><div class="gh gi ob"><img src="../Images/69f854ac915217bf0b58ca0fd5faabbb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*73tJhOmgUuoay-nxXvuvpQ.png"/></div></div><figcaption class="mk ml gj gh gi mm mn bd b be z dk">both n and theta play roles</figcaption></figure><p id="9952" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">正如你所看到的，大的 n 和大的θ可以使分母变小，从而使除法变大，这就是为什么我们想要大的 n 和θ。</p><figure class="lz ma mb mc gt md gh gi paragraph-image"><div class="gh gi oc"><img src="../Images/610b4c71a420b48d84ae752bd9cc0f13.png" data-original-src="https://miro.medium.com/v2/resize:fit:1312/format:webp/1*LFhriST3-HqwOm0duBF3gw.png"/></div><figcaption class="mk ml gj gh gi mm mn bd b be z dk">operation time and the length of dataframes both matter</figcaption></figure><p id="96cb" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">你要尽可能靠近右上角。另一方面，如果您的操作不需要那么长时间，或者您的数据帧很小，您可以只使用 pandas。</p><p id="3351" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir"> <em class="nl">例 2:多特征工程</em> </strong></p><p id="7843" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">如果有多列需要处理，可以同时处理这些列:</p><pre class="lz ma mb mc gt nb nc nd ne aw nf bi"><span id="e607" class="mp lc iq nc b gy ng nh l ni nj">#pandas<br/>operation1(df.F1)<br/>operation2(df.F2)<br/>operation3(df.F3)</span><span id="40e4" class="mp lc iq nc b gy nr nh l ni nj">#dask<br/>a = dask.delayed(operation1)(df.F1)<br/>b = dask.delayed(operation2)(df.F2)<br/>c = dask.delayed(operation3)(df.F3)<br/>work = [a,b,c]<br/>result = dask.compute(*work)</span></pre><p id="c2d6" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">基准测试:和前面的例子一样，操作时间和数据长度都很重要。</p><h1 id="521f" class="lb lc iq bd ld le lf lg lh li lj lk ll jw lm jx ln jz lo ka lp kc lq kd lr ls bi translated">摘要</h1><p id="6a82" class="pw-post-body-paragraph kf kg iq kh b ki lt jr kk kl lu ju kn ko lv kq kr ks lw ku kv kw lx ky kz la ij bi translated">数据处理可能非常耗时，尤其是由单线程处理时。我已经说明了利用 dask 充分发挥计算机的能力是多么容易。当然，还有其他多处理/线程库，但我认为 dask 是帮助数据从业者入门的最简单快捷的工具。</p><p id="5de9" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">现在去加速你的代码吧！</p><h1 id="5399" class="lb lc iq bd ld le lf lg lh li lj lk ll jw lm jx ln jz lo ka lp kc lq kd lr ls bi translated">相关材料</h1><p id="0f6a" class="pw-post-body-paragraph kf kg iq kh b ki lt jr kk kl lu ju kn ko lv kq kr ks lw ku kv kw lx ky kz la ij bi translated">Dask 网站:<a class="ae mo" href="https://docs.dask.org/en/latest/why.html" rel="noopener ugc nofollow" target="_blank">https://docs.dask.org/en/latest/why.html</a></p><p id="2c62" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">深度 Dask 教程:<a class="ae mo" href="https://github.com/dask/dask" rel="noopener ugc nofollow" target="_blank">https://github.com/dask/dask</a></p><p id="2ed2" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">达斯克概述:<a class="ae mo" href="https://www.youtube.com/watch?v=ods97a5Pzw0" rel="noopener ugc nofollow" target="_blank">https://www.youtube.com/watch?v=ods97a5Pzw0</a></p></div></div>    
</body>
</html>