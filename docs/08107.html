<html>
<head>
<title>Labeling Legal Documents Using Machine Learning</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用机器学习标记法律文档</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/labeling-legal-documents-using-machine-learning-49e3a34f2619?source=collection_archive---------30-----------------------#2019-11-06">https://towardsdatascience.com/labeling-legal-documents-using-machine-learning-49e3a34f2619?source=collection_archive---------30-----------------------#2019-11-06</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><h1 id="d8fb" class="jq jr it bd js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn bi translated"><strong class="ak">简介</strong></h1><p id="e467" class="pw-post-body-paragraph ko kp it kq b kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll im bi translated">标记数据的问题通常被认为是机器学习项目的第一步，其中开发了一个训练数据集，该数据集精确地表示看不见的、预期的“测试”数据。然而，对于大型数据集，包括自然语言语料库，标注工作本身就可以给组织带来巨大的价值。</p><p id="ad37" class="pw-post-body-paragraph ko kp it kq b kr lm kt ku kv ln kx ky kz lo lb lc ld lp lf lg lh lq lj lk ll im bi translated">图书馆，尤其是那些旨在教育学生和未来研究人员的学术机构，承担着这样的负担。虽然在使用光学字符识别(OCR)对无数数量的信息进行数字化方面已经取得了长足的进步，但是如果文本没有与基础附录或其他参考材料的链接，研究仍然会被证明是乏味和耗时的。</p><h1 id="e3bb" class="jq jr it bd js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn bi translated">数据</h1><p id="779b" class="pw-post-body-paragraph ko kp it kq b kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll im bi translated">在最近与一家受人尊敬的图书馆的项目中，我的任务是通过识别和标记所提交的证据文件的来源，促进历史法庭的抄本的易用性。这些文件要么是审判文件，要么是证据文件，要么是检方或辩方用来为自己的案件辩护的文件，证据文件是更广泛的文件领域的一部分，包含它们自己的命名方案。</p><p id="4e04" class="pw-post-body-paragraph ko kp it kq b kr lm kt ku kv ln kx ky kz lo lb lc ld lp lf lg lh lq lj lk ll im bi translated">每个人都有自己特定的识别方式。对于证据文件文档，正则表达式(regex)用于查找一组预定义的编码文档组中的任何一个。另一方面，区分控方和辩方的审判文件依赖于更微妙的上下文线索，并且经常需要仔细阅读记录以便正确地跟踪谈话。</p><h1 id="c69c" class="jq jr it bd js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn bi translated">该方法</h1><p id="7a65" class="pw-post-body-paragraph ko kp it kq b kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll im bi translated">在第一遍中，所有可能的引用都用 regex 标记，并且证据文件文档被分区。在剩余的参考文献中，那些明显是起诉或明显是辩护的参考文献被立即分类并搁置，以用作随机森林算法的训练集，以便对更模糊的情况做出决定。</p><p id="2fad" class="pw-post-body-paragraph ko kp it kq b kr lm kt ku kv ln kx ky kz lo lb lc ld lp lf lg lh lq lj lk ll im bi translated">这是模型最容易出错的地方。标签的准确性是最重要的，但紧接着是回忆(找到尽可能多的参考文献)。因此，我们与客户进行了定期的交流，客户对结果进行了人工检查，并向我们汇报。通过这种方式，我们可以对算法进行微调，例如，提供额外的功能、超参数调整或增加较少表示的类。</p><p id="cecc" class="pw-post-body-paragraph ko kp it kq b kr lm kt ku kv ln kx ky kz lo lb lc ld lp lf lg lh lq lj lk ll im bi translated">使用的主要特征是参考上下文。在所讨论的引用的任意一侧收集给定数量的单词或标记后，对实体进行词干分析和词汇化，并最终转换为词频逆文档频率(tf-idf)嵌入。这种方法根据最常见单词在每个“文档”中出现的频率(在这种情况下是围绕单个引用的上下文)对最常见单词的计数进行加权。因此，所有单词都将具有整数表示，能够作为输入提供给机器学习算法。</p><p id="6177" class="pw-post-body-paragraph ko kp it kq b kr lm kt ku kv ln kx ky kz lo lb lc ld lp lf lg lh lq lj lk ll im bi translated">同样的方案也适用于现任议长。其他特征是基于关键触发词的存在或不存在而构建的，例如“起诉”，或者律师或被告之一的名字。随机森林实现为:</p><pre class="lr ls lt lu gt lv lw lx ly aw lz bi"><span id="c405" class="ma jr it lw b gy mb mc l md me">forest = RandomForestClassifier(criterion='entropy', n_estimators=500, random_state=0, n_jobs=-1)</span></pre><p id="a233" class="pw-post-body-paragraph ko kp it kq b kr lm kt ku kv ln kx ky kz lo lb lc ld lp lf lg lh lq lj lk ll im bi translated">其中使用了“熵”分离选择标准。尽管计算量更大，但它通常更适合分类数据。确定在一系列概率阈值的每一个处的算法性能，以便最大化准确性和召回率。此后，任何大于这个界限的都被标为“起诉”，小于这个界限的都被标为“辩护”。</p><h1 id="c1da" class="jq jr it bd js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn bi translated">问题</h1><p id="ebbe" class="pw-post-body-paragraph ko kp it kq b kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll im bi translated">从一开始，该模型的准确性就很高，几乎不需要进一步增强。更大的挑战是确保我们获得大部分的引用。引用参考文献的方式有很大的不同，包括从缩写到零散的标点符号。必须构建正则表达式来接受跨多行出现的引用。此外，许多引用包含不同可能类型的组合，对于正则表达式定义来说，这看起来像多个唯一的标记机会。当在末尾用标签重新构造文本时，后者会变得特别麻烦，因为引用的尾部很容易被切断，并过早地被标签替换。</p><p id="c912" class="pw-post-body-paragraph ko kp it kq b kr lm kt ku kv ln kx ky kz lo lb lc ld lp lf lg lh lq lj lk ll im bi translated">这些边缘情况的唯一共同点是存在一个长度不超过五位数的数字。在第二次浏览抄本时，我们识别了所有剩余的数字，过滤掉任何可能发现的假阳性(日期、页码、基本形容词)。在剩下的那些中，规则被开发以确保参考(某些介绍性短语的存在)和分配的标签。</p><h1 id="c227" class="jq jr it bd js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn bi translated">经验教训</h1><p id="4fdd" class="pw-post-body-paragraph ko kp it kq b kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll im bi translated">虽然是功能性的，但是第二遍中所做的工作是非常特殊的，并且不容易在其他数据集上使用。然而，大部分工作，以及整个项目中的工作，非常类似于作为斯坦福大学<a class="ae mf" href="https://www.snorkel.org/" rel="noopener ugc nofollow" target="_blank">潜泳</a>项目一部分的标记函数(LFs)的应用。意识到标记数据是机器学习中最耗时和不一致的部分，他们使用基于规则的 LFs 来编码标记数据的方法。在这种情况下，覆盖率通常比精确度更难控制，因此，考虑到我们对回忆的限制，这个公式能有多好的帮助还有待观察。</p><p id="9feb" class="pw-post-body-paragraph ko kp it kq b kr lm kt ku kv ln kx ky kz lo lb lc ld lp lf lg lh lq lj lk ll im bi translated">我们使用的数据集不应被视为异常独特或不规则。法律文本是所有职业中最密集的，对于自然语言处理(NLP)提供的许多节省成本和时间的措施来说，似乎已经成熟。搜索速度至关重要，无论是像这里描述的那样，还是将<a class="ae mf" rel="noopener" target="_blank" href="/why-we-switched-from-spacy-to-flair-to-anonymize-french-legal-cases-e7588566825f">文本实体</a>与更广泛的关键词联系起来的一种手段。尽管我们的工作因文本不一致而变得复杂，这可能是 OCR 的产物，但我们不能指望更现代的文档会好得多。</p></div></div>    
</body>
</html>