<html>
<head>
<title>Time Series Forecasting with LSTMs using TensorFlow 2 and Keras in Python</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用 TensorFlow 2 和 Keras 在 Python 中使用 LSTMs 进行时间序列预测</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/time-series-forecasting-with-lstms-using-tensorflow-2-and-keras-in-python-6ceee9c6c651?source=collection_archive---------1-----------------------#2019-11-26">https://towardsdatascience.com/time-series-forecasting-with-lstms-using-tensorflow-2-and-keras-in-python-6ceee9c6c651?source=collection_archive---------1-----------------------#2019-11-26</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="075c" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">利用 LSTMs 进行时间序列预测的数据准备和预测介绍</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/53064b138f30f9570012f4af9d5c435c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*pEfOBEt4OgwJYlfNjjTGuA.jpeg"/></div></div></figure><blockquote class="ku kv kw"><p id="21bc" class="kx ky kz la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><em class="it">TL；DR 了解时间序列，并使用递归神经网络进行预测。准备序列数据并使用 LSTMs 进行简单预测。</em></p></blockquote><p id="a3b0" class="pw-post-body-paragraph kx ky it la b lb lc ju ld le lf jx lg lu li lj lk lv lm ln lo lw lq lr ls lt im bi translated">想学习如何使用多元时间序列数据？阅读下一部分:</p><div class="lx ly gp gr lz ma"><a rel="noopener follow" target="_blank" href="/demand-prediction-with-lstms-using-tensorflow-2-and-keras-in-python-1d1076fc89a0"><div class="mb ab fo"><div class="mc ab md cl cj me"><h2 class="bd iu gy z fp mf fr fs mg fu fw is bi translated">使用 TensorFlow 2 和 Keras 在 Python 中使用 LSTMs 进行需求预测</h2><div class="mh l"><h3 class="bd b gy z fp mf fr fs mg fu fw dk translated">了解如何通过深度学习从多元时间序列数据中预测需求</h3></div><div class="mi l"><p class="bd b dl z fp mf fr fs mg fu fw dk translated">towardsdatascience.com</p></div></div><div class="mj l"><div class="mk l ml mm mn mj mo ks ma"/></div></div></a></div><p id="6632" class="pw-post-body-paragraph kx ky it la b lb lc ju ld le lf jx lg lu li lj lk lv lm ln lo lw lq lr ls lt im bi translated">通常，您可能不得不处理包含时间成分的数据。不管你怎么眯眼，都很难做出你喜欢的数据独立性假设。似乎数据中的新值可能依赖于历史值。你怎么能使用这种数据来建立模型呢？</p><p id="bf8d" class="pw-post-body-paragraph kx ky it la b lb lc ju ld le lf jx lg lu li lj lk lv lm ln lo lw lq lr ls lt im bi translated">本指南将帮助您更好地理解时间序列数据，以及如何使用深度学习(递归神经网络)建立模型。您将学习如何预处理时间序列，构建一个简单的 LSTM 模型，训练它，并使用它来进行预测。以下是步骤:</p><ol class=""><li id="ed0d" class="mp mq it la b lb lc le lf lu mr lv ms lw mt lt mu mv mw mx bi translated">理解什么是时间序列</li><li id="1ba3" class="mp mq it la b lb my le mz lu na lv nb lw nc lt mu mv mw mx bi translated">了解递归神经网络</li><li id="0b7f" class="mp mq it la b lb my le mz lu na lv nb lw nc lt mu mv mw mx bi translated">在 Keras 中用 LSTMs 预测时间序列数据</li><li id="e9d1" class="mp mq it la b lb my le mz lu na lv nb lw nc lt mu mv mw mx bi translated">评估模型</li></ol><p id="b077" class="pw-post-body-paragraph kx ky it la b lb lc ju ld le lf jx lg lu li lj lk lv lm ln lo lw lq lr ls lt im bi translated"><a class="ae nd" href="https://colab.research.google.com/drive/1lUwtvOInzoaNC5eBMljRMVk1K9zcKD-b" rel="noopener ugc nofollow" target="_blank"> <strong class="la iu">在浏览器中运行完整的笔记本</strong> </a></p><p id="8ad9" class="pw-post-body-paragraph kx ky it la b lb lc ju ld le lf jx lg lu li lj lk lv lm ln lo lw lq lr ls lt im bi translated"><a class="ae nd" href="https://github.com/curiousily/Deep-Learning-For-Hackers" rel="noopener ugc nofollow" target="_blank"><strong class="la iu">GitHub 上的完整项目</strong> </a></p><h1 id="b97d" class="ne nf it bd ng nh ni nj nk nl nm nn no jz np ka nq kc nr kd ns kf nt kg nu nv bi translated">时间序列</h1><p id="440d" class="pw-post-body-paragraph kx ky it la b lb nw ju ld le nx jx lg lu ny lj lk lv nz ln lo lw oa lr ls lt im bi translated"><a class="ae nd" href="https://en.wikipedia.org/wiki/Time_series" rel="noopener ugc nofollow" target="_blank">时间序列</a>是数据点的集合，根据它们被收集的时间进行索引。大多数情况下，数据是以固定的时间间隔记录的。时间序列数据的特殊之处是什么？</p><p id="075e" class="pw-post-body-paragraph kx ky it la b lb lc ju ld le lf jx lg lu li lj lk lv lm ln lo lw lq lr ls lt im bi translated">预测未来时间序列值是实践中一个相当常见的问题。预测下一周的天气、明天的比特币价格、圣诞节期间你的销售数量以及未来的心脏衰竭都是常见的例子。</p><p id="09eb" class="pw-post-body-paragraph kx ky it la b lb lc ju ld le lf jx lg lu li lj lk lv lm ln lo lw lq lr ls lt im bi translated">时间序列数据引入了对先前时间步长的“硬依赖”,因此观测值独立性的假设不成立。时间序列可以具有哪些属性？</p><p id="64a1" class="pw-post-body-paragraph kx ky it la b lb lc ju ld le lf jx lg lu li lj lk lv lm ln lo lw lq lr ls lt im bi translated"><strong class="la iu">平稳性</strong>、<strong class="la iu">季节性</strong>和<strong class="la iu">自相关性</strong>是您可能感兴趣的时间序列的一些属性。</p><p id="f8dd" class="pw-post-body-paragraph kx ky it la b lb lc ju ld le lf jx lg lu li lj lk lv lm ln lo lw lq lr ls lt im bi translated">当均值和方差随时间保持不变时，称时间序列为<strong class="la iu">平稳</strong>。如果平均值随时间变化，那么时间序列具有<strong class="la iu">趋势</strong>。通常，您可以通过应用对数变换来消除它并使序列平稳。</p><p id="4c1d" class="pw-post-body-paragraph kx ky it la b lb lc ju ld le lf jx lg lu li lj lk lv lm ln lo lw lq lr ls lt im bi translated"><strong class="la iu">季节性</strong>是指特定时间范围内的变化现象。人们在圣诞节期间购买更多的圣诞树(谁会想到)。消除季节性的一种常见方法是使用<a class="ae nd" href="https://www.quora.com/What-is-the-purpose-of-differencing-in-time-series-models" rel="noopener ugc nofollow" target="_blank">差异</a>。</p><p id="25a6" class="pw-post-body-paragraph kx ky it la b lb lc ju ld le lf jx lg lu li lj lk lv lm ln lo lw lq lr ls lt im bi translated"><a class="ae nd" href="https://en.wikipedia.org/wiki/Autocorrelation" rel="noopener ugc nofollow" target="_blank"> <strong class="la iu">自相关</strong> </a>指当前值与前一时间(滞后)的拷贝值之间的相关性。</p><p id="efea" class="pw-post-body-paragraph kx ky it la b lb lc ju ld le lf jx lg lu li lj lk lv lm ln lo lw lq lr ls lt im bi translated">为什么我们想要季节性、趋势性和平稳的时间序列？这是用经典方法如<a class="ae nd" href="https://en.wikipedia.org/wiki/Autoregressive_integrated_moving_average" rel="noopener ugc nofollow" target="_blank"> ARIMA 模型</a>进行时间序列预测所需的数据预处理步骤。幸运的是，我们将使用递归神经网络进行建模。</p><h1 id="f928" class="ne nf it bd ng nh ni nj nk nl nm nn no jz np ka nq kc nr kd ns kf nt kg nu nv bi translated">递归神经网络</h1><p id="bfcc" class="pw-post-body-paragraph kx ky it la b lb nw ju ld le nx jx lg lu ny lj lk lv nz ln lo lw oa lr ls lt im bi translated">递归神经网络(RNNs)可以预测序列中的下一个值或对其进行分类。一个序列被存储为一个矩阵，其中每一行都是一个描述它的特征向量。自然，矩阵中行的顺序很重要。</p><p id="bf28" class="pw-post-body-paragraph kx ky it la b lb lc ju ld le lf jx lg lu li lj lk lv lm ln lo lw lq lr ls lt im bi translated">rnn 非常适合解决自然语言处理(NLP)任务，其中文本中的单词形成序列，它们的位置很重要。也就是说，前沿 NLP 使用变压器来完成大多数(如果不是全部)任务。</p><p id="a895" class="pw-post-body-paragraph kx ky it la b lb lc ju ld le lf jx lg lu li lj lk lv lm ln lo lw lq lr ls lt im bi translated">你可能已经猜到了，时间序列只是序列的一种类型。我们必须将时间序列切割成更小的序列，这样我们的 RNN 模型就可以用它们进行训练。但是我们如何训练 rnn 呢？</p><p id="aa5d" class="pw-post-body-paragraph kx ky it la b lb lc ju ld le lf jx lg lu li lj lk lv lm ln lo lw lq lr ls lt im bi translated">首先，让我们对递归的含义有一个直观的理解。rnn 包含循环。每个单元都有一个状态，并接收两个输入-来自前一层的状态和来自前一时间步的该层的统计数据。</p><p id="78de" class="pw-post-body-paragraph kx ky it la b lb lc ju ld le lf jx lg lu li lj lk lv lm ln lo lw lq lr ls lt im bi translated"><a class="ae nd" href="https://en.wikipedia.org/wiki/Backpropagation" rel="noopener ugc nofollow" target="_blank">反向传播算法</a>在应用于 RNNs 时会因为循环连接而失效。展开网络可以解决这个问题，在网络中，具有循环连接的神经元的副本被创建。这将 RNN 转换成常规的前馈神经网络，并且可以应用经典的反向传播。该修改被称为通过时间的<a class="ae nd" href="https://en.wikipedia.org/wiki/Backpropagation_through_time" rel="noopener ugc nofollow" target="_blank">反向传播。</a></p><h2 id="212a" class="ob nf it bd ng oc od dn nk oe of dp no lu og oh nq lv oi oj ns lw ok ol nu om bi translated">经典 rnn 的问题</h2><p id="684b" class="pw-post-body-paragraph kx ky it la b lb nw ju ld le nx jx lg lu ny lj lk lv nz ln lo lw oa lr ls lt im bi translated">展开的神经网络会变得非常深(他就是这么说的)，这给梯度计算带来了问题。权重可以变得非常小(<a class="ae nd" href="https://en.wikipedia.org/wiki/Vanishing_gradient_problem" rel="noopener ugc nofollow" target="_blank">消失梯度问题</a>)或者非常大(<a class="ae nd" href="https://www.curiousily.com/posts/time-series-forecasting-with-lstms-using-tensorflow-2-and-keras-in-python/(https://en.wikipedia.org/wiki/Vanishing_gradient_problem)" rel="noopener ugc nofollow" target="_blank">爆炸梯度问题</a>)。</p><p id="3b9a" class="pw-post-body-paragraph kx ky it la b lb lc ju ld le lf jx lg lu li lj lk lv lm ln lo lw lq lr ls lt im bi translated">经典的 rnn 也有记忆问题(长期依赖性)。由于最近状态的压倒性影响，我们用于训练的序列的乞求倾向于被“遗忘”。</p><p id="616b" class="pw-post-body-paragraph kx ky it la b lb lc ju ld le lf jx lg lu li lj lk lv lm ln lo lw lq lr ls lt im bi translated">在实践中，这些问题可以通过使用门控 rnn 来解决。它们可以存储信息以备后用，就像有一个内存一样。阅读、写作和从记忆中删除都是从数据中学习的。两种最常用的门控 rnn 是<a class="ae nd" href="https://en.wikipedia.org/wiki/Long_short-term_memory" rel="noopener ugc nofollow" target="_blank">长短期记忆网络</a>和<a class="ae nd" href="https://en.wikipedia.org/wiki/Gated_recurrent_unit" rel="noopener ugc nofollow" target="_blank">门控复发性单位神经网络</a>。</p><h1 id="5ae0" class="ne nf it bd ng nh ni nj nk nl nm nn no jz np ka nq kc nr kd ns kf nt kg nu nv bi translated">用 LSTMs 进行时间序列预测</h1><p id="481f" class="pw-post-body-paragraph kx ky it la b lb nw ju ld le nx jx lg lu ny lj lk lv nz ln lo lw oa lr ls lt im bi translated">我们将从一个简单的例子开始，使用简单的 LSTM 网络预测<a class="ae nd" href="https://en.wikipedia.org/wiki/Sine" rel="noopener ugc nofollow" target="_blank">正弦函数</a>的值。</p><h1 id="de2b" class="ne nf it bd ng nh ni nj nk nl nm nn no jz np ka nq kc nr kd ns kf nt kg nu nv bi translated">设置</h1><p id="9d2a" class="pw-post-body-paragraph kx ky it la b lb nw ju ld le nx jx lg lu ny lj lk lv nz ln lo lw oa lr ls lt im bi translated">让我们从库导入和设置种子开始:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="on oo l"/></div></figure><h1 id="029a" class="ne nf it bd ng nh ni nj nk nl nm nn no jz np ka nq kc nr kd ns kf nt kg nu nv bi translated">数据</h1><p id="740f" class="pw-post-body-paragraph kx ky it la b lb nw ju ld le nx jx lg lu ny lj lk lv nz ln lo lw oa lr ls lt im bi translated">我们将从正弦函数中生成<em class="kz"> 1，000 </em>值，并将其作为训练数据。但是，我们会添加一点<em class="kz">精加工</em>:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="on oo l"/></div></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi op"><img src="../Images/e6c698dc7ef730850870c487d24639d9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*r7uYE1VItwSX2Vuq.png"/></div></div></figure><p id="a38e" class="pw-post-body-paragraph kx ky it la b lb lc ju ld le lf jx lg lu li lj lk lv lm ln lo lw lq lr ls lt im bi translated">从正态分布中提取的随机值被添加到每个数据点。那会让我们模型的工作变得有点困难。</p><h1 id="f80c" class="ne nf it bd ng nh ni nj nk nl nm nn no jz np ka nq kc nr kd ns kf nt kg nu nv bi translated">数据预处理</h1><p id="5112" class="pw-post-body-paragraph kx ky it la b lb nw ju ld le nx jx lg lu ny lj lk lv nz ln lo lw oa lr ls lt im bi translated">对于我们的模型，我们需要将数据“切碎”成更小的序列。但首先，我们将把它分为训练和测试数据:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="on oo l"/></div></figure><pre class="kj kk kl km gt oq or os ot aw ou bi"><span id="8b96" class="ob nf it or b gy ov ow l ox oy">800 200</span></pre><p id="6939" class="pw-post-body-paragraph kx ky it la b lb lc ju ld le lf jx lg lu li lj lk lv lm ln lo lw lq lr ls lt im bi translated">为时间序列预测(尤其是 LSTMs)准备数据可能很困难。直观地说，我们需要利用历史(<em class="kz"> n </em>时间步长)来预测当前时间步长的值。这里有一个通用函数可以完成这项工作:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="on oo l"/></div></figure><p id="2296" class="pw-post-body-paragraph kx ky it la b lb lc ju ld le lf jx lg lu li lj lk lv lm ln lo lw lq lr ls lt im bi translated">该函数的妙处在于它可以处理单变量(单特征)和多变量(多特征)时间序列数据。让我们用 10 个时间步骤的历史来制作我们的序列:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="on oo l"/></div></figure><pre class="kj kk kl km gt oq or os ot aw ou bi"><span id="af0f" class="ob nf it or b gy ov ow l ox oy">(790, 10, 1) (790,)</span></pre><p id="8313" class="pw-post-body-paragraph kx ky it la b lb lc ju ld le lf jx lg lu li lj lk lv lm ln lo lw lq lr ls lt im bi translated">我们有形状为<code class="fe oz pa pb or b">(samples, time_steps, features)</code>的序列。我们怎么用它们来做预测呢？</p><h1 id="6061" class="ne nf it bd ng nh ni nj nk nl nm nn no jz np ka nq kc nr kd ns kf nt kg nu nv bi translated">建模</h1><p id="f829" class="pw-post-body-paragraph kx ky it la b lb nw ju ld le nx jx lg lu ny lj lk lv nz ln lo lw oa lr ls lt im bi translated">在喀拉斯培养 LSTM 模式很容易。我们将使用序列模型中的<a class="ae nd" href="https://www.tensorflow.org/api_docs/python/tf/keras/layers/LSTM" rel="noopener ugc nofollow" target="_blank"> LSTM 层</a>进行预测:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="on oo l"/></div></figure><p id="094f" class="pw-post-body-paragraph kx ky it la b lb lc ju ld le lf jx lg lu li lj lk lv lm ln lo lw lq lr ls lt im bi translated">LSTM 图层期望时间步长数和要素数能够正常工作。模型的其余部分看起来像一个常规的回归模型。我们如何训练一个 LSTM 模特？</p><h1 id="c674" class="ne nf it bd ng nh ni nj nk nl nm nn no jz np ka nq kc nr kd ns kf nt kg nu nv bi translated">培养</h1><p id="c9c6" class="pw-post-body-paragraph kx ky it la b lb nw ju ld le nx jx lg lu ny lj lk lv nz ln lo lw oa lr ls lt im bi translated">训练时间序列模型时要记住的最重要的事情是不要打乱数据(数据的顺序很重要)。其余的都很标准:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="on oo l"/></div></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pc"><img src="../Images/9e4ae76de5fbfa00e3b1b093bfe6d2df.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*WicIjj9kj-YBBfeP.png"/></div></div></figure><p id="0779" class="pw-post-body-paragraph kx ky it la b lb lc ju ld le lf jx lg lu li lj lk lv lm ln lo lw lq lr ls lt im bi translated">我们的数据集非常简单，包含了我们采样的随机性。经过大约 15 个时期后，模型已经基本完成了学习。</p><h1 id="b8f0" class="ne nf it bd ng nh ni nj nk nl nm nn no jz np ka nq kc nr kd ns kf nt kg nu nv bi translated">估价</h1><p id="8080" class="pw-post-body-paragraph kx ky it la b lb nw ju ld le nx jx lg lu ny lj lk lv nz ln lo lw oa lr ls lt im bi translated">让我们从我们的模型中选取一些预测:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="on oo l"/></div></figure><p id="1f4e" class="pw-post-body-paragraph kx ky it la b lb lc ju ld le lf jx lg lu li lj lk lv lm ln lo lw lq lr ls lt im bi translated">我们可以根据时间序列的真实值绘制预测图:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pd"><img src="../Images/b2a495e3141408df6ffa1c1d83ccabc9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*JQn_ZGJdv8ru7ZUu.png"/></div></div></figure><p id="d557" class="pw-post-body-paragraph kx ky it la b lb lc ju ld le lf jx lg lu li lj lk lv lm ln lo lw lq lr ls lt im bi translated">我们的预测在这个尺度上看起来非常好。让我们放大:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pe"><img src="../Images/6be114c2acdfe3afc8e6d71ca9358101.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*NxeWQekf5WbjNIuw.png"/></div></div></figure><p id="f19f" class="pw-post-body-paragraph kx ky it la b lb lc ju ld le lf jx lg lu li lj lk lv lm ln lo lw lq lr ls lt im bi translated">该模型似乎在捕捉数据的一般模式方面做得很好。它未能捕捉到随机波动，这是一件好事(它概括得很好)。</p><h1 id="7a89" class="ne nf it bd ng nh ni nj nk nl nm nn no jz np ka nq kc nr kd ns kf nt kg nu nv bi translated">结论</h1><p id="0448" class="pw-post-body-paragraph kx ky it la b lb nw ju ld le nx jx lg lu ny lj lk lv nz ln lo lw oa lr ls lt im bi translated">恭喜你！你做了你的第一个递归神经网络模型！您还了解了如何预处理时间序列数据，这是一件让很多人感到困惑的事情。</p><p id="7c54" class="pw-post-body-paragraph kx ky it la b lb lc ju ld le lf jx lg lu li lj lk lv lm ln lo lw lq lr ls lt im bi translated">我们只是触及了时间序列数据和如何使用递归神经网络的表面。一些有趣的应用是时间序列预测、(序列)分类和异常检测。有趣的部分才刚刚开始！</p><p id="9fb2" class="pw-post-body-paragraph kx ky it la b lb lc ju ld le lf jx lg lu li lj lk lv lm ln lo lw lq lr ls lt im bi translated">想学习如何使用多元时间序列数据？阅读下一部分:</p><div class="lx ly gp gr lz ma"><a rel="noopener follow" target="_blank" href="/demand-prediction-with-lstms-using-tensorflow-2-and-keras-in-python-1d1076fc89a0"><div class="mb ab fo"><div class="mc ab md cl cj me"><h2 class="bd iu gy z fp mf fr fs mg fu fw is bi translated">使用 TensorFlow 2 和 Keras 在 Python 中使用 LSTMs 进行需求预测</h2><div class="mh l"><h3 class="bd b gy z fp mf fr fs mg fu fw dk translated">了解如何通过深度学习从多元时间序列数据中预测需求</h3></div><div class="mi l"><p class="bd b dl z fp mf fr fs mg fu fw dk translated">towardsdatascience.com</p></div></div><div class="mj l"><div class="mk l ml mm mn mj mo ks ma"/></div></div></a></div><p id="987b" class="pw-post-body-paragraph kx ky it la b lb lc ju ld le lf jx lg lu li lj lk lv lm ln lo lw lq lr ls lt im bi translated"><a class="ae nd" href="https://colab.research.google.com/drive/1lUwtvOInzoaNC5eBMljRMVk1K9zcKD-b" rel="noopener ugc nofollow" target="_blank"> <strong class="la iu">在浏览器中运行完整的笔记本</strong> </a></p><p id="a217" class="pw-post-body-paragraph kx ky it la b lb lc ju ld le lf jx lg lu li lj lk lv lm ln lo lw lq lr ls lt im bi translated"><a class="ae nd" href="https://github.com/curiousily/Deep-Learning-For-Hackers" rel="noopener ugc nofollow" target="_blank"><strong class="la iu">GitHub 上的完整项目</strong> </a></p><h1 id="8746" class="ne nf it bd ng nh ni nj nk nl nm nn no jz np ka nq kc nr kd ns kf nt kg nu nv bi translated">参考</h1><ul class=""><li id="0e57" class="mp mq it la b lb nw le nx lu pf lv pg lw ph lt pi mv mw mx bi translated"><a class="ae nd" href="https://www.tensorflow.org/tutorials/structured_data/time_series" rel="noopener ugc nofollow" target="_blank">张量流—时间序列预测</a></li><li id="2891" class="mp mq it la b lb my le mz lu na lv nb lw nc lt pi mv mw mx bi translated"><a class="ae nd" href="https://colah.github.io/posts/2015-08-Understanding-LSTMs/" rel="noopener ugc nofollow" target="_blank">了解 LSTM 网络</a></li></ul></div><div class="ab cl pj pk hx pl" role="separator"><span class="pm bw bk pn po pp"/><span class="pm bw bk pn po pp"/><span class="pm bw bk pn po"/></div><div class="im in io ip iq"><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="pq oo l"/></div></figure></div><div class="ab cl pj pk hx pl" role="separator"><span class="pm bw bk pn po pp"/><span class="pm bw bk pn po pp"/><span class="pm bw bk pn po"/></div><div class="im in io ip iq"><div class="kj kk kl km gt ma"><a href="https://leanpub.com/Hackers-Guide-to-Machine-Learning-with-Python" rel="noopener  ugc nofollow" target="_blank"><div class="mb ab fo"><div class="mc ab md cl cj me"><h2 class="bd iu gy z fp mf fr fs mg fu fw is bi translated">用 Python 进行机器学习的黑客指南</h2><div class="mh l"><h3 class="bd b gy z fp mf fr fs mg fu fw dk translated">Scikit-Learn、TensorFlow 和 Keras 深度学习实践指南了解如何解决现实世界的机器学习…</h3></div><div class="mi l"><p class="bd b dl z fp mf fr fs mg fu fw dk translated">leanpub.com</p></div></div><div class="mj l"><div class="pr l ml mm mn mj mo ks ma"/></div></div></a></div></div><div class="ab cl pj pk hx pl" role="separator"><span class="pm bw bk pn po pp"/><span class="pm bw bk pn po pp"/><span class="pm bw bk pn po"/></div><div class="im in io ip iq"><p id="171d" class="pw-post-body-paragraph kx ky it la b lb lc ju ld le lf jx lg lu li lj lk lv lm ln lo lw lq lr ls lt im bi translated"><em class="kz">原载于</em><a class="ae nd" href="https://www.curiousily.com/posts/time-series-forecasting-with-lstms-using-tensorflow-2-and-keras-in-python/" rel="noopener ugc nofollow" target="_blank"><em class="kz">https://www.curiousily.com</em></a><em class="kz">。</em></p></div></div>    
</body>
</html>