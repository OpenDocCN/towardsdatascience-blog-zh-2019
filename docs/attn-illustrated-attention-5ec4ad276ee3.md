# æ”¶ä»¶äºº:å›¾æ–‡å¹¶èŒ‚

> åŸæ–‡ï¼š<https://towardsdatascience.com/attn-illustrated-attention-5ec4ad276ee3?source=collection_archive---------3----------------------->

![](img/a8947aa33619fde621befe2692f6c9bd.png)

## gif å›¾ç‰‡ä¸­çš„æ³¨æ„åŠ›ï¼Œä»¥åŠå¦‚ä½•åœ¨è°·æ­Œç¿»è¯‘è¿™æ ·çš„æœºå™¨ç¿»è¯‘ä¸­ä½¿ç”¨å®ƒ

*(TLDR:åŠ¨ç”»ä¸ºå…³æ³¨* [*æ­¤å¤„*](#0458) *)*

*å˜æ›´æ—¥å¿—:ã€2022 å¹´ 1 æœˆ 5 æ—¥â€”ä¿®å¤é”™åˆ«å­—å¹¶æé«˜æ¸…æ™°åº¦*

F å‡ åå¹´æ¥ï¼Œç»Ÿè®¡æœºå™¨ç¿»è¯‘ä¸€ç›´æ˜¯å ä¸»å¯¼åœ°ä½çš„ç¿»è¯‘æ¨¡å¼ [9](#df28) ï¼Œç›´åˆ°**ç¥ç»æœºå™¨ç¿»è¯‘** (NMT)çš„è¯ç”Ÿã€‚NMT æ˜¯ä¸€ç§æ–°å…´çš„æœºå™¨ç¿»è¯‘æ–¹æ³•ï¼Œå®ƒè¯•å›¾å»ºç«‹å’Œè®­ç»ƒä¸€ä¸ªå•ä¸€çš„å¤§å‹ç¥ç»ç½‘ç»œï¼Œè¯¥ç½‘ç»œè¯»å–è¾“å…¥æ–‡æœ¬å¹¶è¾“å‡ºç¿»è¯‘[ [1](#30c6) ]ã€‚

NMT çš„å…ˆé©±æ˜¯æ¥è‡ª [Kalchbrenner å’Œ Blunsom (2013)](https://www.aclweb.org/anthology/D13-1176) ã€ [Sutskever *ç­‰äººçš„æè®®ã€‚al* (2014)](https://arxiv.org/abs/1409.3215) å’Œ [Choã€‚ *etal* (2014b)](https://arxiv.org/abs/1409.1259) ï¼Œå…¶ä¸­æ›´ç†Ÿæ‚‰çš„æ¡†æ¶æ˜¯ä» Sutskever *ç­‰äººé‚£é‡Œå­¦ä¹ çš„åºåˆ—å¯¹åºåˆ—(seq2seq)ã€‚è‰¾å°”*ã€‚æœ¬æ–‡å°†åŸºäº seq2seq æ¡†æ¶ï¼Œä»¥åŠå¦‚ä½•åœ¨å…¶ä¸Šå»ºç«‹æ³¨æ„åŠ›ã€‚

![](img/e0af6ad56c737c0dfc988d6e9737deee.png)

Fig. 0.1: seq2seq with an input sequence of length 4

åœ¨ **seq2seq** ä¸­ï¼Œæƒ³æ³•æ˜¯æ‹¥æœ‰ä¸¤ä¸ªå…·æœ‰ç¼–ç å™¨-è§£ç å™¨æ¶æ„çš„é€’å½’ç¥ç»ç½‘ç»œ(RNNs):é€ä¸ªè¯»å–è¾“å…¥å•è¯ä»¥è·å¾—å›ºå®šç»´åº¦çš„å‘é‡è¡¨ç¤º(ç¼–ç å™¨)ï¼Œå¹¶æ ¹æ®è¿™äº›è¾“å…¥ï¼Œä½¿ç”¨å¦ä¸€ä¸ª RNN(è§£ç å™¨)é€ä¸ªæå–è¾“å‡ºå•è¯ã€‚è§£é‡Šæ”¹ç¼–è‡ª [5](#16cb) ã€‚

![](img/bfd9b71503986dacfed9b52953d9866a.png)

Fig. 0.2: seq2seq with an input sequence of length 64

seq2seq çš„é—®é¢˜åœ¨äºï¼Œè§£ç å™¨ä»ç¼–ç å™¨æ¥æ”¶åˆ°çš„*å”¯ä¸€çš„*ä¿¡æ¯æ˜¯**æœ€åä¸€ä¸ªç¼–ç å™¨éšè—çŠ¶æ€**(å›¾ 0.1 ä¸­çš„ 2 ä¸ªå¾®å°çº¢è‰²èŠ‚ç‚¹)ï¼Œè¿™æ˜¯ä¸€ç§çŸ¢é‡è¡¨ç¤ºï¼Œå°±åƒè¾“å…¥åºåˆ—çš„æ•°å­—æ±‡æ€»ã€‚å› æ­¤ï¼Œå¯¹äºä¸€ä¸ªé•¿çš„è¾“å…¥æ–‡æœ¬(å›¾ 0.2)ï¼Œæˆ‘ä»¬ä¸åˆç†åœ°æœŸæœ›è§£ç å™¨åªä½¿ç”¨è¿™ä¸ª*ä¸€ä¸ª*å‘é‡è¡¨ç¤º(å¸Œæœ›å®ƒâ€œå……åˆ†æ¦‚æ‹¬äº†è¾“å…¥åºåˆ—â€)æ¥è¾“å‡ºç¿»è¯‘ã€‚è¿™å¯èƒ½ä¼šå¯¼è‡´ç¾éš¾æ€§çš„é—å¿˜ã€‚è¿™ä¸€æ®µæœ‰ 100 ä¸ªå•è¯ã€‚ä½ èƒ½æŠŠè¿™ä¸€æ®µç¿»è¯‘æˆä½ çŸ¥é“çš„å¦ä¸€ç§è¯­è¨€å—ï¼Œå°±åœ¨è¿™ä¸ªé—®å·åé¢ï¼Ÿ

å¦‚æœä¸èƒ½ï¼Œé‚£æˆ‘ä»¬å°±ä¸åº”è¯¥å¯¹è§£ç è€…è¿™ä¹ˆæ®‹å¿ã€‚ä¸ä»…ä»…æ˜¯ä¸€ä¸ªå‘é‡è¡¨ç¤ºï¼Œè®©æˆ‘ä»¬åœ¨æ¯ä¸ªç¼–ç å™¨æ—¶é—´æ­¥ç»™è§£ç å™¨ä¸€ä¸ªæ¥è‡ª*çš„å‘é‡è¡¨ç¤ºï¼Œè¿™æ ·å®ƒå°±å¯ä»¥åšå‡ºæ¶ˆæ¯çµé€šçš„ç¿»è¯‘ï¼Œæ€ä¹ˆæ ·ï¼Ÿè¿›å…¥**å…³æ³¨**ã€‚*

![](img/82d06e71421816a3153c3b8b8b60aa90.png)

Fig 0.3: Adding an attention layer as an interface between encoder and decoder. Here, the first decoder time step is getting ready to receive information from the encoder before giving the first translated word.

æ³¨æ„æ˜¯ç¼–ç å™¨å’Œè§£ç å™¨ä¹‹é—´çš„æ¥å£ï¼Œå®ƒå‘è§£ç å™¨æä¾›æ¥è‡ªæ¯ä¸ªç¼–ç å™¨éšè—çŠ¶æ€çš„ä¿¡æ¯(é™¤äº†å›¾ 0.3 ä¸­çº¢è‰²çš„éšè—çŠ¶æ€)ã€‚é€šè¿‡è¿™ç§è®¾ç½®ï¼Œæ¨¡å‹å¯ä»¥æœ‰é€‰æ‹©åœ°å…³æ³¨è¾“å…¥åºåˆ—çš„æœ‰ç”¨éƒ¨åˆ†ï¼Œä»è€Œå­¦ä¹ å®ƒä»¬ä¹‹é—´çš„*å¯¹é½*ã€‚è¿™æœ‰åŠ©äºæ¨¡å‹æœ‰æ•ˆåœ°å¤„ç†é•¿è¾“å…¥å¥å­[ [9](#df28) ]ã€‚

> ***å®šä¹‰:å¯¹é½*** *å¯¹é½æ˜¯æŒ‡å°†åŸæ–‡çš„ç‰‡æ®µä¸å…¶å¯¹åº”çš„è¯‘æ–‡ç‰‡æ®µè¿›è¡ŒåŒ¹é…ã€‚å®šä¹‰æ”¹ç¼–è‡ª* [*æ­¤å¤„*](https://www.andovar.com/alignment-of-translation) *ã€‚*

![](img/43ea8e5e82833674e139f80b3abff593.png)

Fig. 0.3: Alignment for the French word â€˜laâ€™ is distributed across the input sequence but mainly on these 4 words: â€˜theâ€™, â€˜Europeanâ€™, â€˜Economicâ€™ and â€˜Areaâ€™. Darker purple indicates better attention scores ([Image source](https://distill.pub/2016/augmented-rnns/#attentional-interfaces))

æ­£å¦‚[ [2](#7eef) ä¸­æ‰€ä»‹ç»çš„ï¼Œæ³¨æ„åŠ›æœ‰ä¸¤ç§ç±»å‹ã€‚ä½¿ç”¨æ‰€æœ‰ç¼–ç å™¨éšè—çŠ¶æ€çš„æ³¨æ„åŠ›ç±»å‹ä¹Ÿè¢«ç§°ä¸º*å…¨å±€æ³¨æ„åŠ›*ã€‚ç›¸åï¼Œ*å±€éƒ¨æ³¨æ„*ä»…ä½¿ç”¨ç¼–ç å™¨éšè—çŠ¶æ€çš„å­é›†ã€‚ç”±äºæœ¬æ–‡çš„**èŒƒå›´æ˜¯å…¨çƒå…³æ³¨**ï¼Œæœ¬æ–‡ä¸­æåˆ°çš„ä»»ä½•â€œå…³æ³¨â€éƒ½æ˜¯æŒ‡â€œå…¨çƒå…³æ³¨â€

è¿™ç¯‡æ–‡ç« æ€»ç»“äº†æ³¨æ„åŠ›æ˜¯å¦‚ä½•ä½¿ç”¨åŠ¨ç”»å·¥ä½œçš„ï¼Œè¿™æ ·æˆ‘ä»¬å°±å¯ä»¥åœ¨æ²¡æœ‰æ•°å­¦ç¬¦å·çš„æƒ…å†µä¸‹(æˆ–è€…åœ¨é˜…è¯»äº†å……æ»¡æ•°å­¦ç¬¦å·çš„è®ºæ–‡æˆ–æ•™ç¨‹ä¹‹å)ç†è§£å®ƒä»¬ğŸ˜¬ã€‚ä½œä¸ºä¾‹å­ï¼Œæˆ‘å°†åˆ†äº«è¿‡å» 5 å¹´è®¾è®¡çš„ 4 ä¸ª NMT å»ºç­‘ã€‚æˆ‘è¿˜ä¼šåœ¨è¿™ç¯‡æ–‡ç« ä¸­ç©¿æ’ä¸€äº›å…³äºä¸€äº›æ¦‚å¿µçš„ç›´è§‰ï¼Œæ‰€ä»¥è¯·ä¿æŒè­¦æƒ•ï¼

**ç›®å½•**1ã€‚[æ³¨æ„:æ¦‚è¿°](#1d00)2ã€‚[æ³¨æ„:ä¾‹é¢˜](#c09a)
3ã€‚[æ¦‚è¦](#14eb)
é™„å½•:[åˆ†æ•°å‡½æ•°](#ba24)

## 1.æ³¨æ„:æ¦‚è¿°

åœ¨æˆ‘ä»¬çœ‹æ³¨æ„åŠ›æ˜¯å¦‚ä½•ä½¿ç”¨çš„ä¹‹å‰ï¼Œè¯·å…è®¸æˆ‘ç”¨ seq2seq æ¨¡å‹ä¸ä½ åˆ†äº«ç¿»è¯‘ä»»åŠ¡èƒŒåçš„ç›´è§‰ã€‚

> ***ç›´è§‰:seq2seq*** *è¯‘è€…ä»å¤´åˆ°å°¾é˜…è¯»å¾·æ–‡æ–‡æœ¬ã€‚ä¸€æ—¦å®Œæˆï¼Œä»–å¼€å§‹é€å­—ç¿»è¯‘æˆè‹±è¯­ã€‚å¦‚æœå¥å­éå¸¸é•¿ï¼Œä»–å¯èƒ½ä¼šå¿˜è®°åœ¨æ–‡ç« çš„å‰å‡ éƒ¨åˆ†è¯»è¿‡çš„å†…å®¹ã€‚*

è¿™æ˜¯ä¸€ä¸ªç®€å•çš„ seq2seq æ¨¡å‹ã€‚æˆ‘å°†è¦ç»å†çš„æ³¨æ„åŠ›å±‚çš„åˆ†æ­¥è®¡ç®—æ˜¯ä¸€ä¸ª seq 2 seq+æ³¨æ„åŠ›æ¨¡å‹ã€‚è¿™é‡Œæœ‰ä¸€ä¸ªå…³äºè¿™ä¸ªæ¨¡å‹çš„å¿«é€Ÿç›´è§‰ã€‚

> ***ç›´è§‰:seq2seq +æ³¨æ„*** *ä¸€ä¸ªç¿»è¯‘è¯»å¾·æ–‡æ–‡æœ¬*ï¼ŒåŒæ—¶ä»å¤´åˆ°å°¾å†™ä¸‹å…³é”®è¯*ï¼Œä¹‹åå¼€å§‹ç¿»è¯‘æˆè‹±æ–‡ã€‚åœ¨ç¿»è¯‘æ¯ä¸ªå¾·è¯­å•è¯æ—¶ï¼Œä»–ä¼šä½¿ç”¨è‡ªå·±å†™ä¸‹çš„å…³é”®è¯ã€‚*

æ³¨æ„åŠ›é€šè¿‡ç»™æ¯ä¸ªå•è¯åˆ†é…ä¸€ä¸ªåˆ†æ•°æ¥å°†ä¸åŒçš„ç„¦ç‚¹æ”¾åœ¨ä¸åŒçš„å•è¯ä¸Šã€‚ç„¶åï¼Œä½¿ç”¨ softmaxed åˆ†æ•°ï¼Œæˆ‘ä»¬ä½¿ç”¨ç¼–ç å™¨éšè—çŠ¶æ€çš„åŠ æƒå’Œæ¥èšé›†ç¼–ç å™¨éšè—çŠ¶æ€ï¼Œä»¥è·å¾—ä¸Šä¸‹æ–‡å‘é‡ã€‚å…³æ³¨å±‚çš„å®ç°å¯ä»¥åˆ†ä¸º 4 ä¸ªæ­¥éª¤ã€‚

**æ­¥éª¤ 0:å‡†å¤‡éšè—çŠ¶æ€ã€‚**

è®©æˆ‘ä»¬é¦–å…ˆå‡†å¤‡å¥½æ‰€æœ‰å¯ç”¨çš„ç¼–ç å™¨éšè—çŠ¶æ€(ç»¿è‰²)å’Œç¬¬ä¸€ä¸ªè§£ç å™¨éšè—çŠ¶æ€(çº¢è‰²)ã€‚åœ¨æˆ‘ä»¬çš„ä¾‹å­ä¸­ï¼Œæˆ‘ä»¬æœ‰ 4 ä¸ªç¼–ç å™¨éšè—çŠ¶æ€å’Œå½“å‰è§£ç å™¨éšè—çŠ¶æ€ã€‚(æ³¨æ„:æœ€ååˆå¹¶çš„ç¼–ç å™¨éšè—çŠ¶æ€ä½œä¸º*è¾“å…¥*è¾“å…¥åˆ°è§£ç å™¨çš„ç¬¬ä¸€ä¸ªæ—¶é—´æ­¥é•¿ã€‚è§£ç å™¨ç¬¬ä¸€ä¸ªæ—¶é—´æ­¥é•¿çš„è¾“å‡ºç§°ä¸ºç¬¬ä¸€ä¸ªè§£ç å™¨éšè—çŠ¶æ€ï¼Œå¦‚ä¸‹æ‰€ç¤ºã€‚)

![](img/c46fcc284420b3200b8f2d9707267b65.png)

Fig. 1.0: Getting ready to pay attention

**æ­¥éª¤ 1:è·å¾—æ¯ä¸ªç¼–ç å™¨éšè—çŠ¶æ€çš„åˆ†æ•°*ã€‚***

åˆ†æ•°(æ ‡é‡)ç”±åˆ†æ•°å‡½æ•°(ä¹Ÿç§°ä¸º*æ¯”å¯¹åˆ†æ•°å‡½æ•°* [ [2](#7eef) ]æˆ–*æ¯”å¯¹æ¨¡å‹* [ [1](#30c6) )è·å¾—ã€‚åœ¨è¿™ä¸ªä¾‹å­ä¸­ï¼Œåˆ†æ•°å‡½æ•°æ˜¯è§£ç å™¨å’Œç¼–ç å™¨éšè—çŠ¶æ€ä¹‹é—´çš„ç‚¹ç§¯ã€‚

å„ç§å¾—åˆ†å‡½æ•°è§[é™„å½• A](#ba24) ã€‚

![](img/ebdd5883ac5c154df9f8f713e697e9eb.png)

Fig. 1.1: Get the scores

```
**decoder_hidden** = [10, 5, 10]**encoder_hidden  score**
---------------------
     [0, 1, 1]     15 (= 10Ã—0 + 5Ã—1 + 10Ã—1, the dot product)
     [5, 0, 1]     60
     [1, 1, 0]     15
     [0, 5, 1]     35
```

åœ¨ä¸Šé¢çš„ä¾‹å­ä¸­ï¼Œæˆ‘ä»¬è·å¾—äº†ç¼–ç å™¨éšè—çŠ¶æ€`[5, 0, 1]`çš„é«˜å…³æ³¨åˆ†æ•°`60`ã€‚è¿™æ„å‘³ç€ä¸‹ä¸€ä¸ªå­—(è§£ç å™¨çš„ä¸‹ä¸€ä¸ªè¾“å‡º)å°†ä¼šå—åˆ°ç¼–ç å™¨éšè—çŠ¶æ€çš„ä¸¥é‡å½±å“ã€‚

ç¬¬äºŒæ­¥:é€šè¿‡ä¸€ä¸ª softmax å±‚è¿è¡Œæ‰€æœ‰çš„åˆ†æ•°ã€‚

æˆ‘ä»¬å°†åˆ†æ•°æ”¾åˆ°ä¸€ä¸ª softmax å±‚ï¼Œè¿™æ · soft max çš„åˆ†æ•°(æ ‡é‡)åŠ èµ·æ¥å°±æ˜¯ 1ã€‚è¿™äº› softmaxed åˆ†æ•°ä»£è¡¨*æ³¨æ„åŠ›åˆ†å¸ƒ* [ [3](#286f) ï¼Œ [10](#a255) ã€‚

![](img/0484b853147472d274a780d60b16ce66.png)

Fig. 1.2: Get the softmaxed scores

```
**encoder_hidden  score  score^**
-----------------------------
     [0, 1, 1]     15       0
     [5, 0, 1]     60       1
     [1, 1, 0]     15       0
     [0, 5, 1]     35       0
```

è¯·æ³¨æ„ï¼Œæ ¹æ® softmaxed åˆ†æ•°`score^`ï¼Œæ³¨æ„åŠ›çš„åˆ†å¸ƒä»…å¦‚é¢„æœŸçš„é‚£æ ·æ”¾åœ¨`[5, 0, 1]`ä¸Šã€‚å®é™…ä¸Šï¼Œè¿™äº›æ•°å­—ä¸æ˜¯äºŒè¿›åˆ¶çš„ï¼Œè€Œæ˜¯ä»‹äº 0 å’Œ 1 ä¹‹é—´çš„æµ®ç‚¹æ•°ã€‚

**ç¬¬ä¸‰æ­¥** : **å°†æ¯ä¸ªç¼–ç å™¨éšè—çŠ¶æ€ä¹˜ä»¥å…¶ softmaxed åˆ†æ•°ã€‚**

é€šè¿‡å°†æ¯ä¸ªç¼–ç å™¨éšè—çŠ¶æ€ä¸å…¶ softmaxed åˆ†æ•°(æ ‡é‡)ç›¸ä¹˜ï¼Œæˆ‘ä»¬è·å¾—äº†*å¯¹é½å‘é‡* [ [2](#7eef) ]æˆ–*æ³¨é‡Šå‘é‡* [ [1](#30c6) ]ã€‚è¿™æ­£æ˜¯å¯¹é½å‘ç”Ÿçš„æœºåˆ¶ã€‚

![](img/f592e5fe29563999d5d422d59e5c448e.png)

Fig. 1.3: Get the alignment vectors

```
**encoder  score  score^  alignment**
---------------------------------
[0, 1, 1]   15      0   [0, 0, 0]
[5, 0, 1]   60      1   [5, 0, 1]
[1, 1, 0]   15      0   [0, 0, 0]
[0, 5, 1]   35      0   [0, 0, 0]
```

åœ¨è¿™é‡Œï¼Œæˆ‘ä»¬çœ‹åˆ°é™¤äº†`[5, 0, 1]`ä¹‹å¤–çš„æ‰€æœ‰ç¼–ç å™¨éšè—çŠ¶æ€çš„å¯¹é½ç”±äºä½æ³¨æ„åŠ›åˆ†æ•°è€Œå‡å°‘åˆ° 0ã€‚è¿™æ„å‘³ç€æˆ‘ä»¬å¯ä»¥é¢„æœŸç¬¬ä¸€ä¸ªç¿»è¯‘çš„å•è¯åº”è¯¥ä¸åµŒå…¥äº†`[5, 0, 1]`çš„è¾“å…¥å•è¯ç›¸åŒ¹é…ã€‚

**ç¬¬å››æ­¥** : **å¯¹å¯¹é½å‘é‡æ±‚å’Œã€‚**

å°†å¯¹é½å‘é‡ç›¸åŠ ä»¥äº§ç”Ÿ*ä¸Šä¸‹æ–‡å‘é‡* [ [1](#30c6) ï¼Œ [2](#7eef) ]ã€‚ä¸Šä¸‹æ–‡å‘é‡æ˜¯æ¥è‡ªå‰ä¸€æ­¥éª¤çš„å¯¹é½å‘é‡çš„èšåˆä¿¡æ¯ã€‚

![](img/6b8b0c35821440ff607ef592b63df1af.png)

Fig. 1.4: Get the context vector

```
**encoder  score  score^  alignment**
---------------------------------
[0, 1, 1]   15     0  [0, 0, 0]
[5, 0, 1]   60     1  [5, 0, 1]
[1, 1, 0]   15     0  [0, 0, 0]
[0, 5, 1]   35     0  [0, 0, 0]**context** = [0+5+0+0, 0+0+0+0, 0+1+0+0] = [5, 0, 1]
```

**ç¬¬äº”æ­¥** : **å°†ä¸Šä¸‹æ–‡å‘é‡é¦ˆå…¥è§£ç å™¨ã€‚**

å®Œæˆçš„æ–¹å¼å–å†³äºæ¶æ„è®¾è®¡ã€‚ç¨åï¼Œæˆ‘ä»¬å°†åœ¨ 2aã€2b å’Œ 2c éƒ¨åˆ†çš„ç¤ºä¾‹ä¸­çœ‹åˆ°è¯¥æ¶æ„å¦‚ä½•ä¸ºè§£ç å™¨åˆ©ç”¨ä¸Šä¸‹æ–‡å‘é‡ã€‚

![](img/aba002a82530d8ff003ff673835f2d96.png)

Fig. 1.5: Feed the context vector to the decoder

å·®ä¸å¤šå°±æ˜¯è¿™æ ·ï¼è¿™æ˜¯å®Œæ•´çš„åŠ¨ç”»:

![](img/88509c68d897d2c8f0ff7ba83da88cb5.png)

Fig. 1.6: Attention

> ***è®­ç»ƒå’Œæ¨ç†*** *åœ¨æ¨ç†è¿‡ç¨‹ä¸­ï¼Œæ¯ä¸ªè§£ç å™¨æ—¶é—´æ­¥é•¿ t çš„è¾“å…¥æ˜¯è§£ç å™¨æ—¶é—´æ­¥é•¿* t-1 *çš„* ***é¢„æµ‹è¾“å‡º*** *ã€‚
> è®­ç»ƒæ—¶ï¼Œè¾“å…¥åˆ°æ¯ä¸ªè§£ç å™¨æ—¶é—´æ­¥é•¿ t æ˜¯æˆ‘ä»¬ä»è§£ç å™¨æ—¶é—´æ­¥é•¿* t-1 *å¾—åˆ°çš„* ***åœ°çœŸå€¼è¾“å‡º*** *ã€‚*
> 
> ***ç›´è§‰:æ³¨æ„åŠ›*å®é™…ä¸Š*æ˜¯å¦‚ä½•å·¥ä½œçš„ï¼Ÿ***
> 
> *ç­”æ¡ˆ:åå‘ä¼ æ’­ï¼ŒæƒŠå–œæƒŠå–œã€‚åå‘ä¼ æ’­å°†å°½ä¸€åˆ‡åŠªåŠ›ç¡®ä¿è¾“å‡ºæ¥è¿‘åœ°é¢çœŸå®æƒ…å†µã€‚è¿™æ˜¯é€šè¿‡æ”¹å˜ RNNs ä¸­çš„æƒé‡å’Œå¾—åˆ†å‡½æ•°(å¦‚æœæœ‰çš„è¯)æ¥å®ç°çš„ã€‚è¿™äº›æƒé‡ä¼šå½±å“ç¼–ç å™¨éšè—çŠ¶æ€å’Œè§£ç å™¨éšè—çŠ¶æ€ï¼Œè¿›è€Œå½±å“æ³¨æ„åŠ›å¾—åˆ†ã€‚*

[ [è¿”å›é¡µé¦–](#d442) ]

## 2.æ³¨æ„:ç¤ºä¾‹

åœ¨å‰é¢çš„ç« èŠ‚ä¸­ï¼Œæˆ‘ä»¬å·²ç»çœ‹åˆ°äº† seq2seq å’Œ seq 2 seq+æ³¨æ„åŠ›æ¶æ„ã€‚åœ¨æ¥ä¸‹æ¥çš„å‡ ä¸ªå°èŠ‚ä¸­ï¼Œè®©æˆ‘ä»¬ç ”ç©¶å¦å¤– 3 ä¸ªåŸºäº seq2seq çš„ NMT æ¶æ„ï¼Œå®ƒä»¬å®ç°äº†æ³¨æ„åŠ›ã€‚ä¸ºäº†å®Œæ•´èµ·è§ï¼Œæˆ‘è¿˜é™„ä¸Šäº†ä»–ä»¬çš„åŒè¯­è¯„ä¼°æ›¿è§’(BLEU)åˆ†æ•°â€”â€”è¿™æ˜¯è¯„ä¼°ç”Ÿæˆå¥å­ä¸å‚è€ƒå¥å­çš„æ ‡å‡†æŒ‡æ ‡ã€‚

## 2aã€‚å·´èµ«è¾¾ç‘™ç­‰äººã€‚é“(2015) [ [1](#30c6)

è¿™ç§æ³¨æ„åŠ›çš„å®ç°æ˜¯åˆ›å§‹æ³¨æ„åŠ›ä¹‹çˆ¶ä¹‹ä¸€ã€‚ä½œè€…åœ¨è®ºæ–‡æ ‡é¢˜â€œé€šè¿‡å­¦ä¹ è”åˆå¯¹é½å’Œç¿»è¯‘çš„ç¥ç»æœºå™¨ç¿»è¯‘â€ä¸­ä½¿ç”¨äº†â€œå¯¹é½â€ä¸€è¯ï¼ŒæŒ‡çš„æ˜¯åœ¨è®­ç»ƒæ¨¡å‹æ—¶è°ƒæ•´ç›´æ¥è´Ÿè´£å¾—åˆ†çš„æƒé‡ã€‚ä»¥ä¸‹æ˜¯å…³äºè¯¥æ¶æ„éœ€è¦æ³¨æ„çš„äº‹é¡¹:

1.  ç¼–ç å™¨æ˜¯åŒå‘(æ­£å‘+åå‘)é—¨æ§å¾ªç¯å•å…ƒ(BiGRU)ã€‚è§£ç å™¨æ˜¯ä¸€ä¸ª GRUï¼Œå…¶åˆå§‹éšè—çŠ¶æ€æ˜¯ä»åå‘ç¼–ç å™¨ GRU(ä¸‹å›¾ä¸­æœªæ˜¾ç¤º)çš„æœ€åä¸€ä¸ªéšè—çŠ¶æ€ä¿®æ”¹è€Œæ¥çš„å‘é‡ã€‚
2.  æ³¨æ„åŠ›å±‚ä¸­çš„å¾—åˆ†å‡½æ•°æ˜¯**åŠ æ³•/ä¸²è”**ã€‚
3.  ä¸‹ä¸€ä¸ªè§£ç å™¨æ­¥éª¤çš„è¾“å…¥æ˜¯æ¥è‡ªå‰ä¸€ä¸ªè§£ç å™¨æ—¶é—´æ­¥éª¤çš„ç”Ÿæˆå­—(ç²‰çº¢è‰²)å’Œæ¥è‡ªå½“å‰æ—¶é—´æ­¥éª¤çš„ä¸Šä¸‹æ–‡å‘é‡(æ·±ç»¿è‰²)ä¹‹é—´çš„è¿æ¥ã€‚

![](img/085b52c3e34ced6fd8bda53cb6d87db5.png)

Fig. 2a: NMT from Bahdanau et. al. Encoder is a BiGRU, decoder is a GRU.

ä½œè€…åœ¨ WMT å¤§å­¦çš„ 14 ä¸ªè‹±è¯­-æ³•è¯­æ•°æ®é›†ä¸Šå–å¾—äº† 26.75 çš„ BLEU åˆ†æ•°**ã€‚**

> ***ç›´è§‰:seq2seq å¸¦åŒå‘ç¼–ç å™¨+æ³¨æ„åŠ›***
> 
> *è¯‘è€… A ä¸€è¾¹è¯»å¾·æ–‡æ–‡æœ¬ï¼Œä¸€è¾¹å†™ä¸‹å…³é”®è¯ã€‚ç¿»è¯‘è€… B(æ‰¿æ‹…é«˜çº§è§’è‰²ï¼Œå› ä¸ºä»–å…·æœ‰ä»å€’è¯»å¥å­ç¿»è¯‘å¥å­çš„é¢å¤–èƒ½åŠ›)ä»æœ€åä¸€ä¸ªå•è¯åˆ°ç¬¬ä¸€ä¸ªå•è¯é˜…è¯»ç›¸åŒçš„å¾·è¯­æ–‡æœ¬ï¼ŒåŒæ—¶è®°ä¸‹å…³é”®è¯ã€‚è¿™ä¸¤ä¸ªäººå®šæœŸè®¨è®ºä»–ä»¬åˆ°ç›®å‰ä¸ºæ­¢è¯»åˆ°çš„æ¯ä¸€ä¸ªå•è¯ã€‚é˜…è¯»å®Œè¿™ç¯‡å¾·è¯­æ–‡ç« åï¼Œè¯‘è€… B çš„ä»»åŠ¡æ˜¯æ ¹æ®è®¨è®ºå†…å®¹å’Œä»–ä»¬ä¸¤äººæ”¶é›†çš„ç»¼åˆå…³é”®è¯ï¼Œå°†å¾·è¯­å¥å­é€å­—ç¿»è¯‘æˆè‹±è¯­ã€‚*
> 
> *è¯‘è€… A æ˜¯å‰è¿›çš„ RNNï¼Œè¯‘è€… B æ˜¯è½åçš„ RNNã€‚*

## 2bã€‚Luong ç­‰äººã€‚é“(2015) [ [2](#7eef)

*åŸºäºæ³¨æ„åŠ›çš„ç¥ç»æœºå™¨ç¿»è¯‘çš„æœ‰æ•ˆæ–¹æ³•*çš„ä½œè€…å·²ç»æŠŠç®€åŒ–å’Œæ¦‚æ‹¬ Bahdanau *ç­‰äººçš„æ¶æ„ä½œä¸ºä¸€ä¸ªé‡ç‚¹ã€‚è‰¾å°”*ã€‚æ–¹æ³•å¦‚ä¸‹:

1.  ç¼–ç å™¨æ˜¯ä¸¤å±‚é•¿çŸ­æœŸè®°å¿†(LSTM)ç½‘ç»œã€‚è§£ç å™¨ä¹Ÿå…·æœ‰ç›¸åŒçš„æ¶æ„ï¼Œå…¶åˆå§‹éšè—çŠ¶æ€æ˜¯æœ€åçš„ç¼–ç å™¨éšè—çŠ¶æ€ã€‚
2.  ä»–ä»¬è¯•éªŒçš„è¯„åˆ†å‡½æ•°æ˜¯(i) **åŠ æ³•/ä¸²è”**ã€(ii) **ç‚¹ç§¯**ã€(iii) **åŸºäºä½ç½®çš„**ã€(iv)**â€˜é€šç”¨â€™**ã€‚
3.  æ¥è‡ªå½“å‰è§£ç å™¨æ—¶é—´æ­¥é•¿çš„è¾“å‡ºå’Œæ¥è‡ªå½“å‰æ—¶é—´æ­¥é•¿çš„ä¸Šä¸‹æ–‡å‘é‡ä¹‹é—´çš„è¿æ¥è¢«é¦ˆé€åˆ°å‰é¦ˆç¥ç»ç½‘ç»œï¼Œä»¥ç»™å‡ºå½“å‰è§£ç å™¨æ—¶é—´æ­¥é•¿çš„æœ€ç»ˆè¾“å‡º(ç²‰çº¢è‰²)ã€‚

![](img/87c8119a6d5234bd882ab848e43efbf5.png)

Fig. 2b: NMT from Luong et. al. Encoder is a 2 layer LSTM, likewise for the decoder.

åœ¨ WMT 2015 å¹´è‹±è¯­å¯¹å¾·è¯­çš„æµ‹è¯•ä¸­ï¼Œè¯¥æ¨¡å‹è·å¾—äº† 25.9 åˆ†çš„ BLEU åˆ†æ•°ã€‚

> ***ç›´è§‰:seq2seq å¸¦ 2 å±‚å †æ ˆç¼–ç å™¨+æ³¨æ„***
> 
> *è¯‘è€… A ä¸€è¾¹è¯»å¾·è¯­æ–‡æœ¬ï¼Œä¸€è¾¹å†™ä¸‹å…³é”®è¯ã€‚åŒæ ·ï¼Œè¯‘è€… B(æ¯”è¯‘è€… A çº§åˆ«é«˜)ä¹Ÿé˜…è¯»ç›¸åŒçš„å¾·è¯­æ–‡æœ¬ï¼ŒåŒæ—¶è®°ä¸‹å…³é”®è¯ã€‚è¯·æ³¨æ„ï¼Œåˆçº§è¯‘è€… A å¿…é¡»å‘è¯‘è€… B æŠ¥å‘Šä»–ä»¬é˜…è¯»çš„æ¯ä¸ªå•è¯ã€‚ä¸€æ—¦é˜…è¯»å®Œæ¯•ï¼Œä»–ä»¬ä¸¤äººä¼šæ ¹æ®ä»–ä»¬æ‰€æŒæ¡çš„å…³é”®è¯ï¼Œä¸€èµ·å°†å¥å­é€å­—ç¿»è¯‘æˆè‹±è¯­ã€‚*

[ [è¿”å›é¡µé¦–](#d442) ]

## 2cã€‚è°·æ­Œçš„ç¥ç»æœºå™¨ç¿»è¯‘(GNMT) [ [9](#df28)

å› ä¸ºæˆ‘ä»¬å¤§å¤šæ•°äººè‚¯å®šéƒ½ä»¥è¿™æ ·æˆ–é‚£æ ·çš„æ–¹å¼ä½¿ç”¨è¿‡è°·æ­Œç¿»è¯‘ï¼Œæ‰€ä»¥æˆ‘è§‰å¾—æœ‰å¿…è¦è°ˆè°ˆ 2016 å¹´å®æ–½çš„è°·æ­Œ NMTã€‚GNMT æ˜¯æˆ‘ä»¬å·²ç»çœ‹åˆ°çš„å‰ä¸¤ä¸ªä¾‹å­çš„ç»„åˆ(å¾ˆå¤§ç¨‹åº¦ä¸Šå—ç¬¬ä¸€ä¸ª[ [1](#30c6) ]çš„å¯å‘)ã€‚

1.  ç¼–ç å™¨ç”± 8 ä¸ª LSTMs å †æ ˆç»„æˆï¼Œå…¶ä¸­ç¬¬ä¸€ä¸ª LSTMs æ˜¯åŒå‘çš„(å…¶è¾“å‡ºæ˜¯çº§è”çš„)ï¼Œå‰©ä½™è¿æ¥å­˜åœ¨äºè¿ç»­å±‚çš„è¾“å‡ºä¹‹é—´(ä»ç¬¬ä¸‰å±‚å¼€å§‹)ã€‚è§£ç å™¨æ˜¯ 8 ä¸ªå•å‘ LSTMs çš„*ç‹¬ç«‹*å †æ ˆã€‚
2.  ä½¿ç”¨çš„è¯„åˆ†å‡½æ•°æ˜¯**åŠ æ³•/ä¸²è”**ï¼Œå¦‚[ [1](#30c6) ]ä¸­æ‰€ç¤ºã€‚
3.  åŒæ ·ï¼Œåƒåœ¨[ [1](#30c6) ]ä¸­ä¸€æ ·ï¼Œä¸‹ä¸€ä¸ªè§£ç å™¨æ­¥éª¤çš„è¾“å…¥æ˜¯å‰ä¸€ä¸ªè§£ç å™¨æ—¶é—´æ­¥éª¤çš„è¾“å‡º(ç²‰çº¢è‰²)å’Œå½“å‰æ—¶é—´æ­¥éª¤çš„ä¸Šä¸‹æ–‡å‘é‡(æ·±ç»¿è‰²)ä¹‹é—´çš„è¿æ¥ã€‚

![](img/bfae26703d0740597816c8f519be6c0f.png)

Fig. 2c: Googleâ€™s NMT for Google Translate. Skip connections are denoted by curved arrows. *Note that the LSTM cells only show the hidden state and input; it does not show the cell state input.

è¯¥æ¨¡å‹åœ¨ WMT çš„ 14 è‹±æ³•è¯­ä¸Šè¾¾åˆ°äº† **38.95** BLEUï¼Œåœ¨ WMT çš„ 14 è‹±å¾·è¯­ä¸Šè¾¾åˆ°äº† **24.17** BLEUã€‚

> ***ç›´è§‰:GNMT â€” seq2seq å¸¦ 8 å±‚ç¼–ç å™¨(+åŒå‘+å‰©ä½™è¿æ¥)+æ³¨æ„***
> 
> 8 åè¯‘è€…ä»ä¸‹åˆ°ä¸Šæ’æˆä¸€åˆ—ï¼Œä»è¯‘è€… Aï¼ŒBï¼Œâ€¦ï¼Œh å¼€å§‹ã€‚æ¯ä¸ªè¯‘è€…é˜…è¯»ç›¸åŒçš„å¾·è¯­æ–‡æœ¬ã€‚åœ¨æ¯ä¸€ä¸ªå•è¯ä¸Šï¼Œç¿»è¯‘ A éƒ½ä¸ç¿»è¯‘ B åˆ†äº«ä»–/å¥¹çš„å‘ç°ï¼Œç¿»è¯‘ B å°†å¯¹å…¶è¿›è¡Œæ”¹è¿›å¹¶ä¸ç¿»è¯‘ C åˆ†äº«â€”â€”é‡å¤è¿™ä¸€è¿‡ç¨‹ï¼Œç›´åˆ°æˆ‘ä»¬æ‰¾åˆ°ç¿»è¯‘ Hã€‚æ­¤å¤–ï¼Œåœ¨é˜…è¯»å¾·è¯­æ–‡æœ¬æ—¶ï¼Œç¿»è¯‘ H æ ¹æ®ä»–æ‰€çŸ¥é“çš„å’Œä»–æ‰€æ”¶åˆ°çš„ä¿¡æ¯å†™ä¸‹ç›¸å…³çš„å…³é”®è¯ã€‚
> 
> ä¸€æ—¦æ¯ä¸ªäººéƒ½è¯»å®Œäº†è¿™ç¯‡è‹±è¯­æ–‡ç« ï¼Œè¯‘è€… A è¢«å‘ŠçŸ¥ç¿»è¯‘ç¬¬ä¸€ä¸ªå•è¯ã€‚é¦–å…ˆï¼Œä»–å°è¯•å›å¿†ï¼Œç„¶åä¸ç¿»è¯‘ B åˆ†äº«ä»–çš„ç­”æ¡ˆï¼Œç¿»è¯‘ B æ”¹è¿›ç­”æ¡ˆå¹¶ä¸ç¿»è¯‘ C åˆ†äº«-é‡å¤æ­¤æ“ä½œï¼Œç›´åˆ°æˆ‘ä»¬æ‰¾åˆ°ç¿»è¯‘ Hã€‚ç„¶åï¼Œç¿»è¯‘ H æ ¹æ®ä»–å†™çš„å…³é”®å­—å’Œä»–å¾—åˆ°çš„ç­”æ¡ˆï¼Œå†™å‡ºç¬¬ä¸€ä¸ªç¿»è¯‘å•è¯ã€‚é‡å¤è¿™ä¸ªç›´åˆ°æˆ‘ä»¬ç¿»è¯‘å‡ºæ¥ã€‚

## 3.æ‘˜è¦

ä¸‹é¢æ˜¯æ‚¨åœ¨æœ¬æ–‡ä¸­çœ‹åˆ°çš„æ‰€æœ‰æ¶æ„çš„å¿«é€Ÿæ€»ç»“:

*   seq2seq
*   seq2seq +æ³¨æ„
*   å¸¦åŒå‘ç¼–ç å™¨çš„ seq2seq æ³¨æ„
*   seq2seq å¸¦ 2 å±‚ç¼–ç å™¨+æ³¨æ„
*   GNMT â€” seq2seqï¼Œå¸¦ 8 å±‚ç¼–ç å™¨(+åŒå‘+å‰©ä½™è¿æ¥)+æ³¨æ„

æš‚æ—¶å°±è¿™æ ·å§ï¼åœ¨æˆ‘çš„ä¸‹ä¸€ç¯‡æ–‡ç« ä¸­ï¼Œæˆ‘å°†å’Œä½ ä¸€èµ·å›é¡¾è‡ªæˆ‘å…³æ³¨çš„æ¦‚å¿µï¼Œä»¥åŠå®ƒæ˜¯å¦‚ä½•åœ¨ Google çš„ Transformer å’Œè‡ªæˆ‘å…³æ³¨ç”Ÿæˆå¯¹æŠ—ç½‘ç»œ(SAGAN)ä¸­ä½¿ç”¨çš„ã€‚ç•™æ„è¿™ä¸ªç©ºé—´ï¼

## é™„å½•:åˆ†æ•°å‡½æ•°

ä¸‹é¢æ˜¯ç”± Lilian Weng ç¼–è¯‘çš„ä¸€äº›å¾—åˆ†å‡½æ•°ã€‚åˆ†æ•°å‡½æ•°åŠ æ³•/ä¸²è”å’Œç‚¹ç§¯åœ¨æœ¬æ–‡ä¸­å·²ç»æåˆ°ã€‚åˆ†æ•°å‡½æ•°èƒŒåçš„æ€æƒ³æ¶‰åŠç‚¹ç§¯è¿ç®—(ç‚¹ç§¯ã€ä½™å¼¦ç›¸ä¼¼æ€§ç­‰ã€‚)ï¼Œå°±æ˜¯è¡¡é‡ä¸¤ä¸ªå‘é‡çš„ç›¸ä¼¼åº¦ã€‚å¯¹äºå‰é¦ˆç¥ç»ç½‘ç»œå¾—åˆ†å‡½æ•°ï¼Œæƒ³æ³•æ˜¯è®©æ¨¡å‹å­¦ä¹ å¯¹é½æƒé‡å’Œç¿»è¯‘ã€‚

![](img/cc4df9546849ed3c3b0d26a7379c2ad2.png)

Fig. A0: Summary of score functions

![](img/c2aae01071ef4de8744f9160d3b272c1.png)

Fig. A1: Summary of score functions. **h** represents encoder hidden states while **s** represents decoder hidden states. ([Image source](https://lilianweng.github.io/lil-log/2018/06/24/attention-attention.html#summary))

ã€[è¿”å›é¡µé¦–](#d442)

## å‚è€ƒ

[1] [ç¥ç»æœºå™¨ç¿»è¯‘é€šè¿‡è”åˆå­¦ä¹ æ¥å¯¹é½å’Œç¿»è¯‘(Bahdanau *etã€‚è‰¾å°”*ï¼Œ2015)](https://arxiv.org/abs/1409.0473)

[2] [åŸºäºæ³¨æ„åŠ›çš„ç¥ç»æœºå™¨ç¿»è¯‘çš„æœ‰æ•ˆæ–¹æ³•(Luong *et .é˜¿å°”*ï¼Œ2015)](https://arxiv.org/abs/1508.04025)

ä½ æ‰€éœ€è¦çš„åªæ˜¯å…³æ³¨ã€‚é˜¿å°”ï¼Œ2017)

[4] [è‡ªæˆ‘å…³æ³¨çš„ç”˜(å¼ *ç­‰ã€‚al*2018)](https://arxiv.org/abs/1805.08318)

[5] [ç”¨ç¥ç»ç½‘ç»œè¿›è¡Œåºåˆ—å¯¹åºåˆ—å­¦ä¹ (Sutskever *ç­‰ã€‚é“*ï¼Œ2014)](https://arxiv.org/abs/1409.3215)

[6] [TensorFlow çš„ seq2seq æ•™ç¨‹å¸¦å…³æ³¨](https://github.com/tensorflow/nmt)(seq 2 seq+å…³æ³¨æ•™ç¨‹)

[7] [Lilian Weng å…³äºå…³æ³¨çš„åšå®¢](https://lilianweng.github.io/lil-log/2018/06/24/attention-attention.html#a-family-of-attention-mechanisms)(å…³æ³¨çš„ä¼Ÿå¤§å¼€å§‹)

[8] [Jay Alammar åœ¨ Seq2Seq ä¸Šçš„åšå®¢ï¼Œå…³æ³¨åº¦](https://jalammar.github.io/visualizing-neural-machine-translation-mechanics-of-seq2seq-models-with-attention/)(seq 2 seq+å…³æ³¨åº¦ä¸Šçš„ç²¾å½©æ’å›¾å’Œå·¥ä½œç¤ºä¾‹)

ã€9ã€‘[è°·æ­Œçš„ç¥ç»æœºå™¨ç¿»è¯‘ç³»ç»Ÿ:å¼¥åˆäººä¸æœºå™¨ç¿»è¯‘ä¹‹é—´çš„é¸¿æ²Ÿ(å´ *etã€‚è‰¾å°”*ï¼Œ2016)](https://arxiv.org/abs/1609.08144)

## æ·±åº¦å­¦ä¹ ç›¸å…³æ–‡ç« 

[å›¾æ–‡å¹¶èŒ‚:è‡ªæˆ‘å…³æ³¨](/illustrated-self-attention-2d627e33b20a)

[åŠ¨ç”»ç‰ˆ RNNã€LSTM å’Œ GRU](/animated-rnn-lstm-and-gru-ef124d06cf45)

[é€è¡Œ Word2Vec å®ç°](/an-implementation-guide-to-word2vec-using-numpy-and-google-sheets-13445eebd281)(å…³äºå•è¯åµŒå…¥)

[å…³äºéšæœºæ¢¯åº¦ä¸‹é™çº¿æ€§å›å½’çš„åˆ†æ­¥æŒ‡å—](/step-by-step-tutorial-on-linear-regression-with-stochastic-gradient-descent-1d35b088a843)

[10 ç§æ¢¯åº¦ä¸‹é™ä¼˜åŒ–ç®—æ³•+å¤‡å¿˜å•](/10-gradient-descent-optimisation-algorithms-86989510b5e9)

[ç»Ÿè®¡æ·±åº¦å­¦ä¹ æ¨¡å‹ä¸­çš„å‚æ•°æ•°é‡](/counting-no-of-parameters-in-deep-learning-models-by-hand-8f1716241889)

*å¦‚æœä½ å–œæ¬¢æˆ‘çš„å†…å®¹å¹¶ä¸”è¿˜æ²¡æœ‰è®¢é˜… Mediumï¼Œè¯·é€šè¿‡æˆ‘çš„æ¨èé“¾æ¥* [*è¿™é‡Œ*](https://medium.com/@remykarem/membership) *è®¢é˜…ï¼æ³¨æ„:ä½ çš„ä¼šå‘˜è´¹çš„ä¸€éƒ¨åˆ†å°†ä½œä¸ºä»‹ç»è´¹åˆ†é…ç»™æˆ‘ã€‚*

*ç‰¹åˆ«æ„Ÿè°¢* [*å¾·é‡Œå…‹*](https://medium.com/@derekchia) *ã€å¨å»‰ã€Tjhiã€‘*[*å®‡è½©*](https://medium.com/@wyextay)*[*ã€ä»»æ°*](https://medium.com/@renjietan) *ã€å…‹é‡Œæ–¯å’Œè½¯è½¯ä¸ºæœ¬æ–‡å‡ºè°‹åˆ’ç­–ã€æå‡ºå»ºè®®å’Œä¿®æ”¹æ„è§ã€‚**

**å…³æ³¨æˆ‘ä¸Š* [*æ¨ç‰¹*](https://www.twitter.com/remykarem) *@remykarem æˆ–è€…*[*LinkedIn*](http://www.linkedin.com/in/raimibkarim)*ã€‚ä½ ä¹Ÿå¯ä»¥é€šè¿‡ raimi.bkarim@gmail.com è”ç³»æˆ‘ã€‚æ¬¢è¿è®¿é—®æˆ‘çš„ç½‘ç«™*[*remykarem . github . io*](https://remykarem.github.io/)*ã€‚**