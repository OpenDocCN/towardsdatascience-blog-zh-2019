<html>
<head>
<title>9th Place Solution/Approach/Journey for Game of Deep Learning: Computer Vision Hackathon</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">深度学习游戏的第 9 名解决方案/方法/旅程:计算机视觉黑客马拉松</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/13th-place-solution-approach-journey-for-game-of-deep-learning-computer-vision-hackathon-1d39fd16099e?source=collection_archive---------21-----------------------#2019-06-14">https://towardsdatascience.com/13th-place-solution-approach-journey-for-game-of-deep-learning-computer-vision-hackathon-1d39fd16099e?source=collection_archive---------21-----------------------#2019-06-14</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="7f83" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated"><a class="ae ki" href="https://datahack.analyticsvidhya.com/contest/game-of-deep-learning/" rel="noopener ugc nofollow" target="_blank">由 Analytics Vidhya 主办</a></h2></div><figure class="kk kl km kn gt ko gh gi paragraph-image"><div role="button" tabindex="0" class="kp kq di kr bf ks"><div class="gh gi kj"><img src="../Images/a765cc801f8a735e476260b81fafe78a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*iWIRL4lIn5QApLUK"/></div></div><figcaption class="kv kw gj gh gi kx ky bd b be z dk">Photo by <a class="ae ki" href="https://unsplash.com/@vidarnm?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Vidar Nordli-Mathisen</a> on <a class="ae ki" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><h2 id="c4c9" class="kz la it bd lb lc ld dn le lf lg dp lh li lj lk ll lm ln lo lp lq lr ls lt lu bi translated">问题陈述</h2><p id="f720" class="pw-post-body-paragraph lv lw it lx b ly lz ju ma mb mc jx md li me mf mg lm mh mi mj lq mk ml mm mn im bi translated">船舶或船只探测在海事安全、渔业管理、海洋污染、国防和海事安全、防止海盗、非法移民等领域具有广泛的应用。</p><p id="acc6" class="pw-post-body-paragraph lv lw it lx b ly mo ju ma mb mp jx md li mq mf mg lm mr mi mj lq ms ml mm mn im bi translated">牢记这一点，政府海事和海岸警卫队机构正计划部署基于计算机视觉的自动化系统，以仅从测量船拍摄的图像中识别船舶类型。你被聘为顾问，为这个项目建立一个高效的模型。</p><p id="0dbf" class="pw-post-body-paragraph lv lw it lx b ly mo ju ma mb mp jx md li mq mf mg lm mr mi mj lq ms ml mm mn im bi translated">需要检测的船只分为以下 5 类:</p><figure class="kk kl km kn gt ko gh gi paragraph-image"><div role="button" tabindex="0" class="kp kq di kr bf ks"><div class="gh gi mt"><img src="../Images/83ce48732ad49609aac18caf91949122.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*IsXTA5E6Ts1cvfaPWZapQQ.png"/></div></div></figure><h2 id="a974" class="kz la it bd lb lc ld dn le lf lg dp lh li lj lk ll lm ln lo lp lq lr ls lt lu bi translated">数据集描述</h2><p id="2901" class="pw-post-body-paragraph lv lw it lx b ly lz ju ma mb mc jx md li me mf mg lm mh mi mj lq mk ml mm mn im bi translated">在训练中有 6252 幅图像，在测试数据中有 2680 幅图像。数据集中的船舶类别及其对应的代码如下-</p><figure class="kk kl km kn gt ko gh gi paragraph-image"><div class="gh gi mu"><img src="../Images/95867720e5da17565ab90f7ab39e7512.png" data-original-src="https://miro.medium.com/v2/resize:fit:452/format:webp/1*omiwlCquQzRNE_zPw9NFJw.png"/></div><figcaption class="kv kw gj gh gi kx ky bd b be z dk">Categories of ships and their corresponding codes</figcaption></figure><ul class=""><li id="08bc" class="mv mw it lx b ly mo mb mp li mx lm my lq mz mn na nb nc nd bi translated">提供了三个文件，即 train.zip、test.csv 和 sample_submission.csv，其结构如下。</li></ul><figure class="kk kl km kn gt ko gh gi paragraph-image"><div role="button" tabindex="0" class="kp kq di kr bf ks"><div class="gh gi ne"><img src="../Images/0f2efecd4f1cc891c32818b8886e7331.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*EPnGQiZNPKoOaNZk7wm-vA.png"/></div></div><figcaption class="kv kw gj gh gi kx ky bd b be z dk">Variable Definition</figcaption></figure><ul class=""><li id="a9a8" class="mv mw it lx b ly mo mb mp li mx lm my lq mz mn na nb nc nd bi translated">train.zip 包含对应于训练集和测试集的图像，以及 train.csv 中训练集图像的真实标签</li></ul><h2 id="f2a9" class="kz la it bd lb lc ld dn le lf lg dp lh li lj lk ll lm ln lo lp lq lr ls lt lu bi translated">评估指标</h2><p id="5cfd" class="pw-post-body-paragraph lv lw it lx b ly lz ju ma mb mc jx md li me mf mg lm mh mi mj lq mk ml mm mn im bi translated">本次比赛的评估标准是加权 F1 分数。</p><h2 id="913f" class="kz la it bd lb lc ld dn le lf lg dp lh li lj lk ll lm ln lo lp lq lr ls lt lu bi translated">公私分离</h2><p id="691a" class="pw-post-body-paragraph lv lw it lx b ly lz ju ma mb mc jx md li me mf mg lm mh mi mj lq mk ml mm mn im bi translated">公共排行榜基于随机选择的 30%的测试图像，而私人排行榜将基于剩余的 70%的测试图像进行评估。</p><h2 id="836d" class="kz la it bd lb lc ld dn le lf lg dp lh li lj lk ll lm ln lo lp lq lr ls lt lu bi translated">方法</h2><p id="2438" class="pw-post-body-paragraph lv lw it lx b ly lz ju ma mb mc jx md li me mf mg lm mh mi mj lq mk ml mm mn im bi translated">我为这次黑客马拉松的准备工作在它被宣布为计算机视觉黑客马拉松的 3 周前就开始了。我想复习一下深度学习，特别是计算机视觉，所以我在网上搜索了最好的 DL 教程，无意中发现了一个金矿，<a class="ae ki" href="https://course.fast.ai/" rel="noopener ugc nofollow" target="_blank"> <em class="nf"> fastai </em> </a>！</p><p id="d8ad" class="pw-post-body-paragraph lv lw it lx b ly mo ju ma mb mp jx md li mq mf mg lm mr mi mj lq ms ml mm mn im bi translated">我花了整整 3 周的时间才完成了这 7 节长达 2 小时的课，在我上班的 2 小时通勤时间里，我试图零零碎碎地看着它们，中间的 2 个周末几乎没有练习。</p><h2 id="8b34" class="kz la it bd lb lc ld dn le lf lg dp lh li lj lk ll lm ln lo lp lq lr ls lt lu bi translated">黑客开始-1/3</h2><p id="8c77" class="pw-post-body-paragraph lv lw it lx b ly lz ju ma mb mc jx md li me mf mg lm mh mi mj lq mk ml mm mn im bi translated">黑客攻击的第一周是为了更深入地理解<code class="fe ng nh ni nj b">fastai</code> API 中的细微差别。</p><p id="fcb3" class="pw-post-body-paragraph lv lw it lx b ly mo ju ma mb mp jx md li mq mf mg lm mr mi mj lq ms ml mm mn im bi translated">我从内置的<code class="fe ng nh ni nj b">resnet50</code>架构开始，用预先训练好的<code class="fe ng nh ni nj b">ImageNet</code>权重来训练一个模型，很快就要实验各种内置的<code class="fe ng nh ni nj b">resnet </code>和<code class="fe ng nh ni nj b">densenet</code>模型。在查看了<code class="fe ng nh ni nj b">fastai</code>中可用的各种模型架构的性能后，我决定使用内置的<code class="fe ng nh ni nj b">resnet152</code>和<code class="fe ng nh ni nj b">densenet161</code>架构来构建初始模型。</p><p id="c9d5" class="pw-post-body-paragraph lv lw it lx b ly mo ju ma mb mp jx md li mq mf mg lm mr mi mj lq ms ml mm mn im bi translated">仔细查看 get_transform 函数后，将默认值改为<code class="fe ng nh ni nj b">get_transforms(max_lighting=0.4, max_zoom=1.2, max_warp=0.2, max_rotate=20, xtra_tfms=[flip_lr()]))</code>。我提交的作品从<code class="fe ng nh ni nj b">0.92977</code>到<code class="fe ng nh ni nj b">0.96650</code>不等。第一周结束时，我轻松进入了前 15 名。</p><h2 id="4cc0" class="kz la it bd lb lc ld dn le lf lg dp lh li lj lk ll lm ln lo lp lq lr ls lt lu bi translated">黑客攻击加剧——2/3</h2><p id="0a72" class="pw-post-body-paragraph lv lw it lx b ly lz ju ma mb mc jx md li me mf mg lm mh mi mj lq mk ml mm mn im bi translated">在黑客生涯的第二周，我学到了很多，也收获了很多。我正在浏览 2018 年<code class="fe ng nh ni nj b">fastai </code>课程的<a class="ae ki" href="https://medium.com/@hiromi_suenaga/deep-learning-2-part-1-lesson-2-eeae2edd2be4" rel="noopener">讲义</a>，了解了<code class="fe ng nh ni nj b">TTA, lr_find()</code>和<code class="fe ng nh ni nj b">learn.recorder.plot(suggestion=True)</code>功能以及渐进式图像大小调整技术，令人惊讶的是，这些在 2019 年版本的课程中没有涉及。使用这些新技巧，我可以获得一个最好的<code class="fe ng nh ni nj b">0.974822</code>分数的<code class="fe ng nh ni nj b">densenet161</code>模型。</p><p id="4376" class="pw-post-body-paragraph lv lw it lx b ly mo ju ma mb mp jx md li mq mf mg lm mr mi mj lq ms ml mm mn im bi translated">我意识到我们可以使用这个伟大系列中预先训练好的模特，<code class="fe ng nh ni nj b">fastai</code>中的<a class="ae ki" href="https://github.com/Cadene/pretrained-models.pytorch" rel="noopener ugc nofollow" target="_blank">https://github.com/Cadene/pretrained-models.pytorch</a>，并使用这个<a class="ae ki" href="https://github.com/TheShadow29/FAI-notes/blob/master/notebooks/Using-Pretrained-Pytorch-Models.ipynb" rel="noopener ugc nofollow" target="_blank">教程</a>来了解<code class="fe ng nh ni nj b">fastai </code>模特的头部和身体结构。但是当我想使用模型架构，比如使用 Kaggle 内核的<code class="fe ng nh ni nj b">senet154, se_resnet152, polynet</code>时，我就用完了 GPU 内存。了解了<code class="fe ng nh ni nj b">learn.to_fp16()</code>技巧，但它在 Kaggle 内核的 Tesla K80 上没有用，因为它没有张量内核来利用混合精度训练。</p><p id="aac5" class="pw-post-body-paragraph lv lw it lx b ly mo ju ma mb mp jx md li mq mf mg lm mr mi mj lq ms ml mm mn im bi translated">我决定创建一个 GCP 账户，使用更快的具有张量核的 GPU Tesla V100，并遵循这个<a class="ae ki" href="https://course.fast.ai/start_gcp.html" rel="noopener ugc nofollow" target="_blank">教程</a>。处理 GPU 配额增加请求大约需要 3 个小时。我在混合精度训练的帮助下运行了<code class="fe ng nh ni nj b">senet154, se_resnet152 </code>模型。</p><p id="1087" class="pw-post-body-paragraph lv lw it lx b ly mo ju ma mb mp jx md li mq mf mg lm mr mi mj lq ms ml mm mn im bi translated">到现在为止，我有大约 17 个模特，我决定让她们合奏。由于 output category 列中有离散的类，所以我对所有的提交使用了一个简单的模式，<code class="fe ng nh ni nj b">mode(df, axis=1)[0]</code>给出了一个得分<code class="fe ng nh ni nj b">0.980409</code>，帮助我突破了 0.98 分。</p><p id="d7b0" class="pw-post-body-paragraph lv lw it lx b ly mo ju ma mb mp jx md li mq mf mg lm mr mi mj lq ms ml mm mn im bi translated">到第二周结束时，我已经建立了一个 GCP 环境，可以更快地探索更大的模型，在公共 LB 上排名第八，但几乎已经没有主意了。</p><h2 id="2e94" class="kz la it bd lb lc ld dn le lf lg dp lh li lj lk ll lm ln lo lp lq lr ls lt lu bi translated">黑客高潮——3/3</h2><p id="c17c" class="pw-post-body-paragraph lv lw it lx b ly lz ju ma mb mc jx md li me mf mg lm mh mi mj lq mk ml mm mn im bi translated">在比赛的第三周也是最后一周的一个清新的周一早上，在我浏览黑客新闻和数据科学网站的日常工作中，我看到 ImageNet 数据集上有一个<a class="ae ki" href="https://news.ycombinator.com/item?id=20050786" rel="noopener ugc nofollow" target="_blank">新的 SOTA 模型，即<strong class="lx iu"> EfficientNet。</strong>我很快搜索了 Pytorch 的实现，发现了这个惊人的</a><a class="ae ki" href="https://github.com/lukemelas/EfficientNet-PyTorch" rel="noopener ugc nofollow" target="_blank"> GitHub repo </a>，里面有 B0-B3 的预训练模型。我还发现了这篇<a class="ae ki" rel="noopener" target="_blank" href="/1st-place-solution-for-intel-scene-classification-challenge-c95cf941f8ed">文章</a>关于英特尔场景分类挑战赛第一名获胜者的方法。</p><p id="b46e" class="pw-post-body-paragraph lv lw it lx b ly mo ju ma mb mp jx md li mq mf mg lm mr mi mj lq ms ml mm mn im bi translated">我可以很快意识到我错过了混合增强技术和消除混乱图像的技术，这对于参与者达到最高点非常有帮助。所以在我的代码中加入了这些变化，当我在<code class="fe ng nh ni nj b">fastai</code>文档页面上阅读<code class="fe ng nh ni nj b">mixup()</code>的时候，我了解到了<code class="fe ng nh ni nj b">ResizeMethod.SQUISH</code>的方法，它不是像<code class="fe ng nh ni nj b">224*224,</code>那样将图像居中裁剪成特定的大小，而是将整个图像压缩成所需的大小。然后修剪了训练集中大约 100 幅最容易混淆的图像，并通过添加<code class="fe ng nh ni nj b">valid_pct=0.1</code>来扩大训练集。</p><p id="660e" class="pw-post-body-paragraph lv lw it lx b ly mo ju ma mb mp jx md li mq mf mg lm mr mi mj lq ms ml mm mn im bi translated">下面是我最后的 get_data 函数，</p><figure class="kk kl km kn gt ko gh gi paragraph-image"><div role="button" tabindex="0" class="kp kq di kr bf ks"><div class="gh gi nk"><img src="../Images/bb2fd34f22e66cfaa280984807ecd71c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*3HiSDKSMHMrpSreazOTAlA.png"/></div></div><figcaption class="kv kw gj gh gi kx ky bd b be z dk">get_data.py</figcaption></figure><p id="4201" class="pw-post-body-paragraph lv lw it lx b ly mo ju ma mb mp jx md li mq mf mg lm mr mi mj lq ms ml mm mn im bi translated">下面是<code class="fe ng nh ni nj b">fastai,</code>中的高效网络 B3 模型</p><figure class="kk kl km kn gt ko gh gi paragraph-image"><div role="button" tabindex="0" class="kp kq di kr bf ks"><div class="gh gi ne"><img src="../Images/7dc0fd0c36a0b6ddb693ac6fdffa6908.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*VOzvvGFQ-HHoCDfw_CxS3g.png"/></div></div><figcaption class="kv kw gj gh gi kx ky bd b be z dk">model.py</figcaption></figure><p id="6664" class="pw-post-body-paragraph lv lw it lx b ly mo ju ma mb mp jx md li mq mf mg lm mr mi mj lq ms ml mm mn im bi translated">我用这条代码管道运行了 B0、B1、B2 和 B3 模型，其中 B3 的一个最佳模型在公共 LB 上给出了<code class="fe ng nh ni nj b">0.981322</code>。取了这些模型给出的模式<code class="fe ng nh ni nj b">0.98224</code>。使用<code class="fe ng nh ni nj b">resnet152</code>和<code class="fe ng nh ni nj b">densenet161</code>运行此管道，并使用公共 LB 上给出<code class="fe ng nh ni nj b">0.979470</code>的最佳单 B3 模型来获取这些提交的模式。然后最终提交的让我在公众 LB 排名第五的是到目前为止的 3 个顶级提交的模式，给出的分数是<code class="fe ng nh ni nj b">0.988798</code>。</p><p id="2a4b" class="pw-post-body-paragraph lv lw it lx b ly mo ju ma mb mp jx md li mq mf mg lm mr mi mj lq ms ml mm mn im bi translated">最终的提交严重超过了公共 LB，把我排在了私人 LB 的第 9 位。我提交的<code class="fe ng nh ni nj b">resnet152, densenet161</code>和<code class="fe ng nh ni nj b">efficientnet-b3</code>模式在私人 LB 上表现最好，本可以让我获得第四名。这里是<a class="ae ki" href="https://datahack.analyticsvidhya.com/contest/game-of-deep-learning/pvt_lb" rel="noopener ugc nofollow" target="_blank">链接</a>到二等兵 LB。</p><figure class="kk kl km kn gt ko gh gi paragraph-image"><div role="button" tabindex="0" class="kp kq di kr bf ks"><div class="gh gi nl"><img src="../Images/fd3b4be486020498643946178d3d86c4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*7Ww6H-tLcpd0Ta3BGHcwlw.png"/></div></div><figcaption class="kv kw gj gh gi kx ky bd b be z dk">Best Public and Best Private submissions</figcaption></figure><p id="df7d" class="pw-post-body-paragraph lv lw it lx b ly mo ju ma mb mp jx md li mq mf mg lm mr mi mj lq ms ml mm mn im bi translated">然而，这次黑客马拉松对我来说是一次非同寻常的经历。感谢<a class="nm nn ep" href="https://medium.com/u/c7c686fcd4b?source=post_page-----1d39fd16099e--------------------------------" rel="noopener" target="_blank">团队 AV </a>举办了如此精彩的黑客马拉松。希望在<a class="ae ki" href="https://www.analyticsvidhya.com/datahack-summit-2019/" rel="noopener ugc nofollow" target="_blank"> DataHack 峰会 2019 </a>与大家见面。✌️</p><p id="47c2" class="pw-post-body-paragraph lv lw it lx b ly mo ju ma mb mp jx md li mq mf mg lm mr mi mj lq ms ml mm mn im bi translated"><strong class="lx iu">更新:</strong>使用 FastAI 训练 EfficientNet 的代码发布<strong class="lx iu"> </strong> <a class="ae ki" href="https://www.kaggle.com/kirankunapuli/game-of-dl-efficientnet-kaggle" rel="noopener ugc nofollow" target="_blank"> <strong class="lx iu">此处</strong> </a> <strong class="lx iu">。如果你觉得 Kaggle 内核有用，请投上一票。</strong></p></div><div class="ab cl no np hx nq" role="separator"><span class="nr bw bk ns nt nu"/><span class="nr bw bk ns nt nu"/><span class="nr bw bk ns nt"/></div><div class="im in io ip iq"><h2 id="28f7" class="kz la it bd lb lc ld dn le lf lg dp lh li lj lk ll lm ln lo lp lq lr ls lt lu bi translated">感谢阅读！如果你喜欢这篇文章，请随时通过<a class="ae ki" href="https://www.linkedin.com/in/kirankunapuli/" rel="noopener ugc nofollow" target="_blank"> LinkedIn </a>或<a class="ae ki" href="https://twitter.com/kirankunapuli" rel="noopener ugc nofollow" target="_blank"> Twitter </a>联系我。</h2></div></div>    
</body>
</html>