<html>
<head>
<title>Portable Computer Vision: TensorFlow 2.0 on a Raspberry Pi</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">便携式计算机视觉:树莓 Pi 上的 TensorFlow 2.0</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/portable-computer-vision-tensorflow-2-0-on-a-raspberry-pi-part-1-of-2-84e318798ce9?source=collection_archive---------0-----------------------#2019-06-24">https://towardsdatascience.com/portable-computer-vision-tensorflow-2-0-on-a-raspberry-pi-part-1-of-2-84e318798ce9?source=collection_archive---------0-----------------------#2019-06-24</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><figure class="ip iq gp gr ir is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi io"><img src="../Images/ae9693f1f1b48d074beeece6401a5b76.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*p69rZCP1ydnI55lXQ7LyNg.jpeg"/></div></div></figure><div class=""/><div class=""><h2 id="ef47" class="pw-subtitle-paragraph jy ja jb bd b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp dk translated">微小、低成本的物体检测和分类。</h2></div><h1 id="e4a5" class="kq kr jb bd ks kt ku kv kw kx ky kz la kh lb ki lc kk ld kl le kn lf ko lg lh bi translated">第 1 部分—简介</h1><p id="3472" class="pw-post-body-paragraph li lj jb lk b ll lm kc ln lo lp kf lq lr ls lt lu lv lw lx ly lz ma mb mc md ij bi translated">只需大约 100 美元，你就可以将深度学习添加到嵌入式系统或你的下一个物联网项目中。</p><p id="d8e0" class="pw-post-body-paragraph li lj jb lk b ll me kc ln lo mf kf lq lr mg lt lu lv mh lx ly lz mi mb mc md ij bi translated">你是刚入门机器/深度学习，TensorFlow，还是 Raspberry Pi？完美，这个博客系列是给你的！</p><p id="82e8" class="pw-post-body-paragraph li lj jb lk b ll me kc ln lo mf kf lq lr mg lt lu lv mh lx ly lz mi mb mc md ij bi translated">在这个系列中，我将向您展示如何:</p><ol class=""><li id="a0a2" class="mj mk jb lk b ll me lo mf lr ml lv mm lz mn md mo mp mq mr bi translated">使用<strong class="lk jc"> TensorFlow 2.0 </strong>和<strong class="lk jc"> Keras 部署预训练的图像分类模型(<strong class="lk jc"> MobileNetV2 </strong>)。</strong></li><li id="2f3f" class="mj mk jb lk b ll ms lo mt lr mu lv mv lz mw md mo mp mq mr bi translated">将模型转换为<strong class="lk jc"> TensorFlow Lite，</strong>一种针对嵌入式和移动设备优化的模型格式。</li><li id="5565" class="mj mk jb lk b ll ms lo mt lr mu lv mv lz mw md mo mp mq mr bi translated">使用 Coral 的<strong class="lk jc"> USB Edge TPU 加速器</strong>和<strong class="lk jc"> Edge TPU 编译器，加速任何<strong class="lk jc"> TensorFlow Lite </strong>模型的推理。</strong></li><li id="6fda" class="mj mk jb lk b ll ms lo mt lr mu lv mv lz mw md mo mp mq mr bi translated">使用<strong class="lk jc">转移学习</strong>用<strong class="lk jc">自定义图像分类器重新训练 MobileNetV2。</strong></li></ol><p id="5211" class="pw-post-body-paragraph li lj jb lk b ll me kc ln lo mf kf lq lr mg lt lu lv mh lx ly lz mi mb mc md ij bi translated">本系列<strong class="lk jc">第一篇</strong>(你现在正在看！)将带您完成构建材料、安装以及将 MobileNetV2 部署到您 Raspberry Pi。</p></div><div class="ab cl mx my hu mz" role="separator"><span class="na bw bk nb nc nd"/><span class="na bw bk nb nc nd"/><span class="na bw bk nb nc"/></div><div class="ij ik il im in"><h1 id="a97e" class="kq kr jb bd ks kt ne kv kw kx nf kz la kh ng ki lc kk nh kl le kn ni ko lg lh bi translated">术语和参考📚</h1><p id="0550" class="pw-post-body-paragraph li lj jb lk b ll lm kc ln lo lp kf lq lr ls lt lu lv lw lx ly lz ma mb mc md ij bi translated"><a class="ae nj" href="https://www.raspberrypi.org/" rel="noopener ugc nofollow" target="_blank"> <strong class="lk jc">树莓派</strong></a>——一款受教育者、硬件爱好者和机器人专家欢迎的小型廉价电脑。🤖</p><p id="f2a5" class="pw-post-body-paragraph li lj jb lk b ll me kc ln lo mf kf lq lr mg lt lu lv mh lx ly lz mi mb mc md ij bi translated"><a class="ae nj" href="https://www.tensorflow.org/" rel="noopener ugc nofollow" target="_blank"> <strong class="lk jc"> TensorFlow </strong> </a> —机器学习的开源平台。</p><p id="f7e9" class="pw-post-body-paragraph li lj jb lk b ll me kc ln lo mf kf lq lr mg lt lu lv mh lx ly lz mi mb mc md ij bi translated"><a class="ae nj" href="https://www.tensorflow.org/lite" rel="noopener ugc nofollow" target="_blank"><strong class="lk jc">tensor flow Lite</strong></a>—用于在移动和嵌入式设备上部署<strong class="lk jc"> TensorFlow </strong>模型的轻量级库。</p><p id="9f84" class="pw-post-body-paragraph li lj jb lk b ll me kc ln lo mf kf lq lr mg lt lu lv mh lx ly lz mi mb mc md ij bi translated"><strong class="lk jc">卷积神经网络</strong>——一种深度学习模型，非常适合图像分类和对象检测应用。</p><p id="eacb" class="pw-post-body-paragraph li lj jb lk b ll me kc ln lo mf kf lq lr mg lt lu lv mh lx ly lz mi mb mc md ij bi translated"><a class="ae nj" href="https://ai.googleblog.com/2018/04/mobilenetv2-next-generation-of-on.html" rel="noopener ugc nofollow" target="_blank"><strong class="lk jc">MobileNetV2</strong></a><strong class="lk jc">—</strong>一种先进的图像识别模型，针对普通手机处理器的性能进行了优化。</p><figure class="nl nm nn no gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi nk"><img src="../Images/32001cfa8d79abb17ee79459b58ccc5e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*f57O6E5hQ61JmSJIemGZzg.png"/></div></div><figcaption class="np nq gj gh gi nr ns bd b be z dk">Comparison of general-purpose computer vision neural networks. Image Credit: <a class="ae nj" href="https://ai.googleblog.com/2018/04/mobilenetv2-next-generation-of-on.html" rel="noopener ugc nofollow" target="_blank">MobileNetV2: The Next Generation of On-Device Computer Vision Networks</a></figcaption></figure><p id="ac48" class="pw-post-body-paragraph li lj jb lk b ll me kc ln lo mf kf lq lr mg lt lu lv mh lx ly lz mi mb mc md ij bi translated"><a class="ae nj" href="https://cloud.google.com/edge-tpu/" rel="noopener ugc nofollow" target="_blank"> <strong class="lk jc">边缘 TPU </strong> </a> —张量处理单元(TPU)是一个集成电路，用于加速<strong class="lk jc"> TensorFlow 执行的计算。</strong><strong class="lk jc">边缘 TPU </strong>是为“在边缘”的移动和嵌入式设备开发的，占地面积小</p><div class="nl nm nn no gt ab cb"><figure class="nt is nu nv nw nx ny paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><img src="../Images/2b47c18580f665108f041cd229f63d09.png" data-original-src="https://miro.medium.com/v2/resize:fit:704/format:webp/1*in1ZwQElextZ9mR4HRMoUA.jpeg"/></div></figure><figure class="nt is nz nv nw nx ny paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><img src="../Images/d5397b2102de4819b38915c3a0f2933e.png" data-original-src="https://miro.medium.com/v2/resize:fit:570/format:webp/1*vyGk6VQn1tppT4u-AiG4wQ.jpeg"/></div></figure><figure class="nt is oa nv nw nx ny paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><img src="../Images/62a6a774990ddaa2fa92f9b07199e571.png" data-original-src="https://miro.medium.com/v2/resize:fit:728/format:webp/1*T0wROrsc7ik5DA3yTYioLA.png"/></div><figcaption class="np nq gj gh gi nr ns bd b be z dk ob di oc od">TPUv1, TPUv2 (left, middle) at Cloud Next ‘18. Edge TPUs on a United States penny (right). Image credit: <a class="ae nj" href="https://cloud.google.com/edge-tpu/)" rel="noopener ugc nofollow" target="_blank">Google</a></figcaption></figure></div></div><div class="ab cl mx my hu mz" role="separator"><span class="na bw bk nb nc nd"/><span class="na bw bk nb nc nd"/><span class="na bw bk nb nc"/></div><div class="ij ik il im in"><h1 id="447c" class="kq kr jb bd ks kt ne kv kw kx nf kz la kh ng ki lc kk nh kl le kn ni ko lg lh bi translated">第 2 部分—✅构建列表</h1><h2 id="bdd3" class="oe kr jb bd ks of og dn kw oh oi dp la lr oj ok lc lv ol om le lz on oo lg op bi translated">启动工具包</h2><p id="48ef" class="pw-post-body-paragraph li lj jb lk b ll lm kc ln lo lp kf lq lr ls lt lu lv lw lx ly lz ma mb mc md ij bi translated">如果你刚刚入门树莓 Pi，我推荐 Arrow 的<a class="ae nj" href="https://www.arrow.com/en/products/3275/adafruit-industries" rel="noopener ugc nofollow" target="_blank"> Pi 相机套装</a>(90 美元)。它包括您需要的一切，立即开始:</p><ul class=""><li id="666d" class="mj mk jb lk b ll me lo mf lr ml lv mm lz mn md oq mp mq mr bi translated">5V 2.4A MicroUSB 电源</li><li id="6afe" class="mj mk jb lk b ll ms lo mt lr mu lv mv lz mw md oq mp mq mr bi translated">320x240 2.8 英寸 TFT 型号 PiTFT 电阻式触摸屏</li><li id="5133" class="mj mk jb lk b ll ms lo mt lr mu lv mv lz mw md oq mp mq mr bi translated">树莓 Pi 3 型号 B</li><li id="5ecd" class="mj mk jb lk b ll ms lo mt lr mu lv mv lz mw md oq mp mq mr bi translated">Raspberry Pi 摄像机 v2</li><li id="da41" class="mj mk jb lk b ll ms lo mt lr mu lv mv lz mw md oq mp mq mr bi translated">塑料盒</li><li id="0dbf" class="mj mk jb lk b ll ms lo mt lr mu lv mv lz mw md oq mp mq mr bi translated">预装了 NOOBS 安装管理器的 8GB MicroSD 卡</li></ul><h2 id="028e" class="oe kr jb bd ks of og dn kw oh oi dp la lr oj ok lc lv ol om le lz on oo lg op bi translated">Coral USB Edge TPU 加速器(可选)</h2><p id="98aa" class="pw-post-body-paragraph li lj jb lk b ll lm kc ln lo lp kf lq lr ls lt lu lv lw lx ly lz ma mb mc md ij bi translated">您可以编译<strong class="lk jc"> TensorFlow Lite </strong>模型，在 Coral 的 USB 加速器(<a class="ae nj" href="https://coral.withgoogle.com/products/accelerator/" rel="noopener ugc nofollow" target="_blank"> Link </a>)上运行，以便更快地进行模型预测。</p><p id="cd6b" class="pw-post-body-paragraph li lj jb lk b ll me kc ln lo mf kf lq lr mg lt lu lv mh lx ly lz mi mb mc md ij bi translated">实时应用程序从这种加速中受益匪浅。自动驾驶机器人的决策模块就是一个例子。</p><p id="d591" class="pw-post-body-paragraph li lj jb lk b ll me kc ln lo mf kf lq lr mg lt lu lv mh lx ly lz mi mb mc md ij bi translated">一些应用程序可以容忍更高的预测速度，可能不需要 TPU 加速。例如，你不需要 TPU 加速来建立一个智能狗门，为你的狗开门(但不让浣熊进来)。</p><p id="0a7f" class="pw-post-body-paragraph li lj jb lk b ll me kc ln lo mf kf lq lr mg lt lu lv mh lx ly lz mi mb mc md ij bi translated">如果你刚刚开始，跳过购买这个组件。</p><figure class="nl nm nn no gt is"><div class="bz fp l di"><div class="or os l"/></div></figure><p id="ceb4" class="pw-post-body-paragraph li lj jb lk b ll me kc ln lo mf kf lq lr mg lt lu lv mh lx ly lz mi mb mc md ij bi translated">你不确定你是否需要 USB 加速器？下面的 MobileNet 基准可以帮助您做出决定。下面的测量描述了推理速度(单位为毫秒)——速度越低越好！</p><figure class="nl nm nn no gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi ot"><img src="../Images/dffacc8575d108a2e3ab8d20a76ed892.png" data-original-src="https://miro.medium.com/v2/resize:fit:1164/format:webp/1*Aqy5-TnnCCn-uL2UwQ7ksw.png"/></div></div><figcaption class="np nq gj gh gi nr ns bd b be z dk">Image Credit: <a class="ae nj" href="https://blog.hackster.io/@aallan" rel="noopener ugc nofollow" target="_blank">Alasdair Allan</a>, <a class="ae nj" href="https://blog.hackster.io/benchmarking-tensorflow-and-tensorflow-lite-on-the-raspberry-pi-43f51b796796" rel="noopener ugc nofollow" target="_blank">Benchmarking TensorFlow and TensorFlow Lite on the Raspberry Pi</a></figcaption></figure><h2 id="7d35" class="oe kr jb bd ks of og dn kw oh oi dp la lr oj ok lc lv ol om le lz on oo lg op bi translated">定制构建</h2><p id="2413" class="pw-post-body-paragraph li lj jb lk b ll lm kc ln lo lp kf lq lr ls lt lu lv lw lx ly lz ma mb mc md ij bi translated">如果您已经有了一个 Raspberry Pi 或一些组件，初学者工具包可能会包含您不需要的项目。</p><p id="717d" class="pw-post-body-paragraph li lj jb lk b ll me kc ln lo mf kf lq lr mg lt lu lv mh lx ly lz mi mb mc md ij bi translated">以下是我自己制作的零件(大约 250 美元/台)。</p><ul class=""><li id="4bee" class="mj mk jb lk b ll me lo mf lr ml lv mm lz mn md oq mp mq mr bi translated">树莓 Pi 型号 3 b+(35 美元)</li><li id="2026" class="mj mk jb lk b ll ms lo mt lr mu lv mv lz mw md oq mp mq mr bi translated">树莓 Pi 相机 v2(30 美元)</li><li id="bb72" class="mj mk jb lk b ll ms lo mt lr mu lv mv lz mw md oq mp mq mr bi translated">Coral USB Edge TPU 加速器——加速模型推理(75 美元，<a class="ae nj" href="https://coral.withgoogle.com/products/accelerator" rel="noopener ugc nofollow" target="_blank">链接</a></li><li id="c27d" class="mj mk jb lk b ll ms lo mt lr mu lv mv lz mw md oq mp mq mr bi translated">Pi Foundation 显示屏— 7 英寸触摸屏显示屏(80 美元，<a class="ae nj" href="https://www.adafruit.com/product/2718" rel="noopener ugc nofollow" target="_blank">链接</a></li><li id="bd8d" class="mj mk jb lk b ll ms lo mt lr mu lv mv lz mw md oq mp mq mr bi translated">SmartiPi 触摸支架(25 美元，<a class="ae nj" href="http://www.adafruit.com/product/3187" rel="noopener ugc nofollow" target="_blank">链接</a></li><li id="3885" class="mj mk jb lk b ll ms lo mt lr mu lv mv lz mw md oq mp mq mr bi translated">可调 Pi 摄像机支架(5 美元，<a class="ae nj" href="https://www.adafruit.com/product/1434" rel="noopener ugc nofollow" target="_blank">连杆</a></li><li id="d7ee" class="mj mk jb lk b ll ms lo mt lr mu lv mv lz mw md oq mp mq mr bi translated">RPi 摄像机 24 英寸的柔性电缆(＄3，<a class="ae nj" href="https://www.adafruit.com/product/1731" rel="noopener ugc nofollow" target="_blank">链接</a>)</li></ul><p id="8644" class="pw-post-body-paragraph li lj jb lk b ll me kc ln lo mf kf lq lr mg lt lu lv mh lx ly lz mi mb mc md ij bi translated">我很想听听你自己的构建列表！❤️给我发推特<a class="ae nj" href="https://twitter.com/grepLeigh" rel="noopener ugc nofollow" target="_blank"> @grepLeigh </a>或者在下面评论。</p></div><div class="ab cl mx my hu mz" role="separator"><span class="na bw bk nb nc nd"/><span class="na bw bk nb nc nd"/><span class="na bw bk nb nc"/></div><div class="ij ik il im in"><h1 id="33ab" class="kq kr jb bd ks kt ne kv kw kx nf kz la kh ng ki lc kk nh kl le kn ni ko lg lh bi translated">第 3 部分— Raspberry Pi 设置🍰</h1><p id="3931" class="pw-post-body-paragraph li lj jb lk b ll lm kc ln lo lp kf lq lr ls lt lu lv lw lx ly lz ma mb mc md ij bi translated">如果你购买了一个预装 NOOBS 的 SD 卡，我建议你先浏览一下这个概述:<a class="ae nj" href="https://projects.raspberrypi.org/en/projects/raspberry-pi-setting-up/2" rel="noopener ugc nofollow" target="_blank">设置你的树莓派</a></p><p id="b6b0" class="pw-post-body-paragraph li lj jb lk b ll me kc ln lo mf kf lq lr mg lt lu lv mh lx ly lz mi mb mc md ij bi translated"><strong class="lk jc">在进行</strong>之前，您需要:</p><ul class=""><li id="a5a7" class="mj mk jb lk b ll me lo mf lr ml lv mm lz mn md oq mp mq mr bi translated">将您的 Pi 连接到互联网(<a class="ae nj" href="https://projects.raspberrypi.org/en/projects/raspberry-pi-using/4" rel="noopener ugc nofollow" target="_blank"> doc </a>)</li><li id="d0c7" class="mj mk jb lk b ll ms lo mt lr mu lv mv lz mw md oq mp mq mr bi translated">SSH 到你的树莓 Pi ( <a class="ae nj" href="https://www.raspberrypi.org/documentation/remote-access/ssh/" rel="noopener ugc nofollow" target="_blank"> doc </a>)</li></ul></div><div class="ab cl mx my hu mz" role="separator"><span class="na bw bk nb nc nd"/><span class="na bw bk nb nc nd"/><span class="na bw bk nb nc"/></div><div class="ij ik il im in"><h1 id="0dba" class="kq kr jb bd ks kt ne kv kw kx nf kz la kh ng ki lc kk nh kl le kn ni ko lg lh bi translated">第 4 部分—主要计算机:下载和安装依赖项</h1><p id="7e56" class="pw-post-body-paragraph li lj jb lk b ll lm kc ln lo lp kf lq lr ls lt lu lv lw lx ly lz ma mb mc md ij bi translated"><code class="fe ou ov ow ox b">rpi-vision</code>是一套工具，可让您更轻松地:</p><ul class=""><li id="5995" class="mj mk jb lk b ll me lo mf lr ml lv mm lz mn md oq mp mq mr bi translated">在你的 Raspberry Pi 上安装很多依赖项(TensorFlow Lite，TFT 触摸屏驱动程序，将 PiCamera 帧缓冲区复制到 TFT 触摸屏的工具)。</li><li id="bbf0" class="mj mk jb lk b ll ms lo mt lr mu lv mv lz mw md oq mp mq mr bi translated">将模型部署到 Raspberry Pi。</li><li id="7c02" class="mj mk jb lk b ll ms lo mt lr mu lv mv lz mw md oq mp mq mr bi translated">在你的电脑或谷歌云的人工智能平台上训练新模型。</li><li id="32d7" class="mj mk jb lk b ll ms lo mt lr mu lv mv lz mw md oq mp mq mr bi translated">为边缘 TPU 编译 8 位量化模型。</li></ul><ol class=""><li id="8a19" class="mj mk jb lk b ll me lo mf lr ml lv mm lz mn md mo mp mq mr bi translated">在您的<strong class="lk jc">主计算机</strong>上克隆<code class="fe ou ov ow ox b">rpi-vision</code> repo(不是您的 Raspberry Pi)</li></ol><pre class="nl nm nn no gt oy ox oz pa aw pb bi"><span id="b793" class="oe kr jb ox b gy pc pd l pe pf">$ git clone git@github.com:leigh-johnson/rpi-vision.git &amp;&amp; cd rpi-vision</span></pre><p id="addf" class="pw-post-body-paragraph li lj jb lk b ll me kc ln lo mf kf lq lr mg lt lu lv mh lx ly lz mi mb mc md ij bi translated">2.在您的<strong class="lk jc">主计算机</strong>上，创建一个新的虚拟环境，然后安装<code class="fe ou ov ow ox b">rpi-vision</code>包。</p><pre class="nl nm nn no gt oy ox oz pa aw pb bi"><span id="8865" class="oe kr jb ox b gy pc pd l pe pf">$ pip install virtualenv; virtualenv -p $(which python3) .venv &amp;&amp; source .venv/bin/activate &amp;&amp; pip install -e .</span></pre><p id="f40e" class="pw-post-body-paragraph li lj jb lk b ll me kc ln lo mf kf lq lr mg lt lu lv mh lx ly lz mi mb mc md ij bi translated">3.在继续之前，验证你可以对你的树莓 Pi 进行 SSH。</p><p id="0c6c" class="pw-post-body-paragraph li lj jb lk b ll me kc ln lo mf kf lq lr mg lt lu lv mh lx ly lz mi mb mc md ij bi translated">如果您使用默认的 Raspbian 映像，您的 Pi 的主机名将是<code class="fe ou ov ow ox b">raspberrypi.local</code></p><pre class="nl nm nn no gt oy ox oz pa aw pb bi"><span id="e996" class="oe kr jb ox b gy pc pd l pe pf">$ ssh pi@raspberry.local</span></pre></div><div class="ab cl mx my hu mz" role="separator"><span class="na bw bk nb nc nd"/><span class="na bw bk nb nc nd"/><span class="na bw bk nb nc"/></div><div class="ij ik il im in"><h1 id="6052" class="kq kr jb bd ks kt ne kv kw kx nf kz la kh ng ki lc kk nh kl le kn ni ko lg lh bi translated">第 5 部分—主要计算机:创建配置文件</h1><p id="61e9" class="pw-post-body-paragraph li lj jb lk b ll lm kc ln lo lp kf lq lr ls lt lu lv lw lx ly lz ma mb mc md ij bi translated"><code class="fe ou ov ow ox b">rpi-vision</code>使用<strong class="lk jc"> Ansible </strong>来管理你的 Raspberry Pi 上的部署和任务。Ansible 是一个自动化计算机配置的框架。</p><p id="4a2c" class="pw-post-body-paragraph li lj jb lk b ll me kc ln lo mf kf lq lr mg lt lu lv mh lx ly lz mi mb mc md ij bi translated">创建 Ansible 所需的 2 个配置文件:</p><h2 id="825c" class="oe kr jb bd ks of og dn kw oh oi dp la lr oj ok lc lv ol om le lz on oo lg op bi translated"><strong class="ak">。env/my-inventory.ini </strong></h2><p id="2792" class="pw-post-body-paragraph li lj jb lk b ll lm kc ln lo lp kf lq lr ls lt lu lv lw lx ly lz ma mb mc md ij bi translated">如果您对 Pi 使用自定义主机名，请替换<code class="fe ou ov ow ox b">raspberrypi.local.</code></p><pre class="nl nm nn no gt oy ox oz pa aw pb bi"><span id="ab7c" class="oe kr jb ox b gy pc pd l pe pf">tee -a <!-- -->.env/my-inventory.ini<!-- --> &lt;&lt;EOF<br/>[rpi_vision]<br/>raspberrypi.local</span><span id="cf7f" class="oe kr jb ox b gy pg pd l pe pf">[rpi_vision:vars]<br/>ansible_connection=ssh<br/>ansible_user=pi<br/>ansible_python=/usr/bin/python3<br/>EOF</span></pre><h2 id="6991" class="oe kr jb bd ks of og dn kw oh oi dp la lr oj ok lc lv ol om le lz on oo lg op bi translated">。env/my-vars.json</h2><p id="4551" class="pw-post-body-paragraph li lj jb lk b ll lm kc ln lo lp kf lq lr ls lt lu lv lw lx ly lz ma mb mc md ij bi translated">如果您对 Pi 使用自定义主机名，请替换<code class="fe ou ov ow ox b">raspberrypi.local.</code></p><pre class="nl nm nn no gt oy ox oz pa aw pb bi"><span id="a1aa" class="oe kr jb ox b gy pc pd l pe pf">tee -a <!-- -->.env/my-vars.ini<!-- --> &lt;&lt;EOF<br/>{ <br/>  <em class="ph">"RPI_HOSTNAME"</em>: "raspberrypi.local",<br/>  <em class="ph">"VERSION"</em>: "release-v1.0.0"<br/>}<br/>EOF</span></pre></div><div class="ab cl mx my hu mz" role="separator"><span class="na bw bk nb nc nd"/><span class="na bw bk nb nc nd"/><span class="na bw bk nb nc"/></div><div class="ij ik il im in"><h1 id="a17e" class="kq kr jb bd ks kt ne kv kw kx nf kz la kh ng ki lc kk nh kl le kn ni ko lg lh bi translated">第 6 部分— Raspberry Pi:安装依赖项</h1><pre class="nl nm nn no gt oy ox oz pa aw pb bi"><span id="fd1a" class="oe kr jb ox b gy pc pd l pe pf">$ make rpi-install</span></pre><p id="25b2" class="pw-post-body-paragraph li lj jb lk b ll me kc ln lo mf kf lq lr mg lt lu lv mh lx ly lz mi mb mc md ij bi translated">您将看到一个<strong class="lk jc">可行剧本</strong>的输出。<a class="ae nj" href="https://docs.ansible.com/" rel="noopener ugc nofollow" target="_blank"> <strong class="lk jc"> Ansible </strong> </a>是一个自动化配置计算机的框架。</p><p id="6413" class="pw-post-body-paragraph li lj jb lk b ll me kc ln lo mf kf lq lr mg lt lu lv mh lx ly lz mi mb mc md ij bi translated">您的 Pi 上安装了什么的快速摘要:</p><ul class=""><li id="ec34" class="mj mk jb lk b ll me lo mf lr ml lv mm lz mn md oq mp mq mr bi translated"><code class="fe ou ov ow ox b">rpi-vision</code>回购</li><li id="9df6" class="mj mk jb lk b ll ms lo mt lr mu lv mv lz mw md oq mp mq mr bi translated"><code class="fe ou ov ow ox b">rpi-fbcp</code>(从 PiCamera 复制 framebuffer 到 TFT 触摸屏显示器的工具)</li><li id="b1b6" class="mj mk jb lk b ll ms lo mt lr mu lv mv lz mw md oq mp mq mr bi translated">TFT 触摸屏驱动器和 X11 配置</li></ul><p id="42b6" class="pw-post-body-paragraph li lj jb lk b ll me kc ln lo mf kf lq lr mg lt lu lv mh lx ly lz mi mb mc md ij bi translated">您可以通过打开<code class="fe ou ov ow ox b">playbooks/bootstrap-rpi.yml</code>来检查在您的 Raspberry Pi 上运行的任务</p><p id="5d54" class="pw-post-body-paragraph li lj jb lk b ll me kc ln lo mf kf lq lr mg lt lu lv mh lx ly lz mi mb mc md ij bi translated">在安装运行时，通读下一部分，了解<strong class="lk jc"> <em class="ph">如何</em></strong>CNN<strong class="lk jc"/>工作以及<strong class="lk jc"> <em class="ph">为什么</em> </strong>它们对<strong class="lk jc">计算机视觉</strong>任务有用。</p></div><div class="ab cl mx my hu mz" role="separator"><span class="na bw bk nb nc nd"/><span class="na bw bk nb nc nd"/><span class="na bw bk nb nc"/></div><div class="ij ik il im in"><h1 id="e8cc" class="kq kr jb bd ks kt ne kv kw kx nf kz la kh ng ki lc kk nh kl le kn ni ko lg lh bi translated">第 7 部分 CNNs(卷积神经网络)简介</h1><p id="f834" class="pw-post-body-paragraph li lj jb lk b ll lm kc ln lo lp kf lq lr ls lt lu lv lw lx ly lz ma mb mc md ij bi translated">CNN 是驱动自动驾驶汽车和图像搜索引擎的关键技术。该技术对于计算机视觉来说是常见的，但也可以应用于数据中具有<strong class="lk jc">层次模式的任何问题，其中<strong class="lk jc">复杂模式</strong>可以由简单模式</strong>组装而成<strong class="lk jc">。</strong></p><h2 id="df35" class="oe kr jb bd ks of og dn kw oh oi dp la lr oj ok lc lv ol om le lz on oo lg op bi translated">视觉皮层建模</h2><p id="8b0d" class="pw-post-body-paragraph li lj jb lk b ll lm kc ln lo lp kf lq lr ls lt lu lv lw lx ly lz ma mb mc md ij bi translated">在 20 世纪 50 年代末和 60 年代，大卫·H·哈贝尔和托顿·威尔森在猫和猴子身上做了实验，以更好地了解视觉皮层。</p><figure class="nl nm nn no gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi pi"><img src="../Images/07c001cfd01fc53026c7f010537bca42.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*XTuIUDFclEBtSfgL25FHmg.png"/></div></div><figcaption class="np nq gj gh gi nr ns bd b be z dk">Diagram of the implant installed in the skulls of cats with a trephine. Image Credit: <a class="ae nj" href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC1357023/pdf/jphysiol01301-0020.pdf" rel="noopener ugc nofollow" target="_blank">SINGLE UNIT ACTIVITY IN STRIATE CORTEX OF UNRESTRAINED CATS</a></figcaption></figure><p id="126f" class="pw-post-body-paragraph li lj jb lk b ll me kc ln lo mf kf lq lr mg lt lu lv mh lx ly lz mi mb mc md ij bi translated">他们证明了纹状皮层中的神经元对有限视野中的刺激做出反应，他们称之为感受野。</p><p id="94f8" class="pw-post-body-paragraph li lj jb lk b ll me kc ln lo mf kf lq lr mg lt lu lv mh lx ly lz mi mb mc md ij bi translated">他们<strong class="lk jc"> </strong>注意到了同心重叠反应，其中复杂的模式是低水平模式的组合。</p><p id="8cf7" class="pw-post-body-paragraph li lj jb lk b ll me kc ln lo mf kf lq lr mg lt lu lv mh lx ly lz mi mb mc md ij bi translated">他们的发现还揭示了<strong class="lk jc">特殊化</strong>，其中一些神经元将<strong class="lk jc">只对<strong class="lk jc">特定形状</strong>或模式</strong>做出反应。</p><p id="0dfa" class="pw-post-body-paragraph li lj jb lk b ll me kc ln lo mf kf lq lr mg lt lu lv mh lx ly lz mi mb mc md ij bi translated">在 20 世纪 80 年代，受 Hubel 和 Wielson 的启发，Kunihiko Fukushima 在<strong class="lk jc">neocogniton</strong>、<strong class="lk jc">、</strong>上发表了一种能够学习具有几何相似性的模式的神经网络。</p><figure class="nl nm nn no gt is gh gi paragraph-image"><div class="gh gi pj"><img src="../Images/c458ce629007f0d2d3c48581a8184079.png" data-original-src="https://miro.medium.com/v2/resize:fit:846/format:webp/1*3Ou8n845wH09j7Qi8XVkqw.png"/></div><figcaption class="np nq gj gh gi nr ns bd b be z dk">Diagram of a Neocogitron, the foundation for modern CNNS. Image Credit: <a class="ae nj" href="https://www.cs.princeton.edu/courses/archive/spr08/cos598B/Readings/Fukushima1980.pdf" rel="noopener ugc nofollow" target="_blank">Neocognitron: A Self-organizing Neural Network Model for a Mechanism of Pattern Recognition Unaffected by Shift in Position</a></figcaption></figure><p id="6d8e" class="pw-post-body-paragraph li lj jb lk b ll me kc ln lo mf kf lq lr mg lt lu lv mh lx ly lz mi mb mc md ij bi translated">新回旋加速器有两个关键特性:</p><ul class=""><li id="f812" class="mj mk jb lk b ll me lo mf lr ml lv mm lz mn md oq mp mq mr bi translated"><strong class="lk jc"> <em class="ph">学习到的模式是有层次的。</em> </strong>越来越复杂的图案是由越来越简单的图案组成的。</li><li id="059b" class="mj mk jb lk b ll ms lo mt lr mu lv mv lz mw md oq mp mq mr bi translated"><strong class="lk jc"> <em class="ph">学习到的模式是位置不变和平移不变的</em>。</strong>网络学习到一个模式后，可以在不同的位置识别这个模式。在<strong class="lk jc">学习如何对狗</strong>进行分类之后，网络可以准确地对倒立的狗<strong class="lk jc">进行分类，而无需学习全新的模式。</strong></li></ul><p id="13c5" class="pw-post-body-paragraph li lj jb lk b ll me kc ln lo mf kf lq lr mg lt lu lv mh lx ly lz mi mb mc md ij bi translated">neocogitron 模型是现代卷积神经网络的灵感来源。</p></div><div class="ab cl mx my hu mz" role="separator"><span class="na bw bk nb nc nd"/><span class="na bw bk nb nc nd"/><span class="na bw bk nb nc"/></div><div class="ij ik il im in"><h2 id="2be7" class="oe kr jb bd ks of og dn kw oh oi dp la lr oj ok lc lv ol om le lz on oo lg op bi translated">可视化卷积运算:2D</h2><figure class="nl nm nn no gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi pk"><img src="../Images/39bd4a300e52ac38b3d02f2480532423.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*RovKo3n98vGb9au_EdlAiw.jpeg"/></div></div><figcaption class="np nq gj gh gi nr ns bd b be z dk">(Left) 2D 4x4 Input matrix. (Middle) 2D 2x2 kernel. (Right) 2D 2x2 output feature map.</figcaption></figure><p id="6c99" class="pw-post-body-paragraph li lj jb lk b ll me kc ln lo mf kf lq lr mg lt lu lv mh lx ly lz mi mb mc md ij bi translated"><strong class="lk jc">输入层</strong>被送入<strong class="lk jc">卷积层</strong>，卷积层使用<strong class="lk jc">滤波器转换输入的<strong class="lk jc">区域</strong>。</strong></p><p id="5ef7" class="pw-post-body-paragraph li lj jb lk b ll me kc ln lo mf kf lq lr mg lt lu lv mh lx ly lz mi mb mc md ij bi translated"><strong class="lk jc">过滤器</strong>也被称为<strong class="lk jc">内核。</strong></p><figure class="nl nm nn no gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi pl"><img src="../Images/780f22cc93a46f888ba3a49b8170dd31.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/1*IBqBbX2F698Nd91mBx2ACQ.gif"/></div></div><figcaption class="np nq gj gh gi nr ns bd b be z dk">The filter “slides” to each possible position, and the result is added to the feature map.</figcaption></figure><p id="82c0" class="pw-post-body-paragraph li lj jb lk b ll me kc ln lo mf kf lq lr mg lt lu lv mh lx ly lz mi mb mc md ij bi translated">对于输入矩阵中的每个位置，<strong class="lk jc">卷积运算</strong>对每个元素执行矩阵乘法。</p><p id="715f" class="pw-post-body-paragraph li lj jb lk b ll me kc ln lo mf kf lq lr mg lt lu lv mh lx ly lz mi mb mc md ij bi translated">产生的矩阵被求和并存储在<strong class="lk jc">特征图中。</strong></p><p id="5159" class="pw-post-body-paragraph li lj jb lk b ll me kc ln lo mf kf lq lr mg lt lu lv mh lx ly lz mi mb mc md ij bi translated">对输入矩阵中的每个位置重复该操作。</p><h2 id="b14d" class="oe kr jb bd ks of og dn kw oh oi dp la lr oj ok lc lv ol om le lz on oo lg op bi translated">可视化卷积运算:3D</h2><figure class="nl nm nn no gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi pm"><img src="../Images/298497d2f3123508f5d6ac03fce582a2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/1*sDaGvIgnrePW9BRQoTAtLw@2x.gif"/></div></div><figcaption class="np nq gj gh gi nr ns bd b be z dk">Image Credit: <a class="ae nj" rel="noopener" target="_blank" href="/applied-deep-learning-part-4-convolutional-neural-networks-584bc134c1e2">Applied Deep Learning — Part 4: Convolutional Neural Networks</a></figcaption></figure><p id="26c4" class="pw-post-body-paragraph li lj jb lk b ll me kc ln lo mf kf lq lr mg lt lu lv mh lx ly lz mi mb mc md ij bi translated">CNN 的<strong class="lk jc">输入层</strong>通常是一个 3D 数据结构，具有<strong class="lk jc"> <em class="ph">高度</em> </strong>、<strong class="lk jc"> <em class="ph">宽度</em> </strong>、<strong class="lk jc"> <em class="ph">通道</em> </strong> (RGB 或灰度值)。</p><p id="3c0b" class="pw-post-body-paragraph li lj jb lk b ll me kc ln lo mf kf lq lr mg lt lu lv mh lx ly lz mi mb mc md ij bi translated">我们在特征地图栈中越深入，每个地图层就变得越稀疏。这意味着过滤器检测到的特征更少。</p><p id="ab7f" class="pw-post-body-paragraph li lj jb lk b ll me kc ln lo mf kf lq lr mg lt lu lv mh lx ly lz mi mb mc md ij bi translated">特征地图堆栈<strong class="lk jc">的<strong class="lk jc">前几层</strong>检测简单的边缘和形状</strong>，看起来与输入图像相似。随着我们进入特征地图堆栈越来越深，对于人眼来说，特征变得越来越抽象。更深的特征层<strong class="lk jc">编码分类数据，</strong>像“猫脸”或“猫耳”。</p><figure class="nl nm nn no gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi pn"><img src="../Images/0a7f86b502e1f2eba61edfc0b89561f9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*c-QNnJz-l-6dgGHeukVEOg.png"/></div></div><figcaption class="np nq gj gh gi nr ns bd b be z dk">Comparison of feature maps from the first convolution layer (block1_conv1) with later layers (block5_conv1). Image Credit: <a class="ae nj" rel="noopener" target="_blank" href="/applied-deep-learning-part-4-convolutional-neural-networks-584bc134c1e2">Applied Deep Learning — Part 4: Convolutional Neural Networks</a></figcaption></figure></div><div class="ab cl mx my hu mz" role="separator"><span class="na bw bk nb nc nd"/><span class="na bw bk nb nc nd"/><span class="na bw bk nb nc"/></div><div class="ij ik il im in"><h2 id="54d1" class="oe kr jb bd ks of og dn kw oh oi dp la lr oj ok lc lv ol om le lz on oo lg op bi translated">你想了解更多关于 CNN 的信息吗？</h2><p id="cf57" class="pw-post-body-paragraph li lj jb lk b ll lm kc ln lo lp kf lq lr ls lt lu lv lw lx ly lz ma mb mc md ij bi translated">您的依赖项安装现在可能已经完成了。要向前迈进，请跳到<strong class="lk jc">第 8 部分——部署预培训模型 MobileNetV2。</strong></p><p id="6ac9" class="pw-post-body-paragraph li lj jb lk b ll me kc ln lo mf kf lq lr mg lt lu lv mh lx ly lz mi mb mc md ij bi translated">如果您计划训练一个自定义分类器，或者想了解更多关于卷积神经网络的信息，请从这里开始:</p><ul class=""><li id="405e" class="mj mk jb lk b ll me lo mf lr ml lv mm lz mn md oq mp mq mr bi translated"><a class="ae nj" rel="noopener" target="_blank" href="/applied-deep-learning-part-4-convolutional-neural-networks-584bc134c1e2">应用深度学习—第 4 部分:卷积神经网络</a></li><li id="3221" class="mj mk jb lk b ll ms lo mt lr mu lv mv lz mw md oq mp mq mr bi translated"><a class="ae nj" href="https://www.amazon.com/Hands-Machine-Learning-Scikit-Learn-TensorFlow/dp/1491962291" rel="noopener ugc nofollow" target="_blank">使用 Scikit-learn 和 TensorFlow 进行机器学习</a>，<em class="ph">第 13 章，卷积神经网络</em>，作者 Aurélien Géron</li><li id="4854" class="mj mk jb lk b ll ms lo mt lr mu lv mv lz mw md oq mp mq mr bi translated"><a class="ae nj" href="https://www.amazon.com/Deep-Learning-Python-Francois-Chollet/dp/1617294438/" rel="noopener ugc nofollow" target="_blank">用 Python 进行深度学习</a>，<em class="ph">第五章计算机视觉的深度学习，</em>Francois Chollet</li></ul></div><div class="ab cl mx my hu mz" role="separator"><span class="na bw bk nb nc nd"/><span class="na bw bk nb nc nd"/><span class="na bw bk nb nc"/></div><div class="ij ik il im in"><h1 id="da1d" class="kq kr jb bd ks kt ne kv kw kx nf kz la kh ng ki lc kk nh kl le kn ni ko lg lh bi translated">第 8 部分—部署预训练模型(MobileNetV2)</h1><h2 id="2ea1" class="oe kr jb bd ks of og dn kw oh oi dp la lr oj ok lc lv ol om le lz on oo lg op bi translated">现场演示(使用 TensorFlow 2.0)</h2><figure class="nl nm nn no gt is"><div class="bz fp l di"><div class="or os l"/></div><figcaption class="np nq gj gh gi nr ns bd b be z dk">I used this code to sanity-check the TensorFlow 2.0-beta0 wheel that I cross-compiled for my Raspberry Pi 3.</figcaption></figure><ol class=""><li id="167d" class="mj mk jb lk b ll me lo mf lr ml lv mm lz mn md mo mp mq mr bi translated">嘘到你的树莓皮</li></ol><pre class="nl nm nn no gt oy ox oz pa aw pb bi"><span id="79ad" class="oe kr jb ox b gy pc pd l pe pf">$ ssh raspberrypi.local</span></pre><p id="804e" class="pw-post-body-paragraph li lj jb lk b ll me kc ln lo mf kf lq lr mg lt lu lv mh lx ly lz mi mb mc md ij bi translated">2.启动新的 tmux 会话</p><pre class="nl nm nn no gt oy ox oz pa aw pb bi"><span id="10ed" class="oe kr jb ox b gy pc pd l pe pf">pi@raspberryi:~ $ tmux new-session -s mobilenetv2</span></pre><p id="3cad" class="pw-post-body-paragraph li lj jb lk b ll me kc ln lo mf kf lq lr mg lt lu lv mh lx ly lz mi mb mc md ij bi translated">3.通过按 control+b 垂直拆分 tmux 会话，然后"</p><p id="a239" class="pw-post-body-paragraph li lj jb lk b ll me kc ln lo mf kf lq lr mg lt lu lv mh lx ly lz mi mb mc md ij bi translated">4.启动一个<code class="fe ou ov ow ox b">fbcp</code>进程，通过 SPI 接口将帧缓冲区从 PiCamera 复制到 TFT 显示器。让这个过程继续运行。</p><pre class="nl nm nn no gt oy ox oz pa aw pb bi"><span id="f30c" class="oe kr jb ox b gy pc pd l pe pf">pi@raspberryi:~ $ fbcp</span></pre><p id="3037" class="pw-post-body-paragraph li lj jb lk b ll me kc ln lo mf kf lq lr mg lt lu lv mh lx ly lz mi mb mc md ij bi translated">5.通过按下 control+b，然后按下 o 来切换 tmux 面板。</p><p id="a0ae" class="pw-post-body-paragraph li lj jb lk b ll me kc ln lo mf kf lq lr mg lt lu lv mh lx ly lz mi mb mc md ij bi translated">6.激活前面第 6 部分中安装的虚拟环境。</p><pre class="nl nm nn no gt oy ox oz pa aw pb bi"><span id="8851" class="oe kr jb ox b gy pc pd l pe pf">pi@raspberryi:~ $ cd ~/rpi-vision &amp;&amp; . .venv/bin/activate</span></pre><p id="b81b" class="pw-post-body-paragraph li lj jb lk b ll me kc ln lo mf kf lq lr mg lt lu lv mh lx ly lz mi mb mc md ij bi translated">7.启动 mobilenetv2 代理进程。代理初始化大约需要 60 秒。</p><pre class="nl nm nn no gt oy ox oz pa aw pb bi"><span id="ed7d" class="oe kr jb ox b gy pc pd l pe pf">pi@raspberryi:~/rpi-vision $ python rpi_vision/agent/mobilenet_v2.py</span></pre><p id="5f61" class="pw-post-body-paragraph li lj jb lk b ll me kc ln lo mf kf lq lr mg lt lu lv mh lx ly lz mi mb mc md ij bi translated">您将看到模型基础的摘要，然后代理将打印推理，直到停止。<a class="ae nj" href="https://gist.github.com/leigh-johnson/14541749afbd8e4471b85699ddd0c9f5" rel="noopener ugc nofollow" target="_blank">点击查看您应该看到的要点</a>。</p><p id="7840" class="pw-post-body-paragraph li lj jb lk b ll me kc ln lo mf kf lq lr mg lt lu lv mh lx ly lz mi mb mc md ij bi translated">这个演示使用了<strong class="lk jc"> ImageNet </strong>分类器的权重，你可以在【image-net.org】的<a class="ae nj" href="http://image-net.org/explore" rel="noopener ugc nofollow" target="_blank">中查找。</a></p><h1 id="3109" class="kq kr jb bd ks kt ku kv kw kx ky kz la kh lb ki lc kk ld kl le kn lf ko lg lh bi translated">感谢您的阅读！</h1><p id="8448" class="pw-post-body-paragraph li lj jb lk b ll lm kc ln lo lp kf lq lr ls lt lu lv lw lx ly lz ma mb mc md ij bi translated">恭喜您，您刚刚为您的 Raspberry Pi 部署了一个图像分类模型！✨</p><p id="6955" class="pw-post-body-paragraph li lj jb lk b ll me kc ln lo mf kf lq lr mg lt lu lv mh lx ly lz mi mb mc md ij bi translated">寻找更多针对 Raspberry Pi 和其他小型设备的机器学习实践示例？<a class="ae nj" href="https://www.bitsy.ai/" rel="noopener ugc nofollow" target="_blank">注册我的简讯</a>！</p><p id="7be6" class="pw-post-body-paragraph li lj jb lk b ll me kc ln lo mf kf lq lr mg lt lu lv mh lx ly lz mi mb mc md ij bi translated">我发布了现实世界中 ML 应用程序的例子(有完整的源代码)和漂亮的技巧，如<a class="ae nj" href="https://www.bitsy.ai/automate-bounding-box-annotation-with-tensorflow-and-automl/" rel="noopener ugc nofollow" target="_blank">自动消除边框注释的痛苦</a>。</p></div></div>    
</body>
</html>