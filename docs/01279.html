<html>
<head>
<title>Implementing a Naive Bayes classifier for text categorization in five steps</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">用五个步骤实现用于文本分类的朴素贝叶斯分类器</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/implementing-a-naive-bayes-classifier-for-text-categorization-in-five-steps-f9192cdd54c3?source=collection_archive---------2-----------------------#2019-02-28">https://towardsdatascience.com/implementing-a-naive-bayes-classifier-for-text-categorization-in-five-steps-f9192cdd54c3?source=collection_archive---------2-----------------------#2019-02-28</a></blockquote><div><div class="fc if ig ih ii ij"/><div class="ik il im in io"><div class=""/><div class=""><h2 id="fc04" class="pw-subtitle-paragraph jo iq ir bd b jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf dk translated">我希望我以前有朴素贝叶斯分类器指南</h2></div><figure class="kh ki kj kk gu kl gi gj paragraph-image"><div class="gi gj kg"><img src="../Images/b286e95adf75c6dea9c5a1368d367d6f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1200/format:webp/1*p8Kj4TqNYOSvC1q_QWPCXA.png"/></div><figcaption class="ko kp gk gi gj kq kr bd b be z dk">Thomas Bayes (1701–1761) author of the Bayes’ theorem</figcaption></figure><blockquote class="ks kt ku"><p id="02b7" class="kv kw kx ky b kz la js lb lc ld jv le lf lg lh li lj lk ll lm ln lo lp lq lr ik bi translated">朴素贝叶斯是一种常用于文本分类的学习算法。</p></blockquote><p id="319b" class="pw-post-body-paragraph kv kw ir ky b kz la js lb lc ld jv le ls lg lh li lt lk ll lm lu lo lp lq lr ik bi translated">朴素贝叶斯分类器的一些应用是:</p><ul class=""><li id="bd40" class="lv lw ir ky b kz la lc ld ls lx lt ly lu lz lr ma mb mc md bi translated"><strong class="ky is">(自动)对文件夹</strong>中的电子邮件进行分类，因此收到的电子邮件信息会进入<strong class="ky is">:</strong>“家人”、“朋友”、“更新”、“促销”等文件夹。</li><li id="e10c" class="lv lw ir ky b kz me lc mf ls mg lt mh lu mi lr ma mb mc md bi translated"><strong class="ky is">(自动)工作列表的标记。给定一个原始文本格式的工作列表，我们可以给它分配标签，如:“软件开发”、“设计”、“营销”等。</strong></li><li id="dbb6" class="lv lw ir ky b kz me lc mf ls mg lt mh lu mi lr ma mb mc md bi translated"><strong class="ky is">(自动)产品分类。给定一个产品描述，我们可以将其分类，如:“书籍”、“电子产品”、“服装”等。</strong></li></ul><p id="e9d8" class="pw-post-body-paragraph kv kw ir ky b kz la js lb lc ld jv le ls lg lh li lt lk ll lm lu lo lp lq lr ik bi translated">本文的其余部分将提供必要的背景知识和直觉，通过五个步骤从头构建一个朴素贝叶斯分类器。</p><h1 id="0ae6" class="mj mk ir bd ml mm mn mo mp mq mr ms mt jx mu jy mv ka mw kb mx kd my ke mz na bi translated">第一步。确定训练朴素贝叶斯分类器的先决条件</h1><p id="a9f2" class="pw-post-body-paragraph kv kw ir ky b kz nb js lb lc nc jv le ls nd lh li lt ne ll lm lu nf lp lq lr ik bi translated">如前所述，贝叶斯分类器在文本分类中的应用是无止境的。唯一的先决条件是，对于我们希望将文本片段进行分类的每个类别(<em class="kx"> class) </em>，都有一组现有的<em class="kx">示例</em>。</p><p id="e5e4" class="pw-post-body-paragraph kv kw ir ky b kz la js lb lc ld jv le ls lg lh li lt lk ll lm lu lo lp lq lr ik bi translated">例如，对于工作列表分类示例，我们需要一组已知针对“软件开发人员”的工作列表，一组已知针对“设计人员”的工作列表，以及一组针对“营销人员”的工作列表。</p><p id="6928" class="pw-post-body-paragraph kv kw ir ky b kz la js lb lc ld jv le ls lg lh li lt lk ll lm lu lo lp lq lr ik bi translated">在这种情况下，有三个类(“软件开发”、“设计”和“营销”)。利用每个类别中的工作列表样本，我们可以训练一个朴素贝叶斯分类器，以便自动对<em class="kx">新的</em>工作列表进行分类。</p><p id="2ef8" class="pw-post-body-paragraph kv kw ir ky b kz la js lb lc ld jv le ls lg lh li lt lk ll lm lu lo lp lq lr ik bi translated">我们将在本文剩余部分探讨的示例是<strong class="ky is">垃圾邮件/垃圾邮件分类，</strong>因此，有两个类别:“垃圾邮件”和“垃圾邮件”(即非垃圾邮件)。如前所述，唯一的先决条件是拥有已知为垃圾邮件的现有<em class="kx">训练集</em>和已知为垃圾邮件的训练集<em class="kx">。</em></p><p id="bf3d" class="pw-post-body-paragraph kv kw ir ky b kz la js lb lc ld jv le ls lg lh li lt lk ll lm lu lo lp lq lr ik bi translated">为了说明清楚，我们的训练集将由三封垃圾邮件和三封垃圾邮件组成(下面的图片是可点击的，因此您可以放大并阅读每封邮件):</p><div class="kh ki kj kk gu ab cb"><figure class="ng kl nh ni nj nk nl paragraph-image"><div role="button" tabindex="0" class="nm nn di no bf np"><img src="../Images/d6bea97abb6f54cb2ca1fd7e2d7740f7.png" data-original-src="https://miro.medium.com/v2/resize:fit:632/format:webp/1*MANFKNEtFL17J_18BHBVKA.png"/></div></figure><figure class="ng kl nq ni nj nk nl paragraph-image"><div role="button" tabindex="0" class="nm nn di no bf np"><img src="../Images/4a9f493486c24bc3660d8c462616c5c5.png" data-original-src="https://miro.medium.com/v2/resize:fit:746/format:webp/1*FNjUOhZSctGkYCTmxE3svw.png"/></div></figure><figure class="ng kl nr ni nj nk nl paragraph-image"><div role="button" tabindex="0" class="nm nn di no bf np"><img src="../Images/2b6bd46992a03ad03362d7859539e3d6.png" data-original-src="https://miro.medium.com/v2/resize:fit:626/format:webp/1*5rh2eTnjCe5hC9myl_qP0w.png"/></div><figcaption class="ko kp gk gi gj kq kr bd b be z dk ns di nt nu">Examples of HAM emails.</figcaption></figure></div><div class="ab cb"><figure class="ng kl nv ni nj nk nl paragraph-image"><div role="button" tabindex="0" class="nm nn di no bf np"><img src="../Images/2b86f712d37afd14f04f2ec07ca2f34a.png" data-original-src="https://miro.medium.com/v2/resize:fit:680/format:webp/1*pn7uG0HdWhvhK63rSd6oMA.png"/></div></figure><figure class="ng kl nw ni nj nk nl paragraph-image"><div role="button" tabindex="0" class="nm nn di no bf np"><img src="../Images/010ee4a290d36304b60b1e2b02814c37.png" data-original-src="https://miro.medium.com/v2/resize:fit:620/format:webp/1*0Z-mSs8UfHuSqiIQ4jXyJA.png"/></div></figure><figure class="ng kl nx ni nj nk nl paragraph-image"><div role="button" tabindex="0" class="nm nn di no bf np"><img src="../Images/f07446d42cc48c483efe53b94448d8f1.png" data-original-src="https://miro.medium.com/v2/resize:fit:702/format:webp/1*yIUgcJ7zA249XR7s4yDSqw.png"/></div><figcaption class="ko kp gk gi gj kq kr bd b be z dk ny di nz nu">Examples of SPAM emails.</figcaption></figure></div><p id="e5e5" class="pw-post-body-paragraph kv kw ir ky b kz la js lb lc ld jv le ls lg lh li lt lk ll lm lu lo lp lq lr ik bi translated">请注意，在生产级垃圾邮件过滤器中，训练集的大小(即，已知垃圾邮件和 Ham 电子邮件的数量)通常要大得多，然而，我们将在此开发的概念和直觉确实适用。</p><h1 id="581a" class="mj mk ir bd ml mm mn mo mp mq mr ms mt jx mu jy mv ka mw kb mx kd my ke mz na bi translated"><strong class="ak">步骤二。计算每个类别的术语文档矩阵(TDM)</strong></h1><p id="fb4d" class="pw-post-body-paragraph kv kw ir ky b kz nb js lb lc nc jv le ls nd lh li lt ne ll lm lu nf lp lq lr ik bi translated">术语-文档矩阵(TDM)由出现在一组文档中的词频列表组成。</p><p id="0dac" class="pw-post-body-paragraph kv kw ir ky b kz la js lb lc ld jv le ls lg lh li lt lk ll lm lu lo lp lq lr ik bi translated">TDM 矩阵是由<em class="kx"> n </em>个字和<em class="kx"> m </em>个文档组成的稀疏矩形矩阵。之所以说它稀疏，是因为它包含的大部分都是零。TDM 矩阵的条目(<em class="kx"> i，j </em>)表示单词“<em class="kx">I”</em>在文档“<em class="kx">j”</em>中的出现频率。</p><p id="f01e" class="pw-post-body-paragraph kv kw ir ky b kz la js lb lc ld jv le ls lg lh li lt lk ll lm lu lo lp lq lr ik bi translated">对于考虑英语中所有单词的英语垃圾邮件分类器，单词的数量(<em class="kx"> n </em>)大约为 170k。至于每节课的例题数量，一般规律是越多越好:-)。然而，实际上，几千条信息给出了合理的预测。对于垃圾邮件检测任务，垃圾邮件标记数据的实际来源是<a class="ae oa" href="https://spamassassin.apache.org/" rel="noopener ugc nofollow" target="_blank"> SpamAssassin </a>。</p><p id="7b7c" class="pw-post-body-paragraph kv kw ir ky b kz la js lb lc ld jv le ls lg lh li lt lk ll lm lu lo lp lq lr ik bi translated">以下图片摘自垃圾邮件和垃圾邮件类别的 TDM 矩阵:</p><div class="kh ki kj kk gu ab cb"><figure class="ng kl ob ni nj nk nl paragraph-image"><div role="button" tabindex="0" class="nm nn di no bf np"><img src="../Images/aa76766b660c6b03012f7ec4f7af83b4.png" data-original-src="https://miro.medium.com/v2/resize:fit:970/format:webp/1*mwzaJcKupomrTkksywUzyg.png"/></div></figure><figure class="ng kl oc ni nj nk nl paragraph-image"><div role="button" tabindex="0" class="nm nn di no bf np"><img src="../Images/e9a0817c07c5e8fcc7e4b83493c94bdf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1032/format:webp/1*lf6JHpqQyyCqrgc61CH43g.png"/></div><figcaption class="ko kp gk gi gj kq kr bd b be z dk od di oe nu">Term document matrix excerpts for the HAM and SPAM emails.</figcaption></figure></div><h1 id="330e" class="mj mk ir bd ml mm mn mo mp mq mr ms mt jx mu jy mv ka mw kb mx kd my ke mz na bi translated">九月三日。计算频率</h1><p id="75cf" class="pw-post-body-paragraph kv kw ir ky b kz nb js lb lc nc jv le ls nd lh li lt ne ll lm lu nf lp lq lr ik bi translated">一旦为每个类别计算了 TDM 矩阵，下一步就是计算每个术语的频率和出现次数:</p><div class="kh ki kj kk gu ab cb"><figure class="ng kl of ni nj nk nl paragraph-image"><div role="button" tabindex="0" class="nm nn di no bf np"><img src="../Images/e833114811c71d74b0b08b056920869e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1012/format:webp/1*TtDZuUZ1Lku4QvCyTGsEUw.png"/></div></figure><figure class="ng kl og ni nj nk nl paragraph-image"><div role="button" tabindex="0" class="nm nn di no bf np"><img src="../Images/caaa13cd3339892be9ae788ffdf6569c.png" data-original-src="https://miro.medium.com/v2/resize:fit:990/format:webp/1*G_h0ni44-1PwTXX9uko8Bw.png"/></div><figcaption class="ko kp gk gi gj kq kr bd b be z dk oh di oi nu">Top 10 terms sorted by frequency for the HAM and SPAM classes.</figcaption></figure></div><p id="3c1a" class="pw-post-body-paragraph kv kw ir ky b kz la js lb lc ld jv le ls lg lh li lt lk ll lm lu lo lp lq lr ik bi translated">根据原始频率计数，您可以推断垃圾邮件包含高频术语，如“免费”，而垃圾邮件包含高频术语，如“考试”。这就是分类器将能够区分一个类和另一个类的方式。</p><p id="c917" class="pw-post-body-paragraph kv kw ir ky b kz la js lb lc ld jv le ls lg lh li lt lk ll lm lu lo lp lq lr ik bi translated">“频率”列是每个术语在所有文档中出现的次数，即 TDM 矩阵各列的总和。“出现”列是每个术语在所有文档中出现的时间百分比。</p><p id="4ae7" class="pw-post-body-paragraph kv kw ir ky b kz la js lb lc ld jv le ls lg lh li lt lk ll lm lu lo lp lq lr ik bi translated">“频率”和“出现”列都可以用于计算概率估计，但是，“出现”列是优选的，因为它被限制在 0 和 1 之间。</p><h1 id="b0e0" class="mj mk ir bd ml mm mn mo mp mq mr ms mt jx mu jy mv ka mw kb mx kd my ke mz na bi translated"><strong class="ak">第四步。回想一下朴素贝叶斯法则</strong></h1><p id="89a0" class="pw-post-body-paragraph kv kw ir ky b kz nb js lb lc nc jv le ls nd lh li lt ne ll lm lu nf lp lq lr ik bi translated">根据基本概率，假设另一个事件<strong class="ky is"> B </strong>也发生了，那么一个事件<strong class="ky is"> A </strong>发生的概率是多少？按顺序的话，<strong class="ky is">A</strong>T24】给 T26】B 的概率是多少？</p><figure class="kh ki kj kk gu kl gi gj paragraph-image"><div role="button" tabindex="0" class="nm nn di no bf np"><div class="gi gj oj"><img src="../Images/c2ac916bb20192a95310e4394e8ab40c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*3haPOnUnab_4vrVAy0MjOg.png"/></div></div><figcaption class="ko kp gk gi gj kq kr bd b be z dk">Probability of A given B.</figcaption></figure><p id="c713" class="pw-post-body-paragraph kv kw ir ky b kz la js lb lc ld jv le ls lg lh li lt lk ll lm lu lo lp lq lr ik bi translated">从下面的文氏图中</p><figure class="kh ki kj kk gu kl gi gj paragraph-image"><div role="button" tabindex="0" class="nm nn di no bf np"><div class="gi gj ok"><img src="../Images/3d9329f29079ce89f2f1f858cd05d6d4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*MhvDQ3NI7o1_Oka1N4qj0g.png"/></div></div></figure><p id="fb8d" class="pw-post-body-paragraph kv kw ir ky b kz la js lb lc ld jv le ls lg lh li lt lk ll lm lu lo lp lq lr ik bi translated">我们可以看到，给定 B 的概率是 A 和 B (交集)发生的<strong class="ky is">概率除以 B </strong>发生的<strong class="ky is">概率<strong class="ky is">，</strong>即:</strong></p><figure class="kh ki kj kk gu kl gi gj paragraph-image"><div role="button" tabindex="0" class="nm nn di no bf np"><div class="gi gj ol"><img src="../Images/900fe7404c0a0b8811907d4d91c22d39.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*EbKPutw-9THW0meeQA_2hA.png"/></div></div><figcaption class="ko kp gk gi gj kq kr bd b be z dk">Eq. 1</figcaption></figure><p id="f490" class="pw-post-body-paragraph kv kw ir ky b kz la js lb lc ld jv le ls lg lh li lt lk ll lm lu lo lp lq lr ik bi translated">现在，假设 A 也发生了，那么 B 发生的概率呢？根据前面的公式，我们得到:</p><figure class="kh ki kj kk gu kl gi gj paragraph-image"><div role="button" tabindex="0" class="nm nn di no bf np"><div class="gi gj om"><img src="../Images/1cbf5f4f09ce52ff0b386f6285aa8000.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*HpyCz-mxVAqm5C2nGxLkMw.png"/></div></div><figcaption class="ko kp gk gi gj kq kr bd b be z dk">Eq. 2</figcaption></figure><p id="17b2" class="pw-post-body-paragraph kv kw ir ky b kz la js lb lc ld jv le ls lg lh li lt lk ll lm lu lo lp lq lr ik bi translated">从文氏图中可以看出</p><figure class="kh ki kj kk gu kl gi gj paragraph-image"><div role="button" tabindex="0" class="nm nn di no bf np"><div class="gi gj ol"><img src="../Images/7d3e92b1e8f98064609c9aef8c983af0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*dFw36kPKrTkV7Q7mz6sCfQ.png"/></div></div></figure><p id="cbf0" class="pw-post-body-paragraph kv kw ir ky b kz la js lb lc ld jv le ls lg lh li lt lk ll lm lu lo lp lq lr ik bi translated">因此，通过等式。1 和 Eq。2 我们得到贝叶斯定理:</p><figure class="kh ki kj kk gu kl gi gj paragraph-image"><div role="button" tabindex="0" class="nm nn di no bf np"><div class="gi gj on"><img src="../Images/cf33ed06385068bc5c1a9e00a32d1580.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*DrxI1XrTAEMVIMruqUg9hQ.png"/></div></div><figcaption class="ko kp gk gi gj kq kr bd b be z dk"><strong class="bd oo">Bayes theorem</strong></figcaption></figure><p id="ce6f" class="pw-post-body-paragraph kv kw ir ky b kz la js lb lc ld jv le ls lg lh li lt lk ll lm lu lo lp lq lr ik bi translated">鉴于贝叶斯定理在概率论中的重要性，每个术语都有一个名称:</p><figure class="kh ki kj kk gu kl gi gj paragraph-image"><div role="button" tabindex="0" class="nm nn di no bf np"><div class="gi gj op"><img src="../Images/625045fae7ca9f542a0b68f390f72acc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*7Mwi1C1gG5yjPAwgsBYwcQ.png"/></div></div><figcaption class="ko kp gk gi gj kq kr bd b be z dk">Naming terms in Bayes theorem</figcaption></figure><p id="4dbf" class="pw-post-body-paragraph kv kw ir ky b kz la js lb lc ld jv le ls lg lh li lt lk ll lm lu lo lp lq lr ik bi translated">简单来说，“<strong class="ky is">先验</strong>”<em class="kx">P(A)</em>、“<strong class="ky is">证据</strong>”<em class="kx">P(B)</em>是指相互独立地观察到 A 和 B 的概率，而“<strong class="ky is">后验</strong>”和“<strong class="ky is">似然</strong>是观察到给定 B 的<strong class="ky is">条件</strong> <strong class="ky is">概率</strong>，反之亦然。</p><p id="3a38" class="pw-post-body-paragraph kv kw ir ky b kz la js lb lc ld jv le ls lg lh li lt lk ll lm lu lo lp lq lr ik bi translated">回到我们在垃圾邮件或 Ham 中的电子邮件分类示例，我们要计算的概率是:</p><figure class="kh ki kj kk gu kl gi gj paragraph-image"><div role="button" tabindex="0" class="nm nn di no bf np"><div class="gi gj om"><img src="../Images/99fc6599097094139c81e5b96889d5bc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*RmDK6W3U0oCIYDB9-HJ8ew.png"/></div></div></figure><p id="8257" class="pw-post-body-paragraph kv kw ir ky b kz la js lb lc ld jv le ls lg lh li lt lk ll lm lu lo lp lq lr ik bi translated">其中<strong class="ky is"> x </strong>是包含来自垃圾邮件的单词的特征向量:</p><figure class="kh ki kj kk gu kl gi gj paragraph-image"><div role="button" tabindex="0" class="nm nn di no bf np"><div class="gi gj oq"><img src="../Images/b22e2702a79fb290e5ff8adb2bb00912.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*26Tx1YxhfrYaq060XbNL9g.png"/></div></div><figcaption class="ko kp gk gi gj kq kr bd b be z dk">Feature vector <strong class="bd oo">x </strong>composed of <strong class="bd oo">n </strong>words coming from spam emails.</figcaption></figure><p id="5322" class="pw-post-body-paragraph kv kw ir ky b kz la js lb lc ld jv le ls lg lh li lt lk ll lm lu lo lp lq lr ik bi translated"><em class="kx">朴素贝叶斯</em>结果是“<strong class="ky is">可能性</strong>”是在一组垃圾邮件或业余电子邮件中看到每个单词的个体概率的乘积。我们在步骤 3 中计算了这些概率，并将它们存储在“发生”列中。形式上:</p><figure class="kh ki kj kk gu kl gi gj paragraph-image"><div role="button" tabindex="0" class="nm nn di no bf np"><div class="gi gj or"><img src="../Images/40971eab4758062380b5b9b846cd0926.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_qI6gDqiUsuDYH7_ytECNg.png"/></div></div></figure><p id="8a72" class="pw-post-body-paragraph kv kw ir ky b kz la js lb lc ld jv le ls lg lh li lt lk ll lm lu lo lp lq lr ik bi translated">注意“<strong class="ky is">证据</strong>”是一个仅取决于特征的常数因子，因此在前面的等式中为“<strong class="ky is">可能性</strong>”计算引入了比例符号。</p><p id="1e54" class="pw-post-body-paragraph kv kw ir ky b kz la js lb lc ld jv le ls lg lh li lt lk ll lm lu lo lp lq lr ik bi translated">此外，由于我们的数据集有 3 封垃圾邮件和 3 封垃圾邮件，我们知道“<strong class="ky is">优先于</strong>”<em class="kx">P(垃圾邮件)</em>是 50%。</p><p id="3f0e" class="pw-post-body-paragraph kv kw ir ky b kz la js lb lc ld jv le ls lg lh li lt lk ll lm lu lo lp lq lr ik bi translated">总之，由于我们在贝叶斯定理中有所有必要的术语(“<strong class="ky is">可能性</strong>”、“<strong class="ky is">先验</strong>”和“<strong class="ky is">证据</strong>”)，我们可以继续计算“<strong class="ky is">后验</strong>”概率。回答这个等式的概率是，给定的(看不见的)电子邮件是垃圾邮件的概率是多少？</p><blockquote class="ks kt ku"><p id="f08b" class="kv kw kx ky b kz la js lb lc ld jv le lf lg lh li lj lk ll lm ln lo lp lq lr ik bi translated">回想一下，朴素贝叶斯分类器的主要假设是每个特征(单词)彼此独立。</p></blockquote><h1 id="108f" class="mj mk ir bd ml mm mn mo mp mq mr ms mt jx mu jy mv ka mw kb mx kd my ke mz na bi translated"><strong class="ak">第五步。计算收到垃圾邮件的概率</strong></h1><p id="4c04" class="pw-post-body-paragraph kv kw ir ky b kz nb js lb lc nc jv le ls nd lh li lt ne ll lm lu nf lp lq lr ik bi translated">假设我们计算了垃圾邮件或业余爱好者电子邮件中出现的术语的概率数据库，我们可以继续进行<em class="kx">朴素贝叶斯分类器</em>的最后一步，即分类。</p><p id="218b" class="pw-post-body-paragraph kv kw ir ky b kz la js lb lc ld jv le ls lg lh li lt lk ll lm lu lo lp lq lr ik bi translated">正式的决策规则是:</p><figure class="kh ki kj kk gu kl gi gj paragraph-image"><div role="button" tabindex="0" class="nm nn di no bf np"><div class="gi gj os"><img src="../Images/73f4c073f3cf4ed1915d95179ca04673.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*X7JStLkiPeI_1zyA3loVuw.png"/></div></div><figcaption class="ko kp gk gi gj kq kr bd b be z dk">Decision rule: pick the most probable hypothesis.</figcaption></figure><p id="52f3" class="pw-post-body-paragraph kv kw ir ky b kz la js lb lc ld jv le ls lg lh li lt lk ll lm lu lo lp lq lr ik bi translated">这意味着，对于每个传入的电子邮件，我们必须计算此类电子邮件是垃圾邮件和垃圾邮件的概率(即，对于每个类)，并且我们的最终验证将由最大概率给出。</p><p id="3d3b" class="pw-post-body-paragraph kv kw ir ky b kz la js lb lc ld jv le ls lg lh li lt lk ll lm lu lo lp lq lr ik bi translated">以下面的电子邮件为例:</p><figure class="kh ki kj kk gu kl gi gj paragraph-image"><div role="button" tabindex="0" class="nm nn di no bf np"><div class="gi gj ot"><img src="../Images/58d8b477af52ed92f973d066a10035c9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*F13aNiDTxwW7fzKLS7n3Jg.png"/></div></div><figcaption class="ko kp gk gi gj kq kr bd b be z dk">Test HAM email.</figcaption></figure><p id="f14f" class="pw-post-body-paragraph kv kw ir ky b kz la js lb lc ld jv le ls lg lh li lt lk ll lm lu lo lp lq lr ik bi translated">假设不在我们的训练集中的单词的任意小概率为 1e-2，则每个类别的概率为:</p><figure class="kh ki kj kk gu kl gi gj paragraph-image"><div role="button" tabindex="0" class="nm nn di no bf np"><div class="gi gj ou"><img src="../Images/6eb01dde7dc38970b057512d6b04a27d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*OgAHq06IjsOfFUIESLEWmw.png"/></div></div></figure><p id="9f13" class="pw-post-body-paragraph kv kw ir ky b kz la js lb lc ld jv le ls lg lh li lt lk ll lm lu lo lp lq lr ik bi translated">表明该电子邮件是垃圾邮件。</p><p id="99a1" class="pw-post-body-paragraph kv kw ir ky b kz la js lb lc ld jv le ls lg lh li lt lk ll lm lu lo lp lq lr ik bi translated">关于小数字的链乘的注释(感谢<a class="ae oa" href="https://news.ycombinator.com/user?id=jgrahamc" rel="noopener ugc nofollow" target="_blank"> jgrahamc </a>):</p><p id="36c2" class="pw-post-body-paragraph kv kw ir ky b kz la js lb lc ld jv le ls lg lh li lt lk ll lm lu lo lp lq lr ik bi translated">【http://getpopfile.org/docs/faq:bayesandlogs】<br/>参考:<a class="ae oa" href="http://getpopfile.org/docs/faq:bayesandlogs" rel="noopener ugc nofollow" target="_blank"/>“实际上，取概率的 log()是有用的，这样你就可以处理对数的和，而不是乘以小的浮点数”</p><h2 id="5ff3" class="ov mk ir bd ml ow ox dn mp oy oz dp mt ls pa pb mv lt pc pd mx lu pe pf mz pg bi translated">参考资料和源代码:</h2><figure class="kh ki kj kk gu kl gi gj paragraph-image"><a href="https://amzn.to/2Xjkuqa"><div class="gi gj ph"><img src="../Images/5cd71e827eea520f79696a3f5ab61aca.png" data-original-src="https://miro.medium.com/v2/resize:fit:600/format:webp/1*z13NAbmbZV3eqo3uBGhvAw.jpeg"/></div></a></figure><p id="ea1e" class="pw-post-body-paragraph kv kw ir ky b kz la js lb lc ld jv le ls lg lh li lt lk ll lm lu lo lp lq lr ik bi translated">文件处理、TDM 矩阵计算、频率、最终分类和示例电子邮件的源代码可以在这个存储库中找到:<a class="ae oa" href="https://github.com/gchavez2/code_machine_learning_algorithms" rel="noopener ugc nofollow" target="_blank"><strong class="ky is">https://github . com/gchave z2/code _ machine _ learning _ algorithms</strong></a>。</p><p id="ddf0" class="pw-post-body-paragraph kv kw ir ky b kz la js lb lc ld jv le ls lg lh li lt lk ll lm lu lo lp lq lr ik bi translated">该代码大量借鉴了 O'Reilly Media 出版的<a class="ae oa" href="https://amzn.to/2Xjkuqa" rel="noopener ugc nofollow" target="_blank">Conway&amp;Myles Machine Learning for Hackers 一书第 3 章</a>，该书还提供了一个更大的垃圾邮件和业余邮件数据库，以及估计不在训练集词汇中的单词概率的策略。</p></div><div class="ab cl pi pj hv pk" role="separator"><span class="pl bw bk pm pn po"/><span class="pl bw bk pm pn po"/><span class="pl bw bk pm pn"/></div><div class="ik il im in io"><p id="eba9" class="pw-post-body-paragraph kv kw ir ky b kz la js lb lc ld jv le ls lg lh li lt lk ll lm lu lo lp lq lr ik bi translated"><em class="kx">我是劳伦斯伯克利国家实验室的博士后，在那里从事机器学习和高性能计算的交叉工作。</em></p><p id="6a33" class="pw-post-body-paragraph kv kw ir ky b kz la js lb lc ld jv le ls lg lh li lt lk ll lm lu lo lp lq lr ik bi translated"><em class="kx">如果你觉得这篇文章很有趣，请随意打个招呼，联系 LinkedIn </em>  <em class="kx">，我总是很乐意与该领域的其他专业人士交流。</em></p><p id="6a11" class="pw-post-body-paragraph kv kw ir ky b kz la js lb lc ld jv le ls lg lh li lt lk ll lm lu lo lp lq lr ik bi translated"><em class="kx">一如既往:非常感谢评论、问题和分享！❤️ </em></p><figure class="kh ki kj kk gu kl gi gj paragraph-image"><a href="http://eepurl.com/giSKB9"><div class="gi gj pp"><img src="../Images/fc9812283b6ecba784677161ec8ba4ef.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*FCyfjdltxWoVuR5fiKmlbA.png"/></div></a><figcaption class="ko kp gk gi gj kq kr bd b be z dk">No Spam, ever.</figcaption></figure></div></div>    
</body>
</html>