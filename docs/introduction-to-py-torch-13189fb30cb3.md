# PyTorch 简介

> 原文：<https://towardsdatascience.com/introduction-to-py-torch-13189fb30cb3?source=collection_archive---------7----------------------->

![](img/7667be18c27551c8486446c18799c446.png)

(source: https://pytorch.org)

[PyTorch](https://pytorch.org/) 是一个开源的机器学习库，用于开发和训练基于[神经网络](https://thewiz.net/eUK2)的深度学习模型。它主要由脸书的人工智能研究小组开发。PyTorch 可以和 Python 以及 C++一起使用。自然，Python 的接口更加完善。Pytorch(由脸书、微软、SalesForce、优步等巨头支持)在研究实验室非常受欢迎。Pytorch 在许多生产服务器上还没有，这些服务器由 TensorFlow(由 Google 支持)这样的 fromeworks 控制，它正在快速发展。

与大多数其他流行的深度学习框架不同，如 [TensorFlow](https://thewiz.net/eULN) ，它们使用静态计算图，PyTorch 使用动态计算，这允许在构建复杂架构时有更大的灵活性。Pytorch 使用了 Python 的核心概念，如类、结构和条件循环——这些概念对我们来说非常熟悉，因此理解起来更加直观。这使得它比 TensorFlow 等引入自己编程风格的其他框架简单得多。

为了对这个库有所了解，让我们来看看 PyTorch 的一个基本实现。

# 安装 PyTorch

PyTorch 有一个 Windows 版本，但我宁愿远离它。事实上，如果你真的感兴趣，你最好不要再看窗外了。跳到 [SageMaker](https://thewiz.net/eULQ) 。而如果你不想花一分钱，就试试 [Google Colab](https://colab.research.google.com/) 。

但是如果必须的话，可以在 Anaconda 上安装 PyTorch，使用

现在，让我们从构建神经网络开始。让我们拿起我们的好老 [MNIST](https://thewiz.net/eULO) 数据集。

# 导入模块

第一步当然是导入相关的库。

# 收集数据

当然，这个过程的第一步是收集训练模型所需的数据。这里，我们将使用打包到 PyTorch 中的 MNIST 数据集。

这两行是打包了功能的代码。本质上，它从 torchvision.dataset 模块中选取数据集。该数据被归一化，然后加载到张量中。在此基础上，将其装入数据加载器。

# 建立网络

做完这些，我们从真正的代码开始。如前所述，PyTorch 使用基本的、熟悉的编程范例，而不是发明自己的范例。PyTorch 中的神经网络是一个对象。它是定义这个网络的类的一个实例，继承自 torch.nn 模块

torch.nn .模块提供开发和训练、测试和部署神经网络所需的核心功能。当我们子类化它时，我们通常会覆盖其中的两个方法。框架会处理剩下的事情。

我的意思是。

正如我们所看到的，上面的两种方法给了我们定义神经网络所需要的一切。这个网络有四层(两层隐藏)。前两个是卷积，接下来的两个是线性的、完全连接的层。前三层的激活函数是 Relu，最后一层是 SoftMax。

构造者构建网络。forward()方法定义了它如何向前移动。

# 训练网络

既然模型已经准备好了，我们就必须使用现有的数据来训练模型。这是通过方法训练()完成的

接收的参数是模型(我们实例化的网络模型)、设备(运行负载的设备 gpu/cpu 的种类)、train_loader(用于训练数据)、优化器(用于训练模型)以及纪元编号(仅用于显示在日志中)。

上面方法中的第一行调用 model.train() —一个从 nn.Module 继承的方法。接下来，我们对从加载器中提取的训练数据批次进行循环。

然后我们初始化优化器。下一行负责正向传播——我们根据当前模型计算输入数据的输出。

接下来的两行负责向后传播。我们通过比较输出和目标来计算损失。然后，我们基于这个损失更新模型。我们对整个数据集都这样做。

# 测试网络

同样，我们有一个测试方法，可以根据给定的测试数据集来验证网络的性能。

本质上，这种方法只是在整个测试数据中循环，找出所有的损失。它计算正确和错误预测的数量，并打印格式化的日志。

# 放在一起

有了框架后，我们必须开始将这些片段拼接成一个应用程序，该应用程序可以构建、训练和验证神经网络模型

我们从播种模块开始。

当然，PyTorch(或任何 ML 库)是为 GPU 设计的，但它也可以为 CPU 设计。为了指示执行模式，我们需要实例化设备

下一步是创建我们上面定义的神经网络模型的实例。

下一步是创建一个优化器实例。对于这个例子，我们将使用随机梯度下降来训练这个模型。我们使用 0.01 的学习率和 0.9 的动量

有了舞台设置，剩下的就是用我们拥有的数据来训练网络。

正如我们在教科书中所学的，这是一个 for 循环，它一遍又一遍地向前和向后传播。在每个时期，我们测试我们生成的模型。

与张量流相比，这当然更直观。它的性能成本较低，但研究人员更喜欢 PyTorch 提供的清晰度。

当我们运行上面的代码时，我们得到类似如下的输出:

我们可以看到传入数据的模型训练。我们还可以注意到，该模型在第 9 步之前一直在改进，然后就饱和了——可能过度适应了训练集。我们可以调整超参数来改进这个模型。但我猜 99%对我们的目的来说应该是好的。我们可以使用“提前停止”在步骤 9 中获取模型。

最后，我们保存训练好的模型，以便在现场部署。

当然，这只是一瞥。PyTorch 为不同类型的模型和网络以及不同类型的用例加载了功能。大量的书籍、博客和视频可以给你更多更详细的信息。

他们自己的网站对学习这门学科很有帮助。