<html>
<head>
<title>AI Powered Search for Extra-terrestrial Intelligence — Deep Learning Signal Classifiers</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">人工智能驱动的外星智能搜索——深度学习信号分类器</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/ai-powered-search-for-extra-terrestrial-intelligence-signal-classification-with-deep-learning-6c09de8fd57c?source=collection_archive---------22-----------------------#2019-08-21">https://towardsdatascience.com/ai-powered-search-for-extra-terrestrial-intelligence-signal-classification-with-deep-learning-6c09de8fd57c?source=collection_archive---------22-----------------------#2019-08-21</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><h2 id="9696" class="ir is it bd b dl iu iv iw ix iy iz dk ja translated" aria-label="kicker paragraph">人工智能造福社会系列—第 2.2 部分</h2><div class=""/><div class=""><h2 id="7788" class="pw-subtitle-paragraph jz jc it bd b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq dk translated">基于深度学习的 SETI 射电望远镜信号分类</h2></div><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi kr"><img src="../Images/be7afce7f24465828c71bf12c61266c9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*xHKwf4Vl4GXuh1HIW0Wnjg.jpeg"/></div></div><figcaption class="ld le gj gh gi lf lg bd b be z dk">Photo by <a class="ae lh" href="https://unsplash.com/@wizwow?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank">Donald Giannatti</a> on <a class="ae lh" href="https://unsplash.com/?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><h1 id="bb42" class="li lj it bd lk ll lm ln lo lp lq lr ls ki lt kj lu kl lv km lw ko lx kp ly lz bi translated">介绍</h1><p id="81cd" class="pw-post-body-paragraph ma mb it mc b md me kd mf mg mh kg mi mj mk ml mm mn mo mp mq mr ms mt mu mv im bi translated">欢迎(或者欢迎回来！)到 AI for social good 系列！在这个由两部分组成的系列文章的第二部分，我们将看看人工智能(AI)如何与深度学习等开源工具和技术的力量相结合，帮助我们进一步寻找外星智能！</p><p id="6da8" class="pw-post-body-paragraph ma mb it mc b md mw kd mf mg mx kg mi mj my ml mm mn mz mp mq mr na mt mu mv im bi translated">在<a class="ae lh" rel="noopener" target="_blank" href="/ai-powered-search-for-extra-terrestrial-intelligence-analyzing-radio-telescopic-data-c9e46741041"> <strong class="mc jd"> <em class="nb">这个两部分系列的第一部分</em> </strong> </a> <strong class="mc jd"> <em class="nb"> </em> </strong>中，我们制定了我们做这个项目背后的主要目标和动机。简而言之，我们正在观察来自 SETI(搜寻外星智慧)研究所<strong class="mc jd"><em class="nb"/></strong>数据模拟的不同射电望远镜信号。我们利用技术将无线电信号处理、分析和可视化为频谱图，频谱图基本上是原始信号的可视化表示。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi nc"><img src="../Images/d02f046960b9d7e19706ad7f1e885ec2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*JCcoBc0pwYuX6UHt.png"/></div><figcaption class="ld le gj gh gi lf lg bd b be z dk">Signal observed at the Allen Telescope Array from the Cassini satellite while orbiting Saturn on September 3, 2014 (Source: <a class="ae lh" href="https://medium.com/@gadamc/using-artificial-intelligence-to-search-for-extraterrestrial-intelligence-ec19169e01af" rel="noopener">https://medium.com/@gadamc/using-artificial-intelligence-to-search-for-extraterrestrial-intelligence-ec19169e01af</a>)</figcaption></figure><p id="10e4" class="pw-post-body-paragraph ma mb it mc b md mw kd mf mg mx kg mi mj my ml mm mn mz mp mq mr na mt mu mv im bi translated">在本文中，我们的重点将是尝试使用深度学习为总共七种不同类型的信号构建一个强大的无线电信号分类器！</p><h1 id="b09b" class="li lj it bd lk ll lm ln lo lp lq lr ls ki lt kj lu kl lv km lw ko lx kp ly lz bi translated">加载 SETI 信号数据</h1><p id="26d8" class="pw-post-body-paragraph ma mb it mc b md me kd mf mg mh kg mi mj mk ml mm mn mo mp mq mr ms mt mu mv im bi translated">就像我们在上一篇文章中讨论的那样，模拟的 SETI 无线电信号数据集在<a class="ae lh" href="https://www.kaggle.com/tentotheminus9/seti-data/home" rel="noopener ugc nofollow" target="_blank"> <strong class="mc jd"> Kaggle </strong> </a>中可用。记住，处理过的数据集在<code class="fe nd ne nf ng b"><strong class="mc jd">primary_small</strong></code>文件夹中。解压缩其内容后，这就是目录结构的样子。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi nh"><img src="../Images/eb311bfe13df4d1bac9579f2bffceeed.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*OxHxn-VzZklSAcxh8EVL6Q.png"/></div></div></figure><p id="9edb" class="pw-post-body-paragraph ma mb it mc b md mw kd mf mg mx kg mi mj my ml mm mn mz mp mq mr na mt mu mv im bi translated">我们总共有 7 个不同的信号类别要分类，每个类别总共有 800 个样本用于训练，100 个样本分别用于验证和测试。考虑到噪声已被添加到模拟信号数据中，再加上每类样本数量较少，这是一个很难解决的问题！在我们开始之前，让我们加载我们将用于构建模型的必要依赖项。这里我们将利用 TensorFlow 的<code class="fe nd ne nf ng b"><strong class="mc jd">tf.keras</strong></code> API。</p><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="ni nj l"/></div></figure><pre class="ks kt ku kv gt nk ng nl nm aw nn bi"><span id="e0c7" class="no lj it ng b gy np nq l nr ns"><strong class="ng jd">./data/train<br/>./data/valid<br/>./data/test</strong></span></pre><h1 id="7029" class="li lj it bd lk ll lm ln lo lp lq lr ls ki lt kj lu kl lv km lw ko lx kp ly lz bi translated">可视化样本 SETI 信号</h1><p id="7312" class="pw-post-body-paragraph ma mb it mc b md me kd mf mg mh kg mi mj mk ml mm mn mo mp mq mr ms mt mu mv im bi translated">回顾一下上一篇文章，看看我们正在处理的不同类型的信号，我们可以使用下面的代码来可视化它们的频谱图。</p><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="ni nj l"/></div></figure><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi nt"><img src="../Images/d36ca3f3f4b305fdbd969c7853fadf5c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*F9HPFJKz0jSUJaCQICiTxQ.png"/></div></div></figure><p id="6988" class="pw-post-body-paragraph ma mb it mc b md mw kd mf mg mx kg mi mj my ml mm mn mz mp mq mr na mt mu mv im bi translated">对于我们正在处理的不同信号样本，一切看起来都很正常！</p><h1 id="94a1" class="li lj it bd lk ll lm ln lo lp lq lr ls ki lt kj lu kl lv km lw ko lx kp ly lz bi translated">数据生成器和图像增强</h1><p id="fc2e" class="pw-post-body-paragraph ma mb it mc b md me kd mf mg mh kg mi mj mk ml mm mn mo mp mq mr ms mt mu mv im bi translated">由于我们每个类的训练样本数量很少，因此获得更多数据的一种策略是使用图像增强来生成新数据。图像增强背后的想法就像它的名字一样。我们从训练数据集中加载现有图像，并对其应用一些图像变换操作，如旋转、剪切、平移、缩放、翻转等，以产生现有图像的新的、改变的版本。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi nc"><img src="../Images/f041a8de13a0d46d4f7fd95b1310ac1f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*1eyXxnBCHPU5GiZP.png"/></div></figure><p id="127a" class="pw-post-body-paragraph ma mb it mc b md mw kd mf mg mx kg mi mj my ml mm mn mz mp mq mr na mt mu mv im bi translated">由于这些随机变换，我们每次得到的图像并不相同。基于我们正在解决的问题，我们需要小心增强操作，这样我们就不会过度扭曲源图像。</p><p id="c682" class="pw-post-body-paragraph ma mb it mc b md mw kd mf mg mx kg mi mj my ml mm mn mz mp mq mr na mt mu mv im bi translated">我们将对我们所有的训练数据进行一些基本的转换，但保持我们的验证和测试数据集不变，只是对数据进行缩放。现在让我们构建我们的数据生成器。</p><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="ni nj l"/></div></figure><p id="a973" class="pw-post-body-paragraph ma mb it mc b md mw kd mf mg mx kg mi mj my ml mm mn mz mp mq mr na mt mu mv im bi translated">我们现在可以构建一个样本数据生成器，以便了解数据生成器和图像增强是如何工作的。</p><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="ni nj l"/></div></figure><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi nu"><img src="../Images/f2232a0c4839ed558d96f52dbd66580b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*UllYGM0zLsERk5eDl90jQw.png"/></div></div></figure><p id="dd35" class="pw-post-body-paragraph ma mb it mc b md mw kd mf mg mx kg mi mj my ml mm mn mz mp mq mr na mt mu mv im bi translated">给定我们总共有 7 个类，标签是一次性编码的，因此每个标签是大小为 7 的一次性编码向量。</p><h1 id="67af" class="li lj it bd lk ll lm ln lo lp lq lr ls ki lt kj lu kl lv km lw ko lx kp ly lz bi translated">基于 CNN 的深度迁移学习</h1><p id="8c9c" class="pw-post-body-paragraph ma mb it mc b md me kd mf mg mh kg mi mj mk ml mm mn mo mp mq mr ms mt mu mv im bi translated">迁移学习的想法并不是一个新概念，当我们处理较少的数据时，它是非常有用的。假设我们有一个预先训练好的模型，该模型以前是根据大量数据训练的，我们可以用这个模型来解决一个数据较少的新问题，并且应该理想地得到一个性能更好、收敛更快的模型。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi nc"><img src="../Images/aeef734f139cc9956c31429061d47020.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*2g7__HctYE18eKSk.png"/></div></figure><p id="e1d0" class="pw-post-body-paragraph ma mb it mc b md mw kd mf mg mx kg mi mj my ml mm mn mz mp mq mr na mt mu mv im bi translated">有各种各样的预训练 CNN 模型，它们已经在 ImageNet 数据集上被训练，该数据集具有属于总共 1000 个类别的大量图像。这个想法是，这些模型应该作为图像的有效特征提取器，也可以根据我们执行的特定任务进行微调。预先训练的模型可以完全冻结，当我们在新数据集上训练时，我们根本不改变层权重，或者当我们在新数据集上训练时，我们可以微调(部分或完全)模型权重。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi nc"><img src="../Images/8b26e8a497b144ff13349ae273392134.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*zyLkMjftbFW7Z546.png"/></div></figure><p id="05fe" class="pw-post-body-paragraph ma mb it mc b md mw kd mf mg mx kg mi mj my ml mm mn mz mp mq mr na mt mu mv im bi translated"><strong class="mc jd"> <em class="nb">在我们的场景中，我们将尝试对我们预训练的模型</em> </strong>进行部分和完全的微调。</p><h1 id="3210" class="li lj it bd lk ll lm ln lo lp lq lr ls ki lt kj lu kl lv km lw ko lx kp ly lz bi translated">预先训练的 CNN 模型</h1><p id="bc96" class="pw-post-body-paragraph ma mb it mc b md me kd mf mg mh kg mi mj mk ml mm mn mo mp mq mr ms mt mu mv im bi translated">迁移学习的一个基本要求是要有在源任务中表现良好的模型。幸运的是，深度学习世界相信分享。他们各自的团队已经公开分享了许多最先进的深度学习架构。预训练模型通常以模型在被训练到稳定状态时获得的数百万个参数/权重的形式被共享。每个人都可以通过不同的方式使用预先训练好的模型。</p><p id="9d3a" class="pw-post-body-paragraph ma mb it mc b md mw kd mf mg mx kg mi mj my ml mm mn mz mp mq mr na mt mu mv im bi translated">TensorFlow 中提供了预训练模型，您可以使用其 API 轻松访问。我们将在本文中展示如何做到这一点。你也可以从网上获得预先训练好的模型，因为大多数模型都是开源的。</p><p id="8f97" class="pw-post-body-paragraph ma mb it mc b md mw kd mf mg mx kg mi mj my ml mm mn mz mp mq mr na mt mu mv im bi translated"><strong class="mc jd"> <em class="nb">对于计算机视觉</em> </strong>，可以利用一些流行的模型包括，</p><ul class=""><li id="edf8" class="nv nw it mc b md mw mg mx mj nx mn ny mr nz mv oa ob oc od bi translated"><a class="ae lh" href="https://www.kaggle.com/keras/vgg16/home" rel="noopener ugc nofollow" target="_blank"> VGG-16 </a></li><li id="cb69" class="nv nw it mc b md oe mg of mj og mn oh mr oi mv oa ob oc od bi translated"><a class="ae lh" href="https://www.kaggle.com/keras/vgg19/home" rel="noopener ugc nofollow" target="_blank"> VGG-19 </a></li><li id="4d3a" class="nv nw it mc b md oe mg of mj og mn oh mr oi mv oa ob oc od bi translated"><a class="ae lh" href="https://arxiv.org/abs/1512.00567" rel="noopener ugc nofollow" target="_blank">盗梦空间 V3 </a></li><li id="b16b" class="nv nw it mc b md oe mg of mj og mn oh mr oi mv oa ob oc od bi translated"><a class="ae lh" href="https://arxiv.org/abs/1610.02357" rel="noopener ugc nofollow" target="_blank">异常</a></li><li id="a714" class="nv nw it mc b md oe mg of mj og mn oh mr oi mv oa ob oc od bi translated"><a class="ae lh" href="https://www.kaggle.com/keras/resnet50/home" rel="noopener ugc nofollow" target="_blank"> ResNet-50 </a></li></ul><p id="9e32" class="pw-post-body-paragraph ma mb it mc b md mw kd mf mg mx kg mi mj my ml mm mn mz mp mq mr na mt mu mv im bi translated">我们将在文章中使用的模型是 VGG-19 和 ResNet-50。</p><h1 id="087d" class="li lj it bd lk ll lm ln lo lp lq lr ls ki lt kj lu kl lv km lw ko lx kp ly lz bi translated">VGG-19 模型</h1><p id="72a6" class="pw-post-body-paragraph ma mb it mc b md me kd mf mg mh kg mi mj mk ml mm mn mo mp mq mr ms mt mu mv im bi translated">VGG-19 模型是建立在 ImageNet 数据库上的 19 层(卷积和全连接)深度学习网络，其建立的目的是图像识别和分类。这个模型是由卡伦·西蒙扬和安德鲁·齐泽曼建立的，并在他们题为<a class="ae lh" href="https://arxiv.org/pdf/1409.1556.pdf" rel="noopener ugc nofollow" target="_blank"> <em class="nb">“用于大规模图像识别的非常深的卷积网络”</em> </a> <em class="nb">的论文中提到。我推荐所有感兴趣的读者去阅读这篇文章中的优秀文献。下图描述了 VGG-19 模型的架构。</em></p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi oj"><img src="../Images/2d4e285980559b379ae2ddeb0236e627.png" data-original-src="https://miro.medium.com/v2/resize:fit:1216/format:webp/0*wMgNnJpJHjDgLWb_.png"/></div></figure><h1 id="88f5" class="li lj it bd lk ll lm ln lo lp lq lr ls ki lt kj lu kl lv km lw ko lx kp ly lz bi translated">ResNet-50 型号</h1><p id="204f" class="pw-post-body-paragraph ma mb it mc b md me kd mf mg mh kg mi mj mk ml mm mn mo mp mq mr ms mt mu mv im bi translated">ResNet-50 模型是建立在 ImageNet 数据库上的 50 卷积块(每个块中有几层)深度学习网络。这个模型总共有超过 175 层，是一个非常深的网络。ResNet 代表剩余网络。下图显示了 ResNet-34 的典型架构。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi ok"><img src="../Images/ee1956c82bd889fded7fae43bc171bac.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*XKfCkMhillH_7FgpqQnvdQ.png"/></div></div></figure><p id="5454" class="pw-post-body-paragraph ma mb it mc b md mw kd mf mg mx kg mi mj my ml mm mn mz mp mq mr na mt mu mv im bi translated">总的来说，深度卷积神经网络导致了图像分类准确性的重大突破。然而，随着我们深入下去；神经网络的训练变得困难。其原因通常是因为消失梯度问题。基本上，当梯度反向传播到更浅的层(更接近输入)时，重复的张量运算使梯度变得非常小。因此，精度开始饱和，然后也下降。残差学习试图用残差块解决这些问题。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi ol"><img src="../Images/ee4aead6896b44771af5743d08950fdf.png" data-original-src="https://miro.medium.com/v2/resize:fit:664/format:webp/1*QBTeyaDNIjR6HmJBQ8gldw.png"/></div></figure><p id="cc55" class="pw-post-body-paragraph ma mb it mc b md mw kd mf mg mx kg mi mj my ml mm mn mz mp mq mr na mt mu mv im bi translated">利用跳过连接，我们可以允许网络学习身份函数(如上图所示)，这允许网络通过残差块传递输入，而不通过其他权重层。这有助于解决渐变消失的问题，也有助于保持对高级功能的关注，这些功能有时会因多级最大池而丢失。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi nc"><img src="../Images/ff131d562d8eceb24cf776178fa3956e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*uqAup0yF8ohawYvr.png"/></div><figcaption class="ld le gj gh gi lf lg bd b be z dk">Source: <a class="ae lh" rel="noopener" target="_blank" href="/understanding-and-coding-a-resnet-in-keras-446d7ff84d33">https://towardsdatascience.com/understanding-and-coding-a-resnet-in-keras-446d7ff84d33</a></figcaption></figure><p id="335a" class="pw-post-body-paragraph ma mb it mc b md mw kd mf mg mx kg mi mj my ml mm mn mz mp mq mr na mt mu mv im bi translated">我们将使用的 ResNet-50 模型包括 5 个阶段，每个阶段都有一个卷积和单位块。每个卷积块有 3 个卷积层，每个单位块也有 3 个卷积层。</p><h1 id="c34c" class="li lj it bd lk ll lm ln lo lp lq lr ls ki lt kj lu kl lv km lw ko lx kp ly lz bi translated">深度迁移学习与 VGG-19</h1><p id="b2b5" class="pw-post-body-paragraph ma mb it mc b md me kd mf mg mh kg mi mj mk ml mm mn mo mp mq mr ms mt mu mv im bi translated">这里的重点是采用预训练的 VGG-19 模型，然后对网络中的所有层进行部分和全部微调。我们将为下游分类任务在模型中添加常规密集和输出图层。</p><h2 id="3a3f" class="no lj it bd lk om on dn lo oo op dp ls mj oq or lu mn os ot lw mr ou ov ly iz bi translated">部分微调</h2><p id="f7d8" class="pw-post-body-paragraph ma mb it mc b md me kd mf mg mh kg mi mj mk ml mm mn mo mp mq mr ms mt mu mv im bi translated">我们将以 VGG-19 模型开始我们的模型训练，并对模型的最后两个模块进行微调。这里的第一项任务是构建模型架构，并指定我们想要微调的块/层。</p><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="ni nj l"/></div></figure><p id="f601" class="pw-post-body-paragraph ma mb it mc b md mw kd mf mg mx kg mi mj my ml mm mn mz mp mq mr na mt mu mv im bi translated">现在，我们将对模型进行 100 个纪元的训练。我在每个时期后保存模型，因为我有很多空间。除非你有很多存储空间，否则我不建议你这么做。你总是可以利用像<code class="fe nd ne nf ng b"><strong class="mc jd">ModelCheckpoint</strong></code> <strong class="mc jd"> </strong>这样的回调来集中存储最好的模型。</p><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="ni nj l"/></div></figure><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="ni nj l"/></div></figure><p id="4190" class="pw-post-body-paragraph ma mb it mc b md mw kd mf mg mx kg mi mj my ml mm mn mz mp mq mr na mt mu mv im bi translated">我们可以使用下面的代码片段来查看整个模型学习曲线。</p><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="ni nj l"/></div></figure><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi ow"><img src="../Images/91738d1f085f607ee23efc066bd4c33f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Req-0C3SSE23zTref6NKeQ.png"/></div></div></figure><p id="5d31" class="pw-post-body-paragraph ma mb it mc b md mw kd mf mg mx kg mi mj my ml mm mn mz mp mq mr na mt mu mv im bi translated">看起来不错，但随着时间的推移，验证数据集的损失和准确性肯定会有很大的波动。</p><h2 id="bd3e" class="no lj it bd lk om on dn lo oo op dp ls mj oq or lu mn os ot lw mr ou ov ly iz bi translated">完全微调</h2><p id="8eb4" class="pw-post-body-paragraph ma mb it mc b md me kd mf mg mh kg mi mj mk ml mm mn mo mp mq mr ms mt mu mv im bi translated">在我们的下一个培训流程中，我们将采用 VGG-19 模型，对所有模块进行微调，并添加我们自己的密集层和输出层。</p><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="ni nj l"/></div></figure><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="ni nj l"/></div></figure><p id="a3c7" class="pw-post-body-paragraph ma mb it mc b md mw kd mf mg mx kg mi mj my ml mm mn mz mp mq mr na mt mu mv im bi translated">下图描绘了培训过程的学习曲线。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi ox"><img src="../Images/ffd1ef51eb47c6500291c01dfc2b7fe7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*t3q1VBuO7gT0WB0G1hP0Fw.png"/></div></div></figure><p id="c100" class="pw-post-body-paragraph ma mb it mc b md mw kd mf mg mx kg mi mj my ml mm mn mz mp mq mr na mt mu mv im bi translated">就验证准确性和损失而言，随着时期的增加，看起来更加稳定。</p><h1 id="be70" class="li lj it bd lk ll lm ln lo lp lq lr ls ki lt kj lu kl lv km lw ko lx kp ly lz bi translated">用 ResNet-50 进行深度迁移学习</h1><p id="31d3" class="pw-post-body-paragraph ma mb it mc b md me kd mf mg mh kg mi mj mk ml mm mn mo mp mq mr ms mt mu mv im bi translated">本节的重点将是采用预训练的 ResNet-50 模型，然后对网络中的所有层进行完整的微调。我们将照常添加常规密集图层和输出图层。</p><h2 id="df26" class="no lj it bd lk om on dn lo oo op dp ls mj oq or lu mn os ot lw mr ou ov ly iz bi translated">完全微调</h2><p id="38d3" class="pw-post-body-paragraph ma mb it mc b md me kd mf mg mh kg mi mj mk ml mm mn mo mp mq mr ms mt mu mv im bi translated">对于我们的训练过程，我们将加载预训练的 ResNet-50 模型，并对整个网络进行 500 个时期的微调。让我们从构建模型架构开始。</p><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="ni nj l"/></div></figure><p id="5ff5" class="pw-post-body-paragraph ma mb it mc b md mw kd mf mg mx kg mi mj my ml mm mn mz mp mq mr na mt mu mv im bi translated">现在让我们训练总共 500 个时期的模型。</p><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="ni nj l"/></div></figure><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="ni nj l"/></div></figure><p id="09b9" class="pw-post-body-paragraph ma mb it mc b md mw kd mf mg mx kg mi mj my ml mm mn mz mp mq mr na mt mu mv im bi translated">下图显示了我们训练模型的学习曲线。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi oy"><img src="../Images/8a8a32caa5035963f3f79928fa270221.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*dV_A1cz-Km6snJuaSQbtLA.png"/></div></div></figure><h1 id="d2a2" class="li lj it bd lk ll lm ln lo lp lq lr ls ki lt kj lu kl lv km lw ko lx kp ly lz bi translated">根据测试数据评估模型性能</h1><p id="88a7" class="pw-post-body-paragraph ma mb it mc b md me kd mf mg mh kg mi mj mk ml mm mn mo mp mq mr ms mt mu mv im bi translated">现在是检验我们训练好的模型的时候了。为此，我们将对测试数据集进行预测，并基于多类分类问题的相关分类度量来评估模型性能。</p><h2 id="ec06" class="no lj it bd lk om on dn lo oo op dp ls mj oq or lu mn os ot lw mr ou ov ly iz bi translated">负载测试数据集</h2><p id="7fc9" class="pw-post-body-paragraph ma mb it mc b md me kd mf mg mh kg mi mj mk ml mm mn mo mp mq mr ms mt mu mv im bi translated">我们首先利用之前构建的数据生成器加载测试数据集和标签。</p><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="ni nj l"/></div></figure><pre class="ks kt ku kv gt nk ng nl nm aw nn bi"><span id="6777" class="no lj it ng b gy np nq l nr ns"><strong class="ng jd">Found 700 images belonging to 7 classes.</strong></span><span id="8b82" class="no lj it ng b gy oz nq l nr ns"><strong class="ng jd">((700, 192, 192, 3), (700,))</strong></span></pre><h2 id="e480" class="no lj it bd lk om on dn lo oo op dp ls mj oq or lu mn os ot lw mr ou ov ly iz bi translated">建立模型性能评估函数</h2><p id="6b90" class="pw-post-body-paragraph ma mb it mc b md me kd mf mg mh kg mi mj mk ml mm mn mo mp mq mr ms mt mu mv im bi translated">我们现在将构建一个基本的分类模型性能评估函数，我们将使用它来测试三个模型的性能。</p><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="ni nj l"/></div></figure><p id="8059" class="pw-post-body-paragraph ma mb it mc b md mw kd mf mg mx kg mi mj my ml mm mn mz mp mq mr na mt mu mv im bi translated">我们现在准备在测试数据集上测试我们的模型的性能</p><h2 id="9b49" class="no lj it bd lk om on dn lo oo op dp ls mj oq or lu mn os ot lw mr ou ov ly iz bi translated">模型 1 —部分微调的 VGG-19</h2><p id="7346" class="pw-post-body-paragraph ma mb it mc b md me kd mf mg mh kg mi mj mk ml mm mn mo mp mq mr ms mt mu mv im bi translated">这里，我们在测试数据集上评估了部分微调的 VGG-19 模型的性能。</p><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="ni nj l"/></div></figure><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi pa"><img src="../Images/7600a5f3f79d2c69b8ec99669f8d75e9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*7UpPP6OpYyWOEusSQK2aDw.png"/></div></div></figure><p id="38ae" class="pw-post-body-paragraph ma mb it mc b md mw kd mf mg mx kg mi mj my ml mm mn mz mp mq mr na mt mu mv im bi translated">在测试数据集上，总体准确率为 86%<strong class="mc jd">,相当不错！</strong></p><h2 id="f28a" class="no lj it bd lk om on dn lo oo op dp ls mj oq or lu mn os ot lw mr ou ov ly iz bi translated">模型 2 —完全微调的 VGG-19</h2><p id="e02a" class="pw-post-body-paragraph ma mb it mc b md me kd mf mg mh kg mi mj mk ml mm mn mo mp mq mr ms mt mu mv im bi translated">这里，我们在测试数据集上评估了我们完全微调的 VGG-19 模型的性能。</p><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="ni nj l"/></div></figure><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi pb"><img src="../Images/645e7c9b32917c8a65153be98919cc33.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*jQKdp1U_bRXE1ZvGY0vqOg.png"/></div></div></figure><p id="40f9" class="pw-post-body-paragraph ma mb it mc b md mw kd mf mg mx kg mi mj my ml mm mn mz mp mq mr na mt mu mv im bi translated">测试数据集上的总体准确度得分为 85% ,略低于部分微调的模型。</p><h2 id="aff7" class="no lj it bd lk om on dn lo oo op dp ls mj oq or lu mn os ot lw mr ou ov ly iz bi translated">型号 3 —完全微调的 ResNet-50</h2><p id="4168" class="pw-post-body-paragraph ma mb it mc b md me kd mf mg mh kg mi mj mk ml mm mn mo mp mq mr ms mt mu mv im bi translated">这里，我们在测试数据集上评估了完全微调的 ResNet-50 模型的性能。</p><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="ni nj l"/></div></figure><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi pc"><img src="../Images/00990a87482e8dbb0a9c6d11211fd60d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*08zlKkhRGqz8IU4WIV26uw.png"/></div></div></figure><p id="05ff" class="pw-post-body-paragraph ma mb it mc b md mw kd mf mg mx kg mi mj my ml mm mn mz mp mq mr na mt mu mv im bi translated">我们得到的总体准确度分数为<strong class="mc jd"> 88% </strong>，这绝对是测试数据集上迄今为止最好的模型性能！看起来 ResNet-50 模型表现最好，因为我们确实训练了它 500 个纪元。</p><h2 id="9ca6" class="no lj it bd lk om on dn lo oo op dp ls mj oq or lu mn os ot lw mr ou ov ly iz bi translated">样本测试数据的最佳模型预测</h2><p id="ad44" class="pw-post-body-paragraph ma mb it mc b md me kd mf mg mh kg mi mj mk ml mm mn mo mp mq mr ms mt mu mv im bi translated">我们现在可以用我们最好的模型来预测样本无线电信号频谱图。</p><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="ni nj l"/></div></figure><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi pd"><img src="../Images/c9787c92d63e24d88245e1b57497fd8e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*iYGr8gMYrXJj9kwwZygUtA.png"/></div></div></figure><h1 id="f6d9" class="li lj it bd lk ll lm ln lo lp lq lr ls ki lt kj lu kl lv km lw ko lx kp ly lz bi translated">结论</h1><p id="75a3" class="pw-post-body-paragraph ma mb it mc b md me kd mf mg mh kg mi mj mk ml mm mn mo mp mq mr ms mt mu mv im bi translated">这将我们带到我们关于利用深度学习进一步搜索外星智能的两部分系列的结尾。您看到了我们如何将无线电信号数据转换为频谱图，然后利用迁移学习的能力来构建分类器，这些分类器表现非常好，即使每类的训练数据样本数量非常少。</p></div><div class="ab cl pe pf hx pg" role="separator"><span class="ph bw bk pi pj pk"/><span class="ph bw bk pi pj pk"/><span class="ph bw bk pi pj"/></div><div class="im in io ip iq"><p id="7492" class="pw-post-body-paragraph ma mb it mc b md mw kd mf mg mx kg mi mj my ml mm mn mz mp mq mr na mt mu mv im bi translated">本文使用的代码可以在<a class="ae lh" href="https://github.com/dipanjanS" rel="noopener ugc nofollow" target="_blank"> <strong class="mc jd"> my GitHub </strong> </a> <strong class="mc jd"> </strong>的这个<a class="ae lh" href="https://github.com/dipanjanS/data_science_for_all" rel="noopener ugc nofollow" target="_blank"> <strong class="mc jd">资源库</strong> </a>中获得。</p></div></div>    
</body>
</html>