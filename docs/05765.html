<html>
<head>
<title>The Data Processing Error in a Prominent Fair Machine Learning Dataset (short version)</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">一个显著的公平机器学习数据集(短版本)中的数据处理错误</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/the-data-processing-error-in-the-most-prominent-fair-machine-learning-dataset-short-version-d27d8d390fea?source=collection_archive---------29-----------------------#2019-08-22">https://towardsdatascience.com/the-data-processing-error-in-the-most-prominent-fair-machine-learning-dataset-short-version-d27d8d390fea?source=collection_archive---------29-----------------------#2019-08-22</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="2807" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">ProPublica 的 COMPAS 评分和累犯数据</h2></div><p id="48f4" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi le translated"><span class="l lf lg lh bm li lj lk ll lm di">在</span>最近的一次研究<a class="ae ln" href="https://arxiv.org/abs/1906.04711" rel="noopener ugc nofollow" target="_blank"> <strong class="kk iu">论文</strong> </a> <strong class="kk iu"> </strong>和博客<a class="ae ln" rel="noopener" target="_blank" href="/the-data-processing-error-in-one-of-the-most-prominent-fair-machine-learning-datasets-4fa205daa3c4"> <strong class="kk iu">帖子</strong> </a>中，我重新审视了<strong class="kk iu"> COMPAS 累犯风险评分</strong>和<strong class="kk iu">犯罪史</strong>数据由<strong class="kk iu"> ProPublica </strong>为其开创性的<strong class="kk iu"> 2016 </strong> <a class="ae ln" href="https://www.propublica.org/article/machine-bias-risk-assessments-in-criminal-sentencing" rel="noopener ugc nofollow" target="_blank"> <strong class="kk iu">文章</strong> </a> <strong class="kk iu"> </strong>关于算法公平性</p><p id="08db" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我<em class="lo">发现<strong class="kk iu"> ProPublica </strong>在构建<em class="lo">键</em> <strong class="kk iu">子</strong>-用于文章分析的数据集时，出现了<strong class="kk iu">数据处理错误</strong>。我发现的数据错误<strong class="kk iu"> </strong>会对这些关键子数据集的几个更基本的方面产生相当大的影响<em class="lo"/>，例如样本大小、累犯数量和累犯率。我估计累犯率是<em class="lo">向上偏</em>差不多<strong class="kk iu"> 25% </strong>。</em></p><p id="92d0" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">尽管如此，有趣的是，我发现的非平凡数据处理错误对 ProPublica 使用相同子数据集报告的最引人注目的结果几乎没有影响。即非裔美国人相对于白种人的假阳性率和假阴性率。</p><p id="4893" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi le translated"><span class="l lf lg lh bm li lj lk ll lm di"> C </span></p><p id="8627" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">基于其分析，专注于一组预测指标，ProPublica 得出结论，COMPAS 累犯风险评分<strong class="kk iu">偏向</strong>不利于<em class="lo">非裔美国人</em>。开发 COMPAS 风险评分系统的公司<strong class="kk iu"> Northpointe Inc. </strong>，使用相同的数据，但侧重于一组不同的预测指标，<a class="ae ln" href="http://go.volarisgroup.com/rs/430-MBX-989/images/ProPublica_Commentary_Final_070616.pdf" rel="noopener ugc nofollow" target="_blank"> <em class="lo">为</em> </a> <em class="lo"> </em>风险评分辩护为<strong class="kk iu">无偏</strong>。</p><p id="aa2c" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">由于主题和结果的争议性，以及数据的公开可用性，ProPublica 调查性新闻的开创性工作在公平机器学习或算法公平 T21 这一新兴领域引发了激烈的辩论和研究。</p><p id="b264" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">ProPublica 的 COMPAS 分数和累犯数据可能已经成为研究人员用来测试新的或现有的算法公平性定义和程序的最重要的基准数据。(参见<a class="ae ln" href="http://arxiv.org/abs/1808.00023" rel="noopener ugc nofollow" target="_blank"> Corbett-Davies 和 Goel 2018 </a>以及我在下面列出的其他参考资料；或者是<a class="ae ln" rel="noopener" target="_blank" href="/a-tutorial-on-fairness-in-machine-learning-3ff8ba1040cb"> <strong class="kk iu">中的一篇</strong> </a> <strong class="kk iu"> </strong>中的几篇<strong class="kk iu">博文)</strong></p></div><div class="ab cl lp lq hx lr" role="separator"><span class="ls bw bk lt lu lv"/><span class="ls bw bk lt lu lv"/><span class="ls bw bk lt lu"/></div><div class="im in io ip iq"><p id="a7bf" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi le translated"><span class="l lf lg lh bm li lj lk ll lm di">当 ProPublica 的 COMPAS 数据被越来越多的研究使用时，研究人员通常会按原样采用 ProPublica 创建的数据集，并且<em class="lo">似乎没有</em>仔细检查过它们的数据处理问题。我没有测试一个新的公平定义或程序，而是仔细观察了 ProPublica 收集的真实数据集</span></p><p id="19c1" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">特别是，我检查了<strong class="kk iu">子</strong>——数据集 ProPublica 建立来研究一个<em class="lo">两年内</em> <strong class="kk iu"> <em class="lo"> </em> </strong> <em class="lo">窗口</em>中一个被告最初被捕后的再犯数据。这样做，我发现 ProPublica 在构造这些<strong class="kk iu">两年累犯数据集</strong>时，犯了一个<strong class="kk iu"> </strong>实质性的<strong class="kk iu">数据处理错误</strong>。</p><blockquote class="lw lx ly"><p id="a8a5" class="ki kj lo kk b kl km ju kn ko kp jx kq lz ks kt ku ma kw kx ky mb la lb lc ld im bi translated">如下图所示，<strong class="kk iu"> ProPublica 未能</strong>对<strong class="kk iu">惯犯</strong>实施<strong class="kk iu">两年窗口样本截止</strong>(然而<strong class="kk iu">对<strong class="kk iu">非</strong>惯犯实施了这样的样本截止)</strong></p></blockquote><p id="5bb5" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">因此，ProPublica 错误地在两年的数据集中保留了<strong class="kk iu">累犯</strong>的<strong class="kk iu">不成比例的</strong>份额<strong class="kk iu"> </strong>。我估计这个<strong class="kk iu">将</strong>的<strong class="kk iu">两年</strong>一般<strong class="kk iu">累犯</strong>率<strong class="kk iu">向上</strong>大约<strong class="kk iu">九个</strong>百分点，将其从<strong class="kk iu"> 36% </strong>推至<strong class="kk iu"> 45% </strong>。</p><p id="3dc0" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">因此，ProPublica 计算的两年再犯率比正确处理<em class="lo">的同一数据中的<em class="lo">真实的</em>两年再犯率高约<strong class="kk iu">25%</strong><strong class="kk iu"/></em>。</p><p id="8d74" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在我的研究论文中，我还探讨了这种数据处理错误如何影响其他统计数据。具体来说，我看了 ProPublica 的<strong class="kk iu">混淆矩阵</strong>对高/低 COMPAS 分数与两年累犯状态的分析。我发现有偏差的两年期数据集对<strong class="kk iu">阳性预测值</strong>(或<strong class="kk iu"> <em class="lo">精度</em> </strong>)和<strong class="kk iu">阴性预测值</strong>也有<em class="lo">实质性的</em>影响。</p><p id="8bac" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="kk iu">另一方面</strong>，有偏差的两年期数据集对<em class="lo">混淆矩阵</em>分析中的其他几个关键统计数据的影响相对<em class="lo">较小</em>，这些统计数据对<em class="lo">累犯与非累犯相对比例的变化不太敏感</em>。特别是<strong class="kk iu">准确率</strong>、<strong class="kk iu">假阳性率</strong>和<strong class="kk iu">假阴性率</strong>。</p><p id="e70f" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">ProPublica 的关键发现是<strong class="kk iu"> <em class="lo">的假阳性率高于</em></strong><strong class="kk iu"><em class="lo">假阴性率低于<strong class="kk iu"><em class="lo"/></strong><em class="lo">的非裔美国人</em>比<em class="lo">的白种人</em>高，因此，当一个人正确处理数据时<strong class="kk iu">不会改变</strong>。</em></strong></p><p id="f159" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">据我所知，这是第一次强调上述数据处理错误。<strong class="kk iu">在这篇博文中，我总结了我的研究</strong> <a class="ae ln" href="https://arxiv.org/abs/1906.04711" rel="noopener ugc nofollow" target="_blank"> <strong class="kk iu">论文</strong> </a>。</p><p id="6926" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">(如果你想了解更多信息，但不是全文的研究论文，请看我以前的<strong class="kk iu">长</strong> <a class="ae ln" rel="noopener" target="_blank" href="/the-data-processing-error-in-one-of-the-most-prominent-fair-machine-learning-datasets-4fa205daa3c4"> <strong class="kk iu">版本</strong> </a> <strong class="kk iu"> <em class="lo"> </em> </strong>的这篇博文。我还用我写的 R 程序创建了一个<strong class="kk iu"> GitHub </strong> <a class="ae ln" href="https://github.com/mbarenstein/ProPublica_COMPAS_Data_Revisited" rel="noopener ugc nofollow" target="_blank"> <strong class="kk iu">资源库</strong> </a> <strong class="kk iu"> </strong>来分析数据)</p></div><div class="ab cl lp lq hx lr" role="separator"><span class="ls bw bk lt lu lv"/><span class="ls bw bk lt lu lv"/><span class="ls bw bk lt lu"/></div><div class="im in io ip iq"><p id="a631" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi le translated"><span class="l lf lg lh bm li lj lk ll lm di">在 2016 年的</span> <strong class="kk iu">中，ProPublica 的一组记者获得了一个数据集，该数据集包含超过<strong class="kk iu">一万一千名</strong> <em class="lo">来自佛罗里达州<strong class="kk iu">布劳沃德县</strong>的审前</em>被告，这些被告在 2013 年<strong class="kk iu">1 月 1 日</strong>和 2014 年<strong class="kk iu">12 月 31 日</strong>之间被逮捕并<em class="lo">用 COMPAS 筛选系统评估</em>。</strong></p><p id="08ec" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">ProPublica 随后收集了截至 2016 年 3 月底<strong class="kk iu"/>的<em class="lo">未来</em>逮捕数据，以研究 COMPAS 风险评分对这些被告累犯的预测程度(并于 2016 年 5 月发表了文章)。(<strong class="kk iu"> ProPublica 的</strong> <strong class="kk iu">数据</strong>和<strong class="kk iu">分析</strong>在这里<a class="ae ln" href="https://www.propublica.org/article/how-we-analyzed-the-compas-recidivism-algorithm" rel="noopener ugc nofollow" target="_blank"> <strong class="kk iu">描述</strong> </a>)</p><p id="2a0b" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">从这些数据中，ProPublica 创建了两个数据集，专门用于研究在最初犯罪和对比筛选日期的两年内的累犯。我特别检查了为研究<em class="lo">一般</em>累犯的可能性而构建的两年累犯子数据集 ProPublica。(一般累犯包括暴力和非暴力犯罪)</p><p id="ab12" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">为了构建两年的累犯数据集，ProPublica 可能希望在 2016 年 3 月下旬收集犯罪记录数据的时间窗结束时，让人们<em class="lo">观察</em>至少两年。</p><p id="9746" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">因此，我们不应该期望在 2014 年 4 月 1 日<strong class="kk iu"/>之后<em class="lo">的两年数据集中看到<em class="lo">任何</em>被告。(也就是说，在 ProPublica 收集的犯罪记录数据结束日期之前的两年内，人们观察到的<em class="lo">少于</em>)。</em></p><p id="c22d" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">为了验证这一点，<strong class="kk iu">我通过分析被告在<strong class="kk iu"> COMPAS 筛选日期</strong>的<strong class="kk iu">分布</strong>来可视化</strong>两年<em class="lo">普通</em>累犯数据集(筛选通常在逮捕当天或一天后进行)。这样做的时候，我发现 ProPublica 在创建这个数据集的时候犯了一个实质性的数据处理错误。</p><blockquote class="mc"><p id="4df9" class="md me it bd mf mg mh mi mj mk ml ld dk translated">ProPublica 未能对累犯实施为期两年的窗口样本截断(但它确实对非累犯实施了这样的样本截断)</p></blockquote><p id="8393" class="pw-post-body-paragraph ki kj it kk b kl mm ju kn ko mn jx kq kr mo kt ku kv mp kx ky kz mq lb lc ld im bi translated"><em class="lo">(在之前的一篇</em> <strong class="kk iu"> <em class="lo">长</em> </strong> <a class="ae ln" rel="noopener" target="_blank" href="/the-data-processing-error-in-one-of-the-most-prominent-fair-machine-learning-datasets-4fa205daa3c4"> <strong class="kk iu"> <em class="lo">版本</em> </strong> </a> <em class="lo">的这篇博文中，我解释了可能导致 ProPublica 这样误入歧途的推理)</em></p><p id="6b17" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我在下图中展示了这个数据处理错误(我的研究论文中的关键图)。在这个图中，我做了一个<em class="lo">直方图</em>，显示了按 COMPAS 筛选日期(通常在逮捕当天或之后一天执行)划分的案件或逮捕数量。为了清楚地看到数据处理错误，我做了<em class="lo">分离</em>比较累犯和非累犯的屏幕日期直方图。</p><p id="b47f" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">对于这些直方图，我使用<strong class="kk iu"> 7 天</strong>(即一周)<strong class="kk iu"> </strong>数据<strong class="kk iu">箱</strong>。作为参考，我在<strong class="kk iu">2014 年 4 月 1 日</strong>画一条红色竖线，这是 ProPublica 的犯罪记录数据收集窗口(2016 年 3 月下旬)结束前的两年标记<em class="lo">。</em></p><figure class="ms mt mu mv gt mw gh gi paragraph-image"><div class="gh gi mr"><img src="../Images/70fa0d10facb57f7eb5e8cd2ca232936.png" data-original-src="https://miro.medium.com/v2/resize:fit:1344/format:webp/1*mTcCSUS8MFC6HMASHLmHsQ.png"/></div><figcaption class="mz na gj gh gi nb nc bd b be z dk">Source: <a class="ae ln" href="https://arxiv.org/abs/1906.04711" rel="noopener ugc nofollow" target="_blank">Barenstein, 2019.</a> (Figure 4)</figcaption></figure><p id="e2fd" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><em class="lo">【注:该图还显示了一个</em><strong class="kk iu"><em class="lo"/></strong><em class="lo">，但非常明显，</em> <strong class="kk iu"> <em class="lo">在 2013 年年中的 COMPAS 放映(或案件)中</em> </strong> <em class="lo">下降(对累犯和非累犯一视同仁)。这是一个</em> <strong class="kk iu"> <em class="lo">单独的问题</em> </strong> <em class="lo">，但是，它似乎存在于 ProPublica 从佛罗里达州布劳沃德县收到的</em> <strong class="kk iu"> <em class="lo">原始</em> </strong> <em class="lo">数据集。所以这个</em> <strong class="kk iu"> <em class="lo">不是</em> </strong> <em class="lo">看起来是 ProPublica 的数据处理错误，而</em> <strong class="kk iu"> <em class="lo">我不</em> </strong> <em class="lo">解决这个问题】</em></p><p id="7fed" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi le translated"><span class="l lf lg lh bm li lj lk ll lm di"> T </span>上面描述的<em class="lo">关于累犯的数据处理错误导致</em>到<strong class="kk iu">两年数据集中虚高的</strong>累犯率。这是由于 2014 年 4 月 1 日之后的所有<em class="lo">额外</em>累犯。ProPublica 应该从两年的数据集中剔除这些额外的累犯，但它没有这么做。(在我的长文博文和论文中，我计算出这些额外的累犯构成了 ProPublica 两年<em class="lo">普通</em>累犯数据集中总累犯的大约 30 %)</p><p id="1a6f" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">于是，在 ProPublica 创建的两年<em class="lo">普通</em>累犯数据集里，<strong class="kk iu">两年累犯率</strong>为<strong class="kk iu"> 45% </strong>。但是，当我<em class="lo">去掉</em>多余的<em class="lo">累犯</em>时，我反而估计两年累犯率只有<em class="lo"> </em> <strong class="kk iu"> 36% </strong>。因此，在 ProPublica 的数据集中，两年的累犯率是<strong class="kk iu">向上</strong>偏移大约<strong class="kk iu">九个</strong>百分点或者<strong class="kk iu"> 25% </strong>。</p><p id="fb3a" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在我的研究论文中，我还探讨了这种数据处理错误如何影响其他统计数据。具体我看 ProPublica 的<strong class="kk iu">混淆矩阵</strong>(或<em class="lo">真值表</em>)对 COMPAS 评分 vs 两年累犯状态的分析。为了进行这样的分析，ProPublica 将 COMPAS 分数转化为一个二元分类器，即低分数和高分数。(在我的论文中，我也是这样做的)</p><p id="9510" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">除了累犯患病率(即累犯率)，ProPublica 使用的<em class="lo">偏倚</em>两年期数据集也影响阳性预测值(<strong class="kk iu"> PPV </strong>)(或<strong class="kk iu"> <em class="lo">精度</em> </strong>)和阴性预测值(<strong class="kk iu"> NPV </strong>)。如果 ProPublica<em class="lo">正确地</em>处理了两年的数据，结果是累犯的发生率更低，毫不奇怪，PPV 会更低，NPV 会更高。</p><p id="56ce" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="kk iu">另一方面</strong>，有偏差的两年期数据集对<em class="lo">混淆矩阵</em>分析中的其他几个关键统计数据的<em class="lo">影响相对较小</em>，这些统计数据对<em class="lo">累犯与非累犯相对比例的变化不太敏感</em>。特别是<em class="lo">准确率</em>、<em class="lo">假阳性率</em> <strong class="kk iu"> </strong> ( <strong class="kk iu"> FPR </strong>)、<em class="lo">假阴性率</em> <strong class="kk iu"> </strong> ( <strong class="kk iu"> FNR </strong>)。或者一个减去这些比率，即<strong class="kk iu">特异性</strong>和<strong class="kk iu">敏感性</strong>。(我在这篇博文的<strong class="kk iu">长</strong> <a class="ae ln" rel="noopener" target="_blank" href="/the-data-processing-error-in-one-of-the-most-prominent-fair-machine-learning-datasets-4fa205daa3c4"> <strong class="kk iu">版本</strong> </a>和我的研究论文中解释了为什么会这样)</p><p id="d23e" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">ProPublica 发现<em class="lo">非裔美国人</em>比<em class="lo">白种人</em>假阳性率高假阳性率<strong class="kk iu"> <em class="lo">假阴性率</em><em class="lo"/></strong>低，这是最受关注的关键发现。因此，当正确处理数据<em class="lo">时<strong class="kk iu">不会改变</strong>。</em></p></div><div class="ab cl lp lq hx lr" role="separator"><span class="ls bw bk lt lu lv"/><span class="ls bw bk lt lu lv"/><span class="ls bw bk lt lu"/></div><div class="im in io ip iq"><p id="86a8" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi le translated"><span class="l lf lg lh bm li lj lk ll lm di"> U </span>最后，我这里认定的数据处理错误的实际重要性可能是<em class="lo">有限的</em>。例如，我并不是说 Northpointe 在开发 COMPAS 累犯风险评分时犯了一个错误(尽管用于此的数据和实际模型是专有的，并不公开)。</p><p id="2b7f" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">此外，大多数<em class="lo">公平的</em>机器学习研究似乎以 FPR、FNR 或准确性为目标，这些不受数据处理误差的影响。</p><p id="c0d8" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">最后，请注意，许多潜在的测量问题可能会影响 ProPublica COMPAS 数据中估计的两年累犯率(正如我在论文中提到的)。其中一些可能会对估计值施加向下的压力，也许会在某种程度上抵消我在这里提到的向上的偏差。</p><p id="376a" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">然而，这最后一点并没有使我所指出的数据处理问题的重点和我所呼吁的随后的数据修正无效。我的重点是<em class="lo">内部</em>数据处理的有效性。我并不是说经过这种修正后，数据将不会有任何遗留问题，也不一定会有<em class="lo">外部</em>有效性，这超出了我的分析范围。</p><p id="927d" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在任何情况下，似乎没有人像我上面所做的那样，预先设想过<em class="lo">两年</em>累犯数据集的 COMPAS 筛选日期。(如果他们有，也没有被广泛传播)因此，我在这里指出的数据处理错误一般会持续和传播三年以上。</p><p id="eba2" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我的博客文章和研究论文试图将焦点放回到<em class="lo"> </em>数据<em class="lo">处理</em>阶段，并强调其中的潜在隐患。</p><h1 id="83b7" class="nd ne it bd nf ng nh ni nj nk nl nm nn jz no ka np kc nq kd nr kf ns kg nt nu bi translated">脚注</h1><ol class=""><li id="c6e7" class="nv nw it kk b kl nx ko ny kr nz kv oa kz ob ld oc od oe of bi translated">最近，研究人员指出了<em class="lo">分类奇偶校验</em>的算法公平性目标的一些潜在缺陷，该目标试图在人口亚组之间使分类误差的度量相等，如 FPR 或 FNR(<a class="ae ln" href="http://arxiv.org/abs/1808.00023" rel="noopener ugc nofollow" target="_blank">Corbett-Davies 和 Goel 2018 </a>)。其他工作表明，几种流行的算法公平目标是不相容的，不可能同时实现<em class="lo"/>(例如<a class="ae ln" href="https://arxiv.org/abs/1610.07524" rel="noopener ugc nofollow" target="_blank"> Chouldechova 2016 </a>和<a class="ae ln" href="https://www.aeaweb.org/articles?id=10.1257/pandp.20181018" rel="noopener ugc nofollow" target="_blank"> Kleinberg 等人 2018 </a>)。</li><li id="90fc" class="nv nw it kk b kl og ko oh kr oi kv oj kz ok ld oc od oe of bi translated">在我的博客文章和论文中，我研究了 ProPublica 两年的一般累犯数据集。当我关注这个数据集时，ProPublica 也<em class="lo">T21<em class="lo">创建的两年期<strong class="kk iu">暴力</strong>累犯数据集</em>也遭遇了我在这里指出的同样的数据处理问题。</em></li></ol></div><div class="ab cl lp lq hx lr" role="separator"><span class="ls bw bk lt lu lv"/><span class="ls bw bk lt lu lv"/><span class="ls bw bk lt lu"/></div><div class="im in io ip iq"><p id="bdaf" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">这篇博文是我<strong class="kk iu">上一篇</strong>走向数据科学<a class="ae ln" rel="noopener" target="_blank" href="/the-data-processing-error-in-one-of-the-most-prominent-fair-machine-learning-datasets-4fa205daa3c4"> <strong class="kk iu">帖子</strong> </a>的<em class="lo">短</em>版。我的一篇<em class="lo">长篇</em>版本的论文是<a class="ae ln" href="https://arxiv.org/abs/1906.04711" rel="noopener ugc nofollow" target="_blank"> <strong class="kk iu">可在<strong class="kk iu"> arXiv </strong>上</strong> </a> <strong class="kk iu"> </strong>。(我还用我写的 R 程序创建了一个<strong class="kk iu"> GitHub </strong> <a class="ae ln" href="https://github.com/mbarenstein/ProPublica_COMPAS_Data_Revisited" rel="noopener ugc nofollow" target="_blank"> <strong class="kk iu">资源库</strong> </a> <strong class="kk iu"> </strong>)</p><p id="cb3d" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我是美国联邦贸易委员会的经济学家。这项研究与我在联邦贸易委员会的工作无关。<strong class="kk iu">本文仅代表作者个人观点。他们不一定代表美国联邦贸易委员会或其任何专员的意见。</strong></p></div></div>    
</body>
</html>