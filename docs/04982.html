<html>
<head>
<title>Weekly Selection — July 26, 2019</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">每周精选—2019 年 7 月 26 日</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/weekly-selection-july-26-2019-9dde074025b?source=collection_archive---------28-----------------------#2019-07-26">https://towardsdatascience.com/weekly-selection-july-26-2019-9dde074025b?source=collection_archive---------28-----------------------#2019-07-26</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><figure class="gl gn jo jp jq jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi jn"><img src="../Images/cdaf6760b50959aa95cc3689b6fc810c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*LDL373oV7EW72QakK_I2Lg.jpeg"/></div></div></figure><h2 id="6294" class="jy jz iq bd ka kb kc dn kd ke kf dp kg kh ki kj kk kl km kn ko kp kq kr ks kt bi translated"><a class="ae ku" rel="noopener" target="_blank" href="/5-key-principles-of-software-architecture-e5379cb10fd5">软件架构的 5 个关键原则</a></h2><p id="a5bd" class="pw-post-body-paragraph kv kw iq kx b ky kz la lb lc ld le lf kh lg lh li kl lj lk ll kp lm ln lo lp ij bi translated">由<a class="lq lr ep" href="https://medium.com/u/aabf98f9b9a?source=post_page-----9dde074025b--------------------------------" rel="noopener" target="_blank"> Semi Koen </a> — 7 分钟读取</p><p id="bf4b" class="pw-post-body-paragraph kv kw iq kx b ky ls la lb lc lt le lf kh lu lh li kl lv lk ll kp lw ln lo lp ij bi translated">有哪些伟大的软件架构师藏在他们的腰带下面</p></div><div class="ab cl lx ly hu lz" role="separator"><span class="ma bw bk mb mc md"/><span class="ma bw bk mb mc md"/><span class="ma bw bk mb mc"/></div><div class="ij ik il im in"><h2 id="35bd" class="jy jz iq bd ka kb kc dn kd ke kf dp kg kh ki kj kk kl km kn ko kp kq kr ks kt bi translated"><a class="ae ku" rel="noopener" target="_blank" href="/9-tips-for-training-lightning-fast-neural-networks-in-pytorch-8e63a502f565">在 Pytorch 中训练快如闪电的神经网络的 9 个技巧</a></h2><p id="03e3" class="pw-post-body-paragraph kv kw iq kx b ky kz la lb lc ld le lf kh lg lh li kl lj lk ll kp lm ln lo lp ij bi translated">由<a class="lq lr ep" href="https://medium.com/u/8536ebfbc90b?source=post_page-----9dde074025b--------------------------------" rel="noopener" target="_blank">威廉·法尔肯</a> — 11 分钟读完</p><p id="594c" class="pw-post-body-paragraph kv kw iq kx b ky ls la lb lc lt le lf kh lu lh li kl lv lk ll kp lw ln lo lp ij bi translated">面对现实吧，你的模型很可能还停留在石器时代。我敢打赌，你仍然在使用 32 位精度或* <em class="me"> GASP* </em>甚至可能在单个 GPU 上只训练<strong class="kx ir"/>。</p></div><div class="ab cl lx ly hu lz" role="separator"><span class="ma bw bk mb mc md"/><span class="ma bw bk mb mc md"/><span class="ma bw bk mb mc"/></div><div class="ij ik il im in"><h2 id="4f79" class="jy jz iq bd ka kb kc dn kd ke kf dp kg kh ki kj kk kl km kn ko kp kq kr ks kt bi translated"><a class="ae ku" rel="noopener" target="_blank" href="/the-5-sampling-algorithms-every-data-scientist-need-to-know-43c7bc11d17c">每个数据科学家都需要知道的 5 种采样算法</a></h2><p id="e00e" class="pw-post-body-paragraph kv kw iq kx b ky kz la lb lc ld le lf kh lg lh li kl lj lk ll kp lm ln lo lp ij bi translated">由拉胡尔·阿加瓦尔 — 5 分钟读完</p><p id="fa75" class="pw-post-body-paragraph kv kw iq kx b ky ls la lb lc lt le lf kh lu lh li kl lv lk ll kp lw ln lo lp ij bi translated">我每天都在努力学习许多算法，所以我想列出一些最常见和最常用的算法，这些算法将在新的 DS 算法系列中使用。</p></div><div class="ab cl lx ly hu lz" role="separator"><span class="ma bw bk mb mc md"/><span class="ma bw bk mb mc md"/><span class="ma bw bk mb mc"/></div><div class="ij ik il im in"><h2 id="8a5a" class="jy jz iq bd ka kb kc dn kd ke kf dp kg kh ki kj kk kl km kn ko kp kq kr ks kt bi translated"><a class="ae ku" rel="noopener" target="_blank" href="/predicting-vs-explaining-69b516f90796">预测 vs .解释</a></h2><p id="d24c" class="pw-post-body-paragraph kv kw iq kx b ky kz la lb lc ld le lf kh lg lh li kl lj lk ll kp lm ln lo lp ij bi translated">由<a class="lq lr ep" href="https://medium.com/u/7a83326316c0?source=post_page-----9dde074025b--------------------------------" rel="noopener" target="_blank">黄家仪</a> — 13 分钟读完</p><p id="0f06" class="pw-post-body-paragraph kv kw iq kx b ky ls la lb lc lt le lf kh lu lh li kl lv lk ll kp lw ln lo lp ij bi translated">以及为什么数据科学需要更多的“半贝叶斯人”</p></div><div class="ab cl lx ly hu lz" role="separator"><span class="ma bw bk mb mc md"/><span class="ma bw bk mb mc md"/><span class="ma bw bk mb mc"/></div><div class="ij ik il im in"><h2 id="66c0" class="jy jz iq bd ka kb kc dn kd ke kf dp kg kh ki kj kk kl km kn ko kp kq kr ks kt bi translated"><a class="ae ku" rel="noopener" target="_blank" href="/a-data-scientists-journey-from-sudoku-to-kaggle-120876b7fa33">一位数据科学家从数独到 Kaggle 的旅程</a></h2><p id="3b17" class="pw-post-body-paragraph kv kw iq kx b ky kz la lb lc ld le lf kh lg lh li kl lj lk ll kp lm ln lo lp ij bi translated">通过<a class="lq lr ep" href="https://medium.com/u/7053de462a28?source=post_page-----9dde074025b--------------------------------" rel="noopener" target="_blank"> Parul Pandey </a> — 8 分钟阅读</p><p id="d465" class="pw-post-body-paragraph kv kw iq kx b ky ls la lb lc lt le lf kh lu lh li kl lv lk ll kp lw ln lo lp ij bi translated">与 Rohan Rao 的对话:数据科学家、Kaggle 特级大师、印度数独卫冕冠军</p></div><div class="ab cl lx ly hu lz" role="separator"><span class="ma bw bk mb mc md"/><span class="ma bw bk mb mc md"/><span class="ma bw bk mb mc"/></div><div class="ij ik il im in"><h2 id="478e" class="jy jz iq bd ka kb kc dn kd ke kf dp kg kh ki kj kk kl km kn ko kp kq kr ks kt bi translated"><a class="ae ku" rel="noopener" target="_blank" href="/network-of-networks-a-neural-symbolic-approach-to-inverse-graphics-acf3998ab3d">网络的网络——逆图形的神经符号方法</a></h2><p id="9d08" class="pw-post-body-paragraph kv kw iq kx b ky kz la lb lc ld le lf kh lg lh li kl lj lk ll kp lm ln lo lp ij bi translated">由迈克尔·基斯纳——12 分钟阅读</p><p id="7dc8" class="pw-post-body-paragraph kv kw iq kx b ky ls la lb lc lt le lf kh lu lh li kl lv lk ll kp lw ln lo lp ij bi translated">许多人一旦熟悉了深度学习和神经网络，他们的第一个想法就是，“如果我们制作一个神经网络的网络会怎么样？”。</p></div><div class="ab cl lx ly hu lz" role="separator"><span class="ma bw bk mb mc md"/><span class="ma bw bk mb mc md"/><span class="ma bw bk mb mc"/></div><div class="ij ik il im in"><h2 id="b523" class="jy jz iq bd ka kb kc dn kd ke kf dp kg kh ki kj kk kl km kn ko kp kq kr ks kt bi translated"><a class="ae ku" rel="noopener" target="_blank" href="/how-to-cluster-in-high-dimensions-4ef693bacc6">如何在高维空间中聚类</a></h2><p id="f90d" class="pw-post-body-paragraph kv kw iq kx b ky kz la lb lc ld le lf kh lg lh li kl lj lk ll kp lm ln lo lp ij bi translated">由<a class="lq lr ep" href="https://medium.com/u/8570b484f56c?source=post_page-----9dde074025b--------------------------------" rel="noopener" target="_blank">尼古拉·奥斯科尔科夫</a> — 8 分钟阅读</p><p id="4aa3" class="pw-post-body-paragraph kv kw iq kx b ky ls la lb lc lt le lf kh lu lh li kl lv lk ll kp lw ln lo lp ij bi translated">自动检测集群数量的方法</p></div><div class="ab cl lx ly hu lz" role="separator"><span class="ma bw bk mb mc md"/><span class="ma bw bk mb mc md"/><span class="ma bw bk mb mc"/></div><div class="ij ik il im in"><h2 id="b981" class="jy jz iq bd ka kb kc dn kd ke kf dp kg kh ki kj kk kl km kn ko kp kq kr ks kt bi translated"><a class="ae ku" rel="noopener" target="_blank" href="/building-a-bayesian-logistic-regression-with-python-and-pymc3-4dd463bbb16">用 Python 和 PyMC3 构建贝叶斯逻辑回归</a></h2><p id="728b" class="pw-post-body-paragraph kv kw iq kx b ky kz la lb lc ld le lf kh lg lh li kl lj lk ll kp lm ln lo lp ij bi translated">到<a class="lq lr ep" href="https://medium.com/u/731d8566944a?source=post_page-----9dde074025b--------------------------------" rel="noopener" target="_blank">苏珊李</a> — 10 分钟读完</p><p id="f804" class="pw-post-body-paragraph kv kw iq kx b ky ls la lb lc lt le lf kh lu lh li kl lv lk ll kp lw ln lo lp ij bi translated">我认购定期存款的可能性有多大？后验概率，可信区间，优势比，WAIC</p></div><div class="ab cl lx ly hu lz" role="separator"><span class="ma bw bk mb mc md"/><span class="ma bw bk mb mc md"/><span class="ma bw bk mb mc"/></div><div class="ij ik il im in"><h2 id="f73c" class="jy jz iq bd ka kb kc dn kd ke kf dp kg kh ki kj kk kl km kn ko kp kq kr ks kt bi translated"><a class="ae ku" rel="noopener" target="_blank" href="/17-rules-of-thumb-for-building-a-neural-network-93356f9930af">构建神经网络的经验法则</a></h2><p id="769b" class="pw-post-body-paragraph kv kw iq kx b ky kz la lb lc ld le lf kh lg lh li kl lj lk ll kp lm ln lo lp ij bi translated">通过<a class="lq lr ep" href="https://medium.com/u/1c9fae27a83?source=post_page-----9dde074025b--------------------------------" rel="noopener" target="_blank"> Chitta Ranjan </a> — 11 分钟读取</p><p id="168b" class="pw-post-body-paragraph kv kw iq kx b ky ls la lb lc lt le lf kh lu lh li kl lv lk ll kp lw ln lo lp ij bi translated">在本文中，我们将获得一个构建初始神经网络的起点。我们将学习经验法则，例如隐藏层数、节点数、激活等。，并查看 TensorFlow 2 中的实现。</p></div><div class="ab cl lx ly hu lz" role="separator"><span class="ma bw bk mb mc md"/><span class="ma bw bk mb mc md"/><span class="ma bw bk mb mc"/></div><div class="ij ik il im in"><h2 id="31aa" class="jy jz iq bd ka kb kc dn kd ke kf dp kg kh ki kj kk kl km kn ko kp kq kr ks kt bi translated"><a class="ae ku" rel="noopener" target="_blank" href="/detecting-stationarity-in-time-series-data-d29e0a21e638">检测时间序列数据的平稳性</a></h2><p id="745b" class="pw-post-body-paragraph kv kw iq kx b ky kz la lb lc ld le lf kh lg lh li kl lj lk ll kp lm ln lo lp ij bi translated">通过<a class="lq lr ep" href="https://medium.com/u/ed0e9ae905e3?source=post_page-----9dde074025b--------------------------------" rel="noopener" target="_blank"> Shay Palachy </a> — 9 分钟阅读</p><p id="694e" class="pw-post-body-paragraph kv kw iq kx b ky ls la lb lc lt le lf kh lu lh li kl lv lk ll kp lw ln lo lp ij bi translated">试图通过观察一个时间序列的图表来确定它是否是由一个平稳过程产生的是一个可疑的冒险。</p></div></div>    
</body>
</html>