<html>
<head>
<title>Cat, Dog, or Elon Musk?</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">猫，狗，还是埃隆马斯克？</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/cat-dog-or-elon-musk-145658489730?source=collection_archive---------7-----------------------#2019-10-05">https://towardsdatascience.com/cat-dog-or-elon-musk-145658489730?source=collection_archive---------7-----------------------#2019-10-05</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><h2 id="6cc9" class="ir is it bd b dl iu iv iw ix iy iz dk ja translated" aria-label="kicker paragraph">终极 DIY 机器学习初学者指南</h2><div class=""/><div class=""><h2 id="2b08" class="pw-subtitle-paragraph jz jc it bd b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq dk translated">了解如何用 Python 和 Keras 在不到 15 分钟的时间内构建一个图像识别卷积神经网络！</h2></div><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi kr"><img src="../Images/312dd1de186abb90706fa02cb3dcafaa.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*SFFZYMxxtMTtaDfTB0WCFg.png"/></div></div></figure><p id="faaf" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi lz translated"><span class="l ma mb mc bm md me mf mg mh di"> G </span>从机器学习起步的尝试令人望而生畏。底层的概念是高级的，相关的术语是特定于领域的和技术性的。除此之外，机器学习恰好是研究和实践中发展最快的领域之一，这使得跟上时代变得更加困难。</p><p id="b305" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">本文为您提供了一个简单的(附带代码的)介绍，介绍如何设置、训练和运行卷积神经网络来对图像进行分类。到本文结束时，你将已经建立了一个卷积神经网络，可以区分猫、狗和埃隆·马斯克。它非常容易采用，如果你喜欢，你可以在组合中加入一棵树或一辆车。我强烈建议你自己完成这些步骤，因为这样做会在记忆和满足感方面产生最好的效果。</p><blockquote class="mi"><p id="2567" class="mj mk it bd ml mm mn mo mp mq mr ly dk translated">随着技术的进步，它一次又一次地逆转了每一种情况的特征。自动化时代将是“自己动手”的时代。—马歇尔·麦克卢汉</p></blockquote><p id="cd57" class="pw-post-body-paragraph ld le it lf b lg ms kd li lj mt kg ll lm mu lo lp lq mv ls lt lu mw lw lx ly im bi translated">注意:为了简短起见，我会跳过有时过于简单的话题。我们的目标是让你开始学习，而不是取代正式的关于机器学习的计算机科学课程。</p><h1 id="f52d" class="mx my it bd mz na nb nc nd ne nf ng nh ki ni kj nj kl nk km nl ko nm kp nn no bi translated">文章的结构:</h1><ol class=""><li id="b9f8" class="np nq it lf b lg nr lj ns lm nt lq nu lu nv ly nw nx ny nz bi translated">先决条件和设置</li><li id="3cd6" class="np nq it lf b lg oa lj ob lm oc lq od lu oe ly nw nx ny nz bi translated">什么是 ImageNet 和 MobileNet？</li><li id="7b23" class="np nq it lf b lg oa lj ob lm oc lq od lu oe ly nw nx ny nz bi translated">迁移学习</li><li id="7bc1" class="np nq it lf b lg oa lj ob lm oc lq od lu oe ly nw nx ny nz bi translated">自定义您的 MobileNet 版本</li><li id="abda" class="np nq it lf b lg oa lj ob lm oc lq od lu oe ly nw nx ny nz bi translated">训练模型</li><li id="cbab" class="np nq it lf b lg oa lj ob lm oc lq od lu oe ly nw nx ny nz bi translated">做预测</li></ol></div><div class="ab cl of og hx oh" role="separator"><span class="oi bw bk oj ok ol"/><span class="oi bw bk oj ok ol"/><span class="oi bw bk oj ok"/></div><div class="im in io ip iq"><h1 id="ea6c" class="mx my it bd mz na om nc nd ne on ng nh ki oo kj nj kl op km nl ko oq kp nn no bi translated">①先决条件和设置</h1><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi or"><img src="../Images/1966f7e262b0ca8076ed10d38de76014.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*HF9bVKnSTocpM72L"/></div></div><figcaption class="os ot gj gh gi ou ov bd b be z dk">Photo by <a class="ae ow" href="https://unsplash.com/@dylan_nolte?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">dylan nolte</a> on <a class="ae ow" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><p id="e36e" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi lz translated"><span class="l ma mb mc bm md me mf mg mh di">一个</span> Python 环境(建议 Jupyter 笔记本)。如果你还没有设置这个，不要担心。这是毫不费力的，不到 10 分钟。</p><div class="ox oy gp gr oz pa"><a rel="noopener follow" target="_blank" href="/get-started-with-python-e50dc8c96589"><div class="pb ab fo"><div class="pc ab pd cl cj pe"><h2 class="bd jd gy z fp pf fr fs pg fu fw jc bi translated">所以你想成为一名数据科学家？</h2><div class="ph l"><h3 class="bd b gy z fp pf fr fs pg fu fw dk translated">到底是什么阻止了你？下面是如何开始！</h3></div><div class="pi l"><p class="bd b dl z fp pf fr fs pg fu fw dk translated">towardsdatascience.com</p></div></div><div class="pj l"><div class="pk l pl pm pn pj po lb pa"/></div></div></a></div></div><div class="ab cl of og hx oh" role="separator"><span class="oi bw bk oj ok ol"/><span class="oi bw bk oj ok ol"/><span class="oi bw bk oj ok"/></div><div class="im in io ip iq"><p id="8482" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi lz translated"><span class="l ma mb mc bm md me mf mg mh di">我们</span>将使用<a class="ae ow" href="https://www.tensorflow.org/" rel="noopener ugc nofollow" target="_blank"> TensorFlow </a>和<a class="ae ow" href="https://keras.io/" rel="noopener ugc nofollow" target="_blank"> Keras </a>。由谷歌大脑团队创建的 TensorFlow 是一个用于数值计算和大规模机器学习的开源库。Keras 是一个位于 TensorFlow 之上的高级神经网络 API。Keras 最近已经集成到 TensorFlow 中，可以通过<code class="fe pp pq pr ps b">tensorflow.keras</code>访问。所以还是装 TensorFlow 吧。</p><pre class="ks kt ku kv gt pt ps pu pv aw pw bi"><span id="ab6b" class="px my it ps b gy py pz l qa qb">pip install tensorflow</span><span id="170c" class="px my it ps b gy qc pz l qa qb"><strong class="ps jd"># For progress visualization when training the model</strong><br/>pip install keras_tqdm</span><span id="dc0b" class="px my it ps b gy qc pz l qa qb"><strong class="ps jd"># Required for keras_tqdm</strong><br/>pip install ipywidgets<br/>jupyter nbextension enable --py widgetsnbextension</span></pre><p id="9629" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">我建议在专用的 Python(虚拟)环境中运行笔记本，以防止与您可能有的其他项目发生潜在冲突。随着你职业生涯的进展，虚拟环境将变得更加重要。你会有一些偶尔会回来的项目。对于那些项目，您可能已经使用了您想要继续使用的特定库的特定版本，而不是重构您的整个旧代码来使用新版本。</p></div><div class="ab cl of og hx oh" role="separator"><span class="oi bw bk oj ok ol"/><span class="oi bw bk oj ok ol"/><span class="oi bw bk oj ok"/></div><div class="im in io ip iq"><p id="16b7" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi lz translated"><span class="l ma mb mc bm md me mf mg mh di">到</span>训练一个机器学习网络，你需要数据。由于我们正在建立一个图像分类器，我们将需要图像。你需要为每门课下载至少几百张你想要预测的图片。幸好我一直未雨绸缪，为你准备了快速下载图片的指南。</p><div class="ox oy gp gr oz pa"><a rel="noopener follow" target="_blank" href="/image-scraping-with-python-a96feda8af2d"><div class="pb ab fo"><div class="pc ab pd cl cj pe"><h2 class="bd jd gy z fp pf fr fs pg fu fw jc bi translated">使用 Python 进行图像抓取</h2><div class="ph l"><h3 class="bd b gy z fp pf fr fs pg fu fw dk translated">学习如何用 Python 从 Google 下载图片的代码指南！</h3></div><div class="pi l"><p class="bd b dl z fp pf fr fs pg fu fw dk translated">towardsdatascience.com</p></div></div><div class="pj l"><div class="qd l pl pm pn pj po lb pa"/></div></div></a></div><p id="ed30" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">为了让所提供的 Jupyter 笔记本能够完美地工作，你的文件夹结构应该是这样的，每个文件夹应该包含大约 200-300 张图片。图片的名称和大小并不重要。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi qe"><img src="../Images/62c1f588c3c9bea493631935c780ca53.png" data-original-src="https://miro.medium.com/v2/resize:fit:1206/format:webp/1*092ApiPW8IZEBu2zPI-F6w.png"/></div></figure></div><div class="ab cl of og hx oh" role="separator"><span class="oi bw bk oj ok ol"/><span class="oi bw bk oj ok ol"/><span class="oi bw bk oj ok"/></div><div class="im in io ip iq"><h1 id="aaf8" class="mx my it bd mz na om nc nd ne on ng nh ki oo kj nj kl op km nl ko oq kp nn no bi translated">②什么是 ImageNet 和 MobileNet？</h1><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi qf"><img src="../Images/ec2d7d9bc37facf030059f5a05916c3a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*n6K9R5wrN5H-Vs13"/></div></div><figcaption class="os ot gj gh gi ou ov bd b be z dk">Photo by <a class="ae ow" href="https://unsplash.com/@dulgier?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Anastasia Dulgier</a> on <a class="ae ow" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><h2 id="8f8c" class="px my it bd mz qg qh dn nd qi qj dp nh lm qk ql nj lq qm qn nl lu qo qp nn iz bi translated">MobileNet</h2><p id="9ef4" class="pw-post-body-paragraph ld le it lf b lg nr kd li lj ns kg ll lm qq lo lp lq qr ls lt lu qs lw lx ly im bi lz translated"><span class="l ma mb mc bm md me mf mg mh di">我们</span>将使用<a class="ae ow" href="https://ai.googleblog.com/2017/06/mobilenets-open-source-models-for.html" rel="noopener ugc nofollow" target="_blank"> MobileNet </a>作为基础模型。MobileNet 是 Google 开发的轻量级卷积神经网络，已经在 Imagenet 上进行了训练。原文<a class="ae ow" href="https://arxiv.org/abs/1704.04861" rel="noopener ugc nofollow" target="_blank">可以在这里</a>找到。谷歌最近发布了新版 MobileNet，<a class="ae ow" href="https://ai.googleblog.com/2018/04/mobilenetv2-next-generation-of-on.html" rel="noopener ugc nofollow" target="_blank"> MobileNetV2 </a>。</p><h2 id="5ec4" class="px my it bd mz qg qh dn nd qi qj dp nh lm qk ql nj lq qm qn nl lu qo qp nn iz bi translated">Imagenet</h2><p id="19ee" class="pw-post-body-paragraph ld le it lf b lg nr kd li lj ns kg ll lm qq lo lp lq qr ls lt lu qs lw lx ly im bi lz translated"><span class="l ma mb mc bm md me mf mg mh di"> I </span> <a class="ae ow" href="http://www.image-net.org/" rel="noopener ugc nofollow" target="_blank"> magenet </a>是一个约 1500 万的大范围标记图像数据库，按照<a class="ae ow" href="http://wordnet.princeton.edu/" rel="noopener ugc nofollow" target="_blank"> WordNet </a>层次结构(目前只有名词)组织。成百上千的图像描绘了层次结构的每个节点。Imagenet 通常用于训练图像识别模型。模型的质量通常通过它们在<a class="ae ow" href="http://image-net.org/challenges/LSVRC/" rel="noopener ugc nofollow" target="_blank"><strong class="lf jd">ils vrc</strong></a><strong class="lf jd"/>(ImageNet 大规模视觉识别挑战)上的表现来评估。ILSVRC 非常好，因为它保证了一个公共基线，并提供了模型之间的一些可比性。</p></div><div class="ab cl of og hx oh" role="separator"><span class="oi bw bk oj ok ol"/><span class="oi bw bk oj ok ol"/><span class="oi bw bk oj ok"/></div><div class="im in io ip iq"><h1 id="747c" class="mx my it bd mz na om nc nd ne on ng nh ki oo kj nj kl op km nl ko oq kp nn no bi translated">③迁移学习</h1><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi qt"><img src="../Images/60ca4bca13e66c9e7cee32e639a2f2ef.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*dSU4EI-U4XMZ9mDr"/></div></div><figcaption class="os ot gj gh gi ou ov bd b be z dk">Photo by <a class="ae ow" href="https://unsplash.com/@jonathanborba?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Jonathan Borba</a> on <a class="ae ow" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><p id="cf60" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi lz translated"><span class="l ma mb mc bm md me mf mg mh di">到</span>最好解释迁移学习，让我们快速看一下卷积网络的典型架构。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi qu"><img src="../Images/9664541029acd36f76f00e331f0b2334.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*iH1260MbyvQ0_3Di4PLUsA.png"/></div></div><figcaption class="os ot gj gh gi ou ov bd b be z dk">An exemplary architecture of a convolutional neural network, highlighting feature extraction and classification</figcaption></figure><h2 id="13ce" class="px my it bd mz qg qh dn nd qi qj dp nh lm qk ql nj lq qm qn nl lu qo qp nn iz bi translated">特征抽出</h2><p id="802c" class="pw-post-body-paragraph ld le it lf b lg nr kd li lj ns kg ll lm qq lo lp lq qr ls lt lu qs lw lx ly im bi lz translated"><span class="l ma mb mc bm md me mf mg mh di"> T </span>在典型的卷积神经网络中，较低层(更接近输入的网络层次)可以被认为是逐片扫描整个图像的过滤器。然后，将这些扫描的结果组合起来，创建每个都有单个值的节点。</p><h2 id="9ece" class="px my it bd mz qg qh dn nd qi qj dp nh lm qk ql nj lq qm qn nl lu qo qp nn iz bi translated">分类</h2><p id="e09d" class="pw-post-body-paragraph ld le it lf b lg nr kd li lj ns kg ll lm qq lo lp lq qr ls lt lu qs lw lx ly im bi lz translated"><span class="l ma mb mc bm md me mf mg mh di">在</span>网络的分类部分，我们使用由特征提取部分生成的单值节点的最后一个长列表来将它们映射到我们想要的输出。也就是说，如果我们的输出是一些货币值，那么我们可能只有一个最终节点，表明该值(回归)。如果我们试图对多个对象进行分类，我们将需要和我们拥有的类一样多的最后节点。</p><h2 id="9cab" class="px my it bd mz qg qh dn nd qi qj dp nh lm qk ql nj lq qm qn nl lu qo qp nn iz bi translated">训练一个神经网络意味着什么？</h2><p id="3901" class="pw-post-body-paragraph ld le it lf b lg nr kd li lj ns kg ll lm qq lo lp lq qr ls lt lu qs lw lx ly im bi lz translated">这有助于将神经网络视为一个大的功能。它有一个输入(图像)和一个输出(预测)。<br/>在网络训练过程中，优化器不断优化该函数。优化网络意味着改变网络节点之间连接的权重。该优化基于损失函数。本质上，该损失函数是通过将预测与实际结果进行比较，为每个输入的函数结果分配损失值的函数。更高的损失值是不好的，优化器知道最近的更改不是一个好主意，会尝试其他方法。</p><h2 id="ac0b" class="px my it bd mz qg qh dn nd qi qj dp nh lm qk ql nj lq qm qn nl lu qo qp nn iz bi translated">迁移学习</h2><p id="7e66" class="pw-post-body-paragraph ld le it lf b lg nr kd li lj ns kg ll lm qq lo lp lq qr ls lt lu qs lw lx ly im bi lz translated">转移学习只能应用于以前训练过的模型。通常，这些模型会在运行数天的大型 GPU 上进行训练，以找到最佳权重来生成尽可能好的预测。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi qv"><img src="../Images/13ba1cd1798b521255e0bd2ddece519d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*V6hPq-srR86AIWYrgFYLfA.png"/></div></div><figcaption class="os ot gj gh gi ou ov bd b be z dk">The architecture of a VGG16 convolutional neural network</figcaption></figure><p id="63d2" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">虽然上图描述的是 VGG16 模型的架构，而不是 MobileNet 网络，但它的相似性足以说明这一点。输入图像有三个通道(红色、绿色和蓝色)。然后，图像经过大量的转换、过滤、合并、卷积等等，最终在一个包含 1000 个结果值的层中结束(类别为<a class="ae ow" href="http://image-net.org/challenges/LSVRC/" rel="noopener ugc nofollow" target="_blank"><strong class="lf jd">ils vrc</strong></a><strong class="lf jd">)</strong>)。</p><p id="4afe" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">当使用迁移学习时，我们本质上说:</p><blockquote class="mi"><p id="fefe" class="mj mk it bd ml mm mn mo mp mq mr ly dk translated">“去你的结果，但谢谢你的工作”</p></blockquote><p id="6a78" class="pw-post-body-paragraph ld le it lf b lg ms kd li lj mt kg ll lm mu lo lp lq mv ls lt lu mw lw lx ly im bi translated">换句话说，我们将切断网络的最后一部分(在上面的例子中，是 1x1000 层)，并用一个更适合我们需要的层来代替它(对于猫、狗或 Elon 问题，是 1x3 层)。实质上，我们保留了为网络的特征提取部分寻找最佳权重的所有工作，同时为我们的自定义分类层替换掉网络的最后一部分。虽然并不完美，但这种方法产生了惊人的好结果，只需要训练时间的一小部分。这种不完美源于这样一个事实，即你的模型可能已经学会了，除了别的以外，识别像毛发一样的表面。当你想要区分不同种类的树时，识别像皮毛一样的表面可能没有帮助。然而，能够定位原始形状和模式——这是在网络的较低部分学习的——对于区分树木非常有帮助。</p><h1 id="a77a" class="mx my it bd mz na nb nc nd ne nf ng nh ki ni kj nj kl nk km nl ko nm kp nn no bi translated">④定制您的 MobileNet 版本</h1><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi qw"><img src="../Images/b60902e1580288439fd3a8a4accea526.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*h9VibXHhHfn2-Eta"/></div></div><figcaption class="os ot gj gh gi ou ov bd b be z dk">Photo by <a class="ae ow" href="https://unsplash.com/@aahubs?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Aaron Huber</a> on <a class="ae ow" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><h2 id="7f98" class="px my it bd mz qg qh dn nd qi qj dp nh lm qk ql nj lq qm qn nl lu qo qp nn iz bi translated">进口</h2><pre class="ks kt ku kv gt pt ps pu pv aw pw bi"><span id="7cc5" class="px my it ps b gy py pz l qa qb">import tensorflow as tf<br/>import PIL</span></pre><h2 id="e6a2" class="px my it bd mz qg qh dn nd qi qj dp nh lm qk ql nj lq qm qn nl lu qo qp nn iz bi translated">助手功能</h2><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="qx qy l"/></div></figure><p id="6c56" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">我们稍后会用到的两个辅助函数。</p></div><div class="ab cl of og hx oh" role="separator"><span class="oi bw bk oj ok ol"/><span class="oi bw bk oj ok ol"/><span class="oi bw bk oj ok"/></div><div class="im in io ip iq"><h2 id="9232" class="px my it bd mz qg qh dn nd qi qj dp nh lm qk ql nj lq qm qn nl lu qo qp nn iz bi translated">加载 MobileNet 基本模型</h2><p id="4be8" class="pw-post-body-paragraph ld le it lf b lg nr kd li lj ns kg ll lm qq lo lp lq qr ls lt lu qs lw lx ly im bi lz translated"><span class="l ma mb mc bm md me mf mg mh di"> L </span> et 首先加载默认模型，以了解当我们应用迁移学习时，后来到底发生了什么。</p><pre class="ks kt ku kv gt pt ps pu pv aw pw bi"><span id="90b1" class="px my it ps b gy py pz l qa qb">model = tf.keras.applications.mobilenet.MobileNet()<br/>model.summary()</span></pre><p id="6e32" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">运行前面的代码片段将产生一个模型中所有层的长列表，从最低层(InputLayer)到最高层(这里称为 act_softmax)。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi qz"><img src="../Images/13b95d11a05f80845a4812b1bec20d2a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*3bPvN1dzGA_y4zQbRv9Dog.png"/></div></div><figcaption class="os ot gj gh gi ou ov bd b be z dk">Screenshot of the lowest and topmost layer of the MobileNet model.summary(). I omitted the middle layers for space reasons.</figcaption></figure><p id="1b98" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">我们可以看到最后一层的输出形状为(无，1000)，这意味着它将产生 1000 个值。让我们通过运行以下命令来快速验证:</p><pre class="ks kt ku kv gt pt ps pu pv aw pw bi"><span id="1322" class="px my it ps b gy py pz l qa qb">dog_image_id = os.listdir('images/dog')[0]</span><span id="d07a" class="px my it ps b gy qc pz l qa qb">dog_image = load_image(os.path.join('images/dog',dog_image_id))</span><span id="3039" class="px my it ps b gy qc pz l qa qb">print(f'shape: {dog_image.shape}')<br/>print(f'type: {type(dog_image)}')</span><span id="ca3c" class="px my it ps b gy qc pz l qa qb">model.predict(dog_image)</span></pre><p id="ee97" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">这个命令将创建一个包含 1000 个值的 Numpy 数组。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi ra"><img src="../Images/0e6fd5fbed72303d1fec708f28826190.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Bu52KE5hUfjPZxHEFk_wxQ.png"/></div></div><figcaption class="os ot gj gh gi ou ov bd b be z dk">A random image of a dog fed to the default MobileNet configuration</figcaption></figure><h2 id="1962" class="px my it bd mz qg qh dn nd qi qj dp nh lm qk ql nj lq qm qn nl lu qo qp nn iz bi translated">加载用于迁移学习的 MobileNet 模型</h2><pre class="ks kt ku kv gt pt ps pu pv aw pw bi"><span id="c4ec" class="px my it ps b gy py pz l qa qb">model = tf.keras.applications.mobilenet.MobileNet(<br/>  input_shape=(224, 224, 3), <br/>  include_top=False, <br/>  pooling='avg'<br/>)</span></pre><p id="17f2" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">我们加载模型的主要区别是我们现在使用参数<code class="fe pp pq pr ps b">include_top=False</code>。当使用这个参数时，我们还必须指定 input_shape 和 pooling，这可以在<a class="ae ow" href="https://keras.io/applications/#mobilenet" rel="noopener ugc nofollow" target="_blank">文档</a>中读到。通过指定<code class="fe pp pq pr ps b">include_top=False</code>，我们实例化了没有最高层的模型(即，1000 个类的预测)。</p><p id="e000" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">运行<code class="fe pp pq pr ps b">model.summary()</code>给了我们:</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi rb"><img src="../Images/d1b50c36d58499fe2c7b6645c3f6aebb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*5j-LIKe5JepCjzeCNUixXw.png"/></div></div><figcaption class="os ot gj gh gi ou ov bd b be z dk">MobileNet model with include_top=False</figcaption></figure><p id="123f" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">我们现在可以清楚地看到，模型的最顶层是 global_average_pooling，而不是我们之前看到的 softmax 层。此外，参数的总数已经显著下降。为了确认新的结果值，我们可以运行<code class="fe pp pq pr ps b">model.predict(dog).shape</code>来查看我们现在将获得 1024 个而不是 1000 个值。考察这些数据也表明，它们与之前的预测大相径庭。区别是因为还没有进行分类，那些 1024 值表示一些抽象特征的存在。</p><h2 id="1304" class="px my it bd mz qg qh dn nd qi qj dp nh lm qk ql nj lq qm qn nl lu qo qp nn iz bi translated">添加附加层</h2><p id="ee71" class="pw-post-body-paragraph ld le it lf b lg nr kd li lj ns kg ll lm qq lo lp lq qr ls lt lu qs lw lx ly im bi lz translated"><span class="l ma mb mc bm md me mf mg mh di">为了</span>预测猫狗和埃隆马斯克，我们必须替换原始模型中的预测层。为此，我们添加了三个新层:</p><ul class=""><li id="b3d2" class="np nq it lf b lg lh lj lk lm rc lq rd lu re ly rf nx ny nz bi translated"><strong class="lf jd">删除:</strong>在训练过程中删除节点，以防止过度拟合</li><li id="796e" class="np nq it lf b lg oa lj ob lm oc lq od lu oe ly rf nx ny nz bi translated"><strong class="lf jd">密集:</strong>全连接层(即该层中的每个节点都连接到前一层中的每个节点)</li><li id="2038" class="np nq it lf b lg oa lj ob lm oc lq od lu oe ly rf nx ny nz bi translated"><strong class="lf jd"> Softmax: </strong>指定输出值的函数。Softmax 意味着层中所有节点(我们的三个密集节点)的总和必须为 1。可以理解为一种概率</li></ul><pre class="ks kt ku kv gt pt ps pu pv aw pw bi"><span id="8a27" class="px my it ps b gy py pz l qa qb">from tensorflow.keras.models import Model<br/>from tensorflow.keras.layers import (Dropout, Dense, Softmax)</span><span id="a1fc" class="px my it ps b gy qc pz l qa qb">x = Dropout(rate=0.4)(model.output)<br/>x = Dense(3)(x)<br/>x = Softmax()(x)<br/>model= Model(model.inputs, x)</span></pre><p id="8e6f" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">再次运行<code class="fe pp pq pr ps b">model.summary()</code>将在模型顶部显示新图层。</p><h1 id="091c" class="mx my it bd mz na nb nc nd ne nf ng nh ki ni kj nj kl nk km nl ko nm kp nn no bi translated">⑤训练模型</h1><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi rg"><img src="../Images/3aa19367fd29c10635cedb2b74b7ec22.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*DFkxFZ4ZNNxuW2t7"/></div></div><figcaption class="os ot gj gh gi ou ov bd b be z dk">Photo by <a class="ae ow" href="https://unsplash.com/@joshriemer?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Josh Riemer</a> on <a class="ae ow" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><p id="9a41" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">这开始变得令人兴奋了！我们快到了。</p><h2 id="975d" class="px my it bd mz qg qh dn nd qi qj dp nh lm qk ql nj lq qm qn nl lu qo qp nn iz bi translated">指定要训练的层</h2><p id="a11b" class="pw-post-body-paragraph ld le it lf b lg nr kd li lj ns kg ll lm qq lo lp lq qr ls lt lu qs lw lx ly im bi lz translated">如果我们从头开始，我们现在将训练整个网络和随之而来的数百万个参数。但幸运的是，我们不必那样做。所有下层都是之前训练过的！所以让我们确保只训练新的层。对于生产模型，您通常还会在初始磨合阶段后训练较低的层，此时您只训练新的层。</p><pre class="ks kt ku kv gt pt ps pu pv aw pw bi"><span id="cd43" class="px my it ps b gy py pz l qa qb">for layer in model.layers[:-3]:<br/>    layer.trainable = False</span></pre><h2 id="2e02" class="px my it bd mz qg qh dn nd qi qj dp nh lm qk ql nj lq qm qn nl lu qo qp nn iz bi translated">编译模型</h2><p id="ba09" class="pw-post-body-paragraph ld le it lf b lg nr kd li lj ns kg ll lm qq lo lp lq qr ls lt lu qs lw lx ly im bi lz translated">让我们通过运行带有优化器和损失函数的<code class="fe pp pq pr ps b">model.compile</code>来配置我们的训练模型。有很多不同的优化器和损失函数，但是<code class="fe pp pq pr ps b"><a class="ae ow" href="https://keras.io/optimizers/#adam" rel="noopener ugc nofollow" target="_blank">Adam</a></code>和<code class="fe pp pq pr ps b"><a class="ae ow" href="https://keras.io/losses/" rel="noopener ugc nofollow" target="_blank">categorial_crossentropy</a></code>是很好的默认值。如果你好奇，就去读读它们，但是不要在丛林中迷路。</p><pre class="ks kt ku kv gt pt ps pu pv aw pw bi"><span id="bd06" class="px my it ps b gy py pz l qa qb">from tensorflow.keras.optimizers import Adam<br/>model.compile(<br/>    optimizer=Adam(lr=0.001),<br/>    loss='categorical_crossentropy'<br/>)</span></pre><h2 id="2f1c" class="px my it bd mz qg qh dn nd qi qj dp nh lm qk ql nj lq qm qn nl lu qo qp nn iz bi translated">构建数据生成器</h2><p id="cf0e" class="pw-post-body-paragraph ld le it lf b lg nr kd li lj ns kg ll lm qq lo lp lq qr ls lt lu qs lw lx ly im bi lz translated"><span class="l ma mb mc bm md me mf mg mh di">答</span>差不多了，我们已经指定了训练和验证数据，我们可以开始了！</p><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="qx qy l"/></div></figure><p id="4f23" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">我们首先构建一个数据生成器<code class="fe pp pq pr ps b">datagen</code>，并指定几个参数来定义我们想要在训练过程中应用于图像的增强。我们还为<code class="fe pp pq pr ps b">training</code>和<code class="fe pp pq pr ps b">validation</code>指定了一个<code class="fe pp pq pr ps b">save_to_dir</code>文件夹，并预先保证它们的存在。这样做将允许我们检查在训练过程中创建的增强图片。如果你不想那样，就把线拆了。</p><h2 id="4700" class="px my it bd mz qg qh dn nd qi qj dp nh lm qk ql nj lq qm qn nl lu qo qp nn iz bi translated">训练模型</h2><p id="439c" class="pw-post-body-paragraph ld le it lf b lg nr kd li lj ns kg ll lm qq lo lp lq qr ls lt lu qs lw lx ly im bi lz translated"><span class="l ma mb mc bm md me mf mg mh di"> A </span>好了，该训练模特了！我们使用<code class="fe pp pq pr ps b">fit_generator</code>是因为我们之前已经创建了两个生成器，一个用于训练数据，一个用于验证数据。我们还使用回调来直观地显示我们训练的进度。</p><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="qx qy l"/></div></figure><p id="0f75" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">运行这个意味着，我们要等一会儿。在我的 MacBook Pro 上，大概是 10 分钟。您的里程可能会因硬件而异。如果你想走过场，你也可以设置<code class="fe pp pq pr ps b">epochs=1</code>，这样会快很多。</p><p id="c9db" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">在培训过程中，您应该会看到类似这样的内容:</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi rh"><img src="../Images/e954ec4d674f62d4121a567f25f438c2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*RFnasmU0T9e8UhFb3_inxA.png"/></div></div></figure><p id="c5d4" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">训练完成后，我们可以通过运行以下命令来检查进度:</p><pre class="ks kt ku kv gt pt ps pu pv aw pw bi"><span id="38cb" class="px my it ps b gy py pz l qa qb">import matplotlib.pyplot as plt<br/>plt.plot(history.history['loss'])<br/>plt.plot(history.history['val_loss'])<br/>plt.title('Model loss')<br/>plt.ylabel('Loss')<br/>plt.xlabel('Epoch')<br/>plt.legend(['Train', 'Validation'], loc='upper left')<br/>plt.show()</span></pre><p id="6c49" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">这将为我们提供:</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi ri"><img src="../Images/c92bcae537157970ea94e1c3f7849993.png" data-original-src="https://miro.medium.com/v2/resize:fit:1372/format:webp/1*c-WR16H_ikBEoaBZuuug1g.png"/></div><figcaption class="os ot gj gh gi ou ov bd b be z dk">Typical model training progression, loss decreases quickly at first and then flattens out after some epochs</figcaption></figure></div><div class="ab cl of og hx oh" role="separator"><span class="oi bw bk oj ok ol"/><span class="oi bw bk oj ok ol"/><span class="oi bw bk oj ok"/></div><div class="im in io ip iq"><h1 id="ba2c" class="mx my it bd mz na om nc nd ne on ng nh ki oo kj nj kl op km nl ko oq kp nn no bi translated">⑥进行预测</h1><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi qw"><img src="../Images/51781ac271adf5f470d278329834fb66.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*bz2xTY9ussqoGDeU"/></div></div><figcaption class="os ot gj gh gi ou ov bd b be z dk">Photo by <a class="ae ow" href="https://unsplash.com/@jentheodore?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Jen Theodore</a> on <a class="ae ow" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><p id="f421" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">酷，我们已经成功训练了模型！让我们看看它在预测图像方面的表现如何。让我们加载一个随机的猫、狗和 Elon Musk 图像。</p><pre class="ks kt ku kv gt pt ps pu pv aw pw bi"><span id="9ef7" class="px my it ps b gy py pz l qa qb">elon_with_disguise = load_image('elon_with_disguise.png')<br/>elon_without_disguise = load_image('elon_no_disguise.jpg')</span><span id="2c5f" class="px my it ps b gy qc pz l qa qb">random_cat = random.choice(os.listdir('images/cat/'))<br/>cat_path = os.path.join('images/cat',random_cat)<br/>cat = load_image(cat_path)</span><span id="99b9" class="px my it ps b gy qc pz l qa qb">random_dog = random.choice(os.listdir('images/dog/'))<br/>dog_path = os.path.join('images/dog',random_dog)<br/>dog = load_image(dog_path)</span></pre><p id="1515" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">要检查图像运行(在每个单独的单元格中):</p><pre class="ks kt ku kv gt pt ps pu pv aw pw bi"><span id="8e3f" class="px my it ps b gy py pz l qa qb">tf.keras.preprocessing.image.load_img('elon_with_disguise.png', target_size=(224,224))</span><span id="4e32" class="px my it ps b gy qc pz l qa qb">tf.keras.preprocessing.image.load_img('elon_no_disguise.jpg', target_size=(224,224))</span><span id="1042" class="px my it ps b gy qc pz l qa qb">tf.keras.preprocessing.image.load_img(cat_path, target_size=(224,224))</span><span id="055f" class="px my it ps b gy qc pz l qa qb">tf.keras.preprocessing.image.load_img(dog_path, target_size=(224,224))</span></pre><p id="a43a" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">对于实际预测，我们得到:</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi kr"><img src="../Images/312dd1de186abb90706fa02cb3dcafaa.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*SFFZYMxxtMTtaDfTB0WCFg.png"/></div></div></figure><p id="1567" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">伪装伊隆的尝试不错，但我们的模特看穿了这一点！</p></div><div class="ab cl of og hx oh" role="separator"><span class="oi bw bk oj ok ol"/><span class="oi bw bk oj ok ol"/><span class="oi bw bk oj ok"/></div><div class="im in io ip iq"><h1 id="8d35" class="mx my it bd mz na om nc nd ne on ng nh ki oo kj nj kl op km nl ko oq kp nn no bi translated">结束语</h1><p id="db76" class="pw-post-body-paragraph ld le it lf b lg nr kd li lj ns kg ll lm qq lo lp lq qr ls lt lu qs lw lx ly im bi translated">在<a class="ae ow" href="https://twitter.com/boslerfabian" rel="noopener ugc nofollow" target="_blank">推特</a>上关注我，在那里你可以见到我可爱的机器人给你发送最新最棒的当然也是随机的内容。我可能很快会写一篇关于这个的文章。</p><p id="1873" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">更严重的是，如果你想聊天，请联系 LinkedIn。</p><p id="9b5e" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">看看我在 Medium 上写的其他文章，如果你喜欢这篇文章，请留下一两个掌声。</p><p id="6b49" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated"><strong class="lf jd">不断学习、探索、建设，自己动手就好！</strong></p></div></div>    
</body>
</html>