<html>
<head>
<title>A Simple Explanation of the Bag-of-Words Model</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">单词袋模型的简单解释</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/a-simple-explanation-of-the-bag-of-words-model-b88fc4f4971?source=collection_archive---------5-----------------------#2019-12-11">https://towardsdatascience.com/a-simple-explanation-of-the-bag-of-words-model-b88fc4f4971?source=collection_archive---------5-----------------------#2019-12-11</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="6e15" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">快速、简单地介绍单词袋模型以及如何用 Python 实现它。</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/46728e05e163820425912289aedddd15.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*sVd-1GJJozTJ3ElCFw6IQw.jpeg"/></div></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk">Photo by <a class="ae ky" href="https://unsplash.com/@impatrickt?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank">Patrick Tomasso</a> on <a class="ae ky" href="https://unsplash.com/s/photos/words?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><p id="c2d1" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">单词袋</strong> (BOW)模型是一种通过计算每个单词出现的次数将任意文本转换成<strong class="lb iu">固定长度向量</strong>的表示方法。这个过程通常被称为<strong class="lb iu">矢量化</strong>。</p><p id="6653" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们用一个例子来理解这个。假设我们想要向量化以下内容:</p><ul class=""><li id="8560" class="lv lw it lb b lc ld lf lg li lx lm ly lq lz lu ma mb mc md bi translated">猫坐下了</li><li id="2ce5" class="lv lw it lb b lc mf lf mg li mh lm mi lq mj lu ma mb mc md bi translated">猫坐在帽子里</li><li id="02a1" class="lv lw it lb b lc mf lf mg li mh lm mi lq mj lu ma mb mc md bi translated"><em class="me">戴帽子的猫</em></li></ul><p id="2eaa" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们将每一个都称为文本<strong class="lb iu">文档</strong>。</p><h1 id="fd02" class="mk ml it bd mm mn mo mp mq mr ms mt mu jz mv ka mw kc mx kd my kf mz kg na nb bi translated">第一步:确定词汇</h1><p id="4802" class="pw-post-body-paragraph kz la it lb b lc nc ju le lf nd jx lh li ne lk ll lm nf lo lp lq ng ls lt lu im bi translated">我们首先定义我们的<strong class="lb iu">词汇表</strong>，它是在我们的文档集中找到的所有单词的集合。在上述三个文档中唯一找到的单词是:<code class="fe nh ni nj nk b">the</code>、<code class="fe nh ni nj nk b">cat</code>、<code class="fe nh ni nj nk b">sat</code>、<code class="fe nh ni nj nk b">in</code>、<code class="fe nh ni nj nk b">the</code>、<code class="fe nh ni nj nk b">hat</code>和<code class="fe nh ni nj nk b">with</code>。</p><h1 id="a1c1" class="mk ml it bd mm mn mo mp mq mr ms mt mu jz mv ka mw kc mx kd my kf mz kg na nb bi translated">第二步:计数</h1><p id="c03c" class="pw-post-body-paragraph kz la it lb b lc nc ju le lf nd jx lh li ne lk ll lm nf lo lp lq ng ls lt lu im bi translated">为了对我们的文档进行矢量化，我们所要做的就是<strong class="lb iu">计算每个单词出现的次数</strong>:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nl"><img src="../Images/9c8086228edeff56cde7779ce67fed36.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*3IACMnNpwVlCl8kSTJocPA.png"/></div></div></figure><p id="fa86" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">现在每个文档都有长度为 6 的向量了！</p><ul class=""><li id="0032" class="lv lw it lb b lc ld lf lg li lx lm ly lq lz lu ma mb mc md bi translated"><em class="me">猫坐着</em> : <code class="fe nh ni nj nk b">[1, 1, 1, 0, 0, 0]</code></li><li id="0a55" class="lv lw it lb b lc mf lf mg li mh lm mi lq mj lu ma mb mc md bi translated">猫坐在帽子里</li><li id="1c9e" class="lv lw it lb b lc mf lf mg li mh lm mi lq mj lu ma mb mc md bi translated"><em class="me">戴帽子的猫</em> : <code class="fe nh ni nj nk b">[2, 1, 0, 0, 1, 1]</code></li></ul><p id="b954" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">请注意，当我们使用 BOW 时，我们丢失了上下文信息，例如，单词在文档中出现的位置。这就像一个字面上的<strong class="lb iu">单词包</strong>:它只告诉你<em class="me">哪些</em>单词出现在文档中，而不是<em class="me">它们出现在</em>的什么地方。</p><h1 id="f80a" class="mk ml it bd mm mn mo mp mq mr ms mt mu jz mv ka mw kc mx kd my kf mz kg na nb bi translated">在 Python 中实现 BOW</h1><p id="c7d5" class="pw-post-body-paragraph kz la it lb b lc nc ju le lf nd jx lh li ne lk ll lm nf lo lp lq ng ls lt lu im bi translated">既然您已经知道了 BOW 是什么，我猜您可能需要实现它。下面是我的首选方法，它使用了<a class="ae ky" href="https://keras.io/preprocessing/text/" rel="noopener ugc nofollow" target="_blank"> Keras 的 Tokenizer 类</a>:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nm nn l"/></div></figure><p id="faa3" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">运行该代码会给我们带来:</p><pre class="kj kk kl km gt no nk np nq aw nr bi"><span id="c45a" class="ns ml it nk b gy nt nu l nv nw">Vocabulary: ['the', 'cat', 'sat', 'hat', 'in', 'with']<br/>[[0. 1. 1. 1. 0. 0. 0.]<br/> [0. 2. 1. 1. 1. 1. 0.]<br/> [0. 2. 1. 0. 1. 0. 1.]]</span></pre><p id="ba19" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">注意，这里的向量长度是 7，而不是 6，因为在开头有额外的<code class="fe nh ni nj nk b">0</code>元素。这是一个无关紧要的细节——Keras 储量指数<code class="fe nh ni nj nk b">0</code>并且从来不把它分配给任何单词。</p><h1 id="30ca" class="mk ml it bd mm mn mo mp mq mr ms mt mu jz mv ka mw kc mx kd my kf mz kg na nb bi translated">BOW 有什么用？</h1><p id="4ded" class="pw-post-body-paragraph kz la it lb b lc nc ju le lf nd jx lh li ne lk ll lm nf lo lp lq ng ls lt lu im bi translated">尽管是一个相对基本的模型，BOW 经常被用于自然语言处理任务，如文本分类。它的优势在于它的简单性:它的计算成本很低，有时当定位或上下文信息不相关时，越简单越好。</p><p id="e9c6" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我已经写了一篇使用 BOW 进行亵渎检测的博文——如果你对 BOW 的实际应用感到好奇，就来看看吧！</p></div><div class="ab cl nx ny hx nz" role="separator"><span class="oa bw bk ob oc od"/><span class="oa bw bk ob oc od"/><span class="oa bw bk ob oc"/></div><div class="im in io ip iq"><p id="689e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><em class="me">最初发表于</em><a class="ae ky" href="https://victorzhou.com/blog/bag-of-words/" rel="noopener ugc nofollow" target="_blank">T5【https://victorzhou.com】</a><em class="me">。</em></p></div></div>    
</body>
</html>