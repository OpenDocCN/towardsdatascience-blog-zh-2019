<html>
<head>
<title>Harnessing The Power Of Uncertainty</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">驾驭不确定性的力量</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/harnessing-the-power-of-uncertainty-3ad9431e595c?source=collection_archive---------24-----------------------#2019-10-30">https://towardsdatascience.com/harnessing-the-power-of-uncertainty-3ad9431e595c?source=collection_archive---------24-----------------------#2019-10-30</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="38d4" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">梯度推进树、逻辑回归和深度学习——你可以在你想要的每个 ML 模型中进行，并从你的机器学习模型中实现更多。</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/8def364934fed86dddefbc48439ea4b9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*b3zqY1p0lm7z--g7y86T1g.png"/></div></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk"><a class="ae kv" href="https://unsplash.com/photos/gF6HdRlyJ5o" rel="noopener ugc nofollow" target="_blank">p</a>hoto by <a class="ae kv" href="https://unsplash.com/@lacarta" rel="noopener ugc nofollow" target="_blank">Santiago Lacarta</a> on <a class="ae kv" href="https://unsplash.com" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><p id="37ed" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">让我们从想象开始，例如，给定几张狗品种的照片作为训练数据，我们有一个训练好的模型——当用户上传他的狗的照片时——假设的网站应该以相当高的可信度返回一个预测。</p><p id="6904" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">但是如果一个用户上传了一张猫的照片，并要求网站决定狗的品种，该怎么办呢？</p><p id="e7e7" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">该模型已经在不同品种的狗的照片上进行了训练，并且(希望)已经学会很好地区分它们。但是该模型以前从未见过猫，并且猫的照片会位于该模型被训练的数据分布之外。这个说明性的例子可以<br/>扩展到更严重的设置，例如诊断系统从未观察过的结构的 MRI 扫描，或者自动汽车转向系统从未训练过的场景。</p><p id="4d6f" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在这种情况下，模型的一个可能的预期行为是<br/>返回一个预测(试图从我们观察到的数据外推)，但返回一个带有附加信息的答案，即该点位于数据分布之外(见图 1.2 中回归情况的简单描述)。也就是说，我们希望我们的模型拥有一些数量来传达这种输入的高度不确定性(或者，传达低置信度)。</p><p id="6cad" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在这篇文章中，我将介绍如何挖掘模型不确定性的方法。<br/>我会在 3 种不同的模型上展示:L <a class="ae kv" href="https://www.wikiwand.com/en/Logistic_regression" rel="noopener ugc nofollow" target="_blank">逻辑回归</a>、<a class="ae kv" href="https://www.wikiwand.com/en/Gradient_boosting" rel="noopener ugc nofollow" target="_blank">梯度推进树</a> s、D <a class="ae kv" href="https://www.wikiwand.com/en/Deep_learning" rel="noopener ugc nofollow" target="_blank">深度学习</a>。这篇文章是写给那些已经熟悉这些算法和架构的人的。</p><h2 id="03c1" class="ls lt iq bd lu lv lw dn lx ly lz dp ma lf mb mc md lj me mf mg ln mh mi mj mk bi translated">准备好了吗？开始吧！</h2><h1 id="4a66" class="ml lt iq bd lu mm mn mo lx mp mq mr ma jw ms jx md jz mt ka mg kc mu kd mj mv bi translated">驾驭不确定性的力量</h1><p id="7764" class="pw-post-body-paragraph kw kx iq ky b kz mw jr lb lc mx ju le lf my lh li lj mz ll lm ln na lp lq lr ij bi translated">为了利用你的模型不确定性的力量，你需要知道你的模型的分布(大多数时候很容易假设它接近正态分布)。</p><p id="9dd7" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">当分布已知时，您可以计算您的模型均值和标准差。<br/>标准差是模型的不确定性，平均值是模型的结果。您现在可以将它用于简单的 UCB:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi nb"><img src="../Images/e9164177612ace4cf58b721dd422d806.png" data-original-src="https://miro.medium.com/v2/resize:fit:510/format:webp/1*VRnmPL1mV2MIzAHVAszGjA.png"/></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk">3 is just a factor for the sigma, it can be any number, the larger the factor the more weights on the exploration</figcaption></figure><p id="7bb9" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这是一个例子，你也可以在 Tompson 采样中使用，假设你的模型是正态分布的。</p><h1 id="5fcb" class="ml lt iq bd lu mm mn mo lx mp mq mr ma jw ms jx md jz mt ka mg kc mu kd mj mv bi translated">梯度推进树</h1><p id="d769" class="pw-post-body-paragraph kw kx iq ky b kz mw jr lb lc mx ju le lf my lh li lj mz ll lm ln na lp lq lr ij bi translated">梯度推进树是一种强大的算法，可能是当今最常用的算法。<br/>我觉得最常见的算法有:XGBoost，LightGBM，和 CatBoost。在这篇文章中，我将用 CatBoost 展示这个例子，但是同样的想法可以在所有的例子中实现，也可以在像 Random Forest 这样的常规决策树中实现。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nc"><img src="../Images/2e7c2474a2b64dfe855ef787fbb6e3ac.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*uB0-RSsqIudK2iaGhFQuHw.png"/></div></div></figure><p id="f3d8" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">为了得到你的决策树模型的不确定性，你需要分别收集每棵树的预测。如果你使用分类，得到每棵树分类的概率。如果使用回归，请使用回归的值。</p><p id="8045" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">当每个预测都有一个来自每棵树的概率列表时，可以从每个预测的概率列表中计算平均值和标准偏差。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nd ne l"/></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk">example with CatBoost how to get each tree prediction, and from those predictions calculate the mean and the std of each prediction in order to get and use the uncertainty</figcaption></figure><h1 id="4506" class="ml lt iq bd lu mm mn mo lx mp mq mr ma jw ms jx md jz mt ka mg kc mu kd mj mv bi translated">深度学习</h1><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nf"><img src="../Images/9f5847339851001f6b77b60c5390ee66.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*uxpH46OpTIj63j1MKQ-T2Q.png"/></div></div></figure><p id="6cd1" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我开始研究模型中的不确定性以提高准确性的原因是因为深度学习。我认为把深度学习的不确定性中的“联合国”放在一起的人是<a class="ae kv" href="http://www.cs.ox.ac.uk/people/yarin.gal/website/" rel="noopener ugc nofollow" target="_blank">亚林·加尔</a>，他的论文是“<a class="ae kv" href="http://mlg.eng.cam.ac.uk/yarin/thesis/thesis.pdf" rel="noopener ugc nofollow" target="_blank">深度学习的不确定性</a>”。他的主要想法是使用辍学，谁更常用于训练，以避免过度拟合，也在预测。在预测时，我们也将使用 dropout，并运行相同的预测 X 次，因为 dropout 是随机选择的，每个预测我们将得到相同预测的一些不同结果。有了这些不同的结果，我们可以很容易地计算平均值和标准差。</p><p id="5c79" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">当你有均值和标准差时，这是和之前一样的解。</p><h1 id="9335" class="ml lt iq bd lu mm mn mo lx mp mq mr ma jw ms jx md jz mt ka mg kc mu kd mj mv bi translated">逻辑回归</h1><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi ng"><img src="../Images/e43916ef80dbbb364777a2ec369c3cd0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1280/format:webp/0*3ng5ol8Li128eBfp.png"/></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk">Sigmoid Function Graph</figcaption></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi nh"><img src="../Images/47fe1c698b55d2e7fce1a14a382d9366.png" data-original-src="https://miro.medium.com/v2/resize:fit:542/format:webp/0*9BEeUGSkwgQcSt6R.png"/></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk">The formula of a sigmoid function | Image: Analytics India Magazine</figcaption></figure><p id="2344" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我首先要说的是，这里我们没有得到模型的不确定性，但是我们理解我们训练数据的不确定性。<br/>这里的想法是在来自训练集的不同切割上训练相同的模型。要获得模型的不确定性，您需要做以下工作:</p><ol class=""><li id="6107" class="ni nj iq ky b kz la lc ld lf nk lj nl ln nm lr nn no np nq bi translated">将你的训练集分成 N 份</li><li id="560f" class="ni nj iq ky b kz nr lc ns lf nt lj nu ln nv lr nn no np nq bi translated">每次切割将随机选择 70%–80%的训练集记录。</li><li id="2849" class="ni nj iq ky b kz nr lc ns lf nt lj nu ln nv lr nn no np nq bi translated">在每次切割中，您将训练一个逻辑模型(最后您将有 N 个模型)</li><li id="b919" class="ni nj iq ky b kz nr lc ns lf nt lj nu ln nv lr nn no np nq bi translated">对所有 N 个定型模型运行每个预测</li><li id="af1b" class="ni nj iq ky b kz nr lc ns lf nt lj nu ln nv lr nn no np nq bi translated">计算所有预测的平均值和标准差。</li></ol><h1 id="3b14" class="ml lt iq bd lu mm mn mo lx mp mq mr ma jw ms jx md jz mt ka mg kc mu kd mj mv bi translated">包扎</h1><p id="fd70" class="pw-post-body-paragraph kw kx iq ky b kz mw jr lb lc mx ju le lf my lh li lj mz ll lm ln na lp lq lr ij bi translated">在这篇文章中，我们回顾了获得模型不确定性的方法。<br/>最常见的方法是深度学习，但你也看到了在 GDT 和逻辑回归模型中这样做的方法。</p><p id="c0ae" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">正如我说过的，模型不确定性的用途可以是在打开模型时进行更多的探索，但它也可以提高精确度。如果您的数据可以在对这些项目了解较少的情况下获得新项目，那么模型不确定性在这里会非常有用。</p><p id="36eb" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">如果您有任何问题或需要更好地了解它如何帮助您，以及如何在技术上做到这一点，请通过 Linkedin 联系我。</p></div></div>    
</body>
</html>