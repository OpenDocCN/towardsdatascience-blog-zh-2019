<html>
<head>
<title>The Data Scientist’s Guide to Selecting Machine Learning Predictive Models in Python</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">在 Python 中选择机器学习预测模型的数据科学家指南</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/the-beginners-guide-to-selecting-machine-learning-predictive-models-in-python-f2eb594e4ddc?source=collection_archive---------6-----------------------#2019-07-16">https://towardsdatascience.com/the-beginners-guide-to-selecting-machine-learning-predictive-models-in-python-f2eb594e4ddc?source=collection_archive---------6-----------------------#2019-07-16</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="4ebb" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">了解如何为您的 ML 项目选择最佳模型。</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/8ec72bb734ab400b1caa7bd5f1254d79.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*xAyIFJvU3jnustQj"/></div></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk">Photo by <a class="ae ky" href="https://unsplash.com/@franckinjapan?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Franck V.</a> on <a class="ae ky" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><p id="3872" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">本文提供了 Python 中一些预测性机器学习模型的快速概述，并为针对数据科学问题选择正确的模型提供了指导。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi lv"><img src="../Images/ca6dc97c3c435d909ee67a74e816f356.png" data-original-src="https://miro.medium.com/v2/resize:fit:1140/format:webp/1*hKaX6yElKhvBxVXnJ3YqXQ.png"/></div></figure><p id="4091" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">近年来，随着机器计算能力的提高，预测建模经历了一场革命。我们现在能够在多个内核上以数 GHz 的速度运行数千个模型，使预测建模比以往任何时候都更高效、更经济。虚拟机，例如亚马逊网络服务(AWS)提供的虚拟机，为我们提供了实际上无限的定量能力(当然成本很高！).</p><p id="2fc9" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">然而，每个数据科学家面临的一个基本问题是:</p><blockquote class="lw"><p id="4e52" class="lx ly it bd lz ma mb mc md me mf lu dk translated">哪种预测模型更适合手头的问题？</p></blockquote><p id="6e6a" class="pw-post-body-paragraph kz la it lb b lc mg ju le lf mh jx lh li mi lk ll lm mj lo lp lq mk ls lt lu im bi translated">回答这个问题可以归结为每个机器学习问题中的一个基本问题:</p><blockquote class="lw"><p id="695a" class="lx ly it bd lz ma mb mc md me mf lu dk translated">你试图预测的目标是什么样子的？</p></blockquote><p id="01d6" class="pw-post-body-paragraph kz la it lb b lc mg ju le lf mh jx lh li mi lk ll lm mj lo lp lq mk ls lt lu im bi translated">如果你试图预测一个<strong class="lb iu">连续目标</strong>，那么你将需要一个<strong class="lb iu">回归模型</strong>。</p><p id="97e4" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">但是如果你试图预测一个<strong class="lb iu">离散目标</strong>，那么你将需要一个<strong class="lb iu">分类模型</strong>。</p><h1 id="c9db" class="ml mm it bd mn mo mp mq mr ms mt mu mv jz mw ka mx kc my kd mz kf na kg nb nc bi translated"><strong class="ak">Python 中的回归模型:</strong></h1><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nd"><img src="../Images/ed2e633a88b8c5ed3ee6233003bce535.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*eNek2ILdIYAFBhen.png"/></div></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk">Regression Modeling — <a class="ae ky" href="https://en.wikipedia.org/wiki/Regression_analysis" rel="noopener ugc nofollow" target="_blank">https://en.wikipedia.org/wiki/Regression_analysis</a></figcaption></figure><ul class=""><li id="5147" class="ne nf it lb b lc ld lf lg li ng lm nh lq ni lu nj nk nl nm bi translated"><strong class="lb iu">线性回归:</strong>当您预测一个连续模型，并且您的目标在-∞和+∞(如温度)之间变化时，最佳模型是线性回归模型。根据您可能拥有的预测值(即特征)的数量，您可以使用简单线性回归(SLR)或多元线性回归(MLR)。这两者在 Python 中使用相同的包:<code class="fe nn no np nq b">sklearn.linear_model.LinearRegression()</code> <a class="ae ky" href="https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html" rel="noopener ugc nofollow" target="_blank">关于这一点的文档可以在这里找到</a>。</li><li id="8bf7" class="ne nf it lb b lc nr lf ns li nt lm nu lq nv lu nj nk nl nm bi translated"><strong class="lb iu">伽马回归:</strong>当对具有 0 到+∞分布的目标进行预测时，那么除了线性回归之外，具有<code class="fe nn no np nq b">Gamma Distribution</code>的广义线性模型(GLM)可用于预测。关于 GLM 的详细信息可以在这里找到。</li></ul><h1 id="69f8" class="ml mm it bd mn mo mp mq mr ms mt mu mv jz mw ka mx kc my kd mz kf na kg nb nc bi translated">Python 中的分类模型</h1><p id="cc81" class="pw-post-body-paragraph kz la it lb b lc nw ju le lf nx jx lh li ny lk ll lm nz lo lp lq oa ls lt lu im bi translated">Python 提供了许多分类模型。在这一节中，我们回顾一下<code class="fe nn no np nq b"><a class="ae ky" href="https://scikit-learn.org" rel="noopener ugc nofollow" target="_blank">scikit-learn</a></code>库中一些广泛使用的模型。</p><ul class=""><li id="1951" class="ne nf it lb b lc ld lf lg li ng lm nh lq ni lu nj nk nl nm bi translated"><strong class="lb iu">逻辑回归(LogReg): </strong>该模型用于预测多类目标。与 K_Nearest Neighbors (kNN)不同，该模型在线性情况下工作良好。SciKit-Learn 在其线性模型库中提供了这个包:<code class="fe nn no np nq b">sklearn.linear_model.LogisticRegression()</code> <a class="ae ky" href="https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html" rel="noopener ugc nofollow" target="_blank">关于这个的文档可以在这里找到</a>。</li><li id="1d01" class="ne nf it lb b lc nr lf ns li nt lm nu lq nv lu nj nk nl nm bi translated"><strong class="lb iu"> KNN(或 K 近邻)</strong>为非参数模型，其中 logistic 回归为参数模型。一般来说，<strong class="lb iu"> KNN </strong>比 LogReg 模型效率低，支持非线性解。该模型根据特定类的最近邻居数量(顾名思义)对目标进行分类。这里可以找到<code class="fe nn no np nq b">sklearn.neighbors.KNeighborsClassifer</code> <a class="ae ky" href="https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html" rel="noopener ugc nofollow" target="_blank">的文档。</a>需要注意的是，<code class="fe nn no np nq b">sklearn</code>还提供了一个<code class="fe nn no np nq b">KNeighborsRegressor</code>，本文未涉及。</li></ul><h1 id="10ca" class="ml mm it bd mn mo mp mq mr ms mt mu mv jz mw ka mx kc my kd mz kf na kg nb nc bi translated">分类问题的混淆矩阵</h1><p id="aa76" class="pw-post-body-paragraph kz la it lb b lc nw ju le lf nx jx lh li ny lk ll lm nz lo lp lq oa ls lt lu im bi translated">我的关于<strong class="lb iu"/><a class="ae ky" href="https://medium.com/@minaienick/evaluating-machine-learning-classification-problems-in-python-5-1-metrics-that-matter-792c6faddf5" rel="noopener"><strong class="lb iu">用 Python 评估机器学习分类问题:重要的 5+1 度量</strong> </a>的文章提供了分类性能度量的概述，以及这些模型的<strong class="lb iu">混淆矩阵</strong>和<strong class="lb iu">混淆度量</strong>的定义。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ob"><img src="../Images/3e9795a0a50879ae9ba508a93038d0c2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1094/format:webp/0*WeLYu4WZ0qS9QEbt.png"/></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk">Structure of a Binary Classification Confusion Matrix <a class="ae ky" href="https://medium.com/@minaienick/evaluating-machine-learning-classification-problems-in-python-5-1-metrics-that-matter-792c6faddf5" rel="noopener">https://medium.com/@minaienick/evaluating-machine-learning-classification-problems-in-python-5-1-metrics-that-matter-792c6faddf5</a></figcaption></figure><h1 id="6d09" class="ml mm it bd mn mo mp mq mr ms mt mu mv jz mw ka mx kc my kd mz kf na kg nb nc bi translated">高级分类器/回归器模型</h1><p id="0543" class="pw-post-body-paragraph kz la it lb b lc nw ju le lf nx jx lh li ny lk ll lm nz lo lp lq oa ls lt lu im bi translated">Python 库提供了许多算法，如 SciKit-Learn、XGBoost 和……其中一些算法既提供了分类器又提供了回归器，还提供了许多用于定制的参数。</p><ul class=""><li id="fd44" class="ne nf it lb b lc ld lf lg li ng lm nh lq ni lu nj nk nl nm bi translated"><strong class="lb iu">决策树:</strong>决策树提供可定制的模型，同时也是更加优化的模型的基础，如<strong class="lb iu"> RandomForest </strong>或<strong class="lb iu"> GradientBoosting </strong>。<a class="ae ky" href="https://scikit-learn.org/stable/modules/tree.html" rel="noopener ugc nofollow" target="_blank">文档可在此处找到。</a>决策树是非参数监督学习，因此能够处理异常值和相关变量。但是，它们很容易过度适应训练数据集，用户应该小心这个问题。</li></ul><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi oc"><img src="../Images/8a8f2aa439d3c67497babf80aceee254.png" data-original-src="https://miro.medium.com/v2/resize:fit:1008/format:webp/1*GF3fOgq0x50rgsa1qY8Qbw.png"/></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk">Visualization of a Decision Tree — <a class="ae ky" href="https://scikit-learn.org/stable/modules/tree.html" rel="noopener ugc nofollow" target="_blank">https://scikit-learn.org/stable/modules/tree.html</a></figcaption></figure><ul class=""><li id="08c0" class="ne nf it lb b lc ld lf lg li ng lm nh lq ni lu nj nk nl nm bi translated"><strong class="lb iu"> Bagging 模型(或集成):</strong> Bagging 分类器在原始数据集的随机子集上拟合基本分类器(例如决策树或任何其他分类器)，然后聚合这些分类器以获得最终预测。这可以通过投票或平均来实现。<a class="ae ky" href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.BaggingClassifier.html" rel="noopener ugc nofollow" target="_blank">更多关于</a> <code class="fe nn no np nq b"><a class="ae ky" href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.BaggingClassifier.html" rel="noopener ugc nofollow" target="_blank">sklearn.ensemble.BaggingClassifier</a></code> <a class="ae ky" href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.BaggingClassifier.html" rel="noopener ugc nofollow" target="_blank">的细节可以在这里找到。</a></li></ul><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi od"><img src="../Images/9f867f4ef47b203d664deba1dea0af86.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*nD4DibWC56hwhyrc.png"/></div></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk">Bagging Approach — “Data Mining: Accuracy and Error Measures for Classification and Prediction” , Paola Galdi Roberto Tagliaferri</figcaption></figure><ul class=""><li id="8fc0" class="ne nf it lb b lc ld lf lg li ng lm nh lq ni lu nj nk nl nm bi translated"><strong class="lb iu">随机森林:</strong>随机森林模型类似于装袋模型，但有区别。<a class="ae ky" href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html" rel="noopener ugc nofollow" target="_blank">根据 Sklearn 关于</a> <code class="fe nn no np nq b"><a class="ae ky" href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html" rel="noopener ugc nofollow" target="_blank">sklearn.ensemble.RandomForstClassifie</a>r</code> <a class="ae ky" href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html" rel="noopener ugc nofollow" target="_blank"> : </a> <em class="oe">的文档，“随机森林是一种元估计器，它在数据集的各个子样本上拟合多个决策树分类器，并使用平均来提高预测精度和控制过拟合。子样本大小始终与原始输入样本大小相同，但样本是替换抽取的。</em>这种类型的模型有许多优点，包括高学习速度、可扩展性、模型的非迭代性质(它总是收敛的)。该模型的另一个重要优点是，它可以处理不平衡的情况，并可以利用 bootstrapping 来处理这种情况。但是，该模型可能会占用大量内存，并且可能会过度适应定型数据集。<a class="ae ky" href="https://www.mql5.com/en/articles/3856" rel="noopener ugc nofollow" target="_blank">本文很好地总结了这一模式。</a></li></ul><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi of"><img src="../Images/9be037ec0316217eba379579b457bda6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*OhQmlkMBKH-67tFf.png"/></div></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk">General Scheme of a Random Forest Model — <a class="ae ky" href="https://www.mql5.com/en/articles/3856" rel="noopener ugc nofollow" target="_blank">https://www.mql5.com/en/articles/3856</a></figcaption></figure><ul class=""><li id="20b3" class="ne nf it lb b lc ld lf lg li ng lm nh lq ni lu nj nk nl nm bi translated"><strong class="lb iu">投票模型:</strong>投票模型可以将多个模型打包在一个模型下。Sklearn 文档称之为<a class="ae ky" href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.VotingClassifier.html" rel="noopener ugc nofollow" target="_blank"> <em class="oe">“用于不适合估计器的软投票/多数规则分类器。”</em> </a> <em class="oe"> </em>在这个模型中，可以给每个投票模型分配一个权重，这样不合适的模型就会被打折扣。这类似于 bagging，但适用于不同的模型和不同的权重(Bagging 仅适用于一个基础模型，然后对预测值进行平均)。<code class="fe nn no np nq b"><a class="ae ky" href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.VotingClassifier.html" rel="noopener ugc nofollow" target="_blank">sklearn.ensemble.VotingClassifier</a></code>有关于这款车型的更多细节。</li><li id="343e" class="ne nf it lb b lc nr lf ns li nt lm nu lq nv lu nj nk nl nm bi translated"><strong class="lb iu"> Boosting 模型:</strong>在 Boosting 模型中，每棵树根据其准确性获得一个重要性权重。更精确的模型将具有更高的权重，因此对最终预测的贡献更大。高度不准确的模型将被负权重惩罚，这意味着它们的预测将在最终预测中被逆转。助推模型有多种，但值得注意的有:<code class="fe nn no np nq b"><a class="ae ky" href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingClassifier.html" rel="noopener ugc nofollow" target="_blank">sklearn.ensemble.GradientBoostingClassifier</a></code>和<code class="fe nn no np nq b"><a class="ae ky" href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.AdaBoostClassifier.html" rel="noopener ugc nofollow" target="_blank">sklearn.ensemble.AdaBoostingClassifier</a></code>。</li></ul><h1 id="ff10" class="ml mm it bd mn mo mp mq mr ms mt mu mv jz mw ka mx kc my kd mz kf na kg nb nc bi translated">Scikit-Learn 算法备忘单</h1><p id="9bcb" class="pw-post-body-paragraph kz la it lb b lc nw ju le lf nx jx lh li ny lk ll lm nz lo lp lq oa ls lt lu im bi translated">Scikit-Learn 开发了一个流程图，用于根据样本的特性、特征(或预测值)和目标为机器学习问题选择正确的模型。<a class="ae ky" href="https://scikit-learn.org/stable/tutorial/machine_learning_map/index.html" rel="noopener ugc nofollow" target="_blank">此互动备忘单可在此处找到。</a></p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi og"><img src="../Images/402090e693f89cad64b89a681e1fce8c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*TZFjp3hb3tVe8SAB.png"/></div></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk">Scikit-learn Algorithm Cheat-Sheet (<a class="ae ky" href="https://scikit-learn.org/stable/tutorial/machine_learning_map/index.html" rel="noopener ugc nofollow" target="_blank">https://scikit-learn.org/stable/tutorial/machine_learning_map/index.html</a>)</figcaption></figure><h1 id="18ec" class="ml mm it bd mn mo mp mq mr ms mt mu mv jz mw ka mx kc my kd mz kf na kg nb nc bi translated">最后的想法…</h1><p id="f104" class="pw-post-body-paragraph kz la it lb b lc nw ju le lf nx jx lh li ny lk ll lm nz lo lp lq oa ls lt lu im bi translated">当谈到机器学习预测模型时，这篇文章几乎没有触及表面。为此目的已经开发了许多包(并且仍在增加),这将需要大量的时间来复习和学习。学习这些模型的最好方法是在实际项目中使用它们。我希望这篇文章可以作为为您的数据科学项目选择正确模型的指南，并帮助您完成数据科学之旅。</p></div><div class="ab cl oh oi hx oj" role="separator"><span class="ok bw bk ol om on"/><span class="ok bw bk ol om on"/><span class="ok bw bk ol om"/></div><div class="im in io ip iq"><p id="4c68" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu"> <em class="oe">尼克·米奈，</em> </strong> <em class="oe">博士(</em> <a class="ae ky" href="https://www.linkedin.com/in/nickminaie/" rel="noopener ugc nofollow" target="_blank"> <em class="oe"> LinkedIn 简介</em> </a> <em class="oe">)是一位高级顾问和富有远见的数据科学家，代表了领导技能、世界级数据科学专业知识、商业敏锐度和领导组织变革能力的独特组合。他的使命是推进人工智能(AI)和机器学习在行业中的实践。</em></p></div></div>    
</body>
</html>