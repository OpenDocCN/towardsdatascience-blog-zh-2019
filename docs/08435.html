<html>
<head>
<title>Recurrent Neural Networks (RNN) Explained — the ELI5 way</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">递归神经网络(RNN)解释 ELI5 方式</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/recurrent-neural-networks-rnn-explained-the-eli5-way-3956887e8b75?source=collection_archive---------6-----------------------#2019-11-16">https://towardsdatascience.com/recurrent-neural-networks-rnn-explained-the-eli5-way-3956887e8b75?source=collection_archive---------6-----------------------#2019-11-16</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><h2 id="180d" class="ir is it bd b dl iu iv iw ix iy iz dk ja translated" aria-label="kicker paragraph">ELI5 项目机器学习</h2><div class=""/><figure class="gl gn ka kb kc kd gh gi paragraph-image"><div role="button" tabindex="0" class="ke kf di kg bf kh"><div class="gh gi jz"><img src="../Images/7782ca1316de2adea1fca86f6f59275f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*1GybhuEdwGPu6Ftq"/></div></div><figcaption class="kk kl gj gh gi km kn bd b be z dk">Photo by <a class="ae ko" href="https://unsplash.com/@magrolino?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Michael Fruehmann</a> on <a class="ae ko" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><p id="8cb5" class="pw-post-body-paragraph kp kq it kr b ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">序列建模是预测下一个单词/字母的任务。序列模型计算一定数量的单词在特定序列中出现的概率。与 FNN 和 CNN 不同，在序列建模中，当前输出不仅依赖于当前输入，还依赖于先前输入。在序列模型中，输入的长度是不固定的。</p><blockquote class="ln lo lp"><p id="9fda" class="kp kq lq kr b ks kt ku kv kw kx ky kz lr lb lc ld ls lf lg lh lt lj lk ll lm im bi translated"><strong class="kr jd"> <em class="it">引用注:</em> </strong> <em class="it">本文的内容和结构是基于我对四分之一实验室深度学习讲座——</em><a class="ae ko" href="https://padhai.onefourthlabs.in/" rel="noopener ugc nofollow" target="_blank"><em class="it">pad hai</em></a><em class="it">的理解。</em></p></blockquote><h1 id="bf3a" class="lu lv it bd lw lx ly lz ma mb mc md me mf mg mh mi mj mk ml mm mn mo mp mq mr bi translated">递归神经网络</h1><p id="5ee8" class="pw-post-body-paragraph kp kq it kr b ks ms ku kv kw mt ky kz la mu lc ld le mv lg lh li mw lk ll lm im bi translated"><strong class="kr jd">递归神经网络(RNN) </strong>是一种神经网络，前一步的输出作为当前步骤的输入。</p><figure class="my mz na nb gt kd gh gi paragraph-image"><div role="button" tabindex="0" class="ke kf di kg bf kh"><div class="gh gi mx"><img src="../Images/da380305e2ca7c931ca6892ade65926c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*uwlfcVIiHHr-zF_0.png"/></div></div></figure><p id="825b" class="pw-post-body-paragraph kp kq it kr b ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">RNN 主要用于，</p><ul class=""><li id="071d" class="nc nd it kr b ks kt kw kx la ne le nf li ng lm nh ni nj nk bi translated"><strong class="kr jd">序列分类</strong> —情感分类&amp;视频分类</li><li id="66d8" class="nc nd it kr b ks nl kw nm la nn le no li np lm nh ni nj nk bi translated"><strong class="kr jd">序列标注</strong> —词性标注&amp;命名实体识别</li><li id="98ee" class="nc nd it kr b ks nl kw nm la nn le no li np lm nh ni nj nk bi translated"><strong class="kr jd">序列生成</strong> —机器翻译&amp;音译</li></ul><h1 id="38d5" class="lu lv it bd lw lx ly lz ma mb mc md me mf mg mh mi mj mk ml mm mn mo mp mq mr bi translated">序列分类</h1><p id="7c30" class="pw-post-body-paragraph kp kq it kr b ks ms ku kv kw mt ky kz la mu lc ld le mv lg lh li mw lk ll lm im bi translated">在这一节中，我们将讨论如何使用 RNN 来完成序列分类的任务。在序列分类中，我们将得到一个句子的语料库和相应的标签，即…句子的情感，无论是肯定的还是否定的。</p><figure class="my mz na nb gt kd gh gi paragraph-image"><div role="button" tabindex="0" class="ke kf di kg bf kh"><div class="gh gi nq"><img src="../Images/30b6050a141b0dd0a33aa3fbb3ccff65.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*t9MU3YJ9vVgZN1MBZyW8xw.png"/></div></div></figure><p id="c8cf" class="pw-post-body-paragraph kp kq it kr b ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">在这种情况下，我们不需要在输入的每个单词后输出，而是我们只需要在阅读整个句子后理解情绪，即…积极或消极。</p><figure class="my mz na nb gt kd gh gi paragraph-image"><div role="button" tabindex="0" class="ke kf di kg bf kh"><div class="gh gi nr"><img src="../Images/8432466bcece6809370cd18927269ddb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*fVmdM-fazLd8PGBl.png"/></div></div></figure><p id="a3c2" class="pw-post-body-paragraph kp kq it kr b ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">从上图可以看出，输入的句子长度不等。在将数据输入 RNN 之前，我们需要预处理数据，以使输入序列长度相等(输入矩阵的维数固定为 mxn)。输入的单词应该被转换成一个独热码表示向量。</p><h2 id="151b" class="ns lv it bd lw nt nu dn ma nv nw dp me la nx ny mi le nz oa mm li ob oc mq iz bi translated">预处理数据</h2><p id="3dfe" class="pw-post-body-paragraph kp kq it kr b ks ms ku kv kw mt ky kz la mu lc ld le mv lg lh li mw lk ll lm im bi translated">在处理过程中，我们定义了一些特殊字符，如序列的开始，序列的结束。</p><figure class="my mz na nb gt kd gh gi paragraph-image"><div role="button" tabindex="0" class="ke kf di kg bf kh"><div class="gh gi od"><img src="../Images/de45d3c43ec7a9398db617709aafff6c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*CjjmWd6sN4tvTUdqaVdBgA.png"/></div></div></figure><p id="2593" class="pw-post-body-paragraph kp kq it kr b ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">所有输入序列都附加有“<strong class="kr jd"><em class="lq">”</em></strong>”&lt;SOS&gt;字符，以表示字符序列的开始。序列的末尾追加“<strong class="kr jd"> <em class="lq">序列结束</em></strong>”&lt;EOS&gt;字符来标记字符序列的结束。由于所有字符序列必须与相应输入层定义的长度相同，因此需要的地方会应用<strong class="kr jd">填充</strong>。</p><p id="4b20" class="pw-post-body-paragraph kp kq it kr b ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">我们应用填充的方式是，</p><ul class=""><li id="6e16" class="nc nd it kr b ks kt kw kx la ne le nf li ng lm nh ni nj nk bi translated">找出所有序列的最大输入长度(比如 10)</li><li id="fc41" class="nc nd it kr b ks nl kw nm la nn le no li np lm nh ni nj nk bi translated">将特殊字<strong class="kr jd"> &lt;填充&gt; </strong>添加到所有较短的序列中，使它们具有相同的长度(本例中为 10)。</li></ul><p id="87e1" class="pw-post-body-paragraph kp kq it kr b ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">一旦我们做了预处理(添加特殊字符)，我们必须将这些包含特殊字符的单词转换成一个热点向量表示，并将它们输入网络。</p><p id="f30f" class="pw-post-body-paragraph kp kq it kr b ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">关于填充需要注意的要点是:</p><ul class=""><li id="b50e" class="nc nd it kr b ks kt kw kx la ne le nf li ng lm nh ni nj nk bi translated">填充只是为了确保输入序列大小一致。</li><li id="8a32" class="nc nd it kr b ks nl kw nm la nn le no li np lm nh ni nj nk bi translated">RNN 中的计算仅执行到“<strong class="kr jd"> <em class="lq">序列结束</em> </strong>”特殊字符，即…填充不被认为是网络的输入。</li></ul><h1 id="ee33" class="lu lv it bd lw lx ly lz ma mb mc md me mf mg mh mi mj mk ml mm mn mo mp mq mr bi translated">序列标记</h1><p id="7567" class="pw-post-body-paragraph kp kq it kr b ks ms ku kv kw mt ky kz la mu lc ld le mv lg lh li mw lk ll lm im bi translated">词性标注是对序列中每个单词的<strong class="kr jd">词性</strong>标签进行标注(预测)的任务。同样，在这个问题中，当前时间步长的输出不仅取决于当前输入(当前字)，还取决于先前的输入。例如，如果我们知道前面的单词是形容词，那么将单词“movie”标记为名词<strong class="kr jd">的概率会更高。</strong></p><figure class="my mz na nb gt kd gh gi paragraph-image"><div role="button" tabindex="0" class="ke kf di kg bf kh"><div class="gh gi oe"><img src="../Images/f021937d4414b96a8932b8f97474f983.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*F4FjwTqOSe9yYXfYzUNvaQ.png"/></div></div></figure><p id="fb89" class="pw-post-body-paragraph kp kq it kr b ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">与序列分类问题不同，在序列标记中，我们必须预测序列中出现的每个单词在每个时间步的输出。正如我们从图像中看到的，由于我们在第一个序列中有 6 个单词，我们将根据句子的结构得到 6 个词性预测。</p><figure class="my mz na nb gt kd gh gi paragraph-image"><div role="button" tabindex="0" class="ke kf di kg bf kh"><div class="gh gi of"><img src="../Images/81211ddbd672085f482c6f0b467d1ed1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*UPEEiJneSc_x66s-i7pFYA.png"/></div></div></figure><p id="92dc" class="pw-post-body-paragraph kp kq it kr b ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">因为我们的输入序列长度可变，所以我们必须预处理数据，使输入序列长度相等。请记住，RNN 只有在遇到“<strong class="kr jd"><em class="lq"/></strong>&lt;SOS&gt;令牌和“<strong class="kr jd"><em class="lq">End-of-sequence</em></strong>”令牌后，才会处理单词序列，向网络发出输入已经结束，输出需要最终确定的信号。</p><h1 id="a5e0" class="lu lv it bd lw lx ly lz ma mb mc md me mf mg mh mi mj mk ml mm mn mo mp mq mr bi translated">模型</h1><p id="e858" class="pw-post-body-paragraph kp kq it kr b ks ms ku kv kw mt ky kz la mu lc ld le mv lg lh li mw lk ll lm im bi translated">在前面的部分中，我们讨论了在将数据输入模型之前，可以使用 RNN 的一些任务以及要执行的预处理步骤。在这一节中，我们将讨论如何模拟(近似函数)输入和输出之间的真实关系。</p><h2 id="27d7" class="ns lv it bd lw nt nu dn ma nv nw dp me la nx ny mi le nz oa mm li ob oc mq iz bi translated">序列分类</h2><p id="f057" class="pw-post-body-paragraph kp kq it kr b ks ms ku kv kw mt ky kz la mu lc ld le mv lg lh li mw lk ll lm im bi translated">我们已经知道，在序列分类中，输出依赖于整个序列。通过分析评论来预测这部电影的发展趋势。</p><figure class="my mz na nb gt kd gh gi paragraph-image"><div role="button" tabindex="0" class="ke kf di kg bf kh"><div class="gh gi og"><img src="../Images/cf9486b248a7a37f9b3bcf841983f486.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*gt1Y0WVgDERgSxHRD7vDiA.png"/></div></div></figure><p id="4073" class="pw-post-body-paragraph kp kq it kr b ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">该功能的输入以橙色表示，并表示为一个<strong class="kr jd"> xᵢ </strong>。使用向量<strong class="kr jd"> U </strong>来表示与输入相关联的权重，并且将单词的隐藏表示(<strong class="kr jd"> sᵢ) </strong>计算为先前时间步长的输出和当前输入以及偏差的函数。隐藏的表示将被计算直到序列的长度(sₜ).</p><figure class="my mz na nb gt kd gh gi paragraph-image"><div class="gh gi oh"><img src="../Images/c9d9a8ed29406e47f6edddd12a346a07.png" data-original-src="https://miro.medium.com/v2/resize:fit:846/format:webp/1*k_DGDc274hMk4CE8KOW4OQ.png"/></div></figure><p id="6b1a" class="pw-post-body-paragraph kp kq it kr b ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">来自网络的最终输出(y_hat)是隐藏表示和与其相关联的权重以及偏差的 softmax 函数。</p><h2 id="eb8f" class="ns lv it bd lw nt nu dn ma nv nw dp me la nx ny mi le nz oa mm li ob oc mq iz bi translated">序列标记</h2><p id="1ba2" class="pw-post-body-paragraph kp kq it kr b ks ms ku kv kw mt ky kz la mu lc ld le mv lg lh li mw lk ll lm im bi translated">在序列标记中，我们必须预测每个时间步的输出，这不同于序列分类中最后的预测。</p><figure class="my mz na nb gt kd gh gi paragraph-image"><div role="button" tabindex="0" class="ke kf di kg bf kh"><div class="gh gi oi"><img src="../Images/dc0d11305a67f370b168dfc43d43a016.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*BsbZjOY7vueH9ZOELEtjcQ.png"/></div></div></figure><p id="6c83" class="pw-post-body-paragraph kp kq it kr b ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">数学公式与序列分类略有不同，在这种方法中，我们将预测每个时间步后的输出。</p><figure class="my mz na nb gt kd gh gi paragraph-image"><div class="gh gi oj"><img src="../Images/a5e05f028da838a6c6aabc6ae5784206.png" data-original-src="https://miro.medium.com/v2/resize:fit:880/format:webp/1*GVRi-4ix_jOjpn2LHx24Nw.png"/></div></figure><p id="aa1f" class="pw-post-body-paragraph kp kq it kr b ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">一旦我们计算了隐藏表示，来自网络的特定时间步长的输出(<strong class="kr jd"> yᵢ </strong>)是隐藏表示和与其相关联的权重以及偏差的 softmax 函数。类似地，我们将计算序列中每个时间步的隐藏表示状态和预测输出。</p><h1 id="7fe9" class="lu lv it bd lw lx ly lz ma mb mc md me mf mg mh mi mj mk ml mm mn mo mp mq mr bi translated">损失函数</h1><p id="f294" class="pw-post-body-paragraph kp kq it kr b ks ms ku kv kw mt ky kz la mu lc ld le mv lg lh li mw lk ll lm im bi translated">损失函数的目的是告诉模型在学习过程中需要进行一些校正。</p><p id="30d7" class="pw-post-body-paragraph kp kq it kr b ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">在<strong class="kr jd">序列分类问题</strong>的背景下，为了比较两种概率分布(真实分布和预测分布)，我们将使用<strong class="kr jd">交叉熵</strong>损失函数。损失函数等于真实概率和预测概率的对数之和。</p><figure class="my mz na nb gt kd gh gi paragraph-image"><div class="gh gi ok"><img src="../Images/690102318bfc85575d4a49e7b2d1e3f4.png" data-original-src="https://miro.medium.com/v2/resize:fit:862/format:webp/1*gH4kvliFLX9SQaYx0jyLuw.png"/></div></figure><p id="ffeb" class="pw-post-body-paragraph kp kq it kr b ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">对于“m”个训练样本，总损失将等于总损失的平均值(其中<strong class="kr jd"> c </strong>表示正确类别或真实类别)。</p><figure class="my mz na nb gt kd gh gi paragraph-image"><div class="gh gi ol"><img src="../Images/e650f1afb3c9ed22e584e5d655f755de.png" data-original-src="https://miro.medium.com/v2/resize:fit:784/format:webp/1*4u5qKl9nUUzBryMqbl6OPQ.png"/></div></figure><p id="614d" class="pw-post-body-paragraph kp kq it kr b ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">在<strong class="kr jd">序列标记问题</strong>中，在每个时间步，我们必须做出预测，这意味着在每个时间步，我们都有真实分布和预测分布。</p><figure class="my mz na nb gt kd gh gi paragraph-image"><div role="button" tabindex="0" class="ke kf di kg bf kh"><div class="gh gi om"><img src="../Images/5a5c8e2f773f078a5319c3f090d36398.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*AUp9HMJ87XA0vKa23sxX_A.png"/></div></div></figure><p id="7859" class="pw-post-body-paragraph kp kq it kr b ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">由于我们在每个时间步长预测标签，因此在每个时间步长都有可能出错。所以我们必须检查每个时间步的真实概率分布和预测概率分布，以计算模型的损失。</p><p id="56f6" class="pw-post-body-paragraph kp kq it kr b ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">实际上，对于所有训练示例(m-训练示例)和所有时间步长(T ),我们试图最小化真实类的预测分布之间的交叉熵损失。</p><figure class="my mz na nb gt kd gh gi paragraph-image"><div class="gh gi on"><img src="../Images/788a1d9d4be8063a9271d2a665ed2404.png" data-original-src="https://miro.medium.com/v2/resize:fit:920/format:webp/1*09rGZ-NUW4N3LlycPN1uYg.png"/></div></figure><h1 id="ac48" class="lu lv it bd lw lx ly lz ma mb mc md me mf mg mh mi mj mk ml mm mn mo mp mq mr bi translated">学习算法</h1><p id="d3ab" class="pw-post-body-paragraph kp kq it kr b ks ms ku kv kw mt ky kz la mu lc ld le mv lg lh li mw lk ll lm im bi translated">学习算法的目标是确定参数的最佳可能值，使得模型的总损失(平方误差损失)尽可能最小。学习算法是这样的:</p><figure class="my mz na nb gt kd gh gi paragraph-image"><div role="button" tabindex="0" class="ke kf di kg bf kh"><div class="gh gi oo"><img src="../Images/fef939438a1f6cb9ea33d167bbd15926.png" data-original-src="https://miro.medium.com/v2/resize:fit:858/format:webp/1*sab_DttxEONXY400NATV7Q.png"/></div></div></figure><p id="9a50" class="pw-post-body-paragraph kp kq it kr b ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">我们随机初始化<strong class="kr jd"> w，u，v </strong>和<strong class="kr jd"> b </strong>。然后，我们对数据中的所有观察值进行迭代，使用 RNN 方程找到每个观察值的预测结果，并计算总损失。基于损失值，我们将更新权重，使得模型在新参数下的总损失将比模型的当前损失小<strong class="kr jd">。</strong></p><p id="6f15" class="pw-post-body-paragraph kp kq it kr b ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">我们将继续进行更新操作，直到我们满意为止。直到满意可能意味着以下任何一种情况:</p><ul class=""><li id="ac40" class="nc nd it kr b ks kt kw kx la ne le nf li ng lm nh ni nj nk bi translated">模型的总损失变为零。</li><li id="42ad" class="nc nd it kr b ks nl kw nm la nn le no li np lm nh ni nj nk bi translated">模型的总损失变成接近于零的非常小的值。</li><li id="10b9" class="nc nd it kr b ks nl kw nm la nn le no li np lm nh ni nj nk bi translated">基于计算能力迭代固定次数。</li></ul></div><div class="ab cl op oq hx or" role="separator"><span class="os bw bk ot ou ov"/><span class="os bw bk ot ou ov"/><span class="os bw bk ot ou"/></div><div class="im in io ip iq"><p id="5977" class="pw-post-body-paragraph kp kq it kr b ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated"><em class="lq">推荐阅读</em></p><div class="ow ox gp gr oy oz"><a rel="noopener follow" target="_blank" href="/understanding-convolution-neural-networks-the-eli5-way-785330cd1fb7"><div class="pa ab fo"><div class="pb ab pc cl cj pd"><h2 class="bd jd gy z fp pe fr fs pf fu fw jc bi translated">理解卷积神经网络 ELI5 方法</h2><div class="pg l"><h3 class="bd b gy z fp pe fr fs pf fu fw dk translated">了解卷积运算和 CNN 的</h3></div><div class="ph l"><p class="bd b dl z fp pe fr fs pf fu fw dk translated">towardsdatascience.com</p></div></div><div class="pi l"><div class="pj l pk pl pm pi pn ki oz"/></div></div></a></div><div class="ow ox gp gr oy oz"><a href="https://medium.com/@niranjankumarc/building-a-feedforward-neural-network-using-pytorch-nn-module-52b1d7ea5c3e" rel="noopener follow" target="_blank"><div class="pa ab fo"><div class="pb ab pc cl cj pd"><h2 class="bd jd gy z fp pe fr fs pf fu fw jc bi translated">利用 Pytorch 神经网络模块构建前馈神经网络</h2><div class="pg l"><h3 class="bd b gy z fp pe fr fs pf fu fw dk translated">Pytoch 神经网络模块初学者指南</h3></div><div class="ph l"><p class="bd b dl z fp pe fr fs pf fu fw dk translated">medium.com</p></div></div><div class="pi l"><div class="po l pk pl pm pi pn ki oz"/></div></div></a></div><h1 id="308f" class="lu lv it bd lw lx ly lz ma mb mc md me mf mg mh mi mj mk ml mm mn mo mp mq mr bi translated">从这里去哪里？</h1><p id="5546" class="pw-post-body-paragraph kp kq it kr b ks ms ku kv kw mt ky kz la mu lc ld le mv lg lh li mw lk ll lm im bi translated">如果你想用 Keras &amp; Tensorflow 2.0 (Python 或者 R)学习更多关于人工神经网络的知识。看看来自<a class="ae ko" href="https://courses.starttechacademy.com/full-site-access/?coupon=NKSTACAD" rel="noopener ugc nofollow" target="_blank"> Starttechacademy </a>的 Abhishek 和 Pukhraj 的<a class="ae ko" href="https://courses.starttechacademy.com/full-site-access/?coupon=NKSTACAD" rel="noopener ugc nofollow" target="_blank">人工神经网络</a>。他们以一种简单化的方式解释了深度学习的基础。</p><h1 id="f7aa" class="lu lv it bd lw lx ly lz ma mb mc md me mf mg mh mi mj mk ml mm mn mo mp mq mr bi translated">结论</h1><p id="b707" class="pw-post-body-paragraph kp kq it kr b ks ms ku kv kw mt ky kz la mu lc ld le mv lg lh li mw lk ll lm im bi translated">在这篇文章中，我们讨论了 RNN 如何用于不同的任务，如序列标记和序列分类。然后，我们研究了在输入模型之前用于处理数据的预处理技术。之后，我们研究了如何解决序列标记和序列分类问题的数学模型。最后，我们讨论了 RNN 的损失函数和学习算法。</p><p id="e418" class="pw-post-body-paragraph kp kq it kr b ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">在我的下一篇文章中，我们将深入讨论 LSTM 和 GRU。所以，请务必在 Medium 上跟随我，以便在它下跌时得到通知。</p><p id="c7cd" class="pw-post-body-paragraph kp kq it kr b ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">直到那时，和平:)</p><p id="37b8" class="pw-post-body-paragraph kp kq it kr b ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">NK。</p><h1 id="db8f" class="lu lv it bd lw lx ly lz ma mb mc md me mf mg mh mi mj mk ml mm mn mo mp mq mr bi translated">作者简介</h1><p id="9a72" class="pw-post-body-paragraph kp kq it kr b ks ms ku kv kw mt ky kz la mu lc ld le mv lg lh li mw lk ll lm im bi translated">Niranjan Kumar 是好事达印度公司的高级数据科学顾问。他对深度学习和人工智能充满热情。除了在媒体上写作，他还作为自由数据科学作家为 Marktechpost.com 写作。点击查看他的文章<a class="ae ko" href="https://www.marktechpost.com/author/niranjan-kumar/" rel="noopener ugc nofollow" target="_blank">。</a></p><p id="f409" class="pw-post-body-paragraph kp kq it kr b ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">你可以在<a class="ae ko" href="https://www.linkedin.com/in/niranjankumar-c/" rel="noopener ugc nofollow" target="_blank"> LinkedIn </a>上与他联系，或者在<a class="ae ko" href="https://twitter.com/Nkumar_283" rel="noopener ugc nofollow" target="_blank"> Twitter </a>上关注他，了解关于深度学习和机器学习的最新文章。</p><p id="05b1" class="pw-post-body-paragraph kp kq it kr b ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated"><strong class="kr jd">免责声明</strong> —这篇文章中可能有一些相关资源的附属链接。你可以以尽可能低的价格购买捆绑包。如果你购买这门课程，我会收到一小笔佣金。</p></div></div>    
</body>
</html>