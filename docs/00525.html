<html>
<head>
<title>Neural Networks Intuitions: 2. Dot product, Gram Matrix and Neural Style Transfer</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">神经网络直觉:2。点积、Gram 矩阵和神经风格转移</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/neural-networks-intuitions-2-dot-product-gram-matrix-and-neural-style-transfer-5d39653e7916?source=collection_archive---------6-----------------------#2019-01-24">https://towardsdatascience.com/neural-networks-intuitions-2-dot-product-gram-matrix-and-neural-style-transfer-5d39653e7916?source=collection_archive---------6-----------------------#2019-01-24</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><p id="4562" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">大家好！</p><p id="7d20" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">今天我们要来看看已经用神经网络解决的一个有趣的问题— <strong class="jp ir">“图像风格转换”</strong>。问题是获取两幅图像，从一幅图像中提取内容，从另一幅图像中提取风格(纹理),并将它们无缝地合并成一幅看起来真实的最终图像。这篇博文是对<em class="kl"> </em> Gatys 等人的文章<em class="kl">一种艺术风格的神经算法</em>的解释。艾尔(<a class="ae km" href="https://arxiv.org/abs/1508.06576" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/abs/1508.06576</a>)</p><p id="e6db" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">让我们看一个例子来说明问题。</p><figure class="ko kp kq kr gt ks gh gi paragraph-image"><div class="gh gi kn"><img src="../Images/77a8ce7dde3afc02da4a1dc143a87efc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1034/format:webp/1*-DKzmMajUn45Hu0pe_PUyQ.jpeg"/></div><figcaption class="kv kw gj gh gi kx ky bd b be z dk"><strong class="bd kz">Top left</strong> is the <strong class="bd kz">content</strong> image, <strong class="bd kz">bottom left</strong> is the <strong class="bd kz">style</strong> image, <strong class="bd kz">result</strong> is the one on the <strong class="bd kz">right</strong></figcaption></figure><p id="df95" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">有趣吧？下面我们来看看如何解决。</p></div><div class="ab cl la lb hu lc" role="separator"><span class="ld bw bk le lf lg"/><span class="ld bw bk le lf lg"/><span class="ld bw bk le lf"/></div><div class="ij ik il im in"><p id="9779" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">概述:</strong>让我简单介绍一下该解决方案</p><ol class=""><li id="8a61" class="lh li iq jp b jq jr ju jv jy lj kc lk kg ll kk lm ln lo lp bi translated">创建随机输入图像</li><li id="0786" class="lh li iq jp b jq lq ju lr jy ls kc lt kg lu kk lm ln lo lp bi translated">通过一个预先训练好的主干架构传递输入，比如 VGG、雷斯内特(注意，在反向传播过程中不会训练这个主干)。</li><li id="66ff" class="lh li iq jp b jq lq ju lr jy ls kc lt kg lu kk lm ln lo lp bi translated">计算损失并计算相对于输入图像像素的<strong class="jp ir">梯度。</strong>因此，仅调整输入像素，而权重保持不变。</li></ol><p id="79f3" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">目的是改变输入图像，使其代表各个图像的内容和风格。</p></div><div class="ab cl la lb hu lc" role="separator"><span class="ld bw bk le lf lg"/><span class="ld bw bk le lf lg"/><span class="ld bw bk le lf"/></div><div class="ij ik il im in"><p id="fd05" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">这个问题由两个子问题组成:1 .生成内容和 2。来生成样式。</p><p id="8506" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">问题— 1。生成内容:</strong>问题是生成一个包含内容图像中的内容的图像。</p><blockquote class="lv lw lx"><p id="9566" class="jn jo kl jp b jq jr js jt ju jv jw jx ly jz ka kb lz kd ke kf ma kh ki kj kk ij bi translated">这里需要注意的一点是，图像应该只包含内容(就像内容图像的草图一样，而不是来自内容图像的纹理，因为输出应该包含与样式图像相同的样式)</p></blockquote><p id="e4a6" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">解决方案:</strong>答案应该很简单。使用输入和目标之间的 MSE 损失(或任何相似性度量，如 SSIM，PSNR)。但是这里的目标是什么呢？如果对输出的风格没有限制，那么输入和内容图像之间的 MSE 就足够了。那么如何在不复制图片风格的情况下获取图片的内容呢？</p><p id="2543" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">使用<strong class="jp ir">特征地图。</strong></p><p id="48b8" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">卷积特征图通常是输入图像特征的非常好的表示。它们捕捉图像的空间信息，而不包含样式信息(如果按原样使用特征地图)，这正是我们需要的。这就是我们在反向传播过程中保持主干权重固定的原因。</p><blockquote class="lv lw lx"><p id="6da5" class="jn jo kl jp b jq jr js jt ju jv jw jx ly jz ka kb lz kd ke kf ma kh ki kj kk ij bi translated">因此，<strong class="jp ir">输入图像特征和内容图像特征之间的 MSE 损失</strong>将起作用！</p></blockquote><figure class="ko kp kq kr gt ks gh gi paragraph-image"><div class="gh gi mb"><img src="../Images/75653fd656dce9a4c9fccb518db5890b.png" data-original-src="https://miro.medium.com/v2/resize:fit:936/format:webp/1*PKnjB3bxzgg6yy0uOsljqw.png"/></div><figcaption class="kv kw gj gh gi kx ky bd b be z dk">Content Loss</figcaption></figure><figure class="ko kp kq kr gt ks"><div class="bz fp l di"><div class="mc md l"/></div><figcaption class="kv kw gj gh gi kx ky bd b be z dk">Backbone used is vgg16_bn</figcaption></figure><p id="0524" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">使用早期 conv 图层的要素地图可以更好地表现内容，因为它们更接近输入，因此使用 conv2、conv4 和 conv7 的要素。</p><figure class="ko kp kq kr gt ks"><div class="bz fp l di"><div class="mc md l"/></div><figcaption class="kv kw gj gh gi kx ky bd b be z dk">SaveFeatures is used to save the activations of conv layers(for content/style/input) during a forward pass</figcaption></figure><figure class="ko kp kq kr gt ks"><div class="bz fp l di"><div class="mc md l"/></div><figcaption class="kv kw gj gh gi kx ky bd b be z dk">MSE between input and content features</figcaption></figure></div><div class="ab cl la lb hu lc" role="separator"><span class="ld bw bk le lf lg"/><span class="ld bw bk le lf lg"/><span class="ld bw bk le lf"/></div><div class="ij ik il im in"><p id="1373" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">问题— 2。生成样式:</strong>问题是生成一个包含样式图像中样式的图像。</p><p id="6171" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">解决方案:</strong>为了提取一幅图像的风格(或者更具体地说，为了计算风格损失)，我们需要一种叫做格拉姆矩阵的东西。等等，什么是克矩阵？</p><p id="32ce" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">在谈论如何计算风格损失之前，让我先谈谈一些数学基础。</p><p id="0117" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">点积:</strong></p><p id="c76a" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">两个向量的点积可以写成:</p><figure class="ko kp kq kr gt ks gh gi paragraph-image"><div class="gh gi me"><img src="../Images/7edcee3db4e940ed095478ea0267aab1.png" data-original-src="https://miro.medium.com/v2/resize:fit:490/format:webp/1*H1UW3bwrhqkRUJ11Xg6gGA.png"/></div><figcaption class="kv kw gj gh gi kx ky bd b be z dk">(a)</figcaption></figure><p id="af4f" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">或者</p><figure class="ko kp kq kr gt ks gh gi paragraph-image"><div class="gh gi mf"><img src="../Images/0a6f20d497322d5185623fac43e6f816.png" data-original-src="https://miro.medium.com/v2/resize:fit:1358/format:webp/1*eNoiUiODzGvq0DNTa5-akA.png"/></div><figcaption class="kv kw gj gh gi kx ky bd b be z dk">(b)</figcaption></figure><p id="082b" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">两个向量的点积是各自坐标乘积的和。</p><p id="523c" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">用<em class="kl"> 3blue1brown </em>的话说，<strong class="jp ir">“<em class="kl">点积可以看做是向量 a 在向量 b 上的投影长度乘以向量 b 的长度”。</em>T11】</strong></p><p id="9b70" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">或者用<em class="kl">可汗学园的话来说，</em> <strong class="jp ir"> <em class="kl">“可以看做与向量 b 同向的向量 a 的长度乘以向量 b 的长度”。</em> </strong></p><p id="6e2f" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">图(a)中的术语<em class="kl"> |a|cos θ </em>(重新排列为<em class="kl"> |b||a|cos θ </em>)本质上是邻边的长度(或<strong class="jp ir">投影向量‘a’如 3blue1brown 中的，</strong>)，因此它归结为邻边乘以向量 b 的长度的乘积</p><blockquote class="lv lw lx"><p id="6519" class="jn jo kl jp b jq jr js jt ju jv jw jx ly jz ka kb lz kd ke kf ma kh ki kj kk ij bi translated">那么这意味着什么呢？</p></blockquote><p id="2374" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">用更直观的方式来说，<strong class="jp ir"> <em class="kl">点积可以看做两个向量实际上是多么相似</em> </strong>。它们越相似，它们之间的角度就越小，如图(a)所示，或者各自的坐标就越接近，如图(b)所示。在这两种情况下，结果都很大。所以它们越相似，点积就越大。</p><p id="7097" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">但是这和神经网络有什么关系呢？</p><blockquote class="lv lw lx"><p id="bf54" class="jn jo kl jp b jq jr js jt ju jv jw jx ly jz ka kb lz kd ke kf ma kh ki kj kk ij bi translated">考虑表示输入空间特征的两个向量(<strong class="jp ir">更具体地，来自深度为 C </strong>的卷积特征图的 2 个展平特征向量)，它们的点积给我们提供了关于它们之间关系的信息。乘积越小，学习的特征越不同，乘积越大，特征越相关。换句话说，乘积越小，<strong class="jp ir">两个特征同时出现的次数越少，</strong>乘积越大，<strong class="jp ir">它们同时出现的次数越多。</strong>这在某种意义上给出了关于图像风格(纹理)的信息，而没有给出关于其空间结构的信息，因为我们已经展平了特征并在其上执行了点积。</p></blockquote><p id="26bb" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">现在从深度为 C 的卷积特征图中取出所有的<strong class="jp ir"> C </strong>特征向量(展平的),并计算它们中每一个的点积(包括特征向量本身)。结果是<strong class="jp ir">克矩阵</strong>(大小为 CxC)。</p><figure class="ko kp kq kr gt ks gh gi paragraph-image"><div class="gh gi mg"><img src="../Images/a2d796207f959d4a52252bc0a5b06eae.png" data-original-src="https://miro.medium.com/v2/resize:fit:518/format:webp/1*C3fkQanKHMwOi_rf0q0OQQ.png"/></div><figcaption class="kv kw gj gh gi kx ky bd b be z dk">Gram matrix</figcaption></figure><p id="7bad" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">这就对了。</p><blockquote class="lv lw lx"><p id="8471" class="jn jo kl jp b jq jr js jt ju jv jw jx ly jz ka kb lz kd ke kf ma kh ki kj kk ij bi translated">计算输入的 gram 矩阵和样式图像之间的 MSE 损失，就可以生成所需样式的输入图像了。</p></blockquote><figure class="ko kp kq kr gt ks gh gi paragraph-image"><div class="gh gi mh"><img src="../Images/10e132295e6c2f20e1b4aa5e464c8356.png" data-original-src="https://miro.medium.com/v2/resize:fit:746/format:webp/1*0nASi-BjZI3I9J0RWo7wtw.png"/></div><figcaption class="kv kw gj gh gi kx ky bd b be z dk">Summing MSE of Gram matrices for all layers, normalizing and computing a weighted sum in the end</figcaption></figure><figure class="ko kp kq kr gt ks"><div class="bz fp l di"><div class="mc md l"/></div><figcaption class="kv kw gj gh gi kx ky bd b be z dk">Saving feature maps for style image</figcaption></figure><p id="6f66" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">考虑从几个卷积层(在实验中)提取风格信息的特征图总是更好的。在上述代码中，使用了卷积层 2、4、7、10 和 13。</p><figure class="ko kp kq kr gt ks"><div class="bz fp l di"><div class="mc md l"/></div><figcaption class="kv kw gj gh gi kx ky bd b be z dk">Computing gram matrix and style loss</figcaption></figure></div><div class="ab cl la lb hu lc" role="separator"><span class="ld bw bk le lf lg"/><span class="ld bw bk le lf lg"/><span class="ld bw bk le lf"/></div><div class="ij ik il im in"><p id="ae66" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">最后，<strong class="jp ir">在反向传播</strong>之前将内容和样式损失相加，以获得输出图像，该输出图像具有来自内容图像的内容和来自样式图像的样式。</p><p id="6b45" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">当损失处于不同的范围时，两种损失的正常总和可能不起作用。因此，内容和风格损失的加权总和应该是可行的。</p><figure class="ko kp kq kr gt ks gh gi paragraph-image"><div class="gh gi mi"><img src="../Images/438aaa482e68f72b6c98beacfe50f904.png" data-original-src="https://miro.medium.com/v2/resize:fit:1262/format:webp/1*39DOPiFLq8TcncxuLKro7Q.png"/></div><figcaption class="kv kw gj gh gi kx ky bd b be z dk">Total loss</figcaption></figure><figure class="ko kp kq kr gt ks"><div class="bz fp l di"><div class="mc md l"/></div><figcaption class="kv kw gj gh gi kx ky bd b be z dk">compute weighted sum of both losses and then backprop</figcaption></figure><p id="3079" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">注意，输入图像可以是任意随机张量<strong class="jp ir">，其值与内容和样式图像的范围</strong>相同。</p></div><div class="ab cl la lb hu lc" role="separator"><span class="ld bw bk le lf lg"/><span class="ld bw bk le lf lg"/><span class="ld bw bk le lf"/></div><div class="ij ik il im in"><p id="00d5" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我实施的一些结果:</p><figure class="ko kp kq kr gt ks gh gi paragraph-image"><div role="button" tabindex="0" class="mk ml di mm bf mn"><div class="gh gi mj"><img src="../Images/dacc3ab2a828939bda2cf04740eb495c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*xa9V7EEgW-iwwsDeZhnymw.jpeg"/></div></div></figure><figure class="ko kp kq kr gt ks gh gi paragraph-image"><div role="button" tabindex="0" class="mk ml di mm bf mn"><div class="gh gi mj"><img src="../Images/00f79b52988380a991f85c46d33f30aa.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*cMRLk8roY5N88XqLYx0SOQ.jpeg"/></div></div></figure><figure class="ko kp kq kr gt ks gh gi paragraph-image"><div role="button" tabindex="0" class="mk ml di mm bf mn"><div class="gh gi mj"><img src="../Images/65ed20bd8fad40b6bc3f40b41a45c23d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*AL9gi_6AEQntjZVn7uR4AA.jpeg"/></div></div></figure><p id="e309" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">查看我的 github repo<a class="ae km" href="https://github.com/mailcorahul/deep_learning/tree/master/papers/neural_style_transfer" rel="noopener ugc nofollow" target="_blank"><em class="kl">https://github . com/mailcorahul/deep _ learning/tree/master/papers/Neural _ Style _ Transfer</em></a>，了解 pytorch 实现的论文<em class="kl">Gatys 等人使用卷积神经网络进行图像样式转换。艾尔。</em></p><p id="bfd4" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">干杯-:)</p></div></div>    
</body>
</html>