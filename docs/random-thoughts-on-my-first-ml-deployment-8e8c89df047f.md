# 对我第一次 ML 部署的随想

> 原文：<https://towardsdatascience.com/random-thoughts-on-my-first-ml-deployment-8e8c89df047f?source=collection_archive---------12----------------------->

![](img/de3d13eea44f406191634e01072d2e24.png)

Photo by [Coen van de Broek](https://unsplash.com/@ocen?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText) on [Unsplash](https://unsplash.com/?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)

## 六个月前我不知道的五件事，在接下来的几个月里最好不要忘记

简单介绍一下背景:我目前在[工作，这是一家快速发展的中型公司](https://housinganywhere.com/)，在开发了一个强大且广泛使用的产品后，决定开始利用这些年来产生的数据为最终用户带来一些价值。*数据科学团队*在这一探索的开始并不是非常结构化，六个月后的今天，即使你可以开始注意到一些变化，这些变化都是自然试错过程的结果。因此，对于在结构化公司工作的更有经验的数据科学家来说，以下几点可能是显而易见的，这些结构化公司拥有模型投入生产的良好记录。但是，如果我想到六个月前的我，我可能会对阅读这样的帖子感兴趣，以避免浪费大量时间和 CPU 能力来训练无用的模型或寻找特定的模型，这些模型在几周前训练过，但在一堆无用的其他模型中丢失，主要是因为我保存所有 Jupyter 笔记本的文件夹中混乱不堪。

## 1.关注产品，而不仅仅是性能

在这几个月开发的所有项目的早期阶段，我专注于提高纸面上的性能，设计最复杂和性能最好的功能，只是后来发现这些功能并不实时可用，或者检索它们的过程成本太高，以至于不值得努力提高性能。举例来说，一个列表在发布后的头几个小时内收到的互动数量是一个很好的指标，可以用来判断它是不是一个骗局。然而，如果模型的目标是在上传他们的清单后的第一分钟内检测骗子，这个功能几乎没有用。

另一个重要的建议是尽快用来自产品最终使用场景的实时数据来测试模型。

> 快速发现开发的模型是不可靠的，这要比花几个月的时间研究某个东西，当它已经运行时才发现它是多么的无用要好的多。

我已经在这里和那里写了这个主题，我不会重写整个故事，但在多年期间收集的数据集中，所有样本都遵循相同的分布并不明显:处理这种复杂性使得处理真实数据比处理类似 *Kaggle 的*数据集更具挑战性。不要误解我的意思:它们很酷，最重要的是，它们是想尝试新技术的数据科学家们唯一可以免费获得的资源。唯一的误解是，它们远远不能很好地代表真实世界的数据集，这往往需要大量的努力(真的，很多)才能得到可用的样本，同时消除不良值和离群值。前一段时间，我读到一位高级数据科学家说，他越高级，他发展的技能就越多，主要是数据集清理和准备。我开始理解他的话了…

## 2.拥有计算机科学背景是关键

一个机器学习模型，不管它会变得多么复杂和*深刻*，最终都是一个软件人工制品，可能会作为一个 Web API 暴露在一个已经存在的基础设施之上。拥有计算机科学背景，或者至少对这些主题有扎实的理解，对于构建一个可以在持续数月的研究阶段后快速部署的数据产品是至关重要的。

> 根据经验:没有 CS 背景的人开发的模型越多，在生产中部署它就越困难，可能不得不降低性能或调整特性以适应最终的架构。

在我们的业务阶段，能够在训练模型的同时勾画出客户机-服务器架构可能比拥有一个专注于 ML 的博士学位更重要。当然，这是一个大胆的句子，可能它已经不再有效了(新的结构、新的项目、新的挑战)；但在数据团队的早期阶段，随着尽快带来一些切实价值的严格要求，能够有一点点 CS 愿景是将模型从 Jupyter 笔记本中取出并在几周内(而不是几个月内)提供给用户的基础。

## 3.部署 ML 不是黑魔法

大约一年前，当我参加最后一次大学考试时，我对自己的理论 DS/ML 技能非常自信，渴望获得一些真实世界数据的实践经验，而我完全没有意识到，甚至有点害怕构建由这种复杂技术支持的实际数据产品。Jupyter 笔记本之后还有生活吗？

几个月后，我发现问题在于我认为在一个已部署的 ML 模型背后有谁知道是什么样的技术复杂性。一旦我有了要实际部署的东西，我对该领域研究得越多(再次，参见第 1 点)，我就越注意到:a)如果有许多关于这种非常具体的方法的故事和经验，允许在 *ImageNet* 上增加 0.001%的精确度，那么关于如何实际向世界展示 ML 模型的例子和指南就非常少；b)最终，模型只是计算机函数，通常用 Python 编写，这种技术已经被数百万用户部署和使用了多年。我们公司学到的一个很好的经验是让数据科学家尽可能接近高级工程师，即使他们可能不太了解机器学习，但在构建可靠和健壮的软件产品方面有很多经验。

> Python 脚本就是 Python 脚本，不管它做什么。

## 4.给 Jupyter 笔记本一个结构

我现在不会谈论这个问题的细节，但是在几周内每天工作 8 小时后，试验和草图想法的数量开始增加。Jupyter 笔记本，以及它们可能固有的所有问题，是每个数据科学项目可能非常长的研究阶段的*事实上的*标准。

> 一个项目越长越复杂，就要花费越多的时间，用几周前训练的略有不同的数据集来寻找特定的模型。

如果仔细跟踪每一个测试和实验可能有点大材小用，而且 Jupyter 笔记本的格式本身并不容易进行版本控制，那么在过去的几个月里，开始给文件夹和文件提供一个结构已经节省了我很多时间。

在我的日常工作中，*笔记本*主要可以分为四类:

*   探索:初步数据集分析，包括总体测量、绘图和图表；
*   清理:数据集被清理，异常值被检测并可能被移除，一些初始复杂特征被设计；
*   实验性:模型(甚至每个笔记本不止一个算法)被训练和测试，更复杂的想法被尝试(每个*笔记本不超过一个*)；
*   部署:完整的管道，从数据集清理到预测。理想情况下，它可以从头到尾提供模型和预测。

创建的每个 Jupyter 笔记本必须在文件名中包含这些关键字之一，并带有实际文件内容的简要描述。一旦一个*笔记本*变得太复杂或者开始超出最初的范围，它会被重新排序一点，然后创建一个新的，可能会在之前的一些结果的基础上开始。另一方面:每个数据集的名称必须包含一个日期，以及对所包含特性的简要说明。

当我开始使用这种结构时——不幸的是在第一次使用后的几个月。fit()我在公司的办公室运行——我的效率大大提高了，并且很容易回到几周前训练的模型，或者使用更新的数据集或新功能重新运行相同的管道。

## 5.从容做

最后，而且主要是对未来的我的一个忠告，但是谁知道呢:做事是需要时间的，越早明白这一点越好。单个项目需要多次迭代，最重要的是，构建健壮可靠的软件是一个长期的过程，而不是冲刺。尽快用活数据测试模型，但是然后离线迭代，尝试不同的方法。

> 大多数复杂的解决方案并不总是给出更好的结果，但是构建超级复杂的模型可能是你确定这一点的唯一方法。

如果每个项目都需要结构和期限，那么 ML 研究，即使是在强烈关注产品的情况下完成的，也需要时间来发展和成熟:在无用的分支中浪费时间，只是为了发现它们有多无用，并可能在未来做得更好，这是该过程的基本部分。