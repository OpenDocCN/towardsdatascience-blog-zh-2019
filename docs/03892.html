<html>
<head>
<title>Visualizing Intermediate Activations of a CNN trained on the MNIST Dataset</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">可视化在 MNIST 数据集上训练的 CNN 的中间激活</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/visualizing-intermediate-activations-of-a-cnn-trained-on-the-mnist-dataset-2c34426416c8?source=collection_archive---------11-----------------------#2019-06-19">https://towardsdatascience.com/visualizing-intermediate-activations-of-a-cnn-trained-on-the-mnist-dataset-2c34426416c8?source=collection_archive---------11-----------------------#2019-06-19</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><p id="cb4b" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">在本文中，我们不仅要使用 Keras 和 Python 训练一个卷积神经网络来分类手写数字，还要可视化卷积神经网络的中间激活，以便深入了解每一层学习图像的哪些特征。</p><p id="1f02" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我们将使用 MNIST 数据集，它可以在 Kaggle 上的<a class="ae kl" href="https://www.kaggle.com/c/digit-recognizer/overview" rel="noopener ugc nofollow" target="_blank">这里</a>找到。该数据集在训练集中包含 42000 行，在测试集中包含 24000 行。每行包含 784 个像素值，表示包含从 0 到 9 的手写单数数字的 28 x 28 图像。</p><p id="fe2e" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">让我们深入研究代码。</p><p id="2cd4" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">首先，我们必须导入所有模块:</p><pre class="km kn ko kp gt kq kr ks kt aw ku bi"><span id="6059" class="kv kw iq kr b gy kx ky l kz la">import numpy as np<br/>import pandas as pd<br/>import os<br/>import matplotlib.pyplot as plt<br/>from keras.layers import Dense, Dropout, Flatten<br/>from keras.layers import Conv2D, MaxPooling2D, Input<br/>from keras.models import Model<br/>from sklearn.model_selection import train_test_split</span></pre><p id="72d8" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">现在，让我们将 CSV 文件加载到一个<a class="ae kl" href="https://pandas.pydata.org/" rel="noopener ugc nofollow" target="_blank">熊猫</a>数据帧中，并使用<a class="ae kl" href="https://www.numpy.org/" rel="noopener ugc nofollow" target="_blank"> numpy </a>将它们重新整形为 28 x 28 x 1 的图像。</p><blockquote class="lb lc ld"><p id="de05" class="jn jo le jp b jq jr js jt ju jv jw jx lf jz ka kb lg kd ke kf lh kh ki kj kk ij bi translated">注意:所有图像都是灰度图像，因此它们只有一个通道</p></blockquote><pre class="km kn ko kp gt kq kr ks kt aw ku bi"><span id="5976" class="kv kw iq kr b gy kx ky l kz la">train_df = pd.read_csv("../input/train.csv")<br/>test_df = pd.read_csv("../input/test.csv")</span><span id="33f0" class="kv kw iq kr b gy li ky l kz la">train_labels = train_df['label']<br/>train_dataset = train_df.drop('label',axis=1)</span><span id="1e46" class="kv kw iq kr b gy li ky l kz la">X = np.array(train_dataset).reshape(train_df.shape[0],28,28,1)<br/>Y = np.array(train_labels).reshape(train_df.shape[0],1)</span></pre><p id="20d2" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">让我们来看看我们的一些训练图像:</p><pre class="km kn ko kp gt kq kr ks kt aw ku bi"><span id="bd9b" class="kv kw iq kr b gy kx ky l kz la">f, axes = plt.subplots(2, 10, sharey=True,figsize=(20,20))</span><span id="f39d" class="kv kw iq kr b gy li ky l kz la">for i,ax in enumerate(axes.flat):<br/>    ax.axis('off')<br/>    ax.imshow(X[i,:,:,0],cmap="gray")</span></pre><figure class="km kn ko kp gt lk gh gi paragraph-image"><div role="button" tabindex="0" class="ll lm di ln bf lo"><div class="gh gi lj"><img src="../Images/7d941297816034bf86820e3c7db4165c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*pJwWqy6QZuUKUDmuwPib2w.png"/></div></div></figure><figure class="km kn ko kp gt lk gh gi paragraph-image"><div role="button" tabindex="0" class="ll lm di ln bf lo"><div class="gh gi lr"><img src="../Images/b895f401d257a3bfd6779373f88cd2de.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*qhNMxDmXyXF9LyU4VYDs1Q.png"/></div></div></figure><h2 id="5940" class="kv kw iq bd ls lt lu dn lv lw lx dp ly jy lz ma mb kc mc md me kg mf mg mh mi bi translated">构建我们的 CNN 架构</h2><p id="3114" class="pw-post-body-paragraph jn jo iq jp b jq mj js jt ju mk jw jx jy ml ka kb kc mm ke kf kg mn ki kj kk ij bi translated">我们将使用<a class="ae kl" href="https://keras.io/models/model/" rel="noopener ugc nofollow" target="_blank"> Keras Functional API </a>来构建我们的 CNN 模型。我从 Chris Deotte 的<a class="ae kl" href="https://www.kaggle.com/cdeotte/how-to-choose-cnn-architecture-mnist" rel="noopener ugc nofollow" target="_blank"> Kaggle 笔记本</a>中获得了 CNN 架构的灵感。</p><pre class="km kn ko kp gt kq kr ks kt aw ku bi"><span id="8a82" class="kv kw iq kr b gy kx ky l kz la">def model():<br/>    <br/>    inputs = Input(shape=(28,28,1))<br/>    x = Conv2D(24,kernel_size=(3,3),padding='same',activation="relu")(inputs)<br/>    x = MaxPooling2D(pool_size=(2, 2))(x)<br/>    x = Conv2D(48, (3, 3), padding='same',activation='relu')(x)<br/>    x = MaxPooling2D(pool_size=(2, 2))(x)<br/>    x = Conv2D(64, (3, 3), padding='same',activation='relu')(x)<br/>    x = MaxPooling2D(pool_size=(2, 2))(x)<br/>    x = Flatten()(x)<br/>    x = Dense(128, activation='relu')(x)<br/>    x = Dropout(0.25)(x)<br/>    output = Dense(num_classes,activation="softmax")(x)<br/>    <br/>    model = Model(inputs,output)<br/>    <br/>    model.compile(loss='categorical_crossentropy', <br/>              optimizer='adam', <br/>              metrics=['accuracy'])<br/>    <br/>    return model</span></pre><figure class="km kn ko kp gt lk gh gi paragraph-image"><div class="gh gi mo"><img src="../Images/de9758f5bfaec24d27878c37f9f15b07.png" data-original-src="https://miro.medium.com/v2/resize:fit:574/format:webp/1*puOdO4UZ-9aQO06t18aLPQ.png"/></div></figure><p id="c078" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">现在是训练的时候了:</p><pre class="km kn ko kp gt kq kr ks kt aw ku bi"><span id="bb12" class="kv kw iq kr b gy kx ky l kz la">X_train, X_test, y_train, y_test = train_test_split(X,Y_one_hot,test_size=0.20, random_state=42)</span><span id="af64" class="kv kw iq kr b gy li ky l kz la">epochs = 20<br/>batch_size=256<br/><br/>model = model()<br/>history = model.fit(X_train,y_train,<br/>         epochs=epochs,<br/>         batch_size=batch_size,<br/>         validation_data=(X_test,y_test))</span></pre><p id="3f53" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><em class="le">这最终给出了 99.50%的训练准确度和 98.83%的验证准确度。</em></p><blockquote class="lb lc ld"><p id="2e69" class="jn jo le jp b jq jr js jt ju jv jw jx lf jz ka kb lg kd ke kf lh kh ki kj kk ij bi translated">注意:我们本可以在验证准确性方面做得更好，使用数据增强并对 Dropout 和 BatchNorm 层进行试验<strong class="jp ir">但是</strong>本文的重点不是获得极高的准确性，而是能够深入了解网络的每一层实际上在学习什么，对于这项任务，我们的模型将做得很好。</p></blockquote><p id="d5af" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">让我们快速绘制一张我们的训练和验证准确性以及损失的图表:</p><figure class="km kn ko kp gt lk gh gi paragraph-image"><div role="button" tabindex="0" class="ll lm di ln bf lo"><div class="gh gi mp"><img src="../Images/0609fc05a32d4d2a023ca4d9ae51b79f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ZXXoNLzgGGfv3hqxXo72FA.png"/></div></div></figure><h2 id="4390" class="kv kw iq bd ls lt lu dn lv lw lx dp ly jy lz ma mb kc mc md me kg mf mg mh mi bi translated">让模型旋转一下</h2><pre class="km kn ko kp gt kq kr ks kt aw ku bi"><span id="d0df" class="kv kw iq kr b gy kx ky l kz la">figure = plt.figure(figsize=(20,20))</span><span id="86eb" class="kv kw iq kr b gy li ky l kz la">for i in range(5):<br/>    figure.add_subplot(1,5,i+1)<br/>    plt.imshow(test_images[i+50,:,:,0],cmap="gray")<br/>    plt.axis("off")<br/>    print(np.squeeze(np.argmax(model.predict(test_images[i+50].reshape(1,28,28,1)),axis=1),axis=0),end="\t")</span></pre><figure class="km kn ko kp gt lk gh gi paragraph-image"><div role="button" tabindex="0" class="ll lm di ln bf lo"><div class="gh gi mq"><img src="../Images/a874720528d0281dac663b79612ff2a5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*1L5b10K-04ZwA6yuaucgFg.png"/></div></div></figure><p id="d22c" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">如我们所见，我们的模型给出了相当不错的结果。</p><h2 id="14e4" class="kv kw iq bd ls lt lu dn lv lw lx dp ly jy lz ma mb kc mc md me kg mf mg mh mi bi translated">可视化中间激活</h2><p id="ada3" class="pw-post-body-paragraph jn jo iq jp b jq mj js jt ju mk jw jx jy ml ka kb kc mm ke kf kg mn ki kj kk ij bi translated">我们期待已久的时刻。</p><p id="c24c" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我们首先要决定哪一层的激活我们想要可视化，并建立我们的激活模型。</p><pre class="km kn ko kp gt kq kr ks kt aw ku bi"><span id="f829" class="kv kw iq kr b gy kx ky l kz la">layer_outputs = [layer.output for layer <strong class="kr ir">in</strong> model.layers[1:7]]<br/>activation_model = Model(inputs=model.input,outputs=layer_outputs)</span></pre><p id="af48" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我们现在从测试数据集中选择一个随机图像，我们将在其上使用我们的激活模型。</p><pre class="km kn ko kp gt kq kr ks kt aw ku bi"><span id="e5f6" class="kv kw iq kr b gy kx ky l kz la">img = test_images[51].reshape(1,28,28,1)</span><span id="932d" class="kv kw iq kr b gy li ky l kz la">fig = plt.figure(figsize=(5,5))<br/>plt.imshow(img[0,:,:,0],cmap="gray")<br/>plt.axis('off')</span></pre><figure class="km kn ko kp gt lk gh gi paragraph-image"><div class="gh gi mr"><img src="../Images/1bc89e2c40bdfe74c701adcb033ddd4d.png" data-original-src="https://miro.medium.com/v2/resize:fit:444/format:webp/1*9qFLnYn4pgZ7_dIa-v5HbQ.png"/></div></figure><p id="295f" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我们现在使用我们的激活模型来输出所选层的激活。</p><pre class="km kn ko kp gt kq kr ks kt aw ku bi"><span id="d3d7" class="kv kw iq kr b gy kx ky l kz la">activations = activation_model.predict(img)</span></pre><p id="467d" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">是时候用一些<a class="ae kl" href="https://matplotlib.org/" rel="noopener ugc nofollow" target="_blank"> matplotlib </a>魔法将它们可视化了。🙂</p><pre class="km kn ko kp gt kq kr ks kt aw ku bi"><span id="1eb4" class="kv kw iq kr b gy kx ky l kz la">layer_names = []<br/>for layer in model.layers[1:7]:<br/>    layer_names.append(layer.name) # Names of the layers, so you can have them as part of your plot<br/>    <br/>images_per_row = 16</span><span id="6e55" class="kv kw iq kr b gy li ky l kz la">for layer_name, layer_activation in zip(layer_names, activations): # Displays the feature maps<br/>    n_features = layer_activation.shape[-1] # Number of features in the feature map<br/>    size = layer_activation.shape[1] #The feature map has shape (1, size, size, n_features).<br/>    n_cols = n_features // images_per_row # Tiles the activation channels in this matrix<br/>    display_grid = np.zeros((size * n_cols, images_per_row * size))<br/>    for col in range(n_cols): # Tiles each filter into a big horizontal grid<br/>        for row in range(images_per_row):<br/>            channel_image = layer_activation[0,<br/>                                             :, :,<br/>                                             col * images_per_row + row]<br/>            channel_image -= channel_image.mean() # Post-processes the feature to make it visually palatable<br/>            channel_image /= channel_image.std()<br/>            channel_image *= 64<br/>            channel_image += 128<br/>            channel_image = np.clip(channel_image, 0, 255).astype('uint8')<br/>            display_grid[col * size : (col + 1) * size, # Displays the grid<br/>                         row * size : (row + 1) * size] = channel_image<br/>    scale = 1. / size<br/>    plt.figure(figsize=(scale * display_grid.shape[1],<br/>                        scale * display_grid.shape[0]))<br/>    plt.title(layer_name)<br/>    plt.grid(False)<br/>    plt.imshow(display_grid, aspect='auto', cmap='viridis')</span></pre><figure class="km kn ko kp gt lk gh gi paragraph-image"><div role="button" tabindex="0" class="ll lm di ln bf lo"><div class="gh gi ms"><img src="../Images/999a0bd95f571401442b51fda8a88755.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*U0naEGCx9Sbbk3GvEg39pA.png"/></div></div></figure><figure class="km kn ko kp gt lk gh gi paragraph-image"><div role="button" tabindex="0" class="ll lm di ln bf lo"><div class="gh gi mt"><img src="../Images/c8bcfe80d7bebd09c5934b033a2ffb98.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*WVyfnJqRH33Ntw8xm_vS5A.png"/></div></div></figure><figure class="km kn ko kp gt lk gh gi paragraph-image"><div role="button" tabindex="0" class="ll lm di ln bf lo"><div class="gh gi mu"><img src="../Images/e31d750cbee60450faa2b3d7aac4e3c7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*j1OF1fIWndoQj9mE-yxnqQ.png"/></div></div></figure><p id="9531" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">由此我们可以推断出几点:</p><ul class=""><li id="2637" class="mv mw iq jp b jq jr ju jv jy mx kc my kg mz kk na nb nc nd bi translated">第一层几乎保留了图像的全部形状，也保留了图像中的大部分信息</li><li id="e1a8" class="mv mw iq jp b jq ne ju nf jy ng kc nh kg ni kk na nb nc nd bi translated">随着我们深入网络，我们可以看到激活变得更加复杂和抽象。它开始对边缘、曲线和角度等高级特征进行编码。</li><li id="8c42" class="mv mw iq jp b jq ne ju nf jy ng kc nh kg ni kk na nb nc nd bi translated">此外，随着我们深入研究，我们可以看到我们的许多过滤器没有被激活，这表明我们的模型正在达到其学习能力。</li></ul><p id="45a7" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我们已经成功地可视化了选定的中间激活中的每个通道，并且希望我已经能够给出 CNN 中不同层如何在图像中找出不同模式的基本理解。</p></div></div>    
</body>
</html>