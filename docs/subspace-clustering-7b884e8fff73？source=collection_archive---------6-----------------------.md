# 子空间聚类

> 原文：<https://towardsdatascience.com/subspace-clustering-7b884e8fff73?source=collection_archive---------6----------------------->

## 高维空间中的挑战

这篇文章回答了以下问题:

1.  处理高维数据的挑战是什么？
2.  什么是子空间聚类？
3.  如何用 python 实现子空间聚类算法

![](img/7b2beba79a5ab007e47bc8f5a0159ece.png)

高维数据存在于具有几十到几千个特征(或维度)的输入中。这是在生物信息学(各种测序数据)或 NLP 中经常遇到的情况，其中词汇表的大小非常大。高维数据具有挑战性，因为:

*   这使得可视化和理解输入变得困难，通常需要预先应用降维技术。它导致了“维数灾难”,这意味着随着维数的增加，所有子空间的完全枚举变得难以处理
*   大多数基本的聚类技术依赖于结果和降维技术的选择
*   许多维度可能是不相关的，并且可能掩盖噪声数据中的现有聚类
*   一种常见的技术是执行特征选择(删除不相关的尺寸)，但有时识别冗余尺寸并不容易

# 什么是子空间聚类？

子空间聚类是一种在不同子空间(一个或多个维度的选择)中寻找聚类的技术。潜在的假设是，我们可以找到仅由维度子集定义的有效聚类(不需要所有 N 个特征都一致)。例如，如果我们考虑将观察基因表达水平的患者数据作为输入(我们可以有超过 20000 个特征)，仅通过查看 100 个基因的子集的表达数据就可以发现患有阿尔茨海默病的患者群，或者换句话说，该子集存在于 100 个基因中。换句话说，*子空间聚类是传统 N 维聚类分析的扩展，它允许通过创建行和列聚类来同时对特征和观察值进行分组*。

得到的聚类可能在特征空间和观测空间都重叠。另一个例子如下图所示，摘自[的论文](https://www.kdd.org/exploration_files/parsons.pdf)。我们可以注意到，来自两个聚类的点可能非常接近，这可能会混淆分析整个特征空间的许多传统聚类算法。

![](img/1487f996c144fb3799872e14a6cbde91.png)

此外，我们可以看到子空间聚类设法找到一个子空间(维度 *a* 和 *c* ),在这个子空间中，期望的聚类是容易识别的。

![](img/43b1590dd51099b275375db0395ccc01.png)

# 子空间聚类的类型

根据搜索策略，我们可以区分两种类型的子空间聚类，如下图所示:自底向上方法从在低维(1 D)空间中找到聚类开始，并迭代地合并它们以处理更高维空间(高达 nd)。自顶向下的方法在全维集合中寻找聚类，并评估每个聚类的子空间。下图摘自同一篇论文，概述了最常见的子空间聚类算法。

![](img/2004b83767bb65d2a3bd9f73d787a75e.png)

# 团算法

为了更好地理解子空间聚类，我在 python [这里](https://github.com/ciortanmadalina/subspace_clustering/blob/master/clique_clustering.ipynb)实现了[团](https://www.cs.cornell.edu/johannes/papers/1998/sigmod1998-clique.pdf)算法。

简而言之，该算法的功能如下:对于每个维度(特征)，我们在 *nBins(* 输入参数)中分割空间，并且对于每个 bin，我们计算直方图(计数的数量)。我们只考虑*密集单元*，即计数高于作为第二输入参数给出的*阈值*的仓。密集单元具有以下特征:

*   它所属的尺寸(例如特征 1)
*   容器的索引(或位置)(从 0 到 nBins)
*   躺在箱子里的观察报告

在我的实现中，我已经在 2D 空间中生成了 4 个随机聚类，并且我已经选择了 8 个箱和 2 个点作为最小密度阈值。下图显示了应用于输入空间的结果格网。

![](img/4b230545b030d6d945fb09e3bc93d472.png)

Input space split in 8 bins per dimension

clique 算法背后的直觉是存在于 k 维空间中的聚类也可以在 k-1 中找到。我们从 1D 开始，对于每个维度，我们试图找到密集的箱。如果两个或更多的密集仓是相邻的，我们将它们合并成一个更大的仓。该操作可以通过将所有现有的密集面元转换成图来容易地实现，其中如果 2 个密集单元属于相同的维度并且它们的面元索引之间的差不超过 1(例如，对应于特征 3 和面元 4 的密集单元是相同特征的密集单元以及面元 3 和 5 的邻居)，则绘制边。要合并的密集单元可以通过计算上述图上的连通分量来识别。

该合并操作的结果为第一维度检索 1 D 中的以下聚类(每个聚类一个图):

![](img/f8d931b95627805ad9a16ab08ce780be.png)

对于第二维度:

![](img/84983aca055dd907a434c8f8cd51d134.png)

接下来，我们要计算从 2 到输入维数的每个子空间中的所有有效聚类*。该操作归结为计算 k 维中密集单元的组合，并且仅保留具有大小大于初始最小密度阈值的密集连续箱的重叠的结果。一旦我们计算了 k-1 维的密集单元，我们可以通过计算最后 k-1 个候选的所有组合来扩展到 k 维。*

因此，在 2 D 中，我们能够检索下图所示的集群。注意，4 个聚类之外的一些点(紫色)是因为它们属于密度低于任意输入 2 的箱。

![](img/a997cfb2caea49d4f4ea425d8a9e53c0.png)

团聚类因其对输入参数(箱的数量和最小密度)的高度敏感性而受到批评，这会导致非常不同的结果。然而，它是自底向上子空间聚类家族中的一个基本算法。有多种方法可以优化 clique 算法，例如通过使用 [MAFIA](http://www.quretec.com/u/vilo/edu/2003-04/DM_seminar_2003_II/ver1/P12/articles/goil99mafia.pdf) 算法中提出的密度自适应网格。

# 参考

[小团体论文](https://www.cs.cornell.edu/johannes/papers/1998/sigmod1998-clique.pdf)

[黑手党算法](http://www.quretec.com/u/vilo/edu/2003-04/DM_seminar_2003_II/ver1/P12/articles/goil99mafia.pdf)

[子空间聚类方法的比较研究](https://www.kdd.org/exploration_files/parsons.pdf)

[子空间聚类方法的介绍](https://imada.sdu.dk/~zimek/publications/VLDB08/tutorialSlides.pdf)