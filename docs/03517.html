<html>
<head>
<title>Don’t Overfit! — How to prevent Overfitting in your Deep Learning Models</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">不要过度配合！—如何防止深度学习模型过度拟合</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/dont-overfit-how-to-prevent-overfitting-in-your-deep-learning-models-63274e552323?source=collection_archive---------1-----------------------#2019-06-05">https://towardsdatascience.com/dont-overfit-how-to-prevent-overfitting-in-your-deep-learning-models-63274e552323?source=collection_archive---------1-----------------------#2019-06-05</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><figure class="ip iq gp gr ir is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi io"><img src="../Images/77a74e9276a2679a831b5f2aafad5d94.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*u0LZB6PWVIDcvugn"/></div></div><figcaption class="iz ja gj gh gi jb jc bd b be z dk">Feature Learning can help you prevent overfitting</figcaption></figure><div class=""/><div class=""><h2 id="963c" class="pw-subtitle-paragraph kc je jf bd b kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt dk translated">了解有关无监督特征学习等常见策略的更多信息，这些策略可以帮助您防止过度拟合</h2></div><p id="4877" class="pw-post-body-paragraph ku kv jf kw b kx ky kg kz la lb kj lc ld le lf lg lh li lj lk ll lm ln lo lp ij bi translated">在这篇文章中，我将谈论如何在深度学习模型中防止过度拟合。为了有一个参考数据集，我使用了<a class="ae lq" href="https://www.kaggle.com/c/dont-overfit-ii" rel="noopener ugc nofollow" target="_blank">不要过度拟合！II </a>来自 Kaggle 的挑战。</p><blockquote class="lr ls lt"><p id="3da9" class="ku kv lu kw b kx ky kg kz la lb kj lc lv le lf lg lw li lj lk lx lm ln lo lp ij bi translated">如果你真的想赢得这样的挑战，<strong class="kw jg">不要使用神经网络</strong>，因为它们很容易过度拟合。但是，我们不是来赢得 Kaggle 挑战的，而是来学习如何防止深度学习模型中的过度拟合。</p></blockquote><p id="e3e5" class="pw-post-body-paragraph ku kv jf kw b kx ky kg kz la lb kj lc ld le lf lg lh li lj lk ll lm ln lo lp ij bi translated">所以让我们开始吧！</p></div><div class="ab cl ly lz hu ma" role="separator"><span class="mb bw bk mc md me"/><span class="mb bw bk mc md me"/><span class="mb bw bk mc md"/></div><div class="ij ik il im in"><h1 id="bf34" class="mf mg jf bd mh mi mj mk ml mm mn mo mp kl mq km mr ko ms kp mt kr mu ks mv mw bi translated">基础模型</h1><p id="2f12" class="pw-post-body-paragraph ku kv jf kw b kx mx kg kz la my kj lc ld mz lf lg lh na lj lk ll nb ln lo lp ij bi translated">为了了解如何防止过度拟合，我们首先需要创建一个基础模型来与改进的模型进行比较。基本模型是一个简单的 keras 模型，有两个隐藏层，分别有 128 和 64 个神经元。你可以在这里查看:</p><figure class="nc nd ne nf gt is"><div class="bz fp l di"><div class="ng nh l"/></div></figure><p id="f934" class="pw-post-body-paragraph ku kv jf kw b kx ky kg kz la lb kj lc ld le lf lg lh li lj lk ll lm ln lo lp ij bi translated">使用该模型，我们可以实现超过 97%的训练准确率，但是验证准确率只有大约 60%。在下图中，我们可以看到明显的过度拟合迹象:列车损耗<strong class="kw jg">减少</strong>，但是验证损耗<strong class="kw jg">增加</strong>。</p><figure class="nc nd ne nf gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi ni"><img src="../Images/345e77a44010945aafd6595f66fe3014.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*6f5YKyzGpz_tVM47QoNWGQ.png"/></div></div><figcaption class="iz ja gj gh gi jb jc bd b be z dk">This is a sign of overfitting: Train loss is going down, but validation loss is rising</figcaption></figure><p id="bfaa" class="pw-post-body-paragraph ku kv jf kw b kx ky kg kz la lb kj lc ld le lf lg lh li lj lk ll lm ln lo lp ij bi translated">如果您看到类似这样的情况，这是您的模型过度拟合的明显迹象:它很好地学习了训练数据，但未能将知识推广到测试数据。有了这个模型，我们在 Kaggle 挑战赛中得到了大约<strong class="kw jg"> 59% </strong>的分数——不是很好。</p><p id="1560" class="pw-post-body-paragraph ku kv jf kw b kx ky kg kz la lb kj lc ld le lf lg lh li lj lk ll lm ln lo lp ij bi translated">那么，让我们看看如何改进这个模型</p></div><div class="ab cl ly lz hu ma" role="separator"><span class="mb bw bk mc md me"/><span class="mb bw bk mc md me"/><span class="mb bw bk mc md"/></div><div class="ij ik il im in"><h1 id="69a6" class="mf mg jf bd mh mi mj mk ml mm mn mo mp kl mq km mr ko ms kp mt kr mu ks mv mw bi translated">提高分数</h1><p id="d66c" class="pw-post-body-paragraph ku kv jf kw b kx mx kg kz la my kj lc ld mz lf lg lh na lj lk ll nb ln lo lp ij bi translated">为了提高分数，我们基本上可以做两件事</p><ul class=""><li id="dd52" class="nj nk jf kw b kx ky la lb ld nl lh nm ll nn lp no np nq nr bi translated">改进我们的模型</li><li id="2ff6" class="nj nk jf kw b kx ns la nt ld nu lh nv ll nw lp no np nq nr bi translated">改善我们的数据</li></ul><p id="ee8f" class="pw-post-body-paragraph ku kv jf kw b kx ky kg kz la lb kj lc ld le lf lg lh li lj lk ll lm ln lo lp ij bi translated">我将首先向您展示如何更改基本模型。然后，我将进入<strong class="kw jg">功能选择</strong>，它允许您更改数据</p></div><div class="ab cl ly lz hu ma" role="separator"><span class="mb bw bk mc md me"/><span class="mb bw bk mc md me"/><span class="mb bw bk mc md"/></div><div class="ij ik il im in"><h1 id="07af" class="mf mg jf bd mh mi mj mk ml mm mn mo mp kl mq km mr ko ms kp mt kr mu ks mv mw bi translated">改进我们的模型</h1><p id="f885" class="pw-post-body-paragraph ku kv jf kw b kx mx kg kz la my kj lc ld mz lf lg lh na lj lk ll nb ln lo lp ij bi translated">为了防止过度拟合，我将谈论三种调整你的模型的常用方法。</p><h2 id="0bbc" class="nx mg jf bd mh ny nz dn ml oa ob dp mp ld oc od mr lh oe of mt ll og oh mv oi bi translated">1:简化模型</h2><p id="8121" class="pw-post-body-paragraph ku kv jf kw b kx mx kg kz la my kj lc ld mz lf lg lh na lj lk ll nb ln lo lp ij bi translated">处理过度拟合的第一步是降低模型的复杂性。在给定的基础模型中，有 2 个隐藏层，一个具有 128 个神经元，一个具有 64 个神经元。此外，输入层有 300 个神经元。这是大量的神经元。为了降低复杂性，我们可以简单地删除层或减少神经元的数量，以使我们的网络更小。没有一个通用的规则来规定要移除多少或者你的网络应该有多大。但是，如果你的网络超负荷，试着把它变小。</p><h2 id="50be" class="nx mg jf bd mh ny nz dn ml oa ob dp mp ld oc od mr lh oe of mt ll og oh mv oi bi translated">2:添加漏失层</h2><p id="d741" class="pw-post-body-paragraph ku kv jf kw b kx mx kg kz la my kj lc ld mz lf lg lh na lj lk ll nb ln lo lp ij bi translated">脱落层是防止模型过度拟合的简单有效的方法。丢弃层随机丢弃层之间的一些连接。这有助于防止过度拟合，因为如果一个连接断开，网络被迫幸运的是，使用 keras 很容易添加一个断开层。</p><p id="c198" class="pw-post-body-paragraph ku kv jf kw b kx ky kg kz la lb kj lc ld le lf lg lh li lj lk ll lm ln lo lp ij bi translated">带有脱落层的新的简化模型可能如下所示:</p><figure class="nc nd ne nf gt is"><div class="bz fp l di"><div class="ng nh l"/></div></figure><p id="fafa" class="pw-post-body-paragraph ku kv jf kw b kx ky kg kz la lb kj lc ld le lf lg lh li lj lk ll lm ln lo lp ij bi translated">可以看到，新模型只有一个隐藏层，神经元更少。此外，我还在层间添加了漏失层，漏失率为 0.4。</p><h2 id="4b91" class="nx mg jf bd mh ny nz dn ml oa ob dp mp ld oc od mr lh oe of mt ll og oh mv oi bi translated">3:提前停止</h2><p id="21e6" class="pw-post-body-paragraph ku kv jf kw b kx mx kg kz la my kj lc ld mz lf lg lh na lj lk ll nb ln lo lp ij bi translated">防止过度拟合的另一种方法是尽早停止训练过程:不是训练固定数量的时期，而是在验证损失增加时立即停止，因为在此之后，随着更多的训练，你的模型通常只会变得更差。您可以通过 keras 中的回调轻松实现提前停止:</p><figure class="nc nd ne nf gt is"><div class="bz fp l di"><div class="ng nh l"/></div></figure><p id="bb70" class="pw-post-body-paragraph ku kv jf kw b kx ky kg kz la lb kj lc ld le lf lg lh li lj lk ll lm ln lo lp ij bi translated">为此，您需要将<code class="fe oj ok ol om b">validation_split</code>参数添加到您的<code class="fe oj ok ol om b">fit</code>函数中。否则，<code class="fe oj ok ol om b">val_loss</code>不是用 keras 来衡量的。</p></div><div class="ab cl ly lz hu ma" role="separator"><span class="mb bw bk mc md me"/><span class="mb bw bk mc md me"/><span class="mb bw bk mc md"/></div><div class="ij ik il im in"><h1 id="73c1" class="mf mg jf bd mh mi mj mk ml mm mn mo mp kl mq km mr ko ms kp mt kr mu ks mv mw bi translated">特征选择</h1><p id="c517" class="pw-post-body-paragraph ku kv jf kw b kx mx kg kz la my kj lc ld mz lf lg lh na lj lk ll nb ln lo lp ij bi translated">如果你看一下原始数据，你会看到有<strong class="kw jg"> 300 列</strong>，只有<strong class="kw jg"> 250 行。</strong></p><figure class="nc nd ne nf gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi on"><img src="../Images/420d3ed21715c1d01d668465c289df80.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*04QDRF64JR95HzseIuXfrw.png"/></div></div><figcaption class="iz ja gj gh gi jb jc bd b be z dk">Overview over the datset</figcaption></figure><p id="6910" class="pw-post-body-paragraph ku kv jf kw b kx ky kg kz la lb kj lc ld le lf lg lh li lj lk ll lm ln lo lp ij bi translated">这对于很少的训练样本来说是很多的特征。所以，与其使用所有的特性，不如只使用最重要的特性。一方面，这将使训练过程明显更快，另一方面，它可以帮助防止过度拟合，因为模型不需要学习很多特征。</p><p id="842a" class="pw-post-body-paragraph ku kv jf kw b kx ky kg kz la lb kj lc ld le lf lg lh li lj lk ll lm ln lo lp ij bi translated">幸运的是，scikit-learn 提供了强大的<a class="ae lq" href="https://scikit-learn.org/stable/modules/feature_selection.html" rel="noopener ugc nofollow" target="_blank">特性选择</a>模块，可以帮助您识别数据集的最相关特性。所以，让我们来探索其中的一些方法吧！</p></div><div class="ab cl ly lz hu ma" role="separator"><span class="mb bw bk mc md me"/><span class="mb bw bk mc md me"/><span class="mb bw bk mc md"/></div><div class="ij ik il im in"><h1 id="51d3" class="mf mg jf bd mh mi mj mk ml mm mn mo mp kl mq km mr ko ms kp mt kr mu ks mv mw bi translated">f 分数选择</h1><p id="1fa2" class="pw-post-body-paragraph ku kv jf kw b kx mx kg kz la my kj lc ld mz lf lg lh na lj lk ll nb ln lo lp ij bi translated">选择相关特征的最简单方法之一是计算每个特征的 F 值。F 值是使用要素之间的方差和每个要素内的方差计算的。高 F 值通常意味着该功能比低 F 值的功能更重要。您可以像这样计算要素的 F 值:</p><figure class="nc nd ne nf gt is"><div class="bz fp l di"><div class="ng nh l"/></div></figure><p id="bc70" class="pw-post-body-paragraph ku kv jf kw b kx ky kg kz la lb kj lc ld le lf lg lh li lj lk ll lm ln lo lp ij bi translated">如果你绘制数据，你会看到这样的东西:</p><figure class="nc nd ne nf gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi oo"><img src="../Images/8816a8ad7041bfc1ca281ae0d6047f88.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*f14UWNfTIBWlvCnlt1bFwg.png"/></div></div><figcaption class="iz ja gj gh gi jb jc bd b be z dk">F-Score of each of the 300 features of the dataset</figcaption></figure><p id="972f" class="pw-post-body-paragraph ku kv jf kw b kx ky kg kz la lb kj lc ld le lf lg lh li lj lk ll lm ln lo lp ij bi translated">如你所见，特征之间的 F 值变化很大。您可以使用<code class="fe oj ok ol om b">selector.scores_</code>获得每一列的分数，或者您可以获得前 10 个特性的索引，如下所示:</p><pre class="nc nd ne nf gt op om oq or aw os bi"><span id="efcc" class="nx mg jf om b gy ot ou l ov ow">f_score_indexes = (-selector.scores_).argsort()[:10]</span></pre><h1 id="2bca" class="mf mg jf bd mh mi ox mk ml mm oy mo mp kl oz km mr ko pa kp mt kr pb ks mv mw bi translated">递归特征消除</h1><p id="0bcd" class="pw-post-body-paragraph ku kv jf kw b kx mx kg kz la my kj lc ld mz lf lg lh na lj lk ll nb ln lo lp ij bi translated">另一种方法是递归特征选择。与其他方法不同，使用 RFE，您不需要为每个特征计算分数，而是在越来越小的特征集上多次训练分类器。在每次训练之后，计算特征的重要性，并且从特征集中消除最不重要的特征。</p><figure class="nc nd ne nf gt is"><div class="bz fp l di"><div class="ng nh l"/></div></figure><p id="2e79" class="pw-post-body-paragraph ku kv jf kw b kx ky kg kz la lb kj lc ld le lf lg lh li lj lk ll lm ln lo lp ij bi translated">您可以像这样获得这些特征的索引:</p><pre class="nc nd ne nf gt op om oq or aw os bi"><span id="4075" class="nx mg jf om b gy ot ou l ov ow">rfe_indexes = np.where(rfe_values)[0]</span></pre></div><div class="ab cl ly lz hu ma" role="separator"><span class="mb bw bk mc md me"/><span class="mb bw bk mc md me"/><span class="mb bw bk mc md"/></div><div class="ij ik il im in"><h1 id="5b8b" class="mf mg jf bd mh mi mj mk ml mm mn mo mp kl mq km mr ko ms kp mt kr mu ks mv mw bi translated">结果</h1><p id="3fd0" class="pw-post-body-paragraph ku kv jf kw b kx mx kg kz la my kj lc ld mz lf lg lh na lj lk ll nb ln lo lp ij bi translated">在本文的开始，我们从一个过度拟合的模型开始，这个模型几乎不能达到 50%以上的精度。下面，您可以看到新模型的结果，在选择功能后根据数据进行训练:</p><figure class="nc nd ne nf gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi pc"><img src="../Images/5b8e5cfef6d28e4c927025ee61d1396d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*9SUIv9-99XJIYurnC66_Jw.png"/></div></div><figcaption class="iz ja gj gh gi jb jc bd b be z dk">Results of the improved model</figcaption></figure><p id="da1a" class="pw-post-body-paragraph ku kv jf kw b kx ky kg kz la lb kj lc ld le lf lg lh li lj lk ll lm ln lo lp ij bi translated">它仍然不是完美的，但正如你所看到的，模型过度拟合的方式更少。在 Kaggle 挑战赛中，新模型的得分约为<strong class="kw jg">80%</strong>——比基本模型高出 20%。</p></div></div>    
</body>
</html>