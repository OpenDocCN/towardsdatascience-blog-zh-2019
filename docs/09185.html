<html>
<head>
<title>Metrics and Python II</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">度量和 Python II</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/metrics-and-python-ii-2e49597964ff?source=collection_archive---------15-----------------------#2019-12-05">https://towardsdatascience.com/metrics-and-python-ii-2e49597964ff?source=collection_archive---------15-----------------------#2019-12-05</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="e52c" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">在<a class="ae kf" rel="noopener" target="_blank" href="/metrics-and-python-850b60710e0c">之前的文章</a>中，我们采用了回归问题的度量指南。现在我们来看看分类问题中最常用的指标</h2></div><figure class="kh ki kj kk gt kl gh gi paragraph-image"><div role="button" tabindex="0" class="km kn di ko bf kp"><div class="gh gi kg"><img src="../Images/b18e75f3ef85eb963c1c246c9dd690f1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*y0_a2H0Mswzp7bf5"/></div></div><figcaption class="ks kt gj gh gi ku kv bd b be z dk">Photo by <a class="ae kf" href="https://unsplash.com/@amutiomi?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Miguel A. Amutio</a> on <a class="ae kf" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><h1 id="02ec" class="kw kx iq bd ky kz la lb lc ld le lf lg jw lh jx li jz lj ka lk kc ll kd lm ln bi translated">数据集</h1><p id="25f1" class="pw-post-body-paragraph lo lp iq lq b lr ls jr lt lu lv ju lw lx ly lz ma mb mc md me mf mg mh mi mj ij bi translated">我们创建一个包含三个数组的数据集:真实值、预测值和似然值。<br/><em class="mk">real _ values</em>:0 到 1 之间有 1000 个元素的数据集。<br/> <em class="mk"> pred_values </em>:真实数据集的变体，模拟预测，只改变前 150 个值。<br/><em class="mk">【prob _ values】</em>:pred _ values 数组，但包含概率为 0 或 1 的百分比，而不是实际值 0 或 1。它将用于 ROC 图表和召回与精确对比。</p><pre class="kh ki kj kk gt ml mm mn mo aw mp bi"><span id="5b0f" class="mq kx iq mm b gy mr ms l mt mu">real_values = []<br/>prob_values = []<br/>pred_values = []</span><span id="be90" class="mq kx iq mm b gy mv ms l mt mu">for k in range(0,1000):<br/>   value = random.uniform(0, 1)<br/>   real_values.append(int(round(value,0)))</span><span id="fa2d" class="mq kx iq mm b gy mv ms l mt mu">   if k &lt; 150:<br/>      value2 = random.uniform(0, 1)<br/>      prob_values.append(value2)<br/>      pred_values.append(int(round(value2,0)))<br/>   else:<br/>      prob_values.append(value)<br/>      pred_values.append(int(round(value,0)))</span></pre><h1 id="3138" class="kw kx iq bd ky kz la lb lc ld le lf lg jw lh jx li jz lj ka lk kc ll kd lm ln bi translated">混淆矩阵</h1><p id="cf0b" class="pw-post-body-paragraph lo lp iq lq b lr ls jr lt lu lv ju lw lx ly lz ma mb mc md me mf mg mh mi mj ij bi translated">混淆矩阵本身不是一个指标，但它是对真实数据和预测进行分类的重要工具，因此它的组成部分是第一组指标的触发器。</p><pre class="kh ki kj kk gt ml mm mn mo aw mp bi"><span id="8591" class="mq kx iq mm b gy mr ms l mt mu">from sklearn.metrics import confusion_matrix<br/>import scikitplot as skplt<br/>print(confusion_matrix(real_values, pred_values))<br/>skplt.metrics.plot_confusion_matrix(real_values, pred_values,figsize=(8,8))</span></pre><figure class="kh ki kj kk gt kl gh gi paragraph-image"><div class="gh gi mw"><img src="../Images/59bd8edeaba4d95b813e5741fe7c25f8.png" data-original-src="https://miro.medium.com/v2/resize:fit:962/format:webp/1*6JhBAphsgarcHl4lCicwqg.jpeg"/></div></figure></div><div class="ab cl mx my hu mz" role="separator"><span class="na bw bk nb nc nd"/><span class="na bw bk nb nc nd"/><span class="na bw bk nb nc"/></div><div class="ij ik il im in"><h1 id="14ef" class="kw kx iq bd ky kz ne lb lc ld nf lf lg jw ng jx li jz nh ka lk kc ni kd lm ln bi translated">二元分类—表 2.1</h1><figure class="kh ki kj kk gt kl gh gi paragraph-image"><div role="button" tabindex="0" class="km kn di ko bf kp"><div class="gh gi nj"><img src="../Images/115d0e4356fb5a3c9dde0000c023d46d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*LM42F4nqhoAd1sczdysKlQ.jpeg"/></div></div><figcaption class="ks kt gj gh gi ku kv bd b be z dk"><a class="ae kf" href="https://kreilabs.com/wp-content/uploads/2019/12/Metrics_table.pdf" rel="noopener ugc nofollow" target="_blank">https://kreilabs.com/wp-content/uploads/2019/12/Metrics_table.pdf</a></figcaption></figure><p id="d41b" class="pw-post-body-paragraph lo lp iq lq b lr nk jr lt lu nl ju lw lx nm lz ma mb nn md me mf no mh mi mj ij bi translated">您可以在<a class="ae kf" href="https://kreilabs.com/wp-content/uploads/2019/12/Metrics_table.pdf" rel="noopener ugc nofollow" target="_blank">https://kreilabs . com/WP-content/uploads/2019/12/Metrics _ table . pdf</a>中下载完整文件</p><p id="9bb6" class="pw-post-body-paragraph lo lp iq lq b lr nk jr lt lu nl ju lw lx nm lz ma mb nn md me mf no mh mi mj ij bi translated">在这里，我们可以看到 matrix_metrix 例程中表指标的 pyhton 实现:</p><pre class="kh ki kj kk gt ml mm mn mo aw mp bi"><span id="d86e" class="mq kx iq mm b gy mr ms l mt mu">import sklearn.metrics<br/>import math</span><span id="5df2" class="mq kx iq mm b gy mv ms l mt mu">def matrix_metrix(real_values,pred_values,beta):<br/>   CM = confusion_matrix(real_values,pred_values)<br/>   TN = CM[0][0]<br/>   FN = CM[1][0] <br/>   TP = CM[1][1]<br/>   FP = CM[0][1]<br/>   Population = TN+FN+TP+FP<br/>   Prevalence = round( (TP+FP) / Population,2)<br/>   Accuracy   = round( (TP+TN) / Population,4)<br/>   Precision  = round( TP / (TP+FP),4 )<br/>   NPV        = round( TN / (TN+FN),4 )<br/>   FDR        = round( FP / (TP+FP),4 )<br/>   FOR        = round( FN / (TN+FN),4 ) <br/>   check_Pos  = Precision + FDR<br/>   check_Neg  = NPV + FOR<br/>   Recall     = round( TP / (TP+FN),4 )<br/>   FPR        = round( FP / (TN+FP),4 )<br/>   FNR        = round( FN / (TP+FN),4 )<br/>   TNR        = round( TN / (TN+FP),4 ) <br/>   check_Pos2 = Recall + FNR<br/>   check_Neg2 = FPR + TNR<br/>   LRPos      = round( Recall/FPR,4 ) <br/>   LRNeg      = round( FNR / TNR ,4 )<br/>   DOR        = round( LRPos/LRNeg)<br/>   F1         = round ( 2 * ((Precision*Recall)/(Precision+Recall)),4)<br/>   FBeta      = round ( (1+beta**2)*((Precision*Recall)/((beta**2 * Precision)+ Recall)) ,4)<br/>   MCC        = round ( ((TP*TN)-(FP*FN))/math.sqrt((TP+FP)*(TP+FN)*(TN+FP)*(TN+FN))  ,4)<br/>   BM         = Recall+TNR-1<br/>   MK         = Precision+NPV-1</span><span id="fd50" class="mq kx iq mm b gy mv ms l mt mu">   mat_met = pd.DataFrame({<br/>'Metric':['TP','TN','FP','FN','Prevalence','Accuracy','Precision','NPV','FDR','FOR','check_Pos','check_Neg','Recall','FPR','FNR','TNR','check_Pos2','check_Neg2','LR+','LR-','DOR','F1','FBeta','MCC','BM','MK'],     'Value':[TP,TN,FP,FN,Prevalence,Accuracy,Precision,NPV,FDR,FOR,check_Pos,check_Neg,Recall,FPR,FNR,TNR,check_Pos2,check_Neg2,LRPos,LRNeg,DOR,F1,FBeta,MCC,BM,MK]})</span><span id="7a2a" class="mq kx iq mm b gy mv ms l mt mu">   return (mat_met)</span></pre><p id="67b4" class="pw-post-body-paragraph lo lp iq lq b lr nk jr lt lu nl ju lw lx nm lz ma mb nn md me mf no mh mi mj ij bi translated">当我们调用 matrix_metrix 函数时:</p><pre class="kh ki kj kk gt ml mm mn mo aw mp bi"><span id="9ff3" class="mq kx iq mm b gy mr ms l mt mu">beta = 0.4<br/>mat_met = matrix_metrix(real_values,pred_values,beta)<br/>print (mat_met)</span></pre><figure class="kh ki kj kk gt kl gh gi paragraph-image"><div class="gh gi np"><img src="../Images/2fa6f84ae8254ce36d69b6712b5ebe4d.png" data-original-src="https://miro.medium.com/v2/resize:fit:932/format:webp/1*3teiI238Fvj1ag34DnA89A.jpeg"/></div><figcaption class="ks kt gj gh gi ku kv bd b be z dk">Note: Prevalence is 0.505, code has a mistake at first version</figcaption></figure><h2 id="8167" class="mq kx iq bd ky nq nr dn lc ns nt dp lg lx nu nv li mb nw nx lk mf ny nz lm oa bi translated">预测值和实际值</h2><figure class="kh ki kj kk gt kl gh gi paragraph-image"><div class="gh gi ob"><img src="../Images/6ded092ac35b7391cc776334af185473.png" data-original-src="https://miro.medium.com/v2/resize:fit:1132/format:webp/1*7clgS2NTAFKdIakxUUUgPA.png"/></div><figcaption class="ks kt gj gh gi ku kv bd b be z dk"><a class="ae kf" href="https://en.wikipedia.org/wiki/Confusion_matrix" rel="noopener ugc nofollow" target="_blank">https://en.wikipedia.org/wiki/Confusion_matrix</a></figcaption></figure><p id="97e4" class="pw-post-body-paragraph lo lp iq lq b lr nk jr lt lu nl ju lw lx nm lz ma mb nn md me mf no mh mi mj ij bi translated"><strong class="lq ir"> TP =真阳性</strong></p><p id="1c07" class="pw-post-body-paragraph lo lp iq lq b lr nk jr lt lu nl ju lw lx nm lz ma mb nn md me mf no mh mi mj ij bi translated"><strong class="lq ir"> TN =真阴性</strong></p><p id="944e" class="pw-post-body-paragraph lo lp iq lq b lr nk jr lt lu nl ju lw lx nm lz ma mb nn md me mf no mh mi mj ij bi translated"><strong class="lq ir"> FP =假阳性</strong> —相当于假警报或 I 类错误</p><p id="281f" class="pw-post-body-paragraph lo lp iq lq b lr nk jr lt lu nl ju lw lx nm lz ma mb nn md me mf no mh mi mj ij bi translated"><strong class="lq ir"> FN =假阴性— </strong>相当于遗漏或<a class="ae kf" href="https://en.wikipedia.org/wiki/Type_II_error" rel="noopener ugc nofollow" target="_blank">II 型错误</a></p><h2 id="6c17" class="mq kx iq bd ky nq nr dn lc ns nt dp lg lx nu nv li mb nw nx lk mf ny nz lm oa bi translated">总费率*</h2><figure class="kh ki kj kk gt kl gh gi paragraph-image"><div class="gh gi oc"><img src="../Images/0a00d8f89744e8102febcd2104b553bc.png" data-original-src="https://miro.medium.com/v2/resize:fit:924/format:webp/1*YEV6ofnMWfAZolvTzIskUQ.png"/></div><figcaption class="ks kt gj gh gi ku kv bd b be z dk"><a class="ae kf" href="https://en.wikipedia.org/wiki/Confusion_matrix" rel="noopener ugc nofollow" target="_blank">https://en.wikipedia.org/wiki/Confusion_matrix</a></figcaption></figure><p id="3b5d" class="pw-post-body-paragraph lo lp iq lq b lr nk jr lt lu nl ju lw lx nm lz ma mb nn md me mf no mh mi mj ij bi translated"><strong class="lq ir">患病率:</strong>用于衡量总人口中数据的平衡。<br/>可以测量阳性或阴性的发生率，并且两个商数之和= 1，一个平衡的数据集将给出接近 0.5 的系数<br/>如果相反，其中一个因素接近 1，另一个接近 0，我们将得到一个不平衡的数据集。</p><p id="9cb4" class="pw-post-body-paragraph lo lp iq lq b lr nk jr lt lu nl ju lw lx nm lz ma mb nn md me mf no mh mi mj ij bi translated"><strong class="lq ir">精度:</strong>它是系统成功的度量，正面和负面成果的总和超过总人口，表明模型的成功程度。根据案例研究的灵敏度的<a class="ae kf" href="https://slack-redir.net/link?url=https%3A%2F%2Fmedium.com%2Fmercadolibre-datablog%2Fcost-sensitive-classification-in-fraud-prevention-263170d8fcfe&amp;v=3" rel="noopener ugc nofollow" target="_blank">成本，以及数据的平衡(患病率)。</a></p><h2 id="34aa" class="mq kx iq bd ky nq nr dn lc ns nt dp lg lx nu nv li mb nw nx lk mf ny nz lm oa bi translated">预测利率*</h2><figure class="kh ki kj kk gt kl gh gi paragraph-image"><div class="gh gi od"><img src="../Images/5a4da2ed54447d6bfe646f2626adfcea.png" data-original-src="https://miro.medium.com/v2/resize:fit:930/format:webp/1*-aiHUx5j57BfgpZRELzxLA.png"/></div><figcaption class="ks kt gj gh gi ku kv bd b be z dk"><a class="ae kf" href="https://en.wikipedia.org/wiki/Confusion_matrix" rel="noopener ugc nofollow" target="_blank">https://en.wikipedia.org/wiki/Confusion_matrix</a></figcaption></figure><p id="ae09" class="pw-post-body-paragraph lo lp iq lq b lr nk jr lt lu nl ju lw lx nm lz ma mb nn md me mf no mh mi mj ij bi translated"><strong class="lq ir">PPV</strong>——精确度的阳性预测值</p><p id="1ba1" class="pw-post-body-paragraph lo lp iq lq b lr nk jr lt lu nl ju lw lx nm lz ma mb nn md me mf no mh mi mj ij bi translated"><strong class="lq ir"> NPV </strong> —负面预测值</p><blockquote class="oe of og"><p id="ca9a" class="lo lp mk lq b lr nk jr lt lu nl ju lw oh nm lz ma oi nn md me oj no mh mi mj ij bi translated">PPV 和 NPV 描述了诊断测试或其他统计测量的性能。高结果可以被解释为表明这种统计的准确性。PPV 和 NPV 不是测试固有的；它们还取决于<a class="ae kf" href="https://en.wikipedia.org/wiki/Prevalence" rel="noopener ugc nofollow" target="_blank">流行率</a>。⁴</p></blockquote><p id="770d" class="pw-post-body-paragraph lo lp iq lq b lr nk jr lt lu nl ju lw lx nm lz ma mb nn md me mf no mh mi mj ij bi translated"><strong class="lq ir"> FDR </strong> —错误发现率(第一类)【四】</p><p id="96c9" class="pw-post-body-paragraph lo lp iq lq b lr nk jr lt lu nl ju lw lx nm lz ma mb nn md me mf no mh mi mj ij bi translated"><strong class="lq ir">为</strong>——漏报率</p><p id="748a" class="pw-post-body-paragraph lo lp iq lq b lr nk jr lt lu nl ju lw lx nm lz ma mb nn md me mf no mh mi mj ij bi translated"><strong class="lq ir"> check_Pos: </strong> PPV + FDR = 1</p><p id="8283" class="pw-post-body-paragraph lo lp iq lq b lr nk jr lt lu nl ju lw lx nm lz ma mb nn md me mf no mh mi mj ij bi translated"><strong class="lq ir"> check_Neg: </strong> FOR + NPV = 1</p><h2 id="ab51" class="mq kx iq bd ky nq nr dn lc ns nt dp lg lx nu nv li mb nw nx lk mf ny nz lm oa bi translated">条件利率*</h2><figure class="kh ki kj kk gt kl gh gi paragraph-image"><div class="gh gi ok"><img src="../Images/2a85601d00f1a00f6d48cf8a96871e45.png" data-original-src="https://miro.medium.com/v2/resize:fit:1030/format:webp/1*MwyoEEwqI_hzQ03uwZyvTw.png"/></div><figcaption class="ks kt gj gh gi ku kv bd b be z dk"><a class="ae kf" href="https://en.wikipedia.org/wiki/Confusion_matrix" rel="noopener ugc nofollow" target="_blank">https://en.wikipedia.org/wiki/Confusion_matrix</a></figcaption></figure><p id="881c" class="pw-post-body-paragraph lo lp iq lq b lr nk jr lt lu nl ju lw lx nm lz ma mb nn md me mf no mh mi mj ij bi translated">回忆、灵敏度、检测概率和功效是相同的度量，根据研究领域的不同，它们采用不同的名称和应用。<br/>在涉及二元分类问题的文献中，召回一词的使用更为频繁。</p><blockquote class="oe of og"><p id="8a19" class="lo lp mk lq b lr nk jr lt lu nl ju lw oh nm lz ma oi nn md me oj no mh mi mj ij bi translated"><strong class="lq ir">“敏感性</strong>和<strong class="lq ir">特异性</strong>是二元分类测试性能的统计测量，在统计学中也称为分类函数，广泛用于医学:</p><p id="7d13" class="lo lp mk lq b lr nk jr lt lu nl ju lw oh nm lz ma oi nn md me oj no mh mi mj ij bi translated"><strong class="lq ir">灵敏度</strong>测量被正确识别的实际阳性的比例。</p><p id="9462" class="lo lp mk lq b lr nk jr lt lu nl ju lw oh nm lz ma oi nn md me oj no mh mi mj ij bi translated"><strong class="lq ir">特异性</strong>(也称为<strong class="lq ir">真阴性率</strong>)衡量被正确识别为真阴性的比例(例如，被正确识别为没有患病的健康人的百分比)。⁵</p></blockquote><p id="aa77" class="pw-post-body-paragraph lo lp iq lq b lr nk jr lt lu nl ju lw lx nm lz ma mb nn md me mf no mh mi mj ij bi translated"><strong class="lq ir"> FPR — <em class="mk"> </em> </strong>假阳性率(或误报率)是某一特定检验错误拒绝零假设的概率。</p><p id="1d00" class="pw-post-body-paragraph lo lp iq lq b lr nk jr lt lu nl ju lw lx nm lz ma mb nn md me mf no mh mi mj ij bi translated"><strong class="lq ir"> FNR </strong> —假阴性率是指在测试中产生阴性测试结果的阳性比例，即，假设正在寻找的条件存在，阴性测试结果的条件概率。</p><p id="b424" class="pw-post-body-paragraph lo lp iq lq b lr nk jr lt lu nl ju lw lx nm lz ma mb nn md me mf no mh mi mj ij bi translated">在统计假设检验中，这个分数用字母β表示。测试的“<a class="ae kf" href="https://en.wikipedia.org/wiki/Statistical_power" rel="noopener ugc nofollow" target="_blank">功率</a>”(或“灵敏度”)等于 1β。</p><h2 id="88b3" class="mq kx iq bd ky nq nr dn lc ns nt dp lg lx nu nv li mb nw nx lk mf ny nz lm oa bi translated">组合费率*</h2><figure class="kh ki kj kk gt kl gh gi paragraph-image"><div class="gh gi ol"><img src="../Images/71f92d3d7fa13f3a03aa63b7af62792b.png" data-original-src="https://miro.medium.com/v2/resize:fit:928/format:webp/1*Ml6XMa_IJAu8fmKuik5wRw.png"/></div><figcaption class="ks kt gj gh gi ku kv bd b be z dk"><a class="ae kf" href="https://en.wikipedia.org/wiki/Confusion_matrix" rel="noopener ugc nofollow" target="_blank">https://en.wikipedia.org/wiki/Confusion_matrix</a></figcaption></figure><p id="346f" class="pw-post-body-paragraph lo lp iq lq b lr nk jr lt lu nl ju lw lx nm lz ma mb nn md me mf no mh mi mj ij bi translated">不要与似然比测试混淆。</p><p id="d191" class="pw-post-body-paragraph lo lp iq lq b lr nk jr lt lu nl ju lw lx nm lz ma mb nn md me mf no mh mi mj ij bi translated"><strong class="lq ir"> LR (+ -) </strong>似然比:用于评估执行诊断测试的价值。⁶</p><p id="ade3" class="pw-post-body-paragraph lo lp iq lq b lr nk jr lt lu nl ju lw lx nm lz ma mb nn md me mf no mh mi mj ij bi translated"><strong class="lq ir">or</strong>—诊断优势比是对诊断测试⁷有效性的一种衡量</p></div><div class="ab cl mx my hu mz" role="separator"><span class="na bw bk nb nc nd"/><span class="na bw bk nb nc nd"/><span class="na bw bk nb nc"/></div><div class="ij ik il im in"><h1 id="9f0f" class="kw kx iq bd ky kz ne lb lc ld nf lf lg jw ng jx li jz nh ka lk kc ni kd lm ln bi translated">二元分类—表 2.2</h1><figure class="kh ki kj kk gt kl gh gi paragraph-image"><div role="button" tabindex="0" class="km kn di ko bf kp"><div class="gh gi om"><img src="../Images/64c29dfcf4fcf66d530cf319ec236d25.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*yskpl3M5e6cMI-2v7eX15g.jpeg"/></div></div><figcaption class="ks kt gj gh gi ku kv bd b be z dk"><a class="ae kf" href="https://kreilabs.com/wp-content/uploads/2019/12/Metrics_table.pdf" rel="noopener ugc nofollow" target="_blank">https://kreilabs.com/wp-content/uploads/2019/12/Metrics_table.pdf</a></figcaption></figure><p id="5e3e" class="pw-post-body-paragraph lo lp iq lq b lr nk jr lt lu nl ju lw lx nm lz ma mb nn md me mf no mh mi mj ij bi translated">从用于表 1 的 matrix_metrix 函数中，我们还获得了该表 2 的值:</p><figure class="kh ki kj kk gt kl gh gi paragraph-image"><div class="gh gi on"><img src="../Images/63aa6bdbad95a34234d59b7f5e85c241.png" data-original-src="https://miro.medium.com/v2/resize:fit:282/format:webp/1*dsvStGJDt5k_ycax28TK3w.jpeg"/></div></figure><h2 id="2f0d" class="mq kx iq bd ky nq nr dn lc ns nt dp lg lx nu nv li mb nw nx lk mf ny nz lm oa bi translated">F1 分数</h2><blockquote class="oe of og"><p id="f205" class="lo lp mk lq b lr nk jr lt lu nl ju lw oh nm lz ma oi nn md me oj no mh mi mj ij bi translated">在二进制分类的统计分析中，<strong class="lq ir"> F1 得分</strong>(也称为<strong class="lq ir"> F 得分</strong>或<strong class="lq ir"> F 度量</strong>)是测试准确度的度量。它同时考虑了测试的精度<em class="iq"> p </em>和召回率<em class="iq"> r </em>来计算分数:<em class="iq"> p </em>是正确阳性结果的数量除以分类器返回的所有阳性结果的数量，<em class="iq"> r </em>是正确阳性结果的数量除以所有相关样本(所有本应被识别为阳性的样本)的数量。F1 分数是精确度和召回率的调和平均值，其中 F1 分数在 1 时达到其最佳值(完美的精确度和召回率),在 0 时最差。⁸</p></blockquote><h2 id="aebe" class="mq kx iq bd ky nq nr dn lc ns nt dp lg lx nu nv li mb nw nx lk mf ny nz lm oa bi translated">f-贝塔 Score⁹</h2><p id="16f6" class="pw-post-body-paragraph lo lp iq lq b lr ls jr lt lu lv ju lw lx ly lz ma mb mc md me mf mg mh mi mj ij bi translated">β是用于分数分析的参数，如果我们使用β等于 1，我们就有调和平均值；然后我们有了<strong class="lq ir"> <em class="mk"> F1 的分数</em> </strong>:</p><p id="134e" class="pw-post-body-paragraph lo lp iq lq b lr nk jr lt lu nl ju lw lx nm lz ma mb nn md me mf no mh mi mj ij bi translated">我们可以采取一些经验法则:</p><ul class=""><li id="fc3f" class="oo op iq lq b lr nk lu nl lx oq mb or mf os mj ot ou ov ow bi translated">为了给<strong class="lq ir">精度</strong>更多的权重，我们必须在 0–1<strong class="lq ir"><em class="mk">0&lt;Beta&lt;1</em></strong>之间选择一个 Beta 值<em class="mk"/></li><li id="89c8" class="oo op iq lq b lr ox lu oy lx oz mb pa mf pb mj ot ou ov ow bi translated">为了给<strong class="lq ir">回忆</strong>更多的权重，我们在区间<strong class="lq ir"><em class="mk">1&lt;Beta&lt;+无穷大</em> </strong>中挑选一个 Beta 值</li></ul><h2 id="9218" class="mq kx iq bd ky nq nr dn lc ns nt dp lg lx nu nv li mb nw nx lk mf ny nz lm oa bi translated">ROC 对比精确召回和 AUC ⁰</h2><p id="7109" class="pw-post-body-paragraph lo lp iq lq b lr ls jr lt lu lv ju lw lx ly lz ma mb mc md me mf mg mh mi mj ij bi translated">我们可以在<a class="ae kf" href="https://machinelearningmastery.com/roc-curves-and-precision-recall-curves-for-classification-in-python/" rel="noopener ugc nofollow" target="_blank">中找到一篇关于这些工具的概念和实现的优秀且非常完整的文章</a>。</p><p id="1d24" class="pw-post-body-paragraph lo lp iq lq b lr nk jr lt lu nl ju lw lx nm lz ma mb nn md me mf no mh mi mj ij bi translated"><strong class="lq ir"> ROC </strong> —接收操作特性</p><blockquote class="oe of og"><p id="d83d" class="lo lp mk lq b lr nk jr lt lu nl ju lw oh nm lz ma oi nn md me oj no mh mi mj ij bi translated">它是针对 0.0 和 1.0 之间的多个不同候选阈值的假阳性率(x 轴)与真阳性率(y 轴)的关系图。换句话说，它绘制了虚警率与命中率的关系图。</p></blockquote><p id="ff47" class="pw-post-body-paragraph lo lp iq lq b lr nk jr lt lu nl ju lw lx nm lz ma mb nn md me mf no mh mi mj ij bi translated"><strong class="lq ir">精确召回曲线</strong></p><blockquote class="oe of og"><p id="bcb1" class="lo lp mk lq b lr nk jr lt lu nl ju lw oh nm lz ma oi nn md me oj no mh mi mj ij bi translated">精确度-召回率曲线是不同阈值的精确度(y 轴)和召回率(x 轴)的曲线图，很像 ROC 曲线。无技能分类器是一种不能区分类别的分类器，它在所有情况下都会预测随机类别或恒定类别。无技能线的变化是基于积极类和消极类的分布。它是一条水平线，带有数据集中阳性案例的比率值。对于平衡数据集，这是 0.5。</p></blockquote><p id="a8a1" class="pw-post-body-paragraph lo lp iq lq b lr nk jr lt lu nl ju lw lx nm lz ma mb nn md me mf no mh mi mj ij bi translated"><strong class="lq ir"> AUC —曲线下面积</strong></p><p id="6292" class="pw-post-body-paragraph lo lp iq lq b lr nk jr lt lu nl ju lw lx nm lz ma mb nn md me mf no mh mi mj ij bi translated">曲线下面积(AUC)可用作模型技巧的总结。</p><p id="cfda" class="pw-post-body-paragraph lo lp iq lq b lr nk jr lt lu nl ju lw lx nm lz ma mb nn md me mf no mh mi mj ij bi translated">我们基于上述文章编写了以下代码</p><pre class="kh ki kj kk gt ml mm mn mo aw mp bi"><span id="b34a" class="mq kx iq mm b gy mr ms l mt mu">#ROC Implementation<br/>from sklearn.metrics import roc_curve<br/>from sklearn.metrics import roc_auc_score<br/>from matplotlib import pyplot</span><span id="a8af" class="mq kx iq mm b gy mv ms l mt mu">fpr, tpr, thresholds = roc_curve(real_values, prob_values)<br/>auc = roc_auc_score(real_values, prob_values)<br/>print('AUC: %.3f' % auc)</span><span id="ef8d" class="mq kx iq mm b gy mv ms l mt mu">pyplot.plot(fpr, tpr, linestyle='--', label='Roc curve')<br/>pyplot.xlabel('False Positive Rate')<br/>pyplot.ylabel('True Positive Rate')<br/>pyplot.legend()</span><span id="ab87" class="mq kx iq mm b gy mv ms l mt mu">pyplot.show()</span></pre><figure class="kh ki kj kk gt kl gh gi paragraph-image"><div class="gh gi pc"><img src="../Images/25549e4f0d412df8e9b0a7fc4b67fa58.png" data-original-src="https://miro.medium.com/v2/resize:fit:846/format:webp/1*k0JX3cZwXB-zAyCbIuyOHg.jpeg"/></div></figure><pre class="kh ki kj kk gt ml mm mn mo aw mp bi"><span id="beec" class="mq kx iq mm b gy mr ms l mt mu">#Precision-recall implementation</span><span id="9a30" class="mq kx iq mm b gy mv ms l mt mu">precision, recall, thresholds = sklearn.metrics.precision_recall_curve(real_values,prob_values)</span><span id="b0e0" class="mq kx iq mm b gy mv ms l mt mu">pyplot.plot(recall, precision, linestyle='--', label='Precision versus Recall')<br/>pyplot.xlabel('Recall')<br/>pyplot.ylabel('Precision')<br/>pyplot.legend()</span><span id="88d8" class="mq kx iq mm b gy mv ms l mt mu">pyplot.show()</span></pre><figure class="kh ki kj kk gt kl gh gi paragraph-image"><div class="gh gi pd"><img src="../Images/118eb0f322d896f745bfa22e6b0104f4.png" data-original-src="https://miro.medium.com/v2/resize:fit:804/format:webp/1*60KlZ1reAZPj0PF05AV0Ag.jpeg"/></div></figure><h2 id="3daa" class="mq kx iq bd ky nq nr dn lc ns nt dp lg lx nu nv li mb nw nx lk mf ny nz lm oa bi translated">Sklearn 的其他实现和指标</h2><p id="c02e" class="pw-post-body-paragraph lo lp iq lq b lr ls jr lt lu lv ju lw lx ly lz ma mb mc md me mf mg mh mi mj ij bi translated">这里有一个简单快速的关于二元分类值的报告</p><figure class="kh ki kj kk gt kl gh gi paragraph-image"><div class="gh gi pe"><img src="../Images/0bd6ce63787584a08a8bee861acd3a8c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1150/format:webp/1*hixqgIqcIPz3bh_HaI41TA.jpeg"/></div></figure><p id="b120" class="pw-post-body-paragraph lo lp iq lq b lr nk jr lt lu nl ju lw lx nm lz ma mb nn md me mf no mh mi mj ij bi translated">这里有一个直接从 sklearn 获取许多指标函数:</p><pre class="kh ki kj kk gt ml mm mn mo aw mp bi"><span id="e2fa" class="mq kx iq mm b gy mr ms l mt mu">def sk_metrix(real_values,pred_values,beta):<br/>   Accuracy = round( sklearn.metrics.accuracy_score(real_values,pred_values) ,4)<br/>   <br/>   Precision  = round( sklearn.metrics.precision_score(real_values,pred_values),4 )<br/>   <br/>   Recall     = round( sklearn.metrics.recall_score(real_values,pred_values),4 )</span><span id="575a" class="mq kx iq mm b gy mv ms l mt mu">   F1         = round ( sklearn.metrics.f1_score(real_values,pred_values),4)<br/>   <br/>   FBeta      = round ( sklearn.metrics.fbeta_score(real_values,pred_values,beta) ,4)</span><span id="9b61" class="mq kx iq mm b gy mv ms l mt mu">   MCC        = round ( sklearn.metrics.matthews_corrcoef(real_values,pred_values)  ,4)</span><span id="8a11" class="mq kx iq mm b gy mv ms l mt mu">   Hamming    = round ( sklearn.metrics.hamming_loss(real_values,pred_values) ,4)</span><span id="a2ec" class="mq kx iq mm b gy mv ms l mt mu">   Jaccard    = round ( sklearn.metrics.jaccard_score(real_values,pred_values) ,4)</span><span id="3de2" class="mq kx iq mm b gy mv ms l mt mu">   Prec_Avg   = round ( sklearn.metrics.average_precision_score(real_values,pred_values) ,4)</span><span id="3812" class="mq kx iq mm b gy mv ms l mt mu">   Accu_Avg   = round ( sklearn.metrics.balanced_accuracy_score(real_values,pred_values) ,4)</span><span id="6a6f" class="mq kx iq mm b gy mv ms l mt mu">   mat_met = pd.DataFrame({<br/>'Metric': ['Accuracy','Precision','Recall','F1','FBeta','MCC','Hamming','Jaccard','Precision_Avg','Accuracy_Avg'],<br/>'Value': [Accuracy,Precision,Recall,F1,FBeta,MCC,Hamming,Jaccard,Prec_Avg,Accu_Avg]})</span><span id="b1c8" class="mq kx iq mm b gy mv ms l mt mu">   return (mat_met)</span></pre><p id="b65b" class="pw-post-body-paragraph lo lp iq lq b lr nk jr lt lu nl ju lw lx nm lz ma mb nn md me mf no mh mi mj ij bi translated">调用 sk_metrix 函数</p><pre class="kh ki kj kk gt ml mm mn mo aw mp bi"><span id="5180" class="mq kx iq mm b gy mr ms l mt mu">sk_met = sk_metrix(real_values,pred_values,beta)</span></pre><figure class="kh ki kj kk gt kl gh gi paragraph-image"><div class="gh gi pf"><img src="../Images/b35a977728f3687b2c9e79fdda58ce2b.png" data-original-src="https://miro.medium.com/v2/resize:fit:348/format:webp/1*e74Cgj-JSRg6WkE1_-Fasg.jpeg"/></div></figure><h1 id="8474" class="kw kx iq bd ky kz la lb lc ld le lf lg jw lh jx li jz lj ka lk kc ll kd lm ln bi translated">摘要</h1><p id="2c7c" class="pw-post-body-paragraph lo lp iq lq b lr ls jr lt lu lv ju lw lx ly lz ma mb mc md me mf mg mh mi mj ij bi translated">混淆矩阵中产生的指标数量非常大，根据用例来细化每个指标的使用可能很难涵盖。最常见的指标可能是 F1 评分、ROC、精确回忆 AUC、患病率和敏感性。</p><p id="8236" class="pw-post-body-paragraph lo lp iq lq b lr nk jr lt lu nl ju lw lx nm lz ma mb nn md me mf no mh mi mj ij bi translated">这一系列文章旨在创建一个表格，在该表格中可以快速找到每个案例研究中使用的大多数指标的指南；掌握它们的应用超出了我们的范围，似乎也相当困难。<br/>记住表格可以<a class="ae kf" href="https://kreilabs.com/wp-content/uploads/2019/12/Metrics_table.pdf" rel="noopener ugc nofollow" target="_blank">下载成 pdf 格式</a>。</p><p id="02bf" class="pw-post-body-paragraph lo lp iq lq b lr nk jr lt lu nl ju lw lx nm lz ma mb nn md me mf no mh mi mj ij bi translated">在下一篇文章中，我们将在表 2.3 中看到更多的分类指标和推荐系统的具体指标</p><h1 id="4bb9" class="kw kx iq bd ky kz la lb lc ld le lf lg jw lh jx li jz lj ka lk kc ll kd lm ln bi translated">参考</h1><p id="acbe" class="pw-post-body-paragraph lo lp iq lq b lr ls jr lt lu lv ju lw lx ly lz ma mb mc md me mf mg mh mi mj ij bi translated">https://en.wikipedia.org/wiki/Confusion_matrix<a class="ae kf" href="https://en.wikipedia.org/wiki/Sensitivity_and_specificity" rel="noopener ugc nofollow" target="_blank"/></p><p id="b719" class="pw-post-body-paragraph lo lp iq lq b lr nk jr lt lu nl ju lw lx nm lz ma mb nn md me mf no mh mi mj ij bi translated">[1]第一类错误</p><p id="ad40" class="pw-post-body-paragraph lo lp iq lq b lr nk jr lt lu nl ju lw lx nm lz ma mb nn md me mf no mh mi mj ij bi translated">[2]第二类错误</p><p id="206d" class="pw-post-body-paragraph lo lp iq lq b lr nk jr lt lu nl ju lw lx nm lz ma mb nn md me mf no mh mi mj ij bi translated">[3]<a class="ae kf" href="https://medium.com/mercadolibre-datablog/cost-sensitive-classification-in-fraud-prevention-263170d8fcfe" rel="noopener">https://medium . com/Mercado libre-datablog/cost-sensitive-class-in-fraud-prevention-263170 D8 fcfe</a></p><p id="9dba" class="pw-post-body-paragraph lo lp iq lq b lr nk jr lt lu nl ju lw lx nm lz ma mb nn md me mf no mh mi mj ij bi translated">【4】<strong class="lq ir">阳性和阴性预测值</strong>(分别为<strong class="lq ir"> PPV </strong>和<strong class="lq ir"> NPV </strong>)分别为<a class="ae kf" href="https://en.wikipedia.org/wiki/Statistics" rel="noopener ugc nofollow" target="_blank">统计</a>和<a class="ae kf" href="https://en.wikipedia.org/wiki/Diagnostic_test" rel="noopener ugc nofollow" target="_blank">诊断测试</a>中阳性和阴性结果的比例，分别为<a class="ae kf" href="https://en.wikipedia.org/wiki/True_positive" rel="noopener ugc nofollow" target="_blank">真阳性</a>和<a class="ae kf" href="https://en.wikipedia.org/wiki/True_negative" rel="noopener ugc nofollow" target="_blank">真阴性</a>结果。<a class="ae kf" href="https://en.wikipedia.org/wiki/Positive_and_negative_predictive_values#cite_note-1" rel="noopener ugc nofollow" target="_blank">【1】</a>“PPV 和 NPV 描述了诊断测试或其他统计测量的性能。高结果可以被解释为表明这种统计的准确性。PPV 和 NPV 不是测试固有的；它们也取决于<a class="ae kf" href="https://en.wikipedia.org/wiki/Prevalence" rel="noopener ugc nofollow" target="_blank">流行程度</a>。<a class="ae kf" href="https://en.wikipedia.org/wiki/Positive_and_negative_predictive_values#cite_note-AltmanBland1994-2" rel="noopener ugc nofollow" target="_blank">【2】</a>使用<a class="ae kf" href="https://en.wikipedia.org/wiki/Bayes%27_theorem" rel="noopener ugc nofollow" target="_blank">贝叶斯定理</a>可以推导出 PPV。虽然有时用作同义词，但是<em class="mk">阳性预测值</em>通常是指由对照组建立的，而<a class="ae kf" href="https://en.wikipedia.org/wiki/Pre-_and_post-test_probability" rel="noopener ugc nofollow" target="_blank">测试后概率</a>是指个体的概率。然而，如果个体的目标状况的<a class="ae kf" href="https://en.wikipedia.org/wiki/Pre-test_probability" rel="noopener ugc nofollow" target="_blank">预测试概率</a>与用于建立阳性预测值的对照组中的患病率相同，则两者在数值上相等。</p><p id="674f" class="pw-post-body-paragraph lo lp iq lq b lr nk jr lt lu nl ju lw lx nm lz ma mb nn md me mf no mh mi mj ij bi translated">(<a class="ae kf" href="https://en.wikipedia.org/wiki/Positive_and_negative_predictive_values" rel="noopener ugc nofollow" target="_blank">https://en . Wikipedia . org/wiki/Positive _ and _ negative _ predictive _ values</a>)</p><p id="b7f3" class="pw-post-body-paragraph lo lp iq lq b lr nk jr lt lu nl ju lw lx nm lz ma mb nn md me mf no mh mi mj ij bi translated"><a class="ae kf" href="https://en.wikipedia.org/wiki/Sensitivity_and_specificity" rel="noopener ugc nofollow" target="_blank">https://en.wikipedia.org/wiki/Sensitivity_and_specificity</a></p><p id="8d4a" class="pw-post-body-paragraph lo lp iq lq b lr nk jr lt lu nl ju lw lx nm lz ma mb nn md me mf no mh mi mj ij bi translated">[6]<a class="ae kf" href="https://en.wikipedia.org/wiki/Likelihood_ratios_in_diagnostic_testing#positive_likelihood_ratio" rel="noopener ugc nofollow" target="_blank">https://en . Wikipedia . org/wiki/Likelihood _ ratios _ in _ diagnostic _ testing # positive _ Likelihood _ ratio</a></p><p id="e02b" class="pw-post-body-paragraph lo lp iq lq b lr nk jr lt lu nl ju lw lx nm lz ma mb nn md me mf no mh mi mj ij bi translated">[7]<a class="ae kf" href="https://en.wikipedia.org/wiki/Diagnostic_odds_ratio" rel="noopener ugc nofollow" target="_blank">https://en.wikipedia.org/wiki/Diagnostic_odds_ratio</a></p><p id="3824" class="pw-post-body-paragraph lo lp iq lq b lr nk jr lt lu nl ju lw lx nm lz ma mb nn md me mf no mh mi mj ij bi translated">[8]https://en.wikipedia.org/wiki/F1_score<a class="ae kf" href="https://en.wikipedia.org/wiki/F1_score" rel="noopener ugc nofollow" target="_blank"/></p><p id="f8d6" class="pw-post-body-paragraph lo lp iq lq b lr nk jr lt lu nl ju lw lx nm lz ma mb nn md me mf no mh mi mj ij bi translated">[9]<a class="ae kf" href="http://www.marcelonet.com/snippets/machine-learning/evaluation-metrix/f-beta-score" rel="noopener ugc nofollow" target="_blank">http://www . marcelonet . com/snippets/machine-learning/evaluation-metrix/f-beta-score</a></p><p id="ec00" class="pw-post-body-paragraph lo lp iq lq b lr nk jr lt lu nl ju lw lx nm lz ma mb nn md me mf no mh mi mj ij bi translated">[10]<a class="ae kf" href="https://machinelearningmastery.com/roc-curves-and-precision-recall-curves-for-classification-in-python/" rel="noopener ugc nofollow" target="_blank">https://machine learning mastery . com/roc-curves-and-precision-recall-curves-for-class ification-in-python/</a></p></div></div>    
</body>
</html>