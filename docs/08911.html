<html>
<head>
<title>Object detection using Mask R-CNN on a custom dataset</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">在定制数据集上使用掩模 R-CNN 的对象检测</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/object-detection-using-mask-r-cnn-on-a-custom-dataset-4f79ab692f6d?source=collection_archive---------2-----------------------#2019-11-28">https://towardsdatascience.com/object-detection-using-mask-r-cnn-on-a-custom-dataset-4f79ab692f6d?source=collection_archive---------2-----------------------#2019-11-28</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><p id="c144" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu"> <em class="ko">在这篇文章中，我们将实现掩模 R-CNN，用于从自定义数据集</em> </strong>中检测对象</p><h2 id="a173" class="kp kq it bd kr ks kt dn ku kv kw dp kx kb ky kz la kf lb lc ld kj le lf lg lh bi translated">先决条件:</h2><p id="a0f1" class="pw-post-body-paragraph jq jr it js b jt li jv jw jx lj jz ka kb lk kd ke kf ll kh ki kj lm kl km kn im bi translated"><a class="ae ln" rel="noopener" target="_blank" href="/computer-vision-a-journey-from-cnn-to-mask-r-cnn-and-yolo-1d141eba6e04">计算机视觉:从 CNN 到面具 R-CC 和 YOLO 的旅程第一部分</a></p><p id="f174" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><a class="ae ln" rel="noopener" target="_blank" href="/computer-vision-a-journey-from-cnn-to-mask-r-cnn-and-yolo-part-2-b0b9e67762b1">计算机视觉:从 CNN 到面具之旅 R-CNN 和 YOLO 第二部分</a></p><p id="27e6" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><a class="ae ln" href="https://medium.com/@arshren/computer-vision-instance-segmentation-with-mask-r-cnn-7983502fcad1" rel="noopener">实例分割使用掩模 R-CNN </a></p><p id="4104" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><a class="ae ln" rel="noopener" target="_blank" href="/deep-learning-using-transfer-learning-cfbce1578659">迁移学习</a></p><p id="ec92" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><a class="ae ln" href="https://medium.com/@arshren/deep-learning-using-transfer-learning-python-code-for-resnet50-8acdfb3a2d38" rel="noopener">使用 ResNet50 转移学习</a></p><h2 id="c0f0" class="kp kq it bd kr ks kt dn ku kv kw dp kx kb ky kz la kf lb lc ld kj le lf lg lh bi translated">数据集</h2><p id="43c8" class="pw-post-body-paragraph jq jr it js b jt li jv jw jx lj jz ka kb lk kd ke kf ll kh ki kj lm kl km kn im bi translated"><a class="ae ln" href="https://github.com/experiencor/kangaroo" rel="noopener ugc nofollow" target="_blank">文章中使用了袋鼠数据集</a></p><h2 id="2004" class="kp kq it bd kr ks kt dn ku kv kw dp kx kb ky kz la kf lb lc ld kj le lf lg lh bi translated">屏蔽 R-CNN</h2><p id="4e58" class="pw-post-body-paragraph jq jr it js b jt li jv jw jx lj jz ka kb lk kd ke kf ll kh ki kj lm kl km kn im bi translated">Mask R-CNN 是用于实例分割的深度神经网络。该模型分为两部分</p><ul class=""><li id="b401" class="lo lp it js b jt ju jx jy kb lq kf lr kj ls kn lt lu lv lw bi translated"><strong class="js iu">区域提议网络(RPN)提出候选对象包围盒。</strong></li><li id="6f9a" class="lo lp it js b jt lx jx ly kb lz kf ma kj mb kn lt lu lv lw bi translated"><strong class="js iu">二进制掩码分类器，为每个类别生成掩码</strong></li></ul><figure class="md me mf mg gt mh gh gi paragraph-image"><div role="button" tabindex="0" class="mi mj di mk bf ml"><div class="gh gi mc"><img src="../Images/51ce8b461867e0a371efa49bcc062292.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ZiEsSrN57IlyUF52Vtp0iQ.png"/></div></div></figure><p id="055b" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">掩模 R-CNN 具有用于分类和包围盒回归的分支。它使用</p><ul class=""><li id="020e" class="lo lp it js b jt ju jx jy kb lq kf lr kj ls kn lt lu lv lw bi translated">ResNet101 架构从图像中提取特征。</li><li id="66c9" class="lo lp it js b jt lx jx ly kb lz kf ma kj mb kn lt lu lv lw bi translated">区域提议网络(RPN)生成感兴趣区域(RoI)</li></ul><h1 id="7257" class="mo kq it bd kr mp mq mr ku ms mt mu kx mv mw mx la my mz na ld nb nc nd lg ne bi translated">keras 中使用掩码 R-CNN 码的迁移学习</h1><p id="a67a" class="pw-post-body-paragraph jq jr it js b jt li jv jw jx lj jz ka kb lk kd ke kf ll kh ki kj lm kl km kn im bi translated">为此我们使用<strong class="js iu"/><a class="ae ln" href="https://github.com/matterport/Mask_RCNN" rel="noopener ugc nofollow" target="_blank"><strong class="js iu">matter port Mask R-CNN</strong></a><strong class="js iu">。</strong></p><p id="da87" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu">步骤 1:克隆屏蔽 R-CNN 库</strong></p><pre class="md me mf mg gt nf ng nh ni aw nj bi"><span id="3ffc" class="kp kq it ng b gy nk nl l nm nn">git clone <a class="ae ln" href="https://github.com/matterport/Mask_RCNN.git" rel="noopener ugc nofollow" target="_blank">https://github.com/matterport/Mask_RCNN.git</a><br/>cd Mask_RCNN<br/>$ python setup.py install</span></pre><p id="1826" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu">第二步:从</strong><a class="ae ln" href="https://github.com/matterport/Mask_RCNN/releases/download/v2.0/mask_rcnn_coco.h5" rel="noopener ugc nofollow" target="_blank"><strong class="js iu">matter port</strong></a>下载 COCO 模型的预训练权重。</p><p id="260b" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">将文件放在名为“mask_rcnn_coco.h5”的 Mask_RCNN 文件夹中</p><p id="93e8" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu">第三步:导入所需的库</strong></p><pre class="md me mf mg gt nf ng nh ni aw nj bi"><span id="1e14" class="kp kq it ng b gy nk nl l nm nn">from mrcnn.config import Config<br/>from mrcnn import model as modellib<br/>from mrcnn import visualize<br/>import mrcnn<br/>from mrcnn.utils import Dataset<br/>from mrcnn.model import MaskRCNN</span><span id="d599" class="kp kq it ng b gy no nl l nm nn">import numpy as np<br/>from numpy import zeros<br/>from numpy import asarray<br/>import colorsys<br/>import argparse<br/>import imutils<br/>import random<br/>import cv2<br/>import os<br/>import time</span><span id="eebf" class="kp kq it ng b gy no nl l nm nn">from matplotlib import pyplot<br/>from matplotlib.patches import Rectangle<br/>from keras.models import load_model</span><span id="ac04" class="kp kq it ng b gy no nl l nm nn">%matplotlib inline</span><span id="97f7" class="kp kq it ng b gy no nl l nm nn">from os import listdir<br/>from xml.etree import ElementTree</span></pre><p id="6311" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu">步骤 4: </strong>我们创建一个<strong class="js iu"><em class="ko">myMaskRCNNConfig</em></strong>类，用于在袋鼠数据集<strong class="js iu">上进行训练。</strong>它是从基础<strong class="js iu"><em class="ko">Mask R-CNN Config</em></strong><em class="ko"/>类派生出来的，覆盖了一些值。</p><pre class="md me mf mg gt nf ng nh ni aw nj bi"><span id="c557" class="kp kq it ng b gy nk nl l nm nn"><strong class="ng iu">class myMaskRCNNConfig(Config):</strong><br/>    # give the configuration a recognizable name<br/>    <strong class="ng iu">NAME = "MaskRCNN_config"</strong><br/> <br/>    # set the number of GPUs to use along with the number of images<br/>    # per GPU<br/>    <strong class="ng iu">GPU_COUNT = 1<br/>    IMAGES_PER_GPU = 1</strong><br/> <br/>    # number of classes (we would normally add +1 for the background)<br/>     # kangaroo + BG<br/>    <strong class="ng iu">NUM_CLASSES = 1+1</strong><br/>   <br/>    # Number of training steps per epoch<br/>    <strong class="ng iu">STEPS_PER_EPOCH = 131</strong><br/>    <br/>    # Learning rate<br/>    <strong class="ng iu">LEARNING_RATE=0.006</strong><br/>    <br/>    # Skip detections with &lt; 90% confidence<br/>   <strong class="ng iu"> DETECTION_MIN_CONFIDENCE = 0.9</strong><br/>    <br/>    # setting Max ground truth instances<br/>    <strong class="ng iu">MAX_GT_INSTANCES=10</strong></span></pre><p id="4d0d" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu">步骤 5:创建一个<em class="ko"> myMaskRCNNConfig </em>类</strong>的实例</p><pre class="md me mf mg gt nf ng nh ni aw nj bi"><span id="e062" class="kp kq it ng b gy nk nl l nm nn"><strong class="ng iu">config = myMaskRCNNConfig()</strong></span></pre><p id="6bbd" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">让我们显示所有的配置值。</p><pre class="md me mf mg gt nf ng nh ni aw nj bi"><span id="a141" class="kp kq it ng b gy nk nl l nm nn"><strong class="ng iu">config.display()</strong></span></pre><figure class="md me mf mg gt mh gh gi paragraph-image"><div role="button" tabindex="0" class="mi mj di mk bf ml"><div class="gh gi np"><img src="../Images/c0c4731a89cebd1bcb640bcaf4caa9ba.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ZYU_SW2MXQ-yxb1XBZFiag.png"/></div></div></figure><p id="2e04" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">第六步:建立定制的袋鼠数据集。</p><p id="16fe" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu">数据集类提供了一种一致的方式来处理任何数据集</strong>。我们将为袋鼠数据集创建新的数据集进行训练，而无需更改模型的代码。</p><p id="9845" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">数据集类还支持同时加载多个数据集。当您想要检测不同的对象，而它们都不在一个数据集中时，这非常有用。</p><p id="1d4d" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">在<strong class="js iu"> <em class="ko"> load_dataset </em> </strong>方法中，我们使用<strong class="js iu"> <em class="ko"> add_class </em> </strong>和<strong class="js iu"> <em class="ko"> add_image </em> </strong>方法遍历 image 和 annotations 文件夹中的所有文件来添加类、图像和注释以创建数据集。</p><p id="178c" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu"><em class="ko">extract _ boxes</em></strong>方法从注释文件中提取每个边界框。注释文件是使用 pascal VOC 格式的 xml 文件。它返回盒子，它的高度和宽度</p><p id="1830" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu"> <em class="ko"> load_mask </em> </strong>方法为图像中的每个对象生成遮罩。它为每个实例和类 id 返回一个掩码，这是实例掩码的类 id 的 1D 数组</p><p id="7a57" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu"><em class="ko">image _ reference</em></strong>方法返回图像的路径</p><pre class="md me mf mg gt nf ng nh ni aw nj bi"><span id="f8d4" class="kp kq it ng b gy nk nl l nm nn"><strong class="ng iu">class KangarooDataset(Dataset)</strong>:<br/>    # load the dataset definitions<br/>    <strong class="ng iu">def load_dataset(self, dataset_dir, is_train=True)</strong>:<br/>        <br/>        # Add classes. We have only one class to add.<br/>        <strong class="ng iu">self.add_class("dataset", 1, "kangaroo")</strong><br/>        <br/>        # define data locations for images and annotations<br/>        images_dir = dataset_dir + '\\images\\'<br/>        annotations_dir = dataset_dir + '\\annots\\'<br/>        <br/>        # Iterate through all files in the folder to <br/>        #add class, images and annotaions<br/>        <strong class="ng iu">for filename in listdir(images_dir):</strong><br/>            <br/>            # extract image id<br/>            image_id = filename[:-4]<br/>            <br/>            # skip bad images<br/>            if image_id in ['00090']:<br/>                continue<br/>            # skip all images after 150 if we are building the train set<br/>            if is_train and int(image_id) &gt;= 150:<br/>                continue<br/>            # skip all images before 150 if we are building the test/val set<br/>            if not is_train and int(image_id) &lt; 150:<br/>                continue<br/>            <br/>            # setting image file<br/>            <strong class="ng iu">img_path = images_dir + filename</strong><br/>            <br/>            # setting annotations file<br/>           <strong class="ng iu"> ann_path = annotations_dir + image_id + '.xml'</strong><br/>            <br/>            # adding images and annotations to dataset<br/>            <strong class="ng iu">self.add_image('dataset', image_id=image_id, path=img_path, annotation=ann_path)</strong></span><span id="270e" class="kp kq it ng b gy no nl l nm nn"># extract bounding boxes from an annotation file<br/>    <strong class="ng iu">def extract_boxes(self, filename):</strong><br/>        <br/>        # load and parse the file<br/>        tree = ElementTree.parse(filename)<br/>        # get the root of the document<br/>        root = tree.getroot()<br/>       <strong class="ng iu"> # extract each bounding box</strong><br/>        boxes = list()<br/>        <strong class="ng iu">for box in root.findall('.//bndbox'):<br/>            xmin = int(box.find('xmin').text)<br/>            ymin = int(box.find('ymin').text)<br/>            xmax = int(box.find('xmax').text)<br/>            ymax = int(box.find('ymax').text)<br/>            coors = [xmin, ymin, xmax, ymax]<br/>            boxes.append(coors)</strong><br/>        <br/>        # extract image dimensions<br/>       <strong class="ng iu"> width = int(root.find('.//size/width').text)<br/>        height = int(root.find('.//size/height').text)<br/>        return boxes, width, height</strong></span><span id="e2cf" class="kp kq it ng b gy no nl l nm nn"># load the masks for an image<br/>    """Generate instance masks for an image.<br/>       Returns:<br/>        masks: A bool array of shape [height, width, instance count] with<br/>            one mask per instance.<br/>        class_ids: a 1D array of class IDs of the instance masks.<br/>     """<br/>    <strong class="ng iu">def load_mask(self, image_id):</strong><br/>        # get details of image<br/>        <strong class="ng iu">info = self.image_info[image_id]</strong><br/>        <br/>        # define anntation  file location<br/>        <strong class="ng iu">path = info['annotation']</strong><br/>        <br/>        # load XML<br/>        <strong class="ng iu">boxes, w, h = self.extract_boxes(path)</strong><br/>       <br/>        # create one array for all masks, each on a different channel<br/>        <strong class="ng iu">masks = zeros([h, w, len(boxes)], dtype='uint8')</strong><br/>        <br/>        # create masks<br/>        class_ids = list()<br/>        <strong class="ng iu">for i in range(len(boxes)):<br/>            box = boxes[i]<br/>            row_s, row_e = box[1], box[3]<br/>            col_s, col_e = box[0], box[2]<br/>            masks[row_s:row_e, col_s:col_e, i] = 1<br/>            class_ids.append(self.class_names.index('kangaroo'))<br/>        return masks, asarray(class_ids, dtype='int32')</strong></span><span id="efac" class="kp kq it ng b gy no nl l nm nn"># load an image reference<br/>     """Return the path of the image."""<br/>    <strong class="ng iu">def image_reference(self, image_id):</strong><br/>        <strong class="ng iu">info = self.image_info[image_id]</strong><br/>        print(info)<br/>        <strong class="ng iu">return info['path']</strong></span></pre><p id="7ccf" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu">第七步:准备列车和测试装置</strong></p><pre class="md me mf mg gt nf ng nh ni aw nj bi"><span id="0dff" class="kp kq it ng b gy nk nl l nm nn"># prepare train set<br/><strong class="ng iu">train_set = KangarooDataset()<br/>train_set.load_dataset(‘..\\Kangaroo\\kangaroo-master\\kangaroo-master’, is_train=True)<br/>train_set.prepare()</strong><br/>print(‘Train: %d’ % len(train_set.image_ids))</span><span id="5628" class="kp kq it ng b gy no nl l nm nn"># prepare test/val set<br/><strong class="ng iu">test_set = KangarooDataset()<br/>test_set.load_dataset(‘..\\Kangaroo\\kangaroo-master\\kangaroo-master’, is_train=False)<br/>test_set.prepare()</strong><br/>print(‘Test: %d’ % len(test_set.image_ids))</span></pre><p id="edb4" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu">步骤 8:使用我们创建的配置实例</strong>初始化<em class="ko">“训练”</em>的屏蔽 R-CNN 模型</p><pre class="md me mf mg gt nf ng nh ni aw nj bi"><span id="0e17" class="kp kq it ng b gy nk nl l nm nn">print("Loading Mask R-CNN model...")<br/><strong class="ng iu">model = modellib.MaskRCNN(mode="training", config=config, model_dir='./')</strong></span></pre><p id="deef" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu">步骤 9:从 COCO 数据集中加载掩模 R-CNN 的预训练权重，不包括最后几层</strong></p><p id="13a3" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">我们从 ResNet101 的训练中排除了最后几层。排除最后的层是为了匹配新数据集中的类的数量。</p><pre class="md me mf mg gt nf ng nh ni aw nj bi"><span id="8fda" class="kp kq it ng b gy nk nl l nm nn">#load the weights for COCO<br/>model.load_weights('.\\Mask_RCNN\\mask_rcnn_coco.h5', <br/>                   by_name=True, <br/>                   exclude=["mrcnn_class_logits", "mrcnn_bbox_fc",  "mrcnn_bbox", "mrcnn_mask"])</span></pre><h2 id="04a3" class="kp kq it bd kr ks kt dn ku kv kw dp kx kb ky kz la kf lb lc ld kj le lf lg lh bi translated">第十步:训练学习率较高的头部，加快学习速度</h2><p id="f064" class="pw-post-body-paragraph jq jr it js b jt li jv jw jx lj jz ka kb lk kd ke kf ll kh ki kj lm kl km kn im bi translated">我们可以通过提高学习速率来提高头层的学习速度</p><p id="4b4a" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">此外，我们可以将历元增加到 100–500 之间的任何值，并查看对象检测准确性的差异。我只用了 5 个纪元，因为我在 CPU 上训练它。</p><pre class="md me mf mg gt nf ng nh ni aw nj bi"><span id="7182" class="kp kq it ng b gy nk nl l nm nn">## train heads with higher lr to speedup the learning<br/>model.train(train_set, test_set, learning_rate=2*config.LEARNING_RATE, epochs=5, layers=’heads’)</span><span id="c86e" class="kp kq it ng b gy no nl l nm nn">history = model.keras_model.history.history</span></pre><figure class="md me mf mg gt mh gh gi paragraph-image"><div role="button" tabindex="0" class="mi mj di mk bf ml"><div class="gh gi nq"><img src="../Images/ddd5868db515755e03064bc37eecf32a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*BloOO_yVco2Ksh5j1xT2uA.png"/></div></div></figure><p id="21f9" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu">步骤 11:保存自定义数据集的训练权重</strong></p><pre class="md me mf mg gt nf ng nh ni aw nj bi"><span id="fedd" class="kp kq it ng b gy nk nl l nm nn">import time</span><span id="ad91" class="kp kq it ng b gy no nl l nm nn"><strong class="ng iu">model_path = '..\\Kangaroo\\kangaroo-master\\kangaroo-master\\mask_rcnn_'  + '.' + str(time.time()) + '.h5'</strong></span><span id="cdbc" class="kp kq it ng b gy no nl l nm nn"><strong class="ng iu">model.keras_model.save_weights(model_path)</strong></span></pre><p id="4760" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu">步骤 12:利用来自训练模型的遮罩和包围盒检测图像中的对象</strong></p><p id="e19a" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">在推理模式下创建模型。从我们训练模型的数据集中加载模型的权重。</p><p id="ec21" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">加载我们想要检测的图像的包围盒、类别和置信度百分比</p><pre class="md me mf mg gt nf ng nh ni aw nj bi"><span id="df8a" class="kp kq it ng b gy nk nl l nm nn">from keras.preprocessing.image import load_img<br/>from keras.preprocessing.image import img_to_array</span><span id="e300" class="kp kq it ng b gy no nl l nm nn">#Loading the model in the inference mode<br/><strong class="ng iu">model = modellib.MaskRCNN(mode="inference", config=config, model_dir='./')</strong></span><span id="d4c0" class="kp kq it ng b gy no nl l nm nn"># loading the trained weights o the custom dataset<br/><strong class="ng iu">model.load_weights(model_path, by_name=True)</strong></span><span id="10a6" class="kp kq it ng b gy no nl l nm nn">img = load_img("..\\Kangaroo\\kangaroo-master\\kangaroo-master\\images\\00042.jpg")<br/>img = img_to_array(img)</span><span id="b438" class="kp kq it ng b gy no nl l nm nn"># detecting objects in the image<br/><strong class="ng iu">result= model.detect([img])</strong></span></pre><p id="da5e" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">最后显示结果</p><pre class="md me mf mg gt nf ng nh ni aw nj bi"><span id="f1ee" class="kp kq it ng b gy nk nl l nm nn">image_id = 20<br/><strong class="ng iu">image, image_meta, gt_class_id, gt_bbox, gt_mask =    modellib.load_image_gt(test_set, config, image_id, use_mini_mask=False)</strong></span><span id="602b" class="kp kq it ng b gy no nl l nm nn"><strong class="ng iu">info = test_set.image_info[image_id]</strong><br/>print("image ID: {}.{} ({}) {}".format(info["source"], info["id"], image_id, <br/>                                       <strong class="ng iu">test_set.image_reference(image_id)))</strong></span><span id="8337" class="kp kq it ng b gy no nl l nm nn"># Run object detection<br/><strong class="ng iu">results = model.detect([image], verbose=1)</strong></span><span id="efc9" class="kp kq it ng b gy no nl l nm nn"># Display results<br/><br/><strong class="ng iu">r = results[0]</strong><br/><strong class="ng iu">visualize.display_instances(image, r['rois'], r['masks'], r['class_ids'], <br/>                            test_set.class_names, r['scores'], <br/>                            title="Predictions")</strong></span></pre><figure class="md me mf mg gt mh gh gi paragraph-image"><div role="button" tabindex="0" class="mi mj di mk bf ml"><div class="gh gi nr"><img src="../Images/d39f9cdb1ed38565510a5defe2d22849.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*10bcPAEqMuVwuYNzUz4noQ.png"/></div></div></figure><h2 id="afb4" class="kp kq it bd kr ks kt dn ku kv kw dp kx kb ky kz la kf lb lc ld kj le lf lg lh bi translated">参考资料:</h2><div class="ns nt gp gr nu nv"><a href="https://github.com/matterport/Mask_RCNN/" rel="noopener  ugc nofollow" target="_blank"><div class="nw ab fo"><div class="nx ab ny cl cj nz"><h2 class="bd iu gy z fp oa fr fs ob fu fw is bi translated">matterport/Mask_RCNN</h2><div class="oc l"><h3 class="bd b gy z fp oa fr fs ob fu fw dk translated">这是 Mask R-CNN 在 Python 3、Keras 和 TensorFlow 上的实现。该模型生成边界框和…</h3></div><div class="od l"><p class="bd b dl z fp oa fr fs ob fu fw dk translated">github.com</p></div></div><div class="oe l"><div class="of l og oh oi oe oj mm nv"/></div></div></a></div><p id="8b9c" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><a class="ae ln" href="https://github.com/arshren/Mask_RCNN/blob/master/Transfer%20Learning%20Mask%20RCNN-Custom%20dataset.ipynb" rel="noopener ugc nofollow" target="_blank">https://github . com/arshren/Mask _ RCNN/blob/master/Transfer % 20 learning % 20 Mask % 20 RCNN-Custom % 20 dataset . ipynb</a></p><div class="ns nt gp gr nu nv"><a href="https://engineering.matterport.com/splash-of-color-instance-segmentation-with-mask-r-cnn-and-tensorflow-7c761e238b46" rel="noopener  ugc nofollow" target="_blank"><div class="nw ab fo"><div class="nx ab ny cl cj nz"><h2 class="bd iu gy z fp oa fr fs ob fu fw is bi translated">色彩的飞溅:使用掩膜 R-CNN 和张量流的实例分割</h2><div class="oc l"><h3 class="bd b gy z fp oa fr fs ob fu fw dk translated">通过构建彩色飞溅滤镜来解释</h3></div><div class="od l"><p class="bd b dl z fp oa fr fs ob fu fw dk translated">engineering.matterport.com</p></div></div><div class="oe l"><div class="ok l og oh oi oe oj mm nv"/></div></div></a></div><p id="86cb" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><a class="ae ln" href="https://machinelearningmastery.com/how-to-perform-object-detection-with-yolov3-in-keras/" rel="noopener ugc nofollow" target="_blank">https://machine learning mastery . com/how-to-perform-object-detection-with-yolov 3-in-keras/</a></p></div></div>    
</body>
</html>