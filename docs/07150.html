<html>
<head>
<title/>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1/>
<blockquote>原文：<a href="https://towardsdatascience.com/this-dress-doesnt-exist-90002800f683?source=collection_archive---------15-----------------------#2019-10-09">https://towardsdatascience.com/this-dress-doesnt-exist-90002800f683?source=collection_archive---------15-----------------------#2019-10-09</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><figure class="is it gp gr iu iv gh gi paragraph-image"><div class="gh gi ir"><img src="../Images/2bab81dfa9feb899e5e647ae00642b68.png" data-original-src="https://miro.medium.com/v2/resize:fit:960/1*eQ9tsqvCX8bkk2Qw-Kcf4g.gif"/></div><figcaption class="iy iz gj gh gi ja jb bd b be z dk">Sample images from 4 days of training SR StyleGAN</figcaption></figure><blockquote class="jc jd je"><p id="9138" class="jf jg jh ji b jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd im bi translated">这篇文章最初发表在<strong class="ji ke"> Shoprunner 工程博客</strong> <a class="ae kf" href="https://shoprunnerblog.wordpress.com/2019/10/08/this-dress-doesnt-exist/" rel="noopener ugc nofollow" target="_blank">上，这里</a>请随意查看，以及我们团队正在做的一些其他工作。</p></blockquote><h1 id="fdb3" class="kg kh ki bd kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le bi translated">这件衣服不存在</h1><p id="1ef0" class="pw-post-body-paragraph jf jg ki ji b jj lf jl jm jn lg jp jq lh li jt ju lj lk jx jy ll lm kb kc kd im bi translated">我们的 ShopRunner 数据科学团队允许所有成员拥有一个季度黑客周。对于数据科学团队来说，保持创新非常重要，因此每个季度团队成员可以花一周时间从事他们选择的更具投机性的项目。对于我的 2019 年第三季度黑客周，我决定建立一系列发电机模型，试图创造假产品。发生器模型是通常被训练来基于真实世界的例子创建真实图像或文本的模型。这个项目可能看起来相当奇怪，但我的总体想法是，如果我们可以创建强大的生成器模型，可以捕捉我们产品目录的多样性，那么我们可以使用这些生成器来增加我们目录中的低频类，用于其他深度学习项目，如分类法分类或属性标记。</p><p id="9266" class="pw-post-body-paragraph jf jg ki ji b jj jk jl jm jn jo jp jq lh js jt ju lj jw jx jy ll ka kb kc kd im bi translated">我决定使用的两个网络是用于文本生成的<a class="ae kf" href="https://github.com/nshepperd/gpt-2" rel="noopener ugc nofollow" target="_blank"> OpenAI 的 GPT-2 </a> 117M 参数小型模型和用于图像生成的<a class="ae kf" href="https://github.com/NVlabs/stylegan" rel="noopener ugc nofollow" target="_blank"> Nvidia 的 StyleGAN </a>。然后，我根据内部 ShopRunner 数据集对这些数据进行了微调。对于这两个模型，我发现使用最初的 Tensorflow 实现是最好的方法，因为到其他框架的移植要么没有我需要的特性，要么没有很好地构建。</p><p id="f47d" class="pw-post-body-paragraph jf jg ki ji b jj jk jl jm jn jo jp jq lh js jt ju lj jw jx jy ll ka kb kc kd im bi translated">这两个模型都是在 Nvidia 2080 TI 显卡上训练的。</p><h1 id="5614" class="kg kh ki bd kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le bi translated">GPT-2</h1><p id="1962" class="pw-post-body-paragraph jf jg ki ji b jj lf jl jm jn lg jp jq lh li jt ju lj lk jx jy ll lm kb kc kd im bi translated">2019 年 2 月，OpenAI 宣布了其最新的语言模型<a class="ae kf" href="https://openai.com/blog/better-language-models/" rel="noopener ugc nofollow" target="_blank"> GPT-2 </a>。GPT-2 是在 40GB 的互联网文本上训练的，但由于担心恶意行为，OpenAI 将该模型的发布限制在小得多的版本上。构建高质量数据集的很大一部分是采用更高质量的 reddit。在其原始状态下，GPT-2 在生成逼真的声音文本方面表现出色，但这些文本往往属于 reddit 风格的对话或维基百科风格的描述。因此，为了最大限度地利用 GPT-2 作为假冒产品的发生器，我们需要将其调整到我们的特定用例，在这种情况下，时尚。</p><p id="e8bb" class="pw-post-body-paragraph jf jg ki ji b jj jk jl jm jn jo jp jq lh js jt ju lj jw jx jy ll ka kb kc kd im bi translated">由<a class="ae kf" href="https://github.com/nshepperd/gpt-2" rel="noopener ugc nofollow" target="_blank"> nshepperd </a>提供的用于微调的 repo 提供了一系列用于微调的脚本和指令。为了进行微调，我们只需要格式化一个文本数据集，供 GPT-2 使用。为此，我在一个. txt 文件中将 100K 个产品描述写到它们自己的行中，并在末尾附加了一个 GPT-2 特有的<code class="fe ln lo lp lq b">&lt;endoftext&gt;</code>标记，这样 GPT-2 将学会如何结束产品描述，并希望学会如何以更现实的方式组织它们。</p><p id="3080" class="pw-post-body-paragraph jf jg ki ji b jj jk jl jm jn jo jp jq lh js jt ju lj jw jx jy ll ka kb kc kd im bi translated">GPT-2 训练相当快，在几个小时的 15K 批次/步骤后产生了良好的结果。</p><h1 id="ab90" class="kg kh ki bd kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le bi translated">商店老板 GPT-2(老 GPT-2)</h1><p id="7532" class="pw-post-body-paragraph jf jg ki ji b jj lf jl jm jn lg jp jq lh li jt ju lj lk jx jy ll lm kb kc kd im bi translated">我们在 ShopRunner 数据上对 GPT-2 进行了 15K 步的微调，从而产生了我们所说的 SR GPT-2。经过微调，SR GPT-2 能够生成相当逼真的产品描述，包括换行符和格式。这些读起来也相当有趣。</p><pre class="lr ls lt lu gt lv lq lw lx aw ly bi"><span id="c423" class="lz kh ki lq b gy ma mb l mc md">======================================== SAMPLE 1 ========================================<br/>WATERDOG | PINK HALSTON COLLECTION. HALSTON'S HOODED SILK FIT IS SO AWESOME HONG KONG\'s black wool-blend hooded cowl jacket is handmade from lightweight wool sourced from two countries located in the Arctic Circle and Wye Hydroelectric Power Supply.</span><span id="07e0" class="lz kh ki lq b gy me mb l mc md">- HALSTON WOOL CLIMB JERRY WOOL FIT <br/>- Fabric: 90% wool, 10% wool crepe; 12% viscose, 8% polyester and 5% nylon <br/>- Washable, dry clean recommended <br/>- Imported</span><span id="9cfe" class="lz kh ki lq b gy me mb l mc md">SKU: HU18-17FBC</span><span id="dfd2" class="lz kh ki lq b gy me mb l mc md">FABRIC &amp; CARE</span><span id="7852" class="lz kh ki lq b gy me mb l mc md">Machine wash cold with similar colors</span><span id="bb2b" class="lz kh ki lq b gy me mb l mc md">Warm down with white</span><span id="b8a5" class="lz kh ki lq b gy me mb l mc md">Wash in cold water and hang dry  <br/>======================================== SAMPLE 2 ========================================<br/>Wool-Cotton Cropped T-Shirt Dress Dress with Boho Floral Print - Black This T-Shirt Dress features a Boho Floral printed front, a short sleeve hemline, and an asymmetrical ruffled hemline. A limited edition piece from our New York Fashion Show capsule.</span><span id="b4b9" class="lz kh ki lq b gy me mb l mc md">New York Fashion is celebrating the 20th anniversary of their popular T-Shirt Dress in 2011. The T-Shirt Dress is a loose-fitting bodice cut out cut in black silk crepe de chine with a fitted waistband. The dress has a V neckline, long sleeves, two front split pockets, and a draped waist.</span><span id="fb23" class="lz kh ki lq b gy me mb l mc md">100% Silk</span><span id="83d7" class="lz kh ki lq b gy me mb l mc md">Dry Clean Only</span><span id="d6ac" class="lz kh ki lq b gy me mb l mc md">Imported</span><span id="8b8b" class="lz kh ki lq b gy me mb l mc md">SI38S-F18</span><span id="e594" class="lz kh ki lq b gy me mb l mc md">Size &amp; Fit</span><span id="3638" class="lz kh ki lq b gy me mb l mc md">Model is wearing a size 6</span><span id="033d" class="lz kh ki lq b gy me mb l mc md">Model Measurements: Height: 5ft 9in; Bust-Chest: 33in; Waist: 23.6in; Hips: 34.5in</span><span id="dd05" class="lz kh ki lq b gy me mb l mc md">About SI38S-F18</span><span id="2926" class="lz kh ki lq b gy me mb l mc md">Sieviast designer and renowned expert James Simone launched his versatile collection of womens ready-to-wear and accessories in 2008. The label\'s garments have been named the year\'s top fashion showpieces, and the lines are sure to become a summer staple.</span></pre><p id="6935" class="pw-post-body-paragraph jf jg ki ji b jj jk jl jm jn jo jp jq lh js jt ju lj jw jx jy ll ka kb kc kd im bi translated">然而，使用 GPT-2，我们也可以生成基于上下文的示例。</p><p id="bb54" class="pw-post-body-paragraph jf jg ki ji b jj jk jl jm jn jo jp jq lh js jt ju lj jw jx jy ll ka kb kc kd im bi translated">以下是使用上下文“<strong class="ji ke">无袖红色不对称连衣裙</strong>生成的示例</p><pre class="lr ls lt lu gt lv lq lw lx aw ly bi"><span id="819e" class="lz kh ki lq b gy ma mb l mc md">Details</span><span id="7ba4" class="lz kh ki lq b gy me mb l mc md">This asymmetric fit-and-flare fit is cut in a slim fit. Cut for a flattering, relaxed fit.</span><span id="c0fd" class="lz kh ki lq b gy me mb l mc md">- Round neckline. <br/>- Sleeveless. <br/>- One center front, two center back. <br/>- 100% polyester. <br/>- Machine wash. <br/>- Imported. <br/>- Model is 5\'10""/178 cm and has a 32"" bust. She wears a US size 2.</span></pre><p id="7549" class="pw-post-body-paragraph jf jg ki ji b jj jk jl jm jn jo jp jq lh js jt ju lj jw jx jy ll ka kb kc kd im bi translated">这个例子似乎相当现实和合理。我感到高兴的一件事是，除了生成一个看起来真实的描述之外，在输入短语中使用的像“<strong class="ji ke">不对称</strong>”和“<strong class="ji ke">无袖</strong>”这样的词也出现在生成的描述中。</p><p id="38f4" class="pw-post-body-paragraph jf jg ki ji b jj jk jl jm jn jo jp jq lh js jt ju lj jw jx jy ll ka kb kc kd im bi translated">不那么严肃地说，有时在不那么时尚的背景下，我们仍然可以得到一些旧的 GPT-2 的训练和结构。</p><p id="ad7a" class="pw-post-body-paragraph jf jg ki ji b jj jk jl jm jn jo jp jq lh js jt ju lj jw jx jy ll ka kb kc kd im bi translated"><strong class="ji ke">肉裙</strong>灵感来自<a class="ae kf" href="https://en.wikipedia.org/wiki/Lady_Gaga%27s_meat_dress" rel="noopener ugc nofollow" target="_blank"> Lady Gaga </a></p><p id="7ef4" class="pw-post-body-paragraph jf jg ki ji b jj jk jl jm jn jo jp jq lh js jt ju lj jw jx jy ll ka kb kc kd im bi translated">在相同的上下文中，下面是两个生成的示例。当 SR GPT-2 生成一个样本时，它会考虑跟随给定上下文的概率最高的单词。然而，在这个过程中有一些随机性，所以输出结果可能会非常不同。第一个例子生成了一个看起来相当合理的产品描述。第二架 SR GPT-2 稍微落后于 GPT-2 更精确的训练类型</p><pre class="lr ls lt lu gt lv lq lw lx aw ly bi"><span id="8fd1" class="lz kh ki lq b gy ma mb l mc md"><br/>Meat dress: our Italian twist, crafted of a crepe fabric with a stretchy, crinkle finish. Features hand-woven details, an embroidered floral pattern throughout.</span><span id="6b94" class="lz kh ki lq b gy me mb l mc md">- Adjustable, pull-on, belt <br/>- Side slit <br/>- Adjustable, belt with cut from a relaxed fit <br/>- Fabric has been softened by hand washing <br/>- 95% rayon, 5% spandex blend; lining: 100% polyester crepe de chine <br/>- Washable <br/>- Imported</span><span id="abc7" class="lz kh ki lq b gy me mb l mc md"><br/>dress made of meat, bone, and vegetable gabardine. In honor of the American Heart Foundation.</span></pre><figure class="lr ls lt lu gt iv gh gi paragraph-image"><div class="gh gi mf"><img src="../Images/7240f927bcaf2a17ab653329bf76bb5a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1200/1*A8Ae2WNb1xvyChBOTJmZoA.gif"/></div></figure><h1 id="6a39" class="kg kh ki bd kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le bi translated">StyleGAN</h1><p id="e3b4" class="pw-post-body-paragraph jf jg ki ji b jj lf jl jm jn lg jp jq lh li jt ju lj lk jx jy ll lm kb kc kd im bi translated">生成对抗网络(GAN)是深度学习的一个有趣领域，其中训练过程涉及两个网络:生成器和鉴别器。生成器模型开始自己创建图像，它从随机噪声开始，而鉴别器通过查看训练示例和生成器输出来给出反馈，并预测它们是“真”还是“假”。随着时间的推移，这种反馈有助于生成器创建更真实的图像。</p><p id="1e56" class="pw-post-body-paragraph jf jg ki ji b jj jk jl jm jn jo jp jq lh js jt ju lj jw jx jy ll ka kb kc kd im bi translated">StyleGAN 是 Nvidia 在 2018 年底发布的一款机型。这是对英伟达之前名为 ProGAN 的型号的改进。ProGAN 经过训练可以生成 1024x1024 的高质量图像，并通过实施渐进的训练周期来实现这一点，在该周期中，它以低分辨率(4x4)开始训练图像，并通过添加额外的层来随着时间的推移提高分辨率。训练低分辨率图像有助于使训练更快并提高最终图像的质量，因为网络能够学习重要的较低水平特征。然而，ProGAN 控制生成图像的能力有限。</p><p id="45d3" class="pw-post-body-paragraph jf jg ki ji b jj jk jl jm jn jo jp jq lh js jt ju lj jw jx jy ll ka kb kc kd im bi translated">StyleGAN 通过允许用户操纵生成图像的潜在空间向量来提供控制输出“风格”的能力，从而对 ProGAN 进行了改进。StyleGAN 生成的每个图像都由 StyleGAN 潜在空间中的一个向量表示。因此，如果您修改该向量，您可以调整 StyleGAN 潜在空间中的图像特征，以创建具有所需特征的新图像。</p><p id="03ef" class="pw-post-body-paragraph jf jg ki ji b jj jk jl jm jn jo jp jq lh js jt ju lj jw jx jy ll ka kb kc kd im bi translated">这只是对 StyleGAN 的简单描述，更多信息请查看<a class="ae kf" href="https://arxiv.org/abs/1812.04948?source=post_page---------------------------" rel="noopener ugc nofollow" target="_blank">论文</a>或其他关于<a class="ae kf" rel="noopener" target="_blank" href="/explained-a-style-based-generator-architecture-for-gans-generating-and-tuning-realistic-6cb2be0f431?source=post_page---------------------------"> <em class="jh">或</em>在线</a>的文章。</p><div class="lr ls lt lu gt ab cb"><figure class="mg iv mh mi mj mk ml paragraph-image"><div role="button" tabindex="0" class="mm mn di mo bf mp"><img src="../Images/da1d2de7b4fd791bd0f076fb6f3c4326.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/1*60ohvQ6X10IxM6TAQ1VkBQ.gif"/></div></figure><figure class="mg iv mh mi mj mk ml paragraph-image"><div role="button" tabindex="0" class="mm mn di mo bf mp"><img src="../Images/c46a7e834a435bc9c782b181f5bfac22.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/1*Lbq_pvVwzvZcluqR5IZQNw.gif"/></div><figcaption class="iy iz gj gh gi ja jb bd b be z dk mq di mr ms">StyleGAN taking a slow walk through latent space for a vector. The general structure stays the same but the pattern/color/attributes change</figcaption></figure></div><h1 id="f1ea" class="kg kh ki bd kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le bi translated">ShopRunner StyleGAN(高级 StyleGAN)</h1><p id="7110" class="pw-post-body-paragraph jf jg ki ji b jj lf jl jm jn lg jp jq lh li jt ju lj lk jx jy ll lm kb kc kd im bi translated">我对 SR StyleGAN 进行了大约 4 天的培训，并在此过程中生成了大约 200 万张 512x512 的图像。作为权重初始化的起点，我实际上使用了另一个经过动画训练的 StyleGAN 。我使用这个动画 StyleGAN 作为起点，因为最初的 Nvidia StyleGAN 经过训练可以生成 1024x1024 的图像，这些图像很棒，但也更难处理，因为它们需要更多的计算能力。相比之下，动画 StyleGAN 被训练为生成 512x512 的图像，因此更易于管理。</p><p id="b62a" class="pw-post-body-paragraph jf jg ki ji b jj jk jl jm jn jo jp jq lh js jt ju lj jw jx jy ll ka kb kc kd im bi translated">SR StyleGAN 的数据集大约有 9000 张服装产品图片，我根据一些标准对这些图片进行了删减。第一步我用了几行代码，但是最后三步是手动的。</p><ol class=""><li id="5df0" class="mt mu ki ji b jj jk jn jo lh mv lj mw ll mx kd my mz na nb bi translated">尺寸:我扔掉了宽度或高度低于 300 的图片。如果您将低质量的图像留在数据集中，则最终生成的图像会呈现像素化的外观。</li><li id="ab0d" class="mt mu ki ji b jj nc jn nd lh ne lj nf ll ng kd my mz na nb bi translated">构图:为了简单起见，我尽量把模型/产品放在图像的中心</li><li id="e240" class="mt mu ki ji b jj nc jn nd lh ne lj nf ll ng kd my mz na nb bi translated">背景:移除了过于复杂的背景，因为这意味着模型需要付出更多的努力才能很好地生成背景</li><li id="9ed1" class="mt mu ki ji b jj nc jn nd lh ne lj nf ll ng kd my mz na nb bi translated">删除了非产品照片:某些图像要么是空白占位符图像，要么是放大的图案/面料照片。在我发现的数据集中留下这样的照片给了 StyleGAN 一个简单的作弊方法，生成“真实”的图像来欺骗鉴别者。然而，这并不是最理想的行为，所以我尽了最大努力去删除它们。</li></ol><figure class="lr ls lt lu gt iv gh gi paragraph-image"><div class="ab gu cl nh"><img src="../Images/89e220a17d0bd28a32ae31d5629b3db8.png" data-original-src="https://miro.medium.com/v2/1*168zmjNgieHB3bHqzd9u4g.gif"/></div><figcaption class="iy iz gj gh gi ja jb bd b be z dk">Walks through SR StyleGAN’s latent space</figcaption></figure><h1 id="227b" class="kg kh ki bd kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le bi translated">生成低频示例</h1><p id="3840" class="pw-post-body-paragraph jf jg ki ji b jj lf jl jm jn lg jp jq lh li jt ju lj lk jx jy ll lm kb kc kd im bi translated">现在，我们已经了解了 SR StyleGAN 的一些培训细节，我们可以开始讨论如何产生这些低频产品了。在下面的视频中，您会看到几秒钟的连体衣生成时间，尽管该数据集主要是连衣裙。所以在这个黑客周，我用连体裤作为低频课程的例子。</p><figure class="lr ls lt lu gt iv gh gi paragraph-image"><div class="gh gi ni"><img src="../Images/ba0be4b7c419abeb066859740521fd6f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1024/1*lPl-dPhhsuSfZ-ZwtObtdg.gif"/></div><figcaption class="iy iz gj gh gi ja jb bd b be z dk">This shows some jumpsuits</figcaption></figure><p id="90c0" class="pw-post-body-paragraph jf jg ki ji b jj jk jl jm jn jo jp jq lh js jt ju lj jw jx jy ll ka kb kc kd im bi translated">生成额外连体裤样本的一种快速方法是无条件地生成大量 SR StyleGAN 图像，并搜索这些图像以找到我们关心的低频类别的示例。</p><div class="lr ls lt lu gt ab cb"><figure class="mg iv nj mi mj mk ml paragraph-image"><div role="button" tabindex="0" class="mm mn di mo bf mp"><img src="../Images/52d2b38d3f35624070098c951cc1861e.png" data-original-src="https://miro.medium.com/v2/resize:fit:668/format:webp/1*a9G0MxWWaIBLWY9Nev32Uw.png"/></div></figure><figure class="mg iv nj mi mj mk ml paragraph-image"><div role="button" tabindex="0" class="mm mn di mo bf mp"><img src="../Images/16af90f7a806819b25313e33c77dae25.png" data-original-src="https://miro.medium.com/v2/resize:fit:668/format:webp/1*oAGj4ARumPsqycrnlo0RwA.png"/></div></figure><figure class="mg iv nj mi mj mk ml paragraph-image"><div role="button" tabindex="0" class="mm mn di mo bf mp"><img src="../Images/f00dff541dd41dc32807758dc9ccb669.png" data-original-src="https://miro.medium.com/v2/resize:fit:668/format:webp/1*zGx-rnNIT_HRRvbZ9ZJliA.png"/></div></figure></div><div class="ab cb"><figure class="mg iv nj mi mj mk ml paragraph-image"><div role="button" tabindex="0" class="mm mn di mo bf mp"><img src="../Images/3116e057dd977bda5163db713a10f477.png" data-original-src="https://miro.medium.com/v2/resize:fit:668/format:webp/1*0MNaaIkqzEMeNfOnZAlfVg.png"/></div></figure><figure class="mg iv nj mi mj mk ml paragraph-image"><div role="button" tabindex="0" class="mm mn di mo bf mp"><img src="../Images/bcfa1b8a16f9d15da06e2cc9db2f2608.png" data-original-src="https://miro.medium.com/v2/resize:fit:668/format:webp/1*31a5IlNu5OXH-AAn8GYaRQ.png"/></div></figure><figure class="mg iv nj mi mj mk ml paragraph-image"><div role="button" tabindex="0" class="mm mn di mo bf mp"><img src="../Images/57f5ace45235ff43468d8bf766adfb83.png" data-original-src="https://miro.medium.com/v2/resize:fit:668/format:webp/1*gYpSihvIkFKupPamg-LDKw.png"/></div></figure></div><p id="3226" class="pw-post-body-paragraph jf jg ki ji b jj jk jl jm jn jo jp jq lh js jt ju lj jw jx jy ll ka kb kc kd im bi translated">这里有一些例子，是我从几百张生成的 StyleGAN 图像中手动提取出来的。这样可以吗？但是，如果我们能找出连身衣在 SR StyleGAN 潜在空间中的确切位置，我们就能在我们认为合适的时候生产它们。</p><h1 id="9b61" class="kg kh ki bd kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le bi translated">SR StyleGAN 风格混合</h1><p id="bed7" class="pw-post-body-paragraph jf jg ki ji b jj lf jl jm jn lg jp jq lh li jt ju lj lk jx jy ll lm kb kc kd im bi translated">每个图像由 SR StyleGAN 的潜在空间中的特征向量表示。因此，如果我们将不同的向量组合在一起，我们就能够开始进行“风格混合”。在下面的两组视频中，我们看到右上角的图像被映射到左下角的图像上。得到的混合物在右下图像中，它应该由右上图像的特征所支配。在这两个视频中，您可以看到右上角图像的特征随着左下角图像的变化而变化。</p><figure class="lr ls lt lu gt iv gh gi paragraph-image"><div class="gh gi mf"><img src="../Images/4b7672ac4250c72e444278eacf7b63ba.png" data-original-src="https://miro.medium.com/v2/resize:fit:1200/1*taubcnEnvHnVxYjiQZExfg.gif"/></div><figcaption class="iy iz gj gh gi ja jb bd b be z dk">Top right getting mapped onto bottom left image. Result shown in the bottom right</figcaption></figure><figure class="lr ls lt lu gt iv gh gi paragraph-image"><div class="gh gi mf"><img src="../Images/4fd532618aaa9bad2932a4b55306411a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1200/1*BxHXtGqCL9bMMMLvYaDfcA.gif"/></div><figcaption class="iy iz gj gh gi ja jb bd b be z dk">Top right mapped onto bottom left for a synthesized image the upper right dress mostly just shifts in response to length</figcaption></figure><p id="a078" class="pw-post-body-paragraph jf jg ki ji b jj jk jl jm jn jo jp jq lh js jt ju lj jw jx jy ll ka kb kc kd im bi translated">这很酷，它给了我们一种方法，通过在 SR StyleGAN 的潜在空间中组合它们的特征向量来组合两幅图像。</p><h1 id="5b75" class="kg kh ki bd kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le bi translated">组合图像和文本生成器？</h1><p id="a32a" class="pw-post-body-paragraph jf jg ki ji b jj lf jl jm jn lg jp jq lh li jt ju lj lk jx jy ll lm kb kc kd im bi translated">因为我们的目标是生成看起来真实的假冒产品，所以这里有两个生成图像和上下文生成文本的例子。到目前为止，文本上下文是手动生成的，但未来的项目可能是构建一个标题模型，或者简单地使用由团队一直在工作的内部属性和分类模型生成的标签。这些生成的标签可以作为产品名称的替代品。例如，以下服装的潜在属性可以是“无袖红色不对称服装”,并且可以被馈送到 GPT-2 中以获得上下文生成的产品描述。</p><figure class="lr ls lt lu gt iv gh gi paragraph-image"><div class="gh gi ni"><img src="../Images/599af80851d5caea279bd15bbdd21ae8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1024/format:webp/1*Obp6NbK60RGLVvDZ-5e9NQ.png"/></div><figcaption class="iy iz gj gh gi ja jb bd b be z dk">3SR StyleGAN generated dress.</figcaption></figure><p id="6430" class="pw-post-body-paragraph jf jg ki ji b jj jk jl jm jn jo jp jq lh js jt ju lj jw jx jy ll ka kb kc kd im bi translated">SR GPT-2 的背景:<strong class="ji ke">无袖红色不对称连衣裙</strong></p><pre class="lr ls lt lu gt lv lq lw lx aw ly bi"><span id="ea7d" class="lz kh ki lq b gy ma mb l mc md">Details</span><span id="2ede" class="lz kh ki lq b gy me mb l mc md">This asymmetric fit-and-flare fit is cut in a slim fit. Cut for a flattering, relaxed fit.</span><span id="e30f" class="lz kh ki lq b gy me mb l mc md">- Round neckline. <br/>- Sleeveless. <br/>- One center front, two center back. <br/>- 100% polyester. <br/>- Machine wash. <br/>- Imported. <br/>- Model is 5\'10""/178 cm and has a 32"" bust. She wears a US size 2.</span></pre><p id="3e2b" class="pw-post-body-paragraph jf jg ki ji b jj jk jl jm jn jo jp jq lh js jt ju lj jw jx jy ll ka kb kc kd im bi translated">第二个例子使用 SR StyleGAN 生成的连身衣，其潜在标签是“黑色短袖连身衣”，这感觉像是合理的描述或无聊的标题。</p><figure class="lr ls lt lu gt iv gh gi paragraph-image"><div class="gh gi ni"><img src="../Images/dd46ad3d599832ea2d604f21b1c2d1fe.png" data-original-src="https://miro.medium.com/v2/resize:fit:1024/format:webp/1*31a5IlNu5OXH-AAn8GYaRQ.png"/></div><figcaption class="iy iz gj gh gi ja jb bd b be z dk">SR StyleGAN generated Jumpsuit</figcaption></figure><p id="e675" class="pw-post-body-paragraph jf jg ki ji b jj jk jl jm jn jo jp jq lh js jt ju lj jw jx jy ll ka kb kc kd im bi translated">SR GPT-2 上下文:<strong class="ji ke">黑色短袖连身衣</strong>。</p><pre class="lr ls lt lu gt lv lq lw lx aw ly bi"><span id="19da" class="lz kh ki lq b gy ma mb l mc md">A loose, fluid silhouette lends a comfortable wear to any look. The buttonless back features a keyhole on the chest.</span><span id="0d26" class="lz kh ki lq b gy me mb l mc md">Material and Care</span><span id="015b" class="lz kh ki lq b gy me mb l mc md">Material information: 100% Cotton, Lining: 100% Viscose, Lining: 100% Polyester</span></pre><p id="d941" class="pw-post-body-paragraph jf jg ki ji b jj jk jl jm jn jo jp jq lh js jt ju lj jw jx jy ll ka kb kc kd im bi translated">然后，作为一个有趣的后续步骤，我通过我们内部的分类法分类服务(使用图像和文本输入)输入了这两个示例，发现分类法服务成功地将这两个图像分类为“女装”和“连体裤”。</p><h1 id="b328" class="kg kh ki bd kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le bi translated">包装东西</h1><p id="3ef4" class="pw-post-body-paragraph jf jg ki ji b jj lf jl jm jn lg jp jq lh li jt ju lj lk jx jy ll lm kb kc kd im bi translated">在这个黑客周的过程中，我花了很多时间训练模型，并查看生成的图像和文本输出。我仍然认为，虽然很难利用这些生成器风格的模型，但是对于增加有趣的商业价值可能是非常有用的。我最初提到了像低频类的合成数据增强这样的事情，但来自该团队的其他想法可能是让用户生成项目并操纵项目，如果我们能够找出如何成功地定位和操纵 GAN 潜在空间中的不同功能。如果用户可以生成他们喜欢的项目，那么我们可以对我们的目录进行更标准的可视化搜索等等。</p><p id="2491" class="pw-post-body-paragraph jf jg ki ji b jj jk jl jm jn jo jp jq lh js jt ju lj jw jx jy ll ka kb kc kd im bi translated">至于车型上的注释。</p><p id="9b70" class="pw-post-body-paragraph jf jg ki ji b jj jk jl jm jn jo jp jq lh js jt ju lj jw jx jy ll ka kb kc kd im bi translated">GPT-2 看起来很好，学得很快，也可能很快过度拟合…通过给它适当的上下文，它可以生成合理的文本。我们用什么作为上下文才是真正的问题。思想将是一个基于真实图像或 GAN 图像的字幕模型。更简单的方法是以纯文本的形式输入所有可用的属性和分类信息，然后看看效果如何。</p><p id="45ff" class="pw-post-body-paragraph jf jg ki ji b jj jk jl jm jn jo jp jq lh js jt ju lj jw jx jy ll ka kb kc kd im bi translated">StyleGAN 受过良好的训练，为了获得更好的结果，我可能需要从头开始训练它，或者至少从它训练的早期开始。我有意让 StyleGAN 从生成相当大的图像的地方开始。同时使用那些动漫重量。</p><p id="07b8" class="pw-post-body-paragraph jf jg ki ji b jj jk jl jm jn jo jp jq lh js jt ju lj jw jx jy ll ka kb kc kd im bi translated">我尝试了一件事，但没有取得太大成功，那就是绘制 StyleGAN 潜在空间内外的图像。总体思想是使用预训练的网络，通过生成 StyleGAN 向量并比较图像与原始图像的接近程度，来学习找到 StyleGAN 潜在空间中图像的最接近近似。如果我们可以成功地将项目映射到 StyleGAN 的潜在空间，那么我们就可以组合这些向量，对我们正在修改的内容有更多的控制。例如，我们可以将一堆连体衣映射到 StyleGAN 的潜在空间，并将这些连体衣混合在一起，制成新的样本。另一个相关的步骤是找到潜在空间中的某些属性或模式，然后我们就可以潜在地</p><p id="0108" class="pw-post-body-paragraph jf jg ki ji b jj jk jl jm jn jo jp jq lh js jt ju lj jw jx jy ll ka kb kc kd im bi translated">对于完整的训练运行，Nvidia 列出了 42 天的单个 GPU 训练时间。你可能会在整整一周或两周的训练中获得好的结果，因为其他尝试从头开始训练的人报告说，过去几周实际上只是获得了干净的小细节。</p><p id="5c8d" class="pw-post-body-paragraph jf jg ki ji b jj jk jl jm jn jo jp jq lh js jt ju lj jw jx jy ll ka kb kc kd im bi translated">如果我最终继续这个黑客周的想法，未来的许多工作可能会围绕操纵 SR StyleGAN 输出和定位像衣服/袖子长度或颜色和图案这样的东西的位置，以便允许对操纵生成的图像的不同方面进行更细粒度的控制。</p><figure class="lr ls lt lu gt iv gh gi paragraph-image"><div class="gh gi mf"><img src="../Images/850c638e9a50a5aedf0c88fb78702f98.png" data-original-src="https://miro.medium.com/v2/resize:fit:1200/1*l5eD4qG075bumxMLJlqURQ.gif"/></div></figure></div></div>    
</body>
</html>