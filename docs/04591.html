<html>
<head>
<title>Extracting Data for Machine Learning</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">为机器学习提取数据</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/extracting-data-for-machine-learning-f90b97a97f4c?source=collection_archive---------13-----------------------#2019-07-14">https://towardsdatascience.com/extracting-data-for-machine-learning-f90b97a97f4c?source=collection_archive---------13-----------------------#2019-07-14</a></blockquote><div><div class="fc if ig ih ii ij"/><div class="ik il im in io"><div class=""/><div class=""><h2 id="bbbc" class="pw-subtitle-paragraph jo iq ir bd b jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf dk translated">为下一个机器学习项目获取数据的三种方法</h2></div><figure class="kh ki kj kk gu kl gi gj paragraph-image"><div role="button" tabindex="0" class="km kn di ko bf kp"><div class="gi gj kg"><img src="../Images/63f6e707dcc00c4a47c00f11e0101fac.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*PrfpQcBcm4iHr1Yj8n3AcQ.jpeg"/></div></div><figcaption class="ks kt gk gi gj ku kv bd b be z dk">Photo by <a class="ae kw" href="https://unsplash.com/@matthieuoger?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank">Matthieu Oger</a> on <a class="ae kw" href="https://unsplash.com/search/photos/crete?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><p id="9e9b" class="pw-post-body-paragraph kx ky ir kz b la lb js lc ld le jv lf lg lh li lj lk ll lm ln lo lp lq lr ls ik bi translated"><em class="lt">任何机器学习项目最重要的第一步就是获得优质数据。作为一名数据科学家，您经常需要使用各种不同的方法来提取数据集。您可能使用公开可用的数据、通过 API 可用的数据、在数据库中找到的数据，或者在许多情况下这些方法的组合。</em></p><p id="adf6" class="pw-post-body-paragraph kx ky ir kz b la lb js lc ld le jv lf lg lh li lj lk ll lm ln lo lp lq lr ls ik bi translated">在下面的帖子中，我将简要介绍 python 中提取数据的三种不同方法。在这篇文章中，我将讲述如何在 Jupyter 笔记本中提取数据。我以前在早先的<a class="ae kw" rel="noopener" target="_blank" href="/five-command-line-tools-for-data-science-29f04e5b9c16">文章</a>中报道过如何从命令行使用这些方法。</p><h2 id="a87d" class="lu lv ir bd lw lx ly dn lz ma mb dp mc lg md me mf lk mg mh mi lo mj mk ml mm bi translated">结构化查询语言</h2><p id="3c9d" class="pw-post-body-paragraph kx ky ir kz b la mn js lc ld mo jv lf lg mp li lj lk mq lm ln lo mr lq lr ls ik bi translated">如果您需要从关系数据库中获取数据，很可能需要使用 SQL。您可以使用名为 SQLAlchemy 的库将 Jupyter 笔记本连接到最常见的数据库类型。这个<a class="ae kw" href="https://docs.sqlalchemy.org/en/13/core/engines.html#postgresql" rel="noopener ugc nofollow" target="_blank">链接</a>提供了支持哪些数据库以及如何连接到每种类型的描述。</p><p id="aad3" class="pw-post-body-paragraph kx ky ir kz b la lb js lc ld le jv lf lg lh li lj lk ll lm ln lo lp lq lr ls ik bi translated">您可以直接使用 SQLAlchemy 来查看和查询表，也可以编写原始查询。要连接到您的数据库，您需要一个包含您的凭据的 URL。然后，您可以使用<code class="fe ms mt mu mv b">create_engine</code>命令来创建连接。</p><pre class="kh ki kj kk gu mw mv mx my aw mz bi"><span id="8890" class="lu lv ir mv b gz na nb l nc nd">from sqlalchemy import create_engine<br/>engine = create_engine('dialect+driver://username:password@host:port/database')</span></pre><p id="ba97" class="pw-post-body-paragraph kx ky ir kz b la lb js lc ld le jv lf lg lh li lj lk ll lm ln lo lp lq lr ls ik bi translated">现在，您可以编写数据库查询并返回结果。</p><pre class="kh ki kj kk gu mw mv mx my aw mz bi"><span id="4744" class="lu lv ir mv b gz na nb l nc nd">connection = engine.connect()<br/>result = connection.execute("select * from my_table")</span></pre><h2 id="6e0b" class="lu lv ir bd lw lx ly dn lz ma mb dp mc lg md me mf lk mg mh mi lo mj mk ml mm bi translated">擦</h2><p id="bb4d" class="pw-post-body-paragraph kx ky ir kz b la mn js lc ld mo jv lf lg mp li lj lk mq lm ln lo mr lq lr ls ik bi translated">Web 抓取用于从网站下载数据，并从这些页面中提取所需的信息。有很多 python 库可以用来做这件事，但是最简单的一个是<a class="ae kw" href="https://www.crummy.com/software/BeautifulSoup/bs4/doc/" rel="noopener ugc nofollow" target="_blank"> Beautiful Soup </a>。</p><p id="f053" class="pw-post-body-paragraph kx ky ir kz b la lb js lc ld le jv lf lg lh li lj lk ll lm ln lo lp lq lr ls ik bi translated">你可以通过 pip 安装这个软件包。</p><pre class="kh ki kj kk gu mw mv mx my aw mz bi"><span id="1055" class="lu lv ir mv b gz na nb l nc nd">pip install <!-- -->BeautifulSoup4</span></pre><p id="f1be" class="pw-post-body-paragraph kx ky ir kz b la lb js lc ld le jv lf lg lh li lj lk ll lm ln lo lp lq lr ls ik bi translated">让我们通过一个简单的例子来说明如何使用它。我们将使用 Beautiful Soup 和 urllib 库从猫途鹰网站获取酒店名称和价格。</p><p id="0133" class="pw-post-body-paragraph kx ky ir kz b la lb js lc ld le jv lf lg lh li lj lk ll lm ln lo lp lq lr ls ik bi translated">让我们导入将要使用的所有库。</p><pre class="kh ki kj kk gu mw mv mx my aw mz bi"><span id="0811" class="lu lv ir mv b gz na nb l nc nd">from bs4 import BeautifulSoup<br/>import urllib.request</span></pre><p id="db28" class="pw-post-body-paragraph kx ky ir kz b la lb js lc ld le jv lf lg lh li lj lk ll lm ln lo lp lq lr ls ik bi translated">接下来，我们要下载我们要抓取的页面内容。我将收集希腊克里特岛酒店的价格，所以我使用一个包含该目的地酒店列表的 URL。</p><figure class="kh ki kj kk gu kl gi gj paragraph-image"><div role="button" tabindex="0" class="km kn di ko bf kp"><div class="gi gj ne"><img src="../Images/4d94b0537accbc492f90889be3f2b9dc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*dXwJd_2tBDRZDio8S_LWxQ.png"/></div></div><figcaption class="ks kt gk gi gj ku kv bd b be z dk"><a class="ae kw" href="https://www.tripadvisor.co.uk/Hotels-g189413-Crete-Hotels.html" rel="noopener ugc nofollow" target="_blank">TripAdvisor</a></figcaption></figure><p id="e937" class="pw-post-body-paragraph kx ky ir kz b la lb js lc ld le jv lf lg lh li lj lk ll lm ln lo lp lq lr ls ik bi translated">下面的代码将 URL 定义为一个变量，使用 urllib 库打开页面，使用 Beautiful Soup 读取页面，并以易于阅读的格式返回结果。代码下面显示了部分输出。</p><pre class="kh ki kj kk gu mw mv mx my aw mz bi"><span id="05f8" class="lu lv ir mv b gz na nb l nc nd">URL = '<a class="ae kw" href="https://www.tripadvisor.co.uk/Hotels-g189413-Crete-Hotels.html'" rel="noopener ugc nofollow" target="_blank">https://www.tripadvisor.co.uk/Hotels-g189413-Crete-Hotels.html'</a><br/>page = urllib.request.urlopen(URL)<br/>soup = BeautifulSoup(page, 'html.parser')<br/>print(soup.prettify())</span></pre><figure class="kh ki kj kk gu kl gi gj paragraph-image"><div role="button" tabindex="0" class="km kn di ko bf kp"><div class="gi gj nf"><img src="../Images/b9aa19cab33f2930c588532d748b8bfb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*saFcHOqipFujl5zcL-noFg.png"/></div></div></figure><p id="f8e6" class="pw-post-body-paragraph kx ky ir kz b la lb js lc ld le jv lf lg lh li lj lk ll lm ln lo lp lq lr ls ik bi translated">接下来，让我们获取页面上的酒店名称列表。我们将使用<code class="fe ms mt mu mv b">find_all</code>函数，它允许您提取文档中您感兴趣的部分。您可以使用<code class="fe ms mt mu mv b">find_all</code>以多种方式过滤文档。通过传入字符串、正则表达式或列表。您还可以过滤标签的一个属性，这就是我们将在这里使用的方法。如果你不熟悉 HTML 标签和属性，这篇文章<a class="ae kw" href="https://en.wikipedia.org/wiki/HTML_attribute" rel="noopener ugc nofollow" target="_blank">给出了一个很好的概述。</a></p><p id="2479" class="pw-post-body-paragraph kx ky ir kz b la lb js lc ld le jv lf lg lh li lj lk ll lm ln lo lp lq lr ls ik bi translated">要了解如何最好地访问数据点，您需要检查 web 页面上该元素的代码。要查找酒店名称的代码，我们右键单击列表中的名称，如下图所示。</p><figure class="kh ki kj kk gu kl gi gj paragraph-image"><div role="button" tabindex="0" class="km kn di ko bf kp"><div class="gi gj ng"><img src="../Images/f4644a8fd66dd5583718b20786cbc90d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*gSpoz5a1yVLN5f6V9DzjJA.png"/></div></div></figure><p id="8ffc" class="pw-post-body-paragraph kx ky ir kz b la lb js lc ld le jv lf lg lh li lj lk ll lm ln lo lp lq lr ls ik bi translated">当您点击<code class="fe ms mt mu mv b">inspect</code>时，代码将出现，包含酒店名称的部分将高亮显示，如下所示。</p><figure class="kh ki kj kk gu kl gi gj paragraph-image"><div role="button" tabindex="0" class="km kn di ko bf kp"><div class="gi gj nh"><img src="../Images/d8cf8ee557cb68ad57777f7d654923d1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*uAiyXJwnm-NxT2Q04UNktw.png"/></div></div></figure><p id="b7dd" class="pw-post-body-paragraph kx ky ir kz b la lb js lc ld le jv lf lg lh li lj lk ll lm ln lo lp lq lr ls ik bi translated">我们可以看到酒店名称是名为<code class="fe ms mt mu mv b">listing_title</code>的类中唯一的一段文本。下面的代码将这个属性的类和名称传递给<code class="fe ms mt mu mv b">find_all</code>函数，以及<code class="fe ms mt mu mv b">div</code>标签。</p><pre class="kh ki kj kk gu mw mv mx my aw mz bi"><span id="ab90" class="lu lv ir mv b gz na nb l nc nd">content_name = soup.find_all('div', attrs={'class': 'listing_title'})<br/>print(content_name)</span></pre><p id="07e0" class="pw-post-body-paragraph kx ky ir kz b la lb js lc ld le jv lf lg lh li lj lk ll lm ln lo lp lq lr ls ik bi translated">这会以列表形式返回包含酒店名称的每一段代码。</p><figure class="kh ki kj kk gu kl gi gj paragraph-image"><div role="button" tabindex="0" class="km kn di ko bf kp"><div class="gi gj ni"><img src="../Images/0e597dfc2bedfd0085aab27c028f12c6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*D7eDFEphHeIINFDgB7pXVQ.png"/></div></div></figure><p id="ab26" class="pw-post-body-paragraph kx ky ir kz b la lb js lc ld le jv lf lg lh li lj lk ll lm ln lo lp lq lr ls ik bi translated">为了从代码中提取酒店名称，我们可以使用 Beautiful Soup 的<code class="fe ms mt mu mv b">getText</code>函数。</p><pre class="kh ki kj kk gu mw mv mx my aw mz bi"><span id="0897" class="lu lv ir mv b gz na nb l nc nd">content_name_list = []<br/>for div in content_name:<br/>    content_name_list.append(div.getText().split('\n')[0])<br/>print(content_name_list)</span></pre><p id="b570" class="pw-post-body-paragraph kx ky ir kz b la lb js lc ld le jv lf lg lh li lj lk ll lm ln lo lp lq lr ls ik bi translated">这会以列表形式返回酒店名称。</p><figure class="kh ki kj kk gu kl gi gj paragraph-image"><div role="button" tabindex="0" class="km kn di ko bf kp"><div class="gi gj nj"><img src="../Images/c0373097c9bd90dd95ab4487aebbdd41.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*O65ZOxypPpptJJg9WzetXw.png"/></div></div></figure><p id="6703" class="pw-post-body-paragraph kx ky ir kz b la lb js lc ld le jv lf lg lh li lj lk ll lm ln lo lp lq lr ls ik bi translated">我们可以用类似的方法得到价格。检查价格代码，我们可以看到它有以下结构。</p><figure class="kh ki kj kk gu kl gi gj paragraph-image"><div role="button" tabindex="0" class="km kn di ko bf kp"><div class="gi gj nk"><img src="../Images/e34c80dc4d88329d1fa72d6ddd175893.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*HtvEe7ANso0oZiruIY_Fww.png"/></div></div></figure><p id="417c" class="pw-post-body-paragraph kx ky ir kz b la lb js lc ld le jv lf lg lh li lj lk ll lm ln lo lp lq lr ls ik bi translated">所以我们可以用非常相似的代码提取这一段。</p><pre class="kh ki kj kk gu mw mv mx my aw mz bi"><span id="599a" class="lu lv ir mv b gz na nb l nc nd">content_price = soup.find_all('div', attrs={'class': 'price-wrap'})<br/>print(content_price)</span></pre><p id="3249" class="pw-post-body-paragraph kx ky ir kz b la lb js lc ld le jv lf lg lh li lj lk ll lm ln lo lp lq lr ls ik bi translated">价格有点复杂，如果我们运行下面的代码，我们会看到它。</p><pre class="kh ki kj kk gu mw mv mx my aw mz bi"><span id="0646" class="lu lv ir mv b gz na nb l nc nd">content_price_list = []<br/>for div in content_price:<br/>    content_price_list.append(div.getText().split('\n')[0])<br/>print(content_price_list)</span></pre><p id="0d82" class="pw-post-body-paragraph kx ky ir kz b la lb js lc ld le jv lf lg lh li lj lk ll lm ln lo lp lq lr ls ik bi translated">输出如下所示。当酒店列表显示降价时，除了一些文本之外，还会返回原始价格和销售价格。为了使这个有用，我们只想返回酒店的实际价格，如果我们今天预订的话。</p><figure class="kh ki kj kk gu kl gi gj paragraph-image"><div role="button" tabindex="0" class="km kn di ko bf kp"><div class="gi gj nl"><img src="../Images/d839343499dca1c0d94047d0b623a784.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*4Xbap7jHjRU6afTaduuGEQ.png"/></div></div></figure><p id="e081" class="pw-post-body-paragraph kx ky ir kz b la lb js lc ld le jv lf lg lh li lj lk ll lm ln lo lp lq lr ls ik bi translated">我们可以使用一些简单的逻辑来获得文本中显示的最后价格。</p><pre class="kh ki kj kk gu mw mv mx my aw mz bi"><span id="49e6" class="lu lv ir mv b gz na nb l nc nd">content_price_list = []<br/>for a in content_price:<br/>        a_split = a.getText().split('\n')[0]<br/>        if len(a_split) &gt; 5:<br/>            content_price_list.append(a_split[-4:])<br/>        else:<br/>            content_price_list.append(a_split)  <br/>        <br/>print(content_price_list)</span></pre><p id="488a" class="pw-post-body-paragraph kx ky ir kz b la lb js lc ld le jv lf lg lh li lj lk ll lm ln lo lp lq lr ls ik bi translated">这给出了以下输出。</p><figure class="kh ki kj kk gu kl gi gj paragraph-image"><div role="button" tabindex="0" class="km kn di ko bf kp"><div class="gi gj nm"><img src="../Images/48e911cae24c52cb5dcb076258dbdb55.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*9dDVRRSU7LYREXLcwNgCMw.png"/></div></div></figure><h2 id="7662" class="lu lv ir bd lw lx ly dn lz ma mb dp mc lg md me mf lk mg mh mi lo mj mk ml mm bi translated">应用程序接口</h2><p id="fddd" class="pw-post-body-paragraph kx ky ir kz b la mn js lc ld mo jv lf lg mp li lj lk mq lm ln lo mr lq lr ls ik bi translated">API 代表应用程序编程接口，就数据提取而言，它是一个基于 web 的系统，为数据提供一个端点，您可以通过一些编程连接到该端点。通常，数据将以 JSON 或 XML 格式返回。</p><p id="272f" class="pw-post-body-paragraph kx ky ir kz b la lb js lc ld le jv lf lg lh li lj lk ll lm ln lo lp lq lr ls ik bi translated">在机器学习中，你可能需要用这种方法获取数据。我将给出一个简单的例子，说明如何从一个公开可用的名为<a class="ae kw" href="https://darksky.net/dev" rel="noopener ugc nofollow" target="_blank"> Dark Sky </a>的 API 中获取天气数据。要访问这个 API，你需要注册，每天免费提供 1000 个电话，这应该足够尝试了。</p><p id="76d1" class="pw-post-body-paragraph kx ky ir kz b la lb js lc ld le jv lf lg lh li lj lk ll lm ln lo lp lq lr ls ik bi translated">为了访问来自黑暗天空的数据，我将使用<code class="fe ms mt mu mv b">requests</code>库。首先，我需要获得正确的 URL 来请求数据。“黑暗天空”提供预报和历史天气数据。对于这个例子，我将使用历史数据，我可以从<a class="ae kw" href="https://darksky.net/dev/docs#time-machine-request" rel="noopener ugc nofollow" target="_blank">文档</a>中获得正确的 URL。</p><p id="f609" class="pw-post-body-paragraph kx ky ir kz b la lb js lc ld le jv lf lg lh li lj lk ll lm ln lo lp lq lr ls ik bi translated">该 URL 具有以下结构。</p><pre class="kh ki kj kk gu mw mv mx my aw mz bi"><span id="7ad4" class="lu lv ir mv b gz na nb l nc nd">https://api.darksky.net/forecast/[key]/[latitude],[longitude],[time]</span></pre><p id="9371" class="pw-post-body-paragraph kx ky ir kz b la lb js lc ld le jv lf lg lh li lj lk ll lm ln lo lp lq lr ls ik bi translated">我们将使用<code class="fe ms mt mu mv b">requests</code>库来获取特定纬度和经度以及日期和时间的结果。让我们想象一下，在获得克里特岛酒店的每日价格后，我们想要找出价格是否以某种方式与天气相关。例如，让我们为列表中的一家酒店选择坐标。</p><figure class="kh ki kj kk gu kl gi gj paragraph-image"><div role="button" tabindex="0" class="km kn di ko bf kp"><div class="gi gj nn"><img src="../Images/da49b03a304818b423570187d0baed79.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*21zAzOJwoQweJKaCfYSQQg.png"/></div></div><figcaption class="ks kt gk gi gj ku kv bd b be z dk"><a class="ae kw" href="https://www.google.com/search?q=mitsis+laguna+resort+%26+spa+latitude+and+longitude&amp;oq=mitsis+laguna+resort+%26+spa+latit&amp;aqs=chrome.2.69i57j33l3.7096j0j7&amp;sourceid=chrome&amp;ie=UTF-8" rel="noopener ugc nofollow" target="_blank">Google.com</a></figcaption></figure><p id="2292" class="pw-post-body-paragraph kx ky ir kz b la lb js lc ld le jv lf lg lh li lj lk ll lm ln lo lp lq lr ls ik bi translated">首先，我们用我们需要的正确坐标和日期时间构造 URL。使用<code class="fe ms mt mu mv b">requests</code>库，我们可以访问 JSON 格式的数据。</p><pre class="kh ki kj kk gu mw mv mx my aw mz bi"><span id="534c" class="lu lv ir mv b gz na nb l nc nd">import requests</span><span id="b116" class="lu lv ir mv b gz no nb l nc nd">request_url = '<a class="ae kw" href="https://api.darksky.net/forecast/fd82a22de40c6dca7d1ae392ad83eeb3/35.3378,-25.3741,2019-07-01T12:00:00'" rel="noopener ugc nofollow" target="_blank">https://api.darksky.net/forecast/fd82a22de40c6dca7d1ae392ad83eeb3/35.3378,-25.3741,2019-07-01T12:00:00'</a><br/>result = requests.get(request_url).json()<br/>result</span></pre><p id="4593" class="pw-post-body-paragraph kx ky ir kz b la lb js lc ld le jv lf lg lh li lj lk ll lm ln lo lp lq lr ls ik bi translated">我们可以将结果标准化到一个数据框架中，以便于阅读和分析。</p><pre class="kh ki kj kk gu mw mv mx my aw mz bi"><span id="3e6e" class="lu lv ir mv b gz na nb l nc nd">import pandas as pd</span><span id="6f82" class="lu lv ir mv b gz no nb l nc nd">df = pd.DataFrame.from_dict(json_normalize(result), orient='columns')<br/>df.head()</span></pre><figure class="kh ki kj kk gu kl gi gj paragraph-image"><div role="button" tabindex="0" class="km kn di ko bf kp"><div class="gi gj np"><img src="../Images/b10c8fe7e147d785f9e8d30267a0b13a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_jqk-jj9B0aDZhsCMuB1bQ.png"/></div></div><figcaption class="ks kt gk gi gj ku kv bd b be z dk">Part of the resulting data frame</figcaption></figure><p id="0f30" class="pw-post-body-paragraph kx ky ir kz b la lb js lc ld le jv lf lg lh li lj lk ll lm ln lo lp lq lr ls ik bi translated">使用这些方法，您可以做更多的事情来自动提取这些数据。对于 web 抓取和 API 方法，可以编写函数来自动执行该过程，以便轻松提取大量日期和/或位置的数据。在这篇文章中，我想简单地给出一个概述，用足够的代码来探索这些方法。在以后的文章中，我将会写一些更深入的文章，介绍如何构建完整的数据集并使用这些方法进行分析。</p><p id="ca88" class="pw-post-body-paragraph kx ky ir kz b la lb js lc ld le jv lf lg lh li lj lk ll lm ln lo lp lq lr ls ik bi translated">感谢阅读！</p></div></div>    
</body>
</html>