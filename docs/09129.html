<html>
<head>
<title>The Unknown Benefits of using a Soft-F1 Loss in Classification Systems</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">在分类系统中使用软 F1 损失的未知好处</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/the-unknown-benefits-of-using-a-soft-f1-loss-in-classification-systems-753902c0105d?source=collection_archive---------2-----------------------#2019-12-04">https://towardsdatascience.com/the-unknown-benefits-of-using-a-soft-f1-loss-in-classification-systems-753902c0105d?source=collection_archive---------2-----------------------#2019-12-04</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="5b24" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">如何不保持一个决策门槛，仍然直接针对你关心的东西进行优化！</h2></div><p id="9e59" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在生产中部署机器学习系统并确保其日常效率可能是一项非常艰巨的挑战。在过去的五年里，我看到越来越多的技术变得越来越复杂(算法、编码库、云服务等等)。这是用有用的人工智能应用重塑我们世界的好消息。</p><p id="39dc" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">但是，和许多其他领域一样，化繁为简是成功的关键。莱昂纳多·达·芬奇将简单描述为“终极的复杂”。<br/>在数据科学中，它不仅仅是一种理论，它可以采取流程的形式。</p><figure class="lf lg lh li gt lj gh gi paragraph-image"><div role="button" tabindex="0" class="lk ll di lm bf ln"><div class="gh gi le"><img src="../Images/0c30b4163fde2d89474855f41aeb4b05.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*hYwgNA39daffpTCb"/></div></div><figcaption class="lq lr gj gh gi ls lt bd b be z dk">Photo by <a class="ae lu" href="https://unsplash.com/@h3p?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Hilthart Pedersen</a> on <a class="ae lu" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><p id="b8e9" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">不管怎样，我为什么要说这个话题？<br/>在一篇非常鼓舞人心的题为“<a class="ae lu" href="http://research.google.com/pubs/pub43146.html" rel="noopener ugc nofollow" target="_blank"> <strong class="kk iu"> <em class="lv">机器学习:技术债务的高息信用卡</em></strong></a>的论文中，谷歌的一个人工智能研究团队分享了一些非常务实的建议，关于如何在生产中管理机器学习系统的复杂性。在他们描述的所有方面中，有一个问题是如何使 ML 系统适应外部世界的变化。</p><p id="90bf" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">下面是他们对动态系统中固定阈值的看法:</p><blockquote class="lw"><p id="9b2d" class="lx ly it bd lz ma mb mc md me mf ld dk translated">通常需要为给定模型选择一个决策阈值来执行一些动作:预测真或假，将电子邮件标记为垃圾邮件或非垃圾邮件，显示或不显示给定的广告。机器学习中的一种经典方法是从一组可能的阈值中选择一个阈值，以便在某些指标(如精确度和召回率)上获得良好的折衷。然而，这种阈值通常是手动设置的。因此，如果模型根据新数据更新，旧的手动设置的阈值可能无效。跨多个模型手动更新多个阈值既耗时又脆弱。对于这类问题，一个有用的缓解策略是通过对 heldout 验证数据的简单评估来学习阈值。”</p></blockquote><p id="8c1f" class="pw-post-body-paragraph ki kj it kk b kl mg ju kn ko mh jx kq kr mi kt ku kv mj kx ky kz mk lb lc ld im bi translated">最近，我一直在研究一个 ML 系统，以帮助自动化汽车诊断。基于汽车数据，系统应该预测在发生事故时需要更换哪些零件。这是一个多标签分类问题，可以分解成数百个二元分类子问题(每个部分一个)。</p><p id="017e" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">考虑到所有的生产约束，学习和不断更新每个子问题的决策阈值对我来说非常乏味。</p><p id="dcb5" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在这篇博文中，我想分享一些额外的缓解策略，以忽略决策阈值的调整，并仍然获得分类系统的优化性能。据我所知，没有像这样的普遍做法，没有文章，没有公认的研究。这只是我实验的结果。因此，我建议谨慎使用以下见解，并随时分享您的观点和我们可以一起讨论的任何问题。</p><p id="eb6a" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">如果你想重现结果，你可以一步通过这个<a class="ae lu" href="https://github.com/ashrefm/multi-label-soft-f1/blob/master/Multi-Label%20Image%20Classification%20in%20TensorFlow%202.0.ipynb" rel="noopener ugc nofollow" target="_blank"> <strong class="kk iu"> Jupyter 笔记本</strong> </a>。完整的代码在麻省理工学院的许可下共享在<a class="ae lu" href="https://github.com/ashrefm/multi-label-soft-f1" rel="noopener ugc nofollow" target="_blank"> <strong class="kk iu"> Github </strong> </a>上。</p></div><div class="ab cl ml mm hx mn" role="separator"><span class="mo bw bk mp mq mr"/><span class="mo bw bk mp mq mr"/><span class="mo bw bk mp mq"/></div><div class="im in io ip iq"><h1 id="2a62" class="ms mt it bd mu mv mw mx my mz na nb nc jz nd ka ne kc nf kd ng kf nh kg ni nj bi translated">研究案例</h1><p id="f0ae" class="pw-post-body-paragraph ki kj it kk b kl nk ju kn ko nl jx kq kr nm kt ku kv nn kx ky kz no lb lc ld im bi translated">为了说明这个想法，让我们考虑一个从海报图像预测电影流派的机器学习系统。对于每个海报，可以分配一个或多个标签(动作、惊悚、戏剧、恐怖、奇幻等。).卷积神经网络当然是学习从电影海报到可能的标签列表的映射的非常好的方法。关于实现细节，可以在 tensor flow 2.0<strong class="kk iu"><em class="lv"/></strong>中阅读我关于“<a class="ae lu" href="https://medium.com/@ashrefm/multi-label-image-classification-in-tensorflow-2-0-7d4cf8a4bc72" rel="noopener"> <strong class="kk iu"> <em class="lv">多标签图像分类”的文章，但也可以独立继续阅读本文。</em></strong></a></p><figure class="lf lg lh li gt lj gh gi paragraph-image"><div role="button" tabindex="0" class="lk ll di lm bf ln"><div class="gh gi np"><img src="../Images/632207e9cf245c4fde3ba364f0ee682a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*GilOovlWZrQ_ylreFujy4Q.png"/></div></div></figure></div><div class="ab cl ml mm hx mn" role="separator"><span class="mo bw bk mp mq mr"/><span class="mo bw bk mp mq mr"/><span class="mo bw bk mp mq"/></div><div class="im in io ip iq"><h1 id="b44d" class="ms mt it bd mu mv mw mx my mz na nb nc jz nd ka ne kc nf kd ng kf nh kg ni nj bi translated">了解 F1 分数</h1><p id="3799" class="pw-post-body-paragraph ki kj it kk b kl nk ju kn ko nl jx kq kr nm kt ku kv nn kx ky kz no lb lc ld im bi translated">给定一张电影海报，我们需要预测系统为每个标签生成 0 或 1 的预测。例如，如果一部电影有一些“动作”内容，系统应该给“动作”标签分配 1，否则应该给相同的标签分配 0。对于每部电影，我们以一个 N 维的二进制向量结束，这个向量代表所有的猜测，N 是所有可能的标签(电影类型)的数量。二元预测向量可能看起来像这样:00011000001..000.</p><p id="f9bd" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">当对一个标签进行推理时，有四种类型的预测:</p><ul class=""><li id="c5ac" class="nq nr it kk b kl km ko kp kr ns kv nt kz nu ld nv nw nx ny bi translated">两种类型的正确预测(真阳性和真阴性)。</li><li id="ef2b" class="nq nr it kk b kl nz ko oa kr ob kv oc kz od ld nv nw nx ny bi translated">任何观测值预测为阳性而实际为阴性的错误类型 I(假阳性，也称为假警报)</li><li id="f685" class="nq nr it kk b kl nz ko oa kr ob kv oc kz od ld nv nw nx ny bi translated">任何观测值预测为阴性而实际为阳性的错误类型 II(假阴性)</li></ul><p id="953f" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">这通常使用<a class="ae lu" href="https://en.wikipedia.org/wiki/Confusion_matrix" rel="noopener ugc nofollow" target="_blank">混淆矩阵</a>来可视化。</p><figure class="lf lg lh li gt lj gh gi paragraph-image"><div role="button" tabindex="0" class="lk ll di lm bf ln"><div class="gh gi oe"><img src="../Images/70370d6d6b4b0d6f57ca62ba69511426.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*KoRNBieYAXiKLK609OV9lA.png"/></div></div></figure><p id="d180" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">基于此，通常分析两个指标:</p><ul class=""><li id="42a3" class="nq nr it kk b kl km ko kp kr ns kv nt kz nu ld nv nw nx ny bi translated">Precision: TP/(TP+FP) <br/>在所有预测为阳性的示例中，实际为阳性的百分比是多少→我们希望降低错误警报率</li><li id="daa7" class="nq nr it kk b kl nz ko oa kr ob kv oc kz od ld nv nw nx ny bi translated">回忆:TP/(TP+FN) <br/>在所有实际为正的例子中，预测为正的占百分之几→我们要提高模型的灵敏度</li></ul><p id="9cee" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">但是因为这两个指标通常是相互对立的，所以我们可以依赖它们的调和平均值，即<a class="ae lu" href="https://en.wikipedia.org/wiki/F1_score" rel="noopener ugc nofollow" target="_blank">F1-得分</a>。</p><figure class="lf lg lh li gt lj gh gi paragraph-image"><div role="button" tabindex="0" class="lk ll di lm bf ln"><div class="gh gi of"><img src="../Images/14040406014964cf4ab21006d2c5642b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*iXh-laAdl3gcddkHpJxnLw.png"/></div></div></figure><blockquote class="lw"><p id="589a" class="lx ly it bd lz ma og oh oi oj ok ld dk translated">在开发您的 ML 系统时，有一个单一的评估指标可以加快进度。</p></blockquote></div><div class="ab cl ml mm hx mn" role="separator"><span class="mo bw bk mp mq mr"/><span class="mo bw bk mp mq mr"/><span class="mo bw bk mp mq"/></div><div class="im in io ip iq"><h1 id="c26c" class="ms mt it bd mu mv mw mx my mz na nb nc jz nd ka ne kc nf kd ng kf nh kg ni nj bi translated">直接针对 F1 分数进行优化</h1><p id="d034" class="pw-post-body-paragraph ki kj it kk b kl nk ju kn ko nl jx kq kr nm kt ku kv nn kx ky kz no lb lc ld im bi translated">在训练和评估机器学习算法(如神经网络)之前，我们需要定义两个主要函数:</p><ul class=""><li id="b8ac" class="nq nr it kk b kl km ko kp kr ns kv nt kz nu ld nv nw nx ny bi translated"><strong class="kk iu">一个损失函数:</strong>它是现代机器学习的面包和黄油。我们需要它来测量训练批次的模型误差(成本)。它必须是可微分的，以便<a class="ae lu" href="https://en.wikipedia.org/wiki/Backpropagation" rel="noopener ugc nofollow" target="_blank">反向传播</a>神经网络中的误差并更新权重。</li><li id="00dd" class="nq nr it kk b kl nz ko oa kr ob kv oc kz od ld nv nw nx ny bi translated"><strong class="kk iu">一个评价函数:</strong>它应该代表我们真正关心的最终评价指标。与损失函数不同，它必须更直观地理解模型在现实世界中的表现。</li></ul><p id="4efb" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">如果我们想使用 F1 分数作为评估指标，有两种可能的策略来最大化它:</p><h2 id="b8fb" class="ol mt it bd mu om on dn my oo op dp nc kr oq or ne kv os ot ng kz ou ov ni ow bi translated"><strong class="ak">策略 1: </strong> <strong class="ak">通过设定阈值使 F1 分数最大化</strong></h2><p id="dcc2" class="pw-post-body-paragraph ki kj it kk b kl nk ju kn ko nl jx kq kr nm kt ku kv nn kx ky kz no lb lc ld im bi translated">当模型生成概率值时，我们需要为每个标签设置一个阈值，以获得二元预测。例如，如果动作的概率高于阈值 0.5，我们可以预测 1(电影是关于动作的)，否则我们预测 0(没有动作)。使每个标签的 F1 分数最大化的最佳阈值在 0 到 0.5 之间(有数学证明，但不在本文中讨论)。我们通常在等待验证集上搜索阈值。</p><figure class="lf lg lh li gt lj gh gi paragraph-image"><div role="button" tabindex="0" class="lk ll di lm bf ln"><div class="gh gi ox"><img src="../Images/77cd7f011d07b5d49938e18cea4dc17c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*nLgT-WauN-xVX3sgOSBNzQ.png"/></div></div></figure><h2 id="8d33" class="ol mt it bd mu om on dn my oo op dp nc kr oq or ne kv os ot ng kz ou ov ni ow bi translated"><strong class="ak">策略 2: </strong> <strong class="ak">将 F1 得分嵌入损失函数</strong></h2><p id="b81b" class="pw-post-body-paragraph ki kj it kk b kl nk ju kn ko nl jx kq kr nm kt ku kv nn kx ky kz no lb lc ld im bi translated">如果您想直接针对 F1 指标进行优化，这将是最简单的方法。损失函数不仅提供了模型误差的度量，它还是定义如何最佳拟合数据以实现最佳目标的学习过程的核心。出于某种原因，将 F1 分数嵌入损失函数并不是一种常见的做法。</p><figure class="lf lg lh li gt lj gh gi paragraph-image"><div role="button" tabindex="0" class="lk ll di lm bf ln"><div class="gh gi oy"><img src="../Images/1581957d691f04aebaecad096d77d344.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*lY4uGRFtfZzoQmxQW_Qeeg.png"/></div></div><figcaption class="lq lr gj gh gi ls lt bd b be z dk"><a class="ae lu" href="https://algorithmia.com/blog/introduction-to-loss-functions" rel="noopener ugc nofollow" target="_blank">Introduction to loss functions (Algorithmia)</a></figcaption></figure><h2 id="04d2" class="ol mt it bd mu om on dn my oo op dp nc kr oq or ne kv os ot ng kz ou ov ni ow bi translated"><strong class="ak">为什么在损失函数中出现 F1 得分是不寻常的？</strong></h2><p id="e511" class="pw-post-body-paragraph ki kj it kk b kl nk ju kn ko nl jx kq kr nm kt ku kv nn kx ky kz no lb lc ld im bi translated">F1 分数的问题是它不可微分，因此我们不能将其用作损失函数来计算梯度和在训练模型时更新权重。请记住，F1 分数需要二进制预测(0/1)来衡量。</p><p id="ea44" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">通常我们使用<code class="fe oz pa pb pc b">binary cross-entropy loss</code>,它代表某一特定类别观察值的负对数似然性<code class="fe oz pa pb pc b">-log(p)</code>,模型预测该类别的概率<code class="fe oz pa pb pc b">p</code>。一般来说，这种损失效果很好，并广泛用于使用策略 1 训练分类器，但它并不直接与我们想要最大化的 F1 分数一致。</p><h2 id="3fd9" class="ol mt it bd mu om on dn my oo op dp nc kr oq or ne kv os ot ng kz ou ov ni ow bi translated"><strong class="ak">解决方案？</strong></h2><blockquote class="lw"><p id="9bd9" class="lx ly it bd lz ma mb mc md me mf ld dk translated">我们可以修改 F1 的分数，使其具有可区分性。我们可以通过使用概率而不应用任何阈值，将真阳性、假阳性、假阴性的数量计算为似然值的连续和，而不是将它们计算为离散的整数值。</p></blockquote><p id="a24f" class="pw-post-body-paragraph ki kj it kk b kl mg ju kn ko mh jx kq kr mi kt ku kv mj kx ky kz mk lb lc ld im bi translated">让我们来看两个有助于理解这种转变的例子:</p><pre class="lf lg lh li gt pd pc pe pf aw pg bi"><span id="de39" class="ol mt it pc b gy ph pi l pj pk"><strong class="pc iu">Example 1:</strong> If the target is 1 for a movie being Action and the model prediction for Action is 0.8, it will count as:</span><span id="d2c5" class="ol mt it pc b gy pl pi l pj pk">0.8 x 1 = 0.8 TP (because the target is 1 and the model predicted 1 with 0.8 chance)</span><span id="49a6" class="ol mt it pc b gy pl pi l pj pk">0.2 x 1 = 0.2 FN (because the target is 1 and the model predicted 0 with 0.2 chance)</span><span id="b6b9" class="ol mt it pc b gy pl pi l pj pk">0.8 x 0 = 0 FP (because the target is 1 not 0, condition negative is not valid)</span><span id="3507" class="ol mt it pc b gy pl pi l pj pk">0.2 x 0 = 0 TN (because the target is 1 not 0, condition negative is not valid)<br/></span><span id="6aaf" class="ol mt it pc b gy pl pi l pj pk"><strong class="pc iu">Example 2:</strong> If the target is 0 for a movie being Action and the model prediction for Action is 0.8, it will count as:</span><span id="212f" class="ol mt it pc b gy pl pi l pj pk">0.8 x 0 = 0 TP (because the target is 0 not 1, condition positive is not valid)</span><span id="7e93" class="ol mt it pc b gy pl pi l pj pk">0.2 x 0 = 0 FN (because the target is 0 not 1, condition positive is not valid)</span><span id="4a95" class="ol mt it pc b gy pl pi l pj pk">0.8 x 1 = 0.8 FP (because the target is 0 and the model predicted 1 with 0.8 chance)</span><span id="de62" class="ol mt it pc b gy pl pi l pj pk">0.2 x 1 = 0.2 TN (because the target is 0 and the model predicted 0 with 0.2 chance)</span></pre><p id="7232" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我们将这个版本称为<code class="fe oz pa pb pc b"><strong class="kk iu">soft-F1-score</strong></code>。下面，你可以看到在 TensorFlow 中的一批预测上实现它的代码。</p><figure class="lf lg lh li gt lj"><div class="bz fp l di"><div class="pm pn l"/></div></figure><h2 id="3408" class="ol mt it bd mu om on dn my oo op dp nc kr oq or ne kv os ot ng kz ou ov ni ow bi translated"><strong class="ak">这里有一些事情需要考虑:</strong></h2><ul class=""><li id="8d3a" class="nq nr it kk b kl nk ko nl kr po kv pp kz pq ld nv nw nx ny bi translated">每个标签的成本实际上是该标签的<code class="fe oz pa pb pc b">1 — soft-F1</code>。要想最大化软-F1，就要最小化<code class="fe oz pa pb pc b">1 — soft-F1</code>。</li><li id="3b7a" class="nq nr it kk b kl nz ko oa kr ob kv oc kz od ld nv nw nx ny bi translated">你可以把<code class="fe oz pa pb pc b">soft-F1</code>定义中的<code class="fe oz pa pb pc b">Precision</code>和<code class="fe oz pa pb pc b">Recall</code>替换掉，得到一个更直接的基于 TP、FP、FN 项的公式。之所以要这样做，是因为当 TP = 0 时，F1 的调和平均值表达式是未定义的，但转换后的表达式是定义的。<br/> F1 = 2 * TP / (2 * TP + FN + FP)</li><li id="995c" class="nq nr it kk b kl nz ko oa kr ob kv oc kz od ld nv nw nx ny bi translated">一批观察中的总成本将是所有标签上的平均成本。我们将称之为<code class="fe oz pa pb pc b">macro soft-F1 loss</code>。</li><li id="1a91" class="nq nr it kk b kl nz ko oa kr ob kv oc kz od ld nv nw nx ny bi translated">你必须确保批量足够大，以便在培训时看到一个代表<code class="fe oz pa pb pc b">macro soft-F1 loss</code>。</li></ul><h2 id="e619" class="ol mt it bd mu om on dn my oo op dp nc kr oq or ne kv os ot ng kz ou ov ni ow bi translated">学习曲线(优化和评估指标)</h2><p id="4e90" class="pw-post-body-paragraph ki kj it kk b kl nk ju kn ko nl jx kq kr nm kt ku kv nn kx ky kz no lb lc ld im bi translated">让我们假设，为了简单起见，我们希望对所有标签只使用一个阈值来将任何概率值转换成二元预测。换句话说，我们现在将考虑默认阈值 0.5，并通过优化我们之前定义的宏软 F1 损失(策略 2)来尝试最大化宏 F1 得分@阈值 0.5，而不是通过为每个标签分别设置阈值来最大化性能。</p><p id="d264" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">与使用似然项的宏软 F1 不同，我们将在宏 F1 分数的实现中使用阈值 0.5。</p><figure class="lf lg lh li gt lj"><div class="bz fp l di"><div class="pm pn l"/></div></figure><p id="3d87" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在下面的学习曲线上，我们观察了训练过程中损失度量(宏软 F1)和评估度量(宏 F1-分数@阈值 0.5)的变化。</p><figure class="lf lg lh li gt lj gh gi paragraph-image"><div role="button" tabindex="0" class="lk ll di lm bf ln"><div class="gh gi pr"><img src="../Images/78133d07ad734f76e1b8c57ef97dfd56.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*2ZgMVD2QptGwVNf5zx402Q.png"/></div></div><figcaption class="lq lr gj gh gi ls lt bd b be z dk">Learning curves (macro soft-F1 loss and macro F1 @thesh 0.5) with a batch size of 256</figcaption></figure><blockquote class="ps pt pu"><p id="9b0b" class="ki kj lv kk b kl km ju kn ko kp jx kq pv ks kt ku pw kw kx ky px la lb lc ld im bi translated">您可能会注意到，在学习曲线上，宏观软 F1 损失降低到接近 0.69 的水平与宏观 F1 分数增加到接近 0.33 的水平相关。这两个值几乎互补为 1。请记住，我们定义的宏软 f 1 损失实际上是我们需要最小化的 1-软 F1 的宏。这是第一个指标，表明宏观软 F1 损失直接优化了我们的评估指标，即宏观 F1 得分@阈值 0.5。</p></blockquote></div><div class="ab cl ml mm hx mn" role="separator"><span class="mo bw bk mp mq mr"/><span class="mo bw bk mp mq mr"/><span class="mo bw bk mp mq"/></div><div class="im in io ip iq"><h1 id="0bd4" class="ms mt it bd mu mv mw mx my mz na nb nc jz nd ka ne kc nf kd ng kf nh kg ni nj bi translated">了解宏观软-F1 损失的作用</h1><p id="b724" class="pw-post-body-paragraph ki kj it kk b kl nk ju kn ko nl jx kq kr nm kt ku kv nn kx ky kz no lb lc ld im bi translated">为了解释这个损失函数的含义，我训练了两个神经网络模型，它们具有相同的体系结构，但是有两种不同的优化。第一个模型使用宏观软 F1 损失直接优化宏观 F1 得分，而第二个模型更经典，并针对二进制交叉熵进行了优化。在这两种情况下，当预测电影海报的类型时，训练的模型将为每个标签生成独立的概率分数。为了创建最终的决策系统，我们需要为每个标签选择 0 到 1 之间的决策阈值，以便将每个概率转换成二进制信息。通常，系统的性能取决于这些决策阈值的选择。因此，让我们检查一下，对于每种类型的优化，系统如何根据我们为某些标签设置阈值的级别来处理验证集。</p><figure class="lf lg lh li gt lj gh gi paragraph-image"><div role="button" tabindex="0" class="lk ll di lm bf ln"><div class="gh gi py"><img src="../Images/600d949c9cd95cfb16c1ba39adac23c3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*qyaTz0GAObjuR2853khZWQ.png"/></div></div></figure><h2 id="444d" class="ol mt it bd mu om on dn my oo op dp nc kr oq or ne kv os ot ng kz ou ov ni ow bi translated">有趣的事情正在这里发生！</h2><p id="4194" class="pw-post-body-paragraph ki kj it kk b kl nk ju kn ko nl jx kq kr nm kt ku kv nn kx ky kz no lb lc ld im bi translated">当使用宏软 F1 损失训练模型时，我们得到几乎与阈值无关的 F1 得分(绿色曲线)。当使用二元交叉熵损失时，我们没有这种效应。这实际上是一个有趣的效果，因为它提供了将所有标签的阈值固定在 0.5 的可能性，并且仍然获得接近于当使用 BCE 损失时通过搜索最佳阈值所获得的性能。当构建生产 ML 系统时，这是一个非常好的特性。更新阈值并确保它们在新数据到来时保持最佳状态是一项巨大的工作。使用宏软 F1 损失可以帮助解决这个问题，但实际上这种行为来自哪里？</p><p id="caf4" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">当使用两种不同的优化时，分析来自神经网络的概率值的分布将是有趣的。</p><figure class="lf lg lh li gt lj gh gi paragraph-image"><div role="button" tabindex="0" class="lk ll di lm bf ln"><div class="gh gi pz"><img src="../Images/66f536a46da0130d497efb87f95b17e4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*yF319EgJVzag9pd2ZL4D4Q.png"/></div></div></figure><h2 id="9c3a" class="ol mt it bd mu om on dn my oo op dp nc kr oq or ne kv os ot ng kz ou ov ni ow bi translated"><strong class="ak">好了，现在可能看起来更清楚了！</strong></h2><p id="7c4d" class="pw-post-body-paragraph ki kj it kk b kl nk ju kn ko nl jx kq kr nm kt ku kv nn kx ky kz no lb lc ld im bi translated">当使用二进制交叉熵损失进行训练时，输出的概率分布具有一些高斯属性(注意蓝色直方图的钟形)。实际上，这种优化是从数据的原始分布中学习的。我们可以看到，对于覆盖 50%数据集的标签“Drama ”,概率分布集中在 0.5。顺便说一下，为“戏剧”构建的分类器似乎非常弱，因为这两个类别似乎没有在概率值上分开。我们还可以注意到，标签出现的频率越低，分布就越左移。例如,“喜剧”的概率得分似乎更低，这个标签只覆盖了数据集的 32%。该模型从这种罕见性中学习来预测较低的概率值。另一方面，当使用宏软 F1 损失时，我们正在创建一个不反映相同数量级的条件概率值的系统。相反，它学会不那么犹豫，并生成非常接近 1 或 0 的预测。我们在中间范围有较少的概率值。因此，在该范围内改变阈值时，性能不会发生太大变化。</p><blockquote class="lw"><p id="4caa" class="lx ly it bd lz ma mb mc md me mf ld dk translated">使用宏软 F1 损失进行优化可以取代一些穷举技术，例如:</p><p id="e516" class="lx ly it bd lz ma mb mc md me mf ld dk translated">1-在验证集上搜索使性能最大化的最佳决策阈值</p><p id="86a7" class="lx ly it bd lz ma mb mc md me mf ld dk translated">2-通过在训练前对少数类过采样或对多数类欠采样来校准概率值(在多标签分类的情况下非常复杂，因为标签同时出现)</p></blockquote></div><div class="ab cl ml mm hx mn" role="separator"><span class="mo bw bk mp mq mr"/><span class="mo bw bk mp mq mr"/><span class="mo bw bk mp mq"/></div><div class="im in io ip iq"><h1 id="43c2" class="ms mt it bd mu mv mw mx my mz na nb nc jz nd ka ne kc nf kd ng kf nh kg ni nj bi translated">缺点和对策</h1><p id="5a91" class="pw-post-body-paragraph ki kj it kk b kl nk ju kn ko nl jx kq kr nm kt ku kv nn kx ky kz no lb lc ld im bi translated">您可能已经注意到，在标签“Drama”的情况下，使用宏 soft-F1 loss 进行优化会产生一个预测“Drama”始终为正的模型(请注意概率直方图如何在最右侧接近 1，以及召回曲线如何在 100%的最大水平保持不变)。</p><p id="21fb" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">每当训练好的分类器不提供信息时，这种副作用就可能发生。这是由于加州大学的研究人员在这篇<a class="ae lu" href="https://arxiv.org/pdf/1402.1892.pdf" rel="noopener ugc nofollow" target="_blank"> <strong class="kk iu">论文</strong> </a> <strong class="kk iu"> </strong>的第 10 页上证明了 F1 度量的一些性质。</p><blockquote class="lw"><p id="34c0" class="lx ly it bd lz ma mb mc md me mf ld dk translated">只要测试集中实际阳性的频率不为零，并且分类器不提供信息，就可以通过预测所有样本为阳性来最大化预期 F1</p></blockquote><p id="ffd9" class="pw-post-body-paragraph ki kj it kk b kl mg ju kn ko mh jx kq kr mi kt ku kv mj kx ky kz mk lb lc ld im bi translated">本文关注的是通过阈值化来最大化 F1 得分(策略 1)，但同样的逻辑也适用于本文所述的基于软 F1 优化的最大化(策略 2)。</p><p id="23c0" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我们基本上希望最大化 F1 的期望值，作为正面预测的函数，因此我们可能需要定义以下术语:</p><pre class="lf lg lh li gt pd pc pe pf aw pg bi"><span id="780f" class="ol mt it pc b gy ph pi l pj pk">F1 = 2*tp / (2*tp + fp + fn) # translated expression of F1<br/>a = tp + fn # number of actual positives<br/>b = a / (tp + fp + fn + tn) # label frequency<br/>c = tp + fp # number of predicted positives</span></pre><p id="c933" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">当分类器不提供信息时，真阳性的数量预计是所有阳性预测的一部分，等于基本比率(标签频率)</p><pre class="lf lg lh li gt pd pc pe pf aw pg bi"><span id="aeaa" class="ol mt it pc b gy ph pi l pj pk">E(tp) = c * b # expected tp in case of uninformative classifier<br/>a + c = 2 * tp + fp + fn # denominator in previous F1 expression</span></pre><p id="df80" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">然后，可以使用以下公式计算预期 F1:</p><figure class="lf lg lh li gt lj gh gi paragraph-image"><div role="button" tabindex="0" class="lk ll di lm bf ln"><div class="gh gi qa"><img src="../Images/894698c619f74727980c01d1281e1c01.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*k6_mrZLHkRD35CBRTzI0aA.png"/></div></div></figure><p id="caa1" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">并且期望 F1 相对于 c 的偏导数可以分解如下:</p><figure class="lf lg lh li gt lj gh gi paragraph-image"><div role="button" tabindex="0" class="lk ll di lm bf ln"><div class="gh gi qb"><img src="../Images/1d58ad3bd231051e0436d49609a4d350.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*RPSLFiWykJs3OB_dZBAvFQ.png"/></div></div></figure><p id="f13a" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">这个导数总是正的，这证明了每当分类器没有信息时，系统将通过预测所有样本为正来学习获得最优 F1。</p><h2 id="85fb" class="ol mt it bd mu om on dn my oo op dp nc kr oq or ne kv os ot ng kz ou ov ni ow bi translated"><strong class="ak">如果你觉得这种效果不好，我建议采取以下对策。</strong></h2><p id="f8cb" class="pw-post-body-paragraph ki kj it kk b kl nk ju kn ko nl jx kq kr nm kt ku kv nn kx ky kz no lb lc ld im bi translated">当考虑 F1-socre 时，我们默认推理正类(结果等于 1)。但是，你也可以考虑在相同的条件下，如果你对负类进行推理(结果等于 0)，你会得到的 F1 分数。唯一的区别是 TP 和 TN 量的交替。</p><pre class="lf lg lh li gt pd pc pe pf aw pg bi"><span id="e40e" class="ol mt it pc b gy ph pi l pj pk">F1_class1 = 2*tp / (2*tp + fp + fn)<br/>F1_class0 = 2*tn / (2*tn + fn + fp)</span></pre><p id="f389" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">然后我们可以取这两个量的平均值来定义一个新的度量。</p><pre class="lf lg lh li gt pd pc pe pf aw pg bi"><span id="a889" class="ol mt it pc b gy ph pi l pj pk">New_F1 = (F1_class1 + F1_class0) / 2</span></pre><p id="e700" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">当然，让它变得可区分:</p><figure class="lf lg lh li gt lj"><div class="bz fp l di"><div class="pm pn l"/></div></figure><p id="4025" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">通过这样做，你可以期望系统通过不仅生成正面预测而且生成负面预测来抵消其先前的行为，以便优化这个新的损失。</p><figure class="lf lg lh li gt lj gh gi paragraph-image"><div role="button" tabindex="0" class="lk ll di lm bf ln"><div class="gh gi qc"><img src="../Images/248e6f4fa0b319ba829e6dc1a079a660.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*0RWAVzhDK8sep3iTmEfLJQ.png"/></div></div></figure><p id="53b6" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">这将保护系统在无信息分类器的情况下避免预测总是肯定的不可接受的行为。</p></div><div class="ab cl ml mm hx mn" role="separator"><span class="mo bw bk mp mq mr"/><span class="mo bw bk mp mq mr"/><span class="mo bw bk mp mq"/></div><div class="im in io ip iq"><h1 id="f0a7" class="ms mt it bd mu mv mw mx my mz na nb nc jz nd ka ne kc nf kd ng kf nh kg ni nj bi translated">摘要</h1><p id="0450" class="pw-post-body-paragraph ki kj it kk b kl nk ju kn ko nl jx kq kr nm kt ku kv nn kx ky kz no lb lc ld im bi translated">生产 ML 系统的性能来自于部署可靠且易于维护的模型。决策阈值是复杂性的另一个来源。在这篇博文中，我分享了一个优化技巧，通过将 F1 得分的定义纳入损失函数(软 F1 损失)来避免不断调整决策阈值。这非常有帮助，尤其是在多标签分类的情况下，您希望使用相同的默认阈值 0.5 将预测转换为二进制结果，同时保持最佳的分类性能。</p><p id="5472" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">从海报预测电影类型是标签数量可能变高的一个例子。但这实际上是一个艰难的分类挑战。在一些标签上，我们只能得到非常弱的分类器。在无信息分类器的情况下，所描述的技术可能导致预测总是肯定的不良效果。如果你想避免这种影响，你可以使用双软 F1 损失。</p><p id="cc17" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在其他一些数据集上，比如汽车诊断，我可以看到非常有趣的结果。因此，如果您正在处理类似的任务，您可以在自己的数据集上尝试，并让我知道您得到的结果！</p></div></div>    
</body>
</html>