<html>
<head>
<title>A Beginner’s Tutorial on Building an AI Image Classifier using PyTorch</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用 PyTorch 构建人工智能图像分类器的初学者教程</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/a-beginners-tutorial-on-building-an-ai-image-classifier-using-pytorch-6f85cb69cba7?source=collection_archive---------4-----------------------#2019-02-03">https://towardsdatascience.com/a-beginners-tutorial-on-building-an-ai-image-classifier-using-pytorch-6f85cb69cba7?source=collection_archive---------4-----------------------#2019-02-03</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><p id="0dad" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">这是一个逐步建立图像分类器的指南。人工智能模型将能够学习标记图像。我用 Python 和 Pytorch。</p><figure class="km kn ko kp gt kq gh gi paragraph-image"><div class="gh gi kl"><img src="../Images/6b832ad3713ec0816b27faac507f5e4a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1200/format:webp/1*jcrUUS9Z-x5fEHJ5ZSoLMw.jpeg"/></div></figure><h1 id="5fb0" class="kt ku iq bd kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq bi translated">步骤 1:导入库</h1><p id="904f" class="pw-post-body-paragraph jn jo iq jp b jq lr js jt ju ls jw jx jy lt ka kb kc lu ke kf kg lv ki kj kk ij bi translated">当我们写一个程序时，手动编码我们执行的每个小动作是一个巨大的麻烦。有时候，我们想要使用别人已经写好的代码包。这些打包的例程被称为库，可以通过导入它们并在代码中引用该库来添加到我们的程序中。</p><p id="a788" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我们通常在程序开始时导入所有的库。</p><p id="dfcc" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">当我们引用这个库时，不用输入它的长名字，我们可以用“as”把它缩写成我们选择的名字。</p><pre class="km kn ko kp gt lw lx ly lz aw ma bi"><span id="83c1" class="mb ku iq lx b gy mc md l me mf"># Import Libraries<br/>import torch<br/>import torchvision.transforms as transforms<br/>import torchvision.datasets as datasets<br/>import torchvision.models as models<br/>import torch.nn as nn<br/>import torch.optim as optim<br/>import numpy as np<br/>from PIL import Image<br/>import numpy as np<br/>import matplotlib.pyplot as plt</span></pre><h1 id="e481" class="kt ku iq bd kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq bi translated">步骤 2:定义转换</h1><p id="c43d" class="pw-post-body-paragraph jn jo iq jp b jq lr js jt ju ls jw jx jy lt ka kb kc lu ke kf kg lv ki kj kk ij bi translated">接下来，我们要导入我们的 AI 模型将从中学习的图片数据。</p><p id="1aa5" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">但是在此之前，我们需要指定我们想要在这些图片上执行的更改——因为导入它们的同一个命令也会转换数据。</p><p id="40b6" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">这些转换是使用 torchvision.transforms 库完成的。理解转换的最佳方式是阅读文档<a class="ae mg" href="https://pytorch.org/docs/stable/torchvision/transforms.html" rel="noopener ugc nofollow" target="_blank">这里的</a>。但是我将简要介绍每个命令的作用。</p><ul class=""><li id="57a5" class="mh mi iq jp b jq jr ju jv jy mj kc mk kg ml kk mm mn mo mp bi translated"><strong class="jp ir">变换花样。Compose </strong>让我们将多个转换组合在一起，这样我们就可以使用多个转换。</li><li id="01dc" class="mh mi iq jp b jq mq ju mr jy ms kc mt kg mu kk mm mn mo mp bi translated"><strong class="jp ir">变换花样。Resize((255)) </strong>调整图像大小，使最短边的长度为 255 像素。另一侧被缩放以保持图像的纵横比。</li><li id="e8df" class="mh mi iq jp b jq mq ju mr jy ms kc mt kg mu kk mm mn mo mp bi translated"><strong class="jp ir">变换。中心裁剪(224) </strong>裁剪图像的中心，使其成为 224×224 像素的正方形图像。</li></ul><p id="826e" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我们做这两个步骤，所以所有进入我们的人工智能模型的图像都有相同的大小(人工智能模型不能处理不同大小的输入)</p><ul class=""><li id="316b" class="mh mi iq jp b jq jr ju jv jy mj kc mk kg ml kk mm mn mo mp bi translated"><strong class="jp ir">变身。ToTensor() </strong>将我们的图像转换成数字。它是怎么做到的？</li><li id="2b79" class="mh mi iq jp b jq mq ju mr jy ms kc mt kg mu kk mm mn mo mp bi translated">它将我们图片的每个像素所包含的三种颜色分开:红色、绿色和蓝色。这实质上是将一幅图像变成三幅图像(一幅红色，一幅绿色，一幅蓝色)。</li><li id="3041" class="mh mi iq jp b jq mq ju mr jy ms kc mt kg mu kk mm mn mo mp bi translated">然后，它将每个着色图像的像素转换为其颜色的亮度，从 0 到 255。这些值除以 255，因此它们可以在 0 到 1 的范围内。我们的图像现在是一个 Torch 张量(一个存储大量数字的数据结构)。</li><li id="4fe4" class="mh mi iq jp b jq mq ju mr jy ms kc mt kg mu kk mm mn mo mp bi translated"><strong class="jp ir">变换。Normalize(mean=[0.485，0.456，0.406]，std=[0.229，0.224，0.225]) </strong>从每个值中减去平均值，然后除以标准差。</li><li id="9e02" class="mh mi iq jp b jq mq ju mr jy ms kc mt kg mu kk mm mn mo mp bi translated">我们将使用一个预先训练好的模型，所以我们需要使用 Pytorch 指定的均值和标准差。在平均值和标准偏差中有三个值来匹配每个 RGB 图片。</li></ul><pre class="km kn ko kp gt lw lx ly lz aw ma bi"><span id="65f2" class="mb ku iq lx b gy mc md l me mf"># Specify transforms using torchvision.transforms as transforms<br/># library</span><span id="8799" class="mb ku iq lx b gy mv md l me mf">transformations = transforms.Compose([<br/>    transforms.Resize(255),<br/>    transforms.CenterCrop(224),<br/>    transforms.ToTensor(),<br/>    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])<br/>])</span></pre><h1 id="c3eb" class="kt ku iq bd kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq bi translated">步骤 3:导入我们的数据并将其放入数据加载器</h1><p id="bb54" class="pw-post-body-paragraph jn jo iq jp b jq lr js jt ju ls jw jx jy lt ka kb kc lu ke kf kg lv ki kj kk ij bi translated">最后，我们可以将我们的图片导入程序。我们使用 torchvision.datasets 库。</p><p id="af25" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><a class="ae mg" href="https://pytorch.org/docs/stable/torchvision/datasets.html" rel="noopener ugc nofollow" target="_blank">看这里</a>。</p><p id="1e98" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我们指定了两个不同的数据集，一个用于 AI 学习的图像(训练集)，另一个用于我们用来测试 AI 模型的数据集(验证集)。</p><p id="d666" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">数据集。ImageFolder() </strong>命令期望我们的数据按照以下方式组织:root/label/picture.png .换句话说，图片要按照文件夹排序。例如，所有蜜蜂的图片应该放在一个文件夹里，所有蚂蚁的图片应该放在另一个文件夹里，等等。</p><p id="e114" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我们下命令</p><ol class=""><li id="7882" class="mh mi iq jp b jq jr ju jv jy mj kc mk kg ml kk mw mn mo mp bi translated">所有文件夹和的路径</li><li id="0446" class="mh mi iq jp b jq mq ju mr jy ms kc mt kg mu kk mw mn mo mp bi translated">我们在上一步中指定的转换。</li></ol><pre class="km kn ko kp gt lw lx ly lz aw ma bi"><span id="8e09" class="mb ku iq lx b gy mc md l me mf"># Load in each dataset and apply transformations using<br/># the torchvision.datasets as datasets library</span><span id="4cce" class="mb ku iq lx b gy mv md l me mf">train_set = datasets.ImageFolder("root/label/train", transform = transformations)</span><span id="4cc6" class="mb ku iq lx b gy mv md l me mf">val_set = datasets.ImageFolder("root/label/valid", transform = transformations)</span></pre><p id="d32f" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">然后，我们希望将导入的图像放入数据加载器。</p><p id="5f9b" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">Dataloader 能够吐出我们数据的随机样本，因此我们的模型不必每次都处理整个数据集。这使得训练更有效率。</p><p id="da02" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我们指定一次需要多少张图片作为我们的 batch_size(所以 32 意味着我们一次需要 32 张图片)。我们还想打乱我们的图像，这样它就可以随机输入到我们的人工智能模型中。</p><p id="945b" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><a class="ae mg" href="https://pytorch.org/docs/stable/data.html" rel="noopener ugc nofollow" target="_blank">点击此处了解数据加载器</a>。</p><pre class="km kn ko kp gt lw lx ly lz aw ma bi"><span id="57cd" class="mb ku iq lx b gy mc md l me mf"># Put into a Dataloader using torch library</span><span id="67de" class="mb ku iq lx b gy mv md l me mf">train_loader = torch.utils.data.DataLoader(train_set, batch_size=32, shuffle=True)</span><span id="56cc" class="mb ku iq lx b gy mv md l me mf">val_loader = torch.utils.data.DataLoader(val_set, batch_size =32, shuffle=True)</span></pre><h1 id="79d0" class="kt ku iq bd kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq bi translated">步骤 4:创建我们的模型</h1><p id="54b8" class="pw-post-body-paragraph jn jo iq jp b jq lr js jt ju ls jw jx jy lt ka kb kc lu ke kf kg lv ki kj kk ij bi translated">人工智能模型需要在大量数据上训练才能有效。由于我们没有那么多数据，我们希望采用一个预训练的模型(之前已经在许多图像上训练过的模型)，但对其进行定制以识别我们的特定图像。这个过程叫做迁移学习。</p><p id="b281" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">图像识别模型有两个部分:</p><ol class=""><li id="b6af" class="mh mi iq jp b jq jr ju jv jy mj kc mk kg ml kk mw mn mo mp bi translated">卷积部分和</li><li id="5e25" class="mh mi iq jp b jq mq ju mr jy ms kc mt kg mu kk mw mn mo mp bi translated">分类器部分</li></ol><p id="8500" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我们希望保留预训练的卷积部分，但放入我们自己的分类器。原因如下:</p><p id="06f0" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我们模型的卷积/池部分用于识别图像内部的特征。它首先识别边缘，然后利用边缘识别形状，再利用形状识别物体。</p><p id="93f1" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">但是，训练这一部分需要大量数据，可能比我们拥有的还要多，因此，我们可以使用默认的预训练卷积层。这些预先训练的卷积层被训练成能够很好地识别这些特征，不管你有什么样的图像。</p><p id="881f" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">卷积层之间也有池层，将图像提取到更小的尺寸，这样就可以很容易地输入到我们的分类器中。</p><p id="3b15" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">模型的最后一部分是分类器。分类器在卷积部分提取从照片中提取的所有信息，并使用它来识别图像。这是我们希望替换的预训练模型的一部分，并根据我们自己的图像进行训练。这使得模型能够识别我们给它的图像。</p><p id="8b6b" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我们使用 torchvision.models 库来下载预训练的模型。我们可以下载许多不同的型号，更多信息可以在<a class="ae mg" href="https://pytorch.org/docs/stable/torchvision/models.html" rel="noopener ugc nofollow" target="_blank">这里</a>找到。我选择了一个名为 densenet161 的模型，并指定我们希望通过设置 pretrained=True 对它进行预训练。</p><p id="ccdf" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">然后，我们要确保我们不要训练这个模型，因为它已经被训练过了，我们只想训练我们接下来要放入的分类器。我们告诉模型不要计算任何参数的梯度，因为这只是为了训练。</p><pre class="km kn ko kp gt lw lx ly lz aw ma bi"><span id="2dda" class="mb ku iq lx b gy mc md l me mf"># Get pretrained model using torchvision.models as models library</span><span id="eaaf" class="mb ku iq lx b gy mv md l me mf">model = models.densenet161(pretrained=True)</span><span id="3515" class="mb ku iq lx b gy mv md l me mf"># Turn off training for their parameters</span><span id="18b1" class="mb ku iq lx b gy mv md l me mf">for param in model.parameters():<br/>    param.requires_grad = False</span></pre><p id="6d83" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">现在我们想用我们自己的分类器替换模型的默认分类器。分类器是全连接的神经网络，要做到这一点，首先要建立自己的神经网络。</p><p id="3bfa" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">神经网络只是一种在输入和输出的数字之间寻找复杂模式和联系的方法。在这种情况下，需要通过卷积部分突出显示的图像特征来确定图像是某个标签的可能性。</p><p id="e275" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我们要做的第一件事是确定输入到我们神经网络的数字数量。这必须与之前部分(卷积部分)输出的数字数量相匹配。由于我们根本没有改变卷积部分，在我们的分类器中输入的数字量应该与模型的默认分类器相同。</p><p id="cfb8" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">接下来，我们要确定输出的数量。这个数字应该与您拥有的图像类型相匹配。该模型会给你一个百分比列表，每个百分比对应于图片对该标签的确定程度。所以如果你有蜜蜂、蚂蚁和苍蝇的图像，有三个标签。输出层中应该有 3 个数字，每个数字对应于输入是蜜蜂、蚂蚁或苍蝇的概率。</p><p id="5280" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">一旦我们有了这些细节，我们就使用 torch.nn 库来创建分类器。信息可以在<a class="ae mg" href="https://pytorch.org/docs/stable/nn.html" rel="noopener ugc nofollow" target="_blank">这里</a>找到。</p><ul class=""><li id="456e" class="mh mi iq jp b jq jr ju jv jy mj kc mk kg ml kk mm mn mo mp bi translated"><strong class="jp ir"> nn。顺序</strong>可以帮助我们将多个模块组合在一起。</li><li id="1b7d" class="mh mi iq jp b jq mq ju mr jy ms kc mt kg mu kk mm mn mo mp bi translated"><strong class="jp ir"> nn。Linear </strong>指定两层之间的交互。我们给它 2 个数字，指定两层中的节点数。</li><li id="e26e" class="mh mi iq jp b jq mq ju mr jy ms kc mt kg mu kk mm mn mo mp bi translated">比如在第一个 nn 里。线性，第一层是输入层，我们可以在第二层选择想要多少个数字(我用的是 1024)。</li><li id="e790" class="mh mi iq jp b jq mq ju mr jy ms kc mt kg mu kk mm mn mo mp bi translated"><strong class="jp ir"> nn。ReLU </strong>是隐藏层的激活功能。激活函数帮助模型学习输入和输出之间的复杂关系。我们在除了输出之外的所有层上使用 ReLU。</li></ul><p id="205c" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我们对任意多个隐藏层重复此操作，每个层中有任意多个节点。</p><ul class=""><li id="37e4" class="mh mi iq jp b jq jr ju jv jy mj kc mk kg ml kk mm mn mo mp bi translated"><strong class="jp ir"> nn。LogSoftmax </strong>是输出的激活功能。softmax 函数将输出的数字转换为每个标签的百分比，并应用 log 函数来加快计算速度。我们必须指定输出层是一个列，因此我们将 dimension 设置为 1。</li></ul><p id="88a3" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">创建我们自己的分类器后，我们替换模型的默认分类器。</p><pre class="km kn ko kp gt lw lx ly lz aw ma bi"><span id="a1e2" class="mb ku iq lx b gy mc md l me mf"># Create new classifier for model using torch.nn as nn library</span><span id="70cf" class="mb ku iq lx b gy mv md l me mf">classifier_input = model.classifier.in_features<br/>num_labels = #PUT IN THE NUMBER OF LABELS IN YOUR DATA</span><span id="c2b1" class="mb ku iq lx b gy mv md l me mf">classifier = nn.Sequential(nn.Linear(classifier_input, 1024),<br/>                           nn.ReLU(),<br/>                           nn.Linear(1024, 512),<br/>                           nn.ReLU(),<br/>                           nn.Linear(512, num_labels),<br/>                           nn.LogSoftmax(dim=1))</span><span id="bc27" class="mb ku iq lx b gy mv md l me mf"># Replace default classifier with new classifier</span><span id="0cbf" class="mb ku iq lx b gy mv md l me mf">model.classifier = classifier</span></pre><p id="d172" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">现在模型已经创建好了！接下来，我们只需要训练它。</p><h1 id="10f5" class="kt ku iq bd kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq bi translated">步骤 5:训练和评估我们的模型</h1><p id="50f5" class="pw-post-body-paragraph jn jo iq jp b jq lr js jt ju ls jw jx jy lt ka kb kc lu ke kf kg lv ki kj kk ij bi translated">在 GPU 上训练模型比 CPU 快很多。因此，为了确定哪个设备对您可用，我们使用 Torch 来检查。如果有兼容的 GPU，我们将变量设置为 GPU，如果没有，则坚持使用 CPU。然后我们把模型移到这个设备上。</p><pre class="km kn ko kp gt lw lx ly lz aw ma bi"><span id="ff09" class="mb ku iq lx b gy mc md l me mf"># Find the device available to use using torch library</span><span id="81c1" class="mb ku iq lx b gy mv md l me mf">device = torch.device("cuda" if torch.cuda.is_available() else "cpu")</span><span id="65d8" class="mb ku iq lx b gy mv md l me mf"># Move model to the device specified above</span><span id="d2c5" class="mb ku iq lx b gy mv md l me mf">model.to(device)</span></pre><p id="aba5" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">在训练时，我们需要确定我们的模型有多“偏离”。为了评估我们模型的误差量，我们使用<em class="mx">神经网络。NLLLoss </em>。这个函数接收我们模型的输出，为此我们使用了神经网络。LogSoftmax 函数。</p><p id="3c8b" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">为了训练我们的模型，我们采用我们的误差，看看我们如何调整我们的数字乘以权重，以获得最小的误差。计算我们如何调整我们的体重并将其应用于我们的体重的方法被称为亚当。我们使用<a class="ae mg" href="https://pytorch.org/docs/stable/optim.html" rel="noopener ugc nofollow" target="_blank"> torch.optim </a>库来使用这个方法，并给它我们的参数。</p><pre class="km kn ko kp gt lw lx ly lz aw ma bi"><span id="e26f" class="mb ku iq lx b gy mc md l me mf"># Set the error function using torch.nn as nn library</span><span id="e0e5" class="mb ku iq lx b gy mv md l me mf">criterion = nn.NLLLoss()</span><span id="7002" class="mb ku iq lx b gy mv md l me mf"># Set the optimizer function using torch.optim as optim library</span><span id="3f7f" class="mb ku iq lx b gy mv md l me mf">optimizer = optim.Adam(model.classifier.parameters())</span></pre><p id="0ebe" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">现在我们训练。我们希望我们的模型多次遍历整个数据集，所以我们使用 for 循环。每一次它检查了整组图像，就被称为一个时期。在一个时期内，我们希望模型通过训练集和验证集。</p><h2 id="85ee" class="mb ku iq bd kv my mz dn kz na nb dp ld jy nc nd lh kc ne nf ll kg ng nh lp ni bi translated">我们从训练集开始。</h2><p id="2719" class="pw-post-body-paragraph jn jo iq jp b jq lr js jt ju ls jw jx jy lt ka kb kc lu ke kf kg lv ki kj kk ij bi translated">我们首先将模型设置为训练模式，并使用 for 循环遍历每幅图像。</p><p id="8f4a" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">在将图像和标签移动到适当的设备之后，我们需要通过声明<em class="mx"> optimizer.zero_grad() </em>来清除权重的调整。</p><p id="0fcd" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">然后，在给定图像的情况下，我们可以计算模型的输出，以及在给定输出和正确答案的情况下，我们的模型有多“偏离”。</p><p id="e438" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">然后，我们可以通过调用<em class="mx"> loss.backward() </em>找到我们需要进行的调整以减少这个错误，并通过调用<em class="mx"> optimizer.step() </em>使用我们的优化器来调整权重。</p><p id="6eb0" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">当我们训练时，我们想知道事情进展如何，所以我们记录我们计算的总误差并打印出训练的进度。</p><h2 id="0e50" class="mb ku iq bd kv my mz dn kz na nb dp ld jy nc nd lh kc ne nf ll kg ng nh lp ni bi translated">我们转到验证集。</h2><p id="465c" class="pw-post-body-paragraph jn jo iq jp b jq lr js jt ju ls jw jx jy lt ka kb kc lu ke kf kg lv ki kj kk ij bi translated">我们将模型设置为评估模式，并使用 for 循环遍历集合中的所有图像。</p><p id="050f" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我们重复对训练集采取的步骤，以获得我们的模型的输出以及我们的模型与真实标签“偏离”了多少。</p><p id="831b" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">为了提高计算速度，我们的模型使用了 LogSoftmax 函数，但是现在我们想要的是真实的百分比，而不是对数百分比。所以我们用<em class="mx"> torch.exp </em>来反转 log 函数。然后我们想看看模型为我们的图像猜测了哪个类。<em class="mx">。topk </em>给出了我们猜测的顶级类，以及它猜测的百分比——我们只关心这个类，所以我们可以忽略这个百分比。</p><p id="2731" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">为了确定它猜对了多少图像，我们检查哪些猜测的类等于真实的类。然后，我们可以对整批进行平均，以确定我们的模型的准确性(猜对的图像数除以图像总数)。</p><p id="4d85" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">在检查完训练集和验证集之后，我们希望打印两者的错误以及验证集的准确性。</p><pre class="km kn ko kp gt lw lx ly lz aw ma bi"><span id="88d0" class="mb ku iq lx b gy mc md l me mf">epochs = 10<br/>for epoch in range(epochs):<br/>    train_loss = 0<br/>    val_loss = 0<br/>    accuracy = 0<br/>    <br/>    # Training the model<br/>    model.train()<br/>    counter = 0<br/>    for inputs, labels in train_loader:<br/>        # Move to device<br/>        inputs, labels = inputs.to(device), labels.to(device)</span><span id="da4b" class="mb ku iq lx b gy mv md l me mf">        # Clear optimizers<br/>        optimizer.zero_grad()</span><span id="dd8a" class="mb ku iq lx b gy mv md l me mf">        # Forward pass<br/>        output = model.forward(inputs)</span><span id="cf83" class="mb ku iq lx b gy mv md l me mf">        # Loss<br/>        loss = criterion(output, labels)</span><span id="39f3" class="mb ku iq lx b gy mv md l me mf">        # Calculate gradients (backpropogation)<br/>        loss.backward()</span><span id="e1b6" class="mb ku iq lx b gy mv md l me mf">        # Adjust parameters based on gradients<br/>        optimizer.step()</span><span id="fa04" class="mb ku iq lx b gy mv md l me mf">        # Add the loss to the training set's rnning loss<br/>        train_loss += loss.item()*inputs.size(0)<br/>        <br/>        # Print the progress of our training<br/>        counter += 1<br/>        print(counter, "/", len(train_loader))<br/>        <br/>    # Evaluating the model<br/>    model.eval()<br/>    counter = 0<br/>    # Tell torch not to calculate gradients<br/>    with torch.no_grad():<br/>        for inputs, labels in val_loader:<br/>            # Move to device<br/>            inputs, labels = inputs.to(device), labels.to(device)</span><span id="ae5c" class="mb ku iq lx b gy mv md l me mf">            # Forward pass<br/>            output = model.forward(inputs)</span><span id="d078" class="mb ku iq lx b gy mv md l me mf">            # Calculate Loss<br/>            valloss = criterion(output, labels)</span><span id="6506" class="mb ku iq lx b gy mv md l me mf">            # Add loss to the validation set's running loss<br/>            val_loss += valloss.item()*inputs.size(0)<br/>            <br/>            # Since our model outputs a LogSoftmax, find the real <br/>            # percentages by reversing the log function<br/>            output = torch.exp(output)</span><span id="f6d3" class="mb ku iq lx b gy mv md l me mf">            # Get the top class of the output<br/>            top_p, top_class = output.topk(1, dim=1)</span><span id="ef26" class="mb ku iq lx b gy mv md l me mf">            # See how many of the classes were correct?<br/>            equals = top_class == labels.view(*top_class.shape)</span><span id="1b91" class="mb ku iq lx b gy mv md l me mf">            # Calculate the mean (get the accuracy for this batch)<br/>            # and add it to the running accuracy for this epoch<br/>            accuracy += torch.mean(equals.type(torch.FloatTensor)).item()<br/>            <br/>            # Print the progress of our evaluation<br/>            counter += 1<br/>            print(counter, "/", len(val_loader))<br/>    <br/>    # Get the average loss for the entire epoch<br/>    train_loss = train_loss/len(train_loader.dataset)<br/>    valid_loss = val_loss/len(val_loader.dataset)</span><span id="328b" class="mb ku iq lx b gy mv md l me mf">    # Print out the information<br/>    print('Accuracy: ', accuracy/len(val_loader))<br/>    print('Epoch: {} \tTraining Loss: {:.6f} \tValidation Loss: {:.6f}'.format(epoch, train_loss, valid_loss))</span></pre><h1 id="2ea4" class="kt ku iq bd kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq bi translated">步骤 5:实际使用我们的模型</h1><p id="9840" class="pw-post-body-paragraph jn jo iq jp b jq lr js jt ju ls jw jx jy lt ka kb kc lu ke kf kg lv ki kj kk ij bi translated">太棒了！你刚刚建立了一个人工智能图像分类器。但是，现在我们想实际使用它——我们想给它一个随机图像，看看它认为这是哪个标签。</p><p id="f1ee" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">首先，我们为评估模式设置模型。</p><pre class="km kn ko kp gt lw lx ly lz aw ma bi"><span id="1172" class="mb ku iq lx b gy mc md l me mf">model.eval()</span></pre><p id="76a5" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">然后我们创建一个可以处理图像的函数，这样它就可以输入到我们的模型中。</p><p id="0ff6" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我们打开图像，通过保持纵横比但使最短边仅为 255 px 来调整其大小，并通过 224px 裁剪中心 224px。然后，我们将图片转换成一个数组，并通过转置数组来确保颜色通道的数量是第一维，而不是最后一维。接下来，我们通过除以 255 来转换 0 和 1 之间的每个值。然后，我们通过减去平均值并除以标准偏差来标准化这些值。最后，我们将数组转换为 Torch 张量，并将值转换为 float。</p><p id="e0f3" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">这些步骤与我们在步骤 2 中指定的步骤相同，但是这一次我们必须手动编码命令，而不是依赖于转换库。</p><pre class="km kn ko kp gt lw lx ly lz aw ma bi"><span id="5da1" class="mb ku iq lx b gy mc md l me mf"># Process our image<br/>def process_image(image_path):<br/>    # Load Image<br/>    img = Image.open(image_path)<br/>    <br/>    # Get the dimensions of the image<br/>    width, height = img.size<br/>    <br/>    # Resize by keeping the aspect ratio, but changing the dimension<br/>    # so the shortest size is 255px<br/>    img = img.resize((255, int(255*(height/width))) if width &lt; height else (int(255*(width/height)), 255))<br/>    <br/>    # Get the dimensions of the new image size<br/>    width, height = img.size<br/>    <br/>    # Set the coordinates to do a center crop of 224 x 224<br/>    left = (width - 224)/2<br/>    top = (height - 224)/2<br/>    right = (width + 224)/2<br/>    bottom = (height + 224)/2<br/>    img = img.crop((left, top, right, bottom))<br/>    <br/>    # Turn image into numpy array<br/>    img = np.array(img)<br/>    <br/>    # Make the color channel dimension first instead of last<br/>    img = img.transpose((2, 0, 1))<br/>    <br/>    # Make all values between 0 and 1<br/>    img = img/255<br/>    <br/>    # Normalize based on the preset mean and standard deviation<br/>    img[0] = (img[0] - 0.485)/0.229<br/>    img[1] = (img[1] - 0.456)/0.224<br/>    img[2] = (img[2] - 0.406)/0.225<br/>    <br/>    # Add a fourth dimension to the beginning to indicate batch size<br/>    img = img[np.newaxis,:]<br/>    <br/>    # Turn into a torch tensor<br/>    image = torch.from_numpy(img)<br/>    image = image.float()<br/>    return image</span></pre><p id="ca2a" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">处理完图像后，我们可以构建一个函数来使用我们的模型预测标签。我们将图像输入到我们的模型中，并获得输出。然后，我们反转在输出层应用的 LogSoftmax 函数中的日志，并返回模型预测的顶级类及其猜测的确定程度。</p><pre class="km kn ko kp gt lw lx ly lz aw ma bi"><span id="0c7d" class="mb ku iq lx b gy mc md l me mf"># Using our model to predict the label<br/>def predict(image, model):<br/>    # Pass the image through our model<br/>    output = model.forward(image)<br/>    <br/>    # Reverse the log function in our output<br/>    output = torch.exp(output)<br/>    <br/>    # Get the top predicted class, and the output percentage for<br/>    # that class<br/>    probs, classes = output.topk(1, dim=1)<br/>    return probs.item(), classes.item()</span></pre><p id="e939" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">最后，我们想要显示图像。我们将图像转换回一个数组，并通过乘以标准偏差并加回平均值来取消标准化。然后我们使用 matplotlib.pyplot 库来绘制图片。</p><pre class="km kn ko kp gt lw lx ly lz aw ma bi"><span id="ef55" class="mb ku iq lx b gy mc md l me mf"># Show Image<br/>def show_image(image):<br/>    # Convert image to numpy<br/>    image = image.numpy()<br/>    <br/>    # Un-normalize the image<br/>    image[0] = image[0] * 0.226 + 0.445<br/>    <br/>    # Print the image<br/>    fig = plt.figure(figsize=(25, 4))<br/>    plt.imshow(np.transpose(image[0], (1, 2, 0)))</span></pre><p id="f6ac" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">现在，我们可以使用所有这些函数来打印我们的模型的猜测和它有多确定！</p><pre class="km kn ko kp gt lw lx ly lz aw ma bi"><span id="8e88" class="mb ku iq lx b gy mc md l me mf"># Process Image<br/>image = process_image("root/image1234.jpg")</span><span id="3809" class="mb ku iq lx b gy mv md l me mf"># Give image to model to predict output<br/>top_prob, top_class = predict(image, model)</span><span id="d0ee" class="mb ku iq lx b gy mv md l me mf"># Show the image<br/>show_image(image)</span><span id="412b" class="mb ku iq lx b gy mv md l me mf"># Print the results<br/>print("The model is ", top_prob*100, "% certain that the image has a predicted class of ", top_class  )</span></pre><p id="046f" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">就是这样！</p></div></div>    
</body>
</html>