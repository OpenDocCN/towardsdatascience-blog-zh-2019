<html>
<head>
<title>Kalman Filter(3) — Localisation in Continuous State Space</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">卡尔曼滤波器(3)——连续状态空间中的定位</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/kalman-filter-3-localisation-in-continuous-state-space-1c979f6bde5b?source=collection_archive---------33-----------------------#2019-11-16">https://towardsdatascience.com/kalman-filter-3-localisation-in-continuous-state-space-1c979f6bde5b?source=collection_archive---------33-----------------------#2019-11-16</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="cbd0" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">将高斯分布应用于连续状态空间</h2></div><p id="00fa" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在过去的<a class="ae le" rel="noopener" target="_blank" href="/kalman-filter-2-grid-world-localisation-93674dc750c6">会议</a>中，我们尝试在网格世界中进行定位，在网格世界中，我们的机器人有不同的概率位于不同的单元中。总之，状态空间是离散的。为了将问题设置推广到连续状态空间，我们将到达卡尔曼滤波器的核心。</p><p id="0239" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在我们讨论卡尔曼滤波器的任何细节之前，请记住我们在这里<a class="ae le" rel="noopener" target="_blank" href="/kalman-filter-1-the-basics-68f89deb2613">学到的东西</a>，卡尔曼滤波器总是有两个步骤:</p><ol class=""><li id="1dae" class="lf lg it kk b kl km ko kp kr lh kv li kz lj ld lk ll lm ln bi translated"><strong class="kk iu">传感(测量)</strong>:基于机器人所看到的，更新后验分布</li><li id="fe40" class="lf lg it kk b kl lo ko lp kr lq kv lr kz ls ld lk ll lm ln bi translated"><strong class="kk iu">移动(预测)</strong>:估计机器人移动后的新位置</li></ol><p id="f70a" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">以下是的结构:</p><ol class=""><li id="8bd9" class="lf lg it kk b kl km ko kp kr lh kv li kz lj ld lk ll lm ln bi translated">扩展到连续状态空间的想法</li><li id="4c45" class="lf lg it kk b kl lo ko lp kr lq kv lr kz ls ld lk ll lm ln bi translated">用高斯分布实现 sense(测量)</li><li id="3524" class="lf lg it kk b kl lo ko lp kr lq kv lr kz ls ld lk ll lm ln bi translated">用高斯分布实现移动(预测)</li><li id="5b62" class="lf lg it kk b kl lo ko lp kr lq kv lr kz ls ld lk ll lm ln bi translated">结合在一起</li><li id="2d1b" class="lf lg it kk b kl lo ko lp kr lq kv lr kz ls ld lk ll lm ln bi translated">多维卡尔曼滤波器</li></ol><h1 id="c799" class="lt lu it bd lv lw lx ly lz ma mb mc md jz me ka mf kc mg kd mh kf mi kg mj mk bi translated">原则</h1><p id="0d9a" class="pw-post-body-paragraph ki kj it kk b kl ml ju kn ko mm jx kq kr mn kt ku kv mo kx ky kz mp lb lc ld im bi translated">在离散世界中，每个状态都有一个单独的概率，其总和为 1，将其扩展到连续状态空间的关键是找到一个连续的分布，而在卡尔曼滤波器中，该分布是高斯分布。</p><figure class="mr ms mt mu gt mv gh gi paragraph-image"><div role="button" tabindex="0" class="mw mx di my bf mz"><div class="gh gi mq"><img src="../Images/eeae6f896154b9dc4871a1697a1ef9c5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*mrXLaPnYT0Qi-xwnpAdWog.png"/></div></div></figure><p id="25ac" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">这就是说，无论是步进测量还是预测，我们对机器人位置的估计总是符合高斯分布。高斯的两个参数分别代表:</p><ol class=""><li id="a26a" class="lf lg it kk b kl km ko kp kr lh kv li kz lj ld lk ll lm ln bi translated"><code class="fe nc nd ne nf b">μ</code>:机器人位置最可能的估计</li><li id="1455" class="lf lg it kk b kl lo ko lp kr lq kv lr kz ls ld lk ll lm ln bi translated"><code class="fe nc nd ne nf b">σ</code>:检测器和预测的不精确等造成的我们估计的不确定性。</li></ol><p id="6ca7" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">任务是在一系列测量和预测之后，找到最终的高斯分布参数<code class="fe nc nd ne nf b">μ</code>和<code class="fe nc nd ne nf b">σ</code>。让我们把它分成两部分。</p><h1 id="0d24" class="lt lu it bd lv lw lx ly lz ma mb mc md jz me ka mf kc mg kd mh kf mi kg mj mk bi translated">测量(感觉)</h1><p id="e3e8" class="pw-post-body-paragraph ki kj it kk b kl ml ju kn ko mm jx kq kr mn kt ku kv mo kx ky kz mp lb lc ld im bi translated">在测量阶段，我们根据机器人的传感器更新我们的信念。假设<code class="fe nc nd ne nf b">X</code>是位置<code class="fe nc nd ne nf b">Z</code>是测量(机器人观察到的)，我们正在解决的问题是:</p><figure class="mr ms mt mu gt mv gh gi paragraph-image"><div role="button" tabindex="0" class="mw mx di my bf mz"><div class="gh gi ng"><img src="../Images/12d53754127c5f5194e6fb7a24d4aa46.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*se27PW1gamhsyG4nP7JJvA.png"/></div></div></figure><p id="8412" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我们之前的信念是<code class="fe nc nd ne nf b">p(X)</code>，但是我们的传感器看到的分布<code class="fe nc nd ne nf b">p(Z|X)</code>不同，现在我们正在尝试计算我们的后验分布<code class="fe nc nd ne nf b">p(X|Z)</code>，这是给定的我们所看到的(<code class="fe nc nd ne nf b">Z</code>)，我们现在的最佳估计是什么？</p><p id="ffa5" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">请记住，这里所有的分布都是高斯分布，为了得到后验分布，我们只需要应用贝叶斯规则，即将这两个分布相乘:</p><figure class="mr ms mt mu gt mv gh gi paragraph-image"><div role="button" tabindex="0" class="mw mx di my bf mz"><div class="gh gi nh"><img src="../Images/3dfb25a55c9ff618885b92e808fb9fef.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*PT-wBDZ9o8796gu2_jLFdA.png"/></div></div></figure><p id="cf6e" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">以上是更新分布的参数。注意<code class="fe nc nd ne nf b">σ_new</code>比<code class="fe nc nd ne nf b">σ</code>和<code class="fe nc nd ne nf b">γ</code>都小！这告诉我们，倍增后不确定性降低了，这符合我们的知识，即传感实际上是获取信息和降低不确定性。实施将是:</p><figure class="mr ms mt mu gt mv"><div class="bz fp l di"><div class="ni nj l"/></div></figure><h1 id="c6e7" class="lt lu it bd lv lw lx ly lz ma mb mc md jz me ka mf kc mg kd mh kf mi kg mj mk bi translated">预测(移动)</h1><p id="7ca4" class="pw-post-body-paragraph ki kj it kk b kl ml ju kn ko mm jx kq kr mn kt ku kv mo kx ky kz mp lb lc ld im bi translated">移动是直接向前的加法。初始分布<code class="fe nc nd ne nf b">N(μ, σ)</code>，移动不确定度<code class="fe nc nd ne nf b">U</code><code class="fe nc nd ne nf b">γ^2</code>，移动后的分布为<code class="fe nc nd ne nf b">N(μ+U, σ^2+γ^2)</code>，即均值加<code class="fe nc nd ne nf b">U</code>，不确定度加<code class="fe nc nd ne nf b">γ^2</code>。</p><figure class="mr ms mt mu gt mv"><div class="bz fp l di"><div class="ni nj l"/></div></figure><p id="6551" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">注意，通过进行不确定的运动，方差(不确定性)增加，这与减少方差(不确定性)的测量相反。</p><h1 id="5080" class="lt lu it bd lv lw lx ly lz ma mb mc md jz me ka mf kc mg kd mh kf mi kg mj mk bi translated">1D 卡尔曼滤波器</h1><p id="7483" class="pw-post-body-paragraph ki kj it kk b kl ml ju kn ko mm jx kq kr mn kt ku kv mo kx ky kz mp lb lc ld im bi translated">现在结合测量和预测，我们得到:</p><figure class="mr ms mt mu gt mv"><div class="bz fp l di"><div class="ni nj l"/></div></figure><p id="abaa" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在这个例子中，我们设置了初始位置<code class="fe nc nd ne nf b">mu = 0</code>和不确定度<code class="fe nc nd ne nf b">sig = 10000</code>，这意味着我们对机器人的初始位置非常不确定。经过几轮迭代，我们得到了结果:</p><figure class="mr ms mt mu gt mv gh gi paragraph-image"><div role="button" tabindex="0" class="mw mx di my bf mz"><div class="gh gi nk"><img src="../Images/10d2b3e4cf3e92d220d5bfcd83b8bf8a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Xa4Dgx2wX7eVRf82D2GM4w.png"/></div></div></figure><p id="a97c" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我们看到，通过进行第一次测量，不确定性立即下降到<code class="fe nc nd ne nf b">3.998</code>，它小于初始方差和测量方差。最后，我们用方差<code class="fe nc nd ne nf b">4.0058</code>预测我们的机器人在位置<code class="fe nc nd ne nf b">10.9999</code>着陆。</p><h1 id="3523" class="lt lu it bd lv lw lx ly lz ma mb mc md jz me ka mf kc mg kd mh kf mi kg mj mk bi translated">多维卡尔曼滤波器</h1><p id="26bc" class="pw-post-body-paragraph ki kj it kk b kl ml ju kn ko mm jx kq kr mn kt ku kv mo kx ky kz mp lb lc ld im bi translated">在上面的例子中，我们只有一个变量，即位置<code class="fe nc nd ne nf b">p</code>。现在让我们考虑第二个变速<code class="fe nc nd ne nf b">v</code>，然后我们的任务将是得到<code class="fe nc nd ne nf b">x = (p, v)</code>和不确定矩阵<code class="fe nc nd ne nf b">P = cov(x)</code>的最终估计。</p><h2 id="8eb7" class="nl lu it bd lv nm nn dn lz no np dp md kr nq nr mf kv ns nt mh kz nu nv mj nw bi translated">预言；预测；预告</h2><p id="953e" class="pw-post-body-paragraph ki kj it kk b kl ml ju kn ko mm jx kq kr mn kt ku kv mo kx ky kz mp lb lc ld im bi translated">在预测阶段，假设我们有以下关系:</p><figure class="mr ms mt mu gt mv gh gi paragraph-image"><div class="gh gi nx"><img src="../Images/6444b38eef7d9dd25ab4c59677924c58.png" data-original-src="https://miro.medium.com/v2/resize:fit:800/format:webp/1*wAYKfiRtjEqT76ACwo6mbQ.png"/></div><figcaption class="ny nz gj gh gi oa ob bd b be z dk">from <a class="ae le" href="https://www.bzarg.com/p/how-a-kalman-filter-works-in-pictures/" rel="noopener ugc nofollow" target="_blank">reference</a></figcaption></figure><p id="8842" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">给定速度和时间<code class="fe nc nd ne nf b">t</code>，我们可以得到下一个位置，我们假设的速度保持不变。然后我们得到了它的矩阵形式:</p><figure class="mr ms mt mu gt mv gh gi paragraph-image"><div class="gh gi oc"><img src="../Images/63bd92df91b20d55fc25d5d794aacdb6.png" data-original-src="https://miro.medium.com/v2/resize:fit:648/format:webp/1*yB5F3l1jL4gyJpAZt_cFKw.png"/></div></figure><p id="a444" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">这里<code class="fe nc nd ne nf b">F</code>称为状态转移矩阵，<code class="fe nc nd ne nf b">P</code>为协方差矩阵，<code class="fe nc nd ne nf b">μ</code>为外部运动矢量(比如有加速度或踏板油门)。</p><h2 id="285d" class="nl lu it bd lv nm nn dn lz no np dp md kr nq nr mf kv ns nt mh kz nu nv mj nw bi translated">尺寸</h2><p id="e228" class="pw-post-body-paragraph ki kj it kk b kl ml ju kn ko mm jx kq kr mn kt ku kv mo kx ky kz mp lb lc ld im bi translated">测量也是一样，有一个测量转移矩阵<code class="fe nc nd ne nf b">H</code>。以最简单的形式，让我们假设<code class="fe nc nd ne nf b">H = (1, 0)</code>和，</p><pre class="mr ms mt mu gt od nf oe of aw og bi"><span id="a143" class="nl lu it nf b gy oh oi l oj ok"> <!-- -->μ_0 = Hx = (1, 0)(p, v)^T = p</span></pre><p id="a9b1" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">这就是说，我们的测量只能测量机器人的位置，而看不到速度。现在问题变成我们有两个高斯分布，一个是(先验分布):</p><figure class="mr ms mt mu gt mv gh gi paragraph-image"><div class="gh gi ol"><img src="../Images/7230eb71145b13fb9c9686900eeffc23.png" data-original-src="https://miro.medium.com/v2/resize:fit:652/format:webp/1*9_Co46nM4i-h4LiceaA3eQ.png"/></div></figure><p id="ca23" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">第二个是(测量分布):</p><figure class="mr ms mt mu gt mv gh gi paragraph-image"><div class="gh gi om"><img src="../Images/89bfce471f1f9e956b77d20d5c535511.png" data-original-src="https://miro.medium.com/v2/resize:fit:476/format:webp/1*sZwxr7BbL2bxrNn6wvVWxQ.png"/></div></figure><p id="7328" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">看起来很熟悉我们之前的例子，对吧？现在我们需要将这两个分布组合成后验分布。这里涉及到一系列的推导(一个精彩的解释<a class="ae le" href="https://www.bzarg.com/p/how-a-kalman-filter-works-in-pictures/" rel="noopener ugc nofollow" target="_blank">这里</a>，我把结果放在这里:</p><figure class="mr ms mt mu gt mv gh gi paragraph-image"><div class="gh gi on"><img src="../Images/bc30c769611ce89edf4889a9c98ed41b.png" data-original-src="https://miro.medium.com/v2/resize:fit:684/format:webp/1*0lPacOHYC0ZD4tpfa3GLKg.png"/></div></figure><p id="9dd7" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">现在让我们将它们结合在一起，得到最终的卡尔曼滤波函数:</p><figure class="mr ms mt mu gt mv"><div class="bz fp l di"><div class="ni nj l"/></div></figure><p id="9655" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">完整的实现，请点击查看<a class="ae le" href="https://github.com/MJeremy2017/Machine-Learning-Models/blob/master/Localisation/kalman-filter.ipynb" rel="noopener ugc nofollow" target="_blank">。</a></p><p id="fa55" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="kk iu">参考</strong>:</p><ol class=""><li id="0a4d" class="lf lg it kk b kl km ko kp kr lh kv li kz lj ld lk ll lm ln bi translated"><a class="ae le" href="https://classroom.udacity.com/courses/cs373" rel="noopener ugc nofollow" target="_blank">https://classroom.udacity.com/courses/cs373</a></li><li id="659f" class="lf lg it kk b kl lo ko lp kr lq kv lr kz ls ld lk ll lm ln bi translated"><a class="ae le" href="https://www.bzarg.com/p/how-a-kalman-filter-works-in-pictures/" rel="noopener ugc nofollow" target="_blank">https://www . bzarg . com/p/how-a-Kalman-filter-works-in-pictures/</a></li></ol></div></div>    
</body>
</html>