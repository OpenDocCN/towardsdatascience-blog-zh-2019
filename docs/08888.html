<html>
<head>
<title>Watching machine learning models fitting a curve!</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">看机器学习模型拟合曲线！</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/watching-machine-learning-models-fitting-a-curve-c594fec4bbdb?source=collection_archive---------7-----------------------#2019-11-27">https://towardsdatascience.com/watching-machine-learning-models-fitting-a-curve-c594fec4bbdb?source=collection_archive---------7-----------------------#2019-11-27</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><figure class="gl gn jr js jt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi jq"><img src="../Images/032fcf0b5f4a2e8172424ec6b5543ee6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*XsaDTmCyMyP4E8HWXNvBSA.jpeg"/></div></div><figcaption class="kb kc gj gh gi kd ke bd b be z dk">Image www.pexels.com</figcaption></figure><p id="6a8c" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">图灵奖获得者 Judea Pearl 的声明表达了当前流行的机器学习应用程序(深度学习)背后的简单机制。</p><h2 id="13e1" class="ld le it bd lf lg lh dn li lj lk dp ll kq lm ln lo ku lp lq lr ky ls lt lu lv bi translated">“机器学习只是美化了‘曲线拟合’”</h2><div class="lw lx gp gr ly lz"><a href="https://diginomica.com/ai-curve-fitting-not-intelligence" rel="noopener  ugc nofollow" target="_blank"><div class="ma ab fo"><div class="mb ab mc cl cj md"><h2 class="bd iu gy z fp me fr fs mf fu fw is bi translated">人工智能的今天和明天主要是关于曲线拟合，而不是智能</h2><div class="mg l"><h3 class="bd b gy z fp me fr fs mf fu fw dk translated">随着围绕人工智能价值的辩论继续，人工智能冬天的风险是真实的。我们需要对什么是真实的和什么是…</h3></div><div class="mh l"><p class="bd b dl z fp me fr fs mf fu fw dk translated">diginomica.com</p></div></div><div class="mi l"><div class="mj l mk ml mm mi mn jz lz"/></div></div></a></div><p id="3673" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">在本文中，我想从字面上理解这句话，并在学习过程中观察简单的模型。在动画中，我们将能够看到不同的模型是如何学习的。为了做到这一点，我们查看简单的人工生成的数据，这些数据只包含一个输入参数和一个输出参数。</p><p id="dc66" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">查看生成数据的 Python 代码:</p><figure class="mo mp mq mr gt ju"><div class="bz fp l di"><div class="ms mt l"/></div></figure><p id="964e" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">“listex”值用作输入值，“listey”用作输出值。他们一起构建训练数据。这些值是由线性函数和随机的正态分布数字产生的。</p><h2 id="b2d7" class="ld le it bd lf lg lh dn li lj lk dp ll kq lm ln lo ku lp lq lr ky ls lt lu lv bi translated">神经网络如何找到这些数据背后的联系？是否识别了正确的连接？<br/>如何应对随机干扰？</h2><p id="a0b1" class="pw-post-body-paragraph kf kg it kh b ki mu kk kl km mv ko kp kq mw ks kt ku mx kw kx ky my la lb lc im bi translated">过于擅长表示给定数据集的曲线拟合方法的一个风险是<a class="ae mz" href="https://en.wikipedia.org/wiki/Overfitting" rel="noopener ugc nofollow" target="_blank">过度拟合</a>，即算法无法识别数据中的正常波动，最终被噪声撕裂。</p><p id="597d" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">有了“tensor flow”(【https://www.tensorflow.org/】<a class="ae mz" href="https://www.tensorflow.org/" rel="noopener ugc nofollow" target="_blank">)我们可以轻松地创建和训练这样的模型。</a></p><figure class="mo mp mq mr gt ju"><div class="bz fp l di"><div class="ms mt l"/></div></figure><p id="77bf" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">上面创建的神经网络仅由一个没有激活功能的细胞组成。所以它只代表一个简单的线性回归。</p><p id="a786" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">现在，我们可以通过计算一组输入值的预测来了解模型所学习的函数。</p><figure class="mo mp mq mr gt ju"><div class="bz fp l di"><div class="ms mt l"/></div></figure><p id="a7d4" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">并将它们与训练数据一起绘制出来:</p><figure class="mo mp mq mr gt ju"><div class="bz fp l di"><div class="ms mt l"/></div></figure><p id="90ae" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">首先，用 TensorFlow 对数据(蓝点)训练没有激活函数的线性模型，并在训练-时期(黄点)后进行预测。你可以在视频中看到曲线是如何拟合的。</p><figure class="mo mp mq mr gt ju"><div class="bz fp l di"><div class="na mt l"/></div></figure><p id="4d22" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">它学习数据背后的线性关系。</p><h2 id="bfe4" class="ld le it bd lf lg lh dn li lj lk dp ll kq lm ln lo ku lp lq lr ky ls lt lu lv bi translated">当我们使用一个有更多细胞和层的神经网络时会发生什么？</h2><figure class="mo mp mq mr gt ju"><div class="bz fp l di"><div class="ms mt l"/></div></figure><figure class="mo mp mq mr gt ju"><div class="bz fp l di"><div class="na mt l"/></div></figure><p id="8259" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">更多的神经元</p><figure class="mo mp mq mr gt ju"><div class="bz fp l di"><div class="na mt l"/></div></figure><p id="9701" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">该模型过度解释了数据(过度拟合)，因此不太适合一般化。</p><p id="16c0" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">当数据背后的规则变得更加复杂的时候呢？</p><figure class="mo mp mq mr gt ju"><div class="bz fp l di"><div class="ms mt l"/></div></figure><p id="1991" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">这些值是由二次函数和随机的正态分布数字产生的。</p><p id="1c84" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">让我们从仅包含一个线性单元的简单模型开始。</p><figure class="mo mp mq mr gt ju"><div class="bz fp l di"><div class="na mt l"/></div></figure><p id="3d7f" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">它无法对上下文建模。为此，该模型不够强大(也就是说，它没有足够的参数来学习)。<br/>让我们使用一个更强大的模型:</p><figure class="mo mp mq mr gt ju"><div class="bz fp l di"><div class="na mt l"/></div></figure><p id="7911" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">另一个更强大的模型是:</p><figure class="mo mp mq mr gt ju"><div class="bz fp l di"><div class="na mt l"/></div></figure><p id="db0e" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">这里再次出现过度拟合。</p><p id="dad8" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">在这一系列动画中，我们已经看到，对于只有一个输入和一个输出值的非常简单的情况，选择神经网络的架构是多么重要。参数太少的模型无法正确模拟数据，参数太多的模型往往会很快溢出。</p></div></div>    
</body>
</html>