<html>
<head>
<title>Image Similarity Detection in Action with Tensorflow 2.0</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">Tensorflow 2.0 中的图像相似性检测</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/image-similarity-detection-in-action-with-tensorflow-2-0-b8d9a78b2509?source=collection_archive---------2-----------------------#2019-12-29">https://towardsdatascience.com/image-similarity-detection-in-action-with-tensorflow-2-0-b8d9a78b2509?source=collection_archive---------2-----------------------#2019-12-29</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="22b5" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">准备好为您的 web 应用程序使用管道了吗</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/0b0bb85c2d897ec11323e03f800a67cf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*kkf8c-bX-1Pk-mbm"/></div></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk">Photo by <a class="ae ky" href="https://unsplash.com/@sharonmccutcheon?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Sharon McCutcheon</a> on <a class="ae ky" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><p id="289d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在这篇文章中，我将向您展示我是如何在我的'<strong class="lb iu">时尚价格比较'</strong> web 应用程序中实现'<strong class="lb iu">图像相似性检测</strong>任务的。我将使用图像相似性，根据用户搜索的内容向他们推荐视觉上相似的产品。</p><p id="7146" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">实现的完整源代码可以在我的 GitHub 库的<a class="ae ky" href="https://github.com/eisbilen/ImageSimilarityDetection" rel="noopener ugc nofollow" target="_blank">中找到。</a></p><p id="07c7" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在整篇文章中，将有专门的部分来讨论以下每一个主题:</p><ul class=""><li id="6029" class="lv lw it lb b lc ld lf lg li lx lm ly lq lz lu ma mb mc md bi translated">如何使用<strong class="lb iu"> Tensorflow 2.0 </strong>和<strong class="lb iu"> Tensorflow Hub </strong>生成产品图像的<strong class="lb iu">【图像特征向量】</strong>。</li><li id="3aa4" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated">如何使用<strong class="lb iu">Spotify/airy</strong>库和<strong class="lb iu">图像特征向量</strong>计算图像相似度得分。</li><li id="cd5d" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated">在一个<strong class="lb iu"> JSON 文件</strong>中存储相似性分数和相关的产品标识号，以便在我们的 web 应用程序中进行可视化搜索。</li></ul></div><div class="ab cl mj mk hx ml" role="separator"><span class="mm bw bk mn mo mp"/><span class="mm bw bk mn mo mp"/><span class="mm bw bk mn mo"/></div><div class="im in io ip iq"><h1 id="5627" class="mq mr it bd ms mt mu mv mw mx my mz na jz nb ka nc kc nd kd ne kf nf kg ng nh bi translated">什么是“图像相似性检测”，为什么它很重要？</h1><p id="7cac" class="pw-post-body-paragraph kz la it lb b lc ni ju le lf nj jx lh li nk lk ll lm nl lo lp lq nm ls lt lu im bi translated">图像相似性检测用于量化图像的视觉和语义相似程度。</p><p id="508f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在现代应用中，重复产品检测、图像聚类、视觉搜索和推荐任务都是使用这种技术来执行的。</p><p id="13ed" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">“搜索的未来将是图片而不是关键词。”——<strong class="lb iu"><em class="nn">本·希伯尔曼，Pinterest CEO </em> </strong></p><p id="be17" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">视觉搜索的一个优点是它完全依赖于商品的外观。不需要条形码、二维码、产品名称或其他产品元数据等其他数据。”——<strong class="lb iu"><em class="nn">布伦特·拉博斯基、</em> </strong> <em class="nn"> </em> <strong class="lb iu"> <em class="nn">亚马逊网络服务</em> </strong></p><p id="071c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">“顾客越来越多地使用社交媒体平台，如 Instagram 和 Pinterest，作为灵感的来源，因此视觉搜索有可能改变我们为家庭购物的方式。” <strong class="lb iu"> <em class="nn"> —马克钢，数字导演，Argos </em> </strong></p></div><div class="ab cl mj mk hx ml" role="separator"><span class="mm bw bk mn mo mp"/><span class="mm bw bk mn mo mp"/><span class="mm bw bk mn mo"/></div><div class="im in io ip iq"><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi no"><img src="../Images/930ce58912556090bd86ddf48ab3400a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*okZPM28dm_oAopdT"/></div></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk">Photo by <a class="ae ky" href="https://unsplash.com/@vidarnm?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Vidar Nordli-Mathisen</a> on <a class="ae ky" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><h1 id="0c29" class="mq mr it bd ms mt np mv mw mx nq mz na jz nr ka nc kc ns kd ne kf nt kg ng nh bi translated">如何使用 Tensorflow 2.0 和 Tensorflow Hub 生成“图像特征向量”</h1><ul class=""><li id="bbbb" class="lv lw it lb b lc ni lf nj li nu lm nv lq nw lu ma mb mc md bi translated"><strong class="lb iu"> Tensorflow 2.0 和 Tensorflow Hub </strong></li></ul><p id="112e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><a class="ae ky" href="https://www.tensorflow.org/" rel="noopener ugc nofollow" target="_blank"> Tensorflow </a>是 Google 开发的用于机器学习的端到端开源平台。它拥有工具、库和社区资源，让开发人员可以轻松构建和部署机器学习应用程序。</p><p id="2092" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><a class="ae ky" href="https://www.tensorflow.org/hub" rel="noopener ugc nofollow" target="_blank"> TensorFlow Hub </a>提供了许多可重用的机器学习模型。它使迁移学习变得非常容易，因为它为不同的问题领域和不同的任务(如图像分类、图像分割、姿态检测、文本嵌入、文本分类、视频生成等)提供了预训练的模型。</p><p id="1699" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">关于迁移学习的更多信息，你可以查看我以前的文章。</p><div class="nx ny gp gr nz oa"><a rel="noopener follow" target="_blank" href="/training-custom-image-classification-model-on-the-browser-with-tensorflow-js-and-angular-f1796ed24934"><div class="ob ab fo"><div class="oc ab od cl cj oe"><h2 class="bd iu gy z fp of fr fs og fu fw is bi translated">浏览器中的机器学习:为自定义图像分类训练和服务 Mobilenet 模型</h2><div class="oh l"><h3 class="bd b gy z fp of fr fs og fu fw dk translated">用 Tensorflow.js 和 Angular 在浏览器上训练基于 Mobilenet 的自定义图像分类模型</h3></div><div class="oi l"><p class="bd b dl z fp of fr fs og fu fw dk translated">towardsdatascience.com</p></div></div><div class="oj l"><div class="ok l ol om on oj oo ks oa"/></div></div></a></div><ul class=""><li id="b46c" class="lv lw it lb b lc ld lf lg li lx lm ly lq lz lu ma mb mc md bi translated"><strong class="lb iu">什么是图像特征向量？</strong></li></ul><p id="f143" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">一个<strong class="lb iu">图像特征向量</strong>是代表整个<strong class="lb iu">图像的数字列表，</strong>通常用于图像相似性计算或图像分类任务。</p><p id="71fd" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">一般来说，低级图像特征是图像的次要细节，例如线、边缘、角或点。高级特征建立在低级特征之上，以检测图像中的对象和较大的形状。</p><p id="6a5c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们可以使用卷积神经网络提取这两种类型的特征:第一对卷积层将学习用于找到低级特征的过滤器，而后面的层将学习识别常见的形状和对象。</p><p id="b6b5" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在我们的例子中，我们将使用存储在<a class="ae ky" href="https://www.tensorflow.org/hub" rel="noopener ugc nofollow" target="_blank"> Tensorflow Hub </a>中的<a class="ae ky" href="https://tfhub.dev/google/imagenet/mobilenet_v2_140_224/feature_vector/4" rel="noopener ugc nofollow" target="_blank"><strong class="lb iu">mobilenet _ v2 _ 140 _ 224</strong></a>预训练的卷积神经网络来提取<strong class="lb iu">产品图像</strong>的高级特征。</p><p id="30b5" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">MobilenetV2 是一个简单的神经网络架构，适用于移动和资源受限的应用程序。点击<a class="ae ky" href="https://arxiv.org/pdf/1801.04381.pdf" rel="noopener ugc nofollow" target="_blank">此链接</a>可获得关于 MobilenetV2 的更多信息。</p></div><div class="ab cl mj mk hx ml" role="separator"><span class="mm bw bk mn mo mp"/><span class="mm bw bk mn mo mp"/><span class="mm bw bk mn mo"/></div><div class="im in io ip iq"><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi op"><img src="../Images/66413bffb8a22becc72810bc5cb62ff2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*LAP-Q2pHOR7ksdoS"/></div></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk">Photo by <a class="ae ky" href="https://unsplash.com/@freshseteyes?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Quaid Lagan</a> on <a class="ae ky" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><p id="8a27" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在开始编码之前，需要在我们的本地计算机上安装 Tensorflow 2.0、Tensorflow Hub 和 Spotify/airy 库。</p><pre class="kj kk kl km gt oq or os ot aw ou bi"><span id="8b9d" class="ov mr it or b gy ow ox l oy oz">$ virtualenv --system-site-packages -p python3 ./TFvenv<br/>$ source ./TFvenv/bin/activate</span><span id="4e1d" class="ov mr it or b gy pa ox l oy oz">$ pip install tensorflow<br/>$ pip install tensorflow-hub<br/>$ pip install annoy</span></pre><h1 id="8141" class="mq mr it bd ms mt np mv mw mx nq mz na jz nr ka nc kc ns kd ne kf nt kg ng nh bi translated">我们来生成图像特征向量:get_image_feature_vectors.py</h1><p id="a1c8" class="pw-post-body-paragraph kz la it lb b lc ni ju le lf nj jx lh li nk lk ll lm nl lo lp lq nm ls lt lu im bi translated">这个脚本的主要目的是通过读取位于本地文件夹中的图像文件来生成图像特征向量。</p><p id="f837" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">它有两个功能:<strong class="lb iu"> load_img() </strong>和<strong class="lb iu">get _ image _ feature _ vectors()</strong>。</p><p id="3b1b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu"> load_img(path) </strong>获取文件名，作为函数的参数。然后加载并预处理图像，以便我们可以在我们的 MobilenetV2 CNN 模型中使用它们。</p><p id="1e99" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">预处理步骤如下:</p><ul class=""><li id="3956" class="lv lw it lb b lc ld lf lg li lx lm ly lq lz lu ma mb mc md bi translated">将图像解码为 W x H x 3 形状张量，数据类型为整数。</li><li id="848b" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated">将图像大小调整为 224 x 224 x 3 形状张量，因为我们使用的 MobilenetV2 模型版本需要特定的图像大小。</li><li id="605a" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated">将张量的数据类型转换为<strong class="lb iu"> float </strong>并添加一个新轴，使张量形状为 1 x 224 x 224 x 3。这正是模型所期望的输入形状。</li></ul><p id="ce8a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">get _ image _ feature _ vectors()</strong>函数是我提取图像特征向量的地方。你可以在下面看到，这个函数的一步一步的定义；</p><ul class=""><li id="0266" class="lv lw it lb b lc ld lf lg li lx lm ly lq lz lu ma mb mc md bi translated">使用 Tensorflow Hub 加载 MobilenetV2 模型</li><li id="a8e1" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated">遍历本地文件夹中的所有图像，并将它们传递给<strong class="lb iu"> load_img(path) </strong>函数</li><li id="c3db" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated">推断图像特征向量</li><li id="7d8b" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated">将每个特征向量保存到单独的文件中以备后用</li></ul><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pb"><img src="../Images/7ef0fc3d23dc948dd2904bdb7166d783.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/1*LjgRRoeRLOvcAXeTo11EUg.gif"/></div></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk">get_image_feature_vectors.py in action</figcaption></figure><pre class="kj kk kl km gt oq or os ot aw ou bi"><span id="438b" class="ov mr it or b gy ow ox l oy oz"><strong class="or iu"># get_image_feature_vectors.py</strong></span><span id="172a" class="ov mr it or b gy pa ox l oy oz"><strong class="or iu">#################################################<br/># Imports and function definitions<br/>#################################################</strong><br/><strong class="or iu"># For running inference on the TF-Hub module with Tensorflow</strong><br/>import tensorflow as tf<br/>import tensorflow_hub as hub</span><span id="05c6" class="ov mr it or b gy pa ox l oy oz"><strong class="or iu"># For saving 'feature vectors' into a txt file</strong><br/>import numpy as np</span><span id="ebe8" class="ov mr it or b gy pa ox l oy oz"><strong class="or iu"># Glob for reading file names in a folder</strong><br/>import glob<br/>import os.path<br/><strong class="or iu">#################################################</strong></span><span id="8270" class="ov mr it or b gy pa ox l oy oz"><strong class="or iu">#################################################<br/># This function:<br/># Loads the JPEG image at the given path<br/># Decodes the JPEG image to a uint8 W X H X 3 tensor<br/># Resizes the image to 224 x 224 x 3 tensor<br/># Returns the pre processed image as 224 x 224 x 3 tensor<br/>#################################################</strong><br/>def load_img(path):</span><span id="f44b" class="ov mr it or b gy pa ox l oy oz"><strong class="or iu"># Reads the image file and returns data type of string</strong><br/> img = tf.io.read_file(path)</span><span id="b127" class="ov mr it or b gy pa ox l oy oz"><strong class="or iu"># Decodes the image to W x H x 3 shape tensor with type of uint8</strong><br/> img = tf.io.decode_jpeg(img, channels=3)</span><span id="ec66" class="ov mr it or b gy pa ox l oy oz"><strong class="or iu"># Resizes the image to 224 x 224 x 3 shape tensor</strong><br/> img = tf.image.resize_with_pad(img, 224, 224)</span><span id="86be" class="ov mr it or b gy pa ox l oy oz"><strong class="or iu"># Converts the data type of uint8 to float32 by adding a new axis<br/> # img becomes 1 x 224 x 224 x 3 tensor with data type of float32<br/> # This is required for the mobilenet model we are using</strong><br/> img = tf.image.convert_image_dtype(img,tf.float32)[tf.newaxis, ...]<br/> <br/> return img</span><span id="61f9" class="ov mr it or b gy pa ox l oy oz"><strong class="or iu">#################################################<br/># This function:<br/># Loads the mobilenet model in TF.HUB<br/># Makes an inference for all images stored in a local folder<br/># Saves each of the feature vectors in a file<br/>#################################################</strong><br/>def get_image_feature_vectors():<br/> <br/> <strong class="or iu"># Definition of module with using tfhub.dev</strong><br/> module_handle = "https://tfhub.dev/google/imagenet/<br/>                  mobilenet_v2_140_224/feature_vector/4"<br/> <strong class="or iu"># Loads the module</strong><br/> module = hub.load(module_handle)</span><span id="de92" class="ov mr it or b gy pa ox l oy oz"><strong class="or iu"># Loops through all images in a local folder</strong><br/> for filename in glob.glob('/Users/erdemisbilen/Angular/<br/>          fashionWebScraping/images_scraped/full/*.jpg'):<br/> <br/>  print(filename)</span><span id="1671" class="ov mr it or b gy pa ox l oy oz"><strong class="or iu"># Loads and pre-process the image</strong><br/>  img = load_img(filename)</span><span id="105c" class="ov mr it or b gy pa ox l oy oz"><strong class="or iu"># Calculate the image feature vector of the img</strong><br/>  features = module(img)</span><span id="83b9" class="ov mr it or b gy pa ox l oy oz"><strong class="or iu"># Remove single-dimensional entries from the 'features' array </strong> <br/>  feature_set = np.squeeze(features)<br/> <br/><strong class="or iu">  # Saves the image feature vectors into a file for later use</strong><br/>  outfile_name = os.path.basename(filename) + ".npz"<br/> <br/>  out_path = os.path.join('/Users/erdemisbilen/Angular/<br/>            fashionWebScraping/images_scraped/feature-vectors/',<br/>            outfile_name)</span><span id="6c1f" class="ov mr it or b gy pa ox l oy oz"><strong class="or iu"># Saves the 'feature_set' to a text file</strong><br/>  np.savetxt(out_path, feature_set, delimiter=',')</span><span id="4dfe" class="ov mr it or b gy pa ox l oy oz">get_image_feature_vectors()</span></pre></div><div class="ab cl mj mk hx ml" role="separator"><span class="mm bw bk mn mo mp"/><span class="mm bw bk mn mo mp"/><span class="mm bw bk mn mo"/></div><div class="im in io ip iq"><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pc"><img src="../Images/33e41a1dd19b521328323fa204581836.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*KhigbTjMnTa4QNQ9"/></div></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk">Photo by <a class="ae ky" href="https://unsplash.com/@vsmilelx?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">浮萍 闪电</a> on <a class="ae ky" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><h1 id="5e90" class="mq mr it bd ms mt np mv mw mx nq mz na jz nr ka nc kc ns kd ne kf nt kg ng nh bi translated">如何使用 Spotify/airy 库计算相似度得分</h1><ul class=""><li id="bc2a" class="lv lw it lb b lc ni lf nj li nu lm nv lq nw lu ma mb mc md bi translated"><strong class="lb iu">什么是 Spotify/骚扰库？</strong></li></ul><p id="2cd4" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><a class="ae ky" href="https://github.com/spotify/annoy" rel="noopener ugc nofollow" target="_blank"><strong class="lb iu"/></a><strong class="lb iu"/>(<strong class="lb iu">A</strong>approximate<strong class="lb iu">N</strong>earest<strong class="lb iu">N</strong>eighbor<strong class="lb iu">O</strong>h<strong class="lb iu">Y</strong>eah)<strong class="lb iu">，</strong>是一个用于近似最近邻实现的开源库。</p><p id="1288" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我将使用它来查找给定集合中与给定特征向量最接近(或最相似)的图像特征向量。</p><blockquote class="pd pe pf"><p id="519f" class="kz la nn lb b lc ld ju le lf lg jx lh pg lj lk ll ph ln lo lp pi lr ls lt lu im bi translated">调优 aroy 只需要两个主要参数:树的数量<code class="fe pj pk pl or b"><em class="it">n_trees</em></code>和搜索过程中要检查的节点数量<code class="fe pj pk pl or b"><em class="it">search_k</em></code>。</p><p id="9a04" class="kz la nn lb b lc ld ju le lf lg jx lh pg lj lk ll ph ln lo lp pi lr ls lt lu im bi translated"><code class="fe pj pk pl or b"><em class="it">n_trees</em></code>在构建期间提供，影响构建时间和索引大小。较大的值会给出更准确的结果，但索引也较大。</p><p id="aeab" class="kz la nn lb b lc ld ju le lf lg jx lh pg lj lk ll ph ln lo lp pi lr ls lt lu im bi translated"><code class="fe pj pk pl or b"><em class="it">search_k</em></code>在运行时提供，影响搜索性能。较大的值会给出更准确的结果，但需要更长的时间返回。</p><p id="d236" class="kz la nn lb b lc ld ju le lf lg jx lh pg lj lk ll ph ln lo lp pi lr ls lt lu im bi translated"><a class="ae ky" href="https://github.com/spotify/annoy" rel="noopener ugc nofollow" target="_blank"> <strong class="lb iu">来自 Spotify/asury</strong></a></p></blockquote></div><div class="ab cl mj mk hx ml" role="separator"><span class="mm bw bk mn mo mp"/><span class="mm bw bk mn mo mp"/><span class="mm bw bk mn mo"/></div><div class="im in io ip iq"><h1 id="0d6b" class="mq mr it bd ms mt mu mv mw mx my mz na jz nb ka nc kc nd kd ne kf nf kg ng nh bi translated">让我们来计算相似度得分:cluster _ image _ feature _ vectors . py</h1><p id="07a6" class="pw-post-body-paragraph kz la it lb b lc ni ju le lf nj jx lh li nk lk ll lm nl lo lp lq nm ls lt lu im bi translated">这个脚本的主要目的是使用我们在前一章刚刚生成的图像特征向量来计算图像相似性得分。</p><p id="c541" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">它有两个功能:<strong class="lb iu"> match_id(文件名)</strong>和<strong class="lb iu"> cluster() </strong>。</p><p id="9c70" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu"> cluster() </strong>函数按照以下流程进行图像相似度计算:</p><ul class=""><li id="4c09" class="lv lw it lb b lc ld lf lg li lx lm ly lq lz lu ma mb mc md bi translated">通过追加存储在本地文件夹中的所有图像特征向量来建立恼人的索引</li><li id="4536" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated">计算最近邻和相似性得分</li><li id="7dbf" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated">将信息保存和存储在 JSON 文件中，以备后用。</li></ul><p id="a00a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu"> match_id(filename) </strong>是一个帮助函数，因为我需要将图像与产品 id 进行匹配，以便在我的 web 应用程序中实现可视化产品搜索。有一个 JSON 文件，其中包含与产品图像名称匹配的所有产品 id 信息。该函数使用 JSON 文件检索给定图像文件名的产品 id 信息。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pm"><img src="../Images/1287a10c80ae0b8bf1e3a32f5922d810.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/1*pl4y82PbTdpgJpDw6dkiag.gif"/></div></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk">cluster_image_feature_vectors.py in action</figcaption></figure><pre class="kj kk kl km gt oq or os ot aw ou bi"><span id="4195" class="ov mr it or b gy ow ox l oy oz"><strong class="or iu"># cluster_image_feature_vectors.py</strong></span><span id="fc8f" class="ov mr it or b gy pa ox l oy oz"><strong class="or iu">#################################################<br/># Imports and function definitions<br/>#################################################<br/># Numpy for loading image feature vectors from file</strong><br/>import numpy as np</span><span id="49b5" class="ov mr it or b gy pa ox l oy oz"><strong class="or iu"># Time for measuring the process time</strong><br/>import time</span><span id="7b06" class="ov mr it or b gy pa ox l oy oz"><strong class="or iu"># Glob for reading file names in a folder</strong><br/>import glob<br/>import os.path</span><span id="3a49" class="ov mr it or b gy pa ox l oy oz"><strong class="or iu"># json for storing data in json file</strong><br/>import json</span><span id="2389" class="ov mr it or b gy pa ox l oy oz"><strong class="or iu"># Annoy and Scipy for similarity calculation</strong><br/>from annoy import AnnoyIndex<br/>from scipy import spatial<br/><strong class="or iu">#################################################</strong></span><span id="c3d0" class="ov mr it or b gy pa ox l oy oz"><strong class="or iu">#################################################<br/># This function reads from 'image_data.json' file<br/># Looks for a specific 'filename' value<br/># Returns the product id when product image names are matched<br/># So it is used to find product id based on the product image name<br/>#################################################</strong><br/>def match_id(filename):<br/> with open('/Users/erdemisbilen/Angular/fashionWebScraping<br/> /jsonFiles/image_data.json') as json_file:</span><span id="7efc" class="ov mr it or b gy pa ox l oy oz">for file in json_file:<br/>   seen = json.loads(file)</span><span id="0f53" class="ov mr it or b gy pa ox l oy oz">for line in seen:<br/>    <br/>     if filename==line['imageName']:<br/>      print(line)<br/>      return line['productId']<br/>      break<br/><strong class="or iu">#################################################</strong></span><span id="2ce5" class="ov mr it or b gy pa ox l oy oz"><strong class="or iu">#################################################<br/># This function:<br/># Reads all image feature vectores stored in /feature-vectors/*.npz<br/># Adds them all in Annoy Index<br/># Builds ANNOY index<br/># Calculates the nearest neighbors and image similarity metrics<br/># Stores image similarity scores with productID in a json file<br/>#################################################<br/></strong>def cluster():<br/> start_time = time.time()<br/> <br/> print("---------------------------------")<br/> print ("Step.1 - ANNOY index generation - Started at %s" <br/> %time.ctime())<br/> print("---------------------------------")</span><span id="22f2" class="ov mr it or b gy pa ox l oy oz"><strong class="or iu"># Defining data structures as empty dict</strong><br/> file_index_to_file_name = {}<br/> file_index_to_file_vector = {}<br/> file_index_to_product_id = {}</span><span id="90e3" class="ov mr it or b gy pa ox l oy oz"><strong class="or iu"># Configuring annoy parameters</strong><br/> dims = 1792<br/> n_nearest_neighbors = 20<br/> trees = 10000</span><span id="fe47" class="ov mr it or b gy pa ox l oy oz"><strong class="or iu"># Reads all file names which stores feature vectors</strong><br/> allfiles = glob.glob('/Users/erdemisbilen/Angular<br/> /fashionWebScraping/images_scraped/feature-vectors/*.npz')<br/> <br/> t = AnnoyIndex(dims, metric='angular')</span><span id="0a8a" class="ov mr it or b gy pa ox l oy oz">for file_index, i in enumerate(allfiles):</span><span id="be38" class="ov mr it or b gy pa ox l oy oz"><strong class="or iu"># Reads feature vectors and assigns them into the file_vector</strong><br/>  file_vector = np.loadtxt(i)</span><span id="390e" class="ov mr it or b gy pa ox l oy oz"><strong class="or iu"># Assigns file_name, feature_vectors and corresponding product_id</strong><br/>  file_name = os.path.basename(i).split('.')[0]<br/>  file_index_to_file_name[file_index] = file_name<br/>  file_index_to_file_vector[file_index] = file_vector<br/>  file_index_to_product_id[file_index] = match_id(file_name)</span><span id="34cb" class="ov mr it or b gy pa ox l oy oz"><strong class="or iu"># Adds image feature vectors into annoy index</strong><br/>  t.add_item(file_index, file_vector)</span><span id="6367" class="ov mr it or b gy pa ox l oy oz">print("---------------------------------")<br/>  print("Annoy index     : %s" %file_index)<br/>  print("Image file name : %s" %file_name)<br/>  print("Product id      : %s" <br/>  %file_index_to_product_id[file_index])<br/>  print("--- %.2f minutes passed ---------" % ((time.time() -<br/>  start_time)/60))</span><span id="cd32" class="ov mr it or b gy pa ox l oy oz"><strong class="or iu"># Builds annoy index</strong><br/> t.build(trees)</span><span id="b89f" class="ov mr it or b gy pa ox l oy oz">print ("Step.1 - ANNOY index generation - Finished")<br/> print ("Step.2 - Similarity score calculation - Started ")</span><span id="55f2" class="ov mr it or b gy pa ox l oy oz">named_nearest_neighbors = []</span><span id="1e74" class="ov mr it or b gy pa ox l oy oz"><strong class="or iu"># Loops through all indexed items</strong><br/> for i in file_index_to_file_name.keys():<br/> <br/><strong class="or iu">  # Assigns master file_name, image feature vectors <br/>  # and product id values</strong><br/>  master_file_name = file_index_to_file_name[i]<br/>  master_vector = file_index_to_file_vector[i]<br/>  master_product_id = file_index_to_product_id[i]</span><span id="7825" class="ov mr it or b gy pa ox l oy oz"><strong class="or iu"># Calculates the nearest neighbors of the master item</strong><br/>  nearest_neighbors = t.get_nns_by_item(i, n_nearest_neighbors)</span><span id="85a9" class="ov mr it or b gy pa ox l oy oz"><strong class="or iu"># Loops through the nearest neighbors of the master item</strong><br/>  for j in nearest_neighbors:<br/>   <br/>   print(j)</span><span id="63a3" class="ov mr it or b gy pa ox l oy oz"><strong class="or iu"># Assigns file_name, image feature vectors and <br/>   # product id values of the similar item<br/>   </strong>neighbor_file_name = file_index_to_file_name[j]<br/>   neighbor_file_vector = file_index_to_file_vector[j]<br/>   neighbor_product_id = file_index_to_product_id[j]</span><span id="8031" class="ov mr it or b gy pa ox l oy oz"><strong class="or iu"># Calculates the similarity score of the similar item</strong><br/>   similarity = 1 - spatial.distance.cosine(master_vector,<br/>   neighbor_file_vector)</span><span id="c9b5" class="ov mr it or b gy pa ox l oy oz">rounded_similarity = int((similarity * 10000)) / 10000.0</span><span id="1490" class="ov mr it or b gy pa ox l oy oz"><strong class="or iu"># Appends master product id with the similarity score<br/>   # and the product id of the similar items<br/>   </strong>named_nearest_neighbors.append({<br/>     'similarity': rounded_similarity,<br/>     'master_pi': master_product_id,<br/>     'similar_pi': neighbor_product_id})</span><span id="1744" class="ov mr it or b gy pa ox l oy oz">print("---------------------------------")<br/> print("Similarity index       : %s" %i)<br/> print("Master Image file name : %s" %file_index_to_file_name[i])<br/> print("Nearest Neighbors.     : %s" %nearest_neighbors)<br/> print("--- %.2f minutes passed ---------" % ((time.time() -<br/> start_time)/60))</span><span id="ac00" class="ov mr it or b gy pa ox l oy oz">print ("Step.2 - Similarity score calculation - Finished ")</span><span id="bc42" class="ov mr it or b gy pa ox l oy oz"><strong class="or iu"># Writes the 'named_nearest_neighbors' to a json file</strong><br/> with open('nearest_neighbors.json', 'w') as out:<br/> json.dump(named_nearest_neighbors, out)</span><span id="5971" class="ov mr it or b gy pa ox l oy oz">print ("Step.3 - Data stored in 'nearest_neighbors.json' file ")<br/> print("--- Prosess completed in %.2f minutes ---------" %<br/> ((time.time() - start_time)/60))</span><span id="6fbc" class="ov mr it or b gy pa ox l oy oz">cluster()</span></pre><p id="f9df" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">如您所见，我将每个产品图片的最高 20 个相似性分数保存在一个 JSON 文件中，并带有匹配的产品 id 信息。这是因为我不知道如何在客户端进行相似性计算来消除所需的工作量。</p><p id="b39d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">有了存储在 JSON 文件中的相似性得分，我可以轻松地填充 Elasticsearch 集群，或者填充数据库，以便在我的价格比较 web 应用程序的浏览器上实现近乎实时的可视化搜索体验。</p><p id="f25f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">为了开发这样的应用程序，web 抓取在开发和维护日常产品数据集方面起着重要的作用。如果你对这个主题感兴趣，可以看看我下面的相关文章。</p><div class="nx ny gp gr nz oa"><a rel="noopener follow" target="_blank" href="/web-scraping-of-10-online-shops-in-30-minutes-with-python-and-scrapy-a7f66e42446d"><div class="ob ab fo"><div class="oc ab od cl cj oe"><h2 class="bd iu gy z fp of fr fs og fu fw is bi translated">使用 Python 和 Scrapy 在 30 分钟内抓取 10 家在线商店的网页</h2><div class="oh l"><h3 class="bd b gy z fp of fr fs og fu fw dk translated">获取启动应用程序项目所需的源数据</h3></div><div class="oi l"><p class="bd b dl z fp of fr fs og fu fw dk translated">towardsdatascience.com</p></div></div><div class="oj l"><div class="pn l ol om on oj oo ks oa"/></div></div></a></div></div><div class="ab cl mj mk hx ml" role="separator"><span class="mm bw bk mn mo mp"/><span class="mm bw bk mn mo mp"/><span class="mm bw bk mn mo"/></div><div class="im in io ip iq"><h1 id="e5ab" class="mq mr it bd ms mt mu mv mw mx my mz na jz nb ka nc kc nd kd ne kf nf kg ng nh bi translated">结论</h1><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi po"><img src="../Images/3a920c876c9c4d3a7783249f7b17f5b9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ZmznTwT6W78Q7rIIMDIqdw.jpeg"/></div></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk">Fashion Search Web Application by Erdem Isbilen — Visual Search Results</figcaption></figure><p id="c32a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">正如你在上面所看到的，MobileNetV2 和 Annoy 在寻找视觉上相似的产品方面做得非常好。</p><p id="4a74" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这种实现方式的一个缺点是它只能在整个图像级别工作。如果图像的背景不同，即使物体相似，它也不会提供好的结果。</p><p id="8ab0" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">该应用程序可以进一步改进，以实现类似于<a class="ae ky" href="https://www.pinterest.co.uk" rel="noopener ugc nofollow" target="_blank"> Pinterest </a>或<a class="ae ky" href="https://www.houzz.co.uk" rel="noopener ugc nofollow" target="_blank"> Houzz </a>上的对象级相似性搜索。</p></div></div>    
</body>
</html>