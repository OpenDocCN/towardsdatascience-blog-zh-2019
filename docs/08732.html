<html>
<head>
<title>Very spatial! AI-based parallax 3D videos from photos.</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">很有空间感！基于人工智能的视差 3D 视频。</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/very-spatial-507aa847179d?source=collection_archive---------14-----------------------#2019-11-23">https://towardsdatascience.com/very-spatial-507aa847179d?source=collection_archive---------14-----------------------#2019-11-23</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="cddb" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">三维本·伯恩斯效应</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/7069006d46e68c5628a1c1280960ad00.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/1*xsW_6ndUlJpqcqkU-ZzWUw.gif"/></div></div></figure><p id="b1a6" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi lq translated"><span class="l lr ma bm di mb"> <img alt="T" class="ks mc md me mf mg fc n ih dh bf" src="../Images/8ebcce6f7ca915ae9b80abcb158c86ad.png" width="66" height="79" loading="lazy" data-original-src="https://miro.medium.com/v2/resize:fit:132/1*DuBXbm9w1qkD_9JMypzsNA.jpeg"/> <span class="l lr ls lt bm lu lv lw lx ly di lz"> T </span> </span>以下是我热爱 AI 开发的几个原因。新<strong class="kw iu">技术途径</strong>、<strong class="kw iu">意想不到的可能性</strong>、<strong class="kw iu">令人惊喜的品质</strong>。并且:<strong class="kw iu">团队工作</strong>。每个模型背后都有人，他们编写、测试、增强、审查模型。</p><blockquote class="mh"><p id="4147" class="mi mj it bd mk ml mm mn mo mp mq lp dk translated">人的因素是人工智能背后最重要的因素。</p></blockquote><p id="28e3" class="pw-post-body-paragraph ku kv it kw b kx mr ju kz la ms jx lc ld mt lf lg lh mu lj lk ll mv ln lo lp im bi translated">在这个<strong class="kw iu"> 3D 本·伯恩斯</strong>模型的情况下也是如此。</p><h1 id="2219" class="mw mx it bd my mz na nb nc nd ne nf ng jz nh ka ni kc nj kd nk kf nl kg nm nn bi translated">本·伯恩斯效应。</h1><p id="78d9" class="pw-post-body-paragraph ku kv it kw b kx no ju kz la np jx lc ld nq lf lg lh nr lj lk ll ns ln lo lp im bi translated"><a class="ae nt" href="https://en.wikipedia.org/wiki/Ken_Burns_effect" rel="noopener ugc nofollow" target="_blank"> <strong class="kw iu">本·伯恩斯效应</strong> </a>得名于电影纪录片导演<strong class="kw iu">本·伯恩斯</strong>，他用变焦和相机移动曝光静态照片来模拟视频镜头。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nu nv l"/></div></figure><p id="dad7" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">后来，这种效果通过<strong class="kw iu">视差效果</strong>得到了增强，静止图像被分成几层，类似于<em class="nw">剧院舞台装饰</em>。来模拟深度。并且虚拟摄像机在第三维中移动。它有各种各样的用途——用于视频游戏(<em class="nw">模仿第三维</em>)，用于网站(<em class="nw">沉浸式体验</em>)，用于电影(<em class="nw">重复使用照片作为动态镜头</em>)。</p><div class="kj kk kl km gt ab cb"><figure class="nx kn ny nz oa ob oc paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><img src="../Images/4ed3c9e2fdbd3e19080ffc899f7acd28.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*iaXo5pwHT9SOmGoSZOM_dw.jpeg"/></div></figure><figure class="nx kn ny nz oa ob oc paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><img src="../Images/081d41be303dd26ebc84755a0fb42f57.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*5tgGmOuHOEnmAM1G9dHA1g.jpeg"/></div><figcaption class="od oe gj gh gi of og bd b be z dk oh di oi oj">Layered scene — from a computer game The Whispered World (<a class="ae nt" href="https://en.wikipedia.org/wiki/Parallax_scrolling" rel="noopener ugc nofollow" target="_blank">source</a>).</figcaption></figure></div><p id="48c2" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">这种方法早在 20 世纪 20-30 年代就已经被德国动画师洛塔·赖尼格采用了。这里你也可以看到这样的分层背景是如何在没有任何 CGI 的情况下实现的:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="ok nv l"/></div></figure><p id="210c" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">对于视频，您可以手动使用 Photoshop+Adobe After effects，或者像“Photomotion”这样的特殊解决方案来制作视差视频。就像我曾经做过的多语言项目一样。</p><p id="7423" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">但是——人工智能提供了新的可能性！</p><p id="a577" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">因此，一个研究团队:西蒙·尼克劳斯(波特兰州立大学)、龙脉(Adobe Research)、杨笈每(Adobe Research)和刘峰(波特兰州立大学)致力于基于深度学习的解决方案:</p><blockquote class="ol om on"><p id="1d75" class="ku kv nw kw b kx ky ju kz la lb jx lc oo le lf lg op li lj lk oq lm ln lo lp im bi translated">3D 本·伯恩斯效应。<br/>论文:《单幅图像的 3D 本·伯恩斯效应》<a class="ae nt" href="https://arxiv.org/abs/1909.05483" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/abs/1909.05483</a></p></blockquote><p id="5b49" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">上下文感知修复和深度估计是关键词。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi or"><img src="../Images/12c46f39caeae3ee9a1bbc876ee0a6e4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*HJjSIRrmMSs312P5AaSD7A.jpeg"/></div></div><figcaption class="od oe gj gh gi of og bd b be z dk">Source: Paper “<a class="ae nt" href="https://arxiv.org/abs/1909.05483" rel="noopener ugc nofollow" target="_blank">3D Ken Burns Effect from a Single Image</a>”</figcaption></figure><p id="acf4" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">该模型可以识别背景，模拟深度，用内容敏感的填充来填充缺失的区域，添加新的角度——简而言之:用一张图像就可以制作一个空间 3D 视频镜头。</p><p id="61cc" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">观看由<a class="ae nt" href="https://twitter.com/karoly_zsolnai" rel="noopener ugc nofollow" target="_blank">撰写的 2 分钟的论文<strong class="kw iu">T3】卡罗利·佐尔奈-费希尔</strong>T5】视频解释这一模式(一如既往地提供大量信息):</a></p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nu nv l"/></div></figure><p id="02fb" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">本周，<strong class="kw iu">西蒙·尼克劳斯</strong>可能会从<strong class="kw iu"> Adobe </strong>获得公开代码的批准(= &gt; <a class="ae nt" href="https://github.com/sniklaus/3d-ken-burns" rel="noopener ugc nofollow" target="_blank"> GitHub </a>)。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="ok nv l"/></div></figure><p id="c3b4" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">从现在开始，每个人都可以尝试这个解决方案，比如人工智能研究员兼艺术家乔纳森·弗莱:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="ok nv l"/></div></figure><p id="7fd0" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">或者博客作者兼技术专家安迪·拜奥:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="ok nv l"/></div></figure><p id="2c9b" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">或者我自己:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="ok nv l"/></div></figure><p id="605f" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">它可以完美地处理街道的透视图像，也可以处理室内。</p><p id="c022" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">Andy Baio 在他的 Waxy.org 博客中发布了一个历史照片平行排列的图库(如果你想的话，也可以是 3d 立体图)。在这篇博文中，他还发布了他的 Colab 笔记本，并配有 3D 本·伯恩斯模型以供试用。电脑工程师<strong class="kw iu">马努·罗梅罗</strong>对笔记本进行了一些改进，包括<strong class="kw iu">多张图片上传</strong>。</p><p id="9096" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">这就是:一个 3D 本·伯恩斯效果的 Colab 笔记本。</p><p id="2518" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">这里是我的一些结果。请注意深度和 3D 尺寸的显著识别。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="ok nv l"/></div></figure><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="ok nv l"/></div></figure><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="ok nv l"/></div></figure><p id="be5f" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">在评论中发布你自己视差照片的结果。</p><h2 id="025f" class="ou mx it bd my ov ow dn nc ox oy dp ng ld oz pa ni lh pb pc nk ll pd pe nm pf bi translated">更新 1(2020 年 1 月 22 日)。</h2><p id="86b3" class="pw-post-body-paragraph ku kv it kw b kx no ju kz la np jx lc ld nq lf lg lh nr lj lk ll ns ln lo lp im bi translated">通过使用<a class="ae nt" rel="noopener" target="_blank" href="/deoldify-gan-based-image-colorization-d9592704a57d?source=friends_link&amp;sk=925195b692f4922b90814ff8cc537e1b"> #DeOldify </a>和 3D 本·伯恩斯效果，我们可以让一条古老的纽约街道重现生机:</p><div class="pg ph gp gr pi pj"><a rel="noopener follow" target="_blank" href="/re-animated-history-6b5eb1a85efa"><div class="pk ab fo"><div class="pl ab pm cl cj pn"><h2 class="bd iu gy z fp po fr fs pp fu fw is bi translated">重现历史</h2><div class="pq l"><h3 class="bd b gy z fp po fr fs pp fu fw dk translated">正在使用的深度学习模型</h3></div><div class="pr l"><p class="bd b dl z fp po fr fs pp fu fw dk translated">towardsdatascience.com</p></div></div><div class="ps l"><div class="pt l pu pv pw ps px ks pj"/></div></div></a></div><h2 id="fe38" class="ou mx it bd my ov ow dn nc ox oy dp ng ld oz pa ni lh pb pc nk ll pd pe nm pf bi translated">更新 2(2020 年 1 月 22 日)</h2><p id="3126" class="pw-post-body-paragraph ku kv it kw b kx no ju kz la np jx lc ld nq lf lg lh nr lj lk ll ns ln lo lp im bi translated">如果对“autozoom.py”中的参数进行微调，可以得到有趣的结果。例如，这些值</p><pre class="kj kk kl km gt py pz qa qb aw qc bi"><span id="538b" class="ou mx it pz b gy qd qe l qf qg">objectTo = process_autozoom({</span><span id="d5ee" class="ou mx it pz b gy qh qe l qf qg">'dblShift': 10.0,</span><span id="3321" class="ou mx it pz b gy qh qe l qf qg">'dblZoom': 10000000000000000000000000000000000000000000000000000000,</span><span id="dce6" class="ou mx it pz b gy qh qe l qf qg">'objectFrom': objectFrom</span><span id="3a92" class="ou mx it pz b gy qh qe l qf qg">})</span><span id="29d6" class="ou mx it pz b gy qh qe l qf qg">numpyResult = process_kenburns({</span><span id="36f1" class="ou mx it pz b gy qh qe l qf qg">'dblSteps': numpy.linspace(0.0, 8.0, 400).tolist(),</span><span id="32d0" class="ou mx it pz b gy qh qe l qf qg">'objectFrom': objectFrom,</span><span id="b39f" class="ou mx it pz b gy qh qe l qf qg">'objectTo': objectTo,</span><span id="a5ac" class="ou mx it pz b gy qh qe l qf qg">'boolInpaint': True</span><span id="2103" class="ou mx it pz b gy qh qe l qf qg">})</span></pre><p id="b239" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">产生更长的摄像机飞行时间:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="ok nv l"/></div></figure><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="ok nv l"/></div></figure><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="ok nv l"/></div></figure><h1 id="d234" class="mw mx it bd my mz na nb nc nd ne nf ng jz nh ka ni kc nj kd nk kf nl kg nm nn bi translated">因为团队合作仍在继续——现在用创造性的方法！</h1></div></div>    
</body>
</html>