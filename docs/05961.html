<html>
<head>
<title>Customer Segmentation</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">客户细分</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/customer-segmentation-5f25247eb7e2?source=collection_archive---------15-----------------------#2019-08-30">https://towardsdatascience.com/customer-segmentation-5f25247eb7e2?source=collection_archive---------15-----------------------#2019-08-30</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><h2 id="d9c3" class="ir is it bd b dl iu iv iw ix iy iz dk ja translated" aria-label="kicker paragraph"><a class="ae ep" href="https://medium.com/towards-data-science/in-depth-analysis/home" rel="noopener">深入分析</a></h2><div class=""/><div class=""><h2 id="d7db" class="pw-subtitle-paragraph jz jc it bd b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq dk translated">R 中的实用介绍</h2></div><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi kr"><img src="../Images/6d6f4a814d658cc5cd664130c26686b4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*KjI5mW28lpfrx6JUp5FJww.png"/></div></div><figcaption class="ld le gj gh gi lf lg bd b be z dk">Source: Image by the author</figcaption></figure><p id="b5ad" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi md translated"><span class="l me mf mg bm mh mi mj mk ml di">顾客是任何企业成功的关键因素。传统智慧告诉我们，留住一个现有客户的成本远远低于获得一个新客户的成本。为了使一个企业有一个可持续的增长，保留它的老客户群和扩大新客户群是非常关键的。这就需要了解与业务相关的客户行为。因此，对于寻求市场竞争优势的企业来说，全方位了解客户至关重要。这方面的一种技术是客户细分，它有助于根据客户与产品的互动来识别相似的客户群，然后针对适当的客户有效地采取不同的营销方案。</span></p><p id="eec1" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">本文提供了一个循序渐进的实践介绍，重点介绍了在 r 中执行客户细分的方法之一。为了更好地了解客户细分的思想，本文不包括关于在数据集上执行的探索性数据分析和数据争论的详细信息。</p><p id="5120" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated"><strong class="lj jd">数据来源:</strong>超市 aggr。客户<br/>所使用的数据集是意大利最大的零售分销公司之一<em class="mm"> Coop </em>针对一个意大利城市的零售市场数据。<br/>超市 aggr。用于分析的客户数据集包含从客户和商店信息聚合的数据，并透视到新列。因此，数据集包含 40 个特征和 60，366 个实例，大小约为 14.0 MB。</p><p id="396a" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated"><strong class="lj jd">研究问题(RQ): </strong>根据客户的购买行为，有哪些不同的客户群？</p><p id="7d68" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated"><strong class="lj jd">选择的算法:</strong> K 均值，主成分分析(PCA)</p><p id="89a3" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated"><strong class="lj jd">算法选择理由:</strong> K-means 聚类是一种非常简单快速的 algorithm⁴.这是用于客户细分的流行方法，尤其是对于数字数据。K-means 还具有计算优势，可以很好地处理大型数据集。分层的和基于模型的聚类方法需要计算全距离矩阵，该矩阵表现出有限的可扩展性和对大数据集计算的大存储器需求。相比之下，K-means 聚类在运行时效率更高。考虑到这些事实，并考虑到输入数据集很大且主要包含数值数据，K-means 是客户细分的理想选择。</p><p id="064a" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">PCA 是一种降维算法，它通过数据分解和转换为主成分(PC)来可视化数据集的本质，最大化数据的线性方差(方差越大表示对 data)⁵.的理解越多与 K-means 相比，PCA 不是一个直接的解决方案，因此从不同的角度来看，它可以帮助检测 K-means 没有发现的客户群。主成分分析在这里用于这个研究问题，作为一个有价值的交叉检查，以 K-均值数的集群确定。</p><p id="9415" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated"><strong class="lj jd">选择的特征:</strong>RQ 希望根据顾客的购买行为识别顾客群，即顾客喜欢购买的商店。因此，特性 customer_id、amount_purchased_shop_1、amount_purchased_shop_2、amount_purchased_shop_3、amount_purchased_shop_4、amount_purchased_shop_5 非常重要，并被选择用于此 RQ。</p><p id="d27a" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated"><strong class="lj jd">分析:</strong></p><p id="91ad" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated"><strong class="lj jd"> 1)估计最佳聚类数</strong></p><p id="a62c" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">K-means 要求在算法开始之前指定聚类数。确定最佳聚类数对于输出更好的结果至关重要。</p><pre class="ks kt ku kv gt mn mo mp mq aw mr bi"><span id="5cb3" class="ms mt it mo b gy mu mv l mw mx"><strong class="mo jd">library</strong>(cluster)<br/><strong class="mo jd">library</strong>(factoextra)<br/><strong class="mo jd">library</strong>("metricsgraphics")</span><span id="901b" class="ms mt it mo b gy my mv l mw mx"><em class="mm"># Read file contents</em><br/>supermarket_data_clean &lt;- read.csv("Input Dataset/Cleaned Dataset/Supermarket_DataCleaned.csv")</span><span id="5171" class="ms mt it mo b gy my mv l mw mx"><em class="mm"># Prepare data frames for clustering</em><br/><em class="mm"># Select only the rows customer_id, amount_purchased_shop_1, 2, 3, 4, 5</em><br/>cluster.slice.temp &lt;- supermarket_data_clean[,c(1,29,30,31,32,33)]<br/><em class="mm"># Remover customer_id from the clustering data frame </em><br/>cluster.slice.data &lt;- supermarket_data_clean[,c(29,30,31,32,33)]</span><span id="c4f0" class="ms mt it mo b gy my mv l mw mx"><em class="mm"># Scale the data and Determine the ideal number of clusters</em><br/>cluster.slice.scale &lt;- scale(cluster.slice.data)</span><span id="309e" class="ms mt it mo b gy my mv l mw mx">wssplot &lt;- <strong class="mo jd">function</strong>(data, nc=15, seed=1234){<br/>  wss &lt;- (nrow(data)-1)*sum(apply(data,2,var))<br/>  <strong class="mo jd">for</strong> (i <strong class="mo jd">in</strong> 2:nc){<br/>    set.seed(seed)<br/>    wss[i] &lt;- sum(kmeans(data, centers=i)$withinss)}<br/>  plot(1:nc, wss, type="b", xlab="Number of Clusters",<br/>       ylab="Within groups sum of squares")}</span><span id="02ba" class="ms mt it mo b gy my mv l mw mx">wssplot(cluster.slice.scale)</span></pre><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi mz"><img src="../Images/84819f86aba27320be98f41383a5d641.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*q6xJI05nAiTQrFReC3Y0Gg.png"/></div></div><figcaption class="ld le gj gh gi lf lg bd b be z dk">Source: Image by the author</figcaption></figure><p id="8c78" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">输出图描绘了群集数量从值 1 到 4 的急剧减少，以及从 4 到 5 的轻微减少，这估计了 4-群集或 5-群集解决方案。</p><p id="67de" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated"><strong class="lj jd"> 2)执行 K 均值聚类，聚类为 4 和 5 </strong></p><pre class="ks kt ku kv gt mn mo mp mq aw mr bi"><span id="3571" class="ms mt it mo b gy mu mv l mw mx"><em class="mm"># Perform k-means on cluster values as 4 and 5</em></span><span id="472e" class="ms mt it mo b gy my mv l mw mx"><em class="mm"># On entire dataset</em><br/>set.seed(123) <em class="mm"># fix the random starting clusters</em><br/>kclust4 &lt;- kmeans(cluster.slice.data, 4, nstart = 25)</span><span id="3df8" class="ms mt it mo b gy my mv l mw mx">set.seed(123) <em class="mm"># fix the random starting clusters</em><br/>kclust5 &lt;- kmeans(cluster.slice.data, 5, nstart = 25)</span></pre><p id="7daa" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated"><strong class="lj jd"> 3)执行主成分分析以可视化聚类</strong></p><pre class="ks kt ku kv gt mn mo mp mq aw mr bi"><span id="987f" class="ms mt it mo b gy mu mv l mw mx">pca &lt;- prcomp(t(cluster.slice.data), scale. = T, center = T)<br/>fviz_eig(pca) + <br/>  theme_bw() + scale_y_continuous(labels = scales::comma) +<br/>  ggtitle(label='Principal Component Analysis')</span></pre><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi na"><img src="../Images/81bcbfae2eb28ad6e929a0551b2b4a74.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*rXCNo6hasm10S6TPyxcnYQ.png"/></div></div><figcaption class="ld le gj gh gi lf lg bd b be z dk">Source: Image by the author</figcaption></figure><p id="1102" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">正如所观察到的，主成分分析 1 和主成分分析 2 共同解释了大部分数据差异，然后从主成分分析 2 下降到主成分分析 3。因此，这推断出用 PCA 1 和 PC 2 的可视化将给出对数据的良好理解，并且在 PCA 2 之后包括更多的 PCA 将仅导致最小的改进。</p><p id="c847" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated"><strong class="lj jd">具有 4 个聚类 K-均值的 PCA</strong></p><pre class="ks kt ku kv gt mn mo mp mq aw mr bi"><span id="f0d6" class="ms mt it mo b gy mu mv l mw mx">cluster.pc4 &lt;- prcomp(cluster.slice.data, center = FALSE, scale. = FALSE)$x %&gt;% as.data.frame()<br/>cluster.pc4$kmeans.cluster &lt;- factor(kclust4$cluster)</span><span id="3473" class="ms mt it mo b gy my mv l mw mx">p&lt;-ggplot(cluster.pc4,aes(x=PC1,y=PC2,color=kmeans.cluster))<br/>p+geom_point() +<br/>  theme_bw() + scale_y_continuous(labels = scales::comma) + <br/>  ggtitle(label='PCA with 4 cluster K-means')</span></pre><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi nb"><img src="../Images/3f7a097f686ce0dbdb9a04950a55b6cb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*eEGCFWqjOodw-ADI_12iqQ.png"/></div></div><figcaption class="ld le gj gh gi lf lg bd b be z dk">Source: Image by the author</figcaption></figure><p id="36ba" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated"><strong class="lj jd">具有 5 个聚类 K 均值的 PCA</strong></p><pre class="ks kt ku kv gt mn mo mp mq aw mr bi"><span id="7e45" class="ms mt it mo b gy mu mv l mw mx">cluster.pc5 &lt;- prcomp(cluster.slice.data, center = FALSE, scale. = FALSE)$x %&gt;% as.data.frame()<br/>cluster.pc5$kmeans.cluster &lt;- factor(kclust5$cluster)</span><span id="f65d" class="ms mt it mo b gy my mv l mw mx">p&lt;-ggplot(cluster.pc5,aes(x=PC1,y=PC2,color=kmeans.cluster))<br/>p+geom_point() +<br/>  theme_bw() + scale_y_continuous(labels = scales::comma) + <br/>  ggtitle(label='PCA with 5 cluster K-means')</span></pre><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi nc"><img src="../Images/0b28675be8d8dd80b5e120e4b62c9da8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*64nOfHn_KxNx9cXxNHtZiA.png"/></div></div><figcaption class="ld le gj gh gi lf lg bd b be z dk">Source: Image by the author</figcaption></figure><p id="bd6c" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">比较以上两个图，确定 5 个聚类的解决方案将是 K-均值聚类的理想估计。</p><p id="2e0d" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated"><strong class="lj jd"> 4)可视化数据中不同的可分离聚类</strong></p><pre class="ks kt ku kv gt mn mo mp mq aw mr bi"><span id="2c5c" class="ms mt it mo b gy mu mv l mw mx">fviz_cluster(kclust5, data = cluster.slice.data, geom = "point",<br/>             stand = FALSE, ellipse.type = "norm") + <br/>  theme_bw() + scale_y_continuous(labels = scales::comma) +<br/>  ggtitle(label='Customer Clusters')</span></pre><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi nd"><img src="../Images/45cf4d85d82da71dea3ff456e488e435.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*99n9KabK1z6_FgcTjyq-ww.png"/></div></div><figcaption class="ld le gj gh gi lf lg bd b be z dk">Source: Image by the author</figcaption></figure><p id="4f9a" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated"><strong class="lj jd"> 5)聚类分析</strong></p><p id="db57" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">确定属于每个集群的不同客户</p><pre class="ks kt ku kv gt mn mo mp mq aw mr bi"><span id="3d46" class="ms mt it mo b gy mu mv l mw mx"><em class="mm">## retrieve customer ID's in each cluster</em><br/>head(gather(data.frame(cluster.slice.temp[kclust5$cluster == 1,])))</span><span id="c2dd" class="ms mt it mo b gy my mv l mw mx"><em class="mm">## retrieve customer ID's in each cluster</em><br/>head(gather(data.frame(cluster.slice.temp[kclust5$cluster == 2,])))<br/>head(gather(data.frame(cluster.slice.temp[kclust5$cluster == 3,])))<br/>head(gather(data.frame(cluster.slice.temp[kclust5$cluster == 4,])))<br/>head(gather(data.frame(cluster.slice.temp[kclust5$cluster == 5,])))</span></pre><p id="cbab" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated"><strong class="lj jd"> 6)客户细分</strong></p><pre class="ks kt ku kv gt mn mo mp mq aw mr bi"><span id="b151" class="ms mt it mo b gy mu mv l mw mx"><em class="mm">#Customer segmentation through aggeration of results by mean</em><br/>cluster.slice.kmeans.aggregate &lt;- aggregate(cluster.slice.data, by = list(kclust5$cluster), mean)</span><span id="18d0" class="ms mt it mo b gy my mv l mw mx">cluster&lt;-c(cluster.slice.kmeans.aggregate$Group.1)<br/>shop1&lt;-c(cluster.slice.kmeans.aggregate$amount_purchased_shop_1)<br/>shop2&lt;-c(cluster.slice.kmeans.aggregate$amount_purchased_shop_2)<br/>shop3&lt;-c(cluster.slice.kmeans.aggregate$amount_purchased_shop_3)<br/>shop4&lt;-c(cluster.slice.kmeans.aggregate$amount_purchased_shop_4)<br/>shop5&lt;-c(cluster.slice.kmeans.aggregate$amount_purchased_shop_5)</span><span id="d592" class="ms mt it mo b gy my mv l mw mx"><em class="mm"># Plot a Bar graph</em><br/>Legends &lt;-c(rep("Customers Shop 1", 5), rep("Customers Shop 2", 5), rep("Customers Shop 3", 5), rep("Customers Shop 4", 5), rep("Customers Shop 5", 5))<br/>values &lt;-c(shop1,shop2,shop3,shop4,shop5)<br/>mydata &lt;-data.frame(cluster, values)</span><span id="b464" class="ms mt it mo b gy my mv l mw mx">p &lt;-ggplot(mydata, aes(cluster, values))<br/>p +geom_bar(stat = "identity", aes(fill = Legends)) +<br/>  xlab("Cluster") + ylab("Total") +<br/>  ggtitle("Customer Segmentation") +<br/>  theme_bw() + scale_y_continuous(labels = scales::comma)</span></pre><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi ne"><img src="../Images/6ddb57d68cf3a903804e4c031c823908.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*S9Oc85QuqLQrO29MV4cACA.png"/></div></div><figcaption class="ld le gj gh gi lf lg bd b be z dk">Source: Image by the author</figcaption></figure><p id="01ed" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated"><strong class="lj jd">观察:</strong>根据顾客的购买行为对数据进行聚类，即从他们购物最多的商店中，发现了 5 个可分离的聚类进行分析。聚类分析有助于根据客户 id 识别每个聚类中的客户。这有助于了解在每个集群中构建客户群的不同客户。此外，客户细分有助于识别每个细分(聚类)中不同商店的客户。这进一步有助于划分集群并赋予其意义。因此，通过基于他们的购买行为识别五个客户群，并通过确定属于五个不同商店的特定客户来进一步划分这些客户群，来回答研究问题。</p><p id="872e" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated"><strong class="lj jd">应用:</strong>集群的检测可以帮助企业为每个集群基础制定具体的策略。聚类还可以用于了解客户的购买行为，方法是跟踪数月的客户，并检测从一个聚类转移到另一个聚类的客户数量。这有助于企业更好地组织战略，以增加不同商店的收入。企业可以进一步利用所获得的客户细分洞察来更好地将他们的营销工作集中在正确的客户上，例如，与特定商店相关的折扣和优惠可以只发送给通常在该特定商店购买的那些客户，而不会打扰其他商店的客户。因此，为正确的交易锁定正确的客户有助于降低营销成本、创造更多收入并提高客户满意度。</p><blockquote class="nf ng nh"><p id="1066" class="lh li mm lj b lk ll kd lm ln lo kg lp ni lr ls lt nj lv lw lx nk lz ma mb mc im bi translated">客户行为分析作为一个重要领域，利用数据分析在特定于客户的业务数据中发现有意义的行为模式。本文分享的见解来自对数据源进行的端到端<a class="ae nl" href="https://sites.google.com/view/customerbehaviouralanalytics/home" rel="noopener ugc nofollow" target="_blank">市场篮子分析</a>中的一种方法，旨在了解消费者的购买决策以及影响这些决策的因素。</p></blockquote></div><div class="ab cl nm nn hx no" role="separator"><span class="np bw bk nq nr ns"/><span class="np bw bk nq nr ns"/><span class="np bw bk nq nr"/></div><div class="im in io ip iq"><h2 id="0665" class="ms mt it bd nt nu nv dn nw nx ny dp nz lq oa ob oc lu od oe of ly og oh oi iz bi translated">参考</h2><p id="a87d" class="pw-post-body-paragraph lh li it lj b lk oj kd lm ln ok kg lp lq ol ls lt lu om lw lx ly on ma mb mc im bi translated">[1]<a class="ae nl" href="https://bigml.com/user/czuriaga/gallery/dataset/5559c2c6200d5a6570000084" rel="noopener ugc nofollow" target="_blank">https://bigml . com/user/czuriaga/gallery/dataset/5559 C2 c 6200 d5a 6570000084</a></p><p id="3843" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">[2] Pennacchioli 博士、Coscia m .博士、Rinzivillo s .博士、Pedreschi 博士和 gian notti f .博士，2013 年 10 月。解释购买数据中的产品范围效应。大数据，2013 年 IEEE 国际会议(第 648–656 页)。IEEE。</p><p id="b798" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated"><a class="ae nl" href="http://www.michelecoscia.com/?page_id=379" rel="noopener ugc nofollow" target="_blank">http://www.michelecoscia.com/?page_id=379</a></p><p id="c915" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">[4]哈迪根、约翰·A 和曼切克·A·王 1979."算法 as 136:一个 K 均值聚类算法."皇家统计学会杂志。【T1 系列 C(应用统计学)】28 (1)。JSTOR:100–108。</p><p id="e61d" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">[5]丁、克里斯和。2004." K-均值聚类通过主成分分析."在<em class="mm">第二十一届机器学习国际会议论文集</em>，29 页。ACM。</p></div></div>    
</body>
</html>