<html>
<head>
<title>Image Classification for E-Commerce — Part I</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">电子商务中的图像分类第一部分</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/product-image-classification-with-deep-learning-part-i-5bc4e8dccf41?source=collection_archive---------11-----------------------#2019-02-07">https://towardsdatascience.com/product-image-classification-with-deep-learning-part-i-5bc4e8dccf41?source=collection_archive---------11-----------------------#2019-02-07</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><figure class="gl gn jo jp jq jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi jn"><img src="../Images/ef6028e97b33a379102e4df32847dd13.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*9mdFRvqCYIxWSuDF.jpg"/></div></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk">This eye-catching image becomes all the more enchanting when you get to know that our brain processes visuals <strong class="bd kc">60,000</strong> times faster than text and retains <strong class="bd kc">80</strong> percent of what we see versus just <strong class="bd kc">20</strong> percent of what we read.</figcaption></figure><h1 id="42f8" class="kd ke iq bd kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la bi translated">当图像成为故事讲述者</h1><p id="76c2" class="pw-post-body-paragraph lb lc iq ld b le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly ij bi translated">图像通常承担着讲述故事和表达强大思想的角色，就像他们说的那样“一张图片胜过千言万语”。图像讲述思想的能力吸引了人类，由于人类大脑的一半直接或间接用于视觉，视觉成为我们理解周围世界的主要感觉。</p><p id="f166" class="pw-post-body-paragraph lb lc iq ld b le ma lg lh li mb lk ll lm mc lo lp lq md ls lt lu me lw lx ly ij bi translated">在本文中，我将解释我们如何使用图像来解决最流行的商业问题之一，即产品分类。</p><h1 id="13e4" class="kd ke iq bd kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la bi translated"><strong class="ak">圣杯</strong></h1><p id="431c" class="pw-post-body-paragraph lb lc iq ld b le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly ij bi translated">像<a class="ae mf" href="https://dir.indiamart.com/" rel="noopener ugc nofollow" target="_blank"> Indiamart </a>这样的大型在线市场有数以千计的宏类别，用于列出各种产品。产品必须被映射到平台上最合适的微观类别下。<em class="lz">【关于</em> <strong class="ld ir"> <em class="lz">宏观范畴</em> </strong> <em class="lz">和</em> <strong class="ld ir"> <em class="lz">微观范畴</em> </strong> <em class="lz">的定义请参考这篇值得称道的</em> <a class="ae mf" href="https://medium.com/@mukeshkumar_561/product-classification-using-machine-learning-part-i-5a1cd0c2caf2" rel="noopener"> <em class="lz">帖子</em> </a> <em class="lz">的一节:“我的问题，我的方式”] </em></p><p id="0b8b" class="pw-post-body-paragraph lb lc iq ld b le ma lg lh li mb lk ll lm mc lo lp lq md ls lt lu me lw lx ly ij bi translated"><strong class="ld ir">这篇文章的目标是建立直觉和理解，如何训练神经网络来使用产品的图像识别产品的微观类别。</strong></p><blockquote class="mg mh mi"><p id="af18" class="lb lc lz ld b le ma lg lh li mb lk ll mj mc lo lp mk md ls lt ml me lw lx ly ij bi translated">例如，在宏观类别<em class="iq">‘皮革安全手套’，</em>中可以有各种<em class="iq"> </em>微观类别，如<em class="iq">工业皮革手套、皮革焊接手套、铬革手套等。</em>我们打算对我们的产品进行分类，使<em class="iq">工业</em> <em class="iq">皮革</em> <em class="iq">安全手套</em>图片<em class="iq"> </em>始终归入<em class="iq">工业</em> <em class="iq">皮革</em> <em class="iq">安全手套</em>微型类别<em class="iq">。</em>同样，一个<em class="iq">工作靴</em>的图像总是预测一个微观类别<em class="iq">安全工作靴</em>，其中其宏观类别是“<em class="iq">安全靴</em>”。</p></blockquote><figure class="mn mo mp mq gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi mm"><img src="../Images/b91b3f4cee4201e39ab16256ed8f07ee.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*IZCv0J0NREgJ6af7oDZv7w.png"/></div></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk">For an Industrial Leather Glove product, ‘Leather Safety Gloves’<em class="mr"> is a </em><strong class="bd kc"><em class="mr">macrocategory</em></strong><em class="mr"> for which the </em><strong class="bd kc"><em class="mr">microcategory </em></strong><em class="mr">is ‘Industrial Leather Gloves’</em></figcaption></figure><figure class="mn mo mp mq gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi ms"><img src="../Images/e6e9cc1aac2307cfa43535b04b58631c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*2ktOqQwirCu3AtNLUWYuLQ.png"/></div></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk">For a Work Boot product, ‘Safety Boots’ <em class="mr">is the </em><strong class="bd kc"><em class="mr">macro category</em></strong><em class="mr"> and the micro category</em><strong class="bd kc"><em class="mr"> </em></strong><em class="mr">here</em><strong class="bd kc"><em class="mr"> </em></strong><em class="mr">is ‘Safety Work Boot’</em></figcaption></figure><p id="14e7" class="pw-post-body-paragraph lb lc iq ld b le ma lg lh li mb lk ll lm mc lo lp lq md ls lt lu me lw lx ly ij bi translated">现在让我们看看图像分类背后使用的概念。如果您想直接跳到实现，请随意跳过'<strong class="ld ir"> <em class="lz">引擎盖下有什么？-</em>-</strong>部分技术基础知识。</p><figure class="mn mo mp mq gt jr gh gi paragraph-image"><div class="gh gi mt"><img src="../Images/98f1004fc606ca375bee45a368adf416.png" data-original-src="https://miro.medium.com/v2/resize:fit:1280/1*vDld7zpfWszhq9lE6oMQtg.gif"/></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk">Predicting the number written inside the image would have become comically trivial to dauntingly difficult for a machine using only its pixel information, without the concept of Machine Learning and Neural Network!</figcaption></figure></div><div class="ab cl mu mv hu mw" role="separator"><span class="mx bw bk my mz na"/><span class="mx bw bk my mz na"/><span class="mx bw bk my mz"/></div><div class="ij ik il im in"><h1 id="f195" class="kd ke iq bd kf kg nb ki kj kk nc km kn ko nd kq kr ks ne ku kv kw nf ky kz la bi translated">引擎盖下是什么？-技术基础</h1><p id="7a50" class="pw-post-body-paragraph lb lc iq ld b le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly ij bi translated">我们将使用<em class="lz">卷积神经网络(CNN) </em>使用<a class="ae mf" href="https://en.wikipedia.org/wiki/Supervised_learning" rel="noopener ugc nofollow" target="_blank">监督学习</a>对产品图像进行分类，并在<em class="lz"> PyTorch( </em>这是一个由脸书开发的人工智能框架)上运行。为此，我们采用了脸书的<strong class="ld ir"> ResNet </strong>模型，该模型根据来自<a class="ae mf" href="http://www.image-net.org/about-overview" rel="noopener ugc nofollow" target="_blank"> ImageNet 数据库</a>的 100 多万张图像进行了预训练。</p><h2 id="6573" class="ng ke iq bd kf nh ni dn kj nj nk dp kn lm nl nm kr lq nn no kv lu np nq kz nr bi translated">什么是预训练模型？</h2><p id="9ed8" class="pw-post-body-paragraph lb lc iq ld b le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly ij bi translated">预先训练的模型先前已经在数据集上训练过，并且包含代表它被训练的数据集的<strong class="ld ir">特征</strong>的权重。学习到的特征通常可以转移到不同的数据中。</p><figure class="mn mo mp mq gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi ns"><img src="../Images/103b69c5f9ec9caa5c523a837e7cc244.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*jNx-vvaQtqU9bIKMQsv6Zg.jpeg"/></div></div></figure><h2 id="5d6b" class="ng ke iq bd kf nh ni dn kj nj nk dp kn lm nl nm kr lq nn no kv lu np nq kz nr bi translated">什么是深度学习？</h2><p id="4609" class="pw-post-body-paragraph lb lc iq ld b le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly ij bi translated">深度学习是机器学习的一个子集，它通常有不止一个隐藏层。深度学习最重要的一点是，它可以在有大量(通常是有标签的)数据的地方取得非常好的结果。</p><blockquote class="nt"><p id="aa13" class="nu nv iq bd nw nx ny nz oa ob oc ly dk translated">在数学中，卷积是对两个函数进行数学运算以产生第三个函数，该函数表示一个函数的形状如何被另一个函数修改。</p></blockquote><p id="4366" class="pw-post-body-paragraph lb lc iq ld b le od lg lh li oe lk ll lm of lo lp lq og ls lt lu oh lw lx ly ij bi translated"><strong class="ld ir">卷积神经网络</strong> <strong class="ld ir"> (CNN </strong>)是受构成动物大脑的<a class="ae mf" href="https://en.wikipedia.org/wiki/Biological_neural_network" rel="noopener ugc nofollow" target="_blank">生物神经网络</a>启发的计算系统。这类系统<strong class="ld ir"> <em class="lz">学习</em> </strong> <em class="lz">(逐步提高自己的能力)</em>通过考虑实例来做任务，一般不需要针对任务的编程。例如，他们可能会学习识别包含猫的图像，分析已被手动标记为“猫”或“没有猫”的示例图像，并使用分析结果来识别其他图像中的猫。<strong class="ld ir">标记</strong>通常采用一组未标记的数据，并用有意义的信息性标记来增加每一段未标记的数据。</p><p id="266d" class="pw-post-body-paragraph lb lc iq ld b le ma lg lh li mb lk ll lm mc lo lp lq md ls lt lu me lw lx ly ij bi translated"><em class="lz">残差学习试图解决更深层次的神经网络训练的复杂性及其随深度的饱和精度的问题</em>。</p><p id="f9d1" class="pw-post-body-paragraph lb lc iq ld b le ma lg lh li mb lk ll lm mc lo lp lq md ls lt lu me lw lx ly ij bi translated"><strong class="ld ir">什么是剩余学习？</strong></p><p id="0928" class="pw-post-body-paragraph lb lc iq ld b le ma lg lh li mb lk ll lm mc lo lp lq md ls lt lu me lw lx ly ij bi translated">在一般的 CNN 中，几个层被堆叠起来，并被训练来完成手头的任务。网络在其层的末端学习几个低/中/高级特征。在残差学习中，我们不是试图学习一些特征，而是试图学习一些残差。</p><blockquote class="nt"><p id="1d20" class="nu nv iq bd nw nx ny nz oa ob oc ly dk translated"><em class="mr">残差可以简单理解为学习到的特征减去该层的输入</em>的减法。</p></blockquote><figure class="oj ok ol om on jr gh gi paragraph-image"><div class="gh gi oi"><img src="../Images/a8896eca7c2d74bb6e08765a0e3e8c6e.png" data-original-src="https://miro.medium.com/v2/resize:fit:752/format:webp/1*JCy4o3c6vs9jgAF35V0LOQ.png"/></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk">Residual Learning: A building block</figcaption></figure><p id="9e67" class="pw-post-body-paragraph lb lc iq ld b le ma lg lh li mb lk ll lm mc lo lp lq md ls lt lu me lw lx ly ij bi translated">ResNet 通过将第 n 层的输入直接连接到某个第(n+x)层来实现这一点。使用<strong class="ld ir"> ReLU </strong> (ReLU 代表<strong class="ld ir">整流线性单元</strong>，是一种激活功能)。</p><figure class="mn mo mp mq gt jr gh gi paragraph-image"><div class="gh gi oo"><img src="../Images/b18146d8cf8d2ea2e7e50c39a75d64ed.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/1*Jg0CamAWkgBJSKk2o8rGPw.gif"/></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk">A ‘Rectified’ Linear Unit substitutes everything dissimilar (negative value) with zero. So by the end, we are left with only a similar looking image.</figcaption></figure><p id="4fd5" class="pw-post-body-paragraph lb lc iq ld b le ma lg lh li mb lk ll lm mc lo lp lq md ls lt lu me lw lx ly ij bi translated">如果您不确定在您的网络中使用什么激活功能，ReLU 通常是一个不错的首选。为什么？请阅读<a class="ae mf" href="https://www.tinymind.com/learn/terms/relu" rel="noopener ugc nofollow" target="_blank">这篇</a>了解更多 ReLU。</p><p id="5df0" class="pw-post-body-paragraph lb lc iq ld b le ma lg lh li mb lk ll lm mc lo lp lq md ls lt lu me lw lx ly ij bi translated">ResNet34 是一个 34 层深度剩余网络。其他型号如 ResNet50、ResNet101 和 ResNet152 也有售。</p></div><div class="ab cl mu mv hu mw" role="separator"><span class="mx bw bk my mz na"/><span class="mx bw bk my mz na"/><span class="mx bw bk my mz"/></div><div class="ij ik il im in"><h1 id="f43b" class="kd ke iq bd kf kg nb ki kj kk nc km kn ko nd kq kr ks ne ku kv kw nf ky kz la bi translated">系统需求</h1><p id="c693" class="pw-post-body-paragraph lb lc iq ld b le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly ij bi translated">从脸书的<a class="ae mf" href="https://github.com/facebook/fb.resnet.torch" rel="noopener ugc nofollow" target="_blank"> Github </a>链接下载或克隆 ResNet 模型。</p><p id="4a3b" class="pw-post-body-paragraph lb lc iq ld b le ma lg lh li mb lk ll lm mc lo lp lq md ls lt lu me lw lx ly ij bi translated">在<a class="ae mf" href="http://www.ubuntu.com/" rel="noopener ugc nofollow" target="_blank"> Ubuntu 14.04+ </a>上安装 Torch ResNet 依赖项:</p><ul class=""><li id="aec4" class="op oq iq ld b le ma li mb lm or lq os lu ot ly ou ov ow ox bi translated">在装有<strong class="ld ir"> CUDA GPU </strong>的机器上安装<a class="ae mf" href="http://torch.ch/docs/getting-started.html" rel="noopener ugc nofollow" target="_blank">焊炬</a>(计算能力为<strong class="ld ir">3.5 或以上</strong>的 NVIDIA GPU)</li><li id="9c2f" class="op oq iq ld b le oy li oz lm pa lq pb lu pc ly ou ov ow ox bi translated">安装<a class="ae mf" href="https://developer.nvidia.com/cudnn" rel="noopener ugc nofollow" target="_blank"> cuDNN v4 或 v5 </a>和焊枪<a class="ae mf" href="https://github.com/soumith/cudnn.torch/tree/R4" rel="noopener ugc nofollow" target="_blank"> cuDNN 固定器</a></li></ul><p id="0b8c" class="pw-post-body-paragraph lb lc iq ld b le ma lg lh li mb lk ll lm mc lo lp lq md ls lt lu me lw lx ly ij bi translated">参见<a class="ae mf" href="https://github.com/facebook/fb.resnet.torch/blob/master/INSTALL.md" rel="noopener ugc nofollow" target="_blank">安装说明</a>获取分步指南。</p><h1 id="d00a" class="kd ke iq bd kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la bi translated">我们开始吧！</h1><p id="f636" class="pw-post-body-paragraph lb lc iq ld b le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly ij bi translated"><strong class="ld ir">先决条件:</strong>假设对 Python &amp; Linux 命令有一个基本的了解，以便继续学习。</p><h2 id="3990" class="ng ke iq bd kf nh ni dn kj nj nk dp kn lm nl nm kr lq nn no kv lu np nq kz nr bi translated"><strong class="ak"> <em class="mr">我们如何为自定义数据集采用 RESNET？</em> </strong></h2><h2 id="f241" class="ng ke iq bd kf nh ni dn kj nj nk dp kn lm nl nm kr lq nn no kv lu np nq kz nr bi translated"><strong class="ak">数据收集- </strong></h2><p id="f416" class="pw-post-body-paragraph lb lc iq ld b le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly ij bi translated">了解数据的第一步可以让你达到前所未有的高度，达到预期的预测结果的准确性。我们确定了自定义标签所需的属性，以便与训练好的模型一起使用，并将<strong class="ld ir">微类别 ID </strong>、<strong class="ld ir">产品 ID、</strong>和<strong class="ld ir">产品图片的 URL </strong>提取为 tsv(制表符分隔值)格式。</p><p id="ab3e" class="pw-post-body-paragraph lb lc iq ld b le ma lg lh li mb lk ll lm mc lo lp lq md ls lt lu me lw lx ly ij bi translated">我们把图片从网址下载到一个文件夹结构里，组织成-</p><p id="d6e3" class="pw-post-body-paragraph lb lc iq ld b le ma lg lh li mb lk ll lm mc lo lp lq md ls lt lu me lw lx ly ij bi translated">标签名称被保存为单独的文件夹名称，每个名称都有其相关的图像。这整个结构被封装到另一个文件夹中，该文件夹应该被命名为'<strong class="ld ir"> train </strong>'。同样，另一个名为“<strong class="ld ir"> val </strong>”的文件夹(即包含产品图像的标签名称文件夹)应保存在与“列车”相同的位置。<em class="lz">【该文件夹组织标准由脸书给出，是其模型工作所必需的】</em></p><p id="aed6" class="pw-post-body-paragraph lb lc iq ld b le ma lg lh li mb lk ll lm mc lo lp lq md ls lt lu me lw lx ly ij bi translated">在我们的场景中，该结构应该类似于:</p><pre class="mn mo mp mq gt pd pe pf pg aw ph bi"><span id="7ad6" class="ng ke iq pe b gy pi pj l pk pl">train/&lt;Micro_category_ID1&gt;/&lt;Product_ID1.jpg&gt;<br/>train/&lt;Micro_category_ID2&gt;/&lt;Product_ID1.jpg&gt;<br/>val/&lt;Micro_category_ID1&gt;/&lt;Product_ID1.jpg&gt;<br/>val/&lt;Micro_category_ID2&gt;/&lt;Product_ID1.jpg&gt;</span></pre><p id="ca49" class="pw-post-body-paragraph lb lc iq ld b le ma lg lh li mb lk ll lm mc lo lp lq md ls lt lu me lw lx ly ij bi translated">为了实现这一点，我们使用了下面的 Linux 命令，该命令应该在终端中的路径“train”处触发:</p><pre class="mn mo mp mq gt pd pe pf pg aw ph bi"><span id="300f" class="ng ke iq pe b gy pi pj l pk pl">while read -r mcat_id product_id url; do if [ ! -d "${mcat_id}" ]; then mkdir -p ${mcat_id}; fi; cd $mcat_id; wget -O $product_id $url; cd ..; done &lt; tsvfilename</span></pre><p id="1a60" class="pw-post-body-paragraph lb lc iq ld b le ma lg lh li mb lk ll lm mc lo lp lq md ls lt lu me lw lx ly ij bi translated">该命令从 tsv 文件中读取微类别 id、产品 id 和图像 URL，并在相应的微类别文件夹路径中迭代地从 URL 中下载图像，将其重命名为产品 ID(以便于以后识别)。</p><p id="576e" class="pw-post-body-paragraph lb lc iq ld b le ma lg lh li mb lk ll lm mc lo lp lq md ls lt lu me lw lx ly ij bi translated">瞧！我们已经准备好了训练数据。等等……什么？不，它仍然不在那里！</p><p id="2fac" class="pw-post-body-paragraph lb lc iq ld b le ma lg lh li mb lk ll lm mc lo lp lq md ls lt lu me lw lx ly ij bi translated">下面是获得想要的结果的最重要的步骤之一。</p><h2 id="def1" class="ng ke iq bd kf nh ni dn kj nj nk dp kn lm nl nm kr lq nn no kv lu np nq kz nr bi translated">数据清理-</h2><p id="a43d" class="pw-post-body-paragraph lb lc iq ld b le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly ij bi translated">我们希望准备一个同质的输入数据集，以避免模型在训练时偏向某些微类别 id 的图像，从而总是预测这些微类别。</p><p id="feb0" class="pw-post-body-paragraph lb lc iq ld b le ma lg lh li mb lk ll lm mc lo lp lq md ls lt lu me lw lx ly ij bi translated">我们设计了一个 shell 脚本，将所有图像转换成。jpeg(无论是名称还是格式，不包括。png，。gif 等。)，删除下载的错误文件，删除重复文件，并将所有图像的尺寸缩小到 224 X 224 px(如果宽度或高度大于 224 px)。</p><figure class="mn mo mp mq gt jr"><div class="bz fp l di"><div class="pm pn l"/></div></figure><p id="0f92" class="pw-post-body-paragraph lb lc iq ld b le ma lg lh li mb lk ll lm mc lo lp lq md ls lt lu me lw lx ly ij bi translated">我们选择图像尺寸大小为 224 X 224 px，因为观察到此设置的<em class="lz">顶部 1 </em>和<em class="lz">顶部 5 </em>误差较小。欲了解更多详情，请查看<a class="ae mf" href="https://datascience.stackexchange.com/questions/16601/reason-for-square-images-for-deep-learning" rel="noopener ugc nofollow" target="_blank">和</a>。</p><blockquote class="mg mh mi"><p id="1dd3" class="lb lc lz ld b le ma lg lh li mb lk ll mj mc lo lp mk md ls lt ml me lw lx ly ij bi translated">在<strong class="ld ir"> top1 </strong> score 中，您检查预测的顶级类别(具有最高概率的类别)是否与目标标签相同。</p><p id="1616" class="lb lc lz ld b le ma lg lh li mb lk ll mj mc lo lp mk md ls lt ml me lw lx ly ij bi translated">在<strong class="ld ir"> top5 </strong>得分的情况下，您检查目标标签是否是您的前 5 个预测之一(具有最高概率的 5 个预测)。</p></blockquote><h2 id="db77" class="ng ke iq bd kf nh ni dn kj nj nk dp kn lm nl nm kr lq nn no kv lu np nq kz nr bi translated">标签加载-</h2><p id="c4df" class="pw-post-body-paragraph lb lc iq ld b le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly ij bi translated">顾名思义，这是一个处理标签上的数据负载的过程，使得每个标签的图像计数达到一个可比较的水平。</p><p id="af58" class="pw-post-body-paragraph lb lc iq ld b le ma lg lh li mb lk ll lm mc lo lp lq md ls lt lu me lw lx ly ij bi translated">为了向模型提供涵盖每天从用户处收到的各种产品图像的数据，我们对现有数据集执行了<strong class="ld ir">图像增强</strong>。</p><figure class="mn mo mp mq gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi po"><img src="../Images/f64b6c566b0b65585fc64fb5d5931d6b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*DZtrIJMlZJux94PGEeLa5w.png"/></div></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk">Here, the input image has been augmented in various forms (by introducing noise and inclination) to increase scarcely available training data set.</figcaption></figure><p id="ac88" class="pw-post-body-paragraph lb lc iq ld b le ma lg lh li mb lk ll lm mc lo lp lq md ls lt lu me lw lx ly ij bi translated">下面的 python 脚本用于镜像每张图像，顺时针、逆时针旋转它们，还为每张图像创建了粒状图像。</p><figure class="mn mo mp mq gt jr"><div class="bz fp l di"><div class="pm pn l"/></div></figure><p id="031a" class="pw-post-body-paragraph lb lc iq ld b le ma lg lh li mb lk ll lm mc lo lp lq md ls lt lu me lw lx ly ij bi translated">我们还必须确保一些微类别 id 最终不会比其他微类别 id 具有更大的权重，从而使模型产生偏差，预测不正确的结果。这可能是这样的情况，一些微类别比另一个有更多的列出的产品(有图片)。</p><blockquote class="mg mh mi"><p id="4ebc" class="lb lc lz ld b le ma lg lh li mb lk ll mj mc lo lp mk md ls lt ml me lw lx ly ij bi translated">例如，在宏观类别“充气家具”中，微观类别“充气沙发”比微观类别“充气沙发”具有更多带有图像的产品。</p></blockquote><figure class="mn mo mp mq gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi pp"><img src="../Images/9e9cf0db5a6841480b99f9eb79296cbd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*6nXO27dZrcPWKGSmJVy9rw.png"/></div></div></figure><p id="6eff" class="pw-post-body-paragraph lb lc iq ld b le ma lg lh li mb lk ll lm mc lo lp lq md ls lt lu me lw lx ly ij bi translated">我们使用了一个 Python 脚本，它将文件夹<strong class="ld ir"> train </strong>的微观类别 ID 文件夹中的图像相乘。目前，我们已将倍增系数定为 98 个百分点(即所有单个文件夹的图像计数中的一个图像计数，其中涵盖了总计数的 98%的图像)。</p><figure class="mn mo mp mq gt jr"><div class="bz fp l di"><div class="pm pn l"/></div></figure></div><div class="ab cl mu mv hu mw" role="separator"><span class="mx bw bk my mz na"/><span class="mx bw bk my mz na"/><span class="mx bw bk my mz"/></div><div class="ij ik il im in"><p id="b667" class="pw-post-body-paragraph lb lc iq ld b le ma lg lh li mb lk ll lm mc lo lp lq md ls lt lu me lw lx ly ij bi translated">终于可以去训练了！</p><h1 id="5026" class="kd ke iq bd kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la bi translated">训练模型-</h1><p id="812f" class="pw-post-body-paragraph lb lc iq ld b le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly ij bi translated">使用从 Github 下载的文件夹下的<strong class="ld ir"> <em class="lz"> main.lua </em> </strong>文件，即 fb.resnet.torch，用我们自己的数据集训练模型的各层。</p><pre class="mn mo mp mq gt pd pe pf pg aw ph bi"><span id="b799" class="ng ke iq pe b gy pi pj l pk pl">th ~/fb.resnet.torch/main.lua -nClasses 122 -nEpochs 100 -data ~/imageclassification/train/ -save ~/Desktop/imageclassification_c122e100b30t4g1 -batchSize 30 -nThreads 4 -nGPU 1</span></pre><ul class=""><li id="d961" class="op oq iq ld b le ma li mb lm or lq os lu ot ly ou ov ow ox bi translated"><strong class="ld ir"> -nClasses </strong>是我们的标签数量(即微类别 id)</li><li id="3bb3" class="op oq iq ld b le oy li oz lm pa lq pb lu pc ly ou ov ow ox bi translated"><strong class="ld ir">-数据</strong>是列车文件夹的路径</li><li id="6ee6" class="op oq iq ld b le oy li oz lm pa lq pb lu pc ly ou ov ow ox bi translated"><strong class="ld ir"> -save </strong>是保存所有模型(即. t7 文件)的文件夹路径(在指定的新文件夹(即~ ~/Desktop/image classification _ c 122 e 100 b 10t 4g 1)中的每个时期结束时会生成一个模型，其中每个模型都在其之前的模型数据之上进行训练。)</li><li id="2a12" class="op oq iq ld b le oy li oz lm pa lq pb lu pc ly ou ov ow ox bi translated"><strong class="ld ir"> -batchSize </strong>是每个历元中用于训练的图像数量</li><li id="b119" class="op oq iq ld b le oy li oz lm pa lq pb lu pc ly ou ov ow ox bi translated">- <strong class="ld ir"> nEpochs </strong>是我们希望我们的模型运行的迭代次数(我们还在每个时期的末尾获得 top1 和 top5 误差，用于最佳模型的分析)</li><li id="a839" class="op oq iq ld b le oy li oz lm pa lq pb lu pc ly ou ov ow ox bi translated"><strong class="ld ir"> -nThreads </strong>是 GPU 使用的线程数</li><li id="4dac" class="op oq iq ld b le oy li oz lm pa lq pb lu pc ly ou ov ow ox bi translated">- <strong class="ld ir"> nGPU </strong>是我们将用于培训的 GPU 数量</li></ul><p id="be81" class="pw-post-body-paragraph lb lc iq ld b le ma lg lh li mb lk ll lm mc lo lp lq md ls lt lu me lw lx ly ij bi translated">另一个参数是<strong class="ld ir">-深度</strong>(此处未使用)，因此，默认情况下，<em class="lz">我们有一个 ResNet-34 模型</em>。如果它是 50，我们将有一个 ResNet-50 模型。</p><p id="1341" class="pw-post-body-paragraph lb lc iq ld b le ma lg lh li mb lk ll lm mc lo lp lq md ls lt lu me lw lx ly ij bi translated">根据您的便利和资源可用性，在培训时可以使用各种其他参数。可以通过以下方式探索它们:</p><pre class="mn mo mp mq gt pd pe pf pg aw ph bi"><span id="d1a0" class="ng ke iq pe b gy pi pj l pk pl">th main.lua --help</span></pre><p id="49dc" class="pw-post-body-paragraph lb lc iq ld b le ma lg lh li mb lk ll lm mc lo lp lq md ls lt lu me lw lx ly ij bi translated">好的！让我们发出命令！</p><p id="16c8" class="pw-post-body-paragraph lb lc iq ld b le ma lg lh li mb lk ll lm mc lo lp lq md ls lt lu me lw lx ly ij bi translated"><strong class="ld ir">搞定！</strong></p><p id="e4c0" class="pw-post-body-paragraph lb lc iq ld b le ma lg lh li mb lk ll lm mc lo lp lq md ls lt lu me lw lx ly ij bi translated">根据您的训练数据集大小和系统速度，您应该有<strong class="ld ir">耐心</strong>并为您的学生提供<strong class="ld ir">充足的</strong> <strong class="ld ir">时间</strong>来学好:)</p><figure class="mn mo mp mq gt jr gh gi paragraph-image"><div class="gh gi oo"><img src="../Images/79a2209f246889345e42086dd0a57e1e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/1*awgfGEeoSVOZUP3-fOffMw.gif"/></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk">Training…Training……Training!!!</figcaption></figure><p id="c503" class="pw-post-body-paragraph lb lc iq ld b le ma lg lh li mb lk ll lm mc lo lp lq md ls lt lu me lw lx ly ij bi translated"><strong class="ld ir"> main.lua </strong>自动在-save 文件夹中并行生成两个额外的模型，即<strong class="ld ir"> model_best.t7 </strong>和<strong class="ld ir"> latest.t7 </strong>。</p><blockquote class="nt"><p id="56d9" class="nu nv iq bd nw nx ny nz oa ob oc ly dk translated">model_best.t7 是在具有最少 top1 和 top5 错误的纪元上创建的模型的副本。</p><p id="9dcc" class="nu nv iq bd nw nx ny nz oa ob oc ly dk translated">latest.t7 是完全训练的模型，即由最后一个时期创建的模型。</p></blockquote><p id="b29e" class="pw-post-body-paragraph lb lc iq ld b le od lg lh li oe lk ll lm of lo lp lq og ls lt lu oh lw lx ly ij bi translated">这两种模式并不总是相同的。在我们的例子中，观察到最好的模型是在纪元 99 生成的，但是最新的模型是来自纪元 100 的模型。所以，<strong class="ld ir">我们使用了 model_best.t7 进行测试。</strong></p></div><div class="ab cl mu mv hu mw" role="separator"><span class="mx bw bk my mz na"/><span class="mx bw bk my mz na"/><span class="mx bw bk my mz"/></div><div class="ij ik il im in"><h1 id="f1e1" class="kd ke iq bd kf kg nb ki kj kk nc km kn ko nd kq kr ks ne ku kv kw nf ky kz la bi translated">测试模型-</h1><p id="1554" class="pw-post-body-paragraph lb lc iq ld b le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly ij bi translated"><strong class="ld ir"> classify.lua </strong>(在 fb.resnet.torch/pretrained/文件夹中)用于从 model_best.t7 获取所有测试图像的前 5 个预测。</p><p id="41ac" class="pw-post-body-paragraph lb lc iq ld b le ma lg lh li mb lk ll lm mc lo lp lq md ls lt lu me lw lx ly ij bi translated">这里需要注意的重要一点是，<em class="lz"> classify.lua 从 imagenet.lua </em>(在同一个文件夹中，即“pretrained”)中导出预测标签。</p><figure class="mn mo mp mq gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi pq"><img src="../Images/2b1cff514dbc27e7138b2afa61296a88.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*P7ZmGIMNVY5EiysOPHIw-A.png"/></div></div></figure><p id="d84a" class="pw-post-body-paragraph lb lc iq ld b le ma lg lh li mb lk ll lm mc lo lp lq md ls lt lu me lw lx ly ij bi translated">所以，我们替换 imagenet.lua 中的旧标签(鸟类、动物等的名称。来自 ImageNet 数据库)与我们自己的标签值，即微类别 id。</p><figure class="mn mo mp mq gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi pr"><img src="../Images/74aad51ec8806e4d5985c38cc8e975e7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*pyyiRNlt8gbHOQH3GoijCw.png"/></div></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk">The left image shows the original labels in the <strong class="bd kc">imagenet.lua</strong> file. The micro category ID’s which are used as our labels are being substituted in the same file as shown in the right picture.</figcaption></figure><p id="97db" class="pw-post-body-paragraph lb lc iq ld b le ma lg lh li mb lk ll lm mc lo lp lq md ls lt lu me lw lx ly ij bi translated">现在，让我们测试我们的最佳模型！</p><p id="5839" class="pw-post-body-paragraph lb lc iq ld b le ma lg lh li mb lk ll lm mc lo lp lq md ls lt lu me lw lx ly ij bi translated">我们从“train”中挑选了一些标签，并将其复制到“val”中，以测试我们训练的模型在相同数据上的准确性。</p><p id="254f" class="pw-post-body-paragraph lb lc iq ld b le ma lg lh li mb lk ll lm mc lo lp lq md ls lt lu me lw lx ly ij bi translated">下面的测试命令输出“val”中每个图像的前 5 个预测结果及其预测概率:</p><pre class="mn mo mp mq gt pd pe pf pg aw ph bi"><span id="4c2b" class="ng ke iq pe b gy pi pj l pk pl">for f in ~/imageclassification/val/* ;do ( [ -d $f ] &amp;&amp; cd "$f" &amp;&amp; echo Entering into $f &amp;&amp; th ~/fb.resnet.torch/pretrained/classify_new.lua ~/Desktop/imageclassification_c122e100b30t4g1/model_best.t7 $f/*  &gt;&gt; ~/Desktop/imageclassification_c122e100b30t4g1.txt); done</span></pre></div><div class="ab cl mu mv hu mw" role="separator"><span class="mx bw bk my mz na"/><span class="mx bw bk my mz na"/><span class="mx bw bk my mz"/></div><div class="ij ik il im in"><h1 id="f371" class="kd ke iq bd kf kg nb ki kj kk nc km kn ko nd kq kr ks ne ku kv kw nf ky kz la bi translated">余波</h1><p id="db8a" class="pw-post-body-paragraph lb lc iq ld b le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly ij bi translated">通过将创建的文本文件转换成 excel 文件进行分析。</p><figure class="mn mo mp mq gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi ps"><img src="../Images/4c60edd3b166807bf85c5b061e19d6eb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*OJWZi9DzZsU3YomsKOh-2Q.png"/></div></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk">The testing file created by running <strong class="bd kc">classify.lua</strong></figcaption></figure><p id="e693" class="pw-post-body-paragraph lb lc iq ld b le ma lg lh li mb lk ll lm mc lo lp lq md ls lt lu me lw lx ly ij bi translated">excel 文件将上述预测分成列(使用 R 脚本)用于<strong class="ld ir">原始微类别 ID </strong>和<strong class="ld ir">产品 ID </strong>(来自图像的本地路径)以及<strong class="ld ir">预测微类别 1、预测微类别 1 的概率</strong>。</p><p id="bf3f" class="pw-post-body-paragraph lb lc iq ld b le ma lg lh li mb lk ll lm mc lo lp lq md ls lt lu me lw lx ly ij bi translated">通过对预测的和原始的微类别进行匹配检查，我们观察到在 99.28% 的情况下预测为真。<em class="lz">这些是训练模型的案例。</em></p><p id="f547" class="pw-post-body-paragraph lb lc iq ld b le ma lg lh li mb lk ll lm mc lo lp lq md ls lt lu me lw lx ly ij bi translated">后来，我们为添加的 70 个<strong class="ld ir">新产品</strong>重复了测试活动(因此，被训练的模型没有更早地学习它们)。</p><p id="0f3f" class="pw-post-body-paragraph lb lc iq ld b le ma lg lh li mb lk ll lm mc lo lp lq md ls lt lu me lw lx ly ij bi translated">在这种情况下，<em class="lz">高于覆盖 80%数据的 50%模型置信度(概率)阈值，</em>我们观察到精度为<strong class="ld ir"> 95.38%。</strong></p><p id="b572" class="pw-post-body-paragraph lb lc iq ld b le ma lg lh li mb lk ll lm mc lo lp lq md ls lt lu me lw lx ly ij bi translated">该模型的精度观察为<strong class="ld ir"> 1.00 </strong>，灵敏度/召回率观察为<strong class="ld ir"> 0.95 </strong>。该结果的混淆矩阵如下所示:</p><figure class="mn mo mp mq gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi pt"><img src="../Images/41f24c00e3f293e6e9e9b143207dad6d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*DcqbClAF15lkaQXhVvLwzA.png"/></div></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk">The matrix shows results for 65/70 cases excluding 5 cases where the user uploaded product image was not clear or was irrelevant for this macro category.</figcaption></figure><h1 id="4d51" class="kd ke iq bd kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la bi translated"><strong class="ak">接下来会发生什么… </strong></h1><ul class=""><li id="ad29" class="op oq iq ld b le lf li lj lm pu lq pv lu pw ly ou ov ow ox bi translated">我们也正在分析<em class="lz">宏类别</em>级别的预测准确性。</li><li id="9af8" class="op oq iq ld b le oy li oz lm pa lq pb lu pc ly ou ov ow ox bi translated">我们打算利用特征提取在不同的微观类别中找到相似的图像。为此，fb.resnet.torch/pretained 文件夹中提供了一个有用的脚本，即<em class="lz"> exract-features.lua </em>。</li><li id="944e" class="op oq iq ld b le oy li oz lm pa lq pb lu pc ly ou ov ow ox bi translated">我们希望利用图像分类来识别平台上被禁止的<em class="lz">内容。</em></li></ul><p id="d26d" class="pw-post-body-paragraph lb lc iq ld b le ma lg lh li mb lk ll lm mc lo lp lq md ls lt lu me lw lx ly ij bi translated">本系列的后续文章将会重点介绍上述目标的实现。</p><p id="9a92" class="pw-post-body-paragraph lb lc iq ld b le ma lg lh li mb lk ll lm mc lo lp lq md ls lt lu me lw lx ly ij bi translated">我希望这篇文章能帮助您扩展关于使用 Resnet 进行定制业务案例的知识，如果您有任何问题或意见，我很乐意听取您的意见。你可以打<em class="lz">jain.prachi@indiamart.com</em>找到我</p><p id="7232" class="pw-post-body-paragraph lb lc iq ld b le ma lg lh li mb lk ll lm mc lo lp lq md ls lt lu me lw lx ly ij bi translated"><em class="lz">感谢</em> <a class="px py ep" href="https://medium.com/u/47a096395dd5?source=post_page-----5bc4e8dccf41--------------------------------" rel="noopener" target="_blank"> <em class="lz">维克拉姆</em></a><em class="lz"/><a class="px py ep" href="https://medium.com/u/f3499cb43377?source=post_page-----5bc4e8dccf41--------------------------------" rel="noopener" target="_blank"><em class="lz">阿尤什【古普塔】</em></a><em class="lz"/><a class="px py ep" href="https://medium.com/u/17b024118255?source=post_page-----5bc4e8dccf41--------------------------------" rel="noopener" target="_blank"><em class="lz">阿苏托什</em></a><em class="lz"/><a class="px py ep" href="https://medium.com/u/1b7897ab0b1c?source=post_page-----5bc4e8dccf41--------------------------------" rel="noopener" target="_blank"><em class="lz">穆凯什</em> </a> <em class="lz">的大力支持。</em></p></div></div>    
</body>
</html>