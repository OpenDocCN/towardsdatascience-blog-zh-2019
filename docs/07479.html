<html>
<head>
<title>Deep Learning on Dataframes with PyTorch</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">PyTorch 在数据帧上的深度学习</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/deep-learning-on-dataframes-with-pytorch-66b21be54ef6?source=collection_archive---------9-----------------------#2019-10-19">https://towardsdatascience.com/deep-learning-on-dataframes-with-pytorch-66b21be54ef6?source=collection_archive---------9-----------------------#2019-10-19</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><p id="46a5" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">这篇文章的目标是提出一个框架，可以让你使用 PyTorch 和 Pandas 在任何数据框架上进行深度学习预测。通过<em class="ko">任何</em>数据帧，我的意思是:分类特征、连续特征、日期时间特征、回归、二进制分类或多分类的任何组合。</p><p id="0411" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">我可能会涉及到幕后发生的一些技术问题，但大多数情况下，这只是一个框架讨论，而不是技术讨论。如果你想进一步挖掘，我建议在深度学习中开设 fast.ai 课程——如果你只是想在不看引擎盖的情况下进行预测，fast.ai 库是一个很好的地方，可以用很少的开发时间快速有效地运行这些模型。</p><pre class="kp kq kr ks gt kt ku kv kw aw kx bi"><span id="d079" class="ky kz it ku b gy la lb l lc ld"><strong class="ku iu">import</strong> pandas <strong class="ku iu">as</strong> pd<br/><strong class="ku iu">import</strong> numpy <strong class="ku iu">as</strong> np<br/><strong class="ku iu">import</strong> re<br/><strong class="ku iu">from</strong> pandas.api.types <strong class="ku iu">import</strong> is_string_dtype, is_numeric_dtype<br/><strong class="ku iu">import</strong> warnings<br/><strong class="ku iu">from</strong> pdb <strong class="ku iu">import</strong> set_trace</span><span id="e5fb" class="ky kz it ku b gy le lb l lc ld"><strong class="ku iu">from</strong> torch <strong class="ku iu">import</strong> nn, optim, as_tensor<br/><strong class="ku iu">from</strong> torch.utils.data <strong class="ku iu">import</strong> Dataset, DataLoader<br/><strong class="ku iu">import</strong> torch.nn.functional <strong class="ku iu">as</strong> F<br/><strong class="ku iu">from</strong> torch.nn.init <strong class="ku iu">import</strong> *</span><span id="bfd0" class="ky kz it ku b gy le lb l lc ld"><strong class="ku iu">import</strong> sklearn<br/><strong class="ku iu">from</strong> sklearn_pandas <strong class="ku iu">import</strong> DataFrameMapper<br/><strong class="ku iu">from</strong> sklearn.preprocessing <strong class="ku iu">import</strong> LabelEncoder, Imputer, StandardScaler</span></pre><p id="e938" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">我们将只使用一个虚构的数据帧，它具有分类特征、连续特征和一个日期时间特征。</p><pre class="kp kq kr ks gt kt ku kv kw aw kx bi"><span id="4ab5" class="ky kz it ku b gy la lb l lc ld">rng = pd.date_range('2015-02-24', periods=500, freq='D')<br/>df = pd.DataFrame({'date': rng, <br/>                   'cont1' : np.random.randn(<strong class="ku iu">len</strong>(rng)), <br/>                   'cat1': [np.random.choice([<br/>                            'cat','dog','mouse','cow']) <br/>                               <strong class="ku iu">for</strong> _ <strong class="ku iu">in</strong> <strong class="ku iu">range</strong>(<strong class="ku iu">len</strong>(rng))], <br/>                   'cont2' : 0.5 * np.random.randn(<strong class="ku iu">len</strong>(rng))+5, <br/>                   'cat2': [np.random.choice([<br/>                            'laundry','trash','mop','sweep']) <br/>                               <strong class="ku iu">for</strong> _ <strong class="ku iu">in</strong> <strong class="ku iu">range</strong>(<strong class="ku iu">len</strong>(rng))], <br/>                   'targ' : np.random.randint(low=1, high=10,<br/>                                              size=<strong class="ku iu">len</strong>(rng))})</span></pre><figure class="kp kq kr ks gt lg gh gi paragraph-image"><div role="button" tabindex="0" class="lh li di lj bf lk"><div class="gh gi lf"><img src="../Images/6efd733d94e1ce5291717c303cff7e18.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*yI6M9wyoUxTzoThCjOOrgA.png"/></div></div><figcaption class="ln lo gj gh gi lp lq bd b be z dk">Sample dataframe</figcaption></figure><p id="6279" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">我只是假设我们想要使用所有的数据进行训练，然后预测数据集的最后一天，并检查我们做得如何。对于您的情况，这可能是预测上一周、上一月、上一年的数据，但这里我们将只使用最后一天的数据。</p><pre class="kp kq kr ks gt kt ku kv kw aw kx bi"><span id="f825" class="ky kz it ku b gy la lb l lc ld">max_date = max(df.date).strftime(format='%Y-%m-%d')<br/>test_human_readable = df.loc[df.date ==<br/>                       pd.to_datetime(max_date, <br/>                       format='%Y-%m-%d'),:].copy()</span></pre><p id="4c27" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">我将数据帧(只有一行数据)称为<code class="fe lr ls lt ku b">test_human_readable</code>，因为我们将对数据集进行一些转换，这将使人眼几乎无法理解，所以我喜欢现在提取我的测试集，稍后当我预测时，我会将预测附加到该数据帧，我实际上可以看到所有的特征，因为它们是从开始+预测和实际的。</p><p id="ae69" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">现在我们将为数据的预处理建立一些帮助函数。</p><pre class="kp kq kr ks gt kt ku kv kw aw kx bi"><span id="792d" class="ky kz it ku b gy la lb l lc ld"><strong class="ku iu">def</strong> add_datepart(df, fldname, drop=<strong class="ku iu">True</strong>, time=<strong class="ku iu">False</strong>, errors="raise"):<br/>    "Create many new columns based on datetime column."<br/>    fld = df[fldname]<br/>    fld_dtype = fld.dtype<br/>    <strong class="ku iu">if</strong> isinstance(fld_dtype, pd.core.dtypes.dtypes.DatetimeTZDtype):<br/>        fld_dtype = np.datetime64<br/>    <strong class="ku iu">if</strong> <strong class="ku iu">not</strong> np.issubdtype(fld_dtype, np.datetime64):<br/>        df[fldname] = fld = pd.to_datetime(fld,<br/>                      infer_datetime_format=<strong class="ku iu">True</strong>, errors=errors)<br/>    targ_pre = re.sub('[Dd]ate$', '', fldname)<br/>    attr = ['Year', 'Month', 'Week', 'Day', 'Dayofweek','Dayofyear',<br/>            'Is_month_end', 'Is_month_start', 'Is_quarter_end',<br/>            'Is_quarter_start', 'Is_year_end', 'Is_year_start']<br/>    <strong class="ku iu">if</strong> time: attr = attr + ['Hour', 'Minute', 'Second']<br/>    <strong class="ku iu">for</strong> n <strong class="ku iu">in</strong> attr: df[targ_pre + n] = getattr(fld.dt, n.lower())<br/>    df[targ_pre + 'Elapsed'] = fld.astype(np.int64) // 10 ** 9<br/>    <strong class="ku iu">if</strong> drop: df.drop(fldname, axis=1, inplace=<strong class="ku iu">True</strong>)</span><span id="db42" class="ky kz it ku b gy le lb l lc ld"><strong class="ku iu">def</strong> train_cats(df, cat_vars):<br/>    # numercalize/categoricalize<br/>    <strong class="ku iu">for</strong> name, col <strong class="ku iu">in</strong> df.items(): <br/>        <strong class="ku iu">if</strong> name <strong class="ku iu">in</strong> cat_vars:<br/>            df[name] = col.cat.codes + 1<br/>    df = pd.get_dummies(df, dummy_na=<strong class="ku iu">True</strong>)<br/>    <strong class="ku iu">return</strong> df</span><span id="3558" class="ky kz it ku b gy le lb l lc ld"><strong class="ku iu">def</strong> scale_vars(df, mapper):<br/>    warnings.filterwarnings('ignore',<br/>             category=sklearn.exceptions.DataConversionWarning)<br/>    <strong class="ku iu">if</strong> mapper <strong class="ku iu">is</strong> <strong class="ku iu">None</strong>:<br/>        map_f = [([n],StandardScaler()) <strong class="ku iu">for</strong> n <strong class="ku iu">in</strong> df.columns <strong class="ku iu">if<br/>                 </strong>is_numeric_dtype(df[n])]<br/>        mapper = DataFrameMapper(map_f).fit(df)<br/>    df[mapper.transformed_names_] = mapper.transform(df)<br/>    <strong class="ku iu">return</strong> mapper</span><span id="e5df" class="ky kz it ku b gy le lb l lc ld"><strong class="ku iu">def</strong> proc_df(df, cat_vars, cont_vars, y_fld=<strong class="ku iu">None</strong>, do_scale=<strong class="ku iu">False</strong>,<br/>           mapper=<strong class="ku iu">None</strong>, na_dict=<strong class="ku iu">None</strong>):<br/>    "Preprorocess the train, valid, test sets to numericalize,<br/>     fillmissing, and normalize."<br/>    ignore_flds=[]<br/>    skip_flds=[]<br/>    # set the dependent variable name and concatenate the cat and<br/>    # cont<br/>    dep_var = y_fld<br/>    df = df[cat_vars + cont_vars + [dep_var]].copy()<br/>    df[dep_var] = df[dep_var].astype(int)<br/>    df = df.copy()<br/>    ignored_flds = df.loc[:, ignore_flds]<br/>    y = df[y_fld].values<br/>    # deal with skip fields<br/>    skip_flds += [y_fld]<br/>    df.drop(skip_flds, axis=1, inplace=<strong class="ku iu">True</strong>)<br/>    # initialize the na dictionary<br/>    <strong class="ku iu">if</strong> na_dict <strong class="ku iu">is</strong> <strong class="ku iu">None</strong>: na_dict = {}<br/>    <strong class="ku iu">else</strong>: na_dict = na_dict.copy()<br/>    na_dict_initial = na_dict.copy()<br/>    # fill missing<br/>    <strong class="ku iu">for</strong> name, col <strong class="ku iu">in</strong> df.items(): <br/>        <strong class="ku iu">if</strong> is_numeric_dtype(col):<br/>            <strong class="ku iu">if</strong> pd.isnull(col).sum():<br/>                df[name+'_na'] = pd.isnull(col)<br/>                filler = col.median()<br/>                df[name] = col.fillna(filler)<br/>                na_dict[name] = filler<br/>    # keep track of which entries are missing and possibly use them<br/>    # in the model<br/>    <strong class="ku iu">if</strong> len(na_dict_initial.keys()) &gt; 0:<br/>        df.drop([a + '_na' <strong class="ku iu">for</strong> a <strong class="ku iu">in</strong> list(set(na_dict.keys()) -<br/>        set(na_dict_initial.keys()))], axis=1, inplace=<strong class="ku iu">True</strong>)<br/>    # normalize<br/>    <strong class="ku iu">if</strong> do_scale: mapper = scale_vars(df, mapper)<br/>    res = [df, y, na_dict]<br/>    # keep track of how things were normalized<br/>    <strong class="ku iu">if</strong> do_scale: res = res + [mapper]<br/>    <strong class="ku iu">return</strong> res</span></pre><p id="5119" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">太好了。因此，现在我们希望将新的 datetime 特性添加到我们的数据帧中，规范化连续数据，并对分类特性进行分类(将它们更改为代表其类别的数字)。</p><pre class="kp kq kr ks gt kt ku kv kw aw kx bi"><span id="617a" class="ky kz it ku b gy la lb l lc ld">add_datepart(df, 'date', drop=<strong class="ku iu">False</strong>)</span></pre><p id="254e" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><code class="fe lr ls lt ku b">add_datepart</code>是一个就地操作，所以现在我们的 dataframe 有更多的列来表示列<code class="fe lr ls lt ku b">date</code>的不同方面。我还没有删除<code class="fe lr ls lt ku b">date</code>列，因为我想很快用它来创建我的训练、有效和测试数据帧。</p><figure class="kp kq kr ks gt lg gh gi paragraph-image"><div role="button" tabindex="0" class="lh li di lj bf lk"><div class="gh gi lu"><img src="../Images/d099eebaf93cc7c07ede1455d0c8350a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*gnrmEqlRDI-lk0Hj3S-5qA.png"/></div></div><figcaption class="ln lo gj gh gi lp lq bd b be z dk">columns of df</figcaption></figure><p id="c560" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">现在让我们定义哪些列是分类的，哪些是连续的。</p><pre class="kp kq kr ks gt kt ku kv kw aw kx bi"><span id="ff19" class="ky kz it ku b gy la lb l lc ld">cat_vars = ['cat1', 'cat2', 'Year', 'Month','Week', 'Day',<br/>            'Dayofweek', 'Dayofyear', 'Is_month_end',<br/>            'Is_month_start', 'Is_quarter_end', 'Is_quarter_start',<br/>            'Is_year_end', 'Is_year_start', 'Elapsed']</span><span id="c9c0" class="ky kz it ku b gy le lb l lc ld">cont_vars = ['cont1', 'cont2']</span></pre><p id="5f6d" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">我想<em class="ko">对我所有的 cat 特性进行分类</em>，但我也想确保它们对我的训练、有效和测试数据帧进行了相同的分类。这意味着，如果在我的训练数据中<code class="fe lr ls lt ku b">cow</code>被映射到<code class="fe lr ls lt ku b">2</code>，我不希望<code class="fe lr ls lt ku b">cow</code>被映射到我的有效或测试数据中的其他数据。所以我现在就做这个操作，然后拆分我的数据集。</p><pre class="kp kq kr ks gt kt ku kv kw aw kx bi"><span id="d483" class="ky kz it ku b gy la lb l lc ld"><strong class="ku iu">for</strong> v <strong class="ku iu">in</strong> cat_vars: df[v] = df[v].astype('category').cat.as_ordered()<br/>df = train_cats(df, cat_vars)</span></pre><p id="338a" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">该模型将使用嵌入来处理分类特征，因此我们需要预先计算嵌入大小，以便稍后在模型中进行初始化。fast.ai 的杰瑞米·霍华德建议使用最小 50 和类基数的一半。</p><blockquote class="lv"><p id="3651" class="lw lx it bd ly lz ma mb mc md me kn dk translated">这又是一个应该在将数据集分解成训练、有效、测试之前<strong class="ak">完成的操作。</strong></p></blockquote><pre class="mf mg mh mi mj kt ku kv kw aw kx bi"><span id="6112" class="ky kz it ku b gy la lb l lc ld"><strong class="ku iu">for</strong> v <strong class="ku iu">in</strong> cat_vars: df[v] = df[v].astype('category').cat.as_ordered()<br/>cat_sz = [(c, len(df[c].cat.categories)+1) <strong class="ku iu">for</strong> c <strong class="ku iu">in</strong> cat_vars]<br/>emb_szs = [(c, min(50, (c+1)//2)) <strong class="ku iu">for</strong> _,c <strong class="ku iu">in</strong> cat_sz]</span></pre><p id="15f2" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">如果您首先分解数据集，然后检查嵌入大小，您可能会得到错误:<em class="ko">运行时错误:索引超出范围:试图访问 11 行表中的索引 12。</em>这是因为嵌入大小的计算没有考虑一些偶然被排除在训练数据之外的类别。</p><pre class="kp kq kr ks gt kt ku kv kw aw kx bi"><span id="8600" class="ky kz it ku b gy la lb l lc ld">train = df.loc[df.date &lt; pd.to_datetime('2016-01-01', <br/>               format='%Y-%m-%d'),:].copy()<br/>valid = df.loc[(df.date &gt;= pd.to_datetime('2016-01-01', <br/>               format='%Y-%m-%d')) <strong class="ku iu">&amp;</strong><br/>               (df.date &lt; pd.to_datetime(max_date, <br/>               format='%Y-%m-%d')),:].copy()<br/>test = df.loc[df.date == pd.to_datetime(max_date, <br/>               format='%Y-%m-%d'),:].copy()</span><span id="dd9a" class="ky kz it ku b gy le lb l lc ld">train = train.drop(columns='date')<br/>valid = valid.drop(columns='date')<br/>test = test.drop(columns='date')</span></pre><p id="6801" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">所以我相当随意地选择了我的验证集。这不是一种好的做法，在您的生产环境中，您应该测试不同的集合，并尝试将它们紧密映射到测试集合，但在这种情况下，我只是采用了 2016 年 1 月之后的所有内容。</p><pre class="kp kq kr ks gt kt ku kv kw aw kx bi"><span id="8024" class="ky kz it ku b gy la lb l lc ld"><strong class="ku iu">for</strong> v <strong class="ku iu">in</strong> cat_vars: train[v] =<br/>                   train[v].astype('category').cat.as_ordered()<br/><strong class="ku iu">for</strong> v <strong class="ku iu">in</strong> cont_vars: train[v] = train[v].astype('float32')<br/><strong class="ku iu">for</strong> v <strong class="ku iu">in</strong> cat_vars: valid[v] =<br/>                   valid[v].astype('category').cat.as_ordered()<br/><strong class="ku iu">for</strong> v <strong class="ku iu">in</strong> cont_vars: valid[v] = valid[v].astype('float32')<br/><strong class="ku iu">for</strong> v <strong class="ku iu">in</strong> cat_vars: test[v] = <br/>                   test[v].astype('category').cat.as_ordered()<br/><strong class="ku iu">for</strong> v <strong class="ku iu">in</strong> cont_vars: test[v] = test[v].astype('float32')</span></pre><p id="603c" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">我们希望将分类特征与连续特征分开传递给我们的模型，这样猫可以首先通过嵌入，然后通过线性、relu、batchnorm、dropout 以及 conts。</p><pre class="kp kq kr ks gt kt ku kv kw aw kx bi"><span id="3ae4" class="ky kz it ku b gy la lb l lc ld"><strong class="ku iu">class</strong> ColumnarDataset(Dataset):<br/>    """Dataset class for column dataset.<br/>    Args:<br/>       cats (list of str): List of the name of columns contain<br/>                           categorical variables.<br/>       conts (list of str): List of the name of columns which <br/>                           contain continuous variables.<br/>       y (Tensor, optional): Target variables.<br/>       is_reg (bool): If the task is regression, set ``True``, <br/>                      otherwise (classification) ``False``.<br/>       is_multi (bool): If the task is multi-label classification, <br/>                        set ``True``.<br/>    """<br/>    <strong class="ku iu">def</strong> __init__(<strong class="ku iu">self</strong>, df, cat_flds, y, is_reg, is_multi):<br/>        df_cat = df[cat_flds]<br/>        df_cont = df.drop(cat_flds, axis=1)<br/>        <br/>        cats = [c.values for n,c in df_cat.items()]<br/>        conts = [c.values for n,c in df_cont.items()]<br/>        <br/>        n = len(cats[0]) <strong class="ku iu">if</strong> cats <strong class="ku iu">else</strong> len(conts[0])<br/>        self.cats = np.stack(cats, 1).astype(np.int64)   <br/>                           <strong class="ku iu">if</strong> cats <strong class="ku iu">else</strong> np.zeros((n,1))<br/>        self.conts = np.stack(conts, 1).astype(np.float32) <br/>                           <strong class="ku iu">if</strong> conts <strong class="ku iu">else</strong> np.zeros((n,1))<br/>        self.y = np.zeros((n,1)) <strong class="ku iu">if</strong> y <strong class="ku iu">is</strong> <strong class="ku iu">None</strong> <strong class="ku iu">else</strong> y<br/>        <strong class="ku iu">if</strong> is_reg: self.y =  self.y[:,<strong class="ku iu">None</strong>]<br/>        self.is_reg = is_reg<br/>        self.is_multi = is_multi</span><span id="cffd" class="ky kz it ku b gy le lb l lc ld">    <strong class="ku iu">def</strong> __len__(<strong class="ku iu">self</strong>): <strong class="ku iu">return</strong> <strong class="ku iu">len</strong>(self.y)</span><span id="5d83" class="ky kz it ku b gy le lb l lc ld">    <strong class="ku iu">def</strong> __getitem__(<strong class="ku iu">self</strong>, idx):<br/>        <strong class="ku iu">return</strong> [self.cats[idx], self.conts[idx], self.y[idx]]</span></pre><p id="e154" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">正如您在这个类中看到的，__getitem__ 正在为那个<code class="fe lr ls lt ku b">idx</code>值检索一个 cats、conts 和 target 的列表。</p><p id="1dec" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">归一化和预处理每个数据集。</p><pre class="kp kq kr ks gt kt ku kv kw aw kx bi"><span id="f996" class="ky kz it ku b gy la lb l lc ld">dep_var = 'targ'<br/>df, y, nas, mapper = proc_df(train, cat_vars, cont_vars, dep_var, <br/>                             do_scale=<strong class="ku iu">True</strong>)<br/>df_val, y_val, nas, mapper = proc_df(valid, cat_vars, cont_vars, <br/>                                     dep_var, do_scale=<strong class="ku iu">True</strong>, <br/>                                     mapper=mapper, na_dict=nas)<br/>df_test, y_test, nas, mapper = proc_df(test, cat_vars, cont_vars, <br/>                                       dep_var, do_scale=<strong class="ku iu">True</strong>)</span></pre><p id="86d1" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">初始化每个 dataset 对象并创建 dataloader 对象。</p><pre class="kp kq kr ks gt kt ku kv kw aw kx bi"><span id="e4b0" class="ky kz it ku b gy la lb l lc ld">trn_ds = ColumnarDataset(df, cat_vars, y,is_reg=<strong class="ku iu">True</strong>,is_multi=<strong class="ku iu">False</strong>)<br/>val_ds = ColumnarDataset(df_val, cat_vars, <br/>                         y_val,is_reg=<strong class="ku iu">True</strong>,is_multi=<strong class="ku iu">False</strong>)<br/>test_ds = ColumnarDataset(df_test, cat_vars, <br/>                         y_test,is_reg=<strong class="ku iu">True</strong>,is_multi=<strong class="ku iu">False</strong>)</span><span id="c970" class="ky kz it ku b gy le lb l lc ld">bs = 64<br/>train_dl = DataLoader(trn_ds, bs, shuffle=<strong class="ku iu">True</strong>)<br/>val_dl = DataLoader(val_ds, bs, shuffle=<strong class="ku iu">False</strong>)<br/>test_dl = DataLoader(test_ds, len(df_test), shuffle=<strong class="ku iu">False</strong>)</span></pre><p id="a567" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">定义模型。</p><pre class="kp kq kr ks gt kt ku kv kw aw kx bi"><span id="bbc9" class="ky kz it ku b gy la lb l lc ld"><strong class="ku iu">class</strong> MixedInputModel(nn.Module):<br/>    """Model able to handle inputs consisting of both categorical and continuous variables.<br/>    Args:<br/>       emb_szs (list of int): List of embedding size<br/>       n_cont (int): Number of continuous variables in inputs<br/>       emb_drop (float): Dropout applied to the output of embedding<br/>       out_sz (int): Size of model's output.<br/>       szs (list of int): List of hidden variables sizes<br/>       drops (list of float): List of dropout applied to hidden <br/>                              variables<br/>       y_range (list of float): Min and max of `y`. <br/>                                y_range[0] = min, y_range[1] = max.<br/>       use_bn (bool): If use BatchNorm, set ``True``<br/>       is_reg (bool): If regression, set ``True``<br/>       is_multi (bool): If multi-label classification, set ``True``<br/>    """<br/>    <strong class="ku iu">def</strong> __init__(<strong class="ku iu">self</strong>, emb_szs, n_cont, emb_drop, out_sz, szs, <br/>                 drops, y_range=<strong class="ku iu">None</strong>, use_bn=<strong class="ku iu">False</strong>, is_reg=<strong class="ku iu">True</strong>, <br/>                 is_multi=<strong class="ku iu">False</strong>):<br/>        <strong class="ku iu">super</strong>().__init__()<br/>        <strong class="ku iu">for</strong> i,(c,s) <strong class="ku iu">in</strong> enumerate(emb_szs): <strong class="ku iu">assert</strong> c &gt; 1, <br/>            f"cardinality must be &gt;=2, got emb_szs[{i}]: ({c},{s})"<br/>        <strong class="ku iu">if</strong> is_reg==<strong class="ku iu">False</strong> and is_multi==<strong class="ku iu">False</strong>: <strong class="ku iu">assert</strong> out_sz &gt;= 2, <br/>            "For classification with out_sz=1, use is_multi=True"<br/>        self.embs = nn.ModuleList([nn.Embedding(c, s) <br/>                                      <strong class="ku iu">for</strong> c,s <strong class="ku iu">in</strong> emb_szs])<br/>        <strong class="ku iu">for</strong> emb <strong class="ku iu">in</strong> self.embs: emb_init(emb)<br/>        n_emb = sum(e.embedding_dim <strong class="ku iu">for</strong> e <strong class="ku iu">in</strong> self.embs)<br/>        self.n_emb, self.n_cont=n_emb, n_cont<br/>        <br/>        szs = [n_emb+n_cont] + szs<br/>        self.lins = nn.ModuleList([<br/>            nn.Linear(szs[i], szs[i+1]) <strong class="ku iu">for</strong> i <strong class="ku iu">in</strong> <strong class="ku iu">range</strong>(<strong class="ku iu">len</strong>(szs)-1)])<br/>        self.bns = nn.ModuleList([<br/>            nn.BatchNorm1d(sz) <strong class="ku iu">for</strong> sz <strong class="ku iu">in</strong> szs[1:]])<br/>        <strong class="ku iu">for</strong> o <strong class="ku iu">in</strong> self.lins: kaiming_normal_(o.weight.data)<br/>        self.outp = nn.Linear(szs[-1], out_sz)<br/>        kaiming_normal_(self.outp.weight.data)</span><span id="bc3d" class="ky kz it ku b gy le lb l lc ld">        self.emb_drop = nn.Dropout(emb_drop)<br/>        self.drops = nn.ModuleList([nn.Dropout(drop) <br/>                                        <strong class="ku iu">for</strong> drop <strong class="ku iu">in</strong> drops])<br/>        self.bn = nn.BatchNorm1d(n_cont)<br/>        self.use_bn,self.y_range = use_bn,y_range<br/>        self.is_reg = is_reg<br/>        self.is_multi = is_multi</span><span id="d1fc" class="ky kz it ku b gy le lb l lc ld">    <strong class="ku iu">def</strong> forward(<strong class="ku iu">self</strong>, x_cat, x_cont):<br/>        <strong class="ku iu">if</strong> self.n_emb != 0:<br/>            x = [e(x_cat[:,i]) <strong class="ku iu">for</strong> i,e <strong class="ku iu">in</strong> enumerate(self.embs)]<br/>            x = torch.cat(x, 1)<br/>            x = self.emb_drop(x)<br/>        <strong class="ku iu">if</strong> self.n_cont != 0:<br/>            x2 = self.bn(x_cont)<br/>            x = torch.cat([x, x2], 1) <strong class="ku iu">if</strong> self.n_emb != 0 <strong class="ku iu">else</strong> x2<br/>        <strong class="ku iu">for</strong> l,d,b <strong class="ku iu">in</strong> zip(self.lins, self.drops, self.bns):<br/>            x = F.relu(l(x))<br/>            <strong class="ku iu">if</strong> self.use_bn: x = b(x)<br/>            x = d(x)<br/>        x = self.outp(x)<br/>        <strong class="ku iu">if</strong> <strong class="ku iu">not</strong> self.is_reg:<br/>            <strong class="ku iu">if</strong> self.is_multi:<br/>                x = torch.sigmoid(x)<br/>            <strong class="ku iu">else</strong>:<br/>                x = F.log_softmax(x, dim=1)<br/>        <strong class="ku iu">elif</strong> self.y_range:<br/>            x = torch.sigmoid(x)<br/>            x = x*(self.y_range[1] - self.y_range[0])<br/>            x = x+self.y_range[0]<br/>        <strong class="ku iu">return</strong> x</span><span id="e9fe" class="ky kz it ku b gy le lb l lc ld"><strong class="ku iu">def</strong> emb_init(x):<br/>    x = x.weight.data<br/>    sc = 2/(x.size(1)+1)<br/>    x.uniform_(-sc,sc)</span></pre><p id="1b08" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">初始化模型。我们正在对<code class="fe lr ls lt ku b">targ</code>列执行回归任务。</p><pre class="kp kq kr ks gt kt ku kv kw aw kx bi"><span id="6622" class="ky kz it ku b gy la lb l lc ld">model = MixedInputModel(emb_szs, <br/>                        n_cont=<strong class="ku iu">len</strong>(df.columns)-<strong class="ku iu">len</strong>(cat_vars), <br/>                        emb_drop = 0.04, out_sz = 1, <br/>                        szs = [1000,500], drops = [0.001,0.01], <br/>                        y_range=(0,np.max(y)), use_bn=<strong class="ku iu">True</strong>, <br/>                        is_reg=<strong class="ku iu">True</strong>, is_multi=<strong class="ku iu">False</strong>)</span></pre><p id="d035" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">我们现在准备训练模型。</p><pre class="kp kq kr ks gt kt ku kv kw aw kx bi"><span id="4747" class="ky kz it ku b gy la lb l lc ld"><strong class="ku iu">def</strong> train_model(model, train_dl, val_dl, n_epochs=1, lr=5e-2):<br/>        "Run training loops."<br/>        epochs = n_epochs<br/>        opt = optim.SGD(model.parameters(), lr=lr)<br/>        loss_func = nn.MSELoss()<br/>        <strong class="ku iu">try</strong>:<br/>            <strong class="ku iu">for</strong> epoch <strong class="ku iu">in</strong> range(epochs):<br/>                model.train()<br/>                <strong class="ku iu">for</strong> xb1, xb2, yb <strong class="ku iu">in</strong> train_dl:<br/>                    preds = model(xb1, xb2)<br/>                    loss = loss_func(preds, yb.float())<br/>                    <br/>                    loss.backward()<br/>                    opt.step()<br/>                    opt.zero_grad()<br/>                    <br/>                model.eval()<br/>                <strong class="ku iu">with</strong> torch.no_grad():<br/>                    loss_val = sum(loss_func(model(xv1, xv2), <br/>                                             yv.float()) <br/>                                   <strong class="ku iu">for</strong> xv1, xv2, yv <strong class="ku iu">in</strong> val_dl)<br/>                print(epoch, loss_val / len(val_dl))<br/>        <strong class="ku iu">except</strong> Exception <strong class="ku iu">as</strong> e:<br/>            exception = e<br/>            <strong class="ku iu">raise</strong></span></pre><p id="1636" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">最后，我们可以通过测试集进行训练和预测。</p><pre class="kp kq kr ks gt kt ku kv kw aw kx bi"><span id="d61a" class="ky kz it ku b gy la lb l lc ld">train_model(model, train_dl, val_dl, n_epochs=500, lr=5e-2)</span><span id="f602" class="ky kz it ku b gy le lb l lc ld"><strong class="ku iu">def</strong> predict_test(model, test_dl):<br/>    "Returns predictions over test_df."<br/>    model.eval()<br/>    preds = [model(xv1, xv2) <strong class="ku iu">for</strong> xv1, xv2, _ <strong class="ku iu">in</strong> test_dl][0]<br/>    targs = [yv <strong class="ku iu">for</strong> _, _, yv <strong class="ku iu">in</strong> test_dl][0]<br/>    test_human_readable['targ_pred'] = preds.data.detach().numpy()<br/>    <strong class="ku iu">return</strong> torch.argmax(preds, dim=1).data.detach().numpy(), <br/>           test_human_readable</span><span id="cc87" class="ky kz it ku b gy le lb l lc ld">preds, df = predict_test(model, test_dl)</span></pre><figure class="kp kq kr ks gt lg gh gi paragraph-image"><div role="button" tabindex="0" class="lh li di lj bf lk"><div class="gh gi mk"><img src="../Images/99ae8372ac4a44cb6cad94c735cd4ccf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*NBjQ_ajvL5qX7OKyEfBzrg.png"/></div></div><figcaption class="ln lo gj gh gi lp lq bd b be z dk">Test set with prediction</figcaption></figure><p id="d071" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">所以，理想情况下，你可以拿着熊猫的任何数据框，运行这段代码，得到一个不错的预测输出。但这有望让您更深入地剖析这个过程，尝试一些建模变化或任何您感兴趣的东西。</p><figure class="kp kq kr ks gt lg gh gi paragraph-image"><div role="button" tabindex="0" class="lh li di lj bf lk"><div class="gh gi ml"><img src="../Images/53b740419911847cab37d94c7c3b1c08.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*IyWh6JoVzdhH_NbAL6AqVg.png"/></div></div></figure><p id="6325" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">玩得开心！</p></div></div>    
</body>
</html>