<html>
<head>
<title>Multi-Layer Perceptron using FastAI and PyTorch</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用 FastAI 和 PyTorch 的多层感知器</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/multi-layer-perceptron-usingfastai-and-pytorch-9e401dd288b8?source=collection_archive---------17-----------------------#2019-01-06">https://towardsdatascience.com/multi-layer-perceptron-usingfastai-and-pytorch-9e401dd288b8?source=collection_archive---------17-----------------------#2019-01-06</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="2645" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">使用 FastAI 和 Pytorch 对多层感知器的温和介绍。</h2></div><figure class="kf kg kh ki gt kj gh gi paragraph-image"><div class="ab gu cl kk"><img src="../Images/b3690a45c000e55d9186f14e8f401ad0.png" data-original-src="https://miro.medium.com/v2/format:webp/0*T5d_brtoGf6JSnW_.png"/></div><figcaption class="kn ko gj gh gi kp kq bd b be z dk">Multi-Layer Perceptron network. <em class="kr">Image credit=http://pubs.sciepub.com/ajmm/3/3/1/figure/2s</em></figcaption></figure><p id="5fe3" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated">在这篇博客中，我将向您展示如何使用 FastAI v1 和 Pytorch 构建一个神经网络(多层感知器)，并成功训练它识别图像中的数字。<a class="ae lo" href="https://pytorch.org/" rel="noopener ugc nofollow" target="_blank"> Pytorch </a>是脸书发布的一个非常流行的深度学习框架，<a class="ae lo" href="https://docs.fast.ai/" rel="noopener ugc nofollow" target="_blank"> FastAI v1 </a>是一个库，它使用现代最佳实践简化了训练快速准确的神经网络。它基于在<a class="ae lo" href="https://www.fast.ai/" rel="noopener ugc nofollow" target="_blank"> fast.ai </a>进行的深度学习最佳实践的研究，包括对视觉、文本、表格和 collab(协作过滤)模型的“开箱即用”支持。如果你正在寻找源代码，请前往 GitHub 上的<a class="ae lo" href="https://github.com/fastai/fastai" rel="noopener ugc nofollow" target="_blank"> fastai repo </a>。这个笔记本将指导用这个库建立一个神经网络。如果你想了解什么是多层感知器，你可以看看我的<a class="ae lo" href="https://medium.com/@aayushmnit/building-neural-network-from-scratch-9c88535bf8e9" rel="noopener">以前的博客</a>，在那里我使用 numpy 从头构建了一个多层感知器，以及<a class="ae lo" href="https://medium.com/@aayushmnit/multi-layer-perceptron-using-tensorflow-9f3e218a4809" rel="noopener">另一个博客</a>，在那里我使用 TensorFlow 构建了相同的模型。正如你所注意到的，编写这款笔记本所需的代码量比以前的笔记本少得多，这都要归功于 fastai 库，它让我们能够将更多的精力放在解决问题上，而不是编写代码。这个博客也可以在我的 Github 上作为 Jupyter 笔记本使用。</p><h1 id="4f46" class="lp lq iq bd lr ls lt lu lv lw lx ly lz jw ma jx mb jz mc ka md kc me kd mf mg bi translated">样板命令</h1><p id="97b0" class="pw-post-body-paragraph ks kt iq ku b kv mh jr kx ky mi ju la lb mj ld le lf mk lh li lj ml ll lm ln ij bi translated">标准做法是用下面三行开始笔记本；它们确保您对库所做的任何编辑都会自动重新加载到此处，并且显示的任何图表或图像都会显示在此笔记本中。</p><pre class="kf kg kh ki gt mm mn mo mp aw mq bi"><span id="fa97" class="mr lq iq mn b gy ms mt l mu mv">%reload_ext autoreload<br/>%autoreload 2<br/>%matplotlib inline</span></pre><h1 id="b1c8" class="lp lq iq bd lr ls lt lu lv lw lx ly lz jw ma jx mb jz mc ka md kc me kd mf mg bi translated">导入快速人工智能库</h1><p id="df75" class="pw-post-body-paragraph ks kt iq ku b kv mh jr kx ky mi ju la lb mj ld le lf mk lh li lj ml ll lm ln ij bi translated">让我们导入 fastai 库，并将 batch_size 参数定义为 128。通常，图像数据库非常庞大，因此我们需要使用批处理将这些图像送入 GPU，批处理大小 128 意味着我们将一次送入 128 幅图像，以更新我们深度学习模型的参数。如果由于 GPU RAM 较小而导致内存不足，可以将批处理大小减少到 64 或 32。</p><pre class="kf kg kh ki gt mm mn mo mp aw mq bi"><span id="5a05" class="mr lq iq mn b gy ms mt l mu mv"><strong class="mn ir">from</strong> <strong class="mn ir">fastai.vision</strong> <strong class="mn ir">import</strong> *<br/>bs=128</span></pre><h1 id="1799" class="lp lq iq bd lr ls lt lu lv lw lx ly lz jw ma jx mb jz mc ka md kc me kd mf mg bi translated">下载数据集</h1><p id="f2d5" class="pw-post-body-paragraph ks kt iq ku b kv mh jr kx ky mi ju la lb mj ld le lf mk lh li lj ml ll lm ln ij bi translated">我们将从从<a class="ae lo" href="https://course.fast.ai/datasets" rel="noopener ugc nofollow" target="_blank"> fastai 数据集</a>页面下载 MNIST 手写数据集开始。MNIST 是小型(28x28)手写灰度数字的标准数据集，开发于 20 世纪 90 年代，用于测试当时最复杂的模型；今天，经常被用作介绍深度学习的基本“hello world”。这个 fast.ai datasets 版本使用标准的 PNG 格式，而不是原来的特殊二进制格式，这样你就可以在大多数库中使用常规的数据管道；如果您想像原始通道一样只使用一个输入通道，只需从通道轴中选取一个切片。</p><pre class="kf kg kh ki gt mm mn mo mp aw mq bi"><span id="e3bc" class="mr lq iq mn b gy ms mt l mu mv">path = untar_data(URLs.MNIST);<br/>path</span></pre><figure class="kf kg kh ki gt kj gh gi paragraph-image"><div role="button" tabindex="0" class="mx my di mz bf na"><div class="gh gi mw"><img src="../Images/a24791c13adaf47de7a0c444a6cc024a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*9wkUkeZPySiHHPK5ZahMrQ.png"/></div></div></figure><p id="be8a" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated">通过运行上面的命令，数据被下载并存储在上面显示的路径中。让我们看看数据目录是如何设置的，因为我们必须从这些目录导入数据。让我们从查看路径目录开始，我们可以在下面看到我们的数据已经有了培训和测试文件夹。</p><pre class="kf kg kh ki gt mm mn mo mp aw mq bi"><span id="4fcf" class="mr lq iq mn b gy ms mt l mu mv">path.ls()</span></pre><figure class="kf kg kh ki gt kj gh gi paragraph-image"><div role="button" tabindex="0" class="mx my di mz bf na"><div class="gh gi nb"><img src="../Images/50a3b066b981485cf8a0b7b7bf73c990.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*FFNN4IjK4dI3zc7SAdxc_Q.png"/></div></div></figure><p id="aea3" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated">让我们看看培训文件夹。数据在不同的文件夹中按数字 1 到 9 分割。</p><pre class="kf kg kh ki gt mm mn mo mp aw mq bi"><span id="990d" class="mr lq iq mn b gy ms mt l mu mv">(path/'training').ls()</span></pre><figure class="kf kg kh ki gt kj gh gi paragraph-image"><div role="button" tabindex="0" class="mx my di mz bf na"><div class="gh gi nc"><img src="../Images/ad553582c137f4b339f18045f3d7c46e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*wmsLTsHB2Qh2CnQNVt_VzQ.png"/></div></div></figure><p id="dfdd" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated">在每个数字文件夹中，我们都有图像。</p><pre class="kf kg kh ki gt mm mn mo mp aw mq bi"><span id="cef2" class="mr lq iq mn b gy ms mt l mu mv">(path/'training/0').ls()[1:5]</span></pre><figure class="kf kg kh ki gt kj gh gi paragraph-image"><div role="button" tabindex="0" class="mx my di mz bf na"><div class="gh gi nd"><img src="../Images/8ac06ecb9cc3d7338a8505e4782a106a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_zqzOMGw5Lpo2aX3CRsg9A.png"/></div></div></figure><h1 id="7d6e" class="lp lq iq bd lr ls lt lu lv lw lx ly lz jw ma jx mb jz mc ka md kc me kd mf mg bi translated">导入数据</h1><p id="f986" class="pw-post-body-paragraph ks kt iq ku b kv mh jr kx ky mi ju la lb mj ld le lf mk lh li lj ml ll lm ln ij bi translated">现在我们已经了解了我们的数据目录是如何建立的；我们将使用 FastAI amazing <a class="ae lo" href="https://docs.fast.ai/data_block.html" rel="noopener ugc nofollow" target="_blank">数据块 API </a>导入数据，使用 FastAI <a class="ae lo" href="https://docs.fast.ai/vision.transform.html" rel="noopener ugc nofollow" target="_blank">图像转换函数</a>进行数据扩充。让我们从定义我们想要做什么样的转换开始。</p><pre class="kf kg kh ki gt mm mn mo mp aw mq bi"><span id="f8b8" class="mr lq iq mn b gy ms mt l mu mv">ds_tfms = get_transforms(do_flip=<strong class="mn ir">False</strong>, flip_vert=<strong class="mn ir">False</strong>, max_rotate= 15,max_zoom=1.1, max_lighting=0.2, max_warp=0.2)</span></pre><p id="eb78" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated">在<strong class="ku ir"> get_transforms </strong>函数中，我们可以定义所有我们想要做的转换。FastAI 使数据扩充变得非常容易，因为所有的转换都可以在一个函数中传递，并且使用了非常快速的实现。让我们看看函数中给出的每个参数。</p><ul class=""><li id="0c1a" class="ne nf iq ku b kv kw ky kz lb ng lf nh lj ni ln nj nk nl nm bi translated"><em class="nn"> do_flip=False，flip_vert=False </em>:我们不想在垂直和水平方向翻转数字，因为这对于数字数据来说不是一个好主意。</li><li id="d5ca" class="ne nf iq ku b kv no ky np lb nq lf nr lj ns ln nj nk nl nm bi translated"><em class="nn"> max_rotate= 15 </em>:在顺时针和逆时针最大旋转 15 度的同时，随机旋转图像</li><li id="1b35" class="ne nf iq ku b kv no ky np lb nq lf nr lj ns ln nj nk nl nm bi translated"><em class="nn"> max_zoom=1.1 </em>:将图像放大/缩小原始图像的 10%</li><li id="1dc6" class="ne nf iq ku b kv no ky np lb nq lf nr lj ns ln nj nk nl nm bi translated"><em class="nn"> max_lighting=0.2 </em>:将应用由 max_lighting 控制的随机闪电和对比度变化</li><li id="1fd1" class="ne nf iq ku b kv no ky np lb nq lf nr lj ns ln nj nk nl nm bi translated"><em class="nn"> max_warp=0.2 </em>:以概率 p_affine 应用大小在-max_warp 和+max_warp 之间的随机对称变形，在这种情况下默认为 0.75。</li></ul><p id="d475" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated">既然我们已经定义了我们想要在输入图像上做什么样的转换，那么让我们开始定义 FastAI 称之为 data batches 或 databunch。图像数据集规模庞大，因此我们从不希望将整个数据集导入内存，相反，我们定义了一个 databunch，它将允许我们加载批量数据并即时进行所需的转换。</p><pre class="kf kg kh ki gt mm mn mo mp aw mq bi"><span id="75fb" class="mr lq iq mn b gy ms mt l mu mv">data = (ImageItemList.from_folder(path, convert_mode='L')<br/>        .split_by_folder(train='training', valid='testing')<br/>        .label_from_folder()<br/>        .transform(tfms=ds_tfms, size=28)<br/>        .databunch(bs=bs))</span></pre><p id="85e7" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated">杰瑞米·霍华德称上述步骤为<strong class="ku ir">标签工程</strong>，因为大部分时间和精力都花在正确导入数据上。FastAI 的<a class="ae lo" href="https://docs.fast.ai/data_block.html" rel="noopener ugc nofollow" target="_blank">数据块 API </a>使用类似 API 的 R ggplots <em class="nn">【图形语法】</em>来定义我们想要如何导入我们的数据变得非常容易，在这里你可以不断地链接不同的函数，直到你准备好你的数据束。让我们了解一下上面的代码在做什么-</p><ul class=""><li id="e632" class="ne nf iq ku b kv kw ky kz lb ng lf nh lj ni ln nj nk nl nm bi translated"><em class="nn">image item list . from _ folder(path，convert_mode='L') </em> —根据扩展名中带有后缀的文件名在路径中创建项目列表。Convert_mode='L '帮助我们定义要导入的图像是灰度/单通道图像，默认为“RGB ”,这意味着 3 通道图像。FastAI 使用 PIL 库，所以<a class="ae lo" href="https://pillow.readthedocs.io/en/3.1.x/reference/Image.html#PIL.Image.Image.convert" rel="noopener ugc nofollow" target="_blank"> convert </a>实际上是一个 PIL 功能</li><li id="c253" class="ne nf iq ku b kv no ky np lb nq lf nr lj ns ln nj nk nl nm bi translated"><em class="nn">split _ by _ folder(train = ' training '，valid='testing'): </em>此函数通知 databunch，我们在路径目录的' training '和' testing '子文件夹中有训练和测试数据</li><li id="e8d4" class="ne nf iq ku b kv no ky np lb nq lf nr lj ns ln nj nk nl nm bi translated"><em class="nn"> label_from_folder() </em> —此函数通知 databunch 从文件夹名称中提取数字标签</li><li id="d504" class="ne nf iq ku b kv no ky np lb nq lf nr lj ns ln nj nk nl nm bi translated"><em class="nn"> transform(tfms=ds_tfms，size=28) </em> —该函数通知 databunch 将<em class="nn"> ds_tfms </em>变量中定义的变换应用于每幅图像</li><li id="b6c2" class="ne nf iq ku b kv no ky np lb nq lf nr lj ns ln nj nk nl nm bi translated"><em class="nn"> databunch(bs=bs) </em> —此函数将此 databunch 转换为 FastAI 的 ImageDataBunch 类，批量大小在 bs 变量中定义，即本例中为 128。</li></ul><p id="bdc4" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated">现在我们已经定义了我们的数据，让我们看一看我们的数据。如下图所示，您可以看到数字是使用<em class="nn"> show_batch </em>函数导入并可视化的，注意这些图像应用了我们定义的转换。</p><pre class="kf kg kh ki gt mm mn mo mp aw mq bi"><span id="ab42" class="mr lq iq mn b gy ms mt l mu mv">print(data.classes) <em class="nn">## Prints class labels</em><br/>print(data.c) <em class="nn">## Prints number of classes</em><br/>data.show_batch(rows=3, figsize=(10,6), hide_axis=<strong class="mn ir">False</strong>) <em class="nn">## Show sample data</em></span></pre><figure class="kf kg kh ki gt kj gh gi paragraph-image"><div role="button" tabindex="0" class="mx my di mz bf na"><div class="gh gi nt"><img src="../Images/fbf919987430fb211415ff022c2b58a7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ZPRx5OpiJ6HIIIVl_HgzOA.png"/></div></div></figure><h1 id="78e7" class="lp lq iq bd lr ls lt lu lv lw lx ly lz jw ma jx mb jz mc ka md kc me kd mf mg bi translated">用 Pytorch 定义多层感知器</h1><p id="c2cf" class="pw-post-body-paragraph ks kt iq ku b kv mh jr kx ky mi ju la lb mj ld le lf mk lh li lj ml ll lm ln ij bi translated">现在我们已经定义了我们的数据集群。让我们用 Pytorch 来定义我们的多层感知器模型。对于完全连接的层，我们使用 nn。线性函数，为了应用非线性，我们使用 ReLU 变换。在 Pytorch 中，我们只需要定义<em class="nn">前进</em>函数，而<em class="nn">后退</em>函数是使用自动签名自动定义的。如果您是 Pytorch 的新手，他们会提供优秀的文档和教程。我建议你通过 PYTORCH 完成这个<a class="ae lo" href="https://pytorch.org/tutorials/beginner/deep_learning_60min_blitz.html" rel="noopener ugc nofollow" target="_blank">深度学习:60 分钟闪电战</a>教程，它将涵盖理解下面发生的事情所需的所有基础知识。</p><pre class="kf kg kh ki gt mm mn mo mp aw mq bi"><span id="8b8e" class="mr lq iq mn b gy ms mt l mu mv"><strong class="mn ir">class</strong> <strong class="mn ir">Mnist_NN</strong>(nn.Module):<br/>    <strong class="mn ir">def</strong> __init__(self):<br/>        super().__init__()<br/>        self.lin1 = nn.Linear(784, 512, bias=<strong class="mn ir">True</strong>) <br/>        self.lin2 = nn.Linear(512, 256, bias=<strong class="mn ir">True</strong>)<br/>        self.lin3 = nn.Linear(256, 10, bias=<strong class="mn ir">True</strong>)<br/><br/>    <strong class="mn ir">def</strong> forward(self, xb):<br/>        x = xb.view(-1,784) <br/>        x = F.relu(self.lin1(x))<br/>        x = F.relu(self.lin2(x))<br/>        <strong class="mn ir">return</strong> self.lin3(x)</span></pre><h1 id="d758" class="lp lq iq bd lr ls lt lu lv lw lx ly lz jw ma jx mb jz mc ka md kc me kd mf mg bi translated">训练模型</h1><p id="7bd3" class="pw-post-body-paragraph ks kt iq ku b kv mh jr kx ky mi ju la lb mj ld le lf mk lh li lj ml ll lm ln ij bi translated">现在我们已经定义了我们的模型，我们需要训练它。我们可以使用 FastAI 的<em class="nn">学习器</em>功能，它可以更容易地利用优化方法中的现代增强功能和许多其他巧妙的技巧，如 Leslie Smith 的论文中强调的<a class="ae lo" href="https://arxiv.org/pdf/1803.09820.pdf" rel="noopener ugc nofollow" target="_blank">单周期风格训练，以实现更快的收敛。让我们定义一下我们的学习者类别-</a></p><pre class="kf kg kh ki gt mm mn mo mp aw mq bi"><span id="fe34" class="mr lq iq mn b gy ms mt l mu mv"><em class="nn">## Defining the learner</em><br/>mlp_learner = Learner(data=data, model=Mnist_NN(), loss_func=nn.CrossEntropyLoss(),metrics=accuracy)</span></pre><p id="d8c4" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated">让我们通过上面的论证来理解发生了什么</p><ul class=""><li id="0ce9" class="ne nf iq ku b kv kw ky kz lb ng lf nh lj ni ln nj nk nl nm bi translated"><em class="nn"> data=data </em> —传递我们的 Databunch 函数</li><li id="1d96" class="ne nf iq ku b kv no ky np lb nq lf nr lj ns ln nj nk nl nm bi translated"><em class="nn"> model=Mnist_NN() </em> —传递我们定义的 MLP 模型 Mnist_NN</li><li id="dbe2" class="ne nf iq ku b kv no ky np lb nq lf nr lj ns ln nj nk nl nm bi translated"><em class="nn">损失函数=nn。CrossEntropyLoss() </em> —定义损失函数进行优化，在本例中，我们使用<a class="ae lo" href="https://pytorch.org/docs/stable/nn.html?highlight=loss%20crossentropy#torch.nn.CrossEntropyLoss" rel="noopener ugc nofollow" target="_blank">交叉熵损失</a></li><li id="39d1" class="ne nf iq ku b kv no ky np lb nq lf nr lj ns ln nj nk nl nm bi translated"><em class="nn"> metrics=accuracy </em> —这只是为了培训时的打印目的，此论点与培训无关</li></ul><p id="d3f4" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated"><em class="nn"> Learner </em> class 提供了一个很棒的功能，可以在训练你的深度学习模型的时候，找到理想的学习速率作为起点。让我们试着找到理想的学习速度。</p><pre class="kf kg kh ki gt mm mn mo mp aw mq bi"><span id="c6a0" class="mr lq iq mn b gy ms mt l mu mv"><em class="nn">## Finidng Ideal learning late</em><br/>mlp_learner.lr_find()<br/>mlp_learner.recorder.plot()</span></pre><figure class="kf kg kh ki gt kj gh gi paragraph-image"><div role="button" tabindex="0" class="mx my di mz bf na"><div class="gh gi nd"><img src="../Images/09935897136f456be5f2a8beb94cdf08.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*HzkDHMQI8In2zRMVxtYYfA.png"/></div></div></figure><p id="0e5d" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated">理想情况下，我们希望找到斜率最大的点。在这种情况下，指针是 1e-2。因此，我们将从 1e-2 开始作为我们的学习速率，并使用<em class="nn"> fit_one_cycle </em>函数进行五个时期，该函数使用了<a class="ae lo" href="https://arxiv.org/pdf/1803.09820.pdf" rel="noopener ugc nofollow" target="_blank"> Leslie Smith 的论文</a>中强调的单周期风格训练方法，以实现更快的收敛。此外，FastAI 在训练时显示'<a class="ae lo" href="https://tqdm.github.io/" rel="noopener ugc nofollow" target="_blank"> tqdm </a>风格的进度条，在训练结束时，它开始显示表格，该表格显示我们在验证数据上定义的损失函数和度量的进度。</p><pre class="kf kg kh ki gt mm mn mo mp aw mq bi"><span id="1c0e" class="mr lq iq mn b gy ms mt l mu mv">mlp_learner.fit_one_cycle(5,1e-2)</span></pre><figure class="kf kg kh ki gt kj gh gi paragraph-image"><div role="button" tabindex="0" class="mx my di mz bf na"><div class="gh gi nu"><img src="../Images/3193f961b320ff7855c7dd4cff00e692.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*UD4tdb4qzqiUenjZTQK9Pg.png"/></div></div></figure><p id="38c3" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated">让我们通过降低学习率来进一步降低学习率，并对模型进行更多的训练。</p><pre class="kf kg kh ki gt mm mn mo mp aw mq bi"><span id="fe32" class="mr lq iq mn b gy ms mt l mu mv">mlp_learner.fit_one_cycle(5,1e-3)</span></pre><figure class="kf kg kh ki gt kj gh gi paragraph-image"><div role="button" tabindex="0" class="mx my di mz bf na"><div class="gh gi nv"><img src="../Images/d3fa76e4a1dcff59c13c03ae2ac99c49.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*5J1olZoQx8Nwx_ey7F-hPg.png"/></div></div></figure><pre class="kf kg kh ki gt mm mn mo mp aw mq bi"><span id="5dd0" class="mr lq iq mn b gy ms mt l mu mv">mlp_learner.recorder.plot_losses()</span></pre><p id="b374" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated">正如我们所看到的，仅仅通过使用简单的多层感知器，我们就达到了 98.6%的准确率。</p><figure class="kf kg kh ki gt kj gh gi paragraph-image"><div role="button" tabindex="0" class="mx my di mz bf na"><div class="gh gi nw"><img src="../Images/60e6396c1edc644497338a561a1dbea9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*y4WFmR6oxa_ihd9ZWIayuQ.png"/></div></div></figure><h1 id="258d" class="lp lq iq bd lr ls lt lu lv lw lx ly lz jw ma jx mb jz mc ka md kc me kd mf mg bi translated">结论</h1><p id="68ee" class="pw-post-body-paragraph ks kt iq ku b kv mh jr kx ky mi ju la lb mj ld le lf mk lh li lj ml ll lm ln ij bi translated">Fast.ai 是由<a class="ae lo" href="https://twitter.com/jeremyphoward" rel="noopener ugc nofollow" target="_blank">杰瑞米·霍华德</a>和他的团队提出的一个很好的倡议，我相信 fastai library 可以通过让构建深度学习模型变得超级简单来真正实现将深度学习民主化的动机。</p><p id="45e6" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated">我希望你喜欢阅读，并随时使用我的代码来尝试它为您的目的。此外，如果对代码或博客有任何反馈，请随时联系 aayushmnit@gmail.com 的<a class="ae lo" href="https://www.linkedin.com/in/aayushmnit/" rel="noopener ugc nofollow" target="_blank"> LinkedIn </a>或给我发电子邮件。</p></div></div>    
</body>
</html>