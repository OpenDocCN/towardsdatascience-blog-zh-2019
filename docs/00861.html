<html>
<head>
<title>PVANET: Deep but Lightweight Neural Networks for Real-time Object Detection</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">PVANET:用于实时对象检测的深度但轻量级的神经网络</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/pvanet-deep-but-lightweight-neural-networks-for-real-time-object-detection-aa9de432512?source=collection_archive---------8-----------------------#2019-02-09">https://towardsdatascience.com/pvanet-deep-but-lightweight-neural-networks-for-real-time-object-detection-aa9de432512?source=collection_archive---------8-----------------------#2019-02-09</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="57eb" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">论文摘要</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/db5764303b75c39a804bd527b39532fa.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*JxLoBlCRFgVQgEjpVb6Big.png"/></div></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk"><a class="ae kv" href="https://www.bbsmax.com/A/A2dmV1kgze/" rel="noopener ugc nofollow" target="_blank"><strong class="bd kw">Fig 2. PVANET Entire Model Vizualization</strong></a></figcaption></figure><p id="73b1" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated"><em class="lt">一篇论文论文摘要<br/> </em> <strong class="kz ir"> <em class="lt"> PVANET:深度但轻量级的神经网络用于实时物体检测</em> </strong> <em class="lt"> <br/>作者:、丛瑶、何文、、周树昌、何、梁家军<br/>论文链接:</em> <a class="ae kv" href="https://arxiv.org/pdf/1608.08021.pdf" rel="noopener ugc nofollow" target="_blank"> <em class="lt">、</em> </a></p><h1 id="0bfb" class="lu lv iq bd lw lx ly lz ma mb mc md me jw mf jx mg jz mh ka mi kc mj kd mk ml bi translated">概观</h1><p id="9189" class="pw-post-body-paragraph kx ky iq kz b la mm jr lc ld mn ju lf lg mo li lj lk mp lm ln lo mq lq lr ls ij bi translated">本文介绍了我们的轻量级特征提取网络结构，命名为 PVANET，它实现了实时目标检测性能而不损失准确性。</p><ol class=""><li id="6972" class="mr ms iq kz b la lb ld le lg mt lk mu lo mv ls mw mx my mz bi translated"><strong class="kz ir"> <em class="lt">计算成本</em></strong>:1065 x640 输入的特征提取 7.9GMAC</li><li id="eeb5" class="mr ms iq kz b la na ld nb lg nc lk nd lo ne ls mw mx my mz bi translated"><strong class="kz ir"> <em class="lt">运行时性能</em> </strong>:英特尔 i7 上 750 毫秒/图像(1.3FPS)，NVIDIA Titan X GPU 上 42 毫秒/图像(21.7FPS)</li><li id="13f0" class="mr ms iq kz b la na ld nb lg nc lk nd lo ne ls mw mx my mz bi translated"><strong class="kz ir"> <em class="lt">精度</em></strong>:VOC-2007 上 83.8% mAP；VOC-2012 的 82.5% mAP</li></ol><p id="459b" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated"><strong class="kz ir">关键的设计原则是“少通道多层次”。</strong></p><p id="3bc3" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">此外，该网络还采用了其他一些构件:</p><ol class=""><li id="5f96" class="mr ms iq kz b la lb ld le lg mt lk mu lo mv ls mw mx my mz bi translated">级联校正线性单元(C.ReLU)应用于我们的细胞神经网络的早期阶段，以在不损失精度的情况下将计算量减少一半。</li><li id="d3f8" class="mr ms iq kz b la na ld nb lg nc lk nd lo ne ls mw mx my mz bi translated">初始应用于我们特征生成子网络的剩余部分</li><li id="bc6b" class="mr ms iq kz b la na ld nb lg nc lk nd lo ne ls mw mx my mz bi translated">采用了多尺度表示的概念，它结合了几个中间输出，以便可以同时考虑多层次的细节和非线性。</li></ol><h1 id="62aa" class="lu lv iq bd lw lx ly lz ma mb mc md me jw mf jx mg jz mh ka mi kc mj kd mk ml bi translated">方法</h1><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nf"><img src="../Images/55ade68b2c352e2c74541428a79022d9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Cu576tIcuoyWCUY0C3ZhpA.png"/></div></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk"><strong class="bd kw">Fig 2. Model Architecture</strong></figcaption></figure><h2 id="4e7a" class="ng lv iq bd lw nh ni dn ma nj nk dp me lg nl nm mg lk nn no mi lo np nq mk nr bi translated">级联整流线性单元</h2><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ns"><img src="../Images/dbba45f774928be93934f306e24a8e9c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*UHTzLbxJUWCmFj0TdnHxng.png"/></div></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk"><strong class="bd kw">Fig 3. Concatenated Rectified Linear Unit (C.ReLU)</strong></figcaption></figure><p id="40e3" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">C.ReLU 的动机是观察到，在早期阶段，输出节点往往是成对的，这样一个节点的激活是另一个的相反侧。C.ReLU 将输出通道的数量减少了一半，通过简单地将相同的输出与否定连接起来，使其增加了一倍，从而使早期阶段的速度提高了 2 倍。</p><h2 id="57d6" class="ng lv iq bd lw nh ni dn ma nj nk dp me lg nl nm mg lk nn no mi lo np nq mk nr bi translated">开始</h2><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nt"><img src="../Images/9d6435bf1eb040ef04f9819141a6a9b7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*2h0Ud_IqPWtlTvU_AMdylA.png"/></div></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk"><strong class="bd kw">Fig4. The Inception Module</strong></figcaption></figure><p id="9482" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">对于捕获大对象和小对象来说，Inception 可能是最具成本效益的构建块之一。他们用 2 个 3x3 取代了普通先启块中的 5x5 卷积。</p><h2 id="f4c8" class="ng lv iq bd lw nh ni dn ma nj nk dp me lg nl nm mg lk nn no mi lo np nq mk nr bi translated">超级网络</h2><p id="b1a9" class="pw-post-body-paragraph kx ky iq kz b la mm jr lc ld mn ju lf lg mo li lj lk mp lm ln lo mq lq lr ls ij bi translated">多尺度表示及其组合在许多深度学习任务中被证明是有效的。在特征提取层将细粒度的细节和高度抽象的信息结合起来，有助于后续的区域建议网络和分类网络检测不同尺度的目标。</p><p id="0aaa" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">它们组合了<br/> 1)最后一层<br/> 2)两个中间层，其规模分别是最后一层的 2x 和 4x。</p><h2 id="194c" class="ng lv iq bd lw nh ni dn ma nj nk dp me lg nl nm mg lk nn no mi lo np nq mk nr bi translated">深度网络培训</h2><p id="41cc" class="pw-post-body-paragraph kx ky iq kz b la mm jr lc ld mn ju lf lg mo li lj lk mp lm ln lo mq lq lr ls ij bi translated">为了更好的训练，他们采用了剩余的结构。他们将剩余连接添加到初始层，以稳定深层网络的后期部分。</p><p id="de45" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">在所有 ReLU 激活层之前添加批处理规范化层。</p><p id="7de4" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">他们使用的学习率策略是基于平台检测，他们根据损失的移动平均值检测平台，如果低于某个阈值，他们会以某个系数降低学习率。</p><h2 id="578f" class="ng lv iq bd lw nh ni dn ma nj nk dp me lg nl nm mg lk nn no mi lo np nq mk nr bi translated">使用 PVANET 实现更快的 R-CNN</h2><p id="f84d" class="pw-post-body-paragraph kx ky iq kz b la mm jr lc ld mn ju lf lg mo li lj lk mp lm ln lo mq lq lr ls ij bi translated">conv3_4、conv4_4 和 conv5_4 的三个中间输出合并成 512 通道多电平输出特性，并馈入更快的 RCNN 模块</p><h1 id="c3ef" class="lu lv iq bd lw lx ly lz ma mb mc md me jw mf jx mg jz mh ka mi kc mj kd mk ml bi translated">结果</h1><ol class=""><li id="33cf" class="mr ms iq kz b la mm ld mn lg nu lk nv lo nw ls mw mx my mz bi translated">使用 ILSVRC2012 训练图像对 PVANET 进行预处理，用于 1000 类图像分类。</li><li id="0a9b" class="mr ms iq kz b la na ld nb lg nc lk nd lo ne ls mw mx my mz bi translated">所有图像的尺寸都调整为 256×256，192×192 的小块被随机裁剪并用作网络输入。</li><li id="fb5a" class="mr ms iq kz b la na ld nb lg nc lk nd lo ne ls mw mx my mz bi translated">学习率最初设置为 0.1，然后每当检测到平稳状态时，以 1/sqrt(10) ~ 0.3165 的因子减少。</li><li id="c259" class="mr ms iq kz b la na ld nb lg nc lk nd lo ne ls mw mx my mz bi translated">如果学习率下降到 1e-4 以下(这通常需要大约 2M 迭代)，则预训练终止</li><li id="f3b3" class="mr ms iq kz b la na ld nb lg nc lk nd lo ne ls mw mx my mz bi translated">然后用 MS-COCO trainval、VOC2007 trainval、VOC2012 trainval 的联合集对 PVANET 进行训练。之后还需要对 VOC2007 trainval 和 VOC2012 trainval 进行微调，因为 MS-COCO 和 VOC 的类定义略有不同。</li><li id="4cde" class="mr ms iq kz b la na ld nb lg nc lk nd lo ne ls mw mx my mz bi translated">随机调整训练图像的大小，使图像的短边介于 416 和 864 之间。</li><li id="363b" class="mr ms iq kz b la na ld nb lg nc lk nd lo ne ls mw mx my mz bi translated">对于 PASCAL VOC 评估，调整每个输入图像的大小，使其短边为 640。</li><li id="7f4f" class="mr ms iq kz b la na ld nb lg nc lk nd lo ne ls mw mx my mz bi translated">除了在非最大抑制(NMS) (=12000)和 NMS 阈值(=0.4)之前的建议框的数量之外，与更快的 R-CNN 相关的所有参数都被设置为原始工作中的参数</li><li id="5adf" class="mr ms iq kz b la na ld nb lg nc lk nd lo ne ls mw mx my mz bi translated">所有评估均在单核英特尔 i7 和 NVIDIA Titan X GPU 上完成。</li></ol><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nx"><img src="../Images/4ebb4539990c08d4f0f7db6abf5aef84.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Zhs7oOLbK8YLLFxC9cQ71A.png"/></div></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk"><strong class="bd kw">Fig 5. Performance with VOC2007</strong></figcaption></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ny"><img src="../Images/a8091479ec53d10293285fde6084fc47.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*-CQbgigiAR3_F45qsV-f-Q.png"/></div></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk"><strong class="bd kw">Fig 6.Performance with VOC2012</strong></figcaption></figure><p id="423f" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">PVANET+在 PASCAL VOC 2012 挑战赛中获得第二名。第一个是比 PVANET 重得多的更快的 RCNN + ResNet101。</p></div><div class="ab cl nz oa hu ob" role="separator"><span class="oc bw bk od oe of"/><span class="oc bw bk od oe of"/><span class="oc bw bk od oe"/></div><div class="ij ik il im in"><h1 id="6d76" class="lu lv iq bd lw lx og lz ma mb oh md me jw oi jx mg jz oj ka mi kc ok kd mk ml bi translated">参考</h1><ol class=""><li id="fbd7" class="mr ms iq kz b la mm ld mn lg nu lk nv lo nw ls mw mx my mz bi translated">金敬姬、S. Hong、B. Roh、Y. Cheon 和 M. Park。PVANET:用于实时对象检测的深度但轻量级的神经网络。arXiv 预印本 arXiv:1608.08021，2016。</li><li id="1499" class="mr ms iq kz b la na ld nb lg nc lk nd lo ne ls mw mx my mz bi translated"><em class="lt">克里斯蒂安·塞格迪、贾、皮埃尔·塞尔马内、斯科特·里德、德拉戈米尔·安盖洛夫、杜米特鲁·埃汉、文森特·万霍克和安德鲁·拉宾诺维奇。用回旋越走越深。IEEE 计算机视觉和模式识别国际会议(CVPR)论文集，2015 年。</em></li><li id="e0ef" class="mr ms iq kz b la na ld nb lg nc lk nd lo ne ls mw mx my mz bi translated"><em class="lt">何、、、任、。用于图像识别的深度残差学习。IEEE 计算机视觉与模式识别国际会议(CVPR)论文集，2016。</em></li><li id="dabd" class="mr ms iq kz b la na ld nb lg nc lk nd lo ne ls mw mx my mz bi translated"><em class="lt">孔涛，姚安邦，，孙富春。面向精确区域提议生成和联合目标检测的超网络。IEEE 计算机视觉和模式识别国际会议(CVPR)论文集，2016 年。</em></li></ol></div><div class="ab cl nz oa hu ob" role="separator"><span class="oc bw bk od oe of"/><span class="oc bw bk od oe of"/><span class="oc bw bk od oe"/></div><div class="ij ik il im in"><blockquote class="ol"><p id="d957" class="om on iq bd oo op oq or os ot ou ls dk translated">感谢阅读！一定要看报纸。如果我发现更多有趣的见解，我会更新。</p></blockquote></div></div>    
</body>
</html>