<html>
<head>
<title>Artificial Intelligence &amp; Paleontology: Use Deep Learning to search for Microfossils</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">人工智能和古生物学:利用深度学习搜索微体化石</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/artificial-intelligence-paleontology-use-deep-learning-to-search-for-microfossils-18760bb30880?source=collection_archive---------13-----------------------#2019-06-07">https://towardsdatascience.com/artificial-intelligence-paleontology-use-deep-learning-to-search-for-microfossils-18760bb30880?source=collection_archive---------13-----------------------#2019-06-07</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="1288" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">如何用语义分割分析从钻机探头获得的沉积岩微断层图像</h2></div><p id="8349" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在这篇文章中，我们展示了一种基于深度学习的方法，用于通过 MicroCT 获取的钻孔岩心样本中的全自动微体化石识别和提取。对于鉴定，我们开发了一种深度学习方法，这种方法导致了高正确微化石鉴定率(98% IoU)。为了验证这一点，我们使用了微体古生物领域的专家们得出的基本事实。我们还提出了第一个完全注释的 MicroCT 获得的公开可用的微体化石数据集。</p></div><div class="ab cl le lf hx lg" role="separator"><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj"/></div><div class="im in io ip iq"><h2 id="c1d5" class="ll lm it bd ln lo lp dn lq lr ls dp lt kr lu lv lw kv lx ly lz kz ma mb mc md bi translated">人工智能和古生物学</h2><p id="1f82" class="pw-post-body-paragraph ki kj it kk b kl me ju kn ko mf jx kq kr mg kt ku kv mh kx ky kz mi lb lc ld im bi translated">古生物图像的计算分析的应用范围从动物、植物和微生物进化的研究到给定时代生物栖息地的模拟。</p><p id="5254" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">但是现在古生物学不再仅仅是一门纯科学了。它还可以应用于解决经济活动领域中的问题，例如石油勘探，其中有几个因素需要分析，以便识别勘探地点的潜力并最小化与石油开采过程相关的费用。一个因素是要探索的环境的特征。这种分析可以通过几种方式进行:使用探针、提取样品进行岩石物理成分评估或与其他钻井的测井记录进行对比。</p><p id="04f0" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">当我们研究样本提取时，在沉积岩中发现的化石对于这种岩石的表征至关重要。在这里，计算机断层扫描(CT)是重要的，因为它保存样本，并使其可用于几次分析。基于由 CT 生成的 3D 图像，可以执行若干分析和模拟，并且可以自动执行当前手动且费力执行的过程。</p><p id="ca4e" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">想象一下下面的场景:一个古生物学家收到一个含有微化石的岩石样本进行分析。人工分离微生物化石的整个过程需要很长时间，并且在这个过程之后，岩石样品被破坏。在此之后，古生物学家将使用显微镜对物理隔离的微化石进行分析，并对每个隔离的化石进行人工分类。</p><figure class="mk ml mm mn gt mo gh gi paragraph-image"><div role="button" tabindex="0" class="mp mq di mr bf ms"><div class="gh gi mj"><img src="../Images/c127acc6f51cd09c40c22efe5973b668.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*fg9pBoKrxePwvjOqGHFFKA.png"/></div></div><figcaption class="mv mw gj gh gi mx my bd b be z dk">A few microfossils manually extracted from our carbonatic rocks and photographed with a Z-stack microscope</figcaption></figure><p id="11c0" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">现在让我们假设这位古生物学家工作的公司获得了一种基于人工智能的断层图像分析软件，专门用于微化石分析。该软件在最少或根本没有监督的情况下，自动从岩石样品中进行微生物化石鉴定和提取。古生物学家现在可以加载他的断层扫描样本，选择特定的管道，并让程序在夜间执行，只让古生物学家评估获得的结果并对每个提取的微化石进行分类。</p><figure class="mk ml mm mn gt mo gh gi paragraph-image"><div role="button" tabindex="0" class="mp mq di mr bf ms"><div class="gh gi mz"><img src="../Images/bb3a79ad19f14ef2094e7084aa709af8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*9ZFHMA4yYEIaArgn.png"/></div></div><figcaption class="mv mw gj gh gi mx my bd b be z dk">The before &amp; after of microfossil analysis…</figcaption></figure></div><div class="ab cl le lf hx lg" role="separator"><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj"/></div><div class="im in io ip iq"><h2 id="60a2" class="ll lm it bd ln lo lp dn lq lr ls dp lt kr lu lv lw kv lx ly lz kz ma mb mc md bi translated">基于深度学习的微体化石识别和分类</h2><p id="72ae" class="pw-post-body-paragraph ki kj it kk b kl me ju kn ko mf jx kq kr mg kt ku kv mh kx ky kz mi lb lc ld im bi translated">你可以通过深度学习采用语义分割来执行上述工作流。让我们看看如何…</p><p id="2c29" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我们采用了一个扫描的碳酸盐岩样品，该样品是从巴西东北海岸的<a class="ae na" href="http://www.anp.gov.br/images/Palestras/Seminario_tecnico_R15_P4/Ingles/03_Bacia_de_Sergipe-Alagoas_R15_INGLES.pdf" rel="noopener ugc nofollow" target="_blank"> Sergipe 盆地第四纪沉积物处采集的钻机探针获得的。为了训练我们的语义分割网络，一个微体学家团队为这个岩石样本生成了一个地面真相，对整个 MicroCT 体积进行手动分割和分类。用于数字化样品的扫描仪是 Versa XRM-500 (ZEISS/XRadia)，体积大小为 956×1004×983 体素。</a></p><p id="5397" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">完整的数据集，加上额外的解释和专家注释的手动分割图像的基本事实可以在这里找到:【http://www.lapix.ufsc.br/microfossil-segmentation<a class="ae na" href="http://www.lapix.ufsc.br/microfossil-segmentation" rel="noopener ugc nofollow" target="_blank"/>。</p><figure class="mk ml mm mn gt mo gh gi paragraph-image"><div class="gh gi nb"><img src="../Images/05cf4582b7dc479c6e6cc57c96aafd50.png" data-original-src="https://miro.medium.com/v2/resize:fit:452/format:webp/0*ez286YlLnXJXyZv-.png"/></div><figcaption class="mv mw gj gh gi mx my bd b be z dk">Digitalized rock sample</figcaption></figure><p id="e002" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我们采用的深度学习 API 是 fast.ai/PyTorch 框架，通过超参数优化(HYPO)，我们用 UNET + ResNet34(或 ResNet50)获得了 0.98 的 IoU。不同种类的海波在这里很重要，我们将在下面解释它们。</p><p id="2bf4" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="kk iu">海波#1:可变分辨率</strong>。MicroCT 数据提出了一个挑战:由我们使用的数据集大小和 UNET 体系结构强加的内存需求将极大地限制我们训练集的批量大小。为了克服这一限制，并能够最初处理更大的批量，以更快的速度训练网络，我们采用了一种<strong class="kk iu"> <em class="nc">逐步渐进提高图像分辨率的训练策略</em> </strong>。</p><p id="70c0" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">为此目的，我们在<strong class="kk iu">三个周期</strong>中进行训练:我们以原始 MicroCT 图像分辨率的 1/4 开始我们的迁移学习；训练了模型；将数据集的大小调整为原始分辨率的 1/2；再次训练，之后，我们采用全 CT 体积分辨率进行最终微调训练周期。这一战略的大纲最初是由杰瑞米·霍华德于 2018 年 5 月在<a class="ae na" href="https://www.fast.ai/2018/04/30/dawnbench-fastai/" rel="noopener ugc nofollow" target="_blank">这个讨论帖子</a>中提出的，后来在<a class="ae na" href="https://course.fast.ai/videos/?lesson=1" rel="noopener ugc nofollow" target="_blank">https://course.fast.ai/videos/?lesson=1</a>的一次 CNN 演讲中作为非正式交流提出的。下图显示了我们对逐步提高分辨率培训工作流程的解释。</p><figure class="mk ml mm mn gt mo gh gi paragraph-image"><div class="gh gi nd"><img src="../Images/cc0142026c86e345da47d1d5a1d82912.png" data-original-src="https://miro.medium.com/v2/resize:fit:1086/format:webp/1*1MTSujPanU74vaKM1wA12g.png"/></div><figcaption class="mv mw gj gh gi mx my bd b be z dk">The <strong class="bd ne"><em class="nf">step-wise progressive improving image resolution training strategy</em></strong></figcaption></figure><p id="2c61" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="kk iu"> HYPO #2:差异学习率</strong>:另一个微调我们模型的策略是<em class="nc">差异学习率</em> (DLR)策略，也是由杰瑞米·霍华德在同一个 fast.ai 课程系列的讲座中非正式提出的。</p><p id="b34e" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">当执行迁移学习并随后进行微调时，在第一层中，被调整的预训练模型将从迁移学习中使用的新数据集学习一般的低级特征。不管图像背景如何，这些低级特征很可能与原始数据集的特征相似。因此，没有必要在这些第一层采用高学习率。随着信息在网络中的深入，特征组合变得更加复杂和特定于数据集，并且与应用环境的联系更加直接。为了使网络更好地适应特定于上下文的特征，需要在更深的层中有更高的学习速率。</p><p id="3e31" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="kk iu"> HYPO # 3: Fit1Cycle </strong>:我们采用 Leslie N. Smith 最初开发的<em class="nc"> fit1cycle </em>方法训练网络；</p><ul class=""><li id="8365" class="ng nh it kk b kl km ko kp kr ni kv nj kz nk ld nl nm nn no bi translated"><a class="ae na" href="https://docs.fast.ai/callbacks.one_cycle.html" rel="noopener ugc nofollow" target="_blank">https://docs.fast.ai/callbacks.one_cycle.html</a></li><li id="c33d" class="ng nh it kk b kl np ko nq kr nr kv ns kz nt ld nl nm nn no bi translated">神经网络超参数的训练方法:第 1 部分——学习速率、批量大小、动量和权重衰减—<a class="ae na" href="https://arxiv.org/abs/1803.09820" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/abs/1803.09820</a></li><li id="5f2d" class="ng nh it kk b kl np ko nq kr nr kv ns kz nt ld nl nm nn no bi translated">超收敛:使用大学习率快速训练残差网络—<a class="ae na" href="https://arxiv.org/abs/1708.07120" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/abs/1708.07120</a></li><li id="e49b" class="ng nh it kk b kl np ko nq kr nr kv ns kz nt ld nl nm nn no bi translated">有一篇来自<a class="ae na" href="https://towardsdatascience.com/@nachiket.tanksale" rel="noopener" target="_blank"> Nachiket Tanksale </a>的非常有趣的文章，名为<a class="ae na" rel="noopener" target="_blank" href="/finding-good-learning-rate-and-the-one-cycle-policy-7159fe1db5d6">寻找好的学习率和一个周期政策</a>，其中讨论了周期学习率和动量。</li></ul><p id="05fa" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">这种方法<em class="nc">快</em>，它将允许我们在第一个迁移学习阶段只使用 5 个时期。</p><p id="0015" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">如果你想了解更多关于 fastai 图书馆新的学习 API 的信息，请看这本由 Sylvain Gugger 准备的笔记本。</p></div><div class="ab cl le lf hx lg" role="separator"><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj"/></div><div class="im in io ip iq"><h1 id="5510" class="nu lm it bd ln nv nw nx lq ny nz oa lt jz ob ka lw kc oc kd lz kf od kg mc oe bi translated">动手吧！碳酸盐岩中微体化石的分段</h1><p id="d2ad" class="pw-post-body-paragraph ki kj it kk b kl me ju kn ko mf jx kq kr mg kt ku kv mh kx ky kz mi lb lc ld im bi translated">以下是从碳酸盐岩中获得的微 CT 钻孔岩心中的微化石样品的语义分段代码。这是我们作为笔记本发布的代码(<a class="ae na" href="https://github.com/awangenh/Segmentation-of-Microfossils-in-Carbonatic-Rocks" rel="noopener ugc nofollow" target="_blank">https://github . com/awangenh/Segmentation-of-micro fossils-in-Carbonatic-Rocks</a>)，它假设您要么使用 Google Colab，要么安装了最新版本的 PyTorch 和 fast.ai。你还需要一个至少有 11 GB 内存的 GPU。</p><h2 id="9c28" class="ll lm it bd ln lo lp dn lq lr ls dp lt kr lu lv lw kv lx ly lz kz ma mb mc md bi translated">初始化，导入 Python 库和 fast.ai 框架</h2><pre class="mk ml mm mn gt of og oh oi aw oj bi"><span id="56fb" class="ll lm it og b gy ok ol l om on"># Notebook Initializations<br/>%reload_ext autoreload<br/>%autoreload 2<br/>%matplotlib inline</span><span id="a91a" class="ll lm it og b gy oo ol l om on"># Imports<br/>from fastai.vision import *<br/>from fastai.utils.show_install import *<br/>from fastai.callbacks.hooks import *<br/>from pathlib import Path<br/>torch.backends.cudnn.benchmark=True</span><span id="9416" class="ll lm it og b gy oo ol l om on"># Show if everything is OK<br/>show_install()</span></pre><h1 id="77fa" class="nu lm it bd ln nv op nx lq ny oq oa lt jz or ka lw kc os kd lz kf ot kg mc oe bi translated">定义存储数据的位置并检查它</h1><h2 id="5c2b" class="ll lm it bd ln lo lp dn lq lr ls dp lt kr lu lv lw kv lx ly lz kz ma mb mc md bi translated">如果你将 Google Colab 与 Google Drive 一起使用，请这样做</h2><pre class="mk ml mm mn gt of og oh oi aw oj bi"><span id="a498" class="ll lm it og b gy ok ol l om on">from google.colab import drive<br/>drive.mount('/content/gdrive')</span><span id="f557" class="ll lm it og b gy oo ol l om on">path = Path('gdrive/My Drive/Colab Notebooks/DL/')<br/>path.ls()</span></pre><h2 id="3b12" class="ll lm it bd ln lo lp dn lq lr ls dp lt kr lu lv lw kv lx ly lz kz ma mb mc md bi translated">如果您没有从 Google Drive 导入数据</h2><pre class="mk ml mm mn gt of og oh oi aw oj bi"><span id="06f2" class="ll lm it og b gy ok ol l om on"># Adapt this to match your environment...<br/>path = Path('myPath/')<br/>path.ls()</span></pre><h2 id="243f" class="ll lm it bd ln lo lp dn lq lr ls dp lt kr lu lv lw kv lx ly lz kz ma mb mc md bi translated">定义数据变量，如 path_lbl(标签所在的本地)和 path_img(存储训练和验证数据的本地)</h2><pre class="mk ml mm mn gt of og oh oi aw oj bi"><span id="addd" class="ll lm it og b gy ok ol l om on"># Initialize path_lbl (local where your labels are) <br/>path_lbl = path/'train_masks_labels'<br/># Initialize path_img (local where your train and validation data are stored)<br/>path_img = path/'train'</span><span id="ea81" class="ll lm it og b gy oo ol l om on"># Check how many files are there<br/>fnames = get_image_files(path_img)<br/>fnames[:3]<br/>len(fnames)</span><span id="1bed" class="ll lm it og b gy oo ol l om on"># Check if label names match the size<br/>lbl_names = get_image_files(path_lbl)<br/>lbl_names[:3]<br/>len(lbl_names)</span></pre><h2 id="20ee" class="ll lm it bd ln lo lp dn lq lr ls dp lt kr lu lv lw kv lx ly lz kz ma mb mc md bi translated">显示单个 MicroCT 切片</h2><pre class="mk ml mm mn gt of og oh oi aw oj bi"><span id="1556" class="ll lm it og b gy ok ol l om on">img_f = fnames[0]<br/>img = open_image(img_f)<br/>img.show(figsize=(5,5))</span></pre><figure class="mk ml mm mn gt mo gh gi paragraph-image"><div class="gh gi ou"><img src="../Images/9c2724aae370421931bca5bf4daf5065.png" data-original-src="https://miro.medium.com/v2/resize:fit:648/format:webp/1*mtEhtzto_lUH3tegSUhrzQ.png"/></div></figure><h2 id="2613" class="ll lm it bd ln lo lp dn lq lr ls dp lt kr lu lv lw kv lx ly lz kz ma mb mc md bi translated">加载属于该特定切片的遮罩</h2><pre class="mk ml mm mn gt of og oh oi aw oj bi"><span id="31c1" class="ll lm it og b gy ok ol l om on"># Scan the filenames with a simple lambda function<br/>get_y_fn = lambda x: path_lbl/f'{x.stem}_GT{x.suffix}'</span></pre><h2 id="faee" class="ll lm it bd ln lo lp dn lq lr ls dp lt kr lu lv lw kv lx ly lz kz ma mb mc md bi translated">显示地面真相遮罩</h2><pre class="mk ml mm mn gt of og oh oi aw oj bi"><span id="3a95" class="ll lm it og b gy ok ol l om on">mask = open_mask(get_y_fn(img_f))<br/>mask.show(figsize=(5,5), alpha=1)<br/>src_size = np.array(mask.shape[1:])</span></pre><figure class="mk ml mm mn gt mo gh gi paragraph-image"><div class="gh gi ou"><img src="../Images/9659197e31c940773efbac34c13e1473.png" data-original-src="https://miro.medium.com/v2/resize:fit:648/format:webp/1*4GgU0BNlEv7e5zEJlcg1tg.png"/></div></figure><h2 id="ccd4" class="ll lm it bd ln lo lp dn lq lr ls dp lt kr lu lv lw kv lx ly lz kz ma mb mc md bi translated">加载您的标签</h2><pre class="mk ml mm mn gt of og oh oi aw oj bi"><span id="5c40" class="ll lm it og b gy ok ol l om on">codes = np.loadtxt(path/'codes.txt', dtype=str); codes</span></pre><h2 id="fd66" class="ll lm it bd ln lo lp dn lq lr ls dp lt kr lu lv lw kv lx ly lz kz ma mb mc md bi translated">IOU 指标、初始数据分割和模型</h2><pre class="mk ml mm mn gt of og oh oi aw oj bi"><span id="932b" class="ll lm it og b gy ok ol l om on"># Refer to your labels as numbers<br/>name2id = {v:k for k,v in enumerate(codes)}</span></pre><h2 id="89e9" class="ll lm it bd ln lo lp dn lq lr ls dp lt kr lu lv lw kv lx ly lz kz ma mb mc md bi translated">定义您的误差指标</h2><p id="fbf0" class="pw-post-body-paragraph ki kj it kk b kl me ju kn ko mf jx kq kr mg kt ku kv mh kx ky kz mi lb lc ld im bi translated">并集上的交集(IOU)度量和保存预测定义的函数</p><pre class="mk ml mm mn gt of og oh oi aw oj bi"><span id="a931" class="ll lm it og b gy ok ol l om on">def iou_metric(input, target):<br/>    target = target.squeeze(1)<br/>    mask = target != 0<br/>    return (input.argmax(dim=1)[mask]==target[mask]).float().mean()</span><span id="a7f1" class="ll lm it og b gy oo ol l om on">def save_preds(dl):<br/>    i=0<br/>    names = dl.dataset.items</span><span id="320e" class="ll lm it og b gy oo ol l om on">    for b in dl:<br/>      preds = learn.pred_batch(batch=b, reconstruct=True)<br/>      for o in preds:<br/>          o.save(path_gen/names[i].name)<br/>          i += 1</span></pre><h2 id="c095" class="ll lm it bd ln lo lp dn lq lr ls dp lt kr lu lv lw kv lx ly lz kz ma mb mc md bi translated">更多的定义</h2><p id="5ee1" class="pw-post-body-paragraph ki kj it kk b kl me ju kn ko mf jx kq kr mg kt ku kv mh kx ky kz mi lb lc ld im bi translated">重量衰减、度量、模型的定义，如果我们使用 imageNet 重量</p><pre class="mk ml mm mn gt of og oh oi aw oj bi"><span id="eede" class="ll lm it og b gy ok ol l om on">wd=1e-2<br/>metrics = iou_metric</span><span id="a3a3" class="ll lm it og b gy oo ol l om on"># Use a deep network<br/>used_model=models.resnet101</span><span id="3b74" class="ll lm it og b gy oo ol l om on"># We will employ transfer learning from ImageNet weights...<br/>useImageNet=True</span></pre><h1 id="1b32" class="nu lm it bd ln nv op nx lq ny oq oa lt jz or ka lw kc os kd lz kf ot kg mc oe bi translated">培训周期和验证</h1><p id="b288" class="pw-post-body-paragraph ki kj it kk b kl me ju kn ko mf jx kq kr mg kt ku kv mh kx ky kz mi lb lc ld im bi translated"><strong class="kk iu">这里</strong>是我们开始训练部分的地方。首先，我们采用 256x252(1/4)分辨率。对于 512 (1/2)和 1024(全)分辨率，执行完全相同的顺序。</p><h1 id="d518" class="nu lm it bd ln nv op nx lq ny oq oa lt jz or ka lw kc os kd lz kf ot kg mc oe bi translated">周期#1: 256x256</h1><pre class="mk ml mm mn gt of og oh oi aw oj bi"><span id="d3fb" class="ll lm it og b gy ok ol l om on"># Define the batch size and the resolution employed</span><span id="2f9b" class="ll lm it og b gy oo ol l om on">size = src_size//4<br/>size[1]= size[1]+1<br/>bs=5</span></pre><p id="08c5" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">对数据应用转换，如分辨率更改和数据扩充…</p><pre class="mk ml mm mn gt of og oh oi aw oj bi"><span id="c5d8" class="ll lm it og b gy ok ol l om on">normalizePar=None</span><span id="c313" class="ll lm it og b gy oo ol l om on">if useImageNet:<br/>  normalizePar=imagenet_stats</span><span id="e6e9" class="ll lm it og b gy oo ol l om on">data = (src.transform(get_transforms(), size=size, tfm_y=True)<br/>        .databunch(bs=bs)<br/>        .normalize(normalizePar))</span></pre><p id="7006" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">用所选的数据、度量和重量衰减加载模型</p><pre class="mk ml mm mn gt of og oh oi aw oj bi"><span id="d744" class="ll lm it og b gy ok ol l om on">learn = unet_learner(data, used_model, metrics=metrics, wd=wd)</span></pre><p id="dbbf" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">找到最合适的学习速度</p><pre class="mk ml mm mn gt of og oh oi aw oj bi"><span id="03f8" class="ll lm it og b gy ok ol l om on">lr_find(learn)<br/>learn.recorder.plot()</span></pre><figure class="mk ml mm mn gt mo gh gi paragraph-image"><div class="gh gi ov"><img src="../Images/0489015ae3b9fcf284e820da0cb133c0.png" data-original-src="https://miro.medium.com/v2/resize:fit:812/format:webp/1*bzTlveCEQ6CV5AnEFHQqmA.png"/></div></figure><p id="1d4c" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="kk iu"> <em class="nc">手动</em> </strong>检查上面代码生成的图形后设置学习率…</p><pre class="mk ml mm mn gt of og oh oi aw oj bi"><span id="85b5" class="ll lm it og b gy ok ol l om on"># Adjust this LR accordingly to what you identified above...<br/>lr=2e-4</span></pre><h2 id="b39c" class="ll lm it bd ln lo lp dn lq lr ls dp lt kr lu lv lw kv lx ly lz kz ma mb mc md bi translated">学习！</h2><pre class="mk ml mm mn gt of og oh oi aw oj bi"><span id="3bd5" class="ll lm it og b gy ok ol l om on">learn.fit_one_cycle(5, slice(lr), pct_start=0.9)</span></pre><p id="c703" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">保存重量并加载它以继续训练并执行一些数据发布…</p><pre class="mk ml mm mn gt of og oh oi aw oj bi"><span id="60a5" class="ll lm it og b gy ok ol l om on">learn.save('stage1-256x252')</span></pre><p id="46bf" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">保留一个装载代码，以备不时之需:</p><pre class="mk ml mm mn gt of og oh oi aw oj bi"><span id="e15f" class="ll lm it og b gy ok ol l om on">learn.load('stage1-256x252')</span></pre><p id="088b" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">解冻网络以学习内部权重——在第 1 周期微调</p><pre class="mk ml mm mn gt of og oh oi aw oj bi"><span id="0039" class="ll lm it og b gy ok ol l om on">learn.unfreeze()</span></pre><p id="2de9" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">采用差异学习率(DLR)并培训学习者</p><pre class="mk ml mm mn gt of og oh oi aw oj bi"><span id="b306" class="ll lm it og b gy ok ol l om on">lrs = slice(lr/400,lr/4)</span><span id="55b2" class="ll lm it og b gy oo ol l om on">learn.fit_one_cycle(10, lrs, pct_start=0.8)</span></pre><p id="4a0a" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">保存重量和加载它继续训练和执行一些未使用的内存释放…</p><pre class="mk ml mm mn gt of og oh oi aw oj bi"><span id="9658" class="ll lm it og b gy ok ol l om on"># Save the fine-tuned network @ Cycle #1<br/>learn.save('stage2-256x252')</span><span id="fca8" class="ll lm it og b gy oo ol l om on"># Release Memory<br/>del data<br/>del learn<br/>torch.cuda.empty_cache()<br/># Collect Garbage<br/>gc.collect()</span></pre><h1 id="9a8b" class="nu lm it bd ln nv op nx lq ny oq oa lt jz or ka lw kc os kd lz kf ot kg mc oe bi translated">周期#2: 512x512</h1><p id="f1ed" class="pw-post-body-paragraph ki kj it kk b kl me ju kn ko mf jx kq kr mg kt ku kv mh kx ky kz mi lb lc ld im bi translated">我们将如上执行相同的操作，只是分辨率为 512x512</p><pre class="mk ml mm mn gt of og oh oi aw oj bi"><span id="3627" class="ll lm it og b gy ok ol l om on"># Set the new Size for the MicroCT Slices<br/>size = src_size//2<br/>bs=1</span><span id="d673" class="ll lm it og b gy oo ol l om on"># Adapt ImageNet Parameters to our Image Characteristics<br/>normalizePar=None<br/>if useImageNet:<br/>    normalizePar=imagenet_stats<br/>data = (src.transform(get_transforms(), size=size, tfm_y=True)<br/>        .databunch(bs=bs)<br/>        .normalize(normalizePar))</span><span id="7cd1" class="ll lm it og b gy oo ol l om on"># Create a new Network for 512x512 input images<br/>learn = unet_learner(data, used_model, metrics=metrics, wd=wd)</span><span id="e533" class="ll lm it og b gy oo ol l om on"># Load our fine-tuned low resolution network weights learned on Cycle #1...<br/>learn.load('stage2-256x252')</span><span id="4509" class="ll lm it og b gy oo ol l om on"># Find the best learning rate for this network instance<br/>lr_find(learn)<br/>learn.recorder.plot()</span><span id="f457" class="ll lm it og b gy oo ol l om on"># Manually set the new learning rate (LOOK at the graph above!)<br/>lr=1e-3</span></pre><p id="f104" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">使用这个新的中等分辨率网络执行迁移学习阶段。我们将再次使用莱斯利·n·史密斯开发的<em class="nc"> fit1cycle </em>方法。</p><pre class="mk ml mm mn gt of og oh oi aw oj bi"><span id="a7e5" class="ll lm it og b gy ok ol l om on">learn.fit_one_cycle(5, slice(lr), pct_start=0.8)</span><span id="5f53" class="ll lm it og b gy oo ol l om on"># Save and Load...<br/>learn.save('stage1-512x502')</span><span id="a61a" class="ll lm it og b gy oo ol l om on">learn.load('stage1-512x502')</span><span id="cee9" class="ll lm it og b gy oo ol l om on"># Unfreeze for fine-tuning...<br/>learn.unfreeze()</span></pre><p id="5d5c" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">采用差异学习率(DLR)并培训学习者</p><pre class="mk ml mm mn gt of og oh oi aw oj bi"><span id="3f85" class="ll lm it og b gy ok ol l om on"># Prepare for varying learning rates...<br/>lrs = slice(1e-6,lr/10)</span><span id="574d" class="ll lm it og b gy oo ol l om on"># Fine-tune for 10 epochs<br/>learn.fit_one_cycle(10, lrs)</span><span id="de63" class="ll lm it og b gy oo ol l om on"># SAVE STAGE2 OF CYCLE #2...<br/>learn.save('stage2-512x502')</span><span id="d5b6" class="ll lm it og b gy oo ol l om on"># Flush garbage..<br/>del data<br/>del learn<br/>torch.cuda.empty_cache()<br/>gc.collect()</span></pre><h1 id="7601" class="nu lm it bd ln nv op nx lq ny oq oa lt jz or ka lw kc os kd lz kf ot kg mc oe bi translated">周期# 3:1024 x 1024-全分辨率培训</h1><p id="83b9" class="pw-post-body-paragraph ki kj it kk b kl me ju kn ko mf jx kq kr mg kt ku kv mh kx ky kz mi lb lc ld im bi translated">现在我们将再次执行与上面相同的操作，只是分辨率为 1024x1024。我们将采用较短的迁移学习阶段。下面的大多数单元格都没有被注释，因为我们在重复步骤，只是有一些不同的参数…</p><pre class="mk ml mm mn gt of og oh oi aw oj bi"><span id="a826" class="ll lm it og b gy ok ol l om on"># Original image size<br/>size = src_size<br/># Batch size of one!<br/>bs=1</span><span id="b6a5" class="ll lm it og b gy oo ol l om on">normalizePar=None<br/>if useImageNet:<br/>    normalizePar=imagenet_stats<br/>data = (src.transform(get_transforms(), size=size, tfm_y=True)<br/>        .databunch(bs=bs)<br/>        .normalize(normalizePar))</span><span id="5e16" class="ll lm it og b gy oo ol l om on">learn = unet_learner(data, used_model, metrics=metrics, wd=wd)</span><span id="eea2" class="ll lm it og b gy oo ol l om on">learn.load('stage2-512x502')</span><span id="2df0" class="ll lm it og b gy oo ol l om on">lr_find(learn)<br/>learn.recorder.plot()</span><span id="4430" class="ll lm it og b gy oo ol l om on"># Adapt it to your values<br/>lr=2e-5</span><span id="735d" class="ll lm it og b gy oo ol l om on"># Transfer learning stage<br/>learn.fit_one_cycle(3, slice(lr), pct_start=0.8)</span><span id="f05d" class="ll lm it og b gy oo ol l om on"># Save stage 1 of Cycle #3<br/>learn.save('stage1-1024x1004')</span><span id="e2ae" class="ll lm it og b gy oo ol l om on">learn.load('stage1-1024x1004')</span><span id="41a2" class="ll lm it og b gy oo ol l om on"># Prepare for the final fine-tuning<br/>learn.unfreeze()</span><span id="b6d0" class="ll lm it og b gy oo ol l om on"># Prepare for varying learning rates<br/>lrs = slice(1e-6,lr/10)</span><span id="69b7" class="ll lm it og b gy oo ol l om on"># Fine-tune for 10 epochs<br/>learn.fit_one_cycle(10, lrs)</span><span id="c1b2" class="ll lm it og b gy oo ol l om on"># Save stage 2 of Cycle #3<br/>learn.save('stage2-1024x1004')</span></pre><h2 id="5edc" class="ll lm it bd ln lo lp dn lq lr ls dp lt kr lu lv lw kv lx ly lz kz ma mb mc md bi translated">显示一些预测结果</h2><pre class="mk ml mm mn gt of og oh oi aw oj bi"><span id="cf4c" class="ll lm it og b gy ok ol l om on">learn.show_results(rows=2, figsize=(10,10))</span></pre><figure class="mk ml mm mn gt mo gh gi paragraph-image"><div role="button" tabindex="0" class="mp mq di mr bf ms"><div class="gh gi ow"><img src="../Images/8f601cc02830b96f1a3ac7c36e71eea8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*-vwKWW8dBaZCjRf1zmmpoQ.png"/></div></div></figure><h2 id="8ffa" class="ll lm it bd ln lo lp dn lq lr ls dp lt kr lu lv lw kv lx ly lz kz ma mb mc md bi translated">保存所有预测结果</h2><pre class="mk ml mm mn gt of og oh oi aw oj bi"><span id="c299" class="ll lm it og b gy ok ol l om on">name_gen = 'image_gen'<br/>path_gen = path/name_gen<br/>path_gen.mkdir(exist_ok=True)</span><span id="4dc3" class="ll lm it og b gy oo ol l om on">save_preds(data.fix_dl)</span></pre><h1 id="454d" class="nu lm it bd ln nv op nx lq ny oq oa lt jz or ka lw kc os kd lz kf ot kg mc oe bi translated">如果培训中途中断，我该怎么办？</h1><p id="d537" class="pw-post-body-paragraph ki kj it kk b kl me ju kn ko mf jx kq kr mg kt ku kv mh kx ky kz mi lb lc ld im bi translated">如果你的训练被打断了，你会怎么做？这可能是因为你在 Google Colab 笔记本上达到了连续 12 小时的“免费”操作时间，或者因为你的计算机由于某种原因停止了。我住在巴西，电力短缺是常事…</p><p id="55f9" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><em class="nc"> fit_one_cycle </em>方法适用于变化的自适应学习速率，遵循速率先增大后减小的曲线。如果你中断第 10 个纪元的训练，比如说 20 个纪元，然后重新开始 9 个以上的纪元，<strong class="kk iu">你将不会得到与不间断训练 20 个纪元</strong>相同的结果。您必须能够记录您停止的位置，然后从该点重新开始训练周期，并使用该周期部分的正确超参数。</p><figure class="mk ml mm mn gt mo gh gi paragraph-image"><div role="button" tabindex="0" class="mp mq di mr bf ms"><div class="gh gi ox"><img src="../Images/8d5fa3658ed88e31179157e295612d77.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*SfQdflj95ziJHcMiUfCNbA.png"/></div></div><figcaption class="mv mw gj gh gi mx my bd b be z dk">A fit_one_cycle training session divided into three subsessions. Image by PPW@GitHub</figcaption></figure><p id="47e4" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">你要做的第一件事就是保存你的网络:</p><pre class="mk ml mm mn gt of og oh oi aw oj bi"><span id="dcb2" class="ll lm it og b gy ok ol l om on">learn.fit_one_cycle(20, max_lr=slice(1e-5,1e-6), <br/>       callbacks=[SaveModelCallback(learn, every='epoch',  <br/>                  monitor='accuracy', name='saved_net')])</span></pre><p id="953c" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">这将使您的网络在每个纪元都被保存，您提供的名称后面跟着<em class="nc">_ #纪元</em>。所以在纪元#3，文件<em class="nc"> saved_net_3.pth </em>将被写入。您可以在完成以下操作后加载此文件:</p><ul class=""><li id="4a36" class="ng nh it kk b kl km ko kp kr ni kv nj kz nk ld nl nm nn no bi translated">重新创建了<em class="nc">数据束</em>和</li><li id="cb98" class="ng nh it kk b kl np ko nq kr nr kv ns kz nt ld nl nm nn no bi translated">用它重新实例化了网络。</li></ul><p id="f042" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">重装完<em class="nc">后。pth </em>文件，你可以重新开始你的训练，只是你要告诉<em class="nc"> fit_one_cycle </em>考虑 20 个历元，但是要从历元#4 开始训练。</p><p id="e5e3" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">要了解这是如何做到的，请看这里:</p><ul class=""><li id="70d6" class="ng nh it kk b kl km ko kp kr ni kv nj kz nk ld nl nm nn no bi translated"><a class="ae na" href="https://github.com/PPPW/deep-learning-random-explore/tree/master/divide_1cycle?source=post_page---------------------------" rel="noopener ugc nofollow" target="_blank">把一个长周期的政策分成几个小周期——PPW 的 GitHub</a></li></ul><p id="a704" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="kk iu">你是怎么做到的？</strong></p><p id="42cf" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">fast.ai 中的<em class="nc"> fit_one_cycle </em>方法已经开发出来，允许您告诉它从周期的哪个部分恢复中断的训练。恢复培训的代码如下所示:</p><pre class="mk ml mm mn gt of og oh oi aw oj bi"><span id="9f1f" class="ll lm it og b gy ok ol l om on"># Create a new net if training was interrupted and you had to <br/># restart your Colab session</span><span id="050b" class="ll lm it og b gy oo ol l om on">learn = cnn_learner(data, models.&lt;your_model_here&gt;, <br/>                    metrics=[accuracy, error_rate])</span><span id="3b39" class="ll lm it og b gy oo ol l om on"># If you're resuming, only indicating the epoch from which to <br/># resume, indicated by <strong class="og iu"><em class="nc">start_epoch=&lt;epoch#&gt;</em></strong> will load the last <br/># saved .pth, it is not necessary to explicitly reload the last <br/># epoch, you only should <strong class="og iu">NOT</strong> change the name given in <br/># name=&lt;callback_save_file&gt;:<br/># when resuming fast.ai will try to reload <br/># <strong class="og iu"><em class="nc">&lt;callback_save_file&gt;_&lt;previous_epoch&gt;.pth</em></strong><br/># Unfreeze the network<br/>learn50.unfreeze()</span><span id="1b4d" class="ll lm it og b gy oo ol l om on"># Use start_epoch=&lt;some_epoch&gt; to resume training...<br/>learn.fit_one_cycle(20, max_lr=slice(1e-5,1e-6), <br/>                    <strong class="og iu"><em class="nc">start_epoch=&lt;next_epoch#&gt;</em></strong>,<br/>                    callbacks=[SaveModelCallback(learn, <br/>                    every='epoch', monitor='accuracy', <br/>                    <strong class="og iu"><em class="nc">name=&lt;callback_save_file&gt;</em></strong>)])</span></pre><p id="1ba5" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">fast.ai 会告诉你“<em class="nc">载入&lt;回调 _ 保存 _ 文件&gt; _ &lt;上一个 _ 纪元# &gt; </em>”，恢复训练。</p><p id="9ef1" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">您可以在此查看<em class="nc"> fit_one_cycle </em>方法支持的所有参数:</p><ul class=""><li id="d084" class="ng nh it kk b kl km ko kp kr ni kv nj kz nk ld nl nm nn no bi translated"><a class="ae na" href="https://docs.fast.ai/train.html#fit_one_cycle" rel="noopener ugc nofollow" target="_blank">https://docs.fast.ai/train.html#fit_one_cycle</a></li></ul><h1 id="47cd" class="nu lm it bd ln nv op nx lq ny oq oa lt jz or ka lw kc os kd lz kf ot kg mc oe bi translated">想看看结果吗？</h1><p id="5199" class="pw-post-body-paragraph ki kj it kk b kl me ju kn ko mf jx kq kr mg kt ku kv mh kx ky kz mi lb lc ld im bi translated">(A)显示了由微 CT 切片中的网络识别和分割的微化石。(B)显示了化石的细节,( C)显示了人工提取后化石的显微断层图像。(D)显示同一样本的显微镜照片。</p><figure class="mk ml mm mn gt mo gh gi paragraph-image"><div role="button" tabindex="0" class="mp mq di mr bf ms"><div class="gh gi oy"><img src="../Images/5f92baca3deb9f3ee863f2b6fce0c164.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*DBHPvRvCFmksMVQHIhp9HA.png"/></div></div></figure><h1 id="3bfd" class="nu lm it bd ln nv op nx lq ny oq oa lt jz or ka lw kc os kd lz kf ot kg mc oe bi translated">我们学到了什么？</h1><p id="ca99" class="pw-post-body-paragraph ki kj it kk b kl me ju kn ko mf jx kq kr mg kt ku kv mh kx ky kz mi lb lc ld im bi translated">卷积神经网络和深度学习可以成功地应用于解决海洋微体古生物中的问题，这是一个你不会指望人工智能会找到应用的领域。可以训练语义分割网络，以在沉积岩的微断层图像中可靠地找到微化石，这些图像是从石油勘探钻机获得的钻孔岩心中获得的。一个现成的以 ResNet34 为网络的 UNet 框架就足以解决这个问题。</p><h1 id="7e2a" class="nu lm it bd ln nv op nx lq ny oq oa lt jz or ka lw kc os kd lz kf ot kg mc oe bi translated">想了解更多？</h1><p id="7a0c" class="pw-post-body-paragraph ki kj it kk b kl me ju kn ko mf jx kq kr mg kt ku kv mh kx ky kz mi lb lc ld im bi translated">我们还测试了其他网络，并发布了一些新的出版物:</p><ul class=""><li id="ca30" class="ng nh it kk b kl km ko kp kr ni kv nj kz nk ld nl nm nn no bi translated"><a class="ae na" href="http://www.lapix.ufsc.br/pesquisas/microfosseis/" rel="noopener ugc nofollow" target="_blank">访问我们的项目页面</a>:【http://www.lapix.ufsc.br/pesquisas/microfosseis/ T2】</li><li id="14d5" class="ng nh it kk b kl np ko nq kr nr kv ns kz nt ld nl nm nn no bi translated">访问我们的数据集页面:<a class="ae na" href="http://www.lapix.ufsc.br/microfossil-segmentation/" rel="noopener ugc nofollow" target="_blank">http://www.lapix.ufsc.br/microfossil-segmentation/</a></li><li id="1ade" class="ng nh it kk b kl np ko nq kr nr kv ns kz nt ld nl nm nn no bi translated"><a class="ae na" href="https://authors.elsevier.com/c/1b99p1LwImDX-U" rel="noopener ugc nofollow" target="_blank">看看我们的新论文<em class="nc">使用海洋微体古生物的深度学习方法</em>进行自动微体化石识别和分割</a></li><li id="c89c" class="ng nh it kk b kl np ko nq kr nr kv ns kz nt ld nl nm nn no bi translated"><a class="ae na" href="http://biorxiv.org/cgi/content/short/661694v1" rel="noopener ugc nofollow" target="_blank">查看我们关于<em class="nc"> bioRxiv </em>的稍旧的论文，了解我们使用不同型号</a>获得的结果</li></ul><figure class="mk ml mm mn gt mo gh gi paragraph-image"><div role="button" tabindex="0" class="mp mq di mr bf ms"><div class="gh gi oz"><img src="../Images/6c571ea0eb184fafeb0dd8bc1dd6542c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*6h1mbmgBJJ87De5Z3DC-Qw.png"/></div></div></figure><p id="9c4a" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">采用一种新的 HYPO 策略:一种<strong class="kk iu"> <em class="nc">逐步渐进提高图像分辨率的训练策略</em> </strong>，可以解决微断层体积中的大量数据所带来的存储问题。这使得我们最初可以大批量工作，训练得更快更好。</p></div><div class="ab cl le lf hx lg" role="separator"><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj"/></div><div class="im in io ip iq"><p id="68d5" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">引用这篇文章</p><pre class="mk ml mm mn gt of og oh oi aw oj bi"><span id="cf6d" class="ll lm it og b gy ok ol l om on">@misc{von wangenheim_ramos de carvalho_2019, <br/>   title={Artificial  Intelligence &amp; Paleontology: Use Deep Learning to search for  Microfossils},  <br/>   url={https://towardsdatascience.com/artificial-intelligence-paleontology-use-deep-learning-to-search-for-microfossils-18760bb30880},  <br/>   publisher={Towards Data Science},  <br/>   author={von Wangenheim, Aldo Eduardo and Ramos de Carvalho, Luis  Eduardo}, <br/>   year={2019}, <br/>   month={Jun}<br/>}</span></pre></div></div>    
</body>
</html>