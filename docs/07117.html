<html>
<head>
<title>Attack Toxic Comments Kaggle Competition Using Fast.ai</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">用 Fast.ai 攻击有毒评论 Kaggle 比赛</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/attack-toxic-comments-kaggle-competition-using-fast-ai-b9eb61509e79?source=collection_archive---------16-----------------------#2019-10-08">https://towardsdatascience.com/attack-toxic-comments-kaggle-competition-using-fast-ai-b9eb61509e79?source=collection_archive---------16-----------------------#2019-10-08</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="1208" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">如何从头开始构建多标签 NLP 分类器</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/eb2b54fedf16d34a7ddca9cad83ca35d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*SxwidHTBf5ZSysg9.jpg"/></div></div></figure><p id="486e" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi lq translated"><span class="l lr ls lt bm lu lv lw lx ly di"> K </span> <a class="ae lz" href="http://www.kaggle.com" rel="noopener ugc nofollow" target="_blank"> aggle </a>是学习和练习你的机器学习技能的好地方。这也是为你的学习项目寻找合适的数据集的好地方。我需要一个好的分类 NLP 数据集来实践我最近学习的 fast.ai 课程，我遇到了<a class="ae lz" href="https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge" rel="noopener ugc nofollow" target="_blank">有毒评论分类挑战</a>。比赛是两年前举行的，早就结束了，但提交我的分数并看看我做得有多好也无妨。这是 Kaggle 的优势之一，因为在现实世界中，通常很难知道你的模型是好是坏，而在 Kaggle 中，你可以清楚地看到你的表现在排行榜上的位置。</p></div><div class="ab cl ma mb hx mc" role="separator"><span class="md bw bk me mf mg"/><span class="md bw bk me mf mg"/><span class="md bw bk me mf"/></div><div class="im in io ip iq"><h1 id="f0fd" class="mh mi it bd mj mk ml mm mn mo mp mq mr jz ms ka mt kc mu kd mv kf mw kg mx my bi translated">数据集</h1><p id="c7e4" class="pw-post-body-paragraph ku kv it kw b kx mz ju kz la na jx lc ld nb lf lg lh nc lj lk ll nd ln lo lp im bi lq translated">他的比赛由对话人工智能团队举办，这是一个由竖锯和谷歌(都是 Alphabet 的一部分)创立的研究项目。它的目标是找出能够在评论中对多种毒性类型进行分类的最佳模型。毒性类型包括:</p><blockquote class="ne nf ng"><p id="c7bb" class="ku kv nh kw b kx ky ju kz la lb jx lc ni le lf lg nj li lj lk nk lm ln lo lp im bi translated">有毒的</p><p id="a9da" class="ku kv nh kw b kx ky ju kz la lb jx lc ni le lf lg nj li lj lk nk lm ln lo lp im bi translated">严重 _ 有毒</p><p id="16de" class="ku kv nh kw b kx ky ju kz la lb jx lc ni le lf lg nj li lj lk nk lm ln lo lp im bi translated">猥亵的</p><p id="8b1b" class="ku kv nh kw b kx ky ju kz la lb jx lc ni le lf lg nj li lj lk nk lm ln lo lp im bi translated">威胁</p><p id="2df1" class="ku kv nh kw b kx ky ju kz la lb jx lc ni le lf lg nj li lj lk nk lm ln lo lp im bi translated">侮辱</p><p id="587e" class="ku kv nh kw b kx ky ju kz la lb jx lc ni le lf lg nj li lj lk nk lm ln lo lp im bi translated">同一性 _ 仇恨</p></blockquote><p id="e832" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">在训练文件<code class="fe nl nm nn no b">train.cvs</code>和测试文件<code class="fe nl nm nn no b">test.csv</code>中给出了注释。你需要为<code class="fe nl nm nn no b">test.csv</code>中的每条评论预测每种毒性的概率。这是一个多标签的 NLP 分类问题。</p></div><div class="ab cl ma mb hx mc" role="separator"><span class="md bw bk me mf mg"/><span class="md bw bk me mf mg"/><span class="md bw bk me mf"/></div><div class="im in io ip iq"><h1 id="39eb" class="mh mi it bd mj mk ml mm mn mo mp mq mr jz ms ka mt kc mu kd mv kf mw kg mx my bi translated">看数据</h1><p id="87bb" class="pw-post-body-paragraph ku kv it kw b kx mz ju kz la na jx lc ld nb lf lg lh nc lj lk ll nd ln lo lp im bi lq translated"><span class="l lr ls lt bm lu lv lw lx ly di"> L </span> et 先来看看数据。我们需要导入必要的模块，并做一些后勤工作来为我们的文件设置路径。</p><pre class="kj kk kl km gt np no nq nr aw ns bi"><span id="1795" class="nt mi it no b gy nu nv l nw nx">import numpy as np <em class="nh"># linear algebra</em><br/>import pandas as pd <em class="nh"># data processing, CSV file I/O (e.g. pd.read_csv)<br/></em>from fastai.text import *<br/>from fastai import *</span></pre><p id="99b8" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">注意这里我们从 fastai.text 和 fastai 模块导入了所有内容。我们反对这里的软件工程最佳实践吗？实际上，不完全是。这是一种更具迭代性和互动性的数据科学方式的深思熟虑的举措。有了所有可用的库，我可以轻松地测试和尝试不同的功能/模块，而不必每次都返回并导入它们。这将使探索/实验流程更加顺畅。不过我跑题了，我们来加载数据看看:</p><pre class="kj kk kl km gt np no nq nr aw ns bi"><span id="0a2b" class="nt mi it no b gy nu nv l nw nx"># Kaggle store dataset in the /kaggle/input/ folder,<br/>path = Path('/kaggle/input/jigsaw-toxic-comment-classification-challenge/')<br/>path.ls()</span><span id="628b" class="nt mi it no b gy ny nv l nw nx"># the /kaggle/input/ folder is read-only, copy away so I can also write to the folder. <br/>!mkdir data<br/>!cp -a {path}/*.* ./data/<br/>!ls data</span><span id="a10f" class="nt mi it no b gy ny nv l nw nx"># make sure everything is correctly copied over<br/>path = Path('/kaggle/working/data/')<br/>path.ls()</span><span id="a8c1" class="nt mi it no b gy ny nv l nw nx"># read in the data and have a peak<br/>df = pd.read_csv(path/'train.csv')<br/>df.head()</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nz"><img src="../Images/b1838334e427edaa1e0fee236521036b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*XhZcKKIvj9-r0RmksgoYXQ.png"/></div></div><figcaption class="oa ob gj gh gi oc od bd b be z dk">The toxicity types are one-hot encoded</figcaption></figure><p id="f791" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">注释在<code class="fe nl nm nn no b">comment_text</code>列中，所有毒性类型都是“一次性”编码的，我们将不得不对其进行一些处理，以使其适合我们以后的模型。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oe"><img src="../Images/5b86267803870319a9c719b0f0d8b66b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*9hNkR1Z0Y279_xNxfZ-bMw.png"/></div></div><figcaption class="oa ob gj gh gi oc od bd b be z dk">Have a look at one comment</figcaption></figure></div><div class="ab cl ma mb hx mc" role="separator"><span class="md bw bk me mf mg"/><span class="md bw bk me mf mg"/><span class="md bw bk me mf"/></div><div class="im in io ip iq"><h1 id="9f64" class="mh mi it bd mj mk ml mm mn mo mp mq mr jz ms ka mt kc mu kd mv kf mw kg mx my bi translated">迁移学习:微调我们的语言模型</h1><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi of"><img src="../Images/d05aba4db7198ee3883e0f3e421c1679.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*ZItmfFjXqRgyJIbw.jpg"/></div></div></figure><p id="ac63" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">我们将使用迁移学习来完成这项任务，为此，我们将使用一个基于维基百科的预训练模型，名为<a class="ae lz" href="https://einstein.ai/research/blog/the-wikitext-long-term-dependency-language-modeling-dataset" rel="noopener ugc nofollow" target="_blank"> wikitext-103 </a>。这是一个已经从维基百科数据集(或 NLP 术语中的“语料库”)中训练出来的模型，用于从给定的未完成句子中预测下一个单词。我们将利用模型已经从维基百科数据集学习到的“语言知识”,并在此基础上进行构建。为了达到最佳效果，我们需要“微调”模型，使它从我们的“评论”数据集中学习一些东西，因为人们在评论中所说的不一定与更正式的维基相同。一旦对语言模型进行了微调，我们就可以使用它来进一步完成分类任务。</p><p id="12a2" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">现在让我们将训练数据加载到 fast.ai <code class="fe nl nm nn no b">databunch</code>中，以便我们可以首先开始训练语言模型。</p><pre class="kj kk kl km gt np no nq nr aw ns bi"><span id="68d4" class="nt mi it no b gy nu nv l nw nx">bs = 64   # set batch size to 64, works for Kaggle Kernels<br/>data_lm = (TextList.from_df(df, path, cols='comment_text')<br/>                .split_by_rand_pct(0.1)<br/>                .label_for_lm()<br/>                .databunch(bs=bs))</span></pre><p id="4eac" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">我们使用 fast.ai 的<code class="fe nl nm nn no b">Data Block API</code>来完成这项任务。这是一种非常灵活和强大的方法，可以解决构建管道的挑战性任务:将数据加载到模型中。它将整个过程隔离为不同的部分/步骤，每个步骤都有多种方法/功能来适应不同类型的数据和数据存储方式。这个概念很像 Linux 哲学，高度模块化，每个模块只做一件事，但做得非常非常好。您可以在这里自由探索美妙的 API <a class="ae lz" href="https://docs.fast.ai/data_block.html" rel="noopener ugc nofollow" target="_blank">，尽管对于上面的代码，它做了以下事情:</a></p><ol class=""><li id="5cd5" class="og oh it kw b kx ky la lb ld oi lh oj ll ok lp ol om on oo bi translated">从名为<code class="fe nl nm nn no b">df</code>的 Pandas DataFrame 导入数据，告诉模型使用<code class="fe nl nm nn no b">comment_text</code>作为输入(<code class="fe nl nm nn no b">TextList.from_df(df, path, cols=’comment_text’)</code> ) <em class="nh">注意这里我也可以将 test.csv 包含到语言模型中。这不被认为是“作弊”，因为我们没有使用标签，只是做语言模型训练。</em></li><li id="ba2a" class="og oh it kw b kx op la oq ld or lh os ll ot lp ol om on oo bi translated">将训练数据集按随机的 10/90%分成训练/验证集。(<code class="fe nl nm nn no b">.split_by_rand_pct(0.1)</code>)</li><li id="3859" class="og oh it kw b kx op la oq ld or lh os ll ot lp ol om on oo bi translated">忽略给定的标签(因为我们只是微调语言模型，而不是训练分类器),并使用语言模型的“预测下一个单词”作为标签。(<code class="fe nl nm nn no b">.label_for_lm()</code>)</li><li id="8867" class="og oh it kw b kx op la oq ld or lh os ll ot lp ol om on oo bi translated">将数据构建到一个<code class="fe nl nm nn no b">databunch</code>中，批量大小为<code class="fe nl nm nn no b">bs</code>。(<code class="fe nl nm nn no b">.databunch(bs=bs)</code>)</li></ol><p id="8f51" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">现在让我们看看我们刚刚构建的<code class="fe nl nm nn no b">databunch</code>:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ou"><img src="../Images/802df75c08de56b93406edd82882ba07.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*tZb2mpF3ybJizigXjZD7Vw.png"/></div></div><figcaption class="oa ob gj gh gi oc od bd b be z dk">Notice we lost all the toxicity types</figcaption></figure><p id="a204" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">请注意，<code class="fe nl nm nn no b">databunch</code>没有所有的毒性类型标签，因为我们只是微调了语言模型。</p><p id="3a4d" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">好了，是时候进行一些典型的 fast.ai 学习率调整和训练了:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ov"><img src="../Images/30962912008168ba20c3910384f7cc33.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*vKptpwNJ5yj-ufCweNY5cQ.png"/></div></div></figure><p id="5d26" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">我们将我们的<code class="fe nl nm nn no b">databunch</code>放入一个<code class="fe nl nm nn no b">language_model_learner</code>中，告诉它我们想要使用的语言模型库(<code class="fe nl nm nn no b">AWD_LSTM</code>)，并分配一个默认的辍学率<strong class="kw iu"> 0.3 </strong>。从<code class="fe nl nm nn no b">LR Finder</code>图中，找出最大的下降斜率，选取中间点作为我们的学习率。(关于如何实现这种‘fit _ one _ cycle’魔法的更详细解释，请参考这篇<a class="ae lz" href="https://docs.fast.ai/callbacks.one_cycle.html#What-is-1cycle?" rel="noopener ugc nofollow" target="_blank">文章</a>。它是 fast.ai 的一种 SOTA 技术，结合了学习率和动量退火)。现在，我们可以“解冻”模型，并训练几个时期的整个模型:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ow"><img src="../Images/2c394d55642cc80b602c125dc0e402f7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*pQRrm9fcMkRua9k9LbBbzA.png"/></div></div></figure><p id="585f" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">我们可以看一个模型表现如何的例子:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ox"><img src="../Images/301d48027dca71f7b7909325d4c528e7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*UCNNMwGBhh7oxbRIMxg7Pg.png"/></div></div></figure><p id="7ded" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">结果很难说是最佳的。但我们至少得到了一个实际上有意义的句子，并且预测下一个单词的 0.38 的准确度还不错。理想情况下，我们需要训练更多的纪元，但对于这个 Kaggle 内核，我用完了 GPU 配额，所以我停在了 4。结果肯定有提升的空间，可以自己试试。反正我们想从语言模型中得到的是编码器部分，所以我们把它保存下来。</p><blockquote class="ne nf ng"><p id="bf94" class="ku kv nh kw b kx ky ju kz la lb jx lc ni le lf lg nj li lj lk nk lm ln lo lp im bi translated">训练语言模型确实需要相当长的时间，但好消息是，对于您自己的领域语料库，您只需训练一次，以后您可以将它用作任何其他分类任务的基础。</p></blockquote><pre class="kj kk kl km gt np no nq nr aw ns bi"><span id="bda2" class="nt mi it no b gy nu nv l nw nx"><em class="nh"># save the encoder for next step use</em><br/>learn.save_encoder('fine_tuned_enc')</span></pre></div><div class="ab cl ma mb hx mc" role="separator"><span class="md bw bk me mf mg"/><span class="md bw bk me mf mg"/><span class="md bw bk me mf"/></div><div class="im in io ip iq"><h1 id="6447" class="mh mi it bd mj mk ml mm mn mo mp mq mr jz ms ka mt kc mu kd mv kf mw kg mx my bi translated">迁移学习:训练分类器</h1><p id="e7db" class="pw-post-body-paragraph ku kv it kw b kx mz ju kz la na jx lc ld nb lf lg lh nc lj lk ll nd ln lo lp im bi translated">让我们来看看测试数据集:</p><pre class="kj kk kl km gt np no nq nr aw ns bi"><span id="b249" class="nt mi it no b gy nu nv l nw nx">test = pd.read_csv(path/"test.csv")<br/>test_datalist = TextList.from_df(test, cols='comment_text')</span></pre><p id="edf7" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">再次，建造我们的<code class="fe nl nm nn no b">databunch</code>:</p><pre class="kj kk kl km gt np no nq nr aw ns bi"><span id="3503" class="nt mi it no b gy nu nv l nw nx">data_cls = (TextList.from_csv(path, 'train.csv', cols='comment_text', vocab=data_lm.vocab)<br/>                .split_by_rand_pct(valid_pct=0.1)<br/>                .label_from_df(cols=['toxic', 'severe_toxic','obscene', 'threat', 'insult', 'identity_hate'], label_cls=MultiCategoryList, one_hot=True)<br/>                .add_test(test_datalist)<br/>                .databunch())<br/>data_cls.save('data_clas.pkl')</span></pre><p id="172e" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">请注意这次的不同之处:</p><ol class=""><li id="c810" class="og oh it kw b kx ky la lb ld oi lh oj ll ok lp ol om on oo bi translated"><em class="nh">在构建</em> <code class="fe nl nm nn no b"><em class="nh">TextList</em></code> <em class="nh">时，我们指定了</em> <code class="fe nl nm nn no b"><em class="nh">vocab=data_lm.vocab</em></code> <em class="nh">，这样我们就确保了我们使用的是相同的词汇，并且我们在语言模型上的训练可以恰当地应用到分类器模型上。</em></li><li id="6237" class="og oh it kw b kx op la oq ld or lh os ll ot lp ol om on oo bi translated">我们现在使用我们所有的毒性风格标签(<code class="fe nl nm nn no b">.label_from_df(cols=[‘toxic’, ‘severe_toxic’,’obscene’, ‘threat’, ‘insult’, ‘identity_hate’],label_cls=MultiCategoryList, one_hot=True),</code>)</li><li id="854c" class="og oh it kw b kx op la oq ld or lh os ll ot lp ol om on oo bi translated">我们在这里添加了我们的测试集。(<code class="fe nl nm nn no b">.add_test(test_datalist)</code>)</li></ol><p id="a942" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">现在看看我们的分类器<code class="fe nl nm nn no b">databunch</code>:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oy"><img src="../Images/cb6a506a0db1ab5bf12f7b5ee3e0a7f7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*47Wryn1f-yDMfiu3l-bXMA.png"/></div></div><figcaption class="oa ob gj gh gi oc od bd b be z dk">Note that now we have all the toxicity styles labels</figcaption></figure><p id="3ca1" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">最后，是时候把所有东西放在一起了！我们将把<code class="fe nl nm nn no b">databunch</code>放到<code class="fe nl nm nn no b">text_classifier_learner</code>模型中，并加载我们从语言模型中学到的编码器。</p><pre class="kj kk kl km gt np no nq nr aw ns bi"><span id="e278" class="nt mi it no b gy nu nv l nw nx">learn = text_classifier_learner(data_clas, AWD_LSTM, drop_mult=0.5)<br/>learn.load_encoder('fine_tuned_enc')</span></pre><p id="a570" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">再次，找到最佳学习率，训练一个周期:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oz"><img src="../Images/db2100edd15a05dd38886f41e5ca1772.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*xXpZwueb6Yec9TvVvJN7SA.png"/></div></div></figure><p id="7c2d" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">多训练几个周期，然后解冻:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pa"><img src="../Images/6bf841f2677bc377a0c472b4d16efa4c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*GcvvzZNPv9Qe1M1bwvcjEA.png"/></div></div></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pb"><img src="../Images/71def863758d2212837da66d45c44ae7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*2Ny7Ka7Ewv6b_0TH8R8RsA.png"/></div></div></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pc"><img src="../Images/1b646f819981a36a6b2b92efce994e58.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*BWi5dpbgRmwyvr7VQdh59A.png"/></div></div></figure><p id="9665" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">查看结果:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pd"><img src="../Images/1d939529e22bf607234957c8e3ee17d1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*vePv-fiRXOukp3ZgteqwnA.png"/></div></div></figure><p id="09ba" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">差了一个，但总体来说预测是好的。作为参考，我将预测提交给 Kaggle，得到一个 0.98098 的公众分数(落在公众领袖板的中间)。结果不是最佳的，但是就像我说的，由于 GPU 有限，我没有全程训练。本文的目的是向您展示使用 fast.ai 处理多标签文本分类问题的整个过程。这里真正的挑战是使用数据块 API 将数据加载到模型中。</p></div><div class="ab cl ma mb hx mc" role="separator"><span class="md bw bk me mf mg"/><span class="md bw bk me mf mg"/><span class="md bw bk me mf"/></div><div class="im in io ip iq"><h1 id="af7f" class="mh mi it bd mj mk ml mm mn mo mp mq mr jz ms ka mt kc mu kd mv kf mw kg mx my bi translated">结论</h1><p id="0e04" class="pw-post-body-paragraph ku kv it kw b kx mz ju kz la na jx lc ld nb lf lg lh nc lj lk ll nd ln lo lp im bi translated">我希望你能从这篇文章中学到一些东西。Fast.ai 真的是一个精简、灵活、强大的库。对于它能做的事情(像图像/文本分类，表格数据，协同过滤等。)，它做得很好。它不像 Keras 那样广泛，但它非常尖锐和集中。有点像 Vim 和 Emacs，如果你熟悉命令行文本编辑器 war 的话。😜</p><blockquote class="ne nf ng"><p id="6e3e" class="ku kv nh kw b kx ky ju kz la lb jx lc ni le lf lg nj li lj lk nk lm ln lo lp im bi translated">你可以在这里找到 Kaggle 内核<a class="ae lz" href="https://www.kaggle.com/lymenlee/toxic-comments-classification-fast-ai" rel="noopener ugc nofollow" target="_blank">。</a></p></blockquote></div><div class="ab cl ma mb hx mc" role="separator"><span class="md bw bk me mf mg"/><span class="md bw bk me mf mg"/><span class="md bw bk me mf"/></div><div class="im in io ip iq"><p id="6ca5" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">欢迎任何反馈或建设性的批评。你可以在推特<a class="ae lz" href="https://twitter.com/lymenlee" rel="noopener ugc nofollow" target="_blank"> @lymenlee </a>或者我的博客网站【wayofnumbers.com<a class="ae lz" href="https://wayofnumbers.com/" rel="noopener ugc nofollow" target="_blank">上找到我。</a></p></div></div>    
</body>
</html>