<html>
<head>
<title>GANs and Missing Data Imputation</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">GANs 和缺失数据插补</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/gans-and-missing-data-imputation-815a0cbc4ece?source=collection_archive---------12-----------------------#2019-08-05">https://towardsdatascience.com/gans-and-missing-data-imputation-815a0cbc4ece?source=collection_archive---------12-----------------------#2019-08-05</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="35cc" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">基于生成对抗网络的缺失数据填补新方法</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/07898eb731bb400c37508a6ac34eba2c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*AVhguCq6MEGW9n4eN9o2Ug.jpeg"/></div></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk"><a class="ae ky" href="https://www.flickr.com/photos/crdot/6212236687/" rel="noopener ugc nofollow" target="_blank">https://www.flickr.com/photos/crdot/6212236687/</a></figcaption></figure><h1 id="2da3" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">介绍</h1><p id="abab" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">看看 GANs 令人印象深刻的表现，他们变得如此受欢迎也就不足为奇了。它们广泛用于编辑或生成图像、安全目的以及许多其他领域，优于大多数神经网络架构。它们也有一些不太重要的应用，比如将马变成斑马，或者将城市景观渲染成 GTA 风格。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="mn mo l"/></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk">Rendering cityscape into GTA style. <a class="ae ky" href="https://junyanz.github.io/CycleGAN/" rel="noopener ugc nofollow" target="_blank">[Source]</a></figcaption></figure><p id="29f0" class="pw-post-body-paragraph lr ls it lt b lu mp ju lw lx mq jx lz ma mr mc md me ms mg mh mi mt mk ml mm im bi translated">看来它们被用于输入缺失数据只是时间问题。使用 GANs 处理缺失数据的想法相对较新，主要存在于研究文献中。然而，这是一种非常有前途的方法，我们可能很快就会看到用于缺失数据插补的现成 GAN 模型。事实上，Github 上现有的实现很少，我将在文章的底部提到。在本文中，我将解释缺失数据插补最流行的 GAN 架构，同时摒弃科学术语，以更简单、直观的方式进行解释😉让我们开始吧！</p></div><div class="ab cl mu mv hx mw" role="separator"><span class="mx bw bk my mz na"/><span class="mx bw bk my mz na"/><span class="mx bw bk my mz"/></div><div class="im in io ip iq"><h2 id="b6b9" class="nb la it bd lb nc nd dn lf ne nf dp lj ma ng nh ll me ni nj ln mi nk nl lp nm bi translated">开始之前</h2><p id="3d49" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">在我们研究处理缺失数据的不同 GAN 架构之前，我们需要确保基础知识是正确的。</p><p id="5ac4" class="pw-post-body-paragraph lr ls it lt b lu mp ju lw lx mq jx lz ma mr mc md me ms mg mh mi mt mk ml mm im bi translated">在处理真实数据集时，缺失数据是一个常见问题。我们中的一些人只能在 Kaggle 上使用近乎理想且格式良好的数据。不幸的是，现实生活中并不是这样。数据经常会丢失，它可能以三种不同的方式发生:MCAR(完全随机丢失)，马尔(随机丢失)和 NMAR(非随机丢失)。如果你想了解更多细节，可以看看这篇文章。幸运的是，有各种方法可以处理缺失数据。为了深入了解现有的插补算法(例如 KNN、老鼠、MissForest)和它们各自的 Python 包，我推荐阅读<a class="ae ky" rel="noopener" target="_blank" href="/why-using-a-mean-for-missing-data-is-a-bad-idea-alternative-imputation-algorithms-837c731c1008">我以前的文章</a>。</p><p id="a834" class="pw-post-body-paragraph lr ls it lt b lu mp ju lw lx mq jx lz ma mr mc md me ms mg mh mi mt mk ml mm im bi translated">gan 非常适合处理缺失数据。他们很好地学习隐藏的数据分布，并且发生器和鉴别器之间的反馈回路产生非常高精度的结果。如果你觉得你需要刷新一下关于甘斯的记忆，看看下面欧文·凯里在这篇<a class="ae ky" rel="noopener" target="_blank" href="/generative-adversarial-networks-gans-a-beginners-guide-5b38eceece24">惊人文章</a>中写的一小段话。</p><blockquote class="nn no np"><p id="cb8f" class="lr ls nq lt b lu mp ju lw lx mq jx lz nr mr mc md ns ms mg mh nt mt mk ml mm im bi translated">一个称为生成器的神经网络生成新的数据实例，而另一个称为鉴别器的神经网络评估它们的真实性。</p><p id="1a63" class="lr ls nq lt b lu mp ju lw lx mq jx lz nr mr mc md ns ms mg mh nt mt mk ml mm im bi translated">你可以把一个 GAN 想象成造假者(发生者)和警察(鉴别者)之间的猫捉老鼠的游戏。伪造者正在学习制造假币，而警察正在学习检测假币。两个人都在学习，都在提高。造假者在不断学习制造更好的假货，而警察在检测假货方面也在不断进步。最终结果是伪造者(制造者)现在被训练来创造超现实的货币！</p></blockquote><h1 id="75a2" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">GAN 架构</h1><h2 id="2bfd" class="nb la it bd lb nc nd dn lf ne nf dp lj ma ng nh ll me ni nj ln mi nk nl lp nm bi translated">增加</h2><p id="9c47" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">GAIN 代表生成式对抗插补网。在撰写本文时，它似乎是处理缺失数据的最流行的 GAN 架构。其背后的思想很简单:生成器获取一些缺失值的真实数据的向量，并相应地对它们进行估算。估算的数据被反馈给鉴别器，鉴别器的工作是找出最初丢失的数据。下图更详细地解释了该架构。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nu"><img src="../Images/e809ba724661abdfa3e4bd01d457d149.png" data-original-src="https://miro.medium.com/v2/resize:fit:776/format:webp/1*B7J8O-IYQzvrlrtRmVu7vQ.png"/></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk">GAIN architecture [1]</figcaption></figure><p id="7b4d" class="pw-post-body-paragraph lr ls it lt b lu mp ju lw lx mq jx lz ma mr mc md me ms mg mh mi mt mk ml mm im bi translated">有一个<em class="nq">屏蔽矩阵</em>，它告诉发生器哪些值缺失或存在。<em class="nq">随机矩阵</em>增加了估算值的随机性(所以它们每次都不一样)。还有<em class="nq">提示向量</em>，提供给鉴别器，确保鉴别器强制发生器学习。</p><p id="1e4a" class="pw-post-body-paragraph lr ls it lt b lu mp ju lw lx mq jx lz ma mr mc md me ms mg mh mi mt mk ml mm im bi translated">增益插补的准确性与其他最先进的插补算法进行了比较，并证明其明显优于所有算法[1]。听起来是个不错的估算，是吧？</p><h2 id="9b7a" class="nb la it bd lb nc nd dn lf ne nf dp lj ma ng nh ll me ni nj ln mi nk nl lp nm bi translated">米斯甘</h2><p id="d894" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">MisGAN 是另一个处理缺失数据的 GAN 框架。它的架构与 GAIN 略有不同，因为它有 2 个发生器和 2 个鉴别器[2]。下图展示了 MisGAN 架构。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nv"><img src="../Images/65c3106e2557bac17a4871fb08189e3e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1108/format:webp/1*XKu8F-BdCJf0hxXFeiWstg.png"/></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk">The overall structure of the MisGAN framework [2]</figcaption></figure><p id="8835" class="pw-post-body-paragraph lr ls it lt b lu mp ju lw lx mq jx lz ma mr mc md me ms mg mh mi mt mk ml mm im bi translated">发生器<em class="nq"> Gx </em>产生完整的数据，发生器<em class="nq"> Gm </em>产生缺失数据的掩码(它是一个二进制矩阵，其中‘1’代表非缺失数据，而‘0’代表缺失数据)。然后在鉴别器<em class="nq"> Dx </em>和<em class="nq"> Dm </em>中对其进行比较，以检查其是否可以与真实数据矩阵<em class="nq"> x </em>和真实缺失值掩码矩阵<em class="nq">m</em>区分开来。这里需要注意的重要一点是，在成功训练 MisGAN 架构后，我们可以分别生成完整的数据和缺失值掩码。很酷吧。</p><p id="f422" class="pw-post-body-paragraph lr ls it lt b lu mp ju lw lx mq jx lz ma mr mc md me ms mg mh mi mt mk ml mm im bi translated">对上面的架构有一个调整，可以直接创建一个缺失数据估算器。在这种情况下，我们有可以生成完整数据的预训练生成器<em class="nq"> Gx </em>和充当估算器的生成器<em class="nq"> Gi </em>。它被馈送到单个鉴别器<em class="nq"> Di </em>并检查<em class="nq"> Gi </em>是否从带有缺失值的数据中产生令人满意的结果。下图更详细地展示了该架构。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nw"><img src="../Images/6ba035f2cb5905229ad4277c4a773335.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*OXflBakkORWMBZ80kB1qMQ.png"/></div></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk">Architecture for MisGAN imputation [2]</figcaption></figure><h2 id="8f84" class="nb la it bd lb nc nd dn lf ne nf dp lj ma ng nh ll me ni nj ln mi nk nl lp nm bi translated">维甘</h2><p id="df14" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">VIGAN 以不同的方式处理缺失数据的问题。为了向你介绍这个问题，让我们想象我们有一个实验，在这个实验中，一家医院为某个样本的病人收集神经图像，为一个完全不同的样本的病人收集大脑信号。这导致了不成对的数据，从而导致多模态(<a class="ae ky" rel="noopener" target="_blank" href="/multimodal-deep-learning-ce7d1d994f4">，即以不同的方式表达同一事物；图像和文字描述就是一个很好的例子)</a>数据分析。使用这两个数据集时，患者数据没有一对一的映射。我们不能简单地将它们结合起来，因为患者在数据集中是独一无二的。它需要不同的数学建模来解决这个问题，这通常是大数据中的一个常见问题[3]。通常，您甚至不能将不同来源的数据集组合在一起(所谓的多视图数据)，因为它们实在太大了。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nx"><img src="../Images/5eeb6f83f0e5babaf593c2a763d053e1.png" data-original-src="https://miro.medium.com/v2/resize:fit:802/format:webp/1*J7v8NT9xeKuWGIW-l9Y90A.png"/></div></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk">The missing view problem extremely limits the cross-view collaborative learning [3]</figcaption></figure><p id="85d9" class="pw-post-body-paragraph lr ls it lt b lu mp ju lw lx mq jx lz ma mr mc md me ms mg mh mi mt mk ml mm im bi translated">这种 GAN 架构解决了多模态或多视图数据集中缺失数据的问题。作者声称他们的解决方案是高度可扩展的，并且是将域映射与缺失数据的跨视图插补相结合的第一种方法[3]。</p><p id="9d55" class="pw-post-body-paragraph lr ls it lt b lu mp ju lw lx mq jx lz ma mr mc md me ms mg mh mi mt mk ml mm im bi translated">其背后的思想比 GAIN 和 MisGAN 更复杂，解释其背后的数学概念需要很长时间。如果你想冒险，看看这里的论文<a class="ae ky" href="https://arxiv.org/abs/1708.06724" rel="noopener ugc nofollow" target="_blank"/>。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ny"><img src="../Images/220dbec9853e48e394f4eb1f0fd3396f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1200/format:webp/1*EUqda3XpuVqJygdZ-knmpQ.jpeg"/></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk">It can take a while to read — you’ve been warned! <a class="ae ky" href="https://makeameme.org/meme/after-finishing-this" rel="noopener ugc nofollow" target="_blank">[Source]</a></figcaption></figure><h2 id="fe36" class="nb la it bd lb nc nd dn lf ne nf dp lj ma ng nh ll me ni nj ln mi nk nl lp nm bi translated">科拉根</h2><p id="d781" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">协作 GAN 处理稍微不同类型的丢失数据。它用于缺失图像数据插补。根据论文作者的观点，该架构在图像领域优于其他 GAN 架构的优势如下:</p><ul class=""><li id="5ce2" class="nz oa it lt b lu mp lx mq ma ob me oc mi od mm oe of og oh bi translated">缺失数据估计更加准确</li><li id="2ef6" class="nz oa it lt b lu oi lx oj ma ok me ol mi om mm oe of og oh bi translated">单发生器架构仍然存在，这使得它更节省内存</li></ul><p id="7e63" class="pw-post-body-paragraph lr ls it lt b lu mp ju lw lx mq jx lz ma mr mc md me ms mg mh mi mt mk ml mm im bi translated">该框架的新颖之处在于，它“将图像插补问题转化为多域图像到图像的转换任务，使得单个生成器和鉴别器网络可以使用剩余的干净数据集成功地估计缺失数据。[4]"</p><p id="d8b3" class="pw-post-body-paragraph lr ls it lt b lu mp ju lw lx mq jx lz ma mr mc md me ms mg mh mi mt mk ml mm im bi translated">在我个人看来，这篇论文的措辞有点模糊，我发现很难完全理解他们是如何实现他们的 GAN 架构的。如果你觉得这个想法很有趣，可以在这里看一下最初的<a class="ae ky" href="https://arxiv.org/abs/1901.09764" rel="noopener ugc nofollow" target="_blank">论文。</a></p><h1 id="8d46" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">Github 仓库</h1><p id="4c9b" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">在 Github 中快速浏览之后，我发现这些 GAN 架构已经有了一些实现！为了方便起见，我在下面列出了它们。</p><h2 id="875b" class="nb la it bd lb nc nd dn lf ne nf dp lj ma ng nh ll me ni nj ln mi nk nl lp nm bi translated"><strong class="ak">增益</strong></h2><p id="18ff" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">这个库似乎是 GAIN 中最受欢迎的，它使用了 Tensorflow。它在 Github 上有&gt; 70 颗星，但是从 2019 年 3 月开始就没有更新过。</p><h2 id="7496" class="nb la it bd lb nc nd dn lf ne nf dp lj ma ng nh ll me ni nj ln mi nk nl lp nm bi translated"><strong class="ak">维甘</strong></h2><p id="fb67" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">VIGAN 已经在 PyTorch 中实现了，但是它在拥有 20 颗星的情况下似乎不是很受欢迎。回购的链接是<a class="ae ky" href="https://github.com/chaoshangcs/VIGAN" rel="noopener ugc nofollow" target="_blank">这里的</a>。</p></div><div class="ab cl mu mv hx mw" role="separator"><span class="mx bw bk my mz na"/><span class="mx bw bk my mz na"/><span class="mx bw bk my mz"/></div><div class="im in io ip iq"><h1 id="2ce9" class="kz la it bd lb lc on le lf lg oo li lj jz op ka ll kc oq kd ln kf or kg lp lq bi translated">最后几句话要说</h1><p id="4527" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">虽然用 GANs 输入缺失数据是一个相对较新的概念，但它显示了非常有前途的结果。在不久的将来，我们可能会看到更多的 GAN 架构以更高的精度处理缺失数据。</p><p id="9a58" class="pw-post-body-paragraph lr ls it lt b lu mp ju lw lx mq jx lz ma mr mc md me ms mg mh mi mt mk ml mm im bi translated">希望你觉得我的文章有用。如果你有任何问题，请在评论中告诉我，或者随时在 LinkedIn 上与我联系。</p><h1 id="e548" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">参考</h1><p id="5c77" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">[1]增益，<a class="ae ky" href="https://arxiv.org/abs/1806.02920" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/abs/1806.02920</a></p><p id="771a" class="pw-post-body-paragraph lr ls it lt b lu mp ju lw lx mq jx lz ma mr mc md me ms mg mh mi mt mk ml mm im bi translated">[2]米斯根，<a class="ae ky" href="https://openreview.net/pdf?id=S1lDV3RcKm" rel="noopener ugc nofollow" target="_blank">https://openreview.net/pdf?id=S1lDV3RcKm</a></p><p id="686b" class="pw-post-body-paragraph lr ls it lt b lu mp ju lw lx mq jx lz ma mr mc md me ms mg mh mi mt mk ml mm im bi translated">[3]维根，<a class="ae ky" href="https://arxiv.org/abs/1708.06724" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/abs/1708.06724</a></p><p id="c0df" class="pw-post-body-paragraph lr ls it lt b lu mp ju lw lx mq jx lz ma mr mc md me ms mg mh mi mt mk ml mm im bi translated">[4]科拉甘，<a class="ae ky" href="https://arxiv.org/abs/1901.09764" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/abs/1901.09764</a></p></div></div>    
</body>
</html>