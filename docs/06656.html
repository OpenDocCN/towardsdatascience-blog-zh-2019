<html>
<head>
<title>A Whirlwind Tour of Machine Learning Models</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">机器学习模型的旋风之旅</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/a-whirlwind-tour-of-machine-learning-models-e3574e6f2586?source=collection_archive---------18-----------------------#2019-09-23">https://towardsdatascience.com/a-whirlwind-tour-of-machine-learning-models-e3574e6f2586?source=collection_archive---------18-----------------------#2019-09-23</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><p id="9544" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">深入探讨不同的机器学习模型以及何时应该使用它们！</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi ko"><img src="../Images/ceb46b8e63306e371cdcfa8514f86a9a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*6b735C0fR6ACCzQS.png"/></div></div></figure><p id="63c9" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">在第一部分“选择机器学习模型”中，我们谈到了选择完美的机器学习模型的艺术和科学。</p><p id="4fab" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">在第二部分中，我们深入探讨了你可以训练的不同机器学习模型，以及你何时应该使用它们！</p><p id="f2b4" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">一般来说，基于树的模型在 Kaggle 竞赛中表现最好。其他型号是组装的绝佳选择。对于计算机视觉挑战，CNN 胜过一切。对于自然语言处理，LSTMs 或 GRUs 是您的最佳选择！</p><p id="be62" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">也就是说，下面是可供尝试的模型的非详尽清单，以及每个模型的一些上下文。</p><h1 id="40b4" class="la lb it bd lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx bi translated">回归</h1><h2 id="b9e5" class="ly lb it bd lc lz ma dn lg mb mc dp lk kb md me lo kf mf mg ls kj mh mi lw mj bi translated">回归→线性回归→普通线性回归</h2><p id="6f79" class="pw-post-body-paragraph jq jr it js b jt mk jv jw jx ml jz ka kb mm kd ke kf mn kh ki kj mo kl km kn im bi translated"><strong class="js iu">优势</strong></p><ul class=""><li id="f738" class="mp mq it js b jt ju jx jy kb mr kf ms kj mt kn mu mv mw mx bi translated">很好地捕获数据集中的线性关系</li><li id="48d6" class="mp mq it js b jt my jx mz kb na kf nb kj nc kn mu mv mw mx bi translated">如果您有几个明确定义的变量，并且需要一个简单的预测模型，那么这个方法非常有效</li><li id="8770" class="mp mq it js b jt my jx mz kb na kf nb kj nc kn mu mv mw mx bi translated">快速的训练速度和预测速度</li><li id="aac2" class="mp mq it js b jt my jx mz kb na kf nb kj nc kn mu mv mw mx bi translated">在小数据集上表现良好</li><li id="b14f" class="mp mq it js b jt my jx mz kb na kf nb kj nc kn mu mv mw mx bi translated">可解释的结果，易于解释</li><li id="3d07" class="mp mq it js b jt my jx mz kb na kf nb kj nc kn mu mv mw mx bi translated">当新数据进来时，容易更新模型</li><li id="3183" class="mp mq it js b jt my jx mz kb na kf nb kj nc kn mu mv mw mx bi translated">不需要调整参数(下面的正则化线性模型需要调整正则化参数)</li><li id="8023" class="mp mq it js b jt my jx mz kb na kf nb kj nc kn mu mv mw mx bi translated">不需要特征缩放(下面的正则化线性模型需要特征缩放)</li><li id="fd71" class="mp mq it js b jt my jx mz kb na kf nb kj nc kn mu mv mw mx bi translated">如果数据集包含冗余要素，线性回归可能会不稳定</li></ul><p id="700f" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu">缺点</strong></p><ul class=""><li id="e8e0" class="mp mq it js b jt ju jx jy kb mr kf ms kj mt kn mu mv mw mx bi translated">不适用于非线性数据</li><li id="a426" class="mp mq it js b jt my jx mz kb na kf nb kj nc kn mu mv mw mx bi translated">预测准确度低</li><li id="bb58" class="mp mq it js b jt my jx mz kb na kf nb kj nc kn mu mv mw mx bi translated">可能会过度拟合(见下面的正则化模型来抵消这一点)</li><li id="d68f" class="mp mq it js b jt my jx mz kb na kf nb kj nc kn mu mv mw mx bi translated">无法很好地将信号与噪声分开——在使用前剔除不相关的特征</li><li id="deed" class="mp mq it js b jt my jx mz kb na kf nb kj nc kn mu mv mw mx bi translated">不了解数据集中的要素交互</li></ul><h2 id="9418" class="ly lb it bd lc lz ma dn lg mb mc dp lk kb md me lo kf mf mg ls kj mh mi lw mj bi translated">回归→线性回归→套索、脊、弹性网回归</h2><p id="0c56" class="pw-post-body-paragraph jq jr it js b jt mk jv jw jx ml jz ka kb mm kd ke kf mn kh ki kj mo kl km kn im bi translated"><strong class="js iu">优点</strong></p><ul class=""><li id="555d" class="mp mq it js b jt ju jx jy kb mr kf ms kj mt kn mu mv mw mx bi translated">这些模型是带有正则化的线性回归</li><li id="7e81" class="mp mq it js b jt my jx mz kb na kf nb kj nc kn mu mv mw mx bi translated">帮助抵消过度拟合</li><li id="d6ee" class="mp mq it js b jt my jx mz kb na kf nb kj nc kn mu mv mw mx bi translated">这些模型更容易概括，因为它们更简单</li><li id="adb4" class="mp mq it js b jt my jx mz kb na kf nb kj nc kn mu mv mw mx bi translated">当我们只关心少数几个特性时，它们工作得很好</li></ul><p id="5540" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu">缺点</strong></p><ul class=""><li id="4eba" class="mp mq it js b jt ju jx jy kb mr kf ms kj mt kn mu mv mw mx bi translated">需要功能缩放</li><li id="ee48" class="mp mq it js b jt my jx mz kb na kf nb kj nc kn mu mv mw mx bi translated">需要调整正则化参数</li></ul><h2 id="2035" class="ly lb it bd lc lz ma dn lg mb mc dp lk kb md me lo kf mf mg ls kj mh mi lw mj bi translated">回归→回归树→决策树</h2><p id="716c" class="pw-post-body-paragraph jq jr it js b jt mk jv jw jx ml jz ka kb mm kd ke kf mn kh ki kj mo kl km kn im bi translated"><strong class="js iu">优点</strong></p><ul class=""><li id="f27b" class="mp mq it js b jt ju jx jy kb mr kf ms kj mt kn mu mv mw mx bi translated">快速的训练速度和预测速度</li><li id="02be" class="mp mq it js b jt my jx mz kb na kf nb kj nc kn mu mv mw mx bi translated">很好地捕捉数据集中的非线性关系</li><li id="591c" class="mp mq it js b jt my jx mz kb na kf nb kj nc kn mu mv mw mx bi translated">了解数据集中的要素交互</li><li id="235e" class="mp mq it js b jt my jx mz kb na kf nb kj nc kn mu mv mw mx bi translated">当数据集有异常值时非常有用</li><li id="548e" class="mp mq it js b jt my jx mz kb na kf nb kj nc kn mu mv mw mx bi translated">非常适合在数据集中查找最重要的要素</li><li id="714d" class="mp mq it js b jt my jx mz kb na kf nb kj nc kn mu mv mw mx bi translated">不需要功能缩放</li><li id="d336" class="mp mq it js b jt my jx mz kb na kf nb kj nc kn mu mv mw mx bi translated">合理的解释结果，易于解释</li></ul><p id="36b6" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu">缺点</strong></p><ul class=""><li id="6316" class="mp mq it js b jt ju jx jy kb mr kf ms kj mt kn mu mv mw mx bi translated">预测准确度低</li><li id="857b" class="mp mq it js b jt my jx mz kb na kf nb kj nc kn mu mv mw mx bi translated">需要一些参数调整</li><li id="b372" class="mp mq it js b jt my jx mz kb na kf nb kj nc kn mu mv mw mx bi translated">在小数据集上表现不佳</li><li id="54ed" class="mp mq it js b jt my jx mz kb na kf nb kj nc kn mu mv mw mx bi translated">没有很好地分离信号和噪声</li><li id="869d" class="mp mq it js b jt my jx mz kb na kf nb kj nc kn mu mv mw mx bi translated">当新数据进来时，不容易更新模型</li><li id="73eb" class="mp mq it js b jt my jx mz kb na kf nb kj nc kn mu mv mw mx bi translated">实践中很少使用，请使用集合树</li><li id="7dfa" class="mp mq it js b jt my jx mz kb na kf nb kj nc kn mu mv mw mx bi translated">可以过度装配(见下面的套装模型)</li></ul><h2 id="41c7" class="ly lb it bd lc lz ma dn lg mb mc dp lk kb md me lo kf mf mg ls kj mh mi lw mj bi translated">回归→回归树→集成</h2><p id="fdad" class="pw-post-body-paragraph jq jr it js b jt mk jv jw jx ml jz ka kb mm kd ke kf mn kh ki kj mo kl km kn im bi translated"><strong class="js iu">优点</strong></p><ul class=""><li id="537a" class="mp mq it js b jt ju jx jy kb mr kf ms kj mt kn mu mv mw mx bi translated">整理来自多个树的预测</li><li id="6c51" class="mp mq it js b jt my jx mz kb na kf nb kj nc kn mu mv mw mx bi translated">高预测准确性——在实践中非常有效</li><li id="d6f5" class="mp mq it js b jt my jx mz kb na kf nb kj nc kn mu mv mw mx bi translated">Kaggle 竞赛中的首选算法</li><li id="dcd3" class="mp mq it js b jt my jx mz kb na kf nb kj nc kn mu mv mw mx bi translated">当数据集有异常值时非常有用</li><li id="277d" class="mp mq it js b jt my jx mz kb na kf nb kj nc kn mu mv mw mx bi translated">很好地捕捉数据集中的非线性关系</li><li id="793b" class="mp mq it js b jt my jx mz kb na kf nb kj nc kn mu mv mw mx bi translated">非常适合在数据集中查找最重要的要素</li><li id="1a51" class="mp mq it js b jt my jx mz kb na kf nb kj nc kn mu mv mw mx bi translated">分离信号和噪声</li><li id="4b82" class="mp mq it js b jt my jx mz kb na kf nb kj nc kn mu mv mw mx bi translated">不需要功能缩放</li><li id="8b62" class="mp mq it js b jt my jx mz kb na kf nb kj nc kn mu mv mw mx bi translated">在高维数据上表现出色</li></ul><p id="b0ca" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu">缺点</strong></p><ul class=""><li id="ae16" class="mp mq it js b jt ju jx jy kb mr kf ms kj mt kn mu mv mw mx bi translated">训练速度较慢</li><li id="0fad" class="mp mq it js b jt my jx mz kb na kf nb kj nc kn mu mv mw mx bi translated">预测速度快</li><li id="fef0" class="mp mq it js b jt my jx mz kb na kf nb kj nc kn mu mv mw mx bi translated">不容易解释或者说明</li><li id="fc3d" class="mp mq it js b jt my jx mz kb na kf nb kj nc kn mu mv mw mx bi translated">当新数据进来时，不容易更新模型</li><li id="39b9" class="mp mq it js b jt my jx mz kb na kf nb kj nc kn mu mv mw mx bi translated">需要一些参数调整—更难调整</li><li id="8ce1" class="mp mq it js b jt my jx mz kb na kf nb kj nc kn mu mv mw mx bi translated">在小数据集上表现不佳</li></ul><h2 id="7418" class="ly lb it bd lc lz ma dn lg mb mc dp lk kb md me lo kf mf mg ls kj mh mi lw mj bi translated">回归→深度学习</h2><p id="6dd0" class="pw-post-body-paragraph jq jr it js b jt mk jv jw jx ml jz ka kb mm kd ke kf mn kh ki kj mo kl km kn im bi translated"><strong class="js iu">优势</strong></p><ul class=""><li id="6ba6" class="mp mq it js b jt ju jx jy kb mr kf ms kj mt kn mu mv mw mx bi translated">高预测准确性——在实践中非常有效</li><li id="ddc8" class="mp mq it js b jt my jx mz kb na kf nb kj nc kn mu mv mw mx bi translated">捕捉数据中非常复杂的潜在模式</li><li id="1dee" class="mp mq it js b jt my jx mz kb na kf nb kj nc kn mu mv mw mx bi translated">对大数据集和高维数据都很有效</li><li id="7f0a" class="mp mq it js b jt my jx mz kb na kf nb kj nc kn mu mv mw mx bi translated">当新数据进来时，容易更新模型</li><li id="e9e8" class="mp mq it js b jt my jx mz kb na kf nb kj nc kn mu mv mw mx bi translated">网络的隐藏层显著降低了对特征工程的需求</li><li id="ec9b" class="mp mq it js b jt my jx mz kb na kf nb kj nc kn mu mv mw mx bi translated">是计算机视觉、机器翻译、情感分析和语音识别任务的最新技术</li></ul><p id="0413" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu">缺点</strong></p><ul class=""><li id="d43c" class="mp mq it js b jt ju jx jy kb mr kf ms kj mt kn mu mv mw mx bi translated">非常长的训练速度</li><li id="3c5c" class="mp mq it js b jt my jx mz kb na kf nb kj nc kn mu mv mw mx bi translated">需要巨大的计算能力</li><li id="9db1" class="mp mq it js b jt my jx mz kb na kf nb kj nc kn mu mv mw mx bi translated">需要功能缩放</li><li id="66bb" class="mp mq it js b jt my jx mz kb na kf nb kj nc kn mu mv mw mx bi translated">不容易解释或诠释结果</li><li id="0f20" class="mp mq it js b jt my jx mz kb na kf nb kj nc kn mu mv mw mx bi translated">需要大量的训练数据，因为它学习大量的参数</li><li id="cb98" class="mp mq it js b jt my jx mz kb na kf nb kj nc kn mu mv mw mx bi translated">在非图像、非文本、非语音任务方面优于 Boosting 算法</li><li id="3953" class="mp mq it js b jt my jx mz kb na kf nb kj nc kn mu mv mw mx bi translated">非常灵活，带有许多不同的架构构建模块，因此需要专业知识来设计架构</li></ul><h2 id="7b2a" class="ly lb it bd lc lz ma dn lg mb mc dp lk kb md me lo kf mf mg ls kj mh mi lw mj bi translated">回归→ K 个最近邻(基于距离)</h2><p id="34f8" class="pw-post-body-paragraph jq jr it js b jt mk jv jw jx ml jz ka kb mm kd ke kf mn kh ki kj mo kl km kn im bi translated"><strong class="js iu">优点</strong></p><ul class=""><li id="9c53" class="mp mq it js b jt ju jx jy kb mr kf ms kj mt kn mu mv mw mx bi translated">训练速度快</li><li id="f8d1" class="mp mq it js b jt my jx mz kb na kf nb kj nc kn mu mv mw mx bi translated">不需要太多的参数调整</li><li id="6aec" class="mp mq it js b jt my jx mz kb na kf nb kj nc kn mu mv mw mx bi translated">可解释的结果，易于解释</li><li id="0585" class="mp mq it js b jt my jx mz kb na kf nb kj nc kn mu mv mw mx bi translated">适用于小型数据集(&lt;100k training set)</li></ul><p id="9634" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu">缺点</strong></p><ul class=""><li id="5051" class="mp mq it js b jt ju jx jy kb mr kf ms kj mt kn mu mv mw mx bi translated">预测准确度低</li><li id="07b4" class="mp mq it js b jt my jx mz kb na kf nb kj nc kn mu mv mw mx bi translated">在小数据集上表现不佳</li><li id="d5b3" class="mp mq it js b jt my jx mz kb na kf nb kj nc kn mu mv mw mx bi translated">需要选择一个合适的距离函数</li><li id="0418" class="mp mq it js b jt my jx mz kb na kf nb kj nc kn mu mv mw mx bi translated">需要功能缩放才能正常工作</li><li id="31b7" class="mp mq it js b jt my jx mz kb na kf nb kj nc kn mu mv mw mx bi translated">预测速度随着数据集的大小而增长</li><li id="dedb" class="mp mq it js b jt my jx mz kb na kf nb kj nc kn mu mv mw mx bi translated">无法很好地将信号与噪声分开——在使用前剔除不相关的特征</li><li id="4c14" class="mp mq it js b jt my jx mz kb na kf nb kj nc kn mu mv mw mx bi translated">是内存密集型的，因为它保存每个观察</li><li id="91cd" class="mp mq it js b jt my jx mz kb na kf nb kj nc kn mu mv mw mx bi translated">也意味着它们不能很好地处理高维数据</li></ul><h1 id="a9bd" class="la lb it bd lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx bi translated">2.分类</h1><h2 id="519a" class="ly lb it bd lc lz ma dn lg mb mc dp lk kb md me lo kf mf mg ls kj mh mi lw mj bi translated">分类→逻辑回归</h2><p id="5969" class="pw-post-body-paragraph jq jr it js b jt mk jv jw jx ml jz ka kb mm kd ke kf mn kh ki kj mo kl km kn im bi translated"><strong class="js iu">优点</strong></p><ul class=""><li id="5e90" class="mp mq it js b jt ju jx jy kb mr kf ms kj mt kn mu mv mw mx bi translated">很好地分类线性可分数据</li><li id="e94d" class="mp mq it js b jt my jx mz kb na kf nb kj nc kn mu mv mw mx bi translated">快速的训练速度和预测速度</li><li id="da62" class="mp mq it js b jt my jx mz kb na kf nb kj nc kn mu mv mw mx bi translated">在小数据集上表现良好</li><li id="d131" class="mp mq it js b jt my jx mz kb na kf nb kj nc kn mu mv mw mx bi translated">合理的解释结果，易于解释</li><li id="c55d" class="mp mq it js b jt my jx mz kb na kf nb kj nc kn mu mv mw mx bi translated">当新数据进来时，容易更新模型</li><li id="ec10" class="mp mq it js b jt my jx mz kb na kf nb kj nc kn mu mv mw mx bi translated">正则化时可以避免过度拟合</li><li id="c6e2" class="mp mq it js b jt my jx mz kb na kf nb kj nc kn mu mv mw mx bi translated">可以进行两类和多类分类</li><li id="3935" class="mp mq it js b jt my jx mz kb na kf nb kj nc kn mu mv mw mx bi translated">不需要参数调整(除了正则化时，我们需要调整正则化参数)</li><li id="8bc1" class="mp mq it js b jt my jx mz kb na kf nb kj nc kn mu mv mw mx bi translated">不需要特征缩放(除了正则化时)</li><li id="066b" class="mp mq it js b jt my jx mz kb na kf nb kj nc kn mu mv mw mx bi translated">如果数据集包含冗余要素，线性回归可能会不稳定</li></ul><p id="9d60" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu">缺点</strong></p><ul class=""><li id="9d6f" class="mp mq it js b jt ju jx jy kb mr kf ms kj mt kn mu mv mw mx bi translated">不适用于非线性可分离数据</li><li id="300d" class="mp mq it js b jt my jx mz kb na kf nb kj nc kn mu mv mw mx bi translated">预测准确度低</li><li id="512b" class="mp mq it js b jt my jx mz kb na kf nb kj nc kn mu mv mw mx bi translated">可能过度拟合(参见下面的正则化模型)</li><li id="af49" class="mp mq it js b jt my jx mz kb na kf nb kj nc kn mu mv mw mx bi translated">无法很好地将信号与噪声分开——在使用前剔除不相关的特征</li><li id="70a7" class="mp mq it js b jt my jx mz kb na kf nb kj nc kn mu mv mw mx bi translated">不了解数据集中的要素交互</li></ul><h2 id="01e9" class="ly lb it bd lc lz ma dn lg mb mc dp lk kb md me lo kf mf mg ls kj mh mi lw mj bi translated">分类→支持向量机(基于距离)</h2><p id="6e91" class="pw-post-body-paragraph jq jr it js b jt mk jv jw jx ml jz ka kb mm kd ke kf mn kh ki kj mo kl km kn im bi translated"><strong class="js iu">优势</strong></p><ul class=""><li id="d758" class="mp mq it js b jt ju jx jy kb mr kf ms kj mt kn mu mv mw mx bi translated">预测精度高</li><li id="99be" class="mp mq it js b jt my jx mz kb na kf nb kj nc kn mu mv mw mx bi translated">即使在高维数据集上也不会过度拟合，因此当您拥有大量要素时，它非常有用</li><li id="e3ea" class="mp mq it js b jt my jx mz kb na kf nb kj nc kn mu mv mw mx bi translated">适用于小型数据集(&lt;100k training set)</li><li id="7551" class="mp mq it js b jt my jx mz kb na kf nb kj nc kn mu mv mw mx bi translated">Work well for text classification problems</li></ul><p id="9cb7" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu">缺点</strong></p><ul class=""><li id="cc3e" class="mp mq it js b jt ju jx jy kb mr kf ms kj mt kn mu mv mw mx bi translated">当新数据进来时，不容易更新模型</li><li id="8bf4" class="mp mq it js b jt my jx mz kb na kf nb kj nc kn mu mv mw mx bi translated">非常占用内存</li><li id="52d9" class="mp mq it js b jt my jx mz kb na kf nb kj nc kn mu mv mw mx bi translated">不适用于大型数据集</li><li id="1dd1" class="mp mq it js b jt my jx mz kb na kf nb kj nc kn mu mv mw mx bi translated">当新数据进来时，不容易更新模型</li><li id="e883" class="mp mq it js b jt my jx mz kb na kf nb kj nc kn mu mv mw mx bi translated">需要你选择正确的内核才能工作</li><li id="8494" class="mp mq it js b jt my jx mz kb na kf nb kj nc kn mu mv mw mx bi translated">线性内核模拟线性数据，工作速度很快</li><li id="8d5d" class="mp mq it js b jt my jx mz kb na kf nb kj nc kn mu mv mw mx bi translated">非线性核可以模拟非线性边界，并且可能很慢</li><li id="4643" class="mp mq it js b jt my jx mz kb na kf nb kj nc kn mu mv mw mx bi translated">改用 Boosting！</li></ul><h2 id="77b3" class="ly lb it bd lc lz ma dn lg mb mc dp lk kb md me lo kf mf mg ls kj mh mi lw mj bi translated">分类→朴素贝叶斯(基于概率)</h2><p id="5ac1" class="pw-post-body-paragraph jq jr it js b jt mk jv jw jx ml jz ka kb mm kd ke kf mn kh ki kj mo kl km kn im bi translated"><strong class="js iu">优势</strong></p><ul class=""><li id="a6a0" class="mp mq it js b jt ju jx jy kb mr kf ms kj mt kn mu mv mw mx bi translated">在文本分类问题上表现很好</li><li id="f478" class="mp mq it js b jt my jx mz kb na kf nb kj nc kn mu mv mw mx bi translated">快速的训练速度和预测速度</li><li id="d61e" class="mp mq it js b jt my jx mz kb na kf nb kj nc kn mu mv mw mx bi translated">在小数据集上表现良好</li><li id="6b33" class="mp mq it js b jt my jx mz kb na kf nb kj nc kn mu mv mw mx bi translated">很好地分离信号和噪声</li><li id="b966" class="mp mq it js b jt my jx mz kb na kf nb kj nc kn mu mv mw mx bi translated">在实践中表现良好</li><li id="e12d" class="mp mq it js b jt my jx mz kb na kf nb kj nc kn mu mv mw mx bi translated">简单，易于实施</li><li id="bc7b" class="mp mq it js b jt my jx mz kb na kf nb kj nc kn mu mv mw mx bi translated">适用于小型数据集(&lt;100k training set)</li><li id="1e3d" class="mp mq it js b jt my jx mz kb na kf nb kj nc kn mu mv mw mx bi translated">The naive assumption about the independence of features and their potential distribution lets it avoid overfitting</li><li id="fa64" class="mp mq it js b jt my jx mz kb na kf nb kj nc kn mu mv mw mx bi translated">Also if this condition of independence holds, Naive Bayes can work on smaller datasets and can have faster training speed</li><li id="1cb3" class="mp mq it js b jt my jx mz kb na kf nb kj nc kn mu mv mw mx bi translated">Doesn’t need feature scaling</li><li id="f88f" class="mp mq it js b jt my jx mz kb na kf nb kj nc kn mu mv mw mx bi translated">Not memory intensive</li><li id="0981" class="mp mq it js b jt my jx mz kb na kf nb kj nc kn mu mv mw mx bi translated">Decently interpretable results, easy to explain</li><li id="8f39" class="mp mq it js b jt my jx mz kb na kf nb kj nc kn mu mv mw mx bi translated">Scales well with the size of the dataset</li></ul><p id="9772" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu">缺点</strong></p><ul class=""><li id="6093" class="mp mq it js b jt ju jx jy kb mr kf ms kj mt kn mu mv mw mx bi translated">预测准确度低</li></ul><h2 id="d419" class="ly lb it bd lc lz ma dn lg mb mc dp lk kb md me lo kf mf mg ls kj mh mi lw mj bi translated">分类→ K 个最近邻(基于距离)</h2><p id="e6fd" class="pw-post-body-paragraph jq jr it js b jt mk jv jw jx ml jz ka kb mm kd ke kf mn kh ki kj mo kl km kn im bi translated"><strong class="js iu">优点</strong></p><ul class=""><li id="aa5a" class="mp mq it js b jt ju jx jy kb mr kf ms kj mt kn mu mv mw mx bi translated">训练速度快</li><li id="e670" class="mp mq it js b jt my jx mz kb na kf nb kj nc kn mu mv mw mx bi translated">不需要太多的参数调整</li><li id="880b" class="mp mq it js b jt my jx mz kb na kf nb kj nc kn mu mv mw mx bi translated">可解释的结果，易于解释</li><li id="6d45" class="mp mq it js b jt my jx mz kb na kf nb kj nc kn mu mv mw mx bi translated">适用于小型数据集(&lt;100k training set)</li></ul><p id="5663" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu">缺点</strong></p><ul class=""><li id="72f5" class="mp mq it js b jt ju jx jy kb mr kf ms kj mt kn mu mv mw mx bi translated">预测准确度低</li><li id="c775" class="mp mq it js b jt my jx mz kb na kf nb kj nc kn mu mv mw mx bi translated">在小数据集上表现不佳</li><li id="b7ff" class="mp mq it js b jt my jx mz kb na kf nb kj nc kn mu mv mw mx bi translated">需要选择一个合适的距离函数</li><li id="0ee7" class="mp mq it js b jt my jx mz kb na kf nb kj nc kn mu mv mw mx bi translated">需要功能缩放才能正常工作</li><li id="7052" class="mp mq it js b jt my jx mz kb na kf nb kj nc kn mu mv mw mx bi translated">预测速度随着数据集的大小而增长</li><li id="c0c0" class="mp mq it js b jt my jx mz kb na kf nb kj nc kn mu mv mw mx bi translated">无法很好地将信号与噪声分开——在使用前剔除不相关的特征</li><li id="de5c" class="mp mq it js b jt my jx mz kb na kf nb kj nc kn mu mv mw mx bi translated">是内存密集型的，因为它保存每个观察</li><li id="e109" class="mp mq it js b jt my jx mz kb na kf nb kj nc kn mu mv mw mx bi translated">也意味着它们不能很好地处理高维数据</li></ul><h2 id="c4cc" class="ly lb it bd lc lz ma dn lg mb mc dp lk kb md me lo kf mf mg ls kj mh mi lw mj bi translated">分类→分类树→决策树</h2><p id="524b" class="pw-post-body-paragraph jq jr it js b jt mk jv jw jx ml jz ka kb mm kd ke kf mn kh ki kj mo kl km kn im bi translated"><strong class="js iu">优点</strong></p><ul class=""><li id="d2cd" class="mp mq it js b jt ju jx jy kb mr kf ms kj mt kn mu mv mw mx bi translated">快速的训练速度和预测速度</li><li id="695f" class="mp mq it js b jt my jx mz kb na kf nb kj nc kn mu mv mw mx bi translated">很好地捕捉数据集中的非线性关系</li><li id="789e" class="mp mq it js b jt my jx mz kb na kf nb kj nc kn mu mv mw mx bi translated">了解数据集中的要素交互</li><li id="adb0" class="mp mq it js b jt my jx mz kb na kf nb kj nc kn mu mv mw mx bi translated">当数据集有异常值时非常有用</li><li id="9d81" class="mp mq it js b jt my jx mz kb na kf nb kj nc kn mu mv mw mx bi translated">非常适合在数据集中查找最重要的要素</li><li id="1aa8" class="mp mq it js b jt my jx mz kb na kf nb kj nc kn mu mv mw mx bi translated">可以进行两类和多类分类</li><li id="4f6c" class="mp mq it js b jt my jx mz kb na kf nb kj nc kn mu mv mw mx bi translated">不需要功能缩放</li><li id="5153" class="mp mq it js b jt my jx mz kb na kf nb kj nc kn mu mv mw mx bi translated">合理的解释结果，易于解释</li></ul><p id="8e64" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu">缺点</strong></p><ul class=""><li id="3d4c" class="mp mq it js b jt ju jx jy kb mr kf ms kj mt kn mu mv mw mx bi translated">预测准确度低</li><li id="ed74" class="mp mq it js b jt my jx mz kb na kf nb kj nc kn mu mv mw mx bi translated">需要一些参数调整</li><li id="1460" class="mp mq it js b jt my jx mz kb na kf nb kj nc kn mu mv mw mx bi translated">在小数据集上表现不佳</li><li id="8677" class="mp mq it js b jt my jx mz kb na kf nb kj nc kn mu mv mw mx bi translated">没有很好地分离信号和噪声</li><li id="e55e" class="mp mq it js b jt my jx mz kb na kf nb kj nc kn mu mv mw mx bi translated">实践中很少使用，请使用集合树</li><li id="8445" class="mp mq it js b jt my jx mz kb na kf nb kj nc kn mu mv mw mx bi translated">当新数据进来时，不容易更新模型</li><li id="5d53" class="mp mq it js b jt my jx mz kb na kf nb kj nc kn mu mv mw mx bi translated">可以过度装配(见下面的套装模型)</li></ul><h2 id="17eb" class="ly lb it bd lc lz ma dn lg mb mc dp lk kb md me lo kf mf mg ls kj mh mi lw mj bi translated">分类→分类树→集成</h2><p id="a3fd" class="pw-post-body-paragraph jq jr it js b jt mk jv jw jx ml jz ka kb mm kd ke kf mn kh ki kj mo kl km kn im bi translated"><strong class="js iu">优势</strong></p><ul class=""><li id="f1b4" class="mp mq it js b jt ju jx jy kb mr kf ms kj mt kn mu mv mw mx bi translated">整理来自多个树的预测</li><li id="8143" class="mp mq it js b jt my jx mz kb na kf nb kj nc kn mu mv mw mx bi translated">高预测准确性——在实践中非常有效</li><li id="da3e" class="mp mq it js b jt my jx mz kb na kf nb kj nc kn mu mv mw mx bi translated">Kaggle 竞赛中的首选算法</li><li id="891d" class="mp mq it js b jt my jx mz kb na kf nb kj nc kn mu mv mw mx bi translated">很好地捕捉数据集中的非线性关系</li><li id="19cd" class="mp mq it js b jt my jx mz kb na kf nb kj nc kn mu mv mw mx bi translated">当数据集有异常值时非常有用</li><li id="56f6" class="mp mq it js b jt my jx mz kb na kf nb kj nc kn mu mv mw mx bi translated">非常适合在数据集中查找最重要的要素</li><li id="6d0c" class="mp mq it js b jt my jx mz kb na kf nb kj nc kn mu mv mw mx bi translated">分离信号和噪声</li><li id="a09a" class="mp mq it js b jt my jx mz kb na kf nb kj nc kn mu mv mw mx bi translated">不需要功能缩放</li><li id="93f5" class="mp mq it js b jt my jx mz kb na kf nb kj nc kn mu mv mw mx bi translated">在高维数据上表现出色</li></ul><p id="c1bd" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu">劣势</strong></p><ul class=""><li id="5559" class="mp mq it js b jt ju jx jy kb mr kf ms kj mt kn mu mv mw mx bi translated">训练速度较慢</li><li id="7c92" class="mp mq it js b jt my jx mz kb na kf nb kj nc kn mu mv mw mx bi translated">预测速度快</li><li id="497c" class="mp mq it js b jt my jx mz kb na kf nb kj nc kn mu mv mw mx bi translated">不容易解释或者说明</li><li id="0ef8" class="mp mq it js b jt my jx mz kb na kf nb kj nc kn mu mv mw mx bi translated">当新数据进来时，不容易更新模型</li><li id="408d" class="mp mq it js b jt my jx mz kb na kf nb kj nc kn mu mv mw mx bi translated">需要一些参数调整—更难调整</li><li id="f964" class="mp mq it js b jt my jx mz kb na kf nb kj nc kn mu mv mw mx bi translated">在小数据集上表现不佳</li></ul><h2 id="6ef7" class="ly lb it bd lc lz ma dn lg mb mc dp lk kb md me lo kf mf mg ls kj mh mi lw mj bi translated">分类→深度学习</h2><p id="7adf" class="pw-post-body-paragraph jq jr it js b jt mk jv jw jx ml jz ka kb mm kd ke kf mn kh ki kj mo kl km kn im bi translated"><strong class="js iu">优势</strong></p><ul class=""><li id="df7d" class="mp mq it js b jt ju jx jy kb mr kf ms kj mt kn mu mv mw mx bi translated">高预测准确性——在实践中非常有效</li><li id="8b88" class="mp mq it js b jt my jx mz kb na kf nb kj nc kn mu mv mw mx bi translated">捕捉数据中非常复杂的潜在模式</li><li id="4d16" class="mp mq it js b jt my jx mz kb na kf nb kj nc kn mu mv mw mx bi translated">对大数据集和高维数据都很有效</li><li id="ba96" class="mp mq it js b jt my jx mz kb na kf nb kj nc kn mu mv mw mx bi translated">当新数据进来时，容易更新模型</li><li id="9cd1" class="mp mq it js b jt my jx mz kb na kf nb kj nc kn mu mv mw mx bi translated">网络的隐藏层显著降低了对特征工程的需求</li><li id="819c" class="mp mq it js b jt my jx mz kb na kf nb kj nc kn mu mv mw mx bi translated">是计算机视觉、机器翻译、情感分析和语音识别任务的最新技术</li></ul><p id="7a4e" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu">缺点</strong></p><ul class=""><li id="10ab" class="mp mq it js b jt ju jx jy kb mr kf ms kj mt kn mu mv mw mx bi translated">非常长的训练速度</li><li id="1cc1" class="mp mq it js b jt my jx mz kb na kf nb kj nc kn mu mv mw mx bi translated">不容易解释或诠释结果</li><li id="707f" class="mp mq it js b jt my jx mz kb na kf nb kj nc kn mu mv mw mx bi translated">需要巨大的计算能力</li><li id="6f0f" class="mp mq it js b jt my jx mz kb na kf nb kj nc kn mu mv mw mx bi translated">需要功能缩放</li><li id="a924" class="mp mq it js b jt my jx mz kb na kf nb kj nc kn mu mv mw mx bi translated">需要大量的训练数据，因为它学习大量的参数</li><li id="5a3c" class="mp mq it js b jt my jx mz kb na kf nb kj nc kn mu mv mw mx bi translated">在非图像、非文本、非语音任务方面优于 Boosting 算法</li><li id="6509" class="mp mq it js b jt my jx mz kb na kf nb kj nc kn mu mv mw mx bi translated">非常灵活，带有许多不同的架构构建模块，因此需要专业知识来设计架构</li></ul><h1 id="de58" class="la lb it bd lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx bi translated">3.使聚集</h1><h2 id="1fad" class="ly lb it bd lc lz ma dn lg mb mc dp lk kb md me lo kf mf mg ls kj mh mi lw mj bi translated">聚类→ DBSCAN</h2><p id="16f4" class="pw-post-body-paragraph jq jr it js b jt mk jv jw jx ml jz ka kb mm kd ke kf mn kh ki kj mo kl km kn im bi translated"><strong class="js iu">优点</strong></p><ul class=""><li id="bc31" class="mp mq it js b jt ju jx jy kb mr kf ms kj mt kn mu mv mw mx bi translated">可扩展至大型数据集</li><li id="55cb" class="mp mq it js b jt my jx mz kb na kf nb kj nc kn mu mv mw mx bi translated">很好地检测噪声</li><li id="5248" class="mp mq it js b jt my jx mz kb na kf nb kj nc kn mu mv mw mx bi translated">不需要预先知道集群的数量</li><li id="bce7" class="mp mq it js b jt my jx mz kb na kf nb kj nc kn mu mv mw mx bi translated">并没有假设星团的形状是球状的</li></ul><p id="aca0" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu">缺点</strong></p><ul class=""><li id="e179" class="mp mq it js b jt ju jx jy kb mr kf ms kj mt kn mu mv mw mx bi translated">如果您的整个数据集非常密集，则并不总是有效</li><li id="11b7" class="mp mq it js b jt my jx mz kb na kf nb kj nc kn mu mv mw mx bi translated">需要将密度参数ε和 min_samples 调整到正确的值，以获得良好的结果</li></ul><h2 id="ab08" class="ly lb it bd lc lz ma dn lg mb mc dp lk kb md me lo kf mf mg ls kj mh mi lw mj bi translated">聚类→k 均值</h2><p id="8e58" class="pw-post-body-paragraph jq jr it js b jt mk jv jw jx ml jz ka kb mm kd ke kf mn kh ki kj mo kl km kn im bi translated"><strong class="js iu">优点</strong></p><ul class=""><li id="2956" class="mp mq it js b jt ju jx jy kb mr kf ms kj mt kn mu mv mw mx bi translated">非常适合揭示底层数据集的结构</li><li id="917c" class="mp mq it js b jt my jx mz kb na kf nb kj nc kn mu mv mw mx bi translated">简单，易于理解</li><li id="0651" class="mp mq it js b jt my jx mz kb na kf nb kj nc kn mu mv mw mx bi translated">如果您事先知道集群的数量，那么工作会很好</li></ul><p id="ddb6" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu">缺点</strong></p><ul class=""><li id="964c" class="mp mq it js b jt ju jx jy kb mr kf ms kj mt kn mu mv mw mx bi translated">如果你的星团不是球状的，大小也不相似，就不一定管用</li><li id="06e5" class="mp mq it js b jt my jx mz kb na kf nb kj nc kn mu mv mw mx bi translated">需要预先知道集群的数量—需要调整 k 个集群的选择以获得良好的结果</li><li id="7a49" class="mp mq it js b jt my jx mz kb na kf nb kj nc kn mu mv mw mx bi translated">内存密集型</li><li id="d59e" class="mp mq it js b jt my jx mz kb na kf nb kj nc kn mu mv mw mx bi translated">无法扩展到大型数据集</li></ul><h1 id="c6a7" class="la lb it bd lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx bi translated">4.Misc —本帖中未包含的型号</h1><ul class=""><li id="5ed1" class="mp mq it js b jt mk jx ml kb nd kf ne kj nf kn mu mv mw mx bi translated">降维算法</li><li id="8572" class="mp mq it js b jt my jx mz kb na kf nb kj nc kn mu mv mw mx bi translated">聚类算法——高斯混合模型和层次聚类</li><li id="8733" class="mp mq it js b jt my jx mz kb na kf nb kj nc kn mu mv mw mx bi translated">计算机视觉—卷积神经网络、图像分类、对象检测、图像分割</li><li id="f59c" class="mp mq it js b jt my jx mz kb na kf nb kj nc kn mu mv mw mx bi translated">自然语言处理— RNNs (LSTM 或 GRUs)</li><li id="2ab0" class="mp mq it js b jt my jx mz kb na kf nb kj nc kn mu mv mw mx bi translated">强化学习</li></ul><h1 id="9b2c" class="la lb it bd lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx bi translated">组装您的模型</h1><p id="22ec" class="pw-post-body-paragraph jq jr it js b jt mk jv jw jx ml jz ka kb mm kd ke kf mn kh ki kj mo kl km kn im bi translated">集合模型是一种非常强大的技术，通过组合不同模型的输出，有助于减少过度拟合，并做出更稳健的预测。它尤其是赢得卡格尔比赛的必备工具。</p><p id="9476" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">当选择模型进行集成时，我们希望从不同的模型类中选择它们，以确保它们具有不同的优点和缺点，从而在数据集中捕获不同的模式。这种更大的多样性导致了更低的偏差。我们还希望确保它们的性能是可比较的，以确保生成的预测的稳定性。</p><p id="540e" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">我们可以看到，这些模型的混合实际上比任何单一模型单独产生的损失都要低得多。部分原因是，虽然所有这些模型都非常擅长做出预测，但它们正确地做出了不同的预测，通过将它们结合在一起，我们能够将它们所有不同的优势结合到一个超级强大的模型中。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi ng"><img src="../Images/01a4d5339e242a24487ff922f7d5ff84.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*zSJYta4ZmG09xSvQ.png"/></div></div></figure><p id="4125" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">有 4 种类型的组合(包括混合):</p><ul class=""><li id="e721" class="mp mq it js b jt ju jx jy kb mr kf ms kj mt kn mu mv mw mx bi translated"><strong class="js iu">装袋:</strong>用不同的随机选择的数据子集训练许多基础模型，并进行替换。让基础模型对最终预测进行投票。用于 RandomForests。</li><li id="b0de" class="mp mq it js b jt my jx mz kb na kf nb kj nc kn mu mv mw mx bi translated"><strong class="js iu">提升:</strong>迭代训练模型，并在每次迭代后更新获得每个训练样本的重要性。用于 GradientBoosting。</li><li id="2f39" class="mp mq it js b jt my jx mz kb na kf nb kj nc kn mu mv mw mx bi translated"><strong class="js iu">混合:</strong>训练许多不同类型的基础模型，并在维持集上进行预测。根据他们的预测训练一个新模型，在测试集上进行预测。(与维持集堆叠)。</li><li id="14d4" class="mp mq it js b jt my jx mz kb na kf nb kj nc kn mu mv mw mx bi translated"><strong class="js iu">堆叠:</strong>训练许多不同类型的基础模型，并对数据集的 k 倍进行预测。根据他们的预测训练一个新模型，在测试集上进行预测。</li></ul><h1 id="f868" class="la lb it bd lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx bi translated">比较模型</h1><p id="aca7" class="pw-post-body-paragraph jq jr it js b jt mk jv jw jx ml jz ka kb mm kd ke kf mn kh ki kj mo kl km kn im bi translated"><a class="ae nh" href="http://wandb.com" rel="noopener ugc nofollow" target="_blank">权重和偏差</a>让您用一行代码跟踪和比较模型的性能。</p><p id="df6d" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">一旦你选择了你想尝试的模型，训练它们，然后简单地添加<em class="ni">wandb . log({ ' score ':cv _ score })</em>来记录你的模型状态。一旦你完成训练，你可以在一个简单的仪表板上比较你的模型表现！</p><p id="bc89" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">你可以在这里找到有效完成这项工作的代码<a class="ae nh" href="https://www.kaggle.com/lavanyashukla01/picking-the-best-model-a-whirlwind-tour-of-model" rel="noopener ugc nofollow" target="_blank">。我鼓励你分叉</a><a class="ae nh" href="https://www.kaggle.com/lavanyashukla01/picking-the-best-model-a-whirlwind-tour-of-model" rel="noopener ugc nofollow" target="_blank">这个内核</a>并摆弄代码！</p><figure class="kp kq kr ks gt kt"><div class="bz fp l di"><div class="nj nk l"/></div></figure><p id="c7c8" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">就是这样，现在您拥有了为您的问题选择正确模型所需的所有工具！</p><p id="46a4" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">模型选择可能会非常复杂，但我希望这篇指南能给你一些启发，并给你一个挑选模型的好框架。</p><p id="e302" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">如果您有任何问题或反馈，请随时<a class="ae nh" href="https://twitter.com/lavanyaai" rel="noopener ugc nofollow" target="_blank"> <strong class="js iu">发微博给我</strong> </a>！</p></div></div>    
</body>
</html>