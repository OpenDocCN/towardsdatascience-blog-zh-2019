# 诊断神经网络的有用图表

> 原文：<https://towardsdatascience.com/useful-plots-to-diagnose-your-neural-network-521907fa2f45?source=collection_archive---------2----------------------->

训练神经网络不是一项容易的任务，有时会产生比预期好得多的结果，或者表现得差得多，产生的只是噪音。

![](img/776c733e4aa5f07dfd6447fd95408e9a.png)

Photo by [Nina Ž.](https://unsplash.com/@ninaz?utm_source=medium&utm_medium=referral) on [Unsplash](https://unsplash.com?utm_source=medium&utm_medium=referral)

让我们面对它…训练一个神经网络很难，如果你认为它很容易，那么很有可能你还没有完全理解深度学习。典型的深度学习模型由数百万个可学习的参数组成。分析他们中的每一个人在训练中如何变化，以及一个人如何影响其他人，是一项不可能完成的任务。

幸运的是，我们有一定的数量可以观察训练的进展。这些措施让我们得以一窥黑箱，了解它们是如何变化的。

随着每一次网络培训的开始，让我们从数据开始。

## 数据

对于每一个机器学习模型，数据的重要性高于所有其他因素。我不能强调这一点…看看你的数据！！！。数据可能会解释为什么你在训练时会有问题。您的数据可能会让您了解为什么您的模型没有像预期的那样运行。让我解释一下。

在训练分类模型之后，可能存在模型的输出完全或大部分属于一个类别的情况，即模型有偏差的情况。这主要是由于不平衡的数据集。

人们可能面临的另一个问题是没有足够的数据来支持问题陈述。为了说明这一点，我来分享一个经历。几个月前(在我发表这篇文章的时候)，我的一个朋友请我帮个忙。他让我用很少的数据点重新生成一个图形，即训练一个神经网络作为函数逼近器。

光是看原图照片，就知道是指数曲线。但这还不够，因为他需要对情节进行推理。他需要精确的曲线。他设法给了我一些从图表中手动提取的数据点。当我训练网络并预测一个小域的值时，我得到的只是一条略微弯曲的线。我没想到会是这样的曲线。无论我做什么，图表都保持不变。

当我将数据可视化时，我发现数据是不够的。网络仅仅理解它是一条指数曲线是不够的。

这种情况在数据收集期间是一个严重的问题。我们可能认为我们得到了一切，但我们可能只收集了所需数据的一个子集。这可能不足以解决问题。想想吧…

## 损失曲线

调试神经网络最常用的图之一是训练期间的损失曲线。它为我们提供了训练过程和网络学习方向的快照。斯坦福大学的安德烈·卡帕西在这个[链接](http://cs231n.github.io/neural-networks-3/)上给出了一个令人惊叹的解释。这一节深受它的启发。

![](img/eea61a134411bef819607fd4963c01b9.png)

Effect of Learning rate on Loss (Source: [CS231n Convolutional Neural Networks for Visual Recognition](http://cs231n.github.io/assets/nn3/learningrates.jpeg))

这个图像很容易理解。您可以在两个时间段内记录您的损失:

*   在每个时代之后
*   每次迭代后

> 据说绘制跨时期的损失比迭代更理想。

在一个历元期间，跨每个数据项计算损失函数，并且保证在给定的历元给出定量的损失度量。但是跨迭代绘制曲线仅给出整个数据集的子集的损失。

通过绘制验证损失和训练损失图，可以获得更多的信息。

## 精确度曲线

另一个最常用于理解神经网络进展的曲线是精度曲线。对于任何在深度学习方面有一些经验的人来说，使用准确度和损失曲线是显而易见的。

更重要的曲线是同时具有训练和验证准确性的曲线。

![](img/9e8201421fd06137ba66c1ad9f05809d.png)

Accuracy Plot (Source: [CS231n Convolutional Neural Networks for Visual Recognition](http://cs231n.github.io/assets/nn3/accuracies.jpeg))

> 训练和验证准确性之间的差距是过度拟合的明显标志。间隙越大，过度拟合程度越高。

## 不确定

另一个可能被削弱的量是[不确定性](http://mlg.eng.cam.ac.uk/yarin/thesis/thesis.pdf)。不确定性是一个有点高深的话题，但我建议每个人都应该理解这个概念。它更像是一个定量的衡量，而不是一个情节。不确定性有两种类型:

*   随机不确定性/数据不确定性
*   认知不确定性/模型不确定性

在本节中，我们将重点关注模型的不确定性。

模型不确定性是关于模型参数和模型结构的不确定性。两种神经网络架构可以具有不同的不确定性值。因此，我们得到了一个量化的方法来比较这些体系结构，并找到更好的一个。

在我个人看来，完全偏向准确性不是一个好的方法。

在下面的例子中，我绘制了一个建筑的不确定性，这个建筑是在[波士顿房价数据集](https://www.kaggle.com/shanekonaung/boston-housing-price-dataset-with-keras)上训练出来的。模型的不确定性被记录在整个训练时期。

模型的不确定性随着训练而降低……这是有道理的。我已经训练了 250 个时期的模型，只是为了向你们展示不确定性是如何变化的。

## 结论

当一个模型没有给出想要的结果时，试着去理解发生了什么。这些措施可以让我们一窥神经网络的训练。此外，可视化隐藏层输出(尤其是在卷积网络中)在很大程度上有所帮助。

谢谢大家！！😁