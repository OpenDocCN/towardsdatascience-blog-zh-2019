<html>
<head>
<title>How to resume an interrupted training session in fastai</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">如何在 fastai 中恢复中断的训练课程</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/how-to-resume-an-interrupted-training-session-in-fastai-77c4f36cd3a1?source=collection_archive---------13-----------------------#2019-07-26">https://towardsdatascience.com/how-to-resume-an-interrupted-training-session-in-fastai-77c4f36cd3a1?source=collection_archive---------13-----------------------#2019-07-26</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="8f8a" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">如果使用 fit_one_cycle <em class="ki"> </em>的训练中途中断，该怎么办？</h2></div><figure class="kk kl km kn gt ko gh gi paragraph-image"><div role="button" tabindex="0" class="kp kq di kr bf ks"><div class="gh gi kj"><img src="../Images/6fd24192faf6215d88b2c22af6e5c0c2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*EvWy9jX_ka01ns6nkLjQ3Q.jpeg"/></div></div><figcaption class="kv kw gj gh gi kx ky bd b be z dk">Courtesy of Gratisography@Pexels</figcaption></figure><p id="6b16" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">如果您有一个庞大的数据集、一个庞大且训练缓慢的网络，并且您的训练会话在几个小时的训练后被中断，您会怎么做？发生这种情况的原因有很多:</p><ul class=""><li id="7031" class="lv lw it lb b lc ld lf lg li lx lm ly lq lz lu ma mb mc md bi translated">因为你在谷歌 Colab 笔记本上达到了你的连续 12 小时“免费”操作时间；</li><li id="a33d" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated">您暂时失去了与 Colab 或 Kaggle 的联系；</li><li id="ccb3" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated">因为你的电脑因为某种原因停了。我住在巴西，电力短缺是常事…</li></ul><p id="5852" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">fast.ai 采用的<em class="mj"> fit_one_cycle() </em>方法使用变化的、自适应的学习速率和<em class="mj">动量</em>，遵循速率先增加后减少的曲线，而<em class="mj">动量</em>则相反，如下图所示。</p><figure class="kk kl km kn gt ko gh gi paragraph-image"><div class="gh gi mk"><img src="../Images/4fd6a21d3280471da7aa61089ac7fabe.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*38YBWIKFwXN0YlNOVo_LOA.jpeg"/></div><figcaption class="kv kw gj gh gi kx ky bd b be z dk">Cyclical learning rate and momentum variation in <strong class="bd ml">fit1cycle</strong>. Learning rate highlighting by Roger Mao.</figcaption></figure><p id="3637" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">如果您在第 10 个时段(比如说 20 个时段)中中断训练，然后再次开始 9 个时段以上的训练，<strong class="lb iu">您将不会获得与不间断地训练 20 个时段相同的结果，</strong>因为从头开始的新训练，即使您从上一个时段加载权重，也将采用新的学习速率和动量策略，并再次经历该循环。你想要的是从你在循环中被打断的地方开始。</p><figure class="kk kl km kn gt ko gh gi paragraph-image"><div class="gh gi mk"><img src="../Images/17ec417df6d77e8801adc397d2cd08c7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*AzuB9-kayY2Abfp3.png"/></div><figcaption class="kv kw gj gh gi kx ky bd b be z dk">Learning rate and momentum graphs for one <strong class="bd ml"><em class="ki">fit1cycle</em></strong> training policy, divided into three consecutive training sessions. Image by PPW@GitHub</figcaption></figure><h1 id="cfcf" class="mm mn it bd mo mp mq mr ms mt mu mv mw jz mx ka my kc mz kd na kf nb kg nc nd bi translated">什么是 fit1cycle？</h1><p id="d527" class="pw-post-body-paragraph kz la it lb b lc ne ju le lf nf jx lh li ng lk ll lm nh lo lp lq ni ls lt lu im bi translated">Fit1cycle 是 Leslie N. Smith 开发的超收敛策略。它被用作 fast.ai 中的标准培训策略。有关详细信息，请参见下文:</p><ul class=""><li id="70d9" class="lv lw it lb b lc ld lf lg li lx lm ly lq lz lu ma mb mc md bi translated"><a class="ae nj" href="https://docs.fast.ai/callbacks.one_cycle.html?source=post_page---------------------------" rel="noopener ugc nofollow" target="_blank">https://docs.fast.ai/callbacks.one_cycle.html</a></li><li id="5b89" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated">神经网络超参数的训练方法:第 1 部分——学习速率、批量大小、动量和权重衰减—<a class="ae nj" href="https://arxiv.org/abs/1803.09820?source=post_page---------------------------" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/abs/1803.09820</a></li><li id="5954" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated">超级收敛:使用大学习率快速训练残差网络—<a class="ae nj" href="https://arxiv.org/abs/1708.07120?source=post_page---------------------------" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/abs/1708.07120</a></li></ul><p id="54da" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">如果你想看更多的论文，请点击这个链接:<a class="ae nj" href="https://arxiv.org/search/cs?searchtype=author&amp;query=Smith%2C+L+N" rel="noopener ugc nofollow" target="_blank">莱斯利·n·史密斯论文。</a>我们不会在这个帖子中进入细节。媒体上有几篇帖子以简单易懂的方式介绍和讨论了<em class="mj">第一轮</em>训练政策:</p><ul class=""><li id="4d8b" class="lv lw it lb b lc ld lf lg li lx lm ly lq lz lu ma mb mc md bi translated"><a class="ae nj" href="https://link.medium.com/k7eBAlLwDY" rel="noopener">karan Bir Chahal 将训练神经网络的速度提高了 10 倍；</a></li><li id="b580" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated"><a class="ae nj" href="https://link.medium.com/D8uQlAFwDY" rel="noopener">Yogesh gur jar 内置正则化的超收敛；</a></li><li id="b014" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated">超收敛:Aditya Gupta 使用大学习率非常快速地训练神经网络；</li><li id="76a5" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated"><a class="ae nj" href="https://link.medium.com/tpmouPzwDY" rel="noopener"> Fast.ai Part1 v2/v3 笔记—学习率—从 SGDR 到 1cycle 和超收敛(Roger Mao)；</a></li><li id="fdec" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated"><a class="ae nj" href="http://Reproducing Leslie N. Smith’s papers using fastai” by Kushajveer Singh" rel="noopener ugc nofollow" target="_blank">用 fastai 复制 Leslie N. Smith 的论文。</a></li></ul><p id="bfac" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">Kushajveer Singh 的最后一个帖子是一个非常有说明性的 Jupyter 笔记本，值得一看。还有一篇来自<a class="ae nj" href="https://towardsdatascience.com/@nachiket.tanksale" rel="noopener" target="_blank"> Nachiket Tanksale </a>的非常有趣的文章，名为<a class="ae nj" rel="noopener" target="_blank" href="/finding-good-learning-rate-and-the-one-cycle-policy-7159fe1db5d6">寻找好的学习率和单周期政策</a>，其中讨论了周期学习率和动量。</p><h1 id="6f6c" class="mm mn it bd mo mp mq mr ms mt mu mv mw jz mx ka my kc mz kd na kf nb kg nc nd bi translated">我如何恢复训练？</h1><p id="25e2" class="pw-post-body-paragraph kz la it lb b lc ne ju le lf nf jx lh li ng lk ll lm nh lo lp lq ni ls lt lu im bi translated">为此，您必须首先能够记录您停止的位置，然后从该点恢复训练周期，并使用该周期部分的正确超参数。你要做的第一件事就是保存你的网络:</p><pre class="kk kl km kn gt nk nl nm nn aw no bi"><span id="92bc" class="np mn it nl b gy nq nr l ns nt"># Do not forget to import the callback function<br/>from fastai.callbacks import SaveModelCallback</span><span id="d82d" class="np mn it nl b gy nu nr l ns nt"># Train with the callback function set to save weights every epoch<br/>learn.fit_one_cycle(20, max_lr=slice(1e-5,1e-6), <br/>       callbacks=[SaveModelCallback(learn, every='epoch',  <br/>                  monitor='accuracy', name='saved_net')])</span></pre><p id="284f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这将使您的网络在每个时期都被保存，您提供的名称后跟<em class="mj">_ #时期</em>。所以在时段#3，文件<em class="mj"> saved_net_3.pth </em>将被写入。您可以在完成以下操作后加载此文件:</p><ul class=""><li id="9aeb" class="lv lw it lb b lc ld lf lg li lx lm ly lq lz lu ma mb mc md bi translated">重新创建了<em class="mj">数据束</em>和</li><li id="d1aa" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated">用这个特定的数据集群重新实例化了网络。</li></ul><p id="ebf3" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">重装<em class="mj">后。pth </em>文件，你可以重新开始你的训练，只是你要再次告诉<em class="mj"> fit_one_cycle </em>考虑 20 个历元，而是从历元#4 开始训练。</p><p id="fc32" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">Fast.ai 采用特殊的回调来实现这一点。要了解如何做到这一点的细节，请看这里:</p><ul class=""><li id="229a" class="lv lw it lb b lc ld lf lg li lx lm ly lq lz lu ma mb mc md bi translated"><a class="ae nj" href="https://github.com/PPPW/deep-learning-random-explore/tree/master/divide_1cycle?source=post_page---------------------------" rel="noopener ugc nofollow" target="_blank">把一个长周期的政策分成几个小周期——PPW 的 GitHub</a></li></ul><p id="f1bd" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">怎么编码？</strong></p><p id="2b73" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">fast.ai 中的<em class="mj"> fit_one_cycle </em>方法已经开发出来，允许您告诉它从周期的哪个部分恢复中断的训练。恢复培训的代码如下所示:</p><pre class="kk kl km kn gt nk nl nm nn aw no bi"><span id="e955" class="np mn it nl b gy nq nr l ns nt"># Create a new net if training was interrupted and you had to <br/># restart your Colab session</span><span id="9096" class="np mn it nl b gy nu nr l ns nt">learn = cnn_learner(data, models.&lt;your_model_here&gt;, <br/>                    metrics=[accuracy, error_rate])</span><span id="42cb" class="np mn it nl b gy nu nr l ns nt"># If you're resuming, only indicating the epoch from which to <br/># resume, indicated by <strong class="nl iu"><em class="mj">start_epoch=&lt;epoch#&gt;</em></strong> will load the last <br/># saved .pth, it is not necessary to explicitly reload the last <br/># epoch, you only should <strong class="nl iu">NOT</strong> change the name given in <br/># name=&lt;callback_save_file&gt;: when resuming fast.ai will try <br/># to reload <strong class="nl iu"><em class="mj">&lt;callback_save_file&gt;_&lt;previous_epoch&gt;.pth</em></strong></span><span id="6edd" class="np mn it nl b gy nu nr l ns nt"># Unfreeze the network<br/>learn.unfreeze()</span><span id="b900" class="np mn it nl b gy nu nr l ns nt"># Use start_epoch=&lt;some_epoch&gt; to resume training...<br/>learn.fit_one_cycle(20, max_lr=slice(1e-5,1e-6), <br/>                    <strong class="nl iu"><em class="mj">start_epoch=&lt;next_epoch#&gt;</em></strong>,<br/>                    callbacks=[SaveModelCallback(learn, <br/>                    every='epoch', monitor='accuracy', <br/>                    <strong class="nl iu"><em class="mj">name=&lt;callback_save_file&gt;</em></strong>)])</span></pre><p id="9c43" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">…fast.ai 会告诉你“<em class="mj">已加载&lt;回调 _ 保存 _ 文件&gt; _ &lt;上一个 _ 纪元# &gt; </em>”，恢复训练。</p><p id="7de1" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">您可以在此查看<em class="mj"> fit_one_cycle </em>方法支持的所有参数:</p><ul class=""><li id="35ef" class="lv lw it lb b lc ld lf lg li lx lm ly lq lz lu ma mb mc md bi translated"><a class="ae nj" href="https://docs.fast.ai/train.html?source=post_page---------------------------#fit_one_cycle" rel="noopener ugc nofollow" target="_blank">https://docs.fast.ai/train.html#fit_one_cycle</a></li></ul><h1 id="9868" class="mm mn it bd mo mp mq mr ms mt mu mv mw jz mx ka my kc mz kd na kf nb kg nc nd bi translated">如何将这种恢复策略嵌入到我的网络中？</h1><p id="820a" class="pw-post-body-paragraph kz la it lb b lc ne ju le lf nf jx lh li ng lk ll lm nh lo lp lq ni ls lt lu im bi translated">这篇文章的重点是告诉你如何在 fast.ai 中轻松恢复训练，如果被中断的话。如果你是 fast.ai 的新手，为了找到一些背景并学习如何将上面的代码集成到训练网络的整个过程中，请查看我们在下面的 TowardsDataScience 中的帖子:</p><p id="f1e3" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">图像分类:</p><ul class=""><li id="0cc2" class="lv lw it lb b lc ld lf lg li lx lm ly lq lz lu ma mb mc md bi translated"><a class="ae nj" rel="noopener" target="_blank" href="/deep-learning-for-diagnosis-of-skin-images-with-fastai-792160ab5495?source=post_page---------------------------"> <em class="mj">深度学习用 fastai 诊断皮肤图像</em>——<em class="mj">学习从皮肤镜图像中识别皮肤癌和其他病症</em></a>Aldo von Wangenheim；</li><li id="eb68" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated"><a class="ae nj" rel="noopener" target="_blank" href="/deep-learning-and-medical-image-analysis-for-malaria-detection-with-fastai-c8f08560262f?source=post_page---------------------------">Aldo von Wangenheim 利用 fastai 进行疟疾检测的深度学习和医学图像分析</a>；</li></ul><p id="8ede" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">语义分割:</p><ul class=""><li id="4cdf" class="lv lw it lb b lc ld lf lg li lx lm ly lq lz lu ma mb mc md bi translated"><a class="ae nj" rel="noopener" target="_blank" href="/artificial-intelligence-paleontology-use-deep-learning-to-search-for-microfossils-18760bb30880">人工智能&amp;古生物学:利用深度学习搜索微化石</a>奥尔多·冯·万根海姆；</li></ul><h1 id="a72c" class="mm mn it bd mo mp mq mr ms mt mu mv mw jz mx ka my kc mz kd na kf nb kg nc nd bi translated">我们学到了什么？</h1><p id="0013" class="pw-post-body-paragraph kz la it lb b lc ne ju le lf nf jx lh li ng lk ll lm nh lo lp lq ni ls lt lu im bi translated">在这篇文章中，我们简要介绍了 fast.ai 采用的超级收敛<em class="mj"> fit1cycle </em>训练策略，并展示了一些易于阅读的发布材料，如果你想深入研究，可以使用这些材料，而不必阅读 Leslie N. Smith 的科学论文。</p><p id="13b0" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们还向您展示了如何以一种非常简单实用的方式，使用 fast.ai 的<em class="mj"> fit_one_cycle() </em>方法的一些附加参数来执行完全可中断和可恢复的训练周期。</p></div></div>    
</body>
</html>