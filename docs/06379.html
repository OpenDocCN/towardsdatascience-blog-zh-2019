<html>
<head>
<title>Estimating Uncertainty in Machine Learning Models — Part 1</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">估计机器学习模型中的不确定性—第 1 部分</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/estimating-uncertainty-in-machine-learning-models-part-1-99fde3b0cbc1?source=collection_archive---------6-----------------------#2019-09-13">https://towardsdatascience.com/estimating-uncertainty-in-machine-learning-models-part-1-99fde3b0cbc1?source=collection_archive---------6-----------------------#2019-09-13</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><p id="a4ed" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu">作者:Dhruv Nair，数据科学家，Comet.ml </strong></p><p id="a239" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">"我们要求严格界定怀疑和不确定的领域！"</p><p id="761d" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">——道格拉斯·亚当斯，《银河系漫游指南》</p><h1 id="730d" class="ko kp it bd kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll bi translated">为什么不确定性很重要？</h1><p id="1a62" class="pw-post-body-paragraph jq jr it js b jt lm jv jw jx ln jz ka kb lo kd ke kf lp kh ki kj lq kl km kn im bi translated">让我们想象一下，我们正在为建筑公司 ABC 建筑公司建造一个计算机视觉模型。该公司对其空中现场监控流程的自动化感兴趣，并希望我们的算法能在他们的无人机上运行。</p><p id="50e5" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">我们愉快地开始工作，将我们的算法部署到他们的无人机舰队上，回家后认为这个项目取得了巨大的成功。一周后，我们接到 ABC 建筑公司的电话，说无人机不断撞上他们停在所有工地上的白色卡车。你冲到其中一个站点检查视觉模型，并意识到它错误地预测白色卡车的一侧只是明亮的天空。鉴于这一预测，无人机会径直飞向卡车，以为那里什么也没有。</p><p id="4394" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">对现实世界中的数据进行预测时，最好对模型的预测可信度进行评估。如果需要模型来做出对人们生活有实际影响的决策，这一点尤其正确。在自动驾驶汽车、医疗保健、保险等应用中，不确定性测量有助于防止严重事故的发生。</p><h1 id="8c37" class="ko kp it bd kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll bi translated">不确定性的来源</h1><p id="b229" class="pw-post-body-paragraph jq jr it js b jt lm jv jw jx ln jz ka kb lo kd ke kf lp kh ki kj lq kl km kn im bi translated">当对任何过程建模时，我们主要关心两种类型的不确定性。</p><p id="cffc" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu">随机不确定性</strong>:这是我们试图解释的过程中固有的不确定性。例如，由于与周围空气的复杂相互作用，从桌子上方的相同位置落下的乒乓球每次都会落在稍微不同的点上。这一类的不确定性在实践中往往是不可减少的。</p><p id="9499" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu">认知不确定性</strong>:这种不确定性归因于对最适合解释数据的模型的知识不足。这种不确定性是可以减少的，因为对手头的问题有了更多的了解。例如，通过向模型添加更多参数、收集更多数据等来减少这种不确定性。</p><h1 id="51ee" class="ko kp it bd kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll bi translated">那么我们如何估计不确定性呢？</h1><p id="8aba" class="pw-post-body-paragraph jq jr it js b jt lm jv jw jx ln jz ka kb lo kd ke kf lp kh ki kj lq kl km kn im bi translated">让我们考虑这样一个例子，一家面包店试图根据进入面包店的顾客数量来估计它在一个给定的月内将出售的蛋糕数量。我们将尝试使用一个简单的<a class="ae lr" href="https://en.wikipedia.org/wiki/Linear_regression" rel="noopener ugc nofollow" target="_blank">线性回归</a>模型来模拟这个问题。然后，我们将尝试从我们现有的可用数据中估计该模型中不同类型的认知不确定性。</p><figure class="lt lu lv lw gt lx gh gi paragraph-image"><div class="gh gi ls"><img src="../Images/c94a07a5ab7180dbdf24fc853cc680aa.png" data-original-src="https://miro.medium.com/v2/resize:fit:784/format:webp/0*eDNw9_QYh1i11tSK.png"/></div><figcaption class="ma mb gj gh gi mc md bd b be z dk">Equation for Linear Regression</figcaption></figure><p id="241a" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">这个模型的系数受制于<a class="ae lr" href="https://atmos.washington.edu/~breth/classes/AM582/lect/lect3-notes.pdf" rel="noopener ugc nofollow" target="_blank">采样不确定性</a>，我们不太可能从样本数据中确定模型的真实参数。因此，提供这些系数的一组可能值的估计将告知我们当前模型能够如何恰当地解释这些数据。</p><p id="0d5e" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">首先，让我们生成一些数据。我们将从经过缩放和移位的单位正态分布中对我们的<strong class="js iu"> <em class="me"> x </em> </strong>值进行采样。我们的<strong class="js iu"> <em class="me"> y </em> </strong>值只是这些<strong class="js iu"> <em class="me"> x </em> </strong>值的扰动。</p><pre class="lt lu lv lw gt mf mg mh mi aw mj bi"><span id="55da" class="mk kp it mg b gy ml mm l mn mo">import numpy as np</span><span id="9d29" class="mk kp it mg b gy mp mm l mn mo">from numpy.random import randn, randint<br/>from numpy.random import seed</span><span id="b57d" class="mk kp it mg b gy mp mm l mn mo"># random number seed<br/>seed(1)</span><span id="997e" class="mk kp it mg b gy mp mm l mn mo"># Number of samples<br/>size = 100</span><span id="63dd" class="mk kp it mg b gy mp mm l mn mo">x = 20 * (2.5 + randn(size)) <br/>y = x + (10 * randn(size) + 50)</span></pre><p id="31b2" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">我们得到的数据最终看起来像这样</p><figure class="lt lu lv lw gt lx gh gi paragraph-image"><div role="button" tabindex="0" class="mr ms di mt bf mu"><div class="gh gi mq"><img src="../Images/1b71e020af3455153755882ec123bf5b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*9I2wcSOmuNjJzv3B.png"/></div></div><figcaption class="ma mb gj gh gi mc md bd b be z dk">Distribution of Sample Data</figcaption></figure><p id="951c" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">我们将从使用 bootstrap 抽样估计模型参数的不确定性开始。Bootstrap 采样是一种通过采样替换原始数据集来构建新数据集的技术。它生成我们数据集的变体，并能给我们一些直观的参数范围来描述数据。</p><p id="2984" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">在下面的代码中，我们运行 1000 次 bootstrap 采样迭代，将线性回归模型拟合到每个样本数据集，并记录系数，以及每次迭代时模型的截距。</p><pre class="lt lu lv lw gt mf mg mh mi aw mj bi"><span id="5f5b" class="mk kp it mg b gy ml mm l mn mo">from sklearn.utils import resample</span><span id="d6ac" class="mk kp it mg b gy mp mm l mn mo">coefficients = []<br/>intercepts = []</span><span id="5959" class="mk kp it mg b gy mp mm l mn mo">for _ in range(1000):<br/>    idx = randint(0, size, size)<br/>    x_train = x[idx]<br/>    y_train = y[idx]<br/>    <br/>    model = LinearRegression().fit(x_train, y_train)<br/>    <br/>    coefficients.append(model.coef_.item())<br/>    intercepts.append(model.intercept_)</span></pre><p id="6909" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">最后，我们从记录的系数中提取 97.5，2.5 个百分点。这给了我们系数和截距的 95%置信区间。使用百分位数来确定区间还有一个额外的优点，就是不需要对系数的抽样分布进行假设。</p><pre class="lt lu lv lw gt mf mg mh mi aw mj bi"><span id="dbb6" class="mk kp it mg b gy ml mm l mn mo">upper_coefficient = np.percentile(coefficients, 97.5)<br/>upper_intercept = np.percentile(intercepts, 97.5)</span><span id="741b" class="mk kp it mg b gy mp mm l mn mo">lower_coefficient = np.percentile(coefficients, 2.5)<br/>lower_intercept = np.percentile(intercepts, 2.5)</span></pre><figure class="lt lu lv lw gt lx gh gi paragraph-image"><div role="button" tabindex="0" class="mr ms di mt bf mu"><div class="gh gi mv"><img src="../Images/aa634bd98baa2cdb76735d09ab4c9cf6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*-LBfMpkrMuxnfm0w.png"/></div></div></figure><figure class="lt lu lv lw gt lx gh gi paragraph-image"><div role="button" tabindex="0" class="mr ms di mt bf mu"><div class="gh gi mw"><img src="../Images/785049d480af52ac3f01b206c0c629a0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*JlJwaqhsQq-hLDbA.png"/></div></div></figure><p id="f5c8" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">我们现在可以使用这些系数来绘制能够描述数据的曲线族的 95%置信区间。</p><figure class="lt lu lv lw gt lx gh gi paragraph-image"><div role="button" tabindex="0" class="mr ms di mt bf mu"><div class="gh gi mx"><img src="../Images/d4f004ec1da5a045625dc53b72231c34.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*_ByJ_MOuSd9pJ1RQ.png"/></div></div><figcaption class="ma mb gj gh gi mc md bd b be z dk">Confidence Interval for Model Parameters</figcaption></figure><p id="5565" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">现在让我们估计模型预测的不确定性。我们的线性回归模型预测蛋糕的平均销售数量，假设有<strong class="js iu"> <em class="me"> x </em> </strong>名顾客来到商店。我们预计不同的<strong class="js iu"> <em class="me"> x </em> </strong>值会在<strong class="js iu"><em class="me"/></strong>y 中产生不同的均值响应，我们将假设对于一个固定的<strong class="js iu"> <em class="me"> x </em> </strong>，响应<strong class="js iu"> <em class="me"> y </em> </strong>是正态分布的。</p><figure class="lt lu lv lw gt lx gh gi paragraph-image"><div role="button" tabindex="0" class="mr ms di mt bf mu"><div class="gh gi my"><img src="../Images/0739654206f85a48d6d8183da2f39596.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*gOGBM_skPy2zPe8r.png"/></div></div><figcaption class="ma mb gj gh gi mc md bd b be z dk"><a class="ae lr" href="http://www.stat.uchicago.edu/~eichler/stat22000/Handouts/l23.pdf" rel="noopener ugc nofollow" target="_blank">Visualizing the conditional mean</a></figcaption></figure><p id="7de0" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">基于这一假设，我们可以使用来自我们预测的残差来近似以<strong class="js iu"><em class="me"/></strong>为条件的<strong class="js iu"> <em class="me"> y </em> </strong>中的方差。有了这个方差，我们就可以计算平均响应的<a class="ae lr" href="https://en.wikipedia.org/wiki/Standard_error" rel="noopener ugc nofollow" target="_blank">标准误差</a>，并使用它来建立平均响应的置信区间。这是我们对<strong class="js iu"> <em class="me"> y </em> </strong>的真实平均响应的近似程度的度量。这个值越小越好。</p><figure class="lt lu lv lw gt lx gh gi paragraph-image"><div class="gh gi mz"><img src="../Images/ff14c381a878616baf15b36d676e01ca.png" data-original-src="https://miro.medium.com/v2/resize:fit:1060/format:webp/0*lqS1atokaixBCGVK.png"/></div></figure><figure class="lt lu lv lw gt lx gh gi paragraph-image"><div role="button" tabindex="0" class="mr ms di mt bf mu"><div class="gh gi na"><img src="../Images/d138f24dac4594d5ac5d05dac6cd52ba.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*SCfYcwGRNVgcYpCL.png"/></div></div></figure><figure class="lt lu lv lw gt lx gh gi paragraph-image"><div class="gh gi nb"><img src="../Images/6aab3a1e5fcf8383b2d926ecc97e8d52.png" data-original-src="https://miro.medium.com/v2/resize:fit:1248/format:webp/0*eT3-FQmnjuJt46CU.png"/></div></figure><figure class="lt lu lv lw gt lx gh gi paragraph-image"><div class="gh gi mz"><img src="../Images/a2b4acf047e571884bee8b80f837517b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1060/format:webp/0*B7WORcJNuoPtfAq9.png"/></div></figure><figure class="lt lu lv lw gt lx gh gi paragraph-image"><div class="gh gi nc"><img src="../Images/4fa93d6ba73595e4cee471673dff8657.png" data-original-src="https://miro.medium.com/v2/resize:fit:1044/format:webp/0*uPZSC8_k0gfTN3NL.png"/></div></figure><figure class="lt lu lv lw gt lx gh gi paragraph-image"><div role="button" tabindex="0" class="mr ms di mt bf mu"><div class="gh gi nd"><img src="../Images/964435d667990d53f2cb53554cbd1892.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*A9FIwwAQsuHyuRuh.png"/></div></div><figcaption class="ma mb gj gh gi mc md bd b be z dk">Confidence Intervals of the Mean from the Standard Error of the Model</figcaption></figure><p id="b9c8" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">条件均值的方差取决于系数和截距的方差。标准误差就是这个方差的平方根。由于条件均值的标准误差与<strong class="js iu"> <em class="me"> x </em> </strong>的值与<strong class="js iu"> <em class="me"> </em> </strong>均值的偏差成正比，所以我们可以看到，随着它越来越接近<strong class="js iu"> <em class="me"> x </em> </strong>的均值，它会变得越来越窄。</p><p id="c581" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">有了置信区间，面包店就能够确定给定数量的顾客将出售的蛋糕的平均数量的区间，然而，他们仍然不知道给定数量的顾客他们可能出售的蛋糕的可能数量的区间。</p><p id="46ec" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">置信区间仅说明<strong class="js iu"> <em class="me"> y </em> </strong>的平均响应的漂移。对于给定的<strong class="js iu"> <em class="me"> x </em> </strong>值，不提供<strong class="js iu"> <em class="me"> y </em> </strong>所有可能值的区间。为了做到这一点，我们需要使用一个预测区间。</p><figure class="lt lu lv lw gt lx gh gi paragraph-image"><div role="button" tabindex="0" class="mr ms di mt bf mu"><div class="gh gi ne"><img src="../Images/286a4d8c40bbcb8b9a75b48b4e5db74e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*NqwtzHcxFwHB3tz1.png"/></div></div></figure><figure class="lt lu lv lw gt lx gh gi paragraph-image"><div role="button" tabindex="0" class="mr ms di mt bf mu"><div class="gh gi nf"><img src="../Images/7a51fdd1db6334f931c63330a7b0c971.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*0NY5cS5AXkrbMmuq.png"/></div></div></figure><figure class="lt lu lv lw gt lx gh gi paragraph-image"><div role="button" tabindex="0" class="mr ms di mt bf mu"><div class="gh gi ng"><img src="../Images/e71718dd862338f16b2f61775b46c829.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*Ezg-wbf4x4aB-kSg.png"/></div></div></figure><p id="06ca" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">预测区间以与置信区间相似的方式导出。唯一不同的是，我们在计算标准误时，包含了我们因变量<strong class="js iu"> <em class="me"> y </em> </strong>的方差，导致区间更宽。</p><figure class="lt lu lv lw gt lx gh gi paragraph-image"><div role="button" tabindex="0" class="mr ms di mt bf mu"><div class="gh gi nh"><img src="../Images/2596f1d21cbf53b2bd64d84100da3fc1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*QFXjrjtBN6Jm_c7v.png"/></div></div><figcaption class="ma mb gj gh gi mc md bd b be z dk">Prediction Interval for the Model Predictions</figcaption></figure><h1 id="b3f0" class="ko kp it bd kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll bi translated">结论</h1><p id="f9a2" class="pw-post-body-paragraph jq jr it js b jt lm jv jw jx ln jz ka kb lo kd ke kf lp kh ki kj lq kl km kn im bi translated">在评估不确定性系列的第一部分中，我们研究了在一个简单的回归模型中评估认知不确定性来源的方法。当然，当数据和模型的规模和复杂性增加时，这些评估会变得更加困难。</p><p id="216c" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">当我们处理大型神经网络时，自举技术不起作用，并且通过标准误差估计置信区间和预测区间仅在对模型残差和参数的采样分布进行正态假设时才起作用。当这些假设被违反时，我们如何衡量不确定性？</p><p id="1a49" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">在本系列的下一部分，我们将着眼于在更复杂的模型中量化不确定性的方法。</p><p id="f34e" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu">作者:Dhruv Nair，数据科学家，Comet.ml </strong></p></div></div>    
</body>
</html>