# è„¸ä¹¦å¦‚ä½•é’ˆå¯¹å¤§è§„æ¨¡å·¥ä½œè´Ÿè½½è°ƒæ•´ Apache Sparkï¼Ÿ

> åŸæ–‡ï¼š<https://towardsdatascience.com/how-does-facebook-tune-apache-spark-for-large-scale-workloads-3238ddda0830?source=collection_archive---------6----------------------->

æˆ‘æƒ³å¼€å§‹ç¥ä½ æœ‰ä¸€ä¸ªç¾å¥½çš„ 2019 å¹´ï¼Œåœ¨æˆ‘ä»Šå¹´çš„ç¬¬ä¸€ç¯‡æ–‡ç« ä¸­ï¼Œæˆ‘å°†åˆ†äº«ç”±åˆ˜å’Œæ¥è‡ªçš„ Sital Kedia åœ¨ Spark å³°ä¼šä¼šè®®ä¸Šä»‹ç»çš„é’ˆå¯¹å¤§è§„æ¨¡å·¥ä½œè´Ÿè½½è°ƒæ•´ Apache Spark çš„ä¼šè®®æ‘˜è¦[ä»¥åŠæˆ‘çš„æ—¥å¸¸ç»éªŒã€‚](https://databricks.com/session/tuning-apache-spark-for-large-scale-workloads)

å½“æˆ‘ä»¬è°ˆè®º Spark è°ƒä¼˜æ—¶ï¼Œæˆ‘ä»¬éœ€è¦è®¤è¯†åˆ°æ¯ä¸ªåº”ç”¨å’Œç¯å¢ƒéƒ½æ˜¯ä¸åŒçš„ï¼Œå› æ­¤**æˆ‘ä»¬ä¸èƒ½å‡è®¾è¿™ç§é…ç½®å¯¹æ‰€æœ‰æƒ…å†µéƒ½æ˜¯æœ€å¥½çš„**ã€‚åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œå¤§å¤šæ•°æ¨èçš„å±æ€§éƒ½ä¸å¤§å‹ç®¡é“æˆ–ä»¥æ‰¹å¤„ç†æ¨¡å¼å¤„ç†å¤§å‹æ•°æ®é›†çš„ä½œä¸šç›¸å…³ã€‚

è®©æˆ‘ä»¬å¼€å§‹å®šä¹‰æˆ‘ä»¬å¯ä»¥ä»è„¸ä¹¦æ”¶é›†çš„ä¸»é¢˜

1.  ç¼©æ”¾ç«èŠ±é©±åŠ¨å™¨
2.  ç¼©æ”¾ç«èŠ±æ‰§è¡Œå™¨
3.  æ‰©å±•å¤–éƒ¨æ´—ç‰ŒæœåŠ¡
4.  å·¥å…·

# 1.ç¼©æ”¾ç«èŠ±é©±åŠ¨å™¨

**åŠ¨æ€æ‰§è¡Œäººåˆ†é…**

> æ˜¯ä¸€ä¸ª Spark ç‰¹æ€§ï¼Œå®ƒå…è®¸åŠ¨æ€åœ°æ·»åŠ å’Œåˆ é™¤ Spark æ‰§è¡Œå™¨ï¼Œä»¥åŒ¹é…å·¥ä½œè´Ÿè½½ã€‚[ [æŒæ¡ Apache Spark](https://jaceklaskowski.gitbooks.io/mastering-apache-spark/spark-dynamic-allocation.html) ]

å¦‚æœæ‚¨ä¸å…¶ä»–å›¢é˜Ÿå…±äº«é›†ç¾¤èµ„æºï¼Œé‚£ä¹ˆå®Œå…¨æ¨èå¯ç”¨æ­¤é…ç½®ï¼Œè¿™æ ·æ‚¨çš„ Spark åº”ç”¨ç¨‹åºå°±åªä½¿ç”¨å®ƒæœ€ç»ˆå°†ä½¿ç”¨çš„èµ„æºã€‚å®ƒå¯ä»¥æ ¹æ®å·¥ä½œé‡è°ƒæ•´æ‰§è¡Œè€…çš„æ•°é‡ã€‚

```
spark.dynamicAllocation.enable = true
spark.dynamicAllocation.executorIdleTimeout = 2m
spark.dynamicAllocation.minExecutors = 1
spark.dynamicAllocation.maxExecutors = 2000
```

è¿™å››ä¸ªå‚æ•°æ˜¯è‡ªæˆ‘æè¿°çš„ï¼Œä¹Ÿè®¸ç¬¬äºŒä¸ªéœ€è¦æ›´å¤šçš„ç»†èŠ‚ã€‚executorIDleTimeout ç”¨äºæ­£ç¡®ç§»é™¤æ‰§è¡Œå™¨ã€‚

**æ›´å¥½çš„è·å–å¤±è´¥å¤„ç†**

ä¸­æ­¢é˜¶æ®µä¹‹å‰å…è®¸çš„è¿ç»­é˜¶æ®µå°è¯•æ¬¡æ•°(é»˜è®¤ä¸º 4)ã€‚

```
spark.stage.maxConsecutiveAttempts = 10
```

**è°ƒæ•´ RPC æœåŠ¡å™¨çº¿ç¨‹**

å¢åŠ  RPC æœåŠ¡å™¨çº¿ç¨‹ä»¥ä¿®å¤å†…å­˜ä¸è¶³(å®é™…ä¸Šæˆ‘åœ¨ [spark å®˜æ–¹æ–‡æ¡£](https://people.apache.org/~pwendell/spark-nightly/spark-master-docs/latest/configuration.html#networking)ä¸­æ‰¾ä¸åˆ°æ›´å¤šç»†èŠ‚ï¼Œä¸€ä¸ªå¾ˆå¥½çš„è§£é‡Šæ˜¯[è¿™é‡Œæ˜¯](https://github.com/jaceklaskowski/mastering-apache-spark-book/blob/master/spark-rpc-netty.adoc#settings))

```
spark.rpc.io.serverTreads = 64
```

# 2.ç¼©æ”¾ç«èŠ±æ‰§è¡Œå™¨

é¦–å…ˆå¿…é¡»ç†è§£å¦‚ä½•åŸºäºè‡ª Spark 1.6 [ [Spark å†…å­˜ç®¡ç†](https://0x0fff.com/spark-memory-management/) ]ä»¥æ¥å¼€å‘çš„ç»Ÿä¸€å†…å­˜ç®¡ç†æ¥å®šä¹‰æ‰§è¡Œå™¨å†…å­˜çš„ç»“æ„(å›¾ 1)

![](img/1e042176bbcbdebdacdec0de0c5750c4.png)

Fig. 1 Executor memory layout

**éšæœºå­˜å‚¨å™¨**

ä¸€å°éƒ¨åˆ†(å †ç©ºé—´â€” 300MB)ç”¨äºæ‰§è¡Œå’Œå­˜å‚¨[ã€æ·±å…¥æ¢è®¨:Apache Spark ä¸­çš„å†…å­˜ç®¡ç†ã€‘](http://Deep Dive: Memory Management in Apache Spark)ã€‚è¿™ä¸ªå€¼è¶Šä½ï¼Œæº¢å‡ºå’Œç¼“å­˜æ•°æ®å›æ”¶å°±è¶Šé¢‘ç¹ã€‚æ­¤é…ç½®çš„ç›®çš„æ˜¯ä¸ºå†…éƒ¨å…ƒæ•°æ®ã€ç”¨æˆ·æ•°æ®ç»“æ„å’Œç¨€ç–ã€å¼‚å¸¸å¤§çš„è®°å½•çš„ä¸ç²¾ç¡®å¤§å°ä¼°è®¡ç•™å‡ºå†…å­˜(é»˜è®¤ä¸º 60%)ã€‚

```
spark.memory.fraction * (spark.executor.memory - 300 MB)
```

**ç”¨æˆ·è®°å¿†**

æ˜¯ä¸º Spark ä¸­çš„ç”¨æˆ·æ•°æ®ç»“æ„ã€å†…éƒ¨å…ƒæ•°æ®ä¿ç•™çš„ï¼Œå¹¶ä¸”åœ¨è®°å½•ç¨€ç–å’Œå¼‚å¸¸å¤§çš„æƒ…å†µä¸‹ï¼Œé»˜è®¤æƒ…å†µä¸‹ï¼Œä¿æŠ¤å†…å­˜ä¸è¶³é”™è¯¯çš„å‘ç”Ÿã€‚

```
(1 - spark.memory.fraction) * (spark.executor.memory - 300 MB)
```

**ä¿ç•™è®°å¿†**

è¿™æ˜¯ç³»ç»Ÿä¿ç•™çš„å†…å­˜ã€‚å®ƒçš„å€¼æ˜¯ 300MBï¼Œè¿™æ„å‘³ç€è¿™ 300MB çš„ RAM ä¸å‚ä¸ Spark å†…å­˜åŒºåŸŸå¤§å°çš„è®¡ç®—ã€‚å®ƒä¼šå‚¨å­˜ç«èŠ±å†…éƒ¨ç‰©ä½“ã€‚

**è®°å¿†ç¼“å†²åŒº**

è¦ä¸ºæ¯ä¸ªæ‰§è¡Œå™¨åˆ†é…çš„å †å¤–å†…å­˜é‡(ä»¥å…†å­—èŠ‚ä¸ºå•ä½)ã€‚è¿™æ˜¯ä¸€ä¸ªè€ƒè™‘åˆ°è™šæ‹Ÿæœºå¼€é”€ã€å†…éƒ¨å­—ç¬¦ä¸²ã€å…¶ä»–æœ¬æœºå¼€é”€ç­‰å› ç´ çš„å†…å­˜ã€‚[ã€ç«èŠ±å±æ€§ã€‘](https://spark.apache.org/docs/2.2.0/running-on-yarn.html#spark-properties)

```
spark.yarn.executor.memoryOverhead = 0.1 * (spark.executor.memory)
```

**å¯ç”¨å †å¤–å†…å­˜**

```
#Shuffle Memory spark.memory.offHeap.enable = true
spark.memory.ofHeap.size = 3g#User Memoryspark.executor.memory = 3g#Memory Bufferspark.yarn.executor.memoryOverhead = 0.1 * (spark.executor.memory + spark.memory.offHeap.size)
```

**åƒåœ¾æ”¶é›†è°ƒä¼˜**

> å½“æ‚¨çš„ç¨‹åºå­˜å‚¨çš„ rdd æœ‰å¤§é‡â€œå˜åŠ¨â€æ—¶ï¼ŒJVM åƒåœ¾æ”¶é›†ä¼šæ˜¯ä¸€ä¸ªé—®é¢˜ã€‚(åœ¨åªè¯»å–ä¸€æ¬¡ RDDï¼Œç„¶ååœ¨å…¶ä¸Šè¿è¡Œè®¸å¤šæ“ä½œçš„ç¨‹åºä¸­ï¼Œè¿™é€šå¸¸ä¸æ˜¯é—®é¢˜ã€‚)å½“ Java éœ€è¦é©±é€æ—§å¯¹è±¡ä¸ºæ–°å¯¹è±¡è…¾å‡ºç©ºé—´æ—¶ï¼Œå®ƒå°†éœ€è¦è·Ÿè¸ªæ‰€æœ‰ Java å¯¹è±¡å¹¶æ‰¾åˆ°æœªä½¿ç”¨çš„å¯¹è±¡ã€‚GCT

è¿™é‡Œçš„ä¸€ä¸ªå»ºè®®æ˜¯ä½¿ç”¨ GC è€Œä¸æ˜¯ G1GC

```
spark.executor.extraJavaOptions = -XX:ParallelGCThreads=4 -XX:+UseParallelGC
```

**è°ƒæ··æ–‡ä»¶ç¼“å†²**

ç£ç›˜è®¿é—®æ¯”å†…å­˜è®¿é—®æ…¢ï¼Œå› æ­¤æˆ‘ä»¬å¯ä»¥é€šè¿‡ç¼“å†²è¯»/å†™æ¥åˆ†æ‘Šç£ç›˜ I/O æˆæœ¬ã€‚

```
#Size of the in-memory buffer for each shuffle file output stream. #These buffers reduce the number of disk seeks and system calls made #in creating intermediate shuffle files. [[Shuffle behavior](https://people.apache.org/~pwendell/spark-nightly/spark-master-docs/latest/configuration.html#shuffle-behavior)]
spark.shuffle.file.buffer = 1 MB spark.unsafe.sorter.spill.reader.buffer.size  = 1 MB
```

**ä¼˜åŒ–æº¢å‡ºæ–‡ä»¶åˆå¹¶** [ [Spark-20014](https://issues.apache.org/jira/browse/SPARK-20014)

é€šè¿‡å…³é—­åˆ°çš„ä¼ è¾“å¹¶ä½¿ç”¨ç¼“å†²æ–‡ä»¶è¯»/å†™æ¥æé«˜ io ååé‡ï¼Œä»è€Œä½¿ç”¨ mergeSpillsWithFileStream æ–¹æ³•ã€‚

```
spark.file.transferTo = false
spark.shuffle.file.buffer = 1 MB
spark.shuffle.unsafe.file.ouput.buffer = 5 MB
```

**è°ƒæ•´å‹ç¼©å—å¤§å°**

é»˜è®¤å‹ç¼©å—ä¸º 32 kbï¼Œè¿™å¯¹äºå¤§å‹æ•°æ®é›†æ¥è¯´ä¸æ˜¯æœ€ä½³é€‰æ‹©ã€‚å¦‚æœæ‚¨è½¬åˆ°[å¹»ç¯ç‰‡](https://www.slideshare.net/databricks/tuning-apache-spark-for-largescale-workloads-gaoxiang-liu-and-sital-kedia)ï¼Œæ‚¨ä¼šå‘ç°é€šè¿‡å¢åŠ å—å¤§å°ï¼Œéšæœºæ’­æ”¾/æº¢å‡ºæ–‡ä»¶å¤§å°å‡å°‘äº† 20%ã€‚

```
#Block size used in LZ4 compression, in the case when LZ4 #compression codec is used. Lowering this block size will also lower #shuffle memory usage when LZ4 is used. [[Compression and Serialization](http://Block size used in LZ4 compression, in the case when LZ4 compression codec is used. Lowering this block size will also lower shuffle memory usage when LZ4 is used.)]
spark.io.compression.lz4.blockSize = 512KB#Note that tha default compression code is LZ4 you could change #using
spark.io.compression.codec
```

# 3.æ‰©å±•å¤–éƒ¨æ´—ç‰ŒæœåŠ¡

**åœ¨ Shuffle æœåŠ¡å™¨ä¸Šç¼“å­˜ç´¢å¼•æ–‡ä»¶**

> é—®é¢˜æ˜¯ï¼Œå¯¹äºæ¯æ¬¡ shuffle æå–ï¼Œæˆ‘ä»¬éƒ½è¦é‡æ–°æ‰“å¼€åŒä¸€ä¸ªç´¢å¼•æ–‡ä»¶å¹¶è¯»å–å®ƒã€‚å¦‚æœæˆ‘ä»¬èƒ½å¤Ÿé¿å…å¤šæ¬¡æ‰“å¼€åŒä¸€ä¸ªæ–‡ä»¶å¹¶ç¼“å­˜æ•°æ®ï¼Œæ•ˆç‡ä¼šæ›´é«˜ã€‚æˆ‘ä»¬å¯ä»¥ä½¿ç”¨ LRU ç¼“å­˜æ¥ä¿å­˜ç´¢å¼•æ–‡ä»¶ä¿¡æ¯ã€‚é€šè¿‡è¿™ç§æ–¹å¼ï¼Œæˆ‘ä»¬è¿˜å¯ä»¥é™åˆ¶ç¼“å­˜ä¸­æ¡ç›®çš„æ•°é‡ï¼Œè¿™æ ·æˆ‘ä»¬å°±ä¸ä¼šæ— é™åœ°æµªè´¹å†…å­˜ã€‚[ [Spark-15074](https://issues.apache.org/jira/browse/SPARK-15074)

```
#Cache entries limited to the specified memory footprint.
spark.shuffle.service.index.cache.size = 2048
```

**å¯é…ç½®æ´—ç‰Œæ³¨å†Œè¶…æ—¶å’Œé‡è¯•**

å¯¹äºæ›´æœ‰å¯èƒ½å‘ç”ŸèŠ‚ç‚¹æ•…éšœçš„å¤§å‹é›†ç¾¤(ä¾‹å¦‚ï¼Œè¶…è¿‡ 50 ä¸ªèŠ‚ç‚¹)ï¼Œè¿™æ˜¯ç‰¹åˆ«æ¨èçš„ã€‚

```
spark.shuffle.registration.timeout = 2m
spark.shuffle.registration.maxAttempst = 5
```

# 4.å·¥å…·

**Spark UI æŒ‡æ ‡**

æˆ‘è®¤ä¸ºè¿™å¯èƒ½æ˜¯ä¸‹ä¸€ç¯‡æ–‡ç« çš„ä¸€éƒ¨åˆ†(è¿™æ¬¡æœ‰å®é™…çš„ä¾‹å­ğŸ‘©â€ğŸ’» ğŸ‘¨â€ğŸ’»)å› ä¸ºé‚£é‡Œæœ‰å¾ˆå¤šè°ƒè¯•ã€ä¼˜åŒ–ã€è°ƒä¼˜çš„æœ‰ç”¨ä¿¡æ¯ã€‚

é¦–å…ˆï¼Œä¸ºäº†è¿›è¡Œä¼˜åŒ–ï¼Œæ‚¨å¯ä»¥æ£€æŸ¥éšæœºè¯»å–é˜»å¡æ—¶é—´(ä»»åŠ¡ç­‰å¾…éšæœºæ•°æ®ä»è¿œç¨‹æœºå™¨è¯»å–æ‰€èŠ±è´¹çš„é˜»å¡æ—¶é—´[[å †æ ˆæº¢å‡º](https://stackoverflow.com/questions/37468394/spark-shuffle-read-blocked-time)])

![](img/05fafa1eaefd81364201f38cd9de0a84.png)

Fig 2\. Example of a Spark UI Metric [[Community Hortonworks](https://community.hortonworks.com/questions/67659/what-are-the-important-metrics-to-notice-for-each.html)]

æ„Ÿè°¢é˜…è¯»ï¼ä¸‹ä¸€ç¯‡æ–‡ç« å†è§ã€‚

PS å¦‚æœä½ æœ‰ä»»ä½•é—®é¢˜ï¼Œæˆ–è€…æƒ³è¦æ¾„æ¸…ä¸€äº›äº‹æƒ…ï¼Œä½ å¯ä»¥åœ¨ [Twitter](https://twitter.com/thony_ac77) å’Œ [LinkedIn ä¸Šæ‰¾åˆ°æˆ‘ã€‚](https://www.linkedin.com/in/antoniocachuan/)å¦‚æœä½ æƒ³äº†è§£ Apache Arrow å’Œ Apache Sparkï¼Œæˆ‘æœ‰ä¸€ç¯‡æ–‡ç« [**ç”¨ä¸€äº›ä¾‹å­å¯¹ Apache Arrow å’Œ Apache Spark ä»¥åŠ Pandas**](/a-gentle-introduction-to-apache-arrow-with-apache-spark-and-pandas-bb19ffe0ddae) è¿›è¡Œäº†ç®€å•çš„ä»‹ç»ï¼Œæ­¤å¤–ï¼Œä»Šå¹´å‡ºç‰ˆäº†ä¸€æœ¬æˆ‘è®¤ä¸ºå¾ˆæ£’çš„ä¹¦ [Spark:æƒå¨æŒ‡å—](https://amzn.to/2NQxTmZ)ã€‚