# 应该只有一个！

> 原文：<https://towardsdatascience.com/large-objects-in-python-classes-165a6f98d840?source=collection_archive---------18----------------------->

![](img/fc65540d53341ec651486ba85344391d.png)

Photo by [George Hiles](https://unsplash.com/@hilesy?utm_source=medium&utm_medium=referral) on [Unsplash](https://unsplash.com?utm_source=medium&utm_medium=referral)

## 如何在 Python 类中最有效地加载大型模型(和其他对象)

由于开源的机器学习框架，每个人都可以将强大(和大型)的模型集成到数据管道中。这样做的机会带来了大多数数据科学家没有能力应对的挑战。这篇博客文章解决了其中的一个问题:如何在不使计算系统过载的情况下，以集成最先进模型的方式构建代码？

这里有一个具体的例子。想象一下，你的工作是构建一个处理产品评论的 Python 管道。目标是检测那些试图降低你产品分数的虚假评论。您决定采用多步骤方法来实现这一点:

*   首先，你检查是否有**条新评论**可用。
*   第二，你检查**他们的评级是否低到**足以证明进一步调查的正当性。
*   第三，机器学习流水线通过**计算嵌入并应用分类模型**来检查通过两次检查的文本。

所有产品每天都运行这一流程。这是我们最初版本的`ReviewClassifier`类:

从输出中可以看到，分类器的每个**实例**都重新加载了复杂的模型。我们假设每次加载一个模型大约需要一分钟。如果每天有 100 个产品有可疑评论，那就已经是 100 分钟的加载时间了！这是你的管道需要做的最重要的事情。

为了改进这一点——并节省 99%的加载时间——我们需要将加载从实例转移到**类**级别。这是我们的下一个版本:

这好得多，但我们可以进一步改进。目前，当您导入类时，分类器会立即加载模型:

```
from review_pipeline import ReviewClassifier
# Loaded: A Complicated Model
```

我们不想过早装货。也许我们根本不需要模型。它还会很快搞乱单元测试。

为了改变这一点，当我们计算嵌入时，我们检查模型是否在类级别**上加载，如果没有，就这样做。这是我们的最终版本:**

现在我们已经实现了我们的目标。模型在第一次需要时被加载，因此可供以后使用。

一旦你意识到这个模式，你会发现许多有用的应用。例如，有些情况下，带有后续本地过滤的单个数据库导出比重复的小查询更适合您的基础设施。对于大型预计算来说也是如此。

尽管这是一种巧妙的模式，但有些替代方案更适合某些用例。如果您应用上面的设计，类对象将保留在内存中，这会导致难以检测的问题。在这些情况下，最好创建一个本地副本(一次),并为每个新的类实例从文件系统重新加载对象。

如果这篇文章对你有所帮助，或者你想补充什么，请在评论或 Twitter 上告诉我。我也很乐意在 [LinkedIn](https://www.linkedin.com/in/timo-boehm-datascience/) 上联系。**感谢阅读！**