<html>
<head>
<title>Clustering Evaluation strategies</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">聚类评估策略</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/clustering-evaluation-strategies-98a4006fcfc?source=collection_archive---------1-----------------------#2019-05-22">https://towardsdatascience.com/clustering-evaluation-strategies-98a4006fcfc?source=collection_archive---------1-----------------------#2019-05-22</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><p id="967d" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">聚类是一种无监督的机器学习算法。它有助于将数据点分组。与监督机器学习算法相比，验证聚类算法有点棘手，因为聚类过程不包含基本事实标签。如果想要在存在基础事实标签的情况下进行聚类，可以使用监督机器学习算法的验证方法和度量。这篇博客文章试图解决地面真相标签未知时的评估策略。</p><p id="233e" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu">如何评估聚类？</strong></p><p id="f290" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">评估聚类的三个重要因素是</p><p id="544b" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><em class="ko"> (a)聚类趋势(b)聚类数量，</em> <strong class="js iu"> <em class="ko"> k </em> </strong> <em class="ko"> (c)聚类质量</em></p><h1 id="9631" class="kp kq it bd kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm bi translated"><strong class="ak">聚集趋势</strong></h1><p id="810d" class="pw-post-body-paragraph jq jr it js b jt ln jv jw jx lo jz ka kb lp kd ke kf lq kh ki kj lr kl km kn im bi translated">在评估聚类性能之前，确保我们正在处理的数据集具有聚类趋势并且不包含均匀分布的点是非常重要的。如果数据不包含聚类趋势，那么由任何现有聚类算法识别的聚类可能是不相关的。数据集中点的非均匀分布在聚类中变得很重要。</p><p id="3e6d" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">为了解决这个问题，可以使用 Hopkins 检验(一种对变量空间随机性的统计检验)来衡量均匀数据分布产生的数据点的概率。</p><figure class="lt lu lv lw gt lx gh gi paragraph-image"><div role="button" tabindex="0" class="ly lz di ma bf mb"><div class="gh gi ls"><img src="../Images/e282a133f9b516264c919ff30cc41411.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*N-JifVCYi634KwrjBQpreQ.png"/></div></div><figcaption class="me mf gj gh gi mg mh bd b be z dk">Plot for data from Uniform distribution</figcaption></figure><p id="2856" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu"> <em class="ko">零假设(Ho) : </em> </strong> <em class="ko">数据点由均匀分布产生(暗示没有有意义的聚类)<br/> </em> <strong class="js iu"> <em class="ko">交替假设(Ha): </em> </strong> <em class="ko">数据点由随机数据点产生(有聚类)<br/> </em> <br/>如果 H &gt;为 0.5，可以拒绝零假设，数据很有可能包含聚类。如果 H 更接近 0，则数据集不具有聚类倾向。</p><h1 id="947b" class="kp kq it bd kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm bi translated"><strong class="ak">最佳聚类数，<em class="mi">k</em>T30】</strong></h1><p id="58f5" class="pw-post-body-paragraph jq jr it js b jt ln jv jw jx lo jz ka kb lp kd ke kf lq kh ki kj lr kl km kn im bi translated">像 K-means 这样的一些聚类算法需要聚类的数目<em class="ko"> k </em>作为聚类参数。在分析中，获得最佳的聚类数是非常重要的。如果<em class="ko"> k </em>太高，每个点将大致开始代表一个聚类，如果<em class="ko"> k </em>太低，则数据点被错误地聚类。找到最佳的集群数量可以提高集群的粒度。<br/> <br/>寻找正确的聚类数没有明确的答案，因为它取决于(a)分布形状(b)数据集中的规模(c)用户要求的聚类分辨率。尽管找到聚类数是一个非常主观的问题。有两种主要的方法来寻找最佳的聚类数目:<br/> (1)领域知识<br/> (2)数据驱动方法<br/> <br/> <strong class="js iu">领域知识</strong> —领域知识可能给出一些关于寻找聚类数目的先验知识。例如，在聚类 iris 数据集的情况下，如果我们有物种的先验知识(<em class="ko"> sertosa，virginica，versicolor </em>)，那么 k = 3。领域知识驱动<em class="ko"> k 值</em>给出更多相关见解。<br/> <br/> <strong class="js iu">数据驱动方法</strong> —如果领域知识不可用，数学方法有助于找出正确的聚类数。</p><p id="c35f" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><em class="ko">经验方法:- <br/> </em>寻找聚类数的简单经验方法是 N/2 的平方根，其中 N 是数据点的总数，因此每个聚类包含 2 * N 的平方根<br/> <br/> <em class="ko">肘方法:- <br/> </em>聚类内方差是聚类紧密度的度量。组内方差的值越低，形成的组的紧密度越高。</p><p id="26ed" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">对于使用不同 k 值完成的聚类分析，计算类内方差之和<em class="ko">W</em>。<em class="ko">W</em>是点在分析中聚类程度的累积度量。绘制<em class="ko"> k </em>值及其相应的组内方差之和有助于找到组的数量。</p><figure class="lt lu lv lw gt lx gh gi paragraph-image"><div class="gh gi mj"><img src="../Images/09bec6e885bc26b6385b92d08f805962.png" data-original-src="https://miro.medium.com/v2/resize:fit:1280/format:webp/1*rq7pII1kmkGeH3WSI321tA.png"/></div><figcaption class="me mf gj gh gi mg mh bd b be z dk">Plot of Sum of within cluster distance vs Number of clusters in Elbow method</figcaption></figure><p id="dbd7" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">该图显示最佳聚类数= 4。<br/>最初，误差度量(组内方差)随着组数的增加而减小。在特定点 k=4 之后，误差测量开始变平。对应于特定点 k=4 的聚类数应该被认为是最优的聚类数。<br/> <br/> <em class="ko">统计方法:- </em></p><p id="9a4a" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">间隙统计是一种强有力的统计方法，用来寻找最佳的聚类数，<em class="ko"> k </em>。</p><p id="b4ac" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">与 Elbow 方法类似，计算不同 k 值的组内方差之和。<br/>然后生成来自参考零分布的随机数据点，并计算不同 k 值聚类的组内方差之和。</p><p id="28df" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">更简单地说，将不同 k 值的原始数据集的组内方差之和与相应 k 值的参考数据集(均匀分布的零参考数据集)的组内方差之和进行比较，以找到两者之间的“偏差”或“差距”最高的理想<em class="ko"> k </em>值。由于间隙统计量化了这种偏差，间隙统计越多意味着偏差越大。</p><figure class="lt lu lv lw gt lx gh gi paragraph-image"><div class="gh gi mk"><img src="../Images/c51d968b64fe1a79610c1feaf7855eee.png" data-original-src="https://miro.medium.com/v2/resize:fit:796/format:webp/1*YqxIgHFFac6HXOJ2b4GpdQ.png"/></div><figcaption class="me mf gj gh gi mg mh bd b be z dk">Gap statistic Value-Cluster number (k)</figcaption></figure><p id="7884" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">具有最大间隙统计值的聚类数对应于最优的聚类数。</p><h1 id="f9c1" class="kp kq it bd kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm bi translated">聚类质量</h1><p id="2ceb" class="pw-post-body-paragraph jq jr it js b jt ln jv jw jx lo jz ka kb lp kd ke kf lq kh ki kj lr kl km kn im bi translated">一旦聚类完成，就可以通过许多指标来量化聚类的表现。理想聚类的特征在于最小的类内距离和最大的类间距离。</p><p id="9acc" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">主要有两种类型的度量来评估聚类性能。</p><p id="54b1" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">(i) <em class="ko">需要地面真实标签的外在测量</em>。示例有调整后的 Rand 指数、Fowlkes-Mallows 评分、基于互信息的评分、同质性、完整性和 V-measure。</p><p id="55b1" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">(二)<em class="ko">不需要基础真值标签的内在度量</em>。一些聚类性能度量是剪影系数、Calinski-Harabasz 指数、Davies-Bouldin 指数等。</p><p id="c329" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">Sklearn 文档对这些指标有非常好的详细描述。</p><p id="18c0" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu">有用链接</strong></p><p id="ff22" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><a class="ae ml" href="https://rdrr.io/cran/clustertend/" rel="noopener ugc nofollow" target="_blank">聚类趋势</a> — R 包查找聚类趋势</p><p id="430c" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><a class="ae ml" href="https://www.rdocumentation.org/packages/NbClust/versions/3.0/topics/NbClust" rel="noopener ugc nofollow" target="_blank">nbcluster</a>—R 包查找集群数量</p><p id="71f1" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><a class="ae ml" href="https://scikit-learn.org/stable/modules/clustering.html#clustering-performance-evaluation" rel="noopener ugc nofollow" target="_blank">sk learn</a>—sk learn 中用于集群性能评估的 Python 包</p><p id="7f10" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><a class="ae ml" href="https://pypi.org/project/gap-stat/" rel="noopener ugc nofollow" target="_blank"> gap-stat </a> —用于缺口统计的 Python 包</p><p id="60fa" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">缺口统计笔记本 —解释缺口统计的 Jupyter 笔记本</p></div></div>    
</body>
</html>