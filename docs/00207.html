<html>
<head>
<title>A Comprehensive Guide To Object Detection Using YOLO Framework — Part I</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用 YOLO 框架进行目标检测的综合指南—第一部分</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/object-detection-part1-4dbe5147ad0a?source=collection_archive---------8-----------------------#2019-01-09">https://towardsdatascience.com/object-detection-part1-4dbe5147ad0a?source=collection_archive---------8-----------------------#2019-01-09</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="8598" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">YOLO 背后的理论，网络架构和更多</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi kf"><img src="../Images/b8f590303bf22447af83e011feb22ddb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1120/format:webp/1*98bGotZCI9okJKnuW7lK1g.png"/></div><figcaption class="kn ko gj gh gi kp kq bd b be z dk">Cover Image (Source: Author)</figcaption></figure><h1 id="0e33" class="kr ks iq bd kt ku kv kw kx ky kz la lb jw lc jx ld jz le ka lf kc lg kd lh li bi translated">目录:</h1><ul class=""><li id="7f1f" class="lj lk iq ll b lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma bi translated">介绍</li><li id="fd92" class="lj lk iq ll b lm mb lo mc lq md ls me lu mf lw lx ly lz ma bi translated">为什么是 YOLO？</li><li id="440c" class="lj lk iq ll b lm mb lo mc lq md ls me lu mf lw lx ly lz ma bi translated">它是如何工作的？</li><li id="8ea9" class="lj lk iq ll b lm mb lo mc lq md ls me lu mf lw lx ly lz ma bi translated">并集上的交集</li><li id="f9fd" class="lj lk iq ll b lm mb lo mc lq md ls me lu mf lw lx ly lz ma bi translated">非最大抑制</li><li id="8807" class="lj lk iq ll b lm mb lo mc lq md ls me lu mf lw lx ly lz ma bi translated">网络体系结构</li><li id="3281" class="lj lk iq ll b lm mb lo mc lq md ls me lu mf lw lx ly lz ma bi translated">培养</li><li id="713e" class="lj lk iq ll b lm mb lo mc lq md ls me lu mf lw lx ly lz ma bi translated">YOLO 的局限性</li><li id="298d" class="lj lk iq ll b lm mb lo mc lq md ls me lu mf lw lx ly lz ma bi translated">结论</li></ul><h1 id="cb52" class="kr ks iq bd kt ku kv kw kx ky kz la lb jw lc jx ld jz le ka lf kc lg kd lh li bi translated"><strong class="ak">简介:</strong></h1><p id="8f0c" class="pw-post-body-paragraph mg mh iq ll b lm ln jr mi lo lp ju mj lq mk ml mm ls mn mo mp lu mq mr ms lw ij bi translated">你只看一次(YOLO)是一种新的和更快的对象检测方法。传统系统重新利用分类器来执行检测。基本上，为了检测任何对象，系统采用该对象的分类器，然后对其在图像中不同位置的存在进行分类。其他系统使用区域提议方法在图像中生成潜在的边界框，然后对这些潜在的框运行分类器。这产生了一种稍微有效的方法。分类后，使用后处理来细化边界框，消除重复检测等。由于这些复杂性，系统变得缓慢且难以优化，因为每个组件都必须单独训练。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="mu mv di mw bf mx"><div class="gh gi mt"><img src="../Images/d53e60ad06cc8daf6c9bfc4ab20cc2f6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*2S3euf4QTVkv63wWT845BQ.jpeg"/></div></div><figcaption class="kn ko gj gh gi kp kq bd b be z dk">Object Detection with Confidence Score</figcaption></figure><h1 id="c6f2" class="kr ks iq bd kt ku kv kw kx ky kz la lb jw lc jx ld jz le ka lf kc lg kd lh li bi translated"><strong class="ak">为什么是 YOLO？</strong></h1><p id="6417" class="pw-post-body-paragraph mg mh iq ll b lm ln jr mi lo lp ju mj lq mk ml mm ls mn mo mp lu mq mr ms lw ij bi translated">基本模型可以以每秒 45 帧的速度实时处理图像。作为网络的一个较小版本，快速 YOLO 可以每秒 155 帧的速度处理图像，同时达到其他实时检测器的两倍。它优于其他检测方法，包括 DPM(可变形部分模型)和 R-CNN。</p><h1 id="738a" class="kr ks iq bd kt ku kv kw kx ky kz la lb jw lc jx ld jz le ka lf kc lg kd lh li bi translated"><strong class="ak">它是如何工作的？</strong></h1><p id="e79e" class="pw-post-body-paragraph mg mh iq ll b lm ln jr mi lo lp ju mj lq mk ml mm ls mn mo mp lu mq mr ms lw ij bi translated">YOLO 将物体检测重新定义为一个单一的回归问题，而不是一个分类问题。该系统只需查看图像一次，就能检测出哪些物体存在以及它们的位置，因此得名 YOLO。</p><p id="f501" class="pw-post-body-paragraph mg mh iq ll b lm my jr mi lo mz ju mj lq na ml mm ls nb mo mp lu nc mr ms lw ij bi translated">系统将图像分成一个 S×S 的网格。这些网格单元中的每一个预测 B 边界框和这些框的置信度得分。置信度得分表明模型对盒子包含对象的确信程度，以及它认为盒子预测的准确性。可以使用以下公式计算置信度得分:</p><p id="6718" class="pw-post-body-paragraph mg mh iq ll b lm my jr mi lo mz ju mj lq na ml mm ls nb mo mp lu nc mr ms lw ij bi translated"><em class="nd"> C = Pr(object) * IoU </em></p><p id="aae0" class="pw-post-body-paragraph mg mh iq ll b lm my jr mi lo mz ju mj lq na ml mm ls nb mo mp lu nc mr ms lw ij bi translated">IoU:预测框和实际情况之间的交集。</p><p id="ba79" class="pw-post-body-paragraph mg mh iq ll b lm my jr mi lo mz ju mj lq na ml mm ls nb mo mp lu nc mr ms lw ij bi translated">如果单元格中不存在任何对象，则其置信度得分应该为零。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi ne"><img src="../Images/d7ae687771b0d7862f447a8d389d3af8.png" data-original-src="https://miro.medium.com/v2/resize:fit:708/format:webp/1*hOnSx3wCNuhk_N7Jkd2Vlw.jpeg"/></div><figcaption class="kn ko gj gh gi kp kq bd b be z dk">Bounding Box Predictions (Source: Author)</figcaption></figure><p id="989f" class="pw-post-body-paragraph mg mh iq ll b lm my jr mi lo mz ju mj lq na ml mm ls nb mo mp lu nc mr ms lw ij bi translated">每个边界框由五个预测组成:<strong class="ll ir"> x，y，w，h </strong>和置信度其中，</p><p id="809a" class="pw-post-body-paragraph mg mh iq ll b lm my jr mi lo mz ju mj lq na ml mm ls nb mo mp lu nc mr ms lw ij bi translated"><strong class="ll ir"> (x，y): </strong>代表盒子中心的坐标。这些坐标是相对于网格单元的边界计算的。</p><p id="7622" class="pw-post-body-paragraph mg mh iq ll b lm my jr mi lo mz ju mj lq na ml mm ls nb mo mp lu nc mr ms lw ij bi translated"><strong class="ll ir"> w: </strong>边框的宽度。</p><p id="4f76" class="pw-post-body-paragraph mg mh iq ll b lm my jr mi lo mz ju mj lq na ml mm ls nb mo mp lu nc mr ms lw ij bi translated"><strong class="ll ir"> h: </strong>边框的高度。</p><p id="fd17" class="pw-post-body-paragraph mg mh iq ll b lm my jr mi lo mz ju mj lq na ml mm ls nb mo mp lu nc mr ms lw ij bi translated">每个网格单元还预测 C 个条件类概率<em class="nd"> Pr(Classi|Object) </em>。它只预测每个网格单元的一组类别概率，而不考虑盒子 b 的数量。在测试期间，这些条件类别概率乘以单个盒子置信度预测，该预测给出每个盒子的特定类别置信度得分。这些分数显示了该类别的概率以及该框与对象的匹配程度。</p><p id="6c2b" class="pw-post-body-paragraph mg mh iq ll b lm my jr mi lo mz ju mj lq na ml mm ls nb mo mp lu nc mr ms lw ij bi translated"><em class="nd">Pr(I 类|对象)*Pr(对象)*IoU = Pr(I 类)* IoU。</em></p><p id="bdde" class="pw-post-body-paragraph mg mh iq ll b lm my jr mi lo mz ju mj lq na ml mm ls nb mo mp lu nc mr ms lw ij bi translated">最终的预测被编码为一个 S x S x (B*5 + C)张量。</p><h1 id="7d4f" class="kr ks iq bd kt ku kv kw kx ky kz la lb jw lc jx ld jz le ka lf kc lg kd lh li bi translated"><strong class="ak">交集超过并集(欠条):</strong></h1><p id="7104" class="pw-post-body-paragraph mg mh iq ll b lm ln jr mi lo lp ju mj lq mk ml mm ls mn mo mp lu mq mr ms lw ij bi translated">IoU 用于评估对象检测算法。它是基础真实和预测边界框之间的重叠，即它计算预测框相对于基础真实有多相似。</p><div class="kg kh ki kj gt ab cb"><figure class="nf kk ng nh ni nj nk paragraph-image"><div role="button" tabindex="0" class="mu mv di mw bf mx"><img src="../Images/53cc35ba3a9f7c48bda05233b6dc3cbf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*-utw4apz8fGLHEhHP40TPQ.jpeg"/></div></figure><figure class="nf kk ng nh ni nj nk paragraph-image"><div role="button" tabindex="0" class="mu mv di mw bf mx"><img src="../Images/f7bac0206ea7be2efd929229a973973b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*Reu81oCXYGUKcakvvR-f2g.jpeg"/></div></figure></div><div class="ab cb"><figure class="nf kk ng nh ni nj nk paragraph-image"><div role="button" tabindex="0" class="mu mv di mw bf mx"><img src="../Images/851cd0492536f63e15b1ef6acd431f9f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*fW7v4vEDB_KpglaXDCjkog.jpeg"/></div></figure><figure class="nf kk ng nh ni nj nk paragraph-image"><div role="button" tabindex="0" class="mu mv di mw bf mx"><img src="../Images/803ed9213bc536d8f69cd052bb37c302.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*CGqtaZ4we7tVka8H50Kc0Q.jpeg"/></div><figcaption class="kn ko gj gh gi kp kq bd b be z dk nl di nm nn">Demonstration of IoU (Edited by Author)</figcaption></figure></div><p id="bf22" class="pw-post-body-paragraph mg mh iq ll b lm my jr mi lo mz ju mj lq na ml mm ls nb mo mp lu nc mr ms lw ij bi translated">通常，IoU 的阈值保持在 0.5 以上。尽管许多研究人员采用更严格的阈值，如 0.6 或 0.7。如果边界框的 IoU 小于指定阈值，则不考虑该边界框。</p><h1 id="d7ef" class="kr ks iq bd kt ku kv kw kx ky kz la lb jw lc jx ld jz le ka lf kc lg kd lh li bi translated"><strong class="ak">非最大抑制:</strong></h1><p id="43cc" class="pw-post-body-paragraph mg mh iq ll b lm ln jr mi lo lp ju mj lq mk ml mm ls mn mo mp lu mq mr ms lw ij bi translated">该算法可以找到同一物体的多次检测。非最大值抑制是一种算法仅检测一次对象的技术。考虑一个例子，其中算法检测到同一对象的三个边界框。下图显示了具有相应概率的方框。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="mu mv di mw bf mx"><div class="gh gi no"><img src="../Images/af11361539ae3660b48f1084a8342ef5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*tRhnFJ7_Rw2lH613rLNvNw.jpeg"/></div></div><figcaption class="kn ko gj gh gi kp kq bd b be z dk">Multiple Bounding Boxes Of the Same Object (Edited by Author)</figcaption></figure><p id="9018" class="pw-post-body-paragraph mg mh iq ll b lm my jr mi lo mz ju mj lq na ml mm ls nb mo mp lu nc mr ms lw ij bi translated">盒子的概率分别是 0.7、0.9 和 0.6。为了消除重复，我们首先要选择概率最高的盒子，并将其作为预测输出。然后用预测输出消除任何 IoU &gt; 0.5(或任何阈值)的边界框。结果将是:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="mu mv di mw bf mx"><div class="gh gi no"><img src="../Images/cd7457974c5eebdddc35f3a125010ca6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*mJXACfW3I5vuP8j1PJCeBA.jpeg"/></div></div><figcaption class="kn ko gj gh gi kp kq bd b be z dk">Bounding Box Selected After Non-Max Suppression (Edited by Author)</figcaption></figure><h1 id="4c8c" class="kr ks iq bd kt ku kv kw kx ky kz la lb jw lc jx ld jz le ka lf kc lg kd lh li bi translated"><strong class="ak">网络架构:</strong></h1><p id="4a38" class="pw-post-body-paragraph mg mh iq ll b lm ln jr mi lo lp ju mj lq mk ml mm ls mn mo mp lu mq mr ms lw ij bi translated">基本模型有 24 个卷积层，后面是 2 个全连接层。它使用 1 x 1 缩减层，然后是 3 x 3 卷积层。快速 YOLO 使用的神经网络有 9 个卷积层，这些层中的过滤器较少。完整的网络如图所示。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi np"><img src="../Images/b12f29601dd32fa97e3b64baa6a88870.png" data-original-src="https://miro.medium.com/v2/resize:fit:1306/format:webp/1*LZbsNXikrMoxIA_Eh4OjRA.png"/></div><figcaption class="kn ko gj gh gi kp kq bd b be z dk">Network Architecture (<a class="ae nq" href="https://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/Redmon_You_Only_Look_CVPR_2016_paper.pdf" rel="noopener ugc nofollow" target="_blank">Source</a>)</figcaption></figure><p id="7b20" class="pw-post-body-paragraph mg mh iq ll b lm my jr mi lo mz ju mj lq na ml mm ls nb mo mp lu nc mr ms lw ij bi translated"><strong class="ll ir">注:</strong></p><ul class=""><li id="8fbe" class="lj lk iq ll b lm my lo mz lq nr ls ns lu nt lw lx ly lz ma bi translated">该架构设计用于 Pascal VOC 数据集，其中 S = 7，B = 2，C = 20。这就是为什么最终的特征图是 7×7，并且输出张量的形状也是(7×7×2 * 5+20)的原因。要将此网络用于不同数量的类或不同的格网大小，您可能需要调整图层尺寸。</li><li id="7e31" class="lj lk iq ll b lm mb lo mc lq md ls me lu mf lw lx ly lz ma bi translated">最后一层使用线性激活函数。其余的使用泄漏的 ReLU。</li></ul><h1 id="db2c" class="kr ks iq bd kt ku kv kw kx ky kz la lb jw lc jx ld jz le ka lf kc lg kd lh li bi translated"><strong class="ak">培训:</strong></h1><ul class=""><li id="4bc5" class="lj lk iq ll b lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma bi translated">在 ImageNet 1000 级竞争数据集上预训练前 20 个卷积层，然后是平均池层和全连接层。</li><li id="320b" class="lj lk iq ll b lm mb lo mc lq md ls me lu mf lw lx ly lz ma bi translated">由于检测需要更好的视觉信息，请将输入分辨率从 224 x 224 提高到 448 x 448。</li><li id="1293" class="lj lk iq ll b lm mb lo mc lq md ls me lu mf lw lx ly lz ma bi translated">训练网络 135 个纪元。在整个训练过程中，使用批量 64，动量 0.9，衰减 0.0005。</li><li id="aff9" class="lj lk iq ll b lm mb lo mc lq md ls me lu mf lw lx ly lz ma bi translated">学习率:对于第一个时期，将学习率从 10–3 提高到 10–2，否则模型会由于不稳定的梯度而发散。继续以 10–2 训练 75 个周期，然后 10–3 训练 30 个周期，然后 10–4 训练 30 个周期。</li><li id="8b20" class="lj lk iq ll b lm mb lo mc lq md ls me lu mf lw lx ly lz ma bi translated">为了避免过度拟合，请使用剔除和数据扩充。</li></ul><h1 id="38ea" class="kr ks iq bd kt ku kv kw kx ky kz la lb jw lc jx ld jz le ka lf kc lg kd lh li bi translated"><strong class="ak">YOLO 的局限性:</strong></h1><ul class=""><li id="a4b9" class="lj lk iq ll b lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma bi translated">边界框预测的空间约束，因为每个格网单元只能预测两个框，并且只能有一个类。</li><li id="9840" class="lj lk iq ll b lm mb lo mc lq md ls me lu mf lw lx ly lz ma bi translated">很难检测成群出现的小物体。</li><li id="9c3b" class="lj lk iq ll b lm mb lo mc lq md ls me lu mf lw lx ly lz ma bi translated">当模型学习从数据本身预测边界框时，它很难以新的或不寻常的纵横比来概括对象。</li></ul><h1 id="5ec3" class="kr ks iq bd kt ku kv kw kx ky kz la lb jw lc jx ld jz le ka lf kc lg kd lh li bi translated"><strong class="ak">结论:</strong></h1><p id="b265" class="pw-post-body-paragraph mg mh iq ll b lm ln jr mi lo lp ju mj lq mk ml mm ls mn mo mp lu mq mr ms lw ij bi translated">这是对研究论文的简要解释，以及从各种其他来源获得的细节。我希望我让你更容易理解这个概念。</p><p id="3a8e" class="pw-post-body-paragraph mg mh iq ll b lm my jr mi lo mz ju mj lq na ml mm ls nb mo mp lu nc mr ms lw ij bi translated">虽然如果真的要检查自己的理解，最好的方法还是实现算法。在下一节中，我们将会这样做。许多细节无法通过文本解释，只能在实现时理解。</p><p id="1829" class="pw-post-body-paragraph mg mh iq ll b lm my jr mi lo mz ju mj lq na ml mm ls nb mo mp lu nc mr ms lw ij bi translated">感谢您的阅读。<a class="ae nq" href="https://medium.com/@pratheesh.27998/object-detection-part2-6a265827efe1" rel="noopener">点击这里</a>进入下一部分。</p></div></div>    
</body>
</html>