<html>
<head>
<title>Review: MNC — Multi-task Network Cascade, Winner in 2015 COCO Segmentation (Instance Segmentation)</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">回顾:跨国公司—多任务网络级联，2015 年 COCO 细分赢家(实例细分)</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/review-mnc-multi-task-network-cascade-winner-in-2015-coco-segmentation-instance-segmentation-42a9334e6a34?source=collection_archive---------15-----------------------#2019-01-05">https://towardsdatascience.com/review-mnc-multi-task-network-cascade-winner-in-2015-coco-segmentation-instance-segmentation-42a9334e6a34?source=collection_archive---------15-----------------------#2019-01-05</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="0373" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">三个阶段:区分实例、估计掩码和对对象进行分类。</h2></div><p id="d3d6" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi lb translated"><span class="l lc ld le bm lf lg lh li lj di"> T </span>他的时间，被<strong class="kh ir">微软研究院</strong>命名为<strong class="kh ir"> MNC(多任务网络级联)</strong>的时间，即将被回顾。该模型由三个网络组成，分别为<strong class="kh ir">区分实例</strong>、<strong class="kh ir">估计掩码</strong>、以及<strong class="kh ir">分类对象</strong>。这些网络形成一个<strong class="kh ir">级联</strong>结构，并被设计来共享它们的卷积特征。</p><p id="99ce" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">跨国公司<strong class="kh ir">在 2015 年可可细分挑战</strong>中获得第一名。载于<strong class="kh ir"> 2016 CVPR </strong>号，引用文献<strong class="kh ir"> 300 余篇。(<a class="lk ll ep" href="https://medium.com/u/aff72a0c1243?source=post_page-----42a9334e6a34--------------------------------" rel="noopener" target="_blank">植荷曾</a> @中)</strong></p></div><div class="ab cl lm ln hu lo" role="separator"><span class="lp bw bk lq lr ls"/><span class="lp bw bk lq lr ls"/><span class="lp bw bk lq lr"/></div><div class="ij ik il im in"><h1 id="1f65" class="lt lu iq bd lv lw lx ly lz ma mb mc md jw me jx mf jz mg ka mh kc mi kd mj mk bi translated">保险范围是什么</h1><ol class=""><li id="f282" class="ml mm iq kh b ki mn kl mo ko mp ks mq kw mr la ms mt mu mv bi translated"><strong class="kh ir">多任务网络级联(MNC)架构(3 个阶段)</strong></li><li id="9dfc" class="ml mm iq kh b ki mw kl mx ko my ks mz kw na la ms mt mu mv bi translated"><strong class="kh ir">多级级联(5 级)</strong></li><li id="1768" class="ml mm iq kh b ki mw kl mx ko my ks mz kw na la ms mt mu mv bi translated"><strong class="kh ir">结果</strong></li></ol></div><div class="ab cl lm ln hu lo" role="separator"><span class="lp bw bk lq lr ls"/><span class="lp bw bk lq lr ls"/><span class="lp bw bk lq lr"/></div><div class="ij ik il im in"><h1 id="5cc3" class="lt lu iq bd lv lw lx ly lz ma mb mc md jw me jx mf jz mg ka mh kc mi kd mj mk bi translated"><strong class="ak"> 1。多任务网络级联架构</strong></h1><figure class="nc nd ne nf gt ng gh gi paragraph-image"><div role="button" tabindex="0" class="nh ni di nj bf nk"><div class="gh gi nb"><img src="../Images/b2ec9c9d8a64be66af4a6750fea4e61f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*NBEc_mhh1EJfnSN-0eSzHA.png"/></div></div><figcaption class="nn no gj gh gi np nq bd b be z dk"><strong class="bd nr">Multi-task Network Cascades (MNC) Architecture</strong></figcaption></figure><p id="e8c2" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这里有<strong class="kh ir">三个阶段</strong> : <strong class="kh ir">提出盒级实例</strong>、<strong class="kh ir">回归掩码级实例</strong>、<strong class="kh ir">如上分类每个实例</strong>。</p><p id="00ca" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">进入各阶段前，通过<a class="ae ns" href="https://medium.com/coinmonks/paper-review-of-vggnet-1st-runner-up-of-ilsvlc-2014-image-classification-d02355543a11" rel="noopener"> VGG16 </a>得到卷积特征图。所有阶段都共享这些卷积特征映射。</p><h2 id="85ac" class="nt lu iq bd lv nu nv dn lz nw nx dp md ko ny nz mf ks oa ob mh kw oc od mj oe bi translated">1.1.回归盒级实例</h2><p id="b0bc" class="pw-post-body-paragraph kf kg iq kh b ki mn jr kk kl mo ju kn ko of kq kr ks og ku kv kw oh ky kz la ij bi translated">第一阶段，本阶段网络结构及损耗函数沿用 <a class="ae ns" rel="noopener" target="_blank" href="/review-faster-r-cnn-object-detection-f5685cb30202"> <strong class="kh ir">中的<strong class="kh ir">区域方案网络</strong> </strong></a>卷积运算。</p><p id="518d" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在共享特征的基础上，使用 3×3 卷积层进行降维，随后是<strong class="kh ir">两个同级 1×1 卷积层，用于回归盒子位置和分类对象/非对象。</strong>该损耗函数作为第 1 阶段的<strong class="kh ir">损耗项<em class="oi"> L1 </em> </strong> <em class="oi"> </em>:</p><figure class="nc nd ne nf gt ng gh gi paragraph-image"><div class="gh gi oj"><img src="../Images/79331ca0bd4580fc8fbb2d3f0dc93776.png" data-original-src="https://miro.medium.com/v2/resize:fit:724/format:webp/1*0TQH8cRCLDzJrnN-VPzvZQ.png"/></div></figure><p id="e92f" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">其中<em class="oi"> B </em>为本级网络输出。<em class="oi"> Bi </em>是由<em class="oi"> i </em>索引的盒子。方框<em class="oi"> Bi </em>以(<em class="oi"> xi、</em>T10】伊)为中心，宽度<em class="oi"> wi </em>和高度<em class="oi"> hi </em>，其中<em class="oi"> pi </em>为目标概率。</p><h2 id="ec4e" class="nt lu iq bd lv nu nv dn lz nw nx dp md ko ny nz mf ks oa ob mh kw oc od mj oe bi translated">1.2.回归遮罩层实例</h2><p id="e8b6" class="pw-post-body-paragraph kf kg iq kh b ki mn jr kk kl mo ju kn ko of kq kr ks og ku kv kw oh ky kz la ij bi translated">第二阶段采用共享卷积特征和阶段 1 盒作为输入。它为每个框建议输出像素级分割掩码。在这个阶段，掩码级实例仍然是类不可知的。</p><p id="c7ec" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">给定阶段 1 预测的盒子，在盒子上执行<strong class="kh ir"> 14×14 大小的 ROI 合并</strong>。<strong class="kh ir">两个额外的全连接(fc)层</strong>应用于每个盒子的该特征。<strong class="kh ir">第一个 fc 层(使用 ReLU)将尺寸减少到 256 </strong>，随后是<strong class="kh ir">第二个 fc 层，它回归出一个<em class="oi">m</em>×<em class="oi">m</em>(<em class="oi">m</em>= 28)像素式蒙版</strong>。该掩码对基础真掩码进行<strong class="kh ir">二元逻辑回归，作为阶段 2 的<strong class="kh ir">损失项<em class="oi">L2</em>T37】；</strong></strong></p><figure class="nc nd ne nf gt ng gh gi paragraph-image"><div role="button" tabindex="0" class="nh ni di nj bf nk"><div class="gh gi ok"><img src="../Images/b2e4243c4e5208019e861b7cdc42f9b1.png" data-original-src="https://miro.medium.com/v2/resize:fit:456/format:webp/1*0EDT07tt-XxYdAdDwa5xHQ.png"/></div></div></figure><p id="f6f3" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">其中<em class="oi"> M </em>为本级网络输出。与 DeepMask 相比，MNC 只从几个提出的盒子中回归掩膜，从而降低了计算成本。</p><h2 id="e5a1" class="nt lu iq bd lv nu nv dn lz nw nx dp md ko ny nz mf ks oa ob mh kw oc od mj oe bi translated">1.3.分类实例</h2><p id="9c3c" class="pw-post-body-paragraph kf kg iq kh b ki mn jr kk kl mo ju kn ko of kq kr ks og ku kv kw oh ky kz la ij bi translated">第三阶段采用共享卷积特征、阶段 1 盒子和阶段 2 掩码作为输入。它输出每个实例的类别分数。</p><p id="bce6" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">给定阶段 1 预测的方框，我们还通过 RoI 合并提取特征。然后，该特征图被阶段 2 屏蔽预测“屏蔽”。这导致聚焦于预测遮罩前景的特征。</p><figure class="nc nd ne nf gt ng gh gi paragraph-image"><div class="gh gi ol"><img src="../Images/e4707f40462fe7564c53397d4cc1b455.png" data-original-src="https://miro.medium.com/v2/resize:fit:604/format:webp/1*Ush2ub7QQ_XCSNS39OwjQw.png"/></div></figure><p id="7d24" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">被屏蔽的特征由元素式乘积给出。<strong class="kh ir"> <em class="oi"> FROI </em> </strong>是 ROI 合并后的<strong class="kh ir">特征。<strong class="kh ir"> <em class="oi"> M </em> </strong> <em class="oi"> </em>是从阶段 2 </strong>得到的<strong class="kh ir">掩模预测。</strong></p><ul class=""><li id="8059" class="ml mm iq kh b ki kj kl km ko om ks on kw oo la op mt mu mv bi translated"><strong class="kh ir">在</strong> <strong class="kh ir">被掩蔽的特征<em class="oi"> FMask </em> </strong>上应用两个 4096-d fc 层。这被称为<strong class="kh ir">基于面具的途径</strong>。</li><li id="0b7f" class="ml mm iq kh b ki mw kl mx ko my ks mz kw na la op mt mu mv bi translated">并且<strong class="kh ir"> RoI 汇集特征直接馈入两个 4096-d fc 层</strong>并形成<strong class="kh ir">基于盒的路径</strong>。</li><li id="cfb1" class="ml mm iq kh b ki mw kl mx ko my ks mz kw na la op mt mu mv bi translated">基于遮罩和基于盒子的路径被<strong class="kh ir">连接</strong>。</li><li id="21ec" class="ml mm iq kh b ki mw kl mx ko my ks mz kw na la op mt mu mv bi translated">在拼接的顶部，使用<em class="oi"> N </em> +1 路的<strong class="kh ir"> softmax </strong>分类器来预测<em class="oi"> N </em>个类别加上一个背景类别。盒子级路径可以解决特征大部分被屏蔽级路径屏蔽的情况(例如，在背景上)。<strong class="kh ir">损失条款<em class="oi">L3</em>T9】:</strong></li></ul><figure class="nc nd ne nf gt ng gh gi paragraph-image"><div class="gh gi oq"><img src="../Images/b1ba999b238b046aff2313a02c28143a.png" data-original-src="https://miro.medium.com/v2/resize:fit:588/format:webp/1*nHrrJTqyHob4eomsd6TIog.png"/></div></figure><p id="6978" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">其中<em class="oi"> C </em>是这个阶段的网络输出，它是所有实例的类别预测列表。</p><p id="2138" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">网络的<strong class="kh ir">丢失</strong>变成:</p><figure class="nc nd ne nf gt ng gh gi paragraph-image"><div role="button" tabindex="0" class="nh ni di nj bf nk"><div class="gh gi or"><img src="../Images/ac8980ca991575c2ab83e4b5f4c349bc.png" data-original-src="https://miro.medium.com/v2/resize:fit:754/format:webp/1*ge3Xi81kPXoJApFllekhbw.png"/></div></div></figure></div><div class="ab cl lm ln hu lo" role="separator"><span class="lp bw bk lq lr ls"/><span class="lp bw bk lq lr ls"/><span class="lp bw bk lq lr"/></div><div class="ij ik il im in"><h1 id="46b6" class="lt lu iq bd lv lw lx ly lz ma mb mc md jw me jx mf jz mg ka mh kc mi kd mj mk bi translated"><strong class="ak"> 2。多级级联(5 级)</strong></h1><figure class="nc nd ne nf gt ng gh gi paragraph-image"><div class="gh gi os"><img src="../Images/cd3d13f764e692a2c1d644a0e7fd0cbb.png" data-original-src="https://miro.medium.com/v2/resize:fit:920/format:webp/1*S9bWwx8vUsPTTpEA7BxeWQ.png"/></div><figcaption class="nn no gj gh gi np nq bd b be z dk"><strong class="bd nr">5-stage MNC</strong></figcaption></figure><p id="3134" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">首先，运行整个三阶段网络，并获得第三阶段的回归盒。然后，这些方框被视为新提案。第二阶段和第三阶段是对这些建议的第二次执行。这实际上是 5 阶段推理。</p></div><div class="ab cl lm ln hu lo" role="separator"><span class="lp bw bk lq lr ls"/><span class="lp bw bk lq lr ls"/><span class="lp bw bk lq lr"/></div><div class="ij ik il im in"><h1 id="d061" class="lt lu iq bd lv lw lx ly lz ma mb mc md jw me jx mf jz mg ka mh kc mi kd mj mk bi translated">3.结果</h1><h2 id="6c43" class="nt lu iq bd lv nu nv dn lz nw nx dp md ko ny nz mf ks oa ob mh kw oc od mj oe bi translated">3.1.帕斯卡 VOC 2012</h2><figure class="nc nd ne nf gt ng gh gi paragraph-image"><div role="button" tabindex="0" class="nh ni di nj bf nk"><div class="gh gi ot"><img src="../Images/5b11ccae8d09e9fcefb4946c08689e40.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*qx-VtOH7ZB2hyspyiPg2xw.png"/></div></div><figcaption class="nn no gj gh gi np nq bd b be z dk"><strong class="bd nr">Ablation experiments on PASCAL VOC 2012 validation.</strong></figcaption></figure><ul class=""><li id="6ba6" class="ml mm iq kh b ki kj kl km ko om ks on kw oo la op mt mu mv bi translated">使用<a class="ae ns" href="https://medium.com/coinmonks/paper-review-of-vggnet-1st-runner-up-of-ilsvlc-2014-image-classification-d02355543a11" rel="noopener"> VGG16 </a>提取特征，但<strong class="kh ir">不共享阶段间特征</strong>:60.2%地图。</li><li id="73ec" class="ml mm iq kh b ki mw kl mx ko my ks mz kw na la op mt mu mv bi translated"><strong class="kh ir">分享特色</strong> : 60.5%地图。</li><li id="3721" class="ml mm iq kh b ki mw kl mx ko my ks mz kw na la op mt mu mv bi translated"><strong class="kh ir">3 阶段端到端培训</strong> : 62.6% mAP。</li><li id="c7f5" class="ml mm iq kh b ki mw kl mx ko my ks mz kw na la op mt mu mv bi translated"><strong class="kh ir"> 5 级</strong> : 63.5%地图。</li></ul><figure class="nc nd ne nf gt ng gh gi paragraph-image"><div class="gh gi ou"><img src="../Images/929b0528d793eb6b0b4d9ffd5e9ba780.png" data-original-src="https://miro.medium.com/v2/resize:fit:1052/format:webp/1*wqFOAZA0V6iUYc9yMZctmQ.png"/></div><figcaption class="nn no gj gh gi np nq bd b be z dk"><strong class="bd nr">Comparison on PASCAL VOC 2012 validation for Instance Segmentation.</strong></figcaption></figure><ul class=""><li id="18bf" class="ml mm iq kh b ki kj kl km ko om ks on kw oo la op mt mu mv bi translated">MNC 在 0.5 和 0.7 的不同 IoU 阈值上获得<strong class="kh ir">最高 mAP </strong>。在最先进的方法中,<strong class="kh ir">推理时间也是最短的。</strong></li></ul><figure class="nc nd ne nf gt ng gh gi paragraph-image"><div class="gh gi ov"><img src="../Images/0d790e8b8603c6035fdca64dfade5a1f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1114/format:webp/1*Yd2LEJnhG7c9jCARUfFlmA.png"/></div><figcaption class="nn no gj gh gi np nq bd b be z dk"><strong class="bd nr">Detailed Inference Time Per Image on Nvidia K40 GPU.</strong></figcaption></figure><ul class=""><li id="5072" class="ml mm iq kh b ki kj kl km ko om ks on kw oo la op mt mu mv bi translated">最耗时的部分是<a class="ae ns" href="https://medium.com/coinmonks/paper-review-of-vggnet-1st-runner-up-of-ilsvlc-2014-image-classification-d02355543a11" rel="noopener"> VGG16 </a>特征提取(conv)部分。</li></ul><figure class="nc nd ne nf gt ng gh gi paragraph-image"><div role="button" tabindex="0" class="nh ni di nj bf nk"><div class="gh gi ow"><img src="../Images/ea7eb0fa6f5d37c61c0fe139b4804321.png" data-original-src="https://miro.medium.com/v2/resize:fit:976/format:webp/1*HE2RKlq4K9sVVbtfpvTmlQ.png"/></div></div><figcaption class="nn no gj gh gi np nq bd b be z dk"><strong class="bd nr">Evaluation of (box-level) object detection</strong></figcaption></figure><ul class=""><li id="7a2e" class="ml mm iq kh b ki kj kl km ko om ks on kw oo la op mt mu mv bi translated">由于盒子也可以由 MNC 预测，所以对盒子级别的对象检测进行评估。</li><li id="7f54" class="ml mm iq kh b ki mw kl mx ko my ks mz kw na la op mt mu mv bi translated">MNC 使用 2007 trainval+test 和 2012 trainval 的联合作为训练，获得了 75.9%的最高 mAP，大大优于<a class="ae ns" href="https://medium.com/coinmonks/review-fast-r-cnn-object-detection-a82e172e87ba" rel="noopener">快速 R-CNN </a>和<a class="ae ns" rel="noopener" target="_blank" href="/review-faster-r-cnn-object-detection-f5685cb30202">快速 R-CNN </a>。</li></ul><h2 id="ff5e" class="nt lu iq bd lv nu nv dn lz nw nx dp md ko ny nz mf ks oa ob mh kw oc od mj oe bi translated">3.2.可可女士</h2><figure class="nc nd ne nf gt ng gh gi paragraph-image"><div class="gh gi ox"><img src="../Images/ff19d3ca8fadc0c107ed47b6ee6b1e91.png" data-original-src="https://miro.medium.com/v2/resize:fit:1048/format:webp/1*f3By3tNQNWqIbUuNZnlOQw.png"/></div><figcaption class="nn no gj gh gi np nq bd b be z dk"><strong class="bd nr">Segmentation result (%) on the MS COCO test-dev set.</strong></figcaption></figure><ul class=""><li id="d36b" class="ml mm iq kh b ki kj kl km ko om ks on kw oo la op mt mu mv bi translated">以<a class="ae ns" href="https://medium.com/coinmonks/paper-review-of-vggnet-1st-runner-up-of-ilsvlc-2014-image-classification-d02355543a11" rel="noopener"> VGG16 </a>为骨干进行特征提取，得到了 19.5% mAP @ 0.5 和 39.7% mAP@0.5。</li><li id="461d" class="ml mm iq kh b ki mw kl mx ko my ks mz kw na la op mt mu mv bi translated">使用<a class="ae ns" rel="noopener" target="_blank" href="/review-resnet-winner-of-ilsvrc-2015-image-classification-localization-detection-e39402bfa5d8"> <strong class="kh ir"> ResNet-101 </strong> </a>作为特征提取的骨干，<strong class="kh ir">得到了更高的 mAP</strong>，即 24.6% mAP @ 0.95 和 44.3% mAP@0.5。</li><li id="2dd9" class="ml mm iq kh b ki mw kl mx ko my ks mz kw na la op mt mu mv bi translated">通过<strong class="kh ir">全局上下文建模</strong>、<strong class="kh ir">多尺度测试</strong>、<strong class="kh ir">集合</strong>，最终获得 28.2% mAP@[.5:.95]和 51.5% mAP@0.5 的成绩，<strong class="kh ir">获得 COCO 分割赛道第一名</strong>。</li></ul><h2 id="01ce" class="nt lu iq bd lv nu nv dn lz nw nx dp md ko ny nz mf ks oa ob mh kw oc od mj oe bi translated">3.3.定性结果</h2><figure class="nc nd ne nf gt ng gh gi paragraph-image"><div class="gh gi oy"><img src="../Images/bcd0431ac8dc211af6551c959accb712.png" data-original-src="https://miro.medium.com/v2/resize:fit:1386/format:webp/1*mBaafckhUS_VTIxXy8d-nA.png"/></div><figcaption class="nn no gj gh gi np nq bd b be z dk"><strong class="bd nr">PASCAL VOC 2012 Validation Set</strong></figcaption></figure><figure class="nc nd ne nf gt ng gh gi paragraph-image"><div role="button" tabindex="0" class="nh ni di nj bf nk"><div class="gh gi oz"><img src="../Images/72ce3b2912db9d93be585d3d16585df6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*kGcK74ZGtyDsZIdqy-a8tA.png"/></div></div><figcaption class="nn no gj gh gi np nq bd b be z dk"><strong class="bd nr">MS COCO Test-Dev Set</strong></figcaption></figure></div><div class="ab cl lm ln hu lo" role="separator"><span class="lp bw bk lq lr ls"/><span class="lp bw bk lq lr ls"/><span class="lp bw bk lq lr"/></div><div class="ij ik il im in"><p id="8220" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">有关于可区分的 ROI 扭曲层的细节，也有网络设置的细节。这里我还没有提到。如果有兴趣，请访问该文件。</p></div><div class="ab cl lm ln hu lo" role="separator"><span class="lp bw bk lq lr ls"/><span class="lp bw bk lq lr ls"/><span class="lp bw bk lq lr"/></div><div class="ij ik il im in"><h2 id="4d94" class="nt lu iq bd lv nu nv dn lz nw nx dp md ko ny nz mf ks oa ob mh kw oc od mj oe bi translated">参考</h2><p id="1789" class="pw-post-body-paragraph kf kg iq kh b ki mn jr kk kl mo ju kn ko of kq kr ks og ku kv kw oh ky kz la ij bi translated">【2016 CVPR】【MNC】<br/><a class="ae ns" href="https://arxiv.org/abs/1512.04412" rel="noopener ugc nofollow" target="_blank">经由多任务网络级联的实例感知语义分割</a></p><h2 id="3812" class="nt lu iq bd lv nu nv dn lz nw nx dp md ko ny nz mf ks oa ob mh kw oc od mj oe bi translated">我的相关评论</h2><p id="5972" class="pw-post-body-paragraph kf kg iq kh b ki mn jr kk kl mo ju kn ko of kq kr ks og ku kv kw oh ky kz la ij bi translated">)(我)(们)(都)(不)(想)(到)(这)(些)(人)(,)(我)(们)(都)(不)(想)(要)(到)(这)(些)(人)(,)(但)(是)(这)(些)(人)(还)(不)(想)(到)(这)(些)(人)(,)(我)(们)(还)(没)(想)(到)(这)(些)(事)(,)(我)(们)(就)(想)(到)(了)(这)(些)(人)(们)(,)(我)(们)(们)(都)(不)(想)(要)(到)(这)(些)(人)(,)(但)(我)(们)(还)(没)(想)(到)(这)(些)(事)(,)(我)(们)(还)(没)(想)(到)(这)(里)(来)(。 )(我)(们)(都)(不)(知)(道)(,)(我)(们)(还)(是)(不)(知)(道)(,)(我)(们)(还)(是)(不)(知)(道)(,)(我)(们)(还)(是)(不)(知)(道)(,)(我)(们)(还)(是)(不)(知)(道)(,)(我)(们)(还)(是)(不)(知)(道)(,)(我)(们)(还)(是)(不)(知)(道)(,)(我)(们)(还)(是)(不)(知)(道)(。</p><p id="8b77" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir">物体检测<br/></strong><a class="ae ns" href="https://medium.com/coinmonks/review-of-overfeat-winner-of-ilsvrc-2013-localization-task-object-detection-a6f8b9044754" rel="noopener">过食</a><a class="ae ns" href="https://medium.com/coinmonks/review-r-cnn-object-detection-b476aba290d1" rel="noopener">R-CNN</a><a class="ae ns" href="https://medium.com/coinmonks/review-fast-r-cnn-object-detection-a82e172e87ba" rel="noopener">快 R-CNN</a><a class="ae ns" rel="noopener" target="_blank" href="/review-faster-r-cnn-object-detection-f5685cb30202">快 R-CNN</a><a class="ae ns" rel="noopener" target="_blank" href="/review-deepid-net-def-pooling-layer-object-detection-f72486f1a0f6">DeepID-Net</a><a class="ae ns" rel="noopener" target="_blank" href="/review-r-fcn-positive-sensitive-score-maps-object-detection-91cd2389345c">R-FCN</a>】<a class="ae ns" rel="noopener" target="_blank" href="/review-ion-inside-outside-net-2nd-runner-up-in-2015-coco-detection-object-detection-da19993f4766">离子</a><a class="ae ns" rel="noopener" target="_blank" href="/review-multipath-mpn-1st-runner-up-in-2015-coco-detection-segmentation-object-detection-ea9741e7c413">多路</a><a class="ae ns" rel="noopener" target="_blank" href="/yolov1-you-only-look-once-object-detection-e1f3ffec8a89">yolov 1</a><a class="ae ns" rel="noopener" target="_blank" href="/review-ssd-single-shot-detector-object-detection-851a94607d11"/></p><p id="6582" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir">语义切分<br/></strong>[<a class="ae ns" rel="noopener" target="_blank" href="/review-fcn-semantic-segmentation-eb8c9b50d2d1">FCN</a>][<a class="ae ns" rel="noopener" target="_blank" href="/review-deconvnet-unpooling-layer-semantic-segmentation-55cf8a6e380e">de convnet</a>][<a class="ae ns" rel="noopener" target="_blank" href="/review-deeplabv1-deeplabv2-atrous-convolution-semantic-segmentation-b51c5fbde92d">deeplab v1&amp;deeplab v2</a>][<a class="ae ns" href="https://medium.com/datadriveninvestor/review-parsenet-looking-wider-to-see-better-semantic-segmentation-aa6b6a380990" rel="noopener">parse net</a>][<a class="ae ns" rel="noopener" target="_blank" href="/review-dilated-convolution-semantic-segmentation-9d5a5bd768f5">dilated net</a>][<a class="ae ns" rel="noopener" target="_blank" href="/review-pspnet-winner-in-ilsvrc-2016-semantic-segmentation-scene-parsing-e089e5df177d">PSPNet</a>]</p><p id="98cb" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir">实例分割<br/></strong><a class="ae ns" rel="noopener" target="_blank" href="/review-deepmask-instance-segmentation-30327a072339">深度遮罩</a><a class="ae ns" rel="noopener" target="_blank" href="/review-sharpmask-instance-segmentation-6509f7401a61">锐度遮罩</a><a class="ae ns" rel="noopener" target="_blank" href="/review-multipath-mpn-1st-runner-up-in-2015-coco-detection-segmentation-object-detection-ea9741e7c413">多路径</a></p></div></div>    
</body>
</html>