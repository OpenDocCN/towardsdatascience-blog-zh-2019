# ML 中的实际数据问题

> 原文：<https://towardsdatascience.com/practical-data-problems-in-ml-f68ea8ff3784?source=collection_archive---------31----------------------->

## 在构建第一个模型之前需要考虑的六个问题

![](img/7ca117b9bd74b6a182b37f460a235b7d.png)

Photo by Jacek Dylag on Unsplash

想象一下:我们刚刚为我们公司或客户的机器学习提出了一个巧妙的用例。当我们把这个想法带给我们的团队时，他们立刻被激起了兴趣；我们的想法不仅简单易懂，而且有清晰的商业案例和解决用户生活中反复出现的痛点的机会。我们的执行利益相关者也同样热情，并立即给予我们开发小规模试点所需的资金。在我们知道之前，我们收到了其他团队的经理和数据科学家的 ping 和电子邮件，他们听说了我们正在做的事情，并想知道他们如何才能参与进来。“很明显，我们已经有了一个赢家，”你听到有人说，“如果我们能找到数据就好了”。

这就是玫瑰色眼镜脱落的地方。访问干净、可靠的数据始终是机器学习工作流程中最困难的阶段。许多人惊讶地发现，获取、探索和转换数据会占用我们试点项目总开发时间的 70%以上，有些人很快就在这个过程中寻找捷径。正如我们很快会看到的，我们不能在这一关键步骤上有所懈怠:我们在这一阶段寻求识别的问题极其微妙，难以识别，如果不解决就会停止。

在我们做其他事情之前，我们必须找到数据存储在哪里，以及谁可以为我们提供访问权限。这一步通常比听起来要难。大型企业将把结构良好的数据放在十几个不同的筒仓中(每个筒仓都有自己的所有者)，而初创公司和较小的公司缺乏时间和资金来投资便利的数据库基础设施。如果幸运的话，我们将能够与日常用户一起工作，在几天内绘制出我们需要的系统，并获得访问权限。如果没有，我们将在下一周跟踪数据所有者并填写访问请求，然后才能最终访问适当的后端。

在我们将所需的各种资源连接到我们的开发环境之后，真正的工作就开始了。下一步，通常被称为数据争论或数据清理，是探索、连接和转换我们的数据的迭代过程，以确保它既准备好建模又代表现实。这个过程远不如将预测模型整合到我们的 ML 管道中那么迷人，但它无疑是机器学习工作流程中最重要的阶段。正如亚马逊最近对自动招聘的尝试所示，任何基于有偏见的数据训练的模型都会产生有偏见的结果。在建模之前理清这些偏见对我们试点的成功至关重要。

我们在这个阶段寻找的线索很容易发现:错误的或缺失的值、重复的或标记错误的条目、意外的分布和极端的异常值在基本的汇总统计中都是可见的。然而，这些小问题中的一个或多个的存在可能预示着一个更深层次的问题，这个问题可能没有简单的解决方案:

*   **抽样偏差**:我们的训练数据排除了特定的子群，或者通常不代表总体人口，所以我们的模型不能很好地推广到现实世界。上面提到的亚马逊试点就是这个问题的一个很好的例子。如果你用不成比例的男性数据来训练一个招聘模型，就会错误地认为男性比女性更好。如果我们有足够的数据，我们可以使用重采样来纠正一些偏差，但如果偏差太严重，这个问题就不会发生。
*   **一个接一个的错误**:我们的一个上游循环、连接或映射没有按照我们预期的方式运行，因此，我们的一个变量不再意味着我们认为它意味着什么。这个问题很难诊断，并且经常不被发现，直到有人试图解释错误的模型。如果错误发生在数据收集或 ETL 阶段，那么我们可能必须让数据所有者参与进来，以找到解决方法。
*   **非平稳性**:特定特征的分布会随着时间而变化，所以我们必须考虑我们用来训练模型的时间范围。一个常见的例子是周销售额，当产品经历其生命周期的不同阶段时，它往往会随着时间而变化。如果我们能够从逻辑上解释这种不稳定性，我们也许能够使用一些简单的统计技巧来模拟我们的数据。然而，如果我们不理解变化背后的原因，我们可能会在数据集中遗漏重要的环境变量。
*   **异方差**:我们的一个特征的方差随着我们目标变量的变化而变化，表明我们训练数据中的测量误差或亚群体差异。与非平稳性类似，异方差的存在可能表明我们需要在建模之前找到或生成新的特征。
*   **偏斜变量**:我们的变量表现出强烈的左倾或右倾偏斜，如果我们不在训练前转换数据，这可能会导致我们的模型过度拟合异常值。解决这个问题的常见转换包括标准化、规范化或对数转换；我们必须试验几种不同的缩放方法，以找到最适合我们的数据的方法。
*   编码不当:我们对变量进行编码或索引的方式导致我们的模型做出不代表现实的假设。例如，单独使用线性标度来表示每个月，并不能准确地捕捉时间的循环性质(十二月和一月是相邻的，而不是相隔 12–1 = 11 个月)。如果我们坚持使用基于树的算法(特别是 LightGBM，它在处理类别方面非常出色)，使用索引编码可能没什么大不了的，但是如果我们不生成新的特性来捕捉这些关系，其他技术就会受到影响。

这些问题没有正确的答案，没有灵丹妙药；每种方法都有六种，每种方法都需要不同的权衡。为了选择最好的方法，我们需要不断地产生关于数据来源的假设，使用可视化和统计来测试这些假设，并与数据的所有者一起验证我们的假设。这个过程既乏味又耗时，但它意味着在我们的构建过程中更多的是一个迭代过程:我们会在前面发现一些问题，但许多问题直到我们开始解释我们的模型之后才会被发现。最重要的是，我们尽可能长时间地处于探索模式，并留出足够的时间来测试和解决这些问题，而不会错过最后期限。

有一点是肯定的:当我们的用户和管理人员期望根据我们的工作做出决策时，我们不能忽略这一分析，并期望交付一个成功的试点。探索和理解我们的数据的重要性也是我看淡所有[汽车炒作](https://www.forbes.com/sites/janakirammsv/2018/04/15/why-automl-is-set-to-become-the-future-of-artificial-intelligence/#11410a0d780a)的原因；今天的产品远远不够智能，无法复制在野外捕捉这些问题所需的功能体验和批判性思维。亚马逊的人力资源问题相对较小，因为他们发现得早，但当信息不太灵通的公司将其有偏见的 AutoML 模型投入生产时会发生什么？在接下来的几年里，我们将有无数的例子可以探索。