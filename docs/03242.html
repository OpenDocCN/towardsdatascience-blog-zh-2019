<html>
<head>
<title>Linear Regression</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">线性回归</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/apache-spark-mllib-tutorial-ec6f1cb336a9?source=collection_archive---------8-----------------------#2019-05-24">https://towardsdatascience.com/apache-spark-mllib-tutorial-ec6f1cb336a9?source=collection_archive---------8-----------------------#2019-05-24</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><h2 id="c951" class="ir is it bd b dl iu iv iw ix iy iz dk ja translated" aria-label="kicker paragraph">Apache Spark ML 教程</h2><div class=""/><div class=""><h2 id="a834" class="pw-subtitle-paragraph jz jc it bd b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq dk translated">介绍 Spark ML 以及如何使用它来训练线性回归模型</h2></div><p id="0c70" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">注意:本文是系列文章的一部分。查看完整系列: <strong class="kt jd"> <em class="ln">第 1 部分:回归</em> </strong> <em class="ln">，</em> <a class="ae lo" href="https://medium.com/@alimasri1991/apache-spark-mllib-tutorial-7aba8a1dce6e" rel="noopener"> <em class="ln">第 2 部分:特征转化</em> </a> <em class="ln">，</em> <a class="ae lo" rel="noopener" target="_blank" href="/apache-spark-mllib-tutorial-part-3-complete-classification-workflow-a1eb430ad069"> <em class="ln">第 3 部分:分类</em> </a> <em class="ln">，第 4 部分及以上即将推出。</em></p><figure class="lq lr ls lt gt lu gh gi paragraph-image"><div class="gh gi lp"><img src="../Images/8e34dd2c2ec7b8a9b3700ae441a6250c.png" data-original-src="https://miro.medium.com/v2/resize:fit:752/format:webp/1*Pa7PO1v7bANI7C-eHMS_PQ.png"/></div></figure><p id="81cc" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">本系列的目标是帮助您开始使用 Apache Spark 的 ML 库。我们将一起探索如何以一种结构良好的方式解决各种有趣的机器学习用例。最后，您将能够满怀信心地使用 Spark ML，并学会为您未来的项目实现一个有组织且易于维护的工作流</p></div><div class="ab cl lx ly hx lz" role="separator"><span class="ma bw bk mb mc md"/><span class="ma bw bk mb mc md"/><span class="ma bw bk mb mc"/></div><div class="im in io ip iq"><p id="bf50" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">在本系列的第一部分，我们将重点关注 Spark ML 的基础知识。我们将介绍创建回归模型来预测房价的必要步骤。更复杂的 Spark ML 特性和功能将在本系列的后续文章中发布。</p><p id="8cf0" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">在进一步讨论之前，让我们从一些定义开始。</p><h1 id="6bb7" class="me mf it bd mg mh mi mj mk ml mm mn mo ki mp kj mq kl mr km ms ko mt kp mu mv bi translated">定义</h1><h2 id="36d6" class="mw mf it bd mg mx my dn mk mz na dp mo la nb nc mq le nd ne ms li nf ng mu iz bi translated">阿帕奇火花</h2><p id="a159" class="pw-post-body-paragraph kr ks it kt b ku nh kd kw kx ni kg kz la nj lc ld le nk lg lh li nl lk ll lm im bi translated">Apache Spark 是一个开源的集群计算框架。Spark 代码库最初是由加州大学伯克利分校的 AMPLab 开发的，后来被捐赠给了 Apache Software Foundation，该基金会一直维护着它。Spark 提供了一个接口，通过隐式数据并行和容错对整个集群进行编程。</p><h2 id="f460" class="mw mf it bd mg mx my dn mk mz na dp mo la nb nc mq le nd ne ms li nf ng mu iz bi translated">火花毫升</h2><p id="24fe" class="pw-post-body-paragraph kr ks it kt b ku nh kd kw kx ni kg kz la nj lc ld le nk lg lh li nl lk ll lm im bi translated"><a class="ae lo" href="https://spark.apache.org/mllib/" rel="noopener ugc nofollow" target="_blank"> Apache Spark </a> ML 是由常用学习算法和实用程序组成的机器学习库，包括分类、回归、聚类、协同过滤、降维以及底层优化原语。</p><h2 id="2494" class="mw mf it bd mg mx my dn mk mz na dp mo la nb nc mq le nd ne ms li nf ng mu iz bi translated">为什么选择 Spark ML？</h2><p id="3772" class="pw-post-body-paragraph kr ks it kt b ku nh kd kw kx ni kg kz la nj lc ld le nk lg lh li nl lk ll lm im bi translated">迈向大数据时代需要对非常大的数据集进行大量迭代计算。机器学习算法的标准实现需要非常强大的机器才能运行。依赖高端机器并不有利，因为它们价格高昂，而且不适合扩大规模。使用分布式计算引擎的想法是将计算分布到多个低端机器(商用硬件)，而不是一个高端机器。这无疑加速了学习阶段，并允许我们创建更好的模型。</p><h1 id="c0c1" class="me mf it bd mg mh mi mj mk ml mm mn mo ki mp kj mq kl mr km ms ko mt kp mu mv bi translated">软件要求</h1><p id="5b11" class="pw-post-body-paragraph kr ks it kt b ku nh kd kw kx ni kg kz la nj lc ld le nk lg lh li nl lk ll lm im bi translated">为了继续学习本教程，您必须安装以下软件:</p><ul class=""><li id="fc44" class="nm nn it kt b ku kv kx ky la no le np li nq lm nr ns nt nu bi translated">计算机编程语言</li><li id="21e5" class="nm nn it kt b ku nv kx nw la nx le ny li nz lm nr ns nt nu bi translated">阿帕奇火花</li><li id="266e" class="nm nn it kt b ku nv kx nw la nx le ny li nz lm nr ns nt nu bi translated">findspark 库</li><li id="a8d2" class="nm nn it kt b ku nv kx nw la nx le ny li nz lm nr ns nt nu bi translated">Numpy</li><li id="bf44" class="nm nn it kt b ku nv kx nw la nx le ny li nz lm nr ns nt nu bi translated">朱皮特</li></ul><h2 id="26cf" class="mw mf it bd mg mx my dn mk mz na dp mo la nb nc mq le nd ne ms li nf ng mu iz bi translated">阿帕奇火花</h2><p id="28be" class="pw-post-body-paragraph kr ks it kt b ku nh kd kw kx ni kg kz la nj lc ld le nk lg lh li nl lk ll lm im bi translated">安装 Apache Spark 是如此简单。你只要从<a class="ae lo" href="https://spark.apache.org/downloads.html" rel="noopener ugc nofollow" target="_blank">官网</a>下载包就可以了。</p><p id="5eee" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">要测试您的实现:</p><ol class=""><li id="332b" class="nm nn it kt b ku kv kx ky la no le np li nq lm oa ns nt nu bi translated">解压缩文件</li><li id="e096" class="nm nn it kt b ku nv kx nw la nx le ny li nz lm oa ns nt nu bi translated">转到<strong class="kt jd"> <em class="ln"> bin </em> </strong>目录</li><li id="b1f6" class="nm nn it kt b ku nv kx nw la nx le ny li nz lm oa ns nt nu bi translated">运行以下命令</li></ol><pre class="lq lr ls lt gt ob oc od oe aw of bi"><span id="cf1e" class="mw mf it oc b gy og oh l oi oj">% ./pyspark --version</span></pre><p id="0d8c" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">输出应该如下所示:</p><figure class="lq lr ls lt gt lu gh gi paragraph-image"><div class="gh gi ok"><img src="../Images/905d722cccec35725cff9f5b9ec259ef.png" data-original-src="https://miro.medium.com/v2/resize:fit:960/format:webp/1*DGaDf2xXa2aU8H9Nvulh9g.png"/></div><figcaption class="ol om gj gh gi on oo bd b be z dk">Testing Apache Spark version</figcaption></figure><h2 id="eea1" class="mw mf it bd mg mx my dn mk mz na dp mo la nb nc mq le nd ne ms li nf ng mu iz bi translated">findspark 库</h2><p id="601e" class="pw-post-body-paragraph kr ks it kt b ku nh kd kw kx ni kg kz la nj lc ld le nk lg lh li nl lk ll lm im bi translated">为了更容易到达 Apache Spark，我们将使用<a class="ae lo" href="https://github.com/minrk/findspark" rel="noopener ugc nofollow" target="_blank"> findspark </a>。这是一个非常简单的库，可以自动设置开发环境来导入 Apache Spark 库。</p><p id="3e88" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">要安装 findspark，请在 shell 中运行以下命令:</p><pre class="lq lr ls lt gt ob oc od oe aw of bi"><span id="04f3" class="mw mf it oc b gy og oh l oi oj">% pip install findspark</span></pre><h2 id="9969" class="mw mf it bd mg mx my dn mk mz na dp mo la nb nc mq le nd ne ms li nf ng mu iz bi translated">Numpy</h2><p id="5348" class="pw-post-body-paragraph kr ks it kt b ku nh kd kw kx ni kg kz la nj lc ld le nk lg lh li nl lk ll lm im bi translated">Numpy 是 Python 中著名的数值计算库。Spark ML 在内部使用它进行计算。</p><p id="ab91" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">使用以下命令安装它:</p><pre class="lq lr ls lt gt ob oc od oe aw of bi"><span id="7dd6" class="mw mf it oc b gy og oh l oi oj">% pip install numpy</span></pre><p id="1c79" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated"><strong class="kt jd"> Jupyter </strong></p><p id="7a14" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated"><a class="ae lo" href="https://jupyter.org" rel="noopener ugc nofollow" target="_blank">Jupyter Notebook</a>是一个开源的网络应用程序，允许你创建和共享包含实时代码、公式、可视化和叙述性文本的文档。用途包括:数据清理和转换、数值模拟、统计建模、数据可视化、机器学习等等。</p><p id="41a5" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">要安装 Jupyter:</p><pre class="lq lr ls lt gt ob oc od oe aw of bi"><span id="5f60" class="mw mf it oc b gy og oh l oi oj">% pip install jupyter</span></pre><h1 id="de85" class="me mf it bd mg mh mi mj mk ml mm mn mo ki mp kj mq kl mr km ms ko mt kp mu mv bi translated">问题定义</h1><p id="1f20" class="pw-post-body-paragraph kr ks it kt b ku nh kd kw kx ni kg kz la nj lc ld le nk lg lh li nl lk ll lm im bi translated">这个系列的第一个问题是<strong class="kt jd"> <em class="ln">回归</em> </strong>。我们将训练一个模型来预测著名的<a class="ae lo" href="https://www.cs.toronto.edu/~delve/data/boston/bostonDetail.html" rel="noopener ugc nofollow" target="_blank"> <em class="ln">波士顿房屋</em> </a> <em class="ln"> </em>数据集(从<a class="ae lo" href="https://drive.google.com/open?id=1-zxrKH1T0fM1Oi1mZzCWNtzHzeM4OsKt" rel="noopener ugc nofollow" target="_blank">这里下载</a>)。</p><p id="ab10" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">该数据集包含由美国人口普查局收集的有关马萨诸塞州波士顿地区住房的信息。它是从<a class="ae lo" href="http://lib.stat.cmu.edu/datasets/boston" rel="noopener ugc nofollow" target="_blank"> StatLib 档案</a>中获得的，并在整个文献中被广泛用于基准算法。</p><p id="40ed" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">数据集很小，只有 506 个案例。它包含 14 个特征，描述如下:</p><ol class=""><li id="645e" class="nm nn it kt b ku kv kx ky la no le np li nq lm oa ns nt nu bi translated">CRIM:城镇人均犯罪率</li><li id="c76e" class="nm nn it kt b ku nv kx nw la nx le ny li nz lm oa ns nt nu bi translated">ZN:面积超过 25，000 平方英尺的住宅用地比例</li><li id="d015" class="nm nn it kt b ku nv kx nw la nx le ny li nz lm oa ns nt nu bi translated">印度河流域:每个城镇非零售商业英亩数的比例。</li><li id="0998" class="nm nn it kt b ku nv kx nw la nx le ny li nz lm oa ns nt nu bi translated">CHAS: Charles River 虚拟变量(如果区域边界为河流，则为 1；否则为 0)</li><li id="7196" class="nm nn it kt b ku nv kx nw la nx le ny li nz lm oa ns nt nu bi translated">NOX:氮氧化物浓度(百万分之一)</li><li id="3026" class="nm nn it kt b ku nv kx nw la nx le ny li nz lm oa ns nt nu bi translated">RM:每个住宅的平均房间数</li><li id="60b6" class="nm nn it kt b ku nv kx nw la nx le ny li nz lm oa ns nt nu bi translated">年龄:1940 年以前建造的自有住房的比例</li><li id="80f2" class="nm nn it kt b ku nv kx nw la nx le ny li nz lm oa ns nt nu bi translated">DIS:到五个波士顿就业中心的加权距离</li><li id="c00c" class="nm nn it kt b ku nv kx nw la nx le ny li nz lm oa ns nt nu bi translated">RAD:放射状公路可达性指数</li><li id="2730" class="nm nn it kt b ku nv kx nw la nx le ny li nz lm oa ns nt nu bi translated">税收:每 1 万美元的全价值财产税税率</li><li id="539d" class="nm nn it kt b ku nv kx nw la nx le ny li nz lm oa ns nt nu bi translated">PTRATIO:按城镇分列的师生比率</li><li id="5edc" class="nm nn it kt b ku nv kx nw la nx le ny li nz lm oa ns nt nu bi translated">B: 1000(Bk — 0.63)，其中 Bk 是按城镇划分的黑人比例</li><li id="3a49" class="nm nn it kt b ku nv kx nw la nx le ny li nz lm oa ns nt nu bi translated">LSTAT: %人口的较低地位</li><li id="da66" class="nm nn it kt b ku nv kx nw la nx le ny li nz lm oa ns nt nu bi translated">MEDV:以千美元为单位的自有住房中值</li></ol><p id="8360" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated"><strong class="kt jd">目标是使用这 13 个特征来预测 MEDV 的价值(代表房价)。</strong></p><p id="7d00" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">是时候把手弄脏了。让我们跳跃到火花和火花中。</p><h1 id="675f" class="me mf it bd mg mh mi mj mk ml mm mn mo ki mp kj mq kl mr km ms ko mt kp mu mv bi translated">履行</h1><h2 id="cc98" class="mw mf it bd mg mx my dn mk mz na dp mo la nb nc mq le nd ne ms li nf ng mu iz bi translated">设置 Apache Spark</h2><p id="2a7c" class="pw-post-body-paragraph kr ks it kt b ku nh kd kw kx ni kg kz la nj lc ld le nk lg lh li nl lk ll lm im bi translated">准备好你的开发环境午餐<strong class="kt jd"> <em class="ln"> Jupyter </em> </strong>并创建一个新的笔记本。</p><pre class="lq lr ls lt gt ob oc od oe aw of bi"><span id="cf7a" class="mw mf it oc b gy og oh l oi oj">% jupyter notebook</span></pre><p id="9015" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">我们首先导入<strong class="kt jd"> <em class="ln"> findspark </em> </strong>库，并通过传递 Apache Spark 文件夹的路径来初始化它。</p><pre class="lq lr ls lt gt ob oc od oe aw of bi"><span id="a210" class="mw mf it oc b gy og oh l oi oj">import findspark<br/>findspark.init('/opt/spark')</span></pre><p id="95f5" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">每个 Spark 应用程序都需要一个<strong class="kt jd"> <em class="ln"> SparkSession </em> </strong>。</p><p id="ee15" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">为了创建一个<strong class="kt jd"> <em class="ln"> SparkSession </em> </strong>我们写:</p><pre class="lq lr ls lt gt ob oc od oe aw of bi"><span id="af1e" class="mw mf it oc b gy og oh l oi oj">from pyspark.sql import SparkSession<br/>spark = SparkSession.builder.getOrCreate()</span></pre><h2 id="65fc" class="mw mf it bd mg mx my dn mk mz na dp mo la nb nc mq le nd ne ms li nf ng mu iz bi translated">加载数据</h2><pre class="lq lr ls lt gt ob oc od oe aw of bi"><span id="1639" class="mw mf it oc b gy og oh l oi oj">data = spark.read.csv('./boston_housing.csv', header=True, inferSchema=True)</span></pre><ul class=""><li id="23dc" class="nm nn it kt b ku kv kx ky la no le np li nq lm nr ns nt nu bi translated">header=True 表示第一行包含标题</li><li id="7664" class="nm nn it kt b ku nv kx nw la nx le ny li nz lm nr ns nt nu bi translated">inferSchema=True 启用底层数据模式的自动检测</li></ul><p id="548b" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">要显示数据:</p><pre class="lq lr ls lt gt ob oc od oe aw of bi"><span id="4ad5" class="mw mf it oc b gy og oh l oi oj">data.show()</span></pre><figure class="lq lr ls lt gt lu gh gi paragraph-image"><div role="button" tabindex="0" class="oq or di os bf ot"><div class="gh gi op"><img src="../Images/263122cff36c02ec4c013586421bbfe1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*q8dzRPO0Xv_8IVH-fY7-hw.png"/></div></div><figcaption class="ol om gj gh gi on oo bd b be z dk">Top 20 rows of the data</figcaption></figure><h2 id="c0d6" class="mw mf it bd mg mx my dn mk mz na dp mo la nb nc mq le nd ne ms li nf ng mu iz bi translated">设置功能</h2><p id="41d7" class="pw-post-body-paragraph kr ks it kt b ku nh kd kw kx ni kg kz la nj lc ld le nk lg lh li nl lk ll lm im bi translated">现在是有趣的部分… Spark ML 的算法期望数据以两列表示:<strong class="kt jd">特征</strong>和<strong class="kt jd">标签</strong>。Features 是用于预测的所有特征的数据点数组。标签包含每个数据点的输出标签。</p><p id="1ff9" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">在我们的例子中，特性是从 1 → 13 的列，标签是包含价格的<em class="ln"> MEDV </em>列。</p><blockquote class="ou"><p id="c92f" class="ov ow it bd ox oy oz pa pb pc pd lm dk translated">目标是从特征中预测标签。</p></blockquote><p id="3709" class="pw-post-body-paragraph kr ks it kt b ku pe kd kw kx pf kg kz la pg lc ld le ph lg lh li pi lk ll lm im bi translated">创建特征数组非常简单。您只需导入<strong class="kt jd"><em class="ln">vector assembler</em></strong>类，并传入一个特性列名列表。</p><pre class="lq lr ls lt gt ob oc od oe aw of bi"><span id="0462" class="mw mf it oc b gy og oh l oi oj">feature_columns = data.columns[:-1] # here we omit the final column</span><span id="1001" class="mw mf it oc b gy pj oh l oi oj">from pyspark.ml.feature import VectorAssembler</span><span id="3d0c" class="mw mf it oc b gy pj oh l oi oj">assembler = VectorAssembler(inputCols=feature_columns,outputCol="features")</span></pre><ul class=""><li id="812a" class="nm nn it kt b ku kv kx ky la no le np li nq lm nr ns nt nu bi translated">outputCol="features "定义组合所有值的输出向量的名称</li></ul><p id="20dc" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">现在我们使用汇编程序来创建特性列:</p><pre class="lq lr ls lt gt ob oc od oe aw of bi"><span id="d99a" class="mw mf it oc b gy og oh l oi oj">data_2 = assembler.transform(data)</span></pre><p id="37f3" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">就是这样！如果打印 data_2 的值，您会注意到一个名为“features”的新列，它包含所有组合在一个列表中的值:</p><pre class="lq lr ls lt gt ob oc od oe aw of bi"><span id="fdc7" class="mw mf it oc b gy og oh l oi oj">data_2.show()</span></pre><figure class="lq lr ls lt gt lu gh gi paragraph-image"><div role="button" tabindex="0" class="oq or di os bf ot"><div class="gh gi pk"><img src="../Images/775dbc4a6fa05f40ff8ea61208228e9b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*81GQdVRqzLkdnPPW4lixhw.png"/></div></div><figcaption class="ol om gj gh gi on oo bd b be z dk">Data after VectorAssembler</figcaption></figure><h2 id="dc39" class="mw mf it bd mg mx my dn mk mz na dp mo la nb nc mq le nd ne ms li nf ng mu iz bi translated">训练\测试分割</h2><p id="129d" class="pw-post-body-paragraph kr ks it kt b ku nh kd kw kx ni kg kz la nj lc ld le nk lg lh li nl lk ll lm im bi translated">正如在任何机器学习工作流程中一样，我们将数据分为训练集和测试集。这里我们把它分成 70%的训练样本和 30%的测试样本。</p><pre class="lq lr ls lt gt ob oc od oe aw of bi"><span id="2557" class="mw mf it oc b gy og oh l oi oj">train, test = data_2.randomSplit([0.7, 0.3])</span></pre><h2 id="3215" class="mw mf it bd mg mx my dn mk mz na dp mo la nb nc mq le nd ne ms li nf ng mu iz bi translated">训练机器学习算法</h2><p id="0987" class="pw-post-body-paragraph kr ks it kt b ku nh kd kw kx ni kg kz la nj lc ld le nk lg lh li nl lk ll lm im bi translated">我们转到另一个有趣的部分，让我们根据我们的数据训练一个简单的<strong class="kt jd"> <em class="ln">线性回归</em> </strong>模型。首先，我们导入必要的类。</p><pre class="lq lr ls lt gt ob oc od oe aw of bi"><span id="32d2" class="mw mf it oc b gy og oh l oi oj">from pyspark.ml.regression import LinearRegression</span></pre><p id="a391" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">接下来我们定义<strong class="kt jd"> <em class="ln">算法</em> </strong>变量。我们需要指定特性列和标签列的名称。</p><pre class="lq lr ls lt gt ob oc od oe aw of bi"><span id="2ffb" class="mw mf it oc b gy og oh l oi oj">algo = LinearRegression(featuresCol="features", labelCol="medv")</span></pre><p id="a5ae" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">训练时间…我们调用<strong class="kt jd"> <em class="ln"> fit </em> </strong>方法，开始在训练集上训练我们的模型。</p><pre class="lq lr ls lt gt ob oc od oe aw of bi"><span id="afdc" class="mw mf it oc b gy og oh l oi oj">model = algo.fit(train)</span></pre><p id="efe8" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">瞧啊。您已经使用 Spark ML 训练了您的第一个模型！</p><h2 id="6552" class="mw mf it bd mg mx my dn mk mz na dp mo la nb nc mq le nd ne ms li nf ng mu iz bi translated">评估模型性能</h2><p id="82b0" class="pw-post-body-paragraph kr ks it kt b ku nh kd kw kx ni kg kz la nj lc ld le nk lg lh li nl lk ll lm im bi translated">完成培训阶段是不够的。我们必须计算我们的模型有多好。幸好模型对象有一个<strong class="kt jd"> <em class="ln">求值</em> </strong>的方法:</p><pre class="lq lr ls lt gt ob oc od oe aw of bi"><span id="257b" class="mw mf it oc b gy og oh l oi oj">evaluation_summary = model.evaluate(test)</span></pre><p id="c24b" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">使用<strong class="kt jd"><em class="ln">evaluation _ summary</em></strong>对象访问大量指标:</p><pre class="lq lr ls lt gt ob oc od oe aw of bi"><span id="1339" class="mw mf it oc b gy og oh l oi oj">evaluation_summary.meanAbsoluteError<br/># Output: 3.39<br/>evaluation_summary.rootMeanSquaredError<br/># Output: 5.16<br/>evaluation_summary.r2<br/># Output: 0.58</span></pre><p id="cf44" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">嗯，对于一个简单的模型来说还不错。</p><h2 id="7a63" class="mw mf it bd mg mx my dn mk mz na dp mo la nb nc mq le nd ne ms li nf ng mu iz bi translated">预测值</h2><p id="ebc7" class="pw-post-body-paragraph kr ks it kt b ku nh kd kw kx ni kg kz la nj lc ld le nk lg lh li nl lk ll lm im bi translated">为了预测未标记数据的输出，在传递 DataFrame 时调用<strong class="kt jd"><em class="ln">model . transform</em></strong>函数。</p><p id="fa66" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">例如，让我们从测试集中预测值:</p><pre class="lq lr ls lt gt ob oc od oe aw of bi"><span id="3448" class="mw mf it oc b gy og oh l oi oj">predictions = model.transform(test)</span></pre><p id="b039" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated"><strong class="kt jd"> <em class="ln">预测</em> </strong>是一个数据帧，包含:模型生成的原始列、特征列和预测列。</p><pre class="lq lr ls lt gt ob oc od oe aw of bi"><span id="f1ac" class="mw mf it oc b gy og oh l oi oj">predictions.select(predictions.columns[13:]).show() # here I am filtering out some columns just for the figure to fit</span></pre><figure class="lq lr ls lt gt lu gh gi paragraph-image"><div class="gh gi pl"><img src="../Images/9c503806cb21385bd9527461c5ebfc10.png" data-original-src="https://miro.medium.com/v2/resize:fit:764/format:webp/1*WUeGLFEQEg80_h2zRGt20w.png"/></div><figcaption class="ol om gj gh gi on oo bd b be z dk">Predictions</figcaption></figure><h1 id="0034" class="me mf it bd mg mh mi mj mk ml mm mn mo ki mp kj mq kl mr km ms ko mt kp mu mv bi translated">完整代码</h1><figure class="lq lr ls lt gt lu"><div class="bz fp l di"><div class="pm pn l"/></div><figcaption class="ol om gj gh gi on oo bd b be z dk">Full Code</figcaption></figure><h1 id="8ae4" class="me mf it bd mg mh mi mj mk ml mm mn mo ki mp kj mq kl mr km ms ko mt kp mu mv bi translated">最后的想法</h1><p id="ed1a" class="pw-post-body-paragraph kr ks it kt b ku nh kd kw kx ni kg kz la nj lc ld le nk lg lh li nl lk ll lm im bi translated">我知道这是一篇很长的文章，但我希望它值得你花时间。我们介绍了 Apache Spark 及其令人惊叹的 ML 库。我们在一个回归问题上使用了 Spark ML 来预测房价。接下来，我将介绍其他用例的更多特性。敬请关注…</p><p id="788d" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">如果你喜欢这篇文章，请点击“鼓掌”按钮，我将不胜感激👏所以可能会传染给他人。也可以在 <a class="ae lo" href="https://twitter.com/alimasri1991" rel="noopener ugc nofollow" target="_blank"> <em class="ln">推特</em> </a> <em class="ln">，</em> <a class="ae lo" href="https://www.facebook.com/alimasri91" rel="noopener ugc nofollow" target="_blank"> <em class="ln">脸书</em> </a> <em class="ln">，</em> <a class="ae lo" href="mailto:alimasri1991@gmail.com" rel="noopener ugc nofollow" target="_blank"> <em class="ln">上关注我直接发邮件给我</em> </a> <em class="ln">或者在</em><a class="ae lo" href="https://www.linkedin.com/in/alimasri/" rel="noopener ugc nofollow" target="_blank"><em class="ln">LinkedIn</em></a><em class="ln">上找我。</em></p></div></div>    
</body>
</html>