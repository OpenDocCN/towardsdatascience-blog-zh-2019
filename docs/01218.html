<html>
<head>
<title>Time Series in Python — Part 3: Forecasting taxi trips with LSTMs</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">Python 中的时间序列第 3 部分:用 LSTMs 预测出租车出行</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/time-series-in-python-part-3-forecasting-taxi-trips-with-lstms-277afd4f811?source=collection_archive---------2-----------------------#2019-02-25">https://towardsdatascience.com/time-series-in-python-part-3-forecasting-taxi-trips-with-lstms-277afd4f811?source=collection_archive---------2-----------------------#2019-02-25</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><p id="2b0b" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><em class="ko">在本文中，我们将使用 LSTMs 预测纽约的 FHV 数量(如优步出租汽车)。我们将学习如何使用蒙特卡洛法将置信区间添加到我们的预测中。</em></p><figure class="kq kr ks kt gt ku gh gi paragraph-image"><div role="button" tabindex="0" class="kv kw di kx bf ky"><div class="gh gi kp"><img src="../Images/98414a13b1547b4100fe0ae86d67466d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*_idAYapRhgBrkYvs"/></div></div><figcaption class="lb lc gj gh gi ld le bd b be z dk">Photo by <a class="ae lf" href="https://unsplash.com/@lexianderson?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Lexi Anderson</a> on <a class="ae lf" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><h1 id="cd7e" class="lg lh it bd li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md bi translated">介绍</h1><p id="96e1" class="pw-post-body-paragraph jq jr it js b jt me jv jw jx mf jz ka kb mg kd ke kf mh kh ki kj mi kl km kn im bi translated">LSTM(Long Short Memory)是一种 a 型递归神经网络(RNN)架构，由<a class="ae lf" href="https://en.wikipedia.org/wiki/Sepp_Hochreiter" rel="noopener ugc nofollow" target="_blank"> Sepp Hochreiter </a>和<a class="ae lf" href="https://en.wikipedia.org/wiki/J%C3%BCrgen_Schmidhuber" rel="noopener ugc nofollow" target="_blank"> Jürgen Schmidhuber </a>于 1997 年提出。rnn 是专门设计用于通过递归机制处理顺序数据的深度神经网络。它们以一种自回归的方式表现，因为它们通过内部状态来跟踪过去(因此是“记忆”部分)。它们被广泛用于语音识别、机器翻译、语音合成等。但是当用于时间序列时，LSTMs 值多少呢？假设可用数据的规模足够大，它们可以被证明对非线性关系的建模非常有用..</p></div><div class="ab cl mj mk hx ml" role="separator"><span class="mm bw bk mn mo mp"/><span class="mm bw bk mn mo mp"/><span class="mm bw bk mn mo"/></div><div class="im in io ip iq"><h1 id="4145" class="lg lh it bd li lj mq ll lm ln mr lp lq lr ms lt lu lv mt lx ly lz mu mb mc md bi translated">优步用例:贝叶斯预测</h1><p id="fa98" class="pw-post-body-paragraph jq jr it js b jt me jv jw jx mf jz ka kb mg kd ke kf mh kh ki kj mi kl km kn im bi translated">在找用 LSTMs 实现时间序列预测的论文时，找到了优步 2017 年写的一篇论文，<a class="ae lf" href="https://arxiv.org/pdf/1709.01907.pdf" rel="noopener ugc nofollow" target="_blank"><em class="ko">优步</em></a>对时间序列的深度自信预测。这篇论文背后的基本问题是:<strong class="js iu">我们有多大信心(<em class="ko">即我们如何量化不确定性</em>)用 LSTMs 进行预测？</strong></p><p id="9a51" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">优步开发的方法是编码器-解码器(用作自动编码器)和完全连接的前馈网络的混合，用于根据以前的数据预测城市的出行次数，或实时检测异常。</p><figure class="kq kr ks kt gt ku gh gi paragraph-image"><div class="gh gi mv"><img src="../Images/1c87be8ebd2dd84f0bea0f68c61b5089.png" data-original-src="https://miro.medium.com/v2/resize:fit:1288/format:webp/1*GE3Ld86Pr0qF85zaG7XQvA.png"/></div><figcaption class="lb lc gj gh gi ld le bd b be z dk">The Uber LSTM forecasting architecture (Zhu &amp; Laptev, 2017)</figcaption></figure><p id="aa76" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">优步的论文是最先使用贝叶斯方法进行时间序列预测的论文之一。如果你想了解更多关于贝叶斯神经网络和贝叶斯推理的知识，可以看看下面的链接:</p><ul class=""><li id="bd01" class="mw mx it js b jt ju jx jy kb my kf mz kj na kn nb nc nd ne bi translated"><a class="ae lf" rel="noopener" target="_blank" href="/making-your-neural-network-say-i-dont-know-bayesian-nns-using-pyro-and-pytorch-b1c24e6ab8cd"> <em class="ko">让你的神经网络说不知道</em> </a></li><li id="735d" class="mw mx it js b jt nf jx ng kb nh kf ni kj nj kn nb nc nd ne bi translated"><a class="ae lf" href="https://arxiv.org/pdf/1506.02142.pdf" rel="noopener ugc nofollow" target="_blank"> <em class="ko">辍学为贝叶斯近似</em> </a></li><li id="f4fb" class="mw mx it js b jt nf jx ng kb nh kf ni kj nj kn nb nc nd ne bi translated"><a class="ae lf" href="https://medium.com/@joeDiHare/deep-bayesian-neural-networks-952763a9537" rel="noopener"> <em class="ko">深度贝叶斯神经网络</em> </a></li><li id="a935" class="mw mx it js b jt nf jx ng kb nh kf ni kj nj kn nb nc nd ne bi translated"><em class="ko">黑客的贝叶斯方法</em>，卡梅隆·戴维森-皮隆</li></ul><h2 id="e71c" class="nk lh it bd li nl nm dn lm nn no dp lq kb np nq lu kf nr ns ly kj nt nu mc nv bi translated">贝叶斯神经网络</h2><p id="e69e" class="pw-post-body-paragraph jq jr it js b jt me jv jw jx mf jz ka kb mg kd ke kf mh kh ki kj mi kl km kn im bi translated">简而言之，贝叶斯神经网络估计每个权重的概率分布，而经典神经网络试图找到每个权重的最佳值。听到“贝叶斯”，就想到“概率分布”。</p><p id="c7da" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu"><em class="ko">——但是预测不确定性和贝叶斯网络有什么联系呢？</em>T3】</strong></p><p id="c552" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">想象两个气象专家，鲍勃和爱丽丝。你们都知道他们很擅长预测天气温度，但有时他们也会弄错。你问他们明天早上 8 点的温度是多少，这样你就可以知道你是否需要穿上外套。<br/>鲍勃说:“将会是 15.6 摄氏度”。爱丽丝说:“我有 95%的把握气温会在 16 到 18 摄氏度之间”。虽然他们似乎不同意，但你会相信谁呢？</p><p id="b707" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">就我个人而言，我相信爱丽丝有两个原因:</p><ul class=""><li id="a3b1" class="mw mx it js b jt ju jx jy kb my kf mz kj na kn nb nc nd ne bi translated">她给了我一个信心区间。当有人能够告诉我一些事情以及他/她对这些信息有多自信时，我会感到更加放心。</li><li id="d307" class="mw mx it js b jt nf jx ng kb nh kf ni kj nj kn nb nc nd ne bi translated">我并不在乎确切的温度，因为 1 摄氏度的温差不会影响我穿上外套的决定。</li></ul><p id="8aaa" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">然而，如果 Alice 告诉我“<em class="ko">我 95%确定温度将在 0°C 到 18°C 之间</em>，我会说虽然她给了我一个信心水平，但这个区间太大了，无法提供信息……</p><h2 id="a8c4" class="nk lh it bd li nl nm dn lm nn no dp lq kb np nq lu kf nr ns ly kj nt nu mc nv bi translated">BNN 框架下的不确定性</h2><p id="8290" class="pw-post-body-paragraph jq jr it js b jt me jv jw jx mf jz ka kb mg kd ke kf mh kh ki kj mi kl km kn im bi translated">我们通常将不确定性分为 3 类:<strong class="js iu"> <em class="ko">模型不确定性</em> </strong>，<strong class="js iu"> <em class="ko">固有噪声</em> </strong>，<strong class="js iu"> <em class="ko">模型误设定</em> </strong>。前两个是最著名的，通常被称为<strong class="js iu"><em class="ko"/></strong>和<strong class="js iu"> <em class="ko">任意</em> </strong>不确定性。<br/>模型(或<em class="ko">认知</em>)不确定性是关于我们的模型参数的不确定性。数据越多，就越能解释(即“减少”)这种不确定性。噪声(或<em class="ko">任意性</em>)不确定性是指观测值中的噪声。如果所有样本的噪声不确定度都是常数，我们称之为<strong class="js iu"> <em class="ko">同方差</em> </strong>不确定度。否则，如果一些样本比其他样本更不确定，我们将使用术语<strong class="js iu"> <em class="ko">异方差随机变量</em> </strong>。噪声不确定性不能随着更多的数据而减少。</p><p id="0770" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">在优步的论文中，使用了第三种不确定性:模型设定错误。这种不确定性旨在“<em class="ko">在预测与训练数据集</em>有很大不同的模式的未知样本时捕捉不确定性”。</p><p id="11d1" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu"> — <em class="ko">现在为什么要区分所有这些不确定性</em> </strong> <em class="ko">？</em></p><p id="f64e" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">嗯，正是因为有些可以用更多的数据(模型/认知)来对抗，而有些不能。因此，一些研究人员认为，考虑到即使有更多的数据也无法减少随机不确定性，关注随机不确定性更有意义(<a class="ae lf" href="https://arxiv.org/pdf/1703.04977.pdf" rel="noopener ugc nofollow" target="_blank"> Kendall &amp; Gal，2017 </a>)</p><p id="6be5" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><em class="ko">在本文中，为了简单起见，我们将只关注模型的不确定性。优步使用不同的算法来评估另外两种不确定性，但是研究它们超出了本文的范围。</em></p></div><div class="ab cl mj mk hx ml" role="separator"><span class="mm bw bk mn mo mp"/><span class="mm bw bk mn mo mp"/><span class="mm bw bk mn mo"/></div><div class="im in io ip iq"><h1 id="5a11" class="lg lh it bd li lj mq ll lm ln mr lp lq lr ms lt lu lv mt lx ly lz mu mb mc md bi translated">获取和准备数据</h1><p id="1a14" class="pw-post-body-paragraph jq jr it js b jt me jv jw jx mf jz ka kb mg kd ke kf mh kh ki kj mi kl km kn im bi translated">论文中的作者使用美国 8 个城市 4 年的数据来训练他们的模型。3 年用于培训，1 年用于测试。不幸的是，优步还没有发布这个数据，但是为了重现他们论文的结果，我们将使用纽约开放数据<a class="ae lf" href="https://www1.nyc.gov/site/tlc/about/tlc-trip-record-data.page" rel="noopener ugc nofollow" target="_blank">门户</a>上的可用数据。我们选取了三年的数据，时间跨度从 2015 年初到 2018 年年中。每天对数据进行重新采样。这是完整数据的样子</p><figure class="kq kr ks kt gt ku gh gi paragraph-image"><div class="gh gi nw"><img src="../Images/cdf19e0a38244b30f15f7bd8ef7d8344.png" data-original-src="https://miro.medium.com/v2/resize:fit:1300/format:webp/1*fCexDOMzzo6hH3YTFEtIZA.png"/></div></figure></div><div class="ab cl mj mk hx ml" role="separator"><span class="mm bw bk mn mo mp"/><span class="mm bw bk mn mo mp"/><span class="mm bw bk mn mo"/></div><div class="im in io ip iq"><h2 id="d76c" class="nk lh it bd li nl nm dn lm nn no dp lq kb np nq lu kf nr ns ly kj nt nu mc nv bi translated">平稳性</h2><p id="f9bb" class="pw-post-body-paragraph jq jr it js b jt me jv jw jx mf jz ka kb mg kd ke kf mh kh ki kj mi kl km kn im bi translated">如果你习惯于分析时间序列，我们可以注意到一些你应该熟悉的东西:</p><ol class=""><li id="2e37" class="mw mx it js b jt ju jx jy kb my kf mz kj na kn nx nc nd ne bi translated">我们观察到明显的上升趋势</li><li id="bf34" class="mw mx it js b jt nf jx ng kb nh kf ni kj nj kn nx nc nd ne bi translated">均值和方差随时间增加</li><li id="b1d3" class="mw mx it js b jt nf jx ng kb nh kf ni kj nj kn nx nc nd ne bi translated">我们还观察到可能由外部事件(节假日和天气)引起的峰值。)</li></ol><p id="11f0" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">前两个要点表明我们的系列显然不是一成不变的。后者表明我们可能需要将外部数据合并到我们的系列中。平稳性可以用扩展的迪基-富勒测试或 KPSS 测试来检验。那么我们应该像对 ARIMA 模型那样进行这些测试吗？<br/> —答案是:不一定。</p><p id="fcf0" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">当我们平稳化一个序列时，我们想要的是在整个时间内均值和方差不变。这保证了如果你取一个 N 点样本进行预测，并用另一个 N 点不同的样本重复这一过程，那么你的 N 点样本和你试图预测的 N+1 点之间的关系是相同的(即它们来自相同的分布)。如果均值和方差不相等，那么您是从不同的分布中抽取样本来进行预测，您的模型肯定无法进行概括。</p><p id="e1d2" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">与 ARIMA 不同，rnn 能够模拟数据中的非线性关系。<br/>rnn，尤其是 LSTM 和 GRU，能够捕捉长期依赖关系(前提是你有足够多的数据！).因此，去趋势化和去季节性之类的问题不那么重要，但你应该经常问自己:</p><blockquote class="ny"><p id="00e5" class="nz oa it bd ob oc od oe of og oh kn dk translated">我用于测试的数据是否遵循与我用于训练的数据相同的行为(即来自相同的分布)？</p></blockquote><h2 id="5f0a" class="nk lh it bd li nl oi dn lm nn oj dp lq kb ok nq lu kf ol ns ly kj om nu mc nv bi translated">假期和天气</h2><p id="a4a7" class="pw-post-body-paragraph jq jr it js b jt me jv jw jx mf jz ka kb mg kd ke kf mh kh ki kj mi kl km kn im bi translated">添加假日指示非常简单。我们使用 Python 中的<em class="ko"> holidays </em>库来获取 2015 年到 2018 年的假期日期。<br/>在我们的系列中添加了一个假日布尔之后，我们仍然观察到无法解释的峰值… <br/>在互联网上快速浏览显示，其中几天实际上是纽约州遭受暴风雪等极端天气事件袭击的日子。<br/>我们在下面的图表中用红色标出了节假日，绿色标出了极端天气事件:</p><figure class="kq kr ks kt gt ku gh gi paragraph-image"><div class="gh gi on"><img src="../Images/70d35713e291aea1c1f11ac339f9cb83.png" data-original-src="https://miro.medium.com/v2/resize:fit:1304/format:webp/1*RNPu0k5h7Vt8163Y7llipg.png"/></div></figure><p id="c576" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">因此，在我们的数据框架中，我们有一个“<em class="ko">计数</em>”列，一个“<em class="ko">是 _ 假日</em>”列，一个“<em class="ko">是 _ 恶劣天气</em>”列。但是，假设我们要进行预测，我们需要“预测”这些日期，就像我们对未来预测一样，因此我们将创建两个额外的列，指示第二天是假日或第二天预计会出现极端天气:</p><pre class="kq kr ks kt gt oo op oq or aw os bi"><span id="4510" class="nk lh it op b gy ot ou l ov ow">weather = [datetime.datetime.strptime(date, "%Y-%m-%d") for date in ['2018-01-04', '2018-03-21','2017-03-14','2017-02-09','2016-01-23']]</span><span id="3866" class="nk lh it op b gy ox ou l ov ow">holidays = [date for y in range(2015, 2019) for date, _ in sorted(holidays.US(years=y).items())]</span><span id="3239" class="nk lh it op b gy ox ou l ov ow">df['is_holiday'] = np.where(df.index.isin(holidays), 1, 0)<br/>df['bad_weather'] = np.where(df.index.isin(weather), 1, 0)<br/>df['next_is_holiday'] = df.is_holiday.shift(-1)<br/>df['next_bad_weather'] = df.bad_weather.shift(-1)</span></pre><h2 id="54a5" class="nk lh it bd li nl nm dn lm nn no dp lq kb np nq lu kf nr ns ly kj nt nu mc nv bi translated">选择窗口大小和回测</h2><p id="e8ee" class="pw-post-body-paragraph jq jr it js b jt me jv jw jx mf jz ka kb mg kd ke kf mh kh ki kj mi kl km kn im bi translated">做时间序列预测时，你可能会听说<strong class="js iu"> <em class="ko">回测</em> </strong>。回溯测试是在训练过程中使用的一个程序，它包括以递增的方式将数据分割成块。在每一次迭代中，一个块被用作你的训练集。然后你试着在你的块之前预测一个或多个值。可以使用两种方法，<em class="ko">展开</em>和<em class="ko">滑动</em>窗口:</p><figure class="kq kr ks kt gt ku gh gi paragraph-image"><div class="gh gi oy"><img src="../Images/fa03956945e27a5dafe09507836aaf59.png" data-original-src="https://miro.medium.com/v2/resize:fit:1350/format:webp/1*473sUTkrFKDQsN4n2pdQXA.png"/></div><figcaption class="lb lc gj gh gi ld le bd b be z dk">source: <a class="ae lf" href="https://www.datapred.com/blog/the-basics-of-backtesting" rel="noopener ugc nofollow" target="_blank">https://www.datapred.com/blog/the-basics-of-backtesting</a></figcaption></figure><p id="2b52" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">在我们的案例研究中，作者使用由步长等于 1 的 28 天滑动窗口组成的样本，用于预测下一个值(提前 1 步预测)。</p><h2 id="4cb3" class="nk lh it bd li nl nm dn lm nn no dp lq kb np nq lu kf nr ns ly kj nt nu mc nv bi translated">记录和缩放</h2><p id="7feb" class="pw-post-body-paragraph jq jr it js b jt me jv jw jx mf jz ka kb mg kd ke kf mh kh ki kj mi kl km kn im bi translated">在论文中，作者首先采用数据的对数来“<em class="ko">减轻指数效应</em>”。然后，他们在每个窗口中减去窗口的第一个值，以消除趋势，并根据窗口第一个值的波动来训练网络(<em class="ko">等式(1) </em>)。也可以想到其他方法，例如减去第一值并除以第一值(<em class="ko">等式(2) </em>):</p><figure class="kq kr ks kt gt ku gh gi paragraph-image"><div class="gh gi oz"><img src="../Images/dcbd164c71b99e7984839b45e0e4df8b.png" data-original-src="https://miro.medium.com/v2/resize:fit:686/format:webp/1*1S6f9lsmo8O7Fsh5QEeRjg.png"/></div></figure><h1 id="93f9" class="lg lh it bd li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md bi translated">构建数据集</h1><p id="e1d6" class="pw-post-body-paragraph jq jr it js b jt me jv jw jx mf jz ka kb mg kd ke kf mh kh ki kj mi kl km kn im bi translated">我们的数据集将是一个生成器，产生一批滑动窗口(每一批都是在未来移动 1 个值的前一批)。为了遵循论文的说明，我们还将在每一批中从所有其他值中减去第一个值。然后，每批样本被分为 28 天样本和 1 天目标样本。</p><figure class="kq kr ks kt gt ku"><div class="bz fp l di"><div class="pa pb l"/></div></figure><h1 id="945c" class="lg lh it bd li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md bi translated">定义模型</h1><p id="cd52" class="pw-post-body-paragraph jq jr it js b jt me jv jw jx mf jz ka kb mg kd ke kf mh kh ki kj mi kl km kn im bi translated">我们将使用 PyTorch 来定义我们的模型。一个简单的原因是，我们将在推理过程中使用 dropout，并且它很容易在 PyTorch 中实现。我们将从使用一个简单的 LSTM 网络开始，如论文中所定义的:1 个具有 128 个单元的 LSTM 层，1 个具有 32 个单元的 LSTM 层，以及一个具有 1 个输出的全连接层。在每一层之后添加漏失。</p><p id="0fef" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu"><em class="ko">——中途辍学者<br/> </em> </strong>中途辍学可以被看作是做贝叶斯推理的一种方式(尽管围绕这一点还有争论)。从技术上讲，退出是神经网络中使用的过程，包括随机退出单元(以及它们的连接)。<br/>随机打开和关闭神经元的事实大致相当于执行伯努利分布的采样，因此“模拟”了贝叶斯神经网络的机制(其中权重是分布，而不是单个值)。应用 dropout 有点像我们从网络中“取样”。如果我们在推理过程中多次重复这个过程，我们将得到不同的预测，用这些预测我们可以估计一个分布，最终，不确定性！总而言之:</p><figure class="kq kr ks kt gt ku gh gi paragraph-image"><div role="button" tabindex="0" class="kv kw di kx bf ky"><div class="gh gi pc"><img src="../Images/8a060dae456ffe7081c19533c94c7844.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*i3qGMn9ZiH6UXP03fKoMjg.png"/></div></div></figure><p id="1ac1" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">现在，让我们通过在每个 LSTM 层之间添加下降层来定义模型(注意<em class="ko"> train </em>如何设置为 True，以便在训练和测试期间使用下降)</p><figure class="kq kr ks kt gt ku"><div class="bz fp l di"><div class="pa pb l"/></div></figure><h2 id="3054" class="nk lh it bd li nl nm dn lm nn no dp lq kb np nq lu kf nr ns ly kj nt nu mc nv bi translated">培养</h2><p id="388e" class="pw-post-body-paragraph jq jr it js b jt me jv jw jx mf jz ka kb mg kd ke kf mh kh ki kj mi kl km kn im bi translated">我们用 Adam 优化器和学习率设置为 0.001，batch_size 为 1，训练 5 个时期。</p><figure class="kq kr ks kt gt ku"><div class="bz fp l di"><div class="pa pb l"/></div></figure><p id="228b" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">结果:</p><figure class="kq kr ks kt gt ku gh gi paragraph-image"><div role="button" tabindex="0" class="kv kw di kx bf ky"><div class="gh gi pd"><img src="../Images/5a40537c59e1759434d3466294f18e91.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*7sSbsmbJM5UYf-JmndUk0A.png"/></div></div><figcaption class="lb lc gj gh gi ld le bd b be z dk">Fitted values on the train set</figcaption></figure><h2 id="1e4a" class="nk lh it bd li nl nm dn lm nn no dp lq kb np nq lu kf nr ns ly kj nt nu mc nv bi translated">测试— 1 天预测范围</h2><p id="d98a" class="pw-post-body-paragraph jq jr it js b jt me jv jw jx mf jz ka kb mg kd ke kf mh kh ki kj mi kl km kn im bi translated">本文的主要兴趣之一是不确定性的估计。</p><blockquote class="pe pf pg"><p id="198c" class="jq jr ko js b jt ju jv jw jx jy jz ka ph kc kd ke pi kg kh ki pj kk kl km kn im bi translated">具体而言，在每个隐藏层之后应用随机漏失，并且模型输出可以近似地视为从后验预测分布生成的随机样本。<strong class="js iu">因此，可以通过几次重复的模型预测的样本方差来估计模型的不确定性。</strong></p></blockquote><p id="9068" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">因此，本文背后的想法是用随机漏失运行几次模型，这将产生不同的输出值。然后，我们可以计算输出的经验均值和方差，以获得每个时间步长的置信区间！</p><figure class="kq kr ks kt gt ku"><div class="bz fp l di"><div class="pa pb l"/></div></figure><p id="b243" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">对于每一步，我们预测 100 个值。所有的值都是不同的，假设我们保持辍学集。这使我们能够模拟从我们的网络中采样(事实上，辍学与贝叶斯神经网络密切相关，因为通过随机断开权重，它模拟了一种概率分布)。我们将这 100 个值的平均值作为我们的预测平均值，并将这 100 个值的标准偏差用于我们的置信区间。假设我们的预测来自正态分布<em class="ko"> N </em> ( <em class="ko"> μ </em>，<em class="ko">σ</em>)——均值<em class="ko"> μ </em>等于我们的经验均值，标准差<em class="ko"> σ </em>等于我们的经验标准差——那么我们可以估计置信区间。在我们的例子中，它由下式给出:</p><figure class="kq kr ks kt gt ku gh gi paragraph-image"><div class="gh gi pk"><img src="../Images/e69d1f7860441ef7be5c2f8db28597d9.png" data-original-src="https://miro.medium.com/v2/resize:fit:978/format:webp/1*QIZGDhphldsz1c6R_774UA.png"/></div></figure><figure class="kq kr ks kt gt ku gh gi paragraph-image"><div role="button" tabindex="0" class="kv kw di kx bf ky"><div class="gh gi pl"><img src="../Images/fe4e310a16977d708d741373e028c3fc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*-_lbPeWvwKk1EieX3Tf9zQ.png"/></div></div><figcaption class="lb lc gj gh gi ld le bd b be z dk">Predicted values and uncertainty intervals</figcaption></figure><p id="e105" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">预测和测试曲线似乎非常接近！然而，我们需要找到一个度量标准来查看我们的模型表现如何。</p><p id="99c0" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">如果我们查看 95%预测区间的经验覆盖率(即预测的 95%置信区间中包含的真实测试值的数量)，我们会获得 28.51%的值，与论文中测试集上获得的值相差甚远……当我们取 99% CI 时，该值会上升到 44%覆盖率。这不是一个很好的结果，但请记住，我们的置信区间很小，因为我们只预测模型的不确定性…</p><h2 id="8f72" class="nk lh it bd li nl nm dn lm nn no dp lq kb np nq lu kf nr ns ly kj nt nu mc nv bi translated">测试— 7 天预测范围</h2><p id="f72a" class="pw-post-body-paragraph jq jr it js b jt me jv jw jx mf jz ka kb mg kd ke kf mh kh ki kj mi kl km kn im bi translated">单日预测的结果对于预测模型来说并不太好，而且我们对模型的要求并不高，因为我们要求的是一个非常短的预测范围。如果我们训练我们的模型来预测更大范围的预测会怎么样？</p><h1 id="b33f" class="lg lh it bd li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md bi translated">结论</h1><p id="791b" class="pw-post-body-paragraph jq jr it js b jt me jv jw jx mf jz ka kb mg kd ke kf mh kh ki kj mi kl km kn im bi translated"><strong class="js iu">lstm 因其捕捉长时间相关性的能力而显示出建模时间序列的有趣前景，但应仅用于大型数据集</strong>。永远不要期望你的 RNN 在 100 个样本的数据集上给出好的结果！神经网络中的参数数量和可用数据大小之间的平衡对于避免过度拟合非常重要。优步论文的作者之一尼古拉·拉普捷夫总结说:</p><blockquote class="ny"><p id="3f39" class="nz oa it bd ob oc od oe of og oh kn dk translated"><strong class="ak">经典模型</strong>最适合:<br/> ○短的或不相关的时间序列<br/> ○已知的世界状态</p><p id="cbb8" class="nz oa it bd ob oc od oe of og oh kn dk translated"><strong class="ak">神经网络</strong>最适合:<br/> ○大量时间序列<br/> ○长时间序列<br/> ○隐藏交互<br/> ○解释不重要</p></blockquote><p id="76e5" class="pw-post-body-paragraph jq jr it js b jt pm jv jw jx pn jz ka kb po kd ke kf pp kh ki kj pq kl km kn im bi translated"><strong class="js iu"> <em class="ko">在</em> </strong> <a class="ae lf" rel="noopener" target="_blank" href="/time-series-in-python-exponential-smoothing-and-arima-processes-2c67f2a52788"> <strong class="js iu"> <em class="ko">第一部分</em> </strong> </a> <strong class="js iu"> <em class="ko">和</em> </strong> <a class="ae lf" rel="noopener" target="_blank" href="/time-series-in-python-part-2-dealing-with-seasonal-data-397a65b74051"> <strong class="js iu"> <em class="ko">第二部分</em> </strong> </a> <strong class="js iu"> <em class="ko">中了解有关时间序列的更多信息！</em> </strong></p></div></div>    
</body>
</html>