<html>
<head>
<title>UNet — Line by Line Explanation</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">UNet —逐行解释</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/unet-line-by-line-explanation-9b191c76baf5?source=collection_archive---------0-----------------------#2019-10-18">https://towardsdatascience.com/unet-line-by-line-explanation-9b191c76baf5?source=collection_archive---------0-----------------------#2019-10-18</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="b756" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">UNet 实施示例</h2></div><p id="c746" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">UNet 由传统的卷积神经网络演变而来，于 2015 年首次设计并应用于处理生物医学图像。由于一般卷积神经网络将其任务集中在图像分类上，其中输入是图像，输出是一个标签，但在生物医学情况下，它要求我们不仅要区分是否存在疾病，还要定位异常区域。</p><p id="7fc5" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">UNet 致力于解决这一问题。它能够定位和区分边界的原因是通过对每个像素进行分类，因此输入和输出共享相同的大小。例如，对于尺寸为 2x2 的输入图像:</p><pre class="le lf lg lh gt li lj lk ll aw lm bi"><span id="1554" class="ln lo it lj b gy lp lq l lr ls">[[255, 230], [128, 12]]  # each number is a pixel</span></pre><p id="07bc" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">输出将具有相同的大小 2x2:</p><pre class="le lf lg lh gt li lj lk ll aw lm bi"><span id="f275" class="ln lo it lj b gy lp lq l lr ls">[[1, 0], [1, 1]]  # could be any number between [0, 1]</span></pre><p id="1cd2" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">现在让我们来看看 UNet 的具体实现。我会:</p><ol class=""><li id="3c72" class="lt lu it kk b kl km ko kp kr lv kv lw kz lx ld ly lz ma mb bi translated">显示 UNet 的概述</li><li id="fb9c" class="lt lu it kk b kl mc ko md kr me kv mf kz mg ld ly lz ma mb bi translated">逐行分解实现并进一步解释它</li></ol><h1 id="e0bb" class="mh lo it bd mi mj mk ml mm mn mo mp mq jz mr ka ms kc mt kd mu kf mv kg mw mx bi translated">概观</h1><p id="0cc4" class="pw-post-body-paragraph ki kj it kk b kl my ju kn ko mz jx kq kr na kt ku kv nb kx ky kz nc lb lc ld im bi translated">这个网络的基本基础看起来像是:</p><figure class="le lf lg lh gt ne gh gi paragraph-image"><div role="button" tabindex="0" class="nf ng di nh bf ni"><div class="gh gi nd"><img src="../Images/8ec61019601e1b21856223280dc3fcce.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*f7YOaE4TWubwaFF7Z1fzNw.png"/></div></div><figcaption class="nl nm gj gh gi nn no bd b be z dk">UNet architecture</figcaption></figure><p id="16fb" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">乍一看，它呈“U”形。该架构是对称的，由两大部分组成—左边部分称为收缩路径，由一般的卷积过程构成；右边部分是扩展路径，由转置的 2d 卷积层构成(你现在可以认为它是一种上采样技术)。</p><p id="07fb" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">现在让我们快速看一下实现:</p><figure class="le lf lg lh gt ne"><div class="bz fp l di"><div class="np nq l"/></div></figure><p id="cb27" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">代码引用自 Kaggle 竞赛的一个<a class="ae nr" href="https://www.kaggle.com/phoenigs/u-net-dropout-augmentation-stratification" rel="noopener ugc nofollow" target="_blank">内核</a>，一般来说，大多数 UNet 遵循相同的结构。</p><p id="3151" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">现在让我们一行一行地分解实现，并映射到 UNet 架构映像上的相应部分。</p><h1 id="cf7b" class="mh lo it bd mi mj mk ml mm mn mo mp mq jz mr ka ms kc mt kd mu kf mv kg mw mx bi translated">逐行解释</h1><h2 id="add8" class="ln lo it bd mi ns nt dn mm nu nv dp mq kr nw nx ms kv ny nz mu kz oa ob mw oc bi translated">收缩路径</h2><p id="4c64" class="pw-post-body-paragraph ki kj it kk b kl my ju kn ko mz jx kq kr na kt ku kv nb kx ky kz nc lb lc ld im bi translated">收缩路径遵循以下公式:</p><pre class="le lf lg lh gt li lj lk ll aw lm bi"><span id="6a55" class="ln lo it lj b gy lp lq l lr ls">conv_layer1 -&gt; conv_layer2 -&gt; max_pooling -&gt; dropout(optional)</span></pre><p id="763f" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">所以我们代码的第一部分是:</p><figure class="le lf lg lh gt ne"><div class="bz fp l di"><div class="np nq l"/></div></figure><p id="be86" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">哪一个符合:</p><figure class="le lf lg lh gt ne gh gi paragraph-image"><div class="gh gi od"><img src="../Images/5d4664dffd684697ef8e2cc24c884af0.png" data-original-src="https://miro.medium.com/v2/resize:fit:424/format:webp/1*xW5JGavuJAxwMsJRZs_0Rg.png"/></div></figure><p id="16fa" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="kk iu">注意每个过程构成两个卷积层</strong>，通道数从 1 → 64 变化，因为卷积过程会增加图像的深度。向下的红色箭头是最大池化过程，它将图像的大小减半(大小从 572x572 → 568x568 减少是由于填充问题，但这里的实现使用 padding= "same ")。</p><p id="c5c1" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">该过程重复 3 次以上:</p><figure class="le lf lg lh gt ne gh gi paragraph-image"><div class="gh gi oe"><img src="../Images/4ae1f9f5e8668f73bd7aaf34ebf9e475.png" data-original-src="https://miro.medium.com/v2/resize:fit:768/format:webp/1*yGu1oXPeqEvbKRuWL0z3Dw.png"/></div></figure><p id="60b1" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">带代码:</p><figure class="le lf lg lh gt ne"><div class="bz fp l di"><div class="np nq l"/></div></figure><p id="f3d5" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">现在我们到达了最底部:</p><figure class="le lf lg lh gt ne gh gi paragraph-image"><div class="gh gi of"><img src="../Images/6ff1d6a78582d576f807a1882aff071a.png" data-original-src="https://miro.medium.com/v2/resize:fit:624/format:webp/1*0973DDf8V7UrgqzuLBiyaQ.png"/></div></figure><p id="75d1" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">仍然构建了 2 个卷积层，但是没有最大池化:</p><figure class="le lf lg lh gt ne"><div class="bz fp l di"><div class="np nq l"/></div></figure><p id="5fc2" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">这时的图像已经调整到 28x28x1024。现在让我们走上宽阔的道路。</p><h2 id="7a74" class="ln lo it bd mi ns nt dn mm nu nv dp mq kr nw nx ms kv ny nz mu kz oa ob mw oc bi translated">宽阔的道路</h2><p id="6aa5" class="pw-post-body-paragraph ki kj it kk b kl my ju kn ko mz jx kq kr na kt ku kv nb kx ky kz nc lb lc ld im bi translated">在扩展路径中，图像将被放大到其原始大小。公式如下:</p><pre class="le lf lg lh gt li lj lk ll aw lm bi"><span id="800c" class="ln lo it lj b gy lp lq l lr ls">conv_2d_transpose -&gt; concatenate -&gt; conv_layer1 -&gt; conv_layer2</span></pre><figure class="le lf lg lh gt ne gh gi paragraph-image"><div class="gh gi og"><img src="../Images/9e8ae226168ef14787cb0b69f0536535.png" data-original-src="https://miro.medium.com/v2/resize:fit:1140/format:webp/1*-2FyAsc71aCXiEHTkVnI7Q.png"/></div></figure><figure class="le lf lg lh gt ne"><div class="bz fp l di"><div class="np nq l"/></div></figure><p id="fd9d" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">转置卷积是一种扩大图像大小的上采样技术。这里有一个可视化演示<a class="ae nr" rel="noopener" target="_blank" href="/types-of-convolutions-in-deep-learning-717013397f4d"/>和一个解释<a class="ae nr" href="https://medium.com/activating-robotic-minds/up-sampling-with-transposed-convolution-9ae4f2df52d0" rel="noopener">这里</a>。基本上，它在原始图像上做一些填充，然后进行卷积运算。</p><p id="9d0e" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在转置卷积之后，图像从 28×28×1024→56×56×512 被放大，然后，该图像与来自收缩路径的相应图像连接在一起，并且一起形成大小为 56×56×1024 的图像。这里的原因是组合来自先前层的信息，以便获得更精确的预测。</p><p id="0b50" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在第 4 行和第 5 行中，添加了 2 个其他卷积层。</p><p id="5732" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">与之前相同，该过程重复 3 次以上:</p><figure class="le lf lg lh gt ne"><div class="bz fp l di"><div class="np nq l"/></div></figure><p id="7deb" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">现在我们已经达到了架构的最上层，最后一步是重塑图像，以满足我们的预测要求。</p><figure class="le lf lg lh gt ne gh gi paragraph-image"><div class="gh gi oh"><img src="../Images/1dcc98c2965744db79e10a82c2d144bd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1224/format:webp/1*yNbPtz4rIGgI6iE-1OPOdg.png"/></div></figure><figure class="le lf lg lh gt ne"><div class="bz fp l di"><div class="np nq l"/></div></figure><p id="8cb1" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">最后一层是卷积层，有 1 个大小为 1x1 的滤波器(注意整个网络没有密集层)。剩下的神经网络训练也一样。</p><h1 id="10fd" class="mh lo it bd mi mj mk ml mm mn mo mp mq jz mr ka ms kc mt kd mu kf mv kg mw mx bi translated">结论</h1><p id="a42c" class="pw-post-body-paragraph ki kj it kk b kl my ju kn ko mz jx kq kr na kt ku kv nb kx ky kz nc lb lc ld im bi translated">UNet 能够通过逐个像素地预测图像来进行图像定位，UNet 的作者在他的<a class="ae nr" href="https://arxiv.org/abs/1505.04597" rel="noopener ugc nofollow" target="_blank">论文</a>中声称，该网络足够强大，可以通过使用过多的数据增强技术，基于甚至很少的数据集来进行良好的预测。使用 UNet 进行图像分割有很多应用，也出现在很多比赛中。一个人应该尝试一下自己，我希望这篇文章可以成为你的一个好的起点。</p><p id="76ae" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="kk iu">参考</strong>:</p><ul class=""><li id="1996" class="lt lu it kk b kl km ko kp kr lv kv lw kz lx ld oi lz ma mb bi translated"><a class="ae nr" href="https://github.com/hlamba28/UNET-TGS/blob/master/TGS%20UNET.ipynb" rel="noopener ugc nofollow" target="_blank">https://github . com/hlamba 28/UNET-TGS/blob/master/TGS % 20 unet . ipynb</a></li><li id="3952" class="lt lu it kk b kl mc ko md kr me kv mf kz mg ld oi lz ma mb bi translated"><a class="ae nr" rel="noopener" target="_blank" href="/understanding-semantic-segmentation-with-unet-6be4f42d4b47">https://towards data science . com/understanding-semantic-segmentation-with-unet-6 be 4f 42 D4 b 47</a></li><li id="c52d" class="lt lu it kk b kl mc ko md kr me kv mf kz mg ld oi lz ma mb bi translated"><a class="ae nr" rel="noopener" target="_blank" href="/types-of-convolutions-in-deep-learning-717013397f4d">https://towards data science . com/types-of-convolutions-in-deep-learning-717013397 f4d</a></li><li id="b2a8" class="lt lu it kk b kl mc ko md kr me kv mf kz mg ld oi lz ma mb bi translated"><a class="ae nr" href="https://medium.com/activating-robotic-minds/up-sampling-with-transposed-convolution-9ae4f2df52d0" rel="noopener">https://medium . com/activating-robotic-minds/up-sampling-with-transposed-convolution-9 AE 4 F2 df 52d 0</a></li><li id="81ac" class="lt lu it kk b kl mc ko md kr me kv mf kz mg ld oi lz ma mb bi translated"><a class="ae nr" href="https://www.kaggle.com/phoenigs/u-net-dropout-augmentation-stratification" rel="noopener ugc nofollow" target="_blank">https://www . ka ggle . com/phoenigs/u-net-dropout-augmentation-layering</a></li></ul></div></div>    
</body>
</html>