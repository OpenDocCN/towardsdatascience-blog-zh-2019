<html>
<head>
<title>RLSD: An End-to-End CNN+LSTM Model for Multi-Label Image Classification</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">RLSD:用于多标签图像分类的端到端 CNN+LSTM 模型</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/rlsd-an-end-to-end-cnn-lstm-model-for-multi-label-image-classification-47dfdf8e4bd9?source=collection_archive---------11-----------------------#2019-02-20">https://towardsdatascience.com/rlsd-an-end-to-end-cnn-lstm-model-for-multi-label-image-classification-47dfdf8e4bd9?source=collection_archive---------11-----------------------#2019-02-20</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><figure class="gl gn jo jp jq jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi jn"><img src="../Images/55bd4fc147fd5c6726ef7f8522ccd086.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*IHh85PFsCg2G80tka0onqg.png"/></div></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk">RLSD localizes regions of interest that contain objects with semantic relationships.</figcaption></figure><h1 id="8f02" class="kc kd iq bd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz bi translated"><strong class="ak">阅读小组</strong></h1><p id="0a03" class="pw-post-body-paragraph la lb iq lc b ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ij bi translated"><a class="ae ly" href="https://launchpad.ai/" rel="noopener ugc nofollow" target="_blank">我们公司</a>有<a class="ae ly" href="https://fellowship.ai/" rel="noopener ugc nofollow" target="_blank">一个机器学习工程师的奖学金项目</a>。奖学金项目的一部分是每周一次的研究论文回顾。每周都会有一名研究员发表一篇最新的机器学习研究论文。</p><p id="2e4f" class="pw-post-body-paragraph la lb iq lc b ld lz lf lg lh ma lj lk ll mb ln lo lp mc lr ls lt md lv lw lx ij bi translated">我喜欢这些每周一次的小组，因为它让我们了解最新的研究。大多数数据科学家花时间阅读研究论文，但我个人不会保持每周一篇论文的节奏，如果我的日程表上没有这些阅读小组。</p><p id="1876" class="pw-post-body-paragraph la lb iq lc b ld lz lf lg lh ma lj lk ll mb ln lo lp mc lr ls lt md lv lw lx ij bi translated">我相信每周、每两个月或至少每月一次的研究阅读小组应该是任何专注于应用机器学习的公司的一部分。这一领域的创新步伐势不可挡。</p><p id="0f5d" class="pw-post-body-paragraph la lb iq lc b ld lz lf lg lh ma lj lk ll mb ln lo lp mc lr ls lt md lv lw lx ij bi translated">作为前研究员和该组织的成员，我偶尔有机会提交自己的研究论文。我想在 Medium 上与我的读者分享我从这篇论文中学到的东西会很不错。</p><h1 id="ac0d" class="kc kd iq bd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz bi translated">多标签图像分类</h1><p id="3c54" class="pw-post-body-paragraph la lb iq lc b ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ij bi translated"><a class="ae ly" href="http://www.image-net.org/" rel="noopener ugc nofollow" target="_blank"> ImageNet </a>中的分类任务是将一幅图像作为一组像素 X 作为输入，并返回该图像的标签 Y 的预测，标签 Y 应该描述图像的主题。</p><figure class="mf mg mh mi gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi me"><img src="../Images/865b018887bda03a949e04ef646e509d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ZDB1jkZ7XFAhM85vLJHFiQ.png"/></div></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk">ImageNet prediction outputs from AlexNet. “Vanilla” ImageNet carries just one label per image.</figcaption></figure><p id="4ecf" class="pw-post-body-paragraph la lb iq lc b ld lz lf lg lh ma lj lk ll mb ln lo lp mc lr ls lt md lv lw lx ij bi translated">这是对计算机视觉问题的过度简化。图像自然包含许多主题。我们可以用多标签分类来表示这种更常见的情况。与其将我们的图像标签限制为每张图像一个，为什么不使用多个标签来表示图像中存在的多个对象呢？</p><figure class="mf mg mh mi gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi mj"><img src="../Images/1c8b341c4d42cef132c28f88b81fbb11.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*keuWU9adMp_REJ8c9YpatQ.jpeg"/></div></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk">Most photographs contain many objects; a seabird, many humans, skateboards, hats, and even boats in the background are present in this example.</figcaption></figure><p id="f1f5" class="pw-post-body-paragraph la lb iq lc b ld lz lf lg lh ma lj lk ll mb ln lo lp mc lr ls lt md lv lw lx ij bi translated">传统神经网络架构的简单改编，如 AlexNet、VGG 等。，可以让你多标签输出。<a class="ae ly" rel="noopener" target="_blank" href="/fast-ai-season-1-episode-3-a-case-of-multi-label-classification-a4a90672a889">在模型的最后一层使用 sigmoid 激活函数</a>，代替 softmax，是一种选择。</p><p id="16cc" class="pw-post-body-paragraph la lb iq lc b ld lz lf lg lh ma lj lk ll mb ln lo lp mc lr ls lt md lv lw lx ij bi translated">但是这种方法并不总是那么有效。对于这个问题，有许多可供选择的方法。</p><p id="e792" class="pw-post-body-paragraph la lb iq lc b ld lz lf lg lh ma lj lk ll mb ln lo lp mc lr ls lt md lv lw lx ij bi translated">今天我将谈谈其中的一种方法。</p><h2 id="e4f9" class="mk kd iq bd ke ml mm dn ki mn mo dp km ll mp mq kq lp mr ms ku lt mt mu ky mv bi translated">区域潜在语义依赖(RLSD)模型</h2><p id="28a7" class="pw-post-body-paragraph la lb iq lc b ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ij bi translated">RLSD 是张等人于 2016 年首次提出的一种<a class="ae ly" href="https://arxiv.org/pdf/1612.01082.pdf" rel="noopener ugc nofollow" target="_blank">方法。这个想法的许多扩展最近已经被探索。</a></p><p id="b80f" class="pw-post-body-paragraph la lb iq lc b ld lz lf lg lh ma lj lk ll mb ln lo lp mc lr ls lt md lv lw lx ij bi translated">研究人员的动机是试图对图像中的<strong class="lc ir">潜在语义依赖</strong>进行建模。之所以使用“潜在”这个词，是因为虽然有标签可用，但描述这些关系的标签却不可用。</p><p id="5bc7" class="pw-post-body-paragraph la lb iq lc b ld lz lf lg lh ma lj lk ll mb ln lo lp mc lr ls lt md lv lw lx ij bi translated">图像中的对象通常以某种方式相互关联，尽管并不总是如此:一个女孩用棒球棒击球。一只小猫坐在电脑上。</p><figure class="mf mg mh mi gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi mw"><img src="../Images/22d730076f33f754260ddbdf6101cc92.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*GilknkT5NHHjpgZP.jpg"/></div></div></figure><p id="c81a" class="pw-post-body-paragraph la lb iq lc b ld lz lf lg lh ma lj lk ll mb ln lo lp mc lr ls lt md lv lw lx ij bi translated">这种关系并不总是存在的。例如，一张照片可能包含一栋建筑、一辆汽车和一棵树，尽管这三个对象不会以任何有意义的方式进行交互。</p><figure class="mf mg mh mi gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi mx"><img src="../Images/fd5b45032d0d065452d643ee4ee05f03.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*SwuxIU4mfjnBcQFh"/></div></div></figure><p id="dabe" class="pw-post-body-paragraph la lb iq lc b ld lz lf lg lh ma lj lk ll mb ln lo lp mc lr ls lt md lv lw lx ij bi translated">这篇论文的想法是创建一个模型，它足够具有<strong class="lc ir">表达能力来学习这些潜在的语义依赖</strong>，同时也足够灵活<strong class="lc ir">来检测独立的同现对象</strong>。</p><h1 id="dead" class="kc kd iq bd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz bi translated">了解 RLSD</h1><p id="d9fb" class="pw-post-body-paragraph la lb iq lc b ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ij bi translated">这篇论文对我来说特别难理解，部分原因是它很复杂，部分原因是它的语法。</p><p id="8f81" class="pw-post-body-paragraph la lb iq lc b ld lz lf lg lh ma lj lk ll mb ln lo lp mc lr ls lt md lv lw lx ij bi translated"><em class="my">说真的，如果有任何 ML 研究者需要英文编辑，</em> <strong class="lc ir"> <em class="my">请在发表前</em> </strong> <em class="my">联系我。</em></p><p id="1bb7" class="pw-post-body-paragraph la lb iq lc b ld lz lf lg lh ma lj lk ll mb ln lo lp mc lr ls lt md lv lw lx ij bi translated">幸运的是，我有一些时间来纠正和消化它。</p><p id="1715" class="pw-post-body-paragraph la lb iq lc b ld lz lf lg lh ma lj lk ll mb ln lo lp mc lr ls lt md lv lw lx ij bi translated"><strong class="lc ir">TL；博士</strong></p><p id="ae70" class="pw-post-body-paragraph la lb iq lc b ld lz lf lg lh ma lj lk ll mb ln lo lp mc lr ls lt md lv lw lx ij bi translated">该模型使用来自<a class="ae ly" href="https://arxiv.org/pdf/1506.01497.pdf" rel="noopener ugc nofollow" target="_blank"> Faster-RCNN </a>的<a class="ae ly" href="https://medium.com/@tanaykarmarkar/region-proposal-network-rpn-backbone-of-faster-r-cnn-4a744a38d7f9" rel="noopener">区域提议网络(RPN) </a>来生成感兴趣区域(RoI)提议。当 RoI 具有高置信度得分时，使用<strong class="lc ir">双线性插值</strong>将与其相关的卷积特征转换为固定大小的特征向量。这些向量通过密集层进行进一步压缩。压缩的特征向量然后被输入到<a class="ae ly" href="https://medium.com/mlreview/understanding-lstm-and-its-diagrams-37e2f46f1714" rel="noopener"> LSTM 模型</a>，该模型将在可变数量的时间步长上处理信息。最后，记录 LSTM 的输出，并使用最大池操作将其转换到标签空间。</p><h2 id="ec6c" class="mk kd iq bd ke ml mm dn ki mn mo dp km ll mp mq kq lp mr ms ku lt mt mu ky mv bi translated">这有用吗？</h2><p id="41c3" class="pw-post-body-paragraph la lb iq lc b ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ij bi translated">这似乎太复杂了，无法工作。(一旦你阅读了训练前的步骤，它开始变得更加可信。)</p><h1 id="1b7e" class="kc kd iq bd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz bi translated"><strong class="ak">区域提案网络</strong></h1><p id="7dbf" class="pw-post-body-paragraph la lb iq lc b ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ij bi translated">在<a class="ae ly" href="https://arxiv.org/pdf/1506.01497.pdf" rel="noopener ugc nofollow" target="_blank">fast-RCNN 论文</a>中介绍了<a class="ae ly" href="https://medium.com/@tanaykarmarkar/region-proposal-network-rpn-backbone-of-faster-r-cnn-4a744a38d7f9" rel="noopener">区域提议网络，或 RPN，</a>。网络学习从图像空间到一组固定的边界框的映射，称为<em class="my">锚</em>。锚预测带有置信度得分和四个边界框回归值，它们转换固定锚框以对固定锚位置进行微小调整。</p><figure class="mf mg mh mi gt jr gh gi paragraph-image"><div class="ab gu cl mz"><img src="../Images/a53d72a04e23a55225826fd077f318de.png" data-original-src="https://miro.medium.com/v2/format:webp/1*JDQw0RwmnIKeRABw3ZDI7Q.png"/></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk">Diagram from the faster-RCNN paper explaining RPN. The inputs to the RPN are convolutional features, extracted from (for example) a pretrained VGG network.</figcaption></figure><p id="19f2" class="pw-post-body-paragraph la lb iq lc b ld lz lf lg lh ma lj lk ll mb ln lo lp mc lr ls lt md lv lw lx ij bi translated">使用预训练的 VGG 网络从输入图像中提取 512 维的特定于位置的特征向量。<a class="ae ly" href="http://kaiminghe.com/iccv15tutorial/iccv2015_tutorial_convolutional_feature_maps_kaiminghe.pdf" rel="noopener ugc nofollow" target="_blank">每个 512-d 矢量可以直接映射回输入图像上的一个区域</a>。这些位置中每一个都与多个锚(比如 9 个锚)相关联。这个数字在上图中被称为<em class="my"> k </em>。</p><p id="c4e5" class="pw-post-body-paragraph la lb iq lc b ld lz lf lg lh ma lj lk ll mb ln lo lp mc lr ls lt md lv lw lx ij bi translated">每个<em class="my"> k </em>锚点与一个以输入图像的相应区域为中心的边界框相关联。每个都有不同的大小和长宽比(例如，正方形、高矩形、宽矩形)。RPN 能够使用该输出来预测边界框输出。</p><p id="4d12" class="pw-post-body-paragraph la lb iq lc b ld lz lf lg lh ma lj lk ll mb ln lo lp mc lr ls lt md lv lw lx ij bi translated">RLSD 的作者在<a class="ae ly" href="https://visualgenome.org/" rel="noopener ugc nofollow" target="_blank">视觉基因组图像数据集</a>上对 RPN 进行了预训练，该数据集为这个预训练步骤提供了边界框。</p><h1 id="9fc5" class="kc kd iq bd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz bi translated">感兴趣区域特征提取</h1><p id="82f1" class="pw-post-body-paragraph la lb iq lc b ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ij bi translated">一旦 RPN 检测到感兴趣区域(RoI ),一组 512 维特征向量就被传递到模型的下一部分。</p><p id="1432" class="pw-post-body-paragraph la lb iq lc b ld lz lf lg lh ma lj lk ll mb ln lo lp mc lr ls lt md lv lw lx ij bi translated">这是与 RoI 相关的一组特征向量；由于 RoI 有不同的大小，这通常是向前传递的可变数量的特征向量。</p><p id="92f2" class="pw-post-body-paragraph la lb iq lc b ld lz lf lg lh ma lj lk ll mb ln lo lp mc lr ls lt md lv lw lx ij bi translated">为了固定这些特征的大小，作者使用<a class="ae ly" href="https://en.wikipedia.org/wiki/Bilinear_interpolation#Application_in_image_processing" rel="noopener ugc nofollow" target="_blank">双线性插值</a>将这些特征映射到一组固定的特征。这是 fast-RCNN 的一个变化，它使用了一个池层来实现这一点。输出特征被固定为 512 维特征的 7×7 网格(针对每个 RoI)。</p><p id="3d8d" class="pw-post-body-paragraph la lb iq lc b ld lz lf lg lh ma lj lk ll mb ln lo lp mc lr ls lt md lv lw lx ij bi translated">然后，这个张量被展平，并通过两个完全连接的层(每个层有 4096 个单位)发送。输出是该区域的提取特征的 4096 维编码。</p><h1 id="2e5b" class="kc kd iq bd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz bi translated">LSTM 加工</h1><p id="713d" class="pw-post-body-paragraph la lb iq lc b ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ij bi translated">给定 RoI 的 4096-d 特征编码作为输入给定<a class="ae ly" href="https://medium.com/mlreview/understanding-lstm-and-its-diagrams-37e2f46f1714" rel="noopener"> LSTM 模型</a>。</p><figure class="mf mg mh mi gt jr gh gi paragraph-image"><div class="gh gi na"><img src="../Images/cd13f35dba36992907ae343abe672543.png" data-original-src="https://miro.medium.com/v2/resize:fit:1280/format:webp/1*O4rzgXd4A0SKyBbjbDrd3w.png"/></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk">Diagram of an LSTM model.</figcaption></figure><p id="6649" class="pw-post-body-paragraph la lb iq lc b ld lz lf lg lh ma lj lk ll mb ln lo lp mc lr ls lt md lv lw lx ij bi translated">在每个时间步长，LSTM 模型将前一步的内部输出(上图中的<em class="my"> h </em>和<em class="my"> x </em>)作为输入，这是一组与当前时间步长<em class="my"> t </em>相关的新特征。在<em class="my"> t </em> =0 时，x 是 4096-d 区域特征编码，h 是零向量。时间步长<em class="my"> t </em>的输出是一个 N 维向量，其中 N 是我们拥有的标签数量。由于我们没有输入序列，<strong class="lc ir">时间步长<em class="my"> t </em> +1 的<em class="my"> x </em>输入就是时间步长<em class="my"> t </em> </strong> <em class="my">的预测输出。</em></p><p id="0e16" class="pw-post-body-paragraph la lb iq lc b ld lz lf lg lh ma lj lk ll mb ln lo lp mc lr ls lt md lv lw lx ij bi translated">LSTM 想停就停。标签上有一个特殊的“结束”标签。一旦 LSTM 输出“结束”编码，它就停止预测。</p><p id="f9eb" class="pw-post-body-paragraph la lb iq lc b ld lz lf lg lh ma lj lk ll mb ln lo lp mc lr ls lt md lv lw lx ij bi translated">该模型针对每个 RoI 运行。</p><h1 id="5553" class="kc kd iq bd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz bi translated">获得预测</h1><p id="1b74" class="pw-post-body-paragraph la lb iq lc b ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ij bi translated">LSTM 模型的输出是一个三阶张量。如果有 M 个 ROI、T 个时间步长和 N 个标签，则总输出为 M×T×N 个张量。</p><p id="e055" class="pw-post-body-paragraph la lb iq lc b ld lz lf lg lh ma lj lk ll mb ln lo lp mc lr ls lt md lv lw lx ij bi translated">为了将其映射到 N 维标签空间，<strong class="lc ir">任何给定标签的最大概率</strong>(跨所有时间步长和区域)<strong class="lc ir">被作为最终输出</strong>。根据定义，这是一个<strong class="lc ir">最大池</strong>操作。</p><figure class="mf mg mh mi gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi nb"><img src="../Images/303840a2445188dc26d9e1b4a874ba42.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*oSfBmhXWB2PHqTxCB9zkIA.png"/></div></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk">(<a class="ae ly" href="https://arxiv.org/pdf/1901.00461.pdf" rel="noopener ugc nofollow" target="_blank">source</a>) Global max-pooling is used to get the final predictions. Instead of features, we have predictions; H and W correspond to timesteps and regions.</figcaption></figure><p id="6edb" class="pw-post-body-paragraph la lb iq lc b ld lz lf lg lh ma lj lk ll mb ln lo lp mc lr ls lt md lv lw lx ij bi translated">这里的输出是一个 N 维的预测向量。我们现在可以通过整个模型计算多标签交叉熵损失和反向传播，因为梯度可以通过每个操作反向传递(包括双线性插值操作，如<a class="ae ly" href="https://arxiv.org/pdf/1511.07571.pdf" rel="noopener ugc nofollow" target="_blank"> Karpathy 等人</a>所指出的)</p><h1 id="c2b8" class="kc kd iq bd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz bi translated"><strong class="ak">慷慨的前期培训</strong></h1><p id="804b" class="pw-post-body-paragraph la lb iq lc b ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ij bi translated">作者使用许多预训练步骤来获得收敛的模型。RPN 在带有边界框的数据集上进行了预训练，LSTM 在目标数据集上进行了预训练(跳过 RoI 步骤并向前传递所有要素)。原始卷积特征是从 ImageNet 预训练的 VGG 模型中提取的。</p><p id="b1cb" class="pw-post-body-paragraph la lb iq lc b ld lz lf lg lh ma lj lk ll mb ln lo lp mc lr ls lt md lv lw lx ij bi translated">作者“发现这个初始化过程对模型快速收敛很重要[原文如此]。”</p><p id="1799" class="pw-post-body-paragraph la lb iq lc b ld lz lf lg lh ma lj lk ll mb ln lo lp mc lr ls lt md lv lw lx ij bi translated">由于梯度不能通知来自图像级标签的 RPN 输出，我认为这一步不仅仅是“重要的”，而是模型工作所必需的。</p><h1 id="9e7b" class="kc kd iq bd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz bi translated">结果</h1><figure class="mf mg mh mi gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi nc"><img src="../Images/c4645a98e5fac736b3723088a311d759.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ACKelXOwA3_U1FHx2KoUIg.png"/></div></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk">From the paper. mAP on the PASCAL VOC 2007 dataset, without using bounding boxes in training, got an 87.3 mAP, an apparent 2.1 improvement over the previous SOTA. (RLSD + ft-RPN row should be ignored, as it uses the provided bounding boxes in training).</figcaption></figure><p id="2fd4" class="pw-post-body-paragraph la lb iq lc b ld lz lf lg lh ma lj lk ll mb ln lo lp mc lr ls lt md lv lw lx ij bi translated">这项工作的结果是对以前 SOTA 关于 PASCAL VOC 的结果的明显改进。他们的模型的另一个版本，称为 RLSD + ft-RPN，在训练期间使用数据集中提供的边界框来训练 RPN，所以它不应该与该表上的其他结果进行比较。(看看 RLSD 街吧。)</p><h1 id="c376" class="kc kd iq bd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz bi translated">这样实用吗？</h1><figure class="mf mg mh mi gt jr gh gi paragraph-image"><div class="ab gu cl mz"><img src="../Images/790918d7bc0717d4870447ff5df4b5a5.png" data-original-src="https://miro.medium.com/v2/format:webp/1*2dHUhrfkLjlVKEtWXuZiiA.png"/></div></figure><p id="d1fe" class="pw-post-body-paragraph la lb iq lc b ld lz lf lg lh ma lj lk ll mb ln lo lp mc lr ls lt md lv lw lx ij bi translated">值得一问的是，这种模式对于部署是否足够实用。经过大量的预训练后，由于 LSTM 步骤，推理时间可能比大多数网络更长(尽管这可以在所有 RoI 输出中很好地并行化。)</p><p id="24fd" class="pw-post-body-paragraph la lb iq lc b ld lz lf lg lh ma lj lk ll mb ln lo lp mc lr ls lt md lv lw lx ij bi translated">作者没有报道推断过程中的计算时间。</p><p id="81b8" class="pw-post-body-paragraph la lb iq lc b ld lz lf lg lh ma lj lk ll mb ln lo lp mc lr ls lt md lv lw lx ij bi translated">此外，由于对预培训的依赖，我预计 RPN 在非常不同的领域不会很好地工作；这可能会对性能造成另一个限制，<strong class="lc ir">需要来自与目标数据集相似的域的数据集，并且具有可用的边界框注释</strong>来完成预训练步骤。这样的数据通常很难获得。</p><p id="006e" class="pw-post-body-paragraph la lb iq lc b ld lz lf lg lh ma lj lk ll mb ln lo lp mc lr ls lt md lv lw lx ij bi translated">如果作者提供一些代码(或者一些预先训练好的网络)，我会对这个项目更加乐观<strong class="lc ir">。既然得不到，我就持怀疑态度。</strong></p><h1 id="de13" class="kc kd iq bd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz bi translated">优势</h1><p id="89d7" class="pw-post-body-paragraph la lb iq lc b ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ij bi translated">如果一切顺利，并且你能够预训练一个在你的领域中有效的 RPN，那么从端到端训练 RLSD 模型提供了一些优势。例如，<strong class="lc ir">特定的边界框可以与预测标签</strong>相关联。</p><p id="0502" class="pw-post-body-paragraph la lb iq lc b ld lz lf lg lh ma lj lk ll mb ln lo lp mc lr ls lt md lv lw lx ij bi translated">在多标签分类问题上使用该模型也可能获得最佳结果。只要确保你能完成所有要求的训练前步骤。</p></div></div>    
</body>
</html>