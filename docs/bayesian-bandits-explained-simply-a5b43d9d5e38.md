# 贝氏盗匪简单地解释道

> 原文：<https://towardsdatascience.com/bayesian-bandits-explained-simply-a5b43d9d5e38?source=collection_archive---------6----------------------->

![](img/61e59af269a392053fba260d7f9edaae.png)

Photo by [Alice Wu](https://unsplash.com/@alicewu?utm_source=medium&utm_medium=referral) on [Unsplash](https://unsplash.com?utm_source=medium&utm_medium=referral)

## 探索还是剥削？

勘探和开发在任何业务中都起着关键作用。

任何好的企业都会试图“探索”各种可以盈利的机会。

同时，任何优秀的企业也会努力专注于已经发现的特定机会，并努力“利用”它。

让我用一个思维实验来进一步解释这个问题。

***思想实验:*** 假设我们有`infinite`老虎机。每个吃角子老虎机都有一些获胜概率。但是我们不知道这些概率值。

你必须一个接一个地操作这些老虎机。你如何想出一个策略，在最短的时间内从这些吃角子老虎机中获得最大的收益。

![](img/247da393fe67cdfb4e54b35a8f092d7d.png)

你最有可能从试用一些机器开始。

你会坚持使用一台有一定可能性的机器(开发)还是继续寻找更好的机器(探索)？

这是勘探开发的权衡。

问题是我们如何平衡这种权衡，从而获得最大利润？

**答案是贝氏盗匪。**

# 为什么？业务使用案例:

有很多地方可以进行这样的思维实验。

*   AB 测试:你有各种各样的资产可以在网站上展示。每个资产都有特定的成功概率(被用户点击)。
*   广告点击:你有各种各样的广告可以展示给用户。每个广告都有特定的点击率
*   金融:选择哪只股票回报最高。
*   作为人类，我们面临着完全相同的问题——探索或开发，我们大多处理得相当出色。我们是应该去找一份新工作，还是应该做我们知道会赚钱的事情来赚钱？

在这篇文章中，我们将集中讨论 AB 测试，但是这个实验可以解决上面的任何问题。

# 问题陈述:

![](img/d82353d74466f4976dc9154fea3e6f27.png)

我们的问题是，我们有不同的资产，我们想在我们的网站上展示，但我们真的不知道该展示哪一个。

一个资产是蓝色(B)，另一个是红色(R)，第三个是绿色(G)。

我们的 UX 团队说他们喜欢蓝色的。但是你喜欢绿色的。

在我们的网站上显示哪一个？

# 贝叶斯无处不在:

在我们深入研究解决这个问题的算法之前，让我们重温一下贝叶斯定理。

![](img/4bfc041b7d7d90699cddce6217800be0.png)

记住贝叶斯定理说后验概率*先验

# 贝塔分布

我们只需要一个小小的尝试来理解贝塔分布。**β分布**是定义在区间[0，1]上的连续概率分布，该区间由两个正的形状参数参数化，用 *α* 和 *β表示。*贝塔分布的 PDF 为:

![](img/1a80b1ece5c7373ae2e713c5166a2c41.png)

并且，对于 *α* 和 *β* 的不同值，pdf 看起来如下:

![](img/9f54551f095b8e407ecf8028052386ba.png)

如果您还不了解 beta 分布，请不要担心。

***请记住，贝塔分布经常用于模拟概率的行为，因为它位于范围[0，1]内。***

# 贝叶斯强盗

所以在了解了上述概念之后，让我们回到我们目前的问题上来。

我们有三项资产。

![](img/24963d54897ac08cf774e7f33f55f6d0.png)

为了解决这个问题，让我们假设我们也知道这些资产的点击概率。

蓝色(B)获胜概率是 0.3，红色(R)是 0.8，绿色(G)是 0.4。请注意，在现实生活中，我们不会知道这些。

我们的算法会隐藏这些概率，我们会看到我们的算法如何收敛到这些真实的概率。

***那么，我们对这些资产的概率有什么先验(信念)？***

因为我们没有观察到任何数据，所以我们不能对我们的三个资产中的任何一个有先验的信念。

我们需要对我们的先验概率建模，我们将使用 beta 分布来完成。 参见上述α = 1 和β=1 的β分布曲线。

它实际上只是在范围[0，1]上的均匀分布。这就是我们想要的资产的先验概率。我们还没有任何信息，所以我们从概率值的均匀概率分布开始。

***所以我们可以用贝塔分布来表示我们每个资产的先验概率。***

## ***策略:***

1.  我们将从资产的 3 个分布中随机抽取一个变量。
2.  我们将找出哪个随机变量是最大的，并将显示给出最大随机变量的资产。
3.  我们将了解该资产是否被点击。
4.  我们将使用步骤 3 中的信息更新资产的先验信息。
5.  重复一遍。

## 更新以前的:

我们用贝塔分布来模拟概率的原因是因为它有很好的数学特性。

![](img/66f5a535d9bc7f5a535095061040623c.png)

如果先验是 f(α，β)，那么后验分布也是β，由 f(α+#成功，β+#失败)给出

其中#success 是点击次数，而#failures 是浏览量减去点击次数。

# 让我们编码

![](img/56822ae71b5dad1321830edce4e6f00a.png)

现在，我们已经具备了编写代码所需的所有知识。我将使用非常简单和标准的 Python 功能来做这件事，但是也有像 [pyMC3](https://amzn.to/2y0Tm42) 这样的工具来处理这类问题。

让我们一步一步地解决这个问题。

我们有三种不同概率的资产。

```
real_probs_dict = {'R':0.8,'G':0.4,'B':0.3}
assets = ['R','G','B']
```

我们将努力看看我们上面给出的策略是否奏效。

让我们多次运行这个策略并收集数据。

这是我们跑步的结果。你可以在 [kaggle](https://www.kaggle.com/mlwhiz/bayesian-bandits?scriptVersionId=17478592) 看到我用来可视化后验分布的函数。正如您在下面看到的，在 20 次运行结束时，我们几乎已经收敛到最佳资产。概率也是粗略估计出来的。

***在开始时，我们有一个制服在先。*** 当我们运行时，我们看到“红色”资产的后验分布向更高的平均值收敛，因此选择的概率更高。但请记住，这并不意味着绿色资产和蓝色资产永远不会被选中。

![](img/a70ca55b812859b033e87e64ab7c2b77.png)

让我们看看在我们做的 50 次运行中，每种资产被选择了多少次。

```
Pick 1 : G ,Pick 2 : R ,Pick 3 : R ,Pick 4 : B ,Pick 5 : R ,Pick 6 : R ,Pick 7 : R ,Pick 8 : R ,Pick 9 : R ,Pick 10 : R ,Pick 11 : R ,Pick 12 : R ,Pick 13 : R ,Pick 14 : R ,Pick 15 : R ,Pick 16 : R ,Pick 17 : R ,Pick 18 : R ,Pick 19 : R ,Pick 20 : R ,Pick 21 : R ,Pick 22 : G ,Pick 23 : R ,Pick 24 : R ,Pick 25 : G ,Pick 26 : G ,Pick 27 : R ,Pick 28 : R ,Pick 29 : R ,Pick 30 : R ,Pick 31 : R ,Pick 32 : R ,Pick 33 : R ,Pick 34 : R ,Pick 35 : R ,Pick 36 : R ,Pick 37 : R ,Pick 38 : R ,Pick 39 : G ,Pick 40 : B ,Pick 41 : R ,Pick 42 : R ,Pick 43 : R ,Pick 44 : R ,Pick 45 : B ,Pick 46 : R ,Pick 47 : R ,Pick 48 : R ,Pick 49 : R ,Pick 50 : R
```

我们可以看到，虽然我们大多选择 R，但在后面的运行中，我们有时还是会选择 B(选择 45)和 G(选择 44)。总的来说，我们可以看到，在最初的几轮中，我们专注于勘探，而在后面的几轮中，我们专注于开发。

![](img/e8d1e902b97b7edea70bc26bbf018235.png)

# 结束注释:

我们看到了使用[贝叶斯](https://amzn.to/2y0Tm42)方法解决这个问题如何帮助我们收敛到一个好的解决方案，同时最大化我们的利润，并且不丢弃任何资产。

这种方法的额外优点是，它是自我学习的，并且如果点击红色资产的概率降低而蓝色资产增加，它可以自我校正。例如，当用户偏好改变时，这种情况可能发生。

全部代码贴在 [Kaggle 内核](https://www.kaggle.com/mlwhiz/bayesian-bandits?scriptVersionId=17478592)里。

另外，如果你想了解更多关于贝叶斯统计的知识，你可以关注的最新和最好的资源之一是用于机器学习的 [**贝叶斯方法**](https://coursera.pxf.io/3PqL3r) **。**

我以后也会写更多这样的帖子。在 [**媒体**](https://medium.com/@rahul_agarwal?source=post_page---------------------------) 关注我或者订阅我的 [**博客**](http://eepurl.com/dbQnuX?source=post_page---------------------------) 了解他们。一如既往，我欢迎反馈和建设性的批评，可以通过 Twitter [@mlwhiz](https://twitter.com/MLWhiz?source=post_page---------------------------) 联系。