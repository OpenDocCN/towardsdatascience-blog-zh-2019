<html>
<head>
<title>Automatically finding the best Neural Network for your GAN</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">自动寻找最适合你的神经网络</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/automatically-finding-the-best-neural-network-for-your-gan-c0b97a5949f2?source=collection_archive---------5-----------------------#2019-09-02">https://towardsdatascience.com/automatically-finding-the-best-neural-network-for-your-gan-c0b97a5949f2?source=collection_archive---------5-----------------------#2019-09-02</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="c6af" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">甘斯的汽车！</h2></div><blockquote class="ki kj kk"><p id="7132" class="kl km kn ko b kp kq ju kr ks kt jx ku kv kw kx ky kz la lb lc ld le lf lg lh im bi translated">想获得灵感？快来加入我的<a class="ae li" href="https://www.superquotes.co/?utm_source=mediumtech&amp;utm_medium=web&amp;utm_campaign=sharing" rel="noopener ugc nofollow" target="_blank"> <strong class="ko iu">超级行情快讯</strong> </a>。😎</p></blockquote><p id="b494" class="pw-post-body-paragraph kl km it ko b kp kq ju kr ks kt jx ku lj kw kx ky lk la lb lc ll le lf lg lh im bi translated"><a class="ae li" href="https://en.wikipedia.org/wiki/Generative_adversarial_network" rel="noopener ugc nofollow" target="_blank">生成对抗网络</a> (GANs)自从在 2014NIPS<a class="ae li" href="https://papers.nips.cc/paper/5423-generative-adversarial-nets.pdf" rel="noopener ugc nofollow" target="_blank">上首次发明并发表以来，一直是深度学习领域的热门话题。</a></p><p id="3efb" class="pw-post-body-paragraph kl km it ko b kp kq ju kr ks kt jx ku lj kw kx ky lk la lb lc ll le lf lg lh im bi translated">这一切都有一个很好的理由:GANs 只需要一点点指导就可以创造新的内容。正是这种创造力让他们如此强大。事实证明，GANs 能够将这种创造力应用于多种多样且有用的应用中:</p><ul class=""><li id="eb75" class="lm ln it ko b kp kq ks kt lj lo lk lp ll lq lh lr ls lt lu bi translated"><a class="ae li" href="https://www.forbes.com/sites/forbestechcouncil/2019/05/21/gans-and-deepfakes-could-revolutionize-the-fashion-industry/#4152f4ac3d17" rel="noopener ugc nofollow" target="_blank">生成穿着某种服装的人的图像</a>。非常适合虚拟观看顾客在网上看到的服装会是什么样子。</li><li id="070e" class="lm ln it ko b kp lv ks lw lj lx lk ly ll lz lh lr ls lt lu bi translated">创建<a class="ae li" href="https://github.com/junyanz/CycleGAN" rel="noopener ugc nofollow" target="_blank">艺术品</a></li><li id="28b8" class="lm ln it ko b kp lv ks lw lj lx lk ly ll lz lh lr ls lt lu bi translated">电影和视频游戏<a class="ae li" href="https://www.pcgamesn.com/max-payne/ai-enhanced-hd-remaster" rel="noopener ugc nofollow" target="_blank">的灌制和质量改进</a></li><li id="63cf" class="lm ln it ko b kp lv ks lw lj lx lk ly ll lz lh lr ls lt lu bi translated">加强对非常复杂的深层物理课题的研究，如<a class="ae li" href="https://phys.org/news/2019-05-cosmogan-neural-network-dark.html" rel="noopener ugc nofollow" target="_blank">暗物质</a></li></ul><p id="2167" class="pw-post-body-paragraph kl km it ko b kp kq ju kr ks kt jx ku lj kw kx ky lk la lb lc ll le lf lg lh im bi translated">仅举几个例子。</p><p id="2623" class="pw-post-body-paragraph kl km it ko b kp kq ju kr ks kt jx ku lj kw kx ky lk la lb lc ll le lf lg lh im bi translated">有鉴于此，大量资源被投入到 GAN 研究中，以弄清楚它们是如何工作的，以及如何设计绝对最佳的 GAN 网络。最后，经过几年的成熟，<a class="ae li" rel="noopener" target="_blank" href="/everything-you-need-to-know-about-automl-and-neural-architecture-search-8db1863682bf"> AutoML 和神经架构搜索(NAS) </a>已经进入了 GANs 的领域。</p><p id="8860" class="pw-post-body-paragraph kl km it ko b kp kq ju kr ks kt jx ku lj kw kx ky lk la lb lc ll le lf lg lh im bi translated">本文接下来分为两个部分:第一部分解释了 GANs 是如何工作的，以及它们目前是如何手工设计的。第二个是全新深度学习研究的展示——<a class="ae li" href="https://arxiv.org/pdf/1908.03835v1.pdf" rel="noopener ugc nofollow" target="_blank">AutoGAN</a>，它将神经架构搜索应用于<strong class="ko iu">自动</strong>找到最佳的 GAN 架构。</p><h1 id="ff55" class="ma mb it bd mc md me mf mg mh mi mj mk jz ml ka mm kc mn kd mo kf mp kg mq mr bi translated">gan 是如何工作的</h1><p id="4d0a" class="pw-post-body-paragraph kl km it ko b kp ms ju kr ks mt jx ku lj mu kx ky lk mv lb lc ll mw lf lg lh im bi translated">生成对抗网络(GANs)被归入“生成”模型组。这意味着它们能够生成全新的“有效”数据。所谓有效数据，我们的意思是网络的输出应该是我们认为目标可以接受的。</p><p id="d048" class="pw-post-body-paragraph kl km it ko b kp kq ju kr ks kt jx ku lj kw kx ky lk la lb lc ll le lf lg lh im bi translated">为了说明，考虑一个例子，其中我们希望生成一些新图像来训练图像分类网络。当然，对于这样的应用，我们希望我们的训练数据尽可能真实，也许在风格上与其他图像分类训练数据集非常相似。</p><p id="4f19" class="pw-post-body-paragraph kl km it ko b kp kq ju kr ks kt jx ku lj kw kx ky lk la lb lc ll le lf lg lh im bi translated">下图显示了 GAN 生成的一组图像的示例。它们看起来很真实！如果我们没有被告知它们是计算机生成的，我们可能会相信这些是人类收集的！</p><figure class="my mz na nb gt nc gh gi paragraph-image"><div role="button" tabindex="0" class="nd ne di nf bf ng"><div class="gh gi mx"><img src="../Images/aad51fad30bf3257dcfdce9a6c9a78b0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*nULK3CnaP-FgCBroxRSKLg.png"/></div></div><figcaption class="nj nk gj gh gi nl nm bd b be z dk">An example output of Progressive GANs. <a class="ae li" href="https://arxiv.org/pdf/1710.10196.pdf" rel="noopener ugc nofollow" target="_blank">Source</a></figcaption></figure><p id="1013" class="pw-post-body-paragraph kl km it ko b kp kq ju kr ks kt jx ku lj kw kx ky lk la lb lc ll le lf lg lh im bi translated">为此，gan 由两个独立的、<em class="kn">相对的</em>网络组成:发生器和鉴别器。当仅给定噪声图像阵列作为输入时，生成器被训练来创建看起来逼真的图像。鉴别器被训练来分类图像是否是真实的。</p><p id="90dd" class="pw-post-body-paragraph kl km it ko b kp kq ju kr ks kt jx ku lj kw kx ky lk la lb lc ll le lf lg lh im bi translated">GANs 的真正力量来自他们所遵循的对抗训练风格。基于鉴别器的损耗学习发电机网络的权重。因此，生成器被推动以这样一种方式训练，即对于它生成的图像，很难辨别它们是否真实。在这些图像看起来越来越真实的同时，鉴别器也越来越好地分辨出哪些图像是真实的，不管肉眼看起来有多相似。</p><p id="93d0" class="pw-post-body-paragraph kl km it ko b kp kq ju kr ks kt jx ku lj kw kx ky lk la lb lc ll le lf lg lh im bi translated">因此，GANs 建立了一种反馈回路，发电机帮助训练鉴别器，鉴别器帮助训练发电机。他们一起变得更好。下图有助于说明这一点。</p><figure class="my mz na nb gt nc gh gi paragraph-image"><div class="gh gi nn"><img src="../Images/a1b3cbc92a94f2edd4e40b4d3dc35e49.png" data-original-src="https://miro.medium.com/v2/resize:fit:1312/format:webp/1*TIlDBix6_B4dk1DxfgkJHg.png"/></div><figcaption class="nj nk gj gh gi nl nm bd b be z dk">An illustration of the structure of a Generative Adversarial Network</figcaption></figure><p id="1d31" class="pw-post-body-paragraph kl km it ko b kp kq ju kr ks kt jx ku lj kw kx ky lk la lb lc ll le lf lg lh im bi translated">请注意，生成器只是一个以图像为输出的 CNN，而鉴别器只是一个以分类概率为输出的 CNN 分类网络；很简单。由于这种简单性，大多数 GAN 架构只是其他先进深度网络的副本。生成器可能采取类似于修改的 U-Net 的形式，而鉴别器通常看起来像 ResNet、DenseNet 或类似的体系结构。</p><p id="e40a" class="pw-post-body-paragraph kl km it ko b kp kq ju kr ks kt jx ku lj kw kx ky lk la lb lc ll le lf lg lh im bi translated">好的一面是，这可能会简化部分问题。研究科学家可以简单地借用以前经过验证的研究中的网络设计，并简单地专注于 GANs 的算法设计和训练机制。</p><p id="2886" class="pw-post-body-paragraph kl km it ko b kp kq ju kr ks kt jx ku lj kw kx ky lk la lb lc ll le lf lg lh im bi translated">另一方面，这可能有点限制。如果当前的网络设计不是最适合 GANs 的，该怎么办？它们本身工作得足够好，但也许改进网络结构可以进一步提高专为它们设计的 GAN 性能。</p><h1 id="fced" class="ma mb it bd mc md me mf mg mh mi mj mk jz ml ka mm kc mn kd mo kf mp kg mq mr bi translated">使用 AutoGAN 寻找最佳 GAN</h1><p id="b4dc" class="pw-post-body-paragraph kl km it ko b kp ms ju kr ks mt jx ku lj mu kx ky lk mv lb lc ll mw lf lg lh im bi translated"><a class="ae li" rel="noopener" target="_blank" href="/everything-you-need-to-know-about-automl-and-neural-architecture-search-8db1863682bf">神经架构搜索(NAS) </a>一直是另一个热门的深度学习话题。NAS 是<em class="kn">搜索</em>寻找最佳<em class="kn">神经网络架构</em>的算法。</p><p id="091b" class="pw-post-body-paragraph kl km it ko b kp kq ju kr ks kt jx ku lj kw kx ky lk la lb lc ll le lf lg lh im bi translated">大多数 NAS 算法以如下方式工作。</p><ol class=""><li id="da4f" class="lm ln it ko b kp kq ks kt lj lo lk lp ll lq lh no ls lt lu bi translated">首先定义一组可用于我们网络的“构建模块”。</li><li id="fbf2" class="lm ln it ko b kp lv ks lw lj lx lk ly ll lz lh no ls lt lu bi translated">然后使用控制器递归神经网络(RNN)对这些构建块进行采样，将它们放在一起以创建某种端到端的架构。</li><li id="bd3d" class="lm ln it ko b kp lv ks lw lj lx lk ly ll lz lh no ls lt lu bi translated">然后，在特定数据集上训练和评估这个新建立的网络。</li><li id="3d6e" class="lm ln it ko b kp lv ks lw lj lx lk ly ll lz lh no ls lt lu bi translated">基于评估，RNN 选择的构建模块被调整，即 RNN 将选择新的一组，保留有助于准确性的模块和配置，并替换或移除没有帮助的模块和配置。</li><li id="7715" class="lm ln it ko b kp lv ks lw lj lx lk ly ll lz lh no ls lt lu bi translated">步骤 3 到 4 重复多次，直到找到最佳架构。</li></ol><p id="de3a" class="pw-post-body-paragraph kl km it ko b kp kq ju kr ks kt jx ku lj kw kx ky lk la lb lc ll le lf lg lh im bi translated">这种风格的 NAS 已经成功应用于<a class="ae li" href="https://arxiv.org/pdf/1707.07012.pdf" rel="noopener ugc nofollow" target="_blank">图像分类</a>和<a class="ae li" href="https://arxiv.org/pdf/1707.07012.pdf" rel="noopener ugc nofollow" target="_blank">语义分割</a>。</p><figure class="my mz na nb gt nc gh gi paragraph-image"><div class="gh gi np"><img src="../Images/13e2217fc807bb68dad38741bd3e14c1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1128/format:webp/0*65I7iLv3-t6uWVJ-.png"/></div><figcaption class="nj nk gj gh gi nl nm bd b be z dk">The NAS algorithm. Source from the <a class="ae li" href="https://arxiv.org/pdf/1707.07012.pdf" rel="noopener ugc nofollow" target="_blank">research paper</a></figcaption></figure><p id="4893" class="pw-post-body-paragraph kl km it ko b kp kq ju kr ks kt jx ku lj kw kx ky lk la lb lc ll le lf lg lh im bi translated">AutoGAN 也遵循相同的学习方案，特别侧重于构建生成器网络，因为在寻找最佳分类网络(用于鉴别器)方面已经做了更多的工作。</p><p id="52e7" class="pw-post-body-paragraph kl km it ko b kp kq ju kr ks kt jx ku lj kw kx ky lk la lb lc ll le lf lg lh im bi translated">正如作者在他们的论文中指出的，训练 GANs 由于其设计本身就不稳定。精心的网络建设对整个过程的顺利进行至关重要。考虑到这一点，AutoGANs 的搜索空间比 NAS 的搜索空间要小得多。AutoGAN 的生成器搜索空间被设置为，而不是能够从许多不同类型和大小的卷积块中采样并跳过连接:</p><ul class=""><li id="52fa" class="lm ln it ko b kp kq ks kt lj lo lk lp ll lq lh lr ls lt lu bi translated">一个二进制值<em class="kn"> skip </em>，它指示当前单元格是否从前一个单元格获取一个<em class="kn">加法</em>skip 连接<em class="kn">。</em></li><li id="a7f0" class="lm ln it ko b kp lv ks lw lj lx lk ly ll lz lh lr ls lt lu bi translated">一个基本的卷积模块，决定是否包括预激活或后激活。</li><li id="e90d" class="lm ln it ko b kp lv ks lw lj lx lk ly ll lz lh lr ls lt lu bi translated">归一化类型的选择:批量归一化、实例归一化、无归一化。</li><li id="d938" class="lm ln it ko b kp lv ks lw lj lx lk ly ll lz lh lr ls lt lu bi translated">要使用的上采样类型:双线性上采样、最近邻上采样或步长 2 去卷积。</li><li id="d779" class="lm ln it ko b kp lv ks lw lj lx lk ly ll lz lh lr ls lt lu bi translated">是否使用<em class="kn">单元格内</em> <em class="kn">加法</em> <em class="kn">跳过连接</em></li></ul><figure class="my mz na nb gt nc gh gi paragraph-image"><div role="button" tabindex="0" class="nd ne di nf bf ng"><div class="gh gi nq"><img src="../Images/a884ff66c84143de078e772b9b8c3790.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*YBnqnLFsRWXpROHr.png"/></div></div><figcaption class="nj nk gj gh gi nl nm bd b be z dk">The search space of AutoGAN’s Generator network. Source from the original <a class="ae li" href="https://arxiv.org/pdf/1908.03835v1.pdf" rel="noopener ugc nofollow" target="_blank">research paper</a></figcaption></figure><p id="64bf" class="pw-post-body-paragraph kl km it ko b kp kq ju kr ks kt jx ku lj kw kx ky lk la lb lc ll le lf lg lh im bi translated">有了这个更受控制的搜索空间，应用 NAS 来寻找最佳发电机架构就简单得多，也更稳定，因为 NAS 的搜索范围更广，也更简单。</p><p id="4aa0" class="pw-post-body-paragraph kl km it ko b kp kq ju kr ks kt jx ku lj kw kx ky lk la lb lc ll le lf lg lh im bi translated">另一项使培训更加有效的技术是使用多层次架构搜索(MLAS)，而不是常规的多层次架构搜索(SLAS)。对于常规的 SLAS，一个 RNN 控制器将用于一次构建整个 NAS 网络。但是在 MLAS，网络是逐步建立起来的。</p><p id="b4f0" class="pw-post-body-paragraph kl km it ko b kp kq ju kr ks kt jx ku lj kw kx ky lk la lb lc ll le lf lg lh im bi translated">MLAS 以自下而上的方式执行搜索，对每个单元分别执行架构搜索。因此，每个细胞将使用其<em class="kn">自己的个人</em> RNN 控制器进行搜索。从某种意义上说，这也简化了搜索，因为 NAS 一次只关注网络的一个特定部分，而不是非常复杂的整体。</p><figure class="my mz na nb gt nc gh gi paragraph-image"><div role="button" tabindex="0" class="nd ne di nf bf ng"><div class="gh gi nr"><img src="../Images/68c7b85809c28f4bf5f9b95f4e02a9d0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*HSxBMzUJa6y628ccmS0YoQ.png"/></div></div><figcaption class="nj nk gj gh gi nl nm bd b be z dk">AutoGAN’s RNN controller. Source from the <a class="ae li" href="https://arxiv.org/pdf/1908.03835v1.pdf" rel="noopener ugc nofollow" target="_blank">research paper</a></figcaption></figure><p id="0971" class="pw-post-body-paragraph kl km it ko b kp kq ju kr ks kt jx ku lj kw kx ky lk la lb lc ll le lf lg lh im bi translated">凭借其聪明的新训练设置和精细、集中的细胞搜索空间，AutoGAN 能够实现最先进的结果。具体来说，它为基于人类判断生成<a class="ae li" href="https://github.com/mseitzer/pytorch-fid" rel="noopener ugc nofollow" target="_blank">高视觉质量的新图像</a>设置了新的标准。</p><p id="6af2" class="pw-post-body-paragraph kl km it ko b kp kq ju kr ks kt jx ku lj kw kx ky lk la lb lc ll le lf lg lh im bi translated">AutoML 正在慢慢进入深度学习和人工智能的许多领域。毫无疑问，这将是未来几年人工智能研究的一个重点。人工智能创造人工智能。</p></div><div class="ab cl ns nt hx nu" role="separator"><span class="nv bw bk nw nx ny"/><span class="nv bw bk nw nx ny"/><span class="nv bw bk nw nx"/></div><div class="im in io ip iq"><h1 id="76b2" class="ma mb it bd mc md nz mf mg mh oa mj mk jz ob ka mm kc oc kd mo kf od kg mq mr bi translated">喜欢学习？</h1><p id="dfa7" class="pw-post-body-paragraph kl km it ko b kp ms ju kr ks mt jx ku lj mu kx ky lk mv lb lc ll mw lf lg lh im bi translated">在推特<a class="ae li" href="https://twitter.com/GeorgeSeif94" rel="noopener ugc nofollow" target="_blank">上关注我，我会在这里发布所有最新最棒的人工智能、技术和科学！也请在 LinkedIn</a><a class="ae li" href="https://www.linkedin.com/in/georgeseif/" rel="noopener ugc nofollow" target="_blank">上与我联系！</a></p></div></div>    
</body>
</html>