<html>
<head>
<title>Unraveling Spline Regression in R</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">R 中的解开样条回归</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/unraveling-spline-regression-in-r-937626bc3d96?source=collection_archive---------6-----------------------#2019-08-15">https://towardsdatascience.com/unraveling-spline-regression-in-r-937626bc3d96?source=collection_archive---------6-----------------------#2019-08-15</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><figure class="gl gn jr js jt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi jq"><img src="../Images/7c4a67ee127f068fdbb56d3ef028eb3f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*FEBg11frmvNPqG7jVxsQQA.jpeg"/></div></div><figcaption class="kb kc gj gh gi kd ke bd b be z dk">(image by author)</figcaption></figure><p id="dcba" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">当我们谈论回归时，首先想到的是线性或逻辑回归，以及遥远的多项式回归。线性回归和逻辑回归是两种最流行的回归方法。然而，有许多不同类型的回归方法可以证明在不同的情况下是有用的。今天我们将看看使用阶梯函数的样条回归。</p><p id="2371" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">样条回归是一种非参数回归技术。这种回归技术将数据集分成间隔或称为结的点的箱，每个箱有其单独的拟合。让我们看看在 r 中使用阶跃函数的样条回归的一个简单实现。</p><p id="dfe4" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">可视化数据集:</p><pre class="ld le lf lg gt lh li lj lk aw ll bi"><span id="8c1b" class="lm ln it li b gy lo lp l lq lr">Quantity &lt;- c(25,39,45,57,70,85,89,100,110,124,137,150,177)<br/>Sales &lt;- c(1000,1250,2600,3000,3500,4500,5000,4700,4405,4000,3730,3400,3300)<br/>data &lt;- data.frame(Quantity,Sales)<br/>data</span></pre><figure class="ld le lf lg gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi ls"><img src="../Images/92551aab5d3c14f34fae762223f96c68.png" data-original-src="https://miro.medium.com/v2/resize:fit:1168/format:webp/1*M_lTh9Fubbv5Dcndl8C7TA.png"/></div></div><figcaption class="kb kc gj gh gi kd ke bd b be z dk">Quantity Vs Sales Data</figcaption></figure><pre class="ld le lf lg gt lh li lj lk aw ll bi"><span id="44e2" class="lm ln it li b gy lo lp l lq lr"><strong class="li iu">library</strong>(plotly)</span><span id="dba9" class="lm ln it li b gy lt lp l lq lr">plot_ly(data,x=~Quantity,<br/>        y=~Sales,<br/>        type="scatter"<br/>)</span></pre><figure class="ld le lf lg gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi lu"><img src="../Images/6a96f43ffaf83bf5ab04dba059ed2d6f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*u6zalRSeNOA_WD55HENEVg.png"/></div></div><figcaption class="kb kc gj gh gi kd ke bd b be z dk">Quantity Vs Sales Plot</figcaption></figure><p id="75d5" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">让我们拟合一个线性回归，看看它是如何工作的:</p><pre class="ld le lf lg gt lh li lj lk aw ll bi"><span id="d262" class="lm ln it li b gy lo lp l lq lr">fit &lt;- lm(Sales ~ Quantity, data=data)<br/>summary(fit)</span></pre><figure class="ld le lf lg gt ju gh gi paragraph-image"><div class="gh gi lv"><img src="../Images/5a82877921cf9e005c79960dc35bdf00.png" data-original-src="https://miro.medium.com/v2/resize:fit:1260/format:webp/1*s0PZd6j6NuFbDXbGWHLQCA.png"/></div></figure><pre class="ld le lf lg gt lh li lj lk aw ll bi"><span id="377b" class="lm ln it li b gy lo lp l lq lr">plot_ly(data,x=~Quantity,<br/>        y=~Sales,<br/>        type="scatter") %&gt;% add_lines(x =  ~Quantity, y = fitted(fit))</span></pre><figure class="ld le lf lg gt ju gh gi paragraph-image"><div class="gh gi lw"><img src="../Images/09e47b6c725ad0134f16f5243ad7311c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1344/format:webp/1*lwJtlBbOHfq_fYDp6kQfxg.png"/></div></figure><p id="a7b5" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">这里的等式采用以下形式:</p><figure class="ld le lf lg gt ju gh gi paragraph-image"><div class="gh gi lx"><img src="../Images/909c4811309f021b613411f6cb1fabdf.png" data-original-src="https://miro.medium.com/v2/resize:fit:386/format:webp/1*jHh5ywQNXywTPUGURNy-QA.png"/></div></figure><p id="7e23" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">在这种情况下:</p><figure class="ld le lf lg gt ju gh gi paragraph-image"><div class="gh gi ly"><img src="../Images/6b44fb9a11113ac984f80bf102b104d5.png" data-original-src="https://miro.medium.com/v2/resize:fit:732/format:webp/1*UFwoUqRK99Dn8L73_oSL7w.png"/></div></figure><p id="e4e5" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">我们可以看到，在这种情况下，线性回归产生了一个可怕的拟合，从上面的图和 R 平方值可以看出。</p><p id="6532" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">现在让我们将一个多项式项(此处为二次项)引入方程，并分析模型的性能。</p><pre class="ld le lf lg gt lh li lj lk aw ll bi"><span id="de0f" class="lm ln it li b gy lo lp l lq lr">fit2 &lt;- lm(Sales ~ poly(Quantity,2) + Quantity, data=data)<br/>summary(fit2)</span></pre><figure class="ld le lf lg gt ju gh gi paragraph-image"><div class="gh gi lz"><img src="../Images/a8c0848b6aaa53ff804ac7d3662d7f6e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1206/format:webp/1*z2Rd5Ythv7aLTeNQptYNYA.png"/></div></figure><pre class="ld le lf lg gt lh li lj lk aw ll bi"><span id="dbd7" class="lm ln it li b gy lo lp l lq lr">plot_ly(data,x=~Quantity,<br/>        y=~Sales,<br/>        type="scatter") %&gt;% add_lines(x =  ~Quantity, y = fitted(fit2))</span></pre><figure class="ld le lf lg gt ju gh gi paragraph-image"><div class="gh gi lw"><img src="../Images/decb9eb4dda4cf340a46c0864e7d41b1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1344/format:webp/1*-pdi1HX-h53eUx3kjJlzOA.png"/></div></figure><p id="5a17" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">这里的等式采用以下形式:</p><figure class="ld le lf lg gt ju gh gi paragraph-image"><div class="gh gi ma"><img src="../Images/64e71414f073de3deeb499854644dc81.png" data-original-src="https://miro.medium.com/v2/resize:fit:524/format:webp/1*V043WCssa3DZEQwzZyH2Ag.png"/></div></figure><p id="b077" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">在这种情况下:</p><figure class="ld le lf lg gt ju gh gi paragraph-image"><div class="gh gi mb"><img src="../Images/4ac79796cb281421f1b55afd2e7340f9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1160/format:webp/1*tI_btiDhiDVeKO24jw58lg.png"/></div></figure><p id="9b17" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">我们可以看到，这不是一个坏的适合，但也不是一个伟大的。预测的顶点与实际的顶点有些距离。多项式回归也有各种缺点，容易过度拟合。随着功能数量的增加，它会导致复杂性的增加。</p><p id="a7b2" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">样条回归可以克服多项式回归的缺点和线性模型的不足。</p><p id="24fb" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">让我们通过将数据集分成两个箱来可视化数据集。一个在数量= 89 时出现的峰值的左侧，另一个在右侧，分别如下面两幅图像所示。</p><figure class="ld le lf lg gt ju gh gi paragraph-image"><div class="gh gi mc"><img src="../Images/fd96c35c8a196c7dac0886aa1873522a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1156/format:webp/1*mQRafB5PReqk4wehlZS5wA.png"/></div></figure><figure class="ld le lf lg gt ju gh gi paragraph-image"><div class="gh gi md"><img src="../Images/3e373969da806a28cca23299b8e9f17d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1078/format:webp/1*WE1abGdqKwWWQeuq4Q5r1w.png"/></div></figure><p id="8cbe" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">现在让我们将上述两幅图像合并成一个方程，并使用阶跃函数进行分段回归或样条回归。</p><p id="7227" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">该等式将采用以下形式:</p><figure class="ld le lf lg gt ju gh gi paragraph-image"><div class="gh gi me"><img src="../Images/c798812f46ccda610b55a67ab57c20e9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1010/format:webp/1*K94spoQrQ3HpSus96sizVQ.png"/></div></figure><p id="035b" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">在这种情况下:</p><figure class="ld le lf lg gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi mf"><img src="../Images/e4173e9177848d9e0fe1ca83fe1728d6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*nmCqkXuEHycOUBAvTpQn8g.png"/></div></div></figure><p id="fa3f" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">这里的 Xbar 称为纽结值。</p><pre class="ld le lf lg gt lh li lj lk aw ll bi"><span id="4043" class="lm ln it li b gy lo lp l lq lr">data$Xbar &lt;- ifelse(data$Quantity&gt;89,1,0)<br/>data$diff &lt;- data$Quantity - 89<br/>data$X &lt;- data$diff*data$Xbar<br/><br/>data</span></pre><p id="3a8a" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">执行上述操作后，数据将如下所示:</p><figure class="ld le lf lg gt ju gh gi paragraph-image"><div class="gh gi mg"><img src="../Images/91511f35b11a7b272ca5491a1bb19f9c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1200/format:webp/1*_G541VA-BHmyCgiQe-7Sjw.png"/></div></figure><p id="ac16" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">现在让我们拟合上面看到的等式:</p><p id="8317" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">下面等式中的 X 是(x-xbar)*Xk</p><pre class="ld le lf lg gt lh li lj lk aw ll bi"><span id="6146" class="lm ln it li b gy lo lp l lq lr">reg &lt;- lm(Sales ~ Quantity + X, data = data)<br/><br/><br/>plot_ly(data,x=~Quantity,<br/>        y=~Sales,<br/>        type="scatter") %&gt;% add_lines(x =  ~Quantity, y = fitted(reg))</span></pre><figure class="ld le lf lg gt ju gh gi paragraph-image"><div class="gh gi lw"><img src="../Images/64890a2b3e0a2705071f1185db6715bb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1344/format:webp/1*i6gjJYOs3tE4rwCQs2jyXQ.png"/></div></figure><pre class="ld le lf lg gt lh li lj lk aw ll bi"><span id="3f99" class="lm ln it li b gy lo lp l lq lr">summary(reg)</span></pre><figure class="ld le lf lg gt ju gh gi paragraph-image"><div class="gh gi mh"><img src="../Images/ddba8ee5f44eaf7ed9625f53ee4818ba.png" data-original-src="https://miro.medium.com/v2/resize:fit:1186/format:webp/1*cwmercvJmXpwbXTL5X6Fbw.png"/></div></figure><p id="d325" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">从上面的图和 R 平方值可以看出，在这种情况下，样条回归产生了更好的结果。</p><p id="b5a9" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">上述结果也可以在 R:</p><pre class="ld le lf lg gt lh li lj lk aw ll bi"><span id="a12d" class="lm ln it li b gy lo lp l lq lr"><strong class="li iu">library</strong>(segmented)<br/><br/>fit_seg &lt;- segmented(fit, seg.Z = ~Quantity, psi = list(Quantity=89))<br/><br/>plot_ly(data,x=~Quantity,<br/>        y=~Sales,<br/>        type="scatter") %&gt;% add_lines(x =  ~Quantity, y = fitted(fit_seg))</span></pre><p id="b0e9" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated"><strong class="kh iu">注意:</strong>如果不提供断点值(此处数量= 89)，则使用“psi = NA”</p><figure class="ld le lf lg gt ju gh gi paragraph-image"><div class="gh gi lw"><img src="../Images/86d1d97bd7710dafcd2744cd36218ff5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1344/format:webp/1*37lPEKrgas6vn1ZclOWGIg.png"/></div></figure><pre class="ld le lf lg gt lh li lj lk aw ll bi"><span id="66d5" class="lm ln it li b gy lo lp l lq lr">summary(fit_seg)</span></pre><figure class="ld le lf lg gt ju gh gi paragraph-image"><div class="gh gi mi"><img src="../Images/c9856d059f15fa67814006e6e5f38d47.png" data-original-src="https://miro.medium.com/v2/resize:fit:1306/format:webp/1*Wm6BS2zfiI6JmLfoW63UVQ.png"/></div></figure><p id="8ba5" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">两种方法产生相同的结果。</p><p id="db1d" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">这是样条回归的一个简单例子。也可以使用多项式函数来拟合样条，称为多项式样条，因此可以在 X 的单独区域中拟合样条或具有较低次多项式的分段多项式回归，而不是在整个 X 范围内拟合高次多项式。</p><p id="66d7" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated"><strong class="kh iu">选择结的位置和数量</strong></p><p id="6a5a" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">样条可以通过添加更多的结来建模，从而增加模型的灵活性。一般来说，放置 K 个结导致 K + 1 个函数的拟合。放置结的选择可能取决于各种因素。由于回归在放置更多结的区域非常灵活，因此直观地将结放置在数据变化更多或函数变化更快的地方。看起来相对稳定的区域不需要太多的结，可以使用较少的结。</p><p id="5938" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated"><strong class="kh iu">结论:</strong></p><p id="b853" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">在本文中，我们学习了使用阶跃函数的样条回归。也可以应用其他类型的多项式函数。常见的一种是三次样条，它使用三阶多项式函数。实现样条的另一种方法是平滑样条。与多项式回归相比，样条曲线通常能提供更好的结果。在样条曲线中，可以通过增加结的数量来增加灵活性，而不增加多项式的次数。一般来说，与多项式回归相比，它们还能产生更稳定的结果。</p><p id="ae30" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">我希望这篇文章有助于理解样条和分段回归的思想，并开始使用它。</p></div><div class="ab cl mj mk hx ml" role="separator"><span class="mm bw bk mn mo mp"/><span class="mm bw bk mn mo mp"/><span class="mm bw bk mn mo"/></div><div class="im in io ip iq"><p id="00ad" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated"><strong class="kh iu">参考文献:</strong></p><p id="a25c" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">[1]Andrew Wheeler 的《回归中的样条》。【http://utdallas.edu/~Andrew.Wheeler/Splines.html T4】</p><p id="9771" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">[2]Shokoufeh Mirza ei 如何开发 R 中的分段线性回归模型。<a class="ae mq" href="https://www.youtube.com/watch?v=onfXC1qe7LI" rel="noopener ugc nofollow" target="_blank">https://www.youtube.com/watch?v=onfXC1qe7LI</a></p><p id="788f" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">[3]断点分析，分段回归。<a class="ae mq" href="https://rpubs.com/MarkusLoew/12164" rel="noopener ugc nofollow" target="_blank">https://rpubs.com/MarkusLoew/12164</a></p><p id="c903" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">[4]加雷思·詹姆斯、丹妮拉·威滕、特雷弗·哈斯蒂、罗伯特·蒂布拉尼。《统计学习导论:在 r .纽约的应用》: Springer，2013 年。</p></div></div>    
</body>
</html>