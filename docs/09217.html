<html>
<head>
<title>An Introduction to Discretization Techniques for Data Scientists</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">数据科学家的离散化技术介绍</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/an-introduction-to-discretization-in-data-science-55ef8c9775a2?source=collection_archive---------5-----------------------#2019-12-06">https://towardsdatascience.com/an-introduction-to-discretization-in-data-science-55ef8c9775a2?source=collection_archive---------5-----------------------#2019-12-06</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><figure class="is it gp gr iu iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi ir"><img src="../Images/8507007b41e2656163edf2739b0abdb8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*eWYm3Dm7s0t8lLWYRW4pow.jpeg"/></div></div><figcaption class="jc jd gj gh gi je jf bd b be z dk">Photo by <a class="ae jg" href="https://www.pexels.com/@kevin-ku-92347?utm_content=attributionCopyText&amp;utm_medium=referral&amp;utm_source=pexels" rel="noopener ugc nofollow" target="_blank">Kevin Ku </a>from <a class="ae jg" href="https://www.pexels.com/photo/coding-computer-data-depth-of-field-577585/?utm_content=attributionCopyText&amp;utm_medium=referral&amp;utm_source=pexels" rel="noopener ugc nofollow" target="_blank">Pexels</a></figcaption></figure><div class=""/><div class=""><h2 id="346d" class="pw-subtitle-paragraph kg ji jj bd b kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx dk translated">特征工程:要学习的 4 种离散化技术。</h2></div><p id="c47b" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">离散化是我们将连续变量、模型或函数转换成离散形式的过程。我们通过创建一组连续的区间(或箱)来做到这一点，这些区间跨越了我们期望的变量/模型/函数的范围。</p><blockquote class="lu lv lw"><p id="aae4" class="ky kz lx la b lb lc kk ld le lf kn lg ly li lj lk lz lm ln lo ma lq lr ls lt im bi translated"><strong class="la jk"> <em class="jj">连续数据</em> </strong> <em class="jj">是</em>测得的，<em class="jj">是</em> <strong class="la jk"> <em class="jj">离散数据</em><em class="jj"/></strong><em class="jj">是</em>算出的。</p></blockquote><h1 id="4e08" class="mb mc jj bd md me mf mg mh mi mj mk ml kp mm kq mn ks mo kt mp kv mq kw mr ms bi translated">|| I ||为什么离散化很重要</h1><p id="70fd" class="pw-post-body-paragraph ky kz jj la b lb mt kk ld le mu kn lg lh mv lj lk ll mw ln lo lp mx lr ls lt im bi translated">有连续数据的数学问题有无穷多个自由度。由于我们的计算不可能永远进行下去，所以这样的问题必然要求有限的自由度。出于多种原因，数据科学家需要使用离散化。Kaggle 上的许多顶级贡献使用离散化，原因如下:</p><figure class="mz na nb nc gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi my"><img src="../Images/f5219784622b2e4c3cf79ecf72c0e791.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*cdoed_1hPhjXRz7T"/></div></div><figcaption class="jc jd gj gh gi je jf bd b be z dk">Photo by <a class="ae jg" href="https://unsplash.com/@ryoji__iwata?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Ryoji Iwata</a> on <a class="ae jg" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><h2 id="8e95" class="nd mc jj bd md ne nf dn mh ng nh dp ml lh ni nj mn ll nk nl mp lp nm nn mr no bi translated">符合问题陈述</h2><p id="96b1" class="pw-post-body-paragraph ky kz jj la b lb mt kk ld le mu kn lg lh mv lj lk ll mw ln lo lp mx lr ls lt im bi translated">通常，将连续数据(如体重)划分并存储到有意义的类别或组中会更容易理解。比如我们可以把一个连续变量，体重，分成以下几组来存储:<br/><strong class="la jk"><em class="lx">100 磅以下</em> </strong> <em class="lx">(轻)，140–160 磅之间</em>  <em class="lx">(中)，200 磅以上</em>  <em class="lx">(重)</em></p><p id="a354" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">如果我们看不到属于同一权重类别的变量之间的客观差异，我们将认为该结构是有用的。<br/>在我们的例子中，85 磅<em class="lx">和 56 磅</em>的重量传达了相同的信息(物体很轻)。因此，如果数据符合问题陈述，离散化有助于使我们的数据更容易理解。</p></div><div class="ab cl np nq hx nr" role="separator"><span class="ns bw bk nt nu nv"/><span class="ns bw bk nt nu nv"/><span class="ns bw bk nt nu"/></div><div class="im in io ip iq"><figure class="mz na nb nc gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi nw"><img src="../Images/8599806376e29ca190f00c0d686a07b0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*jHpJFSucD1XYA7i0"/></div></div><figcaption class="jc jd gj gh gi je jf bd b be z dk">Photo by <a class="ae jg" href="https://unsplash.com/@williamdaigneault?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">William Daigneault</a> on <a class="ae jg" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><h2 id="3308" class="nd mc jj bd md ne nf dn mh ng nh dp ml lh ni nj mn ll nk nl mp lp nm nn mr no bi translated">解释特征</h2><p id="0c89" class="pw-post-body-paragraph ky kz jj la b lb mt kk ld le mu kn lg lh mv lj lk ll mw ln lo lp mx lr ls lt im bi translated">由于具有无限的自由度，连续特征与目标变量关联的机会较小，并且可能具有复杂的非线性关系。因此，可能更难解释这样的函数。在离散化变量之后，可以解释对应于目标的组。</p></div><div class="ab cl np nq hx nr" role="separator"><span class="ns bw bk nt nu nv"/><span class="ns bw bk nt nu nv"/><span class="ns bw bk nt nu"/></div><div class="im in io ip iq"><figure class="mz na nb nc gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi nx"><img src="../Images/d4f71c5cf390c2073ca8215a8f582881.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*bBSiceGUCQDx9Tpf"/></div></div><figcaption class="jc jd gj gh gi je jf bd b be z dk">Photo by <a class="ae jg" href="https://unsplash.com/@franckinjapan?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Franck V.</a> on <a class="ae jg" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><h2 id="bc4d" class="nd mc jj bd md ne nf dn mh ng nh dp ml lh ni nj mn ll nk nl mp lp nm nn mr no bi translated">与模型/方法不兼容</h2><p id="8d47" class="pw-post-body-paragraph ky kz jj la b lb mt kk ld le mu kn lg lh mv lj lk ll mw ln lo lp mx lr ls lt im bi translated">某些模型可能与连续数据不兼容，例如，替代决策树模型(如随机森林模型)不适合连续特征。</p><p id="6496" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">特征工程方法，例如任何基于熵的方法可能无法处理连续数据，因此我们将离散化变量以处理不同的模型和方法。</p></div><div class="ab cl np nq hx nr" role="separator"><span class="ns bw bk nt nu nv"/><span class="ns bw bk nt nu nv"/><span class="ns bw bk nt nu"/></div><div class="im in io ip iq"><figure class="mz na nb nc gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi ny"><img src="../Images/fbca7c8ca3a3561279aaffb1f1fe8637.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*V-rijpeouzPU6611"/></div></div><figcaption class="jc jd gj gh gi je jf bd b be z dk">Photo by <a class="ae jg" href="https://unsplash.com/@mwerneck?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Mariano Werneck</a> on <a class="ae jg" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><h2 id="1bb9" class="nd mc jj bd md ne nf dn mh ng nh dp ml lh ni nj mn ll nk nl mp lp nm nn mr no bi translated">信噪比</h2><p id="3d62" class="pw-post-body-paragraph ky kz jj la b lb mt kk ld le mu kn lg lh mv lj lk ll mw ln lo lp mx lr ls lt im bi translated">当我们离散化一个模型时，我们将它拟合到箱中，并减少数据中小波动的影响。通常，我们会将微小的波动视为噪声。我们可以通过离散化来减少这种噪声。这是“平滑”的过程，其中每个箱平滑波动，从而减少数据中的噪声。</p></div><div class="ab cl np nq hx nr" role="separator"><span class="ns bw bk nt nu nv"/><span class="ns bw bk nt nu nv"/><span class="ns bw bk nt nu"/></div><div class="im in io ip iq"><h1 id="4433" class="mb mc jj bd md me nz mg mh mi oa mk ml kp ob kq mn ks oc kt mp kv od kw mr ms bi translated">|| II ||离散化方法</h1><ul class=""><li id="bd03" class="oe of jj la b lb mt le mu lh og ll oh lp oi lt oj ok ol om bi translated">无监督:<br/> —等宽<br/> —等频<br/> — K 均值</li><li id="edee" class="oe of jj la b lb on le oo lh op ll oq lp or lt oj ok ol om bi translated">监督:<br/> —决策树</li></ul><h1 id="3571" class="mb mc jj bd md me mf mg mh mi mj mk ml kp mm kq mn ks mo kt mp kv mq kw mr ms bi translated">|| III ||等宽离散化</h1><p id="6a29" class="pw-post-body-paragraph ky kz jj la b lb mt kk ld le mu kn lg lh mv lj lk ll mw ln lo lp mx lr ls lt im bi translated">将所有可能的值分成“<strong class="la jk"> N </strong>个仓，每个仓具有相同的宽度。间隔宽度的公式:</p><p id="2dc5" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><strong class="la jk"> Width =(最大值-最小值)/ N <br/> </strong> <em class="lx"> *其中 N 是仓或区间的数量。</em></p><p id="49c3" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">在 python 上，您可能希望导入以下内容进行离散化:</p><pre class="mz na nb nc gt os ot ou ov aw ow bi"><span id="5154" class="nd mc jj ot b gy ox oy l oz pa">from sklearn.preprocessing import KBinsDiscretizer<br/>from feature_engine.discretisers import EqualWidthDiscretiser</span></pre><p id="4a30" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">按照以下方式设置等宽离散化器:</p><pre class="mz na nb nc gt os ot ou ov aw ow bi"><span id="2571" class="nd mc jj ot b gy ox oy l oz pa">discretizer = EqualWidthDiscretiser(bins=10, variables = ['var1', 'var2'])</span><span id="5c62" class="nd mc jj ot b gy pb oy l oz pa">#OR </span><span id="1b64" class="nd mc jj ot b gy pb oy l oz pa">discretizer = KBinsDiscretizer(n_bins=10, encode='ordinal', strategy='uniform')</span></pre><ul class=""><li id="d7b6" class="oe of jj la b lb lc le lf lh pc ll pd lp pe lt oj ok ol om bi translated">相等的宽度不会改善值的分布</li><li id="c970" class="oe of jj la b lb on le oo lh op ll oq lp or lt oj ok ol om bi translated">它可以处理异常值</li><li id="173e" class="oe of jj la b lb on le oo lh op ll oq lp or lt oj ok ol om bi translated">可以与分类编码结合使用</li></ul></div><div class="ab cl np nq hx nr" role="separator"><span class="ns bw bk nt nu nv"/><span class="ns bw bk nt nu nv"/><span class="ns bw bk nt nu"/></div><div class="im in io ip iq"><h1 id="4cd5" class="mb mc jj bd md me nz mg mh mi oa mk ml kp ob kq mn ks oc kt mp kv od kw mr ms bi translated">|| IV ||等频离散化</h1><p id="2410" class="pw-post-body-paragraph ky kz jj la b lb mt kk ld le mu kn lg lh mv lj lk ll mw ln lo lp mx lr ls lt im bi translated">将所有可能的值分成数量为“<strong class="la jk"> N </strong>的箱，每个箱具有相同数量的观察值。区间可以对应于分位数值。</p><p id="30e8" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">在 python 上，您可能希望导入以下内容进行离散化:</p><pre class="mz na nb nc gt os ot ou ov aw ow bi"><span id="685b" class="nd mc jj ot b gy ox oy l oz pa">from sklearn.preprocessing import KBinsDiscretizer<br/>from feature_engine.discretisers import EqualFrequencyDiscretiser</span></pre><p id="7318" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">按照以下方式设置等频离散化器:</p><pre class="mz na nb nc gt os ot ou ov aw ow bi"><span id="1989" class="nd mc jj ot b gy ox oy l oz pa">discretizer = KBinsDiscretizer(n_bins=10, encode='ordinal', strategy='quantile')</span><span id="c994" class="nd mc jj ot b gy pb oy l oz pa">#OR </span><span id="eaa7" class="nd mc jj ot b gy pb oy l oz pa">discretizer = EqualFrequencyDiscretiser(q=10, variables = ['var1', 'var2'])</span></pre><ul class=""><li id="31a5" class="oe of jj la b lb lc le lf lh pc ll pd lp pe lt oj ok ol om bi translated">相等的频率确实提高了值的分布</li><li id="03c8" class="oe of jj la b lb on le oo lh op ll oq lp or lt oj ok ol om bi translated">它可以处理异常值</li><li id="b3e0" class="oe of jj la b lb on le oo lh op ll oq lp or lt oj ok ol om bi translated">可以与分类编码结合使用</li></ul></div><div class="ab cl np nq hx nr" role="separator"><span class="ns bw bk nt nu nv"/><span class="ns bw bk nt nu nv"/><span class="ns bw bk nt nu"/></div><div class="im in io ip iq"><h1 id="6bd0" class="mb mc jj bd md me nz mg mh mi oa mk ml kp ob kq mn ks oc kt mp kv od kw mr ms bi translated">| | V | | K-均值离散化</h1><p id="0809" class="pw-post-body-paragraph ky kz jj la b lb mt kk ld le mu kn lg lh mv lj lk ll mw ln lo lp mx lr ls lt im bi translated">我们将 K 均值聚类应用于连续变量，从而将其划分为离散的组或聚类。</p><p id="b956" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">在 python 上，您可能希望导入以下内容以使用 K-means 进行离散化:</p><pre class="mz na nb nc gt os ot ou ov aw ow bi"><span id="984d" class="nd mc jj ot b gy ox oy l oz pa">from sklearn.preprocessing import KBinsDiscretizer</span></pre><p id="b0b7" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">按照以下方式设置 K 均值离散化器:</p><pre class="mz na nb nc gt os ot ou ov aw ow bi"><span id="04a7" class="nd mc jj ot b gy ox oy l oz pa">discretizer = KBinsDiscretizer(n_bins=5, encode='ordinal', strategy='kmeans')</span></pre><ul class=""><li id="1268" class="oe of jj la b lb lc le lf lh pc ll pd lp pe lt oj ok ol om bi translated">K-Means 并不能提高价值传播</li><li id="99e0" class="oe of jj la b lb on le oo lh op ll oq lp or lt oj ok ol om bi translated">它可以处理异常值，但是可能存在质心偏差。</li><li id="2a20" class="oe of jj la b lb on le oo lh op ll oq lp or lt oj ok ol om bi translated">可以与分类编码结合使用</li></ul></div><div class="ab cl np nq hx nr" role="separator"><span class="ns bw bk nt nu nv"/><span class="ns bw bk nt nu nv"/><span class="ns bw bk nt nu"/></div><div class="im in io ip iq"><h1 id="e492" class="mb mc jj bd md me nz mg mh mi oa mk ml kp ob kq mn ks oc kt mp kv od kw mr ms bi translated">|| VI ||决策树离散化</h1><p id="1702" class="pw-post-body-paragraph ky kz jj la b lb mt kk ld le mu kn lg lh mv lj lk ll mw ln lo lp mx lr ls lt im bi translated">我们使用决策树来确定箱的最佳数量。当模型做出决定时，它为每个节点分配一个观察值。然后，这些观察结果被分类为变量的离散输出。</p><p id="76b0" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">在 python 上，您可能希望导入以下内容以使用决策树进行离散化:</p><pre class="mz na nb nc gt os ot ou ov aw ow bi"><span id="0c2a" class="nd mc jj ot b gy ox oy l oz pa">from sklearn.model_selection import train_test_split<br/>from feature_engine.discretisers import DecisionTreeDiscretiser</span></pre><p id="a280" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">您的离散化器应按以下方式设置:</p><pre class="mz na nb nc gt os ot ou ov aw ow bi"><span id="bd1c" class="nd mc jj ot b gy ox oy l oz pa"># cross-validation number (cv)<br/># how to evaluate model performance (scoring)<br/># the variables we want to discretise (variables)<br/># whether it is a target for regression or classification<br/># and the grid with the parameters we want to test</span><span id="5dc7" class="nd mc jj ot b gy pb oy l oz pa">treeDisc = DecisionTreeDiscretiser(cv=10, scoring='accuracy',<br/>                                   variables=['var1', 'var2'],<br/>                                   regression=False,<br/>                                   param_grid={'max_depth': [1,2,3],<br/>'min_samples_leaf':[10,4]})</span></pre><ul class=""><li id="eca1" class="oe of jj la b lb lc le lf lh pc ll pd lp pe lt oj ok ol om bi translated">决策树不能提高价值分布</li><li id="24a3" class="oe of jj la b lb on le oo lh op ll oq lp or lt oj ok ol om bi translated">它可以很好地处理异常值，因为树对于异常值是健壮的。</li><li id="a162" class="oe of jj la b lb on le oo lh op ll oq lp or lt oj ok ol om bi translated">创建单调的关系</li></ul></div><div class="ab cl np nq hx nr" role="separator"><span class="ns bw bk nt nu nv"/><span class="ns bw bk nt nu nv"/><span class="ns bw bk nt nu"/></div><div class="im in io ip iq"><h1 id="a97e" class="mb mc jj bd md me nz mg mh mi oa mk ml kp ob kq mn ks oc kt mp kv od kw mr ms bi translated">|| VII ||下一步</h1><p id="270f" class="pw-post-body-paragraph ky kz jj la b lb mt kk ld le mu kn lg lh mv lj lk ll mw ln lo lp mx lr ls lt im bi translated">离散化变量后，您可以执行以下任一操作:</p><ul class=""><li id="b730" class="oe of jj la b lb lc le lf lh pc ll pd lp pe lt oj ok ol om bi translated">构建决策树算法并直接使用离散化的输出作为箱的数量。决策树可以发现离散化变量和目标变量之间的非线性关系。</li><li id="6f09" class="oe of jj la b lb on le oo lh op ll oq lp or lt oj ok ol om bi translated">使用线性模型，而箱与目标变量没有线性关系。通过将箱子视为具有某种编码的类别来改进模型。</li></ul></div><div class="ab cl np nq hx nr" role="separator"><span class="ns bw bk nt nu nv"/><span class="ns bw bk nt nu nv"/><span class="ns bw bk nt nu"/></div><div class="im in io ip iq"><blockquote class="pf"><p id="6ddc" class="pg ph jj bd pi pj pk pl pm pn po lt dk translated">感谢你的阅读！</p><p id="3010" class="pg ph jj bd pi pj pk pl pm pn po lt dk translated">关注我，了解更多关于数据科学的内容。</p></blockquote></div></div>    
</body>
</html>