<html>
<head>
<title>Deep Learning &amp; Handwritten Arabic Digits</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">深度学习&amp;手写阿拉伯数字</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/deep-learning-handwritten-arabic-digits-5c7abc3c0580?source=collection_archive---------20-----------------------#2019-02-08">https://towardsdatascience.com/deep-learning-handwritten-arabic-digits-5c7abc3c0580?source=collection_archive---------20-----------------------#2019-02-08</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="044e" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">使用 fast.ai 库以 99%的准确率对 AHCD 进行分类！</h2></div><figure class="kf kg kh ki gt kj gh gi paragraph-image"><div class="ab gu cl kk"><img src="../Images/c7479ba853b98ab39650900078627b84.png" data-original-src="https://miro.medium.com/v2/format:webp/1*dT3ZtPSz7w1HrMhHLVabvw.jpeg"/></div><figcaption class="kn ko gj gh gi kp kq bd b be z dk">photo: Morocco, 2000</figcaption></figure><p id="ba1b" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">深度学习的“hello world”通常是 MNIST 手写数字数据集，我想将同样的技术应用到一个更有趣的应用程序中:阿拉伯语手写字符数据集(AHCD)，由美国大学开发的数据集。</p><p id="8b1e" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">在这个例子中，我使用 fast.ai 库来训练一个卷积神经网络(CNN ),以 99+%的准确率对 AHCD 进行正确分类。方法如下:</p><p id="22b5" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">首先，导入我们需要的库，并设置我们的 GPU 使用 cuda:</p><pre class="kf kg kh ki gt lo lp lq lr aw ls bi"><span id="cace" class="lt lu iq lp b gy lv lw l lx ly">%reload_ext autoreload<br/>%autoreload 2<br/>%matplotlib inline</span><span id="61e8" class="lt lu iq lp b gy lz lw l lx ly"><strong class="lp ir">from</strong> <strong class="lp ir">fastai.vision</strong> <strong class="lp ir">import</strong> *<br/><strong class="lp ir">from</strong> <strong class="lp ir">fastai.metrics</strong> <strong class="lp ir">import</strong> error_rate<br/><strong class="lp ir">import</strong> <strong class="lp ir">csv</strong><br/><strong class="lp ir">import</strong> <strong class="lp ir">numpy</strong> <strong class="lp ir">as</strong> <strong class="lp ir">np</strong><br/><strong class="lp ir">import</strong> <strong class="lp ir">PIL</strong> <br/><strong class="lp ir">import</strong> <strong class="lp ir">pandas</strong> <strong class="lp ir">as</strong> <strong class="lp ir">pd</strong></span><span id="f390" class="lt lu iq lp b gy lz lw l lx ly">defaults.device = torch.device('cuda')</span></pre><p id="0c01" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">与许多数据科学工作流一样，数据预处理是最重要的组成部分。以下是为我们的卷积神经网络准备数据的步骤:</p><h2 id="c65e" class="lt lu iq bd ma mb mc dn md me mf dp mg la mh mi mj le mk ml mm li mn mo mp mq bi translated">1 —从 csv 摄取</h2><p id="fae9" class="pw-post-body-paragraph kr ks iq kt b ku mr jr kw kx ms ju kz la mt lc ld le mu lg lh li mv lk ll lm ij bi translated">与 MNIST 拉丁字母版本一样，AHCD 也是一个 784 列的 csv，其中每行包含一个 28x28 的图像，该图像被展平为一行数值。</p><p id="85c3" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">第一个任务是将它加载到内存中，由于数据集有 60k 行，为了加速这个过程，我设置了一个任意的 4k 训练集限制。我们将 Pandas 作为 pd 导入，所以这使用了内置的 Pandas read_csv 函数:</p><pre class="kf kg kh ki gt lo lp lq lr aw ls bi"><span id="bd34" class="lt lu iq lp b gy lv lw l lx ly">trainrows = 4000<br/>train = pd.read_csv('csvtrain.csv', nrows=trainrows)</span></pre><h2 id="9dbc" class="lt lu iq bd ma mb mc dn md me mf dp mg la mh mi mj le mk ml mm li mn mo mp mq bi translated">2-转换为 3D 数据结构以进行图像处理</h2><p id="7de6" class="pw-post-body-paragraph kr ks iq kt b ku mr jr kw kx ms ju kz la mt lc ld le mu lg lh li mv lk ll lm ij bi translated">我们在内存中有数据，但是每个要生成的图像仍然是平面的(1 高 784 宽),我们希望它是正方形和多维的，这样我们可以使用 matplotlib 将其转换为 RGB 图像。为什么是 RGB？我们将使用基于 RGB 图像开发的预训练 restnet34 模型。</p><p id="fcce" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">这个简单的函数获取我们的 Pandas <code class="fe mw mx my lp b">train</code>数据帧并提取一行(作为变量传递)，将该行重新整形为一个正方形结构，将数字规范化为范围[0，1]，添加两个全零的额外维度，并使用 matplotlib.plot 库将图像作为 png 保存在我们的<code class="fe mw mx my lp b">path/digits/</code>文件夹中。</p><p id="479f" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">注意:最后，我将添加逻辑来将文件夹作为变量传递。目前，它是硬编码的。</p><pre class="kf kg kh ki gt lo lp lq lr aw ls bi"><span id="3229" class="lt lu iq lp b gy lv lw l lx ly"><strong class="lp ir">def</strong> pdMakePlot(row):<br/>    pixels = np.array(train.iloc[[row]], dtype='uint8')<br/>    pixels = pixels.reshape((28, 28)).T<br/>    pixels = np.true_divide(pixels, 255)<br/>    dim2 = np.zeros((28,28))<br/>    dim3 = np.zeros((28,28))<br/>    pix = np.stack((pixels, dim2,dim3), axis=2)<br/>    row += 1<br/>    filename = "digits/<strong class="lp ir">%s</strong>.png" % row<br/>    plt.imsave(filename, pix)<br/>    plt.close('all')<br/>    <strong class="lp ir">return</strong></span></pre><h2 id="2c6b" class="lt lu iq bd ma mb mc dn md me mf dp mg la mh mi mj le mk ml mm li mn mo mp mq bi translated">3-准备我们的事实来源数据框架</h2><p id="686e" class="pw-post-body-paragraph kr ks iq kt b ku mr jr kw kx ms ju kz la mt lc ld le mu lg lh li mv lk ll lm ij bi translated">我们正在使用 fast.ai <code class="fe mw mx my lp b">ImageDataBunch.from_df</code>方法为这个卷积神经网络摄取图像数据，因此我们需要一个 Pandas 数据帧，其中包含我们的训练文件名&amp;和有效标签。</p><pre class="kf kg kh ki gt lo lp lq lr aw ls bi"><span id="8d69" class="lt lu iq lp b gy lv lw l lx ly">#import training labels into numpy array</span><span id="0a98" class="lt lu iq lp b gy lz lw l lx ly">csv = np.genfromtxt ('csvtrainlabel.csv', delimiter=",")<br/>csv = csv[0:trainrows]<br/>csv = csv.astype('int32')<br/>csv = np.add(csv,1)<br/>csv[csv == 10] = 0</span><span id="7f23" class="lt lu iq lp b gy lz lw l lx ly"><em class="ln">#np array that we'll make into the filenames</em><br/><em class="ln">#from 1 to trainrows</em><br/>trainrange = trainrows +1<br/>files = np.arange(1,trainrange)<br/>files = files.astype(str)</span><span id="6d6c" class="lt lu iq lp b gy lz lw l lx ly"><em class="ln">#convert to filenames</em><br/>i = 0;<br/>j = 1;<br/><strong class="lp ir">for</strong> file <strong class="lp ir">in</strong> files:<br/>    files[i] = "<strong class="lp ir">%s</strong>.png" % j<br/>    i += 1<br/>    j += 1<br/>    <strong class="lp ir">if</strong> i &gt;= trainrange: <strong class="lp ir">break</strong></span><span id="a0b8" class="lt lu iq lp b gy lz lw l lx ly"><em class="ln">#combine two arrays into dataframe and add header</em><br/>df = pd.DataFrame({'name':files, 'label':csv})<br/>df.head()</span></pre><figure class="kf kg kh ki gt kj gh gi paragraph-image"><div class="gh gi mz"><img src="../Images/493ab6bc504742eb78de8d72d572bd5c.png" data-original-src="https://miro.medium.com/v2/resize:fit:800/format:webp/1*9uegWRgLzfO1qfo00z3hsg.png"/></div><figcaption class="kn ko gj gh gi kp kq bd b be z dk">our dataframe</figcaption></figure><p id="6bf4" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">同样，我将再次讨论 ETL 过程的一部分。</p><h2 id="0f0f" class="lt lu iq bd ma mb mc dn md me mf dp mg la mh mi mj le mk ml mm li mn mo mp mq bi translated">4 —处理并保存我们的培训图像</h2><p id="a635" class="pw-post-body-paragraph kr ks iq kt b ku mr jr kw kx ms ju kz la mt lc ld le mu lg lh li mv lk ll lm ij bi translated">有了这些，我们可以使用我们之前定义的<code class="fe mw mx my lp b">pdMakePlot()</code>函数来处理训练图像。处理的图像数量也由我们之前设置的<code class="fe mw mx my lp b">trainrange</code>变量设置。</p><pre class="kf kg kh ki gt lo lp lq lr aw ls bi"><span id="bab2" class="lt lu iq lp b gy lv lw l lx ly">i = 0<br/>max = trainrange-1<br/>for x in range(i,max):<br/>    pdMakePlot(i)<br/>    i += 1</span></pre><p id="ee43" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">现在我们已经准备好进行深度学习了！只有几行代码:</p><pre class="kf kg kh ki gt lo lp lq lr aw ls bi"><span id="6a1e" class="lt lu iq lp b gy lv lw l lx ly">#define our transforms<br/>tfms = get_transforms(do_flip=False)</span><span id="70f4" class="lt lu iq lp b gy lz lw l lx ly">#define our DataBunch<br/>data = ImageDataBunch.from_df(path=path, df = df, ds_tfms=tfms, size=24)</span><span id="e005" class="lt lu iq lp b gy lz lw l lx ly">#define our learner<br/>learn = create_cnn(data, models.resnet34, metrics=accuracy)</span></pre><p id="d6a6" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">在我们训练之前，我们可以从我们的数据集中查看一小部分选择，以确认我们已经正确处理了所有内容:</p><pre class="kf kg kh ki gt lo lp lq lr aw ls bi"><span id="c8f1" class="lt lu iq lp b gy lv lw l lx ly">data.show_batch(rows=3, figsize=(7,6))</span></pre><figure class="kf kg kh ki gt kj gh gi paragraph-image"><div role="button" tabindex="0" class="nb nc di nd bf ne"><div class="gh gi na"><img src="../Images/45385f2643d1aad7f93df4f8ae0e0b8f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*f2qNILogyCcywhCMVsO7NQ.png"/></div></div><figcaption class="kn ko gj gh gi kp kq bd b be z dk">9 handwritten characters &amp; labels</figcaption></figure><p id="6c3e" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">一切都好！我们还可以运行<code class="fe mw mx my lp b">learn.model</code>来详细了解学习者架构。如果你感兴趣，它是可用的。不管怎样，我们训练吧！</p><h2 id="5176" class="lt lu iq bd ma mb mc dn md me mf dp mg la mh mi mj le mk ml mm li mn mo mp mq bi translated">初步训练</h2><pre class="kf kg kh ki gt lo lp lq lr aw ls bi"><span id="3805" class="lt lu iq lp b gy lv lw l lx ly">learn.fit_one_cycle(4)</span></pre><figure class="kf kg kh ki gt kj gh gi paragraph-image"><div class="gh gi nf"><img src="../Images/d01a160245db3e5ecb219ee97092eaac.png" data-original-src="https://miro.medium.com/v2/resize:fit:1292/format:webp/1*HC63F3WoZDdpHx28xpuaTQ.png"/></div><figcaption class="kn ko gj gh gi kp kq bd b be z dk">transfer learning from resnet34, 95% accuracy in 16 seconds</figcaption></figure><p id="ba2c" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">我认为我们可以做得更好。让我们找到最佳的学习率，重新训练。</p><pre class="kf kg kh ki gt lo lp lq lr aw ls bi"><span id="cec0" class="lt lu iq lp b gy lv lw l lx ly">learn.lr_find()</span><span id="b859" class="lt lu iq lp b gy lz lw l lx ly">LR Finder is complete, type {learner_name}.recorder.plot() to see the graph.</span><span id="9e35" class="lt lu iq lp b gy lz lw l lx ly">learn.recorder.plot()</span></pre><figure class="kf kg kh ki gt kj gh gi paragraph-image"><div class="gh gi ng"><img src="../Images/1d92f3046cfed14eef82a6dd5ff47669.png" data-original-src="https://miro.medium.com/v2/resize:fit:790/format:webp/1*VDYPQhq_EiFthwIeBhH06w.png"/></div><figcaption class="kn ko gj gh gi kp kq bd b be z dk">learning rate against loss</figcaption></figure><p id="64d4" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">我们看到最优学习率确实很高。让我们试着获得一个比最小化损失的学习率低一点的学习率，比如 0.05？然后我们会解冻 CNN 的一些层，重新训练。</p><pre class="kf kg kh ki gt lo lp lq lr aw ls bi"><span id="8a87" class="lt lu iq lp b gy lv lw l lx ly">learn.unfreeze()<br/>learn.fit_one_cycle(3, max_lr=slice(.006, .004))</span></pre><figure class="kf kg kh ki gt kj gh gi paragraph-image"><div class="gh gi nh"><img src="../Images/ba2764363d07610dc28d8e076850c1ee.png" data-original-src="https://miro.medium.com/v2/resize:fit:1260/format:webp/1*s25SsDplca5LdHXiBv5q0g.png"/></div><figcaption class="kn ko gj gh gi kp kq bd b be z dk">much better</figcaption></figure><p id="cea9" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">15 秒钟后，我们有了一个模型，它对我们留在一边进行验证的训练数据子集有 99.6%的准确性。</p><h2 id="50d9" class="lt lu iq bd ma mb mc dn md me mf dp mg la mh mi mj le mk ml mm li mn mo mp mq bi translated">使用模型</h2><p id="d196" class="pw-post-body-paragraph kr ks iq kt b ku mr jr kw kx ms ju kz la mt lc ld le mu lg lh li mv lk ll lm ij bi translated">既然有了模型，那就用起来吧！使用上面的函数从测试 csv 中读取一些测试数据后:</p><pre class="kf kg kh ki gt lo lp lq lr aw ls bi"><span id="9024" class="lt lu iq lp b gy lv lw l lx ly">img = open_image('/path/3.png')</span><span id="7c1b" class="lt lu iq lp b gy lz lw l lx ly">pred_class,pred_idx,outputs = learn.predict(img)<br/>pred_class</span><span id="8852" class="lt lu iq lp b gy lz lw l lx ly"><strong class="lp ir">Category 4  &lt;--- that is correct</strong></span></pre><h2 id="b15d" class="lt lu iq bd ma mb mc dn md me mf dp mg la mh mi mj le mk ml mm li mn mo mp mq bi translated">然后</h2><p id="53a0" class="pw-post-body-paragraph kr ks iq kt b ku mr jr kw kx ms ju kz la mt lc ld le mu lg lh li mv lk ll lm ij bi translated">现在我们有了一个工作模型，而且是一个准确的模型，我想更新管道代码，使它更加优雅。我还想对全套测试数据运行模型，看看它如何与最先进的技术相比较。更多来了！</p><h2 id="955c" class="lt lu iq bd ma mb mc dn md me mf dp mg la mh mi mj le mk ml mm li mn mo mp mq bi translated">也</h2><p id="cbbb" class="pw-post-body-paragraph kr ks iq kt b ku mr jr kw kx ms ju kz la mt lc ld le mu lg lh li mv lk ll lm ij bi translated">附加代码在我的 github 上:<a class="ae ni" href="http://www.github.com/matthewarthur" rel="noopener ugc nofollow" target="_blank">www.github.com/matthewarthur</a>。我的 LinkedIn 是 https://www.linkedin.com/in/matt-a-8208aaa/的<a class="ae ni" href="https://www.linkedin.com/in/matt-a-8208aaa/" rel="noopener ugc nofollow" target="_blank"/>。打个招呼。</p><h2 id="6b67" class="lt lu iq bd ma mb mc dn md me mf dp mg la mh mi mj le mk ml mm li mn mo mp mq bi translated">笔记</h2><p id="d1de" class="pw-post-body-paragraph kr ks iq kt b ku mr jr kw kx ms ju kz la mt lc ld le mu lg lh li mv lk ll lm ij bi translated">https://www.kaggle.com/mloey1/ahcd1&amp;<a class="ae ni" href="http://datacenter.aucegypt.edu/shazeem/" rel="noopener ugc nofollow" target="_blank"/><a class="ae ni" href="https://www.kaggle.com/mloey1/ahcd1" rel="noopener ugc nofollow" target="_blank">http://datacenter.aucegypt.edu/shazeem/</a></p><p id="a457" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">[2]<a class="ae ni" href="https://docs.fast.ai/vision.data.html#ImageDataBunch.from_df" rel="noopener ugc nofollow" target="_blank">https://docs . fast . ai/vision . data . html # imagedata bunch . from _ df</a></p></div></div>    
</body>
</html>