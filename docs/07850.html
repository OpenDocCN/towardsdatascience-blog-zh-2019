<html>
<head>
<title>Build Your Personal Voice Assistant</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">打造您的个人语音助手</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/build-your-personal-voice-assistant-cec7785508da?source=collection_archive---------10-----------------------#2019-10-30">https://towardsdatascience.com/build-your-personal-voice-assistant-cec7785508da?source=collection_archive---------10-----------------------#2019-10-30</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="8c7c" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">通过语音命令在计算机上执行任务</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/c438f6ba4a7cb756c38ae0305ff86947.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*U5HIqx_sQoGGAozjGRS8eA.jpeg"/></div></div></figure><p id="36e4" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">我一直对 Siri、Alexa、谷歌助手或任何其他语音助手的工作方式很着迷。它通过自动化任务使用户的生活变得更加容易。因此，我决定构建自己的语音助手，它将从我的笔记本电脑上的麦克风收集命令，并使用它来执行任务。</p><h1 id="2f34" class="lq lr it bd ls lt lu lv lw lx ly lz ma jz mb ka mc kc md kd me kf mf kg mg mh bi translated">资料组</h1><p id="e458" class="pw-post-body-paragraph ku kv it kw b kx mi ju kz la mj jx lc ld mk lf lg lh ml lj lk ll mm ln lo lp im bi translated">我选择了 5 个我觉得任何人都可能经常使用的简单命令，并决定录下自己说这些命令的过程。我假设当用户说出命令时不会有任何背景噪音。这使得事情变得容易得多，因为我不必担心从噪音中分离出实际的命令，这需要对音频进行一些预处理。</p><p id="1188" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">这五个命令是:</p><ul class=""><li id="9a72" class="mn mo it kw b kx ky la lb ld mp lh mq ll mr lp ms mt mu mv bi translated">‘降低音量’—降低系统音量</li><li id="05b8" class="mn mo it kw b kx mw la mx ld my lh mz ll na lp ms mt mu mv bi translated">‘增加音量’—增加系统音量</li><li id="8f7d" class="mn mo it kw b kx mw la mx ld my lh mz ll na lp ms mt mu mv bi translated">‘打开谷歌’—在浏览器中打开谷歌网页</li><li id="9a70" class="mn mo it kw b kx mw la mx ld my lh mz ll na lp ms mt mu mv bi translated">“显示 CPU 利用率”—显示正在运行的进程的性能详细信息</li><li id="43f7" class="mn mo it kw b kx mw la mx ld my lh mz ll na lp ms mt mu mv bi translated">“拍照”—使用笔记本电脑摄像头点击照片</li></ul><p id="3bfa" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">因为我将使用深度学习模型来预测命令，所以我将需要每个类的大量数据。我使用下面的脚本，通过我的笔记本电脑麦克风为每个命令录制了 20 个样本，其中节奏和音调略有不同。每个样本的长度为 2 秒，刚好大于任何人说出任何命令所需的平均时间。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nb"><img src="../Images/6da8dd1944856f19c4552ffcc06a851f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*c5-hDLWmAZIiJKnhnAsx7w.png"/></div></div><figcaption class="nc nd gj gh gi ne nf bd b be z dk"><a class="ae ng" href="https://gist.github.com/grohith327/deedd75d73070e7667eef1977162a390" rel="noopener ugc nofollow" target="_blank">https://gist.github.com/grohith327/deedd75d73070e7667eef1977162a390</a></figcaption></figure><p id="84d4" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">我们可以从记录的 20 个样本中随机抽取 1 秒的作物，并附加 1 秒的静默。这将为我们提供每门课的大量数据。我们使用下面的脚本获取 200 个这样的作物。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nh"><img src="../Images/94039702a7efd7d46af2b6c0e9a62f33.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*t1ggS_-Fp1EO5D6MTqP7Lg.png"/></div></div><figcaption class="nc nd gj gh gi ne nf bd b be z dk"><a class="ae ng" href="https://gist.github.com/grohith327/2f9121157039840a77b5d527e2313f06" rel="noopener ugc nofollow" target="_blank">https://gist.github.com/grohith327/2f9121157039840a77b5d527e2313f06</a></figcaption></figure><p id="6687" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">现在我们已经为每个类准备了大约 220 个样本(200 个裁剪样本和 20 个原始样本),我们可以考虑对音频样本进行一些预处理。</p><h1 id="a48b" class="lq lr it bd ls lt lu lv lw lx ly lz ma jz mb ka mc kc md kd me kf mf kg mg mh bi translated">音频预处理</h1><p id="8348" class="pw-post-body-paragraph ku kv it kw b kx mi ju kz la mj jx lc ld mk lf lg lh ml lj lk ll mm ln lo lp im bi translated">录制的语音命令存储为。wav 文件，如果我们能得到音频文件的声谱图，我们可以把它当作一个图像，并把它输入 CNN，对音频进行分类。幸运的是，python 库 librosa 让事情变得简单多了，我们可以很容易地用这个库生成音频的频谱图。以下脚本用于生成声谱图。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ni"><img src="../Images/826a88828c99f0b9c65c8f236c1f5ba0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*MfgoaMc9wgJLS_jS9WG8rA.png"/></div></div><figcaption class="nc nd gj gh gi ne nf bd b be z dk"><a class="ae ng" href="https://gist.github.com/grohith327/0e6b2071b8e3f57961a24d06c495fe33" rel="noopener ugc nofollow" target="_blank">https://gist.github.com/grohith327/0e6b2071b8e3f57961a24d06c495fe33</a></figcaption></figure><p id="b2e8" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">为了生成声谱图，我们对音频数据进行短时傅立叶变换。傅立叶变换用于将信号从时域转换到频域，我们这样做是为了了解信号变化的程度。短时傅立叶变换是一种扩展，它采用小窗口，将其与信号进行卷积，并在卷积窗口内应用 DFT，现在我们在信号上移动窗口，迭代执行 DFT。</p><p id="bae2" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">我们可以使用上面的脚本可视化所有五个命令的频谱图。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nj"><img src="../Images/5de2a5b9832e20fcc8363b77d8d70512.png" data-original-src="https://miro.medium.com/v2/resize:fit:1352/format:webp/1*c8AKExUZIZkMjUav8nXajg.png"/></div></figure><p id="aea5" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">我们可以观察到命令“增大音量”和“减小音量”似乎具有相似的频谱图，因为单词“增大”和“减小”之间只有很小的差别。</p><p id="44c3" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">我们现在可以为每个音频样本生成声谱图，并使用以下脚本将其转储到 numpy 数组中。(注意:我们填充光谱图，以便所有维度匹配)</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nk"><img src="../Images/2d8a56d0dcb547cbbcaa4c639609de9d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ufnNBUWUNJ9fVNfMWOnHSQ.png"/></div></div><figcaption class="nc nd gj gh gi ne nf bd b be z dk"><a class="ae ng" href="https://gist.github.com/grohith327/ce30475cd508e0f196fb4face38f47ca" rel="noopener ugc nofollow" target="_blank">https://gist.github.com/grohith327/ce30475cd508e0f196fb4face38f47ca</a></figcaption></figure><p id="b943" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">既然我们已经将音频样本及其相应的标签保存到了一个. npy 文件中，我们可以随时加载它们，而不是每次都生成频谱图。</p><h1 id="a26a" class="lq lr it bd ls lt lu lv lw lx ly lz ma jz mb ka mc kc md kd me kf mf kg mg mh bi translated">构建模型</h1><p id="8833" class="pw-post-body-paragraph ku kv it kw b kx mi ju kz la mj jx lc ld mk lf lg lh ml lj lk ll mm ln lo lp im bi translated">我们可以将频谱图视为图像，并尝试从这些图像中识别有助于我们识别音频样本类别的特征。我们可以使用<a class="ae ng" rel="noopener" target="_blank" href="/build-your-own-convolution-neural-network-in-5-mins-4217c2cf964f">卷积神经网络</a>，它将图像作为输入，学习图像的空间特征并预测类别。</p><p id="ed00" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">在构建模型之前，我们将数据分为训练集和测试集。我们还使用下面的脚本将标签转换成一个热编码。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nl"><img src="../Images/d27b81207a698942d9e221d94a68ec2f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*8r_hC492l2lLDlfdZKuISA.png"/></div></div><figcaption class="nc nd gj gh gi ne nf bd b be z dk"><a class="ae ng" href="https://gist.github.com/grohith327/3d3ab1759f6a7a41654cbedbcd5dd7e8" rel="noopener ugc nofollow" target="_blank">https://gist.github.com/grohith327/3d3ab1759f6a7a41654cbedbcd5dd7e8</a></figcaption></figure><p id="70f2" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">我们现在可以开始构建卷积神经网络，为此我们将使用 TF 2.0 作为我们的框架。要了解如何在 Tensorflow 2.0 <a class="ae ng" rel="noopener" target="_blank" href="/tensorflow-2-0-create-and-train-a-vanilla-cnn-on-google-colab-c7a0ac86d61b">中构建 CNN，请点击此处</a>。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nl"><img src="../Images/4be986c92896ffa37a8c33ef13fd3bf5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*bSL9S90-nc4qItxCcdM7JQ.png"/></div></div><figcaption class="nc nd gj gh gi ne nf bd b be z dk"><a class="ae ng" href="https://gist.github.com/grohith327/3ff5da311fe03e0a8cc615bf7435ae83" rel="noopener ugc nofollow" target="_blank">https://gist.github.com/grohith327/3ff5da311fe03e0a8cc615bf7435ae83</a></figcaption></figure><p id="44fc" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">我们现在可以为 15 个时期训练我们的模型，我们评估我们的交叉熵损失模型，并使用 RMSProp 作为我们的优化器。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nm"><img src="../Images/46b29e53e60ef947cfe8cecb118b5b70.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*nG2UWDXXv0jOf9fXhxzZAg.png"/></div></div><figcaption class="nc nd gj gh gi ne nf bd b be z dk"><a class="ae ng" href="https://gist.github.com/grohith327/3ff5da311fe03e0a8cc615bf7435ae83" rel="noopener ugc nofollow" target="_blank">https://gist.github.com/grohith327/3ff5da311fe03e0a8cc615bf7435ae83</a></figcaption></figure><p id="7bdc" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">我们的模型学习频谱图的内在特征，并根据语音命令的类型区分它。经过 15 个时期的训练，我在测试数据上观察到了 96%的准确率。我们现在可以保存我们的模型，并使用它来预测我们的语音命令的类别并执行任务。</p><h1 id="69f5" class="lq lr it bd ls lt lu lv lw lx ly lz ma jz mb ka mc kc md kd me kf mf kg mg mh bi translated">自动化任务</h1><p id="5d15" class="pw-post-body-paragraph ku kv it kw b kx mi ju kz la mj jx lc ld mk lf lg lh ml lj lk ll mm ln lo lp im bi translated">我们使用笔记本电脑的麦克风连续记录音频，并将其分成 2 秒钟的样本，然后输入到我们的模型中进行预测。如果我们的模型能够以高置信度对命令进行分类，我们就执行该任务。以下是通过 python 执行每个命令的脚本。(注意:根据操作系统，某些命令可能需要不同的库来执行，以下脚本适用于 macOS)</p><h2 id="35c9" class="nn lr it bd ls no np dn lw nq nr dp ma ld ns nt mc lh nu nv me ll nw nx mg ny bi translated">降低音量</h2><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nz"><img src="../Images/02995cfa759776b5124b3b1b69533dae.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Pu9mwehD9gsYlMB2HBoy3Q.png"/></div></div><figcaption class="nc nd gj gh gi ne nf bd b be z dk"><a class="ae ng" href="https://gist.github.com/grohith327/9192644cc40d2d1a2c0cc963dc5520ca" rel="noopener ugc nofollow" target="_blank">https://gist.github.com/grohith327/9192644cc40d2d1a2c0cc963dc5520ca</a></figcaption></figure><h2 id="f798" class="nn lr it bd ls no np dn lw nq nr dp ma ld ns nt mc lh nu nv me ll nw nx mg ny bi translated">增加量</h2><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nb"><img src="../Images/66612dba025df3b19cfa0d47eb481738.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*hQPI2Z1jVlXUxjO-ZjkxYA.png"/></div></div><figcaption class="nc nd gj gh gi ne nf bd b be z dk"><a class="ae ng" href="https://gist.github.com/grohith327/5a7140d573b9416175d0b334da516260" rel="noopener ugc nofollow" target="_blank">https://gist.github.com/grohith327/5a7140d573b9416175d0b334da516260</a></figcaption></figure><h2 id="0f05" class="nn lr it bd ls no np dn lw nq nr dp ma ld ns nt mc lh nu nv me ll nw nx mg ny bi translated">打开谷歌</h2><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oa"><img src="../Images/e0039e8aafa243f97f1a6f1bc16f9c3b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*f3TaA1ihERMp7-3LMvP7Ig.png"/></div></div><figcaption class="nc nd gj gh gi ne nf bd b be z dk"><a class="ae ng" href="https://gist.github.com/grohith327/102a2ec2e16a81956a7bc2a7a0a248a5" rel="noopener ugc nofollow" target="_blank">https://gist.github.com/grohith327/102a2ec2e16a81956a7bc2a7a0a248a5</a></figcaption></figure><h2 id="32c7" class="nn lr it bd ls no np dn lw nq nr dp ma ld ns nt mc lh nu nv me ll nw nx mg ny bi translated">显示 CPU 利用率</h2><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ob"><img src="../Images/cd1304d93ff60b1c07a887d565fe319b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Z_in-SWGZj_oJEnADXl1Yg.png"/></div></div><figcaption class="nc nd gj gh gi ne nf bd b be z dk"><a class="ae ng" href="https://gist.github.com/grohith327/41c810a36097905747f0d5aad57c3500" rel="noopener ugc nofollow" target="_blank">https://gist.github.com/grohith327/41c810a36097905747f0d5aad57c3500</a></figcaption></figure><h2 id="8492" class="nn lr it bd ls no np dn lw nq nr dp ma ld ns nt mc lh nu nv me ll nw nx mg ny bi translated">照相</h2><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oc"><img src="../Images/1a4be897f9024ab2a71d9c42c86e63ed.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*zPeEBzvc_73ckSxgegbQBg.png"/></div></div><figcaption class="nc nd gj gh gi ne nf bd b be z dk"><a class="ae ng" href="https://gist.github.com/grohith327/becb9a96274d04a8e97cac5a6e23abdf" rel="noopener ugc nofollow" target="_blank">https://gist.github.com/grohith327/becb9a96274d04a8e97cac5a6e23abdf</a></figcaption></figure><p id="b507" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">我们现在可以编写一个脚本，它可以无限期地通过笔记本电脑麦克风监听语音命令，并将其分成 2 秒的间隔，然后使用该样本从 CNN 模型中获得预测。如果我们的 CNN 模型能够以高置信度对样本进行分类(这是因为我们不想在没有命令或静默的情况下执行任务)，我们就执行该任务。代码如下。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi od"><img src="../Images/dc4e53128197e0d62266fe826c473cef.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*JXX2lMbexQyUjpbFe96MKg.png"/></div></div><figcaption class="nc nd gj gh gi ne nf bd b be z dk"><a class="ae ng" href="https://gist.github.com/grohith327/27b51531eb7f27f3de26be4af53a45cb" rel="noopener ugc nofollow" target="_blank">https://gist.github.com/grohith327/27b51531eb7f27f3de26be4af53a45cb</a></figcaption></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oe"><img src="../Images/2e0920f4f94d3091e979803a34cb7f62.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*YmqldqJXhqV1gO4UFW8mrg.png"/></div></div><figcaption class="nc nd gj gh gi ne nf bd b be z dk"><a class="ae ng" href="https://gist.github.com/grohith327/27b51531eb7f27f3de26be4af53a45cb" rel="noopener ugc nofollow" target="_blank">https://gist.github.com/grohith327/27b51531eb7f27f3de26be4af53a45cb</a></figcaption></figure><h1 id="fdac" class="lq lr it bd ls lt lu lv lw lx ly lz ma jz mb ka mc kc md kd me kf mf kg mg mh bi translated">演示</h1><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="of og l"/></div></figure><h1 id="4816" class="lq lr it bd ls lt lu lv lw lx ly lz ma jz mb ka mc kc md kd me kf mf kg mg mh bi translated">结论</h1><p id="2a26" class="pw-post-body-paragraph ku kv it kw b kx mi ju kz la mj jx lc ld mk lf lg lh ml lj lk ll mm ln lo lp im bi translated">这种方法有点天真，因此它并不完美，正如你在上面的视频中看到的，它两次都没有识别出命令，但是，这是我们可以在短时间内构建和测试的东西(也很有趣！).</p><p id="0ae3" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">这只是你能做的一个例子。如果你愿意，你可以选择通过不同的命令来自动完成不同的任务，甚至可以扩展命令的数量，并且仍然可以获得很好的准确性。</p><h1 id="6654" class="lq lr it bd ls lt lu lv lw lx ly lz ma jz mb ka mc kc md kd me kf mf kg mg mh bi translated">参考</h1><div class="oh oi gp gr oj ok"><a href="https://github.com/librosa/librosa" rel="noopener  ugc nofollow" target="_blank"><div class="ol ab fo"><div class="om ab on cl cj oo"><h2 class="bd iu gy z fp op fr fs oq fu fw is bi translated">利布罗萨/利布罗萨</h2><div class="or l"><h3 class="bd b gy z fp op fr fs oq fu fw dk translated">一个用于音乐和音频分析的 python 包。参见 http://librosa.github.io/librosa/的完整参考手册…</h3></div><div class="os l"><p class="bd b dl z fp op fr fs oq fu fw dk translated">github.com</p></div></div></div></a></div></div></div>    
</body>
</html>