<html>
<head>
<title>Demystifying Convolutional Neural Networks using GradCam</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用 GradCam 解密卷积神经网络</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/demystifying-convolutional-neural-networks-using-gradcam-554a85dd4e48?source=collection_archive---------4-----------------------#2019-10-15">https://towardsdatascience.com/demystifying-convolutional-neural-networks-using-gradcam-554a85dd4e48?source=collection_archive---------4-----------------------#2019-10-15</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><figure class="is it gp gr iu iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi ir"><img src="../Images/1597fde38e965d1c388157a9d2e872a8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*n9aQlXrazplSkhaq4wAldQ.png"/></div></div><figcaption class="jc jd gj gh gi je jf bd b be z dk">(<a class="ae jg" href="https://unsplash.com/photos/fg8tdcxrkrA" rel="noopener ugc nofollow" target="_blank">source</a>)</figcaption></figure><div class=""/><p id="4471" class="pw-post-body-paragraph kg kh jj ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">卷积神经网络(CNN)和其他深度学习网络已经在各种计算机视觉任务中实现了前所未有的突破，从图像分类到对象检测、语义分割、图像字幕以及最近的视觉问题回答。虽然这些网络实现了卓越的性能，但它们缺乏可分解成直观和可理解的组件的能力，这使得它们很难解释。因此，当今天的智能系统失败时，它们失败得非常可耻，没有警告或解释，让用户盯着不连贯的输出，想知道为什么。</p><blockquote class="le"><p id="8640" class="lf lg jj bd lh li lj lk ll lm ln ld dk translated">深度学习模型的可解释性对于建立信任并将其成功融入我们的日常生活至关重要。为了实现这个目标，模型透明性对于解释他们为什么预测他们所预测的是有用的。</p></blockquote><p id="05c8" class="pw-post-body-paragraph kg kh jj ki b kj lo kl km kn lp kp kq kr lq kt ku kv lr kx ky kz ls lb lc ld im bi translated">概括地说，这种透明性在人工智能(AI)进化的三个阶段都是有用的。</p><blockquote class="lt lu lv"><p id="cb91" class="kg kh lw ki b kj kk kl km kn ko kp kq lx ks kt ku ly kw kx ky lz la lb lc ld im bi translated">首先，当人工智能相对弱于人类，还不能可靠地“部署”时，透明性和解释的目标是识别故障模式。</p><p id="0423" class="kg kh lw ki b kj kk kl km kn ko kp kq lx ks kt ku ly kw kx ky lz la lb lc ld im bi translated">第二，当人工智能与人类相当并且可靠地“可部署”时，目标是在用户中建立适当的信任和信心。</p><p id="58e3" class="kg kh lw ki b kj kk kl km kn ko kp kq lx ks kt ku ly kw kx ky lz la lb lc ld im bi translated">第三，当人工智能明显强于人类时，解释的目标是机器教学，即教人类如何做出更好的决定。</p></blockquote><p id="8afb" class="pw-post-body-paragraph kg kh jj ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在<a class="ae jg" rel="noopener" target="_blank" href="/demystifying-convolutional-neural-networks-using-class-activation-maps-fe94eda4cef1">之前的文章中，</a>我们讨论了卷积神经网络中的可解释性问题，并讨论了一种非常流行的技术，称为类激活图或 CAM，用于在一定程度上解决该问题。虽然 CAM 是一种很好的技术，可以揭开 CNN 工作的神秘面纱，并在开发的应用程序中建立客户信任，但它们有一些局限性。CAM 的一个缺点是，它要求特征映射直接位于 softmax 层之前，因此它适用于特定类型的 CNN 架构，该架构在预测之前立即对卷积映射执行全局平均池。(即 conv 特征地图→全球平均池→softmax 图层)。在某些任务上，这种体系结构可能比一般网络实现的精度差，或者根本不适用于新的任务。</p><p id="6234" class="pw-post-body-paragraph kg kh jj ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在这篇文章中，我们讨论了一个 CAM 的推广，称为 Grad-Cam。Grad-Cam 于 2017 年发布，旨在改善 Cam 的缺点，并声称可以兼容任何一种架构。该技术不需要对现有模型架构进行任何修改，这使得它可以应用于任何基于 CNN 的架构，包括那些用于图像字幕和视觉问答的架构。对于全卷积架构，Grad-Cam 简化为 Cam。</p><h1 id="e5d6" class="ma mb jj bd mc md me mf mg mh mi mj mk ml mm mn mo mp mq mr ms mt mu mv mw mx bi translated">方法:</h1><p id="ef26" class="pw-post-body-paragraph kg kh jj ki b kj my kl km kn mz kp kq kr na kt ku kv nb kx ky kz nc lb lc ld im bi translated">一些先前的作品已经断言，CNN 中的更深层次的表示捕获了最好的高级结构。此外，CNN 自然地重新训练在全连接层中丢失的空间信息，因此我们可以期望最后的卷积层在高级语义和详细的空间信息之间具有最佳的折衷。</p><p id="4aec" class="pw-post-body-paragraph kg kh jj ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">与 Cam 不同，Grad-Cam 使用流入 CNN 最后一个卷积层的梯度信息来了解每个神经元，以做出感兴趣的决策。为了获得任何类别 c 的宽度 u 和高度 v 的类别区别定位图，我们首先计算类别 c 的分数 yc(在 softmax 之前)相对于卷积层的特征图 Ak 的梯度。这些流回的梯度被全局平均汇集，以获得目标类的神经元重要性权重 ak。</p><figure class="ne nf ng nh gt iv gh gi paragraph-image"><div class="gh gi nd"><img src="../Images/d9f05cac455f840dd133a04239f970f4.png" data-original-src="https://miro.medium.com/v2/resize:fit:796/format:webp/1*RE3V1anNLUuYd18NbBuQjg.png"/></div><figcaption class="jc jd gj gh gi je jf bd b be z dk"><strong class="bd ni">Figure 1</strong>.Calculating weights ak</figcaption></figure><p id="3ae5" class="pw-post-body-paragraph kg kh jj ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在为目标类 c 计算 ak 之后，我们执行激活图的加权组合，并在其后跟随 ReLU。</p><figure class="ne nf ng nh gt iv gh gi paragraph-image"><div class="gh gi nj"><img src="../Images/37c892f5d623c7837f07a5d634ac1c0e.png" data-original-src="https://miro.medium.com/v2/resize:fit:794/format:webp/1*FqE04KDQukS5h6doLszqNQ.png"/></div><figcaption class="jc jd gj gh gi je jf bd b be z dk"><strong class="bd ni">Figure 2. </strong>Linear Combination followed by ReLU resulting in final class discriminative map.</figcaption></figure><p id="6d3b" class="pw-post-body-paragraph kg kh jj ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">这导致与卷积特征图大小相同的粗略热图。我们将 ReLU 应用于线性组合，因为我们只对对感兴趣的类别有积极影响的特征感兴趣。如果没有 ReLU，类激活映射会突出显示比所需更多的内容，因此会导致低本地化性能。</p><p id="1a54" class="pw-post-body-paragraph kg kh jj ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">每个计算机视觉任务的完整流水线如图 2 所示，以便更清楚地了解这一重要概念。</p><figure class="ne nf ng nh gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi nk"><img src="../Images/3477fe86ca36bb2f4846b91ff064e79a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Ywow17bDVkNzBnIA8NAUxg.png"/></div></div><figcaption class="jc jd gj gh gi je jf bd b be z dk"><strong class="bd ni">Figure 3.</strong>Complete pipeline extending towards specific tasks.</figcaption></figure><h1 id="9cc6" class="ma mb jj bd mc md me mf mg mh mi mj mk ml mm mn mo mp mq mr ms mt mu mv mw mx bi translated">使用 Keras 实现 Grad Cam</h1><p id="c17a" class="pw-post-body-paragraph kg kh jj ki b kj my kl km kn mz kp kq kr na kt ku kv nb kx ky kz nc lb lc ld im bi translated">实施分为以下步骤:-</p><ol class=""><li id="d9c3" class="nl nm jj ki b kj kk kn ko kr nn kv no kz np ld nq nr ns nt bi translated">首先，我们需要一个模型来运行向前传递。我们使用在 Imagenet 上预先训练的 VGG16。您可以使用任何模型，因为与 Cam 不同，GradCam 不需要特定的架构，并且与任何卷积神经网络兼容。</li></ol><figure class="ne nf ng nh gt iv"><div class="bz fp l di"><div class="nu nv l"/></div></figure><p id="ce68" class="pw-post-body-paragraph kg kh jj ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">2.定义模型后，我们加载一个样本图像并对其进行预处理，使其与模型兼容。</p><figure class="ne nf ng nh gt iv"><div class="bz fp l di"><div class="nu nv l"/></div></figure><figure class="ne nf ng nh gt iv gh gi paragraph-image"><div class="gh gi nw"><img src="../Images/0546e9238dbdbc635de783c4778e2147.png" data-original-src="https://miro.medium.com/v2/resize:fit:514/format:webp/1*1VVTbKm80Vw9osqLMbdQwg.png"/></div><figcaption class="jc jd gj gh gi je jf bd b be z dk"><strong class="bd ni">Input Image</strong></figcaption></figure><p id="03b0" class="pw-post-body-paragraph kg kh jj ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">3.然后，我们使用该模型对样本图像进行预测，并解码前三个预测。正如您在下图中看到的，我们只考虑了模型中的前三个预测，模型中的第一个预测是 boxer。</p><figure class="ne nf ng nh gt iv"><div class="bz fp l di"><div class="nu nv l"/></div></figure><figure class="ne nf ng nh gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi nx"><img src="../Images/f660b41c6084ea742b312103fe622312.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*OZBOd0M3IEWa_fGRIhIfKw.png"/></div></div><figcaption class="jc jd gj gh gi je jf bd b be z dk"><strong class="bd ni">Decoded predictions and Target Class</strong></figcaption></figure><p id="bde3" class="pw-post-body-paragraph kg kh jj ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">5.在下一步中，我们找到目标类得分 yc 相对于最后一个卷积层的特征图 Ak 的梯度。直观地，它告诉我们每个渠道对于目标阶层有多重要。变量 grads 返回一个张量，将在下面的步骤中使用。</p><figure class="ne nf ng nh gt iv"><div class="bz fp l di"><div class="nu nv l"/></div></figure><p id="90cc" class="pw-post-body-paragraph kg kh jj ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">6.这样获得的梯度然后被全局平均，以获得对应于目标类的神经元重要权重<strong class="ki jk"> ak </strong>，如图 1 所示。这将返回一个传递给 Keras 函数的张量，该函数将图像作为输入，并返回 pooled_grads 以及来自最后一个卷积层的激活贴图。</p><figure class="ne nf ng nh gt iv"><div class="bz fp l di"><div class="nu nv l"/></div></figure><p id="1710" class="pw-post-body-paragraph kg kh jj ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">7.之后，我们将每个激活图与相应的混合梯度相乘，该混合梯度作为权重来确定每个通道对于目标类有多重要。然后，我们取沿着通道的所有激活图的平均值，并且所获得的结果是最终的类别区分显著图。</p><figure class="ne nf ng nh gt iv"><div class="bz fp l di"><div class="nu nv l"/></div></figure><figure class="ne nf ng nh gt iv gh gi paragraph-image"><div class="gh gi ny"><img src="../Images/f0924302f0cbf3da2cd9b753ce2907f1.png" data-original-src="https://miro.medium.com/v2/resize:fit:502/format:webp/1*KKu5ZcSqFZatXabkM4VzeA.png"/></div><figcaption class="jc jd gj gh gi je jf bd b be z dk"><strong class="bd ni">Class Discriminative Map</strong></figcaption></figure><p id="968f" class="pw-post-body-paragraph kg kh jj ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">8.然后，我们对生成的热图应用 ReLU，以便只保留对输出图有积极影响的要素。但是我们看到热图中没有太多的负强度，因此在应用 ReLU 后热图没有太大的变化。</p><figure class="ne nf ng nh gt iv"><div class="bz fp l di"><div class="nu nv l"/></div></figure><figure class="ne nf ng nh gt iv gh gi paragraph-image"><div class="gh gi ny"><img src="../Images/f0924302f0cbf3da2cd9b753ce2907f1.png" data-original-src="https://miro.medium.com/v2/resize:fit:502/format:webp/1*KKu5ZcSqFZatXabkM4VzeA.png"/></div><figcaption class="jc jd gj gh gi je jf bd b be z dk"><strong class="bd ni">Class Discriminative Map after ReLU</strong></figcaption></figure><p id="9f81" class="pw-post-body-paragraph kg kh jj ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">9.然后，我们将热图的每个强度值除以最大强度值，以便标准化热图，使所有值都在 0 和 1 之间。</p><figure class="ne nf ng nh gt iv"><div class="bz fp l di"><div class="nu nv l"/></div></figure><figure class="ne nf ng nh gt iv gh gi paragraph-image"><div class="gh gi ny"><img src="../Images/1c2a18b8b3cf100bdfae1640f5d1c917.png" data-original-src="https://miro.medium.com/v2/resize:fit:502/format:webp/1*q3AkcUfxb70-GGTYRedhhw.png"/></div><figcaption class="jc jd gj gh gi je jf bd b be z dk"><strong class="bd ni">Class Discriminative Saliency Map after Normalization</strong></figcaption></figure><p id="6ab5" class="pw-post-body-paragraph kg kh jj ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">10.最后，我们对生成的热图进行上采样，以匹配输入图像的尺寸，并将其覆盖在输入图像上，以便查看结果。</p><figure class="ne nf ng nh gt iv"><div class="bz fp l di"><div class="nu nv l"/></div></figure><figure class="ne nf ng nh gt iv gh gi paragraph-image"><div class="gh gi nw"><img src="../Images/d632f1fd735b31ce2f61f040ef88302a.png" data-original-src="https://miro.medium.com/v2/resize:fit:514/format:webp/1*qcxeQ3rGVINmb4vPxj5E6w.png"/></div><figcaption class="jc jd gj gh gi je jf bd b be z dk"><strong class="bd ni">Final Saliency Map with Bull Dog as Target Class</strong></figcaption></figure><h1 id="f517" class="ma mb jj bd mc md me mf mg mh mi mj mk ml mm mn mo mp mq mr ms mt mu mv mw mx bi translated"><strong class="ak">结论:</strong></h1><p id="dafc" class="pw-post-body-paragraph kg kh jj ki b kj my kl km kn mz kp kq kr na kt ku kv nb kx ky kz nc lb lc ld im bi translated">在这篇文章中，我们学习了一种解释卷积神经网络的新技术，卷积神经网络是一种艺术架构，特别是对于图像相关的任务。Grad Cam 对其前身 Cam 进行了改进，并提供了更好的定位和清晰的类别区分显著图，这些图指导我们揭开黑盒模型背后的复杂性。可解释机器学习领域的研究正在以更快的速度前进，并被证明对于建立客户信任和帮助改进模型至关重要。</p><p id="c3c7" class="pw-post-body-paragraph kg kh jj ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在接下来的文章中，我将探索该领域中与卷积神经网络相关的更多最新研究，并将借助直观的可视化和简单的实现来揭开复杂概念的神秘面纱。如果你喜欢这篇文章，留下掌声激励我，如果你有任何建议，请随时在<a class="ae jg" href="https://www.linkedin.com/in/divyanshu-mishra-ai/" rel="noopener ugc nofollow" target="_blank"> Linkedin </a>上与我联系，或者在<a class="ae jg" href="https://twitter.com/Perceptron97" rel="noopener ugc nofollow" target="_blank"> twitter </a>上关注我。</p></div></div>    
</body>
</html>