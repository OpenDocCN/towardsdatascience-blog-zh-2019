<html>
<head>
<title>Simple Linear Regression From Scratch in Numpy</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">Numpy 中从头开始的简单线性回归</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/simple-linear-regression-from-scratch-in-numpy-871335e14b7a?source=collection_archive---------10-----------------------#2019-10-09">https://towardsdatascience.com/simple-linear-regression-from-scratch-in-numpy-871335e14b7a?source=collection_archive---------10-----------------------#2019-10-09</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><p id="ad90" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">线性回归很可能是你已经学会的，或者打算学习的第一个“机器学习”算法。这是一个简单的算法，最初是在统计领域开发的，并作为理解输入和输出变量之间关系的模型进行研究。</p><p id="acd0" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">顾名思义，它是一个线性模型，因此它假设输入变量(<strong class="js iu"><em class="ko">)X</em></strong>)和单个(<em class="ko">【连续】</em>)输出变量(<strong class="js iu"> <em class="ko"> y </em> </strong>)之间是线性关系。更准确地说，<strong class="js iu"> <em class="ko"> y </em> </strong>可以从输入变量的线性组合中计算出来。</p><p id="2f53" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">在只有一个输入变量的情况下，该方法被称为<strong class="js iu">简单线性回归</strong>，这将是本文的主题。你可以说在现实世界中你有不止一个输入变量，这是真的，但是从基础开始总是一个好主意。</p><p id="b9db" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">线性方程为每个输入值分配一个比例因子，称为系数，通常用希腊字母 Beta ( <strong class="js iu"> <em class="ko"> β </em> </strong>)表示。增加了一个系数，给线一个额外的自由度(<em class="ko">向上或向下</em>移动线)，称为截距或<strong class="js iu">偏差系数</strong>。</p><p id="4511" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">简单的线性回归可以表示为:</p><figure class="kq kr ks kt gt ku gh gi paragraph-image"><div class="gh gi kp"><img src="../Images/7103a03b398cd766148c96734c8ecfd8.png" data-original-src="https://miro.medium.com/v2/resize:fit:450/format:webp/1*xZubuTVDPJrvYkBeKtwcdw.png"/></div></figure><p id="0a97" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">如果你有一个以上的输入变量，回归“线”将被称为一个平面或超平面。此外，不用说，你会有更多的β系数，每一个乘以一定的输入值。如果β系数为零，它告诉你那个位置的变量对模型没有影响。</p><p id="787a" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">学习一个线性回归模型意味着<strong class="js iu">用你现有的数据来估计表示中使用的系数的值。</strong></p></div><div class="ab cl kx ky hx kz" role="separator"><span class="la bw bk lb lc ld"/><span class="la bw bk lb lc ld"/><span class="la bw bk lb lc"/></div><div class="im in io ip iq"><h1 id="29cc" class="le lf it bd lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb bi translated">线性回归的假设</h1><p id="84eb" class="pw-post-body-paragraph jq jr it js b jt mc jv jw jx md jz ka kb me kd ke kf mf kh ki kj mg kl km kn im bi translated">准备用于线性回归的数据时，您应该记住以下几点:</p><ol class=""><li id="7aeb" class="mh mi it js b jt ju jx jy kb mj kf mk kj ml kn mm mn mo mp bi translated"><strong class="js iu">线性假设</strong> —模型假设变量之间的关系是线性的</li><li id="7620" class="mh mi it js b jt mq jx mr kb ms kf mt kj mu kn mm mn mo mp bi translated"><strong class="js iu">无噪声</strong> —模型假设输入和输出变量没有噪声——因此，如果可能的话，移除异常值</li><li id="5f79" class="mh mi it js b jt mq jx mr kb ms kf mt kj mu kn mm mn mo mp bi translated"><strong class="js iu">无共线性</strong>-当输入变量高度相关时，模型会过度拟合</li><li id="9388" class="mh mi it js b jt mq jx mr kb ms kf mt kj mu kn mm mn mo mp bi translated"><strong class="js iu">正态分布</strong>-如果输入和输出变量呈正态分布，模型将做出更可靠的预测。如果不是这样，试着对你的变量进行一些变换，使它们看起来更正常</li><li id="3696" class="mh mi it js b jt mq jx mr kb ms kf mt kj mu kn mm mn mo mp bi translated"><strong class="js iu">重定标输入</strong> —使用定标器或规格化器进行更可靠的预测</li></ol></div><div class="ab cl kx ky hx kz" role="separator"><span class="la bw bk lb lc ld"/><span class="la bw bk lb lc ld"/><span class="la bw bk lb lc"/></div><div class="im in io ip iq"><h1 id="3fd0" class="le lf it bd lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb bi translated">贝塔系数公式</h1><p id="6ce8" class="pw-post-body-paragraph jq jr it js b jt mc jv jw jx md jz ka kb me kd ke kf mf kh ki kj mg kl km kn im bi translated">在简单线性回归中，有两个系数——β0 和β1。它们不一定要‘学习’，你可以通过一个简单的公式计算出来(<em class="ko">仅用于简单的线性回归</em>):</p><figure class="kq kr ks kt gt ku gh gi paragraph-image"><div role="button" tabindex="0" class="mw mx di my bf mz"><div class="gh gi mv"><img src="../Images/99a5af523a893cf942ce2ec9b84967e4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*i1eypsh8N9GeBpaYDuA_UQ.png"/></div></div></figure><figure class="kq kr ks kt gt ku gh gi paragraph-image"><div class="gh gi na"><img src="../Images/e78e81f5e9b7b01e0b27e90f7d168303.png" data-original-src="https://miro.medium.com/v2/resize:fit:1038/format:webp/1*XFJ198TREeESsBo9lfYYuQ.png"/></div></figure><p id="b237" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">可以手工计算，也可以用 Python 计算。我会用 Python。</p></div><div class="ab cl kx ky hx kz" role="separator"><span class="la bw bk lb lc ld"/><span class="la bw bk lb lc ld"/><span class="la bw bk lb lc"/></div><div class="im in io ip iq"><h1 id="ac38" class="le lf it bd lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb bi translated">数据集介绍</h1><p id="3979" class="pw-post-body-paragraph jq jr it js b jt mc jv jw jx md jz ka kb me kd ke kf mf kh ki kj mg kl km kn im bi translated">我决定不从网上下载任意的数据集，而是自己制作。它由 300 个任意点组成:</p><figure class="kq kr ks kt gt ku gh gi paragraph-image"><div class="gh gi nb"><img src="../Images/c1e96f9bd4e1da9f9bc678340159870c.png" data-original-src="https://miro.medium.com/v2/resize:fit:600/format:webp/1*0i7xYu2IXovk4ZeY_4Gp4w.png"/></div></figure><p id="9374" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">快速散点图将揭示变量之间清晰的线性趋势:</p><figure class="kq kr ks kt gt ku gh gi paragraph-image"><div role="button" tabindex="0" class="mw mx di my bf mz"><div class="gh gi nc"><img src="../Images/edb316e3425abdbb53659bfb06ad6e40.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*hTmxVU9qwlsTKcBEq9eeSA.png"/></div></div></figure><p id="9d77" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">现在，您可以将<strong class="js iu"> <em class="ko"> x </em> </strong>和<strong class="js iu"> <em class="ko"> y </em> </strong>插入上面的公式中。首先，我将计算β1 系数:</p><figure class="kq kr ks kt gt ku gh gi paragraph-image"><div class="gh gi nd"><img src="../Images/a164529f690dbdb39c892257d241769c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1026/format:webp/1*E8F-X2ssSftUMzlMctxFFQ.png"/></div></figure><p id="2f63" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">这并不难。β0 或偏差系数的计算将更加简单:</p><figure class="kq kr ks kt gt ku gh gi paragraph-image"><div role="button" tabindex="0" class="mw mx di my bf mz"><div class="gh gi ne"><img src="../Images/7b3d45f536c2fab2e497defa0e58b0e0.png" data-original-src="https://miro.medium.com/v2/resize:fit:648/format:webp/1*Q8msb3ilIV3L2fdF-uPIJw.png"/></div></div></figure><p id="4cd0" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">仅此而已。你现在可以做预测了。为此，我决定声明一个函数，<strong class="js iu"><em class="ko">calc _ predictions()</em></strong>，它将接受<strong class="js iu"> <em class="ko"> x </em> </strong>项作为输入。然后，您可以轻松计算预测值:</p><figure class="kq kr ks kt gt ku gh gi paragraph-image"><div class="gh gi nf"><img src="../Images/55bef63117c4fac4da9eceb88f08d2d3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1340/format:webp/1*BFQcB8Ba6FznpUMDn-YZ6g.png"/></div></figure><p id="b3d6" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">现在那些<strong class="js iu"> <em class="ko"> y_preds </em> </strong>可以用来绘制回归线:</p><figure class="kq kr ks kt gt ku gh gi paragraph-image"><div role="button" tabindex="0" class="mw mx di my bf mz"><div class="gh gi ng"><img src="../Images/1e3830187d04cf1147f4c2cf8a352f78.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*lyMZe9N2Iv9vDN_NnS_xMQ.png"/></div></div></figure><figure class="kq kr ks kt gt ku gh gi paragraph-image"><div role="button" tabindex="0" class="mw mx di my bf mz"><div class="gh gi nh"><img src="../Images/1cbba864b62e2b9c9ded9681e213e5c0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*WyOOfRcJrlBDwQPLJYJWqQ.png"/></div></div></figure><p id="7c3d" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu"> <em class="ko">那才叫爽。</em> </strong>快也。但是你现在可能想知道，有没有更简单快捷的方法来计算系数？</p></div><div class="ab cl kx ky hx kz" role="separator"><span class="la bw bk lb lc ld"/><span class="la bw bk lb lc ld"/><span class="la bw bk lb lc"/></div><div class="im in io ip iq"><h1 id="ab3a" class="le lf it bd lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb bi translated">更简单的方法</h1><p id="e015" class="pw-post-body-paragraph jq jr it js b jt mc jv jw jx md jz ka kb me kd ke kf mf kh ki kj mg kl km kn im bi translated">你不必使用上面的公式来获得系数，有一个更短的方法。还涉及到公式的用法，不过要短很多。偏差截距的公式保持不变，但β1 的公式发生了变化:</p><figure class="kq kr ks kt gt ku gh gi paragraph-image"><div class="gh gi ni"><img src="../Images/dedb5dc077f23d3f8cda8f0ba6ff097d.png" data-original-src="https://miro.medium.com/v2/resize:fit:874/format:webp/1*Ud3uL4DiZ21ZhY854FM0ow.png"/></div></figure><p id="b5fd" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">下面是用 Python 实现它的方法:</p><figure class="kq kr ks kt gt ku gh gi paragraph-image"><div class="gh gi nj"><img src="../Images/83c945c02410a9c3222078fcd87d802e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1116/format:webp/1*ospvACyNhh5lGN7KTeRO_g.png"/></div></figure><p id="2d46" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">请注意您必须如何使用数组索引来获得相关系数，您的任务是探索如果不使用它会发生什么。<br/>你可以看到系数值和之前计算的一样，所以一切正常(<em class="ko">万岁</em>)。</p></div><div class="ab cl kx ky hx kz" role="separator"><span class="la bw bk lb lc ld"/><span class="la bw bk lb lc ld"/><span class="la bw bk lb lc"/></div><div class="im in io ip iq"><h1 id="6f35" class="le lf it bd lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb bi translated">模型评估</h1><p id="c03c" class="pw-post-body-paragraph jq jr it js b jt mc jv jw jx md jz ka kb me kd ke kf mf kh ki kj mg kl km kn im bi translated">评估一个回归模型的方法有很多，但我会用<a class="ae nk" href="https://en.wikipedia.org/wiki/Root-mean-square_deviation" rel="noopener ugc nofollow" target="_blank"> <em class="ko">均方根误差</em> </a>。计算方法如下:</p><figure class="kq kr ks kt gt ku gh gi paragraph-image"><div class="gh gi nl"><img src="../Images/717563c6d2f487f61412619b61480f23.png" data-original-src="https://miro.medium.com/v2/resize:fit:806/format:webp/1*FIGwfLLrAYj9yYvcpVnuTg.png"/></div></figure><p id="c61e" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">其中<strong class="js iu"> <em class="ko"> Pi </em> </strong>为预测值。</p><p id="3a88" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">要在 Python 中使用它，有两个选项:</p><ol class=""><li id="457a" class="mh mi it js b jt ju jx jy kb mj kf mk kj ml kn mm mn mo mp bi translated">从 Scikit 中导入 MSE 学习并求它的平方根</li><li id="4263" class="mh mi it js b jt mq jx mr kb ms kf mt kj mu kn mm mn mo mp bi translated">从头开始写</li></ol><p id="be44" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">我将使用第二个选项，因为计算非常简单:</p><figure class="kq kr ks kt gt ku gh gi paragraph-image"><div class="gh gi nm"><img src="../Images/ea990cb7292bfd61cc146318abce8c15.png" data-original-src="https://miro.medium.com/v2/resize:fit:1230/format:webp/1*EZDXHlmbWdR9X6EdvoLi7A.png"/></div></figure><p id="fd0a" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">现在可以对模型进行评估:</p><figure class="kq kr ks kt gt ku gh gi paragraph-image"><div class="gh gi nn"><img src="../Images/41f3dc548a75b10d9f42842ddf7038f3.png" data-original-src="https://miro.medium.com/v2/resize:fit:434/format:webp/1*9U92Jgr9KTXilRuHcXgeEA.png"/></div></figure></div><div class="ab cl kx ky hx kz" role="separator"><span class="la bw bk lb lc ld"/><span class="la bw bk lb lc ld"/><span class="la bw bk lb lc"/></div><div class="im in io ip iq"><h1 id="e050" class="le lf it bd lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb bi translated">最后的话</h1><p id="c08d" class="pw-post-body-paragraph jq jr it js b jt mc jv jw jx md jz ka kb me kd ke kf mf kh ki kj mg kl km kn im bi translated">该说再见了。这是一篇相当短的文章，但是我想说这是线性回归的一个很好的介绍。稍后，我将从头开始发表一篇关于多元线性回归的文章，它在现实世界中有实际应用，因为您的数据集可能有多个输入变量。</p><p id="77e8" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">在此之前，尝试在您的数据集上使用这些方程，然后尝试将结果与 Scikit-Learn 的线性回归进行比较。</p></div><div class="ab cl kx ky hx kz" role="separator"><span class="la bw bk lb lc ld"/><span class="la bw bk lb lc ld"/><span class="la bw bk lb lc"/></div><div class="im in io ip iq"><p id="e735" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">喜欢这篇文章吗？成为 <a class="ae nk" href="https://medium.com/@radecicdario/membership" rel="noopener"> <em class="ko">中等会员</em> </a> <em class="ko">继续无限制学习。如果你使用下面的链接，我会收到你的一部分会员费，不需要你额外付费。</em></p><div class="no np gp gr nq nr"><a href="https://medium.com/@radecicdario/membership" rel="noopener follow" target="_blank"><div class="ns ab fo"><div class="nt ab nu cl cj nv"><h2 class="bd iu gy z fp nw fr fs nx fu fw is bi translated">通过我的推荐链接加入 Medium-Dario rade ci</h2><div class="ny l"><h3 class="bd b gy z fp nw fr fs nx fu fw dk translated">作为一个媒体会员，你的会员费的一部分会给你阅读的作家，你可以完全接触到每一个故事…</h3></div><div class="nz l"><p class="bd b dl z fp nw fr fs nx fu fw dk translated">medium.com</p></div></div><div class="oa l"><div class="ob l oc od oe oa of kv nr"/></div></div></a></div></div></div>    
</body>
</html>