<html>
<head>
<title>A gentle guide into Decision Trees with Python</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">Python 决策树的简明指南</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/a-gentle-guide-into-decision-trees-with-python-cbfc76deb748?source=collection_archive---------14-----------------------#2019-05-01">https://towardsdatascience.com/a-gentle-guide-into-decision-trees-with-python-cbfc76deb748?source=collection_archive---------14-----------------------#2019-05-01</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><figure class="gl gn jr js jt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi jq"><img src="../Images/2d9ec0b718fe7c8077895360b2c789b0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*jqS4JUY9ySWFXZkWLKFdrg.png"/></div></div></figure><p id="c4ab" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">决策树算法是一种监督学习模型，用于用一系列训练变量预测因变量。决策树算法可用于分类和回归目的。</p><p id="3f4b" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">在这个特别的项目中，我将用一个离散随机变量的分类来说明它。</p><h2 id="0ffd" class="kz la it bd lb lc ld dn le lf lg dp lh km li lj lk kq ll lm ln ku lo lp lq lr bi translated">决策树可以回答的一些问题。</h2><ol class=""><li id="cd08" class="ls lt it kd b ke lu ki lv km lw kq lx ku ly ky lz ma mb mc bi translated">贷款申请人是否应该被接受？这是基于他/她的历史和其他措施。</li><li id="fe75" class="ls lt it kd b ke md ki me km mf kq mg ku mh ky lz ma mb mc bi translated">哪种药物最适合特定的病人。</li><li id="a886" class="ls lt it kd b ke md ki me km mf kq mg ku mh ky lz ma mb mc bi translated">癌细胞是良性的还是恶性的？</li><li id="805a" class="ls lt it kd b ke md ki me km mf kq mg ku mh ky lz ma mb mc bi translated">电子邮件是否是垃圾邮件？</li></ol><p id="9363" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">以及现实生活中更多的场景。</p><h2 id="273c" class="kz la it bd lb lc ld dn le lf lg dp lh km li lj lk kq ll lm ln ku lo lp lq lr bi translated">理解决策树算法。</h2><p id="dcde" class="pw-post-body-paragraph kb kc it kd b ke lu kg kh ki lv kk kl km mi ko kp kq mj ks kt ku mk kw kx ky im bi translated">决策树是使用递归分区将数据分为两组或更多组来构建的。</p><h2 id="3684" class="kz la it bd lb lc ld dn le lf lg dp lh km li lj lk kq ll lm ln ku lo lp lq lr bi translated">现实生活的例子。</h2><p id="58bc" class="pw-post-body-paragraph kb kc it kd b ke lu kg kh ki lv kk kl km mi ko kp kq mj ks kt ku mk kw kx ky im bi translated">假设我们有随着时间的推移进行癌症筛查的患者的数据。基于来自筛选练习的测试，筛选的细胞被分类为良性和恶性。基于该数据，可以建立决策树模型，以比医生更好地为未来的患者以最高的准确度预测这些病例。<br/>决策树从具有最高预测能力、较少杂质和较低熵的变量开始，逐个变量分割数据变量。</p><p id="22a9" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">该方法的主要目的是最小化杂质和每个节点。节点的杂质通过节点中数据的的<strong class="kd iu">熵来计算。</strong></p><p id="7021" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated"><strong class="kd iu">熵</strong></p><p id="9b6b" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">熵是信息量的无序或简单地说是数据的随机性或不确定性。</p><p id="fb22" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">数据集的熵取决于节点的随机性。应当注意，熵越低，分布越不均匀，节点越纯。如果样本完全同质，则熵完全为零，如果样本被等分，则熵为 1。</p><p id="88ab" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">参考上述数据，假设一个节点具有 7 个恶性和 1 个良性，而另一个节点具有 3 个恶性和 5 个良性，前者与后者相比具有低熵。</p><p id="8b40" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">这是熵的数学计算方法:</p><figure class="mm mn mo mp gt ju gh gi paragraph-image"><div class="gh gi ml"><img src="../Images/cc4923fdfbb6b70fdaa07c0825a29faa.png" data-original-src="https://miro.medium.com/v2/resize:fit:1154/0*GIrDElJGwwMEKJbc"/></div></figure><p id="7cf3" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">最佳树的选择取决于分裂后具有最高<strong class="kd iu">信息增益</strong>的节点。</p><p id="b557" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated"><strong class="kd iu">信息增益</strong></p><p id="b37f" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">这是拆分后可以增加确定性水平的信息。计算如下。</p><figure class="mm mn mo mp gt ju gh gi paragraph-image"><div class="gh gi mq"><img src="../Images/c3112878a7ca66a71955848153e70d9d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1202/0*KD_05P46vtTl7b_D"/></div></figure><p id="3177" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">这个过程继续构建一个基本的决策树。下面是 python 中的一步一步的过程。</p><h2 id="f123" class="kz la it bd lb lc ld dn le lf lg dp lh km li lj lk kq ll lm ln ku lo lp lq lr bi translated">用 Python 实现。</h2><h2 id="0330" class="kz la it bd lb lc ld dn le lf lg dp lh km li lj lk kq ll lm ln ku lo lp lq lr bi translated">导入库</h2><pre class="mm mn mo mp gt mr ms mt mu aw mv bi"><span id="bdb0" class="kz la it ms b gy mw mx l my mz">import pandas as pd<br/>import matplotlib.pyplot as plt<br/>import numpy as np<br/>import seaborn as sns</span></pre><h2 id="a4d1" class="kz la it bd lb lc ld dn le lf lg dp lh km li lj lk kq ll lm ln ku lo lp lq lr bi translated"><strong class="ak">数据摄取</strong></h2><pre class="mm mn mo mp gt mr ms mt mu aw mv bi"><span id="a2f8" class="kz la it ms b gy mw mx l my mz">loan_data = pd.read_csv(“loan_data.csv”)<br/>loan_data.info()<br/>loan_data.describe()<br/>loan_data.sample(5)</span></pre><h2 id="8fe8" class="kz la it bd lb lc ld dn le lf lg dp lh km li lj lk kq ll lm ln ku lo lp lq lr bi translated">探索性数据分析。</h2><p id="7e17" class="pw-post-body-paragraph kb kc it kd b ke lu kg kh ki lv kk kl km mi ko kp kq mj ks kt ku mk kw kx ky im bi translated">这是一个简短的 EDA，因为该项目旨在决策树插图。</p><pre class="mm mn mo mp gt mr ms mt mu aw mv bi"><span id="9697" class="kz la it ms b gy mw mx l my mz">plt.figure(figsize=(10,6))<br/>loan_data[loan_data[‘credit.policy’]==1][‘fico’].hist(alpha=0.5,color=’blue’,<br/> bins=30,label=’Credit.Policy=1')<br/>loan_data[loan_data[‘credit.policy’]==0][‘fico’].hist(alpha=0.5,color=’red’,<br/> bins=30,label=’Credit.Policy=0')<br/>plt.legend()<br/>plt.xlabel(‘FICO’)</span></pre><h1 id="e717" class="na la it bd lb nb nc nd le ne nf ng lh nh ni nj lk nk nl nm ln nn no np lq nq bi translated">设置数据。</h1><p id="4dc3" class="pw-post-body-paragraph kb kc it kd b ke lu kg kh ki lv kk kl km mi ko kp kq mj ks kt ku mk kw kx ky im bi translated">我这里的数据有一些我必须驯服的分类变量，因为如果格式不正确，模型算法可能无法很好地处理这些数据。</p><pre class="mm mn mo mp gt mr ms mt mu aw mv bi"><span id="2f45" class="kz la it ms b gy mw mx l my mz">categorical_var = [‘purpose’]<br/>loan_data2 = pd.get_dummies(data= loan_data,columns=categorical_var,drop_first=True)<br/>loan_data2.columns</span></pre><h1 id="f084" class="na la it bd lb nb nc nd le ne nf ng lh nh ni nj lk nk nl nm ln nn no np lq nq bi translated">列车测试分离</h1><pre class="mm mn mo mp gt mr ms mt mu aw mv bi"><span id="be9b" class="kz la it ms b gy mw mx l my mz">from sklearn.model_selection import train_test_split<br/>X = loan_data2.drop('not.fully.paid',axis = 1)<br/>y = loan_data2['not.fully.paid']<br/>X_trainset, X_testset, y_trainset, y_testset = train_test_split(X, y, test_size=0.30, random_state=2)</span></pre><h1 id="266f" class="na la it bd lb nb nc nd le ne nf ng lh nh ni nj lk nk nl nm ln nn no np lq nq bi translated">训练决策树模型</h1><pre class="mm mn mo mp gt mr ms mt mu aw mv bi"><span id="7a04" class="kz la it ms b gy mw mx l my mz">from sklearn.tree import DecisionTreeClassifier<br/>loanTree = DecisionTreeClassifier(criterion="entropy", max_depth = 4)<br/>loanTree<br/>loanTree.fit(X_trainset,y_trainset)</span></pre><h1 id="50dc" class="na la it bd lb nb nc nd le ne nf ng lh nh ni nj lk nk nl nm ln nn no np lq nq bi translated">模型评估</h1><pre class="mm mn mo mp gt mr ms mt mu aw mv bi"><span id="9bc6" class="kz la it ms b gy mw mx l my mz">predLoan = loanTree.predict(X_testset)<br/>from sklearn.metrics import confusion_matrix,classification_report,precision_score<br/>print(classification_report(y_testset,predLoan))</span></pre><p id="3f09" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">这产生了 78%的准确度水平</p><h2 id="0ab7" class="kz la it bd lb lc ld dn le lf lg dp lh km li lj lk kq ll lm ln ku lo lp lq lr bi translated">让我们来看看混淆矩阵的可视化</h2><pre class="mm mn mo mp gt mr ms mt mu aw mv bi"><span id="074f" class="kz la it ms b gy mw mx l my mz">sns.heatmap(confusion_matrix(y_testset,predLoan),cmap=”viridis”,lw = 2,annot=True,cbar=False)</span></pre><p id="cadf" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">决策树模型产生了 78%的准确性，这是令人印象深刻的，因为没有进行任何功能工程，甚至没有调整参数来改进模型。</p><p id="cc4a" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">通过应用随机森林分类器算法也可以提高精度，该算法比简单决策树更好。在另一个内核上有更多的内容。</p><h1 id="7628" class="na la it bd lb nb nc nd le ne nf ng lh nh ni nj lk nk nl nm ln nn no np lq nq bi translated">决策树的可视化</h1><pre class="mm mn mo mp gt mr ms mt mu aw mv bi"><span id="9de2" class="kz la it ms b gy mw mx l my mz">from IPython.display import Image  <br/>from sklearn.externals.six import StringIO  <br/>from sklearn.tree import export_graphviz<br/>import pydot</span><span id="e967" class="kz la it ms b gy nr mx l my mz">features = list(X.columns)<br/># features<br/>dot_data = StringIO()  <br/>export_graphviz(loanTree, out_file=dot_data,feature_names=features,filled=True,rounded=True)</span><span id="62c8" class="kz la it ms b gy nr mx l my mz">graph = pydot.graph_from_dot_data(dot_data.getvalue())  <br/>Image(graph[0].create_png())</span></pre><figure class="mm mn mo mp gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi jq"><img src="../Images/545c6d10f88990de832210e0461c5042.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*zrtc98zkC3QCLLBe154Mkw.png"/></div></div></figure><p id="41cf" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">欢迎所有意见、建议和任何改进！</p><p id="8018" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">请在此处查看上面的代码。在我的 Github 库中。</p><p id="3c14" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">干杯！</p></div></div>    
</body>
</html>